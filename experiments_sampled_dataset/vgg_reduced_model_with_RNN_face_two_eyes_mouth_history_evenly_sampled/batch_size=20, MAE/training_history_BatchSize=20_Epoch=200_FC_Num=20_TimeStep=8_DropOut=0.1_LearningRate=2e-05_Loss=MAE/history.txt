Epoch: 1| Step: 0
Training loss: 5.304340362548828
Validation loss: 5.126930452162219

Epoch: 5| Step: 1
Training loss: 5.019325256347656
Validation loss: 5.0958395542637

Epoch: 5| Step: 2
Training loss: 4.512697219848633
Validation loss: 5.065250632583454

Epoch: 5| Step: 3
Training loss: 4.031474590301514
Validation loss: 5.031224799412553

Epoch: 5| Step: 4
Training loss: 5.535286903381348
Validation loss: 4.993323967020999

Epoch: 5| Step: 5
Training loss: 4.914164066314697
Validation loss: 4.952019183866439

Epoch: 5| Step: 6
Training loss: 4.252397060394287
Validation loss: 4.9053635135773686

Epoch: 5| Step: 7
Training loss: 4.684047222137451
Validation loss: 4.852480298729353

Epoch: 5| Step: 8
Training loss: 4.9078898429870605
Validation loss: 4.793233656114148

Epoch: 5| Step: 9
Training loss: 4.884186744689941
Validation loss: 4.727517666355256

Epoch: 5| Step: 10
Training loss: 3.808506727218628
Validation loss: 4.657412108554635

Epoch: 2| Step: 0
Training loss: 4.763221740722656
Validation loss: 4.580516969003985

Epoch: 5| Step: 1
Training loss: 3.992760419845581
Validation loss: 4.497221100714899

Epoch: 5| Step: 2
Training loss: 4.252114772796631
Validation loss: 4.411411680201049

Epoch: 5| Step: 3
Training loss: 3.9634525775909424
Validation loss: 4.323160176636071

Epoch: 5| Step: 4
Training loss: 4.265557765960693
Validation loss: 4.2392754554748535

Epoch: 5| Step: 5
Training loss: 3.694777727127075
Validation loss: 4.157263537888886

Epoch: 5| Step: 6
Training loss: 4.0882248878479
Validation loss: 4.0786801666341805

Epoch: 5| Step: 7
Training loss: 4.5465192794799805
Validation loss: 4.004391731754426

Epoch: 5| Step: 8
Training loss: 3.2619948387145996
Validation loss: 3.929740575052077

Epoch: 5| Step: 9
Training loss: 3.2784030437469482
Validation loss: 3.864378231827931

Epoch: 5| Step: 10
Training loss: 3.7918167114257812
Validation loss: 3.7980273846657044

Epoch: 3| Step: 0
Training loss: 4.487120628356934
Validation loss: 3.7353121080706195

Epoch: 5| Step: 1
Training loss: 3.4152464866638184
Validation loss: 3.678003018902194

Epoch: 5| Step: 2
Training loss: 2.6723804473876953
Validation loss: 3.6248567155612412

Epoch: 5| Step: 3
Training loss: 3.8519387245178223
Validation loss: 3.5759399475589877

Epoch: 5| Step: 4
Training loss: 3.2918872833251953
Validation loss: 3.528869193087342

Epoch: 5| Step: 5
Training loss: 4.013291835784912
Validation loss: 3.4858941519132225

Epoch: 5| Step: 6
Training loss: 3.9019851684570312
Validation loss: 3.4382423072732906

Epoch: 5| Step: 7
Training loss: 2.383923292160034
Validation loss: 3.3939389926131054

Epoch: 5| Step: 8
Training loss: 3.059455394744873
Validation loss: 3.3369552935323408

Epoch: 5| Step: 9
Training loss: 3.265578508377075
Validation loss: 3.29452484397478

Epoch: 5| Step: 10
Training loss: 3.519543409347534
Validation loss: 3.267637860390448

Epoch: 4| Step: 0
Training loss: 2.6041488647460938
Validation loss: 3.241319905045212

Epoch: 5| Step: 1
Training loss: 4.155610084533691
Validation loss: 3.212671115834226

Epoch: 5| Step: 2
Training loss: 3.2935569286346436
Validation loss: 3.1807260359487226

Epoch: 5| Step: 3
Training loss: 2.9421749114990234
Validation loss: 3.1511509521033174

Epoch: 5| Step: 4
Training loss: 3.2240192890167236
Validation loss: 3.123578445885771

Epoch: 5| Step: 5
Training loss: 2.7946369647979736
Validation loss: 3.102367942051221

Epoch: 5| Step: 6
Training loss: 3.3592746257781982
Validation loss: 3.086450325545444

Epoch: 5| Step: 7
Training loss: 2.7254528999328613
Validation loss: 3.0441304611903366

Epoch: 5| Step: 8
Training loss: 3.3814492225646973
Validation loss: 3.0234559146306847

Epoch: 5| Step: 9
Training loss: 2.9924912452697754
Validation loss: 3.014853936369701

Epoch: 5| Step: 10
Training loss: 3.048563241958618
Validation loss: 2.9941742215105283

Epoch: 5| Step: 0
Training loss: 2.6840858459472656
Validation loss: 2.9846125392503637

Epoch: 5| Step: 1
Training loss: 2.950899839401245
Validation loss: 2.976575579694522

Epoch: 5| Step: 2
Training loss: 2.998154878616333
Validation loss: 2.9597952288966023

Epoch: 5| Step: 3
Training loss: 3.0188064575195312
Validation loss: 2.9407717899609636

Epoch: 5| Step: 4
Training loss: 2.4339001178741455
Validation loss: 2.923777421315511

Epoch: 5| Step: 5
Training loss: 3.486351728439331
Validation loss: 2.909092882628082

Epoch: 5| Step: 6
Training loss: 3.5242950916290283
Validation loss: 2.905392349407237

Epoch: 5| Step: 7
Training loss: 2.9156835079193115
Validation loss: 2.8816130494558685

Epoch: 5| Step: 8
Training loss: 2.891153573989868
Validation loss: 2.853720898269325

Epoch: 5| Step: 9
Training loss: 3.8500404357910156
Validation loss: 2.8545773234418643

Epoch: 5| Step: 10
Training loss: 2.1728672981262207
Validation loss: 2.855203392685101

Epoch: 6| Step: 0
Training loss: 3.6171250343322754
Validation loss: 2.8617793026790825

Epoch: 5| Step: 1
Training loss: 2.2835159301757812
Validation loss: 2.836320830929664

Epoch: 5| Step: 2
Training loss: 3.063302993774414
Validation loss: 2.805310105764738

Epoch: 5| Step: 3
Training loss: 2.8725204467773438
Validation loss: 2.7804824818847

Epoch: 5| Step: 4
Training loss: 2.9446523189544678
Validation loss: 2.7692577787624892

Epoch: 5| Step: 5
Training loss: 3.2124295234680176
Validation loss: 2.765489803847446

Epoch: 5| Step: 6
Training loss: 2.335944175720215
Validation loss: 2.7748336740719375

Epoch: 5| Step: 7
Training loss: 2.1980433464050293
Validation loss: 2.7559967194834063

Epoch: 5| Step: 8
Training loss: 3.6475167274475098
Validation loss: 2.730181422284854

Epoch: 5| Step: 9
Training loss: 3.005204916000366
Validation loss: 2.7125099858930035

Epoch: 5| Step: 10
Training loss: 2.960482358932495
Validation loss: 2.703892643733691

Epoch: 7| Step: 0
Training loss: 2.134645938873291
Validation loss: 2.705327446742724

Epoch: 5| Step: 1
Training loss: 3.0327610969543457
Validation loss: 2.7148095958976337

Epoch: 5| Step: 2
Training loss: 3.0203611850738525
Validation loss: 2.7359734453180784

Epoch: 5| Step: 3
Training loss: 3.388474225997925
Validation loss: 2.7264312210903374

Epoch: 5| Step: 4
Training loss: 3.104249954223633
Validation loss: 2.7026021378014677

Epoch: 5| Step: 5
Training loss: 3.270683765411377
Validation loss: 2.676457025671518

Epoch: 5| Step: 6
Training loss: 3.063308000564575
Validation loss: 2.664052042909848

Epoch: 5| Step: 7
Training loss: 2.079198122024536
Validation loss: 2.65467918303705

Epoch: 5| Step: 8
Training loss: 2.723167896270752
Validation loss: 2.662132114492437

Epoch: 5| Step: 9
Training loss: 2.9721782207489014
Validation loss: 2.6673385250952935

Epoch: 5| Step: 10
Training loss: 2.614553213119507
Validation loss: 2.654656607617614

Epoch: 8| Step: 0
Training loss: 2.5973668098449707
Validation loss: 2.623094675361469

Epoch: 5| Step: 1
Training loss: 2.985337734222412
Validation loss: 2.6142550668408795

Epoch: 5| Step: 2
Training loss: 2.619389533996582
Validation loss: 2.6066152767468522

Epoch: 5| Step: 3
Training loss: 3.072481155395508
Validation loss: 2.6101426950065036

Epoch: 5| Step: 4
Training loss: 2.806730270385742
Validation loss: 2.610110685389529

Epoch: 5| Step: 5
Training loss: 2.985579490661621
Validation loss: 2.610695356963783

Epoch: 5| Step: 6
Training loss: 2.6142725944519043
Validation loss: 2.603629755717452

Epoch: 5| Step: 7
Training loss: 2.655313491821289
Validation loss: 2.591834537444576

Epoch: 5| Step: 8
Training loss: 2.957733631134033
Validation loss: 2.585165375022478

Epoch: 5| Step: 9
Training loss: 2.9286184310913086
Validation loss: 2.576199813555646

Epoch: 5| Step: 10
Training loss: 2.547626495361328
Validation loss: 2.569162563611102

Epoch: 9| Step: 0
Training loss: 2.7134881019592285
Validation loss: 2.577166716257731

Epoch: 5| Step: 1
Training loss: 3.1553595066070557
Validation loss: 2.559271010019446

Epoch: 5| Step: 2
Training loss: 3.272923231124878
Validation loss: 2.550396850032191

Epoch: 5| Step: 3
Training loss: 2.4016366004943848
Validation loss: 2.5449785314580446

Epoch: 5| Step: 4
Training loss: 2.2838633060455322
Validation loss: 2.5427784586465485

Epoch: 5| Step: 5
Training loss: 2.0591530799865723
Validation loss: 2.5324277441988707

Epoch: 5| Step: 6
Training loss: 2.9329757690429688
Validation loss: 2.538844462363951

Epoch: 5| Step: 7
Training loss: 3.3070144653320312
Validation loss: 2.5256348168978127

Epoch: 5| Step: 8
Training loss: 2.97117280960083
Validation loss: 2.5195775775499243

Epoch: 5| Step: 9
Training loss: 2.866088390350342
Validation loss: 2.5207299135064565

Epoch: 5| Step: 10
Training loss: 2.4059736728668213
Validation loss: 2.527554158241518

Epoch: 10| Step: 0
Training loss: 2.366119384765625
Validation loss: 2.5389297444333314

Epoch: 5| Step: 1
Training loss: 2.650489568710327
Validation loss: 2.562225769924861

Epoch: 5| Step: 2
Training loss: 2.9497764110565186
Validation loss: 2.5702320991023893

Epoch: 5| Step: 3
Training loss: 2.913792133331299
Validation loss: 2.5420472186098815

Epoch: 5| Step: 4
Training loss: 2.9394826889038086
Validation loss: 2.544226315713698

Epoch: 5| Step: 5
Training loss: 2.676776647567749
Validation loss: 2.525590759451671

Epoch: 5| Step: 6
Training loss: 3.1373090744018555
Validation loss: 2.517073324931565

Epoch: 5| Step: 7
Training loss: 3.0262110233306885
Validation loss: 2.5241057539498932

Epoch: 5| Step: 8
Training loss: 2.6802656650543213
Validation loss: 2.5392154647457983

Epoch: 5| Step: 9
Training loss: 2.5672645568847656
Validation loss: 2.5392643623454596

Epoch: 5| Step: 10
Training loss: 2.4762980937957764
Validation loss: 2.5001427794015534

Epoch: 11| Step: 0
Training loss: 2.58202862739563
Validation loss: 2.487511732245004

Epoch: 5| Step: 1
Training loss: 3.1968798637390137
Validation loss: 2.498792517569757

Epoch: 5| Step: 2
Training loss: 2.822298049926758
Validation loss: 2.5082387924194336

Epoch: 5| Step: 3
Training loss: 3.1742146015167236
Validation loss: 2.515507995441396

Epoch: 5| Step: 4
Training loss: 2.8651022911071777
Validation loss: 2.502178297247938

Epoch: 5| Step: 5
Training loss: 2.5695438385009766
Validation loss: 2.4908540120688816

Epoch: 5| Step: 6
Training loss: 2.287451982498169
Validation loss: 2.4906704143811296

Epoch: 5| Step: 7
Training loss: 2.4411425590515137
Validation loss: 2.4949137036518385

Epoch: 5| Step: 8
Training loss: 3.072075605392456
Validation loss: 2.5080535796380814

Epoch: 5| Step: 9
Training loss: 2.709500789642334
Validation loss: 2.522122129317253

Epoch: 5| Step: 10
Training loss: 2.4974777698516846
Validation loss: 2.5394066303007063

Epoch: 12| Step: 0
Training loss: 2.3922338485717773
Validation loss: 2.5248657170162407

Epoch: 5| Step: 1
Training loss: 3.510066270828247
Validation loss: 2.5140225887298584

Epoch: 5| Step: 2
Training loss: 2.3547122478485107
Validation loss: 2.5100648685168196

Epoch: 5| Step: 3
Training loss: 3.100179672241211
Validation loss: 2.50020125860809

Epoch: 5| Step: 4
Training loss: 2.405287265777588
Validation loss: 2.487102000944076

Epoch: 5| Step: 5
Training loss: 2.8242406845092773
Validation loss: 2.477230025875953

Epoch: 5| Step: 6
Training loss: 2.6503124237060547
Validation loss: 2.4687763516620924

Epoch: 5| Step: 7
Training loss: 2.782344341278076
Validation loss: 2.466469121235673

Epoch: 5| Step: 8
Training loss: 2.3138375282287598
Validation loss: 2.481199538835915

Epoch: 5| Step: 9
Training loss: 3.234041929244995
Validation loss: 2.490194833406838

Epoch: 5| Step: 10
Training loss: 2.5218398571014404
Validation loss: 2.517273361964892

Epoch: 13| Step: 0
Training loss: 2.1580700874328613
Validation loss: 2.4822389618042977

Epoch: 5| Step: 1
Training loss: 2.626905918121338
Validation loss: 2.4809001261188137

Epoch: 5| Step: 2
Training loss: 1.99517023563385
Validation loss: 2.4793273659162622

Epoch: 5| Step: 3
Training loss: 3.09269380569458
Validation loss: 2.4847781529990574

Epoch: 5| Step: 4
Training loss: 2.6787917613983154
Validation loss: 2.4685322802553893

Epoch: 5| Step: 5
Training loss: 2.1723480224609375
Validation loss: 2.4737035484724146

Epoch: 5| Step: 6
Training loss: 3.5356247425079346
Validation loss: 2.4822113719037784

Epoch: 5| Step: 7
Training loss: 2.82149076461792
Validation loss: 2.4928089521264516

Epoch: 5| Step: 8
Training loss: 3.4084808826446533
Validation loss: 2.465475343888806

Epoch: 5| Step: 9
Training loss: 2.879669189453125
Validation loss: 2.4617117963811403

Epoch: 5| Step: 10
Training loss: 2.44707989692688
Validation loss: 2.458492999435753

Epoch: 14| Step: 0
Training loss: 2.3219399452209473
Validation loss: 2.4611300755572576

Epoch: 5| Step: 1
Training loss: 2.1380600929260254
Validation loss: 2.4710264744297152

Epoch: 5| Step: 2
Training loss: 2.951106309890747
Validation loss: 2.517483119041689

Epoch: 5| Step: 3
Training loss: 3.2274978160858154
Validation loss: 2.53570754297318

Epoch: 5| Step: 4
Training loss: 2.846020221710205
Validation loss: 2.5268484238655335

Epoch: 5| Step: 5
Training loss: 2.654428005218506
Validation loss: 2.510325144695979

Epoch: 5| Step: 6
Training loss: 2.586331367492676
Validation loss: 2.511565039234777

Epoch: 5| Step: 7
Training loss: 2.912200450897217
Validation loss: 2.5328066861757668

Epoch: 5| Step: 8
Training loss: 3.348363161087036
Validation loss: 2.6082092305665374

Epoch: 5| Step: 9
Training loss: 2.2244904041290283
Validation loss: 2.58626490254556

Epoch: 5| Step: 10
Training loss: 3.0743608474731445
Validation loss: 2.5317737928000827

Epoch: 15| Step: 0
Training loss: 2.844589948654175
Validation loss: 2.50440143000695

Epoch: 5| Step: 1
Training loss: 2.5242960453033447
Validation loss: 2.5007260384098178

Epoch: 5| Step: 2
Training loss: 2.3816113471984863
Validation loss: 2.503956481974612

Epoch: 5| Step: 3
Training loss: 2.9862899780273438
Validation loss: 2.514000105601485

Epoch: 5| Step: 4
Training loss: 2.432934284210205
Validation loss: 2.5124984530992407

Epoch: 5| Step: 5
Training loss: 2.1043460369110107
Validation loss: 2.5058057833743352

Epoch: 5| Step: 6
Training loss: 2.5308680534362793
Validation loss: 2.5079207881804435

Epoch: 5| Step: 7
Training loss: 3.4445228576660156
Validation loss: 2.528862007202641

Epoch: 5| Step: 8
Training loss: 2.786452531814575
Validation loss: 2.5430442005075435

Epoch: 5| Step: 9
Training loss: 3.3910012245178223
Validation loss: 2.5802672832242903

Epoch: 5| Step: 10
Training loss: 2.885774850845337
Validation loss: 2.585600527383948

Epoch: 16| Step: 0
Training loss: 2.985271453857422
Validation loss: 2.5707121561932307

Epoch: 5| Step: 1
Training loss: 2.808966875076294
Validation loss: 2.5313878161932832

Epoch: 5| Step: 2
Training loss: 2.739415407180786
Validation loss: 2.5022629050798315

Epoch: 5| Step: 3
Training loss: 2.846018075942993
Validation loss: 2.4876790341510566

Epoch: 5| Step: 4
Training loss: 2.465226173400879
Validation loss: 2.4973898267233245

Epoch: 5| Step: 5
Training loss: 2.749934434890747
Validation loss: 2.530926340369768

Epoch: 5| Step: 6
Training loss: 2.6165006160736084
Validation loss: 2.5719957479866604

Epoch: 5| Step: 7
Training loss: 2.3874659538269043
Validation loss: 2.5999816822749313

Epoch: 5| Step: 8
Training loss: 2.729870319366455
Validation loss: 2.558570520852202

Epoch: 5| Step: 9
Training loss: 3.232591152191162
Validation loss: 2.5042447608004332

Epoch: 5| Step: 10
Training loss: 2.8512449264526367
Validation loss: 2.483526796422979

Epoch: 17| Step: 0
Training loss: 3.0828659534454346
Validation loss: 2.4696170155720045

Epoch: 5| Step: 1
Training loss: 2.491112470626831
Validation loss: 2.473823724254485

Epoch: 5| Step: 2
Training loss: 3.160243272781372
Validation loss: 2.486912896556239

Epoch: 5| Step: 3
Training loss: 3.2724967002868652
Validation loss: 2.4892844846171718

Epoch: 5| Step: 4
Training loss: 2.979790449142456
Validation loss: 2.4927747147057646

Epoch: 5| Step: 5
Training loss: 2.639146327972412
Validation loss: 2.4843699086096978

Epoch: 5| Step: 6
Training loss: 2.3463425636291504
Validation loss: 2.4808299413291355

Epoch: 5| Step: 7
Training loss: 2.0506505966186523
Validation loss: 2.4805932762802287

Epoch: 5| Step: 8
Training loss: 3.2655246257781982
Validation loss: 2.470306437502625

Epoch: 5| Step: 9
Training loss: 2.365457057952881
Validation loss: 2.4640641391918225

Epoch: 5| Step: 10
Training loss: 1.9644144773483276
Validation loss: 2.4637517877804336

Epoch: 18| Step: 0
Training loss: 3.158078670501709
Validation loss: 2.458576020374093

Epoch: 5| Step: 1
Training loss: 2.5161051750183105
Validation loss: 2.4439112345377603

Epoch: 5| Step: 2
Training loss: 2.711540699005127
Validation loss: 2.441979521064348

Epoch: 5| Step: 3
Training loss: 3.4658920764923096
Validation loss: 2.4576873753660466

Epoch: 5| Step: 4
Training loss: 2.9658100605010986
Validation loss: 2.45592664646846

Epoch: 5| Step: 5
Training loss: 2.1607089042663574
Validation loss: 2.438241956054523

Epoch: 5| Step: 6
Training loss: 2.269773244857788
Validation loss: 2.432468257924562

Epoch: 5| Step: 7
Training loss: 2.6187829971313477
Validation loss: 2.4295822651155534

Epoch: 5| Step: 8
Training loss: 2.7123796939849854
Validation loss: 2.4283604134795485

Epoch: 5| Step: 9
Training loss: 2.4831550121307373
Validation loss: 2.4412932703571935

Epoch: 5| Step: 10
Training loss: 2.4808995723724365
Validation loss: 2.431249510857367

Epoch: 19| Step: 0
Training loss: 2.858285427093506
Validation loss: 2.4307009763615106

Epoch: 5| Step: 1
Training loss: 2.61964750289917
Validation loss: 2.424292374682683

Epoch: 5| Step: 2
Training loss: 3.07611346244812
Validation loss: 2.4271260384590394

Epoch: 5| Step: 3
Training loss: 3.2545177936553955
Validation loss: 2.4256548009892946

Epoch: 5| Step: 4
Training loss: 2.987220525741577
Validation loss: 2.4272305375786236

Epoch: 5| Step: 5
Training loss: 2.1780147552490234
Validation loss: 2.4266990256565872

Epoch: 5| Step: 6
Training loss: 2.951604127883911
Validation loss: 2.431314722184212

Epoch: 5| Step: 7
Training loss: 2.2566142082214355
Validation loss: 2.4278117123470513

Epoch: 5| Step: 8
Training loss: 2.813220262527466
Validation loss: 2.4329338663367817

Epoch: 5| Step: 9
Training loss: 2.630948543548584
Validation loss: 2.4504468543555147

Epoch: 5| Step: 10
Training loss: 1.7461286783218384
Validation loss: 2.4465011012169624

Epoch: 20| Step: 0
Training loss: 3.1074020862579346
Validation loss: 2.4301405850277153

Epoch: 5| Step: 1
Training loss: 2.0248782634735107
Validation loss: 2.4161803748018

Epoch: 5| Step: 2
Training loss: 2.844313383102417
Validation loss: 2.4118116209583897

Epoch: 5| Step: 3
Training loss: 3.0271687507629395
Validation loss: 2.411323716563563

Epoch: 5| Step: 4
Training loss: 2.770421266555786
Validation loss: 2.4117250134868007

Epoch: 5| Step: 5
Training loss: 2.4285666942596436
Validation loss: 2.4073201789650867

Epoch: 5| Step: 6
Training loss: 2.8893444538116455
Validation loss: 2.4044815442895375

Epoch: 5| Step: 7
Training loss: 2.9284563064575195
Validation loss: 2.4187231550934496

Epoch: 5| Step: 8
Training loss: 2.3835768699645996
Validation loss: 2.435889895244311

Epoch: 5| Step: 9
Training loss: 2.73049259185791
Validation loss: 2.487300052437731

Epoch: 5| Step: 10
Training loss: 2.2882936000823975
Validation loss: 2.4974662411597466

Epoch: 21| Step: 0
Training loss: 2.5138919353485107
Validation loss: 2.447392781575521

Epoch: 5| Step: 1
Training loss: 2.7433764934539795
Validation loss: 2.4409397314953547

Epoch: 5| Step: 2
Training loss: 2.935068130493164
Validation loss: 2.417327219440091

Epoch: 5| Step: 3
Training loss: 2.4314842224121094
Validation loss: 2.4084180580672396

Epoch: 5| Step: 4
Training loss: 2.306032657623291
Validation loss: 2.409455032758815

Epoch: 5| Step: 5
Training loss: 2.6953749656677246
Validation loss: 2.4117703463441584

Epoch: 5| Step: 6
Training loss: 2.681089401245117
Validation loss: 2.4304943674354145

Epoch: 5| Step: 7
Training loss: 2.64168643951416
Validation loss: 2.4312557789587204

Epoch: 5| Step: 8
Training loss: 2.408940553665161
Validation loss: 2.4190590586713565

Epoch: 5| Step: 9
Training loss: 3.118778944015503
Validation loss: 2.412436887782107

Epoch: 5| Step: 10
Training loss: 3.054582118988037
Validation loss: 2.40301985638116

Epoch: 22| Step: 0
Training loss: 2.723865509033203
Validation loss: 2.4012022966979654

Epoch: 5| Step: 1
Training loss: 3.0483181476593018
Validation loss: 2.410021371738885

Epoch: 5| Step: 2
Training loss: 2.3519740104675293
Validation loss: 2.410373615962203

Epoch: 5| Step: 3
Training loss: 2.8255443572998047
Validation loss: 2.4160377005095124

Epoch: 5| Step: 4
Training loss: 3.315464496612549
Validation loss: 2.429788707405008

Epoch: 5| Step: 5
Training loss: 1.9033750295639038
Validation loss: 2.423634700877692

Epoch: 5| Step: 6
Training loss: 2.3620641231536865
Validation loss: 2.414767462720153

Epoch: 5| Step: 7
Training loss: 2.4631519317626953
Validation loss: 2.400109309022145

Epoch: 5| Step: 8
Training loss: 3.134187698364258
Validation loss: 2.3929629633503575

Epoch: 5| Step: 9
Training loss: 2.624633312225342
Validation loss: 2.3846226610163206

Epoch: 5| Step: 10
Training loss: 2.5541889667510986
Validation loss: 2.386747144883679

Epoch: 23| Step: 0
Training loss: 2.5365519523620605
Validation loss: 2.3858757403589066

Epoch: 5| Step: 1
Training loss: 2.270280361175537
Validation loss: 2.3885923329220025

Epoch: 5| Step: 2
Training loss: 2.5846524238586426
Validation loss: 2.397736110994893

Epoch: 5| Step: 3
Training loss: 2.713305711746216
Validation loss: 2.4035761843445482

Epoch: 5| Step: 4
Training loss: 2.604670286178589
Validation loss: 2.4141386375632337

Epoch: 5| Step: 5
Training loss: 2.836261749267578
Validation loss: 2.4288735210254626

Epoch: 5| Step: 6
Training loss: 2.9724483489990234
Validation loss: 2.4363441057102655

Epoch: 5| Step: 7
Training loss: 2.831163167953491
Validation loss: 2.4225295923089467

Epoch: 5| Step: 8
Training loss: 2.5425517559051514
Validation loss: 2.4298326276963755

Epoch: 5| Step: 9
Training loss: 2.9140801429748535
Validation loss: 2.430510336352933

Epoch: 5| Step: 10
Training loss: 2.388551712036133
Validation loss: 2.4430348052773425

Epoch: 24| Step: 0
Training loss: 2.8631210327148438
Validation loss: 2.427198986853323

Epoch: 5| Step: 1
Training loss: 2.085813283920288
Validation loss: 2.4158369982114403

Epoch: 5| Step: 2
Training loss: 3.039562702178955
Validation loss: 2.3862720099828576

Epoch: 5| Step: 3
Training loss: 2.7442708015441895
Validation loss: 2.3754243773798787

Epoch: 5| Step: 4
Training loss: 2.450572967529297
Validation loss: 2.3776981471687235

Epoch: 5| Step: 5
Training loss: 3.0261521339416504
Validation loss: 2.3764708401054464

Epoch: 5| Step: 6
Training loss: 3.4711437225341797
Validation loss: 2.3751509445969776

Epoch: 5| Step: 7
Training loss: 2.6723902225494385
Validation loss: 2.3725420403224167

Epoch: 5| Step: 8
Training loss: 2.3071281909942627
Validation loss: 2.37456613714977

Epoch: 5| Step: 9
Training loss: 2.428943157196045
Validation loss: 2.366447669203563

Epoch: 5| Step: 10
Training loss: 2.1199071407318115
Validation loss: 2.3737156852599113

Epoch: 25| Step: 0
Training loss: 2.781414031982422
Validation loss: 2.387626217257592

Epoch: 5| Step: 1
Training loss: 3.2081046104431152
Validation loss: 2.4322459159358853

Epoch: 5| Step: 2
Training loss: 2.095554828643799
Validation loss: 2.4472299365587133

Epoch: 5| Step: 3
Training loss: 3.242490291595459
Validation loss: 2.4379319837016444

Epoch: 5| Step: 4
Training loss: 2.669145345687866
Validation loss: 2.444283731522099

Epoch: 5| Step: 5
Training loss: 2.7631893157958984
Validation loss: 2.434733029334776

Epoch: 5| Step: 6
Training loss: 2.845923900604248
Validation loss: 2.420012535587434

Epoch: 5| Step: 7
Training loss: 2.350994110107422
Validation loss: 2.382602478868218

Epoch: 5| Step: 8
Training loss: 2.7328133583068848
Validation loss: 2.356412195390271

Epoch: 5| Step: 9
Training loss: 2.1865346431732178
Validation loss: 2.368426581864716

Epoch: 5| Step: 10
Training loss: 2.471067428588867
Validation loss: 2.3841708424270793

Epoch: 26| Step: 0
Training loss: 2.4186625480651855
Validation loss: 2.395389263347913

Epoch: 5| Step: 1
Training loss: 2.8313145637512207
Validation loss: 2.3931132490916918

Epoch: 5| Step: 2
Training loss: 2.8376975059509277
Validation loss: 2.386317350531137

Epoch: 5| Step: 3
Training loss: 2.881272315979004
Validation loss: 2.3739075019795406

Epoch: 5| Step: 4
Training loss: 2.7240524291992188
Validation loss: 2.3649558790268435

Epoch: 5| Step: 5
Training loss: 2.6502232551574707
Validation loss: 2.351799762377175

Epoch: 5| Step: 6
Training loss: 2.482531785964966
Validation loss: 2.3524806678936048

Epoch: 5| Step: 7
Training loss: 3.554997205734253
Validation loss: 2.3563413543085896

Epoch: 5| Step: 8
Training loss: 1.8608615398406982
Validation loss: 2.371758685317091

Epoch: 5| Step: 9
Training loss: 2.316077470779419
Validation loss: 2.3715049118124027

Epoch: 5| Step: 10
Training loss: 2.6824066638946533
Validation loss: 2.3826764322096303

Epoch: 27| Step: 0
Training loss: 2.312467336654663
Validation loss: 2.367618845355126

Epoch: 5| Step: 1
Training loss: 2.2921364307403564
Validation loss: 2.357765625881892

Epoch: 5| Step: 2
Training loss: 2.635413408279419
Validation loss: 2.3578981853300527

Epoch: 5| Step: 3
Training loss: 1.806510329246521
Validation loss: 2.3514221893843783

Epoch: 5| Step: 4
Training loss: 2.9890570640563965
Validation loss: 2.3464044422231694

Epoch: 5| Step: 5
Training loss: 2.173671007156372
Validation loss: 2.345848456505806

Epoch: 5| Step: 6
Training loss: 2.581040382385254
Validation loss: 2.3496488832658335

Epoch: 5| Step: 7
Training loss: 2.954061985015869
Validation loss: 2.350976126168364

Epoch: 5| Step: 8
Training loss: 3.507056474685669
Validation loss: 2.3613674204836608

Epoch: 5| Step: 9
Training loss: 2.9066967964172363
Validation loss: 2.348916817736882

Epoch: 5| Step: 10
Training loss: 2.67451548576355
Validation loss: 2.353719775394727

Epoch: 28| Step: 0
Training loss: 2.763690233230591
Validation loss: 2.3612964768563547

Epoch: 5| Step: 1
Training loss: 2.2469522953033447
Validation loss: 2.3543354106205765

Epoch: 5| Step: 2
Training loss: 1.9722436666488647
Validation loss: 2.3556367940800165

Epoch: 5| Step: 3
Training loss: 2.651317834854126
Validation loss: 2.3717512135864585

Epoch: 5| Step: 4
Training loss: 2.9951274394989014
Validation loss: 2.3839358398991246

Epoch: 5| Step: 5
Training loss: 2.595815658569336
Validation loss: 2.3779820434508787

Epoch: 5| Step: 6
Training loss: 3.5096707344055176
Validation loss: 2.3770583957754154

Epoch: 5| Step: 7
Training loss: 3.3936264514923096
Validation loss: 2.367076104687106

Epoch: 5| Step: 8
Training loss: 2.2738897800445557
Validation loss: 2.350761846829486

Epoch: 5| Step: 9
Training loss: 2.198540210723877
Validation loss: 2.334876239940684

Epoch: 5| Step: 10
Training loss: 2.206270217895508
Validation loss: 2.3316721608561854

Epoch: 29| Step: 0
Training loss: 2.194675922393799
Validation loss: 2.3308332761128745

Epoch: 5| Step: 1
Training loss: 2.7266106605529785
Validation loss: 2.3342428668852775

Epoch: 5| Step: 2
Training loss: 3.4845974445343018
Validation loss: 2.3339885050250637

Epoch: 5| Step: 3
Training loss: 2.424607753753662
Validation loss: 2.346039992506786

Epoch: 5| Step: 4
Training loss: 2.332122564315796
Validation loss: 2.3371372402355237

Epoch: 5| Step: 5
Training loss: 1.9012762308120728
Validation loss: 2.3338697648817495

Epoch: 5| Step: 6
Training loss: 2.493255138397217
Validation loss: 2.3513692758416616

Epoch: 5| Step: 7
Training loss: 2.9202518463134766
Validation loss: 2.350624402364095

Epoch: 5| Step: 8
Training loss: 2.626990795135498
Validation loss: 2.3377124583849342

Epoch: 5| Step: 9
Training loss: 2.9255523681640625
Validation loss: 2.337440808614095

Epoch: 5| Step: 10
Training loss: 2.757603645324707
Validation loss: 2.340650394398679

Epoch: 30| Step: 0
Training loss: 2.856780529022217
Validation loss: 2.325979389170165

Epoch: 5| Step: 1
Training loss: 2.251063585281372
Validation loss: 2.316064739740023

Epoch: 5| Step: 2
Training loss: 2.7233190536499023
Validation loss: 2.2896942259162985

Epoch: 5| Step: 3
Training loss: 2.925140857696533
Validation loss: 2.2804191420155187

Epoch: 5| Step: 4
Training loss: 2.347471237182617
Validation loss: 2.2793393391434864

Epoch: 5| Step: 5
Training loss: 2.6991283893585205
Validation loss: 2.2782414395322084

Epoch: 5| Step: 6
Training loss: 2.3511481285095215
Validation loss: 2.283875160319831

Epoch: 5| Step: 7
Training loss: 2.1741626262664795
Validation loss: 2.29418731504871

Epoch: 5| Step: 8
Training loss: 3.019946336746216
Validation loss: 2.3051552669976347

Epoch: 5| Step: 9
Training loss: 2.8428964614868164
Validation loss: 2.305559572353158

Epoch: 5| Step: 10
Training loss: 2.333860397338867
Validation loss: 2.2995308342800347

Epoch: 31| Step: 0
Training loss: 2.76619291305542
Validation loss: 2.3066506667803695

Epoch: 5| Step: 1
Training loss: 2.174081325531006
Validation loss: 2.290615940606722

Epoch: 5| Step: 2
Training loss: 1.9455503225326538
Validation loss: 2.284166015604491

Epoch: 5| Step: 3
Training loss: 2.0113131999969482
Validation loss: 2.2970563327112505

Epoch: 5| Step: 4
Training loss: 3.255413770675659
Validation loss: 2.349005255647885

Epoch: 5| Step: 5
Training loss: 2.853278636932373
Validation loss: 2.371266209951011

Epoch: 5| Step: 6
Training loss: 2.9572720527648926
Validation loss: 2.3708050071552234

Epoch: 5| Step: 7
Training loss: 2.7832512855529785
Validation loss: 2.352907339731852

Epoch: 5| Step: 8
Training loss: 2.9789652824401855
Validation loss: 2.3291256248310046

Epoch: 5| Step: 9
Training loss: 2.602200984954834
Validation loss: 2.296846838407619

Epoch: 5| Step: 10
Training loss: 2.117891311645508
Validation loss: 2.2759581945275746

Epoch: 32| Step: 0
Training loss: 2.692220449447632
Validation loss: 2.2677136185348674

Epoch: 5| Step: 1
Training loss: 2.751391887664795
Validation loss: 2.3042799503572526

Epoch: 5| Step: 2
Training loss: 2.966329336166382
Validation loss: 2.322333292294574

Epoch: 5| Step: 3
Training loss: 2.8369479179382324
Validation loss: 2.330061420317619

Epoch: 5| Step: 4
Training loss: 2.666001796722412
Validation loss: 2.3318466191650717

Epoch: 5| Step: 5
Training loss: 2.6476709842681885
Validation loss: 2.342351858333875

Epoch: 5| Step: 6
Training loss: 2.2782320976257324
Validation loss: 2.3335810246006137

Epoch: 5| Step: 7
Training loss: 2.6419384479522705
Validation loss: 2.3317975792833554

Epoch: 5| Step: 8
Training loss: 2.2863502502441406
Validation loss: 2.3266090193102436

Epoch: 5| Step: 9
Training loss: 2.719369649887085
Validation loss: 2.333719448376727

Epoch: 5| Step: 10
Training loss: 2.183311939239502
Validation loss: 2.342224141602875

Epoch: 33| Step: 0
Training loss: 1.6301788091659546
Validation loss: 2.3636975929301274

Epoch: 5| Step: 1
Training loss: 2.959423542022705
Validation loss: 2.4201752652404127

Epoch: 5| Step: 2
Training loss: 2.6570732593536377
Validation loss: 2.4667309458537767

Epoch: 5| Step: 3
Training loss: 2.3888683319091797
Validation loss: 2.5148783473558325

Epoch: 5| Step: 4
Training loss: 3.5789055824279785
Validation loss: 2.530818872554328

Epoch: 5| Step: 5
Training loss: 1.833177924156189
Validation loss: 2.4597504779856694

Epoch: 5| Step: 6
Training loss: 2.504647731781006
Validation loss: 2.432223884008264

Epoch: 5| Step: 7
Training loss: 2.4521327018737793
Validation loss: 2.379065385428808

Epoch: 5| Step: 8
Training loss: 3.11851167678833
Validation loss: 2.3381395211783786

Epoch: 5| Step: 9
Training loss: 2.619091033935547
Validation loss: 2.304643997582056

Epoch: 5| Step: 10
Training loss: 3.415360450744629
Validation loss: 2.303745062120499

Epoch: 34| Step: 0
Training loss: 1.874599814414978
Validation loss: 2.311820596776983

Epoch: 5| Step: 1
Training loss: 2.883608818054199
Validation loss: 2.324750707995507

Epoch: 5| Step: 2
Training loss: 2.63611102104187
Validation loss: 2.3411295772880636

Epoch: 5| Step: 3
Training loss: 2.999135971069336
Validation loss: 2.351701872323149

Epoch: 5| Step: 4
Training loss: 2.0357565879821777
Validation loss: 2.366734876427599

Epoch: 5| Step: 5
Training loss: 2.753478527069092
Validation loss: 2.3657141193266837

Epoch: 5| Step: 6
Training loss: 2.7125372886657715
Validation loss: 2.3367224559989026

Epoch: 5| Step: 7
Training loss: 2.5054047107696533
Validation loss: 2.3169569353903494

Epoch: 5| Step: 8
Training loss: 3.0036463737487793
Validation loss: 2.3056441353213404

Epoch: 5| Step: 9
Training loss: 2.2283191680908203
Validation loss: 2.2971125828322543

Epoch: 5| Step: 10
Training loss: 3.5368752479553223
Validation loss: 2.3056568971244236

Epoch: 35| Step: 0
Training loss: 2.9847464561462402
Validation loss: 2.3098185498227357

Epoch: 5| Step: 1
Training loss: 3.0825977325439453
Validation loss: 2.3484315769646757

Epoch: 5| Step: 2
Training loss: 2.6613383293151855
Validation loss: 2.383278241721533

Epoch: 5| Step: 3
Training loss: 1.8668992519378662
Validation loss: 2.450589790139147

Epoch: 5| Step: 4
Training loss: 3.179553508758545
Validation loss: 2.51759926478068

Epoch: 5| Step: 5
Training loss: 3.0741419792175293
Validation loss: 2.4923428361133864

Epoch: 5| Step: 6
Training loss: 2.7262864112854004
Validation loss: 2.3830938569961058

Epoch: 5| Step: 7
Training loss: 1.7557947635650635
Validation loss: 2.328390936697683

Epoch: 5| Step: 8
Training loss: 1.7654190063476562
Validation loss: 2.3098181293856714

Epoch: 5| Step: 9
Training loss: 2.663029670715332
Validation loss: 2.310722820220455

Epoch: 5| Step: 10
Training loss: 3.1041691303253174
Validation loss: 2.3207408946047545

Epoch: 36| Step: 0
Training loss: 2.7120349407196045
Validation loss: 2.322147692403486

Epoch: 5| Step: 1
Training loss: 2.887509822845459
Validation loss: 2.3440294368292696

Epoch: 5| Step: 2
Training loss: 2.4758238792419434
Validation loss: 2.366914854254774

Epoch: 5| Step: 3
Training loss: 2.3276548385620117
Validation loss: 2.3572856662093953

Epoch: 5| Step: 4
Training loss: 2.7091727256774902
Validation loss: 2.347053438104609

Epoch: 5| Step: 5
Training loss: 2.284763813018799
Validation loss: 2.3932245623680855

Epoch: 5| Step: 6
Training loss: 2.5725505352020264
Validation loss: 2.356875442689465

Epoch: 5| Step: 7
Training loss: 2.6189520359039307
Validation loss: 2.3301852877422045

Epoch: 5| Step: 8
Training loss: 2.715358257293701
Validation loss: 2.302489603719404

Epoch: 5| Step: 9
Training loss: 2.2860774993896484
Validation loss: 2.2777533967007875

Epoch: 5| Step: 10
Training loss: 2.9570651054382324
Validation loss: 2.2781166158696657

Epoch: 37| Step: 0
Training loss: 2.270765781402588
Validation loss: 2.283791320298308

Epoch: 5| Step: 1
Training loss: 2.9758553504943848
Validation loss: 2.305836267368768

Epoch: 5| Step: 2
Training loss: 2.615466594696045
Validation loss: 2.3474170777105514

Epoch: 5| Step: 3
Training loss: 2.6110591888427734
Validation loss: 2.4290972140527542

Epoch: 5| Step: 4
Training loss: 2.1815927028656006
Validation loss: 2.400403081729848

Epoch: 5| Step: 5
Training loss: 1.6879024505615234
Validation loss: 2.385625293177943

Epoch: 5| Step: 6
Training loss: 3.0050435066223145
Validation loss: 2.3523850530706425

Epoch: 5| Step: 7
Training loss: 2.5385091304779053
Validation loss: 2.3001051461824806

Epoch: 5| Step: 8
Training loss: 2.6603684425354004
Validation loss: 2.266471726920015

Epoch: 5| Step: 9
Training loss: 2.892831563949585
Validation loss: 2.251229142629972

Epoch: 5| Step: 10
Training loss: 2.9123239517211914
Validation loss: 2.2485731635042416

Epoch: 38| Step: 0
Training loss: 2.1882824897766113
Validation loss: 2.2418094399154826

Epoch: 5| Step: 1
Training loss: 2.416703462600708
Validation loss: 2.2153059154428463

Epoch: 5| Step: 2
Training loss: 2.430826187133789
Validation loss: 2.2058370574828117

Epoch: 5| Step: 3
Training loss: 2.4326331615448
Validation loss: 2.2090927247078187

Epoch: 5| Step: 4
Training loss: 2.506420612335205
Validation loss: 2.2096955071213427

Epoch: 5| Step: 5
Training loss: 2.765929937362671
Validation loss: 2.205907008981192

Epoch: 5| Step: 6
Training loss: 2.196526050567627
Validation loss: 2.1944677701560398

Epoch: 5| Step: 7
Training loss: 2.9583563804626465
Validation loss: 2.2137171683772916

Epoch: 5| Step: 8
Training loss: 2.0828967094421387
Validation loss: 2.2265336898065384

Epoch: 5| Step: 9
Training loss: 2.911353588104248
Validation loss: 2.2402446962171987

Epoch: 5| Step: 10
Training loss: 3.103425979614258
Validation loss: 2.2483480745746243

Epoch: 39| Step: 0
Training loss: 2.6960701942443848
Validation loss: 2.239860562868016

Epoch: 5| Step: 1
Training loss: 1.9523866176605225
Validation loss: 2.218787572717154

Epoch: 5| Step: 2
Training loss: 1.8882856369018555
Validation loss: 2.216726731228572

Epoch: 5| Step: 3
Training loss: 2.3125083446502686
Validation loss: 2.2402420300309376

Epoch: 5| Step: 4
Training loss: 2.9150640964508057
Validation loss: 2.2716841364419587

Epoch: 5| Step: 5
Training loss: 2.766906261444092
Validation loss: 2.2732584425198135

Epoch: 5| Step: 6
Training loss: 2.643329381942749
Validation loss: 2.2406559990298365

Epoch: 5| Step: 7
Training loss: 2.823514223098755
Validation loss: 2.2022889993524037

Epoch: 5| Step: 8
Training loss: 2.4473702907562256
Validation loss: 2.1753021158197874

Epoch: 5| Step: 9
Training loss: 3.039370059967041
Validation loss: 2.1731931150600476

Epoch: 5| Step: 10
Training loss: 2.3608481884002686
Validation loss: 2.1683172141352007

Epoch: 40| Step: 0
Training loss: 2.450862407684326
Validation loss: 2.172517450906897

Epoch: 5| Step: 1
Training loss: 2.0296342372894287
Validation loss: 2.17092138977461

Epoch: 5| Step: 2
Training loss: 2.8959169387817383
Validation loss: 2.169848941987561

Epoch: 5| Step: 3
Training loss: 3.150839328765869
Validation loss: 2.169272333063105

Epoch: 5| Step: 4
Training loss: 1.9467464685440063
Validation loss: 2.1735118294274933

Epoch: 5| Step: 5
Training loss: 2.4175939559936523
Validation loss: 2.17299755414327

Epoch: 5| Step: 6
Training loss: 2.3567683696746826
Validation loss: 2.200777515288322

Epoch: 5| Step: 7
Training loss: 1.9276535511016846
Validation loss: 2.2178712198811192

Epoch: 5| Step: 8
Training loss: 2.7038707733154297
Validation loss: 2.247717365141838

Epoch: 5| Step: 9
Training loss: 3.0060875415802
Validation loss: 2.3029797666816303

Epoch: 5| Step: 10
Training loss: 2.9493894577026367
Validation loss: 2.342143153631559

Epoch: 41| Step: 0
Training loss: 2.8951117992401123
Validation loss: 2.3529680851967103

Epoch: 5| Step: 1
Training loss: 2.4383769035339355
Validation loss: 2.276262829380651

Epoch: 5| Step: 2
Training loss: 2.4955246448516846
Validation loss: 2.2249204868911416

Epoch: 5| Step: 3
Training loss: 2.6814329624176025
Validation loss: 2.1970639485184864

Epoch: 5| Step: 4
Training loss: 2.089266300201416
Validation loss: 2.182688090109056

Epoch: 5| Step: 5
Training loss: 2.691704273223877
Validation loss: 2.185671308989166

Epoch: 5| Step: 6
Training loss: 2.207063674926758
Validation loss: 2.1843676887532717

Epoch: 5| Step: 7
Training loss: 3.2746779918670654
Validation loss: 2.1891344055052726

Epoch: 5| Step: 8
Training loss: 2.31638765335083
Validation loss: 2.185477133720152

Epoch: 5| Step: 9
Training loss: 2.340249538421631
Validation loss: 2.183980054752801

Epoch: 5| Step: 10
Training loss: 2.422274112701416
Validation loss: 2.1829816500345864

Epoch: 42| Step: 0
Training loss: 2.8687329292297363
Validation loss: 2.1848568762502363

Epoch: 5| Step: 1
Training loss: 2.370797634124756
Validation loss: 2.18540814358701

Epoch: 5| Step: 2
Training loss: 2.873745918273926
Validation loss: 2.2149291525604906

Epoch: 5| Step: 3
Training loss: 2.458249568939209
Validation loss: 2.231456461773124

Epoch: 5| Step: 4
Training loss: 2.772714138031006
Validation loss: 2.2384798680582354

Epoch: 5| Step: 5
Training loss: 2.6934115886688232
Validation loss: 2.220371312992547

Epoch: 5| Step: 6
Training loss: 2.84525465965271
Validation loss: 2.2053129852458997

Epoch: 5| Step: 7
Training loss: 2.374063014984131
Validation loss: 2.192374938277788

Epoch: 5| Step: 8
Training loss: 2.2284445762634277
Validation loss: 2.1769046347628356

Epoch: 5| Step: 9
Training loss: 2.0315117835998535
Validation loss: 2.1804334745612195

Epoch: 5| Step: 10
Training loss: 2.0452747344970703
Validation loss: 2.1777585860221618

Epoch: 43| Step: 0
Training loss: 2.5604348182678223
Validation loss: 2.178646510647189

Epoch: 5| Step: 1
Training loss: 2.6306023597717285
Validation loss: 2.1847053907250844

Epoch: 5| Step: 2
Training loss: 2.6407716274261475
Validation loss: 2.181387819269652

Epoch: 5| Step: 3
Training loss: 3.04154109954834
Validation loss: 2.2049218967396724

Epoch: 5| Step: 4
Training loss: 2.391216278076172
Validation loss: 2.22351905351044

Epoch: 5| Step: 5
Training loss: 2.172837972640991
Validation loss: 2.2237709491483626

Epoch: 5| Step: 6
Training loss: 2.2865123748779297
Validation loss: 2.2205747314678725

Epoch: 5| Step: 7
Training loss: 2.7017934322357178
Validation loss: 2.228356542125825

Epoch: 5| Step: 8
Training loss: 2.801124095916748
Validation loss: 2.220806210271774

Epoch: 5| Step: 9
Training loss: 1.5871503353118896
Validation loss: 2.2086745346746137

Epoch: 5| Step: 10
Training loss: 2.7711522579193115
Validation loss: 2.1904602358418126

Epoch: 44| Step: 0
Training loss: 2.4915385246276855
Validation loss: 2.1879942647872435

Epoch: 5| Step: 1
Training loss: 2.5364532470703125
Validation loss: 2.196895205846397

Epoch: 5| Step: 2
Training loss: 2.614591121673584
Validation loss: 2.2061399464966147

Epoch: 5| Step: 3
Training loss: 2.5070254802703857
Validation loss: 2.2355907719622374

Epoch: 5| Step: 4
Training loss: 2.5816328525543213
Validation loss: 2.2529582464566795

Epoch: 5| Step: 5
Training loss: 2.367241859436035
Validation loss: 2.2663814149877077

Epoch: 5| Step: 6
Training loss: 2.9500348567962646
Validation loss: 2.253921898462439

Epoch: 5| Step: 7
Training loss: 2.3276495933532715
Validation loss: 2.2118076624408847

Epoch: 5| Step: 8
Training loss: 2.2848238945007324
Validation loss: 2.1856977913969304

Epoch: 5| Step: 9
Training loss: 2.051492214202881
Validation loss: 2.1679185487890757

Epoch: 5| Step: 10
Training loss: 2.8462255001068115
Validation loss: 2.154917040178853

Epoch: 45| Step: 0
Training loss: 2.1811132431030273
Validation loss: 2.152841488520304

Epoch: 5| Step: 1
Training loss: 2.557473659515381
Validation loss: 2.1586625294018815

Epoch: 5| Step: 2
Training loss: 2.4045019149780273
Validation loss: 2.160283552703037

Epoch: 5| Step: 3
Training loss: 2.8733088970184326
Validation loss: 2.166545847410797

Epoch: 5| Step: 4
Training loss: 2.6261610984802246
Validation loss: 2.157163114957912

Epoch: 5| Step: 5
Training loss: 2.620039463043213
Validation loss: 2.14880879463688

Epoch: 5| Step: 6
Training loss: 3.180701494216919
Validation loss: 2.1513464579018216

Epoch: 5| Step: 7
Training loss: 2.2921786308288574
Validation loss: 2.142524060382638

Epoch: 5| Step: 8
Training loss: 2.0020174980163574
Validation loss: 2.134250081995482

Epoch: 5| Step: 9
Training loss: 2.5043888092041016
Validation loss: 2.143953264400523

Epoch: 5| Step: 10
Training loss: 2.3389298915863037
Validation loss: 2.156235715394379

Epoch: 46| Step: 0
Training loss: 3.0606846809387207
Validation loss: 2.1783723933722383

Epoch: 5| Step: 1
Training loss: 2.742687702178955
Validation loss: 2.20525421122069

Epoch: 5| Step: 2
Training loss: 2.331696033477783
Validation loss: 2.2409069820116927

Epoch: 5| Step: 3
Training loss: 2.4543421268463135
Validation loss: 2.244567632675171

Epoch: 5| Step: 4
Training loss: 2.0946688652038574
Validation loss: 2.267820159594218

Epoch: 5| Step: 5
Training loss: 2.4505889415740967
Validation loss: 2.3208704353660665

Epoch: 5| Step: 6
Training loss: 2.633808135986328
Validation loss: 2.27910247413061

Epoch: 5| Step: 7
Training loss: 2.4328465461730957
Validation loss: 2.252415285315565

Epoch: 5| Step: 8
Training loss: 2.6299891471862793
Validation loss: 2.2333930397546418

Epoch: 5| Step: 9
Training loss: 2.1370012760162354
Validation loss: 2.2132893736644457

Epoch: 5| Step: 10
Training loss: 2.626128911972046
Validation loss: 2.2119782381160285

Epoch: 47| Step: 0
Training loss: 3.1372628211975098
Validation loss: 2.206067080138832

Epoch: 5| Step: 1
Training loss: 2.3286120891571045
Validation loss: 2.2078656227357927

Epoch: 5| Step: 2
Training loss: 2.3156826496124268
Validation loss: 2.209607489647404

Epoch: 5| Step: 3
Training loss: 2.596586227416992
Validation loss: 2.207230870441724

Epoch: 5| Step: 4
Training loss: 2.5134034156799316
Validation loss: 2.2154879390552478

Epoch: 5| Step: 5
Training loss: 2.649667263031006
Validation loss: 2.1990802467510266

Epoch: 5| Step: 6
Training loss: 1.9279931783676147
Validation loss: 2.195417132428897

Epoch: 5| Step: 7
Training loss: 2.754896402359009
Validation loss: 2.196241214711179

Epoch: 5| Step: 8
Training loss: 2.3886427879333496
Validation loss: 2.205910005877095

Epoch: 5| Step: 9
Training loss: 2.8685202598571777
Validation loss: 2.186707037751393

Epoch: 5| Step: 10
Training loss: 1.9388285875320435
Validation loss: 2.173751151689919

Epoch: 48| Step: 0
Training loss: 1.9224421977996826
Validation loss: 2.167954662794708

Epoch: 5| Step: 1
Training loss: 2.1768386363983154
Validation loss: 2.1556237641201226

Epoch: 5| Step: 2
Training loss: 2.3541550636291504
Validation loss: 2.171414077922862

Epoch: 5| Step: 3
Training loss: 3.0406579971313477
Validation loss: 2.1626838663572907

Epoch: 5| Step: 4
Training loss: 2.7087440490722656
Validation loss: 2.1550695024510866

Epoch: 5| Step: 5
Training loss: 2.0919411182403564
Validation loss: 2.172147745727211

Epoch: 5| Step: 6
Training loss: 2.9817357063293457
Validation loss: 2.169664336789039

Epoch: 5| Step: 7
Training loss: 2.563279151916504
Validation loss: 2.1449217386143182

Epoch: 5| Step: 8
Training loss: 2.464991331100464
Validation loss: 2.1451841092878774

Epoch: 5| Step: 9
Training loss: 2.5654444694519043
Validation loss: 2.1397926525403093

Epoch: 5| Step: 10
Training loss: 2.2752492427825928
Validation loss: 2.1416942598999187

Epoch: 49| Step: 0
Training loss: 2.8349738121032715
Validation loss: 2.148847795301868

Epoch: 5| Step: 1
Training loss: 2.32531476020813
Validation loss: 2.166986139871741

Epoch: 5| Step: 2
Training loss: 2.678955078125
Validation loss: 2.1934106862673195

Epoch: 5| Step: 3
Training loss: 2.129613161087036
Validation loss: 2.165639364591209

Epoch: 5| Step: 4
Training loss: 2.4623565673828125
Validation loss: 2.153140655127905

Epoch: 5| Step: 5
Training loss: 2.4539904594421387
Validation loss: 2.1343907515207925

Epoch: 5| Step: 6
Training loss: 2.6645894050598145
Validation loss: 2.132842779159546

Epoch: 5| Step: 7
Training loss: 2.2854888439178467
Validation loss: 2.138153506863502

Epoch: 5| Step: 8
Training loss: 2.588239908218384
Validation loss: 2.1425939606082056

Epoch: 5| Step: 9
Training loss: 2.486880302429199
Validation loss: 2.1576939705879457

Epoch: 5| Step: 10
Training loss: 2.3966329097747803
Validation loss: 2.1759838058102514

Epoch: 50| Step: 0
Training loss: 2.7774977684020996
Validation loss: 2.1816497387424594

Epoch: 5| Step: 1
Training loss: 2.3568289279937744
Validation loss: 2.1688436795306463

Epoch: 5| Step: 2
Training loss: 2.3113226890563965
Validation loss: 2.162748900792932

Epoch: 5| Step: 3
Training loss: 2.4856011867523193
Validation loss: 2.144732497071707

Epoch: 5| Step: 4
Training loss: 2.3925514221191406
Validation loss: 2.138389782239032

Epoch: 5| Step: 5
Training loss: 2.6654720306396484
Validation loss: 2.1415868113117833

Epoch: 5| Step: 6
Training loss: 2.387167453765869
Validation loss: 2.1523242791493735

Epoch: 5| Step: 7
Training loss: 2.540889263153076
Validation loss: 2.1455344359079995

Epoch: 5| Step: 8
Training loss: 2.393263339996338
Validation loss: 2.1533352815976707

Epoch: 5| Step: 9
Training loss: 2.480226755142212
Validation loss: 2.1690144538879395

Epoch: 5| Step: 10
Training loss: 2.541839838027954
Validation loss: 2.183541444040114

Epoch: 51| Step: 0
Training loss: 2.5837130546569824
Validation loss: 2.2011348483383015

Epoch: 5| Step: 1
Training loss: 2.5084354877471924
Validation loss: 2.207015588719358

Epoch: 5| Step: 2
Training loss: 2.63871693611145
Validation loss: 2.2303448633481096

Epoch: 5| Step: 3
Training loss: 2.8545098304748535
Validation loss: 2.2525442082394838

Epoch: 5| Step: 4
Training loss: 2.705881118774414
Validation loss: 2.2853473258274857

Epoch: 5| Step: 5
Training loss: 2.6188151836395264
Validation loss: 2.315997241645731

Epoch: 5| Step: 6
Training loss: 1.4526695013046265
Validation loss: 2.3199379149303643

Epoch: 5| Step: 7
Training loss: 2.734549045562744
Validation loss: 2.3117280314045567

Epoch: 5| Step: 8
Training loss: 3.2317843437194824
Validation loss: 2.2687175850714407

Epoch: 5| Step: 9
Training loss: 2.183328151702881
Validation loss: 2.235101099937193

Epoch: 5| Step: 10
Training loss: 1.657660961151123
Validation loss: 2.1807943236443306

Epoch: 52| Step: 0
Training loss: 2.7366943359375
Validation loss: 2.133567953622469

Epoch: 5| Step: 1
Training loss: 2.0480761528015137
Validation loss: 2.119645462241224

Epoch: 5| Step: 2
Training loss: 1.7163276672363281
Validation loss: 2.116373613316526

Epoch: 5| Step: 3
Training loss: 3.5440964698791504
Validation loss: 2.1172320894015733

Epoch: 5| Step: 4
Training loss: 2.242744207382202
Validation loss: 2.129108408445953

Epoch: 5| Step: 5
Training loss: 2.859135150909424
Validation loss: 2.1340673380000617

Epoch: 5| Step: 6
Training loss: 2.6349635124206543
Validation loss: 2.123294130448372

Epoch: 5| Step: 7
Training loss: 1.9206300973892212
Validation loss: 2.125154031220303

Epoch: 5| Step: 8
Training loss: 1.7556402683258057
Validation loss: 2.121597307984547

Epoch: 5| Step: 9
Training loss: 2.7057456970214844
Validation loss: 2.1167464358832246

Epoch: 5| Step: 10
Training loss: 3.0735490322113037
Validation loss: 2.1183584941330778

Epoch: 53| Step: 0
Training loss: 2.570111036300659
Validation loss: 2.156899739337224

Epoch: 5| Step: 1
Training loss: 2.149204730987549
Validation loss: 2.1873473928820704

Epoch: 5| Step: 2
Training loss: 2.888097047805786
Validation loss: 2.220651513786726

Epoch: 5| Step: 3
Training loss: 1.4488708972930908
Validation loss: 2.245486551715482

Epoch: 5| Step: 4
Training loss: 2.7244620323181152
Validation loss: 2.2348388292456187

Epoch: 5| Step: 5
Training loss: 2.8089656829833984
Validation loss: 2.225708802541097

Epoch: 5| Step: 6
Training loss: 2.623805522918701
Validation loss: 2.18659798816968

Epoch: 5| Step: 7
Training loss: 2.371213436126709
Validation loss: 2.1580493937256517

Epoch: 5| Step: 8
Training loss: 2.24198317527771
Validation loss: 2.1377195747949744

Epoch: 5| Step: 9
Training loss: 2.5613458156585693
Validation loss: 2.1273771742338776

Epoch: 5| Step: 10
Training loss: 2.7797391414642334
Validation loss: 2.1304042672598236

Epoch: 54| Step: 0
Training loss: 2.9014172554016113
Validation loss: 2.12476618571948

Epoch: 5| Step: 1
Training loss: 2.3333446979522705
Validation loss: 2.120731783169572

Epoch: 5| Step: 2
Training loss: 2.528984546661377
Validation loss: 2.120187952954282

Epoch: 5| Step: 3
Training loss: 2.3167924880981445
Validation loss: 2.1166507479965047

Epoch: 5| Step: 4
Training loss: 2.651948928833008
Validation loss: 2.119057842480239

Epoch: 5| Step: 5
Training loss: 2.793590545654297
Validation loss: 2.109354688275245

Epoch: 5| Step: 6
Training loss: 2.234975814819336
Validation loss: 2.107981498523425

Epoch: 5| Step: 7
Training loss: 1.9460452795028687
Validation loss: 2.107450795430009

Epoch: 5| Step: 8
Training loss: 2.473015785217285
Validation loss: 2.113448387833052

Epoch: 5| Step: 9
Training loss: 2.7420191764831543
Validation loss: 2.10650291750508

Epoch: 5| Step: 10
Training loss: 1.9564173221588135
Validation loss: 2.1031109350983814

Epoch: 55| Step: 0
Training loss: 2.5892117023468018
Validation loss: 2.107481687299667

Epoch: 5| Step: 1
Training loss: 2.8561227321624756
Validation loss: 2.117708667632072

Epoch: 5| Step: 2
Training loss: 2.2912864685058594
Validation loss: 2.1313345457917903

Epoch: 5| Step: 3
Training loss: 2.854174852371216
Validation loss: 2.1460174322128296

Epoch: 5| Step: 4
Training loss: 2.67539119720459
Validation loss: 2.1445252690263974

Epoch: 5| Step: 5
Training loss: 2.410278558731079
Validation loss: 2.1443599629145798

Epoch: 5| Step: 6
Training loss: 1.989612340927124
Validation loss: 2.1373548687145276

Epoch: 5| Step: 7
Training loss: 2.221961259841919
Validation loss: 2.135264265921808

Epoch: 5| Step: 8
Training loss: 2.5196292400360107
Validation loss: 2.130442505241722

Epoch: 5| Step: 9
Training loss: 2.1898176670074463
Validation loss: 2.105212329536356

Epoch: 5| Step: 10
Training loss: 2.2857906818389893
Validation loss: 2.10702052808577

Epoch: 56| Step: 0
Training loss: 2.5615100860595703
Validation loss: 2.1031290318376277

Epoch: 5| Step: 1
Training loss: 2.7271640300750732
Validation loss: 2.1113219081714587

Epoch: 5| Step: 2
Training loss: 2.6208748817443848
Validation loss: 2.1266034277536536

Epoch: 5| Step: 3
Training loss: 2.9071974754333496
Validation loss: 2.1355277722881687

Epoch: 5| Step: 4
Training loss: 2.6102747917175293
Validation loss: 2.1253269564720894

Epoch: 5| Step: 5
Training loss: 1.7388585805892944
Validation loss: 2.1215969157475296

Epoch: 5| Step: 6
Training loss: 2.0688579082489014
Validation loss: 2.115208028465189

Epoch: 5| Step: 7
Training loss: 2.317549467086792
Validation loss: 2.1179571344006445

Epoch: 5| Step: 8
Training loss: 2.253309488296509
Validation loss: 2.113829502495386

Epoch: 5| Step: 9
Training loss: 2.9557549953460693
Validation loss: 2.1406980829854168

Epoch: 5| Step: 10
Training loss: 1.979179859161377
Validation loss: 2.1576872038584884

Epoch: 57| Step: 0
Training loss: 3.0465574264526367
Validation loss: 2.176370072108443

Epoch: 5| Step: 1
Training loss: 2.330726146697998
Validation loss: 2.1585267128482943

Epoch: 5| Step: 2
Training loss: 2.3043205738067627
Validation loss: 2.146702392126924

Epoch: 5| Step: 3
Training loss: 2.5620741844177246
Validation loss: 2.145319231094853

Epoch: 5| Step: 4
Training loss: 2.226501941680908
Validation loss: 2.138058857251239

Epoch: 5| Step: 5
Training loss: 2.705487012863159
Validation loss: 2.1230386098225913

Epoch: 5| Step: 6
Training loss: 2.4696009159088135
Validation loss: 2.1205953410876694

Epoch: 5| Step: 7
Training loss: 1.948114037513733
Validation loss: 2.123701633945588

Epoch: 5| Step: 8
Training loss: 2.8730273246765137
Validation loss: 2.1314762356460735

Epoch: 5| Step: 9
Training loss: 2.220646381378174
Validation loss: 2.151539594896378

Epoch: 5| Step: 10
Training loss: 2.145366668701172
Validation loss: 2.183779247345463

Epoch: 58| Step: 0
Training loss: 2.498314380645752
Validation loss: 2.192807779517225

Epoch: 5| Step: 1
Training loss: 2.2177417278289795
Validation loss: 2.1631297949821717

Epoch: 5| Step: 2
Training loss: 2.640583038330078
Validation loss: 2.1364015789442163

Epoch: 5| Step: 3
Training loss: 2.3062195777893066
Validation loss: 2.104374882995441

Epoch: 5| Step: 4
Training loss: 2.545442819595337
Validation loss: 2.0955663111902054

Epoch: 5| Step: 5
Training loss: 3.0584120750427246
Validation loss: 2.085428237915039

Epoch: 5| Step: 6
Training loss: 2.5290896892547607
Validation loss: 2.0842544647955124

Epoch: 5| Step: 7
Training loss: 1.9122387170791626
Validation loss: 2.087076105097289

Epoch: 5| Step: 8
Training loss: 2.298987865447998
Validation loss: 2.0862163805192515

Epoch: 5| Step: 9
Training loss: 2.7631797790527344
Validation loss: 2.084228907862017

Epoch: 5| Step: 10
Training loss: 2.1883652210235596
Validation loss: 2.0844697606179023

Epoch: 59| Step: 0
Training loss: 2.5061821937561035
Validation loss: 2.085007203522549

Epoch: 5| Step: 1
Training loss: 2.5900349617004395
Validation loss: 2.0948913943383003

Epoch: 5| Step: 2
Training loss: 2.2279739379882812
Validation loss: 2.116486349413472

Epoch: 5| Step: 3
Training loss: 2.982016086578369
Validation loss: 2.1422984587248934

Epoch: 5| Step: 4
Training loss: 2.2028250694274902
Validation loss: 2.1682654273125435

Epoch: 5| Step: 5
Training loss: 1.8650938272476196
Validation loss: 2.213902158121909

Epoch: 5| Step: 6
Training loss: 2.7324891090393066
Validation loss: 2.248640514189197

Epoch: 5| Step: 7
Training loss: 2.9245476722717285
Validation loss: 2.250946726850284

Epoch: 5| Step: 8
Training loss: 2.8269104957580566
Validation loss: 2.2177090798654864

Epoch: 5| Step: 9
Training loss: 2.149815320968628
Validation loss: 2.187815184234291

Epoch: 5| Step: 10
Training loss: 2.045994758605957
Validation loss: 2.1459206265787922

Epoch: 60| Step: 0
Training loss: 2.677807569503784
Validation loss: 2.115968665769023

Epoch: 5| Step: 1
Training loss: 2.6293699741363525
Validation loss: 2.1006991863250732

Epoch: 5| Step: 2
Training loss: 2.270817995071411
Validation loss: 2.115514844976446

Epoch: 5| Step: 3
Training loss: 2.260876178741455
Validation loss: 2.1327497305408603

Epoch: 5| Step: 4
Training loss: 2.3939733505249023
Validation loss: 2.130409279177266

Epoch: 5| Step: 5
Training loss: 2.8579163551330566
Validation loss: 2.1366408922339

Epoch: 5| Step: 6
Training loss: 2.120300054550171
Validation loss: 2.1167789607919674

Epoch: 5| Step: 7
Training loss: 2.5192577838897705
Validation loss: 2.0941164339742353

Epoch: 5| Step: 8
Training loss: 2.38014554977417
Validation loss: 2.09173265323844

Epoch: 5| Step: 9
Training loss: 2.113703966140747
Validation loss: 2.09649137784076

Epoch: 5| Step: 10
Training loss: 2.8631174564361572
Validation loss: 2.115794453569638

Epoch: 61| Step: 0
Training loss: 2.3680288791656494
Validation loss: 2.1222117818811888

Epoch: 5| Step: 1
Training loss: 1.964869499206543
Validation loss: 2.156274428931616

Epoch: 5| Step: 2
Training loss: 2.178056240081787
Validation loss: 2.1892109250509613

Epoch: 5| Step: 3
Training loss: 2.911388397216797
Validation loss: 2.2117247389208887

Epoch: 5| Step: 4
Training loss: 2.592155933380127
Validation loss: 2.192009384914111

Epoch: 5| Step: 5
Training loss: 2.899099349975586
Validation loss: 2.1749513226170696

Epoch: 5| Step: 6
Training loss: 1.8716719150543213
Validation loss: 2.149020302680231

Epoch: 5| Step: 7
Training loss: 2.786924362182617
Validation loss: 2.1209714566507647

Epoch: 5| Step: 8
Training loss: 3.1826279163360596
Validation loss: 2.1070354677015737

Epoch: 5| Step: 9
Training loss: 1.962874412536621
Validation loss: 2.090379648311164

Epoch: 5| Step: 10
Training loss: 1.8415809869766235
Validation loss: 2.0878489914760796

Epoch: 62| Step: 0
Training loss: 2.489765167236328
Validation loss: 2.0848101864578905

Epoch: 5| Step: 1
Training loss: 2.22819447517395
Validation loss: 2.0824632631835116

Epoch: 5| Step: 2
Training loss: 2.674589157104492
Validation loss: 2.0816702778621385

Epoch: 5| Step: 3
Training loss: 2.615196704864502
Validation loss: 2.0965239591495965

Epoch: 5| Step: 4
Training loss: 2.819849729537964
Validation loss: 2.0979377390235983

Epoch: 5| Step: 5
Training loss: 2.2191920280456543
Validation loss: 2.1097406238637944

Epoch: 5| Step: 6
Training loss: 2.122140645980835
Validation loss: 2.1046894942560503

Epoch: 5| Step: 7
Training loss: 2.0478196144104004
Validation loss: 2.1242681575077835

Epoch: 5| Step: 8
Training loss: 2.4035651683807373
Validation loss: 2.1506977747845393

Epoch: 5| Step: 9
Training loss: 1.9800434112548828
Validation loss: 2.195050647181849

Epoch: 5| Step: 10
Training loss: 3.0167739391326904
Validation loss: 2.2442419836598058

Epoch: 63| Step: 0
Training loss: 2.035094976425171
Validation loss: 2.320068028665358

Epoch: 5| Step: 1
Training loss: 2.588841676712036
Validation loss: 2.364970673796951

Epoch: 5| Step: 2
Training loss: 2.511167049407959
Validation loss: 2.364349115279413

Epoch: 5| Step: 3
Training loss: 2.3542118072509766
Validation loss: 2.349681185137841

Epoch: 5| Step: 4
Training loss: 3.036040782928467
Validation loss: 2.282134771347046

Epoch: 5| Step: 5
Training loss: 3.0007128715515137
Validation loss: 2.232501096622918

Epoch: 5| Step: 6
Training loss: 2.3710365295410156
Validation loss: 2.161369090439171

Epoch: 5| Step: 7
Training loss: 2.170851469039917
Validation loss: 2.138328171545459

Epoch: 5| Step: 8
Training loss: 2.421052932739258
Validation loss: 2.1146158197874665

Epoch: 5| Step: 9
Training loss: 1.880753517150879
Validation loss: 2.097846387535013

Epoch: 5| Step: 10
Training loss: 2.2670183181762695
Validation loss: 2.0899210809379496

Epoch: 64| Step: 0
Training loss: 2.396202802658081
Validation loss: 2.081444767213637

Epoch: 5| Step: 1
Training loss: 2.4142990112304688
Validation loss: 2.077378011518909

Epoch: 5| Step: 2
Training loss: 2.2331809997558594
Validation loss: 2.0747292862143567

Epoch: 5| Step: 3
Training loss: 2.8938679695129395
Validation loss: 2.0747988326575166

Epoch: 5| Step: 4
Training loss: 2.2783901691436768
Validation loss: 2.0738925780019453

Epoch: 5| Step: 5
Training loss: 2.331902027130127
Validation loss: 2.0745854480292207

Epoch: 5| Step: 6
Training loss: 2.534224033355713
Validation loss: 2.0884498780773533

Epoch: 5| Step: 7
Training loss: 2.982973098754883
Validation loss: 2.0838072299957275

Epoch: 5| Step: 8
Training loss: 1.5760705471038818
Validation loss: 2.0974486515086186

Epoch: 5| Step: 9
Training loss: 2.514072895050049
Validation loss: 2.1159264708078034

Epoch: 5| Step: 10
Training loss: 2.6296799182891846
Validation loss: 2.1276087555834042

Epoch: 65| Step: 0
Training loss: 2.508009910583496
Validation loss: 2.1438137151861705

Epoch: 5| Step: 1
Training loss: 2.1562087535858154
Validation loss: 2.1548908987352924

Epoch: 5| Step: 2
Training loss: 2.3886301517486572
Validation loss: 2.1524645666922293

Epoch: 5| Step: 3
Training loss: 2.501884937286377
Validation loss: 2.157059056784517

Epoch: 5| Step: 4
Training loss: 2.093219757080078
Validation loss: 2.141217639369349

Epoch: 5| Step: 5
Training loss: 2.1448442935943604
Validation loss: 2.1410255291128673

Epoch: 5| Step: 6
Training loss: 2.6386005878448486
Validation loss: 2.130166199899489

Epoch: 5| Step: 7
Training loss: 2.9424519538879395
Validation loss: 2.123653728474853

Epoch: 5| Step: 8
Training loss: 2.3200981616973877
Validation loss: 2.1105142190892208

Epoch: 5| Step: 9
Training loss: 2.5710058212280273
Validation loss: 2.105416415840067

Epoch: 5| Step: 10
Training loss: 2.2310192584991455
Validation loss: 2.097330113892914

Epoch: 66| Step: 0
Training loss: 2.689251661300659
Validation loss: 2.092677721413233

Epoch: 5| Step: 1
Training loss: 3.121255397796631
Validation loss: 2.096112440991145

Epoch: 5| Step: 2
Training loss: 2.785977602005005
Validation loss: 2.095635647414833

Epoch: 5| Step: 3
Training loss: 1.7641048431396484
Validation loss: 2.0963071161700833

Epoch: 5| Step: 4
Training loss: 2.3020222187042236
Validation loss: 2.110320947503531

Epoch: 5| Step: 5
Training loss: 2.316426992416382
Validation loss: 2.1103735662275747

Epoch: 5| Step: 6
Training loss: 2.650113582611084
Validation loss: 2.1265963841510076

Epoch: 5| Step: 7
Training loss: 1.775805115699768
Validation loss: 2.1390225361752253

Epoch: 5| Step: 8
Training loss: 1.7392158508300781
Validation loss: 2.161550115513545

Epoch: 5| Step: 9
Training loss: 2.4207794666290283
Validation loss: 2.154750862429219

Epoch: 5| Step: 10
Training loss: 2.736522674560547
Validation loss: 2.1708215833992086

Epoch: 67| Step: 0
Training loss: 2.379178762435913
Validation loss: 2.1611558519383913

Epoch: 5| Step: 1
Training loss: 2.446845531463623
Validation loss: 2.1570901998909573

Epoch: 5| Step: 2
Training loss: 2.2359728813171387
Validation loss: 2.149131199365021

Epoch: 5| Step: 3
Training loss: 1.886200189590454
Validation loss: 2.153912858296466

Epoch: 5| Step: 4
Training loss: 2.1983532905578613
Validation loss: 2.1541635246687036

Epoch: 5| Step: 5
Training loss: 2.9112324714660645
Validation loss: 2.145473372551703

Epoch: 5| Step: 6
Training loss: 2.1783394813537598
Validation loss: 2.1367205701848513

Epoch: 5| Step: 7
Training loss: 2.5688328742980957
Validation loss: 2.1285983708597

Epoch: 5| Step: 8
Training loss: 2.40157413482666
Validation loss: 2.1221819154677855

Epoch: 5| Step: 9
Training loss: 2.545741558074951
Validation loss: 2.1146715943531325

Epoch: 5| Step: 10
Training loss: 2.477517604827881
Validation loss: 2.0982463641833236

Epoch: 68| Step: 0
Training loss: 2.568586826324463
Validation loss: 2.082789999182506

Epoch: 5| Step: 1
Training loss: 2.47550368309021
Validation loss: 2.0826983592843495

Epoch: 5| Step: 2
Training loss: 1.872836709022522
Validation loss: 2.085123126224805

Epoch: 5| Step: 3
Training loss: 2.7680881023406982
Validation loss: 2.0879206195954354

Epoch: 5| Step: 4
Training loss: 2.5539798736572266
Validation loss: 2.0808411105986564

Epoch: 5| Step: 5
Training loss: 2.607252597808838
Validation loss: 2.0804751380797355

Epoch: 5| Step: 6
Training loss: 2.429699659347534
Validation loss: 2.086156540019538

Epoch: 5| Step: 7
Training loss: 2.218763589859009
Validation loss: 2.100775036760556

Epoch: 5| Step: 8
Training loss: 2.003457546234131
Validation loss: 2.0892535383983324

Epoch: 5| Step: 9
Training loss: 2.899975299835205
Validation loss: 2.0848810724032822

Epoch: 5| Step: 10
Training loss: 1.8431825637817383
Validation loss: 2.097534565515416

Epoch: 69| Step: 0
Training loss: 2.7167627811431885
Validation loss: 2.10131714933662

Epoch: 5| Step: 1
Training loss: 1.935516119003296
Validation loss: 2.099707798291278

Epoch: 5| Step: 2
Training loss: 2.896533966064453
Validation loss: 2.114980475876921

Epoch: 5| Step: 3
Training loss: 2.1866614818573
Validation loss: 2.1476445454423145

Epoch: 5| Step: 4
Training loss: 2.412684917449951
Validation loss: 2.1580821083438013

Epoch: 5| Step: 5
Training loss: 2.2738468647003174
Validation loss: 2.1672044800173853

Epoch: 5| Step: 6
Training loss: 2.7583556175231934
Validation loss: 2.180607363741885

Epoch: 5| Step: 7
Training loss: 2.315080165863037
Validation loss: 2.1332025630499727

Epoch: 5| Step: 8
Training loss: 2.468400239944458
Validation loss: 2.0933616597165345

Epoch: 5| Step: 9
Training loss: 1.9922597408294678
Validation loss: 2.070806218731788

Epoch: 5| Step: 10
Training loss: 2.60433030128479
Validation loss: 2.051396172533753

Epoch: 70| Step: 0
Training loss: 2.1459920406341553
Validation loss: 2.0536234686451573

Epoch: 5| Step: 1
Training loss: 2.4932339191436768
Validation loss: 2.0510400238857476

Epoch: 5| Step: 2
Training loss: 2.6269683837890625
Validation loss: 2.0451022758278796

Epoch: 5| Step: 3
Training loss: 2.017530918121338
Validation loss: 2.0546655526725193

Epoch: 5| Step: 4
Training loss: 3.0021729469299316
Validation loss: 2.049331029256185

Epoch: 5| Step: 5
Training loss: 2.042513370513916
Validation loss: 2.04136727445869

Epoch: 5| Step: 6
Training loss: 2.320711851119995
Validation loss: 2.0471356338070286

Epoch: 5| Step: 7
Training loss: 2.372894763946533
Validation loss: 2.0437821777918006

Epoch: 5| Step: 8
Training loss: 2.556039810180664
Validation loss: 2.041726073911113

Epoch: 5| Step: 9
Training loss: 2.0020980834960938
Validation loss: 2.0513262235990135

Epoch: 5| Step: 10
Training loss: 3.020723342895508
Validation loss: 2.044630754378534

Epoch: 71| Step: 0
Training loss: 1.444140911102295
Validation loss: 2.05877044123988

Epoch: 5| Step: 1
Training loss: 2.3965272903442383
Validation loss: 2.0588800919953214

Epoch: 5| Step: 2
Training loss: 2.938230276107788
Validation loss: 2.0678955983090144

Epoch: 5| Step: 3
Training loss: 2.4119229316711426
Validation loss: 2.0492192083789456

Epoch: 5| Step: 4
Training loss: 2.3022501468658447
Validation loss: 2.0635426544374034

Epoch: 5| Step: 5
Training loss: 2.9020416736602783
Validation loss: 2.078802472801619

Epoch: 5| Step: 6
Training loss: 2.033461809158325
Validation loss: 2.10133776357097

Epoch: 5| Step: 7
Training loss: 1.9824752807617188
Validation loss: 2.1272080098429034

Epoch: 5| Step: 8
Training loss: 2.7594265937805176
Validation loss: 2.1562172417999594

Epoch: 5| Step: 9
Training loss: 2.7266921997070312
Validation loss: 2.1594027562807967

Epoch: 5| Step: 10
Training loss: 2.3901145458221436
Validation loss: 2.169729686552478

Epoch: 72| Step: 0
Training loss: 2.3515284061431885
Validation loss: 2.2113676353167464

Epoch: 5| Step: 1
Training loss: 1.935124397277832
Validation loss: 2.247203614122124

Epoch: 5| Step: 2
Training loss: 2.340287685394287
Validation loss: 2.221925913646657

Epoch: 5| Step: 3
Training loss: 2.8903872966766357
Validation loss: 2.1964677956796463

Epoch: 5| Step: 4
Training loss: 2.16821026802063
Validation loss: 2.16678544270095

Epoch: 5| Step: 5
Training loss: 2.7879726886749268
Validation loss: 2.1507925602697555

Epoch: 5| Step: 6
Training loss: 2.0449326038360596
Validation loss: 2.146297513797719

Epoch: 5| Step: 7
Training loss: 2.1666817665100098
Validation loss: 2.138537346675832

Epoch: 5| Step: 8
Training loss: 2.785501480102539
Validation loss: 2.167786298259612

Epoch: 5| Step: 9
Training loss: 2.5361578464508057
Validation loss: 2.159451038606705

Epoch: 5| Step: 10
Training loss: 2.6305904388427734
Validation loss: 2.1439737863438104

Epoch: 73| Step: 0
Training loss: 2.023252010345459
Validation loss: 2.129567651338475

Epoch: 5| Step: 1
Training loss: 2.8926279544830322
Validation loss: 2.1244703595356276

Epoch: 5| Step: 2
Training loss: 2.342658281326294
Validation loss: 2.11081136298436

Epoch: 5| Step: 3
Training loss: 2.5031163692474365
Validation loss: 2.1024487044221614

Epoch: 5| Step: 4
Training loss: 1.4883551597595215
Validation loss: 2.08822529033948

Epoch: 5| Step: 5
Training loss: 2.5442862510681152
Validation loss: 2.0880206643894152

Epoch: 5| Step: 6
Training loss: 1.9706165790557861
Validation loss: 2.121657927831014

Epoch: 5| Step: 7
Training loss: 3.018096446990967
Validation loss: 2.1133483058662823

Epoch: 5| Step: 8
Training loss: 2.3872506618499756
Validation loss: 2.159793561504733

Epoch: 5| Step: 9
Training loss: 2.4279937744140625
Validation loss: 2.197406768798828

Epoch: 5| Step: 10
Training loss: 2.6455886363983154
Validation loss: 2.2316827389501754

Epoch: 74| Step: 0
Training loss: 2.5556976795196533
Validation loss: 2.2031200919100034

Epoch: 5| Step: 1
Training loss: 2.433933734893799
Validation loss: 2.217669124244362

Epoch: 5| Step: 2
Training loss: 1.8863704204559326
Validation loss: 2.199615911770892

Epoch: 5| Step: 3
Training loss: 2.295616388320923
Validation loss: 2.1830533268631145

Epoch: 5| Step: 4
Training loss: 2.3931589126586914
Validation loss: 2.1598709962701284

Epoch: 5| Step: 5
Training loss: 2.467766284942627
Validation loss: 2.1183361007321264

Epoch: 5| Step: 6
Training loss: 2.8553261756896973
Validation loss: 2.0885736814109226

Epoch: 5| Step: 7
Training loss: 2.461768627166748
Validation loss: 2.074226807522517

Epoch: 5| Step: 8
Training loss: 2.4346725940704346
Validation loss: 2.0752514844299643

Epoch: 5| Step: 9
Training loss: 2.0659804344177246
Validation loss: 2.098333816374502

Epoch: 5| Step: 10
Training loss: 2.5805623531341553
Validation loss: 2.0770864871240433

Epoch: 75| Step: 0
Training loss: 2.7536373138427734
Validation loss: 2.1260823626672067

Epoch: 5| Step: 1
Training loss: 2.9723331928253174
Validation loss: 2.133189688446701

Epoch: 5| Step: 2
Training loss: 2.1137776374816895
Validation loss: 2.134883961369914

Epoch: 5| Step: 3
Training loss: 2.4996936321258545
Validation loss: 2.1176227074797436

Epoch: 5| Step: 4
Training loss: 2.1944873332977295
Validation loss: 2.1060665781779955

Epoch: 5| Step: 5
Training loss: 1.6380020380020142
Validation loss: 2.1107554487002793

Epoch: 5| Step: 6
Training loss: 2.505192279815674
Validation loss: 2.1048936510598786

Epoch: 5| Step: 7
Training loss: 2.161919116973877
Validation loss: 2.126967578805903

Epoch: 5| Step: 8
Training loss: 2.787668228149414
Validation loss: 2.121613474302394

Epoch: 5| Step: 9
Training loss: 2.524548292160034
Validation loss: 2.104596645601334

Epoch: 5| Step: 10
Training loss: 2.3523616790771484
Validation loss: 2.090158426633445

Epoch: 76| Step: 0
Training loss: 2.5257484912872314
Validation loss: 2.0840131275115477

Epoch: 5| Step: 1
Training loss: 2.1484005451202393
Validation loss: 2.0674970919086086

Epoch: 5| Step: 2
Training loss: 2.3581130504608154
Validation loss: 2.075667642777966

Epoch: 5| Step: 3
Training loss: 2.2225425243377686
Validation loss: 2.0964262229140087

Epoch: 5| Step: 4
Training loss: 2.3973164558410645
Validation loss: 2.1161171236345844

Epoch: 5| Step: 5
Training loss: 2.064530849456787
Validation loss: 2.0953096010351695

Epoch: 5| Step: 6
Training loss: 2.581629991531372
Validation loss: 2.0831103235162716

Epoch: 5| Step: 7
Training loss: 2.596177577972412
Validation loss: 2.066948654831097

Epoch: 5| Step: 8
Training loss: 2.205024003982544
Validation loss: 2.056789416138844

Epoch: 5| Step: 9
Training loss: 2.4334747791290283
Validation loss: 2.052103636085346

Epoch: 5| Step: 10
Training loss: 2.5239195823669434
Validation loss: 2.0516110799645864

Epoch: 77| Step: 0
Training loss: 2.8313961029052734
Validation loss: 2.0514160407486783

Epoch: 5| Step: 1
Training loss: 2.756255626678467
Validation loss: 2.0639155731406262

Epoch: 5| Step: 2
Training loss: 2.3246827125549316
Validation loss: 2.0695990477838824

Epoch: 5| Step: 3
Training loss: 2.052293062210083
Validation loss: 2.0814892245877172

Epoch: 5| Step: 4
Training loss: 2.520308256149292
Validation loss: 2.1003590681219615

Epoch: 5| Step: 5
Training loss: 2.419926166534424
Validation loss: 2.1193478556089502

Epoch: 5| Step: 6
Training loss: 2.1830074787139893
Validation loss: 2.120279545425087

Epoch: 5| Step: 7
Training loss: 2.6848366260528564
Validation loss: 2.1255390567164265

Epoch: 5| Step: 8
Training loss: 2.114471435546875
Validation loss: 2.1308221227379254

Epoch: 5| Step: 9
Training loss: 1.7660980224609375
Validation loss: 2.142342487970988

Epoch: 5| Step: 10
Training loss: 2.239656686782837
Validation loss: 2.140145778656006

Epoch: 78| Step: 0
Training loss: 2.5877914428710938
Validation loss: 2.1092078634487685

Epoch: 5| Step: 1
Training loss: 2.0418403148651123
Validation loss: 2.1014442277211014

Epoch: 5| Step: 2
Training loss: 2.417726993560791
Validation loss: 2.094047596377711

Epoch: 5| Step: 3
Training loss: 2.348331928253174
Validation loss: 2.0844392443215973

Epoch: 5| Step: 4
Training loss: 2.0597305297851562
Validation loss: 2.072994073232015

Epoch: 5| Step: 5
Training loss: 2.661372661590576
Validation loss: 2.0821403970000563

Epoch: 5| Step: 6
Training loss: 2.7001304626464844
Validation loss: 2.0755613311644523

Epoch: 5| Step: 7
Training loss: 2.6167373657226562
Validation loss: 2.0800231272174465

Epoch: 5| Step: 8
Training loss: 1.9515262842178345
Validation loss: 2.0725251167051253

Epoch: 5| Step: 9
Training loss: 2.330876111984253
Validation loss: 2.08313476398427

Epoch: 5| Step: 10
Training loss: 2.3717143535614014
Validation loss: 2.089199762190542

Epoch: 79| Step: 0
Training loss: 2.570525646209717
Validation loss: 2.089882796810519

Epoch: 5| Step: 1
Training loss: 2.18206524848938
Validation loss: 2.1188906572198354

Epoch: 5| Step: 2
Training loss: 2.6543760299682617
Validation loss: 2.1661496470051427

Epoch: 5| Step: 3
Training loss: 2.0807623863220215
Validation loss: 2.1920125048647643

Epoch: 5| Step: 4
Training loss: 2.8115620613098145
Validation loss: 2.1728098328395555

Epoch: 5| Step: 5
Training loss: 1.7574609518051147
Validation loss: 2.1361148152300107

Epoch: 5| Step: 6
Training loss: 2.401817798614502
Validation loss: 2.106729656137446

Epoch: 5| Step: 7
Training loss: 1.9218906164169312
Validation loss: 2.104486588508852

Epoch: 5| Step: 8
Training loss: 1.7419840097427368
Validation loss: 2.0933602689414896

Epoch: 5| Step: 9
Training loss: 2.9401350021362305
Validation loss: 2.0687710264677643

Epoch: 5| Step: 10
Training loss: 2.69412899017334
Validation loss: 2.0566189673639115

Epoch: 80| Step: 0
Training loss: 3.0595285892486572
Validation loss: 2.042976199939687

Epoch: 5| Step: 1
Training loss: 2.108229875564575
Validation loss: 2.0414843277264665

Epoch: 5| Step: 2
Training loss: 2.351318120956421
Validation loss: 2.0449343419844106

Epoch: 5| Step: 3
Training loss: 1.9485142230987549
Validation loss: 2.046650136670759

Epoch: 5| Step: 4
Training loss: 2.625087261199951
Validation loss: 2.080447899397983

Epoch: 5| Step: 5
Training loss: 2.191187858581543
Validation loss: 2.086182757090497

Epoch: 5| Step: 6
Training loss: 2.1349809169769287
Validation loss: 2.1180358702136624

Epoch: 5| Step: 7
Training loss: 2.146688461303711
Validation loss: 2.129736033819055

Epoch: 5| Step: 8
Training loss: 2.497727870941162
Validation loss: 2.132176165939659

Epoch: 5| Step: 9
Training loss: 3.0142464637756348
Validation loss: 2.112685936753468

Epoch: 5| Step: 10
Training loss: 1.7689318656921387
Validation loss: 2.0866368598835443

Epoch: 81| Step: 0
Training loss: 2.29205584526062
Validation loss: 2.0742541295225903

Epoch: 5| Step: 1
Training loss: 2.103313684463501
Validation loss: 2.083426311451902

Epoch: 5| Step: 2
Training loss: 2.655478000640869
Validation loss: 2.077441887188983

Epoch: 5| Step: 3
Training loss: 2.5211291313171387
Validation loss: 2.0792854691064484

Epoch: 5| Step: 4
Training loss: 1.976873755455017
Validation loss: 2.0843990490000737

Epoch: 5| Step: 5
Training loss: 2.7416470050811768
Validation loss: 2.074904021396432

Epoch: 5| Step: 6
Training loss: 2.0798850059509277
Validation loss: 2.081327397336242

Epoch: 5| Step: 7
Training loss: 2.4288341999053955
Validation loss: 2.079956159796766

Epoch: 5| Step: 8
Training loss: 1.9561923742294312
Validation loss: 2.0765987109112483

Epoch: 5| Step: 9
Training loss: 2.4110305309295654
Validation loss: 2.0717524302903043

Epoch: 5| Step: 10
Training loss: 2.366617441177368
Validation loss: 2.074626948243828

Epoch: 82| Step: 0
Training loss: 1.8484878540039062
Validation loss: 2.0708533179375435

Epoch: 5| Step: 1
Training loss: 2.645000696182251
Validation loss: 2.0811576356169996

Epoch: 5| Step: 2
Training loss: 2.511335849761963
Validation loss: 2.094303622040697

Epoch: 5| Step: 3
Training loss: 1.7540925741195679
Validation loss: 2.125863298293083

Epoch: 5| Step: 4
Training loss: 2.406411647796631
Validation loss: 2.1493196871972855

Epoch: 5| Step: 5
Training loss: 1.690542459487915
Validation loss: 2.171354966778909

Epoch: 5| Step: 6
Training loss: 2.9163498878479004
Validation loss: 2.184623650325242

Epoch: 5| Step: 7
Training loss: 1.9728387594223022
Validation loss: 2.1440870941326184

Epoch: 5| Step: 8
Training loss: 2.3295845985412598
Validation loss: 2.09672204397058

Epoch: 5| Step: 9
Training loss: 2.713313579559326
Validation loss: 2.0833901615553003

Epoch: 5| Step: 10
Training loss: 2.9831161499023438
Validation loss: 2.070392866288462

Epoch: 83| Step: 0
Training loss: 2.297632932662964
Validation loss: 2.064729393169444

Epoch: 5| Step: 1
Training loss: 1.9903455972671509
Validation loss: 2.070392039514357

Epoch: 5| Step: 2
Training loss: 1.8613033294677734
Validation loss: 2.074130058288574

Epoch: 5| Step: 3
Training loss: 2.5070273876190186
Validation loss: 2.0727380898690995

Epoch: 5| Step: 4
Training loss: 2.513315200805664
Validation loss: 2.079879337741483

Epoch: 5| Step: 5
Training loss: 2.4293975830078125
Validation loss: 2.0833052935138827

Epoch: 5| Step: 6
Training loss: 2.3129544258117676
Validation loss: 2.0797214559329453

Epoch: 5| Step: 7
Training loss: 2.242464065551758
Validation loss: 2.077677244781166

Epoch: 5| Step: 8
Training loss: 2.507129430770874
Validation loss: 2.089951163978987

Epoch: 5| Step: 9
Training loss: 2.3688225746154785
Validation loss: 2.094607537792575

Epoch: 5| Step: 10
Training loss: 2.396368980407715
Validation loss: 2.098330795124013

Epoch: 84| Step: 0
Training loss: 1.9013350009918213
Validation loss: 2.0926840843692904

Epoch: 5| Step: 1
Training loss: 2.0647311210632324
Validation loss: 2.1265381971995034

Epoch: 5| Step: 2
Training loss: 2.485318422317505
Validation loss: 2.1226068696668072

Epoch: 5| Step: 3
Training loss: 2.3207130432128906
Validation loss: 2.086102117774307

Epoch: 5| Step: 4
Training loss: 3.011579751968384
Validation loss: 2.0753643384543796

Epoch: 5| Step: 5
Training loss: 2.83671498298645
Validation loss: 2.0601994414483347

Epoch: 5| Step: 6
Training loss: 2.082042694091797
Validation loss: 2.064326492688989

Epoch: 5| Step: 7
Training loss: 2.0620503425598145
Validation loss: 2.0734086844228927

Epoch: 5| Step: 8
Training loss: 2.3930776119232178
Validation loss: 2.088467392870175

Epoch: 5| Step: 9
Training loss: 2.121732711791992
Validation loss: 2.081006424401396

Epoch: 5| Step: 10
Training loss: 2.048074722290039
Validation loss: 2.1016284317098637

Epoch: 85| Step: 0
Training loss: 2.5073535442352295
Validation loss: 2.10924687821378

Epoch: 5| Step: 1
Training loss: 1.7558467388153076
Validation loss: 2.11888639901274

Epoch: 5| Step: 2
Training loss: 3.2101776599884033
Validation loss: 2.1385997444070797

Epoch: 5| Step: 3
Training loss: 1.9521701335906982
Validation loss: 2.1497201740100818

Epoch: 5| Step: 4
Training loss: 2.892493724822998
Validation loss: 2.1371261637697936

Epoch: 5| Step: 5
Training loss: 2.4909563064575195
Validation loss: 2.119197363494545

Epoch: 5| Step: 6
Training loss: 1.5001356601715088
Validation loss: 2.0917526368171937

Epoch: 5| Step: 7
Training loss: 2.496093511581421
Validation loss: 2.0779627356477963

Epoch: 5| Step: 8
Training loss: 2.2909493446350098
Validation loss: 2.0669363224378197

Epoch: 5| Step: 9
Training loss: 2.239104986190796
Validation loss: 2.068908824715563

Epoch: 5| Step: 10
Training loss: 1.8835723400115967
Validation loss: 2.0753602263748006

Epoch: 86| Step: 0
Training loss: 2.2107415199279785
Validation loss: 2.0619732282494985

Epoch: 5| Step: 1
Training loss: 2.4053826332092285
Validation loss: 2.0709925261876916

Epoch: 5| Step: 2
Training loss: 2.070051670074463
Validation loss: 2.070570324056892

Epoch: 5| Step: 3
Training loss: 2.4959235191345215
Validation loss: 2.0818239232545257

Epoch: 5| Step: 4
Training loss: 1.872084379196167
Validation loss: 2.1048871227490005

Epoch: 5| Step: 5
Training loss: 1.760887861251831
Validation loss: 2.1134411570846394

Epoch: 5| Step: 6
Training loss: 2.8683667182922363
Validation loss: 2.10192810720013

Epoch: 5| Step: 7
Training loss: 2.831641674041748
Validation loss: 2.077887422295027

Epoch: 5| Step: 8
Training loss: 2.2554798126220703
Validation loss: 2.064430934126659

Epoch: 5| Step: 9
Training loss: 2.618788242340088
Validation loss: 2.0668106450829455

Epoch: 5| Step: 10
Training loss: 1.619541883468628
Validation loss: 2.059434752310476

Epoch: 87| Step: 0
Training loss: 2.4610908031463623
Validation loss: 2.0492162614740352

Epoch: 5| Step: 1
Training loss: 2.3537979125976562
Validation loss: 2.054884172254993

Epoch: 5| Step: 2
Training loss: 2.1527695655822754
Validation loss: 2.0570623708027664

Epoch: 5| Step: 3
Training loss: 2.3307299613952637
Validation loss: 2.0514076550801597

Epoch: 5| Step: 4
Training loss: 2.238264799118042
Validation loss: 2.0469520656011437

Epoch: 5| Step: 5
Training loss: 1.9176292419433594
Validation loss: 2.0603242907472836

Epoch: 5| Step: 6
Training loss: 1.8388683795928955
Validation loss: 2.07044380967335

Epoch: 5| Step: 7
Training loss: 2.591465473175049
Validation loss: 2.0860863757389847

Epoch: 5| Step: 8
Training loss: 2.448897123336792
Validation loss: 2.143178778309976

Epoch: 5| Step: 9
Training loss: 2.346862316131592
Validation loss: 2.1816878831514748

Epoch: 5| Step: 10
Training loss: 2.3657312393188477
Validation loss: 2.192220458420374

Epoch: 88| Step: 0
Training loss: 2.538564443588257
Validation loss: 2.2108973995331795

Epoch: 5| Step: 1
Training loss: 1.9013665914535522
Validation loss: 2.2203414337609404

Epoch: 5| Step: 2
Training loss: 2.603038787841797
Validation loss: 2.2195845573179183

Epoch: 5| Step: 3
Training loss: 2.4266128540039062
Validation loss: 2.1976034423356414

Epoch: 5| Step: 4
Training loss: 2.4777419567108154
Validation loss: 2.1603261270830707

Epoch: 5| Step: 5
Training loss: 1.769696593284607
Validation loss: 2.118527845669818

Epoch: 5| Step: 6
Training loss: 2.445054531097412
Validation loss: 2.0972412158084173

Epoch: 5| Step: 7
Training loss: 1.409140944480896
Validation loss: 2.070727727746451

Epoch: 5| Step: 8
Training loss: 2.811493396759033
Validation loss: 2.0547880100947555

Epoch: 5| Step: 9
Training loss: 2.355020523071289
Validation loss: 2.0652146108688845

Epoch: 5| Step: 10
Training loss: 2.5070364475250244
Validation loss: 2.0696939973420996

Epoch: 89| Step: 0
Training loss: 2.467796802520752
Validation loss: 2.0620084449809086

Epoch: 5| Step: 1
Training loss: 1.9849869012832642
Validation loss: 2.072855821219824

Epoch: 5| Step: 2
Training loss: 2.0868680477142334
Validation loss: 2.0788468699301443

Epoch: 5| Step: 3
Training loss: 2.400743007659912
Validation loss: 2.087360930699174

Epoch: 5| Step: 4
Training loss: 2.0641977787017822
Validation loss: 2.0863008563236525

Epoch: 5| Step: 5
Training loss: 2.1148390769958496
Validation loss: 2.1007031279225505

Epoch: 5| Step: 6
Training loss: 1.8701248168945312
Validation loss: 2.1100088960380963

Epoch: 5| Step: 7
Training loss: 2.8582000732421875
Validation loss: 2.123342271774046

Epoch: 5| Step: 8
Training loss: 2.516050100326538
Validation loss: 2.1289965491141043

Epoch: 5| Step: 9
Training loss: 1.7314335107803345
Validation loss: 2.1055282110809

Epoch: 5| Step: 10
Training loss: 2.8255698680877686
Validation loss: 2.0824565502905075

Epoch: 90| Step: 0
Training loss: 2.2412524223327637
Validation loss: 2.0851660672054497

Epoch: 5| Step: 1
Training loss: 2.42362380027771
Validation loss: 2.0751520126096663

Epoch: 5| Step: 2
Training loss: 2.8903534412384033
Validation loss: 2.0696238574161323

Epoch: 5| Step: 3
Training loss: 2.324573040008545
Validation loss: 2.077256609034795

Epoch: 5| Step: 4
Training loss: 1.5881941318511963
Validation loss: 2.0830149637755526

Epoch: 5| Step: 5
Training loss: 1.801120400428772
Validation loss: 2.0880371344986783

Epoch: 5| Step: 6
Training loss: 2.208772897720337
Validation loss: 2.092465555796059

Epoch: 5| Step: 7
Training loss: 2.4727659225463867
Validation loss: 2.0850160173190537

Epoch: 5| Step: 8
Training loss: 2.518245220184326
Validation loss: 2.0976325414514028

Epoch: 5| Step: 9
Training loss: 2.3039374351501465
Validation loss: 2.1091654095598447

Epoch: 5| Step: 10
Training loss: 1.8264057636260986
Validation loss: 2.094044090599142

Epoch: 91| Step: 0
Training loss: 2.242316722869873
Validation loss: 2.1001154043341197

Epoch: 5| Step: 1
Training loss: 2.482412338256836
Validation loss: 2.104633085189327

Epoch: 5| Step: 2
Training loss: 2.2707161903381348
Validation loss: 2.122912881194904

Epoch: 5| Step: 3
Training loss: 2.0656628608703613
Validation loss: 2.1343583573577223

Epoch: 5| Step: 4
Training loss: 2.127455234527588
Validation loss: 2.146563001858291

Epoch: 5| Step: 5
Training loss: 2.7530362606048584
Validation loss: 2.159144247731855

Epoch: 5| Step: 6
Training loss: 1.635268211364746
Validation loss: 2.167955534432524

Epoch: 5| Step: 7
Training loss: 1.9911797046661377
Validation loss: 2.1583913449318177

Epoch: 5| Step: 8
Training loss: 2.4993042945861816
Validation loss: 2.128843790741377

Epoch: 5| Step: 9
Training loss: 2.003007411956787
Validation loss: 2.1357340530682634

Epoch: 5| Step: 10
Training loss: 2.525686264038086
Validation loss: 2.1601355947473997

Epoch: 92| Step: 0
Training loss: 2.346120834350586
Validation loss: 2.15921308917384

Epoch: 5| Step: 1
Training loss: 1.8974847793579102
Validation loss: 2.1485521806183683

Epoch: 5| Step: 2
Training loss: 2.5494542121887207
Validation loss: 2.137824430260607

Epoch: 5| Step: 3
Training loss: 2.5288944244384766
Validation loss: 2.121452723779986

Epoch: 5| Step: 4
Training loss: 1.8176599740982056
Validation loss: 2.104434126166887

Epoch: 5| Step: 5
Training loss: 2.1613895893096924
Validation loss: 2.0885451839816187

Epoch: 5| Step: 6
Training loss: 2.4159178733825684
Validation loss: 2.0630045731862388

Epoch: 5| Step: 7
Training loss: 2.452713966369629
Validation loss: 2.0450618138877292

Epoch: 5| Step: 8
Training loss: 2.6013150215148926
Validation loss: 2.0434340097570933

Epoch: 5| Step: 9
Training loss: 1.553990364074707
Validation loss: 2.0363991786074895

Epoch: 5| Step: 10
Training loss: 2.285752296447754
Validation loss: 2.0524845841110393

Epoch: 93| Step: 0
Training loss: 2.08742094039917
Validation loss: 2.0663100314396683

Epoch: 5| Step: 1
Training loss: 2.53955340385437
Validation loss: 2.088727545994584

Epoch: 5| Step: 2
Training loss: 2.3894431591033936
Validation loss: 2.1180766346634075

Epoch: 5| Step: 3
Training loss: 2.0664846897125244
Validation loss: 2.168739725184697

Epoch: 5| Step: 4
Training loss: 2.416656970977783
Validation loss: 2.183968118442002

Epoch: 5| Step: 5
Training loss: 2.614079236984253
Validation loss: 2.2001017242349605

Epoch: 5| Step: 6
Training loss: 1.6031039953231812
Validation loss: 2.22499349809462

Epoch: 5| Step: 7
Training loss: 1.8808965682983398
Validation loss: 2.179935178449077

Epoch: 5| Step: 8
Training loss: 2.286553144454956
Validation loss: 2.1130008902601016

Epoch: 5| Step: 9
Training loss: 2.115172863006592
Validation loss: 2.093247463626246

Epoch: 5| Step: 10
Training loss: 2.0580241680145264
Validation loss: 2.0701918627626155

Epoch: 94| Step: 0
Training loss: 1.6030222177505493
Validation loss: 2.075449784596761

Epoch: 5| Step: 1
Training loss: 2.549973726272583
Validation loss: 2.0797446517534155

Epoch: 5| Step: 2
Training loss: 2.7202954292297363
Validation loss: 2.0747290516412384

Epoch: 5| Step: 3
Training loss: 1.8921505212783813
Validation loss: 2.076333024168527

Epoch: 5| Step: 4
Training loss: 2.3567354679107666
Validation loss: 2.080529491106669

Epoch: 5| Step: 5
Training loss: 2.029742956161499
Validation loss: 2.0811516033705844

Epoch: 5| Step: 6
Training loss: 1.9745668172836304
Validation loss: 2.073459953390142

Epoch: 5| Step: 7
Training loss: 1.6715567111968994
Validation loss: 2.0734350296758834

Epoch: 5| Step: 8
Training loss: 1.6168924570083618
Validation loss: 2.103445212046305

Epoch: 5| Step: 9
Training loss: 2.927860975265503
Validation loss: 2.139805437416159

Epoch: 5| Step: 10
Training loss: 3.010866165161133
Validation loss: 2.179861175116672

Epoch: 95| Step: 0
Training loss: 2.6336159706115723
Validation loss: 2.1545400183687926

Epoch: 5| Step: 1
Training loss: 1.7007265090942383
Validation loss: 2.1269464313343005

Epoch: 5| Step: 2
Training loss: 2.795968532562256
Validation loss: 2.109336341581037

Epoch: 5| Step: 3
Training loss: 2.3134024143218994
Validation loss: 2.074371487863602

Epoch: 5| Step: 4
Training loss: 2.363058567047119
Validation loss: 2.0713667356839744

Epoch: 5| Step: 5
Training loss: 1.8984344005584717
Validation loss: 2.0487615600708993

Epoch: 5| Step: 6
Training loss: 2.0139341354370117
Validation loss: 2.0698771835655294

Epoch: 5| Step: 7
Training loss: 1.8519618511199951
Validation loss: 2.091389450975644

Epoch: 5| Step: 8
Training loss: 2.027575731277466
Validation loss: 2.1222125458460983

Epoch: 5| Step: 9
Training loss: 2.220834493637085
Validation loss: 2.1409677907984745

Epoch: 5| Step: 10
Training loss: 2.3650753498077393
Validation loss: 2.08630108833313

Epoch: 96| Step: 0
Training loss: 2.7369399070739746
Validation loss: 2.0692038920617875

Epoch: 5| Step: 1
Training loss: 2.2343077659606934
Validation loss: 2.0499677055625507

Epoch: 5| Step: 2
Training loss: 2.4712719917297363
Validation loss: 2.052791404467757

Epoch: 5| Step: 3
Training loss: 1.894036054611206
Validation loss: 2.0503985330622685

Epoch: 5| Step: 4
Training loss: 1.9383331537246704
Validation loss: 2.0458902107772006

Epoch: 5| Step: 5
Training loss: 1.992384672164917
Validation loss: 2.0387156548038607

Epoch: 5| Step: 6
Training loss: 1.7388582229614258
Validation loss: 2.053046331610731

Epoch: 5| Step: 7
Training loss: 2.5771775245666504
Validation loss: 2.0676978365067513

Epoch: 5| Step: 8
Training loss: 2.3067874908447266
Validation loss: 2.0920185401875484

Epoch: 5| Step: 9
Training loss: 1.8383945226669312
Validation loss: 2.1475381441013788

Epoch: 5| Step: 10
Training loss: 2.1095519065856934
Validation loss: 2.1471569448389034

Epoch: 97| Step: 0
Training loss: 2.662992238998413
Validation loss: 2.173656527714063

Epoch: 5| Step: 1
Training loss: 2.3837742805480957
Validation loss: 2.205364873332362

Epoch: 5| Step: 2
Training loss: 1.6677793264389038
Validation loss: 2.226507056143976

Epoch: 5| Step: 3
Training loss: 1.585223913192749
Validation loss: 2.2050021989371187

Epoch: 5| Step: 4
Training loss: 2.3873167037963867
Validation loss: 2.2054117341195383

Epoch: 5| Step: 5
Training loss: 2.0402114391326904
Validation loss: 2.193100098640688

Epoch: 5| Step: 6
Training loss: 1.8982023000717163
Validation loss: 2.1433830389412503

Epoch: 5| Step: 7
Training loss: 2.6137802600860596
Validation loss: 2.112980486244284

Epoch: 5| Step: 8
Training loss: 2.079507350921631
Validation loss: 2.0865485796364407

Epoch: 5| Step: 9
Training loss: 1.9328091144561768
Validation loss: 2.0642737316828903

Epoch: 5| Step: 10
Training loss: 2.548943042755127
Validation loss: 2.0465928841662664

Epoch: 98| Step: 0
Training loss: 1.9948123693466187
Validation loss: 2.0255786577860513

Epoch: 5| Step: 1
Training loss: 2.2674190998077393
Validation loss: 2.0181626235285113

Epoch: 5| Step: 2
Training loss: 1.9380279779434204
Validation loss: 2.026075373413742

Epoch: 5| Step: 3
Training loss: 2.3824563026428223
Validation loss: 2.034106539141747

Epoch: 5| Step: 4
Training loss: 2.407442808151245
Validation loss: 2.0315027442029727

Epoch: 5| Step: 5
Training loss: 2.086021900177002
Validation loss: 2.0426289714792722

Epoch: 5| Step: 6
Training loss: 2.215677261352539
Validation loss: 2.039294527422997

Epoch: 5| Step: 7
Training loss: 1.9052633047103882
Validation loss: 2.0323255600467807

Epoch: 5| Step: 8
Training loss: 2.1176857948303223
Validation loss: 2.0581830034973803

Epoch: 5| Step: 9
Training loss: 2.0454957485198975
Validation loss: 2.0675212824216453

Epoch: 5| Step: 10
Training loss: 2.5330028533935547
Validation loss: 2.101551522490799

Epoch: 99| Step: 0
Training loss: 1.5658717155456543
Validation loss: 2.1270687400653796

Epoch: 5| Step: 1
Training loss: 2.3136708736419678
Validation loss: 2.1369022400148454

Epoch: 5| Step: 2
Training loss: 2.1693501472473145
Validation loss: 2.108148064664615

Epoch: 5| Step: 3
Training loss: 1.5294967889785767
Validation loss: 2.083955036696567

Epoch: 5| Step: 4
Training loss: 2.009852647781372
Validation loss: 2.0587038455470914

Epoch: 5| Step: 5
Training loss: 2.1825759410858154
Validation loss: 2.0596055881951445

Epoch: 5| Step: 6
Training loss: 2.8340070247650146
Validation loss: 2.057270215403649

Epoch: 5| Step: 7
Training loss: 2.154381275177002
Validation loss: 2.0701380750184417

Epoch: 5| Step: 8
Training loss: 2.294057846069336
Validation loss: 2.069609554865027

Epoch: 5| Step: 9
Training loss: 2.218247175216675
Validation loss: 2.0815003456607943

Epoch: 5| Step: 10
Training loss: 2.006091833114624
Validation loss: 2.0924471027107647

Epoch: 100| Step: 0
Training loss: 1.9539146423339844
Validation loss: 2.1385014339159896

Epoch: 5| Step: 1
Training loss: 1.904909372329712
Validation loss: 2.1609473331000215

Epoch: 5| Step: 2
Training loss: 2.0489959716796875
Validation loss: 2.172111039520592

Epoch: 5| Step: 3
Training loss: 1.6042330265045166
Validation loss: 2.1811308489050916

Epoch: 5| Step: 4
Training loss: 2.034881591796875
Validation loss: 2.1802440997092956

Epoch: 5| Step: 5
Training loss: 2.0824055671691895
Validation loss: 2.1401822208076395

Epoch: 5| Step: 6
Training loss: 1.9672352075576782
Validation loss: 2.1128153236963416

Epoch: 5| Step: 7
Training loss: 2.1219589710235596
Validation loss: 2.089949107939197

Epoch: 5| Step: 8
Training loss: 2.2251667976379395
Validation loss: 2.082087839803388

Epoch: 5| Step: 9
Training loss: 2.559436321258545
Validation loss: 2.098911919901448

Epoch: 5| Step: 10
Training loss: 2.7696781158447266
Validation loss: 2.1111611909763788

Epoch: 101| Step: 0
Training loss: 1.9541652202606201
Validation loss: 2.0844451048040904

Epoch: 5| Step: 1
Training loss: 1.6164343357086182
Validation loss: 2.0889758627901793

Epoch: 5| Step: 2
Training loss: 2.0168964862823486
Validation loss: 2.0828630411496727

Epoch: 5| Step: 3
Training loss: 2.7131972312927246
Validation loss: 2.092296523432578

Epoch: 5| Step: 4
Training loss: 2.5695080757141113
Validation loss: 2.0513178097304476

Epoch: 5| Step: 5
Training loss: 1.9956581592559814
Validation loss: 2.038003497226264

Epoch: 5| Step: 6
Training loss: 2.185800075531006
Validation loss: 2.0017460751277145

Epoch: 5| Step: 7
Training loss: 1.9952418804168701
Validation loss: 2.0041972309030514

Epoch: 5| Step: 8
Training loss: 2.126141309738159
Validation loss: 2.013817410315237

Epoch: 5| Step: 9
Training loss: 2.086728572845459
Validation loss: 2.023547451983216

Epoch: 5| Step: 10
Training loss: 2.0757577419281006
Validation loss: 2.0382204542877855

Epoch: 102| Step: 0
Training loss: 2.495410442352295
Validation loss: 2.075364183354121

Epoch: 5| Step: 1
Training loss: 2.2508556842803955
Validation loss: 2.110637228976014

Epoch: 5| Step: 2
Training loss: 2.3110945224761963
Validation loss: 2.1226618187401884

Epoch: 5| Step: 3
Training loss: 1.9108253717422485
Validation loss: 2.1238506814484954

Epoch: 5| Step: 4
Training loss: 1.9741089344024658
Validation loss: 2.102523701165312

Epoch: 5| Step: 5
Training loss: 2.387273073196411
Validation loss: 2.0850217598740772

Epoch: 5| Step: 6
Training loss: 1.7588367462158203
Validation loss: 2.071174389572554

Epoch: 5| Step: 7
Training loss: 1.9532749652862549
Validation loss: 2.0584577911643573

Epoch: 5| Step: 8
Training loss: 1.9594357013702393
Validation loss: 2.0480884416129

Epoch: 5| Step: 9
Training loss: 1.9396610260009766
Validation loss: 2.0526104306661956

Epoch: 5| Step: 10
Training loss: 1.9811912775039673
Validation loss: 2.044409577564527

Epoch: 103| Step: 0
Training loss: 2.148998498916626
Validation loss: 2.060295740763346

Epoch: 5| Step: 1
Training loss: 1.987321138381958
Validation loss: 2.06065978798815

Epoch: 5| Step: 2
Training loss: 1.8775920867919922
Validation loss: 2.0575300621730026

Epoch: 5| Step: 3
Training loss: 1.9123462438583374
Validation loss: 2.0702769884499173

Epoch: 5| Step: 4
Training loss: 2.6637682914733887
Validation loss: 2.1047009844933786

Epoch: 5| Step: 5
Training loss: 2.3949131965637207
Validation loss: 2.1103256223022298

Epoch: 5| Step: 6
Training loss: 1.9817609786987305
Validation loss: 2.113565109109366

Epoch: 5| Step: 7
Training loss: 1.7826740741729736
Validation loss: 2.099707249672182

Epoch: 5| Step: 8
Training loss: 2.273742437362671
Validation loss: 2.0983486893356487

Epoch: 5| Step: 9
Training loss: 2.279508352279663
Validation loss: 2.0957918090205037

Epoch: 5| Step: 10
Training loss: 1.7909032106399536
Validation loss: 2.1150890563123967

Epoch: 104| Step: 0
Training loss: 2.0992283821105957
Validation loss: 2.123691357592101

Epoch: 5| Step: 1
Training loss: 2.1414637565612793
Validation loss: 2.131188492621145

Epoch: 5| Step: 2
Training loss: 1.662366271018982
Validation loss: 2.1217094775169127

Epoch: 5| Step: 3
Training loss: 1.9063587188720703
Validation loss: 2.1222843764930643

Epoch: 5| Step: 4
Training loss: 2.0815987586975098
Validation loss: 2.1429681034498316

Epoch: 5| Step: 5
Training loss: 2.3603949546813965
Validation loss: 2.1392966008955434

Epoch: 5| Step: 6
Training loss: 1.6765731573104858
Validation loss: 2.1315435773582867

Epoch: 5| Step: 7
Training loss: 1.9379819631576538
Validation loss: 2.126641288880379

Epoch: 5| Step: 8
Training loss: 2.182652235031128
Validation loss: 2.090781327216856

Epoch: 5| Step: 9
Training loss: 2.5144591331481934
Validation loss: 2.059846173050583

Epoch: 5| Step: 10
Training loss: 2.366642713546753
Validation loss: 2.0347346528883903

Epoch: 105| Step: 0
Training loss: 2.172717809677124
Validation loss: 2.055640579551779

Epoch: 5| Step: 1
Training loss: 2.6728758811950684
Validation loss: 2.073143013062016

Epoch: 5| Step: 2
Training loss: 1.765216588973999
Validation loss: 2.0912292029268

Epoch: 5| Step: 3
Training loss: 2.0255126953125
Validation loss: 2.0686827974934734

Epoch: 5| Step: 4
Training loss: 2.227750301361084
Validation loss: 2.034684891341835

Epoch: 5| Step: 5
Training loss: 2.2417831420898438
Validation loss: 2.013295773536928

Epoch: 5| Step: 6
Training loss: 2.3881707191467285
Validation loss: 1.9886526830734745

Epoch: 5| Step: 7
Training loss: 2.3139357566833496
Validation loss: 1.9736719259651758

Epoch: 5| Step: 8
Training loss: 1.9298317432403564
Validation loss: 1.9810725001878635

Epoch: 5| Step: 9
Training loss: 1.7032665014266968
Validation loss: 1.9946733110694475

Epoch: 5| Step: 10
Training loss: 1.3050756454467773
Validation loss: 2.0214318742034254

Epoch: 106| Step: 0
Training loss: 2.4402916431427
Validation loss: 2.052112139681334

Epoch: 5| Step: 1
Training loss: 2.6033434867858887
Validation loss: 2.0754527045834448

Epoch: 5| Step: 2
Training loss: 2.2471070289611816
Validation loss: 2.09208877881368

Epoch: 5| Step: 3
Training loss: 1.3761694431304932
Validation loss: 2.1243479828680716

Epoch: 5| Step: 4
Training loss: 2.4499614238739014
Validation loss: 2.154414439714083

Epoch: 5| Step: 5
Training loss: 1.7671072483062744
Validation loss: 2.1438250028958885

Epoch: 5| Step: 6
Training loss: 2.0717520713806152
Validation loss: 2.125563689457473

Epoch: 5| Step: 7
Training loss: 2.445955753326416
Validation loss: 2.1084325698114212

Epoch: 5| Step: 8
Training loss: 1.8397674560546875
Validation loss: 2.107960988116521

Epoch: 5| Step: 9
Training loss: 1.7657487392425537
Validation loss: 2.1155900134835193

Epoch: 5| Step: 10
Training loss: 1.6672576665878296
Validation loss: 2.092179670128771

Epoch: 107| Step: 0
Training loss: 1.838830590248108
Validation loss: 2.0794247940022457

Epoch: 5| Step: 1
Training loss: 1.681046485900879
Validation loss: 2.090504543755644

Epoch: 5| Step: 2
Training loss: 2.0344955921173096
Validation loss: 2.107973579437502

Epoch: 5| Step: 3
Training loss: 1.7827377319335938
Validation loss: 2.111356705747625

Epoch: 5| Step: 4
Training loss: 2.4369866847991943
Validation loss: 2.1466370346725627

Epoch: 5| Step: 5
Training loss: 2.110535144805908
Validation loss: 2.1366074046780987

Epoch: 5| Step: 6
Training loss: 2.6262314319610596
Validation loss: 2.1018252180468653

Epoch: 5| Step: 7
Training loss: 1.614392876625061
Validation loss: 2.0635485392744823

Epoch: 5| Step: 8
Training loss: 1.810826301574707
Validation loss: 2.036119532841508

Epoch: 5| Step: 9
Training loss: 2.491241931915283
Validation loss: 2.025388612542101

Epoch: 5| Step: 10
Training loss: 2.0648136138916016
Validation loss: 2.0196357568105063

Epoch: 108| Step: 0
Training loss: 2.386258602142334
Validation loss: 2.061757408162599

Epoch: 5| Step: 1
Training loss: 2.115285873413086
Validation loss: 2.1063125902606594

Epoch: 5| Step: 2
Training loss: 2.3396549224853516
Validation loss: 2.142148889521117

Epoch: 5| Step: 3
Training loss: 2.508317470550537
Validation loss: 2.157253634545111

Epoch: 5| Step: 4
Training loss: 2.4063496589660645
Validation loss: 2.1327839000250703

Epoch: 5| Step: 5
Training loss: 2.0892701148986816
Validation loss: 2.094042114032212

Epoch: 5| Step: 6
Training loss: 1.0505425930023193
Validation loss: 2.062631178927678

Epoch: 5| Step: 7
Training loss: 1.8829491138458252
Validation loss: 2.0521571764381985

Epoch: 5| Step: 8
Training loss: 1.964630126953125
Validation loss: 2.0428646020991827

Epoch: 5| Step: 9
Training loss: 1.8159959316253662
Validation loss: 2.0536188617829354

Epoch: 5| Step: 10
Training loss: 2.074483633041382
Validation loss: 2.0538225532859884

Epoch: 109| Step: 0
Training loss: 2.1720573902130127
Validation loss: 2.0520727531884306

Epoch: 5| Step: 1
Training loss: 1.7379289865493774
Validation loss: 2.049179951349894

Epoch: 5| Step: 2
Training loss: 1.5896520614624023
Validation loss: 2.0599032166183635

Epoch: 5| Step: 3
Training loss: 2.0735297203063965
Validation loss: 2.075364629427592

Epoch: 5| Step: 4
Training loss: 2.6471736431121826
Validation loss: 2.0901099584435903

Epoch: 5| Step: 5
Training loss: 1.9394909143447876
Validation loss: 2.081724082269976

Epoch: 5| Step: 6
Training loss: 2.3681132793426514
Validation loss: 2.0591971284599713

Epoch: 5| Step: 7
Training loss: 2.4962849617004395
Validation loss: 2.0781727119158675

Epoch: 5| Step: 8
Training loss: 1.210799217224121
Validation loss: 2.0739429676404564

Epoch: 5| Step: 9
Training loss: 1.944624662399292
Validation loss: 2.056476413562734

Epoch: 5| Step: 10
Training loss: 1.8004779815673828
Validation loss: 2.0489740512704335

Epoch: 110| Step: 0
Training loss: 2.194059371948242
Validation loss: 2.048477160033359

Epoch: 5| Step: 1
Training loss: 1.6423120498657227
Validation loss: 2.0385390430368404

Epoch: 5| Step: 2
Training loss: 1.9445390701293945
Validation loss: 2.038060049856863

Epoch: 5| Step: 3
Training loss: 1.970380425453186
Validation loss: 2.0186216805570867

Epoch: 5| Step: 4
Training loss: 1.9476146697998047
Validation loss: 1.997288752627629

Epoch: 5| Step: 5
Training loss: 1.6478006839752197
Validation loss: 2.005667899244575

Epoch: 5| Step: 6
Training loss: 2.447375535964966
Validation loss: 1.9999619812093756

Epoch: 5| Step: 7
Training loss: 1.8841384649276733
Validation loss: 2.011938830857636

Epoch: 5| Step: 8
Training loss: 1.8429855108261108
Validation loss: 2.021961430067657

Epoch: 5| Step: 9
Training loss: 2.4850916862487793
Validation loss: 2.022474296631352

Epoch: 5| Step: 10
Training loss: 2.041055679321289
Validation loss: 2.0490128096713813

Epoch: 111| Step: 0
Training loss: 1.9261776208877563
Validation loss: 2.055549460072671

Epoch: 5| Step: 1
Training loss: 1.5740406513214111
Validation loss: 2.0563886755256244

Epoch: 5| Step: 2
Training loss: 2.4489502906799316
Validation loss: 2.063735942686758

Epoch: 5| Step: 3
Training loss: 2.0435171127319336
Validation loss: 2.092079859907909

Epoch: 5| Step: 4
Training loss: 1.7009735107421875
Validation loss: 2.0823003784302743

Epoch: 5| Step: 5
Training loss: 2.331111192703247
Validation loss: 2.066001178115927

Epoch: 5| Step: 6
Training loss: 1.0414193868637085
Validation loss: 2.054729196333116

Epoch: 5| Step: 7
Training loss: 2.079802989959717
Validation loss: 2.0358628124319096

Epoch: 5| Step: 8
Training loss: 1.826862096786499
Validation loss: 2.0372535387674966

Epoch: 5| Step: 9
Training loss: 2.827300548553467
Validation loss: 2.0255655396369194

Epoch: 5| Step: 10
Training loss: 1.9571342468261719
Validation loss: 2.009376920679564

Epoch: 112| Step: 0
Training loss: 2.0366740226745605
Validation loss: 2.00359740308536

Epoch: 5| Step: 1
Training loss: 2.8340446949005127
Validation loss: 2.0000082856865338

Epoch: 5| Step: 2
Training loss: 2.1383070945739746
Validation loss: 1.9928379289565548

Epoch: 5| Step: 3
Training loss: 1.4591362476348877
Validation loss: 2.0023147867571924

Epoch: 5| Step: 4
Training loss: 1.7084884643554688
Validation loss: 2.012397684076781

Epoch: 5| Step: 5
Training loss: 1.7431583404541016
Validation loss: 2.0197235192022016

Epoch: 5| Step: 6
Training loss: 2.023437976837158
Validation loss: 2.0366143706024333

Epoch: 5| Step: 7
Training loss: 2.399432420730591
Validation loss: 2.039722099099108

Epoch: 5| Step: 8
Training loss: 1.7344930171966553
Validation loss: 2.0318398552556194

Epoch: 5| Step: 9
Training loss: 1.8024314641952515
Validation loss: 2.01669216668734

Epoch: 5| Step: 10
Training loss: 1.7936770915985107
Validation loss: 2.010943853726951

Epoch: 113| Step: 0
Training loss: 1.6316992044448853
Validation loss: 2.025971016576213

Epoch: 5| Step: 1
Training loss: 1.5587809085845947
Validation loss: 2.043118107703424

Epoch: 5| Step: 2
Training loss: 2.0285487174987793
Validation loss: 2.0757510905624716

Epoch: 5| Step: 3
Training loss: 2.610154867172241
Validation loss: 2.106018581698018

Epoch: 5| Step: 4
Training loss: 2.225698947906494
Validation loss: 2.1058099590322024

Epoch: 5| Step: 5
Training loss: 1.8809776306152344
Validation loss: 2.098192852030518

Epoch: 5| Step: 6
Training loss: 1.9387359619140625
Validation loss: 2.070673493928807

Epoch: 5| Step: 7
Training loss: 1.67669677734375
Validation loss: 2.0684337615966797

Epoch: 5| Step: 8
Training loss: 1.8532791137695312
Validation loss: 2.0370131205486994

Epoch: 5| Step: 9
Training loss: 1.9076659679412842
Validation loss: 2.0225096492357153

Epoch: 5| Step: 10
Training loss: 2.3625428676605225
Validation loss: 2.0009569916673886

Epoch: 114| Step: 0
Training loss: 2.063598155975342
Validation loss: 1.9876774062392533

Epoch: 5| Step: 1
Training loss: 1.617515206336975
Validation loss: 2.004670432818833

Epoch: 5| Step: 2
Training loss: 1.3741021156311035
Validation loss: 2.005690513118621

Epoch: 5| Step: 3
Training loss: 2.373255968093872
Validation loss: 2.017102635034951

Epoch: 5| Step: 4
Training loss: 2.177515745162964
Validation loss: 2.0216509424230105

Epoch: 5| Step: 5
Training loss: 2.1793694496154785
Validation loss: 2.013089959339429

Epoch: 5| Step: 6
Training loss: 2.199904203414917
Validation loss: 2.0175291543365805

Epoch: 5| Step: 7
Training loss: 2.205247402191162
Validation loss: 2.0200155447888117

Epoch: 5| Step: 8
Training loss: 2.0756614208221436
Validation loss: 2.0527129557824906

Epoch: 5| Step: 9
Training loss: 1.6967048645019531
Validation loss: 2.0651645532218357

Epoch: 5| Step: 10
Training loss: 1.3520978689193726
Validation loss: 2.0612753104138117

Epoch: 115| Step: 0
Training loss: 1.6820265054702759
Validation loss: 2.0880396391755793

Epoch: 5| Step: 1
Training loss: 1.4941599369049072
Validation loss: 2.0909104962502756

Epoch: 5| Step: 2
Training loss: 1.237486481666565
Validation loss: 2.0937944560922603

Epoch: 5| Step: 3
Training loss: 2.118150472640991
Validation loss: 2.0516364189886276

Epoch: 5| Step: 4
Training loss: 2.208935260772705
Validation loss: 2.0170463477411578

Epoch: 5| Step: 5
Training loss: 1.6381347179412842
Validation loss: 2.005764733078659

Epoch: 5| Step: 6
Training loss: 2.3336730003356934
Validation loss: 2.0092105891114924

Epoch: 5| Step: 7
Training loss: 1.9392976760864258
Validation loss: 2.002563904690486

Epoch: 5| Step: 8
Training loss: 2.0345757007598877
Validation loss: 2.002516104329017

Epoch: 5| Step: 9
Training loss: 2.3258719444274902
Validation loss: 2.0015489196264618

Epoch: 5| Step: 10
Training loss: 2.8466529846191406
Validation loss: 2.0063358570939753

Epoch: 116| Step: 0
Training loss: 1.7873632907867432
Validation loss: 2.0303634674318376

Epoch: 5| Step: 1
Training loss: 1.6318225860595703
Validation loss: 2.0800566134914273

Epoch: 5| Step: 2
Training loss: 2.4399569034576416
Validation loss: 2.143431519949308

Epoch: 5| Step: 3
Training loss: 2.2353665828704834
Validation loss: 2.191694830053596

Epoch: 5| Step: 4
Training loss: 1.6014935970306396
Validation loss: 2.1764695529014833

Epoch: 5| Step: 5
Training loss: 1.2998197078704834
Validation loss: 2.1281975097553705

Epoch: 5| Step: 6
Training loss: 2.4044713973999023
Validation loss: 2.093713257902412

Epoch: 5| Step: 7
Training loss: 2.035737991333008
Validation loss: 2.0586062118571293

Epoch: 5| Step: 8
Training loss: 2.0541038513183594
Validation loss: 2.0472897996184645

Epoch: 5| Step: 9
Training loss: 1.7780160903930664
Validation loss: 2.0222980745377077

Epoch: 5| Step: 10
Training loss: 2.0961732864379883
Validation loss: 2.0204452186502437

Epoch: 117| Step: 0
Training loss: 1.4102728366851807
Validation loss: 1.9957278120902278

Epoch: 5| Step: 1
Training loss: 1.9660122394561768
Validation loss: 1.9836881122281473

Epoch: 5| Step: 2
Training loss: 2.0748701095581055
Validation loss: 1.9962652665312572

Epoch: 5| Step: 3
Training loss: 2.1367573738098145
Validation loss: 2.015169684604932

Epoch: 5| Step: 4
Training loss: 1.8235737085342407
Validation loss: 2.0511835390521633

Epoch: 5| Step: 5
Training loss: 1.7777044773101807
Validation loss: 2.0734030021134244

Epoch: 5| Step: 6
Training loss: 2.4588608741760254
Validation loss: 2.082665648511661

Epoch: 5| Step: 7
Training loss: 2.147137403488159
Validation loss: 2.0632701817379204

Epoch: 5| Step: 8
Training loss: 1.4780899286270142
Validation loss: 2.066491170596051

Epoch: 5| Step: 9
Training loss: 2.088383674621582
Validation loss: 2.032281715382812

Epoch: 5| Step: 10
Training loss: 2.2059547901153564
Validation loss: 2.0034993079400834

Epoch: 118| Step: 0
Training loss: 1.1458138227462769
Validation loss: 1.9973378437821583

Epoch: 5| Step: 1
Training loss: 1.766534447669983
Validation loss: 2.007857120165261

Epoch: 5| Step: 2
Training loss: 2.421689987182617
Validation loss: 1.9889657779406476

Epoch: 5| Step: 3
Training loss: 2.333723545074463
Validation loss: 2.0077266077841482

Epoch: 5| Step: 4
Training loss: 1.5171321630477905
Validation loss: 1.98514735826882

Epoch: 5| Step: 5
Training loss: 1.62155282497406
Validation loss: 1.9977128813343663

Epoch: 5| Step: 6
Training loss: 1.8734623193740845
Validation loss: 2.0350997191603466

Epoch: 5| Step: 7
Training loss: 2.19233775138855
Validation loss: 2.075185465556319

Epoch: 5| Step: 8
Training loss: 1.6169164180755615
Validation loss: 2.057292330649591

Epoch: 5| Step: 9
Training loss: 2.3206093311309814
Validation loss: 2.0539726800816034

Epoch: 5| Step: 10
Training loss: 2.3862740993499756
Validation loss: 2.0538705625841693

Epoch: 119| Step: 0
Training loss: 1.401167869567871
Validation loss: 2.053169401743079

Epoch: 5| Step: 1
Training loss: 2.309046745300293
Validation loss: 2.041635763260626

Epoch: 5| Step: 2
Training loss: 1.7151597738265991
Validation loss: 2.035688207995507

Epoch: 5| Step: 3
Training loss: 1.884530782699585
Validation loss: 2.0362253688996836

Epoch: 5| Step: 4
Training loss: 2.154576301574707
Validation loss: 2.037082015827138

Epoch: 5| Step: 5
Training loss: 1.806234359741211
Validation loss: 2.021301015730827

Epoch: 5| Step: 6
Training loss: 2.2650554180145264
Validation loss: 2.0398057865840133

Epoch: 5| Step: 7
Training loss: 1.8818861246109009
Validation loss: 2.063903690666281

Epoch: 5| Step: 8
Training loss: 1.6760345697402954
Validation loss: 2.045536328387517

Epoch: 5| Step: 9
Training loss: 1.7879164218902588
Validation loss: 2.063027016578182

Epoch: 5| Step: 10
Training loss: 2.3105642795562744
Validation loss: 2.0501847805515414

Epoch: 120| Step: 0
Training loss: 2.04248046875
Validation loss: 2.0662205167995986

Epoch: 5| Step: 1
Training loss: 2.199907064437866
Validation loss: 2.091621307916539

Epoch: 5| Step: 2
Training loss: 2.0800228118896484
Validation loss: 2.113957255117355

Epoch: 5| Step: 3
Training loss: 2.211867570877075
Validation loss: 2.089851417849141

Epoch: 5| Step: 4
Training loss: 2.095142126083374
Validation loss: 2.0726442093490274

Epoch: 5| Step: 5
Training loss: 1.8231563568115234
Validation loss: 2.0336959951667377

Epoch: 5| Step: 6
Training loss: 1.682421088218689
Validation loss: 1.9877832371701476

Epoch: 5| Step: 7
Training loss: 1.4847161769866943
Validation loss: 1.977750450052241

Epoch: 5| Step: 8
Training loss: 1.2944715023040771
Validation loss: 1.9768387425330378

Epoch: 5| Step: 9
Training loss: 1.7563711404800415
Validation loss: 1.97167408081793

Epoch: 5| Step: 10
Training loss: 2.2682905197143555
Validation loss: 1.9709170403019074

Epoch: 121| Step: 0
Training loss: 2.001024007797241
Validation loss: 1.9737714464946459

Epoch: 5| Step: 1
Training loss: 2.3379828929901123
Validation loss: 1.976772774932205

Epoch: 5| Step: 2
Training loss: 2.176788806915283
Validation loss: 1.9923660037338093

Epoch: 5| Step: 3
Training loss: 1.8203083276748657
Validation loss: 1.9993678433920747

Epoch: 5| Step: 4
Training loss: 1.9504932165145874
Validation loss: 2.0121795823497157

Epoch: 5| Step: 5
Training loss: 1.2849085330963135
Validation loss: 2.01581556822664

Epoch: 5| Step: 6
Training loss: 1.6634807586669922
Validation loss: 2.0378857453664145

Epoch: 5| Step: 7
Training loss: 2.0386955738067627
Validation loss: 2.051938056945801

Epoch: 5| Step: 8
Training loss: 2.137547016143799
Validation loss: 2.069303943264869

Epoch: 5| Step: 9
Training loss: 1.8936313390731812
Validation loss: 2.069431117785874

Epoch: 5| Step: 10
Training loss: 1.3445643186569214
Validation loss: 2.057608292948815

Epoch: 122| Step: 0
Training loss: 1.414746642112732
Validation loss: 2.044896443684896

Epoch: 5| Step: 1
Training loss: 1.6855049133300781
Validation loss: 2.0546333251460904

Epoch: 5| Step: 2
Training loss: 1.8826076984405518
Validation loss: 2.0422429294996363

Epoch: 5| Step: 3
Training loss: 2.0006020069122314
Validation loss: 2.0283788352884273

Epoch: 5| Step: 4
Training loss: 1.9936929941177368
Validation loss: 2.017637821935838

Epoch: 5| Step: 5
Training loss: 1.6681454181671143
Validation loss: 2.009668210501312

Epoch: 5| Step: 6
Training loss: 1.9492213726043701
Validation loss: 2.008276713791714

Epoch: 5| Step: 7
Training loss: 2.175574779510498
Validation loss: 1.9990623958649174

Epoch: 5| Step: 8
Training loss: 1.5252339839935303
Validation loss: 1.9927407823583132

Epoch: 5| Step: 9
Training loss: 2.2569544315338135
Validation loss: 2.0208317092669907

Epoch: 5| Step: 10
Training loss: 1.9790310859680176
Validation loss: 2.0322235989314255

Epoch: 123| Step: 0
Training loss: 2.079702138900757
Validation loss: 2.019327712315385

Epoch: 5| Step: 1
Training loss: 1.6983569860458374
Validation loss: 1.9975000786524948

Epoch: 5| Step: 2
Training loss: 2.5678324699401855
Validation loss: 1.9848792770857453

Epoch: 5| Step: 3
Training loss: 1.5263463258743286
Validation loss: 1.9889648857937063

Epoch: 5| Step: 4
Training loss: 1.6809616088867188
Validation loss: 1.964724011318658

Epoch: 5| Step: 5
Training loss: 1.9681265354156494
Validation loss: 1.9592898263726184

Epoch: 5| Step: 6
Training loss: 1.8537181615829468
Validation loss: 1.9512909894348474

Epoch: 5| Step: 7
Training loss: 1.3349602222442627
Validation loss: 1.9711907191943097

Epoch: 5| Step: 8
Training loss: 1.753679871559143
Validation loss: 1.987939634630757

Epoch: 5| Step: 9
Training loss: 1.7573814392089844
Validation loss: 1.9866550635266047

Epoch: 5| Step: 10
Training loss: 1.9821685552597046
Validation loss: 1.9975572734750726

Epoch: 124| Step: 0
Training loss: 1.618415117263794
Validation loss: 2.007801539154463

Epoch: 5| Step: 1
Training loss: 1.4137130975723267
Validation loss: 2.005187270461872

Epoch: 5| Step: 2
Training loss: 2.4612414836883545
Validation loss: 2.0157055495887675

Epoch: 5| Step: 3
Training loss: 1.1467680931091309
Validation loss: 2.0091158664354714

Epoch: 5| Step: 4
Training loss: 2.076122283935547
Validation loss: 2.0052827981210526

Epoch: 5| Step: 5
Training loss: 1.932776689529419
Validation loss: 2.005536158879598

Epoch: 5| Step: 6
Training loss: 2.3978238105773926
Validation loss: 2.0073630732874714

Epoch: 5| Step: 7
Training loss: 1.8502423763275146
Validation loss: 1.991663904600246

Epoch: 5| Step: 8
Training loss: 1.717327356338501
Validation loss: 2.007157778227201

Epoch: 5| Step: 9
Training loss: 1.4670493602752686
Validation loss: 2.006410833328001

Epoch: 5| Step: 10
Training loss: 1.9054738283157349
Validation loss: 2.0121997197469077

Epoch: 125| Step: 0
Training loss: 1.3107178211212158
Validation loss: 2.0051811689971597

Epoch: 5| Step: 1
Training loss: 2.5849366188049316
Validation loss: 2.010649851573411

Epoch: 5| Step: 2
Training loss: 2.132026433944702
Validation loss: 2.0041420023928405

Epoch: 5| Step: 3
Training loss: 1.645172357559204
Validation loss: 2.011546422076482

Epoch: 5| Step: 4
Training loss: 1.574971079826355
Validation loss: 2.0158415930245512

Epoch: 5| Step: 5
Training loss: 1.3967499732971191
Validation loss: 2.0136054741439

Epoch: 5| Step: 6
Training loss: 1.8377864360809326
Validation loss: 2.0085597474087953

Epoch: 5| Step: 7
Training loss: 2.0695853233337402
Validation loss: 2.0099019619726364

Epoch: 5| Step: 8
Training loss: 1.766696572303772
Validation loss: 1.9990759306056525

Epoch: 5| Step: 9
Training loss: 1.915269136428833
Validation loss: 2.0033168049268824

Epoch: 5| Step: 10
Training loss: 1.58805513381958
Validation loss: 1.9989784340704642

Epoch: 126| Step: 0
Training loss: 1.402625322341919
Validation loss: 2.0022919190827237

Epoch: 5| Step: 1
Training loss: 2.410235643386841
Validation loss: 2.008917462441229

Epoch: 5| Step: 2
Training loss: 2.0458178520202637
Validation loss: 2.0179509783303864

Epoch: 5| Step: 3
Training loss: 2.1570887565612793
Validation loss: 2.0323918391299505

Epoch: 5| Step: 4
Training loss: 2.2391810417175293
Validation loss: 2.0148270873613257

Epoch: 5| Step: 5
Training loss: 1.634060263633728
Validation loss: 2.0144799486283334

Epoch: 5| Step: 6
Training loss: 1.256818413734436
Validation loss: 2.0169021391099498

Epoch: 5| Step: 7
Training loss: 1.4721653461456299
Validation loss: 2.0118018542566607

Epoch: 5| Step: 8
Training loss: 1.8564960956573486
Validation loss: 2.020413168015019

Epoch: 5| Step: 9
Training loss: 1.4883378744125366
Validation loss: 2.0299647123582902

Epoch: 5| Step: 10
Training loss: 1.9217323064804077
Validation loss: 2.007207547464678

Epoch: 127| Step: 0
Training loss: 2.2861483097076416
Validation loss: 2.006815118174399

Epoch: 5| Step: 1
Training loss: 1.8959071636199951
Validation loss: 1.9985027454232658

Epoch: 5| Step: 2
Training loss: 1.651709794998169
Validation loss: 1.996701794285928

Epoch: 5| Step: 3
Training loss: 1.5007416009902954
Validation loss: 1.9887150897774646

Epoch: 5| Step: 4
Training loss: 2.0334534645080566
Validation loss: 2.005340042934623

Epoch: 5| Step: 5
Training loss: 1.5250837802886963
Validation loss: 2.0039333117905485

Epoch: 5| Step: 6
Training loss: 2.292442798614502
Validation loss: 2.0102222965609644

Epoch: 5| Step: 7
Training loss: 2.1148836612701416
Validation loss: 2.0220266747218307

Epoch: 5| Step: 8
Training loss: 1.0512051582336426
Validation loss: 2.0598132200138544

Epoch: 5| Step: 9
Training loss: 1.454929232597351
Validation loss: 2.097369937486546

Epoch: 5| Step: 10
Training loss: 2.167496681213379
Validation loss: 2.111660034425797

Epoch: 128| Step: 0
Training loss: 2.203749179840088
Validation loss: 2.1074896666311447

Epoch: 5| Step: 1
Training loss: 2.275311231613159
Validation loss: 2.033549920205147

Epoch: 5| Step: 2
Training loss: 1.4501707553863525
Validation loss: 1.975930868938405

Epoch: 5| Step: 3
Training loss: 1.9764328002929688
Validation loss: 1.9338483784788398

Epoch: 5| Step: 4
Training loss: 1.4426835775375366
Validation loss: 1.9130604574757237

Epoch: 5| Step: 5
Training loss: 1.469130039215088
Validation loss: 1.9149729705625964

Epoch: 5| Step: 6
Training loss: 1.9491908550262451
Validation loss: 1.928063815639865

Epoch: 5| Step: 7
Training loss: 1.6144654750823975
Validation loss: 1.9446624055985482

Epoch: 5| Step: 8
Training loss: 2.317121982574463
Validation loss: 1.9460414583965013

Epoch: 5| Step: 9
Training loss: 1.6876065731048584
Validation loss: 1.948194687084485

Epoch: 5| Step: 10
Training loss: 1.6571890115737915
Validation loss: 1.9581800673597602

Epoch: 129| Step: 0
Training loss: 2.424354076385498
Validation loss: 1.9711975782148299

Epoch: 5| Step: 1
Training loss: 1.7648403644561768
Validation loss: 1.9824250103324972

Epoch: 5| Step: 2
Training loss: 2.2646021842956543
Validation loss: 1.9965001472862818

Epoch: 5| Step: 3
Training loss: 1.8289817571640015
Validation loss: 1.9982456084220641

Epoch: 5| Step: 4
Training loss: 1.8706114292144775
Validation loss: 2.012506959258869

Epoch: 5| Step: 5
Training loss: 1.2238024473190308
Validation loss: 1.9913427611832977

Epoch: 5| Step: 6
Training loss: 1.6683505773544312
Validation loss: 1.9694796685249574

Epoch: 5| Step: 7
Training loss: 1.3817049264907837
Validation loss: 1.9737068107051234

Epoch: 5| Step: 8
Training loss: 1.896066665649414
Validation loss: 1.9734866426837059

Epoch: 5| Step: 9
Training loss: 1.2092008590698242
Validation loss: 1.965174162259666

Epoch: 5| Step: 10
Training loss: 2.0479841232299805
Validation loss: 1.9495562814897107

Epoch: 130| Step: 0
Training loss: 1.8185447454452515
Validation loss: 1.9464799806635866

Epoch: 5| Step: 1
Training loss: 1.7546417713165283
Validation loss: 1.947606332840458

Epoch: 5| Step: 2
Training loss: 1.7373230457305908
Validation loss: 1.9552639556187454

Epoch: 5| Step: 3
Training loss: 1.833939790725708
Validation loss: 1.9757302640586771

Epoch: 5| Step: 4
Training loss: 0.9948416948318481
Validation loss: 1.9848893637298255

Epoch: 5| Step: 5
Training loss: 2.2170703411102295
Validation loss: 1.99410371370213

Epoch: 5| Step: 6
Training loss: 2.402433395385742
Validation loss: 2.0347867332479006

Epoch: 5| Step: 7
Training loss: 1.6317068338394165
Validation loss: 2.0348488002695064

Epoch: 5| Step: 8
Training loss: 1.8498709201812744
Validation loss: 2.048554148725284

Epoch: 5| Step: 9
Training loss: 1.914671540260315
Validation loss: 2.072853554961502

Epoch: 5| Step: 10
Training loss: 1.516324758529663
Validation loss: 2.040630518749196

Epoch: 131| Step: 0
Training loss: 2.146144390106201
Validation loss: 2.038901643086505

Epoch: 5| Step: 1
Training loss: 2.1108734607696533
Validation loss: 2.0171284444870485

Epoch: 5| Step: 2
Training loss: 1.7390193939208984
Validation loss: 2.0168672864155104

Epoch: 5| Step: 3
Training loss: 1.1825971603393555
Validation loss: 2.0066000287250807

Epoch: 5| Step: 4
Training loss: 2.057525634765625
Validation loss: 1.9887357347755021

Epoch: 5| Step: 5
Training loss: 2.0545787811279297
Validation loss: 1.9926760453049854

Epoch: 5| Step: 6
Training loss: 1.6666486263275146
Validation loss: 1.984662099551129

Epoch: 5| Step: 7
Training loss: 1.8070533275604248
Validation loss: 1.9722320418204031

Epoch: 5| Step: 8
Training loss: 1.6698474884033203
Validation loss: 1.9621137508782007

Epoch: 5| Step: 9
Training loss: 1.2810108661651611
Validation loss: 1.956049451264002

Epoch: 5| Step: 10
Training loss: 1.6828993558883667
Validation loss: 1.955407129820957

Epoch: 132| Step: 0
Training loss: 1.3772557973861694
Validation loss: 1.9269341038119407

Epoch: 5| Step: 1
Training loss: 1.3681724071502686
Validation loss: 1.9320207706061743

Epoch: 5| Step: 2
Training loss: 1.9604930877685547
Validation loss: 1.937028447786967

Epoch: 5| Step: 3
Training loss: 1.8632419109344482
Validation loss: 1.9229126873836722

Epoch: 5| Step: 4
Training loss: 1.429124116897583
Validation loss: 1.9392034815203758

Epoch: 5| Step: 5
Training loss: 2.013317584991455
Validation loss: 1.9338893018743044

Epoch: 5| Step: 6
Training loss: 1.7748336791992188
Validation loss: 1.9299604777366883

Epoch: 5| Step: 7
Training loss: 1.9049720764160156
Validation loss: 1.9418564534956408

Epoch: 5| Step: 8
Training loss: 1.892817735671997
Validation loss: 1.9313892625993299

Epoch: 5| Step: 9
Training loss: 1.5503700971603394
Validation loss: 1.9434110246678835

Epoch: 5| Step: 10
Training loss: 1.9067176580429077
Validation loss: 1.9553786798190045

Epoch: 133| Step: 0
Training loss: 1.8610305786132812
Validation loss: 1.9580168019058883

Epoch: 5| Step: 1
Training loss: 1.9901434183120728
Validation loss: 1.9551561417118195

Epoch: 5| Step: 2
Training loss: 1.846806526184082
Validation loss: 1.9463761544996692

Epoch: 5| Step: 3
Training loss: 1.6652443408966064
Validation loss: 1.9384849507321593

Epoch: 5| Step: 4
Training loss: 1.5547164678573608
Validation loss: 1.9341930432986187

Epoch: 5| Step: 5
Training loss: 1.6092700958251953
Validation loss: 1.936092274163359

Epoch: 5| Step: 6
Training loss: 1.270806908607483
Validation loss: 1.9333349350960023

Epoch: 5| Step: 7
Training loss: 1.5640294551849365
Validation loss: 1.9486975362223964

Epoch: 5| Step: 8
Training loss: 2.31795334815979
Validation loss: 1.9808545522792365

Epoch: 5| Step: 9
Training loss: 0.9530614614486694
Validation loss: 1.979034718646798

Epoch: 5| Step: 10
Training loss: 2.385124444961548
Validation loss: 2.0060448838818457

Epoch: 134| Step: 0
Training loss: 1.9415132999420166
Validation loss: 2.0313245929697508

Epoch: 5| Step: 1
Training loss: 1.7801334857940674
Validation loss: 2.025847590097817

Epoch: 5| Step: 2
Training loss: 1.851007103919983
Validation loss: 2.024497451320771

Epoch: 5| Step: 3
Training loss: 1.2805278301239014
Validation loss: 2.013910073106007

Epoch: 5| Step: 4
Training loss: 1.9801950454711914
Validation loss: 2.0148210294785036

Epoch: 5| Step: 5
Training loss: 1.8515558242797852
Validation loss: 1.991466611944219

Epoch: 5| Step: 6
Training loss: 1.4835827350616455
Validation loss: 1.9652622489519016

Epoch: 5| Step: 7
Training loss: 1.6188099384307861
Validation loss: 1.9582421677086943

Epoch: 5| Step: 8
Training loss: 1.1255241632461548
Validation loss: 1.9438131099106164

Epoch: 5| Step: 9
Training loss: 2.1501212120056152
Validation loss: 1.9448479298622376

Epoch: 5| Step: 10
Training loss: 1.8818567991256714
Validation loss: 1.9497039394993936

Epoch: 135| Step: 0
Training loss: 2.337451934814453
Validation loss: 1.9492377670862342

Epoch: 5| Step: 1
Training loss: 1.8071506023406982
Validation loss: 1.9512378528553953

Epoch: 5| Step: 2
Training loss: 1.7519947290420532
Validation loss: 1.9482949472242785

Epoch: 5| Step: 3
Training loss: 1.428821325302124
Validation loss: 1.945915916914581

Epoch: 5| Step: 4
Training loss: 1.1394487619400024
Validation loss: 1.954485188248337

Epoch: 5| Step: 5
Training loss: 1.490928053855896
Validation loss: 1.9614284499999015

Epoch: 5| Step: 6
Training loss: 1.9185394048690796
Validation loss: 1.9707854691372122

Epoch: 5| Step: 7
Training loss: 1.750806212425232
Validation loss: 1.960901858986065

Epoch: 5| Step: 8
Training loss: 1.578136682510376
Validation loss: 1.9637565074428436

Epoch: 5| Step: 9
Training loss: 1.5746991634368896
Validation loss: 1.9561415397992699

Epoch: 5| Step: 10
Training loss: 1.894618034362793
Validation loss: 1.9501048313674105

Epoch: 136| Step: 0
Training loss: 1.5960148572921753
Validation loss: 1.9601594914672196

Epoch: 5| Step: 1
Training loss: 1.3031351566314697
Validation loss: 1.9463113636098883

Epoch: 5| Step: 2
Training loss: 1.464537262916565
Validation loss: 1.9453976077418174

Epoch: 5| Step: 3
Training loss: 1.6832647323608398
Validation loss: 1.9650413015837311

Epoch: 5| Step: 4
Training loss: 1.4919230937957764
Validation loss: 1.979967978692824

Epoch: 5| Step: 5
Training loss: 1.639095664024353
Validation loss: 2.0033358066312728

Epoch: 5| Step: 6
Training loss: 1.6082935333251953
Validation loss: 2.030206416242866

Epoch: 5| Step: 7
Training loss: 1.8127431869506836
Validation loss: 2.022370098739542

Epoch: 5| Step: 8
Training loss: 2.2258262634277344
Validation loss: 2.0286108575841433

Epoch: 5| Step: 9
Training loss: 2.2129578590393066
Validation loss: 2.023614269430919

Epoch: 5| Step: 10
Training loss: 1.7139099836349487
Validation loss: 1.990265837279699

Epoch: 137| Step: 0
Training loss: 1.6071407794952393
Validation loss: 1.951431159050234

Epoch: 5| Step: 1
Training loss: 1.9235073328018188
Validation loss: 1.9427264057179934

Epoch: 5| Step: 2
Training loss: 2.2335543632507324
Validation loss: 1.9313709441051687

Epoch: 5| Step: 3
Training loss: 0.9960182905197144
Validation loss: 1.9188621172340967

Epoch: 5| Step: 4
Training loss: 2.0723633766174316
Validation loss: 1.9324877005751415

Epoch: 5| Step: 5
Training loss: 1.957720398902893
Validation loss: 1.946295258819416

Epoch: 5| Step: 6
Training loss: 1.0857932567596436
Validation loss: 1.9433850229427378

Epoch: 5| Step: 7
Training loss: 1.1820955276489258
Validation loss: 1.9485131399605864

Epoch: 5| Step: 8
Training loss: 2.0762197971343994
Validation loss: 1.9447816007880754

Epoch: 5| Step: 9
Training loss: 1.8568146228790283
Validation loss: 1.9447404466649538

Epoch: 5| Step: 10
Training loss: 1.6063528060913086
Validation loss: 1.9591594473008187

Epoch: 138| Step: 0
Training loss: 2.1886019706726074
Validation loss: 1.9510074174532326

Epoch: 5| Step: 1
Training loss: 1.7251907587051392
Validation loss: 1.954876934328387

Epoch: 5| Step: 2
Training loss: 1.9491794109344482
Validation loss: 1.958131992688743

Epoch: 5| Step: 3
Training loss: 1.8952624797821045
Validation loss: 1.951193960764075

Epoch: 5| Step: 4
Training loss: 1.4200749397277832
Validation loss: 1.9751575890407767

Epoch: 5| Step: 5
Training loss: 1.7298576831817627
Validation loss: 1.9906580512241652

Epoch: 5| Step: 6
Training loss: 1.5147606134414673
Validation loss: 1.995194378719535

Epoch: 5| Step: 7
Training loss: 1.5238306522369385
Validation loss: 1.9843684921982467

Epoch: 5| Step: 8
Training loss: 1.3501704931259155
Validation loss: 1.97135107363424

Epoch: 5| Step: 9
Training loss: 1.1361457109451294
Validation loss: 1.9418845202333184

Epoch: 5| Step: 10
Training loss: 1.9928027391433716
Validation loss: 1.9335891508287

Epoch: 139| Step: 0
Training loss: 2.400862455368042
Validation loss: 1.9286196642024542

Epoch: 5| Step: 1
Training loss: 1.108273983001709
Validation loss: 1.9259292182102

Epoch: 5| Step: 2
Training loss: 1.8616220951080322
Validation loss: 1.9167392715331046

Epoch: 5| Step: 3
Training loss: 1.7757278680801392
Validation loss: 1.9306311761179278

Epoch: 5| Step: 4
Training loss: 1.3933327198028564
Validation loss: 1.9128758638135848

Epoch: 5| Step: 5
Training loss: 1.2857983112335205
Validation loss: 1.921078335854315

Epoch: 5| Step: 6
Training loss: 1.1314254999160767
Validation loss: 1.9226609660733132

Epoch: 5| Step: 7
Training loss: 1.2974178791046143
Validation loss: 1.9202432709355508

Epoch: 5| Step: 8
Training loss: 1.9388525485992432
Validation loss: 1.9441792734207646

Epoch: 5| Step: 9
Training loss: 1.726253867149353
Validation loss: 1.9571416326748428

Epoch: 5| Step: 10
Training loss: 2.3293044567108154
Validation loss: 1.9929847050738592

Epoch: 140| Step: 0
Training loss: 1.5241336822509766
Validation loss: 1.9753602268875285

Epoch: 5| Step: 1
Training loss: 1.91583251953125
Validation loss: 1.9582438097205213

Epoch: 5| Step: 2
Training loss: 1.901766061782837
Validation loss: 1.9448875586191814

Epoch: 5| Step: 3
Training loss: 1.446500539779663
Validation loss: 1.948174948333412

Epoch: 5| Step: 4
Training loss: 1.6123777627944946
Validation loss: 1.9275441503012052

Epoch: 5| Step: 5
Training loss: 1.234729290008545
Validation loss: 1.941515504672963

Epoch: 5| Step: 6
Training loss: 1.4912071228027344
Validation loss: 1.9517988120355914

Epoch: 5| Step: 7
Training loss: 1.5270413160324097
Validation loss: 1.9278501746475056

Epoch: 5| Step: 8
Training loss: 2.1742825508117676
Validation loss: 1.9330812551641976

Epoch: 5| Step: 9
Training loss: 1.8649177551269531
Validation loss: 1.937206901529784

Epoch: 5| Step: 10
Training loss: 1.6600953340530396
Validation loss: 1.9540903209358134

Epoch: 141| Step: 0
Training loss: 1.1219366788864136
Validation loss: 1.9632324070058844

Epoch: 5| Step: 1
Training loss: 1.4335353374481201
Validation loss: 1.984652591008012

Epoch: 5| Step: 2
Training loss: 1.9444046020507812
Validation loss: 1.9692411192001835

Epoch: 5| Step: 3
Training loss: 2.26667857170105
Validation loss: 1.9516798937192528

Epoch: 5| Step: 4
Training loss: 1.4163148403167725
Validation loss: 1.9444502874087262

Epoch: 5| Step: 5
Training loss: 2.0274813175201416
Validation loss: 1.9322874699869463

Epoch: 5| Step: 6
Training loss: 1.772304892539978
Validation loss: 1.9101653945061468

Epoch: 5| Step: 7
Training loss: 2.05001163482666
Validation loss: 1.902174767627511

Epoch: 5| Step: 8
Training loss: 1.0179320573806763
Validation loss: 1.8888042408932921

Epoch: 5| Step: 9
Training loss: 1.7734047174453735
Validation loss: 1.9085548770043157

Epoch: 5| Step: 10
Training loss: 1.4882107973098755
Validation loss: 1.9329904561401696

Epoch: 142| Step: 0
Training loss: 2.0816705226898193
Validation loss: 1.9413660149420462

Epoch: 5| Step: 1
Training loss: 1.6583057641983032
Validation loss: 1.9441811961512412

Epoch: 5| Step: 2
Training loss: 1.6351032257080078
Validation loss: 1.9649410965622112

Epoch: 5| Step: 3
Training loss: 1.6388708353042603
Validation loss: 1.9678894781297254

Epoch: 5| Step: 4
Training loss: 1.9824203252792358
Validation loss: 1.9711807017685266

Epoch: 5| Step: 5
Training loss: 1.5417721271514893
Validation loss: 1.9736063121467509

Epoch: 5| Step: 6
Training loss: 1.5587079524993896
Validation loss: 1.9603993379941551

Epoch: 5| Step: 7
Training loss: 1.3016005754470825
Validation loss: 1.9386794233834872

Epoch: 5| Step: 8
Training loss: 1.84079110622406
Validation loss: 1.9342010662119875

Epoch: 5| Step: 9
Training loss: 1.5529330968856812
Validation loss: 1.935409317734421

Epoch: 5| Step: 10
Training loss: 1.4745497703552246
Validation loss: 1.9431016496432725

Epoch: 143| Step: 0
Training loss: 2.172140598297119
Validation loss: 1.934909325773998

Epoch: 5| Step: 1
Training loss: 1.9136152267456055
Validation loss: 1.9410844413183068

Epoch: 5| Step: 2
Training loss: 1.5059489011764526
Validation loss: 1.9418416574437132

Epoch: 5| Step: 3
Training loss: 1.5325696468353271
Validation loss: 1.935233513514201

Epoch: 5| Step: 4
Training loss: 1.7712152004241943
Validation loss: 1.9309940184316328

Epoch: 5| Step: 5
Training loss: 1.3313440084457397
Validation loss: 1.9547757538416053

Epoch: 5| Step: 6
Training loss: 1.3956044912338257
Validation loss: 1.9905379408149309

Epoch: 5| Step: 7
Training loss: 1.2909497022628784
Validation loss: 2.0017850924563665

Epoch: 5| Step: 8
Training loss: 1.5777039527893066
Validation loss: 2.004859916625484

Epoch: 5| Step: 9
Training loss: 1.9013255834579468
Validation loss: 1.9831219129664923

Epoch: 5| Step: 10
Training loss: 1.4790738821029663
Validation loss: 1.9829763391966462

Epoch: 144| Step: 0
Training loss: 1.4642484188079834
Validation loss: 1.96881091466514

Epoch: 5| Step: 1
Training loss: 1.4222500324249268
Validation loss: 1.9761819326749412

Epoch: 5| Step: 2
Training loss: 1.7719364166259766
Validation loss: 1.9464212515020882

Epoch: 5| Step: 3
Training loss: 2.0715906620025635
Validation loss: 1.928050712872577

Epoch: 5| Step: 4
Training loss: 1.5977634191513062
Validation loss: 1.9066848331882107

Epoch: 5| Step: 5
Training loss: 2.1723711490631104
Validation loss: 1.8922227121168567

Epoch: 5| Step: 6
Training loss: 1.1162803173065186
Validation loss: 1.8929765865366945

Epoch: 5| Step: 7
Training loss: 1.6074249744415283
Validation loss: 1.8966867282826414

Epoch: 5| Step: 8
Training loss: 1.4180986881256104
Validation loss: 1.9000851415818738

Epoch: 5| Step: 9
Training loss: 1.5532604455947876
Validation loss: 1.9275394537115609

Epoch: 5| Step: 10
Training loss: 2.236940383911133
Validation loss: 1.9534296938168105

Epoch: 145| Step: 0
Training loss: 2.66713285446167
Validation loss: 1.969659379733506

Epoch: 5| Step: 1
Training loss: 1.8794772624969482
Validation loss: 1.9964863125995924

Epoch: 5| Step: 2
Training loss: 1.4170736074447632
Validation loss: 1.999616410142632

Epoch: 5| Step: 3
Training loss: 1.320834755897522
Validation loss: 2.022369407838391

Epoch: 5| Step: 4
Training loss: 1.7926746606826782
Validation loss: 2.01444007760735

Epoch: 5| Step: 5
Training loss: 1.5284632444381714
Validation loss: 2.0058794816335044

Epoch: 5| Step: 6
Training loss: 1.9329826831817627
Validation loss: 1.977628525867257

Epoch: 5| Step: 7
Training loss: 1.291759967803955
Validation loss: 1.9627437847916798

Epoch: 5| Step: 8
Training loss: 0.9137032628059387
Validation loss: 1.9343875838864235

Epoch: 5| Step: 9
Training loss: 1.3130100965499878
Validation loss: 1.9393217999448058

Epoch: 5| Step: 10
Training loss: 2.079150676727295
Validation loss: 1.9168375897151169

Epoch: 146| Step: 0
Training loss: 1.5958918333053589
Validation loss: 1.9275239731675835

Epoch: 5| Step: 1
Training loss: 1.77427077293396
Validation loss: 1.929886894841348

Epoch: 5| Step: 2
Training loss: 1.568721055984497
Validation loss: 1.9420186114567581

Epoch: 5| Step: 3
Training loss: 1.4520366191864014
Validation loss: 1.9351954716508106

Epoch: 5| Step: 4
Training loss: 1.9192969799041748
Validation loss: 1.9284105595721994

Epoch: 5| Step: 5
Training loss: 2.09340763092041
Validation loss: 1.930595818386283

Epoch: 5| Step: 6
Training loss: 1.5512176752090454
Validation loss: 1.9225410312734625

Epoch: 5| Step: 7
Training loss: 1.5390955209732056
Validation loss: 1.9159129845198763

Epoch: 5| Step: 8
Training loss: 1.5227488279342651
Validation loss: 1.9398592031130226

Epoch: 5| Step: 9
Training loss: 1.4924299716949463
Validation loss: 1.9283847860110703

Epoch: 5| Step: 10
Training loss: 1.2001233100891113
Validation loss: 1.9327281111030168

Epoch: 147| Step: 0
Training loss: 1.9268594980239868
Validation loss: 1.9448877855013775

Epoch: 5| Step: 1
Training loss: 1.376662015914917
Validation loss: 1.9523608812721827

Epoch: 5| Step: 2
Training loss: 2.152139902114868
Validation loss: 1.9426907723949802

Epoch: 5| Step: 3
Training loss: 1.34149169921875
Validation loss: 1.9567954412070654

Epoch: 5| Step: 4
Training loss: 1.8435970544815063
Validation loss: 1.9580011393434258

Epoch: 5| Step: 5
Training loss: 0.9764138460159302
Validation loss: 1.9533573824872252

Epoch: 5| Step: 6
Training loss: 1.8367853164672852
Validation loss: 1.9547364352851786

Epoch: 5| Step: 7
Training loss: 1.5973985195159912
Validation loss: 1.9310468153287006

Epoch: 5| Step: 8
Training loss: 1.3021856546401978
Validation loss: 1.9460827458289363

Epoch: 5| Step: 9
Training loss: 1.7048776149749756
Validation loss: 1.9265759721879037

Epoch: 5| Step: 10
Training loss: 1.4163483381271362
Validation loss: 1.9276944796244304

Epoch: 148| Step: 0
Training loss: 1.979042410850525
Validation loss: 1.9222823112241683

Epoch: 5| Step: 1
Training loss: 1.6336911916732788
Validation loss: 1.9185613765511462

Epoch: 5| Step: 2
Training loss: 1.369339942932129
Validation loss: 1.9273641468376241

Epoch: 5| Step: 3
Training loss: 1.4957630634307861
Validation loss: 1.9331845057907926

Epoch: 5| Step: 4
Training loss: 0.946094810962677
Validation loss: 1.9493287801742554

Epoch: 5| Step: 5
Training loss: 1.6666456460952759
Validation loss: 1.959651154856528

Epoch: 5| Step: 6
Training loss: 1.7079641819000244
Validation loss: 1.9567376644380632

Epoch: 5| Step: 7
Training loss: 1.4168236255645752
Validation loss: 1.946812415635714

Epoch: 5| Step: 8
Training loss: 1.6404578685760498
Validation loss: 1.9705192619754421

Epoch: 5| Step: 9
Training loss: 1.6658143997192383
Validation loss: 1.9600896066234959

Epoch: 5| Step: 10
Training loss: 1.9852055311203003
Validation loss: 1.9703725845583024

Epoch: 149| Step: 0
Training loss: 1.4549287557601929
Validation loss: 1.9675799492866761

Epoch: 5| Step: 1
Training loss: 1.3872194290161133
Validation loss: 1.9496685240858345

Epoch: 5| Step: 2
Training loss: 1.9778594970703125
Validation loss: 1.94565837870362

Epoch: 5| Step: 3
Training loss: 1.0369832515716553
Validation loss: 1.9404012862072195

Epoch: 5| Step: 4
Training loss: 1.528420329093933
Validation loss: 1.9442053200096212

Epoch: 5| Step: 5
Training loss: 1.9878616333007812
Validation loss: 1.9421468383522444

Epoch: 5| Step: 6
Training loss: 1.7488353252410889
Validation loss: 1.9661164822116974

Epoch: 5| Step: 7
Training loss: 1.173254370689392
Validation loss: 1.9747557896439747

Epoch: 5| Step: 8
Training loss: 1.557163953781128
Validation loss: 1.9979242176137946

Epoch: 5| Step: 9
Training loss: 1.8665882349014282
Validation loss: 1.9905636643850675

Epoch: 5| Step: 10
Training loss: 1.724622130393982
Validation loss: 1.963855033279747

Epoch: 150| Step: 0
Training loss: 2.1161231994628906
Validation loss: 1.9472781894027547

Epoch: 5| Step: 1
Training loss: 1.8043928146362305
Validation loss: 1.9448711897737236

Epoch: 5| Step: 2
Training loss: 1.3766953945159912
Validation loss: 1.917969702392496

Epoch: 5| Step: 3
Training loss: 1.5839626789093018
Validation loss: 1.8877816969348538

Epoch: 5| Step: 4
Training loss: 1.5867865085601807
Validation loss: 1.9012851125450545

Epoch: 5| Step: 5
Training loss: 1.4712135791778564
Validation loss: 1.8980886423459618

Epoch: 5| Step: 6
Training loss: 1.4231395721435547
Validation loss: 1.9127727106053343

Epoch: 5| Step: 7
Training loss: 1.3258864879608154
Validation loss: 1.9347426288871354

Epoch: 5| Step: 8
Training loss: 1.4751198291778564
Validation loss: 1.9392055901147986

Epoch: 5| Step: 9
Training loss: 1.4796867370605469
Validation loss: 1.9556896455826298

Epoch: 5| Step: 10
Training loss: 1.554754376411438
Validation loss: 1.9805121088540683

Epoch: 151| Step: 0
Training loss: 1.8770949840545654
Validation loss: 1.9956298438451623

Epoch: 5| Step: 1
Training loss: 1.6309829950332642
Validation loss: 1.9937043164366035

Epoch: 5| Step: 2
Training loss: 1.5073140859603882
Validation loss: 1.9737107164116316

Epoch: 5| Step: 3
Training loss: 1.2152917385101318
Validation loss: 1.9615947790043329

Epoch: 5| Step: 4
Training loss: 1.9866092205047607
Validation loss: 1.9455125460060694

Epoch: 5| Step: 5
Training loss: 1.5748440027236938
Validation loss: 1.9527700408812492

Epoch: 5| Step: 6
Training loss: 1.4647719860076904
Validation loss: 1.9598484295670704

Epoch: 5| Step: 7
Training loss: 0.9736863970756531
Validation loss: 1.9790439656985703

Epoch: 5| Step: 8
Training loss: 1.7126224040985107
Validation loss: 1.967487944069729

Epoch: 5| Step: 9
Training loss: 1.5318769216537476
Validation loss: 1.9808411905842442

Epoch: 5| Step: 10
Training loss: 1.8575737476348877
Validation loss: 1.9827723580022012

Epoch: 152| Step: 0
Training loss: 1.5083587169647217
Validation loss: 1.957058229754048

Epoch: 5| Step: 1
Training loss: 1.9917762279510498
Validation loss: 1.9540213461845153

Epoch: 5| Step: 2
Training loss: 0.7525831460952759
Validation loss: 1.953591783841451

Epoch: 5| Step: 3
Training loss: 1.5331850051879883
Validation loss: 1.9641692279487528

Epoch: 5| Step: 4
Training loss: 1.4721946716308594
Validation loss: 1.9482096267002884

Epoch: 5| Step: 5
Training loss: 1.3973662853240967
Validation loss: 1.9144059047904065

Epoch: 5| Step: 6
Training loss: 1.9166066646575928
Validation loss: 1.8977643597510554

Epoch: 5| Step: 7
Training loss: 2.0878589153289795
Validation loss: 1.8868124177378993

Epoch: 5| Step: 8
Training loss: 1.6036779880523682
Validation loss: 1.8700786072720763

Epoch: 5| Step: 9
Training loss: 1.739458441734314
Validation loss: 1.8606273153776764

Epoch: 5| Step: 10
Training loss: 1.1644645929336548
Validation loss: 1.8909312781467233

Epoch: 153| Step: 0
Training loss: 2.2379701137542725
Validation loss: 1.9126318039432648

Epoch: 5| Step: 1
Training loss: 1.4934524297714233
Validation loss: 1.9533451372577297

Epoch: 5| Step: 2
Training loss: 2.0815536975860596
Validation loss: 1.942001619646626

Epoch: 5| Step: 3
Training loss: 0.9791361689567566
Validation loss: 1.9146563109531198

Epoch: 5| Step: 4
Training loss: 1.2320151329040527
Validation loss: 1.9430441279565134

Epoch: 5| Step: 5
Training loss: 1.4697539806365967
Validation loss: 1.9266954391233382

Epoch: 5| Step: 6
Training loss: 1.6056277751922607
Validation loss: 1.9150151744965584

Epoch: 5| Step: 7
Training loss: 1.4807575941085815
Validation loss: 1.9282693324550506

Epoch: 5| Step: 8
Training loss: 0.7979747653007507
Validation loss: 1.9628486479482343

Epoch: 5| Step: 9
Training loss: 1.707909345626831
Validation loss: 1.9654889811751663

Epoch: 5| Step: 10
Training loss: 1.8474626541137695
Validation loss: 2.0033998899562384

Epoch: 154| Step: 0
Training loss: 1.3996405601501465
Validation loss: 2.0203970991155153

Epoch: 5| Step: 1
Training loss: 1.758933663368225
Validation loss: 2.0610041567074355

Epoch: 5| Step: 2
Training loss: 1.7805083990097046
Validation loss: 2.021855115890503

Epoch: 5| Step: 3
Training loss: 1.4742364883422852
Validation loss: 1.964414369675421

Epoch: 5| Step: 4
Training loss: 1.2393356561660767
Validation loss: 1.9158858919656405

Epoch: 5| Step: 5
Training loss: 1.235695481300354
Validation loss: 1.9001501580720306

Epoch: 5| Step: 6
Training loss: 1.1796743869781494
Validation loss: 1.8921873620761338

Epoch: 5| Step: 7
Training loss: 1.6420097351074219
Validation loss: 1.9076196134731334

Epoch: 5| Step: 8
Training loss: 1.9104974269866943
Validation loss: 1.8805069897764473

Epoch: 5| Step: 9
Training loss: 1.7384965419769287
Validation loss: 1.8801256110591273

Epoch: 5| Step: 10
Training loss: 1.77399480342865
Validation loss: 1.8785634130559943

Epoch: 155| Step: 0
Training loss: 1.1329972743988037
Validation loss: 1.8853372463615992

Epoch: 5| Step: 1
Training loss: 2.055514097213745
Validation loss: 1.8770958198014127

Epoch: 5| Step: 2
Training loss: 1.3423094749450684
Validation loss: 1.8773277908243158

Epoch: 5| Step: 3
Training loss: 1.0404280424118042
Validation loss: 1.8994201306373841

Epoch: 5| Step: 4
Training loss: 1.9275968074798584
Validation loss: 1.8974546104349115

Epoch: 5| Step: 5
Training loss: 1.7436155080795288
Validation loss: 1.9163919764180337

Epoch: 5| Step: 6
Training loss: 1.5822099447250366
Validation loss: 1.9243566630988993

Epoch: 5| Step: 7
Training loss: 1.998040795326233
Validation loss: 1.966763747635708

Epoch: 5| Step: 8
Training loss: 1.3010711669921875
Validation loss: 2.013996216558641

Epoch: 5| Step: 9
Training loss: 1.131756067276001
Validation loss: 2.009932739760286

Epoch: 5| Step: 10
Training loss: 1.4060125350952148
Validation loss: 1.9960014717553252

Epoch: 156| Step: 0
Training loss: 1.1717417240142822
Validation loss: 1.9308162645627094

Epoch: 5| Step: 1
Training loss: 1.1914416551589966
Validation loss: 1.9187124262573898

Epoch: 5| Step: 2
Training loss: 1.2211883068084717
Validation loss: 1.899278731756313

Epoch: 5| Step: 3
Training loss: 2.279944896697998
Validation loss: 1.8678438945483136

Epoch: 5| Step: 4
Training loss: 1.029309630393982
Validation loss: 1.878830627728534

Epoch: 5| Step: 5
Training loss: 1.9352293014526367
Validation loss: 1.8790735365242086

Epoch: 5| Step: 6
Training loss: 1.6431901454925537
Validation loss: 1.8896580255159767

Epoch: 5| Step: 7
Training loss: 2.190596342086792
Validation loss: 1.9061094714749245

Epoch: 5| Step: 8
Training loss: 1.4688491821289062
Validation loss: 1.9357704270270564

Epoch: 5| Step: 9
Training loss: 1.2479690313339233
Validation loss: 1.9532805514591995

Epoch: 5| Step: 10
Training loss: 1.8815561532974243
Validation loss: 1.9631589689562399

Epoch: 157| Step: 0
Training loss: 1.852365255355835
Validation loss: 1.980638478391914

Epoch: 5| Step: 1
Training loss: 1.2811965942382812
Validation loss: 2.0259103890388244

Epoch: 5| Step: 2
Training loss: 2.0687501430511475
Validation loss: 2.03442197204918

Epoch: 5| Step: 3
Training loss: 1.9268500804901123
Validation loss: 2.043960258524905

Epoch: 5| Step: 4
Training loss: 0.9729601144790649
Validation loss: 2.0090589010587303

Epoch: 5| Step: 5
Training loss: 1.0512596368789673
Validation loss: 1.9607325574403167

Epoch: 5| Step: 6
Training loss: 1.137384057044983
Validation loss: 1.9441220824436476

Epoch: 5| Step: 7
Training loss: 1.5907224416732788
Validation loss: 1.922436568044847

Epoch: 5| Step: 8
Training loss: 1.3341176509857178
Validation loss: 1.8835001299458165

Epoch: 5| Step: 9
Training loss: 1.651050329208374
Validation loss: 1.8610414433222946

Epoch: 5| Step: 10
Training loss: 2.0687999725341797
Validation loss: 1.8409547882695352

Epoch: 158| Step: 0
Training loss: 1.8289598226547241
Validation loss: 1.8707719772092757

Epoch: 5| Step: 1
Training loss: 1.786972999572754
Validation loss: 1.86016926457805

Epoch: 5| Step: 2
Training loss: 0.83538419008255
Validation loss: 1.8778852954987557

Epoch: 5| Step: 3
Training loss: 2.2083041667938232
Validation loss: 1.8689045918885099

Epoch: 5| Step: 4
Training loss: 1.0116608142852783
Validation loss: 1.9219032070970024

Epoch: 5| Step: 5
Training loss: 1.4036599397659302
Validation loss: 1.917422894508608

Epoch: 5| Step: 6
Training loss: 1.4819068908691406
Validation loss: 1.9433292855498612

Epoch: 5| Step: 7
Training loss: 1.617044448852539
Validation loss: 1.963824624656349

Epoch: 5| Step: 8
Training loss: 1.4309141635894775
Validation loss: 1.950999959822624

Epoch: 5| Step: 9
Training loss: 1.3517825603485107
Validation loss: 1.9638878978708738

Epoch: 5| Step: 10
Training loss: 1.673943281173706
Validation loss: 1.9636534849802654

Epoch: 159| Step: 0
Training loss: 1.3882908821105957
Validation loss: 1.951495914049046

Epoch: 5| Step: 1
Training loss: 1.3902453184127808
Validation loss: 1.949271616115365

Epoch: 5| Step: 2
Training loss: 1.9666244983673096
Validation loss: 1.928773541604319

Epoch: 5| Step: 3
Training loss: 1.460044503211975
Validation loss: 1.9449446970416653

Epoch: 5| Step: 4
Training loss: 1.1808518171310425
Validation loss: 1.9266086803969515

Epoch: 5| Step: 5
Training loss: 1.4204527139663696
Validation loss: 1.9118587663096767

Epoch: 5| Step: 6
Training loss: 1.8244140148162842
Validation loss: 1.8854279056672127

Epoch: 5| Step: 7
Training loss: 1.5262857675552368
Validation loss: 1.8490747803000993

Epoch: 5| Step: 8
Training loss: 1.4074045419692993
Validation loss: 1.8372384707132976

Epoch: 5| Step: 9
Training loss: 1.6979824304580688
Validation loss: 1.8436208104574552

Epoch: 5| Step: 10
Training loss: 0.9050319790840149
Validation loss: 1.8316554100282731

Epoch: 160| Step: 0
Training loss: 0.7794942259788513
Validation loss: 1.8563706310846473

Epoch: 5| Step: 1
Training loss: 1.2185298204421997
Validation loss: 1.8609932353419643

Epoch: 5| Step: 2
Training loss: 1.124607801437378
Validation loss: 1.884289905589114

Epoch: 5| Step: 3
Training loss: 1.4874604940414429
Validation loss: 1.8751505280053744

Epoch: 5| Step: 4
Training loss: 1.9236787557601929
Validation loss: 1.8793868736554218

Epoch: 5| Step: 5
Training loss: 1.6560853719711304
Validation loss: 1.862628375330279

Epoch: 5| Step: 6
Training loss: 1.331363558769226
Validation loss: 1.8602876214570896

Epoch: 5| Step: 7
Training loss: 1.1458826065063477
Validation loss: 1.840789141193513

Epoch: 5| Step: 8
Training loss: 2.3793487548828125
Validation loss: 1.8555765344250588

Epoch: 5| Step: 9
Training loss: 1.4355412721633911
Validation loss: 1.8418284641799105

Epoch: 5| Step: 10
Training loss: 1.5693498849868774
Validation loss: 1.8287451959425403

Epoch: 161| Step: 0
Training loss: 1.1316492557525635
Validation loss: 1.8230233166807441

Epoch: 5| Step: 1
Training loss: 1.5636736154556274
Validation loss: 1.841376014935073

Epoch: 5| Step: 2
Training loss: 1.3806097507476807
Validation loss: 1.8561815472059353

Epoch: 5| Step: 3
Training loss: 1.3503605127334595
Validation loss: 1.8809903411455051

Epoch: 5| Step: 4
Training loss: 1.7154052257537842
Validation loss: 1.873134272072905

Epoch: 5| Step: 5
Training loss: 1.5318877696990967
Validation loss: 1.858003080532115

Epoch: 5| Step: 6
Training loss: 1.673958420753479
Validation loss: 1.8993371532809349

Epoch: 5| Step: 7
Training loss: 1.418764352798462
Validation loss: 1.9420337959002423

Epoch: 5| Step: 8
Training loss: 1.3215339183807373
Validation loss: 1.9445680020957865

Epoch: 5| Step: 9
Training loss: 1.1685130596160889
Validation loss: 1.9275098321258382

Epoch: 5| Step: 10
Training loss: 1.4594535827636719
Validation loss: 1.9078619018677743

Epoch: 162| Step: 0
Training loss: 0.9630573391914368
Validation loss: 1.9125973473313034

Epoch: 5| Step: 1
Training loss: 1.3802884817123413
Validation loss: 1.8870274507871239

Epoch: 5| Step: 2
Training loss: 1.4821919202804565
Validation loss: 1.9012309889639578

Epoch: 5| Step: 3
Training loss: 1.2726458311080933
Validation loss: 1.917958374946348

Epoch: 5| Step: 4
Training loss: 1.9335170984268188
Validation loss: 1.9202830471018308

Epoch: 5| Step: 5
Training loss: 2.0185391902923584
Validation loss: 1.9194778575692126

Epoch: 5| Step: 6
Training loss: 1.6040050983428955
Validation loss: 1.9242737959789973

Epoch: 5| Step: 7
Training loss: 1.346535325050354
Validation loss: 1.9375286486841017

Epoch: 5| Step: 8
Training loss: 1.164315938949585
Validation loss: 1.9323825400362733

Epoch: 5| Step: 9
Training loss: 1.5632375478744507
Validation loss: 1.9267616861610002

Epoch: 5| Step: 10
Training loss: 1.0886398553848267
Validation loss: 1.9599051731888966

Epoch: 163| Step: 0
Training loss: 1.3266615867614746
Validation loss: 1.9471558204261206

Epoch: 5| Step: 1
Training loss: 1.6224969625473022
Validation loss: 1.9872264605696484

Epoch: 5| Step: 2
Training loss: 1.4069750308990479
Validation loss: 1.9949167043932023

Epoch: 5| Step: 3
Training loss: 1.2856762409210205
Validation loss: 1.980531282322381

Epoch: 5| Step: 4
Training loss: 1.2181103229522705
Validation loss: 1.9931726865870978

Epoch: 5| Step: 5
Training loss: 1.6400816440582275
Validation loss: 1.9582592210462015

Epoch: 5| Step: 6
Training loss: 2.2286410331726074
Validation loss: 1.9322016905712824

Epoch: 5| Step: 7
Training loss: 1.6271244287490845
Validation loss: 1.8964034498378795

Epoch: 5| Step: 8
Training loss: 1.3832859992980957
Validation loss: 1.8677495807729743

Epoch: 5| Step: 9
Training loss: 1.1082127094268799
Validation loss: 1.860710008170015

Epoch: 5| Step: 10
Training loss: 0.9039403796195984
Validation loss: 1.8626765961288123

Epoch: 164| Step: 0
Training loss: 1.1420037746429443
Validation loss: 1.8782882882702736

Epoch: 5| Step: 1
Training loss: 1.5045392513275146
Validation loss: 1.8939214098838069

Epoch: 5| Step: 2
Training loss: 1.472938060760498
Validation loss: 1.9133933859486734

Epoch: 5| Step: 3
Training loss: 1.3594911098480225
Validation loss: 1.9209626054251066

Epoch: 5| Step: 4
Training loss: 0.8042728304862976
Validation loss: 1.9436310311799407

Epoch: 5| Step: 5
Training loss: 1.3304181098937988
Validation loss: 1.9346268074486845

Epoch: 5| Step: 6
Training loss: 1.7341232299804688
Validation loss: 1.930195959665442

Epoch: 5| Step: 7
Training loss: 1.383631944656372
Validation loss: 1.9187738728779618

Epoch: 5| Step: 8
Training loss: 0.9901716113090515
Validation loss: 1.9143370069483274

Epoch: 5| Step: 9
Training loss: 1.9946362972259521
Validation loss: 1.9085412320270334

Epoch: 5| Step: 10
Training loss: 1.6798534393310547
Validation loss: 1.9228434498592089

Epoch: 165| Step: 0
Training loss: 1.2637882232666016
Validation loss: 1.9245381073285175

Epoch: 5| Step: 1
Training loss: 1.3153146505355835
Validation loss: 1.9221817242201937

Epoch: 5| Step: 2
Training loss: 1.42978036403656
Validation loss: 1.915733427129766

Epoch: 5| Step: 3
Training loss: 1.5870944261550903
Validation loss: 1.978976441967872

Epoch: 5| Step: 4
Training loss: 2.192682981491089
Validation loss: 2.0368267041380688

Epoch: 5| Step: 5
Training loss: 0.47623610496520996
Validation loss: 2.032327787850493

Epoch: 5| Step: 6
Training loss: 1.3541028499603271
Validation loss: 1.9824870196721887

Epoch: 5| Step: 7
Training loss: 1.1749159097671509
Validation loss: 1.9154962339708883

Epoch: 5| Step: 8
Training loss: 1.6248620748519897
Validation loss: 1.863492509370209

Epoch: 5| Step: 9
Training loss: 1.8000656366348267
Validation loss: 1.8235796830987419

Epoch: 5| Step: 10
Training loss: 1.6269367933273315
Validation loss: 1.796476726890892

Epoch: 166| Step: 0
Training loss: 1.4166226387023926
Validation loss: 1.791513309683851

Epoch: 5| Step: 1
Training loss: 1.4092423915863037
Validation loss: 1.7922508255127938

Epoch: 5| Step: 2
Training loss: 1.296574354171753
Validation loss: 1.7794256582055041

Epoch: 5| Step: 3
Training loss: 0.8631649017333984
Validation loss: 1.813044963344451

Epoch: 5| Step: 4
Training loss: 1.8475306034088135
Validation loss: 1.8520137571519422

Epoch: 5| Step: 5
Training loss: 1.6991935968399048
Validation loss: 1.8668682062497703

Epoch: 5| Step: 6
Training loss: 1.4740091562271118
Validation loss: 1.8824645524383874

Epoch: 5| Step: 7
Training loss: 1.5226490497589111
Validation loss: 1.9059707118618874

Epoch: 5| Step: 8
Training loss: 1.0494693517684937
Validation loss: 1.9069490099465976

Epoch: 5| Step: 9
Training loss: 1.3520770072937012
Validation loss: 1.8852325126688967

Epoch: 5| Step: 10
Training loss: 1.5563620328903198
Validation loss: 1.8892761635523971

Epoch: 167| Step: 0
Training loss: 1.0824140310287476
Validation loss: 1.903564924834877

Epoch: 5| Step: 1
Training loss: 1.0322611331939697
Validation loss: 1.9186323765785462

Epoch: 5| Step: 2
Training loss: 1.1091127395629883
Validation loss: 1.9136664136763541

Epoch: 5| Step: 3
Training loss: 1.885063886642456
Validation loss: 1.9328764407865462

Epoch: 5| Step: 4
Training loss: 1.1722365617752075
Validation loss: 1.9214222174818798

Epoch: 5| Step: 5
Training loss: 1.3603312969207764
Validation loss: 1.9103450236781951

Epoch: 5| Step: 6
Training loss: 1.6089729070663452
Validation loss: 1.8945243884158391

Epoch: 5| Step: 7
Training loss: 1.3098403215408325
Validation loss: 1.887956210362014

Epoch: 5| Step: 8
Training loss: 1.16452956199646
Validation loss: 1.8877329364899667

Epoch: 5| Step: 9
Training loss: 1.5465338230133057
Validation loss: 1.912134688387635

Epoch: 5| Step: 10
Training loss: 1.5861737728118896
Validation loss: 1.901521687866539

Epoch: 168| Step: 0
Training loss: 1.5031722784042358
Validation loss: 1.8919381172426286

Epoch: 5| Step: 1
Training loss: 1.8417634963989258
Validation loss: 1.8796489636103313

Epoch: 5| Step: 2
Training loss: 0.990221381187439
Validation loss: 1.8541498325204337

Epoch: 5| Step: 3
Training loss: 1.39837646484375
Validation loss: 1.8453828673208914

Epoch: 5| Step: 4
Training loss: 1.3448032140731812
Validation loss: 1.8329803956452237

Epoch: 5| Step: 5
Training loss: 1.3920916318893433
Validation loss: 1.8509326980959984

Epoch: 5| Step: 6
Training loss: 1.1348590850830078
Validation loss: 1.8779430338131484

Epoch: 5| Step: 7
Training loss: 1.1514551639556885
Validation loss: 1.9248131808414255

Epoch: 5| Step: 8
Training loss: 1.4394444227218628
Validation loss: 1.9232881581911476

Epoch: 5| Step: 9
Training loss: 1.5169607400894165
Validation loss: 1.9075291515678487

Epoch: 5| Step: 10
Training loss: 1.2134512662887573
Validation loss: 1.8881907668164981

Epoch: 169| Step: 0
Training loss: 1.6439502239227295
Validation loss: 1.9011896861496793

Epoch: 5| Step: 1
Training loss: 1.2333412170410156
Validation loss: 1.894819837744518

Epoch: 5| Step: 2
Training loss: 1.2502962350845337
Validation loss: 1.906756708698888

Epoch: 5| Step: 3
Training loss: 1.1129097938537598
Validation loss: 1.9075698442356561

Epoch: 5| Step: 4
Training loss: 1.7411565780639648
Validation loss: 1.9011134242498746

Epoch: 5| Step: 5
Training loss: 1.4693217277526855
Validation loss: 1.885640957022226

Epoch: 5| Step: 6
Training loss: 1.2202562093734741
Validation loss: 1.850992416822782

Epoch: 5| Step: 7
Training loss: 1.549401044845581
Validation loss: 1.8630880950599589

Epoch: 5| Step: 8
Training loss: 0.972815990447998
Validation loss: 1.8823387827924503

Epoch: 5| Step: 9
Training loss: 1.2712081670761108
Validation loss: 1.886745786154142

Epoch: 5| Step: 10
Training loss: 1.4578425884246826
Validation loss: 1.8620967749626405

Epoch: 170| Step: 0
Training loss: 1.322997808456421
Validation loss: 1.8516409397125244

Epoch: 5| Step: 1
Training loss: 1.3181991577148438
Validation loss: 1.808679933189064

Epoch: 5| Step: 2
Training loss: 1.729116678237915
Validation loss: 1.8217831721869848

Epoch: 5| Step: 3
Training loss: 1.7033029794692993
Validation loss: 1.8322276992182578

Epoch: 5| Step: 4
Training loss: 1.5654809474945068
Validation loss: 1.8324166843968053

Epoch: 5| Step: 5
Training loss: 1.3552587032318115
Validation loss: 1.8391604179977088

Epoch: 5| Step: 6
Training loss: 1.1098995208740234
Validation loss: 1.842814496127508

Epoch: 5| Step: 7
Training loss: 1.0449925661087036
Validation loss: 1.8733592020568026

Epoch: 5| Step: 8
Training loss: 1.4546115398406982
Validation loss: 1.8954320082100489

Epoch: 5| Step: 9
Training loss: 1.1251609325408936
Validation loss: 1.9318049594920168

Epoch: 5| Step: 10
Training loss: 0.9037813544273376
Validation loss: 1.9431781845708047

Epoch: 171| Step: 0
Training loss: 1.272674798965454
Validation loss: 1.9255335459145166

Epoch: 5| Step: 1
Training loss: 1.5447673797607422
Validation loss: 1.932557249581942

Epoch: 5| Step: 2
Training loss: 0.9356688261032104
Validation loss: 1.8841115172191332

Epoch: 5| Step: 3
Training loss: 1.3173155784606934
Validation loss: 1.869360452057213

Epoch: 5| Step: 4
Training loss: 1.4694641828536987
Validation loss: 1.8151152082668838

Epoch: 5| Step: 5
Training loss: 1.1116126775741577
Validation loss: 1.8249565145020843

Epoch: 5| Step: 6
Training loss: 0.6984280347824097
Validation loss: 1.8600317047488304

Epoch: 5| Step: 7
Training loss: 1.5482840538024902
Validation loss: 1.8740622715283466

Epoch: 5| Step: 8
Training loss: 1.2692750692367554
Validation loss: 1.8749286872084423

Epoch: 5| Step: 9
Training loss: 1.5327410697937012
Validation loss: 1.8622412835398028

Epoch: 5| Step: 10
Training loss: 1.7041774988174438
Validation loss: 1.8691283067067463

Epoch: 172| Step: 0
Training loss: 1.3193650245666504
Validation loss: 1.8796751165902743

Epoch: 5| Step: 1
Training loss: 1.0618387460708618
Validation loss: 1.896830157567096

Epoch: 5| Step: 2
Training loss: 1.3712266683578491
Validation loss: 1.9020748317882579

Epoch: 5| Step: 3
Training loss: 1.0917268991470337
Validation loss: 1.9060156729913527

Epoch: 5| Step: 4
Training loss: 0.9255730509757996
Validation loss: 1.894270109873946

Epoch: 5| Step: 5
Training loss: 1.1058263778686523
Validation loss: 1.8705105627736738

Epoch: 5| Step: 6
Training loss: 1.3586084842681885
Validation loss: 1.8690374589735461

Epoch: 5| Step: 7
Training loss: 1.2879705429077148
Validation loss: 1.8605519827976023

Epoch: 5| Step: 8
Training loss: 1.0042132139205933
Validation loss: 1.8549165930799258

Epoch: 5| Step: 9
Training loss: 1.5503581762313843
Validation loss: 1.8428955129397813

Epoch: 5| Step: 10
Training loss: 1.799626111984253
Validation loss: 1.8406774074800554

Epoch: 173| Step: 0
Training loss: 0.6800862550735474
Validation loss: 1.8687435516747095

Epoch: 5| Step: 1
Training loss: 1.772012710571289
Validation loss: 1.8592477639516194

Epoch: 5| Step: 2
Training loss: 1.042364478111267
Validation loss: 1.8601515600758214

Epoch: 5| Step: 3
Training loss: 1.2969028949737549
Validation loss: 1.9054004325661609

Epoch: 5| Step: 4
Training loss: 1.1491940021514893
Validation loss: 1.9092141556483444

Epoch: 5| Step: 5
Training loss: 1.3533052206039429
Validation loss: 1.9088844906899236

Epoch: 5| Step: 6
Training loss: 1.2485663890838623
Validation loss: 1.9127081991523824

Epoch: 5| Step: 7
Training loss: 1.4358623027801514
Validation loss: 1.8822722127360683

Epoch: 5| Step: 8
Training loss: 1.180966854095459
Validation loss: 1.867517036776389

Epoch: 5| Step: 9
Training loss: 1.305677056312561
Validation loss: 1.8295126653486682

Epoch: 5| Step: 10
Training loss: 1.3361696004867554
Validation loss: 1.8164047579611502

Epoch: 174| Step: 0
Training loss: 1.3130357265472412
Validation loss: 1.796492120271088

Epoch: 5| Step: 1
Training loss: 1.1265308856964111
Validation loss: 1.8312986179064679

Epoch: 5| Step: 2
Training loss: 1.2137595415115356
Validation loss: 1.8172906624373568

Epoch: 5| Step: 3
Training loss: 0.787761926651001
Validation loss: 1.8558870054060412

Epoch: 5| Step: 4
Training loss: 2.237551212310791
Validation loss: 1.8814244949689476

Epoch: 5| Step: 5
Training loss: 1.5610003471374512
Validation loss: 1.8445424738750662

Epoch: 5| Step: 6
Training loss: 1.0385593175888062
Validation loss: 1.8571243504042267

Epoch: 5| Step: 7
Training loss: 1.106784462928772
Validation loss: 1.8572257500822826

Epoch: 5| Step: 8
Training loss: 1.257983684539795
Validation loss: 1.8778794119434972

Epoch: 5| Step: 9
Training loss: 1.1782068014144897
Validation loss: 1.914879410497604

Epoch: 5| Step: 10
Training loss: 0.9469749331474304
Validation loss: 1.915004377724022

Epoch: 175| Step: 0
Training loss: 0.7928637862205505
Validation loss: 1.908377565363402

Epoch: 5| Step: 1
Training loss: 1.106748342514038
Validation loss: 1.9238147492049842

Epoch: 5| Step: 2
Training loss: 1.2773529291152954
Validation loss: 1.9263734112503708

Epoch: 5| Step: 3
Training loss: 1.6108629703521729
Validation loss: 1.912883033034622

Epoch: 5| Step: 4
Training loss: 1.2727930545806885
Validation loss: 1.9242560030311666

Epoch: 5| Step: 5
Training loss: 0.707344651222229
Validation loss: 1.9299464610315138

Epoch: 5| Step: 6
Training loss: 0.7694646120071411
Validation loss: 1.9074479854235085

Epoch: 5| Step: 7
Training loss: 1.2972748279571533
Validation loss: 1.9363280380925825

Epoch: 5| Step: 8
Training loss: 1.831467866897583
Validation loss: 1.8933003461489113

Epoch: 5| Step: 9
Training loss: 1.3302373886108398
Validation loss: 1.8787480233817972

Epoch: 5| Step: 10
Training loss: 1.7732597589492798
Validation loss: 1.82206247057966

Epoch: 176| Step: 0
Training loss: 0.9851356744766235
Validation loss: 1.8149341614015642

Epoch: 5| Step: 1
Training loss: 1.446818232536316
Validation loss: 1.854166203929532

Epoch: 5| Step: 2
Training loss: 1.287976861000061
Validation loss: 1.859308873453448

Epoch: 5| Step: 3
Training loss: 1.439057469367981
Validation loss: 1.8836039343187887

Epoch: 5| Step: 4
Training loss: 0.9672874212265015
Validation loss: 1.8671333815461846

Epoch: 5| Step: 5
Training loss: 1.2267720699310303
Validation loss: 1.8614087925162366

Epoch: 5| Step: 6
Training loss: 1.3052419424057007
Validation loss: 1.8511068090315788

Epoch: 5| Step: 7
Training loss: 1.0088310241699219
Validation loss: 1.837661939282571

Epoch: 5| Step: 8
Training loss: 1.2965542078018188
Validation loss: 1.838328548656997

Epoch: 5| Step: 9
Training loss: 1.753690481185913
Validation loss: 1.82251359826775

Epoch: 5| Step: 10
Training loss: 1.022516131401062
Validation loss: 1.8148644944672943

Epoch: 177| Step: 0
Training loss: 1.1144704818725586
Validation loss: 1.8006089502765286

Epoch: 5| Step: 1
Training loss: 1.333482027053833
Validation loss: 1.8529937344212686

Epoch: 5| Step: 2
Training loss: 1.4027128219604492
Validation loss: 1.8951897210972284

Epoch: 5| Step: 3
Training loss: 0.987343966960907
Validation loss: 1.9125161491414553

Epoch: 5| Step: 4
Training loss: 1.3343583345413208
Validation loss: 1.9160913780171385

Epoch: 5| Step: 5
Training loss: 1.7032182216644287
Validation loss: 1.8816400369008381

Epoch: 5| Step: 6
Training loss: 0.8763089179992676
Validation loss: 1.8701564176108247

Epoch: 5| Step: 7
Training loss: 1.5231908559799194
Validation loss: 1.879226871716079

Epoch: 5| Step: 8
Training loss: 1.5403401851654053
Validation loss: 1.877149990809861

Epoch: 5| Step: 9
Training loss: 0.9820140600204468
Validation loss: 1.8694334440333868

Epoch: 5| Step: 10
Training loss: 0.8257908225059509
Validation loss: 1.8919708921063332

Epoch: 178| Step: 0
Training loss: 1.114443063735962
Validation loss: 1.924816664829049

Epoch: 5| Step: 1
Training loss: 1.3586578369140625
Validation loss: 1.9478384487090572

Epoch: 5| Step: 2
Training loss: 1.0753929615020752
Validation loss: 1.9444039175587315

Epoch: 5| Step: 3
Training loss: 1.0284444093704224
Validation loss: 1.9487506535745436

Epoch: 5| Step: 4
Training loss: 0.9106130599975586
Validation loss: 1.9478091552693357

Epoch: 5| Step: 5
Training loss: 1.553930401802063
Validation loss: 1.940457715783068

Epoch: 5| Step: 6
Training loss: 1.472806692123413
Validation loss: 1.8836270224663518

Epoch: 5| Step: 7
Training loss: 0.9023963809013367
Validation loss: 1.8570886734993226

Epoch: 5| Step: 8
Training loss: 1.5794343948364258
Validation loss: 1.845746397972107

Epoch: 5| Step: 9
Training loss: 1.0712095499038696
Validation loss: 1.8530107826314948

Epoch: 5| Step: 10
Training loss: 1.5894138813018799
Validation loss: 1.8333909229565692

Epoch: 179| Step: 0
Training loss: 1.4133825302124023
Validation loss: 1.8315256962212183

Epoch: 5| Step: 1
Training loss: 1.2791844606399536
Validation loss: 1.842147816893875

Epoch: 5| Step: 2
Training loss: 1.6388028860092163
Validation loss: 1.8184065075330837

Epoch: 5| Step: 3
Training loss: 1.1281121969223022
Validation loss: 1.84226175918374

Epoch: 5| Step: 4
Training loss: 1.2220993041992188
Validation loss: 1.8569398977423226

Epoch: 5| Step: 5
Training loss: 0.9605377316474915
Validation loss: 1.8457938778784968

Epoch: 5| Step: 6
Training loss: 0.7890321016311646
Validation loss: 1.8712828492605558

Epoch: 5| Step: 7
Training loss: 0.9276620149612427
Validation loss: 1.8841132079401324

Epoch: 5| Step: 8
Training loss: 1.3584537506103516
Validation loss: 1.8585546837058118

Epoch: 5| Step: 9
Training loss: 1.4786192178726196
Validation loss: 1.8481475127640592

Epoch: 5| Step: 10
Training loss: 1.2052761316299438
Validation loss: 1.8513562858745616

Epoch: 180| Step: 0
Training loss: 0.8066154718399048
Validation loss: 1.8499122563228811

Epoch: 5| Step: 1
Training loss: 1.1746755838394165
Validation loss: 1.8551423639379523

Epoch: 5| Step: 2
Training loss: 2.0308284759521484
Validation loss: 1.8569994613688479

Epoch: 5| Step: 3
Training loss: 1.4207582473754883
Validation loss: 1.8555003994254655

Epoch: 5| Step: 4
Training loss: 0.8162978887557983
Validation loss: 1.8451366027196248

Epoch: 5| Step: 5
Training loss: 1.0911858081817627
Validation loss: 1.838923474793793

Epoch: 5| Step: 6
Training loss: 1.0090439319610596
Validation loss: 1.8670772596072125

Epoch: 5| Step: 7
Training loss: 0.8005512356758118
Validation loss: 1.8833072993063158

Epoch: 5| Step: 8
Training loss: 1.3108088970184326
Validation loss: 1.9004394764541297

Epoch: 5| Step: 9
Training loss: 1.1690900325775146
Validation loss: 1.8765933321368309

Epoch: 5| Step: 10
Training loss: 1.148987054824829
Validation loss: 1.8295271704273839

Epoch: 181| Step: 0
Training loss: 1.1516411304473877
Validation loss: 1.8517383785657986

Epoch: 5| Step: 1
Training loss: 1.0267430543899536
Validation loss: 1.8388339319536764

Epoch: 5| Step: 2
Training loss: 0.7812008261680603
Validation loss: 1.8408715596763037

Epoch: 5| Step: 3
Training loss: 1.0848493576049805
Validation loss: 1.8425776522646669

Epoch: 5| Step: 4
Training loss: 0.8287513852119446
Validation loss: 1.8582613814261653

Epoch: 5| Step: 5
Training loss: 1.2804657220840454
Validation loss: 1.8590242849883212

Epoch: 5| Step: 6
Training loss: 1.3178153038024902
Validation loss: 1.8869310399537444

Epoch: 5| Step: 7
Training loss: 1.5836741924285889
Validation loss: 1.8686133610304965

Epoch: 5| Step: 8
Training loss: 1.1621965169906616
Validation loss: 1.8504771212095856

Epoch: 5| Step: 9
Training loss: 0.7047120928764343
Validation loss: 1.876389516297207

Epoch: 5| Step: 10
Training loss: 1.8771082162857056
Validation loss: 1.8681667389408234

Epoch: 182| Step: 0
Training loss: 0.8031594157218933
Validation loss: 1.8510917566155876

Epoch: 5| Step: 1
Training loss: 1.060001254081726
Validation loss: 1.8583732792126235

Epoch: 5| Step: 2
Training loss: 1.5015227794647217
Validation loss: 1.8690926259563816

Epoch: 5| Step: 3
Training loss: 1.0903853178024292
Validation loss: 1.86497175821694

Epoch: 5| Step: 4
Training loss: 0.9038146138191223
Validation loss: 1.8640749069952196

Epoch: 5| Step: 5
Training loss: 1.1906975507736206
Validation loss: 1.8961093105295652

Epoch: 5| Step: 6
Training loss: 1.3632266521453857
Validation loss: 1.9441257420406546

Epoch: 5| Step: 7
Training loss: 1.043563723564148
Validation loss: 1.9382292121969245

Epoch: 5| Step: 8
Training loss: 1.5458354949951172
Validation loss: 1.8954270732018255

Epoch: 5| Step: 9
Training loss: 1.0013331174850464
Validation loss: 1.9030650636201263

Epoch: 5| Step: 10
Training loss: 1.3600990772247314
Validation loss: 1.8907883974813646

Epoch: 183| Step: 0
Training loss: 1.0858869552612305
Validation loss: 1.8913739458207162

Epoch: 5| Step: 1
Training loss: 0.8801377415657043
Validation loss: 1.849384589861798

Epoch: 5| Step: 2
Training loss: 0.8630182147026062
Validation loss: 1.824553366630308

Epoch: 5| Step: 3
Training loss: 1.2105462551116943
Validation loss: 1.8068214078103342

Epoch: 5| Step: 4
Training loss: 1.0864609479904175
Validation loss: 1.7870980770357194

Epoch: 5| Step: 5
Training loss: 1.7559009790420532
Validation loss: 1.7930202150857577

Epoch: 5| Step: 6
Training loss: 1.594357967376709
Validation loss: 1.7856817142937773

Epoch: 5| Step: 7
Training loss: 1.367173433303833
Validation loss: 1.7639353480390323

Epoch: 5| Step: 8
Training loss: 1.0372971296310425
Validation loss: 1.782411629153836

Epoch: 5| Step: 9
Training loss: 0.8373076319694519
Validation loss: 1.8204421022886872

Epoch: 5| Step: 10
Training loss: 1.0606732368469238
Validation loss: 1.8706028884457004

Epoch: 184| Step: 0
Training loss: 0.8687063455581665
Validation loss: 1.9964830080668132

Epoch: 5| Step: 1
Training loss: 0.9921882748603821
Validation loss: 2.020490700198758

Epoch: 5| Step: 2
Training loss: 0.953369140625
Validation loss: 1.9819007342861545

Epoch: 5| Step: 3
Training loss: 1.2498677968978882
Validation loss: 1.9470185079882223

Epoch: 5| Step: 4
Training loss: 1.1849883794784546
Validation loss: 1.8980372272511965

Epoch: 5| Step: 5
Training loss: 0.9209100008010864
Validation loss: 1.8452536816238074

Epoch: 5| Step: 6
Training loss: 1.2124756574630737
Validation loss: 1.8155717003730036

Epoch: 5| Step: 7
Training loss: 1.668402910232544
Validation loss: 1.8202278024406844

Epoch: 5| Step: 8
Training loss: 1.5666463375091553
Validation loss: 1.824986130960526

Epoch: 5| Step: 9
Training loss: 1.3798811435699463
Validation loss: 1.815672976996309

Epoch: 5| Step: 10
Training loss: 1.482640027999878
Validation loss: 1.8235414745987102

Epoch: 185| Step: 0
Training loss: 1.2628748416900635
Validation loss: 1.8379653089789934

Epoch: 5| Step: 1
Training loss: 1.0780203342437744
Validation loss: 1.889801202281829

Epoch: 5| Step: 2
Training loss: 1.1016112565994263
Validation loss: 1.9384744346782725

Epoch: 5| Step: 3
Training loss: 1.4319757223129272
Validation loss: 1.9651217857996623

Epoch: 5| Step: 4
Training loss: 1.1272133588790894
Validation loss: 2.034993096064496

Epoch: 5| Step: 5
Training loss: 1.3675172328948975
Validation loss: 2.019068528247136

Epoch: 5| Step: 6
Training loss: 0.992764949798584
Validation loss: 1.9811330764524397

Epoch: 5| Step: 7
Training loss: 1.408475637435913
Validation loss: 1.8865955798856673

Epoch: 5| Step: 8
Training loss: 1.03163743019104
Validation loss: 1.816398984642439

Epoch: 5| Step: 9
Training loss: 0.8325583338737488
Validation loss: 1.8168611808489727

Epoch: 5| Step: 10
Training loss: 1.0326944589614868
Validation loss: 1.7899263648576633

Epoch: 186| Step: 0
Training loss: 1.2955338954925537
Validation loss: 1.7874480229552074

Epoch: 5| Step: 1
Training loss: 0.9922317266464233
Validation loss: 1.8091096301232614

Epoch: 5| Step: 2
Training loss: 1.4295198917388916
Validation loss: 1.8113587364073722

Epoch: 5| Step: 3
Training loss: 1.3291492462158203
Validation loss: 1.8463513915256788

Epoch: 5| Step: 4
Training loss: 0.9410154223442078
Validation loss: 1.8617720988488966

Epoch: 5| Step: 5
Training loss: 1.0810792446136475
Validation loss: 1.8851902907894504

Epoch: 5| Step: 6
Training loss: 1.3185856342315674
Validation loss: 1.9054249768616052

Epoch: 5| Step: 7
Training loss: 1.5038734674453735
Validation loss: 1.8943565058451828

Epoch: 5| Step: 8
Training loss: 1.1481585502624512
Validation loss: 1.9096659255284134

Epoch: 5| Step: 9
Training loss: 0.7556074857711792
Validation loss: 1.88721844714175

Epoch: 5| Step: 10
Training loss: 1.0319489240646362
Validation loss: 1.8839377946751092

Epoch: 187| Step: 0
Training loss: 1.116015076637268
Validation loss: 1.9064228816698956

Epoch: 5| Step: 1
Training loss: 0.8664103746414185
Validation loss: 1.916416342540454

Epoch: 5| Step: 2
Training loss: 1.3020002841949463
Validation loss: 1.8955770718154086

Epoch: 5| Step: 3
Training loss: 1.3818268775939941
Validation loss: 1.8970539390399892

Epoch: 5| Step: 4
Training loss: 1.335154414176941
Validation loss: 1.895503181283192

Epoch: 5| Step: 5
Training loss: 1.031553030014038
Validation loss: 1.8593130265512774

Epoch: 5| Step: 6
Training loss: 1.2178480625152588
Validation loss: 1.8369135843810214

Epoch: 5| Step: 7
Training loss: 0.9986384510993958
Validation loss: 1.8550664481296335

Epoch: 5| Step: 8
Training loss: 0.48022833466529846
Validation loss: 1.8561052122423727

Epoch: 5| Step: 9
Training loss: 1.2948271036148071
Validation loss: 1.8417240509422876

Epoch: 5| Step: 10
Training loss: 1.0747195482254028
Validation loss: 1.8647748142160394

Epoch: 188| Step: 0
Training loss: 0.8624706268310547
Validation loss: 1.8566035083545152

Epoch: 5| Step: 1
Training loss: 1.0347754955291748
Validation loss: 1.863371765741738

Epoch: 5| Step: 2
Training loss: 1.046600341796875
Validation loss: 1.8613540305886218

Epoch: 5| Step: 3
Training loss: 1.0430809259414673
Validation loss: 1.862765564713427

Epoch: 5| Step: 4
Training loss: 1.0768929719924927
Validation loss: 1.8474222293464087

Epoch: 5| Step: 5
Training loss: 1.1585874557495117
Validation loss: 1.8310342296477287

Epoch: 5| Step: 6
Training loss: 0.9795050621032715
Validation loss: 1.8115826114531486

Epoch: 5| Step: 7
Training loss: 1.5271662473678589
Validation loss: 1.8212998349179503

Epoch: 5| Step: 8
Training loss: 0.9522610902786255
Validation loss: 1.8626378415733256

Epoch: 5| Step: 9
Training loss: 0.9788640737533569
Validation loss: 1.8599174663584719

Epoch: 5| Step: 10
Training loss: 0.983163058757782
Validation loss: 1.8731766067525393

Epoch: 189| Step: 0
Training loss: 1.2696603536605835
Validation loss: 1.8339402073173112

Epoch: 5| Step: 1
Training loss: 0.807295024394989
Validation loss: 1.8348733712268133

Epoch: 5| Step: 2
Training loss: 1.0857136249542236
Validation loss: 1.822893419573384

Epoch: 5| Step: 3
Training loss: 1.111403465270996
Validation loss: 1.8074174260580411

Epoch: 5| Step: 4
Training loss: 1.0164285898208618
Validation loss: 1.829426114277173

Epoch: 5| Step: 5
Training loss: 1.315780520439148
Validation loss: 1.8130317746952016

Epoch: 5| Step: 6
Training loss: 0.5406288504600525
Validation loss: 1.8089263336632841

Epoch: 5| Step: 7
Training loss: 0.9580146074295044
Validation loss: 1.8414448538134176

Epoch: 5| Step: 8
Training loss: 1.4608620405197144
Validation loss: 1.803288959687756

Epoch: 5| Step: 9
Training loss: 0.894837498664856
Validation loss: 1.7935696930013678

Epoch: 5| Step: 10
Training loss: 1.1558417081832886
Validation loss: 1.8145973964404034

Epoch: 190| Step: 0
Training loss: 1.012192726135254
Validation loss: 1.8303139671202628

Epoch: 5| Step: 1
Training loss: 1.146317481994629
Validation loss: 1.8179581921587709

Epoch: 5| Step: 2
Training loss: 0.7633142471313477
Validation loss: 1.841285756839219

Epoch: 5| Step: 3
Training loss: 1.3372985124588013
Validation loss: 1.8325219667086037

Epoch: 5| Step: 4
Training loss: 0.7428113222122192
Validation loss: 1.8452989721810946

Epoch: 5| Step: 5
Training loss: 0.9404775500297546
Validation loss: 1.8415658961060226

Epoch: 5| Step: 6
Training loss: 0.9542514681816101
Validation loss: 1.841500997543335

Epoch: 5| Step: 7
Training loss: 1.175333023071289
Validation loss: 1.8393397715783888

Epoch: 5| Step: 8
Training loss: 1.4042011499404907
Validation loss: 1.794138869931621

Epoch: 5| Step: 9
Training loss: 0.8746654391288757
Validation loss: 1.7994913529324275

Epoch: 5| Step: 10
Training loss: 0.9433836340904236
Validation loss: 1.802468740811912

Epoch: 191| Step: 0
Training loss: 1.1458804607391357
Validation loss: 1.7945376301324496

Epoch: 5| Step: 1
Training loss: 1.1526610851287842
Validation loss: 1.817012148518716

Epoch: 5| Step: 2
Training loss: 1.1076263189315796
Validation loss: 1.8610332422359015

Epoch: 5| Step: 3
Training loss: 1.2086217403411865
Validation loss: 1.858222790943679

Epoch: 5| Step: 4
Training loss: 0.8021695017814636
Validation loss: 1.862946137305229

Epoch: 5| Step: 5
Training loss: 0.8675187826156616
Validation loss: 1.8473414221117574

Epoch: 5| Step: 6
Training loss: 0.5645095705986023
Validation loss: 1.8543566567923433

Epoch: 5| Step: 7
Training loss: 0.9758129119873047
Validation loss: 1.8302880833225865

Epoch: 5| Step: 8
Training loss: 0.9246432185173035
Validation loss: 1.808293919409475

Epoch: 5| Step: 9
Training loss: 1.2642567157745361
Validation loss: 1.8320667987228723

Epoch: 5| Step: 10
Training loss: 1.4292997121810913
Validation loss: 1.844996367731402

Epoch: 192| Step: 0
Training loss: 0.8963489532470703
Validation loss: 1.8265002363471574

Epoch: 5| Step: 1
Training loss: 1.2575404644012451
Validation loss: 1.8391358890841085

Epoch: 5| Step: 2
Training loss: 0.7308512926101685
Validation loss: 1.792968641045273

Epoch: 5| Step: 3
Training loss: 1.1211092472076416
Validation loss: 1.8036608542165449

Epoch: 5| Step: 4
Training loss: 0.986625075340271
Validation loss: 1.817135134050923

Epoch: 5| Step: 5
Training loss: 1.0758169889450073
Validation loss: 1.8205905396451232

Epoch: 5| Step: 6
Training loss: 1.2239198684692383
Validation loss: 1.8201475861251994

Epoch: 5| Step: 7
Training loss: 0.9154757261276245
Validation loss: 1.791015326335866

Epoch: 5| Step: 8
Training loss: 1.2330639362335205
Validation loss: 1.7780371494190668

Epoch: 5| Step: 9
Training loss: 0.9277219772338867
Validation loss: 1.7999489384312783

Epoch: 5| Step: 10
Training loss: 0.7750009894371033
Validation loss: 1.785690515272079

Epoch: 193| Step: 0
Training loss: 0.9130614995956421
Validation loss: 1.7920203388378184

Epoch: 5| Step: 1
Training loss: 0.5758426785469055
Validation loss: 1.8222657172910628

Epoch: 5| Step: 2
Training loss: 1.0474872589111328
Validation loss: 1.8037235531755673

Epoch: 5| Step: 3
Training loss: 1.3757340908050537
Validation loss: 1.817229260680496

Epoch: 5| Step: 4
Training loss: 0.9670435190200806
Validation loss: 1.806564074690624

Epoch: 5| Step: 5
Training loss: 1.007724642753601
Validation loss: 1.8066498541062879

Epoch: 5| Step: 6
Training loss: 0.9058685302734375
Validation loss: 1.8059335998309556

Epoch: 5| Step: 7
Training loss: 1.4018371105194092
Validation loss: 1.7822812372638333

Epoch: 5| Step: 8
Training loss: 0.6631224155426025
Validation loss: 1.7717375755310059

Epoch: 5| Step: 9
Training loss: 1.1910369396209717
Validation loss: 1.7886197233712802

Epoch: 5| Step: 10
Training loss: 1.461164116859436
Validation loss: 1.766238804786436

Epoch: 194| Step: 0
Training loss: 1.1670880317687988
Validation loss: 1.774315723808863

Epoch: 5| Step: 1
Training loss: 1.061888337135315
Validation loss: 1.7935544547214304

Epoch: 5| Step: 2
Training loss: 1.1301355361938477
Validation loss: 1.8169621562445035

Epoch: 5| Step: 3
Training loss: 1.245174765586853
Validation loss: 1.7837678065863989

Epoch: 5| Step: 4
Training loss: 0.8516941070556641
Validation loss: 1.794099328338459

Epoch: 5| Step: 5
Training loss: 0.9449155926704407
Validation loss: 1.8219222496914607

Epoch: 5| Step: 6
Training loss: 0.8544508218765259
Validation loss: 1.8077648314096595

Epoch: 5| Step: 7
Training loss: 1.47549307346344
Validation loss: 1.7887833913167317

Epoch: 5| Step: 8
Training loss: 0.7396634817123413
Validation loss: 1.8030459893647062

Epoch: 5| Step: 9
Training loss: 1.0074387788772583
Validation loss: 1.8132416740540536

Epoch: 5| Step: 10
Training loss: 1.0670722723007202
Validation loss: 1.8222755744893064

Epoch: 195| Step: 0
Training loss: 1.1856675148010254
Validation loss: 1.8348822362961308

Epoch: 5| Step: 1
Training loss: 1.2968076467514038
Validation loss: 1.8299754332470637

Epoch: 5| Step: 2
Training loss: 1.0852878093719482
Validation loss: 1.8389941492388326

Epoch: 5| Step: 3
Training loss: 1.1867115497589111
Validation loss: 1.8306988772525583

Epoch: 5| Step: 4
Training loss: 0.8981307744979858
Validation loss: 1.7975635349109609

Epoch: 5| Step: 5
Training loss: 0.9106998443603516
Validation loss: 1.8182429754605858

Epoch: 5| Step: 6
Training loss: 0.8686911463737488
Validation loss: 1.8556623023043397

Epoch: 5| Step: 7
Training loss: 1.1986939907073975
Validation loss: 1.8809914486382597

Epoch: 5| Step: 8
Training loss: 0.7152526378631592
Validation loss: 1.8400845155921033

Epoch: 5| Step: 9
Training loss: 0.8033553957939148
Validation loss: 1.8897005665686823

Epoch: 5| Step: 10
Training loss: 0.9501131772994995
Validation loss: 1.8677110415633007

Epoch: 196| Step: 0
Training loss: 1.081976056098938
Validation loss: 1.9061832825342815

Epoch: 5| Step: 1
Training loss: 0.8202781677246094
Validation loss: 1.8924946938791583

Epoch: 5| Step: 2
Training loss: 0.5562654733657837
Validation loss: 1.9117702514894548

Epoch: 5| Step: 3
Training loss: 0.9437723159790039
Validation loss: 1.909816086933177

Epoch: 5| Step: 4
Training loss: 1.5560688972473145
Validation loss: 1.879174050464425

Epoch: 5| Step: 5
Training loss: 0.9038801193237305
Validation loss: 1.8066340543890511

Epoch: 5| Step: 6
Training loss: 0.9586564898490906
Validation loss: 1.799939081233035

Epoch: 5| Step: 7
Training loss: 0.9601293802261353
Validation loss: 1.7672948350188553

Epoch: 5| Step: 8
Training loss: 1.051405668258667
Validation loss: 1.7273629711520286

Epoch: 5| Step: 9
Training loss: 1.3043280839920044
Validation loss: 1.7434037077811457

Epoch: 5| Step: 10
Training loss: 0.7719491124153137
Validation loss: 1.7631897644330097

Epoch: 197| Step: 0
Training loss: 0.8019329309463501
Validation loss: 1.8238054244749007

Epoch: 5| Step: 1
Training loss: 0.7405019998550415
Validation loss: 1.8328819749175862

Epoch: 5| Step: 2
Training loss: 1.1059315204620361
Validation loss: 1.8389221737461705

Epoch: 5| Step: 3
Training loss: 1.0707515478134155
Validation loss: 1.814727339693295

Epoch: 5| Step: 4
Training loss: 0.884515106678009
Validation loss: 1.8494354153192172

Epoch: 5| Step: 5
Training loss: 1.1083766222000122
Validation loss: 1.805141718156876

Epoch: 5| Step: 6
Training loss: 1.0944691896438599
Validation loss: 1.79818679184042

Epoch: 5| Step: 7
Training loss: 0.8104826211929321
Validation loss: 1.8357564915892899

Epoch: 5| Step: 8
Training loss: 0.8028343319892883
Validation loss: 1.835345914286952

Epoch: 5| Step: 9
Training loss: 1.1247519254684448
Validation loss: 1.826575703518365

Epoch: 5| Step: 10
Training loss: 1.0097157955169678
Validation loss: 1.8018358202390774

Epoch: 198| Step: 0
Training loss: 0.9781351089477539
Validation loss: 1.8258418395955076

Epoch: 5| Step: 1
Training loss: 1.0570499897003174
Validation loss: 1.810140634095797

Epoch: 5| Step: 2
Training loss: 0.8581401109695435
Validation loss: 1.798019455325219

Epoch: 5| Step: 3
Training loss: 0.7783044576644897
Validation loss: 1.8232098087187736

Epoch: 5| Step: 4
Training loss: 0.7094430923461914
Validation loss: 1.8415314612850067

Epoch: 5| Step: 5
Training loss: 1.2248404026031494
Validation loss: 1.817276552159299

Epoch: 5| Step: 6
Training loss: 1.0875362157821655
Validation loss: 1.8351927277862385

Epoch: 5| Step: 7
Training loss: 0.8498112559318542
Validation loss: 1.801514647340262

Epoch: 5| Step: 8
Training loss: 0.8199032545089722
Validation loss: 1.8025546599459905

Epoch: 5| Step: 9
Training loss: 1.2450830936431885
Validation loss: 1.8139005912247526

Epoch: 5| Step: 10
Training loss: 0.6786724328994751
Validation loss: 1.8267379755614905

Epoch: 199| Step: 0
Training loss: 1.078796148300171
Validation loss: 1.8138373026283838

Epoch: 5| Step: 1
Training loss: 1.0749248266220093
Validation loss: 1.8141184776060042

Epoch: 5| Step: 2
Training loss: 0.9745383262634277
Validation loss: 1.8413798706505888

Epoch: 5| Step: 3
Training loss: 0.4161037802696228
Validation loss: 1.7924056950435843

Epoch: 5| Step: 4
Training loss: 0.9703792333602905
Validation loss: 1.772365887959798

Epoch: 5| Step: 5
Training loss: 1.029939889907837
Validation loss: 1.7535093112658429

Epoch: 5| Step: 6
Training loss: 0.6814614534378052
Validation loss: 1.751016075893115

Epoch: 5| Step: 7
Training loss: 0.8416403532028198
Validation loss: 1.7336768360548123

Epoch: 5| Step: 8
Training loss: 0.9745875597000122
Validation loss: 1.7689718700224353

Epoch: 5| Step: 9
Training loss: 1.0310479402542114
Validation loss: 1.7930844560746224

Epoch: 5| Step: 10
Training loss: 1.273613452911377
Validation loss: 1.8286344953762588

Epoch: 200| Step: 0
Training loss: 0.9504388570785522
Validation loss: 1.859522004281321

Epoch: 5| Step: 1
Training loss: 0.8259260058403015
Validation loss: 1.8630178961702573

Epoch: 5| Step: 2
Training loss: 1.1446260213851929
Validation loss: 1.8762104472806376

Epoch: 5| Step: 3
Training loss: 0.5739462971687317
Validation loss: 1.847032630315391

Epoch: 5| Step: 4
Training loss: 0.7652167677879333
Validation loss: 1.8504901637313187

Epoch: 5| Step: 5
Training loss: 1.0764083862304688
Validation loss: 1.834703044224811

Epoch: 5| Step: 6
Training loss: 0.40948399901390076
Validation loss: 1.8031144603606193

Epoch: 5| Step: 7
Training loss: 1.2154500484466553
Validation loss: 1.8011502053148003

Epoch: 5| Step: 8
Training loss: 1.3228321075439453
Validation loss: 1.7950365133182977

Epoch: 5| Step: 9
Training loss: 1.059227705001831
Validation loss: 1.845419741445972

Epoch: 5| Step: 10
Training loss: 0.5503262877464294
Validation loss: 1.886490757747363

Testing loss: 2.0220785803265042
