Epoch: 1| Step: 0
Training loss: 5.312206268310547
Validation loss: 5.123742821396038

Epoch: 5| Step: 1
Training loss: 4.836066246032715
Validation loss: 5.10320540910126

Epoch: 5| Step: 2
Training loss: 5.989378452301025
Validation loss: 5.085011266892956

Epoch: 5| Step: 3
Training loss: 5.527426242828369
Validation loss: 5.066360550542032

Epoch: 5| Step: 4
Training loss: 5.954399108886719
Validation loss: 5.044707026532901

Epoch: 5| Step: 5
Training loss: 3.8608741760253906
Validation loss: 5.020514411310995

Epoch: 5| Step: 6
Training loss: 3.2412362098693848
Validation loss: 4.992764078160768

Epoch: 5| Step: 7
Training loss: 4.450536251068115
Validation loss: 4.961738263407061

Epoch: 5| Step: 8
Training loss: 4.056290626525879
Validation loss: 4.926426077401766

Epoch: 5| Step: 9
Training loss: 5.386906623840332
Validation loss: 4.8862614118924705

Epoch: 5| Step: 10
Training loss: 4.1627326011657715
Validation loss: 4.841346289521905

Epoch: 2| Step: 0
Training loss: 4.12445592880249
Validation loss: 4.7909005893174035

Epoch: 5| Step: 1
Training loss: 4.326340198516846
Validation loss: 4.7360433711800525

Epoch: 5| Step: 2
Training loss: 4.523919105529785
Validation loss: 4.678410273726269

Epoch: 5| Step: 3
Training loss: 5.099051475524902
Validation loss: 4.6169693803274505

Epoch: 5| Step: 4
Training loss: 4.231804847717285
Validation loss: 4.55134439981112

Epoch: 5| Step: 5
Training loss: 4.020785331726074
Validation loss: 4.482949277406098

Epoch: 5| Step: 6
Training loss: 4.3412065505981445
Validation loss: 4.412455543395011

Epoch: 5| Step: 7
Training loss: 4.589099884033203
Validation loss: 4.342200976546093

Epoch: 5| Step: 8
Training loss: 3.8657748699188232
Validation loss: 4.273206664669898

Epoch: 5| Step: 9
Training loss: 3.6806514263153076
Validation loss: 4.2005412552946355

Epoch: 5| Step: 10
Training loss: 4.196475982666016
Validation loss: 4.129835287729899

Epoch: 3| Step: 0
Training loss: 3.447929859161377
Validation loss: 4.059016145685668

Epoch: 5| Step: 1
Training loss: 4.4864935874938965
Validation loss: 3.981383372378606

Epoch: 5| Step: 2
Training loss: 5.076290130615234
Validation loss: 3.9072885513305664

Epoch: 5| Step: 3
Training loss: 4.088405609130859
Validation loss: 3.837996575140184

Epoch: 5| Step: 4
Training loss: 3.4345264434814453
Validation loss: 3.7710236041776595

Epoch: 5| Step: 5
Training loss: 3.304288864135742
Validation loss: 3.7064597529749714

Epoch: 5| Step: 6
Training loss: 3.2080206871032715
Validation loss: 3.655592026249055

Epoch: 5| Step: 7
Training loss: 3.2884535789489746
Validation loss: 3.5961738965844594

Epoch: 5| Step: 8
Training loss: 3.1989893913269043
Validation loss: 3.5413463705329487

Epoch: 5| Step: 9
Training loss: 2.896095037460327
Validation loss: 3.4963467146760676

Epoch: 5| Step: 10
Training loss: 3.7231218814849854
Validation loss: 3.4593874997990106

Epoch: 4| Step: 0
Training loss: 3.036781072616577
Validation loss: 3.4241790130574215

Epoch: 5| Step: 1
Training loss: 4.085982799530029
Validation loss: 3.389068559933734

Epoch: 5| Step: 2
Training loss: 3.4743175506591797
Validation loss: 3.3587488179565756

Epoch: 5| Step: 3
Training loss: 2.796738862991333
Validation loss: 3.329444326380248

Epoch: 5| Step: 4
Training loss: 3.3573222160339355
Validation loss: 3.3026948282795567

Epoch: 5| Step: 5
Training loss: 4.5833587646484375
Validation loss: 3.294137580420381

Epoch: 5| Step: 6
Training loss: 4.1944427490234375
Validation loss: 3.257681082653743

Epoch: 5| Step: 7
Training loss: 2.3437459468841553
Validation loss: 3.2367124865131993

Epoch: 5| Step: 8
Training loss: 2.074713945388794
Validation loss: 3.213521167796145

Epoch: 5| Step: 9
Training loss: 3.040785551071167
Validation loss: 3.1984572179855837

Epoch: 5| Step: 10
Training loss: 2.8026978969573975
Validation loss: 3.1857205744712584

Epoch: 5| Step: 0
Training loss: 4.215081214904785
Validation loss: 3.1743397866525958

Epoch: 5| Step: 1
Training loss: 4.197977542877197
Validation loss: 3.1596972916715886

Epoch: 5| Step: 2
Training loss: 3.098688840866089
Validation loss: 3.151265703221803

Epoch: 5| Step: 3
Training loss: 3.112260580062866
Validation loss: 3.131037107077978

Epoch: 5| Step: 4
Training loss: 3.4482874870300293
Validation loss: 3.1198856061504734

Epoch: 5| Step: 5
Training loss: 2.352405548095703
Validation loss: 3.105385664970644

Epoch: 5| Step: 6
Training loss: 2.6736807823181152
Validation loss: 3.0987345326331353

Epoch: 5| Step: 7
Training loss: 2.0578107833862305
Validation loss: 3.0885769346708893

Epoch: 5| Step: 8
Training loss: 2.8288016319274902
Validation loss: 3.0996265616468204

Epoch: 5| Step: 9
Training loss: 3.4769370555877686
Validation loss: 3.0948089374009

Epoch: 5| Step: 10
Training loss: 3.1252171993255615
Validation loss: 3.1069463196621148

Epoch: 6| Step: 0
Training loss: 2.9968314170837402
Validation loss: 3.0862365973893033

Epoch: 5| Step: 1
Training loss: 2.442610025405884
Validation loss: 3.073737859725952

Epoch: 5| Step: 2
Training loss: 2.637366771697998
Validation loss: 3.0535533812738236

Epoch: 5| Step: 3
Training loss: 3.0397136211395264
Validation loss: 3.03245150145664

Epoch: 5| Step: 4
Training loss: 3.3482258319854736
Validation loss: 3.011588352982716

Epoch: 5| Step: 5
Training loss: 4.031636714935303
Validation loss: 2.99993831880631

Epoch: 5| Step: 6
Training loss: 4.66769552230835
Validation loss: 2.990018775386195

Epoch: 5| Step: 7
Training loss: 2.1221041679382324
Validation loss: 2.9801283344145744

Epoch: 5| Step: 8
Training loss: 3.1892852783203125
Validation loss: 2.972322074315881

Epoch: 5| Step: 9
Training loss: 2.9354248046875
Validation loss: 2.9696176821185696

Epoch: 5| Step: 10
Training loss: 2.2613344192504883
Validation loss: 2.9647447601441415

Epoch: 7| Step: 0
Training loss: 3.267461061477661
Validation loss: 2.9566628676588818

Epoch: 5| Step: 1
Training loss: 4.074713230133057
Validation loss: 2.939989556548416

Epoch: 5| Step: 2
Training loss: 3.258037567138672
Validation loss: 2.9236784314596527

Epoch: 5| Step: 3
Training loss: 2.4573140144348145
Validation loss: 2.911149086490754

Epoch: 5| Step: 4
Training loss: 2.7206778526306152
Validation loss: 2.900251257804132

Epoch: 5| Step: 5
Training loss: 2.6000685691833496
Validation loss: 2.9011629089232414

Epoch: 5| Step: 6
Training loss: 2.498990058898926
Validation loss: 2.9071412496669318

Epoch: 5| Step: 7
Training loss: 2.627943992614746
Validation loss: 2.9104980396968063

Epoch: 5| Step: 8
Training loss: 2.9778072834014893
Validation loss: 2.899729031388478

Epoch: 5| Step: 9
Training loss: 3.074653387069702
Validation loss: 2.8902825386293474

Epoch: 5| Step: 10
Training loss: 3.5689194202423096
Validation loss: 2.882434583479358

Epoch: 8| Step: 0
Training loss: 2.4302310943603516
Validation loss: 2.869081453610492

Epoch: 5| Step: 1
Training loss: 3.206820011138916
Validation loss: 2.8562034124969156

Epoch: 5| Step: 2
Training loss: 2.8313183784484863
Validation loss: 2.848312685566564

Epoch: 5| Step: 3
Training loss: 3.743093967437744
Validation loss: 2.836108530721357

Epoch: 5| Step: 4
Training loss: 3.0297834873199463
Validation loss: 2.8316470781962075

Epoch: 5| Step: 5
Training loss: 2.7641215324401855
Validation loss: 2.822493140415479

Epoch: 5| Step: 6
Training loss: 3.059511661529541
Validation loss: 2.819999799933485

Epoch: 5| Step: 7
Training loss: 3.456303834915161
Validation loss: 2.8131819694272933

Epoch: 5| Step: 8
Training loss: 2.9111249446868896
Validation loss: 2.810776056781892

Epoch: 5| Step: 9
Training loss: 2.546553134918213
Validation loss: 2.8091751349869596

Epoch: 5| Step: 10
Training loss: 2.3666439056396484
Validation loss: 2.801252370239586

Epoch: 9| Step: 0
Training loss: 3.5247740745544434
Validation loss: 2.7971938733131654

Epoch: 5| Step: 1
Training loss: 2.5261151790618896
Validation loss: 2.7894416137408187

Epoch: 5| Step: 2
Training loss: 2.8386380672454834
Validation loss: 2.785076223393922

Epoch: 5| Step: 3
Training loss: 3.0022237300872803
Validation loss: 2.773252309009593

Epoch: 5| Step: 4
Training loss: 2.9435322284698486
Validation loss: 2.7645446843998407

Epoch: 5| Step: 5
Training loss: 3.547337293624878
Validation loss: 2.7659376846846713

Epoch: 5| Step: 6
Training loss: 2.8235602378845215
Validation loss: 2.7518543120353454

Epoch: 5| Step: 7
Training loss: 2.6567208766937256
Validation loss: 2.7570493375101397

Epoch: 5| Step: 8
Training loss: 2.1577744483947754
Validation loss: 2.757396585197859

Epoch: 5| Step: 9
Training loss: 3.2210888862609863
Validation loss: 2.7529687112377537

Epoch: 5| Step: 10
Training loss: 2.7308461666107178
Validation loss: 2.7500594841536654

Epoch: 10| Step: 0
Training loss: 2.8560354709625244
Validation loss: 2.7447650612041516

Epoch: 5| Step: 1
Training loss: 3.034128189086914
Validation loss: 2.760711141811904

Epoch: 5| Step: 2
Training loss: 2.6360256671905518
Validation loss: 2.732392364932645

Epoch: 5| Step: 3
Training loss: 3.497072219848633
Validation loss: 2.726519548764793

Epoch: 5| Step: 4
Training loss: 2.39982008934021
Validation loss: 2.71349601335423

Epoch: 5| Step: 5
Training loss: 3.210566759109497
Validation loss: 2.708522004465903

Epoch: 5| Step: 6
Training loss: 2.6696724891662598
Validation loss: 2.7035407994383123

Epoch: 5| Step: 7
Training loss: 2.4701249599456787
Validation loss: 2.7016195430550525

Epoch: 5| Step: 8
Training loss: 2.105762243270874
Validation loss: 2.695777352138232

Epoch: 5| Step: 9
Training loss: 3.5943210124969482
Validation loss: 2.695703298814835

Epoch: 5| Step: 10
Training loss: 3.236116409301758
Validation loss: 2.690648043027488

Epoch: 11| Step: 0
Training loss: 2.5034031867980957
Validation loss: 2.6894153266824703

Epoch: 5| Step: 1
Training loss: 4.359214782714844
Validation loss: 2.6850418352311656

Epoch: 5| Step: 2
Training loss: 2.894868850708008
Validation loss: 2.684965697667932

Epoch: 5| Step: 3
Training loss: 2.722607374191284
Validation loss: 2.6791274547576904

Epoch: 5| Step: 4
Training loss: 3.2794620990753174
Validation loss: 2.6785088867269535

Epoch: 5| Step: 5
Training loss: 2.1458065509796143
Validation loss: 2.6758854209735827

Epoch: 5| Step: 6
Training loss: 2.7377445697784424
Validation loss: 2.669948882954095

Epoch: 5| Step: 7
Training loss: 2.5264832973480225
Validation loss: 2.6610425313313804

Epoch: 5| Step: 8
Training loss: 2.9944348335266113
Validation loss: 2.6524726831784813

Epoch: 5| Step: 9
Training loss: 2.3621914386749268
Validation loss: 2.6565035850771013

Epoch: 5| Step: 10
Training loss: 2.816378355026245
Validation loss: 2.6469948137960126

Epoch: 12| Step: 0
Training loss: 2.2977261543273926
Validation loss: 2.6500325433669554

Epoch: 5| Step: 1
Training loss: 2.160600423812866
Validation loss: 2.6717172591916976

Epoch: 5| Step: 2
Training loss: 2.8028388023376465
Validation loss: 2.6783876419067383

Epoch: 5| Step: 3
Training loss: 2.9915146827697754
Validation loss: 2.659961182584045

Epoch: 5| Step: 4
Training loss: 3.2124075889587402
Validation loss: 2.647756204810194

Epoch: 5| Step: 5
Training loss: 3.3261399269104004
Validation loss: 2.6303523099550636

Epoch: 5| Step: 6
Training loss: 2.6675350666046143
Validation loss: 2.619871062617148

Epoch: 5| Step: 7
Training loss: 2.9022154808044434
Validation loss: 2.628182521430395

Epoch: 5| Step: 8
Training loss: 2.961986541748047
Validation loss: 2.646061817804972

Epoch: 5| Step: 9
Training loss: 2.5316882133483887
Validation loss: 2.6550445454095

Epoch: 5| Step: 10
Training loss: 3.4215240478515625
Validation loss: 2.6418687117997037

Epoch: 13| Step: 0
Training loss: 2.901508331298828
Validation loss: 2.6245781247333815

Epoch: 5| Step: 1
Training loss: 3.3199844360351562
Validation loss: 2.6003962665475826

Epoch: 5| Step: 2
Training loss: 2.1606602668762207
Validation loss: 2.598221666069441

Epoch: 5| Step: 3
Training loss: 2.551204204559326
Validation loss: 2.6100732921272196

Epoch: 5| Step: 4
Training loss: 2.2015204429626465
Validation loss: 2.61014328464385

Epoch: 5| Step: 5
Training loss: 2.7141642570495605
Validation loss: 2.60297389184275

Epoch: 5| Step: 6
Training loss: 2.9352755546569824
Validation loss: 2.6022147645232496

Epoch: 5| Step: 7
Training loss: 2.6709647178649902
Validation loss: 2.5993919987832346

Epoch: 5| Step: 8
Training loss: 3.035041332244873
Validation loss: 2.598737580801851

Epoch: 5| Step: 9
Training loss: 2.9277758598327637
Validation loss: 2.5938511638231176

Epoch: 5| Step: 10
Training loss: 3.4791247844696045
Validation loss: 2.5817246462709162

Epoch: 14| Step: 0
Training loss: 2.476848602294922
Validation loss: 2.5738308583536456

Epoch: 5| Step: 1
Training loss: 3.094635009765625
Validation loss: 2.5703310748582244

Epoch: 5| Step: 2
Training loss: 3.2648766040802
Validation loss: 2.5685487383155414

Epoch: 5| Step: 3
Training loss: 2.7249019145965576
Validation loss: 2.567024761630643

Epoch: 5| Step: 4
Training loss: 2.586725950241089
Validation loss: 2.598073115912817

Epoch: 5| Step: 5
Training loss: 2.655938148498535
Validation loss: 2.5590042734658844

Epoch: 5| Step: 6
Training loss: 3.0898537635803223
Validation loss: 2.5447736901621663

Epoch: 5| Step: 7
Training loss: 2.5415265560150146
Validation loss: 2.5444047835565384

Epoch: 5| Step: 8
Training loss: 2.8105876445770264
Validation loss: 2.5500526197494997

Epoch: 5| Step: 9
Training loss: 2.5636401176452637
Validation loss: 2.546268786153486

Epoch: 5| Step: 10
Training loss: 2.6198575496673584
Validation loss: 2.546462805040421

Epoch: 15| Step: 0
Training loss: 2.515786647796631
Validation loss: 2.5473064684098765

Epoch: 5| Step: 1
Training loss: 2.703230381011963
Validation loss: 2.56167273623969

Epoch: 5| Step: 2
Training loss: 2.740128993988037
Validation loss: 2.559190075884583

Epoch: 5| Step: 3
Training loss: 3.159682512283325
Validation loss: 2.546139717102051

Epoch: 5| Step: 4
Training loss: 2.839942693710327
Validation loss: 2.544994895176221

Epoch: 5| Step: 5
Training loss: 2.7032394409179688
Validation loss: 2.5290210682858705

Epoch: 5| Step: 6
Training loss: 2.180419921875
Validation loss: 2.5259421256280716

Epoch: 5| Step: 7
Training loss: 3.5852813720703125
Validation loss: 2.527890254092473

Epoch: 5| Step: 8
Training loss: 2.611401081085205
Validation loss: 2.5163620543736283

Epoch: 5| Step: 9
Training loss: 2.8741259574890137
Validation loss: 2.511345286523142

Epoch: 5| Step: 10
Training loss: 2.1308889389038086
Validation loss: 2.505205903002011

Epoch: 16| Step: 0
Training loss: 2.5470728874206543
Validation loss: 2.508985093844834

Epoch: 5| Step: 1
Training loss: 3.4671218395233154
Validation loss: 2.5160585987952446

Epoch: 5| Step: 2
Training loss: 2.432954788208008
Validation loss: 2.513704835727651

Epoch: 5| Step: 3
Training loss: 2.348182439804077
Validation loss: 2.502129998258365

Epoch: 5| Step: 4
Training loss: 2.1568541526794434
Validation loss: 2.4986828604052143

Epoch: 5| Step: 5
Training loss: 2.697692394256592
Validation loss: 2.4903970456892446

Epoch: 5| Step: 6
Training loss: 2.462101697921753
Validation loss: 2.488611372568274

Epoch: 5| Step: 7
Training loss: 2.936753034591675
Validation loss: 2.488936229418683

Epoch: 5| Step: 8
Training loss: 2.6585259437561035
Validation loss: 2.489641010120351

Epoch: 5| Step: 9
Training loss: 3.352612018585205
Validation loss: 2.4885727397857176

Epoch: 5| Step: 10
Training loss: 2.8747353553771973
Validation loss: 2.4914392014985443

Epoch: 17| Step: 0
Training loss: 2.6664676666259766
Validation loss: 2.488985658973776

Epoch: 5| Step: 1
Training loss: 2.621396541595459
Validation loss: 2.480736824773973

Epoch: 5| Step: 2
Training loss: 1.854541540145874
Validation loss: 2.4708731405196653

Epoch: 5| Step: 3
Training loss: 2.576137065887451
Validation loss: 2.4762147780387633

Epoch: 5| Step: 4
Training loss: 2.657787322998047
Validation loss: 2.4982227663840018

Epoch: 5| Step: 5
Training loss: 2.728598117828369
Validation loss: 2.504080935191083

Epoch: 5| Step: 6
Training loss: 3.2753899097442627
Validation loss: 2.493305439590126

Epoch: 5| Step: 7
Training loss: 3.3348491191864014
Validation loss: 2.4669571256124847

Epoch: 5| Step: 8
Training loss: 2.722883701324463
Validation loss: 2.461495291802191

Epoch: 5| Step: 9
Training loss: 2.266669750213623
Validation loss: 2.465134720648489

Epoch: 5| Step: 10
Training loss: 3.1781885623931885
Validation loss: 2.4666972878158733

Epoch: 18| Step: 0
Training loss: 3.2357640266418457
Validation loss: 2.471920790210847

Epoch: 5| Step: 1
Training loss: 2.854154109954834
Validation loss: 2.488253329389839

Epoch: 5| Step: 2
Training loss: 3.083055257797241
Validation loss: 2.489130735397339

Epoch: 5| Step: 3
Training loss: 2.5342137813568115
Validation loss: 2.4623721338087514

Epoch: 5| Step: 4
Training loss: 2.8446905612945557
Validation loss: 2.461692105057419

Epoch: 5| Step: 5
Training loss: 3.1930294036865234
Validation loss: 2.4559591841954056

Epoch: 5| Step: 6
Training loss: 2.7927498817443848
Validation loss: 2.4656881440070366

Epoch: 5| Step: 7
Training loss: 1.8738842010498047
Validation loss: 2.4665709182780278

Epoch: 5| Step: 8
Training loss: 2.093846082687378
Validation loss: 2.466136129953528

Epoch: 5| Step: 9
Training loss: 2.6778111457824707
Validation loss: 2.463465693176434

Epoch: 5| Step: 10
Training loss: 2.42195200920105
Validation loss: 2.460384871370049

Epoch: 19| Step: 0
Training loss: 2.349179267883301
Validation loss: 2.4667862153822377

Epoch: 5| Step: 1
Training loss: 2.896574020385742
Validation loss: 2.4883025077081498

Epoch: 5| Step: 2
Training loss: 3.0348403453826904
Validation loss: 2.46391999336981

Epoch: 5| Step: 3
Training loss: 2.842846393585205
Validation loss: 2.4554971469345914

Epoch: 5| Step: 4
Training loss: 2.370201587677002
Validation loss: 2.4608764956074376

Epoch: 5| Step: 5
Training loss: 2.53922700881958
Validation loss: 2.469035435748357

Epoch: 5| Step: 6
Training loss: 2.3394036293029785
Validation loss: 2.4732629253018286

Epoch: 5| Step: 7
Training loss: 2.5535190105438232
Validation loss: 2.4745099698343584

Epoch: 5| Step: 8
Training loss: 2.706526517868042
Validation loss: 2.4730832756206556

Epoch: 5| Step: 9
Training loss: 3.034430503845215
Validation loss: 2.476350543319538

Epoch: 5| Step: 10
Training loss: 2.8960025310516357
Validation loss: 2.4513931492323517

Epoch: 20| Step: 0
Training loss: 2.9344708919525146
Validation loss: 2.433703450746434

Epoch: 5| Step: 1
Training loss: 3.1401448249816895
Validation loss: 2.45284447105982

Epoch: 5| Step: 2
Training loss: 2.2566096782684326
Validation loss: 2.458215739137383

Epoch: 5| Step: 3
Training loss: 3.58604097366333
Validation loss: 2.4442556442752963

Epoch: 5| Step: 4
Training loss: 2.5439019203186035
Validation loss: 2.4420358545036724

Epoch: 5| Step: 5
Training loss: 3.1801669597625732
Validation loss: 2.4695701829848753

Epoch: 5| Step: 6
Training loss: 2.2161948680877686
Validation loss: 2.498234769349457

Epoch: 5| Step: 7
Training loss: 2.1151556968688965
Validation loss: 2.5459939766955633

Epoch: 5| Step: 8
Training loss: 2.753051519393921
Validation loss: 2.4819633473632154

Epoch: 5| Step: 9
Training loss: 2.3522133827209473
Validation loss: 2.4414327080531786

Epoch: 5| Step: 10
Training loss: 2.4454703330993652
Validation loss: 2.438017829771965

Epoch: 21| Step: 0
Training loss: 2.9566636085510254
Validation loss: 2.466202797428254

Epoch: 5| Step: 1
Training loss: 3.1243579387664795
Validation loss: 2.494079887226064

Epoch: 5| Step: 2
Training loss: 2.644636631011963
Validation loss: 2.4887972467689106

Epoch: 5| Step: 3
Training loss: 2.9942727088928223
Validation loss: 2.488347920038367

Epoch: 5| Step: 4
Training loss: 2.312368869781494
Validation loss: 2.488345689671014

Epoch: 5| Step: 5
Training loss: 2.600116729736328
Validation loss: 2.4965753683479885

Epoch: 5| Step: 6
Training loss: 2.3878936767578125
Validation loss: 2.488607434816258

Epoch: 5| Step: 7
Training loss: 2.1325299739837646
Validation loss: 2.498140852938416

Epoch: 5| Step: 8
Training loss: 2.7631962299346924
Validation loss: 2.4677381912867227

Epoch: 5| Step: 9
Training loss: 2.9168448448181152
Validation loss: 2.4347800439403904

Epoch: 5| Step: 10
Training loss: 2.956059694290161
Validation loss: 2.4170336466963573

Epoch: 22| Step: 0
Training loss: 2.760234832763672
Validation loss: 2.4159910114862586

Epoch: 5| Step: 1
Training loss: 1.6317278146743774
Validation loss: 2.423777808425247

Epoch: 5| Step: 2
Training loss: 3.519652843475342
Validation loss: 2.4357465031326457

Epoch: 5| Step: 3
Training loss: 3.2067229747772217
Validation loss: 2.446262413455594

Epoch: 5| Step: 4
Training loss: 2.305043935775757
Validation loss: 2.4321133244422173

Epoch: 5| Step: 5
Training loss: 3.1723029613494873
Validation loss: 2.4249498715964695

Epoch: 5| Step: 6
Training loss: 2.3080742359161377
Validation loss: 2.4230206551090365

Epoch: 5| Step: 7
Training loss: 3.0673201084136963
Validation loss: 2.4297596998112176

Epoch: 5| Step: 8
Training loss: 2.897291421890259
Validation loss: 2.425737806545791

Epoch: 5| Step: 9
Training loss: 2.2521796226501465
Validation loss: 2.4304246953738633

Epoch: 5| Step: 10
Training loss: 2.2084147930145264
Validation loss: 2.437193875671715

Epoch: 23| Step: 0
Training loss: 2.2142040729522705
Validation loss: 2.4498319190035582

Epoch: 5| Step: 1
Training loss: 3.2149500846862793
Validation loss: 2.4644657642610612

Epoch: 5| Step: 2
Training loss: 2.9813969135284424
Validation loss: 2.471292280381726

Epoch: 5| Step: 3
Training loss: 2.6058197021484375
Validation loss: 2.4646721552777033

Epoch: 5| Step: 4
Training loss: 2.6738884449005127
Validation loss: 2.4403496865303285

Epoch: 5| Step: 5
Training loss: 2.9569413661956787
Validation loss: 2.420366615377447

Epoch: 5| Step: 6
Training loss: 3.1515860557556152
Validation loss: 2.403530154176938

Epoch: 5| Step: 7
Training loss: 2.1928293704986572
Validation loss: 2.40075030121752

Epoch: 5| Step: 8
Training loss: 2.1998724937438965
Validation loss: 2.404691926894649

Epoch: 5| Step: 9
Training loss: 2.5392041206359863
Validation loss: 2.4077220142528577

Epoch: 5| Step: 10
Training loss: 2.534363269805908
Validation loss: 2.416856053054974

Epoch: 24| Step: 0
Training loss: 2.245786190032959
Validation loss: 2.4008987360103156

Epoch: 5| Step: 1
Training loss: 2.704329013824463
Validation loss: 2.4098181955276

Epoch: 5| Step: 2
Training loss: 2.711564540863037
Validation loss: 2.4533297143956667

Epoch: 5| Step: 3
Training loss: 2.539649248123169
Validation loss: 2.5025693780632428

Epoch: 5| Step: 4
Training loss: 2.550565242767334
Validation loss: 2.4968542104126303

Epoch: 5| Step: 5
Training loss: 2.9930927753448486
Validation loss: 2.4642177679205455

Epoch: 5| Step: 6
Training loss: 2.962235927581787
Validation loss: 2.4294678959795224

Epoch: 5| Step: 7
Training loss: 2.1993117332458496
Validation loss: 2.407907275743382

Epoch: 5| Step: 8
Training loss: 2.512334108352661
Validation loss: 2.4073265124392766

Epoch: 5| Step: 9
Training loss: 3.188140392303467
Validation loss: 2.406694132794616

Epoch: 5| Step: 10
Training loss: 2.7971324920654297
Validation loss: 2.4026518201315277

Epoch: 25| Step: 0
Training loss: 2.760911464691162
Validation loss: 2.400896863270831

Epoch: 5| Step: 1
Training loss: 2.3318705558776855
Validation loss: 2.4000146568462415

Epoch: 5| Step: 2
Training loss: 3.057410717010498
Validation loss: 2.3886104911886235

Epoch: 5| Step: 3
Training loss: 2.447828769683838
Validation loss: 2.3924679602346113

Epoch: 5| Step: 4
Training loss: 1.9694782495498657
Validation loss: 2.407947281355499

Epoch: 5| Step: 5
Training loss: 3.2947421073913574
Validation loss: 2.465894147913943

Epoch: 5| Step: 6
Training loss: 2.4421420097351074
Validation loss: 2.5096495920611965

Epoch: 5| Step: 7
Training loss: 2.7792913913726807
Validation loss: 2.5279216894539456

Epoch: 5| Step: 8
Training loss: 2.746809720993042
Validation loss: 2.464028917333131

Epoch: 5| Step: 9
Training loss: 2.6813302040100098
Validation loss: 2.4026425346251457

Epoch: 5| Step: 10
Training loss: 2.824105739593506
Validation loss: 2.387311133005286

Epoch: 26| Step: 0
Training loss: 2.654433250427246
Validation loss: 2.386041630980789

Epoch: 5| Step: 1
Training loss: 2.6945722103118896
Validation loss: 2.397827304819579

Epoch: 5| Step: 2
Training loss: 2.1709017753601074
Validation loss: 2.4161154224026586

Epoch: 5| Step: 3
Training loss: 3.072993516921997
Validation loss: 2.4415946058047715

Epoch: 5| Step: 4
Training loss: 2.897425413131714
Validation loss: 2.425647538195374

Epoch: 5| Step: 5
Training loss: 2.8709306716918945
Validation loss: 2.3924239002248293

Epoch: 5| Step: 6
Training loss: 2.864851713180542
Validation loss: 2.3838753930984007

Epoch: 5| Step: 7
Training loss: 2.8041608333587646
Validation loss: 2.3888819704773607

Epoch: 5| Step: 8
Training loss: 2.21897029876709
Validation loss: 2.3931553466345674

Epoch: 5| Step: 9
Training loss: 2.110764503479004
Validation loss: 2.3995488484700522

Epoch: 5| Step: 10
Training loss: 2.8404526710510254
Validation loss: 2.4143738259551344

Epoch: 27| Step: 0
Training loss: 2.5659260749816895
Validation loss: 2.4409469430164625

Epoch: 5| Step: 1
Training loss: 2.517073392868042
Validation loss: 2.4845157784800374

Epoch: 5| Step: 2
Training loss: 2.0677649974823
Validation loss: 2.488226441926854

Epoch: 5| Step: 3
Training loss: 2.8943798542022705
Validation loss: 2.4633401491308726

Epoch: 5| Step: 4
Training loss: 2.3912148475646973
Validation loss: 2.463810092659407

Epoch: 5| Step: 5
Training loss: 3.0711123943328857
Validation loss: 2.4920206249401136

Epoch: 5| Step: 6
Training loss: 2.4937353134155273
Validation loss: 2.505459334260674

Epoch: 5| Step: 7
Training loss: 3.0066936016082764
Validation loss: 2.530942693833382

Epoch: 5| Step: 8
Training loss: 2.945828437805176
Validation loss: 2.5052950382232666

Epoch: 5| Step: 9
Training loss: 2.8478007316589355
Validation loss: 2.4369653014726538

Epoch: 5| Step: 10
Training loss: 2.5551881790161133
Validation loss: 2.404887307074762

Epoch: 28| Step: 0
Training loss: 2.2681822776794434
Validation loss: 2.3860944778688493

Epoch: 5| Step: 1
Training loss: 2.5265278816223145
Validation loss: 2.395865555732481

Epoch: 5| Step: 2
Training loss: 2.2444770336151123
Validation loss: 2.394793671946372

Epoch: 5| Step: 3
Training loss: 2.9458065032958984
Validation loss: 2.4048466938798145

Epoch: 5| Step: 4
Training loss: 1.9124675989151
Validation loss: 2.4035551830004622

Epoch: 5| Step: 5
Training loss: 2.846421718597412
Validation loss: 2.3940373518133677

Epoch: 5| Step: 6
Training loss: 3.075181245803833
Validation loss: 2.4057745856623494

Epoch: 5| Step: 7
Training loss: 2.830049514770508
Validation loss: 2.4148034844347226

Epoch: 5| Step: 8
Training loss: 2.633035898208618
Validation loss: 2.4630586665163756

Epoch: 5| Step: 9
Training loss: 3.071460247039795
Validation loss: 2.4963742148491646

Epoch: 5| Step: 10
Training loss: 2.7532618045806885
Validation loss: 2.476889643617856

Epoch: 29| Step: 0
Training loss: 2.8718674182891846
Validation loss: 2.4737466842897478

Epoch: 5| Step: 1
Training loss: 2.467623472213745
Validation loss: 2.457835087212183

Epoch: 5| Step: 2
Training loss: 2.2054154872894287
Validation loss: 2.4577952405457855

Epoch: 5| Step: 3
Training loss: 2.597581386566162
Validation loss: 2.4641637814942228

Epoch: 5| Step: 4
Training loss: 2.693378210067749
Validation loss: 2.447968372734644

Epoch: 5| Step: 5
Training loss: 2.351821184158325
Validation loss: 2.448305347914337

Epoch: 5| Step: 6
Training loss: 2.9658825397491455
Validation loss: 2.4479486224471882

Epoch: 5| Step: 7
Training loss: 2.829472303390503
Validation loss: 2.450705546204762

Epoch: 5| Step: 8
Training loss: 3.025714874267578
Validation loss: 2.4418956989883096

Epoch: 5| Step: 9
Training loss: 2.290590763092041
Validation loss: 2.4283262811681277

Epoch: 5| Step: 10
Training loss: 3.0684914588928223
Validation loss: 2.4242037239895073

Epoch: 30| Step: 0
Training loss: 2.6522839069366455
Validation loss: 2.4175560371850127

Epoch: 5| Step: 1
Training loss: 2.728266477584839
Validation loss: 2.4121614963777605

Epoch: 5| Step: 2
Training loss: 2.9329075813293457
Validation loss: 2.4022802281123337

Epoch: 5| Step: 3
Training loss: 2.473935604095459
Validation loss: 2.385618725130635

Epoch: 5| Step: 4
Training loss: 2.800445556640625
Validation loss: 2.3698577855222966

Epoch: 5| Step: 5
Training loss: 2.5460829734802246
Validation loss: 2.3660091636001424

Epoch: 5| Step: 6
Training loss: 2.2120583057403564
Validation loss: 2.3632044279447166

Epoch: 5| Step: 7
Training loss: 2.8677101135253906
Validation loss: 2.364205798795146

Epoch: 5| Step: 8
Training loss: 2.1330623626708984
Validation loss: 2.344676084415887

Epoch: 5| Step: 9
Training loss: 2.8657867908477783
Validation loss: 2.3472599649942048

Epoch: 5| Step: 10
Training loss: 2.556325912475586
Validation loss: 2.339559990872619

Epoch: 31| Step: 0
Training loss: 2.5135140419006348
Validation loss: 2.3435006680027133

Epoch: 5| Step: 1
Training loss: 2.6656582355499268
Validation loss: 2.343827438610856

Epoch: 5| Step: 2
Training loss: 2.2248010635375977
Validation loss: 2.3456867638454644

Epoch: 5| Step: 3
Training loss: 3.033221483230591
Validation loss: 2.361756476022864

Epoch: 5| Step: 4
Training loss: 2.0221941471099854
Validation loss: 2.360518786215013

Epoch: 5| Step: 5
Training loss: 1.8774759769439697
Validation loss: 2.354586708930231

Epoch: 5| Step: 6
Training loss: 2.6275315284729004
Validation loss: 2.345386871727564

Epoch: 5| Step: 7
Training loss: 3.4256510734558105
Validation loss: 2.3379997361090874

Epoch: 5| Step: 8
Training loss: 3.089031934738159
Validation loss: 2.3372573852539062

Epoch: 5| Step: 9
Training loss: 2.8221757411956787
Validation loss: 2.334064527224469

Epoch: 5| Step: 10
Training loss: 2.501298427581787
Validation loss: 2.334981723498273

Epoch: 32| Step: 0
Training loss: 2.380136489868164
Validation loss: 2.3340708671077603

Epoch: 5| Step: 1
Training loss: 1.9497798681259155
Validation loss: 2.338239485217679

Epoch: 5| Step: 2
Training loss: 2.054720401763916
Validation loss: 2.338679452096262

Epoch: 5| Step: 3
Training loss: 2.772731065750122
Validation loss: 2.3520644044363372

Epoch: 5| Step: 4
Training loss: 3.0010361671447754
Validation loss: 2.3621899748361237

Epoch: 5| Step: 5
Training loss: 2.240837574005127
Validation loss: 2.3720040475168536

Epoch: 5| Step: 6
Training loss: 2.7204596996307373
Validation loss: 2.3684685871165287

Epoch: 5| Step: 7
Training loss: 3.3771252632141113
Validation loss: 2.349335551261902

Epoch: 5| Step: 8
Training loss: 2.664944648742676
Validation loss: 2.3370394732362483

Epoch: 5| Step: 9
Training loss: 2.8398609161376953
Validation loss: 2.3269668945702175

Epoch: 5| Step: 10
Training loss: 2.783630609512329
Validation loss: 2.324717490903793

Epoch: 33| Step: 0
Training loss: 2.4087371826171875
Validation loss: 2.3207876528463056

Epoch: 5| Step: 1
Training loss: 2.828975200653076
Validation loss: 2.3178879907054286

Epoch: 5| Step: 2
Training loss: 2.2715022563934326
Validation loss: 2.3153973933189147

Epoch: 5| Step: 3
Training loss: 2.3831629753112793
Validation loss: 2.315207260911183

Epoch: 5| Step: 4
Training loss: 2.592205286026001
Validation loss: 2.3168049422643517

Epoch: 5| Step: 5
Training loss: 2.691107988357544
Validation loss: 2.3117516040802

Epoch: 5| Step: 6
Training loss: 2.695697784423828
Validation loss: 2.3117120765870616

Epoch: 5| Step: 7
Training loss: 2.552729606628418
Validation loss: 2.3098214134093253

Epoch: 5| Step: 8
Training loss: 2.9287052154541016
Validation loss: 2.30717303932354

Epoch: 5| Step: 9
Training loss: 2.6793293952941895
Validation loss: 2.3060765574055333

Epoch: 5| Step: 10
Training loss: 2.6276540756225586
Validation loss: 2.318560213171026

Epoch: 34| Step: 0
Training loss: 2.4776835441589355
Validation loss: 2.331289250363586

Epoch: 5| Step: 1
Training loss: 2.354854106903076
Validation loss: 2.350576408447758

Epoch: 5| Step: 2
Training loss: 2.7399346828460693
Validation loss: 2.3639093458011584

Epoch: 5| Step: 3
Training loss: 2.641782522201538
Validation loss: 2.346451892647692

Epoch: 5| Step: 4
Training loss: 2.622462034225464
Validation loss: 2.333900402950984

Epoch: 5| Step: 5
Training loss: 2.360431671142578
Validation loss: 2.3148031080922773

Epoch: 5| Step: 6
Training loss: 2.7930614948272705
Validation loss: 2.300358046767532

Epoch: 5| Step: 7
Training loss: 2.5125715732574463
Validation loss: 2.2962615413050496

Epoch: 5| Step: 8
Training loss: 3.1455981731414795
Validation loss: 2.3014931576226347

Epoch: 5| Step: 9
Training loss: 2.602001190185547
Validation loss: 2.2959544530478855

Epoch: 5| Step: 10
Training loss: 2.2205257415771484
Validation loss: 2.326205271546559

Epoch: 35| Step: 0
Training loss: 2.5025787353515625
Validation loss: 2.352006830194945

Epoch: 5| Step: 1
Training loss: 2.086061477661133
Validation loss: 2.3594055432145313

Epoch: 5| Step: 2
Training loss: 2.601963520050049
Validation loss: 2.374795047185754

Epoch: 5| Step: 3
Training loss: 2.1634912490844727
Validation loss: 2.386765162150065

Epoch: 5| Step: 4
Training loss: 3.2575416564941406
Validation loss: 2.491143318914598

Epoch: 5| Step: 5
Training loss: 1.8457496166229248
Validation loss: 2.392801753936275

Epoch: 5| Step: 6
Training loss: 2.93729829788208
Validation loss: 2.3689901367310555

Epoch: 5| Step: 7
Training loss: 3.144361734390259
Validation loss: 2.3406100683314826

Epoch: 5| Step: 8
Training loss: 2.794280529022217
Validation loss: 2.377677509861608

Epoch: 5| Step: 9
Training loss: 2.942870855331421
Validation loss: 2.408179836888467

Epoch: 5| Step: 10
Training loss: 2.689204692840576
Validation loss: 2.3849986214791574

Epoch: 36| Step: 0
Training loss: 2.1462020874023438
Validation loss: 2.3527893379170406

Epoch: 5| Step: 1
Training loss: 2.773165464401245
Validation loss: 2.3123468301629506

Epoch: 5| Step: 2
Training loss: 2.721226453781128
Validation loss: 2.288308035942816

Epoch: 5| Step: 3
Training loss: 2.11604905128479
Validation loss: 2.2840999249489076

Epoch: 5| Step: 4
Training loss: 2.805046558380127
Validation loss: 2.2940579691240863

Epoch: 5| Step: 5
Training loss: 2.631171464920044
Validation loss: 2.3210031550417662

Epoch: 5| Step: 6
Training loss: 3.1791388988494873
Validation loss: 2.349670763938658

Epoch: 5| Step: 7
Training loss: 2.4481444358825684
Validation loss: 2.3116414982785463

Epoch: 5| Step: 8
Training loss: 2.440366506576538
Validation loss: 2.3023123946241153

Epoch: 5| Step: 9
Training loss: 2.381816864013672
Validation loss: 2.2877676897151495

Epoch: 5| Step: 10
Training loss: 2.9552855491638184
Validation loss: 2.284333448256216

Epoch: 37| Step: 0
Training loss: 2.5848536491394043
Validation loss: 2.285331097982263

Epoch: 5| Step: 1
Training loss: 2.530367136001587
Validation loss: 2.2879820100722776

Epoch: 5| Step: 2
Training loss: 2.5849413871765137
Validation loss: 2.287417386167793

Epoch: 5| Step: 3
Training loss: 3.0035719871520996
Validation loss: 2.2927439699890795

Epoch: 5| Step: 4
Training loss: 2.4687321186065674
Validation loss: 2.2945160686328845

Epoch: 5| Step: 5
Training loss: 2.5971596240997314
Validation loss: 2.2832802995558708

Epoch: 5| Step: 6
Training loss: 2.4478635787963867
Validation loss: 2.282458218195105

Epoch: 5| Step: 7
Training loss: 2.3872299194335938
Validation loss: 2.2758874636824413

Epoch: 5| Step: 8
Training loss: 2.7769978046417236
Validation loss: 2.270958641523956

Epoch: 5| Step: 9
Training loss: 2.533658742904663
Validation loss: 2.268237493371451

Epoch: 5| Step: 10
Training loss: 2.189133644104004
Validation loss: 2.26120348130503

Epoch: 38| Step: 0
Training loss: 2.682034969329834
Validation loss: 2.2613372443824686

Epoch: 5| Step: 1
Training loss: 3.626552104949951
Validation loss: 2.2625776170402445

Epoch: 5| Step: 2
Training loss: 1.9580085277557373
Validation loss: 2.258762464728407

Epoch: 5| Step: 3
Training loss: 2.461491823196411
Validation loss: 2.2536921654978106

Epoch: 5| Step: 4
Training loss: 2.0916361808776855
Validation loss: 2.2546212032277095

Epoch: 5| Step: 5
Training loss: 2.7845377922058105
Validation loss: 2.2601374426195697

Epoch: 5| Step: 6
Training loss: 2.4039552211761475
Validation loss: 2.26068587200616

Epoch: 5| Step: 7
Training loss: 3.1784491539001465
Validation loss: 2.273284883909328

Epoch: 5| Step: 8
Training loss: 1.9347803592681885
Validation loss: 2.290250132160802

Epoch: 5| Step: 9
Training loss: 2.5511929988861084
Validation loss: 2.2956805331732637

Epoch: 5| Step: 10
Training loss: 2.433633804321289
Validation loss: 2.2836037810130785

Epoch: 39| Step: 0
Training loss: 2.376633405685425
Validation loss: 2.2810603649385515

Epoch: 5| Step: 1
Training loss: 2.449984073638916
Validation loss: 2.2871426549009097

Epoch: 5| Step: 2
Training loss: 2.495392322540283
Validation loss: 2.2861740986506143

Epoch: 5| Step: 3
Training loss: 2.917318344116211
Validation loss: 2.277656570557625

Epoch: 5| Step: 4
Training loss: 3.0995934009552
Validation loss: 2.276301953100389

Epoch: 5| Step: 5
Training loss: 2.8318848609924316
Validation loss: 2.282041311264038

Epoch: 5| Step: 6
Training loss: 2.1127688884735107
Validation loss: 2.2746829345662105

Epoch: 5| Step: 7
Training loss: 2.15893816947937
Validation loss: 2.273021997944001

Epoch: 5| Step: 8
Training loss: 2.2526345252990723
Validation loss: 2.2675995365265877

Epoch: 5| Step: 9
Training loss: 2.676778793334961
Validation loss: 2.2668600184943086

Epoch: 5| Step: 10
Training loss: 2.8212714195251465
Validation loss: 2.2580221519675305

Epoch: 40| Step: 0
Training loss: 2.2377166748046875
Validation loss: 2.2636598463981383

Epoch: 5| Step: 1
Training loss: 2.725261688232422
Validation loss: 2.269219829190162

Epoch: 5| Step: 2
Training loss: 2.3334155082702637
Validation loss: 2.2825852645340787

Epoch: 5| Step: 3
Training loss: 2.2358953952789307
Validation loss: 2.3016143998792096

Epoch: 5| Step: 4
Training loss: 2.7611494064331055
Validation loss: 2.312996422090838

Epoch: 5| Step: 5
Training loss: 2.6669464111328125
Validation loss: 2.3015245365840133

Epoch: 5| Step: 6
Training loss: 2.743168830871582
Validation loss: 2.273834038806218

Epoch: 5| Step: 7
Training loss: 2.8823680877685547
Validation loss: 2.2661637465159097

Epoch: 5| Step: 8
Training loss: 2.5059704780578613
Validation loss: 2.2420394933351906

Epoch: 5| Step: 9
Training loss: 2.6002728939056396
Validation loss: 2.2333591958527923

Epoch: 5| Step: 10
Training loss: 2.2763617038726807
Validation loss: 2.237813283038396

Epoch: 41| Step: 0
Training loss: 2.8199286460876465
Validation loss: 2.2393111836525703

Epoch: 5| Step: 1
Training loss: 2.5831427574157715
Validation loss: 2.239508239171838

Epoch: 5| Step: 2
Training loss: 2.889155864715576
Validation loss: 2.2453992700064056

Epoch: 5| Step: 3
Training loss: 2.0587611198425293
Validation loss: 2.244440127444524

Epoch: 5| Step: 4
Training loss: 2.7872166633605957
Validation loss: 2.2553903877094226

Epoch: 5| Step: 5
Training loss: 2.4138386249542236
Validation loss: 2.246559509667017

Epoch: 5| Step: 6
Training loss: 2.5957400798797607
Validation loss: 2.262193887464462

Epoch: 5| Step: 7
Training loss: 2.15323543548584
Validation loss: 2.2746237144675305

Epoch: 5| Step: 8
Training loss: 2.550105333328247
Validation loss: 2.248894340248518

Epoch: 5| Step: 9
Training loss: 2.9251809120178223
Validation loss: 2.2552232639763945

Epoch: 5| Step: 10
Training loss: 2.4204695224761963
Validation loss: 2.260216730897145

Epoch: 42| Step: 0
Training loss: 2.6645312309265137
Validation loss: 2.2601774238771006

Epoch: 5| Step: 1
Training loss: 2.64827823638916
Validation loss: 2.257993523792554

Epoch: 5| Step: 2
Training loss: 3.1832733154296875
Validation loss: 2.247807261764362

Epoch: 5| Step: 3
Training loss: 2.411781072616577
Validation loss: 2.246871148386309

Epoch: 5| Step: 4
Training loss: 2.1444811820983887
Validation loss: 2.2644581666556736

Epoch: 5| Step: 5
Training loss: 2.756373167037964
Validation loss: 2.2878803232664704

Epoch: 5| Step: 6
Training loss: 2.2472736835479736
Validation loss: 2.298085653653709

Epoch: 5| Step: 7
Training loss: 2.25144100189209
Validation loss: 2.3194049045603764

Epoch: 5| Step: 8
Training loss: 2.245744228363037
Validation loss: 2.336800388110581

Epoch: 5| Step: 9
Training loss: 2.264192581176758
Validation loss: 2.3141660433943554

Epoch: 5| Step: 10
Training loss: 3.4057655334472656
Validation loss: 2.309103799122636

Epoch: 43| Step: 0
Training loss: 2.41444993019104
Validation loss: 2.2925562679126696

Epoch: 5| Step: 1
Training loss: 2.848153829574585
Validation loss: 2.27148328545273

Epoch: 5| Step: 2
Training loss: 2.485166549682617
Validation loss: 2.23787736123608

Epoch: 5| Step: 3
Training loss: 2.395651340484619
Validation loss: 2.221337241511191

Epoch: 5| Step: 4
Training loss: 2.935565948486328
Validation loss: 2.2089569799361692

Epoch: 5| Step: 5
Training loss: 2.405930280685425
Validation loss: 2.2092232370889313

Epoch: 5| Step: 6
Training loss: 2.5692553520202637
Validation loss: 2.2177386655602405

Epoch: 5| Step: 7
Training loss: 2.7416739463806152
Validation loss: 2.218992475540407

Epoch: 5| Step: 8
Training loss: 2.4364123344421387
Validation loss: 2.2316375932385846

Epoch: 5| Step: 9
Training loss: 2.143446445465088
Validation loss: 2.263923636046789

Epoch: 5| Step: 10
Training loss: 2.674506187438965
Validation loss: 2.2760927523336103

Epoch: 44| Step: 0
Training loss: 3.023571252822876
Validation loss: 2.254898340471329

Epoch: 5| Step: 1
Training loss: 2.009122371673584
Validation loss: 2.249620965732041

Epoch: 5| Step: 2
Training loss: 2.482809066772461
Validation loss: 2.249248984039471

Epoch: 5| Step: 3
Training loss: 2.1032118797302246
Validation loss: 2.2528795990892636

Epoch: 5| Step: 4
Training loss: 2.801659345626831
Validation loss: 2.2729801119014783

Epoch: 5| Step: 5
Training loss: 2.334993839263916
Validation loss: 2.3065910044536797

Epoch: 5| Step: 6
Training loss: 2.4582648277282715
Validation loss: 2.3322171985462146

Epoch: 5| Step: 7
Training loss: 2.2801880836486816
Validation loss: 2.321890884830106

Epoch: 5| Step: 8
Training loss: 2.8873400688171387
Validation loss: 2.2901812650824107

Epoch: 5| Step: 9
Training loss: 2.903956890106201
Validation loss: 2.255728337072557

Epoch: 5| Step: 10
Training loss: 2.703392505645752
Validation loss: 2.2477707657762753

Epoch: 45| Step: 0
Training loss: 2.603043794631958
Validation loss: 2.2345482328886628

Epoch: 5| Step: 1
Training loss: 2.7181780338287354
Validation loss: 2.2371477747476227

Epoch: 5| Step: 2
Training loss: 2.271775007247925
Validation loss: 2.231762142591579

Epoch: 5| Step: 3
Training loss: 2.5865771770477295
Validation loss: 2.2285543308463147

Epoch: 5| Step: 4
Training loss: 3.079644203186035
Validation loss: 2.226701728759273

Epoch: 5| Step: 5
Training loss: 2.3720710277557373
Validation loss: 2.232307623791438

Epoch: 5| Step: 6
Training loss: 2.412538766860962
Validation loss: 2.2355117490214687

Epoch: 5| Step: 7
Training loss: 2.568654775619507
Validation loss: 2.2299609491902013

Epoch: 5| Step: 8
Training loss: 2.5859856605529785
Validation loss: 2.2399059059799358

Epoch: 5| Step: 9
Training loss: 2.24118971824646
Validation loss: 2.243563767402403

Epoch: 5| Step: 10
Training loss: 2.390575647354126
Validation loss: 2.259247910591864

Epoch: 46| Step: 0
Training loss: 1.809787392616272
Validation loss: 2.268185323284518

Epoch: 5| Step: 1
Training loss: 2.5669779777526855
Validation loss: 2.259879340407669

Epoch: 5| Step: 2
Training loss: 2.435645341873169
Validation loss: 2.2398545357488815

Epoch: 5| Step: 3
Training loss: 2.1533403396606445
Validation loss: 2.2423122236805577

Epoch: 5| Step: 4
Training loss: 2.029648542404175
Validation loss: 2.244965937829787

Epoch: 5| Step: 5
Training loss: 2.4396555423736572
Validation loss: 2.2451872723076933

Epoch: 5| Step: 6
Training loss: 2.2543625831604004
Validation loss: 2.250223062371695

Epoch: 5| Step: 7
Training loss: 2.77583909034729
Validation loss: 2.2548877654537076

Epoch: 5| Step: 8
Training loss: 3.7773900032043457
Validation loss: 2.2485105914454304

Epoch: 5| Step: 9
Training loss: 3.116380214691162
Validation loss: 2.2347615329168176

Epoch: 5| Step: 10
Training loss: 2.3674509525299072
Validation loss: 2.2211733915472545

Epoch: 47| Step: 0
Training loss: 2.4476864337921143
Validation loss: 2.2083871595321165

Epoch: 5| Step: 1
Training loss: 1.5107495784759521
Validation loss: 2.2060972682891355

Epoch: 5| Step: 2
Training loss: 3.0152018070220947
Validation loss: 2.2071454114811395

Epoch: 5| Step: 3
Training loss: 2.4747495651245117
Validation loss: 2.202084393911464

Epoch: 5| Step: 4
Training loss: 2.8334600925445557
Validation loss: 2.190814648905108

Epoch: 5| Step: 5
Training loss: 2.4627959728240967
Validation loss: 2.188563249444449

Epoch: 5| Step: 6
Training loss: 2.395983934402466
Validation loss: 2.1885042934007544

Epoch: 5| Step: 7
Training loss: 2.4103336334228516
Validation loss: 2.1913224035693752

Epoch: 5| Step: 8
Training loss: 3.1200406551361084
Validation loss: 2.1870188379800446

Epoch: 5| Step: 9
Training loss: 2.8465819358825684
Validation loss: 2.1963826059013285

Epoch: 5| Step: 10
Training loss: 2.1613144874572754
Validation loss: 2.2112233818218274

Epoch: 48| Step: 0
Training loss: 2.537806272506714
Validation loss: 2.2077774270888297

Epoch: 5| Step: 1
Training loss: 3.0827763080596924
Validation loss: 2.216643689781107

Epoch: 5| Step: 2
Training loss: 2.1039698123931885
Validation loss: 2.2359382170502857

Epoch: 5| Step: 3
Training loss: 1.982089638710022
Validation loss: 2.2359549050690024

Epoch: 5| Step: 4
Training loss: 2.091200828552246
Validation loss: 2.232425225678311

Epoch: 5| Step: 5
Training loss: 2.296051025390625
Validation loss: 2.234018282223773

Epoch: 5| Step: 6
Training loss: 2.845811128616333
Validation loss: 2.2288713429563787

Epoch: 5| Step: 7
Training loss: 2.6261801719665527
Validation loss: 2.2230813375083347

Epoch: 5| Step: 8
Training loss: 2.874356508255005
Validation loss: 2.2123940836998726

Epoch: 5| Step: 9
Training loss: 2.607692003250122
Validation loss: 2.211511737556868

Epoch: 5| Step: 10
Training loss: 2.4274990558624268
Validation loss: 2.216373628185641

Epoch: 49| Step: 0
Training loss: 2.755070209503174
Validation loss: 2.205356538936656

Epoch: 5| Step: 1
Training loss: 2.3870251178741455
Validation loss: 2.1965460456827635

Epoch: 5| Step: 2
Training loss: 2.392019748687744
Validation loss: 2.1860518352959746

Epoch: 5| Step: 3
Training loss: 2.6393775939941406
Validation loss: 2.190396337098973

Epoch: 5| Step: 4
Training loss: 2.71040678024292
Validation loss: 2.193020305325908

Epoch: 5| Step: 5
Training loss: 2.853062629699707
Validation loss: 2.195373599247266

Epoch: 5| Step: 6
Training loss: 2.693514347076416
Validation loss: 2.1987063666825652

Epoch: 5| Step: 7
Training loss: 1.9429152011871338
Validation loss: 2.210086545636577

Epoch: 5| Step: 8
Training loss: 2.199669361114502
Validation loss: 2.2227539567537207

Epoch: 5| Step: 9
Training loss: 2.5641117095947266
Validation loss: 2.224401238144085

Epoch: 5| Step: 10
Training loss: 2.37258243560791
Validation loss: 2.228467300374021

Epoch: 50| Step: 0
Training loss: 2.3816559314727783
Validation loss: 2.245738516571701

Epoch: 5| Step: 1
Training loss: 3.073453187942505
Validation loss: 2.257455741205523

Epoch: 5| Step: 2
Training loss: 2.260153293609619
Validation loss: 2.253428042575877

Epoch: 5| Step: 3
Training loss: 2.6842288970947266
Validation loss: 2.243796794645248

Epoch: 5| Step: 4
Training loss: 2.37968373298645
Validation loss: 2.2631529044079524

Epoch: 5| Step: 5
Training loss: 2.882413387298584
Validation loss: 2.2740417936796784

Epoch: 5| Step: 6
Training loss: 1.8068183660507202
Validation loss: 2.228138085334532

Epoch: 5| Step: 7
Training loss: 3.142146348953247
Validation loss: 2.2034062288140737

Epoch: 5| Step: 8
Training loss: 2.4089348316192627
Validation loss: 2.1936663440478745

Epoch: 5| Step: 9
Training loss: 1.630004644393921
Validation loss: 2.201245479686286

Epoch: 5| Step: 10
Training loss: 2.797600030899048
Validation loss: 2.213345591739942

Epoch: 51| Step: 0
Training loss: 2.861016035079956
Validation loss: 2.2276210528548046

Epoch: 5| Step: 1
Training loss: 2.48781156539917
Validation loss: 2.253800433169129

Epoch: 5| Step: 2
Training loss: 2.5861003398895264
Validation loss: 2.214939225104547

Epoch: 5| Step: 3
Training loss: 2.3687644004821777
Validation loss: 2.1971843063190417

Epoch: 5| Step: 4
Training loss: 3.093264579772949
Validation loss: 2.1804999189992107

Epoch: 5| Step: 5
Training loss: 2.649545669555664
Validation loss: 2.189192359165479

Epoch: 5| Step: 6
Training loss: 2.468204975128174
Validation loss: 2.199116958084927

Epoch: 5| Step: 7
Training loss: 2.709912061691284
Validation loss: 2.212617056344145

Epoch: 5| Step: 8
Training loss: 2.435037136077881
Validation loss: 2.213883335872363

Epoch: 5| Step: 9
Training loss: 1.9629318714141846
Validation loss: 2.197742928740799

Epoch: 5| Step: 10
Training loss: 2.3257484436035156
Validation loss: 2.182798542002196

Epoch: 52| Step: 0
Training loss: 2.608283042907715
Validation loss: 2.1826714059358

Epoch: 5| Step: 1
Training loss: 2.012890338897705
Validation loss: 2.178755760192871

Epoch: 5| Step: 2
Training loss: 2.9000637531280518
Validation loss: 2.1743586601749545

Epoch: 5| Step: 3
Training loss: 3.208623170852661
Validation loss: 2.178606325580228

Epoch: 5| Step: 4
Training loss: 2.3579046726226807
Validation loss: 2.184348988276656

Epoch: 5| Step: 5
Training loss: 2.146862506866455
Validation loss: 2.182909004149898

Epoch: 5| Step: 6
Training loss: 2.4057297706604004
Validation loss: 2.184419870376587

Epoch: 5| Step: 7
Training loss: 1.9974428415298462
Validation loss: 2.2066300133223176

Epoch: 5| Step: 8
Training loss: 2.584299087524414
Validation loss: 2.215842193172824

Epoch: 5| Step: 9
Training loss: 2.37336802482605
Validation loss: 2.224256802630681

Epoch: 5| Step: 10
Training loss: 2.9772679805755615
Validation loss: 2.2261706859834733

Epoch: 53| Step: 0
Training loss: 1.9766546487808228
Validation loss: 2.2195512069168912

Epoch: 5| Step: 1
Training loss: 3.391308307647705
Validation loss: 2.2102907178222493

Epoch: 5| Step: 2
Training loss: 2.5351321697235107
Validation loss: 2.1937049281212593

Epoch: 5| Step: 3
Training loss: 2.0328967571258545
Validation loss: 2.1986193849194433

Epoch: 5| Step: 4
Training loss: 2.8523337841033936
Validation loss: 2.2182049776918147

Epoch: 5| Step: 5
Training loss: 2.5203301906585693
Validation loss: 2.2447354409002487

Epoch: 5| Step: 6
Training loss: 2.203047752380371
Validation loss: 2.240184017406997

Epoch: 5| Step: 7
Training loss: 2.4477124214172363
Validation loss: 2.227385369680261

Epoch: 5| Step: 8
Training loss: 2.56636381149292
Validation loss: 2.230429531425558

Epoch: 5| Step: 9
Training loss: 2.9059224128723145
Validation loss: 2.2159758793410433

Epoch: 5| Step: 10
Training loss: 1.942211389541626
Validation loss: 2.2076715077123334

Epoch: 54| Step: 0
Training loss: 2.416374683380127
Validation loss: 2.1963827507470244

Epoch: 5| Step: 1
Training loss: 2.397451400756836
Validation loss: 2.191374881293184

Epoch: 5| Step: 2
Training loss: 2.7314743995666504
Validation loss: 2.181928660279961

Epoch: 5| Step: 3
Training loss: 2.5663256645202637
Validation loss: 2.174682483878187

Epoch: 5| Step: 4
Training loss: 2.583144187927246
Validation loss: 2.1678353496777114

Epoch: 5| Step: 5
Training loss: 2.19555401802063
Validation loss: 2.16920062803453

Epoch: 5| Step: 6
Training loss: 2.5852928161621094
Validation loss: 2.182126311845677

Epoch: 5| Step: 7
Training loss: 2.788811206817627
Validation loss: 2.2056062413800146

Epoch: 5| Step: 8
Training loss: 2.186868190765381
Validation loss: 2.2194058049109673

Epoch: 5| Step: 9
Training loss: 1.9722506999969482
Validation loss: 2.216113616061467

Epoch: 5| Step: 10
Training loss: 2.8794329166412354
Validation loss: 2.194962038788744

Epoch: 55| Step: 0
Training loss: 2.5568652153015137
Validation loss: 2.1761325046580327

Epoch: 5| Step: 1
Training loss: 2.092228651046753
Validation loss: 2.167225783871066

Epoch: 5| Step: 2
Training loss: 2.0000932216644287
Validation loss: 2.1521408916801534

Epoch: 5| Step: 3
Training loss: 2.591644763946533
Validation loss: 2.1526626822769

Epoch: 5| Step: 4
Training loss: 2.6715431213378906
Validation loss: 2.149752414354714

Epoch: 5| Step: 5
Training loss: 2.1773369312286377
Validation loss: 2.151846598553401

Epoch: 5| Step: 6
Training loss: 2.255342721939087
Validation loss: 2.1532203766607467

Epoch: 5| Step: 7
Training loss: 2.7799553871154785
Validation loss: 2.1647175024914485

Epoch: 5| Step: 8
Training loss: 2.2509384155273438
Validation loss: 2.1856927538430817

Epoch: 5| Step: 9
Training loss: 2.8420963287353516
Validation loss: 2.1907645758762153

Epoch: 5| Step: 10
Training loss: 3.3165361881256104
Validation loss: 2.18985221462865

Epoch: 56| Step: 0
Training loss: 2.1550917625427246
Validation loss: 2.190330551516625

Epoch: 5| Step: 1
Training loss: 2.071167469024658
Validation loss: 2.1831600717318955

Epoch: 5| Step: 2
Training loss: 2.6132168769836426
Validation loss: 2.17972408827915

Epoch: 5| Step: 3
Training loss: 2.9422364234924316
Validation loss: 2.1820553477092455

Epoch: 5| Step: 4
Training loss: 2.7902283668518066
Validation loss: 2.1662815668249644

Epoch: 5| Step: 5
Training loss: 2.138131856918335
Validation loss: 2.164538329647433

Epoch: 5| Step: 6
Training loss: 2.2322120666503906
Validation loss: 2.1706499707314277

Epoch: 5| Step: 7
Training loss: 2.5839226245880127
Validation loss: 2.1689015280815864

Epoch: 5| Step: 8
Training loss: 1.8006324768066406
Validation loss: 2.1710617542266846

Epoch: 5| Step: 9
Training loss: 2.5996153354644775
Validation loss: 2.1675970579988215

Epoch: 5| Step: 10
Training loss: 3.192556858062744
Validation loss: 2.17343706469382

Epoch: 57| Step: 0
Training loss: 2.751901149749756
Validation loss: 2.184679736373245

Epoch: 5| Step: 1
Training loss: 2.2795231342315674
Validation loss: 2.196029479785632

Epoch: 5| Step: 2
Training loss: 1.4431257247924805
Validation loss: 2.226898565087267

Epoch: 5| Step: 3
Training loss: 3.302227020263672
Validation loss: 2.2282689207343647

Epoch: 5| Step: 4
Training loss: 2.5730700492858887
Validation loss: 2.214601565432805

Epoch: 5| Step: 5
Training loss: 2.7152810096740723
Validation loss: 2.2110613789609683

Epoch: 5| Step: 6
Training loss: 1.970351219177246
Validation loss: 2.1947118005444928

Epoch: 5| Step: 7
Training loss: 2.0824263095855713
Validation loss: 2.1832333136630315

Epoch: 5| Step: 8
Training loss: 2.6863787174224854
Validation loss: 2.1675963632522093

Epoch: 5| Step: 9
Training loss: 2.2495436668395996
Validation loss: 2.156778925208635

Epoch: 5| Step: 10
Training loss: 3.0589442253112793
Validation loss: 2.1605654980546687

Epoch: 58| Step: 0
Training loss: 2.246736764907837
Validation loss: 2.1513710739792034

Epoch: 5| Step: 1
Training loss: 3.0088467597961426
Validation loss: 2.1521402661518385

Epoch: 5| Step: 2
Training loss: 2.0926291942596436
Validation loss: 2.1460430288827546

Epoch: 5| Step: 3
Training loss: 2.5424227714538574
Validation loss: 2.1498822076346285

Epoch: 5| Step: 4
Training loss: 2.372556209564209
Validation loss: 2.153131959258869

Epoch: 5| Step: 5
Training loss: 2.148571491241455
Validation loss: 2.1542486939378964

Epoch: 5| Step: 6
Training loss: 2.308513641357422
Validation loss: 2.180107557645408

Epoch: 5| Step: 7
Training loss: 2.0368800163269043
Validation loss: 2.234150578898768

Epoch: 5| Step: 8
Training loss: 2.8404488563537598
Validation loss: 2.244542411578599

Epoch: 5| Step: 9
Training loss: 2.787609338760376
Validation loss: 2.2210674490979923

Epoch: 5| Step: 10
Training loss: 2.608096122741699
Validation loss: 2.1914789689484464

Epoch: 59| Step: 0
Training loss: 3.2846946716308594
Validation loss: 2.179419089389104

Epoch: 5| Step: 1
Training loss: 2.946413516998291
Validation loss: 2.1531265833044566

Epoch: 5| Step: 2
Training loss: 2.4863381385803223
Validation loss: 2.129103227328229

Epoch: 5| Step: 3
Training loss: 2.3524279594421387
Validation loss: 2.13914091484521

Epoch: 5| Step: 4
Training loss: 2.2542507648468018
Validation loss: 2.148350264436455

Epoch: 5| Step: 5
Training loss: 2.811499834060669
Validation loss: 2.1487833863945416

Epoch: 5| Step: 6
Training loss: 1.8938862085342407
Validation loss: 2.1427985032399497

Epoch: 5| Step: 7
Training loss: 2.656421184539795
Validation loss: 2.1466056249474965

Epoch: 5| Step: 8
Training loss: 2.5432040691375732
Validation loss: 2.140726427878103

Epoch: 5| Step: 9
Training loss: 1.6638085842132568
Validation loss: 2.1269868471289195

Epoch: 5| Step: 10
Training loss: 2.2565152645111084
Validation loss: 2.1435176967292704

Epoch: 60| Step: 0
Training loss: 2.123086452484131
Validation loss: 2.1771932058436896

Epoch: 5| Step: 1
Training loss: 2.3675429821014404
Validation loss: 2.2538038299929712

Epoch: 5| Step: 2
Training loss: 2.848031520843506
Validation loss: 2.315852067803824

Epoch: 5| Step: 3
Training loss: 2.3136000633239746
Validation loss: 2.3228287286655878

Epoch: 5| Step: 4
Training loss: 2.5557379722595215
Validation loss: 2.250884686746905

Epoch: 5| Step: 5
Training loss: 2.1459901332855225
Validation loss: 2.205962086236605

Epoch: 5| Step: 6
Training loss: 2.4897143840789795
Validation loss: 2.168145277166879

Epoch: 5| Step: 7
Training loss: 2.6882071495056152
Validation loss: 2.133241641906

Epoch: 5| Step: 8
Training loss: 2.4188716411590576
Validation loss: 2.1169219760484594

Epoch: 5| Step: 9
Training loss: 3.0929558277130127
Validation loss: 2.117078426063702

Epoch: 5| Step: 10
Training loss: 2.075960874557495
Validation loss: 2.1235443879199285

Epoch: 61| Step: 0
Training loss: 2.300858974456787
Validation loss: 2.123978166170018

Epoch: 5| Step: 1
Training loss: 1.9950370788574219
Validation loss: 2.117083562317715

Epoch: 5| Step: 2
Training loss: 2.529892921447754
Validation loss: 2.1187614625500095

Epoch: 5| Step: 3
Training loss: 2.2346320152282715
Validation loss: 2.1296637776077434

Epoch: 5| Step: 4
Training loss: 2.532405376434326
Validation loss: 2.1325209166413996

Epoch: 5| Step: 5
Training loss: 2.810600996017456
Validation loss: 2.14173718678054

Epoch: 5| Step: 6
Training loss: 2.551204204559326
Validation loss: 2.1540361527473695

Epoch: 5| Step: 7
Training loss: 3.4262900352478027
Validation loss: 2.1699116704284505

Epoch: 5| Step: 8
Training loss: 1.7657268047332764
Validation loss: 2.191278665296493

Epoch: 5| Step: 9
Training loss: 2.8113365173339844
Validation loss: 2.1761744048005793

Epoch: 5| Step: 10
Training loss: 1.880289912223816
Validation loss: 2.169342792162331

Epoch: 62| Step: 0
Training loss: 3.320284366607666
Validation loss: 2.151443160990233

Epoch: 5| Step: 1
Training loss: 2.415597915649414
Validation loss: 2.148252543582711

Epoch: 5| Step: 2
Training loss: 3.02333402633667
Validation loss: 2.1487141450246177

Epoch: 5| Step: 3
Training loss: 1.9750665426254272
Validation loss: 2.1336877858766945

Epoch: 5| Step: 4
Training loss: 1.9324417114257812
Validation loss: 2.136512748656734

Epoch: 5| Step: 5
Training loss: 2.398785352706909
Validation loss: 2.142266663171912

Epoch: 5| Step: 6
Training loss: 1.8272358179092407
Validation loss: 2.150522692229158

Epoch: 5| Step: 7
Training loss: 2.923117160797119
Validation loss: 2.1437011226530998

Epoch: 5| Step: 8
Training loss: 2.051208257675171
Validation loss: 2.1272614284228255

Epoch: 5| Step: 9
Training loss: 2.209461212158203
Validation loss: 2.1199102529915432

Epoch: 5| Step: 10
Training loss: 2.6710317134857178
Validation loss: 2.1193039647994505

Epoch: 63| Step: 0
Training loss: 2.2588987350463867
Validation loss: 2.126801792011466

Epoch: 5| Step: 1
Training loss: 3.096977949142456
Validation loss: 2.1182698011398315

Epoch: 5| Step: 2
Training loss: 2.294320583343506
Validation loss: 2.1208574912881337

Epoch: 5| Step: 3
Training loss: 2.2315733432769775
Validation loss: 2.1121586702203237

Epoch: 5| Step: 4
Training loss: 2.391411304473877
Validation loss: 2.122272281236546

Epoch: 5| Step: 5
Training loss: 2.300004482269287
Validation loss: 2.1336373013834797

Epoch: 5| Step: 6
Training loss: 1.931812047958374
Validation loss: 2.131133715311686

Epoch: 5| Step: 7
Training loss: 3.044633150100708
Validation loss: 2.135756923306373

Epoch: 5| Step: 8
Training loss: 2.2702724933624268
Validation loss: 2.136586530234224

Epoch: 5| Step: 9
Training loss: 2.380967617034912
Validation loss: 2.124177614847819

Epoch: 5| Step: 10
Training loss: 2.32654070854187
Validation loss: 2.132247978641141

Epoch: 64| Step: 0
Training loss: 2.277966022491455
Validation loss: 2.125047581170195

Epoch: 5| Step: 1
Training loss: 2.5362391471862793
Validation loss: 2.136635923898348

Epoch: 5| Step: 2
Training loss: 2.7027995586395264
Validation loss: 2.1414732779225996

Epoch: 5| Step: 3
Training loss: 2.6482367515563965
Validation loss: 2.120156377874395

Epoch: 5| Step: 4
Training loss: 2.262153387069702
Validation loss: 2.1271702961255143

Epoch: 5| Step: 5
Training loss: 2.463853359222412
Validation loss: 2.1287398184499433

Epoch: 5| Step: 6
Training loss: 2.1251022815704346
Validation loss: 2.128530006254873

Epoch: 5| Step: 7
Training loss: 2.73732590675354
Validation loss: 2.130711086334721

Epoch: 5| Step: 8
Training loss: 1.9586868286132812
Validation loss: 2.1165688089145127

Epoch: 5| Step: 9
Training loss: 1.9736909866333008
Validation loss: 2.1256245349043157

Epoch: 5| Step: 10
Training loss: 2.824251174926758
Validation loss: 2.1368685768496607

Epoch: 65| Step: 0
Training loss: 2.4531402587890625
Validation loss: 2.155464936328191

Epoch: 5| Step: 1
Training loss: 2.389275074005127
Validation loss: 2.2042312391342653

Epoch: 5| Step: 2
Training loss: 3.000945568084717
Validation loss: 2.182492809910928

Epoch: 5| Step: 3
Training loss: 2.398021697998047
Validation loss: 2.151917426816879

Epoch: 5| Step: 4
Training loss: 1.948708176612854
Validation loss: 2.1326537055353962

Epoch: 5| Step: 5
Training loss: 2.3430278301239014
Validation loss: 2.115490964663926

Epoch: 5| Step: 6
Training loss: 2.7770702838897705
Validation loss: 2.121789772023437

Epoch: 5| Step: 7
Training loss: 2.240852117538452
Validation loss: 2.114867553916029

Epoch: 5| Step: 8
Training loss: 2.322791576385498
Validation loss: 2.1215377046215917

Epoch: 5| Step: 9
Training loss: 2.3544371128082275
Validation loss: 2.1130721671606905

Epoch: 5| Step: 10
Training loss: 2.4190351963043213
Validation loss: 2.109826926262148

Epoch: 66| Step: 0
Training loss: 2.072847843170166
Validation loss: 2.1087077945791264

Epoch: 5| Step: 1
Training loss: 2.213582754135132
Validation loss: 2.1088493126694874

Epoch: 5| Step: 2
Training loss: 2.2145373821258545
Validation loss: 2.1371742717681395

Epoch: 5| Step: 3
Training loss: 2.444805860519409
Validation loss: 2.1403489369218067

Epoch: 5| Step: 4
Training loss: 3.230973720550537
Validation loss: 2.148948645079008

Epoch: 5| Step: 5
Training loss: 2.35526180267334
Validation loss: 2.1588818129672798

Epoch: 5| Step: 6
Training loss: 2.8195998668670654
Validation loss: 2.18334989265729

Epoch: 5| Step: 7
Training loss: 2.754743814468384
Validation loss: 2.2108757970153645

Epoch: 5| Step: 8
Training loss: 1.8815269470214844
Validation loss: 2.192562210944391

Epoch: 5| Step: 9
Training loss: 2.329744815826416
Validation loss: 2.194321258093721

Epoch: 5| Step: 10
Training loss: 2.2197799682617188
Validation loss: 2.1712759079471713

Epoch: 67| Step: 0
Training loss: 3.079531192779541
Validation loss: 2.1601162110605547

Epoch: 5| Step: 1
Training loss: 1.5589195489883423
Validation loss: 2.125065589463839

Epoch: 5| Step: 2
Training loss: 2.2495810985565186
Validation loss: 2.095908368787458

Epoch: 5| Step: 3
Training loss: 2.3173391819000244
Validation loss: 2.097244014022171

Epoch: 5| Step: 4
Training loss: 2.819199800491333
Validation loss: 2.093598658038724

Epoch: 5| Step: 5
Training loss: 2.3083484172821045
Validation loss: 2.102554093125046

Epoch: 5| Step: 6
Training loss: 2.3173410892486572
Validation loss: 2.1126570778508342

Epoch: 5| Step: 7
Training loss: 2.2774815559387207
Validation loss: 2.1075238207335114

Epoch: 5| Step: 8
Training loss: 2.2356748580932617
Validation loss: 2.0828698347973567

Epoch: 5| Step: 9
Training loss: 2.564250946044922
Validation loss: 2.079033456822877

Epoch: 5| Step: 10
Training loss: 3.0971481800079346
Validation loss: 2.123963761073287

Epoch: 68| Step: 0
Training loss: 2.730268716812134
Validation loss: 2.217803503877373

Epoch: 5| Step: 1
Training loss: 2.7155086994171143
Validation loss: 2.270127838657748

Epoch: 5| Step: 2
Training loss: 2.366767406463623
Validation loss: 2.2468159878125755

Epoch: 5| Step: 3
Training loss: 2.7757649421691895
Validation loss: 2.2350681879187144

Epoch: 5| Step: 4
Training loss: 2.569528102874756
Validation loss: 2.192824061198901

Epoch: 5| Step: 5
Training loss: 2.248715400695801
Validation loss: 2.1651173483940864

Epoch: 5| Step: 6
Training loss: 2.2071616649627686
Validation loss: 2.1256772946285944

Epoch: 5| Step: 7
Training loss: 2.021024703979492
Validation loss: 2.097231803401824

Epoch: 5| Step: 8
Training loss: 2.3385696411132812
Validation loss: 2.094907381201303

Epoch: 5| Step: 9
Training loss: 2.3969693183898926
Validation loss: 2.0850992228395198

Epoch: 5| Step: 10
Training loss: 2.2395057678222656
Validation loss: 2.080040395900767

Epoch: 69| Step: 0
Training loss: 2.1512293815612793
Validation loss: 2.0839628429823023

Epoch: 5| Step: 1
Training loss: 1.9806686639785767
Validation loss: 2.0874894280587473

Epoch: 5| Step: 2
Training loss: 2.0788629055023193
Validation loss: 2.082447582675565

Epoch: 5| Step: 3
Training loss: 3.258490800857544
Validation loss: 2.082313661934227

Epoch: 5| Step: 4
Training loss: 2.052611827850342
Validation loss: 2.089657706599082

Epoch: 5| Step: 5
Training loss: 2.746494770050049
Validation loss: 2.085896163858393

Epoch: 5| Step: 6
Training loss: 2.120091676712036
Validation loss: 2.0817671091325822

Epoch: 5| Step: 7
Training loss: 2.5123138427734375
Validation loss: 2.1009626311640583

Epoch: 5| Step: 8
Training loss: 2.749694585800171
Validation loss: 2.108889400318105

Epoch: 5| Step: 9
Training loss: 2.419445514678955
Validation loss: 2.1370340008889475

Epoch: 5| Step: 10
Training loss: 2.0975394248962402
Validation loss: 2.1678428470447497

Epoch: 70| Step: 0
Training loss: 1.9232864379882812
Validation loss: 2.1873386675311672

Epoch: 5| Step: 1
Training loss: 2.428713321685791
Validation loss: 2.14785929905471

Epoch: 5| Step: 2
Training loss: 2.80682110786438
Validation loss: 2.1360121234770744

Epoch: 5| Step: 3
Training loss: 2.869171380996704
Validation loss: 2.1123135089874268

Epoch: 5| Step: 4
Training loss: 2.3064050674438477
Validation loss: 2.11439617987602

Epoch: 5| Step: 5
Training loss: 2.3083677291870117
Validation loss: 2.088895243983115

Epoch: 5| Step: 6
Training loss: 2.2257277965545654
Validation loss: 2.0851141329734557

Epoch: 5| Step: 7
Training loss: 2.400736093521118
Validation loss: 2.0922786766482937

Epoch: 5| Step: 8
Training loss: 2.213975429534912
Validation loss: 2.127257075361026

Epoch: 5| Step: 9
Training loss: 2.001941680908203
Validation loss: 2.135636270687144

Epoch: 5| Step: 10
Training loss: 3.181171417236328
Validation loss: 2.131060024743439

Epoch: 71| Step: 0
Training loss: 2.298666477203369
Validation loss: 2.115325612406577

Epoch: 5| Step: 1
Training loss: 2.2515015602111816
Validation loss: 2.124636798776606

Epoch: 5| Step: 2
Training loss: 2.612204074859619
Validation loss: 2.134346305683095

Epoch: 5| Step: 3
Training loss: 2.5695347785949707
Validation loss: 2.158987819507558

Epoch: 5| Step: 4
Training loss: 2.378972291946411
Validation loss: 2.16659471296495

Epoch: 5| Step: 5
Training loss: 2.288884401321411
Validation loss: 2.159903512206129

Epoch: 5| Step: 6
Training loss: 2.3191075325012207
Validation loss: 2.163451325508856

Epoch: 5| Step: 7
Training loss: 2.756847620010376
Validation loss: 2.1522247611835437

Epoch: 5| Step: 8
Training loss: 2.6380650997161865
Validation loss: 2.1542610263311737

Epoch: 5| Step: 9
Training loss: 1.5956815481185913
Validation loss: 2.1519008785165767

Epoch: 5| Step: 10
Training loss: 2.989825487136841
Validation loss: 2.143427159196587

Epoch: 72| Step: 0
Training loss: 2.170544385910034
Validation loss: 2.1356317176613757

Epoch: 5| Step: 1
Training loss: 2.539527416229248
Validation loss: 2.119058673099805

Epoch: 5| Step: 2
Training loss: 2.1369006633758545
Validation loss: 2.1281572746974167

Epoch: 5| Step: 3
Training loss: 2.5051369667053223
Validation loss: 2.1332842150042133

Epoch: 5| Step: 4
Training loss: 2.4330317974090576
Validation loss: 2.1321019895615114

Epoch: 5| Step: 5
Training loss: 2.319796085357666
Validation loss: 2.1263506899597826

Epoch: 5| Step: 6
Training loss: 2.9193501472473145
Validation loss: 2.102784065790074

Epoch: 5| Step: 7
Training loss: 3.058929443359375
Validation loss: 2.103694826044062

Epoch: 5| Step: 8
Training loss: 1.8328297138214111
Validation loss: 2.1032692078621156

Epoch: 5| Step: 9
Training loss: 1.7662885189056396
Validation loss: 2.0961652519882366

Epoch: 5| Step: 10
Training loss: 2.4528591632843018
Validation loss: 2.1044217873645086

Epoch: 73| Step: 0
Training loss: 2.6676106452941895
Validation loss: 2.100209577109224

Epoch: 5| Step: 1
Training loss: 2.028486967086792
Validation loss: 2.1004281351643224

Epoch: 5| Step: 2
Training loss: 2.23213267326355
Validation loss: 2.1233709678854993

Epoch: 5| Step: 3
Training loss: 2.144948959350586
Validation loss: 2.125503486202609

Epoch: 5| Step: 4
Training loss: 2.2658071517944336
Validation loss: 2.119269314632621

Epoch: 5| Step: 5
Training loss: 1.874672293663025
Validation loss: 2.1136878562229935

Epoch: 5| Step: 6
Training loss: 2.4730982780456543
Validation loss: 2.0980990138105167

Epoch: 5| Step: 7
Training loss: 2.2097878456115723
Validation loss: 2.0846271386710544

Epoch: 5| Step: 8
Training loss: 2.854006290435791
Validation loss: 2.0888403231097805

Epoch: 5| Step: 9
Training loss: 2.535836696624756
Validation loss: 2.1026124646586757

Epoch: 5| Step: 10
Training loss: 2.890697479248047
Validation loss: 2.102242431332988

Epoch: 74| Step: 0
Training loss: 2.470000743865967
Validation loss: 2.124284382789366

Epoch: 5| Step: 1
Training loss: 3.1738600730895996
Validation loss: 2.1082321354137954

Epoch: 5| Step: 2
Training loss: 2.014096260070801
Validation loss: 2.1054981844399565

Epoch: 5| Step: 3
Training loss: 2.2648942470550537
Validation loss: 2.0927042192028416

Epoch: 5| Step: 4
Training loss: 2.8008201122283936
Validation loss: 2.0866324209397837

Epoch: 5| Step: 5
Training loss: 2.4340901374816895
Validation loss: 2.1246291719457155

Epoch: 5| Step: 6
Training loss: 2.0068295001983643
Validation loss: 2.182112472031706

Epoch: 5| Step: 7
Training loss: 1.7536910772323608
Validation loss: 2.213508503411406

Epoch: 5| Step: 8
Training loss: 2.454007625579834
Validation loss: 2.3502226978219967

Epoch: 5| Step: 9
Training loss: 2.7727036476135254
Validation loss: 2.3798394587732132

Epoch: 5| Step: 10
Training loss: 3.1014938354492188
Validation loss: 2.3958092710023284

Epoch: 75| Step: 0
Training loss: 3.2371997833251953
Validation loss: 2.2793953598186536

Epoch: 5| Step: 1
Training loss: 2.439826488494873
Validation loss: 2.1366994534769366

Epoch: 5| Step: 2
Training loss: 2.4297616481781006
Validation loss: 2.0610698987078924

Epoch: 5| Step: 3
Training loss: 1.9871110916137695
Validation loss: 2.045093964504939

Epoch: 5| Step: 4
Training loss: 2.3578598499298096
Validation loss: 2.0741979947654148

Epoch: 5| Step: 5
Training loss: 2.4834487438201904
Validation loss: 2.1005020910693752

Epoch: 5| Step: 6
Training loss: 2.8869943618774414
Validation loss: 2.128144907694991

Epoch: 5| Step: 7
Training loss: 1.94563889503479
Validation loss: 2.110299312940208

Epoch: 5| Step: 8
Training loss: 2.905492067337036
Validation loss: 2.080231446091847

Epoch: 5| Step: 9
Training loss: 1.6714541912078857
Validation loss: 2.07194427264634

Epoch: 5| Step: 10
Training loss: 2.613739013671875
Validation loss: 2.0598205635624547

Epoch: 76| Step: 0
Training loss: 2.4558091163635254
Validation loss: 2.056815598600654

Epoch: 5| Step: 1
Training loss: 2.2733402252197266
Validation loss: 2.05682635307312

Epoch: 5| Step: 2
Training loss: 2.1347224712371826
Validation loss: 2.071919810387396

Epoch: 5| Step: 3
Training loss: 2.164759635925293
Validation loss: 2.0997812645409697

Epoch: 5| Step: 4
Training loss: 2.9544379711151123
Validation loss: 2.119968507879524

Epoch: 5| Step: 5
Training loss: 1.817352056503296
Validation loss: 2.1272790355067097

Epoch: 5| Step: 6
Training loss: 2.7192063331604004
Validation loss: 2.1223747884073565

Epoch: 5| Step: 7
Training loss: 2.3632004261016846
Validation loss: 2.1262489288083968

Epoch: 5| Step: 8
Training loss: 2.069369316101074
Validation loss: 2.1139620619435466

Epoch: 5| Step: 9
Training loss: 2.7272262573242188
Validation loss: 2.1060387190952095

Epoch: 5| Step: 10
Training loss: 2.455780506134033
Validation loss: 2.1005059852395007

Epoch: 77| Step: 0
Training loss: 1.9541832208633423
Validation loss: 2.093628970525598

Epoch: 5| Step: 1
Training loss: 2.4913527965545654
Validation loss: 2.0800578068661433

Epoch: 5| Step: 2
Training loss: 2.6328892707824707
Validation loss: 2.0612353394108434

Epoch: 5| Step: 3
Training loss: 1.8869400024414062
Validation loss: 2.0628985858732656

Epoch: 5| Step: 4
Training loss: 2.3182144165039062
Validation loss: 2.043405496945945

Epoch: 5| Step: 5
Training loss: 2.171565294265747
Validation loss: 2.045791518303656

Epoch: 5| Step: 6
Training loss: 2.3416545391082764
Validation loss: 2.036107373493974

Epoch: 5| Step: 7
Training loss: 2.5889153480529785
Validation loss: 2.044897605014104

Epoch: 5| Step: 8
Training loss: 2.6646201610565186
Validation loss: 2.051446981327508

Epoch: 5| Step: 9
Training loss: 2.449174165725708
Validation loss: 2.049909185337764

Epoch: 5| Step: 10
Training loss: 2.310723066329956
Validation loss: 2.0549856398695256

Epoch: 78| Step: 0
Training loss: 2.7240190505981445
Validation loss: 2.051846678538989

Epoch: 5| Step: 1
Training loss: 1.628169298171997
Validation loss: 2.041708198926782

Epoch: 5| Step: 2
Training loss: 1.8166930675506592
Validation loss: 2.028801228410454

Epoch: 5| Step: 3
Training loss: 1.9328521490097046
Validation loss: 2.0322231746489003

Epoch: 5| Step: 4
Training loss: 2.31941294670105
Validation loss: 2.0358003083095757

Epoch: 5| Step: 5
Training loss: 2.407163143157959
Validation loss: 2.0362726796057915

Epoch: 5| Step: 6
Training loss: 2.6810526847839355
Validation loss: 2.0375366467301563

Epoch: 5| Step: 7
Training loss: 2.5508878231048584
Validation loss: 2.0470909110961424

Epoch: 5| Step: 8
Training loss: 2.9977118968963623
Validation loss: 2.0607343732669787

Epoch: 5| Step: 9
Training loss: 1.9331340789794922
Validation loss: 2.065240603621288

Epoch: 5| Step: 10
Training loss: 2.7285594940185547
Validation loss: 2.083034548708188

Epoch: 79| Step: 0
Training loss: 2.1810102462768555
Validation loss: 2.059368976982691

Epoch: 5| Step: 1
Training loss: 2.141756534576416
Validation loss: 2.055379513771303

Epoch: 5| Step: 2
Training loss: 2.8661322593688965
Validation loss: 2.0449317245073217

Epoch: 5| Step: 3
Training loss: 2.501258611679077
Validation loss: 2.0409788495750836

Epoch: 5| Step: 4
Training loss: 1.8198773860931396
Validation loss: 2.0331335080567228

Epoch: 5| Step: 5
Training loss: 2.6337130069732666
Validation loss: 2.04107399781545

Epoch: 5| Step: 6
Training loss: 3.397998094558716
Validation loss: 2.036801210013769

Epoch: 5| Step: 7
Training loss: 1.6250613927841187
Validation loss: 2.027223651127149

Epoch: 5| Step: 8
Training loss: 2.7714219093322754
Validation loss: 2.0394214686527046

Epoch: 5| Step: 9
Training loss: 1.9143158197402954
Validation loss: 2.037472512132378

Epoch: 5| Step: 10
Training loss: 1.8097193241119385
Validation loss: 2.076934265834029

Epoch: 80| Step: 0
Training loss: 2.438825845718384
Validation loss: 2.060753886417676

Epoch: 5| Step: 1
Training loss: 2.80696177482605
Validation loss: 2.062881922209135

Epoch: 5| Step: 2
Training loss: 2.6974539756774902
Validation loss: 2.0532666995961177

Epoch: 5| Step: 3
Training loss: 1.893822431564331
Validation loss: 2.045534141602055

Epoch: 5| Step: 4
Training loss: 2.595064401626587
Validation loss: 2.037156667760623

Epoch: 5| Step: 5
Training loss: 2.416121482849121
Validation loss: 2.0350262836743425

Epoch: 5| Step: 6
Training loss: 2.100996255874634
Validation loss: 2.0298306583076395

Epoch: 5| Step: 7
Training loss: 1.9377543926239014
Validation loss: 2.0103443438006985

Epoch: 5| Step: 8
Training loss: 2.0701093673706055
Validation loss: 2.0182223294370916

Epoch: 5| Step: 9
Training loss: 1.773697853088379
Validation loss: 2.0166802175583376

Epoch: 5| Step: 10
Training loss: 3.0179781913757324
Validation loss: 2.0106657551180933

Epoch: 81| Step: 0
Training loss: 2.1551852226257324
Validation loss: 2.0154612346362044

Epoch: 5| Step: 1
Training loss: 2.063443422317505
Validation loss: 2.013246815691712

Epoch: 5| Step: 2
Training loss: 1.7743053436279297
Validation loss: 2.0236989503265708

Epoch: 5| Step: 3
Training loss: 2.1773147583007812
Validation loss: 2.0285583593512095

Epoch: 5| Step: 4
Training loss: 2.2664802074432373
Validation loss: 2.0297485269526

Epoch: 5| Step: 5
Training loss: 2.546929359436035
Validation loss: 2.038106467134209

Epoch: 5| Step: 6
Training loss: 2.179069995880127
Validation loss: 2.0249155887993435

Epoch: 5| Step: 7
Training loss: 2.343971014022827
Validation loss: 2.032679029690322

Epoch: 5| Step: 8
Training loss: 2.9761898517608643
Validation loss: 2.0347293358977123

Epoch: 5| Step: 9
Training loss: 1.9216464757919312
Validation loss: 2.033796118151757

Epoch: 5| Step: 10
Training loss: 3.1337451934814453
Validation loss: 2.030754357255915

Epoch: 82| Step: 0
Training loss: 2.48707914352417
Validation loss: 2.0238992834603913

Epoch: 5| Step: 1
Training loss: 2.1109864711761475
Validation loss: 2.0310739483884586

Epoch: 5| Step: 2
Training loss: 1.9141438007354736
Validation loss: 2.020526788567984

Epoch: 5| Step: 3
Training loss: 2.5095667839050293
Validation loss: 2.024992025026711

Epoch: 5| Step: 4
Training loss: 2.0459091663360596
Validation loss: 2.0041691308380454

Epoch: 5| Step: 5
Training loss: 2.2769076824188232
Validation loss: 2.008007331561017

Epoch: 5| Step: 6
Training loss: 2.104794502258301
Validation loss: 2.0241492871315248

Epoch: 5| Step: 7
Training loss: 3.1815872192382812
Validation loss: 2.0621631107022687

Epoch: 5| Step: 8
Training loss: 2.5375969409942627
Validation loss: 2.092136013892389

Epoch: 5| Step: 9
Training loss: 2.1149697303771973
Validation loss: 2.155462141959898

Epoch: 5| Step: 10
Training loss: 2.465189218521118
Validation loss: 2.223393778647146

Epoch: 83| Step: 0
Training loss: 2.255153179168701
Validation loss: 2.2411178824722127

Epoch: 5| Step: 1
Training loss: 2.5003788471221924
Validation loss: 2.2274212170672674

Epoch: 5| Step: 2
Training loss: 2.0209310054779053
Validation loss: 2.184316576168101

Epoch: 5| Step: 3
Training loss: 1.9525911808013916
Validation loss: 2.12932784839343

Epoch: 5| Step: 4
Training loss: 2.9212565422058105
Validation loss: 2.0777307377066663

Epoch: 5| Step: 5
Training loss: 2.678081750869751
Validation loss: 2.0496090048102924

Epoch: 5| Step: 6
Training loss: 1.9983928203582764
Validation loss: 2.0495360166795793

Epoch: 5| Step: 7
Training loss: 2.4360766410827637
Validation loss: 2.050228500878939

Epoch: 5| Step: 8
Training loss: 1.9488165378570557
Validation loss: 2.058797054393317

Epoch: 5| Step: 9
Training loss: 2.649333953857422
Validation loss: 2.0644741981260237

Epoch: 5| Step: 10
Training loss: 2.4782068729400635
Validation loss: 2.0693611406510874

Epoch: 84| Step: 0
Training loss: 2.4668338298797607
Validation loss: 2.072796993358161

Epoch: 5| Step: 1
Training loss: 1.6039314270019531
Validation loss: 2.0706667169447868

Epoch: 5| Step: 2
Training loss: 2.1920788288116455
Validation loss: 2.08058197780322

Epoch: 5| Step: 3
Training loss: 2.632511854171753
Validation loss: 2.1044423939079366

Epoch: 5| Step: 4
Training loss: 2.5047428607940674
Validation loss: 2.083831981946063

Epoch: 5| Step: 5
Training loss: 2.344923973083496
Validation loss: 2.0781052753489506

Epoch: 5| Step: 6
Training loss: 2.572666645050049
Validation loss: 2.0801857594520814

Epoch: 5| Step: 7
Training loss: 2.1598458290100098
Validation loss: 2.076208934989027

Epoch: 5| Step: 8
Training loss: 2.886094808578491
Validation loss: 2.0855212416700137

Epoch: 5| Step: 9
Training loss: 2.2021751403808594
Validation loss: 2.0972916439015377

Epoch: 5| Step: 10
Training loss: 2.0748026371002197
Validation loss: 2.096390070453767

Epoch: 85| Step: 0
Training loss: 2.861985683441162
Validation loss: 2.082448628640944

Epoch: 5| Step: 1
Training loss: 2.2228705883026123
Validation loss: 2.0678224050870506

Epoch: 5| Step: 2
Training loss: 2.317927837371826
Validation loss: 2.0671010760850805

Epoch: 5| Step: 3
Training loss: 2.594719886779785
Validation loss: 2.0649974038524013

Epoch: 5| Step: 4
Training loss: 1.8522052764892578
Validation loss: 2.051257660312037

Epoch: 5| Step: 5
Training loss: 2.246516704559326
Validation loss: 2.0436897829014766

Epoch: 5| Step: 6
Training loss: 2.658484935760498
Validation loss: 2.046960579451694

Epoch: 5| Step: 7
Training loss: 2.4686553478240967
Validation loss: 2.0436314613588396

Epoch: 5| Step: 8
Training loss: 1.636396050453186
Validation loss: 2.0367835260206655

Epoch: 5| Step: 9
Training loss: 2.7017624378204346
Validation loss: 2.0265424200283584

Epoch: 5| Step: 10
Training loss: 1.9418166875839233
Validation loss: 2.029101376892418

Epoch: 86| Step: 0
Training loss: 2.9069111347198486
Validation loss: 2.055945065713698

Epoch: 5| Step: 1
Training loss: 2.492244243621826
Validation loss: 2.077759450481784

Epoch: 5| Step: 2
Training loss: 2.136937379837036
Validation loss: 2.0921785805815007

Epoch: 5| Step: 3
Training loss: 2.106663703918457
Validation loss: 2.1209041200658327

Epoch: 5| Step: 4
Training loss: 1.6632980108261108
Validation loss: 2.141786203589491

Epoch: 5| Step: 5
Training loss: 2.565007448196411
Validation loss: 2.139563173376104

Epoch: 5| Step: 6
Training loss: 3.0491199493408203
Validation loss: 2.1156827326743834

Epoch: 5| Step: 7
Training loss: 2.28311824798584
Validation loss: 2.0962528233887046

Epoch: 5| Step: 8
Training loss: 2.1614842414855957
Validation loss: 2.0718995089172036

Epoch: 5| Step: 9
Training loss: 2.1308209896087646
Validation loss: 2.0401374217002624

Epoch: 5| Step: 10
Training loss: 1.7218735218048096
Validation loss: 2.0126534495302426

Epoch: 87| Step: 0
Training loss: 1.9100377559661865
Validation loss: 2.0113349896605297

Epoch: 5| Step: 1
Training loss: 2.07084321975708
Validation loss: 2.036187425736458

Epoch: 5| Step: 2
Training loss: 2.9753365516662598
Validation loss: 2.0412918547148347

Epoch: 5| Step: 3
Training loss: 2.096804141998291
Validation loss: 2.055095144497451

Epoch: 5| Step: 4
Training loss: 2.356919765472412
Validation loss: 2.038274074113497

Epoch: 5| Step: 5
Training loss: 2.9517180919647217
Validation loss: 2.0220079370724258

Epoch: 5| Step: 6
Training loss: 2.9856772422790527
Validation loss: 2.010917471301171

Epoch: 5| Step: 7
Training loss: 1.9698667526245117
Validation loss: 2.0415137352481967

Epoch: 5| Step: 8
Training loss: 1.7259029150009155
Validation loss: 2.0371420050180085

Epoch: 5| Step: 9
Training loss: 2.003643751144409
Validation loss: 2.057159585337485

Epoch: 5| Step: 10
Training loss: 2.5276763439178467
Validation loss: 2.064868703965218

Epoch: 88| Step: 0
Training loss: 2.3814730644226074
Validation loss: 2.052462098419025

Epoch: 5| Step: 1
Training loss: 2.304274082183838
Validation loss: 2.034068190923301

Epoch: 5| Step: 2
Training loss: 2.1982181072235107
Validation loss: 2.018903059344138

Epoch: 5| Step: 3
Training loss: 1.864984154701233
Validation loss: 2.0142716541085193

Epoch: 5| Step: 4
Training loss: 2.066453456878662
Validation loss: 2.0137673783045944

Epoch: 5| Step: 5
Training loss: 2.2500479221343994
Validation loss: 2.0093222407884497

Epoch: 5| Step: 6
Training loss: 2.0590882301330566
Validation loss: 1.9945377662617674

Epoch: 5| Step: 7
Training loss: 2.6422390937805176
Validation loss: 1.9889803522376603

Epoch: 5| Step: 8
Training loss: 2.758411169052124
Validation loss: 1.9857776818736907

Epoch: 5| Step: 9
Training loss: 2.429518699645996
Validation loss: 1.986201355534215

Epoch: 5| Step: 10
Training loss: 1.9112881422042847
Validation loss: 1.9787333857628606

Epoch: 89| Step: 0
Training loss: 2.0457370281219482
Validation loss: 1.9834678378156436

Epoch: 5| Step: 1
Training loss: 2.226444721221924
Validation loss: 1.9977727987432992

Epoch: 5| Step: 2
Training loss: 2.8399899005889893
Validation loss: 2.007874837485693

Epoch: 5| Step: 3
Training loss: 2.7548136711120605
Validation loss: 2.0228543563555648

Epoch: 5| Step: 4
Training loss: 3.147003173828125
Validation loss: 2.028540539485152

Epoch: 5| Step: 5
Training loss: 2.109119176864624
Validation loss: 2.0327611418180567

Epoch: 5| Step: 6
Training loss: 1.6659393310546875
Validation loss: 2.0497089893587175

Epoch: 5| Step: 7
Training loss: 2.434055805206299
Validation loss: 2.072424522010229

Epoch: 5| Step: 8
Training loss: 1.3854554891586304
Validation loss: 2.0625844834953226

Epoch: 5| Step: 9
Training loss: 1.8639835119247437
Validation loss: 2.061392402136198

Epoch: 5| Step: 10
Training loss: 2.212205410003662
Validation loss: 2.060983737309774

Epoch: 90| Step: 0
Training loss: 2.624566078186035
Validation loss: 2.0565779029682116

Epoch: 5| Step: 1
Training loss: 2.404204845428467
Validation loss: 2.0592303942608576

Epoch: 5| Step: 2
Training loss: 1.5853022336959839
Validation loss: 2.0553651291836976

Epoch: 5| Step: 3
Training loss: 2.3117313385009766
Validation loss: 2.0612978114876697

Epoch: 5| Step: 4
Training loss: 2.2033591270446777
Validation loss: 2.050996688104445

Epoch: 5| Step: 5
Training loss: 2.1554627418518066
Validation loss: 2.0482064113822034

Epoch: 5| Step: 6
Training loss: 2.4101924896240234
Validation loss: 2.060673277865174

Epoch: 5| Step: 7
Training loss: 2.379399061203003
Validation loss: 2.056238987112558

Epoch: 5| Step: 8
Training loss: 2.6158175468444824
Validation loss: 2.026638379660986

Epoch: 5| Step: 9
Training loss: 2.123459815979004
Validation loss: 2.0310098958271805

Epoch: 5| Step: 10
Training loss: 1.9233311414718628
Validation loss: 2.025697890148368

Epoch: 91| Step: 0
Training loss: 2.6625194549560547
Validation loss: 2.006644888590741

Epoch: 5| Step: 1
Training loss: 1.9889885187149048
Validation loss: 2.0132409167546097

Epoch: 5| Step: 2
Training loss: 2.5439093112945557
Validation loss: 1.9857348472841325

Epoch: 5| Step: 3
Training loss: 2.7139079570770264
Validation loss: 1.9919582002906389

Epoch: 5| Step: 4
Training loss: 1.8867143392562866
Validation loss: 1.9866137325122792

Epoch: 5| Step: 5
Training loss: 1.9804160594940186
Validation loss: 1.9836211178892402

Epoch: 5| Step: 6
Training loss: 1.9721498489379883
Validation loss: 1.985497538761426

Epoch: 5| Step: 7
Training loss: 2.1477174758911133
Validation loss: 1.9966139921578028

Epoch: 5| Step: 8
Training loss: 2.5037460327148438
Validation loss: 1.9960608841270528

Epoch: 5| Step: 9
Training loss: 2.7543094158172607
Validation loss: 2.0214034690651843

Epoch: 5| Step: 10
Training loss: 1.6379156112670898
Validation loss: 2.04136093970268

Epoch: 92| Step: 0
Training loss: 1.9538705348968506
Validation loss: 2.071520327239908

Epoch: 5| Step: 1
Training loss: 2.4094364643096924
Validation loss: 2.1109274536050777

Epoch: 5| Step: 2
Training loss: 2.905127763748169
Validation loss: 2.1630169499304985

Epoch: 5| Step: 3
Training loss: 2.341959238052368
Validation loss: 2.1731042374846754

Epoch: 5| Step: 4
Training loss: 2.812054395675659
Validation loss: 2.1370107525138446

Epoch: 5| Step: 5
Training loss: 2.462775468826294
Validation loss: 2.0627225278526224

Epoch: 5| Step: 6
Training loss: 1.508824110031128
Validation loss: 2.039720603214797

Epoch: 5| Step: 7
Training loss: 1.8503259420394897
Validation loss: 2.0525252306333153

Epoch: 5| Step: 8
Training loss: 2.762688398361206
Validation loss: 2.073697923332132

Epoch: 5| Step: 9
Training loss: 2.033121109008789
Validation loss: 2.073838480057255

Epoch: 5| Step: 10
Training loss: 2.4727072715759277
Validation loss: 2.0933023024630804

Epoch: 93| Step: 0
Training loss: 2.011415481567383
Validation loss: 2.0626898978346135

Epoch: 5| Step: 1
Training loss: 2.118842840194702
Validation loss: 2.0307482993730934

Epoch: 5| Step: 2
Training loss: 2.77726411819458
Validation loss: 1.9930767910454863

Epoch: 5| Step: 3
Training loss: 2.5472733974456787
Validation loss: 2.034054261381908

Epoch: 5| Step: 4
Training loss: 2.2653589248657227
Validation loss: 2.052399722478723

Epoch: 5| Step: 5
Training loss: 1.76626455783844
Validation loss: 2.0727328305603354

Epoch: 5| Step: 6
Training loss: 3.0945136547088623
Validation loss: 2.072412739517868

Epoch: 5| Step: 7
Training loss: 2.6541976928710938
Validation loss: 2.038979543152676

Epoch: 5| Step: 8
Training loss: 1.7711284160614014
Validation loss: 2.017349509782689

Epoch: 5| Step: 9
Training loss: 2.1965508460998535
Validation loss: 2.0040432407009985

Epoch: 5| Step: 10
Training loss: 1.9169723987579346
Validation loss: 1.981117727935955

Epoch: 94| Step: 0
Training loss: 2.038515329360962
Validation loss: 1.959099454264487

Epoch: 5| Step: 1
Training loss: 2.088921546936035
Validation loss: 1.973043562263571

Epoch: 5| Step: 2
Training loss: 2.6511342525482178
Validation loss: 1.9893939251540809

Epoch: 5| Step: 3
Training loss: 2.861370801925659
Validation loss: 1.9818463107591033

Epoch: 5| Step: 4
Training loss: 2.085714101791382
Validation loss: 1.988757779521327

Epoch: 5| Step: 5
Training loss: 2.801370143890381
Validation loss: 1.9935320269676946

Epoch: 5| Step: 6
Training loss: 2.1347224712371826
Validation loss: 1.9968918600390035

Epoch: 5| Step: 7
Training loss: 2.2307868003845215
Validation loss: 1.9874626622405103

Epoch: 5| Step: 8
Training loss: 1.7533365488052368
Validation loss: 1.999561954570073

Epoch: 5| Step: 9
Training loss: 2.4791598320007324
Validation loss: 2.0091604225097166

Epoch: 5| Step: 10
Training loss: 1.9579941034317017
Validation loss: 2.0192054689571424

Epoch: 95| Step: 0
Training loss: 2.6276309490203857
Validation loss: 2.029769794915312

Epoch: 5| Step: 1
Training loss: 2.25840425491333
Validation loss: 2.029736445796105

Epoch: 5| Step: 2
Training loss: 2.1911168098449707
Validation loss: 2.03802901698697

Epoch: 5| Step: 3
Training loss: 1.9425204992294312
Validation loss: 2.0370317415524553

Epoch: 5| Step: 4
Training loss: 2.972139835357666
Validation loss: 2.0440552388468096

Epoch: 5| Step: 5
Training loss: 2.0636980533599854
Validation loss: 2.0387794202373875

Epoch: 5| Step: 6
Training loss: 2.2170193195343018
Validation loss: 2.044267935137595

Epoch: 5| Step: 7
Training loss: 1.6221050024032593
Validation loss: 2.043948204286637

Epoch: 5| Step: 8
Training loss: 1.5525916814804077
Validation loss: 2.0681777769519436

Epoch: 5| Step: 9
Training loss: 2.7665066719055176
Validation loss: 2.0664816864075197

Epoch: 5| Step: 10
Training loss: 2.3697595596313477
Validation loss: 2.0566728320173038

Epoch: 96| Step: 0
Training loss: 2.4263689517974854
Validation loss: 2.0508444206688994

Epoch: 5| Step: 1
Training loss: 2.822991132736206
Validation loss: 2.014051828333127

Epoch: 5| Step: 2
Training loss: 2.186641216278076
Validation loss: 1.9817005767617175

Epoch: 5| Step: 3
Training loss: 1.9000294208526611
Validation loss: 1.9640429622383528

Epoch: 5| Step: 4
Training loss: 1.9766881465911865
Validation loss: 1.9733977343446465

Epoch: 5| Step: 5
Training loss: 2.1049869060516357
Validation loss: 1.9664890817416611

Epoch: 5| Step: 6
Training loss: 1.998154640197754
Validation loss: 1.9753680254823418

Epoch: 5| Step: 7
Training loss: 2.002732515335083
Validation loss: 1.9770952322149788

Epoch: 5| Step: 8
Training loss: 2.288463592529297
Validation loss: 1.9969276176985873

Epoch: 5| Step: 9
Training loss: 2.4568819999694824
Validation loss: 2.0093081369194934

Epoch: 5| Step: 10
Training loss: 2.2936859130859375
Validation loss: 2.011971458312004

Epoch: 97| Step: 0
Training loss: 2.332545042037964
Validation loss: 2.01897527581902

Epoch: 5| Step: 1
Training loss: 2.598327159881592
Validation loss: 2.054157216061828

Epoch: 5| Step: 2
Training loss: 1.8081979751586914
Validation loss: 2.0671427352454073

Epoch: 5| Step: 3
Training loss: 2.1096749305725098
Validation loss: 2.0718756055319183

Epoch: 5| Step: 4
Training loss: 1.922899603843689
Validation loss: 2.079198614243538

Epoch: 5| Step: 5
Training loss: 2.180084705352783
Validation loss: 2.0714541148113947

Epoch: 5| Step: 6
Training loss: 2.296434164047241
Validation loss: 2.0292902838799263

Epoch: 5| Step: 7
Training loss: 2.291201114654541
Validation loss: 2.0173249577963226

Epoch: 5| Step: 8
Training loss: 1.9640191793441772
Validation loss: 2.005212640249601

Epoch: 5| Step: 9
Training loss: 2.0955862998962402
Validation loss: 2.0124058710631503

Epoch: 5| Step: 10
Training loss: 2.3898046016693115
Validation loss: 2.0164149743254467

Epoch: 98| Step: 0
Training loss: 2.3221709728240967
Validation loss: 2.024188054505215

Epoch: 5| Step: 1
Training loss: 2.0029873847961426
Validation loss: 2.040197003272272

Epoch: 5| Step: 2
Training loss: 2.7473409175872803
Validation loss: 2.05098735004343

Epoch: 5| Step: 3
Training loss: 2.2011730670928955
Validation loss: 2.060974303112235

Epoch: 5| Step: 4
Training loss: 1.9654228687286377
Validation loss: 2.0667705638434297

Epoch: 5| Step: 5
Training loss: 2.1353840827941895
Validation loss: 2.0520484191115185

Epoch: 5| Step: 6
Training loss: 2.098295211791992
Validation loss: 2.0598140967789518

Epoch: 5| Step: 7
Training loss: 2.7555575370788574
Validation loss: 2.047396625241926

Epoch: 5| Step: 8
Training loss: 1.521594762802124
Validation loss: 2.0420605995321788

Epoch: 5| Step: 9
Training loss: 2.197831153869629
Validation loss: 2.0253738575084235

Epoch: 5| Step: 10
Training loss: 1.885613203048706
Validation loss: 2.0290827981887327

Epoch: 99| Step: 0
Training loss: 2.627711534500122
Validation loss: 2.0179396188387306

Epoch: 5| Step: 1
Training loss: 1.9167743921279907
Validation loss: 2.0163914913772256

Epoch: 5| Step: 2
Training loss: 2.5262999534606934
Validation loss: 2.013514253400987

Epoch: 5| Step: 3
Training loss: 1.9101941585540771
Validation loss: 2.0094833399659846

Epoch: 5| Step: 4
Training loss: 2.6312100887298584
Validation loss: 2.011382841294812

Epoch: 5| Step: 5
Training loss: 2.068861484527588
Validation loss: 2.0210738848614436

Epoch: 5| Step: 6
Training loss: 2.3867547512054443
Validation loss: 2.033526123210948

Epoch: 5| Step: 7
Training loss: 2.075838565826416
Validation loss: 2.0235003450865388

Epoch: 5| Step: 8
Training loss: 1.30867600440979
Validation loss: 2.0210081249155025

Epoch: 5| Step: 9
Training loss: 2.256805896759033
Validation loss: 2.0005300378286712

Epoch: 5| Step: 10
Training loss: 2.268322467803955
Validation loss: 2.0010438324302755

Epoch: 100| Step: 0
Training loss: 1.9702666997909546
Validation loss: 2.00673088976132

Epoch: 5| Step: 1
Training loss: 2.1841750144958496
Validation loss: 2.016145080648443

Epoch: 5| Step: 2
Training loss: 2.3195042610168457
Validation loss: 2.0227147776593446

Epoch: 5| Step: 3
Training loss: 2.870349884033203
Validation loss: 2.012300811788087

Epoch: 5| Step: 4
Training loss: 1.1459673643112183
Validation loss: 1.9950520351368894

Epoch: 5| Step: 5
Training loss: 2.2997517585754395
Validation loss: 2.0041554230515675

Epoch: 5| Step: 6
Training loss: 2.7990665435791016
Validation loss: 2.0204436522658153

Epoch: 5| Step: 7
Training loss: 2.0036251544952393
Validation loss: 2.042899641939389

Epoch: 5| Step: 8
Training loss: 2.5811944007873535
Validation loss: 2.0541488637206373

Epoch: 5| Step: 9
Training loss: 1.8618320226669312
Validation loss: 2.0466480896037114

Epoch: 5| Step: 10
Training loss: 1.9066096544265747
Validation loss: 2.0318611283456125

Epoch: 101| Step: 0
Training loss: 2.412108898162842
Validation loss: 2.016190057159752

Epoch: 5| Step: 1
Training loss: 1.8597749471664429
Validation loss: 2.0078162903426797

Epoch: 5| Step: 2
Training loss: 1.7640537023544312
Validation loss: 2.0057199078221477

Epoch: 5| Step: 3
Training loss: 2.240631103515625
Validation loss: 1.9902790131107453

Epoch: 5| Step: 4
Training loss: 2.046384334564209
Validation loss: 1.992244771731797

Epoch: 5| Step: 5
Training loss: 2.147759437561035
Validation loss: 1.9975126712552962

Epoch: 5| Step: 6
Training loss: 2.4746251106262207
Validation loss: 1.9943888405317902

Epoch: 5| Step: 7
Training loss: 2.4263863563537598
Validation loss: 2.0104416365264566

Epoch: 5| Step: 8
Training loss: 1.8153902292251587
Validation loss: 2.0261845050319547

Epoch: 5| Step: 9
Training loss: 2.2288033962249756
Validation loss: 2.043714213114913

Epoch: 5| Step: 10
Training loss: 2.011526107788086
Validation loss: 2.0508536587479296

Epoch: 102| Step: 0
Training loss: 2.3546125888824463
Validation loss: 2.0877209299354145

Epoch: 5| Step: 1
Training loss: 1.6795717477798462
Validation loss: 2.075801205891435

Epoch: 5| Step: 2
Training loss: 2.344505786895752
Validation loss: 2.0602023011894635

Epoch: 5| Step: 3
Training loss: 1.913313865661621
Validation loss: 2.0438370576468845

Epoch: 5| Step: 4
Training loss: 2.0645222663879395
Validation loss: 2.0215670344650105

Epoch: 5| Step: 5
Training loss: 2.725374460220337
Validation loss: 2.0272142835842666

Epoch: 5| Step: 6
Training loss: 2.011748790740967
Validation loss: 2.0031797975622196

Epoch: 5| Step: 7
Training loss: 1.9220678806304932
Validation loss: 2.009424389049571

Epoch: 5| Step: 8
Training loss: 1.3113362789154053
Validation loss: 1.9982682812598445

Epoch: 5| Step: 9
Training loss: 2.379513740539551
Validation loss: 2.005889747732429

Epoch: 5| Step: 10
Training loss: 2.8777942657470703
Validation loss: 2.0072541698332755

Epoch: 103| Step: 0
Training loss: 2.1850087642669678
Validation loss: 2.008073781126289

Epoch: 5| Step: 1
Training loss: 2.1542563438415527
Validation loss: 1.9993456473914526

Epoch: 5| Step: 2
Training loss: 2.6479246616363525
Validation loss: 1.992644061324417

Epoch: 5| Step: 3
Training loss: 1.7146265506744385
Validation loss: 1.990916875100905

Epoch: 5| Step: 4
Training loss: 2.0118556022644043
Validation loss: 1.9826809667771863

Epoch: 5| Step: 5
Training loss: 1.8638858795166016
Validation loss: 1.9935318577674128

Epoch: 5| Step: 6
Training loss: 2.3113462924957275
Validation loss: 2.014484526008688

Epoch: 5| Step: 7
Training loss: 1.552398920059204
Validation loss: 2.0294066565011137

Epoch: 5| Step: 8
Training loss: 2.5233216285705566
Validation loss: 2.025656733461606

Epoch: 5| Step: 9
Training loss: 2.2951931953430176
Validation loss: 2.016321579615275

Epoch: 5| Step: 10
Training loss: 1.8364545106887817
Validation loss: 2.0039716330907678

Epoch: 104| Step: 0
Training loss: 2.284825086593628
Validation loss: 2.0389154739277338

Epoch: 5| Step: 1
Training loss: 2.1443629264831543
Validation loss: 2.0389898361698275

Epoch: 5| Step: 2
Training loss: 3.009687900543213
Validation loss: 2.0268178383509317

Epoch: 5| Step: 3
Training loss: 1.521976113319397
Validation loss: 1.9987711342432166

Epoch: 5| Step: 4
Training loss: 1.681148886680603
Validation loss: 2.0021900758948377

Epoch: 5| Step: 5
Training loss: 2.324707269668579
Validation loss: 1.9894124795031805

Epoch: 5| Step: 6
Training loss: 2.184333324432373
Validation loss: 1.9884754534690612

Epoch: 5| Step: 7
Training loss: 2.317845582962036
Validation loss: 1.9936781006474649

Epoch: 5| Step: 8
Training loss: 2.4106662273406982
Validation loss: 1.9941034778471916

Epoch: 5| Step: 9
Training loss: 1.8502748012542725
Validation loss: 2.001344834604571

Epoch: 5| Step: 10
Training loss: 1.2551155090332031
Validation loss: 2.0013165384210567

Epoch: 105| Step: 0
Training loss: 1.946864366531372
Validation loss: 2.0178723976176274

Epoch: 5| Step: 1
Training loss: 1.9897677898406982
Validation loss: 2.035023361124018

Epoch: 5| Step: 2
Training loss: 1.8448936939239502
Validation loss: 2.054731317745742

Epoch: 5| Step: 3
Training loss: 2.5928847789764404
Validation loss: 2.058495565127301

Epoch: 5| Step: 4
Training loss: 2.435389995574951
Validation loss: 2.0491772774727113

Epoch: 5| Step: 5
Training loss: 2.105435848236084
Validation loss: 2.0266968075947096

Epoch: 5| Step: 6
Training loss: 2.595273017883301
Validation loss: 2.013854544649842

Epoch: 5| Step: 7
Training loss: 2.408895969390869
Validation loss: 2.0186830400138773

Epoch: 5| Step: 8
Training loss: 1.9443566799163818
Validation loss: 2.011470684441187

Epoch: 5| Step: 9
Training loss: 1.7813708782196045
Validation loss: 2.00680644794177

Epoch: 5| Step: 10
Training loss: 1.4573705196380615
Validation loss: 2.0063302311846005

Epoch: 106| Step: 0
Training loss: 2.192254066467285
Validation loss: 2.027222628234535

Epoch: 5| Step: 1
Training loss: 1.8120876550674438
Validation loss: 2.040139558494732

Epoch: 5| Step: 2
Training loss: 1.7728636264801025
Validation loss: 2.0299954619458926

Epoch: 5| Step: 3
Training loss: 1.8525397777557373
Validation loss: 2.0206527940688597

Epoch: 5| Step: 4
Training loss: 2.070582151412964
Validation loss: 2.01492658481803

Epoch: 5| Step: 5
Training loss: 2.097285509109497
Validation loss: 1.9700740614245016

Epoch: 5| Step: 6
Training loss: 2.405813694000244
Validation loss: 1.965239030058666

Epoch: 5| Step: 7
Training loss: 2.8570029735565186
Validation loss: 1.9634380058575702

Epoch: 5| Step: 8
Training loss: 2.2006630897521973
Validation loss: 1.9573698812915432

Epoch: 5| Step: 9
Training loss: 2.264120578765869
Validation loss: 1.9616949071166336

Epoch: 5| Step: 10
Training loss: 1.5368572473526
Validation loss: 1.97419737744075

Epoch: 107| Step: 0
Training loss: 1.7782262563705444
Validation loss: 2.0055733919143677

Epoch: 5| Step: 1
Training loss: 2.3466274738311768
Validation loss: 2.0340513337043022

Epoch: 5| Step: 2
Training loss: 2.4695067405700684
Validation loss: 2.040105571029007

Epoch: 5| Step: 3
Training loss: 2.0198240280151367
Validation loss: 2.0630255463302776

Epoch: 5| Step: 4
Training loss: 1.9791643619537354
Validation loss: 2.0888025478650163

Epoch: 5| Step: 5
Training loss: 2.354306697845459
Validation loss: 2.0764229169455906

Epoch: 5| Step: 6
Training loss: 2.0922048091888428
Validation loss: 2.0653142185621363

Epoch: 5| Step: 7
Training loss: 1.918508529663086
Validation loss: 2.0388292920204902

Epoch: 5| Step: 8
Training loss: 2.132211685180664
Validation loss: 2.045540207175798

Epoch: 5| Step: 9
Training loss: 2.1718928813934326
Validation loss: 2.0447013249961277

Epoch: 5| Step: 10
Training loss: 1.6758140325546265
Validation loss: 2.074677603219145

Epoch: 108| Step: 0
Training loss: 2.2114529609680176
Validation loss: 2.0845878457510345

Epoch: 5| Step: 1
Training loss: 2.4511783123016357
Validation loss: 2.099047924882622

Epoch: 5| Step: 2
Training loss: 2.05082368850708
Validation loss: 2.1118797435555408

Epoch: 5| Step: 3
Training loss: 2.4509706497192383
Validation loss: 2.0976749748312016

Epoch: 5| Step: 4
Training loss: 1.6558940410614014
Validation loss: 2.091543056631601

Epoch: 5| Step: 5
Training loss: 1.9507324695587158
Validation loss: 2.0584685482004637

Epoch: 5| Step: 6
Training loss: 1.827064871788025
Validation loss: 2.0672007491511684

Epoch: 5| Step: 7
Training loss: 2.0664725303649902
Validation loss: 2.022234050176477

Epoch: 5| Step: 8
Training loss: 2.082332134246826
Validation loss: 2.000272999527634

Epoch: 5| Step: 9
Training loss: 2.1551883220672607
Validation loss: 1.9973199162431943

Epoch: 5| Step: 10
Training loss: 2.2854127883911133
Validation loss: 1.9922977750019362

Epoch: 109| Step: 0
Training loss: 1.9655272960662842
Validation loss: 1.9733721210110573

Epoch: 5| Step: 1
Training loss: 1.4173110723495483
Validation loss: 1.9677033232104393

Epoch: 5| Step: 2
Training loss: 1.9805495738983154
Validation loss: 1.9709575176239014

Epoch: 5| Step: 3
Training loss: 1.9122635126113892
Validation loss: 1.9790479047324068

Epoch: 5| Step: 4
Training loss: 1.7719764709472656
Validation loss: 1.9958395547764276

Epoch: 5| Step: 5
Training loss: 2.5252621173858643
Validation loss: 2.030307332674662

Epoch: 5| Step: 6
Training loss: 2.3428878784179688
Validation loss: 2.047840851609425

Epoch: 5| Step: 7
Training loss: 1.9332854747772217
Validation loss: 2.054277289298273

Epoch: 5| Step: 8
Training loss: 2.3629260063171387
Validation loss: 2.0786400277127504

Epoch: 5| Step: 9
Training loss: 1.6584560871124268
Validation loss: 2.0910116818643387

Epoch: 5| Step: 10
Training loss: 3.0436580181121826
Validation loss: 2.0697381060610534

Epoch: 110| Step: 0
Training loss: 2.377650022506714
Validation loss: 2.0600341084182903

Epoch: 5| Step: 1
Training loss: 2.1834607124328613
Validation loss: 2.0296516110820155

Epoch: 5| Step: 2
Training loss: 2.014319896697998
Validation loss: 2.0180554530953847

Epoch: 5| Step: 3
Training loss: 2.091522693634033
Validation loss: 1.9987688346575665

Epoch: 5| Step: 4
Training loss: 2.3805992603302
Validation loss: 1.9878867621062903

Epoch: 5| Step: 5
Training loss: 2.5096614360809326
Validation loss: 1.987023804777412

Epoch: 5| Step: 6
Training loss: 1.558479905128479
Validation loss: 1.9667010845676545

Epoch: 5| Step: 7
Training loss: 2.22613787651062
Validation loss: 1.9657007289189163

Epoch: 5| Step: 8
Training loss: 1.38124680519104
Validation loss: 1.9755808012459868

Epoch: 5| Step: 9
Training loss: 1.931908369064331
Validation loss: 1.9811510629551385

Epoch: 5| Step: 10
Training loss: 1.9159144163131714
Validation loss: 1.988508439833118

Epoch: 111| Step: 0
Training loss: 1.9452130794525146
Validation loss: 1.9942138220674248

Epoch: 5| Step: 1
Training loss: 1.7418533563613892
Validation loss: 1.9946861241453437

Epoch: 5| Step: 2
Training loss: 2.474433183670044
Validation loss: 1.9965390671965897

Epoch: 5| Step: 3
Training loss: 1.5956467390060425
Validation loss: 2.0121662168092627

Epoch: 5| Step: 4
Training loss: 2.3502755165100098
Validation loss: 2.0208481588671283

Epoch: 5| Step: 5
Training loss: 1.6460211277008057
Validation loss: 2.0112505164197696

Epoch: 5| Step: 6
Training loss: 2.3903586864471436
Validation loss: 2.0144929270590506

Epoch: 5| Step: 7
Training loss: 2.0911498069763184
Validation loss: 2.0167428857536724

Epoch: 5| Step: 8
Training loss: 2.554028272628784
Validation loss: 2.023054343397899

Epoch: 5| Step: 9
Training loss: 1.7186648845672607
Validation loss: 2.024358618643976

Epoch: 5| Step: 10
Training loss: 1.5652039051055908
Validation loss: 2.0259839988523916

Epoch: 112| Step: 0
Training loss: 2.436730146408081
Validation loss: 2.0263994816810853

Epoch: 5| Step: 1
Training loss: 2.044951915740967
Validation loss: 2.021642836191321

Epoch: 5| Step: 2
Training loss: 2.3200459480285645
Validation loss: 2.00798342304845

Epoch: 5| Step: 3
Training loss: 1.7063820362091064
Validation loss: 1.9971564828708608

Epoch: 5| Step: 4
Training loss: 1.9343948364257812
Validation loss: 1.9942126222836074

Epoch: 5| Step: 5
Training loss: 1.6696479320526123
Validation loss: 1.970982636174848

Epoch: 5| Step: 6
Training loss: 1.8849109411239624
Validation loss: 1.97890438572053

Epoch: 5| Step: 7
Training loss: 2.146779775619507
Validation loss: 1.9798718729326803

Epoch: 5| Step: 8
Training loss: 2.072272777557373
Validation loss: 1.9839581558781285

Epoch: 5| Step: 9
Training loss: 1.4287985563278198
Validation loss: 1.9985228302658244

Epoch: 5| Step: 10
Training loss: 2.3804116249084473
Validation loss: 2.0465796814169934

Epoch: 113| Step: 0
Training loss: 2.0397770404815674
Validation loss: 2.080822137094313

Epoch: 5| Step: 1
Training loss: 2.322735071182251
Validation loss: 2.088639441356864

Epoch: 5| Step: 2
Training loss: 1.8382247686386108
Validation loss: 2.0767610944727415

Epoch: 5| Step: 3
Training loss: 1.788187026977539
Validation loss: 2.0652323512620825

Epoch: 5| Step: 4
Training loss: 2.1796813011169434
Validation loss: 2.032797964670325

Epoch: 5| Step: 5
Training loss: 1.94746994972229
Validation loss: 2.016304636514315

Epoch: 5| Step: 6
Training loss: 1.6816909313201904
Validation loss: 2.0307907878711657

Epoch: 5| Step: 7
Training loss: 1.559922456741333
Validation loss: 2.014450470606486

Epoch: 5| Step: 8
Training loss: 2.4975345134735107
Validation loss: 2.0296201372659333

Epoch: 5| Step: 9
Training loss: 2.101367235183716
Validation loss: 2.0251322151512228

Epoch: 5| Step: 10
Training loss: 1.9985167980194092
Validation loss: 2.004587955372308

Epoch: 114| Step: 0
Training loss: 1.995482087135315
Validation loss: 2.0223587648842924

Epoch: 5| Step: 1
Training loss: 1.603285789489746
Validation loss: 2.038700977961222

Epoch: 5| Step: 2
Training loss: 2.3343825340270996
Validation loss: 2.0489715376207904

Epoch: 5| Step: 3
Training loss: 1.8661880493164062
Validation loss: 2.041204490969258

Epoch: 5| Step: 4
Training loss: 1.8333842754364014
Validation loss: 2.022077013087529

Epoch: 5| Step: 5
Training loss: 2.00679349899292
Validation loss: 2.008172209544848

Epoch: 5| Step: 6
Training loss: 2.8480725288391113
Validation loss: 2.024589551392422

Epoch: 5| Step: 7
Training loss: 1.4657056331634521
Validation loss: 2.0340699175352692

Epoch: 5| Step: 8
Training loss: 2.697303056716919
Validation loss: 2.043849165721606

Epoch: 5| Step: 9
Training loss: 1.568037986755371
Validation loss: 2.039493194190405

Epoch: 5| Step: 10
Training loss: 1.681287169456482
Validation loss: 2.0468268163742556

Epoch: 115| Step: 0
Training loss: 2.356766939163208
Validation loss: 2.0375116602067025

Epoch: 5| Step: 1
Training loss: 2.119266986846924
Validation loss: 2.027118414960882

Epoch: 5| Step: 2
Training loss: 2.5759711265563965
Validation loss: 2.0126009218154417

Epoch: 5| Step: 3
Training loss: 1.8187707662582397
Validation loss: 2.0057622066108127

Epoch: 5| Step: 4
Training loss: 2.1290736198425293
Validation loss: 2.0129211525763235

Epoch: 5| Step: 5
Training loss: 1.4838507175445557
Validation loss: 2.030264492957823

Epoch: 5| Step: 6
Training loss: 2.010833263397217
Validation loss: 2.027241050556142

Epoch: 5| Step: 7
Training loss: 1.670243501663208
Validation loss: 2.053967288745347

Epoch: 5| Step: 8
Training loss: 2.2061734199523926
Validation loss: 2.063966671625773

Epoch: 5| Step: 9
Training loss: 1.6194660663604736
Validation loss: 2.054908579395663

Epoch: 5| Step: 10
Training loss: 1.7587964534759521
Validation loss: 2.043339349890268

Epoch: 116| Step: 0
Training loss: 2.3383889198303223
Validation loss: 2.0196085194105744

Epoch: 5| Step: 1
Training loss: 1.6896741390228271
Validation loss: 1.991025665754913

Epoch: 5| Step: 2
Training loss: 2.0780532360076904
Validation loss: 2.0152683770784767

Epoch: 5| Step: 3
Training loss: 1.7141876220703125
Validation loss: 2.036950583099037

Epoch: 5| Step: 4
Training loss: 3.1449031829833984
Validation loss: 2.052877067237772

Epoch: 5| Step: 5
Training loss: 1.1897847652435303
Validation loss: 2.073684274509389

Epoch: 5| Step: 6
Training loss: 1.3289124965667725
Validation loss: 2.0870856726041405

Epoch: 5| Step: 7
Training loss: 2.6871047019958496
Validation loss: 2.069528447684421

Epoch: 5| Step: 8
Training loss: 1.9219032526016235
Validation loss: 2.0372031529744468

Epoch: 5| Step: 9
Training loss: 1.59647536277771
Validation loss: 2.038190964729555

Epoch: 5| Step: 10
Training loss: 1.7160553932189941
Validation loss: 2.0116628831432712

Epoch: 117| Step: 0
Training loss: 1.9920663833618164
Validation loss: 2.001923544432527

Epoch: 5| Step: 1
Training loss: 1.5501571893692017
Validation loss: 2.0106747445239814

Epoch: 5| Step: 2
Training loss: 2.4153857231140137
Validation loss: 1.9991929582370225

Epoch: 5| Step: 3
Training loss: 1.9749664068222046
Validation loss: 1.9982984271100772

Epoch: 5| Step: 4
Training loss: 1.8720594644546509
Validation loss: 1.9863965370321786

Epoch: 5| Step: 5
Training loss: 2.0333094596862793
Validation loss: 1.9799365843496015

Epoch: 5| Step: 6
Training loss: 2.2426819801330566
Validation loss: 1.9896097747228478

Epoch: 5| Step: 7
Training loss: 2.0534157752990723
Validation loss: 2.0130574780125774

Epoch: 5| Step: 8
Training loss: 1.7377030849456787
Validation loss: 2.003056864584646

Epoch: 5| Step: 9
Training loss: 1.8113658428192139
Validation loss: 1.9947915051573066

Epoch: 5| Step: 10
Training loss: 2.00797963142395
Validation loss: 1.991819118940702

Epoch: 118| Step: 0
Training loss: 2.245797634124756
Validation loss: 1.9917896563006985

Epoch: 5| Step: 1
Training loss: 2.275028705596924
Validation loss: 2.001905454102383

Epoch: 5| Step: 2
Training loss: 1.0430442094802856
Validation loss: 2.007048995264115

Epoch: 5| Step: 3
Training loss: 1.3549344539642334
Validation loss: 2.031839483527727

Epoch: 5| Step: 4
Training loss: 1.6745163202285767
Validation loss: 2.0345809677595734

Epoch: 5| Step: 5
Training loss: 2.1661088466644287
Validation loss: 2.05394503378099

Epoch: 5| Step: 6
Training loss: 2.41835355758667
Validation loss: 2.053299416777908

Epoch: 5| Step: 7
Training loss: 1.7420835494995117
Validation loss: 2.0477732035421554

Epoch: 5| Step: 8
Training loss: 2.1246941089630127
Validation loss: 2.0238225447234286

Epoch: 5| Step: 9
Training loss: 1.5488086938858032
Validation loss: 2.0288500555099978

Epoch: 5| Step: 10
Training loss: 2.716798782348633
Validation loss: 2.027977584510721

Epoch: 119| Step: 0
Training loss: 2.056161880493164
Validation loss: 2.019390130555758

Epoch: 5| Step: 1
Training loss: 2.0135035514831543
Validation loss: 2.010334849357605

Epoch: 5| Step: 2
Training loss: 2.3839774131774902
Validation loss: 2.0070230460936025

Epoch: 5| Step: 3
Training loss: 1.649206519126892
Validation loss: 1.9873957723699591

Epoch: 5| Step: 4
Training loss: 1.6610729694366455
Validation loss: 1.9920286542625838

Epoch: 5| Step: 5
Training loss: 2.262543201446533
Validation loss: 1.981755966781288

Epoch: 5| Step: 6
Training loss: 1.4579761028289795
Validation loss: 1.9928956441981818

Epoch: 5| Step: 7
Training loss: 1.9754009246826172
Validation loss: 1.9974663885690833

Epoch: 5| Step: 8
Training loss: 1.9064077138900757
Validation loss: 1.9961065528213338

Epoch: 5| Step: 9
Training loss: 1.6830470561981201
Validation loss: 2.0203022367210797

Epoch: 5| Step: 10
Training loss: 2.2870943546295166
Validation loss: 2.046562164060531

Epoch: 120| Step: 0
Training loss: 1.9700539112091064
Validation loss: 2.058447366119713

Epoch: 5| Step: 1
Training loss: 1.9837777614593506
Validation loss: 2.079834976503926

Epoch: 5| Step: 2
Training loss: 1.5661566257476807
Validation loss: 2.068440327080347

Epoch: 5| Step: 3
Training loss: 2.1109790802001953
Validation loss: 2.039398216432141

Epoch: 5| Step: 4
Training loss: 1.6001555919647217
Validation loss: 1.993274211883545

Epoch: 5| Step: 5
Training loss: 2.5212273597717285
Validation loss: 1.9936782775386688

Epoch: 5| Step: 6
Training loss: 1.6642000675201416
Validation loss: 2.0295854691536195

Epoch: 5| Step: 7
Training loss: 2.3135623931884766
Validation loss: 2.0421001218980357

Epoch: 5| Step: 8
Training loss: 1.6299192905426025
Validation loss: 2.064685134477513

Epoch: 5| Step: 9
Training loss: 1.9689651727676392
Validation loss: 2.0744748397540023

Epoch: 5| Step: 10
Training loss: 2.0169713497161865
Validation loss: 2.085344386357133

Epoch: 121| Step: 0
Training loss: 1.9807579517364502
Validation loss: 2.1087605953216553

Epoch: 5| Step: 1
Training loss: 1.782941460609436
Validation loss: 2.118228353479857

Epoch: 5| Step: 2
Training loss: 1.6141716241836548
Validation loss: 2.1072811285654702

Epoch: 5| Step: 3
Training loss: 1.9819046258926392
Validation loss: 2.0693539957846365

Epoch: 5| Step: 4
Training loss: 1.9247996807098389
Validation loss: 2.031105051758469

Epoch: 5| Step: 5
Training loss: 2.314335346221924
Validation loss: 2.005404381341832

Epoch: 5| Step: 6
Training loss: 2.2838563919067383
Validation loss: 1.9873996511582406

Epoch: 5| Step: 7
Training loss: 1.6786102056503296
Validation loss: 1.9742461430129183

Epoch: 5| Step: 8
Training loss: 1.75990891456604
Validation loss: 1.998431731295842

Epoch: 5| Step: 9
Training loss: 1.6146150827407837
Validation loss: 1.9943557990494596

Epoch: 5| Step: 10
Training loss: 2.129903554916382
Validation loss: 2.0315801892229306

Epoch: 122| Step: 0
Training loss: 2.270592212677002
Validation loss: 2.05671428608638

Epoch: 5| Step: 1
Training loss: 1.8248167037963867
Validation loss: 2.0734430397710493

Epoch: 5| Step: 2
Training loss: 1.9351463317871094
Validation loss: 2.112064343626781

Epoch: 5| Step: 3
Training loss: 1.4864575862884521
Validation loss: 2.110958981257613

Epoch: 5| Step: 4
Training loss: 2.159653425216675
Validation loss: 2.097359670105801

Epoch: 5| Step: 5
Training loss: 1.7225230932235718
Validation loss: 2.0885094596493627

Epoch: 5| Step: 6
Training loss: 1.7974430322647095
Validation loss: 2.0666356086730957

Epoch: 5| Step: 7
Training loss: 1.9722959995269775
Validation loss: 2.0504119062936432

Epoch: 5| Step: 8
Training loss: 2.0766444206237793
Validation loss: 2.0402613775704497

Epoch: 5| Step: 9
Training loss: 2.254594326019287
Validation loss: 2.0453591667195803

Epoch: 5| Step: 10
Training loss: 1.2202223539352417
Validation loss: 2.039307303326104

Epoch: 123| Step: 0
Training loss: 2.0060312747955322
Validation loss: 2.029452540541208

Epoch: 5| Step: 1
Training loss: 1.5498167276382446
Validation loss: 2.0116758884922152

Epoch: 5| Step: 2
Training loss: 1.7855145931243896
Validation loss: 1.9906206092526835

Epoch: 5| Step: 3
Training loss: 2.064371347427368
Validation loss: 1.9839565164299422

Epoch: 5| Step: 4
Training loss: 1.5754339694976807
Validation loss: 1.9793034189490861

Epoch: 5| Step: 5
Training loss: 1.6384594440460205
Validation loss: 2.0027611306918565

Epoch: 5| Step: 6
Training loss: 1.7498276233673096
Validation loss: 2.02764916676347

Epoch: 5| Step: 7
Training loss: 2.4566426277160645
Validation loss: 2.0709031192205285

Epoch: 5| Step: 8
Training loss: 1.9955848455429077
Validation loss: 2.109927769630186

Epoch: 5| Step: 9
Training loss: 1.7803312540054321
Validation loss: 2.1050897618775726

Epoch: 5| Step: 10
Training loss: 2.0298237800598145
Validation loss: 2.0871202535526727

Epoch: 124| Step: 0
Training loss: 1.630666732788086
Validation loss: 2.093225795735595

Epoch: 5| Step: 1
Training loss: 1.2018687725067139
Validation loss: 2.1127894411804857

Epoch: 5| Step: 2
Training loss: 2.0571553707122803
Validation loss: 2.083905076467863

Epoch: 5| Step: 3
Training loss: 2.321437358856201
Validation loss: 2.066934052334037

Epoch: 5| Step: 4
Training loss: 1.9389126300811768
Validation loss: 2.0542793530289845

Epoch: 5| Step: 5
Training loss: 2.3750267028808594
Validation loss: 2.0350604031675603

Epoch: 5| Step: 6
Training loss: 1.5122706890106201
Validation loss: 1.9992452949605963

Epoch: 5| Step: 7
Training loss: 1.9797782897949219
Validation loss: 1.9965284203970304

Epoch: 5| Step: 8
Training loss: 2.2044873237609863
Validation loss: 2.0079752245256977

Epoch: 5| Step: 9
Training loss: 1.48951256275177
Validation loss: 1.9874293650350263

Epoch: 5| Step: 10
Training loss: 1.738908052444458
Validation loss: 1.9858942339497228

Epoch: 125| Step: 0
Training loss: 1.9914668798446655
Validation loss: 2.011690644807713

Epoch: 5| Step: 1
Training loss: 2.0572564601898193
Validation loss: 2.0122426299638647

Epoch: 5| Step: 2
Training loss: 1.8947267532348633
Validation loss: 2.037776070256387

Epoch: 5| Step: 3
Training loss: 1.6631507873535156
Validation loss: 2.0676189084206857

Epoch: 5| Step: 4
Training loss: 2.075307607650757
Validation loss: 2.08598820881177

Epoch: 5| Step: 5
Training loss: 1.5979301929473877
Validation loss: 2.1145991689415387

Epoch: 5| Step: 6
Training loss: 1.6142810583114624
Validation loss: 2.102531994542768

Epoch: 5| Step: 7
Training loss: 1.695701241493225
Validation loss: 2.1128333909537202

Epoch: 5| Step: 8
Training loss: 1.8283008337020874
Validation loss: 2.0834540961891093

Epoch: 5| Step: 9
Training loss: 1.937543511390686
Validation loss: 2.0914936398947113

Epoch: 5| Step: 10
Training loss: 2.0632500648498535
Validation loss: 2.059957132544569

Epoch: 126| Step: 0
Training loss: 1.8576345443725586
Validation loss: 2.0424075639376076

Epoch: 5| Step: 1
Training loss: 2.078869342803955
Validation loss: 2.0330110890890962

Epoch: 5| Step: 2
Training loss: 1.6595065593719482
Validation loss: 2.0346132593770183

Epoch: 5| Step: 3
Training loss: 1.5319150686264038
Validation loss: 2.040286200020903

Epoch: 5| Step: 4
Training loss: 1.614147424697876
Validation loss: 2.034331621662263

Epoch: 5| Step: 5
Training loss: 1.5658605098724365
Validation loss: 2.045436477148405

Epoch: 5| Step: 6
Training loss: 1.969305396080017
Validation loss: 2.0618163154971216

Epoch: 5| Step: 7
Training loss: 2.1863207817077637
Validation loss: 2.084724723651845

Epoch: 5| Step: 8
Training loss: 1.7022449970245361
Validation loss: 2.0779826435991513

Epoch: 5| Step: 9
Training loss: 1.8182296752929688
Validation loss: 2.0702710792582524

Epoch: 5| Step: 10
Training loss: 2.264906167984009
Validation loss: 2.054771618176532

Epoch: 127| Step: 0
Training loss: 1.2445961236953735
Validation loss: 2.036686620404643

Epoch: 5| Step: 1
Training loss: 1.763622522354126
Validation loss: 2.00739541874137

Epoch: 5| Step: 2
Training loss: 1.1828958988189697
Validation loss: 2.018036187336009

Epoch: 5| Step: 3
Training loss: 1.7708934545516968
Validation loss: 2.0556087775896956

Epoch: 5| Step: 4
Training loss: 2.065732479095459
Validation loss: 2.069717199571671

Epoch: 5| Step: 5
Training loss: 2.2252516746520996
Validation loss: 2.0571498537576325

Epoch: 5| Step: 6
Training loss: 2.221841812133789
Validation loss: 2.026020560213315

Epoch: 5| Step: 7
Training loss: 1.6391973495483398
Validation loss: 2.0398324074283725

Epoch: 5| Step: 8
Training loss: 2.1110761165618896
Validation loss: 2.0709089079210834

Epoch: 5| Step: 9
Training loss: 2.155738353729248
Validation loss: 2.112358445762306

Epoch: 5| Step: 10
Training loss: 2.056766986846924
Validation loss: 2.1527460646885697

Epoch: 128| Step: 0
Training loss: 1.661505937576294
Validation loss: 2.1886164014057448

Epoch: 5| Step: 1
Training loss: 1.7850215435028076
Validation loss: 2.1812651054833525

Epoch: 5| Step: 2
Training loss: 1.8847659826278687
Validation loss: 2.08133513440368

Epoch: 5| Step: 3
Training loss: 2.2795443534851074
Validation loss: 2.020470732001848

Epoch: 5| Step: 4
Training loss: 1.9560407400131226
Validation loss: 2.0098035181722333

Epoch: 5| Step: 5
Training loss: 1.5418646335601807
Validation loss: 2.01083380176175

Epoch: 5| Step: 6
Training loss: 2.111973762512207
Validation loss: 2.0160786515922955

Epoch: 5| Step: 7
Training loss: 2.0598416328430176
Validation loss: 2.046055345125096

Epoch: 5| Step: 8
Training loss: 1.8403425216674805
Validation loss: 2.068821559670151

Epoch: 5| Step: 9
Training loss: 2.198986530303955
Validation loss: 2.0737879507003294

Epoch: 5| Step: 10
Training loss: 1.8118377923965454
Validation loss: 2.030587318123028

Epoch: 129| Step: 0
Training loss: 1.7755486965179443
Validation loss: 2.034898732298164

Epoch: 5| Step: 1
Training loss: 1.6874138116836548
Validation loss: 2.069651678044309

Epoch: 5| Step: 2
Training loss: 1.7803112268447876
Validation loss: 2.1112212045218355

Epoch: 5| Step: 3
Training loss: 2.200883388519287
Validation loss: 2.1513271998333674

Epoch: 5| Step: 4
Training loss: 2.3896853923797607
Validation loss: 2.1807582993661203

Epoch: 5| Step: 5
Training loss: 2.088130235671997
Validation loss: 2.127127411544964

Epoch: 5| Step: 6
Training loss: 1.6329305171966553
Validation loss: 2.0872358288816226

Epoch: 5| Step: 7
Training loss: 1.9222831726074219
Validation loss: 2.041314553189021

Epoch: 5| Step: 8
Training loss: 1.6991651058197021
Validation loss: 2.0279424062339206

Epoch: 5| Step: 9
Training loss: 1.4621412754058838
Validation loss: 2.0327968059047574

Epoch: 5| Step: 10
Training loss: 1.7054048776626587
Validation loss: 2.0588842591931744

Epoch: 130| Step: 0
Training loss: 1.5809171199798584
Validation loss: 2.071055578929122

Epoch: 5| Step: 1
Training loss: 2.2078213691711426
Validation loss: 2.0456899289161927

Epoch: 5| Step: 2
Training loss: 1.5072280168533325
Validation loss: 2.03770516508369

Epoch: 5| Step: 3
Training loss: 1.3970680236816406
Validation loss: 2.0268235129694783

Epoch: 5| Step: 4
Training loss: 1.8986374139785767
Validation loss: 2.0029189291820733

Epoch: 5| Step: 5
Training loss: 2.257204055786133
Validation loss: 2.0175485380234255

Epoch: 5| Step: 6
Training loss: 2.1981284618377686
Validation loss: 2.031473631499916

Epoch: 5| Step: 7
Training loss: 2.179884433746338
Validation loss: 2.0447243823800036

Epoch: 5| Step: 8
Training loss: 2.027498483657837
Validation loss: 2.056061524216847

Epoch: 5| Step: 9
Training loss: 1.120548129081726
Validation loss: 2.1245202326005503

Epoch: 5| Step: 10
Training loss: 1.7930487394332886
Validation loss: 2.178396704376385

Epoch: 131| Step: 0
Training loss: 1.6121746301651
Validation loss: 2.199129225105368

Epoch: 5| Step: 1
Training loss: 2.0681304931640625
Validation loss: 2.1949180633791032

Epoch: 5| Step: 2
Training loss: 1.9008338451385498
Validation loss: 2.201769591659628

Epoch: 5| Step: 3
Training loss: 1.8102943897247314
Validation loss: 2.1939219582465386

Epoch: 5| Step: 4
Training loss: 1.9806630611419678
Validation loss: 2.1734394822069394

Epoch: 5| Step: 5
Training loss: 1.7523012161254883
Validation loss: 2.131675124168396

Epoch: 5| Step: 6
Training loss: 1.9456932544708252
Validation loss: 2.0888028542200723

Epoch: 5| Step: 7
Training loss: 2.0917046070098877
Validation loss: 2.0742812387404905

Epoch: 5| Step: 8
Training loss: 1.6456172466278076
Validation loss: 2.0366921271047285

Epoch: 5| Step: 9
Training loss: 1.152395486831665
Validation loss: 2.0274207925283783

Epoch: 5| Step: 10
Training loss: 1.7857983112335205
Validation loss: 1.9816574896535566

Epoch: 132| Step: 0
Training loss: 1.3790730237960815
Validation loss: 1.9846756842828566

Epoch: 5| Step: 1
Training loss: 2.227198362350464
Validation loss: 1.9919772430132794

Epoch: 5| Step: 2
Training loss: 1.9057197570800781
Validation loss: 2.018818022102438

Epoch: 5| Step: 3
Training loss: 2.054431438446045
Validation loss: 2.0302427173942648

Epoch: 5| Step: 4
Training loss: 2.316389799118042
Validation loss: 2.055050217977134

Epoch: 5| Step: 5
Training loss: 2.1933059692382812
Validation loss: 2.0649507353382726

Epoch: 5| Step: 6
Training loss: 1.009979486465454
Validation loss: 2.0763360556735786

Epoch: 5| Step: 7
Training loss: 1.640496850013733
Validation loss: 2.0952604432259836

Epoch: 5| Step: 8
Training loss: 1.5373313426971436
Validation loss: 2.124392827351888

Epoch: 5| Step: 9
Training loss: 1.4684921503067017
Validation loss: 2.153026101409748

Epoch: 5| Step: 10
Training loss: 1.4287598133087158
Validation loss: 2.1684896215315788

Epoch: 133| Step: 0
Training loss: 1.526909589767456
Validation loss: 2.2117848575756116

Epoch: 5| Step: 1
Training loss: 1.5785290002822876
Validation loss: 2.1775827638564573

Epoch: 5| Step: 2
Training loss: 1.3967968225479126
Validation loss: 2.157847204516011

Epoch: 5| Step: 3
Training loss: 1.7434349060058594
Validation loss: 2.1039572018449024

Epoch: 5| Step: 4
Training loss: 1.9073787927627563
Validation loss: 2.040288016360293

Epoch: 5| Step: 5
Training loss: 2.2628486156463623
Validation loss: 2.009639778444844

Epoch: 5| Step: 6
Training loss: 2.00789737701416
Validation loss: 1.98976001175501

Epoch: 5| Step: 7
Training loss: 2.070624351501465
Validation loss: 1.9872546260074904

Epoch: 5| Step: 8
Training loss: 1.5521736145019531
Validation loss: 2.003338590745003

Epoch: 5| Step: 9
Training loss: 1.494467854499817
Validation loss: 2.0056996883884555

Epoch: 5| Step: 10
Training loss: 1.674946665763855
Validation loss: 2.0007643289463495

Epoch: 134| Step: 0
Training loss: 2.053736448287964
Validation loss: 1.9868326238406602

Epoch: 5| Step: 1
Training loss: 1.7864118814468384
Validation loss: 2.015358921020262

Epoch: 5| Step: 2
Training loss: 1.686746597290039
Validation loss: 2.06200740157917

Epoch: 5| Step: 3
Training loss: 1.4395331144332886
Validation loss: 2.0767207004690684

Epoch: 5| Step: 4
Training loss: 1.9349040985107422
Validation loss: 2.1278424852637836

Epoch: 5| Step: 5
Training loss: 2.1454291343688965
Validation loss: 2.116301208414057

Epoch: 5| Step: 6
Training loss: 1.7203983068466187
Validation loss: 2.119823068700811

Epoch: 5| Step: 7
Training loss: 1.8154098987579346
Validation loss: 2.097413851368812

Epoch: 5| Step: 8
Training loss: 0.9512920379638672
Validation loss: 2.1113686459038847

Epoch: 5| Step: 9
Training loss: 1.3850408792495728
Validation loss: 2.1178264746101956

Epoch: 5| Step: 10
Training loss: 2.0081398487091064
Validation loss: 2.130762452720314

Epoch: 135| Step: 0
Training loss: 2.1250669956207275
Validation loss: 2.1982532880639516

Epoch: 5| Step: 1
Training loss: 1.8814789056777954
Validation loss: 2.2011686653219242

Epoch: 5| Step: 2
Training loss: 1.7579448223114014
Validation loss: 2.2178311424870647

Epoch: 5| Step: 3
Training loss: 1.680071234703064
Validation loss: 2.1776280556955645

Epoch: 5| Step: 4
Training loss: 1.4007612466812134
Validation loss: 2.131286974876158

Epoch: 5| Step: 5
Training loss: 1.6735570430755615
Validation loss: 2.102339240812486

Epoch: 5| Step: 6
Training loss: 1.4045541286468506
Validation loss: 2.0735192644980645

Epoch: 5| Step: 7
Training loss: 2.2490668296813965
Validation loss: 2.096903927864567

Epoch: 5| Step: 8
Training loss: 2.0492072105407715
Validation loss: 2.0483739299158894

Epoch: 5| Step: 9
Training loss: 1.3623297214508057
Validation loss: 2.0205209819219445

Epoch: 5| Step: 10
Training loss: 1.3364744186401367
Validation loss: 1.987103537846637

Epoch: 136| Step: 0
Training loss: 2.0229508876800537
Validation loss: 1.984018741115447

Epoch: 5| Step: 1
Training loss: 1.5921138525009155
Validation loss: 1.986636866805374

Epoch: 5| Step: 2
Training loss: 1.5714223384857178
Validation loss: 1.9873747607713104

Epoch: 5| Step: 3
Training loss: 2.0144290924072266
Validation loss: 2.0060377172244492

Epoch: 5| Step: 4
Training loss: 2.0184807777404785
Validation loss: 2.0351624001738844

Epoch: 5| Step: 5
Training loss: 1.8478443622589111
Validation loss: 2.0732123903048936

Epoch: 5| Step: 6
Training loss: 1.234168291091919
Validation loss: 2.10703182220459

Epoch: 5| Step: 7
Training loss: 1.262424111366272
Validation loss: 2.160432307950912

Epoch: 5| Step: 8
Training loss: 1.3359490633010864
Validation loss: 2.18250250047253

Epoch: 5| Step: 9
Training loss: 1.9802124500274658
Validation loss: 2.1694410744533745

Epoch: 5| Step: 10
Training loss: 1.6073044538497925
Validation loss: 2.1668467662667714

Epoch: 137| Step: 0
Training loss: 1.5141093730926514
Validation loss: 2.1604382043243735

Epoch: 5| Step: 1
Training loss: 1.93179190158844
Validation loss: 2.1059165564916467

Epoch: 5| Step: 2
Training loss: 1.3180526494979858
Validation loss: 2.0417990248690367

Epoch: 5| Step: 3
Training loss: 1.9183915853500366
Validation loss: 2.0288988749186196

Epoch: 5| Step: 4
Training loss: 1.2707321643829346
Validation loss: 1.9999680852377286

Epoch: 5| Step: 5
Training loss: 1.8732421398162842
Validation loss: 1.9972025950749714

Epoch: 5| Step: 6
Training loss: 1.907842993736267
Validation loss: 2.0127141052676785

Epoch: 5| Step: 7
Training loss: 2.0633394718170166
Validation loss: 2.0457824250703216

Epoch: 5| Step: 8
Training loss: 1.4063020944595337
Validation loss: 2.0778701587389876

Epoch: 5| Step: 9
Training loss: 1.5351580381393433
Validation loss: 2.1370327780323644

Epoch: 5| Step: 10
Training loss: 1.581343173980713
Validation loss: 2.2026243978931057

Epoch: 138| Step: 0
Training loss: 1.3664567470550537
Validation loss: 2.2507830307047856

Epoch: 5| Step: 1
Training loss: 1.5072977542877197
Validation loss: 2.279626871949883

Epoch: 5| Step: 2
Training loss: 1.7641252279281616
Validation loss: 2.2671534271650415

Epoch: 5| Step: 3
Training loss: 0.9382165670394897
Validation loss: 2.2654233273639472

Epoch: 5| Step: 4
Training loss: 1.4962178468704224
Validation loss: 2.247282435817103

Epoch: 5| Step: 5
Training loss: 2.0858237743377686
Validation loss: 2.1593681432867564

Epoch: 5| Step: 6
Training loss: 1.9674917459487915
Validation loss: 2.090099770535705

Epoch: 5| Step: 7
Training loss: 1.6323444843292236
Validation loss: 2.067689226519677

Epoch: 5| Step: 8
Training loss: 1.7214946746826172
Validation loss: 1.9977852529095066

Epoch: 5| Step: 9
Training loss: 1.8875322341918945
Validation loss: 1.9741022894459386

Epoch: 5| Step: 10
Training loss: 2.1589102745056152
Validation loss: 1.9364808797836304

Epoch: 139| Step: 0
Training loss: 1.2238997220993042
Validation loss: 1.960733252186929

Epoch: 5| Step: 1
Training loss: 2.120252847671509
Validation loss: 1.9759870408683695

Epoch: 5| Step: 2
Training loss: 1.675254464149475
Validation loss: 1.9911894465005526

Epoch: 5| Step: 3
Training loss: 2.1902995109558105
Validation loss: 1.9836218767268683

Epoch: 5| Step: 4
Training loss: 1.7510287761688232
Validation loss: 1.9795562041703092

Epoch: 5| Step: 5
Training loss: 1.1529741287231445
Validation loss: 2.004334633068372

Epoch: 5| Step: 6
Training loss: 1.2816797494888306
Validation loss: 2.0085297194860314

Epoch: 5| Step: 7
Training loss: 1.7065155506134033
Validation loss: 2.0338036039824128

Epoch: 5| Step: 8
Training loss: 1.3785502910614014
Validation loss: 2.0335073022432226

Epoch: 5| Step: 9
Training loss: 2.3817849159240723
Validation loss: 2.0717636436544438

Epoch: 5| Step: 10
Training loss: 1.5512609481811523
Validation loss: 2.0826810175372708

Epoch: 140| Step: 0
Training loss: 1.0465115308761597
Validation loss: 2.070529022524434

Epoch: 5| Step: 1
Training loss: 1.965531349182129
Validation loss: 2.0857965818015476

Epoch: 5| Step: 2
Training loss: 1.3431832790374756
Validation loss: 2.1111759344736734

Epoch: 5| Step: 3
Training loss: 1.3953375816345215
Validation loss: 2.1272394118770475

Epoch: 5| Step: 4
Training loss: 1.7890828847885132
Validation loss: 2.1313314976230746

Epoch: 5| Step: 5
Training loss: 1.3081982135772705
Validation loss: 2.114465700682773

Epoch: 5| Step: 6
Training loss: 1.930286169052124
Validation loss: 2.095086177190145

Epoch: 5| Step: 7
Training loss: 1.4870258569717407
Validation loss: 2.0641489503204182

Epoch: 5| Step: 8
Training loss: 1.0571720600128174
Validation loss: 2.0500967297502743

Epoch: 5| Step: 9
Training loss: 2.3582236766815186
Validation loss: 2.050027616562382

Epoch: 5| Step: 10
Training loss: 1.8872690200805664
Validation loss: 2.0393098990122476

Epoch: 141| Step: 0
Training loss: 1.2545692920684814
Validation loss: 2.034158250337006

Epoch: 5| Step: 1
Training loss: 1.1092634201049805
Validation loss: 2.0447520517533824

Epoch: 5| Step: 2
Training loss: 1.4576269388198853
Validation loss: 2.0615656798885715

Epoch: 5| Step: 3
Training loss: 1.5961806774139404
Validation loss: 2.080376668642926

Epoch: 5| Step: 4
Training loss: 1.4427965879440308
Validation loss: 2.1070049501234487

Epoch: 5| Step: 5
Training loss: 1.6461988687515259
Validation loss: 2.139934424431093

Epoch: 5| Step: 6
Training loss: 1.53511643409729
Validation loss: 2.2233581799332813

Epoch: 5| Step: 7
Training loss: 2.1305365562438965
Validation loss: 2.2300748760982225

Epoch: 5| Step: 8
Training loss: 1.9754798412322998
Validation loss: 2.1936164017646544

Epoch: 5| Step: 9
Training loss: 1.5751512050628662
Validation loss: 2.09425562812436

Epoch: 5| Step: 10
Training loss: 1.8348010778427124
Validation loss: 2.058247891805505

Epoch: 142| Step: 0
Training loss: 1.6504894495010376
Validation loss: 2.0589136449239587

Epoch: 5| Step: 1
Training loss: 2.050166606903076
Validation loss: 2.0231549932110693

Epoch: 5| Step: 2
Training loss: 1.7599058151245117
Validation loss: 2.027325851942903

Epoch: 5| Step: 3
Training loss: 1.7083266973495483
Validation loss: 2.0685908384220575

Epoch: 5| Step: 4
Training loss: 1.4606704711914062
Validation loss: 2.03606592711582

Epoch: 5| Step: 5
Training loss: 1.0955688953399658
Validation loss: 2.0455800538421958

Epoch: 5| Step: 6
Training loss: 1.624383568763733
Validation loss: 2.080705992637142

Epoch: 5| Step: 7
Training loss: 0.9916795492172241
Validation loss: 2.0906528965119393

Epoch: 5| Step: 8
Training loss: 1.6528247594833374
Validation loss: 2.077991167704264

Epoch: 5| Step: 9
Training loss: 1.7175867557525635
Validation loss: 2.1155954919835573

Epoch: 5| Step: 10
Training loss: 1.415762186050415
Validation loss: 2.152644806010749

Epoch: 143| Step: 0
Training loss: 1.881839394569397
Validation loss: 2.1499414713151994

Epoch: 5| Step: 1
Training loss: 1.522429347038269
Validation loss: 2.0663090546925864

Epoch: 5| Step: 2
Training loss: 1.6020927429199219
Validation loss: 2.0281391246344453

Epoch: 5| Step: 3
Training loss: 1.1662968397140503
Validation loss: 2.0444453390695716

Epoch: 5| Step: 4
Training loss: 1.6471208333969116
Validation loss: 2.0219348515233686

Epoch: 5| Step: 5
Training loss: 1.1654646396636963
Validation loss: 2.041136872383856

Epoch: 5| Step: 6
Training loss: 1.2196217775344849
Validation loss: 2.0702781600336873

Epoch: 5| Step: 7
Training loss: 1.2123985290527344
Validation loss: 2.103195292975313

Epoch: 5| Step: 8
Training loss: 1.851022720336914
Validation loss: 2.114983292036159

Epoch: 5| Step: 9
Training loss: 1.6782417297363281
Validation loss: 2.147015071684314

Epoch: 5| Step: 10
Training loss: 2.113234043121338
Validation loss: 2.158784117749942

Epoch: 144| Step: 0
Training loss: 1.7707078456878662
Validation loss: 2.1788479307646393

Epoch: 5| Step: 1
Training loss: 1.5256321430206299
Validation loss: 2.1583408847931893

Epoch: 5| Step: 2
Training loss: 1.676184058189392
Validation loss: 2.1391792374272502

Epoch: 5| Step: 3
Training loss: 1.4130712747573853
Validation loss: 2.1575447513211157

Epoch: 5| Step: 4
Training loss: 1.4415017366409302
Validation loss: 2.1232395505392425

Epoch: 5| Step: 5
Training loss: 1.4842543601989746
Validation loss: 2.046128511428833

Epoch: 5| Step: 6
Training loss: 0.9743391871452332
Validation loss: 2.014577947637086

Epoch: 5| Step: 7
Training loss: 1.815826654434204
Validation loss: 2.0060731262289067

Epoch: 5| Step: 8
Training loss: 2.006208658218384
Validation loss: 1.9726752683680544

Epoch: 5| Step: 9
Training loss: 1.5143225193023682
Validation loss: 2.038936327862483

Epoch: 5| Step: 10
Training loss: 1.1327626705169678
Validation loss: 2.116733274152202

Epoch: 145| Step: 0
Training loss: 1.936867356300354
Validation loss: 2.1389215453978507

Epoch: 5| Step: 1
Training loss: 1.1556947231292725
Validation loss: 2.159827821998186

Epoch: 5| Step: 2
Training loss: 2.0065019130706787
Validation loss: 2.149283657791794

Epoch: 5| Step: 3
Training loss: 1.584082007408142
Validation loss: 2.180447627139348

Epoch: 5| Step: 4
Training loss: 1.4738483428955078
Validation loss: 2.179838062614523

Epoch: 5| Step: 5
Training loss: 1.0751948356628418
Validation loss: 2.2005206410602858

Epoch: 5| Step: 6
Training loss: 1.5030142068862915
Validation loss: 2.192391532723622

Epoch: 5| Step: 7
Training loss: 1.8247401714324951
Validation loss: 2.156735466372582

Epoch: 5| Step: 8
Training loss: 1.725619912147522
Validation loss: 2.1374800858959073

Epoch: 5| Step: 9
Training loss: 1.28401517868042
Validation loss: 2.124748561971931

Epoch: 5| Step: 10
Training loss: 1.0694104433059692
Validation loss: 2.1209888009614843

Epoch: 146| Step: 0
Training loss: 1.2171322107315063
Validation loss: 2.0943453491375013

Epoch: 5| Step: 1
Training loss: 1.3872482776641846
Validation loss: 2.0876157591419835

Epoch: 5| Step: 2
Training loss: 1.7111549377441406
Validation loss: 2.094853534493395

Epoch: 5| Step: 3
Training loss: 1.1321505308151245
Validation loss: 2.0662838746142644

Epoch: 5| Step: 4
Training loss: 1.645186185836792
Validation loss: 2.0998264410162486

Epoch: 5| Step: 5
Training loss: 1.3228389024734497
Validation loss: 2.1433868818385626

Epoch: 5| Step: 6
Training loss: 2.054506540298462
Validation loss: 2.169466193004321

Epoch: 5| Step: 7
Training loss: 1.3541656732559204
Validation loss: 2.2222978761119228

Epoch: 5| Step: 8
Training loss: 1.441247820854187
Validation loss: 2.250564989223275

Epoch: 5| Step: 9
Training loss: 1.6318700313568115
Validation loss: 2.271362658469908

Epoch: 5| Step: 10
Training loss: 1.4047600030899048
Validation loss: 2.187470215623097

Epoch: 147| Step: 0
Training loss: 1.8381216526031494
Validation loss: 2.1651598202284945

Epoch: 5| Step: 1
Training loss: 2.0158495903015137
Validation loss: 2.1927718424027964

Epoch: 5| Step: 2
Training loss: 1.2896881103515625
Validation loss: 2.1915982359199115

Epoch: 5| Step: 3
Training loss: 1.5461108684539795
Validation loss: 2.180168713292768

Epoch: 5| Step: 4
Training loss: 1.3655320405960083
Validation loss: 2.1558870987225602

Epoch: 5| Step: 5
Training loss: 1.2278786897659302
Validation loss: 2.146965008909984

Epoch: 5| Step: 6
Training loss: 1.6643527746200562
Validation loss: 2.090158745806704

Epoch: 5| Step: 7
Training loss: 1.408367395401001
Validation loss: 2.0326962163371425

Epoch: 5| Step: 8
Training loss: 1.5533027648925781
Validation loss: 2.0004676849611345

Epoch: 5| Step: 9
Training loss: 0.8525419235229492
Validation loss: 2.003789160841255

Epoch: 5| Step: 10
Training loss: 1.2991142272949219
Validation loss: 2.037714277544329

Epoch: 148| Step: 0
Training loss: 1.5854686498641968
Validation loss: 2.089639743169149

Epoch: 5| Step: 1
Training loss: 1.7849420309066772
Validation loss: 2.068976270255222

Epoch: 5| Step: 2
Training loss: 0.6777087450027466
Validation loss: 2.0713195403416953

Epoch: 5| Step: 3
Training loss: 1.4296903610229492
Validation loss: 2.103085910120318

Epoch: 5| Step: 4
Training loss: 1.3330533504486084
Validation loss: 2.1223340239576114

Epoch: 5| Step: 5
Training loss: 1.8102928400039673
Validation loss: 2.1430230140686035

Epoch: 5| Step: 6
Training loss: 1.461264729499817
Validation loss: 2.1534141943018925

Epoch: 5| Step: 7
Training loss: 1.3431766033172607
Validation loss: 2.1051614130696943

Epoch: 5| Step: 8
Training loss: 1.1993334293365479
Validation loss: 2.118065808409004

Epoch: 5| Step: 9
Training loss: 1.8545477390289307
Validation loss: 2.1238605489013014

Epoch: 5| Step: 10
Training loss: 1.4964118003845215
Validation loss: 2.147218752932805

Epoch: 149| Step: 0
Training loss: 1.2835023403167725
Validation loss: 2.1628262612127487

Epoch: 5| Step: 1
Training loss: 1.7013683319091797
Validation loss: 2.1704878909613496

Epoch: 5| Step: 2
Training loss: 1.422406792640686
Validation loss: 2.1375687583800285

Epoch: 5| Step: 3
Training loss: 1.1440296173095703
Validation loss: 2.142207617400795

Epoch: 5| Step: 4
Training loss: 1.3946956396102905
Validation loss: 2.117904273412561

Epoch: 5| Step: 5
Training loss: 0.8018352389335632
Validation loss: 2.1187926543656217

Epoch: 5| Step: 6
Training loss: 1.5305395126342773
Validation loss: 2.1742048827550744

Epoch: 5| Step: 7
Training loss: 1.7861181497573853
Validation loss: 2.2011586825052896

Epoch: 5| Step: 8
Training loss: 1.5425560474395752
Validation loss: 2.230165425167289

Epoch: 5| Step: 9
Training loss: 1.6464850902557373
Validation loss: 2.2130271786002704

Epoch: 5| Step: 10
Training loss: 1.6952086687088013
Validation loss: 2.153297403807281

Epoch: 150| Step: 0
Training loss: 1.1409811973571777
Validation loss: 2.0965475959162556

Epoch: 5| Step: 1
Training loss: 1.7899105548858643
Validation loss: 2.070232001684045

Epoch: 5| Step: 2
Training loss: 0.9936014413833618
Validation loss: 2.064751430224347

Epoch: 5| Step: 3
Training loss: 1.3675496578216553
Validation loss: 2.0440848668416343

Epoch: 5| Step: 4
Training loss: 1.5673203468322754
Validation loss: 2.032424226883919

Epoch: 5| Step: 5
Training loss: 1.705972671508789
Validation loss: 2.0170092121247323

Epoch: 5| Step: 6
Training loss: 2.326873302459717
Validation loss: 2.036895578907382

Epoch: 5| Step: 7
Training loss: 1.2568663358688354
Validation loss: 2.0571170776121077

Epoch: 5| Step: 8
Training loss: 1.5157012939453125
Validation loss: 2.048282395126999

Epoch: 5| Step: 9
Training loss: 1.0080305337905884
Validation loss: 2.0858824214627667

Epoch: 5| Step: 10
Training loss: 1.1494603157043457
Validation loss: 2.097730134123115

Epoch: 151| Step: 0
Training loss: 1.3748949766159058
Validation loss: 2.1507397620908675

Epoch: 5| Step: 1
Training loss: 2.093574047088623
Validation loss: 2.187677388550133

Epoch: 5| Step: 2
Training loss: 1.5764613151550293
Validation loss: 2.1780660921527493

Epoch: 5| Step: 3
Training loss: 1.3573168516159058
Validation loss: 2.1431883893987185

Epoch: 5| Step: 4
Training loss: 0.9930923581123352
Validation loss: 2.118584341900323

Epoch: 5| Step: 5
Training loss: 1.3613812923431396
Validation loss: 2.0915359989289315

Epoch: 5| Step: 6
Training loss: 1.2745553255081177
Validation loss: 2.0783192239781862

Epoch: 5| Step: 7
Training loss: 1.2489944696426392
Validation loss: 2.0957632513456446

Epoch: 5| Step: 8
Training loss: 1.4500725269317627
Validation loss: 2.123510586318149

Epoch: 5| Step: 9
Training loss: 1.4135053157806396
Validation loss: 2.1392604279261764

Epoch: 5| Step: 10
Training loss: 1.3816667795181274
Validation loss: 2.1430493029215003

Epoch: 152| Step: 0
Training loss: 1.5238986015319824
Validation loss: 2.164172136655418

Epoch: 5| Step: 1
Training loss: 1.278139352798462
Validation loss: 2.1646010260428152

Epoch: 5| Step: 2
Training loss: 1.2728458642959595
Validation loss: 2.1867472933184717

Epoch: 5| Step: 3
Training loss: 0.9884588122367859
Validation loss: 2.1464519834005706

Epoch: 5| Step: 4
Training loss: 1.1506047248840332
Validation loss: 2.14900020886493

Epoch: 5| Step: 5
Training loss: 1.1133283376693726
Validation loss: 2.1692479079769504

Epoch: 5| Step: 6
Training loss: 1.9015302658081055
Validation loss: 2.151841578945037

Epoch: 5| Step: 7
Training loss: 2.0464062690734863
Validation loss: 2.125559510723237

Epoch: 5| Step: 8
Training loss: 1.4773236513137817
Validation loss: 2.05195547944756

Epoch: 5| Step: 9
Training loss: 0.9439012408256531
Validation loss: 2.0360873745333765

Epoch: 5| Step: 10
Training loss: 1.606760859489441
Validation loss: 2.057858197919784

Epoch: 153| Step: 0
Training loss: 2.2120871543884277
Validation loss: 2.0851247643911712

Epoch: 5| Step: 1
Training loss: 1.5297906398773193
Validation loss: 2.132854579597391

Epoch: 5| Step: 2
Training loss: 1.1505924463272095
Validation loss: 2.1442344393781436

Epoch: 5| Step: 3
Training loss: 1.3925861120224
Validation loss: 2.1716366378209924

Epoch: 5| Step: 4
Training loss: 1.404180884361267
Validation loss: 2.1894746236903693

Epoch: 5| Step: 5
Training loss: 1.8295342922210693
Validation loss: 2.184564933981947

Epoch: 5| Step: 6
Training loss: 1.2678505182266235
Validation loss: 2.1561059387781287

Epoch: 5| Step: 7
Training loss: 0.7024127244949341
Validation loss: 2.134079164074313

Epoch: 5| Step: 8
Training loss: 1.3608851432800293
Validation loss: 2.1145588992744364

Epoch: 5| Step: 9
Training loss: 1.2426283359527588
Validation loss: 2.06855518843538

Epoch: 5| Step: 10
Training loss: 0.903356671333313
Validation loss: 2.067628634873257

Epoch: 154| Step: 0
Training loss: 1.49971342086792
Validation loss: 2.049079338709513

Epoch: 5| Step: 1
Training loss: 1.1911938190460205
Validation loss: 2.0729668909503567

Epoch: 5| Step: 2
Training loss: 1.3002371788024902
Validation loss: 2.0970642259044032

Epoch: 5| Step: 3
Training loss: 1.5183073282241821
Validation loss: 2.0831304980862524

Epoch: 5| Step: 4
Training loss: 0.7852224707603455
Validation loss: 2.11290862483363

Epoch: 5| Step: 5
Training loss: 1.4549161195755005
Validation loss: 2.1518564865153325

Epoch: 5| Step: 6
Training loss: 1.604233980178833
Validation loss: 2.1493559729668403

Epoch: 5| Step: 7
Training loss: 1.4848541021347046
Validation loss: 2.1624099926282

Epoch: 5| Step: 8
Training loss: 1.2058649063110352
Validation loss: 2.142686754144648

Epoch: 5| Step: 9
Training loss: 1.779982566833496
Validation loss: 2.132382259573988

Epoch: 5| Step: 10
Training loss: 1.0904035568237305
Validation loss: 2.158324836402811

Epoch: 155| Step: 0
Training loss: 0.8494411706924438
Validation loss: 2.179085636651644

Epoch: 5| Step: 1
Training loss: 1.3081287145614624
Validation loss: 2.2272472420046405

Epoch: 5| Step: 2
Training loss: 1.6193218231201172
Validation loss: 2.2034633134001043

Epoch: 5| Step: 3
Training loss: 1.5167373418807983
Validation loss: 2.206578626427599

Epoch: 5| Step: 4
Training loss: 1.324198842048645
Validation loss: 2.198080712749112

Epoch: 5| Step: 5
Training loss: 1.3767436742782593
Validation loss: 2.168283143351155

Epoch: 5| Step: 6
Training loss: 1.555638074874878
Validation loss: 2.1093053305020897

Epoch: 5| Step: 7
Training loss: 1.3019869327545166
Validation loss: 2.168328090380597

Epoch: 5| Step: 8
Training loss: 1.919677734375
Validation loss: 2.187417766099335

Epoch: 5| Step: 9
Training loss: 1.8898391723632812
Validation loss: 2.2256983044326946

Epoch: 5| Step: 10
Training loss: 1.0056556463241577
Validation loss: 2.1481601115195983

Epoch: 156| Step: 0
Training loss: 1.6852279901504517
Validation loss: 2.105797670220816

Epoch: 5| Step: 1
Training loss: 1.2113873958587646
Validation loss: 2.0826105610016854

Epoch: 5| Step: 2
Training loss: 1.3448803424835205
Validation loss: 2.0719945264118973

Epoch: 5| Step: 3
Training loss: 1.286964774131775
Validation loss: 2.108013005666835

Epoch: 5| Step: 4
Training loss: 1.247749924659729
Validation loss: 2.0928485290978545

Epoch: 5| Step: 5
Training loss: 1.4733684062957764
Validation loss: 2.1138647448632026

Epoch: 5| Step: 6
Training loss: 1.2516992092132568
Validation loss: 2.148773770178518

Epoch: 5| Step: 7
Training loss: 0.8044894933700562
Validation loss: 2.1271303110225226

Epoch: 5| Step: 8
Training loss: 1.5919617414474487
Validation loss: 2.1286339657281035

Epoch: 5| Step: 9
Training loss: 1.549224615097046
Validation loss: 2.099238636673138

Epoch: 5| Step: 10
Training loss: 1.2877280712127686
Validation loss: 2.1265111328453146

Epoch: 157| Step: 0
Training loss: 1.3714964389801025
Validation loss: 2.1307541939520065

Epoch: 5| Step: 1
Training loss: 1.201799750328064
Validation loss: 2.0936772605424285

Epoch: 5| Step: 2
Training loss: 1.274096965789795
Validation loss: 2.1046953842204106

Epoch: 5| Step: 3
Training loss: 0.8069486618041992
Validation loss: 2.092512126891844

Epoch: 5| Step: 4
Training loss: 1.3385807275772095
Validation loss: 2.170304595783193

Epoch: 5| Step: 5
Training loss: 1.7387374639511108
Validation loss: 2.1884859684974916

Epoch: 5| Step: 6
Training loss: 1.172194242477417
Validation loss: 2.220133630178308

Epoch: 5| Step: 7
Training loss: 1.3702932596206665
Validation loss: 2.204926094701213

Epoch: 5| Step: 8
Training loss: 1.271597146987915
Validation loss: 2.188257122552523

Epoch: 5| Step: 9
Training loss: 1.4601938724517822
Validation loss: 2.167489122318965

Epoch: 5| Step: 10
Training loss: 1.3613866567611694
Validation loss: 2.1155339287173365

Epoch: 158| Step: 0
Training loss: 1.6215976476669312
Validation loss: 2.0921113503876554

Epoch: 5| Step: 1
Training loss: 1.5318727493286133
Validation loss: 2.0371514084518596

Epoch: 5| Step: 2
Training loss: 1.469948410987854
Validation loss: 2.012873459887761

Epoch: 5| Step: 3
Training loss: 1.7355674505233765
Validation loss: 2.040799912586007

Epoch: 5| Step: 4
Training loss: 0.9430705904960632
Validation loss: 2.017330087641234

Epoch: 5| Step: 5
Training loss: 1.2438441514968872
Validation loss: 2.0474459766059794

Epoch: 5| Step: 6
Training loss: 0.9102878570556641
Validation loss: 2.1240944836729314

Epoch: 5| Step: 7
Training loss: 0.8506987690925598
Validation loss: 2.175366276053972

Epoch: 5| Step: 8
Training loss: 1.3560049533843994
Validation loss: 2.273182233174642

Epoch: 5| Step: 9
Training loss: 1.1337546110153198
Validation loss: 2.3574172143013246

Epoch: 5| Step: 10
Training loss: 1.6377891302108765
Validation loss: 2.2861141440688924

Epoch: 159| Step: 0
Training loss: 1.3146231174468994
Validation loss: 2.210348882982808

Epoch: 5| Step: 1
Training loss: 1.3074476718902588
Validation loss: 2.185014961868204

Epoch: 5| Step: 2
Training loss: 1.5349438190460205
Validation loss: 2.1278634814805883

Epoch: 5| Step: 3
Training loss: 1.2646560668945312
Validation loss: 2.094586464666551

Epoch: 5| Step: 4
Training loss: 1.4868018627166748
Validation loss: 2.043873340852799

Epoch: 5| Step: 5
Training loss: 1.1612181663513184
Validation loss: 2.0536811582503782

Epoch: 5| Step: 6
Training loss: 1.1977484226226807
Validation loss: 2.0378234001897995

Epoch: 5| Step: 7
Training loss: 1.0514682531356812
Validation loss: 2.023579732064278

Epoch: 5| Step: 8
Training loss: 1.3641908168792725
Validation loss: 1.9982351615864744

Epoch: 5| Step: 9
Training loss: 0.8676395416259766
Validation loss: 2.0085577029053883

Epoch: 5| Step: 10
Training loss: 1.7261732816696167
Validation loss: 2.0686757474817257

Epoch: 160| Step: 0
Training loss: 1.3570630550384521
Validation loss: 2.120141847159273

Epoch: 5| Step: 1
Training loss: 0.7546604871749878
Validation loss: 2.198977308888589

Epoch: 5| Step: 2
Training loss: 1.331921100616455
Validation loss: 2.2660764904432398

Epoch: 5| Step: 3
Training loss: 1.3406578302383423
Validation loss: 2.2640979084917294

Epoch: 5| Step: 4
Training loss: 1.5562368631362915
Validation loss: 2.2750678626439904

Epoch: 5| Step: 5
Training loss: 1.478538990020752
Validation loss: 2.2492955833353023

Epoch: 5| Step: 6
Training loss: 1.1923574209213257
Validation loss: 2.232266367122691

Epoch: 5| Step: 7
Training loss: 1.590171456336975
Validation loss: 2.205452170423282

Epoch: 5| Step: 8
Training loss: 1.5780218839645386
Validation loss: 2.1463992134217293

Epoch: 5| Step: 9
Training loss: 0.8698431849479675
Validation loss: 2.088031635489515

Epoch: 5| Step: 10
Training loss: 0.9875512719154358
Validation loss: 2.0291230101739206

Epoch: 161| Step: 0
Training loss: 1.3752361536026
Validation loss: 2.0102539395773285

Epoch: 5| Step: 1
Training loss: 1.431975245475769
Validation loss: 2.0063438056617655

Epoch: 5| Step: 2
Training loss: 0.7542666792869568
Validation loss: 2.0227958130580124

Epoch: 5| Step: 3
Training loss: 1.4436622858047485
Validation loss: 2.05244351971534

Epoch: 5| Step: 4
Training loss: 1.1564931869506836
Validation loss: 2.0861376152243665

Epoch: 5| Step: 5
Training loss: 1.2797539234161377
Validation loss: 2.125155343804308

Epoch: 5| Step: 6
Training loss: 1.8613684177398682
Validation loss: 2.269570530101817

Epoch: 5| Step: 7
Training loss: 1.7479066848754883
Validation loss: 2.3163242391360703

Epoch: 5| Step: 8
Training loss: 1.5202468633651733
Validation loss: 2.264141349382298

Epoch: 5| Step: 9
Training loss: 0.8139826655387878
Validation loss: 2.156094580568293

Epoch: 5| Step: 10
Training loss: 1.2895373106002808
Validation loss: 2.081281787605696

Epoch: 162| Step: 0
Training loss: 1.1705868244171143
Validation loss: 2.0538194846081477

Epoch: 5| Step: 1
Training loss: 1.629787802696228
Validation loss: 2.0237686531518095

Epoch: 5| Step: 2
Training loss: 1.5719788074493408
Validation loss: 2.0145139194303945

Epoch: 5| Step: 3
Training loss: 0.9209004640579224
Validation loss: 2.0403638501321115

Epoch: 5| Step: 4
Training loss: 1.2054537534713745
Validation loss: 2.0497489744617092

Epoch: 5| Step: 5
Training loss: 1.2461678981781006
Validation loss: 2.0865131885774675

Epoch: 5| Step: 6
Training loss: 1.567523717880249
Validation loss: 2.059730911767611

Epoch: 5| Step: 7
Training loss: 1.4212605953216553
Validation loss: 2.079314785618936

Epoch: 5| Step: 8
Training loss: 1.1409672498703003
Validation loss: 2.0618161744968866

Epoch: 5| Step: 9
Training loss: 1.3665651082992554
Validation loss: 2.1383074368199995

Epoch: 5| Step: 10
Training loss: 1.0503634214401245
Validation loss: 2.1716387476972354

Epoch: 163| Step: 0
Training loss: 1.3000991344451904
Validation loss: 2.2552269120370187

Epoch: 5| Step: 1
Training loss: 1.4020110368728638
Validation loss: 2.317798847793251

Epoch: 5| Step: 2
Training loss: 1.3661792278289795
Validation loss: 2.3625645637512207

Epoch: 5| Step: 3
Training loss: 1.340152382850647
Validation loss: 2.300555408641856

Epoch: 5| Step: 4
Training loss: 1.4190475940704346
Validation loss: 2.223420668673772

Epoch: 5| Step: 5
Training loss: 1.3395049571990967
Validation loss: 2.168264635147587

Epoch: 5| Step: 6
Training loss: 1.3188343048095703
Validation loss: 2.075518636293309

Epoch: 5| Step: 7
Training loss: 1.2442244291305542
Validation loss: 2.023898546413709

Epoch: 5| Step: 8
Training loss: 1.0825049877166748
Validation loss: 1.984155349833991

Epoch: 5| Step: 9
Training loss: 1.356493592262268
Validation loss: 1.9441598589702318

Epoch: 5| Step: 10
Training loss: 0.8621264696121216
Validation loss: 1.9197201882639239

Epoch: 164| Step: 0
Training loss: 1.0046045780181885
Validation loss: 1.9180448542359054

Epoch: 5| Step: 1
Training loss: 1.4373468160629272
Validation loss: 1.93905423789896

Epoch: 5| Step: 2
Training loss: 1.3833824396133423
Validation loss: 1.9529012762090212

Epoch: 5| Step: 3
Training loss: 1.7051448822021484
Validation loss: 1.9790354518480198

Epoch: 5| Step: 4
Training loss: 1.0781844854354858
Validation loss: 1.9871241687446513

Epoch: 5| Step: 5
Training loss: 0.895281970500946
Validation loss: 2.0186768206216956

Epoch: 5| Step: 6
Training loss: 1.1254100799560547
Validation loss: 2.0682380135341356

Epoch: 5| Step: 7
Training loss: 1.3616434335708618
Validation loss: 2.1012564512991134

Epoch: 5| Step: 8
Training loss: 1.3551162481307983
Validation loss: 2.1476905089552685

Epoch: 5| Step: 9
Training loss: 1.328688144683838
Validation loss: 2.1761357438179756

Epoch: 5| Step: 10
Training loss: 1.3348400592803955
Validation loss: 2.1972447723470707

Epoch: 165| Step: 0
Training loss: 1.148925542831421
Validation loss: 2.2041033262847574

Epoch: 5| Step: 1
Training loss: 1.5362976789474487
Validation loss: 2.2136918370441725

Epoch: 5| Step: 2
Training loss: 1.3954139947891235
Validation loss: 2.213920993189658

Epoch: 5| Step: 3
Training loss: 0.955551028251648
Validation loss: 2.2296321981696674

Epoch: 5| Step: 4
Training loss: 1.5320827960968018
Validation loss: 2.1991756603281987

Epoch: 5| Step: 5
Training loss: 0.874110996723175
Validation loss: 2.153483716390466

Epoch: 5| Step: 6
Training loss: 1.101736307144165
Validation loss: 2.1212806701660156

Epoch: 5| Step: 7
Training loss: 1.0901888608932495
Validation loss: 2.054608163013253

Epoch: 5| Step: 8
Training loss: 1.1898823976516724
Validation loss: 1.9827537139256795

Epoch: 5| Step: 9
Training loss: 1.143060326576233
Validation loss: 1.9567341804504395

Epoch: 5| Step: 10
Training loss: 1.0228577852249146
Validation loss: 1.9620039629679855

Epoch: 166| Step: 0
Training loss: 1.077197790145874
Validation loss: 2.0009866658077446

Epoch: 5| Step: 1
Training loss: 0.9627946615219116
Validation loss: 2.0578952681633735

Epoch: 5| Step: 2
Training loss: 0.7144562005996704
Validation loss: 2.098567335836349

Epoch: 5| Step: 3
Training loss: 1.1729073524475098
Validation loss: 2.188025007965744

Epoch: 5| Step: 4
Training loss: 1.089852213859558
Validation loss: 2.2312131594586115

Epoch: 5| Step: 5
Training loss: 1.3088105916976929
Validation loss: 2.262134980129939

Epoch: 5| Step: 6
Training loss: 1.276438593864441
Validation loss: 2.263580693993517

Epoch: 5| Step: 7
Training loss: 1.5081956386566162
Validation loss: 2.202377224481234

Epoch: 5| Step: 8
Training loss: 1.579034447669983
Validation loss: 2.1809055728297078

Epoch: 5| Step: 9
Training loss: 0.9036539793014526
Validation loss: 2.1040539433879237

Epoch: 5| Step: 10
Training loss: 0.9856908321380615
Validation loss: 2.0246137124235912

Epoch: 167| Step: 0
Training loss: 1.4481910467147827
Validation loss: 1.989431394043789

Epoch: 5| Step: 1
Training loss: 1.2015655040740967
Validation loss: 1.929416871839954

Epoch: 5| Step: 2
Training loss: 1.4264001846313477
Validation loss: 1.9529461758111113

Epoch: 5| Step: 3
Training loss: 1.0658036470413208
Validation loss: 1.9627733153681601

Epoch: 5| Step: 4
Training loss: 0.9703446626663208
Validation loss: 1.9595003768961916

Epoch: 5| Step: 5
Training loss: 0.8597286939620972
Validation loss: 2.009409490452018

Epoch: 5| Step: 6
Training loss: 1.1731364727020264
Validation loss: 2.045936643436391

Epoch: 5| Step: 7
Training loss: 0.9447892308235168
Validation loss: 2.1011093149903

Epoch: 5| Step: 8
Training loss: 1.2039735317230225
Validation loss: 2.1739877693114744

Epoch: 5| Step: 9
Training loss: 1.7421197891235352
Validation loss: 2.2548360670766523

Epoch: 5| Step: 10
Training loss: 0.9432129859924316
Validation loss: 2.2687526646480767

Epoch: 168| Step: 0
Training loss: 1.7855437994003296
Validation loss: 2.265194574991862

Epoch: 5| Step: 1
Training loss: 1.31125807762146
Validation loss: 2.22446548041477

Epoch: 5| Step: 2
Training loss: 0.650875985622406
Validation loss: 2.1814745562050932

Epoch: 5| Step: 3
Training loss: 0.845384955406189
Validation loss: 2.1801986758426954

Epoch: 5| Step: 4
Training loss: 0.6943788528442383
Validation loss: 2.1654847591154036

Epoch: 5| Step: 5
Training loss: 1.207881212234497
Validation loss: 2.133636930937408

Epoch: 5| Step: 6
Training loss: 1.2562140226364136
Validation loss: 2.0805956753351356

Epoch: 5| Step: 7
Training loss: 1.3245066404342651
Validation loss: 2.0632554984861806

Epoch: 5| Step: 8
Training loss: 1.2178764343261719
Validation loss: 2.06414956174871

Epoch: 5| Step: 9
Training loss: 1.2960180044174194
Validation loss: 2.0383729370691444

Epoch: 5| Step: 10
Training loss: 0.7873036861419678
Validation loss: 2.0498109825195803

Epoch: 169| Step: 0
Training loss: 1.01430344581604
Validation loss: 2.0435827265503588

Epoch: 5| Step: 1
Training loss: 0.8074352145195007
Validation loss: 2.0608127168429795

Epoch: 5| Step: 2
Training loss: 0.970539927482605
Validation loss: 2.053547481054901

Epoch: 5| Step: 3
Training loss: 1.3421093225479126
Validation loss: 2.0567215745167067

Epoch: 5| Step: 4
Training loss: 0.8837302923202515
Validation loss: 2.0335595325757096

Epoch: 5| Step: 5
Training loss: 1.2681022882461548
Validation loss: 2.0558885553831696

Epoch: 5| Step: 6
Training loss: 1.480832815170288
Validation loss: 2.0170854765881776

Epoch: 5| Step: 7
Training loss: 0.9824921488761902
Validation loss: 2.0493228179152294

Epoch: 5| Step: 8
Training loss: 1.1384649276733398
Validation loss: 2.1006282529523297

Epoch: 5| Step: 9
Training loss: 0.9959165453910828
Validation loss: 2.0832794481708157

Epoch: 5| Step: 10
Training loss: 1.0744632482528687
Validation loss: 2.1301823431445706

Epoch: 170| Step: 0
Training loss: 1.0528910160064697
Validation loss: 2.095237869088368

Epoch: 5| Step: 1
Training loss: 1.2299009561538696
Validation loss: 2.0541641455824657

Epoch: 5| Step: 2
Training loss: 1.1256206035614014
Validation loss: 1.9744184863182805

Epoch: 5| Step: 3
Training loss: 1.0081887245178223
Validation loss: 1.9613190991904146

Epoch: 5| Step: 4
Training loss: 0.9582163095474243
Validation loss: 1.9631399621245682

Epoch: 5| Step: 5
Training loss: 1.32017183303833
Validation loss: 1.9561159226202196

Epoch: 5| Step: 6
Training loss: 0.6570631265640259
Validation loss: 2.0292605917940856

Epoch: 5| Step: 7
Training loss: 1.0080316066741943
Validation loss: 2.080409865225515

Epoch: 5| Step: 8
Training loss: 1.058164358139038
Validation loss: 2.149457944336758

Epoch: 5| Step: 9
Training loss: 1.557281255722046
Validation loss: 2.192095769348965

Epoch: 5| Step: 10
Training loss: 1.1902551651000977
Validation loss: 2.2025579637096775

Epoch: 171| Step: 0
Training loss: 1.0879894495010376
Validation loss: 2.232539943469468

Epoch: 5| Step: 1
Training loss: 0.9249229431152344
Validation loss: 2.1978854107600387

Epoch: 5| Step: 2
Training loss: 1.2819937467575073
Validation loss: 2.157452316694362

Epoch: 5| Step: 3
Training loss: 1.5554141998291016
Validation loss: 2.130763861440843

Epoch: 5| Step: 4
Training loss: 1.2736680507659912
Validation loss: 2.0854399870800715

Epoch: 5| Step: 5
Training loss: 0.7530012130737305
Validation loss: 2.032280227189423

Epoch: 5| Step: 6
Training loss: 0.7561158537864685
Validation loss: 2.0283200279358895

Epoch: 5| Step: 7
Training loss: 0.9357120394706726
Validation loss: 1.9770101014003958

Epoch: 5| Step: 8
Training loss: 0.8350275158882141
Validation loss: 1.956668661486718

Epoch: 5| Step: 9
Training loss: 1.1750446557998657
Validation loss: 1.9457809848170127

Epoch: 5| Step: 10
Training loss: 1.12165105342865
Validation loss: 1.996158351180374

Epoch: 172| Step: 0
Training loss: 1.2115769386291504
Validation loss: 2.0470543676807034

Epoch: 5| Step: 1
Training loss: 1.0833100080490112
Validation loss: 2.09238427172425

Epoch: 5| Step: 2
Training loss: 1.2549244165420532
Validation loss: 2.1153088936241726

Epoch: 5| Step: 3
Training loss: 1.2184789180755615
Validation loss: 2.1247616429482736

Epoch: 5| Step: 4
Training loss: 0.5200122594833374
Validation loss: 2.140786499105474

Epoch: 5| Step: 5
Training loss: 0.9874693751335144
Validation loss: 2.1021373195032917

Epoch: 5| Step: 6
Training loss: 0.8391587138175964
Validation loss: 2.0642109301782425

Epoch: 5| Step: 7
Training loss: 1.1608303785324097
Validation loss: 2.025402976620582

Epoch: 5| Step: 8
Training loss: 1.14901864528656
Validation loss: 1.9976373205902755

Epoch: 5| Step: 9
Training loss: 1.0308620929718018
Validation loss: 1.9946462146697506

Epoch: 5| Step: 10
Training loss: 1.177918553352356
Validation loss: 1.9801448070874779

Epoch: 173| Step: 0
Training loss: 0.6044054627418518
Validation loss: 2.0014980787871988

Epoch: 5| Step: 1
Training loss: 1.0832438468933105
Validation loss: 2.018842189542709

Epoch: 5| Step: 2
Training loss: 1.0564812421798706
Validation loss: 2.0355042206343783

Epoch: 5| Step: 3
Training loss: 0.8752981424331665
Validation loss: 2.0478362216744372

Epoch: 5| Step: 4
Training loss: 1.0382025241851807
Validation loss: 2.0627987384796143

Epoch: 5| Step: 5
Training loss: 1.12775456905365
Validation loss: 2.0970395431723645

Epoch: 5| Step: 6
Training loss: 1.2879904508590698
Validation loss: 2.079635102261779

Epoch: 5| Step: 7
Training loss: 0.6734106540679932
Validation loss: 2.03427170425333

Epoch: 5| Step: 8
Training loss: 1.4671895503997803
Validation loss: 2.0230799362223637

Epoch: 5| Step: 9
Training loss: 1.1964069604873657
Validation loss: 1.9806943452486427

Epoch: 5| Step: 10
Training loss: 0.8319137096405029
Validation loss: 1.9702187302292034

Epoch: 174| Step: 0
Training loss: 0.9060544967651367
Validation loss: 1.9646966777822024

Epoch: 5| Step: 1
Training loss: 1.164731502532959
Validation loss: 1.965655324279621

Epoch: 5| Step: 2
Training loss: 0.9855254888534546
Validation loss: 1.9858676566872546

Epoch: 5| Step: 3
Training loss: 1.3473435640335083
Validation loss: 1.9947290497441446

Epoch: 5| Step: 4
Training loss: 1.1848808526992798
Validation loss: 2.0647315850821872

Epoch: 5| Step: 5
Training loss: 1.4933310747146606
Validation loss: 2.0931461805938394

Epoch: 5| Step: 6
Training loss: 0.5118063688278198
Validation loss: 2.143849153672495

Epoch: 5| Step: 7
Training loss: 1.1172034740447998
Validation loss: 2.1529336385829474

Epoch: 5| Step: 8
Training loss: 1.0920315980911255
Validation loss: 2.1233368509559223

Epoch: 5| Step: 9
Training loss: 0.9544229507446289
Validation loss: 2.124602916420147

Epoch: 5| Step: 10
Training loss: 0.7688919305801392
Validation loss: 2.077244897042551

Epoch: 175| Step: 0
Training loss: 1.1061880588531494
Validation loss: 2.0415913289593113

Epoch: 5| Step: 1
Training loss: 1.3435159921646118
Validation loss: 2.003284717118868

Epoch: 5| Step: 2
Training loss: 1.3804800510406494
Validation loss: 1.9820186335553405

Epoch: 5| Step: 3
Training loss: 1.1933586597442627
Validation loss: 1.9494055881295154

Epoch: 5| Step: 4
Training loss: 0.6974280476570129
Validation loss: 1.9489001022872103

Epoch: 5| Step: 5
Training loss: 0.8561229705810547
Validation loss: 1.95468887975139

Epoch: 5| Step: 6
Training loss: 1.0928153991699219
Validation loss: 1.9864010067396267

Epoch: 5| Step: 7
Training loss: 0.6982909440994263
Validation loss: 1.9903553621743315

Epoch: 5| Step: 8
Training loss: 1.343454122543335
Validation loss: 2.019638438378611

Epoch: 5| Step: 9
Training loss: 0.8968399167060852
Validation loss: 2.0287991313524145

Epoch: 5| Step: 10
Training loss: 0.6538891792297363
Validation loss: 2.0746565275294806

Epoch: 176| Step: 0
Training loss: 0.9936758279800415
Validation loss: 2.091291750631025

Epoch: 5| Step: 1
Training loss: 1.067260503768921
Validation loss: 2.074853333093787

Epoch: 5| Step: 2
Training loss: 1.2482386827468872
Validation loss: 2.089423853863952

Epoch: 5| Step: 3
Training loss: 0.5950231552124023
Validation loss: 2.101416867266419

Epoch: 5| Step: 4
Training loss: 0.6940271854400635
Validation loss: 2.1304157087879796

Epoch: 5| Step: 5
Training loss: 1.0533514022827148
Validation loss: 2.08260041411205

Epoch: 5| Step: 6
Training loss: 1.1328822374343872
Validation loss: 2.0597517772387435

Epoch: 5| Step: 7
Training loss: 0.9454719424247742
Validation loss: 2.04354287475668

Epoch: 5| Step: 8
Training loss: 0.9385372996330261
Validation loss: 1.9631082768081336

Epoch: 5| Step: 9
Training loss: 0.9006457328796387
Validation loss: 1.947019197607553

Epoch: 5| Step: 10
Training loss: 1.2292181253433228
Validation loss: 1.9255418046828239

Epoch: 177| Step: 0
Training loss: 0.9350593686103821
Validation loss: 1.892203422002895

Epoch: 5| Step: 1
Training loss: 0.9288929104804993
Validation loss: 1.9015542448207896

Epoch: 5| Step: 2
Training loss: 1.0573499202728271
Validation loss: 1.9044800163597189

Epoch: 5| Step: 3
Training loss: 0.8663101196289062
Validation loss: 1.9507822810962636

Epoch: 5| Step: 4
Training loss: 1.312981128692627
Validation loss: 2.0010267483290805

Epoch: 5| Step: 5
Training loss: 0.7767802476882935
Validation loss: 2.0337546948463685

Epoch: 5| Step: 6
Training loss: 0.9650007486343384
Validation loss: 2.041790544345815

Epoch: 5| Step: 7
Training loss: 0.7564154863357544
Validation loss: 2.0642331953971618

Epoch: 5| Step: 8
Training loss: 1.3123964071273804
Validation loss: 2.0826728138872372

Epoch: 5| Step: 9
Training loss: 1.3786237239837646
Validation loss: 2.085787811586934

Epoch: 5| Step: 10
Training loss: 0.8856103420257568
Validation loss: 2.0480923729558147

Epoch: 178| Step: 0
Training loss: 0.950996994972229
Validation loss: 2.0331814391638643

Epoch: 5| Step: 1
Training loss: 0.9251937866210938
Validation loss: 2.0345077104465936

Epoch: 5| Step: 2
Training loss: 0.7818940877914429
Validation loss: 2.0030227989278813

Epoch: 5| Step: 3
Training loss: 1.0536777973175049
Validation loss: 2.027240587819007

Epoch: 5| Step: 4
Training loss: 0.9664400219917297
Validation loss: 2.0147566128802556

Epoch: 5| Step: 5
Training loss: 1.2264811992645264
Validation loss: 2.0143700556088517

Epoch: 5| Step: 6
Training loss: 1.2002053260803223
Validation loss: 2.020485057625719

Epoch: 5| Step: 7
Training loss: 0.977916419506073
Validation loss: 2.0209058048904582

Epoch: 5| Step: 8
Training loss: 0.8414773941040039
Validation loss: 2.0022999137960453

Epoch: 5| Step: 9
Training loss: 1.0856986045837402
Validation loss: 2.0014311011119554

Epoch: 5| Step: 10
Training loss: 0.8383662700653076
Validation loss: 2.0607770924927085

Epoch: 179| Step: 0
Training loss: 0.6411459445953369
Validation loss: 2.0484674822899605

Epoch: 5| Step: 1
Training loss: 1.0679469108581543
Validation loss: 2.0476621402207242

Epoch: 5| Step: 2
Training loss: 0.8441720008850098
Validation loss: 1.9942199850595126

Epoch: 5| Step: 3
Training loss: 0.8771535158157349
Validation loss: 1.975409492369621

Epoch: 5| Step: 4
Training loss: 0.9918149709701538
Validation loss: 1.946330338396052

Epoch: 5| Step: 5
Training loss: 0.891303539276123
Validation loss: 1.9320956109672465

Epoch: 5| Step: 6
Training loss: 1.1099549531936646
Validation loss: 1.934062518099303

Epoch: 5| Step: 7
Training loss: 0.6685534715652466
Validation loss: 1.9270852663183724

Epoch: 5| Step: 8
Training loss: 1.18295156955719
Validation loss: 1.9237364017835228

Epoch: 5| Step: 9
Training loss: 1.2476915121078491
Validation loss: 1.9089974100871752

Epoch: 5| Step: 10
Training loss: 1.0802379846572876
Validation loss: 1.928053835386871

Epoch: 180| Step: 0
Training loss: 0.7837605476379395
Validation loss: 1.928464412689209

Epoch: 5| Step: 1
Training loss: 0.6588895916938782
Validation loss: 1.942725743016889

Epoch: 5| Step: 2
Training loss: 1.2039645910263062
Validation loss: 1.962718020203293

Epoch: 5| Step: 3
Training loss: 0.915157675743103
Validation loss: 1.9695629278818767

Epoch: 5| Step: 4
Training loss: 0.897004246711731
Validation loss: 1.989478922659351

Epoch: 5| Step: 5
Training loss: 0.9001474380493164
Validation loss: 1.9640302222262147

Epoch: 5| Step: 6
Training loss: 1.1045489311218262
Validation loss: 1.9944441779967277

Epoch: 5| Step: 7
Training loss: 1.0325767993927002
Validation loss: 1.9859590838032384

Epoch: 5| Step: 8
Training loss: 1.0554442405700684
Validation loss: 2.022220539790328

Epoch: 5| Step: 9
Training loss: 0.4605692923069
Validation loss: 2.005593074265347

Epoch: 5| Step: 10
Training loss: 1.2337325811386108
Validation loss: 1.9631364781369445

Epoch: 181| Step: 0
Training loss: 1.2128987312316895
Validation loss: 1.9486841835001463

Epoch: 5| Step: 1
Training loss: 1.1205774545669556
Validation loss: 1.948647335011472

Epoch: 5| Step: 2
Training loss: 0.721524715423584
Validation loss: 1.9589132006450365

Epoch: 5| Step: 3
Training loss: 0.755466639995575
Validation loss: 1.9595295267720376

Epoch: 5| Step: 4
Training loss: 0.9411571621894836
Validation loss: 2.006978290055388

Epoch: 5| Step: 5
Training loss: 1.1606992483139038
Validation loss: 2.0225206280267365

Epoch: 5| Step: 6
Training loss: 0.7384840846061707
Validation loss: 2.049374718819895

Epoch: 5| Step: 7
Training loss: 0.8127254247665405
Validation loss: 2.041652411542913

Epoch: 5| Step: 8
Training loss: 0.8606491088867188
Validation loss: 2.031567217201315

Epoch: 5| Step: 9
Training loss: 0.9688752293586731
Validation loss: 2.0219622658145044

Epoch: 5| Step: 10
Training loss: 0.9988639950752258
Validation loss: 1.987323490522241

Epoch: 182| Step: 0
Training loss: 0.7273279428482056
Validation loss: 1.978089726099404

Epoch: 5| Step: 1
Training loss: 0.8644798398017883
Validation loss: 1.975101162028569

Epoch: 5| Step: 2
Training loss: 0.7211115956306458
Validation loss: 1.985307724245133

Epoch: 5| Step: 3
Training loss: 0.7962470650672913
Validation loss: 2.01032442174932

Epoch: 5| Step: 4
Training loss: 1.0901645421981812
Validation loss: 1.984270699562565

Epoch: 5| Step: 5
Training loss: 0.6127733588218689
Validation loss: 1.9772916032421974

Epoch: 5| Step: 6
Training loss: 1.1293361186981201
Validation loss: 1.9691937405575988

Epoch: 5| Step: 7
Training loss: 0.7354786396026611
Validation loss: 1.976601085355205

Epoch: 5| Step: 8
Training loss: 0.751428484916687
Validation loss: 1.9783239441533242

Epoch: 5| Step: 9
Training loss: 1.4146537780761719
Validation loss: 2.000440502679476

Epoch: 5| Step: 10
Training loss: 1.09600031375885
Validation loss: 2.0267906124873827

Epoch: 183| Step: 0
Training loss: 1.0620757341384888
Validation loss: 2.0289311511542207

Epoch: 5| Step: 1
Training loss: 1.0720577239990234
Validation loss: 2.0407082085968344

Epoch: 5| Step: 2
Training loss: 1.0770343542099
Validation loss: 2.0571302367794897

Epoch: 5| Step: 3
Training loss: 0.5268000364303589
Validation loss: 2.003919234839819

Epoch: 5| Step: 4
Training loss: 0.8355926275253296
Validation loss: 2.044377753811498

Epoch: 5| Step: 5
Training loss: 1.0075219869613647
Validation loss: 1.9942249610859861

Epoch: 5| Step: 6
Training loss: 0.7529488801956177
Validation loss: 2.0360415891934465

Epoch: 5| Step: 7
Training loss: 1.0420196056365967
Validation loss: 2.053205972076744

Epoch: 5| Step: 8
Training loss: 0.7206473350524902
Validation loss: 2.09928144690811

Epoch: 5| Step: 9
Training loss: 0.8767203092575073
Validation loss: 2.0776319657602618

Epoch: 5| Step: 10
Training loss: 0.749771237373352
Validation loss: 2.026241551163376

Epoch: 184| Step: 0
Training loss: 1.1992151737213135
Validation loss: 2.002899759559221

Epoch: 5| Step: 1
Training loss: 0.6811317205429077
Validation loss: 1.9551091617153538

Epoch: 5| Step: 2
Training loss: 0.8428918719291687
Validation loss: 1.9772123752101776

Epoch: 5| Step: 3
Training loss: 1.1470825672149658
Validation loss: 1.9335004052808207

Epoch: 5| Step: 4
Training loss: 1.031200885772705
Validation loss: 1.9435069740459483

Epoch: 5| Step: 5
Training loss: 0.8094328045845032
Validation loss: 1.9498862822850545

Epoch: 5| Step: 6
Training loss: 0.88713538646698
Validation loss: 1.9644318754955004

Epoch: 5| Step: 7
Training loss: 0.6352319717407227
Validation loss: 1.9790086925670665

Epoch: 5| Step: 8
Training loss: 1.0058854818344116
Validation loss: 1.9714200676128428

Epoch: 5| Step: 9
Training loss: 0.7522116899490356
Validation loss: 1.954252004623413

Epoch: 5| Step: 10
Training loss: 0.6424841284751892
Validation loss: 1.9701940423698836

Epoch: 185| Step: 0
Training loss: 0.6821962594985962
Validation loss: 1.9895052704759824

Epoch: 5| Step: 1
Training loss: 0.6465493440628052
Validation loss: 1.9636499202379616

Epoch: 5| Step: 2
Training loss: 0.8052228093147278
Validation loss: 1.9736611215017175

Epoch: 5| Step: 3
Training loss: 1.2158373594284058
Validation loss: 1.9369557480658255

Epoch: 5| Step: 4
Training loss: 1.2384676933288574
Validation loss: 1.9642444285013343

Epoch: 5| Step: 5
Training loss: 1.0874806642532349
Validation loss: 1.993337321025069

Epoch: 5| Step: 6
Training loss: 0.9873625636100769
Validation loss: 1.9784146867772585

Epoch: 5| Step: 7
Training loss: 0.6459514498710632
Validation loss: 1.9513430672307168

Epoch: 5| Step: 8
Training loss: 0.5214968919754028
Validation loss: 1.9519837389710128

Epoch: 5| Step: 9
Training loss: 0.7033700346946716
Validation loss: 1.971419983012702

Epoch: 5| Step: 10
Training loss: 0.9418221712112427
Validation loss: 1.975100483945621

Epoch: 186| Step: 0
Training loss: 1.0212428569793701
Validation loss: 1.9653989268887428

Epoch: 5| Step: 1
Training loss: 0.6096383929252625
Validation loss: 1.9858200191169657

Epoch: 5| Step: 2
Training loss: 0.6627786755561829
Validation loss: 1.9548832857480614

Epoch: 5| Step: 3
Training loss: 0.967851996421814
Validation loss: 1.9463626261680358

Epoch: 5| Step: 4
Training loss: 0.9394888877868652
Validation loss: 1.9473390963769728

Epoch: 5| Step: 5
Training loss: 0.8741403818130493
Validation loss: 1.9800218484734977

Epoch: 5| Step: 6
Training loss: 0.7966030836105347
Validation loss: 1.9896345138549805

Epoch: 5| Step: 7
Training loss: 0.5756250619888306
Validation loss: 2.042387213758243

Epoch: 5| Step: 8
Training loss: 1.3081376552581787
Validation loss: 2.04124116897583

Epoch: 5| Step: 9
Training loss: 0.9299317598342896
Validation loss: 2.055204685016345

Epoch: 5| Step: 10
Training loss: 0.7839257717132568
Validation loss: 2.073731582651856

Epoch: 187| Step: 0
Training loss: 0.9842923879623413
Validation loss: 2.0529168216131066

Epoch: 5| Step: 1
Training loss: 0.7370291948318481
Validation loss: 2.0199624582003524

Epoch: 5| Step: 2
Training loss: 0.8266794085502625
Validation loss: 1.985836345662353

Epoch: 5| Step: 3
Training loss: 0.8514177203178406
Validation loss: 1.9947246095185638

Epoch: 5| Step: 4
Training loss: 0.8391832113265991
Validation loss: 1.9697530372168428

Epoch: 5| Step: 5
Training loss: 0.3464784026145935
Validation loss: 1.9751990751553608

Epoch: 5| Step: 6
Training loss: 0.73954176902771
Validation loss: 1.967406262633621

Epoch: 5| Step: 7
Training loss: 1.1652202606201172
Validation loss: 2.0000866241352533

Epoch: 5| Step: 8
Training loss: 1.285033941268921
Validation loss: 1.9617900745843047

Epoch: 5| Step: 9
Training loss: 0.9392353296279907
Validation loss: 1.9484886264288297

Epoch: 5| Step: 10
Training loss: 0.7312871217727661
Validation loss: 1.9506337745215303

Epoch: 188| Step: 0
Training loss: 0.7668315172195435
Validation loss: 1.9345774342936854

Epoch: 5| Step: 1
Training loss: 0.8366283178329468
Validation loss: 1.9515604408838416

Epoch: 5| Step: 2
Training loss: 0.8934858441352844
Validation loss: 1.9639237926852318

Epoch: 5| Step: 3
Training loss: 0.8405396342277527
Validation loss: 1.9735162617057882

Epoch: 5| Step: 4
Training loss: 0.9761680364608765
Validation loss: 1.9983590008110128

Epoch: 5| Step: 5
Training loss: 0.6337414979934692
Validation loss: 1.9999807227042414

Epoch: 5| Step: 6
Training loss: 0.8297585248947144
Validation loss: 2.0024474795146654

Epoch: 5| Step: 7
Training loss: 0.7122287154197693
Validation loss: 1.994481607150006

Epoch: 5| Step: 8
Training loss: 1.0775378942489624
Validation loss: 1.9744541657868253

Epoch: 5| Step: 9
Training loss: 0.8015137910842896
Validation loss: 1.8907357133844847

Epoch: 5| Step: 10
Training loss: 0.8289408683776855
Validation loss: 1.879215241760336

Epoch: 189| Step: 0
Training loss: 1.121002435684204
Validation loss: 1.8948168652032011

Epoch: 5| Step: 1
Training loss: 0.792672336101532
Validation loss: 1.8855469406292003

Epoch: 5| Step: 2
Training loss: 0.9205295443534851
Validation loss: 1.8952675173359532

Epoch: 5| Step: 3
Training loss: 0.5070006847381592
Validation loss: 1.9268140574937225

Epoch: 5| Step: 4
Training loss: 1.1720491647720337
Validation loss: 1.9204078784552954

Epoch: 5| Step: 5
Training loss: 0.4836142063140869
Validation loss: 1.9694385220927577

Epoch: 5| Step: 6
Training loss: 0.8804359436035156
Validation loss: 1.9986065562053392

Epoch: 5| Step: 7
Training loss: 0.8597413897514343
Validation loss: 2.0146083959969143

Epoch: 5| Step: 8
Training loss: 1.0757323503494263
Validation loss: 1.9859130305628623

Epoch: 5| Step: 9
Training loss: 0.6462359428405762
Validation loss: 1.9583391348520915

Epoch: 5| Step: 10
Training loss: 0.7218576073646545
Validation loss: 1.931888803359001

Epoch: 190| Step: 0
Training loss: 0.6587527990341187
Validation loss: 1.9387150015882266

Epoch: 5| Step: 1
Training loss: 0.5617585182189941
Validation loss: 1.9536422247527747

Epoch: 5| Step: 2
Training loss: 0.8560541868209839
Validation loss: 1.9232275473174227

Epoch: 5| Step: 3
Training loss: 0.8644258379936218
Validation loss: 1.9000923941212315

Epoch: 5| Step: 4
Training loss: 0.8505700826644897
Validation loss: 1.8819854182581748

Epoch: 5| Step: 5
Training loss: 0.8938499689102173
Validation loss: 1.8606145356291084

Epoch: 5| Step: 6
Training loss: 1.2964059114456177
Validation loss: 1.8641512996406966

Epoch: 5| Step: 7
Training loss: 0.8053601384162903
Validation loss: 1.8822020535827966

Epoch: 5| Step: 8
Training loss: 0.6764978766441345
Validation loss: 1.8732347334584882

Epoch: 5| Step: 9
Training loss: 0.8033282160758972
Validation loss: 1.8819195467938659

Epoch: 5| Step: 10
Training loss: 0.7899029850959778
Validation loss: 1.9385573017981745

Epoch: 191| Step: 0
Training loss: 0.9825271368026733
Validation loss: 2.0294646396431872

Epoch: 5| Step: 1
Training loss: 1.169512152671814
Validation loss: 2.1590246051870365

Epoch: 5| Step: 2
Training loss: 0.9932950735092163
Validation loss: 2.1611834213297856

Epoch: 5| Step: 3
Training loss: 0.7363154292106628
Validation loss: 2.120256377804664

Epoch: 5| Step: 4
Training loss: 0.907208263874054
Validation loss: 2.050479168532997

Epoch: 5| Step: 5
Training loss: 0.989364504814148
Validation loss: 1.9824791428863362

Epoch: 5| Step: 6
Training loss: 0.603541910648346
Validation loss: 1.9044506293471142

Epoch: 5| Step: 7
Training loss: 0.7840632200241089
Validation loss: 1.8821846336446784

Epoch: 5| Step: 8
Training loss: 0.6043864488601685
Validation loss: 1.828160935832608

Epoch: 5| Step: 9
Training loss: 0.6515402793884277
Validation loss: 1.7921508486552904

Epoch: 5| Step: 10
Training loss: 1.293645977973938
Validation loss: 1.8048684135560067

Epoch: 192| Step: 0
Training loss: 1.0239150524139404
Validation loss: 1.8037622538946008

Epoch: 5| Step: 1
Training loss: 0.9255267381668091
Validation loss: 1.8037260181160384

Epoch: 5| Step: 2
Training loss: 0.8405744433403015
Validation loss: 1.8297583082670807

Epoch: 5| Step: 3
Training loss: 0.5351759195327759
Validation loss: 1.8348686797644502

Epoch: 5| Step: 4
Training loss: 0.8954675793647766
Validation loss: 1.8859228267464587

Epoch: 5| Step: 5
Training loss: 0.8484164476394653
Validation loss: 1.9643107447572934

Epoch: 5| Step: 6
Training loss: 1.0682458877563477
Validation loss: 2.0610295726406958

Epoch: 5| Step: 7
Training loss: 1.188913345336914
Validation loss: 2.072244428819226

Epoch: 5| Step: 8
Training loss: 1.2186174392700195
Validation loss: 2.1102335081305554

Epoch: 5| Step: 9
Training loss: 0.49463772773742676
Validation loss: 2.0901651715719574

Epoch: 5| Step: 10
Training loss: 0.748199462890625
Validation loss: 2.0538731646794144

Epoch: 193| Step: 0
Training loss: 1.0228378772735596
Validation loss: 2.032679598818543

Epoch: 5| Step: 1
Training loss: 1.09503173828125
Validation loss: 2.0159432682939755

Epoch: 5| Step: 2
Training loss: 0.9704230427742004
Validation loss: 1.9813340992055914

Epoch: 5| Step: 3
Training loss: 0.7728375196456909
Validation loss: 1.9428984144682526

Epoch: 5| Step: 4
Training loss: 0.8575234413146973
Validation loss: 1.9161403845715266

Epoch: 5| Step: 5
Training loss: 0.9934946894645691
Validation loss: 1.8627562394706152

Epoch: 5| Step: 6
Training loss: 0.9102507829666138
Validation loss: 1.8273799739858156

Epoch: 5| Step: 7
Training loss: 0.5714222192764282
Validation loss: 1.8280264331448464

Epoch: 5| Step: 8
Training loss: 0.6168347597122192
Validation loss: 1.832717828853156

Epoch: 5| Step: 9
Training loss: 0.6106871366500854
Validation loss: 1.9229560898196312

Epoch: 5| Step: 10
Training loss: 0.6782137751579285
Validation loss: 1.9214663685009044

Epoch: 194| Step: 0
Training loss: 0.9163713455200195
Validation loss: 1.8889576683762253

Epoch: 5| Step: 1
Training loss: 0.9349363446235657
Validation loss: 1.9000937118325183

Epoch: 5| Step: 2
Training loss: 0.5049566030502319
Validation loss: 1.9173899786446684

Epoch: 5| Step: 3
Training loss: 0.4366278648376465
Validation loss: 1.8984287400399484

Epoch: 5| Step: 4
Training loss: 0.7175816297531128
Validation loss: 1.9600608759028937

Epoch: 5| Step: 5
Training loss: 0.7168207168579102
Validation loss: 1.9924462431220598

Epoch: 5| Step: 6
Training loss: 0.6040034890174866
Validation loss: 1.9957588500874017

Epoch: 5| Step: 7
Training loss: 0.8771265745162964
Validation loss: 2.007002499795729

Epoch: 5| Step: 8
Training loss: 1.2289674282073975
Validation loss: 2.023327845399098

Epoch: 5| Step: 9
Training loss: 1.0472691059112549
Validation loss: 2.0201736816795925

Epoch: 5| Step: 10
Training loss: 1.087356448173523
Validation loss: 1.9587932594360844

Epoch: 195| Step: 0
Training loss: 0.5745798945426941
Validation loss: 1.925790153523927

Epoch: 5| Step: 1
Training loss: 0.6141706109046936
Validation loss: 1.908282600423341

Epoch: 5| Step: 2
Training loss: 0.9373478889465332
Validation loss: 1.8993279062291628

Epoch: 5| Step: 3
Training loss: 0.7654735445976257
Validation loss: 1.912012702675276

Epoch: 5| Step: 4
Training loss: 0.8067299127578735
Validation loss: 1.9053075634023195

Epoch: 5| Step: 5
Training loss: 1.5925654172897339
Validation loss: 1.9041957919315626

Epoch: 5| Step: 6
Training loss: 0.5453702211380005
Validation loss: 1.8978691254892657

Epoch: 5| Step: 7
Training loss: 0.6449240446090698
Validation loss: 1.8902036041341803

Epoch: 5| Step: 8
Training loss: 0.9099805951118469
Validation loss: 1.921035587146718

Epoch: 5| Step: 9
Training loss: 0.5833393335342407
Validation loss: 1.937167263800098

Epoch: 5| Step: 10
Training loss: 0.9504055976867676
Validation loss: 2.0259395799329205

Epoch: 196| Step: 0
Training loss: 0.8357874751091003
Validation loss: 2.0570507767379924

Epoch: 5| Step: 1
Training loss: 1.233529806137085
Validation loss: 2.038691697582122

Epoch: 5| Step: 2
Training loss: 1.0115141868591309
Validation loss: 2.007356292457991

Epoch: 5| Step: 3
Training loss: 0.45650678873062134
Validation loss: 1.9765281343972811

Epoch: 5| Step: 4
Training loss: 1.0148824453353882
Validation loss: 1.9649866370744602

Epoch: 5| Step: 5
Training loss: 0.6440762281417847
Validation loss: 1.9061112480778848

Epoch: 5| Step: 6
Training loss: 0.6403180360794067
Validation loss: 1.8655768645706998

Epoch: 5| Step: 7
Training loss: 0.8669630289077759
Validation loss: 1.8602460584332865

Epoch: 5| Step: 8
Training loss: 0.6198612451553345
Validation loss: 1.8266928106225946

Epoch: 5| Step: 9
Training loss: 0.7811236381530762
Validation loss: 1.8573204727583035

Epoch: 5| Step: 10
Training loss: 0.6023887991905212
Validation loss: 1.900131070485679

Epoch: 197| Step: 0
Training loss: 1.0119866132736206
Validation loss: 1.9401708943869478

Epoch: 5| Step: 1
Training loss: 1.0092203617095947
Validation loss: 1.9319543171954412

Epoch: 5| Step: 2
Training loss: 0.7170920372009277
Validation loss: 1.884932130895635

Epoch: 5| Step: 3
Training loss: 0.5064298510551453
Validation loss: 1.9114342915114535

Epoch: 5| Step: 4
Training loss: 0.6170095205307007
Validation loss: 1.9091435247851956

Epoch: 5| Step: 5
Training loss: 0.8204470872879028
Validation loss: 1.9448398031214231

Epoch: 5| Step: 6
Training loss: 0.7679315209388733
Validation loss: 1.9549690228636547

Epoch: 5| Step: 7
Training loss: 1.1199638843536377
Validation loss: 1.962649614580216

Epoch: 5| Step: 8
Training loss: 0.9287009239196777
Validation loss: 1.948470668126178

Epoch: 5| Step: 9
Training loss: 0.713580310344696
Validation loss: 1.9395229188344811

Epoch: 5| Step: 10
Training loss: 0.4050900936126709
Validation loss: 1.8703864953851188

Epoch: 198| Step: 0
Training loss: 1.0924410820007324
Validation loss: 1.864738715592251

Epoch: 5| Step: 1
Training loss: 1.026521921157837
Validation loss: 1.8726032241698234

Epoch: 5| Step: 2
Training loss: 0.638282299041748
Validation loss: 1.8764324085686797

Epoch: 5| Step: 3
Training loss: 0.4939951002597809
Validation loss: 1.935667359700767

Epoch: 5| Step: 4
Training loss: 0.8626319766044617
Validation loss: 1.9666453458929574

Epoch: 5| Step: 5
Training loss: 0.6950790882110596
Validation loss: 2.005403482785789

Epoch: 5| Step: 6
Training loss: 0.6868355870246887
Validation loss: 2.012326871195147

Epoch: 5| Step: 7
Training loss: 0.8146440386772156
Validation loss: 2.0621662485984062

Epoch: 5| Step: 8
Training loss: 0.9584134817123413
Validation loss: 2.048706736615909

Epoch: 5| Step: 9
Training loss: 0.644015908241272
Validation loss: 2.0362936399316274

Epoch: 5| Step: 10
Training loss: 0.771188497543335
Validation loss: 2.025423308854462

Epoch: 199| Step: 0
Training loss: 0.6728805899620056
Validation loss: 2.0524237719915246

Epoch: 5| Step: 1
Training loss: 1.118026852607727
Validation loss: 2.0041563305803525

Epoch: 5| Step: 2
Training loss: 0.4260029196739197
Validation loss: 1.9878992278088805

Epoch: 5| Step: 3
Training loss: 0.7080444097518921
Validation loss: 1.97720383315958

Epoch: 5| Step: 4
Training loss: 0.9204261898994446
Validation loss: 1.9374582805941183

Epoch: 5| Step: 5
Training loss: 0.8920435905456543
Validation loss: 1.9225401109264744

Epoch: 5| Step: 6
Training loss: 0.869424045085907
Validation loss: 1.9239427017909225

Epoch: 5| Step: 7
Training loss: 0.34426456689834595
Validation loss: 1.9268277152892082

Epoch: 5| Step: 8
Training loss: 1.0220201015472412
Validation loss: 1.9479965958544003

Epoch: 5| Step: 9
Training loss: 0.5957072377204895
Validation loss: 1.955420865807482

Epoch: 5| Step: 10
Training loss: 1.0179941654205322
Validation loss: 1.958190587259108

Epoch: 200| Step: 0
Training loss: 0.9888085126876831
Validation loss: 2.0030767276722896

Epoch: 5| Step: 1
Training loss: 1.0282405614852905
Validation loss: 1.992662719500962

Epoch: 5| Step: 2
Training loss: 0.47156697511672974
Validation loss: 2.0074782845794514

Epoch: 5| Step: 3
Training loss: 0.4324820637702942
Validation loss: 1.9446156242842316

Epoch: 5| Step: 4
Training loss: 0.6972507834434509
Validation loss: 1.9321580253621584

Epoch: 5| Step: 5
Training loss: 0.7842872738838196
Validation loss: 1.9306519736525833

Epoch: 5| Step: 6
Training loss: 0.6906236410140991
Validation loss: 1.917850963531002

Epoch: 5| Step: 7
Training loss: 0.4655880331993103
Validation loss: 1.9300868524018155

Epoch: 5| Step: 8
Training loss: 1.045253872871399
Validation loss: 1.919081013689759

Epoch: 5| Step: 9
Training loss: 0.48763108253479004
Validation loss: 1.9218959154621247

Epoch: 5| Step: 10
Training loss: 1.2439193725585938
Validation loss: 1.9229326786533478

Epoch: 201| Step: 0
Training loss: 0.8124972581863403
Validation loss: 1.8996564957403368

Epoch: 5| Step: 1
Training loss: 0.6121203303337097
Validation loss: 1.8894690659738356

Epoch: 5| Step: 2
Training loss: 0.5329537391662598
Validation loss: 1.9232028427944388

Epoch: 5| Step: 3
Training loss: 0.6112040281295776
Validation loss: 1.884336317739179

Epoch: 5| Step: 4
Training loss: 0.6112033724784851
Validation loss: 1.8635173074660762

Epoch: 5| Step: 5
Training loss: 0.9693201184272766
Validation loss: 1.8823621772950696

Epoch: 5| Step: 6
Training loss: 1.0211938619613647
Validation loss: 1.866308262271266

Epoch: 5| Step: 7
Training loss: 0.6258395910263062
Validation loss: 1.8634176946455432

Epoch: 5| Step: 8
Training loss: 0.6439191102981567
Validation loss: 1.8702159363736388

Epoch: 5| Step: 9
Training loss: 0.7876447439193726
Validation loss: 1.9041411684405418

Epoch: 5| Step: 10
Training loss: 0.5760332942008972
Validation loss: 1.9219263830492574

Epoch: 202| Step: 0
Training loss: 0.4446200430393219
Validation loss: 1.942077875137329

Epoch: 5| Step: 1
Training loss: 0.7744897603988647
Validation loss: 1.944333650732553

Epoch: 5| Step: 2
Training loss: 1.1201635599136353
Validation loss: 1.9537187930076354

Epoch: 5| Step: 3
Training loss: 0.6446274518966675
Validation loss: 1.9523602262620003

Epoch: 5| Step: 4
Training loss: 0.8950101137161255
Validation loss: 1.941483925747615

Epoch: 5| Step: 5
Training loss: 0.7633183598518372
Validation loss: 1.8960048537100516

Epoch: 5| Step: 6
Training loss: 0.384333074092865
Validation loss: 1.896195552682364

Epoch: 5| Step: 7
Training loss: 0.583890974521637
Validation loss: 1.864892819876312

Epoch: 5| Step: 8
Training loss: 0.7403333187103271
Validation loss: 1.8678301816345544

Epoch: 5| Step: 9
Training loss: 0.9423443675041199
Validation loss: 1.8739394231509137

Epoch: 5| Step: 10
Training loss: 0.7436457276344299
Validation loss: 1.8501508428204445

Epoch: 203| Step: 0
Training loss: 0.7016505002975464
Validation loss: 1.8685125099715365

Epoch: 5| Step: 1
Training loss: 0.8898089528083801
Validation loss: 1.859837011624408

Epoch: 5| Step: 2
Training loss: 0.627587616443634
Validation loss: 1.8672996951687721

Epoch: 5| Step: 3
Training loss: 0.6205741763114929
Validation loss: 1.8587758579561788

Epoch: 5| Step: 4
Training loss: 0.7539025545120239
Validation loss: 1.8744684009141819

Epoch: 5| Step: 5
Training loss: 0.794491171836853
Validation loss: 1.9009610324777582

Epoch: 5| Step: 6
Training loss: 0.5277690887451172
Validation loss: 1.9125758089045042

Epoch: 5| Step: 7
Training loss: 1.0606915950775146
Validation loss: 1.8954757836557203

Epoch: 5| Step: 8
Training loss: 0.7589088082313538
Validation loss: 1.8643564280643259

Epoch: 5| Step: 9
Training loss: 0.5062821507453918
Validation loss: 1.842111251687491

Epoch: 5| Step: 10
Training loss: 0.8084196448326111
Validation loss: 1.8553031811150171

Epoch: 204| Step: 0
Training loss: 0.8003144264221191
Validation loss: 1.854380638368668

Epoch: 5| Step: 1
Training loss: 0.506576657295227
Validation loss: 1.8445590234571887

Epoch: 5| Step: 2
Training loss: 0.6100320219993591
Validation loss: 1.8225343765751008

Epoch: 5| Step: 3
Training loss: 1.0989259481430054
Validation loss: 1.8580535752798921

Epoch: 5| Step: 4
Training loss: 0.854828953742981
Validation loss: 1.8970205553116337

Epoch: 5| Step: 5
Training loss: 0.6144025921821594
Validation loss: 1.9052541563587804

Epoch: 5| Step: 6
Training loss: 0.5706247091293335
Validation loss: 1.9277935271622033

Epoch: 5| Step: 7
Training loss: 0.7099429965019226
Validation loss: 1.9090050035907375

Epoch: 5| Step: 8
Training loss: 0.6830369234085083
Validation loss: 1.9560838604486117

Epoch: 5| Step: 9
Training loss: 0.5481956601142883
Validation loss: 1.9417269537525792

Epoch: 5| Step: 10
Training loss: 0.8755748271942139
Validation loss: 1.9166807974538496

Epoch: 205| Step: 0
Training loss: 0.5837692022323608
Validation loss: 1.9327016581771195

Epoch: 5| Step: 1
Training loss: 0.5260683298110962
Validation loss: 1.887942692284943

Epoch: 5| Step: 2
Training loss: 0.6231976747512817
Validation loss: 1.947300693040253

Epoch: 5| Step: 3
Training loss: 1.0074039697647095
Validation loss: 1.917570121826664

Epoch: 5| Step: 4
Training loss: 0.7074228525161743
Validation loss: 1.948688248152374

Epoch: 5| Step: 5
Training loss: 0.5661121606826782
Validation loss: 1.9482946729147306

Epoch: 5| Step: 6
Training loss: 0.7156168818473816
Validation loss: 1.9430875457743162

Epoch: 5| Step: 7
Training loss: 0.9095790982246399
Validation loss: 1.9512807041086175

Epoch: 5| Step: 8
Training loss: 0.684813380241394
Validation loss: 1.918102418222735

Epoch: 5| Step: 9
Training loss: 0.9776017069816589
Validation loss: 1.9004523433664793

Epoch: 5| Step: 10
Training loss: 0.6292530298233032
Validation loss: 1.8724011310967066

Epoch: 206| Step: 0
Training loss: 0.6432821154594421
Validation loss: 1.8611747090534498

Epoch: 5| Step: 1
Training loss: 0.6719794869422913
Validation loss: 1.899012202857643

Epoch: 5| Step: 2
Training loss: 1.0969030857086182
Validation loss: 1.9290451606114705

Epoch: 5| Step: 3
Training loss: 0.6025232076644897
Validation loss: 1.9435298929932296

Epoch: 5| Step: 4
Training loss: 0.587479293346405
Validation loss: 1.9502944946289062

Epoch: 5| Step: 5
Training loss: 0.9984081387519836
Validation loss: 1.9255531411017142

Epoch: 5| Step: 6
Training loss: 0.7974440455436707
Validation loss: 1.9282427718562465

Epoch: 5| Step: 7
Training loss: 1.0006873607635498
Validation loss: 1.915823487825291

Epoch: 5| Step: 8
Training loss: 0.6321367025375366
Validation loss: 1.877974267928831

Epoch: 5| Step: 9
Training loss: 0.5851391553878784
Validation loss: 1.8694042557029313

Epoch: 5| Step: 10
Training loss: 0.3408694267272949
Validation loss: 1.8443074944198772

Epoch: 207| Step: 0
Training loss: 0.7725104093551636
Validation loss: 1.8653186726313766

Epoch: 5| Step: 1
Training loss: 0.6588935256004333
Validation loss: 1.8627780047796105

Epoch: 5| Step: 2
Training loss: 0.278805136680603
Validation loss: 1.9112359785264539

Epoch: 5| Step: 3
Training loss: 0.5340170860290527
Validation loss: 1.9133704682832122

Epoch: 5| Step: 4
Training loss: 0.6768253445625305
Validation loss: 1.8829514800861318

Epoch: 5| Step: 5
Training loss: 1.0065997838974
Validation loss: 1.952563972883327

Epoch: 5| Step: 6
Training loss: 0.5661693811416626
Validation loss: 1.943994117039506

Epoch: 5| Step: 7
Training loss: 0.9295541048049927
Validation loss: 1.9467797779267835

Epoch: 5| Step: 8
Training loss: 0.7258259057998657
Validation loss: 1.9324572111970635

Epoch: 5| Step: 9
Training loss: 0.8850655555725098
Validation loss: 1.8827451582877868

Epoch: 5| Step: 10
Training loss: 0.9160967469215393
Validation loss: 1.8647692793159074

Epoch: 208| Step: 0
Training loss: 0.45586928725242615
Validation loss: 1.8908498287200928

Epoch: 5| Step: 1
Training loss: 0.7180817127227783
Validation loss: 1.8872911622447353

Epoch: 5| Step: 2
Training loss: 0.5753244161605835
Validation loss: 1.8927138569534465

Epoch: 5| Step: 3
Training loss: 0.5542648434638977
Validation loss: 1.9254066251939344

Epoch: 5| Step: 4
Training loss: 0.8424409031867981
Validation loss: 1.9228520995827132

Epoch: 5| Step: 5
Training loss: 0.6603027582168579
Validation loss: 1.9578141268863474

Epoch: 5| Step: 6
Training loss: 1.0702273845672607
Validation loss: 1.9597758272642731

Epoch: 5| Step: 7
Training loss: 0.8256970643997192
Validation loss: 1.9691703011912685

Epoch: 5| Step: 8
Training loss: 1.0043259859085083
Validation loss: 2.0455636183420816

Epoch: 5| Step: 9
Training loss: 0.673852801322937
Validation loss: 2.0210806246726745

Epoch: 5| Step: 10
Training loss: 0.5761609077453613
Validation loss: 2.0281158121683265

Epoch: 209| Step: 0
Training loss: 0.7385244965553284
Validation loss: 1.9399977960894186

Epoch: 5| Step: 1
Training loss: 0.5906266570091248
Validation loss: 1.8800682124271189

Epoch: 5| Step: 2
Training loss: 0.9131214022636414
Validation loss: 1.870554926574871

Epoch: 5| Step: 3
Training loss: 1.023544192314148
Validation loss: 1.8536012749518118

Epoch: 5| Step: 4
Training loss: 0.7378594279289246
Validation loss: 1.862586554660592

Epoch: 5| Step: 5
Training loss: 0.4499894082546234
Validation loss: 1.87188083382063

Epoch: 5| Step: 6
Training loss: 0.5238312482833862
Validation loss: 1.9029199269510084

Epoch: 5| Step: 7
Training loss: 0.7018597722053528
Validation loss: 1.9078858270440051

Epoch: 5| Step: 8
Training loss: 1.1072312593460083
Validation loss: 1.934746180811236

Epoch: 5| Step: 9
Training loss: 0.4536411166191101
Validation loss: 1.917881449063619

Epoch: 5| Step: 10
Training loss: 0.5437684059143066
Validation loss: 1.9400727877052881

Epoch: 210| Step: 0
Training loss: 0.9408614039421082
Validation loss: 1.9574620672451553

Epoch: 5| Step: 1
Training loss: 0.5297315716743469
Validation loss: 1.9362913588041901

Epoch: 5| Step: 2
Training loss: 0.7334426641464233
Validation loss: 1.9829581732391028

Epoch: 5| Step: 3
Training loss: 0.5780251026153564
Validation loss: 1.8978779136493642

Epoch: 5| Step: 4
Training loss: 0.7952898144721985
Validation loss: 1.8958175054160498

Epoch: 5| Step: 5
Training loss: 0.6693239808082581
Validation loss: 1.8785748058749783

Epoch: 5| Step: 6
Training loss: 0.645544171333313
Validation loss: 1.9080024380837717

Epoch: 5| Step: 7
Training loss: 0.5685567259788513
Validation loss: 1.8942880527947539

Epoch: 5| Step: 8
Training loss: 0.5959149599075317
Validation loss: 1.8934673199089624

Epoch: 5| Step: 9
Training loss: 0.568487286567688
Validation loss: 1.8552514468469927

Epoch: 5| Step: 10
Training loss: 0.5152850151062012
Validation loss: 1.846259633700053

Epoch: 211| Step: 0
Training loss: 0.5387448072433472
Validation loss: 1.8412524064381917

Epoch: 5| Step: 1
Training loss: 0.4121376872062683
Validation loss: 1.8180237290679768

Epoch: 5| Step: 2
Training loss: 0.7249641418457031
Validation loss: 1.8444469474977063

Epoch: 5| Step: 3
Training loss: 0.5781432390213013
Validation loss: 1.8148278523516912

Epoch: 5| Step: 4
Training loss: 0.605265200138092
Validation loss: 1.8609332871693436

Epoch: 5| Step: 5
Training loss: 0.7262364029884338
Validation loss: 1.8613516053845804

Epoch: 5| Step: 6
Training loss: 0.9144824147224426
Validation loss: 1.8888063558968164

Epoch: 5| Step: 7
Training loss: 0.4715496897697449
Validation loss: 1.9090721338025984

Epoch: 5| Step: 8
Training loss: 0.7086088061332703
Validation loss: 1.9407374461491902

Epoch: 5| Step: 9
Training loss: 0.929557204246521
Validation loss: 1.907776560834659

Epoch: 5| Step: 10
Training loss: 0.698980450630188
Validation loss: 1.9301658035606466

Epoch: 212| Step: 0
Training loss: 0.46636468172073364
Validation loss: 1.9439389731294365

Epoch: 5| Step: 1
Training loss: 0.7030409574508667
Validation loss: 1.9595408067908338

Epoch: 5| Step: 2
Training loss: 0.8261966705322266
Validation loss: 1.9074498889266804

Epoch: 5| Step: 3
Training loss: 0.7235170602798462
Validation loss: 1.9596608197817238

Epoch: 5| Step: 4
Training loss: 0.692099928855896
Validation loss: 1.9395224073881745

Epoch: 5| Step: 5
Training loss: 0.749212384223938
Validation loss: 1.9222665743161274

Epoch: 5| Step: 6
Training loss: 0.4861375391483307
Validation loss: 1.9122373057949928

Epoch: 5| Step: 7
Training loss: 0.5047063231468201
Validation loss: 1.86995134815093

Epoch: 5| Step: 8
Training loss: 0.614438533782959
Validation loss: 1.8599748765268633

Epoch: 5| Step: 9
Training loss: 0.8176323175430298
Validation loss: 1.8592754128158733

Epoch: 5| Step: 10
Training loss: 0.7574543952941895
Validation loss: 1.8795514004204863

Epoch: 213| Step: 0
Training loss: 0.428241103887558
Validation loss: 1.854228837515718

Epoch: 5| Step: 1
Training loss: 0.7135343551635742
Validation loss: 1.859715510440129

Epoch: 5| Step: 2
Training loss: 0.7975672483444214
Validation loss: 1.8604971413971276

Epoch: 5| Step: 3
Training loss: 0.6490482687950134
Validation loss: 1.8492776270835631

Epoch: 5| Step: 4
Training loss: 0.5862559080123901
Validation loss: 1.8763799077721053

Epoch: 5| Step: 5
Training loss: 0.7296563982963562
Validation loss: 1.8856148604423768

Epoch: 5| Step: 6
Training loss: 0.44026464223861694
Validation loss: 1.9061549273870324

Epoch: 5| Step: 7
Training loss: 0.6994903683662415
Validation loss: 1.930626679492253

Epoch: 5| Step: 8
Training loss: 0.7863616347312927
Validation loss: 1.9099213538631317

Epoch: 5| Step: 9
Training loss: 0.392898291349411
Validation loss: 1.955278164596968

Epoch: 5| Step: 10
Training loss: 0.7213683128356934
Validation loss: 1.9268116604897283

Epoch: 214| Step: 0
Training loss: 0.930830180644989
Validation loss: 1.9104253797120945

Epoch: 5| Step: 1
Training loss: 0.5867971181869507
Validation loss: 1.8882240608174314

Epoch: 5| Step: 2
Training loss: 0.568569004535675
Validation loss: 1.8865350984757947

Epoch: 5| Step: 3
Training loss: 0.7418254613876343
Validation loss: 1.8741740744601014

Epoch: 5| Step: 4
Training loss: 0.5084013938903809
Validation loss: 1.8355054445164178

Epoch: 5| Step: 5
Training loss: 0.319679319858551
Validation loss: 1.8261621434201476

Epoch: 5| Step: 6
Training loss: 0.6693052053451538
Validation loss: 1.815683336668117

Epoch: 5| Step: 7
Training loss: 0.6758593320846558
Validation loss: 1.8352780367738457

Epoch: 5| Step: 8
Training loss: 0.7535309791564941
Validation loss: 1.8531056501532113

Epoch: 5| Step: 9
Training loss: 0.5283456444740295
Validation loss: 1.829696851391946

Epoch: 5| Step: 10
Training loss: 0.5910506844520569
Validation loss: 1.830415924390157

Epoch: 215| Step: 0
Training loss: 0.5429874658584595
Validation loss: 1.845572579291559

Epoch: 5| Step: 1
Training loss: 0.6624645590782166
Validation loss: 1.8737538091598018

Epoch: 5| Step: 2
Training loss: 0.722314178943634
Validation loss: 1.8798817947346678

Epoch: 5| Step: 3
Training loss: 0.5947414040565491
Validation loss: 1.8787032199162308

Epoch: 5| Step: 4
Training loss: 0.5526247024536133
Validation loss: 1.822694734860492

Epoch: 5| Step: 5
Training loss: 0.5758897066116333
Validation loss: 1.8473594880873156

Epoch: 5| Step: 6
Training loss: 0.6940102577209473
Validation loss: 1.836506958930723

Epoch: 5| Step: 7
Training loss: 0.6221541166305542
Validation loss: 1.8370068432182394

Epoch: 5| Step: 8
Training loss: 0.777685284614563
Validation loss: 1.8315304799746441

Epoch: 5| Step: 9
Training loss: 0.4274665415287018
Validation loss: 1.8319807770431682

Epoch: 5| Step: 10
Training loss: 0.6079805493354797
Validation loss: 1.8291195746391051

Epoch: 216| Step: 0
Training loss: 0.6535269618034363
Validation loss: 1.8536945440435921

Epoch: 5| Step: 1
Training loss: 0.5916770696640015
Validation loss: 1.85259578176724

Epoch: 5| Step: 2
Training loss: 0.39973264932632446
Validation loss: 1.8435845016151347

Epoch: 5| Step: 3
Training loss: 0.3131198287010193
Validation loss: 1.853237146972328

Epoch: 5| Step: 4
Training loss: 0.9815627932548523
Validation loss: 1.8580696672521613

Epoch: 5| Step: 5
Training loss: 0.5760665535926819
Validation loss: 1.8694581831655195

Epoch: 5| Step: 6
Training loss: 0.6508240103721619
Validation loss: 1.8380148782525012

Epoch: 5| Step: 7
Training loss: 0.7017806768417358
Validation loss: 1.8444871287192068

Epoch: 5| Step: 8
Training loss: 0.5142674446105957
Validation loss: 1.8625391042360695

Epoch: 5| Step: 9
Training loss: 0.793599545955658
Validation loss: 1.8866322860922864

Epoch: 5| Step: 10
Training loss: 0.5784251093864441
Validation loss: 1.9020560992661344

Epoch: 217| Step: 0
Training loss: 0.9025184512138367
Validation loss: 1.935935329365474

Epoch: 5| Step: 1
Training loss: 0.368914932012558
Validation loss: 1.883379344017275

Epoch: 5| Step: 2
Training loss: 0.7350834012031555
Validation loss: 1.8432714144388835

Epoch: 5| Step: 3
Training loss: 0.6956641674041748
Validation loss: 1.8542475802924043

Epoch: 5| Step: 4
Training loss: 0.48125070333480835
Validation loss: 1.8488965354939944

Epoch: 5| Step: 5
Training loss: 0.6234728097915649
Validation loss: 1.861142505881607

Epoch: 5| Step: 6
Training loss: 0.6532338857650757
Validation loss: 1.8402793920168312

Epoch: 5| Step: 7
Training loss: 0.46605533361434937
Validation loss: 1.8113501328293995

Epoch: 5| Step: 8
Training loss: 0.6391550898551941
Validation loss: 1.7969836573446951

Epoch: 5| Step: 9
Training loss: 0.6409209966659546
Validation loss: 1.8097124612459572

Epoch: 5| Step: 10
Training loss: 0.5392270684242249
Validation loss: 1.8386864367351736

Epoch: 218| Step: 0
Training loss: 0.6081244349479675
Validation loss: 1.871913061347059

Epoch: 5| Step: 1
Training loss: 0.48089680075645447
Validation loss: 1.8694475966115152

Epoch: 5| Step: 2
Training loss: 0.9902234077453613
Validation loss: 1.8998640801316948

Epoch: 5| Step: 3
Training loss: 0.5092185735702515
Validation loss: 1.9130046149735809

Epoch: 5| Step: 4
Training loss: 0.5279895067214966
Validation loss: 1.9119252697114022

Epoch: 5| Step: 5
Training loss: 0.6021015644073486
Validation loss: 1.8844523301688574

Epoch: 5| Step: 6
Training loss: 0.6881059408187866
Validation loss: 1.874878797479855

Epoch: 5| Step: 7
Training loss: 0.4570710062980652
Validation loss: 1.8559865182445896

Epoch: 5| Step: 8
Training loss: 0.8498556017875671
Validation loss: 1.8531210576334307

Epoch: 5| Step: 9
Training loss: 0.8252162933349609
Validation loss: 1.8034397273935296

Epoch: 5| Step: 10
Training loss: 0.24321584403514862
Validation loss: 1.803657470210906

Epoch: 219| Step: 0
Training loss: 0.5843249559402466
Validation loss: 1.819335364526318

Epoch: 5| Step: 1
Training loss: 0.907791793346405
Validation loss: 1.7663006782531738

Epoch: 5| Step: 2
Training loss: 0.6679426431655884
Validation loss: 1.779358058847407

Epoch: 5| Step: 3
Training loss: 0.574510931968689
Validation loss: 1.81101426001518

Epoch: 5| Step: 4
Training loss: 0.5090581774711609
Validation loss: 1.8427386668420607

Epoch: 5| Step: 5
Training loss: 0.6226217746734619
Validation loss: 1.8444832153217767

Epoch: 5| Step: 6
Training loss: 0.7751182913780212
Validation loss: 1.8758406626280917

Epoch: 5| Step: 7
Training loss: 0.29525014758110046
Validation loss: 1.9281098868257256

Epoch: 5| Step: 8
Training loss: 0.4311477243900299
Validation loss: 1.9440444566870247

Epoch: 5| Step: 9
Training loss: 0.4826403558254242
Validation loss: 1.967074486517137

Epoch: 5| Step: 10
Training loss: 1.092726469039917
Validation loss: 1.9437296339260635

Epoch: 220| Step: 0
Training loss: 0.5549658536911011
Validation loss: 1.9411245956215808

Epoch: 5| Step: 1
Training loss: 0.7765372395515442
Validation loss: 1.8919447775809997

Epoch: 5| Step: 2
Training loss: 0.6363920569419861
Validation loss: 1.8420188567971671

Epoch: 5| Step: 3
Training loss: 0.5247787237167358
Validation loss: 1.774103477437009

Epoch: 5| Step: 4
Training loss: 0.5727022886276245
Validation loss: 1.7931236682399627

Epoch: 5| Step: 5
Training loss: 1.0513694286346436
Validation loss: 1.8043396613931144

Epoch: 5| Step: 6
Training loss: 0.48065486550331116
Validation loss: 1.7982046181155789

Epoch: 5| Step: 7
Training loss: 0.4020061492919922
Validation loss: 1.8138977225108812

Epoch: 5| Step: 8
Training loss: 0.7690597772598267
Validation loss: 1.7825935168932843

Epoch: 5| Step: 9
Training loss: 0.3678818345069885
Validation loss: 1.7867916450705579

Epoch: 5| Step: 10
Training loss: 0.6330790519714355
Validation loss: 1.8265723169490855

Epoch: 221| Step: 0
Training loss: 0.47662821412086487
Validation loss: 1.8341393316945722

Epoch: 5| Step: 1
Training loss: 0.4914788603782654
Validation loss: 1.854861492751747

Epoch: 5| Step: 2
Training loss: 0.31134429574012756
Validation loss: 1.9051085505434262

Epoch: 5| Step: 3
Training loss: 0.60822993516922
Validation loss: 1.8946615688262447

Epoch: 5| Step: 4
Training loss: 0.6443466544151306
Validation loss: 1.9050178143285936

Epoch: 5| Step: 5
Training loss: 0.3222328722476959
Validation loss: 1.8767057926424089

Epoch: 5| Step: 6
Training loss: 0.6877785921096802
Validation loss: 1.8746503399264427

Epoch: 5| Step: 7
Training loss: 0.6030040383338928
Validation loss: 1.8380179982031546

Epoch: 5| Step: 8
Training loss: 0.3973274230957031
Validation loss: 1.8470768505527126

Epoch: 5| Step: 9
Training loss: 0.7717435956001282
Validation loss: 1.7800177502375778

Epoch: 5| Step: 10
Training loss: 1.0706416368484497
Validation loss: 1.8378685341086438

Epoch: 222| Step: 0
Training loss: 0.9800115823745728
Validation loss: 1.8023258114373812

Epoch: 5| Step: 1
Training loss: 0.4246494174003601
Validation loss: 1.7501769270948184

Epoch: 5| Step: 2
Training loss: 0.5614622235298157
Validation loss: 1.7859545177029026

Epoch: 5| Step: 3
Training loss: 0.48381155729293823
Validation loss: 1.7839271778701453

Epoch: 5| Step: 4
Training loss: 0.4172945022583008
Validation loss: 1.848016268463545

Epoch: 5| Step: 5
Training loss: 0.5963183641433716
Validation loss: 1.8433077860903997

Epoch: 5| Step: 6
Training loss: 0.6662096381187439
Validation loss: 1.851394376447124

Epoch: 5| Step: 7
Training loss: 0.3267984092235565
Validation loss: 1.8998874977070799

Epoch: 5| Step: 8
Training loss: 0.7672271728515625
Validation loss: 1.8920691038972588

Epoch: 5| Step: 9
Training loss: 0.6139057278633118
Validation loss: 1.883592273599358

Epoch: 5| Step: 10
Training loss: 0.5304745435714722
Validation loss: 1.873929844107679

Epoch: 223| Step: 0
Training loss: 0.4810066819190979
Validation loss: 1.8609212239583333

Epoch: 5| Step: 1
Training loss: 0.6890665888786316
Validation loss: 1.8812705188669183

Epoch: 5| Step: 2
Training loss: 0.6001626253128052
Validation loss: 1.8277072611675467

Epoch: 5| Step: 3
Training loss: 0.6650816798210144
Validation loss: 1.81984995642016

Epoch: 5| Step: 4
Training loss: 0.6319373250007629
Validation loss: 1.8249579065589494

Epoch: 5| Step: 5
Training loss: 0.28613924980163574
Validation loss: 1.807383538574301

Epoch: 5| Step: 6
Training loss: 0.8115416765213013
Validation loss: 1.7778131936186103

Epoch: 5| Step: 7
Training loss: 0.51987224817276
Validation loss: 1.77113417912555

Epoch: 5| Step: 8
Training loss: 0.4499085545539856
Validation loss: 1.8017731046163907

Epoch: 5| Step: 9
Training loss: 0.8743747472763062
Validation loss: 1.811969962171329

Epoch: 5| Step: 10
Training loss: 0.4195425510406494
Validation loss: 1.8435648320823588

Epoch: 224| Step: 0
Training loss: 0.6556124091148376
Validation loss: 1.8447427723997383

Epoch: 5| Step: 1
Training loss: 0.49110931158065796
Validation loss: 1.8361962001810792

Epoch: 5| Step: 2
Training loss: 0.6603913903236389
Validation loss: 1.8592815501715547

Epoch: 5| Step: 3
Training loss: 0.7116343379020691
Validation loss: 1.77662673816886

Epoch: 5| Step: 4
Training loss: 0.47477978467941284
Validation loss: 1.7939132131556028

Epoch: 5| Step: 5
Training loss: 0.7203012704849243
Validation loss: 1.8119787387950446

Epoch: 5| Step: 6
Training loss: 0.5992188453674316
Validation loss: 1.7798489998745661

Epoch: 5| Step: 7
Training loss: 0.6195021867752075
Validation loss: 1.8254534480392293

Epoch: 5| Step: 8
Training loss: 0.5519381165504456
Validation loss: 1.82080380634595

Epoch: 5| Step: 9
Training loss: 0.6878456473350525
Validation loss: 1.8972308404984013

Epoch: 5| Step: 10
Training loss: 0.5538331270217896
Validation loss: 1.8669217504480833

Epoch: 225| Step: 0
Training loss: 0.33923739194869995
Validation loss: 1.8821490541581185

Epoch: 5| Step: 1
Training loss: 1.2638989686965942
Validation loss: 1.871151093513735

Epoch: 5| Step: 2
Training loss: 0.5393617749214172
Validation loss: 1.8452703286242742

Epoch: 5| Step: 3
Training loss: 0.42076611518859863
Validation loss: 1.8228633711414952

Epoch: 5| Step: 4
Training loss: 0.4648292064666748
Validation loss: 1.8012606751534246

Epoch: 5| Step: 5
Training loss: 0.5150246620178223
Validation loss: 1.7858363710423952

Epoch: 5| Step: 6
Training loss: 0.6570426225662231
Validation loss: 1.7864468687324113

Epoch: 5| Step: 7
Training loss: 0.6432156562805176
Validation loss: 1.814787221211259

Epoch: 5| Step: 8
Training loss: 0.4705074429512024
Validation loss: 1.8020547846312165

Epoch: 5| Step: 9
Training loss: 0.5648210644721985
Validation loss: 1.846683350942468

Epoch: 5| Step: 10
Training loss: 0.4457096457481384
Validation loss: 1.899510665606427

Epoch: 226| Step: 0
Training loss: 0.5144676566123962
Validation loss: 1.877892924893287

Epoch: 5| Step: 1
Training loss: 0.5955407023429871
Validation loss: 1.8879628796731271

Epoch: 5| Step: 2
Training loss: 0.5610032081604004
Validation loss: 1.8821171252958235

Epoch: 5| Step: 3
Training loss: 0.7835336923599243
Validation loss: 1.8982549816049554

Epoch: 5| Step: 4
Training loss: 0.3751857876777649
Validation loss: 1.899885962086339

Epoch: 5| Step: 5
Training loss: 0.5487500429153442
Validation loss: 1.8866336973764564

Epoch: 5| Step: 6
Training loss: 0.5555752515792847
Validation loss: 1.9150978647252566

Epoch: 5| Step: 7
Training loss: 0.49117451906204224
Validation loss: 1.9048100594551332

Epoch: 5| Step: 8
Training loss: 0.5191683769226074
Validation loss: 1.8302297066616755

Epoch: 5| Step: 9
Training loss: 0.8188247680664062
Validation loss: 1.8156460408241517

Epoch: 5| Step: 10
Training loss: 0.39089521765708923
Validation loss: 1.84107167361885

Epoch: 227| Step: 0
Training loss: 0.46686238050460815
Validation loss: 1.811284283156036

Epoch: 5| Step: 1
Training loss: 0.4896604120731354
Validation loss: 1.819018735680529

Epoch: 5| Step: 2
Training loss: 0.6417350769042969
Validation loss: 1.8551831142876738

Epoch: 5| Step: 3
Training loss: 0.3833996653556824
Validation loss: 1.826123845192694

Epoch: 5| Step: 4
Training loss: 0.6551026701927185
Validation loss: 1.898832041730163

Epoch: 5| Step: 5
Training loss: 0.5358548760414124
Validation loss: 1.8964615688529065

Epoch: 5| Step: 6
Training loss: 0.5130726099014282
Validation loss: 1.9015072520061205

Epoch: 5| Step: 7
Training loss: 0.7866135835647583
Validation loss: 1.8874368539420507

Epoch: 5| Step: 8
Training loss: 0.7464931607246399
Validation loss: 1.8835124456754295

Epoch: 5| Step: 9
Training loss: 0.4510043263435364
Validation loss: 1.8463048204298942

Epoch: 5| Step: 10
Training loss: 0.5360288023948669
Validation loss: 1.8746327802699099

Epoch: 228| Step: 0
Training loss: 0.45416831970214844
Validation loss: 1.8806066128515428

Epoch: 5| Step: 1
Training loss: 0.6023744344711304
Validation loss: 1.8703620241534324

Epoch: 5| Step: 2
Training loss: 0.5255794525146484
Validation loss: 1.8321293989817302

Epoch: 5| Step: 3
Training loss: 0.7829278707504272
Validation loss: 1.836876433382752

Epoch: 5| Step: 4
Training loss: 0.38128530979156494
Validation loss: 1.8256898823604788

Epoch: 5| Step: 5
Training loss: 0.7123159766197205
Validation loss: 1.8101905930426814

Epoch: 5| Step: 6
Training loss: 0.5318623781204224
Validation loss: 1.8311291330604142

Epoch: 5| Step: 7
Training loss: 0.706450879573822
Validation loss: 1.812959280065311

Epoch: 5| Step: 8
Training loss: 0.7007543444633484
Validation loss: 1.8191540997515443

Epoch: 5| Step: 9
Training loss: 0.42954832315444946
Validation loss: 1.8118457486552577

Epoch: 5| Step: 10
Training loss: 0.27577558159828186
Validation loss: 1.8064240588936755

Epoch: 229| Step: 0
Training loss: 0.5405559539794922
Validation loss: 1.8206590747320524

Epoch: 5| Step: 1
Training loss: 0.5067052841186523
Validation loss: 1.8525603894264466

Epoch: 5| Step: 2
Training loss: 0.4485396444797516
Validation loss: 1.839674465117916

Epoch: 5| Step: 3
Training loss: 0.8174265623092651
Validation loss: 1.7834993588027133

Epoch: 5| Step: 4
Training loss: 0.2746170163154602
Validation loss: 1.7797437008991037

Epoch: 5| Step: 5
Training loss: 0.42149996757507324
Validation loss: 1.7768827202499553

Epoch: 5| Step: 6
Training loss: 0.5114389657974243
Validation loss: 1.81033541053854

Epoch: 5| Step: 7
Training loss: 0.5400753617286682
Validation loss: 1.7921928000706497

Epoch: 5| Step: 8
Training loss: 0.7146595120429993
Validation loss: 1.8128235135027158

Epoch: 5| Step: 9
Training loss: 0.5353825688362122
Validation loss: 1.8078538064033753

Epoch: 5| Step: 10
Training loss: 0.5527705550193787
Validation loss: 1.8710090857680126

Epoch: 230| Step: 0
Training loss: 0.38875821232795715
Validation loss: 1.8167639637506137

Epoch: 5| Step: 1
Training loss: 0.6771412491798401
Validation loss: 1.8759652209538284

Epoch: 5| Step: 2
Training loss: 0.8556974530220032
Validation loss: 1.8516983550081971

Epoch: 5| Step: 3
Training loss: 0.3924388289451599
Validation loss: 1.8041954040527344

Epoch: 5| Step: 4
Training loss: 0.496521532535553
Validation loss: 1.783671082988862

Epoch: 5| Step: 5
Training loss: 0.4305092692375183
Validation loss: 1.762046334564045

Epoch: 5| Step: 6
Training loss: 0.34503206610679626
Validation loss: 1.802703889467383

Epoch: 5| Step: 7
Training loss: 0.9176966547966003
Validation loss: 1.8095880387931742

Epoch: 5| Step: 8
Training loss: 0.5500940680503845
Validation loss: 1.7925788125684183

Epoch: 5| Step: 9
Training loss: 0.3331640958786011
Validation loss: 1.7998603582382202

Epoch: 5| Step: 10
Training loss: 0.39301928877830505
Validation loss: 1.8082130134746592

Epoch: 231| Step: 0
Training loss: 0.4073203206062317
Validation loss: 1.7829776156333186

Epoch: 5| Step: 1
Training loss: 0.6141708493232727
Validation loss: 1.7670963861609017

Epoch: 5| Step: 2
Training loss: 0.4552372992038727
Validation loss: 1.8144714524669032

Epoch: 5| Step: 3
Training loss: 0.4785541892051697
Validation loss: 1.756627716043944

Epoch: 5| Step: 4
Training loss: 0.6321011781692505
Validation loss: 1.8040420573244813

Epoch: 5| Step: 5
Training loss: 0.6355857849121094
Validation loss: 1.8023174937053392

Epoch: 5| Step: 6
Training loss: 0.29729416966438293
Validation loss: 1.8075962797287972

Epoch: 5| Step: 7
Training loss: 0.4813162684440613
Validation loss: 1.854546573854262

Epoch: 5| Step: 8
Training loss: 0.3365189731121063
Validation loss: 1.8154709249414422

Epoch: 5| Step: 9
Training loss: 0.8206213712692261
Validation loss: 1.8646683180204002

Epoch: 5| Step: 10
Training loss: 0.5496132969856262
Validation loss: 1.8817809025446575

Epoch: 232| Step: 0
Training loss: 0.3656613826751709
Validation loss: 1.9049649648768927

Epoch: 5| Step: 1
Training loss: 0.6617899537086487
Validation loss: 1.9010997767089515

Epoch: 5| Step: 2
Training loss: 0.18257002532482147
Validation loss: 1.8906417918461624

Epoch: 5| Step: 3
Training loss: 0.6380369663238525
Validation loss: 1.8954989269215574

Epoch: 5| Step: 4
Training loss: 0.48639488220214844
Validation loss: 1.9142008161032071

Epoch: 5| Step: 5
Training loss: 0.6840302348136902
Validation loss: 1.8973870546587053

Epoch: 5| Step: 6
Training loss: 0.812127947807312
Validation loss: 1.9350452294913671

Epoch: 5| Step: 7
Training loss: 0.32985028624534607
Validation loss: 1.9151161691193939

Epoch: 5| Step: 8
Training loss: 0.5191641449928284
Validation loss: 1.8674604341547976

Epoch: 5| Step: 9
Training loss: 0.4579705595970154
Validation loss: 1.8360142041278142

Epoch: 5| Step: 10
Training loss: 0.5041882395744324
Validation loss: 1.782942819338973

Epoch: 233| Step: 0
Training loss: 0.589479386806488
Validation loss: 1.7471268433396534

Epoch: 5| Step: 1
Training loss: 0.6141495108604431
Validation loss: 1.7421326714177285

Epoch: 5| Step: 2
Training loss: 0.45422831177711487
Validation loss: 1.755023302570466

Epoch: 5| Step: 3
Training loss: 0.5519773960113525
Validation loss: 1.7628483592822988

Epoch: 5| Step: 4
Training loss: 0.7110596299171448
Validation loss: 1.7375721944275724

Epoch: 5| Step: 5
Training loss: 0.5397129058837891
Validation loss: 1.776538522012772

Epoch: 5| Step: 6
Training loss: 0.41294145584106445
Validation loss: 1.8082130544929094

Epoch: 5| Step: 7
Training loss: 0.45437750220298767
Validation loss: 1.887592545119665

Epoch: 5| Step: 8
Training loss: 0.45246487855911255
Validation loss: 1.9060194351339852

Epoch: 5| Step: 9
Training loss: 0.5465620756149292
Validation loss: 1.8557607794320712

Epoch: 5| Step: 10
Training loss: 0.6368975639343262
Validation loss: 1.8028650155631445

Epoch: 234| Step: 0
Training loss: 0.5421780943870544
Validation loss: 1.7775668456990232

Epoch: 5| Step: 1
Training loss: 0.46262890100479126
Validation loss: 1.7470336806389593

Epoch: 5| Step: 2
Training loss: 0.4745733141899109
Validation loss: 1.7294276786106888

Epoch: 5| Step: 3
Training loss: 0.5044645071029663
Validation loss: 1.7361328781292003

Epoch: 5| Step: 4
Training loss: 0.47513633966445923
Validation loss: 1.7110893431530203

Epoch: 5| Step: 5
Training loss: 0.8428596258163452
Validation loss: 1.7179209980913388

Epoch: 5| Step: 6
Training loss: 0.9426183700561523
Validation loss: 1.7646218339602153

Epoch: 5| Step: 7
Training loss: 0.5453252196311951
Validation loss: 1.7775765234424221

Epoch: 5| Step: 8
Training loss: 0.344295859336853
Validation loss: 1.7877008966220322

Epoch: 5| Step: 9
Training loss: 0.4677662253379822
Validation loss: 1.8176123275551745

Epoch: 5| Step: 10
Training loss: 0.26171836256980896
Validation loss: 1.8729663125930294

Epoch: 235| Step: 0
Training loss: 0.7607602477073669
Validation loss: 1.8857674829421505

Epoch: 5| Step: 1
Training loss: 0.5873813033103943
Validation loss: 1.9147249690947994

Epoch: 5| Step: 2
Training loss: 0.6624976992607117
Validation loss: 1.8579582706574471

Epoch: 5| Step: 3
Training loss: 0.39550283551216125
Validation loss: 1.8271018971679032

Epoch: 5| Step: 4
Training loss: 0.42033377289772034
Validation loss: 1.8133770445341706

Epoch: 5| Step: 5
Training loss: 0.6200416684150696
Validation loss: 1.775146020356045

Epoch: 5| Step: 6
Training loss: 0.6391651034355164
Validation loss: 1.767293857630863

Epoch: 5| Step: 7
Training loss: 0.41011229157447815
Validation loss: 1.7826720796605593

Epoch: 5| Step: 8
Training loss: 0.3969395160675049
Validation loss: 1.7916609523116902

Epoch: 5| Step: 9
Training loss: 0.6129578351974487
Validation loss: 1.8384680478803572

Epoch: 5| Step: 10
Training loss: 0.2921227514743805
Validation loss: 1.8618720872427827

Epoch: 236| Step: 0
Training loss: 0.43601447343826294
Validation loss: 1.8539317833480013

Epoch: 5| Step: 1
Training loss: 0.6093252301216125
Validation loss: 1.8986473480860393

Epoch: 5| Step: 2
Training loss: 0.7258652448654175
Validation loss: 1.8976072470347087

Epoch: 5| Step: 3
Training loss: 0.7650918960571289
Validation loss: 1.9032164914633638

Epoch: 5| Step: 4
Training loss: 0.3910289406776428
Validation loss: 1.834491386208483

Epoch: 5| Step: 5
Training loss: 0.33415013551712036
Validation loss: 1.8427361852379256

Epoch: 5| Step: 6
Training loss: 0.25678133964538574
Validation loss: 1.7662110149219472

Epoch: 5| Step: 7
Training loss: 0.5834868550300598
Validation loss: 1.7449897040602982

Epoch: 5| Step: 8
Training loss: 0.21895913779735565
Validation loss: 1.755592953774237

Epoch: 5| Step: 9
Training loss: 0.6472638845443726
Validation loss: 1.7640988570387646

Epoch: 5| Step: 10
Training loss: 0.41326645016670227
Validation loss: 1.7806010848732405

Epoch: 237| Step: 0
Training loss: 0.5474939346313477
Validation loss: 1.8152753588973836

Epoch: 5| Step: 1
Training loss: 0.8138734698295593
Validation loss: 1.8700553909424813

Epoch: 5| Step: 2
Training loss: 0.5832890272140503
Validation loss: 1.9250427715239986

Epoch: 5| Step: 3
Training loss: 0.6373414397239685
Validation loss: 1.8879176801250828

Epoch: 5| Step: 4
Training loss: 0.5090394020080566
Validation loss: 1.941590860325803

Epoch: 5| Step: 5
Training loss: 0.3138837218284607
Validation loss: 1.9320609236276278

Epoch: 5| Step: 6
Training loss: 0.3578747808933258
Validation loss: 1.9142309645170807

Epoch: 5| Step: 7
Training loss: 0.4350690245628357
Validation loss: 1.886309500663511

Epoch: 5| Step: 8
Training loss: 0.43449392914772034
Validation loss: 1.9115388444674912

Epoch: 5| Step: 9
Training loss: 0.49900883436203003
Validation loss: 1.857156051102505

Epoch: 5| Step: 10
Training loss: 0.2802862226963043
Validation loss: 1.831658004432596

Epoch: 238| Step: 0
Training loss: 0.2892180383205414
Validation loss: 1.872383745767737

Epoch: 5| Step: 1
Training loss: 0.7872434854507446
Validation loss: 1.8893675560592322

Epoch: 5| Step: 2
Training loss: 0.5239294171333313
Validation loss: 1.8694209001397575

Epoch: 5| Step: 3
Training loss: 0.34871339797973633
Validation loss: 1.8458219510252758

Epoch: 5| Step: 4
Training loss: 0.5156171917915344
Validation loss: 1.8428490443896222

Epoch: 5| Step: 5
Training loss: 0.6165274381637573
Validation loss: 1.8870997044347948

Epoch: 5| Step: 6
Training loss: 0.49156227707862854
Validation loss: 1.8853848582954817

Epoch: 5| Step: 7
Training loss: 0.46446937322616577
Validation loss: 1.8575977330566735

Epoch: 5| Step: 8
Training loss: 0.6078439354896545
Validation loss: 1.8230983159875358

Epoch: 5| Step: 9
Training loss: 0.43939557671546936
Validation loss: 1.7835287996517715

Epoch: 5| Step: 10
Training loss: 0.3888748586177826
Validation loss: 1.8012818341614099

Epoch: 239| Step: 0
Training loss: 0.45458635687828064
Validation loss: 1.742871792085709

Epoch: 5| Step: 1
Training loss: 0.1929006278514862
Validation loss: 1.7387575244390836

Epoch: 5| Step: 2
Training loss: 0.32589811086654663
Validation loss: 1.7235700238135554

Epoch: 5| Step: 3
Training loss: 0.7038263082504272
Validation loss: 1.7743267987364082

Epoch: 5| Step: 4
Training loss: 0.5056207776069641
Validation loss: 1.7692600501480924

Epoch: 5| Step: 5
Training loss: 0.6570423245429993
Validation loss: 1.753990090021523

Epoch: 5| Step: 6
Training loss: 0.46791476011276245
Validation loss: 1.7464056591833792

Epoch: 5| Step: 7
Training loss: 0.812018096446991
Validation loss: 1.7847302985447708

Epoch: 5| Step: 8
Training loss: 0.32853570580482483
Validation loss: 1.7991621186656337

Epoch: 5| Step: 9
Training loss: 0.4106917381286621
Validation loss: 1.8221372455678961

Epoch: 5| Step: 10
Training loss: 0.38245880603790283
Validation loss: 1.8621327953953897

Epoch: 240| Step: 0
Training loss: 0.6264864206314087
Validation loss: 1.8849820898425194

Epoch: 5| Step: 1
Training loss: 0.48328739404678345
Validation loss: 1.9162264921331917

Epoch: 5| Step: 2
Training loss: 0.47048187255859375
Validation loss: 1.8874763340078375

Epoch: 5| Step: 3
Training loss: 0.7601083517074585
Validation loss: 1.8879543248043265

Epoch: 5| Step: 4
Training loss: 0.38467830419540405
Validation loss: 1.8584773976315734

Epoch: 5| Step: 5
Training loss: 0.3115963637828827
Validation loss: 1.8208492532853158

Epoch: 5| Step: 6
Training loss: 0.42711567878723145
Validation loss: 1.771235663403747

Epoch: 5| Step: 7
Training loss: 0.4093700051307678
Validation loss: 1.7381503633273545

Epoch: 5| Step: 8
Training loss: 0.4353492259979248
Validation loss: 1.6787664236560944

Epoch: 5| Step: 9
Training loss: 0.5587112903594971
Validation loss: 1.6809613127862253

Epoch: 5| Step: 10
Training loss: 0.8183002471923828
Validation loss: 1.692155485512108

Epoch: 241| Step: 0
Training loss: 0.3614862561225891
Validation loss: 1.690943274446713

Epoch: 5| Step: 1
Training loss: 0.894495964050293
Validation loss: 1.721382237249805

Epoch: 5| Step: 2
Training loss: 0.7970161437988281
Validation loss: 1.7579149174433883

Epoch: 5| Step: 3
Training loss: 0.41103386878967285
Validation loss: 1.8440431317975443

Epoch: 5| Step: 4
Training loss: 0.2778058648109436
Validation loss: 1.9660974984527917

Epoch: 5| Step: 5
Training loss: 0.7200876474380493
Validation loss: 2.0382094101239274

Epoch: 5| Step: 6
Training loss: 0.39926931262016296
Validation loss: 2.012040243353895

Epoch: 5| Step: 7
Training loss: 0.5200750827789307
Validation loss: 1.9953689216285624

Epoch: 5| Step: 8
Training loss: 0.3674800395965576
Validation loss: 1.9115127491694626

Epoch: 5| Step: 9
Training loss: 0.29784080386161804
Validation loss: 1.8530253684648903

Epoch: 5| Step: 10
Training loss: 0.6690118312835693
Validation loss: 1.842305548729435

Epoch: 242| Step: 0
Training loss: 0.5760602951049805
Validation loss: 1.8061032987410022

Epoch: 5| Step: 1
Training loss: 0.5375980734825134
Validation loss: 1.8109128436734598

Epoch: 5| Step: 2
Training loss: 0.3607921600341797
Validation loss: 1.7991419428138322

Epoch: 5| Step: 3
Training loss: 0.6502718925476074
Validation loss: 1.8142206194580242

Epoch: 5| Step: 4
Training loss: 0.7536497116088867
Validation loss: 1.7937693583068026

Epoch: 5| Step: 5
Training loss: 0.34073323011398315
Validation loss: 1.8140886996382026

Epoch: 5| Step: 6
Training loss: 0.3262362778186798
Validation loss: 1.8277480089536278

Epoch: 5| Step: 7
Training loss: 0.49906015396118164
Validation loss: 1.811884367337791

Epoch: 5| Step: 8
Training loss: 0.2711213231086731
Validation loss: 1.8749534519769813

Epoch: 5| Step: 9
Training loss: 0.6145127415657043
Validation loss: 1.858978904703612

Epoch: 5| Step: 10
Training loss: 0.45028549432754517
Validation loss: 1.8286090973884828

Epoch: 243| Step: 0
Training loss: 0.3584771752357483
Validation loss: 1.8043543638721589

Epoch: 5| Step: 1
Training loss: 0.29128676652908325
Validation loss: 1.8136732078367663

Epoch: 5| Step: 2
Training loss: 0.6718841791152954
Validation loss: 1.7643398700221893

Epoch: 5| Step: 3
Training loss: 0.6434724926948547
Validation loss: 1.746320354682143

Epoch: 5| Step: 4
Training loss: 0.4200916886329651
Validation loss: 1.7153395939898748

Epoch: 5| Step: 5
Training loss: 0.5565489530563354
Validation loss: 1.7007808249483827

Epoch: 5| Step: 6
Training loss: 0.637274444103241
Validation loss: 1.723350114719842

Epoch: 5| Step: 7
Training loss: 0.5054718852043152
Validation loss: 1.756653106340798

Epoch: 5| Step: 8
Training loss: 0.39894989132881165
Validation loss: 1.756637910360931

Epoch: 5| Step: 9
Training loss: 0.3521899878978729
Validation loss: 1.7948789455557381

Epoch: 5| Step: 10
Training loss: 0.3085525333881378
Validation loss: 1.8107323018453454

Epoch: 244| Step: 0
Training loss: 0.302382230758667
Validation loss: 1.834959456997533

Epoch: 5| Step: 1
Training loss: 0.41193661093711853
Validation loss: 1.8179597354704333

Epoch: 5| Step: 2
Training loss: 0.34993627667427063
Validation loss: 1.7864838492485784

Epoch: 5| Step: 3
Training loss: 0.2679571807384491
Validation loss: 1.7869349320729573

Epoch: 5| Step: 4
Training loss: 0.6908199191093445
Validation loss: 1.782816651046917

Epoch: 5| Step: 5
Training loss: 0.378116637468338
Validation loss: 1.7445540069251932

Epoch: 5| Step: 6
Training loss: 0.45939892530441284
Validation loss: 1.7555180929040397

Epoch: 5| Step: 7
Training loss: 1.0112091302871704
Validation loss: 1.7441772389155563

Epoch: 5| Step: 8
Training loss: 0.46266835927963257
Validation loss: 1.774576360179532

Epoch: 5| Step: 9
Training loss: 0.5985548496246338
Validation loss: 1.7605605445882326

Epoch: 5| Step: 10
Training loss: 0.12939220666885376
Validation loss: 1.8092937290027578

Epoch: 245| Step: 0
Training loss: 0.6516596078872681
Validation loss: 1.8641797675881335

Epoch: 5| Step: 1
Training loss: 0.49934035539627075
Validation loss: 1.8504752369337185

Epoch: 5| Step: 2
Training loss: 0.4470667839050293
Validation loss: 1.852023014458277

Epoch: 5| Step: 3
Training loss: 0.5505765676498413
Validation loss: 1.8356783825864074

Epoch: 5| Step: 4
Training loss: 0.4020596444606781
Validation loss: 1.7901155307728758

Epoch: 5| Step: 5
Training loss: 0.27792906761169434
Validation loss: 1.7727197036948255

Epoch: 5| Step: 6
Training loss: 0.4633474349975586
Validation loss: 1.7540025403422694

Epoch: 5| Step: 7
Training loss: 0.5050504207611084
Validation loss: 1.757057620633033

Epoch: 5| Step: 8
Training loss: 0.3025640845298767
Validation loss: 1.761221275534681

Epoch: 5| Step: 9
Training loss: 0.5530441403388977
Validation loss: 1.7604985339667207

Epoch: 5| Step: 10
Training loss: 0.37309494614601135
Validation loss: 1.768299069455875

Epoch: 246| Step: 0
Training loss: 0.32381242513656616
Validation loss: 1.7755713283374746

Epoch: 5| Step: 1
Training loss: 0.42535877227783203
Validation loss: 1.7697371769976873

Epoch: 5| Step: 2
Training loss: 0.8544656038284302
Validation loss: 1.7817076213898198

Epoch: 5| Step: 3
Training loss: 0.2344101369380951
Validation loss: 1.7616116295578659

Epoch: 5| Step: 4
Training loss: 0.3767699599266052
Validation loss: 1.7763932533161615

Epoch: 5| Step: 5
Training loss: 0.4948197901248932
Validation loss: 1.7675081068469631

Epoch: 5| Step: 6
Training loss: 0.6501377820968628
Validation loss: 1.7897461152845813

Epoch: 5| Step: 7
Training loss: 0.3719136416912079
Validation loss: 1.802780858932003

Epoch: 5| Step: 8
Training loss: 0.4636506140232086
Validation loss: 1.8098389871658818

Epoch: 5| Step: 9
Training loss: 0.35396939516067505
Validation loss: 1.791205612562036

Epoch: 5| Step: 10
Training loss: 0.4626917243003845
Validation loss: 1.7595305865810764

Epoch: 247| Step: 0
Training loss: 0.38943958282470703
Validation loss: 1.7218709004822599

Epoch: 5| Step: 1
Training loss: 0.4772340655326843
Validation loss: 1.7288989379841795

Epoch: 5| Step: 2
Training loss: 0.3951752781867981
Validation loss: 1.7728179193312121

Epoch: 5| Step: 3
Training loss: 0.42794308066368103
Validation loss: 1.7940753839349235

Epoch: 5| Step: 4
Training loss: 0.9384989738464355
Validation loss: 1.7831701604268884

Epoch: 5| Step: 5
Training loss: 0.4322083592414856
Validation loss: 1.815517577432817

Epoch: 5| Step: 6
Training loss: 0.3163071870803833
Validation loss: 1.7895886744222333

Epoch: 5| Step: 7
Training loss: 0.3969250023365021
Validation loss: 1.7962301097890383

Epoch: 5| Step: 8
Training loss: 0.3565983474254608
Validation loss: 1.7795780781776673

Epoch: 5| Step: 9
Training loss: 0.43839579820632935
Validation loss: 1.796066745635002

Epoch: 5| Step: 10
Training loss: 0.5886662602424622
Validation loss: 1.7743601440101542

Epoch: 248| Step: 0
Training loss: 0.292652428150177
Validation loss: 1.769710947108525

Epoch: 5| Step: 1
Training loss: 0.35079410672187805
Validation loss: 1.748752958031111

Epoch: 5| Step: 2
Training loss: 0.4791445732116699
Validation loss: 1.768596625456246

Epoch: 5| Step: 3
Training loss: 0.514309287071228
Validation loss: 1.8038589082738405

Epoch: 5| Step: 4
Training loss: 0.3083775043487549
Validation loss: 1.8504262149974864

Epoch: 5| Step: 5
Training loss: 0.5950533151626587
Validation loss: 1.8666912971004364

Epoch: 5| Step: 6
Training loss: 0.6761353611946106
Validation loss: 1.8752126206633866

Epoch: 5| Step: 7
Training loss: 0.5337232947349548
Validation loss: 1.8968890482379543

Epoch: 5| Step: 8
Training loss: 0.30291980504989624
Validation loss: 1.8327756620222522

Epoch: 5| Step: 9
Training loss: 0.5891141891479492
Validation loss: 1.8273353961206251

Epoch: 5| Step: 10
Training loss: 0.42146092653274536
Validation loss: 1.7912529386499876

Epoch: 249| Step: 0
Training loss: 0.3141810894012451
Validation loss: 1.729470791355256

Epoch: 5| Step: 1
Training loss: 0.49910688400268555
Validation loss: 1.712204816520855

Epoch: 5| Step: 2
Training loss: 0.4208066463470459
Validation loss: 1.6926465777940647

Epoch: 5| Step: 3
Training loss: 0.5709284543991089
Validation loss: 1.728346182454017

Epoch: 5| Step: 4
Training loss: 0.7423609495162964
Validation loss: 1.720568556939402

Epoch: 5| Step: 5
Training loss: 0.2904597222805023
Validation loss: 1.735391250220678

Epoch: 5| Step: 6
Training loss: 0.5093725323677063
Validation loss: 1.7035971918413717

Epoch: 5| Step: 7
Training loss: 0.38899773359298706
Validation loss: 1.7747296940895818

Epoch: 5| Step: 8
Training loss: 0.36729666590690613
Validation loss: 1.7460675636927288

Epoch: 5| Step: 9
Training loss: 0.3502480089664459
Validation loss: 1.825966860658379

Epoch: 5| Step: 10
Training loss: 0.5401782989501953
Validation loss: 1.8634332982442712

Epoch: 250| Step: 0
Training loss: 0.5966582894325256
Validation loss: 1.8355990302178167

Epoch: 5| Step: 1
Training loss: 0.36120325326919556
Validation loss: 1.8333905076467862

Epoch: 5| Step: 2
Training loss: 0.4813021719455719
Validation loss: 1.8118620713551838

Epoch: 5| Step: 3
Training loss: 0.5700887441635132
Validation loss: 1.8068875362796168

Epoch: 5| Step: 4
Training loss: 0.5662125945091248
Validation loss: 1.7866432051504813

Epoch: 5| Step: 5
Training loss: 0.3169252574443817
Validation loss: 1.7656200649917766

Epoch: 5| Step: 6
Training loss: 0.3972380459308624
Validation loss: 1.7626366769113848

Epoch: 5| Step: 7
Training loss: 0.4651881158351898
Validation loss: 1.679567834382416

Epoch: 5| Step: 8
Training loss: 0.3057330250740051
Validation loss: 1.7100843460329118

Epoch: 5| Step: 9
Training loss: 0.19117386639118195
Validation loss: 1.709415110849565

Epoch: 5| Step: 10
Training loss: 0.4553511142730713
Validation loss: 1.7089081925730552

Epoch: 251| Step: 0
Training loss: 0.5946024656295776
Validation loss: 1.700786780285579

Epoch: 5| Step: 1
Training loss: 0.3450390696525574
Validation loss: 1.729784260513962

Epoch: 5| Step: 2
Training loss: 0.3444845378398895
Validation loss: 1.7894530309143888

Epoch: 5| Step: 3
Training loss: 0.33189064264297485
Validation loss: 1.8035377943387596

Epoch: 5| Step: 4
Training loss: 0.4983726441860199
Validation loss: 1.8315329090241463

Epoch: 5| Step: 5
Training loss: 0.3736538589000702
Validation loss: 1.8160078730634464

Epoch: 5| Step: 6
Training loss: 0.48080500960350037
Validation loss: 1.8076606206996466

Epoch: 5| Step: 7
Training loss: 0.2627757489681244
Validation loss: 1.8264784197653494

Epoch: 5| Step: 8
Training loss: 0.6071068644523621
Validation loss: 1.818762998427114

Epoch: 5| Step: 9
Training loss: 0.5658987760543823
Validation loss: 1.8208411899946069

Epoch: 5| Step: 10
Training loss: 0.3727242052555084
Validation loss: 1.7816891029316893

Epoch: 252| Step: 0
Training loss: 0.31314510107040405
Validation loss: 1.7833861868868592

Epoch: 5| Step: 1
Training loss: 0.37245598435401917
Validation loss: 1.7889433227559572

Epoch: 5| Step: 2
Training loss: 0.4718167781829834
Validation loss: 1.765151890375281

Epoch: 5| Step: 3
Training loss: 0.46603021025657654
Validation loss: 1.753338360658256

Epoch: 5| Step: 4
Training loss: 0.22941796481609344
Validation loss: 1.7686653726844377

Epoch: 5| Step: 5
Training loss: 0.8565574884414673
Validation loss: 1.7630743538179705

Epoch: 5| Step: 6
Training loss: 0.35729607939720154
Validation loss: 1.7609154396159674

Epoch: 5| Step: 7
Training loss: 0.27936989068984985
Validation loss: 1.7604973598193097

Epoch: 5| Step: 8
Training loss: 0.37433671951293945
Validation loss: 1.781085624489733

Epoch: 5| Step: 9
Training loss: 0.4473368227481842
Validation loss: 1.7690668977716917

Epoch: 5| Step: 10
Training loss: 0.3799956738948822
Validation loss: 1.7890326220502135

Epoch: 253| Step: 0
Training loss: 0.3270634114742279
Validation loss: 1.81601579471301

Epoch: 5| Step: 1
Training loss: 0.3970739543437958
Validation loss: 1.79601974128395

Epoch: 5| Step: 2
Training loss: 0.2794521749019623
Validation loss: 1.7912053113342614

Epoch: 5| Step: 3
Training loss: 0.25412875413894653
Validation loss: 1.8010233063851633

Epoch: 5| Step: 4
Training loss: 0.4234226644039154
Validation loss: 1.8119049687539377

Epoch: 5| Step: 5
Training loss: 0.42438775300979614
Validation loss: 1.8191357966392272

Epoch: 5| Step: 6
Training loss: 0.3352218270301819
Validation loss: 1.803752455660092

Epoch: 5| Step: 7
Training loss: 0.8230363130569458
Validation loss: 1.7741956274996522

Epoch: 5| Step: 8
Training loss: 0.42816290259361267
Validation loss: 1.7607534316278273

Epoch: 5| Step: 9
Training loss: 0.3024500906467438
Validation loss: 1.7879277044726956

Epoch: 5| Step: 10
Training loss: 0.5854527354240417
Validation loss: 1.7890185925268358

Epoch: 254| Step: 0
Training loss: 0.5312755107879639
Validation loss: 1.8195300973871702

Epoch: 5| Step: 1
Training loss: 0.5530319213867188
Validation loss: 1.801545125181957

Epoch: 5| Step: 2
Training loss: 0.5677605867385864
Validation loss: 1.7816582713075864

Epoch: 5| Step: 3
Training loss: 0.26268601417541504
Validation loss: 1.798626922792004

Epoch: 5| Step: 4
Training loss: 0.4144858717918396
Validation loss: 1.7829641462654195

Epoch: 5| Step: 5
Training loss: 0.4347767233848572
Validation loss: 1.761353172281737

Epoch: 5| Step: 6
Training loss: 0.31284525990486145
Validation loss: 1.7262630398555467

Epoch: 5| Step: 7
Training loss: 0.3799475133419037
Validation loss: 1.7397134124591787

Epoch: 5| Step: 8
Training loss: 0.32552865147590637
Validation loss: 1.7645355386118735

Epoch: 5| Step: 9
Training loss: 0.23700089752674103
Validation loss: 1.7600367620427122

Epoch: 5| Step: 10
Training loss: 0.31013739109039307
Validation loss: 1.7572673751461891

Epoch: 255| Step: 0
Training loss: 0.35430553555488586
Validation loss: 1.781784765182003

Epoch: 5| Step: 1
Training loss: 0.4560564458370209
Validation loss: 1.8197578178938998

Epoch: 5| Step: 2
Training loss: 0.2518685460090637
Validation loss: 1.814631490297215

Epoch: 5| Step: 3
Training loss: 0.33247849345207214
Validation loss: 1.8147878954487462

Epoch: 5| Step: 4
Training loss: 0.24335701763629913
Validation loss: 1.8009204223591795

Epoch: 5| Step: 5
Training loss: 0.38380199670791626
Validation loss: 1.8381240726799093

Epoch: 5| Step: 6
Training loss: 0.40208253264427185
Validation loss: 1.7960097712855185

Epoch: 5| Step: 7
Training loss: 0.3995710015296936
Validation loss: 1.767932403472162

Epoch: 5| Step: 8
Training loss: 0.5098694562911987
Validation loss: 1.7770602100638933

Epoch: 5| Step: 9
Training loss: 0.3581899106502533
Validation loss: 1.7436659566817745

Epoch: 5| Step: 10
Training loss: 0.6191997528076172
Validation loss: 1.735257456379552

Epoch: 256| Step: 0
Training loss: 0.44237184524536133
Validation loss: 1.7276067272309334

Epoch: 5| Step: 1
Training loss: 0.3011860251426697
Validation loss: 1.708189715621292

Epoch: 5| Step: 2
Training loss: 0.33035755157470703
Validation loss: 1.7144988454798216

Epoch: 5| Step: 3
Training loss: 0.6018450260162354
Validation loss: 1.750676812664155

Epoch: 5| Step: 4
Training loss: 0.23840618133544922
Validation loss: 1.76552108282684

Epoch: 5| Step: 5
Training loss: 0.44867318868637085
Validation loss: 1.8073196103495937

Epoch: 5| Step: 6
Training loss: 0.35639920830726624
Validation loss: 1.7940349296856952

Epoch: 5| Step: 7
Training loss: 0.39921367168426514
Validation loss: 1.8002910332013202

Epoch: 5| Step: 8
Training loss: 0.37260955572128296
Validation loss: 1.8013183532222625

Epoch: 5| Step: 9
Training loss: 0.4486159682273865
Validation loss: 1.8166371212210706

Epoch: 5| Step: 10
Training loss: 0.4736986756324768
Validation loss: 1.8064263020792315

Epoch: 257| Step: 0
Training loss: 0.420600563287735
Validation loss: 1.769178666094298

Epoch: 5| Step: 1
Training loss: 0.24634993076324463
Validation loss: 1.787286667413609

Epoch: 5| Step: 2
Training loss: 0.3425540030002594
Validation loss: 1.7967318104159447

Epoch: 5| Step: 3
Training loss: 0.3905971944332123
Validation loss: 1.822785594130075

Epoch: 5| Step: 4
Training loss: 0.4351709485054016
Validation loss: 1.8129108503300657

Epoch: 5| Step: 5
Training loss: 0.8314450979232788
Validation loss: 1.824773407751514

Epoch: 5| Step: 6
Training loss: 0.3070029616355896
Validation loss: 1.8494497204339633

Epoch: 5| Step: 7
Training loss: 0.7446640133857727
Validation loss: 1.8304598433997041

Epoch: 5| Step: 8
Training loss: 0.12231095880270004
Validation loss: 1.8238580278171006

Epoch: 5| Step: 9
Training loss: 0.37908655405044556
Validation loss: 1.7802435928775417

Epoch: 5| Step: 10
Training loss: 0.2992801070213318
Validation loss: 1.796657867329095

Epoch: 258| Step: 0
Training loss: 0.29616573452949524
Validation loss: 1.7909778241188294

Epoch: 5| Step: 1
Training loss: 0.6517285108566284
Validation loss: 1.7495972110379128

Epoch: 5| Step: 2
Training loss: 0.2799093723297119
Validation loss: 1.7596204191125848

Epoch: 5| Step: 3
Training loss: 0.44251155853271484
Validation loss: 1.7745003302892048

Epoch: 5| Step: 4
Training loss: 0.5190253257751465
Validation loss: 1.7833664891540364

Epoch: 5| Step: 5
Training loss: 0.3214806914329529
Validation loss: 1.754631943600152

Epoch: 5| Step: 6
Training loss: 0.3732943534851074
Validation loss: 1.770192571865615

Epoch: 5| Step: 7
Training loss: 0.3352496027946472
Validation loss: 1.7708832204982798

Epoch: 5| Step: 8
Training loss: 0.368208110332489
Validation loss: 1.7500094662430465

Epoch: 5| Step: 9
Training loss: 0.35562193393707275
Validation loss: 1.7943571472680697

Epoch: 5| Step: 10
Training loss: 0.6275826692581177
Validation loss: 1.7599751641673427

Epoch: 259| Step: 0
Training loss: 0.3389340043067932
Validation loss: 1.802625935564759

Epoch: 5| Step: 1
Training loss: 0.3549966812133789
Validation loss: 1.7518456648754817

Epoch: 5| Step: 2
Training loss: 0.5067859292030334
Validation loss: 1.7729666117698915

Epoch: 5| Step: 3
Training loss: 0.6035305261611938
Validation loss: 1.7757391955262871

Epoch: 5| Step: 4
Training loss: 0.42752233147621155
Validation loss: 1.7513081309615925

Epoch: 5| Step: 5
Training loss: 0.6039716005325317
Validation loss: 1.753032571525984

Epoch: 5| Step: 6
Training loss: 0.4005976617336273
Validation loss: 1.7382259086896015

Epoch: 5| Step: 7
Training loss: 0.3012845516204834
Validation loss: 1.728813390577993

Epoch: 5| Step: 8
Training loss: 0.3378053307533264
Validation loss: 1.7233303182868547

Epoch: 5| Step: 9
Training loss: 0.2937830984592438
Validation loss: 1.7466766552258564

Epoch: 5| Step: 10
Training loss: 0.1257960945367813
Validation loss: 1.7481063976082751

Epoch: 260| Step: 0
Training loss: 0.3902604579925537
Validation loss: 1.7851333233617968

Epoch: 5| Step: 1
Training loss: 0.24881534278392792
Validation loss: 1.7944844820166146

Epoch: 5| Step: 2
Training loss: 0.45361265540122986
Validation loss: 1.8621074973895986

Epoch: 5| Step: 3
Training loss: 0.3086155951023102
Validation loss: 1.8666538705107987

Epoch: 5| Step: 4
Training loss: 0.6645466089248657
Validation loss: 1.8529068231582642

Epoch: 5| Step: 5
Training loss: 0.5622302293777466
Validation loss: 1.7996543325403684

Epoch: 5| Step: 6
Training loss: 0.3988071382045746
Validation loss: 1.7664297678137337

Epoch: 5| Step: 7
Training loss: 0.3896600604057312
Validation loss: 1.710176888332572

Epoch: 5| Step: 8
Training loss: 0.42910251021385193
Validation loss: 1.694219304669288

Epoch: 5| Step: 9
Training loss: 0.3199964463710785
Validation loss: 1.690204301188069

Epoch: 5| Step: 10
Training loss: 0.563691258430481
Validation loss: 1.6641779035650275

Epoch: 261| Step: 0
Training loss: 0.5159180760383606
Validation loss: 1.6613186303005423

Epoch: 5| Step: 1
Training loss: 0.3496311902999878
Validation loss: 1.7196372068056496

Epoch: 5| Step: 2
Training loss: 0.6780243515968323
Validation loss: 1.7332007269705496

Epoch: 5| Step: 3
Training loss: 0.34949707984924316
Validation loss: 1.7719114185661398

Epoch: 5| Step: 4
Training loss: 0.2142733633518219
Validation loss: 1.8340068696647562

Epoch: 5| Step: 5
Training loss: 0.42823487520217896
Validation loss: 1.867172948775753

Epoch: 5| Step: 6
Training loss: 0.40591591596603394
Validation loss: 1.939583105425681

Epoch: 5| Step: 7
Training loss: 0.4230981767177582
Validation loss: 1.9817067089901175

Epoch: 5| Step: 8
Training loss: 0.39465898275375366
Validation loss: 1.9296068901656775

Epoch: 5| Step: 9
Training loss: 0.5441392064094543
Validation loss: 1.9034845213736258

Epoch: 5| Step: 10
Training loss: 0.5158932209014893
Validation loss: 1.8302609894865303

Epoch: 262| Step: 0
Training loss: 0.48111170530319214
Validation loss: 1.8024713377798758

Epoch: 5| Step: 1
Training loss: 0.5952717065811157
Validation loss: 1.7613321799103931

Epoch: 5| Step: 2
Training loss: 0.9870492815971375
Validation loss: 1.7847990938412246

Epoch: 5| Step: 3
Training loss: 0.31844696402549744
Validation loss: 1.7465225599145378

Epoch: 5| Step: 4
Training loss: 0.40252524614334106
Validation loss: 1.774652568242883

Epoch: 5| Step: 5
Training loss: 0.4775848388671875
Validation loss: 1.7292153784023818

Epoch: 5| Step: 6
Training loss: 0.5162562131881714
Validation loss: 1.7692158875926849

Epoch: 5| Step: 7
Training loss: 0.5193409323692322
Validation loss: 1.7345010554918678

Epoch: 5| Step: 8
Training loss: 0.2815414071083069
Validation loss: 1.7587897111010808

Epoch: 5| Step: 9
Training loss: 0.31602340936660767
Validation loss: 1.8024975676690378

Epoch: 5| Step: 10
Training loss: 0.4416603446006775
Validation loss: 1.7912033539946361

Epoch: 263| Step: 0
Training loss: 0.3711349368095398
Validation loss: 1.7985605373177478

Epoch: 5| Step: 1
Training loss: 0.41655057668685913
Validation loss: 1.7548154259240756

Epoch: 5| Step: 2
Training loss: 0.32830554246902466
Validation loss: 1.747104581966195

Epoch: 5| Step: 3
Training loss: 0.6130983829498291
Validation loss: 1.7781380171416907

Epoch: 5| Step: 4
Training loss: 0.23499110341072083
Validation loss: 1.7398574852174329

Epoch: 5| Step: 5
Training loss: 0.28198423981666565
Validation loss: 1.7566194252301288

Epoch: 5| Step: 6
Training loss: 0.4704301953315735
Validation loss: 1.771159379712997

Epoch: 5| Step: 7
Training loss: 0.22041699290275574
Validation loss: 1.7631912359627344

Epoch: 5| Step: 8
Training loss: 0.2186238318681717
Validation loss: 1.8144992372041107

Epoch: 5| Step: 9
Training loss: 0.6485884189605713
Validation loss: 1.8162007024211269

Epoch: 5| Step: 10
Training loss: 0.5468018651008606
Validation loss: 1.8478757309657272

Epoch: 264| Step: 0
Training loss: 0.36541253328323364
Validation loss: 1.8306014922357374

Epoch: 5| Step: 1
Training loss: 0.3948444724082947
Validation loss: 1.8169050460220666

Epoch: 5| Step: 2
Training loss: 0.4935981333255768
Validation loss: 1.8428823332632742

Epoch: 5| Step: 3
Training loss: 0.4430662989616394
Validation loss: 1.8355609806635047

Epoch: 5| Step: 4
Training loss: 0.6230254173278809
Validation loss: 1.8189298709233601

Epoch: 5| Step: 5
Training loss: 0.3656071722507477
Validation loss: 1.8025417981609222

Epoch: 5| Step: 6
Training loss: 0.3197597563266754
Validation loss: 1.7845619109369093

Epoch: 5| Step: 7
Training loss: 0.38761839270591736
Validation loss: 1.760701084649691

Epoch: 5| Step: 8
Training loss: 0.4231368899345398
Validation loss: 1.7506418407604258

Epoch: 5| Step: 9
Training loss: 0.23430661857128143
Validation loss: 1.749028891645452

Epoch: 5| Step: 10
Training loss: 0.3165058195590973
Validation loss: 1.7324725620208248

Epoch: 265| Step: 0
Training loss: 0.5194507837295532
Validation loss: 1.7692485752926077

Epoch: 5| Step: 1
Training loss: 0.24867916107177734
Validation loss: 1.7385906839883456

Epoch: 5| Step: 2
Training loss: 0.3543071746826172
Validation loss: 1.7889594672828593

Epoch: 5| Step: 3
Training loss: 0.527058482170105
Validation loss: 1.8297506929725729

Epoch: 5| Step: 4
Training loss: 0.5004220008850098
Validation loss: 1.8833899523622246

Epoch: 5| Step: 5
Training loss: 0.47347840666770935
Validation loss: 1.8524150258751326

Epoch: 5| Step: 6
Training loss: 0.5709673166275024
Validation loss: 1.859509639842536

Epoch: 5| Step: 7
Training loss: 0.1870851218700409
Validation loss: 1.8120197890907206

Epoch: 5| Step: 8
Training loss: 0.2657611668109894
Validation loss: 1.764194957671627

Epoch: 5| Step: 9
Training loss: 0.6152516603469849
Validation loss: 1.7508583709757815

Epoch: 5| Step: 10
Training loss: 0.16141895949840546
Validation loss: 1.7016553340419647

Epoch: 266| Step: 0
Training loss: 0.475394070148468
Validation loss: 1.6924215619282057

Epoch: 5| Step: 1
Training loss: 0.2386365383863449
Validation loss: 1.670860735318994

Epoch: 5| Step: 2
Training loss: 0.45704489946365356
Validation loss: 1.6599501896929998

Epoch: 5| Step: 3
Training loss: 0.28346237540245056
Validation loss: 1.6626573083221272

Epoch: 5| Step: 4
Training loss: 0.3585531711578369
Validation loss: 1.6916995990660884

Epoch: 5| Step: 5
Training loss: 0.439492404460907
Validation loss: 1.7397716635016984

Epoch: 5| Step: 6
Training loss: 0.657467246055603
Validation loss: 1.7768409508530811

Epoch: 5| Step: 7
Training loss: 0.32199913263320923
Validation loss: 1.8162279180301133

Epoch: 5| Step: 8
Training loss: 0.3329198956489563
Validation loss: 1.8620424757721603

Epoch: 5| Step: 9
Training loss: 0.2823914885520935
Validation loss: 1.9008965825521817

Epoch: 5| Step: 10
Training loss: 0.4435901641845703
Validation loss: 1.8829137791869461

Epoch: 267| Step: 0
Training loss: 0.47063326835632324
Validation loss: 1.8621408913725166

Epoch: 5| Step: 1
Training loss: 0.302048921585083
Validation loss: 1.859336087780614

Epoch: 5| Step: 2
Training loss: 0.6434727907180786
Validation loss: 1.8527675367170764

Epoch: 5| Step: 3
Training loss: 0.31475943326950073
Validation loss: 1.8156164628203197

Epoch: 5| Step: 4
Training loss: 0.3579227328300476
Validation loss: 1.761691540800115

Epoch: 5| Step: 5
Training loss: 0.3367551267147064
Validation loss: 1.7297440267378283

Epoch: 5| Step: 6
Training loss: 0.6301414966583252
Validation loss: 1.6876191003348238

Epoch: 5| Step: 7
Training loss: 0.1980867087841034
Validation loss: 1.6715098004187308

Epoch: 5| Step: 8
Training loss: 0.3913949728012085
Validation loss: 1.6693834617573728

Epoch: 5| Step: 9
Training loss: 0.353657066822052
Validation loss: 1.7117106286428307

Epoch: 5| Step: 10
Training loss: 0.3295687437057495
Validation loss: 1.748443979088978

Epoch: 268| Step: 0
Training loss: 0.39012986421585083
Validation loss: 1.7571820097584878

Epoch: 5| Step: 1
Training loss: 0.47059351205825806
Validation loss: 1.7690588530673776

Epoch: 5| Step: 2
Training loss: 0.24147455394268036
Validation loss: 1.7817009956605974

Epoch: 5| Step: 3
Training loss: 0.2859383821487427
Validation loss: 1.8025992173020557

Epoch: 5| Step: 4
Training loss: 0.4016367793083191
Validation loss: 1.8208948822431668

Epoch: 5| Step: 5
Training loss: 0.5278757214546204
Validation loss: 1.842528417546262

Epoch: 5| Step: 6
Training loss: 0.2572968602180481
Validation loss: 1.8460120501056794

Epoch: 5| Step: 7
Training loss: 0.40248575806617737
Validation loss: 1.8356454449315225

Epoch: 5| Step: 8
Training loss: 0.4518349766731262
Validation loss: 1.8445785558351906

Epoch: 5| Step: 9
Training loss: 0.6190832853317261
Validation loss: 1.8423782497323968

Epoch: 5| Step: 10
Training loss: 0.38325709104537964
Validation loss: 1.8104133811048282

Epoch: 269| Step: 0
Training loss: 0.3895626962184906
Validation loss: 1.7960726471357449

Epoch: 5| Step: 1
Training loss: 0.37978890538215637
Validation loss: 1.7728378452280515

Epoch: 5| Step: 2
Training loss: 0.41801437735557556
Validation loss: 1.7549954447695004

Epoch: 5| Step: 3
Training loss: 0.5062943696975708
Validation loss: 1.7214602155070151

Epoch: 5| Step: 4
Training loss: 0.4518582820892334
Validation loss: 1.7210085802180792

Epoch: 5| Step: 5
Training loss: 0.3077930808067322
Validation loss: 1.6910383880779307

Epoch: 5| Step: 6
Training loss: 0.2854391932487488
Validation loss: 1.6701962601753972

Epoch: 5| Step: 7
Training loss: 0.4240776598453522
Validation loss: 1.7137759116388136

Epoch: 5| Step: 8
Training loss: 0.3358895480632782
Validation loss: 1.715230632212854

Epoch: 5| Step: 9
Training loss: 0.42587870359420776
Validation loss: 1.7335851705202492

Epoch: 5| Step: 10
Training loss: 0.43759703636169434
Validation loss: 1.7462382713953655

Epoch: 270| Step: 0
Training loss: 0.555073618888855
Validation loss: 1.7923531609196817

Epoch: 5| Step: 1
Training loss: 0.44879788160324097
Validation loss: 1.8124023637463968

Epoch: 5| Step: 2
Training loss: 0.6041591763496399
Validation loss: 1.8682078161547262

Epoch: 5| Step: 3
Training loss: 0.2455645501613617
Validation loss: 1.8520185139871412

Epoch: 5| Step: 4
Training loss: 0.378186970949173
Validation loss: 1.8115523502390871

Epoch: 5| Step: 5
Training loss: 0.30954763293266296
Validation loss: 1.7689680284069431

Epoch: 5| Step: 6
Training loss: 0.2213635891675949
Validation loss: 1.7479294294952064

Epoch: 5| Step: 7
Training loss: 0.39572176337242126
Validation loss: 1.7478797461396904

Epoch: 5| Step: 8
Training loss: 0.5952126979827881
Validation loss: 1.6971653917784333

Epoch: 5| Step: 9
Training loss: 0.22870421409606934
Validation loss: 1.7290440631169144

Epoch: 5| Step: 10
Training loss: 0.30593356490135193
Validation loss: 1.7141819461699455

Epoch: 271| Step: 0
Training loss: 0.36450374126434326
Validation loss: 1.7274719592063659

Epoch: 5| Step: 1
Training loss: 0.363478422164917
Validation loss: 1.748251147167657

Epoch: 5| Step: 2
Training loss: 0.19033026695251465
Validation loss: 1.7057251430326892

Epoch: 5| Step: 3
Training loss: 0.36559563875198364
Validation loss: 1.7384762123066893

Epoch: 5| Step: 4
Training loss: 0.37374502420425415
Validation loss: 1.7341315643761748

Epoch: 5| Step: 5
Training loss: 0.32183197140693665
Validation loss: 1.7842577029299993

Epoch: 5| Step: 6
Training loss: 0.3262176513671875
Validation loss: 1.8210739410051735

Epoch: 5| Step: 7
Training loss: 0.7674174904823303
Validation loss: 1.8281130893256075

Epoch: 5| Step: 8
Training loss: 0.3485082983970642
Validation loss: 1.8026338610597836

Epoch: 5| Step: 9
Training loss: 0.2656915485858917
Validation loss: 1.7856469743995256

Epoch: 5| Step: 10
Training loss: 0.42024168372154236
Validation loss: 1.7583653068029752

Epoch: 272| Step: 0
Training loss: 0.2550836503505707
Validation loss: 1.7271246461458103

Epoch: 5| Step: 1
Training loss: 0.5390504002571106
Validation loss: 1.7138552601619432

Epoch: 5| Step: 2
Training loss: 0.3453447222709656
Validation loss: 1.6767824337046633

Epoch: 5| Step: 3
Training loss: 0.4007849097251892
Validation loss: 1.6684487891453568

Epoch: 5| Step: 4
Training loss: 0.2451639175415039
Validation loss: 1.6830350532326648

Epoch: 5| Step: 5
Training loss: 0.23258653283119202
Validation loss: 1.6743659575780232

Epoch: 5| Step: 6
Training loss: 0.36825689673423767
Validation loss: 1.678429731758692

Epoch: 5| Step: 7
Training loss: 0.3552555739879608
Validation loss: 1.7443989310213315

Epoch: 5| Step: 8
Training loss: 0.5373504161834717
Validation loss: 1.7603643812159055

Epoch: 5| Step: 9
Training loss: 0.49385252594947815
Validation loss: 1.7801962706350511

Epoch: 5| Step: 10
Training loss: 0.2334173023700714
Validation loss: 1.7942778141267839

Epoch: 273| Step: 0
Training loss: 0.37415528297424316
Validation loss: 1.796595554197988

Epoch: 5| Step: 1
Training loss: 0.2459416389465332
Validation loss: 1.821295835638559

Epoch: 5| Step: 2
Training loss: 0.4118165969848633
Validation loss: 1.8350422792537238

Epoch: 5| Step: 3
Training loss: 0.2966086268424988
Validation loss: 1.7887424204939155

Epoch: 5| Step: 4
Training loss: 0.29556989669799805
Validation loss: 1.7634828257304367

Epoch: 5| Step: 5
Training loss: 0.24092957377433777
Validation loss: 1.756770900500718

Epoch: 5| Step: 6
Training loss: 0.6161180138587952
Validation loss: 1.7177192177823795

Epoch: 5| Step: 7
Training loss: 0.2899664342403412
Validation loss: 1.7382095052349953

Epoch: 5| Step: 8
Training loss: 0.3478702902793884
Validation loss: 1.7224170648923485

Epoch: 5| Step: 9
Training loss: 0.3178468346595764
Validation loss: 1.6908271966441986

Epoch: 5| Step: 10
Training loss: 0.5085413455963135
Validation loss: 1.7352518753338886

Epoch: 274| Step: 0
Training loss: 0.35922178626060486
Validation loss: 1.745947120010212

Epoch: 5| Step: 1
Training loss: 0.24864082038402557
Validation loss: 1.7932701187749063

Epoch: 5| Step: 2
Training loss: 0.32855671644210815
Validation loss: 1.825188438097636

Epoch: 5| Step: 3
Training loss: 0.530232310295105
Validation loss: 1.7960848987743419

Epoch: 5| Step: 4
Training loss: 0.44469958543777466
Validation loss: 1.8297080673197264

Epoch: 5| Step: 5
Training loss: 0.40828990936279297
Validation loss: 1.8474875816734888

Epoch: 5| Step: 6
Training loss: 0.2951560914516449
Validation loss: 1.7750885653239425

Epoch: 5| Step: 7
Training loss: 0.3221754729747772
Validation loss: 1.749769426161243

Epoch: 5| Step: 8
Training loss: 0.2955586314201355
Validation loss: 1.7451583839231921

Epoch: 5| Step: 9
Training loss: 0.37286117672920227
Validation loss: 1.722116365227648

Epoch: 5| Step: 10
Training loss: 0.5898957848548889
Validation loss: 1.7263047387523036

Epoch: 275| Step: 0
Training loss: 0.25767964124679565
Validation loss: 1.6569940684944071

Epoch: 5| Step: 1
Training loss: 0.46081414818763733
Validation loss: 1.687482472388975

Epoch: 5| Step: 2
Training loss: 0.2096865177154541
Validation loss: 1.679927610581921

Epoch: 5| Step: 3
Training loss: 0.3495508134365082
Validation loss: 1.69583256911206

Epoch: 5| Step: 4
Training loss: 0.3560869097709656
Validation loss: 1.7181775775007022

Epoch: 5| Step: 5
Training loss: 0.6143901944160461
Validation loss: 1.726737250563919

Epoch: 5| Step: 6
Training loss: 0.32026609778404236
Validation loss: 1.7117220304345573

Epoch: 5| Step: 7
Training loss: 0.45002323389053345
Validation loss: 1.7104122356701923

Epoch: 5| Step: 8
Training loss: 0.3262903690338135
Validation loss: 1.7190300905576317

Epoch: 5| Step: 9
Training loss: 0.4109729826450348
Validation loss: 1.722315893378309

Epoch: 5| Step: 10
Training loss: 0.3163796067237854
Validation loss: 1.7637610076576151

Epoch: 276| Step: 0
Training loss: 0.6369613409042358
Validation loss: 1.741485627748633

Epoch: 5| Step: 1
Training loss: 0.2990363538265228
Validation loss: 1.745273752879071

Epoch: 5| Step: 2
Training loss: 0.4204544425010681
Validation loss: 1.7297553721294607

Epoch: 5| Step: 3
Training loss: 0.38459405303001404
Validation loss: 1.7282006330387567

Epoch: 5| Step: 4
Training loss: 0.4113261103630066
Validation loss: 1.7445972734881985

Epoch: 5| Step: 5
Training loss: 0.3523027002811432
Validation loss: 1.722090046892884

Epoch: 5| Step: 6
Training loss: 0.22549960017204285
Validation loss: 1.7188322480006883

Epoch: 5| Step: 7
Training loss: 0.34868741035461426
Validation loss: 1.7066965744059572

Epoch: 5| Step: 8
Training loss: 0.25459179282188416
Validation loss: 1.7191488255736649

Epoch: 5| Step: 9
Training loss: 0.3284780979156494
Validation loss: 1.7529081144640524

Epoch: 5| Step: 10
Training loss: 0.5571760535240173
Validation loss: 1.757190050617341

Epoch: 277| Step: 0
Training loss: 0.44654208421707153
Validation loss: 1.7604753099462038

Epoch: 5| Step: 1
Training loss: 0.45341578125953674
Validation loss: 1.7323756711457365

Epoch: 5| Step: 2
Training loss: 0.27204254269599915
Validation loss: 1.6776785068614508

Epoch: 5| Step: 3
Training loss: 0.29481497406959534
Validation loss: 1.6735929173807944

Epoch: 5| Step: 4
Training loss: 0.4355860650539398
Validation loss: 1.641796697852432

Epoch: 5| Step: 5
Training loss: 0.30386561155319214
Validation loss: 1.6469125183679725

Epoch: 5| Step: 6
Training loss: 0.28266066312789917
Validation loss: 1.6419786445556148

Epoch: 5| Step: 7
Training loss: 0.5845704674720764
Validation loss: 1.6563455661137898

Epoch: 5| Step: 8
Training loss: 0.331608384847641
Validation loss: 1.6742238024229645

Epoch: 5| Step: 9
Training loss: 0.32114315032958984
Validation loss: 1.6696808068983016

Epoch: 5| Step: 10
Training loss: 0.3999820053577423
Validation loss: 1.6751194859063754

Epoch: 278| Step: 0
Training loss: 0.5528673529624939
Validation loss: 1.7300005856380667

Epoch: 5| Step: 1
Training loss: 0.19152195751667023
Validation loss: 1.7219446243778351

Epoch: 5| Step: 2
Training loss: 0.2620527148246765
Validation loss: 1.761920630290944

Epoch: 5| Step: 3
Training loss: 0.5495977401733398
Validation loss: 1.7570720231661232

Epoch: 5| Step: 4
Training loss: 0.14550058543682098
Validation loss: 1.745281425855493

Epoch: 5| Step: 5
Training loss: 0.3345891833305359
Validation loss: 1.742948015530904

Epoch: 5| Step: 6
Training loss: 0.5613612532615662
Validation loss: 1.7508679128462268

Epoch: 5| Step: 7
Training loss: 0.24155473709106445
Validation loss: 1.722219301808265

Epoch: 5| Step: 8
Training loss: 0.2802453339099884
Validation loss: 1.7182143413892357

Epoch: 5| Step: 9
Training loss: 0.3513612151145935
Validation loss: 1.7208477233045845

Epoch: 5| Step: 10
Training loss: 0.2640026807785034
Validation loss: 1.6871292142457859

Epoch: 279| Step: 0
Training loss: 0.5234318971633911
Validation loss: 1.6739018168500674

Epoch: 5| Step: 1
Training loss: 0.20908451080322266
Validation loss: 1.67910260282537

Epoch: 5| Step: 2
Training loss: 0.3309337794780731
Validation loss: 1.6824901565428703

Epoch: 5| Step: 3
Training loss: 0.3206217885017395
Validation loss: 1.701706091562907

Epoch: 5| Step: 4
Training loss: 0.37710365653038025
Validation loss: 1.683683164658085

Epoch: 5| Step: 5
Training loss: 0.34415683150291443
Validation loss: 1.6816752097939933

Epoch: 5| Step: 6
Training loss: 0.30517715215682983
Validation loss: 1.746977675345636

Epoch: 5| Step: 7
Training loss: 0.4222700595855713
Validation loss: 1.7880488557200278

Epoch: 5| Step: 8
Training loss: 0.30686336755752563
Validation loss: 1.7917442014140468

Epoch: 5| Step: 9
Training loss: 0.3165002763271332
Validation loss: 1.806570477383111

Epoch: 5| Step: 10
Training loss: 0.20761236548423767
Validation loss: 1.8002571469994002

Epoch: 280| Step: 0
Training loss: 0.2054176777601242
Validation loss: 1.790505611768333

Epoch: 5| Step: 1
Training loss: 0.37344983220100403
Validation loss: 1.751637351128363

Epoch: 5| Step: 2
Training loss: 0.4051681160926819
Validation loss: 1.7451915881967033

Epoch: 5| Step: 3
Training loss: 0.24529309570789337
Validation loss: 1.7148604162277714

Epoch: 5| Step: 4
Training loss: 0.1726786494255066
Validation loss: 1.691066716306953

Epoch: 5| Step: 5
Training loss: 0.3057878017425537
Validation loss: 1.7149774156590945

Epoch: 5| Step: 6
Training loss: 0.32911473512649536
Validation loss: 1.6571627970664733

Epoch: 5| Step: 7
Training loss: 0.3712611198425293
Validation loss: 1.6957871349908973

Epoch: 5| Step: 8
Training loss: 0.5729984641075134
Validation loss: 1.6681376426450667

Epoch: 5| Step: 9
Training loss: 0.22323545813560486
Validation loss: 1.7029069123729583

Epoch: 5| Step: 10
Training loss: 0.4144829511642456
Validation loss: 1.662367779721496

Epoch: 281| Step: 0
Training loss: 0.5723496675491333
Validation loss: 1.684003512064616

Epoch: 5| Step: 1
Training loss: 0.4155154824256897
Validation loss: 1.6938241156198646

Epoch: 5| Step: 2
Training loss: 0.3389538824558258
Validation loss: 1.7095885686976935

Epoch: 5| Step: 3
Training loss: 0.13015024363994598
Validation loss: 1.7306241194407146

Epoch: 5| Step: 4
Training loss: 0.20674780011177063
Validation loss: 1.7763043642044067

Epoch: 5| Step: 5
Training loss: 0.25517287850379944
Validation loss: 1.7842928478794713

Epoch: 5| Step: 6
Training loss: 0.2790924608707428
Validation loss: 1.794049318118762

Epoch: 5| Step: 7
Training loss: 0.2936297655105591
Validation loss: 1.773889983853986

Epoch: 5| Step: 8
Training loss: 0.38849493861198425
Validation loss: 1.7711844777548185

Epoch: 5| Step: 9
Training loss: 0.3204614520072937
Validation loss: 1.802226786972374

Epoch: 5| Step: 10
Training loss: 0.2806485891342163
Validation loss: 1.7678303564748457

Epoch: 282| Step: 0
Training loss: 0.1555076539516449
Validation loss: 1.7130750661255212

Epoch: 5| Step: 1
Training loss: 0.48737984895706177
Validation loss: 1.727933181229458

Epoch: 5| Step: 2
Training loss: 0.4099583029747009
Validation loss: 1.7122411330540974

Epoch: 5| Step: 3
Training loss: 0.3367769718170166
Validation loss: 1.685506941169821

Epoch: 5| Step: 4
Training loss: 0.39504021406173706
Validation loss: 1.7018153834086593

Epoch: 5| Step: 5
Training loss: 0.25867992639541626
Validation loss: 1.6723231448922107

Epoch: 5| Step: 6
Training loss: 0.30183887481689453
Validation loss: 1.741372872424382

Epoch: 5| Step: 7
Training loss: 0.41027626395225525
Validation loss: 1.6935348895288282

Epoch: 5| Step: 8
Training loss: 0.29141512513160706
Validation loss: 1.7250399717720606

Epoch: 5| Step: 9
Training loss: 0.2744561433792114
Validation loss: 1.7616668837044829

Epoch: 5| Step: 10
Training loss: 0.1894049495458603
Validation loss: 1.7496083526201145

Epoch: 283| Step: 0
Training loss: 0.34948891401290894
Validation loss: 1.757453744129468

Epoch: 5| Step: 1
Training loss: 0.18073923885822296
Validation loss: 1.7943281589015838

Epoch: 5| Step: 2
Training loss: 0.36707231402397156
Validation loss: 1.8035752824557725

Epoch: 5| Step: 3
Training loss: 0.3305927515029907
Validation loss: 1.8389171861833142

Epoch: 5| Step: 4
Training loss: 0.36795392632484436
Validation loss: 1.7896577414645944

Epoch: 5| Step: 5
Training loss: 0.30258363485336304
Validation loss: 1.8198908503337572

Epoch: 5| Step: 6
Training loss: 0.30960890650749207
Validation loss: 1.7632388812239452

Epoch: 5| Step: 7
Training loss: 0.35912200808525085
Validation loss: 1.7685373367801789

Epoch: 5| Step: 8
Training loss: 0.6254045367240906
Validation loss: 1.7360624574845838

Epoch: 5| Step: 9
Training loss: 0.12507693469524384
Validation loss: 1.7821872900891047

Epoch: 5| Step: 10
Training loss: 0.17253530025482178
Validation loss: 1.7466716381811327

Epoch: 284| Step: 0
Training loss: 0.19405660033226013
Validation loss: 1.7020809817057785

Epoch: 5| Step: 1
Training loss: 0.24984049797058105
Validation loss: 1.7062685861382434

Epoch: 5| Step: 2
Training loss: 0.25319918990135193
Validation loss: 1.6849365811194144

Epoch: 5| Step: 3
Training loss: 0.3086835443973541
Validation loss: 1.6878153765073387

Epoch: 5| Step: 4
Training loss: 0.5474996566772461
Validation loss: 1.7019368448565084

Epoch: 5| Step: 5
Training loss: 0.17367136478424072
Validation loss: 1.7058627490074403

Epoch: 5| Step: 6
Training loss: 0.3108019530773163
Validation loss: 1.7149701349196895

Epoch: 5| Step: 7
Training loss: 0.34063756465911865
Validation loss: 1.7307146646643197

Epoch: 5| Step: 8
Training loss: 0.49131983518600464
Validation loss: 1.7372365677228538

Epoch: 5| Step: 9
Training loss: 0.15816877782344818
Validation loss: 1.7678985749521563

Epoch: 5| Step: 10
Training loss: 0.40056705474853516
Validation loss: 1.7557762489523938

Epoch: 285| Step: 0
Training loss: 0.2952865660190582
Validation loss: 1.7813096520721272

Epoch: 5| Step: 1
Training loss: 0.3266994059085846
Validation loss: 1.7786968138910109

Epoch: 5| Step: 2
Training loss: 0.46447521448135376
Validation loss: 1.7662879741320046

Epoch: 5| Step: 3
Training loss: 0.2915707528591156
Validation loss: 1.7503733423448378

Epoch: 5| Step: 4
Training loss: 0.17671099305152893
Validation loss: 1.7887441573604461

Epoch: 5| Step: 5
Training loss: 0.49165767431259155
Validation loss: 1.7597030298684233

Epoch: 5| Step: 6
Training loss: 0.26963314414024353
Validation loss: 1.7632717086422829

Epoch: 5| Step: 7
Training loss: 0.3849261403083801
Validation loss: 1.7480471262367823

Epoch: 5| Step: 8
Training loss: 0.17921769618988037
Validation loss: 1.7406536186895063

Epoch: 5| Step: 9
Training loss: 0.23790618777275085
Validation loss: 1.7617778226893435

Epoch: 5| Step: 10
Training loss: 0.31951263546943665
Validation loss: 1.7441539431131015

Epoch: 286| Step: 0
Training loss: 0.314338356256485
Validation loss: 1.7542246157123196

Epoch: 5| Step: 1
Training loss: 0.2439534217119217
Validation loss: 1.7087753280516593

Epoch: 5| Step: 2
Training loss: 0.30927592515945435
Validation loss: 1.6938340458818661

Epoch: 5| Step: 3
Training loss: 0.24068066477775574
Validation loss: 1.7068911496029104

Epoch: 5| Step: 4
Training loss: 0.3896676301956177
Validation loss: 1.6856790973294167

Epoch: 5| Step: 5
Training loss: 0.597330629825592
Validation loss: 1.7070337585223618

Epoch: 5| Step: 6
Training loss: 0.11291687190532684
Validation loss: 1.7193527939499065

Epoch: 5| Step: 7
Training loss: 0.19023017585277557
Validation loss: 1.7278520471306258

Epoch: 5| Step: 8
Training loss: 0.4095277786254883
Validation loss: 1.782966491996601

Epoch: 5| Step: 9
Training loss: 0.2891753315925598
Validation loss: 1.773171861966451

Epoch: 5| Step: 10
Training loss: 0.3089362382888794
Validation loss: 1.7507542653750348

Epoch: 287| Step: 0
Training loss: 0.3022890090942383
Validation loss: 1.7151494731185257

Epoch: 5| Step: 1
Training loss: 0.2764340341091156
Validation loss: 1.7264332848210489

Epoch: 5| Step: 2
Training loss: 0.2509147524833679
Validation loss: 1.7235035268209313

Epoch: 5| Step: 3
Training loss: 0.3149975836277008
Validation loss: 1.6781087242146975

Epoch: 5| Step: 4
Training loss: 0.19547298550605774
Validation loss: 1.700595477575897

Epoch: 5| Step: 5
Training loss: 0.18971696496009827
Validation loss: 1.6762867448150471

Epoch: 5| Step: 6
Training loss: 0.5407317280769348
Validation loss: 1.6810153004943684

Epoch: 5| Step: 7
Training loss: 0.17493115365505219
Validation loss: 1.7071719502889982

Epoch: 5| Step: 8
Training loss: 0.3527300953865051
Validation loss: 1.71319701081963

Epoch: 5| Step: 9
Training loss: 0.2473960816860199
Validation loss: 1.7378992060179352

Epoch: 5| Step: 10
Training loss: 0.3782253861427307
Validation loss: 1.7160772521008727

Epoch: 288| Step: 0
Training loss: 0.35348981618881226
Validation loss: 1.7535966416840911

Epoch: 5| Step: 1
Training loss: 0.22116920351982117
Validation loss: 1.7154020109484274

Epoch: 5| Step: 2
Training loss: 0.3003771901130676
Validation loss: 1.6855084229541082

Epoch: 5| Step: 3
Training loss: 0.2940516769886017
Validation loss: 1.667848886982087

Epoch: 5| Step: 4
Training loss: 0.5882039070129395
Validation loss: 1.6756664040268108

Epoch: 5| Step: 5
Training loss: 0.4362102448940277
Validation loss: 1.6305209654633717

Epoch: 5| Step: 6
Training loss: 0.13233794271945953
Validation loss: 1.6402479833172214

Epoch: 5| Step: 7
Training loss: 0.29041868448257446
Validation loss: 1.6371929671174736

Epoch: 5| Step: 8
Training loss: 0.2694578766822815
Validation loss: 1.6307335463903283

Epoch: 5| Step: 9
Training loss: 0.2646889090538025
Validation loss: 1.6657784292774815

Epoch: 5| Step: 10
Training loss: 0.14575183391571045
Validation loss: 1.6852164960676623

Epoch: 289| Step: 0
Training loss: 0.29171115159988403
Validation loss: 1.7297857986983431

Epoch: 5| Step: 1
Training loss: 0.455538272857666
Validation loss: 1.7389382905857538

Epoch: 5| Step: 2
Training loss: 0.21343617141246796
Validation loss: 1.7222995706783828

Epoch: 5| Step: 3
Training loss: 0.2766682207584381
Validation loss: 1.733260646943123

Epoch: 5| Step: 4
Training loss: 0.48599734902381897
Validation loss: 1.6983317277764762

Epoch: 5| Step: 5
Training loss: 0.26026785373687744
Validation loss: 1.734149908506742

Epoch: 5| Step: 6
Training loss: 0.4444587826728821
Validation loss: 1.6928682429816133

Epoch: 5| Step: 7
Training loss: 0.3725615441799164
Validation loss: 1.6682536114928543

Epoch: 5| Step: 8
Training loss: 0.26371484994888306
Validation loss: 1.691074013710022

Epoch: 5| Step: 9
Training loss: 0.19402557611465454
Validation loss: 1.6846025413082493

Epoch: 5| Step: 10
Training loss: 0.17386925220489502
Validation loss: 1.6992558663891209

Epoch: 290| Step: 0
Training loss: 0.2957286536693573
Validation loss: 1.741416718370171

Epoch: 5| Step: 1
Training loss: 0.24657750129699707
Validation loss: 1.742246594480289

Epoch: 5| Step: 2
Training loss: 0.34059271216392517
Validation loss: 1.7226219843792658

Epoch: 5| Step: 3
Training loss: 0.255769282579422
Validation loss: 1.73382749865132

Epoch: 5| Step: 4
Training loss: 0.24310152232646942
Validation loss: 1.744236196241071

Epoch: 5| Step: 5
Training loss: 0.370567262172699
Validation loss: 1.7095894121354627

Epoch: 5| Step: 6
Training loss: 0.6898912191390991
Validation loss: 1.722937576232418

Epoch: 5| Step: 7
Training loss: 0.1293759047985077
Validation loss: 1.7328036139088292

Epoch: 5| Step: 8
Training loss: 0.2789522111415863
Validation loss: 1.7550545533498128

Epoch: 5| Step: 9
Training loss: 0.22718091309070587
Validation loss: 1.7188166533747027

Epoch: 5| Step: 10
Training loss: 0.41592660546302795
Validation loss: 1.7228054103030954

Epoch: 291| Step: 0
Training loss: 0.3494436740875244
Validation loss: 1.731310259911322

Epoch: 5| Step: 1
Training loss: 0.23522226512432098
Validation loss: 1.7093343862923243

Epoch: 5| Step: 2
Training loss: 0.3031376898288727
Validation loss: 1.7138677412463772

Epoch: 5| Step: 3
Training loss: 0.538027822971344
Validation loss: 1.7262368381664317

Epoch: 5| Step: 4
Training loss: 0.19790998101234436
Validation loss: 1.7116586969744774

Epoch: 5| Step: 5
Training loss: 0.41237372159957886
Validation loss: 1.689816375573476

Epoch: 5| Step: 6
Training loss: 0.2661275267601013
Validation loss: 1.698924328691216

Epoch: 5| Step: 7
Training loss: 0.29556748270988464
Validation loss: 1.6795557545077415

Epoch: 5| Step: 8
Training loss: 0.27572768926620483
Validation loss: 1.7009597952647875

Epoch: 5| Step: 9
Training loss: 0.1726851612329483
Validation loss: 1.6924747420895485

Epoch: 5| Step: 10
Training loss: 0.2544800639152527
Validation loss: 1.7155770768401444

Epoch: 292| Step: 0
Training loss: 0.33552199602127075
Validation loss: 1.7380143955189695

Epoch: 5| Step: 1
Training loss: 0.2332543134689331
Validation loss: 1.7123030347208823

Epoch: 5| Step: 2
Training loss: 0.2241591513156891
Validation loss: 1.741099488350653

Epoch: 5| Step: 3
Training loss: 0.26172298192977905
Validation loss: 1.7074321495589388

Epoch: 5| Step: 4
Training loss: 0.2147933542728424
Validation loss: 1.7492715735589304

Epoch: 5| Step: 5
Training loss: 0.2872914671897888
Validation loss: 1.7987339150521062

Epoch: 5| Step: 6
Training loss: 0.5527645349502563
Validation loss: 1.7779320183620657

Epoch: 5| Step: 7
Training loss: 0.37903571128845215
Validation loss: 1.8090737314634426

Epoch: 5| Step: 8
Training loss: 0.32218894362449646
Validation loss: 1.8080353557422597

Epoch: 5| Step: 9
Training loss: 0.30971041321754456
Validation loss: 1.8180117196934198

Epoch: 5| Step: 10
Training loss: 0.09495913237333298
Validation loss: 1.7972933271879792

Epoch: 293| Step: 0
Training loss: 0.09474648535251617
Validation loss: 1.7706731827028337

Epoch: 5| Step: 1
Training loss: 0.2623766362667084
Validation loss: 1.7052596487024778

Epoch: 5| Step: 2
Training loss: 0.278160959482193
Validation loss: 1.6857382148824713

Epoch: 5| Step: 3
Training loss: 0.6128479838371277
Validation loss: 1.68315222314609

Epoch: 5| Step: 4
Training loss: 0.2940738797187805
Validation loss: 1.6533171143583072

Epoch: 5| Step: 5
Training loss: 0.26230040192604065
Validation loss: 1.673623449058943

Epoch: 5| Step: 6
Training loss: 0.28844743967056274
Validation loss: 1.6830956243699597

Epoch: 5| Step: 7
Training loss: 0.3258614242076874
Validation loss: 1.700123692712476

Epoch: 5| Step: 8
Training loss: 0.36589428782463074
Validation loss: 1.7504884773685085

Epoch: 5| Step: 9
Training loss: 0.34908807277679443
Validation loss: 1.7396516056470974

Epoch: 5| Step: 10
Training loss: 0.13406804203987122
Validation loss: 1.7700321251346218

Epoch: 294| Step: 0
Training loss: 0.3154955506324768
Validation loss: 1.783483951322494

Epoch: 5| Step: 1
Training loss: 0.2736546993255615
Validation loss: 1.7970142210683515

Epoch: 5| Step: 2
Training loss: 0.23569747805595398
Validation loss: 1.8043014682749265

Epoch: 5| Step: 3
Training loss: 0.26202887296676636
Validation loss: 1.7577703537479523

Epoch: 5| Step: 4
Training loss: 0.23055820167064667
Validation loss: 1.7810007308119087

Epoch: 5| Step: 5
Training loss: 0.2409459352493286
Validation loss: 1.7682034725783973

Epoch: 5| Step: 6
Training loss: 0.38821879029273987
Validation loss: 1.7553582358103927

Epoch: 5| Step: 7
Training loss: 0.37542134523391724
Validation loss: 1.6975195728322512

Epoch: 5| Step: 8
Training loss: 0.5633351802825928
Validation loss: 1.6931359152640066

Epoch: 5| Step: 9
Training loss: 0.17426379024982452
Validation loss: 1.6957084517325125

Epoch: 5| Step: 10
Training loss: 0.2050199955701828
Validation loss: 1.6911089920228528

Epoch: 295| Step: 0
Training loss: 0.22763898968696594
Validation loss: 1.6662896435747865

Epoch: 5| Step: 1
Training loss: 0.4276590943336487
Validation loss: 1.7081348306389266

Epoch: 5| Step: 2
Training loss: 0.19041581451892853
Validation loss: 1.6755672859889206

Epoch: 5| Step: 3
Training loss: 0.5416754484176636
Validation loss: 1.7065366827031618

Epoch: 5| Step: 4
Training loss: 0.20619352161884308
Validation loss: 1.713607483012702

Epoch: 5| Step: 5
Training loss: 0.20041978359222412
Validation loss: 1.7060709743089573

Epoch: 5| Step: 6
Training loss: 0.3264974057674408
Validation loss: 1.687444922744587

Epoch: 5| Step: 7
Training loss: 0.3108108639717102
Validation loss: 1.7035857298040902

Epoch: 5| Step: 8
Training loss: 0.2546052932739258
Validation loss: 1.7404699581925587

Epoch: 5| Step: 9
Training loss: 0.20947591960430145
Validation loss: 1.76636383610387

Epoch: 5| Step: 10
Training loss: 0.293611079454422
Validation loss: 1.7962457108241257

Epoch: 296| Step: 0
Training loss: 0.18101616203784943
Validation loss: 1.8018572804748372

Epoch: 5| Step: 1
Training loss: 0.38562777638435364
Validation loss: 1.8272546337496849

Epoch: 5| Step: 2
Training loss: 0.2412085086107254
Validation loss: 1.8347504472219816

Epoch: 5| Step: 3
Training loss: 0.33524784445762634
Validation loss: 1.8065157898010746

Epoch: 5| Step: 4
Training loss: 0.32071176171302795
Validation loss: 1.7574165046855967

Epoch: 5| Step: 5
Training loss: 0.1741657853126526
Validation loss: 1.7562582851738058

Epoch: 5| Step: 6
Training loss: 0.23074555397033691
Validation loss: 1.6900618191688292

Epoch: 5| Step: 7
Training loss: 0.23664388060569763
Validation loss: 1.6621325092930948

Epoch: 5| Step: 8
Training loss: 0.19563694298267365
Validation loss: 1.633314750527823

Epoch: 5| Step: 9
Training loss: 0.8030694127082825
Validation loss: 1.6377139745220062

Epoch: 5| Step: 10
Training loss: 0.38243943452835083
Validation loss: 1.6328150841497606

Epoch: 297| Step: 0
Training loss: 0.3119424283504486
Validation loss: 1.6555914045662008

Epoch: 5| Step: 1
Training loss: 0.29585710167884827
Validation loss: 1.6847147762134511

Epoch: 5| Step: 2
Training loss: 0.2628611624240875
Validation loss: 1.6800883495679466

Epoch: 5| Step: 3
Training loss: 0.19328825175762177
Validation loss: 1.7201938923969065

Epoch: 5| Step: 4
Training loss: 0.32934197783470154
Validation loss: 1.7339692320874942

Epoch: 5| Step: 5
Training loss: 0.4401763081550598
Validation loss: 1.7277670573162776

Epoch: 5| Step: 6
Training loss: 0.21797220408916473
Validation loss: 1.7366355375577045

Epoch: 5| Step: 7
Training loss: 0.20792178809642792
Validation loss: 1.7304292186614005

Epoch: 5| Step: 8
Training loss: 0.29287996888160706
Validation loss: 1.7369538032880394

Epoch: 5| Step: 9
Training loss: 0.3651551902294159
Validation loss: 1.7884657652147355

Epoch: 5| Step: 10
Training loss: 0.5969871282577515
Validation loss: 1.7747767612498293

Epoch: 298| Step: 0
Training loss: 0.11640530824661255
Validation loss: 1.7715687444133144

Epoch: 5| Step: 1
Training loss: 0.17372533679008484
Validation loss: 1.774163721710123

Epoch: 5| Step: 2
Training loss: 0.3814743161201477
Validation loss: 1.736675452160579

Epoch: 5| Step: 3
Training loss: 0.43785524368286133
Validation loss: 1.7761889452575355

Epoch: 5| Step: 4
Training loss: 0.35155510902404785
Validation loss: 1.7649997588126891

Epoch: 5| Step: 5
Training loss: 0.30343136191368103
Validation loss: 1.7628964897125

Epoch: 5| Step: 6
Training loss: 0.14818106591701508
Validation loss: 1.7082036156808176

Epoch: 5| Step: 7
Training loss: 0.2841472029685974
Validation loss: 1.7029602835255284

Epoch: 5| Step: 8
Training loss: 0.5926245450973511
Validation loss: 1.699340025583903

Epoch: 5| Step: 9
Training loss: 0.3108721971511841
Validation loss: 1.6728481874671033

Epoch: 5| Step: 10
Training loss: 0.14121150970458984
Validation loss: 1.6322822660528205

Epoch: 299| Step: 0
Training loss: 0.20929980278015137
Validation loss: 1.6662217276070708

Epoch: 5| Step: 1
Training loss: 0.24769660830497742
Validation loss: 1.652107282351422

Epoch: 5| Step: 2
Training loss: 0.24626179039478302
Validation loss: 1.6607732183189803

Epoch: 5| Step: 3
Training loss: 0.15012042224407196
Validation loss: 1.6560213732463058

Epoch: 5| Step: 4
Training loss: 0.22369810938835144
Validation loss: 1.66571896050566

Epoch: 5| Step: 5
Training loss: 0.23579731583595276
Validation loss: 1.6881278843008063

Epoch: 5| Step: 6
Training loss: 0.5176340937614441
Validation loss: 1.6825367302022955

Epoch: 5| Step: 7
Training loss: 0.5976149439811707
Validation loss: 1.684133634772352

Epoch: 5| Step: 8
Training loss: 0.276203989982605
Validation loss: 1.692801134560698

Epoch: 5| Step: 9
Training loss: 0.26474350690841675
Validation loss: 1.7229783624731085

Epoch: 5| Step: 10
Training loss: 0.23782339692115784
Validation loss: 1.7186600956865536

Epoch: 300| Step: 0
Training loss: 0.26951301097869873
Validation loss: 1.7178780186560847

Epoch: 5| Step: 1
Training loss: 0.21586766839027405
Validation loss: 1.7216688022818616

Epoch: 5| Step: 2
Training loss: 0.3018987476825714
Validation loss: 1.7067901985619658

Epoch: 5| Step: 3
Training loss: 0.19585031270980835
Validation loss: 1.6714686116864603

Epoch: 5| Step: 4
Training loss: 0.24531444907188416
Validation loss: 1.7110634196189143

Epoch: 5| Step: 5
Training loss: 0.2646133303642273
Validation loss: 1.7203956265603342

Epoch: 5| Step: 6
Training loss: 0.337380051612854
Validation loss: 1.7126523269120084

Epoch: 5| Step: 7
Training loss: 0.4717465937137604
Validation loss: 1.6853571181656213

Epoch: 5| Step: 8
Training loss: 0.20692157745361328
Validation loss: 1.7138759513055124

Epoch: 5| Step: 9
Training loss: 0.34532803297042847
Validation loss: 1.713949054800054

Epoch: 5| Step: 10
Training loss: 0.2810765504837036
Validation loss: 1.6862349446101854

Epoch: 301| Step: 0
Training loss: 0.19662287831306458
Validation loss: 1.7073615520231185

Epoch: 5| Step: 1
Training loss: 0.23873749375343323
Validation loss: 1.7081943301744358

Epoch: 5| Step: 2
Training loss: 0.2871623933315277
Validation loss: 1.6889923849413473

Epoch: 5| Step: 3
Training loss: 0.4109322428703308
Validation loss: 1.7070121739500312

Epoch: 5| Step: 4
Training loss: 0.3610369563102722
Validation loss: 1.7067971127007597

Epoch: 5| Step: 5
Training loss: 0.13601115345954895
Validation loss: 1.6780622043917257

Epoch: 5| Step: 6
Training loss: 0.3271714150905609
Validation loss: 1.679312764957387

Epoch: 5| Step: 7
Training loss: 0.2095605581998825
Validation loss: 1.7127694981072539

Epoch: 5| Step: 8
Training loss: 0.27265292406082153
Validation loss: 1.7050291722820652

Epoch: 5| Step: 9
Training loss: 0.2531681954860687
Validation loss: 1.6781020331126388

Epoch: 5| Step: 10
Training loss: 0.3406316339969635
Validation loss: 1.7444579575651435

Epoch: 302| Step: 0
Training loss: 0.20320764183998108
Validation loss: 1.7419842955886677

Epoch: 5| Step: 1
Training loss: 0.3582432270050049
Validation loss: 1.7413271447663665

Epoch: 5| Step: 2
Training loss: 0.2857135236263275
Validation loss: 1.7435759895591325

Epoch: 5| Step: 3
Training loss: 0.2227543294429779
Validation loss: 1.7425927385207145

Epoch: 5| Step: 4
Training loss: 0.1877254694700241
Validation loss: 1.711821303572706

Epoch: 5| Step: 5
Training loss: 0.2304062843322754
Validation loss: 1.7527413855316818

Epoch: 5| Step: 6
Training loss: 0.4610973000526428
Validation loss: 1.7621599769079557

Epoch: 5| Step: 7
Training loss: 0.19999361038208008
Validation loss: 1.745687093786014

Epoch: 5| Step: 8
Training loss: 0.30092334747314453
Validation loss: 1.748423054654111

Epoch: 5| Step: 9
Training loss: 0.1668880730867386
Validation loss: 1.7505640663126463

Epoch: 5| Step: 10
Training loss: 0.2750077545642853
Validation loss: 1.733738168593376

Epoch: 303| Step: 0
Training loss: 0.36231595277786255
Validation loss: 1.7314094958766815

Epoch: 5| Step: 1
Training loss: 0.33904463052749634
Validation loss: 1.7295841337532125

Epoch: 5| Step: 2
Training loss: 0.23858468234539032
Validation loss: 1.7505078085007206

Epoch: 5| Step: 3
Training loss: 0.33728867769241333
Validation loss: 1.7652355381237563

Epoch: 5| Step: 4
Training loss: 0.2091652899980545
Validation loss: 1.7236800584741818

Epoch: 5| Step: 5
Training loss: 0.2031134068965912
Validation loss: 1.7678040894128944

Epoch: 5| Step: 6
Training loss: 0.2241954505443573
Validation loss: 1.748037674093759

Epoch: 5| Step: 7
Training loss: 0.1976209431886673
Validation loss: 1.7295554517417826

Epoch: 5| Step: 8
Training loss: 0.11770473420619965
Validation loss: 1.7716566606234478

Epoch: 5| Step: 9
Training loss: 0.5213345289230347
Validation loss: 1.7166789103579778

Epoch: 5| Step: 10
Training loss: 0.17635023593902588
Validation loss: 1.6867258484645555

Epoch: 304| Step: 0
Training loss: 0.5492291450500488
Validation loss: 1.651020755050003

Epoch: 5| Step: 1
Training loss: 0.23660466074943542
Validation loss: 1.6325556821720575

Epoch: 5| Step: 2
Training loss: 0.1657463014125824
Validation loss: 1.62670503124114

Epoch: 5| Step: 3
Training loss: 0.3318324387073517
Validation loss: 1.615780242027775

Epoch: 5| Step: 4
Training loss: 0.262439489364624
Validation loss: 1.6327664211232176

Epoch: 5| Step: 5
Training loss: 0.2592201232910156
Validation loss: 1.652394163993097

Epoch: 5| Step: 6
Training loss: 0.30046987533569336
Validation loss: 1.6571082709937968

Epoch: 5| Step: 7
Training loss: 0.24091586470603943
Validation loss: 1.6789788110281831

Epoch: 5| Step: 8
Training loss: 0.2097610980272293
Validation loss: 1.7100694384626163

Epoch: 5| Step: 9
Training loss: 0.17052939534187317
Validation loss: 1.7253122304075508

Epoch: 5| Step: 10
Training loss: 0.1964179426431656
Validation loss: 1.7238263917225662

Epoch: 305| Step: 0
Training loss: 0.23712170124053955
Validation loss: 1.776784639204702

Epoch: 5| Step: 1
Training loss: 0.16771827638149261
Validation loss: 1.7651394849182458

Epoch: 5| Step: 2
Training loss: 0.18709759414196014
Validation loss: 1.7873694806970575

Epoch: 5| Step: 3
Training loss: 0.29727938771247864
Validation loss: 1.7970046433069373

Epoch: 5| Step: 4
Training loss: 0.5310778617858887
Validation loss: 1.8096764369677472

Epoch: 5| Step: 5
Training loss: 0.11053452640771866
Validation loss: 1.7655184371497041

Epoch: 5| Step: 6
Training loss: 0.17177936434745789
Validation loss: 1.7542358534310454

Epoch: 5| Step: 7
Training loss: 0.27398577332496643
Validation loss: 1.7215191010505921

Epoch: 5| Step: 8
Training loss: 0.33725762367248535
Validation loss: 1.7146597344388244

Epoch: 5| Step: 9
Training loss: 0.3327654004096985
Validation loss: 1.6912922807919082

Epoch: 5| Step: 10
Training loss: 0.17162345349788666
Validation loss: 1.7011946375652025

Epoch: 306| Step: 0
Training loss: 0.2677029073238373
Validation loss: 1.6933253618978685

Epoch: 5| Step: 1
Training loss: 0.15202680230140686
Validation loss: 1.6854904261968469

Epoch: 5| Step: 2
Training loss: 0.4671909213066101
Validation loss: 1.7097896081145092

Epoch: 5| Step: 3
Training loss: 0.25424790382385254
Validation loss: 1.6797816740569247

Epoch: 5| Step: 4
Training loss: 0.23428797721862793
Validation loss: 1.7218389254744335

Epoch: 5| Step: 5
Training loss: 0.1350317746400833
Validation loss: 1.7684812353503319

Epoch: 5| Step: 6
Training loss: 0.3254498839378357
Validation loss: 1.7833175415633826

Epoch: 5| Step: 7
Training loss: 0.35116392374038696
Validation loss: 1.80531128503943

Epoch: 5| Step: 8
Training loss: 0.27884602546691895
Validation loss: 1.8438116542754635

Epoch: 5| Step: 9
Training loss: 0.270172655582428
Validation loss: 1.8356530897078975

Epoch: 5| Step: 10
Training loss: 0.1513069123029709
Validation loss: 1.858632162053098

Epoch: 307| Step: 0
Training loss: 0.41337496042251587
Validation loss: 1.8170504608461935

Epoch: 5| Step: 1
Training loss: 0.24460859596729279
Validation loss: 1.8045972829223962

Epoch: 5| Step: 2
Training loss: 0.3523010313510895
Validation loss: 1.7554296806294432

Epoch: 5| Step: 3
Training loss: 0.18729235231876373
Validation loss: 1.7078102929617769

Epoch: 5| Step: 4
Training loss: 0.23648743331432343
Validation loss: 1.688936932112581

Epoch: 5| Step: 5
Training loss: 0.255267858505249
Validation loss: 1.6702516796768352

Epoch: 5| Step: 6
Training loss: 0.21105805039405823
Validation loss: 1.655144569694355

Epoch: 5| Step: 7
Training loss: 0.3535706400871277
Validation loss: 1.6385228198061708

Epoch: 5| Step: 8
Training loss: 0.29159900546073914
Validation loss: 1.6581759222092167

Epoch: 5| Step: 9
Training loss: 0.20663905143737793
Validation loss: 1.6611246498682166

Epoch: 5| Step: 10
Training loss: 0.14515559375286102
Validation loss: 1.6804880865158573

Epoch: 308| Step: 0
Training loss: 0.20272254943847656
Validation loss: 1.716780993246263

Epoch: 5| Step: 1
Training loss: 0.24002233147621155
Validation loss: 1.7512789490402385

Epoch: 5| Step: 2
Training loss: 0.44100794196128845
Validation loss: 1.7868982694482292

Epoch: 5| Step: 3
Training loss: 0.3108696937561035
Validation loss: 1.8183037568164129

Epoch: 5| Step: 4
Training loss: 0.18856573104858398
Validation loss: 1.835213561211863

Epoch: 5| Step: 5
Training loss: 0.3079472482204437
Validation loss: 1.843208377079297

Epoch: 5| Step: 6
Training loss: 0.27851516008377075
Validation loss: 1.7557040042774652

Epoch: 5| Step: 7
Training loss: 0.3873744308948517
Validation loss: 1.733438769976298

Epoch: 5| Step: 8
Training loss: 0.31909316778182983
Validation loss: 1.746633469417531

Epoch: 5| Step: 9
Training loss: 0.196835458278656
Validation loss: 1.7194489663647068

Epoch: 5| Step: 10
Training loss: 0.17507198452949524
Validation loss: 1.6831204686113583

Epoch: 309| Step: 0
Training loss: 0.3319781422615051
Validation loss: 1.6737123843162292

Epoch: 5| Step: 1
Training loss: 0.14106793701648712
Validation loss: 1.6750295508292414

Epoch: 5| Step: 2
Training loss: 0.22579383850097656
Validation loss: 1.6827676039870068

Epoch: 5| Step: 3
Training loss: 0.25773078203201294
Validation loss: 1.694930697641065

Epoch: 5| Step: 4
Training loss: 0.1916271150112152
Validation loss: 1.6801824749156993

Epoch: 5| Step: 5
Training loss: 0.2783932089805603
Validation loss: 1.6696782714577132

Epoch: 5| Step: 6
Training loss: 0.29043230414390564
Validation loss: 1.6919216545679236

Epoch: 5| Step: 7
Training loss: 0.3639681339263916
Validation loss: 1.7098468042189074

Epoch: 5| Step: 8
Training loss: 0.5003863573074341
Validation loss: 1.703649035064123

Epoch: 5| Step: 9
Training loss: 0.20078615844249725
Validation loss: 1.7190165083895448

Epoch: 5| Step: 10
Training loss: 0.15516895055770874
Validation loss: 1.7268160773861794

Epoch: 310| Step: 0
Training loss: 0.3790181279182434
Validation loss: 1.7694753164886146

Epoch: 5| Step: 1
Training loss: 0.2633797228336334
Validation loss: 1.7460893918109197

Epoch: 5| Step: 2
Training loss: 0.22777728736400604
Validation loss: 1.7494162154454056

Epoch: 5| Step: 3
Training loss: 0.17749162018299103
Validation loss: 1.7253426954310427

Epoch: 5| Step: 4
Training loss: 0.21187913417816162
Validation loss: 1.7322718533136512

Epoch: 5| Step: 5
Training loss: 0.2509121596813202
Validation loss: 1.7111205439413748

Epoch: 5| Step: 6
Training loss: 0.18635831773281097
Validation loss: 1.6906617661958099

Epoch: 5| Step: 7
Training loss: 0.5338886976242065
Validation loss: 1.657412810992169

Epoch: 5| Step: 8
Training loss: 0.2776055932044983
Validation loss: 1.6522855117756834

Epoch: 5| Step: 9
Training loss: 0.19362720847129822
Validation loss: 1.661065218269184

Epoch: 5| Step: 10
Training loss: 0.29727903008461
Validation loss: 1.640361229578654

Epoch: 311| Step: 0
Training loss: 0.20499777793884277
Validation loss: 1.668373659733803

Epoch: 5| Step: 1
Training loss: 0.12788723409175873
Validation loss: 1.6893981759266188

Epoch: 5| Step: 2
Training loss: 0.23836588859558105
Validation loss: 1.7099682848940614

Epoch: 5| Step: 3
Training loss: 0.24813398718833923
Validation loss: 1.7004324607951666

Epoch: 5| Step: 4
Training loss: 0.2972423732280731
Validation loss: 1.747549662026026

Epoch: 5| Step: 5
Training loss: 0.22899559140205383
Validation loss: 1.7165656205146544

Epoch: 5| Step: 6
Training loss: 0.45700591802597046
Validation loss: 1.7463299843572802

Epoch: 5| Step: 7
Training loss: 0.3548769950866699
Validation loss: 1.7781003905880837

Epoch: 5| Step: 8
Training loss: 0.16412007808685303
Validation loss: 1.7607149603546306

Epoch: 5| Step: 9
Training loss: 0.18344491720199585
Validation loss: 1.7475318383145075

Epoch: 5| Step: 10
Training loss: 0.18753206729888916
Validation loss: 1.7356431368858583

Epoch: 312| Step: 0
Training loss: 0.1897876262664795
Validation loss: 1.733224641892218

Epoch: 5| Step: 1
Training loss: 0.1468481570482254
Validation loss: 1.7209552436746576

Epoch: 5| Step: 2
Training loss: 0.18960890173912048
Validation loss: 1.6795444539798203

Epoch: 5| Step: 3
Training loss: 0.1100800633430481
Validation loss: 1.6624018402509793

Epoch: 5| Step: 4
Training loss: 0.24028488993644714
Validation loss: 1.6333445041410384

Epoch: 5| Step: 5
Training loss: 0.21782779693603516
Validation loss: 1.6781054786456528

Epoch: 5| Step: 6
Training loss: 0.43399500846862793
Validation loss: 1.6418150035283898

Epoch: 5| Step: 7
Training loss: 0.43062692880630493
Validation loss: 1.6911285615736438

Epoch: 5| Step: 8
Training loss: 0.18388953804969788
Validation loss: 1.674209362717085

Epoch: 5| Step: 9
Training loss: 0.22225046157836914
Validation loss: 1.6436623065702376

Epoch: 5| Step: 10
Training loss: 0.17447558045387268
Validation loss: 1.6739684138246762

Epoch: 313| Step: 0
Training loss: 0.17543108761310577
Validation loss: 1.7038469365848008

Epoch: 5| Step: 1
Training loss: 0.23483538627624512
Validation loss: 1.705954784347165

Epoch: 5| Step: 2
Training loss: 0.17981331050395966
Validation loss: 1.6883177372717089

Epoch: 5| Step: 3
Training loss: 0.21497027575969696
Validation loss: 1.7366400200833556

Epoch: 5| Step: 4
Training loss: 0.23253273963928223
Validation loss: 1.7581808784956574

Epoch: 5| Step: 5
Training loss: 0.27518731355667114
Validation loss: 1.7124606896472234

Epoch: 5| Step: 6
Training loss: 0.18245957791805267
Validation loss: 1.7280779884707542

Epoch: 5| Step: 7
Training loss: 0.3377888798713684
Validation loss: 1.6980254073296823

Epoch: 5| Step: 8
Training loss: 0.30930930376052856
Validation loss: 1.6751972577905143

Epoch: 5| Step: 9
Training loss: 0.42121750116348267
Validation loss: 1.719092958716936

Epoch: 5| Step: 10
Training loss: 0.20237763226032257
Validation loss: 1.6865245078199653

Epoch: 314| Step: 0
Training loss: 0.23144011199474335
Validation loss: 1.708877222512358

Epoch: 5| Step: 1
Training loss: 0.14508788287639618
Validation loss: 1.666689501013807

Epoch: 5| Step: 2
Training loss: 0.3197283446788788
Validation loss: 1.6588914009832567

Epoch: 5| Step: 3
Training loss: 0.20551785826683044
Validation loss: 1.6618503062955794

Epoch: 5| Step: 4
Training loss: 0.17277975380420685
Validation loss: 1.6685038414052737

Epoch: 5| Step: 5
Training loss: 0.45840078592300415
Validation loss: 1.64543899156714

Epoch: 5| Step: 6
Training loss: 0.3715214729309082
Validation loss: 1.656905743383592

Epoch: 5| Step: 7
Training loss: 0.2640182375907898
Validation loss: 1.6308210203724522

Epoch: 5| Step: 8
Training loss: 0.179417684674263
Validation loss: 1.6355138030103458

Epoch: 5| Step: 9
Training loss: 0.13043633103370667
Validation loss: 1.6557695942540323

Epoch: 5| Step: 10
Training loss: 0.27363091707229614
Validation loss: 1.6234276063980595

Epoch: 315| Step: 0
Training loss: 0.15273644030094147
Validation loss: 1.642787265521224

Epoch: 5| Step: 1
Training loss: 0.26420173048973083
Validation loss: 1.6132186164138138

Epoch: 5| Step: 2
Training loss: 0.16749818623065948
Validation loss: 1.686526599750724

Epoch: 5| Step: 3
Training loss: 0.2805672287940979
Validation loss: 1.6247524522965955

Epoch: 5| Step: 4
Training loss: 0.23763465881347656
Validation loss: 1.6489574473391297

Epoch: 5| Step: 5
Training loss: 0.5156405568122864
Validation loss: 1.663614167962023

Epoch: 5| Step: 6
Training loss: 0.16398310661315918
Validation loss: 1.6795557634804839

Epoch: 5| Step: 7
Training loss: 0.21308302879333496
Validation loss: 1.6320789629413235

Epoch: 5| Step: 8
Training loss: 0.25518539547920227
Validation loss: 1.6078749561822543

Epoch: 5| Step: 9
Training loss: 0.26700106263160706
Validation loss: 1.6415611749054284

Epoch: 5| Step: 10
Training loss: 0.18233710527420044
Validation loss: 1.634204056955153

Epoch: 316| Step: 0
Training loss: 0.2546776235103607
Validation loss: 1.6539424004093293

Epoch: 5| Step: 1
Training loss: 0.23496802151203156
Validation loss: 1.6657142164886638

Epoch: 5| Step: 2
Training loss: 0.19834476709365845
Validation loss: 1.6851578220244376

Epoch: 5| Step: 3
Training loss: 0.23019258677959442
Validation loss: 1.74176836270158

Epoch: 5| Step: 4
Training loss: 0.17153635621070862
Validation loss: 1.7377308389191986

Epoch: 5| Step: 5
Training loss: 0.16853928565979004
Validation loss: 1.744245744520618

Epoch: 5| Step: 6
Training loss: 0.2185308039188385
Validation loss: 1.7229013109719882

Epoch: 5| Step: 7
Training loss: 0.2313779890537262
Validation loss: 1.6934562152431858

Epoch: 5| Step: 8
Training loss: 0.1958044469356537
Validation loss: 1.7177638597385858

Epoch: 5| Step: 9
Training loss: 0.30471065640449524
Validation loss: 1.7293778209276096

Epoch: 5| Step: 10
Training loss: 0.4587358236312866
Validation loss: 1.6803490179841236

Epoch: 317| Step: 0
Training loss: 0.1490977704524994
Validation loss: 1.7050314295676448

Epoch: 5| Step: 1
Training loss: 0.514236330986023
Validation loss: 1.695304193804341

Epoch: 5| Step: 2
Training loss: 0.25002971291542053
Validation loss: 1.6756075966742732

Epoch: 5| Step: 3
Training loss: 0.22046537697315216
Validation loss: 1.668139237229542

Epoch: 5| Step: 4
Training loss: 0.15435007214546204
Validation loss: 1.6683320050598474

Epoch: 5| Step: 5
Training loss: 0.1077025979757309
Validation loss: 1.6978225823371642

Epoch: 5| Step: 6
Training loss: 0.33961233496665955
Validation loss: 1.656352694316577

Epoch: 5| Step: 7
Training loss: 0.1767747849225998
Validation loss: 1.7152327465754684

Epoch: 5| Step: 8
Training loss: 0.26372799277305603
Validation loss: 1.7641227309421827

Epoch: 5| Step: 9
Training loss: 0.24859802424907684
Validation loss: 1.7490196202390937

Epoch: 5| Step: 10
Training loss: 0.18965882062911987
Validation loss: 1.7361512004688222

Epoch: 318| Step: 0
Training loss: 0.34462136030197144
Validation loss: 1.7412141151325677

Epoch: 5| Step: 1
Training loss: 0.2504751682281494
Validation loss: 1.718171150453629

Epoch: 5| Step: 2
Training loss: 0.11728975921869278
Validation loss: 1.6836995296580817

Epoch: 5| Step: 3
Training loss: 0.23174476623535156
Validation loss: 1.6514652006087764

Epoch: 5| Step: 4
Training loss: 0.24126538634300232
Validation loss: 1.6314092938617994

Epoch: 5| Step: 5
Training loss: 0.19066143035888672
Validation loss: 1.626726547876994

Epoch: 5| Step: 6
Training loss: 0.15419116616249084
Validation loss: 1.5895745485059676

Epoch: 5| Step: 7
Training loss: 0.23425336182117462
Validation loss: 1.5710475496066514

Epoch: 5| Step: 8
Training loss: 0.2757301330566406
Validation loss: 1.6235345768672165

Epoch: 5| Step: 9
Training loss: 0.4210291802883148
Validation loss: 1.5982252218390023

Epoch: 5| Step: 10
Training loss: 0.19256505370140076
Validation loss: 1.6491515123715965

Epoch: 319| Step: 0
Training loss: 0.21616873145103455
Validation loss: 1.6516655016970891

Epoch: 5| Step: 1
Training loss: 0.20787198841571808
Validation loss: 1.6676416038185038

Epoch: 5| Step: 2
Training loss: 0.234115332365036
Validation loss: 1.7275562670923048

Epoch: 5| Step: 3
Training loss: 0.2939619719982147
Validation loss: 1.713410485175348

Epoch: 5| Step: 4
Training loss: 0.14234831929206848
Validation loss: 1.7150864293498378

Epoch: 5| Step: 5
Training loss: 0.3926661014556885
Validation loss: 1.743867524208561

Epoch: 5| Step: 6
Training loss: 0.2200370728969574
Validation loss: 1.7526799889021023

Epoch: 5| Step: 7
Training loss: 0.18977263569831848
Validation loss: 1.7468224827961256

Epoch: 5| Step: 8
Training loss: 0.1974603682756424
Validation loss: 1.7568876999680714

Epoch: 5| Step: 9
Training loss: 0.19328656792640686
Validation loss: 1.7198261496841267

Epoch: 5| Step: 10
Training loss: 0.20950749516487122
Validation loss: 1.7046811798567414

Epoch: 320| Step: 0
Training loss: 0.20909109711647034
Validation loss: 1.6561162561498664

Epoch: 5| Step: 1
Training loss: 0.16327711939811707
Validation loss: 1.6423074506944226

Epoch: 5| Step: 2
Training loss: 0.2451944798231125
Validation loss: 1.6457841780877882

Epoch: 5| Step: 3
Training loss: 0.21997323632240295
Validation loss: 1.6344412116594211

Epoch: 5| Step: 4
Training loss: 0.1521110236644745
Validation loss: 1.6621476719456334

Epoch: 5| Step: 5
Training loss: 0.1691424399614334
Validation loss: 1.6650666011277067

Epoch: 5| Step: 6
Training loss: 0.2232060730457306
Validation loss: 1.653459256695163

Epoch: 5| Step: 7
Training loss: 0.33817386627197266
Validation loss: 1.6785414930312865

Epoch: 5| Step: 8
Training loss: 0.24079188704490662
Validation loss: 1.6699630470686062

Epoch: 5| Step: 9
Training loss: 0.15689466893672943
Validation loss: 1.6853136093385759

Epoch: 5| Step: 10
Training loss: 0.48497143387794495
Validation loss: 1.719408283951462

Epoch: 321| Step: 0
Training loss: 0.25046712160110474
Validation loss: 1.7130316008803665

Epoch: 5| Step: 1
Training loss: 0.27042844891548157
Validation loss: 1.7294534137172084

Epoch: 5| Step: 2
Training loss: 0.20882129669189453
Validation loss: 1.7444416720380065

Epoch: 5| Step: 3
Training loss: 0.21478375792503357
Validation loss: 1.7288135591373648

Epoch: 5| Step: 4
Training loss: 0.1932421624660492
Validation loss: 1.7533352400666924

Epoch: 5| Step: 5
Training loss: 0.1851176917552948
Validation loss: 1.7399523578664309

Epoch: 5| Step: 6
Training loss: 0.22379298508167267
Validation loss: 1.7361285750583937

Epoch: 5| Step: 7
Training loss: 0.24005186557769775
Validation loss: 1.7148981376360821

Epoch: 5| Step: 8
Training loss: 0.3170924782752991
Validation loss: 1.6901759768045077

Epoch: 5| Step: 9
Training loss: 0.1533265858888626
Validation loss: 1.6658293867623934

Epoch: 5| Step: 10
Training loss: 0.42073509097099304
Validation loss: 1.6437440969610726

Epoch: 322| Step: 0
Training loss: 0.28130942583084106
Validation loss: 1.6518309885455715

Epoch: 5| Step: 1
Training loss: 0.18418215215206146
Validation loss: 1.6560954419515466

Epoch: 5| Step: 2
Training loss: 0.22828832268714905
Validation loss: 1.653467523154392

Epoch: 5| Step: 3
Training loss: 0.19105541706085205
Validation loss: 1.6614815009537565

Epoch: 5| Step: 4
Training loss: 0.1368923932313919
Validation loss: 1.6609842033796414

Epoch: 5| Step: 5
Training loss: 0.2684940695762634
Validation loss: 1.6225960959670365

Epoch: 5| Step: 6
Training loss: 0.2281779795885086
Validation loss: 1.678623164853742

Epoch: 5| Step: 7
Training loss: 0.1602502167224884
Validation loss: 1.6703899163071827

Epoch: 5| Step: 8
Training loss: 0.24747636914253235
Validation loss: 1.6386291320605944

Epoch: 5| Step: 9
Training loss: 0.3805275559425354
Validation loss: 1.6811983867358136

Epoch: 5| Step: 10
Training loss: 0.3830024302005768
Validation loss: 1.6761227660281683

Epoch: 323| Step: 0
Training loss: 0.2152513563632965
Validation loss: 1.722853127346244

Epoch: 5| Step: 1
Training loss: 0.0922715812921524
Validation loss: 1.685524857172402

Epoch: 5| Step: 2
Training loss: 0.14956387877464294
Validation loss: 1.7188534223905174

Epoch: 5| Step: 3
Training loss: 0.299410879611969
Validation loss: 1.6876989808133853

Epoch: 5| Step: 4
Training loss: 0.20551356673240662
Validation loss: 1.7198521821729598

Epoch: 5| Step: 5
Training loss: 0.24798312783241272
Validation loss: 1.7195605347233434

Epoch: 5| Step: 6
Training loss: 0.3333030641078949
Validation loss: 1.7024195309608214

Epoch: 5| Step: 7
Training loss: 0.4459018111228943
Validation loss: 1.6914599762167981

Epoch: 5| Step: 8
Training loss: 0.22669240832328796
Validation loss: 1.6474621180565125

Epoch: 5| Step: 9
Training loss: 0.2970612645149231
Validation loss: 1.6495788443473078

Epoch: 5| Step: 10
Training loss: 0.15995407104492188
Validation loss: 1.6530950710337649

Epoch: 324| Step: 0
Training loss: 0.2760394215583801
Validation loss: 1.6400082643314073

Epoch: 5| Step: 1
Training loss: 0.20589223504066467
Validation loss: 1.6884479009976952

Epoch: 5| Step: 2
Training loss: 0.25813013315200806
Validation loss: 1.683907046112963

Epoch: 5| Step: 3
Training loss: 0.2589375078678131
Validation loss: 1.6721518680613527

Epoch: 5| Step: 4
Training loss: 0.18923988938331604
Validation loss: 1.70640088922234

Epoch: 5| Step: 5
Training loss: 0.11945205926895142
Validation loss: 1.6873204246644051

Epoch: 5| Step: 6
Training loss: 0.354118287563324
Validation loss: 1.6669385433197021

Epoch: 5| Step: 7
Training loss: 0.25609317421913147
Validation loss: 1.6633326930384482

Epoch: 5| Step: 8
Training loss: 0.22162523865699768
Validation loss: 1.6457204767452773

Epoch: 5| Step: 9
Training loss: 0.336246520280838
Validation loss: 1.6663577800155969

Epoch: 5| Step: 10
Training loss: 0.17632630467414856
Validation loss: 1.6421759186252471

Epoch: 325| Step: 0
Training loss: 0.15058381855487823
Validation loss: 1.6379023969814341

Epoch: 5| Step: 1
Training loss: 0.2203277349472046
Validation loss: 1.6339030637535998

Epoch: 5| Step: 2
Training loss: 0.17800068855285645
Validation loss: 1.657156405910369

Epoch: 5| Step: 3
Training loss: 0.29661646485328674
Validation loss: 1.6329988638559978

Epoch: 5| Step: 4
Training loss: 0.18132445216178894
Validation loss: 1.6347530964882142

Epoch: 5| Step: 5
Training loss: 0.41721248626708984
Validation loss: 1.6664333010232577

Epoch: 5| Step: 6
Training loss: 0.21029157936573029
Validation loss: 1.694370319766383

Epoch: 5| Step: 7
Training loss: 0.3603103756904602
Validation loss: 1.665585523010582

Epoch: 5| Step: 8
Training loss: 0.11722841113805771
Validation loss: 1.663289020138402

Epoch: 5| Step: 9
Training loss: 0.21319594979286194
Validation loss: 1.6720553239186604

Epoch: 5| Step: 10
Training loss: 0.2124013900756836
Validation loss: 1.6764071090247041

Epoch: 326| Step: 0
Training loss: 0.36689135432243347
Validation loss: 1.6605263435712425

Epoch: 5| Step: 1
Training loss: 0.20009079575538635
Validation loss: 1.6621951236519763

Epoch: 5| Step: 2
Training loss: 0.1919347196817398
Validation loss: 1.695789021830405

Epoch: 5| Step: 3
Training loss: 0.3555799424648285
Validation loss: 1.6998348107901953

Epoch: 5| Step: 4
Training loss: 0.15455272793769836
Validation loss: 1.7072765698996923

Epoch: 5| Step: 5
Training loss: 0.203548863530159
Validation loss: 1.6932136281844108

Epoch: 5| Step: 6
Training loss: 0.19893072545528412
Validation loss: 1.7086543203682028

Epoch: 5| Step: 7
Training loss: 0.1673877239227295
Validation loss: 1.6975591310890772

Epoch: 5| Step: 8
Training loss: 0.2203136384487152
Validation loss: 1.7313536956746092

Epoch: 5| Step: 9
Training loss: 0.14178916811943054
Validation loss: 1.747150804406853

Epoch: 5| Step: 10
Training loss: 0.23877651989459991
Validation loss: 1.7313121864872594

Epoch: 327| Step: 0
Training loss: 0.23210987448692322
Validation loss: 1.7292002824044996

Epoch: 5| Step: 1
Training loss: 0.19053514301776886
Validation loss: 1.719016964717578

Epoch: 5| Step: 2
Training loss: 0.2131640464067459
Validation loss: 1.6844783342012795

Epoch: 5| Step: 3
Training loss: 0.4945146441459656
Validation loss: 1.656482433760038

Epoch: 5| Step: 4
Training loss: 0.20877113938331604
Validation loss: 1.621022621790568

Epoch: 5| Step: 5
Training loss: 0.21463528275489807
Validation loss: 1.6477580317246017

Epoch: 5| Step: 6
Training loss: 0.21172623336315155
Validation loss: 1.6514087889784126

Epoch: 5| Step: 7
Training loss: 0.19706806540489197
Validation loss: 1.6812225336669593

Epoch: 5| Step: 8
Training loss: 0.20708303153514862
Validation loss: 1.6745931204929148

Epoch: 5| Step: 9
Training loss: 0.2235521376132965
Validation loss: 1.6667110599497312

Epoch: 5| Step: 10
Training loss: 0.293255478143692
Validation loss: 1.688444011954851

Epoch: 328| Step: 0
Training loss: 0.364225298166275
Validation loss: 1.6752060587688158

Epoch: 5| Step: 1
Training loss: 0.2346045970916748
Validation loss: 1.7416586837460917

Epoch: 5| Step: 2
Training loss: 0.1401018500328064
Validation loss: 1.7108992081816479

Epoch: 5| Step: 3
Training loss: 0.2212214469909668
Validation loss: 1.7292766814590783

Epoch: 5| Step: 4
Training loss: 0.1964695155620575
Validation loss: 1.6984356808406051

Epoch: 5| Step: 5
Training loss: 0.19534194469451904
Validation loss: 1.6894303662802583

Epoch: 5| Step: 6
Training loss: 0.18251052498817444
Validation loss: 1.6850367720409105

Epoch: 5| Step: 7
Training loss: 0.19193020462989807
Validation loss: 1.670023259296212

Epoch: 5| Step: 8
Training loss: 0.21359089016914368
Validation loss: 1.6601421743310907

Epoch: 5| Step: 9
Training loss: 0.2040596455335617
Validation loss: 1.6143354767112321

Epoch: 5| Step: 10
Training loss: 0.22681674361228943
Validation loss: 1.6142917217746857

Epoch: 329| Step: 0
Training loss: 0.13465210795402527
Validation loss: 1.6394801062922324

Epoch: 5| Step: 1
Training loss: 0.14092403650283813
Validation loss: 1.6284790910700315

Epoch: 5| Step: 2
Training loss: 0.16653010249137878
Validation loss: 1.5886267756903043

Epoch: 5| Step: 3
Training loss: 0.1751747727394104
Validation loss: 1.608498856585513

Epoch: 5| Step: 4
Training loss: 0.33176153898239136
Validation loss: 1.610308644592121

Epoch: 5| Step: 5
Training loss: 0.4749690592288971
Validation loss: 1.5866167160772509

Epoch: 5| Step: 6
Training loss: 0.20305857062339783
Validation loss: 1.6197840577812606

Epoch: 5| Step: 7
Training loss: 0.18378737568855286
Validation loss: 1.6538291387660529

Epoch: 5| Step: 8
Training loss: 0.2226167619228363
Validation loss: 1.6913509086896015

Epoch: 5| Step: 9
Training loss: 0.2637903094291687
Validation loss: 1.6869725796484178

Epoch: 5| Step: 10
Training loss: 0.10059326887130737
Validation loss: 1.7270218018562562

Epoch: 330| Step: 0
Training loss: 0.09170494973659515
Validation loss: 1.6882428764015116

Epoch: 5| Step: 1
Training loss: 0.38219577074050903
Validation loss: 1.7165029228374522

Epoch: 5| Step: 2
Training loss: 0.2420305460691452
Validation loss: 1.7149678878886725

Epoch: 5| Step: 3
Training loss: 0.1816604882478714
Validation loss: 1.7138537668412732

Epoch: 5| Step: 4
Training loss: 0.17652812600135803
Validation loss: 1.7165718463159376

Epoch: 5| Step: 5
Training loss: 0.40420326590538025
Validation loss: 1.6813313730301396

Epoch: 5| Step: 6
Training loss: 0.21031904220581055
Validation loss: 1.646050686477333

Epoch: 5| Step: 7
Training loss: 0.07221394777297974
Validation loss: 1.6996835098471692

Epoch: 5| Step: 8
Training loss: 0.2212347537279129
Validation loss: 1.6598694555221065

Epoch: 5| Step: 9
Training loss: 0.16763228178024292
Validation loss: 1.6498093476859472

Epoch: 5| Step: 10
Training loss: 0.1464891880750656
Validation loss: 1.6504457407100226

Epoch: 331| Step: 0
Training loss: 0.1468733698129654
Validation loss: 1.6374998695106917

Epoch: 5| Step: 1
Training loss: 0.2764725983142853
Validation loss: 1.6318680650444441

Epoch: 5| Step: 2
Training loss: 0.12845927476882935
Validation loss: 1.6780395174539218

Epoch: 5| Step: 3
Training loss: 0.35617899894714355
Validation loss: 1.6418766462674705

Epoch: 5| Step: 4
Training loss: 0.21459715068340302
Validation loss: 1.6030749954203123

Epoch: 5| Step: 5
Training loss: 0.16699053347110748
Validation loss: 1.6282147233204176

Epoch: 5| Step: 6
Training loss: 0.11195643246173859
Validation loss: 1.6135770633656492

Epoch: 5| Step: 7
Training loss: 0.23808321356773376
Validation loss: 1.63784235395411

Epoch: 5| Step: 8
Training loss: 0.1523708999156952
Validation loss: 1.6575216644553727

Epoch: 5| Step: 9
Training loss: 0.36889955401420593
Validation loss: 1.679666094882514

Epoch: 5| Step: 10
Training loss: 0.1741264909505844
Validation loss: 1.758265551700387

Epoch: 332| Step: 0
Training loss: 0.24424850940704346
Validation loss: 1.7484301533750308

Epoch: 5| Step: 1
Training loss: 0.21513807773590088
Validation loss: 1.7273061762573898

Epoch: 5| Step: 2
Training loss: 0.12225671112537384
Validation loss: 1.7233739899050804

Epoch: 5| Step: 3
Training loss: 0.17139534652233124
Validation loss: 1.6950666545539774

Epoch: 5| Step: 4
Training loss: 0.21869322657585144
Validation loss: 1.6605100336895193

Epoch: 5| Step: 5
Training loss: 0.34201690554618835
Validation loss: 1.654353057184527

Epoch: 5| Step: 6
Training loss: 0.16728293895721436
Validation loss: 1.6392815510431926

Epoch: 5| Step: 7
Training loss: 0.12815238535404205
Validation loss: 1.6227377486485306

Epoch: 5| Step: 8
Training loss: 0.2736690044403076
Validation loss: 1.5904279062824864

Epoch: 5| Step: 9
Training loss: 0.18309453129768372
Validation loss: 1.599308148507149

Epoch: 5| Step: 10
Training loss: 0.26326680183410645
Validation loss: 1.6099238882782638

Epoch: 333| Step: 0
Training loss: 0.1455962359905243
Validation loss: 1.6334526667030909

Epoch: 5| Step: 1
Training loss: 0.32858556509017944
Validation loss: 1.6605947684216242

Epoch: 5| Step: 2
Training loss: 0.20617711544036865
Validation loss: 1.6212792422181816

Epoch: 5| Step: 3
Training loss: 0.2958804965019226
Validation loss: 1.607534804651814

Epoch: 5| Step: 4
Training loss: 0.3173161745071411
Validation loss: 1.6143306429668138

Epoch: 5| Step: 5
Training loss: 0.17435304820537567
Validation loss: 1.596135267647364

Epoch: 5| Step: 6
Training loss: 0.13454289734363556
Validation loss: 1.6344979238766495

Epoch: 5| Step: 7
Training loss: 0.26707029342651367
Validation loss: 1.5975557270870413

Epoch: 5| Step: 8
Training loss: 0.21208126842975616
Validation loss: 1.623221367918035

Epoch: 5| Step: 9
Training loss: 0.2287023365497589
Validation loss: 1.6202409933972102

Epoch: 5| Step: 10
Training loss: 0.320852130651474
Validation loss: 1.630567717295821

Epoch: 334| Step: 0
Training loss: 0.1897980272769928
Validation loss: 1.6203339061429423

Epoch: 5| Step: 1
Training loss: 0.18956001102924347
Validation loss: 1.6830381090923021

Epoch: 5| Step: 2
Training loss: 0.289481520652771
Validation loss: 1.6737284006610993

Epoch: 5| Step: 3
Training loss: 0.12829872965812683
Validation loss: 1.683344228293306

Epoch: 5| Step: 4
Training loss: 0.23582963645458221
Validation loss: 1.7156381171236756

Epoch: 5| Step: 5
Training loss: 0.15122339129447937
Validation loss: 1.693661576958113

Epoch: 5| Step: 6
Training loss: 0.20168204605579376
Validation loss: 1.6754340298714177

Epoch: 5| Step: 7
Training loss: 0.42647284269332886
Validation loss: 1.6770610860598985

Epoch: 5| Step: 8
Training loss: 0.229338139295578
Validation loss: 1.6617048171258741

Epoch: 5| Step: 9
Training loss: 0.17213448882102966
Validation loss: 1.6368763023807156

Epoch: 5| Step: 10
Training loss: 0.31405624747276306
Validation loss: 1.6437525146750993

Epoch: 335| Step: 0
Training loss: 0.4007504880428314
Validation loss: 1.6141677543681154

Epoch: 5| Step: 1
Training loss: 0.27179330587387085
Validation loss: 1.5787303498996201

Epoch: 5| Step: 2
Training loss: 0.10331913083791733
Validation loss: 1.5961179400003085

Epoch: 5| Step: 3
Training loss: 0.19624623656272888
Validation loss: 1.596367920598676

Epoch: 5| Step: 4
Training loss: 0.15738269686698914
Validation loss: 1.5982200061121294

Epoch: 5| Step: 5
Training loss: 0.14163468778133392
Validation loss: 1.6142107363670104

Epoch: 5| Step: 6
Training loss: 0.16749027371406555
Validation loss: 1.6061472636397167

Epoch: 5| Step: 7
Training loss: 0.3297920823097229
Validation loss: 1.6252939380625242

Epoch: 5| Step: 8
Training loss: 0.11995871365070343
Validation loss: 1.644558532263643

Epoch: 5| Step: 9
Training loss: 0.21580612659454346
Validation loss: 1.6557292592140935

Epoch: 5| Step: 10
Training loss: 0.20863860845565796
Validation loss: 1.6695636600576422

Epoch: 336| Step: 0
Training loss: 0.14977215230464935
Validation loss: 1.7014853319814127

Epoch: 5| Step: 1
Training loss: 0.22529825568199158
Validation loss: 1.7210021377891622

Epoch: 5| Step: 2
Training loss: 0.3945631980895996
Validation loss: 1.7098540657310075

Epoch: 5| Step: 3
Training loss: 0.13818608224391937
Validation loss: 1.6943297539987872

Epoch: 5| Step: 4
Training loss: 0.2596563696861267
Validation loss: 1.6709018163783576

Epoch: 5| Step: 5
Training loss: 0.1598638892173767
Validation loss: 1.6158572153378559

Epoch: 5| Step: 6
Training loss: 0.1510828286409378
Validation loss: 1.6368957668222406

Epoch: 5| Step: 7
Training loss: 0.16308069229125977
Validation loss: 1.637302424318047

Epoch: 5| Step: 8
Training loss: 0.29504963755607605
Validation loss: 1.6600840489069622

Epoch: 5| Step: 9
Training loss: 0.1616380512714386
Validation loss: 1.6518463857712284

Epoch: 5| Step: 10
Training loss: 0.17138218879699707
Validation loss: 1.6411545699642551

Epoch: 337| Step: 0
Training loss: 0.2688331604003906
Validation loss: 1.6066364062729703

Epoch: 5| Step: 1
Training loss: 0.32284364104270935
Validation loss: 1.5945569135809456

Epoch: 5| Step: 2
Training loss: 0.23620302975177765
Validation loss: 1.6237468424663748

Epoch: 5| Step: 3
Training loss: 0.34308624267578125
Validation loss: 1.6108586403631395

Epoch: 5| Step: 4
Training loss: 0.21641726791858673
Validation loss: 1.6493406770049885

Epoch: 5| Step: 5
Training loss: 0.2253372222185135
Validation loss: 1.656875023277857

Epoch: 5| Step: 6
Training loss: 0.13088549673557281
Validation loss: 1.6463676588509673

Epoch: 5| Step: 7
Training loss: 0.17200006544589996
Validation loss: 1.6516645262318272

Epoch: 5| Step: 8
Training loss: 0.1644977629184723
Validation loss: 1.6438080187766784

Epoch: 5| Step: 9
Training loss: 0.19107511639595032
Validation loss: 1.6826454029288342

Epoch: 5| Step: 10
Training loss: 0.20526814460754395
Validation loss: 1.7045502637022285

Epoch: 338| Step: 0
Training loss: 0.15191270411014557
Validation loss: 1.6631901751282394

Epoch: 5| Step: 1
Training loss: 0.23711557686328888
Validation loss: 1.643294193411386

Epoch: 5| Step: 2
Training loss: 0.15568122267723083
Validation loss: 1.635357428622502

Epoch: 5| Step: 3
Training loss: 0.18287202715873718
Validation loss: 1.6293235491680842

Epoch: 5| Step: 4
Training loss: 0.29482322931289673
Validation loss: 1.6338218130091184

Epoch: 5| Step: 5
Training loss: 0.14926142990589142
Validation loss: 1.6621263040009366

Epoch: 5| Step: 6
Training loss: 0.21265414357185364
Validation loss: 1.6464524884377756

Epoch: 5| Step: 7
Training loss: 0.14717450737953186
Validation loss: 1.695558149327514

Epoch: 5| Step: 8
Training loss: 0.20431438088417053
Validation loss: 1.652790871999597

Epoch: 5| Step: 9
Training loss: 0.18346133828163147
Validation loss: 1.6506889558607531

Epoch: 5| Step: 10
Training loss: 0.346941739320755
Validation loss: 1.6639173582036009

Epoch: 339| Step: 0
Training loss: 0.18746933341026306
Validation loss: 1.689052217750139

Epoch: 5| Step: 1
Training loss: 0.20046767592430115
Validation loss: 1.7083895860179779

Epoch: 5| Step: 2
Training loss: 0.3799475431442261
Validation loss: 1.6825219508140319

Epoch: 5| Step: 3
Training loss: 0.15241296589374542
Validation loss: 1.7246198525992773

Epoch: 5| Step: 4
Training loss: 0.28806954622268677
Validation loss: 1.6693897375496485

Epoch: 5| Step: 5
Training loss: 0.25010940432548523
Validation loss: 1.6690249878873107

Epoch: 5| Step: 6
Training loss: 0.16177299618721008
Validation loss: 1.6595592575688516

Epoch: 5| Step: 7
Training loss: 0.14336809515953064
Validation loss: 1.6047658099923083

Epoch: 5| Step: 8
Training loss: 0.1631069779396057
Validation loss: 1.6072890168877059

Epoch: 5| Step: 9
Training loss: 0.19101671874523163
Validation loss: 1.5947146492619668

Epoch: 5| Step: 10
Training loss: 0.18375980854034424
Validation loss: 1.5962610693388088

Epoch: 340| Step: 0
Training loss: 0.10242670774459839
Validation loss: 1.6023455922321608

Epoch: 5| Step: 1
Training loss: 0.25036516785621643
Validation loss: 1.6286052452620638

Epoch: 5| Step: 2
Training loss: 0.15299208462238312
Validation loss: 1.6394630260364984

Epoch: 5| Step: 3
Training loss: 0.21120628714561462
Validation loss: 1.6478031989066833

Epoch: 5| Step: 4
Training loss: 0.14213980734348297
Validation loss: 1.5940628846486409

Epoch: 5| Step: 5
Training loss: 0.23392315208911896
Validation loss: 1.6345423216460853

Epoch: 5| Step: 6
Training loss: 0.2249137908220291
Validation loss: 1.6032787599871237

Epoch: 5| Step: 7
Training loss: 0.12547661364078522
Validation loss: 1.6397679698082708

Epoch: 5| Step: 8
Training loss: 0.3304685652256012
Validation loss: 1.5936144308377338

Epoch: 5| Step: 9
Training loss: 0.18334226310253143
Validation loss: 1.6393947870500627

Epoch: 5| Step: 10
Training loss: 0.28248196840286255
Validation loss: 1.6262012220198108

Epoch: 341| Step: 0
Training loss: 0.16294756531715393
Validation loss: 1.608758040653762

Epoch: 5| Step: 1
Training loss: 0.12914836406707764
Validation loss: 1.6241356711233816

Epoch: 5| Step: 2
Training loss: 0.20467519760131836
Validation loss: 1.6613762788875128

Epoch: 5| Step: 3
Training loss: 0.17024151980876923
Validation loss: 1.6408159091908445

Epoch: 5| Step: 4
Training loss: 0.3882415294647217
Validation loss: 1.6205526603165494

Epoch: 5| Step: 5
Training loss: 0.146915003657341
Validation loss: 1.6590952488683886

Epoch: 5| Step: 6
Training loss: 0.17456434667110443
Validation loss: 1.6377075615749563

Epoch: 5| Step: 7
Training loss: 0.26219114661216736
Validation loss: 1.6169893805698683

Epoch: 5| Step: 8
Training loss: 0.10081951320171356
Validation loss: 1.6011923872014528

Epoch: 5| Step: 9
Training loss: 0.12791195511817932
Validation loss: 1.5959756297449912

Epoch: 5| Step: 10
Training loss: 0.2607272267341614
Validation loss: 1.6298973047605125

Epoch: 342| Step: 0
Training loss: 0.13189244270324707
Validation loss: 1.6127304031002907

Epoch: 5| Step: 1
Training loss: 0.18301188945770264
Validation loss: 1.6242022001615135

Epoch: 5| Step: 2
Training loss: 0.3566238284111023
Validation loss: 1.626785583393548

Epoch: 5| Step: 3
Training loss: 0.19165264070034027
Validation loss: 1.6359256980239705

Epoch: 5| Step: 4
Training loss: 0.14678475260734558
Validation loss: 1.6378912797538183

Epoch: 5| Step: 5
Training loss: 0.15242429077625275
Validation loss: 1.6193550286754486

Epoch: 5| Step: 6
Training loss: 0.23217248916625977
Validation loss: 1.683852505940263

Epoch: 5| Step: 7
Training loss: 0.16654722392559052
Validation loss: 1.6458553421881892

Epoch: 5| Step: 8
Training loss: 0.21385136246681213
Validation loss: 1.68934840156186

Epoch: 5| Step: 9
Training loss: 0.2460922747850418
Validation loss: 1.6647199725592008

Epoch: 5| Step: 10
Training loss: 0.11379728466272354
Validation loss: 1.6351308899541055

Epoch: 343| Step: 0
Training loss: 0.1398410201072693
Validation loss: 1.6668108676069526

Epoch: 5| Step: 1
Training loss: 0.20358705520629883
Validation loss: 1.6417943072575394

Epoch: 5| Step: 2
Training loss: 0.23735275864601135
Validation loss: 1.6525045543588617

Epoch: 5| Step: 3
Training loss: 0.19726359844207764
Validation loss: 1.6731078355543074

Epoch: 5| Step: 4
Training loss: 0.16077964007854462
Validation loss: 1.657120886669364

Epoch: 5| Step: 5
Training loss: 0.23174086213111877
Validation loss: 1.6670442934959167

Epoch: 5| Step: 6
Training loss: 0.33441296219825745
Validation loss: 1.6655154061573807

Epoch: 5| Step: 7
Training loss: 0.18435940146446228
Validation loss: 1.668407274830726

Epoch: 5| Step: 8
Training loss: 0.2372765988111496
Validation loss: 1.664298274183786

Epoch: 5| Step: 9
Training loss: 0.18136923015117645
Validation loss: 1.6845601656103646

Epoch: 5| Step: 10
Training loss: 0.14313916862010956
Validation loss: 1.6565064102090814

Epoch: 344| Step: 0
Training loss: 0.20717807114124298
Validation loss: 1.6628275661058323

Epoch: 5| Step: 1
Training loss: 0.1728297621011734
Validation loss: 1.6728753325759724

Epoch: 5| Step: 2
Training loss: 0.09219679981470108
Validation loss: 1.6940380962946082

Epoch: 5| Step: 3
Training loss: 0.20663928985595703
Validation loss: 1.6647619380745837

Epoch: 5| Step: 4
Training loss: 0.2050464153289795
Validation loss: 1.6633671035048783

Epoch: 5| Step: 5
Training loss: 0.34565770626068115
Validation loss: 1.6633279849124212

Epoch: 5| Step: 6
Training loss: 0.14624515175819397
Validation loss: 1.6236734851714103

Epoch: 5| Step: 7
Training loss: 0.23559336364269257
Validation loss: 1.6265663587918846

Epoch: 5| Step: 8
Training loss: 0.127989262342453
Validation loss: 1.5911341623593402

Epoch: 5| Step: 9
Training loss: 0.264526903629303
Validation loss: 1.5700933471802743

Epoch: 5| Step: 10
Training loss: 0.135054811835289
Validation loss: 1.5843563938653598

Epoch: 345| Step: 0
Training loss: 0.23249173164367676
Validation loss: 1.5537195526143557

Epoch: 5| Step: 1
Training loss: 0.26753562688827515
Validation loss: 1.5768370025901384

Epoch: 5| Step: 2
Training loss: 0.2448059320449829
Validation loss: 1.5702521198539323

Epoch: 5| Step: 3
Training loss: 0.25643497705459595
Validation loss: 1.5997874070239324

Epoch: 5| Step: 4
Training loss: 0.15851503610610962
Validation loss: 1.616121466441821

Epoch: 5| Step: 5
Training loss: 0.13969211280345917
Validation loss: 1.6585140279544297

Epoch: 5| Step: 6
Training loss: 0.13604409992694855
Validation loss: 1.6602316005255586

Epoch: 5| Step: 7
Training loss: 0.2535153031349182
Validation loss: 1.7160407573946062

Epoch: 5| Step: 8
Training loss: 0.1605602204799652
Validation loss: 1.731040003479168

Epoch: 5| Step: 9
Training loss: 0.20207075774669647
Validation loss: 1.7721150485418176

Epoch: 5| Step: 10
Training loss: 0.21973435580730438
Validation loss: 1.7405274862884192

Epoch: 346| Step: 0
Training loss: 0.1843681037425995
Validation loss: 1.7244931626063522

Epoch: 5| Step: 1
Training loss: 0.23826774954795837
Validation loss: 1.7070276391121648

Epoch: 5| Step: 2
Training loss: 0.23885557055473328
Validation loss: 1.6847304451850154

Epoch: 5| Step: 3
Training loss: 0.13819833099842072
Validation loss: 1.6359250019955378

Epoch: 5| Step: 4
Training loss: 0.2581016421318054
Validation loss: 1.618973487166948

Epoch: 5| Step: 5
Training loss: 0.3204178214073181
Validation loss: 1.6120486515824513

Epoch: 5| Step: 6
Training loss: 0.2521161139011383
Validation loss: 1.6304154831876037

Epoch: 5| Step: 7
Training loss: 0.15393714606761932
Validation loss: 1.6266509204782464

Epoch: 5| Step: 8
Training loss: 0.10844112932682037
Validation loss: 1.5983486893356487

Epoch: 5| Step: 9
Training loss: 0.16458073258399963
Validation loss: 1.6391566363714074

Epoch: 5| Step: 10
Training loss: 0.24794505536556244
Validation loss: 1.6497953309807727

Epoch: 347| Step: 0
Training loss: 0.2551388144493103
Validation loss: 1.6744325096889208

Epoch: 5| Step: 1
Training loss: 0.12318450212478638
Validation loss: 1.6646550188782394

Epoch: 5| Step: 2
Training loss: 0.23115158081054688
Validation loss: 1.6941520142298874

Epoch: 5| Step: 3
Training loss: 0.13258303701877594
Validation loss: 1.6685925888758835

Epoch: 5| Step: 4
Training loss: 0.1964648962020874
Validation loss: 1.6996596564528763

Epoch: 5| Step: 5
Training loss: 0.12470997869968414
Validation loss: 1.7209990178385088

Epoch: 5| Step: 6
Training loss: 0.47959262132644653
Validation loss: 1.6979769801580777

Epoch: 5| Step: 7
Training loss: 0.19631098210811615
Validation loss: 1.6758501042601883

Epoch: 5| Step: 8
Training loss: 0.20718583464622498
Validation loss: 1.6304193350576586

Epoch: 5| Step: 9
Training loss: 0.14263875782489777
Validation loss: 1.5834560868560628

Epoch: 5| Step: 10
Training loss: 0.16189345717430115
Validation loss: 1.5957451610155002

Epoch: 348| Step: 0
Training loss: 0.186621755361557
Validation loss: 1.551312336998601

Epoch: 5| Step: 1
Training loss: 0.20517973601818085
Validation loss: 1.5435179959061325

Epoch: 5| Step: 2
Training loss: 0.41450196504592896
Validation loss: 1.5563191265188239

Epoch: 5| Step: 3
Training loss: 0.21371111273765564
Validation loss: 1.5519193821055914

Epoch: 5| Step: 4
Training loss: 0.1588890552520752
Validation loss: 1.5510165588830107

Epoch: 5| Step: 5
Training loss: 0.21376295387744904
Validation loss: 1.5849676926930745

Epoch: 5| Step: 6
Training loss: 0.15158221125602722
Validation loss: 1.615788016268002

Epoch: 5| Step: 7
Training loss: 0.29473167657852173
Validation loss: 1.6594560556514288

Epoch: 5| Step: 8
Training loss: 0.15831071138381958
Validation loss: 1.6641399565563406

Epoch: 5| Step: 9
Training loss: 0.1718452274799347
Validation loss: 1.6710776564895466

Epoch: 5| Step: 10
Training loss: 0.15863101184368134
Validation loss: 1.6809601706843222

Epoch: 349| Step: 0
Training loss: 0.2260524332523346
Validation loss: 1.6687614661391064

Epoch: 5| Step: 1
Training loss: 0.10163692384958267
Validation loss: 1.6389365388501076

Epoch: 5| Step: 2
Training loss: 0.2977234125137329
Validation loss: 1.6302671817041212

Epoch: 5| Step: 3
Training loss: 0.15466997027397156
Validation loss: 1.6492131371651926

Epoch: 5| Step: 4
Training loss: 0.18158288300037384
Validation loss: 1.6215704179579211

Epoch: 5| Step: 5
Training loss: 0.24601837992668152
Validation loss: 1.5878103574117024

Epoch: 5| Step: 6
Training loss: 0.16534167528152466
Validation loss: 1.6148558893511373

Epoch: 5| Step: 7
Training loss: 0.1522998809814453
Validation loss: 1.6337060953981133

Epoch: 5| Step: 8
Training loss: 0.42046064138412476
Validation loss: 1.6168543215720885

Epoch: 5| Step: 9
Training loss: 0.145903542637825
Validation loss: 1.6210702080880441

Epoch: 5| Step: 10
Training loss: 0.12735684216022491
Validation loss: 1.6344709588635353

Epoch: 350| Step: 0
Training loss: 0.23322978615760803
Validation loss: 1.6260676396790372

Epoch: 5| Step: 1
Training loss: 0.21174950897693634
Validation loss: 1.6362411283677625

Epoch: 5| Step: 2
Training loss: 0.2756243646144867
Validation loss: 1.6283886009647

Epoch: 5| Step: 3
Training loss: 0.17539557814598083
Validation loss: 1.6297750293567617

Epoch: 5| Step: 4
Training loss: 0.1889953315258026
Validation loss: 1.6474611490003523

Epoch: 5| Step: 5
Training loss: 0.10011355578899384
Validation loss: 1.6742267993188673

Epoch: 5| Step: 6
Training loss: 0.1395643651485443
Validation loss: 1.6442563315873504

Epoch: 5| Step: 7
Training loss: 0.14061687886714935
Validation loss: 1.6516399345090311

Epoch: 5| Step: 8
Training loss: 0.1664847582578659
Validation loss: 1.670332033147094

Epoch: 5| Step: 9
Training loss: 0.31621766090393066
Validation loss: 1.6659684809305335

Epoch: 5| Step: 10
Training loss: 0.10435573011636734
Validation loss: 1.6794900996710664

Epoch: 351| Step: 0
Training loss: 0.23260171711444855
Validation loss: 1.7062467746837164

Epoch: 5| Step: 1
Training loss: 0.1893821507692337
Validation loss: 1.698739008236957

Epoch: 5| Step: 2
Training loss: 0.1665639877319336
Validation loss: 1.7094954841880388

Epoch: 5| Step: 3
Training loss: 0.28575611114501953
Validation loss: 1.7085930852479831

Epoch: 5| Step: 4
Training loss: 0.19655823707580566
Validation loss: 1.6902314636015123

Epoch: 5| Step: 5
Training loss: 0.39500853419303894
Validation loss: 1.6767816171851209

Epoch: 5| Step: 6
Training loss: 0.1583431214094162
Validation loss: 1.6429884613201182

Epoch: 5| Step: 7
Training loss: 0.12573456764221191
Validation loss: 1.6358839619544245

Epoch: 5| Step: 8
Training loss: 0.13227400183677673
Validation loss: 1.6077778006112704

Epoch: 5| Step: 9
Training loss: 0.22780375182628632
Validation loss: 1.5848268283310758

Epoch: 5| Step: 10
Training loss: 0.1633099615573883
Validation loss: 1.5930868246222054

Epoch: 352| Step: 0
Training loss: 0.1322714388370514
Validation loss: 1.567052310512912

Epoch: 5| Step: 1
Training loss: 0.18310870230197906
Validation loss: 1.548728709579796

Epoch: 5| Step: 2
Training loss: 0.25958219170570374
Validation loss: 1.5387762605503041

Epoch: 5| Step: 3
Training loss: 0.24024982750415802
Validation loss: 1.5542846674560218

Epoch: 5| Step: 4
Training loss: 0.32204949855804443
Validation loss: 1.5578969178661224

Epoch: 5| Step: 5
Training loss: 0.11628564447164536
Validation loss: 1.5959764090917443

Epoch: 5| Step: 6
Training loss: 0.2278173416852951
Validation loss: 1.5787992092870897

Epoch: 5| Step: 7
Training loss: 0.10937315225601196
Validation loss: 1.6115092141653902

Epoch: 5| Step: 8
Training loss: 0.15677709877490997
Validation loss: 1.6742111175291

Epoch: 5| Step: 9
Training loss: 0.24460360407829285
Validation loss: 1.6601821953250515

Epoch: 5| Step: 10
Training loss: 0.29896634817123413
Validation loss: 1.6623179656203075

Epoch: 353| Step: 0
Training loss: 0.17387068271636963
Validation loss: 1.6968796612114034

Epoch: 5| Step: 1
Training loss: 0.1348789632320404
Validation loss: 1.665154633983489

Epoch: 5| Step: 2
Training loss: 0.35541972517967224
Validation loss: 1.6317004157650856

Epoch: 5| Step: 3
Training loss: 0.10358140617609024
Validation loss: 1.6340154768318258

Epoch: 5| Step: 4
Training loss: 0.17499688267707825
Validation loss: 1.6187077504332348

Epoch: 5| Step: 5
Training loss: 0.19929417967796326
Validation loss: 1.6158334516709851

Epoch: 5| Step: 6
Training loss: 0.2570875585079193
Validation loss: 1.6164317682225218

Epoch: 5| Step: 7
Training loss: 0.2402433604001999
Validation loss: 1.6285184109082786

Epoch: 5| Step: 8
Training loss: 0.27873316407203674
Validation loss: 1.6464620918355963

Epoch: 5| Step: 9
Training loss: 0.16976797580718994
Validation loss: 1.6355670164990168

Epoch: 5| Step: 10
Training loss: 0.13692805171012878
Validation loss: 1.6340125978633921

Epoch: 354| Step: 0
Training loss: 0.12266852706670761
Validation loss: 1.6584475348072667

Epoch: 5| Step: 1
Training loss: 0.1814626157283783
Validation loss: 1.6309116373779953

Epoch: 5| Step: 2
Training loss: 0.31712090969085693
Validation loss: 1.5941559960765224

Epoch: 5| Step: 3
Training loss: 0.15255364775657654
Validation loss: 1.617303777766484

Epoch: 5| Step: 4
Training loss: 0.2570917308330536
Validation loss: 1.6188399407171434

Epoch: 5| Step: 5
Training loss: 0.16678692400455475
Validation loss: 1.6485198723372592

Epoch: 5| Step: 6
Training loss: 0.22661343216896057
Validation loss: 1.6179359151471047

Epoch: 5| Step: 7
Training loss: 0.18172208964824677
Validation loss: 1.629688952558784

Epoch: 5| Step: 8
Training loss: 0.10051528364419937
Validation loss: 1.6222775828453802

Epoch: 5| Step: 9
Training loss: 0.18368300795555115
Validation loss: 1.5990295640883907

Epoch: 5| Step: 10
Training loss: 0.18180738389492035
Validation loss: 1.6203434326315438

Epoch: 355| Step: 0
Training loss: 0.24867358803749084
Validation loss: 1.6409544816581152

Epoch: 5| Step: 1
Training loss: 0.22258631885051727
Validation loss: 1.6257012300593878

Epoch: 5| Step: 2
Training loss: 0.17758692800998688
Validation loss: 1.6405891564584547

Epoch: 5| Step: 3
Training loss: 0.12874487042427063
Validation loss: 1.6887181446116457

Epoch: 5| Step: 4
Training loss: 0.29725998640060425
Validation loss: 1.680642141449836

Epoch: 5| Step: 5
Training loss: 0.1111225038766861
Validation loss: 1.6803797214261946

Epoch: 5| Step: 6
Training loss: 0.20064251124858856
Validation loss: 1.7030645826811432

Epoch: 5| Step: 7
Training loss: 0.15297558903694153
Validation loss: 1.6572448604850358

Epoch: 5| Step: 8
Training loss: 0.32727962732315063
Validation loss: 1.667200876820472

Epoch: 5| Step: 9
Training loss: 0.15930800139904022
Validation loss: 1.6426220670823128

Epoch: 5| Step: 10
Training loss: 0.12252499163150787
Validation loss: 1.5650301056523477

Epoch: 356| Step: 0
Training loss: 0.30134034156799316
Validation loss: 1.582060546003362

Epoch: 5| Step: 1
Training loss: 0.11763608455657959
Validation loss: 1.6301606842266616

Epoch: 5| Step: 2
Training loss: 0.20322127640247345
Validation loss: 1.6081872114571192

Epoch: 5| Step: 3
Training loss: 0.16175806522369385
Validation loss: 1.603666300414711

Epoch: 5| Step: 4
Training loss: 0.1655975729227066
Validation loss: 1.6387850763977214

Epoch: 5| Step: 5
Training loss: 0.0979517325758934
Validation loss: 1.643895859359413

Epoch: 5| Step: 6
Training loss: 0.18033269047737122
Validation loss: 1.676941519142479

Epoch: 5| Step: 7
Training loss: 0.22962908446788788
Validation loss: 1.7096976913431639

Epoch: 5| Step: 8
Training loss: 0.21172063052654266
Validation loss: 1.7021144077342043

Epoch: 5| Step: 9
Training loss: 0.20870718359947205
Validation loss: 1.706029845822242

Epoch: 5| Step: 10
Training loss: 0.30121293663978577
Validation loss: 1.6916284112520115

Epoch: 357| Step: 0
Training loss: 0.21396413445472717
Validation loss: 1.6457524517531037

Epoch: 5| Step: 1
Training loss: 0.15799696743488312
Validation loss: 1.6544067116193875

Epoch: 5| Step: 2
Training loss: 0.370574414730072
Validation loss: 1.603614309782623

Epoch: 5| Step: 3
Training loss: 0.1512896567583084
Validation loss: 1.6072182668152677

Epoch: 5| Step: 4
Training loss: 0.352265864610672
Validation loss: 1.5970474737946705

Epoch: 5| Step: 5
Training loss: 0.21622169017791748
Validation loss: 1.5871026618506319

Epoch: 5| Step: 6
Training loss: 0.15727990865707397
Validation loss: 1.5778795352546118

Epoch: 5| Step: 7
Training loss: 0.09723161160945892
Validation loss: 1.582239709874635

Epoch: 5| Step: 8
Training loss: 0.10578837245702744
Validation loss: 1.6072988920314337

Epoch: 5| Step: 9
Training loss: 0.20640547573566437
Validation loss: 1.6107638484688216

Epoch: 5| Step: 10
Training loss: 0.20702867209911346
Validation loss: 1.63131377004808

Epoch: 358| Step: 0
Training loss: 0.16053448617458344
Validation loss: 1.6492898893612686

Epoch: 5| Step: 1
Training loss: 0.12601245939731598
Validation loss: 1.6414967839435866

Epoch: 5| Step: 2
Training loss: 0.24348075687885284
Validation loss: 1.655572981603684

Epoch: 5| Step: 3
Training loss: 0.3965918719768524
Validation loss: 1.668335630047706

Epoch: 5| Step: 4
Training loss: 0.21303153038024902
Validation loss: 1.6521809242104972

Epoch: 5| Step: 5
Training loss: 0.12369696795940399
Validation loss: 1.658210366002975

Epoch: 5| Step: 6
Training loss: 0.12566745281219482
Validation loss: 1.6958756510929396

Epoch: 5| Step: 7
Training loss: 0.13691788911819458
Validation loss: 1.726032163507195

Epoch: 5| Step: 8
Training loss: 0.28590989112854004
Validation loss: 1.7520946097630326

Epoch: 5| Step: 9
Training loss: 0.2273370325565338
Validation loss: 1.7267606796756867

Epoch: 5| Step: 10
Training loss: 0.24016635119915009
Validation loss: 1.7217475419403405

Epoch: 359| Step: 0
Training loss: 0.17382380366325378
Validation loss: 1.669624658041103

Epoch: 5| Step: 1
Training loss: 0.14637364447116852
Validation loss: 1.710251497965987

Epoch: 5| Step: 2
Training loss: 0.12083716690540314
Validation loss: 1.6477878542356594

Epoch: 5| Step: 3
Training loss: 0.377289354801178
Validation loss: 1.6607798645573277

Epoch: 5| Step: 4
Training loss: 0.14131343364715576
Validation loss: 1.6977311475302583

Epoch: 5| Step: 5
Training loss: 0.19374732673168182
Validation loss: 1.648324631875561

Epoch: 5| Step: 6
Training loss: 0.29816585779190063
Validation loss: 1.6247624863860428

Epoch: 5| Step: 7
Training loss: 0.2521154582500458
Validation loss: 1.6549898168092132

Epoch: 5| Step: 8
Training loss: 0.16422659158706665
Validation loss: 1.6358539981226767

Epoch: 5| Step: 9
Training loss: 0.1428452432155609
Validation loss: 1.6209898482086837

Epoch: 5| Step: 10
Training loss: 0.15567606687545776
Validation loss: 1.5968262636533348

Epoch: 360| Step: 0
Training loss: 0.3795185983181
Validation loss: 1.6071339108610665

Epoch: 5| Step: 1
Training loss: 0.13336968421936035
Validation loss: 1.5899738547622517

Epoch: 5| Step: 2
Training loss: 0.1940968930721283
Validation loss: 1.6160988000131422

Epoch: 5| Step: 3
Training loss: 0.2309558093547821
Validation loss: 1.5994300368011638

Epoch: 5| Step: 4
Training loss: 0.17877697944641113
Validation loss: 1.6241545369548183

Epoch: 5| Step: 5
Training loss: 0.1369662880897522
Validation loss: 1.6069955107986287

Epoch: 5| Step: 6
Training loss: 0.20412544906139374
Validation loss: 1.5861560298550514

Epoch: 5| Step: 7
Training loss: 0.20712921023368835
Validation loss: 1.6089083712588075

Epoch: 5| Step: 8
Training loss: 0.1186366081237793
Validation loss: 1.6059012400206698

Epoch: 5| Step: 9
Training loss: 0.13072563707828522
Validation loss: 1.591983514447366

Epoch: 5| Step: 10
Training loss: 0.14832346141338348
Validation loss: 1.6275197895624305

Epoch: 361| Step: 0
Training loss: 0.2547387182712555
Validation loss: 1.5906465707286712

Epoch: 5| Step: 1
Training loss: 0.18458740413188934
Validation loss: 1.5900465557652135

Epoch: 5| Step: 2
Training loss: 0.12482891231775284
Validation loss: 1.6052045655506912

Epoch: 5| Step: 3
Training loss: 0.11512602865695953
Validation loss: 1.598497729147634

Epoch: 5| Step: 4
Training loss: 0.17904536426067352
Validation loss: 1.6265297012944375

Epoch: 5| Step: 5
Training loss: 0.1734902709722519
Validation loss: 1.638608032657254

Epoch: 5| Step: 6
Training loss: 0.18943464756011963
Validation loss: 1.657208937470631

Epoch: 5| Step: 7
Training loss: 0.1870517134666443
Validation loss: 1.6601773385078675

Epoch: 5| Step: 8
Training loss: 0.1558750569820404
Validation loss: 1.6921975881822648

Epoch: 5| Step: 9
Training loss: 0.1277626007795334
Validation loss: 1.6944816811110384

Epoch: 5| Step: 10
Training loss: 0.41035008430480957
Validation loss: 1.6953816888152913

Epoch: 362| Step: 0
Training loss: 0.2447502166032791
Validation loss: 1.7171191220642419

Epoch: 5| Step: 1
Training loss: 0.15663781762123108
Validation loss: 1.6609050612295828

Epoch: 5| Step: 2
Training loss: 0.21603651344776154
Validation loss: 1.6248641552463654

Epoch: 5| Step: 3
Training loss: 0.17877590656280518
Validation loss: 1.6215336771421536

Epoch: 5| Step: 4
Training loss: 0.20912185311317444
Validation loss: 1.5936055939684632

Epoch: 5| Step: 5
Training loss: 0.24240736663341522
Validation loss: 1.5381191469007922

Epoch: 5| Step: 6
Training loss: 0.30033963918685913
Validation loss: 1.5667408333029798

Epoch: 5| Step: 7
Training loss: 0.2068459689617157
Validation loss: 1.5463488050686416

Epoch: 5| Step: 8
Training loss: 0.20567533373832703
Validation loss: 1.5788249508027108

Epoch: 5| Step: 9
Training loss: 0.12410835176706314
Validation loss: 1.6143507957458496

Epoch: 5| Step: 10
Training loss: 0.13385291397571564
Validation loss: 1.6311677553320443

Epoch: 363| Step: 0
Training loss: 0.12992514669895172
Validation loss: 1.6389843110115296

Epoch: 5| Step: 1
Training loss: 0.16255506873130798
Validation loss: 1.6538817049354635

Epoch: 5| Step: 2
Training loss: 0.17348302900791168
Validation loss: 1.664293122547929

Epoch: 5| Step: 3
Training loss: 0.21054629981517792
Validation loss: 1.6478361878343808

Epoch: 5| Step: 4
Training loss: 0.22232560813426971
Validation loss: 1.642437114510485

Epoch: 5| Step: 5
Training loss: 0.11242671310901642
Validation loss: 1.665869282137963

Epoch: 5| Step: 6
Training loss: 0.15881314873695374
Validation loss: 1.6852593575754473

Epoch: 5| Step: 7
Training loss: 0.10994970798492432
Validation loss: 1.6830758151187692

Epoch: 5| Step: 8
Training loss: 0.29534226655960083
Validation loss: 1.6905770622273928

Epoch: 5| Step: 9
Training loss: 0.1612381786108017
Validation loss: 1.6997194161979101

Epoch: 5| Step: 10
Training loss: 0.32387855648994446
Validation loss: 1.6500976463799835

Epoch: 364| Step: 0
Training loss: 0.17889194190502167
Validation loss: 1.5968380307638517

Epoch: 5| Step: 1
Training loss: 0.16951240599155426
Validation loss: 1.5874313885165798

Epoch: 5| Step: 2
Training loss: 0.17810244858264923
Validation loss: 1.6162002445549093

Epoch: 5| Step: 3
Training loss: 0.30477839708328247
Validation loss: 1.6261631340108893

Epoch: 5| Step: 4
Training loss: 0.18964238464832306
Validation loss: 1.6179779703899095

Epoch: 5| Step: 5
Training loss: 0.14235463738441467
Validation loss: 1.6284874613567064

Epoch: 5| Step: 6
Training loss: 0.116485595703125
Validation loss: 1.6135535317082559

Epoch: 5| Step: 7
Training loss: 0.14836624264717102
Validation loss: 1.634277561659454

Epoch: 5| Step: 8
Training loss: 0.22174811363220215
Validation loss: 1.6420665210293186

Epoch: 5| Step: 9
Training loss: 0.13063915073871613
Validation loss: 1.6329670926576019

Epoch: 5| Step: 10
Training loss: 0.12985184788703918
Validation loss: 1.6880723699446647

Epoch: 365| Step: 0
Training loss: 0.24768562614917755
Validation loss: 1.624237866811855

Epoch: 5| Step: 1
Training loss: 0.11532507091760635
Validation loss: 1.6453002319541028

Epoch: 5| Step: 2
Training loss: 0.12556561827659607
Validation loss: 1.6227718976236158

Epoch: 5| Step: 3
Training loss: 0.22516699135303497
Validation loss: 1.6176370023399271

Epoch: 5| Step: 4
Training loss: 0.19009646773338318
Validation loss: 1.639096374152809

Epoch: 5| Step: 5
Training loss: 0.16858361661434174
Validation loss: 1.636807159710956

Epoch: 5| Step: 6
Training loss: 0.05390961095690727
Validation loss: 1.6334657489612538

Epoch: 5| Step: 7
Training loss: 0.34497660398483276
Validation loss: 1.6720133622487385

Epoch: 5| Step: 8
Training loss: 0.1485334038734436
Validation loss: 1.686456935380095

Epoch: 5| Step: 9
Training loss: 0.23912367224693298
Validation loss: 1.7342738695042108

Epoch: 5| Step: 10
Training loss: 0.19633495807647705
Validation loss: 1.7280125041161813

Epoch: 366| Step: 0
Training loss: 0.10251554101705551
Validation loss: 1.7102957540942776

Epoch: 5| Step: 1
Training loss: 0.10900833457708359
Validation loss: 1.6892499859615038

Epoch: 5| Step: 2
Training loss: 0.08854374289512634
Validation loss: 1.671105028480612

Epoch: 5| Step: 3
Training loss: 0.17758610844612122
Validation loss: 1.6880483422228085

Epoch: 5| Step: 4
Training loss: 0.2967807650566101
Validation loss: 1.67495007412408

Epoch: 5| Step: 5
Training loss: 0.27351856231689453
Validation loss: 1.668943142378202

Epoch: 5| Step: 6
Training loss: 0.16234414279460907
Validation loss: 1.642817848472185

Epoch: 5| Step: 7
Training loss: 0.38097304105758667
Validation loss: 1.6045823712502756

Epoch: 5| Step: 8
Training loss: 0.1488134264945984
Validation loss: 1.5942534003206479

Epoch: 5| Step: 9
Training loss: 0.17510657012462616
Validation loss: 1.598499305786625

Epoch: 5| Step: 10
Training loss: 0.18414729833602905
Validation loss: 1.5632066393411288

Epoch: 367| Step: 0
Training loss: 0.17625769972801208
Validation loss: 1.5910742513595089

Epoch: 5| Step: 1
Training loss: 0.12500688433647156
Validation loss: 1.64897669130756

Epoch: 5| Step: 2
Training loss: 0.2142142802476883
Validation loss: 1.6351998877781693

Epoch: 5| Step: 3
Training loss: 0.23878006637096405
Validation loss: 1.6370799477382372

Epoch: 5| Step: 4
Training loss: 0.22174644470214844
Validation loss: 1.6415413297632688

Epoch: 5| Step: 5
Training loss: 0.20671510696411133
Validation loss: 1.6620329797908824

Epoch: 5| Step: 6
Training loss: 0.2268902063369751
Validation loss: 1.6962036804486347

Epoch: 5| Step: 7
Training loss: 0.16432304680347443
Validation loss: 1.6952530363554597

Epoch: 5| Step: 8
Training loss: 0.35914164781570435
Validation loss: 1.729907642128647

Epoch: 5| Step: 9
Training loss: 0.15253093838691711
Validation loss: 1.672393798828125

Epoch: 5| Step: 10
Training loss: 0.18290388584136963
Validation loss: 1.6717220301269202

Epoch: 368| Step: 0
Training loss: 0.14019736647605896
Validation loss: 1.6057352096803728

Epoch: 5| Step: 1
Training loss: 0.13729779422283173
Validation loss: 1.608048237780089

Epoch: 5| Step: 2
Training loss: 0.2302684485912323
Validation loss: 1.5817104539563578

Epoch: 5| Step: 3
Training loss: 0.14900869131088257
Validation loss: 1.5929098949637464

Epoch: 5| Step: 4
Training loss: 0.3260505199432373
Validation loss: 1.5728038933969313

Epoch: 5| Step: 5
Training loss: 0.1494191735982895
Validation loss: 1.56222528155132

Epoch: 5| Step: 6
Training loss: 0.22514717280864716
Validation loss: 1.562580696998104

Epoch: 5| Step: 7
Training loss: 0.1094568520784378
Validation loss: 1.5733105944048973

Epoch: 5| Step: 8
Training loss: 0.1294240951538086
Validation loss: 1.5678708771223664

Epoch: 5| Step: 9
Training loss: 0.23893508315086365
Validation loss: 1.5734738329405427

Epoch: 5| Step: 10
Training loss: 0.13731889426708221
Validation loss: 1.5842633183284471

Epoch: 369| Step: 0
Training loss: 0.1271684318780899
Validation loss: 1.616214309969256

Epoch: 5| Step: 1
Training loss: 0.14291837811470032
Validation loss: 1.5843351605117961

Epoch: 5| Step: 2
Training loss: 0.20981445908546448
Validation loss: 1.6223441221380746

Epoch: 5| Step: 3
Training loss: 0.1744692176580429
Validation loss: 1.6117347171229701

Epoch: 5| Step: 4
Training loss: 0.132938414812088
Validation loss: 1.642407085305901

Epoch: 5| Step: 5
Training loss: 0.22510381042957306
Validation loss: 1.6321267363845662

Epoch: 5| Step: 6
Training loss: 0.15509572625160217
Validation loss: 1.6205404304688977

Epoch: 5| Step: 7
Training loss: 0.0941707044839859
Validation loss: 1.637435273457599

Epoch: 5| Step: 8
Training loss: 0.0958457961678505
Validation loss: 1.65627682593561

Epoch: 5| Step: 9
Training loss: 0.3928523063659668
Validation loss: 1.6564493768958635

Epoch: 5| Step: 10
Training loss: 0.10764753073453903
Validation loss: 1.6422499687440935

Epoch: 370| Step: 0
Training loss: 0.35613107681274414
Validation loss: 1.6365191641674246

Epoch: 5| Step: 1
Training loss: 0.12430433928966522
Validation loss: 1.6563677069961384

Epoch: 5| Step: 2
Training loss: 0.1215801015496254
Validation loss: 1.6563508972044914

Epoch: 5| Step: 3
Training loss: 0.11021246761083603
Validation loss: 1.6606392065684001

Epoch: 5| Step: 4
Training loss: 0.20483092963695526
Validation loss: 1.671714344332295

Epoch: 5| Step: 5
Training loss: 0.12459590286016464
Validation loss: 1.649205953844132

Epoch: 5| Step: 6
Training loss: 0.18246886134147644
Validation loss: 1.6362822504453762

Epoch: 5| Step: 7
Training loss: 0.18877606093883514
Validation loss: 1.611174314252792

Epoch: 5| Step: 8
Training loss: 0.06497781723737717
Validation loss: 1.601853975685694

Epoch: 5| Step: 9
Training loss: 0.18272395431995392
Validation loss: 1.5540639559427898

Epoch: 5| Step: 10
Training loss: 0.14090128242969513
Validation loss: 1.5518473784128826

Epoch: 371| Step: 0
Training loss: 0.333775132894516
Validation loss: 1.5704051973999187

Epoch: 5| Step: 1
Training loss: 0.15517428517341614
Validation loss: 1.5471976162284933

Epoch: 5| Step: 2
Training loss: 0.16700848937034607
Validation loss: 1.580895972508256

Epoch: 5| Step: 3
Training loss: 0.157348170876503
Validation loss: 1.5909958321561095

Epoch: 5| Step: 4
Training loss: 0.15941672027111053
Validation loss: 1.617348478686425

Epoch: 5| Step: 5
Training loss: 0.11329086869955063
Validation loss: 1.6059471420062486

Epoch: 5| Step: 6
Training loss: 0.1471908986568451
Validation loss: 1.6182256449935257

Epoch: 5| Step: 7
Training loss: 0.09185879677534103
Validation loss: 1.6478255218075168

Epoch: 5| Step: 8
Training loss: 0.11851082742214203
Validation loss: 1.6333789543438983

Epoch: 5| Step: 9
Training loss: 0.09293138980865479
Validation loss: 1.6188302719464867

Epoch: 5| Step: 10
Training loss: 0.13435515761375427
Validation loss: 1.6408610215751074

Epoch: 372| Step: 0
Training loss: 0.10417666286230087
Validation loss: 1.6406833382063015

Epoch: 5| Step: 1
Training loss: 0.10356578975915909
Validation loss: 1.6155296410283735

Epoch: 5| Step: 2
Training loss: 0.11594898998737335
Validation loss: 1.6225674447192941

Epoch: 5| Step: 3
Training loss: 0.16228337585926056
Validation loss: 1.6090336922676332

Epoch: 5| Step: 4
Training loss: 0.16309891641139984
Validation loss: 1.6089825694279005

Epoch: 5| Step: 5
Training loss: 0.1338258683681488
Validation loss: 1.6030849718278455

Epoch: 5| Step: 6
Training loss: 0.33575621247291565
Validation loss: 1.5830425639306345

Epoch: 5| Step: 7
Training loss: 0.12463013827800751
Validation loss: 1.5651332165605278

Epoch: 5| Step: 8
Training loss: 0.19967438280582428
Validation loss: 1.5637910763422649

Epoch: 5| Step: 9
Training loss: 0.15083184838294983
Validation loss: 1.5642200926298737

Epoch: 5| Step: 10
Training loss: 0.11772426217794418
Validation loss: 1.5631358303049558

Epoch: 373| Step: 0
Training loss: 0.1564767062664032
Validation loss: 1.5640505808655933

Epoch: 5| Step: 1
Training loss: 0.1519167572259903
Validation loss: 1.5907547409816454

Epoch: 5| Step: 2
Training loss: 0.09851040691137314
Validation loss: 1.5789049825360697

Epoch: 5| Step: 3
Training loss: 0.13764454424381256
Validation loss: 1.591906896201513

Epoch: 5| Step: 4
Training loss: 0.11632494628429413
Validation loss: 1.6187413405346613

Epoch: 5| Step: 5
Training loss: 0.3025946617126465
Validation loss: 1.6242969997467533

Epoch: 5| Step: 6
Training loss: 0.16001272201538086
Validation loss: 1.6423206380618516

Epoch: 5| Step: 7
Training loss: 0.13716478645801544
Validation loss: 1.6275376081466675

Epoch: 5| Step: 8
Training loss: 0.23455142974853516
Validation loss: 1.6474872096892326

Epoch: 5| Step: 9
Training loss: 0.17067950963974
Validation loss: 1.6243348544643772

Epoch: 5| Step: 10
Training loss: 0.10681917518377304
Validation loss: 1.5981606014313237

Epoch: 374| Step: 0
Training loss: 0.2652743458747864
Validation loss: 1.5956671968583138

Epoch: 5| Step: 1
Training loss: 0.15655294060707092
Validation loss: 1.587743136190599

Epoch: 5| Step: 2
Training loss: 0.1978776901960373
Validation loss: 1.5736944675445557

Epoch: 5| Step: 3
Training loss: 0.10398022085428238
Validation loss: 1.5950574285240584

Epoch: 5| Step: 4
Training loss: 0.11298159509897232
Validation loss: 1.5863459776806574

Epoch: 5| Step: 5
Training loss: 0.14310786128044128
Validation loss: 1.5937284449095368

Epoch: 5| Step: 6
Training loss: 0.14495691657066345
Validation loss: 1.5989696543703797

Epoch: 5| Step: 7
Training loss: 0.08125180751085281
Validation loss: 1.5914337635040283

Epoch: 5| Step: 8
Training loss: 0.16031686961650848
Validation loss: 1.5970954100290935

Epoch: 5| Step: 9
Training loss: 0.1574307084083557
Validation loss: 1.5954667829698133

Epoch: 5| Step: 10
Training loss: 0.11273971199989319
Validation loss: 1.5994395479079215

Epoch: 375| Step: 0
Training loss: 0.11149211972951889
Validation loss: 1.5786304345694921

Epoch: 5| Step: 1
Training loss: 0.15823332965373993
Validation loss: 1.6194672558897285

Epoch: 5| Step: 2
Training loss: 0.152279794216156
Validation loss: 1.6171691238239247

Epoch: 5| Step: 3
Training loss: 0.1900423914194107
Validation loss: 1.6180013482288649

Epoch: 5| Step: 4
Training loss: 0.16431209444999695
Validation loss: 1.6042445731419388

Epoch: 5| Step: 5
Training loss: 0.13577434420585632
Validation loss: 1.5860149148971803

Epoch: 5| Step: 6
Training loss: 0.15104790031909943
Validation loss: 1.5821746036570559

Epoch: 5| Step: 7
Training loss: 0.16084317862987518
Validation loss: 1.5581747101199241

Epoch: 5| Step: 8
Training loss: 0.15079587697982788
Validation loss: 1.5946422328231156

Epoch: 5| Step: 9
Training loss: 0.28850579261779785
Validation loss: 1.5525360056149062

Epoch: 5| Step: 10
Training loss: 0.11030012369155884
Validation loss: 1.5905626243160618

Epoch: 376| Step: 0
Training loss: 0.16844815015792847
Validation loss: 1.6081435347116122

Epoch: 5| Step: 1
Training loss: 0.13095463812351227
Validation loss: 1.5923805864908362

Epoch: 5| Step: 2
Training loss: 0.12706713378429413
Validation loss: 1.5928464064034082

Epoch: 5| Step: 3
Training loss: 0.14138878881931305
Validation loss: 1.6146990099260885

Epoch: 5| Step: 4
Training loss: 0.08269248157739639
Validation loss: 1.6353557032923545

Epoch: 5| Step: 5
Training loss: 0.23634353280067444
Validation loss: 1.6294091978380758

Epoch: 5| Step: 6
Training loss: 0.11022055149078369
Validation loss: 1.6348386041579708

Epoch: 5| Step: 7
Training loss: 0.12460286915302277
Validation loss: 1.6419991639352614

Epoch: 5| Step: 8
Training loss: 0.10399959981441498
Validation loss: 1.6164885823444655

Epoch: 5| Step: 9
Training loss: 0.28844302892684937
Validation loss: 1.6803860228548768

Epoch: 5| Step: 10
Training loss: 0.13006308674812317
Validation loss: 1.6359410696132208

Epoch: 377| Step: 0
Training loss: 0.1219109445810318
Validation loss: 1.6771027734202724

Epoch: 5| Step: 1
Training loss: 0.11292389780282974
Validation loss: 1.6793611639289445

Epoch: 5| Step: 2
Training loss: 0.18609237670898438
Validation loss: 1.6620926318630096

Epoch: 5| Step: 3
Training loss: 0.31942087411880493
Validation loss: 1.6519812178868118

Epoch: 5| Step: 4
Training loss: 0.14408037066459656
Validation loss: 1.6524729703062324

Epoch: 5| Step: 5
Training loss: 0.1179409772157669
Validation loss: 1.6347405141399753

Epoch: 5| Step: 6
Training loss: 0.09420378506183624
Validation loss: 1.5918445881976877

Epoch: 5| Step: 7
Training loss: 0.19329088926315308
Validation loss: 1.586334978380511

Epoch: 5| Step: 8
Training loss: 0.09514418244361877
Validation loss: 1.5841642682270338

Epoch: 5| Step: 9
Training loss: 0.1349194347858429
Validation loss: 1.5748296591543383

Epoch: 5| Step: 10
Training loss: 0.14559876918792725
Validation loss: 1.591729337169278

Epoch: 378| Step: 0
Training loss: 0.10110478103160858
Validation loss: 1.5832591005550918

Epoch: 5| Step: 1
Training loss: 0.11948682367801666
Validation loss: 1.5706100989413518

Epoch: 5| Step: 2
Training loss: 0.16372129321098328
Validation loss: 1.56836788628691

Epoch: 5| Step: 3
Training loss: 0.14763441681861877
Validation loss: 1.5944146853621288

Epoch: 5| Step: 4
Training loss: 0.14116252958774567
Validation loss: 1.6112049510402064

Epoch: 5| Step: 5
Training loss: 0.13612762093544006
Validation loss: 1.6218610591785882

Epoch: 5| Step: 6
Training loss: 0.18158307671546936
Validation loss: 1.6097861233577933

Epoch: 5| Step: 7
Training loss: 0.27439355850219727
Validation loss: 1.6663204354624594

Epoch: 5| Step: 8
Training loss: 0.08458152413368225
Validation loss: 1.6358589792764315

Epoch: 5| Step: 9
Training loss: 0.13229034841060638
Validation loss: 1.666074888680571

Epoch: 5| Step: 10
Training loss: 0.08583518117666245
Validation loss: 1.6604970059087198

Epoch: 379| Step: 0
Training loss: 0.12945125997066498
Validation loss: 1.6643880977425525

Epoch: 5| Step: 1
Training loss: 0.09619290381669998
Validation loss: 1.635560381797052

Epoch: 5| Step: 2
Training loss: 0.20769062638282776
Validation loss: 1.621927321598094

Epoch: 5| Step: 3
Training loss: 0.09621678292751312
Validation loss: 1.6320922387543546

Epoch: 5| Step: 4
Training loss: 0.11056607961654663
Validation loss: 1.5894869271145071

Epoch: 5| Step: 5
Training loss: 0.10873256623744965
Validation loss: 1.5835819641749065

Epoch: 5| Step: 6
Training loss: 0.15655238926410675
Validation loss: 1.5458306112597067

Epoch: 5| Step: 7
Training loss: 0.17050650715827942
Validation loss: 1.5677317893633278

Epoch: 5| Step: 8
Training loss: 0.12619352340698242
Validation loss: 1.5698421065525343

Epoch: 5| Step: 9
Training loss: 0.31645384430885315
Validation loss: 1.5364494541639924

Epoch: 5| Step: 10
Training loss: 0.12250534445047379
Validation loss: 1.5594949260834725

Epoch: 380| Step: 0
Training loss: 0.12628450989723206
Validation loss: 1.5743962692958053

Epoch: 5| Step: 1
Training loss: 0.12251321971416473
Validation loss: 1.5843403365022393

Epoch: 5| Step: 2
Training loss: 0.17685849964618683
Validation loss: 1.6104094084872995

Epoch: 5| Step: 3
Training loss: 0.09459476172924042
Validation loss: 1.6179372149129068

Epoch: 5| Step: 4
Training loss: 0.19542694091796875
Validation loss: 1.6491028493450535

Epoch: 5| Step: 5
Training loss: 0.20999348163604736
Validation loss: 1.6642510903778898

Epoch: 5| Step: 6
Training loss: 0.16044026613235474
Validation loss: 1.703511336798309

Epoch: 5| Step: 7
Training loss: 0.30772626399993896
Validation loss: 1.666317529575799

Epoch: 5| Step: 8
Training loss: 0.0833287388086319
Validation loss: 1.6363475950815345

Epoch: 5| Step: 9
Training loss: 0.08748729526996613
Validation loss: 1.669483123287078

Epoch: 5| Step: 10
Training loss: 0.12335624545812607
Validation loss: 1.6725753532942904

Epoch: 381| Step: 0
Training loss: 0.1377730667591095
Validation loss: 1.7010674233077674

Epoch: 5| Step: 1
Training loss: 0.13112226128578186
Validation loss: 1.6900466924072595

Epoch: 5| Step: 2
Training loss: 0.14843082427978516
Validation loss: 1.6453471055594824

Epoch: 5| Step: 3
Training loss: 0.32099732756614685
Validation loss: 1.635338964000825

Epoch: 5| Step: 4
Training loss: 0.17508181929588318
Validation loss: 1.626393377140004

Epoch: 5| Step: 5
Training loss: 0.06167750805616379
Validation loss: 1.6033885171336513

Epoch: 5| Step: 6
Training loss: 0.08906243741512299
Validation loss: 1.6243106447240359

Epoch: 5| Step: 7
Training loss: 0.20339293777942657
Validation loss: 1.5888744554212015

Epoch: 5| Step: 8
Training loss: 0.14926879107952118
Validation loss: 1.564229565922932

Epoch: 5| Step: 9
Training loss: 0.13243229687213898
Validation loss: 1.5693237730251846

Epoch: 5| Step: 10
Training loss: 0.14120399951934814
Validation loss: 1.5685158083515782

Epoch: 382| Step: 0
Training loss: 0.2112237960100174
Validation loss: 1.555541996673871

Epoch: 5| Step: 1
Training loss: 0.0993320494890213
Validation loss: 1.5352243428589196

Epoch: 5| Step: 2
Training loss: 0.15662604570388794
Validation loss: 1.5663345590714486

Epoch: 5| Step: 3
Training loss: 0.10520359128713608
Validation loss: 1.6001945170023109

Epoch: 5| Step: 4
Training loss: 0.1298215091228485
Validation loss: 1.575297547283993

Epoch: 5| Step: 5
Training loss: 0.08445654064416885
Validation loss: 1.5758613489007438

Epoch: 5| Step: 6
Training loss: 0.17107796669006348
Validation loss: 1.6020652171104186

Epoch: 5| Step: 7
Training loss: 0.11825418472290039
Validation loss: 1.6082692530847364

Epoch: 5| Step: 8
Training loss: 0.28690677881240845
Validation loss: 1.594059549352174

Epoch: 5| Step: 9
Training loss: 0.10656845569610596
Validation loss: 1.6134091122176057

Epoch: 5| Step: 10
Training loss: 0.19067010283470154
Validation loss: 1.6276400858356106

Epoch: 383| Step: 0
Training loss: 0.13733498752117157
Validation loss: 1.6201069060192312

Epoch: 5| Step: 1
Training loss: 0.1667742282152176
Validation loss: 1.6504342004817019

Epoch: 5| Step: 2
Training loss: 0.30166205763816833
Validation loss: 1.62417850699476

Epoch: 5| Step: 3
Training loss: 0.09046139568090439
Validation loss: 1.5975094867008988

Epoch: 5| Step: 4
Training loss: 0.1345902383327484
Validation loss: 1.624882480149628

Epoch: 5| Step: 5
Training loss: 0.11214868724346161
Validation loss: 1.6233670557698896

Epoch: 5| Step: 6
Training loss: 0.1378910392522812
Validation loss: 1.646867598256757

Epoch: 5| Step: 7
Training loss: 0.06653769314289093
Validation loss: 1.6327652315939627

Epoch: 5| Step: 8
Training loss: 0.19150446355342865
Validation loss: 1.6086671102431513

Epoch: 5| Step: 9
Training loss: 0.19462215900421143
Validation loss: 1.6238778150209816

Epoch: 5| Step: 10
Training loss: 0.08762732893228531
Validation loss: 1.5956543901915192

Epoch: 384| Step: 0
Training loss: 0.10039280354976654
Validation loss: 1.6126650623095933

Epoch: 5| Step: 1
Training loss: 0.17449946701526642
Validation loss: 1.5868295725955759

Epoch: 5| Step: 2
Training loss: 0.11493116617202759
Validation loss: 1.5825550543364657

Epoch: 5| Step: 3
Training loss: 0.09053340554237366
Validation loss: 1.5675891009710168

Epoch: 5| Step: 4
Training loss: 0.10917627811431885
Validation loss: 1.589266098314716

Epoch: 5| Step: 5
Training loss: 0.08825387805700302
Validation loss: 1.6066149652645152

Epoch: 5| Step: 6
Training loss: 0.16464249789714813
Validation loss: 1.5920122861862183

Epoch: 5| Step: 7
Training loss: 0.18699321150779724
Validation loss: 1.6211506833312332

Epoch: 5| Step: 8
Training loss: 0.14572909474372864
Validation loss: 1.5925037989052393

Epoch: 5| Step: 9
Training loss: 0.1510784775018692
Validation loss: 1.624891492628282

Epoch: 5| Step: 10
Training loss: 0.31271591782569885
Validation loss: 1.6469179558497604

Epoch: 385| Step: 0
Training loss: 0.09111669659614563
Validation loss: 1.6534160772959392

Epoch: 5| Step: 1
Training loss: 0.08653418719768524
Validation loss: 1.5870476845772035

Epoch: 5| Step: 2
Training loss: 0.15061047673225403
Validation loss: 1.5986865323076966

Epoch: 5| Step: 3
Training loss: 0.1240946426987648
Validation loss: 1.5882458853465256

Epoch: 5| Step: 4
Training loss: 0.18741662800312042
Validation loss: 1.5753822454842188

Epoch: 5| Step: 5
Training loss: 0.15072162449359894
Validation loss: 1.544524379955825

Epoch: 5| Step: 6
Training loss: 0.13984274864196777
Validation loss: 1.5946075275380125

Epoch: 5| Step: 7
Training loss: 0.14533525705337524
Validation loss: 1.5768763621648152

Epoch: 5| Step: 8
Training loss: 0.23295454680919647
Validation loss: 1.5623865294200119

Epoch: 5| Step: 9
Training loss: 0.11466292291879654
Validation loss: 1.563869785237056

Epoch: 5| Step: 10
Training loss: 0.16796843707561493
Validation loss: 1.5656150912725797

Epoch: 386| Step: 0
Training loss: 0.1342369019985199
Validation loss: 1.6055449901088592

Epoch: 5| Step: 1
Training loss: 0.23329143226146698
Validation loss: 1.5874938605934061

Epoch: 5| Step: 2
Training loss: 0.14138469099998474
Validation loss: 1.583601297870759

Epoch: 5| Step: 3
Training loss: 0.1525360643863678
Validation loss: 1.5734321237892233

Epoch: 5| Step: 4
Training loss: 0.14077076315879822
Validation loss: 1.5659322725829257

Epoch: 5| Step: 5
Training loss: 0.17015083134174347
Validation loss: 1.537855452106845

Epoch: 5| Step: 6
Training loss: 0.15161442756652832
Validation loss: 1.5394044935062368

Epoch: 5| Step: 7
Training loss: 0.11808449029922485
Validation loss: 1.532255857221542

Epoch: 5| Step: 8
Training loss: 0.09311874955892563
Validation loss: 1.5387875405691003

Epoch: 5| Step: 9
Training loss: 0.12012533843517303
Validation loss: 1.5457564374451995

Epoch: 5| Step: 10
Training loss: 0.1635391265153885
Validation loss: 1.5925711175446868

Epoch: 387| Step: 0
Training loss: 0.15844659507274628
Validation loss: 1.5996259591912712

Epoch: 5| Step: 1
Training loss: 0.14671650528907776
Validation loss: 1.5879059940256097

Epoch: 5| Step: 2
Training loss: 0.1554800271987915
Validation loss: 1.629482833288049

Epoch: 5| Step: 3
Training loss: 0.22371628880500793
Validation loss: 1.63605603671843

Epoch: 5| Step: 4
Training loss: 0.13726606965065002
Validation loss: 1.6733280881758659

Epoch: 5| Step: 5
Training loss: 0.0908798798918724
Validation loss: 1.6344319376894223

Epoch: 5| Step: 6
Training loss: 0.13792793452739716
Validation loss: 1.6200321182127921

Epoch: 5| Step: 7
Training loss: 0.116480752825737
Validation loss: 1.6243460063011415

Epoch: 5| Step: 8
Training loss: 0.08973117172718048
Validation loss: 1.6349680923646497

Epoch: 5| Step: 9
Training loss: 0.09790411591529846
Validation loss: 1.6256442339189592

Epoch: 5| Step: 10
Training loss: 0.1614549458026886
Validation loss: 1.640055751287809

Epoch: 388| Step: 0
Training loss: 0.29995304346084595
Validation loss: 1.637299273603706

Epoch: 5| Step: 1
Training loss: 0.12625685334205627
Validation loss: 1.6465508181561705

Epoch: 5| Step: 2
Training loss: 0.1077931672334671
Validation loss: 1.6799380471629481

Epoch: 5| Step: 3
Training loss: 0.10196822881698608
Validation loss: 1.6600778346420617

Epoch: 5| Step: 4
Training loss: 0.12414418160915375
Validation loss: 1.6862144265123593

Epoch: 5| Step: 5
Training loss: 0.11215007305145264
Validation loss: 1.6413515819016324

Epoch: 5| Step: 6
Training loss: 0.06336943805217743
Validation loss: 1.6031798188404371

Epoch: 5| Step: 7
Training loss: 0.13270863890647888
Validation loss: 1.6142548745678318

Epoch: 5| Step: 8
Training loss: 0.12532050907611847
Validation loss: 1.6115774749427714

Epoch: 5| Step: 9
Training loss: 0.12148003280162811
Validation loss: 1.597959917078736

Epoch: 5| Step: 10
Training loss: 0.12918484210968018
Validation loss: 1.5479446021459435

Epoch: 389| Step: 0
Training loss: 0.15786294639110565
Validation loss: 1.5472421357708592

Epoch: 5| Step: 1
Training loss: 0.11889463663101196
Validation loss: 1.5315408757937852

Epoch: 5| Step: 2
Training loss: 0.12338446080684662
Validation loss: 1.571018317694305

Epoch: 5| Step: 3
Training loss: 0.11347132921218872
Validation loss: 1.573522420339687

Epoch: 5| Step: 4
Training loss: 0.1524849683046341
Validation loss: 1.5749730339614294

Epoch: 5| Step: 5
Training loss: 0.20218391716480255
Validation loss: 1.6169534101281116

Epoch: 5| Step: 6
Training loss: 0.19159351289272308
Validation loss: 1.6443730208181566

Epoch: 5| Step: 7
Training loss: 0.14974823594093323
Validation loss: 1.6664798221280497

Epoch: 5| Step: 8
Training loss: 0.13625746965408325
Validation loss: 1.6734406409725067

Epoch: 5| Step: 9
Training loss: 0.3632534146308899
Validation loss: 1.7108261187871296

Epoch: 5| Step: 10
Training loss: 0.11829888075590134
Validation loss: 1.661281657475297

Epoch: 390| Step: 0
Training loss: 0.09207427501678467
Validation loss: 1.6406383014494372

Epoch: 5| Step: 1
Training loss: 0.1292504072189331
Validation loss: 1.6587642802987048

Epoch: 5| Step: 2
Training loss: 0.13802728056907654
Validation loss: 1.6525521150199316

Epoch: 5| Step: 3
Training loss: 0.1428254246711731
Validation loss: 1.6085425999856764

Epoch: 5| Step: 4
Training loss: 0.1609005630016327
Validation loss: 1.5463792944467196

Epoch: 5| Step: 5
Training loss: 0.1373485028743744
Validation loss: 1.545881837926885

Epoch: 5| Step: 6
Training loss: 0.11155736446380615
Validation loss: 1.5117548165782806

Epoch: 5| Step: 7
Training loss: 0.2712973952293396
Validation loss: 1.5291400788932719

Epoch: 5| Step: 8
Training loss: 0.16472749412059784
Validation loss: 1.5635188292431574

Epoch: 5| Step: 9
Training loss: 0.1950925588607788
Validation loss: 1.5396698046756048

Epoch: 5| Step: 10
Training loss: 0.1815100908279419
Validation loss: 1.5448731446778903

Epoch: 391| Step: 0
Training loss: 0.10988490283489227
Validation loss: 1.5577578301070838

Epoch: 5| Step: 1
Training loss: 0.24202075600624084
Validation loss: 1.606434270899783

Epoch: 5| Step: 2
Training loss: 0.13683132827281952
Validation loss: 1.5795954324865853

Epoch: 5| Step: 3
Training loss: 0.18392975628376007
Validation loss: 1.630930672409714

Epoch: 5| Step: 4
Training loss: 0.12242688983678818
Validation loss: 1.625027935992005

Epoch: 5| Step: 5
Training loss: 0.1589154303073883
Validation loss: 1.6467092024382723

Epoch: 5| Step: 6
Training loss: 0.12660756707191467
Validation loss: 1.6399642408535045

Epoch: 5| Step: 7
Training loss: 0.09189935773611069
Validation loss: 1.6491225073414464

Epoch: 5| Step: 8
Training loss: 0.1366732120513916
Validation loss: 1.64766522120404

Epoch: 5| Step: 9
Training loss: 0.10790717601776123
Validation loss: 1.6441207060249903

Epoch: 5| Step: 10
Training loss: 0.19724468886852264
Validation loss: 1.6743193852004183

Epoch: 392| Step: 0
Training loss: 0.173892542719841
Validation loss: 1.6780264236593758

Epoch: 5| Step: 1
Training loss: 0.1696195900440216
Validation loss: 1.6681349790224465

Epoch: 5| Step: 2
Training loss: 0.14053235948085785
Validation loss: 1.6031739301578973

Epoch: 5| Step: 3
Training loss: 0.11709312349557877
Validation loss: 1.594552505400873

Epoch: 5| Step: 4
Training loss: 0.16089674830436707
Validation loss: 1.6034349920929118

Epoch: 5| Step: 5
Training loss: 0.13654468953609467
Validation loss: 1.5596693062013196

Epoch: 5| Step: 6
Training loss: 0.1682080328464508
Validation loss: 1.5788644962413336

Epoch: 5| Step: 7
Training loss: 0.18434810638427734
Validation loss: 1.5679913874595397

Epoch: 5| Step: 8
Training loss: 0.08609336614608765
Validation loss: 1.577274481455485

Epoch: 5| Step: 9
Training loss: 0.1563529372215271
Validation loss: 1.5918250865833734

Epoch: 5| Step: 10
Training loss: 0.30783164501190186
Validation loss: 1.591585123410789

Epoch: 393| Step: 0
Training loss: 0.10874917358160019
Validation loss: 1.6038773373890949

Epoch: 5| Step: 1
Training loss: 0.19026058912277222
Validation loss: 1.6237554242534022

Epoch: 5| Step: 2
Training loss: 0.16682079434394836
Validation loss: 1.6328643034863215

Epoch: 5| Step: 3
Training loss: 0.18629612028598785
Validation loss: 1.5757744389195596

Epoch: 5| Step: 4
Training loss: 0.2916965186595917
Validation loss: 1.577392303815452

Epoch: 5| Step: 5
Training loss: 0.13331417739391327
Validation loss: 1.6301306793766637

Epoch: 5| Step: 6
Training loss: 0.10481961071491241
Validation loss: 1.6177166610635736

Epoch: 5| Step: 7
Training loss: 0.15089499950408936
Validation loss: 1.614104300416926

Epoch: 5| Step: 8
Training loss: 0.22113017737865448
Validation loss: 1.6242898266802552

Epoch: 5| Step: 9
Training loss: 0.10696909576654434
Validation loss: 1.6263546674482283

Epoch: 5| Step: 10
Training loss: 0.1375645399093628
Validation loss: 1.5854728401348155

Epoch: 394| Step: 0
Training loss: 0.1383262276649475
Validation loss: 1.5952557915000505

Epoch: 5| Step: 1
Training loss: 0.11279980838298798
Validation loss: 1.6270718856524395

Epoch: 5| Step: 2
Training loss: 0.10311126708984375
Validation loss: 1.6037033757855814

Epoch: 5| Step: 3
Training loss: 0.14064374566078186
Validation loss: 1.5916418862599198

Epoch: 5| Step: 4
Training loss: 0.1557506024837494
Validation loss: 1.6338095677796232

Epoch: 5| Step: 5
Training loss: 0.14177334308624268
Validation loss: 1.6015544963139359

Epoch: 5| Step: 6
Training loss: 0.17235465347766876
Validation loss: 1.6081344889056297

Epoch: 5| Step: 7
Training loss: 0.15391504764556885
Validation loss: 1.5752639706416796

Epoch: 5| Step: 8
Training loss: 0.15659072995185852
Validation loss: 1.5653687471984534

Epoch: 5| Step: 9
Training loss: 0.0973580926656723
Validation loss: 1.5643390327371576

Epoch: 5| Step: 10
Training loss: 0.2774021625518799
Validation loss: 1.57708998392987

Epoch: 395| Step: 0
Training loss: 0.13547421991825104
Validation loss: 1.5818911470392698

Epoch: 5| Step: 1
Training loss: 0.09755519777536392
Validation loss: 1.580151355394753

Epoch: 5| Step: 2
Training loss: 0.2513885796070099
Validation loss: 1.6155232332086051

Epoch: 5| Step: 3
Training loss: 0.16205719113349915
Validation loss: 1.6159988064919748

Epoch: 5| Step: 4
Training loss: 0.14520001411437988
Validation loss: 1.6000270869142266

Epoch: 5| Step: 5
Training loss: 0.17780658602714539
Validation loss: 1.587167957777618

Epoch: 5| Step: 6
Training loss: 0.08781267702579498
Validation loss: 1.6147594067358202

Epoch: 5| Step: 7
Training loss: 0.1282772272825241
Validation loss: 1.6138852744974115

Epoch: 5| Step: 8
Training loss: 0.155676931142807
Validation loss: 1.6246861232224332

Epoch: 5| Step: 9
Training loss: 0.1689375340938568
Validation loss: 1.5992514074489634

Epoch: 5| Step: 10
Training loss: 0.14093337953090668
Validation loss: 1.623433272043864

Epoch: 396| Step: 0
Training loss: 0.26269206404685974
Validation loss: 1.5899036558725501

Epoch: 5| Step: 1
Training loss: 0.1171640008687973
Validation loss: 1.5730335853433097

Epoch: 5| Step: 2
Training loss: 0.13598303496837616
Validation loss: 1.582057406825404

Epoch: 5| Step: 3
Training loss: 0.1454535871744156
Validation loss: 1.563048057658698

Epoch: 5| Step: 4
Training loss: 0.142485573887825
Validation loss: 1.5738603068936257

Epoch: 5| Step: 5
Training loss: 0.1591963768005371
Validation loss: 1.5691637492948962

Epoch: 5| Step: 6
Training loss: 0.1300082504749298
Validation loss: 1.5961964258583643

Epoch: 5| Step: 7
Training loss: 0.07841792702674866
Validation loss: 1.5884553129955004

Epoch: 5| Step: 8
Training loss: 0.09071825444698334
Validation loss: 1.576363322555378

Epoch: 5| Step: 9
Training loss: 0.07409404218196869
Validation loss: 1.589997660729193

Epoch: 5| Step: 10
Training loss: 0.11981119960546494
Validation loss: 1.593838946793669

Epoch: 397| Step: 0
Training loss: 0.10615532100200653
Validation loss: 1.6305596725915068

Epoch: 5| Step: 1
Training loss: 0.08608371019363403
Validation loss: 1.6273464400281188

Epoch: 5| Step: 2
Training loss: 0.10941801220178604
Validation loss: 1.593906460910715

Epoch: 5| Step: 3
Training loss: 0.05500020459294319
Validation loss: 1.5980597221723167

Epoch: 5| Step: 4
Training loss: 0.1557464450597763
Validation loss: 1.5779995867001113

Epoch: 5| Step: 5
Training loss: 0.15289153158664703
Validation loss: 1.551661285020972

Epoch: 5| Step: 6
Training loss: 0.2851235866546631
Validation loss: 1.581915459966147

Epoch: 5| Step: 7
Training loss: 0.13101167976856232
Validation loss: 1.5874361761154667

Epoch: 5| Step: 8
Training loss: 0.12847207486629486
Validation loss: 1.5864034070763537

Epoch: 5| Step: 9
Training loss: 0.13359403610229492
Validation loss: 1.577840648671632

Epoch: 5| Step: 10
Training loss: 0.10156591981649399
Validation loss: 1.5789095868346512

Epoch: 398| Step: 0
Training loss: 0.15574635565280914
Validation loss: 1.5719636896605134

Epoch: 5| Step: 1
Training loss: 0.1243630200624466
Validation loss: 1.5558970717973606

Epoch: 5| Step: 2
Training loss: 0.1852966547012329
Validation loss: 1.5490613188794864

Epoch: 5| Step: 3
Training loss: 0.13418522477149963
Validation loss: 1.506652779476617

Epoch: 5| Step: 4
Training loss: 0.09928198158740997
Validation loss: 1.5523758242207188

Epoch: 5| Step: 5
Training loss: 0.13875453174114227
Validation loss: 1.597749508837218

Epoch: 5| Step: 6
Training loss: 0.13523942232131958
Validation loss: 1.5575334871968916

Epoch: 5| Step: 7
Training loss: 0.11734966188669205
Validation loss: 1.6044850054607596

Epoch: 5| Step: 8
Training loss: 0.13382664322853088
Validation loss: 1.5902090777633011

Epoch: 5| Step: 9
Training loss: 0.09717945754528046
Validation loss: 1.6136522626364103

Epoch: 5| Step: 10
Training loss: 0.2887089252471924
Validation loss: 1.5888315631497292

Epoch: 399| Step: 0
Training loss: 0.07036639004945755
Validation loss: 1.609783668671885

Epoch: 5| Step: 1
Training loss: 0.17995807528495789
Validation loss: 1.6189158911346107

Epoch: 5| Step: 2
Training loss: 0.11566336452960968
Validation loss: 1.6486960354671683

Epoch: 5| Step: 3
Training loss: 0.14678844809532166
Validation loss: 1.6232034698609383

Epoch: 5| Step: 4
Training loss: 0.21019236743450165
Validation loss: 1.5786044905262608

Epoch: 5| Step: 5
Training loss: 0.1448168307542801
Validation loss: 1.5742189922640402

Epoch: 5| Step: 6
Training loss: 0.1324598491191864
Validation loss: 1.5607284179297827

Epoch: 5| Step: 7
Training loss: 0.08119384944438934
Validation loss: 1.5570718037184847

Epoch: 5| Step: 8
Training loss: 0.05891416221857071
Validation loss: 1.5214871924410585

Epoch: 5| Step: 9
Training loss: 0.1346127837896347
Validation loss: 1.5257083036566292

Epoch: 5| Step: 10
Training loss: 0.20426875352859497
Validation loss: 1.557498940857508

Epoch: 400| Step: 0
Training loss: 0.16132281720638275
Validation loss: 1.5287293618725193

Epoch: 5| Step: 1
Training loss: 0.33993178606033325
Validation loss: 1.5276224767008135

Epoch: 5| Step: 2
Training loss: 0.09750019013881683
Validation loss: 1.5824117070885115

Epoch: 5| Step: 3
Training loss: 0.1764877289533615
Validation loss: 1.5690615959064935

Epoch: 5| Step: 4
Training loss: 0.10310755670070648
Validation loss: 1.58490401698697

Epoch: 5| Step: 5
Training loss: 0.10797275602817535
Validation loss: 1.6032418922711444

Epoch: 5| Step: 6
Training loss: 0.12660859525203705
Validation loss: 1.5940001446713683

Epoch: 5| Step: 7
Training loss: 0.1425742208957672
Validation loss: 1.6348747591818533

Epoch: 5| Step: 8
Training loss: 0.1571849137544632
Validation loss: 1.6273531913757324

Epoch: 5| Step: 9
Training loss: 0.14184701442718506
Validation loss: 1.6332845021319646

Epoch: 5| Step: 10
Training loss: 0.15795543789863586
Validation loss: 1.649294626328253

Testing loss: 2.064393083254496
