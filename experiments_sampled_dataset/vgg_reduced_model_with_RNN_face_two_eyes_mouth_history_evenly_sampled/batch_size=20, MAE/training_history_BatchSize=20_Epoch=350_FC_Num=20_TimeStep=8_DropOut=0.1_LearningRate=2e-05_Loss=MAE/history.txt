Epoch: 1| Step: 0
Training loss: 4.377353191375732
Validation loss: 5.117358043629636

Epoch: 5| Step: 1
Training loss: 4.071218490600586
Validation loss: 5.086286062835365

Epoch: 5| Step: 2
Training loss: 5.708559989929199
Validation loss: 5.061106148586478

Epoch: 5| Step: 3
Training loss: 3.8589680194854736
Validation loss: 5.036906873026202

Epoch: 5| Step: 4
Training loss: 4.968389987945557
Validation loss: 5.011699212494717

Epoch: 5| Step: 5
Training loss: 5.463883876800537
Validation loss: 4.984364760819302

Epoch: 5| Step: 6
Training loss: 4.709195137023926
Validation loss: 4.953269820059499

Epoch: 5| Step: 7
Training loss: 3.9738545417785645
Validation loss: 4.918498485319076

Epoch: 5| Step: 8
Training loss: 4.412323951721191
Validation loss: 4.877660243741928

Epoch: 5| Step: 9
Training loss: 5.1361565589904785
Validation loss: 4.833762773903468

Epoch: 5| Step: 10
Training loss: 5.87627649307251
Validation loss: 4.783909018321704

Epoch: 2| Step: 0
Training loss: 4.465128421783447
Validation loss: 4.730073449432209

Epoch: 5| Step: 1
Training loss: 3.9682350158691406
Validation loss: 4.673389629651141

Epoch: 5| Step: 2
Training loss: 5.060496807098389
Validation loss: 4.615044142610284

Epoch: 5| Step: 3
Training loss: 4.522334098815918
Validation loss: 4.553916244096653

Epoch: 5| Step: 4
Training loss: 2.2460293769836426
Validation loss: 4.491664917238297

Epoch: 5| Step: 5
Training loss: 4.170557498931885
Validation loss: 4.428526309228713

Epoch: 5| Step: 6
Training loss: 4.691380977630615
Validation loss: 4.367040116299865

Epoch: 5| Step: 7
Training loss: 4.648295879364014
Validation loss: 4.305346350516042

Epoch: 5| Step: 8
Training loss: 3.856006622314453
Validation loss: 4.240651433185865

Epoch: 5| Step: 9
Training loss: 4.092894554138184
Validation loss: 4.17393995100452

Epoch: 5| Step: 10
Training loss: 4.813333511352539
Validation loss: 4.104277810742778

Epoch: 3| Step: 0
Training loss: 3.770265579223633
Validation loss: 4.03347546310835

Epoch: 5| Step: 1
Training loss: 3.9182116985321045
Validation loss: 3.955366421771306

Epoch: 5| Step: 2
Training loss: 3.7218337059020996
Validation loss: 3.8807109940436577

Epoch: 5| Step: 3
Training loss: 4.414857387542725
Validation loss: 3.819828018065422

Epoch: 5| Step: 4
Training loss: 3.759920120239258
Validation loss: 3.7588449729386197

Epoch: 5| Step: 5
Training loss: 3.79382061958313
Validation loss: 3.7015027282058552

Epoch: 5| Step: 6
Training loss: 3.7697417736053467
Validation loss: 3.6426840443764963

Epoch: 5| Step: 7
Training loss: 4.127349376678467
Validation loss: 3.5883250621057328

Epoch: 5| Step: 8
Training loss: 3.627725124359131
Validation loss: 3.5417908622372534

Epoch: 5| Step: 9
Training loss: 1.7015845775604248
Validation loss: 3.5026603565421155

Epoch: 5| Step: 10
Training loss: 3.4726076126098633
Validation loss: 3.4694025644692044

Epoch: 4| Step: 0
Training loss: 3.3459689617156982
Validation loss: 3.4338866767062934

Epoch: 5| Step: 1
Training loss: 3.6470439434051514
Validation loss: 3.3951631669075257

Epoch: 5| Step: 2
Training loss: 3.276683807373047
Validation loss: 3.361998434989683

Epoch: 5| Step: 3
Training loss: 2.418506622314453
Validation loss: 3.334213928509784

Epoch: 5| Step: 4
Training loss: 2.7470250129699707
Validation loss: 3.3067043724880425

Epoch: 5| Step: 5
Training loss: 3.692417621612549
Validation loss: 3.2866232523354153

Epoch: 5| Step: 6
Training loss: 3.148124933242798
Validation loss: 3.2681297768828688

Epoch: 5| Step: 7
Training loss: 2.871114492416382
Validation loss: 3.2488338357658795

Epoch: 5| Step: 8
Training loss: 3.233847141265869
Validation loss: 3.23040932993735

Epoch: 5| Step: 9
Training loss: 3.33807373046875
Validation loss: 3.2105841149565992

Epoch: 5| Step: 10
Training loss: 4.552463531494141
Validation loss: 3.1927777080125708

Epoch: 5| Step: 0
Training loss: 2.838296890258789
Validation loss: 3.1691129284520305

Epoch: 5| Step: 1
Training loss: 3.7477023601531982
Validation loss: 3.139970499982116

Epoch: 5| Step: 2
Training loss: 2.341334819793701
Validation loss: 3.1179222188970095

Epoch: 5| Step: 3
Training loss: 3.303015947341919
Validation loss: 3.0977499228651806

Epoch: 5| Step: 4
Training loss: 2.9826509952545166
Validation loss: 3.078569225085679

Epoch: 5| Step: 5
Training loss: 2.115285873413086
Validation loss: 3.0604659101014495

Epoch: 5| Step: 6
Training loss: 2.9656662940979004
Validation loss: 3.0517009458234234

Epoch: 5| Step: 7
Training loss: 3.7146382331848145
Validation loss: 3.043449230091546

Epoch: 5| Step: 8
Training loss: 3.378535509109497
Validation loss: 3.0256018125882713

Epoch: 5| Step: 9
Training loss: 3.672363758087158
Validation loss: 3.0102785402728665

Epoch: 5| Step: 10
Training loss: 3.2542724609375
Validation loss: 2.998589995086834

Epoch: 6| Step: 0
Training loss: 2.6856002807617188
Validation loss: 2.9877376812760548

Epoch: 5| Step: 1
Training loss: 2.826343536376953
Validation loss: 2.971888565248059

Epoch: 5| Step: 2
Training loss: 2.211486339569092
Validation loss: 2.9625629173812045

Epoch: 5| Step: 3
Training loss: 3.7179675102233887
Validation loss: 2.9551417494332917

Epoch: 5| Step: 4
Training loss: 3.3122801780700684
Validation loss: 2.942823076760897

Epoch: 5| Step: 5
Training loss: 3.27705454826355
Validation loss: 2.9290627074498

Epoch: 5| Step: 6
Training loss: 3.546323776245117
Validation loss: 2.906132741640973

Epoch: 5| Step: 7
Training loss: 2.888939380645752
Validation loss: 2.889333366065897

Epoch: 5| Step: 8
Training loss: 2.585566282272339
Validation loss: 2.8708293489230576

Epoch: 5| Step: 9
Training loss: 3.0600874423980713
Validation loss: 2.8529604660567416

Epoch: 5| Step: 10
Training loss: 2.89762282371521
Validation loss: 2.8384428306292464

Epoch: 7| Step: 0
Training loss: 3.9492430686950684
Validation loss: 2.887550505258704

Epoch: 5| Step: 1
Training loss: 2.9389543533325195
Validation loss: 2.887084684064311

Epoch: 5| Step: 2
Training loss: 2.2605626583099365
Validation loss: 2.8739870030392884

Epoch: 5| Step: 3
Training loss: 3.111299514770508
Validation loss: 2.8449090937132477

Epoch: 5| Step: 4
Training loss: 2.5865280628204346
Validation loss: 2.8122863436257965

Epoch: 5| Step: 5
Training loss: 3.570319414138794
Validation loss: 2.831536328920754

Epoch: 5| Step: 6
Training loss: 3.035435199737549
Validation loss: 2.8119766840370755

Epoch: 5| Step: 7
Training loss: 2.6543099880218506
Validation loss: 2.78844379865995

Epoch: 5| Step: 8
Training loss: 3.3071365356445312
Validation loss: 2.781134549007621

Epoch: 5| Step: 9
Training loss: 2.5143229961395264
Validation loss: 2.7761667569478354

Epoch: 5| Step: 10
Training loss: 2.5132546424865723
Validation loss: 2.7636476127050256

Epoch: 8| Step: 0
Training loss: 3.1836345195770264
Validation loss: 2.7593261118858092

Epoch: 5| Step: 1
Training loss: 3.4075069427490234
Validation loss: 2.7554105481793805

Epoch: 5| Step: 2
Training loss: 2.173623561859131
Validation loss: 2.7553727498618503

Epoch: 5| Step: 3
Training loss: 3.6788108348846436
Validation loss: 2.7531743152167207

Epoch: 5| Step: 4
Training loss: 3.231957197189331
Validation loss: 2.7352911656902683

Epoch: 5| Step: 5
Training loss: 2.7008187770843506
Validation loss: 2.7267877542844383

Epoch: 5| Step: 6
Training loss: 2.810405731201172
Validation loss: 2.728596559134863

Epoch: 5| Step: 7
Training loss: 2.7333364486694336
Validation loss: 2.7210894887165358

Epoch: 5| Step: 8
Training loss: 2.205030918121338
Validation loss: 2.713003808452237

Epoch: 5| Step: 9
Training loss: 2.5908541679382324
Validation loss: 2.7055686032900246

Epoch: 5| Step: 10
Training loss: 3.115248680114746
Validation loss: 2.6982281387493177

Epoch: 9| Step: 0
Training loss: 2.4534647464752197
Validation loss: 2.6914927651805263

Epoch: 5| Step: 1
Training loss: 2.9243080615997314
Validation loss: 2.684876967501897

Epoch: 5| Step: 2
Training loss: 2.5043203830718994
Validation loss: 2.683684023477698

Epoch: 5| Step: 3
Training loss: 3.710691452026367
Validation loss: 2.6897054538931897

Epoch: 5| Step: 4
Training loss: 2.428879976272583
Validation loss: 2.6783450880358295

Epoch: 5| Step: 5
Training loss: 3.306262254714966
Validation loss: 2.679109698982649

Epoch: 5| Step: 6
Training loss: 3.003563404083252
Validation loss: 2.6797523216534684

Epoch: 5| Step: 7
Training loss: 2.4018256664276123
Validation loss: 2.6755757767667054

Epoch: 5| Step: 8
Training loss: 2.9380786418914795
Validation loss: 2.6718301721798476

Epoch: 5| Step: 9
Training loss: 2.846047878265381
Validation loss: 2.6685576746540685

Epoch: 5| Step: 10
Training loss: 2.9231390953063965
Validation loss: 2.66368120203736

Epoch: 10| Step: 0
Training loss: 2.690575361251831
Validation loss: 2.6648474713807464

Epoch: 5| Step: 1
Training loss: 3.0754566192626953
Validation loss: 2.6603466720991236

Epoch: 5| Step: 2
Training loss: 2.81756591796875
Validation loss: 2.6553148813145135

Epoch: 5| Step: 3
Training loss: 3.6163330078125
Validation loss: 2.65624644935772

Epoch: 5| Step: 4
Training loss: 3.03747820854187
Validation loss: 2.6502913787800777

Epoch: 5| Step: 5
Training loss: 2.8349177837371826
Validation loss: 2.641943936706871

Epoch: 5| Step: 6
Training loss: 2.7982797622680664
Validation loss: 2.6438067036290325

Epoch: 5| Step: 7
Training loss: 2.372354030609131
Validation loss: 2.640294033993957

Epoch: 5| Step: 8
Training loss: 2.769181728363037
Validation loss: 2.633679061807612

Epoch: 5| Step: 9
Training loss: 2.419252872467041
Validation loss: 2.6342695477188274

Epoch: 5| Step: 10
Training loss: 2.731271266937256
Validation loss: 2.6430991208681496

Epoch: 11| Step: 0
Training loss: 2.8033101558685303
Validation loss: 2.6443319833406838

Epoch: 5| Step: 1
Training loss: 1.8828423023223877
Validation loss: 2.661186025988671

Epoch: 5| Step: 2
Training loss: 2.7087948322296143
Validation loss: 2.733175123891523

Epoch: 5| Step: 3
Training loss: 2.541877269744873
Validation loss: 2.731102931884027

Epoch: 5| Step: 4
Training loss: 3.8586738109588623
Validation loss: 2.7083406756001134

Epoch: 5| Step: 5
Training loss: 2.8432087898254395
Validation loss: 2.687172305199408

Epoch: 5| Step: 6
Training loss: 2.596879482269287
Validation loss: 2.6761035739734607

Epoch: 5| Step: 7
Training loss: 3.006089210510254
Validation loss: 2.680689122087212

Epoch: 5| Step: 8
Training loss: 3.1239001750946045
Validation loss: 2.698459066370482

Epoch: 5| Step: 9
Training loss: 3.489520311355591
Validation loss: 2.6667980763220016

Epoch: 5| Step: 10
Training loss: 2.514709711074829
Validation loss: 2.6322761325426

Epoch: 12| Step: 0
Training loss: 3.4839484691619873
Validation loss: 2.6358296102093113

Epoch: 5| Step: 1
Training loss: 2.841601848602295
Validation loss: 2.6463240141509683

Epoch: 5| Step: 2
Training loss: 3.2814884185791016
Validation loss: 2.63159667804677

Epoch: 5| Step: 3
Training loss: 3.720803737640381
Validation loss: 2.618452084961758

Epoch: 5| Step: 4
Training loss: 1.8010658025741577
Validation loss: 2.6204809450334117

Epoch: 5| Step: 5
Training loss: 2.621812343597412
Validation loss: 2.6293457528596282

Epoch: 5| Step: 6
Training loss: 2.699218273162842
Validation loss: 2.630819364260602

Epoch: 5| Step: 7
Training loss: 2.8984649181365967
Validation loss: 2.638319238539665

Epoch: 5| Step: 8
Training loss: 2.530211925506592
Validation loss: 2.602371605493689

Epoch: 5| Step: 9
Training loss: 2.7078723907470703
Validation loss: 2.6029423231719644

Epoch: 5| Step: 10
Training loss: 2.3277926445007324
Validation loss: 2.6138631477150867

Epoch: 13| Step: 0
Training loss: 3.022050380706787
Validation loss: 2.6273588442033335

Epoch: 5| Step: 1
Training loss: 3.0743255615234375
Validation loss: 2.6492037388586227

Epoch: 5| Step: 2
Training loss: 1.9115722179412842
Validation loss: 2.6369122664133706

Epoch: 5| Step: 3
Training loss: 3.094637393951416
Validation loss: 2.6277700188339397

Epoch: 5| Step: 4
Training loss: 3.0882301330566406
Validation loss: 2.617416356199531

Epoch: 5| Step: 5
Training loss: 3.985813856124878
Validation loss: 2.6060301257717993

Epoch: 5| Step: 6
Training loss: 2.755782127380371
Validation loss: 2.5949516219477498

Epoch: 5| Step: 7
Training loss: 2.7818055152893066
Validation loss: 2.5826416515534922

Epoch: 5| Step: 8
Training loss: 2.1965503692626953
Validation loss: 2.581852497593049

Epoch: 5| Step: 9
Training loss: 2.699098825454712
Validation loss: 2.5801483277351625

Epoch: 5| Step: 10
Training loss: 2.1837852001190186
Validation loss: 2.5906371685766403

Epoch: 14| Step: 0
Training loss: 2.9466824531555176
Validation loss: 2.604833451650476

Epoch: 5| Step: 1
Training loss: 3.059386730194092
Validation loss: 2.592894930993357

Epoch: 5| Step: 2
Training loss: 3.3056232929229736
Validation loss: 2.5763048279669976

Epoch: 5| Step: 3
Training loss: 2.490260601043701
Validation loss: 2.5681169391960226

Epoch: 5| Step: 4
Training loss: 2.3275017738342285
Validation loss: 2.579250169056718

Epoch: 5| Step: 5
Training loss: 2.7676684856414795
Validation loss: 2.5937126375013784

Epoch: 5| Step: 6
Training loss: 2.4109878540039062
Validation loss: 2.590299362777382

Epoch: 5| Step: 7
Training loss: 2.681260347366333
Validation loss: 2.5931869604254283

Epoch: 5| Step: 8
Training loss: 2.274409532546997
Validation loss: 2.5908015799778763

Epoch: 5| Step: 9
Training loss: 3.109224796295166
Validation loss: 2.5942468181733163

Epoch: 5| Step: 10
Training loss: 3.5390491485595703
Validation loss: 2.579713039500739

Epoch: 15| Step: 0
Training loss: 3.416149139404297
Validation loss: 2.5730641964943177

Epoch: 5| Step: 1
Training loss: 2.1546130180358887
Validation loss: 2.562006768359933

Epoch: 5| Step: 2
Training loss: 2.572908878326416
Validation loss: 2.5563452782169467

Epoch: 5| Step: 3
Training loss: 3.0572710037231445
Validation loss: 2.5494553812088503

Epoch: 5| Step: 4
Training loss: 2.531036138534546
Validation loss: 2.5483586736904678

Epoch: 5| Step: 5
Training loss: 2.617812156677246
Validation loss: 2.5509406443565124

Epoch: 5| Step: 6
Training loss: 2.3075881004333496
Validation loss: 2.5906059844519502

Epoch: 5| Step: 7
Training loss: 2.9578773975372314
Validation loss: 2.5464715624368317

Epoch: 5| Step: 8
Training loss: 3.081087827682495
Validation loss: 2.545651581979567

Epoch: 5| Step: 9
Training loss: 3.3223729133605957
Validation loss: 2.5436373423504572

Epoch: 5| Step: 10
Training loss: 2.424072742462158
Validation loss: 2.54051810438915

Epoch: 16| Step: 0
Training loss: 2.996882915496826
Validation loss: 2.545847713306386

Epoch: 5| Step: 1
Training loss: 3.4294586181640625
Validation loss: 2.5407403669049664

Epoch: 5| Step: 2
Training loss: 3.2231202125549316
Validation loss: 2.5382843991761566

Epoch: 5| Step: 3
Training loss: 2.569882392883301
Validation loss: 2.5403054965439664

Epoch: 5| Step: 4
Training loss: 2.1369338035583496
Validation loss: 2.5386982117929766

Epoch: 5| Step: 5
Training loss: 2.7039639949798584
Validation loss: 2.53656574731232

Epoch: 5| Step: 6
Training loss: 2.78576397895813
Validation loss: 2.5383376716285624

Epoch: 5| Step: 7
Training loss: 2.879901170730591
Validation loss: 2.5546526960147324

Epoch: 5| Step: 8
Training loss: 2.5598199367523193
Validation loss: 2.535575948735719

Epoch: 5| Step: 9
Training loss: 2.4602370262145996
Validation loss: 2.5265660003949235

Epoch: 5| Step: 10
Training loss: 2.686100482940674
Validation loss: 2.523163031506282

Epoch: 17| Step: 0
Training loss: 3.7977359294891357
Validation loss: 2.5288386908910607

Epoch: 5| Step: 1
Training loss: 2.9359688758850098
Validation loss: 2.5297589609699864

Epoch: 5| Step: 2
Training loss: 2.615424633026123
Validation loss: 2.530243319849814

Epoch: 5| Step: 3
Training loss: 2.0039286613464355
Validation loss: 2.5238156780119865

Epoch: 5| Step: 4
Training loss: 2.9542269706726074
Validation loss: 2.527019851951189

Epoch: 5| Step: 5
Training loss: 3.3366668224334717
Validation loss: 2.5196083925103627

Epoch: 5| Step: 6
Training loss: 2.234419822692871
Validation loss: 2.5159955691265803

Epoch: 5| Step: 7
Training loss: 2.446350574493408
Validation loss: 2.5181817059875815

Epoch: 5| Step: 8
Training loss: 2.5585994720458984
Validation loss: 2.5174946759336736

Epoch: 5| Step: 9
Training loss: 2.3452930450439453
Validation loss: 2.5237486362457275

Epoch: 5| Step: 10
Training loss: 3.084371566772461
Validation loss: 2.538921651019845

Epoch: 18| Step: 0
Training loss: 2.8681607246398926
Validation loss: 2.529804709137127

Epoch: 5| Step: 1
Training loss: 2.52933669090271
Validation loss: 2.5120530538661505

Epoch: 5| Step: 2
Training loss: 2.426426410675049
Validation loss: 2.5128954713062575

Epoch: 5| Step: 3
Training loss: 2.523594379425049
Validation loss: 2.5094157777806765

Epoch: 5| Step: 4
Training loss: 2.937927722930908
Validation loss: 2.5060951735383723

Epoch: 5| Step: 5
Training loss: 2.3242077827453613
Validation loss: 2.507594685400686

Epoch: 5| Step: 6
Training loss: 2.6243650913238525
Validation loss: 2.5195990159947383

Epoch: 5| Step: 7
Training loss: 2.971482276916504
Validation loss: 2.567497637964064

Epoch: 5| Step: 8
Training loss: 3.0975093841552734
Validation loss: 2.5874986058922222

Epoch: 5| Step: 9
Training loss: 2.9676265716552734
Validation loss: 2.522626502539522

Epoch: 5| Step: 10
Training loss: 3.1449692249298096
Validation loss: 2.4979839606951644

Epoch: 19| Step: 0
Training loss: 2.497891902923584
Validation loss: 2.5017198106294036

Epoch: 5| Step: 1
Training loss: 2.728519916534424
Validation loss: 2.5188113348458403

Epoch: 5| Step: 2
Training loss: 2.2979989051818848
Validation loss: 2.5332442919413247

Epoch: 5| Step: 3
Training loss: 2.631822109222412
Validation loss: 2.5323692778105378

Epoch: 5| Step: 4
Training loss: 2.5019021034240723
Validation loss: 2.523020790469262

Epoch: 5| Step: 5
Training loss: 2.986360549926758
Validation loss: 2.5270604138733237

Epoch: 5| Step: 6
Training loss: 3.0628867149353027
Validation loss: 2.5166064257262857

Epoch: 5| Step: 7
Training loss: 3.0347633361816406
Validation loss: 2.5119892909962642

Epoch: 5| Step: 8
Training loss: 2.8663604259490967
Validation loss: 2.499955605435115

Epoch: 5| Step: 9
Training loss: 2.982699155807495
Validation loss: 2.486656259464961

Epoch: 5| Step: 10
Training loss: 2.725236415863037
Validation loss: 2.4835108454509447

Epoch: 20| Step: 0
Training loss: 2.396635055541992
Validation loss: 2.481499861645442

Epoch: 5| Step: 1
Training loss: 2.990717649459839
Validation loss: 2.5322685574972503

Epoch: 5| Step: 2
Training loss: 3.3315823078155518
Validation loss: 2.5791927742701706

Epoch: 5| Step: 3
Training loss: 2.601860523223877
Validation loss: 2.55703043681319

Epoch: 5| Step: 4
Training loss: 2.656005620956421
Validation loss: 2.481118168882144

Epoch: 5| Step: 5
Training loss: 2.62214732170105
Validation loss: 2.4755349005422285

Epoch: 5| Step: 6
Training loss: 2.6982650756835938
Validation loss: 2.486868932682981

Epoch: 5| Step: 7
Training loss: 2.4513862133026123
Validation loss: 2.4907785538704164

Epoch: 5| Step: 8
Training loss: 2.621211290359497
Validation loss: 2.4964750633444837

Epoch: 5| Step: 9
Training loss: 2.7291314601898193
Validation loss: 2.4920259137307443

Epoch: 5| Step: 10
Training loss: 3.1188089847564697
Validation loss: 2.485970327931066

Epoch: 21| Step: 0
Training loss: 2.4478988647460938
Validation loss: 2.48279631522394

Epoch: 5| Step: 1
Training loss: 1.7428478002548218
Validation loss: 2.4788133559688443

Epoch: 5| Step: 2
Training loss: 2.9534385204315186
Validation loss: 2.480132338821247

Epoch: 5| Step: 3
Training loss: 2.134708881378174
Validation loss: 2.4864419121896066

Epoch: 5| Step: 4
Training loss: 3.10499906539917
Validation loss: 2.5022436059931272

Epoch: 5| Step: 5
Training loss: 3.458216905593872
Validation loss: 2.496529976526896

Epoch: 5| Step: 6
Training loss: 2.7161455154418945
Validation loss: 2.4974738526087936

Epoch: 5| Step: 7
Training loss: 3.020254135131836
Validation loss: 2.4769325025619997

Epoch: 5| Step: 8
Training loss: 2.655210256576538
Validation loss: 2.4623471870217273

Epoch: 5| Step: 9
Training loss: 2.857722043991089
Validation loss: 2.4573225231580835

Epoch: 5| Step: 10
Training loss: 2.824528932571411
Validation loss: 2.4637307095271286

Epoch: 22| Step: 0
Training loss: 3.3987159729003906
Validation loss: 2.4710858124558643

Epoch: 5| Step: 1
Training loss: 2.686264753341675
Validation loss: 2.463573722429173

Epoch: 5| Step: 2
Training loss: 3.240988254547119
Validation loss: 2.457656652696671

Epoch: 5| Step: 3
Training loss: 1.9416621923446655
Validation loss: 2.4497438041112756

Epoch: 5| Step: 4
Training loss: 2.7308714389801025
Validation loss: 2.45427083200024

Epoch: 5| Step: 5
Training loss: 2.101046323776245
Validation loss: 2.466141723817395

Epoch: 5| Step: 6
Training loss: 3.2158493995666504
Validation loss: 2.469087882708478

Epoch: 5| Step: 7
Training loss: 3.1889262199401855
Validation loss: 2.4538213719603834

Epoch: 5| Step: 8
Training loss: 1.945591926574707
Validation loss: 2.4466811328805904

Epoch: 5| Step: 9
Training loss: 2.8988537788391113
Validation loss: 2.444243102945307

Epoch: 5| Step: 10
Training loss: 2.2699975967407227
Validation loss: 2.4346240515350015

Epoch: 23| Step: 0
Training loss: 3.120408058166504
Validation loss: 2.4326568111296623

Epoch: 5| Step: 1
Training loss: 2.594209671020508
Validation loss: 2.4314351927849556

Epoch: 5| Step: 2
Training loss: 2.8814663887023926
Validation loss: 2.432830382418889

Epoch: 5| Step: 3
Training loss: 3.395179033279419
Validation loss: 2.445578375170308

Epoch: 5| Step: 4
Training loss: 2.74953293800354
Validation loss: 2.4567416867902203

Epoch: 5| Step: 5
Training loss: 2.808738946914673
Validation loss: 2.4751987354729765

Epoch: 5| Step: 6
Training loss: 2.8575732707977295
Validation loss: 2.464306508341143

Epoch: 5| Step: 7
Training loss: 2.0559537410736084
Validation loss: 2.4294200610089045

Epoch: 5| Step: 8
Training loss: 2.1936867237091064
Validation loss: 2.4160299634420745

Epoch: 5| Step: 9
Training loss: 2.799128293991089
Validation loss: 2.421659238876835

Epoch: 5| Step: 10
Training loss: 1.9434194564819336
Validation loss: 2.4150815343344085

Epoch: 24| Step: 0
Training loss: 2.009253740310669
Validation loss: 2.42040184492706

Epoch: 5| Step: 1
Training loss: 2.150380849838257
Validation loss: 2.417689819489756

Epoch: 5| Step: 2
Training loss: 3.490196704864502
Validation loss: 2.441064719230898

Epoch: 5| Step: 3
Training loss: 2.1219913959503174
Validation loss: 2.4333805499538297

Epoch: 5| Step: 4
Training loss: 3.1756668090820312
Validation loss: 2.4442254420249694

Epoch: 5| Step: 5
Training loss: 2.933216094970703
Validation loss: 2.457731931440292

Epoch: 5| Step: 6
Training loss: 2.5206918716430664
Validation loss: 2.470101228324316

Epoch: 5| Step: 7
Training loss: 2.8802859783172607
Validation loss: 2.4843842265426472

Epoch: 5| Step: 8
Training loss: 2.437610149383545
Validation loss: 2.4659762792689826

Epoch: 5| Step: 9
Training loss: 2.5566210746765137
Validation loss: 2.440350632513723

Epoch: 5| Step: 10
Training loss: 3.168447256088257
Validation loss: 2.41203510761261

Epoch: 25| Step: 0
Training loss: 2.9554829597473145
Validation loss: 2.4048352805517053

Epoch: 5| Step: 1
Training loss: 2.482260227203369
Validation loss: 2.4196973077712522

Epoch: 5| Step: 2
Training loss: 2.352938413619995
Validation loss: 2.423362203823623

Epoch: 5| Step: 3
Training loss: 3.309445858001709
Validation loss: 2.422158774509225

Epoch: 5| Step: 4
Training loss: 2.8664045333862305
Validation loss: 2.41651463636788

Epoch: 5| Step: 5
Training loss: 2.2109084129333496
Validation loss: 2.418521968267297

Epoch: 5| Step: 6
Training loss: 2.7686305046081543
Validation loss: 2.4185299770806425

Epoch: 5| Step: 7
Training loss: 2.5636799335479736
Validation loss: 2.410370406284127

Epoch: 5| Step: 8
Training loss: 2.400090456008911
Validation loss: 2.412408608262257

Epoch: 5| Step: 9
Training loss: 2.6485798358917236
Validation loss: 2.4140960490831764

Epoch: 5| Step: 10
Training loss: 2.9924726486206055
Validation loss: 2.4144304926677416

Epoch: 26| Step: 0
Training loss: 2.71854305267334
Validation loss: 2.3987164087192987

Epoch: 5| Step: 1
Training loss: 2.373931407928467
Validation loss: 2.3976191307908747

Epoch: 5| Step: 2
Training loss: 2.007445812225342
Validation loss: 2.40325855183345

Epoch: 5| Step: 3
Training loss: 2.545154094696045
Validation loss: 2.4265292344554776

Epoch: 5| Step: 4
Training loss: 3.071350574493408
Validation loss: 2.464758837094871

Epoch: 5| Step: 5
Training loss: 2.9936444759368896
Validation loss: 2.487353160817136

Epoch: 5| Step: 6
Training loss: 2.5054450035095215
Validation loss: 2.483460098184565

Epoch: 5| Step: 7
Training loss: 3.0350773334503174
Validation loss: 2.458534609886908

Epoch: 5| Step: 8
Training loss: 2.4941186904907227
Validation loss: 2.4142906870893253

Epoch: 5| Step: 9
Training loss: 3.030144453048706
Validation loss: 2.3938343166023173

Epoch: 5| Step: 10
Training loss: 2.5357859134674072
Validation loss: 2.3886625100207586

Epoch: 27| Step: 0
Training loss: 2.5562639236450195
Validation loss: 2.391875607993013

Epoch: 5| Step: 1
Training loss: 3.4156012535095215
Validation loss: 2.3970262927393757

Epoch: 5| Step: 2
Training loss: 2.770336627960205
Validation loss: 2.3967680110726306

Epoch: 5| Step: 3
Training loss: 2.7709453105926514
Validation loss: 2.398488331866521

Epoch: 5| Step: 4
Training loss: 2.431105136871338
Validation loss: 2.3956838192478305

Epoch: 5| Step: 5
Training loss: 2.9988791942596436
Validation loss: 2.39135556579918

Epoch: 5| Step: 6
Training loss: 2.6311352252960205
Validation loss: 2.3940926136509066

Epoch: 5| Step: 7
Training loss: 2.3086001873016357
Validation loss: 2.3983382768528436

Epoch: 5| Step: 8
Training loss: 2.7333590984344482
Validation loss: 2.396984125978203

Epoch: 5| Step: 9
Training loss: 1.909867525100708
Validation loss: 2.4016385168157597

Epoch: 5| Step: 10
Training loss: 2.699533700942993
Validation loss: 2.3935905553961314

Epoch: 28| Step: 0
Training loss: 2.7512261867523193
Validation loss: 2.413639494167861

Epoch: 5| Step: 1
Training loss: 2.0376996994018555
Validation loss: 2.4107917329316497

Epoch: 5| Step: 2
Training loss: 2.6406311988830566
Validation loss: 2.4363074892310688

Epoch: 5| Step: 3
Training loss: 3.210524082183838
Validation loss: 2.438425669106104

Epoch: 5| Step: 4
Training loss: 2.023638963699341
Validation loss: 2.4212949263152255

Epoch: 5| Step: 5
Training loss: 2.6782302856445312
Validation loss: 2.4023200799060125

Epoch: 5| Step: 6
Training loss: 2.6368355751037598
Validation loss: 2.388062423275363

Epoch: 5| Step: 7
Training loss: 2.5527946949005127
Validation loss: 2.3910122174088673

Epoch: 5| Step: 8
Training loss: 2.438308000564575
Validation loss: 2.390801801476427

Epoch: 5| Step: 9
Training loss: 2.9797186851501465
Validation loss: 2.397046143008817

Epoch: 5| Step: 10
Training loss: 3.276456832885742
Validation loss: 2.4005211194356284

Epoch: 29| Step: 0
Training loss: 2.261122941970825
Validation loss: 2.397536470044044

Epoch: 5| Step: 1
Training loss: 3.265718936920166
Validation loss: 2.401961326599121

Epoch: 5| Step: 2
Training loss: 2.862443208694458
Validation loss: 2.396469662266393

Epoch: 5| Step: 3
Training loss: 2.980516195297241
Validation loss: 2.4023798409328667

Epoch: 5| Step: 4
Training loss: 2.5067107677459717
Validation loss: 2.392166458150392

Epoch: 5| Step: 5
Training loss: 2.208159923553467
Validation loss: 2.401481113126201

Epoch: 5| Step: 6
Training loss: 2.3129324913024902
Validation loss: 2.4064132987812

Epoch: 5| Step: 7
Training loss: 2.284289836883545
Validation loss: 2.3970488117587183

Epoch: 5| Step: 8
Training loss: 3.3380935192108154
Validation loss: 2.3941229107559368

Epoch: 5| Step: 9
Training loss: 2.6950411796569824
Validation loss: 2.381511934341923

Epoch: 5| Step: 10
Training loss: 2.19852352142334
Validation loss: 2.3759261715796685

Epoch: 30| Step: 0
Training loss: 2.304016590118408
Validation loss: 2.3867618319808797

Epoch: 5| Step: 1
Training loss: 2.294363498687744
Validation loss: 2.394215065945861

Epoch: 5| Step: 2
Training loss: 3.175414562225342
Validation loss: 2.3943681511827695

Epoch: 5| Step: 3
Training loss: 2.891864061355591
Validation loss: 2.3755117154890493

Epoch: 5| Step: 4
Training loss: 1.5871738195419312
Validation loss: 2.367860132648099

Epoch: 5| Step: 5
Training loss: 2.5784287452697754
Validation loss: 2.360680833939583

Epoch: 5| Step: 6
Training loss: 3.0762248039245605
Validation loss: 2.363259925637194

Epoch: 5| Step: 7
Training loss: 2.627797842025757
Validation loss: 2.3700904718009372

Epoch: 5| Step: 8
Training loss: 3.0842361450195312
Validation loss: 2.365938940355855

Epoch: 5| Step: 9
Training loss: 2.919571876525879
Validation loss: 2.3729266428178355

Epoch: 5| Step: 10
Training loss: 2.565735340118408
Validation loss: 2.375713699607439

Epoch: 31| Step: 0
Training loss: 2.4268290996551514
Validation loss: 2.412522913307272

Epoch: 5| Step: 1
Training loss: 2.6816012859344482
Validation loss: 2.45753203668902

Epoch: 5| Step: 2
Training loss: 2.9409351348876953
Validation loss: 2.444932299275552

Epoch: 5| Step: 3
Training loss: 2.8038992881774902
Validation loss: 2.41416661970077

Epoch: 5| Step: 4
Training loss: 2.28383469581604
Validation loss: 2.378392775853475

Epoch: 5| Step: 5
Training loss: 2.878443479537964
Validation loss: 2.3710131004292476

Epoch: 5| Step: 6
Training loss: 2.7292816638946533
Validation loss: 2.37465194220184

Epoch: 5| Step: 7
Training loss: 2.9577910900115967
Validation loss: 2.3901834641733477

Epoch: 5| Step: 8
Training loss: 1.528989553451538
Validation loss: 2.391934351254535

Epoch: 5| Step: 9
Training loss: 2.741891622543335
Validation loss: 2.3924089144634944

Epoch: 5| Step: 10
Training loss: 3.02724552154541
Validation loss: 2.3768286807562715

Epoch: 32| Step: 0
Training loss: 2.587787628173828
Validation loss: 2.3588455287359094

Epoch: 5| Step: 1
Training loss: 2.756648302078247
Validation loss: 2.3580265327166487

Epoch: 5| Step: 2
Training loss: 2.9134292602539062
Validation loss: 2.3642622347800963

Epoch: 5| Step: 3
Training loss: 2.455366849899292
Validation loss: 2.365406988769449

Epoch: 5| Step: 4
Training loss: 2.3968427181243896
Validation loss: 2.380043714277206

Epoch: 5| Step: 5
Training loss: 2.7416515350341797
Validation loss: 2.3850348636668217

Epoch: 5| Step: 6
Training loss: 1.78708016872406
Validation loss: 2.3821378318212365

Epoch: 5| Step: 7
Training loss: 3.271294355392456
Validation loss: 2.3650383026369157

Epoch: 5| Step: 8
Training loss: 2.8967013359069824
Validation loss: 2.353059020093692

Epoch: 5| Step: 9
Training loss: 2.1993660926818848
Validation loss: 2.3450295745685534

Epoch: 5| Step: 10
Training loss: 2.784252643585205
Validation loss: 2.3442465438637683

Epoch: 33| Step: 0
Training loss: 2.0326719284057617
Validation loss: 2.34092467318299

Epoch: 5| Step: 1
Training loss: 2.57426381111145
Validation loss: 2.340692094577256

Epoch: 5| Step: 2
Training loss: 2.8099799156188965
Validation loss: 2.337352070757138

Epoch: 5| Step: 3
Training loss: 2.5987162590026855
Validation loss: 2.3372745462643203

Epoch: 5| Step: 4
Training loss: 1.5160868167877197
Validation loss: 2.356521298808436

Epoch: 5| Step: 5
Training loss: 2.7498297691345215
Validation loss: 2.3700579904740855

Epoch: 5| Step: 6
Training loss: 3.1889443397521973
Validation loss: 2.388010819753011

Epoch: 5| Step: 7
Training loss: 2.9547958374023438
Validation loss: 2.3813988136988815

Epoch: 5| Step: 8
Training loss: 3.42900013923645
Validation loss: 2.3688278441788047

Epoch: 5| Step: 9
Training loss: 2.238262891769409
Validation loss: 2.358653055724277

Epoch: 5| Step: 10
Training loss: 2.7855043411254883
Validation loss: 2.348618922695037

Epoch: 34| Step: 0
Training loss: 2.3113832473754883
Validation loss: 2.3437609031636226

Epoch: 5| Step: 1
Training loss: 2.72232723236084
Validation loss: 2.3367133909656155

Epoch: 5| Step: 2
Training loss: 3.2253060340881348
Validation loss: 2.3349437457258984

Epoch: 5| Step: 3
Training loss: 2.1345534324645996
Validation loss: 2.339663915736701

Epoch: 5| Step: 4
Training loss: 2.515206813812256
Validation loss: 2.3512904900376514

Epoch: 5| Step: 5
Training loss: 2.433335542678833
Validation loss: 2.343370171003444

Epoch: 5| Step: 6
Training loss: 3.102200984954834
Validation loss: 2.3297567034280426

Epoch: 5| Step: 7
Training loss: 3.0024547576904297
Validation loss: 2.321059360299059

Epoch: 5| Step: 8
Training loss: 2.679807186126709
Validation loss: 2.3249733089118876

Epoch: 5| Step: 9
Training loss: 1.9156993627548218
Validation loss: 2.322785628739224

Epoch: 5| Step: 10
Training loss: 2.658174991607666
Validation loss: 2.3189959808062484

Epoch: 35| Step: 0
Training loss: 2.5356192588806152
Validation loss: 2.3220685271806616

Epoch: 5| Step: 1
Training loss: 2.5949997901916504
Validation loss: 2.334481998156476

Epoch: 5| Step: 2
Training loss: 2.2017452716827393
Validation loss: 2.348475012727963

Epoch: 5| Step: 3
Training loss: 3.0400030612945557
Validation loss: 2.362615575072586

Epoch: 5| Step: 4
Training loss: 2.203366756439209
Validation loss: 2.381951268001269

Epoch: 5| Step: 5
Training loss: 3.0835046768188477
Validation loss: 2.3992464696207354

Epoch: 5| Step: 6
Training loss: 2.648200511932373
Validation loss: 2.377815866983065

Epoch: 5| Step: 7
Training loss: 2.2663700580596924
Validation loss: 2.3696666148401078

Epoch: 5| Step: 8
Training loss: 3.021360397338867
Validation loss: 2.343898315583506

Epoch: 5| Step: 9
Training loss: 2.3855292797088623
Validation loss: 2.3257997510253743

Epoch: 5| Step: 10
Training loss: 2.5382020473480225
Validation loss: 2.324185961036272

Epoch: 36| Step: 0
Training loss: 2.8651111125946045
Validation loss: 2.3232736638797227

Epoch: 5| Step: 1
Training loss: 2.365309953689575
Validation loss: 2.324269248593238

Epoch: 5| Step: 2
Training loss: 1.8936141729354858
Validation loss: 2.314247836348831

Epoch: 5| Step: 3
Training loss: 2.189061403274536
Validation loss: 2.313285573836296

Epoch: 5| Step: 4
Training loss: 2.825313091278076
Validation loss: 2.314347711942529

Epoch: 5| Step: 5
Training loss: 2.9609436988830566
Validation loss: 2.317219324009393

Epoch: 5| Step: 6
Training loss: 2.621265411376953
Validation loss: 2.3227464409284693

Epoch: 5| Step: 7
Training loss: 2.8320345878601074
Validation loss: 2.3245831971527426

Epoch: 5| Step: 8
Training loss: 2.4625048637390137
Validation loss: 2.311711367740426

Epoch: 5| Step: 9
Training loss: 2.5432872772216797
Validation loss: 2.3061007761186167

Epoch: 5| Step: 10
Training loss: 3.0588150024414062
Validation loss: 2.3118883512353383

Epoch: 37| Step: 0
Training loss: 2.3074357509613037
Validation loss: 2.3249421376054005

Epoch: 5| Step: 1
Training loss: 2.332496166229248
Validation loss: 2.3436520535458802

Epoch: 5| Step: 2
Training loss: 2.8917911052703857
Validation loss: 2.3776019260447514

Epoch: 5| Step: 3
Training loss: 2.516629695892334
Validation loss: 2.3909899009171354

Epoch: 5| Step: 4
Training loss: 2.497868537902832
Validation loss: 2.3538021528592674

Epoch: 5| Step: 5
Training loss: 2.1438770294189453
Validation loss: 2.3419536698249077

Epoch: 5| Step: 6
Training loss: 2.9953866004943848
Validation loss: 2.326633071386686

Epoch: 5| Step: 7
Training loss: 2.394440174102783
Validation loss: 2.310931033985589

Epoch: 5| Step: 8
Training loss: 2.4525413513183594
Validation loss: 2.3005168566139798

Epoch: 5| Step: 9
Training loss: 2.905367612838745
Validation loss: 2.2959296498247372

Epoch: 5| Step: 10
Training loss: 3.101451873779297
Validation loss: 2.2984153686031217

Epoch: 38| Step: 0
Training loss: 2.566765546798706
Validation loss: 2.3027677792374805

Epoch: 5| Step: 1
Training loss: 2.5276668071746826
Validation loss: 2.303601513626755

Epoch: 5| Step: 2
Training loss: 3.1063027381896973
Validation loss: 2.3003333922355407

Epoch: 5| Step: 3
Training loss: 2.4033026695251465
Validation loss: 2.306562021214475

Epoch: 5| Step: 4
Training loss: 2.2389261722564697
Validation loss: 2.3238924267471477

Epoch: 5| Step: 5
Training loss: 2.8209877014160156
Validation loss: 2.3301910995155253

Epoch: 5| Step: 6
Training loss: 2.530388832092285
Validation loss: 2.382710410702613

Epoch: 5| Step: 7
Training loss: 2.9577410221099854
Validation loss: 2.4044097623517438

Epoch: 5| Step: 8
Training loss: 2.522197723388672
Validation loss: 2.3967756430308023

Epoch: 5| Step: 9
Training loss: 2.585453987121582
Validation loss: 2.378767696760034

Epoch: 5| Step: 10
Training loss: 2.2649667263031006
Validation loss: 2.364176345127885

Epoch: 39| Step: 0
Training loss: 2.4302120208740234
Validation loss: 2.3383070063847367

Epoch: 5| Step: 1
Training loss: 3.336894989013672
Validation loss: 2.326958607601863

Epoch: 5| Step: 2
Training loss: 2.296140193939209
Validation loss: 2.3252363410047305

Epoch: 5| Step: 3
Training loss: 2.303475856781006
Validation loss: 2.3279613320545485

Epoch: 5| Step: 4
Training loss: 2.333751916885376
Validation loss: 2.3284781261156966

Epoch: 5| Step: 5
Training loss: 2.8622231483459473
Validation loss: 2.3342054261956164

Epoch: 5| Step: 6
Training loss: 2.7598323822021484
Validation loss: 2.335500596671976

Epoch: 5| Step: 7
Training loss: 2.85661244392395
Validation loss: 2.325906915049399

Epoch: 5| Step: 8
Training loss: 2.729048252105713
Validation loss: 2.319809875180644

Epoch: 5| Step: 9
Training loss: 2.0722172260284424
Validation loss: 2.307025040349653

Epoch: 5| Step: 10
Training loss: 2.3584609031677246
Validation loss: 2.2965436725206274

Epoch: 40| Step: 0
Training loss: 2.291719675064087
Validation loss: 2.292784406292823

Epoch: 5| Step: 1
Training loss: 2.638502597808838
Validation loss: 2.3021714789893037

Epoch: 5| Step: 2
Training loss: 2.564493417739868
Validation loss: 2.3077926174286874

Epoch: 5| Step: 3
Training loss: 2.6569201946258545
Validation loss: 2.304735806680495

Epoch: 5| Step: 4
Training loss: 1.9494218826293945
Validation loss: 2.292566914712229

Epoch: 5| Step: 5
Training loss: 2.5838780403137207
Validation loss: 2.31149354545019

Epoch: 5| Step: 6
Training loss: 2.7933685779571533
Validation loss: 2.3293816658758346

Epoch: 5| Step: 7
Training loss: 2.5748467445373535
Validation loss: 2.333173655694531

Epoch: 5| Step: 8
Training loss: 2.5357513427734375
Validation loss: 2.3270004667261595

Epoch: 5| Step: 9
Training loss: 3.1248104572296143
Validation loss: 2.299694641943901

Epoch: 5| Step: 10
Training loss: 2.611665725708008
Validation loss: 2.2916110895013295

Epoch: 41| Step: 0
Training loss: 2.1824727058410645
Validation loss: 2.2843652258637133

Epoch: 5| Step: 1
Training loss: 2.9037394523620605
Validation loss: 2.2801415510075067

Epoch: 5| Step: 2
Training loss: 2.3715407848358154
Validation loss: 2.281158354974562

Epoch: 5| Step: 3
Training loss: 2.6978800296783447
Validation loss: 2.2783700266192035

Epoch: 5| Step: 4
Training loss: 2.7240824699401855
Validation loss: 2.294138621258479

Epoch: 5| Step: 5
Training loss: 2.2438015937805176
Validation loss: 2.3020633856455484

Epoch: 5| Step: 6
Training loss: 2.93503999710083
Validation loss: 2.3381491117579962

Epoch: 5| Step: 7
Training loss: 2.398130178451538
Validation loss: 2.3556021618586716

Epoch: 5| Step: 8
Training loss: 2.9006733894348145
Validation loss: 2.3699602080929663

Epoch: 5| Step: 9
Training loss: 2.6983730792999268
Validation loss: 2.3552611463813373

Epoch: 5| Step: 10
Training loss: 2.1738460063934326
Validation loss: 2.326960266277354

Epoch: 42| Step: 0
Training loss: 2.4132819175720215
Validation loss: 2.306392636350406

Epoch: 5| Step: 1
Training loss: 2.652275800704956
Validation loss: 2.294510551678237

Epoch: 5| Step: 2
Training loss: 2.418318510055542
Validation loss: 2.2881268326954176

Epoch: 5| Step: 3
Training loss: 2.7233078479766846
Validation loss: 2.2893675117082495

Epoch: 5| Step: 4
Training loss: 2.613770008087158
Validation loss: 2.2860782684818393

Epoch: 5| Step: 5
Training loss: 2.3536558151245117
Validation loss: 2.280849764423986

Epoch: 5| Step: 6
Training loss: 2.472707986831665
Validation loss: 2.28317169989309

Epoch: 5| Step: 7
Training loss: 2.6667494773864746
Validation loss: 2.280430316925049

Epoch: 5| Step: 8
Training loss: 2.052121639251709
Validation loss: 2.2799927252595142

Epoch: 5| Step: 9
Training loss: 2.9331955909729004
Validation loss: 2.286514569354314

Epoch: 5| Step: 10
Training loss: 2.9318881034851074
Validation loss: 2.2936847389385266

Epoch: 43| Step: 0
Training loss: 2.2671165466308594
Validation loss: 2.2910229916213662

Epoch: 5| Step: 1
Training loss: 2.868542194366455
Validation loss: 2.295549564464118

Epoch: 5| Step: 2
Training loss: 2.180962085723877
Validation loss: 2.3132621754882154

Epoch: 5| Step: 3
Training loss: 2.233274221420288
Validation loss: 2.321012158547678

Epoch: 5| Step: 4
Training loss: 2.2453548908233643
Validation loss: 2.295181051377327

Epoch: 5| Step: 5
Training loss: 2.953702449798584
Validation loss: 2.2851127937275875

Epoch: 5| Step: 6
Training loss: 2.4680919647216797
Validation loss: 2.279926141103109

Epoch: 5| Step: 7
Training loss: 2.410254716873169
Validation loss: 2.2770042470706406

Epoch: 5| Step: 8
Training loss: 2.7169108390808105
Validation loss: 2.2744836038158787

Epoch: 5| Step: 9
Training loss: 2.8247463703155518
Validation loss: 2.267384918787146

Epoch: 5| Step: 10
Training loss: 2.9938549995422363
Validation loss: 2.274840598465294

Epoch: 44| Step: 0
Training loss: 2.1258301734924316
Validation loss: 2.271024465560913

Epoch: 5| Step: 1
Training loss: 2.0711581707000732
Validation loss: 2.2737275759379068

Epoch: 5| Step: 2
Training loss: 3.3585517406463623
Validation loss: 2.2735958714638986

Epoch: 5| Step: 3
Training loss: 2.5561535358428955
Validation loss: 2.277858877694735

Epoch: 5| Step: 4
Training loss: 2.481196641921997
Validation loss: 2.278930846080985

Epoch: 5| Step: 5
Training loss: 2.3804681301116943
Validation loss: 2.2699561747171546

Epoch: 5| Step: 6
Training loss: 2.668421506881714
Validation loss: 2.2689172631950787

Epoch: 5| Step: 7
Training loss: 2.431231737136841
Validation loss: 2.2609478222426547

Epoch: 5| Step: 8
Training loss: 3.133427143096924
Validation loss: 2.25720480949648

Epoch: 5| Step: 9
Training loss: 2.8689398765563965
Validation loss: 2.276797784272061

Epoch: 5| Step: 10
Training loss: 1.8232948780059814
Validation loss: 2.2888372482792025

Epoch: 45| Step: 0
Training loss: 2.498751163482666
Validation loss: 2.2964104503713627

Epoch: 5| Step: 1
Training loss: 2.5266528129577637
Validation loss: 2.3081384243503695

Epoch: 5| Step: 2
Training loss: 2.4141430854797363
Validation loss: 2.3051324813596663

Epoch: 5| Step: 3
Training loss: 2.749955415725708
Validation loss: 2.3104924412183863

Epoch: 5| Step: 4
Training loss: 2.84275484085083
Validation loss: 2.3041603308852

Epoch: 5| Step: 5
Training loss: 2.116532802581787
Validation loss: 2.29602034630314

Epoch: 5| Step: 6
Training loss: 2.457956314086914
Validation loss: 2.2849928127822055

Epoch: 5| Step: 7
Training loss: 3.190986156463623
Validation loss: 2.275140457255866

Epoch: 5| Step: 8
Training loss: 2.581037998199463
Validation loss: 2.2553035405374344

Epoch: 5| Step: 9
Training loss: 2.4375741481781006
Validation loss: 2.253565275540916

Epoch: 5| Step: 10
Training loss: 2.1058568954467773
Validation loss: 2.253963537113641

Epoch: 46| Step: 0
Training loss: 2.6186423301696777
Validation loss: 2.2534920438643424

Epoch: 5| Step: 1
Training loss: 2.4193520545959473
Validation loss: 2.2586433195298716

Epoch: 5| Step: 2
Training loss: 3.2979865074157715
Validation loss: 2.2583366824734594

Epoch: 5| Step: 3
Training loss: 1.798031210899353
Validation loss: 2.2613143485079528

Epoch: 5| Step: 4
Training loss: 2.8816287517547607
Validation loss: 2.273003129548924

Epoch: 5| Step: 5
Training loss: 2.2637381553649902
Validation loss: 2.2768902932443926

Epoch: 5| Step: 6
Training loss: 2.6315486431121826
Validation loss: 2.2931534782532723

Epoch: 5| Step: 7
Training loss: 2.740604877471924
Validation loss: 2.306165243989678

Epoch: 5| Step: 8
Training loss: 2.4821102619171143
Validation loss: 2.296275684910436

Epoch: 5| Step: 9
Training loss: 2.5604612827301025
Validation loss: 2.2779222585821666

Epoch: 5| Step: 10
Training loss: 2.2477428913116455
Validation loss: 2.2709767844087336

Epoch: 47| Step: 0
Training loss: 3.10516619682312
Validation loss: 2.2691103642986667

Epoch: 5| Step: 1
Training loss: 3.3774662017822266
Validation loss: 2.268997123164515

Epoch: 5| Step: 2
Training loss: 2.2196576595306396
Validation loss: 2.2668598800577144

Epoch: 5| Step: 3
Training loss: 2.256880283355713
Validation loss: 2.276286220037809

Epoch: 5| Step: 4
Training loss: 3.026555299758911
Validation loss: 2.286256636342695

Epoch: 5| Step: 5
Training loss: 2.580975294113159
Validation loss: 2.2737871113643853

Epoch: 5| Step: 6
Training loss: 2.1296005249023438
Validation loss: 2.2675220094701296

Epoch: 5| Step: 7
Training loss: 1.8296797275543213
Validation loss: 2.2686849435170493

Epoch: 5| Step: 8
Training loss: 1.8571803569793701
Validation loss: 2.2479975402996106

Epoch: 5| Step: 9
Training loss: 2.9320194721221924
Validation loss: 2.2461968391172347

Epoch: 5| Step: 10
Training loss: 2.5190680027008057
Validation loss: 2.2533089550592567

Epoch: 48| Step: 0
Training loss: 2.0042405128479004
Validation loss: 2.248641099981082

Epoch: 5| Step: 1
Training loss: 2.341158390045166
Validation loss: 2.2707224686940513

Epoch: 5| Step: 2
Training loss: 2.2528903484344482
Validation loss: 2.289299390649283

Epoch: 5| Step: 3
Training loss: 2.791295289993286
Validation loss: 2.281814741831954

Epoch: 5| Step: 4
Training loss: 2.885652542114258
Validation loss: 2.276311400116131

Epoch: 5| Step: 5
Training loss: 3.2582695484161377
Validation loss: 2.2572214090695946

Epoch: 5| Step: 6
Training loss: 2.009432077407837
Validation loss: 2.246744389175087

Epoch: 5| Step: 7
Training loss: 2.6042332649230957
Validation loss: 2.2455043510724138

Epoch: 5| Step: 8
Training loss: 3.230513095855713
Validation loss: 2.239307677874001

Epoch: 5| Step: 9
Training loss: 2.0365519523620605
Validation loss: 2.2458786759325253

Epoch: 5| Step: 10
Training loss: 2.447049617767334
Validation loss: 2.2402832661905596

Epoch: 49| Step: 0
Training loss: 2.2689316272735596
Validation loss: 2.245680811584637

Epoch: 5| Step: 1
Training loss: 2.4243321418762207
Validation loss: 2.261431678648918

Epoch: 5| Step: 2
Training loss: 2.9642155170440674
Validation loss: 2.269429301702848

Epoch: 5| Step: 3
Training loss: 2.1818594932556152
Validation loss: 2.2641421569290983

Epoch: 5| Step: 4
Training loss: 1.9865366220474243
Validation loss: 2.265736605531426

Epoch: 5| Step: 5
Training loss: 2.4733128547668457
Validation loss: 2.266905041151149

Epoch: 5| Step: 6
Training loss: 1.903306007385254
Validation loss: 2.266445944386144

Epoch: 5| Step: 7
Training loss: 2.2655417919158936
Validation loss: 2.25469139570831

Epoch: 5| Step: 8
Training loss: 2.8510890007019043
Validation loss: 2.2467223367383404

Epoch: 5| Step: 9
Training loss: 3.5253684520721436
Validation loss: 2.246706252456993

Epoch: 5| Step: 10
Training loss: 2.878004789352417
Validation loss: 2.253256477335448

Epoch: 50| Step: 0
Training loss: 2.737532377243042
Validation loss: 2.250070494990195

Epoch: 5| Step: 1
Training loss: 2.7135026454925537
Validation loss: 2.2856580159997426

Epoch: 5| Step: 2
Training loss: 2.6310336589813232
Validation loss: 2.2359174323338333

Epoch: 5| Step: 3
Training loss: 2.393155574798584
Validation loss: 2.220802168692312

Epoch: 5| Step: 4
Training loss: 3.410592555999756
Validation loss: 2.2235892998274935

Epoch: 5| Step: 5
Training loss: 2.6609981060028076
Validation loss: 2.2338015622990106

Epoch: 5| Step: 6
Training loss: 2.6297433376312256
Validation loss: 2.226212388725691

Epoch: 5| Step: 7
Training loss: 2.166419267654419
Validation loss: 2.2231224057494954

Epoch: 5| Step: 8
Training loss: 2.3712496757507324
Validation loss: 2.2227688220239457

Epoch: 5| Step: 9
Training loss: 2.154000997543335
Validation loss: 2.2299641691228396

Epoch: 5| Step: 10
Training loss: 1.9353922605514526
Validation loss: 2.2434933441941456

Epoch: 51| Step: 0
Training loss: 2.2311387062072754
Validation loss: 2.280683514892414

Epoch: 5| Step: 1
Training loss: 2.211195707321167
Validation loss: 2.297603702032438

Epoch: 5| Step: 2
Training loss: 2.2607483863830566
Validation loss: 2.3602167662753852

Epoch: 5| Step: 3
Training loss: 2.4371895790100098
Validation loss: 2.3684717865400415

Epoch: 5| Step: 4
Training loss: 3.243974208831787
Validation loss: 2.359012713996313

Epoch: 5| Step: 5
Training loss: 2.875462055206299
Validation loss: 2.30722648866715

Epoch: 5| Step: 6
Training loss: 3.317549228668213
Validation loss: 2.268578576785262

Epoch: 5| Step: 7
Training loss: 2.1999523639678955
Validation loss: 2.2568873128583355

Epoch: 5| Step: 8
Training loss: 2.0120108127593994
Validation loss: 2.25337048756179

Epoch: 5| Step: 9
Training loss: 2.0829341411590576
Validation loss: 2.259910278422858

Epoch: 5| Step: 10
Training loss: 3.1272661685943604
Validation loss: 2.2775731599459084

Epoch: 52| Step: 0
Training loss: 2.575268268585205
Validation loss: 2.336961352696983

Epoch: 5| Step: 1
Training loss: 2.0272202491760254
Validation loss: 2.3534095466777845

Epoch: 5| Step: 2
Training loss: 2.362375497817993
Validation loss: 2.381777932566981

Epoch: 5| Step: 3
Training loss: 2.8758630752563477
Validation loss: 2.3803925052765877

Epoch: 5| Step: 4
Training loss: 2.1200146675109863
Validation loss: 2.41384917946272

Epoch: 5| Step: 5
Training loss: 2.551126003265381
Validation loss: 2.502840518951416

Epoch: 5| Step: 6
Training loss: 3.1905245780944824
Validation loss: 2.3936811057470178

Epoch: 5| Step: 7
Training loss: 3.165856122970581
Validation loss: 2.334784956388576

Epoch: 5| Step: 8
Training loss: 2.5410168170928955
Validation loss: 2.331340656485609

Epoch: 5| Step: 9
Training loss: 2.6717371940612793
Validation loss: 2.3247844301244265

Epoch: 5| Step: 10
Training loss: 2.395627737045288
Validation loss: 2.3286141759605816

Epoch: 53| Step: 0
Training loss: 2.5739824771881104
Validation loss: 2.3222781073662544

Epoch: 5| Step: 1
Training loss: 2.751041889190674
Validation loss: 2.2988948052929294

Epoch: 5| Step: 2
Training loss: 2.2380502223968506
Validation loss: 2.294898827870687

Epoch: 5| Step: 3
Training loss: 2.4203572273254395
Validation loss: 2.2955923157353557

Epoch: 5| Step: 4
Training loss: 2.3785762786865234
Validation loss: 2.2980333374392603

Epoch: 5| Step: 5
Training loss: 2.232245922088623
Validation loss: 2.312835695923016

Epoch: 5| Step: 6
Training loss: 3.2081432342529297
Validation loss: 2.3069549837420062

Epoch: 5| Step: 7
Training loss: 2.9282965660095215
Validation loss: 2.3059551023667857

Epoch: 5| Step: 8
Training loss: 2.3273684978485107
Validation loss: 2.299123725583476

Epoch: 5| Step: 9
Training loss: 2.8154749870300293
Validation loss: 2.295185237802485

Epoch: 5| Step: 10
Training loss: 2.3347408771514893
Validation loss: 2.295582922556067

Epoch: 54| Step: 0
Training loss: 2.669417142868042
Validation loss: 2.285667678361298

Epoch: 5| Step: 1
Training loss: 2.7191720008850098
Validation loss: 2.267187733804026

Epoch: 5| Step: 2
Training loss: 2.1503663063049316
Validation loss: 2.2651067267182055

Epoch: 5| Step: 3
Training loss: 3.2315497398376465
Validation loss: 2.2788040689242783

Epoch: 5| Step: 4
Training loss: 2.948235511779785
Validation loss: 2.3010224603837535

Epoch: 5| Step: 5
Training loss: 2.4887263774871826
Validation loss: 2.299504003217143

Epoch: 5| Step: 6
Training loss: 2.4650306701660156
Validation loss: 2.3074681912699053

Epoch: 5| Step: 7
Training loss: 2.8024258613586426
Validation loss: 2.290200320623254

Epoch: 5| Step: 8
Training loss: 2.116260528564453
Validation loss: 2.2969578337925736

Epoch: 5| Step: 9
Training loss: 2.564824104309082
Validation loss: 2.300709460371284

Epoch: 5| Step: 10
Training loss: 1.924743890762329
Validation loss: 2.336780837787095

Epoch: 55| Step: 0
Training loss: 2.7682535648345947
Validation loss: 2.4086156839965494

Epoch: 5| Step: 1
Training loss: 2.574673652648926
Validation loss: 2.422448742774225

Epoch: 5| Step: 2
Training loss: 2.6748721599578857
Validation loss: 2.3927331637310725

Epoch: 5| Step: 3
Training loss: 2.213409900665283
Validation loss: 2.311243631506479

Epoch: 5| Step: 4
Training loss: 2.5371181964874268
Validation loss: 2.292339301878406

Epoch: 5| Step: 5
Training loss: 3.1931426525115967
Validation loss: 2.272815706909344

Epoch: 5| Step: 6
Training loss: 2.2286810874938965
Validation loss: 2.2619353314881683

Epoch: 5| Step: 7
Training loss: 2.790440320968628
Validation loss: 2.2507547511849353

Epoch: 5| Step: 8
Training loss: 2.3079538345336914
Validation loss: 2.2470730414954563

Epoch: 5| Step: 9
Training loss: 2.5499985218048096
Validation loss: 2.259806543268183

Epoch: 5| Step: 10
Training loss: 2.399998664855957
Validation loss: 2.263771362202142

Epoch: 56| Step: 0
Training loss: 2.1562609672546387
Validation loss: 2.291303957662275

Epoch: 5| Step: 1
Training loss: 2.5989670753479004
Validation loss: 2.2978208423942648

Epoch: 5| Step: 2
Training loss: 2.7613024711608887
Validation loss: 2.2899833212616625

Epoch: 5| Step: 3
Training loss: 2.9324569702148438
Validation loss: 2.2767992147835354

Epoch: 5| Step: 4
Training loss: 3.159336805343628
Validation loss: 2.263637693979407

Epoch: 5| Step: 5
Training loss: 1.4418531656265259
Validation loss: 2.2585391921381794

Epoch: 5| Step: 6
Training loss: 2.719316005706787
Validation loss: 2.2492578260360228

Epoch: 5| Step: 7
Training loss: 2.7205429077148438
Validation loss: 2.2606262135249313

Epoch: 5| Step: 8
Training loss: 2.6175270080566406
Validation loss: 2.2499434281420965

Epoch: 5| Step: 9
Training loss: 2.2180557250976562
Validation loss: 2.255482960772771

Epoch: 5| Step: 10
Training loss: 2.6416280269622803
Validation loss: 2.2488075328129593

Epoch: 57| Step: 0
Training loss: 2.7567474842071533
Validation loss: 2.254991549317555

Epoch: 5| Step: 1
Training loss: 2.2117393016815186
Validation loss: 2.261782915361466

Epoch: 5| Step: 2
Training loss: 2.7892816066741943
Validation loss: 2.2662770773774836

Epoch: 5| Step: 3
Training loss: 2.6712377071380615
Validation loss: 2.2727074315471034

Epoch: 5| Step: 4
Training loss: 2.627098560333252
Validation loss: 2.2784237733451267

Epoch: 5| Step: 5
Training loss: 2.3234033584594727
Validation loss: 2.2671915010739396

Epoch: 5| Step: 6
Training loss: 2.404536008834839
Validation loss: 2.2600618588027133

Epoch: 5| Step: 7
Training loss: 2.6949260234832764
Validation loss: 2.244304036581388

Epoch: 5| Step: 8
Training loss: 2.433150053024292
Validation loss: 2.242003453675137

Epoch: 5| Step: 9
Training loss: 2.098554849624634
Validation loss: 2.2222461174893122

Epoch: 5| Step: 10
Training loss: 2.918745279312134
Validation loss: 2.213171773059394

Epoch: 58| Step: 0
Training loss: 2.4991650581359863
Validation loss: 2.2199257086682063

Epoch: 5| Step: 1
Training loss: 2.7717642784118652
Validation loss: 2.230362258931642

Epoch: 5| Step: 2
Training loss: 2.934469699859619
Validation loss: 2.2444591881126486

Epoch: 5| Step: 3
Training loss: 2.591590404510498
Validation loss: 2.264507496228782

Epoch: 5| Step: 4
Training loss: 1.8903656005859375
Validation loss: 2.2571224909956737

Epoch: 5| Step: 5
Training loss: 2.89931583404541
Validation loss: 2.2319060243586057

Epoch: 5| Step: 6
Training loss: 1.9069583415985107
Validation loss: 2.229887475249588

Epoch: 5| Step: 7
Training loss: 2.290208101272583
Validation loss: 2.2377459900353545

Epoch: 5| Step: 8
Training loss: 2.5125699043273926
Validation loss: 2.2445009241821947

Epoch: 5| Step: 9
Training loss: 2.4548354148864746
Validation loss: 2.2527069212287985

Epoch: 5| Step: 10
Training loss: 3.016113519668579
Validation loss: 2.265536892798639

Epoch: 59| Step: 0
Training loss: 2.7628872394561768
Validation loss: 2.2913209315269225

Epoch: 5| Step: 1
Training loss: 2.6107444763183594
Validation loss: 2.276304475722774

Epoch: 5| Step: 2
Training loss: 2.6012842655181885
Validation loss: 2.259016557406354

Epoch: 5| Step: 3
Training loss: 2.0950491428375244
Validation loss: 2.253263327383226

Epoch: 5| Step: 4
Training loss: 2.7644083499908447
Validation loss: 2.234747068856352

Epoch: 5| Step: 5
Training loss: 1.9193490743637085
Validation loss: 2.248852211941955

Epoch: 5| Step: 6
Training loss: 3.1720523834228516
Validation loss: 2.2595430497200257

Epoch: 5| Step: 7
Training loss: 2.547100782394409
Validation loss: 2.2508735554192656

Epoch: 5| Step: 8
Training loss: 2.7238736152648926
Validation loss: 2.2465666711971326

Epoch: 5| Step: 9
Training loss: 2.160524606704712
Validation loss: 2.242128928502401

Epoch: 5| Step: 10
Training loss: 2.2359731197357178
Validation loss: 2.250502263346026

Epoch: 60| Step: 0
Training loss: 2.343411684036255
Validation loss: 2.253097685434485

Epoch: 5| Step: 1
Training loss: 2.715507984161377
Validation loss: 2.2629363049742994

Epoch: 5| Step: 2
Training loss: 2.793325424194336
Validation loss: 2.2786393268134004

Epoch: 5| Step: 3
Training loss: 2.5824217796325684
Validation loss: 2.259799603492983

Epoch: 5| Step: 4
Training loss: 2.7305572032928467
Validation loss: 2.2439997914016887

Epoch: 5| Step: 5
Training loss: 2.6054952144622803
Validation loss: 2.231781659587737

Epoch: 5| Step: 6
Training loss: 2.1179327964782715
Validation loss: 2.214574021677817

Epoch: 5| Step: 7
Training loss: 2.595754623413086
Validation loss: 2.2240321610563543

Epoch: 5| Step: 8
Training loss: 2.595907211303711
Validation loss: 2.2260182326839817

Epoch: 5| Step: 9
Training loss: 2.220233917236328
Validation loss: 2.2442017011745

Epoch: 5| Step: 10
Training loss: 2.367832899093628
Validation loss: 2.2512516783129786

Epoch: 61| Step: 0
Training loss: 2.574357032775879
Validation loss: 2.247664938690842

Epoch: 5| Step: 1
Training loss: 2.578739643096924
Validation loss: 2.24414724175648

Epoch: 5| Step: 2
Training loss: 2.3902900218963623
Validation loss: 2.2502483142319547

Epoch: 5| Step: 3
Training loss: 2.680570125579834
Validation loss: 2.2481356987389187

Epoch: 5| Step: 4
Training loss: 2.6769137382507324
Validation loss: 2.2633625179208736

Epoch: 5| Step: 5
Training loss: 2.1038405895233154
Validation loss: 2.2917669921792965

Epoch: 5| Step: 6
Training loss: 2.3914637565612793
Validation loss: 2.2873308094598914

Epoch: 5| Step: 7
Training loss: 2.7500267028808594
Validation loss: 2.2528421109722507

Epoch: 5| Step: 8
Training loss: 2.911659002304077
Validation loss: 2.2215046164810017

Epoch: 5| Step: 9
Training loss: 2.5355172157287598
Validation loss: 2.2069206699248283

Epoch: 5| Step: 10
Training loss: 1.8730050325393677
Validation loss: 2.202000210362096

Epoch: 62| Step: 0
Training loss: 2.2725508213043213
Validation loss: 2.204930938700194

Epoch: 5| Step: 1
Training loss: 2.767954111099243
Validation loss: 2.2130969685892903

Epoch: 5| Step: 2
Training loss: 3.3823249340057373
Validation loss: 2.224678062623547

Epoch: 5| Step: 3
Training loss: 2.755563259124756
Validation loss: 2.2082763743656937

Epoch: 5| Step: 4
Training loss: 3.241974353790283
Validation loss: 2.216405125074489

Epoch: 5| Step: 5
Training loss: 2.1303985118865967
Validation loss: 2.21019761536711

Epoch: 5| Step: 6
Training loss: 2.1029257774353027
Validation loss: 2.2011241823114376

Epoch: 5| Step: 7
Training loss: 2.256894588470459
Validation loss: 2.1981183508391022

Epoch: 5| Step: 8
Training loss: 2.52112078666687
Validation loss: 2.195101943067325

Epoch: 5| Step: 9
Training loss: 2.0502371788024902
Validation loss: 2.208480377351084

Epoch: 5| Step: 10
Training loss: 2.115042209625244
Validation loss: 2.218153540806104

Epoch: 63| Step: 0
Training loss: 2.6572868824005127
Validation loss: 2.2382190817145893

Epoch: 5| Step: 1
Training loss: 2.851494550704956
Validation loss: 2.2270650838011052

Epoch: 5| Step: 2
Training loss: 2.422875165939331
Validation loss: 2.2287513030472623

Epoch: 5| Step: 3
Training loss: 2.1385419368743896
Validation loss: 2.2194335037662136

Epoch: 5| Step: 4
Training loss: 1.966619849205017
Validation loss: 2.216386036206317

Epoch: 5| Step: 5
Training loss: 2.818000078201294
Validation loss: 2.215383703990649

Epoch: 5| Step: 6
Training loss: 3.0771689414978027
Validation loss: 2.228329550835394

Epoch: 5| Step: 7
Training loss: 2.1512508392333984
Validation loss: 2.216560879061299

Epoch: 5| Step: 8
Training loss: 2.341799259185791
Validation loss: 2.2073447012132212

Epoch: 5| Step: 9
Training loss: 2.3497345447540283
Validation loss: 2.2062023224369174

Epoch: 5| Step: 10
Training loss: 2.5607728958129883
Validation loss: 2.2119810350479616

Epoch: 64| Step: 0
Training loss: 2.7149176597595215
Validation loss: 2.209124078032791

Epoch: 5| Step: 1
Training loss: 2.4659817218780518
Validation loss: 2.229337059041505

Epoch: 5| Step: 2
Training loss: 1.8650192022323608
Validation loss: 2.248404368277519

Epoch: 5| Step: 3
Training loss: 2.601931095123291
Validation loss: 2.238115364505399

Epoch: 5| Step: 4
Training loss: 2.6836297512054443
Validation loss: 2.2187474966049194

Epoch: 5| Step: 5
Training loss: 2.038708209991455
Validation loss: 2.210116091594901

Epoch: 5| Step: 6
Training loss: 2.779026508331299
Validation loss: 2.197906140358217

Epoch: 5| Step: 7
Training loss: 2.4529311656951904
Validation loss: 2.1853458932650986

Epoch: 5| Step: 8
Training loss: 2.3846821784973145
Validation loss: 2.189386449834352

Epoch: 5| Step: 9
Training loss: 2.814204692840576
Validation loss: 2.196364987281061

Epoch: 5| Step: 10
Training loss: 2.610368490219116
Validation loss: 2.193174623673962

Epoch: 65| Step: 0
Training loss: 2.2347805500030518
Validation loss: 2.1844205471777145

Epoch: 5| Step: 1
Training loss: 2.851768970489502
Validation loss: 2.193406097350582

Epoch: 5| Step: 2
Training loss: 2.550248861312866
Validation loss: 2.203945021475515

Epoch: 5| Step: 3
Training loss: 2.514845848083496
Validation loss: 2.205565660230575

Epoch: 5| Step: 4
Training loss: 2.5091586112976074
Validation loss: 2.2203332531836724

Epoch: 5| Step: 5
Training loss: 2.0921683311462402
Validation loss: 2.231950162559427

Epoch: 5| Step: 6
Training loss: 2.6525890827178955
Validation loss: 2.2492895382706837

Epoch: 5| Step: 7
Training loss: 3.03779673576355
Validation loss: 2.253530271591679

Epoch: 5| Step: 8
Training loss: 2.3192954063415527
Validation loss: 2.212638649889218

Epoch: 5| Step: 9
Training loss: 2.1233432292938232
Validation loss: 2.2005180364014

Epoch: 5| Step: 10
Training loss: 2.376600503921509
Validation loss: 2.194813318150018

Epoch: 66| Step: 0
Training loss: 2.602423906326294
Validation loss: 2.1860076945315123

Epoch: 5| Step: 1
Training loss: 2.496110200881958
Validation loss: 2.1855504538423274

Epoch: 5| Step: 2
Training loss: 2.201972246170044
Validation loss: 2.2072966521786106

Epoch: 5| Step: 3
Training loss: 3.2585010528564453
Validation loss: 2.222621061468637

Epoch: 5| Step: 4
Training loss: 2.4546425342559814
Validation loss: 2.2224654279729372

Epoch: 5| Step: 5
Training loss: 2.210967540740967
Validation loss: 2.2415378632084018

Epoch: 5| Step: 6
Training loss: 3.002739667892456
Validation loss: 2.236298991787818

Epoch: 5| Step: 7
Training loss: 2.427051544189453
Validation loss: 2.2327069236386206

Epoch: 5| Step: 8
Training loss: 2.244896650314331
Validation loss: 2.2275504373734996

Epoch: 5| Step: 9
Training loss: 2.1412229537963867
Validation loss: 2.211219056960075

Epoch: 5| Step: 10
Training loss: 2.2088282108306885
Validation loss: 2.2056345465362712

Epoch: 67| Step: 0
Training loss: 1.9439579248428345
Validation loss: 2.2070680510613228

Epoch: 5| Step: 1
Training loss: 3.084320068359375
Validation loss: 2.21518555507865

Epoch: 5| Step: 2
Training loss: 1.5798063278198242
Validation loss: 2.2031704520666473

Epoch: 5| Step: 3
Training loss: 2.984450578689575
Validation loss: 2.1963026395408054

Epoch: 5| Step: 4
Training loss: 2.2701351642608643
Validation loss: 2.1851232897850776

Epoch: 5| Step: 5
Training loss: 2.278257369995117
Validation loss: 2.172325588041736

Epoch: 5| Step: 6
Training loss: 3.0690388679504395
Validation loss: 2.169841427956858

Epoch: 5| Step: 7
Training loss: 2.6632473468780518
Validation loss: 2.177205801010132

Epoch: 5| Step: 8
Training loss: 1.8592170476913452
Validation loss: 2.183299074890793

Epoch: 5| Step: 9
Training loss: 2.7733778953552246
Validation loss: 2.2082341973499586

Epoch: 5| Step: 10
Training loss: 2.521757125854492
Validation loss: 2.2289205212746896

Epoch: 68| Step: 0
Training loss: 2.066795825958252
Validation loss: 2.2504685360898256

Epoch: 5| Step: 1
Training loss: 2.3528130054473877
Validation loss: 2.221557932515298

Epoch: 5| Step: 2
Training loss: 2.3959505558013916
Validation loss: 2.202284679617933

Epoch: 5| Step: 3
Training loss: 2.4041051864624023
Validation loss: 2.184349525359369

Epoch: 5| Step: 4
Training loss: 3.3522064685821533
Validation loss: 2.1753572264025287

Epoch: 5| Step: 5
Training loss: 2.3680872917175293
Validation loss: 2.1762816598338466

Epoch: 5| Step: 6
Training loss: 2.539911985397339
Validation loss: 2.1897416909535727

Epoch: 5| Step: 7
Training loss: 2.198380470275879
Validation loss: 2.1892100072676137

Epoch: 5| Step: 8
Training loss: 2.553893804550171
Validation loss: 2.1938687639851726

Epoch: 5| Step: 9
Training loss: 2.4062352180480957
Validation loss: 2.1825207407756517

Epoch: 5| Step: 10
Training loss: 2.8148012161254883
Validation loss: 2.184277698557864

Epoch: 69| Step: 0
Training loss: 2.546861171722412
Validation loss: 2.198460413563636

Epoch: 5| Step: 1
Training loss: 2.356292247772217
Validation loss: 2.220474281618672

Epoch: 5| Step: 2
Training loss: 2.5247883796691895
Validation loss: 2.2294690301341396

Epoch: 5| Step: 3
Training loss: 2.745826482772827
Validation loss: 2.2226949994282057

Epoch: 5| Step: 4
Training loss: 2.840406656265259
Validation loss: 2.2299913103862474

Epoch: 5| Step: 5
Training loss: 1.693781852722168
Validation loss: 2.2009952299056517

Epoch: 5| Step: 6
Training loss: 2.434004783630371
Validation loss: 2.1912392493217223

Epoch: 5| Step: 7
Training loss: 2.267322063446045
Validation loss: 2.1848147581982356

Epoch: 5| Step: 8
Training loss: 3.0943799018859863
Validation loss: 2.1890011474650395

Epoch: 5| Step: 9
Training loss: 1.907405138015747
Validation loss: 2.199572391407464

Epoch: 5| Step: 10
Training loss: 2.6209774017333984
Validation loss: 2.2625187032966205

Epoch: 70| Step: 0
Training loss: 2.9321048259735107
Validation loss: 2.2713234040044967

Epoch: 5| Step: 1
Training loss: 1.8745863437652588
Validation loss: 2.2851217049424366

Epoch: 5| Step: 2
Training loss: 2.544187068939209
Validation loss: 2.3030131401554232

Epoch: 5| Step: 3
Training loss: 2.9237661361694336
Validation loss: 2.2922280885839976

Epoch: 5| Step: 4
Training loss: 2.937706470489502
Validation loss: 2.2398101693840435

Epoch: 5| Step: 5
Training loss: 1.9890674352645874
Validation loss: 2.2033585579164567

Epoch: 5| Step: 6
Training loss: 1.8644895553588867
Validation loss: 2.189658277778215

Epoch: 5| Step: 7
Training loss: 3.099308490753174
Validation loss: 2.167587503310173

Epoch: 5| Step: 8
Training loss: 2.189650297164917
Validation loss: 2.1536033999535347

Epoch: 5| Step: 9
Training loss: 1.8738009929656982
Validation loss: 2.1636128220506894

Epoch: 5| Step: 10
Training loss: 3.026442050933838
Validation loss: 2.1530468540806926

Epoch: 71| Step: 0
Training loss: 3.0910422801971436
Validation loss: 2.163360498284781

Epoch: 5| Step: 1
Training loss: 2.6264824867248535
Validation loss: 2.1650838672473864

Epoch: 5| Step: 2
Training loss: 2.1934401988983154
Validation loss: 2.1546725829442344

Epoch: 5| Step: 3
Training loss: 2.5690054893493652
Validation loss: 2.1633815214198124

Epoch: 5| Step: 4
Training loss: 2.467172622680664
Validation loss: 2.1833020769139773

Epoch: 5| Step: 5
Training loss: 2.5722897052764893
Validation loss: 2.226630533895185

Epoch: 5| Step: 6
Training loss: 2.2107136249542236
Validation loss: 2.248147972168461

Epoch: 5| Step: 7
Training loss: 2.827240467071533
Validation loss: 2.2816831629763366

Epoch: 5| Step: 8
Training loss: 2.0828499794006348
Validation loss: 2.3447866362910115

Epoch: 5| Step: 9
Training loss: 2.472705364227295
Validation loss: 2.390533954866471

Epoch: 5| Step: 10
Training loss: 2.3988726139068604
Validation loss: 2.3519085709766676

Epoch: 72| Step: 0
Training loss: 2.394538402557373
Validation loss: 2.263853035947328

Epoch: 5| Step: 1
Training loss: 2.3552632331848145
Validation loss: 2.209430399761405

Epoch: 5| Step: 2
Training loss: 2.126551389694214
Validation loss: 2.173939161403205

Epoch: 5| Step: 3
Training loss: 2.0415239334106445
Validation loss: 2.1561956431276057

Epoch: 5| Step: 4
Training loss: 2.6862101554870605
Validation loss: 2.194142210868097

Epoch: 5| Step: 5
Training loss: 3.110933542251587
Validation loss: 2.2162180305809103

Epoch: 5| Step: 6
Training loss: 2.731091260910034
Validation loss: 2.2297051106729815

Epoch: 5| Step: 7
Training loss: 3.1496987342834473
Validation loss: 2.237278139719399

Epoch: 5| Step: 8
Training loss: 2.5609824657440186
Validation loss: 2.2290781313373196

Epoch: 5| Step: 9
Training loss: 2.1016674041748047
Validation loss: 2.2164206492003573

Epoch: 5| Step: 10
Training loss: 2.593240976333618
Validation loss: 2.2067035269993607

Epoch: 73| Step: 0
Training loss: 2.2502636909484863
Validation loss: 2.1816473789112543

Epoch: 5| Step: 1
Training loss: 2.196694850921631
Validation loss: 2.1641058127085366

Epoch: 5| Step: 2
Training loss: 3.195108652114868
Validation loss: 2.149678517413396

Epoch: 5| Step: 3
Training loss: 2.9674744606018066
Validation loss: 2.1515339497596986

Epoch: 5| Step: 4
Training loss: 2.2542319297790527
Validation loss: 2.1703815639659925

Epoch: 5| Step: 5
Training loss: 2.4623634815216064
Validation loss: 2.217611312866211

Epoch: 5| Step: 6
Training loss: 2.112619161605835
Validation loss: 2.2344127162810294

Epoch: 5| Step: 7
Training loss: 2.6999542713165283
Validation loss: 2.2202305357943297

Epoch: 5| Step: 8
Training loss: 2.235375165939331
Validation loss: 2.188382835798366

Epoch: 5| Step: 9
Training loss: 1.8147239685058594
Validation loss: 2.177334946970786

Epoch: 5| Step: 10
Training loss: 2.976301908493042
Validation loss: 2.179308236286204

Epoch: 74| Step: 0
Training loss: 2.497509002685547
Validation loss: 2.1708356616317586

Epoch: 5| Step: 1
Training loss: 2.5376369953155518
Validation loss: 2.132365137018183

Epoch: 5| Step: 2
Training loss: 2.4089603424072266
Validation loss: 2.120115312196875

Epoch: 5| Step: 3
Training loss: 1.954965591430664
Validation loss: 2.109412018970777

Epoch: 5| Step: 4
Training loss: 2.4786529541015625
Validation loss: 2.111367371774489

Epoch: 5| Step: 5
Training loss: 2.57888126373291
Validation loss: 2.114343553461054

Epoch: 5| Step: 6
Training loss: 2.7513341903686523
Validation loss: 2.118935256875971

Epoch: 5| Step: 7
Training loss: 2.456317186355591
Validation loss: 2.119810360734181

Epoch: 5| Step: 8
Training loss: 2.418132781982422
Validation loss: 2.126947218371976

Epoch: 5| Step: 9
Training loss: 2.3373396396636963
Validation loss: 2.1479158786035355

Epoch: 5| Step: 10
Training loss: 2.1032886505126953
Validation loss: 2.1552361108923472

Epoch: 75| Step: 0
Training loss: 1.945055603981018
Validation loss: 2.1693661418012393

Epoch: 5| Step: 1
Training loss: 2.537433624267578
Validation loss: 2.167152279166765

Epoch: 5| Step: 2
Training loss: 3.022495746612549
Validation loss: 2.15139260086962

Epoch: 5| Step: 3
Training loss: 2.63018798828125
Validation loss: 2.1143264001415623

Epoch: 5| Step: 4
Training loss: 2.5135698318481445
Validation loss: 2.0877475366797498

Epoch: 5| Step: 5
Training loss: 2.542011260986328
Validation loss: 2.0762855173439108

Epoch: 5| Step: 6
Training loss: 1.9889843463897705
Validation loss: 2.0704795775874967

Epoch: 5| Step: 7
Training loss: 2.0101816654205322
Validation loss: 2.080028450617226

Epoch: 5| Step: 8
Training loss: 2.2778384685516357
Validation loss: 2.0887465066807245

Epoch: 5| Step: 9
Training loss: 2.7437076568603516
Validation loss: 2.1060876705313243

Epoch: 5| Step: 10
Training loss: 2.427940845489502
Validation loss: 2.13183254836708

Epoch: 76| Step: 0
Training loss: 1.8818994760513306
Validation loss: 2.1518219722214567

Epoch: 5| Step: 1
Training loss: 2.4213621616363525
Validation loss: 2.1625620421542915

Epoch: 5| Step: 2
Training loss: 1.9136896133422852
Validation loss: 2.139592856489202

Epoch: 5| Step: 3
Training loss: 2.6767306327819824
Validation loss: 2.1090869160108667

Epoch: 5| Step: 4
Training loss: 2.9567298889160156
Validation loss: 2.1056483291810557

Epoch: 5| Step: 5
Training loss: 2.0354602336883545
Validation loss: 2.0885895183009486

Epoch: 5| Step: 6
Training loss: 2.716940402984619
Validation loss: 2.086700777853689

Epoch: 5| Step: 7
Training loss: 2.5325698852539062
Validation loss: 2.084340432638763

Epoch: 5| Step: 8
Training loss: 2.4478249549865723
Validation loss: 2.0833443185334564

Epoch: 5| Step: 9
Training loss: 2.620972156524658
Validation loss: 2.0878054749581123

Epoch: 5| Step: 10
Training loss: 2.2168169021606445
Validation loss: 2.1074214737902404

Epoch: 77| Step: 0
Training loss: 2.1109862327575684
Validation loss: 2.117482787819319

Epoch: 5| Step: 1
Training loss: 2.6138007640838623
Validation loss: 2.1680316027774604

Epoch: 5| Step: 2
Training loss: 2.859755039215088
Validation loss: 2.1855816174578924

Epoch: 5| Step: 3
Training loss: 2.2816171646118164
Validation loss: 2.1390453461677796

Epoch: 5| Step: 4
Training loss: 2.1350255012512207
Validation loss: 2.1031966337593655

Epoch: 5| Step: 5
Training loss: 2.426119804382324
Validation loss: 2.0894578272296536

Epoch: 5| Step: 6
Training loss: 2.7323291301727295
Validation loss: 2.095841601330747

Epoch: 5| Step: 7
Training loss: 2.139233350753784
Validation loss: 2.0968765276734547

Epoch: 5| Step: 8
Training loss: 2.114013671875
Validation loss: 2.1006981839415846

Epoch: 5| Step: 9
Training loss: 2.2477660179138184
Validation loss: 2.0743421687874743

Epoch: 5| Step: 10
Training loss: 2.823733329772949
Validation loss: 2.0707962384787937

Epoch: 78| Step: 0
Training loss: 3.013561248779297
Validation loss: 2.0676174548364457

Epoch: 5| Step: 1
Training loss: 2.5172171592712402
Validation loss: 2.074708128488192

Epoch: 5| Step: 2
Training loss: 2.2300336360931396
Validation loss: 2.0756118912850656

Epoch: 5| Step: 3
Training loss: 1.8790109157562256
Validation loss: 2.0955091548222367

Epoch: 5| Step: 4
Training loss: 2.0414886474609375
Validation loss: 2.098361776721093

Epoch: 5| Step: 5
Training loss: 2.4970638751983643
Validation loss: 2.108793625267603

Epoch: 5| Step: 6
Training loss: 2.649927854537964
Validation loss: 2.1417426396441717

Epoch: 5| Step: 7
Training loss: 2.976613998413086
Validation loss: 2.215898549684914

Epoch: 5| Step: 8
Training loss: 2.240290880203247
Validation loss: 2.2798545924566125

Epoch: 5| Step: 9
Training loss: 2.5998635292053223
Validation loss: 2.275077457069069

Epoch: 5| Step: 10
Training loss: 2.1526758670806885
Validation loss: 2.227015233808948

Epoch: 79| Step: 0
Training loss: 1.9496933221817017
Validation loss: 2.17431112258665

Epoch: 5| Step: 1
Training loss: 1.883723258972168
Validation loss: 2.1105105800013386

Epoch: 5| Step: 2
Training loss: 2.059302568435669
Validation loss: 2.0765363990619616

Epoch: 5| Step: 3
Training loss: 2.7828726768493652
Validation loss: 2.07993334339511

Epoch: 5| Step: 4
Training loss: 2.3172459602355957
Validation loss: 2.107107267584852

Epoch: 5| Step: 5
Training loss: 2.558314561843872
Validation loss: 2.1105196886165167

Epoch: 5| Step: 6
Training loss: 3.262512683868408
Validation loss: 2.1037112858987626

Epoch: 5| Step: 7
Training loss: 2.1766726970672607
Validation loss: 2.09385266611653

Epoch: 5| Step: 8
Training loss: 2.332578659057617
Validation loss: 2.0948062545509747

Epoch: 5| Step: 9
Training loss: 2.4207253456115723
Validation loss: 2.0914393881315827

Epoch: 5| Step: 10
Training loss: 2.879500150680542
Validation loss: 2.083604020457114

Epoch: 80| Step: 0
Training loss: 1.9796838760375977
Validation loss: 2.082168976465861

Epoch: 5| Step: 1
Training loss: 2.7627220153808594
Validation loss: 2.1330362904456353

Epoch: 5| Step: 2
Training loss: 2.4595818519592285
Validation loss: 2.1538918300341536

Epoch: 5| Step: 3
Training loss: 2.140259265899658
Validation loss: 2.155865130885955

Epoch: 5| Step: 4
Training loss: 2.221806049346924
Validation loss: 2.172469603118076

Epoch: 5| Step: 5
Training loss: 2.912090301513672
Validation loss: 2.2562024644626084

Epoch: 5| Step: 6
Training loss: 2.593876361846924
Validation loss: 2.306125513968929

Epoch: 5| Step: 7
Training loss: 2.978532552719116
Validation loss: 2.2658530063526605

Epoch: 5| Step: 8
Training loss: 2.2668230533599854
Validation loss: 2.2302200614765124

Epoch: 5| Step: 9
Training loss: 1.911389946937561
Validation loss: 2.1656959851582847

Epoch: 5| Step: 10
Training loss: 2.181720733642578
Validation loss: 2.1241851032421155

Epoch: 81| Step: 0
Training loss: 2.602328062057495
Validation loss: 2.0984970356828425

Epoch: 5| Step: 1
Training loss: 2.392502784729004
Validation loss: 2.0890189345164965

Epoch: 5| Step: 2
Training loss: 1.9279005527496338
Validation loss: 2.0766577618096465

Epoch: 5| Step: 3
Training loss: 2.8292059898376465
Validation loss: 2.0841267698554584

Epoch: 5| Step: 4
Training loss: 2.406358480453491
Validation loss: 2.0902411142985025

Epoch: 5| Step: 5
Training loss: 2.243058443069458
Validation loss: 2.085289029664891

Epoch: 5| Step: 6
Training loss: 2.4370083808898926
Validation loss: 2.0948318371208767

Epoch: 5| Step: 7
Training loss: 2.520883083343506
Validation loss: 2.0900462981193297

Epoch: 5| Step: 8
Training loss: 2.342489719390869
Validation loss: 2.0856696482627624

Epoch: 5| Step: 9
Training loss: 2.384885311126709
Validation loss: 2.084164111844955

Epoch: 5| Step: 10
Training loss: 2.2787086963653564
Validation loss: 2.075196873757147

Epoch: 82| Step: 0
Training loss: 1.763220191001892
Validation loss: 2.070885609554988

Epoch: 5| Step: 1
Training loss: 2.3793749809265137
Validation loss: 2.077491201380248

Epoch: 5| Step: 2
Training loss: 1.5915617942810059
Validation loss: 2.075886267487721

Epoch: 5| Step: 3
Training loss: 2.524092197418213
Validation loss: 2.0668352726967103

Epoch: 5| Step: 4
Training loss: 2.3730225563049316
Validation loss: 2.076345670607782

Epoch: 5| Step: 5
Training loss: 2.9398865699768066
Validation loss: 2.0873795465756486

Epoch: 5| Step: 6
Training loss: 2.5739336013793945
Validation loss: 2.081827868697464

Epoch: 5| Step: 7
Training loss: 2.5195600986480713
Validation loss: 2.0775964119101085

Epoch: 5| Step: 8
Training loss: 2.365004301071167
Validation loss: 2.09116506320174

Epoch: 5| Step: 9
Training loss: 2.5967602729797363
Validation loss: 2.1143317786596154

Epoch: 5| Step: 10
Training loss: 2.485830307006836
Validation loss: 2.1260669821052143

Epoch: 83| Step: 0
Training loss: 2.6728243827819824
Validation loss: 2.136130027873542

Epoch: 5| Step: 1
Training loss: 1.988908052444458
Validation loss: 2.1073166221700688

Epoch: 5| Step: 2
Training loss: 2.790086269378662
Validation loss: 2.0851615821161578

Epoch: 5| Step: 3
Training loss: 2.2333102226257324
Validation loss: 2.0667524260859333

Epoch: 5| Step: 4
Training loss: 2.540600299835205
Validation loss: 2.063759405125854

Epoch: 5| Step: 5
Training loss: 3.0236282348632812
Validation loss: 2.063444017082132

Epoch: 5| Step: 6
Training loss: 1.602901816368103
Validation loss: 2.0627870649419804

Epoch: 5| Step: 7
Training loss: 2.2846977710723877
Validation loss: 2.064925609096404

Epoch: 5| Step: 8
Training loss: 2.002615451812744
Validation loss: 2.0687333460777038

Epoch: 5| Step: 9
Training loss: 2.5672221183776855
Validation loss: 2.0816325808084137

Epoch: 5| Step: 10
Training loss: 2.2980589866638184
Validation loss: 2.1102371344002346

Epoch: 84| Step: 0
Training loss: 2.414501667022705
Validation loss: 2.1819710359778455

Epoch: 5| Step: 1
Training loss: 1.9257144927978516
Validation loss: 2.226158562526908

Epoch: 5| Step: 2
Training loss: 3.315093994140625
Validation loss: 2.2169904631953083

Epoch: 5| Step: 3
Training loss: 1.7378475666046143
Validation loss: 2.1628624700730845

Epoch: 5| Step: 4
Training loss: 2.3277411460876465
Validation loss: 2.126372834687592

Epoch: 5| Step: 5
Training loss: 2.778262138366699
Validation loss: 2.1064151756225096

Epoch: 5| Step: 6
Training loss: 2.2536771297454834
Validation loss: 2.0860722141881145

Epoch: 5| Step: 7
Training loss: 2.75472354888916
Validation loss: 2.066171705081899

Epoch: 5| Step: 8
Training loss: 2.7133843898773193
Validation loss: 2.059287432701357

Epoch: 5| Step: 9
Training loss: 1.8310226202011108
Validation loss: 2.0833507545532717

Epoch: 5| Step: 10
Training loss: 2.388174295425415
Validation loss: 2.090423407093171

Epoch: 85| Step: 0
Training loss: 2.132472515106201
Validation loss: 2.0780823153834187

Epoch: 5| Step: 1
Training loss: 2.0386157035827637
Validation loss: 2.088503909367387

Epoch: 5| Step: 2
Training loss: 2.804438352584839
Validation loss: 2.0926582941444973

Epoch: 5| Step: 3
Training loss: 1.8000881671905518
Validation loss: 2.0791941509451917

Epoch: 5| Step: 4
Training loss: 1.7410528659820557
Validation loss: 2.0799158004022416

Epoch: 5| Step: 5
Training loss: 2.3121519088745117
Validation loss: 2.093393692406275

Epoch: 5| Step: 6
Training loss: 2.961015224456787
Validation loss: 2.0751492746414675

Epoch: 5| Step: 7
Training loss: 2.618466854095459
Validation loss: 2.0471670832685245

Epoch: 5| Step: 8
Training loss: 1.6890437602996826
Validation loss: 2.046361541235319

Epoch: 5| Step: 9
Training loss: 3.054884672164917
Validation loss: 2.0489376514188704

Epoch: 5| Step: 10
Training loss: 2.8231377601623535
Validation loss: 2.0355625780679847

Epoch: 86| Step: 0
Training loss: 2.6993203163146973
Validation loss: 2.044846988493396

Epoch: 5| Step: 1
Training loss: 2.1886844635009766
Validation loss: 2.0540133804403324

Epoch: 5| Step: 2
Training loss: 1.934287428855896
Validation loss: 2.0544847032075286

Epoch: 5| Step: 3
Training loss: 2.249539613723755
Validation loss: 2.0649705958622757

Epoch: 5| Step: 4
Training loss: 2.476973056793213
Validation loss: 2.08130665363804

Epoch: 5| Step: 5
Training loss: 2.606100082397461
Validation loss: 2.0896376973839215

Epoch: 5| Step: 6
Training loss: 2.930133581161499
Validation loss: 2.078836332085312

Epoch: 5| Step: 7
Training loss: 2.4193975925445557
Validation loss: 2.0740083366312008

Epoch: 5| Step: 8
Training loss: 2.3350882530212402
Validation loss: 2.06058991852627

Epoch: 5| Step: 9
Training loss: 1.4768381118774414
Validation loss: 2.048087586638748

Epoch: 5| Step: 10
Training loss: 2.5702762603759766
Validation loss: 2.0669763511227024

Epoch: 87| Step: 0
Training loss: 2.767134666442871
Validation loss: 2.062361183986869

Epoch: 5| Step: 1
Training loss: 3.1369788646698
Validation loss: 2.0693774543782717

Epoch: 5| Step: 2
Training loss: 2.4379067420959473
Validation loss: 2.0730462023006972

Epoch: 5| Step: 3
Training loss: 2.049238920211792
Validation loss: 2.0758096505236883

Epoch: 5| Step: 4
Training loss: 2.38157057762146
Validation loss: 2.0769335428873696

Epoch: 5| Step: 5
Training loss: 2.345951795578003
Validation loss: 2.0946881796724055

Epoch: 5| Step: 6
Training loss: 2.2375125885009766
Validation loss: 2.084563160455355

Epoch: 5| Step: 7
Training loss: 2.812264919281006
Validation loss: 2.0950293207681305

Epoch: 5| Step: 8
Training loss: 1.7460778951644897
Validation loss: 2.0965722863392164

Epoch: 5| Step: 9
Training loss: 2.2097344398498535
Validation loss: 2.0954004077501196

Epoch: 5| Step: 10
Training loss: 1.411018967628479
Validation loss: 2.10834204125148

Epoch: 88| Step: 0
Training loss: 2.535792589187622
Validation loss: 2.0955056733982538

Epoch: 5| Step: 1
Training loss: 2.19856333732605
Validation loss: 2.0904578957506406

Epoch: 5| Step: 2
Training loss: 2.3948915004730225
Validation loss: 2.1108496650572746

Epoch: 5| Step: 3
Training loss: 2.26882004737854
Validation loss: 2.1086315993339784

Epoch: 5| Step: 4
Training loss: 2.9293160438537598
Validation loss: 2.1157430179657473

Epoch: 5| Step: 5
Training loss: 2.5054595470428467
Validation loss: 2.1290996971950737

Epoch: 5| Step: 6
Training loss: 2.387155532836914
Validation loss: 2.131760028100783

Epoch: 5| Step: 7
Training loss: 2.3219871520996094
Validation loss: 2.1249210860139582

Epoch: 5| Step: 8
Training loss: 1.7055257558822632
Validation loss: 2.0858677843565583

Epoch: 5| Step: 9
Training loss: 2.0697591304779053
Validation loss: 2.06937865800755

Epoch: 5| Step: 10
Training loss: 2.585963010787964
Validation loss: 2.0855891179012995

Epoch: 89| Step: 0
Training loss: 1.654327630996704
Validation loss: 2.1219953619023806

Epoch: 5| Step: 1
Training loss: 2.5771751403808594
Validation loss: 2.150755037543594

Epoch: 5| Step: 2
Training loss: 1.8200209140777588
Validation loss: 2.1245782900882024

Epoch: 5| Step: 3
Training loss: 2.6367907524108887
Validation loss: 2.0941661301479546

Epoch: 5| Step: 4
Training loss: 2.1478357315063477
Validation loss: 2.073749230753991

Epoch: 5| Step: 5
Training loss: 2.7813494205474854
Validation loss: 2.0796974051383232

Epoch: 5| Step: 6
Training loss: 2.398852825164795
Validation loss: 2.091392760635704

Epoch: 5| Step: 7
Training loss: 2.526808500289917
Validation loss: 2.098857766838484

Epoch: 5| Step: 8
Training loss: 2.3984382152557373
Validation loss: 2.071609979034752

Epoch: 5| Step: 9
Training loss: 2.8235278129577637
Validation loss: 2.0541319975288967

Epoch: 5| Step: 10
Training loss: 1.9433510303497314
Validation loss: 2.036941602665891

Epoch: 90| Step: 0
Training loss: 1.9603691101074219
Validation loss: 2.021478094080443

Epoch: 5| Step: 1
Training loss: 2.04807448387146
Validation loss: 2.0352642151617233

Epoch: 5| Step: 2
Training loss: 1.8607299327850342
Validation loss: 2.0546612842108614

Epoch: 5| Step: 3
Training loss: 2.529587745666504
Validation loss: 2.080746655823082

Epoch: 5| Step: 4
Training loss: 2.7033908367156982
Validation loss: 2.105542980214601

Epoch: 5| Step: 5
Training loss: 2.187945604324341
Validation loss: 2.11363890863234

Epoch: 5| Step: 6
Training loss: 2.469452381134033
Validation loss: 2.116827375145369

Epoch: 5| Step: 7
Training loss: 2.2863285541534424
Validation loss: 2.1484428092997563

Epoch: 5| Step: 8
Training loss: 2.4225659370422363
Validation loss: 2.1475309838530836

Epoch: 5| Step: 9
Training loss: 2.3809378147125244
Validation loss: 2.0853438838835685

Epoch: 5| Step: 10
Training loss: 3.0198915004730225
Validation loss: 2.0571612324765933

Epoch: 91| Step: 0
Training loss: 3.080216884613037
Validation loss: 2.036321393905147

Epoch: 5| Step: 1
Training loss: 2.318620204925537
Validation loss: 2.039588628276702

Epoch: 5| Step: 2
Training loss: 2.534914255142212
Validation loss: 2.039046904092194

Epoch: 5| Step: 3
Training loss: 2.3350625038146973
Validation loss: 2.0476665599371797

Epoch: 5| Step: 4
Training loss: 2.4023141860961914
Validation loss: 2.032459412851641

Epoch: 5| Step: 5
Training loss: 1.6449615955352783
Validation loss: 2.0408820567592496

Epoch: 5| Step: 6
Training loss: 2.2858946323394775
Validation loss: 2.041845028118421

Epoch: 5| Step: 7
Training loss: 2.4279706478118896
Validation loss: 2.062716794270341

Epoch: 5| Step: 8
Training loss: 1.8375253677368164
Validation loss: 2.0813149944428475

Epoch: 5| Step: 9
Training loss: 2.5159552097320557
Validation loss: 2.134277266840781

Epoch: 5| Step: 10
Training loss: 2.332087993621826
Validation loss: 2.1599819583277546

Epoch: 92| Step: 0
Training loss: 2.706338405609131
Validation loss: 2.2027616270126833

Epoch: 5| Step: 1
Training loss: 2.8897604942321777
Validation loss: 2.1787437239000873

Epoch: 5| Step: 2
Training loss: 2.3858933448791504
Validation loss: 2.185258227009927

Epoch: 5| Step: 3
Training loss: 2.6311676502227783
Validation loss: 2.1980786964457524

Epoch: 5| Step: 4
Training loss: 1.9240150451660156
Validation loss: 2.1710712935334895

Epoch: 5| Step: 5
Training loss: 2.229203939437866
Validation loss: 2.1181987536850797

Epoch: 5| Step: 6
Training loss: 1.8743473291397095
Validation loss: 2.065682076638745

Epoch: 5| Step: 7
Training loss: 2.1654648780822754
Validation loss: 2.0430413074390863

Epoch: 5| Step: 8
Training loss: 2.514986991882324
Validation loss: 2.0339841227377615

Epoch: 5| Step: 9
Training loss: 2.0759334564208984
Validation loss: 2.0228078724235616

Epoch: 5| Step: 10
Training loss: 2.2683098316192627
Validation loss: 2.0168760489392024

Epoch: 93| Step: 0
Training loss: 2.243675708770752
Validation loss: 2.0107229268679054

Epoch: 5| Step: 1
Training loss: 2.334125518798828
Validation loss: 2.011265234280658

Epoch: 5| Step: 2
Training loss: 2.4257149696350098
Validation loss: 2.023879938228156

Epoch: 5| Step: 3
Training loss: 2.2479491233825684
Validation loss: 2.0423110005676106

Epoch: 5| Step: 4
Training loss: 2.5657925605773926
Validation loss: 2.061118807843936

Epoch: 5| Step: 5
Training loss: 1.895501732826233
Validation loss: 2.0825628413948962

Epoch: 5| Step: 6
Training loss: 1.943368911743164
Validation loss: 2.0865255325071272

Epoch: 5| Step: 7
Training loss: 2.5393829345703125
Validation loss: 2.1283246791490944

Epoch: 5| Step: 8
Training loss: 2.1064305305480957
Validation loss: 2.166423254115607

Epoch: 5| Step: 9
Training loss: 2.4272849559783936
Validation loss: 2.190226347215714

Epoch: 5| Step: 10
Training loss: 2.7498788833618164
Validation loss: 2.1806068138409684

Epoch: 94| Step: 0
Training loss: 2.350633144378662
Validation loss: 2.132644904557095

Epoch: 5| Step: 1
Training loss: 1.9771473407745361
Validation loss: 2.076922808924029

Epoch: 5| Step: 2
Training loss: 2.3271098136901855
Validation loss: 2.062716349478691

Epoch: 5| Step: 3
Training loss: 2.6135475635528564
Validation loss: 2.027798124538955

Epoch: 5| Step: 4
Training loss: 2.3566842079162598
Validation loss: 2.0270472982878327

Epoch: 5| Step: 5
Training loss: 2.344831943511963
Validation loss: 2.028239357856012

Epoch: 5| Step: 6
Training loss: 2.764465808868408
Validation loss: 2.016011917462913

Epoch: 5| Step: 7
Training loss: 2.741001605987549
Validation loss: 2.018601317559519

Epoch: 5| Step: 8
Training loss: 1.8390710353851318
Validation loss: 2.0257637103398642

Epoch: 5| Step: 9
Training loss: 2.040745496749878
Validation loss: 2.0316251067705053

Epoch: 5| Step: 10
Training loss: 1.9659103155136108
Validation loss: 2.0395337150942896

Epoch: 95| Step: 0
Training loss: 2.2177071571350098
Validation loss: 2.0582082386939757

Epoch: 5| Step: 1
Training loss: 2.4299635887145996
Validation loss: 2.0339867043238815

Epoch: 5| Step: 2
Training loss: 1.7195450067520142
Validation loss: 2.021454090713173

Epoch: 5| Step: 3
Training loss: 2.378711223602295
Validation loss: 2.0080935096227996

Epoch: 5| Step: 4
Training loss: 2.476810932159424
Validation loss: 2.0081223275071833

Epoch: 5| Step: 5
Training loss: 2.510272264480591
Validation loss: 2.0139912482230895

Epoch: 5| Step: 6
Training loss: 2.652174711227417
Validation loss: 2.018258353715302

Epoch: 5| Step: 7
Training loss: 3.1652896404266357
Validation loss: 2.057661182136946

Epoch: 5| Step: 8
Training loss: 2.0050156116485596
Validation loss: 2.0790660535135577

Epoch: 5| Step: 9
Training loss: 1.7090332508087158
Validation loss: 2.0769370063658683

Epoch: 5| Step: 10
Training loss: 1.7217713594436646
Validation loss: 2.0835526527897006

Epoch: 96| Step: 0
Training loss: 1.9867569208145142
Validation loss: 2.0637493030999297

Epoch: 5| Step: 1
Training loss: 1.5645854473114014
Validation loss: 2.049988777406754

Epoch: 5| Step: 2
Training loss: 2.576202154159546
Validation loss: 2.025583072375226

Epoch: 5| Step: 3
Training loss: 2.6828224658966064
Validation loss: 2.0051501258727042

Epoch: 5| Step: 4
Training loss: 2.7486844062805176
Validation loss: 1.9880529719014322

Epoch: 5| Step: 5
Training loss: 2.139218807220459
Validation loss: 1.994023330750004

Epoch: 5| Step: 6
Training loss: 2.3269526958465576
Validation loss: 2.005284681115099

Epoch: 5| Step: 7
Training loss: 2.1079609394073486
Validation loss: 2.001032584456987

Epoch: 5| Step: 8
Training loss: 2.535489559173584
Validation loss: 2.009462243767195

Epoch: 5| Step: 9
Training loss: 2.2125742435455322
Validation loss: 2.004671847948464

Epoch: 5| Step: 10
Training loss: 2.399751901626587
Validation loss: 2.0035933871423044

Epoch: 97| Step: 0
Training loss: 2.698904037475586
Validation loss: 2.003655550300434

Epoch: 5| Step: 1
Training loss: 2.9075675010681152
Validation loss: 2.021030669571251

Epoch: 5| Step: 2
Training loss: 1.9396528005599976
Validation loss: 2.039412147255354

Epoch: 5| Step: 3
Training loss: 2.3077378273010254
Validation loss: 2.0425720676299064

Epoch: 5| Step: 4
Training loss: 2.2580018043518066
Validation loss: 2.0441566231430217

Epoch: 5| Step: 5
Training loss: 1.6967239379882812
Validation loss: 2.0718248864655853

Epoch: 5| Step: 6
Training loss: 2.2722296714782715
Validation loss: 2.0486395602585166

Epoch: 5| Step: 7
Training loss: 2.6339330673217773
Validation loss: 2.050975820069672

Epoch: 5| Step: 8
Training loss: 1.5048434734344482
Validation loss: 2.0477285333859023

Epoch: 5| Step: 9
Training loss: 2.0734152793884277
Validation loss: 2.049151248829339

Epoch: 5| Step: 10
Training loss: 2.8196375370025635
Validation loss: 2.078138769313853

Epoch: 98| Step: 0
Training loss: 2.250913381576538
Validation loss: 2.0440373971898067

Epoch: 5| Step: 1
Training loss: 2.0410332679748535
Validation loss: 2.0345547096703642

Epoch: 5| Step: 2
Training loss: 2.437668800354004
Validation loss: 2.0479089239592194

Epoch: 5| Step: 3
Training loss: 1.8090019226074219
Validation loss: 2.039850850259104

Epoch: 5| Step: 4
Training loss: 2.5873990058898926
Validation loss: 2.03679145151569

Epoch: 5| Step: 5
Training loss: 1.8699861764907837
Validation loss: 2.024244762236072

Epoch: 5| Step: 6
Training loss: 3.0122437477111816
Validation loss: 2.022652687564973

Epoch: 5| Step: 7
Training loss: 2.5842652320861816
Validation loss: 2.035873431031422

Epoch: 5| Step: 8
Training loss: 1.9505321979522705
Validation loss: 2.0316001984380905

Epoch: 5| Step: 9
Training loss: 1.8624775409698486
Validation loss: 2.0709832996450444

Epoch: 5| Step: 10
Training loss: 2.6258466243743896
Validation loss: 2.1175362269083657

Epoch: 99| Step: 0
Training loss: 2.306316614151001
Validation loss: 2.134583660351333

Epoch: 5| Step: 1
Training loss: 2.6811060905456543
Validation loss: 2.136505857590706

Epoch: 5| Step: 2
Training loss: 2.7091994285583496
Validation loss: 2.111763431179908

Epoch: 5| Step: 3
Training loss: 2.2396490573883057
Validation loss: 2.0424922409877984

Epoch: 5| Step: 4
Training loss: 2.1634011268615723
Validation loss: 1.9980721832603536

Epoch: 5| Step: 5
Training loss: 2.263329029083252
Validation loss: 1.9779317494361632

Epoch: 5| Step: 6
Training loss: 1.9952738285064697
Validation loss: 1.9798208423840102

Epoch: 5| Step: 7
Training loss: 2.1414389610290527
Validation loss: 1.9919668384777602

Epoch: 5| Step: 8
Training loss: 2.134787082672119
Validation loss: 2.0040206704088437

Epoch: 5| Step: 9
Training loss: 1.9183695316314697
Validation loss: 2.0176241320948445

Epoch: 5| Step: 10
Training loss: 2.4424376487731934
Validation loss: 2.0150058038773073

Epoch: 100| Step: 0
Training loss: 2.3898262977600098
Validation loss: 2.0276175724562777

Epoch: 5| Step: 1
Training loss: 2.3758578300476074
Validation loss: 2.0191210777528825

Epoch: 5| Step: 2
Training loss: 2.769486427307129
Validation loss: 2.021734250489102

Epoch: 5| Step: 3
Training loss: 1.915152907371521
Validation loss: 2.0299546769870225

Epoch: 5| Step: 4
Training loss: 2.5427074432373047
Validation loss: 2.0347074975249586

Epoch: 5| Step: 5
Training loss: 2.572075366973877
Validation loss: 2.0257725574636973

Epoch: 5| Step: 6
Training loss: 2.0444846153259277
Validation loss: 2.0288376731257283

Epoch: 5| Step: 7
Training loss: 1.9644088745117188
Validation loss: 2.0298708843928512

Epoch: 5| Step: 8
Training loss: 1.528674840927124
Validation loss: 2.020341618086702

Epoch: 5| Step: 9
Training loss: 2.3853445053100586
Validation loss: 2.0212173718278126

Epoch: 5| Step: 10
Training loss: 2.0437464714050293
Validation loss: 2.0324113253624208

Epoch: 101| Step: 0
Training loss: 2.585725784301758
Validation loss: 2.0450148338912637

Epoch: 5| Step: 1
Training loss: 2.068826198577881
Validation loss: 2.0430801530038156

Epoch: 5| Step: 2
Training loss: 2.5610811710357666
Validation loss: 2.0513146820888726

Epoch: 5| Step: 3
Training loss: 2.0074150562286377
Validation loss: 2.0363183290727678

Epoch: 5| Step: 4
Training loss: 2.2972614765167236
Validation loss: 2.025800267855326

Epoch: 5| Step: 5
Training loss: 1.8769111633300781
Validation loss: 2.016637896978727

Epoch: 5| Step: 6
Training loss: 2.671325206756592
Validation loss: 1.9877756000846944

Epoch: 5| Step: 7
Training loss: 2.371366024017334
Validation loss: 1.9903766980735205

Epoch: 5| Step: 8
Training loss: 2.1363158226013184
Validation loss: 1.9899455962642547

Epoch: 5| Step: 9
Training loss: 1.7727997303009033
Validation loss: 1.9960960547129314

Epoch: 5| Step: 10
Training loss: 2.2266829013824463
Validation loss: 1.9865245614000546

Epoch: 102| Step: 0
Training loss: 2.271496534347534
Validation loss: 1.9873583624439854

Epoch: 5| Step: 1
Training loss: 2.2195591926574707
Validation loss: 2.0131107402104202

Epoch: 5| Step: 2
Training loss: 1.5893526077270508
Validation loss: 2.0552480131067257

Epoch: 5| Step: 3
Training loss: 2.091759204864502
Validation loss: 2.070136426597513

Epoch: 5| Step: 4
Training loss: 2.106187343597412
Validation loss: 2.0532597034208235

Epoch: 5| Step: 5
Training loss: 2.5767529010772705
Validation loss: 2.050038872226592

Epoch: 5| Step: 6
Training loss: 1.595689058303833
Validation loss: 2.017000672637775

Epoch: 5| Step: 7
Training loss: 2.49570894241333
Validation loss: 2.0200363871871785

Epoch: 5| Step: 8
Training loss: 2.6838488578796387
Validation loss: 2.0250679151986235

Epoch: 5| Step: 9
Training loss: 2.3274128437042236
Validation loss: 2.007218978738272

Epoch: 5| Step: 10
Training loss: 2.691398859024048
Validation loss: 2.0061124729853805

Epoch: 103| Step: 0
Training loss: 1.572566032409668
Validation loss: 2.0039733622663762

Epoch: 5| Step: 1
Training loss: 1.8735263347625732
Validation loss: 1.9950497816967707

Epoch: 5| Step: 2
Training loss: 2.8908019065856934
Validation loss: 2.0021019776662192

Epoch: 5| Step: 3
Training loss: 2.53792142868042
Validation loss: 2.0086546738942466

Epoch: 5| Step: 4
Training loss: 2.0613090991973877
Validation loss: 2.010612282701718

Epoch: 5| Step: 5
Training loss: 1.9633824825286865
Validation loss: 2.0205012111253637

Epoch: 5| Step: 6
Training loss: 1.8014171123504639
Validation loss: 2.0300251668499363

Epoch: 5| Step: 7
Training loss: 2.457768201828003
Validation loss: 2.019516480866299

Epoch: 5| Step: 8
Training loss: 1.7430827617645264
Validation loss: 2.0042863481788227

Epoch: 5| Step: 9
Training loss: 2.5345733165740967
Validation loss: 1.969287246786138

Epoch: 5| Step: 10
Training loss: 3.105435609817505
Validation loss: 1.9566615384112123

Epoch: 104| Step: 0
Training loss: 2.0327553749084473
Validation loss: 1.9691701858274397

Epoch: 5| Step: 1
Training loss: 2.0484299659729004
Validation loss: 1.9594182865594023

Epoch: 5| Step: 2
Training loss: 2.414355516433716
Validation loss: 1.960143635349889

Epoch: 5| Step: 3
Training loss: 1.688963532447815
Validation loss: 1.964312291914417

Epoch: 5| Step: 4
Training loss: 2.3846945762634277
Validation loss: 2.004395261887581

Epoch: 5| Step: 5
Training loss: 2.1765809059143066
Validation loss: 2.0267376002445014

Epoch: 5| Step: 6
Training loss: 2.162726640701294
Validation loss: 2.025506729720741

Epoch: 5| Step: 7
Training loss: 2.8585400581359863
Validation loss: 2.028813121139362

Epoch: 5| Step: 8
Training loss: 2.5657668113708496
Validation loss: 2.0384209873855754

Epoch: 5| Step: 9
Training loss: 2.0978434085845947
Validation loss: 2.052335846808649

Epoch: 5| Step: 10
Training loss: 1.931899070739746
Validation loss: 2.0486413278887348

Epoch: 105| Step: 0
Training loss: 2.2471323013305664
Validation loss: 2.0186691745635

Epoch: 5| Step: 1
Training loss: 2.4422545433044434
Validation loss: 2.0012717811010217

Epoch: 5| Step: 2
Training loss: 1.8206077814102173
Validation loss: 2.0004124154326735

Epoch: 5| Step: 3
Training loss: 2.1262357234954834
Validation loss: 1.9974352185444166

Epoch: 5| Step: 4
Training loss: 2.2349658012390137
Validation loss: 2.002641316383116

Epoch: 5| Step: 5
Training loss: 2.5294008255004883
Validation loss: 2.013184178260065

Epoch: 5| Step: 6
Training loss: 2.627594470977783
Validation loss: 2.006147257743343

Epoch: 5| Step: 7
Training loss: 1.8138538599014282
Validation loss: 2.009361428599204

Epoch: 5| Step: 8
Training loss: 1.98904287815094
Validation loss: 2.005281627819102

Epoch: 5| Step: 9
Training loss: 2.141159772872925
Validation loss: 2.018932024637858

Epoch: 5| Step: 10
Training loss: 2.126711130142212
Validation loss: 2.0449645621802217

Epoch: 106| Step: 0
Training loss: 2.3686254024505615
Validation loss: 2.079834338157408

Epoch: 5| Step: 1
Training loss: 1.7503950595855713
Validation loss: 2.114749957156438

Epoch: 5| Step: 2
Training loss: 2.3560070991516113
Validation loss: 2.1021770379876576

Epoch: 5| Step: 3
Training loss: 1.656386375427246
Validation loss: 2.0593948453985234

Epoch: 5| Step: 4
Training loss: 2.2940890789031982
Validation loss: 2.039738714054067

Epoch: 5| Step: 5
Training loss: 2.4445765018463135
Validation loss: 2.020019315904187

Epoch: 5| Step: 6
Training loss: 2.143352508544922
Validation loss: 2.0151091852495746

Epoch: 5| Step: 7
Training loss: 2.7926361560821533
Validation loss: 2.0258252313060146

Epoch: 5| Step: 8
Training loss: 2.0241477489471436
Validation loss: 2.0280339769137803

Epoch: 5| Step: 9
Training loss: 1.475120186805725
Validation loss: 2.0525562224849576

Epoch: 5| Step: 10
Training loss: 3.254851818084717
Validation loss: 2.099690616771739

Epoch: 107| Step: 0
Training loss: 2.0658328533172607
Validation loss: 2.1226160436548214

Epoch: 5| Step: 1
Training loss: 2.3314578533172607
Validation loss: 2.1125692680317867

Epoch: 5| Step: 2
Training loss: 2.803215503692627
Validation loss: 2.107496794833932

Epoch: 5| Step: 3
Training loss: 2.176534652709961
Validation loss: 2.081905978982167

Epoch: 5| Step: 4
Training loss: 2.518798828125
Validation loss: 2.0259189708258516

Epoch: 5| Step: 5
Training loss: 2.115565538406372
Validation loss: 2.0120043677668416

Epoch: 5| Step: 6
Training loss: 1.9462640285491943
Validation loss: 2.002964711958362

Epoch: 5| Step: 7
Training loss: 2.056480646133423
Validation loss: 1.9955480508906867

Epoch: 5| Step: 8
Training loss: 2.2103874683380127
Validation loss: 1.9828887447234123

Epoch: 5| Step: 9
Training loss: 2.105710029602051
Validation loss: 1.981418655764672

Epoch: 5| Step: 10
Training loss: 1.8995145559310913
Validation loss: 1.9627922299087688

Epoch: 108| Step: 0
Training loss: 2.3387739658355713
Validation loss: 1.9755981993931595

Epoch: 5| Step: 1
Training loss: 2.259849786758423
Validation loss: 1.9787427840694305

Epoch: 5| Step: 2
Training loss: 2.4022278785705566
Validation loss: 1.9974081900811964

Epoch: 5| Step: 3
Training loss: 1.7333406209945679
Validation loss: 1.9809634506061513

Epoch: 5| Step: 4
Training loss: 2.3007237911224365
Validation loss: 1.9861109231107978

Epoch: 5| Step: 5
Training loss: 2.1453869342803955
Validation loss: 1.9873680978692987

Epoch: 5| Step: 6
Training loss: 2.222815990447998
Validation loss: 1.9881384885439308

Epoch: 5| Step: 7
Training loss: 2.5458133220672607
Validation loss: 2.0168254785640265

Epoch: 5| Step: 8
Training loss: 2.462608814239502
Validation loss: 1.9973182562858827

Epoch: 5| Step: 9
Training loss: 1.9897149801254272
Validation loss: 2.0140240128322313

Epoch: 5| Step: 10
Training loss: 1.598686695098877
Validation loss: 2.011820052259712

Epoch: 109| Step: 0
Training loss: 1.5501048564910889
Validation loss: 1.9947512636902511

Epoch: 5| Step: 1
Training loss: 2.217094659805298
Validation loss: 1.9924403826395671

Epoch: 5| Step: 2
Training loss: 2.2753801345825195
Validation loss: 1.9775843479300057

Epoch: 5| Step: 3
Training loss: 2.201206922531128
Validation loss: 1.9720303614934285

Epoch: 5| Step: 4
Training loss: 1.9612878561019897
Validation loss: 1.983300942246632

Epoch: 5| Step: 5
Training loss: 1.8820667266845703
Validation loss: 2.0334973181447675

Epoch: 5| Step: 6
Training loss: 2.881633758544922
Validation loss: 2.0716176750839397

Epoch: 5| Step: 7
Training loss: 2.2082035541534424
Validation loss: 2.1211480863632692

Epoch: 5| Step: 8
Training loss: 2.108705759048462
Validation loss: 2.1392142670128935

Epoch: 5| Step: 9
Training loss: 2.3162167072296143
Validation loss: 2.1129490688282955

Epoch: 5| Step: 10
Training loss: 2.5824978351593018
Validation loss: 2.092295103175666

Epoch: 110| Step: 0
Training loss: 2.363467216491699
Validation loss: 2.0438950292525755

Epoch: 5| Step: 1
Training loss: 1.957432508468628
Validation loss: 2.013988676891532

Epoch: 5| Step: 2
Training loss: 2.747241973876953
Validation loss: 1.9979560695668703

Epoch: 5| Step: 3
Training loss: 1.6501142978668213
Validation loss: 2.0119907599623486

Epoch: 5| Step: 4
Training loss: 2.0451018810272217
Validation loss: 2.0151962311037126

Epoch: 5| Step: 5
Training loss: 1.9173091650009155
Validation loss: 2.0452287581659134

Epoch: 5| Step: 6
Training loss: 2.2634339332580566
Validation loss: 2.0681472055373655

Epoch: 5| Step: 7
Training loss: 2.5183911323547363
Validation loss: 2.088316117563555

Epoch: 5| Step: 8
Training loss: 2.14082407951355
Validation loss: 2.1107979166892266

Epoch: 5| Step: 9
Training loss: 2.1721842288970947
Validation loss: 2.1257581608269804

Epoch: 5| Step: 10
Training loss: 2.363955497741699
Validation loss: 2.1172607919221282

Epoch: 111| Step: 0
Training loss: 2.402874708175659
Validation loss: 2.103330781382899

Epoch: 5| Step: 1
Training loss: 2.154810667037964
Validation loss: 2.090021587187244

Epoch: 5| Step: 2
Training loss: 1.8154503107070923
Validation loss: 2.084451434432819

Epoch: 5| Step: 3
Training loss: 2.106907606124878
Validation loss: 2.0564476507966236

Epoch: 5| Step: 4
Training loss: 2.3041651248931885
Validation loss: 2.0285461282217376

Epoch: 5| Step: 5
Training loss: 2.5260207653045654
Validation loss: 2.0157184549557265

Epoch: 5| Step: 6
Training loss: 2.180569887161255
Validation loss: 2.0026508992718113

Epoch: 5| Step: 7
Training loss: 2.1027472019195557
Validation loss: 1.9920826650434924

Epoch: 5| Step: 8
Training loss: 2.0228888988494873
Validation loss: 1.989387253279327

Epoch: 5| Step: 9
Training loss: 1.9669557809829712
Validation loss: 2.0059260963111796

Epoch: 5| Step: 10
Training loss: 2.1935524940490723
Validation loss: 2.0546553109281804

Epoch: 112| Step: 0
Training loss: 2.7700753211975098
Validation loss: 2.080367131899762

Epoch: 5| Step: 1
Training loss: 1.7184326648712158
Validation loss: 2.102092983902142

Epoch: 5| Step: 2
Training loss: 1.9336986541748047
Validation loss: 2.0942010328333867

Epoch: 5| Step: 3
Training loss: 1.7190967798233032
Validation loss: 2.088406406423097

Epoch: 5| Step: 4
Training loss: 2.2766621112823486
Validation loss: 2.064256819345618

Epoch: 5| Step: 5
Training loss: 1.765515923500061
Validation loss: 2.0622206336708477

Epoch: 5| Step: 6
Training loss: 3.175499200820923
Validation loss: 2.096221290608888

Epoch: 5| Step: 7
Training loss: 2.8596372604370117
Validation loss: 2.12619460269969

Epoch: 5| Step: 8
Training loss: 1.8957599401474
Validation loss: 2.141158224433981

Epoch: 5| Step: 9
Training loss: 2.1781365871429443
Validation loss: 2.103947329264815

Epoch: 5| Step: 10
Training loss: 1.6914838552474976
Validation loss: 2.067515524484778

Epoch: 113| Step: 0
Training loss: 2.2207179069519043
Validation loss: 1.9809103934995589

Epoch: 5| Step: 1
Training loss: 2.558898687362671
Validation loss: 1.9729497971073273

Epoch: 5| Step: 2
Training loss: 2.3874456882476807
Validation loss: 1.9820029479201122

Epoch: 5| Step: 3
Training loss: 2.24652099609375
Validation loss: 2.006481724400674

Epoch: 5| Step: 4
Training loss: 1.5378468036651611
Validation loss: 2.0120403100085515

Epoch: 5| Step: 5
Training loss: 1.897676706314087
Validation loss: 2.0337571790141444

Epoch: 5| Step: 6
Training loss: 2.5618393421173096
Validation loss: 2.0399701018487253

Epoch: 5| Step: 7
Training loss: 2.7609405517578125
Validation loss: 2.035605974094842

Epoch: 5| Step: 8
Training loss: 1.672950029373169
Validation loss: 2.025032301102915

Epoch: 5| Step: 9
Training loss: 2.511974811553955
Validation loss: 2.016991420458722

Epoch: 5| Step: 10
Training loss: 2.0380868911743164
Validation loss: 2.0234774081937728

Epoch: 114| Step: 0
Training loss: 2.187300682067871
Validation loss: 2.0237878471292476

Epoch: 5| Step: 1
Training loss: 2.3040385246276855
Validation loss: 2.0458934896735737

Epoch: 5| Step: 2
Training loss: 1.8137319087982178
Validation loss: 2.0574688039800173

Epoch: 5| Step: 3
Training loss: 2.2676634788513184
Validation loss: 2.087207616016429

Epoch: 5| Step: 4
Training loss: 2.3425631523132324
Validation loss: 2.121903265676191

Epoch: 5| Step: 5
Training loss: 2.310786008834839
Validation loss: 2.1290050655282955

Epoch: 5| Step: 6
Training loss: 1.9138526916503906
Validation loss: 2.13209060699709

Epoch: 5| Step: 7
Training loss: 2.014254093170166
Validation loss: 2.1365688693138862

Epoch: 5| Step: 8
Training loss: 2.283372640609741
Validation loss: 2.1254628614712785

Epoch: 5| Step: 9
Training loss: 2.145869255065918
Validation loss: 2.078465574531145

Epoch: 5| Step: 10
Training loss: 1.8441801071166992
Validation loss: 2.050410742400795

Epoch: 115| Step: 0
Training loss: 2.023205518722534
Validation loss: 2.0379564826206495

Epoch: 5| Step: 1
Training loss: 2.5047082901000977
Validation loss: 2.031537186714911

Epoch: 5| Step: 2
Training loss: 1.737865686416626
Validation loss: 2.026019643711787

Epoch: 5| Step: 3
Training loss: 2.111236095428467
Validation loss: 2.042100247516427

Epoch: 5| Step: 4
Training loss: 1.8035961389541626
Validation loss: 2.0320248129547283

Epoch: 5| Step: 5
Training loss: 2.120626926422119
Validation loss: 2.022086158875496

Epoch: 5| Step: 6
Training loss: 1.8919063806533813
Validation loss: 2.033308608557588

Epoch: 5| Step: 7
Training loss: 1.7622058391571045
Validation loss: 2.0511204401652017

Epoch: 5| Step: 8
Training loss: 2.327263593673706
Validation loss: 2.039245004295021

Epoch: 5| Step: 9
Training loss: 2.298872470855713
Validation loss: 2.062460781425558

Epoch: 5| Step: 10
Training loss: 2.870755672454834
Validation loss: 2.059270948492071

Epoch: 116| Step: 0
Training loss: 2.3038291931152344
Validation loss: 2.057782285956926

Epoch: 5| Step: 1
Training loss: 1.6494029760360718
Validation loss: 2.0492796256978023

Epoch: 5| Step: 2
Training loss: 1.5084161758422852
Validation loss: 2.0580525475163616

Epoch: 5| Step: 3
Training loss: 1.9862474203109741
Validation loss: 2.045678925770585

Epoch: 5| Step: 4
Training loss: 2.2933757305145264
Validation loss: 2.0396871207862772

Epoch: 5| Step: 5
Training loss: 2.210750102996826
Validation loss: 2.0386056925660823

Epoch: 5| Step: 6
Training loss: 2.613926410675049
Validation loss: 2.0260604273888374

Epoch: 5| Step: 7
Training loss: 1.8903768062591553
Validation loss: 2.0339648697965886

Epoch: 5| Step: 8
Training loss: 2.1733973026275635
Validation loss: 2.0390474873204387

Epoch: 5| Step: 9
Training loss: 2.1775879859924316
Validation loss: 2.0211412829737507

Epoch: 5| Step: 10
Training loss: 1.9904184341430664
Validation loss: 2.027692779417961

Epoch: 117| Step: 0
Training loss: 2.6537728309631348
Validation loss: 2.021459651249711

Epoch: 5| Step: 1
Training loss: 1.6556392908096313
Validation loss: 2.0106575668499036

Epoch: 5| Step: 2
Training loss: 2.207489252090454
Validation loss: 2.0058838193134596

Epoch: 5| Step: 3
Training loss: 2.217522144317627
Validation loss: 2.0254003488889305

Epoch: 5| Step: 4
Training loss: 1.9807583093643188
Validation loss: 2.046388197970647

Epoch: 5| Step: 5
Training loss: 1.9029604196548462
Validation loss: 2.074083735865931

Epoch: 5| Step: 6
Training loss: 2.112011432647705
Validation loss: 2.1123581804255003

Epoch: 5| Step: 7
Training loss: 1.8400166034698486
Validation loss: 2.1225983699162803

Epoch: 5| Step: 8
Training loss: 1.9266784191131592
Validation loss: 2.113384674954158

Epoch: 5| Step: 9
Training loss: 3.053971290588379
Validation loss: 2.1081131709519254

Epoch: 5| Step: 10
Training loss: 1.6218633651733398
Validation loss: 2.092453328512048

Epoch: 118| Step: 0
Training loss: 2.3824896812438965
Validation loss: 2.0699803598465456

Epoch: 5| Step: 1
Training loss: 2.307858943939209
Validation loss: 2.052988201059321

Epoch: 5| Step: 2
Training loss: 1.9406013488769531
Validation loss: 2.0446922471446376

Epoch: 5| Step: 3
Training loss: 2.07538104057312
Validation loss: 2.0598017913039013

Epoch: 5| Step: 4
Training loss: 1.9707361459732056
Validation loss: 2.045124005245906

Epoch: 5| Step: 5
Training loss: 2.2009410858154297
Validation loss: 2.0304084465067875

Epoch: 5| Step: 6
Training loss: 1.9904972314834595
Validation loss: 2.031331049498691

Epoch: 5| Step: 7
Training loss: 2.6808021068573
Validation loss: 2.0692923543273762

Epoch: 5| Step: 8
Training loss: 1.5807397365570068
Validation loss: 2.072591330415459

Epoch: 5| Step: 9
Training loss: 2.351325511932373
Validation loss: 2.070052569912326

Epoch: 5| Step: 10
Training loss: 1.9047465324401855
Validation loss: 2.0762480843451714

Epoch: 119| Step: 0
Training loss: 1.774682641029358
Validation loss: 2.0620839057430143

Epoch: 5| Step: 1
Training loss: 2.30586576461792
Validation loss: 2.0460071256083827

Epoch: 5| Step: 2
Training loss: 1.9756675958633423
Validation loss: 2.047604339097136

Epoch: 5| Step: 3
Training loss: 1.0143741369247437
Validation loss: 2.0376436710357666

Epoch: 5| Step: 4
Training loss: 2.0410268306732178
Validation loss: 2.0469031205741306

Epoch: 5| Step: 5
Training loss: 2.511138439178467
Validation loss: 2.0400947345200406

Epoch: 5| Step: 6
Training loss: 2.634230375289917
Validation loss: 2.041395274541711

Epoch: 5| Step: 7
Training loss: 2.0468974113464355
Validation loss: 2.03859616351384

Epoch: 5| Step: 8
Training loss: 2.4533143043518066
Validation loss: 2.041348200972362

Epoch: 5| Step: 9
Training loss: 2.178894281387329
Validation loss: 2.0418011373089207

Epoch: 5| Step: 10
Training loss: 1.758909821510315
Validation loss: 2.0304626982699157

Epoch: 120| Step: 0
Training loss: 1.948786973953247
Validation loss: 2.050694987338076

Epoch: 5| Step: 1
Training loss: 2.6037979125976562
Validation loss: 2.076185646877494

Epoch: 5| Step: 2
Training loss: 2.5173606872558594
Validation loss: 2.0816065752378075

Epoch: 5| Step: 3
Training loss: 2.560838222503662
Validation loss: 2.0936208040483537

Epoch: 5| Step: 4
Training loss: 2.7236390113830566
Validation loss: 2.0861689198401665

Epoch: 5| Step: 5
Training loss: 1.7669137716293335
Validation loss: 2.0662052836469424

Epoch: 5| Step: 6
Training loss: 1.8160755634307861
Validation loss: 2.044215521504802

Epoch: 5| Step: 7
Training loss: 1.8938030004501343
Validation loss: 2.010974448214295

Epoch: 5| Step: 8
Training loss: 2.1147868633270264
Validation loss: 1.9997400083849508

Epoch: 5| Step: 9
Training loss: 1.3981353044509888
Validation loss: 1.9903030600599063

Epoch: 5| Step: 10
Training loss: 1.2909579277038574
Validation loss: 2.006090417984993

Epoch: 121| Step: 0
Training loss: 2.211043119430542
Validation loss: 2.008634808242962

Epoch: 5| Step: 1
Training loss: 2.053711414337158
Validation loss: 2.0043169965026197

Epoch: 5| Step: 2
Training loss: 1.8373275995254517
Validation loss: 2.0205820619419055

Epoch: 5| Step: 3
Training loss: 2.2299304008483887
Validation loss: 2.0338834075517553

Epoch: 5| Step: 4
Training loss: 1.9615437984466553
Validation loss: 2.0375257743302213

Epoch: 5| Step: 5
Training loss: 1.7698907852172852
Validation loss: 2.049944762260683

Epoch: 5| Step: 6
Training loss: 2.1938624382019043
Validation loss: 2.0602936283234627

Epoch: 5| Step: 7
Training loss: 2.224696397781372
Validation loss: 2.0664630038763887

Epoch: 5| Step: 8
Training loss: 1.9046621322631836
Validation loss: 2.0725956527135705

Epoch: 5| Step: 9
Training loss: 2.0021555423736572
Validation loss: 2.0580057418474587

Epoch: 5| Step: 10
Training loss: 2.3083198070526123
Validation loss: 2.0546633787052606

Epoch: 122| Step: 0
Training loss: 2.0544238090515137
Validation loss: 2.038628629458848

Epoch: 5| Step: 1
Training loss: 2.8323097229003906
Validation loss: 2.038245649747951

Epoch: 5| Step: 2
Training loss: 2.037543773651123
Validation loss: 2.0238868036577777

Epoch: 5| Step: 3
Training loss: 1.7471277713775635
Validation loss: 2.0268287927873674

Epoch: 5| Step: 4
Training loss: 1.7773287296295166
Validation loss: 2.0185950263853996

Epoch: 5| Step: 5
Training loss: 1.7457380294799805
Validation loss: 2.0323841648717083

Epoch: 5| Step: 6
Training loss: 1.7648481130599976
Validation loss: 2.0490908571468887

Epoch: 5| Step: 7
Training loss: 2.253790855407715
Validation loss: 2.074161068085701

Epoch: 5| Step: 8
Training loss: 1.755495309829712
Validation loss: 2.0553529339451946

Epoch: 5| Step: 9
Training loss: 2.2784640789031982
Validation loss: 2.042876915265155

Epoch: 5| Step: 10
Training loss: 2.058422327041626
Validation loss: 2.030790992962417

Epoch: 123| Step: 0
Training loss: 2.040712833404541
Validation loss: 2.044108466435504

Epoch: 5| Step: 1
Training loss: 2.0861334800720215
Validation loss: 2.061975158670897

Epoch: 5| Step: 2
Training loss: 1.768547773361206
Validation loss: 2.0673641825235016

Epoch: 5| Step: 3
Training loss: 1.5666307210922241
Validation loss: 2.073484141339538

Epoch: 5| Step: 4
Training loss: 1.9272578954696655
Validation loss: 2.0985733514191

Epoch: 5| Step: 5
Training loss: 2.110307216644287
Validation loss: 2.1258399883906045

Epoch: 5| Step: 6
Training loss: 2.3905205726623535
Validation loss: 2.132754756558326

Epoch: 5| Step: 7
Training loss: 1.494227647781372
Validation loss: 2.1525446573893228

Epoch: 5| Step: 8
Training loss: 1.708992600440979
Validation loss: 2.1602883018473142

Epoch: 5| Step: 9
Training loss: 2.7943131923675537
Validation loss: 2.1264392432346138

Epoch: 5| Step: 10
Training loss: 2.675271987915039
Validation loss: 2.09611242048202

Epoch: 124| Step: 0
Training loss: 2.0824756622314453
Validation loss: 2.069202797387236

Epoch: 5| Step: 1
Training loss: 2.0108485221862793
Validation loss: 2.0492995451855403

Epoch: 5| Step: 2
Training loss: 1.5109117031097412
Validation loss: 2.0383579769442157

Epoch: 5| Step: 3
Training loss: 2.0194761753082275
Validation loss: 2.04417424560875

Epoch: 5| Step: 4
Training loss: 2.0207438468933105
Validation loss: 2.0596183730709936

Epoch: 5| Step: 5
Training loss: 2.1822121143341064
Validation loss: 2.0577597207920526

Epoch: 5| Step: 6
Training loss: 1.9570887088775635
Validation loss: 2.0498985193109

Epoch: 5| Step: 7
Training loss: 2.12453031539917
Validation loss: 2.05710611292111

Epoch: 5| Step: 8
Training loss: 2.1029021739959717
Validation loss: 2.0550318917920514

Epoch: 5| Step: 9
Training loss: 1.8055601119995117
Validation loss: 2.041909074270597

Epoch: 5| Step: 10
Training loss: 2.103696823120117
Validation loss: 2.0628301482046805

Epoch: 125| Step: 0
Training loss: 2.0789058208465576
Validation loss: 2.0576895360023744

Epoch: 5| Step: 1
Training loss: 2.253540515899658
Validation loss: 2.062609616146293

Epoch: 5| Step: 2
Training loss: 1.3864190578460693
Validation loss: 2.075246234093943

Epoch: 5| Step: 3
Training loss: 1.9837381839752197
Validation loss: 2.060451420404578

Epoch: 5| Step: 4
Training loss: 2.0188632011413574
Validation loss: 2.068331128807478

Epoch: 5| Step: 5
Training loss: 2.166901111602783
Validation loss: 2.0467994879650813

Epoch: 5| Step: 6
Training loss: 2.2269015312194824
Validation loss: 2.041081210618378

Epoch: 5| Step: 7
Training loss: 2.2579314708709717
Validation loss: 2.022423119955165

Epoch: 5| Step: 8
Training loss: 2.0034339427948
Validation loss: 2.0082859505889235

Epoch: 5| Step: 9
Training loss: 1.7322715520858765
Validation loss: 2.0103358607138357

Epoch: 5| Step: 10
Training loss: 1.7136969566345215
Validation loss: 2.0166455109914145

Epoch: 126| Step: 0
Training loss: 1.9525673389434814
Validation loss: 2.015478471274017

Epoch: 5| Step: 1
Training loss: 2.2171008586883545
Validation loss: 2.0146365293892483

Epoch: 5| Step: 2
Training loss: 2.1363162994384766
Validation loss: 2.0080945543063584

Epoch: 5| Step: 3
Training loss: 1.9256250858306885
Validation loss: 2.011867594975297

Epoch: 5| Step: 4
Training loss: 2.029797077178955
Validation loss: 2.026839199886527

Epoch: 5| Step: 5
Training loss: 2.3232946395874023
Validation loss: 2.0361166333639495

Epoch: 5| Step: 6
Training loss: 2.389331340789795
Validation loss: 2.0347558606055474

Epoch: 5| Step: 7
Training loss: 1.6973302364349365
Validation loss: 2.0484926110954693

Epoch: 5| Step: 8
Training loss: 1.5934326648712158
Validation loss: 2.0370621501758532

Epoch: 5| Step: 9
Training loss: 1.8288217782974243
Validation loss: 2.054137655483779

Epoch: 5| Step: 10
Training loss: 1.725561499595642
Validation loss: 2.0675030216093986

Epoch: 127| Step: 0
Training loss: 1.4927440881729126
Validation loss: 2.060968073465491

Epoch: 5| Step: 1
Training loss: 2.7904584407806396
Validation loss: 2.074121108619116

Epoch: 5| Step: 2
Training loss: 1.7616455554962158
Validation loss: 2.0865518380236883

Epoch: 5| Step: 3
Training loss: 1.907748818397522
Validation loss: 2.1010508934656777

Epoch: 5| Step: 4
Training loss: 1.6455329656600952
Validation loss: 2.090237489310644

Epoch: 5| Step: 5
Training loss: 2.488342761993408
Validation loss: 2.074238141377767

Epoch: 5| Step: 6
Training loss: 1.1620384454727173
Validation loss: 2.065828520764587

Epoch: 5| Step: 7
Training loss: 1.858700156211853
Validation loss: 2.067403639516523

Epoch: 5| Step: 8
Training loss: 2.2328085899353027
Validation loss: 2.056579771862235

Epoch: 5| Step: 9
Training loss: 2.103450298309326
Validation loss: 2.0774930279742003

Epoch: 5| Step: 10
Training loss: 2.165360689163208
Validation loss: 2.0827119094069286

Epoch: 128| Step: 0
Training loss: 2.030679702758789
Validation loss: 2.1005774774859027

Epoch: 5| Step: 1
Training loss: 1.7821718454360962
Validation loss: 2.1056799068245837

Epoch: 5| Step: 2
Training loss: 2.1630187034606934
Validation loss: 2.1029533006811656

Epoch: 5| Step: 3
Training loss: 2.1505842208862305
Validation loss: 2.082117857471589

Epoch: 5| Step: 4
Training loss: 2.085258960723877
Validation loss: 2.0826534532731578

Epoch: 5| Step: 5
Training loss: 2.32409930229187
Validation loss: 2.067858075582853

Epoch: 5| Step: 6
Training loss: 1.5898232460021973
Validation loss: 2.057831856512254

Epoch: 5| Step: 7
Training loss: 2.019505500793457
Validation loss: 2.044667492630661

Epoch: 5| Step: 8
Training loss: 1.9214742183685303
Validation loss: 2.0314717267149236

Epoch: 5| Step: 9
Training loss: 1.8170650005340576
Validation loss: 2.0460313750851538

Epoch: 5| Step: 10
Training loss: 1.8179601430892944
Validation loss: 2.059763608440276

Epoch: 129| Step: 0
Training loss: 1.3319169282913208
Validation loss: 2.0645503792711484

Epoch: 5| Step: 1
Training loss: 2.018711566925049
Validation loss: 2.06476273844319

Epoch: 5| Step: 2
Training loss: 2.033581256866455
Validation loss: 2.0646695424151678

Epoch: 5| Step: 3
Training loss: 2.1534483432769775
Validation loss: 2.073426660671029

Epoch: 5| Step: 4
Training loss: 1.771908164024353
Validation loss: 2.060304502005218

Epoch: 5| Step: 5
Training loss: 2.143105983734131
Validation loss: 2.0549300409132436

Epoch: 5| Step: 6
Training loss: 2.2203152179718018
Validation loss: 2.0523294518070836

Epoch: 5| Step: 7
Training loss: 1.9911222457885742
Validation loss: 2.0588123260005826

Epoch: 5| Step: 8
Training loss: 2.0412888526916504
Validation loss: 2.0638322984018633

Epoch: 5| Step: 9
Training loss: 1.679222822189331
Validation loss: 2.0566126915716354

Epoch: 5| Step: 10
Training loss: 1.8980984687805176
Validation loss: 2.0494119505728445

Epoch: 130| Step: 0
Training loss: 1.7740672826766968
Validation loss: 2.0376609602282123

Epoch: 5| Step: 1
Training loss: 1.985144019126892
Validation loss: 2.021726841567665

Epoch: 5| Step: 2
Training loss: 2.140265941619873
Validation loss: 2.0176659040553595

Epoch: 5| Step: 3
Training loss: 1.8377037048339844
Validation loss: 2.011845028528603

Epoch: 5| Step: 4
Training loss: 1.921339988708496
Validation loss: 2.0110224793034215

Epoch: 5| Step: 5
Training loss: 2.378862142562866
Validation loss: 2.022434235900961

Epoch: 5| Step: 6
Training loss: 1.5654771327972412
Validation loss: 2.028042580491753

Epoch: 5| Step: 7
Training loss: 1.6051180362701416
Validation loss: 2.0493147168108212

Epoch: 5| Step: 8
Training loss: 2.1028785705566406
Validation loss: 2.0707633110784713

Epoch: 5| Step: 9
Training loss: 1.7665834426879883
Validation loss: 2.129746012790229

Epoch: 5| Step: 10
Training loss: 2.288950204849243
Validation loss: 2.143554664427234

Epoch: 131| Step: 0
Training loss: 1.7502832412719727
Validation loss: 2.1818610955310125

Epoch: 5| Step: 1
Training loss: 2.5939533710479736
Validation loss: 2.1711334797643844

Epoch: 5| Step: 2
Training loss: 1.678556203842163
Validation loss: 2.1384075585231987

Epoch: 5| Step: 3
Training loss: 2.0615074634552
Validation loss: 2.10921537235219

Epoch: 5| Step: 4
Training loss: 1.9805701971054077
Validation loss: 2.0691185433377504

Epoch: 5| Step: 5
Training loss: 1.9533612728118896
Validation loss: 2.0572543067316853

Epoch: 5| Step: 6
Training loss: 1.6060104370117188
Validation loss: 2.0349959865693124

Epoch: 5| Step: 7
Training loss: 1.6527070999145508
Validation loss: 2.0258884276113203

Epoch: 5| Step: 8
Training loss: 2.003596067428589
Validation loss: 2.01712090610176

Epoch: 5| Step: 9
Training loss: 2.130258083343506
Validation loss: 2.007428084650347

Epoch: 5| Step: 10
Training loss: 1.9323984384536743
Validation loss: 2.008987278066656

Epoch: 132| Step: 0
Training loss: 1.7768900394439697
Validation loss: 2.0110329684390815

Epoch: 5| Step: 1
Training loss: 1.8311189413070679
Validation loss: 2.026743688891011

Epoch: 5| Step: 2
Training loss: 2.0967578887939453
Validation loss: 2.032661605906743

Epoch: 5| Step: 3
Training loss: 1.7617079019546509
Validation loss: 2.0221381187438965

Epoch: 5| Step: 4
Training loss: 1.9628970623016357
Validation loss: 2.0401181277408393

Epoch: 5| Step: 5
Training loss: 1.9132366180419922
Validation loss: 2.087771549019762

Epoch: 5| Step: 6
Training loss: 1.707681655883789
Validation loss: 2.1006789617640997

Epoch: 5| Step: 7
Training loss: 2.0835022926330566
Validation loss: 2.1219428175239154

Epoch: 5| Step: 8
Training loss: 2.3895270824432373
Validation loss: 2.1343633231296333

Epoch: 5| Step: 9
Training loss: 2.208850383758545
Validation loss: 2.1323492116825555

Epoch: 5| Step: 10
Training loss: 1.1787761449813843
Validation loss: 2.130089203516642

Epoch: 133| Step: 0
Training loss: 1.7418339252471924
Validation loss: 2.124657395065472

Epoch: 5| Step: 1
Training loss: 1.9385645389556885
Validation loss: 2.103064728039567

Epoch: 5| Step: 2
Training loss: 1.947370171546936
Validation loss: 2.0858705005338116

Epoch: 5| Step: 3
Training loss: 1.6361496448516846
Validation loss: 2.0725093272424515

Epoch: 5| Step: 4
Training loss: 2.332720994949341
Validation loss: 2.0506686779760543

Epoch: 5| Step: 5
Training loss: 1.401931643486023
Validation loss: 2.0238358513001473

Epoch: 5| Step: 6
Training loss: 2.26709246635437
Validation loss: 2.0091717063739734

Epoch: 5| Step: 7
Training loss: 2.0919971466064453
Validation loss: 2.0196332957154963

Epoch: 5| Step: 8
Training loss: 2.007049560546875
Validation loss: 2.0090799921302387

Epoch: 5| Step: 9
Training loss: 1.8902921676635742
Validation loss: 2.0161702607267644

Epoch: 5| Step: 10
Training loss: 1.9543977975845337
Validation loss: 2.017191078073235

Epoch: 134| Step: 0
Training loss: 2.1097140312194824
Validation loss: 2.03903523055456

Epoch: 5| Step: 1
Training loss: 2.1718406677246094
Validation loss: 2.0649169286092124

Epoch: 5| Step: 2
Training loss: 2.027127265930176
Validation loss: 2.079863950770388

Epoch: 5| Step: 3
Training loss: 2.072018623352051
Validation loss: 2.0900497103250153

Epoch: 5| Step: 4
Training loss: 1.9352896213531494
Validation loss: 2.080209985856087

Epoch: 5| Step: 5
Training loss: 2.014317035675049
Validation loss: 2.063596881845946

Epoch: 5| Step: 6
Training loss: 1.7406905889511108
Validation loss: 2.032279791370515

Epoch: 5| Step: 7
Training loss: 1.4288526773452759
Validation loss: 2.0304384231567383

Epoch: 5| Step: 8
Training loss: 1.6247851848602295
Validation loss: 2.004921947756121

Epoch: 5| Step: 9
Training loss: 1.5658161640167236
Validation loss: 2.0009295837853545

Epoch: 5| Step: 10
Training loss: 2.3829774856567383
Validation loss: 2.0043004994751303

Epoch: 135| Step: 0
Training loss: 2.0192556381225586
Validation loss: 1.9974730104528449

Epoch: 5| Step: 1
Training loss: 1.8505761623382568
Validation loss: 1.9972467037939257

Epoch: 5| Step: 2
Training loss: 1.7923526763916016
Validation loss: 2.021534853084113

Epoch: 5| Step: 3
Training loss: 2.621220827102661
Validation loss: 2.025953931193198

Epoch: 5| Step: 4
Training loss: 1.2604920864105225
Validation loss: 2.0477480760184665

Epoch: 5| Step: 5
Training loss: 2.247342586517334
Validation loss: 2.0611479384924776

Epoch: 5| Step: 6
Training loss: 1.6067171096801758
Validation loss: 2.0914567683332708

Epoch: 5| Step: 7
Training loss: 0.7625842690467834
Validation loss: 2.089557073449576

Epoch: 5| Step: 8
Training loss: 2.030661106109619
Validation loss: 2.0835491431656705

Epoch: 5| Step: 9
Training loss: 2.5413966178894043
Validation loss: 2.0887004380585044

Epoch: 5| Step: 10
Training loss: 1.9175509214401245
Validation loss: 2.078085567361565

Epoch: 136| Step: 0
Training loss: 2.1130318641662598
Validation loss: 2.0483612245129

Epoch: 5| Step: 1
Training loss: 2.069899559020996
Validation loss: 2.0448610385258994

Epoch: 5| Step: 2
Training loss: 1.860201120376587
Validation loss: 2.044821159813994

Epoch: 5| Step: 3
Training loss: 2.0334129333496094
Validation loss: 2.039587205456149

Epoch: 5| Step: 4
Training loss: 1.4433472156524658
Validation loss: 2.04749160428201

Epoch: 5| Step: 5
Training loss: 1.9688705205917358
Validation loss: 2.0530517844743628

Epoch: 5| Step: 6
Training loss: 1.8327440023422241
Validation loss: 2.053450483147816

Epoch: 5| Step: 7
Training loss: 1.5181909799575806
Validation loss: 2.0568948202235724

Epoch: 5| Step: 8
Training loss: 1.9187772274017334
Validation loss: 2.0547378063201904

Epoch: 5| Step: 9
Training loss: 1.268747329711914
Validation loss: 2.048207494520372

Epoch: 5| Step: 10
Training loss: 2.784710645675659
Validation loss: 2.0324601127255346

Epoch: 137| Step: 0
Training loss: 1.7457168102264404
Validation loss: 2.0435474354733705

Epoch: 5| Step: 1
Training loss: 2.315639019012451
Validation loss: 2.0389291932505946

Epoch: 5| Step: 2
Training loss: 1.9529978036880493
Validation loss: 2.041808714148819

Epoch: 5| Step: 3
Training loss: 2.0230751037597656
Validation loss: 2.047907442174932

Epoch: 5| Step: 4
Training loss: 1.7637567520141602
Validation loss: 2.0628897759222213

Epoch: 5| Step: 5
Training loss: 1.4918617010116577
Validation loss: 2.0681687849824146

Epoch: 5| Step: 6
Training loss: 1.8167273998260498
Validation loss: 2.0783909059339956

Epoch: 5| Step: 7
Training loss: 1.495507001876831
Validation loss: 2.08424404744179

Epoch: 5| Step: 8
Training loss: 1.5993566513061523
Validation loss: 2.0625893685125534

Epoch: 5| Step: 9
Training loss: 2.260202407836914
Validation loss: 2.04678838868295

Epoch: 5| Step: 10
Training loss: 2.1796040534973145
Validation loss: 2.0418059825897217

Epoch: 138| Step: 0
Training loss: 1.8676722049713135
Validation loss: 2.0163383586432344

Epoch: 5| Step: 1
Training loss: 1.8080501556396484
Validation loss: 2.0159283555963987

Epoch: 5| Step: 2
Training loss: 1.6097772121429443
Validation loss: 2.0213812769100232

Epoch: 5| Step: 3
Training loss: 2.586022138595581
Validation loss: 2.02150046953591

Epoch: 5| Step: 4
Training loss: 2.072636365890503
Validation loss: 2.0402229883337535

Epoch: 5| Step: 5
Training loss: 1.3824752569198608
Validation loss: 2.0854035218556723

Epoch: 5| Step: 6
Training loss: 1.402875304222107
Validation loss: 2.094471977603051

Epoch: 5| Step: 7
Training loss: 2.5428688526153564
Validation loss: 2.1206770379056215

Epoch: 5| Step: 8
Training loss: 2.2599105834960938
Validation loss: 2.1344588136160247

Epoch: 5| Step: 9
Training loss: 1.287559986114502
Validation loss: 2.1135554211114043

Epoch: 5| Step: 10
Training loss: 1.285064935684204
Validation loss: 2.0894751292403027

Epoch: 139| Step: 0
Training loss: 2.1492621898651123
Validation loss: 2.067655360826882

Epoch: 5| Step: 1
Training loss: 1.6501861810684204
Validation loss: 2.044522548234591

Epoch: 5| Step: 2
Training loss: 1.8309497833251953
Validation loss: 2.0270691456333285

Epoch: 5| Step: 3
Training loss: 2.1954569816589355
Validation loss: 2.011153931258827

Epoch: 5| Step: 4
Training loss: 1.532016396522522
Validation loss: 1.9934819359933176

Epoch: 5| Step: 5
Training loss: 1.981461763381958
Validation loss: 2.0160455191007225

Epoch: 5| Step: 6
Training loss: 2.167025089263916
Validation loss: 2.0624248878930205

Epoch: 5| Step: 7
Training loss: 1.5145068168640137
Validation loss: 2.069582600747385

Epoch: 5| Step: 8
Training loss: 1.5300501585006714
Validation loss: 2.068755806133311

Epoch: 5| Step: 9
Training loss: 1.6720244884490967
Validation loss: 2.0822666460467922

Epoch: 5| Step: 10
Training loss: 2.0082976818084717
Validation loss: 2.06438676516215

Epoch: 140| Step: 0
Training loss: 1.6650750637054443
Validation loss: 2.0529937949231876

Epoch: 5| Step: 1
Training loss: 2.2833077907562256
Validation loss: 2.0549141873595533

Epoch: 5| Step: 2
Training loss: 1.7205263376235962
Validation loss: 2.0552017381114345

Epoch: 5| Step: 3
Training loss: 1.753525972366333
Validation loss: 2.061824180746591

Epoch: 5| Step: 4
Training loss: 1.8723506927490234
Validation loss: 2.059954253576135

Epoch: 5| Step: 5
Training loss: 1.7181921005249023
Validation loss: 2.0594449402183614

Epoch: 5| Step: 6
Training loss: 2.14373779296875
Validation loss: 2.070108198350476

Epoch: 5| Step: 7
Training loss: 1.9489330053329468
Validation loss: 2.053264376937702

Epoch: 5| Step: 8
Training loss: 1.3731682300567627
Validation loss: 2.0475535238942792

Epoch: 5| Step: 9
Training loss: 1.7012546062469482
Validation loss: 2.042526933454698

Epoch: 5| Step: 10
Training loss: 1.812482237815857
Validation loss: 2.036304868677611

Epoch: 141| Step: 0
Training loss: 1.887857437133789
Validation loss: 2.0341429351478495

Epoch: 5| Step: 1
Training loss: 1.6274887323379517
Validation loss: 2.036477211982973

Epoch: 5| Step: 2
Training loss: 1.901445746421814
Validation loss: 2.05358693163882

Epoch: 5| Step: 3
Training loss: 1.764915108680725
Validation loss: 2.066067326453424

Epoch: 5| Step: 4
Training loss: 1.9456958770751953
Validation loss: 2.074896817566246

Epoch: 5| Step: 5
Training loss: 2.6257452964782715
Validation loss: 2.095741900064612

Epoch: 5| Step: 6
Training loss: 1.9304441213607788
Validation loss: 2.0826925936565606

Epoch: 5| Step: 7
Training loss: 1.5532596111297607
Validation loss: 2.04618142753519

Epoch: 5| Step: 8
Training loss: 1.609236717224121
Validation loss: 2.025487756216398

Epoch: 5| Step: 9
Training loss: 1.3839629888534546
Validation loss: 2.009420828152728

Epoch: 5| Step: 10
Training loss: 1.6914454698562622
Validation loss: 2.004126052702627

Epoch: 142| Step: 0
Training loss: 2.4708149433135986
Validation loss: 2.007446121144038

Epoch: 5| Step: 1
Training loss: 1.0876705646514893
Validation loss: 1.999749199036629

Epoch: 5| Step: 2
Training loss: 1.8589998483657837
Validation loss: 2.0163667304541475

Epoch: 5| Step: 3
Training loss: 1.891661286354065
Validation loss: 2.0521474845947756

Epoch: 5| Step: 4
Training loss: 2.147265911102295
Validation loss: 2.0812866354501374

Epoch: 5| Step: 5
Training loss: 1.235757827758789
Validation loss: 2.1080956946137133

Epoch: 5| Step: 6
Training loss: 1.7571035623550415
Validation loss: 2.109718471445063

Epoch: 5| Step: 7
Training loss: 0.9402974843978882
Validation loss: 2.090103792887862

Epoch: 5| Step: 8
Training loss: 2.11279559135437
Validation loss: 2.079140051718681

Epoch: 5| Step: 9
Training loss: 2.09639310836792
Validation loss: 2.0584793936821724

Epoch: 5| Step: 10
Training loss: 2.1960878372192383
Validation loss: 2.0432979112030356

Epoch: 143| Step: 0
Training loss: 1.558798909187317
Validation loss: 2.028500941491896

Epoch: 5| Step: 1
Training loss: 2.3655190467834473
Validation loss: 2.003213067208567

Epoch: 5| Step: 2
Training loss: 1.4957994222640991
Validation loss: 2.0267111960277764

Epoch: 5| Step: 3
Training loss: 2.056291103363037
Validation loss: 2.002936374756598

Epoch: 5| Step: 4
Training loss: 1.6768763065338135
Validation loss: 2.0178752304405294

Epoch: 5| Step: 5
Training loss: 1.487514853477478
Validation loss: 2.020195266251923

Epoch: 5| Step: 6
Training loss: 2.0402495861053467
Validation loss: 2.030402855206561

Epoch: 5| Step: 7
Training loss: 1.5905276536941528
Validation loss: 2.0548126133539344

Epoch: 5| Step: 8
Training loss: 1.977847695350647
Validation loss: 2.081976659836308

Epoch: 5| Step: 9
Training loss: 1.7191261053085327
Validation loss: 2.107763995406448

Epoch: 5| Step: 10
Training loss: 1.6066721677780151
Validation loss: 2.088178752571024

Epoch: 144| Step: 0
Training loss: 1.703778624534607
Validation loss: 2.088650426556987

Epoch: 5| Step: 1
Training loss: 2.019059658050537
Validation loss: 2.084979675149405

Epoch: 5| Step: 2
Training loss: 1.6345221996307373
Validation loss: 2.082409184466126

Epoch: 5| Step: 3
Training loss: 0.8964767456054688
Validation loss: 2.074587211813978

Epoch: 5| Step: 4
Training loss: 2.095027446746826
Validation loss: 2.0570332350269442

Epoch: 5| Step: 5
Training loss: 1.877009630203247
Validation loss: 2.037004037569928

Epoch: 5| Step: 6
Training loss: 1.4176485538482666
Validation loss: 2.0118970922244492

Epoch: 5| Step: 7
Training loss: 1.5804967880249023
Validation loss: 2.004905862192954

Epoch: 5| Step: 8
Training loss: 1.7086379528045654
Validation loss: 2.0140029191970825

Epoch: 5| Step: 9
Training loss: 2.162386655807495
Validation loss: 1.9983891133339173

Epoch: 5| Step: 10
Training loss: 2.230483055114746
Validation loss: 1.9849754789824128

Epoch: 145| Step: 0
Training loss: 1.8375682830810547
Validation loss: 2.004071932966991

Epoch: 5| Step: 1
Training loss: 1.8504480123519897
Validation loss: 1.9950004393054592

Epoch: 5| Step: 2
Training loss: 1.6813716888427734
Validation loss: 2.003407880824099

Epoch: 5| Step: 3
Training loss: 1.6841129064559937
Validation loss: 2.026501678651379

Epoch: 5| Step: 4
Training loss: 1.5022993087768555
Validation loss: 2.0483245900882188

Epoch: 5| Step: 5
Training loss: 1.8441894054412842
Validation loss: 2.0761081121301137

Epoch: 5| Step: 6
Training loss: 1.7968677282333374
Validation loss: 2.113688503542254

Epoch: 5| Step: 7
Training loss: 1.9007532596588135
Validation loss: 2.106171149079518

Epoch: 5| Step: 8
Training loss: 2.0595157146453857
Validation loss: 2.08953187798941

Epoch: 5| Step: 9
Training loss: 1.5543180704116821
Validation loss: 2.064422849685915

Epoch: 5| Step: 10
Training loss: 1.4430227279663086
Validation loss: 2.0457341773535616

Epoch: 146| Step: 0
Training loss: 1.6307023763656616
Validation loss: 2.0217859129751883

Epoch: 5| Step: 1
Training loss: 1.3079469203948975
Validation loss: 2.024668842233637

Epoch: 5| Step: 2
Training loss: 2.049898862838745
Validation loss: 2.027695405867792

Epoch: 5| Step: 3
Training loss: 1.557813286781311
Validation loss: 2.036169409751892

Epoch: 5| Step: 4
Training loss: 1.9068920612335205
Validation loss: 2.033894428642847

Epoch: 5| Step: 5
Training loss: 1.4279948472976685
Validation loss: 2.023681281715311

Epoch: 5| Step: 6
Training loss: 2.704591751098633
Validation loss: 2.0412906472400953

Epoch: 5| Step: 7
Training loss: 1.4735233783721924
Validation loss: 2.025715313931947

Epoch: 5| Step: 8
Training loss: 1.7886230945587158
Validation loss: 2.0391536117881857

Epoch: 5| Step: 9
Training loss: 1.247707486152649
Validation loss: 2.0653315410819104

Epoch: 5| Step: 10
Training loss: 1.7260154485702515
Validation loss: 2.0447954952075915

Epoch: 147| Step: 0
Training loss: 1.938964605331421
Validation loss: 2.0401243445693806

Epoch: 5| Step: 1
Training loss: 0.9744512438774109
Validation loss: 2.0412137867302023

Epoch: 5| Step: 2
Training loss: 1.6447871923446655
Validation loss: 2.0351602415884695

Epoch: 5| Step: 3
Training loss: 2.0740222930908203
Validation loss: 2.0619894894220496

Epoch: 5| Step: 4
Training loss: 1.5315721035003662
Validation loss: 2.076579987361867

Epoch: 5| Step: 5
Training loss: 1.7738233804702759
Validation loss: 2.121353524987416

Epoch: 5| Step: 6
Training loss: 1.4844845533370972
Validation loss: 2.1008895815059705

Epoch: 5| Step: 7
Training loss: 1.8627071380615234
Validation loss: 2.1179125898627826

Epoch: 5| Step: 8
Training loss: 2.0595860481262207
Validation loss: 2.129087307119882

Epoch: 5| Step: 9
Training loss: 1.255499243736267
Validation loss: 2.1286986797086653

Epoch: 5| Step: 10
Training loss: 2.470231771469116
Validation loss: 2.0997991100434334

Epoch: 148| Step: 0
Training loss: 1.3391337394714355
Validation loss: 2.041387273419288

Epoch: 5| Step: 1
Training loss: 2.0829176902770996
Validation loss: 1.984673712843208

Epoch: 5| Step: 2
Training loss: 1.9122169017791748
Validation loss: 1.976824491254745

Epoch: 5| Step: 3
Training loss: 2.1006176471710205
Validation loss: 1.9505568627388246

Epoch: 5| Step: 4
Training loss: 1.5843018293380737
Validation loss: 1.9633537364262406

Epoch: 5| Step: 5
Training loss: 1.2327522039413452
Validation loss: 1.950470955141129

Epoch: 5| Step: 6
Training loss: 1.5080360174179077
Validation loss: 1.9362706381787536

Epoch: 5| Step: 7
Training loss: 1.8777799606323242
Validation loss: 1.9691657558564217

Epoch: 5| Step: 8
Training loss: 1.9425853490829468
Validation loss: 2.0004986793764177

Epoch: 5| Step: 9
Training loss: 1.6709492206573486
Validation loss: 2.0583727718681417

Epoch: 5| Step: 10
Training loss: 1.7906339168548584
Validation loss: 2.097943495678645

Epoch: 149| Step: 0
Training loss: 1.6451209783554077
Validation loss: 2.0931436579714537

Epoch: 5| Step: 1
Training loss: 2.134371519088745
Validation loss: 2.1157017420696955

Epoch: 5| Step: 2
Training loss: 1.8982912302017212
Validation loss: 2.115629901168167

Epoch: 5| Step: 3
Training loss: 1.326897382736206
Validation loss: 2.126382852113375

Epoch: 5| Step: 4
Training loss: 1.1279648542404175
Validation loss: 2.0940835168284755

Epoch: 5| Step: 5
Training loss: 1.3355950117111206
Validation loss: 2.110464349869759

Epoch: 5| Step: 6
Training loss: 1.6585487127304077
Validation loss: 2.080908818911481

Epoch: 5| Step: 7
Training loss: 1.6215355396270752
Validation loss: 2.0675931925414712

Epoch: 5| Step: 8
Training loss: 2.2569568157196045
Validation loss: 2.062980790292063

Epoch: 5| Step: 9
Training loss: 1.5090105533599854
Validation loss: 2.077239344196935

Epoch: 5| Step: 10
Training loss: 2.1884493827819824
Validation loss: 2.0690619355888775

Epoch: 150| Step: 0
Training loss: 1.3934452533721924
Validation loss: 2.0467204868152575

Epoch: 5| Step: 1
Training loss: 1.5719012022018433
Validation loss: 2.01683384372342

Epoch: 5| Step: 2
Training loss: 1.4806244373321533
Validation loss: 1.9868694402838265

Epoch: 5| Step: 3
Training loss: 2.1479902267456055
Validation loss: 1.9780940535247966

Epoch: 5| Step: 4
Training loss: 2.130552291870117
Validation loss: 1.95261424843983

Epoch: 5| Step: 5
Training loss: 1.4164855480194092
Validation loss: 1.9536295783135198

Epoch: 5| Step: 6
Training loss: 1.872011423110962
Validation loss: 1.9513119087424329

Epoch: 5| Step: 7
Training loss: 2.100726366043091
Validation loss: 1.9750219545056742

Epoch: 5| Step: 8
Training loss: 1.545099139213562
Validation loss: 1.9913875467033797

Epoch: 5| Step: 9
Training loss: 1.432610034942627
Validation loss: 2.023057628703374

Epoch: 5| Step: 10
Training loss: 1.6044416427612305
Validation loss: 2.042408690657667

Epoch: 151| Step: 0
Training loss: 2.4944403171539307
Validation loss: 2.122005938201822

Epoch: 5| Step: 1
Training loss: 1.8166431188583374
Validation loss: 2.1449532226849626

Epoch: 5| Step: 2
Training loss: 2.191997528076172
Validation loss: 2.1736844919061147

Epoch: 5| Step: 3
Training loss: 1.1589608192443848
Validation loss: 2.1758414673548874

Epoch: 5| Step: 4
Training loss: 1.4619226455688477
Validation loss: 2.1541640348331903

Epoch: 5| Step: 5
Training loss: 0.89287269115448
Validation loss: 2.134789200239284

Epoch: 5| Step: 6
Training loss: 1.5291633605957031
Validation loss: 2.099796547684618

Epoch: 5| Step: 7
Training loss: 1.560757040977478
Validation loss: 2.095802025128436

Epoch: 5| Step: 8
Training loss: 1.6079133749008179
Validation loss: 2.077284756527152

Epoch: 5| Step: 9
Training loss: 2.099356174468994
Validation loss: 2.053041979830752

Epoch: 5| Step: 10
Training loss: 1.9064041376113892
Validation loss: 2.0610444289381786

Epoch: 152| Step: 0
Training loss: 1.399181604385376
Validation loss: 2.0559722249225905

Epoch: 5| Step: 1
Training loss: 1.8044618368148804
Validation loss: 2.0434856671158985

Epoch: 5| Step: 2
Training loss: 1.7925269603729248
Validation loss: 2.036545175378041

Epoch: 5| Step: 3
Training loss: 1.7381080389022827
Validation loss: 2.0555646291343113

Epoch: 5| Step: 4
Training loss: 1.6938550472259521
Validation loss: 2.035806229037623

Epoch: 5| Step: 5
Training loss: 1.8223413228988647
Validation loss: 2.044779203271353

Epoch: 5| Step: 6
Training loss: 1.769809365272522
Validation loss: 2.072409370894073

Epoch: 5| Step: 7
Training loss: 1.6091591119766235
Validation loss: 2.0871994341573408

Epoch: 5| Step: 8
Training loss: 1.4912844896316528
Validation loss: 2.1074326063997004

Epoch: 5| Step: 9
Training loss: 1.517368197441101
Validation loss: 2.1667233769611647

Epoch: 5| Step: 10
Training loss: 1.7551743984222412
Validation loss: 2.1765282846266225

Epoch: 153| Step: 0
Training loss: 1.67568039894104
Validation loss: 2.169825234720784

Epoch: 5| Step: 1
Training loss: 1.5077087879180908
Validation loss: 2.141251333298222

Epoch: 5| Step: 2
Training loss: 1.2283533811569214
Validation loss: 2.089367920352567

Epoch: 5| Step: 3
Training loss: 1.691803216934204
Validation loss: 2.053373493174071

Epoch: 5| Step: 4
Training loss: 1.8818336725234985
Validation loss: 2.0160808229959137

Epoch: 5| Step: 5
Training loss: 1.5830118656158447
Validation loss: 2.032078273834721

Epoch: 5| Step: 6
Training loss: 1.5856462717056274
Validation loss: 1.9828545047390846

Epoch: 5| Step: 7
Training loss: 2.1947402954101562
Validation loss: 1.9718401714037823

Epoch: 5| Step: 8
Training loss: 1.3092769384384155
Validation loss: 1.9754910545964395

Epoch: 5| Step: 9
Training loss: 1.895546317100525
Validation loss: 1.9873554783482705

Epoch: 5| Step: 10
Training loss: 1.4380782842636108
Validation loss: 2.00952685007485

Epoch: 154| Step: 0
Training loss: 1.8051618337631226
Validation loss: 2.041411643387169

Epoch: 5| Step: 1
Training loss: 1.6149260997772217
Validation loss: 2.0396436029864895

Epoch: 5| Step: 2
Training loss: 1.982853889465332
Validation loss: 2.0478261568213023

Epoch: 5| Step: 3
Training loss: 1.7131887674331665
Validation loss: 2.03789016508287

Epoch: 5| Step: 4
Training loss: 1.3237550258636475
Validation loss: 2.0661372138607885

Epoch: 5| Step: 5
Training loss: 1.4670671224594116
Validation loss: 2.072762007354408

Epoch: 5| Step: 6
Training loss: 1.7196404933929443
Validation loss: 2.0514531020195252

Epoch: 5| Step: 7
Training loss: 1.2428491115570068
Validation loss: 2.016831277519144

Epoch: 5| Step: 8
Training loss: 1.8389335870742798
Validation loss: 1.9941844568457654

Epoch: 5| Step: 9
Training loss: 1.3034822940826416
Validation loss: 2.0030369322787047

Epoch: 5| Step: 10
Training loss: 1.6850740909576416
Validation loss: 2.0223428754396338

Epoch: 155| Step: 0
Training loss: 1.2890514135360718
Validation loss: 2.025044256641019

Epoch: 5| Step: 1
Training loss: 1.9460090398788452
Validation loss: 2.0550166227484263

Epoch: 5| Step: 2
Training loss: 1.3804190158843994
Validation loss: 2.0804914953888103

Epoch: 5| Step: 3
Training loss: 1.7959277629852295
Validation loss: 2.121610867079868

Epoch: 5| Step: 4
Training loss: 1.8003591299057007
Validation loss: 2.124725798124908

Epoch: 5| Step: 5
Training loss: 1.0716617107391357
Validation loss: 2.1185383399327598

Epoch: 5| Step: 6
Training loss: 1.8143107891082764
Validation loss: 2.0892611088291293

Epoch: 5| Step: 7
Training loss: 1.6074206829071045
Validation loss: 2.022659445321688

Epoch: 5| Step: 8
Training loss: 1.8156490325927734
Validation loss: 1.9946860664634294

Epoch: 5| Step: 9
Training loss: 1.6757951974868774
Validation loss: 1.9864775467944402

Epoch: 5| Step: 10
Training loss: 1.2944111824035645
Validation loss: 1.9824648185442852

Epoch: 156| Step: 0
Training loss: 1.5057566165924072
Validation loss: 1.9768121293796006

Epoch: 5| Step: 1
Training loss: 1.9040191173553467
Validation loss: 1.9755613573135868

Epoch: 5| Step: 2
Training loss: 1.3030816316604614
Validation loss: 1.9921242114036315

Epoch: 5| Step: 3
Training loss: 1.980196237564087
Validation loss: 2.0165417399457706

Epoch: 5| Step: 4
Training loss: 1.5800399780273438
Validation loss: 2.062182307243347

Epoch: 5| Step: 5
Training loss: 1.2079646587371826
Validation loss: 2.122320282843805

Epoch: 5| Step: 6
Training loss: 1.6220054626464844
Validation loss: 2.115158498928111

Epoch: 5| Step: 7
Training loss: 1.4817211627960205
Validation loss: 2.0690391717418546

Epoch: 5| Step: 8
Training loss: 1.7279256582260132
Validation loss: 2.034933349137665

Epoch: 5| Step: 9
Training loss: 1.060652494430542
Validation loss: 1.9996044635772705

Epoch: 5| Step: 10
Training loss: 2.245607852935791
Validation loss: 1.989554883331381

Epoch: 157| Step: 0
Training loss: 2.155289649963379
Validation loss: 1.975320944222071

Epoch: 5| Step: 1
Training loss: 2.300990104675293
Validation loss: 1.9713974101569063

Epoch: 5| Step: 2
Training loss: 1.470867395401001
Validation loss: 1.9689360767282464

Epoch: 5| Step: 3
Training loss: 1.5193476676940918
Validation loss: 1.968369237838253

Epoch: 5| Step: 4
Training loss: 1.5715632438659668
Validation loss: 1.9878132189473798

Epoch: 5| Step: 5
Training loss: 1.2091996669769287
Validation loss: 1.9855416692713255

Epoch: 5| Step: 6
Training loss: 1.5968091487884521
Validation loss: 2.037894977036343

Epoch: 5| Step: 7
Training loss: 1.4145948886871338
Validation loss: 2.0737977027893066

Epoch: 5| Step: 8
Training loss: 1.4274992942810059
Validation loss: 2.102512605728642

Epoch: 5| Step: 9
Training loss: 0.9687337875366211
Validation loss: 2.118704057508899

Epoch: 5| Step: 10
Training loss: 1.647578477859497
Validation loss: 2.104534577297908

Epoch: 158| Step: 0
Training loss: 1.7512028217315674
Validation loss: 2.13227782839088

Epoch: 5| Step: 1
Training loss: 1.5673460960388184
Validation loss: 2.111481720401395

Epoch: 5| Step: 2
Training loss: 1.661846399307251
Validation loss: 2.071029145230529

Epoch: 5| Step: 3
Training loss: 1.8101927042007446
Validation loss: 2.0339344073367376

Epoch: 5| Step: 4
Training loss: 1.288083791732788
Validation loss: 2.0267526565059537

Epoch: 5| Step: 5
Training loss: 1.5440552234649658
Validation loss: 2.0007601527757544

Epoch: 5| Step: 6
Training loss: 1.3240363597869873
Validation loss: 1.984981216410155

Epoch: 5| Step: 7
Training loss: 0.8686841726303101
Validation loss: 1.9893165275614748

Epoch: 5| Step: 8
Training loss: 1.699997901916504
Validation loss: 1.992984087236466

Epoch: 5| Step: 9
Training loss: 1.7711454629898071
Validation loss: 2.039404320460494

Epoch: 5| Step: 10
Training loss: 1.9497464895248413
Validation loss: 2.04981654690158

Epoch: 159| Step: 0
Training loss: 1.0928581953048706
Validation loss: 2.0402207656573226

Epoch: 5| Step: 1
Training loss: 1.219069480895996
Validation loss: 2.022012731080414

Epoch: 5| Step: 2
Training loss: 1.670249581336975
Validation loss: 2.0408951531174364

Epoch: 5| Step: 3
Training loss: 1.9436054229736328
Validation loss: 2.026538589949249

Epoch: 5| Step: 4
Training loss: 1.9162060022354126
Validation loss: 2.0215431849161782

Epoch: 5| Step: 5
Training loss: 1.5411198139190674
Validation loss: 2.005096061255342

Epoch: 5| Step: 6
Training loss: 1.712746024131775
Validation loss: 2.013392752216708

Epoch: 5| Step: 7
Training loss: 1.3459011316299438
Validation loss: 2.0071596343030214

Epoch: 5| Step: 8
Training loss: 1.677732229232788
Validation loss: 2.01860414525514

Epoch: 5| Step: 9
Training loss: 1.755724310874939
Validation loss: 2.0670796632766724

Epoch: 5| Step: 10
Training loss: 0.45857593417167664
Validation loss: 2.0582093269594255

Epoch: 160| Step: 0
Training loss: 1.890511155128479
Validation loss: 2.0558610513646114

Epoch: 5| Step: 1
Training loss: 1.3462820053100586
Validation loss: 2.0554852883021035

Epoch: 5| Step: 2
Training loss: 1.6927295923233032
Validation loss: 2.0502764601861276

Epoch: 5| Step: 3
Training loss: 1.5183604955673218
Validation loss: 2.021682918712657

Epoch: 5| Step: 4
Training loss: 1.9744828939437866
Validation loss: 1.978863295688424

Epoch: 5| Step: 5
Training loss: 1.657292127609253
Validation loss: 1.979161585530927

Epoch: 5| Step: 6
Training loss: 1.3137019872665405
Validation loss: 1.975865399965676

Epoch: 5| Step: 7
Training loss: 1.1230766773223877
Validation loss: 1.9650614902537356

Epoch: 5| Step: 8
Training loss: 1.2571656703948975
Validation loss: 1.9575886726379395

Epoch: 5| Step: 9
Training loss: 1.4783637523651123
Validation loss: 1.9908767746340843

Epoch: 5| Step: 10
Training loss: 1.229217767715454
Validation loss: 1.9997050403266825

Epoch: 161| Step: 0
Training loss: 1.936354398727417
Validation loss: 1.9985624359500023

Epoch: 5| Step: 1
Training loss: 1.2773905992507935
Validation loss: 2.0390737172096007

Epoch: 5| Step: 2
Training loss: 1.238578200340271
Validation loss: 2.0758538733246508

Epoch: 5| Step: 3
Training loss: 1.9173195362091064
Validation loss: 2.086924127353135

Epoch: 5| Step: 4
Training loss: 1.5536301136016846
Validation loss: 2.090938091278076

Epoch: 5| Step: 5
Training loss: 1.4494956731796265
Validation loss: 2.08526135388241

Epoch: 5| Step: 6
Training loss: 1.3713375329971313
Validation loss: 2.0841280901303856

Epoch: 5| Step: 7
Training loss: 1.3363876342773438
Validation loss: 2.0804192712230067

Epoch: 5| Step: 8
Training loss: 1.6321003437042236
Validation loss: 2.0525874976188905

Epoch: 5| Step: 9
Training loss: 1.6698150634765625
Validation loss: 2.024259092987225

Epoch: 5| Step: 10
Training loss: 1.1734592914581299
Validation loss: 1.9968234544159265

Epoch: 162| Step: 0
Training loss: 1.3433126211166382
Validation loss: 1.9828244357980707

Epoch: 5| Step: 1
Training loss: 1.6722265481948853
Validation loss: 1.9925257967364403

Epoch: 5| Step: 2
Training loss: 1.129082441329956
Validation loss: 1.9869903467034782

Epoch: 5| Step: 3
Training loss: 1.7551472187042236
Validation loss: 1.9818167366007322

Epoch: 5| Step: 4
Training loss: 1.7882028818130493
Validation loss: 2.0015104944987963

Epoch: 5| Step: 5
Training loss: 0.7852073907852173
Validation loss: 2.0484940749342724

Epoch: 5| Step: 6
Training loss: 1.2178936004638672
Validation loss: 2.075061330231287

Epoch: 5| Step: 7
Training loss: 1.3433964252471924
Validation loss: 2.0648555024977653

Epoch: 5| Step: 8
Training loss: 1.6008548736572266
Validation loss: 2.083312460171279

Epoch: 5| Step: 9
Training loss: 2.267108917236328
Validation loss: 2.085918676468634

Epoch: 5| Step: 10
Training loss: 1.3117467164993286
Validation loss: 2.064738299257012

Epoch: 163| Step: 0
Training loss: 1.5749952793121338
Validation loss: 2.046537087809655

Epoch: 5| Step: 1
Training loss: 1.4720218181610107
Validation loss: 2.0259711383491434

Epoch: 5| Step: 2
Training loss: 1.8883510828018188
Validation loss: 2.011820077896118

Epoch: 5| Step: 3
Training loss: 1.256284475326538
Validation loss: 2.0125965405535955

Epoch: 5| Step: 4
Training loss: 1.4125092029571533
Validation loss: 2.0242874801799817

Epoch: 5| Step: 5
Training loss: 1.093909502029419
Validation loss: 2.0368409220890333

Epoch: 5| Step: 6
Training loss: 1.9448856115341187
Validation loss: 2.070877239268313

Epoch: 5| Step: 7
Training loss: 1.0221821069717407
Validation loss: 2.0411960181369575

Epoch: 5| Step: 8
Training loss: 1.7461738586425781
Validation loss: 2.053158685725222

Epoch: 5| Step: 9
Training loss: 1.3552643060684204
Validation loss: 2.037926338052237

Epoch: 5| Step: 10
Training loss: 1.5881102085113525
Validation loss: 2.026898258475847

Epoch: 164| Step: 0
Training loss: 1.3710269927978516
Validation loss: 1.9951683987853348

Epoch: 5| Step: 1
Training loss: 1.4061849117279053
Validation loss: 2.0160983941888295

Epoch: 5| Step: 2
Training loss: 1.631243109703064
Validation loss: 2.0466115538791945

Epoch: 5| Step: 3
Training loss: 1.5168691873550415
Validation loss: 2.0696108443762666

Epoch: 5| Step: 4
Training loss: 2.0209195613861084
Validation loss: 2.071879276665308

Epoch: 5| Step: 5
Training loss: 1.702519178390503
Validation loss: 2.0601398944854736

Epoch: 5| Step: 6
Training loss: 1.516884446144104
Validation loss: 2.0352390350834018

Epoch: 5| Step: 7
Training loss: 0.931747317314148
Validation loss: 2.025895785259944

Epoch: 5| Step: 8
Training loss: 1.6148359775543213
Validation loss: 2.0390748746933474

Epoch: 5| Step: 9
Training loss: 1.1881656646728516
Validation loss: 2.0324288516916256

Epoch: 5| Step: 10
Training loss: 1.1687244176864624
Validation loss: 2.039245613159672

Epoch: 165| Step: 0
Training loss: 1.2193289995193481
Validation loss: 2.033932867870536

Epoch: 5| Step: 1
Training loss: 1.2103604078292847
Validation loss: 2.091638110017264

Epoch: 5| Step: 2
Training loss: 1.4273284673690796
Validation loss: 2.1108430431735132

Epoch: 5| Step: 3
Training loss: 1.3574069738388062
Validation loss: 2.089879269241005

Epoch: 5| Step: 4
Training loss: 1.8544349670410156
Validation loss: 2.0670838996928227

Epoch: 5| Step: 5
Training loss: 1.44920814037323
Validation loss: 2.0010009093951155

Epoch: 5| Step: 6
Training loss: 1.3333451747894287
Validation loss: 1.9552971214376471

Epoch: 5| Step: 7
Training loss: 1.6151902675628662
Validation loss: 1.9447302228660994

Epoch: 5| Step: 8
Training loss: 1.752781629562378
Validation loss: 1.9172582498160742

Epoch: 5| Step: 9
Training loss: 1.557261347770691
Validation loss: 1.9276726040788876

Epoch: 5| Step: 10
Training loss: 1.5900964736938477
Validation loss: 1.9355681045081026

Epoch: 166| Step: 0
Training loss: 1.4011950492858887
Validation loss: 1.9607321113668463

Epoch: 5| Step: 1
Training loss: 1.4730594158172607
Validation loss: 1.973451422106835

Epoch: 5| Step: 2
Training loss: 1.1393017768859863
Validation loss: 1.9954087067675847

Epoch: 5| Step: 3
Training loss: 1.5896146297454834
Validation loss: 2.0252885972299883

Epoch: 5| Step: 4
Training loss: 1.7875242233276367
Validation loss: 2.0627275231064006

Epoch: 5| Step: 5
Training loss: 1.3626420497894287
Validation loss: 2.0900573012649373

Epoch: 5| Step: 6
Training loss: 1.392894983291626
Validation loss: 2.0961073585735854

Epoch: 5| Step: 7
Training loss: 1.3226181268692017
Validation loss: 2.0777228237480245

Epoch: 5| Step: 8
Training loss: 1.267707109451294
Validation loss: 2.058996013415757

Epoch: 5| Step: 9
Training loss: 1.3754222393035889
Validation loss: 2.033579562299995

Epoch: 5| Step: 10
Training loss: 1.4043906927108765
Validation loss: 2.0117320168402886

Epoch: 167| Step: 0
Training loss: 1.3464781045913696
Validation loss: 1.9819856587276663

Epoch: 5| Step: 1
Training loss: 1.123900055885315
Validation loss: 1.9661579016716249

Epoch: 5| Step: 2
Training loss: 1.4410288333892822
Validation loss: 1.9498112355509112

Epoch: 5| Step: 3
Training loss: 1.3937817811965942
Validation loss: 1.9524738301513016

Epoch: 5| Step: 4
Training loss: 1.3855265378952026
Validation loss: 1.9683930950780069

Epoch: 5| Step: 5
Training loss: 1.0948476791381836
Validation loss: 2.012324274227183

Epoch: 5| Step: 6
Training loss: 1.8455816507339478
Validation loss: 2.0513589664172103

Epoch: 5| Step: 7
Training loss: 1.0753881931304932
Validation loss: 2.077738518355995

Epoch: 5| Step: 8
Training loss: 1.3224574327468872
Validation loss: 2.1341025008950183

Epoch: 5| Step: 9
Training loss: 1.1992191076278687
Validation loss: 2.0953713142743675

Epoch: 5| Step: 10
Training loss: 2.2976741790771484
Validation loss: 2.067825440437563

Epoch: 168| Step: 0
Training loss: 1.1446290016174316
Validation loss: 2.0616835060939995

Epoch: 5| Step: 1
Training loss: 1.8674592971801758
Validation loss: 2.019475225479372

Epoch: 5| Step: 2
Training loss: 1.3395785093307495
Validation loss: 2.034603798261253

Epoch: 5| Step: 3
Training loss: 1.7225795984268188
Validation loss: 2.019108005749282

Epoch: 5| Step: 4
Training loss: 1.7541446685791016
Validation loss: 1.9845144953778995

Epoch: 5| Step: 5
Training loss: 0.9328309893608093
Validation loss: 1.9776097100268129

Epoch: 5| Step: 6
Training loss: 1.624640703201294
Validation loss: 1.9943100047367874

Epoch: 5| Step: 7
Training loss: 1.2025244235992432
Validation loss: 2.0207731775058213

Epoch: 5| Step: 8
Training loss: 1.722285509109497
Validation loss: 2.024601908140285

Epoch: 5| Step: 9
Training loss: 0.7697963714599609
Validation loss: 2.0343825586380495

Epoch: 5| Step: 10
Training loss: 0.838513970375061
Validation loss: 2.0493947818715084

Epoch: 169| Step: 0
Training loss: 1.675754189491272
Validation loss: 2.0881853898366294

Epoch: 5| Step: 1
Training loss: 1.3523948192596436
Validation loss: 2.0927680551364856

Epoch: 5| Step: 2
Training loss: 1.7675622701644897
Validation loss: 2.0724826589707406

Epoch: 5| Step: 3
Training loss: 0.7998058795928955
Validation loss: 2.0242883569450787

Epoch: 5| Step: 4
Training loss: 1.3777438402175903
Validation loss: 1.9876287316763273

Epoch: 5| Step: 5
Training loss: 0.8867474794387817
Validation loss: 1.9740551261491672

Epoch: 5| Step: 6
Training loss: 1.3655697107315063
Validation loss: 1.9465053286603702

Epoch: 5| Step: 7
Training loss: 1.6863956451416016
Validation loss: 1.9966425600872244

Epoch: 5| Step: 8
Training loss: 1.355809211730957
Validation loss: 2.0202672430264053

Epoch: 5| Step: 9
Training loss: 1.3985750675201416
Validation loss: 2.0356973191743255

Epoch: 5| Step: 10
Training loss: 1.3569029569625854
Validation loss: 2.046241585926343

Epoch: 170| Step: 0
Training loss: 1.783738374710083
Validation loss: 2.0748011476250103

Epoch: 5| Step: 1
Training loss: 1.6021404266357422
Validation loss: 2.093577869476811

Epoch: 5| Step: 2
Training loss: 1.3530457019805908
Validation loss: 2.075593266435849

Epoch: 5| Step: 3
Training loss: 1.1169911623001099
Validation loss: 2.071456383633357

Epoch: 5| Step: 4
Training loss: 1.0669835805892944
Validation loss: 2.0477098085547007

Epoch: 5| Step: 5
Training loss: 1.9736320972442627
Validation loss: 2.0435547623583066

Epoch: 5| Step: 6
Training loss: 1.5961487293243408
Validation loss: 2.0361614278567735

Epoch: 5| Step: 7
Training loss: 1.021710991859436
Validation loss: 2.0074729534887497

Epoch: 5| Step: 8
Training loss: 1.2734761238098145
Validation loss: 1.9897317860716133

Epoch: 5| Step: 9
Training loss: 0.9606107473373413
Validation loss: 1.998902727198857

Epoch: 5| Step: 10
Training loss: 1.1204419136047363
Validation loss: 1.9867088589617001

Epoch: 171| Step: 0
Training loss: 1.4033437967300415
Validation loss: 2.023487352555798

Epoch: 5| Step: 1
Training loss: 1.1917698383331299
Validation loss: 2.054292940324353

Epoch: 5| Step: 2
Training loss: 1.7716480493545532
Validation loss: 2.1043310665315196

Epoch: 5| Step: 3
Training loss: 1.2780317068099976
Validation loss: 2.0954924450125745

Epoch: 5| Step: 4
Training loss: 1.0084961652755737
Validation loss: 2.0890620587974467

Epoch: 5| Step: 5
Training loss: 1.5446476936340332
Validation loss: 2.064962230702882

Epoch: 5| Step: 6
Training loss: 1.2647714614868164
Validation loss: 2.0263762832969747

Epoch: 5| Step: 7
Training loss: 1.6612974405288696
Validation loss: 2.009055047906855

Epoch: 5| Step: 8
Training loss: 1.84912109375
Validation loss: 1.991617351449946

Epoch: 5| Step: 9
Training loss: 1.0191752910614014
Validation loss: 1.98544825789749

Epoch: 5| Step: 10
Training loss: 0.7643634676933289
Validation loss: 1.9289416254207652

Epoch: 172| Step: 0
Training loss: 1.1899129152297974
Validation loss: 1.9451111785827144

Epoch: 5| Step: 1
Training loss: 1.22549307346344
Validation loss: 1.930065829266784

Epoch: 5| Step: 2
Training loss: 1.2543424367904663
Validation loss: 1.9499080591304327

Epoch: 5| Step: 3
Training loss: 1.4433952569961548
Validation loss: 1.9673035926716302

Epoch: 5| Step: 4
Training loss: 0.9800748825073242
Validation loss: 1.968428022118025

Epoch: 5| Step: 5
Training loss: 1.6540828943252563
Validation loss: 2.0107683802163727

Epoch: 5| Step: 6
Training loss: 1.473405122756958
Validation loss: 2.080619704338812

Epoch: 5| Step: 7
Training loss: 1.513655424118042
Validation loss: 2.0880206631075953

Epoch: 5| Step: 8
Training loss: 1.0487830638885498
Validation loss: 2.1094052060957877

Epoch: 5| Step: 9
Training loss: 1.5273154973983765
Validation loss: 2.100389794636798

Epoch: 5| Step: 10
Training loss: 1.3031890392303467
Validation loss: 2.0543865619167203

Epoch: 173| Step: 0
Training loss: 1.590024709701538
Validation loss: 2.08894395443701

Epoch: 5| Step: 1
Training loss: 1.4068080186843872
Validation loss: 2.1104075498478387

Epoch: 5| Step: 2
Training loss: 1.0828052759170532
Validation loss: 2.125425192617601

Epoch: 5| Step: 3
Training loss: 1.3253815174102783
Validation loss: 2.1252754144771124

Epoch: 5| Step: 4
Training loss: 1.0631917715072632
Validation loss: 2.0691012182543354

Epoch: 5| Step: 5
Training loss: 0.8370000123977661
Validation loss: 2.0431290890580867

Epoch: 5| Step: 6
Training loss: 1.6409269571304321
Validation loss: 2.0279169210823635

Epoch: 5| Step: 7
Training loss: 1.3558671474456787
Validation loss: 2.0368378982749036

Epoch: 5| Step: 8
Training loss: 0.9349663853645325
Validation loss: 2.0309096203055432

Epoch: 5| Step: 9
Training loss: 1.3870303630828857
Validation loss: 2.0324134749750935

Epoch: 5| Step: 10
Training loss: 1.6458297967910767
Validation loss: 2.0223633845647178

Epoch: 174| Step: 0
Training loss: 1.1931926012039185
Validation loss: 2.0078821489887853

Epoch: 5| Step: 1
Training loss: 1.1065160036087036
Validation loss: 1.9956841802084317

Epoch: 5| Step: 2
Training loss: 1.2250038385391235
Validation loss: 1.999899297632197

Epoch: 5| Step: 3
Training loss: 1.114137887954712
Validation loss: 2.0494682583757626

Epoch: 5| Step: 4
Training loss: 2.1143412590026855
Validation loss: 2.0636821228970765

Epoch: 5| Step: 5
Training loss: 1.0006049871444702
Validation loss: 2.0821133134185628

Epoch: 5| Step: 6
Training loss: 1.6928373575210571
Validation loss: 2.0831922510618806

Epoch: 5| Step: 7
Training loss: 1.1684343814849854
Validation loss: 2.0827984143328924

Epoch: 5| Step: 8
Training loss: 1.1811444759368896
Validation loss: 2.078387055345761

Epoch: 5| Step: 9
Training loss: 0.9682132601737976
Validation loss: 2.04473401013241

Epoch: 5| Step: 10
Training loss: 1.1782439947128296
Validation loss: 2.029065333386903

Epoch: 175| Step: 0
Training loss: 1.5473030805587769
Validation loss: 2.0234674792135916

Epoch: 5| Step: 1
Training loss: 1.3973257541656494
Validation loss: 2.0270333854101037

Epoch: 5| Step: 2
Training loss: 1.2932766675949097
Validation loss: 2.024786167247321

Epoch: 5| Step: 3
Training loss: 1.1357804536819458
Validation loss: 2.013746940961448

Epoch: 5| Step: 4
Training loss: 0.9901859164237976
Validation loss: 2.034454180348304

Epoch: 5| Step: 5
Training loss: 1.1029112339019775
Validation loss: 2.081753683346574

Epoch: 5| Step: 6
Training loss: 2.0300135612487793
Validation loss: 2.0903324081051733

Epoch: 5| Step: 7
Training loss: 1.0692417621612549
Validation loss: 2.1566465298334756

Epoch: 5| Step: 8
Training loss: 1.0636323690414429
Validation loss: 2.170697810829327

Epoch: 5| Step: 9
Training loss: 1.5046131610870361
Validation loss: 2.1561874728049

Epoch: 5| Step: 10
Training loss: 1.3692044019699097
Validation loss: 2.0897768748703824

Epoch: 176| Step: 0
Training loss: 1.5937587022781372
Validation loss: 2.052307391679415

Epoch: 5| Step: 1
Training loss: 1.1491609811782837
Validation loss: 2.0133029568579888

Epoch: 5| Step: 2
Training loss: 1.2802530527114868
Validation loss: 1.9859933801876601

Epoch: 5| Step: 3
Training loss: 1.5693031549453735
Validation loss: 1.9911379429601854

Epoch: 5| Step: 4
Training loss: 1.2387073040008545
Validation loss: 1.9721298115227812

Epoch: 5| Step: 5
Training loss: 1.7013355493545532
Validation loss: 1.9497063288124659

Epoch: 5| Step: 6
Training loss: 1.2398405075073242
Validation loss: 1.9528934724869267

Epoch: 5| Step: 7
Training loss: 0.9998366236686707
Validation loss: 1.9708873687251922

Epoch: 5| Step: 8
Training loss: 0.6714175939559937
Validation loss: 1.9704371549749886

Epoch: 5| Step: 9
Training loss: 1.503753423690796
Validation loss: 2.004148324330648

Epoch: 5| Step: 10
Training loss: 0.7613435387611389
Validation loss: 2.0332338271602506

Epoch: 177| Step: 0
Training loss: 1.2464778423309326
Validation loss: 2.068579218720877

Epoch: 5| Step: 1
Training loss: 1.2807533740997314
Validation loss: 2.0965781519489903

Epoch: 5| Step: 2
Training loss: 0.8550037145614624
Validation loss: 2.0991262184676303

Epoch: 5| Step: 3
Training loss: 1.3714948892593384
Validation loss: 2.068338624892696

Epoch: 5| Step: 4
Training loss: 1.2544089555740356
Validation loss: 2.0439521779296217

Epoch: 5| Step: 5
Training loss: 1.4854402542114258
Validation loss: 1.970646454441932

Epoch: 5| Step: 6
Training loss: 1.0929391384124756
Validation loss: 1.934332016975649

Epoch: 5| Step: 7
Training loss: 1.146789312362671
Validation loss: 1.9320060745362313

Epoch: 5| Step: 8
Training loss: 1.335965633392334
Validation loss: 1.9348594014362623

Epoch: 5| Step: 9
Training loss: 1.5159209966659546
Validation loss: 1.9604746398105417

Epoch: 5| Step: 10
Training loss: 1.1185961961746216
Validation loss: 1.9841680193460116

Epoch: 178| Step: 0
Training loss: 1.8758563995361328
Validation loss: 2.004521007178932

Epoch: 5| Step: 1
Training loss: 0.7704077959060669
Validation loss: 2.007633375865157

Epoch: 5| Step: 2
Training loss: 0.8537448644638062
Validation loss: 2.0338343830518824

Epoch: 5| Step: 3
Training loss: 1.0775675773620605
Validation loss: 2.0661536326972385

Epoch: 5| Step: 4
Training loss: 1.0279020071029663
Validation loss: 2.0740331501089115

Epoch: 5| Step: 5
Training loss: 0.9043431282043457
Validation loss: 2.0615567571373394

Epoch: 5| Step: 6
Training loss: 1.0867570638656616
Validation loss: 2.0350479259285876

Epoch: 5| Step: 7
Training loss: 1.4894551038742065
Validation loss: 2.0078761833970264

Epoch: 5| Step: 8
Training loss: 1.0421408414840698
Validation loss: 1.992375866059334

Epoch: 5| Step: 9
Training loss: 1.4341456890106201
Validation loss: 1.9856434688773206

Epoch: 5| Step: 10
Training loss: 1.4078261852264404
Validation loss: 1.9871398466889576

Epoch: 179| Step: 0
Training loss: 1.093629240989685
Validation loss: 1.9526142381852674

Epoch: 5| Step: 1
Training loss: 1.0692026615142822
Validation loss: 1.9831538520833498

Epoch: 5| Step: 2
Training loss: 1.2114231586456299
Validation loss: 2.0125479544362714

Epoch: 5| Step: 3
Training loss: 0.7257572412490845
Validation loss: 2.0523144737366708

Epoch: 5| Step: 4
Training loss: 0.9322360754013062
Validation loss: 2.058660578984086

Epoch: 5| Step: 5
Training loss: 1.2430078983306885
Validation loss: 2.082646372497723

Epoch: 5| Step: 6
Training loss: 1.1695988178253174
Validation loss: 2.0903148010212886

Epoch: 5| Step: 7
Training loss: 1.2097326517105103
Validation loss: 2.0595982613102084

Epoch: 5| Step: 8
Training loss: 1.3056353330612183
Validation loss: 2.0042754603970434

Epoch: 5| Step: 9
Training loss: 1.4868870973587036
Validation loss: 1.9989449798419912

Epoch: 5| Step: 10
Training loss: 1.5650948286056519
Validation loss: 1.9719196429816626

Epoch: 180| Step: 0
Training loss: 1.2206506729125977
Validation loss: 1.9670532288089875

Epoch: 5| Step: 1
Training loss: 1.3763408660888672
Validation loss: 1.9340470285825833

Epoch: 5| Step: 2
Training loss: 1.1301825046539307
Validation loss: 1.9414921076067033

Epoch: 5| Step: 3
Training loss: 1.122960090637207
Validation loss: 1.9377427562590568

Epoch: 5| Step: 4
Training loss: 1.1509398221969604
Validation loss: 1.9466870933450677

Epoch: 5| Step: 5
Training loss: 1.2437198162078857
Validation loss: 1.9652167520215433

Epoch: 5| Step: 6
Training loss: 0.9172412157058716
Validation loss: 2.0062758358575965

Epoch: 5| Step: 7
Training loss: 1.0805277824401855
Validation loss: 2.0459853859357935

Epoch: 5| Step: 8
Training loss: 0.8698469996452332
Validation loss: 2.0482775113915883

Epoch: 5| Step: 9
Training loss: 1.7896753549575806
Validation loss: 2.037062252721479

Epoch: 5| Step: 10
Training loss: 0.9756308197975159
Validation loss: 2.0404767015928864

Epoch: 181| Step: 0
Training loss: 1.2807567119598389
Validation loss: 2.0276306226689327

Epoch: 5| Step: 1
Training loss: 1.349508285522461
Validation loss: 1.9706487835094493

Epoch: 5| Step: 2
Training loss: 1.6945329904556274
Validation loss: 1.9644520667291456

Epoch: 5| Step: 3
Training loss: 1.135315179824829
Validation loss: 1.931843816593129

Epoch: 5| Step: 4
Training loss: 0.9859141111373901
Validation loss: 1.9115683750439716

Epoch: 5| Step: 5
Training loss: 1.107183814048767
Validation loss: 1.9314528152506838

Epoch: 5| Step: 6
Training loss: 0.7252171635627747
Validation loss: 1.9380088288296935

Epoch: 5| Step: 7
Training loss: 1.0890982151031494
Validation loss: 2.0019329555573

Epoch: 5| Step: 8
Training loss: 1.4117282629013062
Validation loss: 2.092732262867753

Epoch: 5| Step: 9
Training loss: 1.3121354579925537
Validation loss: 2.167154101915257

Epoch: 5| Step: 10
Training loss: 0.9296453595161438
Validation loss: 2.2241450202080513

Epoch: 182| Step: 0
Training loss: 1.7773315906524658
Validation loss: 2.2268683115641275

Epoch: 5| Step: 1
Training loss: 1.4037401676177979
Validation loss: 2.2309969548256166

Epoch: 5| Step: 2
Training loss: 1.536895990371704
Validation loss: 2.2032710429160827

Epoch: 5| Step: 3
Training loss: 1.3154890537261963
Validation loss: 2.110105595281047

Epoch: 5| Step: 4
Training loss: 1.1169475317001343
Validation loss: 2.0213635967623804

Epoch: 5| Step: 5
Training loss: 1.17995285987854
Validation loss: 1.9563029786591888

Epoch: 5| Step: 6
Training loss: 0.7203961610794067
Validation loss: 1.9249673069164317

Epoch: 5| Step: 7
Training loss: 0.9684292674064636
Validation loss: 1.9409553748305126

Epoch: 5| Step: 8
Training loss: 0.9903022646903992
Validation loss: 1.9049800865111812

Epoch: 5| Step: 9
Training loss: 1.1998634338378906
Validation loss: 1.9153298895846131

Epoch: 5| Step: 10
Training loss: 0.9543197751045227
Validation loss: 1.9034043512036722

Epoch: 183| Step: 0
Training loss: 1.1186535358428955
Validation loss: 1.9370769787860174

Epoch: 5| Step: 1
Training loss: 1.0676681995391846
Validation loss: 1.976022216581529

Epoch: 5| Step: 2
Training loss: 1.2026582956314087
Validation loss: 2.0069410903479463

Epoch: 5| Step: 3
Training loss: 1.6530576944351196
Validation loss: 2.049641381027878

Epoch: 5| Step: 4
Training loss: 0.6378323435783386
Validation loss: 2.0443156714080484

Epoch: 5| Step: 5
Training loss: 1.0650099515914917
Validation loss: 2.109507747875747

Epoch: 5| Step: 6
Training loss: 1.0086992979049683
Validation loss: 2.0946965832864084

Epoch: 5| Step: 7
Training loss: 1.1517062187194824
Validation loss: 2.0967930029797297

Epoch: 5| Step: 8
Training loss: 1.0464956760406494
Validation loss: 2.045341089207639

Epoch: 5| Step: 9
Training loss: 1.4910383224487305
Validation loss: 1.9873060462295369

Epoch: 5| Step: 10
Training loss: 1.07241690158844
Validation loss: 1.9450529095947102

Epoch: 184| Step: 0
Training loss: 0.9107288122177124
Validation loss: 1.95117780470079

Epoch: 5| Step: 1
Training loss: 1.4150733947753906
Validation loss: 1.977236440104823

Epoch: 5| Step: 2
Training loss: 1.5038658380508423
Validation loss: 2.0269385768521215

Epoch: 5| Step: 3
Training loss: 1.0777240991592407
Validation loss: 2.0390762334228842

Epoch: 5| Step: 4
Training loss: 1.1015676259994507
Validation loss: 2.071553650722709

Epoch: 5| Step: 5
Training loss: 0.9643763303756714
Validation loss: 2.074391157396378

Epoch: 5| Step: 6
Training loss: 1.2086162567138672
Validation loss: 2.04600703331732

Epoch: 5| Step: 7
Training loss: 1.101477861404419
Validation loss: 2.0004839512609665

Epoch: 5| Step: 8
Training loss: 0.7369189858436584
Validation loss: 2.0034591356913247

Epoch: 5| Step: 9
Training loss: 1.4664669036865234
Validation loss: 2.007488153314078

Epoch: 5| Step: 10
Training loss: 1.0488379001617432
Validation loss: 2.020955865101148

Epoch: 185| Step: 0
Training loss: 0.8190305829048157
Validation loss: 2.008798078824115

Epoch: 5| Step: 1
Training loss: 1.5638014078140259
Validation loss: 2.0231550483293432

Epoch: 5| Step: 2
Training loss: 0.9135299921035767
Validation loss: 1.9814855308942898

Epoch: 5| Step: 3
Training loss: 0.5720313787460327
Validation loss: 1.9943690299987793

Epoch: 5| Step: 4
Training loss: 1.1732938289642334
Validation loss: 2.0043198626528502

Epoch: 5| Step: 5
Training loss: 1.2431585788726807
Validation loss: 2.044449302457994

Epoch: 5| Step: 6
Training loss: 1.3337510824203491
Validation loss: 2.063002350509808

Epoch: 5| Step: 7
Training loss: 1.21499502658844
Validation loss: 2.093584063232586

Epoch: 5| Step: 8
Training loss: 1.5607285499572754
Validation loss: 2.0913404008393646

Epoch: 5| Step: 9
Training loss: 0.760499119758606
Validation loss: 2.0381609137340257

Epoch: 5| Step: 10
Training loss: 0.8768755793571472
Validation loss: 2.0023825565973916

Epoch: 186| Step: 0
Training loss: 1.1366474628448486
Validation loss: 1.9431545337041218

Epoch: 5| Step: 1
Training loss: 0.7389405965805054
Validation loss: 1.8916276283161615

Epoch: 5| Step: 2
Training loss: 1.1071757078170776
Validation loss: 1.9042583127175607

Epoch: 5| Step: 3
Training loss: 1.4451278448104858
Validation loss: 1.8885334973694177

Epoch: 5| Step: 4
Training loss: 1.0681005716323853
Validation loss: 1.909780607428602

Epoch: 5| Step: 5
Training loss: 1.469590187072754
Validation loss: 1.9084124103669198

Epoch: 5| Step: 6
Training loss: 0.7756592035293579
Validation loss: 1.9339200706892117

Epoch: 5| Step: 7
Training loss: 0.948938250541687
Validation loss: 1.9410792012368479

Epoch: 5| Step: 8
Training loss: 1.2350232601165771
Validation loss: 1.9486516867914507

Epoch: 5| Step: 9
Training loss: 0.7213581800460815
Validation loss: 1.957157737465315

Epoch: 5| Step: 10
Training loss: 1.0814138650894165
Validation loss: 1.9657266306620773

Epoch: 187| Step: 0
Training loss: 1.5095279216766357
Validation loss: 1.9624447181660643

Epoch: 5| Step: 1
Training loss: 1.3635828495025635
Validation loss: 2.003275191912087

Epoch: 5| Step: 2
Training loss: 0.9038721323013306
Validation loss: 2.003045194892473

Epoch: 5| Step: 3
Training loss: 0.9179736375808716
Validation loss: 2.0260179914453977

Epoch: 5| Step: 4
Training loss: 0.8712465167045593
Validation loss: 2.071136878382775

Epoch: 5| Step: 5
Training loss: 1.2528531551361084
Validation loss: 2.039485254595357

Epoch: 5| Step: 6
Training loss: 1.3687365055084229
Validation loss: 2.0403577307219147

Epoch: 5| Step: 7
Training loss: 0.9928061366081238
Validation loss: 2.0013150745822537

Epoch: 5| Step: 8
Training loss: 0.8443968892097473
Validation loss: 1.9857556050823582

Epoch: 5| Step: 9
Training loss: 0.7881504893302917
Validation loss: 1.969063143576345

Epoch: 5| Step: 10
Training loss: 0.9889293909072876
Validation loss: 1.993822205451227

Epoch: 188| Step: 0
Training loss: 0.9550722241401672
Validation loss: 1.9680543740590413

Epoch: 5| Step: 1
Training loss: 0.8298273086547852
Validation loss: 1.9320309444140362

Epoch: 5| Step: 2
Training loss: 0.8995628356933594
Validation loss: 1.9092623059467604

Epoch: 5| Step: 3
Training loss: 1.0271389484405518
Validation loss: 1.9016545831516225

Epoch: 5| Step: 4
Training loss: 0.9336622953414917
Validation loss: 1.9124180937326083

Epoch: 5| Step: 5
Training loss: 1.084002137184143
Validation loss: 1.9261023165077291

Epoch: 5| Step: 6
Training loss: 0.6956793069839478
Validation loss: 1.9675148456327376

Epoch: 5| Step: 7
Training loss: 1.7342939376831055
Validation loss: 1.9601437955774286

Epoch: 5| Step: 8
Training loss: 0.6267508864402771
Validation loss: 1.9702531394138132

Epoch: 5| Step: 9
Training loss: 1.1507333517074585
Validation loss: 1.938702921713552

Epoch: 5| Step: 10
Training loss: 1.4871110916137695
Validation loss: 1.946184048088648

Epoch: 189| Step: 0
Training loss: 1.2750836610794067
Validation loss: 1.9512353276693692

Epoch: 5| Step: 1
Training loss: 1.169685959815979
Validation loss: 1.9280508948910622

Epoch: 5| Step: 2
Training loss: 0.7163968682289124
Validation loss: 1.9082368445652786

Epoch: 5| Step: 3
Training loss: 0.9529800415039062
Validation loss: 1.9104794302294332

Epoch: 5| Step: 4
Training loss: 0.540228545665741
Validation loss: 1.8943608294251144

Epoch: 5| Step: 5
Training loss: 1.1220797300338745
Validation loss: 1.8892979698796426

Epoch: 5| Step: 6
Training loss: 1.2124661207199097
Validation loss: 1.9168738818937732

Epoch: 5| Step: 7
Training loss: 0.8326711654663086
Validation loss: 1.9283018817183792

Epoch: 5| Step: 8
Training loss: 0.9666953086853027
Validation loss: 1.9820103440233456

Epoch: 5| Step: 9
Training loss: 0.9622648358345032
Validation loss: 1.9837895721517584

Epoch: 5| Step: 10
Training loss: 1.1704195737838745
Validation loss: 2.006251440253309

Epoch: 190| Step: 0
Training loss: 0.8691899180412292
Validation loss: 1.9896451811636648

Epoch: 5| Step: 1
Training loss: 1.1165869235992432
Validation loss: 2.0172234888999694

Epoch: 5| Step: 2
Training loss: 1.3029135465621948
Validation loss: 1.990295305046984

Epoch: 5| Step: 3
Training loss: 0.9228610992431641
Validation loss: 1.9648205464886082

Epoch: 5| Step: 4
Training loss: 1.0142141580581665
Validation loss: 1.9571578259109168

Epoch: 5| Step: 5
Training loss: 0.9846475720405579
Validation loss: 1.9055163321956512

Epoch: 5| Step: 6
Training loss: 0.7605911493301392
Validation loss: 1.8979461334084953

Epoch: 5| Step: 7
Training loss: 1.4208606481552124
Validation loss: 1.9036797925990114

Epoch: 5| Step: 8
Training loss: 0.8701555132865906
Validation loss: 1.9415441264388382

Epoch: 5| Step: 9
Training loss: 1.008160948753357
Validation loss: 1.956385507378527

Epoch: 5| Step: 10
Training loss: 0.6121325492858887
Validation loss: 1.970541218275665

Epoch: 191| Step: 0
Training loss: 1.4450589418411255
Validation loss: 1.9298604149972238

Epoch: 5| Step: 1
Training loss: 0.9836403727531433
Validation loss: 1.9725759016570223

Epoch: 5| Step: 2
Training loss: 0.7319082021713257
Validation loss: 1.9347846700299172

Epoch: 5| Step: 3
Training loss: 0.5618866682052612
Validation loss: 1.9556760973827814

Epoch: 5| Step: 4
Training loss: 0.8146970868110657
Validation loss: 1.9601146277560983

Epoch: 5| Step: 5
Training loss: 1.0393917560577393
Validation loss: 1.9602964667863743

Epoch: 5| Step: 6
Training loss: 0.7844380140304565
Validation loss: 1.9168471700401717

Epoch: 5| Step: 7
Training loss: 1.257493257522583
Validation loss: 1.884221291029325

Epoch: 5| Step: 8
Training loss: 1.158278226852417
Validation loss: 1.847701839221421

Epoch: 5| Step: 9
Training loss: 1.433836579322815
Validation loss: 1.8388942031450168

Epoch: 5| Step: 10
Training loss: 0.48194095492362976
Validation loss: 1.8231818368357997

Epoch: 192| Step: 0
Training loss: 0.688075065612793
Validation loss: 1.8164930369264336

Epoch: 5| Step: 1
Training loss: 1.017397403717041
Validation loss: 1.8670095935944588

Epoch: 5| Step: 2
Training loss: 0.8415278196334839
Validation loss: 1.8955443213062901

Epoch: 5| Step: 3
Training loss: 1.2092162370681763
Validation loss: 1.9286152188495924

Epoch: 5| Step: 4
Training loss: 0.8611534237861633
Validation loss: 1.940080981100759

Epoch: 5| Step: 5
Training loss: 1.4842510223388672
Validation loss: 1.9299879535551994

Epoch: 5| Step: 6
Training loss: 0.7007874846458435
Validation loss: 1.912445906669863

Epoch: 5| Step: 7
Training loss: 0.6881051063537598
Validation loss: 1.9385570428704704

Epoch: 5| Step: 8
Training loss: 0.9638740420341492
Validation loss: 1.950317362303375

Epoch: 5| Step: 9
Training loss: 0.9295161962509155
Validation loss: 1.9837625757340462

Epoch: 5| Step: 10
Training loss: 1.8304924964904785
Validation loss: 1.992196306105583

Epoch: 193| Step: 0
Training loss: 0.7972649335861206
Validation loss: 1.9991543677545363

Epoch: 5| Step: 1
Training loss: 0.9267635345458984
Validation loss: 1.9827123495840258

Epoch: 5| Step: 2
Training loss: 1.4389498233795166
Validation loss: 1.9769940927464476

Epoch: 5| Step: 3
Training loss: 1.129339575767517
Validation loss: 1.956507222626799

Epoch: 5| Step: 4
Training loss: 0.5994489192962646
Validation loss: 1.9256086118759648

Epoch: 5| Step: 5
Training loss: 1.1490097045898438
Validation loss: 1.8852606050429805

Epoch: 5| Step: 6
Training loss: 0.6778838634490967
Validation loss: 1.888227460204914

Epoch: 5| Step: 7
Training loss: 0.8177016973495483
Validation loss: 1.8952239277542278

Epoch: 5| Step: 8
Training loss: 0.9465255737304688
Validation loss: 1.9253745040585917

Epoch: 5| Step: 9
Training loss: 0.9140512347221375
Validation loss: 1.9629047839872298

Epoch: 5| Step: 10
Training loss: 1.1606804132461548
Validation loss: 1.9849009488218574

Epoch: 194| Step: 0
Training loss: 0.691226601600647
Validation loss: 1.9823123819084578

Epoch: 5| Step: 1
Training loss: 0.631543755531311
Validation loss: 1.9764396567498483

Epoch: 5| Step: 2
Training loss: 0.8862775564193726
Validation loss: 1.9350642388866794

Epoch: 5| Step: 3
Training loss: 1.2589255571365356
Validation loss: 1.9243718808697117

Epoch: 5| Step: 4
Training loss: 1.327636957168579
Validation loss: 1.8994651904670141

Epoch: 5| Step: 5
Training loss: 0.8595746755599976
Validation loss: 1.8618557914610832

Epoch: 5| Step: 6
Training loss: 0.7632948160171509
Validation loss: 1.8759797670507943

Epoch: 5| Step: 7
Training loss: 1.1300230026245117
Validation loss: 1.8282281980719617

Epoch: 5| Step: 8
Training loss: 0.9564996957778931
Validation loss: 1.8327136161506816

Epoch: 5| Step: 9
Training loss: 1.0426024198532104
Validation loss: 1.8450126622312812

Epoch: 5| Step: 10
Training loss: 0.816530704498291
Validation loss: 1.8563129940340597

Epoch: 195| Step: 0
Training loss: 1.1159934997558594
Validation loss: 1.9012225725317513

Epoch: 5| Step: 1
Training loss: 1.1490336656570435
Validation loss: 1.9093512104403587

Epoch: 5| Step: 2
Training loss: 0.3670521378517151
Validation loss: 1.9118705564929592

Epoch: 5| Step: 3
Training loss: 1.3376165628433228
Validation loss: 1.9472392976924937

Epoch: 5| Step: 4
Training loss: 1.0730434656143188
Validation loss: 1.960264116205195

Epoch: 5| Step: 5
Training loss: 0.9330746531486511
Validation loss: 1.9944931832692956

Epoch: 5| Step: 6
Training loss: 1.1278789043426514
Validation loss: 1.9794853630886282

Epoch: 5| Step: 7
Training loss: 0.7212495803833008
Validation loss: 1.9450120900266914

Epoch: 5| Step: 8
Training loss: 1.0978747606277466
Validation loss: 1.921771623755014

Epoch: 5| Step: 9
Training loss: 0.7093251347541809
Validation loss: 1.9050131984936294

Epoch: 5| Step: 10
Training loss: 0.7427263855934143
Validation loss: 1.9029757476622058

Epoch: 196| Step: 0
Training loss: 1.331648588180542
Validation loss: 1.9224842620152298

Epoch: 5| Step: 1
Training loss: 0.7172209024429321
Validation loss: 1.8961680396910636

Epoch: 5| Step: 2
Training loss: 0.981108546257019
Validation loss: 1.8907184921285158

Epoch: 5| Step: 3
Training loss: 0.7361932992935181
Validation loss: 1.8611210994823004

Epoch: 5| Step: 4
Training loss: 0.8577154278755188
Validation loss: 1.8549872713704263

Epoch: 5| Step: 5
Training loss: 0.8220177888870239
Validation loss: 1.8732269451182375

Epoch: 5| Step: 6
Training loss: 0.9263777732849121
Validation loss: 1.8827071497517247

Epoch: 5| Step: 7
Training loss: 0.879717230796814
Validation loss: 1.903313366315698

Epoch: 5| Step: 8
Training loss: 0.7803251147270203
Validation loss: 1.9590951960573915

Epoch: 5| Step: 9
Training loss: 1.0139014720916748
Validation loss: 1.9634427191108785

Epoch: 5| Step: 10
Training loss: 0.9408092498779297
Validation loss: 1.946283241753937

Epoch: 197| Step: 0
Training loss: 0.5752571225166321
Validation loss: 1.9077591408965409

Epoch: 5| Step: 1
Training loss: 0.6982859373092651
Validation loss: 1.8632541241184357

Epoch: 5| Step: 2
Training loss: 1.2893197536468506
Validation loss: 1.824761858550451

Epoch: 5| Step: 3
Training loss: 0.8730298280715942
Validation loss: 1.8797946642803889

Epoch: 5| Step: 4
Training loss: 0.9840654134750366
Validation loss: 1.8990307443885392

Epoch: 5| Step: 5
Training loss: 1.1185567378997803
Validation loss: 1.9315319279188752

Epoch: 5| Step: 6
Training loss: 0.850436806678772
Validation loss: 1.9544123244541947

Epoch: 5| Step: 7
Training loss: 0.8651465177536011
Validation loss: 1.9488227021309636

Epoch: 5| Step: 8
Training loss: 0.8713511228561401
Validation loss: 1.9606400728225708

Epoch: 5| Step: 9
Training loss: 0.9985278844833374
Validation loss: 1.9840861033367854

Epoch: 5| Step: 10
Training loss: 1.1750067472457886
Validation loss: 1.9460813101901804

Epoch: 198| Step: 0
Training loss: 1.0627950429916382
Validation loss: 1.9350869194153817

Epoch: 5| Step: 1
Training loss: 1.6897674798965454
Validation loss: 1.9274128995915896

Epoch: 5| Step: 2
Training loss: 0.6328979134559631
Validation loss: 1.8830703022659465

Epoch: 5| Step: 3
Training loss: 0.8824186325073242
Validation loss: 1.8798623392658849

Epoch: 5| Step: 4
Training loss: 0.9134551286697388
Validation loss: 1.8887028142970095

Epoch: 5| Step: 5
Training loss: 0.9844258427619934
Validation loss: 1.8883563613378873

Epoch: 5| Step: 6
Training loss: 0.8672399520874023
Validation loss: 1.902604918326101

Epoch: 5| Step: 7
Training loss: 0.7362308502197266
Validation loss: 1.9228751223574403

Epoch: 5| Step: 8
Training loss: 0.6388117671012878
Validation loss: 1.952304942633516

Epoch: 5| Step: 9
Training loss: 0.934633731842041
Validation loss: 1.9557736342953098

Epoch: 5| Step: 10
Training loss: 0.584412157535553
Validation loss: 1.9651833183021956

Epoch: 199| Step: 0
Training loss: 0.9276412129402161
Validation loss: 1.954890130668558

Epoch: 5| Step: 1
Training loss: 1.1565958261489868
Validation loss: 1.9263472121248963

Epoch: 5| Step: 2
Training loss: 0.7187992930412292
Validation loss: 1.8884258270263672

Epoch: 5| Step: 3
Training loss: 0.6521953344345093
Validation loss: 1.8666996596961893

Epoch: 5| Step: 4
Training loss: 1.0611350536346436
Validation loss: 1.871461638840296

Epoch: 5| Step: 5
Training loss: 0.6633318662643433
Validation loss: 1.8751262029012044

Epoch: 5| Step: 6
Training loss: 1.1547404527664185
Validation loss: 1.8839575449625652

Epoch: 5| Step: 7
Training loss: 0.922600269317627
Validation loss: 1.9293800297603811

Epoch: 5| Step: 8
Training loss: 0.8252103924751282
Validation loss: 1.9790559532821819

Epoch: 5| Step: 9
Training loss: 1.0621206760406494
Validation loss: 1.9850751353848366

Epoch: 5| Step: 10
Training loss: 0.45696836709976196
Validation loss: 1.9970483497906757

Epoch: 200| Step: 0
Training loss: 1.1668446063995361
Validation loss: 1.9649450958416026

Epoch: 5| Step: 1
Training loss: 1.3182191848754883
Validation loss: 1.9392747507300427

Epoch: 5| Step: 2
Training loss: 0.6768763661384583
Validation loss: 1.8942172450404013

Epoch: 5| Step: 3
Training loss: 0.6774164438247681
Validation loss: 1.8834626443924443

Epoch: 5| Step: 4
Training loss: 0.9447968602180481
Validation loss: 1.8594119343706357

Epoch: 5| Step: 5
Training loss: 0.9374951124191284
Validation loss: 1.848785146590202

Epoch: 5| Step: 6
Training loss: 0.5605791807174683
Validation loss: 1.8483102834352882

Epoch: 5| Step: 7
Training loss: 1.0867869853973389
Validation loss: 1.8623247479879728

Epoch: 5| Step: 8
Training loss: 0.9184234738349915
Validation loss: 1.9118671007053827

Epoch: 5| Step: 9
Training loss: 0.39202946424484253
Validation loss: 1.9660272059902069

Epoch: 5| Step: 10
Training loss: 1.077825903892517
Validation loss: 2.004426953613117

Epoch: 201| Step: 0
Training loss: 0.8601347208023071
Validation loss: 2.0015715014549995

Epoch: 5| Step: 1
Training loss: 1.3351662158966064
Validation loss: 1.998042130983004

Epoch: 5| Step: 2
Training loss: 1.0746004581451416
Validation loss: 1.952807625134786

Epoch: 5| Step: 3
Training loss: 0.9062095880508423
Validation loss: 1.9279283810687322

Epoch: 5| Step: 4
Training loss: 0.7065192461013794
Validation loss: 1.8915923936392671

Epoch: 5| Step: 5
Training loss: 0.6912055611610413
Validation loss: 1.8157787002542967

Epoch: 5| Step: 6
Training loss: 1.0406666994094849
Validation loss: 1.767079766078662

Epoch: 5| Step: 7
Training loss: 0.8864297866821289
Validation loss: 1.758741859466799

Epoch: 5| Step: 8
Training loss: 0.838473916053772
Validation loss: 1.8032006858497538

Epoch: 5| Step: 9
Training loss: 0.8507181406021118
Validation loss: 1.8201029300689697

Epoch: 5| Step: 10
Training loss: 0.8497058749198914
Validation loss: 1.8389564842306159

Epoch: 202| Step: 0
Training loss: 1.0194098949432373
Validation loss: 1.8802635310798563

Epoch: 5| Step: 1
Training loss: 0.5654225945472717
Validation loss: 1.9345357007877801

Epoch: 5| Step: 2
Training loss: 1.3022762537002563
Validation loss: 1.9837811095740205

Epoch: 5| Step: 3
Training loss: 1.0924959182739258
Validation loss: 1.9809328522733463

Epoch: 5| Step: 4
Training loss: 0.6997581124305725
Validation loss: 1.9399354534764444

Epoch: 5| Step: 5
Training loss: 0.8305201530456543
Validation loss: 1.872027353573871

Epoch: 5| Step: 6
Training loss: 0.764264702796936
Validation loss: 1.8496961888446604

Epoch: 5| Step: 7
Training loss: 1.1040455102920532
Validation loss: 1.853406370327037

Epoch: 5| Step: 8
Training loss: 0.7891572713851929
Validation loss: 1.8403101557044572

Epoch: 5| Step: 9
Training loss: 1.0431921482086182
Validation loss: 1.8232528471177625

Epoch: 5| Step: 10
Training loss: 0.8207270503044128
Validation loss: 1.800543555649378

Epoch: 203| Step: 0
Training loss: 1.2262908220291138
Validation loss: 1.8377676971497074

Epoch: 5| Step: 1
Training loss: 0.863205075263977
Validation loss: 1.8721325230854813

Epoch: 5| Step: 2
Training loss: 0.6843914985656738
Validation loss: 1.8857583166450582

Epoch: 5| Step: 3
Training loss: 0.8702723383903503
Validation loss: 1.911921372977636

Epoch: 5| Step: 4
Training loss: 0.8507366180419922
Validation loss: 1.9196687411236506

Epoch: 5| Step: 5
Training loss: 0.8400676846504211
Validation loss: 1.9636624641315912

Epoch: 5| Step: 6
Training loss: 0.6866661310195923
Validation loss: 1.968315011711531

Epoch: 5| Step: 7
Training loss: 0.6981437802314758
Validation loss: 1.9998277694948259

Epoch: 5| Step: 8
Training loss: 1.1961002349853516
Validation loss: 1.9845085964407971

Epoch: 5| Step: 9
Training loss: 0.8637111783027649
Validation loss: 1.9803167620012838

Epoch: 5| Step: 10
Training loss: 0.9092820286750793
Validation loss: 1.9248315954721102

Epoch: 204| Step: 0
Training loss: 0.7631788849830627
Validation loss: 1.8738037245247954

Epoch: 5| Step: 1
Training loss: 0.7791301012039185
Validation loss: 1.8604333144362255

Epoch: 5| Step: 2
Training loss: 0.9180747270584106
Validation loss: 1.8465745743884836

Epoch: 5| Step: 3
Training loss: 1.0326718091964722
Validation loss: 1.8098346328222623

Epoch: 5| Step: 4
Training loss: 0.6611558198928833
Validation loss: 1.819403640685543

Epoch: 5| Step: 5
Training loss: 0.43734097480773926
Validation loss: 1.7983184847780453

Epoch: 5| Step: 6
Training loss: 1.06394362449646
Validation loss: 1.8405746503542828

Epoch: 5| Step: 7
Training loss: 1.363486886024475
Validation loss: 1.8646250617119573

Epoch: 5| Step: 8
Training loss: 1.1199769973754883
Validation loss: 1.8909136543991745

Epoch: 5| Step: 9
Training loss: 0.7384829521179199
Validation loss: 1.838702255679715

Epoch: 5| Step: 10
Training loss: 0.6109545230865479
Validation loss: 1.8184353254174674

Epoch: 205| Step: 0
Training loss: 0.9373372793197632
Validation loss: 1.8341562158317977

Epoch: 5| Step: 1
Training loss: 0.815255343914032
Validation loss: 1.851185796081379

Epoch: 5| Step: 2
Training loss: 0.5891744494438171
Validation loss: 1.850881540647117

Epoch: 5| Step: 3
Training loss: 0.6269196271896362
Validation loss: 1.8748269247752365

Epoch: 5| Step: 4
Training loss: 1.0119917392730713
Validation loss: 1.8715877507322578

Epoch: 5| Step: 5
Training loss: 0.6952086687088013
Validation loss: 1.911608680602043

Epoch: 5| Step: 6
Training loss: 0.8388897180557251
Validation loss: 1.9301785448546052

Epoch: 5| Step: 7
Training loss: 1.360526442527771
Validation loss: 1.9528592555753645

Epoch: 5| Step: 8
Training loss: 0.9194859266281128
Validation loss: 1.9508597555980887

Epoch: 5| Step: 9
Training loss: 0.5312047600746155
Validation loss: 1.943486980212632

Epoch: 5| Step: 10
Training loss: 1.1319137811660767
Validation loss: 1.9174682465932702

Epoch: 206| Step: 0
Training loss: 0.9368284344673157
Validation loss: 1.8590981037386003

Epoch: 5| Step: 1
Training loss: 1.0393764972686768
Validation loss: 1.8257787509631085

Epoch: 5| Step: 2
Training loss: 0.8826524019241333
Validation loss: 1.8357407072538972

Epoch: 5| Step: 3
Training loss: 0.7133587002754211
Validation loss: 1.8101988787292151

Epoch: 5| Step: 4
Training loss: 0.7391495704650879
Validation loss: 1.8267913544049827

Epoch: 5| Step: 5
Training loss: 0.8574491739273071
Validation loss: 1.8245350532634284

Epoch: 5| Step: 6
Training loss: 0.5448326468467712
Validation loss: 1.8322874089722991

Epoch: 5| Step: 7
Training loss: 0.4949076175689697
Validation loss: 1.8292493179280271

Epoch: 5| Step: 8
Training loss: 1.1741008758544922
Validation loss: 1.8679532825305898

Epoch: 5| Step: 9
Training loss: 0.6909937858581543
Validation loss: 1.8978165811108005

Epoch: 5| Step: 10
Training loss: 0.9844731688499451
Validation loss: 1.900692347557314

Epoch: 207| Step: 0
Training loss: 0.792662501335144
Validation loss: 1.9455717661047494

Epoch: 5| Step: 1
Training loss: 0.8100152015686035
Validation loss: 1.9231904501556067

Epoch: 5| Step: 2
Training loss: 1.2279728651046753
Validation loss: 1.8829036733155609

Epoch: 5| Step: 3
Training loss: 0.6565070152282715
Validation loss: 1.8875879933757167

Epoch: 5| Step: 4
Training loss: 0.8955762982368469
Validation loss: 1.8941086466594408

Epoch: 5| Step: 5
Training loss: 0.4935934543609619
Validation loss: 1.9055669640982023

Epoch: 5| Step: 6
Training loss: 0.4436782896518707
Validation loss: 1.8993043053534724

Epoch: 5| Step: 7
Training loss: 0.9617029428482056
Validation loss: 1.9139741338709348

Epoch: 5| Step: 8
Training loss: 0.9680693745613098
Validation loss: 1.896578388829385

Epoch: 5| Step: 9
Training loss: 0.7847084999084473
Validation loss: 1.8885210534577728

Epoch: 5| Step: 10
Training loss: 1.030613660812378
Validation loss: 1.8479364930942495

Epoch: 208| Step: 0
Training loss: 0.681221604347229
Validation loss: 1.8240529721783054

Epoch: 5| Step: 1
Training loss: 1.0131901502609253
Validation loss: 1.8598803807330389

Epoch: 5| Step: 2
Training loss: 0.5590012669563293
Validation loss: 1.8195297346320203

Epoch: 5| Step: 3
Training loss: 0.6864498853683472
Validation loss: 1.8647907357062063

Epoch: 5| Step: 4
Training loss: 1.0793211460113525
Validation loss: 1.9051971704729143

Epoch: 5| Step: 5
Training loss: 1.1638895273208618
Validation loss: 1.947099079367935

Epoch: 5| Step: 6
Training loss: 0.765254557132721
Validation loss: 1.9414833591830345

Epoch: 5| Step: 7
Training loss: 1.009428858757019
Validation loss: 1.9299077090396677

Epoch: 5| Step: 8
Training loss: 0.7940215468406677
Validation loss: 1.8887483355819539

Epoch: 5| Step: 9
Training loss: 0.49277105927467346
Validation loss: 1.8867268805862756

Epoch: 5| Step: 10
Training loss: 0.794394314289093
Validation loss: 1.8806393531060988

Epoch: 209| Step: 0
Training loss: 0.8477581739425659
Validation loss: 1.8783076604207356

Epoch: 5| Step: 1
Training loss: 0.8101336359977722
Validation loss: 1.862139428815534

Epoch: 5| Step: 2
Training loss: 0.7012900114059448
Validation loss: 1.8528982247075727

Epoch: 5| Step: 3
Training loss: 0.7098992466926575
Validation loss: 1.8071794586796914

Epoch: 5| Step: 4
Training loss: 0.5743668079376221
Validation loss: 1.827349284643768

Epoch: 5| Step: 5
Training loss: 0.5782601237297058
Validation loss: 1.8221431534777406

Epoch: 5| Step: 6
Training loss: 0.9839159250259399
Validation loss: 1.8434721974916355

Epoch: 5| Step: 7
Training loss: 1.227455496788025
Validation loss: 1.8712902428001486

Epoch: 5| Step: 8
Training loss: 0.8033065795898438
Validation loss: 1.8652784696189306

Epoch: 5| Step: 9
Training loss: 0.8648905754089355
Validation loss: 1.8724959037637199

Epoch: 5| Step: 10
Training loss: 0.6567057371139526
Validation loss: 1.9085915921836771

Epoch: 210| Step: 0
Training loss: 0.4033186435699463
Validation loss: 1.8943999454539309

Epoch: 5| Step: 1
Training loss: 0.6520102620124817
Validation loss: 1.8798275673261253

Epoch: 5| Step: 2
Training loss: 0.7330441474914551
Validation loss: 1.855078463913292

Epoch: 5| Step: 3
Training loss: 0.8416008949279785
Validation loss: 1.8395223591917305

Epoch: 5| Step: 4
Training loss: 1.0492584705352783
Validation loss: 1.8190289851157897

Epoch: 5| Step: 5
Training loss: 1.0165735483169556
Validation loss: 1.8082230014185752

Epoch: 5| Step: 6
Training loss: 0.9599491357803345
Validation loss: 1.8413367579060216

Epoch: 5| Step: 7
Training loss: 0.6883366703987122
Validation loss: 1.8459759937819613

Epoch: 5| Step: 8
Training loss: 0.3910054564476013
Validation loss: 1.8738345292306715

Epoch: 5| Step: 9
Training loss: 1.1551192998886108
Validation loss: 1.9102417089605843

Epoch: 5| Step: 10
Training loss: 0.7513870000839233
Validation loss: 1.9217023439304803

Epoch: 211| Step: 0
Training loss: 0.7202435731887817
Validation loss: 1.8742231989419589

Epoch: 5| Step: 1
Training loss: 0.46035605669021606
Validation loss: 1.8870915546212146

Epoch: 5| Step: 2
Training loss: 0.7721307277679443
Validation loss: 1.8918904976178241

Epoch: 5| Step: 3
Training loss: 0.830497145652771
Validation loss: 1.859386662001251

Epoch: 5| Step: 4
Training loss: 0.5175707936286926
Validation loss: 1.8681676464696084

Epoch: 5| Step: 5
Training loss: 1.1192939281463623
Validation loss: 1.8452722513547508

Epoch: 5| Step: 6
Training loss: 0.6280247569084167
Validation loss: 1.8462048140905236

Epoch: 5| Step: 7
Training loss: 1.0771483182907104
Validation loss: 1.8520380630288074

Epoch: 5| Step: 8
Training loss: 0.8746078610420227
Validation loss: 1.8368064793207313

Epoch: 5| Step: 9
Training loss: 0.7251995801925659
Validation loss: 1.8380529483159382

Epoch: 5| Step: 10
Training loss: 0.8515625
Validation loss: 1.8094311170680548

Epoch: 212| Step: 0
Training loss: 0.49023526906967163
Validation loss: 1.80060911691317

Epoch: 5| Step: 1
Training loss: 1.0868536233901978
Validation loss: 1.8174798450162333

Epoch: 5| Step: 2
Training loss: 0.5505600571632385
Validation loss: 1.836139173917873

Epoch: 5| Step: 3
Training loss: 0.6006763577461243
Validation loss: 1.8424669465711039

Epoch: 5| Step: 4
Training loss: 0.8151056170463562
Validation loss: 1.8599695428725211

Epoch: 5| Step: 5
Training loss: 0.8787009119987488
Validation loss: 1.9020063454105007

Epoch: 5| Step: 6
Training loss: 0.7813516855239868
Validation loss: 1.9165295413745347

Epoch: 5| Step: 7
Training loss: 0.6257615089416504
Validation loss: 1.9260201043980096

Epoch: 5| Step: 8
Training loss: 0.8011213541030884
Validation loss: 1.8833093303506092

Epoch: 5| Step: 9
Training loss: 0.8245371580123901
Validation loss: 1.8358918684785084

Epoch: 5| Step: 10
Training loss: 0.8932085633277893
Validation loss: 1.7990925273587626

Epoch: 213| Step: 0
Training loss: 0.43510866165161133
Validation loss: 1.7914853801009476

Epoch: 5| Step: 1
Training loss: 0.7467804551124573
Validation loss: 1.8247697263635614

Epoch: 5| Step: 2
Training loss: 0.9195770025253296
Validation loss: 1.8421488077409807

Epoch: 5| Step: 3
Training loss: 1.0056674480438232
Validation loss: 1.902859148158822

Epoch: 5| Step: 4
Training loss: 0.5837501287460327
Validation loss: 1.8920094710524364

Epoch: 5| Step: 5
Training loss: 0.5363790392875671
Validation loss: 1.893726307858703

Epoch: 5| Step: 6
Training loss: 0.7424423098564148
Validation loss: 1.8721379951764179

Epoch: 5| Step: 7
Training loss: 0.7044683694839478
Validation loss: 1.8602154998369114

Epoch: 5| Step: 8
Training loss: 0.6897379159927368
Validation loss: 1.8715848461274178

Epoch: 5| Step: 9
Training loss: 0.8665706515312195
Validation loss: 1.8654159384389077

Epoch: 5| Step: 10
Training loss: 0.9151269197463989
Validation loss: 1.862001399840078

Epoch: 214| Step: 0
Training loss: 0.6511300802230835
Validation loss: 1.8254128297170003

Epoch: 5| Step: 1
Training loss: 0.6333228349685669
Validation loss: 1.8144769694215508

Epoch: 5| Step: 2
Training loss: 0.8034235239028931
Validation loss: 1.8005598155401086

Epoch: 5| Step: 3
Training loss: 0.9874992370605469
Validation loss: 1.8272032148094588

Epoch: 5| Step: 4
Training loss: 0.6101456880569458
Validation loss: 1.8220113054398568

Epoch: 5| Step: 5
Training loss: 0.4391447901725769
Validation loss: 1.8104283694298036

Epoch: 5| Step: 6
Training loss: 0.8645591735839844
Validation loss: 1.815613292878674

Epoch: 5| Step: 7
Training loss: 0.5194968581199646
Validation loss: 1.8348122316022073

Epoch: 5| Step: 8
Training loss: 0.6837732195854187
Validation loss: 1.8928505438630299

Epoch: 5| Step: 9
Training loss: 0.8040916323661804
Validation loss: 1.8926831881205242

Epoch: 5| Step: 10
Training loss: 1.0355864763259888
Validation loss: 1.9360356023234706

Epoch: 215| Step: 0
Training loss: 0.5869134664535522
Validation loss: 1.895040447993945

Epoch: 5| Step: 1
Training loss: 0.48160189390182495
Validation loss: 1.8545979812581053

Epoch: 5| Step: 2
Training loss: 0.9659644365310669
Validation loss: 1.8178550351050593

Epoch: 5| Step: 3
Training loss: 0.5766623020172119
Validation loss: 1.7909717341904998

Epoch: 5| Step: 4
Training loss: 0.576149582862854
Validation loss: 1.7872697422581334

Epoch: 5| Step: 5
Training loss: 0.5911325216293335
Validation loss: 1.7802317719305716

Epoch: 5| Step: 6
Training loss: 0.74277263879776
Validation loss: 1.793147374224919

Epoch: 5| Step: 7
Training loss: 0.9591771960258484
Validation loss: 1.803777684447586

Epoch: 5| Step: 8
Training loss: 0.8898292779922485
Validation loss: 1.8377250573968376

Epoch: 5| Step: 9
Training loss: 0.6787969470024109
Validation loss: 1.8900923780215684

Epoch: 5| Step: 10
Training loss: 0.875359058380127
Validation loss: 1.8944489020173267

Epoch: 216| Step: 0
Training loss: 0.9348897933959961
Validation loss: 1.8640701873328096

Epoch: 5| Step: 1
Training loss: 0.6329068541526794
Validation loss: 1.886722246805827

Epoch: 5| Step: 2
Training loss: 0.9015569686889648
Validation loss: 1.8618094177656277

Epoch: 5| Step: 3
Training loss: 0.605326235294342
Validation loss: 1.8446755588695567

Epoch: 5| Step: 4
Training loss: 1.0008323192596436
Validation loss: 1.7975009167066185

Epoch: 5| Step: 5
Training loss: 0.6136742830276489
Validation loss: 1.7740511355861541

Epoch: 5| Step: 6
Training loss: 0.5234960913658142
Validation loss: 1.7676420801429338

Epoch: 5| Step: 7
Training loss: 0.5955955982208252
Validation loss: 1.738369208510204

Epoch: 5| Step: 8
Training loss: 0.9669815897941589
Validation loss: 1.7596733211189188

Epoch: 5| Step: 9
Training loss: 0.6422382593154907
Validation loss: 1.7671234505150908

Epoch: 5| Step: 10
Training loss: 0.5827391147613525
Validation loss: 1.8006001467345862

Epoch: 217| Step: 0
Training loss: 0.566450834274292
Validation loss: 1.8368771870930989

Epoch: 5| Step: 1
Training loss: 0.9098491668701172
Validation loss: 1.8844187375037902

Epoch: 5| Step: 2
Training loss: 0.4196375012397766
Validation loss: 1.8980021886928107

Epoch: 5| Step: 3
Training loss: 0.7081786394119263
Validation loss: 1.9054094347902524

Epoch: 5| Step: 4
Training loss: 0.8794193267822266
Validation loss: 1.8803081025359452

Epoch: 5| Step: 5
Training loss: 0.8930191993713379
Validation loss: 1.8272971978751562

Epoch: 5| Step: 6
Training loss: 0.9842879176139832
Validation loss: 1.8368406013775898

Epoch: 5| Step: 7
Training loss: 0.7531126737594604
Validation loss: 1.7979856255233928

Epoch: 5| Step: 8
Training loss: 0.7577314376831055
Validation loss: 1.7583542331572501

Epoch: 5| Step: 9
Training loss: 0.41063809394836426
Validation loss: 1.742820087299552

Epoch: 5| Step: 10
Training loss: 0.8065188527107239
Validation loss: 1.741143093314222

Epoch: 218| Step: 0
Training loss: 0.7767035365104675
Validation loss: 1.7367504988947222

Epoch: 5| Step: 1
Training loss: 0.5704629421234131
Validation loss: 1.76920025579391

Epoch: 5| Step: 2
Training loss: 0.8055580854415894
Validation loss: 1.7852670941301572

Epoch: 5| Step: 3
Training loss: 0.7878049612045288
Validation loss: 1.8338819473020491

Epoch: 5| Step: 4
Training loss: 0.4856582581996918
Validation loss: 1.890861770158173

Epoch: 5| Step: 5
Training loss: 0.7721894979476929
Validation loss: 1.9281015729391446

Epoch: 5| Step: 6
Training loss: 1.0310790538787842
Validation loss: 1.9759818930779733

Epoch: 5| Step: 7
Training loss: 0.6641265153884888
Validation loss: 1.976632200261598

Epoch: 5| Step: 8
Training loss: 0.8074496984481812
Validation loss: 1.9115190787981915

Epoch: 5| Step: 9
Training loss: 0.5745383501052856
Validation loss: 1.861436128616333

Epoch: 5| Step: 10
Training loss: 0.8239584565162659
Validation loss: 1.7840495135194512

Epoch: 219| Step: 0
Training loss: 0.5941178798675537
Validation loss: 1.7697465445405693

Epoch: 5| Step: 1
Training loss: 0.9172695875167847
Validation loss: 1.7507751321279874

Epoch: 5| Step: 2
Training loss: 0.5972028970718384
Validation loss: 1.7479010749888677

Epoch: 5| Step: 3
Training loss: 0.7246795892715454
Validation loss: 1.76534620664453

Epoch: 5| Step: 4
Training loss: 1.0677870512008667
Validation loss: 1.8013152435261717

Epoch: 5| Step: 5
Training loss: 0.7450821399688721
Validation loss: 1.8385451109178605

Epoch: 5| Step: 6
Training loss: 0.3723357617855072
Validation loss: 1.843415852515928

Epoch: 5| Step: 7
Training loss: 0.5235666036605835
Validation loss: 1.8305652744026595

Epoch: 5| Step: 8
Training loss: 0.9717289805412292
Validation loss: 1.8456560450215493

Epoch: 5| Step: 9
Training loss: 0.7625781297683716
Validation loss: 1.839988072713216

Epoch: 5| Step: 10
Training loss: 0.7703246474266052
Validation loss: 1.847259452266078

Epoch: 220| Step: 0
Training loss: 0.6832887530326843
Validation loss: 1.779152108776954

Epoch: 5| Step: 1
Training loss: 0.7813608646392822
Validation loss: 1.772300511278132

Epoch: 5| Step: 2
Training loss: 0.5535141229629517
Validation loss: 1.7326493135062597

Epoch: 5| Step: 3
Training loss: 1.0299886465072632
Validation loss: 1.7508902601016465

Epoch: 5| Step: 4
Training loss: 0.7398395538330078
Validation loss: 1.7760323145056283

Epoch: 5| Step: 5
Training loss: 0.9664187431335449
Validation loss: 1.8123118364682762

Epoch: 5| Step: 6
Training loss: 0.5794188380241394
Validation loss: 1.819864046189093

Epoch: 5| Step: 7
Training loss: 0.8146201372146606
Validation loss: 1.8832883757929648

Epoch: 5| Step: 8
Training loss: 0.7110275030136108
Validation loss: 1.8990756401451685

Epoch: 5| Step: 9
Training loss: 0.48545607924461365
Validation loss: 1.9399198665413806

Epoch: 5| Step: 10
Training loss: 0.3874402344226837
Validation loss: 1.9095627210473503

Epoch: 221| Step: 0
Training loss: 0.9892367124557495
Validation loss: 1.8583394686381023

Epoch: 5| Step: 1
Training loss: 0.5286864042282104
Validation loss: 1.8012625863475185

Epoch: 5| Step: 2
Training loss: 0.7935671210289001
Validation loss: 1.7242986707277195

Epoch: 5| Step: 3
Training loss: 1.0649759769439697
Validation loss: 1.6886138864742812

Epoch: 5| Step: 4
Training loss: 0.5963088870048523
Validation loss: 1.6779899661258986

Epoch: 5| Step: 5
Training loss: 1.1084372997283936
Validation loss: 1.6835492913440993

Epoch: 5| Step: 6
Training loss: 0.7948845028877258
Validation loss: 1.693969944471954

Epoch: 5| Step: 7
Training loss: 0.7193940877914429
Validation loss: 1.7194799351435837

Epoch: 5| Step: 8
Training loss: 0.73392254114151
Validation loss: 1.7355519430611723

Epoch: 5| Step: 9
Training loss: 0.28344497084617615
Validation loss: 1.7498653845120502

Epoch: 5| Step: 10
Training loss: 0.39059165120124817
Validation loss: 1.7871319068375455

Epoch: 222| Step: 0
Training loss: 0.6995354294776917
Validation loss: 1.849993808295137

Epoch: 5| Step: 1
Training loss: 0.6740437746047974
Validation loss: 1.8898207064597838

Epoch: 5| Step: 2
Training loss: 0.6562012434005737
Validation loss: 1.9409004155025686

Epoch: 5| Step: 3
Training loss: 0.6015179753303528
Validation loss: 1.9172505588941677

Epoch: 5| Step: 4
Training loss: 0.9187628626823425
Validation loss: 1.9327986060932119

Epoch: 5| Step: 5
Training loss: 0.45072174072265625
Validation loss: 1.8864911756207865

Epoch: 5| Step: 6
Training loss: 0.6547133326530457
Validation loss: 1.8027422428131104

Epoch: 5| Step: 7
Training loss: 0.8549176454544067
Validation loss: 1.7654631881303684

Epoch: 5| Step: 8
Training loss: 0.46576929092407227
Validation loss: 1.7643796987431024

Epoch: 5| Step: 9
Training loss: 0.7997433543205261
Validation loss: 1.74070833575341

Epoch: 5| Step: 10
Training loss: 1.1521269083023071
Validation loss: 1.7248964668602071

Epoch: 223| Step: 0
Training loss: 1.082953929901123
Validation loss: 1.7901369551176667

Epoch: 5| Step: 1
Training loss: 0.5294345021247864
Validation loss: 1.8174151066810853

Epoch: 5| Step: 2
Training loss: 0.8424045443534851
Validation loss: 1.8497566356453845

Epoch: 5| Step: 3
Training loss: 0.7091977000236511
Validation loss: 1.8488458766732165

Epoch: 5| Step: 4
Training loss: 0.5793227553367615
Validation loss: 1.8476393786809777

Epoch: 5| Step: 5
Training loss: 0.5290050506591797
Validation loss: 1.865813647547076

Epoch: 5| Step: 6
Training loss: 0.8440530896186829
Validation loss: 1.89732345714364

Epoch: 5| Step: 7
Training loss: 0.5918918251991272
Validation loss: 1.9347278815443798

Epoch: 5| Step: 8
Training loss: 0.622389018535614
Validation loss: 1.9349631622273435

Epoch: 5| Step: 9
Training loss: 0.8533791303634644
Validation loss: 1.9240590603120866

Epoch: 5| Step: 10
Training loss: 0.9170212745666504
Validation loss: 1.9112428106287473

Epoch: 224| Step: 0
Training loss: 0.6000844240188599
Validation loss: 1.8628360174035514

Epoch: 5| Step: 1
Training loss: 0.47136861085891724
Validation loss: 1.7548128584379792

Epoch: 5| Step: 2
Training loss: 0.4295714497566223
Validation loss: 1.7387327301886775

Epoch: 5| Step: 3
Training loss: 0.5806742906570435
Validation loss: 1.7538813980676795

Epoch: 5| Step: 4
Training loss: 0.5627371072769165
Validation loss: 1.7680119237592142

Epoch: 5| Step: 5
Training loss: 0.7213883996009827
Validation loss: 1.7443329224022486

Epoch: 5| Step: 6
Training loss: 1.0202066898345947
Validation loss: 1.764308794852226

Epoch: 5| Step: 7
Training loss: 0.7311156392097473
Validation loss: 1.7728518901332733

Epoch: 5| Step: 8
Training loss: 0.5660497546195984
Validation loss: 1.7798528068809099

Epoch: 5| Step: 9
Training loss: 0.7163339853286743
Validation loss: 1.7751107497881817

Epoch: 5| Step: 10
Training loss: 0.8914423584938049
Validation loss: 1.7993458970900504

Epoch: 225| Step: 0
Training loss: 0.925366997718811
Validation loss: 1.8255190182757635

Epoch: 5| Step: 1
Training loss: 0.6418261528015137
Validation loss: 1.8640906439032605

Epoch: 5| Step: 2
Training loss: 0.39392217993736267
Validation loss: 1.8276012097635577

Epoch: 5| Step: 3
Training loss: 0.6540752053260803
Validation loss: 1.8292585188342678

Epoch: 5| Step: 4
Training loss: 0.6899311542510986
Validation loss: 1.8240090416323753

Epoch: 5| Step: 5
Training loss: 0.6295315027236938
Validation loss: 1.8108138897085702

Epoch: 5| Step: 6
Training loss: 0.6031637191772461
Validation loss: 1.8166889631620018

Epoch: 5| Step: 7
Training loss: 0.6920208930969238
Validation loss: 1.7775682185285835

Epoch: 5| Step: 8
Training loss: 0.7949738502502441
Validation loss: 1.8056841998971918

Epoch: 5| Step: 9
Training loss: 0.6179794073104858
Validation loss: 1.7762566176793908

Epoch: 5| Step: 10
Training loss: 0.38654541969299316
Validation loss: 1.778139119507164

Epoch: 226| Step: 0
Training loss: 0.7564445734024048
Validation loss: 1.7302252272123932

Epoch: 5| Step: 1
Training loss: 0.7485231161117554
Validation loss: 1.8024153735048027

Epoch: 5| Step: 2
Training loss: 0.2920193672180176
Validation loss: 1.8040791224407893

Epoch: 5| Step: 3
Training loss: 0.7290727496147156
Validation loss: 1.847112981222009

Epoch: 5| Step: 4
Training loss: 0.4473351538181305
Validation loss: 1.856510409744837

Epoch: 5| Step: 5
Training loss: 0.5363408923149109
Validation loss: 1.8472238432976507

Epoch: 5| Step: 6
Training loss: 0.8539482355117798
Validation loss: 1.8180491437194168

Epoch: 5| Step: 7
Training loss: 0.8217467069625854
Validation loss: 1.8382609300715949

Epoch: 5| Step: 8
Training loss: 0.617530107498169
Validation loss: 1.7895836086683377

Epoch: 5| Step: 9
Training loss: 0.3750055730342865
Validation loss: 1.7878151221941876

Epoch: 5| Step: 10
Training loss: 0.8575109839439392
Validation loss: 1.8127072267634894

Epoch: 227| Step: 0
Training loss: 0.6103382706642151
Validation loss: 1.824515514476325

Epoch: 5| Step: 1
Training loss: 0.6757468581199646
Validation loss: 1.796524206797282

Epoch: 5| Step: 2
Training loss: 0.8005302548408508
Validation loss: 1.799290987753099

Epoch: 5| Step: 3
Training loss: 0.3819285035133362
Validation loss: 1.8134884270288611

Epoch: 5| Step: 4
Training loss: 0.47776779532432556
Validation loss: 1.803637941678365

Epoch: 5| Step: 5
Training loss: 0.5260366201400757
Validation loss: 1.8552195513120262

Epoch: 5| Step: 6
Training loss: 0.6708731651306152
Validation loss: 1.8785579999287922

Epoch: 5| Step: 7
Training loss: 0.9223803281784058
Validation loss: 1.8691387432877735

Epoch: 5| Step: 8
Training loss: 0.6812728643417358
Validation loss: 1.880265470473997

Epoch: 5| Step: 9
Training loss: 0.6009899377822876
Validation loss: 1.9006504730511737

Epoch: 5| Step: 10
Training loss: 0.8029872179031372
Validation loss: 1.8598585205693399

Epoch: 228| Step: 0
Training loss: 0.8780662417411804
Validation loss: 1.8366187951898063

Epoch: 5| Step: 1
Training loss: 0.7137049436569214
Validation loss: 1.853185829295907

Epoch: 5| Step: 2
Training loss: 0.8405841588973999
Validation loss: 1.838871354697853

Epoch: 5| Step: 3
Training loss: 0.426159143447876
Validation loss: 1.84825042499009

Epoch: 5| Step: 4
Training loss: 0.5217323899269104
Validation loss: 1.8353514850780528

Epoch: 5| Step: 5
Training loss: 0.7187634706497192
Validation loss: 1.8193648758754934

Epoch: 5| Step: 6
Training loss: 0.33751264214515686
Validation loss: 1.8261202048229914

Epoch: 5| Step: 7
Training loss: 0.39941906929016113
Validation loss: 1.8203667761177145

Epoch: 5| Step: 8
Training loss: 0.8002734184265137
Validation loss: 1.824360809018535

Epoch: 5| Step: 9
Training loss: 0.819290816783905
Validation loss: 1.8623801623621294

Epoch: 5| Step: 10
Training loss: 0.555857241153717
Validation loss: 1.8757637751999723

Epoch: 229| Step: 0
Training loss: 0.35610443353652954
Validation loss: 1.9173532903835337

Epoch: 5| Step: 1
Training loss: 0.5253604650497437
Validation loss: 1.8724288735338437

Epoch: 5| Step: 2
Training loss: 0.5551929473876953
Validation loss: 1.8143417514780515

Epoch: 5| Step: 3
Training loss: 0.6661901473999023
Validation loss: 1.8002278368960145

Epoch: 5| Step: 4
Training loss: 0.4596617817878723
Validation loss: 1.75974985220099

Epoch: 5| Step: 5
Training loss: 0.7131444811820984
Validation loss: 1.7268529245930333

Epoch: 5| Step: 6
Training loss: 0.7515888810157776
Validation loss: 1.720767233961372

Epoch: 5| Step: 7
Training loss: 0.6729571223258972
Validation loss: 1.7299877212893577

Epoch: 5| Step: 8
Training loss: 0.5107537508010864
Validation loss: 1.7351446651643323

Epoch: 5| Step: 9
Training loss: 0.5777547955513
Validation loss: 1.7716718873670023

Epoch: 5| Step: 10
Training loss: 1.188715934753418
Validation loss: 1.794458358518539

Epoch: 230| Step: 0
Training loss: 0.7741667032241821
Validation loss: 1.8117801015095045

Epoch: 5| Step: 1
Training loss: 0.7274031639099121
Validation loss: 1.7930815758243683

Epoch: 5| Step: 2
Training loss: 0.5310801863670349
Validation loss: 1.785634353596677

Epoch: 5| Step: 3
Training loss: 0.3395112454891205
Validation loss: 1.789781621707383

Epoch: 5| Step: 4
Training loss: 0.5626046061515808
Validation loss: 1.8021463412110523

Epoch: 5| Step: 5
Training loss: 0.754214346408844
Validation loss: 1.800732183200057

Epoch: 5| Step: 6
Training loss: 0.49061569571495056
Validation loss: 1.7902011961065314

Epoch: 5| Step: 7
Training loss: 0.7709507346153259
Validation loss: 1.7794874855267104

Epoch: 5| Step: 8
Training loss: 0.5105561017990112
Validation loss: 1.7879272519901235

Epoch: 5| Step: 9
Training loss: 0.5278715491294861
Validation loss: 1.7904360909615793

Epoch: 5| Step: 10
Training loss: 0.7368884086608887
Validation loss: 1.789326108911986

Epoch: 231| Step: 0
Training loss: 0.9262495040893555
Validation loss: 1.7795548528753302

Epoch: 5| Step: 1
Training loss: 0.5267273187637329
Validation loss: 1.7931833382575744

Epoch: 5| Step: 2
Training loss: 0.3922330439090729
Validation loss: 1.8292607440743396

Epoch: 5| Step: 3
Training loss: 0.8519105911254883
Validation loss: 1.8541482853633102

Epoch: 5| Step: 4
Training loss: 0.7551170587539673
Validation loss: 1.8712510960076445

Epoch: 5| Step: 5
Training loss: 0.658318281173706
Validation loss: 1.841651080757059

Epoch: 5| Step: 6
Training loss: 0.5044795274734497
Validation loss: 1.849466312316156

Epoch: 5| Step: 7
Training loss: 0.7309112548828125
Validation loss: 1.809836213306714

Epoch: 5| Step: 8
Training loss: 0.3898398280143738
Validation loss: 1.81486423553959

Epoch: 5| Step: 9
Training loss: 0.5464078783988953
Validation loss: 1.807410232482418

Epoch: 5| Step: 10
Training loss: 0.7784682512283325
Validation loss: 1.7773405967220184

Epoch: 232| Step: 0
Training loss: 0.7859470248222351
Validation loss: 1.7583924467845629

Epoch: 5| Step: 1
Training loss: 0.4319973886013031
Validation loss: 1.7620575069099345

Epoch: 5| Step: 2
Training loss: 0.5474913716316223
Validation loss: 1.7634982985834922

Epoch: 5| Step: 3
Training loss: 0.6698199510574341
Validation loss: 1.773735930842738

Epoch: 5| Step: 4
Training loss: 0.5483176708221436
Validation loss: 1.7842237975007744

Epoch: 5| Step: 5
Training loss: 0.7560672163963318
Validation loss: 1.8121247176201112

Epoch: 5| Step: 6
Training loss: 0.5384275317192078
Validation loss: 1.8259632792524112

Epoch: 5| Step: 7
Training loss: 0.7007373571395874
Validation loss: 1.8254010215882333

Epoch: 5| Step: 8
Training loss: 0.5437163710594177
Validation loss: 1.8314476346456876

Epoch: 5| Step: 9
Training loss: 0.6690167188644409
Validation loss: 1.8702074635413386

Epoch: 5| Step: 10
Training loss: 0.7828531861305237
Validation loss: 1.8720190768600793

Epoch: 233| Step: 0
Training loss: 0.4197198748588562
Validation loss: 1.8563804177827732

Epoch: 5| Step: 1
Training loss: 0.6847855448722839
Validation loss: 1.8415550801061815

Epoch: 5| Step: 2
Training loss: 0.3441517651081085
Validation loss: 1.755254885201813

Epoch: 5| Step: 3
Training loss: 0.946844756603241
Validation loss: 1.7463167841716478

Epoch: 5| Step: 4
Training loss: 0.5684803128242493
Validation loss: 1.7226242583285096

Epoch: 5| Step: 5
Training loss: 0.73554927110672
Validation loss: 1.691765191734478

Epoch: 5| Step: 6
Training loss: 0.42679542303085327
Validation loss: 1.7053598011693647

Epoch: 5| Step: 7
Training loss: 0.5500513315200806
Validation loss: 1.7365151041297502

Epoch: 5| Step: 8
Training loss: 0.5541937947273254
Validation loss: 1.7675393653172318

Epoch: 5| Step: 9
Training loss: 0.928045392036438
Validation loss: 1.7854798301573722

Epoch: 5| Step: 10
Training loss: 0.3090251684188843
Validation loss: 1.792692930467667

Epoch: 234| Step: 0
Training loss: 0.3176341950893402
Validation loss: 1.791520426350255

Epoch: 5| Step: 1
Training loss: 0.5410709381103516
Validation loss: 1.7967348291027931

Epoch: 5| Step: 2
Training loss: 0.7307420969009399
Validation loss: 1.8007984443377423

Epoch: 5| Step: 3
Training loss: 0.3527848422527313
Validation loss: 1.8236879635882635

Epoch: 5| Step: 4
Training loss: 0.5855386257171631
Validation loss: 1.8517326411380564

Epoch: 5| Step: 5
Training loss: 0.45803752541542053
Validation loss: 1.8704387282812467

Epoch: 5| Step: 6
Training loss: 0.6489517092704773
Validation loss: 1.8399344657057075

Epoch: 5| Step: 7
Training loss: 0.728164553642273
Validation loss: 1.825266525309573

Epoch: 5| Step: 8
Training loss: 0.6221761107444763
Validation loss: 1.7888068601649294

Epoch: 5| Step: 9
Training loss: 0.6945590376853943
Validation loss: 1.7895881193940357

Epoch: 5| Step: 10
Training loss: 0.652454137802124
Validation loss: 1.7696013142985683

Epoch: 235| Step: 0
Training loss: 0.5888713598251343
Validation loss: 1.76176026046917

Epoch: 5| Step: 1
Training loss: 0.5449686646461487
Validation loss: 1.761903807681094

Epoch: 5| Step: 2
Training loss: 0.5008196234703064
Validation loss: 1.751827964218714

Epoch: 5| Step: 3
Training loss: 0.41046303510665894
Validation loss: 1.7711395371344782

Epoch: 5| Step: 4
Training loss: 0.5460858345031738
Validation loss: 1.7658477085892872

Epoch: 5| Step: 5
Training loss: 0.6778483986854553
Validation loss: 1.7911047422757713

Epoch: 5| Step: 6
Training loss: 0.6803063154220581
Validation loss: 1.7774620434289337

Epoch: 5| Step: 7
Training loss: 0.5594285726547241
Validation loss: 1.7685864971530052

Epoch: 5| Step: 8
Training loss: 0.6188291311264038
Validation loss: 1.753328920692526

Epoch: 5| Step: 9
Training loss: 0.6795711517333984
Validation loss: 1.765542596899053

Epoch: 5| Step: 10
Training loss: 0.5672681331634521
Validation loss: 1.7646424129445066

Epoch: 236| Step: 0
Training loss: 0.5428583025932312
Validation loss: 1.7886883827947802

Epoch: 5| Step: 1
Training loss: 0.6054908633232117
Validation loss: 1.828129974744653

Epoch: 5| Step: 2
Training loss: 0.6197071075439453
Validation loss: 1.8561479814590947

Epoch: 5| Step: 3
Training loss: 0.4690316319465637
Validation loss: 1.8484738603714974

Epoch: 5| Step: 4
Training loss: 0.6949694752693176
Validation loss: 1.8328611235464773

Epoch: 5| Step: 5
Training loss: 0.8803221583366394
Validation loss: 1.8106709231612503

Epoch: 5| Step: 6
Training loss: 0.6071171164512634
Validation loss: 1.821483822279079

Epoch: 5| Step: 7
Training loss: 0.36234429478645325
Validation loss: 1.7900135017210437

Epoch: 5| Step: 8
Training loss: 0.6775635480880737
Validation loss: 1.764590173639277

Epoch: 5| Step: 9
Training loss: 0.41336193680763245
Validation loss: 1.752362492263958

Epoch: 5| Step: 10
Training loss: 0.45213064551353455
Validation loss: 1.7134739455356394

Epoch: 237| Step: 0
Training loss: 0.3884216547012329
Validation loss: 1.728457672621614

Epoch: 5| Step: 1
Training loss: 0.6867374181747437
Validation loss: 1.7255276544119722

Epoch: 5| Step: 2
Training loss: 0.535616934299469
Validation loss: 1.7066309035465281

Epoch: 5| Step: 3
Training loss: 0.7084277868270874
Validation loss: 1.7027743131883684

Epoch: 5| Step: 4
Training loss: 0.612349808216095
Validation loss: 1.7011639853959442

Epoch: 5| Step: 5
Training loss: 0.5024498701095581
Validation loss: 1.7268721057522682

Epoch: 5| Step: 6
Training loss: 0.6290783882141113
Validation loss: 1.7624347645749328

Epoch: 5| Step: 7
Training loss: 0.6223480701446533
Validation loss: 1.7865726858057

Epoch: 5| Step: 8
Training loss: 0.5088256597518921
Validation loss: 1.7668627180078977

Epoch: 5| Step: 9
Training loss: 0.6529539823532104
Validation loss: 1.7676834329482047

Epoch: 5| Step: 10
Training loss: 0.49277764558792114
Validation loss: 1.8152236823112733

Epoch: 238| Step: 0
Training loss: 0.41057318449020386
Validation loss: 1.8114058817586591

Epoch: 5| Step: 1
Training loss: 0.5502935647964478
Validation loss: 1.8349220598897626

Epoch: 5| Step: 2
Training loss: 0.4724641442298889
Validation loss: 1.8184442699596446

Epoch: 5| Step: 3
Training loss: 0.4931170344352722
Validation loss: 1.7781237914998045

Epoch: 5| Step: 4
Training loss: 0.6984503865242004
Validation loss: 1.7719539711552281

Epoch: 5| Step: 5
Training loss: 0.8571702837944031
Validation loss: 1.770341452731881

Epoch: 5| Step: 6
Training loss: 0.6331379413604736
Validation loss: 1.762121199279703

Epoch: 5| Step: 7
Training loss: 0.47549933195114136
Validation loss: 1.7555229202393563

Epoch: 5| Step: 8
Training loss: 0.46972864866256714
Validation loss: 1.772141351494738

Epoch: 5| Step: 9
Training loss: 0.5119599103927612
Validation loss: 1.7711683422006586

Epoch: 5| Step: 10
Training loss: 0.6869655847549438
Validation loss: 1.7618717314094625

Epoch: 239| Step: 0
Training loss: 0.44434499740600586
Validation loss: 1.7679629800140217

Epoch: 5| Step: 1
Training loss: 0.5153006315231323
Validation loss: 1.7370619132954588

Epoch: 5| Step: 2
Training loss: 0.40339574217796326
Validation loss: 1.728799121354216

Epoch: 5| Step: 3
Training loss: 0.6380483508110046
Validation loss: 1.7049573749624274

Epoch: 5| Step: 4
Training loss: 0.9148126840591431
Validation loss: 1.735546983698363

Epoch: 5| Step: 5
Training loss: 0.9065116047859192
Validation loss: 1.7510971715373378

Epoch: 5| Step: 6
Training loss: 0.5154145359992981
Validation loss: 1.786042433913036

Epoch: 5| Step: 7
Training loss: 0.7024000883102417
Validation loss: 1.7834264962903914

Epoch: 5| Step: 8
Training loss: 0.5784176588058472
Validation loss: 1.796770611116963

Epoch: 5| Step: 9
Training loss: 0.19729551672935486
Validation loss: 1.7888589956427132

Epoch: 5| Step: 10
Training loss: 0.558712363243103
Validation loss: 1.823626466976699

Epoch: 240| Step: 0
Training loss: 0.706321120262146
Validation loss: 1.8272049273214033

Epoch: 5| Step: 1
Training loss: 0.752016544342041
Validation loss: 1.8335739335706156

Epoch: 5| Step: 2
Training loss: 0.5521966814994812
Validation loss: 1.8373325076154483

Epoch: 5| Step: 3
Training loss: 0.6350785493850708
Validation loss: 1.8394569299554313

Epoch: 5| Step: 4
Training loss: 0.5561445355415344
Validation loss: 1.8146091532963577

Epoch: 5| Step: 5
Training loss: 0.5470448732376099
Validation loss: 1.792283679849358

Epoch: 5| Step: 6
Training loss: 0.5178776383399963
Validation loss: 1.7568289131246588

Epoch: 5| Step: 7
Training loss: 0.25777333974838257
Validation loss: 1.7355731930784

Epoch: 5| Step: 8
Training loss: 0.5640616416931152
Validation loss: 1.7253072928356867

Epoch: 5| Step: 9
Training loss: 0.7540028691291809
Validation loss: 1.7453357301732546

Epoch: 5| Step: 10
Training loss: 0.26354774832725525
Validation loss: 1.7593163841514177

Epoch: 241| Step: 0
Training loss: 0.4714347720146179
Validation loss: 1.7745227172810545

Epoch: 5| Step: 1
Training loss: 0.4185849130153656
Validation loss: 1.79318440985936

Epoch: 5| Step: 2
Training loss: 0.8932428359985352
Validation loss: 1.7958091817876345

Epoch: 5| Step: 3
Training loss: 0.5083102583885193
Validation loss: 1.7675040063037668

Epoch: 5| Step: 4
Training loss: 0.6036215424537659
Validation loss: 1.7541703178036598

Epoch: 5| Step: 5
Training loss: 0.671294093132019
Validation loss: 1.738923547088459

Epoch: 5| Step: 6
Training loss: 0.4646431505680084
Validation loss: 1.762349065913949

Epoch: 5| Step: 7
Training loss: 0.7022478580474854
Validation loss: 1.775189168991581

Epoch: 5| Step: 8
Training loss: 0.5218857526779175
Validation loss: 1.7568669806244552

Epoch: 5| Step: 9
Training loss: 0.5633038282394409
Validation loss: 1.7619676077237694

Epoch: 5| Step: 10
Training loss: 0.4052836298942566
Validation loss: 1.7661146515159196

Epoch: 242| Step: 0
Training loss: 0.9025334119796753
Validation loss: 1.7303373300901024

Epoch: 5| Step: 1
Training loss: 0.47190895676612854
Validation loss: 1.7373385826746623

Epoch: 5| Step: 2
Training loss: 0.3151571750640869
Validation loss: 1.7429297233140597

Epoch: 5| Step: 3
Training loss: 0.5058087706565857
Validation loss: 1.7146924388024114

Epoch: 5| Step: 4
Training loss: 0.6262175440788269
Validation loss: 1.7412789713951848

Epoch: 5| Step: 5
Training loss: 0.6182817816734314
Validation loss: 1.7370511254956644

Epoch: 5| Step: 6
Training loss: 0.41672903299331665
Validation loss: 1.7526211533495175

Epoch: 5| Step: 7
Training loss: 0.4210895001888275
Validation loss: 1.7556209371935936

Epoch: 5| Step: 8
Training loss: 0.7079169154167175
Validation loss: 1.7995282526939147

Epoch: 5| Step: 9
Training loss: 0.5835233926773071
Validation loss: 1.819499986146086

Epoch: 5| Step: 10
Training loss: 0.5645725131034851
Validation loss: 1.8612022617811799

Epoch: 243| Step: 0
Training loss: 0.6919585466384888
Validation loss: 1.8844773538651005

Epoch: 5| Step: 1
Training loss: 0.8375716209411621
Validation loss: 1.8673871819690993

Epoch: 5| Step: 2
Training loss: 0.7687422037124634
Validation loss: 1.8520679166240077

Epoch: 5| Step: 3
Training loss: 0.7471965551376343
Validation loss: 1.8149994009284562

Epoch: 5| Step: 4
Training loss: 0.4888980984687805
Validation loss: 1.8172433363494052

Epoch: 5| Step: 5
Training loss: 0.23812563717365265
Validation loss: 1.7685783422121437

Epoch: 5| Step: 6
Training loss: 0.33090290427207947
Validation loss: 1.7514228474709295

Epoch: 5| Step: 7
Training loss: 0.5748006105422974
Validation loss: 1.7534667702131375

Epoch: 5| Step: 8
Training loss: 0.5841585397720337
Validation loss: 1.772954233231083

Epoch: 5| Step: 9
Training loss: 0.4892924726009369
Validation loss: 1.7731908136798489

Epoch: 5| Step: 10
Training loss: 0.4466630220413208
Validation loss: 1.7450407576817337

Epoch: 244| Step: 0
Training loss: 0.35932278633117676
Validation loss: 1.7734158257002473

Epoch: 5| Step: 1
Training loss: 0.8337215185165405
Validation loss: 1.7473030526150939

Epoch: 5| Step: 2
Training loss: 0.5815173983573914
Validation loss: 1.7599406588462092

Epoch: 5| Step: 3
Training loss: 0.316603422164917
Validation loss: 1.76161729392185

Epoch: 5| Step: 4
Training loss: 0.4530288577079773
Validation loss: 1.7797074497386973

Epoch: 5| Step: 5
Training loss: 0.4819084107875824
Validation loss: 1.8061531897514098

Epoch: 5| Step: 6
Training loss: 0.32109126448631287
Validation loss: 1.830952134183658

Epoch: 5| Step: 7
Training loss: 0.40993523597717285
Validation loss: 1.8179376330426944

Epoch: 5| Step: 8
Training loss: 0.5641732215881348
Validation loss: 1.846240266676872

Epoch: 5| Step: 9
Training loss: 0.8108037710189819
Validation loss: 1.8916526789306312

Epoch: 5| Step: 10
Training loss: 0.8038803935050964
Validation loss: 1.9105519299866052

Epoch: 245| Step: 0
Training loss: 0.4634578824043274
Validation loss: 1.8941172092191634

Epoch: 5| Step: 1
Training loss: 0.4322609305381775
Validation loss: 1.88219504843476

Epoch: 5| Step: 2
Training loss: 0.49793776869773865
Validation loss: 1.794160960822977

Epoch: 5| Step: 3
Training loss: 0.9346944689750671
Validation loss: 1.751568858341504

Epoch: 5| Step: 4
Training loss: 0.5130111575126648
Validation loss: 1.7596386568520659

Epoch: 5| Step: 5
Training loss: 0.5115398168563843
Validation loss: 1.7210702498753865

Epoch: 5| Step: 6
Training loss: 0.4942503869533539
Validation loss: 1.731705197723963

Epoch: 5| Step: 7
Training loss: 0.7211753726005554
Validation loss: 1.6862640111677107

Epoch: 5| Step: 8
Training loss: 0.4973909258842468
Validation loss: 1.6735350701116747

Epoch: 5| Step: 9
Training loss: 0.47757214307785034
Validation loss: 1.687495590538107

Epoch: 5| Step: 10
Training loss: 0.7421380281448364
Validation loss: 1.7007062101876864

Epoch: 246| Step: 0
Training loss: 0.5485254526138306
Validation loss: 1.7451593260611258

Epoch: 5| Step: 1
Training loss: 0.6919828653335571
Validation loss: 1.782205347091921

Epoch: 5| Step: 2
Training loss: 0.5359874367713928
Validation loss: 1.8143147268602926

Epoch: 5| Step: 3
Training loss: 0.765863299369812
Validation loss: 1.8342040584933372

Epoch: 5| Step: 4
Training loss: 0.9311838150024414
Validation loss: 1.851196563372048

Epoch: 5| Step: 5
Training loss: 0.4088098108768463
Validation loss: 1.8558547266067997

Epoch: 5| Step: 6
Training loss: 0.4771536886692047
Validation loss: 1.8239579316108459

Epoch: 5| Step: 7
Training loss: 0.26806193590164185
Validation loss: 1.7853394016142814

Epoch: 5| Step: 8
Training loss: 0.43194133043289185
Validation loss: 1.7806073017017816

Epoch: 5| Step: 9
Training loss: 0.6460423469543457
Validation loss: 1.7532772312882126

Epoch: 5| Step: 10
Training loss: 0.2943814694881439
Validation loss: 1.7222199081092753

Epoch: 247| Step: 0
Training loss: 0.48166847229003906
Validation loss: 1.703522938554005

Epoch: 5| Step: 1
Training loss: 0.5335713624954224
Validation loss: 1.7104278661871468

Epoch: 5| Step: 2
Training loss: 0.3137444257736206
Validation loss: 1.7279083690335673

Epoch: 5| Step: 3
Training loss: 0.6157971620559692
Validation loss: 1.733529031917613

Epoch: 5| Step: 4
Training loss: 0.44636526703834534
Validation loss: 1.7801370159272225

Epoch: 5| Step: 5
Training loss: 0.5497886538505554
Validation loss: 1.7405068335994598

Epoch: 5| Step: 6
Training loss: 0.6006119847297668
Validation loss: 1.7780245273343978

Epoch: 5| Step: 7
Training loss: 0.5699722170829773
Validation loss: 1.8100819856889787

Epoch: 5| Step: 8
Training loss: 0.46100372076034546
Validation loss: 1.8153838021780855

Epoch: 5| Step: 9
Training loss: 0.7563814520835876
Validation loss: 1.8117314025919924

Epoch: 5| Step: 10
Training loss: 0.41700655221939087
Validation loss: 1.795108094010302

Epoch: 248| Step: 0
Training loss: 0.6365591287612915
Validation loss: 1.7905840284080916

Epoch: 5| Step: 1
Training loss: 0.4684295654296875
Validation loss: 1.7698648629649993

Epoch: 5| Step: 2
Training loss: 0.6143769025802612
Validation loss: 1.7505034605662029

Epoch: 5| Step: 3
Training loss: 0.46546855568885803
Validation loss: 1.7185970660178893

Epoch: 5| Step: 4
Training loss: 0.3832909166812897
Validation loss: 1.6961900957169072

Epoch: 5| Step: 5
Training loss: 0.6449573636054993
Validation loss: 1.6830616689497424

Epoch: 5| Step: 6
Training loss: 0.6100553274154663
Validation loss: 1.6763478709805397

Epoch: 5| Step: 7
Training loss: 0.48578470945358276
Validation loss: 1.6839213909641388

Epoch: 5| Step: 8
Training loss: 0.271584689617157
Validation loss: 1.6654606237206409

Epoch: 5| Step: 9
Training loss: 0.4372343420982361
Validation loss: 1.706971900437468

Epoch: 5| Step: 10
Training loss: 0.496377557516098
Validation loss: 1.7268048819675241

Epoch: 249| Step: 0
Training loss: 0.2934941351413727
Validation loss: 1.7244567563456874

Epoch: 5| Step: 1
Training loss: 0.23807255923748016
Validation loss: 1.731940427134114

Epoch: 5| Step: 2
Training loss: 0.2612759470939636
Validation loss: 1.7030302786057996

Epoch: 5| Step: 3
Training loss: 0.6922820806503296
Validation loss: 1.6794105319566623

Epoch: 5| Step: 4
Training loss: 0.5576233863830566
Validation loss: 1.6879734608434862

Epoch: 5| Step: 5
Training loss: 0.2952371835708618
Validation loss: 1.729367498428591

Epoch: 5| Step: 6
Training loss: 0.573919415473938
Validation loss: 1.7286162889131935

Epoch: 5| Step: 7
Training loss: 0.7863572835922241
Validation loss: 1.7625413838253225

Epoch: 5| Step: 8
Training loss: 0.53346186876297
Validation loss: 1.7518399441114036

Epoch: 5| Step: 9
Training loss: 0.5928822755813599
Validation loss: 1.7769524371752174

Epoch: 5| Step: 10
Training loss: 0.5114626884460449
Validation loss: 1.7780888721507082

Epoch: 250| Step: 0
Training loss: 0.25811535120010376
Validation loss: 1.796024312255203

Epoch: 5| Step: 1
Training loss: 0.6690980195999146
Validation loss: 1.8227131353911532

Epoch: 5| Step: 2
Training loss: 0.4156753420829773
Validation loss: 1.8319268918806506

Epoch: 5| Step: 3
Training loss: 0.6364949345588684
Validation loss: 1.7997596161339873

Epoch: 5| Step: 4
Training loss: 0.6155580282211304
Validation loss: 1.7876529642330703

Epoch: 5| Step: 5
Training loss: 0.3337339758872986
Validation loss: 1.7611893761542536

Epoch: 5| Step: 6
Training loss: 0.6088203191757202
Validation loss: 1.7117224624080043

Epoch: 5| Step: 7
Training loss: 0.40678858757019043
Validation loss: 1.7018924643916469

Epoch: 5| Step: 8
Training loss: 0.6455633044242859
Validation loss: 1.7301953531080676

Epoch: 5| Step: 9
Training loss: 0.6175154447555542
Validation loss: 1.7355165481567383

Epoch: 5| Step: 10
Training loss: 0.31697821617126465
Validation loss: 1.7717812125400831

Epoch: 251| Step: 0
Training loss: 0.450584352016449
Validation loss: 1.7614800686477332

Epoch: 5| Step: 1
Training loss: 0.6309526562690735
Validation loss: 1.7831473978616859

Epoch: 5| Step: 2
Training loss: 0.25998830795288086
Validation loss: 1.795526719862415

Epoch: 5| Step: 3
Training loss: 0.4799068868160248
Validation loss: 1.7967886706834197

Epoch: 5| Step: 4
Training loss: 0.37880462408065796
Validation loss: 1.7901600612107145

Epoch: 5| Step: 5
Training loss: 0.5978177785873413
Validation loss: 1.7594925421540455

Epoch: 5| Step: 6
Training loss: 0.5932220220565796
Validation loss: 1.7255633569532824

Epoch: 5| Step: 7
Training loss: 0.5265980958938599
Validation loss: 1.7086263241306427

Epoch: 5| Step: 8
Training loss: 0.4089471697807312
Validation loss: 1.6973974832924463

Epoch: 5| Step: 9
Training loss: 0.7351697087287903
Validation loss: 1.6753989983630437

Epoch: 5| Step: 10
Training loss: 0.3962344229221344
Validation loss: 1.717370815174554

Epoch: 252| Step: 0
Training loss: 0.3357996940612793
Validation loss: 1.691228974250055

Epoch: 5| Step: 1
Training loss: 0.3892405033111572
Validation loss: 1.7026380723522556

Epoch: 5| Step: 2
Training loss: 0.5438397526741028
Validation loss: 1.7488206407075286

Epoch: 5| Step: 3
Training loss: 0.3889524042606354
Validation loss: 1.8039612616262128

Epoch: 5| Step: 4
Training loss: 0.8201637268066406
Validation loss: 1.8678668904048141

Epoch: 5| Step: 5
Training loss: 0.6928554177284241
Validation loss: 1.9052046704035934

Epoch: 5| Step: 6
Training loss: 0.5356807708740234
Validation loss: 1.8870587297665176

Epoch: 5| Step: 7
Training loss: 0.6206900477409363
Validation loss: 1.8311788510250788

Epoch: 5| Step: 8
Training loss: 0.45289692282676697
Validation loss: 1.7558900258874381

Epoch: 5| Step: 9
Training loss: 0.5813651084899902
Validation loss: 1.688448545753315

Epoch: 5| Step: 10
Training loss: 0.29689446091651917
Validation loss: 1.645817841252973

Epoch: 253| Step: 0
Training loss: 0.6212373971939087
Validation loss: 1.6313937351267824

Epoch: 5| Step: 1
Training loss: 0.6155820488929749
Validation loss: 1.631709123170504

Epoch: 5| Step: 2
Training loss: 0.47324639558792114
Validation loss: 1.612955424093431

Epoch: 5| Step: 3
Training loss: 0.3231274485588074
Validation loss: 1.6675517853870188

Epoch: 5| Step: 4
Training loss: 0.4479486346244812
Validation loss: 1.7178151915150304

Epoch: 5| Step: 5
Training loss: 0.43807873129844666
Validation loss: 1.774777312432566

Epoch: 5| Step: 6
Training loss: 0.6553935408592224
Validation loss: 1.794168431271789

Epoch: 5| Step: 7
Training loss: 0.5612062811851501
Validation loss: 1.7784069699625815

Epoch: 5| Step: 8
Training loss: 0.3779941201210022
Validation loss: 1.8289489694820937

Epoch: 5| Step: 9
Training loss: 0.4864540100097656
Validation loss: 1.7811867511400612

Epoch: 5| Step: 10
Training loss: 0.36634159088134766
Validation loss: 1.783254506767437

Epoch: 254| Step: 0
Training loss: 0.42805570363998413
Validation loss: 1.753710554492089

Epoch: 5| Step: 1
Training loss: 0.25750479102134705
Validation loss: 1.7138187244374266

Epoch: 5| Step: 2
Training loss: 0.40785136818885803
Validation loss: 1.666029171277118

Epoch: 5| Step: 3
Training loss: 0.43959546089172363
Validation loss: 1.6837502320607503

Epoch: 5| Step: 4
Training loss: 0.6309088468551636
Validation loss: 1.684072809834634

Epoch: 5| Step: 5
Training loss: 0.5510722994804382
Validation loss: 1.7114583433315318

Epoch: 5| Step: 6
Training loss: 0.448965460062027
Validation loss: 1.6931258375926683

Epoch: 5| Step: 7
Training loss: 0.615678071975708
Validation loss: 1.7192713086323073

Epoch: 5| Step: 8
Training loss: 0.5527099370956421
Validation loss: 1.7167512562967115

Epoch: 5| Step: 9
Training loss: 0.5052743554115295
Validation loss: 1.7403713528827955

Epoch: 5| Step: 10
Training loss: 0.3198487162590027
Validation loss: 1.7703655983812066

Epoch: 255| Step: 0
Training loss: 0.46023789048194885
Validation loss: 1.8041146032271846

Epoch: 5| Step: 1
Training loss: 0.4343241751194
Validation loss: 1.810375846842284

Epoch: 5| Step: 2
Training loss: 0.2850542366504669
Validation loss: 1.8342627427911247

Epoch: 5| Step: 3
Training loss: 0.3300544321537018
Validation loss: 1.8116327742094636

Epoch: 5| Step: 4
Training loss: 0.4758242666721344
Validation loss: 1.81477734094025

Epoch: 5| Step: 5
Training loss: 0.5664297342300415
Validation loss: 1.810591846384028

Epoch: 5| Step: 6
Training loss: 0.4426259994506836
Validation loss: 1.7668010278414654

Epoch: 5| Step: 7
Training loss: 0.5228513479232788
Validation loss: 1.7405637054033176

Epoch: 5| Step: 8
Training loss: 0.4067601263523102
Validation loss: 1.7289073082708544

Epoch: 5| Step: 9
Training loss: 0.4573957920074463
Validation loss: 1.695552513163577

Epoch: 5| Step: 10
Training loss: 0.635208249092102
Validation loss: 1.701180955415131

Epoch: 256| Step: 0
Training loss: 0.5700203776359558
Validation loss: 1.7225105993209346

Epoch: 5| Step: 1
Training loss: 0.9402793645858765
Validation loss: 1.7246961747446368

Epoch: 5| Step: 2
Training loss: 0.3423137068748474
Validation loss: 1.7155519826437837

Epoch: 5| Step: 3
Training loss: 0.2397240698337555
Validation loss: 1.7323188563828826

Epoch: 5| Step: 4
Training loss: 0.3680335581302643
Validation loss: 1.7640870822373258

Epoch: 5| Step: 5
Training loss: 0.4096427857875824
Validation loss: 1.7757918860322686

Epoch: 5| Step: 6
Training loss: 0.6038715839385986
Validation loss: 1.801492230866545

Epoch: 5| Step: 7
Training loss: 0.14103753864765167
Validation loss: 1.7712672756564232

Epoch: 5| Step: 8
Training loss: 0.553022563457489
Validation loss: 1.7961358588228944

Epoch: 5| Step: 9
Training loss: 0.3135114014148712
Validation loss: 1.7751039638314197

Epoch: 5| Step: 10
Training loss: 0.3449903428554535
Validation loss: 1.754161148942927

Epoch: 257| Step: 0
Training loss: 0.3595256209373474
Validation loss: 1.753220312057003

Epoch: 5| Step: 1
Training loss: 0.31580644845962524
Validation loss: 1.7257147982556333

Epoch: 5| Step: 2
Training loss: 0.5051096677780151
Validation loss: 1.7310773634141492

Epoch: 5| Step: 3
Training loss: 0.27086013555526733
Validation loss: 1.7383355748268865

Epoch: 5| Step: 4
Training loss: 0.6086448431015015
Validation loss: 1.7546866350276495

Epoch: 5| Step: 5
Training loss: 0.5352951288223267
Validation loss: 1.7621644107244347

Epoch: 5| Step: 6
Training loss: 0.34884166717529297
Validation loss: 1.7437379757563274

Epoch: 5| Step: 7
Training loss: 0.6302540302276611
Validation loss: 1.7627598265165925

Epoch: 5| Step: 8
Training loss: 0.3158359229564667
Validation loss: 1.752000072950958

Epoch: 5| Step: 9
Training loss: 0.44865474104881287
Validation loss: 1.7211630677664151

Epoch: 5| Step: 10
Training loss: 0.3808656632900238
Validation loss: 1.729886137029176

Epoch: 258| Step: 0
Training loss: 0.6302034258842468
Validation loss: 1.7312051032179145

Epoch: 5| Step: 1
Training loss: 0.32875198125839233
Validation loss: 1.7300702743632819

Epoch: 5| Step: 2
Training loss: 0.30873021483421326
Validation loss: 1.7323555664349628

Epoch: 5| Step: 3
Training loss: 0.44620370864868164
Validation loss: 1.7738116159233996

Epoch: 5| Step: 4
Training loss: 0.3804304003715515
Validation loss: 1.7869775859258508

Epoch: 5| Step: 5
Training loss: 0.30527201294898987
Validation loss: 1.7952950193035988

Epoch: 5| Step: 6
Training loss: 0.5358974933624268
Validation loss: 1.7832667443060106

Epoch: 5| Step: 7
Training loss: 0.22758230566978455
Validation loss: 1.7432683180737238

Epoch: 5| Step: 8
Training loss: 0.5865474939346313
Validation loss: 1.7390598404792048

Epoch: 5| Step: 9
Training loss: 0.6996482610702515
Validation loss: 1.7187349873204385

Epoch: 5| Step: 10
Training loss: 0.39528322219848633
Validation loss: 1.7233557566519706

Epoch: 259| Step: 0
Training loss: 0.42960959672927856
Validation loss: 1.6784624309949978

Epoch: 5| Step: 1
Training loss: 0.38513511419296265
Validation loss: 1.673955596903319

Epoch: 5| Step: 2
Training loss: 0.5424138307571411
Validation loss: 1.6802693131149455

Epoch: 5| Step: 3
Training loss: 0.3960327208042145
Validation loss: 1.6886038113665838

Epoch: 5| Step: 4
Training loss: 0.7169250249862671
Validation loss: 1.7095684671914706

Epoch: 5| Step: 5
Training loss: 0.4472845196723938
Validation loss: 1.7123340329816263

Epoch: 5| Step: 6
Training loss: 0.34222400188446045
Validation loss: 1.7017319651060208

Epoch: 5| Step: 7
Training loss: 0.43856945633888245
Validation loss: 1.7425574512891873

Epoch: 5| Step: 8
Training loss: 0.1727122962474823
Validation loss: 1.7010205420114661

Epoch: 5| Step: 9
Training loss: 0.36616021394729614
Validation loss: 1.7146296052522556

Epoch: 5| Step: 10
Training loss: 0.32072338461875916
Validation loss: 1.7089197353650165

Epoch: 260| Step: 0
Training loss: 0.45683878660202026
Validation loss: 1.7366508912014704

Epoch: 5| Step: 1
Training loss: 0.5765694379806519
Validation loss: 1.751977337303982

Epoch: 5| Step: 2
Training loss: 0.3468801975250244
Validation loss: 1.8019757168267363

Epoch: 5| Step: 3
Training loss: 0.41897478699684143
Validation loss: 1.791963702888899

Epoch: 5| Step: 4
Training loss: 0.240993931889534
Validation loss: 1.7617863352580736

Epoch: 5| Step: 5
Training loss: 0.2646639347076416
Validation loss: 1.7172567254753524

Epoch: 5| Step: 6
Training loss: 0.3294725716114044
Validation loss: 1.7107845698633501

Epoch: 5| Step: 7
Training loss: 0.4039795398712158
Validation loss: 1.694432202205863

Epoch: 5| Step: 8
Training loss: 0.437691867351532
Validation loss: 1.682804540921283

Epoch: 5| Step: 9
Training loss: 0.7464502453804016
Validation loss: 1.6623625755310059

Epoch: 5| Step: 10
Training loss: 0.42805591225624084
Validation loss: 1.6706074681333316

Epoch: 261| Step: 0
Training loss: 0.34724515676498413
Validation loss: 1.692413446723774

Epoch: 5| Step: 1
Training loss: 0.5490579605102539
Validation loss: 1.685937722524007

Epoch: 5| Step: 2
Training loss: 0.5459132194519043
Validation loss: 1.7006809647365282

Epoch: 5| Step: 3
Training loss: 0.6145989298820496
Validation loss: 1.74455762422213

Epoch: 5| Step: 4
Training loss: 0.5191548466682434
Validation loss: 1.7326194112018873

Epoch: 5| Step: 5
Training loss: 0.5476316809654236
Validation loss: 1.7565905612002137

Epoch: 5| Step: 6
Training loss: 0.3453314006328583
Validation loss: 1.7371628104999501

Epoch: 5| Step: 7
Training loss: 0.2985169291496277
Validation loss: 1.7527681268671507

Epoch: 5| Step: 8
Training loss: 0.2574131488800049
Validation loss: 1.759902306782302

Epoch: 5| Step: 9
Training loss: 0.17671090364456177
Validation loss: 1.7566520398662937

Epoch: 5| Step: 10
Training loss: 0.4160177707672119
Validation loss: 1.7567797655700355

Epoch: 262| Step: 0
Training loss: 0.5520967245101929
Validation loss: 1.720279441084913

Epoch: 5| Step: 1
Training loss: 0.27932602167129517
Validation loss: 1.7188319647183983

Epoch: 5| Step: 2
Training loss: 0.44033026695251465
Validation loss: 1.7054309562970233

Epoch: 5| Step: 3
Training loss: 0.1834096610546112
Validation loss: 1.6864521529084893

Epoch: 5| Step: 4
Training loss: 0.5057495832443237
Validation loss: 1.685603819867616

Epoch: 5| Step: 5
Training loss: 0.4896436631679535
Validation loss: 1.6843480910024335

Epoch: 5| Step: 6
Training loss: 0.3008289039134979
Validation loss: 1.7162599384143788

Epoch: 5| Step: 7
Training loss: 0.6049863696098328
Validation loss: 1.7326238411729054

Epoch: 5| Step: 8
Training loss: 0.4298947751522064
Validation loss: 1.7538105839042253

Epoch: 5| Step: 9
Training loss: 0.44023823738098145
Validation loss: 1.782219066414782

Epoch: 5| Step: 10
Training loss: 0.36013543605804443
Validation loss: 1.8036301482108332

Epoch: 263| Step: 0
Training loss: 0.5666206479072571
Validation loss: 1.788884601926291

Epoch: 5| Step: 1
Training loss: 0.36680588126182556
Validation loss: 1.7560263628600745

Epoch: 5| Step: 2
Training loss: 0.41504478454589844
Validation loss: 1.7231037065547

Epoch: 5| Step: 3
Training loss: 0.3337560296058655
Validation loss: 1.6987159200893935

Epoch: 5| Step: 4
Training loss: 0.4018177390098572
Validation loss: 1.6835155884424846

Epoch: 5| Step: 5
Training loss: 0.6351515054702759
Validation loss: 1.689443172947053

Epoch: 5| Step: 6
Training loss: 0.6973556280136108
Validation loss: 1.691881775856018

Epoch: 5| Step: 7
Training loss: 0.24989382922649384
Validation loss: 1.7046518582169727

Epoch: 5| Step: 8
Training loss: 0.4454732835292816
Validation loss: 1.7275403109929894

Epoch: 5| Step: 9
Training loss: 0.3513125777244568
Validation loss: 1.7493672242728613

Epoch: 5| Step: 10
Training loss: 0.3192945420742035
Validation loss: 1.764909541735085

Epoch: 264| Step: 0
Training loss: 0.48198747634887695
Validation loss: 1.7913925122189265

Epoch: 5| Step: 1
Training loss: 0.4220009744167328
Validation loss: 1.7574373765658307

Epoch: 5| Step: 2
Training loss: 0.6325479745864868
Validation loss: 1.749341751939507

Epoch: 5| Step: 3
Training loss: 0.3437693119049072
Validation loss: 1.759270437302128

Epoch: 5| Step: 4
Training loss: 0.3075486123561859
Validation loss: 1.7426444317704888

Epoch: 5| Step: 5
Training loss: 0.3998205065727234
Validation loss: 1.742360253487864

Epoch: 5| Step: 6
Training loss: 0.2704375982284546
Validation loss: 1.7350968558301207

Epoch: 5| Step: 7
Training loss: 0.37397611141204834
Validation loss: 1.7378290571192259

Epoch: 5| Step: 8
Training loss: 0.4287680685520172
Validation loss: 1.7539311250050862

Epoch: 5| Step: 9
Training loss: 0.44874030351638794
Validation loss: 1.7427610876739665

Epoch: 5| Step: 10
Training loss: 0.46624401211738586
Validation loss: 1.739097326032577

Epoch: 265| Step: 0
Training loss: 0.3799116611480713
Validation loss: 1.7384595883789884

Epoch: 5| Step: 1
Training loss: 0.4886525273323059
Validation loss: 1.7183723821434924

Epoch: 5| Step: 2
Training loss: 0.6910201907157898
Validation loss: 1.7435345149809314

Epoch: 5| Step: 3
Training loss: 0.35717228055000305
Validation loss: 1.7345788196850849

Epoch: 5| Step: 4
Training loss: 0.2859247326850891
Validation loss: 1.7264189053607244

Epoch: 5| Step: 5
Training loss: 0.2918732464313507
Validation loss: 1.7213855994644987

Epoch: 5| Step: 6
Training loss: 0.2850058972835541
Validation loss: 1.7537245981154903

Epoch: 5| Step: 7
Training loss: 0.3653111159801483
Validation loss: 1.7161053406294955

Epoch: 5| Step: 8
Training loss: 0.357516348361969
Validation loss: 1.750476921758344

Epoch: 5| Step: 9
Training loss: 0.3493489623069763
Validation loss: 1.7346078042061097

Epoch: 5| Step: 10
Training loss: 0.593127429485321
Validation loss: 1.732943747633247

Epoch: 266| Step: 0
Training loss: 0.3729940354824066
Validation loss: 1.7533539828433786

Epoch: 5| Step: 1
Training loss: 0.3006476163864136
Validation loss: 1.7346084066616592

Epoch: 5| Step: 2
Training loss: 0.2615048289299011
Validation loss: 1.7377996213974491

Epoch: 5| Step: 3
Training loss: 0.7021156549453735
Validation loss: 1.7226250607480285

Epoch: 5| Step: 4
Training loss: 0.4096452593803406
Validation loss: 1.7000385445933188

Epoch: 5| Step: 5
Training loss: 0.4296283721923828
Validation loss: 1.6965730626096007

Epoch: 5| Step: 6
Training loss: 0.4033046364784241
Validation loss: 1.6974605815384978

Epoch: 5| Step: 7
Training loss: 0.4788019061088562
Validation loss: 1.664505773975003

Epoch: 5| Step: 8
Training loss: 0.29928138852119446
Validation loss: 1.6864904024267708

Epoch: 5| Step: 9
Training loss: 0.34323006868362427
Validation loss: 1.6762050005697435

Epoch: 5| Step: 10
Training loss: 0.3769485652446747
Validation loss: 1.6706117276222474

Epoch: 267| Step: 0
Training loss: 0.35165882110595703
Validation loss: 1.6909421118356849

Epoch: 5| Step: 1
Training loss: 0.20792612433433533
Validation loss: 1.7113413426183886

Epoch: 5| Step: 2
Training loss: 0.17853155732154846
Validation loss: 1.7118036131705008

Epoch: 5| Step: 3
Training loss: 0.48756831884384155
Validation loss: 1.7251291826207151

Epoch: 5| Step: 4
Training loss: 0.3050885498523712
Validation loss: 1.7095804188841133

Epoch: 5| Step: 5
Training loss: 0.36937808990478516
Validation loss: 1.7370467365428965

Epoch: 5| Step: 6
Training loss: 0.42898377776145935
Validation loss: 1.7559577495821062

Epoch: 5| Step: 7
Training loss: 0.686179518699646
Validation loss: 1.7191876198655816

Epoch: 5| Step: 8
Training loss: 0.27829301357269287
Validation loss: 1.7560758103606522

Epoch: 5| Step: 9
Training loss: 0.4954749643802643
Validation loss: 1.7310371834744689

Epoch: 5| Step: 10
Training loss: 0.5676891207695007
Validation loss: 1.721930383995015

Epoch: 268| Step: 0
Training loss: 0.3216976523399353
Validation loss: 1.7170085445527108

Epoch: 5| Step: 1
Training loss: 0.36638492345809937
Validation loss: 1.7071349736182921

Epoch: 5| Step: 2
Training loss: 0.234584242105484
Validation loss: 1.6637930152236775

Epoch: 5| Step: 3
Training loss: 0.4655900001525879
Validation loss: 1.6470682774820635

Epoch: 5| Step: 4
Training loss: 0.5465089082717896
Validation loss: 1.696781725011846

Epoch: 5| Step: 5
Training loss: 0.33824777603149414
Validation loss: 1.647499276745704

Epoch: 5| Step: 6
Training loss: 0.16079965233802795
Validation loss: 1.6954941839300177

Epoch: 5| Step: 7
Training loss: 0.5522299408912659
Validation loss: 1.7193910742318759

Epoch: 5| Step: 8
Training loss: 0.33283334970474243
Validation loss: 1.7342888373200611

Epoch: 5| Step: 9
Training loss: 0.31229475140571594
Validation loss: 1.7317351448920466

Epoch: 5| Step: 10
Training loss: 0.6183956265449524
Validation loss: 1.777762936007592

Epoch: 269| Step: 0
Training loss: 0.30096644163131714
Validation loss: 1.7649261156717937

Epoch: 5| Step: 1
Training loss: 0.5245652794837952
Validation loss: 1.7543188859057683

Epoch: 5| Step: 2
Training loss: 0.3159486949443817
Validation loss: 1.706124932535233

Epoch: 5| Step: 3
Training loss: 0.2608150541782379
Validation loss: 1.7081936995188396

Epoch: 5| Step: 4
Training loss: 0.29992759227752686
Validation loss: 1.6892059720972532

Epoch: 5| Step: 5
Training loss: 0.6222962141036987
Validation loss: 1.6956829294081657

Epoch: 5| Step: 6
Training loss: 0.301704078912735
Validation loss: 1.6924571516693279

Epoch: 5| Step: 7
Training loss: 0.4700676500797272
Validation loss: 1.6884651594264533

Epoch: 5| Step: 8
Training loss: 0.40448611974716187
Validation loss: 1.6934662724053988

Epoch: 5| Step: 9
Training loss: 0.3021460175514221
Validation loss: 1.711203686652645

Epoch: 5| Step: 10
Training loss: 0.348850280046463
Validation loss: 1.7189087585736347

Epoch: 270| Step: 0
Training loss: 0.500660240650177
Validation loss: 1.7055749483005975

Epoch: 5| Step: 1
Training loss: 0.2027377188205719
Validation loss: 1.7045218085729947

Epoch: 5| Step: 2
Training loss: 0.2662746012210846
Validation loss: 1.711285133515635

Epoch: 5| Step: 3
Training loss: 0.36594194173812866
Validation loss: 1.7124247140781854

Epoch: 5| Step: 4
Training loss: 0.33965954184532166
Validation loss: 1.7085505839317077

Epoch: 5| Step: 5
Training loss: 0.3423519730567932
Validation loss: 1.7124756766903786

Epoch: 5| Step: 6
Training loss: 0.23360159993171692
Validation loss: 1.6787281997742192

Epoch: 5| Step: 7
Training loss: 0.35356906056404114
Validation loss: 1.666895184465634

Epoch: 5| Step: 8
Training loss: 0.6251729130744934
Validation loss: 1.7038151359045377

Epoch: 5| Step: 9
Training loss: 0.4958910048007965
Validation loss: 1.6721112471754833

Epoch: 5| Step: 10
Training loss: 0.26493650674819946
Validation loss: 1.6580556541360834

Epoch: 271| Step: 0
Training loss: 0.12482228130102158
Validation loss: 1.6785308020089262

Epoch: 5| Step: 1
Training loss: 0.3867937922477722
Validation loss: 1.680212160592438

Epoch: 5| Step: 2
Training loss: 0.3462717533111572
Validation loss: 1.6936336089205999

Epoch: 5| Step: 3
Training loss: 0.15014412999153137
Validation loss: 1.6884797721780755

Epoch: 5| Step: 4
Training loss: 0.4045916497707367
Validation loss: 1.693231765941907

Epoch: 5| Step: 5
Training loss: 0.3184531331062317
Validation loss: 1.6799019895574099

Epoch: 5| Step: 6
Training loss: 0.4367419183254242
Validation loss: 1.685975932305859

Epoch: 5| Step: 7
Training loss: 0.6808297038078308
Validation loss: 1.656841762604252

Epoch: 5| Step: 8
Training loss: 0.25550511479377747
Validation loss: 1.6438436456905898

Epoch: 5| Step: 9
Training loss: 0.49294695258140564
Validation loss: 1.6299838225046794

Epoch: 5| Step: 10
Training loss: 0.40068158507347107
Validation loss: 1.6399328631739463

Epoch: 272| Step: 0
Training loss: 0.29331475496292114
Validation loss: 1.6562119940275788

Epoch: 5| Step: 1
Training loss: 0.4694289565086365
Validation loss: 1.6636403799057007

Epoch: 5| Step: 2
Training loss: 0.2837907671928406
Validation loss: 1.6797800910088323

Epoch: 5| Step: 3
Training loss: 0.33719339966773987
Validation loss: 1.7120416356671242

Epoch: 5| Step: 4
Training loss: 0.3907041549682617
Validation loss: 1.7279469556705926

Epoch: 5| Step: 5
Training loss: 0.3246591091156006
Validation loss: 1.7406191813048495

Epoch: 5| Step: 6
Training loss: 0.540218710899353
Validation loss: 1.7457165115623063

Epoch: 5| Step: 7
Training loss: 0.3824688196182251
Validation loss: 1.7320965554124566

Epoch: 5| Step: 8
Training loss: 0.2744186520576477
Validation loss: 1.7015351518507926

Epoch: 5| Step: 9
Training loss: 0.3520130515098572
Validation loss: 1.6989531222210135

Epoch: 5| Step: 10
Training loss: 0.3607710003852844
Validation loss: 1.6728508856988722

Epoch: 273| Step: 0
Training loss: 0.29956626892089844
Validation loss: 1.6214048631729618

Epoch: 5| Step: 1
Training loss: 0.4208351671695709
Validation loss: 1.5829576433345836

Epoch: 5| Step: 2
Training loss: 0.3346945643424988
Validation loss: 1.5564869988349177

Epoch: 5| Step: 3
Training loss: 0.6272048354148865
Validation loss: 1.5714018870425481

Epoch: 5| Step: 4
Training loss: 0.3633081316947937
Validation loss: 1.572087299439215

Epoch: 5| Step: 5
Training loss: 0.4109116196632385
Validation loss: 1.5852564611742574

Epoch: 5| Step: 6
Training loss: 0.39048171043395996
Validation loss: 1.6577146886497416

Epoch: 5| Step: 7
Training loss: 0.30912381410598755
Validation loss: 1.673712613762066

Epoch: 5| Step: 8
Training loss: 0.23852738738059998
Validation loss: 1.7149342272871284

Epoch: 5| Step: 9
Training loss: 0.38386526703834534
Validation loss: 1.7582916700711815

Epoch: 5| Step: 10
Training loss: 0.30242738127708435
Validation loss: 1.7706530081328524

Epoch: 274| Step: 0
Training loss: 0.2071772813796997
Validation loss: 1.8398681263769827

Epoch: 5| Step: 1
Training loss: 0.3961102366447449
Validation loss: 1.8318052753325431

Epoch: 5| Step: 2
Training loss: 0.4490998387336731
Validation loss: 1.821909289847138

Epoch: 5| Step: 3
Training loss: 0.25805431604385376
Validation loss: 1.8005734746174147

Epoch: 5| Step: 4
Training loss: 0.2945103645324707
Validation loss: 1.7512009912921536

Epoch: 5| Step: 5
Training loss: 0.47021475434303284
Validation loss: 1.7196195894672024

Epoch: 5| Step: 6
Training loss: 0.41179245710372925
Validation loss: 1.6635308573322911

Epoch: 5| Step: 7
Training loss: 0.628359317779541
Validation loss: 1.6467093588203512

Epoch: 5| Step: 8
Training loss: 0.33593469858169556
Validation loss: 1.6491085175544984

Epoch: 5| Step: 9
Training loss: 0.3653078079223633
Validation loss: 1.6204121330732941

Epoch: 5| Step: 10
Training loss: 0.5134596824645996
Validation loss: 1.6107684361037387

Epoch: 275| Step: 0
Training loss: 0.5230964422225952
Validation loss: 1.615176344430575

Epoch: 5| Step: 1
Training loss: 0.3847440183162689
Validation loss: 1.6184920072555542

Epoch: 5| Step: 2
Training loss: 0.25983190536499023
Validation loss: 1.6141277731105845

Epoch: 5| Step: 3
Training loss: 0.38819751143455505
Validation loss: 1.6300472328739781

Epoch: 5| Step: 4
Training loss: 0.22535035014152527
Validation loss: 1.6371167757177865

Epoch: 5| Step: 5
Training loss: 0.38913974165916443
Validation loss: 1.6837973697211153

Epoch: 5| Step: 6
Training loss: 0.2566256523132324
Validation loss: 1.7171271962504233

Epoch: 5| Step: 7
Training loss: 0.3161209523677826
Validation loss: 1.7360668778419495

Epoch: 5| Step: 8
Training loss: 0.36711350083351135
Validation loss: 1.7404608636774042

Epoch: 5| Step: 9
Training loss: 0.2807248532772064
Validation loss: 1.7260693170691048

Epoch: 5| Step: 10
Training loss: 0.5848761200904846
Validation loss: 1.720855716736086

Epoch: 276| Step: 0
Training loss: 0.22850115597248077
Validation loss: 1.6907443615698046

Epoch: 5| Step: 1
Training loss: 0.47299617528915405
Validation loss: 1.666965748674126

Epoch: 5| Step: 2
Training loss: 0.3185262084007263
Validation loss: 1.6265418119327997

Epoch: 5| Step: 3
Training loss: 0.48870939016342163
Validation loss: 1.6903592950554305

Epoch: 5| Step: 4
Training loss: 0.4479896128177643
Validation loss: 1.686669893803135

Epoch: 5| Step: 5
Training loss: 0.34489208459854126
Validation loss: 1.6875070705208728

Epoch: 5| Step: 6
Training loss: 0.41275542974472046
Validation loss: 1.6583018533645137

Epoch: 5| Step: 7
Training loss: 0.28922414779663086
Validation loss: 1.673429250717163

Epoch: 5| Step: 8
Training loss: 0.33008673787117004
Validation loss: 1.7046869198481243

Epoch: 5| Step: 9
Training loss: 0.433215469121933
Validation loss: 1.719772760586072

Epoch: 5| Step: 10
Training loss: 0.4024617671966553
Validation loss: 1.7552259916900306

Epoch: 277| Step: 0
Training loss: 0.2965252995491028
Validation loss: 1.729195817824333

Epoch: 5| Step: 1
Training loss: 0.3055249750614166
Validation loss: 1.7370439524291663

Epoch: 5| Step: 2
Training loss: 0.24065890908241272
Validation loss: 1.7311955113564768

Epoch: 5| Step: 3
Training loss: 0.23514433205127716
Validation loss: 1.716563340156309

Epoch: 5| Step: 4
Training loss: 0.3072234094142914
Validation loss: 1.692360531899237

Epoch: 5| Step: 5
Training loss: 0.34580880403518677
Validation loss: 1.6895195002196937

Epoch: 5| Step: 6
Training loss: 0.8404535055160522
Validation loss: 1.6832657142352032

Epoch: 5| Step: 7
Training loss: 0.32346463203430176
Validation loss: 1.6581434075550368

Epoch: 5| Step: 8
Training loss: 0.24811632931232452
Validation loss: 1.670134336717667

Epoch: 5| Step: 9
Training loss: 0.4359816908836365
Validation loss: 1.627922397787853

Epoch: 5| Step: 10
Training loss: 0.4130726456642151
Validation loss: 1.6655095238839426

Epoch: 278| Step: 0
Training loss: 0.2599692940711975
Validation loss: 1.6662873939801288

Epoch: 5| Step: 1
Training loss: 0.29897117614746094
Validation loss: 1.6793651426992109

Epoch: 5| Step: 2
Training loss: 0.19234631955623627
Validation loss: 1.6687013141570552

Epoch: 5| Step: 3
Training loss: 0.4473331868648529
Validation loss: 1.6572033089976157

Epoch: 5| Step: 4
Training loss: 0.36395063996315
Validation loss: 1.6650286771917855

Epoch: 5| Step: 5
Training loss: 0.3147340416908264
Validation loss: 1.6769600363187893

Epoch: 5| Step: 6
Training loss: 0.5030468106269836
Validation loss: 1.6807192615283433

Epoch: 5| Step: 7
Training loss: 0.33071041107177734
Validation loss: 1.6721811486828713

Epoch: 5| Step: 8
Training loss: 0.22183051705360413
Validation loss: 1.6623856495785456

Epoch: 5| Step: 9
Training loss: 0.6045074462890625
Validation loss: 1.6625009454706663

Epoch: 5| Step: 10
Training loss: 0.17249368131160736
Validation loss: 1.674248759464551

Epoch: 279| Step: 0
Training loss: 0.213021919131279
Validation loss: 1.6698014684902724

Epoch: 5| Step: 1
Training loss: 0.3271135687828064
Validation loss: 1.6947373908053163

Epoch: 5| Step: 2
Training loss: 0.2168637216091156
Validation loss: 1.6921110601835354

Epoch: 5| Step: 3
Training loss: 0.24521103501319885
Validation loss: 1.682928640355346

Epoch: 5| Step: 4
Training loss: 0.3382117748260498
Validation loss: 1.7144746613758866

Epoch: 5| Step: 5
Training loss: 0.7371799349784851
Validation loss: 1.681886189727373

Epoch: 5| Step: 6
Training loss: 0.4216514229774475
Validation loss: 1.7459623454719462

Epoch: 5| Step: 7
Training loss: 0.52137291431427
Validation loss: 1.7462075525714504

Epoch: 5| Step: 8
Training loss: 0.4160972535610199
Validation loss: 1.7303969667803856

Epoch: 5| Step: 9
Training loss: 0.22374308109283447
Validation loss: 1.7462200785195956

Epoch: 5| Step: 10
Training loss: 0.171883687376976
Validation loss: 1.7337213934108775

Epoch: 280| Step: 0
Training loss: 0.2689184546470642
Validation loss: 1.7259695568392355

Epoch: 5| Step: 1
Training loss: 0.3625703454017639
Validation loss: 1.6942767981559999

Epoch: 5| Step: 2
Training loss: 0.15346001088619232
Validation loss: 1.6911924192982335

Epoch: 5| Step: 3
Training loss: 0.40516266226768494
Validation loss: 1.6509689797637284

Epoch: 5| Step: 4
Training loss: 0.4608437418937683
Validation loss: 1.694894439430647

Epoch: 5| Step: 5
Training loss: 0.4536672532558441
Validation loss: 1.6726956444401895

Epoch: 5| Step: 6
Training loss: 0.4141014516353607
Validation loss: 1.6598201144126155

Epoch: 5| Step: 7
Training loss: 0.35271209478378296
Validation loss: 1.6794010016226

Epoch: 5| Step: 8
Training loss: 0.19905324280261993
Validation loss: 1.6787543988996936

Epoch: 5| Step: 9
Training loss: 0.24283751845359802
Validation loss: 1.6471886737372285

Epoch: 5| Step: 10
Training loss: 0.37222588062286377
Validation loss: 1.677419380475116

Epoch: 281| Step: 0
Training loss: 0.26398223638534546
Validation loss: 1.670588590765512

Epoch: 5| Step: 1
Training loss: 0.34423670172691345
Validation loss: 1.6778164832822737

Epoch: 5| Step: 2
Training loss: 0.426973819732666
Validation loss: 1.6478619601136895

Epoch: 5| Step: 3
Training loss: 0.5396576523780823
Validation loss: 1.6871050903874059

Epoch: 5| Step: 4
Training loss: 0.3014470636844635
Validation loss: 1.671485480441842

Epoch: 5| Step: 5
Training loss: 0.32018598914146423
Validation loss: 1.653271993001302

Epoch: 5| Step: 6
Training loss: 0.3898163437843323
Validation loss: 1.6394756686302923

Epoch: 5| Step: 7
Training loss: 0.1515149176120758
Validation loss: 1.679930586968699

Epoch: 5| Step: 8
Training loss: 0.6060270071029663
Validation loss: 1.6944953523656374

Epoch: 5| Step: 9
Training loss: 0.25325044989585876
Validation loss: 1.7231415112813313

Epoch: 5| Step: 10
Training loss: 0.27014559507369995
Validation loss: 1.74442809115174

Epoch: 282| Step: 0
Training loss: 0.23767808079719543
Validation loss: 1.7477550711683048

Epoch: 5| Step: 1
Training loss: 0.3397291302680969
Validation loss: 1.7824974906060003

Epoch: 5| Step: 2
Training loss: 0.7359970808029175
Validation loss: 1.7761023864951184

Epoch: 5| Step: 3
Training loss: 0.30578213930130005
Validation loss: 1.7388772349203787

Epoch: 5| Step: 4
Training loss: 0.3684503436088562
Validation loss: 1.7592759670749787

Epoch: 5| Step: 5
Training loss: 0.2744816541671753
Validation loss: 1.7242239098395071

Epoch: 5| Step: 6
Training loss: 0.3136877715587616
Validation loss: 1.7025823144502537

Epoch: 5| Step: 7
Training loss: 0.25494450330734253
Validation loss: 1.6461998531895299

Epoch: 5| Step: 8
Training loss: 0.2724187970161438
Validation loss: 1.6231475107131466

Epoch: 5| Step: 9
Training loss: 0.20454876124858856
Validation loss: 1.589307431251772

Epoch: 5| Step: 10
Training loss: 0.4142628014087677
Validation loss: 1.6084364018132609

Epoch: 283| Step: 0
Training loss: 0.23226454854011536
Validation loss: 1.5741637163264777

Epoch: 5| Step: 1
Training loss: 0.2413262575864792
Validation loss: 1.6573949372896584

Epoch: 5| Step: 2
Training loss: 0.3129190504550934
Validation loss: 1.6850726373734013

Epoch: 5| Step: 3
Training loss: 0.2947062849998474
Validation loss: 1.7201561094612203

Epoch: 5| Step: 4
Training loss: 0.696388840675354
Validation loss: 1.727315423309162

Epoch: 5| Step: 5
Training loss: 0.42431268095970154
Validation loss: 1.7270156093823013

Epoch: 5| Step: 6
Training loss: 0.14340753853321075
Validation loss: 1.7527340663376676

Epoch: 5| Step: 7
Training loss: 0.32392412424087524
Validation loss: 1.7271674858626498

Epoch: 5| Step: 8
Training loss: 0.25425833463668823
Validation loss: 1.741945356451055

Epoch: 5| Step: 9
Training loss: 0.4277063310146332
Validation loss: 1.7280548746867845

Epoch: 5| Step: 10
Training loss: 0.46327319741249084
Validation loss: 1.7264407706517044

Epoch: 284| Step: 0
Training loss: 0.4213849604129791
Validation loss: 1.7355056501203967

Epoch: 5| Step: 1
Training loss: 0.2916969358921051
Validation loss: 1.680260786446192

Epoch: 5| Step: 2
Training loss: 0.32781946659088135
Validation loss: 1.6488258325925438

Epoch: 5| Step: 3
Training loss: 0.4267197251319885
Validation loss: 1.6945280695474276

Epoch: 5| Step: 4
Training loss: 0.41196733713150024
Validation loss: 1.7193846753848496

Epoch: 5| Step: 5
Training loss: 0.3816063702106476
Validation loss: 1.70727192201922

Epoch: 5| Step: 6
Training loss: 0.22977976500988007
Validation loss: 1.692486091967552

Epoch: 5| Step: 7
Training loss: 0.4489881098270416
Validation loss: 1.697447936381063

Epoch: 5| Step: 8
Training loss: 0.2710087299346924
Validation loss: 1.68410248397499

Epoch: 5| Step: 9
Training loss: 0.27634671330451965
Validation loss: 1.6661034944236919

Epoch: 5| Step: 10
Training loss: 0.3004385530948639
Validation loss: 1.6615074001332766

Epoch: 285| Step: 0
Training loss: 0.1698598712682724
Validation loss: 1.6931610389422345

Epoch: 5| Step: 1
Training loss: 0.27105259895324707
Validation loss: 1.6837420976290138

Epoch: 5| Step: 2
Training loss: 0.28700992465019226
Validation loss: 1.732856713315492

Epoch: 5| Step: 3
Training loss: 0.5088791847229004
Validation loss: 1.7241790166465185

Epoch: 5| Step: 4
Training loss: 0.45912250876426697
Validation loss: 1.6839195528338033

Epoch: 5| Step: 5
Training loss: 0.18857236206531525
Validation loss: 1.7076492771025626

Epoch: 5| Step: 6
Training loss: 0.30691584944725037
Validation loss: 1.7029900422660254

Epoch: 5| Step: 7
Training loss: 0.3693506717681885
Validation loss: 1.6801624823642034

Epoch: 5| Step: 8
Training loss: 0.48055094480514526
Validation loss: 1.6784478707980084

Epoch: 5| Step: 9
Training loss: 0.23623566329479218
Validation loss: 1.6367014082529212

Epoch: 5| Step: 10
Training loss: 0.19638344645500183
Validation loss: 1.6601384749976538

Epoch: 286| Step: 0
Training loss: 0.27005115151405334
Validation loss: 1.6634675482267975

Epoch: 5| Step: 1
Training loss: 0.3387925624847412
Validation loss: 1.6757106037550076

Epoch: 5| Step: 2
Training loss: 0.2309531420469284
Validation loss: 1.7186405004993561

Epoch: 5| Step: 3
Training loss: 0.46981382369995117
Validation loss: 1.7075924655442596

Epoch: 5| Step: 4
Training loss: 0.5219091176986694
Validation loss: 1.7463595995339014

Epoch: 5| Step: 5
Training loss: 0.22538602352142334
Validation loss: 1.7399747538310226

Epoch: 5| Step: 6
Training loss: 0.32036370038986206
Validation loss: 1.7048082197866132

Epoch: 5| Step: 7
Training loss: 0.26142263412475586
Validation loss: 1.7401161193847656

Epoch: 5| Step: 8
Training loss: 0.25515007972717285
Validation loss: 1.6962270275239022

Epoch: 5| Step: 9
Training loss: 0.34232255816459656
Validation loss: 1.6299690187618296

Epoch: 5| Step: 10
Training loss: 0.3496410846710205
Validation loss: 1.6143825848897297

Epoch: 287| Step: 0
Training loss: 0.4074782431125641
Validation loss: 1.5977664468108967

Epoch: 5| Step: 1
Training loss: 0.3671987056732178
Validation loss: 1.577149461674434

Epoch: 5| Step: 2
Training loss: 0.28284820914268494
Validation loss: 1.5487498467968357

Epoch: 5| Step: 3
Training loss: 0.5489190220832825
Validation loss: 1.6028794973127303

Epoch: 5| Step: 4
Training loss: 0.3194117844104767
Validation loss: 1.585628322375718

Epoch: 5| Step: 5
Training loss: 0.2512912452220917
Validation loss: 1.5950016667765956

Epoch: 5| Step: 6
Training loss: 0.3005601763725281
Validation loss: 1.6071100337530977

Epoch: 5| Step: 7
Training loss: 0.506324291229248
Validation loss: 1.6370724965167303

Epoch: 5| Step: 8
Training loss: 0.34405428171157837
Validation loss: 1.6565709255074943

Epoch: 5| Step: 9
Training loss: 0.2442198544740677
Validation loss: 1.6778675715128581

Epoch: 5| Step: 10
Training loss: 0.3470388948917389
Validation loss: 1.717391070499215

Epoch: 288| Step: 0
Training loss: 0.24743039906024933
Validation loss: 1.7708301416007421

Epoch: 5| Step: 1
Training loss: 0.4356667995452881
Validation loss: 1.7453482715032433

Epoch: 5| Step: 2
Training loss: 0.3948824405670166
Validation loss: 1.753806274424317

Epoch: 5| Step: 3
Training loss: 0.32018569111824036
Validation loss: 1.723241356111342

Epoch: 5| Step: 4
Training loss: 0.3021017909049988
Validation loss: 1.7227260040980514

Epoch: 5| Step: 5
Training loss: 0.33156245946884155
Validation loss: 1.6792800785392843

Epoch: 5| Step: 6
Training loss: 0.40894848108291626
Validation loss: 1.6335331598917644

Epoch: 5| Step: 7
Training loss: 0.3270226716995239
Validation loss: 1.6315549317226614

Epoch: 5| Step: 8
Training loss: 0.21022868156433105
Validation loss: 1.6031843603298228

Epoch: 5| Step: 9
Training loss: 0.4090229570865631
Validation loss: 1.5987461241342689

Epoch: 5| Step: 10
Training loss: 0.42053306102752686
Validation loss: 1.6104563102927258

Epoch: 289| Step: 0
Training loss: 0.4948089122772217
Validation loss: 1.645056639948199

Epoch: 5| Step: 1
Training loss: 0.1695270985364914
Validation loss: 1.6347653724813973

Epoch: 5| Step: 2
Training loss: 0.2718047499656677
Validation loss: 1.6525475953214912

Epoch: 5| Step: 3
Training loss: 0.21134519577026367
Validation loss: 1.6858892210068241

Epoch: 5| Step: 4
Training loss: 0.30039313435554504
Validation loss: 1.7040278142498386

Epoch: 5| Step: 5
Training loss: 0.19878990948200226
Validation loss: 1.6819490335320915

Epoch: 5| Step: 6
Training loss: 0.23227444291114807
Validation loss: 1.675737798854869

Epoch: 5| Step: 7
Training loss: 0.35493263602256775
Validation loss: 1.674059703785886

Epoch: 5| Step: 8
Training loss: 0.4272688031196594
Validation loss: 1.6758606446686612

Epoch: 5| Step: 9
Training loss: 0.31508052349090576
Validation loss: 1.6717970243064306

Epoch: 5| Step: 10
Training loss: 0.23002977669239044
Validation loss: 1.694394539761287

Epoch: 290| Step: 0
Training loss: 0.2741522192955017
Validation loss: 1.657621806667697

Epoch: 5| Step: 1
Training loss: 0.31238335371017456
Validation loss: 1.6648319267457532

Epoch: 5| Step: 2
Training loss: 0.21231190860271454
Validation loss: 1.6372348531599967

Epoch: 5| Step: 3
Training loss: 0.41528740525245667
Validation loss: 1.6530106324021534

Epoch: 5| Step: 4
Training loss: 0.4012547433376312
Validation loss: 1.6107394695281982

Epoch: 5| Step: 5
Training loss: 0.3148757517337799
Validation loss: 1.6508086016101222

Epoch: 5| Step: 6
Training loss: 0.5561016201972961
Validation loss: 1.651927173778575

Epoch: 5| Step: 7
Training loss: 0.20256328582763672
Validation loss: 1.6715325424748082

Epoch: 5| Step: 8
Training loss: 0.22540831565856934
Validation loss: 1.6684923697543401

Epoch: 5| Step: 9
Training loss: 0.2866021990776062
Validation loss: 1.6531424291672245

Epoch: 5| Step: 10
Training loss: 0.16431653499603271
Validation loss: 1.6073512877187421

Epoch: 291| Step: 0
Training loss: 0.30182838439941406
Validation loss: 1.5868530632347189

Epoch: 5| Step: 1
Training loss: 0.2493515908718109
Validation loss: 1.587009358149703

Epoch: 5| Step: 2
Training loss: 0.19196808338165283
Validation loss: 1.574435317388145

Epoch: 5| Step: 3
Training loss: 0.30868738889694214
Validation loss: 1.5620452691149969

Epoch: 5| Step: 4
Training loss: 0.27940040826797485
Validation loss: 1.5953318572813464

Epoch: 5| Step: 5
Training loss: 0.5033702254295349
Validation loss: 1.64851007282093

Epoch: 5| Step: 6
Training loss: 0.3563063144683838
Validation loss: 1.6727432512467908

Epoch: 5| Step: 7
Training loss: 0.3352438807487488
Validation loss: 1.7274309345470962

Epoch: 5| Step: 8
Training loss: 0.45453518629074097
Validation loss: 1.709433074920408

Epoch: 5| Step: 9
Training loss: 0.38322994112968445
Validation loss: 1.703900033427823

Epoch: 5| Step: 10
Training loss: 0.348490446805954
Validation loss: 1.7349731896513252

Epoch: 292| Step: 0
Training loss: 0.5719619989395142
Validation loss: 1.7259920643221947

Epoch: 5| Step: 1
Training loss: 0.21744713187217712
Validation loss: 1.740508492274951

Epoch: 5| Step: 2
Training loss: 0.4326527714729309
Validation loss: 1.706152113535071

Epoch: 5| Step: 3
Training loss: 0.2355702668428421
Validation loss: 1.7126878153893255

Epoch: 5| Step: 4
Training loss: 0.4488312304019928
Validation loss: 1.7256203620664534

Epoch: 5| Step: 5
Training loss: 0.32459408044815063
Validation loss: 1.724744228906529

Epoch: 5| Step: 6
Training loss: 0.2751348912715912
Validation loss: 1.7304383042038127

Epoch: 5| Step: 7
Training loss: 0.4604570269584656
Validation loss: 1.72496336249895

Epoch: 5| Step: 8
Training loss: 0.23965556919574738
Validation loss: 1.7019952817629742

Epoch: 5| Step: 9
Training loss: 0.4315250515937805
Validation loss: 1.684154559207219

Epoch: 5| Step: 10
Training loss: 0.3749798834323883
Validation loss: 1.620509236089645

Epoch: 293| Step: 0
Training loss: 0.17342177033424377
Validation loss: 1.5525425685349332

Epoch: 5| Step: 1
Training loss: 0.33550602197647095
Validation loss: 1.5350112479220155

Epoch: 5| Step: 2
Training loss: 0.39691561460494995
Validation loss: 1.5169431586419382

Epoch: 5| Step: 3
Training loss: 0.34077784419059753
Validation loss: 1.5727335893979637

Epoch: 5| Step: 4
Training loss: 0.5599883198738098
Validation loss: 1.581130176462153

Epoch: 5| Step: 5
Training loss: 0.3078250288963318
Validation loss: 1.6134152194505096

Epoch: 5| Step: 6
Training loss: 0.17736105620861053
Validation loss: 1.7198413366912513

Epoch: 5| Step: 7
Training loss: 0.4402409493923187
Validation loss: 1.7347604587513914

Epoch: 5| Step: 8
Training loss: 0.2561822831630707
Validation loss: 1.7305990829262683

Epoch: 5| Step: 9
Training loss: 0.2843887209892273
Validation loss: 1.7544633983283915

Epoch: 5| Step: 10
Training loss: 0.37774574756622314
Validation loss: 1.740522825589744

Epoch: 294| Step: 0
Training loss: 0.3095986247062683
Validation loss: 1.7027408307598484

Epoch: 5| Step: 1
Training loss: 0.24268925189971924
Validation loss: 1.6742448883671914

Epoch: 5| Step: 2
Training loss: 0.25514349341392517
Validation loss: 1.6348001700575634

Epoch: 5| Step: 3
Training loss: 0.29930350184440613
Validation loss: 1.6151021167796145

Epoch: 5| Step: 4
Training loss: 0.45341673493385315
Validation loss: 1.5768998848494662

Epoch: 5| Step: 5
Training loss: 0.4744585454463959
Validation loss: 1.6010417515231716

Epoch: 5| Step: 6
Training loss: 0.30816036462783813
Validation loss: 1.5617163181304932

Epoch: 5| Step: 7
Training loss: 0.1681687831878662
Validation loss: 1.536480413970127

Epoch: 5| Step: 8
Training loss: 0.5152328014373779
Validation loss: 1.592930555343628

Epoch: 5| Step: 9
Training loss: 0.3095676898956299
Validation loss: 1.639357937279568

Epoch: 5| Step: 10
Training loss: 0.23587456345558167
Validation loss: 1.67391671288398

Epoch: 295| Step: 0
Training loss: 0.6398248672485352
Validation loss: 1.6991104913014237

Epoch: 5| Step: 1
Training loss: 0.19059082865715027
Validation loss: 1.7270473972443612

Epoch: 5| Step: 2
Training loss: 0.307822048664093
Validation loss: 1.7167947728146788

Epoch: 5| Step: 3
Training loss: 0.27109259366989136
Validation loss: 1.7118202640164284

Epoch: 5| Step: 4
Training loss: 0.3149084448814392
Validation loss: 1.6821277397935108

Epoch: 5| Step: 5
Training loss: 0.31740549206733704
Validation loss: 1.669125045499494

Epoch: 5| Step: 6
Training loss: 0.23802852630615234
Validation loss: 1.6348157813472133

Epoch: 5| Step: 7
Training loss: 0.23064203560352325
Validation loss: 1.6025050788797357

Epoch: 5| Step: 8
Training loss: 0.339249849319458
Validation loss: 1.6266532880003735

Epoch: 5| Step: 9
Training loss: 0.2942473292350769
Validation loss: 1.6209358323004939

Epoch: 5| Step: 10
Training loss: 0.37144923210144043
Validation loss: 1.6025947652837282

Epoch: 296| Step: 0
Training loss: 0.3296329081058502
Validation loss: 1.6058781441821848

Epoch: 5| Step: 1
Training loss: 0.24062709510326385
Validation loss: 1.614267659443681

Epoch: 5| Step: 2
Training loss: 0.2830045521259308
Validation loss: 1.6593536894808534

Epoch: 5| Step: 3
Training loss: 0.3457602560520172
Validation loss: 1.66035476551261

Epoch: 5| Step: 4
Training loss: 0.2579909861087799
Validation loss: 1.6812863324278144

Epoch: 5| Step: 5
Training loss: 0.3048827648162842
Validation loss: 1.673886800325045

Epoch: 5| Step: 6
Training loss: 0.22419604659080505
Validation loss: 1.6680877054891279

Epoch: 5| Step: 7
Training loss: 0.2568402886390686
Validation loss: 1.6714884068376274

Epoch: 5| Step: 8
Training loss: 0.6224365234375
Validation loss: 1.6626271650355349

Epoch: 5| Step: 9
Training loss: 0.3588780462741852
Validation loss: 1.683698437547171

Epoch: 5| Step: 10
Training loss: 0.2125307023525238
Validation loss: 1.6814123853560416

Epoch: 297| Step: 0
Training loss: 0.2052573412656784
Validation loss: 1.668396362694361

Epoch: 5| Step: 1
Training loss: 0.24523019790649414
Validation loss: 1.6863039219251243

Epoch: 5| Step: 2
Training loss: 0.26665645837783813
Validation loss: 1.6775950808678903

Epoch: 5| Step: 3
Training loss: 0.2554909586906433
Validation loss: 1.6886196751748361

Epoch: 5| Step: 4
Training loss: 0.23145580291748047
Validation loss: 1.6796355619225452

Epoch: 5| Step: 5
Training loss: 0.2547807991504669
Validation loss: 1.6408218004370247

Epoch: 5| Step: 6
Training loss: 0.44872063398361206
Validation loss: 1.6545624899607834

Epoch: 5| Step: 7
Training loss: 0.37121301889419556
Validation loss: 1.6493391208751227

Epoch: 5| Step: 8
Training loss: 0.3148943781852722
Validation loss: 1.6308683733786307

Epoch: 5| Step: 9
Training loss: 0.4500493109226227
Validation loss: 1.659545018467852

Epoch: 5| Step: 10
Training loss: 0.10768149048089981
Validation loss: 1.6573000159314883

Epoch: 298| Step: 0
Training loss: 0.5499550700187683
Validation loss: 1.6592274199249923

Epoch: 5| Step: 1
Training loss: 0.18529079854488373
Validation loss: 1.699042344606051

Epoch: 5| Step: 2
Training loss: 0.2186998873949051
Validation loss: 1.6992124601077008

Epoch: 5| Step: 3
Training loss: 0.25447869300842285
Validation loss: 1.6732882094639603

Epoch: 5| Step: 4
Training loss: 0.2589750289916992
Validation loss: 1.6912653343651884

Epoch: 5| Step: 5
Training loss: 0.31957438588142395
Validation loss: 1.6683951077922698

Epoch: 5| Step: 6
Training loss: 0.28150278329849243
Validation loss: 1.5898000681272118

Epoch: 5| Step: 7
Training loss: 0.2280568778514862
Validation loss: 1.6201187987481394

Epoch: 5| Step: 8
Training loss: 0.286916583776474
Validation loss: 1.6385517299816172

Epoch: 5| Step: 9
Training loss: 0.2814939618110657
Validation loss: 1.5998095299607964

Epoch: 5| Step: 10
Training loss: 0.2513130307197571
Validation loss: 1.6001995712198236

Epoch: 299| Step: 0
Training loss: 0.20677080750465393
Validation loss: 1.5964424943411222

Epoch: 5| Step: 1
Training loss: 0.3729862570762634
Validation loss: 1.6066347783611667

Epoch: 5| Step: 2
Training loss: 0.25034794211387634
Validation loss: 1.5914392637950119

Epoch: 5| Step: 3
Training loss: 0.5114564895629883
Validation loss: 1.610183006973677

Epoch: 5| Step: 4
Training loss: 0.2302428036928177
Validation loss: 1.6120848463427635

Epoch: 5| Step: 5
Training loss: 0.26263564825057983
Validation loss: 1.622082983293841

Epoch: 5| Step: 6
Training loss: 0.31828272342681885
Validation loss: 1.6613118751074678

Epoch: 5| Step: 7
Training loss: 0.3888106346130371
Validation loss: 1.6982728973511727

Epoch: 5| Step: 8
Training loss: 0.26439112424850464
Validation loss: 1.7026966079588859

Epoch: 5| Step: 9
Training loss: 0.20140421390533447
Validation loss: 1.7433718199371009

Epoch: 5| Step: 10
Training loss: 0.2615582048892975
Validation loss: 1.7792639873361076

Epoch: 300| Step: 0
Training loss: 0.2913529872894287
Validation loss: 1.803980569685659

Epoch: 5| Step: 1
Training loss: 0.2141832858324051
Validation loss: 1.827084151647424

Epoch: 5| Step: 2
Training loss: 0.3440622091293335
Validation loss: 1.7365173344971032

Epoch: 5| Step: 3
Training loss: 0.23003920912742615
Validation loss: 1.7032388615351852

Epoch: 5| Step: 4
Training loss: 0.2706029713153839
Validation loss: 1.6643503968433668

Epoch: 5| Step: 5
Training loss: 0.22924962639808655
Validation loss: 1.6296556893215384

Epoch: 5| Step: 6
Training loss: 0.26156917214393616
Validation loss: 1.6263216362204602

Epoch: 5| Step: 7
Training loss: 0.49018460512161255
Validation loss: 1.5929769764664352

Epoch: 5| Step: 8
Training loss: 0.2976759076118469
Validation loss: 1.6088190206917383

Epoch: 5| Step: 9
Training loss: 0.18079937994480133
Validation loss: 1.5849427894879413

Epoch: 5| Step: 10
Training loss: 0.5221972465515137
Validation loss: 1.6125850562126405

Epoch: 301| Step: 0
Training loss: 0.29178228974342346
Validation loss: 1.6161889991452616

Epoch: 5| Step: 1
Training loss: 0.23713275790214539
Validation loss: 1.6178877404941026

Epoch: 5| Step: 2
Training loss: 0.3498561978340149
Validation loss: 1.6395329736894177

Epoch: 5| Step: 3
Training loss: 0.18879950046539307
Validation loss: 1.6615065643864293

Epoch: 5| Step: 4
Training loss: 0.22387833893299103
Validation loss: 1.6450769209092664

Epoch: 5| Step: 5
Training loss: 0.2951590120792389
Validation loss: 1.6341261850890292

Epoch: 5| Step: 6
Training loss: 0.21421441435813904
Validation loss: 1.6489090342675485

Epoch: 5| Step: 7
Training loss: 0.2247563898563385
Validation loss: 1.6605518582046672

Epoch: 5| Step: 8
Training loss: 0.4891842305660248
Validation loss: 1.6471293639111262

Epoch: 5| Step: 9
Training loss: 0.3096024692058563
Validation loss: 1.665050793719548

Epoch: 5| Step: 10
Training loss: 0.31549549102783203
Validation loss: 1.6387518144422961

Epoch: 302| Step: 0
Training loss: 0.23184219002723694
Validation loss: 1.6297162489224506

Epoch: 5| Step: 1
Training loss: 0.30106934905052185
Validation loss: 1.621306961582553

Epoch: 5| Step: 2
Training loss: 0.2773229479789734
Validation loss: 1.6589383694433397

Epoch: 5| Step: 3
Training loss: 0.4209989011287689
Validation loss: 1.633747003411734

Epoch: 5| Step: 4
Training loss: 0.18229636549949646
Validation loss: 1.6306697886477235

Epoch: 5| Step: 5
Training loss: 0.24845273792743683
Validation loss: 1.6362026968309957

Epoch: 5| Step: 6
Training loss: 0.3697900176048279
Validation loss: 1.6326395991027995

Epoch: 5| Step: 7
Training loss: 0.25747066736221313
Validation loss: 1.671042916595295

Epoch: 5| Step: 8
Training loss: 0.2935141623020172
Validation loss: 1.6379285999523696

Epoch: 5| Step: 9
Training loss: 0.2888084053993225
Validation loss: 1.6892719704617736

Epoch: 5| Step: 10
Training loss: 0.2629249095916748
Validation loss: 1.7236974367531397

Epoch: 303| Step: 0
Training loss: 0.18222004175186157
Validation loss: 1.717513096588914

Epoch: 5| Step: 1
Training loss: 0.22398777306079865
Validation loss: 1.751814701223886

Epoch: 5| Step: 2
Training loss: 0.35070210695266724
Validation loss: 1.7118927689008816

Epoch: 5| Step: 3
Training loss: 0.2948245406150818
Validation loss: 1.6908962034410047

Epoch: 5| Step: 4
Training loss: 0.09646140038967133
Validation loss: 1.6462261728061143

Epoch: 5| Step: 5
Training loss: 0.2990357279777527
Validation loss: 1.6187390563308552

Epoch: 5| Step: 6
Training loss: 0.5112096667289734
Validation loss: 1.5893322383203814

Epoch: 5| Step: 7
Training loss: 0.24157056212425232
Validation loss: 1.6016438891810756

Epoch: 5| Step: 8
Training loss: 0.30332550406455994
Validation loss: 1.5859187431232904

Epoch: 5| Step: 9
Training loss: 0.3835001587867737
Validation loss: 1.5571496166208738

Epoch: 5| Step: 10
Training loss: 0.3459935486316681
Validation loss: 1.587021214987642

Epoch: 304| Step: 0
Training loss: 0.3808395266532898
Validation loss: 1.5973841631284325

Epoch: 5| Step: 1
Training loss: 0.21086308360099792
Validation loss: 1.604478559827292

Epoch: 5| Step: 2
Training loss: 0.32072561979293823
Validation loss: 1.631023181382046

Epoch: 5| Step: 3
Training loss: 0.25261634588241577
Validation loss: 1.6501595333058348

Epoch: 5| Step: 4
Training loss: 0.32391437888145447
Validation loss: 1.6861171453229842

Epoch: 5| Step: 5
Training loss: 0.2820529639720917
Validation loss: 1.686054314336469

Epoch: 5| Step: 6
Training loss: 0.24826569855213165
Validation loss: 1.6922285146610712

Epoch: 5| Step: 7
Training loss: 0.23279500007629395
Validation loss: 1.670604012345755

Epoch: 5| Step: 8
Training loss: 0.40555447340011597
Validation loss: 1.669549319051927

Epoch: 5| Step: 9
Training loss: 0.26172202825546265
Validation loss: 1.613808907488341

Epoch: 5| Step: 10
Training loss: 0.11974181979894638
Validation loss: 1.5957203360014065

Epoch: 305| Step: 0
Training loss: 0.22724103927612305
Validation loss: 1.614549688113633

Epoch: 5| Step: 1
Training loss: 0.3441823124885559
Validation loss: 1.6102712128752021

Epoch: 5| Step: 2
Training loss: 0.23960471153259277
Validation loss: 1.6112890397348711

Epoch: 5| Step: 3
Training loss: 0.2511579692363739
Validation loss: 1.5939160623858053

Epoch: 5| Step: 4
Training loss: 0.2613370716571808
Validation loss: 1.6082539737865489

Epoch: 5| Step: 5
Training loss: 0.24800226092338562
Validation loss: 1.6413583114583006

Epoch: 5| Step: 6
Training loss: 0.2501112222671509
Validation loss: 1.6059983673916067

Epoch: 5| Step: 7
Training loss: 0.2477196753025055
Validation loss: 1.6097130435769276

Epoch: 5| Step: 8
Training loss: 0.22822389006614685
Validation loss: 1.5874568339317077

Epoch: 5| Step: 9
Training loss: 0.24376177787780762
Validation loss: 1.5935242124783096

Epoch: 5| Step: 10
Training loss: 0.4744076430797577
Validation loss: 1.613910880140079

Epoch: 306| Step: 0
Training loss: 0.21540942788124084
Validation loss: 1.6398165713074386

Epoch: 5| Step: 1
Training loss: 0.1814713180065155
Validation loss: 1.6045746623828847

Epoch: 5| Step: 2
Training loss: 0.2277645766735077
Validation loss: 1.6123847115424372

Epoch: 5| Step: 3
Training loss: 0.23169967532157898
Validation loss: 1.5936429295488583

Epoch: 5| Step: 4
Training loss: 0.313093364238739
Validation loss: 1.6204964076319048

Epoch: 5| Step: 5
Training loss: 0.3311169147491455
Validation loss: 1.6159206333980765

Epoch: 5| Step: 6
Training loss: 0.508397102355957
Validation loss: 1.6463031704707811

Epoch: 5| Step: 7
Training loss: 0.24228596687316895
Validation loss: 1.6803277769396383

Epoch: 5| Step: 8
Training loss: 0.4091404974460602
Validation loss: 1.681850210312874

Epoch: 5| Step: 9
Training loss: 0.22241108119487762
Validation loss: 1.638516656814083

Epoch: 5| Step: 10
Training loss: 0.22193829715251923
Validation loss: 1.6497075044980614

Epoch: 307| Step: 0
Training loss: 0.25982892513275146
Validation loss: 1.6197186721268522

Epoch: 5| Step: 1
Training loss: 0.21114256978034973
Validation loss: 1.613526366090262

Epoch: 5| Step: 2
Training loss: 0.3208716809749603
Validation loss: 1.6155917734228156

Epoch: 5| Step: 3
Training loss: 0.24040766060352325
Validation loss: 1.634206876959852

Epoch: 5| Step: 4
Training loss: 0.3377918601036072
Validation loss: 1.6470713589781074

Epoch: 5| Step: 5
Training loss: 0.37571173906326294
Validation loss: 1.6557089449256979

Epoch: 5| Step: 6
Training loss: 0.21927404403686523
Validation loss: 1.6766654419642624

Epoch: 5| Step: 7
Training loss: 0.37033551931381226
Validation loss: 1.6594561620425152

Epoch: 5| Step: 8
Training loss: 0.43948954343795776
Validation loss: 1.6734151494118474

Epoch: 5| Step: 9
Training loss: 0.24508428573608398
Validation loss: 1.688554326693217

Epoch: 5| Step: 10
Training loss: 0.15699341893196106
Validation loss: 1.648215393866262

Epoch: 308| Step: 0
Training loss: 0.22679026424884796
Validation loss: 1.614232454248654

Epoch: 5| Step: 1
Training loss: 0.2166612595319748
Validation loss: 1.6145334487320275

Epoch: 5| Step: 2
Training loss: 0.3107569217681885
Validation loss: 1.583445805375294

Epoch: 5| Step: 3
Training loss: 0.23231594264507294
Validation loss: 1.6075985880308254

Epoch: 5| Step: 4
Training loss: 0.23905333876609802
Validation loss: 1.6001498096732683

Epoch: 5| Step: 5
Training loss: 0.3469438850879669
Validation loss: 1.614987281060988

Epoch: 5| Step: 6
Training loss: 0.2625226080417633
Validation loss: 1.5958767616620628

Epoch: 5| Step: 7
Training loss: 0.47451287508010864
Validation loss: 1.6230223012226883

Epoch: 5| Step: 8
Training loss: 0.3083855211734772
Validation loss: 1.62148997476024

Epoch: 5| Step: 9
Training loss: 0.29650458693504333
Validation loss: 1.6010871471897248

Epoch: 5| Step: 10
Training loss: 0.2019711285829544
Validation loss: 1.6185387078151907

Epoch: 309| Step: 0
Training loss: 0.17548206448554993
Validation loss: 1.640086075311066

Epoch: 5| Step: 1
Training loss: 0.18283988535404205
Validation loss: 1.619779573973789

Epoch: 5| Step: 2
Training loss: 0.2700732946395874
Validation loss: 1.6134406699929187

Epoch: 5| Step: 3
Training loss: 0.20615443587303162
Validation loss: 1.6472254427530433

Epoch: 5| Step: 4
Training loss: 0.3048192262649536
Validation loss: 1.6482443963327715

Epoch: 5| Step: 5
Training loss: 0.31029218435287476
Validation loss: 1.6105122412404707

Epoch: 5| Step: 6
Training loss: 0.22417178750038147
Validation loss: 1.60349856140793

Epoch: 5| Step: 7
Training loss: 0.41756314039230347
Validation loss: 1.5632243720434045

Epoch: 5| Step: 8
Training loss: 0.3034358322620392
Validation loss: 1.5635191407254947

Epoch: 5| Step: 9
Training loss: 0.1238768920302391
Validation loss: 1.5536495408704203

Epoch: 5| Step: 10
Training loss: 0.39625105261802673
Validation loss: 1.5755708922622025

Epoch: 310| Step: 0
Training loss: 0.29582342505455017
Validation loss: 1.573820899891597

Epoch: 5| Step: 1
Training loss: 0.2149936705827713
Validation loss: 1.5925900756671865

Epoch: 5| Step: 2
Training loss: 0.21703609824180603
Validation loss: 1.5777246990511495

Epoch: 5| Step: 3
Training loss: 0.39516764879226685
Validation loss: 1.6132994172393635

Epoch: 5| Step: 4
Training loss: 0.28466805815696716
Validation loss: 1.617203693236074

Epoch: 5| Step: 5
Training loss: 0.4995804727077484
Validation loss: 1.608552969271137

Epoch: 5| Step: 6
Training loss: 0.3009338080883026
Validation loss: 1.6162404411582536

Epoch: 5| Step: 7
Training loss: 0.21564018726348877
Validation loss: 1.6024476597386021

Epoch: 5| Step: 8
Training loss: 0.15993472933769226
Validation loss: 1.627509496545279

Epoch: 5| Step: 9
Training loss: 0.29318228363990784
Validation loss: 1.6403709983312955

Epoch: 5| Step: 10
Training loss: 0.1625489741563797
Validation loss: 1.652703328799176

Epoch: 311| Step: 0
Training loss: 0.2782088816165924
Validation loss: 1.6318539791209723

Epoch: 5| Step: 1
Training loss: 0.1716223657131195
Validation loss: 1.6207782376197077

Epoch: 5| Step: 2
Training loss: 0.19708342850208282
Validation loss: 1.6336210466200305

Epoch: 5| Step: 3
Training loss: 0.2306484431028366
Validation loss: 1.5758274203987532

Epoch: 5| Step: 4
Training loss: 0.13536645472049713
Validation loss: 1.5703800711580502

Epoch: 5| Step: 5
Training loss: 0.26496976613998413
Validation loss: 1.5319284956942323

Epoch: 5| Step: 6
Training loss: 0.3130285143852234
Validation loss: 1.5227376953248055

Epoch: 5| Step: 7
Training loss: 0.20250916481018066
Validation loss: 1.4925524778263544

Epoch: 5| Step: 8
Training loss: 0.2551930248737335
Validation loss: 1.5544099794921054

Epoch: 5| Step: 9
Training loss: 0.34848707914352417
Validation loss: 1.560851735453452

Epoch: 5| Step: 10
Training loss: 0.44991543889045715
Validation loss: 1.566938200304585

Epoch: 312| Step: 0
Training loss: 0.181413933634758
Validation loss: 1.580257414489664

Epoch: 5| Step: 1
Training loss: 0.37487679719924927
Validation loss: 1.6053302236782607

Epoch: 5| Step: 2
Training loss: 0.34450727701187134
Validation loss: 1.626347198281237

Epoch: 5| Step: 3
Training loss: 0.31388458609580994
Validation loss: 1.6557675228323987

Epoch: 5| Step: 4
Training loss: 0.169939324259758
Validation loss: 1.6683590386503486

Epoch: 5| Step: 5
Training loss: 0.33218565583229065
Validation loss: 1.644807433569303

Epoch: 5| Step: 6
Training loss: 0.22764889895915985
Validation loss: 1.675299914934302

Epoch: 5| Step: 7
Training loss: 0.29806146025657654
Validation loss: 1.634135151422152

Epoch: 5| Step: 8
Training loss: 0.21566839516162872
Validation loss: 1.6074131035035657

Epoch: 5| Step: 9
Training loss: 0.2925184369087219
Validation loss: 1.5733167612424461

Epoch: 5| Step: 10
Training loss: 0.07744306325912476
Validation loss: 1.5969583014006257

Epoch: 313| Step: 0
Training loss: 0.3145199418067932
Validation loss: 1.5554608401431833

Epoch: 5| Step: 1
Training loss: 0.15181660652160645
Validation loss: 1.5435603049493605

Epoch: 5| Step: 2
Training loss: 0.2376432865858078
Validation loss: 1.574792447910514

Epoch: 5| Step: 3
Training loss: 0.15982761979103088
Validation loss: 1.588750090650333

Epoch: 5| Step: 4
Training loss: 0.20811672508716583
Validation loss: 1.5737956698222826

Epoch: 5| Step: 5
Training loss: 0.32437190413475037
Validation loss: 1.6292392028275358

Epoch: 5| Step: 6
Training loss: 0.3455560505390167
Validation loss: 1.5895868488537368

Epoch: 5| Step: 7
Training loss: 0.24559327960014343
Validation loss: 1.626821489744289

Epoch: 5| Step: 8
Training loss: 0.20940537750720978
Validation loss: 1.6643851816013295

Epoch: 5| Step: 9
Training loss: 0.3238777220249176
Validation loss: 1.64629578334029

Epoch: 5| Step: 10
Training loss: 0.37071579694747925
Validation loss: 1.6592588296500586

Epoch: 314| Step: 0
Training loss: 0.283223032951355
Validation loss: 1.6476978999312206

Epoch: 5| Step: 1
Training loss: 0.1986701339483261
Validation loss: 1.6509689464364001

Epoch: 5| Step: 2
Training loss: 0.17997165024280548
Validation loss: 1.6249261953497445

Epoch: 5| Step: 3
Training loss: 0.19211189448833466
Validation loss: 1.6187210672645158

Epoch: 5| Step: 4
Training loss: 0.3116097152233124
Validation loss: 1.613455262235416

Epoch: 5| Step: 5
Training loss: 0.1749192476272583
Validation loss: 1.6045108200401388

Epoch: 5| Step: 6
Training loss: 0.33043164014816284
Validation loss: 1.5766660872326101

Epoch: 5| Step: 7
Training loss: 0.2935449481010437
Validation loss: 1.574370950780889

Epoch: 5| Step: 8
Training loss: 0.4909757971763611
Validation loss: 1.5576128985292168

Epoch: 5| Step: 9
Training loss: 0.3024190366268158
Validation loss: 1.5730168947609522

Epoch: 5| Step: 10
Training loss: 0.09606657922267914
Validation loss: 1.5812011123985372

Epoch: 315| Step: 0
Training loss: 0.16180342435836792
Validation loss: 1.6089373916708014

Epoch: 5| Step: 1
Training loss: 0.3361029028892517
Validation loss: 1.5940330054170342

Epoch: 5| Step: 2
Training loss: 0.2746804654598236
Validation loss: 1.639248990243481

Epoch: 5| Step: 3
Training loss: 0.44539347290992737
Validation loss: 1.6136678982806463

Epoch: 5| Step: 4
Training loss: 0.25283804535865784
Validation loss: 1.613106123862728

Epoch: 5| Step: 5
Training loss: 0.23036551475524902
Validation loss: 1.6536154747009277

Epoch: 5| Step: 6
Training loss: 0.23856143653392792
Validation loss: 1.6500051611213273

Epoch: 5| Step: 7
Training loss: 0.29609444737434387
Validation loss: 1.6528094571123841

Epoch: 5| Step: 8
Training loss: 0.32157647609710693
Validation loss: 1.609271578891303

Epoch: 5| Step: 9
Training loss: 0.23179133236408234
Validation loss: 1.575275997961721

Epoch: 5| Step: 10
Training loss: 0.21406924724578857
Validation loss: 1.5384194210011473

Epoch: 316| Step: 0
Training loss: 0.2917422652244568
Validation loss: 1.5096192757288616

Epoch: 5| Step: 1
Training loss: 0.30605778098106384
Validation loss: 1.5249114754379436

Epoch: 5| Step: 2
Training loss: 0.4001932740211487
Validation loss: 1.5178099274635315

Epoch: 5| Step: 3
Training loss: 0.18703456223011017
Validation loss: 1.5156752794019637

Epoch: 5| Step: 4
Training loss: 0.16878435015678406
Validation loss: 1.5355215892996839

Epoch: 5| Step: 5
Training loss: 0.17448775470256805
Validation loss: 1.5354017967818885

Epoch: 5| Step: 6
Training loss: 0.2388501912355423
Validation loss: 1.5942210766576952

Epoch: 5| Step: 7
Training loss: 0.30336642265319824
Validation loss: 1.633675347092331

Epoch: 5| Step: 8
Training loss: 0.267376571893692
Validation loss: 1.667899049738402

Epoch: 5| Step: 9
Training loss: 0.3154848515987396
Validation loss: 1.658223359815536

Epoch: 5| Step: 10
Training loss: 0.17043079435825348
Validation loss: 1.663964363836473

Epoch: 317| Step: 0
Training loss: 0.1530722677707672
Validation loss: 1.6499633442971013

Epoch: 5| Step: 1
Training loss: 0.23804430663585663
Validation loss: 1.647737221051288

Epoch: 5| Step: 2
Training loss: 0.2436962127685547
Validation loss: 1.6266265684558499

Epoch: 5| Step: 3
Training loss: 0.2154146134853363
Validation loss: 1.6091008045340096

Epoch: 5| Step: 4
Training loss: 0.17435212433338165
Validation loss: 1.6049524141896157

Epoch: 5| Step: 5
Training loss: 0.21781134605407715
Validation loss: 1.6089562190476285

Epoch: 5| Step: 6
Training loss: 0.21315734088420868
Validation loss: 1.6115772544696767

Epoch: 5| Step: 7
Training loss: 0.33537882566452026
Validation loss: 1.5977544605091054

Epoch: 5| Step: 8
Training loss: 0.4788847863674164
Validation loss: 1.6103231573617587

Epoch: 5| Step: 9
Training loss: 0.2882883548736572
Validation loss: 1.597047059766708

Epoch: 5| Step: 10
Training loss: 0.27969592809677124
Validation loss: 1.579007605070709

Epoch: 318| Step: 0
Training loss: 0.22815528512001038
Validation loss: 1.6385632009916409

Epoch: 5| Step: 1
Training loss: 0.18691802024841309
Validation loss: 1.6143877147346415

Epoch: 5| Step: 2
Training loss: 0.2533052861690521
Validation loss: 1.6163076431520524

Epoch: 5| Step: 3
Training loss: 0.25960391759872437
Validation loss: 1.6245000311123428

Epoch: 5| Step: 4
Training loss: 0.22076889872550964
Validation loss: 1.5719380788905646

Epoch: 5| Step: 5
Training loss: 0.1987951248884201
Validation loss: 1.577845584961676

Epoch: 5| Step: 6
Training loss: 0.32692471146583557
Validation loss: 1.5895172190922562

Epoch: 5| Step: 7
Training loss: 0.22488334774971008
Validation loss: 1.5573196590587657

Epoch: 5| Step: 8
Training loss: 0.27862343192100525
Validation loss: 1.551423607334014

Epoch: 5| Step: 9
Training loss: 0.13439753651618958
Validation loss: 1.5458115749461676

Epoch: 5| Step: 10
Training loss: 0.3333624601364136
Validation loss: 1.5550066783864012

Epoch: 319| Step: 0
Training loss: 0.35641446709632874
Validation loss: 1.5717980938573037

Epoch: 5| Step: 1
Training loss: 0.18525227904319763
Validation loss: 1.5562113062027962

Epoch: 5| Step: 2
Training loss: 0.2817046344280243
Validation loss: 1.5588989847449846

Epoch: 5| Step: 3
Training loss: 0.15185746550559998
Validation loss: 1.5642375792226484

Epoch: 5| Step: 4
Training loss: 0.21763639152050018
Validation loss: 1.5788025932927285

Epoch: 5| Step: 5
Training loss: 0.2644333839416504
Validation loss: 1.6274309760780745

Epoch: 5| Step: 6
Training loss: 0.1836501806974411
Validation loss: 1.6180553308097265

Epoch: 5| Step: 7
Training loss: 0.14025893807411194
Validation loss: 1.6174458252486361

Epoch: 5| Step: 8
Training loss: 0.18507078289985657
Validation loss: 1.6212282232058945

Epoch: 5| Step: 9
Training loss: 0.35475966334342957
Validation loss: 1.6386040622188198

Epoch: 5| Step: 10
Training loss: 0.2573833167552948
Validation loss: 1.6478127330862067

Epoch: 320| Step: 0
Training loss: 0.17473441362380981
Validation loss: 1.652048078916406

Epoch: 5| Step: 1
Training loss: 0.287885844707489
Validation loss: 1.63584057746395

Epoch: 5| Step: 2
Training loss: 0.20052547752857208
Validation loss: 1.661279991108884

Epoch: 5| Step: 3
Training loss: 0.25868499279022217
Validation loss: 1.6629498799641926

Epoch: 5| Step: 4
Training loss: 0.21132135391235352
Validation loss: 1.6245739177990985

Epoch: 5| Step: 5
Training loss: 0.33564457297325134
Validation loss: 1.6354588744460896

Epoch: 5| Step: 6
Training loss: 0.21371786296367645
Validation loss: 1.6332356865688036

Epoch: 5| Step: 7
Training loss: 0.23527848720550537
Validation loss: 1.6279040049481135

Epoch: 5| Step: 8
Training loss: 0.29989808797836304
Validation loss: 1.6212539839488205

Epoch: 5| Step: 9
Training loss: 0.2402968406677246
Validation loss: 1.5899309073725054

Epoch: 5| Step: 10
Training loss: 0.2074199914932251
Validation loss: 1.5945374645212644

Epoch: 321| Step: 0
Training loss: 0.28502458333969116
Validation loss: 1.5830050860681841

Epoch: 5| Step: 1
Training loss: 0.20520082116127014
Validation loss: 1.583112644892867

Epoch: 5| Step: 2
Training loss: 0.31127285957336426
Validation loss: 1.594385176576594

Epoch: 5| Step: 3
Training loss: 0.15251906216144562
Validation loss: 1.5678291551528438

Epoch: 5| Step: 4
Training loss: 0.22222478687763214
Validation loss: 1.5987483929562312

Epoch: 5| Step: 5
Training loss: 0.14217069745063782
Validation loss: 1.578969217115833

Epoch: 5| Step: 6
Training loss: 0.24867519736289978
Validation loss: 1.6543664996341994

Epoch: 5| Step: 7
Training loss: 0.3292616903781891
Validation loss: 1.6176840489910496

Epoch: 5| Step: 8
Training loss: 0.3415011167526245
Validation loss: 1.6400730199711298

Epoch: 5| Step: 9
Training loss: 0.25141626596450806
Validation loss: 1.6519728552910589

Epoch: 5| Step: 10
Training loss: 0.15413779020309448
Validation loss: 1.64639953900409

Epoch: 322| Step: 0
Training loss: 0.17696914076805115
Validation loss: 1.6193478684271536

Epoch: 5| Step: 1
Training loss: 0.21745069324970245
Validation loss: 1.6242251729452482

Epoch: 5| Step: 2
Training loss: 0.26093339920043945
Validation loss: 1.6299319946637718

Epoch: 5| Step: 3
Training loss: 0.24683237075805664
Validation loss: 1.612123571416383

Epoch: 5| Step: 4
Training loss: 0.25112786889076233
Validation loss: 1.6107031709404402

Epoch: 5| Step: 5
Training loss: 0.3010256886482239
Validation loss: 1.6125758976064704

Epoch: 5| Step: 6
Training loss: 0.34984520077705383
Validation loss: 1.622506505699568

Epoch: 5| Step: 7
Training loss: 0.2535434365272522
Validation loss: 1.6282977968133905

Epoch: 5| Step: 8
Training loss: 0.15933196246623993
Validation loss: 1.6107361406408331

Epoch: 5| Step: 9
Training loss: 0.20262464880943298
Validation loss: 1.6188078990546606

Epoch: 5| Step: 10
Training loss: 0.19717177748680115
Validation loss: 1.6141908630248039

Epoch: 323| Step: 0
Training loss: 0.14347341656684875
Validation loss: 1.6176107545052805

Epoch: 5| Step: 1
Training loss: 0.32844406366348267
Validation loss: 1.617273812652916

Epoch: 5| Step: 2
Training loss: 0.14935053884983063
Validation loss: 1.5744888282591296

Epoch: 5| Step: 3
Training loss: 0.14320427179336548
Validation loss: 1.5993063270404775

Epoch: 5| Step: 4
Training loss: 0.25277116894721985
Validation loss: 1.5653432082104426

Epoch: 5| Step: 5
Training loss: 0.17854043841362
Validation loss: 1.5552719203374719

Epoch: 5| Step: 6
Training loss: 0.300838828086853
Validation loss: 1.541819663457973

Epoch: 5| Step: 7
Training loss: 0.2023119479417801
Validation loss: 1.5196363259387273

Epoch: 5| Step: 8
Training loss: 0.3108305037021637
Validation loss: 1.5628661519737654

Epoch: 5| Step: 9
Training loss: 0.29691940546035767
Validation loss: 1.5535248043716594

Epoch: 5| Step: 10
Training loss: 0.26492831110954285
Validation loss: 1.581932439598986

Epoch: 324| Step: 0
Training loss: 0.17941507697105408
Validation loss: 1.5836252576561385

Epoch: 5| Step: 1
Training loss: 0.3465003967285156
Validation loss: 1.576316463050022

Epoch: 5| Step: 2
Training loss: 0.12552113831043243
Validation loss: 1.596825498406605

Epoch: 5| Step: 3
Training loss: 0.2507844567298889
Validation loss: 1.6110182141744962

Epoch: 5| Step: 4
Training loss: 0.27060166001319885
Validation loss: 1.6056657222009474

Epoch: 5| Step: 5
Training loss: 0.29101425409317017
Validation loss: 1.619371550057524

Epoch: 5| Step: 6
Training loss: 0.10992749035358429
Validation loss: 1.5895776582020584

Epoch: 5| Step: 7
Training loss: 0.35106396675109863
Validation loss: 1.5420310381920106

Epoch: 5| Step: 8
Training loss: 0.15671028196811676
Validation loss: 1.5288565094752977

Epoch: 5| Step: 9
Training loss: 0.24559080600738525
Validation loss: 1.5616738885961554

Epoch: 5| Step: 10
Training loss: 0.1964847892522812
Validation loss: 1.5366144026479414

Epoch: 325| Step: 0
Training loss: 0.19178184866905212
Validation loss: 1.563811259244078

Epoch: 5| Step: 1
Training loss: 0.19166222214698792
Validation loss: 1.546465418672049

Epoch: 5| Step: 2
Training loss: 0.4339974820613861
Validation loss: 1.5624171751801685

Epoch: 5| Step: 3
Training loss: 0.18085643649101257
Validation loss: 1.578988831530335

Epoch: 5| Step: 4
Training loss: 0.17330780625343323
Validation loss: 1.5827489206867833

Epoch: 5| Step: 5
Training loss: 0.3913334012031555
Validation loss: 1.643339967214933

Epoch: 5| Step: 6
Training loss: 0.16205213963985443
Validation loss: 1.6423028733140679

Epoch: 5| Step: 7
Training loss: 0.2469497174024582
Validation loss: 1.622096469325404

Epoch: 5| Step: 8
Training loss: 0.27704182267189026
Validation loss: 1.646361006203518

Epoch: 5| Step: 9
Training loss: 0.24213095009326935
Validation loss: 1.6120106507373113

Epoch: 5| Step: 10
Training loss: 0.10657144337892532
Validation loss: 1.5923951979606383

Epoch: 326| Step: 0
Training loss: 0.13405391573905945
Validation loss: 1.572574669314969

Epoch: 5| Step: 1
Training loss: 0.20202331244945526
Validation loss: 1.5568123812316566

Epoch: 5| Step: 2
Training loss: 0.25890251994132996
Validation loss: 1.578365574600876

Epoch: 5| Step: 3
Training loss: 0.2273847609758377
Validation loss: 1.574068050230703

Epoch: 5| Step: 4
Training loss: 0.2392362803220749
Validation loss: 1.550278223970885

Epoch: 5| Step: 5
Training loss: 0.20499010384082794
Validation loss: 1.574189757788053

Epoch: 5| Step: 6
Training loss: 0.21153302490711212
Validation loss: 1.5720079534797258

Epoch: 5| Step: 7
Training loss: 0.2877604365348816
Validation loss: 1.5781161464670652

Epoch: 5| Step: 8
Training loss: 0.16227273643016815
Validation loss: 1.5928416072681386

Epoch: 5| Step: 9
Training loss: 0.4296032786369324
Validation loss: 1.5982344547907512

Epoch: 5| Step: 10
Training loss: 0.1956844925880432
Validation loss: 1.6040293273105417

Epoch: 327| Step: 0
Training loss: 0.1471244990825653
Validation loss: 1.608053327888571

Epoch: 5| Step: 1
Training loss: 0.22909121215343475
Validation loss: 1.622900757738339

Epoch: 5| Step: 2
Training loss: 0.36416858434677124
Validation loss: 1.5983683819411902

Epoch: 5| Step: 3
Training loss: 0.18313321471214294
Validation loss: 1.6192299460852018

Epoch: 5| Step: 4
Training loss: 0.14774325489997864
Validation loss: 1.6307982654981716

Epoch: 5| Step: 5
Training loss: 0.2962058186531067
Validation loss: 1.5870888233184814

Epoch: 5| Step: 6
Training loss: 0.3158102333545685
Validation loss: 1.5844436999290221

Epoch: 5| Step: 7
Training loss: 0.26679837703704834
Validation loss: 1.5498780601768083

Epoch: 5| Step: 8
Training loss: 0.16991619765758514
Validation loss: 1.5696127145521102

Epoch: 5| Step: 9
Training loss: 0.183329775929451
Validation loss: 1.5377883808587187

Epoch: 5| Step: 10
Training loss: 0.17237117886543274
Validation loss: 1.5241644305567588

Epoch: 328| Step: 0
Training loss: 0.35893985629081726
Validation loss: 1.5207341999135993

Epoch: 5| Step: 1
Training loss: 0.1915828436613083
Validation loss: 1.5207225763669578

Epoch: 5| Step: 2
Training loss: 0.26912418007850647
Validation loss: 1.5283555510223552

Epoch: 5| Step: 3
Training loss: 0.21756711602210999
Validation loss: 1.5050094384019093

Epoch: 5| Step: 4
Training loss: 0.2749839425086975
Validation loss: 1.535747980558744

Epoch: 5| Step: 5
Training loss: 0.18124794960021973
Validation loss: 1.5260563140274377

Epoch: 5| Step: 6
Training loss: 0.2481801062822342
Validation loss: 1.5565581372989121

Epoch: 5| Step: 7
Training loss: 0.19317862391471863
Validation loss: 1.5940111670442807

Epoch: 5| Step: 8
Training loss: 0.13794434070587158
Validation loss: 1.5820077388517317

Epoch: 5| Step: 9
Training loss: 0.16349801421165466
Validation loss: 1.6441774086285663

Epoch: 5| Step: 10
Training loss: 0.3032521605491638
Validation loss: 1.6246862578135666

Epoch: 329| Step: 0
Training loss: 0.15491622686386108
Validation loss: 1.586415510664704

Epoch: 5| Step: 1
Training loss: 0.33786606788635254
Validation loss: 1.5666935443878174

Epoch: 5| Step: 2
Training loss: 0.17468015849590302
Validation loss: 1.585271591781288

Epoch: 5| Step: 3
Training loss: 0.230555921792984
Validation loss: 1.5766727321891374

Epoch: 5| Step: 4
Training loss: 0.19100028276443481
Validation loss: 1.565243265962088

Epoch: 5| Step: 5
Training loss: 0.268293172121048
Validation loss: 1.5656810383642874

Epoch: 5| Step: 6
Training loss: 0.27763161063194275
Validation loss: 1.591536214274745

Epoch: 5| Step: 7
Training loss: 0.23311081528663635
Validation loss: 1.5974366677704679

Epoch: 5| Step: 8
Training loss: 0.19295351207256317
Validation loss: 1.5704291059124855

Epoch: 5| Step: 9
Training loss: 0.14228983223438263
Validation loss: 1.5826157036648

Epoch: 5| Step: 10
Training loss: 0.23984788358211517
Validation loss: 1.5881637834733533

Epoch: 330| Step: 0
Training loss: 0.23256561160087585
Validation loss: 1.621925130967171

Epoch: 5| Step: 1
Training loss: 0.22258830070495605
Validation loss: 1.5855878617173882

Epoch: 5| Step: 2
Training loss: 0.23144519329071045
Validation loss: 1.5856123867855276

Epoch: 5| Step: 3
Training loss: 0.14419642090797424
Validation loss: 1.5512916990505752

Epoch: 5| Step: 4
Training loss: 0.25807976722717285
Validation loss: 1.5841369974997737

Epoch: 5| Step: 5
Training loss: 0.1753927767276764
Validation loss: 1.5678463764088129

Epoch: 5| Step: 6
Training loss: 0.15364089608192444
Validation loss: 1.5796358905812746

Epoch: 5| Step: 7
Training loss: 0.3720686435699463
Validation loss: 1.594596875611172

Epoch: 5| Step: 8
Training loss: 0.24943402409553528
Validation loss: 1.5870219763889108

Epoch: 5| Step: 9
Training loss: 0.12807613611221313
Validation loss: 1.5789804650891213

Epoch: 5| Step: 10
Training loss: 0.2256552129983902
Validation loss: 1.6040808808419011

Epoch: 331| Step: 0
Training loss: 0.21743349730968475
Validation loss: 1.5730117943979078

Epoch: 5| Step: 1
Training loss: 0.12892422080039978
Validation loss: 1.5794431124964068

Epoch: 5| Step: 2
Training loss: 0.07877933979034424
Validation loss: 1.5797774240534792

Epoch: 5| Step: 3
Training loss: 0.24418139457702637
Validation loss: 1.5673784857155175

Epoch: 5| Step: 4
Training loss: 0.22208651900291443
Validation loss: 1.6041613804396762

Epoch: 5| Step: 5
Training loss: 0.15710002183914185
Validation loss: 1.59235579224043

Epoch: 5| Step: 6
Training loss: 0.21889206767082214
Validation loss: 1.5806044083769604

Epoch: 5| Step: 7
Training loss: 0.3542187213897705
Validation loss: 1.5980912408521097

Epoch: 5| Step: 8
Training loss: 0.20762813091278076
Validation loss: 1.6102480452547792

Epoch: 5| Step: 9
Training loss: 0.2320631444454193
Validation loss: 1.5924174548477255

Epoch: 5| Step: 10
Training loss: 0.17804373800754547
Validation loss: 1.61866045254533

Epoch: 332| Step: 0
Training loss: 0.26107463240623474
Validation loss: 1.6216613015820902

Epoch: 5| Step: 1
Training loss: 0.14391349256038666
Validation loss: 1.5961417408399685

Epoch: 5| Step: 2
Training loss: 0.17297370731830597
Validation loss: 1.6088531344167647

Epoch: 5| Step: 3
Training loss: 0.22501349449157715
Validation loss: 1.5526321972570112

Epoch: 5| Step: 4
Training loss: 0.3723406195640564
Validation loss: 1.57162808474674

Epoch: 5| Step: 5
Training loss: 0.19724972546100616
Validation loss: 1.5264886117750598

Epoch: 5| Step: 6
Training loss: 0.1948612928390503
Validation loss: 1.543139898648826

Epoch: 5| Step: 7
Training loss: 0.18775098025798798
Validation loss: 1.5286665449860275

Epoch: 5| Step: 8
Training loss: 0.1893312633037567
Validation loss: 1.5389122706587597

Epoch: 5| Step: 9
Training loss: 0.20455889403820038
Validation loss: 1.5251627147838633

Epoch: 5| Step: 10
Training loss: 0.27722686529159546
Validation loss: 1.525514583433828

Epoch: 333| Step: 0
Training loss: 0.1663903295993805
Validation loss: 1.5703874147066506

Epoch: 5| Step: 1
Training loss: 0.3054920732975006
Validation loss: 1.5856054873876675

Epoch: 5| Step: 2
Training loss: 0.17644210159778595
Validation loss: 1.6119339081548876

Epoch: 5| Step: 3
Training loss: 0.23572587966918945
Validation loss: 1.6421196255632626

Epoch: 5| Step: 4
Training loss: 0.19259503483772278
Validation loss: 1.6471520252125238

Epoch: 5| Step: 5
Training loss: 0.351924866437912
Validation loss: 1.6780407838923956

Epoch: 5| Step: 6
Training loss: 0.18686407804489136
Validation loss: 1.6952440687405166

Epoch: 5| Step: 7
Training loss: 0.15654197335243225
Validation loss: 1.6986981463688675

Epoch: 5| Step: 8
Training loss: 0.28916382789611816
Validation loss: 1.6435645216254777

Epoch: 5| Step: 9
Training loss: 0.24052782356739044
Validation loss: 1.6103954802277267

Epoch: 5| Step: 10
Training loss: 0.3383183777332306
Validation loss: 1.6142658713043376

Epoch: 334| Step: 0
Training loss: 0.14526519179344177
Validation loss: 1.5536892606366066

Epoch: 5| Step: 1
Training loss: 0.28655052185058594
Validation loss: 1.554085623833441

Epoch: 5| Step: 2
Training loss: 0.2941835820674896
Validation loss: 1.5252894701496247

Epoch: 5| Step: 3
Training loss: 0.2186514139175415
Validation loss: 1.4979821558921569

Epoch: 5| Step: 4
Training loss: 0.19566379487514496
Validation loss: 1.5220822589371794

Epoch: 5| Step: 5
Training loss: 0.2766767144203186
Validation loss: 1.5089874523942188

Epoch: 5| Step: 6
Training loss: 0.19337622821331024
Validation loss: 1.533960965371901

Epoch: 5| Step: 7
Training loss: 0.19141289591789246
Validation loss: 1.5493579885011077

Epoch: 5| Step: 8
Training loss: 0.18777993321418762
Validation loss: 1.562152551707401

Epoch: 5| Step: 9
Training loss: 0.11205212771892548
Validation loss: 1.5717614568689817

Epoch: 5| Step: 10
Training loss: 0.16975250840187073
Validation loss: 1.6063036072638728

Epoch: 335| Step: 0
Training loss: 0.26792192459106445
Validation loss: 1.633754800724727

Epoch: 5| Step: 1
Training loss: 0.29042166471481323
Validation loss: 1.6757081195872316

Epoch: 5| Step: 2
Training loss: 0.19816383719444275
Validation loss: 1.6713315389489616

Epoch: 5| Step: 3
Training loss: 0.18162813782691956
Validation loss: 1.6993851213045017

Epoch: 5| Step: 4
Training loss: 0.2186814248561859
Validation loss: 1.6703884755411456

Epoch: 5| Step: 5
Training loss: 0.2990381717681885
Validation loss: 1.680921305892288

Epoch: 5| Step: 6
Training loss: 0.18612733483314514
Validation loss: 1.654840494996758

Epoch: 5| Step: 7
Training loss: 0.19511306285858154
Validation loss: 1.6448049711924728

Epoch: 5| Step: 8
Training loss: 0.06153804063796997
Validation loss: 1.6275444133307344

Epoch: 5| Step: 9
Training loss: 0.22267718613147736
Validation loss: 1.6232352038865447

Epoch: 5| Step: 10
Training loss: 0.12468206137418747
Validation loss: 1.617854638766217

Epoch: 336| Step: 0
Training loss: 0.4654545783996582
Validation loss: 1.6092420572875648

Epoch: 5| Step: 1
Training loss: 0.18801197409629822
Validation loss: 1.6092461386034567

Epoch: 5| Step: 2
Training loss: 0.17594031989574432
Validation loss: 1.6085063731798561

Epoch: 5| Step: 3
Training loss: 0.19606193900108337
Validation loss: 1.601166429058198

Epoch: 5| Step: 4
Training loss: 0.12574665248394012
Validation loss: 1.5934100932972406

Epoch: 5| Step: 5
Training loss: 0.09428051859140396
Validation loss: 1.614155618093347

Epoch: 5| Step: 6
Training loss: 0.1337164342403412
Validation loss: 1.6299497312115085

Epoch: 5| Step: 7
Training loss: 0.18070726096630096
Validation loss: 1.6325976848602295

Epoch: 5| Step: 8
Training loss: 0.19218426942825317
Validation loss: 1.6098559966651342

Epoch: 5| Step: 9
Training loss: 0.20551690459251404
Validation loss: 1.6271490602083103

Epoch: 5| Step: 10
Training loss: 0.22291989624500275
Validation loss: 1.6321200734825545

Epoch: 337| Step: 0
Training loss: 0.20921540260314941
Validation loss: 1.609067113168778

Epoch: 5| Step: 1
Training loss: 0.09529095888137817
Validation loss: 1.6197767411508868

Epoch: 5| Step: 2
Training loss: 0.31086283922195435
Validation loss: 1.6039222158411497

Epoch: 5| Step: 3
Training loss: 0.27474135160446167
Validation loss: 1.5675671946617864

Epoch: 5| Step: 4
Training loss: 0.22574064135551453
Validation loss: 1.5715212411777948

Epoch: 5| Step: 5
Training loss: 0.14471285045146942
Validation loss: 1.582312092986158

Epoch: 5| Step: 6
Training loss: 0.2144933044910431
Validation loss: 1.5818430044317757

Epoch: 5| Step: 7
Training loss: 0.2210811823606491
Validation loss: 1.584379046194015

Epoch: 5| Step: 8
Training loss: 0.23061172664165497
Validation loss: 1.5871733478320542

Epoch: 5| Step: 9
Training loss: 0.1663358509540558
Validation loss: 1.6110046884065032

Epoch: 5| Step: 10
Training loss: 0.22989322245121002
Validation loss: 1.616119602675079

Epoch: 338| Step: 0
Training loss: 0.21831226348876953
Validation loss: 1.6231727113005936

Epoch: 5| Step: 1
Training loss: 0.22284924983978271
Validation loss: 1.612996732034991

Epoch: 5| Step: 2
Training loss: 0.1676073670387268
Validation loss: 1.6111592464549567

Epoch: 5| Step: 3
Training loss: 0.21935033798217773
Validation loss: 1.5871082185417094

Epoch: 5| Step: 4
Training loss: 0.22625450789928436
Validation loss: 1.614206616596509

Epoch: 5| Step: 5
Training loss: 0.18324753642082214
Validation loss: 1.603030825173983

Epoch: 5| Step: 6
Training loss: 0.13672097027301788
Validation loss: 1.6364827335521739

Epoch: 5| Step: 7
Training loss: 0.21915856003761292
Validation loss: 1.6522574988744592

Epoch: 5| Step: 8
Training loss: 0.26940983533859253
Validation loss: 1.675632235824421

Epoch: 5| Step: 9
Training loss: 0.21225205063819885
Validation loss: 1.6594969162376978

Epoch: 5| Step: 10
Training loss: 0.20499032735824585
Validation loss: 1.6566850421249226

Epoch: 339| Step: 0
Training loss: 0.24769747257232666
Validation loss: 1.64152511729989

Epoch: 5| Step: 1
Training loss: 0.3381376564502716
Validation loss: 1.6023331175568283

Epoch: 5| Step: 2
Training loss: 0.20407304167747498
Validation loss: 1.598119016616575

Epoch: 5| Step: 3
Training loss: 0.16347470879554749
Validation loss: 1.5731142887505152

Epoch: 5| Step: 4
Training loss: 0.2869280278682709
Validation loss: 1.5448198485118088

Epoch: 5| Step: 5
Training loss: 0.14655718207359314
Validation loss: 1.544340718177057

Epoch: 5| Step: 6
Training loss: 0.14597275853157043
Validation loss: 1.5481532030208136

Epoch: 5| Step: 7
Training loss: 0.1874047815799713
Validation loss: 1.5323825907963577

Epoch: 5| Step: 8
Training loss: 0.17467698454856873
Validation loss: 1.5358848289776874

Epoch: 5| Step: 9
Training loss: 0.22412064671516418
Validation loss: 1.5394443247907905

Epoch: 5| Step: 10
Training loss: 0.20203933119773865
Validation loss: 1.5692681625325193

Epoch: 340| Step: 0
Training loss: 0.21932940185070038
Validation loss: 1.5627799828847249

Epoch: 5| Step: 1
Training loss: 0.11238851398229599
Validation loss: 1.5621656615247008

Epoch: 5| Step: 2
Training loss: 0.16655313968658447
Validation loss: 1.5808362307087067

Epoch: 5| Step: 3
Training loss: 0.14617577195167542
Validation loss: 1.5913600690903202

Epoch: 5| Step: 4
Training loss: 0.19244258105754852
Validation loss: 1.6029260350811867

Epoch: 5| Step: 5
Training loss: 0.2907569706439972
Validation loss: 1.6031794868489748

Epoch: 5| Step: 6
Training loss: 0.30516865849494934
Validation loss: 1.596575233885037

Epoch: 5| Step: 7
Training loss: 0.26101040840148926
Validation loss: 1.6016821002447477

Epoch: 5| Step: 8
Training loss: 0.08863344043493271
Validation loss: 1.5781566276345202

Epoch: 5| Step: 9
Training loss: 0.22408118844032288
Validation loss: 1.565188245106769

Epoch: 5| Step: 10
Training loss: 0.17649628221988678
Validation loss: 1.5582323817796604

Epoch: 341| Step: 0
Training loss: 0.2448205202817917
Validation loss: 1.5657275325508528

Epoch: 5| Step: 1
Training loss: 0.1631164401769638
Validation loss: 1.5506212531879384

Epoch: 5| Step: 2
Training loss: 0.20646217465400696
Validation loss: 1.5461759605715353

Epoch: 5| Step: 3
Training loss: 0.16457624733448029
Validation loss: 1.5570007190909436

Epoch: 5| Step: 4
Training loss: 0.31289660930633545
Validation loss: 1.5536637203667754

Epoch: 5| Step: 5
Training loss: 0.13766691088676453
Validation loss: 1.5668554703394573

Epoch: 5| Step: 6
Training loss: 0.17614102363586426
Validation loss: 1.5731988517186974

Epoch: 5| Step: 7
Training loss: 0.21704168617725372
Validation loss: 1.5600058776076122

Epoch: 5| Step: 8
Training loss: 0.19512273371219635
Validation loss: 1.582615093518329

Epoch: 5| Step: 9
Training loss: 0.19399511814117432
Validation loss: 1.5787925797124063

Epoch: 5| Step: 10
Training loss: 0.12313836812973022
Validation loss: 1.5872733221259168

Epoch: 342| Step: 0
Training loss: 0.12710118293762207
Validation loss: 1.5828838598343633

Epoch: 5| Step: 1
Training loss: 0.35282212495803833
Validation loss: 1.5746250883225472

Epoch: 5| Step: 2
Training loss: 0.18132320046424866
Validation loss: 1.557587130095369

Epoch: 5| Step: 3
Training loss: 0.16113848984241486
Validation loss: 1.5747922210283176

Epoch: 5| Step: 4
Training loss: 0.23733067512512207
Validation loss: 1.5416744806433236

Epoch: 5| Step: 5
Training loss: 0.1549074947834015
Validation loss: 1.5503555190178655

Epoch: 5| Step: 6
Training loss: 0.14858247339725494
Validation loss: 1.5342279134258148

Epoch: 5| Step: 7
Training loss: 0.19350996613502502
Validation loss: 1.525355754360076

Epoch: 5| Step: 8
Training loss: 0.17976225912570953
Validation loss: 1.5289737537343016

Epoch: 5| Step: 9
Training loss: 0.23710349202156067
Validation loss: 1.5316946269363485

Epoch: 5| Step: 10
Training loss: 0.1939389854669571
Validation loss: 1.5459250532170778

Epoch: 343| Step: 0
Training loss: 0.22922973334789276
Validation loss: 1.5544944245328185

Epoch: 5| Step: 1
Training loss: 0.2003783881664276
Validation loss: 1.5487793478914487

Epoch: 5| Step: 2
Training loss: 0.1681211292743683
Validation loss: 1.5606251250031173

Epoch: 5| Step: 3
Training loss: 0.17834386229515076
Validation loss: 1.5852502763912242

Epoch: 5| Step: 4
Training loss: 0.21572229266166687
Validation loss: 1.5449458161989849

Epoch: 5| Step: 5
Training loss: 0.24064043164253235
Validation loss: 1.5109041839517572

Epoch: 5| Step: 6
Training loss: 0.22691722214221954
Validation loss: 1.4749628895072526

Epoch: 5| Step: 7
Training loss: 0.14495113492012024
Validation loss: 1.4880203136833765

Epoch: 5| Step: 8
Training loss: 0.19187729060649872
Validation loss: 1.5115040643240816

Epoch: 5| Step: 9
Training loss: 0.1288096159696579
Validation loss: 1.4835412489470614

Epoch: 5| Step: 10
Training loss: 0.3767455220222473
Validation loss: 1.4984315159500285

Epoch: 344| Step: 0
Training loss: 0.25013256072998047
Validation loss: 1.521587602553829

Epoch: 5| Step: 1
Training loss: 0.18321137130260468
Validation loss: 1.5405641755750101

Epoch: 5| Step: 2
Training loss: 0.2036486566066742
Validation loss: 1.5677592446727138

Epoch: 5| Step: 3
Training loss: 0.12989605963230133
Validation loss: 1.568031700708533

Epoch: 5| Step: 4
Training loss: 0.17967960238456726
Validation loss: 1.5809171686890304

Epoch: 5| Step: 5
Training loss: 0.17385080456733704
Validation loss: 1.5643194067862727

Epoch: 5| Step: 6
Training loss: 0.12268657982349396
Validation loss: 1.5865581920070033

Epoch: 5| Step: 7
Training loss: 0.24846133589744568
Validation loss: 1.5737405361667756

Epoch: 5| Step: 8
Training loss: 0.2519388198852539
Validation loss: 1.5714234459784724

Epoch: 5| Step: 9
Training loss: 0.1821439415216446
Validation loss: 1.5305663206244027

Epoch: 5| Step: 10
Training loss: 0.13149891793727875
Validation loss: 1.5557900667190552

Epoch: 345| Step: 0
Training loss: 0.23266637325286865
Validation loss: 1.5408854279466855

Epoch: 5| Step: 1
Training loss: 0.27940717339515686
Validation loss: 1.5577283033760645

Epoch: 5| Step: 2
Training loss: 0.22617864608764648
Validation loss: 1.549635043708227

Epoch: 5| Step: 3
Training loss: 0.27490106225013733
Validation loss: 1.559280018652639

Epoch: 5| Step: 4
Training loss: 0.12625131011009216
Validation loss: 1.5606312444133144

Epoch: 5| Step: 5
Training loss: 0.1247936338186264
Validation loss: 1.5671013670582925

Epoch: 5| Step: 6
Training loss: 0.15158352255821228
Validation loss: 1.5798693151884182

Epoch: 5| Step: 7
Training loss: 0.1608111560344696
Validation loss: 1.5941303032700733

Epoch: 5| Step: 8
Training loss: 0.08633638918399811
Validation loss: 1.5838033050619147

Epoch: 5| Step: 9
Training loss: 0.18552552163600922
Validation loss: 1.5757596338948896

Epoch: 5| Step: 10
Training loss: 0.2218829095363617
Validation loss: 1.5748807602031256

Epoch: 346| Step: 0
Training loss: 0.1126304492354393
Validation loss: 1.5822225072050606

Epoch: 5| Step: 1
Training loss: 0.2919777035713196
Validation loss: 1.5666832411161034

Epoch: 5| Step: 2
Training loss: 0.17835848033428192
Validation loss: 1.5458544761903825

Epoch: 5| Step: 3
Training loss: 0.21638865768909454
Validation loss: 1.5157195393757155

Epoch: 5| Step: 4
Training loss: 0.18537625670433044
Validation loss: 1.4976119892571562

Epoch: 5| Step: 5
Training loss: 0.2147752344608307
Validation loss: 1.47540323580465

Epoch: 5| Step: 6
Training loss: 0.14534394443035126
Validation loss: 1.5174586298645183

Epoch: 5| Step: 7
Training loss: 0.20593388378620148
Validation loss: 1.5161770736017535

Epoch: 5| Step: 8
Training loss: 0.19830015301704407
Validation loss: 1.5080100810655983

Epoch: 5| Step: 9
Training loss: 0.2107793539762497
Validation loss: 1.5425083291146062

Epoch: 5| Step: 10
Training loss: 0.1209169253706932
Validation loss: 1.5248040601771364

Epoch: 347| Step: 0
Training loss: 0.2212212085723877
Validation loss: 1.5241208826341937

Epoch: 5| Step: 1
Training loss: 0.32976946234703064
Validation loss: 1.5447609168227001

Epoch: 5| Step: 2
Training loss: 0.2239873856306076
Validation loss: 1.5178469996298514

Epoch: 5| Step: 3
Training loss: 0.09243147075176239
Validation loss: 1.5431731157405402

Epoch: 5| Step: 4
Training loss: 0.2125457227230072
Validation loss: 1.5427354394748647

Epoch: 5| Step: 5
Training loss: 0.2271079123020172
Validation loss: 1.5311655216319586

Epoch: 5| Step: 6
Training loss: 0.17726700007915497
Validation loss: 1.579575106661807

Epoch: 5| Step: 7
Training loss: 0.1868707835674286
Validation loss: 1.5941871212374779

Epoch: 5| Step: 8
Training loss: 0.24642153084278107
Validation loss: 1.5935299191423642

Epoch: 5| Step: 9
Training loss: 0.20960740745067596
Validation loss: 1.6162233967934885

Epoch: 5| Step: 10
Training loss: 0.10813025385141373
Validation loss: 1.6197786766995665

Epoch: 348| Step: 0
Training loss: 0.2565118670463562
Validation loss: 1.6322342157363892

Epoch: 5| Step: 1
Training loss: 0.390037477016449
Validation loss: 1.6108277638753254

Epoch: 5| Step: 2
Training loss: 0.09290613979101181
Validation loss: 1.6489911335770802

Epoch: 5| Step: 3
Training loss: 0.16778035461902618
Validation loss: 1.6443710762967345

Epoch: 5| Step: 4
Training loss: 0.08391930162906647
Validation loss: 1.595135704163582

Epoch: 5| Step: 5
Training loss: 0.22040514647960663
Validation loss: 1.5731739779954315

Epoch: 5| Step: 6
Training loss: 0.14085014164447784
Validation loss: 1.5522314604892526

Epoch: 5| Step: 7
Training loss: 0.16396358609199524
Validation loss: 1.5461191990042245

Epoch: 5| Step: 8
Training loss: 0.17473439872264862
Validation loss: 1.5426386812681794

Epoch: 5| Step: 9
Training loss: 0.22679977118968964
Validation loss: 1.5298377608740201

Epoch: 5| Step: 10
Training loss: 0.21415531635284424
Validation loss: 1.5357566392549904

Epoch: 349| Step: 0
Training loss: 0.14756664633750916
Validation loss: 1.5558777496378908

Epoch: 5| Step: 1
Training loss: 0.2068600207567215
Validation loss: 1.5495151883812361

Epoch: 5| Step: 2
Training loss: 0.24124391376972198
Validation loss: 1.545364833647205

Epoch: 5| Step: 3
Training loss: 0.14810937643051147
Validation loss: 1.5561694906603905

Epoch: 5| Step: 4
Training loss: 0.20664994418621063
Validation loss: 1.5756159777282386

Epoch: 5| Step: 5
Training loss: 0.10996562242507935
Validation loss: 1.529356316853595

Epoch: 5| Step: 6
Training loss: 0.12267609685659409
Validation loss: 1.5750305960255284

Epoch: 5| Step: 7
Training loss: 0.21883049607276917
Validation loss: 1.5622034906059183

Epoch: 5| Step: 8
Training loss: 0.1936793327331543
Validation loss: 1.535833812529041

Epoch: 5| Step: 9
Training loss: 0.17609314620494843
Validation loss: 1.5620959022993683

Epoch: 5| Step: 10
Training loss: 0.10993414372205734
Validation loss: 1.5516759798090944

Epoch: 350| Step: 0
Training loss: 0.186820387840271
Validation loss: 1.5413016439766012

Epoch: 5| Step: 1
Training loss: 0.18029405176639557
Validation loss: 1.5519759501180341

Epoch: 5| Step: 2
Training loss: 0.19740480184555054
Validation loss: 1.5398349390234998

Epoch: 5| Step: 3
Training loss: 0.19551174342632294
Validation loss: 1.5423600545493505

Epoch: 5| Step: 4
Training loss: 0.1598379909992218
Validation loss: 1.5339235503186461

Epoch: 5| Step: 5
Training loss: 0.14127901196479797
Validation loss: 1.5613108168366134

Epoch: 5| Step: 6
Training loss: 0.2560945153236389
Validation loss: 1.5661993565097931

Epoch: 5| Step: 7
Training loss: 0.3004280924797058
Validation loss: 1.5619951364814595

Epoch: 5| Step: 8
Training loss: 0.12105180323123932
Validation loss: 1.557556083125453

Epoch: 5| Step: 9
Training loss: 0.12231475114822388
Validation loss: 1.5282089300053094

Epoch: 5| Step: 10
Training loss: 0.3482811152935028
Validation loss: 1.4784770857903264

Testing loss: 2.1969349119398327
