Epoch: 1| Step: 0
Training loss: 5.775365352630615
Validation loss: 5.18216476645521

Epoch: 5| Step: 1
Training loss: 5.0250325202941895
Validation loss: 5.151345560627599

Epoch: 5| Step: 2
Training loss: 5.058102130889893
Validation loss: 5.126143609323809

Epoch: 5| Step: 3
Training loss: 4.094313144683838
Validation loss: 5.101652453022618

Epoch: 5| Step: 4
Training loss: 4.9295973777771
Validation loss: 5.074387693917879

Epoch: 5| Step: 5
Training loss: 5.364849090576172
Validation loss: 5.042847018088064

Epoch: 5| Step: 6
Training loss: 4.6473493576049805
Validation loss: 5.006207773762364

Epoch: 5| Step: 7
Training loss: 4.774641990661621
Validation loss: 4.966101738714403

Epoch: 5| Step: 8
Training loss: 4.890079498291016
Validation loss: 4.920348203310403

Epoch: 5| Step: 9
Training loss: 4.119235038757324
Validation loss: 4.871597331057313

Epoch: 5| Step: 10
Training loss: 4.2299981117248535
Validation loss: 4.817792666855679

Epoch: 2| Step: 0
Training loss: 4.385839939117432
Validation loss: 4.760819614574474

Epoch: 5| Step: 1
Training loss: 3.6940929889678955
Validation loss: 4.700212565801477

Epoch: 5| Step: 2
Training loss: 4.040009498596191
Validation loss: 4.638555029387115

Epoch: 5| Step: 3
Training loss: 4.621888160705566
Validation loss: 4.576163453440512

Epoch: 5| Step: 4
Training loss: 4.796801567077637
Validation loss: 4.512428509291782

Epoch: 5| Step: 5
Training loss: 4.028778076171875
Validation loss: 4.4452339295418035

Epoch: 5| Step: 6
Training loss: 3.669142484664917
Validation loss: 4.379799222433439

Epoch: 5| Step: 7
Training loss: 5.041197299957275
Validation loss: 4.31425105884511

Epoch: 5| Step: 8
Training loss: 4.694896697998047
Validation loss: 4.2495421158370155

Epoch: 5| Step: 9
Training loss: 4.353433132171631
Validation loss: 4.186725052454138

Epoch: 5| Step: 10
Training loss: 3.2920725345611572
Validation loss: 4.122529783556538

Epoch: 3| Step: 0
Training loss: 3.526334762573242
Validation loss: 4.0604463649052445

Epoch: 5| Step: 1
Training loss: 3.5493075847625732
Validation loss: 3.9948124372830955

Epoch: 5| Step: 2
Training loss: 4.64028787612915
Validation loss: 3.9353713117619997

Epoch: 5| Step: 3
Training loss: 3.09389591217041
Validation loss: 3.886303578653643

Epoch: 5| Step: 4
Training loss: 3.7437241077423096
Validation loss: 3.841367152429396

Epoch: 5| Step: 5
Training loss: 3.456831455230713
Validation loss: 3.798647270407728

Epoch: 5| Step: 6
Training loss: 3.221644163131714
Validation loss: 3.7581328089519213

Epoch: 5| Step: 7
Training loss: 5.064380645751953
Validation loss: 3.726618702693652

Epoch: 5| Step: 8
Training loss: 3.7072863578796387
Validation loss: 3.7035234128275225

Epoch: 5| Step: 9
Training loss: 2.9275870323181152
Validation loss: 3.676651616250315

Epoch: 5| Step: 10
Training loss: 3.9222285747528076
Validation loss: 3.655800332305252

Epoch: 4| Step: 0
Training loss: 3.8540077209472656
Validation loss: 3.6299145196073797

Epoch: 5| Step: 1
Training loss: 3.4275927543640137
Validation loss: 3.6005119841585875

Epoch: 5| Step: 2
Training loss: 2.9597275257110596
Validation loss: 3.565157357082572

Epoch: 5| Step: 3
Training loss: 2.816732168197632
Validation loss: 3.5446573713774323

Epoch: 5| Step: 4
Training loss: 2.9103610515594482
Validation loss: 3.5373813234349734

Epoch: 5| Step: 5
Training loss: 3.4091594219207764
Validation loss: 3.5111802752299974

Epoch: 5| Step: 6
Training loss: 4.0986328125
Validation loss: 3.4893241005559124

Epoch: 5| Step: 7
Training loss: 3.88946795463562
Validation loss: 3.475959188194685

Epoch: 5| Step: 8
Training loss: 3.577413558959961
Validation loss: 3.454190356757051

Epoch: 5| Step: 9
Training loss: 3.2857913970947266
Validation loss: 3.431363126283051

Epoch: 5| Step: 10
Training loss: 3.6461246013641357
Validation loss: 3.414822501520957

Epoch: 5| Step: 0
Training loss: 3.021097183227539
Validation loss: 3.399572185290757

Epoch: 5| Step: 1
Training loss: 3.4056453704833984
Validation loss: 3.383400019779

Epoch: 5| Step: 2
Training loss: 2.752345323562622
Validation loss: 3.3719964181223223

Epoch: 5| Step: 3
Training loss: 3.956460952758789
Validation loss: 3.36579494578864

Epoch: 5| Step: 4
Training loss: 3.4928557872772217
Validation loss: 3.3492500653830906

Epoch: 5| Step: 5
Training loss: 3.099821090698242
Validation loss: 3.3384459941617903

Epoch: 5| Step: 6
Training loss: 3.222440242767334
Validation loss: 3.329270737145537

Epoch: 5| Step: 7
Training loss: 3.516242504119873
Validation loss: 3.319373430744294

Epoch: 5| Step: 8
Training loss: 2.962333917617798
Validation loss: 3.3069795639284196

Epoch: 5| Step: 9
Training loss: 2.854891300201416
Validation loss: 3.294523387826899

Epoch: 5| Step: 10
Training loss: 4.219473361968994
Validation loss: 3.2863052122054563

Epoch: 6| Step: 0
Training loss: 2.686267614364624
Validation loss: 3.2747056894404913

Epoch: 5| Step: 1
Training loss: 3.342627763748169
Validation loss: 3.2564806245988414

Epoch: 5| Step: 2
Training loss: 3.26375150680542
Validation loss: 3.245830853780111

Epoch: 5| Step: 3
Training loss: 2.738062620162964
Validation loss: 3.2362826716515327

Epoch: 5| Step: 4
Training loss: 3.616328477859497
Validation loss: 3.2288760985097578

Epoch: 5| Step: 5
Training loss: 3.224269151687622
Validation loss: 3.2190968708325456

Epoch: 5| Step: 6
Training loss: 2.548739433288574
Validation loss: 3.2099734019207697

Epoch: 5| Step: 7
Training loss: 4.029483795166016
Validation loss: 3.19819462683893

Epoch: 5| Step: 8
Training loss: 3.558328628540039
Validation loss: 3.1877584944489183

Epoch: 5| Step: 9
Training loss: 3.2724156379699707
Validation loss: 3.1762006795534523

Epoch: 5| Step: 10
Training loss: 3.0229454040527344
Validation loss: 3.166273973321402

Epoch: 7| Step: 0
Training loss: 3.4057846069335938
Validation loss: 3.1563621362050376

Epoch: 5| Step: 1
Training loss: 3.1956000328063965
Validation loss: 3.1459118448277956

Epoch: 5| Step: 2
Training loss: 2.80953311920166
Validation loss: 3.1329801697884836

Epoch: 5| Step: 3
Training loss: 3.4208221435546875
Validation loss: 3.129041761480352

Epoch: 5| Step: 4
Training loss: 3.2501182556152344
Validation loss: 3.128486156463623

Epoch: 5| Step: 5
Training loss: 3.1195311546325684
Validation loss: 3.1107405078026558

Epoch: 5| Step: 6
Training loss: 2.6622443199157715
Validation loss: 3.1024392343336538

Epoch: 5| Step: 7
Training loss: 3.269339084625244
Validation loss: 3.0969345800338255

Epoch: 5| Step: 8
Training loss: 2.7896361351013184
Validation loss: 3.0911141467350784

Epoch: 5| Step: 9
Training loss: 3.1557681560516357
Validation loss: 3.0830474079296155

Epoch: 5| Step: 10
Training loss: 3.5168051719665527
Validation loss: 3.075285944887387

Epoch: 8| Step: 0
Training loss: 3.5347914695739746
Validation loss: 3.0681983296589186

Epoch: 5| Step: 1
Training loss: 3.8029181957244873
Validation loss: 3.0629524005356656

Epoch: 5| Step: 2
Training loss: 3.4184505939483643
Validation loss: 3.0548352682462303

Epoch: 5| Step: 3
Training loss: 3.124448299407959
Validation loss: 3.0486555509669806

Epoch: 5| Step: 4
Training loss: 3.427243709564209
Validation loss: 3.0454103049411567

Epoch: 5| Step: 5
Training loss: 2.8780903816223145
Validation loss: 3.039760169162545

Epoch: 5| Step: 6
Training loss: 2.142518997192383
Validation loss: 3.03587051873566

Epoch: 5| Step: 7
Training loss: 2.616485118865967
Validation loss: 3.0307330803204606

Epoch: 5| Step: 8
Training loss: 3.254924774169922
Validation loss: 3.0227353906118744

Epoch: 5| Step: 9
Training loss: 2.401270627975464
Validation loss: 3.014992795964723

Epoch: 5| Step: 10
Training loss: 3.471193552017212
Validation loss: 3.010532271477484

Epoch: 9| Step: 0
Training loss: 2.5978198051452637
Validation loss: 3.0064499660204818

Epoch: 5| Step: 1
Training loss: 3.346959352493286
Validation loss: 3.002941798138362

Epoch: 5| Step: 2
Training loss: 3.129812240600586
Validation loss: 2.998014150127288

Epoch: 5| Step: 3
Training loss: 3.5090041160583496
Validation loss: 2.995294899068853

Epoch: 5| Step: 4
Training loss: 2.678758144378662
Validation loss: 2.9904358617721067

Epoch: 5| Step: 5
Training loss: 2.6655313968658447
Validation loss: 2.985325215965189

Epoch: 5| Step: 6
Training loss: 2.674778699874878
Validation loss: 2.9819099364742154

Epoch: 5| Step: 7
Training loss: 3.9083874225616455
Validation loss: 2.978372691780008

Epoch: 5| Step: 8
Training loss: 2.976930618286133
Validation loss: 2.9727067537205194

Epoch: 5| Step: 9
Training loss: 2.985520839691162
Validation loss: 2.968171996455039

Epoch: 5| Step: 10
Training loss: 3.169450044631958
Validation loss: 2.9654205319701985

Epoch: 10| Step: 0
Training loss: 2.7235822677612305
Validation loss: 2.958303195174022

Epoch: 5| Step: 1
Training loss: 3.2053794860839844
Validation loss: 2.956543402005267

Epoch: 5| Step: 2
Training loss: 3.089176654815674
Validation loss: 2.954233241337602

Epoch: 5| Step: 3
Training loss: 2.5031120777130127
Validation loss: 2.951372397843228

Epoch: 5| Step: 4
Training loss: 2.6152195930480957
Validation loss: 2.947900641349054

Epoch: 5| Step: 5
Training loss: 3.023364543914795
Validation loss: 2.9404417186655025

Epoch: 5| Step: 6
Training loss: 3.9065184593200684
Validation loss: 2.939232231468283

Epoch: 5| Step: 7
Training loss: 2.982426643371582
Validation loss: 2.9321111248385523

Epoch: 5| Step: 8
Training loss: 3.2366490364074707
Validation loss: 2.9350572657841507

Epoch: 5| Step: 9
Training loss: 3.4262003898620605
Validation loss: 2.934799660918533

Epoch: 5| Step: 10
Training loss: 2.5096943378448486
Validation loss: 2.9261487863397084

Epoch: 11| Step: 0
Training loss: 2.9485199451446533
Validation loss: 2.920598735091507

Epoch: 5| Step: 1
Training loss: 2.5293333530426025
Validation loss: 2.9216652429232033

Epoch: 5| Step: 2
Training loss: 3.251723051071167
Validation loss: 2.922772187058644

Epoch: 5| Step: 3
Training loss: 2.814277172088623
Validation loss: 2.914420115050449

Epoch: 5| Step: 4
Training loss: 4.032873153686523
Validation loss: 2.9334620967988045

Epoch: 5| Step: 5
Training loss: 2.4704132080078125
Validation loss: 2.9489938828252975

Epoch: 5| Step: 6
Training loss: 3.193061351776123
Validation loss: 2.9273545075488347

Epoch: 5| Step: 7
Training loss: 2.993440866470337
Validation loss: 2.9172685453968663

Epoch: 5| Step: 8
Training loss: 2.8313217163085938
Validation loss: 2.9126433351988434

Epoch: 5| Step: 9
Training loss: 3.3082375526428223
Validation loss: 2.9061494565779165

Epoch: 5| Step: 10
Training loss: 2.744852066040039
Validation loss: 2.9035068532472015

Epoch: 12| Step: 0
Training loss: 2.6430554389953613
Validation loss: 2.893611923340828

Epoch: 5| Step: 1
Training loss: 2.8010966777801514
Validation loss: 2.886525897569554

Epoch: 5| Step: 2
Training loss: 2.653573989868164
Validation loss: 2.8847904615504767

Epoch: 5| Step: 3
Training loss: 3.6091580390930176
Validation loss: 2.8795727863106677

Epoch: 5| Step: 4
Training loss: 2.872549533843994
Validation loss: 2.877640939527942

Epoch: 5| Step: 5
Training loss: 3.325518846511841
Validation loss: 2.8731333799259637

Epoch: 5| Step: 6
Training loss: 2.421297788619995
Validation loss: 2.870560722966348

Epoch: 5| Step: 7
Training loss: 3.3044867515563965
Validation loss: 2.8673675829364407

Epoch: 5| Step: 8
Training loss: 2.362374782562256
Validation loss: 2.8615527153015137

Epoch: 5| Step: 9
Training loss: 3.5512757301330566
Validation loss: 2.8653541098358812

Epoch: 5| Step: 10
Training loss: 3.307650089263916
Validation loss: 2.8565386854192263

Epoch: 13| Step: 0
Training loss: 2.6541545391082764
Validation loss: 2.8475776846690843

Epoch: 5| Step: 1
Training loss: 3.021836757659912
Validation loss: 2.839634851742816

Epoch: 5| Step: 2
Training loss: 2.796086311340332
Validation loss: 2.8390940209870696

Epoch: 5| Step: 3
Training loss: 3.0629725456237793
Validation loss: 2.831986073524721

Epoch: 5| Step: 4
Training loss: 2.3116753101348877
Validation loss: 2.824982996909849

Epoch: 5| Step: 5
Training loss: 3.8987362384796143
Validation loss: 2.829485129284602

Epoch: 5| Step: 6
Training loss: 2.6295382976531982
Validation loss: 2.836170170896797

Epoch: 5| Step: 7
Training loss: 2.3565754890441895
Validation loss: 2.839361144650367

Epoch: 5| Step: 8
Training loss: 2.4073898792266846
Validation loss: 2.8379467892390426

Epoch: 5| Step: 9
Training loss: 3.1200900077819824
Validation loss: 2.8626931354563725

Epoch: 5| Step: 10
Training loss: 4.493521690368652
Validation loss: 2.8213771645740797

Epoch: 14| Step: 0
Training loss: 2.420022964477539
Validation loss: 2.814253725031371

Epoch: 5| Step: 1
Training loss: 2.94651460647583
Validation loss: 2.8613389307452786

Epoch: 5| Step: 2
Training loss: 3.5536370277404785
Validation loss: 2.832131447330598

Epoch: 5| Step: 3
Training loss: 3.0343177318573
Validation loss: 2.8222353125131256

Epoch: 5| Step: 4
Training loss: 2.9572319984436035
Validation loss: 2.8160859923208914

Epoch: 5| Step: 5
Training loss: 3.873103380203247
Validation loss: 2.8112279856076805

Epoch: 5| Step: 6
Training loss: 2.7596874237060547
Validation loss: 2.8090670749705327

Epoch: 5| Step: 7
Training loss: 3.150153160095215
Validation loss: 2.813268720462758

Epoch: 5| Step: 8
Training loss: 2.4998772144317627
Validation loss: 2.804600556691488

Epoch: 5| Step: 9
Training loss: 2.3780202865600586
Validation loss: 2.810660723716982

Epoch: 5| Step: 10
Training loss: 2.871483325958252
Validation loss: 2.819881667373001

Epoch: 15| Step: 0
Training loss: 2.0670981407165527
Validation loss: 2.831003140377742

Epoch: 5| Step: 1
Training loss: 2.538428783416748
Validation loss: 2.842413371609103

Epoch: 5| Step: 2
Training loss: 3.3249053955078125
Validation loss: 2.842119506610337

Epoch: 5| Step: 3
Training loss: 2.2286503314971924
Validation loss: 2.8385962670849216

Epoch: 5| Step: 4
Training loss: 2.317809581756592
Validation loss: 2.8248854144926994

Epoch: 5| Step: 5
Training loss: 3.4920907020568848
Validation loss: 2.810857206262568

Epoch: 5| Step: 6
Training loss: 3.563755750656128
Validation loss: 2.800000734226678

Epoch: 5| Step: 7
Training loss: 3.3271865844726562
Validation loss: 2.7879574145040205

Epoch: 5| Step: 8
Training loss: 2.7846839427948
Validation loss: 2.7849906490695093

Epoch: 5| Step: 9
Training loss: 3.5102150440216064
Validation loss: 2.784487275667088

Epoch: 5| Step: 10
Training loss: 3.186701774597168
Validation loss: 2.7835685104452152

Epoch: 16| Step: 0
Training loss: 3.4979825019836426
Validation loss: 2.783290591291202

Epoch: 5| Step: 1
Training loss: 3.058225154876709
Validation loss: 2.7836568432469524

Epoch: 5| Step: 2
Training loss: 2.4524402618408203
Validation loss: 2.777611635064566

Epoch: 5| Step: 3
Training loss: 2.6955714225769043
Validation loss: 2.7769747934033795

Epoch: 5| Step: 4
Training loss: 3.3743958473205566
Validation loss: 2.772972958062285

Epoch: 5| Step: 5
Training loss: 3.639474868774414
Validation loss: 2.7735270941129295

Epoch: 5| Step: 6
Training loss: 2.6319899559020996
Validation loss: 2.768551636767644

Epoch: 5| Step: 7
Training loss: 2.23721981048584
Validation loss: 2.7700301216494654

Epoch: 5| Step: 8
Training loss: 3.289206027984619
Validation loss: 2.767920006987869

Epoch: 5| Step: 9
Training loss: 2.615609645843506
Validation loss: 2.766692525597029

Epoch: 5| Step: 10
Training loss: 2.555340051651001
Validation loss: 2.766751048385456

Epoch: 17| Step: 0
Training loss: 2.724030017852783
Validation loss: 2.765388588751516

Epoch: 5| Step: 1
Training loss: 2.9140896797180176
Validation loss: 2.7661909698158182

Epoch: 5| Step: 2
Training loss: 3.280705213546753
Validation loss: 2.7641062864693264

Epoch: 5| Step: 3
Training loss: 3.1826953887939453
Validation loss: 2.7628536224365234

Epoch: 5| Step: 4
Training loss: 2.744706630706787
Validation loss: 2.762058365729547

Epoch: 5| Step: 5
Training loss: 2.579902172088623
Validation loss: 2.760171474949006

Epoch: 5| Step: 6
Training loss: 3.400735378265381
Validation loss: 2.7579006918015017

Epoch: 5| Step: 7
Training loss: 2.8419928550720215
Validation loss: 2.758073119707005

Epoch: 5| Step: 8
Training loss: 2.9346044063568115
Validation loss: 2.756311688371884

Epoch: 5| Step: 9
Training loss: 3.267103910446167
Validation loss: 2.75470313461878

Epoch: 5| Step: 10
Training loss: 2.0006425380706787
Validation loss: 2.756307363510132

Epoch: 18| Step: 0
Training loss: 3.3462650775909424
Validation loss: 2.755273013986567

Epoch: 5| Step: 1
Training loss: 3.571080446243286
Validation loss: 2.7542829154640116

Epoch: 5| Step: 2
Training loss: 2.8412082195281982
Validation loss: 2.754216663299068

Epoch: 5| Step: 3
Training loss: 2.565581798553467
Validation loss: 2.7525155185371317

Epoch: 5| Step: 4
Training loss: 3.010195255279541
Validation loss: 2.7512086155594035

Epoch: 5| Step: 5
Training loss: 2.882490873336792
Validation loss: 2.7505050936052875

Epoch: 5| Step: 6
Training loss: 2.805825710296631
Validation loss: 2.7492549342493855

Epoch: 5| Step: 7
Training loss: 2.2072606086730957
Validation loss: 2.7505505495173956

Epoch: 5| Step: 8
Training loss: 3.0494887828826904
Validation loss: 2.7510494673123924

Epoch: 5| Step: 9
Training loss: 2.9057517051696777
Validation loss: 2.748274503215667

Epoch: 5| Step: 10
Training loss: 2.7234764099121094
Validation loss: 2.748045395779353

Epoch: 19| Step: 0
Training loss: 3.3270676136016846
Validation loss: 2.7479618364764797

Epoch: 5| Step: 1
Training loss: 3.152297258377075
Validation loss: 2.747041192106021

Epoch: 5| Step: 2
Training loss: 3.2082626819610596
Validation loss: 2.7466702256151425

Epoch: 5| Step: 3
Training loss: 2.599541187286377
Validation loss: 2.7451174541186263

Epoch: 5| Step: 4
Training loss: 2.078101396560669
Validation loss: 2.7459755174575315

Epoch: 5| Step: 5
Training loss: 2.8823153972625732
Validation loss: 2.746981123442291

Epoch: 5| Step: 6
Training loss: 3.0963950157165527
Validation loss: 2.7475317678143902

Epoch: 5| Step: 7
Training loss: 2.819380521774292
Validation loss: 2.746722957139374

Epoch: 5| Step: 8
Training loss: 3.643662691116333
Validation loss: 2.7466496344535583

Epoch: 5| Step: 9
Training loss: 2.680703639984131
Validation loss: 2.7382510169859855

Epoch: 5| Step: 10
Training loss: 2.291682481765747
Validation loss: 2.7390790370202835

Epoch: 20| Step: 0
Training loss: 3.5429019927978516
Validation loss: 2.7375788073385916

Epoch: 5| Step: 1
Training loss: 3.3912014961242676
Validation loss: 2.738496862432008

Epoch: 5| Step: 2
Training loss: 3.209027051925659
Validation loss: 2.7377147059286795

Epoch: 5| Step: 3
Training loss: 2.7571861743927
Validation loss: 2.7390293459738455

Epoch: 5| Step: 4
Training loss: 3.4077019691467285
Validation loss: 2.741437107004145

Epoch: 5| Step: 5
Training loss: 2.3403916358947754
Validation loss: 2.739535741908576

Epoch: 5| Step: 6
Training loss: 2.3806095123291016
Validation loss: 2.745839975213492

Epoch: 5| Step: 7
Training loss: 3.529963254928589
Validation loss: 2.743821346631614

Epoch: 5| Step: 8
Training loss: 2.7431411743164062
Validation loss: 2.7376598517100015

Epoch: 5| Step: 9
Training loss: 2.4665145874023438
Validation loss: 2.737495437745125

Epoch: 5| Step: 10
Training loss: 1.917736291885376
Validation loss: 2.7355354601337063

Epoch: 21| Step: 0
Training loss: 2.474365711212158
Validation loss: 2.729814680673743

Epoch: 5| Step: 1
Training loss: 2.237389087677002
Validation loss: 2.7284056473803777

Epoch: 5| Step: 2
Training loss: 2.831524133682251
Validation loss: 2.727259171906338

Epoch: 5| Step: 3
Training loss: 3.455345630645752
Validation loss: 2.7290966074953795

Epoch: 5| Step: 4
Training loss: 3.252699375152588
Validation loss: 2.7300478181531354

Epoch: 5| Step: 5
Training loss: 2.6015090942382812
Validation loss: 2.727310449846329

Epoch: 5| Step: 6
Training loss: 2.6415998935699463
Validation loss: 2.7261626310245965

Epoch: 5| Step: 7
Training loss: 3.452096462249756
Validation loss: 2.7272436490622898

Epoch: 5| Step: 8
Training loss: 3.364229679107666
Validation loss: 2.7258121608405985

Epoch: 5| Step: 9
Training loss: 2.2179226875305176
Validation loss: 2.7249624216428368

Epoch: 5| Step: 10
Training loss: 3.29610013961792
Validation loss: 2.7253568198091243

Epoch: 22| Step: 0
Training loss: 2.4505648612976074
Validation loss: 2.7225210923020557

Epoch: 5| Step: 1
Training loss: 2.990389585494995
Validation loss: 2.7240633990174983

Epoch: 5| Step: 2
Training loss: 2.940145969390869
Validation loss: 2.7208597454973447

Epoch: 5| Step: 3
Training loss: 3.4993343353271484
Validation loss: 2.7213719250053487

Epoch: 5| Step: 4
Training loss: 2.362156391143799
Validation loss: 2.720185466991958

Epoch: 5| Step: 5
Training loss: 2.6070854663848877
Validation loss: 2.717925307571247

Epoch: 5| Step: 6
Training loss: 2.9160027503967285
Validation loss: 2.7192961400555027

Epoch: 5| Step: 7
Training loss: 3.652186632156372
Validation loss: 2.717142976740355

Epoch: 5| Step: 8
Training loss: 2.5680229663848877
Validation loss: 2.718509103662224

Epoch: 5| Step: 9
Training loss: 2.967459201812744
Validation loss: 2.7191187104871197

Epoch: 5| Step: 10
Training loss: 2.724867105484009
Validation loss: 2.7165724231350805

Epoch: 23| Step: 0
Training loss: 2.0311942100524902
Validation loss: 2.714314330008722

Epoch: 5| Step: 1
Training loss: 3.7015182971954346
Validation loss: 2.7132548747524137

Epoch: 5| Step: 2
Training loss: 2.896592617034912
Validation loss: 2.713178465443273

Epoch: 5| Step: 3
Training loss: 2.972099781036377
Validation loss: 2.7111676969835834

Epoch: 5| Step: 4
Training loss: 2.527556896209717
Validation loss: 2.710216934962939

Epoch: 5| Step: 5
Training loss: 3.5082499980926514
Validation loss: 2.713095777778215

Epoch: 5| Step: 6
Training loss: 3.1058478355407715
Validation loss: 2.7086638917205152

Epoch: 5| Step: 7
Training loss: 2.5916669368743896
Validation loss: 2.711889756623135

Epoch: 5| Step: 8
Training loss: 3.2740752696990967
Validation loss: 2.7185676790052846

Epoch: 5| Step: 9
Training loss: 2.3837504386901855
Validation loss: 2.7109756290271716

Epoch: 5| Step: 10
Training loss: 2.5991170406341553
Validation loss: 2.706978464639315

Epoch: 24| Step: 0
Training loss: 2.973778247833252
Validation loss: 2.7080556705433834

Epoch: 5| Step: 1
Training loss: 2.534369945526123
Validation loss: 2.7085780225774294

Epoch: 5| Step: 2
Training loss: 2.42753267288208
Validation loss: 2.7088801168626353

Epoch: 5| Step: 3
Training loss: 2.6577634811401367
Validation loss: 2.7085319334460842

Epoch: 5| Step: 4
Training loss: 2.876528263092041
Validation loss: 2.7086966012113836

Epoch: 5| Step: 5
Training loss: 3.025550603866577
Validation loss: 2.710195126072053

Epoch: 5| Step: 6
Training loss: 2.5420444011688232
Validation loss: 2.7063958414139284

Epoch: 5| Step: 7
Training loss: 3.6499195098876953
Validation loss: 2.708852688471476

Epoch: 5| Step: 8
Training loss: 3.1469831466674805
Validation loss: 2.706834964854743

Epoch: 5| Step: 9
Training loss: 3.08722186088562
Validation loss: 2.704652552963585

Epoch: 5| Step: 10
Training loss: 2.6053755283355713
Validation loss: 2.707332703375047

Epoch: 25| Step: 0
Training loss: 2.4717912673950195
Validation loss: 2.7058955315620667

Epoch: 5| Step: 1
Training loss: 2.898893356323242
Validation loss: 2.7206896581957416

Epoch: 5| Step: 2
Training loss: 2.715663194656372
Validation loss: 2.7183711451868855

Epoch: 5| Step: 3
Training loss: 2.6723761558532715
Validation loss: 2.7039577499512704

Epoch: 5| Step: 4
Training loss: 2.7867319583892822
Validation loss: 2.7006482744729645

Epoch: 5| Step: 5
Training loss: 2.837054967880249
Validation loss: 2.7040274168855403

Epoch: 5| Step: 6
Training loss: 2.523324489593506
Validation loss: 2.7030450990123134

Epoch: 5| Step: 7
Training loss: 3.254680633544922
Validation loss: 2.6999816843258437

Epoch: 5| Step: 8
Training loss: 2.812906265258789
Validation loss: 2.700669006634784

Epoch: 5| Step: 9
Training loss: 3.0759708881378174
Validation loss: 2.721243791682746

Epoch: 5| Step: 10
Training loss: 3.618887424468994
Validation loss: 2.711297929927867

Epoch: 26| Step: 0
Training loss: 2.2866733074188232
Validation loss: 2.6987839488572973

Epoch: 5| Step: 1
Training loss: 2.8346500396728516
Validation loss: 2.6988141049620924

Epoch: 5| Step: 2
Training loss: 2.808518648147583
Validation loss: 2.7113068795973256

Epoch: 5| Step: 3
Training loss: 2.759653091430664
Validation loss: 2.7294937308116625

Epoch: 5| Step: 4
Training loss: 2.6153006553649902
Validation loss: 2.7452332973480225

Epoch: 5| Step: 5
Training loss: 3.675670623779297
Validation loss: 2.7285638445167133

Epoch: 5| Step: 6
Training loss: 2.2426981925964355
Validation loss: 2.7114741674033542

Epoch: 5| Step: 7
Training loss: 2.3790760040283203
Validation loss: 2.704132690224596

Epoch: 5| Step: 8
Training loss: 3.6655972003936768
Validation loss: 2.697015828983758

Epoch: 5| Step: 9
Training loss: 2.738255739212036
Validation loss: 2.7016621302532893

Epoch: 5| Step: 10
Training loss: 3.561417579650879
Validation loss: 2.696147011172387

Epoch: 27| Step: 0
Training loss: 2.703105926513672
Validation loss: 2.6991361494987243

Epoch: 5| Step: 1
Training loss: 2.391571521759033
Validation loss: 2.697465906861008

Epoch: 5| Step: 2
Training loss: 2.3767013549804688
Validation loss: 2.6957217493364887

Epoch: 5| Step: 3
Training loss: 3.532224178314209
Validation loss: 2.6995628290278937

Epoch: 5| Step: 4
Training loss: 2.981079339981079
Validation loss: 2.691029261517268

Epoch: 5| Step: 5
Training loss: 3.2976317405700684
Validation loss: 2.687612033659412

Epoch: 5| Step: 6
Training loss: 3.1486916542053223
Validation loss: 2.6854674841768

Epoch: 5| Step: 7
Training loss: 2.323584794998169
Validation loss: 2.686739908751621

Epoch: 5| Step: 8
Training loss: 3.2099220752716064
Validation loss: 2.6853355259023686

Epoch: 5| Step: 9
Training loss: 3.0047571659088135
Validation loss: 2.683877968019055

Epoch: 5| Step: 10
Training loss: 2.359633684158325
Validation loss: 2.6848417097522366

Epoch: 28| Step: 0
Training loss: 2.9339945316314697
Validation loss: 2.6835215822342904

Epoch: 5| Step: 1
Training loss: 2.624828815460205
Validation loss: 2.687786402240876

Epoch: 5| Step: 2
Training loss: 2.6340219974517822
Validation loss: 2.710896658641036

Epoch: 5| Step: 3
Training loss: 3.0572550296783447
Validation loss: 2.6987354845129032

Epoch: 5| Step: 4
Training loss: 2.29628324508667
Validation loss: 2.684183589873775

Epoch: 5| Step: 5
Training loss: 2.853745937347412
Validation loss: 2.680107093626453

Epoch: 5| Step: 6
Training loss: 3.3014633655548096
Validation loss: 2.683117666552144

Epoch: 5| Step: 7
Training loss: 2.478747606277466
Validation loss: 2.6811291274204048

Epoch: 5| Step: 8
Training loss: 3.0416600704193115
Validation loss: 2.679668882841705

Epoch: 5| Step: 9
Training loss: 3.1961193084716797
Validation loss: 2.6807572072552097

Epoch: 5| Step: 10
Training loss: 2.8981683254241943
Validation loss: 2.6798929117059194

Epoch: 29| Step: 0
Training loss: 3.4599075317382812
Validation loss: 2.675508576054727

Epoch: 5| Step: 1
Training loss: 2.814558506011963
Validation loss: 2.675211978215043

Epoch: 5| Step: 2
Training loss: 3.7946949005126953
Validation loss: 2.6722872693051576

Epoch: 5| Step: 3
Training loss: 2.5909764766693115
Validation loss: 2.6745320161183677

Epoch: 5| Step: 4
Training loss: 2.8342044353485107
Validation loss: 2.675629141510174

Epoch: 5| Step: 5
Training loss: 2.351998805999756
Validation loss: 2.6774148479584725

Epoch: 5| Step: 6
Training loss: 2.8579089641571045
Validation loss: 2.67875535257401

Epoch: 5| Step: 7
Training loss: 2.618441581726074
Validation loss: 2.6675408963234193

Epoch: 5| Step: 8
Training loss: 2.367079496383667
Validation loss: 2.670261780420939

Epoch: 5| Step: 9
Training loss: 2.700831890106201
Validation loss: 2.6671185160195954

Epoch: 5| Step: 10
Training loss: 2.7864315509796143
Validation loss: 2.6600877187585317

Epoch: 30| Step: 0
Training loss: 3.505573272705078
Validation loss: 2.6597193979447886

Epoch: 5| Step: 1
Training loss: 2.805880308151245
Validation loss: 2.6594388984864756

Epoch: 5| Step: 2
Training loss: 2.2453994750976562
Validation loss: 2.6620813133896037

Epoch: 5| Step: 3
Training loss: 3.109504222869873
Validation loss: 2.65915011846891

Epoch: 5| Step: 4
Training loss: 2.511096477508545
Validation loss: 2.669992281544593

Epoch: 5| Step: 5
Training loss: 3.1166129112243652
Validation loss: 2.6704352107099307

Epoch: 5| Step: 6
Training loss: 3.390178680419922
Validation loss: 2.657965265294557

Epoch: 5| Step: 7
Training loss: 2.8889644145965576
Validation loss: 2.654447804215134

Epoch: 5| Step: 8
Training loss: 2.4595065116882324
Validation loss: 2.6559607777544247

Epoch: 5| Step: 9
Training loss: 2.5670390129089355
Validation loss: 2.650937811020882

Epoch: 5| Step: 10
Training loss: 2.4320156574249268
Validation loss: 2.651991992868403

Epoch: 31| Step: 0
Training loss: 2.7709124088287354
Validation loss: 2.6781274887823288

Epoch: 5| Step: 1
Training loss: 2.7701401710510254
Validation loss: 2.727088515476514

Epoch: 5| Step: 2
Training loss: 2.8356831073760986
Validation loss: 2.7957136682284776

Epoch: 5| Step: 3
Training loss: 2.643028736114502
Validation loss: 2.848557687574817

Epoch: 5| Step: 4
Training loss: 4.029313564300537
Validation loss: 2.802846577859694

Epoch: 5| Step: 5
Training loss: 2.677612781524658
Validation loss: 2.7297161471459175

Epoch: 5| Step: 6
Training loss: 2.2350945472717285
Validation loss: 2.7111746393224245

Epoch: 5| Step: 7
Training loss: 3.180795669555664
Validation loss: 2.7023412719849618

Epoch: 5| Step: 8
Training loss: 3.0026397705078125
Validation loss: 2.7094450612221994

Epoch: 5| Step: 9
Training loss: 2.440138578414917
Validation loss: 2.6574037869771323

Epoch: 5| Step: 10
Training loss: 2.961209297180176
Validation loss: 2.652270460641512

Epoch: 32| Step: 0
Training loss: 2.880126714706421
Validation loss: 2.649947533043482

Epoch: 5| Step: 1
Training loss: 2.517697811126709
Validation loss: 2.65583860745994

Epoch: 5| Step: 2
Training loss: 2.4604289531707764
Validation loss: 2.6643401653535905

Epoch: 5| Step: 3
Training loss: 2.780442714691162
Validation loss: 2.6673191362811672

Epoch: 5| Step: 4
Training loss: 3.897578477859497
Validation loss: 2.6659580661404516

Epoch: 5| Step: 5
Training loss: 3.0571722984313965
Validation loss: 2.689142647609916

Epoch: 5| Step: 6
Training loss: 2.3367011547088623
Validation loss: 2.741294999276438

Epoch: 5| Step: 7
Training loss: 2.9788403511047363
Validation loss: 2.743505765033025

Epoch: 5| Step: 8
Training loss: 2.813028335571289
Validation loss: 2.74805635534307

Epoch: 5| Step: 9
Training loss: 2.5422797203063965
Validation loss: 2.7444037519475466

Epoch: 5| Step: 10
Training loss: 3.047823190689087
Validation loss: 2.7265282805247972

Epoch: 33| Step: 0
Training loss: 2.7312304973602295
Validation loss: 2.7017756354424263

Epoch: 5| Step: 1
Training loss: 2.2901549339294434
Validation loss: 2.6997727681231756

Epoch: 5| Step: 2
Training loss: 2.573401927947998
Validation loss: 2.6878397567297823

Epoch: 5| Step: 3
Training loss: 3.114955186843872
Validation loss: 2.64553762251331

Epoch: 5| Step: 4
Training loss: 2.9175076484680176
Validation loss: 2.6537461562823226

Epoch: 5| Step: 5
Training loss: 2.116711378097534
Validation loss: 2.649312678203788

Epoch: 5| Step: 6
Training loss: 2.5679421424865723
Validation loss: 2.6364493011146464

Epoch: 5| Step: 7
Training loss: 2.8800225257873535
Validation loss: 2.638034964120516

Epoch: 5| Step: 8
Training loss: 3.541085720062256
Validation loss: 2.6450260839154645

Epoch: 5| Step: 9
Training loss: 4.0881452560424805
Validation loss: 2.6209056095410417

Epoch: 5| Step: 10
Training loss: 2.012423515319824
Validation loss: 2.6162435059906333

Epoch: 34| Step: 0
Training loss: 3.2721638679504395
Validation loss: 2.6132041408169653

Epoch: 5| Step: 1
Training loss: 2.95192813873291
Validation loss: 2.6171678496945288

Epoch: 5| Step: 2
Training loss: 2.2964651584625244
Validation loss: 2.6218711663317937

Epoch: 5| Step: 3
Training loss: 3.1775171756744385
Validation loss: 2.621761219475859

Epoch: 5| Step: 4
Training loss: 2.889890432357788
Validation loss: 2.6272697576912503

Epoch: 5| Step: 5
Training loss: 2.870227336883545
Validation loss: 2.624190048504901

Epoch: 5| Step: 6
Training loss: 2.5445642471313477
Validation loss: 2.6173677752094884

Epoch: 5| Step: 7
Training loss: 2.429075241088867
Validation loss: 2.6114737269698933

Epoch: 5| Step: 8
Training loss: 2.644599437713623
Validation loss: 2.606320029945784

Epoch: 5| Step: 9
Training loss: 2.367842197418213
Validation loss: 2.609794650026547

Epoch: 5| Step: 10
Training loss: 3.374422073364258
Validation loss: 2.606582933856595

Epoch: 35| Step: 0
Training loss: 2.8307061195373535
Validation loss: 2.6008906031167633

Epoch: 5| Step: 1
Training loss: 2.7714245319366455
Validation loss: 2.6049202949770036

Epoch: 5| Step: 2
Training loss: 3.270833969116211
Validation loss: 2.6002566199148855

Epoch: 5| Step: 3
Training loss: 2.5457866191864014
Validation loss: 2.59812452203484

Epoch: 5| Step: 4
Training loss: 2.698617458343506
Validation loss: 2.600289770351943

Epoch: 5| Step: 5
Training loss: 2.9711756706237793
Validation loss: 2.6092380862082205

Epoch: 5| Step: 6
Training loss: 1.8255033493041992
Validation loss: 2.6101875715358283

Epoch: 5| Step: 7
Training loss: 2.5057952404022217
Validation loss: 2.6033506829251527

Epoch: 5| Step: 8
Training loss: 2.6223196983337402
Validation loss: 2.600762833831131

Epoch: 5| Step: 9
Training loss: 3.1387665271759033
Validation loss: 2.59473144367177

Epoch: 5| Step: 10
Training loss: 3.4873321056365967
Validation loss: 2.592332504128897

Epoch: 36| Step: 0
Training loss: 3.247295379638672
Validation loss: 2.598519504711192

Epoch: 5| Step: 1
Training loss: 2.180729866027832
Validation loss: 2.601208125391314

Epoch: 5| Step: 2
Training loss: 3.4868226051330566
Validation loss: 2.6205367170354372

Epoch: 5| Step: 3
Training loss: 3.2663989067077637
Validation loss: 2.618858891148721

Epoch: 5| Step: 4
Training loss: 1.918787956237793
Validation loss: 2.610938584932717

Epoch: 5| Step: 5
Training loss: 2.3212313652038574
Validation loss: 2.584830748137607

Epoch: 5| Step: 6
Training loss: 2.80810284614563
Validation loss: 2.60047580862558

Epoch: 5| Step: 7
Training loss: 2.5225718021392822
Validation loss: 2.6128371864236812

Epoch: 5| Step: 8
Training loss: 3.455573320388794
Validation loss: 2.5995820260817006

Epoch: 5| Step: 9
Training loss: 2.8796050548553467
Validation loss: 2.57656192779541

Epoch: 5| Step: 10
Training loss: 2.393489122390747
Validation loss: 2.5656525909259753

Epoch: 37| Step: 0
Training loss: 3.2290759086608887
Validation loss: 2.5778126844795803

Epoch: 5| Step: 1
Training loss: 2.1986334323883057
Validation loss: 2.5797323693511305

Epoch: 5| Step: 2
Training loss: 2.127673387527466
Validation loss: 2.580754990218788

Epoch: 5| Step: 3
Training loss: 2.348802089691162
Validation loss: 2.5861814483519523

Epoch: 5| Step: 4
Training loss: 2.829869270324707
Validation loss: 2.5984951501251548

Epoch: 5| Step: 5
Training loss: 3.713071346282959
Validation loss: 2.588880567140477

Epoch: 5| Step: 6
Training loss: 3.66388201713562
Validation loss: 2.5768668343943935

Epoch: 5| Step: 7
Training loss: 2.1829993724823
Validation loss: 2.568028168011737

Epoch: 5| Step: 8
Training loss: 2.613865613937378
Validation loss: 2.556947769657258

Epoch: 5| Step: 9
Training loss: 2.641181468963623
Validation loss: 2.555395375015915

Epoch: 5| Step: 10
Training loss: 2.79443359375
Validation loss: 2.5660403441357356

Epoch: 38| Step: 0
Training loss: 2.946406841278076
Validation loss: 2.591610557289534

Epoch: 5| Step: 1
Training loss: 2.8963093757629395
Validation loss: 2.624519476326563

Epoch: 5| Step: 2
Training loss: 2.5249764919281006
Validation loss: 2.6309612284424486

Epoch: 5| Step: 3
Training loss: 2.7050652503967285
Validation loss: 2.590929200572352

Epoch: 5| Step: 4
Training loss: 2.624091625213623
Validation loss: 2.569557584742064

Epoch: 5| Step: 5
Training loss: 2.9153225421905518
Validation loss: 2.586555222029327

Epoch: 5| Step: 6
Training loss: 2.2335031032562256
Validation loss: 2.5868519147237143

Epoch: 5| Step: 7
Training loss: 3.073897123336792
Validation loss: 2.6154309447093675

Epoch: 5| Step: 8
Training loss: 2.101135730743408
Validation loss: 2.6562646896608415

Epoch: 5| Step: 9
Training loss: 3.7371551990509033
Validation loss: 2.6603373532654135

Epoch: 5| Step: 10
Training loss: 2.9190731048583984
Validation loss: 2.6308904386335805

Epoch: 39| Step: 0
Training loss: 3.3220763206481934
Validation loss: 2.60860929694227

Epoch: 5| Step: 1
Training loss: 2.4333949089050293
Validation loss: 2.548646032169301

Epoch: 5| Step: 2
Training loss: 3.0289225578308105
Validation loss: 2.544366862184258

Epoch: 5| Step: 3
Training loss: 2.8407249450683594
Validation loss: 2.5431664605294504

Epoch: 5| Step: 4
Training loss: 3.1567718982696533
Validation loss: 2.5472576566921767

Epoch: 5| Step: 5
Training loss: 2.8997912406921387
Validation loss: 2.549334067170338

Epoch: 5| Step: 6
Training loss: 2.471487045288086
Validation loss: 2.578969699080272

Epoch: 5| Step: 7
Training loss: 2.562798023223877
Validation loss: 2.5714444601407616

Epoch: 5| Step: 8
Training loss: 2.7405548095703125
Validation loss: 2.5560771111519105

Epoch: 5| Step: 9
Training loss: 2.3960723876953125
Validation loss: 2.5363153514041694

Epoch: 5| Step: 10
Training loss: 2.343777656555176
Validation loss: 2.552927827322355

Epoch: 40| Step: 0
Training loss: 3.572152614593506
Validation loss: 2.5473073836295836

Epoch: 5| Step: 1
Training loss: 2.3587374687194824
Validation loss: 2.5329369319382535

Epoch: 5| Step: 2
Training loss: 3.1030092239379883
Validation loss: 2.55516448584936

Epoch: 5| Step: 3
Training loss: 2.510916233062744
Validation loss: 2.5812180067903254

Epoch: 5| Step: 4
Training loss: 3.138800621032715
Validation loss: 2.604635364265852

Epoch: 5| Step: 5
Training loss: 2.7418904304504395
Validation loss: 2.5952952549021733

Epoch: 5| Step: 6
Training loss: 2.94706130027771
Validation loss: 2.5730010488981843

Epoch: 5| Step: 7
Training loss: 2.9654018878936768
Validation loss: 2.5546603638638734

Epoch: 5| Step: 8
Training loss: 2.3583285808563232
Validation loss: 2.5389414474528325

Epoch: 5| Step: 9
Training loss: 1.950971007347107
Validation loss: 2.533793839075232

Epoch: 5| Step: 10
Training loss: 2.537355661392212
Validation loss: 2.5290571412732525

Epoch: 41| Step: 0
Training loss: 2.437047243118286
Validation loss: 2.5295340835407214

Epoch: 5| Step: 1
Training loss: 3.0807299613952637
Validation loss: 2.5275978657507125

Epoch: 5| Step: 2
Training loss: 2.4887588024139404
Validation loss: 2.526971588852585

Epoch: 5| Step: 3
Training loss: 3.140350103378296
Validation loss: 2.5236198620129655

Epoch: 5| Step: 4
Training loss: 3.1430022716522217
Validation loss: 2.520612806402227

Epoch: 5| Step: 5
Training loss: 2.1075778007507324
Validation loss: 2.5189460323702906

Epoch: 5| Step: 6
Training loss: 2.3872947692871094
Validation loss: 2.5143263724542435

Epoch: 5| Step: 7
Training loss: 2.7364563941955566
Validation loss: 2.5133728519562752

Epoch: 5| Step: 8
Training loss: 2.8397529125213623
Validation loss: 2.5106694236878426

Epoch: 5| Step: 9
Training loss: 2.5667130947113037
Validation loss: 2.5114328835600164

Epoch: 5| Step: 10
Training loss: 3.1153252124786377
Validation loss: 2.509691094839445

Epoch: 42| Step: 0
Training loss: 2.8298463821411133
Validation loss: 2.5112538465889553

Epoch: 5| Step: 1
Training loss: 3.0972983837127686
Validation loss: 2.510014434014597

Epoch: 5| Step: 2
Training loss: 3.1248674392700195
Validation loss: 2.510895388100737

Epoch: 5| Step: 3
Training loss: 2.137237787246704
Validation loss: 2.510330879560081

Epoch: 5| Step: 4
Training loss: 2.7206428050994873
Validation loss: 2.5098334076584026

Epoch: 5| Step: 5
Training loss: 2.6206793785095215
Validation loss: 2.5087899238832536

Epoch: 5| Step: 6
Training loss: 2.278978109359741
Validation loss: 2.5093146934304187

Epoch: 5| Step: 7
Training loss: 2.1401515007019043
Validation loss: 2.5132537195759435

Epoch: 5| Step: 8
Training loss: 2.964139699935913
Validation loss: 2.5143331302109586

Epoch: 5| Step: 9
Training loss: 2.610363006591797
Validation loss: 2.5156233592699935

Epoch: 5| Step: 10
Training loss: 3.4050207138061523
Validation loss: 2.51245589153741

Epoch: 43| Step: 0
Training loss: 2.233454465866089
Validation loss: 2.5112779114836004

Epoch: 5| Step: 1
Training loss: 2.245894193649292
Validation loss: 2.520873103090512

Epoch: 5| Step: 2
Training loss: 2.5877323150634766
Validation loss: 2.5349386840738277

Epoch: 5| Step: 3
Training loss: 3.0222854614257812
Validation loss: 2.555007019350606

Epoch: 5| Step: 4
Training loss: 2.854048490524292
Validation loss: 2.5651720416161323

Epoch: 5| Step: 5
Training loss: 2.986626148223877
Validation loss: 2.5627238519730104

Epoch: 5| Step: 6
Training loss: 2.7795050144195557
Validation loss: 2.554420894192111

Epoch: 5| Step: 7
Training loss: 2.4421894550323486
Validation loss: 2.537293703325333

Epoch: 5| Step: 8
Training loss: 2.5732388496398926
Validation loss: 2.5195190368160123

Epoch: 5| Step: 9
Training loss: 3.5032143592834473
Validation loss: 2.50958655470161

Epoch: 5| Step: 10
Training loss: 2.769852876663208
Validation loss: 2.4983188977805515

Epoch: 44| Step: 0
Training loss: 1.6173572540283203
Validation loss: 2.5006283124287925

Epoch: 5| Step: 1
Training loss: 2.332911968231201
Validation loss: 2.5035459303086802

Epoch: 5| Step: 2
Training loss: 2.545706272125244
Validation loss: 2.506213895736202

Epoch: 5| Step: 3
Training loss: 2.387873888015747
Validation loss: 2.4994384140096684

Epoch: 5| Step: 4
Training loss: 2.7430481910705566
Validation loss: 2.493213253636514

Epoch: 5| Step: 5
Training loss: 3.376513719558716
Validation loss: 2.4940344825867684

Epoch: 5| Step: 6
Training loss: 3.0617780685424805
Validation loss: 2.4996435770424466

Epoch: 5| Step: 7
Training loss: 2.505937337875366
Validation loss: 2.519450133846652

Epoch: 5| Step: 8
Training loss: 2.540595531463623
Validation loss: 2.566969984321184

Epoch: 5| Step: 9
Training loss: 3.229607343673706
Validation loss: 2.581466213349373

Epoch: 5| Step: 10
Training loss: 3.7380237579345703
Validation loss: 2.598697334207514

Epoch: 45| Step: 0
Training loss: 2.7681877613067627
Validation loss: 2.5432500223959646

Epoch: 5| Step: 1
Training loss: 2.902716636657715
Validation loss: 2.5107873460297943

Epoch: 5| Step: 2
Training loss: 2.226616621017456
Validation loss: 2.497522877108666

Epoch: 5| Step: 3
Training loss: 2.781634569168091
Validation loss: 2.4817635359302646

Epoch: 5| Step: 4
Training loss: 2.1703805923461914
Validation loss: 2.4725258914373254

Epoch: 5| Step: 5
Training loss: 2.5735819339752197
Validation loss: 2.46986311481845

Epoch: 5| Step: 6
Training loss: 3.064850330352783
Validation loss: 2.4706474222162718

Epoch: 5| Step: 7
Training loss: 2.8307249546051025
Validation loss: 2.4755681945431616

Epoch: 5| Step: 8
Training loss: 2.6564388275146484
Validation loss: 2.4808872438246206

Epoch: 5| Step: 9
Training loss: 2.581815481185913
Validation loss: 2.4826115690251833

Epoch: 5| Step: 10
Training loss: 3.0829286575317383
Validation loss: 2.4828141222717943

Epoch: 46| Step: 0
Training loss: 1.9998409748077393
Validation loss: 2.4773675498142036

Epoch: 5| Step: 1
Training loss: 2.49190616607666
Validation loss: 2.4734140211536038

Epoch: 5| Step: 2
Training loss: 3.2442574501037598
Validation loss: 2.4688482156363865

Epoch: 5| Step: 3
Training loss: 3.26926851272583
Validation loss: 2.470639685148834

Epoch: 5| Step: 4
Training loss: 2.823326349258423
Validation loss: 2.4720788822379163

Epoch: 5| Step: 5
Training loss: 2.371400833129883
Validation loss: 2.4667719641039447

Epoch: 5| Step: 6
Training loss: 2.869471788406372
Validation loss: 2.4655041463913454

Epoch: 5| Step: 7
Training loss: 2.2579550743103027
Validation loss: 2.4647950254460818

Epoch: 5| Step: 8
Training loss: 2.851074695587158
Validation loss: 2.4668964775659705

Epoch: 5| Step: 9
Training loss: 2.755605697631836
Validation loss: 2.464428286398611

Epoch: 5| Step: 10
Training loss: 2.7249763011932373
Validation loss: 2.4641874836337183

Epoch: 47| Step: 0
Training loss: 2.5815281867980957
Validation loss: 2.4690398811012186

Epoch: 5| Step: 1
Training loss: 2.7178006172180176
Validation loss: 2.4757172164096626

Epoch: 5| Step: 2
Training loss: 3.2019195556640625
Validation loss: 2.4818598608816824

Epoch: 5| Step: 3
Training loss: 3.2823092937469482
Validation loss: 2.4949818657290552

Epoch: 5| Step: 4
Training loss: 1.7669236660003662
Validation loss: 2.4875202512228363

Epoch: 5| Step: 5
Training loss: 2.364431619644165
Validation loss: 2.493204903858964

Epoch: 5| Step: 6
Training loss: 2.402371883392334
Validation loss: 2.4948542707709858

Epoch: 5| Step: 7
Training loss: 2.997927188873291
Validation loss: 2.5060576777304373

Epoch: 5| Step: 8
Training loss: 2.632368803024292
Validation loss: 2.5032364424838813

Epoch: 5| Step: 9
Training loss: 3.075209617614746
Validation loss: 2.482422564619331

Epoch: 5| Step: 10
Training loss: 2.6196963787078857
Validation loss: 2.478706298335906

Epoch: 48| Step: 0
Training loss: 2.079300880432129
Validation loss: 2.473333761256228

Epoch: 5| Step: 1
Training loss: 2.510733127593994
Validation loss: 2.464450910527219

Epoch: 5| Step: 2
Training loss: 2.054025650024414
Validation loss: 2.475755745364774

Epoch: 5| Step: 3
Training loss: 2.5524680614471436
Validation loss: 2.5335391311235327

Epoch: 5| Step: 4
Training loss: 2.5549464225769043
Validation loss: 2.575629472732544

Epoch: 5| Step: 5
Training loss: 2.832217216491699
Validation loss: 2.5514989975960023

Epoch: 5| Step: 6
Training loss: 2.9041051864624023
Validation loss: 2.5404593021638933

Epoch: 5| Step: 7
Training loss: 3.449277400970459
Validation loss: 2.5098725339417816

Epoch: 5| Step: 8
Training loss: 2.652503490447998
Validation loss: 2.4811568362738496

Epoch: 5| Step: 9
Training loss: 2.925767421722412
Validation loss: 2.464758283348494

Epoch: 5| Step: 10
Training loss: 3.404634714126587
Validation loss: 2.4807005697681057

Epoch: 49| Step: 0
Training loss: 2.9274497032165527
Validation loss: 2.5016901185435634

Epoch: 5| Step: 1
Training loss: 2.4878227710723877
Validation loss: 2.480427203639861

Epoch: 5| Step: 2
Training loss: 2.024942636489868
Validation loss: 2.4801664198598554

Epoch: 5| Step: 3
Training loss: 2.2557976245880127
Validation loss: 2.462330989940192

Epoch: 5| Step: 4
Training loss: 2.723832130432129
Validation loss: 2.4508468310038247

Epoch: 5| Step: 5
Training loss: 3.205946683883667
Validation loss: 2.445530427399502

Epoch: 5| Step: 6
Training loss: 2.7632720470428467
Validation loss: 2.441831542599586

Epoch: 5| Step: 7
Training loss: 2.5701537132263184
Validation loss: 2.4418030605521253

Epoch: 5| Step: 8
Training loss: 3.4142894744873047
Validation loss: 2.4393949149757304

Epoch: 5| Step: 9
Training loss: 2.1799614429473877
Validation loss: 2.4449184991980113

Epoch: 5| Step: 10
Training loss: 2.9916741847991943
Validation loss: 2.450681404400897

Epoch: 50| Step: 0
Training loss: 2.605851411819458
Validation loss: 2.4461614880510556

Epoch: 5| Step: 1
Training loss: 2.353311061859131
Validation loss: 2.442911937672605

Epoch: 5| Step: 2
Training loss: 2.9511942863464355
Validation loss: 2.4425334212600545

Epoch: 5| Step: 3
Training loss: 2.180866241455078
Validation loss: 2.438770640280939

Epoch: 5| Step: 4
Training loss: 2.7280921936035156
Validation loss: 2.4390406736763577

Epoch: 5| Step: 5
Training loss: 2.5919411182403564
Validation loss: 2.4378571202678065

Epoch: 5| Step: 6
Training loss: 2.7274346351623535
Validation loss: 2.4393400684479745

Epoch: 5| Step: 7
Training loss: 3.350710391998291
Validation loss: 2.4377371316315024

Epoch: 5| Step: 8
Training loss: 2.5864980220794678
Validation loss: 2.4359424601319017

Epoch: 5| Step: 9
Training loss: 2.5896568298339844
Validation loss: 2.441315581721644

Epoch: 5| Step: 10
Training loss: 2.793712854385376
Validation loss: 2.44481328482269

Epoch: 51| Step: 0
Training loss: 2.903637647628784
Validation loss: 2.4493063265277493

Epoch: 5| Step: 1
Training loss: 2.1733577251434326
Validation loss: 2.4557956880138767

Epoch: 5| Step: 2
Training loss: 2.312533378601074
Validation loss: 2.4492086056740052

Epoch: 5| Step: 3
Training loss: 2.6749989986419678
Validation loss: 2.439013732376919

Epoch: 5| Step: 4
Training loss: 2.5898146629333496
Validation loss: 2.438483479202435

Epoch: 5| Step: 5
Training loss: 2.603065013885498
Validation loss: 2.4360437162460817

Epoch: 5| Step: 6
Training loss: 3.053234577178955
Validation loss: 2.4357445573294036

Epoch: 5| Step: 7
Training loss: 2.414139986038208
Validation loss: 2.4355573807993243

Epoch: 5| Step: 8
Training loss: 2.863097667694092
Validation loss: 2.439320147678416

Epoch: 5| Step: 9
Training loss: 2.994011163711548
Validation loss: 2.440114405847365

Epoch: 5| Step: 10
Training loss: 2.655348777770996
Validation loss: 2.434939161423714

Epoch: 52| Step: 0
Training loss: 2.6617884635925293
Validation loss: 2.4343523030639975

Epoch: 5| Step: 1
Training loss: 2.2507688999176025
Validation loss: 2.4296513936852895

Epoch: 5| Step: 2
Training loss: 2.8707756996154785
Validation loss: 2.429905629927112

Epoch: 5| Step: 3
Training loss: 2.0597777366638184
Validation loss: 2.4299480197250203

Epoch: 5| Step: 4
Training loss: 2.5525448322296143
Validation loss: 2.436235394529117

Epoch: 5| Step: 5
Training loss: 3.097672462463379
Validation loss: 2.4361080943897204

Epoch: 5| Step: 6
Training loss: 3.014605760574341
Validation loss: 2.437534163075109

Epoch: 5| Step: 7
Training loss: 3.2938690185546875
Validation loss: 2.445319021901777

Epoch: 5| Step: 8
Training loss: 2.3361003398895264
Validation loss: 2.437869587252217

Epoch: 5| Step: 9
Training loss: 3.0794315338134766
Validation loss: 2.4427522202973724

Epoch: 5| Step: 10
Training loss: 1.8873034715652466
Validation loss: 2.4346762241855746

Epoch: 53| Step: 0
Training loss: 2.4913527965545654
Validation loss: 2.436478991662302

Epoch: 5| Step: 1
Training loss: 1.8629086017608643
Validation loss: 2.441844645366874

Epoch: 5| Step: 2
Training loss: 2.8820033073425293
Validation loss: 2.4437503840333674

Epoch: 5| Step: 3
Training loss: 2.64931058883667
Validation loss: 2.4492920957585818

Epoch: 5| Step: 4
Training loss: 2.2027230262756348
Validation loss: 2.4498167422509964

Epoch: 5| Step: 5
Training loss: 2.4877612590789795
Validation loss: 2.446389008593816

Epoch: 5| Step: 6
Training loss: 2.8453381061553955
Validation loss: 2.4416696640752975

Epoch: 5| Step: 7
Training loss: 3.2011539936065674
Validation loss: 2.439354770927019

Epoch: 5| Step: 8
Training loss: 2.2945661544799805
Validation loss: 2.4402186998756985

Epoch: 5| Step: 9
Training loss: 2.8960514068603516
Validation loss: 2.4449459968074674

Epoch: 5| Step: 10
Training loss: 3.5694942474365234
Validation loss: 2.450219267158098

Epoch: 54| Step: 0
Training loss: 2.2387259006500244
Validation loss: 2.4453759885603383

Epoch: 5| Step: 1
Training loss: 3.518343687057495
Validation loss: 2.4331749972476753

Epoch: 5| Step: 2
Training loss: 2.5795633792877197
Validation loss: 2.432184560324556

Epoch: 5| Step: 3
Training loss: 2.9309592247009277
Validation loss: 2.4195511879459506

Epoch: 5| Step: 4
Training loss: 2.6167068481445312
Validation loss: 2.417163914249789

Epoch: 5| Step: 5
Training loss: 2.377439498901367
Validation loss: 2.415691670551095

Epoch: 5| Step: 6
Training loss: 2.3596084117889404
Validation loss: 2.415172211585506

Epoch: 5| Step: 7
Training loss: 2.6125264167785645
Validation loss: 2.4180395936453216

Epoch: 5| Step: 8
Training loss: 2.562110424041748
Validation loss: 2.4279719270685667

Epoch: 5| Step: 9
Training loss: 2.512469530105591
Validation loss: 2.435756908949985

Epoch: 5| Step: 10
Training loss: 2.885619640350342
Validation loss: 2.454783926727951

Epoch: 55| Step: 0
Training loss: 2.0127005577087402
Validation loss: 2.487760915551134

Epoch: 5| Step: 1
Training loss: 2.848071575164795
Validation loss: 2.474157347474047

Epoch: 5| Step: 2
Training loss: 2.6139087677001953
Validation loss: 2.437064581019904

Epoch: 5| Step: 3
Training loss: 2.5893232822418213
Validation loss: 2.4196797365783365

Epoch: 5| Step: 4
Training loss: 3.2654366493225098
Validation loss: 2.409050021120297

Epoch: 5| Step: 5
Training loss: 2.5601394176483154
Validation loss: 2.4117278078550934

Epoch: 5| Step: 6
Training loss: 2.792121171951294
Validation loss: 2.4268741043665076

Epoch: 5| Step: 7
Training loss: 2.7457354068756104
Validation loss: 2.4729819297790527

Epoch: 5| Step: 8
Training loss: 2.822672128677368
Validation loss: 2.511433332197128

Epoch: 5| Step: 9
Training loss: 2.462817430496216
Validation loss: 2.5406133667115243

Epoch: 5| Step: 10
Training loss: 2.782306432723999
Validation loss: 2.5968897932319233

Epoch: 56| Step: 0
Training loss: 3.278017044067383
Validation loss: 2.5391620051476265

Epoch: 5| Step: 1
Training loss: 2.4910202026367188
Validation loss: 2.5114054654234197

Epoch: 5| Step: 2
Training loss: 3.2001330852508545
Validation loss: 2.499908152446952

Epoch: 5| Step: 3
Training loss: 1.9360637664794922
Validation loss: 2.4831667433502855

Epoch: 5| Step: 4
Training loss: 2.1221413612365723
Validation loss: 2.4855343039317797

Epoch: 5| Step: 5
Training loss: 2.4534358978271484
Validation loss: 2.500686794198969

Epoch: 5| Step: 6
Training loss: 3.0759685039520264
Validation loss: 2.498600962341473

Epoch: 5| Step: 7
Training loss: 3.117959499359131
Validation loss: 2.5110138103526127

Epoch: 5| Step: 8
Training loss: 2.8260936737060547
Validation loss: 2.5093148293033725

Epoch: 5| Step: 9
Training loss: 2.6517844200134277
Validation loss: 2.5080653159849104

Epoch: 5| Step: 10
Training loss: 2.3798575401306152
Validation loss: 2.497041230560631

Epoch: 57| Step: 0
Training loss: 3.535315752029419
Validation loss: 2.497624933078725

Epoch: 5| Step: 1
Training loss: 2.62559175491333
Validation loss: 2.489007088445848

Epoch: 5| Step: 2
Training loss: 2.118020534515381
Validation loss: 2.4797636847342215

Epoch: 5| Step: 3
Training loss: 2.9156460762023926
Validation loss: 2.471123057027017

Epoch: 5| Step: 4
Training loss: 2.91416072845459
Validation loss: 2.467687065883349

Epoch: 5| Step: 5
Training loss: 2.327202320098877
Validation loss: 2.472801693024174

Epoch: 5| Step: 6
Training loss: 2.8793914318084717
Validation loss: 2.473411565185875

Epoch: 5| Step: 7
Training loss: 2.3352668285369873
Validation loss: 2.4669523085317304

Epoch: 5| Step: 8
Training loss: 2.2855324745178223
Validation loss: 2.458893140157064

Epoch: 5| Step: 9
Training loss: 2.4925427436828613
Validation loss: 2.457198037896105

Epoch: 5| Step: 10
Training loss: 3.012310743331909
Validation loss: 2.4615262862174743

Epoch: 58| Step: 0
Training loss: 2.9379665851593018
Validation loss: 2.461990192372312

Epoch: 5| Step: 1
Training loss: 2.842525005340576
Validation loss: 2.4689003190686627

Epoch: 5| Step: 2
Training loss: 3.194594144821167
Validation loss: 2.4752123368683683

Epoch: 5| Step: 3
Training loss: 2.8260080814361572
Validation loss: 2.4762547528871925

Epoch: 5| Step: 4
Training loss: 2.7133069038391113
Validation loss: 2.4712203215527278

Epoch: 5| Step: 5
Training loss: 2.2530956268310547
Validation loss: 2.482537741302162

Epoch: 5| Step: 6
Training loss: 2.6991751194000244
Validation loss: 2.4996906147208264

Epoch: 5| Step: 7
Training loss: 1.910930871963501
Validation loss: 2.480651793941375

Epoch: 5| Step: 8
Training loss: 2.876376152038574
Validation loss: 2.4545136754230787

Epoch: 5| Step: 9
Training loss: 2.7097268104553223
Validation loss: 2.44840342767777

Epoch: 5| Step: 10
Training loss: 2.281550645828247
Validation loss: 2.4481673522662093

Epoch: 59| Step: 0
Training loss: 2.6767635345458984
Validation loss: 2.4448188145955405

Epoch: 5| Step: 1
Training loss: 2.4987964630126953
Validation loss: 2.4470589353192236

Epoch: 5| Step: 2
Training loss: 3.1691818237304688
Validation loss: 2.448243389847458

Epoch: 5| Step: 3
Training loss: 3.245758056640625
Validation loss: 2.4480824624338458

Epoch: 5| Step: 4
Training loss: 1.9614570140838623
Validation loss: 2.4445748508617444

Epoch: 5| Step: 5
Training loss: 2.5847578048706055
Validation loss: 2.4480956959468063

Epoch: 5| Step: 6
Training loss: 2.6096811294555664
Validation loss: 2.4488474245994323

Epoch: 5| Step: 7
Training loss: 2.976400852203369
Validation loss: 2.455407496421568

Epoch: 5| Step: 8
Training loss: 2.623654842376709
Validation loss: 2.4681510643292497

Epoch: 5| Step: 9
Training loss: 2.555494785308838
Validation loss: 2.4543318389564432

Epoch: 5| Step: 10
Training loss: 2.4122602939605713
Validation loss: 2.453238010406494

Epoch: 60| Step: 0
Training loss: 2.7417449951171875
Validation loss: 2.4509228557668705

Epoch: 5| Step: 1
Training loss: 2.324990749359131
Validation loss: 2.4510454593166227

Epoch: 5| Step: 2
Training loss: 2.5987682342529297
Validation loss: 2.454309889065322

Epoch: 5| Step: 3
Training loss: 2.944674253463745
Validation loss: 2.4588701084095943

Epoch: 5| Step: 4
Training loss: 2.454258441925049
Validation loss: 2.4560335015737884

Epoch: 5| Step: 5
Training loss: 2.657017946243286
Validation loss: 2.4580201564296598

Epoch: 5| Step: 6
Training loss: 2.616300582885742
Validation loss: 2.4564889438690676

Epoch: 5| Step: 7
Training loss: 2.8115758895874023
Validation loss: 2.4573904186166744

Epoch: 5| Step: 8
Training loss: 2.570502758026123
Validation loss: 2.456271222842637

Epoch: 5| Step: 9
Training loss: 2.780397653579712
Validation loss: 2.4524860894808205

Epoch: 5| Step: 10
Training loss: 2.8314507007598877
Validation loss: 2.4500520126793974

Epoch: 61| Step: 0
Training loss: 2.4212729930877686
Validation loss: 2.445761083274759

Epoch: 5| Step: 1
Training loss: 3.3425323963165283
Validation loss: 2.4420425302238873

Epoch: 5| Step: 2
Training loss: 2.4868502616882324
Validation loss: 2.436745887161583

Epoch: 5| Step: 3
Training loss: 2.706113338470459
Validation loss: 2.4354354643052623

Epoch: 5| Step: 4
Training loss: 2.697680711746216
Validation loss: 2.4350461139473865

Epoch: 5| Step: 5
Training loss: 3.0598866939544678
Validation loss: 2.434401378836683

Epoch: 5| Step: 6
Training loss: 2.212905168533325
Validation loss: 2.4309830973225255

Epoch: 5| Step: 7
Training loss: 2.75785756111145
Validation loss: 2.436325732097831

Epoch: 5| Step: 8
Training loss: 2.558605909347534
Validation loss: 2.4322460479633783

Epoch: 5| Step: 9
Training loss: 2.569545269012451
Validation loss: 2.4314023884393836

Epoch: 5| Step: 10
Training loss: 2.4189577102661133
Validation loss: 2.424587065173734

Epoch: 62| Step: 0
Training loss: 2.842855215072632
Validation loss: 2.4255245500995266

Epoch: 5| Step: 1
Training loss: 2.447044610977173
Validation loss: 2.421503613072057

Epoch: 5| Step: 2
Training loss: 2.6971864700317383
Validation loss: 2.4236775572581957

Epoch: 5| Step: 3
Training loss: 2.4222521781921387
Validation loss: 2.4246573294362714

Epoch: 5| Step: 4
Training loss: 2.750624418258667
Validation loss: 2.4301163124781784

Epoch: 5| Step: 5
Training loss: 2.8320624828338623
Validation loss: 2.426138154921993

Epoch: 5| Step: 6
Training loss: 2.499983310699463
Validation loss: 2.427779807839342

Epoch: 5| Step: 7
Training loss: 2.81620717048645
Validation loss: 2.42635936890879

Epoch: 5| Step: 8
Training loss: 2.9532291889190674
Validation loss: 2.4248534761449343

Epoch: 5| Step: 9
Training loss: 2.7897303104400635
Validation loss: 2.42353287178983

Epoch: 5| Step: 10
Training loss: 2.009934902191162
Validation loss: 2.427990136608001

Epoch: 63| Step: 0
Training loss: 2.537522315979004
Validation loss: 2.4365316821682836

Epoch: 5| Step: 1
Training loss: 2.5848093032836914
Validation loss: 2.4465130708550893

Epoch: 5| Step: 2
Training loss: 2.430659294128418
Validation loss: 2.4417959015856505

Epoch: 5| Step: 3
Training loss: 2.5410966873168945
Validation loss: 2.4369960318329515

Epoch: 5| Step: 4
Training loss: 2.77323579788208
Validation loss: 2.437956679251886

Epoch: 5| Step: 5
Training loss: 2.9385316371917725
Validation loss: 2.4404441977059967

Epoch: 5| Step: 6
Training loss: 2.4795451164245605
Validation loss: 2.436328741811937

Epoch: 5| Step: 7
Training loss: 1.9588340520858765
Validation loss: 2.427538325709681

Epoch: 5| Step: 8
Training loss: 2.925128698348999
Validation loss: 2.4234024837452877

Epoch: 5| Step: 9
Training loss: 3.287980556488037
Validation loss: 2.419001175511268

Epoch: 5| Step: 10
Training loss: 2.6608705520629883
Validation loss: 2.4119937342982136

Epoch: 64| Step: 0
Training loss: 3.0600056648254395
Validation loss: 2.408459383954284

Epoch: 5| Step: 1
Training loss: 2.3873093128204346
Validation loss: 2.4068092582046345

Epoch: 5| Step: 2
Training loss: 2.4717276096343994
Validation loss: 2.4115850028171333

Epoch: 5| Step: 3
Training loss: 2.7222557067871094
Validation loss: 2.4147032383949525

Epoch: 5| Step: 4
Training loss: 2.9922292232513428
Validation loss: 2.4129661360094623

Epoch: 5| Step: 5
Training loss: 2.409719467163086
Validation loss: 2.4138877481542607

Epoch: 5| Step: 6
Training loss: 2.870943784713745
Validation loss: 2.414967272871284

Epoch: 5| Step: 7
Training loss: 2.2160308361053467
Validation loss: 2.4178736620051886

Epoch: 5| Step: 8
Training loss: 3.0835366249084473
Validation loss: 2.4225071527624644

Epoch: 5| Step: 9
Training loss: 2.6861023902893066
Validation loss: 2.425270631749143

Epoch: 5| Step: 10
Training loss: 2.3494884967803955
Validation loss: 2.4190093137884654

Epoch: 65| Step: 0
Training loss: 2.418208122253418
Validation loss: 2.4188163972670034

Epoch: 5| Step: 1
Training loss: 3.2885303497314453
Validation loss: 2.414227439511207

Epoch: 5| Step: 2
Training loss: 2.492172956466675
Validation loss: 2.4130280581853722

Epoch: 5| Step: 3
Training loss: 2.504936695098877
Validation loss: 2.414446307766822

Epoch: 5| Step: 4
Training loss: 2.603947639465332
Validation loss: 2.4151236088045183

Epoch: 5| Step: 5
Training loss: 2.55216646194458
Validation loss: 2.420294956494403

Epoch: 5| Step: 6
Training loss: 2.4041690826416016
Validation loss: 2.420165677224436

Epoch: 5| Step: 7
Training loss: 2.934691905975342
Validation loss: 2.429828566889609

Epoch: 5| Step: 8
Training loss: 3.245434284210205
Validation loss: 2.429547402166551

Epoch: 5| Step: 9
Training loss: 2.5049123764038086
Validation loss: 2.431637120503251

Epoch: 5| Step: 10
Training loss: 2.0572614669799805
Validation loss: 2.438919231455813

Epoch: 66| Step: 0
Training loss: 2.6908607482910156
Validation loss: 2.4307350317637124

Epoch: 5| Step: 1
Training loss: 2.6372718811035156
Validation loss: 2.4329445592818724

Epoch: 5| Step: 2
Training loss: 2.3180012702941895
Validation loss: 2.4219831830711773

Epoch: 5| Step: 3
Training loss: 2.5500946044921875
Validation loss: 2.4110427018134826

Epoch: 5| Step: 4
Training loss: 3.008678913116455
Validation loss: 2.422000397918045

Epoch: 5| Step: 5
Training loss: 3.1268651485443115
Validation loss: 2.4176726366883967

Epoch: 5| Step: 6
Training loss: 2.310864210128784
Validation loss: 2.4194987409858295

Epoch: 5| Step: 7
Training loss: 2.547128200531006
Validation loss: 2.420717323980024

Epoch: 5| Step: 8
Training loss: 2.6140453815460205
Validation loss: 2.4165424890415643

Epoch: 5| Step: 9
Training loss: 3.040114402770996
Validation loss: 2.4161682180179063

Epoch: 5| Step: 10
Training loss: 2.0668513774871826
Validation loss: 2.4111704569990917

Epoch: 67| Step: 0
Training loss: 2.493823528289795
Validation loss: 2.406923863195604

Epoch: 5| Step: 1
Training loss: 2.419363498687744
Validation loss: 2.3985267403305217

Epoch: 5| Step: 2
Training loss: 2.5130386352539062
Validation loss: 2.397907213498187

Epoch: 5| Step: 3
Training loss: 2.097902297973633
Validation loss: 2.393287697146016

Epoch: 5| Step: 4
Training loss: 2.9773478507995605
Validation loss: 2.3919841730466453

Epoch: 5| Step: 5
Training loss: 2.66474986076355
Validation loss: 2.3911040726528374

Epoch: 5| Step: 6
Training loss: 3.1860556602478027
Validation loss: 2.3991630820817846

Epoch: 5| Step: 7
Training loss: 2.440142869949341
Validation loss: 2.4037606946883665

Epoch: 5| Step: 8
Training loss: 2.4926960468292236
Validation loss: 2.4039202890088482

Epoch: 5| Step: 9
Training loss: 2.9897329807281494
Validation loss: 2.4110881410619265

Epoch: 5| Step: 10
Training loss: 2.8255364894866943
Validation loss: 2.4050575046129126

Epoch: 68| Step: 0
Training loss: 3.055241107940674
Validation loss: 2.392285623858052

Epoch: 5| Step: 1
Training loss: 3.155797243118286
Validation loss: 2.391692384596794

Epoch: 5| Step: 2
Training loss: 2.531733751296997
Validation loss: 2.3867920342312066

Epoch: 5| Step: 3
Training loss: 2.740264415740967
Validation loss: 2.39360805737075

Epoch: 5| Step: 4
Training loss: 2.508504867553711
Validation loss: 2.4010802853491997

Epoch: 5| Step: 5
Training loss: 2.259498119354248
Validation loss: 2.4123290431114937

Epoch: 5| Step: 6
Training loss: 2.5065462589263916
Validation loss: 2.4126843688308552

Epoch: 5| Step: 7
Training loss: 2.723646402359009
Validation loss: 2.416965328237062

Epoch: 5| Step: 8
Training loss: 1.66360604763031
Validation loss: 2.4035629790316344

Epoch: 5| Step: 9
Training loss: 2.9718728065490723
Validation loss: 2.395195298297431

Epoch: 5| Step: 10
Training loss: 2.9246442317962646
Validation loss: 2.3860332017303794

Epoch: 69| Step: 0
Training loss: 2.8008456230163574
Validation loss: 2.38682480524945

Epoch: 5| Step: 1
Training loss: 2.899075984954834
Validation loss: 2.395332213371031

Epoch: 5| Step: 2
Training loss: 2.252887725830078
Validation loss: 2.4156510855561946

Epoch: 5| Step: 3
Training loss: 1.6266193389892578
Validation loss: 2.4398905795107604

Epoch: 5| Step: 4
Training loss: 2.064791679382324
Validation loss: 2.4731894693067

Epoch: 5| Step: 5
Training loss: 3.208383560180664
Validation loss: 2.570551536416495

Epoch: 5| Step: 6
Training loss: 3.1033387184143066
Validation loss: 2.5151084366665093

Epoch: 5| Step: 7
Training loss: 2.9667797088623047
Validation loss: 2.43270444357267

Epoch: 5| Step: 8
Training loss: 3.0860915184020996
Validation loss: 2.3812156120936074

Epoch: 5| Step: 9
Training loss: 2.9080700874328613
Validation loss: 2.3860242494972805

Epoch: 5| Step: 10
Training loss: 2.539174795150757
Validation loss: 2.3988111352407806

Epoch: 70| Step: 0
Training loss: 2.4934306144714355
Validation loss: 2.4350507900279057

Epoch: 5| Step: 1
Training loss: 2.811384916305542
Validation loss: 2.4813001232762493

Epoch: 5| Step: 2
Training loss: 3.2919459342956543
Validation loss: 2.5152256027344735

Epoch: 5| Step: 3
Training loss: 2.313551664352417
Validation loss: 2.491056888334213

Epoch: 5| Step: 4
Training loss: 3.3088130950927734
Validation loss: 2.4447536737688127

Epoch: 5| Step: 5
Training loss: 2.1173717975616455
Validation loss: 2.395921837898993

Epoch: 5| Step: 6
Training loss: 2.330141067504883
Validation loss: 2.3743264316230692

Epoch: 5| Step: 7
Training loss: 2.8739023208618164
Validation loss: 2.368566241315616

Epoch: 5| Step: 8
Training loss: 2.93522572517395
Validation loss: 2.372347095961212

Epoch: 5| Step: 9
Training loss: 2.3145599365234375
Validation loss: 2.3764206158217562

Epoch: 5| Step: 10
Training loss: 2.447368860244751
Validation loss: 2.3836770314042286

Epoch: 71| Step: 0
Training loss: 2.415700674057007
Validation loss: 2.386118427399666

Epoch: 5| Step: 1
Training loss: 2.7339463233947754
Validation loss: 2.3858666727619786

Epoch: 5| Step: 2
Training loss: 2.580662727355957
Validation loss: 2.381805823695275

Epoch: 5| Step: 3
Training loss: 3.069096088409424
Validation loss: 2.383287032445272

Epoch: 5| Step: 4
Training loss: 2.438082218170166
Validation loss: 2.378693849809708

Epoch: 5| Step: 5
Training loss: 2.8491296768188477
Validation loss: 2.372682020228396

Epoch: 5| Step: 6
Training loss: 2.7146294116973877
Validation loss: 2.372145314370432

Epoch: 5| Step: 7
Training loss: 2.3073792457580566
Validation loss: 2.366397919193391

Epoch: 5| Step: 8
Training loss: 3.004781484603882
Validation loss: 2.3650380360182894

Epoch: 5| Step: 9
Training loss: 2.6190319061279297
Validation loss: 2.362034915595926

Epoch: 5| Step: 10
Training loss: 2.2950692176818848
Validation loss: 2.3663962912815872

Epoch: 72| Step: 0
Training loss: 2.9109320640563965
Validation loss: 2.366254355317803

Epoch: 5| Step: 1
Training loss: 2.596385955810547
Validation loss: 2.365651854904749

Epoch: 5| Step: 2
Training loss: 2.1934237480163574
Validation loss: 2.3693362128350044

Epoch: 5| Step: 3
Training loss: 2.6876296997070312
Validation loss: 2.3710013922824653

Epoch: 5| Step: 4
Training loss: 2.4109089374542236
Validation loss: 2.377569403699649

Epoch: 5| Step: 5
Training loss: 2.349682569503784
Validation loss: 2.3795121997915287

Epoch: 5| Step: 6
Training loss: 2.1085658073425293
Validation loss: 2.380512358039938

Epoch: 5| Step: 7
Training loss: 3.4036643505096436
Validation loss: 2.3883811325155277

Epoch: 5| Step: 8
Training loss: 3.1878247261047363
Validation loss: 2.395159516283261

Epoch: 5| Step: 9
Training loss: 2.611374855041504
Validation loss: 2.3992478693685224

Epoch: 5| Step: 10
Training loss: 2.433846950531006
Validation loss: 2.398095287302489

Epoch: 73| Step: 0
Training loss: 3.029200792312622
Validation loss: 2.411575335328297

Epoch: 5| Step: 1
Training loss: 2.8193488121032715
Validation loss: 2.4199890475119314

Epoch: 5| Step: 2
Training loss: 1.9712927341461182
Validation loss: 2.4235185089931695

Epoch: 5| Step: 3
Training loss: 2.2852988243103027
Validation loss: 2.419771960986558

Epoch: 5| Step: 4
Training loss: 2.711719036102295
Validation loss: 2.4139909539171445

Epoch: 5| Step: 5
Training loss: 2.3245387077331543
Validation loss: 2.4087572841234106

Epoch: 5| Step: 6
Training loss: 2.8027055263519287
Validation loss: 2.400644420295633

Epoch: 5| Step: 7
Training loss: 3.3959097862243652
Validation loss: 2.3990480540901102

Epoch: 5| Step: 8
Training loss: 2.6400163173675537
Validation loss: 2.386137234267368

Epoch: 5| Step: 9
Training loss: 2.5555970668792725
Validation loss: 2.3687195982984317

Epoch: 5| Step: 10
Training loss: 2.3082895278930664
Validation loss: 2.3585397863900788

Epoch: 74| Step: 0
Training loss: 2.618560314178467
Validation loss: 2.3525792309032973

Epoch: 5| Step: 1
Training loss: 2.55655574798584
Validation loss: 2.349407983082597

Epoch: 5| Step: 2
Training loss: 2.750230550765991
Validation loss: 2.343715619015437

Epoch: 5| Step: 3
Training loss: 2.2707300186157227
Validation loss: 2.3447052855645456

Epoch: 5| Step: 4
Training loss: 3.18902325630188
Validation loss: 2.3522954858759397

Epoch: 5| Step: 5
Training loss: 2.1833534240722656
Validation loss: 2.355542552086615

Epoch: 5| Step: 6
Training loss: 3.1185362339019775
Validation loss: 2.3585562603448027

Epoch: 5| Step: 7
Training loss: 2.5228917598724365
Validation loss: 2.3573228902714227

Epoch: 5| Step: 8
Training loss: 2.718029260635376
Validation loss: 2.3458749581408758

Epoch: 5| Step: 9
Training loss: 2.535332441329956
Validation loss: 2.342033606703563

Epoch: 5| Step: 10
Training loss: 2.2621309757232666
Validation loss: 2.3398888521297003

Epoch: 75| Step: 0
Training loss: 2.654154062271118
Validation loss: 2.340998734197309

Epoch: 5| Step: 1
Training loss: 2.217191457748413
Validation loss: 2.3381949265797934

Epoch: 5| Step: 2
Training loss: 2.7779347896575928
Validation loss: 2.3364314058775544

Epoch: 5| Step: 3
Training loss: 2.6102638244628906
Validation loss: 2.3399254096451627

Epoch: 5| Step: 4
Training loss: 2.8450379371643066
Validation loss: 2.3348260771843696

Epoch: 5| Step: 5
Training loss: 2.804749011993408
Validation loss: 2.3415931937515095

Epoch: 5| Step: 6
Training loss: 2.6170654296875
Validation loss: 2.3376237384734617

Epoch: 5| Step: 7
Training loss: 2.3361194133758545
Validation loss: 2.3421424255576184

Epoch: 5| Step: 8
Training loss: 2.4645602703094482
Validation loss: 2.340705769036406

Epoch: 5| Step: 9
Training loss: 2.5723330974578857
Validation loss: 2.337797457172025

Epoch: 5| Step: 10
Training loss: 2.6664481163024902
Validation loss: 2.337520081509826

Epoch: 76| Step: 0
Training loss: 2.8463244438171387
Validation loss: 2.3439416270102225

Epoch: 5| Step: 1
Training loss: 2.905447006225586
Validation loss: 2.3575802669730237

Epoch: 5| Step: 2
Training loss: 2.6910297870635986
Validation loss: 2.356574550751717

Epoch: 5| Step: 3
Training loss: 3.3279736042022705
Validation loss: 2.3580007578736994

Epoch: 5| Step: 4
Training loss: 2.3051095008850098
Validation loss: 2.347473403458954

Epoch: 5| Step: 5
Training loss: 2.4452219009399414
Validation loss: 2.3499889373779297

Epoch: 5| Step: 6
Training loss: 2.678098440170288
Validation loss: 2.3354466512639034

Epoch: 5| Step: 7
Training loss: 2.523144245147705
Validation loss: 2.3273896914656445

Epoch: 5| Step: 8
Training loss: 2.5263118743896484
Validation loss: 2.3292050579542756

Epoch: 5| Step: 9
Training loss: 2.6891939640045166
Validation loss: 2.327834138306238

Epoch: 5| Step: 10
Training loss: 1.462106466293335
Validation loss: 2.3325663561462076

Epoch: 77| Step: 0
Training loss: 2.666806697845459
Validation loss: 2.3360140913276264

Epoch: 5| Step: 1
Training loss: 2.856010913848877
Validation loss: 2.331621790444979

Epoch: 5| Step: 2
Training loss: 2.016166925430298
Validation loss: 2.3172496749508764

Epoch: 5| Step: 3
Training loss: 2.39866304397583
Validation loss: 2.327150542248962

Epoch: 5| Step: 4
Training loss: 2.4168381690979004
Validation loss: 2.320460875829061

Epoch: 5| Step: 5
Training loss: 2.4708800315856934
Validation loss: 2.325854883399061

Epoch: 5| Step: 6
Training loss: 2.7060208320617676
Validation loss: 2.3336193792281614

Epoch: 5| Step: 7
Training loss: 2.655089855194092
Validation loss: 2.3424794186827955

Epoch: 5| Step: 8
Training loss: 2.498190402984619
Validation loss: 2.353591554908342

Epoch: 5| Step: 9
Training loss: 2.624612331390381
Validation loss: 2.363693860269362

Epoch: 5| Step: 10
Training loss: 3.3628451824188232
Validation loss: 2.3636264672843357

Epoch: 78| Step: 0
Training loss: 3.1955769062042236
Validation loss: 2.349758078975062

Epoch: 5| Step: 1
Training loss: 2.603980779647827
Validation loss: 2.333325001501268

Epoch: 5| Step: 2
Training loss: 2.1050987243652344
Validation loss: 2.3227839482727872

Epoch: 5| Step: 3
Training loss: 3.022589683532715
Validation loss: 2.3153615536228305

Epoch: 5| Step: 4
Training loss: 2.5929787158966064
Validation loss: 2.306778957766871

Epoch: 5| Step: 5
Training loss: 2.7444422245025635
Validation loss: 2.303171657746838

Epoch: 5| Step: 6
Training loss: 2.458725690841675
Validation loss: 2.2961951481398715

Epoch: 5| Step: 7
Training loss: 2.6257166862487793
Validation loss: 2.2986612678855978

Epoch: 5| Step: 8
Training loss: 2.1480302810668945
Validation loss: 2.294874006702054

Epoch: 5| Step: 9
Training loss: 2.2697017192840576
Validation loss: 2.2921388764535227

Epoch: 5| Step: 10
Training loss: 2.672980546951294
Validation loss: 2.2897627558759464

Epoch: 79| Step: 0
Training loss: 3.112581491470337
Validation loss: 2.298217664482773

Epoch: 5| Step: 1
Training loss: 2.802194356918335
Validation loss: 2.296226252791702

Epoch: 5| Step: 2
Training loss: 2.4623260498046875
Validation loss: 2.301074884271109

Epoch: 5| Step: 3
Training loss: 2.396392345428467
Validation loss: 2.3053983257662867

Epoch: 5| Step: 4
Training loss: 2.7687230110168457
Validation loss: 2.3131936801377164

Epoch: 5| Step: 5
Training loss: 2.3370604515075684
Validation loss: 2.310041512212446

Epoch: 5| Step: 6
Training loss: 2.8354289531707764
Validation loss: 2.3212103843688965

Epoch: 5| Step: 7
Training loss: 2.826355457305908
Validation loss: 2.3442227609695925

Epoch: 5| Step: 8
Training loss: 2.2080726623535156
Validation loss: 2.321156447933566

Epoch: 5| Step: 9
Training loss: 2.1619651317596436
Validation loss: 2.3111443288864626

Epoch: 5| Step: 10
Training loss: 2.3283913135528564
Validation loss: 2.3098464960693033

Epoch: 80| Step: 0
Training loss: 1.8855869770050049
Validation loss: 2.315572715574695

Epoch: 5| Step: 1
Training loss: 3.092275857925415
Validation loss: 2.3286360104878745

Epoch: 5| Step: 2
Training loss: 2.6915230751037598
Validation loss: 2.332656873169766

Epoch: 5| Step: 3
Training loss: 2.592735767364502
Validation loss: 2.3253930999386694

Epoch: 5| Step: 4
Training loss: 2.473426103591919
Validation loss: 2.330407532312537

Epoch: 5| Step: 5
Training loss: 2.717712879180908
Validation loss: 2.3320881166765766

Epoch: 5| Step: 6
Training loss: 2.5529980659484863
Validation loss: 2.333954700859644

Epoch: 5| Step: 7
Training loss: 2.919215679168701
Validation loss: 2.3274905143245572

Epoch: 5| Step: 8
Training loss: 1.9540550708770752
Validation loss: 2.3119811268262964

Epoch: 5| Step: 9
Training loss: 2.4826064109802246
Validation loss: 2.2971050790561143

Epoch: 5| Step: 10
Training loss: 3.047412395477295
Validation loss: 2.2944649688659178

Epoch: 81| Step: 0
Training loss: 1.7344701290130615
Validation loss: 2.289532851147395

Epoch: 5| Step: 1
Training loss: 2.9278147220611572
Validation loss: 2.2794204142785843

Epoch: 5| Step: 2
Training loss: 2.8751864433288574
Validation loss: 2.2766351828011135

Epoch: 5| Step: 3
Training loss: 1.943028211593628
Validation loss: 2.277291620931318

Epoch: 5| Step: 4
Training loss: 3.1660447120666504
Validation loss: 2.2750844955444336

Epoch: 5| Step: 5
Training loss: 2.5141825675964355
Validation loss: 2.27471677718624

Epoch: 5| Step: 6
Training loss: 2.292407751083374
Validation loss: 2.267769746882941

Epoch: 5| Step: 7
Training loss: 2.7126526832580566
Validation loss: 2.271895254811933

Epoch: 5| Step: 8
Training loss: 2.8446924686431885
Validation loss: 2.2697926336719143

Epoch: 5| Step: 9
Training loss: 2.7396507263183594
Validation loss: 2.268393155067198

Epoch: 5| Step: 10
Training loss: 2.550889730453491
Validation loss: 2.265091262837892

Epoch: 82| Step: 0
Training loss: 3.05488657951355
Validation loss: 2.265760073097803

Epoch: 5| Step: 1
Training loss: 2.0428779125213623
Validation loss: 2.2819564675772064

Epoch: 5| Step: 2
Training loss: 1.949568748474121
Validation loss: 2.2835095544015207

Epoch: 5| Step: 3
Training loss: 2.6622517108917236
Validation loss: 2.2992050365735124

Epoch: 5| Step: 4
Training loss: 2.8823447227478027
Validation loss: 2.3250182802959154

Epoch: 5| Step: 5
Training loss: 1.9527959823608398
Validation loss: 2.3412795707743657

Epoch: 5| Step: 6
Training loss: 2.0718002319335938
Validation loss: 2.334761352949245

Epoch: 5| Step: 7
Training loss: 2.6592884063720703
Validation loss: 2.294005399109215

Epoch: 5| Step: 8
Training loss: 2.9579033851623535
Validation loss: 2.274694909331619

Epoch: 5| Step: 9
Training loss: 3.0386385917663574
Validation loss: 2.2876607884642897

Epoch: 5| Step: 10
Training loss: 3.0538742542266846
Validation loss: 2.288430639492568

Epoch: 83| Step: 0
Training loss: 2.847118854522705
Validation loss: 2.295072086395756

Epoch: 5| Step: 1
Training loss: 2.6775221824645996
Validation loss: 2.3092650264822026

Epoch: 5| Step: 2
Training loss: 2.7562241554260254
Validation loss: 2.3283663962476995

Epoch: 5| Step: 3
Training loss: 2.4042916297912598
Validation loss: 2.3599399956323768

Epoch: 5| Step: 4
Training loss: 2.1055922508239746
Validation loss: 2.386040077414564

Epoch: 5| Step: 5
Training loss: 1.9217067956924438
Validation loss: 2.3891875974593626

Epoch: 5| Step: 6
Training loss: 3.296099901199341
Validation loss: 2.3795934107995804

Epoch: 5| Step: 7
Training loss: 2.144395351409912
Validation loss: 2.3349334834724345

Epoch: 5| Step: 8
Training loss: 3.389676570892334
Validation loss: 2.312436370439427

Epoch: 5| Step: 9
Training loss: 2.8393802642822266
Validation loss: 2.2852622129583873

Epoch: 5| Step: 10
Training loss: 2.006256341934204
Validation loss: 2.290119924852925

Epoch: 84| Step: 0
Training loss: 3.0230681896209717
Validation loss: 2.307994996347735

Epoch: 5| Step: 1
Training loss: 2.1402382850646973
Validation loss: 2.3043621791306363

Epoch: 5| Step: 2
Training loss: 3.189288377761841
Validation loss: 2.335717498615224

Epoch: 5| Step: 3
Training loss: 2.287614345550537
Validation loss: 2.3466599987399195

Epoch: 5| Step: 4
Training loss: 2.3196024894714355
Validation loss: 2.3386493395733576

Epoch: 5| Step: 5
Training loss: 2.1061923503875732
Validation loss: 2.3263885974884033

Epoch: 5| Step: 6
Training loss: 2.7043981552124023
Validation loss: 2.3127346705364924

Epoch: 5| Step: 7
Training loss: 2.45576548576355
Validation loss: 2.292741460184897

Epoch: 5| Step: 8
Training loss: 2.5153419971466064
Validation loss: 2.2792827416491765

Epoch: 5| Step: 9
Training loss: 2.5485591888427734
Validation loss: 2.274374092778852

Epoch: 5| Step: 10
Training loss: 3.0571000576019287
Validation loss: 2.2803290403017433

Epoch: 85| Step: 0
Training loss: 2.8893051147460938
Validation loss: 2.2974330879026845

Epoch: 5| Step: 1
Training loss: 2.5712733268737793
Validation loss: 2.311777909596761

Epoch: 5| Step: 2
Training loss: 2.183973789215088
Validation loss: 2.3121146848124843

Epoch: 5| Step: 3
Training loss: 3.113454580307007
Validation loss: 2.3258048436974965

Epoch: 5| Step: 4
Training loss: 2.149287223815918
Validation loss: 2.3144033878080306

Epoch: 5| Step: 5
Training loss: 2.4258289337158203
Validation loss: 2.330773902195756

Epoch: 5| Step: 6
Training loss: 2.4972217082977295
Validation loss: 2.321633815765381

Epoch: 5| Step: 7
Training loss: 2.7975833415985107
Validation loss: 2.2938956727263746

Epoch: 5| Step: 8
Training loss: 2.132628917694092
Validation loss: 2.2688940955746557

Epoch: 5| Step: 9
Training loss: 2.797548770904541
Validation loss: 2.2674686831812703

Epoch: 5| Step: 10
Training loss: 3.0848491191864014
Validation loss: 2.2687632627384637

Epoch: 86| Step: 0
Training loss: 3.0586369037628174
Validation loss: 2.2761810428352764

Epoch: 5| Step: 1
Training loss: 3.09932279586792
Validation loss: 2.2883632926530737

Epoch: 5| Step: 2
Training loss: 2.6498379707336426
Validation loss: 2.2894595207706576

Epoch: 5| Step: 3
Training loss: 2.5176234245300293
Validation loss: 2.266662210546514

Epoch: 5| Step: 4
Training loss: 1.9964487552642822
Validation loss: 2.2710632226800405

Epoch: 5| Step: 5
Training loss: 2.576385974884033
Validation loss: 2.2677690393181256

Epoch: 5| Step: 6
Training loss: 2.4853813648223877
Validation loss: 2.2823646812028784

Epoch: 5| Step: 7
Training loss: 2.5288796424865723
Validation loss: 2.268255067128007

Epoch: 5| Step: 8
Training loss: 2.423844575881958
Validation loss: 2.265763818576772

Epoch: 5| Step: 9
Training loss: 2.280339479446411
Validation loss: 2.2537922474645797

Epoch: 5| Step: 10
Training loss: 2.341508626937866
Validation loss: 2.2582906625604116

Epoch: 87| Step: 0
Training loss: 2.5447824001312256
Validation loss: 2.2538009535881782

Epoch: 5| Step: 1
Training loss: 2.51031231880188
Validation loss: 2.2494101960171937

Epoch: 5| Step: 2
Training loss: 2.8932976722717285
Validation loss: 2.2419416545539774

Epoch: 5| Step: 3
Training loss: 2.7486650943756104
Validation loss: 2.235838423493088

Epoch: 5| Step: 4
Training loss: 2.4283995628356934
Validation loss: 2.230447789674164

Epoch: 5| Step: 5
Training loss: 2.732795238494873
Validation loss: 2.2419085579533733

Epoch: 5| Step: 6
Training loss: 2.5247812271118164
Validation loss: 2.261770982896128

Epoch: 5| Step: 7
Training loss: 2.4874322414398193
Validation loss: 2.281302231614308

Epoch: 5| Step: 8
Training loss: 2.535849094390869
Validation loss: 2.3217810943562496

Epoch: 5| Step: 9
Training loss: 2.1538681983947754
Validation loss: 2.3448543266583513

Epoch: 5| Step: 10
Training loss: 2.210928201675415
Validation loss: 2.3137392664468415

Epoch: 88| Step: 0
Training loss: 2.3653805255889893
Validation loss: 2.272328604934036

Epoch: 5| Step: 1
Training loss: 2.894117832183838
Validation loss: 2.233708243216238

Epoch: 5| Step: 2
Training loss: 2.6497702598571777
Validation loss: 2.2164904584166822

Epoch: 5| Step: 3
Training loss: 2.67211651802063
Validation loss: 2.2043663609412407

Epoch: 5| Step: 4
Training loss: 2.7057547569274902
Validation loss: 2.203281464115266

Epoch: 5| Step: 5
Training loss: 2.700005531311035
Validation loss: 2.207739463416479

Epoch: 5| Step: 6
Training loss: 1.8457149267196655
Validation loss: 2.205202671789354

Epoch: 5| Step: 7
Training loss: 2.455575466156006
Validation loss: 2.204334035996468

Epoch: 5| Step: 8
Training loss: 2.414815902709961
Validation loss: 2.2266204075146745

Epoch: 5| Step: 9
Training loss: 2.3910441398620605
Validation loss: 2.2338602863332278

Epoch: 5| Step: 10
Training loss: 2.551003932952881
Validation loss: 2.223187905485912

Epoch: 89| Step: 0
Training loss: 2.8335399627685547
Validation loss: 2.237352683979978

Epoch: 5| Step: 1
Training loss: 2.7472896575927734
Validation loss: 2.2686507483964324

Epoch: 5| Step: 2
Training loss: 2.6144754886627197
Validation loss: 2.2900232115099506

Epoch: 5| Step: 3
Training loss: 2.7632508277893066
Validation loss: 2.2969654170415734

Epoch: 5| Step: 4
Training loss: 2.2742087841033936
Validation loss: 2.287333947356029

Epoch: 5| Step: 5
Training loss: 1.982767105102539
Validation loss: 2.281342593572473

Epoch: 5| Step: 6
Training loss: 2.1043267250061035
Validation loss: 2.2793021689179125

Epoch: 5| Step: 7
Training loss: 3.522473096847534
Validation loss: 2.2776605544551725

Epoch: 5| Step: 8
Training loss: 3.038789749145508
Validation loss: 2.2688375878077682

Epoch: 5| Step: 9
Training loss: 1.9992954730987549
Validation loss: 2.2706302263403453

Epoch: 5| Step: 10
Training loss: 1.993822455406189
Validation loss: 2.2518531353242937

Epoch: 90| Step: 0
Training loss: 2.2399888038635254
Validation loss: 2.2522338090404386

Epoch: 5| Step: 1
Training loss: 2.0349221229553223
Validation loss: 2.247340198486082

Epoch: 5| Step: 2
Training loss: 2.832319736480713
Validation loss: 2.2410827144499748

Epoch: 5| Step: 3
Training loss: 2.1913399696350098
Validation loss: 2.2493995133266655

Epoch: 5| Step: 4
Training loss: 2.746910810470581
Validation loss: 2.2467898835418043

Epoch: 5| Step: 5
Training loss: 2.4910800457000732
Validation loss: 2.2487568060557046

Epoch: 5| Step: 6
Training loss: 1.9905275106430054
Validation loss: 2.2517663906979304

Epoch: 5| Step: 7
Training loss: 2.8244709968566895
Validation loss: 2.2489126600244993

Epoch: 5| Step: 8
Training loss: 2.7828731536865234
Validation loss: 2.253198564693492

Epoch: 5| Step: 9
Training loss: 2.6329243183135986
Validation loss: 2.248484339765323

Epoch: 5| Step: 10
Training loss: 3.1543638706207275
Validation loss: 2.242667169981105

Epoch: 91| Step: 0
Training loss: 3.0446181297302246
Validation loss: 2.2474741679365917

Epoch: 5| Step: 1
Training loss: 2.806006908416748
Validation loss: 2.2498923219660276

Epoch: 5| Step: 2
Training loss: 2.7080912590026855
Validation loss: 2.260280542476203

Epoch: 5| Step: 3
Training loss: 3.0137100219726562
Validation loss: 2.25632559099505

Epoch: 5| Step: 4
Training loss: 2.286543369293213
Validation loss: 2.253222729570122

Epoch: 5| Step: 5
Training loss: 2.846029043197632
Validation loss: 2.2516524919899563

Epoch: 5| Step: 6
Training loss: 1.9249223470687866
Validation loss: 2.2601396268413914

Epoch: 5| Step: 7
Training loss: 2.1815555095672607
Validation loss: 2.26003336650069

Epoch: 5| Step: 8
Training loss: 2.2741878032684326
Validation loss: 2.269213961016747

Epoch: 5| Step: 9
Training loss: 2.526207685470581
Validation loss: 2.2649360651611

Epoch: 5| Step: 10
Training loss: 2.058587074279785
Validation loss: 2.2623931566874185

Epoch: 92| Step: 0
Training loss: 2.5293450355529785
Validation loss: 2.2521321542801394

Epoch: 5| Step: 1
Training loss: 3.1043267250061035
Validation loss: 2.245852408870574

Epoch: 5| Step: 2
Training loss: 2.1323177814483643
Validation loss: 2.2451735363211682

Epoch: 5| Step: 3
Training loss: 2.647195816040039
Validation loss: 2.2344414880198817

Epoch: 5| Step: 4
Training loss: 2.033332586288452
Validation loss: 2.2268460745452554

Epoch: 5| Step: 5
Training loss: 2.161263942718506
Validation loss: 2.21289139152855

Epoch: 5| Step: 6
Training loss: 2.7700657844543457
Validation loss: 2.2249268216471516

Epoch: 5| Step: 7
Training loss: 2.246654987335205
Validation loss: 2.2278286808280536

Epoch: 5| Step: 8
Training loss: 2.234597682952881
Validation loss: 2.2536370549150693

Epoch: 5| Step: 9
Training loss: 2.5318057537078857
Validation loss: 2.264019241897009

Epoch: 5| Step: 10
Training loss: 3.2001638412475586
Validation loss: 2.220441641346101

Epoch: 93| Step: 0
Training loss: 2.51544451713562
Validation loss: 2.1996000428353586

Epoch: 5| Step: 1
Training loss: 2.333793878555298
Validation loss: 2.1852991786054385

Epoch: 5| Step: 2
Training loss: 2.368755340576172
Validation loss: 2.175180665908321

Epoch: 5| Step: 3
Training loss: 2.0316460132598877
Validation loss: 2.165900368844309

Epoch: 5| Step: 4
Training loss: 2.737055540084839
Validation loss: 2.1627077569243727

Epoch: 5| Step: 5
Training loss: 2.8669891357421875
Validation loss: 2.1745442677569646

Epoch: 5| Step: 6
Training loss: 2.2123141288757324
Validation loss: 2.175485090542865

Epoch: 5| Step: 7
Training loss: 2.574354648590088
Validation loss: 2.170621423311131

Epoch: 5| Step: 8
Training loss: 2.3666656017303467
Validation loss: 2.161192565835932

Epoch: 5| Step: 9
Training loss: 2.834284543991089
Validation loss: 2.1557930566931285

Epoch: 5| Step: 10
Training loss: 2.5468015670776367
Validation loss: 2.155550572179979

Epoch: 94| Step: 0
Training loss: 2.735943555831909
Validation loss: 2.15268845840167

Epoch: 5| Step: 1
Training loss: 2.4380252361297607
Validation loss: 2.1603794597810313

Epoch: 5| Step: 2
Training loss: 2.4615378379821777
Validation loss: 2.1758273442586265

Epoch: 5| Step: 3
Training loss: 2.354099988937378
Validation loss: 2.177281746300318

Epoch: 5| Step: 4
Training loss: 2.0211825370788574
Validation loss: 2.180874947578676

Epoch: 5| Step: 5
Training loss: 2.330399751663208
Validation loss: 2.1995396037255563

Epoch: 5| Step: 6
Training loss: 2.6159682273864746
Validation loss: 2.198726489979734

Epoch: 5| Step: 7
Training loss: 3.2000644207000732
Validation loss: 2.200912635813477

Epoch: 5| Step: 8
Training loss: 2.1302871704101562
Validation loss: 2.1877174556896253

Epoch: 5| Step: 9
Training loss: 2.1265711784362793
Validation loss: 2.1893038185693885

Epoch: 5| Step: 10
Training loss: 2.957845687866211
Validation loss: 2.1884653568267822

Epoch: 95| Step: 0
Training loss: 2.1942293643951416
Validation loss: 2.175880921784268

Epoch: 5| Step: 1
Training loss: 1.99668288230896
Validation loss: 2.1865815744605115

Epoch: 5| Step: 2
Training loss: 2.4297409057617188
Validation loss: 2.1795354017647366

Epoch: 5| Step: 3
Training loss: 2.2206175327301025
Validation loss: 2.1786582751940657

Epoch: 5| Step: 4
Training loss: 2.899348497390747
Validation loss: 2.1734380414409022

Epoch: 5| Step: 5
Training loss: 2.195899486541748
Validation loss: 2.1737209007304203

Epoch: 5| Step: 6
Training loss: 2.6451659202575684
Validation loss: 2.179411285667009

Epoch: 5| Step: 7
Training loss: 3.0746660232543945
Validation loss: 2.177726766114594

Epoch: 5| Step: 8
Training loss: 2.289626359939575
Validation loss: 2.184091667975149

Epoch: 5| Step: 9
Training loss: 2.7510364055633545
Validation loss: 2.19125456963816

Epoch: 5| Step: 10
Training loss: 2.3365302085876465
Validation loss: 2.2035038727585987

Epoch: 96| Step: 0
Training loss: 2.710106372833252
Validation loss: 2.21357463764888

Epoch: 5| Step: 1
Training loss: 2.4583585262298584
Validation loss: 2.224521126798404

Epoch: 5| Step: 2
Training loss: 2.346806764602661
Validation loss: 2.2102070098282187

Epoch: 5| Step: 3
Training loss: 2.4277830123901367
Validation loss: 2.1993559945014214

Epoch: 5| Step: 4
Training loss: 1.7366619110107422
Validation loss: 2.194298199428025

Epoch: 5| Step: 5
Training loss: 2.848374843597412
Validation loss: 2.179845699699976

Epoch: 5| Step: 6
Training loss: 2.6285560131073
Validation loss: 2.162119004034227

Epoch: 5| Step: 7
Training loss: 2.391188383102417
Validation loss: 2.1609363812272266

Epoch: 5| Step: 8
Training loss: 2.6753487586975098
Validation loss: 2.163975792546426

Epoch: 5| Step: 9
Training loss: 2.4546115398406982
Validation loss: 2.165842922784949

Epoch: 5| Step: 10
Training loss: 2.4614477157592773
Validation loss: 2.1706022318973335

Epoch: 97| Step: 0
Training loss: 1.9240410327911377
Validation loss: 2.176282154616489

Epoch: 5| Step: 1
Training loss: 2.935091257095337
Validation loss: 2.1694591711926203

Epoch: 5| Step: 2
Training loss: 2.7201757431030273
Validation loss: 2.1728275334963234

Epoch: 5| Step: 3
Training loss: 2.5789666175842285
Validation loss: 2.1673404965349423

Epoch: 5| Step: 4
Training loss: 2.6708791255950928
Validation loss: 2.1483957613668134

Epoch: 5| Step: 5
Training loss: 2.1244571208953857
Validation loss: 2.1399077600048435

Epoch: 5| Step: 6
Training loss: 1.9188053607940674
Validation loss: 2.143247483879007

Epoch: 5| Step: 7
Training loss: 2.444166660308838
Validation loss: 2.1364428381766043

Epoch: 5| Step: 8
Training loss: 2.7625014781951904
Validation loss: 2.1409291221249487

Epoch: 5| Step: 9
Training loss: 2.359565258026123
Validation loss: 2.154765313671481

Epoch: 5| Step: 10
Training loss: 2.660867214202881
Validation loss: 2.162176715430393

Epoch: 98| Step: 0
Training loss: 2.5112805366516113
Validation loss: 2.1790286212839107

Epoch: 5| Step: 1
Training loss: 2.7766525745391846
Validation loss: 2.1696765858639955

Epoch: 5| Step: 2
Training loss: 2.172935962677002
Validation loss: 2.1643960296466784

Epoch: 5| Step: 3
Training loss: 2.171586275100708
Validation loss: 2.149033764357208

Epoch: 5| Step: 4
Training loss: 2.3560261726379395
Validation loss: 2.1426738462140484

Epoch: 5| Step: 5
Training loss: 2.438382863998413
Validation loss: 2.130958523801578

Epoch: 5| Step: 6
Training loss: 2.443164348602295
Validation loss: 2.135112759887531

Epoch: 5| Step: 7
Training loss: 2.674038887023926
Validation loss: 2.1324589534472396

Epoch: 5| Step: 8
Training loss: 2.3909459114074707
Validation loss: 2.1418587469285533

Epoch: 5| Step: 9
Training loss: 2.1806626319885254
Validation loss: 2.1464621789993776

Epoch: 5| Step: 10
Training loss: 3.108649492263794
Validation loss: 2.1466940949040074

Epoch: 99| Step: 0
Training loss: 2.745239734649658
Validation loss: 2.160899328929122

Epoch: 5| Step: 1
Training loss: 2.89858078956604
Validation loss: 2.177438391152249

Epoch: 5| Step: 2
Training loss: 2.7813022136688232
Validation loss: 2.1756802143589145

Epoch: 5| Step: 3
Training loss: 2.375093460083008
Validation loss: 2.191292160300798

Epoch: 5| Step: 4
Training loss: 1.8119277954101562
Validation loss: 2.1859251658121743

Epoch: 5| Step: 5
Training loss: 2.6619210243225098
Validation loss: 2.169986658198859

Epoch: 5| Step: 6
Training loss: 2.911999464035034
Validation loss: 2.1499911636434574

Epoch: 5| Step: 7
Training loss: 2.6098265647888184
Validation loss: 2.1360280513763428

Epoch: 5| Step: 8
Training loss: 2.3542771339416504
Validation loss: 2.132723013559977

Epoch: 5| Step: 9
Training loss: 2.04388427734375
Validation loss: 2.131054243733806

Epoch: 5| Step: 10
Training loss: 1.827147364616394
Validation loss: 2.130993212423017

Epoch: 100| Step: 0
Training loss: 2.166238307952881
Validation loss: 2.1366091671810357

Epoch: 5| Step: 1
Training loss: 1.8650760650634766
Validation loss: 2.146587530771891

Epoch: 5| Step: 2
Training loss: 2.7388014793395996
Validation loss: 2.173626263936361

Epoch: 5| Step: 3
Training loss: 2.699512243270874
Validation loss: 2.2005643011421285

Epoch: 5| Step: 4
Training loss: 3.0900046825408936
Validation loss: 2.224596228650821

Epoch: 5| Step: 5
Training loss: 2.4191081523895264
Validation loss: 2.2404844350712274

Epoch: 5| Step: 6
Training loss: 3.199669361114502
Validation loss: 2.249642236258394

Epoch: 5| Step: 7
Training loss: 2.677731513977051
Validation loss: 2.2236376065079884

Epoch: 5| Step: 8
Training loss: 1.7823207378387451
Validation loss: 2.217683684441351

Epoch: 5| Step: 9
Training loss: 2.5319395065307617
Validation loss: 2.1972666440471524

Epoch: 5| Step: 10
Training loss: 1.9838470220565796
Validation loss: 2.190953936628116

Epoch: 101| Step: 0
Training loss: 1.7052175998687744
Validation loss: 2.192593079741283

Epoch: 5| Step: 1
Training loss: 2.2453408241271973
Validation loss: 2.1851639901438067

Epoch: 5| Step: 2
Training loss: 3.1272454261779785
Validation loss: 2.2012220608290805

Epoch: 5| Step: 3
Training loss: 1.8574130535125732
Validation loss: 2.2121620819132817

Epoch: 5| Step: 4
Training loss: 2.432673931121826
Validation loss: 2.2178321628160376

Epoch: 5| Step: 5
Training loss: 2.430837631225586
Validation loss: 2.2230084967869583

Epoch: 5| Step: 6
Training loss: 2.5758209228515625
Validation loss: 2.235965754396172

Epoch: 5| Step: 7
Training loss: 3.014939546585083
Validation loss: 2.2360682051668883

Epoch: 5| Step: 8
Training loss: 2.412654399871826
Validation loss: 2.2399390589806343

Epoch: 5| Step: 9
Training loss: 2.6384356021881104
Validation loss: 2.2327569505219818

Epoch: 5| Step: 10
Training loss: 3.0397262573242188
Validation loss: 2.240315724444646

Epoch: 102| Step: 0
Training loss: 2.3964364528656006
Validation loss: 2.229944243226

Epoch: 5| Step: 1
Training loss: 2.8438241481781006
Validation loss: 2.22578009482353

Epoch: 5| Step: 2
Training loss: 2.905264377593994
Validation loss: 2.2248954901131253

Epoch: 5| Step: 3
Training loss: 2.1676201820373535
Validation loss: 2.2081194718678794

Epoch: 5| Step: 4
Training loss: 2.2116494178771973
Validation loss: 2.1919440300233903

Epoch: 5| Step: 5
Training loss: 2.2669811248779297
Validation loss: 2.1801276232606623

Epoch: 5| Step: 6
Training loss: 2.6092453002929688
Validation loss: 2.1770198088820263

Epoch: 5| Step: 7
Training loss: 2.135467529296875
Validation loss: 2.1686580591304327

Epoch: 5| Step: 8
Training loss: 2.986013174057007
Validation loss: 2.1679216507942445

Epoch: 5| Step: 9
Training loss: 2.314396619796753
Validation loss: 2.1703280043858353

Epoch: 5| Step: 10
Training loss: 2.2453999519348145
Validation loss: 2.1848799361977527

Epoch: 103| Step: 0
Training loss: 2.143793821334839
Validation loss: 2.1766599429550992

Epoch: 5| Step: 1
Training loss: 2.1170029640197754
Validation loss: 2.153834596756966

Epoch: 5| Step: 2
Training loss: 3.6342906951904297
Validation loss: 2.137608012845439

Epoch: 5| Step: 3
Training loss: 2.368490219116211
Validation loss: 2.1202419752715738

Epoch: 5| Step: 4
Training loss: 2.171743392944336
Validation loss: 2.115881040532102

Epoch: 5| Step: 5
Training loss: 1.846825361251831
Validation loss: 2.1238953451956473

Epoch: 5| Step: 6
Training loss: 2.418457269668579
Validation loss: 2.1252019533547024

Epoch: 5| Step: 7
Training loss: 3.035094976425171
Validation loss: 2.1265511025664625

Epoch: 5| Step: 8
Training loss: 2.32883358001709
Validation loss: 2.1233390018504155

Epoch: 5| Step: 9
Training loss: 2.4368577003479004
Validation loss: 2.1268727523024364

Epoch: 5| Step: 10
Training loss: 2.535965919494629
Validation loss: 2.1159450956570205

Epoch: 104| Step: 0
Training loss: 1.7760894298553467
Validation loss: 2.123269118288512

Epoch: 5| Step: 1
Training loss: 2.512882709503174
Validation loss: 2.129892688925548

Epoch: 5| Step: 2
Training loss: 2.516741991043091
Validation loss: 2.146112529180383

Epoch: 5| Step: 3
Training loss: 3.0202577114105225
Validation loss: 2.164749289071688

Epoch: 5| Step: 4
Training loss: 2.769355297088623
Validation loss: 2.1636637692810385

Epoch: 5| Step: 5
Training loss: 2.2491185665130615
Validation loss: 2.166124197744554

Epoch: 5| Step: 6
Training loss: 2.764599561691284
Validation loss: 2.1379867356310607

Epoch: 5| Step: 7
Training loss: 2.3765289783477783
Validation loss: 2.1230976017572547

Epoch: 5| Step: 8
Training loss: 2.4975829124450684
Validation loss: 2.120746179293561

Epoch: 5| Step: 9
Training loss: 2.0591468811035156
Validation loss: 2.135940513303203

Epoch: 5| Step: 10
Training loss: 2.4274630546569824
Validation loss: 2.1377718602457354

Epoch: 105| Step: 0
Training loss: 2.314493417739868
Validation loss: 2.1292061113542124

Epoch: 5| Step: 1
Training loss: 1.9787280559539795
Validation loss: 2.1370063597156155

Epoch: 5| Step: 2
Training loss: 2.2708847522735596
Validation loss: 2.130668112026748

Epoch: 5| Step: 3
Training loss: 2.1347618103027344
Validation loss: 2.1239038821189635

Epoch: 5| Step: 4
Training loss: 2.3275694847106934
Validation loss: 2.124427277554748

Epoch: 5| Step: 5
Training loss: 2.919987440109253
Validation loss: 2.1927553428116666

Epoch: 5| Step: 6
Training loss: 2.7335195541381836
Validation loss: 2.2414731812733475

Epoch: 5| Step: 7
Training loss: 2.70121431350708
Validation loss: 2.245998583814149

Epoch: 5| Step: 8
Training loss: 2.398982286453247
Validation loss: 2.2385200223615094

Epoch: 5| Step: 9
Training loss: 2.7488627433776855
Validation loss: 2.2260534301880868

Epoch: 5| Step: 10
Training loss: 2.8461756706237793
Validation loss: 2.228173278993176

Epoch: 106| Step: 0
Training loss: 1.6323225498199463
Validation loss: 2.2367953138966716

Epoch: 5| Step: 1
Training loss: 2.6096301078796387
Validation loss: 2.2477550173318512

Epoch: 5| Step: 2
Training loss: 1.6994400024414062
Validation loss: 2.286823939251643

Epoch: 5| Step: 3
Training loss: 3.3793678283691406
Validation loss: 2.3314576379714476

Epoch: 5| Step: 4
Training loss: 2.857926845550537
Validation loss: 2.3076748847961426

Epoch: 5| Step: 5
Training loss: 2.590796709060669
Validation loss: 2.2212579301608506

Epoch: 5| Step: 6
Training loss: 3.129554510116577
Validation loss: 2.1464901624187345

Epoch: 5| Step: 7
Training loss: 2.606351375579834
Validation loss: 2.1389568108384327

Epoch: 5| Step: 8
Training loss: 2.4417216777801514
Validation loss: 2.159958644579816

Epoch: 5| Step: 9
Training loss: 2.652479648590088
Validation loss: 2.169894044117261

Epoch: 5| Step: 10
Training loss: 2.183206081390381
Validation loss: 2.1850564761828353

Epoch: 107| Step: 0
Training loss: 2.548950672149658
Validation loss: 2.181022295387842

Epoch: 5| Step: 1
Training loss: 2.767465114593506
Validation loss: 2.178189887795397

Epoch: 5| Step: 2
Training loss: 2.783463478088379
Validation loss: 2.157574761298395

Epoch: 5| Step: 3
Training loss: 2.6932880878448486
Validation loss: 2.1446151271943124

Epoch: 5| Step: 4
Training loss: 2.514846086502075
Validation loss: 2.1389850980492047

Epoch: 5| Step: 5
Training loss: 2.772876262664795
Validation loss: 2.130057127245011

Epoch: 5| Step: 6
Training loss: 2.097012996673584
Validation loss: 2.158758032706476

Epoch: 5| Step: 7
Training loss: 2.091482639312744
Validation loss: 2.194280534662226

Epoch: 5| Step: 8
Training loss: 1.972146987915039
Validation loss: 2.214366615459483

Epoch: 5| Step: 9
Training loss: 2.2855923175811768
Validation loss: 2.244559895607733

Epoch: 5| Step: 10
Training loss: 3.0323657989501953
Validation loss: 2.220855907727313

Epoch: 108| Step: 0
Training loss: 2.4985954761505127
Validation loss: 2.1747747403319164

Epoch: 5| Step: 1
Training loss: 2.490554094314575
Validation loss: 2.1301681969755437

Epoch: 5| Step: 2
Training loss: 2.88423752784729
Validation loss: 2.1041771288841002

Epoch: 5| Step: 3
Training loss: 2.483616828918457
Validation loss: 2.1145868173209568

Epoch: 5| Step: 4
Training loss: 2.6287949085235596
Validation loss: 2.117678150053947

Epoch: 5| Step: 5
Training loss: 2.5549533367156982
Validation loss: 2.1310931431349887

Epoch: 5| Step: 6
Training loss: 2.429032802581787
Validation loss: 2.138912541891939

Epoch: 5| Step: 7
Training loss: 2.3517260551452637
Validation loss: 2.1449575988195275

Epoch: 5| Step: 8
Training loss: 2.077634334564209
Validation loss: 2.139518701902

Epoch: 5| Step: 9
Training loss: 2.324895143508911
Validation loss: 2.132626305344284

Epoch: 5| Step: 10
Training loss: 2.2847580909729004
Validation loss: 2.1172770902674687

Epoch: 109| Step: 0
Training loss: 2.064297914505005
Validation loss: 2.1066420616642123

Epoch: 5| Step: 1
Training loss: 3.238010883331299
Validation loss: 2.1098793988586753

Epoch: 5| Step: 2
Training loss: 3.226647138595581
Validation loss: 2.143900481603479

Epoch: 5| Step: 3
Training loss: 1.8835912942886353
Validation loss: 2.1832442360539592

Epoch: 5| Step: 4
Training loss: 2.255836009979248
Validation loss: 2.2013957628639798

Epoch: 5| Step: 5
Training loss: 2.4604387283325195
Validation loss: 2.2057520035774476

Epoch: 5| Step: 6
Training loss: 1.9237842559814453
Validation loss: 2.2193982729347805

Epoch: 5| Step: 7
Training loss: 2.6214356422424316
Validation loss: 2.2168557515708347

Epoch: 5| Step: 8
Training loss: 2.6358118057250977
Validation loss: 2.2248620166573474

Epoch: 5| Step: 9
Training loss: 2.1866581439971924
Validation loss: 2.2122274137312368

Epoch: 5| Step: 10
Training loss: 2.5442607402801514
Validation loss: 2.204615808302356

Epoch: 110| Step: 0
Training loss: 1.8163038492202759
Validation loss: 2.186168796272688

Epoch: 5| Step: 1
Training loss: 2.9435667991638184
Validation loss: 2.182251391872283

Epoch: 5| Step: 2
Training loss: 2.452314853668213
Validation loss: 2.176052475488314

Epoch: 5| Step: 3
Training loss: 2.0775344371795654
Validation loss: 2.167169229958647

Epoch: 5| Step: 4
Training loss: 2.6359245777130127
Validation loss: 2.1569752308630172

Epoch: 5| Step: 5
Training loss: 2.0636022090911865
Validation loss: 2.146289584457233

Epoch: 5| Step: 6
Training loss: 2.4738457202911377
Validation loss: 2.143003225326538

Epoch: 5| Step: 7
Training loss: 2.06809663772583
Validation loss: 2.1472496730025097

Epoch: 5| Step: 8
Training loss: 2.4381606578826904
Validation loss: 2.1500894177344536

Epoch: 5| Step: 9
Training loss: 2.805403232574463
Validation loss: 2.149890575357663

Epoch: 5| Step: 10
Training loss: 3.147920608520508
Validation loss: 2.152996893851988

Epoch: 111| Step: 0
Training loss: 2.3502516746520996
Validation loss: 2.133789321427704

Epoch: 5| Step: 1
Training loss: 2.1453604698181152
Validation loss: 2.1210016383919665

Epoch: 5| Step: 2
Training loss: 2.5847339630126953
Validation loss: 2.120023060870427

Epoch: 5| Step: 3
Training loss: 2.0090060234069824
Validation loss: 2.122724692026774

Epoch: 5| Step: 4
Training loss: 2.5684256553649902
Validation loss: 2.1236234557244087

Epoch: 5| Step: 5
Training loss: 2.392171859741211
Validation loss: 2.1156075962128176

Epoch: 5| Step: 6
Training loss: 2.963172435760498
Validation loss: 2.125477247340705

Epoch: 5| Step: 7
Training loss: 2.648792028427124
Validation loss: 2.117847578499907

Epoch: 5| Step: 8
Training loss: 2.32747745513916
Validation loss: 2.106600699886199

Epoch: 5| Step: 9
Training loss: 2.4025425910949707
Validation loss: 2.103508085332891

Epoch: 5| Step: 10
Training loss: 2.2624993324279785
Validation loss: 2.0908747091088244

Epoch: 112| Step: 0
Training loss: 2.102159023284912
Validation loss: 2.0812965951940066

Epoch: 5| Step: 1
Training loss: 2.376936912536621
Validation loss: 2.0815513287821124

Epoch: 5| Step: 2
Training loss: 1.9472076892852783
Validation loss: 2.0927446042337725

Epoch: 5| Step: 3
Training loss: 2.5718276500701904
Validation loss: 2.099552180177422

Epoch: 5| Step: 4
Training loss: 2.985581159591675
Validation loss: 2.109220620124571

Epoch: 5| Step: 5
Training loss: 2.5667946338653564
Validation loss: 2.129815855333882

Epoch: 5| Step: 6
Training loss: 2.820230007171631
Validation loss: 2.135115385055542

Epoch: 5| Step: 7
Training loss: 2.0972988605499268
Validation loss: 2.127530764507991

Epoch: 5| Step: 8
Training loss: 2.492954969406128
Validation loss: 2.1257593542016964

Epoch: 5| Step: 9
Training loss: 2.390779972076416
Validation loss: 2.113042341765537

Epoch: 5| Step: 10
Training loss: 2.2822093963623047
Validation loss: 2.1030481092391478

Epoch: 113| Step: 0
Training loss: 2.2470476627349854
Validation loss: 2.1012734623365503

Epoch: 5| Step: 1
Training loss: 2.190739154815674
Validation loss: 2.099527274408648

Epoch: 5| Step: 2
Training loss: 2.6581528186798096
Validation loss: 2.0933770031057377

Epoch: 5| Step: 3
Training loss: 2.1862363815307617
Validation loss: 2.0997729660362325

Epoch: 5| Step: 4
Training loss: 1.8312584161758423
Validation loss: 2.099652527480997

Epoch: 5| Step: 5
Training loss: 3.0113320350646973
Validation loss: 2.1004681177036737

Epoch: 5| Step: 6
Training loss: 2.481680393218994
Validation loss: 2.101410299219111

Epoch: 5| Step: 7
Training loss: 2.519430160522461
Validation loss: 2.1074222980007047

Epoch: 5| Step: 8
Training loss: 2.1616532802581787
Validation loss: 2.1084053772752003

Epoch: 5| Step: 9
Training loss: 2.674680233001709
Validation loss: 2.0988990196617703

Epoch: 5| Step: 10
Training loss: 2.4430577754974365
Validation loss: 2.0991321238138343

Epoch: 114| Step: 0
Training loss: 2.7666873931884766
Validation loss: 2.0915787143092

Epoch: 5| Step: 1
Training loss: 1.885963797569275
Validation loss: 2.0959834078306794

Epoch: 5| Step: 2
Training loss: 2.7122185230255127
Validation loss: 2.098502020682058

Epoch: 5| Step: 3
Training loss: 2.5461549758911133
Validation loss: 2.095846378675071

Epoch: 5| Step: 4
Training loss: 2.348806142807007
Validation loss: 2.095766138005

Epoch: 5| Step: 5
Training loss: 2.2928338050842285
Validation loss: 2.0942405295628372

Epoch: 5| Step: 6
Training loss: 2.479901075363159
Validation loss: 2.0979963297485025

Epoch: 5| Step: 7
Training loss: 2.500669002532959
Validation loss: 2.096150562327395

Epoch: 5| Step: 8
Training loss: 2.025019407272339
Validation loss: 2.0952716655628656

Epoch: 5| Step: 9
Training loss: 2.884328842163086
Validation loss: 2.0950141311973653

Epoch: 5| Step: 10
Training loss: 1.8008397817611694
Validation loss: 2.0944530322987545

Epoch: 115| Step: 0
Training loss: 2.558131456375122
Validation loss: 2.0921188105819044

Epoch: 5| Step: 1
Training loss: 2.353084087371826
Validation loss: 2.091554152068271

Epoch: 5| Step: 2
Training loss: 2.002856731414795
Validation loss: 2.0990869358021724

Epoch: 5| Step: 3
Training loss: 2.2549901008605957
Validation loss: 2.1068053527544905

Epoch: 5| Step: 4
Training loss: 2.4651036262512207
Validation loss: 2.1061404289737826

Epoch: 5| Step: 5
Training loss: 2.2097785472869873
Validation loss: 2.104483183994088

Epoch: 5| Step: 6
Training loss: 2.6094202995300293
Validation loss: 2.109705933960535

Epoch: 5| Step: 7
Training loss: 2.1416609287261963
Validation loss: 2.1015550962058445

Epoch: 5| Step: 8
Training loss: 2.223496437072754
Validation loss: 2.111845685589698

Epoch: 5| Step: 9
Training loss: 2.8190760612487793
Validation loss: 2.088628221583623

Epoch: 5| Step: 10
Training loss: 2.5954654216766357
Validation loss: 2.0891130739642727

Epoch: 116| Step: 0
Training loss: 1.993509292602539
Validation loss: 2.094684223974905

Epoch: 5| Step: 1
Training loss: 2.7754204273223877
Validation loss: 2.0902761605478104

Epoch: 5| Step: 2
Training loss: 2.8100533485412598
Validation loss: 2.0901200950786634

Epoch: 5| Step: 3
Training loss: 2.057048797607422
Validation loss: 2.092680767018308

Epoch: 5| Step: 4
Training loss: 2.070828914642334
Validation loss: 2.092466664570634

Epoch: 5| Step: 5
Training loss: 2.3490915298461914
Validation loss: 2.1017412716342556

Epoch: 5| Step: 6
Training loss: 2.379232406616211
Validation loss: 2.102647368625928

Epoch: 5| Step: 7
Training loss: 2.769209384918213
Validation loss: 2.1091814566684026

Epoch: 5| Step: 8
Training loss: 2.9715380668640137
Validation loss: 2.0963890655066377

Epoch: 5| Step: 9
Training loss: 1.9592440128326416
Validation loss: 2.0886451198208715

Epoch: 5| Step: 10
Training loss: 2.176844358444214
Validation loss: 2.084417691794775

Epoch: 117| Step: 0
Training loss: 2.0202362537384033
Validation loss: 2.0801103679082726

Epoch: 5| Step: 1
Training loss: 2.6540112495422363
Validation loss: 2.0819299810676166

Epoch: 5| Step: 2
Training loss: 1.8553149700164795
Validation loss: 2.0772477503745788

Epoch: 5| Step: 3
Training loss: 2.4596598148345947
Validation loss: 2.0812615809902066

Epoch: 5| Step: 4
Training loss: 2.4869894981384277
Validation loss: 2.0782759317787747

Epoch: 5| Step: 5
Training loss: 2.5698788166046143
Validation loss: 2.0785139811936246

Epoch: 5| Step: 6
Training loss: 2.338662624359131
Validation loss: 2.0813726584116616

Epoch: 5| Step: 7
Training loss: 2.6619529724121094
Validation loss: 2.080692602742103

Epoch: 5| Step: 8
Training loss: 2.1096534729003906
Validation loss: 2.0857649451942852

Epoch: 5| Step: 9
Training loss: 2.7668471336364746
Validation loss: 2.113237407899672

Epoch: 5| Step: 10
Training loss: 2.525507688522339
Validation loss: 2.1353087476504746

Epoch: 118| Step: 0
Training loss: 1.9480924606323242
Validation loss: 2.1412269428212154

Epoch: 5| Step: 1
Training loss: 2.2764506340026855
Validation loss: 2.112525737413796

Epoch: 5| Step: 2
Training loss: 2.9545955657958984
Validation loss: 2.093790708049651

Epoch: 5| Step: 3
Training loss: 2.4276254177093506
Validation loss: 2.082260157472344

Epoch: 5| Step: 4
Training loss: 1.9558961391448975
Validation loss: 2.078070799509684

Epoch: 5| Step: 5
Training loss: 2.139475107192993
Validation loss: 2.0791933023801414

Epoch: 5| Step: 6
Training loss: 2.9718329906463623
Validation loss: 2.077287922623337

Epoch: 5| Step: 7
Training loss: 1.9055887460708618
Validation loss: 2.0770970980326333

Epoch: 5| Step: 8
Training loss: 2.597888708114624
Validation loss: 2.078966909839261

Epoch: 5| Step: 9
Training loss: 2.3002026081085205
Validation loss: 2.085230529949229

Epoch: 5| Step: 10
Training loss: 2.694542407989502
Validation loss: 2.0840284209097586

Epoch: 119| Step: 0
Training loss: 2.122861385345459
Validation loss: 2.0882225831349692

Epoch: 5| Step: 1
Training loss: 2.502711534500122
Validation loss: 2.0903367252760034

Epoch: 5| Step: 2
Training loss: 2.1457431316375732
Validation loss: 2.079399001213812

Epoch: 5| Step: 3
Training loss: 2.177297353744507
Validation loss: 2.0813295533580165

Epoch: 5| Step: 4
Training loss: 2.603722095489502
Validation loss: 2.091990342704199

Epoch: 5| Step: 5
Training loss: 2.22813081741333
Validation loss: 2.0886407539408696

Epoch: 5| Step: 6
Training loss: 2.5291895866394043
Validation loss: 2.0924917933761433

Epoch: 5| Step: 7
Training loss: 2.7942872047424316
Validation loss: 2.077070164424117

Epoch: 5| Step: 8
Training loss: 2.752350091934204
Validation loss: 2.0821180292355117

Epoch: 5| Step: 9
Training loss: 2.127883195877075
Validation loss: 2.082704267194194

Epoch: 5| Step: 10
Training loss: 2.4221367835998535
Validation loss: 2.075847802623626

Epoch: 120| Step: 0
Training loss: 2.6303837299346924
Validation loss: 2.069106476281279

Epoch: 5| Step: 1
Training loss: 1.8305599689483643
Validation loss: 2.0706387642891175

Epoch: 5| Step: 2
Training loss: 2.939391613006592
Validation loss: 2.0808875304396435

Epoch: 5| Step: 3
Training loss: 2.3573272228240967
Validation loss: 2.0820867451288367

Epoch: 5| Step: 4
Training loss: 2.4769740104675293
Validation loss: 2.0906375710682203

Epoch: 5| Step: 5
Training loss: 2.060037136077881
Validation loss: 2.107676254805698

Epoch: 5| Step: 6
Training loss: 2.853212356567383
Validation loss: 2.1038846520967383

Epoch: 5| Step: 7
Training loss: 2.508267641067505
Validation loss: 2.1143652136607836

Epoch: 5| Step: 8
Training loss: 2.075887680053711
Validation loss: 2.118899165943105

Epoch: 5| Step: 9
Training loss: 2.5423166751861572
Validation loss: 2.1148016016970397

Epoch: 5| Step: 10
Training loss: 1.8276923894882202
Validation loss: 2.1002518066795925

Epoch: 121| Step: 0
Training loss: 2.670064926147461
Validation loss: 2.084812271979547

Epoch: 5| Step: 1
Training loss: 1.9345643520355225
Validation loss: 2.073857045942737

Epoch: 5| Step: 2
Training loss: 3.0031025409698486
Validation loss: 2.0755953865666545

Epoch: 5| Step: 3
Training loss: 2.2090213298797607
Validation loss: 2.079255547574771

Epoch: 5| Step: 4
Training loss: 2.4089627265930176
Validation loss: 2.0874626187868017

Epoch: 5| Step: 5
Training loss: 1.4645411968231201
Validation loss: 2.0924650520406742

Epoch: 5| Step: 6
Training loss: 2.963655471801758
Validation loss: 2.083759005351733

Epoch: 5| Step: 7
Training loss: 2.334982395172119
Validation loss: 2.079221752382094

Epoch: 5| Step: 8
Training loss: 2.6579818725585938
Validation loss: 2.083122548236642

Epoch: 5| Step: 9
Training loss: 2.7947990894317627
Validation loss: 2.0790988501682075

Epoch: 5| Step: 10
Training loss: 1.6185526847839355
Validation loss: 2.0801853672150643

Epoch: 122| Step: 0
Training loss: 2.730529546737671
Validation loss: 2.0748717913063626

Epoch: 5| Step: 1
Training loss: 2.520129680633545
Validation loss: 2.077772673740182

Epoch: 5| Step: 2
Training loss: 2.4425883293151855
Validation loss: 2.076592017245549

Epoch: 5| Step: 3
Training loss: 2.51151967048645
Validation loss: 2.06702188522585

Epoch: 5| Step: 4
Training loss: 2.48622465133667
Validation loss: 2.0588821621351343

Epoch: 5| Step: 5
Training loss: 2.1445505619049072
Validation loss: 2.0664231341372252

Epoch: 5| Step: 6
Training loss: 2.426431179046631
Validation loss: 2.0650602668844242

Epoch: 5| Step: 7
Training loss: 2.1379334926605225
Validation loss: 2.0706745155396

Epoch: 5| Step: 8
Training loss: 1.9701855182647705
Validation loss: 2.0546083616954025

Epoch: 5| Step: 9
Training loss: 2.685835599899292
Validation loss: 2.068705995877584

Epoch: 5| Step: 10
Training loss: 1.9221076965332031
Validation loss: 2.0866473336373605

Epoch: 123| Step: 0
Training loss: 2.012254238128662
Validation loss: 2.0941655302560456

Epoch: 5| Step: 1
Training loss: 1.5738779306411743
Validation loss: 2.1113602653626473

Epoch: 5| Step: 2
Training loss: 2.7303080558776855
Validation loss: 2.122983535130819

Epoch: 5| Step: 3
Training loss: 2.4137415885925293
Validation loss: 2.123946182189449

Epoch: 5| Step: 4
Training loss: 2.797929048538208
Validation loss: 2.1174903518410138

Epoch: 5| Step: 5
Training loss: 1.3265057802200317
Validation loss: 2.1090521735529744

Epoch: 5| Step: 6
Training loss: 2.802570343017578
Validation loss: 2.1030633705918507

Epoch: 5| Step: 7
Training loss: 2.163306713104248
Validation loss: 2.0994093366848525

Epoch: 5| Step: 8
Training loss: 3.0309433937072754
Validation loss: 2.09493992405553

Epoch: 5| Step: 9
Training loss: 2.8243327140808105
Validation loss: 2.0934724987194104

Epoch: 5| Step: 10
Training loss: 2.5561630725860596
Validation loss: 2.092386284182149

Epoch: 124| Step: 0
Training loss: 2.0022075176239014
Validation loss: 2.0845937805791057

Epoch: 5| Step: 1
Training loss: 2.305877208709717
Validation loss: 2.089667070296503

Epoch: 5| Step: 2
Training loss: 2.107442855834961
Validation loss: 2.088120029818627

Epoch: 5| Step: 3
Training loss: 2.579355001449585
Validation loss: 2.0769739304819415

Epoch: 5| Step: 4
Training loss: 2.7480111122131348
Validation loss: 2.068921660864225

Epoch: 5| Step: 5
Training loss: 1.737765908241272
Validation loss: 2.0598430530999297

Epoch: 5| Step: 6
Training loss: 2.391178846359253
Validation loss: 2.0577001340927614

Epoch: 5| Step: 7
Training loss: 2.1672520637512207
Validation loss: 2.056969206820252

Epoch: 5| Step: 8
Training loss: 2.5526092052459717
Validation loss: 2.054996471251211

Epoch: 5| Step: 9
Training loss: 2.8288121223449707
Validation loss: 2.062129520600842

Epoch: 5| Step: 10
Training loss: 2.6170542240142822
Validation loss: 2.0709633109390095

Epoch: 125| Step: 0
Training loss: 2.4502193927764893
Validation loss: 2.068775351329516

Epoch: 5| Step: 1
Training loss: 2.7882537841796875
Validation loss: 2.075029351378

Epoch: 5| Step: 2
Training loss: 2.150416612625122
Validation loss: 2.066081016294418

Epoch: 5| Step: 3
Training loss: 2.266723155975342
Validation loss: 2.070071174252418

Epoch: 5| Step: 4
Training loss: 3.105134963989258
Validation loss: 2.0849707613709154

Epoch: 5| Step: 5
Training loss: 2.412426471710205
Validation loss: 2.0870812349422003

Epoch: 5| Step: 6
Training loss: 2.1810967922210693
Validation loss: 2.0953374114087833

Epoch: 5| Step: 7
Training loss: 1.762794852256775
Validation loss: 2.1040691662860174

Epoch: 5| Step: 8
Training loss: 2.4542884826660156
Validation loss: 2.118566733534618

Epoch: 5| Step: 9
Training loss: 1.7269160747528076
Validation loss: 2.158585120272893

Epoch: 5| Step: 10
Training loss: 2.9166600704193115
Validation loss: 2.188790446968489

Epoch: 126| Step: 0
Training loss: 1.9952319860458374
Validation loss: 2.211636838092599

Epoch: 5| Step: 1
Training loss: 2.6662678718566895
Validation loss: 2.207670739901963

Epoch: 5| Step: 2
Training loss: 2.323094129562378
Validation loss: 2.185003485730899

Epoch: 5| Step: 3
Training loss: 2.945435047149658
Validation loss: 2.163371727030764

Epoch: 5| Step: 4
Training loss: 2.515397548675537
Validation loss: 2.1433703604564873

Epoch: 5| Step: 5
Training loss: 1.9410024881362915
Validation loss: 2.105072598303518

Epoch: 5| Step: 6
Training loss: 2.8792459964752197
Validation loss: 2.099283153010953

Epoch: 5| Step: 7
Training loss: 2.430436372756958
Validation loss: 2.0912887409169185

Epoch: 5| Step: 8
Training loss: 1.5872074365615845
Validation loss: 2.088436375382126

Epoch: 5| Step: 9
Training loss: 2.328085422515869
Validation loss: 2.090215736819852

Epoch: 5| Step: 10
Training loss: 2.9733710289001465
Validation loss: 2.084762752697032

Epoch: 127| Step: 0
Training loss: 2.403653860092163
Validation loss: 2.0966456167159544

Epoch: 5| Step: 1
Training loss: 2.344794273376465
Validation loss: 2.1103140718193463

Epoch: 5| Step: 2
Training loss: 2.7441840171813965
Validation loss: 2.11473669544343

Epoch: 5| Step: 3
Training loss: 2.651093006134033
Validation loss: 2.1291993587247786

Epoch: 5| Step: 4
Training loss: 2.479713201522827
Validation loss: 2.1411817919823433

Epoch: 5| Step: 5
Training loss: 2.5053904056549072
Validation loss: 2.1352581772752988

Epoch: 5| Step: 6
Training loss: 2.344391345977783
Validation loss: 2.1071556947564565

Epoch: 5| Step: 7
Training loss: 2.1600358486175537
Validation loss: 2.091758305026639

Epoch: 5| Step: 8
Training loss: 1.7390003204345703
Validation loss: 2.101498329511253

Epoch: 5| Step: 9
Training loss: 2.2372937202453613
Validation loss: 2.10132037567836

Epoch: 5| Step: 10
Training loss: 2.8824243545532227
Validation loss: 2.105572731264176

Epoch: 128| Step: 0
Training loss: 2.7536139488220215
Validation loss: 2.1058522655117895

Epoch: 5| Step: 1
Training loss: 2.0088114738464355
Validation loss: 2.0975144883637786

Epoch: 5| Step: 2
Training loss: 2.7802374362945557
Validation loss: 2.101584452454762

Epoch: 5| Step: 3
Training loss: 2.212862730026245
Validation loss: 2.100540684115502

Epoch: 5| Step: 4
Training loss: 2.3664042949676514
Validation loss: 2.1006551404153146

Epoch: 5| Step: 5
Training loss: 1.9099773168563843
Validation loss: 2.1035119641211724

Epoch: 5| Step: 6
Training loss: 2.0271763801574707
Validation loss: 2.106025472764046

Epoch: 5| Step: 7
Training loss: 2.981904983520508
Validation loss: 2.096960157476446

Epoch: 5| Step: 8
Training loss: 2.4243757724761963
Validation loss: 2.094461046239381

Epoch: 5| Step: 9
Training loss: 2.0954220294952393
Validation loss: 2.0904838180029266

Epoch: 5| Step: 10
Training loss: 2.6649234294891357
Validation loss: 2.0796791712443032

Epoch: 129| Step: 0
Training loss: 2.509458065032959
Validation loss: 2.0877160090272144

Epoch: 5| Step: 1
Training loss: 2.232952117919922
Validation loss: 2.0739669517804216

Epoch: 5| Step: 2
Training loss: 2.533201217651367
Validation loss: 2.0569418450837493

Epoch: 5| Step: 3
Training loss: 1.6296488046646118
Validation loss: 2.047775281372891

Epoch: 5| Step: 4
Training loss: 2.0089101791381836
Validation loss: 2.0440814751450733

Epoch: 5| Step: 5
Training loss: 3.053760051727295
Validation loss: 2.0466964373024563

Epoch: 5| Step: 6
Training loss: 2.461028575897217
Validation loss: 2.0499264245392173

Epoch: 5| Step: 7
Training loss: 2.8182733058929443
Validation loss: 2.058895598175705

Epoch: 5| Step: 8
Training loss: 2.4685285091400146
Validation loss: 2.063650474753431

Epoch: 5| Step: 9
Training loss: 2.0628747940063477
Validation loss: 2.0636985942881596

Epoch: 5| Step: 10
Training loss: 2.091859817504883
Validation loss: 2.070532726985152

Epoch: 130| Step: 0
Training loss: 2.8605117797851562
Validation loss: 2.0552761144535516

Epoch: 5| Step: 1
Training loss: 2.1645426750183105
Validation loss: 2.0407735275965866

Epoch: 5| Step: 2
Training loss: 1.8375253677368164
Validation loss: 2.042683375779019

Epoch: 5| Step: 3
Training loss: 3.02972412109375
Validation loss: 2.045888004764434

Epoch: 5| Step: 4
Training loss: 1.3287163972854614
Validation loss: 2.043636375857938

Epoch: 5| Step: 5
Training loss: 2.1842455863952637
Validation loss: 2.043002825911327

Epoch: 5| Step: 6
Training loss: 2.440969467163086
Validation loss: 2.0425661404927573

Epoch: 5| Step: 7
Training loss: 2.619401216506958
Validation loss: 2.047544633188555

Epoch: 5| Step: 8
Training loss: 2.47517728805542
Validation loss: 2.073033937843897

Epoch: 5| Step: 9
Training loss: 2.415905475616455
Validation loss: 2.0735900530251126

Epoch: 5| Step: 10
Training loss: 2.363966464996338
Validation loss: 2.072663378971879

Epoch: 131| Step: 0
Training loss: 2.4370555877685547
Validation loss: 2.060180635862453

Epoch: 5| Step: 1
Training loss: 2.3998212814331055
Validation loss: 2.0759324642919723

Epoch: 5| Step: 2
Training loss: 2.815372943878174
Validation loss: 2.0753628412882485

Epoch: 5| Step: 3
Training loss: 2.258735179901123
Validation loss: 2.0631711944457023

Epoch: 5| Step: 4
Training loss: 1.8110759258270264
Validation loss: 2.064392702553862

Epoch: 5| Step: 5
Training loss: 2.271541118621826
Validation loss: 2.077886034083623

Epoch: 5| Step: 6
Training loss: 2.39036226272583
Validation loss: 2.0721409102921844

Epoch: 5| Step: 7
Training loss: 3.1105892658233643
Validation loss: 2.077773831223929

Epoch: 5| Step: 8
Training loss: 2.499454975128174
Validation loss: 2.089919772199405

Epoch: 5| Step: 9
Training loss: 1.6880048513412476
Validation loss: 2.088989709013252

Epoch: 5| Step: 10
Training loss: 2.1406326293945312
Validation loss: 2.0941575009335756

Epoch: 132| Step: 0
Training loss: 1.79230535030365
Validation loss: 2.105570249660041

Epoch: 5| Step: 1
Training loss: 2.1424882411956787
Validation loss: 2.1190471136441795

Epoch: 5| Step: 2
Training loss: 2.4133710861206055
Validation loss: 2.1298711607533116

Epoch: 5| Step: 3
Training loss: 2.5228171348571777
Validation loss: 2.1252564230272846

Epoch: 5| Step: 4
Training loss: 2.281909942626953
Validation loss: 2.1229611468571488

Epoch: 5| Step: 5
Training loss: 2.185894012451172
Validation loss: 2.111665218107162

Epoch: 5| Step: 6
Training loss: 2.8191168308258057
Validation loss: 2.104650192363288

Epoch: 5| Step: 7
Training loss: 2.3547744750976562
Validation loss: 2.0860317894207534

Epoch: 5| Step: 8
Training loss: 2.435382127761841
Validation loss: 2.077391239904588

Epoch: 5| Step: 9
Training loss: 2.7692790031433105
Validation loss: 2.0714400429879465

Epoch: 5| Step: 10
Training loss: 2.119621753692627
Validation loss: 2.0721762846874934

Epoch: 133| Step: 0
Training loss: 2.0347087383270264
Validation loss: 2.081441466526319

Epoch: 5| Step: 1
Training loss: 2.3361003398895264
Validation loss: 2.087111319265058

Epoch: 5| Step: 2
Training loss: 2.1969094276428223
Validation loss: 2.117149035135905

Epoch: 5| Step: 3
Training loss: 2.153860569000244
Validation loss: 2.116544194118951

Epoch: 5| Step: 4
Training loss: 1.7393842935562134
Validation loss: 2.1095136045127787

Epoch: 5| Step: 5
Training loss: 2.264193058013916
Validation loss: 2.0929197085800992

Epoch: 5| Step: 6
Training loss: 2.4636149406433105
Validation loss: 2.076802853615053

Epoch: 5| Step: 7
Training loss: 2.7530407905578613
Validation loss: 2.076472164482199

Epoch: 5| Step: 8
Training loss: 2.1181282997131348
Validation loss: 2.0778685692817933

Epoch: 5| Step: 9
Training loss: 2.842336654663086
Validation loss: 2.06882998763874

Epoch: 5| Step: 10
Training loss: 2.7487378120422363
Validation loss: 2.069823386848614

Epoch: 134| Step: 0
Training loss: 1.939515471458435
Validation loss: 2.066413443575623

Epoch: 5| Step: 1
Training loss: 2.8690600395202637
Validation loss: 2.084500342287043

Epoch: 5| Step: 2
Training loss: 2.363861560821533
Validation loss: 2.082198122496246

Epoch: 5| Step: 3
Training loss: 2.06953763961792
Validation loss: 2.052778479873493

Epoch: 5| Step: 4
Training loss: 2.4144287109375
Validation loss: 2.043035912257369

Epoch: 5| Step: 5
Training loss: 2.429297685623169
Validation loss: 2.0418108483796478

Epoch: 5| Step: 6
Training loss: 1.8907558917999268
Validation loss: 2.031317718567387

Epoch: 5| Step: 7
Training loss: 2.1433207988739014
Validation loss: 2.0323956140907864

Epoch: 5| Step: 8
Training loss: 2.5192008018493652
Validation loss: 2.031211132644325

Epoch: 5| Step: 9
Training loss: 2.8158864974975586
Validation loss: 2.0300871761896278

Epoch: 5| Step: 10
Training loss: 2.0909597873687744
Validation loss: 2.028835910622792

Epoch: 135| Step: 0
Training loss: 2.323578357696533
Validation loss: 2.0306822510175806

Epoch: 5| Step: 1
Training loss: 2.2297115325927734
Validation loss: 2.0488522744947866

Epoch: 5| Step: 2
Training loss: 2.5810701847076416
Validation loss: 2.061321799473096

Epoch: 5| Step: 3
Training loss: 2.6942458152770996
Validation loss: 2.072739360153034

Epoch: 5| Step: 4
Training loss: 2.5458176136016846
Validation loss: 2.0732302922074513

Epoch: 5| Step: 5
Training loss: 2.355682849884033
Validation loss: 2.0579078556388937

Epoch: 5| Step: 6
Training loss: 2.54067063331604
Validation loss: 2.0686196780973867

Epoch: 5| Step: 7
Training loss: 2.2641615867614746
Validation loss: 2.0952865872331845

Epoch: 5| Step: 8
Training loss: 1.912101149559021
Validation loss: 2.098738089684517

Epoch: 5| Step: 9
Training loss: 2.1590352058410645
Validation loss: 2.1044369359170236

Epoch: 5| Step: 10
Training loss: 1.892724633216858
Validation loss: 2.1042356003997145

Epoch: 136| Step: 0
Training loss: 2.7910518646240234
Validation loss: 2.1040954794935

Epoch: 5| Step: 1
Training loss: 2.280285358428955
Validation loss: 2.0764350468112576

Epoch: 5| Step: 2
Training loss: 2.2427361011505127
Validation loss: 2.071811237642842

Epoch: 5| Step: 3
Training loss: 2.1376960277557373
Validation loss: 2.0724552805705736

Epoch: 5| Step: 4
Training loss: 1.9812049865722656
Validation loss: 2.0754074050534155

Epoch: 5| Step: 5
Training loss: 2.327404737472534
Validation loss: 2.0664432933253627

Epoch: 5| Step: 6
Training loss: 2.779737710952759
Validation loss: 2.067010115551692

Epoch: 5| Step: 7
Training loss: 2.3059756755828857
Validation loss: 2.0676671356283207

Epoch: 5| Step: 8
Training loss: 2.2535853385925293
Validation loss: 2.0609854421307965

Epoch: 5| Step: 9
Training loss: 2.069796085357666
Validation loss: 2.082332923848142

Epoch: 5| Step: 10
Training loss: 2.723634719848633
Validation loss: 2.0828163700719036

Epoch: 137| Step: 0
Training loss: 2.4965217113494873
Validation loss: 2.0901666174652758

Epoch: 5| Step: 1
Training loss: 2.470745801925659
Validation loss: 2.094258254574191

Epoch: 5| Step: 2
Training loss: 1.6451759338378906
Validation loss: 2.0838805988270748

Epoch: 5| Step: 3
Training loss: 2.3837075233459473
Validation loss: 2.0880440486374723

Epoch: 5| Step: 4
Training loss: 2.443699359893799
Validation loss: 2.0866936073508313

Epoch: 5| Step: 5
Training loss: 2.1128830909729004
Validation loss: 2.0903105953688264

Epoch: 5| Step: 6
Training loss: 2.239003896713257
Validation loss: 2.089411361243135

Epoch: 5| Step: 7
Training loss: 2.5546345710754395
Validation loss: 2.0931267123068533

Epoch: 5| Step: 8
Training loss: 2.2313148975372314
Validation loss: 2.107440456267326

Epoch: 5| Step: 9
Training loss: 2.8858087062835693
Validation loss: 2.093773388093518

Epoch: 5| Step: 10
Training loss: 2.2397301197052
Validation loss: 2.0931798463226645

Epoch: 138| Step: 0
Training loss: 2.6881942749023438
Validation loss: 2.086035320835729

Epoch: 5| Step: 1
Training loss: 2.808703899383545
Validation loss: 2.0788416836851384

Epoch: 5| Step: 2
Training loss: 2.1697239875793457
Validation loss: 2.084308340985288

Epoch: 5| Step: 3
Training loss: 2.085486888885498
Validation loss: 2.089217178283199

Epoch: 5| Step: 4
Training loss: 2.435673236846924
Validation loss: 2.0845167995781027

Epoch: 5| Step: 5
Training loss: 2.2816054821014404
Validation loss: 2.0995974258709977

Epoch: 5| Step: 6
Training loss: 2.762486219406128
Validation loss: 2.0898017934573594

Epoch: 5| Step: 7
Training loss: 1.8788769245147705
Validation loss: 2.0826659138484667

Epoch: 5| Step: 8
Training loss: 2.3480193614959717
Validation loss: 2.097038229306539

Epoch: 5| Step: 9
Training loss: 1.9886407852172852
Validation loss: 2.104675351932485

Epoch: 5| Step: 10
Training loss: 2.6580588817596436
Validation loss: 2.098031686198327

Epoch: 139| Step: 0
Training loss: 2.032292366027832
Validation loss: 2.095492652667466

Epoch: 5| Step: 1
Training loss: 2.3883559703826904
Validation loss: 2.0829329952116935

Epoch: 5| Step: 2
Training loss: 2.704876661300659
Validation loss: 2.0990298691616265

Epoch: 5| Step: 3
Training loss: 1.9123542308807373
Validation loss: 2.0907779534657798

Epoch: 5| Step: 4
Training loss: 2.876443386077881
Validation loss: 2.093855320766408

Epoch: 5| Step: 5
Training loss: 2.522423505783081
Validation loss: 2.095138442131781

Epoch: 5| Step: 6
Training loss: 2.3847107887268066
Validation loss: 2.084579613900954

Epoch: 5| Step: 7
Training loss: 2.1394119262695312
Validation loss: 2.0929125765318513

Epoch: 5| Step: 8
Training loss: 2.4331557750701904
Validation loss: 2.094364804606284

Epoch: 5| Step: 9
Training loss: 2.114635944366455
Validation loss: 2.0876025435745076

Epoch: 5| Step: 10
Training loss: 2.2105045318603516
Validation loss: 2.076749565780804

Epoch: 140| Step: 0
Training loss: 2.6659557819366455
Validation loss: 2.0728926530448337

Epoch: 5| Step: 1
Training loss: 1.9412155151367188
Validation loss: 2.0720608670224427

Epoch: 5| Step: 2
Training loss: 1.584899663925171
Validation loss: 2.062096033045041

Epoch: 5| Step: 3
Training loss: 2.409029006958008
Validation loss: 2.070537587647797

Epoch: 5| Step: 4
Training loss: 2.1797831058502197
Validation loss: 2.0685256527316187

Epoch: 5| Step: 5
Training loss: 2.7507948875427246
Validation loss: 2.0612813349693053

Epoch: 5| Step: 6
Training loss: 2.4020321369171143
Validation loss: 2.067869805520581

Epoch: 5| Step: 7
Training loss: 2.331805467605591
Validation loss: 2.079489420819026

Epoch: 5| Step: 8
Training loss: 2.715292453765869
Validation loss: 2.0952977544517926

Epoch: 5| Step: 9
Training loss: 1.9319067001342773
Validation loss: 2.0983062777467953

Epoch: 5| Step: 10
Training loss: 2.801985025405884
Validation loss: 2.0769171996783187

Epoch: 141| Step: 0
Training loss: 2.401099681854248
Validation loss: 2.067432507391899

Epoch: 5| Step: 1
Training loss: 2.910452365875244
Validation loss: 2.0629478090552875

Epoch: 5| Step: 2
Training loss: 2.8351683616638184
Validation loss: 2.0610957478964202

Epoch: 5| Step: 3
Training loss: 2.3983209133148193
Validation loss: 2.0555391414191133

Epoch: 5| Step: 4
Training loss: 2.4968180656433105
Validation loss: 2.0587052478585193

Epoch: 5| Step: 5
Training loss: 1.9415096044540405
Validation loss: 2.06173562875358

Epoch: 5| Step: 6
Training loss: 1.954779863357544
Validation loss: 2.075358900972592

Epoch: 5| Step: 7
Training loss: 2.632089614868164
Validation loss: 2.0821895214819137

Epoch: 5| Step: 8
Training loss: 1.6354811191558838
Validation loss: 2.06629172448189

Epoch: 5| Step: 9
Training loss: 2.4639651775360107
Validation loss: 2.0628298854315155

Epoch: 5| Step: 10
Training loss: 1.698254942893982
Validation loss: 2.0537193667504097

Epoch: 142| Step: 0
Training loss: 2.3862690925598145
Validation loss: 2.0396307014649913

Epoch: 5| Step: 1
Training loss: 2.8650436401367188
Validation loss: 2.032213213623211

Epoch: 5| Step: 2
Training loss: 1.9478336572647095
Validation loss: 2.020954365371376

Epoch: 5| Step: 3
Training loss: 1.7623236179351807
Validation loss: 2.019149580309468

Epoch: 5| Step: 4
Training loss: 2.1855883598327637
Validation loss: 2.0105853285840762

Epoch: 5| Step: 5
Training loss: 2.1632025241851807
Validation loss: 2.007169605583273

Epoch: 5| Step: 6
Training loss: 2.5433859825134277
Validation loss: 2.013469583244734

Epoch: 5| Step: 7
Training loss: 2.528542995452881
Validation loss: 2.0202507677898613

Epoch: 5| Step: 8
Training loss: 2.4797070026397705
Validation loss: 2.0335973590932865

Epoch: 5| Step: 9
Training loss: 1.9922481775283813
Validation loss: 2.0306296271662556

Epoch: 5| Step: 10
Training loss: 2.2460684776306152
Validation loss: 2.0337462681595997

Epoch: 143| Step: 0
Training loss: 2.317988872528076
Validation loss: 2.0308564760351695

Epoch: 5| Step: 1
Training loss: 2.576796054840088
Validation loss: 2.0483695896722938

Epoch: 5| Step: 2
Training loss: 2.39888596534729
Validation loss: 2.043391707122967

Epoch: 5| Step: 3
Training loss: 1.6651417016983032
Validation loss: 2.0630244439648044

Epoch: 5| Step: 4
Training loss: 2.141085147857666
Validation loss: 2.069302128207299

Epoch: 5| Step: 5
Training loss: 2.382080078125
Validation loss: 2.0722531772428945

Epoch: 5| Step: 6
Training loss: 2.496466875076294
Validation loss: 2.0778604963774323

Epoch: 5| Step: 7
Training loss: 2.068615436553955
Validation loss: 2.0755012407097766

Epoch: 5| Step: 8
Training loss: 2.3456051349639893
Validation loss: 2.063058158402802

Epoch: 5| Step: 9
Training loss: 2.9143478870391846
Validation loss: 2.043518086915375

Epoch: 5| Step: 10
Training loss: 2.0039470195770264
Validation loss: 2.0344449204783284

Epoch: 144| Step: 0
Training loss: 1.7523492574691772
Validation loss: 2.0415069992824266

Epoch: 5| Step: 1
Training loss: 2.3454082012176514
Validation loss: 2.0534964581971527

Epoch: 5| Step: 2
Training loss: 2.1568195819854736
Validation loss: 2.0746474009688183

Epoch: 5| Step: 3
Training loss: 2.6323068141937256
Validation loss: 2.0878599997489684

Epoch: 5| Step: 4
Training loss: 1.9355570077896118
Validation loss: 2.1090550294486423

Epoch: 5| Step: 5
Training loss: 2.2505035400390625
Validation loss: 2.1319243138836277

Epoch: 5| Step: 6
Training loss: 2.27760648727417
Validation loss: 2.1282632684194915

Epoch: 5| Step: 7
Training loss: 2.8023018836975098
Validation loss: 2.125105480993948

Epoch: 5| Step: 8
Training loss: 2.927140712738037
Validation loss: 2.051447570964854

Epoch: 5| Step: 9
Training loss: 2.2010626792907715
Validation loss: 2.030652420495146

Epoch: 5| Step: 10
Training loss: 2.1013870239257812
Validation loss: 2.008232693518362

Epoch: 145| Step: 0
Training loss: 2.2436282634735107
Validation loss: 2.0047548945232103

Epoch: 5| Step: 1
Training loss: 2.496647834777832
Validation loss: 2.0117246258643364

Epoch: 5| Step: 2
Training loss: 2.134911298751831
Validation loss: 2.006611421544065

Epoch: 5| Step: 3
Training loss: 2.3177828788757324
Validation loss: 2.0007559509687525

Epoch: 5| Step: 4
Training loss: 1.7616913318634033
Validation loss: 1.995157229003086

Epoch: 5| Step: 5
Training loss: 2.0689144134521484
Validation loss: 1.9927930857545586

Epoch: 5| Step: 6
Training loss: 2.116328239440918
Validation loss: 1.9960883432818997

Epoch: 5| Step: 7
Training loss: 2.8025460243225098
Validation loss: 1.9887279028533607

Epoch: 5| Step: 8
Training loss: 2.5953173637390137
Validation loss: 1.9840004597940752

Epoch: 5| Step: 9
Training loss: 1.9032074213027954
Validation loss: 1.9872490308618034

Epoch: 5| Step: 10
Training loss: 3.021582841873169
Validation loss: 1.9845414379591584

Epoch: 146| Step: 0
Training loss: 1.9296438694000244
Validation loss: 1.9925275412938928

Epoch: 5| Step: 1
Training loss: 1.907569169998169
Validation loss: 1.9873426575814523

Epoch: 5| Step: 2
Training loss: 2.269655704498291
Validation loss: 1.985231996864401

Epoch: 5| Step: 3
Training loss: 2.281393527984619
Validation loss: 1.9824765125910442

Epoch: 5| Step: 4
Training loss: 2.7687642574310303
Validation loss: 1.9834516125340615

Epoch: 5| Step: 5
Training loss: 2.298915147781372
Validation loss: 1.9816290204242994

Epoch: 5| Step: 6
Training loss: 2.138808488845825
Validation loss: 1.9892488500123382

Epoch: 5| Step: 7
Training loss: 2.240668773651123
Validation loss: 1.9973778006851033

Epoch: 5| Step: 8
Training loss: 2.3513007164001465
Validation loss: 1.9956862388118621

Epoch: 5| Step: 9
Training loss: 2.1145997047424316
Validation loss: 1.9959082359908729

Epoch: 5| Step: 10
Training loss: 2.6975104808807373
Validation loss: 1.9976896137319586

Epoch: 147| Step: 0
Training loss: 1.9616962671279907
Validation loss: 2.0128751441996586

Epoch: 5| Step: 1
Training loss: 2.5095295906066895
Validation loss: 2.031820689478228

Epoch: 5| Step: 2
Training loss: 2.101780652999878
Validation loss: 2.0243343358398764

Epoch: 5| Step: 3
Training loss: 2.5580050945281982
Validation loss: 2.0343888421212473

Epoch: 5| Step: 4
Training loss: 2.2909188270568848
Validation loss: 2.0416037241617837

Epoch: 5| Step: 5
Training loss: 2.626249313354492
Validation loss: 2.0821776441348496

Epoch: 5| Step: 6
Training loss: 1.6827703714370728
Validation loss: 2.109541077767649

Epoch: 5| Step: 7
Training loss: 2.2892439365386963
Validation loss: 2.098599777426771

Epoch: 5| Step: 8
Training loss: 2.266263008117676
Validation loss: 2.084983987192954

Epoch: 5| Step: 9
Training loss: 2.084894895553589
Validation loss: 2.10432493558494

Epoch: 5| Step: 10
Training loss: 2.506990432739258
Validation loss: 2.076985848847256

Epoch: 148| Step: 0
Training loss: 2.014289379119873
Validation loss: 2.086994483906736

Epoch: 5| Step: 1
Training loss: 1.927716851234436
Validation loss: 2.07231185513158

Epoch: 5| Step: 2
Training loss: 2.3042232990264893
Validation loss: 2.045673977944159

Epoch: 5| Step: 3
Training loss: 3.2916343212127686
Validation loss: 2.0455399251753286

Epoch: 5| Step: 4
Training loss: 2.5126612186431885
Validation loss: 2.025411218725225

Epoch: 5| Step: 5
Training loss: 1.6276721954345703
Validation loss: 2.0172908049757763

Epoch: 5| Step: 6
Training loss: 2.0841071605682373
Validation loss: 2.011015838192355

Epoch: 5| Step: 7
Training loss: 2.490607500076294
Validation loss: 2.004753215338594

Epoch: 5| Step: 8
Training loss: 2.378247022628784
Validation loss: 2.010455874986546

Epoch: 5| Step: 9
Training loss: 2.1992435455322266
Validation loss: 2.0029394729163057

Epoch: 5| Step: 10
Training loss: 1.796885371208191
Validation loss: 2.01389451308917

Epoch: 149| Step: 0
Training loss: 2.1443777084350586
Validation loss: 2.0150655277313723

Epoch: 5| Step: 1
Training loss: 2.7024550437927246
Validation loss: 2.0158884166389384

Epoch: 5| Step: 2
Training loss: 1.7660093307495117
Validation loss: 2.009452332732498

Epoch: 5| Step: 3
Training loss: 1.9737895727157593
Validation loss: 2.019335372473604

Epoch: 5| Step: 4
Training loss: 2.4378764629364014
Validation loss: 2.0031186893422115

Epoch: 5| Step: 5
Training loss: 2.406625270843506
Validation loss: 2.0113880736853487

Epoch: 5| Step: 6
Training loss: 1.860227346420288
Validation loss: 2.0042037143502185

Epoch: 5| Step: 7
Training loss: 2.2876057624816895
Validation loss: 2.012362754473122

Epoch: 5| Step: 8
Training loss: 2.6073763370513916
Validation loss: 2.0201055426751413

Epoch: 5| Step: 9
Training loss: 2.4216461181640625
Validation loss: 2.01700637930183

Epoch: 5| Step: 10
Training loss: 2.0581307411193848
Validation loss: 2.0342675844828286

Epoch: 150| Step: 0
Training loss: 2.3262031078338623
Validation loss: 2.019147301232943

Epoch: 5| Step: 1
Training loss: 2.1273608207702637
Validation loss: 2.041099489376109

Epoch: 5| Step: 2
Training loss: 2.8476855754852295
Validation loss: 2.0236538763969176

Epoch: 5| Step: 3
Training loss: 2.222081422805786
Validation loss: 2.0107745790994294

Epoch: 5| Step: 4
Training loss: 2.522695779800415
Validation loss: 2.02067425686826

Epoch: 5| Step: 5
Training loss: 2.472114086151123
Validation loss: 2.0100208610616703

Epoch: 5| Step: 6
Training loss: 1.7539165019989014
Validation loss: 2.029049011968797

Epoch: 5| Step: 7
Training loss: 1.9283239841461182
Validation loss: 2.0270026473588842

Epoch: 5| Step: 8
Training loss: 2.8016600608825684
Validation loss: 2.0592716945114957

Epoch: 5| Step: 9
Training loss: 1.5112006664276123
Validation loss: 2.0880018459853305

Epoch: 5| Step: 10
Training loss: 2.1494171619415283
Validation loss: 2.0863063796874015

Epoch: 151| Step: 0
Training loss: 2.828146457672119
Validation loss: 2.0870600643978325

Epoch: 5| Step: 1
Training loss: 2.000847339630127
Validation loss: 2.0718460775190786

Epoch: 5| Step: 2
Training loss: 1.684096336364746
Validation loss: 2.0581949257081553

Epoch: 5| Step: 3
Training loss: 2.3877017498016357
Validation loss: 2.0242845268659693

Epoch: 5| Step: 4
Training loss: 2.2596161365509033
Validation loss: 2.021515175860415

Epoch: 5| Step: 5
Training loss: 2.2253661155700684
Validation loss: 2.0223226521604802

Epoch: 5| Step: 6
Training loss: 2.756338596343994
Validation loss: 2.008114905767543

Epoch: 5| Step: 7
Training loss: 1.761537790298462
Validation loss: 2.0064458590681835

Epoch: 5| Step: 8
Training loss: 2.0534822940826416
Validation loss: 2.0090309650667253

Epoch: 5| Step: 9
Training loss: 2.702894687652588
Validation loss: 2.0081451913361907

Epoch: 5| Step: 10
Training loss: 1.955207347869873
Validation loss: 2.001636223126483

Epoch: 152| Step: 0
Training loss: 2.028416156768799
Validation loss: 2.0089509743516163

Epoch: 5| Step: 1
Training loss: 2.1974687576293945
Validation loss: 2.009352742984731

Epoch: 5| Step: 2
Training loss: 1.8443171977996826
Validation loss: 2.005482341653557

Epoch: 5| Step: 3
Training loss: 2.2668888568878174
Validation loss: 2.021604523863844

Epoch: 5| Step: 4
Training loss: 2.2802932262420654
Validation loss: 2.0258524520422823

Epoch: 5| Step: 5
Training loss: 2.3965582847595215
Validation loss: 2.0364947293394353

Epoch: 5| Step: 6
Training loss: 2.185107469558716
Validation loss: 2.036658030684276

Epoch: 5| Step: 7
Training loss: 2.397566318511963
Validation loss: 2.038010915120443

Epoch: 5| Step: 8
Training loss: 2.655522108078003
Validation loss: 2.0187312274850826

Epoch: 5| Step: 9
Training loss: 2.4448177814483643
Validation loss: 2.022277157793763

Epoch: 5| Step: 10
Training loss: 1.92924165725708
Validation loss: 2.0367101507802166

Epoch: 153| Step: 0
Training loss: 2.200913906097412
Validation loss: 2.0359934760678198

Epoch: 5| Step: 1
Training loss: 2.6642184257507324
Validation loss: 2.0561962768595707

Epoch: 5| Step: 2
Training loss: 2.2101335525512695
Validation loss: 2.0504057804743447

Epoch: 5| Step: 3
Training loss: 1.8682750463485718
Validation loss: 2.0519973718991844

Epoch: 5| Step: 4
Training loss: 2.1912646293640137
Validation loss: 2.039215680091612

Epoch: 5| Step: 5
Training loss: 2.1306564807891846
Validation loss: 2.0324654527889785

Epoch: 5| Step: 6
Training loss: 1.9994258880615234
Validation loss: 2.057350927783597

Epoch: 5| Step: 7
Training loss: 2.5935332775115967
Validation loss: 2.0776177042274067

Epoch: 5| Step: 8
Training loss: 2.758617877960205
Validation loss: 2.1288846782458726

Epoch: 5| Step: 9
Training loss: 1.475510835647583
Validation loss: 2.1350207098068728

Epoch: 5| Step: 10
Training loss: 2.901578187942505
Validation loss: 2.137479107867005

Epoch: 154| Step: 0
Training loss: 1.7861055135726929
Validation loss: 2.1375248483432236

Epoch: 5| Step: 1
Training loss: 2.0771400928497314
Validation loss: 2.1305159855914373

Epoch: 5| Step: 2
Training loss: 2.2566444873809814
Validation loss: 2.1503391599142425

Epoch: 5| Step: 3
Training loss: 2.2743680477142334
Validation loss: 2.1093637148539224

Epoch: 5| Step: 4
Training loss: 2.532470464706421
Validation loss: 2.1011535416367235

Epoch: 5| Step: 5
Training loss: 2.052361488342285
Validation loss: 2.103481449106688

Epoch: 5| Step: 6
Training loss: 2.4826457500457764
Validation loss: 2.090972364589732

Epoch: 5| Step: 7
Training loss: 2.5101845264434814
Validation loss: 2.0970920901144705

Epoch: 5| Step: 8
Training loss: 2.4856109619140625
Validation loss: 2.085422954251689

Epoch: 5| Step: 9
Training loss: 2.02187180519104
Validation loss: 2.0633328191695677

Epoch: 5| Step: 10
Training loss: 2.5182650089263916
Validation loss: 2.0425105453819357

Epoch: 155| Step: 0
Training loss: 1.6661468744277954
Validation loss: 2.0288299078582437

Epoch: 5| Step: 1
Training loss: 2.539621353149414
Validation loss: 2.0100901383225636

Epoch: 5| Step: 2
Training loss: 2.6644227504730225
Validation loss: 1.9957041945508731

Epoch: 5| Step: 3
Training loss: 2.7476305961608887
Validation loss: 2.00093226919892

Epoch: 5| Step: 4
Training loss: 2.4090170860290527
Validation loss: 1.985377223260941

Epoch: 5| Step: 5
Training loss: 2.1678240299224854
Validation loss: 1.9869612237458587

Epoch: 5| Step: 6
Training loss: 1.5141055583953857
Validation loss: 2.0117014172256633

Epoch: 5| Step: 7
Training loss: 2.166585922241211
Validation loss: 1.9971752717930784

Epoch: 5| Step: 8
Training loss: 2.4928107261657715
Validation loss: 1.9976114021834506

Epoch: 5| Step: 9
Training loss: 2.023895502090454
Validation loss: 1.9874125321706135

Epoch: 5| Step: 10
Training loss: 2.27693772315979
Validation loss: 1.9808285415813487

Epoch: 156| Step: 0
Training loss: 2.528902769088745
Validation loss: 1.9728901181169736

Epoch: 5| Step: 1
Training loss: 2.19404935836792
Validation loss: 1.976819820301507

Epoch: 5| Step: 2
Training loss: 2.519681453704834
Validation loss: 1.9728045361016386

Epoch: 5| Step: 3
Training loss: 2.0536763668060303
Validation loss: 1.9735682267014698

Epoch: 5| Step: 4
Training loss: 2.531829357147217
Validation loss: 1.9824926109724148

Epoch: 5| Step: 5
Training loss: 2.0336990356445312
Validation loss: 1.9852667931587464

Epoch: 5| Step: 6
Training loss: 2.204601287841797
Validation loss: 2.0079031234146445

Epoch: 5| Step: 7
Training loss: 1.8706191778182983
Validation loss: 2.0393771612516014

Epoch: 5| Step: 8
Training loss: 2.2777740955352783
Validation loss: 2.0370258080062045

Epoch: 5| Step: 9
Training loss: 2.3387131690979004
Validation loss: 2.071529052590811

Epoch: 5| Step: 10
Training loss: 1.7940566539764404
Validation loss: 2.0986901662682973

Epoch: 157| Step: 0
Training loss: 2.3051044940948486
Validation loss: 2.097811997577708

Epoch: 5| Step: 1
Training loss: 2.0647425651550293
Validation loss: 2.1101756916251233

Epoch: 5| Step: 2
Training loss: 2.406212329864502
Validation loss: 2.10147108826586

Epoch: 5| Step: 3
Training loss: 2.03590726852417
Validation loss: 2.064078951394686

Epoch: 5| Step: 4
Training loss: 1.966623306274414
Validation loss: 2.0447863776196717

Epoch: 5| Step: 5
Training loss: 2.1275343894958496
Validation loss: 2.0152954978327595

Epoch: 5| Step: 6
Training loss: 2.506984233856201
Validation loss: 2.0034938320036857

Epoch: 5| Step: 7
Training loss: 2.863144636154175
Validation loss: 2.017676297054496

Epoch: 5| Step: 8
Training loss: 2.2715632915496826
Validation loss: 2.0466245476917555

Epoch: 5| Step: 9
Training loss: 1.9817606210708618
Validation loss: 2.056220268690458

Epoch: 5| Step: 10
Training loss: 2.397801160812378
Validation loss: 2.0737596814350416

Epoch: 158| Step: 0
Training loss: 1.630139946937561
Validation loss: 2.048121770222982

Epoch: 5| Step: 1
Training loss: 2.3933522701263428
Validation loss: 2.037715514500936

Epoch: 5| Step: 2
Training loss: 2.311927080154419
Validation loss: 2.052373460544053

Epoch: 5| Step: 3
Training loss: 2.2116453647613525
Validation loss: 2.0491960817767727

Epoch: 5| Step: 4
Training loss: 2.4025886058807373
Validation loss: 2.064757888035108

Epoch: 5| Step: 5
Training loss: 1.941115140914917
Validation loss: 2.0599805488381335

Epoch: 5| Step: 6
Training loss: 2.0999503135681152
Validation loss: 2.059201714813068

Epoch: 5| Step: 7
Training loss: 2.3000645637512207
Validation loss: 2.0645231098257084

Epoch: 5| Step: 8
Training loss: 2.726835250854492
Validation loss: 2.062972540496498

Epoch: 5| Step: 9
Training loss: 1.7131977081298828
Validation loss: 2.0635389486948648

Epoch: 5| Step: 10
Training loss: 2.746764898300171
Validation loss: 2.0696764389673867

Epoch: 159| Step: 0
Training loss: 1.7208188772201538
Validation loss: 2.0853076493868263

Epoch: 5| Step: 1
Training loss: 2.211214065551758
Validation loss: 2.0949846595846195

Epoch: 5| Step: 2
Training loss: 3.061910629272461
Validation loss: 2.0885291048275527

Epoch: 5| Step: 3
Training loss: 2.1120476722717285
Validation loss: 2.0817964217996083

Epoch: 5| Step: 4
Training loss: 2.1879525184631348
Validation loss: 2.0767872794981925

Epoch: 5| Step: 5
Training loss: 1.8108627796173096
Validation loss: 2.064760886212831

Epoch: 5| Step: 6
Training loss: 2.321021795272827
Validation loss: 2.0909542293958765

Epoch: 5| Step: 7
Training loss: 2.139111042022705
Validation loss: 2.0912387473608858

Epoch: 5| Step: 8
Training loss: 2.6096320152282715
Validation loss: 2.0813702690985894

Epoch: 5| Step: 9
Training loss: 1.9811623096466064
Validation loss: 2.058816825189898

Epoch: 5| Step: 10
Training loss: 2.2112255096435547
Validation loss: 2.0459914361276934

Epoch: 160| Step: 0
Training loss: 2.0110220909118652
Validation loss: 2.0317465669365338

Epoch: 5| Step: 1
Training loss: 2.790738105773926
Validation loss: 2.0157698944050777

Epoch: 5| Step: 2
Training loss: 2.0157625675201416
Validation loss: 2.0071517177807388

Epoch: 5| Step: 3
Training loss: 2.0553629398345947
Validation loss: 2.0056146665285994

Epoch: 5| Step: 4
Training loss: 2.4244167804718018
Validation loss: 2.002264206127454

Epoch: 5| Step: 5
Training loss: 2.0125980377197266
Validation loss: 2.02705983449054

Epoch: 5| Step: 6
Training loss: 2.140995740890503
Validation loss: 2.024514780249647

Epoch: 5| Step: 7
Training loss: 2.414823532104492
Validation loss: 2.017620687843651

Epoch: 5| Step: 8
Training loss: 2.695592164993286
Validation loss: 2.0231428761636057

Epoch: 5| Step: 9
Training loss: 2.023146152496338
Validation loss: 2.0281032951929236

Epoch: 5| Step: 10
Training loss: 1.9211863279342651
Validation loss: 2.0067241486682685

Epoch: 161| Step: 0
Training loss: 1.7507003545761108
Validation loss: 2.0067141402152275

Epoch: 5| Step: 1
Training loss: 1.966261863708496
Validation loss: 2.0200463238582818

Epoch: 5| Step: 2
Training loss: 2.6370291709899902
Validation loss: 2.0193395691533245

Epoch: 5| Step: 3
Training loss: 1.7875773906707764
Validation loss: 2.027970657553724

Epoch: 5| Step: 4
Training loss: 1.9651718139648438
Validation loss: 2.0258131924495903

Epoch: 5| Step: 5
Training loss: 2.4315102100372314
Validation loss: 2.043071407143788

Epoch: 5| Step: 6
Training loss: 2.552135944366455
Validation loss: 2.0325119239027782

Epoch: 5| Step: 7
Training loss: 1.85366952419281
Validation loss: 2.0308611880066576

Epoch: 5| Step: 8
Training loss: 2.683502197265625
Validation loss: 2.048374246525508

Epoch: 5| Step: 9
Training loss: 2.4571762084960938
Validation loss: 2.0507646965724167

Epoch: 5| Step: 10
Training loss: 2.2404494285583496
Validation loss: 2.0765563890498173

Epoch: 162| Step: 0
Training loss: 2.0076637268066406
Validation loss: 2.0868428830177552

Epoch: 5| Step: 1
Training loss: 1.947150468826294
Validation loss: 2.0917319533645466

Epoch: 5| Step: 2
Training loss: 2.6005754470825195
Validation loss: 2.098985125941615

Epoch: 5| Step: 3
Training loss: 1.7930234670639038
Validation loss: 2.1100752366486417

Epoch: 5| Step: 4
Training loss: 2.1050937175750732
Validation loss: 2.118303047713413

Epoch: 5| Step: 5
Training loss: 2.0640463829040527
Validation loss: 2.1228828071266093

Epoch: 5| Step: 6
Training loss: 2.30922532081604
Validation loss: 2.1048898901990665

Epoch: 5| Step: 7
Training loss: 2.3719775676727295
Validation loss: 2.1004278531638523

Epoch: 5| Step: 8
Training loss: 2.3478457927703857
Validation loss: 2.1182694819665726

Epoch: 5| Step: 9
Training loss: 2.3795056343078613
Validation loss: 2.0887558178235124

Epoch: 5| Step: 10
Training loss: 2.488515853881836
Validation loss: 2.06327994151782

Epoch: 163| Step: 0
Training loss: 1.6072885990142822
Validation loss: 2.0394012005098405

Epoch: 5| Step: 1
Training loss: 2.595066547393799
Validation loss: 2.02728949310959

Epoch: 5| Step: 2
Training loss: 1.448915719985962
Validation loss: 2.0308233563617994

Epoch: 5| Step: 3
Training loss: 2.3911571502685547
Validation loss: 2.0218498219725904

Epoch: 5| Step: 4
Training loss: 2.169480085372925
Validation loss: 2.013278471526279

Epoch: 5| Step: 5
Training loss: 2.2752280235290527
Validation loss: 2.020163632208301

Epoch: 5| Step: 6
Training loss: 1.745868444442749
Validation loss: 2.0120434812320176

Epoch: 5| Step: 7
Training loss: 2.642810106277466
Validation loss: 2.0232096384930354

Epoch: 5| Step: 8
Training loss: 2.32718563079834
Validation loss: 2.0239191337298323

Epoch: 5| Step: 9
Training loss: 2.4152233600616455
Validation loss: 2.028569450942419

Epoch: 5| Step: 10
Training loss: 2.4385721683502197
Validation loss: 2.054718699506534

Epoch: 164| Step: 0
Training loss: 2.0543735027313232
Validation loss: 2.0434150541982343

Epoch: 5| Step: 1
Training loss: 2.92492938041687
Validation loss: 2.045989926143359

Epoch: 5| Step: 2
Training loss: 1.962415337562561
Validation loss: 2.047734729705318

Epoch: 5| Step: 3
Training loss: 3.036224365234375
Validation loss: 2.036857904926423

Epoch: 5| Step: 4
Training loss: 1.6926543712615967
Validation loss: 2.0168340334328274

Epoch: 5| Step: 5
Training loss: 1.690709114074707
Validation loss: 2.0108828877889984

Epoch: 5| Step: 6
Training loss: 1.9189971685409546
Validation loss: 2.017927469745759

Epoch: 5| Step: 7
Training loss: 2.5971198081970215
Validation loss: 2.0137773483030257

Epoch: 5| Step: 8
Training loss: 2.3989920616149902
Validation loss: 2.0207507635957453

Epoch: 5| Step: 9
Training loss: 1.4525926113128662
Validation loss: 2.0387072358080136

Epoch: 5| Step: 10
Training loss: 2.6912734508514404
Validation loss: 2.042852440188008

Epoch: 165| Step: 0
Training loss: 2.2531991004943848
Validation loss: 2.0217737587549354

Epoch: 5| Step: 1
Training loss: 2.6538166999816895
Validation loss: 2.040273115199099

Epoch: 5| Step: 2
Training loss: 2.402940034866333
Validation loss: 2.0675775133153445

Epoch: 5| Step: 3
Training loss: 2.617616653442383
Validation loss: 2.0962173041476997

Epoch: 5| Step: 4
Training loss: 2.006941795349121
Validation loss: 2.120832040745725

Epoch: 5| Step: 5
Training loss: 2.8631203174591064
Validation loss: 2.125840829264733

Epoch: 5| Step: 6
Training loss: 1.7786725759506226
Validation loss: 2.1309486127668813

Epoch: 5| Step: 7
Training loss: 1.417110562324524
Validation loss: 2.1208559082400416

Epoch: 5| Step: 8
Training loss: 2.0571398735046387
Validation loss: 2.148700956375368

Epoch: 5| Step: 9
Training loss: 1.670492172241211
Validation loss: 2.130646344154112

Epoch: 5| Step: 10
Training loss: 2.4175689220428467
Validation loss: 2.1081962457267185

Epoch: 166| Step: 0
Training loss: 2.7247910499572754
Validation loss: 2.0800034076936784

Epoch: 5| Step: 1
Training loss: 1.8809915781021118
Validation loss: 2.070186566281062

Epoch: 5| Step: 2
Training loss: 2.255553960800171
Validation loss: 2.0520434302668416

Epoch: 5| Step: 3
Training loss: 2.0203073024749756
Validation loss: 2.0429949657891386

Epoch: 5| Step: 4
Training loss: 1.5402815341949463
Validation loss: 2.017264776332404

Epoch: 5| Step: 5
Training loss: 2.371009349822998
Validation loss: 2.0457040597033758

Epoch: 5| Step: 6
Training loss: 2.3863914012908936
Validation loss: 2.066696466938142

Epoch: 5| Step: 7
Training loss: 2.4346516132354736
Validation loss: 2.067752303615693

Epoch: 5| Step: 8
Training loss: 2.1610605716705322
Validation loss: 2.0620651783481723

Epoch: 5| Step: 9
Training loss: 1.7530730962753296
Validation loss: 2.068867104027861

Epoch: 5| Step: 10
Training loss: 2.429490566253662
Validation loss: 2.0741626088337233

Epoch: 167| Step: 0
Training loss: 2.256092071533203
Validation loss: 2.0638021525516304

Epoch: 5| Step: 1
Training loss: 1.305338978767395
Validation loss: 2.0572739570371565

Epoch: 5| Step: 2
Training loss: 2.0070834159851074
Validation loss: 2.0674974226182505

Epoch: 5| Step: 3
Training loss: 1.7501176595687866
Validation loss: 2.0960783650798183

Epoch: 5| Step: 4
Training loss: 3.0336194038391113
Validation loss: 2.1305632693793184

Epoch: 5| Step: 5
Training loss: 2.881157636642456
Validation loss: 2.1463615253407466

Epoch: 5| Step: 6
Training loss: 2.9654643535614014
Validation loss: 2.14684477672782

Epoch: 5| Step: 7
Training loss: 1.798729658126831
Validation loss: 2.095824449293075

Epoch: 5| Step: 8
Training loss: 2.308443546295166
Validation loss: 2.0602047046025596

Epoch: 5| Step: 9
Training loss: 2.102539539337158
Validation loss: 2.063035713729038

Epoch: 5| Step: 10
Training loss: 2.290372848510742
Validation loss: 2.0504516657962593

Epoch: 168| Step: 0
Training loss: 1.7099567651748657
Validation loss: 2.060240553271386

Epoch: 5| Step: 1
Training loss: 2.3532347679138184
Validation loss: 2.032572760376879

Epoch: 5| Step: 2
Training loss: 2.4103312492370605
Validation loss: 2.05564433656713

Epoch: 5| Step: 3
Training loss: 1.8317358493804932
Validation loss: 2.045170166159189

Epoch: 5| Step: 4
Training loss: 2.3917319774627686
Validation loss: 2.0254605688074583

Epoch: 5| Step: 5
Training loss: 1.9763367176055908
Validation loss: 2.015121720170462

Epoch: 5| Step: 6
Training loss: 2.3173859119415283
Validation loss: 2.012827479711143

Epoch: 5| Step: 7
Training loss: 2.603435516357422
Validation loss: 2.008215444062346

Epoch: 5| Step: 8
Training loss: 2.233558177947998
Validation loss: 1.994777633297828

Epoch: 5| Step: 9
Training loss: 2.235403537750244
Validation loss: 1.9929349576273272

Epoch: 5| Step: 10
Training loss: 2.0124309062957764
Validation loss: 2.0049344019223283

Epoch: 169| Step: 0
Training loss: 2.1827304363250732
Validation loss: 2.0147467121001212

Epoch: 5| Step: 1
Training loss: 2.2323622703552246
Validation loss: 2.027010157544126

Epoch: 5| Step: 2
Training loss: 2.4519050121307373
Validation loss: 2.0356065944958757

Epoch: 5| Step: 3
Training loss: 1.727508783340454
Validation loss: 2.0344462189623105

Epoch: 5| Step: 4
Training loss: 2.757017135620117
Validation loss: 2.061831566595262

Epoch: 5| Step: 5
Training loss: 1.9272264242172241
Validation loss: 2.0789986605285318

Epoch: 5| Step: 6
Training loss: 1.9190527200698853
Validation loss: 2.092474368310744

Epoch: 5| Step: 7
Training loss: 1.7613706588745117
Validation loss: 2.0960881107596943

Epoch: 5| Step: 8
Training loss: 2.082298994064331
Validation loss: 2.1437740761746644

Epoch: 5| Step: 9
Training loss: 2.9459469318389893
Validation loss: 2.1474878198357037

Epoch: 5| Step: 10
Training loss: 1.8293602466583252
Validation loss: 2.14784473629408

Epoch: 170| Step: 0
Training loss: 2.409712314605713
Validation loss: 2.1336171293771393

Epoch: 5| Step: 1
Training loss: 2.398587465286255
Validation loss: 2.1079177292444373

Epoch: 5| Step: 2
Training loss: 2.2410521507263184
Validation loss: 2.0773690708221926

Epoch: 5| Step: 3
Training loss: 2.250380039215088
Validation loss: 2.0511014102607645

Epoch: 5| Step: 4
Training loss: 1.7789825201034546
Validation loss: 2.041859970297865

Epoch: 5| Step: 5
Training loss: 2.5333316326141357
Validation loss: 2.0338387079136346

Epoch: 5| Step: 6
Training loss: 1.882663369178772
Validation loss: 2.0208434597138436

Epoch: 5| Step: 7
Training loss: 1.8997802734375
Validation loss: 2.0177285812234365

Epoch: 5| Step: 8
Training loss: 1.9678428173065186
Validation loss: 2.0081101668778287

Epoch: 5| Step: 9
Training loss: 2.1922218799591064
Validation loss: 2.015466983600329

Epoch: 5| Step: 10
Training loss: 2.3637218475341797
Validation loss: 2.0123077438723658

Epoch: 171| Step: 0
Training loss: 2.166121006011963
Validation loss: 1.9982380585003925

Epoch: 5| Step: 1
Training loss: 2.295125722885132
Validation loss: 2.011166491816121

Epoch: 5| Step: 2
Training loss: 2.548353672027588
Validation loss: 2.0031150335906656

Epoch: 5| Step: 3
Training loss: 1.2277010679244995
Validation loss: 2.005816387873824

Epoch: 5| Step: 4
Training loss: 2.0606794357299805
Validation loss: 2.0158605421743085

Epoch: 5| Step: 5
Training loss: 1.925902009010315
Validation loss: 2.0128976529644382

Epoch: 5| Step: 6
Training loss: 2.3201208114624023
Validation loss: 2.0162916452653947

Epoch: 5| Step: 7
Training loss: 2.286123037338257
Validation loss: 2.020056275911229

Epoch: 5| Step: 8
Training loss: 2.149843692779541
Validation loss: 2.0086726142514135

Epoch: 5| Step: 9
Training loss: 1.96109139919281
Validation loss: 2.0139404663475613

Epoch: 5| Step: 10
Training loss: 2.5049219131469727
Validation loss: 2.032983446633944

Epoch: 172| Step: 0
Training loss: 1.8706104755401611
Validation loss: 2.0386423436544274

Epoch: 5| Step: 1
Training loss: 2.371609687805176
Validation loss: 2.0478958955375095

Epoch: 5| Step: 2
Training loss: 2.2233757972717285
Validation loss: 2.0772007357689644

Epoch: 5| Step: 3
Training loss: 1.4044578075408936
Validation loss: 2.085895117893014

Epoch: 5| Step: 4
Training loss: 2.3019652366638184
Validation loss: 2.0966809411202707

Epoch: 5| Step: 5
Training loss: 2.473829746246338
Validation loss: 2.090506586977231

Epoch: 5| Step: 6
Training loss: 2.1766891479492188
Validation loss: 2.097464656317106

Epoch: 5| Step: 7
Training loss: 2.0633158683776855
Validation loss: 2.112575666878813

Epoch: 5| Step: 8
Training loss: 2.635634183883667
Validation loss: 2.087018976929367

Epoch: 5| Step: 9
Training loss: 1.9784822463989258
Validation loss: 2.0729243473340104

Epoch: 5| Step: 10
Training loss: 2.4449586868286133
Validation loss: 2.0528391650927964

Epoch: 173| Step: 0
Training loss: 1.9095470905303955
Validation loss: 2.038767312162666

Epoch: 5| Step: 1
Training loss: 2.1848132610321045
Validation loss: 2.042407317828107

Epoch: 5| Step: 2
Training loss: 1.5945675373077393
Validation loss: 2.03473227254806

Epoch: 5| Step: 3
Training loss: 1.6913810968399048
Validation loss: 2.0467073225205943

Epoch: 5| Step: 4
Training loss: 2.750566005706787
Validation loss: 2.058128255669789

Epoch: 5| Step: 5
Training loss: 2.64375376701355
Validation loss: 2.0322179486674647

Epoch: 5| Step: 6
Training loss: 2.351490020751953
Validation loss: 2.0278552693705403

Epoch: 5| Step: 7
Training loss: 2.1250338554382324
Validation loss: 2.020126568373813

Epoch: 5| Step: 8
Training loss: 2.1916604042053223
Validation loss: 1.9978927668704782

Epoch: 5| Step: 9
Training loss: 1.5343286991119385
Validation loss: 1.9994806474254978

Epoch: 5| Step: 10
Training loss: 2.4425008296966553
Validation loss: 1.994178351535592

Epoch: 174| Step: 0
Training loss: 1.9384090900421143
Validation loss: 1.9946857934357018

Epoch: 5| Step: 1
Training loss: 2.9166390895843506
Validation loss: 1.992214008044171

Epoch: 5| Step: 2
Training loss: 1.9122943878173828
Validation loss: 2.0040889093952794

Epoch: 5| Step: 3
Training loss: 2.133126735687256
Validation loss: 2.0167785536858345

Epoch: 5| Step: 4
Training loss: 1.9545392990112305
Validation loss: 2.0264253975242696

Epoch: 5| Step: 5
Training loss: 2.5297343730926514
Validation loss: 2.044371553646621

Epoch: 5| Step: 6
Training loss: 1.9204342365264893
Validation loss: 2.036686904968754

Epoch: 5| Step: 7
Training loss: 1.7984482049942017
Validation loss: 2.0735114338577434

Epoch: 5| Step: 8
Training loss: 2.204944133758545
Validation loss: 2.099242347542958

Epoch: 5| Step: 9
Training loss: 2.1650617122650146
Validation loss: 2.137521768129

Epoch: 5| Step: 10
Training loss: 1.6763900518417358
Validation loss: 2.1313299158568024

Epoch: 175| Step: 0
Training loss: 2.7036075592041016
Validation loss: 2.1252370265222367

Epoch: 5| Step: 1
Training loss: 1.8683290481567383
Validation loss: 2.098491350809733

Epoch: 5| Step: 2
Training loss: 2.318127155303955
Validation loss: 2.0746577119314544

Epoch: 5| Step: 3
Training loss: 1.8255767822265625
Validation loss: 2.0776660801261984

Epoch: 5| Step: 4
Training loss: 2.184459924697876
Validation loss: 2.079871598110404

Epoch: 5| Step: 5
Training loss: 1.7985401153564453
Validation loss: 2.064944709500959

Epoch: 5| Step: 6
Training loss: 2.1254143714904785
Validation loss: 2.0410432443823865

Epoch: 5| Step: 7
Training loss: 1.8384811878204346
Validation loss: 2.034471606695524

Epoch: 5| Step: 8
Training loss: 2.4862220287323
Validation loss: 2.027718464533488

Epoch: 5| Step: 9
Training loss: 2.479788064956665
Validation loss: 2.023551494844498

Epoch: 5| Step: 10
Training loss: 1.557978868484497
Validation loss: 2.0286651375473186

Epoch: 176| Step: 0
Training loss: 1.7333095073699951
Validation loss: 2.032114782641011

Epoch: 5| Step: 1
Training loss: 2.457728147506714
Validation loss: 2.0162601432492657

Epoch: 5| Step: 2
Training loss: 2.4013209342956543
Validation loss: 2.010811044323829

Epoch: 5| Step: 3
Training loss: 1.9887778759002686
Validation loss: 2.002653544948947

Epoch: 5| Step: 4
Training loss: 2.2170255184173584
Validation loss: 1.9986998163243777

Epoch: 5| Step: 5
Training loss: 2.7588343620300293
Validation loss: 2.0097533220885904

Epoch: 5| Step: 6
Training loss: 1.8350547552108765
Validation loss: 2.0238392609421925

Epoch: 5| Step: 7
Training loss: 1.651492714881897
Validation loss: 2.01514684513051

Epoch: 5| Step: 8
Training loss: 2.4182779788970947
Validation loss: 2.0181013230354554

Epoch: 5| Step: 9
Training loss: 2.1722075939178467
Validation loss: 2.0326611777787567

Epoch: 5| Step: 10
Training loss: 1.9786235094070435
Validation loss: 2.0232516283630044

Epoch: 177| Step: 0
Training loss: 2.0466418266296387
Validation loss: 2.0172607796166533

Epoch: 5| Step: 1
Training loss: 2.3081412315368652
Validation loss: 2.028252770823817

Epoch: 5| Step: 2
Training loss: 1.5875968933105469
Validation loss: 2.018987294166319

Epoch: 5| Step: 3
Training loss: 1.4454880952835083
Validation loss: 2.034824876375096

Epoch: 5| Step: 4
Training loss: 2.1720921993255615
Validation loss: 2.0410966168167772

Epoch: 5| Step: 5
Training loss: 2.521503448486328
Validation loss: 2.054497725220137

Epoch: 5| Step: 6
Training loss: 2.277899742126465
Validation loss: 2.0530835120908675

Epoch: 5| Step: 7
Training loss: 2.5912461280822754
Validation loss: 2.0776604003803705

Epoch: 5| Step: 8
Training loss: 2.336752414703369
Validation loss: 2.0698695182800293

Epoch: 5| Step: 9
Training loss: 2.046722888946533
Validation loss: 2.067446885570403

Epoch: 5| Step: 10
Training loss: 1.495970606803894
Validation loss: 2.1024919671397053

Epoch: 178| Step: 0
Training loss: 2.064251184463501
Validation loss: 2.1138622350590204

Epoch: 5| Step: 1
Training loss: 1.7913610935211182
Validation loss: 2.0691643991777973

Epoch: 5| Step: 2
Training loss: 2.2014753818511963
Validation loss: 2.0722329796001477

Epoch: 5| Step: 3
Training loss: 1.9138847589492798
Validation loss: 2.040047912187474

Epoch: 5| Step: 4
Training loss: 2.023195743560791
Validation loss: 2.058742578311633

Epoch: 5| Step: 5
Training loss: 1.8840000629425049
Validation loss: 2.059475011723016

Epoch: 5| Step: 6
Training loss: 1.9761507511138916
Validation loss: 2.0639311446938464

Epoch: 5| Step: 7
Training loss: 2.297034740447998
Validation loss: 2.0593605118413127

Epoch: 5| Step: 8
Training loss: 2.145437717437744
Validation loss: 2.0528988774104784

Epoch: 5| Step: 9
Training loss: 2.3579940795898438
Validation loss: 2.0333148382043325

Epoch: 5| Step: 10
Training loss: 2.3687925338745117
Validation loss: 2.02991041316781

Epoch: 179| Step: 0
Training loss: 1.9613676071166992
Validation loss: 2.0248115703623784

Epoch: 5| Step: 1
Training loss: 1.773799180984497
Validation loss: 2.0363430720503612

Epoch: 5| Step: 2
Training loss: 2.154115915298462
Validation loss: 2.0499797790281233

Epoch: 5| Step: 3
Training loss: 1.8016999959945679
Validation loss: 2.060253293283524

Epoch: 5| Step: 4
Training loss: 2.5863709449768066
Validation loss: 2.04770867670736

Epoch: 5| Step: 5
Training loss: 2.2464146614074707
Validation loss: 2.040447594017111

Epoch: 5| Step: 6
Training loss: 1.988465666770935
Validation loss: 2.0277343847418345

Epoch: 5| Step: 7
Training loss: 2.297929286956787
Validation loss: 2.0244086711637435

Epoch: 5| Step: 8
Training loss: 2.1518635749816895
Validation loss: 2.023648620933615

Epoch: 5| Step: 9
Training loss: 1.882432222366333
Validation loss: 2.01997314089088

Epoch: 5| Step: 10
Training loss: 2.1713597774505615
Validation loss: 2.0181735215648526

Epoch: 180| Step: 0
Training loss: 2.104128360748291
Validation loss: 2.022837338909026

Epoch: 5| Step: 1
Training loss: 2.092684268951416
Validation loss: 2.0425388992473645

Epoch: 5| Step: 2
Training loss: 2.089174509048462
Validation loss: 2.049396757156618

Epoch: 5| Step: 3
Training loss: 1.6057374477386475
Validation loss: 2.0688150762229838

Epoch: 5| Step: 4
Training loss: 1.9531538486480713
Validation loss: 2.0602111316496328

Epoch: 5| Step: 5
Training loss: 2.6926488876342773
Validation loss: 2.060340964665977

Epoch: 5| Step: 6
Training loss: 1.7488737106323242
Validation loss: 2.0698635885792394

Epoch: 5| Step: 7
Training loss: 2.628211498260498
Validation loss: 2.0599744448097805

Epoch: 5| Step: 8
Training loss: 2.349821090698242
Validation loss: 2.0620715695042766

Epoch: 5| Step: 9
Training loss: 1.681052565574646
Validation loss: 2.05274409760711

Epoch: 5| Step: 10
Training loss: 1.817674160003662
Validation loss: 2.0549088511415707

Epoch: 181| Step: 0
Training loss: 1.4212862253189087
Validation loss: 2.076993200086778

Epoch: 5| Step: 1
Training loss: 2.182856798171997
Validation loss: 2.057738002910409

Epoch: 5| Step: 2
Training loss: 1.9514042139053345
Validation loss: 2.03374941502848

Epoch: 5| Step: 3
Training loss: 1.8525416851043701
Validation loss: 2.024078128158405

Epoch: 5| Step: 4
Training loss: 2.1104941368103027
Validation loss: 2.008716485833609

Epoch: 5| Step: 5
Training loss: 2.890075922012329
Validation loss: 2.006654131797052

Epoch: 5| Step: 6
Training loss: 2.2639169692993164
Validation loss: 2.00090665330169

Epoch: 5| Step: 7
Training loss: 2.167959690093994
Validation loss: 2.0128661509483092

Epoch: 5| Step: 8
Training loss: 2.3919763565063477
Validation loss: 1.9979697094168714

Epoch: 5| Step: 9
Training loss: 1.8416551351547241
Validation loss: 2.00988918735135

Epoch: 5| Step: 10
Training loss: 1.68601393699646
Validation loss: 2.0103959216866443

Epoch: 182| Step: 0
Training loss: 1.1113722324371338
Validation loss: 2.012782831345835

Epoch: 5| Step: 1
Training loss: 2.4543263912200928
Validation loss: 2.012629806354482

Epoch: 5| Step: 2
Training loss: 2.2792787551879883
Validation loss: 2.006373869475498

Epoch: 5| Step: 3
Training loss: 1.8633098602294922
Validation loss: 2.013177876831383

Epoch: 5| Step: 4
Training loss: 1.3817198276519775
Validation loss: 2.0084190855744066

Epoch: 5| Step: 5
Training loss: 1.7731670141220093
Validation loss: 2.018172089771558

Epoch: 5| Step: 6
Training loss: 2.145963668823242
Validation loss: 2.0183625644253147

Epoch: 5| Step: 7
Training loss: 1.772599458694458
Validation loss: 2.007110911030923

Epoch: 5| Step: 8
Training loss: 2.223942279815674
Validation loss: 2.0166873008974138

Epoch: 5| Step: 9
Training loss: 2.4627013206481934
Validation loss: 2.024483541006683

Epoch: 5| Step: 10
Training loss: 3.0384521484375
Validation loss: 2.0069521114390385

Epoch: 183| Step: 0
Training loss: 1.73369562625885
Validation loss: 2.008025480854896

Epoch: 5| Step: 1
Training loss: 2.532362937927246
Validation loss: 2.0142496093626945

Epoch: 5| Step: 2
Training loss: 2.0617165565490723
Validation loss: 2.0116323758197088

Epoch: 5| Step: 3
Training loss: 2.1774725914001465
Validation loss: 2.001089488306353

Epoch: 5| Step: 4
Training loss: 1.7658004760742188
Validation loss: 2.009870359974523

Epoch: 5| Step: 5
Training loss: 2.0754787921905518
Validation loss: 2.0170109323275986

Epoch: 5| Step: 6
Training loss: 1.9323341846466064
Validation loss: 2.0316817017011743

Epoch: 5| Step: 7
Training loss: 2.0385353565216064
Validation loss: 2.0189462220796974

Epoch: 5| Step: 8
Training loss: 2.500324010848999
Validation loss: 2.039939293297388

Epoch: 5| Step: 9
Training loss: 1.6740859746932983
Validation loss: 2.0338867556664253

Epoch: 5| Step: 10
Training loss: 1.7893868684768677
Validation loss: 2.035309386509721

Epoch: 184| Step: 0
Training loss: 1.6453574895858765
Validation loss: 2.035343136838687

Epoch: 5| Step: 1
Training loss: 1.4061295986175537
Validation loss: 2.026357623838609

Epoch: 5| Step: 2
Training loss: 2.038191080093384
Validation loss: 2.0200760492714505

Epoch: 5| Step: 3
Training loss: 2.1127941608428955
Validation loss: 2.0434533062801568

Epoch: 5| Step: 4
Training loss: 2.554292917251587
Validation loss: 2.0541629150349605

Epoch: 5| Step: 5
Training loss: 1.7871580123901367
Validation loss: 2.042232027617834

Epoch: 5| Step: 6
Training loss: 2.289888620376587
Validation loss: 2.0499083931728075

Epoch: 5| Step: 7
Training loss: 1.9645553827285767
Validation loss: 2.030865042440353

Epoch: 5| Step: 8
Training loss: 2.589712619781494
Validation loss: 2.0513935242929766

Epoch: 5| Step: 9
Training loss: 2.4300761222839355
Validation loss: 2.055459801868726

Epoch: 5| Step: 10
Training loss: 1.2909877300262451
Validation loss: 2.04823366800944

Epoch: 185| Step: 0
Training loss: 1.3114746809005737
Validation loss: 2.0423151062380884

Epoch: 5| Step: 1
Training loss: 2.178229808807373
Validation loss: 2.0464693551422446

Epoch: 5| Step: 2
Training loss: 1.8607219457626343
Validation loss: 2.022869917654222

Epoch: 5| Step: 3
Training loss: 2.5557072162628174
Validation loss: 2.0316786689143025

Epoch: 5| Step: 4
Training loss: 1.5112788677215576
Validation loss: 2.0168946801975207

Epoch: 5| Step: 5
Training loss: 2.288728713989258
Validation loss: 2.021205982854289

Epoch: 5| Step: 6
Training loss: 2.1071560382843018
Validation loss: 2.0300386541633197

Epoch: 5| Step: 7
Training loss: 2.342634916305542
Validation loss: 2.0446395233113277

Epoch: 5| Step: 8
Training loss: 1.79388427734375
Validation loss: 2.0419715886474936

Epoch: 5| Step: 9
Training loss: 1.7240955829620361
Validation loss: 2.052643747739894

Epoch: 5| Step: 10
Training loss: 2.477541446685791
Validation loss: 2.0492892470411075

Epoch: 186| Step: 0
Training loss: 1.4821258783340454
Validation loss: 2.0433035486487934

Epoch: 5| Step: 1
Training loss: 2.2769675254821777
Validation loss: 2.0485053536712483

Epoch: 5| Step: 2
Training loss: 2.3856334686279297
Validation loss: 2.05612414626665

Epoch: 5| Step: 3
Training loss: 2.656740427017212
Validation loss: 2.0592958337517193

Epoch: 5| Step: 4
Training loss: 1.8480064868927002
Validation loss: 2.0658946652566232

Epoch: 5| Step: 5
Training loss: 2.280705213546753
Validation loss: 2.047381683062482

Epoch: 5| Step: 6
Training loss: 1.7718849182128906
Validation loss: 2.0451525308752574

Epoch: 5| Step: 7
Training loss: 1.8207504749298096
Validation loss: 2.0221896094660603

Epoch: 5| Step: 8
Training loss: 1.5757544040679932
Validation loss: 2.0310939165853683

Epoch: 5| Step: 9
Training loss: 1.8747985363006592
Validation loss: 2.0198120814497753

Epoch: 5| Step: 10
Training loss: 2.072031259536743
Validation loss: 2.0128458648599605

Epoch: 187| Step: 0
Training loss: 1.5384206771850586
Validation loss: 2.012157542731172

Epoch: 5| Step: 1
Training loss: 2.251499891281128
Validation loss: 2.0020048554225633

Epoch: 5| Step: 2
Training loss: 1.8469970226287842
Validation loss: 2.0055732547595935

Epoch: 5| Step: 3
Training loss: 2.3686118125915527
Validation loss: 2.0116930072025587

Epoch: 5| Step: 4
Training loss: 2.3402035236358643
Validation loss: 2.007740246352329

Epoch: 5| Step: 5
Training loss: 1.8439991474151611
Validation loss: 2.0128013933858564

Epoch: 5| Step: 6
Training loss: 2.1742284297943115
Validation loss: 2.009495622368269

Epoch: 5| Step: 7
Training loss: 1.5629323720932007
Validation loss: 2.0048485891793364

Epoch: 5| Step: 8
Training loss: 2.042816638946533
Validation loss: 2.011612594768565

Epoch: 5| Step: 9
Training loss: 1.3399676084518433
Validation loss: 2.0322144185343096

Epoch: 5| Step: 10
Training loss: 2.7428970336914062
Validation loss: 2.0415794182849187

Epoch: 188| Step: 0
Training loss: 1.3191475868225098
Validation loss: 2.0396717415061048

Epoch: 5| Step: 1
Training loss: 1.818547010421753
Validation loss: 2.0224322811249764

Epoch: 5| Step: 2
Training loss: 1.6453475952148438
Validation loss: 2.0141011245789064

Epoch: 5| Step: 3
Training loss: 1.9368278980255127
Validation loss: 2.0113720381131737

Epoch: 5| Step: 4
Training loss: 2.549938201904297
Validation loss: 2.0225874031743696

Epoch: 5| Step: 5
Training loss: 1.9619977474212646
Validation loss: 2.00750591165276

Epoch: 5| Step: 6
Training loss: 2.3401942253112793
Validation loss: 2.018495337937468

Epoch: 5| Step: 7
Training loss: 2.1379764080047607
Validation loss: 2.0248854519218527

Epoch: 5| Step: 8
Training loss: 2.0181102752685547
Validation loss: 2.0203009549007622

Epoch: 5| Step: 9
Training loss: 2.5701236724853516
Validation loss: 2.011763261210534

Epoch: 5| Step: 10
Training loss: 2.2182624340057373
Validation loss: 2.0354052423149027

Epoch: 189| Step: 0
Training loss: 2.536827564239502
Validation loss: 2.0600338712815316

Epoch: 5| Step: 1
Training loss: 2.079102039337158
Validation loss: 2.055862044775358

Epoch: 5| Step: 2
Training loss: 2.4439854621887207
Validation loss: 2.059891446944206

Epoch: 5| Step: 3
Training loss: 1.0546600818634033
Validation loss: 2.0524726478002404

Epoch: 5| Step: 4
Training loss: 1.1180572509765625
Validation loss: 2.0633128227726107

Epoch: 5| Step: 5
Training loss: 2.106675863265991
Validation loss: 2.0564698583336285

Epoch: 5| Step: 6
Training loss: 2.1552555561065674
Validation loss: 2.0404028943789903

Epoch: 5| Step: 7
Training loss: 2.3736846446990967
Validation loss: 2.035740283227736

Epoch: 5| Step: 8
Training loss: 2.358337640762329
Validation loss: 2.016773795568815

Epoch: 5| Step: 9
Training loss: 2.0373120307922363
Validation loss: 2.0290495208514634

Epoch: 5| Step: 10
Training loss: 1.7247540950775146
Validation loss: 2.0280258694002704

Epoch: 190| Step: 0
Training loss: 2.2745308876037598
Validation loss: 2.02187329722989

Epoch: 5| Step: 1
Training loss: 1.5599416494369507
Validation loss: 2.0232792746636177

Epoch: 5| Step: 2
Training loss: 1.9721767902374268
Validation loss: 2.0042163697622155

Epoch: 5| Step: 3
Training loss: 2.6679563522338867
Validation loss: 2.0032810267581733

Epoch: 5| Step: 4
Training loss: 1.6819998025894165
Validation loss: 1.9987731133737872

Epoch: 5| Step: 5
Training loss: 1.3011178970336914
Validation loss: 2.0125543327741724

Epoch: 5| Step: 6
Training loss: 2.420928478240967
Validation loss: 2.017766665386897

Epoch: 5| Step: 7
Training loss: 1.9390836954116821
Validation loss: 2.0161870910275366

Epoch: 5| Step: 8
Training loss: 1.7472003698349
Validation loss: 2.0152436840918755

Epoch: 5| Step: 9
Training loss: 2.14837908744812
Validation loss: 2.023650565455037

Epoch: 5| Step: 10
Training loss: 2.077737331390381
Validation loss: 2.0246695651802966

Epoch: 191| Step: 0
Training loss: 1.5869455337524414
Validation loss: 2.0206284881919943

Epoch: 5| Step: 1
Training loss: 1.5145820379257202
Validation loss: 2.0190799620843705

Epoch: 5| Step: 2
Training loss: 2.639430522918701
Validation loss: 2.022454083606761

Epoch: 5| Step: 3
Training loss: 2.201040267944336
Validation loss: 2.0189818823209373

Epoch: 5| Step: 4
Training loss: 1.9767587184906006
Validation loss: 2.031376605392784

Epoch: 5| Step: 5
Training loss: 2.2291369438171387
Validation loss: 2.0423474106737363

Epoch: 5| Step: 6
Training loss: 1.3282673358917236
Validation loss: 2.074925793114529

Epoch: 5| Step: 7
Training loss: 2.4552688598632812
Validation loss: 2.066465254752867

Epoch: 5| Step: 8
Training loss: 1.324975609779358
Validation loss: 2.05605790691991

Epoch: 5| Step: 9
Training loss: 2.3333804607391357
Validation loss: 2.0450396640326387

Epoch: 5| Step: 10
Training loss: 2.1246163845062256
Validation loss: 2.0523919341384724

Epoch: 192| Step: 0
Training loss: 1.8240264654159546
Validation loss: 2.0690156234207975

Epoch: 5| Step: 1
Training loss: 1.8590247631072998
Validation loss: 2.0650524900805567

Epoch: 5| Step: 2
Training loss: 2.2156028747558594
Validation loss: 2.045900023111733

Epoch: 5| Step: 3
Training loss: 1.863527536392212
Validation loss: 2.03772638433723

Epoch: 5| Step: 4
Training loss: 2.4895200729370117
Validation loss: 2.0514042544108566

Epoch: 5| Step: 5
Training loss: 1.397477149963379
Validation loss: 2.038224874004241

Epoch: 5| Step: 6
Training loss: 2.235217571258545
Validation loss: 2.0313401709320726

Epoch: 5| Step: 7
Training loss: 1.7772210836410522
Validation loss: 2.0149531723350607

Epoch: 5| Step: 8
Training loss: 1.4349299669265747
Validation loss: 2.0054378676158127

Epoch: 5| Step: 9
Training loss: 2.10649037361145
Validation loss: 2.02411751849677

Epoch: 5| Step: 10
Training loss: 2.48089861869812
Validation loss: 2.010145859051776

Epoch: 193| Step: 0
Training loss: 1.421600341796875
Validation loss: 2.0232990454601985

Epoch: 5| Step: 1
Training loss: 1.637743353843689
Validation loss: 2.016821868958012

Epoch: 5| Step: 2
Training loss: 2.279721736907959
Validation loss: 2.0317257309472687

Epoch: 5| Step: 3
Training loss: 1.6825920343399048
Validation loss: 2.014954532346418

Epoch: 5| Step: 4
Training loss: 2.246464252471924
Validation loss: 2.017752424363167

Epoch: 5| Step: 5
Training loss: 2.576937198638916
Validation loss: 2.0364745509239937

Epoch: 5| Step: 6
Training loss: 2.4928202629089355
Validation loss: 2.0363633004567956

Epoch: 5| Step: 7
Training loss: 1.9822219610214233
Validation loss: 2.034952643097088

Epoch: 5| Step: 8
Training loss: 1.9013042449951172
Validation loss: 2.058681182963874

Epoch: 5| Step: 9
Training loss: 1.902860403060913
Validation loss: 2.047877980816749

Epoch: 5| Step: 10
Training loss: 1.9140902757644653
Validation loss: 2.0502702625848914

Epoch: 194| Step: 0
Training loss: 2.5683250427246094
Validation loss: 2.0449858967975905

Epoch: 5| Step: 1
Training loss: 2.093285083770752
Validation loss: 2.0341989430048133

Epoch: 5| Step: 2
Training loss: 2.043336868286133
Validation loss: 2.042883487157924

Epoch: 5| Step: 3
Training loss: 1.2160539627075195
Validation loss: 2.0531840708947953

Epoch: 5| Step: 4
Training loss: 2.046565055847168
Validation loss: 2.0585559696279545

Epoch: 5| Step: 5
Training loss: 1.444509506225586
Validation loss: 2.051210423951508

Epoch: 5| Step: 6
Training loss: 2.047811985015869
Validation loss: 2.030876933887441

Epoch: 5| Step: 7
Training loss: 2.0476489067077637
Validation loss: 2.0224257258958716

Epoch: 5| Step: 8
Training loss: 2.149326801300049
Validation loss: 2.018062312115905

Epoch: 5| Step: 9
Training loss: 2.251352071762085
Validation loss: 2.0188774652378534

Epoch: 5| Step: 10
Training loss: 1.367823600769043
Validation loss: 1.9985692501068115

Epoch: 195| Step: 0
Training loss: 1.8256632089614868
Validation loss: 2.0224618027287145

Epoch: 5| Step: 1
Training loss: 1.7770856618881226
Validation loss: 2.024189893917371

Epoch: 5| Step: 2
Training loss: 1.5240933895111084
Validation loss: 2.0180264442197737

Epoch: 5| Step: 3
Training loss: 2.0328850746154785
Validation loss: 2.0200686031772244

Epoch: 5| Step: 4
Training loss: 2.556750774383545
Validation loss: 2.01846811591938

Epoch: 5| Step: 5
Training loss: 2.4981160163879395
Validation loss: 2.024039573566888

Epoch: 5| Step: 6
Training loss: 1.6822004318237305
Validation loss: 2.0287658270969184

Epoch: 5| Step: 7
Training loss: 1.9676040410995483
Validation loss: 2.034741593945411

Epoch: 5| Step: 8
Training loss: 1.9121768474578857
Validation loss: 2.0424168507258096

Epoch: 5| Step: 9
Training loss: 1.7390270233154297
Validation loss: 2.0471175768042125

Epoch: 5| Step: 10
Training loss: 1.950579047203064
Validation loss: 2.044537003322314

Epoch: 196| Step: 0
Training loss: 2.172217845916748
Validation loss: 2.040103829035195

Epoch: 5| Step: 1
Training loss: 1.8159277439117432
Validation loss: 2.038557001339492

Epoch: 5| Step: 2
Training loss: 1.8936307430267334
Validation loss: 2.034674982870779

Epoch: 5| Step: 3
Training loss: 1.979935646057129
Validation loss: 2.025090035571847

Epoch: 5| Step: 4
Training loss: 1.991581678390503
Validation loss: 2.020649763845628

Epoch: 5| Step: 5
Training loss: 2.2110352516174316
Validation loss: 1.9967912435531616

Epoch: 5| Step: 6
Training loss: 1.9416354894638062
Validation loss: 1.9815745815154044

Epoch: 5| Step: 7
Training loss: 2.1696057319641113
Validation loss: 1.9847623148272115

Epoch: 5| Step: 8
Training loss: 1.7426822185516357
Validation loss: 1.9846382628205002

Epoch: 5| Step: 9
Training loss: 1.4051105976104736
Validation loss: 2.0027999352383357

Epoch: 5| Step: 10
Training loss: 2.1920955181121826
Validation loss: 2.0020558346984205

Epoch: 197| Step: 0
Training loss: 2.013309955596924
Validation loss: 2.0102951090822936

Epoch: 5| Step: 1
Training loss: 1.5575543642044067
Validation loss: 2.014203243358161

Epoch: 5| Step: 2
Training loss: 2.2976272106170654
Validation loss: 2.0227544999891713

Epoch: 5| Step: 3
Training loss: 1.8770440816879272
Validation loss: 2.0281795917018766

Epoch: 5| Step: 4
Training loss: 1.9715144634246826
Validation loss: 2.026963719757654

Epoch: 5| Step: 5
Training loss: 1.8437178134918213
Validation loss: 2.055461727162843

Epoch: 5| Step: 6
Training loss: 2.2416841983795166
Validation loss: 2.071855070770428

Epoch: 5| Step: 7
Training loss: 1.8146355152130127
Validation loss: 2.0718214896417435

Epoch: 5| Step: 8
Training loss: 2.291245222091675
Validation loss: 2.083891257163017

Epoch: 5| Step: 9
Training loss: 1.9249732494354248
Validation loss: 2.079162169528264

Epoch: 5| Step: 10
Training loss: 1.7683093547821045
Validation loss: 2.064031477897398

Epoch: 198| Step: 0
Training loss: 1.6451181173324585
Validation loss: 2.0435989056864092

Epoch: 5| Step: 1
Training loss: 1.7242892980575562
Validation loss: 2.0290613405166136

Epoch: 5| Step: 2
Training loss: 1.9133117198944092
Validation loss: 2.029264343682156

Epoch: 5| Step: 3
Training loss: 2.3162682056427
Validation loss: 2.031755942170338

Epoch: 5| Step: 4
Training loss: 1.3318418264389038
Validation loss: 2.04560104749536

Epoch: 5| Step: 5
Training loss: 2.09945011138916
Validation loss: 2.030205821478239

Epoch: 5| Step: 6
Training loss: 2.705099105834961
Validation loss: 2.008828921984601

Epoch: 5| Step: 7
Training loss: 1.7077395915985107
Validation loss: 2.0067835866764026

Epoch: 5| Step: 8
Training loss: 2.101200580596924
Validation loss: 2.032923262606385

Epoch: 5| Step: 9
Training loss: 1.4904308319091797
Validation loss: 2.018789296509117

Epoch: 5| Step: 10
Training loss: 2.1248743534088135
Validation loss: 2.015156897165442

Epoch: 199| Step: 0
Training loss: 2.4041285514831543
Validation loss: 1.998832341163389

Epoch: 5| Step: 1
Training loss: 1.7293049097061157
Validation loss: 1.9981612543905936

Epoch: 5| Step: 2
Training loss: 1.7670055627822876
Validation loss: 1.9904357784537858

Epoch: 5| Step: 3
Training loss: 1.6452938318252563
Validation loss: 2.0009837868393108

Epoch: 5| Step: 4
Training loss: 2.184530019760132
Validation loss: 2.0069638298403834

Epoch: 5| Step: 5
Training loss: 2.637411594390869
Validation loss: 1.9949000779018606

Epoch: 5| Step: 6
Training loss: 1.7888572216033936
Validation loss: 2.0020555347524662

Epoch: 5| Step: 7
Training loss: 1.9737465381622314
Validation loss: 2.0018957391861947

Epoch: 5| Step: 8
Training loss: 1.5723223686218262
Validation loss: 2.0106430797166723

Epoch: 5| Step: 9
Training loss: 1.770809531211853
Validation loss: 2.0116213214012886

Epoch: 5| Step: 10
Training loss: 1.7934740781784058
Validation loss: 2.015414313603473

Epoch: 200| Step: 0
Training loss: 1.6160752773284912
Validation loss: 2.0256052991395355

Epoch: 5| Step: 1
Training loss: 2.2536654472351074
Validation loss: 2.016813767853604

Epoch: 5| Step: 2
Training loss: 2.102386951446533
Validation loss: 2.012549618239044

Epoch: 5| Step: 3
Training loss: 1.9298484325408936
Validation loss: 2.014458592220019

Epoch: 5| Step: 4
Training loss: 2.175959825515747
Validation loss: 2.0239291626919984

Epoch: 5| Step: 5
Training loss: 1.6598694324493408
Validation loss: 2.0189968373185847

Epoch: 5| Step: 6
Training loss: 1.5896230936050415
Validation loss: 2.010657628377279

Epoch: 5| Step: 7
Training loss: 1.5111887454986572
Validation loss: 2.0245589107595463

Epoch: 5| Step: 8
Training loss: 2.388460397720337
Validation loss: 2.0243329078920427

Epoch: 5| Step: 9
Training loss: 1.826542615890503
Validation loss: 2.035960684540451

Epoch: 5| Step: 10
Training loss: 2.0113131999969482
Validation loss: 2.032276843183784

Epoch: 201| Step: 0
Training loss: 2.223846912384033
Validation loss: 2.033773406859367

Epoch: 5| Step: 1
Training loss: 1.2723296880722046
Validation loss: 2.026602501510292

Epoch: 5| Step: 2
Training loss: 1.603593111038208
Validation loss: 2.0334302558693835

Epoch: 5| Step: 3
Training loss: 1.91543710231781
Validation loss: 2.026930924384825

Epoch: 5| Step: 4
Training loss: 2.0265440940856934
Validation loss: 2.0302708020774265

Epoch: 5| Step: 5
Training loss: 1.9746668338775635
Validation loss: 2.0288590538886284

Epoch: 5| Step: 6
Training loss: 2.2432711124420166
Validation loss: 2.012070204622002

Epoch: 5| Step: 7
Training loss: 1.7647966146469116
Validation loss: 2.0176577875691075

Epoch: 5| Step: 8
Training loss: 2.4990217685699463
Validation loss: 2.005443144870061

Epoch: 5| Step: 9
Training loss: 1.817070722579956
Validation loss: 2.006181804082727

Epoch: 5| Step: 10
Training loss: 1.7450592517852783
Validation loss: 2.020622396981844

Epoch: 202| Step: 0
Training loss: 2.695742607116699
Validation loss: 2.052936832110087

Epoch: 5| Step: 1
Training loss: 1.614772081375122
Validation loss: 2.075311588984664

Epoch: 5| Step: 2
Training loss: 2.1437294483184814
Validation loss: 2.076029340426127

Epoch: 5| Step: 3
Training loss: 2.076373338699341
Validation loss: 2.0526475368007535

Epoch: 5| Step: 4
Training loss: 1.880449891090393
Validation loss: 2.0432875540948685

Epoch: 5| Step: 5
Training loss: 1.8087536096572876
Validation loss: 2.060852635291315

Epoch: 5| Step: 6
Training loss: 1.6488031148910522
Validation loss: 2.0779985432983725

Epoch: 5| Step: 7
Training loss: 1.834193229675293
Validation loss: 2.0681088175824893

Epoch: 5| Step: 8
Training loss: 2.583528518676758
Validation loss: 2.0426415140910814

Epoch: 5| Step: 9
Training loss: 1.570671796798706
Validation loss: 2.0436973366686093

Epoch: 5| Step: 10
Training loss: 1.3678510189056396
Validation loss: 2.017398452246061

Epoch: 203| Step: 0
Training loss: 1.632560133934021
Validation loss: 2.0358193574413175

Epoch: 5| Step: 1
Training loss: 2.0856966972351074
Validation loss: 2.044017535383983

Epoch: 5| Step: 2
Training loss: 1.9802181720733643
Validation loss: 2.0398034562346754

Epoch: 5| Step: 3
Training loss: 2.0099904537200928
Validation loss: 2.0456319701287056

Epoch: 5| Step: 4
Training loss: 2.357278347015381
Validation loss: 2.0353306711360974

Epoch: 5| Step: 5
Training loss: 1.8630781173706055
Validation loss: 2.049242188853602

Epoch: 5| Step: 6
Training loss: 2.1183860301971436
Validation loss: 2.0251923812332975

Epoch: 5| Step: 7
Training loss: 1.8920509815216064
Validation loss: 2.02042959326057

Epoch: 5| Step: 8
Training loss: 1.7683302164077759
Validation loss: 2.031253973642985

Epoch: 5| Step: 9
Training loss: 2.3266899585723877
Validation loss: 2.0193110691603793

Epoch: 5| Step: 10
Training loss: 1.395980715751648
Validation loss: 2.0151320529240433

Epoch: 204| Step: 0
Training loss: 1.7354166507720947
Validation loss: 2.0139145492225565

Epoch: 5| Step: 1
Training loss: 1.926164984703064
Validation loss: 2.023384731302979

Epoch: 5| Step: 2
Training loss: 2.210036516189575
Validation loss: 2.0090204772128852

Epoch: 5| Step: 3
Training loss: 1.7209552526474
Validation loss: 2.0145614019004245

Epoch: 5| Step: 4
Training loss: 1.736511468887329
Validation loss: 2.021807950030091

Epoch: 5| Step: 5
Training loss: 1.8453956842422485
Validation loss: 2.0312015779556765

Epoch: 5| Step: 6
Training loss: 2.1581320762634277
Validation loss: 2.0310125222770115

Epoch: 5| Step: 7
Training loss: 1.6849676370620728
Validation loss: 2.021494557780604

Epoch: 5| Step: 8
Training loss: 1.836846113204956
Validation loss: 2.037132445202079

Epoch: 5| Step: 9
Training loss: 1.7700942754745483
Validation loss: 2.063718057447864

Epoch: 5| Step: 10
Training loss: 2.0918233394622803
Validation loss: 2.0773571973205893

Epoch: 205| Step: 0
Training loss: 1.5452827215194702
Validation loss: 2.074390712604728

Epoch: 5| Step: 1
Training loss: 2.2839531898498535
Validation loss: 2.053689577246225

Epoch: 5| Step: 2
Training loss: 2.060690402984619
Validation loss: 2.0475489708685104

Epoch: 5| Step: 3
Training loss: 2.1465964317321777
Validation loss: 2.0115429688525457

Epoch: 5| Step: 4
Training loss: 1.4505259990692139
Validation loss: 2.010798368402707

Epoch: 5| Step: 5
Training loss: 1.7233078479766846
Validation loss: 1.9922870512931579

Epoch: 5| Step: 6
Training loss: 2.419269323348999
Validation loss: 1.9872436087618592

Epoch: 5| Step: 7
Training loss: 2.3490798473358154
Validation loss: 1.9916948785064041

Epoch: 5| Step: 8
Training loss: 1.6412540674209595
Validation loss: 1.9883673037252119

Epoch: 5| Step: 9
Training loss: 1.9602922201156616
Validation loss: 1.9905885393901537

Epoch: 5| Step: 10
Training loss: 0.8639260530471802
Validation loss: 1.9898119382960822

Epoch: 206| Step: 0
Training loss: 1.8649826049804688
Validation loss: 1.995575451081799

Epoch: 5| Step: 1
Training loss: 1.771327257156372
Validation loss: 2.002102205830236

Epoch: 5| Step: 2
Training loss: 2.1133832931518555
Validation loss: 2.0111590521309965

Epoch: 5| Step: 3
Training loss: 1.532277226448059
Validation loss: 2.0160665768449024

Epoch: 5| Step: 4
Training loss: 1.989816665649414
Validation loss: 2.0287340328257573

Epoch: 5| Step: 5
Training loss: 1.3731390237808228
Validation loss: 2.0371829514862387

Epoch: 5| Step: 6
Training loss: 2.0769004821777344
Validation loss: 2.0414859094927387

Epoch: 5| Step: 7
Training loss: 1.8781369924545288
Validation loss: 2.0516839027404785

Epoch: 5| Step: 8
Training loss: 1.6331470012664795
Validation loss: 2.0364471109964515

Epoch: 5| Step: 9
Training loss: 2.0624098777770996
Validation loss: 2.046190002913116

Epoch: 5| Step: 10
Training loss: 2.1399788856506348
Validation loss: 2.0398092692898167

Epoch: 207| Step: 0
Training loss: 1.7190860509872437
Validation loss: 2.0322672884951354

Epoch: 5| Step: 1
Training loss: 1.962402582168579
Validation loss: 2.0274725908874185

Epoch: 5| Step: 2
Training loss: 1.4331647157669067
Validation loss: 2.018394693251579

Epoch: 5| Step: 3
Training loss: 2.347383975982666
Validation loss: 2.0219773143850346

Epoch: 5| Step: 4
Training loss: 1.535430669784546
Validation loss: 2.0315735263209187

Epoch: 5| Step: 5
Training loss: 1.3662208318710327
Validation loss: 2.0342808590140393

Epoch: 5| Step: 6
Training loss: 2.3747634887695312
Validation loss: 2.0230655259983514

Epoch: 5| Step: 7
Training loss: 2.076324939727783
Validation loss: 2.049164516951448

Epoch: 5| Step: 8
Training loss: 2.0381269454956055
Validation loss: 2.04505475618506

Epoch: 5| Step: 9
Training loss: 1.5264108180999756
Validation loss: 2.0472243165457122

Epoch: 5| Step: 10
Training loss: 1.9975634813308716
Validation loss: 2.059711821617619

Epoch: 208| Step: 0
Training loss: 1.677656888961792
Validation loss: 2.0403250212310464

Epoch: 5| Step: 1
Training loss: 1.6566581726074219
Validation loss: 2.038640163278067

Epoch: 5| Step: 2
Training loss: 2.281733751296997
Validation loss: 2.048218506638722

Epoch: 5| Step: 3
Training loss: 2.2575180530548096
Validation loss: 2.044058125506165

Epoch: 5| Step: 4
Training loss: 0.8947141766548157
Validation loss: 2.0630881427436747

Epoch: 5| Step: 5
Training loss: 1.7073863744735718
Validation loss: 2.061375685917434

Epoch: 5| Step: 6
Training loss: 1.0000288486480713
Validation loss: 2.0399168255508586

Epoch: 5| Step: 7
Training loss: 1.9910995960235596
Validation loss: 2.0465565932694303

Epoch: 5| Step: 8
Training loss: 2.166584014892578
Validation loss: 2.031905348582934

Epoch: 5| Step: 9
Training loss: 2.017578125
Validation loss: 2.034316532073482

Epoch: 5| Step: 10
Training loss: 2.7479662895202637
Validation loss: 2.0291189750035605

Epoch: 209| Step: 0
Training loss: 2.02644681930542
Validation loss: 2.0352346974034465

Epoch: 5| Step: 1
Training loss: 1.885046362876892
Validation loss: 2.0146855051799486

Epoch: 5| Step: 2
Training loss: 1.9355175495147705
Validation loss: 2.011454677069059

Epoch: 5| Step: 3
Training loss: 2.588243007659912
Validation loss: 2.0236509923012025

Epoch: 5| Step: 4
Training loss: 1.8545379638671875
Validation loss: 2.0165826735957975

Epoch: 5| Step: 5
Training loss: 1.3858363628387451
Validation loss: 1.9981196747031262

Epoch: 5| Step: 6
Training loss: 1.881504774093628
Validation loss: 2.0100230888653825

Epoch: 5| Step: 7
Training loss: 1.9460538625717163
Validation loss: 2.007689328603847

Epoch: 5| Step: 8
Training loss: 2.1124258041381836
Validation loss: 2.00031949627784

Epoch: 5| Step: 9
Training loss: 1.3122118711471558
Validation loss: 1.9991168181101482

Epoch: 5| Step: 10
Training loss: 1.4949101209640503
Validation loss: 2.021498965960677

Epoch: 210| Step: 0
Training loss: 2.131962299346924
Validation loss: 2.028150969936002

Epoch: 5| Step: 1
Training loss: 1.443765640258789
Validation loss: 2.0356121229869064

Epoch: 5| Step: 2
Training loss: 1.598629117012024
Validation loss: 2.0434891408489597

Epoch: 5| Step: 3
Training loss: 1.8968420028686523
Validation loss: 2.041908029587038

Epoch: 5| Step: 4
Training loss: 2.088989734649658
Validation loss: 2.0190539667683263

Epoch: 5| Step: 5
Training loss: 1.4568092823028564
Validation loss: 2.01230965634828

Epoch: 5| Step: 6
Training loss: 2.674797534942627
Validation loss: 2.0244367558469056

Epoch: 5| Step: 7
Training loss: 1.9018135070800781
Validation loss: 2.039028065178984

Epoch: 5| Step: 8
Training loss: 1.9041258096694946
Validation loss: 2.0159245716628207

Epoch: 5| Step: 9
Training loss: 1.5648283958435059
Validation loss: 2.018409111166513

Epoch: 5| Step: 10
Training loss: 1.7158780097961426
Validation loss: 2.020600857273225

Epoch: 211| Step: 0
Training loss: 1.8162214756011963
Validation loss: 2.0354422471856557

Epoch: 5| Step: 1
Training loss: 1.399237871170044
Validation loss: 2.038365799893615

Epoch: 5| Step: 2
Training loss: 1.99123215675354
Validation loss: 2.0385186518392255

Epoch: 5| Step: 3
Training loss: 1.4165220260620117
Validation loss: 2.0448490137694986

Epoch: 5| Step: 4
Training loss: 2.3902535438537598
Validation loss: 2.0522057548646004

Epoch: 5| Step: 5
Training loss: 2.0371017456054688
Validation loss: 2.0407746479075444

Epoch: 5| Step: 6
Training loss: 1.7525733709335327
Validation loss: 2.0319923188096736

Epoch: 5| Step: 7
Training loss: 2.1639792919158936
Validation loss: 2.0304388769211306

Epoch: 5| Step: 8
Training loss: 2.249483823776245
Validation loss: 2.0276477362519953

Epoch: 5| Step: 9
Training loss: 1.5677927732467651
Validation loss: 2.0026193946920414

Epoch: 5| Step: 10
Training loss: 1.2658607959747314
Validation loss: 2.015723982164937

Epoch: 212| Step: 0
Training loss: 1.8817520141601562
Validation loss: 2.018117730335523

Epoch: 5| Step: 1
Training loss: 1.8987982273101807
Validation loss: 2.009628366398555

Epoch: 5| Step: 2
Training loss: 2.6646735668182373
Validation loss: 2.0179760943176928

Epoch: 5| Step: 3
Training loss: 1.4597089290618896
Validation loss: 2.011924978225462

Epoch: 5| Step: 4
Training loss: 1.3584219217300415
Validation loss: 2.024176155367205

Epoch: 5| Step: 5
Training loss: 2.415494441986084
Validation loss: 2.0201172136491343

Epoch: 5| Step: 6
Training loss: 1.6197595596313477
Validation loss: 2.0459344669054915

Epoch: 5| Step: 7
Training loss: 1.38688063621521
Validation loss: 2.0321264395149807

Epoch: 5| Step: 8
Training loss: 1.9417228698730469
Validation loss: 2.0464871032263643

Epoch: 5| Step: 9
Training loss: 1.6162296533584595
Validation loss: 2.064163009325663

Epoch: 5| Step: 10
Training loss: 1.7857036590576172
Validation loss: 2.070467923277168

Epoch: 213| Step: 0
Training loss: 1.8848994970321655
Validation loss: 2.0682964812042894

Epoch: 5| Step: 1
Training loss: 1.2497667074203491
Validation loss: 2.0813583379150717

Epoch: 5| Step: 2
Training loss: 2.2440109252929688
Validation loss: 2.074855678824968

Epoch: 5| Step: 3
Training loss: 1.1726571321487427
Validation loss: 2.0553183504330215

Epoch: 5| Step: 4
Training loss: 1.302189826965332
Validation loss: 2.038939760577294

Epoch: 5| Step: 5
Training loss: 2.497056484222412
Validation loss: 2.032733004580262

Epoch: 5| Step: 6
Training loss: 1.537170648574829
Validation loss: 2.025945463488179

Epoch: 5| Step: 7
Training loss: 1.677882194519043
Validation loss: 2.033380295640679

Epoch: 5| Step: 8
Training loss: 2.6247634887695312
Validation loss: 2.023826563230125

Epoch: 5| Step: 9
Training loss: 2.200470447540283
Validation loss: 2.0296942790349326

Epoch: 5| Step: 10
Training loss: 1.5168567895889282
Validation loss: 2.027762492497762

Epoch: 214| Step: 0
Training loss: 1.724704384803772
Validation loss: 2.0185142652962798

Epoch: 5| Step: 1
Training loss: 1.8160406351089478
Validation loss: 2.0189094825457503

Epoch: 5| Step: 2
Training loss: 1.714440107345581
Validation loss: 2.0333498293353665

Epoch: 5| Step: 3
Training loss: 2.2961246967315674
Validation loss: 2.0208940711072696

Epoch: 5| Step: 4
Training loss: 2.1316394805908203
Validation loss: 1.9999976709324827

Epoch: 5| Step: 5
Training loss: 1.0896612405776978
Validation loss: 2.009086396104546

Epoch: 5| Step: 6
Training loss: 2.0925285816192627
Validation loss: 2.0268426172194944

Epoch: 5| Step: 7
Training loss: 1.79630446434021
Validation loss: 2.033143645973616

Epoch: 5| Step: 8
Training loss: 1.6138362884521484
Validation loss: 2.0312835016558246

Epoch: 5| Step: 9
Training loss: 1.8100147247314453
Validation loss: 2.025843704900434

Epoch: 5| Step: 10
Training loss: 1.9311707019805908
Validation loss: 2.007798279485395

Epoch: 215| Step: 0
Training loss: 1.8285881280899048
Validation loss: 2.0238391340419812

Epoch: 5| Step: 1
Training loss: 1.9580652713775635
Validation loss: 2.0136967000140937

Epoch: 5| Step: 2
Training loss: 1.7982515096664429
Validation loss: 2.0218073270654164

Epoch: 5| Step: 3
Training loss: 1.6491464376449585
Validation loss: 2.020105265801953

Epoch: 5| Step: 4
Training loss: 1.2635738849639893
Validation loss: 2.021624119051041

Epoch: 5| Step: 5
Training loss: 2.0946969985961914
Validation loss: 2.038398109456544

Epoch: 5| Step: 6
Training loss: 1.589134931564331
Validation loss: 2.038265864054362

Epoch: 5| Step: 7
Training loss: 2.1637775897979736
Validation loss: 2.040009965178787

Epoch: 5| Step: 8
Training loss: 1.781897783279419
Validation loss: 2.035788211771237

Epoch: 5| Step: 9
Training loss: 1.5915943384170532
Validation loss: 2.038689322369073

Epoch: 5| Step: 10
Training loss: 2.047764778137207
Validation loss: 2.046418680939623

Epoch: 216| Step: 0
Training loss: 1.600298523902893
Validation loss: 2.0385401607841573

Epoch: 5| Step: 1
Training loss: 2.606083631515503
Validation loss: 2.032666137141566

Epoch: 5| Step: 2
Training loss: 2.298712730407715
Validation loss: 2.0529176445417505

Epoch: 5| Step: 3
Training loss: 1.8294804096221924
Validation loss: 2.0558915035699004

Epoch: 5| Step: 4
Training loss: 1.4642250537872314
Validation loss: 2.0165575217175227

Epoch: 5| Step: 5
Training loss: 1.9688594341278076
Validation loss: 2.024280119967717

Epoch: 5| Step: 6
Training loss: 1.3927456140518188
Validation loss: 2.0403738585851525

Epoch: 5| Step: 7
Training loss: 1.771388292312622
Validation loss: 2.03131575481866

Epoch: 5| Step: 8
Training loss: 1.6105730533599854
Validation loss: 2.0053200414103847

Epoch: 5| Step: 9
Training loss: 1.153782606124878
Validation loss: 2.018531746761773

Epoch: 5| Step: 10
Training loss: 2.078561305999756
Validation loss: 2.022163370604156

Epoch: 217| Step: 0
Training loss: 1.3444033861160278
Validation loss: 2.028811331718199

Epoch: 5| Step: 1
Training loss: 2.2007012367248535
Validation loss: 2.025705031169358

Epoch: 5| Step: 2
Training loss: 1.6089744567871094
Validation loss: 2.0180007693588093

Epoch: 5| Step: 3
Training loss: 1.4192191362380981
Validation loss: 2.020964550715621

Epoch: 5| Step: 4
Training loss: 1.6545851230621338
Validation loss: 2.0190661414977042

Epoch: 5| Step: 5
Training loss: 2.0652832984924316
Validation loss: 2.0263735966015886

Epoch: 5| Step: 6
Training loss: 1.4781911373138428
Validation loss: 2.0461861087429907

Epoch: 5| Step: 7
Training loss: 2.105638027191162
Validation loss: 2.049079220782044

Epoch: 5| Step: 8
Training loss: 2.4787275791168213
Validation loss: 2.040677699991452

Epoch: 5| Step: 9
Training loss: 1.794631004333496
Validation loss: 2.044925069296232

Epoch: 5| Step: 10
Training loss: 1.9195547103881836
Validation loss: 2.0336788982473393

Epoch: 218| Step: 0
Training loss: 1.7535425424575806
Validation loss: 2.0562354864612704

Epoch: 5| Step: 1
Training loss: 1.7521998882293701
Validation loss: 2.0357325000147664

Epoch: 5| Step: 2
Training loss: 1.4864256381988525
Validation loss: 2.070588336195997

Epoch: 5| Step: 3
Training loss: 2.047330379486084
Validation loss: 2.0544298387342885

Epoch: 5| Step: 4
Training loss: 1.4376554489135742
Validation loss: 2.0431609743384906

Epoch: 5| Step: 5
Training loss: 2.1395764350891113
Validation loss: 2.0325438232832056

Epoch: 5| Step: 6
Training loss: 2.0439999103546143
Validation loss: 2.013113292314673

Epoch: 5| Step: 7
Training loss: 1.2712737321853638
Validation loss: 2.0111468517652122

Epoch: 5| Step: 8
Training loss: 1.3507550954818726
Validation loss: 1.9960056325440765

Epoch: 5| Step: 9
Training loss: 1.7783896923065186
Validation loss: 2.0049157245184785

Epoch: 5| Step: 10
Training loss: 2.488718032836914
Validation loss: 2.0078104977966635

Epoch: 219| Step: 0
Training loss: 1.3429105281829834
Validation loss: 2.0116956900524836

Epoch: 5| Step: 1
Training loss: 1.4485079050064087
Validation loss: 2.0116412767799954

Epoch: 5| Step: 2
Training loss: 1.866994857788086
Validation loss: 2.0048505952281337

Epoch: 5| Step: 3
Training loss: 1.401785135269165
Validation loss: 1.9966932112170803

Epoch: 5| Step: 4
Training loss: 1.4963183403015137
Validation loss: 2.0192447375225764

Epoch: 5| Step: 5
Training loss: 2.053011178970337
Validation loss: 2.0476495758179696

Epoch: 5| Step: 6
Training loss: 1.8429161310195923
Validation loss: 2.061215995460428

Epoch: 5| Step: 7
Training loss: 1.3132143020629883
Validation loss: 2.094822989997043

Epoch: 5| Step: 8
Training loss: 2.357661008834839
Validation loss: 2.0987351184250205

Epoch: 5| Step: 9
Training loss: 2.063416004180908
Validation loss: 2.0763730836170975

Epoch: 5| Step: 10
Training loss: 2.5461249351501465
Validation loss: 2.0432670218970186

Epoch: 220| Step: 0
Training loss: 1.4308375120162964
Validation loss: 2.0009289018569456

Epoch: 5| Step: 1
Training loss: 1.4835240840911865
Validation loss: 1.9863883192821215

Epoch: 5| Step: 2
Training loss: 1.5067451000213623
Validation loss: 1.996297150529841

Epoch: 5| Step: 3
Training loss: 1.6994733810424805
Validation loss: 1.9876557652668287

Epoch: 5| Step: 4
Training loss: 1.6228058338165283
Validation loss: 1.985845737559821

Epoch: 5| Step: 5
Training loss: 1.7773077487945557
Validation loss: 1.982004423295298

Epoch: 5| Step: 6
Training loss: 1.8918708562850952
Validation loss: 1.992994693017775

Epoch: 5| Step: 7
Training loss: 1.912874460220337
Validation loss: 2.0005265858865555

Epoch: 5| Step: 8
Training loss: 2.0423970222473145
Validation loss: 1.9924359398503457

Epoch: 5| Step: 9
Training loss: 2.0682599544525146
Validation loss: 1.9978658076255553

Epoch: 5| Step: 10
Training loss: 1.9398397207260132
Validation loss: 2.0066438823617916

Epoch: 221| Step: 0
Training loss: 1.5388286113739014
Validation loss: 2.022234350122431

Epoch: 5| Step: 1
Training loss: 1.6120933294296265
Validation loss: 2.0485101720338226

Epoch: 5| Step: 2
Training loss: 2.034113645553589
Validation loss: 2.0576828801503746

Epoch: 5| Step: 3
Training loss: 1.868943452835083
Validation loss: 2.0878393419327272

Epoch: 5| Step: 4
Training loss: 1.4654582738876343
Validation loss: 2.0823179726959555

Epoch: 5| Step: 5
Training loss: 1.734880805015564
Validation loss: 2.072035595934878

Epoch: 5| Step: 6
Training loss: 1.2554233074188232
Validation loss: 2.0682526250039377

Epoch: 5| Step: 7
Training loss: 1.7461917400360107
Validation loss: 2.041643306773196

Epoch: 5| Step: 8
Training loss: 1.7111419439315796
Validation loss: 2.03132269459386

Epoch: 5| Step: 9
Training loss: 2.0187225341796875
Validation loss: 2.006972012981292

Epoch: 5| Step: 10
Training loss: 2.218169927597046
Validation loss: 1.9919634480630197

Epoch: 222| Step: 0
Training loss: 1.6029068231582642
Validation loss: 1.9950695832570393

Epoch: 5| Step: 1
Training loss: 2.2359347343444824
Validation loss: 1.980154125921188

Epoch: 5| Step: 2
Training loss: 1.6767475605010986
Validation loss: 2.014955037383623

Epoch: 5| Step: 3
Training loss: 1.5799808502197266
Validation loss: 1.9883641068653395

Epoch: 5| Step: 4
Training loss: 2.3819804191589355
Validation loss: 1.9742527956603675

Epoch: 5| Step: 5
Training loss: 1.727764368057251
Validation loss: 1.9508926894075127

Epoch: 5| Step: 6
Training loss: 1.377169132232666
Validation loss: 1.9769237092746201

Epoch: 5| Step: 7
Training loss: 1.3322278261184692
Validation loss: 1.9683095127023675

Epoch: 5| Step: 8
Training loss: 1.6044623851776123
Validation loss: 1.9577408426551408

Epoch: 5| Step: 9
Training loss: 1.7724494934082031
Validation loss: 1.9731377247841126

Epoch: 5| Step: 10
Training loss: 1.9486193656921387
Validation loss: 1.9901814922209708

Epoch: 223| Step: 0
Training loss: 1.8293977975845337
Validation loss: 2.014346217596403

Epoch: 5| Step: 1
Training loss: 1.8875494003295898
Validation loss: 2.0226896578265774

Epoch: 5| Step: 2
Training loss: 1.5074621438980103
Validation loss: 2.029331414930282

Epoch: 5| Step: 3
Training loss: 1.1689258813858032
Validation loss: 2.0317033362644974

Epoch: 5| Step: 4
Training loss: 2.4583446979522705
Validation loss: 2.041145775907783

Epoch: 5| Step: 5
Training loss: 1.1699144840240479
Validation loss: 2.044589578464467

Epoch: 5| Step: 6
Training loss: 1.9144487380981445
Validation loss: 2.0338678206166914

Epoch: 5| Step: 7
Training loss: 1.536516785621643
Validation loss: 2.026838933267901

Epoch: 5| Step: 8
Training loss: 1.631018042564392
Validation loss: 2.0175223196706464

Epoch: 5| Step: 9
Training loss: 1.863257646560669
Validation loss: 2.041290456248868

Epoch: 5| Step: 10
Training loss: 1.9953768253326416
Validation loss: 2.0261452441574423

Epoch: 224| Step: 0
Training loss: 1.5935451984405518
Validation loss: 2.0191239746668006

Epoch: 5| Step: 1
Training loss: 1.8629233837127686
Validation loss: 2.0383921041283557

Epoch: 5| Step: 2
Training loss: 1.4735974073410034
Validation loss: 2.049427442653205

Epoch: 5| Step: 3
Training loss: 2.0661208629608154
Validation loss: 2.049216813938592

Epoch: 5| Step: 4
Training loss: 2.0469906330108643
Validation loss: 2.0581925287041614

Epoch: 5| Step: 5
Training loss: 1.4932057857513428
Validation loss: 2.049121428561467

Epoch: 5| Step: 6
Training loss: 1.5065639019012451
Validation loss: 2.0216614430950535

Epoch: 5| Step: 7
Training loss: 2.0978002548217773
Validation loss: 2.0107738676891533

Epoch: 5| Step: 8
Training loss: 1.2368649244308472
Validation loss: 1.9804304876635153

Epoch: 5| Step: 9
Training loss: 1.716992974281311
Validation loss: 1.9954977702069026

Epoch: 5| Step: 10
Training loss: 1.718249797821045
Validation loss: 1.9833784167484572

Epoch: 225| Step: 0
Training loss: 2.1662278175354004
Validation loss: 1.9813823469223515

Epoch: 5| Step: 1
Training loss: 1.5305136442184448
Validation loss: 1.9917133008280108

Epoch: 5| Step: 2
Training loss: 1.8759419918060303
Validation loss: 1.9898040525374874

Epoch: 5| Step: 3
Training loss: 1.5099072456359863
Validation loss: 1.9756911518753215

Epoch: 5| Step: 4
Training loss: 1.4216594696044922
Validation loss: 1.9783260899205362

Epoch: 5| Step: 5
Training loss: 1.1603422164916992
Validation loss: 1.9671319402674192

Epoch: 5| Step: 6
Training loss: 1.9259494543075562
Validation loss: 1.9770773726124917

Epoch: 5| Step: 7
Training loss: 2.3090338706970215
Validation loss: 1.9938705223862843

Epoch: 5| Step: 8
Training loss: 1.888477087020874
Validation loss: 1.9957171024814728

Epoch: 5| Step: 9
Training loss: 1.6694494485855103
Validation loss: 1.996845147942984

Epoch: 5| Step: 10
Training loss: 1.3038685321807861
Validation loss: 2.0501425163720244

Epoch: 226| Step: 0
Training loss: 1.5875217914581299
Validation loss: 2.058608579379256

Epoch: 5| Step: 1
Training loss: 2.317415237426758
Validation loss: 2.0648104221590105

Epoch: 5| Step: 2
Training loss: 2.5591318607330322
Validation loss: 2.0845107916862733

Epoch: 5| Step: 3
Training loss: 1.8572620153427124
Validation loss: 2.0764345417740526

Epoch: 5| Step: 4
Training loss: 1.797307014465332
Validation loss: 2.049975117047628

Epoch: 5| Step: 5
Training loss: 1.5144635438919067
Validation loss: 2.025992972876436

Epoch: 5| Step: 6
Training loss: 1.5029884576797485
Validation loss: 2.0116889810049408

Epoch: 5| Step: 7
Training loss: 0.7572329640388489
Validation loss: 1.9998355578350764

Epoch: 5| Step: 8
Training loss: 2.0511834621429443
Validation loss: 2.0229575903184953

Epoch: 5| Step: 9
Training loss: 1.3469364643096924
Validation loss: 2.0054847989031064

Epoch: 5| Step: 10
Training loss: 1.626922845840454
Validation loss: 2.000030086886498

Epoch: 227| Step: 0
Training loss: 1.642307996749878
Validation loss: 1.9807075223615092

Epoch: 5| Step: 1
Training loss: 1.8274829387664795
Validation loss: 1.9946852627620901

Epoch: 5| Step: 2
Training loss: 1.7822548151016235
Validation loss: 1.987277373190849

Epoch: 5| Step: 3
Training loss: 1.7108821868896484
Validation loss: 1.9964651600007088

Epoch: 5| Step: 4
Training loss: 1.8453044891357422
Validation loss: 2.0014536201312976

Epoch: 5| Step: 5
Training loss: 1.2383112907409668
Validation loss: 2.0034697568544777

Epoch: 5| Step: 6
Training loss: 1.0184032917022705
Validation loss: 1.9898609166504235

Epoch: 5| Step: 7
Training loss: 2.154421806335449
Validation loss: 1.9768993803249892

Epoch: 5| Step: 8
Training loss: 1.404565453529358
Validation loss: 1.9860376196522866

Epoch: 5| Step: 9
Training loss: 2.1107935905456543
Validation loss: 1.9899566135098856

Epoch: 5| Step: 10
Training loss: 1.9346753358840942
Validation loss: 2.0102611869894047

Epoch: 228| Step: 0
Training loss: 1.7470096349716187
Validation loss: 2.0235970199749036

Epoch: 5| Step: 1
Training loss: 2.4620940685272217
Validation loss: 2.0110828953404583

Epoch: 5| Step: 2
Training loss: 1.7909225225448608
Validation loss: 2.009220459127939

Epoch: 5| Step: 3
Training loss: 1.610084891319275
Validation loss: 2.004465300549743

Epoch: 5| Step: 4
Training loss: 1.7795798778533936
Validation loss: 1.9943554529579737

Epoch: 5| Step: 5
Training loss: 1.8281257152557373
Validation loss: 2.011641971526607

Epoch: 5| Step: 6
Training loss: 1.544480323791504
Validation loss: 2.006387215788646

Epoch: 5| Step: 7
Training loss: 1.445264458656311
Validation loss: 1.9994880717287782

Epoch: 5| Step: 8
Training loss: 1.5790873765945435
Validation loss: 1.999408955215126

Epoch: 5| Step: 9
Training loss: 1.8481166362762451
Validation loss: 1.987396454298368

Epoch: 5| Step: 10
Training loss: 1.1823557615280151
Validation loss: 1.9946319954369658

Epoch: 229| Step: 0
Training loss: 1.9440500736236572
Validation loss: 1.9875491998528922

Epoch: 5| Step: 1
Training loss: 1.4087082147598267
Validation loss: 1.9883898996537732

Epoch: 5| Step: 2
Training loss: 1.1749465465545654
Validation loss: 1.992678056481064

Epoch: 5| Step: 3
Training loss: 2.0553908348083496
Validation loss: 1.9978394316088768

Epoch: 5| Step: 4
Training loss: 1.7507457733154297
Validation loss: 2.0078381005153862

Epoch: 5| Step: 5
Training loss: 1.8793113231658936
Validation loss: 2.0257877201162358

Epoch: 5| Step: 6
Training loss: 1.7340545654296875
Validation loss: 2.008677195477229

Epoch: 5| Step: 7
Training loss: 1.7216771841049194
Validation loss: 2.0247225325594664

Epoch: 5| Step: 8
Training loss: 1.7553329467773438
Validation loss: 1.9934679333881666

Epoch: 5| Step: 9
Training loss: 1.567851185798645
Validation loss: 2.0051887766007455

Epoch: 5| Step: 10
Training loss: 1.6059454679489136
Validation loss: 2.0131608516939226

Epoch: 230| Step: 0
Training loss: 1.6228218078613281
Validation loss: 1.9920580822934386

Epoch: 5| Step: 1
Training loss: 1.849278211593628
Validation loss: 2.0049732987598707

Epoch: 5| Step: 2
Training loss: 2.1629252433776855
Validation loss: 2.0178580168754823

Epoch: 5| Step: 3
Training loss: 1.8128726482391357
Validation loss: 1.9976457101042553

Epoch: 5| Step: 4
Training loss: 1.7711178064346313
Validation loss: 1.986958331959222

Epoch: 5| Step: 5
Training loss: 1.9250274896621704
Validation loss: 1.9687554195363035

Epoch: 5| Step: 6
Training loss: 1.3237383365631104
Validation loss: 1.9730732543494112

Epoch: 5| Step: 7
Training loss: 1.8714510202407837
Validation loss: 1.9751013658379997

Epoch: 5| Step: 8
Training loss: 0.91553795337677
Validation loss: 1.9687325787800614

Epoch: 5| Step: 9
Training loss: 1.5755960941314697
Validation loss: 1.9666576539316485

Epoch: 5| Step: 10
Training loss: 1.438021183013916
Validation loss: 1.9740754276193597

Epoch: 231| Step: 0
Training loss: 1.1936219930648804
Validation loss: 1.9763046003157092

Epoch: 5| Step: 1
Training loss: 1.7011921405792236
Validation loss: 1.993684950695243

Epoch: 5| Step: 2
Training loss: 1.975915551185608
Validation loss: 1.9957649964158253

Epoch: 5| Step: 3
Training loss: 1.6552127599716187
Validation loss: 1.997984734914636

Epoch: 5| Step: 4
Training loss: 1.6515207290649414
Validation loss: 2.012958154883436

Epoch: 5| Step: 5
Training loss: 2.0981857776641846
Validation loss: 2.0156550074136383

Epoch: 5| Step: 6
Training loss: 1.226493239402771
Validation loss: 2.045844001154746

Epoch: 5| Step: 7
Training loss: 1.4464448690414429
Validation loss: 2.0163080000108287

Epoch: 5| Step: 8
Training loss: 1.5372823476791382
Validation loss: 2.024139000523475

Epoch: 5| Step: 9
Training loss: 1.920850157737732
Validation loss: 2.018312651623962

Epoch: 5| Step: 10
Training loss: 1.7497491836547852
Validation loss: 1.9951485356976908

Epoch: 232| Step: 0
Training loss: 2.1771762371063232
Validation loss: 1.9900219414823799

Epoch: 5| Step: 1
Training loss: 2.1645522117614746
Validation loss: 1.999977816817581

Epoch: 5| Step: 2
Training loss: 1.6252968311309814
Validation loss: 1.9889537237023796

Epoch: 5| Step: 3
Training loss: 1.4158344268798828
Validation loss: 2.0055931768109723

Epoch: 5| Step: 4
Training loss: 1.6314570903778076
Validation loss: 2.005553683926982

Epoch: 5| Step: 5
Training loss: 1.5685253143310547
Validation loss: 2.0141578259006625

Epoch: 5| Step: 6
Training loss: 0.9203093647956848
Validation loss: 2.0045221492808354

Epoch: 5| Step: 7
Training loss: 1.6490446329116821
Validation loss: 1.9983576266996321

Epoch: 5| Step: 8
Training loss: 1.5897865295410156
Validation loss: 2.0146603635562363

Epoch: 5| Step: 9
Training loss: 1.7940242290496826
Validation loss: 2.027423679187734

Epoch: 5| Step: 10
Training loss: 1.6475729942321777
Validation loss: 2.0300279560909478

Epoch: 233| Step: 0
Training loss: 1.4346719980239868
Validation loss: 2.0201564501690608

Epoch: 5| Step: 1
Training loss: 1.3657289743423462
Validation loss: 2.0117915509849467

Epoch: 5| Step: 2
Training loss: 1.6649364233016968
Validation loss: 2.0041476039476294

Epoch: 5| Step: 3
Training loss: 1.6490743160247803
Validation loss: 1.9895549717769827

Epoch: 5| Step: 4
Training loss: 2.0570149421691895
Validation loss: 1.997301955376902

Epoch: 5| Step: 5
Training loss: 1.1151478290557861
Validation loss: 1.9873448520578363

Epoch: 5| Step: 6
Training loss: 1.3099803924560547
Validation loss: 1.972498675828339

Epoch: 5| Step: 7
Training loss: 2.053110122680664
Validation loss: 1.9730792430139357

Epoch: 5| Step: 8
Training loss: 1.7685587406158447
Validation loss: 1.9833433397354618

Epoch: 5| Step: 9
Training loss: 1.8271023035049438
Validation loss: 1.9627358131511237

Epoch: 5| Step: 10
Training loss: 1.6154229640960693
Validation loss: 1.9580565344902776

Epoch: 234| Step: 0
Training loss: 1.8414599895477295
Validation loss: 1.9698049945216025

Epoch: 5| Step: 1
Training loss: 1.5032126903533936
Validation loss: 1.9639552639376732

Epoch: 5| Step: 2
Training loss: 1.8571217060089111
Validation loss: 1.960425628128872

Epoch: 5| Step: 3
Training loss: 1.733873724937439
Validation loss: 1.9669153280155633

Epoch: 5| Step: 4
Training loss: 1.231414556503296
Validation loss: 1.9607444655510686

Epoch: 5| Step: 5
Training loss: 2.01613187789917
Validation loss: 1.994740250290081

Epoch: 5| Step: 6
Training loss: 2.1552860736846924
Validation loss: 1.9838200794753207

Epoch: 5| Step: 7
Training loss: 1.8130509853363037
Validation loss: 1.9876759308640675

Epoch: 5| Step: 8
Training loss: 1.0133846998214722
Validation loss: 1.996361965774208

Epoch: 5| Step: 9
Training loss: 1.2479102611541748
Validation loss: 2.011593544355003

Epoch: 5| Step: 10
Training loss: 1.362053394317627
Validation loss: 2.00477643551365

Epoch: 235| Step: 0
Training loss: 1.6204278469085693
Validation loss: 2.0161347081584315

Epoch: 5| Step: 1
Training loss: 1.3648481369018555
Validation loss: 2.021497332921592

Epoch: 5| Step: 2
Training loss: 0.896955132484436
Validation loss: 2.0261413961328487

Epoch: 5| Step: 3
Training loss: 1.1593124866485596
Validation loss: 2.0246062945294123

Epoch: 5| Step: 4
Training loss: 1.9123090505599976
Validation loss: 2.00811335861042

Epoch: 5| Step: 5
Training loss: 1.8370637893676758
Validation loss: 2.020122544739836

Epoch: 5| Step: 6
Training loss: 2.0270791053771973
Validation loss: 2.016983696209487

Epoch: 5| Step: 7
Training loss: 1.365290641784668
Validation loss: 2.00406991153635

Epoch: 5| Step: 8
Training loss: 2.1723453998565674
Validation loss: 1.9937237975417927

Epoch: 5| Step: 9
Training loss: 1.6508705615997314
Validation loss: 2.0102230874441003

Epoch: 5| Step: 10
Training loss: 1.7306170463562012
Validation loss: 1.979349164552586

Epoch: 236| Step: 0
Training loss: 1.5798218250274658
Validation loss: 1.985034784963054

Epoch: 5| Step: 1
Training loss: 1.944514513015747
Validation loss: 1.9716392691417406

Epoch: 5| Step: 2
Training loss: 1.4074875116348267
Validation loss: 1.9837624385792723

Epoch: 5| Step: 3
Training loss: 1.4889647960662842
Validation loss: 1.9557371088253555

Epoch: 5| Step: 4
Training loss: 2.0240724086761475
Validation loss: 1.9648086947779502

Epoch: 5| Step: 5
Training loss: 1.7391895055770874
Validation loss: 1.955632596887568

Epoch: 5| Step: 6
Training loss: 1.7825567722320557
Validation loss: 1.9530450836304696

Epoch: 5| Step: 7
Training loss: 1.6261672973632812
Validation loss: 1.9551638454519293

Epoch: 5| Step: 8
Training loss: 1.1218788623809814
Validation loss: 1.934489805211303

Epoch: 5| Step: 9
Training loss: 1.5052413940429688
Validation loss: 1.9501756288672005

Epoch: 5| Step: 10
Training loss: 1.519970178604126
Validation loss: 1.9676198497895272

Epoch: 237| Step: 0
Training loss: 2.2131295204162598
Validation loss: 1.9916027028073546

Epoch: 5| Step: 1
Training loss: 1.5949628353118896
Validation loss: 2.0057015931734474

Epoch: 5| Step: 2
Training loss: 1.2774995565414429
Validation loss: 1.9893041285135413

Epoch: 5| Step: 3
Training loss: 1.5359764099121094
Validation loss: 1.9906241175948933

Epoch: 5| Step: 4
Training loss: 2.057377815246582
Validation loss: 2.0133190219120314

Epoch: 5| Step: 5
Training loss: 1.329798936843872
Validation loss: 2.0150608157598846

Epoch: 5| Step: 6
Training loss: 0.9251939058303833
Validation loss: 2.0215825534635976

Epoch: 5| Step: 7
Training loss: 1.3440873622894287
Validation loss: 2.0043692050441617

Epoch: 5| Step: 8
Training loss: 2.093538999557495
Validation loss: 1.9961800395801503

Epoch: 5| Step: 9
Training loss: 1.486069679260254
Validation loss: 2.0006750399066555

Epoch: 5| Step: 10
Training loss: 1.891797423362732
Validation loss: 2.001431821494974

Epoch: 238| Step: 0
Training loss: 2.0445046424865723
Validation loss: 1.987137884222051

Epoch: 5| Step: 1
Training loss: 1.1582797765731812
Validation loss: 2.0022556474131923

Epoch: 5| Step: 2
Training loss: 1.182035207748413
Validation loss: 2.00017455316359

Epoch: 5| Step: 3
Training loss: 1.9872016906738281
Validation loss: 1.99486082343645

Epoch: 5| Step: 4
Training loss: 1.4921108484268188
Validation loss: 1.9914381286149383

Epoch: 5| Step: 5
Training loss: 1.6793553829193115
Validation loss: 1.9818449199840587

Epoch: 5| Step: 6
Training loss: 2.055680274963379
Validation loss: 1.9831623543975174

Epoch: 5| Step: 7
Training loss: 1.8222644329071045
Validation loss: 1.976378043492635

Epoch: 5| Step: 8
Training loss: 1.5143094062805176
Validation loss: 1.9819874673761346

Epoch: 5| Step: 9
Training loss: 0.9490151405334473
Validation loss: 1.9723045595230595

Epoch: 5| Step: 10
Training loss: 1.2326414585113525
Validation loss: 1.9541055207611413

Epoch: 239| Step: 0
Training loss: 1.1621761322021484
Validation loss: 1.9793534881325179

Epoch: 5| Step: 1
Training loss: 1.3931071758270264
Validation loss: 1.9855292945779779

Epoch: 5| Step: 2
Training loss: 2.0286357402801514
Validation loss: 1.9852347373962402

Epoch: 5| Step: 3
Training loss: 1.221273422241211
Validation loss: 1.9731913048733947

Epoch: 5| Step: 4
Training loss: 1.362579345703125
Validation loss: 1.9634082932626047

Epoch: 5| Step: 5
Training loss: 1.8685258626937866
Validation loss: 1.9540257005281345

Epoch: 5| Step: 6
Training loss: 1.7348711490631104
Validation loss: 1.9577169790062854

Epoch: 5| Step: 7
Training loss: 1.739452600479126
Validation loss: 1.9711872377703268

Epoch: 5| Step: 8
Training loss: 2.088557720184326
Validation loss: 1.9778193671216246

Epoch: 5| Step: 9
Training loss: 0.9403796195983887
Validation loss: 1.9927821287544825

Epoch: 5| Step: 10
Training loss: 1.9403737783432007
Validation loss: 1.976555743525105

Epoch: 240| Step: 0
Training loss: 1.5097979307174683
Validation loss: 2.0013688123354347

Epoch: 5| Step: 1
Training loss: 1.6572206020355225
Validation loss: 1.9813079885257188

Epoch: 5| Step: 2
Training loss: 1.5244296789169312
Validation loss: 1.9986835730973112

Epoch: 5| Step: 3
Training loss: 1.9378036260604858
Validation loss: 2.0069412851846344

Epoch: 5| Step: 4
Training loss: 1.4469733238220215
Validation loss: 2.002812857268959

Epoch: 5| Step: 5
Training loss: 1.2397239208221436
Validation loss: 1.9992728566610685

Epoch: 5| Step: 6
Training loss: 1.1948087215423584
Validation loss: 1.9984996780272453

Epoch: 5| Step: 7
Training loss: 1.9705270528793335
Validation loss: 2.01657074113046

Epoch: 5| Step: 8
Training loss: 1.3073015213012695
Validation loss: 1.9872466274487075

Epoch: 5| Step: 9
Training loss: 2.0006909370422363
Validation loss: 1.9633151587619577

Epoch: 5| Step: 10
Training loss: 1.6043407917022705
Validation loss: 1.9852510562507055

Epoch: 241| Step: 0
Training loss: 1.4402488470077515
Validation loss: 1.9714198330397248

Epoch: 5| Step: 1
Training loss: 1.2455918788909912
Validation loss: 1.9627720130387174

Epoch: 5| Step: 2
Training loss: 1.5734105110168457
Validation loss: 1.9540787050800938

Epoch: 5| Step: 3
Training loss: 1.674600601196289
Validation loss: 1.9680533511664278

Epoch: 5| Step: 4
Training loss: 1.7277262210845947
Validation loss: 1.9571402559998214

Epoch: 5| Step: 5
Training loss: 1.7918875217437744
Validation loss: 1.9626002875707482

Epoch: 5| Step: 6
Training loss: 1.7457551956176758
Validation loss: 1.973809870340491

Epoch: 5| Step: 7
Training loss: 1.4407788515090942
Validation loss: 1.9611735831024826

Epoch: 5| Step: 8
Training loss: 1.5034053325653076
Validation loss: 1.9554461240768433

Epoch: 5| Step: 9
Training loss: 1.3240275382995605
Validation loss: 1.972480373997842

Epoch: 5| Step: 10
Training loss: 1.4602996110916138
Validation loss: 1.9736995671385078

Epoch: 242| Step: 0
Training loss: 1.2192506790161133
Validation loss: 1.9661862619461552

Epoch: 5| Step: 1
Training loss: 1.0855991840362549
Validation loss: 1.9936851237409858

Epoch: 5| Step: 2
Training loss: 1.903440237045288
Validation loss: 2.004602837306197

Epoch: 5| Step: 3
Training loss: 2.1433329582214355
Validation loss: 2.005204443008669

Epoch: 5| Step: 4
Training loss: 0.7657095193862915
Validation loss: 2.0012824702006515

Epoch: 5| Step: 5
Training loss: 1.8038374185562134
Validation loss: 2.004580651560137

Epoch: 5| Step: 6
Training loss: 1.4283709526062012
Validation loss: 1.9939148015873407

Epoch: 5| Step: 7
Training loss: 1.7573492527008057
Validation loss: 2.0072561822911745

Epoch: 5| Step: 8
Training loss: 1.3432985544204712
Validation loss: 1.9925980042385798

Epoch: 5| Step: 9
Training loss: 1.9585130214691162
Validation loss: 1.9914840011186496

Epoch: 5| Step: 10
Training loss: 1.7159571647644043
Validation loss: 1.987894832447011

Epoch: 243| Step: 0
Training loss: 1.9185943603515625
Validation loss: 1.9750786007091563

Epoch: 5| Step: 1
Training loss: 1.335365653038025
Validation loss: 1.9741596175778298

Epoch: 5| Step: 2
Training loss: 1.5942100286483765
Validation loss: 1.9634095391919535

Epoch: 5| Step: 3
Training loss: 1.461058259010315
Validation loss: 1.9670024559062014

Epoch: 5| Step: 4
Training loss: 1.313093662261963
Validation loss: 1.9809993838751188

Epoch: 5| Step: 5
Training loss: 1.799155831336975
Validation loss: 1.9997721641294417

Epoch: 5| Step: 6
Training loss: 1.3684568405151367
Validation loss: 2.0030828496461273

Epoch: 5| Step: 7
Training loss: 1.405279517173767
Validation loss: 1.9785182014588387

Epoch: 5| Step: 8
Training loss: 1.752049207687378
Validation loss: 1.990092372381559

Epoch: 5| Step: 9
Training loss: 1.337610125541687
Validation loss: 2.0184355243559806

Epoch: 5| Step: 10
Training loss: 2.1078884601593018
Validation loss: 2.0506550958079677

Epoch: 244| Step: 0
Training loss: 1.6166642904281616
Validation loss: 2.0177944808877926

Epoch: 5| Step: 1
Training loss: 1.350683569908142
Validation loss: 2.0112197322230183

Epoch: 5| Step: 2
Training loss: 1.5833113193511963
Validation loss: 1.9830447102105746

Epoch: 5| Step: 3
Training loss: 1.5575512647628784
Validation loss: 1.9988612154478669

Epoch: 5| Step: 4
Training loss: 1.7876180410385132
Validation loss: 1.9875288689008324

Epoch: 5| Step: 5
Training loss: 1.4952392578125
Validation loss: 1.9744568230003439

Epoch: 5| Step: 6
Training loss: 1.6545350551605225
Validation loss: 1.9632574012202602

Epoch: 5| Step: 7
Training loss: 1.7195956707000732
Validation loss: 1.9428251148552023

Epoch: 5| Step: 8
Training loss: 1.646145224571228
Validation loss: 1.9651247967955887

Epoch: 5| Step: 9
Training loss: 1.5907033681869507
Validation loss: 2.0023589441853185

Epoch: 5| Step: 10
Training loss: 1.3734151124954224
Validation loss: 1.9888352347958473

Epoch: 245| Step: 0
Training loss: 2.0234947204589844
Validation loss: 2.0070606559835453

Epoch: 5| Step: 1
Training loss: 1.8543323278427124
Validation loss: 1.9911049540324877

Epoch: 5| Step: 2
Training loss: 0.9917046427726746
Validation loss: 2.0031861938456053

Epoch: 5| Step: 3
Training loss: 1.5571558475494385
Validation loss: 1.9899431428601664

Epoch: 5| Step: 4
Training loss: 0.900338351726532
Validation loss: 1.9795323853851647

Epoch: 5| Step: 5
Training loss: 1.8452078104019165
Validation loss: 1.9784862841329267

Epoch: 5| Step: 6
Training loss: 1.1592607498168945
Validation loss: 1.9841872158870901

Epoch: 5| Step: 7
Training loss: 1.8998806476593018
Validation loss: 1.9773846057153517

Epoch: 5| Step: 8
Training loss: 1.5839526653289795
Validation loss: 1.9639237234669347

Epoch: 5| Step: 9
Training loss: 1.6274211406707764
Validation loss: 1.9665835429263372

Epoch: 5| Step: 10
Training loss: 1.219351053237915
Validation loss: 1.977015358145519

Epoch: 246| Step: 0
Training loss: 1.4017093181610107
Validation loss: 1.9740101778379051

Epoch: 5| Step: 1
Training loss: 1.3875117301940918
Validation loss: 1.9791204237168836

Epoch: 5| Step: 2
Training loss: 1.564147710800171
Validation loss: 1.9768118576336933

Epoch: 5| Step: 3
Training loss: 2.3748488426208496
Validation loss: 1.9790081183115642

Epoch: 5| Step: 4
Training loss: 1.2046140432357788
Validation loss: 1.9922177868504678

Epoch: 5| Step: 5
Training loss: 1.8138107061386108
Validation loss: 2.0056595956125567

Epoch: 5| Step: 6
Training loss: 0.9847118258476257
Validation loss: 1.9819190015075028

Epoch: 5| Step: 7
Training loss: 1.4656782150268555
Validation loss: 1.9654296803218063

Epoch: 5| Step: 8
Training loss: 1.5891613960266113
Validation loss: 1.9526826079173754

Epoch: 5| Step: 9
Training loss: 1.3657273054122925
Validation loss: 1.952247509392359

Epoch: 5| Step: 10
Training loss: 1.594245433807373
Validation loss: 1.941331689075757

Epoch: 247| Step: 0
Training loss: 2.105048418045044
Validation loss: 1.9359204333315614

Epoch: 5| Step: 1
Training loss: 1.434098482131958
Validation loss: 1.9406569696241809

Epoch: 5| Step: 2
Training loss: 1.3846848011016846
Validation loss: 1.932413112732672

Epoch: 5| Step: 3
Training loss: 1.3358197212219238
Validation loss: 1.940511756045844

Epoch: 5| Step: 4
Training loss: 1.675095796585083
Validation loss: 1.968022455451309

Epoch: 5| Step: 5
Training loss: 1.8674697875976562
Validation loss: 1.97576476681617

Epoch: 5| Step: 6
Training loss: 1.573512077331543
Validation loss: 1.9933497354548464

Epoch: 5| Step: 7
Training loss: 1.0257364511489868
Validation loss: 1.9769696843239568

Epoch: 5| Step: 8
Training loss: 1.4479697942733765
Validation loss: 1.998312009278164

Epoch: 5| Step: 9
Training loss: 1.0126949548721313
Validation loss: 2.0073898505139094

Epoch: 5| Step: 10
Training loss: 1.8954923152923584
Validation loss: 2.0161943153668473

Epoch: 248| Step: 0
Training loss: 1.2236915826797485
Validation loss: 2.0165557040963122

Epoch: 5| Step: 1
Training loss: 1.4557535648345947
Validation loss: 1.9867341595311319

Epoch: 5| Step: 2
Training loss: 0.9112366437911987
Validation loss: 1.9603773727211902

Epoch: 5| Step: 3
Training loss: 1.215942621231079
Validation loss: 1.9919018745422363

Epoch: 5| Step: 4
Training loss: 1.4488346576690674
Validation loss: 2.0333213421606247

Epoch: 5| Step: 5
Training loss: 1.6812442541122437
Validation loss: 2.0460288524627686

Epoch: 5| Step: 6
Training loss: 1.6865684986114502
Validation loss: 1.9861547831566102

Epoch: 5| Step: 7
Training loss: 1.9042781591415405
Validation loss: 1.9626608830626293

Epoch: 5| Step: 8
Training loss: 1.4453428983688354
Validation loss: 1.9683247356004612

Epoch: 5| Step: 9
Training loss: 2.484689235687256
Validation loss: 2.0231161861009497

Epoch: 5| Step: 10
Training loss: 1.3944940567016602
Validation loss: 2.0765798117524836

Epoch: 249| Step: 0
Training loss: 2.0295791625976562
Validation loss: 2.082280369215114

Epoch: 5| Step: 1
Training loss: 2.235818862915039
Validation loss: 2.0581672960712063

Epoch: 5| Step: 2
Training loss: 1.352811574935913
Validation loss: 2.0371210844286027

Epoch: 5| Step: 3
Training loss: 1.2424229383468628
Validation loss: 2.007428556360224

Epoch: 5| Step: 4
Training loss: 1.5328047275543213
Validation loss: 1.9606483610727454

Epoch: 5| Step: 5
Training loss: 1.3807998895645142
Validation loss: 1.923543135325114

Epoch: 5| Step: 6
Training loss: 1.4453363418579102
Validation loss: 1.9535216182790778

Epoch: 5| Step: 7
Training loss: 1.8355127573013306
Validation loss: 2.0012090308691866

Epoch: 5| Step: 8
Training loss: 1.1890971660614014
Validation loss: 2.0360811718048586

Epoch: 5| Step: 9
Training loss: 1.9727935791015625
Validation loss: 2.0538201332092285

Epoch: 5| Step: 10
Training loss: 1.8585376739501953
Validation loss: 2.080308475802022

Epoch: 250| Step: 0
Training loss: 1.4550822973251343
Validation loss: 2.0897687148022395

Epoch: 5| Step: 1
Training loss: 1.4661190509796143
Validation loss: 2.052089842416907

Epoch: 5| Step: 2
Training loss: 1.9589637517929077
Validation loss: 2.0232464036633893

Epoch: 5| Step: 3
Training loss: 1.9312702417373657
Validation loss: 2.0166508690003426

Epoch: 5| Step: 4
Training loss: 1.921115517616272
Validation loss: 1.9894268563998643

Epoch: 5| Step: 5
Training loss: 1.5965849161148071
Validation loss: 2.0278723316807903

Epoch: 5| Step: 6
Training loss: 1.6257635354995728
Validation loss: 2.003170967102051

Epoch: 5| Step: 7
Training loss: 1.4350974559783936
Validation loss: 1.9682107023013535

Epoch: 5| Step: 8
Training loss: 1.6074813604354858
Validation loss: 1.9771241936632382

Epoch: 5| Step: 9
Training loss: 1.5599287748336792
Validation loss: 1.963510654305899

Epoch: 5| Step: 10
Training loss: 1.4114623069763184
Validation loss: 1.9374536083590599

Epoch: 251| Step: 0
Training loss: 1.674913763999939
Validation loss: 1.9452536644474152

Epoch: 5| Step: 1
Training loss: 1.6031105518341064
Validation loss: 1.9485479606095182

Epoch: 5| Step: 2
Training loss: 1.669548749923706
Validation loss: 1.9730185257491244

Epoch: 5| Step: 3
Training loss: 1.3637769222259521
Validation loss: 2.0168744325637817

Epoch: 5| Step: 4
Training loss: 1.537788987159729
Validation loss: 2.0064273906010452

Epoch: 5| Step: 5
Training loss: 1.4608511924743652
Validation loss: 1.99050570559758

Epoch: 5| Step: 6
Training loss: 1.454652190208435
Validation loss: 1.9778388418177122

Epoch: 5| Step: 7
Training loss: 1.765753149986267
Validation loss: 1.9615919333632275

Epoch: 5| Step: 8
Training loss: 1.0279419422149658
Validation loss: 1.961493307544339

Epoch: 5| Step: 9
Training loss: 1.467362642288208
Validation loss: 1.9697937016846032

Epoch: 5| Step: 10
Training loss: 2.3036587238311768
Validation loss: 1.9772263406425394

Epoch: 252| Step: 0
Training loss: 1.214046597480774
Validation loss: 2.0130491410532305

Epoch: 5| Step: 1
Training loss: 1.7399572134017944
Validation loss: 1.9845732783758512

Epoch: 5| Step: 2
Training loss: 1.712792992591858
Validation loss: 1.963637464789934

Epoch: 5| Step: 3
Training loss: 1.4002585411071777
Validation loss: 1.9440282147417787

Epoch: 5| Step: 4
Training loss: 2.3633768558502197
Validation loss: 1.951655774988154

Epoch: 5| Step: 5
Training loss: 1.5470691919326782
Validation loss: 1.951384190590151

Epoch: 5| Step: 6
Training loss: 1.5425821542739868
Validation loss: 1.9342060166020547

Epoch: 5| Step: 7
Training loss: 1.2234477996826172
Validation loss: 1.9374433358510335

Epoch: 5| Step: 8
Training loss: 1.3849031925201416
Validation loss: 1.9491116231487644

Epoch: 5| Step: 9
Training loss: 0.9783254861831665
Validation loss: 1.939786503391881

Epoch: 5| Step: 10
Training loss: 1.4635708332061768
Validation loss: 1.9672051604076097

Epoch: 253| Step: 0
Training loss: 1.1776365041732788
Validation loss: 1.9728137523897233

Epoch: 5| Step: 1
Training loss: 1.910498857498169
Validation loss: 1.9866837763017224

Epoch: 5| Step: 2
Training loss: 1.04616117477417
Validation loss: 2.0071281540778374

Epoch: 5| Step: 3
Training loss: 1.4248424768447876
Validation loss: 2.0175926095695904

Epoch: 5| Step: 4
Training loss: 1.6808874607086182
Validation loss: 2.0382521870315715

Epoch: 5| Step: 5
Training loss: 1.152141809463501
Validation loss: 2.054349413482092

Epoch: 5| Step: 6
Training loss: 1.6139943599700928
Validation loss: 2.0417350222987514

Epoch: 5| Step: 7
Training loss: 1.2104806900024414
Validation loss: 2.0061420343255483

Epoch: 5| Step: 8
Training loss: 1.4829766750335693
Validation loss: 2.003113390297018

Epoch: 5| Step: 9
Training loss: 1.7203941345214844
Validation loss: 1.9697660246203024

Epoch: 5| Step: 10
Training loss: 1.859086275100708
Validation loss: 1.9829219848878923

Epoch: 254| Step: 0
Training loss: 1.682941198348999
Validation loss: 1.9762161829138314

Epoch: 5| Step: 1
Training loss: 1.7967122793197632
Validation loss: 1.9936541280438822

Epoch: 5| Step: 2
Training loss: 1.4832749366760254
Validation loss: 1.986558997502891

Epoch: 5| Step: 3
Training loss: 1.592402696609497
Validation loss: 1.9700297924780077

Epoch: 5| Step: 4
Training loss: 0.935877799987793
Validation loss: 1.9898117614048783

Epoch: 5| Step: 5
Training loss: 1.0337157249450684
Validation loss: 1.9607597333128735

Epoch: 5| Step: 6
Training loss: 1.5356693267822266
Validation loss: 1.9363087877150504

Epoch: 5| Step: 7
Training loss: 1.5099575519561768
Validation loss: 1.9380895412096413

Epoch: 5| Step: 8
Training loss: 1.820582628250122
Validation loss: 1.95759831577219

Epoch: 5| Step: 9
Training loss: 1.4599562883377075
Validation loss: 1.987897180741833

Epoch: 5| Step: 10
Training loss: 1.3277498483657837
Validation loss: 1.9622755640296525

Epoch: 255| Step: 0
Training loss: 1.3599025011062622
Validation loss: 1.9446480748473958

Epoch: 5| Step: 1
Training loss: 1.5494873523712158
Validation loss: 1.9369040958343013

Epoch: 5| Step: 2
Training loss: 1.3669332265853882
Validation loss: 1.949207116198796

Epoch: 5| Step: 3
Training loss: 1.9557723999023438
Validation loss: 1.9454553140107023

Epoch: 5| Step: 4
Training loss: 1.5643107891082764
Validation loss: 1.9471720200712963

Epoch: 5| Step: 5
Training loss: 1.1725437641143799
Validation loss: 1.9575625235034573

Epoch: 5| Step: 6
Training loss: 1.628305196762085
Validation loss: 1.9385909341996717

Epoch: 5| Step: 7
Training loss: 1.0358607769012451
Validation loss: 1.9371428848594747

Epoch: 5| Step: 8
Training loss: 1.298368215560913
Validation loss: 1.9194582764820387

Epoch: 5| Step: 9
Training loss: 1.5073373317718506
Validation loss: 1.9330216197557346

Epoch: 5| Step: 10
Training loss: 1.4188199043273926
Validation loss: 1.9376698001738517

Epoch: 256| Step: 0
Training loss: 1.7410084009170532
Validation loss: 1.9682392727944158

Epoch: 5| Step: 1
Training loss: 1.5106146335601807
Validation loss: 1.9597379648557274

Epoch: 5| Step: 2
Training loss: 1.2931787967681885
Validation loss: 1.9810270776030838

Epoch: 5| Step: 3
Training loss: 1.3982793092727661
Validation loss: 1.9826799079936037

Epoch: 5| Step: 4
Training loss: 1.4503005743026733
Validation loss: 1.9609845235783567

Epoch: 5| Step: 5
Training loss: 1.3886679410934448
Validation loss: 1.9876904179972987

Epoch: 5| Step: 6
Training loss: 1.342073917388916
Validation loss: 1.9845018848296134

Epoch: 5| Step: 7
Training loss: 1.3322585821151733
Validation loss: 2.0076855215975034

Epoch: 5| Step: 8
Training loss: 1.3929086923599243
Validation loss: 1.9946866522553146

Epoch: 5| Step: 9
Training loss: 1.9877372980117798
Validation loss: 1.9938692123659196

Epoch: 5| Step: 10
Training loss: 1.3242019414901733
Validation loss: 1.963413579489595

Epoch: 257| Step: 0
Training loss: 1.8029696941375732
Validation loss: 1.970664865227156

Epoch: 5| Step: 1
Training loss: 1.5118522644042969
Validation loss: 1.955175079325194

Epoch: 5| Step: 2
Training loss: 1.5968568325042725
Validation loss: 1.948427930954964

Epoch: 5| Step: 3
Training loss: 1.0192512273788452
Validation loss: 1.9357304675604707

Epoch: 5| Step: 4
Training loss: 1.165177583694458
Validation loss: 1.962217887242635

Epoch: 5| Step: 5
Training loss: 1.6092487573623657
Validation loss: 1.9516645708391744

Epoch: 5| Step: 6
Training loss: 1.2244269847869873
Validation loss: 1.9455659697132726

Epoch: 5| Step: 7
Training loss: 1.5625274181365967
Validation loss: 1.951836383470925

Epoch: 5| Step: 8
Training loss: 1.7897870540618896
Validation loss: 1.9416869045585714

Epoch: 5| Step: 9
Training loss: 1.3127853870391846
Validation loss: 1.9516169858235184

Epoch: 5| Step: 10
Training loss: 0.9437496066093445
Validation loss: 1.9340075574895388

Epoch: 258| Step: 0
Training loss: 1.028259515762329
Validation loss: 1.9215834371505245

Epoch: 5| Step: 1
Training loss: 1.639209508895874
Validation loss: 1.9252526298646004

Epoch: 5| Step: 2
Training loss: 1.276724100112915
Validation loss: 1.926989983486873

Epoch: 5| Step: 3
Training loss: 1.2128527164459229
Validation loss: 1.9357449393118582

Epoch: 5| Step: 4
Training loss: 1.5369333028793335
Validation loss: 1.955618558391448

Epoch: 5| Step: 5
Training loss: 0.8862506747245789
Validation loss: 1.953790049399099

Epoch: 5| Step: 6
Training loss: 1.034277319908142
Validation loss: 1.9579176748952558

Epoch: 5| Step: 7
Training loss: 1.6224256753921509
Validation loss: 1.95544615099507

Epoch: 5| Step: 8
Training loss: 1.8691987991333008
Validation loss: 1.9659987649609965

Epoch: 5| Step: 9
Training loss: 1.501821756362915
Validation loss: 1.971706941563596

Epoch: 5| Step: 10
Training loss: 1.7980445623397827
Validation loss: 1.9649977145656463

Epoch: 259| Step: 0
Training loss: 1.5118770599365234
Validation loss: 1.9556241868644633

Epoch: 5| Step: 1
Training loss: 1.1019036769866943
Validation loss: 1.9403384308661185

Epoch: 5| Step: 2
Training loss: 1.1925084590911865
Validation loss: 1.934124836357691

Epoch: 5| Step: 3
Training loss: 1.2316488027572632
Validation loss: 1.9318842503332323

Epoch: 5| Step: 4
Training loss: 1.153241515159607
Validation loss: 1.9393194542136243

Epoch: 5| Step: 5
Training loss: 1.4256715774536133
Validation loss: 1.9331194316187212

Epoch: 5| Step: 6
Training loss: 1.962464690208435
Validation loss: 1.9249263476299983

Epoch: 5| Step: 7
Training loss: 1.6359941959381104
Validation loss: 1.9312750741999636

Epoch: 5| Step: 8
Training loss: 0.8996360898017883
Validation loss: 1.9157753272723126

Epoch: 5| Step: 9
Training loss: 1.6190690994262695
Validation loss: 1.9068474615773847

Epoch: 5| Step: 10
Training loss: 1.3179715871810913
Validation loss: 1.9134416041835662

Epoch: 260| Step: 0
Training loss: 1.8069003820419312
Validation loss: 1.8950552722459197

Epoch: 5| Step: 1
Training loss: 1.194062352180481
Validation loss: 1.9324359509252733

Epoch: 5| Step: 2
Training loss: 1.1265268325805664
Validation loss: 1.9084483410722466

Epoch: 5| Step: 3
Training loss: 1.4106475114822388
Validation loss: 1.8842223023855558

Epoch: 5| Step: 4
Training loss: 1.0113811492919922
Validation loss: 1.884513508888983

Epoch: 5| Step: 5
Training loss: 1.9837429523468018
Validation loss: 1.9009931638676634

Epoch: 5| Step: 6
Training loss: 1.717289686203003
Validation loss: 1.9175811531723186

Epoch: 5| Step: 7
Training loss: 1.0882844924926758
Validation loss: 1.8664135163830173

Epoch: 5| Step: 8
Training loss: 0.8773029446601868
Validation loss: 1.8849800376481907

Epoch: 5| Step: 9
Training loss: 1.3292049169540405
Validation loss: 1.8887915752267326

Epoch: 5| Step: 10
Training loss: 1.4368093013763428
Validation loss: 1.895014262968494

Epoch: 261| Step: 0
Training loss: 1.6219333410263062
Validation loss: 1.9092442873985536

Epoch: 5| Step: 1
Training loss: 1.2870676517486572
Validation loss: 1.908731657971618

Epoch: 5| Step: 2
Training loss: 1.4316550493240356
Validation loss: 1.9607303245093233

Epoch: 5| Step: 3
Training loss: 1.5570809841156006
Validation loss: 1.93327316417489

Epoch: 5| Step: 4
Training loss: 0.8595679402351379
Validation loss: 1.9674359252375941

Epoch: 5| Step: 5
Training loss: 1.3533194065093994
Validation loss: 1.9679944797228741

Epoch: 5| Step: 6
Training loss: 0.7900115251541138
Validation loss: 1.9618941686486686

Epoch: 5| Step: 7
Training loss: 1.0937223434448242
Validation loss: 1.959247871111798

Epoch: 5| Step: 8
Training loss: 1.6243274211883545
Validation loss: 1.947105364132953

Epoch: 5| Step: 9
Training loss: 1.8486770391464233
Validation loss: 1.957709845676217

Epoch: 5| Step: 10
Training loss: 1.5475066900253296
Validation loss: 1.9595714717782953

Epoch: 262| Step: 0
Training loss: 1.5351816415786743
Validation loss: 1.9511391834546161

Epoch: 5| Step: 1
Training loss: 1.7428487539291382
Validation loss: 1.9567709033207228

Epoch: 5| Step: 2
Training loss: 1.9676597118377686
Validation loss: 1.9593981799258982

Epoch: 5| Step: 3
Training loss: 1.3898636102676392
Validation loss: 1.9317670547834007

Epoch: 5| Step: 4
Training loss: 1.3829281330108643
Validation loss: 1.9451037927340435

Epoch: 5| Step: 5
Training loss: 1.6180274486541748
Validation loss: 1.9225408095185474

Epoch: 5| Step: 6
Training loss: 1.270780086517334
Validation loss: 1.921976814987839

Epoch: 5| Step: 7
Training loss: 1.237105131149292
Validation loss: 1.9420425443239109

Epoch: 5| Step: 8
Training loss: 0.6576792001724243
Validation loss: 1.9306346831783172

Epoch: 5| Step: 9
Training loss: 1.1311259269714355
Validation loss: 1.9345043833537767

Epoch: 5| Step: 10
Training loss: 1.0664533376693726
Validation loss: 1.9690289933194396

Epoch: 263| Step: 0
Training loss: 0.8425725102424622
Validation loss: 1.9395851191654

Epoch: 5| Step: 1
Training loss: 0.7559391260147095
Validation loss: 1.9620493304344915

Epoch: 5| Step: 2
Training loss: 1.689549207687378
Validation loss: 1.9624210044901857

Epoch: 5| Step: 3
Training loss: 2.046686887741089
Validation loss: 1.9636880890015633

Epoch: 5| Step: 4
Training loss: 0.49198970198631287
Validation loss: 1.9659378631140596

Epoch: 5| Step: 5
Training loss: 1.647007942199707
Validation loss: 1.9926547440149451

Epoch: 5| Step: 6
Training loss: 1.544901967048645
Validation loss: 1.9738225629252772

Epoch: 5| Step: 7
Training loss: 1.4317634105682373
Validation loss: 1.9613646871300154

Epoch: 5| Step: 8
Training loss: 1.4135397672653198
Validation loss: 1.9724434575726908

Epoch: 5| Step: 9
Training loss: 1.181069016456604
Validation loss: 1.949322913282661

Epoch: 5| Step: 10
Training loss: 1.9065309762954712
Validation loss: 1.9157367560171312

Epoch: 264| Step: 0
Training loss: 1.470034122467041
Validation loss: 1.9048929188841133

Epoch: 5| Step: 1
Training loss: 1.4000601768493652
Validation loss: 1.905373647648801

Epoch: 5| Step: 2
Training loss: 1.6166378259658813
Validation loss: 1.8806852961099276

Epoch: 5| Step: 3
Training loss: 0.958727240562439
Validation loss: 1.882689747759091

Epoch: 5| Step: 4
Training loss: 1.0519431829452515
Validation loss: 1.8827588327469365

Epoch: 5| Step: 5
Training loss: 1.43605637550354
Validation loss: 1.8941436108722483

Epoch: 5| Step: 6
Training loss: 1.3600143194198608
Validation loss: 1.9159362559677453

Epoch: 5| Step: 7
Training loss: 1.7085500955581665
Validation loss: 1.90957385493863

Epoch: 5| Step: 8
Training loss: 1.432464838027954
Validation loss: 1.8969319776822162

Epoch: 5| Step: 9
Training loss: 1.1932690143585205
Validation loss: 1.9051039693176106

Epoch: 5| Step: 10
Training loss: 1.211864948272705
Validation loss: 1.8906422353559924

Epoch: 265| Step: 0
Training loss: 0.9080392718315125
Validation loss: 1.9313018142536122

Epoch: 5| Step: 1
Training loss: 1.566886067390442
Validation loss: 1.917463476939868

Epoch: 5| Step: 2
Training loss: 1.438963770866394
Validation loss: 1.901069559076781

Epoch: 5| Step: 3
Training loss: 1.3484270572662354
Validation loss: 1.9271569713469474

Epoch: 5| Step: 4
Training loss: 1.8060293197631836
Validation loss: 1.916712612234136

Epoch: 5| Step: 5
Training loss: 2.3413615226745605
Validation loss: 1.9178031862422984

Epoch: 5| Step: 6
Training loss: 0.810223400592804
Validation loss: 1.915199759185955

Epoch: 5| Step: 7
Training loss: 1.3543000221252441
Validation loss: 1.9176896682349585

Epoch: 5| Step: 8
Training loss: 0.46749526262283325
Validation loss: 1.9139561781319239

Epoch: 5| Step: 9
Training loss: 1.852623701095581
Validation loss: 1.911470426026211

Epoch: 5| Step: 10
Training loss: 0.6761036515235901
Validation loss: 1.9090962102336269

Epoch: 266| Step: 0
Training loss: 1.5329163074493408
Validation loss: 1.9071128035104403

Epoch: 5| Step: 1
Training loss: 1.5236809253692627
Validation loss: 1.9271408063109203

Epoch: 5| Step: 2
Training loss: 1.8436088562011719
Validation loss: 1.9484727767206007

Epoch: 5| Step: 3
Training loss: 1.312952995300293
Validation loss: 1.8989389045264131

Epoch: 5| Step: 4
Training loss: 1.6724097728729248
Validation loss: 1.8909571927080873

Epoch: 5| Step: 5
Training loss: 1.3371689319610596
Validation loss: 1.8984952652326195

Epoch: 5| Step: 6
Training loss: 1.1451339721679688
Validation loss: 1.9191097674831268

Epoch: 5| Step: 7
Training loss: 1.6698627471923828
Validation loss: 1.9795972839478524

Epoch: 5| Step: 8
Training loss: 0.8410843014717102
Validation loss: 1.979187926938457

Epoch: 5| Step: 9
Training loss: 0.9748085737228394
Validation loss: 1.9411916578969648

Epoch: 5| Step: 10
Training loss: 1.0946006774902344
Validation loss: 1.8979669463249944

Epoch: 267| Step: 0
Training loss: 1.0027278661727905
Validation loss: 1.9144296620481758

Epoch: 5| Step: 1
Training loss: 1.1727240085601807
Validation loss: 1.9268303507117814

Epoch: 5| Step: 2
Training loss: 1.8487069606781006
Validation loss: 1.9316177137436406

Epoch: 5| Step: 3
Training loss: 1.0858157873153687
Validation loss: 1.9487183965662473

Epoch: 5| Step: 4
Training loss: 1.399658441543579
Validation loss: 1.9744659341791624

Epoch: 5| Step: 5
Training loss: 1.9887237548828125
Validation loss: 1.9722235638608214

Epoch: 5| Step: 6
Training loss: 1.3740475177764893
Validation loss: 1.9539985554192656

Epoch: 5| Step: 7
Training loss: 1.453691840171814
Validation loss: 1.9329896896116194

Epoch: 5| Step: 8
Training loss: 1.4313865900039673
Validation loss: 1.9671476041117022

Epoch: 5| Step: 9
Training loss: 1.0533138513565063
Validation loss: 1.9644139043746456

Epoch: 5| Step: 10
Training loss: 0.773941695690155
Validation loss: 1.958126780807331

Epoch: 268| Step: 0
Training loss: 2.1333746910095215
Validation loss: 1.9220123637107112

Epoch: 5| Step: 1
Training loss: 1.1670647859573364
Validation loss: 1.9105758269627888

Epoch: 5| Step: 2
Training loss: 1.0118342638015747
Validation loss: 1.9028280345342492

Epoch: 5| Step: 3
Training loss: 1.105440616607666
Validation loss: 1.8826992306658017

Epoch: 5| Step: 4
Training loss: 1.2352344989776611
Validation loss: 1.9059143771407425

Epoch: 5| Step: 5
Training loss: 1.4946368932724
Validation loss: 1.907089981981503

Epoch: 5| Step: 6
Training loss: 1.6450319290161133
Validation loss: 1.8999290902127501

Epoch: 5| Step: 7
Training loss: 1.4717490673065186
Validation loss: 1.8943971177583099

Epoch: 5| Step: 8
Training loss: 0.8712131381034851
Validation loss: 1.8943627393373879

Epoch: 5| Step: 9
Training loss: 1.4600979089736938
Validation loss: 1.9173813648121332

Epoch: 5| Step: 10
Training loss: 0.9359542727470398
Validation loss: 1.9357878572197371

Epoch: 269| Step: 0
Training loss: 0.8028383255004883
Validation loss: 1.9142304017979612

Epoch: 5| Step: 1
Training loss: 1.257335901260376
Validation loss: 1.9520054863345238

Epoch: 5| Step: 2
Training loss: 1.1474792957305908
Validation loss: 1.9242377883644515

Epoch: 5| Step: 3
Training loss: 1.3317301273345947
Validation loss: 1.9407227398246847

Epoch: 5| Step: 4
Training loss: 1.1226978302001953
Validation loss: 1.9483801164934713

Epoch: 5| Step: 5
Training loss: 1.0420854091644287
Validation loss: 1.9217513376666653

Epoch: 5| Step: 6
Training loss: 1.3788201808929443
Validation loss: 1.9236131816781976

Epoch: 5| Step: 7
Training loss: 1.458406925201416
Validation loss: 1.9485037865177277

Epoch: 5| Step: 8
Training loss: 1.883385419845581
Validation loss: 1.9441148901498446

Epoch: 5| Step: 9
Training loss: 1.330141544342041
Validation loss: 1.9208406350945915

Epoch: 5| Step: 10
Training loss: 1.2619723081588745
Validation loss: 1.9185051520665486

Epoch: 270| Step: 0
Training loss: 0.953260600566864
Validation loss: 1.93049362397963

Epoch: 5| Step: 1
Training loss: 1.220860242843628
Validation loss: 1.902268725056802

Epoch: 5| Step: 2
Training loss: 1.723855972290039
Validation loss: 1.905762594233277

Epoch: 5| Step: 3
Training loss: 0.8519091606140137
Validation loss: 1.8979410663727792

Epoch: 5| Step: 4
Training loss: 1.6406112909317017
Validation loss: 1.9040682367099229

Epoch: 5| Step: 5
Training loss: 0.8443527221679688
Validation loss: 1.919981562963096

Epoch: 5| Step: 6
Training loss: 1.5077568292617798
Validation loss: 1.9349201789466284

Epoch: 5| Step: 7
Training loss: 1.4904944896697998
Validation loss: 1.9209333030126428

Epoch: 5| Step: 8
Training loss: 1.2596261501312256
Validation loss: 1.943531850332855

Epoch: 5| Step: 9
Training loss: 1.3265886306762695
Validation loss: 1.9399476410240255

Epoch: 5| Step: 10
Training loss: 1.150909662246704
Validation loss: 1.9542133808135986

Epoch: 271| Step: 0
Training loss: 0.700104296207428
Validation loss: 2.0070670676487747

Epoch: 5| Step: 1
Training loss: 1.0261919498443604
Validation loss: 2.0070130389223815

Epoch: 5| Step: 2
Training loss: 1.0941998958587646
Validation loss: 1.996012718446793

Epoch: 5| Step: 3
Training loss: 1.27217698097229
Validation loss: 1.9626735512928297

Epoch: 5| Step: 4
Training loss: 0.8671863675117493
Validation loss: 1.9259225322354225

Epoch: 5| Step: 5
Training loss: 1.2797619104385376
Validation loss: 1.9226900364762993

Epoch: 5| Step: 6
Training loss: 1.4955627918243408
Validation loss: 1.9084118796933083

Epoch: 5| Step: 7
Training loss: 0.8456569910049438
Validation loss: 1.8822781168004519

Epoch: 5| Step: 8
Training loss: 1.8350965976715088
Validation loss: 1.886004376155074

Epoch: 5| Step: 9
Training loss: 1.9557701349258423
Validation loss: 1.8980531307958788

Epoch: 5| Step: 10
Training loss: 2.1021413803100586
Validation loss: 1.889171633669125

Epoch: 272| Step: 0
Training loss: 1.3544831275939941
Validation loss: 1.9019244076103292

Epoch: 5| Step: 1
Training loss: 1.5976684093475342
Validation loss: 1.8993028261328255

Epoch: 5| Step: 2
Training loss: 1.129237413406372
Validation loss: 1.90981948760248

Epoch: 5| Step: 3
Training loss: 1.0670452117919922
Validation loss: 1.933366355075631

Epoch: 5| Step: 4
Training loss: 1.6908433437347412
Validation loss: 1.9594370626634168

Epoch: 5| Step: 5
Training loss: 0.9145526885986328
Validation loss: 1.9803254065975067

Epoch: 5| Step: 6
Training loss: 1.2026132345199585
Validation loss: 1.9842491072993125

Epoch: 5| Step: 7
Training loss: 0.9180170297622681
Validation loss: 1.9779951931327902

Epoch: 5| Step: 8
Training loss: 1.4351674318313599
Validation loss: 1.9771865798581032

Epoch: 5| Step: 9
Training loss: 1.2639968395233154
Validation loss: 1.925144724948432

Epoch: 5| Step: 10
Training loss: 1.6784731149673462
Validation loss: 1.9125158145863523

Epoch: 273| Step: 0
Training loss: 1.0468366146087646
Validation loss: 1.8973342205888482

Epoch: 5| Step: 1
Training loss: 1.782345175743103
Validation loss: 1.9102093519703034

Epoch: 5| Step: 2
Training loss: 1.31982421875
Validation loss: 1.9069818886377479

Epoch: 5| Step: 3
Training loss: 1.2173360586166382
Validation loss: 1.914854923884074

Epoch: 5| Step: 4
Training loss: 1.588696002960205
Validation loss: 1.9654252926508586

Epoch: 5| Step: 5
Training loss: 1.4145042896270752
Validation loss: 1.9663902739042878

Epoch: 5| Step: 6
Training loss: 1.2788166999816895
Validation loss: 1.9711871852156937

Epoch: 5| Step: 7
Training loss: 1.0611941814422607
Validation loss: 1.9372130593945902

Epoch: 5| Step: 8
Training loss: 0.9681824445724487
Validation loss: 1.9435218816162438

Epoch: 5| Step: 9
Training loss: 1.5836613178253174
Validation loss: 1.9336606610205866

Epoch: 5| Step: 10
Training loss: 0.976742148399353
Validation loss: 1.9175016892853605

Epoch: 274| Step: 0
Training loss: 1.3304535150527954
Validation loss: 1.9306730762604745

Epoch: 5| Step: 1
Training loss: 1.0948801040649414
Validation loss: 1.92357555256095

Epoch: 5| Step: 2
Training loss: 1.5514131784439087
Validation loss: 1.923911904775968

Epoch: 5| Step: 3
Training loss: 1.6988296508789062
Validation loss: 1.9232506905832598

Epoch: 5| Step: 4
Training loss: 0.541047215461731
Validation loss: 1.939302570076399

Epoch: 5| Step: 5
Training loss: 1.3042433261871338
Validation loss: 1.909666322892712

Epoch: 5| Step: 6
Training loss: 1.0209124088287354
Validation loss: 1.889397305826987

Epoch: 5| Step: 7
Training loss: 0.7133442163467407
Validation loss: 1.8959120524826871

Epoch: 5| Step: 8
Training loss: 1.7876840829849243
Validation loss: 1.8995283444722493

Epoch: 5| Step: 9
Training loss: 1.3496173620224
Validation loss: 1.9110757253503288

Epoch: 5| Step: 10
Training loss: 1.646185040473938
Validation loss: 1.9276500209685294

Epoch: 275| Step: 0
Training loss: 0.566123366355896
Validation loss: 1.9342245004510368

Epoch: 5| Step: 1
Training loss: 1.3776801824569702
Validation loss: 1.9328683422457786

Epoch: 5| Step: 2
Training loss: 1.3937089443206787
Validation loss: 1.9344017685100596

Epoch: 5| Step: 3
Training loss: 1.3126882314682007
Validation loss: 1.96663083312332

Epoch: 5| Step: 4
Training loss: 1.162140130996704
Validation loss: 2.008854881409676

Epoch: 5| Step: 5
Training loss: 1.2471212148666382
Validation loss: 2.0357322308324997

Epoch: 5| Step: 6
Training loss: 1.5175533294677734
Validation loss: 2.0471324074652886

Epoch: 5| Step: 7
Training loss: 1.3790960311889648
Validation loss: 2.0380614214046027

Epoch: 5| Step: 8
Training loss: 1.3872992992401123
Validation loss: 1.977195046281302

Epoch: 5| Step: 9
Training loss: 1.5461618900299072
Validation loss: 1.9174621335921749

Epoch: 5| Step: 10
Training loss: 1.1334789991378784
Validation loss: 1.9206140220806163

Epoch: 276| Step: 0
Training loss: 1.2894556522369385
Validation loss: 1.8967474147837649

Epoch: 5| Step: 1
Training loss: 1.5796772241592407
Validation loss: 1.8975027556060462

Epoch: 5| Step: 2
Training loss: 1.480013132095337
Validation loss: 1.8699961067527853

Epoch: 5| Step: 3
Training loss: 1.2190684080123901
Validation loss: 1.886032755656909

Epoch: 5| Step: 4
Training loss: 1.0729243755340576
Validation loss: 1.9113028049468994

Epoch: 5| Step: 5
Training loss: 1.2730967998504639
Validation loss: 1.8937068536717405

Epoch: 5| Step: 6
Training loss: 1.6184921264648438
Validation loss: 1.9145036179532287

Epoch: 5| Step: 7
Training loss: 0.8199199438095093
Validation loss: 1.928544686686608

Epoch: 5| Step: 8
Training loss: 1.6157073974609375
Validation loss: 1.9293679819312146

Epoch: 5| Step: 9
Training loss: 0.8397356271743774
Validation loss: 1.937748268086423

Epoch: 5| Step: 10
Training loss: 1.1879068613052368
Validation loss: 1.9190412875144713

Epoch: 277| Step: 0
Training loss: 1.0870752334594727
Validation loss: 1.9242586397355603

Epoch: 5| Step: 1
Training loss: 0.9709985852241516
Validation loss: 1.9089338894813292

Epoch: 5| Step: 2
Training loss: 0.6882786750793457
Validation loss: 1.9253159851156256

Epoch: 5| Step: 3
Training loss: 0.9103697538375854
Validation loss: 1.897791781733113

Epoch: 5| Step: 4
Training loss: 1.4557335376739502
Validation loss: 1.9112780850420716

Epoch: 5| Step: 5
Training loss: 1.7334133386611938
Validation loss: 1.9054444951395835

Epoch: 5| Step: 6
Training loss: 1.5381624698638916
Validation loss: 1.9133545583294285

Epoch: 5| Step: 7
Training loss: 1.5175580978393555
Validation loss: 1.9205975122349237

Epoch: 5| Step: 8
Training loss: 1.0353176593780518
Validation loss: 1.9227235060866161

Epoch: 5| Step: 9
Training loss: 1.155122995376587
Validation loss: 1.9195115386798818

Epoch: 5| Step: 10
Training loss: 1.5138206481933594
Validation loss: 1.9234797211103543

Epoch: 278| Step: 0
Training loss: 1.4558897018432617
Validation loss: 1.92426255185117

Epoch: 5| Step: 1
Training loss: 0.8336353302001953
Validation loss: 1.9183252216667257

Epoch: 5| Step: 2
Training loss: 1.538362979888916
Validation loss: 1.9002184611494823

Epoch: 5| Step: 3
Training loss: 0.9754320979118347
Validation loss: 1.888036717650711

Epoch: 5| Step: 4
Training loss: 0.8859752416610718
Validation loss: 1.8784075885690668

Epoch: 5| Step: 5
Training loss: 1.4552662372589111
Validation loss: 1.898181115427325

Epoch: 5| Step: 6
Training loss: 1.1864832639694214
Validation loss: 1.8921984780219294

Epoch: 5| Step: 7
Training loss: 1.4308559894561768
Validation loss: 1.8983714362626434

Epoch: 5| Step: 8
Training loss: 1.2803146839141846
Validation loss: 1.8817932221197313

Epoch: 5| Step: 9
Training loss: 1.3925739526748657
Validation loss: 1.9055825715423913

Epoch: 5| Step: 10
Training loss: 0.7730896472930908
Validation loss: 1.8923450528934438

Epoch: 279| Step: 0
Training loss: 1.1855170726776123
Validation loss: 1.9055798284469112

Epoch: 5| Step: 1
Training loss: 1.6117055416107178
Validation loss: 1.912207830336786

Epoch: 5| Step: 2
Training loss: 1.425416111946106
Validation loss: 1.9318733676787345

Epoch: 5| Step: 3
Training loss: 0.9949471354484558
Validation loss: 1.948202884325417

Epoch: 5| Step: 4
Training loss: 0.7174423933029175
Validation loss: 1.930003837872577

Epoch: 5| Step: 5
Training loss: 0.8587998151779175
Validation loss: 1.8969140565523537

Epoch: 5| Step: 6
Training loss: 1.130401372909546
Validation loss: 1.9146739923825828

Epoch: 5| Step: 7
Training loss: 1.7497904300689697
Validation loss: 1.8780059929816955

Epoch: 5| Step: 8
Training loss: 1.5216002464294434
Validation loss: 1.9019868527689288

Epoch: 5| Step: 9
Training loss: 1.1395809650421143
Validation loss: 1.88545653640583

Epoch: 5| Step: 10
Training loss: 1.2761108875274658
Validation loss: 1.8802598522555443

Epoch: 280| Step: 0
Training loss: 1.1431469917297363
Validation loss: 1.8645670080697665

Epoch: 5| Step: 1
Training loss: 0.8889525532722473
Validation loss: 1.8720388515021211

Epoch: 5| Step: 2
Training loss: 1.25214684009552
Validation loss: 1.8659204039522397

Epoch: 5| Step: 3
Training loss: 1.6531982421875
Validation loss: 1.8628634701492965

Epoch: 5| Step: 4
Training loss: 1.5365489721298218
Validation loss: 1.869580102223222

Epoch: 5| Step: 5
Training loss: 1.0929313898086548
Validation loss: 1.9048065382947204

Epoch: 5| Step: 6
Training loss: 1.1374168395996094
Validation loss: 1.877994604008172

Epoch: 5| Step: 7
Training loss: 1.2009074687957764
Validation loss: 1.8950248072224278

Epoch: 5| Step: 8
Training loss: 1.0562726259231567
Validation loss: 1.8929023768312188

Epoch: 5| Step: 9
Training loss: 1.397796392440796
Validation loss: 1.9437902178815616

Epoch: 5| Step: 10
Training loss: 1.198230504989624
Validation loss: 1.9577482361947336

Epoch: 281| Step: 0
Training loss: 1.3500149250030518
Validation loss: 1.9685153691999373

Epoch: 5| Step: 1
Training loss: 1.1485521793365479
Validation loss: 1.9212223778488815

Epoch: 5| Step: 2
Training loss: 1.504487156867981
Validation loss: 1.9075570824325725

Epoch: 5| Step: 3
Training loss: 1.3330790996551514
Validation loss: 1.8833220556218138

Epoch: 5| Step: 4
Training loss: 1.5749390125274658
Validation loss: 1.8821023792348883

Epoch: 5| Step: 5
Training loss: 0.8868731260299683
Validation loss: 1.8930712771672074

Epoch: 5| Step: 6
Training loss: 0.794028103351593
Validation loss: 1.9068190487482215

Epoch: 5| Step: 7
Training loss: 1.0787937641143799
Validation loss: 1.899984085431663

Epoch: 5| Step: 8
Training loss: 0.7112545371055603
Validation loss: 1.8700000163047545

Epoch: 5| Step: 9
Training loss: 1.1850740909576416
Validation loss: 1.9350373078418035

Epoch: 5| Step: 10
Training loss: 1.5891684293746948
Validation loss: 1.9327448465490853

Epoch: 282| Step: 0
Training loss: 1.6389917135238647
Validation loss: 1.9536931245557723

Epoch: 5| Step: 1
Training loss: 1.2485193014144897
Validation loss: 1.9455743169271817

Epoch: 5| Step: 2
Training loss: 0.7268146276473999
Validation loss: 1.9327744181438158

Epoch: 5| Step: 3
Training loss: 1.4875766038894653
Validation loss: 1.9130309717629546

Epoch: 5| Step: 4
Training loss: 1.0819345712661743
Validation loss: 1.8811388067019883

Epoch: 5| Step: 5
Training loss: 0.9983595609664917
Validation loss: 1.8730519971539896

Epoch: 5| Step: 6
Training loss: 1.1256139278411865
Validation loss: 1.872436003018451

Epoch: 5| Step: 7
Training loss: 0.5511716604232788
Validation loss: 1.8758705328869563

Epoch: 5| Step: 8
Training loss: 1.3902791738510132
Validation loss: 1.8728823687440606

Epoch: 5| Step: 9
Training loss: 1.5279829502105713
Validation loss: 1.868099207519203

Epoch: 5| Step: 10
Training loss: 1.2909047603607178
Validation loss: 1.869269303096238

Epoch: 283| Step: 0
Training loss: 0.8800845146179199
Validation loss: 1.8820143207426994

Epoch: 5| Step: 1
Training loss: 0.785391628742218
Validation loss: 1.9081950546592794

Epoch: 5| Step: 2
Training loss: 1.162269949913025
Validation loss: 1.9918462768677743

Epoch: 5| Step: 3
Training loss: 1.7663002014160156
Validation loss: 1.9620200818584812

Epoch: 5| Step: 4
Training loss: 1.2222607135772705
Validation loss: 1.9529200036038634

Epoch: 5| Step: 5
Training loss: 1.1113183498382568
Validation loss: 1.9032843676946496

Epoch: 5| Step: 6
Training loss: 1.174213171005249
Validation loss: 1.8810420190134356

Epoch: 5| Step: 7
Training loss: 1.2005804777145386
Validation loss: 1.9018213300294773

Epoch: 5| Step: 8
Training loss: 0.9961442947387695
Validation loss: 1.8818047482480285

Epoch: 5| Step: 9
Training loss: 1.319300889968872
Validation loss: 1.9031835191993303

Epoch: 5| Step: 10
Training loss: 1.6685914993286133
Validation loss: 1.9019925478966004

Epoch: 284| Step: 0
Training loss: 1.3472046852111816
Validation loss: 1.8853821062272595

Epoch: 5| Step: 1
Training loss: 1.2376347780227661
Validation loss: 1.8546002487982474

Epoch: 5| Step: 2
Training loss: 1.0605669021606445
Validation loss: 1.8426451375407558

Epoch: 5| Step: 3
Training loss: 1.1044431924819946
Validation loss: 1.8160063771791355

Epoch: 5| Step: 4
Training loss: 1.0735347270965576
Validation loss: 1.8321590372311172

Epoch: 5| Step: 5
Training loss: 0.9815133810043335
Validation loss: 1.8818477481924079

Epoch: 5| Step: 6
Training loss: 0.9037827253341675
Validation loss: 1.8901752887233612

Epoch: 5| Step: 7
Training loss: 1.4317376613616943
Validation loss: 1.8515945275624592

Epoch: 5| Step: 8
Training loss: 1.5403958559036255
Validation loss: 1.838010872564008

Epoch: 5| Step: 9
Training loss: 1.2474853992462158
Validation loss: 1.85732525907537

Epoch: 5| Step: 10
Training loss: 1.3458009958267212
Validation loss: 1.8974917806604856

Epoch: 285| Step: 0
Training loss: 0.9560900926589966
Validation loss: 1.903939188167613

Epoch: 5| Step: 1
Training loss: 1.3302490711212158
Validation loss: 1.9126992751193304

Epoch: 5| Step: 2
Training loss: 1.095707654953003
Validation loss: 1.913930678880343

Epoch: 5| Step: 3
Training loss: 1.1168975830078125
Validation loss: 1.9188723512875137

Epoch: 5| Step: 4
Training loss: 0.8330726623535156
Validation loss: 1.8888331395323559

Epoch: 5| Step: 5
Training loss: 1.3060086965560913
Validation loss: 1.930435239627797

Epoch: 5| Step: 6
Training loss: 1.5323054790496826
Validation loss: 1.926706490978118

Epoch: 5| Step: 7
Training loss: 1.2386807203292847
Validation loss: 1.9149826386923432

Epoch: 5| Step: 8
Training loss: 0.7492774724960327
Validation loss: 1.908419970543154

Epoch: 5| Step: 9
Training loss: 1.4676828384399414
Validation loss: 1.8778071723958498

Epoch: 5| Step: 10
Training loss: 0.8437578082084656
Validation loss: 1.8655291218911447

Epoch: 286| Step: 0
Training loss: 1.6002699136734009
Validation loss: 1.87175404384572

Epoch: 5| Step: 1
Training loss: 0.7575556635856628
Validation loss: 1.899187013667117

Epoch: 5| Step: 2
Training loss: 0.8145268559455872
Validation loss: 1.8902502867483324

Epoch: 5| Step: 3
Training loss: 1.4933902025222778
Validation loss: 1.8684989906126452

Epoch: 5| Step: 4
Training loss: 1.3326504230499268
Validation loss: 1.8570487319782216

Epoch: 5| Step: 5
Training loss: 1.465234398841858
Validation loss: 1.8416855642872472

Epoch: 5| Step: 6
Training loss: 0.6740524768829346
Validation loss: 1.8362741470336914

Epoch: 5| Step: 7
Training loss: 1.161395788192749
Validation loss: 1.8706136480454476

Epoch: 5| Step: 8
Training loss: 1.2488906383514404
Validation loss: 1.859720810767143

Epoch: 5| Step: 9
Training loss: 1.0106933116912842
Validation loss: 1.8998041742591447

Epoch: 5| Step: 10
Training loss: 0.8867754936218262
Validation loss: 1.8991976713621488

Epoch: 287| Step: 0
Training loss: 1.0282539129257202
Validation loss: 1.9358387954773442

Epoch: 5| Step: 1
Training loss: 1.2695796489715576
Validation loss: 1.9142123101859965

Epoch: 5| Step: 2
Training loss: 1.3649357557296753
Validation loss: 1.9001812627238612

Epoch: 5| Step: 3
Training loss: 1.1001628637313843
Validation loss: 1.890365469840265

Epoch: 5| Step: 4
Training loss: 1.50387704372406
Validation loss: 1.8943787659368208

Epoch: 5| Step: 5
Training loss: 1.0011852979660034
Validation loss: 1.8869878604847898

Epoch: 5| Step: 6
Training loss: 1.088023066520691
Validation loss: 1.8671150233155938

Epoch: 5| Step: 7
Training loss: 0.8543335199356079
Validation loss: 1.8467123944272277

Epoch: 5| Step: 8
Training loss: 0.6627790927886963
Validation loss: 1.8354046844667005

Epoch: 5| Step: 9
Training loss: 1.8151025772094727
Validation loss: 1.843958576520284

Epoch: 5| Step: 10
Training loss: 0.34819063544273376
Validation loss: 1.8558018502368723

Epoch: 288| Step: 0
Training loss: 0.9842950701713562
Validation loss: 1.8534393156728437

Epoch: 5| Step: 1
Training loss: 0.7998758554458618
Validation loss: 1.877770762289724

Epoch: 5| Step: 2
Training loss: 1.4152538776397705
Validation loss: 1.8663891797424645

Epoch: 5| Step: 3
Training loss: 1.202263593673706
Validation loss: 1.8741861210074475

Epoch: 5| Step: 4
Training loss: 1.2194852828979492
Validation loss: 1.8536045455163526

Epoch: 5| Step: 5
Training loss: 0.7840873599052429
Validation loss: 1.875409867173882

Epoch: 5| Step: 6
Training loss: 1.042769193649292
Validation loss: 1.8735511392675421

Epoch: 5| Step: 7
Training loss: 1.3016390800476074
Validation loss: 1.8834321691143898

Epoch: 5| Step: 8
Training loss: 1.110442876815796
Validation loss: 1.8729496976380706

Epoch: 5| Step: 9
Training loss: 1.2273590564727783
Validation loss: 1.9013274728610952

Epoch: 5| Step: 10
Training loss: 0.8973823189735413
Validation loss: 1.8980172180360364

Epoch: 289| Step: 0
Training loss: 1.3524523973464966
Validation loss: 1.9087825744382796

Epoch: 5| Step: 1
Training loss: 0.9068535566329956
Validation loss: 1.9015964000455794

Epoch: 5| Step: 2
Training loss: 0.8159662485122681
Validation loss: 1.8864598338321974

Epoch: 5| Step: 3
Training loss: 1.2133023738861084
Validation loss: 1.8707981699256486

Epoch: 5| Step: 4
Training loss: 0.829507052898407
Validation loss: 1.8725758009059454

Epoch: 5| Step: 5
Training loss: 1.1347236633300781
Validation loss: 1.8871942374014086

Epoch: 5| Step: 6
Training loss: 1.3878748416900635
Validation loss: 1.881008671176049

Epoch: 5| Step: 7
Training loss: 0.8274692296981812
Validation loss: 1.886886340315624

Epoch: 5| Step: 8
Training loss: 0.9238132238388062
Validation loss: 1.885967819921432

Epoch: 5| Step: 9
Training loss: 1.0296273231506348
Validation loss: 1.8857697056185814

Epoch: 5| Step: 10
Training loss: 1.3126437664031982
Validation loss: 1.878000533708962

Epoch: 290| Step: 0
Training loss: 0.750603973865509
Validation loss: 1.8630854557919245

Epoch: 5| Step: 1
Training loss: 0.9588692784309387
Validation loss: 1.8794645724758026

Epoch: 5| Step: 2
Training loss: 0.9254943132400513
Validation loss: 1.8619358026853172

Epoch: 5| Step: 3
Training loss: 1.0578594207763672
Validation loss: 1.8578749702822777

Epoch: 5| Step: 4
Training loss: 0.9184600114822388
Validation loss: 1.8387793815264137

Epoch: 5| Step: 5
Training loss: 1.1702854633331299
Validation loss: 1.8592313079423801

Epoch: 5| Step: 6
Training loss: 1.25442373752594
Validation loss: 1.879868625312723

Epoch: 5| Step: 7
Training loss: 1.4028581380844116
Validation loss: 1.8476497165618404

Epoch: 5| Step: 8
Training loss: 0.9564110040664673
Validation loss: 1.8861512291815974

Epoch: 5| Step: 9
Training loss: 1.3348853588104248
Validation loss: 1.9032341395654986

Epoch: 5| Step: 10
Training loss: 0.9322068691253662
Validation loss: 1.8885088300192228

Epoch: 291| Step: 0
Training loss: 1.1235915422439575
Validation loss: 1.9190333607376262

Epoch: 5| Step: 1
Training loss: 0.9589982032775879
Validation loss: 1.9316527010292135

Epoch: 5| Step: 2
Training loss: 1.090105414390564
Validation loss: 1.903508601650115

Epoch: 5| Step: 3
Training loss: 0.8499313592910767
Validation loss: 1.897131666060417

Epoch: 5| Step: 4
Training loss: 1.3154728412628174
Validation loss: 1.894279408198531

Epoch: 5| Step: 5
Training loss: 0.6726830005645752
Validation loss: 1.8752721214807162

Epoch: 5| Step: 6
Training loss: 0.8122377395629883
Validation loss: 1.8758109493922162

Epoch: 5| Step: 7
Training loss: 1.150788426399231
Validation loss: 1.8620117454118625

Epoch: 5| Step: 8
Training loss: 1.1679189205169678
Validation loss: 1.8690332802393104

Epoch: 5| Step: 9
Training loss: 1.6196815967559814
Validation loss: 1.8617361630162885

Epoch: 5| Step: 10
Training loss: 1.157344937324524
Validation loss: 1.8713274899349417

Epoch: 292| Step: 0
Training loss: 0.7693454027175903
Validation loss: 1.868455663804085

Epoch: 5| Step: 1
Training loss: 0.8688864707946777
Validation loss: 1.8579544431419783

Epoch: 5| Step: 2
Training loss: 1.115545630455017
Validation loss: 1.8829117526290238

Epoch: 5| Step: 3
Training loss: 1.185359001159668
Validation loss: 1.8898640422410862

Epoch: 5| Step: 4
Training loss: 1.5811574459075928
Validation loss: 1.8975850177067581

Epoch: 5| Step: 5
Training loss: 0.5352247357368469
Validation loss: 1.8856078668307232

Epoch: 5| Step: 6
Training loss: 1.1644304990768433
Validation loss: 1.8890658065836916

Epoch: 5| Step: 7
Training loss: 1.3385828733444214
Validation loss: 1.8900372610297254

Epoch: 5| Step: 8
Training loss: 1.0864336490631104
Validation loss: 1.8643723251999065

Epoch: 5| Step: 9
Training loss: 1.189719796180725
Validation loss: 1.8330649150315153

Epoch: 5| Step: 10
Training loss: 0.6626396775245667
Validation loss: 1.840631825949556

Epoch: 293| Step: 0
Training loss: 1.0697886943817139
Validation loss: 1.8382003935434486

Epoch: 5| Step: 1
Training loss: 1.4072459936141968
Validation loss: 1.8467230719904746

Epoch: 5| Step: 2
Training loss: 0.6428841352462769
Validation loss: 1.8382357128204838

Epoch: 5| Step: 3
Training loss: 0.9593621492385864
Validation loss: 1.8488580232025476

Epoch: 5| Step: 4
Training loss: 1.3731963634490967
Validation loss: 1.8309117055708362

Epoch: 5| Step: 5
Training loss: 0.6787683963775635
Validation loss: 1.8469580655456872

Epoch: 5| Step: 6
Training loss: 1.1027292013168335
Validation loss: 1.829748212650258

Epoch: 5| Step: 7
Training loss: 1.034982442855835
Validation loss: 1.8460663646780036

Epoch: 5| Step: 8
Training loss: 1.0908223390579224
Validation loss: 1.860231996864401

Epoch: 5| Step: 9
Training loss: 1.1456680297851562
Validation loss: 1.8612732733449628

Epoch: 5| Step: 10
Training loss: 0.9304006099700928
Validation loss: 1.8412659181061612

Epoch: 294| Step: 0
Training loss: 0.9266312718391418
Validation loss: 1.8476971041771673

Epoch: 5| Step: 1
Training loss: 1.0930979251861572
Validation loss: 1.8426552241848362

Epoch: 5| Step: 2
Training loss: 0.9782922863960266
Validation loss: 1.8340057237173921

Epoch: 5| Step: 3
Training loss: 1.157081961631775
Validation loss: 1.826676821195951

Epoch: 5| Step: 4
Training loss: 1.2478537559509277
Validation loss: 1.8407043192976265

Epoch: 5| Step: 5
Training loss: 0.9117829203605652
Validation loss: 1.8314821181758758

Epoch: 5| Step: 6
Training loss: 1.0045878887176514
Validation loss: 1.828763731064335

Epoch: 5| Step: 7
Training loss: 1.118496298789978
Validation loss: 1.8523782594229585

Epoch: 5| Step: 8
Training loss: 0.6589199900627136
Validation loss: 1.8509375485040809

Epoch: 5| Step: 9
Training loss: 0.8831574320793152
Validation loss: 1.8737915228771906

Epoch: 5| Step: 10
Training loss: 1.276506781578064
Validation loss: 1.8610395231554586

Epoch: 295| Step: 0
Training loss: 0.9846542477607727
Validation loss: 1.8709491286226498

Epoch: 5| Step: 1
Training loss: 0.978583812713623
Validation loss: 1.8935606889827277

Epoch: 5| Step: 2
Training loss: 0.9474694132804871
Validation loss: 1.8835445040015764

Epoch: 5| Step: 3
Training loss: 1.2063310146331787
Validation loss: 1.8931499937529206

Epoch: 5| Step: 4
Training loss: 1.0013008117675781
Validation loss: 1.8768686607319822

Epoch: 5| Step: 5
Training loss: 1.0317137241363525
Validation loss: 1.88362035828252

Epoch: 5| Step: 6
Training loss: 1.2253111600875854
Validation loss: 1.8387258732190697

Epoch: 5| Step: 7
Training loss: 0.8096052408218384
Validation loss: 1.8435761287648191

Epoch: 5| Step: 8
Training loss: 0.8549121618270874
Validation loss: 1.8390703855022308

Epoch: 5| Step: 9
Training loss: 1.0765966176986694
Validation loss: 1.8472882188776487

Epoch: 5| Step: 10
Training loss: 1.2529667615890503
Validation loss: 1.8659226304741316

Epoch: 296| Step: 0
Training loss: 0.945466160774231
Validation loss: 1.8648782660884242

Epoch: 5| Step: 1
Training loss: 0.8128793835639954
Validation loss: 1.8724325446672336

Epoch: 5| Step: 2
Training loss: 0.6528361439704895
Validation loss: 1.857432488472231

Epoch: 5| Step: 3
Training loss: 1.5726038217544556
Validation loss: 1.8749449188991258

Epoch: 5| Step: 4
Training loss: 0.7745482325553894
Validation loss: 1.888829351753317

Epoch: 5| Step: 5
Training loss: 1.4414652585983276
Validation loss: 1.912485130371586

Epoch: 5| Step: 6
Training loss: 1.232738733291626
Validation loss: 1.8570195821023756

Epoch: 5| Step: 7
Training loss: 0.8307806849479675
Validation loss: 1.8438805559630036

Epoch: 5| Step: 8
Training loss: 0.9113892316818237
Validation loss: 1.813148974090494

Epoch: 5| Step: 9
Training loss: 0.7491771578788757
Validation loss: 1.8146317235885128

Epoch: 5| Step: 10
Training loss: 1.3877794742584229
Validation loss: 1.8033801637670046

Epoch: 297| Step: 0
Training loss: 0.8722907900810242
Validation loss: 1.8035681145165556

Epoch: 5| Step: 1
Training loss: 0.9710267782211304
Validation loss: 1.8065396175589612

Epoch: 5| Step: 2
Training loss: 0.8378702402114868
Validation loss: 1.8150706727017638

Epoch: 5| Step: 3
Training loss: 1.065278172492981
Validation loss: 1.8043190407496628

Epoch: 5| Step: 4
Training loss: 1.2144978046417236
Validation loss: 1.8135386795125983

Epoch: 5| Step: 5
Training loss: 1.3194684982299805
Validation loss: 1.835728113369275

Epoch: 5| Step: 6
Training loss: 0.7592328190803528
Validation loss: 1.8476066281718593

Epoch: 5| Step: 7
Training loss: 1.0124962329864502
Validation loss: 1.8818632428364088

Epoch: 5| Step: 8
Training loss: 0.9412240982055664
Validation loss: 1.881424456514338

Epoch: 5| Step: 9
Training loss: 0.8439263105392456
Validation loss: 1.8964460870271087

Epoch: 5| Step: 10
Training loss: 1.381373643875122
Validation loss: 1.8798838789745043

Epoch: 298| Step: 0
Training loss: 0.8623253107070923
Validation loss: 1.8938020160121303

Epoch: 5| Step: 1
Training loss: 1.060133695602417
Validation loss: 1.8696311763537827

Epoch: 5| Step: 2
Training loss: 1.5763444900512695
Validation loss: 1.8139023011730564

Epoch: 5| Step: 3
Training loss: 0.8433386087417603
Validation loss: 1.8250896417966453

Epoch: 5| Step: 4
Training loss: 0.6368632316589355
Validation loss: 1.830097371532071

Epoch: 5| Step: 5
Training loss: 0.8171356916427612
Validation loss: 1.83879764105684

Epoch: 5| Step: 6
Training loss: 0.5122309923171997
Validation loss: 1.8307882073105022

Epoch: 5| Step: 7
Training loss: 1.386983871459961
Validation loss: 1.8302869053297146

Epoch: 5| Step: 8
Training loss: 0.7666589617729187
Validation loss: 1.824022836582635

Epoch: 5| Step: 9
Training loss: 1.1896162033081055
Validation loss: 1.8128395477930705

Epoch: 5| Step: 10
Training loss: 1.3581852912902832
Validation loss: 1.8127809673227289

Epoch: 299| Step: 0
Training loss: 1.1661252975463867
Validation loss: 1.828278249309909

Epoch: 5| Step: 1
Training loss: 0.9515175819396973
Validation loss: 1.8260998777163926

Epoch: 5| Step: 2
Training loss: 1.2225085496902466
Validation loss: 1.8467743576213878

Epoch: 5| Step: 3
Training loss: 0.9901730418205261
Validation loss: 1.854098089279667

Epoch: 5| Step: 4
Training loss: 1.0733492374420166
Validation loss: 1.85476912477965

Epoch: 5| Step: 5
Training loss: 0.8359939455986023
Validation loss: 1.8669568274610786

Epoch: 5| Step: 6
Training loss: 0.8453890085220337
Validation loss: 1.8597676600179365

Epoch: 5| Step: 7
Training loss: 0.5770977735519409
Validation loss: 1.8674243701401578

Epoch: 5| Step: 8
Training loss: 0.8952190279960632
Validation loss: 1.8532440021473875

Epoch: 5| Step: 9
Training loss: 1.0545098781585693
Validation loss: 1.8289758441268757

Epoch: 5| Step: 10
Training loss: 1.1387568712234497
Validation loss: 1.8434623185024466

Epoch: 300| Step: 0
Training loss: 0.7077821493148804
Validation loss: 1.829093622904952

Epoch: 5| Step: 1
Training loss: 0.5418620705604553
Validation loss: 1.828173888626919

Epoch: 5| Step: 2
Training loss: 1.0732605457305908
Validation loss: 1.8409565764088784

Epoch: 5| Step: 3
Training loss: 1.0118038654327393
Validation loss: 1.8408669758868474

Epoch: 5| Step: 4
Training loss: 1.2240902185440063
Validation loss: 1.8594366068481116

Epoch: 5| Step: 5
Training loss: 1.175965428352356
Validation loss: 1.8525666139459098

Epoch: 5| Step: 6
Training loss: 1.0541508197784424
Validation loss: 1.850685219610891

Epoch: 5| Step: 7
Training loss: 0.8972709774971008
Validation loss: 1.8484640608551681

Epoch: 5| Step: 8
Training loss: 1.0647424459457397
Validation loss: 1.82420563954179

Epoch: 5| Step: 9
Training loss: 0.6704815626144409
Validation loss: 1.8187536437024352

Epoch: 5| Step: 10
Training loss: 0.9125924110412598
Validation loss: 1.8008787119260399

Epoch: 301| Step: 0
Training loss: 0.9785205125808716
Validation loss: 1.810377049189742

Epoch: 5| Step: 1
Training loss: 0.7189069986343384
Validation loss: 1.8125380521179528

Epoch: 5| Step: 2
Training loss: 1.243612289428711
Validation loss: 1.7992244548695062

Epoch: 5| Step: 3
Training loss: 0.8882225751876831
Validation loss: 1.7972600921507804

Epoch: 5| Step: 4
Training loss: 0.9962474703788757
Validation loss: 1.808478020852612

Epoch: 5| Step: 5
Training loss: 0.9971601366996765
Validation loss: 1.8387455837700957

Epoch: 5| Step: 6
Training loss: 0.7601140737533569
Validation loss: 1.833771082662767

Epoch: 5| Step: 7
Training loss: 0.811240553855896
Validation loss: 1.8421657700692453

Epoch: 5| Step: 8
Training loss: 0.9148346185684204
Validation loss: 1.8750635757241199

Epoch: 5| Step: 9
Training loss: 0.7894306182861328
Validation loss: 1.8887231144853818

Epoch: 5| Step: 10
Training loss: 1.2015804052352905
Validation loss: 1.8927653271664855

Epoch: 302| Step: 0
Training loss: 0.8783084154129028
Validation loss: 1.8705908367710729

Epoch: 5| Step: 1
Training loss: 1.198925256729126
Validation loss: 1.8821842952441143

Epoch: 5| Step: 2
Training loss: 1.3152005672454834
Validation loss: 1.8565205220253236

Epoch: 5| Step: 3
Training loss: 0.8194114565849304
Validation loss: 1.8564504769540602

Epoch: 5| Step: 4
Training loss: 0.8014041185379028
Validation loss: 1.843672119161134

Epoch: 5| Step: 5
Training loss: 1.0838544368743896
Validation loss: 1.8350950223143383

Epoch: 5| Step: 6
Training loss: 0.9154852628707886
Validation loss: 1.8599530163631643

Epoch: 5| Step: 7
Training loss: 0.8446351289749146
Validation loss: 1.8352411716215071

Epoch: 5| Step: 8
Training loss: 0.6737667322158813
Validation loss: 1.8383181556578605

Epoch: 5| Step: 9
Training loss: 1.056178092956543
Validation loss: 1.8453359937155118

Epoch: 5| Step: 10
Training loss: 0.7098358869552612
Validation loss: 1.8612488918406989

Epoch: 303| Step: 0
Training loss: 0.7774354219436646
Validation loss: 1.8391828818987774

Epoch: 5| Step: 1
Training loss: 0.7280734777450562
Validation loss: 1.8507038790692565

Epoch: 5| Step: 2
Training loss: 1.0955028533935547
Validation loss: 1.847629229227702

Epoch: 5| Step: 3
Training loss: 0.962943434715271
Validation loss: 1.8499210957557923

Epoch: 5| Step: 4
Training loss: 0.7067216038703918
Validation loss: 1.838815076376802

Epoch: 5| Step: 5
Training loss: 0.76031893491745
Validation loss: 1.8351799262467252

Epoch: 5| Step: 6
Training loss: 0.7908344268798828
Validation loss: 1.834720253944397

Epoch: 5| Step: 7
Training loss: 1.579772710800171
Validation loss: 1.856903976009738

Epoch: 5| Step: 8
Training loss: 1.2081754207611084
Validation loss: 1.860338322577938

Epoch: 5| Step: 9
Training loss: 0.7442232370376587
Validation loss: 1.8688709146233016

Epoch: 5| Step: 10
Training loss: 0.9280158877372742
Validation loss: 1.8340230680281115

Epoch: 304| Step: 0
Training loss: 1.5524301528930664
Validation loss: 1.8478575739809262

Epoch: 5| Step: 1
Training loss: 0.6894623041152954
Validation loss: 1.8387956952535978

Epoch: 5| Step: 2
Training loss: 0.9764629602432251
Validation loss: 1.8377991222566175

Epoch: 5| Step: 3
Training loss: 0.92078697681427
Validation loss: 1.8417564425417172

Epoch: 5| Step: 4
Training loss: 0.5759008526802063
Validation loss: 1.8685380092231176

Epoch: 5| Step: 5
Training loss: 0.6152213215827942
Validation loss: 1.858256693809263

Epoch: 5| Step: 6
Training loss: 1.0611228942871094
Validation loss: 1.881002929902846

Epoch: 5| Step: 7
Training loss: 1.118401288986206
Validation loss: 1.8878882956761185

Epoch: 5| Step: 8
Training loss: 0.8726905584335327
Validation loss: 1.8643212510693459

Epoch: 5| Step: 9
Training loss: 1.0050874948501587
Validation loss: 1.8600462931458668

Epoch: 5| Step: 10
Training loss: 0.6384179592132568
Validation loss: 1.8455589381597375

Epoch: 305| Step: 0
Training loss: 1.035470724105835
Validation loss: 1.8354301606455157

Epoch: 5| Step: 1
Training loss: 0.9464854001998901
Validation loss: 1.8449699519782938

Epoch: 5| Step: 2
Training loss: 1.329909086227417
Validation loss: 1.8383091559974096

Epoch: 5| Step: 3
Training loss: 0.9083690643310547
Validation loss: 1.83592898871309

Epoch: 5| Step: 4
Training loss: 0.836661696434021
Validation loss: 1.862647997435703

Epoch: 5| Step: 5
Training loss: 0.717691957950592
Validation loss: 1.8345881085241995

Epoch: 5| Step: 6
Training loss: 0.9005037546157837
Validation loss: 1.821407264278781

Epoch: 5| Step: 7
Training loss: 0.7983459234237671
Validation loss: 1.7930913958498227

Epoch: 5| Step: 8
Training loss: 0.7881909012794495
Validation loss: 1.8140455497208463

Epoch: 5| Step: 9
Training loss: 0.8274780511856079
Validation loss: 1.8065631838255032

Epoch: 5| Step: 10
Training loss: 0.9019676446914673
Validation loss: 1.7871041169730566

Epoch: 306| Step: 0
Training loss: 0.7815755009651184
Validation loss: 1.8082085168489845

Epoch: 5| Step: 1
Training loss: 1.179403305053711
Validation loss: 1.8214911748004217

Epoch: 5| Step: 2
Training loss: 0.8839849233627319
Validation loss: 1.8147002279117543

Epoch: 5| Step: 3
Training loss: 0.8952769041061401
Validation loss: 1.8287297333440473

Epoch: 5| Step: 4
Training loss: 0.7389132976531982
Validation loss: 1.8106178352909703

Epoch: 5| Step: 5
Training loss: 0.678242564201355
Validation loss: 1.8206911484400432

Epoch: 5| Step: 6
Training loss: 0.7521287202835083
Validation loss: 1.827208439509074

Epoch: 5| Step: 7
Training loss: 1.0640697479248047
Validation loss: 1.8177483709909583

Epoch: 5| Step: 8
Training loss: 1.0934211015701294
Validation loss: 1.8038063664590158

Epoch: 5| Step: 9
Training loss: 1.2414144277572632
Validation loss: 1.803139122583533

Epoch: 5| Step: 10
Training loss: 0.5233931541442871
Validation loss: 1.8052389314097743

Epoch: 307| Step: 0
Training loss: 0.7752998471260071
Validation loss: 1.8037674362941454

Epoch: 5| Step: 1
Training loss: 1.1591295003890991
Validation loss: 1.8450484968000842

Epoch: 5| Step: 2
Training loss: 0.6717859506607056
Validation loss: 1.860702130102342

Epoch: 5| Step: 3
Training loss: 1.1915010213851929
Validation loss: 1.8575524360902849

Epoch: 5| Step: 4
Training loss: 0.9841558337211609
Validation loss: 1.821319608278172

Epoch: 5| Step: 5
Training loss: 0.5222431421279907
Validation loss: 1.8228349531850507

Epoch: 5| Step: 6
Training loss: 0.6972940564155579
Validation loss: 1.823011544442946

Epoch: 5| Step: 7
Training loss: 1.053236961364746
Validation loss: 1.8185735838387602

Epoch: 5| Step: 8
Training loss: 0.683306097984314
Validation loss: 1.814976574272238

Epoch: 5| Step: 9
Training loss: 0.899675726890564
Validation loss: 1.821625606988066

Epoch: 5| Step: 10
Training loss: 0.9711849093437195
Validation loss: 1.831600437882126

Epoch: 308| Step: 0
Training loss: 1.0499441623687744
Validation loss: 1.847379938248665

Epoch: 5| Step: 1
Training loss: 1.1593701839447021
Validation loss: 1.8589160519261514

Epoch: 5| Step: 2
Training loss: 0.5160170793533325
Validation loss: 1.8593498609399284

Epoch: 5| Step: 3
Training loss: 0.787744402885437
Validation loss: 1.8678328119298464

Epoch: 5| Step: 4
Training loss: 1.1137465238571167
Validation loss: 1.8560640440192273

Epoch: 5| Step: 5
Training loss: 1.239008903503418
Validation loss: 1.8595302976587766

Epoch: 5| Step: 6
Training loss: 0.6893883943557739
Validation loss: 1.8483607461375575

Epoch: 5| Step: 7
Training loss: 0.8288976550102234
Validation loss: 1.8445283482151646

Epoch: 5| Step: 8
Training loss: 0.8328679800033569
Validation loss: 1.8443662376813992

Epoch: 5| Step: 9
Training loss: 0.7143486738204956
Validation loss: 1.8206313963859313

Epoch: 5| Step: 10
Training loss: 0.8899629712104797
Validation loss: 1.7960229304529005

Epoch: 309| Step: 0
Training loss: 0.710379958152771
Validation loss: 1.8210792823504376

Epoch: 5| Step: 1
Training loss: 0.8678407669067383
Validation loss: 1.819032976704259

Epoch: 5| Step: 2
Training loss: 0.8906875848770142
Validation loss: 1.808882236480713

Epoch: 5| Step: 3
Training loss: 0.8245197534561157
Validation loss: 1.824783286740703

Epoch: 5| Step: 4
Training loss: 0.6747218370437622
Validation loss: 1.834622101117206

Epoch: 5| Step: 5
Training loss: 1.0088998079299927
Validation loss: 1.8159361846985356

Epoch: 5| Step: 6
Training loss: 0.34894734621047974
Validation loss: 1.792590803997491

Epoch: 5| Step: 7
Training loss: 1.099250316619873
Validation loss: 1.8051894839091966

Epoch: 5| Step: 8
Training loss: 0.8972324132919312
Validation loss: 1.8136484546046103

Epoch: 5| Step: 9
Training loss: 0.8851420283317566
Validation loss: 1.798643788983745

Epoch: 5| Step: 10
Training loss: 1.4095656871795654
Validation loss: 1.8098689125430198

Epoch: 310| Step: 0
Training loss: 0.5828368067741394
Validation loss: 1.7834329169283631

Epoch: 5| Step: 1
Training loss: 0.6156998872756958
Validation loss: 1.8096725325430594

Epoch: 5| Step: 2
Training loss: 0.7431961297988892
Validation loss: 1.7927663992809992

Epoch: 5| Step: 3
Training loss: 0.9623258709907532
Validation loss: 1.7716267557554348

Epoch: 5| Step: 4
Training loss: 1.0060083866119385
Validation loss: 1.802684764708242

Epoch: 5| Step: 5
Training loss: 1.3597297668457031
Validation loss: 1.7950320500199513

Epoch: 5| Step: 6
Training loss: 0.6433483362197876
Validation loss: 1.8131496829371299

Epoch: 5| Step: 7
Training loss: 0.866108238697052
Validation loss: 1.8323855348812637

Epoch: 5| Step: 8
Training loss: 0.9300007820129395
Validation loss: 1.841394983312135

Epoch: 5| Step: 9
Training loss: 0.7297391891479492
Validation loss: 1.8485814294507426

Epoch: 5| Step: 10
Training loss: 1.1040687561035156
Validation loss: 1.8763954895798878

Epoch: 311| Step: 0
Training loss: 0.7899194955825806
Validation loss: 1.8850058394093667

Epoch: 5| Step: 1
Training loss: 1.3586187362670898
Validation loss: 1.8701537014335714

Epoch: 5| Step: 2
Training loss: 1.1511542797088623
Validation loss: 1.884785993124849

Epoch: 5| Step: 3
Training loss: 0.9729493260383606
Validation loss: 1.8603301714825373

Epoch: 5| Step: 4
Training loss: 0.6257644891738892
Validation loss: 1.8634706594610726

Epoch: 5| Step: 5
Training loss: 0.7785910964012146
Validation loss: 1.8245254665292718

Epoch: 5| Step: 6
Training loss: 1.041422963142395
Validation loss: 1.8431653079166208

Epoch: 5| Step: 7
Training loss: 0.7958022356033325
Validation loss: 1.834655418190905

Epoch: 5| Step: 8
Training loss: 0.7174395322799683
Validation loss: 1.8338529704719462

Epoch: 5| Step: 9
Training loss: 0.5215166211128235
Validation loss: 1.8472389944138066

Epoch: 5| Step: 10
Training loss: 1.05337655544281
Validation loss: 1.8421260624803522

Epoch: 312| Step: 0
Training loss: 0.8620458841323853
Validation loss: 1.8527585319293443

Epoch: 5| Step: 1
Training loss: 0.667272686958313
Validation loss: 1.9002512014040382

Epoch: 5| Step: 2
Training loss: 0.9563491940498352
Validation loss: 1.9456034578302854

Epoch: 5| Step: 3
Training loss: 1.0800769329071045
Validation loss: 1.9354002527011338

Epoch: 5| Step: 4
Training loss: 0.8549708127975464
Validation loss: 1.925042135741121

Epoch: 5| Step: 5
Training loss: 0.9148563146591187
Validation loss: 1.8841369690433625

Epoch: 5| Step: 6
Training loss: 0.7131600379943848
Validation loss: 1.8338631058251986

Epoch: 5| Step: 7
Training loss: 0.5738751292228699
Validation loss: 1.8173537895243654

Epoch: 5| Step: 8
Training loss: 1.0641825199127197
Validation loss: 1.8026254689821632

Epoch: 5| Step: 9
Training loss: 1.3922039270401
Validation loss: 1.7912185345926592

Epoch: 5| Step: 10
Training loss: 0.7810120582580566
Validation loss: 1.7923186902076966

Epoch: 313| Step: 0
Training loss: 0.8631397485733032
Validation loss: 1.7895771995667489

Epoch: 5| Step: 1
Training loss: 0.7298206090927124
Validation loss: 1.785661207732334

Epoch: 5| Step: 2
Training loss: 0.6985856294631958
Validation loss: 1.7719011909218245

Epoch: 5| Step: 3
Training loss: 0.7602337598800659
Validation loss: 1.7888342334378151

Epoch: 5| Step: 4
Training loss: 1.0170953273773193
Validation loss: 1.815059418319374

Epoch: 5| Step: 5
Training loss: 0.7592129707336426
Validation loss: 1.8447681165510608

Epoch: 5| Step: 6
Training loss: 1.2129452228546143
Validation loss: 1.8571243183587187

Epoch: 5| Step: 7
Training loss: 0.8487914204597473
Validation loss: 1.8501093079966884

Epoch: 5| Step: 8
Training loss: 0.8141722679138184
Validation loss: 1.8391776507900608

Epoch: 5| Step: 9
Training loss: 0.9689086675643921
Validation loss: 1.8043337842469573

Epoch: 5| Step: 10
Training loss: 0.8707083463668823
Validation loss: 1.7928473628977293

Epoch: 314| Step: 0
Training loss: 0.773320198059082
Validation loss: 1.7861675485487907

Epoch: 5| Step: 1
Training loss: 0.9831680059432983
Validation loss: 1.8174712696383077

Epoch: 5| Step: 2
Training loss: 0.6315651535987854
Validation loss: 1.8124630207656531

Epoch: 5| Step: 3
Training loss: 0.5979059934616089
Validation loss: 1.8252607468635804

Epoch: 5| Step: 4
Training loss: 1.2336078882217407
Validation loss: 1.8206860955043505

Epoch: 5| Step: 5
Training loss: 0.5815072059631348
Validation loss: 1.8347993384125412

Epoch: 5| Step: 6
Training loss: 1.0089528560638428
Validation loss: 1.841220655748921

Epoch: 5| Step: 7
Training loss: 0.6852883100509644
Validation loss: 1.8386622833949264

Epoch: 5| Step: 8
Training loss: 0.9723876714706421
Validation loss: 1.8414030408346524

Epoch: 5| Step: 9
Training loss: 0.9320396184921265
Validation loss: 1.8250340415585427

Epoch: 5| Step: 10
Training loss: 0.9089351892471313
Validation loss: 1.8617135850332116

Epoch: 315| Step: 0
Training loss: 0.5568370819091797
Validation loss: 1.8579310435120777

Epoch: 5| Step: 1
Training loss: 0.9733866453170776
Validation loss: 1.8469146913097751

Epoch: 5| Step: 2
Training loss: 0.8680644035339355
Validation loss: 1.858609805824936

Epoch: 5| Step: 3
Training loss: 1.0285743474960327
Validation loss: 1.8456295703047065

Epoch: 5| Step: 4
Training loss: 1.108069896697998
Validation loss: 1.8470561863273702

Epoch: 5| Step: 5
Training loss: 0.6054670214653015
Validation loss: 1.8515801378475722

Epoch: 5| Step: 6
Training loss: 0.5509534478187561
Validation loss: 1.8521709506229689

Epoch: 5| Step: 7
Training loss: 0.7306913733482361
Validation loss: 1.831051206076017

Epoch: 5| Step: 8
Training loss: 0.7861400246620178
Validation loss: 1.8507447063281972

Epoch: 5| Step: 9
Training loss: 0.8838631510734558
Validation loss: 1.8154551752151982

Epoch: 5| Step: 10
Training loss: 1.0311899185180664
Validation loss: 1.8159387906392415

Epoch: 316| Step: 0
Training loss: 0.6086819171905518
Validation loss: 1.8065214785196448

Epoch: 5| Step: 1
Training loss: 0.9177290201187134
Validation loss: 1.8147976603559268

Epoch: 5| Step: 2
Training loss: 0.5605445504188538
Validation loss: 1.800900956635834

Epoch: 5| Step: 3
Training loss: 1.1191774606704712
Validation loss: 1.7818005520810363

Epoch: 5| Step: 4
Training loss: 1.1190202236175537
Validation loss: 1.8010556851663897

Epoch: 5| Step: 5
Training loss: 1.0538592338562012
Validation loss: 1.7854399014544744

Epoch: 5| Step: 6
Training loss: 0.7449607849121094
Validation loss: 1.7736999527100594

Epoch: 5| Step: 7
Training loss: 0.8231641054153442
Validation loss: 1.8000887337551321

Epoch: 5| Step: 8
Training loss: 0.7435464262962341
Validation loss: 1.784301391211889

Epoch: 5| Step: 9
Training loss: 0.46882882714271545
Validation loss: 1.798031787718496

Epoch: 5| Step: 10
Training loss: 0.8148860931396484
Validation loss: 1.8334885130646408

Epoch: 317| Step: 0
Training loss: 0.8557125329971313
Validation loss: 1.8295709087002663

Epoch: 5| Step: 1
Training loss: 0.9396050572395325
Validation loss: 1.8355683793303788

Epoch: 5| Step: 2
Training loss: 0.6041525602340698
Validation loss: 1.8528744687316239

Epoch: 5| Step: 3
Training loss: 0.8896498680114746
Validation loss: 1.8530061116782568

Epoch: 5| Step: 4
Training loss: 0.7791444063186646
Validation loss: 1.8553521325511317

Epoch: 5| Step: 5
Training loss: 1.1790235042572021
Validation loss: 1.8451917914934055

Epoch: 5| Step: 6
Training loss: 0.6705005168914795
Validation loss: 1.8308943971510856

Epoch: 5| Step: 7
Training loss: 0.7115650177001953
Validation loss: 1.841155598240514

Epoch: 5| Step: 8
Training loss: 0.7249924540519714
Validation loss: 1.8437637449592672

Epoch: 5| Step: 9
Training loss: 0.6879725456237793
Validation loss: 1.831023238038504

Epoch: 5| Step: 10
Training loss: 0.7503647804260254
Validation loss: 1.835792685067782

Epoch: 318| Step: 0
Training loss: 0.5753897428512573
Validation loss: 1.792823904304094

Epoch: 5| Step: 1
Training loss: 0.5599757432937622
Validation loss: 1.8263774456516388

Epoch: 5| Step: 2
Training loss: 0.7679683566093445
Validation loss: 1.8250607790485505

Epoch: 5| Step: 3
Training loss: 0.8592623472213745
Validation loss: 1.8361824584263626

Epoch: 5| Step: 4
Training loss: 0.6311606168746948
Validation loss: 1.822255132018879

Epoch: 5| Step: 5
Training loss: 0.6309890747070312
Validation loss: 1.8460946262523692

Epoch: 5| Step: 6
Training loss: 0.5631502866744995
Validation loss: 1.8210240000037736

Epoch: 5| Step: 7
Training loss: 0.9568051099777222
Validation loss: 1.8114250923997612

Epoch: 5| Step: 8
Training loss: 1.2977354526519775
Validation loss: 1.8286433732637795

Epoch: 5| Step: 9
Training loss: 1.098917007446289
Validation loss: 1.8067312996874574

Epoch: 5| Step: 10
Training loss: 0.85123211145401
Validation loss: 1.8005405202988656

Epoch: 319| Step: 0
Training loss: 0.7026669979095459
Validation loss: 1.8131278368734545

Epoch: 5| Step: 1
Training loss: 0.5058104395866394
Validation loss: 1.8047262494282057

Epoch: 5| Step: 2
Training loss: 0.9063337445259094
Validation loss: 1.8361905941399195

Epoch: 5| Step: 3
Training loss: 0.7191169261932373
Validation loss: 1.7972282594250095

Epoch: 5| Step: 4
Training loss: 0.6475892066955566
Validation loss: 1.7970707903626144

Epoch: 5| Step: 5
Training loss: 0.8236417770385742
Validation loss: 1.8085607444086382

Epoch: 5| Step: 6
Training loss: 0.7176848649978638
Validation loss: 1.8012070002094391

Epoch: 5| Step: 7
Training loss: 0.8588579297065735
Validation loss: 1.7913343047582975

Epoch: 5| Step: 8
Training loss: 0.8088533282279968
Validation loss: 1.8042791953650854

Epoch: 5| Step: 9
Training loss: 0.9465118646621704
Validation loss: 1.8014989027412989

Epoch: 5| Step: 10
Training loss: 0.8331713080406189
Validation loss: 1.819608328162983

Epoch: 320| Step: 0
Training loss: 0.7090660333633423
Validation loss: 1.8049720705196421

Epoch: 5| Step: 1
Training loss: 0.5698165893554688
Validation loss: 1.791933859548261

Epoch: 5| Step: 2
Training loss: 0.7878696322441101
Validation loss: 1.811854854706795

Epoch: 5| Step: 3
Training loss: 0.7005795836448669
Validation loss: 1.813060151633396

Epoch: 5| Step: 4
Training loss: 0.818656325340271
Validation loss: 1.7868118542496876

Epoch: 5| Step: 5
Training loss: 0.8581849336624146
Validation loss: 1.7875173694343978

Epoch: 5| Step: 6
Training loss: 0.5931638479232788
Validation loss: 1.7977595918922014

Epoch: 5| Step: 7
Training loss: 0.5906604528427124
Validation loss: 1.8056304172802997

Epoch: 5| Step: 8
Training loss: 0.8160865902900696
Validation loss: 1.8107468210240847

Epoch: 5| Step: 9
Training loss: 0.9535852670669556
Validation loss: 1.8181781986708283

Epoch: 5| Step: 10
Training loss: 1.1743186712265015
Validation loss: 1.8268915363537368

Epoch: 321| Step: 0
Training loss: 1.0092084407806396
Validation loss: 1.8152509107384631

Epoch: 5| Step: 1
Training loss: 1.0672564506530762
Validation loss: 1.7800500149367957

Epoch: 5| Step: 2
Training loss: 0.8520082235336304
Validation loss: 1.776349377888505

Epoch: 5| Step: 3
Training loss: 0.929766058921814
Validation loss: 1.7975230422071231

Epoch: 5| Step: 4
Training loss: 0.5741317272186279
Validation loss: 1.8336931761874948

Epoch: 5| Step: 5
Training loss: 0.642162024974823
Validation loss: 1.8119276685099448

Epoch: 5| Step: 6
Training loss: 0.718311071395874
Validation loss: 1.795748136376822

Epoch: 5| Step: 7
Training loss: 1.0844333171844482
Validation loss: 1.8095655313102148

Epoch: 5| Step: 8
Training loss: 0.5099089741706848
Validation loss: 1.8103751418411091

Epoch: 5| Step: 9
Training loss: 0.6781594157218933
Validation loss: 1.822020246136573

Epoch: 5| Step: 10
Training loss: 0.6034212708473206
Validation loss: 1.8171504992310719

Epoch: 322| Step: 0
Training loss: 0.8665231466293335
Validation loss: 1.859999204194674

Epoch: 5| Step: 1
Training loss: 1.0119260549545288
Validation loss: 1.8886386732901297

Epoch: 5| Step: 2
Training loss: 0.8695617914199829
Validation loss: 1.9012234774968957

Epoch: 5| Step: 3
Training loss: 0.9379183650016785
Validation loss: 1.897996292319349

Epoch: 5| Step: 4
Training loss: 0.7592450976371765
Validation loss: 1.8654659883950346

Epoch: 5| Step: 5
Training loss: 0.724811851978302
Validation loss: 1.855162251380182

Epoch: 5| Step: 6
Training loss: 0.5853349566459656
Validation loss: 1.8482071071542718

Epoch: 5| Step: 7
Training loss: 0.7242490649223328
Validation loss: 1.866246764377881

Epoch: 5| Step: 8
Training loss: 0.6937797665596008
Validation loss: 1.8213398610391924

Epoch: 5| Step: 9
Training loss: 0.6372109651565552
Validation loss: 1.7985011018732542

Epoch: 5| Step: 10
Training loss: 0.7780397534370422
Validation loss: 1.7898543265558058

Epoch: 323| Step: 0
Training loss: 0.5643261671066284
Validation loss: 1.812670002701462

Epoch: 5| Step: 1
Training loss: 0.6497051119804382
Validation loss: 1.7941678249707786

Epoch: 5| Step: 2
Training loss: 0.9208514094352722
Validation loss: 1.8272896966626566

Epoch: 5| Step: 3
Training loss: 0.9486767053604126
Validation loss: 1.8527814470311648

Epoch: 5| Step: 4
Training loss: 0.6945458650588989
Validation loss: 1.8618302447821504

Epoch: 5| Step: 5
Training loss: 0.6355479955673218
Validation loss: 1.8593007390217116

Epoch: 5| Step: 6
Training loss: 1.0015203952789307
Validation loss: 1.8757013326050134

Epoch: 5| Step: 7
Training loss: 0.8306306600570679
Validation loss: 1.8574944785846177

Epoch: 5| Step: 8
Training loss: 0.8262015581130981
Validation loss: 1.824963023585658

Epoch: 5| Step: 9
Training loss: 0.8650881052017212
Validation loss: 1.7973485146799395

Epoch: 5| Step: 10
Training loss: 0.7901464104652405
Validation loss: 1.794516348069714

Epoch: 324| Step: 0
Training loss: 0.6700693368911743
Validation loss: 1.7781632446473645

Epoch: 5| Step: 1
Training loss: 0.766882598400116
Validation loss: 1.812856662657953

Epoch: 5| Step: 2
Training loss: 1.4151052236557007
Validation loss: 1.7753895790346208

Epoch: 5| Step: 3
Training loss: 1.0093361139297485
Validation loss: 1.7924979194518058

Epoch: 5| Step: 4
Training loss: 0.8724497556686401
Validation loss: 1.8254428999398344

Epoch: 5| Step: 5
Training loss: 0.2688367962837219
Validation loss: 1.8325949868848246

Epoch: 5| Step: 6
Training loss: 0.5855914354324341
Validation loss: 1.8629015825128044

Epoch: 5| Step: 7
Training loss: 0.8645685315132141
Validation loss: 1.894474922969777

Epoch: 5| Step: 8
Training loss: 0.7154842019081116
Validation loss: 1.8878649768008982

Epoch: 5| Step: 9
Training loss: 0.7139219045639038
Validation loss: 1.9036794298438615

Epoch: 5| Step: 10
Training loss: 0.8575963973999023
Validation loss: 1.8704061174905429

Epoch: 325| Step: 0
Training loss: 0.6624523401260376
Validation loss: 1.8328946636569114

Epoch: 5| Step: 1
Training loss: 0.47736233472824097
Validation loss: 1.8128432932720389

Epoch: 5| Step: 2
Training loss: 0.577449381351471
Validation loss: 1.8064355850219727

Epoch: 5| Step: 3
Training loss: 0.6774806380271912
Validation loss: 1.7879232206652242

Epoch: 5| Step: 4
Training loss: 0.8184078931808472
Validation loss: 1.7968924442927043

Epoch: 5| Step: 5
Training loss: 1.0450745820999146
Validation loss: 1.8051089804659608

Epoch: 5| Step: 6
Training loss: 0.70616614818573
Validation loss: 1.803408040795275

Epoch: 5| Step: 7
Training loss: 1.1568204164505005
Validation loss: 1.8058596272622385

Epoch: 5| Step: 8
Training loss: 1.1533257961273193
Validation loss: 1.847677997363511

Epoch: 5| Step: 9
Training loss: 0.6946561932563782
Validation loss: 1.8890194341700564

Epoch: 5| Step: 10
Training loss: 0.8739814758300781
Validation loss: 1.9054422814358947

Epoch: 326| Step: 0
Training loss: 0.7086873054504395
Validation loss: 1.8615602741959274

Epoch: 5| Step: 1
Training loss: 0.6794114708900452
Validation loss: 1.868739733131983

Epoch: 5| Step: 2
Training loss: 0.6261459589004517
Validation loss: 1.8340805410056986

Epoch: 5| Step: 3
Training loss: 1.178292989730835
Validation loss: 1.8423528261082147

Epoch: 5| Step: 4
Training loss: 0.6036759614944458
Validation loss: 1.8194133056107389

Epoch: 5| Step: 5
Training loss: 0.8181689977645874
Validation loss: 1.7885923283074492

Epoch: 5| Step: 6
Training loss: 0.6561664342880249
Validation loss: 1.783059061214488

Epoch: 5| Step: 7
Training loss: 0.6495864987373352
Validation loss: 1.7583394653053694

Epoch: 5| Step: 8
Training loss: 0.6936559677124023
Validation loss: 1.76951172531292

Epoch: 5| Step: 9
Training loss: 0.8632394075393677
Validation loss: 1.7793831491983065

Epoch: 5| Step: 10
Training loss: 0.7961292266845703
Validation loss: 1.8027630275295627

Epoch: 327| Step: 0
Training loss: 0.9471399188041687
Validation loss: 1.8112849830299296

Epoch: 5| Step: 1
Training loss: 0.9365875124931335
Validation loss: 1.8330658776785738

Epoch: 5| Step: 2
Training loss: 0.7393178939819336
Validation loss: 1.8077401884140507

Epoch: 5| Step: 3
Training loss: 0.4494507908821106
Validation loss: 1.7753358271814161

Epoch: 5| Step: 4
Training loss: 1.1131541728973389
Validation loss: 1.7861013527839416

Epoch: 5| Step: 5
Training loss: 0.7169145345687866
Validation loss: 1.7633683604578818

Epoch: 5| Step: 6
Training loss: 0.7386374473571777
Validation loss: 1.7994092138864661

Epoch: 5| Step: 7
Training loss: 0.9320372343063354
Validation loss: 1.8076012301188644

Epoch: 5| Step: 8
Training loss: 0.750141978263855
Validation loss: 1.8506434989231888

Epoch: 5| Step: 9
Training loss: 0.5424742698669434
Validation loss: 1.9041398904656852

Epoch: 5| Step: 10
Training loss: 0.894486129283905
Validation loss: 1.9111315434978855

Epoch: 328| Step: 0
Training loss: 0.6056782603263855
Validation loss: 1.897590515434101

Epoch: 5| Step: 1
Training loss: 0.5523432493209839
Validation loss: 1.8946098178945563

Epoch: 5| Step: 2
Training loss: 0.5675293207168579
Validation loss: 1.8871141941316667

Epoch: 5| Step: 3
Training loss: 1.0264842510223389
Validation loss: 1.8720513056683283

Epoch: 5| Step: 4
Training loss: 0.8182517886161804
Validation loss: 1.8544515191867788

Epoch: 5| Step: 5
Training loss: 1.0689159631729126
Validation loss: 1.8146728700207126

Epoch: 5| Step: 6
Training loss: 0.8149870038032532
Validation loss: 1.7888986564451648

Epoch: 5| Step: 7
Training loss: 0.9434523582458496
Validation loss: 1.7825824893930906

Epoch: 5| Step: 8
Training loss: 0.8852278590202332
Validation loss: 1.7737892032951437

Epoch: 5| Step: 9
Training loss: 0.7930348515510559
Validation loss: 1.788871742063953

Epoch: 5| Step: 10
Training loss: 0.4359789192676544
Validation loss: 1.8071466107522287

Epoch: 329| Step: 0
Training loss: 0.6902002692222595
Validation loss: 1.8213483364351335

Epoch: 5| Step: 1
Training loss: 0.802991509437561
Validation loss: 1.8463521067814161

Epoch: 5| Step: 2
Training loss: 0.6390210390090942
Validation loss: 1.8673508295448877

Epoch: 5| Step: 3
Training loss: 0.9056564569473267
Validation loss: 1.902085147878175

Epoch: 5| Step: 4
Training loss: 0.6886293888092041
Validation loss: 1.9055492313959266

Epoch: 5| Step: 5
Training loss: 0.47840291261672974
Validation loss: 1.8773755155583864

Epoch: 5| Step: 6
Training loss: 0.5560028553009033
Validation loss: 1.8377447769206057

Epoch: 5| Step: 7
Training loss: 0.9668141603469849
Validation loss: 1.828811845471782

Epoch: 5| Step: 8
Training loss: 0.9607388377189636
Validation loss: 1.8036421511762886

Epoch: 5| Step: 9
Training loss: 0.8558105230331421
Validation loss: 1.806807174477526

Epoch: 5| Step: 10
Training loss: 0.8262972831726074
Validation loss: 1.7967413727955153

Epoch: 330| Step: 0
Training loss: 0.8150774240493774
Validation loss: 1.8152420187509188

Epoch: 5| Step: 1
Training loss: 0.7694159746170044
Validation loss: 1.7985890001379035

Epoch: 5| Step: 2
Training loss: 0.9835175275802612
Validation loss: 1.7842857017312

Epoch: 5| Step: 3
Training loss: 0.9229329824447632
Validation loss: 1.8056035926265102

Epoch: 5| Step: 4
Training loss: 0.6243530511856079
Validation loss: 1.8178249251457952

Epoch: 5| Step: 5
Training loss: 0.8617151975631714
Validation loss: 1.8670412391744635

Epoch: 5| Step: 6
Training loss: 0.8628311157226562
Validation loss: 1.839934015786776

Epoch: 5| Step: 7
Training loss: 0.8044328689575195
Validation loss: 1.8707315716692197

Epoch: 5| Step: 8
Training loss: 0.5493628978729248
Validation loss: 1.861905308179958

Epoch: 5| Step: 9
Training loss: 0.5961458683013916
Validation loss: 1.8695503050281155

Epoch: 5| Step: 10
Training loss: 0.5606183409690857
Validation loss: 1.8650922339449647

Epoch: 331| Step: 0
Training loss: 0.837727427482605
Validation loss: 1.843924949246068

Epoch: 5| Step: 1
Training loss: 1.0133683681488037
Validation loss: 1.8135245179617276

Epoch: 5| Step: 2
Training loss: 0.7141422033309937
Validation loss: 1.8042220197698122

Epoch: 5| Step: 3
Training loss: 0.5140053629875183
Validation loss: 1.7685540388989192

Epoch: 5| Step: 4
Training loss: 0.5103104114532471
Validation loss: 1.7806484929976925

Epoch: 5| Step: 5
Training loss: 0.7899297475814819
Validation loss: 1.7721953622756466

Epoch: 5| Step: 6
Training loss: 1.1612250804901123
Validation loss: 1.780556300634979

Epoch: 5| Step: 7
Training loss: 0.560661792755127
Validation loss: 1.7961586752245504

Epoch: 5| Step: 8
Training loss: 0.3833008408546448
Validation loss: 1.7790386369151454

Epoch: 5| Step: 9
Training loss: 0.9123619794845581
Validation loss: 1.7873352086672218

Epoch: 5| Step: 10
Training loss: 0.43578392267227173
Validation loss: 1.8247791938884284

Epoch: 332| Step: 0
Training loss: 0.6346117258071899
Validation loss: 1.8553108925460486

Epoch: 5| Step: 1
Training loss: 0.9061924815177917
Validation loss: 1.89684126710379

Epoch: 5| Step: 2
Training loss: 1.2271602153778076
Validation loss: 1.8572043065101869

Epoch: 5| Step: 3
Training loss: 0.5347835421562195
Validation loss: 1.8387785060431368

Epoch: 5| Step: 4
Training loss: 0.5573471784591675
Validation loss: 1.7928569650137296

Epoch: 5| Step: 5
Training loss: 0.5811076760292053
Validation loss: 1.819312161014926

Epoch: 5| Step: 6
Training loss: 0.6970187425613403
Validation loss: 1.829658604437305

Epoch: 5| Step: 7
Training loss: 0.5994028449058533
Validation loss: 1.814012449274781

Epoch: 5| Step: 8
Training loss: 0.9392818212509155
Validation loss: 1.8117464460352415

Epoch: 5| Step: 9
Training loss: 0.8611796498298645
Validation loss: 1.7954634940752419

Epoch: 5| Step: 10
Training loss: 0.5419129729270935
Validation loss: 1.8019305723969654

Epoch: 333| Step: 0
Training loss: 0.6254816651344299
Validation loss: 1.8006311129498225

Epoch: 5| Step: 1
Training loss: 0.5928095579147339
Validation loss: 1.8217537428743096

Epoch: 5| Step: 2
Training loss: 0.8717058897018433
Validation loss: 1.8213575091413272

Epoch: 5| Step: 3
Training loss: 0.7571829557418823
Validation loss: 1.8010420030163181

Epoch: 5| Step: 4
Training loss: 0.7793752551078796
Validation loss: 1.8149175144010974

Epoch: 5| Step: 5
Training loss: 0.7828892469406128
Validation loss: 1.8389326526272682

Epoch: 5| Step: 6
Training loss: 0.8726602792739868
Validation loss: 1.8223499264768375

Epoch: 5| Step: 7
Training loss: 0.5114946365356445
Validation loss: 1.8142307419930734

Epoch: 5| Step: 8
Training loss: 0.6782280206680298
Validation loss: 1.7918453575462423

Epoch: 5| Step: 9
Training loss: 0.5962752103805542
Validation loss: 1.8155698468608241

Epoch: 5| Step: 10
Training loss: 0.5802526473999023
Validation loss: 1.7978071871624197

Epoch: 334| Step: 0
Training loss: 0.5278717279434204
Validation loss: 1.798063374334766

Epoch: 5| Step: 1
Training loss: 0.7445359230041504
Validation loss: 1.812886312443723

Epoch: 5| Step: 2
Training loss: 1.1230430603027344
Validation loss: 1.8173976072701075

Epoch: 5| Step: 3
Training loss: 0.483210951089859
Validation loss: 1.8096653364037956

Epoch: 5| Step: 4
Training loss: 0.5113780498504639
Validation loss: 1.806372912981177

Epoch: 5| Step: 5
Training loss: 0.6148881912231445
Validation loss: 1.7956036752270115

Epoch: 5| Step: 6
Training loss: 0.7756193280220032
Validation loss: 1.7717568810268114

Epoch: 5| Step: 7
Training loss: 0.6262067556381226
Validation loss: 1.7738967095651934

Epoch: 5| Step: 8
Training loss: 0.4056641161441803
Validation loss: 1.7815004523082445

Epoch: 5| Step: 9
Training loss: 0.9443890452384949
Validation loss: 1.7801488355923725

Epoch: 5| Step: 10
Training loss: 0.6201557517051697
Validation loss: 1.7779650483080136

Epoch: 335| Step: 0
Training loss: 0.4909445643424988
Validation loss: 1.810409733044204

Epoch: 5| Step: 1
Training loss: 0.6010040044784546
Validation loss: 1.791854246970146

Epoch: 5| Step: 2
Training loss: 0.6134450435638428
Validation loss: 1.8344408542879167

Epoch: 5| Step: 3
Training loss: 0.9822180867195129
Validation loss: 1.8453738843241045

Epoch: 5| Step: 4
Training loss: 0.6370004415512085
Validation loss: 1.86703307654268

Epoch: 5| Step: 5
Training loss: 0.6360331177711487
Validation loss: 1.8520472024076728

Epoch: 5| Step: 6
Training loss: 0.8865419626235962
Validation loss: 1.8702279521572975

Epoch: 5| Step: 7
Training loss: 0.5113497376441956
Validation loss: 1.8758617665178032

Epoch: 5| Step: 8
Training loss: 0.5918652415275574
Validation loss: 1.844885697928808

Epoch: 5| Step: 9
Training loss: 0.25933319330215454
Validation loss: 1.8472982862944245

Epoch: 5| Step: 10
Training loss: 1.207473635673523
Validation loss: 1.796214388262841

Epoch: 336| Step: 0
Training loss: 0.6337538361549377
Validation loss: 1.7996750057384532

Epoch: 5| Step: 1
Training loss: 0.7587610483169556
Validation loss: 1.7731242692598732

Epoch: 5| Step: 2
Training loss: 0.4017396867275238
Validation loss: 1.7767066801747968

Epoch: 5| Step: 3
Training loss: 0.5445149540901184
Validation loss: 1.7617973999310566

Epoch: 5| Step: 4
Training loss: 1.1462548971176147
Validation loss: 1.813287752930836

Epoch: 5| Step: 5
Training loss: 0.518896222114563
Validation loss: 1.8311888902418074

Epoch: 5| Step: 6
Training loss: 0.6587091684341431
Validation loss: 1.7893743797015118

Epoch: 5| Step: 7
Training loss: 0.6456046104431152
Validation loss: 1.8256804577765926

Epoch: 5| Step: 8
Training loss: 0.4934752583503723
Validation loss: 1.8102355285357403

Epoch: 5| Step: 9
Training loss: 0.6669870615005493
Validation loss: 1.8341167139750656

Epoch: 5| Step: 10
Training loss: 0.8286369442939758
Validation loss: 1.8419622118755052

Epoch: 337| Step: 0
Training loss: 0.3733745217323303
Validation loss: 1.8185501752361175

Epoch: 5| Step: 1
Training loss: 0.5728784799575806
Validation loss: 1.7952922595444547

Epoch: 5| Step: 2
Training loss: 0.30069899559020996
Validation loss: 1.7727246451121506

Epoch: 5| Step: 3
Training loss: 0.36280354857444763
Validation loss: 1.7509845277314544

Epoch: 5| Step: 4
Training loss: 0.7916769981384277
Validation loss: 1.750980108014999

Epoch: 5| Step: 5
Training loss: 1.0495221614837646
Validation loss: 1.7658186317771993

Epoch: 5| Step: 6
Training loss: 0.7034670114517212
Validation loss: 1.7716228705580517

Epoch: 5| Step: 7
Training loss: 0.5944792628288269
Validation loss: 1.767738817840494

Epoch: 5| Step: 8
Training loss: 1.0510694980621338
Validation loss: 1.7696882268433929

Epoch: 5| Step: 9
Training loss: 0.5714036226272583
Validation loss: 1.7957138912652129

Epoch: 5| Step: 10
Training loss: 0.9056456089019775
Validation loss: 1.7830463776024439

Epoch: 338| Step: 0
Training loss: 1.0252918004989624
Validation loss: 1.7846656986462173

Epoch: 5| Step: 1
Training loss: 0.34327811002731323
Validation loss: 1.7537510625777706

Epoch: 5| Step: 2
Training loss: 0.917140781879425
Validation loss: 1.7485595018632951

Epoch: 5| Step: 3
Training loss: 0.3901451826095581
Validation loss: 1.7922954623417189

Epoch: 5| Step: 4
Training loss: 0.5169771909713745
Validation loss: 1.797402593397325

Epoch: 5| Step: 5
Training loss: 0.8808344006538391
Validation loss: 1.7915562352826517

Epoch: 5| Step: 6
Training loss: 0.44263705611228943
Validation loss: 1.803924383655671

Epoch: 5| Step: 7
Training loss: 0.5910931825637817
Validation loss: 1.802857687396388

Epoch: 5| Step: 8
Training loss: 0.4678628444671631
Validation loss: 1.8098334830294374

Epoch: 5| Step: 9
Training loss: 0.5814645886421204
Validation loss: 1.849469284857473

Epoch: 5| Step: 10
Training loss: 0.7669618129730225
Validation loss: 1.8544341594942155

Epoch: 339| Step: 0
Training loss: 0.361483097076416
Validation loss: 1.8687182177779496

Epoch: 5| Step: 1
Training loss: 0.7532345652580261
Validation loss: 1.8458550694168254

Epoch: 5| Step: 2
Training loss: 0.4408062994480133
Validation loss: 1.8345417732833533

Epoch: 5| Step: 3
Training loss: 0.8331695795059204
Validation loss: 1.8347771475392003

Epoch: 5| Step: 4
Training loss: 0.6108700633049011
Validation loss: 1.8105890648339384

Epoch: 5| Step: 5
Training loss: 0.7108758687973022
Validation loss: 1.7906242519296625

Epoch: 5| Step: 6
Training loss: 0.6625538468360901
Validation loss: 1.7693863517494612

Epoch: 5| Step: 7
Training loss: 0.6091641187667847
Validation loss: 1.771356786451032

Epoch: 5| Step: 8
Training loss: 0.8775779604911804
Validation loss: 1.7622842352877381

Epoch: 5| Step: 9
Training loss: 0.6168655157089233
Validation loss: 1.7754701645143571

Epoch: 5| Step: 10
Training loss: 0.4167727530002594
Validation loss: 1.797900571618029

Epoch: 340| Step: 0
Training loss: 0.619827389717102
Validation loss: 1.810239855961133

Epoch: 5| Step: 1
Training loss: 0.24017730355262756
Validation loss: 1.8234184813755814

Epoch: 5| Step: 2
Training loss: 0.6404946446418762
Validation loss: 1.8233896942548855

Epoch: 5| Step: 3
Training loss: 0.6106818318367004
Validation loss: 1.7992662563118884

Epoch: 5| Step: 4
Training loss: 0.4858957827091217
Validation loss: 1.7910070662857385

Epoch: 5| Step: 5
Training loss: 0.5364103317260742
Validation loss: 1.7655131663045576

Epoch: 5| Step: 6
Training loss: 0.8707191348075867
Validation loss: 1.7740595289455947

Epoch: 5| Step: 7
Training loss: 0.7360196113586426
Validation loss: 1.7742798264308641

Epoch: 5| Step: 8
Training loss: 0.8560392260551453
Validation loss: 1.788017717740869

Epoch: 5| Step: 9
Training loss: 0.5815660357475281
Validation loss: 1.7737652588916082

Epoch: 5| Step: 10
Training loss: 0.6815716028213501
Validation loss: 1.768315533156036

Epoch: 341| Step: 0
Training loss: 0.555971622467041
Validation loss: 1.7478944140095865

Epoch: 5| Step: 1
Training loss: 0.5373688340187073
Validation loss: 1.7467087904612224

Epoch: 5| Step: 2
Training loss: 0.7642809152603149
Validation loss: 1.754771170436695

Epoch: 5| Step: 3
Training loss: 0.6479674577713013
Validation loss: 1.7296059259804346

Epoch: 5| Step: 4
Training loss: 0.3703775703907013
Validation loss: 1.7277620569352181

Epoch: 5| Step: 5
Training loss: 0.6213258504867554
Validation loss: 1.7471054382221674

Epoch: 5| Step: 6
Training loss: 0.5548941493034363
Validation loss: 1.7209973142993065

Epoch: 5| Step: 7
Training loss: 0.3175857961177826
Validation loss: 1.7351724922016103

Epoch: 5| Step: 8
Training loss: 0.6866333484649658
Validation loss: 1.7560755411783855

Epoch: 5| Step: 9
Training loss: 1.1927516460418701
Validation loss: 1.7488332422830726

Epoch: 5| Step: 10
Training loss: 0.2137846052646637
Validation loss: 1.7646306201975832

Epoch: 342| Step: 0
Training loss: 0.5779922604560852
Validation loss: 1.7831791805964645

Epoch: 5| Step: 1
Training loss: 0.9557024240493774
Validation loss: 1.778697367637388

Epoch: 5| Step: 2
Training loss: 0.5379329919815063
Validation loss: 1.7712999108017131

Epoch: 5| Step: 3
Training loss: 0.6774778366088867
Validation loss: 1.76555024936635

Epoch: 5| Step: 4
Training loss: 0.5415118336677551
Validation loss: 1.7973439924178585

Epoch: 5| Step: 5
Training loss: 0.6184621453285217
Validation loss: 1.7994065771820724

Epoch: 5| Step: 6
Training loss: 0.45322442054748535
Validation loss: 1.811406184268254

Epoch: 5| Step: 7
Training loss: 0.5201239585876465
Validation loss: 1.7930006416895057

Epoch: 5| Step: 8
Training loss: 0.49717825651168823
Validation loss: 1.772270348764235

Epoch: 5| Step: 9
Training loss: 0.7079035043716431
Validation loss: 1.741975765074453

Epoch: 5| Step: 10
Training loss: 0.618593692779541
Validation loss: 1.723425998482653

Epoch: 343| Step: 0
Training loss: 0.519400954246521
Validation loss: 1.7155552218037267

Epoch: 5| Step: 1
Training loss: 0.5094951391220093
Validation loss: 1.7290077312018282

Epoch: 5| Step: 2
Training loss: 0.829617977142334
Validation loss: 1.692429583559754

Epoch: 5| Step: 3
Training loss: 0.528889000415802
Validation loss: 1.7216337380870697

Epoch: 5| Step: 4
Training loss: 0.5601220726966858
Validation loss: 1.7311444743987052

Epoch: 5| Step: 5
Training loss: 0.6228581666946411
Validation loss: 1.7611804726303264

Epoch: 5| Step: 6
Training loss: 1.0033514499664307
Validation loss: 1.76421780227333

Epoch: 5| Step: 7
Training loss: 0.4444211423397064
Validation loss: 1.8586827875465475

Epoch: 5| Step: 8
Training loss: 0.6846442222595215
Validation loss: 1.85581160360767

Epoch: 5| Step: 9
Training loss: 0.5808112025260925
Validation loss: 1.8540401792013517

Epoch: 5| Step: 10
Training loss: 0.8638592958450317
Validation loss: 1.8420363100626136

Epoch: 344| Step: 0
Training loss: 0.7416034936904907
Validation loss: 1.7968726875961467

Epoch: 5| Step: 1
Training loss: 0.8059476613998413
Validation loss: 1.773950869037259

Epoch: 5| Step: 2
Training loss: 0.6539480090141296
Validation loss: 1.769328240425356

Epoch: 5| Step: 3
Training loss: 0.890539288520813
Validation loss: 1.7434679859427995

Epoch: 5| Step: 4
Training loss: 0.7120354175567627
Validation loss: 1.7511332445247199

Epoch: 5| Step: 5
Training loss: 0.5515682697296143
Validation loss: 1.7616222981483705

Epoch: 5| Step: 6
Training loss: 0.29120969772338867
Validation loss: 1.7990515975541965

Epoch: 5| Step: 7
Training loss: 0.44707173109054565
Validation loss: 1.8080221683748308

Epoch: 5| Step: 8
Training loss: 0.5831865072250366
Validation loss: 1.8257024185631865

Epoch: 5| Step: 9
Training loss: 0.5615010261535645
Validation loss: 1.8486483686713762

Epoch: 5| Step: 10
Training loss: 0.5648669600486755
Validation loss: 1.8533973642574844

Epoch: 345| Step: 0
Training loss: 0.3910486102104187
Validation loss: 1.8455477888866136

Epoch: 5| Step: 1
Training loss: 0.6057142019271851
Validation loss: 1.8080261843178862

Epoch: 5| Step: 2
Training loss: 0.5133872628211975
Validation loss: 1.7665484695024387

Epoch: 5| Step: 3
Training loss: 0.6708008646965027
Validation loss: 1.7534886547314223

Epoch: 5| Step: 4
Training loss: 0.7785957455635071
Validation loss: 1.7415543627995316

Epoch: 5| Step: 5
Training loss: 0.6844915151596069
Validation loss: 1.7497887098661034

Epoch: 5| Step: 6
Training loss: 0.4283541738986969
Validation loss: 1.7383842160624843

Epoch: 5| Step: 7
Training loss: 0.3363264799118042
Validation loss: 1.7478091947494014

Epoch: 5| Step: 8
Training loss: 0.6454955339431763
Validation loss: 1.787134216677758

Epoch: 5| Step: 9
Training loss: 0.6932125091552734
Validation loss: 1.7664343721123152

Epoch: 5| Step: 10
Training loss: 0.6832368969917297
Validation loss: 1.8110571433139104

Epoch: 346| Step: 0
Training loss: 0.7133434414863586
Validation loss: 1.7837918112354894

Epoch: 5| Step: 1
Training loss: 0.5515879392623901
Validation loss: 1.817892179694227

Epoch: 5| Step: 2
Training loss: 0.5525651574134827
Validation loss: 1.7972415877926735

Epoch: 5| Step: 3
Training loss: 0.515296220779419
Validation loss: 1.7785370029428953

Epoch: 5| Step: 4
Training loss: 0.4449969232082367
Validation loss: 1.7575076600556732

Epoch: 5| Step: 5
Training loss: 0.6027129888534546
Validation loss: 1.7613180388686478

Epoch: 5| Step: 6
Training loss: 0.6060413122177124
Validation loss: 1.744352788053533

Epoch: 5| Step: 7
Training loss: 0.5189896821975708
Validation loss: 1.7432922060771654

Epoch: 5| Step: 8
Training loss: 0.7278118133544922
Validation loss: 1.7639166180805494

Epoch: 5| Step: 9
Training loss: 0.5966736078262329
Validation loss: 1.7539712562355945

Epoch: 5| Step: 10
Training loss: 0.6513317227363586
Validation loss: 1.7686606568674887

Epoch: 347| Step: 0
Training loss: 0.4045730531215668
Validation loss: 1.7589966609913816

Epoch: 5| Step: 1
Training loss: 0.3296392560005188
Validation loss: 1.7695780684871059

Epoch: 5| Step: 2
Training loss: 0.5990480184555054
Validation loss: 1.7833862740506408

Epoch: 5| Step: 3
Training loss: 0.5831015110015869
Validation loss: 1.777324048421716

Epoch: 5| Step: 4
Training loss: 0.8119291067123413
Validation loss: 1.822380465845908

Epoch: 5| Step: 5
Training loss: 0.5318154692649841
Validation loss: 1.7896038396384126

Epoch: 5| Step: 6
Training loss: 0.47065839171409607
Validation loss: 1.773088578254946

Epoch: 5| Step: 7
Training loss: 0.7510233521461487
Validation loss: 1.7720625810725714

Epoch: 5| Step: 8
Training loss: 0.6358847618103027
Validation loss: 1.7365775223701232

Epoch: 5| Step: 9
Training loss: 0.7734201550483704
Validation loss: 1.756925746958743

Epoch: 5| Step: 10
Training loss: 0.6380470395088196
Validation loss: 1.763954923998925

Epoch: 348| Step: 0
Training loss: 0.483269602060318
Validation loss: 1.7342653646264026

Epoch: 5| Step: 1
Training loss: 0.4189993739128113
Validation loss: 1.7154510098118936

Epoch: 5| Step: 2
Training loss: 0.7177928686141968
Validation loss: 1.7361952617604246

Epoch: 5| Step: 3
Training loss: 0.4829300045967102
Validation loss: 1.7515986581002512

Epoch: 5| Step: 4
Training loss: 0.367320716381073
Validation loss: 1.7631934765846498

Epoch: 5| Step: 5
Training loss: 0.4414830207824707
Validation loss: 1.762690616551266

Epoch: 5| Step: 6
Training loss: 0.4409855306148529
Validation loss: 1.7998322812459802

Epoch: 5| Step: 7
Training loss: 0.8053299784660339
Validation loss: 1.7981508816442182

Epoch: 5| Step: 8
Training loss: 1.0315877199172974
Validation loss: 1.8198984310191164

Epoch: 5| Step: 9
Training loss: 0.8045762181282043
Validation loss: 1.8066288463531002

Epoch: 5| Step: 10
Training loss: 0.6090831756591797
Validation loss: 1.8106689478761406

Epoch: 349| Step: 0
Training loss: 0.5393926501274109
Validation loss: 1.7914634584098734

Epoch: 5| Step: 1
Training loss: 0.46431979537010193
Validation loss: 1.7513904379260155

Epoch: 5| Step: 2
Training loss: 0.26320427656173706
Validation loss: 1.726389072274649

Epoch: 5| Step: 3
Training loss: 0.5356805920600891
Validation loss: 1.73177517614057

Epoch: 5| Step: 4
Training loss: 0.6299571990966797
Validation loss: 1.7148218065179803

Epoch: 5| Step: 5
Training loss: 0.5612751245498657
Validation loss: 1.707420914403854

Epoch: 5| Step: 6
Training loss: 0.579332172870636
Validation loss: 1.7035767237345378

Epoch: 5| Step: 7
Training loss: 0.4446694254875183
Validation loss: 1.6753351278202508

Epoch: 5| Step: 8
Training loss: 0.7903012037277222
Validation loss: 1.7095831363431868

Epoch: 5| Step: 9
Training loss: 0.7463642358779907
Validation loss: 1.735075899349746

Epoch: 5| Step: 10
Training loss: 0.7304002046585083
Validation loss: 1.7268148801660026

Epoch: 350| Step: 0
Training loss: 0.5883533358573914
Validation loss: 1.7513700492920414

Epoch: 5| Step: 1
Training loss: 0.7909835577011108
Validation loss: 1.765614087863635

Epoch: 5| Step: 2
Training loss: 0.6660972833633423
Validation loss: 1.7948570994920627

Epoch: 5| Step: 3
Training loss: 0.5616214871406555
Validation loss: 1.800323131263897

Epoch: 5| Step: 4
Training loss: 0.4841689467430115
Validation loss: 1.7812956930488668

Epoch: 5| Step: 5
Training loss: 0.39291128516197205
Validation loss: 1.6987411232404812

Epoch: 5| Step: 6
Training loss: 0.4755379557609558
Validation loss: 1.6953104131965226

Epoch: 5| Step: 7
Training loss: 0.5334441065788269
Validation loss: 1.7200119341573408

Epoch: 5| Step: 8
Training loss: 0.31411299109458923
Validation loss: 1.6990288162744174

Epoch: 5| Step: 9
Training loss: 0.6761665344238281
Validation loss: 1.714485223575305

Epoch: 5| Step: 10
Training loss: 0.5058823823928833
Validation loss: 1.727822781250041

Epoch: 351| Step: 0
Training loss: 0.5191599130630493
Validation loss: 1.7260838221478205

Epoch: 5| Step: 1
Training loss: 0.7905041575431824
Validation loss: 1.7295376216211626

Epoch: 5| Step: 2
Training loss: 0.6048761606216431
Validation loss: 1.7320088237844489

Epoch: 5| Step: 3
Training loss: 0.24218854308128357
Validation loss: 1.7401114061314573

Epoch: 5| Step: 4
Training loss: 0.49925917387008667
Validation loss: 1.7411252388390162

Epoch: 5| Step: 5
Training loss: 0.4572847783565521
Validation loss: 1.7736742816945559

Epoch: 5| Step: 6
Training loss: 0.5385938882827759
Validation loss: 1.737416285340504

Epoch: 5| Step: 7
Training loss: 0.4112488627433777
Validation loss: 1.7530758637253956

Epoch: 5| Step: 8
Training loss: 0.5857383012771606
Validation loss: 1.7671451363512265

Epoch: 5| Step: 9
Training loss: 0.684822678565979
Validation loss: 1.7624540649434572

Epoch: 5| Step: 10
Training loss: 0.547394871711731
Validation loss: 1.751508253876881

Epoch: 352| Step: 0
Training loss: 0.6172617673873901
Validation loss: 1.77765392872595

Epoch: 5| Step: 1
Training loss: 0.7271889448165894
Validation loss: 1.7631994511491509

Epoch: 5| Step: 2
Training loss: 0.541995108127594
Validation loss: 1.7862566722336637

Epoch: 5| Step: 3
Training loss: 0.3638954162597656
Validation loss: 1.7779083187862108

Epoch: 5| Step: 4
Training loss: 0.30306658148765564
Validation loss: 1.7637113089202552

Epoch: 5| Step: 5
Training loss: 0.7211920619010925
Validation loss: 1.7721987475631058

Epoch: 5| Step: 6
Training loss: 0.4104038178920746
Validation loss: 1.764886725333429

Epoch: 5| Step: 7
Training loss: 0.5445824861526489
Validation loss: 1.796500890485702

Epoch: 5| Step: 8
Training loss: 0.5260359048843384
Validation loss: 1.7694249460774083

Epoch: 5| Step: 9
Training loss: 0.6062425971031189
Validation loss: 1.7798125936139015

Epoch: 5| Step: 10
Training loss: 0.5100659728050232
Validation loss: 1.7760323375783942

Epoch: 353| Step: 0
Training loss: 0.5846880674362183
Validation loss: 1.761082592830863

Epoch: 5| Step: 1
Training loss: 0.3351728916168213
Validation loss: 1.7181140351039108

Epoch: 5| Step: 2
Training loss: 0.8437702059745789
Validation loss: 1.7334330184485323

Epoch: 5| Step: 3
Training loss: 0.451066255569458
Validation loss: 1.7251818128811416

Epoch: 5| Step: 4
Training loss: 0.7096196413040161
Validation loss: 1.7264226380214895

Epoch: 5| Step: 5
Training loss: 0.36974185705184937
Validation loss: 1.7355228508672407

Epoch: 5| Step: 6
Training loss: 0.40448132157325745
Validation loss: 1.6917425355603617

Epoch: 5| Step: 7
Training loss: 0.590844988822937
Validation loss: 1.718092462067963

Epoch: 5| Step: 8
Training loss: 0.5728013515472412
Validation loss: 1.7321474526518135

Epoch: 5| Step: 9
Training loss: 0.3204475939273834
Validation loss: 1.7310672665155062

Epoch: 5| Step: 10
Training loss: 0.42254307866096497
Validation loss: 1.7618996135650142

Epoch: 354| Step: 0
Training loss: 0.33508503437042236
Validation loss: 1.7451364994049072

Epoch: 5| Step: 1
Training loss: 0.3001444637775421
Validation loss: 1.7461269094098

Epoch: 5| Step: 2
Training loss: 0.8486809730529785
Validation loss: 1.7548267302974578

Epoch: 5| Step: 3
Training loss: 0.36052459478378296
Validation loss: 1.7472967896410214

Epoch: 5| Step: 4
Training loss: 0.774384617805481
Validation loss: 1.7783511184876966

Epoch: 5| Step: 5
Training loss: 0.5487838983535767
Validation loss: 1.7873900167403682

Epoch: 5| Step: 6
Training loss: 0.3476925492286682
Validation loss: 1.7944420281276907

Epoch: 5| Step: 7
Training loss: 0.5246407985687256
Validation loss: 1.7843525486607705

Epoch: 5| Step: 8
Training loss: 0.5787230730056763
Validation loss: 1.7756141090905795

Epoch: 5| Step: 9
Training loss: 0.6257874965667725
Validation loss: 1.7892867275463638

Epoch: 5| Step: 10
Training loss: 0.27651625871658325
Validation loss: 1.7235722259808612

Epoch: 355| Step: 0
Training loss: 0.6745323538780212
Validation loss: 1.7432577751016105

Epoch: 5| Step: 1
Training loss: 0.5985745191574097
Validation loss: 1.7415145212604153

Epoch: 5| Step: 2
Training loss: 0.35210752487182617
Validation loss: 1.7299392992450344

Epoch: 5| Step: 3
Training loss: 0.469230979681015
Validation loss: 1.7118245452962897

Epoch: 5| Step: 4
Training loss: 0.565099835395813
Validation loss: 1.7101735620088474

Epoch: 5| Step: 5
Training loss: 0.4195200502872467
Validation loss: 1.7009259423901957

Epoch: 5| Step: 6
Training loss: 0.37633854150772095
Validation loss: 1.7076157844194801

Epoch: 5| Step: 7
Training loss: 0.5281802415847778
Validation loss: 1.726086264015526

Epoch: 5| Step: 8
Training loss: 0.6951988339424133
Validation loss: 1.7093993463823873

Epoch: 5| Step: 9
Training loss: 0.5901703238487244
Validation loss: 1.7248602746635355

Epoch: 5| Step: 10
Training loss: 0.37113049626350403
Validation loss: 1.727698552993036

Epoch: 356| Step: 0
Training loss: 0.294575035572052
Validation loss: 1.7665098380017024

Epoch: 5| Step: 1
Training loss: 0.7446027398109436
Validation loss: 1.803746259340676

Epoch: 5| Step: 2
Training loss: 0.3535303473472595
Validation loss: 1.8228906534051383

Epoch: 5| Step: 3
Training loss: 0.6007256507873535
Validation loss: 1.8025287159027592

Epoch: 5| Step: 4
Training loss: 0.4333157539367676
Validation loss: 1.8116610447565715

Epoch: 5| Step: 5
Training loss: 0.6414456367492676
Validation loss: 1.8125859960432975

Epoch: 5| Step: 6
Training loss: 0.28354114294052124
Validation loss: 1.7987302170004895

Epoch: 5| Step: 7
Training loss: 0.6166515350341797
Validation loss: 1.795199142989292

Epoch: 5| Step: 8
Training loss: 0.7534433007240295
Validation loss: 1.7655002417102936

Epoch: 5| Step: 9
Training loss: 0.325643926858902
Validation loss: 1.7755590241442445

Epoch: 5| Step: 10
Training loss: 0.42792484164237976
Validation loss: 1.7980758708010438

Epoch: 357| Step: 0
Training loss: 0.5418415665626526
Validation loss: 1.7769070709905317

Epoch: 5| Step: 1
Training loss: 0.4663158357143402
Validation loss: 1.750289091499903

Epoch: 5| Step: 2
Training loss: 0.5125691890716553
Validation loss: 1.7646956533514044

Epoch: 5| Step: 3
Training loss: 0.5505856275558472
Validation loss: 1.7790596792774815

Epoch: 5| Step: 4
Training loss: 0.7921772003173828
Validation loss: 1.785859501490029

Epoch: 5| Step: 5
Training loss: 0.4399009644985199
Validation loss: 1.7862260931281633

Epoch: 5| Step: 6
Training loss: 0.4136192798614502
Validation loss: 1.7849640410433534

Epoch: 5| Step: 7
Training loss: 0.4317903518676758
Validation loss: 1.7917431785214333

Epoch: 5| Step: 8
Training loss: 0.5186686515808105
Validation loss: 1.7805321588311145

Epoch: 5| Step: 9
Training loss: 0.47181934118270874
Validation loss: 1.76896886287197

Epoch: 5| Step: 10
Training loss: 0.4829843044281006
Validation loss: 1.7617419304386261

Epoch: 358| Step: 0
Training loss: 0.4247525632381439
Validation loss: 1.7244514009003997

Epoch: 5| Step: 1
Training loss: 0.3946383595466614
Validation loss: 1.684204888600175

Epoch: 5| Step: 2
Training loss: 0.7709363102912903
Validation loss: 1.6922545048498339

Epoch: 5| Step: 3
Training loss: 0.6830965280532837
Validation loss: 1.7014445515089138

Epoch: 5| Step: 4
Training loss: 0.5071045756340027
Validation loss: 1.672203924066277

Epoch: 5| Step: 5
Training loss: 0.3261726200580597
Validation loss: 1.6901186486726165

Epoch: 5| Step: 6
Training loss: 0.5540863275527954
Validation loss: 1.6920149121233212

Epoch: 5| Step: 7
Training loss: 0.628294825553894
Validation loss: 1.6893294703575872

Epoch: 5| Step: 8
Training loss: 0.48218101263046265
Validation loss: 1.7128769300317253

Epoch: 5| Step: 9
Training loss: 0.2978292405605316
Validation loss: 1.7328049085473503

Epoch: 5| Step: 10
Training loss: 0.5163558721542358
Validation loss: 1.7930229697176205

Epoch: 359| Step: 0
Training loss: 0.4520854353904724
Validation loss: 1.8230340967896164

Epoch: 5| Step: 1
Training loss: 0.32216164469718933
Validation loss: 1.8286388868926673

Epoch: 5| Step: 2
Training loss: 0.39081698656082153
Validation loss: 1.8046640221790602

Epoch: 5| Step: 3
Training loss: 0.46285247802734375
Validation loss: 1.8634339314635082

Epoch: 5| Step: 4
Training loss: 0.7021908164024353
Validation loss: 1.8762680279311312

Epoch: 5| Step: 5
Training loss: 0.3969332277774811
Validation loss: 1.8558247204749816

Epoch: 5| Step: 6
Training loss: 0.5425172448158264
Validation loss: 1.8181674864984327

Epoch: 5| Step: 7
Training loss: 0.5946146845817566
Validation loss: 1.764544835654638

Epoch: 5| Step: 8
Training loss: 0.6051079034805298
Validation loss: 1.7591855269606396

Epoch: 5| Step: 9
Training loss: 0.3199353814125061
Validation loss: 1.746259459885218

Epoch: 5| Step: 10
Training loss: 1.0455482006072998
Validation loss: 1.7359272997866395

Epoch: 360| Step: 0
Training loss: 0.3788462281227112
Validation loss: 1.7162729373542212

Epoch: 5| Step: 1
Training loss: 0.3689301609992981
Validation loss: 1.7595073266695904

Epoch: 5| Step: 2
Training loss: 0.7584726810455322
Validation loss: 1.742893757358674

Epoch: 5| Step: 3
Training loss: 0.6583558917045593
Validation loss: 1.7219213131935365

Epoch: 5| Step: 4
Training loss: 0.2981911897659302
Validation loss: 1.7597471949874715

Epoch: 5| Step: 5
Training loss: 0.35941606760025024
Validation loss: 1.7815332079446444

Epoch: 5| Step: 6
Training loss: 0.6591125726699829
Validation loss: 1.7862801167272753

Epoch: 5| Step: 7
Training loss: 0.5750345587730408
Validation loss: 1.780958124386367

Epoch: 5| Step: 8
Training loss: 0.3297398090362549
Validation loss: 1.7877191292342318

Epoch: 5| Step: 9
Training loss: 0.5868716239929199
Validation loss: 1.7732961139371317

Epoch: 5| Step: 10
Training loss: 0.3142798840999603
Validation loss: 1.7633909281863962

Epoch: 361| Step: 0
Training loss: 0.4059768617153168
Validation loss: 1.7487858828677927

Epoch: 5| Step: 1
Training loss: 0.7454708814620972
Validation loss: 1.744227211962464

Epoch: 5| Step: 2
Training loss: 0.3969464600086212
Validation loss: 1.7548564352015013

Epoch: 5| Step: 3
Training loss: 0.3157626986503601
Validation loss: 1.7323867646596764

Epoch: 5| Step: 4
Training loss: 0.32902225852012634
Validation loss: 1.7527552330365745

Epoch: 5| Step: 5
Training loss: 0.4146119952201843
Validation loss: 1.7563634880127446

Epoch: 5| Step: 6
Training loss: 0.2287209928035736
Validation loss: 1.7482392275205223

Epoch: 5| Step: 7
Training loss: 0.8314024209976196
Validation loss: 1.7327768366823915

Epoch: 5| Step: 8
Training loss: 0.6013981103897095
Validation loss: 1.6804050783957205

Epoch: 5| Step: 9
Training loss: 0.3341163694858551
Validation loss: 1.6722132775091356

Epoch: 5| Step: 10
Training loss: 0.4798974394798279
Validation loss: 1.6931137320815877

Epoch: 362| Step: 0
Training loss: 0.5144261121749878
Validation loss: 1.7214615511637863

Epoch: 5| Step: 1
Training loss: 0.28497180342674255
Validation loss: 1.7556821735956336

Epoch: 5| Step: 2
Training loss: 0.5577620267868042
Validation loss: 1.7578094800313313

Epoch: 5| Step: 3
Training loss: 0.4161597192287445
Validation loss: 1.7554471095403035

Epoch: 5| Step: 4
Training loss: 0.4208923280239105
Validation loss: 1.7478501899268037

Epoch: 5| Step: 5
Training loss: 0.28777509927749634
Validation loss: 1.7320455043546614

Epoch: 5| Step: 6
Training loss: 0.5378106236457825
Validation loss: 1.7539763066076464

Epoch: 5| Step: 7
Training loss: 0.6132442355155945
Validation loss: 1.735501234249402

Epoch: 5| Step: 8
Training loss: 0.3009769022464752
Validation loss: 1.7362133738815144

Epoch: 5| Step: 9
Training loss: 0.920872688293457
Validation loss: 1.7494861284891765

Epoch: 5| Step: 10
Training loss: 0.4173230826854706
Validation loss: 1.7420734987464002

Epoch: 363| Step: 0
Training loss: 0.5405007600784302
Validation loss: 1.731606246322714

Epoch: 5| Step: 1
Training loss: 0.29339104890823364
Validation loss: 1.7594718381922732

Epoch: 5| Step: 2
Training loss: 0.422804594039917
Validation loss: 1.7331743573629728

Epoch: 5| Step: 3
Training loss: 0.3888905644416809
Validation loss: 1.7594384660003006

Epoch: 5| Step: 4
Training loss: 0.3928840756416321
Validation loss: 1.7747251141455866

Epoch: 5| Step: 5
Training loss: 0.47318997979164124
Validation loss: 1.8135987750945552

Epoch: 5| Step: 6
Training loss: 0.6446455717086792
Validation loss: 1.8049584204150784

Epoch: 5| Step: 7
Training loss: 0.48248690366744995
Validation loss: 1.775997793802651

Epoch: 5| Step: 8
Training loss: 0.7820799350738525
Validation loss: 1.7492400164245276

Epoch: 5| Step: 9
Training loss: 0.34739556908607483
Validation loss: 1.7266116962637952

Epoch: 5| Step: 10
Training loss: 0.2508693039417267
Validation loss: 1.7285036784346386

Epoch: 364| Step: 0
Training loss: 0.1375025063753128
Validation loss: 1.7343182256144862

Epoch: 5| Step: 1
Training loss: 0.46621400117874146
Validation loss: 1.7147179944540865

Epoch: 5| Step: 2
Training loss: 0.2444494664669037
Validation loss: 1.7052022462250085

Epoch: 5| Step: 3
Training loss: 0.626521110534668
Validation loss: 1.718852380270599

Epoch: 5| Step: 4
Training loss: 0.2736600935459137
Validation loss: 1.730678758313579

Epoch: 5| Step: 5
Training loss: 0.3761467933654785
Validation loss: 1.7522761667928388

Epoch: 5| Step: 6
Training loss: 0.20254036784172058
Validation loss: 1.7132904888481222

Epoch: 5| Step: 7
Training loss: 0.5904288291931152
Validation loss: 1.7284670055553477

Epoch: 5| Step: 8
Training loss: 0.5534903407096863
Validation loss: 1.7433907319140691

Epoch: 5| Step: 9
Training loss: 0.7691265940666199
Validation loss: 1.72660840711286

Epoch: 5| Step: 10
Training loss: 0.5673864483833313
Validation loss: 1.7119957195815219

Epoch: 365| Step: 0
Training loss: 0.3098011016845703
Validation loss: 1.744334210631668

Epoch: 5| Step: 1
Training loss: 0.4793940484523773
Validation loss: 1.7191461247782553

Epoch: 5| Step: 2
Training loss: 0.450935035943985
Validation loss: 1.755161549455376

Epoch: 5| Step: 3
Training loss: 0.49401402473449707
Validation loss: 1.7464267758912937

Epoch: 5| Step: 4
Training loss: 0.7250235676765442
Validation loss: 1.7478756404692126

Epoch: 5| Step: 5
Training loss: 0.545677900314331
Validation loss: 1.7464080831056

Epoch: 5| Step: 6
Training loss: 0.4128120541572571
Validation loss: 1.729786931827504

Epoch: 5| Step: 7
Training loss: 0.6194368600845337
Validation loss: 1.7272485789432321

Epoch: 5| Step: 8
Training loss: 0.31599855422973633
Validation loss: 1.7324448939292663

Epoch: 5| Step: 9
Training loss: 0.4116952419281006
Validation loss: 1.7535411875735047

Epoch: 5| Step: 10
Training loss: 0.2632504105567932
Validation loss: 1.75409605169809

Epoch: 366| Step: 0
Training loss: 0.3229930102825165
Validation loss: 1.7585050021448443

Epoch: 5| Step: 1
Training loss: 0.4038763642311096
Validation loss: 1.7343104142014698

Epoch: 5| Step: 2
Training loss: 0.403634250164032
Validation loss: 1.6997278877483901

Epoch: 5| Step: 3
Training loss: 0.27831897139549255
Validation loss: 1.733247192957068

Epoch: 5| Step: 4
Training loss: 0.5376006960868835
Validation loss: 1.7246756072967284

Epoch: 5| Step: 5
Training loss: 0.19708752632141113
Validation loss: 1.717398488393394

Epoch: 5| Step: 6
Training loss: 0.3895491659641266
Validation loss: 1.7099468169673797

Epoch: 5| Step: 7
Training loss: 0.9004918932914734
Validation loss: 1.7113985694864744

Epoch: 5| Step: 8
Training loss: 0.4388503134250641
Validation loss: 1.709602181629468

Epoch: 5| Step: 9
Training loss: 0.50324547290802
Validation loss: 1.7060534313160887

Epoch: 5| Step: 10
Training loss: 0.34988054633140564
Validation loss: 1.6856937036719373

Epoch: 367| Step: 0
Training loss: 0.195861354470253
Validation loss: 1.6936263858631093

Epoch: 5| Step: 1
Training loss: 0.534949004650116
Validation loss: 1.6813123174892959

Epoch: 5| Step: 2
Training loss: 0.2924198806285858
Validation loss: 1.7004455225442046

Epoch: 5| Step: 3
Training loss: 0.720446765422821
Validation loss: 1.7131231946329917

Epoch: 5| Step: 4
Training loss: 0.33093228936195374
Validation loss: 1.6767655700765631

Epoch: 5| Step: 5
Training loss: 0.7748827934265137
Validation loss: 1.6850311640770204

Epoch: 5| Step: 6
Training loss: 0.3913074731826782
Validation loss: 1.6884580632691741

Epoch: 5| Step: 7
Training loss: 0.43847909569740295
Validation loss: 1.698780845570308

Epoch: 5| Step: 8
Training loss: 0.46710672974586487
Validation loss: 1.7005752504512828

Epoch: 5| Step: 9
Training loss: 0.2684393525123596
Validation loss: 1.762189317775029

Epoch: 5| Step: 10
Training loss: 0.28028589487075806
Validation loss: 1.7423600663420975

Epoch: 368| Step: 0
Training loss: 0.5316202640533447
Validation loss: 1.7217640325587282

Epoch: 5| Step: 1
Training loss: 0.4240620732307434
Validation loss: 1.7258610225492907

Epoch: 5| Step: 2
Training loss: 0.19100145995616913
Validation loss: 1.7375458466109408

Epoch: 5| Step: 3
Training loss: 0.3356569707393646
Validation loss: 1.7263694501692248

Epoch: 5| Step: 4
Training loss: 0.3339637815952301
Validation loss: 1.7118819182918918

Epoch: 5| Step: 5
Training loss: 0.39330756664276123
Validation loss: 1.6744856783138808

Epoch: 5| Step: 6
Training loss: 0.2561476230621338
Validation loss: 1.7005725663195375

Epoch: 5| Step: 7
Training loss: 0.7614062428474426
Validation loss: 1.6786985140974804

Epoch: 5| Step: 8
Training loss: 0.4219130575656891
Validation loss: 1.7109233089672622

Epoch: 5| Step: 9
Training loss: 0.40404146909713745
Validation loss: 1.7115013202031453

Epoch: 5| Step: 10
Training loss: 0.41251620650291443
Validation loss: 1.7331640758822042

Epoch: 369| Step: 0
Training loss: 0.3563072681427002
Validation loss: 1.7214779264183455

Epoch: 5| Step: 1
Training loss: 0.4277188181877136
Validation loss: 1.6995638519205072

Epoch: 5| Step: 2
Training loss: 0.6703556776046753
Validation loss: 1.7122621113254177

Epoch: 5| Step: 3
Training loss: 0.4261510968208313
Validation loss: 1.7099572855939147

Epoch: 5| Step: 4
Training loss: 0.32670801877975464
Validation loss: 1.6903703225556241

Epoch: 5| Step: 5
Training loss: 0.3918035924434662
Validation loss: 1.7132577242389802

Epoch: 5| Step: 6
Training loss: 0.264051616191864
Validation loss: 1.7065272023600917

Epoch: 5| Step: 7
Training loss: 0.3629150986671448
Validation loss: 1.6895109632963776

Epoch: 5| Step: 8
Training loss: 0.34729552268981934
Validation loss: 1.6957696932618336

Epoch: 5| Step: 9
Training loss: 0.4320296347141266
Validation loss: 1.695646773102463

Epoch: 5| Step: 10
Training loss: 0.3747258186340332
Validation loss: 1.722687509752089

Epoch: 370| Step: 0
Training loss: 0.506848156452179
Validation loss: 1.753895454509284

Epoch: 5| Step: 1
Training loss: 0.6662651896476746
Validation loss: 1.7196968101686048

Epoch: 5| Step: 2
Training loss: 0.25281620025634766
Validation loss: 1.737239001258727

Epoch: 5| Step: 3
Training loss: 0.22636179625988007
Validation loss: 1.7211077674742667

Epoch: 5| Step: 4
Training loss: 0.446084588766098
Validation loss: 1.7417168578793925

Epoch: 5| Step: 5
Training loss: 0.27837273478507996
Validation loss: 1.7317851217844153

Epoch: 5| Step: 6
Training loss: 0.43204647302627563
Validation loss: 1.7394298609866892

Epoch: 5| Step: 7
Training loss: 0.3674507737159729
Validation loss: 1.6973467629442933

Epoch: 5| Step: 8
Training loss: 0.3121050000190735
Validation loss: 1.6768804391225178

Epoch: 5| Step: 9
Training loss: 0.312211275100708
Validation loss: 1.654860568943844

Epoch: 5| Step: 10
Training loss: 0.6081236004829407
Validation loss: 1.6736161452467724

Epoch: 371| Step: 0
Training loss: 0.346690833568573
Validation loss: 1.6985494859756962

Epoch: 5| Step: 1
Training loss: 0.4480573534965515
Validation loss: 1.725750724474589

Epoch: 5| Step: 2
Training loss: 0.448634535074234
Validation loss: 1.7418174102742185

Epoch: 5| Step: 3
Training loss: 0.3117184042930603
Validation loss: 1.7915741397488503

Epoch: 5| Step: 4
Training loss: 0.3422437310218811
Validation loss: 1.7748130816285328

Epoch: 5| Step: 5
Training loss: 0.380370169878006
Validation loss: 1.7895495135297057

Epoch: 5| Step: 6
Training loss: 0.11302318423986435
Validation loss: 1.7519131693788754

Epoch: 5| Step: 7
Training loss: 0.37628668546676636
Validation loss: 1.7048518734593545

Epoch: 5| Step: 8
Training loss: 0.6613391041755676
Validation loss: 1.668960589234547

Epoch: 5| Step: 9
Training loss: 0.37083882093429565
Validation loss: 1.700342453936095

Epoch: 5| Step: 10
Training loss: 0.726036548614502
Validation loss: 1.6960404470402708

Epoch: 372| Step: 0
Training loss: 0.6265658736228943
Validation loss: 1.6997678049149052

Epoch: 5| Step: 1
Training loss: 0.4647170901298523
Validation loss: 1.7309093052341091

Epoch: 5| Step: 2
Training loss: 0.19086316227912903
Validation loss: 1.7289981867677422

Epoch: 5| Step: 3
Training loss: 0.2947409749031067
Validation loss: 1.728084373217757

Epoch: 5| Step: 4
Training loss: 0.5231474041938782
Validation loss: 1.697083338614433

Epoch: 5| Step: 5
Training loss: 0.25278910994529724
Validation loss: 1.688049724025111

Epoch: 5| Step: 6
Training loss: 0.49292707443237305
Validation loss: 1.69131891317265

Epoch: 5| Step: 7
Training loss: 0.4063957631587982
Validation loss: 1.681879364034181

Epoch: 5| Step: 8
Training loss: 0.34622877836227417
Validation loss: 1.6686212990873603

Epoch: 5| Step: 9
Training loss: 0.2775900363922119
Validation loss: 1.6663895076321018

Epoch: 5| Step: 10
Training loss: 0.563372790813446
Validation loss: 1.6920509248651483

Epoch: 373| Step: 0
Training loss: 0.4000686705112457
Validation loss: 1.6918051140282744

Epoch: 5| Step: 1
Training loss: 0.3501811623573303
Validation loss: 1.7245273641360703

Epoch: 5| Step: 2
Training loss: 0.40817612409591675
Validation loss: 1.7369211566063665

Epoch: 5| Step: 3
Training loss: 0.43331655859947205
Validation loss: 1.7310907661273915

Epoch: 5| Step: 4
Training loss: 0.5265135765075684
Validation loss: 1.7306430596177296

Epoch: 5| Step: 5
Training loss: 0.25369349122047424
Validation loss: 1.729187306537423

Epoch: 5| Step: 6
Training loss: 0.19072453677654266
Validation loss: 1.696932738827121

Epoch: 5| Step: 7
Training loss: 0.27161064743995667
Validation loss: 1.6597776271963631

Epoch: 5| Step: 8
Training loss: 0.2929683327674866
Validation loss: 1.6520442655009608

Epoch: 5| Step: 9
Training loss: 0.8738549947738647
Validation loss: 1.6879567074519333

Epoch: 5| Step: 10
Training loss: 0.551903247833252
Validation loss: 1.709185883563052

Epoch: 374| Step: 0
Training loss: 0.3390423059463501
Validation loss: 1.7091034702075425

Epoch: 5| Step: 1
Training loss: 0.26346099376678467
Validation loss: 1.7389709898220596

Epoch: 5| Step: 2
Training loss: 0.5375189781188965
Validation loss: 1.7547911777291247

Epoch: 5| Step: 3
Training loss: 0.5219486951828003
Validation loss: 1.7582783827217676

Epoch: 5| Step: 4
Training loss: 0.3635830879211426
Validation loss: 1.789035766355453

Epoch: 5| Step: 5
Training loss: 0.5334571003913879
Validation loss: 1.778616436066166

Epoch: 5| Step: 6
Training loss: 0.515973687171936
Validation loss: 1.8080655695289694

Epoch: 5| Step: 7
Training loss: 0.32494455575942993
Validation loss: 1.7715659244086153

Epoch: 5| Step: 8
Training loss: 0.300422340631485
Validation loss: 1.7375634216493177

Epoch: 5| Step: 9
Training loss: 0.36022770404815674
Validation loss: 1.7305103117419827

Epoch: 5| Step: 10
Training loss: 0.5614991784095764
Validation loss: 1.708964963113108

Epoch: 375| Step: 0
Training loss: 0.4685702323913574
Validation loss: 1.7044186630556661

Epoch: 5| Step: 1
Training loss: 0.46923017501831055
Validation loss: 1.6943492511267304

Epoch: 5| Step: 2
Training loss: 0.2506505250930786
Validation loss: 1.7296800382675663

Epoch: 5| Step: 3
Training loss: 0.326296865940094
Validation loss: 1.7559302647908528

Epoch: 5| Step: 4
Training loss: 0.5754337906837463
Validation loss: 1.7641788682629984

Epoch: 5| Step: 5
Training loss: 0.6955469250679016
Validation loss: 1.7779936175192557

Epoch: 5| Step: 6
Training loss: 0.4511978030204773
Validation loss: 1.759998958597901

Epoch: 5| Step: 7
Training loss: 0.26413634419441223
Validation loss: 1.7306205047074186

Epoch: 5| Step: 8
Training loss: 0.2821323275566101
Validation loss: 1.7205396621457991

Epoch: 5| Step: 9
Training loss: 0.3347618579864502
Validation loss: 1.6769293995313748

Epoch: 5| Step: 10
Training loss: 0.29987406730651855
Validation loss: 1.6787022172763784

Epoch: 376| Step: 0
Training loss: 0.3664824366569519
Validation loss: 1.6808296377940843

Epoch: 5| Step: 1
Training loss: 0.29503926634788513
Validation loss: 1.653720231466396

Epoch: 5| Step: 2
Training loss: 0.17786219716072083
Validation loss: 1.6602888376482072

Epoch: 5| Step: 3
Training loss: 0.57026606798172
Validation loss: 1.692265700268489

Epoch: 5| Step: 4
Training loss: 0.2712952196598053
Validation loss: 1.686377598393348

Epoch: 5| Step: 5
Training loss: 0.28803253173828125
Validation loss: 1.7197965543757203

Epoch: 5| Step: 6
Training loss: 0.29666876792907715
Validation loss: 1.7292711273316415

Epoch: 5| Step: 7
Training loss: 0.40138179063796997
Validation loss: 1.7323482459591282

Epoch: 5| Step: 8
Training loss: 0.8074480891227722
Validation loss: 1.7619960038892684

Epoch: 5| Step: 9
Training loss: 0.4995994567871094
Validation loss: 1.7590998962361326

Epoch: 5| Step: 10
Training loss: 0.4863753616809845
Validation loss: 1.764871892108712

Epoch: 377| Step: 0
Training loss: 0.2775244414806366
Validation loss: 1.7436590335702384

Epoch: 5| Step: 1
Training loss: 0.366301029920578
Validation loss: 1.7365451410252561

Epoch: 5| Step: 2
Training loss: 0.43449288606643677
Validation loss: 1.7087080735032276

Epoch: 5| Step: 3
Training loss: 0.3722725808620453
Validation loss: 1.7102548191624303

Epoch: 5| Step: 4
Training loss: 0.3659180998802185
Validation loss: 1.7078540901983938

Epoch: 5| Step: 5
Training loss: 0.7461777925491333
Validation loss: 1.697647370317931

Epoch: 5| Step: 6
Training loss: 0.36063507199287415
Validation loss: 1.7182412967886975

Epoch: 5| Step: 7
Training loss: 0.4029589593410492
Validation loss: 1.7146632671356201

Epoch: 5| Step: 8
Training loss: 0.4036788046360016
Validation loss: 1.7333496027095343

Epoch: 5| Step: 9
Training loss: 0.4408462643623352
Validation loss: 1.7556192797999228

Epoch: 5| Step: 10
Training loss: 0.23068669438362122
Validation loss: 1.7260970530971405

Epoch: 378| Step: 0
Training loss: 0.4367576241493225
Validation loss: 1.7079021469239266

Epoch: 5| Step: 1
Training loss: 0.4332326054573059
Validation loss: 1.706775596064906

Epoch: 5| Step: 2
Training loss: 0.18364252150058746
Validation loss: 1.6832311461048741

Epoch: 5| Step: 3
Training loss: 0.41285401582717896
Validation loss: 1.673661660122615

Epoch: 5| Step: 4
Training loss: 0.34428316354751587
Validation loss: 1.6398048234242264

Epoch: 5| Step: 5
Training loss: 0.2897571921348572
Validation loss: 1.635552522956684

Epoch: 5| Step: 6
Training loss: 0.5972344875335693
Validation loss: 1.6845550972928283

Epoch: 5| Step: 7
Training loss: 0.35570353269577026
Validation loss: 1.6607244732559368

Epoch: 5| Step: 8
Training loss: 0.4060518741607666
Validation loss: 1.69894451479758

Epoch: 5| Step: 9
Training loss: 0.35886335372924805
Validation loss: 1.6805720957376624

Epoch: 5| Step: 10
Training loss: 0.5925326943397522
Validation loss: 1.6625448196165022

Epoch: 379| Step: 0
Training loss: 0.30554622411727905
Validation loss: 1.6603635164999193

Epoch: 5| Step: 1
Training loss: 0.4018377661705017
Validation loss: 1.7062934778069938

Epoch: 5| Step: 2
Training loss: 0.582011342048645
Validation loss: 1.7217444155805854

Epoch: 5| Step: 3
Training loss: 0.3275172710418701
Validation loss: 1.7164281619492399

Epoch: 5| Step: 4
Training loss: 0.4370662569999695
Validation loss: 1.736837193530093

Epoch: 5| Step: 5
Training loss: 0.41185101866722107
Validation loss: 1.7555343002401373

Epoch: 5| Step: 6
Training loss: 0.12565168738365173
Validation loss: 1.7417719492348291

Epoch: 5| Step: 7
Training loss: 0.3544541299343109
Validation loss: 1.7281122182005195

Epoch: 5| Step: 8
Training loss: 0.314109742641449
Validation loss: 1.748531037761319

Epoch: 5| Step: 9
Training loss: 0.3597319722175598
Validation loss: 1.7132306175847207

Epoch: 5| Step: 10
Training loss: 0.6493779420852661
Validation loss: 1.7230483870352469

Epoch: 380| Step: 0
Training loss: 0.41979312896728516
Validation loss: 1.7017290476829774

Epoch: 5| Step: 1
Training loss: 0.7759734392166138
Validation loss: 1.6957224517740228

Epoch: 5| Step: 2
Training loss: 0.29308241605758667
Validation loss: 1.685389204691815

Epoch: 5| Step: 3
Training loss: 0.3410147428512573
Validation loss: 1.674036930966121

Epoch: 5| Step: 4
Training loss: 0.3269873261451721
Validation loss: 1.684615849166788

Epoch: 5| Step: 5
Training loss: 0.1836594045162201
Validation loss: 1.6773939030144804

Epoch: 5| Step: 6
Training loss: 0.44945257902145386
Validation loss: 1.650856448758033

Epoch: 5| Step: 7
Training loss: 0.361364483833313
Validation loss: 1.6810852045653968

Epoch: 5| Step: 8
Training loss: 0.4497665464878082
Validation loss: 1.668803176572246

Epoch: 5| Step: 9
Training loss: 0.26871544122695923
Validation loss: 1.6550036707232076

Epoch: 5| Step: 10
Training loss: 0.3152979612350464
Validation loss: 1.6836592689637215

Epoch: 381| Step: 0
Training loss: 0.23026204109191895
Validation loss: 1.6919333806601904

Epoch: 5| Step: 1
Training loss: 0.1550942361354828
Validation loss: 1.7036300051596858

Epoch: 5| Step: 2
Training loss: 0.41765785217285156
Validation loss: 1.7126676869648758

Epoch: 5| Step: 3
Training loss: 0.26082777976989746
Validation loss: 1.6952146971097557

Epoch: 5| Step: 4
Training loss: 0.3952289819717407
Validation loss: 1.647585343289119

Epoch: 5| Step: 5
Training loss: 0.328136146068573
Validation loss: 1.652573420155433

Epoch: 5| Step: 6
Training loss: 0.29383760690689087
Validation loss: 1.6420592928445468

Epoch: 5| Step: 7
Training loss: 0.6351205110549927
Validation loss: 1.645254897814925

Epoch: 5| Step: 8
Training loss: 0.4402347505092621
Validation loss: 1.654757506103926

Epoch: 5| Step: 9
Training loss: 0.46708226203918457
Validation loss: 1.6243641966132707

Epoch: 5| Step: 10
Training loss: 0.4164990186691284
Validation loss: 1.6123981168193202

Epoch: 382| Step: 0
Training loss: 0.44456368684768677
Validation loss: 1.6281954473064792

Epoch: 5| Step: 1
Training loss: 0.17733515799045563
Validation loss: 1.6442460206247145

Epoch: 5| Step: 2
Training loss: 0.30675822496414185
Validation loss: 1.6093780558596376

Epoch: 5| Step: 3
Training loss: 0.3122601807117462
Validation loss: 1.6682423853105115

Epoch: 5| Step: 4
Training loss: 0.4245900511741638
Validation loss: 1.6735187307480843

Epoch: 5| Step: 5
Training loss: 0.3878612220287323
Validation loss: 1.6782890212151311

Epoch: 5| Step: 6
Training loss: 0.26368457078933716
Validation loss: 1.6996314487149637

Epoch: 5| Step: 7
Training loss: 0.461186945438385
Validation loss: 1.6844660902536044

Epoch: 5| Step: 8
Training loss: 0.2650724947452545
Validation loss: 1.687125789221897

Epoch: 5| Step: 9
Training loss: 0.6461186408996582
Validation loss: 1.7108981929799563

Epoch: 5| Step: 10
Training loss: 0.38155385851860046
Validation loss: 1.7316543863665672

Epoch: 383| Step: 0
Training loss: 0.3605790138244629
Validation loss: 1.7613703230375886

Epoch: 5| Step: 1
Training loss: 0.16574589908123016
Validation loss: 1.725520166017676

Epoch: 5| Step: 2
Training loss: 0.5644040107727051
Validation loss: 1.7311400726277342

Epoch: 5| Step: 3
Training loss: 0.2786743640899658
Validation loss: 1.7118011648936937

Epoch: 5| Step: 4
Training loss: 0.236196368932724
Validation loss: 1.6665538946787517

Epoch: 5| Step: 5
Training loss: 0.5127540826797485
Validation loss: 1.6421201177822646

Epoch: 5| Step: 6
Training loss: 0.5080269575119019
Validation loss: 1.662672209483321

Epoch: 5| Step: 7
Training loss: 0.6157187223434448
Validation loss: 1.6977880744523899

Epoch: 5| Step: 8
Training loss: 0.3936704695224762
Validation loss: 1.6438171748192079

Epoch: 5| Step: 9
Training loss: 0.3810374140739441
Validation loss: 1.6546735276458084

Epoch: 5| Step: 10
Training loss: 0.24552053213119507
Validation loss: 1.6359127131841515

Epoch: 384| Step: 0
Training loss: 0.3925027847290039
Validation loss: 1.6515634393179288

Epoch: 5| Step: 1
Training loss: 0.4351179003715515
Validation loss: 1.6880436481968049

Epoch: 5| Step: 2
Training loss: 0.18941952288150787
Validation loss: 1.6886440912882488

Epoch: 5| Step: 3
Training loss: 0.5250006914138794
Validation loss: 1.665130840834751

Epoch: 5| Step: 4
Training loss: 0.25606268644332886
Validation loss: 1.6705079796493694

Epoch: 5| Step: 5
Training loss: 0.6002209782600403
Validation loss: 1.6621820490847352

Epoch: 5| Step: 6
Training loss: 0.2578355371952057
Validation loss: 1.6402746605616745

Epoch: 5| Step: 7
Training loss: 0.15690097212791443
Validation loss: 1.6506035238183954

Epoch: 5| Step: 8
Training loss: 0.4224891662597656
Validation loss: 1.6386909228499218

Epoch: 5| Step: 9
Training loss: 0.44371214509010315
Validation loss: 1.6397433947491389

Epoch: 5| Step: 10
Training loss: 0.4647110402584076
Validation loss: 1.6482778249248382

Epoch: 385| Step: 0
Training loss: 0.23628106713294983
Validation loss: 1.6776440822949974

Epoch: 5| Step: 1
Training loss: 0.2505994439125061
Validation loss: 1.7034296938168105

Epoch: 5| Step: 2
Training loss: 0.31680941581726074
Validation loss: 1.693024489187425

Epoch: 5| Step: 3
Training loss: 0.46538639068603516
Validation loss: 1.7098251414555374

Epoch: 5| Step: 4
Training loss: 0.3194872736930847
Validation loss: 1.749606401689591

Epoch: 5| Step: 5
Training loss: 0.37056538462638855
Validation loss: 1.7721207885332004

Epoch: 5| Step: 6
Training loss: 0.4240519404411316
Validation loss: 1.7774595317020212

Epoch: 5| Step: 7
Training loss: 0.28270816802978516
Validation loss: 1.7351315329151769

Epoch: 5| Step: 8
Training loss: 0.550821840763092
Validation loss: 1.7291519206057313

Epoch: 5| Step: 9
Training loss: 0.2854461073875427
Validation loss: 1.718094712944441

Epoch: 5| Step: 10
Training loss: 0.4352278709411621
Validation loss: 1.7076803817543933

Epoch: 386| Step: 0
Training loss: 0.18202099204063416
Validation loss: 1.719697859979445

Epoch: 5| Step: 1
Training loss: 0.3279949724674225
Validation loss: 1.7027181694584508

Epoch: 5| Step: 2
Training loss: 0.34508001804351807
Validation loss: 1.6825163108046337

Epoch: 5| Step: 3
Training loss: 0.4679492115974426
Validation loss: 1.7039424809076453

Epoch: 5| Step: 4
Training loss: 0.17125795781612396
Validation loss: 1.6750361880948466

Epoch: 5| Step: 5
Training loss: 0.47079333662986755
Validation loss: 1.7280356396910965

Epoch: 5| Step: 6
Training loss: 0.3796354830265045
Validation loss: 1.7492225798227454

Epoch: 5| Step: 7
Training loss: 0.2963252663612366
Validation loss: 1.8071738443066996

Epoch: 5| Step: 8
Training loss: 0.9757281541824341
Validation loss: 1.8719811362604941

Epoch: 5| Step: 9
Training loss: 0.34739965200424194
Validation loss: 1.8203890977367279

Epoch: 5| Step: 10
Training loss: 0.431883305311203
Validation loss: 1.7807382973291541

Epoch: 387| Step: 0
Training loss: 0.27530044317245483
Validation loss: 1.7631827887668405

Epoch: 5| Step: 1
Training loss: 0.17616213858127594
Validation loss: 1.697511871655782

Epoch: 5| Step: 2
Training loss: 0.2932334542274475
Validation loss: 1.7050707929877824

Epoch: 5| Step: 3
Training loss: 0.311810165643692
Validation loss: 1.6810074390903595

Epoch: 5| Step: 4
Training loss: 0.8855354189872742
Validation loss: 1.6748769744749992

Epoch: 5| Step: 5
Training loss: 0.27798813581466675
Validation loss: 1.6629142171593123

Epoch: 5| Step: 6
Training loss: 0.2910160422325134
Validation loss: 1.660598688869066

Epoch: 5| Step: 7
Training loss: 0.4597231447696686
Validation loss: 1.6388047331122941

Epoch: 5| Step: 8
Training loss: 0.5187153220176697
Validation loss: 1.6504125684820197

Epoch: 5| Step: 9
Training loss: 0.45572763681411743
Validation loss: 1.6539071836779196

Epoch: 5| Step: 10
Training loss: 0.2974851131439209
Validation loss: 1.6539361694807648

Epoch: 388| Step: 0
Training loss: 0.43149471282958984
Validation loss: 1.6769484268721713

Epoch: 5| Step: 1
Training loss: 0.2904003858566284
Validation loss: 1.7219873833399948

Epoch: 5| Step: 2
Training loss: 0.6081908345222473
Validation loss: 1.73925446438533

Epoch: 5| Step: 3
Training loss: 0.27460092306137085
Validation loss: 1.7027582737707323

Epoch: 5| Step: 4
Training loss: 0.2596939504146576
Validation loss: 1.7095900197182932

Epoch: 5| Step: 5
Training loss: 0.43895411491394043
Validation loss: 1.6872489913817375

Epoch: 5| Step: 6
Training loss: 0.3312729597091675
Validation loss: 1.6562094983234201

Epoch: 5| Step: 7
Training loss: 0.28063347935676575
Validation loss: 1.6426001466730589

Epoch: 5| Step: 8
Training loss: 0.3691153824329376
Validation loss: 1.6512797865816342

Epoch: 5| Step: 9
Training loss: 0.5147644281387329
Validation loss: 1.6400692834649035

Epoch: 5| Step: 10
Training loss: 0.2906092405319214
Validation loss: 1.7055989785860943

Epoch: 389| Step: 0
Training loss: 0.23366260528564453
Validation loss: 1.702866518369285

Epoch: 5| Step: 1
Training loss: 0.3483651876449585
Validation loss: 1.7200124289399834

Epoch: 5| Step: 2
Training loss: 0.34049010276794434
Validation loss: 1.7173259181361045

Epoch: 5| Step: 3
Training loss: 0.32073774933815
Validation loss: 1.6985525495262557

Epoch: 5| Step: 4
Training loss: 0.21073374152183533
Validation loss: 1.674117745891694

Epoch: 5| Step: 5
Training loss: 0.6543965339660645
Validation loss: 1.6436044496874656

Epoch: 5| Step: 6
Training loss: 0.2158328741788864
Validation loss: 1.6400648022210726

Epoch: 5| Step: 7
Training loss: 0.4950549602508545
Validation loss: 1.6511377339722009

Epoch: 5| Step: 8
Training loss: 0.5667245984077454
Validation loss: 1.6300876755868234

Epoch: 5| Step: 9
Training loss: 0.2705952227115631
Validation loss: 1.6774561610273135

Epoch: 5| Step: 10
Training loss: 0.25060805678367615
Validation loss: 1.6837092048378401

Epoch: 390| Step: 0
Training loss: 0.20734591782093048
Validation loss: 1.7050905048206288

Epoch: 5| Step: 1
Training loss: 0.37573426961898804
Validation loss: 1.7392862253291632

Epoch: 5| Step: 2
Training loss: 0.3430381417274475
Validation loss: 1.7640951269416398

Epoch: 5| Step: 3
Training loss: 0.39642781019210815
Validation loss: 1.7166186096847698

Epoch: 5| Step: 4
Training loss: 0.40031570196151733
Validation loss: 1.7147190045284968

Epoch: 5| Step: 5
Training loss: 0.451500803232193
Validation loss: 1.7151821185183782

Epoch: 5| Step: 6
Training loss: 0.273611843585968
Validation loss: 1.7140861608648812

Epoch: 5| Step: 7
Training loss: 0.45811980962753296
Validation loss: 1.7095873291774462

Epoch: 5| Step: 8
Training loss: 0.6260225176811218
Validation loss: 1.70842699081667

Epoch: 5| Step: 9
Training loss: 0.25649863481521606
Validation loss: 1.6954861148711173

Epoch: 5| Step: 10
Training loss: 0.40075045824050903
Validation loss: 1.7116840295894171

Epoch: 391| Step: 0
Training loss: 0.38149094581604004
Validation loss: 1.6792088708569926

Epoch: 5| Step: 1
Training loss: 0.322078138589859
Validation loss: 1.6777718656806535

Epoch: 5| Step: 2
Training loss: 0.26165422797203064
Validation loss: 1.6847728683102516

Epoch: 5| Step: 3
Training loss: 0.38222768902778625
Validation loss: 1.7101890117891374

Epoch: 5| Step: 4
Training loss: 0.5119343996047974
Validation loss: 1.6963205811797932

Epoch: 5| Step: 5
Training loss: 0.39481139183044434
Validation loss: 1.7207468094364289

Epoch: 5| Step: 6
Training loss: 0.22684916853904724
Validation loss: 1.6803096417457826

Epoch: 5| Step: 7
Training loss: 0.40546560287475586
Validation loss: 1.6654893544412428

Epoch: 5| Step: 8
Training loss: 0.46462908387184143
Validation loss: 1.6418567934343893

Epoch: 5| Step: 9
Training loss: 0.5007299184799194
Validation loss: 1.6402900513782297

Epoch: 5| Step: 10
Training loss: 0.4302929639816284
Validation loss: 1.6947236843006586

Epoch: 392| Step: 0
Training loss: 0.306770920753479
Validation loss: 1.6911320711976738

Epoch: 5| Step: 1
Training loss: 0.3478582799434662
Validation loss: 1.6855856833919403

Epoch: 5| Step: 2
Training loss: 0.27303749322891235
Validation loss: 1.6700978830296507

Epoch: 5| Step: 3
Training loss: 0.18259498476982117
Validation loss: 1.6814177625922746

Epoch: 5| Step: 4
Training loss: 0.243533656001091
Validation loss: 1.6833440065383911

Epoch: 5| Step: 5
Training loss: 0.31713324785232544
Validation loss: 1.6613045930862427

Epoch: 5| Step: 6
Training loss: 0.44394248723983765
Validation loss: 1.6742966482716222

Epoch: 5| Step: 7
Training loss: 0.5045573711395264
Validation loss: 1.668875616083863

Epoch: 5| Step: 8
Training loss: 0.4442853033542633
Validation loss: 1.622391003434376

Epoch: 5| Step: 9
Training loss: 0.5036925077438354
Validation loss: 1.6093716544489707

Epoch: 5| Step: 10
Training loss: 0.4620884358882904
Validation loss: 1.6022002799536592

Epoch: 393| Step: 0
Training loss: 0.32410627603530884
Validation loss: 1.6072282624501053

Epoch: 5| Step: 1
Training loss: 0.3724084496498108
Validation loss: 1.664404663988339

Epoch: 5| Step: 2
Training loss: 0.21161803603172302
Validation loss: 1.6901451797895535

Epoch: 5| Step: 3
Training loss: 0.4082452654838562
Validation loss: 1.7451161479437223

Epoch: 5| Step: 4
Training loss: 0.42083629965782166
Validation loss: 1.755712588628133

Epoch: 5| Step: 5
Training loss: 0.27608543634414673
Validation loss: 1.723032074589883

Epoch: 5| Step: 6
Training loss: 0.2952653765678406
Validation loss: 1.6927569438052434

Epoch: 5| Step: 7
Training loss: 0.25287342071533203
Validation loss: 1.6454152855821835

Epoch: 5| Step: 8
Training loss: 0.7247331738471985
Validation loss: 1.6729257978418821

Epoch: 5| Step: 9
Training loss: 0.41720739006996155
Validation loss: 1.6849245807175994

Epoch: 5| Step: 10
Training loss: 0.44715622067451477
Validation loss: 1.6698197113570346

Epoch: 394| Step: 0
Training loss: 0.5567250847816467
Validation loss: 1.660782411534299

Epoch: 5| Step: 1
Training loss: 0.30948176980018616
Validation loss: 1.617365728142441

Epoch: 5| Step: 2
Training loss: 0.42752885818481445
Validation loss: 1.6034121974822013

Epoch: 5| Step: 3
Training loss: 0.33239972591400146
Validation loss: 1.6074242002220565

Epoch: 5| Step: 4
Training loss: 0.2685072124004364
Validation loss: 1.631281437412385

Epoch: 5| Step: 5
Training loss: 0.32509198784828186
Validation loss: 1.6388691394559798

Epoch: 5| Step: 6
Training loss: 0.314947247505188
Validation loss: 1.7176216904835035

Epoch: 5| Step: 7
Training loss: 0.223481222987175
Validation loss: 1.7309764303186888

Epoch: 5| Step: 8
Training loss: 0.5090094208717346
Validation loss: 1.7397259691710114

Epoch: 5| Step: 9
Training loss: 0.2900516986846924
Validation loss: 1.7629347103898243

Epoch: 5| Step: 10
Training loss: 0.6912106275558472
Validation loss: 1.7326817025420487

Epoch: 395| Step: 0
Training loss: 0.303825318813324
Validation loss: 1.7074676521362797

Epoch: 5| Step: 1
Training loss: 0.44305139780044556
Validation loss: 1.6849105588851436

Epoch: 5| Step: 2
Training loss: 0.1282215118408203
Validation loss: 1.6549246606006418

Epoch: 5| Step: 3
Training loss: 0.24275317788124084
Validation loss: 1.666698419919578

Epoch: 5| Step: 4
Training loss: 0.37734800577163696
Validation loss: 1.6915551283026253

Epoch: 5| Step: 5
Training loss: 0.279436856508255
Validation loss: 1.6636207372911516

Epoch: 5| Step: 6
Training loss: 0.5884374380111694
Validation loss: 1.6692376290598223

Epoch: 5| Step: 7
Training loss: 0.21034984290599823
Validation loss: 1.6474980782437068

Epoch: 5| Step: 8
Training loss: 0.3045079708099365
Validation loss: 1.6658899732815322

Epoch: 5| Step: 9
Training loss: 0.39438527822494507
Validation loss: 1.670306633877498

Epoch: 5| Step: 10
Training loss: 0.33121103048324585
Validation loss: 1.6866090092607724

Epoch: 396| Step: 0
Training loss: 0.29334282875061035
Validation loss: 1.6390606100841234

Epoch: 5| Step: 1
Training loss: 0.3816758990287781
Validation loss: 1.654406100832006

Epoch: 5| Step: 2
Training loss: 0.17856788635253906
Validation loss: 1.6056479997532342

Epoch: 5| Step: 3
Training loss: 0.30073243379592896
Validation loss: 1.6072077546068417

Epoch: 5| Step: 4
Training loss: 0.24082550406455994
Validation loss: 1.6142916858837169

Epoch: 5| Step: 5
Training loss: 0.3853583335876465
Validation loss: 1.6294113179688812

Epoch: 5| Step: 6
Training loss: 0.29052555561065674
Validation loss: 1.6527387685673212

Epoch: 5| Step: 7
Training loss: 0.3031901717185974
Validation loss: 1.7009746797623173

Epoch: 5| Step: 8
Training loss: 0.5358093976974487
Validation loss: 1.7189156393851004

Epoch: 5| Step: 9
Training loss: 0.4852277636528015
Validation loss: 1.6792239489093903

Epoch: 5| Step: 10
Training loss: 0.35041821002960205
Validation loss: 1.677317597532785

Epoch: 397| Step: 0
Training loss: 0.25043338537216187
Validation loss: 1.659030971988555

Epoch: 5| Step: 1
Training loss: 0.42325472831726074
Validation loss: 1.6808252744777228

Epoch: 5| Step: 2
Training loss: 0.20693521201610565
Validation loss: 1.6868700006956696

Epoch: 5| Step: 3
Training loss: 0.30273905396461487
Validation loss: 1.6927180085130917

Epoch: 5| Step: 4
Training loss: 0.21264132857322693
Validation loss: 1.6702549483186455

Epoch: 5| Step: 5
Training loss: 0.688319981098175
Validation loss: 1.6441409728860343

Epoch: 5| Step: 6
Training loss: 0.47337454557418823
Validation loss: 1.6227835468066636

Epoch: 5| Step: 7
Training loss: 0.3396361470222473
Validation loss: 1.5879504654997139

Epoch: 5| Step: 8
Training loss: 0.2954789102077484
Validation loss: 1.6140513227831932

Epoch: 5| Step: 9
Training loss: 0.24253840744495392
Validation loss: 1.6284217937018282

Epoch: 5| Step: 10
Training loss: 0.39438527822494507
Validation loss: 1.6470009408971316

Epoch: 398| Step: 0
Training loss: 0.35141149163246155
Validation loss: 1.6595846388929634

Epoch: 5| Step: 1
Training loss: 0.47746676206588745
Validation loss: 1.648965903507766

Epoch: 5| Step: 2
Training loss: 0.18789997696876526
Validation loss: 1.6867356505445255

Epoch: 5| Step: 3
Training loss: 0.2730758488178253
Validation loss: 1.6378674712232364

Epoch: 5| Step: 4
Training loss: 0.2503172755241394
Validation loss: 1.6748126245314074

Epoch: 5| Step: 5
Training loss: 0.2946329116821289
Validation loss: 1.6633852809988043

Epoch: 5| Step: 6
Training loss: 0.34841710329055786
Validation loss: 1.6962696762495144

Epoch: 5| Step: 7
Training loss: 0.7609701752662659
Validation loss: 1.6697124358146422

Epoch: 5| Step: 8
Training loss: 0.3561103045940399
Validation loss: 1.6745654075376448

Epoch: 5| Step: 9
Training loss: 0.18988054990768433
Validation loss: 1.6856143064396356

Epoch: 5| Step: 10
Training loss: 0.19233174622058868
Validation loss: 1.616540701158585

Epoch: 399| Step: 0
Training loss: 0.3054620325565338
Validation loss: 1.6197797213831255

Epoch: 5| Step: 1
Training loss: 0.38865646719932556
Validation loss: 1.6020951822239866

Epoch: 5| Step: 2
Training loss: 0.3167746365070343
Validation loss: 1.63129807800375

Epoch: 5| Step: 3
Training loss: 0.17972488701343536
Validation loss: 1.6219548807349256

Epoch: 5| Step: 4
Training loss: 0.3481774926185608
Validation loss: 1.5983468409507506

Epoch: 5| Step: 5
Training loss: 0.26080814003944397
Validation loss: 1.6290954876971502

Epoch: 5| Step: 6
Training loss: 0.23713627457618713
Validation loss: 1.6069534965740737

Epoch: 5| Step: 7
Training loss: 0.7079777121543884
Validation loss: 1.674964533057264

Epoch: 5| Step: 8
Training loss: 0.2546427845954895
Validation loss: 1.6881785444034043

Epoch: 5| Step: 9
Training loss: 0.20764431357383728
Validation loss: 1.6863899320684455

Epoch: 5| Step: 10
Training loss: 0.21543633937835693
Validation loss: 1.6737565635353007

Epoch: 400| Step: 0
Training loss: 0.48298510909080505
Validation loss: 1.6812267316285001

Epoch: 5| Step: 1
Training loss: 0.33858609199523926
Validation loss: 1.6819272207957443

Epoch: 5| Step: 2
Training loss: 0.23374482989311218
Validation loss: 1.7000863231638426

Epoch: 5| Step: 3
Training loss: 0.22092540562152863
Validation loss: 1.6591754126292404

Epoch: 5| Step: 4
Training loss: 0.31447556614875793
Validation loss: 1.647504468117991

Epoch: 5| Step: 5
Training loss: 0.3932149410247803
Validation loss: 1.6279842930455362

Epoch: 5| Step: 6
Training loss: 0.2925182282924652
Validation loss: 1.613585202924667

Epoch: 5| Step: 7
Training loss: 0.3551107943058014
Validation loss: 1.6547608888277443

Epoch: 5| Step: 8
Training loss: 0.31971508264541626
Validation loss: 1.6162723713023688

Epoch: 5| Step: 9
Training loss: 0.20911462604999542
Validation loss: 1.6483234000462357

Epoch: 5| Step: 10
Training loss: 0.2414124459028244
Validation loss: 1.6476096748023905

Epoch: 401| Step: 0
Training loss: 0.1724654883146286
Validation loss: 1.6601345885184504

Epoch: 5| Step: 1
Training loss: 0.6305611729621887
Validation loss: 1.6975880028099142

Epoch: 5| Step: 2
Training loss: 0.21197418868541718
Validation loss: 1.6837414439006517

Epoch: 5| Step: 3
Training loss: 0.3474349081516266
Validation loss: 1.648921230787872

Epoch: 5| Step: 4
Training loss: 0.25500020384788513
Validation loss: 1.6317933080016926

Epoch: 5| Step: 5
Training loss: 0.21697600185871124
Validation loss: 1.6262274839544808

Epoch: 5| Step: 6
Training loss: 0.3167385756969452
Validation loss: 1.6180923190168155

Epoch: 5| Step: 7
Training loss: 0.34826886653900146
Validation loss: 1.6277571544852307

Epoch: 5| Step: 8
Training loss: 0.29626959562301636
Validation loss: 1.6230461725624659

Epoch: 5| Step: 9
Training loss: 0.3624703586101532
Validation loss: 1.6197078458724483

Epoch: 5| Step: 10
Training loss: 0.3478538691997528
Validation loss: 1.6433667335458981

Epoch: 402| Step: 0
Training loss: 0.31561148166656494
Validation loss: 1.6413107674608949

Epoch: 5| Step: 1
Training loss: 0.18438102304935455
Validation loss: 1.6580607096354167

Epoch: 5| Step: 2
Training loss: 0.5720996856689453
Validation loss: 1.6818778155952372

Epoch: 5| Step: 3
Training loss: 0.438495934009552
Validation loss: 1.6564702410851755

Epoch: 5| Step: 4
Training loss: 0.3176327347755432
Validation loss: 1.7006391761123494

Epoch: 5| Step: 5
Training loss: 0.2504097819328308
Validation loss: 1.6648232680495068

Epoch: 5| Step: 6
Training loss: 0.14125238358974457
Validation loss: 1.629084260232987

Epoch: 5| Step: 7
Training loss: 0.25376003980636597
Validation loss: 1.6244556891020907

Epoch: 5| Step: 8
Training loss: 0.29721322655677795
Validation loss: 1.5648175900982273

Epoch: 5| Step: 9
Training loss: 0.3523404598236084
Validation loss: 1.5691659130075926

Epoch: 5| Step: 10
Training loss: 0.3165685832500458
Validation loss: 1.5753297703240507

Epoch: 403| Step: 0
Training loss: 0.1941104382276535
Validation loss: 1.5684797622824227

Epoch: 5| Step: 1
Training loss: 0.4207889437675476
Validation loss: 1.5520103413571593

Epoch: 5| Step: 2
Training loss: 0.23549842834472656
Validation loss: 1.5845408080726542

Epoch: 5| Step: 3
Training loss: 0.3289332687854767
Validation loss: 1.5837419340687413

Epoch: 5| Step: 4
Training loss: 0.20445410907268524
Validation loss: 1.589349191675904

Epoch: 5| Step: 5
Training loss: 0.4217677116394043
Validation loss: 1.6035634932979461

Epoch: 5| Step: 6
Training loss: 0.2397605925798416
Validation loss: 1.6040122457729873

Epoch: 5| Step: 7
Training loss: 0.3433449864387512
Validation loss: 1.6388764035317205

Epoch: 5| Step: 8
Training loss: 0.15248730778694153
Validation loss: 1.5993307457175305

Epoch: 5| Step: 9
Training loss: 0.59807950258255
Validation loss: 1.6024577656099874

Epoch: 5| Step: 10
Training loss: 0.16840165853500366
Validation loss: 1.6006562978990617

Epoch: 404| Step: 0
Training loss: 0.2811874747276306
Validation loss: 1.6047444112839238

Epoch: 5| Step: 1
Training loss: 0.2289702445268631
Validation loss: 1.6101411029856691

Epoch: 5| Step: 2
Training loss: 0.247107595205307
Validation loss: 1.6054298928988877

Epoch: 5| Step: 3
Training loss: 0.19843550026416779
Validation loss: 1.5928191292670466

Epoch: 5| Step: 4
Training loss: 0.2232888638973236
Validation loss: 1.6037778931279336

Epoch: 5| Step: 5
Training loss: 0.2288396805524826
Validation loss: 1.6127592325210571

Epoch: 5| Step: 6
Training loss: 0.311462938785553
Validation loss: 1.6084401030694284

Epoch: 5| Step: 7
Training loss: 0.2660600244998932
Validation loss: 1.6425246115653747

Epoch: 5| Step: 8
Training loss: 0.4978809952735901
Validation loss: 1.6711193451317408

Epoch: 5| Step: 9
Training loss: 0.31280574202537537
Validation loss: 1.6782413477538733

Epoch: 5| Step: 10
Training loss: 0.25159040093421936
Validation loss: 1.6381662212392336

Epoch: 405| Step: 0
Training loss: 0.33968424797058105
Validation loss: 1.6592342699727705

Epoch: 5| Step: 1
Training loss: 0.12111005932092667
Validation loss: 1.6275916150821153

Epoch: 5| Step: 2
Training loss: 0.29197296500205994
Validation loss: 1.6279434619411346

Epoch: 5| Step: 3
Training loss: 0.27906423807144165
Validation loss: 1.59815502038566

Epoch: 5| Step: 4
Training loss: 0.27355465292930603
Validation loss: 1.6143915755774385

Epoch: 5| Step: 5
Training loss: 0.2874564528465271
Validation loss: 1.606485216848312

Epoch: 5| Step: 6
Training loss: 0.28980737924575806
Validation loss: 1.6347955080770677

Epoch: 5| Step: 7
Training loss: 0.20025241374969482
Validation loss: 1.642108291708013

Epoch: 5| Step: 8
Training loss: 0.27309995889663696
Validation loss: 1.637719169739754

Epoch: 5| Step: 9
Training loss: 0.3635141849517822
Validation loss: 1.641138481837447

Epoch: 5| Step: 10
Training loss: 0.4968050718307495
Validation loss: 1.6204136879213396

Epoch: 406| Step: 0
Training loss: 0.28551048040390015
Validation loss: 1.6291883722428353

Epoch: 5| Step: 1
Training loss: 0.5745899081230164
Validation loss: 1.6180395093015445

Epoch: 5| Step: 2
Training loss: 0.2496442347764969
Validation loss: 1.6209209574166166

Epoch: 5| Step: 3
Training loss: 0.28922706842422485
Validation loss: 1.6211056350379862

Epoch: 5| Step: 4
Training loss: 0.2746122479438782
Validation loss: 1.6743558286338724

Epoch: 5| Step: 5
Training loss: 0.25795674324035645
Validation loss: 1.6694282806047829

Epoch: 5| Step: 6
Training loss: 0.3278980851173401
Validation loss: 1.6617594700987621

Epoch: 5| Step: 7
Training loss: 0.24131126701831818
Validation loss: 1.6554400587594638

Epoch: 5| Step: 8
Training loss: 0.3136802315711975
Validation loss: 1.6191715040514547

Epoch: 5| Step: 9
Training loss: 0.23450812697410583
Validation loss: 1.6038392166937552

Epoch: 5| Step: 10
Training loss: 0.15428952872753143
Validation loss: 1.5967887704090407

Epoch: 407| Step: 0
Training loss: 0.25770872831344604
Validation loss: 1.5929913841268069

Epoch: 5| Step: 1
Training loss: 0.6553708910942078
Validation loss: 1.5905410705074188

Epoch: 5| Step: 2
Training loss: 0.28457194566726685
Validation loss: 1.574120339526925

Epoch: 5| Step: 3
Training loss: 0.17547999322414398
Validation loss: 1.5740339192011024

Epoch: 5| Step: 4
Training loss: 0.17008747160434723
Validation loss: 1.5883402619310605

Epoch: 5| Step: 5
Training loss: 0.21517714858055115
Validation loss: 1.6036273612770984

Epoch: 5| Step: 6
Training loss: 0.3078595995903015
Validation loss: 1.6127596004034883

Epoch: 5| Step: 7
Training loss: 0.28287798166275024
Validation loss: 1.6207953729937155

Epoch: 5| Step: 8
Training loss: 0.27174270153045654
Validation loss: 1.61614857181426

Epoch: 5| Step: 9
Training loss: 0.24387094378471375
Validation loss: 1.6056834766941686

Epoch: 5| Step: 10
Training loss: 0.3304590880870819
Validation loss: 1.588146799354143

Epoch: 408| Step: 0
Training loss: 0.3472853899002075
Validation loss: 1.5761709238893242

Epoch: 5| Step: 1
Training loss: 0.1667517125606537
Validation loss: 1.5600775198269916

Epoch: 5| Step: 2
Training loss: 0.3516770005226135
Validation loss: 1.5623581781182239

Epoch: 5| Step: 3
Training loss: 0.19417592883110046
Validation loss: 1.5823676150332215

Epoch: 5| Step: 4
Training loss: 0.28352323174476624
Validation loss: 1.5628048309715845

Epoch: 5| Step: 5
Training loss: 0.21665354073047638
Validation loss: 1.6022006850088797

Epoch: 5| Step: 6
Training loss: 0.42934122681617737
Validation loss: 1.6208991267347848

Epoch: 5| Step: 7
Training loss: 0.2412342131137848
Validation loss: 1.6206252312147489

Epoch: 5| Step: 8
Training loss: 0.2545367479324341
Validation loss: 1.6646110498777

Epoch: 5| Step: 9
Training loss: 0.3120296597480774
Validation loss: 1.6676746952918269

Epoch: 5| Step: 10
Training loss: 0.26138997077941895
Validation loss: 1.668571376031445

Epoch: 409| Step: 0
Training loss: 0.12856397032737732
Validation loss: 1.6418066076053086

Epoch: 5| Step: 1
Training loss: 0.24825601279735565
Validation loss: 1.6398609440813783

Epoch: 5| Step: 2
Training loss: 0.2018022984266281
Validation loss: 1.6191165883054015

Epoch: 5| Step: 3
Training loss: 0.277537077665329
Validation loss: 1.627605983006057

Epoch: 5| Step: 4
Training loss: 0.2753613591194153
Validation loss: 1.6088145625206731

Epoch: 5| Step: 5
Training loss: 0.6697731018066406
Validation loss: 1.6147129356220205

Epoch: 5| Step: 6
Training loss: 0.20509573817253113
Validation loss: 1.6290854600168043

Epoch: 5| Step: 7
Training loss: 0.22970762848854065
Validation loss: 1.6513331282523371

Epoch: 5| Step: 8
Training loss: 0.19233985245227814
Validation loss: 1.5939357537095264

Epoch: 5| Step: 9
Training loss: 0.35901302099227905
Validation loss: 1.6581679621050436

Epoch: 5| Step: 10
Training loss: 0.28762006759643555
Validation loss: 1.6289526544591433

Epoch: 410| Step: 0
Training loss: 0.14950475096702576
Validation loss: 1.6438064658513634

Epoch: 5| Step: 1
Training loss: 0.37822985649108887
Validation loss: 1.6124210203847578

Epoch: 5| Step: 2
Training loss: 0.24052166938781738
Validation loss: 1.5893694848142645

Epoch: 5| Step: 3
Training loss: 0.14160682260990143
Validation loss: 1.5960490536946121

Epoch: 5| Step: 4
Training loss: 0.2100079506635666
Validation loss: 1.6074729939942718

Epoch: 5| Step: 5
Training loss: 0.24559693038463593
Validation loss: 1.5961795186483732

Epoch: 5| Step: 6
Training loss: 0.2924250662326813
Validation loss: 1.5908220327028664

Epoch: 5| Step: 7
Training loss: 0.297806978225708
Validation loss: 1.6156132631404425

Epoch: 5| Step: 8
Training loss: 0.5025433301925659
Validation loss: 1.6270154842766382

Epoch: 5| Step: 9
Training loss: 0.20435509085655212
Validation loss: 1.6487714231655162

Epoch: 5| Step: 10
Training loss: 0.40712031722068787
Validation loss: 1.6403280970870808

Epoch: 411| Step: 0
Training loss: 0.24351949989795685
Validation loss: 1.6583257029133458

Epoch: 5| Step: 1
Training loss: 0.16654805839061737
Validation loss: 1.6416278833984046

Epoch: 5| Step: 2
Training loss: 0.24768567085266113
Validation loss: 1.6777893638098111

Epoch: 5| Step: 3
Training loss: 0.5277986526489258
Validation loss: 1.6916595812766784

Epoch: 5| Step: 4
Training loss: 0.26287323236465454
Validation loss: 1.6337489171694684

Epoch: 5| Step: 5
Training loss: 0.3936542272567749
Validation loss: 1.6251667532869565

Epoch: 5| Step: 6
Training loss: 0.13106808066368103
Validation loss: 1.594443558364786

Epoch: 5| Step: 7
Training loss: 0.18678313493728638
Validation loss: 1.5860038124104983

Epoch: 5| Step: 8
Training loss: 0.24602010846138
Validation loss: 1.5394216839985182

Epoch: 5| Step: 9
Training loss: 0.34213918447494507
Validation loss: 1.564960592536516

Epoch: 5| Step: 10
Training loss: 0.24227425456047058
Validation loss: 1.5619309281790128

Epoch: 412| Step: 0
Training loss: 0.35418009757995605
Validation loss: 1.5675633786827006

Epoch: 5| Step: 1
Training loss: 0.14961950480937958
Validation loss: 1.582459783041349

Epoch: 5| Step: 2
Training loss: 0.15837393701076508
Validation loss: 1.5754426333212084

Epoch: 5| Step: 3
Training loss: 0.40282315015792847
Validation loss: 1.6339578705449258

Epoch: 5| Step: 4
Training loss: 0.2751586139202118
Validation loss: 1.6308030530970583

Epoch: 5| Step: 5
Training loss: 0.2513884902000427
Validation loss: 1.62097918346364

Epoch: 5| Step: 6
Training loss: 0.20680966973304749
Validation loss: 1.6214340771398237

Epoch: 5| Step: 7
Training loss: 0.21450893580913544
Validation loss: 1.5899645936104558

Epoch: 5| Step: 8
Training loss: 0.5384625196456909
Validation loss: 1.581716873312509

Epoch: 5| Step: 9
Training loss: 0.21675679087638855
Validation loss: 1.5657799782291535

Epoch: 5| Step: 10
Training loss: 0.16730210185050964
Validation loss: 1.589605471139313

Epoch: 413| Step: 0
Training loss: 0.20489530265331268
Validation loss: 1.579197778496691

Epoch: 5| Step: 1
Training loss: 0.22387933731079102
Validation loss: 1.601630901777616

Epoch: 5| Step: 2
Training loss: 0.49078455567359924
Validation loss: 1.5959694641892628

Epoch: 5| Step: 3
Training loss: 0.1604803204536438
Validation loss: 1.578427703149857

Epoch: 5| Step: 4
Training loss: 0.256079763174057
Validation loss: 1.5590043990842757

Epoch: 5| Step: 5
Training loss: 0.3142065107822418
Validation loss: 1.5411419817196426

Epoch: 5| Step: 6
Training loss: 0.3324093520641327
Validation loss: 1.4856895528813845

Epoch: 5| Step: 7
Training loss: 0.2279244214296341
Validation loss: 1.5109011556512566

Epoch: 5| Step: 8
Training loss: 0.3288472592830658
Validation loss: 1.4919392383226784

Epoch: 5| Step: 9
Training loss: 0.36723700165748596
Validation loss: 1.5000479477708057

Epoch: 5| Step: 10
Training loss: 0.1985214352607727
Validation loss: 1.485558138098768

Epoch: 414| Step: 0
Training loss: 0.5055011510848999
Validation loss: 1.5558025080670592

Epoch: 5| Step: 1
Training loss: 0.2281109094619751
Validation loss: 1.5948479239658644

Epoch: 5| Step: 2
Training loss: 0.4656505584716797
Validation loss: 1.6383381723075785

Epoch: 5| Step: 3
Training loss: 0.18480780720710754
Validation loss: 1.6924933669387654

Epoch: 5| Step: 4
Training loss: 0.27145010232925415
Validation loss: 1.6801279232066164

Epoch: 5| Step: 5
Training loss: 0.25390520691871643
Validation loss: 1.6604772485712522

Epoch: 5| Step: 6
Training loss: 0.18395109474658966
Validation loss: 1.6753414811626557

Epoch: 5| Step: 7
Training loss: 0.2830786406993866
Validation loss: 1.6401399284280755

Epoch: 5| Step: 8
Training loss: 0.3267621099948883
Validation loss: 1.6459180206380866

Epoch: 5| Step: 9
Training loss: 0.25416138768196106
Validation loss: 1.6571839932472474

Epoch: 5| Step: 10
Training loss: 0.36358827352523804
Validation loss: 1.612020827108814

Epoch: 415| Step: 0
Training loss: 0.2537637948989868
Validation loss: 1.601131481509055

Epoch: 5| Step: 1
Training loss: 0.29017582535743713
Validation loss: 1.5971627825049943

Epoch: 5| Step: 2
Training loss: 0.25050053000450134
Validation loss: 1.6278455885507728

Epoch: 5| Step: 3
Training loss: 0.298331081867218
Validation loss: 1.6429833904389413

Epoch: 5| Step: 4
Training loss: 0.21664142608642578
Validation loss: 1.6060853158274004

Epoch: 5| Step: 5
Training loss: 0.17993777990341187
Validation loss: 1.632322424201555

Epoch: 5| Step: 6
Training loss: 0.6357408165931702
Validation loss: 1.597773068694658

Epoch: 5| Step: 7
Training loss: 0.24650433659553528
Validation loss: 1.5968183650765368

Epoch: 5| Step: 8
Training loss: 0.21385088562965393
Validation loss: 1.5599135519355856

Epoch: 5| Step: 9
Training loss: 0.19546648859977722
Validation loss: 1.5588608493087113

Epoch: 5| Step: 10
Training loss: 0.2468254417181015
Validation loss: 1.5317306672373125

Epoch: 416| Step: 0
Training loss: 0.30070921778678894
Validation loss: 1.5585533598417878

Epoch: 5| Step: 1
Training loss: 0.15627430379390717
Validation loss: 1.5595007955387075

Epoch: 5| Step: 2
Training loss: 0.23748239874839783
Validation loss: 1.5670228478729085

Epoch: 5| Step: 3
Training loss: 0.2655249536037445
Validation loss: 1.5984917891922819

Epoch: 5| Step: 4
Training loss: 0.29258471727371216
Validation loss: 1.6000372414947839

Epoch: 5| Step: 5
Training loss: 0.3421441912651062
Validation loss: 1.6761071835794756

Epoch: 5| Step: 6
Training loss: 0.4842293858528137
Validation loss: 1.675344112098858

Epoch: 5| Step: 7
Training loss: 0.3149644136428833
Validation loss: 1.6547486910256006

Epoch: 5| Step: 8
Training loss: 0.31588053703308105
Validation loss: 1.6386207226783998

Epoch: 5| Step: 9
Training loss: 0.12771335244178772
Validation loss: 1.5979942083358765

Epoch: 5| Step: 10
Training loss: 0.2610540986061096
Validation loss: 1.5940179068555114

Epoch: 417| Step: 0
Training loss: 0.5476661920547485
Validation loss: 1.5700273462521133

Epoch: 5| Step: 1
Training loss: 0.34386542439460754
Validation loss: 1.5699230278691938

Epoch: 5| Step: 2
Training loss: 0.3844548165798187
Validation loss: 1.5878473148551038

Epoch: 5| Step: 3
Training loss: 0.21734198927879333
Validation loss: 1.5895555147560694

Epoch: 5| Step: 4
Training loss: 0.16019053757190704
Validation loss: 1.5813903167683592

Epoch: 5| Step: 5
Training loss: 0.18800124526023865
Validation loss: 1.597245334297098

Epoch: 5| Step: 6
Training loss: 0.1596585512161255
Validation loss: 1.5748682124640352

Epoch: 5| Step: 7
Training loss: 0.25305795669555664
Validation loss: 1.6153155988262546

Epoch: 5| Step: 8
Training loss: 0.2795214056968689
Validation loss: 1.6351511734788136

Epoch: 5| Step: 9
Training loss: 0.28653234243392944
Validation loss: 1.6546335335700744

Epoch: 5| Step: 10
Training loss: 0.18861114978790283
Validation loss: 1.6226440347650999

Epoch: 418| Step: 0
Training loss: 0.1355881541967392
Validation loss: 1.5961682399113972

Epoch: 5| Step: 1
Training loss: 0.4795893728733063
Validation loss: 1.5323627328359952

Epoch: 5| Step: 2
Training loss: 0.20832912623882294
Validation loss: 1.521534958193379

Epoch: 5| Step: 3
Training loss: 0.3508186936378479
Validation loss: 1.5227699497694611

Epoch: 5| Step: 4
Training loss: 0.21476897597312927
Validation loss: 1.5646718163644113

Epoch: 5| Step: 5
Training loss: 0.1907522976398468
Validation loss: 1.5961975897512128

Epoch: 5| Step: 6
Training loss: 0.2782481610774994
Validation loss: 1.5709284838809763

Epoch: 5| Step: 7
Training loss: 0.3097287714481354
Validation loss: 1.6107155930611394

Epoch: 5| Step: 8
Training loss: 0.20549626648426056
Validation loss: 1.6065647704626924

Epoch: 5| Step: 9
Training loss: 0.3404982089996338
Validation loss: 1.6138778553214124

Epoch: 5| Step: 10
Training loss: 0.11608865857124329
Validation loss: 1.619389933283611

Epoch: 419| Step: 0
Training loss: 0.2203035056591034
Validation loss: 1.6138846361508934

Epoch: 5| Step: 1
Training loss: 0.20945744216442108
Validation loss: 1.6327354895171298

Epoch: 5| Step: 2
Training loss: 0.16286030411720276
Validation loss: 1.6096607613307174

Epoch: 5| Step: 3
Training loss: 0.255041241645813
Validation loss: 1.603488617045905

Epoch: 5| Step: 4
Training loss: 0.26709118485450745
Validation loss: 1.611945955984054

Epoch: 5| Step: 5
Training loss: 0.3241441249847412
Validation loss: 1.6047097072806409

Epoch: 5| Step: 6
Training loss: 0.23112396895885468
Validation loss: 1.5729804321001934

Epoch: 5| Step: 7
Training loss: 0.16296926140785217
Validation loss: 1.5976710357973654

Epoch: 5| Step: 8
Training loss: 0.4983680844306946
Validation loss: 1.61919564970078

Epoch: 5| Step: 9
Training loss: 0.22208090126514435
Validation loss: 1.6120858576989943

Epoch: 5| Step: 10
Training loss: 0.17096230387687683
Validation loss: 1.653602889789048

Epoch: 420| Step: 0
Training loss: 0.14484195411205292
Validation loss: 1.632884842093273

Epoch: 5| Step: 1
Training loss: 0.5511282682418823
Validation loss: 1.6165744232875046

Epoch: 5| Step: 2
Training loss: 0.14763124287128448
Validation loss: 1.5973526572668424

Epoch: 5| Step: 3
Training loss: 0.26702338457107544
Validation loss: 1.576937694703379

Epoch: 5| Step: 4
Training loss: 0.2959710657596588
Validation loss: 1.5654686125375892

Epoch: 5| Step: 5
Training loss: 0.2544366717338562
Validation loss: 1.5492501130668066

Epoch: 5| Step: 6
Training loss: 0.24290259182453156
Validation loss: 1.5441808034014959

Epoch: 5| Step: 7
Training loss: 0.1907866895198822
Validation loss: 1.5572847768824587

Epoch: 5| Step: 8
Training loss: 0.2549891471862793
Validation loss: 1.5604591536265549

Epoch: 5| Step: 9
Training loss: 0.09791246056556702
Validation loss: 1.6165949042125414

Epoch: 5| Step: 10
Training loss: 0.30671030282974243
Validation loss: 1.646219527849587

Epoch: 421| Step: 0
Training loss: 0.3281199038028717
Validation loss: 1.6808186948940318

Epoch: 5| Step: 1
Training loss: 0.21992835402488708
Validation loss: 1.6868377782965218

Epoch: 5| Step: 2
Training loss: 0.2783886790275574
Validation loss: 1.6739004632478118

Epoch: 5| Step: 3
Training loss: 0.3320032060146332
Validation loss: 1.6628035678658435

Epoch: 5| Step: 4
Training loss: 0.46542006731033325
Validation loss: 1.6376677610540902

Epoch: 5| Step: 5
Training loss: 0.2679653465747833
Validation loss: 1.631504717693534

Epoch: 5| Step: 6
Training loss: 0.139985591173172
Validation loss: 1.636860675709222

Epoch: 5| Step: 7
Training loss: 0.1482907235622406
Validation loss: 1.5826410580706853

Epoch: 5| Step: 8
Training loss: 0.20752739906311035
Validation loss: 1.5823652116201257

Epoch: 5| Step: 9
Training loss: 0.34545212984085083
Validation loss: 1.5580759766281291

Epoch: 5| Step: 10
Training loss: 0.12733672559261322
Validation loss: 1.573989245199388

Epoch: 422| Step: 0
Training loss: 0.1944829523563385
Validation loss: 1.5740062831550516

Epoch: 5| Step: 1
Training loss: 0.19132719933986664
Validation loss: 1.5766911352834394

Epoch: 5| Step: 2
Training loss: 0.22584207355976105
Validation loss: 1.5849746145227903

Epoch: 5| Step: 3
Training loss: 0.21709322929382324
Validation loss: 1.6156677667812636

Epoch: 5| Step: 4
Training loss: 0.24756667017936707
Validation loss: 1.6263199531903831

Epoch: 5| Step: 5
Training loss: 0.13276293873786926
Validation loss: 1.60762833779858

Epoch: 5| Step: 6
Training loss: 0.3168983459472656
Validation loss: 1.5891415970299834

Epoch: 5| Step: 7
Training loss: 0.29222410917282104
Validation loss: 1.5909534820946314

Epoch: 5| Step: 8
Training loss: 0.5872763991355896
Validation loss: 1.6069548040307977

Epoch: 5| Step: 9
Training loss: 0.19563129544258118
Validation loss: 1.6138341426849365

Epoch: 5| Step: 10
Training loss: 0.37290966510772705
Validation loss: 1.629953956732186

Epoch: 423| Step: 0
Training loss: 0.1873282492160797
Validation loss: 1.594743259491459

Epoch: 5| Step: 1
Training loss: 0.2929978370666504
Validation loss: 1.653790835411318

Epoch: 5| Step: 2
Training loss: 0.16790254414081573
Validation loss: 1.6258422315761607

Epoch: 5| Step: 3
Training loss: 0.3136492967605591
Validation loss: 1.6143841320468533

Epoch: 5| Step: 4
Training loss: 0.1611769199371338
Validation loss: 1.6051163647764473

Epoch: 5| Step: 5
Training loss: 0.44766077399253845
Validation loss: 1.5352158097810642

Epoch: 5| Step: 6
Training loss: 0.2258133590221405
Validation loss: 1.5668621242687266

Epoch: 5| Step: 7
Training loss: 0.24708358943462372
Validation loss: 1.5379479380064114

Epoch: 5| Step: 8
Training loss: 0.33080849051475525
Validation loss: 1.5498446456847652

Epoch: 5| Step: 9
Training loss: 0.21524691581726074
Validation loss: 1.5246932609106905

Epoch: 5| Step: 10
Training loss: 0.12024042010307312
Validation loss: 1.5517748145646946

Epoch: 424| Step: 0
Training loss: 0.1954289823770523
Validation loss: 1.6018908889062944

Epoch: 5| Step: 1
Training loss: 0.14417052268981934
Validation loss: 1.6119771939451977

Epoch: 5| Step: 2
Training loss: 0.24765701591968536
Validation loss: 1.6398051169610792

Epoch: 5| Step: 3
Training loss: 0.4541071057319641
Validation loss: 1.6707756147589734

Epoch: 5| Step: 4
Training loss: 0.25640326738357544
Validation loss: 1.6937390604326803

Epoch: 5| Step: 5
Training loss: 0.24547350406646729
Validation loss: 1.689050179655834

Epoch: 5| Step: 6
Training loss: 0.5203668475151062
Validation loss: 1.6872810458624234

Epoch: 5| Step: 7
Training loss: 0.19483540952205658
Validation loss: 1.6457849651254632

Epoch: 5| Step: 8
Training loss: 0.18725742399692535
Validation loss: 1.5827330517512497

Epoch: 5| Step: 9
Training loss: 0.21040725708007812
Validation loss: 1.5617191688988799

Epoch: 5| Step: 10
Training loss: 0.2826879024505615
Validation loss: 1.528191117830174

Epoch: 425| Step: 0
Training loss: 0.23315314948558807
Validation loss: 1.5553841103789627

Epoch: 5| Step: 1
Training loss: 0.1877024620771408
Validation loss: 1.5209332422543598

Epoch: 5| Step: 2
Training loss: 0.2972448468208313
Validation loss: 1.5285111332452426

Epoch: 5| Step: 3
Training loss: 0.5187265276908875
Validation loss: 1.5333306661216162

Epoch: 5| Step: 4
Training loss: 0.14772894978523254
Validation loss: 1.532746800812342

Epoch: 5| Step: 5
Training loss: 0.12197069078683853
Validation loss: 1.55928817102986

Epoch: 5| Step: 6
Training loss: 0.3738628923892975
Validation loss: 1.5973524790938183

Epoch: 5| Step: 7
Training loss: 0.21952684223651886
Validation loss: 1.6303866640213998

Epoch: 5| Step: 8
Training loss: 0.2189728021621704
Validation loss: 1.638268091345346

Epoch: 5| Step: 9
Training loss: 0.32594728469848633
Validation loss: 1.6623816797810216

Epoch: 5| Step: 10
Training loss: 0.23130683600902557
Validation loss: 1.6452559822349138

Epoch: 426| Step: 0
Training loss: 0.3664068281650543
Validation loss: 1.607175962899321

Epoch: 5| Step: 1
Training loss: 0.31596189737319946
Validation loss: 1.5844338696490052

Epoch: 5| Step: 2
Training loss: 0.2294902354478836
Validation loss: 1.5447119128319524

Epoch: 5| Step: 3
Training loss: 0.11712735891342163
Validation loss: 1.5697826928989862

Epoch: 5| Step: 4
Training loss: 0.2295621931552887
Validation loss: 1.570127289141378

Epoch: 5| Step: 5
Training loss: 0.2506827414035797
Validation loss: 1.5495707963102607

Epoch: 5| Step: 6
Training loss: 0.1431596577167511
Validation loss: 1.5608255901644308

Epoch: 5| Step: 7
Training loss: 0.137324720621109
Validation loss: 1.5855313731778053

Epoch: 5| Step: 8
Training loss: 0.23222558200359344
Validation loss: 1.6123100942181003

Epoch: 5| Step: 9
Training loss: 0.5667982697486877
Validation loss: 1.6055784930465042

Epoch: 5| Step: 10
Training loss: 0.1307893693447113
Validation loss: 1.5942194551549933

Epoch: 427| Step: 0
Training loss: 0.22457949817180634
Validation loss: 1.6333591809836767

Epoch: 5| Step: 1
Training loss: 0.40736284852027893
Validation loss: 1.615781669975609

Epoch: 5| Step: 2
Training loss: 0.19743402302265167
Validation loss: 1.629009808263471

Epoch: 5| Step: 3
Training loss: 0.1546214371919632
Validation loss: 1.6246989157892042

Epoch: 5| Step: 4
Training loss: 0.27224984765052795
Validation loss: 1.61302319136999

Epoch: 5| Step: 5
Training loss: 0.14181002974510193
Validation loss: 1.5652778469106203

Epoch: 5| Step: 6
Training loss: 0.25917762517929077
Validation loss: 1.6030102750306487

Epoch: 5| Step: 7
Training loss: 0.21500368416309357
Validation loss: 1.534145309079078

Epoch: 5| Step: 8
Training loss: 0.18812775611877441
Validation loss: 1.571753257064409

Epoch: 5| Step: 9
Training loss: 0.2522397041320801
Validation loss: 1.577450116475423

Epoch: 5| Step: 10
Training loss: 0.27245032787323
Validation loss: 1.5627282063166301

Epoch: 428| Step: 0
Training loss: 0.15682728588581085
Validation loss: 1.6010569577576013

Epoch: 5| Step: 1
Training loss: 0.23378801345825195
Validation loss: 1.5809857319760066

Epoch: 5| Step: 2
Training loss: 0.2039983719587326
Validation loss: 1.5760171336512412

Epoch: 5| Step: 3
Training loss: 0.43073493242263794
Validation loss: 1.57591615697389

Epoch: 5| Step: 4
Training loss: 0.22826702892780304
Validation loss: 1.5615782519822479

Epoch: 5| Step: 5
Training loss: 0.5526307821273804
Validation loss: 1.5478495244056947

Epoch: 5| Step: 6
Training loss: 0.26891517639160156
Validation loss: 1.5429484369934245

Epoch: 5| Step: 7
Training loss: 0.2202681005001068
Validation loss: 1.5518345429051308

Epoch: 5| Step: 8
Training loss: 0.16223491728305817
Validation loss: 1.557902632221099

Epoch: 5| Step: 9
Training loss: 0.11739616096019745
Validation loss: 1.5921651445409304

Epoch: 5| Step: 10
Training loss: 0.34556344151496887
Validation loss: 1.6446398458173197

Epoch: 429| Step: 0
Training loss: 0.23951244354248047
Validation loss: 1.6215815774856075

Epoch: 5| Step: 1
Training loss: 0.4521876275539398
Validation loss: 1.575974956635506

Epoch: 5| Step: 2
Training loss: 0.24453353881835938
Validation loss: 1.5752796947315175

Epoch: 5| Step: 3
Training loss: 0.20451359450817108
Validation loss: 1.5600565710375387

Epoch: 5| Step: 4
Training loss: 0.21404564380645752
Validation loss: 1.5175757741415372

Epoch: 5| Step: 5
Training loss: 0.17747172713279724
Validation loss: 1.4832465264105028

Epoch: 5| Step: 6
Training loss: 0.21418896317481995
Validation loss: 1.4992792247444071

Epoch: 5| Step: 7
Training loss: 0.25191670656204224
Validation loss: 1.494549778199965

Epoch: 5| Step: 8
Training loss: 0.23916950821876526
Validation loss: 1.4936871003079157

Epoch: 5| Step: 9
Training loss: 0.15657171607017517
Validation loss: 1.5001593059109104

Epoch: 5| Step: 10
Training loss: 0.19655247032642365
Validation loss: 1.538447053201737

Epoch: 430| Step: 0
Training loss: 0.17700700461864471
Validation loss: 1.542956817534662

Epoch: 5| Step: 1
Training loss: 0.13529875874519348
Validation loss: 1.5441233688785183

Epoch: 5| Step: 2
Training loss: 0.24884247779846191
Validation loss: 1.575736523956381

Epoch: 5| Step: 3
Training loss: 0.2666507065296173
Validation loss: 1.5824239997453586

Epoch: 5| Step: 4
Training loss: 0.4860890805721283
Validation loss: 1.5845321275854622

Epoch: 5| Step: 5
Training loss: 0.19098234176635742
Validation loss: 1.563137314652884

Epoch: 5| Step: 6
Training loss: 0.12019580602645874
Validation loss: 1.5651301735190934

Epoch: 5| Step: 7
Training loss: 0.24536752700805664
Validation loss: 1.5717170699950187

Epoch: 5| Step: 8
Training loss: 0.3803769052028656
Validation loss: 1.547834796290244

Epoch: 5| Step: 9
Training loss: 0.1821748912334442
Validation loss: 1.5592393849485664

Epoch: 5| Step: 10
Training loss: 0.24515651166439056
Validation loss: 1.5620541918662287

Epoch: 431| Step: 0
Training loss: 0.18979355692863464
Validation loss: 1.55211966653024

Epoch: 5| Step: 1
Training loss: 0.18588878214359283
Validation loss: 1.58627563394526

Epoch: 5| Step: 2
Training loss: 0.6003023982048035
Validation loss: 1.591427364657002

Epoch: 5| Step: 3
Training loss: 0.21945436298847198
Validation loss: 1.6136144591915993

Epoch: 5| Step: 4
Training loss: 0.2182859480381012
Validation loss: 1.5843593446157311

Epoch: 5| Step: 5
Training loss: 0.3381549119949341
Validation loss: 1.5811788087250085

Epoch: 5| Step: 6
Training loss: 0.21941907703876495
Validation loss: 1.5683234750583608

Epoch: 5| Step: 7
Training loss: 0.20679005980491638
Validation loss: 1.5536739339110672

Epoch: 5| Step: 8
Training loss: 0.22549161314964294
Validation loss: 1.5284533577580606

Epoch: 5| Step: 9
Training loss: 0.12300250679254532
Validation loss: 1.5106622531849851

Epoch: 5| Step: 10
Training loss: 0.20592033863067627
Validation loss: 1.5142594524609145

Epoch: 432| Step: 0
Training loss: 0.2860305607318878
Validation loss: 1.5519501047749673

Epoch: 5| Step: 1
Training loss: 0.16200515627861023
Validation loss: 1.565387891184899

Epoch: 5| Step: 2
Training loss: 0.1710016280412674
Validation loss: 1.612984376568948

Epoch: 5| Step: 3
Training loss: 0.49871841073036194
Validation loss: 1.6531344767539733

Epoch: 5| Step: 4
Training loss: 0.32896342873573303
Validation loss: 1.673198308995975

Epoch: 5| Step: 5
Training loss: 0.3127702474594116
Validation loss: 1.6877993652897496

Epoch: 5| Step: 6
Training loss: 0.13340561091899872
Validation loss: 1.6069048886658044

Epoch: 5| Step: 7
Training loss: 0.17944270372390747
Validation loss: 1.6365114822182605

Epoch: 5| Step: 8
Training loss: 0.24094116687774658
Validation loss: 1.594806081505232

Epoch: 5| Step: 9
Training loss: 0.23776070773601532
Validation loss: 1.6019277072721911

Epoch: 5| Step: 10
Training loss: 0.17027242481708527
Validation loss: 1.5544621098426081

Epoch: 433| Step: 0
Training loss: 0.13779255747795105
Validation loss: 1.5673185035746584

Epoch: 5| Step: 1
Training loss: 0.16890257596969604
Validation loss: 1.5391167530449488

Epoch: 5| Step: 2
Training loss: 0.23920169472694397
Validation loss: 1.5368227304950837

Epoch: 5| Step: 3
Training loss: 0.15444450080394745
Validation loss: 1.5515419296039048

Epoch: 5| Step: 4
Training loss: 0.20716241002082825
Validation loss: 1.5624036917122461

Epoch: 5| Step: 5
Training loss: 0.2844444215297699
Validation loss: 1.5805232319780576

Epoch: 5| Step: 6
Training loss: 0.5102169513702393
Validation loss: 1.5993678057065575

Epoch: 5| Step: 7
Training loss: 0.15599912405014038
Validation loss: 1.6093972344552316

Epoch: 5| Step: 8
Training loss: 0.2893385887145996
Validation loss: 1.5955046838329685

Epoch: 5| Step: 9
Training loss: 0.14447930455207825
Validation loss: 1.5873353532565537

Epoch: 5| Step: 10
Training loss: 0.22524048388004303
Validation loss: 1.598952233150441

Epoch: 434| Step: 0
Training loss: 0.30932530760765076
Validation loss: 1.5636975547318817

Epoch: 5| Step: 1
Training loss: 0.20283710956573486
Validation loss: 1.5880532021163611

Epoch: 5| Step: 2
Training loss: 0.1667887419462204
Validation loss: 1.5276931838322712

Epoch: 5| Step: 3
Training loss: 0.42635244131088257
Validation loss: 1.5600915660140335

Epoch: 5| Step: 4
Training loss: 0.11963920295238495
Validation loss: 1.5373661530915128

Epoch: 5| Step: 5
Training loss: 0.24472348392009735
Validation loss: 1.4985466221327424

Epoch: 5| Step: 6
Training loss: 0.3235653340816498
Validation loss: 1.5486407510695919

Epoch: 5| Step: 7
Training loss: 0.23845668137073517
Validation loss: 1.5680080806055376

Epoch: 5| Step: 8
Training loss: 0.2298537790775299
Validation loss: 1.5701988961106987

Epoch: 5| Step: 9
Training loss: 0.172575905919075
Validation loss: 1.56380408681849

Epoch: 5| Step: 10
Training loss: 0.20423465967178345
Validation loss: 1.5634921353350404

Epoch: 435| Step: 0
Training loss: 0.15274767577648163
Validation loss: 1.55629809441105

Epoch: 5| Step: 1
Training loss: 0.30794739723205566
Validation loss: 1.5539827782620665

Epoch: 5| Step: 2
Training loss: 0.11966930329799652
Validation loss: 1.5408695743929954

Epoch: 5| Step: 3
Training loss: 0.21483030915260315
Validation loss: 1.5425393504481162

Epoch: 5| Step: 4
Training loss: 0.21080441772937775
Validation loss: 1.5177108119892817

Epoch: 5| Step: 5
Training loss: 0.16801021993160248
Validation loss: 1.539733826473195

Epoch: 5| Step: 6
Training loss: 0.43652382493019104
Validation loss: 1.540440526700789

Epoch: 5| Step: 7
Training loss: 0.26914381980895996
Validation loss: 1.541219179348279

Epoch: 5| Step: 8
Training loss: 0.23545093834400177
Validation loss: 1.5616672064668389

Epoch: 5| Step: 9
Training loss: 0.23598191142082214
Validation loss: 1.56183684256769

Epoch: 5| Step: 10
Training loss: 0.2014012634754181
Validation loss: 1.5455917081525248

Epoch: 436| Step: 0
Training loss: 0.20140723884105682
Validation loss: 1.5436259995224655

Epoch: 5| Step: 1
Training loss: 0.19220983982086182
Validation loss: 1.5463589775946833

Epoch: 5| Step: 2
Training loss: 0.273080438375473
Validation loss: 1.521527535171919

Epoch: 5| Step: 3
Training loss: 0.12566760182380676
Validation loss: 1.5255147257158834

Epoch: 5| Step: 4
Training loss: 0.16601726412773132
Validation loss: 1.5349536659897014

Epoch: 5| Step: 5
Training loss: 0.5147724151611328
Validation loss: 1.5269655027697164

Epoch: 5| Step: 6
Training loss: 0.1721215546131134
Validation loss: 1.5602193570906115

Epoch: 5| Step: 7
Training loss: 0.19666829705238342
Validation loss: 1.5361998222207511

Epoch: 5| Step: 8
Training loss: 0.33173781633377075
Validation loss: 1.589324370507271

Epoch: 5| Step: 9
Training loss: 0.2688314914703369
Validation loss: 1.6119465276759157

Epoch: 5| Step: 10
Training loss: 0.207098126411438
Validation loss: 1.590476353963216

Epoch: 437| Step: 0
Training loss: 0.2782217562198639
Validation loss: 1.5957678832033628

Epoch: 5| Step: 1
Training loss: 0.22818489372730255
Validation loss: 1.5746367118691886

Epoch: 5| Step: 2
Training loss: 0.14878499507904053
Validation loss: 1.5501681130419496

Epoch: 5| Step: 3
Training loss: 0.07933945953845978
Validation loss: 1.5269142222660843

Epoch: 5| Step: 4
Training loss: 0.22471582889556885
Validation loss: 1.5206439623268702

Epoch: 5| Step: 5
Training loss: 0.2720884680747986
Validation loss: 1.553948897828338

Epoch: 5| Step: 6
Training loss: 0.2299180030822754
Validation loss: 1.5139487129385754

Epoch: 5| Step: 7
Training loss: 0.12654100358486176
Validation loss: 1.5262968835010324

Epoch: 5| Step: 8
Training loss: 0.4527166485786438
Validation loss: 1.5098171464858516

Epoch: 5| Step: 9
Training loss: 0.16297727823257446
Validation loss: 1.4954502480004424

Epoch: 5| Step: 10
Training loss: 0.27305445075035095
Validation loss: 1.527562915637929

Epoch: 438| Step: 0
Training loss: 0.15025997161865234
Validation loss: 1.5291882740553988

Epoch: 5| Step: 1
Training loss: 0.1087370365858078
Validation loss: 1.5397773429911623

Epoch: 5| Step: 2
Training loss: 0.460773766040802
Validation loss: 1.5501519198058753

Epoch: 5| Step: 3
Training loss: 0.2154853343963623
Validation loss: 1.5452064134741341

Epoch: 5| Step: 4
Training loss: 0.17810246348381042
Validation loss: 1.5747024961697158

Epoch: 5| Step: 5
Training loss: 0.2502821385860443
Validation loss: 1.56913588893029

Epoch: 5| Step: 6
Training loss: 0.168519526720047
Validation loss: 1.5560878226833958

Epoch: 5| Step: 7
Training loss: 0.26991426944732666
Validation loss: 1.570933271479863

Epoch: 5| Step: 8
Training loss: 0.18567915260791779
Validation loss: 1.5510494401378017

Epoch: 5| Step: 9
Training loss: 0.12264347076416016
Validation loss: 1.5517359279817151

Epoch: 5| Step: 10
Training loss: 0.22022786736488342
Validation loss: 1.566800695593639

Epoch: 439| Step: 0
Training loss: 0.2598040699958801
Validation loss: 1.5798006621740197

Epoch: 5| Step: 1
Training loss: 0.10458359867334366
Validation loss: 1.562696365899937

Epoch: 5| Step: 2
Training loss: 0.18506307899951935
Validation loss: 1.5369263310586252

Epoch: 5| Step: 3
Training loss: 0.2533927857875824
Validation loss: 1.5587138809183592

Epoch: 5| Step: 4
Training loss: 0.12909534573554993
Validation loss: 1.535786203158799

Epoch: 5| Step: 5
Training loss: 0.5002965331077576
Validation loss: 1.5384715795516968

Epoch: 5| Step: 6
Training loss: 0.2559898793697357
Validation loss: 1.5328259262987363

Epoch: 5| Step: 7
Training loss: 0.18648922443389893
Validation loss: 1.5428157935860336

Epoch: 5| Step: 8
Training loss: 0.1571042239665985
Validation loss: 1.5212808744881743

Epoch: 5| Step: 9
Training loss: 0.20265576243400574
Validation loss: 1.5029404727361535

Epoch: 5| Step: 10
Training loss: 0.17375823855400085
Validation loss: 1.524158968720385

Epoch: 440| Step: 0
Training loss: 0.18782256543636322
Validation loss: 1.513089463274966

Epoch: 5| Step: 1
Training loss: 0.3484850525856018
Validation loss: 1.5246499533294349

Epoch: 5| Step: 2
Training loss: 0.1798645704984665
Validation loss: 1.5086140812084239

Epoch: 5| Step: 3
Training loss: 0.23622646927833557
Validation loss: 1.5531296806950723

Epoch: 5| Step: 4
Training loss: 0.19634118676185608
Validation loss: 1.5519482717719129

Epoch: 5| Step: 5
Training loss: 0.09595781564712524
Validation loss: 1.5555940610106274

Epoch: 5| Step: 6
Training loss: 0.09727104008197784
Validation loss: 1.5496652433949132

Epoch: 5| Step: 7
Training loss: 0.21874022483825684
Validation loss: 1.5507123342124365

Epoch: 5| Step: 8
Training loss: 0.18340227007865906
Validation loss: 1.5358447240244957

Epoch: 5| Step: 9
Training loss: 0.241500586271286
Validation loss: 1.5279127782390964

Epoch: 5| Step: 10
Training loss: 0.1941492110490799
Validation loss: 1.4863463089030275

Epoch: 441| Step: 0
Training loss: 0.13736864924430847
Validation loss: 1.4899821371160529

Epoch: 5| Step: 1
Training loss: 0.1622781902551651
Validation loss: 1.526482428273847

Epoch: 5| Step: 2
Training loss: 0.20500703155994415
Validation loss: 1.5414033564188148

Epoch: 5| Step: 3
Training loss: 0.2327674925327301
Validation loss: 1.543809078072989

Epoch: 5| Step: 4
Training loss: 0.21748819947242737
Validation loss: 1.5813261719160183

Epoch: 5| Step: 5
Training loss: 0.1317840963602066
Validation loss: 1.5839074632172943

Epoch: 5| Step: 6
Training loss: 0.29326552152633667
Validation loss: 1.6276808707944808

Epoch: 5| Step: 7
Training loss: 0.5325888991355896
Validation loss: 1.647019188891175

Epoch: 5| Step: 8
Training loss: 0.1547016203403473
Validation loss: 1.6023564928321428

Epoch: 5| Step: 9
Training loss: 0.24199335277080536
Validation loss: 1.5748856606022004

Epoch: 5| Step: 10
Training loss: 0.18631088733673096
Validation loss: 1.5722852624872679

Epoch: 442| Step: 0
Training loss: 0.16689375042915344
Validation loss: 1.5282624985582085

Epoch: 5| Step: 1
Training loss: 0.49118366837501526
Validation loss: 1.5243535631446428

Epoch: 5| Step: 2
Training loss: 0.1998046487569809
Validation loss: 1.546565084047215

Epoch: 5| Step: 3
Training loss: 0.19703006744384766
Validation loss: 1.5253800653642224

Epoch: 5| Step: 4
Training loss: 0.25624197721481323
Validation loss: 1.5662509600321453

Epoch: 5| Step: 5
Training loss: 0.2825491428375244
Validation loss: 1.572040597597758

Epoch: 5| Step: 6
Training loss: 0.13004270195960999
Validation loss: 1.614364739387266

Epoch: 5| Step: 7
Training loss: 0.1741187423467636
Validation loss: 1.6434387801795878

Epoch: 5| Step: 8
Training loss: 0.18667015433311462
Validation loss: 1.6876806110464118

Epoch: 5| Step: 9
Training loss: 0.2693755030632019
Validation loss: 1.7470990291205786

Epoch: 5| Step: 10
Training loss: 0.2903122007846832
Validation loss: 1.7278454995924426

Epoch: 443| Step: 0
Training loss: 0.13897088170051575
Validation loss: 1.6985894672332271

Epoch: 5| Step: 1
Training loss: 0.18162737786769867
Validation loss: 1.6519209325954478

Epoch: 5| Step: 2
Training loss: 0.23873455822467804
Validation loss: 1.5753084664703698

Epoch: 5| Step: 3
Training loss: 0.11693890392780304
Validation loss: 1.5529309408639067

Epoch: 5| Step: 4
Training loss: 0.36407846212387085
Validation loss: 1.5402123799888037

Epoch: 5| Step: 5
Training loss: 0.27167364954948425
Validation loss: 1.5151856035314581

Epoch: 5| Step: 6
Training loss: 0.3011787235736847
Validation loss: 1.512031127047795

Epoch: 5| Step: 7
Training loss: 0.1819840371608734
Validation loss: 1.5338250244817426

Epoch: 5| Step: 8
Training loss: 0.20746640861034393
Validation loss: 1.5357224595162176

Epoch: 5| Step: 9
Training loss: 0.23356661200523376
Validation loss: 1.5355949632583126

Epoch: 5| Step: 10
Training loss: 0.3113434314727783
Validation loss: 1.5491413377946424

Epoch: 444| Step: 0
Training loss: 0.17579281330108643
Validation loss: 1.551548013123133

Epoch: 5| Step: 1
Training loss: 0.2474098652601242
Validation loss: 1.5204537837736067

Epoch: 5| Step: 2
Training loss: 0.14455953240394592
Validation loss: 1.5503093760500672

Epoch: 5| Step: 3
Training loss: 0.2685869336128235
Validation loss: 1.584926414233382

Epoch: 5| Step: 4
Training loss: 0.21205461025238037
Validation loss: 1.597685553694284

Epoch: 5| Step: 5
Training loss: 0.24782276153564453
Validation loss: 1.5911388679217267

Epoch: 5| Step: 6
Training loss: 0.24679966270923615
Validation loss: 1.5629601863122755

Epoch: 5| Step: 7
Training loss: 0.16074752807617188
Validation loss: 1.5378885243528633

Epoch: 5| Step: 8
Training loss: 0.44359254837036133
Validation loss: 1.5333106940792454

Epoch: 5| Step: 9
Training loss: 0.23927387595176697
Validation loss: 1.4923654756238383

Epoch: 5| Step: 10
Training loss: 0.23544692993164062
Validation loss: 1.4958745023255706

Epoch: 445| Step: 0
Training loss: 0.2050396203994751
Validation loss: 1.4921539316895187

Epoch: 5| Step: 1
Training loss: 0.22383877635002136
Validation loss: 1.5271334475086582

Epoch: 5| Step: 2
Training loss: 0.44031915068626404
Validation loss: 1.4997857834703179

Epoch: 5| Step: 3
Training loss: 0.27814608812332153
Validation loss: 1.509701476302198

Epoch: 5| Step: 4
Training loss: 0.15360689163208008
Validation loss: 1.5508532024198962

Epoch: 5| Step: 5
Training loss: 0.22683317959308624
Validation loss: 1.5836656785780383

Epoch: 5| Step: 6
Training loss: 0.15247035026550293
Validation loss: 1.5544097872190579

Epoch: 5| Step: 7
Training loss: 0.23349258303642273
Validation loss: 1.5971709694913638

Epoch: 5| Step: 8
Training loss: 0.31092506647109985
Validation loss: 1.6208230141670472

Epoch: 5| Step: 9
Training loss: 0.21475477516651154
Validation loss: 1.5949968291867165

Epoch: 5| Step: 10
Training loss: 0.248779296875
Validation loss: 1.596155007680257

Epoch: 446| Step: 0
Training loss: 0.1282382309436798
Validation loss: 1.524966533466052

Epoch: 5| Step: 1
Training loss: 0.13608220219612122
Validation loss: 1.498356278224658

Epoch: 5| Step: 2
Training loss: 0.23909910023212433
Validation loss: 1.4808177255815076

Epoch: 5| Step: 3
Training loss: 0.14160779118537903
Validation loss: 1.4814806356224963

Epoch: 5| Step: 4
Training loss: 0.14239323139190674
Validation loss: 1.4836567069894524

Epoch: 5| Step: 5
Training loss: 0.2972371578216553
Validation loss: 1.4969254039948987

Epoch: 5| Step: 6
Training loss: 0.47877079248428345
Validation loss: 1.5257078934741277

Epoch: 5| Step: 7
Training loss: 0.32281237840652466
Validation loss: 1.5405503485792427

Epoch: 5| Step: 8
Training loss: 0.20472893118858337
Validation loss: 1.507905044863301

Epoch: 5| Step: 9
Training loss: 0.26499292254447937
Validation loss: 1.5262816503483763

Epoch: 5| Step: 10
Training loss: 0.20129065215587616
Validation loss: 1.4986458401526175

Epoch: 447| Step: 0
Training loss: 0.1971699297428131
Validation loss: 1.527879544483718

Epoch: 5| Step: 1
Training loss: 0.32419353723526
Validation loss: 1.536076755292954

Epoch: 5| Step: 2
Training loss: 0.19539080560207367
Validation loss: 1.5513694875983781

Epoch: 5| Step: 3
Training loss: 0.16184411942958832
Validation loss: 1.5575587736662997

Epoch: 5| Step: 4
Training loss: 0.25177738070487976
Validation loss: 1.5355191948593303

Epoch: 5| Step: 5
Training loss: 0.13900089263916016
Validation loss: 1.506473281050241

Epoch: 5| Step: 6
Training loss: 0.15973107516765594
Validation loss: 1.5128729343414307

Epoch: 5| Step: 7
Training loss: 0.1184726133942604
Validation loss: 1.5354422523129372

Epoch: 5| Step: 8
Training loss: 0.1313907653093338
Validation loss: 1.5373835679023498

Epoch: 5| Step: 9
Training loss: 0.501268208026886
Validation loss: 1.5457418746845697

Epoch: 5| Step: 10
Training loss: 0.2932795286178589
Validation loss: 1.525556246439616

Epoch: 448| Step: 0
Training loss: 0.24993184208869934
Validation loss: 1.5314996178432176

Epoch: 5| Step: 1
Training loss: 0.21279892325401306
Validation loss: 1.5012562159569032

Epoch: 5| Step: 2
Training loss: 0.489448219537735
Validation loss: 1.4927882359873863

Epoch: 5| Step: 3
Training loss: 0.13907667994499207
Validation loss: 1.4767367570630965

Epoch: 5| Step: 4
Training loss: 0.13299694657325745
Validation loss: 1.4875969438142673

Epoch: 5| Step: 5
Training loss: 0.19435854256153107
Validation loss: 1.4899159695512505

Epoch: 5| Step: 6
Training loss: 0.2293369323015213
Validation loss: 1.5164324609182214

Epoch: 5| Step: 7
Training loss: 0.19215258955955505
Validation loss: 1.5189554486223447

Epoch: 5| Step: 8
Training loss: 0.1311665028333664
Validation loss: 1.5160307909852715

Epoch: 5| Step: 9
Training loss: 0.19505083560943604
Validation loss: 1.498907317397415

Epoch: 5| Step: 10
Training loss: 0.1671990603208542
Validation loss: 1.4855889107591362

Epoch: 449| Step: 0
Training loss: 0.1739107221364975
Validation loss: 1.5151329053345548

Epoch: 5| Step: 1
Training loss: 0.15163947641849518
Validation loss: 1.50065024821989

Epoch: 5| Step: 2
Training loss: 0.22474603354930878
Validation loss: 1.540674997914222

Epoch: 5| Step: 3
Training loss: 0.5692561268806458
Validation loss: 1.5584860142841135

Epoch: 5| Step: 4
Training loss: 0.2419341504573822
Validation loss: 1.5406188131660543

Epoch: 5| Step: 5
Training loss: 0.15832090377807617
Validation loss: 1.5516883198932936

Epoch: 5| Step: 6
Training loss: 0.2118537724018097
Validation loss: 1.5305276686145413

Epoch: 5| Step: 7
Training loss: 0.1362481415271759
Validation loss: 1.5281666696712535

Epoch: 5| Step: 8
Training loss: 0.23923972249031067
Validation loss: 1.5817065469680294

Epoch: 5| Step: 9
Training loss: 0.21483483910560608
Validation loss: 1.6099257174358572

Epoch: 5| Step: 10
Training loss: 0.2306707352399826
Validation loss: 1.592822681191147

Epoch: 450| Step: 0
Training loss: 0.3201698958873749
Validation loss: 1.5587910952106598

Epoch: 5| Step: 1
Training loss: 0.2079802006483078
Validation loss: 1.5612803172039729

Epoch: 5| Step: 2
Training loss: 0.26356974244117737
Validation loss: 1.5598706532550115

Epoch: 5| Step: 3
Training loss: 0.14432311058044434
Validation loss: 1.5598539780544978

Epoch: 5| Step: 4
Training loss: 0.12226782739162445
Validation loss: 1.576879750015915

Epoch: 5| Step: 5
Training loss: 0.18920837342739105
Validation loss: 1.5607561193486696

Epoch: 5| Step: 6
Training loss: 0.19289305806159973
Validation loss: 1.5884791112715198

Epoch: 5| Step: 7
Training loss: 0.12075714766979218
Validation loss: 1.563274691181798

Epoch: 5| Step: 8
Training loss: 0.39821165800094604
Validation loss: 1.5431712353101341

Epoch: 5| Step: 9
Training loss: 0.17599424719810486
Validation loss: 1.577220384792615

Epoch: 5| Step: 10
Training loss: 0.18847350776195526
Validation loss: 1.5316403001867316

Epoch: 451| Step: 0
Training loss: 0.11372514069080353
Validation loss: 1.5442862997772873

Epoch: 5| Step: 1
Training loss: 0.10311345010995865
Validation loss: 1.5315653393345494

Epoch: 5| Step: 2
Training loss: 0.47289571166038513
Validation loss: 1.5139885243549143

Epoch: 5| Step: 3
Training loss: 0.18947236239910126
Validation loss: 1.5303517451850317

Epoch: 5| Step: 4
Training loss: 0.23061498999595642
Validation loss: 1.5118944939746652

Epoch: 5| Step: 5
Training loss: 0.23082880675792694
Validation loss: 1.4958844787331038

Epoch: 5| Step: 6
Training loss: 0.1461690366268158
Validation loss: 1.5051844478935323

Epoch: 5| Step: 7
Training loss: 0.22279015183448792
Validation loss: 1.4842416496687039

Epoch: 5| Step: 8
Training loss: 0.14960217475891113
Validation loss: 1.4621146276432981

Epoch: 5| Step: 9
Training loss: 0.23752474784851074
Validation loss: 1.4963569807749924

Epoch: 5| Step: 10
Training loss: 0.18600720167160034
Validation loss: 1.5394170271453036

Epoch: 452| Step: 0
Training loss: 0.1269797384738922
Validation loss: 1.5215622955752957

Epoch: 5| Step: 1
Training loss: 0.4404817521572113
Validation loss: 1.5436511629371232

Epoch: 5| Step: 2
Training loss: 0.3088177740573883
Validation loss: 1.5306896394298923

Epoch: 5| Step: 3
Training loss: 0.22810666263103485
Validation loss: 1.5357373799047163

Epoch: 5| Step: 4
Training loss: 0.14565452933311462
Validation loss: 1.518152795812135

Epoch: 5| Step: 5
Training loss: 0.16843807697296143
Validation loss: 1.5302614012072164

Epoch: 5| Step: 6
Training loss: 0.12134756147861481
Validation loss: 1.54846026051429

Epoch: 5| Step: 7
Training loss: 0.13156966865062714
Validation loss: 1.542710336305762

Epoch: 5| Step: 8
Training loss: 0.23717260360717773
Validation loss: 1.5564657231812835

Epoch: 5| Step: 9
Training loss: 0.168650820851326
Validation loss: 1.5734256416238763

Epoch: 5| Step: 10
Training loss: 0.25160908699035645
Validation loss: 1.5846077549842097

Epoch: 453| Step: 0
Training loss: 0.13778845965862274
Validation loss: 1.5593919587391678

Epoch: 5| Step: 1
Training loss: 0.12168538570404053
Validation loss: 1.5823715963671285

Epoch: 5| Step: 2
Training loss: 0.1869269162416458
Validation loss: 1.5609898003198768

Epoch: 5| Step: 3
Training loss: 0.2533680200576782
Validation loss: 1.572859339816596

Epoch: 5| Step: 4
Training loss: 0.17619316279888153
Validation loss: 1.5587958430731168

Epoch: 5| Step: 5
Training loss: 0.12859566509723663
Validation loss: 1.5446229980837913

Epoch: 5| Step: 6
Training loss: 0.2644537389278412
Validation loss: 1.5297952352031585

Epoch: 5| Step: 7
Training loss: 0.17473576962947845
Validation loss: 1.522661062978929

Epoch: 5| Step: 8
Training loss: 0.16971886157989502
Validation loss: 1.5353796648722824

Epoch: 5| Step: 9
Training loss: 0.22307893633842468
Validation loss: 1.5384955675371232

Epoch: 5| Step: 10
Training loss: 0.48857682943344116
Validation loss: 1.5402329557685441

Epoch: 454| Step: 0
Training loss: 0.12243447452783585
Validation loss: 1.5262034964817826

Epoch: 5| Step: 1
Training loss: 0.15857455134391785
Validation loss: 1.5038477182388306

Epoch: 5| Step: 2
Training loss: 0.2927379608154297
Validation loss: 1.5278293855728642

Epoch: 5| Step: 3
Training loss: 0.14503617584705353
Validation loss: 1.5399601267230125

Epoch: 5| Step: 4
Training loss: 0.35500264167785645
Validation loss: 1.5292746789993779

Epoch: 5| Step: 5
Training loss: 0.20250491797924042
Validation loss: 1.508467593500691

Epoch: 5| Step: 6
Training loss: 0.1892513930797577
Validation loss: 1.4893557243449713

Epoch: 5| Step: 7
Training loss: 0.11115767806768417
Validation loss: 1.4588862202500785

Epoch: 5| Step: 8
Training loss: 0.1718779355287552
Validation loss: 1.4538054376520135

Epoch: 5| Step: 9
Training loss: 0.433837354183197
Validation loss: 1.437630666840461

Epoch: 5| Step: 10
Training loss: 0.19454942643642426
Validation loss: 1.4454245439139746

Epoch: 455| Step: 0
Training loss: 0.2365354597568512
Validation loss: 1.4523923948246946

Epoch: 5| Step: 1
Training loss: 0.12754568457603455
Validation loss: 1.4328091362471223

Epoch: 5| Step: 2
Training loss: 0.2593846023082733
Validation loss: 1.420785653975702

Epoch: 5| Step: 3
Training loss: 0.2470943033695221
Validation loss: 1.438496922933927

Epoch: 5| Step: 4
Training loss: 0.13739174604415894
Validation loss: 1.4643031756083171

Epoch: 5| Step: 5
Training loss: 0.4266061782836914
Validation loss: 1.477567894484407

Epoch: 5| Step: 6
Training loss: 0.20234008133411407
Validation loss: 1.5509596998973558

Epoch: 5| Step: 7
Training loss: 0.22776904702186584
Validation loss: 1.552355271513744

Epoch: 5| Step: 8
Training loss: 0.19442632794380188
Validation loss: 1.5548418747481478

Epoch: 5| Step: 9
Training loss: 0.17194156348705292
Validation loss: 1.5843653460984588

Epoch: 5| Step: 10
Training loss: 0.17761580646038055
Validation loss: 1.606554522309252

Epoch: 456| Step: 0
Training loss: 0.14519944787025452
Validation loss: 1.568843391633803

Epoch: 5| Step: 1
Training loss: 0.18568140268325806
Validation loss: 1.5467677744486

Epoch: 5| Step: 2
Training loss: 0.219011589884758
Validation loss: 1.553113668195663

Epoch: 5| Step: 3
Training loss: 0.1725378930568695
Validation loss: 1.536827124575133

Epoch: 5| Step: 4
Training loss: 0.19220420718193054
Validation loss: 1.5363688494569512

Epoch: 5| Step: 5
Training loss: 0.44067326188087463
Validation loss: 1.5200633912958124

Epoch: 5| Step: 6
Training loss: 0.27341902256011963
Validation loss: 1.520142694955231

Epoch: 5| Step: 7
Training loss: 0.18872246146202087
Validation loss: 1.5334050802774326

Epoch: 5| Step: 8
Training loss: 0.296832412481308
Validation loss: 1.55434835726215

Epoch: 5| Step: 9
Training loss: 0.12113239616155624
Validation loss: 1.584377302918383

Epoch: 5| Step: 10
Training loss: 0.14079147577285767
Validation loss: 1.5871367633983653

Epoch: 457| Step: 0
Training loss: 0.18338623642921448
Validation loss: 1.595622762556999

Epoch: 5| Step: 1
Training loss: 0.1637144833803177
Validation loss: 1.6079286503535446

Epoch: 5| Step: 2
Training loss: 0.21348650753498077
Validation loss: 1.5616119677020657

Epoch: 5| Step: 3
Training loss: 0.1504049003124237
Validation loss: 1.5673418557772072

Epoch: 5| Step: 4
Training loss: 0.12729178369045258
Validation loss: 1.5395861979453795

Epoch: 5| Step: 5
Training loss: 0.27227583527565
Validation loss: 1.548003718417178

Epoch: 5| Step: 6
Training loss: 0.1839357614517212
Validation loss: 1.5341432979029994

Epoch: 5| Step: 7
Training loss: 0.19760647416114807
Validation loss: 1.534425543200585

Epoch: 5| Step: 8
Training loss: 0.1772945672273636
Validation loss: 1.531472417616075

Epoch: 5| Step: 9
Training loss: 0.433084100484848
Validation loss: 1.5118608628549883

Epoch: 5| Step: 10
Training loss: 0.16122739017009735
Validation loss: 1.515553227034948

Epoch: 458| Step: 0
Training loss: 0.2577281594276428
Validation loss: 1.4902113355616087

Epoch: 5| Step: 1
Training loss: 0.20633797347545624
Validation loss: 1.4981770143714002

Epoch: 5| Step: 2
Training loss: 0.20965704321861267
Validation loss: 1.501324519034355

Epoch: 5| Step: 3
Training loss: 0.3540061116218567
Validation loss: 1.5284645954767864

Epoch: 5| Step: 4
Training loss: 0.12119755893945694
Validation loss: 1.557554300113391

Epoch: 5| Step: 5
Training loss: 0.09389253705739975
Validation loss: 1.5667445031545495

Epoch: 5| Step: 6
Training loss: 0.20868246257305145
Validation loss: 1.5847729047139485

Epoch: 5| Step: 7
Training loss: 0.16725535690784454
Validation loss: 1.575450446016045

Epoch: 5| Step: 8
Training loss: 0.2646406292915344
Validation loss: 1.5582626827301518

Epoch: 5| Step: 9
Training loss: 0.13853655755519867
Validation loss: 1.5409391644180461

Epoch: 5| Step: 10
Training loss: 0.14873498678207397
Validation loss: 1.52033035473157

Epoch: 459| Step: 0
Training loss: 0.22338175773620605
Validation loss: 1.5024515326305101

Epoch: 5| Step: 1
Training loss: 0.15626540780067444
Validation loss: 1.4741397621811076

Epoch: 5| Step: 2
Training loss: 0.15668608248233795
Validation loss: 1.5029041972211612

Epoch: 5| Step: 3
Training loss: 0.2167464792728424
Validation loss: 1.493212490953425

Epoch: 5| Step: 4
Training loss: 0.17132239043712616
Validation loss: 1.5039636601683914

Epoch: 5| Step: 5
Training loss: 0.3718624413013458
Validation loss: 1.4962479324751004

Epoch: 5| Step: 6
Training loss: 0.21823665499687195
Validation loss: 1.510328705592822

Epoch: 5| Step: 7
Training loss: 0.20535388588905334
Validation loss: 1.5104429978196339

Epoch: 5| Step: 8
Training loss: 0.14093531668186188
Validation loss: 1.5317157417215326

Epoch: 5| Step: 9
Training loss: 0.17818425595760345
Validation loss: 1.5229985457594677

Epoch: 5| Step: 10
Training loss: 0.14584696292877197
Validation loss: 1.511522246945289

Epoch: 460| Step: 0
Training loss: 0.16836674511432648
Validation loss: 1.4973009529934134

Epoch: 5| Step: 1
Training loss: 0.3428860604763031
Validation loss: 1.5211679435545398

Epoch: 5| Step: 2
Training loss: 0.10722603648900986
Validation loss: 1.4888159023818148

Epoch: 5| Step: 3
Training loss: 0.2386137992143631
Validation loss: 1.492507225723677

Epoch: 5| Step: 4
Training loss: 0.181472510099411
Validation loss: 1.4963103186699651

Epoch: 5| Step: 5
Training loss: 0.1488315612077713
Validation loss: 1.469926175250802

Epoch: 5| Step: 6
Training loss: 0.12494377791881561
Validation loss: 1.4859923329404605

Epoch: 5| Step: 7
Training loss: 0.17014166712760925
Validation loss: 1.495373978409716

Epoch: 5| Step: 8
Training loss: 0.19664795696735382
Validation loss: 1.4809617534760506

Epoch: 5| Step: 9
Training loss: 0.11179401725530624
Validation loss: 1.5209253475230227

Epoch: 5| Step: 10
Training loss: 0.16154667735099792
Validation loss: 1.525470208096248

Epoch: 461| Step: 0
Training loss: 0.16568374633789062
Validation loss: 1.5188486614534933

Epoch: 5| Step: 1
Training loss: 0.11912886053323746
Validation loss: 1.500605622927348

Epoch: 5| Step: 2
Training loss: 0.4124435484409332
Validation loss: 1.4977515077078214

Epoch: 5| Step: 3
Training loss: 0.15691737830638885
Validation loss: 1.502439989838549

Epoch: 5| Step: 4
Training loss: 0.11967021226882935
Validation loss: 1.4902850812481296

Epoch: 5| Step: 5
Training loss: 0.10255660861730576
Validation loss: 1.4717924582060946

Epoch: 5| Step: 6
Training loss: 0.177039235830307
Validation loss: 1.4592667689887426

Epoch: 5| Step: 7
Training loss: 0.21587686240673065
Validation loss: 1.4830288233295563

Epoch: 5| Step: 8
Training loss: 0.22144785523414612
Validation loss: 1.4661217581841253

Epoch: 5| Step: 9
Training loss: 0.1626875251531601
Validation loss: 1.4933751372880832

Epoch: 5| Step: 10
Training loss: 0.12215971946716309
Validation loss: 1.4613737072995914

Epoch: 462| Step: 0
Training loss: 0.43093523383140564
Validation loss: 1.475113857176996

Epoch: 5| Step: 1
Training loss: 0.09491462260484695
Validation loss: 1.482619070878593

Epoch: 5| Step: 2
Training loss: 0.08708872646093369
Validation loss: 1.491567701421758

Epoch: 5| Step: 3
Training loss: 0.15785659849643707
Validation loss: 1.5218177418554983

Epoch: 5| Step: 4
Training loss: 0.09497876465320587
Validation loss: 1.5011893972273795

Epoch: 5| Step: 5
Training loss: 0.21015839278697968
Validation loss: 1.5026767792240265

Epoch: 5| Step: 6
Training loss: 0.17252326011657715
Validation loss: 1.4764178081225323

Epoch: 5| Step: 7
Training loss: 0.22337178885936737
Validation loss: 1.4188665331050914

Epoch: 5| Step: 8
Training loss: 0.2371106892824173
Validation loss: 1.4269383094644035

Epoch: 5| Step: 9
Training loss: 0.24856364727020264
Validation loss: 1.4185591513110745

Epoch: 5| Step: 10
Training loss: 0.20136111974716187
Validation loss: 1.4104822842023705

Epoch: 463| Step: 0
Training loss: 0.2219202071428299
Validation loss: 1.4208480747797156

Epoch: 5| Step: 1
Training loss: 0.1861990988254547
Validation loss: 1.4085280408141434

Epoch: 5| Step: 2
Training loss: 0.19741781055927277
Validation loss: 1.4123824822005404

Epoch: 5| Step: 3
Training loss: 0.17719797790050507
Validation loss: 1.4763746389778711

Epoch: 5| Step: 4
Training loss: 0.25692057609558105
Validation loss: 1.4596303239945443

Epoch: 5| Step: 5
Training loss: 0.4154006838798523
Validation loss: 1.4906980834340537

Epoch: 5| Step: 6
Training loss: 0.154875248670578
Validation loss: 1.5416051392914147

Epoch: 5| Step: 7
Training loss: 0.24565544724464417
Validation loss: 1.546493826373931

Epoch: 5| Step: 8
Training loss: 0.22159114480018616
Validation loss: 1.5578389462604318

Epoch: 5| Step: 9
Training loss: 0.15892717242240906
Validation loss: 1.5346557683842157

Epoch: 5| Step: 10
Training loss: 0.1427803784608841
Validation loss: 1.530215130057386

Epoch: 464| Step: 0
Training loss: 0.12315968424081802
Validation loss: 1.499287110503002

Epoch: 5| Step: 1
Training loss: 0.1946992725133896
Validation loss: 1.4797197439337288

Epoch: 5| Step: 2
Training loss: 0.1162755936384201
Validation loss: 1.4470376519746677

Epoch: 5| Step: 3
Training loss: 0.2116355448961258
Validation loss: 1.4437353418719383

Epoch: 5| Step: 4
Training loss: 0.10639771074056625
Validation loss: 1.4245411503699519

Epoch: 5| Step: 5
Training loss: 0.2648538649082184
Validation loss: 1.4457449938661309

Epoch: 5| Step: 6
Training loss: 0.15132558345794678
Validation loss: 1.4968577174730198

Epoch: 5| Step: 7
Training loss: 0.4100643992424011
Validation loss: 1.4470794713625343

Epoch: 5| Step: 8
Training loss: 0.10729905217885971
Validation loss: 1.4508033785768735

Epoch: 5| Step: 9
Training loss: 0.13760289549827576
Validation loss: 1.4607640786837506

Epoch: 5| Step: 10
Training loss: 0.1745927929878235
Validation loss: 1.4742472479420323

Epoch: 465| Step: 0
Training loss: 0.4440237879753113
Validation loss: 1.4845039915013056

Epoch: 5| Step: 1
Training loss: 0.13050416111946106
Validation loss: 1.4801873660856677

Epoch: 5| Step: 2
Training loss: 0.18291164934635162
Validation loss: 1.499134753340034

Epoch: 5| Step: 3
Training loss: 0.1988489180803299
Validation loss: 1.4858329232021044

Epoch: 5| Step: 4
Training loss: 0.14494465291500092
Validation loss: 1.490166671814457

Epoch: 5| Step: 5
Training loss: 0.1298885941505432
Validation loss: 1.5038881494152931

Epoch: 5| Step: 6
Training loss: 0.21234063804149628
Validation loss: 1.50414655798225

Epoch: 5| Step: 7
Training loss: 0.1581343710422516
Validation loss: 1.4902901803293536

Epoch: 5| Step: 8
Training loss: 0.1259147822856903
Validation loss: 1.4695431160670456

Epoch: 5| Step: 9
Training loss: 0.09883784502744675
Validation loss: 1.4592353579818562

Epoch: 5| Step: 10
Training loss: 0.16961392760276794
Validation loss: 1.4527575969696045

Epoch: 466| Step: 0
Training loss: 0.36930808424949646
Validation loss: 1.4246352218812512

Epoch: 5| Step: 1
Training loss: 0.11760084331035614
Validation loss: 1.4808949962739022

Epoch: 5| Step: 2
Training loss: 0.16846299171447754
Validation loss: 1.4505038440868419

Epoch: 5| Step: 3
Training loss: 0.24592085182666779
Validation loss: 1.4418986612750637

Epoch: 5| Step: 4
Training loss: 0.16509892046451569
Validation loss: 1.4504490603682816

Epoch: 5| Step: 5
Training loss: 0.10416503250598907
Validation loss: 1.4457778751209218

Epoch: 5| Step: 6
Training loss: 0.12769147753715515
Validation loss: 1.4595262414665633

Epoch: 5| Step: 7
Training loss: 0.17454485595226288
Validation loss: 1.4346247026997228

Epoch: 5| Step: 8
Training loss: 0.09549273550510406
Validation loss: 1.463802024882327

Epoch: 5| Step: 9
Training loss: 0.17054519057273865
Validation loss: 1.4340925562766291

Epoch: 5| Step: 10
Training loss: 0.17898330092430115
Validation loss: 1.422649650163548

Epoch: 467| Step: 0
Training loss: 0.15260007977485657
Validation loss: 1.455907585800335

Epoch: 5| Step: 1
Training loss: 0.16035613417625427
Validation loss: 1.4571614521805958

Epoch: 5| Step: 2
Training loss: 0.2144518792629242
Validation loss: 1.4466430922990203

Epoch: 5| Step: 3
Training loss: 0.17804808914661407
Validation loss: 1.430261169710467

Epoch: 5| Step: 4
Training loss: 0.13230973482131958
Validation loss: 1.435809593046865

Epoch: 5| Step: 5
Training loss: 0.13548673689365387
Validation loss: 1.4287194077686598

Epoch: 5| Step: 6
Training loss: 0.20823931694030762
Validation loss: 1.4665513615454397

Epoch: 5| Step: 7
Training loss: 0.1440914273262024
Validation loss: 1.4816171571772585

Epoch: 5| Step: 8
Training loss: 0.11517183482646942
Validation loss: 1.463962483149703

Epoch: 5| Step: 9
Training loss: 0.1439904272556305
Validation loss: 1.451956586171222

Epoch: 5| Step: 10
Training loss: 0.4671323597431183
Validation loss: 1.4615474227936036

Epoch: 468| Step: 0
Training loss: 0.08392457664012909
Validation loss: 1.4459762803969844

Epoch: 5| Step: 1
Training loss: 0.15703807771205902
Validation loss: 1.4703693402710782

Epoch: 5| Step: 2
Training loss: 0.3298516571521759
Validation loss: 1.4723952649742045

Epoch: 5| Step: 3
Training loss: 0.22156557440757751
Validation loss: 1.4721785604312856

Epoch: 5| Step: 4
Training loss: 0.108147993683815
Validation loss: 1.4996474301943215

Epoch: 5| Step: 5
Training loss: 0.23516789078712463
Validation loss: 1.4919687330081899

Epoch: 5| Step: 6
Training loss: 0.14507755637168884
Validation loss: 1.4720452498364192

Epoch: 5| Step: 7
Training loss: 0.12924157083034515
Validation loss: 1.5053730869805941

Epoch: 5| Step: 8
Training loss: 0.17268668115139008
Validation loss: 1.5193744923478814

Epoch: 5| Step: 9
Training loss: 0.14522771537303925
Validation loss: 1.5763002698139479

Epoch: 5| Step: 10
Training loss: 0.17189180850982666
Validation loss: 1.5683552706113426

Epoch: 469| Step: 0
Training loss: 0.13548263907432556
Validation loss: 1.5560086863015288

Epoch: 5| Step: 1
Training loss: 0.11786065250635147
Validation loss: 1.5455954010768602

Epoch: 5| Step: 2
Training loss: 0.10002358257770538
Validation loss: 1.5388078343483709

Epoch: 5| Step: 3
Training loss: 0.34786245226860046
Validation loss: 1.4875375698971491

Epoch: 5| Step: 4
Training loss: 0.2147308886051178
Validation loss: 1.4779278386023738

Epoch: 5| Step: 5
Training loss: 0.12757664918899536
Validation loss: 1.4628355438991258

Epoch: 5| Step: 6
Training loss: 0.1445612907409668
Validation loss: 1.4714740130209154

Epoch: 5| Step: 7
Training loss: 0.21179857850074768
Validation loss: 1.4319512818449287

Epoch: 5| Step: 8
Training loss: 0.1903717815876007
Validation loss: 1.4571721387165848

Epoch: 5| Step: 9
Training loss: 0.13988366723060608
Validation loss: 1.46527168122671

Epoch: 5| Step: 10
Training loss: 0.10748517513275146
Validation loss: 1.4638390329576307

Epoch: 470| Step: 0
Training loss: 0.1495169699192047
Validation loss: 1.4762070871168567

Epoch: 5| Step: 1
Training loss: 0.1407664269208908
Validation loss: 1.494958746817804

Epoch: 5| Step: 2
Training loss: 0.21789340674877167
Validation loss: 1.4841556831072735

Epoch: 5| Step: 3
Training loss: 0.34700050950050354
Validation loss: 1.5182918348620016

Epoch: 5| Step: 4
Training loss: 0.0893344134092331
Validation loss: 1.496801878816338

Epoch: 5| Step: 5
Training loss: 0.14789226651191711
Validation loss: 1.5010141941808886

Epoch: 5| Step: 6
Training loss: 0.2501031756401062
Validation loss: 1.5090748148579751

Epoch: 5| Step: 7
Training loss: 0.17382986843585968
Validation loss: 1.502370511331866

Epoch: 5| Step: 8
Training loss: 0.14758189022541046
Validation loss: 1.4938647708585184

Epoch: 5| Step: 9
Training loss: 0.08890418708324432
Validation loss: 1.47065854841663

Epoch: 5| Step: 10
Training loss: 0.14410248398780823
Validation loss: 1.4583066740343649

Epoch: 471| Step: 0
Training loss: 0.21577396988868713
Validation loss: 1.4667015575593518

Epoch: 5| Step: 1
Training loss: 0.14336058497428894
Validation loss: 1.4477170564795052

Epoch: 5| Step: 2
Training loss: 0.14909884333610535
Validation loss: 1.4488845922613656

Epoch: 5| Step: 3
Training loss: 0.23493461310863495
Validation loss: 1.4561272205845002

Epoch: 5| Step: 4
Training loss: 0.15213854610919952
Validation loss: 1.4753459384364467

Epoch: 5| Step: 5
Training loss: 0.08937684446573257
Validation loss: 1.4694813733459802

Epoch: 5| Step: 6
Training loss: 0.17565147578716278
Validation loss: 1.5088071720574492

Epoch: 5| Step: 7
Training loss: 0.13626410067081451
Validation loss: 1.5619544495818436

Epoch: 5| Step: 8
Training loss: 0.1971348375082016
Validation loss: 1.5333590776689592

Epoch: 5| Step: 9
Training loss: 0.12107884883880615
Validation loss: 1.5161386228376819

Epoch: 5| Step: 10
Training loss: 0.39008456468582153
Validation loss: 1.5214292656990789

Epoch: 472| Step: 0
Training loss: 0.11546425521373749
Validation loss: 1.4790559994277133

Epoch: 5| Step: 1
Training loss: 0.10033319890499115
Validation loss: 1.4737058685671898

Epoch: 5| Step: 2
Training loss: 0.1141277328133583
Validation loss: 1.465679730138471

Epoch: 5| Step: 3
Training loss: 0.42189478874206543
Validation loss: 1.446675972271991

Epoch: 5| Step: 4
Training loss: 0.12532806396484375
Validation loss: 1.4454507212485037

Epoch: 5| Step: 5
Training loss: 0.200851172208786
Validation loss: 1.45047531589385

Epoch: 5| Step: 6
Training loss: 0.18355199694633484
Validation loss: 1.4475067956473238

Epoch: 5| Step: 7
Training loss: 0.1457993984222412
Validation loss: 1.4786276484048495

Epoch: 5| Step: 8
Training loss: 0.17773301899433136
Validation loss: 1.4876243645145046

Epoch: 5| Step: 9
Training loss: 0.17806024849414825
Validation loss: 1.5258301842597224

Epoch: 5| Step: 10
Training loss: 0.23443390429019928
Validation loss: 1.518978335524118

Epoch: 473| Step: 0
Training loss: 0.13176244497299194
Validation loss: 1.50214409700004

Epoch: 5| Step: 1
Training loss: 0.18896429240703583
Validation loss: 1.4958907737526843

Epoch: 5| Step: 2
Training loss: 0.12610386312007904
Validation loss: 1.4807708686397922

Epoch: 5| Step: 3
Training loss: 0.20035693049430847
Validation loss: 1.4723668867541897

Epoch: 5| Step: 4
Training loss: 0.14213037490844727
Validation loss: 1.4437228723238873

Epoch: 5| Step: 5
Training loss: 0.16754452884197235
Validation loss: 1.4470461978707263

Epoch: 5| Step: 6
Training loss: 0.4060850739479065
Validation loss: 1.46839734303054

Epoch: 5| Step: 7
Training loss: 0.19714048504829407
Validation loss: 1.476382165826777

Epoch: 5| Step: 8
Training loss: 0.09039850533008575
Validation loss: 1.4862605397419264

Epoch: 5| Step: 9
Training loss: 0.08034880459308624
Validation loss: 1.4883502183421966

Epoch: 5| Step: 10
Training loss: 0.23323391377925873
Validation loss: 1.4937147722449353

Epoch: 474| Step: 0
Training loss: 0.12753598392009735
Validation loss: 1.5231935619026102

Epoch: 5| Step: 1
Training loss: 0.11081068217754364
Validation loss: 1.490000094136884

Epoch: 5| Step: 2
Training loss: 0.17365804314613342
Validation loss: 1.5141332111051005

Epoch: 5| Step: 3
Training loss: 0.13232992589473724
Validation loss: 1.491995193625009

Epoch: 5| Step: 4
Training loss: 0.14855989813804626
Validation loss: 1.5068743671140363

Epoch: 5| Step: 5
Training loss: 0.155196875333786
Validation loss: 1.5150420281194872

Epoch: 5| Step: 6
Training loss: 0.2366882860660553
Validation loss: 1.5002477527946554

Epoch: 5| Step: 7
Training loss: 0.17600169777870178
Validation loss: 1.4831771914676954

Epoch: 5| Step: 8
Training loss: 0.3804490566253662
Validation loss: 1.4975437259161344

Epoch: 5| Step: 9
Training loss: 0.11060859262943268
Validation loss: 1.4744076613456971

Epoch: 5| Step: 10
Training loss: 0.11628756672143936
Validation loss: 1.4699242115020752

Epoch: 475| Step: 0
Training loss: 0.10715725272893906
Validation loss: 1.4451296694817082

Epoch: 5| Step: 1
Training loss: 0.33757516741752625
Validation loss: 1.4902949730555217

Epoch: 5| Step: 2
Training loss: 0.20829972624778748
Validation loss: 1.5125456651051838

Epoch: 5| Step: 3
Training loss: 0.1195753961801529
Validation loss: 1.4952174412306918

Epoch: 5| Step: 4
Training loss: 0.10884656757116318
Validation loss: 1.495811721330048

Epoch: 5| Step: 5
Training loss: 0.21519331634044647
Validation loss: 1.525216120545582

Epoch: 5| Step: 6
Training loss: 0.17757265269756317
Validation loss: 1.536443220671787

Epoch: 5| Step: 7
Training loss: 0.1503903865814209
Validation loss: 1.5253245689535653

Epoch: 5| Step: 8
Training loss: 0.15534165501594543
Validation loss: 1.4980308804460751

Epoch: 5| Step: 9
Training loss: 0.13098201155662537
Validation loss: 1.4840506097321868

Epoch: 5| Step: 10
Training loss: 0.16445082426071167
Validation loss: 1.4380126896724905

Epoch: 476| Step: 0
Training loss: 0.12661895155906677
Validation loss: 1.4668233112622333

Epoch: 5| Step: 1
Training loss: 0.1230781078338623
Validation loss: 1.4669388237819876

Epoch: 5| Step: 2
Training loss: 0.14787058532238007
Validation loss: 1.452678261264678

Epoch: 5| Step: 3
Training loss: 0.12465639412403107
Validation loss: 1.4592657883961995

Epoch: 5| Step: 4
Training loss: 0.42451319098472595
Validation loss: 1.489625060430137

Epoch: 5| Step: 5
Training loss: 0.13742825388908386
Validation loss: 1.5125037854717625

Epoch: 5| Step: 6
Training loss: 0.24854202568531036
Validation loss: 1.5120425057667557

Epoch: 5| Step: 7
Training loss: 0.14406922459602356
Validation loss: 1.5201459930789085

Epoch: 5| Step: 8
Training loss: 0.11729788780212402
Validation loss: 1.4971802183376846

Epoch: 5| Step: 9
Training loss: 0.17555466294288635
Validation loss: 1.4751350251577233

Epoch: 5| Step: 10
Training loss: 0.13258498907089233
Validation loss: 1.4659914316669587

Epoch: 477| Step: 0
Training loss: 0.17669577896595
Validation loss: 1.4222875948875182

Epoch: 5| Step: 1
Training loss: 0.10125432908535004
Validation loss: 1.4695194767367454

Epoch: 5| Step: 2
Training loss: 0.14153952896595
Validation loss: 1.4406634934486882

Epoch: 5| Step: 3
Training loss: 0.3727792203426361
Validation loss: 1.4630394545934533

Epoch: 5| Step: 4
Training loss: 0.19164344668388367
Validation loss: 1.4716940964421918

Epoch: 5| Step: 5
Training loss: 0.09206502139568329
Validation loss: 1.4787883668817499

Epoch: 5| Step: 6
Training loss: 0.11558814346790314
Validation loss: 1.5018421462787095

Epoch: 5| Step: 7
Training loss: 0.16493740677833557
Validation loss: 1.4824777239112443

Epoch: 5| Step: 8
Training loss: 0.16813907027244568
Validation loss: 1.5106725622248907

Epoch: 5| Step: 9
Training loss: 0.10115335881710052
Validation loss: 1.5313661342026086

Epoch: 5| Step: 10
Training loss: 0.2576894164085388
Validation loss: 1.5640694120878815

Epoch: 478| Step: 0
Training loss: 0.0944519191980362
Validation loss: 1.549237480727575

Epoch: 5| Step: 1
Training loss: 0.16655802726745605
Validation loss: 1.5486354353607341

Epoch: 5| Step: 2
Training loss: 0.13491089642047882
Validation loss: 1.5409606502902122

Epoch: 5| Step: 3
Training loss: 0.18635118007659912
Validation loss: 1.5468145390992523

Epoch: 5| Step: 4
Training loss: 0.36655837297439575
Validation loss: 1.5236742252944617

Epoch: 5| Step: 5
Training loss: 0.16640737652778625
Validation loss: 1.5373863045887282

Epoch: 5| Step: 6
Training loss: 0.2208114117383957
Validation loss: 1.542803438760901

Epoch: 5| Step: 7
Training loss: 0.17889375984668732
Validation loss: 1.5523278905499367

Epoch: 5| Step: 8
Training loss: 0.14111581444740295
Validation loss: 1.5619888100572812

Epoch: 5| Step: 9
Training loss: 0.19756421446800232
Validation loss: 1.5150679080717024

Epoch: 5| Step: 10
Training loss: 0.18041425943374634
Validation loss: 1.5275212359684769

Epoch: 479| Step: 0
Training loss: 0.13050341606140137
Validation loss: 1.5790456418068177

Epoch: 5| Step: 1
Training loss: 0.22028020024299622
Validation loss: 1.566201256167504

Epoch: 5| Step: 2
Training loss: 0.16357862949371338
Validation loss: 1.567438825484245

Epoch: 5| Step: 3
Training loss: 0.1839543879032135
Validation loss: 1.5730239716909264

Epoch: 5| Step: 4
Training loss: 0.1769970953464508
Validation loss: 1.565383352259154

Epoch: 5| Step: 5
Training loss: 0.3209696412086487
Validation loss: 1.5788537456143288

Epoch: 5| Step: 6
Training loss: 0.18631398677825928
Validation loss: 1.5585963777316514

Epoch: 5| Step: 7
Training loss: 0.13301494717597961
Validation loss: 1.5866149702379782

Epoch: 5| Step: 8
Training loss: 0.2169610559940338
Validation loss: 1.602164577412349

Epoch: 5| Step: 9
Training loss: 0.23907165229320526
Validation loss: 1.6139348117254113

Epoch: 5| Step: 10
Training loss: 0.1761942207813263
Validation loss: 1.5526948846796507

Epoch: 480| Step: 0
Training loss: 0.19190244376659393
Validation loss: 1.5092999012239519

Epoch: 5| Step: 1
Training loss: 0.2211928814649582
Validation loss: 1.4885987671472694

Epoch: 5| Step: 2
Training loss: 0.134007066488266
Validation loss: 1.4976706620185607

Epoch: 5| Step: 3
Training loss: 0.20171420276165009
Validation loss: 1.5131178620041057

Epoch: 5| Step: 4
Training loss: 0.11829222738742828
Validation loss: 1.4485414226849873

Epoch: 5| Step: 5
Training loss: 0.1364521086215973
Validation loss: 1.4711063715719408

Epoch: 5| Step: 6
Training loss: 0.15305113792419434
Validation loss: 1.4838593262498097

Epoch: 5| Step: 7
Training loss: 0.17845794558525085
Validation loss: 1.4719105971756803

Epoch: 5| Step: 8
Training loss: 0.3622148036956787
Validation loss: 1.4833120992106776

Epoch: 5| Step: 9
Training loss: 0.14039874076843262
Validation loss: 1.480165687940454

Epoch: 5| Step: 10
Training loss: 0.11249779164791107
Validation loss: 1.470358153825165

Epoch: 481| Step: 0
Training loss: 0.11259738355875015
Validation loss: 1.4686273144137474

Epoch: 5| Step: 1
Training loss: 0.1291245073080063
Validation loss: 1.4752348084603586

Epoch: 5| Step: 2
Training loss: 0.11976146697998047
Validation loss: 1.4681357517037341

Epoch: 5| Step: 3
Training loss: 0.09288543462753296
Validation loss: 1.4494733477151522

Epoch: 5| Step: 4
Training loss: 0.14034149050712585
Validation loss: 1.464806427237808

Epoch: 5| Step: 5
Training loss: 0.11184144020080566
Validation loss: 1.4753334881157003

Epoch: 5| Step: 6
Training loss: 0.11200563609600067
Validation loss: 1.4814027663200133

Epoch: 5| Step: 7
Training loss: 0.16751627624034882
Validation loss: 1.4957211466245754

Epoch: 5| Step: 8
Training loss: 0.17246870696544647
Validation loss: 1.5079818630731234

Epoch: 5| Step: 9
Training loss: 0.3723192811012268
Validation loss: 1.5145821148349392

Epoch: 5| Step: 10
Training loss: 0.08811413496732712
Validation loss: 1.5091953187860467

Epoch: 482| Step: 0
Training loss: 0.13336268067359924
Validation loss: 1.5216894547144573

Epoch: 5| Step: 1
Training loss: 0.10161809623241425
Validation loss: 1.4776729383776266

Epoch: 5| Step: 2
Training loss: 0.13024947047233582
Validation loss: 1.5077535830518252

Epoch: 5| Step: 3
Training loss: 0.11824735254049301
Validation loss: 1.4915862442344747

Epoch: 5| Step: 4
Training loss: 0.13381646573543549
Validation loss: 1.5086251381904847

Epoch: 5| Step: 5
Training loss: 0.13668690621852875
Validation loss: 1.497255495799485

Epoch: 5| Step: 6
Training loss: 0.13613934814929962
Validation loss: 1.4998301293260308

Epoch: 5| Step: 7
Training loss: 0.1734587550163269
Validation loss: 1.5213042100270588

Epoch: 5| Step: 8
Training loss: 0.3103131651878357
Validation loss: 1.5253831391693444

Epoch: 5| Step: 9
Training loss: 0.21021953225135803
Validation loss: 1.52829449407516

Epoch: 5| Step: 10
Training loss: 0.1995081901550293
Validation loss: 1.554193869713814

Epoch: 483| Step: 0
Training loss: 0.17257218062877655
Validation loss: 1.5564603318450272

Epoch: 5| Step: 1
Training loss: 0.12017522007226944
Validation loss: 1.5520505136059177

Epoch: 5| Step: 2
Training loss: 0.16075894236564636
Validation loss: 1.557900123698737

Epoch: 5| Step: 3
Training loss: 0.09246821701526642
Validation loss: 1.5422713769379484

Epoch: 5| Step: 4
Training loss: 0.1424051970243454
Validation loss: 1.5437069874937817

Epoch: 5| Step: 5
Training loss: 0.09263724088668823
Validation loss: 1.4930105331123515

Epoch: 5| Step: 6
Training loss: 0.11943074315786362
Validation loss: 1.5073683684872043

Epoch: 5| Step: 7
Training loss: 0.13356268405914307
Validation loss: 1.4745436829905356

Epoch: 5| Step: 8
Training loss: 0.19617614150047302
Validation loss: 1.4868422746658325

Epoch: 5| Step: 9
Training loss: 0.12652434408664703
Validation loss: 1.4988509083306918

Epoch: 5| Step: 10
Training loss: 0.43643420934677124
Validation loss: 1.4597175249489405

Epoch: 484| Step: 0
Training loss: 0.10857369750738144
Validation loss: 1.4806829408932758

Epoch: 5| Step: 1
Training loss: 0.13780605792999268
Validation loss: 1.4946548887478408

Epoch: 5| Step: 2
Training loss: 0.09822435677051544
Validation loss: 1.4979300755326466

Epoch: 5| Step: 3
Training loss: 0.1435527503490448
Validation loss: 1.5388484039614279

Epoch: 5| Step: 4
Training loss: 0.14345769584178925
Validation loss: 1.5290424951943018

Epoch: 5| Step: 5
Training loss: 0.15451005101203918
Validation loss: 1.5152342152851883

Epoch: 5| Step: 6
Training loss: 0.3097728192806244
Validation loss: 1.4900245788276836

Epoch: 5| Step: 7
Training loss: 0.12888042628765106
Validation loss: 1.489643863452378

Epoch: 5| Step: 8
Training loss: 0.11723776906728745
Validation loss: 1.5017497513883857

Epoch: 5| Step: 9
Training loss: 0.1418299525976181
Validation loss: 1.4660098315567098

Epoch: 5| Step: 10
Training loss: 0.13192632794380188
Validation loss: 1.4929722893622615

Epoch: 485| Step: 0
Training loss: 0.09004384279251099
Validation loss: 1.4782765706380208

Epoch: 5| Step: 1
Training loss: 0.3741235136985779
Validation loss: 1.4781827926635742

Epoch: 5| Step: 2
Training loss: 0.12073855102062225
Validation loss: 1.44693313875506

Epoch: 5| Step: 3
Training loss: 0.16727879643440247
Validation loss: 1.448236551976973

Epoch: 5| Step: 4
Training loss: 0.18900330364704132
Validation loss: 1.4555802056866307

Epoch: 5| Step: 5
Training loss: 0.16166165471076965
Validation loss: 1.460132674504352

Epoch: 5| Step: 6
Training loss: 0.12651094794273376
Validation loss: 1.4988934096469675

Epoch: 5| Step: 7
Training loss: 0.14997610449790955
Validation loss: 1.4865509835622643

Epoch: 5| Step: 8
Training loss: 0.19112816452980042
Validation loss: 1.5044976306217972

Epoch: 5| Step: 9
Training loss: 0.13796541094779968
Validation loss: 1.4584214501483466

Epoch: 5| Step: 10
Training loss: 0.16103293001651764
Validation loss: 1.4411208584744444

Epoch: 486| Step: 0
Training loss: 0.13804420828819275
Validation loss: 1.4251370852993381

Epoch: 5| Step: 1
Training loss: 0.12205244600772858
Validation loss: 1.4471802519213768

Epoch: 5| Step: 2
Training loss: 0.11506104469299316
Validation loss: 1.462553717756784

Epoch: 5| Step: 3
Training loss: 0.15227559208869934
Validation loss: 1.4607093000924716

Epoch: 5| Step: 4
Training loss: 0.3541649878025055
Validation loss: 1.4756568247272122

Epoch: 5| Step: 5
Training loss: 0.18840807676315308
Validation loss: 1.4790471241038332

Epoch: 5| Step: 6
Training loss: 0.10031044483184814
Validation loss: 1.4838164378237981

Epoch: 5| Step: 7
Training loss: 0.157209113240242
Validation loss: 1.4623217108429118

Epoch: 5| Step: 8
Training loss: 0.12731142342090607
Validation loss: 1.4756702492314

Epoch: 5| Step: 9
Training loss: 0.17419497668743134
Validation loss: 1.4935303977740708

Epoch: 5| Step: 10
Training loss: 0.057616088539361954
Validation loss: 1.4929773935707666

Epoch: 487| Step: 0
Training loss: 0.1445334404706955
Validation loss: 1.510381394816983

Epoch: 5| Step: 1
Training loss: 0.12273266166448593
Validation loss: 1.5220597610678723

Epoch: 5| Step: 2
Training loss: 0.18627244234085083
Validation loss: 1.5429302171994281

Epoch: 5| Step: 3
Training loss: 0.12738056480884552
Validation loss: 1.513352023657932

Epoch: 5| Step: 4
Training loss: 0.10706745088100433
Validation loss: 1.5259312186189877

Epoch: 5| Step: 5
Training loss: 0.3480589687824249
Validation loss: 1.4651737661771878

Epoch: 5| Step: 6
Training loss: 0.1382385492324829
Validation loss: 1.4726986692797752

Epoch: 5| Step: 7
Training loss: 0.15519419312477112
Validation loss: 1.485089426399559

Epoch: 5| Step: 8
Training loss: 0.18165114521980286
Validation loss: 1.4854954455488472

Epoch: 5| Step: 9
Training loss: 0.15200239419937134
Validation loss: 1.4850847900554698

Epoch: 5| Step: 10
Training loss: 0.17013274133205414
Validation loss: 1.4642093335428545

Epoch: 488| Step: 0
Training loss: 0.1719445139169693
Validation loss: 1.4960986773173015

Epoch: 5| Step: 1
Training loss: 0.1140432357788086
Validation loss: 1.5053720922880276

Epoch: 5| Step: 2
Training loss: 0.10711240768432617
Validation loss: 1.5017815789868754

Epoch: 5| Step: 3
Training loss: 0.18202850222587585
Validation loss: 1.5223937252516389

Epoch: 5| Step: 4
Training loss: 0.19425347447395325
Validation loss: 1.48799567966051

Epoch: 5| Step: 5
Training loss: 0.09329073131084442
Validation loss: 1.4841479639853201

Epoch: 5| Step: 6
Training loss: 0.12488416582345963
Validation loss: 1.4738666639533093

Epoch: 5| Step: 7
Training loss: 0.20037135481834412
Validation loss: 1.4734984533761137

Epoch: 5| Step: 8
Training loss: 0.3892439603805542
Validation loss: 1.452063650213262

Epoch: 5| Step: 9
Training loss: 0.14593669772148132
Validation loss: 1.4328491905684113

Epoch: 5| Step: 10
Training loss: 0.16559378802776337
Validation loss: 1.4230657418568928

Epoch: 489| Step: 0
Training loss: 0.11800435930490494
Validation loss: 1.4043371677398682

Epoch: 5| Step: 1
Training loss: 0.1514178216457367
Validation loss: 1.4326054203894831

Epoch: 5| Step: 2
Training loss: 0.3411921262741089
Validation loss: 1.4606409495876682

Epoch: 5| Step: 3
Training loss: 0.15332373976707458
Validation loss: 1.5151345165826942

Epoch: 5| Step: 4
Training loss: 0.09761501848697662
Validation loss: 1.5407300802969164

Epoch: 5| Step: 5
Training loss: 0.2137165516614914
Validation loss: 1.5680498089841617

Epoch: 5| Step: 6
Training loss: 0.17321978509426117
Validation loss: 1.5485087684405747

Epoch: 5| Step: 7
Training loss: 0.19771544635295868
Validation loss: 1.5053064592422978

Epoch: 5| Step: 8
Training loss: 0.14328834414482117
Validation loss: 1.4988699792533793

Epoch: 5| Step: 9
Training loss: 0.1346922069787979
Validation loss: 1.4776568938327093

Epoch: 5| Step: 10
Training loss: 0.1651381105184555
Validation loss: 1.4520518754118232

Epoch: 490| Step: 0
Training loss: 0.1817743480205536
Validation loss: 1.435245067842545

Epoch: 5| Step: 1
Training loss: 0.10117492824792862
Validation loss: 1.43596226041035

Epoch: 5| Step: 2
Training loss: 0.33939123153686523
Validation loss: 1.4086537854645842

Epoch: 5| Step: 3
Training loss: 0.23598751425743103
Validation loss: 1.4121819324390863

Epoch: 5| Step: 4
Training loss: 0.12130007892847061
Validation loss: 1.424209073025693

Epoch: 5| Step: 5
Training loss: 0.181041419506073
Validation loss: 1.4519491746861448

Epoch: 5| Step: 6
Training loss: 0.10831282287836075
Validation loss: 1.4820122987993303

Epoch: 5| Step: 7
Training loss: 0.1927078664302826
Validation loss: 1.522404691224457

Epoch: 5| Step: 8
Training loss: 0.1998334676027298
Validation loss: 1.5258552194923483

Epoch: 5| Step: 9
Training loss: 0.05836782976984978
Validation loss: 1.5146444382206086

Epoch: 5| Step: 10
Training loss: 0.1641320288181305
Validation loss: 1.5225823854887357

Epoch: 491| Step: 0
Training loss: 0.38061273097991943
Validation loss: 1.532989267380007

Epoch: 5| Step: 1
Training loss: 0.15819551050662994
Validation loss: 1.5387855499021468

Epoch: 5| Step: 2
Training loss: 0.19692668318748474
Validation loss: 1.5340032410878006

Epoch: 5| Step: 3
Training loss: 0.1362815648317337
Validation loss: 1.5203188760306245

Epoch: 5| Step: 4
Training loss: 0.10803182423114777
Validation loss: 1.5194706839899863

Epoch: 5| Step: 5
Training loss: 0.22054123878479004
Validation loss: 1.5093170404434204

Epoch: 5| Step: 6
Training loss: 0.15232884883880615
Validation loss: 1.5122855645354076

Epoch: 5| Step: 7
Training loss: 0.1580624133348465
Validation loss: 1.4828834687509844

Epoch: 5| Step: 8
Training loss: 0.16826549172401428
Validation loss: 1.498233655447601

Epoch: 5| Step: 9
Training loss: 0.21685774624347687
Validation loss: 1.5130805097600466

Epoch: 5| Step: 10
Training loss: 0.09802629053592682
Validation loss: 1.511712799790085

Epoch: 492| Step: 0
Training loss: 0.3274698853492737
Validation loss: 1.4953662631332234

Epoch: 5| Step: 1
Training loss: 0.1113269105553627
Validation loss: 1.5256127067791518

Epoch: 5| Step: 2
Training loss: 0.11673412472009659
Validation loss: 1.5320602693865377

Epoch: 5| Step: 3
Training loss: 0.09673701226711273
Validation loss: 1.5406672275194557

Epoch: 5| Step: 4
Training loss: 0.14747127890586853
Validation loss: 1.560621150078312

Epoch: 5| Step: 5
Training loss: 0.16293053328990936
Validation loss: 1.5163786231830556

Epoch: 5| Step: 6
Training loss: 0.10519427061080933
Validation loss: 1.517416751512917

Epoch: 5| Step: 7
Training loss: 0.1573224663734436
Validation loss: 1.494748494958365

Epoch: 5| Step: 8
Training loss: 0.07584182173013687
Validation loss: 1.4794569041139336

Epoch: 5| Step: 9
Training loss: 0.1708519011735916
Validation loss: 1.4844547343510452

Epoch: 5| Step: 10
Training loss: 0.16276325285434723
Validation loss: 1.429774248471824

Epoch: 493| Step: 0
Training loss: 0.13247323036193848
Validation loss: 1.483420964210264

Epoch: 5| Step: 1
Training loss: 0.09496261924505234
Validation loss: 1.4770104077554518

Epoch: 5| Step: 2
Training loss: 0.15151698887348175
Validation loss: 1.480429385298042

Epoch: 5| Step: 3
Training loss: 0.12793007493019104
Validation loss: 1.4738551801250828

Epoch: 5| Step: 4
Training loss: 0.12327691167593002
Validation loss: 1.4996664293350712

Epoch: 5| Step: 5
Training loss: 0.36144647002220154
Validation loss: 1.4673283792311145

Epoch: 5| Step: 6
Training loss: 0.12274382263422012
Validation loss: 1.5037920257096649

Epoch: 5| Step: 7
Training loss: 0.1871703416109085
Validation loss: 1.5108461597914338

Epoch: 5| Step: 8
Training loss: 0.10736852884292603
Validation loss: 1.501380620464202

Epoch: 5| Step: 9
Training loss: 0.14135241508483887
Validation loss: 1.4834192747710853

Epoch: 5| Step: 10
Training loss: 0.18549130856990814
Validation loss: 1.4697198688343007

Epoch: 494| Step: 0
Training loss: 0.09058307111263275
Validation loss: 1.458946043445218

Epoch: 5| Step: 1
Training loss: 0.09957418590784073
Validation loss: 1.492899638350292

Epoch: 5| Step: 2
Training loss: 0.0886475220322609
Validation loss: 1.47613472964174

Epoch: 5| Step: 3
Training loss: 0.1253148764371872
Validation loss: 1.4851653691261046

Epoch: 5| Step: 4
Training loss: 0.4067329466342926
Validation loss: 1.5072784475100938

Epoch: 5| Step: 5
Training loss: 0.0989786833524704
Validation loss: 1.4575815072623632

Epoch: 5| Step: 6
Training loss: 0.10756178200244904
Validation loss: 1.4923907415841215

Epoch: 5| Step: 7
Training loss: 0.11965968459844589
Validation loss: 1.4873613952308573

Epoch: 5| Step: 8
Training loss: 0.1330084353685379
Validation loss: 1.4474776675624232

Epoch: 5| Step: 9
Training loss: 0.13088472187519073
Validation loss: 1.475407463248058

Epoch: 5| Step: 10
Training loss: 0.12185773998498917
Validation loss: 1.4762261138167432

Epoch: 495| Step: 0
Training loss: 0.10494627803564072
Validation loss: 1.496865265471961

Epoch: 5| Step: 1
Training loss: 0.19885344803333282
Validation loss: 1.4704004359501663

Epoch: 5| Step: 2
Training loss: 0.09594631940126419
Validation loss: 1.467569467841938

Epoch: 5| Step: 3
Training loss: 0.1204601526260376
Validation loss: 1.454534089693459

Epoch: 5| Step: 4
Training loss: 0.14042401313781738
Validation loss: 1.4651494359457364

Epoch: 5| Step: 5
Training loss: 0.08176270872354507
Validation loss: 1.4652265899924821

Epoch: 5| Step: 6
Training loss: 0.3259349465370178
Validation loss: 1.476116229129094

Epoch: 5| Step: 7
Training loss: 0.12764938175678253
Validation loss: 1.4785316304493976

Epoch: 5| Step: 8
Training loss: 0.1993788480758667
Validation loss: 1.4861693779627483

Epoch: 5| Step: 9
Training loss: 0.09252720326185226
Validation loss: 1.4962893468077465

Epoch: 5| Step: 10
Training loss: 0.13720126450061798
Validation loss: 1.4943298537244079

Epoch: 496| Step: 0
Training loss: 0.11773812770843506
Validation loss: 1.4992845353259836

Epoch: 5| Step: 1
Training loss: 0.08145123720169067
Validation loss: 1.4723521022386448

Epoch: 5| Step: 2
Training loss: 0.1411915272474289
Validation loss: 1.4659759408684188

Epoch: 5| Step: 3
Training loss: 0.13542453944683075
Validation loss: 1.4345607296113045

Epoch: 5| Step: 4
Training loss: 0.07905496656894684
Validation loss: 1.4586480586759505

Epoch: 5| Step: 5
Training loss: 0.1371900886297226
Validation loss: 1.466411288066577

Epoch: 5| Step: 6
Training loss: 0.16761848330497742
Validation loss: 1.4477800259026148

Epoch: 5| Step: 7
Training loss: 0.14509597420692444
Validation loss: 1.453931490580241

Epoch: 5| Step: 8
Training loss: 0.128109410405159
Validation loss: 1.4591811164732902

Epoch: 5| Step: 9
Training loss: 0.3477424681186676
Validation loss: 1.4764866546917987

Epoch: 5| Step: 10
Training loss: 0.2183079868555069
Validation loss: 1.4976205184895506

Epoch: 497| Step: 0
Training loss: 0.1523369699716568
Validation loss: 1.515634664925196

Epoch: 5| Step: 1
Training loss: 0.09954678267240524
Validation loss: 1.4801676939892512

Epoch: 5| Step: 2
Training loss: 0.15068559348583221
Validation loss: 1.4561908578359952

Epoch: 5| Step: 3
Training loss: 0.3534674048423767
Validation loss: 1.4434914076200096

Epoch: 5| Step: 4
Training loss: 0.11522330343723297
Validation loss: 1.4365930505978164

Epoch: 5| Step: 5
Training loss: 0.12434593588113785
Validation loss: 1.4525207088839622

Epoch: 5| Step: 6
Training loss: 0.07050056755542755
Validation loss: 1.4569953372401576

Epoch: 5| Step: 7
Training loss: 0.09526348114013672
Validation loss: 1.4668101879858202

Epoch: 5| Step: 8
Training loss: 0.18789830803871155
Validation loss: 1.4746053065023115

Epoch: 5| Step: 9
Training loss: 0.12114963680505753
Validation loss: 1.4721236280215684

Epoch: 5| Step: 10
Training loss: 0.1426079273223877
Validation loss: 1.4810121264508975

Epoch: 498| Step: 0
Training loss: 0.10654857009649277
Validation loss: 1.490416798540341

Epoch: 5| Step: 1
Training loss: 0.14571355283260345
Validation loss: 1.488825640370769

Epoch: 5| Step: 2
Training loss: 0.34407931566238403
Validation loss: 1.4791012861395394

Epoch: 5| Step: 3
Training loss: 0.11732976138591766
Validation loss: 1.4763414090679539

Epoch: 5| Step: 4
Training loss: 0.18435168266296387
Validation loss: 1.4903977353085753

Epoch: 5| Step: 5
Training loss: 0.09517636150121689
Validation loss: 1.456075679871344

Epoch: 5| Step: 6
Training loss: 0.09699214994907379
Validation loss: 1.470882042761772

Epoch: 5| Step: 7
Training loss: 0.11759648472070694
Validation loss: 1.4783104606854018

Epoch: 5| Step: 8
Training loss: 0.13786889612674713
Validation loss: 1.471420495740829

Epoch: 5| Step: 9
Training loss: 0.13929599523544312
Validation loss: 1.4663653912082795

Epoch: 5| Step: 10
Training loss: 0.12150918692350388
Validation loss: 1.4896454836732598

Epoch: 499| Step: 0
Training loss: 0.08100559562444687
Validation loss: 1.4932324001866002

Epoch: 5| Step: 1
Training loss: 0.08409306406974792
Validation loss: 1.4719455972794564

Epoch: 5| Step: 2
Training loss: 0.18138167262077332
Validation loss: 1.48452502681363

Epoch: 5| Step: 3
Training loss: 0.12423346191644669
Validation loss: 1.4845507529474073

Epoch: 5| Step: 4
Training loss: 0.12502548098564148
Validation loss: 1.4514923287976174

Epoch: 5| Step: 5
Training loss: 0.15401284396648407
Validation loss: 1.4515601358106058

Epoch: 5| Step: 6
Training loss: 0.13845551013946533
Validation loss: 1.4431352570492735

Epoch: 5| Step: 7
Training loss: 0.30592283606529236
Validation loss: 1.4573484800195182

Epoch: 5| Step: 8
Training loss: 0.1317364126443863
Validation loss: 1.4923134760190082

Epoch: 5| Step: 9
Training loss: 0.13935337960720062
Validation loss: 1.4681782786564161

Epoch: 5| Step: 10
Training loss: 0.11090416461229324
Validation loss: 1.4958525267980431

Epoch: 500| Step: 0
Training loss: 0.12277083098888397
Validation loss: 1.4732895128188594

Epoch: 5| Step: 1
Training loss: 0.11237271875143051
Validation loss: 1.4906628747140207

Epoch: 5| Step: 2
Training loss: 0.13119426369667053
Validation loss: 1.4642310693699827

Epoch: 5| Step: 3
Training loss: 0.07352093607187271
Validation loss: 1.4483622709910076

Epoch: 5| Step: 4
Training loss: 0.3082062602043152
Validation loss: 1.4463817804090437

Epoch: 5| Step: 5
Training loss: 0.12932188808918
Validation loss: 1.4780631565278577

Epoch: 5| Step: 6
Training loss: 0.21225647628307343
Validation loss: 1.4451128769946355

Epoch: 5| Step: 7
Training loss: 0.16077378392219543
Validation loss: 1.4362699882958525

Epoch: 5| Step: 8
Training loss: 0.148722842335701
Validation loss: 1.4525001241314797

Epoch: 5| Step: 9
Training loss: 0.09225118160247803
Validation loss: 1.433796598065284

Epoch: 5| Step: 10
Training loss: 0.09342744946479797
Validation loss: 1.4374962519573908

Epoch: 501| Step: 0
Training loss: 0.10325465351343155
Validation loss: 1.4169489593916043

Epoch: 5| Step: 1
Training loss: 0.11686007678508759
Validation loss: 1.4250275588804675

Epoch: 5| Step: 2
Training loss: 0.2792057693004608
Validation loss: 1.4578467710043794

Epoch: 5| Step: 3
Training loss: 0.15728071331977844
Validation loss: 1.4660924044988488

Epoch: 5| Step: 4
Training loss: 0.19032739102840424
Validation loss: 1.4466131989673903

Epoch: 5| Step: 5
Training loss: 0.08670112490653992
Validation loss: 1.461720133340487

Epoch: 5| Step: 6
Training loss: 0.13712838292121887
Validation loss: 1.4682933592027234

Epoch: 5| Step: 7
Training loss: 0.09200568497180939
Validation loss: 1.447411702525231

Epoch: 5| Step: 8
Training loss: 0.15162308514118195
Validation loss: 1.4589946398171045

Epoch: 5| Step: 9
Training loss: 0.11785368621349335
Validation loss: 1.4539508281215545

Epoch: 5| Step: 10
Training loss: 0.12088197469711304
Validation loss: 1.4266713011649348

Epoch: 502| Step: 0
Training loss: 0.08825063705444336
Validation loss: 1.4498419107929352

Epoch: 5| Step: 1
Training loss: 0.117873415350914
Validation loss: 1.4687398377285208

Epoch: 5| Step: 2
Training loss: 0.09964283555746078
Validation loss: 1.4540173648506083

Epoch: 5| Step: 3
Training loss: 0.19047407805919647
Validation loss: 1.431436172095678

Epoch: 5| Step: 4
Training loss: 0.27112340927124023
Validation loss: 1.4070142853644587

Epoch: 5| Step: 5
Training loss: 0.07198978960514069
Validation loss: 1.44122604913609

Epoch: 5| Step: 6
Training loss: 0.14665977656841278
Validation loss: 1.431329696409164

Epoch: 5| Step: 7
Training loss: 0.07610993087291718
Validation loss: 1.43719433969067

Epoch: 5| Step: 8
Training loss: 0.1480691134929657
Validation loss: 1.4744722240714616

Epoch: 5| Step: 9
Training loss: 0.1811155378818512
Validation loss: 1.4700285901305497

Epoch: 5| Step: 10
Training loss: 0.13586586713790894
Validation loss: 1.4636395003205986

Epoch: 503| Step: 0
Training loss: 0.16963770985603333
Validation loss: 1.4520880458175496

Epoch: 5| Step: 1
Training loss: 0.09474936872720718
Validation loss: 1.4482294891470222

Epoch: 5| Step: 2
Training loss: 0.12635822594165802
Validation loss: 1.4719254509095223

Epoch: 5| Step: 3
Training loss: 0.10756659507751465
Validation loss: 1.4671373380127775

Epoch: 5| Step: 4
Training loss: 0.10336162894964218
Validation loss: 1.4442072145400509

Epoch: 5| Step: 5
Training loss: 0.129697784781456
Validation loss: 1.4378919088712303

Epoch: 5| Step: 6
Training loss: 0.31919151544570923
Validation loss: 1.4641174622761306

Epoch: 5| Step: 7
Training loss: 0.14767351746559143
Validation loss: 1.4656744746751682

Epoch: 5| Step: 8
Training loss: 0.12428255379199982
Validation loss: 1.4924605033730949

Epoch: 5| Step: 9
Training loss: 0.13063298165798187
Validation loss: 1.501463975957645

Epoch: 5| Step: 10
Training loss: 0.09305255115032196
Validation loss: 1.5269381205240886

Epoch: 504| Step: 0
Training loss: 0.11532624810934067
Validation loss: 1.504465454368181

Epoch: 5| Step: 1
Training loss: 0.12089095264673233
Validation loss: 1.47718422771782

Epoch: 5| Step: 2
Training loss: 0.05483020469546318
Validation loss: 1.455536638536761

Epoch: 5| Step: 3
Training loss: 0.1534341722726822
Validation loss: 1.4500090781078543

Epoch: 5| Step: 4
Training loss: 0.30302923917770386
Validation loss: 1.4483588055897785

Epoch: 5| Step: 5
Training loss: 0.08908107131719589
Validation loss: 1.4293604909732778

Epoch: 5| Step: 6
Training loss: 0.14092814922332764
Validation loss: 1.4452637780097224

Epoch: 5| Step: 7
Training loss: 0.10298605263233185
Validation loss: 1.4140115937879008

Epoch: 5| Step: 8
Training loss: 0.08671670407056808
Validation loss: 1.443356724195583

Epoch: 5| Step: 9
Training loss: 0.08212333172559738
Validation loss: 1.4753803104482672

Epoch: 5| Step: 10
Training loss: 0.15372663736343384
Validation loss: 1.4350249408393778

Epoch: 505| Step: 0
Training loss: 0.12030951678752899
Validation loss: 1.4495982162414058

Epoch: 5| Step: 1
Training loss: 0.10377015918493271
Validation loss: 1.4725340476600073

Epoch: 5| Step: 2
Training loss: 0.06375319510698318
Validation loss: 1.466769746554795

Epoch: 5| Step: 3
Training loss: 0.17891155183315277
Validation loss: 1.4579575484798801

Epoch: 5| Step: 4
Training loss: 0.16668760776519775
Validation loss: 1.4547410139473536

Epoch: 5| Step: 5
Training loss: 0.30291250348091125
Validation loss: 1.4636135562773673

Epoch: 5| Step: 6
Training loss: 0.11644365638494492
Validation loss: 1.4548204329706007

Epoch: 5| Step: 7
Training loss: 0.0771714299917221
Validation loss: 1.4339768655838505

Epoch: 5| Step: 8
Training loss: 0.10296027362346649
Validation loss: 1.4371128953913206

Epoch: 5| Step: 9
Training loss: 0.10678841173648834
Validation loss: 1.4511493457260953

Epoch: 5| Step: 10
Training loss: 0.09794977307319641
Validation loss: 1.459188106239483

Epoch: 506| Step: 0
Training loss: 0.13363255560398102
Validation loss: 1.4627047084992932

Epoch: 5| Step: 1
Training loss: 0.3164110779762268
Validation loss: 1.4803870147274387

Epoch: 5| Step: 2
Training loss: 0.11244432628154755
Validation loss: 1.4792739114453715

Epoch: 5| Step: 3
Training loss: 0.12763339281082153
Validation loss: 1.5073932627195954

Epoch: 5| Step: 4
Training loss: 0.12830671668052673
Validation loss: 1.525604304446969

Epoch: 5| Step: 5
Training loss: 0.1564987301826477
Validation loss: 1.5183818135210263

Epoch: 5| Step: 6
Training loss: 0.1113211065530777
Validation loss: 1.4435686763896738

Epoch: 5| Step: 7
Training loss: 0.13769316673278809
Validation loss: 1.4322037350746892

Epoch: 5| Step: 8
Training loss: 0.11774556338787079
Validation loss: 1.4101872687698693

Epoch: 5| Step: 9
Training loss: 0.19087909162044525
Validation loss: 1.4134691107657649

Epoch: 5| Step: 10
Training loss: 0.13405267894268036
Validation loss: 1.4211775269559634

Epoch: 507| Step: 0
Training loss: 0.15640750527381897
Validation loss: 1.4383517619102233

Epoch: 5| Step: 1
Training loss: 0.07364368438720703
Validation loss: 1.4398443545064619

Epoch: 5| Step: 2
Training loss: 0.1558971107006073
Validation loss: 1.4743291793331024

Epoch: 5| Step: 3
Training loss: 0.11934985965490341
Validation loss: 1.4812513589859009

Epoch: 5| Step: 4
Training loss: 0.1532273292541504
Validation loss: 1.4948429279429938

Epoch: 5| Step: 5
Training loss: 0.14235851168632507
Validation loss: 1.5055594444274902

Epoch: 5| Step: 6
Training loss: 0.21497544646263123
Validation loss: 1.4988181052669403

Epoch: 5| Step: 7
Training loss: 0.12705951929092407
Validation loss: 1.485586816264737

Epoch: 5| Step: 8
Training loss: 0.2890236973762512
Validation loss: 1.4658825051399968

Epoch: 5| Step: 9
Training loss: 0.09113240987062454
Validation loss: 1.454349321703757

Epoch: 5| Step: 10
Training loss: 0.08338406682014465
Validation loss: 1.4755511578693186

Epoch: 508| Step: 0
Training loss: 0.1176634281873703
Validation loss: 1.478801482467241

Epoch: 5| Step: 1
Training loss: 0.3298911452293396
Validation loss: 1.4615092162163026

Epoch: 5| Step: 2
Training loss: 0.11969928443431854
Validation loss: 1.4618273204372776

Epoch: 5| Step: 3
Training loss: 0.12908117473125458
Validation loss: 1.4357057732920493

Epoch: 5| Step: 4
Training loss: 0.0795898586511612
Validation loss: 1.4574381471962057

Epoch: 5| Step: 5
Training loss: 0.1340235471725464
Validation loss: 1.4445887829667778

Epoch: 5| Step: 6
Training loss: 0.1591220498085022
Validation loss: 1.4593047031792261

Epoch: 5| Step: 7
Training loss: 0.15793077647686005
Validation loss: 1.4673847344613844

Epoch: 5| Step: 8
Training loss: 0.16488957405090332
Validation loss: 1.4625839879435878

Epoch: 5| Step: 9
Training loss: 0.107522152364254
Validation loss: 1.479281440857918

Epoch: 5| Step: 10
Training loss: 0.07275954633951187
Validation loss: 1.523777594489436

Epoch: 509| Step: 0
Training loss: 0.15766766667366028
Validation loss: 1.553320191239798

Epoch: 5| Step: 1
Training loss: 0.10019958019256592
Validation loss: 1.5292558670043945

Epoch: 5| Step: 2
Training loss: 0.09885577112436295
Validation loss: 1.530269044701771

Epoch: 5| Step: 3
Training loss: 0.11083744466304779
Validation loss: 1.5216992619217082

Epoch: 5| Step: 4
Training loss: 0.14249621331691742
Validation loss: 1.5265168746312459

Epoch: 5| Step: 5
Training loss: 0.1255328357219696
Validation loss: 1.4964555783938336

Epoch: 5| Step: 6
Training loss: 0.0932447612285614
Validation loss: 1.4790114061806792

Epoch: 5| Step: 7
Training loss: 0.1996827870607376
Validation loss: 1.487398188601258

Epoch: 5| Step: 8
Training loss: 0.1297064572572708
Validation loss: 1.4940767326662618

Epoch: 5| Step: 9
Training loss: 0.3929925560951233
Validation loss: 1.4549937722503499

Epoch: 5| Step: 10
Training loss: 0.09679023921489716
Validation loss: 1.5145769157717306

Epoch: 510| Step: 0
Training loss: 0.13336047530174255
Validation loss: 1.4924320020983297

Epoch: 5| Step: 1
Training loss: 0.1339666098356247
Validation loss: 1.4866303051671674

Epoch: 5| Step: 2
Training loss: 0.09461968392133713
Validation loss: 1.5097679425311346

Epoch: 5| Step: 3
Training loss: 0.2958042621612549
Validation loss: 1.4838168556972215

Epoch: 5| Step: 4
Training loss: 0.10225293785333633
Validation loss: 1.5110267221286733

Epoch: 5| Step: 5
Training loss: 0.22715727984905243
Validation loss: 1.496292252694407

Epoch: 5| Step: 6
Training loss: 0.16124257445335388
Validation loss: 1.4860621498477073

Epoch: 5| Step: 7
Training loss: 0.13035157322883606
Validation loss: 1.5015742804414483

Epoch: 5| Step: 8
Training loss: 0.14150187373161316
Validation loss: 1.4479729014058267

Epoch: 5| Step: 9
Training loss: 0.11995773017406464
Validation loss: 1.432118394041574

Epoch: 5| Step: 10
Training loss: 0.10398147255182266
Validation loss: 1.4521919552997877

Epoch: 511| Step: 0
Training loss: 0.13511332869529724
Validation loss: 1.4362712342252013

Epoch: 5| Step: 1
Training loss: 0.159738227725029
Validation loss: 1.4437345945706932

Epoch: 5| Step: 2
Training loss: 0.1855606585741043
Validation loss: 1.4530905369789369

Epoch: 5| Step: 3
Training loss: 0.12927374243736267
Validation loss: 1.4367060776679748

Epoch: 5| Step: 4
Training loss: 0.10761690139770508
Validation loss: 1.4245748225078787

Epoch: 5| Step: 5
Training loss: 0.07503578811883926
Validation loss: 1.41234222022436

Epoch: 5| Step: 6
Training loss: 0.06395784020423889
Validation loss: 1.423169138611004

Epoch: 5| Step: 7
Training loss: 0.10554163157939911
Validation loss: 1.4238104256250526

Epoch: 5| Step: 8
Training loss: 0.29191815853118896
Validation loss: 1.4318116941759664

Epoch: 5| Step: 9
Training loss: 0.21223397552967072
Validation loss: 1.4474587645581973

Epoch: 5| Step: 10
Training loss: 0.12567822635173798
Validation loss: 1.4236529937354467

Epoch: 512| Step: 0
Training loss: 0.103032685816288
Validation loss: 1.4332233962192331

Epoch: 5| Step: 1
Training loss: 0.09347362071275711
Validation loss: 1.467624004169177

Epoch: 5| Step: 2
Training loss: 0.17003504931926727
Validation loss: 1.434357830914118

Epoch: 5| Step: 3
Training loss: 0.10579250007867813
Validation loss: 1.4562657225516535

Epoch: 5| Step: 4
Training loss: 0.10656275600194931
Validation loss: 1.4533228233296385

Epoch: 5| Step: 5
Training loss: 0.10192122310400009
Validation loss: 1.444435586211502

Epoch: 5| Step: 6
Training loss: 0.07406111806631088
Validation loss: 1.4567989662129393

Epoch: 5| Step: 7
Training loss: 0.15072649717330933
Validation loss: 1.4949383453656269

Epoch: 5| Step: 8
Training loss: 0.3350173234939575
Validation loss: 1.5086334982225973

Epoch: 5| Step: 9
Training loss: 0.08406929671764374
Validation loss: 1.520858480084327

Epoch: 5| Step: 10
Training loss: 0.11968234181404114
Validation loss: 1.5245828102993708

Epoch: 513| Step: 0
Training loss: 0.08110049366950989
Validation loss: 1.5402279233419767

Epoch: 5| Step: 1
Training loss: 0.08637788146734238
Validation loss: 1.5411693165379186

Epoch: 5| Step: 2
Training loss: 0.28596943616867065
Validation loss: 1.529563916626797

Epoch: 5| Step: 3
Training loss: 0.1510782688856125
Validation loss: 1.5582169922449256

Epoch: 5| Step: 4
Training loss: 0.12173168361186981
Validation loss: 1.5225593825822235

Epoch: 5| Step: 5
Training loss: 0.1227356567978859
Validation loss: 1.5261660391284573

Epoch: 5| Step: 6
Training loss: 0.17816384136676788
Validation loss: 1.4907984502853886

Epoch: 5| Step: 7
Training loss: 0.13644364476203918
Validation loss: 1.4524957819651532

Epoch: 5| Step: 8
Training loss: 0.204935222864151
Validation loss: 1.421875580664604

Epoch: 5| Step: 9
Training loss: 0.11563137918710709
Validation loss: 1.4331819818865867

Epoch: 5| Step: 10
Training loss: 0.1512346863746643
Validation loss: 1.4165957845667356

Epoch: 514| Step: 0
Training loss: 0.16336190700531006
Validation loss: 1.427618540743346

Epoch: 5| Step: 1
Training loss: 0.11211661994457245
Validation loss: 1.3940621614456177

Epoch: 5| Step: 2
Training loss: 0.14117205142974854
Validation loss: 1.4362185296191965

Epoch: 5| Step: 3
Training loss: 0.12021972984075546
Validation loss: 1.4576862050640969

Epoch: 5| Step: 4
Training loss: 0.18660664558410645
Validation loss: 1.4926008357796618

Epoch: 5| Step: 5
Training loss: 0.318416565656662
Validation loss: 1.491214071550677

Epoch: 5| Step: 6
Training loss: 0.12314137071371078
Validation loss: 1.5280414832535612

Epoch: 5| Step: 7
Training loss: 0.12934976816177368
Validation loss: 1.5358001339820124

Epoch: 5| Step: 8
Training loss: 0.1673823595046997
Validation loss: 1.5325780043037989

Epoch: 5| Step: 9
Training loss: 0.07618720829486847
Validation loss: 1.5196799603841638

Epoch: 5| Step: 10
Training loss: 0.18398059904575348
Validation loss: 1.5036568872390255

Epoch: 515| Step: 0
Training loss: 0.1020202487707138
Validation loss: 1.5099245399557135

Epoch: 5| Step: 1
Training loss: 0.16382452845573425
Validation loss: 1.4734490866302161

Epoch: 5| Step: 2
Training loss: 0.09365788847208023
Validation loss: 1.464629038046765

Epoch: 5| Step: 3
Training loss: 0.16044023633003235
Validation loss: 1.4436819143192743

Epoch: 5| Step: 4
Training loss: 0.18926291167736053
Validation loss: 1.4329971203240015

Epoch: 5| Step: 5
Training loss: 0.1270325481891632
Validation loss: 1.4019556724896995

Epoch: 5| Step: 6
Training loss: 0.1992868036031723
Validation loss: 1.4185439117493168

Epoch: 5| Step: 7
Training loss: 0.1475491225719452
Validation loss: 1.4743332157852829

Epoch: 5| Step: 8
Training loss: 0.36875754594802856
Validation loss: 1.496943191815448

Epoch: 5| Step: 9
Training loss: 0.12123189121484756
Validation loss: 1.4885810062449465

Epoch: 5| Step: 10
Training loss: 0.12192843854427338
Validation loss: 1.4924881689010128

Epoch: 516| Step: 0
Training loss: 0.07195967435836792
Validation loss: 1.4701824726596955

Epoch: 5| Step: 1
Training loss: 0.09814535081386566
Validation loss: 1.4566844496675717

Epoch: 5| Step: 2
Training loss: 0.13019269704818726
Validation loss: 1.441221014786792

Epoch: 5| Step: 3
Training loss: 0.1288311779499054
Validation loss: 1.452118218586009

Epoch: 5| Step: 4
Training loss: 0.2887834906578064
Validation loss: 1.4336622838051087

Epoch: 5| Step: 5
Training loss: 0.15171721577644348
Validation loss: 1.4705674738012335

Epoch: 5| Step: 6
Training loss: 0.1152939647436142
Validation loss: 1.4748810580981675

Epoch: 5| Step: 7
Training loss: 0.0756475105881691
Validation loss: 1.4800045144173406

Epoch: 5| Step: 8
Training loss: 0.12489444017410278
Validation loss: 1.4997335659560336

Epoch: 5| Step: 9
Training loss: 0.14260996878147125
Validation loss: 1.4671073587991859

Epoch: 5| Step: 10
Training loss: 0.08566676825284958
Validation loss: 1.4660163329493614

Epoch: 517| Step: 0
Training loss: 0.08064432442188263
Validation loss: 1.4524146959345827

Epoch: 5| Step: 1
Training loss: 0.11470825970172882
Validation loss: 1.4532023963107858

Epoch: 5| Step: 2
Training loss: 0.15201659500598907
Validation loss: 1.4785279676478396

Epoch: 5| Step: 3
Training loss: 0.09879472106695175
Validation loss: 1.4509470347435243

Epoch: 5| Step: 4
Training loss: 0.12440261989831924
Validation loss: 1.4251237492407522

Epoch: 5| Step: 5
Training loss: 0.1500435769557953
Validation loss: 1.444987561113091

Epoch: 5| Step: 6
Training loss: 0.06948725134134293
Validation loss: 1.4515042984357445

Epoch: 5| Step: 7
Training loss: 0.09896473586559296
Validation loss: 1.4262191710933563

Epoch: 5| Step: 8
Training loss: 0.2707783579826355
Validation loss: 1.434923206606219

Epoch: 5| Step: 9
Training loss: 0.14378204941749573
Validation loss: 1.4405184022841915

Epoch: 5| Step: 10
Training loss: 0.12443067133426666
Validation loss: 1.4579136307521532

Epoch: 518| Step: 0
Training loss: 0.07187742739915848
Validation loss: 1.4576987015303744

Epoch: 5| Step: 1
Training loss: 0.111732617020607
Validation loss: 1.4591989594121133

Epoch: 5| Step: 2
Training loss: 0.09197214245796204
Validation loss: 1.4548960193510978

Epoch: 5| Step: 3
Training loss: 0.09629005193710327
Validation loss: 1.4528125768066735

Epoch: 5| Step: 4
Training loss: 0.09861840307712555
Validation loss: 1.4492021119722756

Epoch: 5| Step: 5
Training loss: 0.07660029828548431
Validation loss: 1.4668412182920723

Epoch: 5| Step: 6
Training loss: 0.10825274884700775
Validation loss: 1.4206176675775999

Epoch: 5| Step: 7
Training loss: 0.11433076858520508
Validation loss: 1.4254200086798718

Epoch: 5| Step: 8
Training loss: 0.1495581567287445
Validation loss: 1.4537818995855187

Epoch: 5| Step: 9
Training loss: 0.092234767973423
Validation loss: 1.4060820648747105

Epoch: 5| Step: 10
Training loss: 0.34570497274398804
Validation loss: 1.4306620949058122

Epoch: 519| Step: 0
Training loss: 0.10876457393169403
Validation loss: 1.4188432757572462

Epoch: 5| Step: 1
Training loss: 0.09124960750341415
Validation loss: 1.425178086885842

Epoch: 5| Step: 2
Training loss: 0.06866301596164703
Validation loss: 1.4155234931617655

Epoch: 5| Step: 3
Training loss: 0.16298986971378326
Validation loss: 1.426714979192262

Epoch: 5| Step: 4
Training loss: 0.08393172919750214
Validation loss: 1.437234172257044

Epoch: 5| Step: 5
Training loss: 0.12894700467586517
Validation loss: 1.4718118047201505

Epoch: 5| Step: 6
Training loss: 0.29292961955070496
Validation loss: 1.4655559383412844

Epoch: 5| Step: 7
Training loss: 0.14503233134746552
Validation loss: 1.4638868942055652

Epoch: 5| Step: 8
Training loss: 0.13856203854084015
Validation loss: 1.4741541954778856

Epoch: 5| Step: 9
Training loss: 0.10310472548007965
Validation loss: 1.458319499928464

Epoch: 5| Step: 10
Training loss: 0.12219758331775665
Validation loss: 1.466879052500571

Epoch: 520| Step: 0
Training loss: 0.06366367638111115
Validation loss: 1.4733056765730663

Epoch: 5| Step: 1
Training loss: 0.14148367941379547
Validation loss: 1.4524946058950117

Epoch: 5| Step: 2
Training loss: 0.09454181045293808
Validation loss: 1.4590020718113068

Epoch: 5| Step: 3
Training loss: 0.1551409661769867
Validation loss: 1.461189341801469

Epoch: 5| Step: 4
Training loss: 0.11116552352905273
Validation loss: 1.4295068120443692

Epoch: 5| Step: 5
Training loss: 0.31640443205833435
Validation loss: 1.4099859960617558

Epoch: 5| Step: 6
Training loss: 0.1434432417154312
Validation loss: 1.4102137921958842

Epoch: 5| Step: 7
Training loss: 0.07662468403577805
Validation loss: 1.4353697299957275

Epoch: 5| Step: 8
Training loss: 0.08955607563257217
Validation loss: 1.4248356075697048

Epoch: 5| Step: 9
Training loss: 0.1454903483390808
Validation loss: 1.428749244700196

Epoch: 5| Step: 10
Training loss: 0.14940591156482697
Validation loss: 1.4498160654498684

Epoch: 521| Step: 0
Training loss: 0.05711112171411514
Validation loss: 1.4184042548620572

Epoch: 5| Step: 1
Training loss: 0.1200467199087143
Validation loss: 1.443763808537555

Epoch: 5| Step: 2
Training loss: 0.18498489260673523
Validation loss: 1.4381491766181043

Epoch: 5| Step: 3
Training loss: 0.09280464053153992
Validation loss: 1.4321632821072814

Epoch: 5| Step: 4
Training loss: 0.08852052688598633
Validation loss: 1.426430550954675

Epoch: 5| Step: 5
Training loss: 0.11734382808208466
Validation loss: 1.4773069491950415

Epoch: 5| Step: 6
Training loss: 0.07505372911691666
Validation loss: 1.4624143954246276

Epoch: 5| Step: 7
Training loss: 0.09856526553630829
Validation loss: 1.4909927178454656

Epoch: 5| Step: 8
Training loss: 0.10439427196979523
Validation loss: 1.4970105860822944

Epoch: 5| Step: 9
Training loss: 0.08430147171020508
Validation loss: 1.503820303947695

Epoch: 5| Step: 10
Training loss: 0.31618377566337585
Validation loss: 1.5025394385860813

Epoch: 522| Step: 0
Training loss: 0.08865722268819809
Validation loss: 1.5098616487236434

Epoch: 5| Step: 1
Training loss: 0.12838561832904816
Validation loss: 1.5182038558426725

Epoch: 5| Step: 2
Training loss: 0.16666588187217712
Validation loss: 1.4993550982526553

Epoch: 5| Step: 3
Training loss: 0.12487856298685074
Validation loss: 1.5102058572153891

Epoch: 5| Step: 4
Training loss: 0.08036027103662491
Validation loss: 1.4931919433737313

Epoch: 5| Step: 5
Training loss: 0.07862456142902374
Validation loss: 1.4920466817835325

Epoch: 5| Step: 6
Training loss: 0.08798877894878387
Validation loss: 1.4793617417735438

Epoch: 5| Step: 7
Training loss: 0.13654842972755432
Validation loss: 1.4687517407119914

Epoch: 5| Step: 8
Training loss: 0.1187320351600647
Validation loss: 1.4789486290306173

Epoch: 5| Step: 9
Training loss: 0.09265585988759995
Validation loss: 1.4564750188140458

Epoch: 5| Step: 10
Training loss: 0.32846251130104065
Validation loss: 1.4371180098543885

Epoch: 523| Step: 0
Training loss: 0.12417753040790558
Validation loss: 1.428105923437303

Epoch: 5| Step: 1
Training loss: 0.11776427924633026
Validation loss: 1.3930116468860256

Epoch: 5| Step: 2
Training loss: 0.1041397675871849
Validation loss: 1.4044946406477241

Epoch: 5| Step: 3
Training loss: 0.07654206454753876
Validation loss: 1.3995049730423959

Epoch: 5| Step: 4
Training loss: 0.10559318214654922
Validation loss: 1.3905831338256918

Epoch: 5| Step: 5
Training loss: 0.08315025269985199
Validation loss: 1.4307858354301863

Epoch: 5| Step: 6
Training loss: 0.32411661744117737
Validation loss: 1.4185016591061828

Epoch: 5| Step: 7
Training loss: 0.1938437819480896
Validation loss: 1.4556310407577022

Epoch: 5| Step: 8
Training loss: 0.07224146276712418
Validation loss: 1.4334939141427316

Epoch: 5| Step: 9
Training loss: 0.08468440920114517
Validation loss: 1.4539992617022606

Epoch: 5| Step: 10
Training loss: 0.10178141295909882
Validation loss: 1.4620885579816756

Epoch: 524| Step: 0
Training loss: 0.08822741359472275
Validation loss: 1.4617339039361605

Epoch: 5| Step: 1
Training loss: 0.11738133430480957
Validation loss: 1.4390136285494732

Epoch: 5| Step: 2
Training loss: 0.1645108163356781
Validation loss: 1.4727897015951013

Epoch: 5| Step: 3
Training loss: 0.16517901420593262
Validation loss: 1.4584547858084402

Epoch: 5| Step: 4
Training loss: 0.12393160164356232
Validation loss: 1.4245600315832323

Epoch: 5| Step: 5
Training loss: 0.10234123468399048
Validation loss: 1.4289955733924784

Epoch: 5| Step: 6
Training loss: 0.13782553374767303
Validation loss: 1.4081317250446608

Epoch: 5| Step: 7
Training loss: 0.0957835242152214
Validation loss: 1.4131826892975838

Epoch: 5| Step: 8
Training loss: 0.08485442399978638
Validation loss: 1.4155232214158582

Epoch: 5| Step: 9
Training loss: 0.08216620981693268
Validation loss: 1.451152273403701

Epoch: 5| Step: 10
Training loss: 0.3471566140651703
Validation loss: 1.454792828970058

Epoch: 525| Step: 0
Training loss: 0.12437901645898819
Validation loss: 1.4710326310127013

Epoch: 5| Step: 1
Training loss: 0.162557914853096
Validation loss: 1.4784616834373885

Epoch: 5| Step: 2
Training loss: 0.28548943996429443
Validation loss: 1.4468204212445084

Epoch: 5| Step: 3
Training loss: 0.09632506221532822
Validation loss: 1.4512121690216886

Epoch: 5| Step: 4
Training loss: 0.14397282898426056
Validation loss: 1.4740091626362135

Epoch: 5| Step: 5
Training loss: 0.13701339066028595
Validation loss: 1.4910370528057058

Epoch: 5| Step: 6
Training loss: 0.13422363996505737
Validation loss: 1.4958316151813795

Epoch: 5| Step: 7
Training loss: 0.09669804573059082
Validation loss: 1.5010748012091524

Epoch: 5| Step: 8
Training loss: 0.22760061919689178
Validation loss: 1.4860652492892357

Epoch: 5| Step: 9
Training loss: 0.0637340396642685
Validation loss: 1.4882570466687601

Epoch: 5| Step: 10
Training loss: 0.08935524523258209
Validation loss: 1.4912236006029191

Epoch: 526| Step: 0
Training loss: 0.10288600623607635
Validation loss: 1.4738741670885394

Epoch: 5| Step: 1
Training loss: 0.10004743188619614
Validation loss: 1.4668940728710544

Epoch: 5| Step: 2
Training loss: 0.22319217026233673
Validation loss: 1.491869065069383

Epoch: 5| Step: 3
Training loss: 0.14470848441123962
Validation loss: 1.482803540845071

Epoch: 5| Step: 4
Training loss: 0.18208220601081848
Validation loss: 1.4635332399798977

Epoch: 5| Step: 5
Training loss: 0.09349483251571655
Validation loss: 1.469940185546875

Epoch: 5| Step: 6
Training loss: 0.11647465080022812
Validation loss: 1.4423088578767673

Epoch: 5| Step: 7
Training loss: 0.10396021604537964
Validation loss: 1.4524960133337206

Epoch: 5| Step: 8
Training loss: 0.09231514483690262
Validation loss: 1.431966277860826

Epoch: 5| Step: 9
Training loss: 0.10748525708913803
Validation loss: 1.4328334216148622

Epoch: 5| Step: 10
Training loss: 0.1443844586610794
Validation loss: 1.4380747041394633

Epoch: 527| Step: 0
Training loss: 0.09519380331039429
Validation loss: 1.4284422038703837

Epoch: 5| Step: 1
Training loss: 0.13482311367988586
Validation loss: 1.4057551494208715

Epoch: 5| Step: 2
Training loss: 0.0903548151254654
Validation loss: 1.3959776432283464

Epoch: 5| Step: 3
Training loss: 0.09773561358451843
Validation loss: 1.3951334357261658

Epoch: 5| Step: 4
Training loss: 0.16455624997615814
Validation loss: 1.3877724524467223

Epoch: 5| Step: 5
Training loss: 0.12005772441625595
Validation loss: 1.4211180165249815

Epoch: 5| Step: 6
Training loss: 0.28194695711135864
Validation loss: 1.4005035725972985

Epoch: 5| Step: 7
Training loss: 0.13984529674053192
Validation loss: 1.4167189162264588

Epoch: 5| Step: 8
Training loss: 0.11360205709934235
Validation loss: 1.3973571363315787

Epoch: 5| Step: 9
Training loss: 0.1210225373506546
Validation loss: 1.4051530476539367

Epoch: 5| Step: 10
Training loss: 0.1060246154665947
Validation loss: 1.4252993554197333

Epoch: 528| Step: 0
Training loss: 0.09524009376764297
Validation loss: 1.3935996922113563

Epoch: 5| Step: 1
Training loss: 0.06873603165149689
Validation loss: 1.4375636269969325

Epoch: 5| Step: 2
Training loss: 0.12698322534561157
Validation loss: 1.4166572715646477

Epoch: 5| Step: 3
Training loss: 0.246669203042984
Validation loss: 1.4243842760721843

Epoch: 5| Step: 4
Training loss: 0.12180282920598984
Validation loss: 1.4264964365190076

Epoch: 5| Step: 5
Training loss: 0.09781987965106964
Validation loss: 1.4137020187993203

Epoch: 5| Step: 6
Training loss: 0.07655732333660126
Validation loss: 1.4679425429272395

Epoch: 5| Step: 7
Training loss: 0.14723661541938782
Validation loss: 1.4376314083735149

Epoch: 5| Step: 8
Training loss: 0.11169624328613281
Validation loss: 1.4495839008720972

Epoch: 5| Step: 9
Training loss: 0.07160261273384094
Validation loss: 1.4366542075269966

Epoch: 5| Step: 10
Training loss: 0.07334521412849426
Validation loss: 1.4277124110088553

Epoch: 529| Step: 0
Training loss: 0.08532517403364182
Validation loss: 1.4160243452236216

Epoch: 5| Step: 1
Training loss: 0.08023881167173386
Validation loss: 1.432854333231526

Epoch: 5| Step: 2
Training loss: 0.10887368768453598
Validation loss: 1.424197913498007

Epoch: 5| Step: 3
Training loss: 0.07922999560832977
Validation loss: 1.4436641816169984

Epoch: 5| Step: 4
Training loss: 0.09541475772857666
Validation loss: 1.4356596495515557

Epoch: 5| Step: 5
Training loss: 0.0687173381447792
Validation loss: 1.4160486690459713

Epoch: 5| Step: 6
Training loss: 0.05467907339334488
Validation loss: 1.4192338534580764

Epoch: 5| Step: 7
Training loss: 0.3050183653831482
Validation loss: 1.4409128004504788

Epoch: 5| Step: 8
Training loss: 0.1934630423784256
Validation loss: 1.4174246800843107

Epoch: 5| Step: 9
Training loss: 0.13575980067253113
Validation loss: 1.4125669951079993

Epoch: 5| Step: 10
Training loss: 0.06975919008255005
Validation loss: 1.409912238838852

Epoch: 530| Step: 0
Training loss: 0.14142180979251862
Validation loss: 1.4237772418606667

Epoch: 5| Step: 1
Training loss: 0.11373312771320343
Validation loss: 1.4192206757042998

Epoch: 5| Step: 2
Training loss: 0.0839947834610939
Validation loss: 1.4098085485478884

Epoch: 5| Step: 3
Training loss: 0.0837944895029068
Validation loss: 1.4485316725187405

Epoch: 5| Step: 4
Training loss: 0.11169536411762238
Validation loss: 1.4284366958884782

Epoch: 5| Step: 5
Training loss: 0.2227403223514557
Validation loss: 1.4330627956698019

Epoch: 5| Step: 6
Training loss: 0.06652967631816864
Validation loss: 1.4226832883332365

Epoch: 5| Step: 7
Training loss: 0.07894427329301834
Validation loss: 1.4490274575448805

Epoch: 5| Step: 8
Training loss: 0.11964313685894012
Validation loss: 1.4430473760891986

Epoch: 5| Step: 9
Training loss: 0.11986406147480011
Validation loss: 1.4640530834915817

Epoch: 5| Step: 10
Training loss: 0.1175256073474884
Validation loss: 1.4881831112728323

Epoch: 531| Step: 0
Training loss: 0.1620979607105255
Validation loss: 1.4656385644789665

Epoch: 5| Step: 1
Training loss: 0.1189100593328476
Validation loss: 1.4971149993199173

Epoch: 5| Step: 2
Training loss: 0.12492481619119644
Validation loss: 1.4841165798966602

Epoch: 5| Step: 3
Training loss: 0.05378464609384537
Validation loss: 1.47970409675311

Epoch: 5| Step: 4
Training loss: 0.08855704963207245
Validation loss: 1.4456539128416328

Epoch: 5| Step: 5
Training loss: 0.07634477317333221
Validation loss: 1.442436146479781

Epoch: 5| Step: 6
Training loss: 0.08685115724802017
Validation loss: 1.4201652183327624

Epoch: 5| Step: 7
Training loss: 0.102033331990242
Validation loss: 1.4252813221305929

Epoch: 5| Step: 8
Training loss: 0.09210208803415298
Validation loss: 1.438603606275333

Epoch: 5| Step: 9
Training loss: 0.14421534538269043
Validation loss: 1.4363601989643549

Epoch: 5| Step: 10
Training loss: 0.2745826244354248
Validation loss: 1.425326173023511

Epoch: 532| Step: 0
Training loss: 0.1133245974779129
Validation loss: 1.4446684795041238

Epoch: 5| Step: 1
Training loss: 0.08715226501226425
Validation loss: 1.4307413921561292

Epoch: 5| Step: 2
Training loss: 0.06722965091466904
Validation loss: 1.4642037614699333

Epoch: 5| Step: 3
Training loss: 0.222432941198349
Validation loss: 1.4393122696107434

Epoch: 5| Step: 4
Training loss: 0.08938176929950714
Validation loss: 1.455139772866362

Epoch: 5| Step: 5
Training loss: 0.08480139821767807
Validation loss: 1.4782797034068773

Epoch: 5| Step: 6
Training loss: 0.15291988849639893
Validation loss: 1.4892755298204319

Epoch: 5| Step: 7
Training loss: 0.11836640536785126
Validation loss: 1.4631890481518162

Epoch: 5| Step: 8
Training loss: 0.12618227303028107
Validation loss: 1.4611385419804563

Epoch: 5| Step: 9
Training loss: 0.08504486829042435
Validation loss: 1.4540027546626266

Epoch: 5| Step: 10
Training loss: 0.09025739133358002
Validation loss: 1.4305127179750832

Epoch: 533| Step: 0
Training loss: 0.12755854427814484
Validation loss: 1.4219280686429752

Epoch: 5| Step: 1
Training loss: 0.10047434270381927
Validation loss: 1.4183877616800287

Epoch: 5| Step: 2
Training loss: 0.0766056552529335
Validation loss: 1.4405891728657547

Epoch: 5| Step: 3
Training loss: 0.07317733019590378
Validation loss: 1.4215072098598684

Epoch: 5| Step: 4
Training loss: 0.09082825481891632
Validation loss: 1.4416496766510831

Epoch: 5| Step: 5
Training loss: 0.12098269164562225
Validation loss: 1.447723783472533

Epoch: 5| Step: 6
Training loss: 0.06862851232290268
Validation loss: 1.4373419131002119

Epoch: 5| Step: 7
Training loss: 0.08951590955257416
Validation loss: 1.4303009369040047

Epoch: 5| Step: 8
Training loss: 0.24449653923511505
Validation loss: 1.4129526333142353

Epoch: 5| Step: 9
Training loss: 0.09968573600053787
Validation loss: 1.3992523583032752

Epoch: 5| Step: 10
Training loss: 0.1400752067565918
Validation loss: 1.4239533678177865

Epoch: 534| Step: 0
Training loss: 0.064030721783638
Validation loss: 1.438565210629535

Epoch: 5| Step: 1
Training loss: 0.10766728222370148
Validation loss: 1.4148048444460797

Epoch: 5| Step: 2
Training loss: 0.1259373128414154
Validation loss: 1.4542121207842262

Epoch: 5| Step: 3
Training loss: 0.07570596784353256
Validation loss: 1.4328581639515456

Epoch: 5| Step: 4
Training loss: 0.25352734327316284
Validation loss: 1.4388697890825168

Epoch: 5| Step: 5
Training loss: 0.08141491562128067
Validation loss: 1.4481594972713019

Epoch: 5| Step: 6
Training loss: 0.11431746184825897
Validation loss: 1.4340843782630017

Epoch: 5| Step: 7
Training loss: 0.13601358234882355
Validation loss: 1.4497090539624613

Epoch: 5| Step: 8
Training loss: 0.1049775630235672
Validation loss: 1.425218883381095

Epoch: 5| Step: 9
Training loss: 0.10639329254627228
Validation loss: 1.424360631614603

Epoch: 5| Step: 10
Training loss: 0.09345917403697968
Validation loss: 1.406835324020796

Epoch: 535| Step: 0
Training loss: 0.07795441895723343
Validation loss: 1.4131605830243839

Epoch: 5| Step: 1
Training loss: 0.130141943693161
Validation loss: 1.3955023814273138

Epoch: 5| Step: 2
Training loss: 0.1193297877907753
Validation loss: 1.3966561504589614

Epoch: 5| Step: 3
Training loss: 0.10240151733160019
Validation loss: 1.429810227886323

Epoch: 5| Step: 4
Training loss: 0.13860099017620087
Validation loss: 1.4397058717666134

Epoch: 5| Step: 5
Training loss: 0.12990711629390717
Validation loss: 1.4534534369745562

Epoch: 5| Step: 6
Training loss: 0.12455680221319199
Validation loss: 1.4445603803921772

Epoch: 5| Step: 7
Training loss: 0.11370740830898285
Validation loss: 1.4251893149909152

Epoch: 5| Step: 8
Training loss: 0.09091930091381073
Validation loss: 1.4385725067507835

Epoch: 5| Step: 9
Training loss: 0.12167836725711823
Validation loss: 1.4208142295960458

Epoch: 5| Step: 10
Training loss: 0.2958361804485321
Validation loss: 1.423268356630879

Epoch: 536| Step: 0
Training loss: 0.1336974799633026
Validation loss: 1.4102032812692786

Epoch: 5| Step: 1
Training loss: 0.2673129141330719
Validation loss: 1.408783680649214

Epoch: 5| Step: 2
Training loss: 0.08380044996738434
Validation loss: 1.3924414605222724

Epoch: 5| Step: 3
Training loss: 0.086441770195961
Validation loss: 1.4076036381465133

Epoch: 5| Step: 4
Training loss: 0.145478755235672
Validation loss: 1.4137119388067594

Epoch: 5| Step: 5
Training loss: 0.0843328908085823
Validation loss: 1.4158339449154433

Epoch: 5| Step: 6
Training loss: 0.14131560921669006
Validation loss: 1.415412611858819

Epoch: 5| Step: 7
Training loss: 0.06935817003250122
Validation loss: 1.413539481419389

Epoch: 5| Step: 8
Training loss: 0.06790801882743835
Validation loss: 1.4292051728053758

Epoch: 5| Step: 9
Training loss: 0.13660822808742523
Validation loss: 1.4546553588682605

Epoch: 5| Step: 10
Training loss: 0.11597058176994324
Validation loss: 1.45345466239478

Epoch: 537| Step: 0
Training loss: 0.14680235087871552
Validation loss: 1.4777837978896273

Epoch: 5| Step: 1
Training loss: 0.14849591255187988
Validation loss: 1.4996288899452455

Epoch: 5| Step: 2
Training loss: 0.31088316440582275
Validation loss: 1.4556611455896848

Epoch: 5| Step: 3
Training loss: 0.09607052057981491
Validation loss: 1.4285740211445799

Epoch: 5| Step: 4
Training loss: 0.1401757299900055
Validation loss: 1.4003197473864402

Epoch: 5| Step: 5
Training loss: 0.07525583356618881
Validation loss: 1.4138458826208626

Epoch: 5| Step: 6
Training loss: 0.08980730921030045
Validation loss: 1.4072100334270026

Epoch: 5| Step: 7
Training loss: 0.12406931072473526
Validation loss: 1.4403065148220267

Epoch: 5| Step: 8
Training loss: 0.0971769243478775
Validation loss: 1.4558401582061604

Epoch: 5| Step: 9
Training loss: 0.09848228096961975
Validation loss: 1.4558278283765238

Epoch: 5| Step: 10
Training loss: 0.1397799253463745
Validation loss: 1.4607767110229821

Epoch: 538| Step: 0
Training loss: 0.08281458914279938
Validation loss: 1.4842489150262648

Epoch: 5| Step: 1
Training loss: 0.15387777984142303
Validation loss: 1.5127355988307665

Epoch: 5| Step: 2
Training loss: 0.1554834395647049
Validation loss: 1.4661224003761046

Epoch: 5| Step: 3
Training loss: 0.06789696216583252
Validation loss: 1.46760182867768

Epoch: 5| Step: 4
Training loss: 0.06791920214891434
Validation loss: 1.44167245716177

Epoch: 5| Step: 5
Training loss: 0.07949187606573105
Validation loss: 1.4469043259979577

Epoch: 5| Step: 6
Training loss: 0.11139100790023804
Validation loss: 1.4347479343414307

Epoch: 5| Step: 7
Training loss: 0.09920051693916321
Validation loss: 1.433932755583076

Epoch: 5| Step: 8
Training loss: 0.1505127102136612
Validation loss: 1.4363860436665115

Epoch: 5| Step: 9
Training loss: 0.235067218542099
Validation loss: 1.4432125540189846

Epoch: 5| Step: 10
Training loss: 0.1280689686536789
Validation loss: 1.4274003255751826

Epoch: 539| Step: 0
Training loss: 0.12964221835136414
Validation loss: 1.466375768825572

Epoch: 5| Step: 1
Training loss: 0.09139034152030945
Validation loss: 1.4429230049092283

Epoch: 5| Step: 2
Training loss: 0.0867481455206871
Validation loss: 1.4270438045583747

Epoch: 5| Step: 3
Training loss: 0.08553056418895721
Validation loss: 1.4173470338185628

Epoch: 5| Step: 4
Training loss: 0.11775469779968262
Validation loss: 1.4128712466968003

Epoch: 5| Step: 5
Training loss: 0.05423302575945854
Validation loss: 1.4298894918093117

Epoch: 5| Step: 6
Training loss: 0.07622838020324707
Validation loss: 1.395384644949308

Epoch: 5| Step: 7
Training loss: 0.13061627745628357
Validation loss: 1.3901371289325017

Epoch: 5| Step: 8
Training loss: 0.078379787504673
Validation loss: 1.3533164826772546

Epoch: 5| Step: 9
Training loss: 0.07949502766132355
Validation loss: 1.3665816271176903

Epoch: 5| Step: 10
Training loss: 0.2627948224544525
Validation loss: 1.379239243845786

Epoch: 540| Step: 0
Training loss: 0.16418945789337158
Validation loss: 1.378674037994877

Epoch: 5| Step: 1
Training loss: 0.09165561199188232
Validation loss: 1.3761803411668347

Epoch: 5| Step: 2
Training loss: 0.09402544796466827
Validation loss: 1.4028219881878103

Epoch: 5| Step: 3
Training loss: 0.09271680563688278
Validation loss: 1.4325172080788562

Epoch: 5| Step: 4
Training loss: 0.10673283040523529
Validation loss: 1.4506136614789245

Epoch: 5| Step: 5
Training loss: 0.09283456206321716
Validation loss: 1.440943859597688

Epoch: 5| Step: 6
Training loss: 0.24682751297950745
Validation loss: 1.4738552201819677

Epoch: 5| Step: 7
Training loss: 0.12102445214986801
Validation loss: 1.4710897232896538

Epoch: 5| Step: 8
Training loss: 0.14563079178333282
Validation loss: 1.4755824060850247

Epoch: 5| Step: 9
Training loss: 0.09337891638278961
Validation loss: 1.4443904469090123

Epoch: 5| Step: 10
Training loss: 0.10397620499134064
Validation loss: 1.4419308157377346

Epoch: 541| Step: 0
Training loss: 0.11944973468780518
Validation loss: 1.4208271708539737

Epoch: 5| Step: 1
Training loss: 0.10237002372741699
Validation loss: 1.4271487728241952

Epoch: 5| Step: 2
Training loss: 0.09015832841396332
Validation loss: 1.4063941983766453

Epoch: 5| Step: 3
Training loss: 0.23676595091819763
Validation loss: 1.4109182473151916

Epoch: 5| Step: 4
Training loss: 0.09693548828363419
Validation loss: 1.4217888591110066

Epoch: 5| Step: 5
Training loss: 0.11838839203119278
Validation loss: 1.4150634273405998

Epoch: 5| Step: 6
Training loss: 0.10724272578954697
Validation loss: 1.4345375632727018

Epoch: 5| Step: 7
Training loss: 0.16830018162727356
Validation loss: 1.464991182409307

Epoch: 5| Step: 8
Training loss: 0.14440204203128815
Validation loss: 1.4612707848189979

Epoch: 5| Step: 9
Training loss: 0.11305920779705048
Validation loss: 1.4599297046661377

Epoch: 5| Step: 10
Training loss: 0.19212864339351654
Validation loss: 1.5017166868332894

Epoch: 542| Step: 0
Training loss: 0.16026835143566132
Validation loss: 1.5066793567390853

Epoch: 5| Step: 1
Training loss: 0.0739477202296257
Validation loss: 1.4532495256393188

Epoch: 5| Step: 2
Training loss: 0.06685134023427963
Validation loss: 1.411661046807484

Epoch: 5| Step: 3
Training loss: 0.16873659193515778
Validation loss: 1.4267838834434428

Epoch: 5| Step: 4
Training loss: 0.09497877955436707
Validation loss: 1.3990838604588662

Epoch: 5| Step: 5
Training loss: 0.2647004723548889
Validation loss: 1.3975796212432205

Epoch: 5| Step: 6
Training loss: 0.1281460076570511
Validation loss: 1.384728773947685

Epoch: 5| Step: 7
Training loss: 0.04690774530172348
Validation loss: 1.378260890642802

Epoch: 5| Step: 8
Training loss: 0.09124957770109177
Validation loss: 1.401128189538115

Epoch: 5| Step: 9
Training loss: 0.059302978217601776
Validation loss: 1.4009404970753578

Epoch: 5| Step: 10
Training loss: 0.16850773990154266
Validation loss: 1.4008579100331953

Epoch: 543| Step: 0
Training loss: 0.13228097558021545
Validation loss: 1.417462295101535

Epoch: 5| Step: 1
Training loss: 0.1467151939868927
Validation loss: 1.4072087336612005

Epoch: 5| Step: 2
Training loss: 0.15158765017986298
Validation loss: 1.4342250567610546

Epoch: 5| Step: 3
Training loss: 0.08334032446146011
Validation loss: 1.418967625146271

Epoch: 5| Step: 4
Training loss: 0.10065104067325592
Validation loss: 1.433152005236636

Epoch: 5| Step: 5
Training loss: 0.08459450304508209
Validation loss: 1.4386237975089782

Epoch: 5| Step: 6
Training loss: 0.11613907665014267
Validation loss: 1.431038413637428

Epoch: 5| Step: 7
Training loss: 0.24714989960193634
Validation loss: 1.4296870590538107

Epoch: 5| Step: 8
Training loss: 0.11487293243408203
Validation loss: 1.4135705937621414

Epoch: 5| Step: 9
Training loss: 0.10123155266046524
Validation loss: 1.3902773587934432

Epoch: 5| Step: 10
Training loss: 0.12609468400478363
Validation loss: 1.3745155180654218

Epoch: 544| Step: 0
Training loss: 0.11941511929035187
Validation loss: 1.3877118813094271

Epoch: 5| Step: 1
Training loss: 0.11499150097370148
Validation loss: 1.3619575833761564

Epoch: 5| Step: 2
Training loss: 0.0806979164481163
Validation loss: 1.3408426072007866

Epoch: 5| Step: 3
Training loss: 0.12967023253440857
Validation loss: 1.3860744417354625

Epoch: 5| Step: 4
Training loss: 0.09003864973783493
Validation loss: 1.385877195224967

Epoch: 5| Step: 5
Training loss: 0.08728106319904327
Validation loss: 1.3973148099837764

Epoch: 5| Step: 6
Training loss: 0.10535778850317001
Validation loss: 1.4150030087399226

Epoch: 5| Step: 7
Training loss: 0.12016169726848602
Validation loss: 1.4149533958845242

Epoch: 5| Step: 8
Training loss: 0.08033924549818039
Validation loss: 1.4455947401703044

Epoch: 5| Step: 9
Training loss: 0.06421815603971481
Validation loss: 1.4118415245445826

Epoch: 5| Step: 10
Training loss: 0.22488683462142944
Validation loss: 1.3978093362623645

Epoch: 545| Step: 0
Training loss: 0.11864010244607925
Validation loss: 1.427392029634086

Epoch: 5| Step: 1
Training loss: 0.06613393872976303
Validation loss: 1.4590255848823055

Epoch: 5| Step: 2
Training loss: 0.1242576390504837
Validation loss: 1.4330624354782926

Epoch: 5| Step: 3
Training loss: 0.0769883245229721
Validation loss: 1.4503500359032744

Epoch: 5| Step: 4
Training loss: 0.12360374629497528
Validation loss: 1.4619553640324583

Epoch: 5| Step: 5
Training loss: 0.10723531246185303
Validation loss: 1.4634012240235523

Epoch: 5| Step: 6
Training loss: 0.18198734521865845
Validation loss: 1.45554107235324

Epoch: 5| Step: 7
Training loss: 0.12781313061714172
Validation loss: 1.4311392679009387

Epoch: 5| Step: 8
Training loss: 0.11958882957696915
Validation loss: 1.408380719923204

Epoch: 5| Step: 9
Training loss: 0.08771699666976929
Validation loss: 1.4138423319785827

Epoch: 5| Step: 10
Training loss: 0.11937222629785538
Validation loss: 1.3763181894056258

Epoch: 546| Step: 0
Training loss: 0.10558631271123886
Validation loss: 1.3674550441003614

Epoch: 5| Step: 1
Training loss: 0.08303549885749817
Validation loss: 1.3812783584799817

Epoch: 5| Step: 2
Training loss: 0.264862060546875
Validation loss: 1.3744999465122019

Epoch: 5| Step: 3
Training loss: 0.10814349353313446
Validation loss: 1.4039415505624586

Epoch: 5| Step: 4
Training loss: 0.07797703891992569
Validation loss: 1.40504204457806

Epoch: 5| Step: 5
Training loss: 0.09694065153598785
Validation loss: 1.410313230688854

Epoch: 5| Step: 6
Training loss: 0.09541372954845428
Validation loss: 1.432341060330791

Epoch: 5| Step: 7
Training loss: 0.10984406620264053
Validation loss: 1.4425601959228516

Epoch: 5| Step: 8
Training loss: 0.06973092257976532
Validation loss: 1.4807910329552108

Epoch: 5| Step: 9
Training loss: 0.0921752005815506
Validation loss: 1.474975480828234

Epoch: 5| Step: 10
Training loss: 0.08637957274913788
Validation loss: 1.4724871766182683

Epoch: 547| Step: 0
Training loss: 0.05141286924481392
Validation loss: 1.4428719243695658

Epoch: 5| Step: 1
Training loss: 0.0685659795999527
Validation loss: 1.4403593399191414

Epoch: 5| Step: 2
Training loss: 0.06583867967128754
Validation loss: 1.4635249664706569

Epoch: 5| Step: 3
Training loss: 0.07403431087732315
Validation loss: 1.4618575957513624

Epoch: 5| Step: 4
Training loss: 0.21598391234874725
Validation loss: 1.4542201898431266

Epoch: 5| Step: 5
Training loss: 0.11891438812017441
Validation loss: 1.4383366864214662

Epoch: 5| Step: 6
Training loss: 0.11094927787780762
Validation loss: 1.4306251246442077

Epoch: 5| Step: 7
Training loss: 0.08899199962615967
Validation loss: 1.4308618627568728

Epoch: 5| Step: 8
Training loss: 0.16669638454914093
Validation loss: 1.4228539236130253

Epoch: 5| Step: 9
Training loss: 0.1087963804602623
Validation loss: 1.4060733356783468

Epoch: 5| Step: 10
Training loss: 0.059012554585933685
Validation loss: 1.3881914397721649

Epoch: 548| Step: 0
Training loss: 0.09290014207363129
Validation loss: 1.381948099982354

Epoch: 5| Step: 1
Training loss: 0.08884996920824051
Validation loss: 1.3828576751934585

Epoch: 5| Step: 2
Training loss: 0.2223523110151291
Validation loss: 1.3900705370851743

Epoch: 5| Step: 3
Training loss: 0.07695068418979645
Validation loss: 1.3958590992035405

Epoch: 5| Step: 4
Training loss: 0.07825921475887299
Validation loss: 1.4028208935132591

Epoch: 5| Step: 5
Training loss: 0.10366062819957733
Validation loss: 1.4155023456901632

Epoch: 5| Step: 6
Training loss: 0.07064969092607498
Validation loss: 1.4071142820901767

Epoch: 5| Step: 7
Training loss: 0.12524285912513733
Validation loss: 1.406939814167638

Epoch: 5| Step: 8
Training loss: 0.11527591943740845
Validation loss: 1.4013609565714353

Epoch: 5| Step: 9
Training loss: 0.14861750602722168
Validation loss: 1.405027348508117

Epoch: 5| Step: 10
Training loss: 0.07391151040792465
Validation loss: 1.4040814907320085

Epoch: 549| Step: 0
Training loss: 0.06920598447322845
Validation loss: 1.4288052307662142

Epoch: 5| Step: 1
Training loss: 0.09870687872171402
Validation loss: 1.4278033266785324

Epoch: 5| Step: 2
Training loss: 0.14861539006233215
Validation loss: 1.4385310629362702

Epoch: 5| Step: 3
Training loss: 0.058363862335681915
Validation loss: 1.4475132957581551

Epoch: 5| Step: 4
Training loss: 0.0617239885032177
Validation loss: 1.4493085043404692

Epoch: 5| Step: 5
Training loss: 0.11427917331457138
Validation loss: 1.4423831611551263

Epoch: 5| Step: 6
Training loss: 0.10748116672039032
Validation loss: 1.4616558705606768

Epoch: 5| Step: 7
Training loss: 0.08509156852960587
Validation loss: 1.471153058031554

Epoch: 5| Step: 8
Training loss: 0.05076780170202255
Validation loss: 1.4804434340487245

Epoch: 5| Step: 9
Training loss: 0.10238711535930634
Validation loss: 1.474084618271038

Epoch: 5| Step: 10
Training loss: 0.27790218591690063
Validation loss: 1.48603222831603

Epoch: 550| Step: 0
Training loss: 0.12990012764930725
Validation loss: 1.4861264164729784

Epoch: 5| Step: 1
Training loss: 0.09199253469705582
Validation loss: 1.4471529145394602

Epoch: 5| Step: 2
Training loss: 0.10836120694875717
Validation loss: 1.4288184745337373

Epoch: 5| Step: 3
Training loss: 0.08442926406860352
Validation loss: 1.4149923234857538

Epoch: 5| Step: 4
Training loss: 0.11784888803958893
Validation loss: 1.4259288452004875

Epoch: 5| Step: 5
Training loss: 0.09487225860357285
Validation loss: 1.408725341161092

Epoch: 5| Step: 6
Training loss: 0.0615994818508625
Validation loss: 1.4006708264350891

Epoch: 5| Step: 7
Training loss: 0.18927383422851562
Validation loss: 1.3947534509884414

Epoch: 5| Step: 8
Training loss: 0.13513103127479553
Validation loss: 1.3914482542263564

Epoch: 5| Step: 9
Training loss: 0.09958775341510773
Validation loss: 1.4115386560399046

Epoch: 5| Step: 10
Training loss: 0.14344266057014465
Validation loss: 1.4182440709042292

Epoch: 551| Step: 0
Training loss: 0.0670631006360054
Validation loss: 1.4118695348821662

Epoch: 5| Step: 1
Training loss: 0.07041633129119873
Validation loss: 1.399601521030549

Epoch: 5| Step: 2
Training loss: 0.07592085003852844
Validation loss: 1.3926580497013625

Epoch: 5| Step: 3
Training loss: 0.12694533169269562
Validation loss: 1.3780560685742287

Epoch: 5| Step: 4
Training loss: 0.07655946910381317
Validation loss: 1.3550632589606828

Epoch: 5| Step: 5
Training loss: 0.11227039247751236
Validation loss: 1.3542441732139998

Epoch: 5| Step: 6
Training loss: 0.1261705607175827
Validation loss: 1.3298900960594096

Epoch: 5| Step: 7
Training loss: 0.11000819504261017
Validation loss: 1.3333464604552074

Epoch: 5| Step: 8
Training loss: 0.10987798869609833
Validation loss: 1.3261210674880652

Epoch: 5| Step: 9
Training loss: 0.11910979449748993
Validation loss: 1.338427024502908

Epoch: 5| Step: 10
Training loss: 0.2975826561450958
Validation loss: 1.346255415229387

Epoch: 552| Step: 0
Training loss: 0.09767972677946091
Validation loss: 1.3635150681259811

Epoch: 5| Step: 1
Training loss: 0.08343847095966339
Validation loss: 1.3923663926380936

Epoch: 5| Step: 2
Training loss: 0.13360866904258728
Validation loss: 1.4214844870310959

Epoch: 5| Step: 3
Training loss: 0.10885127633810043
Validation loss: 1.4299349579759824

Epoch: 5| Step: 4
Training loss: 0.15901947021484375
Validation loss: 1.4269266705359183

Epoch: 5| Step: 5
Training loss: 0.10117832571268082
Validation loss: 1.4200472895817091

Epoch: 5| Step: 6
Training loss: 0.07902002334594727
Validation loss: 1.4394242596882645

Epoch: 5| Step: 7
Training loss: 0.09680578857660294
Validation loss: 1.4569216376991683

Epoch: 5| Step: 8
Training loss: 0.16839036345481873
Validation loss: 1.4128011439436226

Epoch: 5| Step: 9
Training loss: 0.2554599344730377
Validation loss: 1.41963013269568

Epoch: 5| Step: 10
Training loss: 0.09110481292009354
Validation loss: 1.4543570395438903

Epoch: 553| Step: 0
Training loss: 0.12954595685005188
Validation loss: 1.4440059725956251

Epoch: 5| Step: 1
Training loss: 0.082425557076931
Validation loss: 1.4291641622461297

Epoch: 5| Step: 2
Training loss: 0.1348700225353241
Validation loss: 1.4538487593332927

Epoch: 5| Step: 3
Training loss: 0.11227134615182877
Validation loss: 1.4713168618499592

Epoch: 5| Step: 4
Training loss: 0.22519183158874512
Validation loss: 1.4716102525752077

Epoch: 5| Step: 5
Training loss: 0.19397321343421936
Validation loss: 1.4404141018467564

Epoch: 5| Step: 6
Training loss: 0.06440390646457672
Validation loss: 1.4302605826367614

Epoch: 5| Step: 7
Training loss: 0.07250005006790161
Validation loss: 1.401861467669087

Epoch: 5| Step: 8
Training loss: 0.11849851906299591
Validation loss: 1.377360934852272

Epoch: 5| Step: 9
Training loss: 0.1756071299314499
Validation loss: 1.3927157361020324

Epoch: 5| Step: 10
Training loss: 0.1808377206325531
Validation loss: 1.378029102920204

Epoch: 554| Step: 0
Training loss: 0.11216402053833008
Validation loss: 1.4160345497951712

Epoch: 5| Step: 1
Training loss: 0.09387154877185822
Validation loss: 1.4419912208792984

Epoch: 5| Step: 2
Training loss: 0.21806970238685608
Validation loss: 1.4479035113447456

Epoch: 5| Step: 3
Training loss: 0.09094823896884918
Validation loss: 1.5020595083954513

Epoch: 5| Step: 4
Training loss: 0.15291720628738403
Validation loss: 1.5327830974773695

Epoch: 5| Step: 5
Training loss: 0.13528355956077576
Validation loss: 1.5267146877063218

Epoch: 5| Step: 6
Training loss: 0.1730506867170334
Validation loss: 1.5344789297349992

Epoch: 5| Step: 7
Training loss: 0.1448642462491989
Validation loss: 1.5076376468904558

Epoch: 5| Step: 8
Training loss: 0.11922071129083633
Validation loss: 1.459212399298145

Epoch: 5| Step: 9
Training loss: 0.11767476797103882
Validation loss: 1.4292976651140439

Epoch: 5| Step: 10
Training loss: 0.10016382485628128
Validation loss: 1.3600679648819791

Epoch: 555| Step: 0
Training loss: 0.14338676631450653
Validation loss: 1.3846125307903494

Epoch: 5| Step: 1
Training loss: 0.1333300769329071
Validation loss: 1.3334615448469758

Epoch: 5| Step: 2
Training loss: 0.23978498578071594
Validation loss: 1.3458318851327384

Epoch: 5| Step: 3
Training loss: 0.17446500062942505
Validation loss: 1.3026143568818287

Epoch: 5| Step: 4
Training loss: 0.13320979475975037
Validation loss: 1.3276951569382862

Epoch: 5| Step: 5
Training loss: 0.10626450926065445
Validation loss: 1.361083976684078

Epoch: 5| Step: 6
Training loss: 0.11629915237426758
Validation loss: 1.4128806424397293

Epoch: 5| Step: 7
Training loss: 0.14192989468574524
Validation loss: 1.4428760979765205

Epoch: 5| Step: 8
Training loss: 0.11020225286483765
Validation loss: 1.4548748321430658

Epoch: 5| Step: 9
Training loss: 0.14560647308826447
Validation loss: 1.4384766804274691

Epoch: 5| Step: 10
Training loss: 0.2190198302268982
Validation loss: 1.440843791090032

Epoch: 556| Step: 0
Training loss: 0.0981503576040268
Validation loss: 1.4089140853574198

Epoch: 5| Step: 1
Training loss: 0.0770677924156189
Validation loss: 1.393012273696161

Epoch: 5| Step: 2
Training loss: 0.14445778727531433
Validation loss: 1.3831720070172382

Epoch: 5| Step: 3
Training loss: 0.08601363003253937
Validation loss: 1.4055072876714891

Epoch: 5| Step: 4
Training loss: 0.07212749868631363
Validation loss: 1.3890218273285897

Epoch: 5| Step: 5
Training loss: 0.12353463470935822
Validation loss: 1.3866901077249998

Epoch: 5| Step: 6
Training loss: 0.11291375011205673
Validation loss: 1.391595717399351

Epoch: 5| Step: 7
Training loss: 0.08087996393442154
Validation loss: 1.410707054599639

Epoch: 5| Step: 8
Training loss: 0.18601122498512268
Validation loss: 1.4309689139807096

Epoch: 5| Step: 9
Training loss: 0.0853690579533577
Validation loss: 1.4198831781264274

Epoch: 5| Step: 10
Training loss: 0.08106642961502075
Validation loss: 1.4436465194148402

Epoch: 557| Step: 0
Training loss: 0.058229170739650726
Validation loss: 1.432033101717631

Epoch: 5| Step: 1
Training loss: 0.17827463150024414
Validation loss: 1.3944218203585634

Epoch: 5| Step: 2
Training loss: 0.07140109688043594
Validation loss: 1.3972479797178698

Epoch: 5| Step: 3
Training loss: 0.11483877897262573
Validation loss: 1.4279183380065426

Epoch: 5| Step: 4
Training loss: 0.0757884681224823
Validation loss: 1.412992917081361

Epoch: 5| Step: 5
Training loss: 0.09157553315162659
Validation loss: 1.4445956996692124

Epoch: 5| Step: 6
Training loss: 0.10099524259567261
Validation loss: 1.460723933353219

Epoch: 5| Step: 7
Training loss: 0.08029942214488983
Validation loss: 1.4081974926815237

Epoch: 5| Step: 8
Training loss: 0.11219372600317001
Validation loss: 1.4781664648363668

Epoch: 5| Step: 9
Training loss: 0.0907498449087143
Validation loss: 1.4480622224910285

Epoch: 5| Step: 10
Training loss: 0.12221434712409973
Validation loss: 1.455066938554087

Epoch: 558| Step: 0
Training loss: 0.06332005560398102
Validation loss: 1.46459678552484

Epoch: 5| Step: 1
Training loss: 0.10775693506002426
Validation loss: 1.4623536640597927

Epoch: 5| Step: 2
Training loss: 0.0996236577630043
Validation loss: 1.4573599048840102

Epoch: 5| Step: 3
Training loss: 0.10034199804067612
Validation loss: 1.4499590960882043

Epoch: 5| Step: 4
Training loss: 0.08822708576917648
Validation loss: 1.4583665017158753

Epoch: 5| Step: 5
Training loss: 0.09743786603212357
Validation loss: 1.4472310107241395

Epoch: 5| Step: 6
Training loss: 0.07821532338857651
Validation loss: 1.4165345879011257

Epoch: 5| Step: 7
Training loss: 0.18877340853214264
Validation loss: 1.4099358999600975

Epoch: 5| Step: 8
Training loss: 0.1032973974943161
Validation loss: 1.405201982426387

Epoch: 5| Step: 9
Training loss: 0.06376007944345474
Validation loss: 1.4056763982260099

Epoch: 5| Step: 10
Training loss: 0.09002925455570221
Validation loss: 1.4007618683640675

Epoch: 559| Step: 0
Training loss: 0.08575326204299927
Validation loss: 1.4168576463576286

Epoch: 5| Step: 1
Training loss: 0.16441312432289124
Validation loss: 1.4075472239525086

Epoch: 5| Step: 2
Training loss: 0.11810717731714249
Validation loss: 1.4114492144635928

Epoch: 5| Step: 3
Training loss: 0.09992897510528564
Validation loss: 1.4261381856856807

Epoch: 5| Step: 4
Training loss: 0.07998156547546387
Validation loss: 1.4093593807630642

Epoch: 5| Step: 5
Training loss: 0.05059739202260971
Validation loss: 1.4167790515448457

Epoch: 5| Step: 6
Training loss: 0.08435020595788956
Validation loss: 1.435143506655129

Epoch: 5| Step: 7
Training loss: 0.08785201609134674
Validation loss: 1.4335065669910882

Epoch: 5| Step: 8
Training loss: 0.08967706561088562
Validation loss: 1.4415139613613006

Epoch: 5| Step: 9
Training loss: 0.10157996416091919
Validation loss: 1.451093566033148

Epoch: 5| Step: 10
Training loss: 0.06505852937698364
Validation loss: 1.457697287682564

Epoch: 560| Step: 0
Training loss: 0.17095060646533966
Validation loss: 1.464012328014579

Epoch: 5| Step: 1
Training loss: 0.06202635169029236
Validation loss: 1.4389480442129157

Epoch: 5| Step: 2
Training loss: 0.09935447573661804
Validation loss: 1.4312616753321823

Epoch: 5| Step: 3
Training loss: 0.10949929058551788
Validation loss: 1.4341531078661642

Epoch: 5| Step: 4
Training loss: 0.06066853925585747
Validation loss: 1.419989546140035

Epoch: 5| Step: 5
Training loss: 0.2029912918806076
Validation loss: 1.4002399201034217

Epoch: 5| Step: 6
Training loss: 0.07912951707839966
Validation loss: 1.4253101887241486

Epoch: 5| Step: 7
Training loss: 0.08191274106502533
Validation loss: 1.4312147491721696

Epoch: 5| Step: 8
Training loss: 0.10258910804986954
Validation loss: 1.430635534307008

Epoch: 5| Step: 9
Training loss: 0.11530226469039917
Validation loss: 1.4200667117231636

Epoch: 5| Step: 10
Training loss: 0.06295549124479294
Validation loss: 1.4305096300699378

Epoch: 561| Step: 0
Training loss: 0.07192990183830261
Validation loss: 1.4351500234296244

Epoch: 5| Step: 1
Training loss: 0.09239978343248367
Validation loss: 1.4765675721629974

Epoch: 5| Step: 2
Training loss: 0.07334686815738678
Validation loss: 1.4745756003164476

Epoch: 5| Step: 3
Training loss: 0.1452888399362564
Validation loss: 1.4627360816924804

Epoch: 5| Step: 4
Training loss: 0.19193097949028015
Validation loss: 1.4621030566512898

Epoch: 5| Step: 5
Training loss: 0.09231796115636826
Validation loss: 1.4713971717383272

Epoch: 5| Step: 6
Training loss: 0.10503803193569183
Validation loss: 1.4561273295392272

Epoch: 5| Step: 7
Training loss: 0.08995995670557022
Validation loss: 1.4233315529361847

Epoch: 5| Step: 8
Training loss: 0.09614437073469162
Validation loss: 1.4004731062919862

Epoch: 5| Step: 9
Training loss: 0.11103677749633789
Validation loss: 1.4216015736262004

Epoch: 5| Step: 10
Training loss: 0.08157221227884293
Validation loss: 1.408252162958986

Epoch: 562| Step: 0
Training loss: 0.1038653701543808
Validation loss: 1.370401931065385

Epoch: 5| Step: 1
Training loss: 0.10344517230987549
Validation loss: 1.3895732369474185

Epoch: 5| Step: 2
Training loss: 0.10961447656154633
Validation loss: 1.3793050858282274

Epoch: 5| Step: 3
Training loss: 0.08732753247022629
Validation loss: 1.3944213069895262

Epoch: 5| Step: 4
Training loss: 0.06976690888404846
Validation loss: 1.4379828335136495

Epoch: 5| Step: 5
Training loss: 0.11158400774002075
Validation loss: 1.465517145331188

Epoch: 5| Step: 6
Training loss: 0.12653848528862
Validation loss: 1.4991670654666038

Epoch: 5| Step: 7
Training loss: 0.16385960578918457
Validation loss: 1.455749439295902

Epoch: 5| Step: 8
Training loss: 0.06328756362199783
Validation loss: 1.4186996208724154

Epoch: 5| Step: 9
Training loss: 0.0773300975561142
Validation loss: 1.4207638156029485

Epoch: 5| Step: 10
Training loss: 0.25358277559280396
Validation loss: 1.3749808008952806

Epoch: 563| Step: 0
Training loss: 0.12366024404764175
Validation loss: 1.356326445456474

Epoch: 5| Step: 1
Training loss: 0.1455640196800232
Validation loss: 1.3238887991956485

Epoch: 5| Step: 2
Training loss: 0.07938162982463837
Validation loss: 1.3513065730371783

Epoch: 5| Step: 3
Training loss: 0.10176566988229752
Validation loss: 1.3409195830745082

Epoch: 5| Step: 4
Training loss: 0.0892539694905281
Validation loss: 1.3604683799128379

Epoch: 5| Step: 5
Training loss: 0.10694500058889389
Validation loss: 1.3749005704797723

Epoch: 5| Step: 6
Training loss: 0.07370907813310623
Validation loss: 1.3984974930363316

Epoch: 5| Step: 7
Training loss: 0.08137725293636322
Validation loss: 1.4202779493024271

Epoch: 5| Step: 8
Training loss: 0.18119826912879944
Validation loss: 1.468713443766358

Epoch: 5| Step: 9
Training loss: 0.1915668249130249
Validation loss: 1.449663192995133

Epoch: 5| Step: 10
Training loss: 0.12508341670036316
Validation loss: 1.4506931279295234

Epoch: 564| Step: 0
Training loss: 0.1732720136642456
Validation loss: 1.4712848253147577

Epoch: 5| Step: 1
Training loss: 0.07073228061199188
Validation loss: 1.4647481056951708

Epoch: 5| Step: 2
Training loss: 0.10992719233036041
Validation loss: 1.469068778458462

Epoch: 5| Step: 3
Training loss: 0.09058727324008942
Validation loss: 1.4373641475554435

Epoch: 5| Step: 4
Training loss: 0.08447655290365219
Validation loss: 1.4561271500843826

Epoch: 5| Step: 5
Training loss: 0.16171857714653015
Validation loss: 1.4437425694158

Epoch: 5| Step: 6
Training loss: 0.14615090191364288
Validation loss: 1.4509841319053405

Epoch: 5| Step: 7
Training loss: 0.10803297907114029
Validation loss: 1.4368914737496326

Epoch: 5| Step: 8
Training loss: 0.09333876520395279
Validation loss: 1.4403693752904092

Epoch: 5| Step: 9
Training loss: 0.07479214668273926
Validation loss: 1.4554788579222977

Epoch: 5| Step: 10
Training loss: 0.12418979406356812
Validation loss: 1.4623696855319444

Epoch: 565| Step: 0
Training loss: 0.12930981814861298
Validation loss: 1.4859455990534958

Epoch: 5| Step: 1
Training loss: 0.20387741923332214
Validation loss: 1.44380997842358

Epoch: 5| Step: 2
Training loss: 0.09302425384521484
Validation loss: 1.4390128915027907

Epoch: 5| Step: 3
Training loss: 0.11337210983037949
Validation loss: 1.4408041687421902

Epoch: 5| Step: 4
Training loss: 0.0745670348405838
Validation loss: 1.4472499726921

Epoch: 5| Step: 5
Training loss: 0.06165466457605362
Validation loss: 1.436797248419895

Epoch: 5| Step: 6
Training loss: 0.10183592140674591
Validation loss: 1.4347968332229122

Epoch: 5| Step: 7
Training loss: 0.0782502070069313
Validation loss: 1.420271195391173

Epoch: 5| Step: 8
Training loss: 0.1739477813243866
Validation loss: 1.443659290190666

Epoch: 5| Step: 9
Training loss: 0.11669202148914337
Validation loss: 1.4253799684586064

Epoch: 5| Step: 10
Training loss: 0.08834010362625122
Validation loss: 1.4245618927863337

Epoch: 566| Step: 0
Training loss: 0.10692385584115982
Validation loss: 1.4245494514383295

Epoch: 5| Step: 1
Training loss: 0.07100266218185425
Validation loss: 1.4152447292881627

Epoch: 5| Step: 2
Training loss: 0.07686149328947067
Validation loss: 1.418420809571461

Epoch: 5| Step: 3
Training loss: 0.09121094644069672
Validation loss: 1.4370907250271048

Epoch: 5| Step: 4
Training loss: 0.10383601486682892
Validation loss: 1.4407451793711672

Epoch: 5| Step: 5
Training loss: 0.24041330814361572
Validation loss: 1.4183498031349593

Epoch: 5| Step: 6
Training loss: 0.10126324743032455
Validation loss: 1.4223260251424645

Epoch: 5| Step: 7
Training loss: 0.1191108450293541
Validation loss: 1.4340992845514768

Epoch: 5| Step: 8
Training loss: 0.10276565700769424
Validation loss: 1.4392115300701511

Epoch: 5| Step: 9
Training loss: 0.09633370488882065
Validation loss: 1.446207570773299

Epoch: 5| Step: 10
Training loss: 0.10013200342655182
Validation loss: 1.4028883134165118

Epoch: 567| Step: 0
Training loss: 0.10101465880870819
Validation loss: 1.4208093471424554

Epoch: 5| Step: 1
Training loss: 0.11870521306991577
Validation loss: 1.4339363831345753

Epoch: 5| Step: 2
Training loss: 0.09578908979892731
Validation loss: 1.4447479222410469

Epoch: 5| Step: 3
Training loss: 0.09203685820102692
Validation loss: 1.4231997914211725

Epoch: 5| Step: 4
Training loss: 0.2208433449268341
Validation loss: 1.4200878284310783

Epoch: 5| Step: 5
Training loss: 0.09793192148208618
Validation loss: 1.4280584871128041

Epoch: 5| Step: 6
Training loss: 0.13411085307598114
Validation loss: 1.420736881994432

Epoch: 5| Step: 7
Training loss: 0.09031929075717926
Validation loss: 1.4353967661498694

Epoch: 5| Step: 8
Training loss: 0.06562447547912598
Validation loss: 1.4363031451420119

Epoch: 5| Step: 9
Training loss: 0.11753280460834503
Validation loss: 1.4498897547362952

Epoch: 5| Step: 10
Training loss: 0.11898010224103928
Validation loss: 1.4216698856763943

Epoch: 568| Step: 0
Training loss: 0.11434558779001236
Validation loss: 1.4330530269171602

Epoch: 5| Step: 1
Training loss: 0.0786440372467041
Validation loss: 1.4137663469519666

Epoch: 5| Step: 2
Training loss: 0.12759926915168762
Validation loss: 1.4041529111964728

Epoch: 5| Step: 3
Training loss: 0.1312875598669052
Validation loss: 1.406995258023662

Epoch: 5| Step: 4
Training loss: 0.07602579891681671
Validation loss: 1.4195501189078055

Epoch: 5| Step: 5
Training loss: 0.10408568382263184
Validation loss: 1.4114374806804042

Epoch: 5| Step: 6
Training loss: 0.09526033699512482
Validation loss: 1.4097539032659223

Epoch: 5| Step: 7
Training loss: 0.1364176720380783
Validation loss: 1.412916156553453

Epoch: 5| Step: 8
Training loss: 0.10836746543645859
Validation loss: 1.4155975580215454

Epoch: 5| Step: 9
Training loss: 0.08516629040241241
Validation loss: 1.428121744945485

Epoch: 5| Step: 10
Training loss: 0.1772720068693161
Validation loss: 1.440410940877853

Epoch: 569| Step: 0
Training loss: 0.13866844773292542
Validation loss: 1.445606679044744

Epoch: 5| Step: 1
Training loss: 0.07533907890319824
Validation loss: 1.4300432615382697

Epoch: 5| Step: 2
Training loss: 0.07070831954479218
Validation loss: 1.432110091691376

Epoch: 5| Step: 3
Training loss: 0.11991788446903229
Validation loss: 1.43281328293585

Epoch: 5| Step: 4
Training loss: 0.10522069036960602
Validation loss: 1.4353793724890678

Epoch: 5| Step: 5
Training loss: 0.12463764101266861
Validation loss: 1.4193152560982654

Epoch: 5| Step: 6
Training loss: 0.10241180658340454
Validation loss: 1.4183578645029375

Epoch: 5| Step: 7
Training loss: 0.07713700830936432
Validation loss: 1.4083924114063222

Epoch: 5| Step: 8
Training loss: 0.17792396247386932
Validation loss: 1.4057108484288698

Epoch: 5| Step: 9
Training loss: 0.06007300689816475
Validation loss: 1.399393177801563

Epoch: 5| Step: 10
Training loss: 0.11285368353128433
Validation loss: 1.3862214908804944

Epoch: 570| Step: 0
Training loss: 0.07831330597400665
Validation loss: 1.3945446373313986

Epoch: 5| Step: 1
Training loss: 0.1103827953338623
Validation loss: 1.401101650089346

Epoch: 5| Step: 2
Training loss: 0.1072927713394165
Validation loss: 1.3942318795829691

Epoch: 5| Step: 3
Training loss: 0.08723358809947968
Validation loss: 1.3454447536058323

Epoch: 5| Step: 4
Training loss: 0.07766105979681015
Validation loss: 1.3780274262992285

Epoch: 5| Step: 5
Training loss: 0.09019928425550461
Validation loss: 1.387860736539287

Epoch: 5| Step: 6
Training loss: 0.13039933145046234
Validation loss: 1.3786796183996304

Epoch: 5| Step: 7
Training loss: 0.124653659760952
Validation loss: 1.3521991839972876

Epoch: 5| Step: 8
Training loss: 0.07087498903274536
Validation loss: 1.3896129797863703

Epoch: 5| Step: 9
Training loss: 0.17575673758983612
Validation loss: 1.4233325476287513

Epoch: 5| Step: 10
Training loss: 0.03544727712869644
Validation loss: 1.4126076877758067

Epoch: 571| Step: 0
Training loss: 0.11136353015899658
Validation loss: 1.431780997142997

Epoch: 5| Step: 1
Training loss: 0.07427706569433212
Validation loss: 1.4451934060742777

Epoch: 5| Step: 2
Training loss: 0.1212058812379837
Validation loss: 1.4425870410857662

Epoch: 5| Step: 3
Training loss: 0.09473022073507309
Validation loss: 1.4448945253126082

Epoch: 5| Step: 4
Training loss: 0.17015187442302704
Validation loss: 1.426702530153336

Epoch: 5| Step: 5
Training loss: 0.08389433473348618
Validation loss: 1.4280081243925198

Epoch: 5| Step: 6
Training loss: 0.07422574609518051
Validation loss: 1.4386253613297657

Epoch: 5| Step: 7
Training loss: 0.09250031411647797
Validation loss: 1.4028754644496466

Epoch: 5| Step: 8
Training loss: 0.05976773053407669
Validation loss: 1.4023178726114252

Epoch: 5| Step: 9
Training loss: 0.10842232406139374
Validation loss: 1.4002054173459288

Epoch: 5| Step: 10
Training loss: 0.11492285877466202
Validation loss: 1.4216950798547396

Epoch: 572| Step: 0
Training loss: 0.06703852117061615
Validation loss: 1.3974866174882459

Epoch: 5| Step: 1
Training loss: 0.0883672833442688
Validation loss: 1.3896115755522123

Epoch: 5| Step: 2
Training loss: 0.11354639381170273
Validation loss: 1.4134757570041123

Epoch: 5| Step: 3
Training loss: 0.06886503845453262
Validation loss: 1.4420880938089022

Epoch: 5| Step: 4
Training loss: 0.09441103041172028
Validation loss: 1.4358761643850675

Epoch: 5| Step: 5
Training loss: 0.2504252791404724
Validation loss: 1.4608531754503968

Epoch: 5| Step: 6
Training loss: 0.06378617882728577
Validation loss: 1.444936151145607

Epoch: 5| Step: 7
Training loss: 0.07009183615446091
Validation loss: 1.4422802361108924

Epoch: 5| Step: 8
Training loss: 0.13697853684425354
Validation loss: 1.4408275709357312

Epoch: 5| Step: 9
Training loss: 0.06563170254230499
Validation loss: 1.419806254807339

Epoch: 5| Step: 10
Training loss: 0.08695543557405472
Validation loss: 1.4188201260823075

Epoch: 573| Step: 0
Training loss: 0.11520595848560333
Validation loss: 1.3905838868951286

Epoch: 5| Step: 1
Training loss: 0.06178943067789078
Validation loss: 1.429094692712189

Epoch: 5| Step: 2
Training loss: 0.08853229135274887
Validation loss: 1.408504811666345

Epoch: 5| Step: 3
Training loss: 0.10295011103153229
Validation loss: 1.4098842964377454

Epoch: 5| Step: 4
Training loss: 0.10310427844524384
Validation loss: 1.4117665470287364

Epoch: 5| Step: 5
Training loss: 0.12024782598018646
Validation loss: 1.421672054516372

Epoch: 5| Step: 6
Training loss: 0.07495133578777313
Validation loss: 1.4392973453767839

Epoch: 5| Step: 7
Training loss: 0.08129610121250153
Validation loss: 1.4691554705301921

Epoch: 5| Step: 8
Training loss: 0.1121540516614914
Validation loss: 1.474361736287353

Epoch: 5| Step: 9
Training loss: 0.10701346397399902
Validation loss: 1.4706280128930205

Epoch: 5| Step: 10
Training loss: 0.1616211086511612
Validation loss: 1.4411726843926214

Epoch: 574| Step: 0
Training loss: 0.057399362325668335
Validation loss: 1.4397152803277458

Epoch: 5| Step: 1
Training loss: 0.06562067568302155
Validation loss: 1.410387719831159

Epoch: 5| Step: 2
Training loss: 0.09614831209182739
Validation loss: 1.4086625294018817

Epoch: 5| Step: 3
Training loss: 0.1401759833097458
Validation loss: 1.401071826616923

Epoch: 5| Step: 4
Training loss: 0.08112481236457825
Validation loss: 1.3581878331399733

Epoch: 5| Step: 5
Training loss: 0.18219728767871857
Validation loss: 1.3819187456561672

Epoch: 5| Step: 6
Training loss: 0.12325539439916611
Validation loss: 1.3751984245033675

Epoch: 5| Step: 7
Training loss: 0.05869659036397934
Validation loss: 1.396257677385884

Epoch: 5| Step: 8
Training loss: 0.07119511067867279
Validation loss: 1.3957969142544655

Epoch: 5| Step: 9
Training loss: 0.045875184237957
Validation loss: 1.4039242600881925

Epoch: 5| Step: 10
Training loss: 0.07532861083745956
Validation loss: 1.4007702873599144

Epoch: 575| Step: 0
Training loss: 0.05615048483014107
Validation loss: 1.4231465619097474

Epoch: 5| Step: 1
Training loss: 0.06293817609548569
Validation loss: 1.4139694603540565

Epoch: 5| Step: 2
Training loss: 0.07626917958259583
Validation loss: 1.414293114857007

Epoch: 5| Step: 3
Training loss: 0.1870535910129547
Validation loss: 1.3817195956425001

Epoch: 5| Step: 4
Training loss: 0.060288894921541214
Validation loss: 1.4093259854983258

Epoch: 5| Step: 5
Training loss: 0.1086183562874794
Validation loss: 1.4178973346628168

Epoch: 5| Step: 6
Training loss: 0.1405680775642395
Validation loss: 1.4019263790499779

Epoch: 5| Step: 7
Training loss: 0.07098441570997238
Validation loss: 1.4114724115658832

Epoch: 5| Step: 8
Training loss: 0.08922196924686432
Validation loss: 1.4096941640300136

Epoch: 5| Step: 9
Training loss: 0.08562254160642624
Validation loss: 1.3934890852179578

Epoch: 5| Step: 10
Training loss: 0.07552894204854965
Validation loss: 1.4360666967207385

Epoch: 576| Step: 0
Training loss: 0.06278947740793228
Validation loss: 1.4106866851929696

Epoch: 5| Step: 1
Training loss: 0.05876647308468819
Validation loss: 1.408417033892806

Epoch: 5| Step: 2
Training loss: 0.0879683718085289
Validation loss: 1.4141003829176708

Epoch: 5| Step: 3
Training loss: 0.06458909809589386
Validation loss: 1.4268965362220682

Epoch: 5| Step: 4
Training loss: 0.13542214035987854
Validation loss: 1.4271327154610747

Epoch: 5| Step: 5
Training loss: 0.06741205602884293
Validation loss: 1.4106763127029582

Epoch: 5| Step: 6
Training loss: 0.06830935180187225
Validation loss: 1.423974447352912

Epoch: 5| Step: 7
Training loss: 0.10218651592731476
Validation loss: 1.4291908382087626

Epoch: 5| Step: 8
Training loss: 0.21673905849456787
Validation loss: 1.4024870946843138

Epoch: 5| Step: 9
Training loss: 0.060682378709316254
Validation loss: 1.3933499487497474

Epoch: 5| Step: 10
Training loss: 0.07325560599565506
Validation loss: 1.3660935099406908

Epoch: 577| Step: 0
Training loss: 0.09972303360700607
Validation loss: 1.3961611806705434

Epoch: 5| Step: 1
Training loss: 0.07989166676998138
Validation loss: 1.3418106981503066

Epoch: 5| Step: 2
Training loss: 0.141170933842659
Validation loss: 1.3761294157274309

Epoch: 5| Step: 3
Training loss: 0.08596471697092056
Validation loss: 1.3860193407663735

Epoch: 5| Step: 4
Training loss: 0.1144721508026123
Validation loss: 1.385224897374389

Epoch: 5| Step: 5
Training loss: 0.09337422251701355
Validation loss: 1.4109244026163572

Epoch: 5| Step: 6
Training loss: 0.1658121645450592
Validation loss: 1.4338810200332313

Epoch: 5| Step: 7
Training loss: 0.07270733267068863
Validation loss: 1.445152169914656

Epoch: 5| Step: 8
Training loss: 0.12708982825279236
Validation loss: 1.4609532824126623

Epoch: 5| Step: 9
Training loss: 0.11944861710071564
Validation loss: 1.4888098791081419

Epoch: 5| Step: 10
Training loss: 0.09896836429834366
Validation loss: 1.4923726807358444

Epoch: 578| Step: 0
Training loss: 0.11940513551235199
Validation loss: 1.4925320186922628

Epoch: 5| Step: 1
Training loss: 0.04553614929318428
Validation loss: 1.4578114010954415

Epoch: 5| Step: 2
Training loss: 0.18405596911907196
Validation loss: 1.4683789271180347

Epoch: 5| Step: 3
Training loss: 0.06983993947505951
Validation loss: 1.4159202460319764

Epoch: 5| Step: 4
Training loss: 0.06611182540655136
Validation loss: 1.4149368040023311

Epoch: 5| Step: 5
Training loss: 0.08412853628396988
Validation loss: 1.3929904263506654

Epoch: 5| Step: 6
Training loss: 0.06546971946954727
Validation loss: 1.405875229066418

Epoch: 5| Step: 7
Training loss: 0.11120595782995224
Validation loss: 1.4107810681866062

Epoch: 5| Step: 8
Training loss: 0.11553917825222015
Validation loss: 1.3919750336677796

Epoch: 5| Step: 9
Training loss: 0.14005212485790253
Validation loss: 1.4012579789725683

Epoch: 5| Step: 10
Training loss: 0.09384488314390182
Validation loss: 1.4107475050034062

Epoch: 579| Step: 0
Training loss: 0.17006058990955353
Validation loss: 1.4096735485138432

Epoch: 5| Step: 1
Training loss: 0.07690595090389252
Validation loss: 1.4349175871059459

Epoch: 5| Step: 2
Training loss: 0.08351859450340271
Validation loss: 1.4488579380896784

Epoch: 5| Step: 3
Training loss: 0.05414944887161255
Validation loss: 1.4523933318353468

Epoch: 5| Step: 4
Training loss: 0.10364378988742828
Validation loss: 1.4505812852613387

Epoch: 5| Step: 5
Training loss: 0.1147712841629982
Validation loss: 1.4396315069608792

Epoch: 5| Step: 6
Training loss: 0.17233358323574066
Validation loss: 1.3975098645815285

Epoch: 5| Step: 7
Training loss: 0.06469415873289108
Validation loss: 1.3824676159889466

Epoch: 5| Step: 8
Training loss: 0.06938135623931885
Validation loss: 1.3705730521550743

Epoch: 5| Step: 9
Training loss: 0.16989628970623016
Validation loss: 1.3853100781799645

Epoch: 5| Step: 10
Training loss: 0.07757312804460526
Validation loss: 1.380646167262908

Epoch: 580| Step: 0
Training loss: 0.15894222259521484
Validation loss: 1.3471288360575193

Epoch: 5| Step: 1
Training loss: 0.24599213898181915
Validation loss: 1.364750990303614

Epoch: 5| Step: 2
Training loss: 0.1168331503868103
Validation loss: 1.3736311120371665

Epoch: 5| Step: 3
Training loss: 0.05806279927492142
Validation loss: 1.377685518674953

Epoch: 5| Step: 4
Training loss: 0.10337680578231812
Validation loss: 1.3941221250000821

Epoch: 5| Step: 5
Training loss: 0.10021903365850449
Validation loss: 1.4142336678761307

Epoch: 5| Step: 6
Training loss: 0.08820970356464386
Validation loss: 1.4140090455291092

Epoch: 5| Step: 7
Training loss: 0.08653424680233002
Validation loss: 1.4246477221929899

Epoch: 5| Step: 8
Training loss: 0.09333159774541855
Validation loss: 1.4640463808531403

Epoch: 5| Step: 9
Training loss: 0.0532628670334816
Validation loss: 1.4791122585214593

Epoch: 5| Step: 10
Training loss: 0.08815234154462814
Validation loss: 1.485137391474939

Epoch: 581| Step: 0
Training loss: 0.14353236556053162
Validation loss: 1.4859689922742947

Epoch: 5| Step: 1
Training loss: 0.12054749578237534
Validation loss: 1.4649796537173692

Epoch: 5| Step: 2
Training loss: 0.08775545656681061
Validation loss: 1.4219999633809572

Epoch: 5| Step: 3
Training loss: 0.12989363074302673
Validation loss: 1.4502406363846154

Epoch: 5| Step: 4
Training loss: 0.10760758072137833
Validation loss: 1.4539762299547914

Epoch: 5| Step: 5
Training loss: 0.07841366529464722
Validation loss: 1.4568559879897742

Epoch: 5| Step: 6
Training loss: 0.15345317125320435
Validation loss: 1.4786797851644538

Epoch: 5| Step: 7
Training loss: 0.0948401540517807
Validation loss: 1.4092228310082549

Epoch: 5| Step: 8
Training loss: 0.07375465333461761
Validation loss: 1.426957517541865

Epoch: 5| Step: 9
Training loss: 0.060548216104507446
Validation loss: 1.4032988817461076

Epoch: 5| Step: 10
Training loss: 0.1313832402229309
Validation loss: 1.4023490682724984

Epoch: 582| Step: 0
Training loss: 0.06697959452867508
Validation loss: 1.3804623990930536

Epoch: 5| Step: 1
Training loss: 0.07994172722101212
Validation loss: 1.404353146271039

Epoch: 5| Step: 2
Training loss: 0.09727643430233002
Validation loss: 1.3773705574773973

Epoch: 5| Step: 3
Training loss: 0.10700477659702301
Validation loss: 1.3919812908736608

Epoch: 5| Step: 4
Training loss: 0.08617149293422699
Validation loss: 1.3992590494053339

Epoch: 5| Step: 5
Training loss: 0.11226256191730499
Validation loss: 1.4019803821399648

Epoch: 5| Step: 6
Training loss: 0.10567037016153336
Validation loss: 1.410224514622842

Epoch: 5| Step: 7
Training loss: 0.0996263325214386
Validation loss: 1.4225306690380137

Epoch: 5| Step: 8
Training loss: 0.19546213746070862
Validation loss: 1.423472003270221

Epoch: 5| Step: 9
Training loss: 0.08505024015903473
Validation loss: 1.3996076212134412

Epoch: 5| Step: 10
Training loss: 0.05835694447159767
Validation loss: 1.423820085422967

Epoch: 583| Step: 0
Training loss: 0.058290787041187286
Validation loss: 1.404587362402229

Epoch: 5| Step: 1
Training loss: 0.0983763039112091
Validation loss: 1.416566320644912

Epoch: 5| Step: 2
Training loss: 0.06786620616912842
Validation loss: 1.4156059244627595

Epoch: 5| Step: 3
Training loss: 0.11560463905334473
Validation loss: 1.3995392059767118

Epoch: 5| Step: 4
Training loss: 0.08564378321170807
Validation loss: 1.4089530488496185

Epoch: 5| Step: 5
Training loss: 0.0733376294374466
Validation loss: 1.3741276559009348

Epoch: 5| Step: 6
Training loss: 0.13427665829658508
Validation loss: 1.37869292946272

Epoch: 5| Step: 7
Training loss: 0.12959229946136475
Validation loss: 1.3662754771529988

Epoch: 5| Step: 8
Training loss: 0.1817469596862793
Validation loss: 1.349235979459619

Epoch: 5| Step: 9
Training loss: 0.08263911306858063
Validation loss: 1.367908239364624

Epoch: 5| Step: 10
Training loss: 0.08631681650876999
Validation loss: 1.3937375160955614

Epoch: 584| Step: 0
Training loss: 0.12240016460418701
Validation loss: 1.3795742834767988

Epoch: 5| Step: 1
Training loss: 0.07705342024564743
Validation loss: 1.4017652580814977

Epoch: 5| Step: 2
Training loss: 0.11434938758611679
Validation loss: 1.3714400299133793

Epoch: 5| Step: 3
Training loss: 0.19747018814086914
Validation loss: 1.404172743520429

Epoch: 5| Step: 4
Training loss: 0.08215054124593735
Validation loss: 1.3790606234663276

Epoch: 5| Step: 5
Training loss: 0.08624132722616196
Validation loss: 1.369698728284528

Epoch: 5| Step: 6
Training loss: 0.046025168150663376
Validation loss: 1.3925905714752853

Epoch: 5| Step: 7
Training loss: 0.08958504348993301
Validation loss: 1.4151941448129632

Epoch: 5| Step: 8
Training loss: 0.08650841563940048
Validation loss: 1.4228778551983576

Epoch: 5| Step: 9
Training loss: 0.12137453258037567
Validation loss: 1.4137840104359451

Epoch: 5| Step: 10
Training loss: 0.08111163228750229
Validation loss: 1.4011704114175612

Epoch: 585| Step: 0
Training loss: 0.06648999452590942
Validation loss: 1.413442434162222

Epoch: 5| Step: 1
Training loss: 0.08206391334533691
Validation loss: 1.4252051653400544

Epoch: 5| Step: 2
Training loss: 0.10193528980016708
Validation loss: 1.4165923108336747

Epoch: 5| Step: 3
Training loss: 0.09411512315273285
Validation loss: 1.422379474486074

Epoch: 5| Step: 4
Training loss: 0.13207314908504486
Validation loss: 1.4256854057312012

Epoch: 5| Step: 5
Training loss: 0.15822191536426544
Validation loss: 1.4062279501268942

Epoch: 5| Step: 6
Training loss: 0.11331341415643692
Validation loss: 1.3944285479925012

Epoch: 5| Step: 7
Training loss: 0.09117613732814789
Validation loss: 1.4119507625538816

Epoch: 5| Step: 8
Training loss: 0.1194455623626709
Validation loss: 1.3974159597068705

Epoch: 5| Step: 9
Training loss: 0.09881206601858139
Validation loss: 1.398567263798047

Epoch: 5| Step: 10
Training loss: 0.07791517674922943
Validation loss: 1.4164714313322497

Epoch: 586| Step: 0
Training loss: 0.12286438792943954
Validation loss: 1.4098579793848016

Epoch: 5| Step: 1
Training loss: 0.0921703428030014
Validation loss: 1.4028831604988343

Epoch: 5| Step: 2
Training loss: 0.18026049435138702
Validation loss: 1.425723712931397

Epoch: 5| Step: 3
Training loss: 0.10067955404520035
Validation loss: 1.4093996549165377

Epoch: 5| Step: 4
Training loss: 0.06504227966070175
Validation loss: 1.409184476380707

Epoch: 5| Step: 5
Training loss: 0.08680205047130585
Validation loss: 1.4204135415374592

Epoch: 5| Step: 6
Training loss: 0.10435471683740616
Validation loss: 1.4235289426901008

Epoch: 5| Step: 7
Training loss: 0.052335578948259354
Validation loss: 1.417087629277219

Epoch: 5| Step: 8
Training loss: 0.08464156836271286
Validation loss: 1.4338589022236485

Epoch: 5| Step: 9
Training loss: 0.06506293267011642
Validation loss: 1.4515731693595968

Epoch: 5| Step: 10
Training loss: 0.09764754772186279
Validation loss: 1.426603780638787

Epoch: 587| Step: 0
Training loss: 0.06769351661205292
Validation loss: 1.4593401205155156

Epoch: 5| Step: 1
Training loss: 0.047973357141017914
Validation loss: 1.442173671978776

Epoch: 5| Step: 2
Training loss: 0.10507645457983017
Validation loss: 1.430650354713522

Epoch: 5| Step: 3
Training loss: 0.10365718603134155
Validation loss: 1.4144488643574458

Epoch: 5| Step: 4
Training loss: 0.10588867962360382
Validation loss: 1.449183520450387

Epoch: 5| Step: 5
Training loss: 0.14475086331367493
Validation loss: 1.4284252569239626

Epoch: 5| Step: 6
Training loss: 0.10979721695184708
Validation loss: 1.4378150727159233

Epoch: 5| Step: 7
Training loss: 0.07941432297229767
Validation loss: 1.410570090816867

Epoch: 5| Step: 8
Training loss: 0.07602003216743469
Validation loss: 1.416772997507485

Epoch: 5| Step: 9
Training loss: 0.12606073915958405
Validation loss: 1.4377292112637592

Epoch: 5| Step: 10
Training loss: 0.09648419171571732
Validation loss: 1.4394968043091476

Epoch: 588| Step: 0
Training loss: 0.061548542231321335
Validation loss: 1.4116007243433306

Epoch: 5| Step: 1
Training loss: 0.10270638763904572
Validation loss: 1.4445052249457246

Epoch: 5| Step: 2
Training loss: 0.09993000328540802
Validation loss: 1.411414473287521

Epoch: 5| Step: 3
Training loss: 0.09633446484804153
Validation loss: 1.425271939205867

Epoch: 5| Step: 4
Training loss: 0.1461787223815918
Validation loss: 1.457961759259624

Epoch: 5| Step: 5
Training loss: 0.09987233579158783
Validation loss: 1.4648513037671325

Epoch: 5| Step: 6
Training loss: 0.08901041001081467
Validation loss: 1.463334333512091

Epoch: 5| Step: 7
Training loss: 0.07550927251577377
Validation loss: 1.4703405877595306

Epoch: 5| Step: 8
Training loss: 0.10574625432491302
Validation loss: 1.4545315311801048

Epoch: 5| Step: 9
Training loss: 0.08873327076435089
Validation loss: 1.4250411987304688

Epoch: 5| Step: 10
Training loss: 0.0696985274553299
Validation loss: 1.4347176064727127

Epoch: 589| Step: 0
Training loss: 0.09226875007152557
Validation loss: 1.4350971150141891

Epoch: 5| Step: 1
Training loss: 0.10681869834661484
Validation loss: 1.4544501432808496

Epoch: 5| Step: 2
Training loss: 0.08531971275806427
Validation loss: 1.4507345499530915

Epoch: 5| Step: 3
Training loss: 0.057241041213274
Validation loss: 1.4670552579305505

Epoch: 5| Step: 4
Training loss: 0.11099795997142792
Validation loss: 1.4511184410382343

Epoch: 5| Step: 5
Training loss: 0.08321255445480347
Validation loss: 1.4454971718531784

Epoch: 5| Step: 6
Training loss: 0.10095970332622528
Validation loss: 1.4434814542852423

Epoch: 5| Step: 7
Training loss: 0.14678171277046204
Validation loss: 1.4577942753350863

Epoch: 5| Step: 8
Training loss: 0.0913592129945755
Validation loss: 1.4733127265848138

Epoch: 5| Step: 9
Training loss: 0.07488925755023956
Validation loss: 1.4731309349818895

Epoch: 5| Step: 10
Training loss: 0.1657254546880722
Validation loss: 1.4908984168883292

Epoch: 590| Step: 0
Training loss: 0.11372128874063492
Validation loss: 1.4726851242844776

Epoch: 5| Step: 1
Training loss: 0.0890040248632431
Validation loss: 1.4649693414729128

Epoch: 5| Step: 2
Training loss: 0.1073014959692955
Validation loss: 1.4008805969709992

Epoch: 5| Step: 3
Training loss: 0.07372036576271057
Validation loss: 1.4122808441039054

Epoch: 5| Step: 4
Training loss: 0.10453615337610245
Validation loss: 1.390975038210551

Epoch: 5| Step: 5
Training loss: 0.13296392560005188
Validation loss: 1.3799692751258932

Epoch: 5| Step: 6
Training loss: 0.07441382110118866
Validation loss: 1.373915377483573

Epoch: 5| Step: 7
Training loss: 0.08183233439922333
Validation loss: 1.3927862157103836

Epoch: 5| Step: 8
Training loss: 0.21643610298633575
Validation loss: 1.3966206632634646

Epoch: 5| Step: 9
Training loss: 0.11556166410446167
Validation loss: 1.387600400114572

Epoch: 5| Step: 10
Training loss: 0.07277815043926239
Validation loss: 1.4061495014416274

Epoch: 591| Step: 0
Training loss: 0.15197184681892395
Validation loss: 1.3974728738107989

Epoch: 5| Step: 1
Training loss: 0.06187986582517624
Validation loss: 1.4177177593272219

Epoch: 5| Step: 2
Training loss: 0.05119525268673897
Validation loss: 1.4262809009962185

Epoch: 5| Step: 3
Training loss: 0.08108866214752197
Validation loss: 1.455297391901734

Epoch: 5| Step: 4
Training loss: 0.0468330904841423
Validation loss: 1.4391915131640691

Epoch: 5| Step: 5
Training loss: 0.08323774486780167
Validation loss: 1.4547152724317325

Epoch: 5| Step: 6
Training loss: 0.12255893647670746
Validation loss: 1.4555937577319402

Epoch: 5| Step: 7
Training loss: 0.10478230565786362
Validation loss: 1.4347905644806482

Epoch: 5| Step: 8
Training loss: 0.12682998180389404
Validation loss: 1.4452995202874626

Epoch: 5| Step: 9
Training loss: 0.09305175393819809
Validation loss: 1.4382160209840344

Epoch: 5| Step: 10
Training loss: 0.0816238597035408
Validation loss: 1.458469517769352

Epoch: 592| Step: 0
Training loss: 0.115494504570961
Validation loss: 1.4359013906089209

Epoch: 5| Step: 1
Training loss: 0.07212954759597778
Validation loss: 1.4434776844516877

Epoch: 5| Step: 2
Training loss: 0.0748312771320343
Validation loss: 1.4140526620290612

Epoch: 5| Step: 3
Training loss: 0.10629115253686905
Validation loss: 1.405872893589799

Epoch: 5| Step: 4
Training loss: 0.1289280354976654
Validation loss: 1.3999660220197452

Epoch: 5| Step: 5
Training loss: 0.10600294172763824
Validation loss: 1.428595059661455

Epoch: 5| Step: 6
Training loss: 0.11856776475906372
Validation loss: 1.388115180436001

Epoch: 5| Step: 7
Training loss: 0.07173202186822891
Validation loss: 1.4258005106320946

Epoch: 5| Step: 8
Training loss: 0.08035190403461456
Validation loss: 1.4235598194983698

Epoch: 5| Step: 9
Training loss: 0.17717978358268738
Validation loss: 1.4294662373040312

Epoch: 5| Step: 10
Training loss: 0.056630559265613556
Validation loss: 1.4423814595386546

Epoch: 593| Step: 0
Training loss: 0.22762084007263184
Validation loss: 1.4434269782035583

Epoch: 5| Step: 1
Training loss: 0.07518729567527771
Validation loss: 1.4503860358268983

Epoch: 5| Step: 2
Training loss: 0.11037516593933105
Validation loss: 1.4595110813776653

Epoch: 5| Step: 3
Training loss: 0.08498337864875793
Validation loss: 1.4671699218852545

Epoch: 5| Step: 4
Training loss: 0.10676471889019012
Validation loss: 1.448815902074178

Epoch: 5| Step: 5
Training loss: 0.09194248169660568
Validation loss: 1.4529391181084417

Epoch: 5| Step: 6
Training loss: 0.11165761947631836
Validation loss: 1.46036361622554

Epoch: 5| Step: 7
Training loss: 0.10562682151794434
Validation loss: 1.4183252844759213

Epoch: 5| Step: 8
Training loss: 0.082570381462574
Validation loss: 1.4183797938849336

Epoch: 5| Step: 9
Training loss: 0.07099975645542145
Validation loss: 1.3952800048294889

Epoch: 5| Step: 10
Training loss: 0.08928736299276352
Validation loss: 1.4032021158485002

Epoch: 594| Step: 0
Training loss: 0.11107931286096573
Validation loss: 1.3993076919227518

Epoch: 5| Step: 1
Training loss: 0.09316626936197281
Validation loss: 1.4067612296791487

Epoch: 5| Step: 2
Training loss: 0.08625587075948715
Validation loss: 1.3879703719128844

Epoch: 5| Step: 3
Training loss: 0.08873611688613892
Validation loss: 1.4085712253406484

Epoch: 5| Step: 4
Training loss: 0.08094047009944916
Validation loss: 1.4047269077711209

Epoch: 5| Step: 5
Training loss: 0.10104862600564957
Validation loss: 1.4056381615259315

Epoch: 5| Step: 6
Training loss: 0.12227513641119003
Validation loss: 1.3999245641052083

Epoch: 5| Step: 7
Training loss: 0.06442397087812424
Validation loss: 1.3867521593647618

Epoch: 5| Step: 8
Training loss: 0.10568241775035858
Validation loss: 1.39621720006389

Epoch: 5| Step: 9
Training loss: 0.09575434029102325
Validation loss: 1.4103692744367866

Epoch: 5| Step: 10
Training loss: 0.2156757116317749
Validation loss: 1.3854903713349374

Epoch: 595| Step: 0
Training loss: 0.07974746078252792
Validation loss: 1.3605145619761558

Epoch: 5| Step: 1
Training loss: 0.0851723700761795
Validation loss: 1.3878501128124934

Epoch: 5| Step: 2
Training loss: 0.11012816429138184
Validation loss: 1.3584231356138825

Epoch: 5| Step: 3
Training loss: 0.08894021809101105
Validation loss: 1.3834616458544167

Epoch: 5| Step: 4
Training loss: 0.08076508343219757
Validation loss: 1.3802462367601291

Epoch: 5| Step: 5
Training loss: 0.08067768067121506
Validation loss: 1.3757880810768373

Epoch: 5| Step: 6
Training loss: 0.08021538704633713
Validation loss: 1.3545653672628506

Epoch: 5| Step: 7
Training loss: 0.1574287712574005
Validation loss: 1.3688856292796392

Epoch: 5| Step: 8
Training loss: 0.0985003262758255
Validation loss: 1.363386760475815

Epoch: 5| Step: 9
Training loss: 0.08836044371128082
Validation loss: 1.3666202996366767

Epoch: 5| Step: 10
Training loss: 0.06880462914705276
Validation loss: 1.3950547531086912

Epoch: 596| Step: 0
Training loss: 0.10106834024190903
Validation loss: 1.3689134377305225

Epoch: 5| Step: 1
Training loss: 0.07769425213336945
Validation loss: 1.3683006507094189

Epoch: 5| Step: 2
Training loss: 0.057075392454862595
Validation loss: 1.3839799595135513

Epoch: 5| Step: 3
Training loss: 0.068601593375206
Validation loss: 1.3857096843822028

Epoch: 5| Step: 4
Training loss: 0.10738243907690048
Validation loss: 1.3674567143122356

Epoch: 5| Step: 5
Training loss: 0.14574763178825378
Validation loss: 1.390629462016526

Epoch: 5| Step: 6
Training loss: 0.07237090915441513
Validation loss: 1.4139643317909651

Epoch: 5| Step: 7
Training loss: 0.09465907514095306
Validation loss: 1.4080389866264917

Epoch: 5| Step: 8
Training loss: 0.07496964931488037
Validation loss: 1.4170285322332894

Epoch: 5| Step: 9
Training loss: 0.08522966504096985
Validation loss: 1.392071532946761

Epoch: 5| Step: 10
Training loss: 0.061168503016233444
Validation loss: 1.431255393130805

Epoch: 597| Step: 0
Training loss: 0.07048129290342331
Validation loss: 1.442772574322198

Epoch: 5| Step: 1
Training loss: 0.07687432318925858
Validation loss: 1.4284461044496106

Epoch: 5| Step: 2
Training loss: 0.05655106157064438
Validation loss: 1.4196246798320482

Epoch: 5| Step: 3
Training loss: 0.07440447807312012
Validation loss: 1.424763088585228

Epoch: 5| Step: 4
Training loss: 0.05167729780077934
Validation loss: 1.4420830613823348

Epoch: 5| Step: 5
Training loss: 0.05908866599202156
Validation loss: 1.410782447425268

Epoch: 5| Step: 6
Training loss: 0.09954660385847092
Validation loss: 1.4170239817711614

Epoch: 5| Step: 7
Training loss: 0.06989958882331848
Validation loss: 1.4182451783969838

Epoch: 5| Step: 8
Training loss: 0.10825691372156143
Validation loss: 1.403918081714261

Epoch: 5| Step: 9
Training loss: 0.14511069655418396
Validation loss: 1.4216548973514187

Epoch: 5| Step: 10
Training loss: 0.08705718070268631
Validation loss: 1.4037631275833293

Epoch: 598| Step: 0
Training loss: 0.06851059198379517
Validation loss: 1.4233810747823408

Epoch: 5| Step: 1
Training loss: 0.078255295753479
Validation loss: 1.4228702584902446

Epoch: 5| Step: 2
Training loss: 0.06806160509586334
Validation loss: 1.3917523161057503

Epoch: 5| Step: 3
Training loss: 0.17350707948207855
Validation loss: 1.4025385546427902

Epoch: 5| Step: 4
Training loss: 0.06234488636255264
Validation loss: 1.4140726398396235

Epoch: 5| Step: 5
Training loss: 0.07186180353164673
Validation loss: 1.4293569749401462

Epoch: 5| Step: 6
Training loss: 0.07607214897871017
Validation loss: 1.4063281013119606

Epoch: 5| Step: 7
Training loss: 0.09608398377895355
Validation loss: 1.4176005035318353

Epoch: 5| Step: 8
Training loss: 0.07546602189540863
Validation loss: 1.420178908173756

Epoch: 5| Step: 9
Training loss: 0.09922797232866287
Validation loss: 1.3815194586271882

Epoch: 5| Step: 10
Training loss: 0.08346176147460938
Validation loss: 1.3697848448189356

Epoch: 599| Step: 0
Training loss: 0.110612653195858
Validation loss: 1.3523420659444665

Epoch: 5| Step: 1
Training loss: 0.07635984569787979
Validation loss: 1.3510929820358113

Epoch: 5| Step: 2
Training loss: 0.11518914997577667
Validation loss: 1.3565291871306717

Epoch: 5| Step: 3
Training loss: 0.06952390819787979
Validation loss: 1.3361289411462762

Epoch: 5| Step: 4
Training loss: 0.080025315284729
Validation loss: 1.3522141774495442

Epoch: 5| Step: 5
Training loss: 0.10627772659063339
Validation loss: 1.357055966572095

Epoch: 5| Step: 6
Training loss: 0.15220032632350922
Validation loss: 1.3578854081451253

Epoch: 5| Step: 7
Training loss: 0.07502175122499466
Validation loss: 1.3977608629452285

Epoch: 5| Step: 8
Training loss: 0.11331839859485626
Validation loss: 1.4261463047355734

Epoch: 5| Step: 9
Training loss: 0.12090804427862167
Validation loss: 1.4560808673981698

Epoch: 5| Step: 10
Training loss: 0.08283311128616333
Validation loss: 1.4217853623051797

Epoch: 600| Step: 0
Training loss: 0.1367952823638916
Validation loss: 1.4393800291963803

Epoch: 5| Step: 1
Training loss: 0.0605943500995636
Validation loss: 1.4170844131900417

Epoch: 5| Step: 2
Training loss: 0.11467720568180084
Validation loss: 1.3922867454508299

Epoch: 5| Step: 3
Training loss: 0.13503018021583557
Validation loss: 1.3960195741345804

Epoch: 5| Step: 4
Training loss: 0.1282246708869934
Validation loss: 1.3684305772986463

Epoch: 5| Step: 5
Training loss: 0.061778474599123
Validation loss: 1.3698096634239278

Epoch: 5| Step: 6
Training loss: 0.08860565721988678
Validation loss: 1.3823834939669537

Epoch: 5| Step: 7
Training loss: 0.09806261956691742
Validation loss: 1.3890568056414205

Epoch: 5| Step: 8
Training loss: 0.06716114282608032
Validation loss: 1.4050454965201757

Epoch: 5| Step: 9
Training loss: 0.0659739226102829
Validation loss: 1.4213227571979645

Epoch: 5| Step: 10
Training loss: 0.0828988179564476
Validation loss: 1.4418933506934875

Epoch: 601| Step: 0
Training loss: 0.08385413885116577
Validation loss: 1.459400059074484

Epoch: 5| Step: 1
Training loss: 0.12822851538658142
Validation loss: 1.4819782036606983

Epoch: 5| Step: 2
Training loss: 0.10552577674388885
Validation loss: 1.494189077808011

Epoch: 5| Step: 3
Training loss: 0.052732061594724655
Validation loss: 1.4802905039120746

Epoch: 5| Step: 4
Training loss: 0.15597036480903625
Validation loss: 1.4482880612855316

Epoch: 5| Step: 5
Training loss: 0.09466618299484253
Validation loss: 1.4685194607703917

Epoch: 5| Step: 6
Training loss: 0.1296495646238327
Validation loss: 1.4468290075179069

Epoch: 5| Step: 7
Training loss: 0.09177984297275543
Validation loss: 1.4139695039359472

Epoch: 5| Step: 8
Training loss: 0.07268373668193817
Validation loss: 1.3906796375910442

Epoch: 5| Step: 9
Training loss: 0.08814261853694916
Validation loss: 1.4047577317043016

Epoch: 5| Step: 10
Training loss: 0.09905867278575897
Validation loss: 1.3518580916107341

Epoch: 602| Step: 0
Training loss: 0.09211559593677521
Validation loss: 1.4016005941616592

Epoch: 5| Step: 1
Training loss: 0.09287601709365845
Validation loss: 1.4339359511611283

Epoch: 5| Step: 2
Training loss: 0.08720304816961288
Validation loss: 1.4025187030915292

Epoch: 5| Step: 3
Training loss: 0.16339311003684998
Validation loss: 1.4140782266534784

Epoch: 5| Step: 4
Training loss: 0.08012793213129044
Validation loss: 1.4147006042541996

Epoch: 5| Step: 5
Training loss: 0.08960764110088348
Validation loss: 1.4113484415956723

Epoch: 5| Step: 6
Training loss: 0.11158952862024307
Validation loss: 1.4524145856980355

Epoch: 5| Step: 7
Training loss: 0.08413930237293243
Validation loss: 1.4322143664924047

Epoch: 5| Step: 8
Training loss: 0.06521086394786835
Validation loss: 1.4409258775813605

Epoch: 5| Step: 9
Training loss: 0.08926636725664139
Validation loss: 1.4178991394658242

Epoch: 5| Step: 10
Training loss: 0.11034734547138214
Validation loss: 1.4263261261806692

Epoch: 603| Step: 0
Training loss: 0.04487181827425957
Validation loss: 1.4118829670772757

Epoch: 5| Step: 1
Training loss: 0.0908387079834938
Validation loss: 1.4207465526878194

Epoch: 5| Step: 2
Training loss: 0.07306976616382599
Validation loss: 1.4049402590720885

Epoch: 5| Step: 3
Training loss: 0.06718789041042328
Validation loss: 1.4262284501906364

Epoch: 5| Step: 4
Training loss: 0.11351607739925385
Validation loss: 1.3904320962967411

Epoch: 5| Step: 5
Training loss: 0.06323827803134918
Validation loss: 1.425867324234337

Epoch: 5| Step: 6
Training loss: 0.11444127559661865
Validation loss: 1.4541085272706964

Epoch: 5| Step: 7
Training loss: 0.09892081469297409
Validation loss: 1.4343876056773688

Epoch: 5| Step: 8
Training loss: 0.08674011379480362
Validation loss: 1.4221188483699676

Epoch: 5| Step: 9
Training loss: 0.05477312207221985
Validation loss: 1.4045247916252381

Epoch: 5| Step: 10
Training loss: 0.09887544810771942
Validation loss: 1.3703125292255032

Epoch: 604| Step: 0
Training loss: 0.07900112867355347
Validation loss: 1.3549897773291475

Epoch: 5| Step: 1
Training loss: 0.06715376675128937
Validation loss: 1.3576083426834435

Epoch: 5| Step: 2
Training loss: 0.08832208812236786
Validation loss: 1.3313362393327939

Epoch: 5| Step: 3
Training loss: 0.06873946636915207
Validation loss: 1.3428475203052643

Epoch: 5| Step: 4
Training loss: 0.06753204017877579
Validation loss: 1.344142078071512

Epoch: 5| Step: 5
Training loss: 0.11105965077877045
Validation loss: 1.3930387759721408

Epoch: 5| Step: 6
Training loss: 0.1661207675933838
Validation loss: 1.3990486994866402

Epoch: 5| Step: 7
Training loss: 0.09983544051647186
Validation loss: 1.4294687368536507

Epoch: 5| Step: 8
Training loss: 0.10210837423801422
Validation loss: 1.4740440281488563

Epoch: 5| Step: 9
Training loss: 0.1108970195055008
Validation loss: 1.4661921275559293

Epoch: 5| Step: 10
Training loss: 0.09734742343425751
Validation loss: 1.427603393472651

Epoch: 605| Step: 0
Training loss: 0.10503356158733368
Validation loss: 1.3857216053111578

Epoch: 5| Step: 1
Training loss: 0.06335651874542236
Validation loss: 1.3665168208460654

Epoch: 5| Step: 2
Training loss: 0.08062317967414856
Validation loss: 1.359736466920504

Epoch: 5| Step: 3
Training loss: 0.08014856278896332
Validation loss: 1.3708268673189226

Epoch: 5| Step: 4
Training loss: 0.08545849472284317
Validation loss: 1.3626180412948772

Epoch: 5| Step: 5
Training loss: 0.07338982820510864
Validation loss: 1.3779912046206895

Epoch: 5| Step: 6
Training loss: 0.11707863956689835
Validation loss: 1.378720127126222

Epoch: 5| Step: 7
Training loss: 0.04777388274669647
Validation loss: 1.3944167385819137

Epoch: 5| Step: 8
Training loss: 0.1411237269639969
Validation loss: 1.4300806003232156

Epoch: 5| Step: 9
Training loss: 0.08908386528491974
Validation loss: 1.4209318135374336

Epoch: 5| Step: 10
Training loss: 0.13655617833137512
Validation loss: 1.40360055815789

Epoch: 606| Step: 0
Training loss: 0.17287710309028625
Validation loss: 1.413988495385775

Epoch: 5| Step: 1
Training loss: 0.0700024664402008
Validation loss: 1.404321648741281

Epoch: 5| Step: 2
Training loss: 0.06945602595806122
Validation loss: 1.4162532129595358

Epoch: 5| Step: 3
Training loss: 0.06605822592973709
Validation loss: 1.4294660168309365

Epoch: 5| Step: 4
Training loss: 0.04198302701115608
Validation loss: 1.403295418267609

Epoch: 5| Step: 5
Training loss: 0.05982302501797676
Validation loss: 1.4058866244490429

Epoch: 5| Step: 6
Training loss: 0.04992332309484482
Validation loss: 1.397062063217163

Epoch: 5| Step: 7
Training loss: 0.0958535447716713
Validation loss: 1.3988402851166264

Epoch: 5| Step: 8
Training loss: 0.0999860018491745
Validation loss: 1.400995821081182

Epoch: 5| Step: 9
Training loss: 0.07391289621591568
Validation loss: 1.3920650776996408

Epoch: 5| Step: 10
Training loss: 0.1215062141418457
Validation loss: 1.4068493740532988

Epoch: 607| Step: 0
Training loss: 0.06545571982860565
Validation loss: 1.4078671714311004

Epoch: 5| Step: 1
Training loss: 0.0586811788380146
Validation loss: 1.3969767311567902

Epoch: 5| Step: 2
Training loss: 0.06145929545164108
Validation loss: 1.4025368709718027

Epoch: 5| Step: 3
Training loss: 0.07018612325191498
Validation loss: 1.3877538891248806

Epoch: 5| Step: 4
Training loss: 0.15329761803150177
Validation loss: 1.3710532098688104

Epoch: 5| Step: 5
Training loss: 0.06048533320426941
Validation loss: 1.3693402633872083

Epoch: 5| Step: 6
Training loss: 0.0781085342168808
Validation loss: 1.366065776476296

Epoch: 5| Step: 7
Training loss: 0.06369505077600479
Validation loss: 1.3833722465781755

Epoch: 5| Step: 8
Training loss: 0.08590985089540482
Validation loss: 1.3812718788782756

Epoch: 5| Step: 9
Training loss: 0.10800661891698837
Validation loss: 1.3607356625218545

Epoch: 5| Step: 10
Training loss: 0.060179486870765686
Validation loss: 1.3645229031962733

Epoch: 608| Step: 0
Training loss: 0.07489113509654999
Validation loss: 1.34756935668248

Epoch: 5| Step: 1
Training loss: 0.1452026218175888
Validation loss: 1.380465663889403

Epoch: 5| Step: 2
Training loss: 0.11150336265563965
Validation loss: 1.3755817073647694

Epoch: 5| Step: 3
Training loss: 0.09842618554830551
Validation loss: 1.4152746527425704

Epoch: 5| Step: 4
Training loss: 0.13117079436779022
Validation loss: 1.3966825469847648

Epoch: 5| Step: 5
Training loss: 0.07111658155918121
Validation loss: 1.3767156357406287

Epoch: 5| Step: 6
Training loss: 0.07854019105434418
Validation loss: 1.425075973233869

Epoch: 5| Step: 7
Training loss: 0.058991290628910065
Validation loss: 1.4050273331262733

Epoch: 5| Step: 8
Training loss: 0.05079773813486099
Validation loss: 1.4084521198785434

Epoch: 5| Step: 9
Training loss: 0.05916902422904968
Validation loss: 1.3922778124450355

Epoch: 5| Step: 10
Training loss: 0.06409917026758194
Validation loss: 1.3924530539461362

Epoch: 609| Step: 0
Training loss: 0.0552842803299427
Validation loss: 1.404067591954303

Epoch: 5| Step: 1
Training loss: 0.17769798636436462
Validation loss: 1.414294251831629

Epoch: 5| Step: 2
Training loss: 0.06257810443639755
Validation loss: 1.4033000546116983

Epoch: 5| Step: 3
Training loss: 0.0782548040151596
Validation loss: 1.4010608632077453

Epoch: 5| Step: 4
Training loss: 0.0566449873149395
Validation loss: 1.3934994794989144

Epoch: 5| Step: 5
Training loss: 0.09288334101438522
Validation loss: 1.395031395137951

Epoch: 5| Step: 6
Training loss: 0.07169127464294434
Validation loss: 1.386747544811618

Epoch: 5| Step: 7
Training loss: 0.071247398853302
Validation loss: 1.4060700099955323

Epoch: 5| Step: 8
Training loss: 0.0935656875371933
Validation loss: 1.4146392230064637

Epoch: 5| Step: 9
Training loss: 0.10558007657527924
Validation loss: 1.4210098738311439

Epoch: 5| Step: 10
Training loss: 0.06314758211374283
Validation loss: 1.422469251899309

Epoch: 610| Step: 0
Training loss: 0.12408442795276642
Validation loss: 1.42611091239478

Epoch: 5| Step: 1
Training loss: 0.08609257638454437
Validation loss: 1.424726132423647

Epoch: 5| Step: 2
Training loss: 0.08999153971672058
Validation loss: 1.4210321775046728

Epoch: 5| Step: 3
Training loss: 0.06664708256721497
Validation loss: 1.4369432336540633

Epoch: 5| Step: 4
Training loss: 0.06380356103181839
Validation loss: 1.4161159690990244

Epoch: 5| Step: 5
Training loss: 0.10020382702350616
Validation loss: 1.3827905795907462

Epoch: 5| Step: 6
Training loss: 0.12199410051107407
Validation loss: 1.4209770874310566

Epoch: 5| Step: 7
Training loss: 0.06972427666187286
Validation loss: 1.4353258263680242

Epoch: 5| Step: 8
Training loss: 0.06508749723434448
Validation loss: 1.4608191386345895

Epoch: 5| Step: 9
Training loss: 0.10972528159618378
Validation loss: 1.468239140766923

Epoch: 5| Step: 10
Training loss: 0.173383891582489
Validation loss: 1.4681261277967883

Epoch: 611| Step: 0
Training loss: 0.11982067674398422
Validation loss: 1.4204630441563104

Epoch: 5| Step: 1
Training loss: 0.06939508020877838
Validation loss: 1.4233804736086118

Epoch: 5| Step: 2
Training loss: 0.06114978343248367
Validation loss: 1.378688039959118

Epoch: 5| Step: 3
Training loss: 0.14512984454631805
Validation loss: 1.3962481829427904

Epoch: 5| Step: 4
Training loss: 0.09342090040445328
Validation loss: 1.399056883268459

Epoch: 5| Step: 5
Training loss: 0.14093241095542908
Validation loss: 1.3904060586806266

Epoch: 5| Step: 6
Training loss: 0.10424548387527466
Validation loss: 1.3692410011445322

Epoch: 5| Step: 7
Training loss: 0.10675318539142609
Validation loss: 1.3827959158087288

Epoch: 5| Step: 8
Training loss: 0.11493366956710815
Validation loss: 1.4083074914511813

Epoch: 5| Step: 9
Training loss: 0.07177835702896118
Validation loss: 1.399512001263198

Epoch: 5| Step: 10
Training loss: 0.0780516117811203
Validation loss: 1.4315597972562235

Epoch: 612| Step: 0
Training loss: 0.0913623720407486
Validation loss: 1.437293105227973

Epoch: 5| Step: 1
Training loss: 0.08925119787454605
Validation loss: 1.420679779462917

Epoch: 5| Step: 2
Training loss: 0.10230891406536102
Validation loss: 1.4119790850147125

Epoch: 5| Step: 3
Training loss: 0.09376363456249237
Validation loss: 1.4049979922592

Epoch: 5| Step: 4
Training loss: 0.12458209693431854
Validation loss: 1.4108433242767089

Epoch: 5| Step: 5
Training loss: 0.07448689639568329
Validation loss: 1.391343452597177

Epoch: 5| Step: 6
Training loss: 0.07508733868598938
Validation loss: 1.3868968647013429

Epoch: 5| Step: 7
Training loss: 0.09735546261072159
Validation loss: 1.3616662935544086

Epoch: 5| Step: 8
Training loss: 0.15061430633068085
Validation loss: 1.3684557817315544

Epoch: 5| Step: 9
Training loss: 0.08737163245677948
Validation loss: 1.3797823645735299

Epoch: 5| Step: 10
Training loss: 0.060174956917762756
Validation loss: 1.376145956336811

Epoch: 613| Step: 0
Training loss: 0.11463499069213867
Validation loss: 1.4067069343341294

Epoch: 5| Step: 1
Training loss: 0.08076053857803345
Validation loss: 1.378407971833342

Epoch: 5| Step: 2
Training loss: 0.06612448394298553
Validation loss: 1.3714103814094298

Epoch: 5| Step: 3
Training loss: 0.08944687992334366
Validation loss: 1.3954317249277586

Epoch: 5| Step: 4
Training loss: 0.08975784480571747
Validation loss: 1.3858791538464126

Epoch: 5| Step: 5
Training loss: 0.10425428301095963
Validation loss: 1.4159624730387042

Epoch: 5| Step: 6
Training loss: 0.13655200600624084
Validation loss: 1.41053980781186

Epoch: 5| Step: 7
Training loss: 0.0862107202410698
Validation loss: 1.4047165698902582

Epoch: 5| Step: 8
Training loss: 0.09766211360692978
Validation loss: 1.3791544796318136

Epoch: 5| Step: 9
Training loss: 0.09420692920684814
Validation loss: 1.3874991798913607

Epoch: 5| Step: 10
Training loss: 0.08804778009653091
Validation loss: 1.4209332414852676

Epoch: 614| Step: 0
Training loss: 0.07338370382785797
Validation loss: 1.4253386912807342

Epoch: 5| Step: 1
Training loss: 0.15278980135917664
Validation loss: 1.4119675031272314

Epoch: 5| Step: 2
Training loss: 0.09668226540088654
Validation loss: 1.4182128278158044

Epoch: 5| Step: 3
Training loss: 0.06759308278560638
Validation loss: 1.3868951361666444

Epoch: 5| Step: 4
Training loss: 0.11875218152999878
Validation loss: 1.3943648107590214

Epoch: 5| Step: 5
Training loss: 0.07760754972696304
Validation loss: 1.3982571812086209

Epoch: 5| Step: 6
Training loss: 0.07428524643182755
Validation loss: 1.3812402666255992

Epoch: 5| Step: 7
Training loss: 0.08249127864837646
Validation loss: 1.3892776190593679

Epoch: 5| Step: 8
Training loss: 0.08325556665658951
Validation loss: 1.3678594263651038

Epoch: 5| Step: 9
Training loss: 0.11427204310894012
Validation loss: 1.3742118086866153

Epoch: 5| Step: 10
Training loss: 0.06848842650651932
Validation loss: 1.4006187678665243

Epoch: 615| Step: 0
Training loss: 0.05898083373904228
Validation loss: 1.3733828740735208

Epoch: 5| Step: 1
Training loss: 0.06995834410190582
Validation loss: 1.3991507778885544

Epoch: 5| Step: 2
Training loss: 0.14128629863262177
Validation loss: 1.3863306917170042

Epoch: 5| Step: 3
Training loss: 0.07322943210601807
Validation loss: 1.386451385354483

Epoch: 5| Step: 4
Training loss: 0.09504753351211548
Validation loss: 1.411743184571625

Epoch: 5| Step: 5
Training loss: 0.07217631489038467
Validation loss: 1.4213907616112822

Epoch: 5| Step: 6
Training loss: 0.11625900119543076
Validation loss: 1.406354029973348

Epoch: 5| Step: 7
Training loss: 0.04476601630449295
Validation loss: 1.3775152788367322

Epoch: 5| Step: 8
Training loss: 0.08929271996021271
Validation loss: 1.385391116142273

Epoch: 5| Step: 9
Training loss: 0.0756683498620987
Validation loss: 1.3810294917834702

Epoch: 5| Step: 10
Training loss: 0.11965771019458771
Validation loss: 1.3568740326871154

Epoch: 616| Step: 0
Training loss: 0.09687862545251846
Validation loss: 1.3686323332530197

Epoch: 5| Step: 1
Training loss: 0.07267729192972183
Validation loss: 1.3678496499215402

Epoch: 5| Step: 2
Training loss: 0.09071366488933563
Validation loss: 1.379770690394986

Epoch: 5| Step: 3
Training loss: 0.07357528805732727
Validation loss: 1.4002115694425439

Epoch: 5| Step: 4
Training loss: 0.060194920748472214
Validation loss: 1.4102137216957666

Epoch: 5| Step: 5
Training loss: 0.11538650095462799
Validation loss: 1.37565234655975

Epoch: 5| Step: 6
Training loss: 0.06666513532400131
Validation loss: 1.4343099196751912

Epoch: 5| Step: 7
Training loss: 0.07687915861606598
Validation loss: 1.4052102617038194

Epoch: 5| Step: 8
Training loss: 0.077329121530056
Validation loss: 1.4214212215074928

Epoch: 5| Step: 9
Training loss: 0.10059423744678497
Validation loss: 1.4163499987253578

Epoch: 5| Step: 10
Training loss: 0.037738364189863205
Validation loss: 1.4146312231658607

Epoch: 617| Step: 0
Training loss: 0.08325479924678802
Validation loss: 1.3989707628885906

Epoch: 5| Step: 1
Training loss: 0.07209192961454391
Validation loss: 1.4089979766517557

Epoch: 5| Step: 2
Training loss: 0.04479570686817169
Validation loss: 1.4146660630420973

Epoch: 5| Step: 3
Training loss: 0.1195407286286354
Validation loss: 1.426611772147558

Epoch: 5| Step: 4
Training loss: 0.06395688652992249
Validation loss: 1.4338904555125902

Epoch: 5| Step: 5
Training loss: 0.06339968740940094
Validation loss: 1.4227126413776028

Epoch: 5| Step: 6
Training loss: 0.06571991741657257
Validation loss: 1.4300734766067997

Epoch: 5| Step: 7
Training loss: 0.10188640654087067
Validation loss: 1.4268093762859222

Epoch: 5| Step: 8
Training loss: 0.12581300735473633
Validation loss: 1.4291482305014005

Epoch: 5| Step: 9
Training loss: 0.04503114894032478
Validation loss: 1.4259305795033772

Epoch: 5| Step: 10
Training loss: 0.08430884778499603
Validation loss: 1.4488682951978458

Epoch: 618| Step: 0
Training loss: 0.10625986009836197
Validation loss: 1.4464790263483602

Epoch: 5| Step: 1
Training loss: 0.06958971172571182
Validation loss: 1.44483575641468

Epoch: 5| Step: 2
Training loss: 0.07618691027164459
Validation loss: 1.414099581139062

Epoch: 5| Step: 3
Training loss: 0.08725466579198837
Validation loss: 1.389323511431294

Epoch: 5| Step: 4
Training loss: 0.18259768187999725
Validation loss: 1.3702747796171455

Epoch: 5| Step: 5
Training loss: 0.07085921615362167
Validation loss: 1.3701757307975524

Epoch: 5| Step: 6
Training loss: 0.07045702636241913
Validation loss: 1.3452513012834775

Epoch: 5| Step: 7
Training loss: 0.06569967418909073
Validation loss: 1.340341184728889

Epoch: 5| Step: 8
Training loss: 0.11803986132144928
Validation loss: 1.35476972979884

Epoch: 5| Step: 9
Training loss: 0.10206524282693863
Validation loss: 1.366105641088178

Epoch: 5| Step: 10
Training loss: 0.10694702714681625
Validation loss: 1.3778251986349783

Epoch: 619| Step: 0
Training loss: 0.06213624030351639
Validation loss: 1.4042475492723527

Epoch: 5| Step: 1
Training loss: 0.07394399493932724
Validation loss: 1.4013636355758996

Epoch: 5| Step: 2
Training loss: 0.08513125777244568
Validation loss: 1.415346267402813

Epoch: 5| Step: 3
Training loss: 0.0762961208820343
Validation loss: 1.414905023831193

Epoch: 5| Step: 4
Training loss: 0.10588028281927109
Validation loss: 1.4364727927792458

Epoch: 5| Step: 5
Training loss: 0.044810861349105835
Validation loss: 1.4379929598941599

Epoch: 5| Step: 6
Training loss: 0.08794458955526352
Validation loss: 1.4406034510622743

Epoch: 5| Step: 7
Training loss: 0.06488107144832611
Validation loss: 1.4328965134518121

Epoch: 5| Step: 8
Training loss: 0.09655109792947769
Validation loss: 1.4258837904981387

Epoch: 5| Step: 9
Training loss: 0.06347250938415527
Validation loss: 1.4227260517817673

Epoch: 5| Step: 10
Training loss: 0.0934290736913681
Validation loss: 1.4168666787044977

Epoch: 620| Step: 0
Training loss: 0.054113734513521194
Validation loss: 1.3857229281497259

Epoch: 5| Step: 1
Training loss: 0.07526379823684692
Validation loss: 1.4281035418151526

Epoch: 5| Step: 2
Training loss: 0.045128438621759415
Validation loss: 1.4413768975965437

Epoch: 5| Step: 3
Training loss: 0.07869633287191391
Validation loss: 1.4492934980700094

Epoch: 5| Step: 4
Training loss: 0.09921256452798843
Validation loss: 1.4407221796692058

Epoch: 5| Step: 5
Training loss: 0.12008114159107208
Validation loss: 1.4639049409538187

Epoch: 5| Step: 6
Training loss: 0.06618492305278778
Validation loss: 1.4431769437687372

Epoch: 5| Step: 7
Training loss: 0.07130803912878036
Validation loss: 1.4184288645303378

Epoch: 5| Step: 8
Training loss: 0.0627979263663292
Validation loss: 1.4384705103853697

Epoch: 5| Step: 9
Training loss: 0.062108080834150314
Validation loss: 1.4186775017810125

Epoch: 5| Step: 10
Training loss: 0.12433495372533798
Validation loss: 1.4136305329620198

Epoch: 621| Step: 0
Training loss: 0.06423184275627136
Validation loss: 1.4002501951750888

Epoch: 5| Step: 1
Training loss: 0.05272113159298897
Validation loss: 1.3868408267216017

Epoch: 5| Step: 2
Training loss: 0.05302714183926582
Validation loss: 1.4129223906865684

Epoch: 5| Step: 3
Training loss: 0.07174895703792572
Validation loss: 1.393131661158736

Epoch: 5| Step: 4
Training loss: 0.05979368835687637
Validation loss: 1.378029586166464

Epoch: 5| Step: 5
Training loss: 0.07307618111371994
Validation loss: 1.3765635195598807

Epoch: 5| Step: 6
Training loss: 0.05385466665029526
Validation loss: 1.401832079374662

Epoch: 5| Step: 7
Training loss: 0.10090667009353638
Validation loss: 1.3980454552558161

Epoch: 5| Step: 8
Training loss: 0.10154549032449722
Validation loss: 1.367671300006169

Epoch: 5| Step: 9
Training loss: 0.07703591138124466
Validation loss: 1.3875948613689792

Epoch: 5| Step: 10
Training loss: 0.0858953595161438
Validation loss: 1.3923291820351795

Epoch: 622| Step: 0
Training loss: 0.12668141722679138
Validation loss: 1.4101974387322702

Epoch: 5| Step: 1
Training loss: 0.12089662253856659
Validation loss: 1.4277169422436786

Epoch: 5| Step: 2
Training loss: 0.11216428130865097
Validation loss: 1.4297141105897966

Epoch: 5| Step: 3
Training loss: 0.08845818787813187
Validation loss: 1.4252893373530398

Epoch: 5| Step: 4
Training loss: 0.07104827463626862
Validation loss: 1.441335944719212

Epoch: 5| Step: 5
Training loss: 0.059294264763593674
Validation loss: 1.4504679877270934

Epoch: 5| Step: 6
Training loss: 0.06317615509033203
Validation loss: 1.423477143369695

Epoch: 5| Step: 7
Training loss: 0.0716857984662056
Validation loss: 1.4041600868266115

Epoch: 5| Step: 8
Training loss: 0.0799064189195633
Validation loss: 1.4296376987170147

Epoch: 5| Step: 9
Training loss: 0.06520354747772217
Validation loss: 1.455940547809806

Epoch: 5| Step: 10
Training loss: 0.06563752144575119
Validation loss: 1.445113730686967

Epoch: 623| Step: 0
Training loss: 0.052065659314394
Validation loss: 1.431189194802315

Epoch: 5| Step: 1
Training loss: 0.13670697808265686
Validation loss: 1.4505549630811136

Epoch: 5| Step: 2
Training loss: 0.0850657969713211
Validation loss: 1.4429178199460428

Epoch: 5| Step: 3
Training loss: 0.10466138273477554
Validation loss: 1.4220352711216095

Epoch: 5| Step: 4
Training loss: 0.09143323451280594
Validation loss: 1.4041559683379305

Epoch: 5| Step: 5
Training loss: 0.11570477485656738
Validation loss: 1.411939235143764

Epoch: 5| Step: 6
Training loss: 0.08922405540943146
Validation loss: 1.4098868575147403

Epoch: 5| Step: 7
Training loss: 0.08125941455364227
Validation loss: 1.4388961612537343

Epoch: 5| Step: 8
Training loss: 0.11237404495477676
Validation loss: 1.4140806300665743

Epoch: 5| Step: 9
Training loss: 0.10921734571456909
Validation loss: 1.4570404611608034

Epoch: 5| Step: 10
Training loss: 0.06463823467493057
Validation loss: 1.4784481788194308

Epoch: 624| Step: 0
Training loss: 0.13634304702281952
Validation loss: 1.4451258112025518

Epoch: 5| Step: 1
Training loss: 0.05124477297067642
Validation loss: 1.4259219438798967

Epoch: 5| Step: 2
Training loss: 0.0745374858379364
Validation loss: 1.4172769874654791

Epoch: 5| Step: 3
Training loss: 0.04658251255750656
Validation loss: 1.3833749050735145

Epoch: 5| Step: 4
Training loss: 0.0685778334736824
Validation loss: 1.3719498380537956

Epoch: 5| Step: 5
Training loss: 0.05841086059808731
Validation loss: 1.383971098930605

Epoch: 5| Step: 6
Training loss: 0.08066795766353607
Validation loss: 1.388747363962153

Epoch: 5| Step: 7
Training loss: 0.07582883536815643
Validation loss: 1.364828453269056

Epoch: 5| Step: 8
Training loss: 0.09090100228786469
Validation loss: 1.3488518794377644

Epoch: 5| Step: 9
Training loss: 0.13578888773918152
Validation loss: 1.3703376913583407

Epoch: 5| Step: 10
Training loss: 0.13775578141212463
Validation loss: 1.3494387852248324

Epoch: 625| Step: 0
Training loss: 0.07547514140605927
Validation loss: 1.36717902844952

Epoch: 5| Step: 1
Training loss: 0.07018549740314484
Validation loss: 1.386863217558912

Epoch: 5| Step: 2
Training loss: 0.07678910344839096
Validation loss: 1.3654580744363929

Epoch: 5| Step: 3
Training loss: 0.08897764980792999
Validation loss: 1.3696223740936608

Epoch: 5| Step: 4
Training loss: 0.04766688868403435
Validation loss: 1.3834174640717045

Epoch: 5| Step: 5
Training loss: 0.07786741107702255
Validation loss: 1.3905143481428905

Epoch: 5| Step: 6
Training loss: 0.13871333003044128
Validation loss: 1.390170661352014

Epoch: 5| Step: 7
Training loss: 0.11908914148807526
Validation loss: 1.3836977020386727

Epoch: 5| Step: 8
Training loss: 0.06370271742343903
Validation loss: 1.3518452118801814

Epoch: 5| Step: 9
Training loss: 0.07057566195726395
Validation loss: 1.35536914871585

Epoch: 5| Step: 10
Training loss: 0.0784616693854332
Validation loss: 1.3803627670452159

Epoch: 626| Step: 0
Training loss: 0.131679505109787
Validation loss: 1.3338013169586018

Epoch: 5| Step: 1
Training loss: 0.08763062208890915
Validation loss: 1.3387377685116184

Epoch: 5| Step: 2
Training loss: 0.06392908096313477
Validation loss: 1.3647444248199463

Epoch: 5| Step: 3
Training loss: 0.11434666812419891
Validation loss: 1.3562593947174728

Epoch: 5| Step: 4
Training loss: 0.05219344049692154
Validation loss: 1.3724494102180644

Epoch: 5| Step: 5
Training loss: 0.07984504103660583
Validation loss: 1.4047602991903982

Epoch: 5| Step: 6
Training loss: 0.11852612346410751
Validation loss: 1.3822525316669094

Epoch: 5| Step: 7
Training loss: 0.07413894683122635
Validation loss: 1.398365234815946

Epoch: 5| Step: 8
Training loss: 0.08589746057987213
Validation loss: 1.405484934006968

Epoch: 5| Step: 9
Training loss: 0.07530038058757782
Validation loss: 1.4108811732261413

Epoch: 5| Step: 10
Training loss: 0.03681138530373573
Validation loss: 1.4051295916239421

Epoch: 627| Step: 0
Training loss: 0.04553859680891037
Validation loss: 1.4004169382074827

Epoch: 5| Step: 1
Training loss: 0.07658638060092926
Validation loss: 1.4261203991469515

Epoch: 5| Step: 2
Training loss: 0.04583171010017395
Validation loss: 1.4047807519153883

Epoch: 5| Step: 3
Training loss: 0.11218404769897461
Validation loss: 1.4062299779666367

Epoch: 5| Step: 4
Training loss: 0.11125321686267853
Validation loss: 1.418236937574161

Epoch: 5| Step: 5
Training loss: 0.05628290772438049
Validation loss: 1.4334326200587775

Epoch: 5| Step: 6
Training loss: 0.08426646888256073
Validation loss: 1.432773531124156

Epoch: 5| Step: 7
Training loss: 0.0684765949845314
Validation loss: 1.4242451152493876

Epoch: 5| Step: 8
Training loss: 0.08877725899219513
Validation loss: 1.416052726007277

Epoch: 5| Step: 9
Training loss: 0.08846378326416016
Validation loss: 1.4192573229471843

Epoch: 5| Step: 10
Training loss: 0.06531070917844772
Validation loss: 1.4018310026455951

Epoch: 628| Step: 0
Training loss: 0.07983941584825516
Validation loss: 1.3756069470477361

Epoch: 5| Step: 1
Training loss: 0.06763766705989838
Validation loss: 1.3918424742196196

Epoch: 5| Step: 2
Training loss: 0.08247829228639603
Validation loss: 1.3652610394262499

Epoch: 5| Step: 3
Training loss: 0.040894389152526855
Validation loss: 1.36021166206688

Epoch: 5| Step: 4
Training loss: 0.07301262766122818
Validation loss: 1.3348837757623324

Epoch: 5| Step: 5
Training loss: 0.0615752711892128
Validation loss: 1.3413883216919438

Epoch: 5| Step: 6
Training loss: 0.08879677206277847
Validation loss: 1.3188763203159455

Epoch: 5| Step: 7
Training loss: 0.07097402960062027
Validation loss: 1.3314040014820714

Epoch: 5| Step: 8
Training loss: 0.11414690315723419
Validation loss: 1.334450311558221

Epoch: 5| Step: 9
Training loss: 0.11058590561151505
Validation loss: 1.3368193141875728

Epoch: 5| Step: 10
Training loss: 0.05757636949419975
Validation loss: 1.346829254140136

Epoch: 629| Step: 0
Training loss: 0.05899685621261597
Validation loss: 1.3711634412888558

Epoch: 5| Step: 1
Training loss: 0.06079249456524849
Validation loss: 1.397610152921369

Epoch: 5| Step: 2
Training loss: 0.06133440136909485
Validation loss: 1.3951295421969505

Epoch: 5| Step: 3
Training loss: 0.05546225234866142
Validation loss: 1.3908936118566861

Epoch: 5| Step: 4
Training loss: 0.11070122569799423
Validation loss: 1.3790728533139793

Epoch: 5| Step: 5
Training loss: 0.06937815248966217
Validation loss: 1.3965128532019995

Epoch: 5| Step: 6
Training loss: 0.06088787317276001
Validation loss: 1.3768716191732755

Epoch: 5| Step: 7
Training loss: 0.047775931656360626
Validation loss: 1.3769345373235724

Epoch: 5| Step: 8
Training loss: 0.07454373687505722
Validation loss: 1.3613351827026696

Epoch: 5| Step: 9
Training loss: 0.06266266107559204
Validation loss: 1.3588446647890153

Epoch: 5| Step: 10
Training loss: 0.11602926254272461
Validation loss: 1.3537769843173284

Epoch: 630| Step: 0
Training loss: 0.05796848610043526
Validation loss: 1.3375841212529007

Epoch: 5| Step: 1
Training loss: 0.07542622834444046
Validation loss: 1.3621655189862816

Epoch: 5| Step: 2
Training loss: 0.04619736224412918
Validation loss: 1.3750019176031953

Epoch: 5| Step: 3
Training loss: 0.07992909848690033
Validation loss: 1.387148851989418

Epoch: 5| Step: 4
Training loss: 0.08036313205957413
Validation loss: 1.3966772569123136

Epoch: 5| Step: 5
Training loss: 0.059424448758363724
Validation loss: 1.4065799379861483

Epoch: 5| Step: 6
Training loss: 0.06954356282949448
Validation loss: 1.3991670762338946

Epoch: 5| Step: 7
Training loss: 0.12184979766607285
Validation loss: 1.4179578955455492

Epoch: 5| Step: 8
Training loss: 0.08894260972738266
Validation loss: 1.4039372795371599

Epoch: 5| Step: 9
Training loss: 0.07099490612745285
Validation loss: 1.4509843382784116

Epoch: 5| Step: 10
Training loss: 0.11519565433263779
Validation loss: 1.4440354236992456

Epoch: 631| Step: 0
Training loss: 0.04862157255411148
Validation loss: 1.4387498645372288

Epoch: 5| Step: 1
Training loss: 0.09468499571084976
Validation loss: 1.4280182571821316

Epoch: 5| Step: 2
Training loss: 0.083929643034935
Validation loss: 1.4306794879257039

Epoch: 5| Step: 3
Training loss: 0.15369632840156555
Validation loss: 1.420982277521523

Epoch: 5| Step: 4
Training loss: 0.027582813054323196
Validation loss: 1.4147161309437086

Epoch: 5| Step: 5
Training loss: 0.09771005064249039
Validation loss: 1.419072231938762

Epoch: 5| Step: 6
Training loss: 0.06755056977272034
Validation loss: 1.4170114353138914

Epoch: 5| Step: 7
Training loss: 0.07366832345724106
Validation loss: 1.411964144757999

Epoch: 5| Step: 8
Training loss: 0.055825281888246536
Validation loss: 1.3890349621413856

Epoch: 5| Step: 9
Training loss: 0.07025593519210815
Validation loss: 1.3855597178141277

Epoch: 5| Step: 10
Training loss: 0.07606019824743271
Validation loss: 1.4095454228821622

Epoch: 632| Step: 0
Training loss: 0.08961139619350433
Validation loss: 1.40564001119265

Epoch: 5| Step: 1
Training loss: 0.05605441331863403
Validation loss: 1.3981410393150904

Epoch: 5| Step: 2
Training loss: 0.09609991312026978
Validation loss: 1.409828233462508

Epoch: 5| Step: 3
Training loss: 0.08636604994535446
Validation loss: 1.416051213459302

Epoch: 5| Step: 4
Training loss: 0.06783682107925415
Validation loss: 1.4025561719812372

Epoch: 5| Step: 5
Training loss: 0.09690762311220169
Validation loss: 1.3918085187994025

Epoch: 5| Step: 6
Training loss: 0.11741390079259872
Validation loss: 1.3954421115177933

Epoch: 5| Step: 7
Training loss: 0.0751541405916214
Validation loss: 1.4032065496649793

Epoch: 5| Step: 8
Training loss: 0.07377059757709503
Validation loss: 1.3921855252276185

Epoch: 5| Step: 9
Training loss: 0.14742103219032288
Validation loss: 1.3715650343125867

Epoch: 5| Step: 10
Training loss: 0.09528560936450958
Validation loss: 1.3816406714018954

Epoch: 633| Step: 0
Training loss: 0.09367523342370987
Validation loss: 1.3819441192893571

Epoch: 5| Step: 1
Training loss: 0.05890918895602226
Validation loss: 1.3937311839031916

Epoch: 5| Step: 2
Training loss: 0.0572916641831398
Validation loss: 1.3915564731885028

Epoch: 5| Step: 3
Training loss: 0.13625796139240265
Validation loss: 1.381977835009175

Epoch: 5| Step: 4
Training loss: 0.07498414814472198
Validation loss: 1.380841899943608

Epoch: 5| Step: 5
Training loss: 0.08043912798166275
Validation loss: 1.3849026964556785

Epoch: 5| Step: 6
Training loss: 0.05932658910751343
Validation loss: 1.3775803119905534

Epoch: 5| Step: 7
Training loss: 0.07750263065099716
Validation loss: 1.3909427812022548

Epoch: 5| Step: 8
Training loss: 0.06346486508846283
Validation loss: 1.40367631758413

Epoch: 5| Step: 9
Training loss: 0.06559063494205475
Validation loss: 1.4119451148535616

Epoch: 5| Step: 10
Training loss: 0.09072132408618927
Validation loss: 1.4102536452713834

Epoch: 634| Step: 0
Training loss: 0.09833215177059174
Validation loss: 1.3932783885668683

Epoch: 5| Step: 1
Training loss: 0.10172595083713531
Validation loss: 1.4248370124447731

Epoch: 5| Step: 2
Training loss: 0.06846343725919724
Validation loss: 1.4063490821469216

Epoch: 5| Step: 3
Training loss: 0.07247616350650787
Validation loss: 1.4014431814993582

Epoch: 5| Step: 4
Training loss: 0.06057692691683769
Validation loss: 1.4047635550140052

Epoch: 5| Step: 5
Training loss: 0.10519661754369736
Validation loss: 1.416097976828134

Epoch: 5| Step: 6
Training loss: 0.0763671025633812
Validation loss: 1.385670349803022

Epoch: 5| Step: 7
Training loss: 0.06675203144550323
Validation loss: 1.3776193575192524

Epoch: 5| Step: 8
Training loss: 0.061701416969299316
Validation loss: 1.376439017634238

Epoch: 5| Step: 9
Training loss: 0.04811326041817665
Validation loss: 1.4043162048503917

Epoch: 5| Step: 10
Training loss: 0.07413095235824585
Validation loss: 1.39971504288335

Epoch: 635| Step: 0
Training loss: 0.10792847722768784
Validation loss: 1.394100505818603

Epoch: 5| Step: 1
Training loss: 0.07870575040578842
Validation loss: 1.4139486487193773

Epoch: 5| Step: 2
Training loss: 0.09394340217113495
Validation loss: 1.4501585761706035

Epoch: 5| Step: 3
Training loss: 0.0797102078795433
Validation loss: 1.424535410378569

Epoch: 5| Step: 4
Training loss: 0.06765985488891602
Validation loss: 1.4033313464092951

Epoch: 5| Step: 5
Training loss: 0.07822079956531525
Validation loss: 1.3693674533597884

Epoch: 5| Step: 6
Training loss: 0.06900159269571304
Validation loss: 1.3970249186279953

Epoch: 5| Step: 7
Training loss: 0.0814599022269249
Validation loss: 1.3860865434010823

Epoch: 5| Step: 8
Training loss: 0.10293712466955185
Validation loss: 1.366963900545592

Epoch: 5| Step: 9
Training loss: 0.05099532753229141
Validation loss: 1.37450203716114

Epoch: 5| Step: 10
Training loss: 0.06208745017647743
Validation loss: 1.382522395862046

Epoch: 636| Step: 0
Training loss: 0.0823298990726471
Validation loss: 1.3731737611114339

Epoch: 5| Step: 1
Training loss: 0.06168724223971367
Validation loss: 1.375281915869764

Epoch: 5| Step: 2
Training loss: 0.06518961489200592
Validation loss: 1.356156822173826

Epoch: 5| Step: 3
Training loss: 0.055396128445863724
Validation loss: 1.3649001845749476

Epoch: 5| Step: 4
Training loss: 0.06244369596242905
Validation loss: 1.3668561661115257

Epoch: 5| Step: 5
Training loss: 0.11012425273656845
Validation loss: 1.3629710860149835

Epoch: 5| Step: 6
Training loss: 0.04857485741376877
Validation loss: 1.3585763227555059

Epoch: 5| Step: 7
Training loss: 0.1596200317144394
Validation loss: 1.3620794062973351

Epoch: 5| Step: 8
Training loss: 0.06805677711963654
Validation loss: 1.4062400159015451

Epoch: 5| Step: 9
Training loss: 0.10035903751850128
Validation loss: 1.4109340880506782

Epoch: 5| Step: 10
Training loss: 0.10702600330114365
Validation loss: 1.424083927626251

Epoch: 637| Step: 0
Training loss: 0.09738457202911377
Validation loss: 1.4007870356241863

Epoch: 5| Step: 1
Training loss: 0.07029049098491669
Validation loss: 1.4143500142200018

Epoch: 5| Step: 2
Training loss: 0.061849385499954224
Validation loss: 1.4224612661587295

Epoch: 5| Step: 3
Training loss: 0.09419341385364532
Validation loss: 1.4630922835360292

Epoch: 5| Step: 4
Training loss: 0.05374465137720108
Validation loss: 1.4109940644233459

Epoch: 5| Step: 5
Training loss: 0.053255945444107056
Validation loss: 1.4067973930348632

Epoch: 5| Step: 6
Training loss: 0.047468751668930054
Validation loss: 1.3898792997483285

Epoch: 5| Step: 7
Training loss: 0.09506560862064362
Validation loss: 1.3966576309614285

Epoch: 5| Step: 8
Training loss: 0.0906032845377922
Validation loss: 1.367900937475184

Epoch: 5| Step: 9
Training loss: 0.06606518477201462
Validation loss: 1.3740635546304847

Epoch: 5| Step: 10
Training loss: 0.05819816514849663
Validation loss: 1.3944638570149739

Epoch: 638| Step: 0
Training loss: 0.07766663283109665
Validation loss: 1.4001679164107128

Epoch: 5| Step: 1
Training loss: 0.06328756362199783
Validation loss: 1.409091446989326

Epoch: 5| Step: 2
Training loss: 0.05838654562830925
Validation loss: 1.3968529508959862

Epoch: 5| Step: 3
Training loss: 0.06608928740024567
Validation loss: 1.388759385514003

Epoch: 5| Step: 4
Training loss: 0.06694132834672928
Validation loss: 1.4051385489843224

Epoch: 5| Step: 5
Training loss: 0.06857029348611832
Validation loss: 1.4259344236825102

Epoch: 5| Step: 6
Training loss: 0.05702275037765503
Validation loss: 1.3891493915229716

Epoch: 5| Step: 7
Training loss: 0.1259998083114624
Validation loss: 1.4028151958219466

Epoch: 5| Step: 8
Training loss: 0.0754285380244255
Validation loss: 1.3833520527808898

Epoch: 5| Step: 9
Training loss: 0.0502040758728981
Validation loss: 1.3897561334794568

Epoch: 5| Step: 10
Training loss: 0.08437415212392807
Validation loss: 1.3973527467379006

Epoch: 639| Step: 0
Training loss: 0.0527682900428772
Validation loss: 1.3996242553957048

Epoch: 5| Step: 1
Training loss: 0.05984692648053169
Validation loss: 1.4039578271168534

Epoch: 5| Step: 2
Training loss: 0.0404818169772625
Validation loss: 1.4018219324850267

Epoch: 5| Step: 3
Training loss: 0.07181797921657562
Validation loss: 1.39148493864203

Epoch: 5| Step: 4
Training loss: 0.05862601846456528
Validation loss: 1.4047981718535065

Epoch: 5| Step: 5
Training loss: 0.09690496325492859
Validation loss: 1.412049690882365

Epoch: 5| Step: 6
Training loss: 0.08534274995326996
Validation loss: 1.392781622948185

Epoch: 5| Step: 7
Training loss: 0.10005155950784683
Validation loss: 1.4012760116207985

Epoch: 5| Step: 8
Training loss: 0.1088416799902916
Validation loss: 1.4239482418183358

Epoch: 5| Step: 9
Training loss: 0.07112505286931992
Validation loss: 1.4243203978384695

Epoch: 5| Step: 10
Training loss: 0.0688287764787674
Validation loss: 1.4145237643231627

Epoch: 640| Step: 0
Training loss: 0.06159697845578194
Validation loss: 1.4105329205912929

Epoch: 5| Step: 1
Training loss: 0.0712340846657753
Validation loss: 1.4176551001046294

Epoch: 5| Step: 2
Training loss: 0.07920749485492706
Validation loss: 1.4258148362559657

Epoch: 5| Step: 3
Training loss: 0.08342935889959335
Validation loss: 1.3898620169649842

Epoch: 5| Step: 4
Training loss: 0.08350832760334015
Validation loss: 1.381871118340441

Epoch: 5| Step: 5
Training loss: 0.0958317220211029
Validation loss: 1.4038394830560172

Epoch: 5| Step: 6
Training loss: 0.047853026539087296
Validation loss: 1.4043213667408112

Epoch: 5| Step: 7
Training loss: 0.10259006172418594
Validation loss: 1.42154279639644

Epoch: 5| Step: 8
Training loss: 0.08569936454296112
Validation loss: 1.4006164817399875

Epoch: 5| Step: 9
Training loss: 0.03558032959699631
Validation loss: 1.396302984606835

Epoch: 5| Step: 10
Training loss: 0.06272418797016144
Validation loss: 1.4043593034949353

Epoch: 641| Step: 0
Training loss: 0.06561224162578583
Validation loss: 1.407358447710673

Epoch: 5| Step: 1
Training loss: 0.06659460067749023
Validation loss: 1.3856210503526913

Epoch: 5| Step: 2
Training loss: 0.06911472231149673
Validation loss: 1.388211097768558

Epoch: 5| Step: 3
Training loss: 0.05197461321949959
Validation loss: 1.3743142645846131

Epoch: 5| Step: 4
Training loss: 0.08046301454305649
Validation loss: 1.3621560296704691

Epoch: 5| Step: 5
Training loss: 0.03616161271929741
Validation loss: 1.368201526262427

Epoch: 5| Step: 6
Training loss: 0.09784675389528275
Validation loss: 1.3657615396284288

Epoch: 5| Step: 7
Training loss: 0.10803935676813126
Validation loss: 1.343692748777328

Epoch: 5| Step: 8
Training loss: 0.06594108045101166
Validation loss: 1.3719649814790296

Epoch: 5| Step: 9
Training loss: 0.058095790445804596
Validation loss: 1.3577562660299323

Epoch: 5| Step: 10
Training loss: 0.119509756565094
Validation loss: 1.3576213211141608

Epoch: 642| Step: 0
Training loss: 0.08483591675758362
Validation loss: 1.355238745289464

Epoch: 5| Step: 1
Training loss: 0.0657697394490242
Validation loss: 1.3730634322730444

Epoch: 5| Step: 2
Training loss: 0.045123688876628876
Validation loss: 1.3602937857309978

Epoch: 5| Step: 3
Training loss: 0.08463160693645477
Validation loss: 1.4065620399290515

Epoch: 5| Step: 4
Training loss: 0.09116490930318832
Validation loss: 1.39004470199667

Epoch: 5| Step: 5
Training loss: 0.0684167742729187
Validation loss: 1.387763382286154

Epoch: 5| Step: 6
Training loss: 0.06574980914592743
Validation loss: 1.3987722159713827

Epoch: 5| Step: 7
Training loss: 0.09531699866056442
Validation loss: 1.3938751015611874

Epoch: 5| Step: 8
Training loss: 0.056877218186855316
Validation loss: 1.3793728274683799

Epoch: 5| Step: 9
Training loss: 0.0903998389840126
Validation loss: 1.388715333195143

Epoch: 5| Step: 10
Training loss: 0.04288738593459129
Validation loss: 1.3944954013311734

Epoch: 643| Step: 0
Training loss: 0.08021378517150879
Validation loss: 1.3711850758521789

Epoch: 5| Step: 1
Training loss: 0.0646495446562767
Validation loss: 1.392979641114512

Epoch: 5| Step: 2
Training loss: 0.06364213675260544
Validation loss: 1.3892314523778937

Epoch: 5| Step: 3
Training loss: 0.12514565885066986
Validation loss: 1.3691494746874737

Epoch: 5| Step: 4
Training loss: 0.04684934765100479
Validation loss: 1.3842056579487299

Epoch: 5| Step: 5
Training loss: 0.06344875693321228
Validation loss: 1.3825353307108725

Epoch: 5| Step: 6
Training loss: 0.056573234498500824
Validation loss: 1.3896938857211862

Epoch: 5| Step: 7
Training loss: 0.0590459480881691
Validation loss: 1.4147251075313938

Epoch: 5| Step: 8
Training loss: 0.08801928907632828
Validation loss: 1.3927808192468458

Epoch: 5| Step: 9
Training loss: 0.12433825433254242
Validation loss: 1.4026164822680975

Epoch: 5| Step: 10
Training loss: 0.09781386703252792
Validation loss: 1.4015468884539861

Epoch: 644| Step: 0
Training loss: 0.06977976858615875
Validation loss: 1.378857825392036

Epoch: 5| Step: 1
Training loss: 0.05618929862976074
Validation loss: 1.4121179542233866

Epoch: 5| Step: 2
Training loss: 0.06411968171596527
Validation loss: 1.4086011814814743

Epoch: 5| Step: 3
Training loss: 0.10250337421894073
Validation loss: 1.4039423542637979

Epoch: 5| Step: 4
Training loss: 0.0947810560464859
Validation loss: 1.4238906944951704

Epoch: 5| Step: 5
Training loss: 0.0802328884601593
Validation loss: 1.3901604939532537

Epoch: 5| Step: 6
Training loss: 0.06983514130115509
Validation loss: 1.3843174929259925

Epoch: 5| Step: 7
Training loss: 0.06374527513980865
Validation loss: 1.3619436910075526

Epoch: 5| Step: 8
Training loss: 0.0810256153345108
Validation loss: 1.3656088421421666

Epoch: 5| Step: 9
Training loss: 0.07819761335849762
Validation loss: 1.356314201508799

Epoch: 5| Step: 10
Training loss: 0.0880684033036232
Validation loss: 1.3348484955808169

Epoch: 645| Step: 0
Training loss: 0.1487198770046234
Validation loss: 1.3529237681819546

Epoch: 5| Step: 1
Training loss: 0.0703658014535904
Validation loss: 1.3725953896840413

Epoch: 5| Step: 2
Training loss: 0.08870689570903778
Validation loss: 1.3907894947195565

Epoch: 5| Step: 3
Training loss: 0.10534071922302246
Validation loss: 1.3884233018403411

Epoch: 5| Step: 4
Training loss: 0.05494551733136177
Validation loss: 1.3827035837276007

Epoch: 5| Step: 5
Training loss: 0.07590233534574509
Validation loss: 1.4036964985632128

Epoch: 5| Step: 6
Training loss: 0.09699346125125885
Validation loss: 1.3762068671564902

Epoch: 5| Step: 7
Training loss: 0.05028349906206131
Validation loss: 1.3505555109311176

Epoch: 5| Step: 8
Training loss: 0.06407277286052704
Validation loss: 1.3604724593059991

Epoch: 5| Step: 9
Training loss: 0.06539250165224075
Validation loss: 1.3371299191187787

Epoch: 5| Step: 10
Training loss: 0.05449213832616806
Validation loss: 1.3342937679700955

Epoch: 646| Step: 0
Training loss: 0.15748782455921173
Validation loss: 1.3226468114442722

Epoch: 5| Step: 1
Training loss: 0.07464957982301712
Validation loss: 1.324914352868193

Epoch: 5| Step: 2
Training loss: 0.06285595148801804
Validation loss: 1.326429533702071

Epoch: 5| Step: 3
Training loss: 0.05730285122990608
Validation loss: 1.3675470057354178

Epoch: 5| Step: 4
Training loss: 0.08431945741176605
Validation loss: 1.3828564818187425

Epoch: 5| Step: 5
Training loss: 0.06864358484745026
Validation loss: 1.4152540301763883

Epoch: 5| Step: 6
Training loss: 0.10335224866867065
Validation loss: 1.4611977505427536

Epoch: 5| Step: 7
Training loss: 0.09354332834482193
Validation loss: 1.43738394014297

Epoch: 5| Step: 8
Training loss: 0.038169015198946
Validation loss: 1.4170308843735726

Epoch: 5| Step: 9
Training loss: 0.061489857733249664
Validation loss: 1.4126024887125979

Epoch: 5| Step: 10
Training loss: 0.08083370327949524
Validation loss: 1.4107538705231042

Epoch: 647| Step: 0
Training loss: 0.0690169706940651
Validation loss: 1.3900014661973523

Epoch: 5| Step: 1
Training loss: 0.06665513664484024
Validation loss: 1.377555997140946

Epoch: 5| Step: 2
Training loss: 0.07720500230789185
Validation loss: 1.3668066032471196

Epoch: 5| Step: 3
Training loss: 0.09044522792100906
Validation loss: 1.3662813389173118

Epoch: 5| Step: 4
Training loss: 0.055947255343198776
Validation loss: 1.3926954333500197

Epoch: 5| Step: 5
Training loss: 0.07836903631687164
Validation loss: 1.3632496236473002

Epoch: 5| Step: 6
Training loss: 0.07281345129013062
Validation loss: 1.3873636517473447

Epoch: 5| Step: 7
Training loss: 0.0731642097234726
Validation loss: 1.4220509118931268

Epoch: 5| Step: 8
Training loss: 0.09228403866291046
Validation loss: 1.4448607967745872

Epoch: 5| Step: 9
Training loss: 0.135493203997612
Validation loss: 1.4524492871376775

Epoch: 5| Step: 10
Training loss: 0.13856445252895355
Validation loss: 1.4130195379257202

Epoch: 648| Step: 0
Training loss: 0.07211705297231674
Validation loss: 1.3982569825264715

Epoch: 5| Step: 1
Training loss: 0.06107776239514351
Validation loss: 1.4189459931465886

Epoch: 5| Step: 2
Training loss: 0.0767616331577301
Validation loss: 1.3865534297881588

Epoch: 5| Step: 3
Training loss: 0.05218055099248886
Validation loss: 1.3870258491526368

Epoch: 5| Step: 4
Training loss: 0.07889484614133835
Validation loss: 1.3530205398477533

Epoch: 5| Step: 5
Training loss: 0.08154548704624176
Validation loss: 1.3504199315142889

Epoch: 5| Step: 6
Training loss: 0.07505898177623749
Validation loss: 1.3348691219924598

Epoch: 5| Step: 7
Training loss: 0.14656579494476318
Validation loss: 1.3584787371338054

Epoch: 5| Step: 8
Training loss: 0.06879505515098572
Validation loss: 1.3682744938840148

Epoch: 5| Step: 9
Training loss: 0.08203550428152084
Validation loss: 1.3592018811933455

Epoch: 5| Step: 10
Training loss: 0.06550367921590805
Validation loss: 1.382294943255763

Epoch: 649| Step: 0
Training loss: 0.0803767666220665
Validation loss: 1.3851177794958955

Epoch: 5| Step: 1
Training loss: 0.06429651379585266
Validation loss: 1.3845503227685088

Epoch: 5| Step: 2
Training loss: 0.09464836120605469
Validation loss: 1.3756561253660469

Epoch: 5| Step: 3
Training loss: 0.11785084009170532
Validation loss: 1.3465780083851149

Epoch: 5| Step: 4
Training loss: 0.07584469765424728
Validation loss: 1.3660843705618253

Epoch: 5| Step: 5
Training loss: 0.06278286874294281
Validation loss: 1.3738507301576677

Epoch: 5| Step: 6
Training loss: 0.13384483754634857
Validation loss: 1.3598792424765966

Epoch: 5| Step: 7
Training loss: 0.054202258586883545
Validation loss: 1.3504601781086256

Epoch: 5| Step: 8
Training loss: 0.06624198704957962
Validation loss: 1.3830182116518739

Epoch: 5| Step: 9
Training loss: 0.07618062198162079
Validation loss: 1.3505769570668538

Epoch: 5| Step: 10
Training loss: 0.08562470227479935
Validation loss: 1.3691351323999383

Epoch: 650| Step: 0
Training loss: 0.07594780623912811
Validation loss: 1.3774082795266183

Epoch: 5| Step: 1
Training loss: 0.06400556862354279
Validation loss: 1.3657096124464465

Epoch: 5| Step: 2
Training loss: 0.0749901756644249
Validation loss: 1.3740849943571194

Epoch: 5| Step: 3
Training loss: 0.0643400102853775
Validation loss: 1.4213171543613556

Epoch: 5| Step: 4
Training loss: 0.07329832017421722
Validation loss: 1.4113022242822955

Epoch: 5| Step: 5
Training loss: 0.08579115569591522
Validation loss: 1.405389117938216

Epoch: 5| Step: 6
Training loss: 0.059823207557201385
Validation loss: 1.39828949077155

Epoch: 5| Step: 7
Training loss: 0.05518548935651779
Validation loss: 1.4231689155742686

Epoch: 5| Step: 8
Training loss: 0.0745144933462143
Validation loss: 1.4164213903488652

Epoch: 5| Step: 9
Training loss: 0.10757973045110703
Validation loss: 1.4225477787756151

Epoch: 5| Step: 10
Training loss: 0.09948329627513885
Validation loss: 1.4313595423134424

Epoch: 651| Step: 0
Training loss: 0.08728037774562836
Validation loss: 1.412007361330012

Epoch: 5| Step: 1
Training loss: 0.0763823613524437
Validation loss: 1.3890713837838942

Epoch: 5| Step: 2
Training loss: 0.09391911327838898
Validation loss: 1.3930669625600178

Epoch: 5| Step: 3
Training loss: 0.11204403638839722
Validation loss: 1.3542218990223382

Epoch: 5| Step: 4
Training loss: 0.08275968581438065
Validation loss: 1.3598607958004039

Epoch: 5| Step: 5
Training loss: 0.08952128887176514
Validation loss: 1.3255677133478143

Epoch: 5| Step: 6
Training loss: 0.05102577060461044
Validation loss: 1.3386648060173116

Epoch: 5| Step: 7
Training loss: 0.07643836736679077
Validation loss: 1.3268264044997513

Epoch: 5| Step: 8
Training loss: 0.08111347258090973
Validation loss: 1.3418472377202844

Epoch: 5| Step: 9
Training loss: 0.09949370473623276
Validation loss: 1.3395588115979267

Epoch: 5| Step: 10
Training loss: 0.06396406143903732
Validation loss: 1.3577258266428465

Epoch: 652| Step: 0
Training loss: 0.0714179128408432
Validation loss: 1.3786130387295958

Epoch: 5| Step: 1
Training loss: 0.0874263346195221
Validation loss: 1.3528903120307512

Epoch: 5| Step: 2
Training loss: 0.09331781417131424
Validation loss: 1.3779056194008037

Epoch: 5| Step: 3
Training loss: 0.145198792219162
Validation loss: 1.3493842399248512

Epoch: 5| Step: 4
Training loss: 0.076469287276268
Validation loss: 1.3633917595750542

Epoch: 5| Step: 5
Training loss: 0.08050521463155746
Validation loss: 1.3532682554696196

Epoch: 5| Step: 6
Training loss: 0.05081164836883545
Validation loss: 1.332827938500271

Epoch: 5| Step: 7
Training loss: 0.06699912250041962
Validation loss: 1.3546188839020268

Epoch: 5| Step: 8
Training loss: 0.05186856910586357
Validation loss: 1.3537259870959866

Epoch: 5| Step: 9
Training loss: 0.06586664915084839
Validation loss: 1.3663714534492903

Epoch: 5| Step: 10
Training loss: 0.06525317579507828
Validation loss: 1.3633904175091816

Epoch: 653| Step: 0
Training loss: 0.08328749239444733
Validation loss: 1.3529068494355807

Epoch: 5| Step: 1
Training loss: 0.09228004515171051
Validation loss: 1.328782171331426

Epoch: 5| Step: 2
Training loss: 0.04988671466708183
Validation loss: 1.3684710315478745

Epoch: 5| Step: 3
Training loss: 0.05529450252652168
Validation loss: 1.3597563082172024

Epoch: 5| Step: 4
Training loss: 0.04903016611933708
Validation loss: 1.389902812178417

Epoch: 5| Step: 5
Training loss: 0.11663968861103058
Validation loss: 1.394570061596491

Epoch: 5| Step: 6
Training loss: 0.0592961311340332
Validation loss: 1.39767752539727

Epoch: 5| Step: 7
Training loss: 0.07172670215368271
Validation loss: 1.4134715372516262

Epoch: 5| Step: 8
Training loss: 0.07554586231708527
Validation loss: 1.395656302411069

Epoch: 5| Step: 9
Training loss: 0.11906258761882782
Validation loss: 1.3913457227009598

Epoch: 5| Step: 10
Training loss: 0.06225499510765076
Validation loss: 1.40648720213162

Epoch: 654| Step: 0
Training loss: 0.06466224044561386
Validation loss: 1.3594150453485467

Epoch: 5| Step: 1
Training loss: 0.04322436451911926
Validation loss: 1.4076519063723985

Epoch: 5| Step: 2
Training loss: 0.09735403954982758
Validation loss: 1.4040060376608243

Epoch: 5| Step: 3
Training loss: 0.05685671418905258
Validation loss: 1.364701026229448

Epoch: 5| Step: 4
Training loss: 0.05274149030447006
Validation loss: 1.4113513833733016

Epoch: 5| Step: 5
Training loss: 0.06939584016799927
Validation loss: 1.3944736937040925

Epoch: 5| Step: 6
Training loss: 0.07512704282999039
Validation loss: 1.3812494047226445

Epoch: 5| Step: 7
Training loss: 0.044894762337207794
Validation loss: 1.3723354134508359

Epoch: 5| Step: 8
Training loss: 0.058002494275569916
Validation loss: 1.363798479880056

Epoch: 5| Step: 9
Training loss: 0.07364276051521301
Validation loss: 1.378842777462416

Epoch: 5| Step: 10
Training loss: 0.0682557225227356
Validation loss: 1.3783688968227756

Epoch: 655| Step: 0
Training loss: 0.06809137016534805
Validation loss: 1.3831905318844704

Epoch: 5| Step: 1
Training loss: 0.06387124955654144
Validation loss: 1.3786593957613873

Epoch: 5| Step: 2
Training loss: 0.07118556648492813
Validation loss: 1.376824604567661

Epoch: 5| Step: 3
Training loss: 0.04877514764666557
Validation loss: 1.3848498585403606

Epoch: 5| Step: 4
Training loss: 0.06475907564163208
Validation loss: 1.3916599660791376

Epoch: 5| Step: 5
Training loss: 0.05613432452082634
Validation loss: 1.3532909936802362

Epoch: 5| Step: 6
Training loss: 0.09095672518014908
Validation loss: 1.3710092049773022

Epoch: 5| Step: 7
Training loss: 0.08808264881372452
Validation loss: 1.3868819000900432

Epoch: 5| Step: 8
Training loss: 0.06256010383367538
Validation loss: 1.385804460894677

Epoch: 5| Step: 9
Training loss: 0.04428483918309212
Validation loss: 1.392139228441382

Epoch: 5| Step: 10
Training loss: 0.08163672685623169
Validation loss: 1.3712728920803274

Epoch: 656| Step: 0
Training loss: 0.05205748230218887
Validation loss: 1.4063282878168168

Epoch: 5| Step: 1
Training loss: 0.046892594546079636
Validation loss: 1.3988791524723012

Epoch: 5| Step: 2
Training loss: 0.07413595914840698
Validation loss: 1.3801586679233018

Epoch: 5| Step: 3
Training loss: 0.13274823129177094
Validation loss: 1.3936057308668732

Epoch: 5| Step: 4
Training loss: 0.05985792726278305
Validation loss: 1.3724725656611945

Epoch: 5| Step: 5
Training loss: 0.054049551486968994
Validation loss: 1.384164103897669

Epoch: 5| Step: 6
Training loss: 0.05225766822695732
Validation loss: 1.379505371534696

Epoch: 5| Step: 7
Training loss: 0.08738156408071518
Validation loss: 1.3826257849252352

Epoch: 5| Step: 8
Training loss: 0.06821208447217941
Validation loss: 1.4016355974699861

Epoch: 5| Step: 9
Training loss: 0.06729419529438019
Validation loss: 1.3980666757911764

Epoch: 5| Step: 10
Training loss: 0.07054578512907028
Validation loss: 1.3724114817957724

Epoch: 657| Step: 0
Training loss: 0.05110020190477371
Validation loss: 1.3746229346080492

Epoch: 5| Step: 1
Training loss: 0.09273292124271393
Validation loss: 1.3753732289037397

Epoch: 5| Step: 2
Training loss: 0.07130240648984909
Validation loss: 1.3596977495378064

Epoch: 5| Step: 3
Training loss: 0.07336292415857315
Validation loss: 1.3714087470885246

Epoch: 5| Step: 4
Training loss: 0.057588137686252594
Validation loss: 1.3584086702715965

Epoch: 5| Step: 5
Training loss: 0.08590482175350189
Validation loss: 1.3532299687785487

Epoch: 5| Step: 6
Training loss: 0.08371935039758682
Validation loss: 1.4056498094271588

Epoch: 5| Step: 7
Training loss: 0.07234980165958405
Validation loss: 1.4077187238201019

Epoch: 5| Step: 8
Training loss: 0.06474053859710693
Validation loss: 1.4022061017251783

Epoch: 5| Step: 9
Training loss: 0.0799114853143692
Validation loss: 1.3921778919876262

Epoch: 5| Step: 10
Training loss: 0.04116415977478027
Validation loss: 1.4234278740421418

Epoch: 658| Step: 0
Training loss: 0.09969605505466461
Validation loss: 1.3997130035072245

Epoch: 5| Step: 1
Training loss: 0.04871607571840286
Validation loss: 1.417996004063596

Epoch: 5| Step: 2
Training loss: 0.05563335865736008
Validation loss: 1.4042258262634277

Epoch: 5| Step: 3
Training loss: 0.07665755599737167
Validation loss: 1.3871432113391098

Epoch: 5| Step: 4
Training loss: 0.08292971551418304
Validation loss: 1.402117281831721

Epoch: 5| Step: 5
Training loss: 0.04791766405105591
Validation loss: 1.3705513374779814

Epoch: 5| Step: 6
Training loss: 0.10672899335622787
Validation loss: 1.3711982145104358

Epoch: 5| Step: 7
Training loss: 0.06515426188707352
Validation loss: 1.3737891335641184

Epoch: 5| Step: 8
Training loss: 0.07221263647079468
Validation loss: 1.3755214509143625

Epoch: 5| Step: 9
Training loss: 0.07381326705217361
Validation loss: 1.387365984660323

Epoch: 5| Step: 10
Training loss: 0.06810462474822998
Validation loss: 1.393040200715424

Epoch: 659| Step: 0
Training loss: 0.10116416215896606
Validation loss: 1.3974352062389415

Epoch: 5| Step: 1
Training loss: 0.07929223030805588
Validation loss: 1.3807884467545377

Epoch: 5| Step: 2
Training loss: 0.06044645234942436
Validation loss: 1.3737400372823079

Epoch: 5| Step: 3
Training loss: 0.0727013498544693
Validation loss: 1.4027977425565001

Epoch: 5| Step: 4
Training loss: 0.08238734304904938
Validation loss: 1.3918059224723487

Epoch: 5| Step: 5
Training loss: 0.059709299355745316
Validation loss: 1.3989966338680637

Epoch: 5| Step: 6
Training loss: 0.07957235723733902
Validation loss: 1.4015763728849349

Epoch: 5| Step: 7
Training loss: 0.07332302629947662
Validation loss: 1.397352817238018

Epoch: 5| Step: 8
Training loss: 0.0939621701836586
Validation loss: 1.4123876992092337

Epoch: 5| Step: 9
Training loss: 0.055654894560575485
Validation loss: 1.4062839105565061

Epoch: 5| Step: 10
Training loss: 0.046406567096710205
Validation loss: 1.3858736945736794

Epoch: 660| Step: 0
Training loss: 0.06799586117267609
Validation loss: 1.3955832681348246

Epoch: 5| Step: 1
Training loss: 0.05920190364122391
Validation loss: 1.392381944964009

Epoch: 5| Step: 2
Training loss: 0.038147635757923126
Validation loss: 1.396444309142328

Epoch: 5| Step: 3
Training loss: 0.045412443578243256
Validation loss: 1.3891160526583273

Epoch: 5| Step: 4
Training loss: 0.05119679123163223
Validation loss: 1.4224315074182325

Epoch: 5| Step: 5
Training loss: 0.06994113326072693
Validation loss: 1.4241320228063932

Epoch: 5| Step: 6
Training loss: 0.07221554219722748
Validation loss: 1.4083226803810365

Epoch: 5| Step: 7
Training loss: 0.10425081104040146
Validation loss: 1.4293257318517214

Epoch: 5| Step: 8
Training loss: 0.06049780920147896
Validation loss: 1.4132539508163289

Epoch: 5| Step: 9
Training loss: 0.09591899812221527
Validation loss: 1.3763456729150587

Epoch: 5| Step: 10
Training loss: 0.027033185586333275
Validation loss: 1.3682106156503

Epoch: 661| Step: 0
Training loss: 0.05221251770853996
Validation loss: 1.3412628942920315

Epoch: 5| Step: 1
Training loss: 0.08464726060628891
Validation loss: 1.3690948524782736

Epoch: 5| Step: 2
Training loss: 0.10771916061639786
Validation loss: 1.35153781149977

Epoch: 5| Step: 3
Training loss: 0.06981821358203888
Validation loss: 1.348685315860215

Epoch: 5| Step: 4
Training loss: 0.05571049451828003
Validation loss: 1.327046278984316

Epoch: 5| Step: 5
Training loss: 0.09141398966312408
Validation loss: 1.3363768951867216

Epoch: 5| Step: 6
Training loss: 0.12495642900466919
Validation loss: 1.3311416032493755

Epoch: 5| Step: 7
Training loss: 0.10605990886688232
Validation loss: 1.3467392171582868

Epoch: 5| Step: 8
Training loss: 0.060550011694431305
Validation loss: 1.3798072056103778

Epoch: 5| Step: 9
Training loss: 0.0935259610414505
Validation loss: 1.3647620870221047

Epoch: 5| Step: 10
Training loss: 0.061977893114089966
Validation loss: 1.391010167137269

Epoch: 662| Step: 0
Training loss: 0.08569654077291489
Validation loss: 1.401181827309311

Epoch: 5| Step: 1
Training loss: 0.09544958919286728
Validation loss: 1.4164121112515848

Epoch: 5| Step: 2
Training loss: 0.11027487367391586
Validation loss: 1.4290183513395247

Epoch: 5| Step: 3
Training loss: 0.09940747916698456
Validation loss: 1.4020967803975588

Epoch: 5| Step: 4
Training loss: 0.09228596836328506
Validation loss: 1.4044612082101966

Epoch: 5| Step: 5
Training loss: 0.07993370294570923
Validation loss: 1.4157167198837444

Epoch: 5| Step: 6
Training loss: 0.08507243543863297
Validation loss: 1.3953011202555832

Epoch: 5| Step: 7
Training loss: 0.07703936100006104
Validation loss: 1.3733294779254543

Epoch: 5| Step: 8
Training loss: 0.040674012154340744
Validation loss: 1.388296446492595

Epoch: 5| Step: 9
Training loss: 0.042964059859514236
Validation loss: 1.3944514630943217

Epoch: 5| Step: 10
Training loss: 0.07081418484449387
Validation loss: 1.3834965126488799

Epoch: 663| Step: 0
Training loss: 0.09403102099895477
Validation loss: 1.3894178085429694

Epoch: 5| Step: 1
Training loss: 0.12019707262516022
Validation loss: 1.398070699425154

Epoch: 5| Step: 2
Training loss: 0.06215337663888931
Validation loss: 1.3682513698454826

Epoch: 5| Step: 3
Training loss: 0.0570489764213562
Validation loss: 1.3744317023984847

Epoch: 5| Step: 4
Training loss: 0.04923278093338013
Validation loss: 1.4014155172532605

Epoch: 5| Step: 5
Training loss: 0.07596983760595322
Validation loss: 1.376946081397354

Epoch: 5| Step: 6
Training loss: 0.056729160249233246
Validation loss: 1.3749908913848221

Epoch: 5| Step: 7
Training loss: 0.10839692503213882
Validation loss: 1.4101023084373885

Epoch: 5| Step: 8
Training loss: 0.07562093436717987
Validation loss: 1.4281956918777958

Epoch: 5| Step: 9
Training loss: 0.13531191647052765
Validation loss: 1.4127650555743967

Epoch: 5| Step: 10
Training loss: 0.059379830956459045
Validation loss: 1.3897304701548752

Epoch: 664| Step: 0
Training loss: 0.061430059373378754
Validation loss: 1.4054157067370672

Epoch: 5| Step: 1
Training loss: 0.0676688700914383
Validation loss: 1.3998390782263972

Epoch: 5| Step: 2
Training loss: 0.04887649416923523
Validation loss: 1.3883393336367864

Epoch: 5| Step: 3
Training loss: 0.062142420560121536
Validation loss: 1.3969745789804766

Epoch: 5| Step: 4
Training loss: 0.06604406982660294
Validation loss: 1.3654985902129964

Epoch: 5| Step: 5
Training loss: 0.05923948436975479
Validation loss: 1.3730992790191405

Epoch: 5| Step: 6
Training loss: 0.10107336938381195
Validation loss: 1.3628039648455958

Epoch: 5| Step: 7
Training loss: 0.057696498930454254
Validation loss: 1.3749885764173282

Epoch: 5| Step: 8
Training loss: 0.06942685693502426
Validation loss: 1.3593201867995723

Epoch: 5| Step: 9
Training loss: 0.11140730232000351
Validation loss: 1.371645685165159

Epoch: 5| Step: 10
Training loss: 0.06748656928539276
Validation loss: 1.36118830403974

Epoch: 665| Step: 0
Training loss: 0.10234687477350235
Validation loss: 1.378810216021794

Epoch: 5| Step: 1
Training loss: 0.10429131984710693
Validation loss: 1.3749861281405213

Epoch: 5| Step: 2
Training loss: 0.07090068608522415
Validation loss: 1.3965174869824482

Epoch: 5| Step: 3
Training loss: 0.0701955184340477
Validation loss: 1.4032758205167708

Epoch: 5| Step: 4
Training loss: 0.12234525382518768
Validation loss: 1.3808704473639046

Epoch: 5| Step: 5
Training loss: 0.05929812788963318
Validation loss: 1.3773843934459071

Epoch: 5| Step: 6
Training loss: 0.07709652185440063
Validation loss: 1.3626139830517512

Epoch: 5| Step: 7
Training loss: 0.08821277320384979
Validation loss: 1.3634999029098018

Epoch: 5| Step: 8
Training loss: 0.06462585180997849
Validation loss: 1.3595795721136115

Epoch: 5| Step: 9
Training loss: 0.05993150919675827
Validation loss: 1.32727688102312

Epoch: 5| Step: 10
Training loss: 0.06883985549211502
Validation loss: 1.3497671773356776

Epoch: 666| Step: 0
Training loss: 0.041678521782159805
Validation loss: 1.350128012318765

Epoch: 5| Step: 1
Training loss: 0.07925975322723389
Validation loss: 1.3801613456459456

Epoch: 5| Step: 2
Training loss: 0.06395120918750763
Validation loss: 1.3601820776539464

Epoch: 5| Step: 3
Training loss: 0.07924243062734604
Validation loss: 1.370314073818986

Epoch: 5| Step: 4
Training loss: 0.13343530893325806
Validation loss: 1.3899263438358103

Epoch: 5| Step: 5
Training loss: 0.0854484885931015
Validation loss: 1.379234467783282

Epoch: 5| Step: 6
Training loss: 0.07019440829753876
Validation loss: 1.378455533776232

Epoch: 5| Step: 7
Training loss: 0.057491231709718704
Validation loss: 1.3718688231642528

Epoch: 5| Step: 8
Training loss: 0.05625128746032715
Validation loss: 1.3768346719844367

Epoch: 5| Step: 9
Training loss: 0.0909537523984909
Validation loss: 1.378091041759778

Epoch: 5| Step: 10
Training loss: 0.12668704986572266
Validation loss: 1.3638916605262346

Epoch: 667| Step: 0
Training loss: 0.09207452833652496
Validation loss: 1.3667433338780557

Epoch: 5| Step: 1
Training loss: 0.09971289336681366
Validation loss: 1.3645138240629626

Epoch: 5| Step: 2
Training loss: 0.09698038548231125
Validation loss: 1.38255613593645

Epoch: 5| Step: 3
Training loss: 0.05972509831190109
Validation loss: 1.4078558875668434

Epoch: 5| Step: 4
Training loss: 0.08733361214399338
Validation loss: 1.3987489990008775

Epoch: 5| Step: 5
Training loss: 0.10116052627563477
Validation loss: 1.3880531198234969

Epoch: 5| Step: 6
Training loss: 0.05131151154637337
Validation loss: 1.4009048118386218

Epoch: 5| Step: 7
Training loss: 0.07971420884132385
Validation loss: 1.3823861601532146

Epoch: 5| Step: 8
Training loss: 0.0802425891160965
Validation loss: 1.3648230850055654

Epoch: 5| Step: 9
Training loss: 0.07366998493671417
Validation loss: 1.3708573169605707

Epoch: 5| Step: 10
Training loss: 0.09306085109710693
Validation loss: 1.3432832546131586

Epoch: 668| Step: 0
Training loss: 0.06861885637044907
Validation loss: 1.3540235937282603

Epoch: 5| Step: 1
Training loss: 0.10422195494174957
Validation loss: 1.3602067309041177

Epoch: 5| Step: 2
Training loss: 0.08299103379249573
Validation loss: 1.367848063027987

Epoch: 5| Step: 3
Training loss: 0.074641652405262
Validation loss: 1.3688855542931506

Epoch: 5| Step: 4
Training loss: 0.06696359813213348
Validation loss: 1.3827573169944107

Epoch: 5| Step: 5
Training loss: 0.07850424945354462
Validation loss: 1.4173938189783404

Epoch: 5| Step: 6
Training loss: 0.08538739383220673
Validation loss: 1.3906186466575952

Epoch: 5| Step: 7
Training loss: 0.11380161345005035
Validation loss: 1.426041603088379

Epoch: 5| Step: 8
Training loss: 0.11416295915842056
Validation loss: 1.4162343381553568

Epoch: 5| Step: 9
Training loss: 0.07359498739242554
Validation loss: 1.3990900683146652

Epoch: 5| Step: 10
Training loss: 0.09532465785741806
Validation loss: 1.4023973172710789

Epoch: 669| Step: 0
Training loss: 0.04346958547830582
Validation loss: 1.3971375034701439

Epoch: 5| Step: 1
Training loss: 0.08939101547002792
Validation loss: 1.4095730230372439

Epoch: 5| Step: 2
Training loss: 0.1142728328704834
Validation loss: 1.4149077733357747

Epoch: 5| Step: 3
Training loss: 0.06067880243062973
Validation loss: 1.4141511753682168

Epoch: 5| Step: 4
Training loss: 0.07080010324716568
Validation loss: 1.4155725227889193

Epoch: 5| Step: 5
Training loss: 0.09424758702516556
Validation loss: 1.4167110714861142

Epoch: 5| Step: 6
Training loss: 0.06772809475660324
Validation loss: 1.3844204884703442

Epoch: 5| Step: 7
Training loss: 0.08913547545671463
Validation loss: 1.3791442853148266

Epoch: 5| Step: 8
Training loss: 0.05475759506225586
Validation loss: 1.380853819590743

Epoch: 5| Step: 9
Training loss: 0.057811420410871506
Validation loss: 1.3974969669054913

Epoch: 5| Step: 10
Training loss: 0.05445197969675064
Validation loss: 1.40298455889507

Epoch: 670| Step: 0
Training loss: 0.05807178094983101
Validation loss: 1.4142836934776717

Epoch: 5| Step: 1
Training loss: 0.049960650503635406
Validation loss: 1.4121498946220643

Epoch: 5| Step: 2
Training loss: 0.06535820662975311
Validation loss: 1.3987570360142698

Epoch: 5| Step: 3
Training loss: 0.07411649078130722
Validation loss: 1.4190515305406304

Epoch: 5| Step: 4
Training loss: 0.07146356999874115
Validation loss: 1.4220987257137094

Epoch: 5| Step: 5
Training loss: 0.12809890508651733
Validation loss: 1.3820552287563201

Epoch: 5| Step: 6
Training loss: 0.11766455322504044
Validation loss: 1.3920668722480856

Epoch: 5| Step: 7
Training loss: 0.07589848339557648
Validation loss: 1.4035837855390323

Epoch: 5| Step: 8
Training loss: 0.06546439230442047
Validation loss: 1.3603454725716704

Epoch: 5| Step: 9
Training loss: 0.061904240399599075
Validation loss: 1.3438748486580387

Epoch: 5| Step: 10
Training loss: 0.05620540678501129
Validation loss: 1.3590970231640724

Epoch: 671| Step: 0
Training loss: 0.045537643134593964
Validation loss: 1.3712589125479422

Epoch: 5| Step: 1
Training loss: 0.09778101742267609
Validation loss: 1.3304034535602858

Epoch: 5| Step: 2
Training loss: 0.08145339787006378
Validation loss: 1.347936152770955

Epoch: 5| Step: 3
Training loss: 0.0507916584610939
Validation loss: 1.3378907813820788

Epoch: 5| Step: 4
Training loss: 0.07281176745891571
Validation loss: 1.351739095103356

Epoch: 5| Step: 5
Training loss: 0.052519261837005615
Validation loss: 1.3471769696922713

Epoch: 5| Step: 6
Training loss: 0.055039070546627045
Validation loss: 1.354670366933269

Epoch: 5| Step: 7
Training loss: 0.03800816088914871
Validation loss: 1.3837924118964904

Epoch: 5| Step: 8
Training loss: 0.054043252021074295
Validation loss: 1.376647783863929

Epoch: 5| Step: 9
Training loss: 0.05754967778921127
Validation loss: 1.3746968751312585

Epoch: 5| Step: 10
Training loss: 0.07836771011352539
Validation loss: 1.363970430948401

Epoch: 672| Step: 0
Training loss: 0.07618866860866547
Validation loss: 1.3782674189536803

Epoch: 5| Step: 1
Training loss: 0.0869249477982521
Validation loss: 1.3647393347114645

Epoch: 5| Step: 2
Training loss: 0.057815659791231155
Validation loss: 1.3897935549418132

Epoch: 5| Step: 3
Training loss: 0.09904592484235764
Validation loss: 1.368305588922193

Epoch: 5| Step: 4
Training loss: 0.03250229358673096
Validation loss: 1.3693374645325445

Epoch: 5| Step: 5
Training loss: 0.04071502760052681
Validation loss: 1.3892466919396513

Epoch: 5| Step: 6
Training loss: 0.0532340407371521
Validation loss: 1.3979276585322555

Epoch: 5| Step: 7
Training loss: 0.07093654572963715
Validation loss: 1.4064321344898594

Epoch: 5| Step: 8
Training loss: 0.07612224668264389
Validation loss: 1.402970620380935

Epoch: 5| Step: 9
Training loss: 0.09229966253042221
Validation loss: 1.3999990006928802

Epoch: 5| Step: 10
Training loss: 0.08502477407455444
Validation loss: 1.3923570212497507

Epoch: 673| Step: 0
Training loss: 0.06408558040857315
Validation loss: 1.3763737409345564

Epoch: 5| Step: 1
Training loss: 0.057624451816082
Validation loss: 1.3870331215602096

Epoch: 5| Step: 2
Training loss: 0.06257367879152298
Validation loss: 1.3477648804264684

Epoch: 5| Step: 3
Training loss: 0.06055653095245361
Validation loss: 1.356831164770229

Epoch: 5| Step: 4
Training loss: 0.08476737886667252
Validation loss: 1.371167335458981

Epoch: 5| Step: 5
Training loss: 0.0873713493347168
Validation loss: 1.3893543302371938

Epoch: 5| Step: 6
Training loss: 0.06314234435558319
Validation loss: 1.4008539902266635

Epoch: 5| Step: 7
Training loss: 0.07428592443466187
Validation loss: 1.4083416679854035

Epoch: 5| Step: 8
Training loss: 0.08370305597782135
Validation loss: 1.4536829981752621

Epoch: 5| Step: 9
Training loss: 0.09737976640462875
Validation loss: 1.4387769545278242

Epoch: 5| Step: 10
Training loss: 0.07324494421482086
Validation loss: 1.4156301406122023

Epoch: 674| Step: 0
Training loss: 0.06016696244478226
Validation loss: 1.43768871215082

Epoch: 5| Step: 1
Training loss: 0.0428570881485939
Validation loss: 1.3930168062128045

Epoch: 5| Step: 2
Training loss: 0.0700426772236824
Validation loss: 1.3806454135525612

Epoch: 5| Step: 3
Training loss: 0.05601527541875839
Validation loss: 1.3742392242595713

Epoch: 5| Step: 4
Training loss: 0.06658117473125458
Validation loss: 1.3564058202569202

Epoch: 5| Step: 5
Training loss: 0.11262460798025131
Validation loss: 1.3575214288567985

Epoch: 5| Step: 6
Training loss: 0.06135132163763046
Validation loss: 1.3591387893563958

Epoch: 5| Step: 7
Training loss: 0.08184345066547394
Validation loss: 1.3593119184176128

Epoch: 5| Step: 8
Training loss: 0.07249148190021515
Validation loss: 1.3894833351976128

Epoch: 5| Step: 9
Training loss: 0.12943042814731598
Validation loss: 1.4088779957063737

Epoch: 5| Step: 10
Training loss: 0.07681500166654587
Validation loss: 1.4294104588929044

Epoch: 675| Step: 0
Training loss: 0.0825577974319458
Validation loss: 1.4281417567242858

Epoch: 5| Step: 1
Training loss: 0.10505692660808563
Validation loss: 1.4496596179982668

Epoch: 5| Step: 2
Training loss: 0.09671305865049362
Validation loss: 1.4133780951141028

Epoch: 5| Step: 3
Training loss: 0.059692561626434326
Validation loss: 1.3821655793856549

Epoch: 5| Step: 4
Training loss: 0.07322782278060913
Validation loss: 1.3705707205239164

Epoch: 5| Step: 5
Training loss: 0.07307005673646927
Validation loss: 1.3617391932395198

Epoch: 5| Step: 6
Training loss: 0.06906389445066452
Validation loss: 1.3357821799093677

Epoch: 5| Step: 7
Training loss: 0.061657797545194626
Validation loss: 1.3368374186177407

Epoch: 5| Step: 8
Training loss: 0.059156984090805054
Validation loss: 1.3382082869929652

Epoch: 5| Step: 9
Training loss: 0.09880934655666351
Validation loss: 1.3512517342003443

Epoch: 5| Step: 10
Training loss: 0.08920196443796158
Validation loss: 1.3541000389283704

Epoch: 676| Step: 0
Training loss: 0.05474921315908432
Validation loss: 1.352846743599061

Epoch: 5| Step: 1
Training loss: 0.10028167814016342
Validation loss: 1.384952550293297

Epoch: 5| Step: 2
Training loss: 0.07014144957065582
Validation loss: 1.367914524129642

Epoch: 5| Step: 3
Training loss: 0.05814700201153755
Validation loss: 1.379205378152991

Epoch: 5| Step: 4
Training loss: 0.06507010757923126
Validation loss: 1.393158991490641

Epoch: 5| Step: 5
Training loss: 0.053838253021240234
Validation loss: 1.4370796449722782

Epoch: 5| Step: 6
Training loss: 0.09295172989368439
Validation loss: 1.4279374332838162

Epoch: 5| Step: 7
Training loss: 0.11611956357955933
Validation loss: 1.428160407209909

Epoch: 5| Step: 8
Training loss: 0.03930358961224556
Validation loss: 1.4132341255423844

Epoch: 5| Step: 9
Training loss: 0.07216602563858032
Validation loss: 1.3991124681247178

Epoch: 5| Step: 10
Training loss: 0.08577308058738708
Validation loss: 1.3815371951749247

Epoch: 677| Step: 0
Training loss: 0.08762878179550171
Validation loss: 1.371480385462443

Epoch: 5| Step: 1
Training loss: 0.09408308565616608
Validation loss: 1.3593390436582669

Epoch: 5| Step: 2
Training loss: 0.08948159962892532
Validation loss: 1.3398965417697866

Epoch: 5| Step: 3
Training loss: 0.11675238609313965
Validation loss: 1.3187524964732509

Epoch: 5| Step: 4
Training loss: 0.09969879686832428
Validation loss: 1.3344131272326234

Epoch: 5| Step: 5
Training loss: 0.05889946222305298
Validation loss: 1.3571501162744337

Epoch: 5| Step: 6
Training loss: 0.05380254238843918
Validation loss: 1.3570944980908466

Epoch: 5| Step: 7
Training loss: 0.03450788930058479
Validation loss: 1.3853818626813992

Epoch: 5| Step: 8
Training loss: 0.05196336656808853
Validation loss: 1.3981559174035185

Epoch: 5| Step: 9
Training loss: 0.09317249059677124
Validation loss: 1.4035865670891219

Epoch: 5| Step: 10
Training loss: 0.07584482431411743
Validation loss: 1.4442472675795197

Epoch: 678| Step: 0
Training loss: 0.11533675342798233
Validation loss: 1.3738030720782537

Epoch: 5| Step: 1
Training loss: 0.05851674824953079
Validation loss: 1.3777382809628722

Epoch: 5| Step: 2
Training loss: 0.05782750993967056
Validation loss: 1.3541255574072562

Epoch: 5| Step: 3
Training loss: 0.06743200868368149
Validation loss: 1.3430356928097305

Epoch: 5| Step: 4
Training loss: 0.09224369376897812
Validation loss: 1.3138281869631943

Epoch: 5| Step: 5
Training loss: 0.07106824219226837
Validation loss: 1.3516769293815858

Epoch: 5| Step: 6
Training loss: 0.10025068372488022
Validation loss: 1.3538936222753217

Epoch: 5| Step: 7
Training loss: 0.07747060060501099
Validation loss: 1.3652707146060081

Epoch: 5| Step: 8
Training loss: 0.06052533909678459
Validation loss: 1.3844910526788363

Epoch: 5| Step: 9
Training loss: 0.1046174019575119
Validation loss: 1.3848502488546475

Epoch: 5| Step: 10
Training loss: 0.09288083761930466
Validation loss: 1.3977040321596208

Epoch: 679| Step: 0
Training loss: 0.05853452533483505
Validation loss: 1.4194131000067598

Epoch: 5| Step: 1
Training loss: 0.052342839539051056
Validation loss: 1.4143180783076952

Epoch: 5| Step: 2
Training loss: 0.09259433299303055
Validation loss: 1.4135149191784602

Epoch: 5| Step: 3
Training loss: 0.06562332063913345
Validation loss: 1.4129665449101438

Epoch: 5| Step: 4
Training loss: 0.0871620923280716
Validation loss: 1.4082663007961806

Epoch: 5| Step: 5
Training loss: 0.06559388339519501
Validation loss: 1.3884282086485176

Epoch: 5| Step: 6
Training loss: 0.08344341814517975
Validation loss: 1.3818675177071684

Epoch: 5| Step: 7
Training loss: 0.08334968984127045
Validation loss: 1.368864687540198

Epoch: 5| Step: 8
Training loss: 0.07456637173891068
Validation loss: 1.3474970889347855

Epoch: 5| Step: 9
Training loss: 0.09636443108320236
Validation loss: 1.362356690950291

Epoch: 5| Step: 10
Training loss: 0.08845727890729904
Validation loss: 1.3786809213699833

Epoch: 680| Step: 0
Training loss: 0.12616968154907227
Validation loss: 1.3642982718765095

Epoch: 5| Step: 1
Training loss: 0.05033594369888306
Validation loss: 1.3858182827631633

Epoch: 5| Step: 2
Training loss: 0.06346671283245087
Validation loss: 1.368593785711514

Epoch: 5| Step: 3
Training loss: 0.04712005704641342
Validation loss: 1.3763534375416335

Epoch: 5| Step: 4
Training loss: 0.07910014688968658
Validation loss: 1.3650159617905975

Epoch: 5| Step: 5
Training loss: 0.049059461802244186
Validation loss: 1.3873728013807727

Epoch: 5| Step: 6
Training loss: 0.06825073063373566
Validation loss: 1.3680988248958383

Epoch: 5| Step: 7
Training loss: 0.10070357471704483
Validation loss: 1.3812042519610415

Epoch: 5| Step: 8
Training loss: 0.0720442682504654
Validation loss: 1.3138958433622956

Epoch: 5| Step: 9
Training loss: 0.0792369544506073
Validation loss: 1.3101825380838046

Epoch: 5| Step: 10
Training loss: 0.1359943002462387
Validation loss: 1.3125056246275544

Epoch: 681| Step: 0
Training loss: 0.20034527778625488
Validation loss: 1.3216114159553283

Epoch: 5| Step: 1
Training loss: 0.06840072572231293
Validation loss: 1.334462655487881

Epoch: 5| Step: 2
Training loss: 0.08250369131565094
Validation loss: 1.3536355559543898

Epoch: 5| Step: 3
Training loss: 0.07708920538425446
Validation loss: 1.3901572048023183

Epoch: 5| Step: 4
Training loss: 0.07764257490634918
Validation loss: 1.4180793339206326

Epoch: 5| Step: 5
Training loss: 0.07362765818834305
Validation loss: 1.4052542332679994

Epoch: 5| Step: 6
Training loss: 0.06957006454467773
Validation loss: 1.4271801338400891

Epoch: 5| Step: 7
Training loss: 0.10163847357034683
Validation loss: 1.4059813073886338

Epoch: 5| Step: 8
Training loss: 0.0906878337264061
Validation loss: 1.4284183184305828

Epoch: 5| Step: 9
Training loss: 0.09426015615463257
Validation loss: 1.4020056852730371

Epoch: 5| Step: 10
Training loss: 0.08023779839277267
Validation loss: 1.363113825039197

Epoch: 682| Step: 0
Training loss: 0.06513219326734543
Validation loss: 1.364870734112237

Epoch: 5| Step: 1
Training loss: 0.038925476372241974
Validation loss: 1.3102766390769713

Epoch: 5| Step: 2
Training loss: 0.09154759347438812
Validation loss: 1.3486561268888495

Epoch: 5| Step: 3
Training loss: 0.04480834677815437
Validation loss: 1.3375765508221042

Epoch: 5| Step: 4
Training loss: 0.09592260420322418
Validation loss: 1.3477297572679416

Epoch: 5| Step: 5
Training loss: 0.057432472705841064
Validation loss: 1.3151021298541818

Epoch: 5| Step: 6
Training loss: 0.0641925185918808
Validation loss: 1.3338624924741767

Epoch: 5| Step: 7
Training loss: 0.07695326954126358
Validation loss: 1.3281059085681874

Epoch: 5| Step: 8
Training loss: 0.09170691668987274
Validation loss: 1.3426069828771776

Epoch: 5| Step: 9
Training loss: 0.05887652188539505
Validation loss: 1.375944201664258

Epoch: 5| Step: 10
Training loss: 0.10093729943037033
Validation loss: 1.3768290717114684

Epoch: 683| Step: 0
Training loss: 0.09195084124803543
Validation loss: 1.366343027801924

Epoch: 5| Step: 1
Training loss: 0.06088568642735481
Validation loss: 1.3826573151414112

Epoch: 5| Step: 2
Training loss: 0.08982539176940918
Validation loss: 1.3856500682010446

Epoch: 5| Step: 3
Training loss: 0.060782335698604584
Validation loss: 1.3799504144217378

Epoch: 5| Step: 4
Training loss: 0.08397270739078522
Validation loss: 1.3941841651034612

Epoch: 5| Step: 5
Training loss: 0.08513981848955154
Validation loss: 1.3565290307485929

Epoch: 5| Step: 6
Training loss: 0.07500302791595459
Validation loss: 1.3799911852805846

Epoch: 5| Step: 7
Training loss: 0.07328031212091446
Validation loss: 1.3574253128420921

Epoch: 5| Step: 8
Training loss: 0.0820569172501564
Validation loss: 1.3084416158737675

Epoch: 5| Step: 9
Training loss: 0.07317135483026505
Validation loss: 1.3466536377065925

Epoch: 5| Step: 10
Training loss: 0.08913353085517883
Validation loss: 1.3382471210213118

Epoch: 684| Step: 0
Training loss: 0.059772610664367676
Validation loss: 1.3427397563893309

Epoch: 5| Step: 1
Training loss: 0.07297433912754059
Validation loss: 1.325613837088308

Epoch: 5| Step: 2
Training loss: 0.06275851279497147
Validation loss: 1.3251732318632063

Epoch: 5| Step: 3
Training loss: 0.08487924188375473
Validation loss: 1.352702102353496

Epoch: 5| Step: 4
Training loss: 0.058832891285419464
Validation loss: 1.363311630423351

Epoch: 5| Step: 5
Training loss: 0.09354852885007858
Validation loss: 1.3827670902334235

Epoch: 5| Step: 6
Training loss: 0.0680759847164154
Validation loss: 1.4135921296253

Epoch: 5| Step: 7
Training loss: 0.10183992236852646
Validation loss: 1.417036623083135

Epoch: 5| Step: 8
Training loss: 0.11549316346645355
Validation loss: 1.416560152525543

Epoch: 5| Step: 9
Training loss: 0.08896618336439133
Validation loss: 1.3816463947296143

Epoch: 5| Step: 10
Training loss: 0.08691719174385071
Validation loss: 1.3606938687703942

Epoch: 685| Step: 0
Training loss: 0.0760083943605423
Validation loss: 1.3518352623908751

Epoch: 5| Step: 1
Training loss: 0.09753487259149551
Validation loss: 1.3429982123836395

Epoch: 5| Step: 2
Training loss: 0.08398669213056564
Validation loss: 1.3598277664953662

Epoch: 5| Step: 3
Training loss: 0.0894353985786438
Validation loss: 1.381748866009456

Epoch: 5| Step: 4
Training loss: 0.11546645313501358
Validation loss: 1.3713226901587618

Epoch: 5| Step: 5
Training loss: 0.12657636404037476
Validation loss: 1.3253067706220893

Epoch: 5| Step: 6
Training loss: 0.1228625625371933
Validation loss: 1.3739359250632666

Epoch: 5| Step: 7
Training loss: 0.05837496370077133
Validation loss: 1.3714052618190806

Epoch: 5| Step: 8
Training loss: 0.07029145956039429
Validation loss: 1.3721972652660903

Epoch: 5| Step: 9
Training loss: 0.07318536937236786
Validation loss: 1.3805597110461163

Epoch: 5| Step: 10
Training loss: 0.10556929558515549
Validation loss: 1.3771801187146095

Epoch: 686| Step: 0
Training loss: 0.10366731882095337
Validation loss: 1.3901198499946184

Epoch: 5| Step: 1
Training loss: 0.11509307473897934
Validation loss: 1.3516291873429411

Epoch: 5| Step: 2
Training loss: 0.06310813128948212
Validation loss: 1.3344289205407585

Epoch: 5| Step: 3
Training loss: 0.04673904553055763
Validation loss: 1.354445606149653

Epoch: 5| Step: 4
Training loss: 0.07847845554351807
Validation loss: 1.3198753633806783

Epoch: 5| Step: 5
Training loss: 0.04934665560722351
Validation loss: 1.338849429161318

Epoch: 5| Step: 6
Training loss: 0.05027363821864128
Validation loss: 1.352395878043226

Epoch: 5| Step: 7
Training loss: 0.05644773319363594
Validation loss: 1.3352668003369403

Epoch: 5| Step: 8
Training loss: 0.06524650007486343
Validation loss: 1.3505754387506874

Epoch: 5| Step: 9
Training loss: 0.050435908138751984
Validation loss: 1.3397384946064284

Epoch: 5| Step: 10
Training loss: 0.11138825118541718
Validation loss: 1.3349621936839113

Epoch: 687| Step: 0
Training loss: 0.080746591091156
Validation loss: 1.3650208750078756

Epoch: 5| Step: 1
Training loss: 0.03515293449163437
Validation loss: 1.366698142020933

Epoch: 5| Step: 2
Training loss: 0.04747150093317032
Validation loss: 1.385478759324679

Epoch: 5| Step: 3
Training loss: 0.10053034126758575
Validation loss: 1.3717853529478914

Epoch: 5| Step: 4
Training loss: 0.07322683185338974
Validation loss: 1.4010432625329623

Epoch: 5| Step: 5
Training loss: 0.05844186618924141
Validation loss: 1.418527494194687

Epoch: 5| Step: 6
Training loss: 0.07336254417896271
Validation loss: 1.4236824897027784

Epoch: 5| Step: 7
Training loss: 0.07018742710351944
Validation loss: 1.414609553352479

Epoch: 5| Step: 8
Training loss: 0.07282256335020065
Validation loss: 1.4341942328278736

Epoch: 5| Step: 9
Training loss: 0.10487747192382812
Validation loss: 1.4110417058390956

Epoch: 5| Step: 10
Training loss: 0.06486289948225021
Validation loss: 1.3542587141836844

Epoch: 688| Step: 0
Training loss: 0.05682684853672981
Validation loss: 1.3660513649704635

Epoch: 5| Step: 1
Training loss: 0.1258101761341095
Validation loss: 1.3640917296050696

Epoch: 5| Step: 2
Training loss: 0.09853953868150711
Validation loss: 1.335693633684548

Epoch: 5| Step: 3
Training loss: 0.03460808843374252
Validation loss: 1.358128442559191

Epoch: 5| Step: 4
Training loss: 0.041763074696063995
Validation loss: 1.3638307631656688

Epoch: 5| Step: 5
Training loss: 0.11507543176412582
Validation loss: 1.416062831878662

Epoch: 5| Step: 6
Training loss: 0.135330468416214
Validation loss: 1.4348723760215185

Epoch: 5| Step: 7
Training loss: 0.06525731086730957
Validation loss: 1.436434336887893

Epoch: 5| Step: 8
Training loss: 0.11097858101129532
Validation loss: 1.449069590978725

Epoch: 5| Step: 9
Training loss: 0.07768317312002182
Validation loss: 1.4241331892628823

Epoch: 5| Step: 10
Training loss: 0.07889459282159805
Validation loss: 1.4098726658410923

Epoch: 689| Step: 0
Training loss: 0.07933992147445679
Validation loss: 1.3830154557381906

Epoch: 5| Step: 1
Training loss: 0.07153532654047012
Validation loss: 1.3866804133179367

Epoch: 5| Step: 2
Training loss: 0.050677645951509476
Validation loss: 1.3817777326030116

Epoch: 5| Step: 3
Training loss: 0.0811009481549263
Validation loss: 1.3750281000650058

Epoch: 5| Step: 4
Training loss: 0.08094710856676102
Validation loss: 1.371332710789096

Epoch: 5| Step: 5
Training loss: 0.09001808613538742
Validation loss: 1.3657357795264131

Epoch: 5| Step: 6
Training loss: 0.07367037981748581
Validation loss: 1.3692482479156987

Epoch: 5| Step: 7
Training loss: 0.07333262264728546
Validation loss: 1.4188560593512751

Epoch: 5| Step: 8
Training loss: 0.07802116125822067
Validation loss: 1.3915884084598993

Epoch: 5| Step: 9
Training loss: 0.07876075059175491
Validation loss: 1.3914583447158977

Epoch: 5| Step: 10
Training loss: 0.06168082356452942
Validation loss: 1.4049733864363803

Epoch: 690| Step: 0
Training loss: 0.050155915319919586
Validation loss: 1.3864819721509052

Epoch: 5| Step: 1
Training loss: 0.06538738310337067
Validation loss: 1.3946758316409202

Epoch: 5| Step: 2
Training loss: 0.05606650561094284
Validation loss: 1.3571542853950171

Epoch: 5| Step: 3
Training loss: 0.08346180617809296
Validation loss: 1.3448488289310085

Epoch: 5| Step: 4
Training loss: 0.05765075609087944
Validation loss: 1.3400870004007894

Epoch: 5| Step: 5
Training loss: 0.0809788852930069
Validation loss: 1.338992057308074

Epoch: 5| Step: 6
Training loss: 0.08830666542053223
Validation loss: 1.350438738381991

Epoch: 5| Step: 7
Training loss: 0.0738799199461937
Validation loss: 1.3462042244531776

Epoch: 5| Step: 8
Training loss: 0.08707447350025177
Validation loss: 1.352171746633386

Epoch: 5| Step: 9
Training loss: 0.09810023754835129
Validation loss: 1.3651280877410725

Epoch: 5| Step: 10
Training loss: 0.1251467764377594
Validation loss: 1.3775704304377239

Epoch: 691| Step: 0
Training loss: 0.10150183737277985
Validation loss: 1.4179436147853892

Epoch: 5| Step: 1
Training loss: 0.06867187470197678
Validation loss: 1.419337167534777

Epoch: 5| Step: 2
Training loss: 0.09712382405996323
Validation loss: 1.4466825531375023

Epoch: 5| Step: 3
Training loss: 0.07261820137500763
Validation loss: 1.450317415498918

Epoch: 5| Step: 4
Training loss: 0.05469299480319023
Validation loss: 1.455397476432144

Epoch: 5| Step: 5
Training loss: 0.0695359855890274
Validation loss: 1.4322782921534714

Epoch: 5| Step: 6
Training loss: 0.15176580846309662
Validation loss: 1.4389071669629825

Epoch: 5| Step: 7
Training loss: 0.054324597120285034
Validation loss: 1.4170560439427693

Epoch: 5| Step: 8
Training loss: 0.0952831357717514
Validation loss: 1.4052191485640824

Epoch: 5| Step: 9
Training loss: 0.10049259662628174
Validation loss: 1.3980305323036768

Epoch: 5| Step: 10
Training loss: 0.06250476092100143
Validation loss: 1.409110374348138

Epoch: 692| Step: 0
Training loss: 0.0642327070236206
Validation loss: 1.389057582424533

Epoch: 5| Step: 1
Training loss: 0.04157538712024689
Validation loss: 1.4070361442463373

Epoch: 5| Step: 2
Training loss: 0.04976140707731247
Validation loss: 1.389923527676572

Epoch: 5| Step: 3
Training loss: 0.07823292911052704
Validation loss: 1.3921339947690246

Epoch: 5| Step: 4
Training loss: 0.06157632917165756
Validation loss: 1.406615109853847

Epoch: 5| Step: 5
Training loss: 0.06949169933795929
Validation loss: 1.399383287275991

Epoch: 5| Step: 6
Training loss: 0.09117472171783447
Validation loss: 1.382781574803014

Epoch: 5| Step: 7
Training loss: 0.04761362820863724
Validation loss: 1.392084934378183

Epoch: 5| Step: 8
Training loss: 0.08451390266418457
Validation loss: 1.365423107659945

Epoch: 5| Step: 9
Training loss: 0.06090978533029556
Validation loss: 1.3595323184485077

Epoch: 5| Step: 10
Training loss: 0.09127119183540344
Validation loss: 1.379199722761749

Epoch: 693| Step: 0
Training loss: 0.08740781247615814
Validation loss: 1.401344189720769

Epoch: 5| Step: 1
Training loss: 0.06302099674940109
Validation loss: 1.3728407454747025

Epoch: 5| Step: 2
Training loss: 0.07580802589654922
Validation loss: 1.3782746625202957

Epoch: 5| Step: 3
Training loss: 0.06452883034944534
Validation loss: 1.3587644946190618

Epoch: 5| Step: 4
Training loss: 0.036994047462940216
Validation loss: 1.3614742960981143

Epoch: 5| Step: 5
Training loss: 0.05764346197247505
Validation loss: 1.3706283684699767

Epoch: 5| Step: 6
Training loss: 0.042771320790052414
Validation loss: 1.363598878665637

Epoch: 5| Step: 7
Training loss: 0.1014786809682846
Validation loss: 1.37149461366797

Epoch: 5| Step: 8
Training loss: 0.08804721385240555
Validation loss: 1.364235358853494

Epoch: 5| Step: 9
Training loss: 0.04822716861963272
Validation loss: 1.3721229427604265

Epoch: 5| Step: 10
Training loss: 0.050269074738025665
Validation loss: 1.367406334928287

Epoch: 694| Step: 0
Training loss: 0.05072760581970215
Validation loss: 1.3813401229919926

Epoch: 5| Step: 1
Training loss: 0.0616590678691864
Validation loss: 1.3806520867091354

Epoch: 5| Step: 2
Training loss: 0.037836361676454544
Validation loss: 1.399554721770748

Epoch: 5| Step: 3
Training loss: 0.0798298791050911
Validation loss: 1.354959753251845

Epoch: 5| Step: 4
Training loss: 0.0805015042424202
Validation loss: 1.3610729927657752

Epoch: 5| Step: 5
Training loss: 0.09510307013988495
Validation loss: 1.3496342743596723

Epoch: 5| Step: 6
Training loss: 0.045466650277376175
Validation loss: 1.3667629111197688

Epoch: 5| Step: 7
Training loss: 0.06140778213739395
Validation loss: 1.3639082729175527

Epoch: 5| Step: 8
Training loss: 0.05988398194313049
Validation loss: 1.337425019151421

Epoch: 5| Step: 9
Training loss: 0.055563636124134064
Validation loss: 1.3621569218174103

Epoch: 5| Step: 10
Training loss: 0.06243421137332916
Validation loss: 1.3609482678033973

Epoch: 695| Step: 0
Training loss: 0.04810359701514244
Validation loss: 1.3610317854471103

Epoch: 5| Step: 1
Training loss: 0.04351598769426346
Validation loss: 1.356236337333597

Epoch: 5| Step: 2
Training loss: 0.05058930069208145
Validation loss: 1.358435974326185

Epoch: 5| Step: 3
Training loss: 0.06196082383394241
Validation loss: 1.363330961555563

Epoch: 5| Step: 4
Training loss: 0.0850316509604454
Validation loss: 1.377563105475518

Epoch: 5| Step: 5
Training loss: 0.04396055266261101
Validation loss: 1.389383412176563

Epoch: 5| Step: 6
Training loss: 0.06173454597592354
Validation loss: 1.3623093904987458

Epoch: 5| Step: 7
Training loss: 0.048131220042705536
Validation loss: 1.3553801569887387

Epoch: 5| Step: 8
Training loss: 0.041307639330625534
Validation loss: 1.3616244203300887

Epoch: 5| Step: 9
Training loss: 0.06770944595336914
Validation loss: 1.3561073048140413

Epoch: 5| Step: 10
Training loss: 0.049394138157367706
Validation loss: 1.381920555586456

Epoch: 696| Step: 0
Training loss: 0.042436376214027405
Validation loss: 1.3765217309357018

Epoch: 5| Step: 1
Training loss: 0.060114048421382904
Validation loss: 1.3611424405087706

Epoch: 5| Step: 2
Training loss: 0.0764382854104042
Validation loss: 1.332673006160285

Epoch: 5| Step: 3
Training loss: 0.04584578052163124
Validation loss: 1.3003744822676464

Epoch: 5| Step: 4
Training loss: 0.06337253749370575
Validation loss: 1.3140098330795125

Epoch: 5| Step: 5
Training loss: 0.06677652895450592
Validation loss: 1.3138556749589982

Epoch: 5| Step: 6
Training loss: 0.06589112430810928
Validation loss: 1.3184737877179218

Epoch: 5| Step: 7
Training loss: 0.06343253701925278
Validation loss: 1.3245893870630572

Epoch: 5| Step: 8
Training loss: 0.08321480453014374
Validation loss: 1.3076082352669007

Epoch: 5| Step: 9
Training loss: 0.060654349625110626
Validation loss: 1.3116409112048406

Epoch: 5| Step: 10
Training loss: 0.04460898041725159
Validation loss: 1.3212667357537053

Epoch: 697| Step: 0
Training loss: 0.04774755239486694
Validation loss: 1.3559276532101374

Epoch: 5| Step: 1
Training loss: 0.07796762138605118
Validation loss: 1.3475188311710153

Epoch: 5| Step: 2
Training loss: 0.09782274812459946
Validation loss: 1.3447274636196833

Epoch: 5| Step: 3
Training loss: 0.07464122772216797
Validation loss: 1.353374856774525

Epoch: 5| Step: 4
Training loss: 0.06522005051374435
Validation loss: 1.3790294111415904

Epoch: 5| Step: 5
Training loss: 0.10301332175731659
Validation loss: 1.3712187120991368

Epoch: 5| Step: 6
Training loss: 0.04956318065524101
Validation loss: 1.35118878528636

Epoch: 5| Step: 7
Training loss: 0.03887180984020233
Validation loss: 1.3658581779849144

Epoch: 5| Step: 8
Training loss: 0.08438901603221893
Validation loss: 1.337529646453037

Epoch: 5| Step: 9
Training loss: 0.044434595853090286
Validation loss: 1.3387531516372517

Epoch: 5| Step: 10
Training loss: 0.051404666155576706
Validation loss: 1.3473008191713722

Epoch: 698| Step: 0
Training loss: 0.0586412250995636
Validation loss: 1.3512486847498084

Epoch: 5| Step: 1
Training loss: 0.07052788883447647
Validation loss: 1.3271533366172545

Epoch: 5| Step: 2
Training loss: 0.08636759221553802
Validation loss: 1.3502894255422777

Epoch: 5| Step: 3
Training loss: 0.025321537628769875
Validation loss: 1.3663647456835675

Epoch: 5| Step: 4
Training loss: 0.05610649660229683
Validation loss: 1.3746129928096649

Epoch: 5| Step: 5
Training loss: 0.06389011442661285
Validation loss: 1.389567090618995

Epoch: 5| Step: 6
Training loss: 0.0839439406991005
Validation loss: 1.3880666635369743

Epoch: 5| Step: 7
Training loss: 0.09853913635015488
Validation loss: 1.3978088607070267

Epoch: 5| Step: 8
Training loss: 0.04924832656979561
Validation loss: 1.4006769234134304

Epoch: 5| Step: 9
Training loss: 0.07271823287010193
Validation loss: 1.3898024700021232

Epoch: 5| Step: 10
Training loss: 0.10697052627801895
Validation loss: 1.387455310872806

Epoch: 699| Step: 0
Training loss: 0.06612076610326767
Validation loss: 1.3727274043585664

Epoch: 5| Step: 1
Training loss: 0.08301018178462982
Validation loss: 1.374112908558179

Epoch: 5| Step: 2
Training loss: 0.08360208570957184
Validation loss: 1.3683941261742705

Epoch: 5| Step: 3
Training loss: 0.07967354357242584
Validation loss: 1.3548926871309999

Epoch: 5| Step: 4
Training loss: 0.06326122581958771
Validation loss: 1.3714211435728176

Epoch: 5| Step: 5
Training loss: 0.077339306473732
Validation loss: 1.3801637875136508

Epoch: 5| Step: 6
Training loss: 0.14237600564956665
Validation loss: 1.416909299870973

Epoch: 5| Step: 7
Training loss: 0.12290024757385254
Validation loss: 1.4123042962884391

Epoch: 5| Step: 8
Training loss: 0.05728422477841377
Validation loss: 1.427819703214912

Epoch: 5| Step: 9
Training loss: 0.07112426310777664
Validation loss: 1.4146469741739252

Epoch: 5| Step: 10
Training loss: 0.061403561383485794
Validation loss: 1.4299779015202676

Epoch: 700| Step: 0
Training loss: 0.07419700920581818
Validation loss: 1.4367411444264073

Epoch: 5| Step: 1
Training loss: 0.10084055364131927
Validation loss: 1.45517187605622

Epoch: 5| Step: 2
Training loss: 0.05908868834376335
Validation loss: 1.4397896823062692

Epoch: 5| Step: 3
Training loss: 0.06841188669204712
Validation loss: 1.4015022849523893

Epoch: 5| Step: 4
Training loss: 0.05993220955133438
Validation loss: 1.3821498552958171

Epoch: 5| Step: 5
Training loss: 0.08634581416845322
Validation loss: 1.3470943871364798

Epoch: 5| Step: 6
Training loss: 0.10876651853322983
Validation loss: 1.336288453430258

Epoch: 5| Step: 7
Training loss: 0.06933513283729553
Validation loss: 1.3312720855077107

Epoch: 5| Step: 8
Training loss: 0.06951329112052917
Validation loss: 1.344863905701586

Epoch: 5| Step: 9
Training loss: 0.04252760484814644
Validation loss: 1.3558778814090195

Epoch: 5| Step: 10
Training loss: 0.047496672719717026
Validation loss: 1.3570276575703775

Testing loss: 2.1862331893708973
