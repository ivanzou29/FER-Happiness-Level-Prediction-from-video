Epoch: 1| Step: 0
Training loss: 5.258921146392822
Validation loss: 5.196122169494629

Epoch: 5| Step: 1
Training loss: 5.7633819580078125
Validation loss: 5.177215165989374

Epoch: 5| Step: 2
Training loss: 5.063099384307861
Validation loss: 5.158404883518014

Epoch: 5| Step: 3
Training loss: 4.582111358642578
Validation loss: 5.138625396195279

Epoch: 5| Step: 4
Training loss: 3.7801315784454346
Validation loss: 5.116305992167483

Epoch: 5| Step: 5
Training loss: 4.934484004974365
Validation loss: 5.09156314275598

Epoch: 5| Step: 6
Training loss: 4.587217330932617
Validation loss: 5.062825900252148

Epoch: 5| Step: 7
Training loss: 4.965332508087158
Validation loss: 5.0313552066844

Epoch: 5| Step: 8
Training loss: 4.886702537536621
Validation loss: 4.99463499746015

Epoch: 5| Step: 9
Training loss: 5.3183722496032715
Validation loss: 4.952361511927779

Epoch: 5| Step: 10
Training loss: 4.364981174468994
Validation loss: 4.9065788792025655

Epoch: 2| Step: 0
Training loss: 3.571240186691284
Validation loss: 4.857091739613523

Epoch: 5| Step: 1
Training loss: 3.8668105602264404
Validation loss: 4.804485228753859

Epoch: 5| Step: 2
Training loss: 3.5720629692077637
Validation loss: 4.749894419024067

Epoch: 5| Step: 3
Training loss: 5.253772258758545
Validation loss: 4.694796510922012

Epoch: 5| Step: 4
Training loss: 4.835258960723877
Validation loss: 4.636921144300891

Epoch: 5| Step: 5
Training loss: 3.9210846424102783
Validation loss: 4.576957959000782

Epoch: 5| Step: 6
Training loss: 3.4592113494873047
Validation loss: 4.516121223408689

Epoch: 5| Step: 7
Training loss: 4.428898334503174
Validation loss: 4.455507860388807

Epoch: 5| Step: 8
Training loss: 5.862242698669434
Validation loss: 4.398809489383493

Epoch: 5| Step: 9
Training loss: 4.238694190979004
Validation loss: 4.342172925190259

Epoch: 5| Step: 10
Training loss: 5.157328128814697
Validation loss: 4.2903914759236

Epoch: 3| Step: 0
Training loss: 4.157681465148926
Validation loss: 4.240706223313526

Epoch: 5| Step: 1
Training loss: 3.460463285446167
Validation loss: 4.19609453857586

Epoch: 5| Step: 2
Training loss: 4.821341037750244
Validation loss: 4.157276912402081

Epoch: 5| Step: 3
Training loss: 3.271141529083252
Validation loss: 4.120736537441131

Epoch: 5| Step: 4
Training loss: 3.4753546714782715
Validation loss: 4.08574269407539

Epoch: 5| Step: 5
Training loss: 5.076989650726318
Validation loss: 4.049624766072919

Epoch: 5| Step: 6
Training loss: 3.434919834136963
Validation loss: 4.013194822495984

Epoch: 5| Step: 7
Training loss: 4.374226093292236
Validation loss: 3.9818538183807046

Epoch: 5| Step: 8
Training loss: 4.030399322509766
Validation loss: 3.952472645749328

Epoch: 5| Step: 9
Training loss: 3.7259650230407715
Validation loss: 3.925244936379053

Epoch: 5| Step: 10
Training loss: 2.877504587173462
Validation loss: 3.8957545936748548

Epoch: 4| Step: 0
Training loss: 3.7538952827453613
Validation loss: 3.85803484916687

Epoch: 5| Step: 1
Training loss: 3.8287246227264404
Validation loss: 3.836187075543147

Epoch: 5| Step: 2
Training loss: 2.9029436111450195
Validation loss: 3.8173042266599593

Epoch: 5| Step: 3
Training loss: 3.4666314125061035
Validation loss: 3.7958746622967463

Epoch: 5| Step: 4
Training loss: 3.8337483406066895
Validation loss: 3.7769522154203026

Epoch: 5| Step: 5
Training loss: 2.9613614082336426
Validation loss: 3.7589196928085817

Epoch: 5| Step: 6
Training loss: 3.794764757156372
Validation loss: 3.7355279255938787

Epoch: 5| Step: 7
Training loss: 3.8478634357452393
Validation loss: 3.7081151931516585

Epoch: 5| Step: 8
Training loss: 3.9516594409942627
Validation loss: 3.6873409824986614

Epoch: 5| Step: 9
Training loss: 4.045458793640137
Validation loss: 3.6706069643779466

Epoch: 5| Step: 10
Training loss: 3.715998888015747
Validation loss: 3.6515507339149393

Epoch: 5| Step: 0
Training loss: 3.4594383239746094
Validation loss: 3.6342689555178405

Epoch: 5| Step: 1
Training loss: 4.026078224182129
Validation loss: 3.6138663471386

Epoch: 5| Step: 2
Training loss: 4.256816864013672
Validation loss: 3.5902469388900267

Epoch: 5| Step: 3
Training loss: 3.808884382247925
Validation loss: 3.5721370045856764

Epoch: 5| Step: 4
Training loss: 3.4508767127990723
Validation loss: 3.5551924679868963

Epoch: 5| Step: 5
Training loss: 2.796208143234253
Validation loss: 3.526550433968985

Epoch: 5| Step: 6
Training loss: 2.4924983978271484
Validation loss: 3.501211322763915

Epoch: 5| Step: 7
Training loss: 3.055048704147339
Validation loss: 3.4819378955389864

Epoch: 5| Step: 8
Training loss: 3.567279100418091
Validation loss: 3.4592152205846642

Epoch: 5| Step: 9
Training loss: 3.818347930908203
Validation loss: 3.4362640021949686

Epoch: 5| Step: 10
Training loss: 3.2872672080993652
Validation loss: 3.4122121436621553

Epoch: 6| Step: 0
Training loss: 2.636788845062256
Validation loss: 3.3949855219933296

Epoch: 5| Step: 1
Training loss: 3.1535801887512207
Validation loss: 3.3737274087885374

Epoch: 5| Step: 2
Training loss: 3.85424542427063
Validation loss: 3.362048800273608

Epoch: 5| Step: 3
Training loss: 2.7952158451080322
Validation loss: 3.349142418112806

Epoch: 5| Step: 4
Training loss: 4.729433536529541
Validation loss: 3.3268090422435472

Epoch: 5| Step: 5
Training loss: 3.2338759899139404
Validation loss: 3.312528997339228

Epoch: 5| Step: 6
Training loss: 2.600159168243408
Validation loss: 3.3033015907451673

Epoch: 5| Step: 7
Training loss: 3.1823697090148926
Validation loss: 3.284778587279781

Epoch: 5| Step: 8
Training loss: 3.2314624786376953
Validation loss: 3.2680972237740793

Epoch: 5| Step: 9
Training loss: 3.5619072914123535
Validation loss: 3.251793074351485

Epoch: 5| Step: 10
Training loss: 3.137787103652954
Validation loss: 3.243459483628632

Epoch: 7| Step: 0
Training loss: 2.9751195907592773
Validation loss: 3.240495656126289

Epoch: 5| Step: 1
Training loss: 3.0790016651153564
Validation loss: 3.248442788277903

Epoch: 5| Step: 2
Training loss: 3.0886173248291016
Validation loss: 3.187335624489733

Epoch: 5| Step: 3
Training loss: 2.688530445098877
Validation loss: 3.1833256829169487

Epoch: 5| Step: 4
Training loss: 3.548539638519287
Validation loss: 3.1789518453741588

Epoch: 5| Step: 5
Training loss: 2.1192073822021484
Validation loss: 3.1785432036205004

Epoch: 5| Step: 6
Training loss: 4.188170433044434
Validation loss: 3.173379562234366

Epoch: 5| Step: 7
Training loss: 3.2074756622314453
Validation loss: 3.1578556465846237

Epoch: 5| Step: 8
Training loss: 3.45548939704895
Validation loss: 3.1382238198352117

Epoch: 5| Step: 9
Training loss: 2.8488593101501465
Validation loss: 3.1286672776745212

Epoch: 5| Step: 10
Training loss: 3.7739343643188477
Validation loss: 3.1167202867487425

Epoch: 8| Step: 0
Training loss: 2.895453929901123
Validation loss: 3.100846787934662

Epoch: 5| Step: 1
Training loss: 3.2688231468200684
Validation loss: 3.0895376923263713

Epoch: 5| Step: 2
Training loss: 2.9583353996276855
Validation loss: 3.0767048225607923

Epoch: 5| Step: 3
Training loss: 2.3173699378967285
Validation loss: 3.068000724238734

Epoch: 5| Step: 4
Training loss: 3.9519925117492676
Validation loss: 3.0572720804522113

Epoch: 5| Step: 5
Training loss: 3.8028595447540283
Validation loss: 3.0423569269077753

Epoch: 5| Step: 6
Training loss: 2.455376386642456
Validation loss: 3.0307953203878095

Epoch: 5| Step: 7
Training loss: 3.558763027191162
Validation loss: 3.0211424648120837

Epoch: 5| Step: 8
Training loss: 2.6366710662841797
Validation loss: 3.006854065002934

Epoch: 5| Step: 9
Training loss: 3.128152370452881
Validation loss: 2.9964162713737896

Epoch: 5| Step: 10
Training loss: 3.0746326446533203
Validation loss: 2.9945820070082143

Epoch: 9| Step: 0
Training loss: 3.28818941116333
Validation loss: 2.9893269590152207

Epoch: 5| Step: 1
Training loss: 3.3526673316955566
Validation loss: 2.973936568024338

Epoch: 5| Step: 2
Training loss: 2.8616623878479004
Validation loss: 2.9740547518576346

Epoch: 5| Step: 3
Training loss: 2.9141926765441895
Validation loss: 3.001197309904201

Epoch: 5| Step: 4
Training loss: 2.8349530696868896
Validation loss: 2.977575432869696

Epoch: 5| Step: 5
Training loss: 3.029160261154175
Validation loss: 2.9776171638119604

Epoch: 5| Step: 6
Training loss: 2.3754541873931885
Validation loss: 2.9619500713963665

Epoch: 5| Step: 7
Training loss: 3.866598606109619
Validation loss: 2.953562641656527

Epoch: 5| Step: 8
Training loss: 2.872645139694214
Validation loss: 2.9582887772590882

Epoch: 5| Step: 9
Training loss: 3.0963988304138184
Validation loss: 2.960042348472021

Epoch: 5| Step: 10
Training loss: 3.0366575717926025
Validation loss: 2.9566821898183515

Epoch: 10| Step: 0
Training loss: 3.6227970123291016
Validation loss: 2.945437974827264

Epoch: 5| Step: 1
Training loss: 2.497546672821045
Validation loss: 2.9404993211069415

Epoch: 5| Step: 2
Training loss: 2.479719877243042
Validation loss: 2.936713951890187

Epoch: 5| Step: 3
Training loss: 3.2164244651794434
Validation loss: 2.9334286207793863

Epoch: 5| Step: 4
Training loss: 3.2893569469451904
Validation loss: 2.9288500226953977

Epoch: 5| Step: 5
Training loss: 2.996459484100342
Validation loss: 2.9251645277905207

Epoch: 5| Step: 6
Training loss: 3.0298678874969482
Validation loss: 2.922028890220068

Epoch: 5| Step: 7
Training loss: 3.4747347831726074
Validation loss: 2.916708210463165

Epoch: 5| Step: 8
Training loss: 3.2642905712127686
Validation loss: 2.941739205391176

Epoch: 5| Step: 9
Training loss: 2.64088773727417
Validation loss: 2.903416474660238

Epoch: 5| Step: 10
Training loss: 2.611795663833618
Validation loss: 2.9080744046036915

Epoch: 11| Step: 0
Training loss: 3.2789199352264404
Validation loss: 2.9068183232379217

Epoch: 5| Step: 1
Training loss: 3.120393753051758
Validation loss: 2.9094789002531316

Epoch: 5| Step: 2
Training loss: 3.1138837337493896
Validation loss: 2.9063903798339186

Epoch: 5| Step: 3
Training loss: 3.2478885650634766
Validation loss: 2.901215132846627

Epoch: 5| Step: 4
Training loss: 2.9729180335998535
Validation loss: 2.8957535451458347

Epoch: 5| Step: 5
Training loss: 3.059857130050659
Validation loss: 2.8912365872372865

Epoch: 5| Step: 6
Training loss: 2.1817312240600586
Validation loss: 2.883756850355415

Epoch: 5| Step: 7
Training loss: 3.3936848640441895
Validation loss: 2.8769995063863774

Epoch: 5| Step: 8
Training loss: 2.534899950027466
Validation loss: 2.873539455475346

Epoch: 5| Step: 9
Training loss: 3.002868175506592
Validation loss: 2.8705059841114986

Epoch: 5| Step: 10
Training loss: 3.0370607376098633
Validation loss: 2.868589416626961

Epoch: 12| Step: 0
Training loss: 2.4690234661102295
Validation loss: 2.863884607950846

Epoch: 5| Step: 1
Training loss: 3.0947418212890625
Validation loss: 2.862934445822111

Epoch: 5| Step: 2
Training loss: 3.3902626037597656
Validation loss: 2.891730821260842

Epoch: 5| Step: 3
Training loss: 1.9910974502563477
Validation loss: 2.8579536663588656

Epoch: 5| Step: 4
Training loss: 3.433445692062378
Validation loss: 2.8554175925511185

Epoch: 5| Step: 5
Training loss: 2.854534864425659
Validation loss: 2.853233778348533

Epoch: 5| Step: 6
Training loss: 3.6066524982452393
Validation loss: 2.854121485064107

Epoch: 5| Step: 7
Training loss: 2.9487857818603516
Validation loss: 2.853993251759519

Epoch: 5| Step: 8
Training loss: 3.483065128326416
Validation loss: 2.8546192466571765

Epoch: 5| Step: 9
Training loss: 3.3377158641815186
Validation loss: 2.8522234552650043

Epoch: 5| Step: 10
Training loss: 1.9203120470046997
Validation loss: 2.8548738546268915

Epoch: 13| Step: 0
Training loss: 3.26546049118042
Validation loss: 2.8459973899267053

Epoch: 5| Step: 1
Training loss: 3.239656925201416
Validation loss: 2.8411588873914493

Epoch: 5| Step: 2
Training loss: 3.521570920944214
Validation loss: 2.851032946699409

Epoch: 5| Step: 3
Training loss: 2.4127299785614014
Validation loss: 2.8439665302153556

Epoch: 5| Step: 4
Training loss: 3.5153281688690186
Validation loss: 2.8341767454660065

Epoch: 5| Step: 5
Training loss: 1.9401977062225342
Validation loss: 2.8316391950012534

Epoch: 5| Step: 6
Training loss: 3.0959107875823975
Validation loss: 2.8286831122572704

Epoch: 5| Step: 7
Training loss: 3.044011116027832
Validation loss: 2.8272158638123543

Epoch: 5| Step: 8
Training loss: 2.7169413566589355
Validation loss: 2.8258586519507953

Epoch: 5| Step: 9
Training loss: 2.411428689956665
Validation loss: 2.8265046534999723

Epoch: 5| Step: 10
Training loss: 3.399484395980835
Validation loss: 2.8173342007462696

Epoch: 14| Step: 0
Training loss: 3.4312636852264404
Validation loss: 2.8134328883181334

Epoch: 5| Step: 1
Training loss: 3.016960382461548
Validation loss: 2.8106668738908667

Epoch: 5| Step: 2
Training loss: 3.245032548904419
Validation loss: 2.808910426273141

Epoch: 5| Step: 3
Training loss: 3.076770305633545
Validation loss: 2.8083830905216995

Epoch: 5| Step: 4
Training loss: 3.72660493850708
Validation loss: 2.8044339867048365

Epoch: 5| Step: 5
Training loss: 2.788057327270508
Validation loss: 2.800712618776547

Epoch: 5| Step: 6
Training loss: 2.8739101886749268
Validation loss: 2.7987758292946765

Epoch: 5| Step: 7
Training loss: 2.5858030319213867
Validation loss: 2.79974881551599

Epoch: 5| Step: 8
Training loss: 2.4025301933288574
Validation loss: 2.8014309278098484

Epoch: 5| Step: 9
Training loss: 2.640000581741333
Validation loss: 2.7996237149802585

Epoch: 5| Step: 10
Training loss: 2.4519824981689453
Validation loss: 2.803572298378073

Epoch: 15| Step: 0
Training loss: 2.503798484802246
Validation loss: 2.797487776766541

Epoch: 5| Step: 1
Training loss: 2.603912353515625
Validation loss: 2.798338085092524

Epoch: 5| Step: 2
Training loss: 3.1717960834503174
Validation loss: 2.8056336525947816

Epoch: 5| Step: 3
Training loss: 2.76608943939209
Validation loss: 2.8112564548369376

Epoch: 5| Step: 4
Training loss: 2.8615448474884033
Validation loss: 2.809360642586985

Epoch: 5| Step: 5
Training loss: 3.024088144302368
Validation loss: 2.80156688023639

Epoch: 5| Step: 6
Training loss: 3.825573444366455
Validation loss: 2.7932976753480974

Epoch: 5| Step: 7
Training loss: 2.442474603652954
Validation loss: 2.79984587495045

Epoch: 5| Step: 8
Training loss: 2.4755606651306152
Validation loss: 2.8118138954203618

Epoch: 5| Step: 9
Training loss: 3.3592967987060547
Validation loss: 2.8204644367259037

Epoch: 5| Step: 10
Training loss: 3.286663055419922
Validation loss: 2.8169152685391006

Epoch: 16| Step: 0
Training loss: 2.218503475189209
Validation loss: 2.8023531847102667

Epoch: 5| Step: 1
Training loss: 3.188716411590576
Validation loss: 2.7917731602986655

Epoch: 5| Step: 2
Training loss: 2.1283278465270996
Validation loss: 2.789183424365136

Epoch: 5| Step: 3
Training loss: 2.5254859924316406
Validation loss: 2.791248475351641

Epoch: 5| Step: 4
Training loss: 3.4890480041503906
Validation loss: 2.799119862177039

Epoch: 5| Step: 5
Training loss: 2.9081227779388428
Validation loss: 2.812219960715181

Epoch: 5| Step: 6
Training loss: 2.724794626235962
Validation loss: 2.820063288493823

Epoch: 5| Step: 7
Training loss: 3.3978867530822754
Validation loss: 2.7975526266200568

Epoch: 5| Step: 8
Training loss: 2.9530043601989746
Validation loss: 2.780808356500441

Epoch: 5| Step: 9
Training loss: 3.209951877593994
Validation loss: 2.776665905470489

Epoch: 5| Step: 10
Training loss: 3.5583856105804443
Validation loss: 2.7797066883374284

Epoch: 17| Step: 0
Training loss: 3.583742618560791
Validation loss: 2.785964091618856

Epoch: 5| Step: 1
Training loss: 2.900182008743286
Validation loss: 2.7808598856772146

Epoch: 5| Step: 2
Training loss: 3.176525592803955
Validation loss: 2.775984328280213

Epoch: 5| Step: 3
Training loss: 2.5220041275024414
Validation loss: 2.7722322120461413

Epoch: 5| Step: 4
Training loss: 2.333588123321533
Validation loss: 2.7716515192421536

Epoch: 5| Step: 5
Training loss: 2.2810072898864746
Validation loss: 2.766749384582684

Epoch: 5| Step: 6
Training loss: 3.0730323791503906
Validation loss: 2.770250576798634

Epoch: 5| Step: 7
Training loss: 2.8709521293640137
Validation loss: 2.7646957353879045

Epoch: 5| Step: 8
Training loss: 3.5595977306365967
Validation loss: 2.770173085633145

Epoch: 5| Step: 9
Training loss: 3.3147056102752686
Validation loss: 2.772569569208289

Epoch: 5| Step: 10
Training loss: 2.361811637878418
Validation loss: 2.821172768069852

Epoch: 18| Step: 0
Training loss: 3.46622896194458
Validation loss: 2.820095134037797

Epoch: 5| Step: 1
Training loss: 3.233442783355713
Validation loss: 2.765994320633591

Epoch: 5| Step: 2
Training loss: 2.7685604095458984
Validation loss: 2.7628367024083293

Epoch: 5| Step: 3
Training loss: 2.5418362617492676
Validation loss: 2.76928210771212

Epoch: 5| Step: 4
Training loss: 3.1120147705078125
Validation loss: 2.7717090934835453

Epoch: 5| Step: 5
Training loss: 2.585033655166626
Validation loss: 2.7782000469905075

Epoch: 5| Step: 6
Training loss: 2.9731976985931396
Validation loss: 2.7782766460090556

Epoch: 5| Step: 7
Training loss: 2.997847318649292
Validation loss: 2.779221091219174

Epoch: 5| Step: 8
Training loss: 3.376218795776367
Validation loss: 2.774772946552564

Epoch: 5| Step: 9
Training loss: 2.4495606422424316
Validation loss: 2.768968656498899

Epoch: 5| Step: 10
Training loss: 2.51403546333313
Validation loss: 2.7671510045246412

Epoch: 19| Step: 0
Training loss: 3.279160737991333
Validation loss: 2.7668920768204557

Epoch: 5| Step: 1
Training loss: 2.7615854740142822
Validation loss: 2.763714903144426

Epoch: 5| Step: 2
Training loss: 2.858313798904419
Validation loss: 2.7623407661273913

Epoch: 5| Step: 3
Training loss: 2.0544469356536865
Validation loss: 2.7858692984427176

Epoch: 5| Step: 4
Training loss: 2.533583879470825
Validation loss: 2.7863966572669243

Epoch: 5| Step: 5
Training loss: 2.9323041439056396
Validation loss: 2.754991526244789

Epoch: 5| Step: 6
Training loss: 3.1516623497009277
Validation loss: 2.7517370664945213

Epoch: 5| Step: 7
Training loss: 3.5421929359436035
Validation loss: 2.7566662193626486

Epoch: 5| Step: 8
Training loss: 2.740804433822632
Validation loss: 2.7623009784247285

Epoch: 5| Step: 9
Training loss: 3.1773574352264404
Validation loss: 2.755865973810996

Epoch: 5| Step: 10
Training loss: 2.9900286197662354
Validation loss: 2.748957536553824

Epoch: 20| Step: 0
Training loss: 3.2689690589904785
Validation loss: 2.7469460630929596

Epoch: 5| Step: 1
Training loss: 2.839794397354126
Validation loss: 2.7507754269466607

Epoch: 5| Step: 2
Training loss: 2.2234950065612793
Validation loss: 2.744729003598613

Epoch: 5| Step: 3
Training loss: 2.97212553024292
Validation loss: 2.7437607908761628

Epoch: 5| Step: 4
Training loss: 3.0274384021759033
Validation loss: 2.7404617032697125

Epoch: 5| Step: 5
Training loss: 2.3661279678344727
Validation loss: 2.738845940559141

Epoch: 5| Step: 6
Training loss: 2.8680248260498047
Validation loss: 2.7363726221105105

Epoch: 5| Step: 7
Training loss: 2.621431827545166
Validation loss: 2.7344434081867175

Epoch: 5| Step: 8
Training loss: 3.520153760910034
Validation loss: 2.7324331370733117

Epoch: 5| Step: 9
Training loss: 3.3368842601776123
Validation loss: 2.7319169147040254

Epoch: 5| Step: 10
Training loss: 2.7962629795074463
Validation loss: 2.732563118780813

Epoch: 21| Step: 0
Training loss: 2.2531991004943848
Validation loss: 2.7317014560904553

Epoch: 5| Step: 1
Training loss: 2.949162006378174
Validation loss: 2.7299110248524654

Epoch: 5| Step: 2
Training loss: 3.280613422393799
Validation loss: 2.7318345885122977

Epoch: 5| Step: 3
Training loss: 2.4415156841278076
Validation loss: 2.7294629953240834

Epoch: 5| Step: 4
Training loss: 3.7064433097839355
Validation loss: 2.7269520246854393

Epoch: 5| Step: 5
Training loss: 3.0035133361816406
Validation loss: 2.7286041987839567

Epoch: 5| Step: 6
Training loss: 2.4795782566070557
Validation loss: 2.724502573731125

Epoch: 5| Step: 7
Training loss: 3.0141282081604004
Validation loss: 2.72108615854735

Epoch: 5| Step: 8
Training loss: 3.175842761993408
Validation loss: 2.722326860632948

Epoch: 5| Step: 9
Training loss: 2.899566173553467
Validation loss: 2.7219379204575733

Epoch: 5| Step: 10
Training loss: 2.4579274654388428
Validation loss: 2.7224423603344987

Epoch: 22| Step: 0
Training loss: 3.076035499572754
Validation loss: 2.7218159193633706

Epoch: 5| Step: 1
Training loss: 2.971623182296753
Validation loss: 2.714504877726237

Epoch: 5| Step: 2
Training loss: 2.8545844554901123
Validation loss: 2.708009119956724

Epoch: 5| Step: 3
Training loss: 3.500710964202881
Validation loss: 2.7067572429615963

Epoch: 5| Step: 4
Training loss: 2.836249828338623
Validation loss: 2.7036235896489953

Epoch: 5| Step: 5
Training loss: 3.0195038318634033
Validation loss: 2.7053587821222123

Epoch: 5| Step: 6
Training loss: 3.1718387603759766
Validation loss: 2.697560264218238

Epoch: 5| Step: 7
Training loss: 3.1094698905944824
Validation loss: 2.700958223753078

Epoch: 5| Step: 8
Training loss: 2.3122239112854004
Validation loss: 2.698088727971559

Epoch: 5| Step: 9
Training loss: 1.9236853122711182
Validation loss: 2.6984148179331133

Epoch: 5| Step: 10
Training loss: 2.7414658069610596
Validation loss: 2.700241593904393

Epoch: 23| Step: 0
Training loss: 2.784050703048706
Validation loss: 2.696448072310417

Epoch: 5| Step: 1
Training loss: 2.849052906036377
Validation loss: 2.6974198151660222

Epoch: 5| Step: 2
Training loss: 3.348820209503174
Validation loss: 2.699373314457555

Epoch: 5| Step: 3
Training loss: 2.524779796600342
Validation loss: 2.6997833200680312

Epoch: 5| Step: 4
Training loss: 2.784942150115967
Validation loss: 2.6972404756853656

Epoch: 5| Step: 5
Training loss: 2.4464290142059326
Validation loss: 2.690481516622728

Epoch: 5| Step: 6
Training loss: 2.715294361114502
Validation loss: 2.6952212907934703

Epoch: 5| Step: 7
Training loss: 2.917762517929077
Validation loss: 2.707480917694748

Epoch: 5| Step: 8
Training loss: 3.6171486377716064
Validation loss: 2.771281083424886

Epoch: 5| Step: 9
Training loss: 2.834481716156006
Validation loss: 2.6996064801369943

Epoch: 5| Step: 10
Training loss: 2.740924119949341
Validation loss: 2.689495030269828

Epoch: 24| Step: 0
Training loss: 2.7999846935272217
Validation loss: 2.694448724869759

Epoch: 5| Step: 1
Training loss: 3.9592278003692627
Validation loss: 2.69926691568026

Epoch: 5| Step: 2
Training loss: 2.7012438774108887
Validation loss: 2.7018279260204685

Epoch: 5| Step: 3
Training loss: 2.4499518871307373
Validation loss: 2.7009330667475218

Epoch: 5| Step: 4
Training loss: 3.6414904594421387
Validation loss: 2.6964024292525424

Epoch: 5| Step: 5
Training loss: 2.7336840629577637
Validation loss: 2.692943834489392

Epoch: 5| Step: 6
Training loss: 2.991997003555298
Validation loss: 2.6921217364649617

Epoch: 5| Step: 7
Training loss: 2.3237390518188477
Validation loss: 2.6993132945029967

Epoch: 5| Step: 8
Training loss: 2.230611801147461
Validation loss: 2.704959407929451

Epoch: 5| Step: 9
Training loss: 2.9871811866760254
Validation loss: 2.726841729174378

Epoch: 5| Step: 10
Training loss: 2.614760398864746
Validation loss: 2.763427634393015

Epoch: 25| Step: 0
Training loss: 3.7675461769104004
Validation loss: 2.74805252270032

Epoch: 5| Step: 1
Training loss: 3.05873441696167
Validation loss: 2.7170871252654702

Epoch: 5| Step: 2
Training loss: 2.919013500213623
Validation loss: 2.6924058339929067

Epoch: 5| Step: 3
Training loss: 2.70576810836792
Validation loss: 2.691681295312861

Epoch: 5| Step: 4
Training loss: 2.8619773387908936
Validation loss: 2.6988420460813787

Epoch: 5| Step: 5
Training loss: 2.6789209842681885
Validation loss: 2.7011077634749876

Epoch: 5| Step: 6
Training loss: 2.722277879714966
Validation loss: 2.7138609168350056

Epoch: 5| Step: 7
Training loss: 2.5964622497558594
Validation loss: 2.7255821433118594

Epoch: 5| Step: 8
Training loss: 2.9287898540496826
Validation loss: 2.7187909515955115

Epoch: 5| Step: 9
Training loss: 3.163931131362915
Validation loss: 2.6982442717398367

Epoch: 5| Step: 10
Training loss: 2.050295352935791
Validation loss: 2.6943104523484425

Epoch: 26| Step: 0
Training loss: 2.8311591148376465
Validation loss: 2.7109903238152944

Epoch: 5| Step: 1
Training loss: 3.017930030822754
Validation loss: 2.7036777363028577

Epoch: 5| Step: 2
Training loss: 2.596874952316284
Validation loss: 2.6980894919364684

Epoch: 5| Step: 3
Training loss: 3.323763608932495
Validation loss: 2.690470626277308

Epoch: 5| Step: 4
Training loss: 3.636223554611206
Validation loss: 2.690499608234693

Epoch: 5| Step: 5
Training loss: 2.448164224624634
Validation loss: 2.6814655847446893

Epoch: 5| Step: 6
Training loss: 2.795124053955078
Validation loss: 2.6785667147687686

Epoch: 5| Step: 7
Training loss: 2.4825310707092285
Validation loss: 2.6738466729399977

Epoch: 5| Step: 8
Training loss: 2.83734130859375
Validation loss: 2.6696971001163607

Epoch: 5| Step: 9
Training loss: 2.3866634368896484
Validation loss: 2.6813865271947717

Epoch: 5| Step: 10
Training loss: 3.0142295360565186
Validation loss: 2.6846585222469863

Epoch: 27| Step: 0
Training loss: 2.2109575271606445
Validation loss: 2.678386434431999

Epoch: 5| Step: 1
Training loss: 3.0001327991485596
Validation loss: 2.6768136460294008

Epoch: 5| Step: 2
Training loss: 2.9725794792175293
Validation loss: 2.677082976987285

Epoch: 5| Step: 3
Training loss: 3.543569564819336
Validation loss: 2.685685585903865

Epoch: 5| Step: 4
Training loss: 2.73451828956604
Validation loss: 2.6701261817768054

Epoch: 5| Step: 5
Training loss: 2.349099636077881
Validation loss: 2.675510729512861

Epoch: 5| Step: 6
Training loss: 2.3820037841796875
Validation loss: 2.6999913979602117

Epoch: 5| Step: 7
Training loss: 2.5918128490448
Validation loss: 2.6867940195145144

Epoch: 5| Step: 8
Training loss: 3.5398764610290527
Validation loss: 2.688014366293466

Epoch: 5| Step: 9
Training loss: 3.5630059242248535
Validation loss: 2.685654006978517

Epoch: 5| Step: 10
Training loss: 2.126516819000244
Validation loss: 2.6638374995159846

Epoch: 28| Step: 0
Training loss: 2.920746326446533
Validation loss: 2.655361326791907

Epoch: 5| Step: 1
Training loss: 2.721801996231079
Validation loss: 2.660727157387682

Epoch: 5| Step: 2
Training loss: 2.9806389808654785
Validation loss: 2.667688910679151

Epoch: 5| Step: 3
Training loss: 3.328213930130005
Validation loss: 2.662732885729882

Epoch: 5| Step: 4
Training loss: 3.0997912883758545
Validation loss: 2.658903726967432

Epoch: 5| Step: 5
Training loss: 2.489351987838745
Validation loss: 2.669429163778982

Epoch: 5| Step: 6
Training loss: 2.5002925395965576
Validation loss: 2.6705520947774253

Epoch: 5| Step: 7
Training loss: 3.0742201805114746
Validation loss: 2.656615346990606

Epoch: 5| Step: 8
Training loss: 2.5861518383026123
Validation loss: 2.667731679895873

Epoch: 5| Step: 9
Training loss: 2.520082950592041
Validation loss: 2.703256645510274

Epoch: 5| Step: 10
Training loss: 3.0520689487457275
Validation loss: 2.7214367158951296

Epoch: 29| Step: 0
Training loss: 3.205139636993408
Validation loss: 2.7290777160275366

Epoch: 5| Step: 1
Training loss: 3.1450068950653076
Validation loss: 2.7397703355358494

Epoch: 5| Step: 2
Training loss: 3.1426148414611816
Validation loss: 2.6744753545330417

Epoch: 5| Step: 3
Training loss: 2.645754337310791
Validation loss: 2.660338176194058

Epoch: 5| Step: 4
Training loss: 2.883115768432617
Validation loss: 2.6780013063902497

Epoch: 5| Step: 5
Training loss: 2.4059970378875732
Validation loss: 2.7102789494299118

Epoch: 5| Step: 6
Training loss: 2.779094696044922
Validation loss: 2.7362570275542555

Epoch: 5| Step: 7
Training loss: 3.163994312286377
Validation loss: 2.7259383509235997

Epoch: 5| Step: 8
Training loss: 2.2953975200653076
Validation loss: 2.686207668755644

Epoch: 5| Step: 9
Training loss: 2.7379372119903564
Validation loss: 2.655762962115708

Epoch: 5| Step: 10
Training loss: 3.2836735248565674
Validation loss: 2.6492141805669314

Epoch: 30| Step: 0
Training loss: 2.4955966472625732
Validation loss: 2.6948430384359052

Epoch: 5| Step: 1
Training loss: 3.1478431224823
Validation loss: 2.689639424764982

Epoch: 5| Step: 2
Training loss: 3.505358934402466
Validation loss: 2.685787618801158

Epoch: 5| Step: 3
Training loss: 2.6901004314422607
Validation loss: 2.664424645003452

Epoch: 5| Step: 4
Training loss: 2.3029632568359375
Validation loss: 2.64938953615004

Epoch: 5| Step: 5
Training loss: 3.90594482421875
Validation loss: 2.642087359582224

Epoch: 5| Step: 6
Training loss: 2.611497402191162
Validation loss: 2.643144153779553

Epoch: 5| Step: 7
Training loss: 2.502737522125244
Validation loss: 2.6409090590733353

Epoch: 5| Step: 8
Training loss: 2.1882262229919434
Validation loss: 2.641345565037061

Epoch: 5| Step: 9
Training loss: 2.8360023498535156
Validation loss: 2.6471236187924623

Epoch: 5| Step: 10
Training loss: 2.727546453475952
Validation loss: 2.6693881557833765

Epoch: 31| Step: 0
Training loss: 2.956587314605713
Validation loss: 2.674391895212153

Epoch: 5| Step: 1
Training loss: 2.037943124771118
Validation loss: 2.6845584248983734

Epoch: 5| Step: 2
Training loss: 2.5630345344543457
Validation loss: 2.7123270906427854

Epoch: 5| Step: 3
Training loss: 3.1429600715637207
Validation loss: 2.753012744329309

Epoch: 5| Step: 4
Training loss: 2.8683087825775146
Validation loss: 2.715163625696654

Epoch: 5| Step: 5
Training loss: 3.058567523956299
Validation loss: 2.6497365659283054

Epoch: 5| Step: 6
Training loss: 3.548938035964966
Validation loss: 2.6348154006465787

Epoch: 5| Step: 7
Training loss: 2.723284959793091
Validation loss: 2.648342811933128

Epoch: 5| Step: 8
Training loss: 2.8952996730804443
Validation loss: 2.674626014565909

Epoch: 5| Step: 9
Training loss: 2.7236340045928955
Validation loss: 2.712443100508823

Epoch: 5| Step: 10
Training loss: 2.491516351699829
Validation loss: 2.7170638217720935

Epoch: 32| Step: 0
Training loss: 2.348794937133789
Validation loss: 2.7033600499553065

Epoch: 5| Step: 1
Training loss: 2.4528496265411377
Validation loss: 2.675899813252111

Epoch: 5| Step: 2
Training loss: 2.7228891849517822
Validation loss: 2.6667968765381844

Epoch: 5| Step: 3
Training loss: 2.747344970703125
Validation loss: 2.6524651768387004

Epoch: 5| Step: 4
Training loss: 2.6443862915039062
Validation loss: 2.6517090720515095

Epoch: 5| Step: 5
Training loss: 4.165148735046387
Validation loss: 2.6498524296668267

Epoch: 5| Step: 6
Training loss: 1.9610803127288818
Validation loss: 2.647292278146231

Epoch: 5| Step: 7
Training loss: 3.332789659500122
Validation loss: 2.6639164006838234

Epoch: 5| Step: 8
Training loss: 2.5575673580169678
Validation loss: 2.6444548176180933

Epoch: 5| Step: 9
Training loss: 2.7547430992126465
Validation loss: 2.617596482717863

Epoch: 5| Step: 10
Training loss: 3.381230115890503
Validation loss: 2.599729173926897

Epoch: 33| Step: 0
Training loss: 2.7618019580841064
Validation loss: 2.5862807355901247

Epoch: 5| Step: 1
Training loss: 2.7335832118988037
Validation loss: 2.566878926369452

Epoch: 5| Step: 2
Training loss: 2.80549955368042
Validation loss: 2.563398863679619

Epoch: 5| Step: 3
Training loss: 3.392357349395752
Validation loss: 2.5580021104504986

Epoch: 5| Step: 4
Training loss: 2.697687864303589
Validation loss: 2.556324653728034

Epoch: 5| Step: 5
Training loss: 3.145730495452881
Validation loss: 2.5565598933927474

Epoch: 5| Step: 6
Training loss: 2.494286298751831
Validation loss: 2.5684321849576888

Epoch: 5| Step: 7
Training loss: 2.1067240238189697
Validation loss: 2.5682197822037565

Epoch: 5| Step: 8
Training loss: 2.8799850940704346
Validation loss: 2.562147468648931

Epoch: 5| Step: 9
Training loss: 2.378352642059326
Validation loss: 2.557954752317039

Epoch: 5| Step: 10
Training loss: 2.706052780151367
Validation loss: 2.563962080145395

Epoch: 34| Step: 0
Training loss: 2.086385488510132
Validation loss: 2.5748164089777137

Epoch: 5| Step: 1
Training loss: 2.262899160385132
Validation loss: 2.573601186916392

Epoch: 5| Step: 2
Training loss: 2.4268622398376465
Validation loss: 2.5656241422058432

Epoch: 5| Step: 3
Training loss: 2.5448615550994873
Validation loss: 2.5735516701975176

Epoch: 5| Step: 4
Training loss: 3.2298977375030518
Validation loss: 2.5968911058159283

Epoch: 5| Step: 5
Training loss: 3.5209972858428955
Validation loss: 2.5983249859143327

Epoch: 5| Step: 6
Training loss: 2.944760799407959
Validation loss: 2.5519301096598306

Epoch: 5| Step: 7
Training loss: 2.4385902881622314
Validation loss: 2.5441170918044222

Epoch: 5| Step: 8
Training loss: 2.7770514488220215
Validation loss: 2.5463671453537478

Epoch: 5| Step: 9
Training loss: 3.399515151977539
Validation loss: 2.560745328985235

Epoch: 5| Step: 10
Training loss: 2.442270278930664
Validation loss: 2.5440654241910545

Epoch: 35| Step: 0
Training loss: 2.6665492057800293
Validation loss: 2.5376349777303715

Epoch: 5| Step: 1
Training loss: 2.0983211994171143
Validation loss: 2.529563375698623

Epoch: 5| Step: 2
Training loss: 3.132262706756592
Validation loss: 2.5301355033792476

Epoch: 5| Step: 3
Training loss: 2.4323501586914062
Validation loss: 2.536471220754808

Epoch: 5| Step: 4
Training loss: 3.3091278076171875
Validation loss: 2.550454488364599

Epoch: 5| Step: 5
Training loss: 2.7878692150115967
Validation loss: 2.540171443775136

Epoch: 5| Step: 6
Training loss: 1.990751028060913
Validation loss: 2.544734529269639

Epoch: 5| Step: 7
Training loss: 2.8718464374542236
Validation loss: 2.541919608269968

Epoch: 5| Step: 8
Training loss: 3.385725498199463
Validation loss: 2.5348326083152526

Epoch: 5| Step: 9
Training loss: 2.396899938583374
Validation loss: 2.5351166417521815

Epoch: 5| Step: 10
Training loss: 2.8948898315429688
Validation loss: 2.5297222778361332

Epoch: 36| Step: 0
Training loss: 2.6829051971435547
Validation loss: 2.5353995497508715

Epoch: 5| Step: 1
Training loss: 2.465879440307617
Validation loss: 2.545122404252329

Epoch: 5| Step: 2
Training loss: 2.159524440765381
Validation loss: 2.5363096883220058

Epoch: 5| Step: 3
Training loss: 2.4809365272521973
Validation loss: 2.5305100256396877

Epoch: 5| Step: 4
Training loss: 2.560473918914795
Validation loss: 2.543642751632198

Epoch: 5| Step: 5
Training loss: 2.648026943206787
Validation loss: 2.5692173075932327

Epoch: 5| Step: 6
Training loss: 2.6750824451446533
Validation loss: 2.5762857749897945

Epoch: 5| Step: 7
Training loss: 2.6249241828918457
Validation loss: 2.547972171537338

Epoch: 5| Step: 8
Training loss: 2.988921642303467
Validation loss: 2.538814257549983

Epoch: 5| Step: 9
Training loss: 3.068141222000122
Validation loss: 2.5503516581750687

Epoch: 5| Step: 10
Training loss: 3.7055883407592773
Validation loss: 2.5702157123114473

Epoch: 37| Step: 0
Training loss: 2.752497911453247
Validation loss: 2.5774048271999566

Epoch: 5| Step: 1
Training loss: 2.628859043121338
Validation loss: 2.59900176653298

Epoch: 5| Step: 2
Training loss: 2.74544358253479
Validation loss: 2.5839012463887534

Epoch: 5| Step: 3
Training loss: 2.426609516143799
Validation loss: 2.5592285612578034

Epoch: 5| Step: 4
Training loss: 2.3772776126861572
Validation loss: 2.529457881886472

Epoch: 5| Step: 5
Training loss: 2.4186809062957764
Validation loss: 2.519308336319462

Epoch: 5| Step: 6
Training loss: 2.661073684692383
Validation loss: 2.5128476799175306

Epoch: 5| Step: 7
Training loss: 2.944166660308838
Validation loss: 2.514673476578087

Epoch: 5| Step: 8
Training loss: 3.270984172821045
Validation loss: 2.51737141865556

Epoch: 5| Step: 9
Training loss: 2.694254159927368
Validation loss: 2.5218066169369604

Epoch: 5| Step: 10
Training loss: 2.971736192703247
Validation loss: 2.523732036672613

Epoch: 38| Step: 0
Training loss: 2.4000227451324463
Validation loss: 2.5231699071904665

Epoch: 5| Step: 1
Training loss: 3.057577610015869
Validation loss: 2.5227188551297752

Epoch: 5| Step: 2
Training loss: 2.6335091590881348
Validation loss: 2.5183371779739216

Epoch: 5| Step: 3
Training loss: 2.7535998821258545
Validation loss: 2.515890554715228

Epoch: 5| Step: 4
Training loss: 3.2346160411834717
Validation loss: 2.5142173177452496

Epoch: 5| Step: 5
Training loss: 2.8399553298950195
Validation loss: 2.509648184622488

Epoch: 5| Step: 6
Training loss: 3.1956467628479004
Validation loss: 2.5080005763679423

Epoch: 5| Step: 7
Training loss: 2.1591086387634277
Validation loss: 2.5100168720368417

Epoch: 5| Step: 8
Training loss: 2.3499622344970703
Validation loss: 2.5151432765427457

Epoch: 5| Step: 9
Training loss: 2.6781885623931885
Validation loss: 2.526075250358992

Epoch: 5| Step: 10
Training loss: 2.603837490081787
Validation loss: 2.5315116425996185

Epoch: 39| Step: 0
Training loss: 2.622150421142578
Validation loss: 2.526861338205235

Epoch: 5| Step: 1
Training loss: 2.082057476043701
Validation loss: 2.5195692457178587

Epoch: 5| Step: 2
Training loss: 2.4018733501434326
Validation loss: 2.51446807512673

Epoch: 5| Step: 3
Training loss: 3.35797119140625
Validation loss: 2.5083187574981363

Epoch: 5| Step: 4
Training loss: 2.529937982559204
Validation loss: 2.5063776995546077

Epoch: 5| Step: 5
Training loss: 2.934257745742798
Validation loss: 2.513204551512195

Epoch: 5| Step: 6
Training loss: 3.2628014087677
Validation loss: 2.510168719035323

Epoch: 5| Step: 7
Training loss: 2.6091551780700684
Validation loss: 2.51499500325931

Epoch: 5| Step: 8
Training loss: 2.5031778812408447
Validation loss: 2.5058560115034862

Epoch: 5| Step: 9
Training loss: 2.309335708618164
Validation loss: 2.5105405469094553

Epoch: 5| Step: 10
Training loss: 3.1892178058624268
Validation loss: 2.5437305563239643

Epoch: 40| Step: 0
Training loss: 2.5080819129943848
Validation loss: 2.530611233044696

Epoch: 5| Step: 1
Training loss: 2.6318137645721436
Validation loss: 2.507727312785323

Epoch: 5| Step: 2
Training loss: 3.162580966949463
Validation loss: 2.497842796387211

Epoch: 5| Step: 3
Training loss: 3.0901780128479004
Validation loss: 2.490120598064956

Epoch: 5| Step: 4
Training loss: 2.839327573776245
Validation loss: 2.4898452604970625

Epoch: 5| Step: 5
Training loss: 2.0541749000549316
Validation loss: 2.4898667156055407

Epoch: 5| Step: 6
Training loss: 3.092832565307617
Validation loss: 2.48758945157451

Epoch: 5| Step: 7
Training loss: 2.7381093502044678
Validation loss: 2.48701403474295

Epoch: 5| Step: 8
Training loss: 2.4382381439208984
Validation loss: 2.48301007927105

Epoch: 5| Step: 9
Training loss: 2.725576400756836
Validation loss: 2.4890406618836107

Epoch: 5| Step: 10
Training loss: 2.282944917678833
Validation loss: 2.500026003006966

Epoch: 41| Step: 0
Training loss: 2.6627285480499268
Validation loss: 2.4988426418714624

Epoch: 5| Step: 1
Training loss: 3.059790849685669
Validation loss: 2.507562944965978

Epoch: 5| Step: 2
Training loss: 2.1632683277130127
Validation loss: 2.4975187675927275

Epoch: 5| Step: 3
Training loss: 2.3562941551208496
Validation loss: 2.50379749267332

Epoch: 5| Step: 4
Training loss: 3.194446563720703
Validation loss: 2.502876376592985

Epoch: 5| Step: 5
Training loss: 2.9480583667755127
Validation loss: 2.4843434031291673

Epoch: 5| Step: 6
Training loss: 2.3798828125
Validation loss: 2.4817180966818206

Epoch: 5| Step: 7
Training loss: 2.664243221282959
Validation loss: 2.4833291422936226

Epoch: 5| Step: 8
Training loss: 2.9445207118988037
Validation loss: 2.481859907027214

Epoch: 5| Step: 9
Training loss: 2.333405017852783
Validation loss: 2.4795549479863976

Epoch: 5| Step: 10
Training loss: 3.0283422470092773
Validation loss: 2.4800691707159883

Epoch: 42| Step: 0
Training loss: 2.4519541263580322
Validation loss: 2.4822150584190124

Epoch: 5| Step: 1
Training loss: 2.77262806892395
Validation loss: 2.4774347505261822

Epoch: 5| Step: 2
Training loss: 2.980375289916992
Validation loss: 2.4777041660842074

Epoch: 5| Step: 3
Training loss: 2.3545823097229004
Validation loss: 2.4803995804120134

Epoch: 5| Step: 4
Training loss: 2.316296339035034
Validation loss: 2.4905589165226107

Epoch: 5| Step: 5
Training loss: 2.543912649154663
Validation loss: 2.533764813535957

Epoch: 5| Step: 6
Training loss: 2.4948678016662598
Validation loss: 2.5739080085549304

Epoch: 5| Step: 7
Training loss: 3.169377088546753
Validation loss: 2.5592909782163558

Epoch: 5| Step: 8
Training loss: 2.8245558738708496
Validation loss: 2.5169161314605386

Epoch: 5| Step: 9
Training loss: 2.646106004714966
Validation loss: 2.490953594125727

Epoch: 5| Step: 10
Training loss: 3.2273998260498047
Validation loss: 2.4694076276594594

Epoch: 43| Step: 0
Training loss: 3.3179290294647217
Validation loss: 2.4746051039747012

Epoch: 5| Step: 1
Training loss: 3.2711517810821533
Validation loss: 2.477098097083389

Epoch: 5| Step: 2
Training loss: 2.664543628692627
Validation loss: 2.4811321458508893

Epoch: 5| Step: 3
Training loss: 2.195758819580078
Validation loss: 2.4839002445179927

Epoch: 5| Step: 4
Training loss: 2.7147929668426514
Validation loss: 2.499468829042168

Epoch: 5| Step: 5
Training loss: 2.5626332759857178
Validation loss: 2.506768129205191

Epoch: 5| Step: 6
Training loss: 2.8369107246398926
Validation loss: 2.498736504585512

Epoch: 5| Step: 7
Training loss: 2.8225579261779785
Validation loss: 2.4732653094876196

Epoch: 5| Step: 8
Training loss: 2.8457138538360596
Validation loss: 2.4691947480683685

Epoch: 5| Step: 9
Training loss: 2.3039536476135254
Validation loss: 2.4598448481611026

Epoch: 5| Step: 10
Training loss: 2.1098875999450684
Validation loss: 2.465422640564621

Epoch: 44| Step: 0
Training loss: 2.418177366256714
Validation loss: 2.472200470585977

Epoch: 5| Step: 1
Training loss: 2.976095199584961
Validation loss: 2.4927959698502735

Epoch: 5| Step: 2
Training loss: 2.9309372901916504
Validation loss: 2.5264708252363306

Epoch: 5| Step: 3
Training loss: 3.1476075649261475
Validation loss: 2.5205475745662564

Epoch: 5| Step: 4
Training loss: 3.2627265453338623
Validation loss: 2.5282956554043676

Epoch: 5| Step: 5
Training loss: 3.098047971725464
Validation loss: 2.5135113628961707

Epoch: 5| Step: 6
Training loss: 2.2375881671905518
Validation loss: 2.493921128652429

Epoch: 5| Step: 7
Training loss: 2.789350986480713
Validation loss: 2.4842448619104203

Epoch: 5| Step: 8
Training loss: 2.563697338104248
Validation loss: 2.45971348977858

Epoch: 5| Step: 9
Training loss: 2.017732620239258
Validation loss: 2.45673857965777

Epoch: 5| Step: 10
Training loss: 2.0585439205169678
Validation loss: 2.454758938922677

Epoch: 45| Step: 0
Training loss: 1.8932437896728516
Validation loss: 2.4555497630949943

Epoch: 5| Step: 1
Training loss: 2.9490365982055664
Validation loss: 2.4555462175799954

Epoch: 5| Step: 2
Training loss: 2.445556163787842
Validation loss: 2.45814154225011

Epoch: 5| Step: 3
Training loss: 3.0438742637634277
Validation loss: 2.4561143357266664

Epoch: 5| Step: 4
Training loss: 2.508119583129883
Validation loss: 2.4550887538540747

Epoch: 5| Step: 5
Training loss: 2.783501625061035
Validation loss: 2.4544488435150473

Epoch: 5| Step: 6
Training loss: 2.15276837348938
Validation loss: 2.4534180087427937

Epoch: 5| Step: 7
Training loss: 3.1347808837890625
Validation loss: 2.4578875187904603

Epoch: 5| Step: 8
Training loss: 3.0031280517578125
Validation loss: 2.4670125951049147

Epoch: 5| Step: 9
Training loss: 3.0540359020233154
Validation loss: 2.46232799688975

Epoch: 5| Step: 10
Training loss: 2.4234988689422607
Validation loss: 2.4685170330027097

Epoch: 46| Step: 0
Training loss: 2.8993048667907715
Validation loss: 2.47093871331984

Epoch: 5| Step: 1
Training loss: 2.4816393852233887
Validation loss: 2.464675836665656

Epoch: 5| Step: 2
Training loss: 3.060140371322632
Validation loss: 2.453394046393774

Epoch: 5| Step: 3
Training loss: 2.4661126136779785
Validation loss: 2.4486021149543022

Epoch: 5| Step: 4
Training loss: 2.5289134979248047
Validation loss: 2.445931124430831

Epoch: 5| Step: 5
Training loss: 2.8797309398651123
Validation loss: 2.4469093276608374

Epoch: 5| Step: 6
Training loss: 2.597884178161621
Validation loss: 2.4490273229537474

Epoch: 5| Step: 7
Training loss: 2.647109031677246
Validation loss: 2.4562443225614485

Epoch: 5| Step: 8
Training loss: 2.329329013824463
Validation loss: 2.455755777256463

Epoch: 5| Step: 9
Training loss: 2.743948459625244
Validation loss: 2.4629209836324057

Epoch: 5| Step: 10
Training loss: 2.7421483993530273
Validation loss: 2.466368785468481

Epoch: 47| Step: 0
Training loss: 2.47695255279541
Validation loss: 2.4681127712290776

Epoch: 5| Step: 1
Training loss: 2.7348897457122803
Validation loss: 2.4683662717060377

Epoch: 5| Step: 2
Training loss: 2.3561477661132812
Validation loss: 2.4710643599110265

Epoch: 5| Step: 3
Training loss: 3.1032485961914062
Validation loss: 2.4653287574809086

Epoch: 5| Step: 4
Training loss: 2.8582091331481934
Validation loss: 2.4696822474079747

Epoch: 5| Step: 5
Training loss: 2.956939697265625
Validation loss: 2.4715662361473165

Epoch: 5| Step: 6
Training loss: 2.586423397064209
Validation loss: 2.4693990574088147

Epoch: 5| Step: 7
Training loss: 2.7228140830993652
Validation loss: 2.465004067267141

Epoch: 5| Step: 8
Training loss: 2.0756418704986572
Validation loss: 2.466168244679769

Epoch: 5| Step: 9
Training loss: 2.8901028633117676
Validation loss: 2.460842050531859

Epoch: 5| Step: 10
Training loss: 2.6758944988250732
Validation loss: 2.4565876119880268

Epoch: 48| Step: 0
Training loss: 2.4779088497161865
Validation loss: 2.4563134690766693

Epoch: 5| Step: 1
Training loss: 2.9912867546081543
Validation loss: 2.4480123212260585

Epoch: 5| Step: 2
Training loss: 2.3856868743896484
Validation loss: 2.4445403160587436

Epoch: 5| Step: 3
Training loss: 2.477155923843384
Validation loss: 2.4490992920373076

Epoch: 5| Step: 4
Training loss: 3.3641891479492188
Validation loss: 2.4436435981463362

Epoch: 5| Step: 5
Training loss: 2.5398712158203125
Validation loss: 2.4421224927389495

Epoch: 5| Step: 6
Training loss: 2.4739818572998047
Validation loss: 2.4374970518132693

Epoch: 5| Step: 7
Training loss: 2.6588456630706787
Validation loss: 2.433968092805596

Epoch: 5| Step: 8
Training loss: 3.08699107170105
Validation loss: 2.433490135336435

Epoch: 5| Step: 9
Training loss: 2.605966329574585
Validation loss: 2.429400610667403

Epoch: 5| Step: 10
Training loss: 2.1494319438934326
Validation loss: 2.4294705826749086

Epoch: 49| Step: 0
Training loss: 2.6302201747894287
Validation loss: 2.4254301042966944

Epoch: 5| Step: 1
Training loss: 2.4509408473968506
Validation loss: 2.4291778482416624

Epoch: 5| Step: 2
Training loss: 2.7493295669555664
Validation loss: 2.4284197540693384

Epoch: 5| Step: 3
Training loss: 2.4749960899353027
Validation loss: 2.429529115717898

Epoch: 5| Step: 4
Training loss: 2.731440544128418
Validation loss: 2.435462728623421

Epoch: 5| Step: 5
Training loss: 2.1131529808044434
Validation loss: 2.4342282907937163

Epoch: 5| Step: 6
Training loss: 3.0439414978027344
Validation loss: 2.439596358165946

Epoch: 5| Step: 7
Training loss: 2.2448222637176514
Validation loss: 2.4420545203711397

Epoch: 5| Step: 8
Training loss: 3.3098177909851074
Validation loss: 2.4424366822806736

Epoch: 5| Step: 9
Training loss: 3.270033359527588
Validation loss: 2.440949216965706

Epoch: 5| Step: 10
Training loss: 2.1647675037384033
Validation loss: 2.4484222730000815

Epoch: 50| Step: 0
Training loss: 2.764051675796509
Validation loss: 2.434654264039891

Epoch: 5| Step: 1
Training loss: 2.302004337310791
Validation loss: 2.426840636038011

Epoch: 5| Step: 2
Training loss: 2.4503443241119385
Validation loss: 2.420715073103546

Epoch: 5| Step: 3
Training loss: 2.414802312850952
Validation loss: 2.4162257922592985

Epoch: 5| Step: 4
Training loss: 2.3832345008850098
Validation loss: 2.420977674504762

Epoch: 5| Step: 5
Training loss: 2.796642541885376
Validation loss: 2.4234637368109917

Epoch: 5| Step: 6
Training loss: 2.7197253704071045
Validation loss: 2.4239353441422984

Epoch: 5| Step: 7
Training loss: 2.917534351348877
Validation loss: 2.420060024466566

Epoch: 5| Step: 8
Training loss: 3.126070022583008
Validation loss: 2.4210829247710524

Epoch: 5| Step: 9
Training loss: 2.8671975135803223
Validation loss: 2.4158766372229463

Epoch: 5| Step: 10
Training loss: 2.5002379417419434
Validation loss: 2.4156142229674966

Epoch: 51| Step: 0
Training loss: 2.6690244674682617
Validation loss: 2.4127492058661675

Epoch: 5| Step: 1
Training loss: 2.910579204559326
Validation loss: 2.410002218779697

Epoch: 5| Step: 2
Training loss: 2.889775037765503
Validation loss: 2.414378255926153

Epoch: 5| Step: 3
Training loss: 2.613363265991211
Validation loss: 2.4176966554375103

Epoch: 5| Step: 4
Training loss: 2.7507076263427734
Validation loss: 2.4398607387337634

Epoch: 5| Step: 5
Training loss: 2.677767276763916
Validation loss: 2.4405828547734085

Epoch: 5| Step: 6
Training loss: 2.596292495727539
Validation loss: 2.4421919468910462

Epoch: 5| Step: 7
Training loss: 2.6861612796783447
Validation loss: 2.4547293545097433

Epoch: 5| Step: 8
Training loss: 2.5551373958587646
Validation loss: 2.4744356345104914

Epoch: 5| Step: 9
Training loss: 2.0147664546966553
Validation loss: 2.471261570530553

Epoch: 5| Step: 10
Training loss: 2.8429691791534424
Validation loss: 2.469341251157945

Epoch: 52| Step: 0
Training loss: 3.034475803375244
Validation loss: 2.4416565202897593

Epoch: 5| Step: 1
Training loss: 2.567474603652954
Validation loss: 2.4199139661686395

Epoch: 5| Step: 2
Training loss: 2.736574649810791
Validation loss: 2.4210923128230597

Epoch: 5| Step: 3
Training loss: 2.6912827491760254
Validation loss: 2.413022989867836

Epoch: 5| Step: 4
Training loss: 2.7742438316345215
Validation loss: 2.407940528726065

Epoch: 5| Step: 5
Training loss: 2.7704784870147705
Validation loss: 2.403252857987599

Epoch: 5| Step: 6
Training loss: 2.790160655975342
Validation loss: 2.4052591708398636

Epoch: 5| Step: 7
Training loss: 2.4241690635681152
Validation loss: 2.404293367939611

Epoch: 5| Step: 8
Training loss: 2.5893938541412354
Validation loss: 2.421794340174685

Epoch: 5| Step: 9
Training loss: 2.394930362701416
Validation loss: 2.4283418757941133

Epoch: 5| Step: 10
Training loss: 2.253326416015625
Validation loss: 2.4390087486595236

Epoch: 53| Step: 0
Training loss: 2.589071750640869
Validation loss: 2.4472400552483013

Epoch: 5| Step: 1
Training loss: 2.2933332920074463
Validation loss: 2.437537847026702

Epoch: 5| Step: 2
Training loss: 2.850090742111206
Validation loss: 2.4518215758826143

Epoch: 5| Step: 3
Training loss: 2.6330208778381348
Validation loss: 2.490195248716621

Epoch: 5| Step: 4
Training loss: 2.845783233642578
Validation loss: 2.518952387635426

Epoch: 5| Step: 5
Training loss: 2.7406017780303955
Validation loss: 2.484539572910596

Epoch: 5| Step: 6
Training loss: 2.6500794887542725
Validation loss: 2.473466537332022

Epoch: 5| Step: 7
Training loss: 3.2756080627441406
Validation loss: 2.4453550205435803

Epoch: 5| Step: 8
Training loss: 2.5186538696289062
Validation loss: 2.426365383209721

Epoch: 5| Step: 9
Training loss: 2.8285813331604004
Validation loss: 2.4064030980551117

Epoch: 5| Step: 10
Training loss: 1.998584270477295
Validation loss: 2.4177844755111204

Epoch: 54| Step: 0
Training loss: 2.5073580741882324
Validation loss: 2.438589084532953

Epoch: 5| Step: 1
Training loss: 2.1368675231933594
Validation loss: 2.463885545730591

Epoch: 5| Step: 2
Training loss: 2.536778211593628
Validation loss: 2.425772718203965

Epoch: 5| Step: 3
Training loss: 3.0898079872131348
Validation loss: 2.415439421130765

Epoch: 5| Step: 4
Training loss: 2.681339740753174
Validation loss: 2.4020638132608063

Epoch: 5| Step: 5
Training loss: 2.5341880321502686
Validation loss: 2.408654410351989

Epoch: 5| Step: 6
Training loss: 3.212766647338867
Validation loss: 2.421018938864431

Epoch: 5| Step: 7
Training loss: 2.676016092300415
Validation loss: 2.4328032091099727

Epoch: 5| Step: 8
Training loss: 3.0914344787597656
Validation loss: 2.4570381256841842

Epoch: 5| Step: 9
Training loss: 2.332916736602783
Validation loss: 2.4566006173369703

Epoch: 5| Step: 10
Training loss: 2.700173854827881
Validation loss: 2.4663686906137774

Epoch: 55| Step: 0
Training loss: 2.482248067855835
Validation loss: 2.457495630428355

Epoch: 5| Step: 1
Training loss: 2.5713391304016113
Validation loss: 2.477205812290151

Epoch: 5| Step: 2
Training loss: 2.3392271995544434
Validation loss: 2.4917121933352564

Epoch: 5| Step: 3
Training loss: 2.96838116645813
Validation loss: 2.44084237211494

Epoch: 5| Step: 4
Training loss: 2.425626277923584
Validation loss: 2.418670485096593

Epoch: 5| Step: 5
Training loss: 2.6220340728759766
Validation loss: 2.413391908009847

Epoch: 5| Step: 6
Training loss: 3.027973175048828
Validation loss: 2.4365154697049047

Epoch: 5| Step: 7
Training loss: 2.4482388496398926
Validation loss: 2.466544830670921

Epoch: 5| Step: 8
Training loss: 3.5543923377990723
Validation loss: 2.4717613573997252

Epoch: 5| Step: 9
Training loss: 2.6723265647888184
Validation loss: 2.4686152242845103

Epoch: 5| Step: 10
Training loss: 2.502690315246582
Validation loss: 2.4263354578325824

Epoch: 56| Step: 0
Training loss: 2.3015732765197754
Validation loss: 2.4118822159305697

Epoch: 5| Step: 1
Training loss: 3.098241090774536
Validation loss: 2.4071743719039427

Epoch: 5| Step: 2
Training loss: 2.6806373596191406
Validation loss: 2.405107339223226

Epoch: 5| Step: 3
Training loss: 2.6241469383239746
Validation loss: 2.398410979137626

Epoch: 5| Step: 4
Training loss: 2.0546722412109375
Validation loss: 2.3949699530037503

Epoch: 5| Step: 5
Training loss: 2.473036289215088
Validation loss: 2.3972862971726285

Epoch: 5| Step: 6
Training loss: 3.613632917404175
Validation loss: 2.4108352943133284

Epoch: 5| Step: 7
Training loss: 2.5122315883636475
Validation loss: 2.416246403930008

Epoch: 5| Step: 8
Training loss: 2.4778778553009033
Validation loss: 2.417005113376084

Epoch: 5| Step: 9
Training loss: 2.4444515705108643
Validation loss: 2.414892976002027

Epoch: 5| Step: 10
Training loss: 2.9892430305480957
Validation loss: 2.43358447218454

Epoch: 57| Step: 0
Training loss: 2.214890718460083
Validation loss: 2.4114635131692372

Epoch: 5| Step: 1
Training loss: 2.627819538116455
Validation loss: 2.3959869466802126

Epoch: 5| Step: 2
Training loss: 2.4890823364257812
Validation loss: 2.388624042593023

Epoch: 5| Step: 3
Training loss: 3.210113525390625
Validation loss: 2.3756529169697918

Epoch: 5| Step: 4
Training loss: 2.5662496089935303
Validation loss: 2.382897694905599

Epoch: 5| Step: 5
Training loss: 2.3428540229797363
Validation loss: 2.38239187066273

Epoch: 5| Step: 6
Training loss: 3.22607684135437
Validation loss: 2.3881338514307493

Epoch: 5| Step: 7
Training loss: 3.1443819999694824
Validation loss: 2.3921285803600023

Epoch: 5| Step: 8
Training loss: 2.61857008934021
Validation loss: 2.392085398397138

Epoch: 5| Step: 9
Training loss: 2.3222577571868896
Validation loss: 2.3915278783408542

Epoch: 5| Step: 10
Training loss: 2.437796115875244
Validation loss: 2.392154070638841

Epoch: 58| Step: 0
Training loss: 2.8196403980255127
Validation loss: 2.3885414895190986

Epoch: 5| Step: 1
Training loss: 2.5635812282562256
Validation loss: 2.3869909701808805

Epoch: 5| Step: 2
Training loss: 2.7984507083892822
Validation loss: 2.380447180040421

Epoch: 5| Step: 3
Training loss: 2.441042423248291
Validation loss: 2.372558788586688

Epoch: 5| Step: 4
Training loss: 2.2735233306884766
Validation loss: 2.3730948202071653

Epoch: 5| Step: 5
Training loss: 3.5664448738098145
Validation loss: 2.3769203744908816

Epoch: 5| Step: 6
Training loss: 3.122903823852539
Validation loss: 2.371083531328427

Epoch: 5| Step: 7
Training loss: 2.152956247329712
Validation loss: 2.3756922278352963

Epoch: 5| Step: 8
Training loss: 2.773381233215332
Validation loss: 2.3819605176166823

Epoch: 5| Step: 9
Training loss: 2.266596794128418
Validation loss: 2.3890721362124205

Epoch: 5| Step: 10
Training loss: 2.0034804344177246
Validation loss: 2.3842112915490263

Epoch: 59| Step: 0
Training loss: 2.6618072986602783
Validation loss: 2.3995106438154816

Epoch: 5| Step: 1
Training loss: 1.9162218570709229
Validation loss: 2.4343237133436304

Epoch: 5| Step: 2
Training loss: 2.370645046234131
Validation loss: 2.4668784141540527

Epoch: 5| Step: 3
Training loss: 2.8053832054138184
Validation loss: 2.4833037007239556

Epoch: 5| Step: 4
Training loss: 2.5655837059020996
Validation loss: 2.443403254273117

Epoch: 5| Step: 5
Training loss: 3.0205600261688232
Validation loss: 2.412781015519173

Epoch: 5| Step: 6
Training loss: 2.8809688091278076
Validation loss: 2.3847965117423766

Epoch: 5| Step: 7
Training loss: 2.4924209117889404
Validation loss: 2.372732813640307

Epoch: 5| Step: 8
Training loss: 2.5301153659820557
Validation loss: 2.370727754408313

Epoch: 5| Step: 9
Training loss: 3.1837894916534424
Validation loss: 2.366512193474718

Epoch: 5| Step: 10
Training loss: 2.707489013671875
Validation loss: 2.363851590823102

Epoch: 60| Step: 0
Training loss: 2.9706923961639404
Validation loss: 2.36413432962151

Epoch: 5| Step: 1
Training loss: 2.3484890460968018
Validation loss: 2.365445844588741

Epoch: 5| Step: 2
Training loss: 2.3096656799316406
Validation loss: 2.3731056182615218

Epoch: 5| Step: 3
Training loss: 3.1341257095336914
Validation loss: 2.3748605430767102

Epoch: 5| Step: 4
Training loss: 2.335392951965332
Validation loss: 2.383489595946445

Epoch: 5| Step: 5
Training loss: 2.7778658866882324
Validation loss: 2.3809192744634484

Epoch: 5| Step: 6
Training loss: 2.408529758453369
Validation loss: 2.3807971067326044

Epoch: 5| Step: 7
Training loss: 2.545437812805176
Validation loss: 2.3771421883695867

Epoch: 5| Step: 8
Training loss: 2.194530725479126
Validation loss: 2.3695479823696997

Epoch: 5| Step: 9
Training loss: 3.128840684890747
Validation loss: 2.3690026088427474

Epoch: 5| Step: 10
Training loss: 2.9774744510650635
Validation loss: 2.36478248206518

Epoch: 61| Step: 0
Training loss: 2.739851474761963
Validation loss: 2.3677607838825514

Epoch: 5| Step: 1
Training loss: 2.372056484222412
Validation loss: 2.363140211310438

Epoch: 5| Step: 2
Training loss: 3.0185842514038086
Validation loss: 2.370485774932369

Epoch: 5| Step: 3
Training loss: 2.609084367752075
Validation loss: 2.374985779485395

Epoch: 5| Step: 4
Training loss: 3.0694332122802734
Validation loss: 2.3844460364310973

Epoch: 5| Step: 5
Training loss: 1.9708945751190186
Validation loss: 2.3862803520694857

Epoch: 5| Step: 6
Training loss: 2.984670877456665
Validation loss: 2.3903360238639255

Epoch: 5| Step: 7
Training loss: 2.5869736671447754
Validation loss: 2.390271950793523

Epoch: 5| Step: 8
Training loss: 2.252373695373535
Validation loss: 2.3907510413918445

Epoch: 5| Step: 9
Training loss: 2.4082107543945312
Validation loss: 2.385889543000088

Epoch: 5| Step: 10
Training loss: 2.904374361038208
Validation loss: 2.3754994253958426

Epoch: 62| Step: 0
Training loss: 2.707794189453125
Validation loss: 2.3744439130188315

Epoch: 5| Step: 1
Training loss: 2.6546661853790283
Validation loss: 2.358791894810174

Epoch: 5| Step: 2
Training loss: 2.421722888946533
Validation loss: 2.358292818069458

Epoch: 5| Step: 3
Training loss: 2.2488391399383545
Validation loss: 2.367092191532094

Epoch: 5| Step: 4
Training loss: 2.7170968055725098
Validation loss: 2.3652138120384625

Epoch: 5| Step: 5
Training loss: 2.6090006828308105
Validation loss: 2.3628745617405063

Epoch: 5| Step: 6
Training loss: 1.431139588356018
Validation loss: 2.3603801163293983

Epoch: 5| Step: 7
Training loss: 2.9420793056488037
Validation loss: 2.370435824958227

Epoch: 5| Step: 8
Training loss: 3.354921340942383
Validation loss: 2.3678018226418445

Epoch: 5| Step: 9
Training loss: 3.196937084197998
Validation loss: 2.3672247727711997

Epoch: 5| Step: 10
Training loss: 2.402203321456909
Validation loss: 2.3652988685074674

Epoch: 63| Step: 0
Training loss: 1.9200403690338135
Validation loss: 2.3680322272803194

Epoch: 5| Step: 1
Training loss: 2.7894091606140137
Validation loss: 2.3882070818255023

Epoch: 5| Step: 2
Training loss: 2.0942158699035645
Validation loss: 2.398316111615909

Epoch: 5| Step: 3
Training loss: 3.362421751022339
Validation loss: 2.431741483749882

Epoch: 5| Step: 4
Training loss: 2.218651056289673
Validation loss: 2.440049489339193

Epoch: 5| Step: 5
Training loss: 2.6057610511779785
Validation loss: 2.4426853374768327

Epoch: 5| Step: 6
Training loss: 2.846010684967041
Validation loss: 2.4325155878579743

Epoch: 5| Step: 7
Training loss: 3.171754837036133
Validation loss: 2.4069282188210437

Epoch: 5| Step: 8
Training loss: 2.611056327819824
Validation loss: 2.3729688839245866

Epoch: 5| Step: 9
Training loss: 2.709583044052124
Validation loss: 2.35070445717022

Epoch: 5| Step: 10
Training loss: 2.5288801193237305
Validation loss: 2.3437557425550235

Epoch: 64| Step: 0
Training loss: 1.8431651592254639
Validation loss: 2.340627577997023

Epoch: 5| Step: 1
Training loss: 2.514198064804077
Validation loss: 2.3488774197075957

Epoch: 5| Step: 2
Training loss: 2.3683664798736572
Validation loss: 2.3495738173043854

Epoch: 5| Step: 3
Training loss: 2.4067254066467285
Validation loss: 2.3466185267253588

Epoch: 5| Step: 4
Training loss: 2.474771499633789
Validation loss: 2.3455950547290105

Epoch: 5| Step: 5
Training loss: 2.748809814453125
Validation loss: 2.3460274050312657

Epoch: 5| Step: 6
Training loss: 3.082083225250244
Validation loss: 2.34484294409393

Epoch: 5| Step: 7
Training loss: 2.848499298095703
Validation loss: 2.344378371392527

Epoch: 5| Step: 8
Training loss: 3.454498767852783
Validation loss: 2.34500458932692

Epoch: 5| Step: 9
Training loss: 2.4504828453063965
Validation loss: 2.3455473876768544

Epoch: 5| Step: 10
Training loss: 2.645927906036377
Validation loss: 2.3481682859441286

Epoch: 65| Step: 0
Training loss: 2.8545143604278564
Validation loss: 2.3536072725890786

Epoch: 5| Step: 1
Training loss: 2.9914066791534424
Validation loss: 2.360495150730174

Epoch: 5| Step: 2
Training loss: 2.4294426441192627
Validation loss: 2.3720811259362007

Epoch: 5| Step: 3
Training loss: 2.434861898422241
Validation loss: 2.391044009116388

Epoch: 5| Step: 4
Training loss: 2.057619094848633
Validation loss: 2.3989687247942855

Epoch: 5| Step: 5
Training loss: 2.5982964038848877
Validation loss: 2.407672410370201

Epoch: 5| Step: 6
Training loss: 2.7052831649780273
Validation loss: 2.419314492133356

Epoch: 5| Step: 7
Training loss: 2.2337260246276855
Validation loss: 2.4103658891493276

Epoch: 5| Step: 8
Training loss: 3.306025743484497
Validation loss: 2.3934976977686726

Epoch: 5| Step: 9
Training loss: 2.424269199371338
Validation loss: 2.3638053671006234

Epoch: 5| Step: 10
Training loss: 2.754220485687256
Validation loss: 2.3430845045274302

Epoch: 66| Step: 0
Training loss: 2.3474440574645996
Validation loss: 2.3365161649642454

Epoch: 5| Step: 1
Training loss: 2.1819560527801514
Validation loss: 2.3292100634626163

Epoch: 5| Step: 2
Training loss: 2.5742993354797363
Validation loss: 2.3297693242308912

Epoch: 5| Step: 3
Training loss: 3.083047389984131
Validation loss: 2.338087207527571

Epoch: 5| Step: 4
Training loss: 2.2812881469726562
Validation loss: 2.3368812530271468

Epoch: 5| Step: 5
Training loss: 2.9232544898986816
Validation loss: 2.3301876770552767

Epoch: 5| Step: 6
Training loss: 2.608520984649658
Validation loss: 2.3353716250388854

Epoch: 5| Step: 7
Training loss: 2.4658801555633545
Validation loss: 2.3278843946354364

Epoch: 5| Step: 8
Training loss: 3.317190647125244
Validation loss: 2.3286665075568744

Epoch: 5| Step: 9
Training loss: 2.5642666816711426
Validation loss: 2.331571093169592

Epoch: 5| Step: 10
Training loss: 2.378345251083374
Validation loss: 2.329652081253708

Epoch: 67| Step: 0
Training loss: 2.295271873474121
Validation loss: 2.329068978627523

Epoch: 5| Step: 1
Training loss: 2.6105692386627197
Validation loss: 2.3298006493558168

Epoch: 5| Step: 2
Training loss: 2.896857500076294
Validation loss: 2.3265996799674085

Epoch: 5| Step: 3
Training loss: 3.0139262676239014
Validation loss: 2.335355584339429

Epoch: 5| Step: 4
Training loss: 2.3516106605529785
Validation loss: 2.338875553941214

Epoch: 5| Step: 5
Training loss: 2.0380160808563232
Validation loss: 2.3411780044596684

Epoch: 5| Step: 6
Training loss: 2.992030143737793
Validation loss: 2.344889392134964

Epoch: 5| Step: 7
Training loss: 2.7244372367858887
Validation loss: 2.3392659156553206

Epoch: 5| Step: 8
Training loss: 2.7725138664245605
Validation loss: 2.3361174855180966

Epoch: 5| Step: 9
Training loss: 2.3794400691986084
Validation loss: 2.3351713277960338

Epoch: 5| Step: 10
Training loss: 2.515839099884033
Validation loss: 2.329776948498141

Epoch: 68| Step: 0
Training loss: 3.581263780593872
Validation loss: 2.3241884323858444

Epoch: 5| Step: 1
Training loss: 2.611906051635742
Validation loss: 2.3225318026799027

Epoch: 5| Step: 2
Training loss: 2.7263588905334473
Validation loss: 2.318535357393244

Epoch: 5| Step: 3
Training loss: 3.4372429847717285
Validation loss: 2.3159452048681115

Epoch: 5| Step: 4
Training loss: 2.61965274810791
Validation loss: 2.3183446494481896

Epoch: 5| Step: 5
Training loss: 2.0700314044952393
Validation loss: 2.321962897495557

Epoch: 5| Step: 6
Training loss: 2.6810710430145264
Validation loss: 2.318431418429139

Epoch: 5| Step: 7
Training loss: 2.1116127967834473
Validation loss: 2.3180504614307034

Epoch: 5| Step: 8
Training loss: 2.582164764404297
Validation loss: 2.3218512176185526

Epoch: 5| Step: 9
Training loss: 1.8446937799453735
Validation loss: 2.3189946669404224

Epoch: 5| Step: 10
Training loss: 2.4264135360717773
Validation loss: 2.321125053590344

Epoch: 69| Step: 0
Training loss: 2.430408000946045
Validation loss: 2.3234681519128944

Epoch: 5| Step: 1
Training loss: 2.8187880516052246
Validation loss: 2.324755484058011

Epoch: 5| Step: 2
Training loss: 2.8820395469665527
Validation loss: 2.3258943775648713

Epoch: 5| Step: 3
Training loss: 2.798323631286621
Validation loss: 2.3290490975943943

Epoch: 5| Step: 4
Training loss: 1.8762203454971313
Validation loss: 2.33619442806449

Epoch: 5| Step: 5
Training loss: 3.073789119720459
Validation loss: 2.3411782762055755

Epoch: 5| Step: 6
Training loss: 2.115561008453369
Validation loss: 2.355512918964509

Epoch: 5| Step: 7
Training loss: 2.7994823455810547
Validation loss: 2.3607092595869497

Epoch: 5| Step: 8
Training loss: 3.1807756423950195
Validation loss: 2.4023124069295902

Epoch: 5| Step: 9
Training loss: 2.1948635578155518
Validation loss: 2.383577815947994

Epoch: 5| Step: 10
Training loss: 2.3238584995269775
Validation loss: 2.363089007716025

Epoch: 70| Step: 0
Training loss: 2.400712490081787
Validation loss: 2.347296522509667

Epoch: 5| Step: 1
Training loss: 2.4817309379577637
Validation loss: 2.350356312208278

Epoch: 5| Step: 2
Training loss: 2.967620849609375
Validation loss: 2.3538888244218725

Epoch: 5| Step: 3
Training loss: 2.5610134601593018
Validation loss: 2.3623876392200427

Epoch: 5| Step: 4
Training loss: 2.746673583984375
Validation loss: 2.3868591298339186

Epoch: 5| Step: 5
Training loss: 2.568889617919922
Validation loss: 2.394782445764029

Epoch: 5| Step: 6
Training loss: 2.6202476024627686
Validation loss: 2.402058096342189

Epoch: 5| Step: 7
Training loss: 2.330322027206421
Validation loss: 2.3988536660389235

Epoch: 5| Step: 8
Training loss: 3.009373664855957
Validation loss: 2.372337866854924

Epoch: 5| Step: 9
Training loss: 2.574404239654541
Validation loss: 2.343163505677254

Epoch: 5| Step: 10
Training loss: 2.510065793991089
Validation loss: 2.322153147830758

Epoch: 71| Step: 0
Training loss: 2.262511968612671
Validation loss: 2.3142949842637583

Epoch: 5| Step: 1
Training loss: 2.5687341690063477
Validation loss: 2.313971329760808

Epoch: 5| Step: 2
Training loss: 2.5423598289489746
Validation loss: 2.3069750852482294

Epoch: 5| Step: 3
Training loss: 2.9864542484283447
Validation loss: 2.3113623870316373

Epoch: 5| Step: 4
Training loss: 2.726857900619507
Validation loss: 2.3044136057617846

Epoch: 5| Step: 5
Training loss: 2.817589521408081
Validation loss: 2.3082767430172173

Epoch: 5| Step: 6
Training loss: 2.1162915229797363
Validation loss: 2.307155996240595

Epoch: 5| Step: 7
Training loss: 3.227480411529541
Validation loss: 2.3043380296358498

Epoch: 5| Step: 8
Training loss: 2.1272568702697754
Validation loss: 2.300538232249598

Epoch: 5| Step: 9
Training loss: 2.567124843597412
Validation loss: 2.3016381135550876

Epoch: 5| Step: 10
Training loss: 2.534377098083496
Validation loss: 2.3017614605606243

Epoch: 72| Step: 0
Training loss: 2.6998844146728516
Validation loss: 2.3112365443219423

Epoch: 5| Step: 1
Training loss: 2.3299553394317627
Validation loss: 2.316488556964423

Epoch: 5| Step: 2
Training loss: 2.336531162261963
Validation loss: 2.322023130232288

Epoch: 5| Step: 3
Training loss: 3.0118186473846436
Validation loss: 2.3281225824868805

Epoch: 5| Step: 4
Training loss: 2.3405888080596924
Validation loss: 2.349624215915639

Epoch: 5| Step: 5
Training loss: 2.6949126720428467
Validation loss: 2.3607578815952426

Epoch: 5| Step: 6
Training loss: 2.514237403869629
Validation loss: 2.366209601843229

Epoch: 5| Step: 7
Training loss: 1.9217989444732666
Validation loss: 2.3430818101411224

Epoch: 5| Step: 8
Training loss: 2.673676013946533
Validation loss: 2.335969648053569

Epoch: 5| Step: 9
Training loss: 3.324819564819336
Validation loss: 2.316381344231226

Epoch: 5| Step: 10
Training loss: 2.605684280395508
Validation loss: 2.306106682746641

Epoch: 73| Step: 0
Training loss: 2.633801221847534
Validation loss: 2.3009272698433167

Epoch: 5| Step: 1
Training loss: 2.86015248298645
Validation loss: 2.306439221546214

Epoch: 5| Step: 2
Training loss: 2.6027145385742188
Validation loss: 2.3078840291628273

Epoch: 5| Step: 3
Training loss: 2.648090362548828
Validation loss: 2.2949506646843365

Epoch: 5| Step: 4
Training loss: 2.3258023262023926
Validation loss: 2.2962449327591927

Epoch: 5| Step: 5
Training loss: 2.6893773078918457
Validation loss: 2.2910962309888614

Epoch: 5| Step: 6
Training loss: 1.8684202432632446
Validation loss: 2.290809110928607

Epoch: 5| Step: 7
Training loss: 3.1127867698669434
Validation loss: 2.285422145679433

Epoch: 5| Step: 8
Training loss: 2.6395812034606934
Validation loss: 2.2896823754874607

Epoch: 5| Step: 9
Training loss: 2.177340030670166
Validation loss: 2.2895404292691137

Epoch: 5| Step: 10
Training loss: 2.7898197174072266
Validation loss: 2.2917618341343378

Epoch: 74| Step: 0
Training loss: 2.4846184253692627
Validation loss: 2.2934731693678003

Epoch: 5| Step: 1
Training loss: 2.101362943649292
Validation loss: 2.3007280313840477

Epoch: 5| Step: 2
Training loss: 2.747554063796997
Validation loss: 2.295451036063574

Epoch: 5| Step: 3
Training loss: 2.780823230743408
Validation loss: 2.296922617061164

Epoch: 5| Step: 4
Training loss: 1.976630449295044
Validation loss: 2.2985478742148286

Epoch: 5| Step: 5
Training loss: 3.337338924407959
Validation loss: 2.29892478194288

Epoch: 5| Step: 6
Training loss: 2.697575569152832
Validation loss: 2.316342992167319

Epoch: 5| Step: 7
Training loss: 2.192141056060791
Validation loss: 2.3156427670550603

Epoch: 5| Step: 8
Training loss: 2.8372159004211426
Validation loss: 2.326018202689386

Epoch: 5| Step: 9
Training loss: 2.3176426887512207
Validation loss: 2.322715933604907

Epoch: 5| Step: 10
Training loss: 2.9822921752929688
Validation loss: 2.3337917276608047

Epoch: 75| Step: 0
Training loss: 2.094834566116333
Validation loss: 2.3357811051030315

Epoch: 5| Step: 1
Training loss: 2.4098846912384033
Validation loss: 2.3156369104180285

Epoch: 5| Step: 2
Training loss: 2.728588104248047
Validation loss: 2.3084340428793304

Epoch: 5| Step: 3
Training loss: 1.7582712173461914
Validation loss: 2.3000461516841764

Epoch: 5| Step: 4
Training loss: 2.6029982566833496
Validation loss: 2.293987004987655

Epoch: 5| Step: 5
Training loss: 2.991048812866211
Validation loss: 2.3014869843759844

Epoch: 5| Step: 6
Training loss: 2.57086443901062
Validation loss: 2.289658131137971

Epoch: 5| Step: 7
Training loss: 2.533867597579956
Validation loss: 2.2863876127427623

Epoch: 5| Step: 8
Training loss: 3.06475567817688
Validation loss: 2.2890982448413806

Epoch: 5| Step: 9
Training loss: 2.9089725017547607
Validation loss: 2.275212977522163

Epoch: 5| Step: 10
Training loss: 2.602421522140503
Validation loss: 2.2809270325527398

Epoch: 76| Step: 0
Training loss: 2.565014600753784
Validation loss: 2.279571469112109

Epoch: 5| Step: 1
Training loss: 1.824345350265503
Validation loss: 2.281126444057752

Epoch: 5| Step: 2
Training loss: 2.8187901973724365
Validation loss: 2.2869344552357993

Epoch: 5| Step: 3
Training loss: 3.3846163749694824
Validation loss: 2.2890264846945323

Epoch: 5| Step: 4
Training loss: 3.096829414367676
Validation loss: 2.287288829844485

Epoch: 5| Step: 5
Training loss: 2.1925182342529297
Validation loss: 2.2793955674735447

Epoch: 5| Step: 6
Training loss: 2.0058677196502686
Validation loss: 2.2820405754991757

Epoch: 5| Step: 7
Training loss: 2.7620112895965576
Validation loss: 2.281268068539199

Epoch: 5| Step: 8
Training loss: 2.4396324157714844
Validation loss: 2.2913480984267367

Epoch: 5| Step: 9
Training loss: 2.924677848815918
Validation loss: 2.288432719886944

Epoch: 5| Step: 10
Training loss: 2.0099563598632812
Validation loss: 2.29007206168226

Epoch: 77| Step: 0
Training loss: 2.4065463542938232
Validation loss: 2.2820953399904313

Epoch: 5| Step: 1
Training loss: 2.651245594024658
Validation loss: 2.2775061348433137

Epoch: 5| Step: 2
Training loss: 2.2476742267608643
Validation loss: 2.279242120763307

Epoch: 5| Step: 3
Training loss: 2.6729063987731934
Validation loss: 2.2820546345044206

Epoch: 5| Step: 4
Training loss: 2.8843300342559814
Validation loss: 2.2836443916443856

Epoch: 5| Step: 5
Training loss: 2.561249017715454
Validation loss: 2.2846048929358043

Epoch: 5| Step: 6
Training loss: 2.9860758781433105
Validation loss: 2.297552885547761

Epoch: 5| Step: 7
Training loss: 2.4335525035858154
Validation loss: 2.291645239758235

Epoch: 5| Step: 8
Training loss: 2.1679420471191406
Validation loss: 2.2913607474296325

Epoch: 5| Step: 9
Training loss: 2.506131649017334
Validation loss: 2.287056666548534

Epoch: 5| Step: 10
Training loss: 2.51863431930542
Validation loss: 2.277384611868089

Epoch: 78| Step: 0
Training loss: 2.603729009628296
Validation loss: 2.2728846867879233

Epoch: 5| Step: 1
Training loss: 2.29971981048584
Validation loss: 2.261548367879724

Epoch: 5| Step: 2
Training loss: 2.394937753677368
Validation loss: 2.259499042264877

Epoch: 5| Step: 3
Training loss: 2.465510606765747
Validation loss: 2.258318442170338

Epoch: 5| Step: 4
Training loss: 3.2370498180389404
Validation loss: 2.2571632887727473

Epoch: 5| Step: 5
Training loss: 2.257798433303833
Validation loss: 2.259463241023402

Epoch: 5| Step: 6
Training loss: 3.1415674686431885
Validation loss: 2.249957264110606

Epoch: 5| Step: 7
Training loss: 2.4448227882385254
Validation loss: 2.2531634787077546

Epoch: 5| Step: 8
Training loss: 2.3985042572021484
Validation loss: 2.255346905800604

Epoch: 5| Step: 9
Training loss: 2.4997665882110596
Validation loss: 2.259192714127161

Epoch: 5| Step: 10
Training loss: 2.343515157699585
Validation loss: 2.2872947364725094

Epoch: 79| Step: 0
Training loss: 2.7455756664276123
Validation loss: 2.3137243383674213

Epoch: 5| Step: 1
Training loss: 2.44419527053833
Validation loss: 2.31244912967887

Epoch: 5| Step: 2
Training loss: 2.50835919380188
Validation loss: 2.3211160141934633

Epoch: 5| Step: 3
Training loss: 3.119279384613037
Validation loss: 2.3133369748310377

Epoch: 5| Step: 4
Training loss: 2.3176567554473877
Validation loss: 2.2826256880196194

Epoch: 5| Step: 5
Training loss: 3.0629501342773438
Validation loss: 2.2688132844945437

Epoch: 5| Step: 6
Training loss: 2.4630227088928223
Validation loss: 2.268234929730815

Epoch: 5| Step: 7
Training loss: 2.559331178665161
Validation loss: 2.261230637950282

Epoch: 5| Step: 8
Training loss: 2.069575786590576
Validation loss: 2.2561504969032864

Epoch: 5| Step: 9
Training loss: 2.161921977996826
Validation loss: 2.2529992083067536

Epoch: 5| Step: 10
Training loss: 2.6600685119628906
Validation loss: 2.245150525082824

Epoch: 80| Step: 0
Training loss: 2.854543447494507
Validation loss: 2.248438455725229

Epoch: 5| Step: 1
Training loss: 2.0059409141540527
Validation loss: 2.248570757527505

Epoch: 5| Step: 2
Training loss: 1.9963245391845703
Validation loss: 2.2434493841663485

Epoch: 5| Step: 3
Training loss: 1.9188377857208252
Validation loss: 2.2514333930066837

Epoch: 5| Step: 4
Training loss: 2.4715564250946045
Validation loss: 2.2629442471329884

Epoch: 5| Step: 5
Training loss: 2.3370769023895264
Validation loss: 2.2812704552886305

Epoch: 5| Step: 6
Training loss: 3.099170446395874
Validation loss: 2.277160757331438

Epoch: 5| Step: 7
Training loss: 3.2304909229278564
Validation loss: 2.266117554838939

Epoch: 5| Step: 8
Training loss: 2.2491164207458496
Validation loss: 2.26142716920504

Epoch: 5| Step: 9
Training loss: 2.8179609775543213
Validation loss: 2.257377847548454

Epoch: 5| Step: 10
Training loss: 3.141845703125
Validation loss: 2.2496938500353085

Epoch: 81| Step: 0
Training loss: 2.664433717727661
Validation loss: 2.2480616697701077

Epoch: 5| Step: 1
Training loss: 2.4764373302459717
Validation loss: 2.242245771551645

Epoch: 5| Step: 2
Training loss: 2.5176825523376465
Validation loss: 2.242028826026506

Epoch: 5| Step: 3
Training loss: 2.17077374458313
Validation loss: 2.263563350964618

Epoch: 5| Step: 4
Training loss: 3.067700147628784
Validation loss: 2.287009237914957

Epoch: 5| Step: 5
Training loss: 2.347476005554199
Validation loss: 2.2956955432891846

Epoch: 5| Step: 6
Training loss: 2.119631290435791
Validation loss: 2.2962655226389566

Epoch: 5| Step: 7
Training loss: 2.6118526458740234
Validation loss: 2.30871513325681

Epoch: 5| Step: 8
Training loss: 2.7019338607788086
Validation loss: 2.3025931196828044

Epoch: 5| Step: 9
Training loss: 2.5035061836242676
Validation loss: 2.290785197288759

Epoch: 5| Step: 10
Training loss: 3.005995750427246
Validation loss: 2.25865533274989

Epoch: 82| Step: 0
Training loss: 2.5043325424194336
Validation loss: 2.2451699549152004

Epoch: 5| Step: 1
Training loss: 2.7276549339294434
Validation loss: 2.2452247373519407

Epoch: 5| Step: 2
Training loss: 1.8922748565673828
Validation loss: 2.2480057131859565

Epoch: 5| Step: 3
Training loss: 3.2810752391815186
Validation loss: 2.253639610864783

Epoch: 5| Step: 4
Training loss: 2.420167922973633
Validation loss: 2.246563455109955

Epoch: 5| Step: 5
Training loss: 2.0027735233306885
Validation loss: 2.234873464030604

Epoch: 5| Step: 6
Training loss: 3.0369925498962402
Validation loss: 2.2263840398480816

Epoch: 5| Step: 7
Training loss: 2.091113328933716
Validation loss: 2.222716059736026

Epoch: 5| Step: 8
Training loss: 2.6402382850646973
Validation loss: 2.218470053006244

Epoch: 5| Step: 9
Training loss: 2.6923975944519043
Validation loss: 2.22968473229357

Epoch: 5| Step: 10
Training loss: 2.7398016452789307
Validation loss: 2.2278815546343402

Epoch: 83| Step: 0
Training loss: 2.8125736713409424
Validation loss: 2.240384712014147

Epoch: 5| Step: 1
Training loss: 1.938528299331665
Validation loss: 2.2622775723857265

Epoch: 5| Step: 2
Training loss: 2.8217251300811768
Validation loss: 2.3032093176277737

Epoch: 5| Step: 3
Training loss: 2.4764814376831055
Validation loss: 2.3185783534921627

Epoch: 5| Step: 4
Training loss: 2.736004590988159
Validation loss: 2.321262791592588

Epoch: 5| Step: 5
Training loss: 2.7057251930236816
Validation loss: 2.308754760731933

Epoch: 5| Step: 6
Training loss: 2.6996448040008545
Validation loss: 2.2923672378704114

Epoch: 5| Step: 7
Training loss: 2.901935577392578
Validation loss: 2.239167028857816

Epoch: 5| Step: 8
Training loss: 2.1162257194519043
Validation loss: 2.2264158674465713

Epoch: 5| Step: 9
Training loss: 2.1737418174743652
Validation loss: 2.2229665069169897

Epoch: 5| Step: 10
Training loss: 2.831475257873535
Validation loss: 2.2311960279300647

Epoch: 84| Step: 0
Training loss: 2.656796455383301
Validation loss: 2.2316952431073753

Epoch: 5| Step: 1
Training loss: 2.8200061321258545
Validation loss: 2.2313058555767102

Epoch: 5| Step: 2
Training loss: 2.473565101623535
Validation loss: 2.2263515533939486

Epoch: 5| Step: 3
Training loss: 2.0763659477233887
Validation loss: 2.224316845658005

Epoch: 5| Step: 4
Training loss: 2.3474955558776855
Validation loss: 2.219601100490939

Epoch: 5| Step: 5
Training loss: 2.235567808151245
Validation loss: 2.219806491687734

Epoch: 5| Step: 6
Training loss: 2.499084234237671
Validation loss: 2.2184026728394213

Epoch: 5| Step: 7
Training loss: 3.0909976959228516
Validation loss: 2.219095912030948

Epoch: 5| Step: 8
Training loss: 2.331169843673706
Validation loss: 2.2210545693674395

Epoch: 5| Step: 9
Training loss: 2.841299295425415
Validation loss: 2.227985740989767

Epoch: 5| Step: 10
Training loss: 2.703667640686035
Validation loss: 2.2440331443663566

Epoch: 85| Step: 0
Training loss: 1.9216716289520264
Validation loss: 2.267473607934931

Epoch: 5| Step: 1
Training loss: 2.3886795043945312
Validation loss: 2.2835935623415056

Epoch: 5| Step: 2
Training loss: 2.8604018688201904
Validation loss: 2.32119486665213

Epoch: 5| Step: 3
Training loss: 2.710289716720581
Validation loss: 2.3191765380162064

Epoch: 5| Step: 4
Training loss: 2.1210122108459473
Validation loss: 2.3283722016119186

Epoch: 5| Step: 5
Training loss: 2.8309178352355957
Validation loss: 2.326073669618176

Epoch: 5| Step: 6
Training loss: 3.229271411895752
Validation loss: 2.2618952489668325

Epoch: 5| Step: 7
Training loss: 2.2710800170898438
Validation loss: 2.227984607860606

Epoch: 5| Step: 8
Training loss: 2.8907546997070312
Validation loss: 2.213928258547219

Epoch: 5| Step: 9
Training loss: 2.132694721221924
Validation loss: 2.2091827392578125

Epoch: 5| Step: 10
Training loss: 2.500999927520752
Validation loss: 2.2023050785064697

Epoch: 86| Step: 0
Training loss: 1.7848294973373413
Validation loss: 2.203311509983514

Epoch: 5| Step: 1
Training loss: 2.6040773391723633
Validation loss: 2.2082322438557944

Epoch: 5| Step: 2
Training loss: 3.0446364879608154
Validation loss: 2.2149427834377495

Epoch: 5| Step: 3
Training loss: 2.215364694595337
Validation loss: 2.2161689932628343

Epoch: 5| Step: 4
Training loss: 2.929398775100708
Validation loss: 2.2116793278724916

Epoch: 5| Step: 5
Training loss: 2.9131720066070557
Validation loss: 2.212271918532669

Epoch: 5| Step: 6
Training loss: 2.920466423034668
Validation loss: 2.213248056750144

Epoch: 5| Step: 7
Training loss: 2.1272339820861816
Validation loss: 2.2142302989959717

Epoch: 5| Step: 8
Training loss: 2.97442364692688
Validation loss: 2.228839635848999

Epoch: 5| Step: 9
Training loss: 2.292038679122925
Validation loss: 2.2411270603056876

Epoch: 5| Step: 10
Training loss: 2.0315706729888916
Validation loss: 2.2819765216560772

Epoch: 87| Step: 0
Training loss: 2.4725613594055176
Validation loss: 2.3081085476824033

Epoch: 5| Step: 1
Training loss: 2.4963839054107666
Validation loss: 2.3076657543900194

Epoch: 5| Step: 2
Training loss: 2.5131118297576904
Validation loss: 2.2673739284597416

Epoch: 5| Step: 3
Training loss: 2.427746534347534
Validation loss: 2.2484455031733357

Epoch: 5| Step: 4
Training loss: 2.6783242225646973
Validation loss: 2.2460069143643944

Epoch: 5| Step: 5
Training loss: 2.732907772064209
Validation loss: 2.243072889184439

Epoch: 5| Step: 6
Training loss: 2.8855342864990234
Validation loss: 2.248378053788216

Epoch: 5| Step: 7
Training loss: 2.556802272796631
Validation loss: 2.241074364672425

Epoch: 5| Step: 8
Training loss: 2.913323163986206
Validation loss: 2.240416908776888

Epoch: 5| Step: 9
Training loss: 1.6949564218521118
Validation loss: 2.2392282255234255

Epoch: 5| Step: 10
Training loss: 2.487626075744629
Validation loss: 2.257463860255416

Epoch: 88| Step: 0
Training loss: 2.4898977279663086
Validation loss: 2.283940681847193

Epoch: 5| Step: 1
Training loss: 2.6982572078704834
Validation loss: 2.3045382422785603

Epoch: 5| Step: 2
Training loss: 1.8723602294921875
Validation loss: 2.368472529995826

Epoch: 5| Step: 3
Training loss: 2.4116568565368652
Validation loss: 2.4351244075323946

Epoch: 5| Step: 4
Training loss: 2.922753095626831
Validation loss: 2.435144039892381

Epoch: 5| Step: 5
Training loss: 2.5225791931152344
Validation loss: 2.458555329230524

Epoch: 5| Step: 6
Training loss: 2.723456859588623
Validation loss: 2.393695180134107

Epoch: 5| Step: 7
Training loss: 2.539330005645752
Validation loss: 2.3527983055319837

Epoch: 5| Step: 8
Training loss: 3.016089916229248
Validation loss: 2.262743490998463

Epoch: 5| Step: 9
Training loss: 2.6886415481567383
Validation loss: 2.2417601795606714

Epoch: 5| Step: 10
Training loss: 2.4279606342315674
Validation loss: 2.247648891582284

Epoch: 89| Step: 0
Training loss: 3.0263099670410156
Validation loss: 2.2874065086405766

Epoch: 5| Step: 1
Training loss: 2.631814956665039
Validation loss: 2.3185348946561097

Epoch: 5| Step: 2
Training loss: 3.157744884490967
Validation loss: 2.314510163440499

Epoch: 5| Step: 3
Training loss: 2.3320865631103516
Validation loss: 2.307412770486647

Epoch: 5| Step: 4
Training loss: 2.8586719036102295
Validation loss: 2.2737557195848033

Epoch: 5| Step: 5
Training loss: 2.340684413909912
Validation loss: 2.2466074882015103

Epoch: 5| Step: 6
Training loss: 1.9731794595718384
Validation loss: 2.2307697637106783

Epoch: 5| Step: 7
Training loss: 2.318751573562622
Validation loss: 2.2195190511724

Epoch: 5| Step: 8
Training loss: 2.5116310119628906
Validation loss: 2.2323168695613904

Epoch: 5| Step: 9
Training loss: 2.8817801475524902
Validation loss: 2.234921142619143

Epoch: 5| Step: 10
Training loss: 2.24129319190979
Validation loss: 2.241949709512854

Epoch: 90| Step: 0
Training loss: 2.3515610694885254
Validation loss: 2.2526781071898756

Epoch: 5| Step: 1
Training loss: 2.698209762573242
Validation loss: 2.2519688798535253

Epoch: 5| Step: 2
Training loss: 2.4101462364196777
Validation loss: 2.2621713812633226

Epoch: 5| Step: 3
Training loss: 2.212578535079956
Validation loss: 2.276696466630505

Epoch: 5| Step: 4
Training loss: 2.9123096466064453
Validation loss: 2.2950642698554584

Epoch: 5| Step: 5
Training loss: 2.340372085571289
Validation loss: 2.2412579162146455

Epoch: 5| Step: 6
Training loss: 2.6156435012817383
Validation loss: 2.2228066972506944

Epoch: 5| Step: 7
Training loss: 2.479712724685669
Validation loss: 2.2088505260406004

Epoch: 5| Step: 8
Training loss: 2.3971261978149414
Validation loss: 2.2193563035739365

Epoch: 5| Step: 9
Training loss: 2.754528760910034
Validation loss: 2.214768276419691

Epoch: 5| Step: 10
Training loss: 2.355741500854492
Validation loss: 2.1890398199840257

Epoch: 91| Step: 0
Training loss: 2.600902795791626
Validation loss: 2.17446675480053

Epoch: 5| Step: 1
Training loss: 1.9767366647720337
Validation loss: 2.1777553071257887

Epoch: 5| Step: 2
Training loss: 2.421048641204834
Validation loss: 2.1864875337128997

Epoch: 5| Step: 3
Training loss: 2.6391639709472656
Validation loss: 2.1888064415224138

Epoch: 5| Step: 4
Training loss: 2.6625113487243652
Validation loss: 2.188517011621947

Epoch: 5| Step: 5
Training loss: 2.3040294647216797
Validation loss: 2.192971839699694

Epoch: 5| Step: 6
Training loss: 2.9322381019592285
Validation loss: 2.188476029262748

Epoch: 5| Step: 7
Training loss: 3.016007900238037
Validation loss: 2.188785819597142

Epoch: 5| Step: 8
Training loss: 2.1045608520507812
Validation loss: 2.1877885377535256

Epoch: 5| Step: 9
Training loss: 2.5494675636291504
Validation loss: 2.1849127174705587

Epoch: 5| Step: 10
Training loss: 2.599452495574951
Validation loss: 2.1945700953083653

Epoch: 92| Step: 0
Training loss: 3.2578063011169434
Validation loss: 2.2198439310955744

Epoch: 5| Step: 1
Training loss: 2.746051549911499
Validation loss: 2.277428565486785

Epoch: 5| Step: 2
Training loss: 1.6187976598739624
Validation loss: 2.3265029486789497

Epoch: 5| Step: 3
Training loss: 2.6498217582702637
Validation loss: 2.3558916481592322

Epoch: 5| Step: 4
Training loss: 2.17500638961792
Validation loss: 2.351940684421088

Epoch: 5| Step: 5
Training loss: 2.504354238510132
Validation loss: 2.308992935765174

Epoch: 5| Step: 6
Training loss: 2.3639190196990967
Validation loss: 2.2587903161202707

Epoch: 5| Step: 7
Training loss: 2.6338119506835938
Validation loss: 2.2096347103836718

Epoch: 5| Step: 8
Training loss: 2.980469226837158
Validation loss: 2.1840054911951863

Epoch: 5| Step: 9
Training loss: 1.8849918842315674
Validation loss: 2.174616024058352

Epoch: 5| Step: 10
Training loss: 2.6903939247131348
Validation loss: 2.174804347817616

Epoch: 93| Step: 0
Training loss: 2.3989014625549316
Validation loss: 2.177908376980853

Epoch: 5| Step: 1
Training loss: 2.8625152111053467
Validation loss: 2.179752298580703

Epoch: 5| Step: 2
Training loss: 3.11393666267395
Validation loss: 2.197546421840627

Epoch: 5| Step: 3
Training loss: 2.7226333618164062
Validation loss: 2.197766327088879

Epoch: 5| Step: 4
Training loss: 2.5590643882751465
Validation loss: 2.1988837539508777

Epoch: 5| Step: 5
Training loss: 2.589881420135498
Validation loss: 2.1982068554047616

Epoch: 5| Step: 6
Training loss: 2.409214735031128
Validation loss: 2.19349302271361

Epoch: 5| Step: 7
Training loss: 2.696617603302002
Validation loss: 2.1814588731335056

Epoch: 5| Step: 8
Training loss: 2.228280544281006
Validation loss: 2.1707925065871208

Epoch: 5| Step: 9
Training loss: 2.2808313369750977
Validation loss: 2.171270365356117

Epoch: 5| Step: 10
Training loss: 2.0721683502197266
Validation loss: 2.1689672444456365

Epoch: 94| Step: 0
Training loss: 2.3953185081481934
Validation loss: 2.1737418879744825

Epoch: 5| Step: 1
Training loss: 2.7220299243927
Validation loss: 2.178325007038732

Epoch: 5| Step: 2
Training loss: 2.4088997840881348
Validation loss: 2.1859599390337543

Epoch: 5| Step: 3
Training loss: 2.3053524494171143
Validation loss: 2.1911011818916566

Epoch: 5| Step: 4
Training loss: 2.393925189971924
Validation loss: 2.2511519565377185

Epoch: 5| Step: 5
Training loss: 2.055284261703491
Validation loss: 2.3103984760981735

Epoch: 5| Step: 6
Training loss: 2.7057971954345703
Validation loss: 2.3533367572292203

Epoch: 5| Step: 7
Training loss: 3.278714418411255
Validation loss: 2.353901929752801

Epoch: 5| Step: 8
Training loss: 2.2154839038848877
Validation loss: 2.3140310677148963

Epoch: 5| Step: 9
Training loss: 2.2014405727386475
Validation loss: 2.3052392493012133

Epoch: 5| Step: 10
Training loss: 3.0856947898864746
Validation loss: 2.238502384513937

Epoch: 95| Step: 0
Training loss: 1.8188819885253906
Validation loss: 2.2360408331758235

Epoch: 5| Step: 1
Training loss: 2.1799514293670654
Validation loss: 2.2261057143570273

Epoch: 5| Step: 2
Training loss: 3.1725528240203857
Validation loss: 2.2217298015471427

Epoch: 5| Step: 3
Training loss: 2.567927122116089
Validation loss: 2.2511224233975975

Epoch: 5| Step: 4
Training loss: 2.248117446899414
Validation loss: 2.2370335196936004

Epoch: 5| Step: 5
Training loss: 2.763702869415283
Validation loss: 2.2175006699818436

Epoch: 5| Step: 6
Training loss: 2.569783926010132
Validation loss: 2.1870370834104476

Epoch: 5| Step: 7
Training loss: 2.389979124069214
Validation loss: 2.1971729852819957

Epoch: 5| Step: 8
Training loss: 2.3386096954345703
Validation loss: 2.1850786362924883

Epoch: 5| Step: 9
Training loss: 2.4266164302825928
Validation loss: 2.1767466760450795

Epoch: 5| Step: 10
Training loss: 2.893115758895874
Validation loss: 2.165369256850212

Epoch: 96| Step: 0
Training loss: 2.5948541164398193
Validation loss: 2.1639673876506027

Epoch: 5| Step: 1
Training loss: 2.142810821533203
Validation loss: 2.1627531538727465

Epoch: 5| Step: 2
Training loss: 2.5080668926239014
Validation loss: 2.1660351599416425

Epoch: 5| Step: 3
Training loss: 2.4161601066589355
Validation loss: 2.166925855862197

Epoch: 5| Step: 4
Training loss: 3.2195639610290527
Validation loss: 2.1759520935755905

Epoch: 5| Step: 5
Training loss: 2.5376322269439697
Validation loss: 2.183659120272565

Epoch: 5| Step: 6
Training loss: 2.496168613433838
Validation loss: 2.188500581249114

Epoch: 5| Step: 7
Training loss: 2.4906651973724365
Validation loss: 2.1906828341945523

Epoch: 5| Step: 8
Training loss: 2.556082248687744
Validation loss: 2.1904680549457507

Epoch: 5| Step: 9
Training loss: 2.500762462615967
Validation loss: 2.194470097941737

Epoch: 5| Step: 10
Training loss: 1.7569284439086914
Validation loss: 2.213687076363512

Epoch: 97| Step: 0
Training loss: 2.539480447769165
Validation loss: 2.2326255280484437

Epoch: 5| Step: 1
Training loss: 2.898665428161621
Validation loss: 2.2464332170383905

Epoch: 5| Step: 2
Training loss: 2.4740853309631348
Validation loss: 2.261508931395828

Epoch: 5| Step: 3
Training loss: 2.2115836143493652
Validation loss: 2.240170681348411

Epoch: 5| Step: 4
Training loss: 2.8365721702575684
Validation loss: 2.2412789765224663

Epoch: 5| Step: 5
Training loss: 2.8240063190460205
Validation loss: 2.2462018023255053

Epoch: 5| Step: 6
Training loss: 2.366635799407959
Validation loss: 2.251809222723848

Epoch: 5| Step: 7
Training loss: 1.953438401222229
Validation loss: 2.2658510208129883

Epoch: 5| Step: 8
Training loss: 2.2812137603759766
Validation loss: 2.255390597927955

Epoch: 5| Step: 9
Training loss: 2.727379560470581
Validation loss: 2.206908224731363

Epoch: 5| Step: 10
Training loss: 2.2527904510498047
Validation loss: 2.1823556448823664

Epoch: 98| Step: 0
Training loss: 2.3498995304107666
Validation loss: 2.1519102857958887

Epoch: 5| Step: 1
Training loss: 2.542008876800537
Validation loss: 2.148433349465811

Epoch: 5| Step: 2
Training loss: 2.299163579940796
Validation loss: 2.1368208777519966

Epoch: 5| Step: 3
Training loss: 3.0444300174713135
Validation loss: 2.1440569444369246

Epoch: 5| Step: 4
Training loss: 2.5828700065612793
Validation loss: 2.1394645398662937

Epoch: 5| Step: 5
Training loss: 2.2120518684387207
Validation loss: 2.143221714163339

Epoch: 5| Step: 6
Training loss: 2.862518310546875
Validation loss: 2.148931100804319

Epoch: 5| Step: 7
Training loss: 2.4920058250427246
Validation loss: 2.157566624303018

Epoch: 5| Step: 8
Training loss: 2.1569066047668457
Validation loss: 2.156902861851518

Epoch: 5| Step: 9
Training loss: 2.5997157096862793
Validation loss: 2.1552547511234077

Epoch: 5| Step: 10
Training loss: 2.009218454360962
Validation loss: 2.165571943406136

Epoch: 99| Step: 0
Training loss: 1.9287254810333252
Validation loss: 2.1568675323199202

Epoch: 5| Step: 1
Training loss: 1.9052021503448486
Validation loss: 2.150995631371775

Epoch: 5| Step: 2
Training loss: 2.6948180198669434
Validation loss: 2.146678945069672

Epoch: 5| Step: 3
Training loss: 2.733508348464966
Validation loss: 2.147932731977073

Epoch: 5| Step: 4
Training loss: 2.739095687866211
Validation loss: 2.145460690221479

Epoch: 5| Step: 5
Training loss: 2.619692325592041
Validation loss: 2.1458073303263676

Epoch: 5| Step: 6
Training loss: 2.7085580825805664
Validation loss: 2.15134685526612

Epoch: 5| Step: 7
Training loss: 2.3424322605133057
Validation loss: 2.142606544238265

Epoch: 5| Step: 8
Training loss: 2.477383613586426
Validation loss: 2.1438142689325477

Epoch: 5| Step: 9
Training loss: 2.922912836074829
Validation loss: 2.1612473623726958

Epoch: 5| Step: 10
Training loss: 1.8368886709213257
Validation loss: 2.185901698245797

Epoch: 100| Step: 0
Training loss: 2.082097291946411
Validation loss: 2.2554420591682516

Epoch: 5| Step: 1
Training loss: 2.6385371685028076
Validation loss: 2.2478105791153444

Epoch: 5| Step: 2
Training loss: 2.5396218299865723
Validation loss: 2.2369231562460623

Epoch: 5| Step: 3
Training loss: 2.7104690074920654
Validation loss: 2.226501871180791

Epoch: 5| Step: 4
Training loss: 2.4714152812957764
Validation loss: 2.1722601562417965

Epoch: 5| Step: 5
Training loss: 2.863063335418701
Validation loss: 2.141744711065805

Epoch: 5| Step: 6
Training loss: 2.3576924800872803
Validation loss: 2.1316125521095852

Epoch: 5| Step: 7
Training loss: 2.455122232437134
Validation loss: 2.1345120578683834

Epoch: 5| Step: 8
Training loss: 2.733516216278076
Validation loss: 2.134295827598982

Epoch: 5| Step: 9
Training loss: 2.077083110809326
Validation loss: 2.1435239494487806

Epoch: 5| Step: 10
Training loss: 2.7048556804656982
Validation loss: 2.1536975419649513

Epoch: 101| Step: 0
Training loss: 3.0086283683776855
Validation loss: 2.1541885586195093

Epoch: 5| Step: 1
Training loss: 3.1143102645874023
Validation loss: 2.153955705704228

Epoch: 5| Step: 2
Training loss: 2.5060153007507324
Validation loss: 2.1555841738177883

Epoch: 5| Step: 3
Training loss: 3.051004409790039
Validation loss: 2.151280559519286

Epoch: 5| Step: 4
Training loss: 2.830703020095825
Validation loss: 2.1449403839726604

Epoch: 5| Step: 5
Training loss: 2.2444169521331787
Validation loss: 2.1351341714141188

Epoch: 5| Step: 6
Training loss: 1.4649229049682617
Validation loss: 2.1310603977531515

Epoch: 5| Step: 7
Training loss: 1.9682594537734985
Validation loss: 2.1281934130576348

Epoch: 5| Step: 8
Training loss: 2.2840025424957275
Validation loss: 2.1282461997001403

Epoch: 5| Step: 9
Training loss: 2.4197490215301514
Validation loss: 2.1347527427058064

Epoch: 5| Step: 10
Training loss: 2.6727590560913086
Validation loss: 2.1431847644108597

Epoch: 102| Step: 0
Training loss: 2.1800074577331543
Validation loss: 2.15755549810266

Epoch: 5| Step: 1
Training loss: 2.3359339237213135
Validation loss: 2.175233651232976

Epoch: 5| Step: 2
Training loss: 2.3727669715881348
Validation loss: 2.205022088942989

Epoch: 5| Step: 3
Training loss: 2.4355530738830566
Validation loss: 2.1765974285782024

Epoch: 5| Step: 4
Training loss: 2.4899144172668457
Validation loss: 2.165260539259962

Epoch: 5| Step: 5
Training loss: 2.49912428855896
Validation loss: 2.1501769686257965

Epoch: 5| Step: 6
Training loss: 2.673426389694214
Validation loss: 2.1461010158702893

Epoch: 5| Step: 7
Training loss: 2.480743885040283
Validation loss: 2.141918082391062

Epoch: 5| Step: 8
Training loss: 2.3004984855651855
Validation loss: 2.134565968667307

Epoch: 5| Step: 9
Training loss: 2.347259521484375
Validation loss: 2.1423602181096233

Epoch: 5| Step: 10
Training loss: 2.9770236015319824
Validation loss: 2.135697063579354

Epoch: 103| Step: 0
Training loss: 2.9328408241271973
Validation loss: 2.143472489490304

Epoch: 5| Step: 1
Training loss: 2.291633129119873
Validation loss: 2.1427574849897817

Epoch: 5| Step: 2
Training loss: 2.1652753353118896
Validation loss: 2.1347091890150502

Epoch: 5| Step: 3
Training loss: 2.8323793411254883
Validation loss: 2.13522659578631

Epoch: 5| Step: 4
Training loss: 2.682443618774414
Validation loss: 2.138357534203478

Epoch: 5| Step: 5
Training loss: 1.802727460861206
Validation loss: 2.1436093520092707

Epoch: 5| Step: 6
Training loss: 2.1985793113708496
Validation loss: 2.147479316239716

Epoch: 5| Step: 7
Training loss: 2.67720103263855
Validation loss: 2.1555162527227916

Epoch: 5| Step: 8
Training loss: 2.775477647781372
Validation loss: 2.1731681490457184

Epoch: 5| Step: 9
Training loss: 1.6544727087020874
Validation loss: 2.1769154353808333

Epoch: 5| Step: 10
Training loss: 2.7646944522857666
Validation loss: 2.1622803775213097

Epoch: 104| Step: 0
Training loss: 2.229064702987671
Validation loss: 2.158983143427039

Epoch: 5| Step: 1
Training loss: 2.299107313156128
Validation loss: 2.1506512357342626

Epoch: 5| Step: 2
Training loss: 2.279545307159424
Validation loss: 2.1326234417576946

Epoch: 5| Step: 3
Training loss: 1.9794954061508179
Validation loss: 2.1293310567896855

Epoch: 5| Step: 4
Training loss: 2.72017240524292
Validation loss: 2.1278309424718223

Epoch: 5| Step: 5
Training loss: 2.585657835006714
Validation loss: 2.1451589292095554

Epoch: 5| Step: 6
Training loss: 2.578543186187744
Validation loss: 2.1504678674923476

Epoch: 5| Step: 7
Training loss: 2.3229002952575684
Validation loss: 2.1648859400903024

Epoch: 5| Step: 8
Training loss: 2.575705051422119
Validation loss: 2.1870850209266908

Epoch: 5| Step: 9
Training loss: 2.965097427368164
Validation loss: 2.2019902006272347

Epoch: 5| Step: 10
Training loss: 2.2855403423309326
Validation loss: 2.1925226078238538

Epoch: 105| Step: 0
Training loss: 3.1331849098205566
Validation loss: 2.170595330576743

Epoch: 5| Step: 1
Training loss: 2.1719329357147217
Validation loss: 2.1487385098652174

Epoch: 5| Step: 2
Training loss: 2.9088945388793945
Validation loss: 2.133938730403941

Epoch: 5| Step: 3
Training loss: 1.911550760269165
Validation loss: 2.123306002668155

Epoch: 5| Step: 4
Training loss: 2.5218005180358887
Validation loss: 2.125613953477593

Epoch: 5| Step: 5
Training loss: 2.722238540649414
Validation loss: 2.136051457415345

Epoch: 5| Step: 6
Training loss: 2.369576930999756
Validation loss: 2.1741915543874106

Epoch: 5| Step: 7
Training loss: 2.3603262901306152
Validation loss: 2.197638419366652

Epoch: 5| Step: 8
Training loss: 2.6119320392608643
Validation loss: 2.2291977636275755

Epoch: 5| Step: 9
Training loss: 2.489443778991699
Validation loss: 2.2352860191816926

Epoch: 5| Step: 10
Training loss: 1.59157395362854
Validation loss: 2.1577297077384046

Epoch: 106| Step: 0
Training loss: 2.0339789390563965
Validation loss: 2.123786549414358

Epoch: 5| Step: 1
Training loss: 2.6986706256866455
Validation loss: 2.1149948399554015

Epoch: 5| Step: 2
Training loss: 2.2328455448150635
Validation loss: 2.1090263833281813

Epoch: 5| Step: 3
Training loss: 2.6414220333099365
Validation loss: 2.110729243165703

Epoch: 5| Step: 4
Training loss: 2.3317065238952637
Validation loss: 2.1089248875136017

Epoch: 5| Step: 5
Training loss: 2.816518545150757
Validation loss: 2.114968228083785

Epoch: 5| Step: 6
Training loss: 3.0429463386535645
Validation loss: 2.1068684016504595

Epoch: 5| Step: 7
Training loss: 2.3460402488708496
Validation loss: 2.1039188010718233

Epoch: 5| Step: 8
Training loss: 2.339277744293213
Validation loss: 2.1016742542225826

Epoch: 5| Step: 9
Training loss: 2.088972330093384
Validation loss: 2.105410401539136

Epoch: 5| Step: 10
Training loss: 2.4611332416534424
Validation loss: 2.1132636672707013

Epoch: 107| Step: 0
Training loss: 2.566781759262085
Validation loss: 2.1228525689853135

Epoch: 5| Step: 1
Training loss: 2.139439344406128
Validation loss: 2.1363516238427933

Epoch: 5| Step: 2
Training loss: 2.3704450130462646
Validation loss: 2.1511577303691576

Epoch: 5| Step: 3
Training loss: 2.6180953979492188
Validation loss: 2.166639179311773

Epoch: 5| Step: 4
Training loss: 1.9144020080566406
Validation loss: 2.1647897894664476

Epoch: 5| Step: 5
Training loss: 2.7697761058807373
Validation loss: 2.1717808579885833

Epoch: 5| Step: 6
Training loss: 3.1155219078063965
Validation loss: 2.1508363600700133

Epoch: 5| Step: 7
Training loss: 2.5627923011779785
Validation loss: 2.152716598203105

Epoch: 5| Step: 8
Training loss: 2.594691276550293
Validation loss: 2.153928141440115

Epoch: 5| Step: 9
Training loss: 2.3248603343963623
Validation loss: 2.141048877469955

Epoch: 5| Step: 10
Training loss: 1.7272920608520508
Validation loss: 2.148857590972736

Epoch: 108| Step: 0
Training loss: 2.3916075229644775
Validation loss: 2.1482166346683296

Epoch: 5| Step: 1
Training loss: 2.4862942695617676
Validation loss: 2.139282072744062

Epoch: 5| Step: 2
Training loss: 2.6568055152893066
Validation loss: 2.1321004359952864

Epoch: 5| Step: 3
Training loss: 1.610252022743225
Validation loss: 2.1235985973829865

Epoch: 5| Step: 4
Training loss: 2.012709856033325
Validation loss: 2.128224167772519

Epoch: 5| Step: 5
Training loss: 2.386600971221924
Validation loss: 2.122608543724142

Epoch: 5| Step: 6
Training loss: 2.389478921890259
Validation loss: 2.116520889343754

Epoch: 5| Step: 7
Training loss: 2.542945623397827
Validation loss: 2.1143926779429116

Epoch: 5| Step: 8
Training loss: 2.842113971710205
Validation loss: 2.1120160574554117

Epoch: 5| Step: 9
Training loss: 2.4034554958343506
Validation loss: 2.1147614704665316

Epoch: 5| Step: 10
Training loss: 2.9779109954833984
Validation loss: 2.1205365093805457

Epoch: 109| Step: 0
Training loss: 1.674254059791565
Validation loss: 2.1163334461950485

Epoch: 5| Step: 1
Training loss: 2.35139799118042
Validation loss: 2.1019833703194895

Epoch: 5| Step: 2
Training loss: 2.781663417816162
Validation loss: 2.1002109460933234

Epoch: 5| Step: 3
Training loss: 2.1864116191864014
Validation loss: 2.0976614477813884

Epoch: 5| Step: 4
Training loss: 2.0260281562805176
Validation loss: 2.0948885922790854

Epoch: 5| Step: 5
Training loss: 3.085876226425171
Validation loss: 2.0965100129445395

Epoch: 5| Step: 6
Training loss: 2.506748914718628
Validation loss: 2.1043812408242175

Epoch: 5| Step: 7
Training loss: 2.518728256225586
Validation loss: 2.101163584698913

Epoch: 5| Step: 8
Training loss: 2.3858754634857178
Validation loss: 2.1026096856722267

Epoch: 5| Step: 9
Training loss: 2.106076717376709
Validation loss: 2.101306220536591

Epoch: 5| Step: 10
Training loss: 2.994950294494629
Validation loss: 2.102591879906193

Epoch: 110| Step: 0
Training loss: 2.5857508182525635
Validation loss: 2.110802223605494

Epoch: 5| Step: 1
Training loss: 2.1383697986602783
Validation loss: 2.1041150528897523

Epoch: 5| Step: 2
Training loss: 2.19240140914917
Validation loss: 2.1182648315224597

Epoch: 5| Step: 3
Training loss: 1.984715223312378
Validation loss: 2.1153721142840642

Epoch: 5| Step: 4
Training loss: 2.605360507965088
Validation loss: 2.1304464622210433

Epoch: 5| Step: 5
Training loss: 2.6886589527130127
Validation loss: 2.172919084948878

Epoch: 5| Step: 6
Training loss: 2.4608726501464844
Validation loss: 2.1480820178985596

Epoch: 5| Step: 7
Training loss: 2.4076056480407715
Validation loss: 2.133520803143901

Epoch: 5| Step: 8
Training loss: 2.1779024600982666
Validation loss: 2.110575824655512

Epoch: 5| Step: 9
Training loss: 2.492396116256714
Validation loss: 2.091621378416656

Epoch: 5| Step: 10
Training loss: 2.7246837615966797
Validation loss: 2.0872257114738546

Epoch: 111| Step: 0
Training loss: 1.8578580617904663
Validation loss: 2.0802358042809272

Epoch: 5| Step: 1
Training loss: 2.4871418476104736
Validation loss: 2.084745148176788

Epoch: 5| Step: 2
Training loss: 2.908032178878784
Validation loss: 2.0835931762572257

Epoch: 5| Step: 3
Training loss: 1.95267653465271
Validation loss: 2.085865315570626

Epoch: 5| Step: 4
Training loss: 2.7584023475646973
Validation loss: 2.1004405483122794

Epoch: 5| Step: 5
Training loss: 3.1021647453308105
Validation loss: 2.113872135839155

Epoch: 5| Step: 6
Training loss: 2.3244388103485107
Validation loss: 2.1032303020518315

Epoch: 5| Step: 7
Training loss: 2.279348134994507
Validation loss: 2.0968010092294342

Epoch: 5| Step: 8
Training loss: 2.2095351219177246
Validation loss: 2.0918852231835805

Epoch: 5| Step: 9
Training loss: 2.5478579998016357
Validation loss: 2.097290623572565

Epoch: 5| Step: 10
Training loss: 1.9348442554473877
Validation loss: 2.0947261574447795

Epoch: 112| Step: 0
Training loss: 2.1245903968811035
Validation loss: 2.0916226474187707

Epoch: 5| Step: 1
Training loss: 1.7095295190811157
Validation loss: 2.085320121498518

Epoch: 5| Step: 2
Training loss: 2.443570375442505
Validation loss: 2.086638771077638

Epoch: 5| Step: 3
Training loss: 3.2335433959960938
Validation loss: 2.0879471481487317

Epoch: 5| Step: 4
Training loss: 2.4644312858581543
Validation loss: 2.0865494025650846

Epoch: 5| Step: 5
Training loss: 2.5612080097198486
Validation loss: 2.0883271822365383

Epoch: 5| Step: 6
Training loss: 2.537391424179077
Validation loss: 2.0865558526849233

Epoch: 5| Step: 7
Training loss: 1.7043168544769287
Validation loss: 2.090186334425403

Epoch: 5| Step: 8
Training loss: 1.8655115365982056
Validation loss: 2.094228806034211

Epoch: 5| Step: 9
Training loss: 3.242414951324463
Validation loss: 2.0871367403255996

Epoch: 5| Step: 10
Training loss: 2.3190534114837646
Validation loss: 2.090565389202487

Epoch: 113| Step: 0
Training loss: 2.2968995571136475
Validation loss: 2.0843166253900014

Epoch: 5| Step: 1
Training loss: 2.3501014709472656
Validation loss: 2.077398180961609

Epoch: 5| Step: 2
Training loss: 2.25962495803833
Validation loss: 2.0790384277220695

Epoch: 5| Step: 3
Training loss: 2.2132747173309326
Validation loss: 2.078825073857461

Epoch: 5| Step: 4
Training loss: 2.735433340072632
Validation loss: 2.0809513599641862

Epoch: 5| Step: 5
Training loss: 2.1020140647888184
Validation loss: 2.0798374837444675

Epoch: 5| Step: 6
Training loss: 2.9087376594543457
Validation loss: 2.0799695420008835

Epoch: 5| Step: 7
Training loss: 2.451267719268799
Validation loss: 2.086249633501935

Epoch: 5| Step: 8
Training loss: 2.4601502418518066
Validation loss: 2.1013118015822543

Epoch: 5| Step: 9
Training loss: 2.2513108253479004
Validation loss: 2.103389581044515

Epoch: 5| Step: 10
Training loss: 2.133176803588867
Validation loss: 2.0779864249690885

Epoch: 114| Step: 0
Training loss: 2.2861456871032715
Validation loss: 2.0830845050914313

Epoch: 5| Step: 1
Training loss: 3.3551993370056152
Validation loss: 2.0717244199527207

Epoch: 5| Step: 2
Training loss: 1.854656457901001
Validation loss: 2.081635036776143

Epoch: 5| Step: 3
Training loss: 2.2654669284820557
Validation loss: 2.0797835652546217

Epoch: 5| Step: 4
Training loss: 2.3708205223083496
Validation loss: 2.0753333440390964

Epoch: 5| Step: 5
Training loss: 2.8725264072418213
Validation loss: 2.0831110349265476

Epoch: 5| Step: 6
Training loss: 2.1848552227020264
Validation loss: 2.0846940907098914

Epoch: 5| Step: 7
Training loss: 2.024852991104126
Validation loss: 2.086587805901804

Epoch: 5| Step: 8
Training loss: 2.60170578956604
Validation loss: 2.087124006722563

Epoch: 5| Step: 9
Training loss: 2.2793240547180176
Validation loss: 2.090608009728052

Epoch: 5| Step: 10
Training loss: 1.9409875869750977
Validation loss: 2.0807323481446955

Epoch: 115| Step: 0
Training loss: 1.9415626525878906
Validation loss: 2.0737623168576147

Epoch: 5| Step: 1
Training loss: 2.4796648025512695
Validation loss: 2.0659220398113294

Epoch: 5| Step: 2
Training loss: 2.440944194793701
Validation loss: 2.0664020315293343

Epoch: 5| Step: 3
Training loss: 2.2252578735351562
Validation loss: 2.0637824766097532

Epoch: 5| Step: 4
Training loss: 2.339557647705078
Validation loss: 2.064902141530027

Epoch: 5| Step: 5
Training loss: 2.4977259635925293
Validation loss: 2.085229367338201

Epoch: 5| Step: 6
Training loss: 2.4151127338409424
Validation loss: 2.104451261540895

Epoch: 5| Step: 7
Training loss: 2.1050078868865967
Validation loss: 2.0853181500588693

Epoch: 5| Step: 8
Training loss: 3.081718921661377
Validation loss: 2.0776829104269705

Epoch: 5| Step: 9
Training loss: 2.587275981903076
Validation loss: 2.0806689134208103

Epoch: 5| Step: 10
Training loss: 1.8526463508605957
Validation loss: 2.0762414701523317

Epoch: 116| Step: 0
Training loss: 2.317686080932617
Validation loss: 2.070383069335773

Epoch: 5| Step: 1
Training loss: 2.5472140312194824
Validation loss: 2.0771697387900403

Epoch: 5| Step: 2
Training loss: 2.649198293685913
Validation loss: 2.082417667552989

Epoch: 5| Step: 3
Training loss: 2.3479816913604736
Validation loss: 2.0834929622629637

Epoch: 5| Step: 4
Training loss: 2.629401445388794
Validation loss: 2.0782353724202802

Epoch: 5| Step: 5
Training loss: 2.2913241386413574
Validation loss: 2.100537725674209

Epoch: 5| Step: 6
Training loss: 1.7473253011703491
Validation loss: 2.082094241214055

Epoch: 5| Step: 7
Training loss: 2.296229600906372
Validation loss: 2.0763625829450545

Epoch: 5| Step: 8
Training loss: 2.4642670154571533
Validation loss: 2.087979814057709

Epoch: 5| Step: 9
Training loss: 2.194648027420044
Validation loss: 2.074291950912886

Epoch: 5| Step: 10
Training loss: 2.711822271347046
Validation loss: 2.0777746336434477

Epoch: 117| Step: 0
Training loss: 2.7103919982910156
Validation loss: 2.0845650370403

Epoch: 5| Step: 1
Training loss: 1.8962322473526
Validation loss: 2.081711628103769

Epoch: 5| Step: 2
Training loss: 2.4807305335998535
Validation loss: 2.0835489226925756

Epoch: 5| Step: 3
Training loss: 2.2396535873413086
Validation loss: 2.062411105760964

Epoch: 5| Step: 4
Training loss: 2.72314190864563
Validation loss: 2.0524287813453266

Epoch: 5| Step: 5
Training loss: 1.6446220874786377
Validation loss: 2.0590714472596363

Epoch: 5| Step: 6
Training loss: 2.674750566482544
Validation loss: 2.0537962349512244

Epoch: 5| Step: 7
Training loss: 2.46348237991333
Validation loss: 2.0567184520024124

Epoch: 5| Step: 8
Training loss: 2.3944497108459473
Validation loss: 2.055432099168019

Epoch: 5| Step: 9
Training loss: 2.3831443786621094
Validation loss: 2.0695004655468847

Epoch: 5| Step: 10
Training loss: 2.2568607330322266
Validation loss: 2.0741560100227274

Epoch: 118| Step: 0
Training loss: 2.363945484161377
Validation loss: 2.079330067480764

Epoch: 5| Step: 1
Training loss: 2.682882308959961
Validation loss: 2.0758706062070784

Epoch: 5| Step: 2
Training loss: 2.3946738243103027
Validation loss: 2.0697700605597547

Epoch: 5| Step: 3
Training loss: 2.1492838859558105
Validation loss: 2.0479819415717997

Epoch: 5| Step: 4
Training loss: 2.3025715351104736
Validation loss: 2.0479247659765263

Epoch: 5| Step: 5
Training loss: 2.495838165283203
Validation loss: 2.0474717309398036

Epoch: 5| Step: 6
Training loss: 2.497302532196045
Validation loss: 2.057828228960755

Epoch: 5| Step: 7
Training loss: 2.104717969894409
Validation loss: 2.066879649316111

Epoch: 5| Step: 8
Training loss: 2.465841770172119
Validation loss: 2.048651813178934

Epoch: 5| Step: 9
Training loss: 2.281456708908081
Validation loss: 2.0469755870039745

Epoch: 5| Step: 10
Training loss: 2.2188239097595215
Validation loss: 2.0395581850441555

Epoch: 119| Step: 0
Training loss: 2.3549513816833496
Validation loss: 2.034662751741307

Epoch: 5| Step: 1
Training loss: 2.4990572929382324
Validation loss: 2.038562866949266

Epoch: 5| Step: 2
Training loss: 2.3812801837921143
Validation loss: 2.043402243685979

Epoch: 5| Step: 3
Training loss: 2.176198959350586
Validation loss: 2.0464598030172367

Epoch: 5| Step: 4
Training loss: 2.762606382369995
Validation loss: 2.047869172147525

Epoch: 5| Step: 5
Training loss: 2.1512532234191895
Validation loss: 2.041974711161788

Epoch: 5| Step: 6
Training loss: 1.9970369338989258
Validation loss: 2.0546028793499036

Epoch: 5| Step: 7
Training loss: 2.187196731567383
Validation loss: 2.0582950538204563

Epoch: 5| Step: 8
Training loss: 2.631662607192993
Validation loss: 2.0577132189145653

Epoch: 5| Step: 9
Training loss: 2.6658921241760254
Validation loss: 2.0553039043180403

Epoch: 5| Step: 10
Training loss: 2.0166492462158203
Validation loss: 2.060309653641075

Epoch: 120| Step: 0
Training loss: 2.6489949226379395
Validation loss: 2.062862855131908

Epoch: 5| Step: 1
Training loss: 2.4051666259765625
Validation loss: 2.0744129111689906

Epoch: 5| Step: 2
Training loss: 2.5820846557617188
Validation loss: 2.090803027153015

Epoch: 5| Step: 3
Training loss: 2.9991257190704346
Validation loss: 2.0976268232509656

Epoch: 5| Step: 4
Training loss: 2.5401973724365234
Validation loss: 2.0791804816133235

Epoch: 5| Step: 5
Training loss: 1.9138705730438232
Validation loss: 2.059268487397061

Epoch: 5| Step: 6
Training loss: 1.8914973735809326
Validation loss: 2.0422512715862644

Epoch: 5| Step: 7
Training loss: 2.5695788860321045
Validation loss: 2.0393824474785918

Epoch: 5| Step: 8
Training loss: 2.313660144805908
Validation loss: 2.0440910323973625

Epoch: 5| Step: 9
Training loss: 2.239744186401367
Validation loss: 2.0398506861861034

Epoch: 5| Step: 10
Training loss: 1.6842286586761475
Validation loss: 2.041280011976919

Epoch: 121| Step: 0
Training loss: 2.4107112884521484
Validation loss: 2.048638573256872

Epoch: 5| Step: 1
Training loss: 2.3324601650238037
Validation loss: 2.0498646920727146

Epoch: 5| Step: 2
Training loss: 2.697960376739502
Validation loss: 2.0520154327474613

Epoch: 5| Step: 3
Training loss: 2.2799839973449707
Validation loss: 2.0655766712721957

Epoch: 5| Step: 4
Training loss: 2.9309628009796143
Validation loss: 2.075795206972348

Epoch: 5| Step: 5
Training loss: 1.8400356769561768
Validation loss: 2.0708205059010494

Epoch: 5| Step: 6
Training loss: 2.755387783050537
Validation loss: 2.077206330914651

Epoch: 5| Step: 7
Training loss: 2.203810930252075
Validation loss: 2.0711095615099837

Epoch: 5| Step: 8
Training loss: 1.9501816034317017
Validation loss: 2.0643843835399998

Epoch: 5| Step: 9
Training loss: 1.9703385829925537
Validation loss: 2.067998000370559

Epoch: 5| Step: 10
Training loss: 2.4713382720947266
Validation loss: 2.059091088592365

Epoch: 122| Step: 0
Training loss: 2.46830677986145
Validation loss: 2.0471758688649824

Epoch: 5| Step: 1
Training loss: 2.5217082500457764
Validation loss: 2.02891142137589

Epoch: 5| Step: 2
Training loss: 2.0359272956848145
Validation loss: 2.040142236217376

Epoch: 5| Step: 3
Training loss: 2.266117811203003
Validation loss: 2.033842771284042

Epoch: 5| Step: 4
Training loss: 2.0245256423950195
Validation loss: 2.036711105736353

Epoch: 5| Step: 5
Training loss: 1.974735975265503
Validation loss: 2.0388561397470455

Epoch: 5| Step: 6
Training loss: 2.300602436065674
Validation loss: 2.039700100498815

Epoch: 5| Step: 7
Training loss: 2.845900297164917
Validation loss: 2.040411392847697

Epoch: 5| Step: 8
Training loss: 2.3882594108581543
Validation loss: 2.039627690469065

Epoch: 5| Step: 9
Training loss: 2.781546115875244
Validation loss: 2.0695870307184037

Epoch: 5| Step: 10
Training loss: 2.367863655090332
Validation loss: 2.102263100685612

Epoch: 123| Step: 0
Training loss: 1.7550216913223267
Validation loss: 2.126809638033631

Epoch: 5| Step: 1
Training loss: 2.375321865081787
Validation loss: 2.151929904055852

Epoch: 5| Step: 2
Training loss: 2.300290584564209
Validation loss: 2.16579960238549

Epoch: 5| Step: 3
Training loss: 2.112722635269165
Validation loss: 2.1462383911173832

Epoch: 5| Step: 4
Training loss: 2.6688601970672607
Validation loss: 2.1093252089715775

Epoch: 5| Step: 5
Training loss: 2.561655044555664
Validation loss: 2.0791307880032446

Epoch: 5| Step: 6
Training loss: 2.2421011924743652
Validation loss: 2.0467347304026284

Epoch: 5| Step: 7
Training loss: 2.4943103790283203
Validation loss: 2.0274250379172702

Epoch: 5| Step: 8
Training loss: 2.3569698333740234
Validation loss: 2.0350266707840787

Epoch: 5| Step: 9
Training loss: 2.701871871948242
Validation loss: 2.0315967887960453

Epoch: 5| Step: 10
Training loss: 2.390481948852539
Validation loss: 2.038887234144313

Epoch: 124| Step: 0
Training loss: 2.2499022483825684
Validation loss: 2.0469504351256997

Epoch: 5| Step: 1
Training loss: 2.6314308643341064
Validation loss: 2.0516829900844122

Epoch: 5| Step: 2
Training loss: 2.2699742317199707
Validation loss: 2.052422833699052

Epoch: 5| Step: 3
Training loss: 2.2494308948516846
Validation loss: 2.044223423927061

Epoch: 5| Step: 4
Training loss: 1.7281720638275146
Validation loss: 2.0362206197554067

Epoch: 5| Step: 5
Training loss: 2.8806893825531006
Validation loss: 2.027003152396089

Epoch: 5| Step: 6
Training loss: 2.4189391136169434
Validation loss: 2.024775210247245

Epoch: 5| Step: 7
Training loss: 2.074066638946533
Validation loss: 2.0690179870974634

Epoch: 5| Step: 8
Training loss: 2.973444700241089
Validation loss: 2.1054880554958055

Epoch: 5| Step: 9
Training loss: 1.9525514841079712
Validation loss: 2.1123900182785524

Epoch: 5| Step: 10
Training loss: 3.0652174949645996
Validation loss: 2.1139633373547624

Epoch: 125| Step: 0
Training loss: 1.7950975894927979
Validation loss: 2.1059701237627255

Epoch: 5| Step: 1
Training loss: 2.2540602684020996
Validation loss: 2.08132436198573

Epoch: 5| Step: 2
Training loss: 2.313271999359131
Validation loss: 2.0559049716559787

Epoch: 5| Step: 3
Training loss: 2.5481603145599365
Validation loss: 2.0370167686093237

Epoch: 5| Step: 4
Training loss: 2.8866991996765137
Validation loss: 2.0379682176856586

Epoch: 5| Step: 5
Training loss: 2.2000370025634766
Validation loss: 2.033696110530566

Epoch: 5| Step: 6
Training loss: 2.738375425338745
Validation loss: 2.0335415512002926

Epoch: 5| Step: 7
Training loss: 1.9990355968475342
Validation loss: 2.034751057624817

Epoch: 5| Step: 8
Training loss: 2.876279830932617
Validation loss: 2.0374124357777257

Epoch: 5| Step: 9
Training loss: 2.4502549171447754
Validation loss: 2.039221494428573

Epoch: 5| Step: 10
Training loss: 1.7640269994735718
Validation loss: 2.06950088982941

Epoch: 126| Step: 0
Training loss: 2.226410388946533
Validation loss: 2.0947100936725573

Epoch: 5| Step: 1
Training loss: 2.842088222503662
Validation loss: 2.105361594948717

Epoch: 5| Step: 2
Training loss: 2.3011679649353027
Validation loss: 2.1179050335320095

Epoch: 5| Step: 3
Training loss: 2.526956558227539
Validation loss: 2.118966579437256

Epoch: 5| Step: 4
Training loss: 2.7101187705993652
Validation loss: 2.120627967260217

Epoch: 5| Step: 5
Training loss: 2.11222767829895
Validation loss: 2.10609697270137

Epoch: 5| Step: 6
Training loss: 2.1890411376953125
Validation loss: 2.079099550042101

Epoch: 5| Step: 7
Training loss: 2.755713939666748
Validation loss: 2.04498875910236

Epoch: 5| Step: 8
Training loss: 1.8664684295654297
Validation loss: 2.0318689064313005

Epoch: 5| Step: 9
Training loss: 1.9544219970703125
Validation loss: 2.030347620287249

Epoch: 5| Step: 10
Training loss: 2.4716074466705322
Validation loss: 2.0269140120475524

Epoch: 127| Step: 0
Training loss: 2.65954327583313
Validation loss: 2.0367590650435416

Epoch: 5| Step: 1
Training loss: 2.628922462463379
Validation loss: 2.035263438378611

Epoch: 5| Step: 2
Training loss: 2.5631651878356934
Validation loss: 2.0312497641450618

Epoch: 5| Step: 3
Training loss: 2.3032515048980713
Validation loss: 2.0363527908120105

Epoch: 5| Step: 4
Training loss: 2.525179386138916
Validation loss: 2.0381816561504076

Epoch: 5| Step: 5
Training loss: 2.074814796447754
Validation loss: 2.041445298861432

Epoch: 5| Step: 6
Training loss: 2.294992446899414
Validation loss: 2.0500139472305134

Epoch: 5| Step: 7
Training loss: 2.277100086212158
Validation loss: 2.063797655925956

Epoch: 5| Step: 8
Training loss: 2.5489211082458496
Validation loss: 2.0778293891619612

Epoch: 5| Step: 9
Training loss: 1.8204708099365234
Validation loss: 2.0792702192901285

Epoch: 5| Step: 10
Training loss: 2.0492100715637207
Validation loss: 2.0919771784095356

Epoch: 128| Step: 0
Training loss: 2.1928305625915527
Validation loss: 2.0729478328458724

Epoch: 5| Step: 1
Training loss: 2.443291187286377
Validation loss: 2.0529068567419566

Epoch: 5| Step: 2
Training loss: 1.886103630065918
Validation loss: 2.0278451891355616

Epoch: 5| Step: 3
Training loss: 2.409423828125
Validation loss: 2.008626332847021

Epoch: 5| Step: 4
Training loss: 2.4417712688446045
Validation loss: 2.011920352135935

Epoch: 5| Step: 5
Training loss: 1.9359239339828491
Validation loss: 2.008722371952508

Epoch: 5| Step: 6
Training loss: 2.171795606613159
Validation loss: 2.009667420899996

Epoch: 5| Step: 7
Training loss: 2.36126708984375
Validation loss: 2.01645734489605

Epoch: 5| Step: 8
Training loss: 2.4608681201934814
Validation loss: 2.0236270607158704

Epoch: 5| Step: 9
Training loss: 2.9169702529907227
Validation loss: 2.0329734715082313

Epoch: 5| Step: 10
Training loss: 2.5494046211242676
Validation loss: 2.0562361004532024

Epoch: 129| Step: 0
Training loss: 2.093372106552124
Validation loss: 2.0589154510087866

Epoch: 5| Step: 1
Training loss: 2.088768720626831
Validation loss: 2.0554876788969962

Epoch: 5| Step: 2
Training loss: 2.309967041015625
Validation loss: 2.056650653962166

Epoch: 5| Step: 3
Training loss: 2.4784164428710938
Validation loss: 2.0469176666710966

Epoch: 5| Step: 4
Training loss: 2.574937105178833
Validation loss: 2.03659208871985

Epoch: 5| Step: 5
Training loss: 2.45893931388855
Validation loss: 2.0177892497790757

Epoch: 5| Step: 6
Training loss: 2.3248982429504395
Validation loss: 2.0085390678016086

Epoch: 5| Step: 7
Training loss: 1.7903047800064087
Validation loss: 2.0023259629485426

Epoch: 5| Step: 8
Training loss: 1.9968417882919312
Validation loss: 1.997501040017733

Epoch: 5| Step: 9
Training loss: 2.6463685035705566
Validation loss: 2.0014486159047773

Epoch: 5| Step: 10
Training loss: 2.664684295654297
Validation loss: 1.9988326398275231

Epoch: 130| Step: 0
Training loss: 1.6808109283447266
Validation loss: 2.0002136102286716

Epoch: 5| Step: 1
Training loss: 2.463026762008667
Validation loss: 1.9998273977669336

Epoch: 5| Step: 2
Training loss: 1.791926622390747
Validation loss: 2.0014459779185634

Epoch: 5| Step: 3
Training loss: 2.4496560096740723
Validation loss: 2.0031672703322543

Epoch: 5| Step: 4
Training loss: 2.027113199234009
Validation loss: 2.005455838736667

Epoch: 5| Step: 5
Training loss: 2.6638214588165283
Validation loss: 2.016843616321523

Epoch: 5| Step: 6
Training loss: 2.3955039978027344
Validation loss: 2.0206587006968837

Epoch: 5| Step: 7
Training loss: 2.3033032417297363
Validation loss: 2.008036798046481

Epoch: 5| Step: 8
Training loss: 2.4951977729797363
Validation loss: 2.0053636950831257

Epoch: 5| Step: 9
Training loss: 2.6923866271972656
Validation loss: 2.0074679056803384

Epoch: 5| Step: 10
Training loss: 2.528817892074585
Validation loss: 1.9904983274398311

Epoch: 131| Step: 0
Training loss: 2.219059705734253
Validation loss: 1.9909747992792437

Epoch: 5| Step: 1
Training loss: 2.4022762775421143
Validation loss: 1.9983112965860674

Epoch: 5| Step: 2
Training loss: 2.6352038383483887
Validation loss: 2.005594934186628

Epoch: 5| Step: 3
Training loss: 1.9427744150161743
Validation loss: 2.0179408647680797

Epoch: 5| Step: 4
Training loss: 1.9991319179534912
Validation loss: 2.0117751885485906

Epoch: 5| Step: 5
Training loss: 3.1035685539245605
Validation loss: 2.011015724110347

Epoch: 5| Step: 6
Training loss: 3.06200909614563
Validation loss: 2.010133333103631

Epoch: 5| Step: 7
Training loss: 2.373365879058838
Validation loss: 1.9970129715499056

Epoch: 5| Step: 8
Training loss: 1.4362643957138062
Validation loss: 1.9930657148361206

Epoch: 5| Step: 9
Training loss: 2.130448341369629
Validation loss: 1.995150282818784

Epoch: 5| Step: 10
Training loss: 2.046590566635132
Validation loss: 1.9830948742487098

Epoch: 132| Step: 0
Training loss: 2.309812068939209
Validation loss: 1.9878648532334195

Epoch: 5| Step: 1
Training loss: 2.1006407737731934
Validation loss: 1.9870046210545365

Epoch: 5| Step: 2
Training loss: 2.2947497367858887
Validation loss: 1.9849002156206357

Epoch: 5| Step: 3
Training loss: 1.6882013082504272
Validation loss: 1.992314455329731

Epoch: 5| Step: 4
Training loss: 1.863997220993042
Validation loss: 2.003353823897659

Epoch: 5| Step: 5
Training loss: 2.437997817993164
Validation loss: 1.9997688672875846

Epoch: 5| Step: 6
Training loss: 2.483124256134033
Validation loss: 2.0100085504593386

Epoch: 5| Step: 7
Training loss: 2.1318936347961426
Validation loss: 2.0298526043533

Epoch: 5| Step: 8
Training loss: 2.5761449337005615
Validation loss: 2.02166409133583

Epoch: 5| Step: 9
Training loss: 2.685248851776123
Validation loss: 1.9950895847812775

Epoch: 5| Step: 10
Training loss: 2.8955237865448
Validation loss: 1.9830355567316855

Epoch: 133| Step: 0
Training loss: 1.9443851709365845
Validation loss: 1.9823816207147413

Epoch: 5| Step: 1
Training loss: 3.089322090148926
Validation loss: 1.975393327333594

Epoch: 5| Step: 2
Training loss: 2.0479681491851807
Validation loss: 1.978561706440423

Epoch: 5| Step: 3
Training loss: 1.9246070384979248
Validation loss: 1.986381023160873

Epoch: 5| Step: 4
Training loss: 1.947995901107788
Validation loss: 1.9859192858460128

Epoch: 5| Step: 5
Training loss: 2.476229190826416
Validation loss: 2.0217164921504196

Epoch: 5| Step: 6
Training loss: 2.3618850708007812
Validation loss: 2.051058421852768

Epoch: 5| Step: 7
Training loss: 2.198166608810425
Validation loss: 2.0552998665840394

Epoch: 5| Step: 8
Training loss: 2.3124899864196777
Validation loss: 2.0814680668615524

Epoch: 5| Step: 9
Training loss: 3.062542676925659
Validation loss: 2.128919098966865

Epoch: 5| Step: 10
Training loss: 2.317732334136963
Validation loss: 2.0679981759799424

Epoch: 134| Step: 0
Training loss: 2.2254202365875244
Validation loss: 2.0276780410479476

Epoch: 5| Step: 1
Training loss: 1.64585280418396
Validation loss: 2.014000964421098

Epoch: 5| Step: 2
Training loss: 2.7928147315979004
Validation loss: 2.025056133988083

Epoch: 5| Step: 3
Training loss: 2.155789613723755
Validation loss: 2.023131005225643

Epoch: 5| Step: 4
Training loss: 2.247447967529297
Validation loss: 2.025932796539799

Epoch: 5| Step: 5
Training loss: 2.134185314178467
Validation loss: 2.030215301821309

Epoch: 5| Step: 6
Training loss: 2.2110259532928467
Validation loss: 2.043899236186858

Epoch: 5| Step: 7
Training loss: 2.5229287147521973
Validation loss: 2.036620516930857

Epoch: 5| Step: 8
Training loss: 3.163450241088867
Validation loss: 2.01554093053264

Epoch: 5| Step: 9
Training loss: 2.547110080718994
Validation loss: 2.0082501044837375

Epoch: 5| Step: 10
Training loss: 2.57784104347229
Validation loss: 2.007553203131563

Epoch: 135| Step: 0
Training loss: 1.9620482921600342
Validation loss: 2.0054611031727125

Epoch: 5| Step: 1
Training loss: 2.694450855255127
Validation loss: 2.0253611636418167

Epoch: 5| Step: 2
Training loss: 2.3919055461883545
Validation loss: 2.053255283704368

Epoch: 5| Step: 3
Training loss: 2.602733850479126
Validation loss: 2.070889434506816

Epoch: 5| Step: 4
Training loss: 2.6943678855895996
Validation loss: 2.0992809982709986

Epoch: 5| Step: 5
Training loss: 2.3518519401550293
Validation loss: 2.094633453635759

Epoch: 5| Step: 6
Training loss: 2.4165501594543457
Validation loss: 2.078278123691518

Epoch: 5| Step: 7
Training loss: 2.1382737159729004
Validation loss: 2.0450946079787387

Epoch: 5| Step: 8
Training loss: 1.9272253513336182
Validation loss: 2.010205876442694

Epoch: 5| Step: 9
Training loss: 2.420581340789795
Validation loss: 1.9844975695815137

Epoch: 5| Step: 10
Training loss: 2.1924452781677246
Validation loss: 1.9891561769670056

Epoch: 136| Step: 0
Training loss: 1.9521080255508423
Validation loss: 2.005157768085439

Epoch: 5| Step: 1
Training loss: 2.886270046234131
Validation loss: 2.0079059254738594

Epoch: 5| Step: 2
Training loss: 1.9197393655776978
Validation loss: 2.003222874415818

Epoch: 5| Step: 3
Training loss: 3.2675673961639404
Validation loss: 2.0003748888610513

Epoch: 5| Step: 4
Training loss: 2.4600796699523926
Validation loss: 1.9998616300603396

Epoch: 5| Step: 5
Training loss: 2.4284815788269043
Validation loss: 1.9906644308438866

Epoch: 5| Step: 6
Training loss: 1.4028091430664062
Validation loss: 1.9751953335218533

Epoch: 5| Step: 7
Training loss: 2.6917166709899902
Validation loss: 1.9702730665924728

Epoch: 5| Step: 8
Training loss: 2.428703784942627
Validation loss: 1.9744046721407162

Epoch: 5| Step: 9
Training loss: 2.05523419380188
Validation loss: 2.0063043435414634

Epoch: 5| Step: 10
Training loss: 2.3100550174713135
Validation loss: 2.049569978508898

Epoch: 137| Step: 0
Training loss: 2.565371036529541
Validation loss: 2.0849808800605034

Epoch: 5| Step: 1
Training loss: 2.516439914703369
Validation loss: 2.0874427992810487

Epoch: 5| Step: 2
Training loss: 2.669891595840454
Validation loss: 2.0993138115893126

Epoch: 5| Step: 3
Training loss: 1.8753235340118408
Validation loss: 2.125795704062267

Epoch: 5| Step: 4
Training loss: 2.1291251182556152
Validation loss: 2.0738021532694497

Epoch: 5| Step: 5
Training loss: 2.611820936203003
Validation loss: 2.011302063542028

Epoch: 5| Step: 6
Training loss: 2.5791447162628174
Validation loss: 1.9778847207305252

Epoch: 5| Step: 7
Training loss: 2.57066011428833
Validation loss: 1.9696462192843038

Epoch: 5| Step: 8
Training loss: 1.9860213994979858
Validation loss: 1.973213872601909

Epoch: 5| Step: 9
Training loss: 2.220923662185669
Validation loss: 1.9858334846394037

Epoch: 5| Step: 10
Training loss: 2.1176304817199707
Validation loss: 1.9938177216437556

Epoch: 138| Step: 0
Training loss: 1.7368167638778687
Validation loss: 2.0028043062456193

Epoch: 5| Step: 1
Training loss: 2.045196294784546
Validation loss: 1.998704691087046

Epoch: 5| Step: 2
Training loss: 2.673842668533325
Validation loss: 1.9890388750260877

Epoch: 5| Step: 3
Training loss: 2.16339111328125
Validation loss: 1.9895223686772008

Epoch: 5| Step: 4
Training loss: 2.1409339904785156
Validation loss: 1.9886724615609774

Epoch: 5| Step: 5
Training loss: 2.9653193950653076
Validation loss: 1.9825258049913632

Epoch: 5| Step: 6
Training loss: 2.49654483795166
Validation loss: 1.9806080646412347

Epoch: 5| Step: 7
Training loss: 2.9461328983306885
Validation loss: 1.995605173931327

Epoch: 5| Step: 8
Training loss: 2.212306261062622
Validation loss: 2.0163151551318426

Epoch: 5| Step: 9
Training loss: 2.1680588722229004
Validation loss: 2.029203612317321

Epoch: 5| Step: 10
Training loss: 2.366246461868286
Validation loss: 2.0391477410511305

Epoch: 139| Step: 0
Training loss: 2.2170894145965576
Validation loss: 2.0648803172572965

Epoch: 5| Step: 1
Training loss: 2.300014019012451
Validation loss: 2.077659865861298

Epoch: 5| Step: 2
Training loss: 2.199068069458008
Validation loss: 2.076790190512134

Epoch: 5| Step: 3
Training loss: 2.2508809566497803
Validation loss: 2.071063797960999

Epoch: 5| Step: 4
Training loss: 2.1358485221862793
Validation loss: 2.074464859501008

Epoch: 5| Step: 5
Training loss: 3.087695360183716
Validation loss: 2.05820873988572

Epoch: 5| Step: 6
Training loss: 1.9258289337158203
Validation loss: 2.061496091145341

Epoch: 5| Step: 7
Training loss: 2.788316011428833
Validation loss: 2.070370771551645

Epoch: 5| Step: 8
Training loss: 2.273439884185791
Validation loss: 2.0997982102055706

Epoch: 5| Step: 9
Training loss: 2.6339046955108643
Validation loss: 2.062685792164136

Epoch: 5| Step: 10
Training loss: 2.0813326835632324
Validation loss: 2.033770425345308

Epoch: 140| Step: 0
Training loss: 2.6038432121276855
Validation loss: 2.0236038084953063

Epoch: 5| Step: 1
Training loss: 2.9206957817077637
Validation loss: 2.0084928774064585

Epoch: 5| Step: 2
Training loss: 1.8696262836456299
Validation loss: 1.9996240164643975

Epoch: 5| Step: 3
Training loss: 2.9612908363342285
Validation loss: 1.9985880903018418

Epoch: 5| Step: 4
Training loss: 1.627135992050171
Validation loss: 1.9974481815932899

Epoch: 5| Step: 5
Training loss: 2.7682645320892334
Validation loss: 2.0217027407820507

Epoch: 5| Step: 6
Training loss: 1.9514272212982178
Validation loss: 2.022528777840317

Epoch: 5| Step: 7
Training loss: 2.6282947063446045
Validation loss: 2.015677176496034

Epoch: 5| Step: 8
Training loss: 1.8932937383651733
Validation loss: 2.01301662383541

Epoch: 5| Step: 9
Training loss: 1.894425630569458
Validation loss: 2.0064242847504152

Epoch: 5| Step: 10
Training loss: 2.2868518829345703
Validation loss: 1.996096500786402

Epoch: 141| Step: 0
Training loss: 1.8987839221954346
Validation loss: 1.992804015836408

Epoch: 5| Step: 1
Training loss: 2.4380104541778564
Validation loss: 1.9821912268156647

Epoch: 5| Step: 2
Training loss: 2.937196969985962
Validation loss: 1.9856144151379984

Epoch: 5| Step: 3
Training loss: 2.5378823280334473
Validation loss: 1.969637640060917

Epoch: 5| Step: 4
Training loss: 2.6639297008514404
Validation loss: 1.9638097837407102

Epoch: 5| Step: 5
Training loss: 2.948241710662842
Validation loss: 1.9632244353653283

Epoch: 5| Step: 6
Training loss: 1.8357441425323486
Validation loss: 1.9608176139093214

Epoch: 5| Step: 7
Training loss: 1.6417267322540283
Validation loss: 1.9778650294068039

Epoch: 5| Step: 8
Training loss: 2.4145219326019287
Validation loss: 1.981498379861155

Epoch: 5| Step: 9
Training loss: 2.1182363033294678
Validation loss: 1.9829548969063708

Epoch: 5| Step: 10
Training loss: 1.9854291677474976
Validation loss: 1.9702543955977245

Epoch: 142| Step: 0
Training loss: 1.4068479537963867
Validation loss: 1.9553152579133228

Epoch: 5| Step: 1
Training loss: 1.874352216720581
Validation loss: 1.9512400845045685

Epoch: 5| Step: 2
Training loss: 2.5104594230651855
Validation loss: 1.945064139622514

Epoch: 5| Step: 3
Training loss: 2.2544052600860596
Validation loss: 1.9492663811611872

Epoch: 5| Step: 4
Training loss: 2.8263864517211914
Validation loss: 1.961410307115124

Epoch: 5| Step: 5
Training loss: 2.5575318336486816
Validation loss: 1.965088955817684

Epoch: 5| Step: 6
Training loss: 1.998263955116272
Validation loss: 1.956377428065064

Epoch: 5| Step: 7
Training loss: 2.1127915382385254
Validation loss: 1.9517837801287252

Epoch: 5| Step: 8
Training loss: 2.1299118995666504
Validation loss: 1.9491581429717362

Epoch: 5| Step: 9
Training loss: 2.8422048091888428
Validation loss: 1.9676312297903082

Epoch: 5| Step: 10
Training loss: 2.9505863189697266
Validation loss: 1.973169413946008

Epoch: 143| Step: 0
Training loss: 2.3734471797943115
Validation loss: 1.9917182576271795

Epoch: 5| Step: 1
Training loss: 2.7615225315093994
Validation loss: 1.9913084019896805

Epoch: 5| Step: 2
Training loss: 2.282505512237549
Validation loss: 1.9957809755879063

Epoch: 5| Step: 3
Training loss: 2.6230993270874023
Validation loss: 2.0050189982178392

Epoch: 5| Step: 4
Training loss: 2.1710801124572754
Validation loss: 1.9990653120061403

Epoch: 5| Step: 5
Training loss: 1.803375244140625
Validation loss: 1.9832607341069046

Epoch: 5| Step: 6
Training loss: 2.4717440605163574
Validation loss: 1.9777304562189246

Epoch: 5| Step: 7
Training loss: 1.4177076816558838
Validation loss: 1.9755136479613602

Epoch: 5| Step: 8
Training loss: 2.7781503200531006
Validation loss: 1.9759030470284082

Epoch: 5| Step: 9
Training loss: 1.832522988319397
Validation loss: 1.9716338842145857

Epoch: 5| Step: 10
Training loss: 2.5425612926483154
Validation loss: 1.963189576261787

Epoch: 144| Step: 0
Training loss: 2.081913471221924
Validation loss: 1.9630729972675283

Epoch: 5| Step: 1
Training loss: 2.635821580886841
Validation loss: 1.9615206923536075

Epoch: 5| Step: 2
Training loss: 2.2391223907470703
Validation loss: 1.9609829892394364

Epoch: 5| Step: 3
Training loss: 2.1174731254577637
Validation loss: 1.9585791198156213

Epoch: 5| Step: 4
Training loss: 2.920809507369995
Validation loss: 1.957375080354752

Epoch: 5| Step: 5
Training loss: 1.8297150135040283
Validation loss: 1.9690542221069336

Epoch: 5| Step: 6
Training loss: 1.9224884510040283
Validation loss: 1.9659409087191346

Epoch: 5| Step: 7
Training loss: 2.3459413051605225
Validation loss: 1.959095912594949

Epoch: 5| Step: 8
Training loss: 2.5556626319885254
Validation loss: 1.9645656052456106

Epoch: 5| Step: 9
Training loss: 2.2458384037017822
Validation loss: 1.966957628086049

Epoch: 5| Step: 10
Training loss: 1.9808378219604492
Validation loss: 1.9837402118149625

Epoch: 145| Step: 0
Training loss: 2.7591066360473633
Validation loss: 1.9931032196167977

Epoch: 5| Step: 1
Training loss: 2.5912861824035645
Validation loss: 2.003295511327764

Epoch: 5| Step: 2
Training loss: 2.0802485942840576
Validation loss: 2.0049373565181607

Epoch: 5| Step: 3
Training loss: 2.2277987003326416
Validation loss: 1.9923462508827128

Epoch: 5| Step: 4
Training loss: 2.367490530014038
Validation loss: 1.9652151548734276

Epoch: 5| Step: 5
Training loss: 2.5514633655548096
Validation loss: 1.9451797264878468

Epoch: 5| Step: 6
Training loss: 2.278271198272705
Validation loss: 1.9373894199248283

Epoch: 5| Step: 7
Training loss: 1.7110226154327393
Validation loss: 1.9375236008756904

Epoch: 5| Step: 8
Training loss: 2.1245083808898926
Validation loss: 1.9388895573154572

Epoch: 5| Step: 9
Training loss: 1.9534037113189697
Validation loss: 1.9370902558808685

Epoch: 5| Step: 10
Training loss: 2.3880786895751953
Validation loss: 1.9396465837314565

Epoch: 146| Step: 0
Training loss: 1.8415648937225342
Validation loss: 1.9401284225525395

Epoch: 5| Step: 1
Training loss: 2.3981425762176514
Validation loss: 1.9408222847087409

Epoch: 5| Step: 2
Training loss: 2.7487881183624268
Validation loss: 1.9575360564775364

Epoch: 5| Step: 3
Training loss: 2.757063627243042
Validation loss: 1.965670991969365

Epoch: 5| Step: 4
Training loss: 2.116764545440674
Validation loss: 1.9651921128713956

Epoch: 5| Step: 5
Training loss: 1.6519548892974854
Validation loss: 1.9699403867926648

Epoch: 5| Step: 6
Training loss: 2.496796131134033
Validation loss: 1.9667787064788163

Epoch: 5| Step: 7
Training loss: 2.1757757663726807
Validation loss: 1.973041993315502

Epoch: 5| Step: 8
Training loss: 2.4465043544769287
Validation loss: 1.9619844882718978

Epoch: 5| Step: 9
Training loss: 2.0210232734680176
Validation loss: 1.9490831321285618

Epoch: 5| Step: 10
Training loss: 2.0943779945373535
Validation loss: 1.9452314863922775

Epoch: 147| Step: 0
Training loss: 2.6472482681274414
Validation loss: 1.9438391782904183

Epoch: 5| Step: 1
Training loss: 3.0857152938842773
Validation loss: 1.955039930599992

Epoch: 5| Step: 2
Training loss: 2.2864022254943848
Validation loss: 1.9511941197097942

Epoch: 5| Step: 3
Training loss: 2.0117006301879883
Validation loss: 1.9546672195516608

Epoch: 5| Step: 4
Training loss: 2.3318874835968018
Validation loss: 1.9529198344035814

Epoch: 5| Step: 5
Training loss: 2.1427173614501953
Validation loss: 1.9505719446366834

Epoch: 5| Step: 6
Training loss: 2.0564491748809814
Validation loss: 1.940919994026102

Epoch: 5| Step: 7
Training loss: 1.9768264293670654
Validation loss: 1.9388894240061443

Epoch: 5| Step: 8
Training loss: 1.7426878213882446
Validation loss: 1.9438385501984627

Epoch: 5| Step: 9
Training loss: 1.8894052505493164
Validation loss: 1.9518001797378703

Epoch: 5| Step: 10
Training loss: 2.537148952484131
Validation loss: 1.9534816434306483

Epoch: 148| Step: 0
Training loss: 1.843069076538086
Validation loss: 1.962944112798219

Epoch: 5| Step: 1
Training loss: 1.9035625457763672
Validation loss: 1.9647585576580417

Epoch: 5| Step: 2
Training loss: 2.027750015258789
Validation loss: 1.96795908481844

Epoch: 5| Step: 3
Training loss: 1.9422687292099
Validation loss: 1.9760349976119174

Epoch: 5| Step: 4
Training loss: 3.203234910964966
Validation loss: 1.9877135240903465

Epoch: 5| Step: 5
Training loss: 2.4110195636749268
Validation loss: 1.9932558780075402

Epoch: 5| Step: 6
Training loss: 2.0422322750091553
Validation loss: 1.9935801593206262

Epoch: 5| Step: 7
Training loss: 2.14789080619812
Validation loss: 1.9883269033124369

Epoch: 5| Step: 8
Training loss: 2.6846060752868652
Validation loss: 1.982325630803262

Epoch: 5| Step: 9
Training loss: 2.073791027069092
Validation loss: 1.9664790425249326

Epoch: 5| Step: 10
Training loss: 2.395719528198242
Validation loss: 1.954029248606774

Epoch: 149| Step: 0
Training loss: 1.9797500371932983
Validation loss: 1.9465570860011603

Epoch: 5| Step: 1
Training loss: 2.078824758529663
Validation loss: 1.9552585617188485

Epoch: 5| Step: 2
Training loss: 2.2261404991149902
Validation loss: 1.955498210845455

Epoch: 5| Step: 3
Training loss: 1.9434131383895874
Validation loss: 1.951284723897134

Epoch: 5| Step: 4
Training loss: 2.105696678161621
Validation loss: 1.9572938462739349

Epoch: 5| Step: 5
Training loss: 2.4562416076660156
Validation loss: 1.9850874241962229

Epoch: 5| Step: 6
Training loss: 2.248624324798584
Validation loss: 1.998268090268617

Epoch: 5| Step: 7
Training loss: 2.248178243637085
Validation loss: 2.0106031561410553

Epoch: 5| Step: 8
Training loss: 2.7288758754730225
Validation loss: 2.0190470449386106

Epoch: 5| Step: 9
Training loss: 2.642895460128784
Validation loss: 2.0095630820079515

Epoch: 5| Step: 10
Training loss: 2.1048431396484375
Validation loss: 2.023349408180483

Epoch: 150| Step: 0
Training loss: 1.799146294593811
Validation loss: 2.020944062099662

Epoch: 5| Step: 1
Training loss: 1.3766244649887085
Validation loss: 1.977392993947511

Epoch: 5| Step: 2
Training loss: 2.7171623706817627
Validation loss: 1.9711538604510728

Epoch: 5| Step: 3
Training loss: 2.2179160118103027
Validation loss: 1.9511282238908993

Epoch: 5| Step: 4
Training loss: 1.4713908433914185
Validation loss: 1.9330996377493745

Epoch: 5| Step: 5
Training loss: 2.947364330291748
Validation loss: 1.9480918581767748

Epoch: 5| Step: 6
Training loss: 2.8935749530792236
Validation loss: 1.9501292051807526

Epoch: 5| Step: 7
Training loss: 2.370617389678955
Validation loss: 1.9612805561352802

Epoch: 5| Step: 8
Training loss: 2.791313648223877
Validation loss: 1.959516473995742

Epoch: 5| Step: 9
Training loss: 2.2622909545898438
Validation loss: 1.9472903833594373

Epoch: 5| Step: 10
Training loss: 1.8768284320831299
Validation loss: 1.9397525069534138

Epoch: 151| Step: 0
Training loss: 3.0752084255218506
Validation loss: 1.9391386380759619

Epoch: 5| Step: 1
Training loss: 2.2781312465667725
Validation loss: 1.9507158033309444

Epoch: 5| Step: 2
Training loss: 1.699517011642456
Validation loss: 1.9924422681972545

Epoch: 5| Step: 3
Training loss: 2.867732524871826
Validation loss: 2.014849337198401

Epoch: 5| Step: 4
Training loss: 1.5752664804458618
Validation loss: 1.9985923254361717

Epoch: 5| Step: 5
Training loss: 1.600351333618164
Validation loss: 1.9932486100863385

Epoch: 5| Step: 6
Training loss: 2.5146617889404297
Validation loss: 1.9731950785524102

Epoch: 5| Step: 7
Training loss: 2.678766965866089
Validation loss: 1.9829432451596825

Epoch: 5| Step: 8
Training loss: 2.004725933074951
Validation loss: 1.9652056130029822

Epoch: 5| Step: 9
Training loss: 2.3084187507629395
Validation loss: 1.9640512030611756

Epoch: 5| Step: 10
Training loss: 1.835646390914917
Validation loss: 1.9546885054598573

Epoch: 152| Step: 0
Training loss: 1.2641615867614746
Validation loss: 1.952311283798628

Epoch: 5| Step: 1
Training loss: 1.580231785774231
Validation loss: 1.9636968758798414

Epoch: 5| Step: 2
Training loss: 2.235422134399414
Validation loss: 1.9798142525457567

Epoch: 5| Step: 3
Training loss: 2.244133949279785
Validation loss: 2.029746678567702

Epoch: 5| Step: 4
Training loss: 2.3663482666015625
Validation loss: 2.0746050650073635

Epoch: 5| Step: 5
Training loss: 3.2906837463378906
Validation loss: 2.0777102619089107

Epoch: 5| Step: 6
Training loss: 2.3468844890594482
Validation loss: 2.0459503819865565

Epoch: 5| Step: 7
Training loss: 2.477663278579712
Validation loss: 1.9982647882994784

Epoch: 5| Step: 8
Training loss: 1.9290316104888916
Validation loss: 1.9848261366608322

Epoch: 5| Step: 9
Training loss: 2.558454990386963
Validation loss: 1.9732485407142228

Epoch: 5| Step: 10
Training loss: 2.591280221939087
Validation loss: 1.9705769669625066

Epoch: 153| Step: 0
Training loss: 1.9760783910751343
Validation loss: 1.951734899192728

Epoch: 5| Step: 1
Training loss: 2.5947093963623047
Validation loss: 1.953996935198384

Epoch: 5| Step: 2
Training loss: 1.9645071029663086
Validation loss: 1.9506745376894552

Epoch: 5| Step: 3
Training loss: 2.031501293182373
Validation loss: 1.9588157746099657

Epoch: 5| Step: 4
Training loss: 1.994234323501587
Validation loss: 1.9549814308843305

Epoch: 5| Step: 5
Training loss: 2.4078526496887207
Validation loss: 1.9596008293090328

Epoch: 5| Step: 6
Training loss: 2.26867938041687
Validation loss: 1.9617427267054075

Epoch: 5| Step: 7
Training loss: 2.2467918395996094
Validation loss: 1.960402911709201

Epoch: 5| Step: 8
Training loss: 2.82554030418396
Validation loss: 1.9627328316370647

Epoch: 5| Step: 9
Training loss: 1.8130886554718018
Validation loss: 1.9595973748032764

Epoch: 5| Step: 10
Training loss: 2.0320346355438232
Validation loss: 1.9701521499182588

Epoch: 154| Step: 0
Training loss: 2.3876290321350098
Validation loss: 1.9763995319284418

Epoch: 5| Step: 1
Training loss: 2.3869850635528564
Validation loss: 1.9713698740928405

Epoch: 5| Step: 2
Training loss: 2.1356759071350098
Validation loss: 1.962588748624248

Epoch: 5| Step: 3
Training loss: 2.5623650550842285
Validation loss: 1.9531283750328967

Epoch: 5| Step: 4
Training loss: 2.061227321624756
Validation loss: 1.9540739033811836

Epoch: 5| Step: 5
Training loss: 2.168147563934326
Validation loss: 1.9516345198436449

Epoch: 5| Step: 6
Training loss: 1.9281867742538452
Validation loss: 1.9471696333218647

Epoch: 5| Step: 7
Training loss: 2.0421130657196045
Validation loss: 1.9435144291129163

Epoch: 5| Step: 8
Training loss: 2.7045836448669434
Validation loss: 1.9407495144874818

Epoch: 5| Step: 9
Training loss: 2.0716891288757324
Validation loss: 1.94349076414621

Epoch: 5| Step: 10
Training loss: 2.0485987663269043
Validation loss: 1.9308454669931883

Epoch: 155| Step: 0
Training loss: 2.0453991889953613
Validation loss: 1.9358273885583366

Epoch: 5| Step: 1
Training loss: 2.488752841949463
Validation loss: 1.9461178138691893

Epoch: 5| Step: 2
Training loss: 2.2166731357574463
Validation loss: 1.959798046337661

Epoch: 5| Step: 3
Training loss: 1.8384166955947876
Validation loss: 1.961766557026935

Epoch: 5| Step: 4
Training loss: 2.272639036178589
Validation loss: 1.9651835836390013

Epoch: 5| Step: 5
Training loss: 2.0559849739074707
Validation loss: 1.9492780213714929

Epoch: 5| Step: 6
Training loss: 2.4365944862365723
Validation loss: 1.937420524576659

Epoch: 5| Step: 7
Training loss: 2.322568416595459
Validation loss: 1.927893131009994

Epoch: 5| Step: 8
Training loss: 1.7478832006454468
Validation loss: 1.9209156574741486

Epoch: 5| Step: 9
Training loss: 3.017444133758545
Validation loss: 1.9159359188490017

Epoch: 5| Step: 10
Training loss: 1.8907997608184814
Validation loss: 1.9167400419071157

Epoch: 156| Step: 0
Training loss: 2.5458788871765137
Validation loss: 1.931435223548643

Epoch: 5| Step: 1
Training loss: 1.7463347911834717
Validation loss: 1.9508335090452624

Epoch: 5| Step: 2
Training loss: 2.472093105316162
Validation loss: 1.9622625368897633

Epoch: 5| Step: 3
Training loss: 2.1068952083587646
Validation loss: 1.9644517308922225

Epoch: 5| Step: 4
Training loss: 2.407099962234497
Validation loss: 1.960844885918402

Epoch: 5| Step: 5
Training loss: 1.938889741897583
Validation loss: 1.9436527939252957

Epoch: 5| Step: 6
Training loss: 2.2389678955078125
Validation loss: 1.9316331840330554

Epoch: 5| Step: 7
Training loss: 2.7310004234313965
Validation loss: 1.9186309088942826

Epoch: 5| Step: 8
Training loss: 2.0646510124206543
Validation loss: 1.9252683539544382

Epoch: 5| Step: 9
Training loss: 1.9490264654159546
Validation loss: 1.9254492072648899

Epoch: 5| Step: 10
Training loss: 1.9123331308364868
Validation loss: 1.9239345647955453

Epoch: 157| Step: 0
Training loss: 2.6275506019592285
Validation loss: 1.927263735443033

Epoch: 5| Step: 1
Training loss: 2.1410939693450928
Validation loss: 1.9297323816566057

Epoch: 5| Step: 2
Training loss: 1.6363309621810913
Validation loss: 1.9313779043894943

Epoch: 5| Step: 3
Training loss: 2.6133110523223877
Validation loss: 1.9411717691729147

Epoch: 5| Step: 4
Training loss: 2.2767245769500732
Validation loss: 1.9387241704489595

Epoch: 5| Step: 5
Training loss: 2.349571704864502
Validation loss: 1.9351296424865723

Epoch: 5| Step: 6
Training loss: 1.7236818075180054
Validation loss: 1.9255852058369627

Epoch: 5| Step: 7
Training loss: 2.1156885623931885
Validation loss: 1.9263779963216474

Epoch: 5| Step: 8
Training loss: 2.1747453212738037
Validation loss: 1.9299105213534447

Epoch: 5| Step: 9
Training loss: 2.2999191284179688
Validation loss: 1.9337648422487321

Epoch: 5| Step: 10
Training loss: 1.8526257276535034
Validation loss: 1.9328090888197704

Epoch: 158| Step: 0
Training loss: 1.5692386627197266
Validation loss: 1.9365790864472747

Epoch: 5| Step: 1
Training loss: 2.08579158782959
Validation loss: 1.9563273742634764

Epoch: 5| Step: 2
Training loss: 2.402996778488159
Validation loss: 1.9416504970160864

Epoch: 5| Step: 3
Training loss: 2.759242534637451
Validation loss: 1.950251874103341

Epoch: 5| Step: 4
Training loss: 2.100670337677002
Validation loss: 1.9420400922016432

Epoch: 5| Step: 5
Training loss: 2.270293712615967
Validation loss: 1.944653308519753

Epoch: 5| Step: 6
Training loss: 1.9980335235595703
Validation loss: 1.9404516373911211

Epoch: 5| Step: 7
Training loss: 2.5318679809570312
Validation loss: 1.9479351415429065

Epoch: 5| Step: 8
Training loss: 1.8909895420074463
Validation loss: 1.9527279330838112

Epoch: 5| Step: 9
Training loss: 2.5989832878112793
Validation loss: 1.951424301311534

Epoch: 5| Step: 10
Training loss: 1.3839412927627563
Validation loss: 1.9522225997781242

Epoch: 159| Step: 0
Training loss: 2.183854341506958
Validation loss: 1.9462819176335489

Epoch: 5| Step: 1
Training loss: 2.233820915222168
Validation loss: 1.9415679644512873

Epoch: 5| Step: 2
Training loss: 1.9742202758789062
Validation loss: 1.9366910226883427

Epoch: 5| Step: 3
Training loss: 2.041219472885132
Validation loss: 1.9315594819284254

Epoch: 5| Step: 4
Training loss: 2.5082385540008545
Validation loss: 1.933315054062874

Epoch: 5| Step: 5
Training loss: 2.256305694580078
Validation loss: 1.9348937285843717

Epoch: 5| Step: 6
Training loss: 2.155452013015747
Validation loss: 1.9498510847809494

Epoch: 5| Step: 7
Training loss: 2.116187334060669
Validation loss: 1.9413302777915873

Epoch: 5| Step: 8
Training loss: 2.0304348468780518
Validation loss: 1.9700912198712748

Epoch: 5| Step: 9
Training loss: 2.060045003890991
Validation loss: 1.979720054134246

Epoch: 5| Step: 10
Training loss: 1.9879984855651855
Validation loss: 1.9858908550713652

Epoch: 160| Step: 0
Training loss: 2.57452392578125
Validation loss: 1.9611321495425316

Epoch: 5| Step: 1
Training loss: 2.358318328857422
Validation loss: 1.9488026275429675

Epoch: 5| Step: 2
Training loss: 2.0088820457458496
Validation loss: 1.957824243012295

Epoch: 5| Step: 3
Training loss: 1.9587703943252563
Validation loss: 1.9411095188510032

Epoch: 5| Step: 4
Training loss: 2.0489184856414795
Validation loss: 1.94359250222483

Epoch: 5| Step: 5
Training loss: 2.701965808868408
Validation loss: 1.9406879883940502

Epoch: 5| Step: 6
Training loss: 2.37250018119812
Validation loss: 1.9319875112143896

Epoch: 5| Step: 7
Training loss: 1.7753312587738037
Validation loss: 1.9357244994050713

Epoch: 5| Step: 8
Training loss: 1.5430877208709717
Validation loss: 1.9297554108404344

Epoch: 5| Step: 9
Training loss: 2.530923366546631
Validation loss: 1.936982403519333

Epoch: 5| Step: 10
Training loss: 1.5180301666259766
Validation loss: 1.9269050410998765

Epoch: 161| Step: 0
Training loss: 2.3634305000305176
Validation loss: 1.931249008383802

Epoch: 5| Step: 1
Training loss: 1.6465076208114624
Validation loss: 1.9319125503622077

Epoch: 5| Step: 2
Training loss: 1.630753755569458
Validation loss: 1.9322342077891033

Epoch: 5| Step: 3
Training loss: 2.2194817066192627
Validation loss: 1.9292981714330695

Epoch: 5| Step: 4
Training loss: 2.1547274589538574
Validation loss: 1.9190341682844265

Epoch: 5| Step: 5
Training loss: 1.6333786249160767
Validation loss: 1.9314691802506805

Epoch: 5| Step: 6
Training loss: 2.560063123703003
Validation loss: 1.9519010231059084

Epoch: 5| Step: 7
Training loss: 2.422886848449707
Validation loss: 1.9809086399693643

Epoch: 5| Step: 8
Training loss: 2.1473536491394043
Validation loss: 1.9986329591402443

Epoch: 5| Step: 9
Training loss: 2.565417528152466
Validation loss: 2.022353743994108

Epoch: 5| Step: 10
Training loss: 2.0758626461029053
Validation loss: 2.035782124406548

Epoch: 162| Step: 0
Training loss: 1.9802213907241821
Validation loss: 2.0136781815559632

Epoch: 5| Step: 1
Training loss: 2.6020801067352295
Validation loss: 2.0098812016107703

Epoch: 5| Step: 2
Training loss: 3.0588183403015137
Validation loss: 1.9996132991647209

Epoch: 5| Step: 3
Training loss: 1.610838532447815
Validation loss: 1.9823188986829532

Epoch: 5| Step: 4
Training loss: 1.7002897262573242
Validation loss: 1.9550128854731077

Epoch: 5| Step: 5
Training loss: 2.418898820877075
Validation loss: 1.9350768340531217

Epoch: 5| Step: 6
Training loss: 1.7212488651275635
Validation loss: 1.9233304787707586

Epoch: 5| Step: 7
Training loss: 2.1680750846862793
Validation loss: 1.9244265607608262

Epoch: 5| Step: 8
Training loss: 2.1150472164154053
Validation loss: 1.9162212238516858

Epoch: 5| Step: 9
Training loss: 2.247910737991333
Validation loss: 1.9156702269789994

Epoch: 5| Step: 10
Training loss: 2.0399041175842285
Validation loss: 1.9090215698365243

Epoch: 163| Step: 0
Training loss: 2.1145377159118652
Validation loss: 1.9104382991790771

Epoch: 5| Step: 1
Training loss: 2.641289234161377
Validation loss: 1.9205780054933281

Epoch: 5| Step: 2
Training loss: 2.335209608078003
Validation loss: 1.933341787707421

Epoch: 5| Step: 3
Training loss: 2.1879074573516846
Validation loss: 1.946781736548229

Epoch: 5| Step: 4
Training loss: 1.8200321197509766
Validation loss: 1.9801975578390143

Epoch: 5| Step: 5
Training loss: 2.073223114013672
Validation loss: 1.9641147621216313

Epoch: 5| Step: 6
Training loss: 2.1483986377716064
Validation loss: 1.9665273389508646

Epoch: 5| Step: 7
Training loss: 2.035747766494751
Validation loss: 1.9685062887848064

Epoch: 5| Step: 8
Training loss: 1.9396727085113525
Validation loss: 1.9492406896365586

Epoch: 5| Step: 9
Training loss: 2.2484681606292725
Validation loss: 1.8999931120103406

Epoch: 5| Step: 10
Training loss: 2.256704807281494
Validation loss: 1.9405699955519808

Epoch: 164| Step: 0
Training loss: 2.1880393028259277
Validation loss: 1.9719219541036954

Epoch: 5| Step: 1
Training loss: 3.1131348609924316
Validation loss: 2.0019139935893397

Epoch: 5| Step: 2
Training loss: 2.0426278114318848
Validation loss: 2.0375721787893646

Epoch: 5| Step: 3
Training loss: 1.934949517250061
Validation loss: 2.0314775551519086

Epoch: 5| Step: 4
Training loss: 2.5042226314544678
Validation loss: 1.9810165743674002

Epoch: 5| Step: 5
Training loss: 2.07749605178833
Validation loss: 1.9340138166181502

Epoch: 5| Step: 6
Training loss: 2.113358974456787
Validation loss: 1.8917128193762995

Epoch: 5| Step: 7
Training loss: 1.846663236618042
Validation loss: 1.9245963122255059

Epoch: 5| Step: 8
Training loss: 2.3971080780029297
Validation loss: 1.9950880645423807

Epoch: 5| Step: 9
Training loss: 1.9829086065292358
Validation loss: 2.048618857578565

Epoch: 5| Step: 10
Training loss: 2.429417371749878
Validation loss: 2.100289547315208

Epoch: 165| Step: 0
Training loss: 2.8854293823242188
Validation loss: 2.072672269677603

Epoch: 5| Step: 1
Training loss: 2.296407461166382
Validation loss: 2.021506255672824

Epoch: 5| Step: 2
Training loss: 1.940565824508667
Validation loss: 1.9815203643614245

Epoch: 5| Step: 3
Training loss: 1.5988775491714478
Validation loss: 1.9038301014131116

Epoch: 5| Step: 4
Training loss: 2.315035820007324
Validation loss: 1.896978941015018

Epoch: 5| Step: 5
Training loss: 2.069153308868408
Validation loss: 1.8901686424850135

Epoch: 5| Step: 6
Training loss: 1.849660873413086
Validation loss: 1.898684282456675

Epoch: 5| Step: 7
Training loss: 2.4126954078674316
Validation loss: 1.8918629051536642

Epoch: 5| Step: 8
Training loss: 1.8904564380645752
Validation loss: 1.8907306707033547

Epoch: 5| Step: 9
Training loss: 2.3008971214294434
Validation loss: 1.905083002582673

Epoch: 5| Step: 10
Training loss: 2.5139999389648438
Validation loss: 1.909004266544055

Epoch: 166| Step: 0
Training loss: 2.329601764678955
Validation loss: 1.9383650197777698

Epoch: 5| Step: 1
Training loss: 2.0274484157562256
Validation loss: 1.974989386015041

Epoch: 5| Step: 2
Training loss: 1.8246753215789795
Validation loss: 1.9782903258518507

Epoch: 5| Step: 3
Training loss: 2.3420615196228027
Validation loss: 1.9543778486149286

Epoch: 5| Step: 4
Training loss: 2.7943825721740723
Validation loss: 1.947175689922866

Epoch: 5| Step: 5
Training loss: 2.2457830905914307
Validation loss: 1.9330006030298048

Epoch: 5| Step: 6
Training loss: 2.5881400108337402
Validation loss: 1.9273902113719652

Epoch: 5| Step: 7
Training loss: 1.944706678390503
Validation loss: 1.9303333400398173

Epoch: 5| Step: 8
Training loss: 1.3159024715423584
Validation loss: 1.9252241593535229

Epoch: 5| Step: 9
Training loss: 1.8058840036392212
Validation loss: 1.9309687101712791

Epoch: 5| Step: 10
Training loss: 2.529017925262451
Validation loss: 1.9418087467070548

Epoch: 167| Step: 0
Training loss: 2.3448679447174072
Validation loss: 1.944310983022054

Epoch: 5| Step: 1
Training loss: 2.085385799407959
Validation loss: 1.9496014336104035

Epoch: 5| Step: 2
Training loss: 2.159511089324951
Validation loss: 1.949404908764747

Epoch: 5| Step: 3
Training loss: 1.818489670753479
Validation loss: 1.9343175080514723

Epoch: 5| Step: 4
Training loss: 1.9874626398086548
Validation loss: 1.9311285390648791

Epoch: 5| Step: 5
Training loss: 2.101977825164795
Validation loss: 1.9251641970808788

Epoch: 5| Step: 6
Training loss: 1.965036392211914
Validation loss: 1.9365425776409846

Epoch: 5| Step: 7
Training loss: 1.6556628942489624
Validation loss: 1.959230306327984

Epoch: 5| Step: 8
Training loss: 1.7330433130264282
Validation loss: 1.9567193587621052

Epoch: 5| Step: 9
Training loss: 2.270463705062866
Validation loss: 1.9609149194532824

Epoch: 5| Step: 10
Training loss: 3.119630813598633
Validation loss: 1.956297005376508

Epoch: 168| Step: 0
Training loss: 1.6493909358978271
Validation loss: 1.983133872350057

Epoch: 5| Step: 1
Training loss: 1.3787637948989868
Validation loss: 1.9752803630726312

Epoch: 5| Step: 2
Training loss: 2.7948718070983887
Validation loss: 1.98292512278403

Epoch: 5| Step: 3
Training loss: 1.8317842483520508
Validation loss: 1.9882337252298992

Epoch: 5| Step: 4
Training loss: 2.696531295776367
Validation loss: 1.9847808243125997

Epoch: 5| Step: 5
Training loss: 2.0524468421936035
Validation loss: 1.9773997658042497

Epoch: 5| Step: 6
Training loss: 2.3770179748535156
Validation loss: 1.9647353118465793

Epoch: 5| Step: 7
Training loss: 1.7211658954620361
Validation loss: 1.9503395224130282

Epoch: 5| Step: 8
Training loss: 2.633357286453247
Validation loss: 1.9337123286339544

Epoch: 5| Step: 9
Training loss: 1.78788161277771
Validation loss: 1.9222067607346403

Epoch: 5| Step: 10
Training loss: 2.0853629112243652
Validation loss: 1.92516157960379

Epoch: 169| Step: 0
Training loss: 2.548130512237549
Validation loss: 1.9277382384064377

Epoch: 5| Step: 1
Training loss: 1.8847339153289795
Validation loss: 1.9278473392609627

Epoch: 5| Step: 2
Training loss: 1.8261865377426147
Validation loss: 1.9440265599117483

Epoch: 5| Step: 3
Training loss: 1.885048270225525
Validation loss: 1.914395611773255

Epoch: 5| Step: 4
Training loss: 1.9019088745117188
Validation loss: 1.9206076091335667

Epoch: 5| Step: 5
Training loss: 2.108271598815918
Validation loss: 1.9121548680848972

Epoch: 5| Step: 6
Training loss: 2.0863537788391113
Validation loss: 1.9400170349305677

Epoch: 5| Step: 7
Training loss: 1.7381194829940796
Validation loss: 1.9564141445262457

Epoch: 5| Step: 8
Training loss: 1.880092978477478
Validation loss: 1.9665698018125308

Epoch: 5| Step: 9
Training loss: 2.3959875106811523
Validation loss: 1.9835729009361678

Epoch: 5| Step: 10
Training loss: 2.7291221618652344
Validation loss: 1.9602535488784953

Epoch: 170| Step: 0
Training loss: 1.561960220336914
Validation loss: 1.959028604210064

Epoch: 5| Step: 1
Training loss: 2.24137544631958
Validation loss: 1.9671859613028906

Epoch: 5| Step: 2
Training loss: 1.2284228801727295
Validation loss: 1.9785733556234708

Epoch: 5| Step: 3
Training loss: 1.7940864562988281
Validation loss: 1.9865449410612865

Epoch: 5| Step: 4
Training loss: 2.2264599800109863
Validation loss: 1.9979276221285585

Epoch: 5| Step: 5
Training loss: 2.5019171237945557
Validation loss: 1.9718384973464473

Epoch: 5| Step: 6
Training loss: 2.606104612350464
Validation loss: 1.971655717460058

Epoch: 5| Step: 7
Training loss: 2.654533863067627
Validation loss: 1.9567077057335966

Epoch: 5| Step: 8
Training loss: 1.863329529762268
Validation loss: 1.9546682475715556

Epoch: 5| Step: 9
Training loss: 2.132875442504883
Validation loss: 1.9773487634556268

Epoch: 5| Step: 10
Training loss: 2.3535826206207275
Validation loss: 2.005525004479193

Epoch: 171| Step: 0
Training loss: 2.084926128387451
Validation loss: 2.0435858016373007

Epoch: 5| Step: 1
Training loss: 2.150887966156006
Validation loss: 2.0442024097647717

Epoch: 5| Step: 2
Training loss: 2.686361312866211
Validation loss: 2.0322082593876827

Epoch: 5| Step: 3
Training loss: 2.2728934288024902
Validation loss: 1.9737671831602692

Epoch: 5| Step: 4
Training loss: 1.5430508852005005
Validation loss: 1.9110817409330798

Epoch: 5| Step: 5
Training loss: 1.728183388710022
Validation loss: 1.9014310516336912

Epoch: 5| Step: 6
Training loss: 1.9301131963729858
Validation loss: 1.9490160967714043

Epoch: 5| Step: 7
Training loss: 1.9513118267059326
Validation loss: 1.9604144480920607

Epoch: 5| Step: 8
Training loss: 2.5032782554626465
Validation loss: 1.9645606343464186

Epoch: 5| Step: 9
Training loss: 2.637294054031372
Validation loss: 1.9522777347154514

Epoch: 5| Step: 10
Training loss: 2.288907289505005
Validation loss: 1.9410718000063332

Epoch: 172| Step: 0
Training loss: 2.1117992401123047
Validation loss: 1.9261522959637385

Epoch: 5| Step: 1
Training loss: 2.2644660472869873
Validation loss: 1.8903917689477243

Epoch: 5| Step: 2
Training loss: 2.8243720531463623
Validation loss: 1.8715528493286462

Epoch: 5| Step: 3
Training loss: 1.8450950384140015
Validation loss: 1.8759117305919688

Epoch: 5| Step: 4
Training loss: 1.3579154014587402
Validation loss: 1.8769520213527064

Epoch: 5| Step: 5
Training loss: 2.0985653400421143
Validation loss: 1.8883573547486336

Epoch: 5| Step: 6
Training loss: 2.2985427379608154
Validation loss: 1.8947284836922922

Epoch: 5| Step: 7
Training loss: 1.9220588207244873
Validation loss: 1.908292701167445

Epoch: 5| Step: 8
Training loss: 1.6363775730133057
Validation loss: 1.9349796259275047

Epoch: 5| Step: 9
Training loss: 2.3959951400756836
Validation loss: 1.945869609873782

Epoch: 5| Step: 10
Training loss: 2.304231882095337
Validation loss: 1.9598389287148752

Epoch: 173| Step: 0
Training loss: 2.7127296924591064
Validation loss: 1.9748301172769198

Epoch: 5| Step: 1
Training loss: 1.753469705581665
Validation loss: 1.991091428264495

Epoch: 5| Step: 2
Training loss: 2.518085241317749
Validation loss: 2.018032876394128

Epoch: 5| Step: 3
Training loss: 1.9506200551986694
Validation loss: 2.0322265086635465

Epoch: 5| Step: 4
Training loss: 2.031923770904541
Validation loss: 2.021894854883994

Epoch: 5| Step: 5
Training loss: 2.0126705169677734
Validation loss: 2.0003823336734565

Epoch: 5| Step: 6
Training loss: 2.231071949005127
Validation loss: 1.9813044699289466

Epoch: 5| Step: 7
Training loss: 2.3035616874694824
Validation loss: 1.9569974022526895

Epoch: 5| Step: 8
Training loss: 2.1540050506591797
Validation loss: 1.9749845279160367

Epoch: 5| Step: 9
Training loss: 1.6074482202529907
Validation loss: 1.9603901614425003

Epoch: 5| Step: 10
Training loss: 1.9509063959121704
Validation loss: 1.9504827119970833

Epoch: 174| Step: 0
Training loss: 1.9168307781219482
Validation loss: 1.938549546785252

Epoch: 5| Step: 1
Training loss: 2.133716106414795
Validation loss: 1.9385429889925065

Epoch: 5| Step: 2
Training loss: 1.7041877508163452
Validation loss: 1.9245951457690167

Epoch: 5| Step: 3
Training loss: 2.201023578643799
Validation loss: 1.9322548438143987

Epoch: 5| Step: 4
Training loss: 2.1798882484436035
Validation loss: 1.9207455291542956

Epoch: 5| Step: 5
Training loss: 1.961408257484436
Validation loss: 1.936878586328158

Epoch: 5| Step: 6
Training loss: 2.53363299369812
Validation loss: 1.9325450569070795

Epoch: 5| Step: 7
Training loss: 1.6126177310943604
Validation loss: 1.9365818039063485

Epoch: 5| Step: 8
Training loss: 1.5666722059249878
Validation loss: 1.9504930485961258

Epoch: 5| Step: 9
Training loss: 2.6228604316711426
Validation loss: 1.9689966709383073

Epoch: 5| Step: 10
Training loss: 2.1153602600097656
Validation loss: 1.992792797344987

Epoch: 175| Step: 0
Training loss: 1.9965336322784424
Validation loss: 2.002053347967004

Epoch: 5| Step: 1
Training loss: 2.3602819442749023
Validation loss: 2.0031939680858324

Epoch: 5| Step: 2
Training loss: 1.6975446939468384
Validation loss: 2.009887117211537

Epoch: 5| Step: 3
Training loss: 1.8710085153579712
Validation loss: 1.998086433256826

Epoch: 5| Step: 4
Training loss: 1.722799301147461
Validation loss: 1.9958286311036797

Epoch: 5| Step: 5
Training loss: 2.587002992630005
Validation loss: 1.992158282187677

Epoch: 5| Step: 6
Training loss: 2.036869525909424
Validation loss: 1.9851559900468396

Epoch: 5| Step: 7
Training loss: 1.6183173656463623
Validation loss: 1.9820508828727148

Epoch: 5| Step: 8
Training loss: 2.3199241161346436
Validation loss: 1.9915202176699074

Epoch: 5| Step: 9
Training loss: 2.1646728515625
Validation loss: 1.9853433755136305

Epoch: 5| Step: 10
Training loss: 2.5397820472717285
Validation loss: 1.9625820190675798

Epoch: 176| Step: 0
Training loss: 2.027522325515747
Validation loss: 1.9320169148906585

Epoch: 5| Step: 1
Training loss: 1.814711332321167
Validation loss: 1.8850371453069872

Epoch: 5| Step: 2
Training loss: 2.2354979515075684
Validation loss: 1.8696272783381964

Epoch: 5| Step: 3
Training loss: 1.9228817224502563
Validation loss: 1.8765009257101244

Epoch: 5| Step: 4
Training loss: 1.7929105758666992
Validation loss: 1.889718130070676

Epoch: 5| Step: 5
Training loss: 2.5315895080566406
Validation loss: 1.9045634192805136

Epoch: 5| Step: 6
Training loss: 1.4871453046798706
Validation loss: 1.9200793530351372

Epoch: 5| Step: 7
Training loss: 2.55253529548645
Validation loss: 1.9318690940897951

Epoch: 5| Step: 8
Training loss: 2.3489291667938232
Validation loss: 1.9213790893554688

Epoch: 5| Step: 9
Training loss: 2.5981545448303223
Validation loss: 1.8904744399491178

Epoch: 5| Step: 10
Training loss: 1.4367382526397705
Validation loss: 1.9024180635329215

Epoch: 177| Step: 0
Training loss: 2.1328561305999756
Validation loss: 1.9168784951650968

Epoch: 5| Step: 1
Training loss: 1.7650203704833984
Validation loss: 1.9226733292302778

Epoch: 5| Step: 2
Training loss: 1.8034366369247437
Validation loss: 1.9263640437074887

Epoch: 5| Step: 3
Training loss: 1.8516387939453125
Validation loss: 1.9218317129278695

Epoch: 5| Step: 4
Training loss: 1.9461357593536377
Validation loss: 1.9219728080175256

Epoch: 5| Step: 5
Training loss: 2.179950475692749
Validation loss: 1.9435250566851707

Epoch: 5| Step: 6
Training loss: 1.9457533359527588
Validation loss: 1.9438774175541376

Epoch: 5| Step: 7
Training loss: 1.7971360683441162
Validation loss: 1.9427340953580794

Epoch: 5| Step: 8
Training loss: 2.8221702575683594
Validation loss: 1.937330194698867

Epoch: 5| Step: 9
Training loss: 2.0871028900146484
Validation loss: 1.9610208260115756

Epoch: 5| Step: 10
Training loss: 2.0384862422943115
Validation loss: 1.9992099359471311

Epoch: 178| Step: 0
Training loss: 2.329030752182007
Validation loss: 2.0398777172129643

Epoch: 5| Step: 1
Training loss: 2.4739253520965576
Validation loss: 2.072420415057931

Epoch: 5| Step: 2
Training loss: 1.9637324810028076
Validation loss: 2.0925337447915027

Epoch: 5| Step: 3
Training loss: 3.020667552947998
Validation loss: 2.0769545262859714

Epoch: 5| Step: 4
Training loss: 2.213799476623535
Validation loss: 2.0394055971535305

Epoch: 5| Step: 5
Training loss: 1.6878761053085327
Validation loss: 2.0195331637577345

Epoch: 5| Step: 6
Training loss: 1.479369878768921
Validation loss: 1.9977183124070526

Epoch: 5| Step: 7
Training loss: 1.8718618154525757
Validation loss: 1.9836897183490056

Epoch: 5| Step: 8
Training loss: 1.6372724771499634
Validation loss: 1.9849158307557464

Epoch: 5| Step: 9
Training loss: 2.3211066722869873
Validation loss: 1.9570066313589773

Epoch: 5| Step: 10
Training loss: 2.2256999015808105
Validation loss: 1.9524985359561058

Epoch: 179| Step: 0
Training loss: 1.5223002433776855
Validation loss: 1.9157057731382308

Epoch: 5| Step: 1
Training loss: 2.4599227905273438
Validation loss: 1.8671503643835745

Epoch: 5| Step: 2
Training loss: 2.2690601348876953
Validation loss: 1.8758518080557547

Epoch: 5| Step: 3
Training loss: 2.228105306625366
Validation loss: 1.8748141091356996

Epoch: 5| Step: 4
Training loss: 2.0831046104431152
Validation loss: 1.8754027120528682

Epoch: 5| Step: 5
Training loss: 2.4705562591552734
Validation loss: 1.8932850142960906

Epoch: 5| Step: 6
Training loss: 2.169193744659424
Validation loss: 1.892450035259288

Epoch: 5| Step: 7
Training loss: 2.518343687057495
Validation loss: 1.9105694588794504

Epoch: 5| Step: 8
Training loss: 1.3831169605255127
Validation loss: 1.8714158419639833

Epoch: 5| Step: 9
Training loss: 1.681422233581543
Validation loss: 1.846105082060701

Epoch: 5| Step: 10
Training loss: 1.6084680557250977
Validation loss: 1.8509486695771575

Epoch: 180| Step: 0
Training loss: 1.928009271621704
Validation loss: 1.8686560828198668

Epoch: 5| Step: 1
Training loss: 1.7951843738555908
Validation loss: 1.8625008726632724

Epoch: 5| Step: 2
Training loss: 1.8094031810760498
Validation loss: 1.8703721941158336

Epoch: 5| Step: 3
Training loss: 2.2678627967834473
Validation loss: 1.8742246909808087

Epoch: 5| Step: 4
Training loss: 2.1025590896606445
Validation loss: 1.8865451159015778

Epoch: 5| Step: 5
Training loss: 1.7477877140045166
Validation loss: 1.8972560462131296

Epoch: 5| Step: 6
Training loss: 2.1970105171203613
Validation loss: 1.9020274877548218

Epoch: 5| Step: 7
Training loss: 2.2685024738311768
Validation loss: 1.8959149737511911

Epoch: 5| Step: 8
Training loss: 2.2907283306121826
Validation loss: 1.9145634635802238

Epoch: 5| Step: 9
Training loss: 1.9838664531707764
Validation loss: 1.918270408466298

Epoch: 5| Step: 10
Training loss: 1.8169846534729004
Validation loss: 1.92612898477944

Epoch: 181| Step: 0
Training loss: 2.353024959564209
Validation loss: 1.937052272981213

Epoch: 5| Step: 1
Training loss: 2.412757396697998
Validation loss: 1.947241799805754

Epoch: 5| Step: 2
Training loss: 2.4805407524108887
Validation loss: 1.9769193228854929

Epoch: 5| Step: 3
Training loss: 2.411085844039917
Validation loss: 1.9914452029812721

Epoch: 5| Step: 4
Training loss: 1.6211073398590088
Validation loss: 1.9840869237017889

Epoch: 5| Step: 5
Training loss: 1.2962383031845093
Validation loss: 1.9907761632755239

Epoch: 5| Step: 6
Training loss: 1.5526795387268066
Validation loss: 1.972673741720056

Epoch: 5| Step: 7
Training loss: 1.9438436031341553
Validation loss: 1.9653268091140255

Epoch: 5| Step: 8
Training loss: 2.4388091564178467
Validation loss: 1.9604198009737077

Epoch: 5| Step: 9
Training loss: 1.556292176246643
Validation loss: 1.9476165925302813

Epoch: 5| Step: 10
Training loss: 1.7409099340438843
Validation loss: 1.914328145724471

Epoch: 182| Step: 0
Training loss: 2.14462947845459
Validation loss: 1.9028716574433029

Epoch: 5| Step: 1
Training loss: 1.6775156259536743
Validation loss: 1.8994875082405664

Epoch: 5| Step: 2
Training loss: 1.7764564752578735
Validation loss: 1.9000870655941706

Epoch: 5| Step: 3
Training loss: 2.2073516845703125
Validation loss: 1.8776085120375439

Epoch: 5| Step: 4
Training loss: 2.013046979904175
Validation loss: 1.8864648598496632

Epoch: 5| Step: 5
Training loss: 1.850005865097046
Validation loss: 1.8696690400441487

Epoch: 5| Step: 6
Training loss: 2.6127209663391113
Validation loss: 1.8720670874400804

Epoch: 5| Step: 7
Training loss: 1.8166143894195557
Validation loss: 1.8891778761340725

Epoch: 5| Step: 8
Training loss: 2.4558730125427246
Validation loss: 1.9286140780295096

Epoch: 5| Step: 9
Training loss: 1.299729585647583
Validation loss: 1.9430066757304694

Epoch: 5| Step: 10
Training loss: 2.1547868251800537
Validation loss: 1.9483675110724665

Epoch: 183| Step: 0
Training loss: 2.6506218910217285
Validation loss: 1.968070601904264

Epoch: 5| Step: 1
Training loss: 1.5358712673187256
Validation loss: 1.9958101062364475

Epoch: 5| Step: 2
Training loss: 2.1066396236419678
Validation loss: 1.9991396473300072

Epoch: 5| Step: 3
Training loss: 1.690234899520874
Validation loss: 2.019498502054522

Epoch: 5| Step: 4
Training loss: 1.1208312511444092
Validation loss: 2.0190573635921685

Epoch: 5| Step: 5
Training loss: 2.4390995502471924
Validation loss: 2.0030911148235364

Epoch: 5| Step: 6
Training loss: 1.8893333673477173
Validation loss: 1.9906257608885407

Epoch: 5| Step: 7
Training loss: 1.6999595165252686
Validation loss: 1.9808831330268615

Epoch: 5| Step: 8
Training loss: 2.4788639545440674
Validation loss: 1.979375575178413

Epoch: 5| Step: 9
Training loss: 1.507389783859253
Validation loss: 1.9591318561184792

Epoch: 5| Step: 10
Training loss: 2.505269765853882
Validation loss: 1.9422977201400264

Epoch: 184| Step: 0
Training loss: 2.2177252769470215
Validation loss: 1.9238554367455103

Epoch: 5| Step: 1
Training loss: 1.517714023590088
Validation loss: 1.9043242995456984

Epoch: 5| Step: 2
Training loss: 2.4349567890167236
Validation loss: 1.886484258918352

Epoch: 5| Step: 3
Training loss: 2.6322596073150635
Validation loss: 1.8846887491082633

Epoch: 5| Step: 4
Training loss: 1.5529390573501587
Validation loss: 1.8879860613935737

Epoch: 5| Step: 5
Training loss: 1.585776925086975
Validation loss: 1.891344525480783

Epoch: 5| Step: 6
Training loss: 1.7974469661712646
Validation loss: 1.9002863014897993

Epoch: 5| Step: 7
Training loss: 2.265773057937622
Validation loss: 1.9151854412530058

Epoch: 5| Step: 8
Training loss: 1.7904670238494873
Validation loss: 1.9219246654100315

Epoch: 5| Step: 9
Training loss: 1.8213298320770264
Validation loss: 1.9397043874186854

Epoch: 5| Step: 10
Training loss: 1.8434646129608154
Validation loss: 1.9454554998746483

Epoch: 185| Step: 0
Training loss: 2.010744094848633
Validation loss: 1.95301188448424

Epoch: 5| Step: 1
Training loss: 1.5334457159042358
Validation loss: 1.9570877039304344

Epoch: 5| Step: 2
Training loss: 1.8521759510040283
Validation loss: 1.9193063577016194

Epoch: 5| Step: 3
Training loss: 1.9634811878204346
Validation loss: 1.9006773502595964

Epoch: 5| Step: 4
Training loss: 2.225356340408325
Validation loss: 1.8959211046977709

Epoch: 5| Step: 5
Training loss: 2.3593595027923584
Validation loss: 1.901099576744982

Epoch: 5| Step: 6
Training loss: 1.2648414373397827
Validation loss: 1.9043121696800314

Epoch: 5| Step: 7
Training loss: 2.3763134479522705
Validation loss: 1.8887096335811

Epoch: 5| Step: 8
Training loss: 2.2200615406036377
Validation loss: 1.8851278315308273

Epoch: 5| Step: 9
Training loss: 2.055443048477173
Validation loss: 1.9032646199708343

Epoch: 5| Step: 10
Training loss: 1.6240324974060059
Validation loss: 1.9171104931062268

Epoch: 186| Step: 0
Training loss: 2.1315081119537354
Validation loss: 1.946891462931069

Epoch: 5| Step: 1
Training loss: 1.8412002325057983
Validation loss: 1.9744390210797709

Epoch: 5| Step: 2
Training loss: 1.6812827587127686
Validation loss: 1.9597426922090593

Epoch: 5| Step: 3
Training loss: 1.6381946802139282
Validation loss: 1.9415713407660042

Epoch: 5| Step: 4
Training loss: 2.265995740890503
Validation loss: 1.9363524683060185

Epoch: 5| Step: 5
Training loss: 2.1936631202697754
Validation loss: 1.9471223021066317

Epoch: 5| Step: 6
Training loss: 2.1222078800201416
Validation loss: 1.9519085371366112

Epoch: 5| Step: 7
Training loss: 1.8755801916122437
Validation loss: 1.9773703736643637

Epoch: 5| Step: 8
Training loss: 1.6564276218414307
Validation loss: 1.9732450413447555

Epoch: 5| Step: 9
Training loss: 1.806152105331421
Validation loss: 1.9681330906447543

Epoch: 5| Step: 10
Training loss: 2.0905370712280273
Validation loss: 1.9535260969592678

Epoch: 187| Step: 0
Training loss: 1.9614145755767822
Validation loss: 1.9579561141229445

Epoch: 5| Step: 1
Training loss: 2.0094146728515625
Validation loss: 1.9549385860402098

Epoch: 5| Step: 2
Training loss: 1.1433823108673096
Validation loss: 1.932947167786219

Epoch: 5| Step: 3
Training loss: 1.9670941829681396
Validation loss: 1.9320032750406573

Epoch: 5| Step: 4
Training loss: 1.7904285192489624
Validation loss: 1.9249658738413165

Epoch: 5| Step: 5
Training loss: 2.316952705383301
Validation loss: 1.9258776813425043

Epoch: 5| Step: 6
Training loss: 1.4241502285003662
Validation loss: 1.9430446804210704

Epoch: 5| Step: 7
Training loss: 2.0602498054504395
Validation loss: 1.9270027081171672

Epoch: 5| Step: 8
Training loss: 1.8218581676483154
Validation loss: 1.9301500666526057

Epoch: 5| Step: 9
Training loss: 2.456519603729248
Validation loss: 1.9264499628415672

Epoch: 5| Step: 10
Training loss: 2.17771315574646
Validation loss: 1.9280770670983098

Epoch: 188| Step: 0
Training loss: 1.836019515991211
Validation loss: 1.936069626961985

Epoch: 5| Step: 1
Training loss: 1.638165831565857
Validation loss: 1.957571917964566

Epoch: 5| Step: 2
Training loss: 2.303969621658325
Validation loss: 1.965615031539753

Epoch: 5| Step: 3
Training loss: 1.9737743139266968
Validation loss: 1.961502767378284

Epoch: 5| Step: 4
Training loss: 2.349688768386841
Validation loss: 1.9623468332393195

Epoch: 5| Step: 5
Training loss: 2.184880018234253
Validation loss: 1.9572916774339573

Epoch: 5| Step: 6
Training loss: 0.9568802118301392
Validation loss: 1.954983643306199

Epoch: 5| Step: 7
Training loss: 1.6387144327163696
Validation loss: 1.9604613281065417

Epoch: 5| Step: 8
Training loss: 2.2575836181640625
Validation loss: 1.991398713921988

Epoch: 5| Step: 9
Training loss: 1.5200624465942383
Validation loss: 2.003131922855172

Epoch: 5| Step: 10
Training loss: 2.4688737392425537
Validation loss: 1.9795671791158698

Epoch: 189| Step: 0
Training loss: 2.0520029067993164
Validation loss: 1.964119465120377

Epoch: 5| Step: 1
Training loss: 1.9257415533065796
Validation loss: 1.9910456493336668

Epoch: 5| Step: 2
Training loss: 2.406921863555908
Validation loss: 1.997950033474994

Epoch: 5| Step: 3
Training loss: 1.8759698867797852
Validation loss: 1.9873518956604825

Epoch: 5| Step: 4
Training loss: 1.8402372598648071
Validation loss: 1.94677488265499

Epoch: 5| Step: 5
Training loss: 1.6404507160186768
Validation loss: 1.893335262934367

Epoch: 5| Step: 6
Training loss: 2.3527767658233643
Validation loss: 1.8636900378811745

Epoch: 5| Step: 7
Training loss: 1.5305829048156738
Validation loss: 1.9060138399882982

Epoch: 5| Step: 8
Training loss: 1.412941336631775
Validation loss: 1.8869297440334032

Epoch: 5| Step: 9
Training loss: 2.066152811050415
Validation loss: 1.8675176456410398

Epoch: 5| Step: 10
Training loss: 2.3725039958953857
Validation loss: 1.877413979140661

Epoch: 190| Step: 0
Training loss: 2.3910160064697266
Validation loss: 1.8905499084021455

Epoch: 5| Step: 1
Training loss: 1.7932546138763428
Validation loss: 1.9658815501838602

Epoch: 5| Step: 2
Training loss: 1.9312843084335327
Validation loss: 2.0036786346025366

Epoch: 5| Step: 3
Training loss: 2.7371177673339844
Validation loss: 2.000290996284895

Epoch: 5| Step: 4
Training loss: 2.0240705013275146
Validation loss: 1.9487542997124374

Epoch: 5| Step: 5
Training loss: 1.2144546508789062
Validation loss: 1.9201759458870016

Epoch: 5| Step: 6
Training loss: 2.4042866230010986
Validation loss: 1.9168091563768284

Epoch: 5| Step: 7
Training loss: 1.6694002151489258
Validation loss: 1.920313665943761

Epoch: 5| Step: 8
Training loss: 2.3295998573303223
Validation loss: 1.9337960238097816

Epoch: 5| Step: 9
Training loss: 1.8532739877700806
Validation loss: 1.9094858336192306

Epoch: 5| Step: 10
Training loss: 1.3758063316345215
Validation loss: 1.8876915593301096

Epoch: 191| Step: 0
Training loss: 1.330945611000061
Validation loss: 1.8911923746908865

Epoch: 5| Step: 1
Training loss: 1.922398328781128
Validation loss: 1.903424503982708

Epoch: 5| Step: 2
Training loss: 2.1310627460479736
Validation loss: 1.9134474659478793

Epoch: 5| Step: 3
Training loss: 2.0012497901916504
Validation loss: 1.9096665305476035

Epoch: 5| Step: 4
Training loss: 2.1376869678497314
Validation loss: 1.9081627348417878

Epoch: 5| Step: 5
Training loss: 1.7047550678253174
Validation loss: 1.9020735345860964

Epoch: 5| Step: 6
Training loss: 1.1899757385253906
Validation loss: 1.912185965045806

Epoch: 5| Step: 7
Training loss: 1.7335669994354248
Validation loss: 1.9164986482230566

Epoch: 5| Step: 8
Training loss: 1.889749526977539
Validation loss: 1.922243760478112

Epoch: 5| Step: 9
Training loss: 2.282351493835449
Validation loss: 1.9660926506083498

Epoch: 5| Step: 10
Training loss: 2.6979196071624756
Validation loss: 1.9630238394583426

Epoch: 192| Step: 0
Training loss: 1.601646065711975
Validation loss: 1.9781010099636611

Epoch: 5| Step: 1
Training loss: 1.6870129108428955
Validation loss: 1.9878125267644082

Epoch: 5| Step: 2
Training loss: 2.0250096321105957
Validation loss: 2.021163537938108

Epoch: 5| Step: 3
Training loss: 1.8761346340179443
Validation loss: 2.033050360218171

Epoch: 5| Step: 4
Training loss: 1.6351063251495361
Validation loss: 2.0515703565330914

Epoch: 5| Step: 5
Training loss: 2.203299045562744
Validation loss: 2.024805707316245

Epoch: 5| Step: 6
Training loss: 1.9756088256835938
Validation loss: 2.002927977551696

Epoch: 5| Step: 7
Training loss: 1.784131646156311
Validation loss: 1.9605293132925545

Epoch: 5| Step: 8
Training loss: 1.8511931896209717
Validation loss: 1.9248356665334394

Epoch: 5| Step: 9
Training loss: 1.969982385635376
Validation loss: 1.9185960805544289

Epoch: 5| Step: 10
Training loss: 2.121161937713623
Validation loss: 1.9284609992017028

Epoch: 193| Step: 0
Training loss: 2.3882834911346436
Validation loss: 1.9609614213307698

Epoch: 5| Step: 1
Training loss: 1.8839632272720337
Validation loss: 1.9550638301398164

Epoch: 5| Step: 2
Training loss: 1.8727073669433594
Validation loss: 1.9397576214164816

Epoch: 5| Step: 3
Training loss: 1.8066707849502563
Validation loss: 1.9381461040948027

Epoch: 5| Step: 4
Training loss: 1.3595153093338013
Validation loss: 1.9411071244106497

Epoch: 5| Step: 5
Training loss: 1.835465669631958
Validation loss: 1.9434931944775324

Epoch: 5| Step: 6
Training loss: 1.1550145149230957
Validation loss: 1.9993809448775424

Epoch: 5| Step: 7
Training loss: 1.8770500421524048
Validation loss: 2.0502540808852

Epoch: 5| Step: 8
Training loss: 2.887895107269287
Validation loss: 2.0670718941637265

Epoch: 5| Step: 9
Training loss: 2.4909374713897705
Validation loss: 2.0389299982337543

Epoch: 5| Step: 10
Training loss: 1.5253223180770874
Validation loss: 2.006959212723599

Epoch: 194| Step: 0
Training loss: 1.5052740573883057
Validation loss: 1.9708934419898576

Epoch: 5| Step: 1
Training loss: 1.6819922924041748
Validation loss: 1.9571509797085997

Epoch: 5| Step: 2
Training loss: 2.6140923500061035
Validation loss: 1.9562132973824777

Epoch: 5| Step: 3
Training loss: 1.1604682207107544
Validation loss: 1.954215750899366

Epoch: 5| Step: 4
Training loss: 2.0948691368103027
Validation loss: 1.947769688021752

Epoch: 5| Step: 5
Training loss: 1.8299108743667603
Validation loss: 1.9305928471267864

Epoch: 5| Step: 6
Training loss: 1.478121280670166
Validation loss: 1.9164323242761756

Epoch: 5| Step: 7
Training loss: 1.6876157522201538
Validation loss: 1.921150174192203

Epoch: 5| Step: 8
Training loss: 2.14741849899292
Validation loss: 1.9487371137065272

Epoch: 5| Step: 9
Training loss: 2.3953564167022705
Validation loss: 1.9404949449723767

Epoch: 5| Step: 10
Training loss: 1.6601191759109497
Validation loss: 1.9622805285197433

Epoch: 195| Step: 0
Training loss: 2.0098559856414795
Validation loss: 1.9422785851263231

Epoch: 5| Step: 1
Training loss: 2.084965229034424
Validation loss: 1.9278613290479105

Epoch: 5| Step: 2
Training loss: 2.043964385986328
Validation loss: 1.928426573353429

Epoch: 5| Step: 3
Training loss: 1.96855890750885
Validation loss: 1.9209288422779371

Epoch: 5| Step: 4
Training loss: 1.1815216541290283
Validation loss: 1.9293247128045687

Epoch: 5| Step: 5
Training loss: 1.486124038696289
Validation loss: 1.9221666423223351

Epoch: 5| Step: 6
Training loss: 2.1346092224121094
Validation loss: 1.9105092594700475

Epoch: 5| Step: 7
Training loss: 1.365181565284729
Validation loss: 1.8858648218134397

Epoch: 5| Step: 8
Training loss: 2.2218995094299316
Validation loss: 1.8904936775084464

Epoch: 5| Step: 9
Training loss: 1.780287742614746
Validation loss: 1.9068097029962847

Epoch: 5| Step: 10
Training loss: 1.8923581838607788
Validation loss: 1.9347422366501184

Epoch: 196| Step: 0
Training loss: 1.7891136407852173
Validation loss: 1.959570215594384

Epoch: 5| Step: 1
Training loss: 2.290536403656006
Validation loss: 1.9709412231240222

Epoch: 5| Step: 2
Training loss: 1.8103755712509155
Validation loss: 1.98106760491607

Epoch: 5| Step: 3
Training loss: 1.8689171075820923
Validation loss: 1.9768068957072433

Epoch: 5| Step: 4
Training loss: 2.046520709991455
Validation loss: 1.9675999520927347

Epoch: 5| Step: 5
Training loss: 2.2713639736175537
Validation loss: 1.9853138898008613

Epoch: 5| Step: 6
Training loss: 1.6381076574325562
Validation loss: 1.9778253596316102

Epoch: 5| Step: 7
Training loss: 1.1673860549926758
Validation loss: 2.0069838390555432

Epoch: 5| Step: 8
Training loss: 1.9548391103744507
Validation loss: 2.002723602838414

Epoch: 5| Step: 9
Training loss: 1.8109642267227173
Validation loss: 1.9804643584835915

Epoch: 5| Step: 10
Training loss: 2.012537717819214
Validation loss: 1.9711457734466882

Epoch: 197| Step: 0
Training loss: 1.8564802408218384
Validation loss: 1.924694615025674

Epoch: 5| Step: 1
Training loss: 2.2713279724121094
Validation loss: 1.9201299118739303

Epoch: 5| Step: 2
Training loss: 1.5863947868347168
Validation loss: 1.923845628256439

Epoch: 5| Step: 3
Training loss: 1.6429229974746704
Validation loss: 1.9414507086559007

Epoch: 5| Step: 4
Training loss: 1.5159547328948975
Validation loss: 1.923346237469745

Epoch: 5| Step: 5
Training loss: 2.381453275680542
Validation loss: 1.9025591496498353

Epoch: 5| Step: 6
Training loss: 1.6059329509735107
Validation loss: 1.8892652014250397

Epoch: 5| Step: 7
Training loss: 2.5007152557373047
Validation loss: 1.8694742943650933

Epoch: 5| Step: 8
Training loss: 1.6519702672958374
Validation loss: 1.875358755870532

Epoch: 5| Step: 9
Training loss: 1.7398903369903564
Validation loss: 1.9233340217221169

Epoch: 5| Step: 10
Training loss: 1.6763581037521362
Validation loss: 1.9691032363522438

Epoch: 198| Step: 0
Training loss: 1.5164380073547363
Validation loss: 1.9973934594021048

Epoch: 5| Step: 1
Training loss: 2.0430212020874023
Validation loss: 2.0368670660962342

Epoch: 5| Step: 2
Training loss: 2.2005603313446045
Validation loss: 2.0237624209414244

Epoch: 5| Step: 3
Training loss: 1.873558759689331
Validation loss: 2.01067663392713

Epoch: 5| Step: 4
Training loss: 1.8871787786483765
Validation loss: 2.02177192190642

Epoch: 5| Step: 5
Training loss: 1.8443448543548584
Validation loss: 2.0050766237320437

Epoch: 5| Step: 6
Training loss: 2.328781843185425
Validation loss: 1.9803529721434399

Epoch: 5| Step: 7
Training loss: 2.1846346855163574
Validation loss: 1.9390170343460575

Epoch: 5| Step: 8
Training loss: 1.8918777704238892
Validation loss: 1.9038841262940438

Epoch: 5| Step: 9
Training loss: 0.9900051355361938
Validation loss: 1.8889535985967165

Epoch: 5| Step: 10
Training loss: 1.7620658874511719
Validation loss: 1.8776551228697582

Epoch: 199| Step: 0
Training loss: 2.009915351867676
Validation loss: 1.894738451127083

Epoch: 5| Step: 1
Training loss: 2.104966402053833
Validation loss: 1.9021948076063586

Epoch: 5| Step: 2
Training loss: 1.9961678981781006
Validation loss: 1.8855150092032649

Epoch: 5| Step: 3
Training loss: 1.7803064584732056
Validation loss: 1.881301478673053

Epoch: 5| Step: 4
Training loss: 1.4307022094726562
Validation loss: 1.8779037537113312

Epoch: 5| Step: 5
Training loss: 1.819501519203186
Validation loss: 1.890337900448871

Epoch: 5| Step: 6
Training loss: 2.04701566696167
Validation loss: 1.9118179172597907

Epoch: 5| Step: 7
Training loss: 1.9163177013397217
Validation loss: 1.9532398716095956

Epoch: 5| Step: 8
Training loss: 1.4222915172576904
Validation loss: 1.968572264076561

Epoch: 5| Step: 9
Training loss: 1.5124597549438477
Validation loss: 1.954196089057512

Epoch: 5| Step: 10
Training loss: 2.0579111576080322
Validation loss: 1.9678775995008406

Epoch: 200| Step: 0
Training loss: 1.8239660263061523
Validation loss: 1.9484381957720684

Epoch: 5| Step: 1
Training loss: 2.0770316123962402
Validation loss: 1.9426562222101356

Epoch: 5| Step: 2
Training loss: 1.7973835468292236
Validation loss: 1.9588110459748136

Epoch: 5| Step: 3
Training loss: 1.496699333190918
Validation loss: 1.9587063110002907

Epoch: 5| Step: 4
Training loss: 1.9816007614135742
Validation loss: 1.9355756800661805

Epoch: 5| Step: 5
Training loss: 2.0653023719787598
Validation loss: 1.9511093272957751

Epoch: 5| Step: 6
Training loss: 2.1265945434570312
Validation loss: 1.9551233565935524

Epoch: 5| Step: 7
Training loss: 1.9526307582855225
Validation loss: 1.9780500909333587

Epoch: 5| Step: 8
Training loss: 1.6869560480117798
Validation loss: 1.9788533923446492

Epoch: 5| Step: 9
Training loss: 1.1459821462631226
Validation loss: 1.967307209968567

Epoch: 5| Step: 10
Training loss: 1.4835748672485352
Validation loss: 1.96289994383371

Epoch: 201| Step: 0
Training loss: 1.704714059829712
Validation loss: 1.9385680126887497

Epoch: 5| Step: 1
Training loss: 1.506082534790039
Validation loss: 1.9250457286834717

Epoch: 5| Step: 2
Training loss: 1.0636550188064575
Validation loss: 1.9361146906370759

Epoch: 5| Step: 3
Training loss: 1.6935417652130127
Validation loss: 1.925375259050759

Epoch: 5| Step: 4
Training loss: 2.9180145263671875
Validation loss: 1.9717994172085997

Epoch: 5| Step: 5
Training loss: 1.7599750757217407
Validation loss: 1.9660211839983541

Epoch: 5| Step: 6
Training loss: 1.3096259832382202
Validation loss: 1.9517935270904212

Epoch: 5| Step: 7
Training loss: 1.7709314823150635
Validation loss: 1.941830006978845

Epoch: 5| Step: 8
Training loss: 1.9333900213241577
Validation loss: 1.9279941243510093

Epoch: 5| Step: 9
Training loss: 2.3848929405212402
Validation loss: 1.9389395739442559

Epoch: 5| Step: 10
Training loss: 1.199294090270996
Validation loss: 1.944739730127396

Epoch: 202| Step: 0
Training loss: 1.8366754055023193
Validation loss: 1.9666206605972782

Epoch: 5| Step: 1
Training loss: 1.6086183786392212
Validation loss: 1.9601248182276243

Epoch: 5| Step: 2
Training loss: 2.1662888526916504
Validation loss: 1.9654829156014226

Epoch: 5| Step: 3
Training loss: 1.7903721332550049
Validation loss: 1.9519524779371036

Epoch: 5| Step: 4
Training loss: 1.8995885848999023
Validation loss: 1.9105489253997803

Epoch: 5| Step: 5
Training loss: 1.1422125101089478
Validation loss: 1.8983287952279533

Epoch: 5| Step: 6
Training loss: 2.2090346813201904
Validation loss: 1.90405450969614

Epoch: 5| Step: 7
Training loss: 1.452815294265747
Validation loss: 1.9145666040400022

Epoch: 5| Step: 8
Training loss: 2.6609599590301514
Validation loss: 1.9435787662383048

Epoch: 5| Step: 9
Training loss: 1.212885856628418
Validation loss: 1.9468692579577047

Epoch: 5| Step: 10
Training loss: 1.7418415546417236
Validation loss: 1.9679522052887948

Epoch: 203| Step: 0
Training loss: 1.6613601446151733
Validation loss: 1.9563527017511346

Epoch: 5| Step: 1
Training loss: 1.6397850513458252
Validation loss: 1.951765452661822

Epoch: 5| Step: 2
Training loss: 1.8513892889022827
Validation loss: 1.962312324072725

Epoch: 5| Step: 3
Training loss: 1.6019783020019531
Validation loss: 1.94642182319395

Epoch: 5| Step: 4
Training loss: 1.1945756673812866
Validation loss: 1.9475836753845215

Epoch: 5| Step: 5
Training loss: 1.715754747390747
Validation loss: 1.9366737642595846

Epoch: 5| Step: 6
Training loss: 1.6536668539047241
Validation loss: 1.9190275233278993

Epoch: 5| Step: 7
Training loss: 1.4107977151870728
Validation loss: 1.917879230232649

Epoch: 5| Step: 8
Training loss: 2.6101598739624023
Validation loss: 1.9162208008509811

Epoch: 5| Step: 9
Training loss: 1.4482874870300293
Validation loss: 1.921387844188239

Epoch: 5| Step: 10
Training loss: 2.43552565574646
Validation loss: 1.9394127732963973

Epoch: 204| Step: 0
Training loss: 1.6020710468292236
Validation loss: 1.9391640617001442

Epoch: 5| Step: 1
Training loss: 1.6135387420654297
Validation loss: 1.9349869963943318

Epoch: 5| Step: 2
Training loss: 2.2245960235595703
Validation loss: 1.957850339592144

Epoch: 5| Step: 3
Training loss: 1.6628373861312866
Validation loss: 1.9726828195715462

Epoch: 5| Step: 4
Training loss: 1.3572975397109985
Validation loss: 1.9834618914511897

Epoch: 5| Step: 5
Training loss: 1.4284400939941406
Validation loss: 1.9797562424854567

Epoch: 5| Step: 6
Training loss: 1.9442096948623657
Validation loss: 1.9831739728168776

Epoch: 5| Step: 7
Training loss: 1.9123671054840088
Validation loss: 1.9699194533850557

Epoch: 5| Step: 8
Training loss: 1.734735131263733
Validation loss: 1.9373763684303529

Epoch: 5| Step: 9
Training loss: 1.840732216835022
Validation loss: 1.9314899931671798

Epoch: 5| Step: 10
Training loss: 1.8032112121582031
Validation loss: 1.905657104266587

Epoch: 205| Step: 0
Training loss: 1.6708018779754639
Validation loss: 1.9377320210138957

Epoch: 5| Step: 1
Training loss: 1.6347249746322632
Validation loss: 1.9326335076362855

Epoch: 5| Step: 2
Training loss: 1.769855260848999
Validation loss: 1.9437173156328098

Epoch: 5| Step: 3
Training loss: 2.0359556674957275
Validation loss: 1.9456487035238614

Epoch: 5| Step: 4
Training loss: 1.4919524192810059
Validation loss: 1.9612061746658818

Epoch: 5| Step: 5
Training loss: 2.2680675983428955
Validation loss: 1.9509463335878106

Epoch: 5| Step: 6
Training loss: 1.356912612915039
Validation loss: 1.9484696080607753

Epoch: 5| Step: 7
Training loss: 2.5186169147491455
Validation loss: 1.9429916899691346

Epoch: 5| Step: 8
Training loss: 1.2862259149551392
Validation loss: 1.935110172917766

Epoch: 5| Step: 9
Training loss: 1.5007051229476929
Validation loss: 1.937832119644329

Epoch: 5| Step: 10
Training loss: 1.4396097660064697
Validation loss: 1.9376561167419597

Epoch: 206| Step: 0
Training loss: 1.5612612962722778
Validation loss: 1.9386240987367527

Epoch: 5| Step: 1
Training loss: 1.6729873418807983
Validation loss: 1.898465210391629

Epoch: 5| Step: 2
Training loss: 1.64975106716156
Validation loss: 1.8851276174668343

Epoch: 5| Step: 3
Training loss: 1.8163213729858398
Validation loss: 1.8972460774965183

Epoch: 5| Step: 4
Training loss: 2.0591726303100586
Validation loss: 1.9162245501754105

Epoch: 5| Step: 5
Training loss: 2.2540688514709473
Validation loss: 1.9204492594606133

Epoch: 5| Step: 6
Training loss: 1.4440345764160156
Validation loss: 1.912128161358577

Epoch: 5| Step: 7
Training loss: 1.3687517642974854
Validation loss: 1.9056245242395708

Epoch: 5| Step: 8
Training loss: 1.7736597061157227
Validation loss: 1.8961653978593889

Epoch: 5| Step: 9
Training loss: 1.777705430984497
Validation loss: 1.8851551599400018

Epoch: 5| Step: 10
Training loss: 1.54361093044281
Validation loss: 1.9089160401334044

Epoch: 207| Step: 0
Training loss: 1.8220574855804443
Validation loss: 1.9307122512530255

Epoch: 5| Step: 1
Training loss: 2.1342246532440186
Validation loss: 1.9491848689253612

Epoch: 5| Step: 2
Training loss: 1.2353692054748535
Validation loss: 1.964012771524409

Epoch: 5| Step: 3
Training loss: 1.742903470993042
Validation loss: 1.9912716086192797

Epoch: 5| Step: 4
Training loss: 2.05989408493042
Validation loss: 2.007055628684259

Epoch: 5| Step: 5
Training loss: 1.5949803590774536
Validation loss: 2.0154239490468013

Epoch: 5| Step: 6
Training loss: 1.7802550792694092
Validation loss: 2.014515333278205

Epoch: 5| Step: 7
Training loss: 1.5836172103881836
Validation loss: 2.0085793707960393

Epoch: 5| Step: 8
Training loss: 1.7204477787017822
Validation loss: 2.0263560920633297

Epoch: 5| Step: 9
Training loss: 1.503448486328125
Validation loss: 1.9914061638616747

Epoch: 5| Step: 10
Training loss: 2.1522209644317627
Validation loss: 1.9723271426334177

Epoch: 208| Step: 0
Training loss: 1.7290351390838623
Validation loss: 1.9495627469913934

Epoch: 5| Step: 1
Training loss: 1.4569075107574463
Validation loss: 1.9269276716375863

Epoch: 5| Step: 2
Training loss: 1.9182713031768799
Validation loss: 1.9023305600689304

Epoch: 5| Step: 3
Training loss: 1.5381038188934326
Validation loss: 1.8908634672882736

Epoch: 5| Step: 4
Training loss: 2.26794171333313
Validation loss: 1.8871009990733156

Epoch: 5| Step: 5
Training loss: 1.7737407684326172
Validation loss: 1.88877139552947

Epoch: 5| Step: 6
Training loss: 1.9850269556045532
Validation loss: 1.892910111335016

Epoch: 5| Step: 7
Training loss: 1.2422559261322021
Validation loss: 1.8840287757176224

Epoch: 5| Step: 8
Training loss: 1.2632038593292236
Validation loss: 1.8918144164546844

Epoch: 5| Step: 9
Training loss: 2.315504312515259
Validation loss: 1.8887307272162488

Epoch: 5| Step: 10
Training loss: 1.0974435806274414
Validation loss: 1.9061541377857167

Epoch: 209| Step: 0
Training loss: 1.5437815189361572
Validation loss: 1.8930002989307526

Epoch: 5| Step: 1
Training loss: 1.1655988693237305
Validation loss: 1.9213995087531306

Epoch: 5| Step: 2
Training loss: 2.2949225902557373
Validation loss: 1.9414864368336175

Epoch: 5| Step: 3
Training loss: 1.2908430099487305
Validation loss: 1.9524720189391926

Epoch: 5| Step: 4
Training loss: 1.612732172012329
Validation loss: 1.9577023175454908

Epoch: 5| Step: 5
Training loss: 1.7234560251235962
Validation loss: 1.9608841339747112

Epoch: 5| Step: 6
Training loss: 1.9288303852081299
Validation loss: 1.9340355985908098

Epoch: 5| Step: 7
Training loss: 1.7657537460327148
Validation loss: 1.925351760720694

Epoch: 5| Step: 8
Training loss: 1.3470044136047363
Validation loss: 1.922924421166861

Epoch: 5| Step: 9
Training loss: 1.8185192346572876
Validation loss: 1.9150902443034674

Epoch: 5| Step: 10
Training loss: 1.6765367984771729
Validation loss: 1.894920188893554

Epoch: 210| Step: 0
Training loss: 1.6326431035995483
Validation loss: 1.8991999292886386

Epoch: 5| Step: 1
Training loss: 1.7997347116470337
Validation loss: 1.891785237096971

Epoch: 5| Step: 2
Training loss: 1.4915789365768433
Validation loss: 1.8783804729420652

Epoch: 5| Step: 3
Training loss: 1.3385913372039795
Validation loss: 1.867886879110849

Epoch: 5| Step: 4
Training loss: 2.117985963821411
Validation loss: 1.8460608067051056

Epoch: 5| Step: 5
Training loss: 1.4375030994415283
Validation loss: 1.870171812272841

Epoch: 5| Step: 6
Training loss: 1.4294354915618896
Validation loss: 1.865055896902597

Epoch: 5| Step: 7
Training loss: 1.6053874492645264
Validation loss: 1.8666666041138351

Epoch: 5| Step: 8
Training loss: 1.1775579452514648
Validation loss: 1.8676196452110045

Epoch: 5| Step: 9
Training loss: 1.6875451803207397
Validation loss: 1.8875970045725505

Epoch: 5| Step: 10
Training loss: 2.3455052375793457
Validation loss: 1.915693900918448

Epoch: 211| Step: 0
Training loss: 1.8614476919174194
Validation loss: 1.9620165735162713

Epoch: 5| Step: 1
Training loss: 1.079145908355713
Validation loss: 1.9928575779802056

Epoch: 5| Step: 2
Training loss: 1.659402847290039
Validation loss: 2.006751327104466

Epoch: 5| Step: 3
Training loss: 2.0015060901641846
Validation loss: 2.016962510283275

Epoch: 5| Step: 4
Training loss: 1.7515251636505127
Validation loss: 2.017091485761827

Epoch: 5| Step: 5
Training loss: 1.1613075733184814
Validation loss: 1.999487409027674

Epoch: 5| Step: 6
Training loss: 1.9118897914886475
Validation loss: 1.9790459909746725

Epoch: 5| Step: 7
Training loss: 1.7870826721191406
Validation loss: 1.9726499639531618

Epoch: 5| Step: 8
Training loss: 1.629826307296753
Validation loss: 1.950780991585024

Epoch: 5| Step: 9
Training loss: 1.6329047679901123
Validation loss: 1.9284722202567643

Epoch: 5| Step: 10
Training loss: 1.5769741535186768
Validation loss: 1.9155750274658203

Epoch: 212| Step: 0
Training loss: 1.3877507448196411
Validation loss: 1.9026996692021687

Epoch: 5| Step: 1
Training loss: 2.1562626361846924
Validation loss: 1.8944448655651462

Epoch: 5| Step: 2
Training loss: 1.5758951902389526
Validation loss: 1.899869881650453

Epoch: 5| Step: 3
Training loss: 2.306457281112671
Validation loss: 1.9102311493248068

Epoch: 5| Step: 4
Training loss: 1.2300364971160889
Validation loss: 1.8878925743923392

Epoch: 5| Step: 5
Training loss: 1.4448028802871704
Validation loss: 1.874095332237982

Epoch: 5| Step: 6
Training loss: 1.4012888669967651
Validation loss: 1.8891130647351664

Epoch: 5| Step: 7
Training loss: 1.0508474111557007
Validation loss: 1.8926673230304514

Epoch: 5| Step: 8
Training loss: 1.194853663444519
Validation loss: 1.9028927023692797

Epoch: 5| Step: 9
Training loss: 2.7381339073181152
Validation loss: 1.9291446093590028

Epoch: 5| Step: 10
Training loss: 1.9407308101654053
Validation loss: 1.9482272350659935

Epoch: 213| Step: 0
Training loss: 1.5810835361480713
Validation loss: 1.9526944750098771

Epoch: 5| Step: 1
Training loss: 1.2428536415100098
Validation loss: 1.9846308167262743

Epoch: 5| Step: 2
Training loss: 2.1150729656219482
Validation loss: 1.9762116811608756

Epoch: 5| Step: 3
Training loss: 1.594610333442688
Validation loss: 1.968033290678455

Epoch: 5| Step: 4
Training loss: 1.4941195249557495
Validation loss: 1.9622803670103832

Epoch: 5| Step: 5
Training loss: 1.5367087125778198
Validation loss: 1.9395918339811347

Epoch: 5| Step: 6
Training loss: 1.3374840021133423
Validation loss: 1.9450475990131337

Epoch: 5| Step: 7
Training loss: 1.8482444286346436
Validation loss: 1.9159809697058894

Epoch: 5| Step: 8
Training loss: 1.661689043045044
Validation loss: 1.9191655971670663

Epoch: 5| Step: 9
Training loss: 2.0157017707824707
Validation loss: 1.9077078501383464

Epoch: 5| Step: 10
Training loss: 1.7310361862182617
Validation loss: 1.9007813007600847

Epoch: 214| Step: 0
Training loss: 1.4870214462280273
Validation loss: 1.9203745370270104

Epoch: 5| Step: 1
Training loss: 1.6368640661239624
Validation loss: 1.9401005186060423

Epoch: 5| Step: 2
Training loss: 0.8324697613716125
Validation loss: 1.916574651195157

Epoch: 5| Step: 3
Training loss: 1.5776383876800537
Validation loss: 1.899619786970077

Epoch: 5| Step: 4
Training loss: 1.6581623554229736
Validation loss: 1.8934261619403798

Epoch: 5| Step: 5
Training loss: 1.6838487386703491
Validation loss: 1.8904212841423609

Epoch: 5| Step: 6
Training loss: 1.399253487586975
Validation loss: 1.9146843597453127

Epoch: 5| Step: 7
Training loss: 2.2561473846435547
Validation loss: 1.896274919150978

Epoch: 5| Step: 8
Training loss: 1.5407178401947021
Validation loss: 1.9216439172785769

Epoch: 5| Step: 9
Training loss: 1.6416099071502686
Validation loss: 1.9304943776899768

Epoch: 5| Step: 10
Training loss: 1.9908345937728882
Validation loss: 1.9256380245249758

Epoch: 215| Step: 0
Training loss: 1.580702304840088
Validation loss: 1.9449650664483347

Epoch: 5| Step: 1
Training loss: 1.9324321746826172
Validation loss: 1.9463625313133321

Epoch: 5| Step: 2
Training loss: 1.468157410621643
Validation loss: 1.9468043081222042

Epoch: 5| Step: 3
Training loss: 1.6457687616348267
Validation loss: 1.9280216270877468

Epoch: 5| Step: 4
Training loss: 1.7131983041763306
Validation loss: 1.9221268084741407

Epoch: 5| Step: 5
Training loss: 1.1014817953109741
Validation loss: 1.9375570897133119

Epoch: 5| Step: 6
Training loss: 1.2191517353057861
Validation loss: 1.920726873541391

Epoch: 5| Step: 7
Training loss: 1.7449918985366821
Validation loss: 1.9262395084545176

Epoch: 5| Step: 8
Training loss: 1.5001357793807983
Validation loss: 1.9110814948235788

Epoch: 5| Step: 9
Training loss: 2.2055418491363525
Validation loss: 1.915927735708093

Epoch: 5| Step: 10
Training loss: 1.2474782466888428
Validation loss: 1.9058849375735047

Epoch: 216| Step: 0
Training loss: 1.7912929058074951
Validation loss: 1.8918775755872008

Epoch: 5| Step: 1
Training loss: 2.101071834564209
Validation loss: 1.9087475538253784

Epoch: 5| Step: 2
Training loss: 1.526907205581665
Validation loss: 1.9161751783022316

Epoch: 5| Step: 3
Training loss: 1.6118755340576172
Validation loss: 1.9179527285278484

Epoch: 5| Step: 4
Training loss: 1.2297725677490234
Validation loss: 1.9047504522467171

Epoch: 5| Step: 5
Training loss: 1.0073652267456055
Validation loss: 1.8891838853077223

Epoch: 5| Step: 6
Training loss: 1.748375654220581
Validation loss: 1.8909796899364841

Epoch: 5| Step: 7
Training loss: 1.5265395641326904
Validation loss: 1.8951018856417747

Epoch: 5| Step: 8
Training loss: 1.3485982418060303
Validation loss: 1.893851690394904

Epoch: 5| Step: 9
Training loss: 1.8543707132339478
Validation loss: 1.9055654951321181

Epoch: 5| Step: 10
Training loss: 1.4271180629730225
Validation loss: 1.895672398228799

Epoch: 217| Step: 0
Training loss: 1.0285837650299072
Validation loss: 1.9006308278729838

Epoch: 5| Step: 1
Training loss: 1.4098575115203857
Validation loss: 1.9153771272269629

Epoch: 5| Step: 2
Training loss: 1.916254997253418
Validation loss: 1.9235770638271044

Epoch: 5| Step: 3
Training loss: 1.61708664894104
Validation loss: 1.9215635971356464

Epoch: 5| Step: 4
Training loss: 2.0019004344940186
Validation loss: 1.9307988933337632

Epoch: 5| Step: 5
Training loss: 0.8741618990898132
Validation loss: 1.9347461833748767

Epoch: 5| Step: 6
Training loss: 1.5458042621612549
Validation loss: 1.931804951801095

Epoch: 5| Step: 7
Training loss: 1.527893304824829
Validation loss: 1.9443108471491004

Epoch: 5| Step: 8
Training loss: 1.212009310722351
Validation loss: 1.9375543696905977

Epoch: 5| Step: 9
Training loss: 2.2731680870056152
Validation loss: 1.9420831767461633

Epoch: 5| Step: 10
Training loss: 1.4719280004501343
Validation loss: 1.9127970857004966

Epoch: 218| Step: 0
Training loss: 1.8299922943115234
Validation loss: 1.932765797902179

Epoch: 5| Step: 1
Training loss: 1.576898217201233
Validation loss: 1.917129562747094

Epoch: 5| Step: 2
Training loss: 1.3758676052093506
Validation loss: 1.8881887607677008

Epoch: 5| Step: 3
Training loss: 1.7369966506958008
Validation loss: 1.8640561437094083

Epoch: 5| Step: 4
Training loss: 1.5387378931045532
Validation loss: 1.8816286004999632

Epoch: 5| Step: 5
Training loss: 1.6501796245574951
Validation loss: 1.8958755539309593

Epoch: 5| Step: 6
Training loss: 1.6936038732528687
Validation loss: 1.9111763995180848

Epoch: 5| Step: 7
Training loss: 1.3051413297653198
Validation loss: 1.9339628988696682

Epoch: 5| Step: 8
Training loss: 1.3802307844161987
Validation loss: 1.9490070304562968

Epoch: 5| Step: 9
Training loss: 1.2521783113479614
Validation loss: 1.9692215304220877

Epoch: 5| Step: 10
Training loss: 1.6655864715576172
Validation loss: 1.9637919933565202

Epoch: 219| Step: 0
Training loss: 1.5418727397918701
Validation loss: 1.9606670820584862

Epoch: 5| Step: 1
Training loss: 1.1206591129302979
Validation loss: 1.9646639336821854

Epoch: 5| Step: 2
Training loss: 1.9401094913482666
Validation loss: 1.9530187204319944

Epoch: 5| Step: 3
Training loss: 1.3739521503448486
Validation loss: 1.9313526743201799

Epoch: 5| Step: 4
Training loss: 1.3520314693450928
Validation loss: 1.9125971794128418

Epoch: 5| Step: 5
Training loss: 1.5082848072052002
Validation loss: 1.8907497300896594

Epoch: 5| Step: 6
Training loss: 1.3011350631713867
Validation loss: 1.8886327307711366

Epoch: 5| Step: 7
Training loss: 1.5482518672943115
Validation loss: 1.87541901680731

Epoch: 5| Step: 8
Training loss: 1.3896375894546509
Validation loss: 1.8633789516264392

Epoch: 5| Step: 9
Training loss: 1.1324797868728638
Validation loss: 1.8875067849313059

Epoch: 5| Step: 10
Training loss: 2.630173444747925
Validation loss: 1.9038109510175643

Epoch: 220| Step: 0
Training loss: 1.8100745677947998
Validation loss: 1.9332991902546217

Epoch: 5| Step: 1
Training loss: 1.8284629583358765
Validation loss: 1.955619627429593

Epoch: 5| Step: 2
Training loss: 1.8216365575790405
Validation loss: 1.9820295585099088

Epoch: 5| Step: 3
Training loss: 1.2712339162826538
Validation loss: 2.013908783594767

Epoch: 5| Step: 4
Training loss: 0.9810585975646973
Validation loss: 2.00787797281819

Epoch: 5| Step: 5
Training loss: 1.8706239461898804
Validation loss: 1.9909098148345947

Epoch: 5| Step: 6
Training loss: 1.4702911376953125
Validation loss: 1.9680015784437939

Epoch: 5| Step: 7
Training loss: 0.99702388048172
Validation loss: 1.9498168165965746

Epoch: 5| Step: 8
Training loss: 1.4194481372833252
Validation loss: 1.9359905283938172

Epoch: 5| Step: 9
Training loss: 1.404217004776001
Validation loss: 1.8929404122855074

Epoch: 5| Step: 10
Training loss: 2.0418827533721924
Validation loss: 1.8675737034889959

Epoch: 221| Step: 0
Training loss: 1.4484851360321045
Validation loss: 1.8650312833888556

Epoch: 5| Step: 1
Training loss: 1.8139474391937256
Validation loss: 1.8861369022759058

Epoch: 5| Step: 2
Training loss: 1.3952934741973877
Validation loss: 1.899204093922851

Epoch: 5| Step: 3
Training loss: 1.7084108591079712
Validation loss: 1.9134071501352454

Epoch: 5| Step: 4
Training loss: 1.6808044910430908
Validation loss: 1.8934463390740015

Epoch: 5| Step: 5
Training loss: 1.1288011074066162
Validation loss: 1.9082426717204433

Epoch: 5| Step: 6
Training loss: 1.2197802066802979
Validation loss: 1.9085018968069425

Epoch: 5| Step: 7
Training loss: 1.8898948431015015
Validation loss: 1.9307600157235258

Epoch: 5| Step: 8
Training loss: 1.806295394897461
Validation loss: 1.9543561397060272

Epoch: 5| Step: 9
Training loss: 1.4857609272003174
Validation loss: 1.9648142899236372

Epoch: 5| Step: 10
Training loss: 1.0161595344543457
Validation loss: 1.9791969022443217

Epoch: 222| Step: 0
Training loss: 1.184064507484436
Validation loss: 1.9722683250263173

Epoch: 5| Step: 1
Training loss: 1.0903644561767578
Validation loss: 1.943075644072666

Epoch: 5| Step: 2
Training loss: 1.204134225845337
Validation loss: 1.942582154786715

Epoch: 5| Step: 3
Training loss: 1.8593549728393555
Validation loss: 1.8988633527550647

Epoch: 5| Step: 4
Training loss: 1.1071255207061768
Validation loss: 1.8978403345231087

Epoch: 5| Step: 5
Training loss: 1.1769145727157593
Validation loss: 1.8805966915622834

Epoch: 5| Step: 6
Training loss: 1.9852287769317627
Validation loss: 1.8858282181524462

Epoch: 5| Step: 7
Training loss: 1.8805650472640991
Validation loss: 1.9131425298670286

Epoch: 5| Step: 8
Training loss: 2.1067428588867188
Validation loss: 1.9148904200523131

Epoch: 5| Step: 9
Training loss: 1.4547971487045288
Validation loss: 1.89868293141806

Epoch: 5| Step: 10
Training loss: 1.1640198230743408
Validation loss: 1.8683127434022966

Epoch: 223| Step: 0
Training loss: 1.3010547161102295
Validation loss: 1.8954384788390128

Epoch: 5| Step: 1
Training loss: 1.6550077199935913
Validation loss: 1.867234460769161

Epoch: 5| Step: 2
Training loss: 1.3609203100204468
Validation loss: 1.868067846503309

Epoch: 5| Step: 3
Training loss: 1.3078184127807617
Validation loss: 1.8779913379300026

Epoch: 5| Step: 4
Training loss: 1.389015555381775
Validation loss: 1.8711135028510966

Epoch: 5| Step: 5
Training loss: 1.9288524389266968
Validation loss: 1.88858667624894

Epoch: 5| Step: 6
Training loss: 1.7171308994293213
Validation loss: 1.9107114922615789

Epoch: 5| Step: 7
Training loss: 1.5877745151519775
Validation loss: 1.8933938792956773

Epoch: 5| Step: 8
Training loss: 0.9603587985038757
Validation loss: 1.8824392326416508

Epoch: 5| Step: 9
Training loss: 1.3659471273422241
Validation loss: 1.8728862283050374

Epoch: 5| Step: 10
Training loss: 1.4422742128372192
Validation loss: 1.8750905939327773

Epoch: 224| Step: 0
Training loss: 1.8464744091033936
Validation loss: 1.8763773441314697

Epoch: 5| Step: 1
Training loss: 1.0820834636688232
Validation loss: 1.8927218888395576

Epoch: 5| Step: 2
Training loss: 1.4981613159179688
Validation loss: 1.901367183654539

Epoch: 5| Step: 3
Training loss: 1.7245512008666992
Validation loss: 1.8798723169552383

Epoch: 5| Step: 4
Training loss: 1.1084660291671753
Validation loss: 1.8876348131446428

Epoch: 5| Step: 5
Training loss: 1.6211732625961304
Validation loss: 1.8779156720766457

Epoch: 5| Step: 6
Training loss: 2.09009051322937
Validation loss: 1.879991146825975

Epoch: 5| Step: 7
Training loss: 1.408877968788147
Validation loss: 1.884527680694416

Epoch: 5| Step: 8
Training loss: 0.9846888780593872
Validation loss: 1.8787799009712793

Epoch: 5| Step: 9
Training loss: 1.2087657451629639
Validation loss: 1.8846809146224812

Epoch: 5| Step: 10
Training loss: 1.4062405824661255
Validation loss: 1.8915978144573908

Epoch: 225| Step: 0
Training loss: 1.6622272729873657
Validation loss: 1.909336600252377

Epoch: 5| Step: 1
Training loss: 1.2790437936782837
Validation loss: 1.9071077300656227

Epoch: 5| Step: 2
Training loss: 1.3447178602218628
Validation loss: 1.895817764343754

Epoch: 5| Step: 3
Training loss: 1.9086357355117798
Validation loss: 1.8896361832977624

Epoch: 5| Step: 4
Training loss: 1.8938496112823486
Validation loss: 1.8771208550340386

Epoch: 5| Step: 5
Training loss: 1.2811367511749268
Validation loss: 1.859939190649217

Epoch: 5| Step: 6
Training loss: 1.5445473194122314
Validation loss: 1.8705521398975002

Epoch: 5| Step: 7
Training loss: 1.3084080219268799
Validation loss: 1.8762477123609154

Epoch: 5| Step: 8
Training loss: 1.4487642049789429
Validation loss: 1.875513143436883

Epoch: 5| Step: 9
Training loss: 0.9106317758560181
Validation loss: 1.8626914267898889

Epoch: 5| Step: 10
Training loss: 1.2159552574157715
Validation loss: 1.8499381029477684

Epoch: 226| Step: 0
Training loss: 1.2352914810180664
Validation loss: 1.8733106467031664

Epoch: 5| Step: 1
Training loss: 1.7626104354858398
Validation loss: 1.8753816748178134

Epoch: 5| Step: 2
Training loss: 1.1164737939834595
Validation loss: 1.8909841250347834

Epoch: 5| Step: 3
Training loss: 1.6828769445419312
Validation loss: 1.8770530185391825

Epoch: 5| Step: 4
Training loss: 1.868373155593872
Validation loss: 1.8930040098005725

Epoch: 5| Step: 5
Training loss: 1.6716018915176392
Validation loss: 1.8620131169596026

Epoch: 5| Step: 6
Training loss: 1.2131983041763306
Validation loss: 1.8691833762712375

Epoch: 5| Step: 7
Training loss: 1.5149551630020142
Validation loss: 1.865027461000668

Epoch: 5| Step: 8
Training loss: 1.3598194122314453
Validation loss: 1.868305246035258

Epoch: 5| Step: 9
Training loss: 0.7181787490844727
Validation loss: 1.8840109584152058

Epoch: 5| Step: 10
Training loss: 1.4061301946640015
Validation loss: 1.902121179847307

Epoch: 227| Step: 0
Training loss: 1.6636394262313843
Validation loss: 1.9036999389689455

Epoch: 5| Step: 1
Training loss: 1.2615182399749756
Validation loss: 1.9206578475172802

Epoch: 5| Step: 2
Training loss: 1.9325145483016968
Validation loss: 1.9660976420166671

Epoch: 5| Step: 3
Training loss: 0.9523748159408569
Validation loss: 2.0016247623710224

Epoch: 5| Step: 4
Training loss: 1.3136171102523804
Validation loss: 2.0315496870266494

Epoch: 5| Step: 5
Training loss: 2.0821125507354736
Validation loss: 2.0105820907059537

Epoch: 5| Step: 6
Training loss: 1.6986932754516602
Validation loss: 2.008856966931333

Epoch: 5| Step: 7
Training loss: 1.0916988849639893
Validation loss: 2.0133448493096138

Epoch: 5| Step: 8
Training loss: 1.2680155038833618
Validation loss: 2.0229726555526897

Epoch: 5| Step: 9
Training loss: 2.2450785636901855
Validation loss: 2.000248582132401

Epoch: 5| Step: 10
Training loss: 1.389005184173584
Validation loss: 1.9540531584011611

Epoch: 228| Step: 0
Training loss: 1.2513582706451416
Validation loss: 1.9099732470768753

Epoch: 5| Step: 1
Training loss: 1.4266023635864258
Validation loss: 1.8516771024273289

Epoch: 5| Step: 2
Training loss: 1.4222997426986694
Validation loss: 1.8244923250649565

Epoch: 5| Step: 3
Training loss: 1.3367841243743896
Validation loss: 1.8479873172698482

Epoch: 5| Step: 4
Training loss: 1.2913925647735596
Validation loss: 1.8645998149789789

Epoch: 5| Step: 5
Training loss: 1.4147781133651733
Validation loss: 1.901938872952615

Epoch: 5| Step: 6
Training loss: 1.4284722805023193
Validation loss: 1.8808283998120217

Epoch: 5| Step: 7
Training loss: 1.196865200996399
Validation loss: 1.8900302212725404

Epoch: 5| Step: 8
Training loss: 1.7222812175750732
Validation loss: 1.9082278154229606

Epoch: 5| Step: 9
Training loss: 2.0799529552459717
Validation loss: 1.9432894824653544

Epoch: 5| Step: 10
Training loss: 1.6333227157592773
Validation loss: 1.9677013479253298

Epoch: 229| Step: 0
Training loss: 1.7220592498779297
Validation loss: 1.9798921077482161

Epoch: 5| Step: 1
Training loss: 1.5090734958648682
Validation loss: 1.9901451603058846

Epoch: 5| Step: 2
Training loss: 1.2976590394973755
Validation loss: 1.9838755335859073

Epoch: 5| Step: 3
Training loss: 1.2111406326293945
Validation loss: 1.957058725818511

Epoch: 5| Step: 4
Training loss: 1.453586220741272
Validation loss: 1.9364461821894492

Epoch: 5| Step: 5
Training loss: 1.2854502201080322
Validation loss: 1.9309295172332435

Epoch: 5| Step: 6
Training loss: 1.4857077598571777
Validation loss: 1.9408672317381828

Epoch: 5| Step: 7
Training loss: 1.0720956325531006
Validation loss: 1.916346097505221

Epoch: 5| Step: 8
Training loss: 1.6627264022827148
Validation loss: 1.893018973770962

Epoch: 5| Step: 9
Training loss: 1.076811671257019
Validation loss: 1.8623299944785334

Epoch: 5| Step: 10
Training loss: 1.8060795068740845
Validation loss: 1.8433041508479784

Epoch: 230| Step: 0
Training loss: 1.5254566669464111
Validation loss: 1.839288511583882

Epoch: 5| Step: 1
Training loss: 1.9641027450561523
Validation loss: 1.838058493470633

Epoch: 5| Step: 2
Training loss: 1.4517176151275635
Validation loss: 1.8578073234968289

Epoch: 5| Step: 3
Training loss: 1.435423493385315
Validation loss: 1.8713100853786673

Epoch: 5| Step: 4
Training loss: 0.9461150169372559
Validation loss: 1.8611224620572981

Epoch: 5| Step: 5
Training loss: 1.364640712738037
Validation loss: 1.8667540024685603

Epoch: 5| Step: 6
Training loss: 1.5696384906768799
Validation loss: 1.8866244105882541

Epoch: 5| Step: 7
Training loss: 1.046710729598999
Validation loss: 1.8888289197798698

Epoch: 5| Step: 8
Training loss: 1.011977195739746
Validation loss: 1.9205056775000788

Epoch: 5| Step: 9
Training loss: 0.9631637334823608
Validation loss: 1.9039958215528918

Epoch: 5| Step: 10
Training loss: 2.008957862854004
Validation loss: 1.9251500355300082

Epoch: 231| Step: 0
Training loss: 1.2035138607025146
Validation loss: 1.9047507124562417

Epoch: 5| Step: 1
Training loss: 0.9014032483100891
Validation loss: 1.9107304234658518

Epoch: 5| Step: 2
Training loss: 1.6483207941055298
Validation loss: 1.9074749651775564

Epoch: 5| Step: 3
Training loss: 1.6684871912002563
Validation loss: 1.8909903367360432

Epoch: 5| Step: 4
Training loss: 1.5394515991210938
Validation loss: 1.8838645335166686

Epoch: 5| Step: 5
Training loss: 1.2644764184951782
Validation loss: 1.8591898820733512

Epoch: 5| Step: 6
Training loss: 1.6966416835784912
Validation loss: 1.8586849935593144

Epoch: 5| Step: 7
Training loss: 1.185943603515625
Validation loss: 1.853531604172081

Epoch: 5| Step: 8
Training loss: 1.3838480710983276
Validation loss: 1.8530734918450797

Epoch: 5| Step: 9
Training loss: 0.8475421667098999
Validation loss: 1.8824494807950911

Epoch: 5| Step: 10
Training loss: 1.652669906616211
Validation loss: 1.8895931961715862

Epoch: 232| Step: 0
Training loss: 1.6242866516113281
Validation loss: 1.9170734100444342

Epoch: 5| Step: 1
Training loss: 1.7536922693252563
Validation loss: 1.911397107185856

Epoch: 5| Step: 2
Training loss: 1.2344915866851807
Validation loss: 1.9122828283617574

Epoch: 5| Step: 3
Training loss: 1.7111942768096924
Validation loss: 1.9105537527350969

Epoch: 5| Step: 4
Training loss: 1.393777847290039
Validation loss: 1.9041023664577033

Epoch: 5| Step: 5
Training loss: 1.2079734802246094
Validation loss: 1.9277389203348467

Epoch: 5| Step: 6
Training loss: 1.588059663772583
Validation loss: 1.936019447542006

Epoch: 5| Step: 7
Training loss: 1.3350404500961304
Validation loss: 1.9167388280232747

Epoch: 5| Step: 8
Training loss: 0.8775566220283508
Validation loss: 1.8871462832215011

Epoch: 5| Step: 9
Training loss: 1.0205953121185303
Validation loss: 1.9040015846170404

Epoch: 5| Step: 10
Training loss: 1.4791606664657593
Validation loss: 1.9049290739079958

Epoch: 233| Step: 0
Training loss: 1.52153742313385
Validation loss: 1.9097778976604503

Epoch: 5| Step: 1
Training loss: 1.408152461051941
Validation loss: 1.8967054761866087

Epoch: 5| Step: 2
Training loss: 1.1775844097137451
Validation loss: 1.894804564855432

Epoch: 5| Step: 3
Training loss: 1.7585653066635132
Validation loss: 1.8587565652785762

Epoch: 5| Step: 4
Training loss: 1.2162246704101562
Validation loss: 1.8399445600407098

Epoch: 5| Step: 5
Training loss: 1.0562324523925781
Validation loss: 1.8215450240719704

Epoch: 5| Step: 6
Training loss: 1.6105420589447021
Validation loss: 1.7947474859094108

Epoch: 5| Step: 7
Training loss: 1.4941303730010986
Validation loss: 1.79026759055353

Epoch: 5| Step: 8
Training loss: 1.0223984718322754
Validation loss: 1.7994451035735428

Epoch: 5| Step: 9
Training loss: 1.3230232000350952
Validation loss: 1.7784398242991457

Epoch: 5| Step: 10
Training loss: 1.454943060874939
Validation loss: 1.7896777186342465

Epoch: 234| Step: 0
Training loss: 1.4035491943359375
Validation loss: 1.7874340613683064

Epoch: 5| Step: 1
Training loss: 1.8587125539779663
Validation loss: 1.8053201808724353

Epoch: 5| Step: 2
Training loss: 1.645477056503296
Validation loss: 1.8191135032202608

Epoch: 5| Step: 3
Training loss: 1.117489218711853
Validation loss: 1.8187307850007088

Epoch: 5| Step: 4
Training loss: 1.5168368816375732
Validation loss: 1.8124003666703419

Epoch: 5| Step: 5
Training loss: 1.0925958156585693
Validation loss: 1.8457941470607635

Epoch: 5| Step: 6
Training loss: 1.1315643787384033
Validation loss: 1.84023384253184

Epoch: 5| Step: 7
Training loss: 1.1526129245758057
Validation loss: 1.8594636045476443

Epoch: 5| Step: 8
Training loss: 0.8742011189460754
Validation loss: 1.8983485916609406

Epoch: 5| Step: 9
Training loss: 1.5207959413528442
Validation loss: 1.9186919491778138

Epoch: 5| Step: 10
Training loss: 1.406641960144043
Validation loss: 1.8996196677607875

Epoch: 235| Step: 0
Training loss: 0.8057078123092651
Validation loss: 1.9141981153077976

Epoch: 5| Step: 1
Training loss: 1.3425517082214355
Validation loss: 1.9116104084958312

Epoch: 5| Step: 2
Training loss: 0.9740107655525208
Validation loss: 1.885137934838572

Epoch: 5| Step: 3
Training loss: 1.5825374126434326
Validation loss: 1.9013727518819994

Epoch: 5| Step: 4
Training loss: 1.7439079284667969
Validation loss: 1.90062403550712

Epoch: 5| Step: 5
Training loss: 1.351833701133728
Validation loss: 1.888354673180529

Epoch: 5| Step: 6
Training loss: 0.8510128259658813
Validation loss: 1.8753736813863118

Epoch: 5| Step: 7
Training loss: 1.9873340129852295
Validation loss: 1.8780486301709247

Epoch: 5| Step: 8
Training loss: 1.2706142663955688
Validation loss: 1.8877483926793581

Epoch: 5| Step: 9
Training loss: 1.5311208963394165
Validation loss: 1.9029225559644802

Epoch: 5| Step: 10
Training loss: 1.0978491306304932
Validation loss: 1.9127112447574575

Epoch: 236| Step: 0
Training loss: 1.2051055431365967
Validation loss: 1.8974402207200245

Epoch: 5| Step: 1
Training loss: 0.9265285730361938
Validation loss: 1.8729013915984862

Epoch: 5| Step: 2
Training loss: 1.337539792060852
Validation loss: 1.8917699347260177

Epoch: 5| Step: 3
Training loss: 2.027463912963867
Validation loss: 1.8910538816964755

Epoch: 5| Step: 4
Training loss: 1.4343318939208984
Validation loss: 1.8786951905937606

Epoch: 5| Step: 5
Training loss: 1.3451958894729614
Validation loss: 1.843009489838795

Epoch: 5| Step: 6
Training loss: 1.5151522159576416
Validation loss: 1.8354900293452765

Epoch: 5| Step: 7
Training loss: 1.2722246646881104
Validation loss: 1.81379872111864

Epoch: 5| Step: 8
Training loss: 1.4868671894073486
Validation loss: 1.8359149322714856

Epoch: 5| Step: 9
Training loss: 1.0385359525680542
Validation loss: 1.8638400659766248

Epoch: 5| Step: 10
Training loss: 1.0077030658721924
Validation loss: 1.8818552622231104

Epoch: 237| Step: 0
Training loss: 1.3683109283447266
Validation loss: 1.8974426677150111

Epoch: 5| Step: 1
Training loss: 1.2256810665130615
Validation loss: 1.926159704885175

Epoch: 5| Step: 2
Training loss: 1.5549125671386719
Validation loss: 1.9465552760708718

Epoch: 5| Step: 3
Training loss: 1.4316884279251099
Validation loss: 1.9194127667334773

Epoch: 5| Step: 4
Training loss: 1.4697320461273193
Validation loss: 1.9288685142353017

Epoch: 5| Step: 5
Training loss: 1.4093197584152222
Validation loss: 1.9481987619912753

Epoch: 5| Step: 6
Training loss: 1.1871709823608398
Validation loss: 1.9352654218673706

Epoch: 5| Step: 7
Training loss: 0.6308919787406921
Validation loss: 1.9186041278223838

Epoch: 5| Step: 8
Training loss: 1.3608201742172241
Validation loss: 1.9027102608834543

Epoch: 5| Step: 9
Training loss: 1.2555080652236938
Validation loss: 1.8772238044328586

Epoch: 5| Step: 10
Training loss: 1.276384949684143
Validation loss: 1.890666886042523

Epoch: 238| Step: 0
Training loss: 2.0837719440460205
Validation loss: 1.8343393251460085

Epoch: 5| Step: 1
Training loss: 1.0659891366958618
Validation loss: 1.8151058368785407

Epoch: 5| Step: 2
Training loss: 1.3296058177947998
Validation loss: 1.7960961172657628

Epoch: 5| Step: 3
Training loss: 1.1658719778060913
Validation loss: 1.8074126679410216

Epoch: 5| Step: 4
Training loss: 0.9495833516120911
Validation loss: 1.8110330027918662

Epoch: 5| Step: 5
Training loss: 1.0168287754058838
Validation loss: 1.8408562752508348

Epoch: 5| Step: 6
Training loss: 0.9226170778274536
Validation loss: 1.8465613280573199

Epoch: 5| Step: 7
Training loss: 1.3356497287750244
Validation loss: 1.820754115299512

Epoch: 5| Step: 8
Training loss: 1.3439137935638428
Validation loss: 1.8220638305910173

Epoch: 5| Step: 9
Training loss: 1.5818498134613037
Validation loss: 1.841765470402215

Epoch: 5| Step: 10
Training loss: 1.4741989374160767
Validation loss: 1.8362040032622635

Epoch: 239| Step: 0
Training loss: 1.1794615983963013
Validation loss: 1.8474521367780623

Epoch: 5| Step: 1
Training loss: 1.3967939615249634
Validation loss: 1.883555402037918

Epoch: 5| Step: 2
Training loss: 1.194628357887268
Validation loss: 1.8718434623492661

Epoch: 5| Step: 3
Training loss: 1.2852180004119873
Validation loss: 1.8826545720459313

Epoch: 5| Step: 4
Training loss: 1.0336525440216064
Validation loss: 1.896606347894156

Epoch: 5| Step: 5
Training loss: 1.0554615259170532
Validation loss: 1.8913502488085019

Epoch: 5| Step: 6
Training loss: 1.2687852382659912
Validation loss: 1.8691787604362733

Epoch: 5| Step: 7
Training loss: 1.2737740278244019
Validation loss: 1.8683850175590926

Epoch: 5| Step: 8
Training loss: 1.0963428020477295
Validation loss: 1.852207346629071

Epoch: 5| Step: 9
Training loss: 1.1733332872390747
Validation loss: 1.8509478658758185

Epoch: 5| Step: 10
Training loss: 1.639373779296875
Validation loss: 1.8420495487028552

Epoch: 240| Step: 0
Training loss: 1.0571348667144775
Validation loss: 1.8368163147280294

Epoch: 5| Step: 1
Training loss: 0.9951565861701965
Validation loss: 1.8373738335024925

Epoch: 5| Step: 2
Training loss: 1.303929090499878
Validation loss: 1.840644367279545

Epoch: 5| Step: 3
Training loss: 1.931500792503357
Validation loss: 1.8518205124844787

Epoch: 5| Step: 4
Training loss: 1.345436930656433
Validation loss: 1.8567428511957969

Epoch: 5| Step: 5
Training loss: 1.5833613872528076
Validation loss: 1.8476549463887368

Epoch: 5| Step: 6
Training loss: 1.0821163654327393
Validation loss: 1.844073466075364

Epoch: 5| Step: 7
Training loss: 1.283388614654541
Validation loss: 1.8353582735984557

Epoch: 5| Step: 8
Training loss: 0.8903781175613403
Validation loss: 1.8560073555156749

Epoch: 5| Step: 9
Training loss: 0.8959226608276367
Validation loss: 1.8518100246306388

Epoch: 5| Step: 10
Training loss: 1.0855129957199097
Validation loss: 1.86228766364436

Epoch: 241| Step: 0
Training loss: 1.0990922451019287
Validation loss: 1.8617318189272316

Epoch: 5| Step: 1
Training loss: 1.199635624885559
Validation loss: 1.8636258238105363

Epoch: 5| Step: 2
Training loss: 1.1812188625335693
Validation loss: 1.861007603265906

Epoch: 5| Step: 3
Training loss: 1.1496485471725464
Validation loss: 1.8809191052631666

Epoch: 5| Step: 4
Training loss: 1.3678653240203857
Validation loss: 1.882107621879988

Epoch: 5| Step: 5
Training loss: 0.879673957824707
Validation loss: 1.8991150689381424

Epoch: 5| Step: 6
Training loss: 1.2787654399871826
Validation loss: 1.8685362082655712

Epoch: 5| Step: 7
Training loss: 1.4062044620513916
Validation loss: 1.8522342507557203

Epoch: 5| Step: 8
Training loss: 1.370985507965088
Validation loss: 1.8418032725652058

Epoch: 5| Step: 9
Training loss: 0.7946678996086121
Validation loss: 1.8469265827568628

Epoch: 5| Step: 10
Training loss: 1.4578198194503784
Validation loss: 1.830804645374257

Epoch: 242| Step: 0
Training loss: 1.114201307296753
Validation loss: 1.818361661767447

Epoch: 5| Step: 1
Training loss: 1.1250219345092773
Validation loss: 1.812856012775052

Epoch: 5| Step: 2
Training loss: 1.0573608875274658
Validation loss: 1.805119163246565

Epoch: 5| Step: 3
Training loss: 1.2972216606140137
Validation loss: 1.7894899165758522

Epoch: 5| Step: 4
Training loss: 1.4879051446914673
Validation loss: 1.7802752435848277

Epoch: 5| Step: 5
Training loss: 0.8798149824142456
Validation loss: 1.7859076787066717

Epoch: 5| Step: 6
Training loss: 1.194986343383789
Validation loss: 1.8093578482186923

Epoch: 5| Step: 7
Training loss: 1.409695029258728
Validation loss: 1.8076536732335244

Epoch: 5| Step: 8
Training loss: 1.1897586584091187
Validation loss: 1.791305600955922

Epoch: 5| Step: 9
Training loss: 1.4224063158035278
Validation loss: 1.8289556682750743

Epoch: 5| Step: 10
Training loss: 1.1158231496810913
Validation loss: 1.8426863224275651

Epoch: 243| Step: 0
Training loss: 1.1554075479507446
Validation loss: 1.8598202531055739

Epoch: 5| Step: 1
Training loss: 1.324526071548462
Validation loss: 1.8563935038863972

Epoch: 5| Step: 2
Training loss: 1.3985494375228882
Validation loss: 1.8376996747909053

Epoch: 5| Step: 3
Training loss: 0.7921267747879028
Validation loss: 1.8407513274941394

Epoch: 5| Step: 4
Training loss: 1.0494381189346313
Validation loss: 1.817508585991398

Epoch: 5| Step: 5
Training loss: 1.4058316946029663
Validation loss: 1.8178247597909742

Epoch: 5| Step: 6
Training loss: 1.0315322875976562
Validation loss: 1.8392962589058826

Epoch: 5| Step: 7
Training loss: 1.0962045192718506
Validation loss: 1.8478213805024342

Epoch: 5| Step: 8
Training loss: 1.476547122001648
Validation loss: 1.8612865081397436

Epoch: 5| Step: 9
Training loss: 0.8772113919258118
Validation loss: 1.8545005603503155

Epoch: 5| Step: 10
Training loss: 1.4225358963012695
Validation loss: 1.8463826128231582

Epoch: 244| Step: 0
Training loss: 0.9203356504440308
Validation loss: 1.8316133073581162

Epoch: 5| Step: 1
Training loss: 1.1222423315048218
Validation loss: 1.8114297684802805

Epoch: 5| Step: 2
Training loss: 1.0125676393508911
Validation loss: 1.8198941420483332

Epoch: 5| Step: 3
Training loss: 1.1171343326568604
Validation loss: 1.82517239868

Epoch: 5| Step: 4
Training loss: 0.9555780291557312
Validation loss: 1.8582419528756091

Epoch: 5| Step: 5
Training loss: 1.1512407064437866
Validation loss: 1.8372234977701658

Epoch: 5| Step: 6
Training loss: 1.1926097869873047
Validation loss: 1.827192497509782

Epoch: 5| Step: 7
Training loss: 1.0770626068115234
Validation loss: 1.8405417216721403

Epoch: 5| Step: 8
Training loss: 1.1818718910217285
Validation loss: 1.831259850532778

Epoch: 5| Step: 9
Training loss: 1.1708964109420776
Validation loss: 1.8055618834751908

Epoch: 5| Step: 10
Training loss: 1.8599352836608887
Validation loss: 1.8122496733101465

Epoch: 245| Step: 0
Training loss: 0.8165661096572876
Validation loss: 1.8407261153703094

Epoch: 5| Step: 1
Training loss: 1.396363377571106
Validation loss: 1.8503612395255797

Epoch: 5| Step: 2
Training loss: 1.129238486289978
Validation loss: 1.860637923722626

Epoch: 5| Step: 3
Training loss: 1.2216641902923584
Validation loss: 1.8913669009362497

Epoch: 5| Step: 4
Training loss: 1.046139121055603
Validation loss: 1.8906933697321082

Epoch: 5| Step: 5
Training loss: 1.4967372417449951
Validation loss: 1.8933313674824213

Epoch: 5| Step: 6
Training loss: 0.7886540293693542
Validation loss: 1.8710432693522463

Epoch: 5| Step: 7
Training loss: 1.3731534481048584
Validation loss: 1.8562371602622412

Epoch: 5| Step: 8
Training loss: 1.6860615015029907
Validation loss: 1.8572587133735738

Epoch: 5| Step: 9
Training loss: 1.0171616077423096
Validation loss: 1.8378973840385355

Epoch: 5| Step: 10
Training loss: 0.6637995839118958
Validation loss: 1.8239765628691642

Epoch: 246| Step: 0
Training loss: 1.291693091392517
Validation loss: 1.8098384770013953

Epoch: 5| Step: 1
Training loss: 1.0732237100601196
Validation loss: 1.804694455157044

Epoch: 5| Step: 2
Training loss: 0.9009504318237305
Validation loss: 1.7935047790568361

Epoch: 5| Step: 3
Training loss: 0.832155704498291
Validation loss: 1.8046429464893956

Epoch: 5| Step: 4
Training loss: 0.9211724400520325
Validation loss: 1.834040318765948

Epoch: 5| Step: 5
Training loss: 1.1794062852859497
Validation loss: 1.8217781679604643

Epoch: 5| Step: 6
Training loss: 1.454571008682251
Validation loss: 1.8080596590554843

Epoch: 5| Step: 7
Training loss: 1.3817498683929443
Validation loss: 1.8103457714921685

Epoch: 5| Step: 8
Training loss: 1.3657656908035278
Validation loss: 1.8220776550231441

Epoch: 5| Step: 9
Training loss: 1.3996518850326538
Validation loss: 1.8363841208078528

Epoch: 5| Step: 10
Training loss: 0.7902069091796875
Validation loss: 1.8545949664167178

Epoch: 247| Step: 0
Training loss: 1.6189162731170654
Validation loss: 1.8589172799100158

Epoch: 5| Step: 1
Training loss: 1.3302538394927979
Validation loss: 1.8581143207447504

Epoch: 5| Step: 2
Training loss: 0.9794050455093384
Validation loss: 1.8454648602393366

Epoch: 5| Step: 3
Training loss: 0.8290932774543762
Validation loss: 1.8310563384845693

Epoch: 5| Step: 4
Training loss: 0.9303181767463684
Validation loss: 1.8205357264446955

Epoch: 5| Step: 5
Training loss: 0.9837058782577515
Validation loss: 1.7905832176567407

Epoch: 5| Step: 6
Training loss: 0.8433182835578918
Validation loss: 1.773400181083269

Epoch: 5| Step: 7
Training loss: 0.9041117429733276
Validation loss: 1.7681519985198975

Epoch: 5| Step: 8
Training loss: 1.4503347873687744
Validation loss: 1.7560066792272753

Epoch: 5| Step: 9
Training loss: 1.5629557371139526
Validation loss: 1.7552454881770636

Epoch: 5| Step: 10
Training loss: 1.056929349899292
Validation loss: 1.767253266867771

Epoch: 248| Step: 0
Training loss: 1.4568259716033936
Validation loss: 1.7859460705070085

Epoch: 5| Step: 1
Training loss: 1.3529802560806274
Validation loss: 1.8144520392981909

Epoch: 5| Step: 2
Training loss: 1.2588164806365967
Validation loss: 1.8187586915108465

Epoch: 5| Step: 3
Training loss: 1.1931465864181519
Validation loss: 1.8381143231545725

Epoch: 5| Step: 4
Training loss: 1.1720616817474365
Validation loss: 1.832024170506385

Epoch: 5| Step: 5
Training loss: 0.7616420388221741
Validation loss: 1.823937423767582

Epoch: 5| Step: 6
Training loss: 0.692834734916687
Validation loss: 1.7882105919622606

Epoch: 5| Step: 7
Training loss: 1.4496116638183594
Validation loss: 1.779511720903458

Epoch: 5| Step: 8
Training loss: 1.2519571781158447
Validation loss: 1.7970430927891885

Epoch: 5| Step: 9
Training loss: 0.5396510362625122
Validation loss: 1.8097396140457482

Epoch: 5| Step: 10
Training loss: 1.00631582736969
Validation loss: 1.8238162468838435

Epoch: 249| Step: 0
Training loss: 1.1284140348434448
Validation loss: 1.8232694954000495

Epoch: 5| Step: 1
Training loss: 1.0575263500213623
Validation loss: 1.8314746092724543

Epoch: 5| Step: 2
Training loss: 1.0529074668884277
Validation loss: 1.8528194888945548

Epoch: 5| Step: 3
Training loss: 1.0893932580947876
Validation loss: 1.8381819455854354

Epoch: 5| Step: 4
Training loss: 0.6766185760498047
Validation loss: 1.8170519310940978

Epoch: 5| Step: 5
Training loss: 0.6698929071426392
Validation loss: 1.8136646593770673

Epoch: 5| Step: 6
Training loss: 1.350887656211853
Validation loss: 1.8008433131761448

Epoch: 5| Step: 7
Training loss: 0.8700135946273804
Validation loss: 1.8123754826925134

Epoch: 5| Step: 8
Training loss: 1.4251739978790283
Validation loss: 1.8280201240252423

Epoch: 5| Step: 9
Training loss: 1.2878315448760986
Validation loss: 1.8418219320235714

Epoch: 5| Step: 10
Training loss: 1.331434965133667
Validation loss: 1.8596517911521337

Epoch: 250| Step: 0
Training loss: 1.0193053483963013
Validation loss: 1.891269160855201

Epoch: 5| Step: 1
Training loss: 1.0775527954101562
Validation loss: 1.9141757488250732

Epoch: 5| Step: 2
Training loss: 1.6333118677139282
Validation loss: 1.8868605680363153

Epoch: 5| Step: 3
Training loss: 1.130041241645813
Validation loss: 1.8589089967871224

Epoch: 5| Step: 4
Training loss: 0.9930987358093262
Validation loss: 1.8487488172387565

Epoch: 5| Step: 5
Training loss: 1.3718061447143555
Validation loss: 1.8215908837574784

Epoch: 5| Step: 6
Training loss: 0.7330948114395142
Validation loss: 1.8377953831867506

Epoch: 5| Step: 7
Training loss: 0.9297932386398315
Validation loss: 1.8265408392875426

Epoch: 5| Step: 8
Training loss: 0.7485907077789307
Validation loss: 1.791014895644239

Epoch: 5| Step: 9
Training loss: 0.8579704165458679
Validation loss: 1.8213900250773276

Epoch: 5| Step: 10
Training loss: 1.4750168323516846
Validation loss: 1.8509387008605465

Testing loss: 2.3375502957238092
