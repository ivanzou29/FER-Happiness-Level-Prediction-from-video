Epoch: 1| Step: 0
Training loss: 5.38053035736084
Validation loss: 5.131722962984475

Epoch: 5| Step: 1
Training loss: 4.337152004241943
Validation loss: 5.100865492256739

Epoch: 5| Step: 2
Training loss: 4.964825630187988
Validation loss: 5.070960908807734

Epoch: 5| Step: 3
Training loss: 4.6189961433410645
Validation loss: 5.040673209774878

Epoch: 5| Step: 4
Training loss: 5.253533840179443
Validation loss: 5.006344436317362

Epoch: 5| Step: 5
Training loss: 4.9430999755859375
Validation loss: 4.968260883003153

Epoch: 5| Step: 6
Training loss: 3.9643630981445312
Validation loss: 4.92526485073951

Epoch: 5| Step: 7
Training loss: 5.26076602935791
Validation loss: 4.876458342357348

Epoch: 5| Step: 8
Training loss: 5.119221210479736
Validation loss: 4.823550211485996

Epoch: 5| Step: 9
Training loss: 3.969459056854248
Validation loss: 4.765252759379726

Epoch: 5| Step: 10
Training loss: 4.304838180541992
Validation loss: 4.70218845593032

Epoch: 2| Step: 0
Training loss: 3.7352592945098877
Validation loss: 4.636791593285017

Epoch: 5| Step: 1
Training loss: 4.202389717102051
Validation loss: 4.566975116729736

Epoch: 5| Step: 2
Training loss: 3.936866044998169
Validation loss: 4.497224707757273

Epoch: 5| Step: 3
Training loss: 4.017209053039551
Validation loss: 4.4230073549414195

Epoch: 5| Step: 4
Training loss: 4.259608268737793
Validation loss: 4.353189411983695

Epoch: 5| Step: 5
Training loss: 3.5388550758361816
Validation loss: 4.285203902952133

Epoch: 5| Step: 6
Training loss: 4.983889102935791
Validation loss: 4.217282777191491

Epoch: 5| Step: 7
Training loss: 3.935147762298584
Validation loss: 4.149341211524061

Epoch: 5| Step: 8
Training loss: 4.579748153686523
Validation loss: 4.083357446937151

Epoch: 5| Step: 9
Training loss: 4.37769079208374
Validation loss: 4.012324697227888

Epoch: 5| Step: 10
Training loss: 3.5257980823516846
Validation loss: 3.950179289746028

Epoch: 3| Step: 0
Training loss: 4.648705005645752
Validation loss: 3.8945311987271873

Epoch: 5| Step: 1
Training loss: 4.561030864715576
Validation loss: 3.8451282080783638

Epoch: 5| Step: 2
Training loss: 3.146176815032959
Validation loss: 3.799107433647238

Epoch: 5| Step: 3
Training loss: 3.2673516273498535
Validation loss: 3.751418939200781

Epoch: 5| Step: 4
Training loss: 4.393874645233154
Validation loss: 3.7075925693717053

Epoch: 5| Step: 5
Training loss: 3.3006033897399902
Validation loss: 3.6629232745016775

Epoch: 5| Step: 6
Training loss: 4.0484490394592285
Validation loss: 3.6101644680064213

Epoch: 5| Step: 7
Training loss: 2.654711961746216
Validation loss: 3.563121126544091

Epoch: 5| Step: 8
Training loss: 3.3301234245300293
Validation loss: 3.522861349967218

Epoch: 5| Step: 9
Training loss: 2.7918543815612793
Validation loss: 3.4870412349700928

Epoch: 5| Step: 10
Training loss: 3.260406732559204
Validation loss: 3.459916509607787

Epoch: 4| Step: 0
Training loss: 2.637298107147217
Validation loss: 3.441569697472357

Epoch: 5| Step: 1
Training loss: 3.52180552482605
Validation loss: 3.421897690783265

Epoch: 5| Step: 2
Training loss: 3.0227084159851074
Validation loss: 3.4071555727271625

Epoch: 5| Step: 3
Training loss: 4.09008264541626
Validation loss: 3.3883956452851653

Epoch: 5| Step: 4
Training loss: 3.4548606872558594
Validation loss: 3.3642879865502797

Epoch: 5| Step: 5
Training loss: 3.2294585704803467
Validation loss: 3.3404721444652927

Epoch: 5| Step: 6
Training loss: 3.133923053741455
Validation loss: 3.3215212693778415

Epoch: 5| Step: 7
Training loss: 3.5670082569122314
Validation loss: 3.302784788993097

Epoch: 5| Step: 8
Training loss: 2.5618083477020264
Validation loss: 3.286206986314507

Epoch: 5| Step: 9
Training loss: 2.9306063652038574
Validation loss: 3.26822337027519

Epoch: 5| Step: 10
Training loss: 4.446444988250732
Validation loss: 3.253297516094741

Epoch: 5| Step: 0
Training loss: 2.4747207164764404
Validation loss: 3.242089399727442

Epoch: 5| Step: 1
Training loss: 3.3261895179748535
Validation loss: 3.2241048146319646

Epoch: 5| Step: 2
Training loss: 3.351008653640747
Validation loss: 3.212841741500362

Epoch: 5| Step: 3
Training loss: 3.8063645362854004
Validation loss: 3.198772217637749

Epoch: 5| Step: 4
Training loss: 3.1221604347229004
Validation loss: 3.181729596148255

Epoch: 5| Step: 5
Training loss: 3.236107349395752
Validation loss: 3.1583635781400945

Epoch: 5| Step: 6
Training loss: 2.4621193408966064
Validation loss: 3.1438857150334183

Epoch: 5| Step: 7
Training loss: 3.879995346069336
Validation loss: 3.136198792406308

Epoch: 5| Step: 8
Training loss: 3.581059217453003
Validation loss: 3.123392584503338

Epoch: 5| Step: 9
Training loss: 2.24172306060791
Validation loss: 3.105029606050061

Epoch: 5| Step: 10
Training loss: 3.4663968086242676
Validation loss: 3.092598940736504

Epoch: 6| Step: 0
Training loss: 2.2043468952178955
Validation loss: 3.079965906758462

Epoch: 5| Step: 1
Training loss: 3.1502766609191895
Validation loss: 3.073566754659017

Epoch: 5| Step: 2
Training loss: 3.6995997428894043
Validation loss: 3.0668659389659925

Epoch: 5| Step: 3
Training loss: 2.7647128105163574
Validation loss: 3.0570622669753207

Epoch: 5| Step: 4
Training loss: 2.896191120147705
Validation loss: 3.044490527081233

Epoch: 5| Step: 5
Training loss: 2.654778003692627
Validation loss: 3.0425744107974473

Epoch: 5| Step: 6
Training loss: 2.913576602935791
Validation loss: 3.0281228506436912

Epoch: 5| Step: 7
Training loss: 3.0097568035125732
Validation loss: 3.023977853918588

Epoch: 5| Step: 8
Training loss: 3.2658305168151855
Validation loss: 3.0214311845840944

Epoch: 5| Step: 9
Training loss: 3.0559582710266113
Validation loss: 3.014875670915009

Epoch: 5| Step: 10
Training loss: 4.630335807800293
Validation loss: 3.0120824254969114

Epoch: 7| Step: 0
Training loss: 3.265918731689453
Validation loss: 3.002636627484393

Epoch: 5| Step: 1
Training loss: 3.0028698444366455
Validation loss: 2.988158133722121

Epoch: 5| Step: 2
Training loss: 3.4199776649475098
Validation loss: 2.9784863918058333

Epoch: 5| Step: 3
Training loss: 2.2600977420806885
Validation loss: 2.9780213063763035

Epoch: 5| Step: 4
Training loss: 3.1341958045959473
Validation loss: 3.031393999694496

Epoch: 5| Step: 5
Training loss: 3.595902919769287
Validation loss: 3.0084391947715514

Epoch: 5| Step: 6
Training loss: 3.2743911743164062
Validation loss: 3.003168039424445

Epoch: 5| Step: 7
Training loss: 2.414525032043457
Validation loss: 3.002499326582878

Epoch: 5| Step: 8
Training loss: 3.218289852142334
Validation loss: 3.0150355549268824

Epoch: 5| Step: 9
Training loss: 3.2550525665283203
Validation loss: 3.013078763920774

Epoch: 5| Step: 10
Training loss: 2.8453168869018555
Validation loss: 2.980633730529457

Epoch: 8| Step: 0
Training loss: 3.7454898357391357
Validation loss: 2.9609491773830947

Epoch: 5| Step: 1
Training loss: 3.0642306804656982
Validation loss: 2.954958869564918

Epoch: 5| Step: 2
Training loss: 2.7630395889282227
Validation loss: 2.9464514127341648

Epoch: 5| Step: 3
Training loss: 2.99586820602417
Validation loss: 2.9371575181202223

Epoch: 5| Step: 4
Training loss: 2.649832248687744
Validation loss: 2.9302517009037796

Epoch: 5| Step: 5
Training loss: 3.1974937915802
Validation loss: 2.925152814516457

Epoch: 5| Step: 6
Training loss: 2.824645757675171
Validation loss: 2.9207385534881265

Epoch: 5| Step: 7
Training loss: 2.713629722595215
Validation loss: 2.927079298162973

Epoch: 5| Step: 8
Training loss: 2.9272873401641846
Validation loss: 2.922295742137458

Epoch: 5| Step: 9
Training loss: 2.883340358734131
Validation loss: 2.9060656639837448

Epoch: 5| Step: 10
Training loss: 3.5586915016174316
Validation loss: 2.905764595154793

Epoch: 9| Step: 0
Training loss: 2.0736048221588135
Validation loss: 2.90171322771298

Epoch: 5| Step: 1
Training loss: 2.807267427444458
Validation loss: 2.903474146319974

Epoch: 5| Step: 2
Training loss: 2.733551502227783
Validation loss: 2.895223545771773

Epoch: 5| Step: 3
Training loss: 3.4333622455596924
Validation loss: 2.883392544202907

Epoch: 5| Step: 4
Training loss: 2.808875560760498
Validation loss: 2.8783398469289145

Epoch: 5| Step: 5
Training loss: 3.9843649864196777
Validation loss: 2.873653704120267

Epoch: 5| Step: 6
Training loss: 2.8127853870391846
Validation loss: 2.881688948600523

Epoch: 5| Step: 7
Training loss: 3.755966901779175
Validation loss: 2.8653891624942904

Epoch: 5| Step: 8
Training loss: 2.9944756031036377
Validation loss: 2.8602365755265757

Epoch: 5| Step: 9
Training loss: 2.3860855102539062
Validation loss: 2.8594566698997252

Epoch: 5| Step: 10
Training loss: 3.0132250785827637
Validation loss: 2.8568851537601923

Epoch: 10| Step: 0
Training loss: 2.9485652446746826
Validation loss: 2.857863854336482

Epoch: 5| Step: 1
Training loss: 2.495360851287842
Validation loss: 2.843873272659958

Epoch: 5| Step: 2
Training loss: 2.6720941066741943
Validation loss: 2.8395239460852837

Epoch: 5| Step: 3
Training loss: 2.6673474311828613
Validation loss: 2.839080595201062

Epoch: 5| Step: 4
Training loss: 2.832412004470825
Validation loss: 2.835237546633649

Epoch: 5| Step: 5
Training loss: 3.218846082687378
Validation loss: 2.8275831591698433

Epoch: 5| Step: 6
Training loss: 2.550229787826538
Validation loss: 2.8196426591565533

Epoch: 5| Step: 7
Training loss: 3.807563304901123
Validation loss: 2.810642166804242

Epoch: 5| Step: 8
Training loss: 3.3201770782470703
Validation loss: 2.8095359622791247

Epoch: 5| Step: 9
Training loss: 2.711416006088257
Validation loss: 2.807616687590076

Epoch: 5| Step: 10
Training loss: 3.2655751705169678
Validation loss: 2.8021033117848058

Epoch: 11| Step: 0
Training loss: 3.001992702484131
Validation loss: 2.7965675887241157

Epoch: 5| Step: 1
Training loss: 2.954374313354492
Validation loss: 2.798857399212417

Epoch: 5| Step: 2
Training loss: 3.2939212322235107
Validation loss: 2.7913995378760883

Epoch: 5| Step: 3
Training loss: 2.442072629928589
Validation loss: 2.784206598035751

Epoch: 5| Step: 4
Training loss: 2.8469746112823486
Validation loss: 2.7783252321263796

Epoch: 5| Step: 5
Training loss: 2.6634912490844727
Validation loss: 2.779695141700006

Epoch: 5| Step: 6
Training loss: 2.7228496074676514
Validation loss: 2.77617976486042

Epoch: 5| Step: 7
Training loss: 2.8188538551330566
Validation loss: 2.768674232626474

Epoch: 5| Step: 8
Training loss: 3.5499253273010254
Validation loss: 2.7677984981126684

Epoch: 5| Step: 9
Training loss: 1.930294394493103
Validation loss: 2.768014200272099

Epoch: 5| Step: 10
Training loss: 3.961791515350342
Validation loss: 2.7680796192538355

Epoch: 12| Step: 0
Training loss: 2.696986675262451
Validation loss: 2.781764979003578

Epoch: 5| Step: 1
Training loss: 2.34517502784729
Validation loss: 2.80267079927588

Epoch: 5| Step: 2
Training loss: 2.7411115169525146
Validation loss: 2.7583711608763664

Epoch: 5| Step: 3
Training loss: 3.118725538253784
Validation loss: 2.7530350864574475

Epoch: 5| Step: 4
Training loss: 3.00878643989563
Validation loss: 2.75610121603935

Epoch: 5| Step: 5
Training loss: 3.2923264503479004
Validation loss: 2.7603031076410764

Epoch: 5| Step: 6
Training loss: 2.742525577545166
Validation loss: 2.761372632877801

Epoch: 5| Step: 7
Training loss: 2.183415174484253
Validation loss: 2.758442776177519

Epoch: 5| Step: 8
Training loss: 3.4779536724090576
Validation loss: 2.7628795305887857

Epoch: 5| Step: 9
Training loss: 2.732570171356201
Validation loss: 2.760466324385776

Epoch: 5| Step: 10
Training loss: 3.7367606163024902
Validation loss: 2.7566112190164547

Epoch: 13| Step: 0
Training loss: 2.527310371398926
Validation loss: 2.7445528712323917

Epoch: 5| Step: 1
Training loss: 3.1111748218536377
Validation loss: 2.7436670693018104

Epoch: 5| Step: 2
Training loss: 2.0014595985412598
Validation loss: 2.7469625729386524

Epoch: 5| Step: 3
Training loss: 2.8932414054870605
Validation loss: 2.7433505853017173

Epoch: 5| Step: 4
Training loss: 3.0662848949432373
Validation loss: 2.7348793270767375

Epoch: 5| Step: 5
Training loss: 3.1696178913116455
Validation loss: 2.7330553275282665

Epoch: 5| Step: 6
Training loss: 2.7769675254821777
Validation loss: 2.733755211676321

Epoch: 5| Step: 7
Training loss: 3.0132038593292236
Validation loss: 2.733399424501645

Epoch: 5| Step: 8
Training loss: 3.4286491870880127
Validation loss: 2.727066598912721

Epoch: 5| Step: 9
Training loss: 2.8476595878601074
Validation loss: 2.7232060329888457

Epoch: 5| Step: 10
Training loss: 2.9535274505615234
Validation loss: 2.7272019232473066

Epoch: 14| Step: 0
Training loss: 2.026425838470459
Validation loss: 2.7298844937355287

Epoch: 5| Step: 1
Training loss: 2.7136709690093994
Validation loss: 2.735484210393762

Epoch: 5| Step: 2
Training loss: 3.3923614025115967
Validation loss: 2.7620640877754457

Epoch: 5| Step: 3
Training loss: 2.9774551391601562
Validation loss: 2.7568291464159564

Epoch: 5| Step: 4
Training loss: 2.125837802886963
Validation loss: 2.7337036389176563

Epoch: 5| Step: 5
Training loss: 3.3849987983703613
Validation loss: 2.727627456829112

Epoch: 5| Step: 6
Training loss: 3.0174643993377686
Validation loss: 2.722096235521378

Epoch: 5| Step: 7
Training loss: 3.1452572345733643
Validation loss: 2.7209075650861188

Epoch: 5| Step: 8
Training loss: 3.861323833465576
Validation loss: 2.7195523861915833

Epoch: 5| Step: 9
Training loss: 2.371537446975708
Validation loss: 2.719250694397957

Epoch: 5| Step: 10
Training loss: 2.7281265258789062
Validation loss: 2.7169949598209833

Epoch: 15| Step: 0
Training loss: 2.9396936893463135
Validation loss: 2.7069273533359652

Epoch: 5| Step: 1
Training loss: 3.1213958263397217
Validation loss: 2.7084057279812392

Epoch: 5| Step: 2
Training loss: 3.5765273571014404
Validation loss: 2.7050244500560146

Epoch: 5| Step: 3
Training loss: 3.049119710922241
Validation loss: 2.7032826844082085

Epoch: 5| Step: 4
Training loss: 2.628596067428589
Validation loss: 2.6998984224052838

Epoch: 5| Step: 5
Training loss: 2.902287244796753
Validation loss: 2.699005155153172

Epoch: 5| Step: 6
Training loss: 2.2849669456481934
Validation loss: 2.7092375857855684

Epoch: 5| Step: 7
Training loss: 2.4116339683532715
Validation loss: 2.705737554898826

Epoch: 5| Step: 8
Training loss: 2.943984270095825
Validation loss: 2.7051923069902646

Epoch: 5| Step: 9
Training loss: 3.201601028442383
Validation loss: 2.7157781252297024

Epoch: 5| Step: 10
Training loss: 2.4076521396636963
Validation loss: 2.6963197851693756

Epoch: 16| Step: 0
Training loss: 3.162452220916748
Validation loss: 2.6922104973946848

Epoch: 5| Step: 1
Training loss: 2.6333911418914795
Validation loss: 2.696688893020794

Epoch: 5| Step: 2
Training loss: 3.095933198928833
Validation loss: 2.6927925361100065

Epoch: 5| Step: 3
Training loss: 3.1146023273468018
Validation loss: 2.6911367857328026

Epoch: 5| Step: 4
Training loss: 2.429236888885498
Validation loss: 2.688755412255564

Epoch: 5| Step: 5
Training loss: 4.020866394042969
Validation loss: 2.6884988123370754

Epoch: 5| Step: 6
Training loss: 2.7132821083068848
Validation loss: 2.684826171526345

Epoch: 5| Step: 7
Training loss: 2.880190372467041
Validation loss: 2.6918482037000757

Epoch: 5| Step: 8
Training loss: 3.085292100906372
Validation loss: 2.71042703300394

Epoch: 5| Step: 9
Training loss: 2.2475743293762207
Validation loss: 2.711334602807158

Epoch: 5| Step: 10
Training loss: 1.94313383102417
Validation loss: 2.7108569863022014

Epoch: 17| Step: 0
Training loss: 2.391594171524048
Validation loss: 2.700485655056533

Epoch: 5| Step: 1
Training loss: 3.0432288646698
Validation loss: 2.6786942635813067

Epoch: 5| Step: 2
Training loss: 3.4878039360046387
Validation loss: 2.683693660202847

Epoch: 5| Step: 3
Training loss: 2.943986177444458
Validation loss: 2.6875279847011773

Epoch: 5| Step: 4
Training loss: 2.5362489223480225
Validation loss: 2.6966789307132846

Epoch: 5| Step: 5
Training loss: 2.9914355278015137
Validation loss: 2.705566390868156

Epoch: 5| Step: 6
Training loss: 2.4485981464385986
Validation loss: 2.7178938081187587

Epoch: 5| Step: 7
Training loss: 3.5845565795898438
Validation loss: 2.7193632766764653

Epoch: 5| Step: 8
Training loss: 3.047924041748047
Validation loss: 2.6983763223053305

Epoch: 5| Step: 9
Training loss: 2.460392475128174
Validation loss: 2.684949977423555

Epoch: 5| Step: 10
Training loss: 2.593289613723755
Validation loss: 2.680823282528949

Epoch: 18| Step: 0
Training loss: 2.774242401123047
Validation loss: 2.678586785511304

Epoch: 5| Step: 1
Training loss: 2.5203700065612793
Validation loss: 2.678001465335969

Epoch: 5| Step: 2
Training loss: 2.7152984142303467
Validation loss: 2.680503865723969

Epoch: 5| Step: 3
Training loss: 2.4346752166748047
Validation loss: 2.6773217954943256

Epoch: 5| Step: 4
Training loss: 3.243875026702881
Validation loss: 2.6819594496039936

Epoch: 5| Step: 5
Training loss: 3.175243854522705
Validation loss: 2.7271360710103023

Epoch: 5| Step: 6
Training loss: 3.507532835006714
Validation loss: 2.722315275540916

Epoch: 5| Step: 7
Training loss: 2.0890421867370605
Validation loss: 2.7118222636561238

Epoch: 5| Step: 8
Training loss: 3.2144367694854736
Validation loss: 2.676499505196848

Epoch: 5| Step: 9
Training loss: 2.92256498336792
Validation loss: 2.6941826215354343

Epoch: 5| Step: 10
Training loss: 2.863593101501465
Validation loss: 2.71813105511409

Epoch: 19| Step: 0
Training loss: 2.80574369430542
Validation loss: 2.668550814351728

Epoch: 5| Step: 1
Training loss: 2.3676958084106445
Validation loss: 2.662647662624236

Epoch: 5| Step: 2
Training loss: 2.937201976776123
Validation loss: 2.6619338668802732

Epoch: 5| Step: 3
Training loss: 2.6764512062072754
Validation loss: 2.6627857326179423

Epoch: 5| Step: 4
Training loss: 2.927445888519287
Validation loss: 2.6768340577361402

Epoch: 5| Step: 5
Training loss: 2.8267440795898438
Validation loss: 2.6764512831164944

Epoch: 5| Step: 6
Training loss: 2.5411202907562256
Validation loss: 2.675483401103686

Epoch: 5| Step: 7
Training loss: 2.5752289295196533
Validation loss: 2.6699948413397676

Epoch: 5| Step: 8
Training loss: 3.0130066871643066
Validation loss: 2.6703619162241616

Epoch: 5| Step: 9
Training loss: 3.759131908416748
Validation loss: 2.664117085036411

Epoch: 5| Step: 10
Training loss: 2.942460060119629
Validation loss: 2.6605066535293416

Epoch: 20| Step: 0
Training loss: 2.484330892562866
Validation loss: 2.659355281501688

Epoch: 5| Step: 1
Training loss: 2.858471393585205
Validation loss: 2.659364579826273

Epoch: 5| Step: 2
Training loss: 3.4496188163757324
Validation loss: 2.6570373965847875

Epoch: 5| Step: 3
Training loss: 2.647426128387451
Validation loss: 2.6573113087684876

Epoch: 5| Step: 4
Training loss: 2.4015145301818848
Validation loss: 2.6535841623942056

Epoch: 5| Step: 5
Training loss: 2.787506103515625
Validation loss: 2.6523045852620113

Epoch: 5| Step: 6
Training loss: 2.9392435550689697
Validation loss: 2.6507506216725996

Epoch: 5| Step: 7
Training loss: 2.6401870250701904
Validation loss: 2.6516871657422794

Epoch: 5| Step: 8
Training loss: 3.291980266571045
Validation loss: 2.6480749499413276

Epoch: 5| Step: 9
Training loss: 2.8765594959259033
Validation loss: 2.6442272022206295

Epoch: 5| Step: 10
Training loss: 2.891937494277954
Validation loss: 2.643838231281568

Epoch: 21| Step: 0
Training loss: 2.9677741527557373
Validation loss: 2.642938426745835

Epoch: 5| Step: 1
Training loss: 2.7168233394622803
Validation loss: 2.640848300790274

Epoch: 5| Step: 2
Training loss: 3.0943286418914795
Validation loss: 2.6386119883547545

Epoch: 5| Step: 3
Training loss: 2.5769665241241455
Validation loss: 2.6373111637689735

Epoch: 5| Step: 4
Training loss: 3.0050649642944336
Validation loss: 2.63668776840292

Epoch: 5| Step: 5
Training loss: 2.2675280570983887
Validation loss: 2.6339433372661634

Epoch: 5| Step: 6
Training loss: 2.7421393394470215
Validation loss: 2.6315607409323416

Epoch: 5| Step: 7
Training loss: 2.786137342453003
Validation loss: 2.632856866364838

Epoch: 5| Step: 8
Training loss: 3.0313518047332764
Validation loss: 2.6287481297728834

Epoch: 5| Step: 9
Training loss: 3.1318583488464355
Validation loss: 2.628748401518791

Epoch: 5| Step: 10
Training loss: 2.772164821624756
Validation loss: 2.62906684542215

Epoch: 22| Step: 0
Training loss: 2.826875925064087
Validation loss: 2.631042959869549

Epoch: 5| Step: 1
Training loss: 2.187753438949585
Validation loss: 2.641726129798479

Epoch: 5| Step: 2
Training loss: 3.6840286254882812
Validation loss: 2.6480807629964684

Epoch: 5| Step: 3
Training loss: 3.118607997894287
Validation loss: 2.621881966949791

Epoch: 5| Step: 4
Training loss: 2.780313014984131
Validation loss: 2.6152849812661447

Epoch: 5| Step: 5
Training loss: 3.1789567470550537
Validation loss: 2.614708323632517

Epoch: 5| Step: 6
Training loss: 2.2456822395324707
Validation loss: 2.613220061025312

Epoch: 5| Step: 7
Training loss: 2.904747724533081
Validation loss: 2.616662215161067

Epoch: 5| Step: 8
Training loss: 2.1889846324920654
Validation loss: 2.616584003612559

Epoch: 5| Step: 9
Training loss: 3.0989253520965576
Validation loss: 2.6157282731866323

Epoch: 5| Step: 10
Training loss: 2.7846970558166504
Validation loss: 2.614011154379896

Epoch: 23| Step: 0
Training loss: 2.6397345066070557
Validation loss: 2.611816378049953

Epoch: 5| Step: 1
Training loss: 2.9281890392303467
Validation loss: 2.6100226115154963

Epoch: 5| Step: 2
Training loss: 3.7475719451904297
Validation loss: 2.6097911070751887

Epoch: 5| Step: 3
Training loss: 2.6241917610168457
Validation loss: 2.60605949740256

Epoch: 5| Step: 4
Training loss: 2.5146291255950928
Validation loss: 2.6056405728863132

Epoch: 5| Step: 5
Training loss: 2.1805078983306885
Validation loss: 2.6038423199807443

Epoch: 5| Step: 6
Training loss: 2.591841220855713
Validation loss: 2.620799349200341

Epoch: 5| Step: 7
Training loss: 2.7175822257995605
Validation loss: 2.6663353725146224

Epoch: 5| Step: 8
Training loss: 3.018187999725342
Validation loss: 2.684976439322195

Epoch: 5| Step: 9
Training loss: 2.763646364212036
Validation loss: 2.651231097918685

Epoch: 5| Step: 10
Training loss: 3.4238154888153076
Validation loss: 2.6099583538629676

Epoch: 24| Step: 0
Training loss: 2.919489622116089
Validation loss: 2.609244349182293

Epoch: 5| Step: 1
Training loss: 2.4480042457580566
Validation loss: 2.6171609919558287

Epoch: 5| Step: 2
Training loss: 2.927767515182495
Validation loss: 2.6172746945452947

Epoch: 5| Step: 3
Training loss: 2.855696439743042
Validation loss: 2.619676177219678

Epoch: 5| Step: 4
Training loss: 2.1624271869659424
Validation loss: 2.6151516540076143

Epoch: 5| Step: 5
Training loss: 2.8295130729675293
Validation loss: 2.610044930570869

Epoch: 5| Step: 6
Training loss: 3.0673699378967285
Validation loss: 2.602183308652652

Epoch: 5| Step: 7
Training loss: 2.865382671356201
Validation loss: 2.5984185536702475

Epoch: 5| Step: 8
Training loss: 3.4545867443084717
Validation loss: 2.59939996657833

Epoch: 5| Step: 9
Training loss: 2.8282973766326904
Validation loss: 2.5972507845970894

Epoch: 5| Step: 10
Training loss: 2.443599224090576
Validation loss: 2.600357478664767

Epoch: 25| Step: 0
Training loss: 3.065016508102417
Validation loss: 2.599319827172064

Epoch: 5| Step: 1
Training loss: 2.2884788513183594
Validation loss: 2.5967877244436615

Epoch: 5| Step: 2
Training loss: 2.9490723609924316
Validation loss: 2.593892110291348

Epoch: 5| Step: 3
Training loss: 2.286345958709717
Validation loss: 2.591407924570063

Epoch: 5| Step: 4
Training loss: 3.4494755268096924
Validation loss: 2.5940857395049064

Epoch: 5| Step: 5
Training loss: 3.4074833393096924
Validation loss: 2.5917878817486506

Epoch: 5| Step: 6
Training loss: 2.1933600902557373
Validation loss: 2.588080072915682

Epoch: 5| Step: 7
Training loss: 2.628507614135742
Validation loss: 2.5859081822056926

Epoch: 5| Step: 8
Training loss: 3.059845447540283
Validation loss: 2.5847489500558503

Epoch: 5| Step: 9
Training loss: 2.233344554901123
Validation loss: 2.5831685091859553

Epoch: 5| Step: 10
Training loss: 3.1840872764587402
Validation loss: 2.5834408216578986

Epoch: 26| Step: 0
Training loss: 3.2611279487609863
Validation loss: 2.582466774089362

Epoch: 5| Step: 1
Training loss: 2.5241284370422363
Validation loss: 2.579050281996368

Epoch: 5| Step: 2
Training loss: 3.037257432937622
Validation loss: 2.577125446770781

Epoch: 5| Step: 3
Training loss: 2.873464345932007
Validation loss: 2.576297452372889

Epoch: 5| Step: 4
Training loss: 2.18115496635437
Validation loss: 2.5832620897600727

Epoch: 5| Step: 5
Training loss: 1.9908447265625
Validation loss: 2.5766012489154773

Epoch: 5| Step: 6
Training loss: 3.8803131580352783
Validation loss: 2.573691342466621

Epoch: 5| Step: 7
Training loss: 2.783550500869751
Validation loss: 2.5734045159432197

Epoch: 5| Step: 8
Training loss: 2.5442376136779785
Validation loss: 2.5701963670792116

Epoch: 5| Step: 9
Training loss: 2.908088445663452
Validation loss: 2.570005259206218

Epoch: 5| Step: 10
Training loss: 2.5555434226989746
Validation loss: 2.567467548513925

Epoch: 27| Step: 0
Training loss: 3.330153226852417
Validation loss: 2.5646995985379784

Epoch: 5| Step: 1
Training loss: 3.4234116077423096
Validation loss: 2.5589482399725143

Epoch: 5| Step: 2
Training loss: 2.6098949909210205
Validation loss: 2.5623738534988894

Epoch: 5| Step: 3
Training loss: 3.1046674251556396
Validation loss: 2.5592881941026255

Epoch: 5| Step: 4
Training loss: 2.6585984230041504
Validation loss: 2.561640406167635

Epoch: 5| Step: 5
Training loss: 2.1747336387634277
Validation loss: 2.5647112169573383

Epoch: 5| Step: 6
Training loss: 2.1035380363464355
Validation loss: 2.569608042317052

Epoch: 5| Step: 7
Training loss: 2.922423839569092
Validation loss: 2.5667559357099634

Epoch: 5| Step: 8
Training loss: 2.5400891304016113
Validation loss: 2.554455775086598

Epoch: 5| Step: 9
Training loss: 2.668853521347046
Validation loss: 2.5512200914403445

Epoch: 5| Step: 10
Training loss: 2.9928646087646484
Validation loss: 2.5538094223186536

Epoch: 28| Step: 0
Training loss: 2.9084486961364746
Validation loss: 2.552618867607527

Epoch: 5| Step: 1
Training loss: 3.03374981880188
Validation loss: 2.5659830442038913

Epoch: 5| Step: 2
Training loss: 2.2567009925842285
Validation loss: 2.5568124735227196

Epoch: 5| Step: 3
Training loss: 2.946176767349243
Validation loss: 2.5511509936342955

Epoch: 5| Step: 4
Training loss: 2.560317277908325
Validation loss: 2.5522407998320875

Epoch: 5| Step: 5
Training loss: 2.678913116455078
Validation loss: 2.551933278319656

Epoch: 5| Step: 6
Training loss: 2.7625441551208496
Validation loss: 2.551255387644614

Epoch: 5| Step: 7
Training loss: 2.6619133949279785
Validation loss: 2.544542243403773

Epoch: 5| Step: 8
Training loss: 3.2503762245178223
Validation loss: 2.5514267388210503

Epoch: 5| Step: 9
Training loss: 2.5790352821350098
Validation loss: 2.559040879690519

Epoch: 5| Step: 10
Training loss: 2.812913417816162
Validation loss: 2.5835965551355833

Epoch: 29| Step: 0
Training loss: 2.6465487480163574
Validation loss: 2.574519159973309

Epoch: 5| Step: 1
Training loss: 2.6245980262756348
Validation loss: 2.555934936769547

Epoch: 5| Step: 2
Training loss: 2.5658347606658936
Validation loss: 2.5421676302468903

Epoch: 5| Step: 3
Training loss: 2.4004502296447754
Validation loss: 2.537970273725448

Epoch: 5| Step: 4
Training loss: 3.0768914222717285
Validation loss: 2.539983900644446

Epoch: 5| Step: 5
Training loss: 3.2426955699920654
Validation loss: 2.542060782832484

Epoch: 5| Step: 6
Training loss: 2.016674518585205
Validation loss: 2.550998244234311

Epoch: 5| Step: 7
Training loss: 3.065908670425415
Validation loss: 2.5481550629420946

Epoch: 5| Step: 8
Training loss: 2.9645352363586426
Validation loss: 2.548742627584806

Epoch: 5| Step: 9
Training loss: 2.6017022132873535
Validation loss: 2.5377592373919744

Epoch: 5| Step: 10
Training loss: 3.2860422134399414
Validation loss: 2.5363648245411534

Epoch: 30| Step: 0
Training loss: 2.977099895477295
Validation loss: 2.537392126616611

Epoch: 5| Step: 1
Training loss: 3.059870958328247
Validation loss: 2.5376377003167265

Epoch: 5| Step: 2
Training loss: 2.155876636505127
Validation loss: 2.542127591307445

Epoch: 5| Step: 3
Training loss: 2.964675188064575
Validation loss: 2.546417869547362

Epoch: 5| Step: 4
Training loss: 2.525282621383667
Validation loss: 2.5495201362076627

Epoch: 5| Step: 5
Training loss: 3.0246315002441406
Validation loss: 2.546390784684048

Epoch: 5| Step: 6
Training loss: 2.4171836376190186
Validation loss: 2.5457353668828167

Epoch: 5| Step: 7
Training loss: 3.0550925731658936
Validation loss: 2.538599665446948

Epoch: 5| Step: 8
Training loss: 3.0883445739746094
Validation loss: 2.526551959335163

Epoch: 5| Step: 9
Training loss: 2.800550937652588
Validation loss: 2.5277298112069406

Epoch: 5| Step: 10
Training loss: 2.0095059871673584
Validation loss: 2.5355009776289745

Epoch: 31| Step: 0
Training loss: 3.2497615814208984
Validation loss: 2.5230037858409267

Epoch: 5| Step: 1
Training loss: 2.990903377532959
Validation loss: 2.523472688531363

Epoch: 5| Step: 2
Training loss: 3.0365214347839355
Validation loss: 2.526045476236651

Epoch: 5| Step: 3
Training loss: 2.692479372024536
Validation loss: 2.525591593916698

Epoch: 5| Step: 4
Training loss: 2.7869441509246826
Validation loss: 2.5262570278618925

Epoch: 5| Step: 5
Training loss: 3.2790939807891846
Validation loss: 2.5312675609383533

Epoch: 5| Step: 6
Training loss: 2.6069247722625732
Validation loss: 2.536135055685556

Epoch: 5| Step: 7
Training loss: 2.8796255588531494
Validation loss: 2.5373863071523686

Epoch: 5| Step: 8
Training loss: 2.009603500366211
Validation loss: 2.536898325848323

Epoch: 5| Step: 9
Training loss: 2.0301976203918457
Validation loss: 2.5427211176964546

Epoch: 5| Step: 10
Training loss: 2.678417205810547
Validation loss: 2.534415865457186

Epoch: 32| Step: 0
Training loss: 2.5180752277374268
Validation loss: 2.5268590834832962

Epoch: 5| Step: 1
Training loss: 2.8703296184539795
Validation loss: 2.5233688380128596

Epoch: 5| Step: 2
Training loss: 2.5708842277526855
Validation loss: 2.5187026710920435

Epoch: 5| Step: 3
Training loss: 1.9876701831817627
Validation loss: 2.5158252921155704

Epoch: 5| Step: 4
Training loss: 2.730492353439331
Validation loss: 2.5121152990607807

Epoch: 5| Step: 5
Training loss: 3.4569766521453857
Validation loss: 2.5117684102827504

Epoch: 5| Step: 6
Training loss: 2.8963325023651123
Validation loss: 2.507042154189079

Epoch: 5| Step: 7
Training loss: 3.1027748584747314
Validation loss: 2.5047854287649995

Epoch: 5| Step: 8
Training loss: 3.1644790172576904
Validation loss: 2.510394516811576

Epoch: 5| Step: 9
Training loss: 2.3799610137939453
Validation loss: 2.5118376875436432

Epoch: 5| Step: 10
Training loss: 2.2839388847351074
Validation loss: 2.5205521096465406

Epoch: 33| Step: 0
Training loss: 2.1186299324035645
Validation loss: 2.5274242918978453

Epoch: 5| Step: 1
Training loss: 3.4890408515930176
Validation loss: 2.5162203901557514

Epoch: 5| Step: 2
Training loss: 2.6322181224823
Validation loss: 2.5111925140503915

Epoch: 5| Step: 3
Training loss: 2.419271945953369
Validation loss: 2.5078034375303533

Epoch: 5| Step: 4
Training loss: 3.4109253883361816
Validation loss: 2.510001372265559

Epoch: 5| Step: 5
Training loss: 3.006101131439209
Validation loss: 2.5104847954165552

Epoch: 5| Step: 6
Training loss: 3.0711569786071777
Validation loss: 2.5129925999590146

Epoch: 5| Step: 7
Training loss: 2.2928757667541504
Validation loss: 2.5110650677834787

Epoch: 5| Step: 8
Training loss: 2.596482038497925
Validation loss: 2.5127186672661894

Epoch: 5| Step: 9
Training loss: 2.6974902153015137
Validation loss: 2.5071194171905518

Epoch: 5| Step: 10
Training loss: 2.156432867050171
Validation loss: 2.506749414628552

Epoch: 34| Step: 0
Training loss: 2.0114243030548096
Validation loss: 2.5209531168783865

Epoch: 5| Step: 1
Training loss: 2.8519654273986816
Validation loss: 2.5290412518285934

Epoch: 5| Step: 2
Training loss: 2.725695848464966
Validation loss: 2.5291649423619753

Epoch: 5| Step: 3
Training loss: 2.7552318572998047
Validation loss: 2.5159508156520065

Epoch: 5| Step: 4
Training loss: 3.157627582550049
Validation loss: 2.5100040461427424

Epoch: 5| Step: 5
Training loss: 3.5998153686523438
Validation loss: 2.5067697289169475

Epoch: 5| Step: 6
Training loss: 2.766247272491455
Validation loss: 2.5095505714416504

Epoch: 5| Step: 7
Training loss: 2.8834197521209717
Validation loss: 2.5122414558164534

Epoch: 5| Step: 8
Training loss: 2.472907543182373
Validation loss: 2.5024159364802863

Epoch: 5| Step: 9
Training loss: 2.369335889816284
Validation loss: 2.502104510543167

Epoch: 5| Step: 10
Training loss: 2.2955358028411865
Validation loss: 2.5016993937953824

Epoch: 35| Step: 0
Training loss: 2.451941967010498
Validation loss: 2.501354717439221

Epoch: 5| Step: 1
Training loss: 3.0141897201538086
Validation loss: 2.5059891772526566

Epoch: 5| Step: 2
Training loss: 2.8726727962493896
Validation loss: 2.516059319178263

Epoch: 5| Step: 3
Training loss: 2.352139949798584
Validation loss: 2.532094883662398

Epoch: 5| Step: 4
Training loss: 2.449923038482666
Validation loss: 2.5256069078240344

Epoch: 5| Step: 5
Training loss: 3.4828929901123047
Validation loss: 2.530184725279449

Epoch: 5| Step: 6
Training loss: 3.140982151031494
Validation loss: 2.504970245463874

Epoch: 5| Step: 7
Training loss: 2.087691068649292
Validation loss: 2.4952571161331667

Epoch: 5| Step: 8
Training loss: 2.8210997581481934
Validation loss: 2.4914406063736125

Epoch: 5| Step: 9
Training loss: 2.642840623855591
Validation loss: 2.4984865034780195

Epoch: 5| Step: 10
Training loss: 2.4321718215942383
Validation loss: 2.5214775121340187

Epoch: 36| Step: 0
Training loss: 2.523024082183838
Validation loss: 2.5315958799854403

Epoch: 5| Step: 1
Training loss: 2.7591195106506348
Validation loss: 2.5280091480542253

Epoch: 5| Step: 2
Training loss: 2.8857717514038086
Validation loss: 2.5306152041240404

Epoch: 5| Step: 3
Training loss: 3.124711275100708
Validation loss: 2.5176786350947555

Epoch: 5| Step: 4
Training loss: 2.2772223949432373
Validation loss: 2.4921256470423874

Epoch: 5| Step: 5
Training loss: 2.686879873275757
Validation loss: 2.4858525209529425

Epoch: 5| Step: 6
Training loss: 2.7852847576141357
Validation loss: 2.4855377289556686

Epoch: 5| Step: 7
Training loss: 2.726463794708252
Validation loss: 2.4909837733032885

Epoch: 5| Step: 8
Training loss: 2.5544257164001465
Validation loss: 2.507921007371718

Epoch: 5| Step: 9
Training loss: 2.841909885406494
Validation loss: 2.5344146118369153

Epoch: 5| Step: 10
Training loss: 2.683605194091797
Validation loss: 2.525910838957756

Epoch: 37| Step: 0
Training loss: 2.5713534355163574
Validation loss: 2.4903539355083177

Epoch: 5| Step: 1
Training loss: 2.2928414344787598
Validation loss: 2.486736397589407

Epoch: 5| Step: 2
Training loss: 1.9401543140411377
Validation loss: 2.4893027108202697

Epoch: 5| Step: 3
Training loss: 2.914334535598755
Validation loss: 2.503404945455572

Epoch: 5| Step: 4
Training loss: 2.846891403198242
Validation loss: 2.5080030451538744

Epoch: 5| Step: 5
Training loss: 2.485046863555908
Validation loss: 2.5062950272713937

Epoch: 5| Step: 6
Training loss: 3.437206268310547
Validation loss: 2.5067009361841346

Epoch: 5| Step: 7
Training loss: 2.53753924369812
Validation loss: 2.5006392489197435

Epoch: 5| Step: 8
Training loss: 2.405280351638794
Validation loss: 2.490428906615062

Epoch: 5| Step: 9
Training loss: 3.32171630859375
Validation loss: 2.484511370299965

Epoch: 5| Step: 10
Training loss: 2.979255437850952
Validation loss: 2.477897492788171

Epoch: 38| Step: 0
Training loss: 2.1837704181671143
Validation loss: 2.4807240834800144

Epoch: 5| Step: 1
Training loss: 2.665196180343628
Validation loss: 2.4819144920636247

Epoch: 5| Step: 2
Training loss: 2.641078472137451
Validation loss: 2.4782843641055528

Epoch: 5| Step: 3
Training loss: 2.770411252975464
Validation loss: 2.47582507646212

Epoch: 5| Step: 4
Training loss: 3.2964653968811035
Validation loss: 2.474478906200778

Epoch: 5| Step: 5
Training loss: 2.7056796550750732
Validation loss: 2.478365710986558

Epoch: 5| Step: 6
Training loss: 2.2788963317871094
Validation loss: 2.488267498631631

Epoch: 5| Step: 7
Training loss: 3.400599956512451
Validation loss: 2.5272109713605655

Epoch: 5| Step: 8
Training loss: 2.8147642612457275
Validation loss: 2.542177700227307

Epoch: 5| Step: 9
Training loss: 2.2264320850372314
Validation loss: 2.51859236532642

Epoch: 5| Step: 10
Training loss: 2.6840217113494873
Validation loss: 2.5142470803312076

Epoch: 39| Step: 0
Training loss: 2.9300293922424316
Validation loss: 2.5021678145213793

Epoch: 5| Step: 1
Training loss: 2.3777835369110107
Validation loss: 2.5022035080899476

Epoch: 5| Step: 2
Training loss: 2.252661943435669
Validation loss: 2.4934562842051187

Epoch: 5| Step: 3
Training loss: 2.807936668395996
Validation loss: 2.4947853011469685

Epoch: 5| Step: 4
Training loss: 2.643815517425537
Validation loss: 2.4905665843717513

Epoch: 5| Step: 5
Training loss: 2.513183116912842
Validation loss: 2.4754066851831253

Epoch: 5| Step: 6
Training loss: 2.7757887840270996
Validation loss: 2.463854620533605

Epoch: 5| Step: 7
Training loss: 3.279550552368164
Validation loss: 2.4598750337477653

Epoch: 5| Step: 8
Training loss: 2.6274077892303467
Validation loss: 2.4563259822066112

Epoch: 5| Step: 9
Training loss: 2.616392135620117
Validation loss: 2.455635247691985

Epoch: 5| Step: 10
Training loss: 2.735301971435547
Validation loss: 2.452037929206766

Epoch: 40| Step: 0
Training loss: 2.456329345703125
Validation loss: 2.459449391211233

Epoch: 5| Step: 1
Training loss: 2.479391098022461
Validation loss: 2.4525500664147

Epoch: 5| Step: 2
Training loss: 2.2608940601348877
Validation loss: 2.4755398996414675

Epoch: 5| Step: 3
Training loss: 2.192469358444214
Validation loss: 2.45827555143705

Epoch: 5| Step: 4
Training loss: 2.096280574798584
Validation loss: 2.4454563484396985

Epoch: 5| Step: 5
Training loss: 3.2652580738067627
Validation loss: 2.4468265656502015

Epoch: 5| Step: 6
Training loss: 3.0014443397521973
Validation loss: 2.4614303060757217

Epoch: 5| Step: 7
Training loss: 3.2065768241882324
Validation loss: 2.4609815818007275

Epoch: 5| Step: 8
Training loss: 2.892885684967041
Validation loss: 2.458466091463643

Epoch: 5| Step: 9
Training loss: 2.466384172439575
Validation loss: 2.4554122955568376

Epoch: 5| Step: 10
Training loss: 3.228537082672119
Validation loss: 2.464579192540979

Epoch: 41| Step: 0
Training loss: 2.4997477531433105
Validation loss: 2.4755046829100578

Epoch: 5| Step: 1
Training loss: 2.7432968616485596
Validation loss: 2.495638685841714

Epoch: 5| Step: 2
Training loss: 2.511009693145752
Validation loss: 2.49090229311297

Epoch: 5| Step: 3
Training loss: 2.9585957527160645
Validation loss: 2.4632585587040072

Epoch: 5| Step: 4
Training loss: 3.3150200843811035
Validation loss: 2.442802171553335

Epoch: 5| Step: 5
Training loss: 2.2746357917785645
Validation loss: 2.441706283118135

Epoch: 5| Step: 6
Training loss: 2.497149705886841
Validation loss: 2.439065230790005

Epoch: 5| Step: 7
Training loss: 2.567978620529175
Validation loss: 2.440685959272487

Epoch: 5| Step: 8
Training loss: 3.0577807426452637
Validation loss: 2.4454664543110836

Epoch: 5| Step: 9
Training loss: 2.4525747299194336
Validation loss: 2.440881913708102

Epoch: 5| Step: 10
Training loss: 2.511035203933716
Validation loss: 2.44057035446167

Epoch: 42| Step: 0
Training loss: 3.0443520545959473
Validation loss: 2.435333626244658

Epoch: 5| Step: 1
Training loss: 2.244497776031494
Validation loss: 2.4358135115715767

Epoch: 5| Step: 2
Training loss: 2.077092409133911
Validation loss: 2.432335921513137

Epoch: 5| Step: 3
Training loss: 3.076427459716797
Validation loss: 2.4333664371121313

Epoch: 5| Step: 4
Training loss: 2.3723511695861816
Validation loss: 2.4347622343288955

Epoch: 5| Step: 5
Training loss: 3.006824493408203
Validation loss: 2.437129318073232

Epoch: 5| Step: 6
Training loss: 2.7209415435791016
Validation loss: 2.443574279867193

Epoch: 5| Step: 7
Training loss: 2.9895966053009033
Validation loss: 2.444315437347658

Epoch: 5| Step: 8
Training loss: 2.4714269638061523
Validation loss: 2.4397565305873914

Epoch: 5| Step: 9
Training loss: 2.8778176307678223
Validation loss: 2.4412378521375757

Epoch: 5| Step: 10
Training loss: 2.3164279460906982
Validation loss: 2.454287766128458

Epoch: 43| Step: 0
Training loss: 3.449370861053467
Validation loss: 2.4696963653769544

Epoch: 5| Step: 1
Training loss: 2.640521764755249
Validation loss: 2.4702641784503894

Epoch: 5| Step: 2
Training loss: 2.7230067253112793
Validation loss: 2.465816667003016

Epoch: 5| Step: 3
Training loss: 2.0813779830932617
Validation loss: 2.4426654795164704

Epoch: 5| Step: 4
Training loss: 2.2189228534698486
Validation loss: 2.4270678438166136

Epoch: 5| Step: 5
Training loss: 3.3758625984191895
Validation loss: 2.4223589512609665

Epoch: 5| Step: 6
Training loss: 2.4439523220062256
Validation loss: 2.423780664320915

Epoch: 5| Step: 7
Training loss: 2.7625646591186523
Validation loss: 2.4224247137705484

Epoch: 5| Step: 8
Training loss: 2.049783229827881
Validation loss: 2.4270707407305316

Epoch: 5| Step: 9
Training loss: 2.7317967414855957
Validation loss: 2.4266665879116265

Epoch: 5| Step: 10
Training loss: 3.079418659210205
Validation loss: 2.435010281942224

Epoch: 44| Step: 0
Training loss: 2.1822509765625
Validation loss: 2.427517916566582

Epoch: 5| Step: 1
Training loss: 2.318735122680664
Validation loss: 2.4355367973286617

Epoch: 5| Step: 2
Training loss: 2.904170513153076
Validation loss: 2.469024222384217

Epoch: 5| Step: 3
Training loss: 2.4789795875549316
Validation loss: 2.472655673180857

Epoch: 5| Step: 4
Training loss: 2.910630702972412
Validation loss: 2.4702495144259546

Epoch: 5| Step: 5
Training loss: 2.468535900115967
Validation loss: 2.4740242855523222

Epoch: 5| Step: 6
Training loss: 2.8499011993408203
Validation loss: 2.4552616086057437

Epoch: 5| Step: 7
Training loss: 2.8311190605163574
Validation loss: 2.4307228288342877

Epoch: 5| Step: 8
Training loss: 2.7612428665161133
Validation loss: 2.423010964547434

Epoch: 5| Step: 9
Training loss: 2.8576877117156982
Validation loss: 2.418292976194812

Epoch: 5| Step: 10
Training loss: 2.8165783882141113
Validation loss: 2.420841816932924

Epoch: 45| Step: 0
Training loss: 3.0189006328582764
Validation loss: 2.422102494906354

Epoch: 5| Step: 1
Training loss: 2.8693675994873047
Validation loss: 2.4303812391014508

Epoch: 5| Step: 2
Training loss: 2.2129504680633545
Validation loss: 2.4238845225303405

Epoch: 5| Step: 3
Training loss: 2.568744421005249
Validation loss: 2.429831866295107

Epoch: 5| Step: 4
Training loss: 2.738693952560425
Validation loss: 2.43953719446736

Epoch: 5| Step: 5
Training loss: 2.493049383163452
Validation loss: 2.447553462879632

Epoch: 5| Step: 6
Training loss: 3.0991477966308594
Validation loss: 2.4455091286731023

Epoch: 5| Step: 7
Training loss: 2.4335827827453613
Validation loss: 2.422530151182605

Epoch: 5| Step: 8
Training loss: 3.4757542610168457
Validation loss: 2.408198297664683

Epoch: 5| Step: 9
Training loss: 1.7888339757919312
Validation loss: 2.40377107743294

Epoch: 5| Step: 10
Training loss: 2.634927749633789
Validation loss: 2.40499440316231

Epoch: 46| Step: 0
Training loss: 3.1714160442352295
Validation loss: 2.405078236774732

Epoch: 5| Step: 1
Training loss: 2.8381974697113037
Validation loss: 2.4117846232588573

Epoch: 5| Step: 2
Training loss: 2.662923812866211
Validation loss: 2.423539266791395

Epoch: 5| Step: 3
Training loss: 2.693739652633667
Validation loss: 2.4494021477237826

Epoch: 5| Step: 4
Training loss: 2.252156972885132
Validation loss: 2.4658013466865785

Epoch: 5| Step: 5
Training loss: 2.483891248703003
Validation loss: 2.4740867691655315

Epoch: 5| Step: 6
Training loss: 3.335932970046997
Validation loss: 2.472070247896256

Epoch: 5| Step: 7
Training loss: 2.680039882659912
Validation loss: 2.4413618118532243

Epoch: 5| Step: 8
Training loss: 1.8730672597885132
Validation loss: 2.415660268516951

Epoch: 5| Step: 9
Training loss: 2.9257149696350098
Validation loss: 2.4068742464947444

Epoch: 5| Step: 10
Training loss: 2.3089988231658936
Validation loss: 2.408659627360682

Epoch: 47| Step: 0
Training loss: 2.4550411701202393
Validation loss: 2.414592630119734

Epoch: 5| Step: 1
Training loss: 2.4926979541778564
Validation loss: 2.4130856580631708

Epoch: 5| Step: 2
Training loss: 2.6476855278015137
Validation loss: 2.4122246260284097

Epoch: 5| Step: 3
Training loss: 2.927345037460327
Validation loss: 2.406786290548181

Epoch: 5| Step: 4
Training loss: 2.54586124420166
Validation loss: 2.4038333662094606

Epoch: 5| Step: 5
Training loss: 2.957439422607422
Validation loss: 2.407547402125533

Epoch: 5| Step: 6
Training loss: 2.2966244220733643
Validation loss: 2.416976941529141

Epoch: 5| Step: 7
Training loss: 2.9130897521972656
Validation loss: 2.435059142369096

Epoch: 5| Step: 8
Training loss: 2.704061985015869
Validation loss: 2.4405781428019204

Epoch: 5| Step: 9
Training loss: 2.499568223953247
Validation loss: 2.4337672495072886

Epoch: 5| Step: 10
Training loss: 2.771043062210083
Validation loss: 2.4560837950757755

Epoch: 48| Step: 0
Training loss: 3.164332389831543
Validation loss: 2.440910188100671

Epoch: 5| Step: 1
Training loss: 2.9161486625671387
Validation loss: 2.4231290278896207

Epoch: 5| Step: 2
Training loss: 2.8745555877685547
Validation loss: 2.406071229647565

Epoch: 5| Step: 3
Training loss: 2.7705788612365723
Validation loss: 2.3985258686927056

Epoch: 5| Step: 4
Training loss: 2.3285775184631348
Validation loss: 2.388940477883944

Epoch: 5| Step: 5
Training loss: 2.6922290325164795
Validation loss: 2.3941782366844917

Epoch: 5| Step: 6
Training loss: 2.463949203491211
Validation loss: 2.401650728717927

Epoch: 5| Step: 7
Training loss: 2.4695372581481934
Validation loss: 2.399279304729995

Epoch: 5| Step: 8
Training loss: 2.1966381072998047
Validation loss: 2.394907610390776

Epoch: 5| Step: 9
Training loss: 2.487572431564331
Validation loss: 2.3860592329373924

Epoch: 5| Step: 10
Training loss: 2.8494577407836914
Validation loss: 2.3906080235717115

Epoch: 49| Step: 0
Training loss: 2.4725067615509033
Validation loss: 2.3978041115627495

Epoch: 5| Step: 1
Training loss: 2.8490538597106934
Validation loss: 2.4233377800192883

Epoch: 5| Step: 2
Training loss: 2.452336549758911
Validation loss: 2.4678494340629986

Epoch: 5| Step: 3
Training loss: 2.891740083694458
Validation loss: 2.500762962525891

Epoch: 5| Step: 4
Training loss: 2.4789323806762695
Validation loss: 2.477592501589047

Epoch: 5| Step: 5
Training loss: 2.186861515045166
Validation loss: 2.445745501466977

Epoch: 5| Step: 6
Training loss: 2.862083911895752
Validation loss: 2.402297806996171

Epoch: 5| Step: 7
Training loss: 2.642796277999878
Validation loss: 2.386740794745825

Epoch: 5| Step: 8
Training loss: 2.711526870727539
Validation loss: 2.3830280816683205

Epoch: 5| Step: 9
Training loss: 3.008898973464966
Validation loss: 2.385296047374766

Epoch: 5| Step: 10
Training loss: 2.6503055095672607
Validation loss: 2.391041014784126

Epoch: 50| Step: 0
Training loss: 2.782078981399536
Validation loss: 2.4019060365615355

Epoch: 5| Step: 1
Training loss: 2.3400661945343018
Validation loss: 2.405612652019788

Epoch: 5| Step: 2
Training loss: 2.6601788997650146
Validation loss: 2.395957936522781

Epoch: 5| Step: 3
Training loss: 2.6224844455718994
Validation loss: 2.391772529130341

Epoch: 5| Step: 4
Training loss: 2.0022695064544678
Validation loss: 2.3830385490130355

Epoch: 5| Step: 5
Training loss: 3.081669569015503
Validation loss: 2.378759132918491

Epoch: 5| Step: 6
Training loss: 2.422135829925537
Validation loss: 2.3780849120950185

Epoch: 5| Step: 7
Training loss: 2.8373539447784424
Validation loss: 2.3803460674901165

Epoch: 5| Step: 8
Training loss: 3.0403990745544434
Validation loss: 2.377933563724641

Epoch: 5| Step: 9
Training loss: 2.861489772796631
Validation loss: 2.3790280126756236

Epoch: 5| Step: 10
Training loss: 2.4508092403411865
Validation loss: 2.3842528712364937

Epoch: 51| Step: 0
Training loss: 2.259629487991333
Validation loss: 2.3966107701742523

Epoch: 5| Step: 1
Training loss: 3.2658042907714844
Validation loss: 2.4023900467862367

Epoch: 5| Step: 2
Training loss: 3.378627061843872
Validation loss: 2.408239277460242

Epoch: 5| Step: 3
Training loss: 2.350681781768799
Validation loss: 2.409873083073606

Epoch: 5| Step: 4
Training loss: 2.028550863265991
Validation loss: 2.3998978881425757

Epoch: 5| Step: 5
Training loss: 2.236032009124756
Validation loss: 2.408512169314969

Epoch: 5| Step: 6
Training loss: 2.868345022201538
Validation loss: 2.3938169915189027

Epoch: 5| Step: 7
Training loss: 2.202840805053711
Validation loss: 2.3813083646118

Epoch: 5| Step: 8
Training loss: 3.054797887802124
Validation loss: 2.3783700440519597

Epoch: 5| Step: 9
Training loss: 2.540397882461548
Validation loss: 2.3728266044329573

Epoch: 5| Step: 10
Training loss: 2.782397747039795
Validation loss: 2.370853849636611

Epoch: 52| Step: 0
Training loss: 2.138822078704834
Validation loss: 2.3713235726920505

Epoch: 5| Step: 1
Training loss: 3.4298012256622314
Validation loss: 2.373078292415988

Epoch: 5| Step: 2
Training loss: 2.86784029006958
Validation loss: 2.3845266526745212

Epoch: 5| Step: 3
Training loss: 2.4532763957977295
Validation loss: 2.3928828623987015

Epoch: 5| Step: 4
Training loss: 3.511906862258911
Validation loss: 2.381537519475465

Epoch: 5| Step: 5
Training loss: 2.102705478668213
Validation loss: 2.372118462798416

Epoch: 5| Step: 6
Training loss: 2.597719669342041
Validation loss: 2.363160715308241

Epoch: 5| Step: 7
Training loss: 2.5980143547058105
Validation loss: 2.3619666586640062

Epoch: 5| Step: 8
Training loss: 1.978764533996582
Validation loss: 2.3608681899245068

Epoch: 5| Step: 9
Training loss: 2.156007766723633
Validation loss: 2.357650920908938

Epoch: 5| Step: 10
Training loss: 3.168576240539551
Validation loss: 2.3643305634939544

Epoch: 53| Step: 0
Training loss: 2.718093156814575
Validation loss: 2.3713995410550024

Epoch: 5| Step: 1
Training loss: 2.445542097091675
Validation loss: 2.3826274282188824

Epoch: 5| Step: 2
Training loss: 2.5323679447174072
Validation loss: 2.395166563731368

Epoch: 5| Step: 3
Training loss: 2.7730884552001953
Validation loss: 2.413592538525981

Epoch: 5| Step: 4
Training loss: 2.009166955947876
Validation loss: 2.3965192379490023

Epoch: 5| Step: 5
Training loss: 3.0036847591400146
Validation loss: 2.395826789640611

Epoch: 5| Step: 6
Training loss: 2.9088873863220215
Validation loss: 2.3957007982397593

Epoch: 5| Step: 7
Training loss: 2.8454430103302
Validation loss: 2.398664794942384

Epoch: 5| Step: 8
Training loss: 2.313333034515381
Validation loss: 2.401973539783109

Epoch: 5| Step: 9
Training loss: 2.2470779418945312
Validation loss: 2.413094646187239

Epoch: 5| Step: 10
Training loss: 3.180083990097046
Validation loss: 2.410371490704116

Epoch: 54| Step: 0
Training loss: 2.493607997894287
Validation loss: 2.3969964750351442

Epoch: 5| Step: 1
Training loss: 2.09291410446167
Validation loss: 2.3856449409197737

Epoch: 5| Step: 2
Training loss: 1.903655767440796
Validation loss: 2.3749935960256927

Epoch: 5| Step: 3
Training loss: 2.9327051639556885
Validation loss: 2.380003075445852

Epoch: 5| Step: 4
Training loss: 2.9480443000793457
Validation loss: 2.375974593623992

Epoch: 5| Step: 5
Training loss: 2.7967023849487305
Validation loss: 2.370811467529625

Epoch: 5| Step: 6
Training loss: 2.214132785797119
Validation loss: 2.3679694334665933

Epoch: 5| Step: 7
Training loss: 3.063722848892212
Validation loss: 2.367711146672567

Epoch: 5| Step: 8
Training loss: 3.2724928855895996
Validation loss: 2.3645397168333813

Epoch: 5| Step: 9
Training loss: 2.3917758464813232
Validation loss: 2.3619247354486936

Epoch: 5| Step: 10
Training loss: 2.6719374656677246
Validation loss: 2.3573239464913645

Epoch: 55| Step: 0
Training loss: 3.1545910835266113
Validation loss: 2.350832188001243

Epoch: 5| Step: 1
Training loss: 2.7834548950195312
Validation loss: 2.3495626270130114

Epoch: 5| Step: 2
Training loss: 2.656639814376831
Validation loss: 2.3419335990823726

Epoch: 5| Step: 3
Training loss: 2.8033313751220703
Validation loss: 2.3425036707232074

Epoch: 5| Step: 4
Training loss: 2.3513855934143066
Validation loss: 2.3464655183976695

Epoch: 5| Step: 5
Training loss: 2.643557071685791
Validation loss: 2.356301220514441

Epoch: 5| Step: 6
Training loss: 2.370335817337036
Validation loss: 2.3653243357135403

Epoch: 5| Step: 7
Training loss: 2.3905675411224365
Validation loss: 2.3970577563008955

Epoch: 5| Step: 8
Training loss: 2.8519673347473145
Validation loss: 2.3921421215098393

Epoch: 5| Step: 9
Training loss: 2.184810161590576
Validation loss: 2.384528039604105

Epoch: 5| Step: 10
Training loss: 2.7594659328460693
Validation loss: 2.3597126571081017

Epoch: 56| Step: 0
Training loss: 3.0232198238372803
Validation loss: 2.3382347988825973

Epoch: 5| Step: 1
Training loss: 2.926201105117798
Validation loss: 2.333296278471588

Epoch: 5| Step: 2
Training loss: 2.9681272506713867
Validation loss: 2.333612149761569

Epoch: 5| Step: 3
Training loss: 1.95059072971344
Validation loss: 2.3277192013238066

Epoch: 5| Step: 4
Training loss: 2.385356903076172
Validation loss: 2.3271239406319073

Epoch: 5| Step: 5
Training loss: 2.213484525680542
Validation loss: 2.330150397874976

Epoch: 5| Step: 6
Training loss: 2.7129883766174316
Validation loss: 2.336895012086438

Epoch: 5| Step: 7
Training loss: 2.4050536155700684
Validation loss: 2.3383983642824235

Epoch: 5| Step: 8
Training loss: 2.70280122756958
Validation loss: 2.341753795582761

Epoch: 5| Step: 9
Training loss: 2.6664936542510986
Validation loss: 2.3427736041366414

Epoch: 5| Step: 10
Training loss: 2.7605984210968018
Validation loss: 2.3498942223928307

Epoch: 57| Step: 0
Training loss: 2.088170289993286
Validation loss: 2.3438460006508777

Epoch: 5| Step: 1
Training loss: 3.2439751625061035
Validation loss: 2.3343298922302904

Epoch: 5| Step: 2
Training loss: 2.846522808074951
Validation loss: 2.3223100093103226

Epoch: 5| Step: 3
Training loss: 2.40269136428833
Validation loss: 2.3163614606344574

Epoch: 5| Step: 4
Training loss: 2.5433757305145264
Validation loss: 2.316421993317143

Epoch: 5| Step: 5
Training loss: 2.8046600818634033
Validation loss: 2.3122562823757047

Epoch: 5| Step: 6
Training loss: 2.3067874908447266
Validation loss: 2.3134666232652563

Epoch: 5| Step: 7
Training loss: 2.6992270946502686
Validation loss: 2.3126676902976087

Epoch: 5| Step: 8
Training loss: 2.4059982299804688
Validation loss: 2.3139071233810915

Epoch: 5| Step: 9
Training loss: 2.59759783744812
Validation loss: 2.3130619666909658

Epoch: 5| Step: 10
Training loss: 2.5166594982147217
Validation loss: 2.3138171549766295

Epoch: 58| Step: 0
Training loss: 2.54502272605896
Validation loss: 2.3242902909555743

Epoch: 5| Step: 1
Training loss: 2.4300780296325684
Validation loss: 2.329042838465783

Epoch: 5| Step: 2
Training loss: 2.183718204498291
Validation loss: 2.3393233309509935

Epoch: 5| Step: 3
Training loss: 3.0928986072540283
Validation loss: 2.3684193241980767

Epoch: 5| Step: 4
Training loss: 2.6220474243164062
Validation loss: 2.3723645646085023

Epoch: 5| Step: 5
Training loss: 2.59196138381958
Validation loss: 2.366257057395033

Epoch: 5| Step: 6
Training loss: 2.3786017894744873
Validation loss: 2.3604882865823726

Epoch: 5| Step: 7
Training loss: 2.9783153533935547
Validation loss: 2.3334122601375786

Epoch: 5| Step: 8
Training loss: 2.8216490745544434
Validation loss: 2.321296158657279

Epoch: 5| Step: 9
Training loss: 2.2558412551879883
Validation loss: 2.308138620468878

Epoch: 5| Step: 10
Training loss: 2.6674046516418457
Validation loss: 2.3059567764241207

Epoch: 59| Step: 0
Training loss: 2.2682547569274902
Validation loss: 2.302376156212181

Epoch: 5| Step: 1
Training loss: 2.530060291290283
Validation loss: 2.29970274689377

Epoch: 5| Step: 2
Training loss: 2.0177698135375977
Validation loss: 2.308543723116639

Epoch: 5| Step: 3
Training loss: 2.430795192718506
Validation loss: 2.3191499299900507

Epoch: 5| Step: 4
Training loss: 2.4173502922058105
Validation loss: 2.3288766337979223

Epoch: 5| Step: 5
Training loss: 3.058581829071045
Validation loss: 2.3627560113065984

Epoch: 5| Step: 6
Training loss: 2.9867966175079346
Validation loss: 2.357272853133499

Epoch: 5| Step: 7
Training loss: 2.5588347911834717
Validation loss: 2.3355083965486094

Epoch: 5| Step: 8
Training loss: 3.003904342651367
Validation loss: 2.3364089688947125

Epoch: 5| Step: 9
Training loss: 2.561161518096924
Validation loss: 2.339993123085268

Epoch: 5| Step: 10
Training loss: 2.5541698932647705
Validation loss: 2.322158029002528

Epoch: 60| Step: 0
Training loss: 2.975835084915161
Validation loss: 2.3145131987910115

Epoch: 5| Step: 1
Training loss: 2.5756967067718506
Validation loss: 2.3037438341366347

Epoch: 5| Step: 2
Training loss: 2.044821262359619
Validation loss: 2.3006613767275246

Epoch: 5| Step: 3
Training loss: 2.5901691913604736
Validation loss: 2.294931944980416

Epoch: 5| Step: 4
Training loss: 1.9461917877197266
Validation loss: 2.290854146403651

Epoch: 5| Step: 5
Training loss: 2.2370152473449707
Validation loss: 2.289997967340613

Epoch: 5| Step: 6
Training loss: 2.5051023960113525
Validation loss: 2.2890143881561937

Epoch: 5| Step: 7
Training loss: 3.205751895904541
Validation loss: 2.290191847790954

Epoch: 5| Step: 8
Training loss: 3.136245012283325
Validation loss: 2.2881561069078344

Epoch: 5| Step: 9
Training loss: 2.9009580612182617
Validation loss: 2.308950193466679

Epoch: 5| Step: 10
Training loss: 2.249541759490967
Validation loss: 2.324304542233867

Epoch: 61| Step: 0
Training loss: 3.253549575805664
Validation loss: 2.37364258304719

Epoch: 5| Step: 1
Training loss: 2.898932456970215
Validation loss: 2.405628122309203

Epoch: 5| Step: 2
Training loss: 1.9364538192749023
Validation loss: 2.413573790622014

Epoch: 5| Step: 3
Training loss: 2.304546356201172
Validation loss: 2.3909237230977705

Epoch: 5| Step: 4
Training loss: 2.558365821838379
Validation loss: 2.3577394049654723

Epoch: 5| Step: 5
Training loss: 2.2518391609191895
Validation loss: 2.3345922705947713

Epoch: 5| Step: 6
Training loss: 2.3821473121643066
Validation loss: 2.31200409448275

Epoch: 5| Step: 7
Training loss: 1.9964265823364258
Validation loss: 2.299028604261337

Epoch: 5| Step: 8
Training loss: 2.545142650604248
Validation loss: 2.305804498734013

Epoch: 5| Step: 9
Training loss: 3.0374224185943604
Validation loss: 2.326797431515109

Epoch: 5| Step: 10
Training loss: 3.4541425704956055
Validation loss: 2.347133723638391

Epoch: 62| Step: 0
Training loss: 2.485002040863037
Validation loss: 2.3354259255111858

Epoch: 5| Step: 1
Training loss: 2.949516773223877
Validation loss: 2.3106165778252388

Epoch: 5| Step: 2
Training loss: 3.150428295135498
Validation loss: 2.2889923152103218

Epoch: 5| Step: 3
Training loss: 1.979212999343872
Validation loss: 2.2856464565441175

Epoch: 5| Step: 4
Training loss: 2.2907791137695312
Validation loss: 2.289528357085361

Epoch: 5| Step: 5
Training loss: 2.4446568489074707
Validation loss: 2.2893282444246355

Epoch: 5| Step: 6
Training loss: 2.797116756439209
Validation loss: 2.296860611566933

Epoch: 5| Step: 7
Training loss: 2.7605667114257812
Validation loss: 2.317151528532787

Epoch: 5| Step: 8
Training loss: 3.1150989532470703
Validation loss: 2.3392314987797893

Epoch: 5| Step: 9
Training loss: 2.035926580429077
Validation loss: 2.34889567026528

Epoch: 5| Step: 10
Training loss: 2.318333148956299
Validation loss: 2.3591465668011735

Epoch: 63| Step: 0
Training loss: 2.2550649642944336
Validation loss: 2.3301903227324128

Epoch: 5| Step: 1
Training loss: 2.6861777305603027
Validation loss: 2.305048168346446

Epoch: 5| Step: 2
Training loss: 2.2343146800994873
Validation loss: 2.2962730212878157

Epoch: 5| Step: 3
Training loss: 2.6319539546966553
Validation loss: 2.29413539619856

Epoch: 5| Step: 4
Training loss: 1.9416391849517822
Validation loss: 2.296568106579524

Epoch: 5| Step: 5
Training loss: 3.093810558319092
Validation loss: 2.30066571440748

Epoch: 5| Step: 6
Training loss: 2.3580737113952637
Validation loss: 2.2982084622947117

Epoch: 5| Step: 7
Training loss: 2.8612987995147705
Validation loss: 2.279439410855693

Epoch: 5| Step: 8
Training loss: 2.285262107849121
Validation loss: 2.271912487604285

Epoch: 5| Step: 9
Training loss: 2.9664175510406494
Validation loss: 2.2679537611622966

Epoch: 5| Step: 10
Training loss: 2.9488329887390137
Validation loss: 2.262269853263773

Epoch: 64| Step: 0
Training loss: 3.110382080078125
Validation loss: 2.2687517109737603

Epoch: 5| Step: 1
Training loss: 2.2409517765045166
Validation loss: 2.265604398583853

Epoch: 5| Step: 2
Training loss: 2.930454730987549
Validation loss: 2.275953218501101

Epoch: 5| Step: 3
Training loss: 2.738438129425049
Validation loss: 2.2818933071628695

Epoch: 5| Step: 4
Training loss: 2.6002297401428223
Validation loss: 2.2989210787639824

Epoch: 5| Step: 5
Training loss: 2.7554867267608643
Validation loss: 2.292620374310401

Epoch: 5| Step: 6
Training loss: 1.8782600164413452
Validation loss: 2.273440884005639

Epoch: 5| Step: 7
Training loss: 2.8847477436065674
Validation loss: 2.2615368212423017

Epoch: 5| Step: 8
Training loss: 2.455700159072876
Validation loss: 2.2578207087773148

Epoch: 5| Step: 9
Training loss: 1.993213415145874
Validation loss: 2.261417160751999

Epoch: 5| Step: 10
Training loss: 2.8600730895996094
Validation loss: 2.2713136083336285

Epoch: 65| Step: 0
Training loss: 2.611426830291748
Validation loss: 2.2691602245453866

Epoch: 5| Step: 1
Training loss: 2.6073880195617676
Validation loss: 2.2821384681168424

Epoch: 5| Step: 2
Training loss: 2.1410677433013916
Validation loss: 2.298888116754511

Epoch: 5| Step: 3
Training loss: 2.8080387115478516
Validation loss: 2.3480816861634612

Epoch: 5| Step: 4
Training loss: 2.479768753051758
Validation loss: 2.4517984979896137

Epoch: 5| Step: 5
Training loss: 2.5086910724639893
Validation loss: 2.486745421604444

Epoch: 5| Step: 6
Training loss: 2.6502292156219482
Validation loss: 2.504153638757685

Epoch: 5| Step: 7
Training loss: 2.383509397506714
Validation loss: 2.4396534965884302

Epoch: 5| Step: 8
Training loss: 2.909161329269409
Validation loss: 2.394528417177098

Epoch: 5| Step: 9
Training loss: 2.719566583633423
Validation loss: 2.347278848771126

Epoch: 5| Step: 10
Training loss: 3.1019325256347656
Validation loss: 2.3076714469540502

Epoch: 66| Step: 0
Training loss: 2.970336437225342
Validation loss: 2.2645594176425727

Epoch: 5| Step: 1
Training loss: 2.1648597717285156
Validation loss: 2.244367326459577

Epoch: 5| Step: 2
Training loss: 2.4364521503448486
Validation loss: 2.253561968444496

Epoch: 5| Step: 3
Training loss: 2.631139039993286
Validation loss: 2.272983617680047

Epoch: 5| Step: 4
Training loss: 2.761289596557617
Validation loss: 2.280824133144912

Epoch: 5| Step: 5
Training loss: 2.9476559162139893
Validation loss: 2.2745214918608307

Epoch: 5| Step: 6
Training loss: 2.363138437271118
Validation loss: 2.2663871831791376

Epoch: 5| Step: 7
Training loss: 2.361513614654541
Validation loss: 2.2666501114445348

Epoch: 5| Step: 8
Training loss: 2.2759509086608887
Validation loss: 2.2615132383120957

Epoch: 5| Step: 9
Training loss: 2.771066188812256
Validation loss: 2.252659638722738

Epoch: 5| Step: 10
Training loss: 2.7994532585144043
Validation loss: 2.247836171939809

Epoch: 67| Step: 0
Training loss: 1.9167506694793701
Validation loss: 2.244897214315271

Epoch: 5| Step: 1
Training loss: 2.17488431930542
Validation loss: 2.2423095305760703

Epoch: 5| Step: 2
Training loss: 2.5621495246887207
Validation loss: 2.2553320187394337

Epoch: 5| Step: 3
Training loss: 2.5720009803771973
Validation loss: 2.2860813076778124

Epoch: 5| Step: 4
Training loss: 2.4664745330810547
Validation loss: 2.2762379184845956

Epoch: 5| Step: 5
Training loss: 3.180461883544922
Validation loss: 2.2750144543186313

Epoch: 5| Step: 6
Training loss: 3.013507127761841
Validation loss: 2.2609629528496855

Epoch: 5| Step: 7
Training loss: 2.4964864253997803
Validation loss: 2.2519239482059272

Epoch: 5| Step: 8
Training loss: 2.6689321994781494
Validation loss: 2.281344367611793

Epoch: 5| Step: 9
Training loss: 2.3939614295959473
Validation loss: 2.3069085408282537

Epoch: 5| Step: 10
Training loss: 2.6850388050079346
Validation loss: 2.310157319550873

Epoch: 68| Step: 0
Training loss: 2.496809244155884
Validation loss: 2.330205886594711

Epoch: 5| Step: 1
Training loss: 2.57100248336792
Validation loss: 2.355796185872888

Epoch: 5| Step: 2
Training loss: 2.4147684574127197
Validation loss: 2.357329140427292

Epoch: 5| Step: 3
Training loss: 2.386549472808838
Validation loss: 2.3387038707733154

Epoch: 5| Step: 4
Training loss: 2.395049571990967
Validation loss: 2.3355124265916887

Epoch: 5| Step: 5
Training loss: 3.093938112258911
Validation loss: 2.322696965227845

Epoch: 5| Step: 6
Training loss: 2.6046271324157715
Validation loss: 2.294341920524515

Epoch: 5| Step: 7
Training loss: 2.700594663619995
Validation loss: 2.2812011703368156

Epoch: 5| Step: 8
Training loss: 2.736576795578003
Validation loss: 2.273942220595575

Epoch: 5| Step: 9
Training loss: 2.913768768310547
Validation loss: 2.2517155729314333

Epoch: 5| Step: 10
Training loss: 1.9891902208328247
Validation loss: 2.2416746180544616

Epoch: 69| Step: 0
Training loss: 2.6826491355895996
Validation loss: 2.2361655517291

Epoch: 5| Step: 1
Training loss: 2.192955493927002
Validation loss: 2.2399633289665304

Epoch: 5| Step: 2
Training loss: 2.1605782508850098
Validation loss: 2.2377393527697493

Epoch: 5| Step: 3
Training loss: 2.571913003921509
Validation loss: 2.2376499688753517

Epoch: 5| Step: 4
Training loss: 2.2797913551330566
Validation loss: 2.243281105513214

Epoch: 5| Step: 5
Training loss: 2.989534854888916
Validation loss: 2.2450050025857906

Epoch: 5| Step: 6
Training loss: 2.6598057746887207
Validation loss: 2.250332047862391

Epoch: 5| Step: 7
Training loss: 3.341200590133667
Validation loss: 2.252070511541059

Epoch: 5| Step: 8
Training loss: 2.311220169067383
Validation loss: 2.2698657281937136

Epoch: 5| Step: 9
Training loss: 2.431530475616455
Validation loss: 2.2985815181527087

Epoch: 5| Step: 10
Training loss: 2.617722511291504
Validation loss: 2.3173844916846162

Epoch: 70| Step: 0
Training loss: 2.214348554611206
Validation loss: 2.302140812720022

Epoch: 5| Step: 1
Training loss: 2.9314420223236084
Validation loss: 2.272393867533694

Epoch: 5| Step: 2
Training loss: 2.7623534202575684
Validation loss: 2.258413214837351

Epoch: 5| Step: 3
Training loss: 2.3740720748901367
Validation loss: 2.2660724860365673

Epoch: 5| Step: 4
Training loss: 1.7578849792480469
Validation loss: 2.27870193348136

Epoch: 5| Step: 5
Training loss: 2.552518367767334
Validation loss: 2.292415060022826

Epoch: 5| Step: 6
Training loss: 2.540074586868286
Validation loss: 2.2869086265563965

Epoch: 5| Step: 7
Training loss: 2.931760311126709
Validation loss: 2.274132349157846

Epoch: 5| Step: 8
Training loss: 2.501485586166382
Validation loss: 2.2493911738036783

Epoch: 5| Step: 9
Training loss: 2.533078670501709
Validation loss: 2.25277219792848

Epoch: 5| Step: 10
Training loss: 2.889949321746826
Validation loss: 2.2436672103020454

Epoch: 71| Step: 0
Training loss: 2.9954535961151123
Validation loss: 2.23543986710169

Epoch: 5| Step: 1
Training loss: 2.0007948875427246
Validation loss: 2.236752810016755

Epoch: 5| Step: 2
Training loss: 2.464897632598877
Validation loss: 2.227765590913834

Epoch: 5| Step: 3
Training loss: 2.5583930015563965
Validation loss: 2.2290302348393265

Epoch: 5| Step: 4
Training loss: 2.654750108718872
Validation loss: 2.2231080942256476

Epoch: 5| Step: 5
Training loss: 2.9420511722564697
Validation loss: 2.2191243812602055

Epoch: 5| Step: 6
Training loss: 2.5106139183044434
Validation loss: 2.217172899553853

Epoch: 5| Step: 7
Training loss: 2.480184555053711
Validation loss: 2.2170998896321943

Epoch: 5| Step: 8
Training loss: 2.423100471496582
Validation loss: 2.224127528487995

Epoch: 5| Step: 9
Training loss: 2.5971031188964844
Validation loss: 2.235260050783875

Epoch: 5| Step: 10
Training loss: 2.462421178817749
Validation loss: 2.2539422742782103

Epoch: 72| Step: 0
Training loss: 2.2744908332824707
Validation loss: 2.2672315130951586

Epoch: 5| Step: 1
Training loss: 2.1082468032836914
Validation loss: 2.3085518190937657

Epoch: 5| Step: 2
Training loss: 2.8450334072113037
Validation loss: 2.305868389785931

Epoch: 5| Step: 3
Training loss: 2.4707179069519043
Validation loss: 2.3181099814753376

Epoch: 5| Step: 4
Training loss: 2.8474507331848145
Validation loss: 2.3263676653626146

Epoch: 5| Step: 5
Training loss: 2.704735279083252
Validation loss: 2.3176678560113393

Epoch: 5| Step: 6
Training loss: 2.8929309844970703
Validation loss: 2.304113772607619

Epoch: 5| Step: 7
Training loss: 2.1690752506256104
Validation loss: 2.2545053164164224

Epoch: 5| Step: 8
Training loss: 3.2208411693573
Validation loss: 2.2298187850624003

Epoch: 5| Step: 9
Training loss: 2.154473304748535
Validation loss: 2.2102773368999524

Epoch: 5| Step: 10
Training loss: 2.262680768966675
Validation loss: 2.214408269492529

Epoch: 73| Step: 0
Training loss: 2.3495678901672363
Validation loss: 2.2345704647802536

Epoch: 5| Step: 1
Training loss: 2.3174290657043457
Validation loss: 2.2447241762632966

Epoch: 5| Step: 2
Training loss: 2.3982033729553223
Validation loss: 2.243845623026612

Epoch: 5| Step: 3
Training loss: 2.3922677040100098
Validation loss: 2.2304447004871983

Epoch: 5| Step: 4
Training loss: 3.1354787349700928
Validation loss: 2.2225876392856723

Epoch: 5| Step: 5
Training loss: 2.667044162750244
Validation loss: 2.220711244049893

Epoch: 5| Step: 6
Training loss: 2.495851516723633
Validation loss: 2.2193320156425558

Epoch: 5| Step: 7
Training loss: 2.4072749614715576
Validation loss: 2.2161901074071086

Epoch: 5| Step: 8
Training loss: 1.8625361919403076
Validation loss: 2.2299508869007068

Epoch: 5| Step: 9
Training loss: 2.3603177070617676
Validation loss: 2.232401937566778

Epoch: 5| Step: 10
Training loss: 3.8085803985595703
Validation loss: 2.235946188690842

Epoch: 74| Step: 0
Training loss: 2.5938022136688232
Validation loss: 2.2421793373682166

Epoch: 5| Step: 1
Training loss: 2.2766618728637695
Validation loss: 2.2662572783808552

Epoch: 5| Step: 2
Training loss: 2.7254106998443604
Validation loss: 2.3143527789782454

Epoch: 5| Step: 3
Training loss: 2.480236291885376
Validation loss: 2.3937729520182454

Epoch: 5| Step: 4
Training loss: 3.1727023124694824
Validation loss: 2.4592503616886754

Epoch: 5| Step: 5
Training loss: 2.7221462726593018
Validation loss: 2.4530384617467083

Epoch: 5| Step: 6
Training loss: 2.7395081520080566
Validation loss: 2.3906295812258156

Epoch: 5| Step: 7
Training loss: 2.972721815109253
Validation loss: 2.326009004346786

Epoch: 5| Step: 8
Training loss: 2.041879653930664
Validation loss: 2.2678268430053548

Epoch: 5| Step: 9
Training loss: 2.376610279083252
Validation loss: 2.2255335059217227

Epoch: 5| Step: 10
Training loss: 2.4217464923858643
Validation loss: 2.2078981168808474

Epoch: 75| Step: 0
Training loss: 2.6096768379211426
Validation loss: 2.2090245395578365

Epoch: 5| Step: 1
Training loss: 2.0894150733947754
Validation loss: 2.22276629811974

Epoch: 5| Step: 2
Training loss: 2.591642379760742
Validation loss: 2.2359979383407103

Epoch: 5| Step: 3
Training loss: 2.507235288619995
Validation loss: 2.2518465288223757

Epoch: 5| Step: 4
Training loss: 2.8938841819763184
Validation loss: 2.251324753607473

Epoch: 5| Step: 5
Training loss: 2.1501247882843018
Validation loss: 2.2334522585715018

Epoch: 5| Step: 6
Training loss: 2.5146164894104004
Validation loss: 2.2337908514084353

Epoch: 5| Step: 7
Training loss: 2.2718794345855713
Validation loss: 2.2275862950150684

Epoch: 5| Step: 8
Training loss: 3.4447059631347656
Validation loss: 2.2333670790477465

Epoch: 5| Step: 9
Training loss: 2.67771577835083
Validation loss: 2.233203523902483

Epoch: 5| Step: 10
Training loss: 2.197449207305908
Validation loss: 2.2545777238825315

Epoch: 76| Step: 0
Training loss: 2.56953501701355
Validation loss: 2.291204439696445

Epoch: 5| Step: 1
Training loss: 2.4295780658721924
Validation loss: 2.3117824292952016

Epoch: 5| Step: 2
Training loss: 2.7739157676696777
Validation loss: 2.326355375269408

Epoch: 5| Step: 3
Training loss: 2.564204692840576
Validation loss: 2.332587636927123

Epoch: 5| Step: 4
Training loss: 3.1242480278015137
Validation loss: 2.336025150873328

Epoch: 5| Step: 5
Training loss: 2.4934589862823486
Validation loss: 2.313035698347194

Epoch: 5| Step: 6
Training loss: 2.228080987930298
Validation loss: 2.2828518190691547

Epoch: 5| Step: 7
Training loss: 2.15462064743042
Validation loss: 2.2718696209692184

Epoch: 5| Step: 8
Training loss: 2.586941957473755
Validation loss: 2.2534977313010924

Epoch: 5| Step: 9
Training loss: 2.2859890460968018
Validation loss: 2.23442014058431

Epoch: 5| Step: 10
Training loss: 2.667600631713867
Validation loss: 2.2208955031569286

Epoch: 77| Step: 0
Training loss: 2.1962943077087402
Validation loss: 2.195155284738028

Epoch: 5| Step: 1
Training loss: 2.1438050270080566
Validation loss: 2.197795514137514

Epoch: 5| Step: 2
Training loss: 3.3791160583496094
Validation loss: 2.191153367360433

Epoch: 5| Step: 3
Training loss: 1.5646753311157227
Validation loss: 2.1811086849499772

Epoch: 5| Step: 4
Training loss: 2.7980453968048096
Validation loss: 2.1771631189571914

Epoch: 5| Step: 5
Training loss: 2.4324278831481934
Validation loss: 2.17666369868863

Epoch: 5| Step: 6
Training loss: 3.1186795234680176
Validation loss: 2.1778465958051783

Epoch: 5| Step: 7
Training loss: 2.266932964324951
Validation loss: 2.175384356129554

Epoch: 5| Step: 8
Training loss: 2.5317111015319824
Validation loss: 2.1827263268091346

Epoch: 5| Step: 9
Training loss: 2.0610179901123047
Validation loss: 2.202108411378758

Epoch: 5| Step: 10
Training loss: 3.2762742042541504
Validation loss: 2.2354343040015108

Epoch: 78| Step: 0
Training loss: 2.824767589569092
Validation loss: 2.284899171962533

Epoch: 5| Step: 1
Training loss: 2.5645480155944824
Validation loss: 2.3180375022272908

Epoch: 5| Step: 2
Training loss: 2.7068986892700195
Validation loss: 2.325219984977476

Epoch: 5| Step: 3
Training loss: 2.2597086429595947
Validation loss: 2.2972967009390555

Epoch: 5| Step: 4
Training loss: 2.687854766845703
Validation loss: 2.2594439675731044

Epoch: 5| Step: 5
Training loss: 2.6186304092407227
Validation loss: 2.2187337657456756

Epoch: 5| Step: 6
Training loss: 2.7078442573547363
Validation loss: 2.1971257502032864

Epoch: 5| Step: 7
Training loss: 2.4236605167388916
Validation loss: 2.1912301830066148

Epoch: 5| Step: 8
Training loss: 2.424330949783325
Validation loss: 2.1909442076119046

Epoch: 5| Step: 9
Training loss: 2.2849979400634766
Validation loss: 2.1826114090540076

Epoch: 5| Step: 10
Training loss: 2.4849905967712402
Validation loss: 2.1810088503745293

Epoch: 79| Step: 0
Training loss: 2.5315909385681152
Validation loss: 2.197963829963438

Epoch: 5| Step: 1
Training loss: 2.735909938812256
Validation loss: 2.2196527681043072

Epoch: 5| Step: 2
Training loss: 3.070681571960449
Validation loss: 2.2391346385402064

Epoch: 5| Step: 3
Training loss: 2.524758815765381
Validation loss: 2.2663906107666674

Epoch: 5| Step: 4
Training loss: 2.0447776317596436
Validation loss: 2.2582457655219623

Epoch: 5| Step: 5
Training loss: 2.4326961040496826
Validation loss: 2.228037093275337

Epoch: 5| Step: 6
Training loss: 3.161212205886841
Validation loss: 2.200954996129518

Epoch: 5| Step: 7
Training loss: 2.8786795139312744
Validation loss: 2.1815158782466764

Epoch: 5| Step: 8
Training loss: 1.9778261184692383
Validation loss: 2.1764528853918916

Epoch: 5| Step: 9
Training loss: 2.5248913764953613
Validation loss: 2.167123225427443

Epoch: 5| Step: 10
Training loss: 1.6838176250457764
Validation loss: 2.168211180676696

Epoch: 80| Step: 0
Training loss: 3.037738800048828
Validation loss: 2.165833547551145

Epoch: 5| Step: 1
Training loss: 3.112569808959961
Validation loss: 2.167266586775421

Epoch: 5| Step: 2
Training loss: 2.3997387886047363
Validation loss: 2.1669212925818657

Epoch: 5| Step: 3
Training loss: 2.523677349090576
Validation loss: 2.17072989351006

Epoch: 5| Step: 4
Training loss: 2.3048758506774902
Validation loss: 2.180747393638857

Epoch: 5| Step: 5
Training loss: 2.1945414543151855
Validation loss: 2.1900989535034343

Epoch: 5| Step: 6
Training loss: 2.8581578731536865
Validation loss: 2.1920836407651185

Epoch: 5| Step: 7
Training loss: 2.5146021842956543
Validation loss: 2.188442794225549

Epoch: 5| Step: 8
Training loss: 2.797539234161377
Validation loss: 2.184683624134269

Epoch: 5| Step: 9
Training loss: 1.4272416830062866
Validation loss: 2.1844696280776814

Epoch: 5| Step: 10
Training loss: 2.25927996635437
Validation loss: 2.18881441316297

Epoch: 81| Step: 0
Training loss: 2.1402077674865723
Validation loss: 2.187660227539719

Epoch: 5| Step: 1
Training loss: 2.140113353729248
Validation loss: 2.182827434232158

Epoch: 5| Step: 2
Training loss: 2.1860077381134033
Validation loss: 2.179435770998719

Epoch: 5| Step: 3
Training loss: 2.344128370285034
Validation loss: 2.179356973658326

Epoch: 5| Step: 4
Training loss: 2.9250025749206543
Validation loss: 2.177143645542924

Epoch: 5| Step: 5
Training loss: 2.560467004776001
Validation loss: 2.1736286071039017

Epoch: 5| Step: 6
Training loss: 2.26572322845459
Validation loss: 2.1753806350051716

Epoch: 5| Step: 7
Training loss: 2.8587334156036377
Validation loss: 2.180705165350309

Epoch: 5| Step: 8
Training loss: 3.0698025226593018
Validation loss: 2.1778473841246737

Epoch: 5| Step: 9
Training loss: 2.3846306800842285
Validation loss: 2.1876809045832646

Epoch: 5| Step: 10
Training loss: 2.537731647491455
Validation loss: 2.2055493875216414

Epoch: 82| Step: 0
Training loss: 2.021103858947754
Validation loss: 2.222121238708496

Epoch: 5| Step: 1
Training loss: 2.982705593109131
Validation loss: 2.252021530623077

Epoch: 5| Step: 2
Training loss: 2.158176898956299
Validation loss: 2.2606257777060232

Epoch: 5| Step: 3
Training loss: 2.3816170692443848
Validation loss: 2.2518439215998494

Epoch: 5| Step: 4
Training loss: 2.7319464683532715
Validation loss: 2.235278234686903

Epoch: 5| Step: 5
Training loss: 2.731494665145874
Validation loss: 2.2247858662759104

Epoch: 5| Step: 6
Training loss: 2.5711026191711426
Validation loss: 2.2211284893815235

Epoch: 5| Step: 7
Training loss: 2.4641566276550293
Validation loss: 2.207361009813124

Epoch: 5| Step: 8
Training loss: 3.0093984603881836
Validation loss: 2.1946476582557923

Epoch: 5| Step: 9
Training loss: 2.643087387084961
Validation loss: 2.1859376904784993

Epoch: 5| Step: 10
Training loss: 1.6063555479049683
Validation loss: 2.1834141721007643

Epoch: 83| Step: 0
Training loss: 2.954151153564453
Validation loss: 2.1850076567742134

Epoch: 5| Step: 1
Training loss: 2.9203624725341797
Validation loss: 2.177929562907065

Epoch: 5| Step: 2
Training loss: 2.1531920433044434
Validation loss: 2.1810829665071223

Epoch: 5| Step: 3
Training loss: 2.197544574737549
Validation loss: 2.179081191298782

Epoch: 5| Step: 4
Training loss: 2.158351421356201
Validation loss: 2.179547449593903

Epoch: 5| Step: 5
Training loss: 2.4984540939331055
Validation loss: 2.1899131267301497

Epoch: 5| Step: 6
Training loss: 2.8979806900024414
Validation loss: 2.1989052731503724

Epoch: 5| Step: 7
Training loss: 1.9399986267089844
Validation loss: 2.202080240813635

Epoch: 5| Step: 8
Training loss: 2.730952501296997
Validation loss: 2.1995470652016262

Epoch: 5| Step: 9
Training loss: 2.64243745803833
Validation loss: 2.224831840043427

Epoch: 5| Step: 10
Training loss: 2.2105560302734375
Validation loss: 2.2366179650829685

Epoch: 84| Step: 0
Training loss: 2.2424979209899902
Validation loss: 2.270739277203878

Epoch: 5| Step: 1
Training loss: 3.4357972145080566
Validation loss: 2.2420260906219482

Epoch: 5| Step: 2
Training loss: 2.55458402633667
Validation loss: 2.1601438060883553

Epoch: 5| Step: 3
Training loss: 2.3240232467651367
Validation loss: 2.1454080215064426

Epoch: 5| Step: 4
Training loss: 2.325925827026367
Validation loss: 2.1398686465396675

Epoch: 5| Step: 5
Training loss: 3.430173397064209
Validation loss: 2.1405900345053723

Epoch: 5| Step: 6
Training loss: 1.761948823928833
Validation loss: 2.1420592569535777

Epoch: 5| Step: 7
Training loss: 1.901429533958435
Validation loss: 2.150936019036078

Epoch: 5| Step: 8
Training loss: 2.0363948345184326
Validation loss: 2.152824053200342

Epoch: 5| Step: 9
Training loss: 3.0698230266571045
Validation loss: 2.170511217527492

Epoch: 5| Step: 10
Training loss: 2.483034133911133
Validation loss: 2.1669538995271087

Epoch: 85| Step: 0
Training loss: 1.924220323562622
Validation loss: 2.1731438841871036

Epoch: 5| Step: 1
Training loss: 2.35239839553833
Validation loss: 2.1766818569552515

Epoch: 5| Step: 2
Training loss: 2.524116277694702
Validation loss: 2.171291801237291

Epoch: 5| Step: 3
Training loss: 2.068965196609497
Validation loss: 2.165949865054059

Epoch: 5| Step: 4
Training loss: 2.945643901824951
Validation loss: 2.1652249572097615

Epoch: 5| Step: 5
Training loss: 2.325226306915283
Validation loss: 2.165733147692937

Epoch: 5| Step: 6
Training loss: 2.7739157676696777
Validation loss: 2.1561950560539

Epoch: 5| Step: 7
Training loss: 2.2588911056518555
Validation loss: 2.1560143655346287

Epoch: 5| Step: 8
Training loss: 2.713218927383423
Validation loss: 2.1656013470824047

Epoch: 5| Step: 9
Training loss: 2.455544948577881
Validation loss: 2.1540869346228977

Epoch: 5| Step: 10
Training loss: 3.010262966156006
Validation loss: 2.1520217516089

Epoch: 86| Step: 0
Training loss: 2.567211866378784
Validation loss: 2.157015226220572

Epoch: 5| Step: 1
Training loss: 2.392130136489868
Validation loss: 2.1574605793081303

Epoch: 5| Step: 2
Training loss: 2.556955337524414
Validation loss: 2.1507765400794243

Epoch: 5| Step: 3
Training loss: 2.1849708557128906
Validation loss: 2.143939705305202

Epoch: 5| Step: 4
Training loss: 2.574693441390991
Validation loss: 2.1489344643008326

Epoch: 5| Step: 5
Training loss: 2.4526662826538086
Validation loss: 2.1494731121165778

Epoch: 5| Step: 6
Training loss: 2.130056858062744
Validation loss: 2.15174037666731

Epoch: 5| Step: 7
Training loss: 2.7921223640441895
Validation loss: 2.1473688143555836

Epoch: 5| Step: 8
Training loss: 2.08595609664917
Validation loss: 2.162506418843423

Epoch: 5| Step: 9
Training loss: 2.576981782913208
Validation loss: 2.1754727748132523

Epoch: 5| Step: 10
Training loss: 2.871534585952759
Validation loss: 2.182373418602892

Epoch: 87| Step: 0
Training loss: 2.4276440143585205
Validation loss: 2.1817867191888953

Epoch: 5| Step: 1
Training loss: 2.229541540145874
Validation loss: 2.1901850213286695

Epoch: 5| Step: 2
Training loss: 2.596020221710205
Validation loss: 2.1999391766004663

Epoch: 5| Step: 3
Training loss: 3.0457918643951416
Validation loss: 2.2258220359843266

Epoch: 5| Step: 4
Training loss: 2.2414064407348633
Validation loss: 2.248669539728472

Epoch: 5| Step: 5
Training loss: 2.1756763458251953
Validation loss: 2.266354404469972

Epoch: 5| Step: 6
Training loss: 2.331486463546753
Validation loss: 2.259918471818329

Epoch: 5| Step: 7
Training loss: 3.0706818103790283
Validation loss: 2.2115451443579888

Epoch: 5| Step: 8
Training loss: 2.0344719886779785
Validation loss: 2.187025508572978

Epoch: 5| Step: 9
Training loss: 2.229121208190918
Validation loss: 2.1809176655225855

Epoch: 5| Step: 10
Training loss: 2.9959757328033447
Validation loss: 2.1631019653812533

Epoch: 88| Step: 0
Training loss: 2.7282216548919678
Validation loss: 2.1499255985342045

Epoch: 5| Step: 1
Training loss: 2.3063559532165527
Validation loss: 2.1449970071033766

Epoch: 5| Step: 2
Training loss: 2.5635592937469482
Validation loss: 2.141876769322221

Epoch: 5| Step: 3
Training loss: 2.8896331787109375
Validation loss: 2.134155942547706

Epoch: 5| Step: 4
Training loss: 2.456542491912842
Validation loss: 2.1323106545273975

Epoch: 5| Step: 5
Training loss: 1.7683525085449219
Validation loss: 2.1262982968361146

Epoch: 5| Step: 6
Training loss: 2.4713294506073
Validation loss: 2.1256515492675123

Epoch: 5| Step: 7
Training loss: 2.439272165298462
Validation loss: 2.129530293967134

Epoch: 5| Step: 8
Training loss: 2.6659398078918457
Validation loss: 2.1295597399434736

Epoch: 5| Step: 9
Training loss: 2.351680278778076
Validation loss: 2.130063223582442

Epoch: 5| Step: 10
Training loss: 2.4854090213775635
Validation loss: 2.1322092548493417

Epoch: 89| Step: 0
Training loss: 1.6924266815185547
Validation loss: 2.1392333597265263

Epoch: 5| Step: 1
Training loss: 2.9103634357452393
Validation loss: 2.149950522248463

Epoch: 5| Step: 2
Training loss: 1.9824609756469727
Validation loss: 2.1536357748893

Epoch: 5| Step: 3
Training loss: 2.616828203201294
Validation loss: 2.1543186005725654

Epoch: 5| Step: 4
Training loss: 2.964008331298828
Validation loss: 2.1707001937332975

Epoch: 5| Step: 5
Training loss: 2.2231152057647705
Validation loss: 2.177194592773273

Epoch: 5| Step: 6
Training loss: 2.3659071922302246
Validation loss: 2.1691106211754585

Epoch: 5| Step: 7
Training loss: 2.6225922107696533
Validation loss: 2.1522904211475002

Epoch: 5| Step: 8
Training loss: 2.175442934036255
Validation loss: 2.159424146016439

Epoch: 5| Step: 9
Training loss: 2.5595767498016357
Validation loss: 2.170480889658774

Epoch: 5| Step: 10
Training loss: 2.944331169128418
Validation loss: 2.1770461554168374

Epoch: 90| Step: 0
Training loss: 2.401939868927002
Validation loss: 2.178373541883243

Epoch: 5| Step: 1
Training loss: 2.6021008491516113
Validation loss: 2.178441095095809

Epoch: 5| Step: 2
Training loss: 3.307671308517456
Validation loss: 2.1634359334104802

Epoch: 5| Step: 3
Training loss: 2.7618887424468994
Validation loss: 2.1516352840649184

Epoch: 5| Step: 4
Training loss: 1.8083082437515259
Validation loss: 2.136702984891912

Epoch: 5| Step: 5
Training loss: 3.033264636993408
Validation loss: 2.1394468943277993

Epoch: 5| Step: 6
Training loss: 2.173502206802368
Validation loss: 2.1406062802960797

Epoch: 5| Step: 7
Training loss: 2.2189910411834717
Validation loss: 2.13676393160256

Epoch: 5| Step: 8
Training loss: 2.4208035469055176
Validation loss: 2.1473067473339778

Epoch: 5| Step: 9
Training loss: 2.6331474781036377
Validation loss: 2.1531044744676158

Epoch: 5| Step: 10
Training loss: 1.4841417074203491
Validation loss: 2.1460091067898657

Epoch: 91| Step: 0
Training loss: 2.7818093299865723
Validation loss: 2.1531075136635893

Epoch: 5| Step: 1
Training loss: 2.23768949508667
Validation loss: 2.14513930197685

Epoch: 5| Step: 2
Training loss: 2.49865984916687
Validation loss: 2.1452352949368056

Epoch: 5| Step: 3
Training loss: 2.306716203689575
Validation loss: 2.1515448657415246

Epoch: 5| Step: 4
Training loss: 2.7849979400634766
Validation loss: 2.143361363359677

Epoch: 5| Step: 5
Training loss: 2.3084490299224854
Validation loss: 2.1463840892238

Epoch: 5| Step: 6
Training loss: 2.808128833770752
Validation loss: 2.1507783192460255

Epoch: 5| Step: 7
Training loss: 2.3508543968200684
Validation loss: 2.1444251960323704

Epoch: 5| Step: 8
Training loss: 2.648674964904785
Validation loss: 2.146294688665739

Epoch: 5| Step: 9
Training loss: 1.9662954807281494
Validation loss: 2.1474769012902373

Epoch: 5| Step: 10
Training loss: 1.9665534496307373
Validation loss: 2.164521965929257

Epoch: 92| Step: 0
Training loss: 1.9006147384643555
Validation loss: 2.1836299947513047

Epoch: 5| Step: 1
Training loss: 2.2208595275878906
Validation loss: 2.193785475146386

Epoch: 5| Step: 2
Training loss: 2.482483386993408
Validation loss: 2.1987791010128555

Epoch: 5| Step: 3
Training loss: 2.269340991973877
Validation loss: 2.194406055635022

Epoch: 5| Step: 4
Training loss: 2.1883633136749268
Validation loss: 2.1762977466788342

Epoch: 5| Step: 5
Training loss: 3.031390428543091
Validation loss: 2.1772189345411075

Epoch: 5| Step: 6
Training loss: 2.5156409740448
Validation loss: 2.15557647392314

Epoch: 5| Step: 7
Training loss: 2.7303266525268555
Validation loss: 2.1521371897830757

Epoch: 5| Step: 8
Training loss: 2.0037856101989746
Validation loss: 2.125459865857196

Epoch: 5| Step: 9
Training loss: 3.0121707916259766
Validation loss: 2.117727506545282

Epoch: 5| Step: 10
Training loss: 2.600160837173462
Validation loss: 2.1159191516137894

Epoch: 93| Step: 0
Training loss: 2.5435235500335693
Validation loss: 2.1195171007546048

Epoch: 5| Step: 1
Training loss: 2.400709867477417
Validation loss: 2.1313566225831226

Epoch: 5| Step: 2
Training loss: 2.2217159271240234
Validation loss: 2.175466542602867

Epoch: 5| Step: 3
Training loss: 2.4255828857421875
Validation loss: 2.189348059315835

Epoch: 5| Step: 4
Training loss: 2.112940549850464
Validation loss: 2.1970282754590436

Epoch: 5| Step: 5
Training loss: 1.620112657546997
Validation loss: 2.208528841695478

Epoch: 5| Step: 6
Training loss: 2.7758948802948
Validation loss: 2.1986064551978983

Epoch: 5| Step: 7
Training loss: 3.2162559032440186
Validation loss: 2.1751158878367436

Epoch: 5| Step: 8
Training loss: 1.8605260848999023
Validation loss: 2.1737874643777007

Epoch: 5| Step: 9
Training loss: 2.7025604248046875
Validation loss: 2.167598839729063

Epoch: 5| Step: 10
Training loss: 3.5197739601135254
Validation loss: 2.170910927557176

Epoch: 94| Step: 0
Training loss: 2.752927780151367
Validation loss: 2.170984083606351

Epoch: 5| Step: 1
Training loss: 2.7482895851135254
Validation loss: 2.177397072956126

Epoch: 5| Step: 2
Training loss: 2.363525867462158
Validation loss: 2.1806047680557414

Epoch: 5| Step: 3
Training loss: 2.311978578567505
Validation loss: 2.1847394589454896

Epoch: 5| Step: 4
Training loss: 2.453174114227295
Validation loss: 2.1833353850149337

Epoch: 5| Step: 5
Training loss: 3.257065534591675
Validation loss: 2.1963133209495136

Epoch: 5| Step: 6
Training loss: 1.853597640991211
Validation loss: 2.1974004891610917

Epoch: 5| Step: 7
Training loss: 2.874321699142456
Validation loss: 2.2065894988275345

Epoch: 5| Step: 8
Training loss: 2.6977603435516357
Validation loss: 2.2046652378574496

Epoch: 5| Step: 9
Training loss: 1.816348671913147
Validation loss: 2.210708523309359

Epoch: 5| Step: 10
Training loss: 2.0414881706237793
Validation loss: 2.2015850672157864

Epoch: 95| Step: 0
Training loss: 2.503727436065674
Validation loss: 2.1935901257299606

Epoch: 5| Step: 1
Training loss: 2.58917498588562
Validation loss: 2.1853932975440897

Epoch: 5| Step: 2
Training loss: 2.099350690841675
Validation loss: 2.1820628822490735

Epoch: 5| Step: 3
Training loss: 2.3907065391540527
Validation loss: 2.184818862586893

Epoch: 5| Step: 4
Training loss: 2.1856799125671387
Validation loss: 2.189893394388178

Epoch: 5| Step: 5
Training loss: 2.1896591186523438
Validation loss: 2.1980210119678127

Epoch: 5| Step: 6
Training loss: 2.4295966625213623
Validation loss: 2.2081558319830124

Epoch: 5| Step: 7
Training loss: 2.7322609424591064
Validation loss: 2.196592072004913

Epoch: 5| Step: 8
Training loss: 2.871863842010498
Validation loss: 2.193166366187475

Epoch: 5| Step: 9
Training loss: 2.679166078567505
Validation loss: 2.1766026327686925

Epoch: 5| Step: 10
Training loss: 2.2870168685913086
Validation loss: 2.158744640247796

Epoch: 96| Step: 0
Training loss: 2.8611137866973877
Validation loss: 2.1535080427764566

Epoch: 5| Step: 1
Training loss: 2.122612714767456
Validation loss: 2.1431958008837957

Epoch: 5| Step: 2
Training loss: 2.502305269241333
Validation loss: 2.1467445640153784

Epoch: 5| Step: 3
Training loss: 2.6168437004089355
Validation loss: 2.144002978519727

Epoch: 5| Step: 4
Training loss: 2.507960557937622
Validation loss: 2.1443734566370645

Epoch: 5| Step: 5
Training loss: 2.503740072250366
Validation loss: 2.151343212332777

Epoch: 5| Step: 6
Training loss: 2.6488659381866455
Validation loss: 2.146487153986449

Epoch: 5| Step: 7
Training loss: 1.808405876159668
Validation loss: 2.157800784675024

Epoch: 5| Step: 8
Training loss: 2.211491346359253
Validation loss: 2.1872619121305403

Epoch: 5| Step: 9
Training loss: 3.004920482635498
Validation loss: 2.2401229771234656

Epoch: 5| Step: 10
Training loss: 2.0622353553771973
Validation loss: 2.2477468047090756

Epoch: 97| Step: 0
Training loss: 1.7293701171875
Validation loss: 2.254203934823313

Epoch: 5| Step: 1
Training loss: 3.4120631217956543
Validation loss: 2.248255519456761

Epoch: 5| Step: 2
Training loss: 2.572052240371704
Validation loss: 2.2117985166529173

Epoch: 5| Step: 3
Training loss: 2.3942742347717285
Validation loss: 2.193352239106291

Epoch: 5| Step: 4
Training loss: 2.489208221435547
Validation loss: 2.179445243650867

Epoch: 5| Step: 5
Training loss: 2.3788695335388184
Validation loss: 2.1497878912956483

Epoch: 5| Step: 6
Training loss: 2.040672540664673
Validation loss: 2.1466850183343373

Epoch: 5| Step: 7
Training loss: 2.2007699012756348
Validation loss: 2.1424674039245932

Epoch: 5| Step: 8
Training loss: 2.2874011993408203
Validation loss: 2.151339146398729

Epoch: 5| Step: 9
Training loss: 2.977095365524292
Validation loss: 2.161427718336864

Epoch: 5| Step: 10
Training loss: 2.497507095336914
Validation loss: 2.15774824542384

Epoch: 98| Step: 0
Training loss: 2.505189895629883
Validation loss: 2.1375266710917153

Epoch: 5| Step: 1
Training loss: 2.092689037322998
Validation loss: 2.144630111673827

Epoch: 5| Step: 2
Training loss: 2.1741185188293457
Validation loss: 2.1338454318302933

Epoch: 5| Step: 3
Training loss: 2.500084400177002
Validation loss: 2.115917685211346

Epoch: 5| Step: 4
Training loss: 2.426161766052246
Validation loss: 2.104323994728827

Epoch: 5| Step: 5
Training loss: 2.8516035079956055
Validation loss: 2.111475775318761

Epoch: 5| Step: 6
Training loss: 2.635387897491455
Validation loss: 2.1496448721936954

Epoch: 5| Step: 7
Training loss: 2.652801752090454
Validation loss: 2.2169355218128493

Epoch: 5| Step: 8
Training loss: 2.3067872524261475
Validation loss: 2.2853711292307866

Epoch: 5| Step: 9
Training loss: 2.581097364425659
Validation loss: 2.2693396640080277

Epoch: 5| Step: 10
Training loss: 2.3500447273254395
Validation loss: 2.2536338183187667

Epoch: 99| Step: 0
Training loss: 2.3255627155303955
Validation loss: 2.2082305018619826

Epoch: 5| Step: 1
Training loss: 2.5338871479034424
Validation loss: 2.171653498885452

Epoch: 5| Step: 2
Training loss: 2.5643105506896973
Validation loss: 2.165340615857032

Epoch: 5| Step: 3
Training loss: 3.1169183254241943
Validation loss: 2.133136095539216

Epoch: 5| Step: 4
Training loss: 2.045093059539795
Validation loss: 2.124636366803159

Epoch: 5| Step: 5
Training loss: 1.9174751043319702
Validation loss: 2.1212777578702537

Epoch: 5| Step: 6
Training loss: 2.3428168296813965
Validation loss: 2.125665985127931

Epoch: 5| Step: 7
Training loss: 2.3808493614196777
Validation loss: 2.142472526078583

Epoch: 5| Step: 8
Training loss: 2.568124771118164
Validation loss: 2.1455346486901723

Epoch: 5| Step: 9
Training loss: 2.3176498413085938
Validation loss: 2.1510477245494886

Epoch: 5| Step: 10
Training loss: 2.5365586280822754
Validation loss: 2.126833592691729

Epoch: 100| Step: 0
Training loss: 2.8269965648651123
Validation loss: 2.1308417281796856

Epoch: 5| Step: 1
Training loss: 2.0867228507995605
Validation loss: 2.1449179828807874

Epoch: 5| Step: 2
Training loss: 2.8809425830841064
Validation loss: 2.1367612141434864

Epoch: 5| Step: 3
Training loss: 1.9865596294403076
Validation loss: 2.127680500348409

Epoch: 5| Step: 4
Training loss: 2.141514301300049
Validation loss: 2.1310430188332834

Epoch: 5| Step: 5
Training loss: 2.2345175743103027
Validation loss: 2.1266723114957093

Epoch: 5| Step: 6
Training loss: 2.121138334274292
Validation loss: 2.130254004591255

Epoch: 5| Step: 7
Training loss: 2.7870736122131348
Validation loss: 2.1751426368631344

Epoch: 5| Step: 8
Training loss: 2.614760637283325
Validation loss: 2.2183128941443657

Epoch: 5| Step: 9
Training loss: 2.3975577354431152
Validation loss: 2.2714128289171445

Epoch: 5| Step: 10
Training loss: 2.591724157333374
Validation loss: 2.2214120857177244

Epoch: 101| Step: 0
Training loss: 2.401271343231201
Validation loss: 2.1349241490005166

Epoch: 5| Step: 1
Training loss: 2.6500298976898193
Validation loss: 2.092988475676506

Epoch: 5| Step: 2
Training loss: 2.0911476612091064
Validation loss: 2.0803123520266626

Epoch: 5| Step: 3
Training loss: 1.6629350185394287
Validation loss: 2.0845075781627367

Epoch: 5| Step: 4
Training loss: 2.683565139770508
Validation loss: 2.0788324084333194

Epoch: 5| Step: 5
Training loss: 2.977090835571289
Validation loss: 2.0887301903899

Epoch: 5| Step: 6
Training loss: 1.8742164373397827
Validation loss: 2.09069126395769

Epoch: 5| Step: 7
Training loss: 2.6981122493743896
Validation loss: 2.1026694620809248

Epoch: 5| Step: 8
Training loss: 3.024104595184326
Validation loss: 2.107023016099007

Epoch: 5| Step: 9
Training loss: 2.309187650680542
Validation loss: 2.108470183546825

Epoch: 5| Step: 10
Training loss: 2.2721009254455566
Validation loss: 2.1035369929446968

Epoch: 102| Step: 0
Training loss: 2.8716061115264893
Validation loss: 2.0974756748445573

Epoch: 5| Step: 1
Training loss: 2.2081661224365234
Validation loss: 2.099113977083596

Epoch: 5| Step: 2
Training loss: 2.905799150466919
Validation loss: 2.096866075710584

Epoch: 5| Step: 3
Training loss: 2.6907622814178467
Validation loss: 2.090389261963547

Epoch: 5| Step: 4
Training loss: 2.3093035221099854
Validation loss: 2.094321452161317

Epoch: 5| Step: 5
Training loss: 2.805206537246704
Validation loss: 2.110294149767968

Epoch: 5| Step: 6
Training loss: 1.674923300743103
Validation loss: 2.1286213603070987

Epoch: 5| Step: 7
Training loss: 2.4107918739318848
Validation loss: 2.133056502188406

Epoch: 5| Step: 8
Training loss: 2.5150794982910156
Validation loss: 2.1293779585951116

Epoch: 5| Step: 9
Training loss: 2.1547787189483643
Validation loss: 2.1217406206233527

Epoch: 5| Step: 10
Training loss: 1.7458834648132324
Validation loss: 2.1175305663898425

Epoch: 103| Step: 0
Training loss: 2.3982086181640625
Validation loss: 2.1043503002453874

Epoch: 5| Step: 1
Training loss: 2.138643503189087
Validation loss: 2.096589071776277

Epoch: 5| Step: 2
Training loss: 1.9185653924942017
Validation loss: 2.0859467278244677

Epoch: 5| Step: 3
Training loss: 2.0106518268585205
Validation loss: 2.0892595244992163

Epoch: 5| Step: 4
Training loss: 2.5048298835754395
Validation loss: 2.085140606408478

Epoch: 5| Step: 5
Training loss: 3.111095428466797
Validation loss: 2.0842445409426125

Epoch: 5| Step: 6
Training loss: 2.1124119758605957
Validation loss: 2.089352869218396

Epoch: 5| Step: 7
Training loss: 2.357184886932373
Validation loss: 2.08303056481064

Epoch: 5| Step: 8
Training loss: 3.4587063789367676
Validation loss: 2.0804446820289857

Epoch: 5| Step: 9
Training loss: 2.23032808303833
Validation loss: 2.0735150229546333

Epoch: 5| Step: 10
Training loss: 1.9633491039276123
Validation loss: 2.078353108898286

Epoch: 104| Step: 0
Training loss: 2.445178270339966
Validation loss: 2.0795782868580153

Epoch: 5| Step: 1
Training loss: 1.9187978506088257
Validation loss: 2.0904104325079147

Epoch: 5| Step: 2
Training loss: 2.5833141803741455
Validation loss: 2.1264524382929646

Epoch: 5| Step: 3
Training loss: 1.9944305419921875
Validation loss: 2.1801912758940007

Epoch: 5| Step: 4
Training loss: 1.8684765100479126
Validation loss: 2.193356817768466

Epoch: 5| Step: 5
Training loss: 3.158156156539917
Validation loss: 2.2261350462513585

Epoch: 5| Step: 6
Training loss: 2.4853196144104004
Validation loss: 2.196738927595077

Epoch: 5| Step: 7
Training loss: 2.71718168258667
Validation loss: 2.145309358514765

Epoch: 5| Step: 8
Training loss: 2.3503170013427734
Validation loss: 2.1021951834360757

Epoch: 5| Step: 9
Training loss: 2.2709622383117676
Validation loss: 2.0917686159892748

Epoch: 5| Step: 10
Training loss: 2.532841682434082
Validation loss: 2.07582845739139

Epoch: 105| Step: 0
Training loss: 2.199909210205078
Validation loss: 2.0705889219878824

Epoch: 5| Step: 1
Training loss: 2.505107879638672
Validation loss: 2.0712724116540726

Epoch: 5| Step: 2
Training loss: 1.6473042964935303
Validation loss: 2.0734965275692683

Epoch: 5| Step: 3
Training loss: 2.70442533493042
Validation loss: 2.072604510091966

Epoch: 5| Step: 4
Training loss: 2.1442389488220215
Validation loss: 2.0750677098510084

Epoch: 5| Step: 5
Training loss: 2.446608066558838
Validation loss: 2.081300445782241

Epoch: 5| Step: 6
Training loss: 3.082395076751709
Validation loss: 2.076871751457132

Epoch: 5| Step: 7
Training loss: 2.5371367931365967
Validation loss: 2.0800311103943856

Epoch: 5| Step: 8
Training loss: 1.8728883266448975
Validation loss: 2.1013589353971582

Epoch: 5| Step: 9
Training loss: 2.3937532901763916
Validation loss: 2.1112794850462224

Epoch: 5| Step: 10
Training loss: 2.515598773956299
Validation loss: 2.1066047747929892

Epoch: 106| Step: 0
Training loss: 2.538904905319214
Validation loss: 2.0936005115509033

Epoch: 5| Step: 1
Training loss: 2.6690361499786377
Validation loss: 2.085180967084823

Epoch: 5| Step: 2
Training loss: 2.484567403793335
Validation loss: 2.0793212562479

Epoch: 5| Step: 3
Training loss: 2.0049901008605957
Validation loss: 2.07825348454137

Epoch: 5| Step: 4
Training loss: 2.687661647796631
Validation loss: 2.093462754321355

Epoch: 5| Step: 5
Training loss: 1.940879464149475
Validation loss: 2.115906530810941

Epoch: 5| Step: 6
Training loss: 2.690279483795166
Validation loss: 2.137379066918486

Epoch: 5| Step: 7
Training loss: 2.5147335529327393
Validation loss: 2.13818395650515

Epoch: 5| Step: 8
Training loss: 1.8051830530166626
Validation loss: 2.11585077803622

Epoch: 5| Step: 9
Training loss: 2.040919542312622
Validation loss: 2.0946117883087485

Epoch: 5| Step: 10
Training loss: 2.6581835746765137
Validation loss: 2.073236443663156

Epoch: 107| Step: 0
Training loss: 2.5392024517059326
Validation loss: 2.0721643688858196

Epoch: 5| Step: 1
Training loss: 1.7787164449691772
Validation loss: 2.0668507442679456

Epoch: 5| Step: 2
Training loss: 2.6887409687042236
Validation loss: 2.0624417720302457

Epoch: 5| Step: 3
Training loss: 1.7532415390014648
Validation loss: 2.0492794077883483

Epoch: 5| Step: 4
Training loss: 2.721953868865967
Validation loss: 2.0407095519445275

Epoch: 5| Step: 5
Training loss: 2.335538387298584
Validation loss: 2.0484225570514636

Epoch: 5| Step: 6
Training loss: 2.053135395050049
Validation loss: 2.059024641590734

Epoch: 5| Step: 7
Training loss: 2.2277092933654785
Validation loss: 2.0772589009295226

Epoch: 5| Step: 8
Training loss: 2.5598833560943604
Validation loss: 2.09876734851509

Epoch: 5| Step: 9
Training loss: 2.601832628250122
Validation loss: 2.1481496287930395

Epoch: 5| Step: 10
Training loss: 2.7369508743286133
Validation loss: 2.1818317803003455

Epoch: 108| Step: 0
Training loss: 2.6214606761932373
Validation loss: 2.2024899785236647

Epoch: 5| Step: 1
Training loss: 2.8337180614471436
Validation loss: 2.213239908218384

Epoch: 5| Step: 2
Training loss: 2.271646499633789
Validation loss: 2.23908426684718

Epoch: 5| Step: 3
Training loss: 1.7178150415420532
Validation loss: 2.2313360552633963

Epoch: 5| Step: 4
Training loss: 2.310995578765869
Validation loss: 2.1569143572161273

Epoch: 5| Step: 5
Training loss: 2.377387285232544
Validation loss: 2.091501498735079

Epoch: 5| Step: 6
Training loss: 2.1342861652374268
Validation loss: 2.060015686096684

Epoch: 5| Step: 7
Training loss: 2.3539347648620605
Validation loss: 2.050759328308926

Epoch: 5| Step: 8
Training loss: 2.650813341140747
Validation loss: 2.0482607015999417

Epoch: 5| Step: 9
Training loss: 2.6751821041107178
Validation loss: 2.0465745028629097

Epoch: 5| Step: 10
Training loss: 2.7543249130249023
Validation loss: 2.053585380636236

Epoch: 109| Step: 0
Training loss: 2.1099436283111572
Validation loss: 2.048450323843187

Epoch: 5| Step: 1
Training loss: 2.6398024559020996
Validation loss: 2.060456004194034

Epoch: 5| Step: 2
Training loss: 2.4982101917266846
Validation loss: 2.0720099454284995

Epoch: 5| Step: 3
Training loss: 2.2042980194091797
Validation loss: 2.082199522244033

Epoch: 5| Step: 4
Training loss: 2.27156400680542
Validation loss: 2.0818123612352597

Epoch: 5| Step: 5
Training loss: 1.9019567966461182
Validation loss: 2.070376947361936

Epoch: 5| Step: 6
Training loss: 1.8772186040878296
Validation loss: 2.070960465297904

Epoch: 5| Step: 7
Training loss: 3.154069185256958
Validation loss: 2.0682180594372492

Epoch: 5| Step: 8
Training loss: 2.8856329917907715
Validation loss: 2.073186441134381

Epoch: 5| Step: 9
Training loss: 2.143190860748291
Validation loss: 2.083786277360814

Epoch: 5| Step: 10
Training loss: 2.2558863162994385
Validation loss: 2.0984694727005495

Epoch: 110| Step: 0
Training loss: 2.2272353172302246
Validation loss: 2.077747296261531

Epoch: 5| Step: 1
Training loss: 2.385066270828247
Validation loss: 2.0713384459095616

Epoch: 5| Step: 2
Training loss: 1.9166520833969116
Validation loss: 2.0575504661888204

Epoch: 5| Step: 3
Training loss: 2.221947431564331
Validation loss: 2.049407623147452

Epoch: 5| Step: 4
Training loss: 2.900158405303955
Validation loss: 2.044909510561215

Epoch: 5| Step: 5
Training loss: 1.8135433197021484
Validation loss: 2.0481365252566595

Epoch: 5| Step: 6
Training loss: 2.47398042678833
Validation loss: 2.048575908906998

Epoch: 5| Step: 7
Training loss: 2.3244333267211914
Validation loss: 2.0519204216618694

Epoch: 5| Step: 8
Training loss: 2.8226606845855713
Validation loss: 2.050924798493744

Epoch: 5| Step: 9
Training loss: 2.5236668586730957
Validation loss: 2.0603172061263875

Epoch: 5| Step: 10
Training loss: 2.1899261474609375
Validation loss: 2.073463847560267

Epoch: 111| Step: 0
Training loss: 2.4455466270446777
Validation loss: 2.0814521287077214

Epoch: 5| Step: 1
Training loss: 2.775670289993286
Validation loss: 2.088011613456152

Epoch: 5| Step: 2
Training loss: 2.6403470039367676
Validation loss: 2.0918427923674225

Epoch: 5| Step: 3
Training loss: 2.2878241539001465
Validation loss: 2.0963844176261657

Epoch: 5| Step: 4
Training loss: 2.39471173286438
Validation loss: 2.0943092300045874

Epoch: 5| Step: 5
Training loss: 1.8976624011993408
Validation loss: 2.1140300355931765

Epoch: 5| Step: 6
Training loss: 1.9394652843475342
Validation loss: 2.114516992722788

Epoch: 5| Step: 7
Training loss: 2.9247658252716064
Validation loss: 2.108390495341311

Epoch: 5| Step: 8
Training loss: 2.0316672325134277
Validation loss: 2.08665660888918

Epoch: 5| Step: 9
Training loss: 2.0104072093963623
Validation loss: 2.0560028194099345

Epoch: 5| Step: 10
Training loss: 2.4632740020751953
Validation loss: 2.0412445837451565

Epoch: 112| Step: 0
Training loss: 2.751887321472168
Validation loss: 2.035381124865624

Epoch: 5| Step: 1
Training loss: 2.7391879558563232
Validation loss: 2.0322336573754587

Epoch: 5| Step: 2
Training loss: 2.3844492435455322
Validation loss: 2.034448226292928

Epoch: 5| Step: 3
Training loss: 2.1482205390930176
Validation loss: 2.0351885108537573

Epoch: 5| Step: 4
Training loss: 1.8176615238189697
Validation loss: 2.03377277364013

Epoch: 5| Step: 5
Training loss: 2.149794101715088
Validation loss: 2.0347141527360484

Epoch: 5| Step: 6
Training loss: 2.4664275646209717
Validation loss: 2.0279709651906

Epoch: 5| Step: 7
Training loss: 2.6277451515197754
Validation loss: 2.032714259239935

Epoch: 5| Step: 8
Training loss: 1.907288908958435
Validation loss: 2.0301568802966865

Epoch: 5| Step: 9
Training loss: 2.1552374362945557
Validation loss: 2.0286355339070803

Epoch: 5| Step: 10
Training loss: 2.605048418045044
Validation loss: 2.0293352039911414

Epoch: 113| Step: 0
Training loss: 2.7265164852142334
Validation loss: 2.0305130981629893

Epoch: 5| Step: 1
Training loss: 2.3432204723358154
Validation loss: 2.0535885992870537

Epoch: 5| Step: 2
Training loss: 1.538010597229004
Validation loss: 2.072919004706926

Epoch: 5| Step: 3
Training loss: 2.3516554832458496
Validation loss: 2.073597308128111

Epoch: 5| Step: 4
Training loss: 1.9527862071990967
Validation loss: 2.070438059427405

Epoch: 5| Step: 5
Training loss: 2.5640511512756348
Validation loss: 2.0561287556925127

Epoch: 5| Step: 6
Training loss: 3.054281711578369
Validation loss: 2.0350522225902927

Epoch: 5| Step: 7
Training loss: 2.305577516555786
Validation loss: 2.0362254445270827

Epoch: 5| Step: 8
Training loss: 1.838281273841858
Validation loss: 2.01799342965567

Epoch: 5| Step: 9
Training loss: 2.2798049449920654
Validation loss: 2.02651737582299

Epoch: 5| Step: 10
Training loss: 2.418792247772217
Validation loss: 2.018831754243502

Epoch: 114| Step: 0
Training loss: 3.0219268798828125
Validation loss: 2.020268242846253

Epoch: 5| Step: 1
Training loss: 1.8738243579864502
Validation loss: 2.019886821828863

Epoch: 5| Step: 2
Training loss: 1.4962002038955688
Validation loss: 2.0192335395402807

Epoch: 5| Step: 3
Training loss: 2.44500470161438
Validation loss: 2.034595226728788

Epoch: 5| Step: 4
Training loss: 2.071715831756592
Validation loss: 2.0397866900249193

Epoch: 5| Step: 5
Training loss: 2.7522499561309814
Validation loss: 2.0351347948915217

Epoch: 5| Step: 6
Training loss: 2.5179696083068848
Validation loss: 2.0346803626706524

Epoch: 5| Step: 7
Training loss: 2.163546562194824
Validation loss: 2.045010248819987

Epoch: 5| Step: 8
Training loss: 2.324458599090576
Validation loss: 2.062534345093594

Epoch: 5| Step: 9
Training loss: 2.296255588531494
Validation loss: 2.088649208827685

Epoch: 5| Step: 10
Training loss: 2.854266881942749
Validation loss: 2.104344432071973

Epoch: 115| Step: 0
Training loss: 2.1851940155029297
Validation loss: 2.0948066762698594

Epoch: 5| Step: 1
Training loss: 2.454030752182007
Validation loss: 2.058617215002737

Epoch: 5| Step: 2
Training loss: 1.809491753578186
Validation loss: 2.032433074007752

Epoch: 5| Step: 3
Training loss: 1.9548025131225586
Validation loss: 2.0081732029555948

Epoch: 5| Step: 4
Training loss: 2.514587163925171
Validation loss: 1.9979452599761307

Epoch: 5| Step: 5
Training loss: 1.8108148574829102
Validation loss: 2.0057998985372563

Epoch: 5| Step: 6
Training loss: 2.2737114429473877
Validation loss: 1.9990829113991029

Epoch: 5| Step: 7
Training loss: 2.5218186378479004
Validation loss: 2.004447506320092

Epoch: 5| Step: 8
Training loss: 2.2161004543304443
Validation loss: 2.007202212528516

Epoch: 5| Step: 9
Training loss: 3.0598604679107666
Validation loss: 2.010329541339669

Epoch: 5| Step: 10
Training loss: 2.532832384109497
Validation loss: 2.013767478286579

Epoch: 116| Step: 0
Training loss: 1.7514302730560303
Validation loss: 2.0240459416502263

Epoch: 5| Step: 1
Training loss: 2.308098316192627
Validation loss: 2.0478635577745337

Epoch: 5| Step: 2
Training loss: 2.1889607906341553
Validation loss: 2.0788032829120593

Epoch: 5| Step: 3
Training loss: 2.4260716438293457
Validation loss: 2.085287465844103

Epoch: 5| Step: 4
Training loss: 1.9562766551971436
Validation loss: 2.109626249600482

Epoch: 5| Step: 5
Training loss: 2.2433440685272217
Validation loss: 2.0947236681497223

Epoch: 5| Step: 6
Training loss: 2.225928783416748
Validation loss: 2.0658566259568736

Epoch: 5| Step: 7
Training loss: 2.859776020050049
Validation loss: 2.0340828959659865

Epoch: 5| Step: 8
Training loss: 2.6496145725250244
Validation loss: 2.0213017156047206

Epoch: 5| Step: 9
Training loss: 2.642608880996704
Validation loss: 2.017894629509218

Epoch: 5| Step: 10
Training loss: 1.7898420095443726
Validation loss: 2.0287952397459295

Epoch: 117| Step: 0
Training loss: 1.8578678369522095
Validation loss: 2.022877998249505

Epoch: 5| Step: 1
Training loss: 2.4390368461608887
Validation loss: 2.0245044731324717

Epoch: 5| Step: 2
Training loss: 2.463261842727661
Validation loss: 2.02082037028446

Epoch: 5| Step: 3
Training loss: 1.772234559059143
Validation loss: 2.031354445283131

Epoch: 5| Step: 4
Training loss: 3.1328530311584473
Validation loss: 2.0427681220475065

Epoch: 5| Step: 5
Training loss: 1.7330920696258545
Validation loss: 2.0354500996169222

Epoch: 5| Step: 6
Training loss: 2.719759702682495
Validation loss: 2.0527760777422177

Epoch: 5| Step: 7
Training loss: 1.9626067876815796
Validation loss: 2.0556742760442916

Epoch: 5| Step: 8
Training loss: 2.5824825763702393
Validation loss: 2.0823144220536753

Epoch: 5| Step: 9
Training loss: 2.395217180252075
Validation loss: 2.0944988189205045

Epoch: 5| Step: 10
Training loss: 2.0326125621795654
Validation loss: 2.077434996122955

Epoch: 118| Step: 0
Training loss: 1.4955811500549316
Validation loss: 2.0622252110512025

Epoch: 5| Step: 1
Training loss: 2.0117335319519043
Validation loss: 2.045604882701751

Epoch: 5| Step: 2
Training loss: 2.179900646209717
Validation loss: 2.035317015904252

Epoch: 5| Step: 3
Training loss: 2.6427884101867676
Validation loss: 2.029335261673056

Epoch: 5| Step: 4
Training loss: 2.0515317916870117
Validation loss: 2.0158429158631193

Epoch: 5| Step: 5
Training loss: 2.5175042152404785
Validation loss: 2.00562019758327

Epoch: 5| Step: 6
Training loss: 2.5718257427215576
Validation loss: 2.0117791122005833

Epoch: 5| Step: 7
Training loss: 1.5504425764083862
Validation loss: 2.0124988696908437

Epoch: 5| Step: 8
Training loss: 2.593897581100464
Validation loss: 2.0169757232871106

Epoch: 5| Step: 9
Training loss: 2.4754605293273926
Validation loss: 2.022971481405279

Epoch: 5| Step: 10
Training loss: 2.894596576690674
Validation loss: 2.0171326321940266

Epoch: 119| Step: 0
Training loss: 2.2352192401885986
Validation loss: 2.0139993095910675

Epoch: 5| Step: 1
Training loss: 2.3612093925476074
Validation loss: 2.0118545101534937

Epoch: 5| Step: 2
Training loss: 1.8996028900146484
Validation loss: 2.022503411898049

Epoch: 5| Step: 3
Training loss: 1.7838973999023438
Validation loss: 2.027273078118601

Epoch: 5| Step: 4
Training loss: 2.4604721069335938
Validation loss: 2.034469066127654

Epoch: 5| Step: 5
Training loss: 2.262134075164795
Validation loss: 2.0262996842784267

Epoch: 5| Step: 6
Training loss: 2.1907920837402344
Validation loss: 2.0159834700246013

Epoch: 5| Step: 7
Training loss: 3.0062670707702637
Validation loss: 2.023610638033959

Epoch: 5| Step: 8
Training loss: 2.36501145362854
Validation loss: 2.0305685227917087

Epoch: 5| Step: 9
Training loss: 2.1898446083068848
Validation loss: 2.036225975200694

Epoch: 5| Step: 10
Training loss: 1.972119688987732
Validation loss: 2.03223531605095

Epoch: 120| Step: 0
Training loss: 2.613365888595581
Validation loss: 2.016389504555733

Epoch: 5| Step: 1
Training loss: 2.314119577407837
Validation loss: 2.0099476024668705

Epoch: 5| Step: 2
Training loss: 2.356640577316284
Validation loss: 1.9931510443328528

Epoch: 5| Step: 3
Training loss: 2.086494207382202
Validation loss: 1.9872023533749323

Epoch: 5| Step: 4
Training loss: 2.4653449058532715
Validation loss: 1.990182771477648

Epoch: 5| Step: 5
Training loss: 1.9286304712295532
Validation loss: 1.9931975667194655

Epoch: 5| Step: 6
Training loss: 2.2974696159362793
Validation loss: 1.982456858440112

Epoch: 5| Step: 7
Training loss: 2.5647330284118652
Validation loss: 1.9782955172241374

Epoch: 5| Step: 8
Training loss: 1.8913860321044922
Validation loss: 1.9855554334578975

Epoch: 5| Step: 9
Training loss: 2.29295015335083
Validation loss: 2.016629142145957

Epoch: 5| Step: 10
Training loss: 2.019282579421997
Validation loss: 2.049777461636451

Epoch: 121| Step: 0
Training loss: 2.403754711151123
Validation loss: 2.0956909425797

Epoch: 5| Step: 1
Training loss: 2.026547431945801
Validation loss: 2.1599976093538347

Epoch: 5| Step: 2
Training loss: 2.524080276489258
Validation loss: 2.1995651568135908

Epoch: 5| Step: 3
Training loss: 1.7692285776138306
Validation loss: 2.2105785441654984

Epoch: 5| Step: 4
Training loss: 2.494854688644409
Validation loss: 2.1882480472646733

Epoch: 5| Step: 5
Training loss: 3.0139269828796387
Validation loss: 2.1560546685290594

Epoch: 5| Step: 6
Training loss: 2.15486216545105
Validation loss: 2.0842673458078855

Epoch: 5| Step: 7
Training loss: 1.7976773977279663
Validation loss: 2.0191565739211215

Epoch: 5| Step: 8
Training loss: 2.255046844482422
Validation loss: 2.0035219166868474

Epoch: 5| Step: 9
Training loss: 2.113715171813965
Validation loss: 2.0034495246025825

Epoch: 5| Step: 10
Training loss: 2.9661240577697754
Validation loss: 1.9983255811916885

Epoch: 122| Step: 0
Training loss: 2.580577850341797
Validation loss: 2.001027963494742

Epoch: 5| Step: 1
Training loss: 2.3307480812072754
Validation loss: 2.0019906079897316

Epoch: 5| Step: 2
Training loss: 2.319281816482544
Validation loss: 2.0218372550061954

Epoch: 5| Step: 3
Training loss: 2.640529155731201
Validation loss: 2.0317450966886295

Epoch: 5| Step: 4
Training loss: 1.9223439693450928
Validation loss: 2.026196559270223

Epoch: 5| Step: 5
Training loss: 2.2506816387176514
Validation loss: 2.029560314711704

Epoch: 5| Step: 6
Training loss: 2.258995294570923
Validation loss: 2.0361475072881228

Epoch: 5| Step: 7
Training loss: 1.803728699684143
Validation loss: 2.070374855431177

Epoch: 5| Step: 8
Training loss: 2.3181052207946777
Validation loss: 2.0997579533566713

Epoch: 5| Step: 9
Training loss: 2.868786334991455
Validation loss: 2.108042750307309

Epoch: 5| Step: 10
Training loss: 2.18799090385437
Validation loss: 2.1308960427520094

Epoch: 123| Step: 0
Training loss: 1.9982633590698242
Validation loss: 2.140317150341567

Epoch: 5| Step: 1
Training loss: 2.317348003387451
Validation loss: 2.1357463944342827

Epoch: 5| Step: 2
Training loss: 2.38202166557312
Validation loss: 2.131400021173621

Epoch: 5| Step: 3
Training loss: 2.6006247997283936
Validation loss: 2.114777018946986

Epoch: 5| Step: 4
Training loss: 2.7202446460723877
Validation loss: 2.0892705814812773

Epoch: 5| Step: 5
Training loss: 1.4916518926620483
Validation loss: 2.0577453836317985

Epoch: 5| Step: 6
Training loss: 1.9380671977996826
Validation loss: 2.0542100680771695

Epoch: 5| Step: 7
Training loss: 2.558584213256836
Validation loss: 2.043900156533846

Epoch: 5| Step: 8
Training loss: 2.5098180770874023
Validation loss: 2.0321215942341793

Epoch: 5| Step: 9
Training loss: 2.512774705886841
Validation loss: 2.036292850330312

Epoch: 5| Step: 10
Training loss: 2.0028069019317627
Validation loss: 2.036751280548752

Epoch: 124| Step: 0
Training loss: 2.2971718311309814
Validation loss: 2.035235094767745

Epoch: 5| Step: 1
Training loss: 2.2633614540100098
Validation loss: 2.0263136535562496

Epoch: 5| Step: 2
Training loss: 2.1084389686584473
Validation loss: 2.0152617321219495

Epoch: 5| Step: 3
Training loss: 2.524522304534912
Validation loss: 2.0175449476447156

Epoch: 5| Step: 4
Training loss: 2.501338481903076
Validation loss: 2.0223357626186904

Epoch: 5| Step: 5
Training loss: 2.300879955291748
Validation loss: 2.0139196406128588

Epoch: 5| Step: 6
Training loss: 1.8586994409561157
Validation loss: 2.0132449160340014

Epoch: 5| Step: 7
Training loss: 2.0085341930389404
Validation loss: 2.0123430195675103

Epoch: 5| Step: 8
Training loss: 2.240711212158203
Validation loss: 2.0024985754361717

Epoch: 5| Step: 9
Training loss: 2.7216689586639404
Validation loss: 2.0160280273806666

Epoch: 5| Step: 10
Training loss: 1.7508803606033325
Validation loss: 2.017341063868615

Epoch: 125| Step: 0
Training loss: 2.5733766555786133
Validation loss: 2.025134810837366

Epoch: 5| Step: 1
Training loss: 1.7715339660644531
Validation loss: 2.0471363349627425

Epoch: 5| Step: 2
Training loss: 1.787735939025879
Validation loss: 2.0609734173743957

Epoch: 5| Step: 3
Training loss: 2.9470574855804443
Validation loss: 2.0658027638671217

Epoch: 5| Step: 4
Training loss: 2.3705620765686035
Validation loss: 2.058385137588747

Epoch: 5| Step: 5
Training loss: 1.979701280593872
Validation loss: 2.066323568744044

Epoch: 5| Step: 6
Training loss: 2.925630569458008
Validation loss: 2.0346143053423975

Epoch: 5| Step: 7
Training loss: 2.283095121383667
Validation loss: 2.012308753946776

Epoch: 5| Step: 8
Training loss: 1.9820111989974976
Validation loss: 2.0151558050545315

Epoch: 5| Step: 9
Training loss: 1.9242490530014038
Validation loss: 2.0111493410602694

Epoch: 5| Step: 10
Training loss: 1.9639602899551392
Validation loss: 2.009756456139267

Epoch: 126| Step: 0
Training loss: 2.781506299972534
Validation loss: 2.003987750699443

Epoch: 5| Step: 1
Training loss: 1.6024993658065796
Validation loss: 2.0087329110791607

Epoch: 5| Step: 2
Training loss: 1.8943849802017212
Validation loss: 2.0062377068304245

Epoch: 5| Step: 3
Training loss: 2.5473577976226807
Validation loss: 2.018451988056142

Epoch: 5| Step: 4
Training loss: 2.1390814781188965
Validation loss: 2.022133106826454

Epoch: 5| Step: 5
Training loss: 2.245069980621338
Validation loss: 2.0410036527982323

Epoch: 5| Step: 6
Training loss: 2.3917973041534424
Validation loss: 2.0609452724456787

Epoch: 5| Step: 7
Training loss: 2.8416688442230225
Validation loss: 2.1033567177352084

Epoch: 5| Step: 8
Training loss: 2.378657341003418
Validation loss: 2.140134249964068

Epoch: 5| Step: 9
Training loss: 1.3949556350708008
Validation loss: 2.154109069096145

Epoch: 5| Step: 10
Training loss: 2.4692330360412598
Validation loss: 2.1639130756419194

Epoch: 127| Step: 0
Training loss: 2.0619139671325684
Validation loss: 2.1236682335535684

Epoch: 5| Step: 1
Training loss: 2.2648983001708984
Validation loss: 2.0716527021059425

Epoch: 5| Step: 2
Training loss: 2.9026432037353516
Validation loss: 2.0355857777339157

Epoch: 5| Step: 3
Training loss: 2.1145858764648438
Validation loss: 2.01139659009954

Epoch: 5| Step: 4
Training loss: 2.559915065765381
Validation loss: 1.9949306877710486

Epoch: 5| Step: 5
Training loss: 1.7163728475570679
Validation loss: 2.003731027726204

Epoch: 5| Step: 6
Training loss: 1.966504454612732
Validation loss: 1.9899097129862795

Epoch: 5| Step: 7
Training loss: 1.817323088645935
Validation loss: 1.9852013126496346

Epoch: 5| Step: 8
Training loss: 2.156728982925415
Validation loss: 2.002764058369462

Epoch: 5| Step: 9
Training loss: 2.2735402584075928
Validation loss: 2.0102522014289774

Epoch: 5| Step: 10
Training loss: 2.5708556175231934
Validation loss: 2.0072738880752237

Epoch: 128| Step: 0
Training loss: 2.3613123893737793
Validation loss: 2.0357531668037496

Epoch: 5| Step: 1
Training loss: 2.899916887283325
Validation loss: 2.0728934836643997

Epoch: 5| Step: 2
Training loss: 2.227268695831299
Validation loss: 2.059969940493184

Epoch: 5| Step: 3
Training loss: 1.715762734413147
Validation loss: 2.0404106032463813

Epoch: 5| Step: 4
Training loss: 2.0263521671295166
Validation loss: 2.0103387794186993

Epoch: 5| Step: 5
Training loss: 2.010373830795288
Validation loss: 1.9793685456757903

Epoch: 5| Step: 6
Training loss: 2.0801539421081543
Validation loss: 1.9632523264936221

Epoch: 5| Step: 7
Training loss: 2.6830496788024902
Validation loss: 1.9587385295539774

Epoch: 5| Step: 8
Training loss: 2.3936846256256104
Validation loss: 1.9612121992213751

Epoch: 5| Step: 9
Training loss: 1.8490285873413086
Validation loss: 1.9574169522972518

Epoch: 5| Step: 10
Training loss: 2.3295607566833496
Validation loss: 1.9790287428004767

Epoch: 129| Step: 0
Training loss: 2.9862122535705566
Validation loss: 1.9918358069594189

Epoch: 5| Step: 1
Training loss: 1.5812212228775024
Validation loss: 2.0040647496459303

Epoch: 5| Step: 2
Training loss: 1.446169376373291
Validation loss: 2.0237466878788446

Epoch: 5| Step: 3
Training loss: 2.00341534614563
Validation loss: 2.0225167812839633

Epoch: 5| Step: 4
Training loss: 2.560945987701416
Validation loss: 2.0315321709520076

Epoch: 5| Step: 5
Training loss: 2.112459659576416
Validation loss: 2.038335100297005

Epoch: 5| Step: 6
Training loss: 2.279052495956421
Validation loss: 2.037479510871313

Epoch: 5| Step: 7
Training loss: 1.997380018234253
Validation loss: 2.054647558478899

Epoch: 5| Step: 8
Training loss: 1.7174793481826782
Validation loss: 2.0596314373836724

Epoch: 5| Step: 9
Training loss: 2.4370973110198975
Validation loss: 2.0697139386207826

Epoch: 5| Step: 10
Training loss: 2.9042577743530273
Validation loss: 2.0892852096147436

Epoch: 130| Step: 0
Training loss: 2.450615167617798
Validation loss: 2.070509046636602

Epoch: 5| Step: 1
Training loss: 2.4872488975524902
Validation loss: 2.0491221591990483

Epoch: 5| Step: 2
Training loss: 1.8936042785644531
Validation loss: 2.0381045290218887

Epoch: 5| Step: 3
Training loss: 2.3055076599121094
Validation loss: 2.048074032670708

Epoch: 5| Step: 4
Training loss: 2.9788291454315186
Validation loss: 2.0477112365025345

Epoch: 5| Step: 5
Training loss: 2.342158079147339
Validation loss: 2.0328638579255793

Epoch: 5| Step: 6
Training loss: 1.9564135074615479
Validation loss: 2.018775581031717

Epoch: 5| Step: 7
Training loss: 1.6663949489593506
Validation loss: 2.003419601789085

Epoch: 5| Step: 8
Training loss: 1.8750717639923096
Validation loss: 2.0047102615397465

Epoch: 5| Step: 9
Training loss: 2.3527767658233643
Validation loss: 2.0244608950871292

Epoch: 5| Step: 10
Training loss: 1.5749653577804565
Validation loss: 2.0745916020485664

Epoch: 131| Step: 0
Training loss: 2.34678316116333
Validation loss: 2.1237930943889003

Epoch: 5| Step: 1
Training loss: 1.6865562200546265
Validation loss: 2.1588901909448768

Epoch: 5| Step: 2
Training loss: 2.6197047233581543
Validation loss: 2.155503958784124

Epoch: 5| Step: 3
Training loss: 2.23547625541687
Validation loss: 2.142388894993772

Epoch: 5| Step: 4
Training loss: 2.5844528675079346
Validation loss: 2.103291239789737

Epoch: 5| Step: 5
Training loss: 1.9774885177612305
Validation loss: 2.074504047311762

Epoch: 5| Step: 6
Training loss: 2.3513126373291016
Validation loss: 2.040442366753855

Epoch: 5| Step: 7
Training loss: 2.222144603729248
Validation loss: 2.023117608921502

Epoch: 5| Step: 8
Training loss: 1.8215293884277344
Validation loss: 2.0178608279074393

Epoch: 5| Step: 9
Training loss: 1.8365005254745483
Validation loss: 2.0283325910568237

Epoch: 5| Step: 10
Training loss: 2.816657304763794
Validation loss: 2.0412169105263165

Epoch: 132| Step: 0
Training loss: 2.207303762435913
Validation loss: 2.065439754916776

Epoch: 5| Step: 1
Training loss: 1.7055097818374634
Validation loss: 2.099659481356221

Epoch: 5| Step: 2
Training loss: 2.255861520767212
Validation loss: 2.138713721306093

Epoch: 5| Step: 3
Training loss: 2.403536319732666
Validation loss: 2.1623942928929485

Epoch: 5| Step: 4
Training loss: 2.178523540496826
Validation loss: 2.189362483639871

Epoch: 5| Step: 5
Training loss: 2.342616319656372
Validation loss: 2.181512689077726

Epoch: 5| Step: 6
Training loss: 1.8948723077774048
Validation loss: 2.1585773691054313

Epoch: 5| Step: 7
Training loss: 1.9487113952636719
Validation loss: 2.1302757763093516

Epoch: 5| Step: 8
Training loss: 2.1633245944976807
Validation loss: 2.098515966887115

Epoch: 5| Step: 9
Training loss: 2.605008125305176
Validation loss: 2.077540554026122

Epoch: 5| Step: 10
Training loss: 2.400222063064575
Validation loss: 2.0855825331903275

Epoch: 133| Step: 0
Training loss: 1.9506326913833618
Validation loss: 2.06527663559042

Epoch: 5| Step: 1
Training loss: 2.465618133544922
Validation loss: 2.057320890888091

Epoch: 5| Step: 2
Training loss: 2.8288087844848633
Validation loss: 2.054473594952655

Epoch: 5| Step: 3
Training loss: 1.7792037725448608
Validation loss: 2.0483042168360885

Epoch: 5| Step: 4
Training loss: 2.1958985328674316
Validation loss: 2.0579379694436186

Epoch: 5| Step: 5
Training loss: 1.7311038970947266
Validation loss: 2.0560485009224183

Epoch: 5| Step: 6
Training loss: 2.223034620285034
Validation loss: 2.045344970559561

Epoch: 5| Step: 7
Training loss: 1.8844553232192993
Validation loss: 2.086193092407719

Epoch: 5| Step: 8
Training loss: 2.5093860626220703
Validation loss: 2.12930965423584

Epoch: 5| Step: 9
Training loss: 2.2564337253570557
Validation loss: 2.161544438331358

Epoch: 5| Step: 10
Training loss: 2.055166244506836
Validation loss: 2.162410340001506

Epoch: 134| Step: 0
Training loss: 2.509946584701538
Validation loss: 2.154652378892386

Epoch: 5| Step: 1
Training loss: 1.5882753133773804
Validation loss: 2.1410182445280013

Epoch: 5| Step: 2
Training loss: 1.8427261114120483
Validation loss: 2.106147994277298

Epoch: 5| Step: 3
Training loss: 2.3780574798583984
Validation loss: 2.0855723273369575

Epoch: 5| Step: 4
Training loss: 1.9142338037490845
Validation loss: 2.046429717412559

Epoch: 5| Step: 5
Training loss: 2.356843948364258
Validation loss: 2.0419806280443744

Epoch: 5| Step: 6
Training loss: 1.9398189783096313
Validation loss: 2.0370870008263537

Epoch: 5| Step: 7
Training loss: 2.769810199737549
Validation loss: 2.0040004996843237

Epoch: 5| Step: 8
Training loss: 1.6597106456756592
Validation loss: 2.0147570076809136

Epoch: 5| Step: 9
Training loss: 2.8407673835754395
Validation loss: 2.0320929288864136

Epoch: 5| Step: 10
Training loss: 2.222860097885132
Validation loss: 2.049787800799134

Epoch: 135| Step: 0
Training loss: 2.2925477027893066
Validation loss: 2.0613386887376026

Epoch: 5| Step: 1
Training loss: 2.2088494300842285
Validation loss: 2.0687310772557415

Epoch: 5| Step: 2
Training loss: 1.9187361001968384
Validation loss: 2.095532689043271

Epoch: 5| Step: 3
Training loss: 2.166757583618164
Validation loss: 2.1108157186097998

Epoch: 5| Step: 4
Training loss: 2.398677349090576
Validation loss: 2.127293158602971

Epoch: 5| Step: 5
Training loss: 2.0985827445983887
Validation loss: 2.148221751695038

Epoch: 5| Step: 6
Training loss: 2.083916187286377
Validation loss: 2.1445203596545803

Epoch: 5| Step: 7
Training loss: 1.773432970046997
Validation loss: 2.1275715904851116

Epoch: 5| Step: 8
Training loss: 1.9175517559051514
Validation loss: 2.1035624652780514

Epoch: 5| Step: 9
Training loss: 2.152468204498291
Validation loss: 2.0672538793215187

Epoch: 5| Step: 10
Training loss: 2.5694217681884766
Validation loss: 2.0499708575587117

Epoch: 136| Step: 0
Training loss: 1.9392166137695312
Validation loss: 2.0323129366802912

Epoch: 5| Step: 1
Training loss: 2.5926175117492676
Validation loss: 2.0288680548309

Epoch: 5| Step: 2
Training loss: 1.9330320358276367
Validation loss: 2.010777167094651

Epoch: 5| Step: 3
Training loss: 2.19537615776062
Validation loss: 1.9993779031179284

Epoch: 5| Step: 4
Training loss: 1.877915382385254
Validation loss: 2.0130009061546734

Epoch: 5| Step: 5
Training loss: 2.4611775875091553
Validation loss: 2.0242407527021182

Epoch: 5| Step: 6
Training loss: 1.699376106262207
Validation loss: 2.0501314798990884

Epoch: 5| Step: 7
Training loss: 1.6785986423492432
Validation loss: 2.072931666528025

Epoch: 5| Step: 8
Training loss: 2.7983222007751465
Validation loss: 2.076781572834138

Epoch: 5| Step: 9
Training loss: 1.6859333515167236
Validation loss: 2.0685781432736303

Epoch: 5| Step: 10
Training loss: 2.5521788597106934
Validation loss: 2.0753712115749234

Epoch: 137| Step: 0
Training loss: 1.826342225074768
Validation loss: 2.0696699747475247

Epoch: 5| Step: 1
Training loss: 2.045163631439209
Validation loss: 2.0550367947547667

Epoch: 5| Step: 2
Training loss: 2.320765256881714
Validation loss: 2.054886425695112

Epoch: 5| Step: 3
Training loss: 2.4961349964141846
Validation loss: 2.050326557569606

Epoch: 5| Step: 4
Training loss: 1.8646070957183838
Validation loss: 2.0267062007739978

Epoch: 5| Step: 5
Training loss: 1.9615647792816162
Validation loss: 2.028996565008676

Epoch: 5| Step: 6
Training loss: 1.9506094455718994
Validation loss: 2.0449067008110786

Epoch: 5| Step: 7
Training loss: 2.1949234008789062
Validation loss: 2.054766312722237

Epoch: 5| Step: 8
Training loss: 2.02602219581604
Validation loss: 2.0675360156643774

Epoch: 5| Step: 9
Training loss: 2.1473934650421143
Validation loss: 2.0725631367775703

Epoch: 5| Step: 10
Training loss: 2.2727184295654297
Validation loss: 2.088696540042918

Epoch: 138| Step: 0
Training loss: 2.102600336074829
Validation loss: 2.11502117623565

Epoch: 5| Step: 1
Training loss: 2.480867862701416
Validation loss: 2.1335933618648077

Epoch: 5| Step: 2
Training loss: 2.219332218170166
Validation loss: 2.1448045546008694

Epoch: 5| Step: 3
Training loss: 2.4345078468322754
Validation loss: 2.138674830877653

Epoch: 5| Step: 4
Training loss: 1.6656078100204468
Validation loss: 2.103215253481301

Epoch: 5| Step: 5
Training loss: 2.4895284175872803
Validation loss: 2.086406009171599

Epoch: 5| Step: 6
Training loss: 1.7064599990844727
Validation loss: 2.074448372728081

Epoch: 5| Step: 7
Training loss: 2.0984976291656494
Validation loss: 2.0617199918275237

Epoch: 5| Step: 8
Training loss: 1.8049097061157227
Validation loss: 2.0664536594062723

Epoch: 5| Step: 9
Training loss: 2.1579222679138184
Validation loss: 2.0761024926298406

Epoch: 5| Step: 10
Training loss: 1.776354432106018
Validation loss: 2.07989969945723

Epoch: 139| Step: 0
Training loss: 1.9959224462509155
Validation loss: 2.075894337828441

Epoch: 5| Step: 1
Training loss: 1.8515526056289673
Validation loss: 2.0832233787864767

Epoch: 5| Step: 2
Training loss: 2.1627655029296875
Validation loss: 2.0702158097297914

Epoch: 5| Step: 3
Training loss: 2.0510201454162598
Validation loss: 2.0477463686338035

Epoch: 5| Step: 4
Training loss: 2.2297630310058594
Validation loss: 2.030828497743094

Epoch: 5| Step: 5
Training loss: 1.803544282913208
Validation loss: 2.015833839293449

Epoch: 5| Step: 6
Training loss: 2.738781452178955
Validation loss: 2.0104777838594172

Epoch: 5| Step: 7
Training loss: 2.3152658939361572
Validation loss: 2.028503788414822

Epoch: 5| Step: 8
Training loss: 2.4177920818328857
Validation loss: 2.0510347145859913

Epoch: 5| Step: 9
Training loss: 1.582578182220459
Validation loss: 2.0838165129384687

Epoch: 5| Step: 10
Training loss: 1.9889312982559204
Validation loss: 2.113351821899414

Epoch: 140| Step: 0
Training loss: 2.547179698944092
Validation loss: 2.1114873809199177

Epoch: 5| Step: 1
Training loss: 1.9066569805145264
Validation loss: 2.107997348231654

Epoch: 5| Step: 2
Training loss: 1.586661696434021
Validation loss: 2.09128023347547

Epoch: 5| Step: 3
Training loss: 2.386709690093994
Validation loss: 2.076298559865644

Epoch: 5| Step: 4
Training loss: 1.1324306726455688
Validation loss: 2.0809592072681715

Epoch: 5| Step: 5
Training loss: 1.7169749736785889
Validation loss: 2.085995081932314

Epoch: 5| Step: 6
Training loss: 1.5937281847000122
Validation loss: 2.09464515665526

Epoch: 5| Step: 7
Training loss: 2.6615347862243652
Validation loss: 2.080860750649565

Epoch: 5| Step: 8
Training loss: 2.512411594390869
Validation loss: 2.0889381413818686

Epoch: 5| Step: 9
Training loss: 2.3933892250061035
Validation loss: 2.082147200902303

Epoch: 5| Step: 10
Training loss: 2.3408493995666504
Validation loss: 2.0836131816269248

Epoch: 141| Step: 0
Training loss: 2.006483793258667
Validation loss: 2.0997418921480895

Epoch: 5| Step: 1
Training loss: 2.0063223838806152
Validation loss: 2.115020312288756

Epoch: 5| Step: 2
Training loss: 2.457507371902466
Validation loss: 2.094074131340109

Epoch: 5| Step: 3
Training loss: 2.029419422149658
Validation loss: 2.088428420405234

Epoch: 5| Step: 4
Training loss: 2.49175763130188
Validation loss: 2.0835582146080593

Epoch: 5| Step: 5
Training loss: 2.3432345390319824
Validation loss: 2.0870772010536602

Epoch: 5| Step: 6
Training loss: 1.632926344871521
Validation loss: 2.0855891063649166

Epoch: 5| Step: 7
Training loss: 1.8348348140716553
Validation loss: 2.1060356081172986

Epoch: 5| Step: 8
Training loss: 2.025578022003174
Validation loss: 2.1173766043878373

Epoch: 5| Step: 9
Training loss: 2.0961127281188965
Validation loss: 2.117349842543243

Epoch: 5| Step: 10
Training loss: 1.9385730028152466
Validation loss: 2.1257151711371636

Epoch: 142| Step: 0
Training loss: 2.5313029289245605
Validation loss: 2.1235101915174917

Epoch: 5| Step: 1
Training loss: 1.8827991485595703
Validation loss: 2.109445466790148

Epoch: 5| Step: 2
Training loss: 2.156707763671875
Validation loss: 2.1001887680381857

Epoch: 5| Step: 3
Training loss: 1.779417634010315
Validation loss: 2.07633206664875

Epoch: 5| Step: 4
Training loss: 2.824659824371338
Validation loss: 2.0716258120793167

Epoch: 5| Step: 5
Training loss: 2.029658555984497
Validation loss: 2.0781362210550616

Epoch: 5| Step: 6
Training loss: 2.2211925983428955
Validation loss: 2.0961470732124905

Epoch: 5| Step: 7
Training loss: 1.7288055419921875
Validation loss: 2.085877098062987

Epoch: 5| Step: 8
Training loss: 1.8367925882339478
Validation loss: 2.0943635509860132

Epoch: 5| Step: 9
Training loss: 2.005526065826416
Validation loss: 2.0930993685158352

Epoch: 5| Step: 10
Training loss: 1.4349361658096313
Validation loss: 2.082255394228043

Epoch: 143| Step: 0
Training loss: 2.049119472503662
Validation loss: 2.088595580029231

Epoch: 5| Step: 1
Training loss: 1.6489670276641846
Validation loss: 2.077564372811266

Epoch: 5| Step: 2
Training loss: 1.6069062948226929
Validation loss: 2.077793462302095

Epoch: 5| Step: 3
Training loss: 2.338468074798584
Validation loss: 2.0857556635333645

Epoch: 5| Step: 4
Training loss: 2.094569683074951
Validation loss: 2.085415631212214

Epoch: 5| Step: 5
Training loss: 1.852290391921997
Validation loss: 2.0944926559284167

Epoch: 5| Step: 6
Training loss: 2.374760150909424
Validation loss: 2.0913194238498645

Epoch: 5| Step: 7
Training loss: 2.2592813968658447
Validation loss: 2.0789077769043627

Epoch: 5| Step: 8
Training loss: 1.3337504863739014
Validation loss: 2.0686701689997027

Epoch: 5| Step: 9
Training loss: 2.050920248031616
Validation loss: 2.087865288539599

Epoch: 5| Step: 10
Training loss: 2.764619827270508
Validation loss: 2.0960211189844276

Epoch: 144| Step: 0
Training loss: 2.00862979888916
Validation loss: 2.1006383895874023

Epoch: 5| Step: 1
Training loss: 2.3207504749298096
Validation loss: 2.1174947702756493

Epoch: 5| Step: 2
Training loss: 1.9847412109375
Validation loss: 2.116987605248728

Epoch: 5| Step: 3
Training loss: 2.070963144302368
Validation loss: 2.1345234506873676

Epoch: 5| Step: 4
Training loss: 1.8165967464447021
Validation loss: 2.1280616842290407

Epoch: 5| Step: 5
Training loss: 1.0989406108856201
Validation loss: 2.1227856451465237

Epoch: 5| Step: 6
Training loss: 2.441835403442383
Validation loss: 2.116890814996535

Epoch: 5| Step: 7
Training loss: 1.8824717998504639
Validation loss: 2.110662160381194

Epoch: 5| Step: 8
Training loss: 1.9995996952056885
Validation loss: 2.123959843830396

Epoch: 5| Step: 9
Training loss: 2.3916091918945312
Validation loss: 2.1374561684105986

Epoch: 5| Step: 10
Training loss: 2.475520133972168
Validation loss: 2.1298151067508164

Epoch: 145| Step: 0
Training loss: 1.6331241130828857
Validation loss: 2.1209249355459727

Epoch: 5| Step: 1
Training loss: 2.1394925117492676
Validation loss: 2.099773014745405

Epoch: 5| Step: 2
Training loss: 1.9971870183944702
Validation loss: 2.0907532015154437

Epoch: 5| Step: 3
Training loss: 1.9651882648468018
Validation loss: 2.094799150702774

Epoch: 5| Step: 4
Training loss: 1.7675793170928955
Validation loss: 2.091286822031903

Epoch: 5| Step: 5
Training loss: 2.1628222465515137
Validation loss: 2.0784698199200373

Epoch: 5| Step: 6
Training loss: 1.7524738311767578
Validation loss: 2.0705388489589898

Epoch: 5| Step: 7
Training loss: 2.025435209274292
Validation loss: 2.0679053965435235

Epoch: 5| Step: 8
Training loss: 2.537216901779175
Validation loss: 2.058711609532756

Epoch: 5| Step: 9
Training loss: 1.9030046463012695
Validation loss: 2.042680222501037

Epoch: 5| Step: 10
Training loss: 2.18693208694458
Validation loss: 2.0591344602646364

Epoch: 146| Step: 0
Training loss: 1.7686494588851929
Validation loss: 2.0581370810026764

Epoch: 5| Step: 1
Training loss: 2.057002305984497
Validation loss: 2.0737607376549834

Epoch: 5| Step: 2
Training loss: 1.8133926391601562
Validation loss: 2.0802241115159887

Epoch: 5| Step: 3
Training loss: 2.0960075855255127
Validation loss: 2.123784657447569

Epoch: 5| Step: 4
Training loss: 2.027824878692627
Validation loss: 2.157500987411827

Epoch: 5| Step: 5
Training loss: 2.9083640575408936
Validation loss: 2.139865718862062

Epoch: 5| Step: 6
Training loss: 1.5634231567382812
Validation loss: 2.0894896035553305

Epoch: 5| Step: 7
Training loss: 2.1778550148010254
Validation loss: 2.077176599092381

Epoch: 5| Step: 8
Training loss: 1.8643357753753662
Validation loss: 2.066095826446369

Epoch: 5| Step: 9
Training loss: 2.036202907562256
Validation loss: 2.064643595808296

Epoch: 5| Step: 10
Training loss: 2.0610108375549316
Validation loss: 2.06721213171559

Epoch: 147| Step: 0
Training loss: 2.1536591053009033
Validation loss: 2.067010377043037

Epoch: 5| Step: 1
Training loss: 1.6690466403961182
Validation loss: 2.074801432189121

Epoch: 5| Step: 2
Training loss: 2.0491700172424316
Validation loss: 2.0562290440323534

Epoch: 5| Step: 3
Training loss: 1.684647798538208
Validation loss: 2.0817708020569174

Epoch: 5| Step: 4
Training loss: 1.9606645107269287
Validation loss: 2.0860476122107556

Epoch: 5| Step: 5
Training loss: 2.5098280906677246
Validation loss: 2.090562064160583

Epoch: 5| Step: 6
Training loss: 1.2282401323318481
Validation loss: 2.0797580352393528

Epoch: 5| Step: 7
Training loss: 2.2022645473480225
Validation loss: 2.0778094876197075

Epoch: 5| Step: 8
Training loss: 1.8728153705596924
Validation loss: 2.0691171256444787

Epoch: 5| Step: 9
Training loss: 2.187629222869873
Validation loss: 2.065742015838623

Epoch: 5| Step: 10
Training loss: 2.701932668685913
Validation loss: 2.0560870221866074

Epoch: 148| Step: 0
Training loss: 1.8874006271362305
Validation loss: 2.061068514341949

Epoch: 5| Step: 1
Training loss: 2.098483085632324
Validation loss: 2.0792324337908017

Epoch: 5| Step: 2
Training loss: 1.2100332975387573
Validation loss: 2.0660881791063535

Epoch: 5| Step: 3
Training loss: 1.9378538131713867
Validation loss: 2.073960009441581

Epoch: 5| Step: 4
Training loss: 1.7834011316299438
Validation loss: 2.0829054514567056

Epoch: 5| Step: 5
Training loss: 2.264859437942505
Validation loss: 2.0776741607214815

Epoch: 5| Step: 6
Training loss: 1.7752113342285156
Validation loss: 2.084411790294032

Epoch: 5| Step: 7
Training loss: 1.7685892581939697
Validation loss: 2.084803201818979

Epoch: 5| Step: 8
Training loss: 1.5342755317687988
Validation loss: 2.0838119304308327

Epoch: 5| Step: 9
Training loss: 2.7266383171081543
Validation loss: 2.0764048560973136

Epoch: 5| Step: 10
Training loss: 3.008265972137451
Validation loss: 2.0715612621717554

Epoch: 149| Step: 0
Training loss: 2.1692023277282715
Validation loss: 2.076100699363216

Epoch: 5| Step: 1
Training loss: 2.119661808013916
Validation loss: 2.077459227654242

Epoch: 5| Step: 2
Training loss: 2.2976999282836914
Validation loss: 2.0939837886441137

Epoch: 5| Step: 3
Training loss: 2.5335612297058105
Validation loss: 2.0940597518797843

Epoch: 5| Step: 4
Training loss: 1.9427655935287476
Validation loss: 2.0955566334468063

Epoch: 5| Step: 5
Training loss: 1.998836874961853
Validation loss: 2.09397247657981

Epoch: 5| Step: 6
Training loss: 1.480800747871399
Validation loss: 2.0790012728783394

Epoch: 5| Step: 7
Training loss: 1.6506856679916382
Validation loss: 2.0767827700543147

Epoch: 5| Step: 8
Training loss: 1.9360936880111694
Validation loss: 2.057982078162573

Epoch: 5| Step: 9
Training loss: 1.6319618225097656
Validation loss: 2.0625346142758607

Epoch: 5| Step: 10
Training loss: 1.791648268699646
Validation loss: 2.0726155542558238

Epoch: 150| Step: 0
Training loss: 2.4780800342559814
Validation loss: 2.059724910284883

Epoch: 5| Step: 1
Training loss: 1.9679372310638428
Validation loss: 2.0579571595755954

Epoch: 5| Step: 2
Training loss: 2.3153960704803467
Validation loss: 2.0651132906636884

Epoch: 5| Step: 3
Training loss: 2.239325523376465
Validation loss: 2.0584174125425276

Epoch: 5| Step: 4
Training loss: 2.1725189685821533
Validation loss: 2.0680047568454536

Epoch: 5| Step: 5
Training loss: 1.7081283330917358
Validation loss: 2.0769087755551903

Epoch: 5| Step: 6
Training loss: 1.9175784587860107
Validation loss: 2.1069991447592296

Epoch: 5| Step: 7
Training loss: 2.1080541610717773
Validation loss: 2.123575868145112

Epoch: 5| Step: 8
Training loss: 1.5321282148361206
Validation loss: 2.135338043653837

Epoch: 5| Step: 9
Training loss: 1.647580862045288
Validation loss: 2.142124499044111

Epoch: 5| Step: 10
Training loss: 1.2757726907730103
Validation loss: 2.132945619603639

Epoch: 151| Step: 0
Training loss: 1.6570707559585571
Validation loss: 2.1459885515192503

Epoch: 5| Step: 1
Training loss: 1.4112188816070557
Validation loss: 2.131660689589798

Epoch: 5| Step: 2
Training loss: 2.389045476913452
Validation loss: 2.109760602315267

Epoch: 5| Step: 3
Training loss: 1.607245683670044
Validation loss: 2.0969146887461343

Epoch: 5| Step: 4
Training loss: 2.5889487266540527
Validation loss: 2.0896115790131273

Epoch: 5| Step: 5
Training loss: 2.133774995803833
Validation loss: 2.0921354960369807

Epoch: 5| Step: 6
Training loss: 2.8382763862609863
Validation loss: 2.0823834121868177

Epoch: 5| Step: 7
Training loss: 1.756818413734436
Validation loss: 2.0569181724261214

Epoch: 5| Step: 8
Training loss: 1.8192598819732666
Validation loss: 2.0690725682884135

Epoch: 5| Step: 9
Training loss: 1.598046064376831
Validation loss: 2.0775962414280063

Epoch: 5| Step: 10
Training loss: 1.9635000228881836
Validation loss: 2.0825486208802912

Epoch: 152| Step: 0
Training loss: 1.6871951818466187
Validation loss: 2.1006510847358295

Epoch: 5| Step: 1
Training loss: 2.3043949604034424
Validation loss: 2.093477767000916

Epoch: 5| Step: 2
Training loss: 2.0944151878356934
Validation loss: 2.0911379796202465

Epoch: 5| Step: 3
Training loss: 2.1787657737731934
Validation loss: 2.0829545887567664

Epoch: 5| Step: 4
Training loss: 2.15366530418396
Validation loss: 2.071342647716563

Epoch: 5| Step: 5
Training loss: 2.1008236408233643
Validation loss: 2.0603709887432795

Epoch: 5| Step: 6
Training loss: 1.8474323749542236
Validation loss: 2.0653246269431165

Epoch: 5| Step: 7
Training loss: 1.677412986755371
Validation loss: 2.079428898390903

Epoch: 5| Step: 8
Training loss: 1.9079030752182007
Validation loss: 2.088286945896764

Epoch: 5| Step: 9
Training loss: 1.9366258382797241
Validation loss: 2.100023409371735

Epoch: 5| Step: 10
Training loss: 1.2937853336334229
Validation loss: 2.1089033362685994

Epoch: 153| Step: 0
Training loss: 1.6631014347076416
Validation loss: 2.1011273860931396

Epoch: 5| Step: 1
Training loss: 1.5281288623809814
Validation loss: 2.101958438914309

Epoch: 5| Step: 2
Training loss: 1.3853743076324463
Validation loss: 2.092091985928115

Epoch: 5| Step: 3
Training loss: 1.7039598226547241
Validation loss: 2.0929630725614485

Epoch: 5| Step: 4
Training loss: 2.157991409301758
Validation loss: 2.085671632520614

Epoch: 5| Step: 5
Training loss: 3.0198116302490234
Validation loss: 2.0802478149373043

Epoch: 5| Step: 6
Training loss: 2.4303619861602783
Validation loss: 2.0915874588874077

Epoch: 5| Step: 7
Training loss: 1.6463607549667358
Validation loss: 2.080024678220031

Epoch: 5| Step: 8
Training loss: 2.914207935333252
Validation loss: 2.0953302716696136

Epoch: 5| Step: 9
Training loss: 1.7122730016708374
Validation loss: 2.076967618798697

Epoch: 5| Step: 10
Training loss: 1.0293978452682495
Validation loss: 2.056947983721251

Epoch: 154| Step: 0
Training loss: 2.275388240814209
Validation loss: 2.0341338137144684

Epoch: 5| Step: 1
Training loss: 1.9963748455047607
Validation loss: 2.03141983350118

Epoch: 5| Step: 2
Training loss: 2.6988813877105713
Validation loss: 2.028374274571737

Epoch: 5| Step: 3
Training loss: 1.3996391296386719
Validation loss: 2.0303504133737214

Epoch: 5| Step: 4
Training loss: 1.5438783168792725
Validation loss: 2.02090548956266

Epoch: 5| Step: 5
Training loss: 1.5488884449005127
Validation loss: 2.0225516570511686

Epoch: 5| Step: 6
Training loss: 1.0830013751983643
Validation loss: 2.025470831060922

Epoch: 5| Step: 7
Training loss: 2.3889353275299072
Validation loss: 2.0439210143140567

Epoch: 5| Step: 8
Training loss: 2.101759672164917
Validation loss: 2.059638225904075

Epoch: 5| Step: 9
Training loss: 1.7344080209732056
Validation loss: 2.075267753293437

Epoch: 5| Step: 10
Training loss: 2.4553143978118896
Validation loss: 2.095054300882483

Epoch: 155| Step: 0
Training loss: 1.4817280769348145
Validation loss: 2.0718510804637784

Epoch: 5| Step: 1
Training loss: 1.7538855075836182
Validation loss: 2.05899759902749

Epoch: 5| Step: 2
Training loss: 1.7522990703582764
Validation loss: 2.056455323773046

Epoch: 5| Step: 3
Training loss: 1.7260710000991821
Validation loss: 2.076126011469031

Epoch: 5| Step: 4
Training loss: 1.702275276184082
Validation loss: 2.098875614904588

Epoch: 5| Step: 5
Training loss: 1.8205124139785767
Validation loss: 2.09952978421283

Epoch: 5| Step: 6
Training loss: 2.1581337451934814
Validation loss: 2.104757665306009

Epoch: 5| Step: 7
Training loss: 2.1646201610565186
Validation loss: 2.117640026154057

Epoch: 5| Step: 8
Training loss: 2.048719644546509
Validation loss: 2.1310719879724647

Epoch: 5| Step: 9
Training loss: 2.307704210281372
Validation loss: 2.115914278132941

Epoch: 5| Step: 10
Training loss: 2.6559841632843018
Validation loss: 2.1263494953032462

Epoch: 156| Step: 0
Training loss: 2.223747968673706
Validation loss: 2.1561411478186168

Epoch: 5| Step: 1
Training loss: 1.6541001796722412
Validation loss: 2.149293811090531

Epoch: 5| Step: 2
Training loss: 1.5468471050262451
Validation loss: 2.134404933580788

Epoch: 5| Step: 3
Training loss: 1.6432645320892334
Validation loss: 2.1275569802971295

Epoch: 5| Step: 4
Training loss: 1.4873422384262085
Validation loss: 2.117257801435327

Epoch: 5| Step: 5
Training loss: 2.360947847366333
Validation loss: 2.0853765831198743

Epoch: 5| Step: 6
Training loss: 2.0797722339630127
Validation loss: 2.0670009095181703

Epoch: 5| Step: 7
Training loss: 1.9474143981933594
Validation loss: 2.061411606368198

Epoch: 5| Step: 8
Training loss: 2.8185129165649414
Validation loss: 2.0497366459138933

Epoch: 5| Step: 9
Training loss: 1.8481357097625732
Validation loss: 2.07083878209514

Epoch: 5| Step: 10
Training loss: 1.6176133155822754
Validation loss: 2.0599441861593597

Epoch: 157| Step: 0
Training loss: 2.3811497688293457
Validation loss: 2.0492533509449293

Epoch: 5| Step: 1
Training loss: 2.0531504154205322
Validation loss: 2.0662448816401984

Epoch: 5| Step: 2
Training loss: 2.1998848915100098
Validation loss: 2.067760007355803

Epoch: 5| Step: 3
Training loss: 1.6443723440170288
Validation loss: 2.066666918416177

Epoch: 5| Step: 4
Training loss: 1.8168079853057861
Validation loss: 2.07629289678348

Epoch: 5| Step: 5
Training loss: 2.079983711242676
Validation loss: 2.0749849632222164

Epoch: 5| Step: 6
Training loss: 2.078495502471924
Validation loss: 2.0931472265592186

Epoch: 5| Step: 7
Training loss: 2.0238354206085205
Validation loss: 2.071428386113977

Epoch: 5| Step: 8
Training loss: 1.7950751781463623
Validation loss: 2.062743022877683

Epoch: 5| Step: 9
Training loss: 1.6348152160644531
Validation loss: 2.0715375369594944

Epoch: 5| Step: 10
Training loss: 1.555420160293579
Validation loss: 2.0816220544999644

Epoch: 158| Step: 0
Training loss: 1.6421916484832764
Validation loss: 2.0824609187341507

Epoch: 5| Step: 1
Training loss: 1.3439546823501587
Validation loss: 2.085360896202826

Epoch: 5| Step: 2
Training loss: 1.5926107168197632
Validation loss: 2.102565021925075

Epoch: 5| Step: 3
Training loss: 1.5705206394195557
Validation loss: 2.1361017509173323

Epoch: 5| Step: 4
Training loss: 2.357985496520996
Validation loss: 2.126375990529214

Epoch: 5| Step: 5
Training loss: 2.490185260772705
Validation loss: 2.1391602549501645

Epoch: 5| Step: 6
Training loss: 1.8858954906463623
Validation loss: 2.15136379836708

Epoch: 5| Step: 7
Training loss: 1.8400367498397827
Validation loss: 2.155749882421186

Epoch: 5| Step: 8
Training loss: 1.8253059387207031
Validation loss: 2.1574730488561813

Epoch: 5| Step: 9
Training loss: 2.3491580486297607
Validation loss: 2.165469100398402

Epoch: 5| Step: 10
Training loss: 2.504596471786499
Validation loss: 2.168580027036769

Epoch: 159| Step: 0
Training loss: 1.4167654514312744
Validation loss: 2.1277930646814327

Epoch: 5| Step: 1
Training loss: 1.49325430393219
Validation loss: 2.1379005062964653

Epoch: 5| Step: 2
Training loss: 1.8284244537353516
Validation loss: 2.1187237206325737

Epoch: 5| Step: 3
Training loss: 1.8241010904312134
Validation loss: 2.1176397672263523

Epoch: 5| Step: 4
Training loss: 2.2586827278137207
Validation loss: 2.113944028013496

Epoch: 5| Step: 5
Training loss: 2.296501398086548
Validation loss: 2.104644203698763

Epoch: 5| Step: 6
Training loss: 2.084411382675171
Validation loss: 2.0995630013045443

Epoch: 5| Step: 7
Training loss: 2.1678338050842285
Validation loss: 2.1027995027521604

Epoch: 5| Step: 8
Training loss: 2.1479897499084473
Validation loss: 2.093539914777202

Epoch: 5| Step: 9
Training loss: 1.5268819332122803
Validation loss: 2.082683540159656

Epoch: 5| Step: 10
Training loss: 2.03562068939209
Validation loss: 2.0843309330683883

Epoch: 160| Step: 0
Training loss: 2.345670700073242
Validation loss: 2.0684083059269893

Epoch: 5| Step: 1
Training loss: 2.034358501434326
Validation loss: 2.077860155413228

Epoch: 5| Step: 2
Training loss: 1.367305040359497
Validation loss: 2.0909626342917003

Epoch: 5| Step: 3
Training loss: 2.43638277053833
Validation loss: 2.101052804659772

Epoch: 5| Step: 4
Training loss: 2.11545991897583
Validation loss: 2.0479924576256865

Epoch: 5| Step: 5
Training loss: 1.199143648147583
Validation loss: 2.0335285253422235

Epoch: 5| Step: 6
Training loss: 2.088818311691284
Validation loss: 2.0391015275832145

Epoch: 5| Step: 7
Training loss: 1.9280961751937866
Validation loss: 2.0373445287827523

Epoch: 5| Step: 8
Training loss: 1.950659155845642
Validation loss: 2.038101142452609

Epoch: 5| Step: 9
Training loss: 1.7455180883407593
Validation loss: 2.0464990241553194

Epoch: 5| Step: 10
Training loss: 1.995978832244873
Validation loss: 2.0439538827506443

Epoch: 161| Step: 0
Training loss: 1.4119070768356323
Validation loss: 2.0495308137709096

Epoch: 5| Step: 1
Training loss: 1.9357755184173584
Validation loss: 2.0526450782693844

Epoch: 5| Step: 2
Training loss: 1.9141258001327515
Validation loss: 2.0698184108221405

Epoch: 5| Step: 3
Training loss: 2.0120277404785156
Validation loss: 2.068986946536649

Epoch: 5| Step: 4
Training loss: 1.9372873306274414
Validation loss: 2.096527832810597

Epoch: 5| Step: 5
Training loss: 2.516272783279419
Validation loss: 2.0930407380545013

Epoch: 5| Step: 6
Training loss: 2.024624824523926
Validation loss: 2.0938256402169504

Epoch: 5| Step: 7
Training loss: 1.4468209743499756
Validation loss: 2.1119954996211554

Epoch: 5| Step: 8
Training loss: 1.4905760288238525
Validation loss: 2.112309220016644

Epoch: 5| Step: 9
Training loss: 1.6356052160263062
Validation loss: 2.1176847629649664

Epoch: 5| Step: 10
Training loss: 2.4218173027038574
Validation loss: 2.122870681106403

Epoch: 162| Step: 0
Training loss: 1.9006292819976807
Validation loss: 2.1137245291022846

Epoch: 5| Step: 1
Training loss: 1.7574107646942139
Validation loss: 2.0990218065118276

Epoch: 5| Step: 2
Training loss: 2.10961651802063
Validation loss: 2.1022733026935208

Epoch: 5| Step: 3
Training loss: 1.9657115936279297
Validation loss: 2.1017427316275974

Epoch: 5| Step: 4
Training loss: 2.148320436477661
Validation loss: 2.1137288206367084

Epoch: 5| Step: 5
Training loss: 1.3810813426971436
Validation loss: 2.0856424787993073

Epoch: 5| Step: 6
Training loss: 1.0548121929168701
Validation loss: 2.08713803240048

Epoch: 5| Step: 7
Training loss: 2.2258684635162354
Validation loss: 2.081357986696305

Epoch: 5| Step: 8
Training loss: 2.0859851837158203
Validation loss: 2.089321400529595

Epoch: 5| Step: 9
Training loss: 1.9209659099578857
Validation loss: 2.0961473859766477

Epoch: 5| Step: 10
Training loss: 2.301558017730713
Validation loss: 2.100551025841826

Epoch: 163| Step: 0
Training loss: 1.465174913406372
Validation loss: 2.080784856632192

Epoch: 5| Step: 1
Training loss: 1.7581802606582642
Validation loss: 2.059714847995389

Epoch: 5| Step: 2
Training loss: 2.0187785625457764
Validation loss: 2.066211305638795

Epoch: 5| Step: 3
Training loss: 1.7931312322616577
Validation loss: 2.075634885859746

Epoch: 5| Step: 4
Training loss: 1.6766914129257202
Validation loss: 2.0785761546063166

Epoch: 5| Step: 5
Training loss: 1.5310555696487427
Validation loss: 2.1042873167222544

Epoch: 5| Step: 6
Training loss: 1.9690558910369873
Validation loss: 2.1033273666135726

Epoch: 5| Step: 7
Training loss: 2.1701207160949707
Validation loss: 2.1199075124597035

Epoch: 5| Step: 8
Training loss: 2.0211310386657715
Validation loss: 2.097778066512077

Epoch: 5| Step: 9
Training loss: 2.043194532394409
Validation loss: 2.100405263644393

Epoch: 5| Step: 10
Training loss: 2.0654664039611816
Validation loss: 2.0913127955570014

Epoch: 164| Step: 0
Training loss: 1.4817851781845093
Validation loss: 2.0900530943306546

Epoch: 5| Step: 1
Training loss: 1.9944469928741455
Validation loss: 2.0866833681701333

Epoch: 5| Step: 2
Training loss: 1.8167164325714111
Validation loss: 2.0854644121662265

Epoch: 5| Step: 3
Training loss: 2.3614964485168457
Validation loss: 2.0820270046111076

Epoch: 5| Step: 4
Training loss: 1.7321529388427734
Validation loss: 2.1031826080814486

Epoch: 5| Step: 5
Training loss: 1.880122423171997
Validation loss: 2.12231457361611

Epoch: 5| Step: 6
Training loss: 2.1624808311462402
Validation loss: 2.113167157737158

Epoch: 5| Step: 7
Training loss: 1.7107127904891968
Validation loss: 2.122137164556852

Epoch: 5| Step: 8
Training loss: 1.9756215810775757
Validation loss: 2.12257331801999

Epoch: 5| Step: 9
Training loss: 1.5441484451293945
Validation loss: 2.128272989744781

Epoch: 5| Step: 10
Training loss: 2.047816276550293
Validation loss: 2.1087349435334564

Epoch: 165| Step: 0
Training loss: 1.8863528966903687
Validation loss: 2.0614927532852336

Epoch: 5| Step: 1
Training loss: 1.8815075159072876
Validation loss: 2.0544260958189606

Epoch: 5| Step: 2
Training loss: 1.5031830072402954
Validation loss: 2.0562551201030774

Epoch: 5| Step: 3
Training loss: 2.1478750705718994
Validation loss: 2.0710379859452606

Epoch: 5| Step: 4
Training loss: 2.288674831390381
Validation loss: 2.0648025979277906

Epoch: 5| Step: 5
Training loss: 2.270232915878296
Validation loss: 2.0662457263597878

Epoch: 5| Step: 6
Training loss: 1.3962862491607666
Validation loss: 2.0687655005403744

Epoch: 5| Step: 7
Training loss: 1.684715986251831
Validation loss: 2.0773267733153475

Epoch: 5| Step: 8
Training loss: 1.6646995544433594
Validation loss: 2.0804039611611316

Epoch: 5| Step: 9
Training loss: 1.4590656757354736
Validation loss: 2.072267698985274

Epoch: 5| Step: 10
Training loss: 2.266356945037842
Validation loss: 2.0739817311686854

Epoch: 166| Step: 0
Training loss: 2.216092348098755
Validation loss: 2.0940291945652296

Epoch: 5| Step: 1
Training loss: 1.868060827255249
Validation loss: 2.11390959319248

Epoch: 5| Step: 2
Training loss: 1.3606889247894287
Validation loss: 2.1208180381405737

Epoch: 5| Step: 3
Training loss: 1.8993438482284546
Validation loss: 2.1150536434624785

Epoch: 5| Step: 4
Training loss: 1.7509477138519287
Validation loss: 2.097656067981515

Epoch: 5| Step: 5
Training loss: 1.985242486000061
Validation loss: 2.11167473177756

Epoch: 5| Step: 6
Training loss: 1.4616857767105103
Validation loss: 2.0853583223076275

Epoch: 5| Step: 7
Training loss: 1.6734905242919922
Validation loss: 2.072884613467801

Epoch: 5| Step: 8
Training loss: 1.994336724281311
Validation loss: 2.0743350495574293

Epoch: 5| Step: 9
Training loss: 2.045491933822632
Validation loss: 2.0709183703186693

Epoch: 5| Step: 10
Training loss: 1.940051555633545
Validation loss: 2.049611960687945

Epoch: 167| Step: 0
Training loss: 1.9777851104736328
Validation loss: 2.072822091399982

Epoch: 5| Step: 1
Training loss: 1.815657377243042
Validation loss: 2.0667978755889402

Epoch: 5| Step: 2
Training loss: 1.7517894506454468
Validation loss: 2.0676046443241898

Epoch: 5| Step: 3
Training loss: 1.2831586599349976
Validation loss: 2.074708074651739

Epoch: 5| Step: 4
Training loss: 1.9995590448379517
Validation loss: 2.0588844386480187

Epoch: 5| Step: 5
Training loss: 1.9428256750106812
Validation loss: 2.0632166683032946

Epoch: 5| Step: 6
Training loss: 1.7258613109588623
Validation loss: 2.0711324022662256

Epoch: 5| Step: 7
Training loss: 1.8112125396728516
Validation loss: 2.0770747289862683

Epoch: 5| Step: 8
Training loss: 1.8823753595352173
Validation loss: 2.05246038334344

Epoch: 5| Step: 9
Training loss: 2.266859531402588
Validation loss: 2.069430205129808

Epoch: 5| Step: 10
Training loss: 1.4806057214736938
Validation loss: 2.0490416737012964

Epoch: 168| Step: 0
Training loss: 2.1298489570617676
Validation loss: 2.05336606630715

Epoch: 5| Step: 1
Training loss: 1.6146436929702759
Validation loss: 2.052732459960445

Epoch: 5| Step: 2
Training loss: 2.2544569969177246
Validation loss: 2.0569560117619012

Epoch: 5| Step: 3
Training loss: 1.4560350179672241
Validation loss: 2.0530102291414813

Epoch: 5| Step: 4
Training loss: 1.541877031326294
Validation loss: 2.0464406116034395

Epoch: 5| Step: 5
Training loss: 1.230454683303833
Validation loss: 2.047276718642122

Epoch: 5| Step: 6
Training loss: 2.2699780464172363
Validation loss: 2.0523419405824397

Epoch: 5| Step: 7
Training loss: 1.8871526718139648
Validation loss: 2.0744170732395624

Epoch: 5| Step: 8
Training loss: 2.3822124004364014
Validation loss: 2.0862443959841164

Epoch: 5| Step: 9
Training loss: 1.5710175037384033
Validation loss: 2.081154905339723

Epoch: 5| Step: 10
Training loss: 1.651845097541809
Validation loss: 2.0680576665427095

Epoch: 169| Step: 0
Training loss: 2.0861966609954834
Validation loss: 2.0620629915627102

Epoch: 5| Step: 1
Training loss: 1.8662309646606445
Validation loss: 2.0685572393478884

Epoch: 5| Step: 2
Training loss: 1.6563209295272827
Validation loss: 2.049542970554803

Epoch: 5| Step: 3
Training loss: 1.3424782752990723
Validation loss: 2.048331804172967

Epoch: 5| Step: 4
Training loss: 1.8271297216415405
Validation loss: 2.0477500884763655

Epoch: 5| Step: 5
Training loss: 1.6689558029174805
Validation loss: 2.064735269033781

Epoch: 5| Step: 6
Training loss: 1.9934179782867432
Validation loss: 2.086322433205061

Epoch: 5| Step: 7
Training loss: 1.8599374294281006
Validation loss: 2.0836016875441357

Epoch: 5| Step: 8
Training loss: 1.4059150218963623
Validation loss: 2.083522562057741

Epoch: 5| Step: 9
Training loss: 2.1630306243896484
Validation loss: 2.0611044437654558

Epoch: 5| Step: 10
Training loss: 2.0143585205078125
Validation loss: 2.0616151619982976

Epoch: 170| Step: 0
Training loss: 1.5438898801803589
Validation loss: 2.038232239343787

Epoch: 5| Step: 1
Training loss: 2.3207199573516846
Validation loss: 2.017122058458226

Epoch: 5| Step: 2
Training loss: 1.7264608144760132
Validation loss: 2.0200431282802294

Epoch: 5| Step: 3
Training loss: 1.8649084568023682
Validation loss: 2.0137836907499578

Epoch: 5| Step: 4
Training loss: 1.7823680639266968
Validation loss: 2.0379076170664963

Epoch: 5| Step: 5
Training loss: 1.9305654764175415
Validation loss: 2.0576577737767208

Epoch: 5| Step: 6
Training loss: 1.848624587059021
Validation loss: 2.0798161875817085

Epoch: 5| Step: 7
Training loss: 2.250016689300537
Validation loss: 2.109438369351049

Epoch: 5| Step: 8
Training loss: 1.277417540550232
Validation loss: 2.158793282765214

Epoch: 5| Step: 9
Training loss: 2.2355384826660156
Validation loss: 2.14182682447536

Epoch: 5| Step: 10
Training loss: 1.529579758644104
Validation loss: 2.1066482874654953

Epoch: 171| Step: 0
Training loss: 2.115259885787964
Validation loss: 2.075675665691335

Epoch: 5| Step: 1
Training loss: 1.565916895866394
Validation loss: 2.044475163182905

Epoch: 5| Step: 2
Training loss: 1.7741615772247314
Validation loss: 2.03368825938112

Epoch: 5| Step: 3
Training loss: 2.1282477378845215
Validation loss: 2.0199799640204317

Epoch: 5| Step: 4
Training loss: 1.5992228984832764
Validation loss: 2.0199674508904897

Epoch: 5| Step: 5
Training loss: 2.221383810043335
Validation loss: 2.0143103497002715

Epoch: 5| Step: 6
Training loss: 1.3238084316253662
Validation loss: 2.01745242457236

Epoch: 5| Step: 7
Training loss: 1.3565220832824707
Validation loss: 2.0092298817890946

Epoch: 5| Step: 8
Training loss: 2.033383846282959
Validation loss: 2.028065932694302

Epoch: 5| Step: 9
Training loss: 1.7442489862442017
Validation loss: 2.0383792269614434

Epoch: 5| Step: 10
Training loss: 2.1131045818328857
Validation loss: 2.051750449724095

Epoch: 172| Step: 0
Training loss: 1.8166389465332031
Validation loss: 2.0686822988653697

Epoch: 5| Step: 1
Training loss: 1.8232024908065796
Validation loss: 2.052087765867992

Epoch: 5| Step: 2
Training loss: 2.025501251220703
Validation loss: 2.050458291525482

Epoch: 5| Step: 3
Training loss: 1.5795936584472656
Validation loss: 2.0467664464827506

Epoch: 5| Step: 4
Training loss: 1.06789231300354
Validation loss: 2.050675762596951

Epoch: 5| Step: 5
Training loss: 2.095492124557495
Validation loss: 2.029665772632886

Epoch: 5| Step: 6
Training loss: 1.5310884714126587
Validation loss: 2.0343792823053177

Epoch: 5| Step: 7
Training loss: 1.6812629699707031
Validation loss: 2.0478778090528262

Epoch: 5| Step: 8
Training loss: 2.1883654594421387
Validation loss: 2.041919554433515

Epoch: 5| Step: 9
Training loss: 2.1793110370635986
Validation loss: 2.041189601344447

Epoch: 5| Step: 10
Training loss: 1.638116717338562
Validation loss: 2.046333384770219

Epoch: 173| Step: 0
Training loss: 1.405543327331543
Validation loss: 2.035445664518623

Epoch: 5| Step: 1
Training loss: 1.3871562480926514
Validation loss: 2.0413369965809647

Epoch: 5| Step: 2
Training loss: 2.336641788482666
Validation loss: 2.051141195399787

Epoch: 5| Step: 3
Training loss: 2.220956802368164
Validation loss: 2.089913632280083

Epoch: 5| Step: 4
Training loss: 1.4166879653930664
Validation loss: 2.120691922403151

Epoch: 5| Step: 5
Training loss: 1.97537100315094
Validation loss: 2.1369582888900593

Epoch: 5| Step: 6
Training loss: 2.4253463745117188
Validation loss: 2.1683627482383483

Epoch: 5| Step: 7
Training loss: 1.5850093364715576
Validation loss: 2.1196353102243073

Epoch: 5| Step: 8
Training loss: 1.49660325050354
Validation loss: 2.0860133145445134

Epoch: 5| Step: 9
Training loss: 2.1078994274139404
Validation loss: 2.00659724332953

Epoch: 5| Step: 10
Training loss: 1.451003074645996
Validation loss: 1.997008619769927

Epoch: 174| Step: 0
Training loss: 1.533596396446228
Validation loss: 1.9876934533478112

Epoch: 5| Step: 1
Training loss: 1.5945359468460083
Validation loss: 1.9975776159635155

Epoch: 5| Step: 2
Training loss: 1.5437228679656982
Validation loss: 1.9782130743867608

Epoch: 5| Step: 3
Training loss: 2.5710649490356445
Validation loss: 1.9986795661269978

Epoch: 5| Step: 4
Training loss: 1.890043020248413
Validation loss: 1.9862516785180697

Epoch: 5| Step: 5
Training loss: 2.04427170753479
Validation loss: 1.9933922034437939

Epoch: 5| Step: 6
Training loss: 1.1235005855560303
Validation loss: 2.027968966832725

Epoch: 5| Step: 7
Training loss: 1.78493332862854
Validation loss: 2.056622368033214

Epoch: 5| Step: 8
Training loss: 1.5703219175338745
Validation loss: 2.0647002240662933

Epoch: 5| Step: 9
Training loss: 1.8706254959106445
Validation loss: 2.0611454286882953

Epoch: 5| Step: 10
Training loss: 2.078728199005127
Validation loss: 2.056766107518186

Epoch: 175| Step: 0
Training loss: 2.1345646381378174
Validation loss: 2.040471292311145

Epoch: 5| Step: 1
Training loss: 2.145336627960205
Validation loss: 2.0173091439790625

Epoch: 5| Step: 2
Training loss: 1.9982141256332397
Validation loss: 2.002329436681604

Epoch: 5| Step: 3
Training loss: 1.7254829406738281
Validation loss: 2.0145291897558395

Epoch: 5| Step: 4
Training loss: 1.5154908895492554
Validation loss: 2.022442187032392

Epoch: 5| Step: 5
Training loss: 2.0956835746765137
Validation loss: 2.01232635846702

Epoch: 5| Step: 6
Training loss: 2.0927767753601074
Validation loss: 2.020864273912163

Epoch: 5| Step: 7
Training loss: 1.7180389165878296
Validation loss: 2.0140069735947477

Epoch: 5| Step: 8
Training loss: 1.0701789855957031
Validation loss: 2.0278944482085524

Epoch: 5| Step: 9
Training loss: 1.0390926599502563
Validation loss: 2.030592267231275

Epoch: 5| Step: 10
Training loss: 1.6901068687438965
Validation loss: 2.0437553236561437

Epoch: 176| Step: 0
Training loss: 1.9303371906280518
Validation loss: 2.0918577307014057

Epoch: 5| Step: 1
Training loss: 1.8426721096038818
Validation loss: 2.1037432801338936

Epoch: 5| Step: 2
Training loss: 1.9021724462509155
Validation loss: 2.1273401014266478

Epoch: 5| Step: 3
Training loss: 2.206660032272339
Validation loss: 2.088264432004703

Epoch: 5| Step: 4
Training loss: 1.638135313987732
Validation loss: 2.0470188279305734

Epoch: 5| Step: 5
Training loss: 1.766714334487915
Validation loss: 2.0206469361500075

Epoch: 5| Step: 6
Training loss: 1.3995492458343506
Validation loss: 2.0161934360381095

Epoch: 5| Step: 7
Training loss: 0.9537919759750366
Validation loss: 2.0026866825678016

Epoch: 5| Step: 8
Training loss: 2.280991792678833
Validation loss: 2.0127942433921238

Epoch: 5| Step: 9
Training loss: 1.8010470867156982
Validation loss: 1.9937243743609356

Epoch: 5| Step: 10
Training loss: 1.6911399364471436
Validation loss: 2.005442270668604

Epoch: 177| Step: 0
Training loss: 2.2090587615966797
Validation loss: 2.01356590178705

Epoch: 5| Step: 1
Training loss: 1.854214072227478
Validation loss: 2.0066667711862953

Epoch: 5| Step: 2
Training loss: 1.681052803993225
Validation loss: 2.0041762628862934

Epoch: 5| Step: 3
Training loss: 1.9397869110107422
Validation loss: 2.0392542731377388

Epoch: 5| Step: 4
Training loss: 1.8176448345184326
Validation loss: 2.059516937501969

Epoch: 5| Step: 5
Training loss: 1.8710743188858032
Validation loss: 2.0765312025623937

Epoch: 5| Step: 6
Training loss: 1.5940039157867432
Validation loss: 2.0690837880616546

Epoch: 5| Step: 7
Training loss: 1.8220901489257812
Validation loss: 2.0726650786656204

Epoch: 5| Step: 8
Training loss: 1.6207460165023804
Validation loss: 2.093080706493829

Epoch: 5| Step: 9
Training loss: 1.579083800315857
Validation loss: 2.0992921360077395

Epoch: 5| Step: 10
Training loss: 1.0956368446350098
Validation loss: 2.087254480649066

Epoch: 178| Step: 0
Training loss: 1.5513993501663208
Validation loss: 2.072419781838694

Epoch: 5| Step: 1
Training loss: 1.8010578155517578
Validation loss: 2.059424518257059

Epoch: 5| Step: 2
Training loss: 1.6077232360839844
Validation loss: 2.0538003060125534

Epoch: 5| Step: 3
Training loss: 1.9995334148406982
Validation loss: 2.0331609710570304

Epoch: 5| Step: 4
Training loss: 1.57283616065979
Validation loss: 2.04088621242072

Epoch: 5| Step: 5
Training loss: 2.234896183013916
Validation loss: 2.0105631454016573

Epoch: 5| Step: 6
Training loss: 1.625311255455017
Validation loss: 2.0036749634691464

Epoch: 5| Step: 7
Training loss: 1.3827263116836548
Validation loss: 2.0056465646272064

Epoch: 5| Step: 8
Training loss: 1.8081026077270508
Validation loss: 2.02006438983384

Epoch: 5| Step: 9
Training loss: 1.605836272239685
Validation loss: 2.0109850975774948

Epoch: 5| Step: 10
Training loss: 1.921862006187439
Validation loss: 1.9947043336847776

Epoch: 179| Step: 0
Training loss: 2.2854363918304443
Validation loss: 2.0125368141358897

Epoch: 5| Step: 1
Training loss: 1.7433443069458008
Validation loss: 2.020453355645621

Epoch: 5| Step: 2
Training loss: 1.6187381744384766
Validation loss: 2.0720312236457743

Epoch: 5| Step: 3
Training loss: 1.4109383821487427
Validation loss: 2.1036130741078365

Epoch: 5| Step: 4
Training loss: 2.2089052200317383
Validation loss: 2.11748339796579

Epoch: 5| Step: 5
Training loss: 1.8087068796157837
Validation loss: 2.1103515317363124

Epoch: 5| Step: 6
Training loss: 1.1786739826202393
Validation loss: 2.0483618667048793

Epoch: 5| Step: 7
Training loss: 1.3639893531799316
Validation loss: 2.0157892755282822

Epoch: 5| Step: 8
Training loss: 2.199040651321411
Validation loss: 1.986864536039291

Epoch: 5| Step: 9
Training loss: 1.7303329706192017
Validation loss: 1.9832131593458113

Epoch: 5| Step: 10
Training loss: 1.4355754852294922
Validation loss: 1.9705778937185965

Epoch: 180| Step: 0
Training loss: 1.6800562143325806
Validation loss: 2.0162706516122304

Epoch: 5| Step: 1
Training loss: 1.5750423669815063
Validation loss: 2.0278583111301547

Epoch: 5| Step: 2
Training loss: 1.4769985675811768
Validation loss: 2.055423243071443

Epoch: 5| Step: 3
Training loss: 1.796007513999939
Validation loss: 2.0674040804627123

Epoch: 5| Step: 4
Training loss: 1.2402560710906982
Validation loss: 2.046748443316388

Epoch: 5| Step: 5
Training loss: 2.0830769538879395
Validation loss: 2.021621991229314

Epoch: 5| Step: 6
Training loss: 1.5117508172988892
Validation loss: 2.018086753865724

Epoch: 5| Step: 7
Training loss: 2.179123878479004
Validation loss: 1.9912731878219112

Epoch: 5| Step: 8
Training loss: 1.5857129096984863
Validation loss: 1.9945452097923524

Epoch: 5| Step: 9
Training loss: 1.975282073020935
Validation loss: 1.9929832296986734

Epoch: 5| Step: 10
Training loss: 1.51204514503479
Validation loss: 2.0223571638907156

Epoch: 181| Step: 0
Training loss: 1.15259850025177
Validation loss: 2.02611509958903

Epoch: 5| Step: 1
Training loss: 1.5499851703643799
Validation loss: 2.069065360612767

Epoch: 5| Step: 2
Training loss: 1.6685947179794312
Validation loss: 2.074868470109919

Epoch: 5| Step: 3
Training loss: 1.9806782007217407
Validation loss: 2.1323728125582457

Epoch: 5| Step: 4
Training loss: 1.777106523513794
Validation loss: 2.1541005398637507

Epoch: 5| Step: 5
Training loss: 2.369333028793335
Validation loss: 2.1822297393634753

Epoch: 5| Step: 6
Training loss: 1.5204603672027588
Validation loss: 2.1629650618440364

Epoch: 5| Step: 7
Training loss: 1.6972957849502563
Validation loss: 2.1272696051546323

Epoch: 5| Step: 8
Training loss: 1.488254427909851
Validation loss: 2.081419816581152

Epoch: 5| Step: 9
Training loss: 2.0411453247070312
Validation loss: 2.015089322161931

Epoch: 5| Step: 10
Training loss: 1.5009217262268066
Validation loss: 1.994134928590508

Epoch: 182| Step: 0
Training loss: 2.0483365058898926
Validation loss: 1.9566632175958285

Epoch: 5| Step: 1
Training loss: 1.8797975778579712
Validation loss: 1.9785327706285702

Epoch: 5| Step: 2
Training loss: 1.8433376550674438
Validation loss: 1.9590882460276287

Epoch: 5| Step: 3
Training loss: 2.116130828857422
Validation loss: 1.9768630663553874

Epoch: 5| Step: 4
Training loss: 0.7133874893188477
Validation loss: 1.9706556425299695

Epoch: 5| Step: 5
Training loss: 1.296630859375
Validation loss: 1.9926582100570842

Epoch: 5| Step: 6
Training loss: 1.9996795654296875
Validation loss: 2.021570069815523

Epoch: 5| Step: 7
Training loss: 1.690441370010376
Validation loss: 2.047152690989997

Epoch: 5| Step: 8
Training loss: 1.6219069957733154
Validation loss: 2.0884485488296836

Epoch: 5| Step: 9
Training loss: 1.8158633708953857
Validation loss: 2.0893068646871917

Epoch: 5| Step: 10
Training loss: 1.830336570739746
Validation loss: 2.114878903153122

Epoch: 183| Step: 0
Training loss: 1.8345047235488892
Validation loss: 2.084875024775023

Epoch: 5| Step: 1
Training loss: 1.5692777633666992
Validation loss: 2.0348053696335002

Epoch: 5| Step: 2
Training loss: 2.041673183441162
Validation loss: 2.027114874573164

Epoch: 5| Step: 3
Training loss: 1.7500778436660767
Validation loss: 2.0056575370091263

Epoch: 5| Step: 4
Training loss: 1.635890245437622
Validation loss: 1.9910684490716586

Epoch: 5| Step: 5
Training loss: 1.6447670459747314
Validation loss: 1.9808752152227587

Epoch: 5| Step: 6
Training loss: 2.0047767162323
Validation loss: 2.0019925358474895

Epoch: 5| Step: 7
Training loss: 1.9626705646514893
Validation loss: 2.0090508742999007

Epoch: 5| Step: 8
Training loss: 1.7170041799545288
Validation loss: 2.000600112381802

Epoch: 5| Step: 9
Training loss: 1.1517215967178345
Validation loss: 2.046982208887736

Epoch: 5| Step: 10
Training loss: 1.550593376159668
Validation loss: 2.0826403479422293

Epoch: 184| Step: 0
Training loss: 1.5145851373672485
Validation loss: 2.11219701972059

Epoch: 5| Step: 1
Training loss: 1.6153905391693115
Validation loss: 2.13068865447916

Epoch: 5| Step: 2
Training loss: 1.984417200088501
Validation loss: 2.160622701849989

Epoch: 5| Step: 3
Training loss: 1.5102005004882812
Validation loss: 2.1500717234867874

Epoch: 5| Step: 4
Training loss: 2.4092459678649902
Validation loss: 2.1327434560304046

Epoch: 5| Step: 5
Training loss: 2.193366527557373
Validation loss: 2.123625619437105

Epoch: 5| Step: 6
Training loss: 1.5376819372177124
Validation loss: 2.09171232100456

Epoch: 5| Step: 7
Training loss: 1.669610619544983
Validation loss: 2.039965714177778

Epoch: 5| Step: 8
Training loss: 1.2016973495483398
Validation loss: 1.9826260356492893

Epoch: 5| Step: 9
Training loss: 1.4585158824920654
Validation loss: 1.9593781258470269

Epoch: 5| Step: 10
Training loss: 1.1278834342956543
Validation loss: 1.9612053466099564

Epoch: 185| Step: 0
Training loss: 1.79507315158844
Validation loss: 1.9575469724593624

Epoch: 5| Step: 1
Training loss: 1.4803831577301025
Validation loss: 1.9481182995662893

Epoch: 5| Step: 2
Training loss: 1.1744941473007202
Validation loss: 1.9912740645870086

Epoch: 5| Step: 3
Training loss: 1.2808072566986084
Validation loss: 2.022674563110516

Epoch: 5| Step: 4
Training loss: 1.9728243350982666
Validation loss: 2.0409469835219847

Epoch: 5| Step: 5
Training loss: 2.081244707107544
Validation loss: 2.097614344730172

Epoch: 5| Step: 6
Training loss: 1.775170922279358
Validation loss: 2.106298174909366

Epoch: 5| Step: 7
Training loss: 1.6431598663330078
Validation loss: 2.0814197422355734

Epoch: 5| Step: 8
Training loss: 2.2431743144989014
Validation loss: 2.070067459537137

Epoch: 5| Step: 9
Training loss: 1.6106513738632202
Validation loss: 2.000663485578311

Epoch: 5| Step: 10
Training loss: 1.3153390884399414
Validation loss: 1.962533614968741

Epoch: 186| Step: 0
Training loss: 1.7082217931747437
Validation loss: 1.9415894631416566

Epoch: 5| Step: 1
Training loss: 1.422485589981079
Validation loss: 1.9359169852349065

Epoch: 5| Step: 2
Training loss: 2.129112720489502
Validation loss: 1.9518703004365325

Epoch: 5| Step: 3
Training loss: 1.499856948852539
Validation loss: 1.9580896259636007

Epoch: 5| Step: 4
Training loss: 1.7261279821395874
Validation loss: 1.9650561322448075

Epoch: 5| Step: 5
Training loss: 2.1050474643707275
Validation loss: 1.9655922253926594

Epoch: 5| Step: 6
Training loss: 1.4523980617523193
Validation loss: 2.0184727048361175

Epoch: 5| Step: 7
Training loss: 1.4884278774261475
Validation loss: 2.062074435654507

Epoch: 5| Step: 8
Training loss: 0.9147415161132812
Validation loss: 2.1048853628097044

Epoch: 5| Step: 9
Training loss: 1.898730993270874
Validation loss: 2.1400005996868177

Epoch: 5| Step: 10
Training loss: 1.8658910989761353
Validation loss: 2.1131070660006617

Epoch: 187| Step: 0
Training loss: 1.9626356363296509
Validation loss: 2.1078858439640333

Epoch: 5| Step: 1
Training loss: 1.6190105676651
Validation loss: 2.0728549175364996

Epoch: 5| Step: 2
Training loss: 1.9932626485824585
Validation loss: 2.0482812094432052

Epoch: 5| Step: 3
Training loss: 1.7313785552978516
Validation loss: 2.04598972874303

Epoch: 5| Step: 4
Training loss: 2.1434967517852783
Validation loss: 2.0459591675830144

Epoch: 5| Step: 5
Training loss: 1.1510604619979858
Validation loss: 2.059782488371736

Epoch: 5| Step: 6
Training loss: 1.191296100616455
Validation loss: 2.068326803945726

Epoch: 5| Step: 7
Training loss: 1.591869592666626
Validation loss: 2.059330386500205

Epoch: 5| Step: 8
Training loss: 1.7249877452850342
Validation loss: 2.062320488755421

Epoch: 5| Step: 9
Training loss: 1.3882466554641724
Validation loss: 2.0791061706440424

Epoch: 5| Step: 10
Training loss: 1.6577357053756714
Validation loss: 2.0559536731371315

Epoch: 188| Step: 0
Training loss: 2.173229455947876
Validation loss: 2.0201279450488347

Epoch: 5| Step: 1
Training loss: 1.0853593349456787
Validation loss: 1.9864407867513678

Epoch: 5| Step: 2
Training loss: 1.4114494323730469
Validation loss: 1.981998343621531

Epoch: 5| Step: 3
Training loss: 2.2940938472747803
Validation loss: 1.978433201389928

Epoch: 5| Step: 4
Training loss: 1.5817995071411133
Validation loss: 1.9958191430696877

Epoch: 5| Step: 5
Training loss: 1.7021236419677734
Validation loss: 2.0046775046215264

Epoch: 5| Step: 6
Training loss: 1.7505226135253906
Validation loss: 2.0276379905721194

Epoch: 5| Step: 7
Training loss: 1.410834789276123
Validation loss: 2.0356604719674714

Epoch: 5| Step: 8
Training loss: 1.2501771450042725
Validation loss: 2.0334515751049085

Epoch: 5| Step: 9
Training loss: 1.7162892818450928
Validation loss: 2.049646508309149

Epoch: 5| Step: 10
Training loss: 1.5002156496047974
Validation loss: 2.0529445909684703

Epoch: 189| Step: 0
Training loss: 1.7056070566177368
Validation loss: 2.033424710714689

Epoch: 5| Step: 1
Training loss: 1.0562821626663208
Validation loss: 2.0469836393992105

Epoch: 5| Step: 2
Training loss: 1.0202044248580933
Validation loss: 2.047517738034648

Epoch: 5| Step: 3
Training loss: 1.4278583526611328
Validation loss: 2.057706755976523

Epoch: 5| Step: 4
Training loss: 2.1169424057006836
Validation loss: 2.0630071111904678

Epoch: 5| Step: 5
Training loss: 1.6012458801269531
Validation loss: 2.0321134469842397

Epoch: 5| Step: 6
Training loss: 1.5646172761917114
Validation loss: 2.030223310634654

Epoch: 5| Step: 7
Training loss: 1.8497982025146484
Validation loss: 2.027419654271936

Epoch: 5| Step: 8
Training loss: 1.947056770324707
Validation loss: 2.00966989609503

Epoch: 5| Step: 9
Training loss: 1.654048204421997
Validation loss: 1.9990976414372843

Epoch: 5| Step: 10
Training loss: 1.655724287033081
Validation loss: 2.0059116143052296

Epoch: 190| Step: 0
Training loss: 2.2497172355651855
Validation loss: 1.9888357616239978

Epoch: 5| Step: 1
Training loss: 1.5483280420303345
Validation loss: 1.9844171821430165

Epoch: 5| Step: 2
Training loss: 2.1035971641540527
Validation loss: 1.978297725800545

Epoch: 5| Step: 3
Training loss: 1.256014108657837
Validation loss: 1.9517712067532282

Epoch: 5| Step: 4
Training loss: 1.7370535135269165
Validation loss: 1.9624895549589587

Epoch: 5| Step: 5
Training loss: 1.5228301286697388
Validation loss: 2.011274472359688

Epoch: 5| Step: 6
Training loss: 1.571944236755371
Validation loss: 2.051070668364084

Epoch: 5| Step: 7
Training loss: 1.1096234321594238
Validation loss: 2.0707640468433337

Epoch: 5| Step: 8
Training loss: 1.6662288904190063
Validation loss: 2.098674976697532

Epoch: 5| Step: 9
Training loss: 1.7852160930633545
Validation loss: 2.0753965121443554

Epoch: 5| Step: 10
Training loss: 1.3508429527282715
Validation loss: 2.057046312157826

Epoch: 191| Step: 0
Training loss: 2.3626856803894043
Validation loss: 2.0089715091131066

Epoch: 5| Step: 1
Training loss: 1.5501821041107178
Validation loss: 1.9864693175080002

Epoch: 5| Step: 2
Training loss: 1.2764700651168823
Validation loss: 1.972114832170548

Epoch: 5| Step: 3
Training loss: 1.9680736064910889
Validation loss: 1.9535825713988273

Epoch: 5| Step: 4
Training loss: 1.2155616283416748
Validation loss: 1.9643325856936875

Epoch: 5| Step: 5
Training loss: 1.442535638809204
Validation loss: 1.9455875965856737

Epoch: 5| Step: 6
Training loss: 1.2687578201293945
Validation loss: 1.9747326656054425

Epoch: 5| Step: 7
Training loss: 1.7748825550079346
Validation loss: 1.9813165690309258

Epoch: 5| Step: 8
Training loss: 1.5649504661560059
Validation loss: 1.9826334907162575

Epoch: 5| Step: 9
Training loss: 1.326762080192566
Validation loss: 2.0325797129702825

Epoch: 5| Step: 10
Training loss: 1.7030649185180664
Validation loss: 2.0550418617904826

Epoch: 192| Step: 0
Training loss: 1.8040765523910522
Validation loss: 2.081893933716641

Epoch: 5| Step: 1
Training loss: 1.9988425970077515
Validation loss: 2.1306522366821126

Epoch: 5| Step: 2
Training loss: 2.039416790008545
Validation loss: 2.135194266996076

Epoch: 5| Step: 3
Training loss: 1.7222858667373657
Validation loss: 2.095453434093024

Epoch: 5| Step: 4
Training loss: 1.235961675643921
Validation loss: 2.0373767755364858

Epoch: 5| Step: 5
Training loss: 1.3032076358795166
Validation loss: 1.9933967474968202

Epoch: 5| Step: 6
Training loss: 1.4638502597808838
Validation loss: 1.9584281008730653

Epoch: 5| Step: 7
Training loss: 1.2866742610931396
Validation loss: 1.951633520023797

Epoch: 5| Step: 8
Training loss: 1.5988091230392456
Validation loss: 1.9410741816284836

Epoch: 5| Step: 9
Training loss: 1.55208420753479
Validation loss: 1.9430171687115905

Epoch: 5| Step: 10
Training loss: 1.890869140625
Validation loss: 1.943398206464706

Epoch: 193| Step: 0
Training loss: 0.9616511464118958
Validation loss: 1.9761659047936881

Epoch: 5| Step: 1
Training loss: 1.5737760066986084
Validation loss: 2.020058753669903

Epoch: 5| Step: 2
Training loss: 1.636968970298767
Validation loss: 2.087046004110767

Epoch: 5| Step: 3
Training loss: 1.7989308834075928
Validation loss: 2.1543169624061993

Epoch: 5| Step: 4
Training loss: 1.9282493591308594
Validation loss: 2.226257326782391

Epoch: 5| Step: 5
Training loss: 1.6480919122695923
Validation loss: 2.225026621613451

Epoch: 5| Step: 6
Training loss: 1.4293888807296753
Validation loss: 2.166680351380379

Epoch: 5| Step: 7
Training loss: 1.7972749471664429
Validation loss: 2.0832723186862085

Epoch: 5| Step: 8
Training loss: 1.6946990489959717
Validation loss: 2.017218001427189

Epoch: 5| Step: 9
Training loss: 1.5030553340911865
Validation loss: 1.9974975444937264

Epoch: 5| Step: 10
Training loss: 1.7681193351745605
Validation loss: 1.9649950201793382

Epoch: 194| Step: 0
Training loss: 2.026848316192627
Validation loss: 1.946256838819032

Epoch: 5| Step: 1
Training loss: 1.731663703918457
Validation loss: 1.9530866504997335

Epoch: 5| Step: 2
Training loss: 1.8853737115859985
Validation loss: 1.916397935600691

Epoch: 5| Step: 3
Training loss: 1.0439350605010986
Validation loss: 1.9276789888258903

Epoch: 5| Step: 4
Training loss: 1.31924569606781
Validation loss: 1.9181126561216129

Epoch: 5| Step: 5
Training loss: 1.3542232513427734
Validation loss: 1.9424593243547665

Epoch: 5| Step: 6
Training loss: 1.6813490390777588
Validation loss: 1.9929999177173903

Epoch: 5| Step: 7
Training loss: 1.4134222269058228
Validation loss: 2.020333351627473

Epoch: 5| Step: 8
Training loss: 1.8270965814590454
Validation loss: 2.024055537357125

Epoch: 5| Step: 9
Training loss: 1.714817762374878
Validation loss: 2.051401274178618

Epoch: 5| Step: 10
Training loss: 1.0115125179290771
Validation loss: 2.0548064144708778

Epoch: 195| Step: 0
Training loss: 1.3931081295013428
Validation loss: 2.085023437776873

Epoch: 5| Step: 1
Training loss: 1.6164344549179077
Validation loss: 2.093728027036113

Epoch: 5| Step: 2
Training loss: 2.002685785293579
Validation loss: 2.108932638681063

Epoch: 5| Step: 3
Training loss: 2.10571551322937
Validation loss: 2.0698122798755603

Epoch: 5| Step: 4
Training loss: 1.428340196609497
Validation loss: 2.0532282808775544

Epoch: 5| Step: 5
Training loss: 1.5213220119476318
Validation loss: 2.03316617268388

Epoch: 5| Step: 6
Training loss: 1.1570823192596436
Validation loss: 2.0114420203752417

Epoch: 5| Step: 7
Training loss: 1.332335114479065
Validation loss: 2.02032841790107

Epoch: 5| Step: 8
Training loss: 1.6963313817977905
Validation loss: 2.013641552258563

Epoch: 5| Step: 9
Training loss: 1.250740647315979
Validation loss: 2.007281408515028

Epoch: 5| Step: 10
Training loss: 1.7357314825057983
Validation loss: 2.0266813744780836

Epoch: 196| Step: 0
Training loss: 2.041076898574829
Validation loss: 2.0919479080425796

Epoch: 5| Step: 1
Training loss: 1.504749059677124
Validation loss: 2.126919898935544

Epoch: 5| Step: 2
Training loss: 1.575507402420044
Validation loss: 2.0953476839168097

Epoch: 5| Step: 3
Training loss: 1.092775583267212
Validation loss: 2.0381384870057464

Epoch: 5| Step: 4
Training loss: 1.643493890762329
Validation loss: 2.0044144648377613

Epoch: 5| Step: 5
Training loss: 1.2417771816253662
Validation loss: 1.9741875433152722

Epoch: 5| Step: 6
Training loss: 1.1797833442687988
Validation loss: 1.9531367466013918

Epoch: 5| Step: 7
Training loss: 1.5646570920944214
Validation loss: 1.9254308874889086

Epoch: 5| Step: 8
Training loss: 1.8699947595596313
Validation loss: 1.9257974957907071

Epoch: 5| Step: 9
Training loss: 1.8190590143203735
Validation loss: 1.9535114752349032

Epoch: 5| Step: 10
Training loss: 1.8767491579055786
Validation loss: 1.9702805344776442

Epoch: 197| Step: 0
Training loss: 1.2013633251190186
Validation loss: 1.9875408231571157

Epoch: 5| Step: 1
Training loss: 1.427432894706726
Validation loss: 2.006671088998036

Epoch: 5| Step: 2
Training loss: 1.567638635635376
Validation loss: 1.999490157250435

Epoch: 5| Step: 3
Training loss: 1.1054933071136475
Validation loss: 1.9902108779517553

Epoch: 5| Step: 4
Training loss: 2.1389315128326416
Validation loss: 1.9875169953992289

Epoch: 5| Step: 5
Training loss: 1.1290949583053589
Validation loss: 2.0092000935667302

Epoch: 5| Step: 6
Training loss: 1.8180042505264282
Validation loss: 2.0305921249492194

Epoch: 5| Step: 7
Training loss: 1.3560309410095215
Validation loss: 2.014706434742097

Epoch: 5| Step: 8
Training loss: 1.3134431838989258
Validation loss: 2.018915955738355

Epoch: 5| Step: 9
Training loss: 2.2467682361602783
Validation loss: 2.0203092944237495

Epoch: 5| Step: 10
Training loss: 1.7876300811767578
Validation loss: 2.048259360815889

Epoch: 198| Step: 0
Training loss: 1.0232893228530884
Validation loss: 2.0560468755742556

Epoch: 5| Step: 1
Training loss: 1.9426624774932861
Validation loss: 2.0685386888442503

Epoch: 5| Step: 2
Training loss: 1.6825376749038696
Validation loss: 2.082671565394248

Epoch: 5| Step: 3
Training loss: 1.397986650466919
Validation loss: 2.109645034677239

Epoch: 5| Step: 4
Training loss: 0.9898594617843628
Validation loss: 2.083837637337305

Epoch: 5| Step: 5
Training loss: 2.2454020977020264
Validation loss: 2.101435890761755

Epoch: 5| Step: 6
Training loss: 1.8133857250213623
Validation loss: 2.0815761960962766

Epoch: 5| Step: 7
Training loss: 1.258124589920044
Validation loss: 2.0796885362235447

Epoch: 5| Step: 8
Training loss: 1.1190025806427002
Validation loss: 2.0717049465384534

Epoch: 5| Step: 9
Training loss: 1.6162601709365845
Validation loss: 2.03697221766236

Epoch: 5| Step: 10
Training loss: 1.8740977048873901
Validation loss: 2.0072370408683695

Epoch: 199| Step: 0
Training loss: 1.7218818664550781
Validation loss: 2.017169649882983

Epoch: 5| Step: 1
Training loss: 0.8437566757202148
Validation loss: 2.023280983330101

Epoch: 5| Step: 2
Training loss: 0.8691741228103638
Validation loss: 2.0172430315325336

Epoch: 5| Step: 3
Training loss: 1.9564813375473022
Validation loss: 2.035797780559909

Epoch: 5| Step: 4
Training loss: 1.5850050449371338
Validation loss: 2.023400299010738

Epoch: 5| Step: 5
Training loss: 1.7791244983673096
Validation loss: 2.010515541158697

Epoch: 5| Step: 6
Training loss: 1.9385106563568115
Validation loss: 2.029279067952146

Epoch: 5| Step: 7
Training loss: 1.4716204404830933
Validation loss: 2.033906726426976

Epoch: 5| Step: 8
Training loss: 1.6910680532455444
Validation loss: 2.0503089530493623

Epoch: 5| Step: 9
Training loss: 1.6944698095321655
Validation loss: 2.032538593456309

Epoch: 5| Step: 10
Training loss: 1.857356071472168
Validation loss: 2.027280822876961

Epoch: 200| Step: 0
Training loss: 1.8465001583099365
Validation loss: 2.024324796533072

Epoch: 5| Step: 1
Training loss: 2.0513806343078613
Validation loss: 2.005296427716491

Epoch: 5| Step: 2
Training loss: 1.3286526203155518
Validation loss: 2.024743426230646

Epoch: 5| Step: 3
Training loss: 1.1502399444580078
Validation loss: 2.02197273572286

Epoch: 5| Step: 4
Training loss: 1.3023790121078491
Validation loss: 2.042419469484719

Epoch: 5| Step: 5
Training loss: 1.790104866027832
Validation loss: 2.034806231016754

Epoch: 5| Step: 6
Training loss: 1.2406129837036133
Validation loss: 2.0552325184627245

Epoch: 5| Step: 7
Training loss: 1.4203912019729614
Validation loss: 2.0224122001278784

Epoch: 5| Step: 8
Training loss: 1.7528650760650635
Validation loss: 2.0107009231403308

Epoch: 5| Step: 9
Training loss: 1.5294544696807861
Validation loss: 2.012826927246586

Epoch: 5| Step: 10
Training loss: 1.2000367641448975
Validation loss: 2.018980973510332

Epoch: 201| Step: 0
Training loss: 1.8816522359848022
Validation loss: 2.034506079971149

Epoch: 5| Step: 1
Training loss: 1.477791666984558
Validation loss: 2.046306647280211

Epoch: 5| Step: 2
Training loss: 1.1396723985671997
Validation loss: 2.0294380598170783

Epoch: 5| Step: 3
Training loss: 1.4085862636566162
Validation loss: 2.0440912349249727

Epoch: 5| Step: 4
Training loss: 1.3606141805648804
Validation loss: 2.026287550567299

Epoch: 5| Step: 5
Training loss: 1.642535924911499
Validation loss: 2.0202421398573023

Epoch: 5| Step: 6
Training loss: 1.3900625705718994
Validation loss: 1.9791432529367425

Epoch: 5| Step: 7
Training loss: 1.5433683395385742
Validation loss: 1.9784917139237927

Epoch: 5| Step: 8
Training loss: 1.7121212482452393
Validation loss: 1.9973345033584102

Epoch: 5| Step: 9
Training loss: 1.5742769241333008
Validation loss: 2.0304806642634894

Epoch: 5| Step: 10
Training loss: 1.2149629592895508
Validation loss: 2.036868267161872

Epoch: 202| Step: 0
Training loss: 1.8265527486801147
Validation loss: 2.019506492922383

Epoch: 5| Step: 1
Training loss: 1.6978693008422852
Validation loss: 2.005775455505617

Epoch: 5| Step: 2
Training loss: 1.0135924816131592
Validation loss: 2.0004903808716805

Epoch: 5| Step: 3
Training loss: 1.5730178356170654
Validation loss: 1.9923199171661048

Epoch: 5| Step: 4
Training loss: 1.4031236171722412
Validation loss: 2.0196837507268435

Epoch: 5| Step: 5
Training loss: 0.9896936416625977
Validation loss: 1.997159796376382

Epoch: 5| Step: 6
Training loss: 1.6611340045928955
Validation loss: 1.9966845307298886

Epoch: 5| Step: 7
Training loss: 1.1747726202011108
Validation loss: 1.9796370998505624

Epoch: 5| Step: 8
Training loss: 1.3587960004806519
Validation loss: 2.0123696301573064

Epoch: 5| Step: 9
Training loss: 2.159048557281494
Validation loss: 2.0480388287575013

Epoch: 5| Step: 10
Training loss: 1.5206425189971924
Validation loss: 2.04352371282475

Epoch: 203| Step: 0
Training loss: 1.7393163442611694
Validation loss: 2.0634572006041005

Epoch: 5| Step: 1
Training loss: 1.2587220668792725
Validation loss: 2.0598330600287325

Epoch: 5| Step: 2
Training loss: 0.894200325012207
Validation loss: 2.052677280159407

Epoch: 5| Step: 3
Training loss: 1.2935072183609009
Validation loss: 2.048425095055693

Epoch: 5| Step: 4
Training loss: 1.4272186756134033
Validation loss: 2.017924754850326

Epoch: 5| Step: 5
Training loss: 1.4107019901275635
Validation loss: 2.0113511316237913

Epoch: 5| Step: 6
Training loss: 1.6664352416992188
Validation loss: 2.0051457010289675

Epoch: 5| Step: 7
Training loss: 1.4159753322601318
Validation loss: 1.9692992138606247

Epoch: 5| Step: 8
Training loss: 1.556036114692688
Validation loss: 1.9620491843069754

Epoch: 5| Step: 9
Training loss: 1.483904242515564
Validation loss: 1.9716043831199728

Epoch: 5| Step: 10
Training loss: 2.194028377532959
Validation loss: 1.948123388392951

Epoch: 204| Step: 0
Training loss: 2.180746078491211
Validation loss: 1.9716444592322073

Epoch: 5| Step: 1
Training loss: 1.1787078380584717
Validation loss: 1.9922408929435156

Epoch: 5| Step: 2
Training loss: 0.8108837008476257
Validation loss: 2.0133323900161253

Epoch: 5| Step: 3
Training loss: 1.4646327495574951
Validation loss: 2.04975664231085

Epoch: 5| Step: 4
Training loss: 1.5091698169708252
Validation loss: 2.0612582263126167

Epoch: 5| Step: 5
Training loss: 1.5078321695327759
Validation loss: 2.0560596989047144

Epoch: 5| Step: 6
Training loss: 1.8312406539916992
Validation loss: 2.0445999368544547

Epoch: 5| Step: 7
Training loss: 1.2913814783096313
Validation loss: 2.030723894796064

Epoch: 5| Step: 8
Training loss: 0.6550338864326477
Validation loss: 2.0280718136859197

Epoch: 5| Step: 9
Training loss: 1.7144609689712524
Validation loss: 2.0258608146380355

Epoch: 5| Step: 10
Training loss: 2.1224122047424316
Validation loss: 2.041881589479344

Epoch: 205| Step: 0
Training loss: 1.4886757135391235
Validation loss: 2.034905279836347

Epoch: 5| Step: 1
Training loss: 0.774617075920105
Validation loss: 2.028100493133709

Epoch: 5| Step: 2
Training loss: 1.3862866163253784
Validation loss: 2.063229117342221

Epoch: 5| Step: 3
Training loss: 2.0590767860412598
Validation loss: 2.0641738060981996

Epoch: 5| Step: 4
Training loss: 1.839189887046814
Validation loss: 2.028658578472753

Epoch: 5| Step: 5
Training loss: 1.511181354522705
Validation loss: 2.036739900547971

Epoch: 5| Step: 6
Training loss: 1.61678946018219
Validation loss: 2.016743080590361

Epoch: 5| Step: 7
Training loss: 0.948291003704071
Validation loss: 2.023048380369781

Epoch: 5| Step: 8
Training loss: 1.1820493936538696
Validation loss: 1.998863947006964

Epoch: 5| Step: 9
Training loss: 1.1296765804290771
Validation loss: 1.9527738030238817

Epoch: 5| Step: 10
Training loss: 1.8952497243881226
Validation loss: 1.9688761541920323

Epoch: 206| Step: 0
Training loss: 1.2308235168457031
Validation loss: 1.9631921014478129

Epoch: 5| Step: 1
Training loss: 1.633226752281189
Validation loss: 1.951176494680425

Epoch: 5| Step: 2
Training loss: 1.321016788482666
Validation loss: 1.960220798369377

Epoch: 5| Step: 3
Training loss: 1.2233426570892334
Validation loss: 1.9424040163716962

Epoch: 5| Step: 4
Training loss: 1.2804901599884033
Validation loss: 1.9501808766395814

Epoch: 5| Step: 5
Training loss: 1.116118311882019
Validation loss: 1.9856535119395102

Epoch: 5| Step: 6
Training loss: 1.421635389328003
Validation loss: 1.9829275236334851

Epoch: 5| Step: 7
Training loss: 1.2618712186813354
Validation loss: 2.0072845182111188

Epoch: 5| Step: 8
Training loss: 2.120727062225342
Validation loss: 2.038064185009208

Epoch: 5| Step: 9
Training loss: 1.4885094165802002
Validation loss: 2.0416906725975776

Epoch: 5| Step: 10
Training loss: 1.9012478590011597
Validation loss: 2.0094970067342124

Epoch: 207| Step: 0
Training loss: 1.0558691024780273
Validation loss: 2.0095285472049507

Epoch: 5| Step: 1
Training loss: 1.8753786087036133
Validation loss: 2.0262752886741393

Epoch: 5| Step: 2
Training loss: 1.4719849824905396
Validation loss: 2.018856710003268

Epoch: 5| Step: 3
Training loss: 1.388366937637329
Validation loss: 2.017162271725234

Epoch: 5| Step: 4
Training loss: 1.3483110666275024
Validation loss: 2.000969188187712

Epoch: 5| Step: 5
Training loss: 1.5239691734313965
Validation loss: 1.9963698053872714

Epoch: 5| Step: 6
Training loss: 1.0490888357162476
Validation loss: 1.9672569856848767

Epoch: 5| Step: 7
Training loss: 1.7438199520111084
Validation loss: 1.9672837911113616

Epoch: 5| Step: 8
Training loss: 1.3019226789474487
Validation loss: 1.9836764425359747

Epoch: 5| Step: 9
Training loss: 1.3798552751541138
Validation loss: 1.9810108125850718

Epoch: 5| Step: 10
Training loss: 1.5507291555404663
Validation loss: 2.015972770670409

Epoch: 208| Step: 0
Training loss: 1.525151252746582
Validation loss: 2.067529114343787

Epoch: 5| Step: 1
Training loss: 1.207066297531128
Validation loss: 2.058839008372317

Epoch: 5| Step: 2
Training loss: 1.6327232122421265
Validation loss: 2.0457015665628577

Epoch: 5| Step: 3
Training loss: 1.333656668663025
Validation loss: 2.0271871141208115

Epoch: 5| Step: 4
Training loss: 1.5087239742279053
Validation loss: 2.062087392294279

Epoch: 5| Step: 5
Training loss: 1.5317556858062744
Validation loss: 2.064560987616098

Epoch: 5| Step: 6
Training loss: 1.3241567611694336
Validation loss: 2.0306843967847925

Epoch: 5| Step: 7
Training loss: 1.0701740980148315
Validation loss: 2.005384134989913

Epoch: 5| Step: 8
Training loss: 1.7884228229522705
Validation loss: 1.9719201723734539

Epoch: 5| Step: 9
Training loss: 1.5256248712539673
Validation loss: 1.927545416739679

Epoch: 5| Step: 10
Training loss: 1.1927568912506104
Validation loss: 1.9265673096461962

Epoch: 209| Step: 0
Training loss: 1.6744476556777954
Validation loss: 1.9194656905307566

Epoch: 5| Step: 1
Training loss: 1.2087366580963135
Validation loss: 1.954397274601844

Epoch: 5| Step: 2
Training loss: 1.2560867071151733
Validation loss: 1.9815996282844133

Epoch: 5| Step: 3
Training loss: 1.475135087966919
Validation loss: 2.061610294926551

Epoch: 5| Step: 4
Training loss: 1.8741886615753174
Validation loss: 2.101648379397649

Epoch: 5| Step: 5
Training loss: 1.46697998046875
Validation loss: 2.0667582660593014

Epoch: 5| Step: 6
Training loss: 1.0740824937820435
Validation loss: 2.025207304185437

Epoch: 5| Step: 7
Training loss: 1.5622100830078125
Validation loss: 2.0356214097751084

Epoch: 5| Step: 8
Training loss: 1.6545875072479248
Validation loss: 2.059442953396869

Epoch: 5| Step: 9
Training loss: 1.2700016498565674
Validation loss: 2.0588045479148946

Epoch: 5| Step: 10
Training loss: 1.587414264678955
Validation loss: 2.031501946910735

Epoch: 210| Step: 0
Training loss: 1.853697419166565
Validation loss: 1.9700563466677101

Epoch: 5| Step: 1
Training loss: 2.1391682624816895
Validation loss: 1.9502645231062365

Epoch: 5| Step: 2
Training loss: 1.0095216035842896
Validation loss: 1.9162895602564658

Epoch: 5| Step: 3
Training loss: 1.2660561800003052
Validation loss: 1.9224711425842778

Epoch: 5| Step: 4
Training loss: 1.4668118953704834
Validation loss: 1.8959657069175475

Epoch: 5| Step: 5
Training loss: 1.0590507984161377
Validation loss: 1.9304282870343936

Epoch: 5| Step: 6
Training loss: 1.3646196126937866
Validation loss: 1.9351461754050305

Epoch: 5| Step: 7
Training loss: 1.3570481538772583
Validation loss: 1.9485315071639193

Epoch: 5| Step: 8
Training loss: 1.3912270069122314
Validation loss: 1.9522164534497004

Epoch: 5| Step: 9
Training loss: 1.6112276315689087
Validation loss: 1.9679766598568167

Epoch: 5| Step: 10
Training loss: 1.1675138473510742
Validation loss: 2.003784882125034

Epoch: 211| Step: 0
Training loss: 1.0644091367721558
Validation loss: 2.025623893225065

Epoch: 5| Step: 1
Training loss: 1.2869911193847656
Validation loss: 2.045382127966932

Epoch: 5| Step: 2
Training loss: 1.7190964221954346
Validation loss: 2.0566506167893768

Epoch: 5| Step: 3
Training loss: 1.2371373176574707
Validation loss: 2.0101518156707927

Epoch: 5| Step: 4
Training loss: 1.2363505363464355
Validation loss: 1.9701823303776402

Epoch: 5| Step: 5
Training loss: 1.9304802417755127
Validation loss: 1.9479033254807996

Epoch: 5| Step: 6
Training loss: 1.4636553525924683
Validation loss: 1.954202473804515

Epoch: 5| Step: 7
Training loss: 1.4728370904922485
Validation loss: 1.913085296589841

Epoch: 5| Step: 8
Training loss: 1.5245647430419922
Validation loss: 1.9317863372064406

Epoch: 5| Step: 9
Training loss: 1.2054227590560913
Validation loss: 1.9218184076329714

Epoch: 5| Step: 10
Training loss: 1.418936848640442
Validation loss: 1.9256417302675144

Epoch: 212| Step: 0
Training loss: 1.8656184673309326
Validation loss: 1.9643921390656502

Epoch: 5| Step: 1
Training loss: 1.4406063556671143
Validation loss: 1.9782885377125075

Epoch: 5| Step: 2
Training loss: 1.2138445377349854
Validation loss: 2.0308330546143236

Epoch: 5| Step: 3
Training loss: 1.491729974746704
Validation loss: 2.04609711452197

Epoch: 5| Step: 4
Training loss: 1.4384052753448486
Validation loss: 2.0686292635497225

Epoch: 5| Step: 5
Training loss: 1.1733691692352295
Validation loss: 2.115962633522608

Epoch: 5| Step: 6
Training loss: 0.8781097531318665
Validation loss: 2.104093897727228

Epoch: 5| Step: 7
Training loss: 1.2793424129486084
Validation loss: 2.0889036681062434

Epoch: 5| Step: 8
Training loss: 1.44074285030365
Validation loss: 2.059449408643989

Epoch: 5| Step: 9
Training loss: 1.6056827306747437
Validation loss: 2.031694486577024

Epoch: 5| Step: 10
Training loss: 1.7267276048660278
Validation loss: 1.9406383140112764

Epoch: 213| Step: 0
Training loss: 1.8853504657745361
Validation loss: 1.9140241786997805

Epoch: 5| Step: 1
Training loss: 0.9183594584465027
Validation loss: 1.8870637545021631

Epoch: 5| Step: 2
Training loss: 1.6741501092910767
Validation loss: 1.8816083092843332

Epoch: 5| Step: 3
Training loss: 1.9304460287094116
Validation loss: 1.9112160410932315

Epoch: 5| Step: 4
Training loss: 1.6947177648544312
Validation loss: 1.8996815373820644

Epoch: 5| Step: 5
Training loss: 0.9620630145072937
Validation loss: 1.9514385923262565

Epoch: 5| Step: 6
Training loss: 1.4177095890045166
Validation loss: 1.9916031001716532

Epoch: 5| Step: 7
Training loss: 1.5417840480804443
Validation loss: 2.0006647417622228

Epoch: 5| Step: 8
Training loss: 1.7880340814590454
Validation loss: 1.9851183186295212

Epoch: 5| Step: 9
Training loss: 0.7283610105514526
Validation loss: 2.00873738719571

Epoch: 5| Step: 10
Training loss: 1.4765076637268066
Validation loss: 2.011446185009454

Epoch: 214| Step: 0
Training loss: 1.2423722743988037
Validation loss: 2.001077845532407

Epoch: 5| Step: 1
Training loss: 1.4600474834442139
Validation loss: 2.0000346501668296

Epoch: 5| Step: 2
Training loss: 1.0211007595062256
Validation loss: 1.9967130807138258

Epoch: 5| Step: 3
Training loss: 1.4708625078201294
Validation loss: 1.9662982263872701

Epoch: 5| Step: 4
Training loss: 1.5175788402557373
Validation loss: 1.9568679896734094

Epoch: 5| Step: 5
Training loss: 1.808300256729126
Validation loss: 1.958749008435075

Epoch: 5| Step: 6
Training loss: 1.2528331279754639
Validation loss: 1.9420974498154016

Epoch: 5| Step: 7
Training loss: 1.5213849544525146
Validation loss: 1.9254283546119608

Epoch: 5| Step: 8
Training loss: 1.1469151973724365
Validation loss: 1.951460853699715

Epoch: 5| Step: 9
Training loss: 1.5211598873138428
Validation loss: 1.9487865073706514

Epoch: 5| Step: 10
Training loss: 1.3619050979614258
Validation loss: 1.9621336998478058

Epoch: 215| Step: 0
Training loss: 1.4935579299926758
Validation loss: 1.971603285881781

Epoch: 5| Step: 1
Training loss: 1.4580930471420288
Validation loss: 1.993645369365651

Epoch: 5| Step: 2
Training loss: 1.5519200563430786
Validation loss: 2.03873267737768

Epoch: 5| Step: 3
Training loss: 0.7591460347175598
Validation loss: 2.043956620718843

Epoch: 5| Step: 4
Training loss: 1.5129034519195557
Validation loss: 2.0273197017690188

Epoch: 5| Step: 5
Training loss: 1.553602933883667
Validation loss: 2.0087269198509956

Epoch: 5| Step: 6
Training loss: 1.5041468143463135
Validation loss: 1.9698350198807255

Epoch: 5| Step: 7
Training loss: 1.4002621173858643
Validation loss: 1.9677690459835915

Epoch: 5| Step: 8
Training loss: 1.2041913270950317
Validation loss: 1.9383089978207824

Epoch: 5| Step: 9
Training loss: 1.598212718963623
Validation loss: 1.950257965313491

Epoch: 5| Step: 10
Training loss: 1.2866060733795166
Validation loss: 1.933448196739279

Epoch: 216| Step: 0
Training loss: 1.462296724319458
Validation loss: 1.9438028425298712

Epoch: 5| Step: 1
Training loss: 1.8359254598617554
Validation loss: 1.9374806368222801

Epoch: 5| Step: 2
Training loss: 1.4691580533981323
Validation loss: 1.974531207033383

Epoch: 5| Step: 3
Training loss: 0.974407970905304
Validation loss: 1.9781097737691735

Epoch: 5| Step: 4
Training loss: 1.5689122676849365
Validation loss: 1.9923992374891877

Epoch: 5| Step: 5
Training loss: 1.1709035634994507
Validation loss: 2.0217018204350627

Epoch: 5| Step: 6
Training loss: 0.8672394752502441
Validation loss: 2.0123216285500476

Epoch: 5| Step: 7
Training loss: 1.5435640811920166
Validation loss: 2.026447298706219

Epoch: 5| Step: 8
Training loss: 1.390125036239624
Validation loss: 2.027674598078574

Epoch: 5| Step: 9
Training loss: 1.4646611213684082
Validation loss: 2.0043165581200713

Epoch: 5| Step: 10
Training loss: 1.1767988204956055
Validation loss: 1.9883461062626173

Epoch: 217| Step: 0
Training loss: 1.7675424814224243
Validation loss: 1.9725976400477911

Epoch: 5| Step: 1
Training loss: 1.4932612180709839
Validation loss: 1.9467547426941574

Epoch: 5| Step: 2
Training loss: 0.8204011917114258
Validation loss: 1.9028935150433612

Epoch: 5| Step: 3
Training loss: 1.2261085510253906
Validation loss: 1.909004501117173

Epoch: 5| Step: 4
Training loss: 1.3120355606079102
Validation loss: 1.940141721438336

Epoch: 5| Step: 5
Training loss: 1.2506729364395142
Validation loss: 1.965445879966982

Epoch: 5| Step: 6
Training loss: 0.9265414476394653
Validation loss: 2.027542511622111

Epoch: 5| Step: 7
Training loss: 1.6989469528198242
Validation loss: 2.063109319697144

Epoch: 5| Step: 8
Training loss: 1.7489795684814453
Validation loss: 2.0518858266133133

Epoch: 5| Step: 9
Training loss: 1.702579140663147
Validation loss: 2.0661569449209396

Epoch: 5| Step: 10
Training loss: 0.7957278490066528
Validation loss: 2.042886887827227

Epoch: 218| Step: 0
Training loss: 1.522619605064392
Validation loss: 2.019438987137169

Epoch: 5| Step: 1
Training loss: 1.2446184158325195
Validation loss: 1.9910416782543223

Epoch: 5| Step: 2
Training loss: 1.1021506786346436
Validation loss: 1.9660323281441965

Epoch: 5| Step: 3
Training loss: 1.927151083946228
Validation loss: 2.0028638134720507

Epoch: 5| Step: 4
Training loss: 1.1854298114776611
Validation loss: 1.9695012671973116

Epoch: 5| Step: 5
Training loss: 1.5139045715332031
Validation loss: 1.958795634649133

Epoch: 5| Step: 6
Training loss: 0.9424810409545898
Validation loss: 1.9498479186847646

Epoch: 5| Step: 7
Training loss: 1.2404346466064453
Validation loss: 1.9327339715855096

Epoch: 5| Step: 8
Training loss: 1.5605385303497314
Validation loss: 1.919453315837409

Epoch: 5| Step: 9
Training loss: 1.3089442253112793
Validation loss: 1.9151952946057884

Epoch: 5| Step: 10
Training loss: 1.031652569770813
Validation loss: 1.9240082899729412

Epoch: 219| Step: 0
Training loss: 0.8995561599731445
Validation loss: 1.9367211916113412

Epoch: 5| Step: 1
Training loss: 1.2987310886383057
Validation loss: 1.9382782584877425

Epoch: 5| Step: 2
Training loss: 1.0509166717529297
Validation loss: 1.9726604479615406

Epoch: 5| Step: 3
Training loss: 1.7381961345672607
Validation loss: 1.9697455001133743

Epoch: 5| Step: 4
Training loss: 0.8656452894210815
Validation loss: 1.9870438883381505

Epoch: 5| Step: 5
Training loss: 1.2919460535049438
Validation loss: 1.996278339816678

Epoch: 5| Step: 6
Training loss: 1.7482550144195557
Validation loss: 2.018428473062413

Epoch: 5| Step: 7
Training loss: 1.7188419103622437
Validation loss: 2.030212898408213

Epoch: 5| Step: 8
Training loss: 1.2743672132492065
Validation loss: 2.0410468988521124

Epoch: 5| Step: 9
Training loss: 1.0278267860412598
Validation loss: 2.0027317141973846

Epoch: 5| Step: 10
Training loss: 1.7709403038024902
Validation loss: 1.994467055925759

Epoch: 220| Step: 0
Training loss: 1.349955677986145
Validation loss: 1.9682132890147548

Epoch: 5| Step: 1
Training loss: 1.537755012512207
Validation loss: 1.9641120254352529

Epoch: 5| Step: 2
Training loss: 1.535874366760254
Validation loss: 1.9636248439870856

Epoch: 5| Step: 3
Training loss: 0.9365605115890503
Validation loss: 1.9958959035975958

Epoch: 5| Step: 4
Training loss: 1.4005820751190186
Validation loss: 1.9906603290188698

Epoch: 5| Step: 5
Training loss: 1.0992438793182373
Validation loss: 1.9889564834615236

Epoch: 5| Step: 6
Training loss: 1.4135860204696655
Validation loss: 1.9480545725873721

Epoch: 5| Step: 7
Training loss: 1.9628816843032837
Validation loss: 1.927901243650785

Epoch: 5| Step: 8
Training loss: 1.1499286890029907
Validation loss: 1.8966924964740712

Epoch: 5| Step: 9
Training loss: 1.0025482177734375
Validation loss: 1.8884114578206053

Epoch: 5| Step: 10
Training loss: 1.0304157733917236
Validation loss: 1.8729883881025418

Epoch: 221| Step: 0
Training loss: 1.4455455541610718
Validation loss: 1.8774917176974717

Epoch: 5| Step: 1
Training loss: 1.2094488143920898
Validation loss: 1.915560055804509

Epoch: 5| Step: 2
Training loss: 0.5821558237075806
Validation loss: 1.9415543105012627

Epoch: 5| Step: 3
Training loss: 1.6541965007781982
Validation loss: 1.9893130192192652

Epoch: 5| Step: 4
Training loss: 1.4549115896224976
Validation loss: 1.9944698656758955

Epoch: 5| Step: 5
Training loss: 1.252699375152588
Validation loss: 2.006158503152991

Epoch: 5| Step: 6
Training loss: 1.7382103204727173
Validation loss: 2.0040071728408977

Epoch: 5| Step: 7
Training loss: 1.0298343896865845
Validation loss: 2.0294977567529164

Epoch: 5| Step: 8
Training loss: 1.3315891027450562
Validation loss: 2.023175903545913

Epoch: 5| Step: 9
Training loss: 1.245399832725525
Validation loss: 1.9887830582998132

Epoch: 5| Step: 10
Training loss: 1.4821441173553467
Validation loss: 1.9482900275978992

Epoch: 222| Step: 0
Training loss: 1.154908299446106
Validation loss: 1.9238658412810294

Epoch: 5| Step: 1
Training loss: 0.9429367184638977
Validation loss: 1.8771011329466296

Epoch: 5| Step: 2
Training loss: 0.99029541015625
Validation loss: 1.876610290619635

Epoch: 5| Step: 3
Training loss: 2.1521780490875244
Validation loss: 1.8599191109339397

Epoch: 5| Step: 4
Training loss: 1.8797286748886108
Validation loss: 1.876175921450379

Epoch: 5| Step: 5
Training loss: 1.6757020950317383
Validation loss: 1.8826050578906972

Epoch: 5| Step: 6
Training loss: 1.5712149143218994
Validation loss: 1.9315291194505588

Epoch: 5| Step: 7
Training loss: 1.355655550956726
Validation loss: 1.9632320532234766

Epoch: 5| Step: 8
Training loss: 0.7044298052787781
Validation loss: 1.999880370273385

Epoch: 5| Step: 9
Training loss: 0.7541447281837463
Validation loss: 2.0708566378521662

Epoch: 5| Step: 10
Training loss: 1.0835671424865723
Validation loss: 2.0869892668980423

Epoch: 223| Step: 0
Training loss: 1.4852670431137085
Validation loss: 2.083067924745621

Epoch: 5| Step: 1
Training loss: 1.2852482795715332
Validation loss: 2.0797907870302916

Epoch: 5| Step: 2
Training loss: 1.7063640356063843
Validation loss: 2.0257403581373152

Epoch: 5| Step: 3
Training loss: 1.1018412113189697
Validation loss: 1.9567670911870978

Epoch: 5| Step: 4
Training loss: 1.6044574975967407
Validation loss: 1.9373985041854203

Epoch: 5| Step: 5
Training loss: 1.277121901512146
Validation loss: 1.9028134089644237

Epoch: 5| Step: 6
Training loss: 1.1451959609985352
Validation loss: 1.8890946744590678

Epoch: 5| Step: 7
Training loss: 1.5772957801818848
Validation loss: 1.8990289242036882

Epoch: 5| Step: 8
Training loss: 0.889983057975769
Validation loss: 1.8977377888976887

Epoch: 5| Step: 9
Training loss: 1.4594215154647827
Validation loss: 1.9171382304160827

Epoch: 5| Step: 10
Training loss: 0.8012580275535583
Validation loss: 1.9591783182595366

Epoch: 224| Step: 0
Training loss: 1.0377871990203857
Validation loss: 2.003087689799647

Epoch: 5| Step: 1
Training loss: 1.323097825050354
Validation loss: 2.004347426916963

Epoch: 5| Step: 2
Training loss: 1.3193585872650146
Validation loss: 1.9877741285549697

Epoch: 5| Step: 3
Training loss: 1.122861623764038
Validation loss: 1.9559748198396416

Epoch: 5| Step: 4
Training loss: 1.1726418733596802
Validation loss: 1.9664502002859627

Epoch: 5| Step: 5
Training loss: 1.2625154256820679
Validation loss: 1.9183910546764251

Epoch: 5| Step: 6
Training loss: 1.3258779048919678
Validation loss: 1.9068960553856307

Epoch: 5| Step: 7
Training loss: 1.4143755435943604
Validation loss: 1.899962148358745

Epoch: 5| Step: 8
Training loss: 1.800536870956421
Validation loss: 1.8888782916530487

Epoch: 5| Step: 9
Training loss: 1.4655201435089111
Validation loss: 1.8879371355938654

Epoch: 5| Step: 10
Training loss: 1.0947380065917969
Validation loss: 1.9210332824337868

Epoch: 225| Step: 0
Training loss: 1.2161781787872314
Validation loss: 1.9174004421439221

Epoch: 5| Step: 1
Training loss: 1.680415153503418
Validation loss: 1.9420803054686515

Epoch: 5| Step: 2
Training loss: 1.1237752437591553
Validation loss: 1.951262422787246

Epoch: 5| Step: 3
Training loss: 1.034608006477356
Validation loss: 1.9621881695203884

Epoch: 5| Step: 4
Training loss: 1.346287488937378
Validation loss: 1.9710461170442644

Epoch: 5| Step: 5
Training loss: 1.0715411901474
Validation loss: 2.0181348810913744

Epoch: 5| Step: 6
Training loss: 1.2501205205917358
Validation loss: 2.0008306452023086

Epoch: 5| Step: 7
Training loss: 1.501293420791626
Validation loss: 2.0133068561553955

Epoch: 5| Step: 8
Training loss: 1.6155474185943604
Validation loss: 1.975216632248253

Epoch: 5| Step: 9
Training loss: 1.0080217123031616
Validation loss: 1.966231776821998

Epoch: 5| Step: 10
Training loss: 1.0581145286560059
Validation loss: 1.9490759654711651

Epoch: 226| Step: 0
Training loss: 0.8769580721855164
Validation loss: 1.9435355612026748

Epoch: 5| Step: 1
Training loss: 1.1773821115493774
Validation loss: 1.9149865206851755

Epoch: 5| Step: 2
Training loss: 1.3157942295074463
Validation loss: 1.9140642176392257

Epoch: 5| Step: 3
Training loss: 1.0673891305923462
Validation loss: 1.9399162620626471

Epoch: 5| Step: 4
Training loss: 1.4072757959365845
Validation loss: 1.9447723306635374

Epoch: 5| Step: 5
Training loss: 0.9245868921279907
Validation loss: 1.9559824684614777

Epoch: 5| Step: 6
Training loss: 1.7662010192871094
Validation loss: 1.9996625890013993

Epoch: 5| Step: 7
Training loss: 1.2506942749023438
Validation loss: 2.0258485796631023

Epoch: 5| Step: 8
Training loss: 1.6580770015716553
Validation loss: 2.0429922637119087

Epoch: 5| Step: 9
Training loss: 1.5731593370437622
Validation loss: 2.033401991731377

Epoch: 5| Step: 10
Training loss: 0.9409366846084595
Validation loss: 2.0031516116152526

Epoch: 227| Step: 0
Training loss: 1.226442575454712
Validation loss: 1.964091782928795

Epoch: 5| Step: 1
Training loss: 1.4703582525253296
Validation loss: 1.9666754840522684

Epoch: 5| Step: 2
Training loss: 1.3303906917572021
Validation loss: 1.9371998976635676

Epoch: 5| Step: 3
Training loss: 0.9924281239509583
Validation loss: 1.9578522046407063

Epoch: 5| Step: 4
Training loss: 1.0805302858352661
Validation loss: 1.9696990546359812

Epoch: 5| Step: 5
Training loss: 1.326355218887329
Validation loss: 1.9611516050113145

Epoch: 5| Step: 6
Training loss: 1.5721580982208252
Validation loss: 1.9849588101910007

Epoch: 5| Step: 7
Training loss: 1.164107322692871
Validation loss: 1.9724988911741523

Epoch: 5| Step: 8
Training loss: 1.0283077955245972
Validation loss: 1.9958303205428585

Epoch: 5| Step: 9
Training loss: 1.4958034753799438
Validation loss: 1.996826438493626

Epoch: 5| Step: 10
Training loss: 0.839859664440155
Validation loss: 1.9753749139847294

Epoch: 228| Step: 0
Training loss: 1.2604209184646606
Validation loss: 1.9967917498721872

Epoch: 5| Step: 1
Training loss: 1.246525526046753
Validation loss: 1.9752580196626726

Epoch: 5| Step: 2
Training loss: 0.8857865333557129
Validation loss: 1.9501215591225574

Epoch: 5| Step: 3
Training loss: 1.0292937755584717
Validation loss: 1.9430985732745099

Epoch: 5| Step: 4
Training loss: 1.1164195537567139
Validation loss: 1.9500636259714763

Epoch: 5| Step: 5
Training loss: 1.531023383140564
Validation loss: 1.9785216367372902

Epoch: 5| Step: 6
Training loss: 1.3793504238128662
Validation loss: 1.9835308264660578

Epoch: 5| Step: 7
Training loss: 0.9690302014350891
Validation loss: 1.9776316586361136

Epoch: 5| Step: 8
Training loss: 1.0648930072784424
Validation loss: 1.9762141102103776

Epoch: 5| Step: 9
Training loss: 1.9141428470611572
Validation loss: 1.9466809495802848

Epoch: 5| Step: 10
Training loss: 0.8110800385475159
Validation loss: 1.9378680080495856

Epoch: 229| Step: 0
Training loss: 1.2324278354644775
Validation loss: 1.9342110182649346

Epoch: 5| Step: 1
Training loss: 0.969287097454071
Validation loss: 1.9139814607558712

Epoch: 5| Step: 2
Training loss: 1.0894606113433838
Validation loss: 1.9165725220916092

Epoch: 5| Step: 3
Training loss: 0.938266396522522
Validation loss: 1.946420677246586

Epoch: 5| Step: 4
Training loss: 0.8262326121330261
Validation loss: 1.9489727353536954

Epoch: 5| Step: 5
Training loss: 1.344388723373413
Validation loss: 1.952305782225824

Epoch: 5| Step: 6
Training loss: 1.2928351163864136
Validation loss: 1.9422541126128166

Epoch: 5| Step: 7
Training loss: 1.5750795602798462
Validation loss: 1.9538171829715851

Epoch: 5| Step: 8
Training loss: 1.09037184715271
Validation loss: 1.9577314456303914

Epoch: 5| Step: 9
Training loss: 1.4411871433258057
Validation loss: 1.974801701884116

Epoch: 5| Step: 10
Training loss: 1.2124148607254028
Validation loss: 1.9207212284047117

Epoch: 230| Step: 0
Training loss: 1.019113302230835
Validation loss: 1.9287564164848738

Epoch: 5| Step: 1
Training loss: 1.0370135307312012
Validation loss: 1.9358340770967546

Epoch: 5| Step: 2
Training loss: 1.4308524131774902
Validation loss: 1.9555112469580866

Epoch: 5| Step: 3
Training loss: 0.9371966123580933
Validation loss: 1.9397852164442821

Epoch: 5| Step: 4
Training loss: 1.4424184560775757
Validation loss: 1.9195827271348687

Epoch: 5| Step: 5
Training loss: 1.2857249975204468
Validation loss: 1.9134141065741097

Epoch: 5| Step: 6
Training loss: 1.0713084936141968
Validation loss: 1.9250011546637422

Epoch: 5| Step: 7
Training loss: 0.8580998182296753
Validation loss: 1.901681218096005

Epoch: 5| Step: 8
Training loss: 1.725042700767517
Validation loss: 1.8951103866741221

Epoch: 5| Step: 9
Training loss: 1.1800419092178345
Validation loss: 1.9211310494330622

Epoch: 5| Step: 10
Training loss: 1.1119900941848755
Validation loss: 1.9324300776245773

Epoch: 231| Step: 0
Training loss: 1.6043342351913452
Validation loss: 1.9580382224052184

Epoch: 5| Step: 1
Training loss: 0.8604044914245605
Validation loss: 1.9541954045654626

Epoch: 5| Step: 2
Training loss: 1.2262523174285889
Validation loss: 1.9609951562778924

Epoch: 5| Step: 3
Training loss: 0.8399669528007507
Validation loss: 1.9238663181181876

Epoch: 5| Step: 4
Training loss: 1.0084724426269531
Validation loss: 1.9370359220812399

Epoch: 5| Step: 5
Training loss: 1.2632917165756226
Validation loss: 1.933728297551473

Epoch: 5| Step: 6
Training loss: 1.6653449535369873
Validation loss: 1.9383223748976184

Epoch: 5| Step: 7
Training loss: 1.205101728439331
Validation loss: 1.9668961981291413

Epoch: 5| Step: 8
Training loss: 0.8427352905273438
Validation loss: 1.938332514096332

Epoch: 5| Step: 9
Training loss: 1.1312110424041748
Validation loss: 1.925299088160197

Epoch: 5| Step: 10
Training loss: 1.2108007669448853
Validation loss: 1.9223000772537724

Epoch: 232| Step: 0
Training loss: 1.0181812047958374
Validation loss: 1.933095319296724

Epoch: 5| Step: 1
Training loss: 0.6219112277030945
Validation loss: 1.9225503501071726

Epoch: 5| Step: 2
Training loss: 1.4031215906143188
Validation loss: 1.9345894936592347

Epoch: 5| Step: 3
Training loss: 1.3302987813949585
Validation loss: 1.992871779267506

Epoch: 5| Step: 4
Training loss: 0.860134482383728
Validation loss: 1.993206670207362

Epoch: 5| Step: 5
Training loss: 1.0768043994903564
Validation loss: 2.0137250449067805

Epoch: 5| Step: 6
Training loss: 1.0070055723190308
Validation loss: 2.0224223226629277

Epoch: 5| Step: 7
Training loss: 1.6120668649673462
Validation loss: 1.9898960590362549

Epoch: 5| Step: 8
Training loss: 1.7366702556610107
Validation loss: 1.9728886055689987

Epoch: 5| Step: 9
Training loss: 0.9298547506332397
Validation loss: 1.9411655138897639

Epoch: 5| Step: 10
Training loss: 1.0375092029571533
Validation loss: 1.919515053431193

Epoch: 233| Step: 0
Training loss: 1.1217539310455322
Validation loss: 1.9206338813227992

Epoch: 5| Step: 1
Training loss: 1.538461446762085
Validation loss: 1.9265907028669953

Epoch: 5| Step: 2
Training loss: 1.1688640117645264
Validation loss: 1.9176660212137366

Epoch: 5| Step: 3
Training loss: 1.0021588802337646
Validation loss: 1.99424869783463

Epoch: 5| Step: 4
Training loss: 1.219279170036316
Validation loss: 1.951694880762408

Epoch: 5| Step: 5
Training loss: 1.2435905933380127
Validation loss: 1.9596853845862932

Epoch: 5| Step: 6
Training loss: 1.1556437015533447
Validation loss: 1.94362671144547

Epoch: 5| Step: 7
Training loss: 0.9902139902114868
Validation loss: 1.9305456928027573

Epoch: 5| Step: 8
Training loss: 0.7445734739303589
Validation loss: 1.9220003440815916

Epoch: 5| Step: 9
Training loss: 1.261286973953247
Validation loss: 1.9336267850732292

Epoch: 5| Step: 10
Training loss: 1.421836256980896
Validation loss: 1.929609057723835

Epoch: 234| Step: 0
Training loss: 1.179633378982544
Validation loss: 1.9438481830781507

Epoch: 5| Step: 1
Training loss: 1.295912742614746
Validation loss: 1.889292223479158

Epoch: 5| Step: 2
Training loss: 1.193528413772583
Validation loss: 1.8906383258040234

Epoch: 5| Step: 3
Training loss: 0.9432099461555481
Validation loss: 1.894241786772205

Epoch: 5| Step: 4
Training loss: 1.1469045877456665
Validation loss: 1.9002638452796525

Epoch: 5| Step: 5
Training loss: 1.4017263650894165
Validation loss: 1.8963251165164414

Epoch: 5| Step: 6
Training loss: 1.0272877216339111
Validation loss: 1.960778990099507

Epoch: 5| Step: 7
Training loss: 1.4664061069488525
Validation loss: 1.984519035585465

Epoch: 5| Step: 8
Training loss: 1.3001232147216797
Validation loss: 2.011669297372141

Epoch: 5| Step: 9
Training loss: 1.0988364219665527
Validation loss: 2.0414006158869755

Epoch: 5| Step: 10
Training loss: 0.8241710066795349
Validation loss: 1.996366968718908

Epoch: 235| Step: 0
Training loss: 1.1500394344329834
Validation loss: 1.9798282064417356

Epoch: 5| Step: 1
Training loss: 0.8183432817459106
Validation loss: 1.9451374033445954

Epoch: 5| Step: 2
Training loss: 1.2527883052825928
Validation loss: 1.9090762035821074

Epoch: 5| Step: 3
Training loss: 1.0151176452636719
Validation loss: 1.917017081732391

Epoch: 5| Step: 4
Training loss: 1.1974639892578125
Validation loss: 1.9184928606915217

Epoch: 5| Step: 5
Training loss: 0.8201029896736145
Validation loss: 1.9063380738740325

Epoch: 5| Step: 6
Training loss: 0.8211110830307007
Validation loss: 1.9140916357758224

Epoch: 5| Step: 7
Training loss: 1.0832363367080688
Validation loss: 1.936102395416588

Epoch: 5| Step: 8
Training loss: 1.1782567501068115
Validation loss: 2.0409381722891204

Epoch: 5| Step: 9
Training loss: 1.5862716436386108
Validation loss: 2.079858164633474

Epoch: 5| Step: 10
Training loss: 1.7130812406539917
Validation loss: 2.0964466500025924

Epoch: 236| Step: 0
Training loss: 1.4092656373977661
Validation loss: 2.0970447627446984

Epoch: 5| Step: 1
Training loss: 1.3663324117660522
Validation loss: 2.061776707249303

Epoch: 5| Step: 2
Training loss: 1.1481719017028809
Validation loss: 1.987875086005016

Epoch: 5| Step: 3
Training loss: 1.1776511669158936
Validation loss: 1.95722399732118

Epoch: 5| Step: 4
Training loss: 0.6197373270988464
Validation loss: 1.9179272497853925

Epoch: 5| Step: 5
Training loss: 0.8818174600601196
Validation loss: 1.8682280996794343

Epoch: 5| Step: 6
Training loss: 1.5323470830917358
Validation loss: 1.8564059324161981

Epoch: 5| Step: 7
Training loss: 0.8759312629699707
Validation loss: 1.8389928276820848

Epoch: 5| Step: 8
Training loss: 1.7966419458389282
Validation loss: 1.8423706049560218

Epoch: 5| Step: 9
Training loss: 1.1732269525527954
Validation loss: 1.8432955716245918

Epoch: 5| Step: 10
Training loss: 0.6034995317459106
Validation loss: 1.862395235287246

Epoch: 237| Step: 0
Training loss: 1.5161677598953247
Validation loss: 1.8734026275655276

Epoch: 5| Step: 1
Training loss: 0.6940482258796692
Validation loss: 1.8951017664324852

Epoch: 5| Step: 2
Training loss: 1.2808839082717896
Validation loss: 1.9044437562265704

Epoch: 5| Step: 3
Training loss: 1.2561476230621338
Validation loss: 1.935708898369984

Epoch: 5| Step: 4
Training loss: 0.912089467048645
Validation loss: 1.917882050237348

Epoch: 5| Step: 5
Training loss: 1.0019285678863525
Validation loss: 1.908071482053367

Epoch: 5| Step: 6
Training loss: 0.5252877473831177
Validation loss: 1.8997865338479318

Epoch: 5| Step: 7
Training loss: 1.2255996465682983
Validation loss: 1.8768796254229803

Epoch: 5| Step: 8
Training loss: 1.3305784463882446
Validation loss: 1.8866769959849696

Epoch: 5| Step: 9
Training loss: 1.3507561683654785
Validation loss: 1.8776450746802873

Epoch: 5| Step: 10
Training loss: 1.063263177871704
Validation loss: 1.8977094132413146

Epoch: 238| Step: 0
Training loss: 0.956224799156189
Validation loss: 1.8864532670667093

Epoch: 5| Step: 1
Training loss: 1.4884485006332397
Validation loss: 1.8816110164888444

Epoch: 5| Step: 2
Training loss: 0.7780493497848511
Validation loss: 1.882583523309359

Epoch: 5| Step: 3
Training loss: 1.208206295967102
Validation loss: 1.8904957873846895

Epoch: 5| Step: 4
Training loss: 0.7983565926551819
Validation loss: 1.8884530503262755

Epoch: 5| Step: 5
Training loss: 1.3909690380096436
Validation loss: 1.9242282836667952

Epoch: 5| Step: 6
Training loss: 1.2548860311508179
Validation loss: 1.9257384859105593

Epoch: 5| Step: 7
Training loss: 0.9928320050239563
Validation loss: 1.9085013699787918

Epoch: 5| Step: 8
Training loss: 1.1844680309295654
Validation loss: 1.8914232946211291

Epoch: 5| Step: 9
Training loss: 0.8641252517700195
Validation loss: 1.8641661136381087

Epoch: 5| Step: 10
Training loss: 1.1599897146224976
Validation loss: 1.8695642153422039

Epoch: 239| Step: 0
Training loss: 0.8120707273483276
Validation loss: 1.8544788719505392

Epoch: 5| Step: 1
Training loss: 1.4094332456588745
Validation loss: 1.8679319773950884

Epoch: 5| Step: 2
Training loss: 1.2233974933624268
Validation loss: 1.8777216224260227

Epoch: 5| Step: 3
Training loss: 1.3578068017959595
Validation loss: 1.879254138597878

Epoch: 5| Step: 4
Training loss: 0.582525372505188
Validation loss: 1.9037998260990265

Epoch: 5| Step: 5
Training loss: 1.009805679321289
Validation loss: 1.8920490190547

Epoch: 5| Step: 6
Training loss: 1.3278175592422485
Validation loss: 1.9221942655501827

Epoch: 5| Step: 7
Training loss: 1.053082823753357
Validation loss: 1.93478565062246

Epoch: 5| Step: 8
Training loss: 1.04415762424469
Validation loss: 1.9840877671395578

Epoch: 5| Step: 9
Training loss: 1.33595609664917
Validation loss: 1.9863902266307543

Epoch: 5| Step: 10
Training loss: 0.9909349083900452
Validation loss: 1.9665836339355798

Epoch: 240| Step: 0
Training loss: 0.9976352453231812
Validation loss: 1.9204204120943624

Epoch: 5| Step: 1
Training loss: 1.4359445571899414
Validation loss: 1.906345804532369

Epoch: 5| Step: 2
Training loss: 1.1156235933303833
Validation loss: 1.8745647412474438

Epoch: 5| Step: 3
Training loss: 1.0891205072402954
Validation loss: 1.8547524175336283

Epoch: 5| Step: 4
Training loss: 0.7075744867324829
Validation loss: 1.8347636743258404

Epoch: 5| Step: 5
Training loss: 1.301743507385254
Validation loss: 1.852465045067572

Epoch: 5| Step: 6
Training loss: 0.9094762802124023
Validation loss: 1.859003154180383

Epoch: 5| Step: 7
Training loss: 1.220585823059082
Validation loss: 1.8530568550991755

Epoch: 5| Step: 8
Training loss: 0.5058442950248718
Validation loss: 1.867695257227908

Epoch: 5| Step: 9
Training loss: 1.4725964069366455
Validation loss: 1.8619384611806562

Epoch: 5| Step: 10
Training loss: 1.1613693237304688
Validation loss: 1.8491099444768762

Epoch: 241| Step: 0
Training loss: 0.7344821095466614
Validation loss: 1.8755470552752096

Epoch: 5| Step: 1
Training loss: 0.9847321510314941
Validation loss: 1.8561163102426836

Epoch: 5| Step: 2
Training loss: 1.092331051826477
Validation loss: 1.8629697715082476

Epoch: 5| Step: 3
Training loss: 0.8408920168876648
Validation loss: 1.8813185768742715

Epoch: 5| Step: 4
Training loss: 1.176353931427002
Validation loss: 1.8970609685426116

Epoch: 5| Step: 5
Training loss: 1.0914311408996582
Validation loss: 1.900592586045624

Epoch: 5| Step: 6
Training loss: 1.2309643030166626
Validation loss: 1.9397256989632883

Epoch: 5| Step: 7
Training loss: 1.245587706565857
Validation loss: 1.936105320530553

Epoch: 5| Step: 8
Training loss: 1.4050493240356445
Validation loss: 1.916604817554515

Epoch: 5| Step: 9
Training loss: 1.0776536464691162
Validation loss: 1.9028933214884933

Epoch: 5| Step: 10
Training loss: 1.0986931324005127
Validation loss: 1.8758294838731007

Epoch: 242| Step: 0
Training loss: 1.1269416809082031
Validation loss: 1.8791407026270384

Epoch: 5| Step: 1
Training loss: 0.8935152292251587
Validation loss: 1.8495557961925384

Epoch: 5| Step: 2
Training loss: 1.1779506206512451
Validation loss: 1.8871218222443775

Epoch: 5| Step: 3
Training loss: 1.171419620513916
Validation loss: 1.8790364380805724

Epoch: 5| Step: 4
Training loss: 1.2106621265411377
Validation loss: 1.895968185958042

Epoch: 5| Step: 5
Training loss: 1.0034139156341553
Validation loss: 1.9153325121889833

Epoch: 5| Step: 6
Training loss: 0.502953290939331
Validation loss: 1.935730859797488

Epoch: 5| Step: 7
Training loss: 0.9955245852470398
Validation loss: 1.9113823265157721

Epoch: 5| Step: 8
Training loss: 1.2613521814346313
Validation loss: 1.9234178386708742

Epoch: 5| Step: 9
Training loss: 1.2183473110198975
Validation loss: 1.93062122150134

Epoch: 5| Step: 10
Training loss: 1.2473151683807373
Validation loss: 1.928212042777769

Epoch: 243| Step: 0
Training loss: 1.1628012657165527
Validation loss: 1.9345032245882097

Epoch: 5| Step: 1
Training loss: 0.7808932662010193
Validation loss: 1.9121040105819702

Epoch: 5| Step: 2
Training loss: 0.6930879354476929
Validation loss: 1.9037006439701203

Epoch: 5| Step: 3
Training loss: 1.0784813165664673
Validation loss: 1.9248060205931306

Epoch: 5| Step: 4
Training loss: 0.47270864248275757
Validation loss: 1.8907447527813654

Epoch: 5| Step: 5
Training loss: 1.090993881225586
Validation loss: 1.8841066129745976

Epoch: 5| Step: 6
Training loss: 1.240545630455017
Validation loss: 1.9137397491803734

Epoch: 5| Step: 7
Training loss: 1.0132189989089966
Validation loss: 1.9321038094899987

Epoch: 5| Step: 8
Training loss: 1.3707071542739868
Validation loss: 1.9314550135725288

Epoch: 5| Step: 9
Training loss: 1.5383713245391846
Validation loss: 1.95201624208881

Epoch: 5| Step: 10
Training loss: 1.2496933937072754
Validation loss: 1.9314516103395851

Epoch: 244| Step: 0
Training loss: 1.3946492671966553
Validation loss: 1.8904639174861293

Epoch: 5| Step: 1
Training loss: 1.1198501586914062
Validation loss: 1.8929109034999725

Epoch: 5| Step: 2
Training loss: 0.9492691159248352
Validation loss: 1.9055300181911838

Epoch: 5| Step: 3
Training loss: 1.0767494440078735
Validation loss: 1.8722642608868179

Epoch: 5| Step: 4
Training loss: 1.017979383468628
Validation loss: 1.8953238418025355

Epoch: 5| Step: 5
Training loss: 1.1397888660430908
Validation loss: 1.8950856949693413

Epoch: 5| Step: 6
Training loss: 1.4387658834457397
Validation loss: 1.8720879298384472

Epoch: 5| Step: 7
Training loss: 0.6189044117927551
Validation loss: 1.8822409645203622

Epoch: 5| Step: 8
Training loss: 0.7408930063247681
Validation loss: 1.9020885857202674

Epoch: 5| Step: 9
Training loss: 0.8570283055305481
Validation loss: 1.8940279124885477

Epoch: 5| Step: 10
Training loss: 0.9047491550445557
Validation loss: 1.8922325257332093

Epoch: 245| Step: 0
Training loss: 0.8329582214355469
Validation loss: 1.890953565156588

Epoch: 5| Step: 1
Training loss: 0.5444804430007935
Validation loss: 1.8848645200011551

Epoch: 5| Step: 2
Training loss: 1.1578948497772217
Validation loss: 1.8807289292735438

Epoch: 5| Step: 3
Training loss: 1.2003999948501587
Validation loss: 1.8890156553637596

Epoch: 5| Step: 4
Training loss: 0.8664255142211914
Validation loss: 1.9033663195948447

Epoch: 5| Step: 5
Training loss: 1.0014314651489258
Validation loss: 1.8980504723005398

Epoch: 5| Step: 6
Training loss: 0.7561421394348145
Validation loss: 1.8655314932587326

Epoch: 5| Step: 7
Training loss: 1.1913549900054932
Validation loss: 1.8778946207415672

Epoch: 5| Step: 8
Training loss: 1.5029933452606201
Validation loss: 1.8609999905350387

Epoch: 5| Step: 9
Training loss: 1.0796349048614502
Validation loss: 1.885269872603878

Epoch: 5| Step: 10
Training loss: 1.1366090774536133
Validation loss: 1.8813669963549542

Epoch: 246| Step: 0
Training loss: 0.9555791020393372
Validation loss: 1.877544141584827

Epoch: 5| Step: 1
Training loss: 1.2250233888626099
Validation loss: 1.8788486911404518

Epoch: 5| Step: 2
Training loss: 0.5842159390449524
Validation loss: 1.86393323252278

Epoch: 5| Step: 3
Training loss: 0.9392492175102234
Validation loss: 1.8487081976347073

Epoch: 5| Step: 4
Training loss: 1.4286959171295166
Validation loss: 1.8816807282868253

Epoch: 5| Step: 5
Training loss: 1.579098105430603
Validation loss: 1.904056296553663

Epoch: 5| Step: 6
Training loss: 0.6142763495445251
Validation loss: 1.9055885602069158

Epoch: 5| Step: 7
Training loss: 1.0827019214630127
Validation loss: 1.9322966350022184

Epoch: 5| Step: 8
Training loss: 0.8214853405952454
Validation loss: 1.9184925684364893

Epoch: 5| Step: 9
Training loss: 1.180053472518921
Validation loss: 1.9106579634451097

Epoch: 5| Step: 10
Training loss: 1.0730667114257812
Validation loss: 1.951521058236399

Epoch: 247| Step: 0
Training loss: 0.9267681241035461
Validation loss: 1.945936176084703

Epoch: 5| Step: 1
Training loss: 0.620499312877655
Validation loss: 1.9114376562897877

Epoch: 5| Step: 2
Training loss: 1.5572993755340576
Validation loss: 1.8869408228064095

Epoch: 5| Step: 3
Training loss: 1.091252088546753
Validation loss: 1.8722112768439836

Epoch: 5| Step: 4
Training loss: 0.6588547825813293
Validation loss: 1.8611743783438077

Epoch: 5| Step: 5
Training loss: 0.8726387023925781
Validation loss: 1.8732759670544696

Epoch: 5| Step: 6
Training loss: 0.7900407910346985
Validation loss: 1.9001242012105963

Epoch: 5| Step: 7
Training loss: 1.050436019897461
Validation loss: 1.9386767674517889

Epoch: 5| Step: 8
Training loss: 1.0745044946670532
Validation loss: 1.9432792612301406

Epoch: 5| Step: 9
Training loss: 1.1886203289031982
Validation loss: 1.9594611096125778

Epoch: 5| Step: 10
Training loss: 1.3416547775268555
Validation loss: 1.9490650392347766

Epoch: 248| Step: 0
Training loss: 0.5113385319709778
Validation loss: 1.9202479098432808

Epoch: 5| Step: 1
Training loss: 1.4053207635879517
Validation loss: 1.94088541435939

Epoch: 5| Step: 2
Training loss: 0.9717405438423157
Validation loss: 1.8958972730944235

Epoch: 5| Step: 3
Training loss: 0.9760581851005554
Validation loss: 1.888954354870704

Epoch: 5| Step: 4
Training loss: 0.8887424468994141
Validation loss: 1.8804637244952622

Epoch: 5| Step: 5
Training loss: 1.2377949953079224
Validation loss: 1.873542288298248

Epoch: 5| Step: 6
Training loss: 0.910271167755127
Validation loss: 1.8833359890086676

Epoch: 5| Step: 7
Training loss: 0.9154966473579407
Validation loss: 1.8933667969960037

Epoch: 5| Step: 8
Training loss: 1.1653358936309814
Validation loss: 1.902841385974679

Epoch: 5| Step: 9
Training loss: 0.9456278085708618
Validation loss: 1.8875868499919932

Epoch: 5| Step: 10
Training loss: 1.1263476610183716
Validation loss: 1.8866132484969271

Epoch: 249| Step: 0
Training loss: 1.2966195344924927
Validation loss: 1.8455163137887114

Epoch: 5| Step: 1
Training loss: 0.7527533769607544
Validation loss: 1.863245048830586

Epoch: 5| Step: 2
Training loss: 0.9511003494262695
Validation loss: 1.833816151465139

Epoch: 5| Step: 3
Training loss: 1.7375562191009521
Validation loss: 1.8680598774263937

Epoch: 5| Step: 4
Training loss: 0.5808447599411011
Validation loss: 1.8357356543182044

Epoch: 5| Step: 5
Training loss: 0.8315284848213196
Validation loss: 1.8745121225234

Epoch: 5| Step: 6
Training loss: 0.7079788446426392
Validation loss: 1.9041093203329271

Epoch: 5| Step: 7
Training loss: 1.0282320976257324
Validation loss: 1.9316745663201937

Epoch: 5| Step: 8
Training loss: 0.8897765874862671
Validation loss: 1.9298392777801843

Epoch: 5| Step: 9
Training loss: 0.9938037991523743
Validation loss: 1.9263491502372168

Epoch: 5| Step: 10
Training loss: 1.061598777770996
Validation loss: 1.9108665681654406

Epoch: 250| Step: 0
Training loss: 0.9722267389297485
Validation loss: 1.9018942835510417

Epoch: 5| Step: 1
Training loss: 1.1215287446975708
Validation loss: 1.9126980484172862

Epoch: 5| Step: 2
Training loss: 1.055849313735962
Validation loss: 1.899112952652798

Epoch: 5| Step: 3
Training loss: 1.0672019720077515
Validation loss: 1.8847258219154932

Epoch: 5| Step: 4
Training loss: 1.1120933294296265
Validation loss: 1.8711810163272324

Epoch: 5| Step: 5
Training loss: 0.6508468389511108
Validation loss: 1.8379080193017119

Epoch: 5| Step: 6
Training loss: 0.7497372031211853
Validation loss: 1.8368831706303421

Epoch: 5| Step: 7
Training loss: 1.4653112888336182
Validation loss: 1.8346978707980084

Epoch: 5| Step: 8
Training loss: 0.8887909650802612
Validation loss: 1.8378624608439784

Epoch: 5| Step: 9
Training loss: 1.0388085842132568
Validation loss: 1.846533844547887

Epoch: 5| Step: 10
Training loss: 0.7602514028549194
Validation loss: 1.8525561594193982

Epoch: 251| Step: 0
Training loss: 1.1641417741775513
Validation loss: 1.853852577106927

Epoch: 5| Step: 1
Training loss: 1.3186650276184082
Validation loss: 1.8431072132561797

Epoch: 5| Step: 2
Training loss: 1.5969961881637573
Validation loss: 1.8315552742250505

Epoch: 5| Step: 3
Training loss: 0.6928342580795288
Validation loss: 1.8364361704036753

Epoch: 5| Step: 4
Training loss: 0.9922295808792114
Validation loss: 1.8399613800869192

Epoch: 5| Step: 5
Training loss: 0.9263140559196472
Validation loss: 1.858466358594997

Epoch: 5| Step: 6
Training loss: 0.6575900316238403
Validation loss: 1.8527270094040902

Epoch: 5| Step: 7
Training loss: 0.730455756187439
Validation loss: 1.8781595947921916

Epoch: 5| Step: 8
Training loss: 1.030516266822815
Validation loss: 1.8733359613726217

Epoch: 5| Step: 9
Training loss: 0.8940593004226685
Validation loss: 1.94185136723262

Epoch: 5| Step: 10
Training loss: 0.6410019993782043
Validation loss: 1.93245953641912

Epoch: 252| Step: 0
Training loss: 1.0259358882904053
Validation loss: 1.906450952253034

Epoch: 5| Step: 1
Training loss: 0.8534078598022461
Validation loss: 1.8807953903751988

Epoch: 5| Step: 2
Training loss: 1.0067851543426514
Validation loss: 1.8729156601813532

Epoch: 5| Step: 3
Training loss: 1.2789475917816162
Validation loss: 1.8688956409372308

Epoch: 5| Step: 4
Training loss: 0.8668511509895325
Validation loss: 1.8656816969635666

Epoch: 5| Step: 5
Training loss: 1.1074838638305664
Validation loss: 1.8349778793191398

Epoch: 5| Step: 6
Training loss: 0.6470783352851868
Validation loss: 1.9008634731333742

Epoch: 5| Step: 7
Training loss: 0.4375874102115631
Validation loss: 1.8564706412694787

Epoch: 5| Step: 8
Training loss: 1.2723968029022217
Validation loss: 1.868062860222273

Epoch: 5| Step: 9
Training loss: 1.2260687351226807
Validation loss: 1.8763965560543923

Epoch: 5| Step: 10
Training loss: 0.7976267337799072
Validation loss: 1.8778274174659484

Epoch: 253| Step: 0
Training loss: 0.5456703901290894
Validation loss: 1.8883708074528684

Epoch: 5| Step: 1
Training loss: 0.8628114461898804
Validation loss: 1.8654165434580978

Epoch: 5| Step: 2
Training loss: 0.8688139915466309
Validation loss: 1.8342481108121975

Epoch: 5| Step: 3
Training loss: 1.1525108814239502
Validation loss: 1.830626892787154

Epoch: 5| Step: 4
Training loss: 1.2226641178131104
Validation loss: 1.832948077109552

Epoch: 5| Step: 5
Training loss: 1.2823522090911865
Validation loss: 1.8439905399917274

Epoch: 5| Step: 6
Training loss: 0.9363749623298645
Validation loss: 1.8598223860545824

Epoch: 5| Step: 7
Training loss: 1.036786437034607
Validation loss: 1.8750687209508752

Epoch: 5| Step: 8
Training loss: 1.2879691123962402
Validation loss: 1.9235892898292952

Epoch: 5| Step: 9
Training loss: 0.7831813097000122
Validation loss: 1.9301074192088137

Epoch: 5| Step: 10
Training loss: 0.916615903377533
Validation loss: 1.9520971672509306

Epoch: 254| Step: 0
Training loss: 1.207884430885315
Validation loss: 1.9809183548855525

Epoch: 5| Step: 1
Training loss: 0.6955479383468628
Validation loss: 1.9250693423773653

Epoch: 5| Step: 2
Training loss: 0.8616085052490234
Validation loss: 1.8920637907520417

Epoch: 5| Step: 3
Training loss: 0.8044045567512512
Validation loss: 1.8771020930300477

Epoch: 5| Step: 4
Training loss: 0.7820060849189758
Validation loss: 1.8541470407157816

Epoch: 5| Step: 5
Training loss: 1.1704027652740479
Validation loss: 1.8503538216314008

Epoch: 5| Step: 6
Training loss: 0.8479554057121277
Validation loss: 1.8658821249520907

Epoch: 5| Step: 7
Training loss: 0.8347173929214478
Validation loss: 1.8650323126905708

Epoch: 5| Step: 8
Training loss: 1.075124740600586
Validation loss: 1.8601120748827535

Epoch: 5| Step: 9
Training loss: 0.9019386172294617
Validation loss: 1.8874645386972735

Epoch: 5| Step: 10
Training loss: 1.3450461626052856
Validation loss: 1.873789305328041

Epoch: 255| Step: 0
Training loss: 0.5109637379646301
Validation loss: 1.8822834132820048

Epoch: 5| Step: 1
Training loss: 0.878242015838623
Validation loss: 1.8879995833161056

Epoch: 5| Step: 2
Training loss: 1.2754414081573486
Validation loss: 1.8573943030449651

Epoch: 5| Step: 3
Training loss: 0.9328547716140747
Validation loss: 1.908182003164804

Epoch: 5| Step: 4
Training loss: 0.7977659106254578
Validation loss: 1.8875947626688148

Epoch: 5| Step: 5
Training loss: 0.9145331382751465
Validation loss: 1.9130750651000648

Epoch: 5| Step: 6
Training loss: 1.0050619840621948
Validation loss: 1.9090130021495204

Epoch: 5| Step: 7
Training loss: 0.9554575085639954
Validation loss: 1.906156111789006

Epoch: 5| Step: 8
Training loss: 1.2513960599899292
Validation loss: 1.9098044339046683

Epoch: 5| Step: 9
Training loss: 0.5445030927658081
Validation loss: 1.8823085779784827

Epoch: 5| Step: 10
Training loss: 1.0408252477645874
Validation loss: 1.8548741725183302

Epoch: 256| Step: 0
Training loss: 0.9287934303283691
Validation loss: 1.8286133145773282

Epoch: 5| Step: 1
Training loss: 1.2062329053878784
Validation loss: 1.848588987063336

Epoch: 5| Step: 2
Training loss: 0.7061632871627808
Validation loss: 1.816327856433007

Epoch: 5| Step: 3
Training loss: 0.9947745203971863
Validation loss: 1.810423320339572

Epoch: 5| Step: 4
Training loss: 0.9640199542045593
Validation loss: 1.8198476132526193

Epoch: 5| Step: 5
Training loss: 1.0354026556015015
Validation loss: 1.8415868487409366

Epoch: 5| Step: 6
Training loss: 1.1798821687698364
Validation loss: 1.8666031591353878

Epoch: 5| Step: 7
Training loss: 0.9726465344429016
Validation loss: 1.8936108799390896

Epoch: 5| Step: 8
Training loss: 0.8244592547416687
Validation loss: 1.8944075697211809

Epoch: 5| Step: 9
Training loss: 0.7000768780708313
Validation loss: 1.9167356452634257

Epoch: 5| Step: 10
Training loss: 0.43235695362091064
Validation loss: 1.9135342772288988

Epoch: 257| Step: 0
Training loss: 0.6739133596420288
Validation loss: 1.88733721035783

Epoch: 5| Step: 1
Training loss: 0.7172688245773315
Validation loss: 1.886793536524619

Epoch: 5| Step: 2
Training loss: 0.9235790371894836
Validation loss: 1.889071354302027

Epoch: 5| Step: 3
Training loss: 0.8247972726821899
Validation loss: 1.8468937976385957

Epoch: 5| Step: 4
Training loss: 0.7601259350776672
Validation loss: 1.8298974421716505

Epoch: 5| Step: 5
Training loss: 0.9471376538276672
Validation loss: 1.8379209618414603

Epoch: 5| Step: 6
Training loss: 0.908669114112854
Validation loss: 1.807780441417489

Epoch: 5| Step: 7
Training loss: 1.3303104639053345
Validation loss: 1.8314166966304983

Epoch: 5| Step: 8
Training loss: 1.114900827407837
Validation loss: 1.8394799360664942

Epoch: 5| Step: 9
Training loss: 0.7774933576583862
Validation loss: 1.8674796242867746

Epoch: 5| Step: 10
Training loss: 1.2941290140151978
Validation loss: 1.888585550810701

Epoch: 258| Step: 0
Training loss: 0.8900743722915649
Validation loss: 1.9227541928650231

Epoch: 5| Step: 1
Training loss: 1.169646978378296
Validation loss: 1.918428167220085

Epoch: 5| Step: 2
Training loss: 1.1298911571502686
Validation loss: 1.9211648343711771

Epoch: 5| Step: 3
Training loss: 0.7418841123580933
Validation loss: 1.90612288700637

Epoch: 5| Step: 4
Training loss: 0.5513501763343811
Validation loss: 1.918129071112602

Epoch: 5| Step: 5
Training loss: 0.7078033685684204
Validation loss: 1.915675941333976

Epoch: 5| Step: 6
Training loss: 1.626755714416504
Validation loss: 1.8937188668917584

Epoch: 5| Step: 7
Training loss: 1.3163254261016846
Validation loss: 1.8802027420331073

Epoch: 5| Step: 8
Training loss: 0.7236788868904114
Validation loss: 1.8493545811663392

Epoch: 5| Step: 9
Training loss: 1.0316489934921265
Validation loss: 1.8279547050435057

Epoch: 5| Step: 10
Training loss: 0.7369434237480164
Validation loss: 1.81804903604651

Epoch: 259| Step: 0
Training loss: 1.0089104175567627
Validation loss: 1.8306750623128747

Epoch: 5| Step: 1
Training loss: 1.5706360340118408
Validation loss: 1.8278316195293138

Epoch: 5| Step: 2
Training loss: 0.7857991456985474
Validation loss: 1.8448746371012863

Epoch: 5| Step: 3
Training loss: 0.8263337016105652
Validation loss: 1.874676037860173

Epoch: 5| Step: 4
Training loss: 1.1201565265655518
Validation loss: 1.9059196569586312

Epoch: 5| Step: 5
Training loss: 1.3769214153289795
Validation loss: 1.9496860734878048

Epoch: 5| Step: 6
Training loss: 0.9161157608032227
Validation loss: 2.0101007069310834

Epoch: 5| Step: 7
Training loss: 1.0361716747283936
Validation loss: 1.9912369481978878

Epoch: 5| Step: 8
Training loss: 0.5581604242324829
Validation loss: 1.9135115761910715

Epoch: 5| Step: 9
Training loss: 0.7408722639083862
Validation loss: 1.8952334247609621

Epoch: 5| Step: 10
Training loss: 0.6424552202224731
Validation loss: 1.8813274688618158

Epoch: 260| Step: 0
Training loss: 1.0146452188491821
Validation loss: 1.8634507861188663

Epoch: 5| Step: 1
Training loss: 0.9556735754013062
Validation loss: 1.8731991014172953

Epoch: 5| Step: 2
Training loss: 0.6570087671279907
Validation loss: 1.8821267697118944

Epoch: 5| Step: 3
Training loss: 1.2543551921844482
Validation loss: 1.9054785441326838

Epoch: 5| Step: 4
Training loss: 0.9365194439888
Validation loss: 1.8686136725128337

Epoch: 5| Step: 5
Training loss: 0.8688627481460571
Validation loss: 1.8751505767145464

Epoch: 5| Step: 6
Training loss: 1.3900846242904663
Validation loss: 1.899165702122514

Epoch: 5| Step: 7
Training loss: 0.6928568482398987
Validation loss: 1.8708842108326573

Epoch: 5| Step: 8
Training loss: 1.0641372203826904
Validation loss: 1.8882203230293848

Epoch: 5| Step: 9
Training loss: 0.6765210628509521
Validation loss: 1.8834006709437217

Epoch: 5| Step: 10
Training loss: 0.9481305480003357
Validation loss: 1.8861370137942735

Epoch: 261| Step: 0
Training loss: 1.0122721195220947
Validation loss: 1.883990164726011

Epoch: 5| Step: 1
Training loss: 0.531063973903656
Validation loss: 1.88849635406207

Epoch: 5| Step: 2
Training loss: 1.2533570528030396
Validation loss: 1.8950232677562262

Epoch: 5| Step: 3
Training loss: 0.7244107127189636
Validation loss: 1.879247324441069

Epoch: 5| Step: 4
Training loss: 0.9383255839347839
Validation loss: 1.893759701841621

Epoch: 5| Step: 5
Training loss: 1.1244781017303467
Validation loss: 1.8930070105419363

Epoch: 5| Step: 6
Training loss: 0.9360576868057251
Validation loss: 1.9344661633173625

Epoch: 5| Step: 7
Training loss: 0.6290996670722961
Validation loss: 1.9044920411161197

Epoch: 5| Step: 8
Training loss: 1.0731291770935059
Validation loss: 1.9250534157599173

Epoch: 5| Step: 9
Training loss: 0.9148209691047668
Validation loss: 1.9168361925309705

Epoch: 5| Step: 10
Training loss: 0.9413301944732666
Validation loss: 1.8763121776683356

Epoch: 262| Step: 0
Training loss: 0.5858570337295532
Validation loss: 1.8679244261915966

Epoch: 5| Step: 1
Training loss: 0.8798737525939941
Validation loss: 1.8307888046387704

Epoch: 5| Step: 2
Training loss: 1.2584110498428345
Validation loss: 1.8191821408528153

Epoch: 5| Step: 3
Training loss: 0.9436833262443542
Validation loss: 1.8057574764374764

Epoch: 5| Step: 4
Training loss: 1.2035977840423584
Validation loss: 1.8068850104526808

Epoch: 5| Step: 5
Training loss: 0.7513061761856079
Validation loss: 1.8050198426810644

Epoch: 5| Step: 6
Training loss: 0.8179519772529602
Validation loss: 1.8222710329999205

Epoch: 5| Step: 7
Training loss: 0.6849755048751831
Validation loss: 1.8378542328393588

Epoch: 5| Step: 8
Training loss: 0.9917734265327454
Validation loss: 1.8632387307382399

Epoch: 5| Step: 9
Training loss: 0.8418649435043335
Validation loss: 1.8824882468869608

Epoch: 5| Step: 10
Training loss: 0.9265775680541992
Validation loss: 1.90712696249767

Epoch: 263| Step: 0
Training loss: 0.6787439584732056
Validation loss: 1.940755885134461

Epoch: 5| Step: 1
Training loss: 1.138245701789856
Validation loss: 1.909910660918041

Epoch: 5| Step: 2
Training loss: 1.2834068536758423
Validation loss: 1.9490389259912635

Epoch: 5| Step: 3
Training loss: 0.5861808061599731
Validation loss: 1.939097512152887

Epoch: 5| Step: 4
Training loss: 0.6617883443832397
Validation loss: 1.8979304939187982

Epoch: 5| Step: 5
Training loss: 0.6956197023391724
Validation loss: 1.8618385343141453

Epoch: 5| Step: 6
Training loss: 0.7954005002975464
Validation loss: 1.8579547315515497

Epoch: 5| Step: 7
Training loss: 0.6767041683197021
Validation loss: 1.832094354014243

Epoch: 5| Step: 8
Training loss: 0.8784897923469543
Validation loss: 1.8424399078533213

Epoch: 5| Step: 9
Training loss: 1.2986751794815063
Validation loss: 1.8666404921521422

Epoch: 5| Step: 10
Training loss: 1.10330331325531
Validation loss: 1.8724994620969218

Epoch: 264| Step: 0
Training loss: 0.7790309190750122
Validation loss: 1.8599221398753505

Epoch: 5| Step: 1
Training loss: 0.7218092679977417
Validation loss: 1.8829877491920226

Epoch: 5| Step: 2
Training loss: 0.9799352884292603
Validation loss: 1.8479363879849833

Epoch: 5| Step: 3
Training loss: 0.8909150958061218
Validation loss: 1.835651454105172

Epoch: 5| Step: 4
Training loss: 0.7956470251083374
Validation loss: 1.8182444751903575

Epoch: 5| Step: 5
Training loss: 0.8871981501579285
Validation loss: 1.8291922717966058

Epoch: 5| Step: 6
Training loss: 1.0277105569839478
Validation loss: 1.8618985760596491

Epoch: 5| Step: 7
Training loss: 0.7841030359268188
Validation loss: 1.861895949609818

Epoch: 5| Step: 8
Training loss: 0.9605660438537598
Validation loss: 1.9219654888235114

Epoch: 5| Step: 9
Training loss: 1.077617883682251
Validation loss: 1.9274494981253019

Epoch: 5| Step: 10
Training loss: 0.6822177767753601
Validation loss: 1.8680248375861876

Epoch: 265| Step: 0
Training loss: 0.8686797022819519
Validation loss: 1.8480363956061743

Epoch: 5| Step: 1
Training loss: 0.6304144263267517
Validation loss: 1.8253648499006867

Epoch: 5| Step: 2
Training loss: 0.9438130259513855
Validation loss: 1.8190144210733392

Epoch: 5| Step: 3
Training loss: 0.8713051676750183
Validation loss: 1.8181454955890615

Epoch: 5| Step: 4
Training loss: 0.5677459836006165
Validation loss: 1.8187639892742198

Epoch: 5| Step: 5
Training loss: 1.0644639730453491
Validation loss: 1.8111316645017235

Epoch: 5| Step: 6
Training loss: 0.5995368361473083
Validation loss: 1.8361185263561945

Epoch: 5| Step: 7
Training loss: 0.9957146644592285
Validation loss: 1.8697283062883603

Epoch: 5| Step: 8
Training loss: 0.7319434285163879
Validation loss: 1.844908078511556

Epoch: 5| Step: 9
Training loss: 1.0923268795013428
Validation loss: 1.8666139289896975

Epoch: 5| Step: 10
Training loss: 1.0896697044372559
Validation loss: 1.8748850873721543

Epoch: 266| Step: 0
Training loss: 0.7686874270439148
Validation loss: 1.8545517152355564

Epoch: 5| Step: 1
Training loss: 0.709286093711853
Validation loss: 1.8902364264252365

Epoch: 5| Step: 2
Training loss: 0.9519259333610535
Validation loss: 1.8963962370349514

Epoch: 5| Step: 3
Training loss: 0.7775325775146484
Validation loss: 1.9083042606230705

Epoch: 5| Step: 4
Training loss: 1.0565284490585327
Validation loss: 1.896127580314554

Epoch: 5| Step: 5
Training loss: 0.8562583923339844
Validation loss: 1.892451513198114

Epoch: 5| Step: 6
Training loss: 0.8170255422592163
Validation loss: 1.9018726143785702

Epoch: 5| Step: 7
Training loss: 0.8684039115905762
Validation loss: 1.8948710374934699

Epoch: 5| Step: 8
Training loss: 0.769067645072937
Validation loss: 1.886653648909702

Epoch: 5| Step: 9
Training loss: 0.9149402379989624
Validation loss: 1.858032500872048

Epoch: 5| Step: 10
Training loss: 0.9146502017974854
Validation loss: 1.8846530093941638

Epoch: 267| Step: 0
Training loss: 1.1312429904937744
Validation loss: 1.8968606815543225

Epoch: 5| Step: 1
Training loss: 0.9475935101509094
Validation loss: 1.8796892358410744

Epoch: 5| Step: 2
Training loss: 0.6231728792190552
Validation loss: 1.8798146965683147

Epoch: 5| Step: 3
Training loss: 0.6369228959083557
Validation loss: 1.8818462458989953

Epoch: 5| Step: 4
Training loss: 0.7961148023605347
Validation loss: 1.8681606977216658

Epoch: 5| Step: 5
Training loss: 0.894233226776123
Validation loss: 1.8449130032652168

Epoch: 5| Step: 6
Training loss: 1.143550157546997
Validation loss: 1.8386086033236595

Epoch: 5| Step: 7
Training loss: 0.9328166246414185
Validation loss: 1.8480265627625168

Epoch: 5| Step: 8
Training loss: 0.46158847212791443
Validation loss: 1.8467762418972549

Epoch: 5| Step: 9
Training loss: 1.0220654010772705
Validation loss: 1.8460494369588873

Epoch: 5| Step: 10
Training loss: 0.7362125515937805
Validation loss: 1.8313250785232873

Epoch: 268| Step: 0
Training loss: 0.8305222392082214
Validation loss: 1.8393090309635285

Epoch: 5| Step: 1
Training loss: 0.5830408930778503
Validation loss: 1.8209750754858858

Epoch: 5| Step: 2
Training loss: 0.6363333463668823
Validation loss: 1.8139830635439964

Epoch: 5| Step: 3
Training loss: 0.8469617962837219
Validation loss: 1.8266423530476068

Epoch: 5| Step: 4
Training loss: 0.6422396302223206
Validation loss: 1.8394261149949924

Epoch: 5| Step: 5
Training loss: 0.7926478385925293
Validation loss: 1.8456551259563816

Epoch: 5| Step: 6
Training loss: 1.4439818859100342
Validation loss: 1.851576191122814

Epoch: 5| Step: 7
Training loss: 0.7262219190597534
Validation loss: 1.8395932797462708

Epoch: 5| Step: 8
Training loss: 0.9860053062438965
Validation loss: 1.860385182083294

Epoch: 5| Step: 9
Training loss: 0.6701050996780396
Validation loss: 1.8850989572463497

Epoch: 5| Step: 10
Training loss: 1.2613394260406494
Validation loss: 1.8623757849457443

Epoch: 269| Step: 0
Training loss: 0.4747026562690735
Validation loss: 1.8586580035507039

Epoch: 5| Step: 1
Training loss: 0.8608016967773438
Validation loss: 1.8623258708625712

Epoch: 5| Step: 2
Training loss: 0.819123387336731
Validation loss: 1.8302267161748742

Epoch: 5| Step: 3
Training loss: 1.2370481491088867
Validation loss: 1.8733118708415697

Epoch: 5| Step: 4
Training loss: 1.2327499389648438
Validation loss: 1.8619496489083895

Epoch: 5| Step: 5
Training loss: 0.5772035121917725
Validation loss: 1.8607426920244772

Epoch: 5| Step: 6
Training loss: 0.683911919593811
Validation loss: 1.8808817940373574

Epoch: 5| Step: 7
Training loss: 0.7535431981086731
Validation loss: 1.8935783152939172

Epoch: 5| Step: 8
Training loss: 0.7065460681915283
Validation loss: 1.8975004034657632

Epoch: 5| Step: 9
Training loss: 0.7390263676643372
Validation loss: 1.9325286021796606

Epoch: 5| Step: 10
Training loss: 0.9776612520217896
Validation loss: 1.8640225497625207

Epoch: 270| Step: 0
Training loss: 0.5321301817893982
Validation loss: 1.857071102306407

Epoch: 5| Step: 1
Training loss: 0.8636391758918762
Validation loss: 1.8237365368873841

Epoch: 5| Step: 2
Training loss: 0.8624687194824219
Validation loss: 1.800922260489515

Epoch: 5| Step: 3
Training loss: 1.0898221731185913
Validation loss: 1.8088439741442282

Epoch: 5| Step: 4
Training loss: 0.529854953289032
Validation loss: 1.7886062783579673

Epoch: 5| Step: 5
Training loss: 0.9279979467391968
Validation loss: 1.7850621284977082

Epoch: 5| Step: 6
Training loss: 1.0958021879196167
Validation loss: 1.7816574893971926

Epoch: 5| Step: 7
Training loss: 0.8359559774398804
Validation loss: 1.8069177058435255

Epoch: 5| Step: 8
Training loss: 0.6271377801895142
Validation loss: 1.8315025862827097

Epoch: 5| Step: 9
Training loss: 1.052363634109497
Validation loss: 1.860349150114162

Epoch: 5| Step: 10
Training loss: 0.8503939509391785
Validation loss: 1.9046934894336167

Epoch: 271| Step: 0
Training loss: 0.8013431429862976
Validation loss: 1.9811818420246083

Epoch: 5| Step: 1
Training loss: 1.116605520248413
Validation loss: 2.0595537898361043

Epoch: 5| Step: 2
Training loss: 0.9915933609008789
Validation loss: 1.9856978949680124

Epoch: 5| Step: 3
Training loss: 0.8132722973823547
Validation loss: 1.959022310472304

Epoch: 5| Step: 4
Training loss: 0.45810016989707947
Validation loss: 1.8992721483271608

Epoch: 5| Step: 5
Training loss: 0.4435478150844574
Validation loss: 1.8614247870701615

Epoch: 5| Step: 6
Training loss: 0.7992986440658569
Validation loss: 1.8188883014904556

Epoch: 5| Step: 7
Training loss: 0.9608775973320007
Validation loss: 1.8103884586723902

Epoch: 5| Step: 8
Training loss: 0.7596554756164551
Validation loss: 1.8048524638657928

Epoch: 5| Step: 9
Training loss: 1.1543776988983154
Validation loss: 1.7806023628480974

Epoch: 5| Step: 10
Training loss: 0.8278205394744873
Validation loss: 1.8032535147923294

Epoch: 272| Step: 0
Training loss: 0.48933181166648865
Validation loss: 1.8299735925530876

Epoch: 5| Step: 1
Training loss: 0.6195210814476013
Validation loss: 1.825297773525279

Epoch: 5| Step: 2
Training loss: 0.6695772409439087
Validation loss: 1.8357011925789617

Epoch: 5| Step: 3
Training loss: 0.8124963641166687
Validation loss: 1.8622914411688363

Epoch: 5| Step: 4
Training loss: 0.6637970209121704
Validation loss: 1.8676458712547057

Epoch: 5| Step: 5
Training loss: 0.9848442077636719
Validation loss: 1.845589449328761

Epoch: 5| Step: 6
Training loss: 0.7093089818954468
Validation loss: 1.8469456062521985

Epoch: 5| Step: 7
Training loss: 1.20796537399292
Validation loss: 1.8301596359540058

Epoch: 5| Step: 8
Training loss: 0.9273017644882202
Validation loss: 1.829204156834592

Epoch: 5| Step: 9
Training loss: 0.29976215958595276
Validation loss: 1.8184148624379148

Epoch: 5| Step: 10
Training loss: 1.171106219291687
Validation loss: 1.8217111813124789

Epoch: 273| Step: 0
Training loss: 0.4767003059387207
Validation loss: 1.8649194214933662

Epoch: 5| Step: 1
Training loss: 0.6937204003334045
Validation loss: 1.8478477821555188

Epoch: 5| Step: 2
Training loss: 0.8502939343452454
Validation loss: 1.8842112992399482

Epoch: 5| Step: 3
Training loss: 0.7753505706787109
Validation loss: 1.8909039074374783

Epoch: 5| Step: 4
Training loss: 0.6347764730453491
Validation loss: 1.8620011601396786

Epoch: 5| Step: 5
Training loss: 0.9582330584526062
Validation loss: 1.8332821258934595

Epoch: 5| Step: 6
Training loss: 0.7046718001365662
Validation loss: 1.8156645041640087

Epoch: 5| Step: 7
Training loss: 1.162399172782898
Validation loss: 1.8185299032477922

Epoch: 5| Step: 8
Training loss: 0.6572754979133606
Validation loss: 1.8321024820368776

Epoch: 5| Step: 9
Training loss: 0.7334448099136353
Validation loss: 1.8108352794442126

Epoch: 5| Step: 10
Training loss: 0.8483975529670715
Validation loss: 1.829916710494667

Epoch: 274| Step: 0
Training loss: 0.9803459048271179
Validation loss: 1.8303324791692919

Epoch: 5| Step: 1
Training loss: 1.1757023334503174
Validation loss: 1.8499472397629932

Epoch: 5| Step: 2
Training loss: 0.5232327580451965
Validation loss: 1.8766955355162263

Epoch: 5| Step: 3
Training loss: 0.7539361715316772
Validation loss: 1.8818454588613203

Epoch: 5| Step: 4
Training loss: 0.856950581073761
Validation loss: 1.9093201967977709

Epoch: 5| Step: 5
Training loss: 0.800148606300354
Validation loss: 1.9028921716956682

Epoch: 5| Step: 6
Training loss: 0.5200084447860718
Validation loss: 1.8871292760295253

Epoch: 5| Step: 7
Training loss: 0.8697083592414856
Validation loss: 1.882835006201139

Epoch: 5| Step: 8
Training loss: 0.4833751320838928
Validation loss: 1.8601848053675827

Epoch: 5| Step: 9
Training loss: 0.8048096895217896
Validation loss: 1.845293152716852

Epoch: 5| Step: 10
Training loss: 0.724111795425415
Validation loss: 1.844805637995402

Epoch: 275| Step: 0
Training loss: 0.6656931638717651
Validation loss: 1.8033890275545017

Epoch: 5| Step: 1
Training loss: 0.7840067148208618
Validation loss: 1.8078942798799085

Epoch: 5| Step: 2
Training loss: 0.5384419560432434
Validation loss: 1.8391108538514824

Epoch: 5| Step: 3
Training loss: 0.5030989646911621
Validation loss: 1.8411571453976374

Epoch: 5| Step: 4
Training loss: 0.8573794364929199
Validation loss: 1.86415445932778

Epoch: 5| Step: 5
Training loss: 0.6646913290023804
Validation loss: 1.8683355674948743

Epoch: 5| Step: 6
Training loss: 0.9078415036201477
Validation loss: 1.894601034861739

Epoch: 5| Step: 7
Training loss: 0.5260237455368042
Validation loss: 1.898147948326603

Epoch: 5| Step: 8
Training loss: 0.7354825139045715
Validation loss: 1.892222405761801

Epoch: 5| Step: 9
Training loss: 1.0278525352478027
Validation loss: 1.875469010363343

Epoch: 5| Step: 10
Training loss: 1.140355110168457
Validation loss: 1.8052234303566717

Epoch: 276| Step: 0
Training loss: 0.4766360819339752
Validation loss: 1.8039713380157307

Epoch: 5| Step: 1
Training loss: 0.5261350870132446
Validation loss: 1.7908970591842488

Epoch: 5| Step: 2
Training loss: 0.605905294418335
Validation loss: 1.8070265413612447

Epoch: 5| Step: 3
Training loss: 1.2121202945709229
Validation loss: 1.809904706093573

Epoch: 5| Step: 4
Training loss: 0.728357195854187
Validation loss: 1.8127102031502673

Epoch: 5| Step: 5
Training loss: 0.6660152077674866
Validation loss: 1.830617465639627

Epoch: 5| Step: 6
Training loss: 0.5558112859725952
Validation loss: 1.8253990296394593

Epoch: 5| Step: 7
Training loss: 0.9914695024490356
Validation loss: 1.829538227409445

Epoch: 5| Step: 8
Training loss: 1.231637716293335
Validation loss: 1.8652561736363236

Epoch: 5| Step: 9
Training loss: 0.5282524228096008
Validation loss: 1.8932576666596115

Epoch: 5| Step: 10
Training loss: 0.6972936391830444
Validation loss: 1.8837373102864912

Epoch: 277| Step: 0
Training loss: 0.5916957855224609
Validation loss: 1.8697034902470087

Epoch: 5| Step: 1
Training loss: 0.4898134171962738
Validation loss: 1.8535639060440885

Epoch: 5| Step: 2
Training loss: 0.4599180817604065
Validation loss: 1.8535626767784037

Epoch: 5| Step: 3
Training loss: 1.3622432947158813
Validation loss: 1.849186489658971

Epoch: 5| Step: 4
Training loss: 0.6048527359962463
Validation loss: 1.7643904750065138

Epoch: 5| Step: 5
Training loss: 0.7057477831840515
Validation loss: 1.779034750435942

Epoch: 5| Step: 6
Training loss: 0.6652138233184814
Validation loss: 1.7819359276884346

Epoch: 5| Step: 7
Training loss: 1.030905842781067
Validation loss: 1.7577622769981303

Epoch: 5| Step: 8
Training loss: 0.6958826184272766
Validation loss: 1.7884326980959984

Epoch: 5| Step: 9
Training loss: 0.8224605321884155
Validation loss: 1.7753420824645667

Epoch: 5| Step: 10
Training loss: 0.7190478444099426
Validation loss: 1.7968161298382668

Epoch: 278| Step: 0
Training loss: 0.9328719973564148
Validation loss: 1.7716226347031132

Epoch: 5| Step: 1
Training loss: 0.8497210741043091
Validation loss: 1.788663810940199

Epoch: 5| Step: 2
Training loss: 0.628646969795227
Validation loss: 1.796425046459321

Epoch: 5| Step: 3
Training loss: 0.5886390805244446
Validation loss: 1.86268025700764

Epoch: 5| Step: 4
Training loss: 0.47645169496536255
Validation loss: 1.8787852051437541

Epoch: 5| Step: 5
Training loss: 0.6215071678161621
Validation loss: 1.90235290732435

Epoch: 5| Step: 6
Training loss: 1.0577819347381592
Validation loss: 1.9075125212310462

Epoch: 5| Step: 7
Training loss: 0.8131707906723022
Validation loss: 1.8856439616090508

Epoch: 5| Step: 8
Training loss: 0.721268892288208
Validation loss: 1.879360209229172

Epoch: 5| Step: 9
Training loss: 0.3535647988319397
Validation loss: 1.8533074714804207

Epoch: 5| Step: 10
Training loss: 1.0250970125198364
Validation loss: 1.8354300632271716

Epoch: 279| Step: 0
Training loss: 0.7908545732498169
Validation loss: 1.8194724308547152

Epoch: 5| Step: 1
Training loss: 1.1198148727416992
Validation loss: 1.8217438792669645

Epoch: 5| Step: 2
Training loss: 0.8279032707214355
Validation loss: 1.8199575421630696

Epoch: 5| Step: 3
Training loss: 0.55534428358078
Validation loss: 1.805203563423567

Epoch: 5| Step: 4
Training loss: 0.9758380055427551
Validation loss: 1.806005738114798

Epoch: 5| Step: 5
Training loss: 0.8367033004760742
Validation loss: 1.8099745319735618

Epoch: 5| Step: 6
Training loss: 0.2706364095211029
Validation loss: 1.8128071882391488

Epoch: 5| Step: 7
Training loss: 0.6386892199516296
Validation loss: 1.8460725725338023

Epoch: 5| Step: 8
Training loss: 1.0086209774017334
Validation loss: 1.8586006779824533

Epoch: 5| Step: 9
Training loss: 0.7191984057426453
Validation loss: 1.859601911678109

Epoch: 5| Step: 10
Training loss: 0.5326776504516602
Validation loss: 1.8505881371036652

Epoch: 280| Step: 0
Training loss: 0.5633441209793091
Validation loss: 1.831434795933385

Epoch: 5| Step: 1
Training loss: 0.6751319169998169
Validation loss: 1.813888701059485

Epoch: 5| Step: 2
Training loss: 0.9596023559570312
Validation loss: 1.7776249941959177

Epoch: 5| Step: 3
Training loss: 1.1193150281906128
Validation loss: 1.7719428295730262

Epoch: 5| Step: 4
Training loss: 0.49520978331565857
Validation loss: 1.7732079003446846

Epoch: 5| Step: 5
Training loss: 0.5327579975128174
Validation loss: 1.7846817457547752

Epoch: 5| Step: 6
Training loss: 0.6490049362182617
Validation loss: 1.758902531798168

Epoch: 5| Step: 7
Training loss: 0.6966272592544556
Validation loss: 1.789124934904037

Epoch: 5| Step: 8
Training loss: 1.0208523273468018
Validation loss: 1.787676727899941

Epoch: 5| Step: 9
Training loss: 0.5995020270347595
Validation loss: 1.8041642583826536

Epoch: 5| Step: 10
Training loss: 0.6147697567939758
Validation loss: 1.838798576785672

Epoch: 281| Step: 0
Training loss: 0.7036172151565552
Validation loss: 1.8420068102498208

Epoch: 5| Step: 1
Training loss: 0.7458370327949524
Validation loss: 1.8432959100251556

Epoch: 5| Step: 2
Training loss: 0.7164229154586792
Validation loss: 1.8166498561059274

Epoch: 5| Step: 3
Training loss: 0.6883339881896973
Validation loss: 1.7848372523502638

Epoch: 5| Step: 4
Training loss: 0.533374011516571
Validation loss: 1.7739463980479906

Epoch: 5| Step: 5
Training loss: 0.49249330163002014
Validation loss: 1.7946634395148164

Epoch: 5| Step: 6
Training loss: 0.7536142468452454
Validation loss: 1.7802883284066313

Epoch: 5| Step: 7
Training loss: 0.994213879108429
Validation loss: 1.7719895378235848

Epoch: 5| Step: 8
Training loss: 0.6891672611236572
Validation loss: 1.7745985318255681

Epoch: 5| Step: 9
Training loss: 0.9765183329582214
Validation loss: 1.7975113327785204

Epoch: 5| Step: 10
Training loss: 0.8231121301651001
Validation loss: 1.7761516917136408

Epoch: 282| Step: 0
Training loss: 0.6576394438743591
Validation loss: 1.7577034196546

Epoch: 5| Step: 1
Training loss: 0.7729185223579407
Validation loss: 1.7721671853014218

Epoch: 5| Step: 2
Training loss: 0.4056243300437927
Validation loss: 1.7765446529593518

Epoch: 5| Step: 3
Training loss: 0.6128926277160645
Validation loss: 1.778892469662492

Epoch: 5| Step: 4
Training loss: 0.8164962530136108
Validation loss: 1.7549109792196622

Epoch: 5| Step: 5
Training loss: 0.9482776522636414
Validation loss: 1.7772500284256474

Epoch: 5| Step: 6
Training loss: 0.18409167230129242
Validation loss: 1.7681586537309872

Epoch: 5| Step: 7
Training loss: 1.1897735595703125
Validation loss: 1.8338011708310855

Epoch: 5| Step: 8
Training loss: 0.7506606578826904
Validation loss: 1.8174657590927616

Epoch: 5| Step: 9
Training loss: 0.5318856239318848
Validation loss: 1.850484553203788

Epoch: 5| Step: 10
Training loss: 0.9157817959785461
Validation loss: 1.824762309751203

Epoch: 283| Step: 0
Training loss: 0.7977632880210876
Validation loss: 1.8624266180940854

Epoch: 5| Step: 1
Training loss: 0.519720196723938
Validation loss: 1.8486484199441888

Epoch: 5| Step: 2
Training loss: 0.7272535562515259
Validation loss: 1.8281238014980028

Epoch: 5| Step: 3
Training loss: 0.6555649042129517
Validation loss: 1.8024052919880036

Epoch: 5| Step: 4
Training loss: 0.6554206609725952
Validation loss: 1.8016749223073323

Epoch: 5| Step: 5
Training loss: 0.7560807466506958
Validation loss: 1.7460670035372499

Epoch: 5| Step: 6
Training loss: 0.8007758855819702
Validation loss: 1.7307746538551905

Epoch: 5| Step: 7
Training loss: 0.5978602170944214
Validation loss: 1.7604498991402246

Epoch: 5| Step: 8
Training loss: 0.5789278149604797
Validation loss: 1.7662673586158342

Epoch: 5| Step: 9
Training loss: 0.805581271648407
Validation loss: 1.794054212108735

Epoch: 5| Step: 10
Training loss: 0.8026503324508667
Validation loss: 1.835334998305126

Epoch: 284| Step: 0
Training loss: 0.6526838541030884
Validation loss: 1.8552799635036017

Epoch: 5| Step: 1
Training loss: 0.5289300680160522
Validation loss: 1.8816089181489841

Epoch: 5| Step: 2
Training loss: 0.5875668525695801
Validation loss: 1.9336578153794812

Epoch: 5| Step: 3
Training loss: 0.7030811309814453
Validation loss: 1.9060164549017464

Epoch: 5| Step: 4
Training loss: 0.45274263620376587
Validation loss: 1.8718019300891506

Epoch: 5| Step: 5
Training loss: 0.6553828120231628
Validation loss: 1.8439715267509542

Epoch: 5| Step: 6
Training loss: 0.996163010597229
Validation loss: 1.834010096006496

Epoch: 5| Step: 7
Training loss: 0.9280633926391602
Validation loss: 1.8257076906901535

Epoch: 5| Step: 8
Training loss: 0.7864096760749817
Validation loss: 1.8188484048330655

Epoch: 5| Step: 9
Training loss: 0.5068089962005615
Validation loss: 1.8527555311879804

Epoch: 5| Step: 10
Training loss: 1.0956087112426758
Validation loss: 1.8405285189228673

Epoch: 285| Step: 0
Training loss: 0.45797377824783325
Validation loss: 1.8485277506612963

Epoch: 5| Step: 1
Training loss: 0.5323525667190552
Validation loss: 1.8201723457664571

Epoch: 5| Step: 2
Training loss: 0.5160449743270874
Validation loss: 1.7982656391718055

Epoch: 5| Step: 3
Training loss: 0.8347281217575073
Validation loss: 1.7909838191924556

Epoch: 5| Step: 4
Training loss: 0.6576709747314453
Validation loss: 1.7880254996720182

Epoch: 5| Step: 5
Training loss: 0.98003089427948
Validation loss: 1.7874573058979486

Epoch: 5| Step: 6
Training loss: 0.6840832829475403
Validation loss: 1.7715057096173685

Epoch: 5| Step: 7
Training loss: 0.618327796459198
Validation loss: 1.7891533156876922

Epoch: 5| Step: 8
Training loss: 1.0009279251098633
Validation loss: 1.8033900748017013

Epoch: 5| Step: 9
Training loss: 0.8705147504806519
Validation loss: 1.7640376552458732

Epoch: 5| Step: 10
Training loss: 0.5846169590950012
Validation loss: 1.7847362244001

Epoch: 286| Step: 0
Training loss: 0.987636923789978
Validation loss: 1.8123444177771126

Epoch: 5| Step: 1
Training loss: 0.4043117165565491
Validation loss: 1.8212826854439192

Epoch: 5| Step: 2
Training loss: 0.50898277759552
Validation loss: 1.8080164078743226

Epoch: 5| Step: 3
Training loss: 0.6976742744445801
Validation loss: 1.7752458651860554

Epoch: 5| Step: 4
Training loss: 0.8012421727180481
Validation loss: 1.770752663253456

Epoch: 5| Step: 5
Training loss: 0.9210485219955444
Validation loss: 1.7859733027796592

Epoch: 5| Step: 6
Training loss: 0.2951027452945709
Validation loss: 1.7493274301610968

Epoch: 5| Step: 7
Training loss: 0.9441412091255188
Validation loss: 1.7489568494981336

Epoch: 5| Step: 8
Training loss: 0.7542480230331421
Validation loss: 1.7495127698426605

Epoch: 5| Step: 9
Training loss: 0.7957698702812195
Validation loss: 1.7930817168246034

Epoch: 5| Step: 10
Training loss: 0.39591509103775024
Validation loss: 1.7892187462058118

Epoch: 287| Step: 0
Training loss: 0.704296886920929
Validation loss: 1.8141465469073224

Epoch: 5| Step: 1
Training loss: 0.9961061477661133
Validation loss: 1.7704677338241248

Epoch: 5| Step: 2
Training loss: 0.672736644744873
Validation loss: 1.8049967609426028

Epoch: 5| Step: 3
Training loss: 0.9369021654129028
Validation loss: 1.77676857543248

Epoch: 5| Step: 4
Training loss: 0.8510711789131165
Validation loss: 1.724476037486907

Epoch: 5| Step: 5
Training loss: 0.6456915140151978
Validation loss: 1.7364900855607883

Epoch: 5| Step: 6
Training loss: 0.5362919569015503
Validation loss: 1.7244324030414704

Epoch: 5| Step: 7
Training loss: 0.6937452554702759
Validation loss: 1.7086124458620626

Epoch: 5| Step: 8
Training loss: 0.4776698052883148
Validation loss: 1.7340807825006463

Epoch: 5| Step: 9
Training loss: 0.43010878562927246
Validation loss: 1.7297904619606592

Epoch: 5| Step: 10
Training loss: 0.5824418067932129
Validation loss: 1.7360592452428674

Epoch: 288| Step: 0
Training loss: 0.8756834268569946
Validation loss: 1.7969891076446862

Epoch: 5| Step: 1
Training loss: 0.925460696220398
Validation loss: 1.8275618565979825

Epoch: 5| Step: 2
Training loss: 0.5796554684638977
Validation loss: 1.8576683664834628

Epoch: 5| Step: 3
Training loss: 0.680963397026062
Validation loss: 1.838013364422706

Epoch: 5| Step: 4
Training loss: 0.6944392323493958
Validation loss: 1.7935860233922158

Epoch: 5| Step: 5
Training loss: 0.33463719487190247
Validation loss: 1.7753885023055538

Epoch: 5| Step: 6
Training loss: 0.6957734823226929
Validation loss: 1.7666839784191501

Epoch: 5| Step: 7
Training loss: 0.881421685218811
Validation loss: 1.7377409550451464

Epoch: 5| Step: 8
Training loss: 0.35863998532295227
Validation loss: 1.7122163157309256

Epoch: 5| Step: 9
Training loss: 0.9290851354598999
Validation loss: 1.7733913365230765

Epoch: 5| Step: 10
Training loss: 0.34575268626213074
Validation loss: 1.7348359477135442

Epoch: 289| Step: 0
Training loss: 0.6485499143600464
Validation loss: 1.7488543513000652

Epoch: 5| Step: 1
Training loss: 0.5613095164299011
Validation loss: 1.735007034834995

Epoch: 5| Step: 2
Training loss: 0.6646530032157898
Validation loss: 1.7683608865225187

Epoch: 5| Step: 3
Training loss: 0.6981016993522644
Validation loss: 1.8328586829605924

Epoch: 5| Step: 4
Training loss: 0.6089392900466919
Validation loss: 1.8049017972843622

Epoch: 5| Step: 5
Training loss: 0.6164858937263489
Validation loss: 1.7970191022401214

Epoch: 5| Step: 6
Training loss: 0.8641506433486938
Validation loss: 1.8114857571099394

Epoch: 5| Step: 7
Training loss: 0.5276461839675903
Validation loss: 1.7503350204037083

Epoch: 5| Step: 8
Training loss: 0.5899096727371216
Validation loss: 1.7098714190144693

Epoch: 5| Step: 9
Training loss: 0.7563444972038269
Validation loss: 1.7316183838793027

Epoch: 5| Step: 10
Training loss: 0.7568269968032837
Validation loss: 1.7088210544278544

Epoch: 290| Step: 0
Training loss: 0.4210070073604584
Validation loss: 1.7154214638535694

Epoch: 5| Step: 1
Training loss: 0.7662215232849121
Validation loss: 1.7053584937126405

Epoch: 5| Step: 2
Training loss: 0.4543883800506592
Validation loss: 1.7481010498539094

Epoch: 5| Step: 3
Training loss: 1.1630480289459229
Validation loss: 1.7800406268847886

Epoch: 5| Step: 4
Training loss: 0.6063414812088013
Validation loss: 1.78564324045694

Epoch: 5| Step: 5
Training loss: 0.4483603537082672
Validation loss: 1.820241464081631

Epoch: 5| Step: 6
Training loss: 0.5848861932754517
Validation loss: 1.809932211393951

Epoch: 5| Step: 7
Training loss: 0.2891599237918854
Validation loss: 1.806753186769383

Epoch: 5| Step: 8
Training loss: 0.8282361030578613
Validation loss: 1.83392898754407

Epoch: 5| Step: 9
Training loss: 0.9072809219360352
Validation loss: 1.8203447941810853

Epoch: 5| Step: 10
Training loss: 0.9831227660179138
Validation loss: 1.8226592040831042

Epoch: 291| Step: 0
Training loss: 0.9246624112129211
Validation loss: 1.8113552678015925

Epoch: 5| Step: 1
Training loss: 0.6220080256462097
Validation loss: 1.72770611188745

Epoch: 5| Step: 2
Training loss: 0.510694146156311
Validation loss: 1.7412331155551377

Epoch: 5| Step: 3
Training loss: 0.6145973801612854
Validation loss: 1.724877797147279

Epoch: 5| Step: 4
Training loss: 0.4155338406562805
Validation loss: 1.7710422687633063

Epoch: 5| Step: 5
Training loss: 0.7212567329406738
Validation loss: 1.7807901931065384

Epoch: 5| Step: 6
Training loss: 0.9527410268783569
Validation loss: 1.8078936389697495

Epoch: 5| Step: 7
Training loss: 0.7043246030807495
Validation loss: 1.7800989433001446

Epoch: 5| Step: 8
Training loss: 0.6725362539291382
Validation loss: 1.7927723251363283

Epoch: 5| Step: 9
Training loss: 0.8394418954849243
Validation loss: 1.7634937673486688

Epoch: 5| Step: 10
Training loss: 0.32383906841278076
Validation loss: 1.7744580007368518

Epoch: 292| Step: 0
Training loss: 0.3998640179634094
Validation loss: 1.793397895751461

Epoch: 5| Step: 1
Training loss: 0.8363744020462036
Validation loss: 1.8099408688083771

Epoch: 5| Step: 2
Training loss: 0.665014922618866
Validation loss: 1.858504823459092

Epoch: 5| Step: 3
Training loss: 0.4953416883945465
Validation loss: 1.8179772848724036

Epoch: 5| Step: 4
Training loss: 0.42388278245925903
Validation loss: 1.8126378854115803

Epoch: 5| Step: 5
Training loss: 0.7362672686576843
Validation loss: 1.797287743578675

Epoch: 5| Step: 6
Training loss: 1.2086365222930908
Validation loss: 1.7954113726974816

Epoch: 5| Step: 7
Training loss: 0.6000990867614746
Validation loss: 1.7467773768209642

Epoch: 5| Step: 8
Training loss: 0.4561181962490082
Validation loss: 1.730221172814728

Epoch: 5| Step: 9
Training loss: 0.8846603631973267
Validation loss: 1.720096662480344

Epoch: 5| Step: 10
Training loss: 0.47929948568344116
Validation loss: 1.713631260779596

Epoch: 293| Step: 0
Training loss: 0.5531109571456909
Validation loss: 1.7275170638997068

Epoch: 5| Step: 1
Training loss: 0.656049370765686
Validation loss: 1.717407621363158

Epoch: 5| Step: 2
Training loss: 0.709436297416687
Validation loss: 1.7774458341701056

Epoch: 5| Step: 3
Training loss: 0.5856267213821411
Validation loss: 1.8089366266804356

Epoch: 5| Step: 4
Training loss: 0.6778348088264465
Validation loss: 1.7673628137957664

Epoch: 5| Step: 5
Training loss: 0.4663240909576416
Validation loss: 1.777192013238066

Epoch: 5| Step: 6
Training loss: 0.6615743637084961
Validation loss: 1.788201557692661

Epoch: 5| Step: 7
Training loss: 0.8152672648429871
Validation loss: 1.8177712091835596

Epoch: 5| Step: 8
Training loss: 0.8281341791152954
Validation loss: 1.7778605004792571

Epoch: 5| Step: 9
Training loss: 0.439969003200531
Validation loss: 1.8296220866582726

Epoch: 5| Step: 10
Training loss: 0.45464715361595154
Validation loss: 1.8173668371733798

Epoch: 294| Step: 0
Training loss: 0.3664073348045349
Validation loss: 1.790385889750655

Epoch: 5| Step: 1
Training loss: 0.3433936834335327
Validation loss: 1.7894138674582205

Epoch: 5| Step: 2
Training loss: 0.5907121896743774
Validation loss: 1.7969810039766374

Epoch: 5| Step: 3
Training loss: 0.568945050239563
Validation loss: 1.7825308115251604

Epoch: 5| Step: 4
Training loss: 0.5323740839958191
Validation loss: 1.7930299851202196

Epoch: 5| Step: 5
Training loss: 0.9120434522628784
Validation loss: 1.7887734418274255

Epoch: 5| Step: 6
Training loss: 0.7833598852157593
Validation loss: 1.7645139232758553

Epoch: 5| Step: 7
Training loss: 0.5531928539276123
Validation loss: 1.7590366691671393

Epoch: 5| Step: 8
Training loss: 0.5955440402030945
Validation loss: 1.7600858173062723

Epoch: 5| Step: 9
Training loss: 0.6523410677909851
Validation loss: 1.7858701905896586

Epoch: 5| Step: 10
Training loss: 0.7052305936813354
Validation loss: 1.77166243778762

Epoch: 295| Step: 0
Training loss: 0.6436539888381958
Validation loss: 1.8172205045659056

Epoch: 5| Step: 1
Training loss: 0.5483571290969849
Validation loss: 1.7827478006321897

Epoch: 5| Step: 2
Training loss: 0.6587985754013062
Validation loss: 1.778334734260395

Epoch: 5| Step: 3
Training loss: 0.5914689302444458
Validation loss: 1.7814390300422587

Epoch: 5| Step: 4
Training loss: 0.3745908737182617
Validation loss: 1.7784357532378166

Epoch: 5| Step: 5
Training loss: 0.6559855341911316
Validation loss: 1.7461199734800605

Epoch: 5| Step: 6
Training loss: 0.5900043249130249
Validation loss: 1.7638006723055275

Epoch: 5| Step: 7
Training loss: 0.5977841019630432
Validation loss: 1.7370990476300638

Epoch: 5| Step: 8
Training loss: 0.6537923812866211
Validation loss: 1.698504956819678

Epoch: 5| Step: 9
Training loss: 0.6719998121261597
Validation loss: 1.7219489889760171

Epoch: 5| Step: 10
Training loss: 0.5317575931549072
Validation loss: 1.7686666045137631

Epoch: 296| Step: 0
Training loss: 0.7753912210464478
Validation loss: 1.7771270198206748

Epoch: 5| Step: 1
Training loss: 0.6217128038406372
Validation loss: 1.774047395875377

Epoch: 5| Step: 2
Training loss: 0.5564166903495789
Validation loss: 1.7928646251719484

Epoch: 5| Step: 3
Training loss: 0.5651947855949402
Validation loss: 1.8096742476186445

Epoch: 5| Step: 4
Training loss: 0.746055006980896
Validation loss: 1.8527493297412831

Epoch: 5| Step: 5
Training loss: 0.8514601588249207
Validation loss: 1.860031953421972

Epoch: 5| Step: 6
Training loss: 0.40479883551597595
Validation loss: 1.8420511753328386

Epoch: 5| Step: 7
Training loss: 0.6129953861236572
Validation loss: 1.7949341612477456

Epoch: 5| Step: 8
Training loss: 0.8896190524101257
Validation loss: 1.7709900012580297

Epoch: 5| Step: 9
Training loss: 0.4110449254512787
Validation loss: 1.7211611245268135

Epoch: 5| Step: 10
Training loss: 0.3404865562915802
Validation loss: 1.6980839198635471

Epoch: 297| Step: 0
Training loss: 0.4413011968135834
Validation loss: 1.7205770630990305

Epoch: 5| Step: 1
Training loss: 0.7884150743484497
Validation loss: 1.711033280177783

Epoch: 5| Step: 2
Training loss: 0.9044338464736938
Validation loss: 1.7498564707335604

Epoch: 5| Step: 3
Training loss: 0.40960803627967834
Validation loss: 1.7590976197232482

Epoch: 5| Step: 4
Training loss: 0.6125375032424927
Validation loss: 1.7625631798980057

Epoch: 5| Step: 5
Training loss: 0.6123459935188293
Validation loss: 1.7833231495272728

Epoch: 5| Step: 6
Training loss: 0.4238490164279938
Validation loss: 1.7932378963757587

Epoch: 5| Step: 7
Training loss: 0.4997342526912689
Validation loss: 1.829423653182163

Epoch: 5| Step: 8
Training loss: 0.6822569966316223
Validation loss: 1.8635677496592205

Epoch: 5| Step: 9
Training loss: 0.5973034501075745
Validation loss: 1.8795674077926143

Epoch: 5| Step: 10
Training loss: 0.5922787189483643
Validation loss: 1.892874740785168

Epoch: 298| Step: 0
Training loss: 0.6132668256759644
Validation loss: 1.8612868273130028

Epoch: 5| Step: 1
Training loss: 0.47057396173477173
Validation loss: 1.8299328114396782

Epoch: 5| Step: 2
Training loss: 0.6131675243377686
Validation loss: 1.818516650507527

Epoch: 5| Step: 3
Training loss: 0.5035751461982727
Validation loss: 1.7907819696651992

Epoch: 5| Step: 4
Training loss: 0.33285969495773315
Validation loss: 1.7950599975483392

Epoch: 5| Step: 5
Training loss: 0.6676440834999084
Validation loss: 1.7618165657084475

Epoch: 5| Step: 6
Training loss: 0.6248471736907959
Validation loss: 1.7581342907362087

Epoch: 5| Step: 7
Training loss: 0.6249847412109375
Validation loss: 1.7554922860155824

Epoch: 5| Step: 8
Training loss: 0.6669638752937317
Validation loss: 1.7707940199041878

Epoch: 5| Step: 9
Training loss: 0.45845872163772583
Validation loss: 1.7672241605738157

Epoch: 5| Step: 10
Training loss: 0.6846391558647156
Validation loss: 1.7629504203796387

Epoch: 299| Step: 0
Training loss: 0.45157894492149353
Validation loss: 1.7573872586732269

Epoch: 5| Step: 1
Training loss: 0.7070616483688354
Validation loss: 1.759622440543226

Epoch: 5| Step: 2
Training loss: 0.5042091012001038
Validation loss: 1.7339748515877673

Epoch: 5| Step: 3
Training loss: 0.4243597984313965
Validation loss: 1.7276354476969729

Epoch: 5| Step: 4
Training loss: 0.5691448450088501
Validation loss: 1.7341704932592248

Epoch: 5| Step: 5
Training loss: 0.7200582027435303
Validation loss: 1.7826581847283147

Epoch: 5| Step: 6
Training loss: 0.47599276900291443
Validation loss: 1.7836630511027511

Epoch: 5| Step: 7
Training loss: 0.5024980902671814
Validation loss: 1.8120192045806556

Epoch: 5| Step: 8
Training loss: 0.8376907110214233
Validation loss: 1.7956572245526057

Epoch: 5| Step: 9
Training loss: 0.5685989260673523
Validation loss: 1.75152107848916

Epoch: 5| Step: 10
Training loss: 0.545866847038269
Validation loss: 1.7803042665604623

Epoch: 300| Step: 0
Training loss: 0.698141872882843
Validation loss: 1.77926726495066

Epoch: 5| Step: 1
Training loss: 0.6371899843215942
Validation loss: 1.7587325111512215

Epoch: 5| Step: 2
Training loss: 0.5436754822731018
Validation loss: 1.73074012033401

Epoch: 5| Step: 3
Training loss: 0.5211650729179382
Validation loss: 1.734132711605359

Epoch: 5| Step: 4
Training loss: 0.6382456421852112
Validation loss: 1.723650187574407

Epoch: 5| Step: 5
Training loss: 0.48711806535720825
Validation loss: 1.7538417667470954

Epoch: 5| Step: 6
Training loss: 0.37693867087364197
Validation loss: 1.7275279132268762

Epoch: 5| Step: 7
Training loss: 0.5942076444625854
Validation loss: 1.7069984956454205

Epoch: 5| Step: 8
Training loss: 0.8373838663101196
Validation loss: 1.7617661594062723

Epoch: 5| Step: 9
Training loss: 0.6290364265441895
Validation loss: 1.7799028709370603

Epoch: 5| Step: 10
Training loss: 0.5009378790855408
Validation loss: 1.8006682421571465

Epoch: 301| Step: 0
Training loss: 0.6286271810531616
Validation loss: 1.83710221064988

Epoch: 5| Step: 1
Training loss: 0.680316150188446
Validation loss: 1.8920877146464523

Epoch: 5| Step: 2
Training loss: 0.7603580355644226
Validation loss: 1.8417732382333407

Epoch: 5| Step: 3
Training loss: 0.4458102583885193
Validation loss: 1.9100407784984959

Epoch: 5| Step: 4
Training loss: 0.3750382959842682
Validation loss: 1.8710475954958188

Epoch: 5| Step: 5
Training loss: 0.6906412839889526
Validation loss: 1.8540093706500145

Epoch: 5| Step: 6
Training loss: 0.6266517639160156
Validation loss: 1.8386756643172233

Epoch: 5| Step: 7
Training loss: 0.6883803009986877
Validation loss: 1.8482567289824128

Epoch: 5| Step: 8
Training loss: 0.7098981738090515
Validation loss: 1.831442383027846

Epoch: 5| Step: 9
Training loss: 0.7031135559082031
Validation loss: 1.8271913092623475

Epoch: 5| Step: 10
Training loss: 0.2775985598564148
Validation loss: 1.859622807912929

Epoch: 302| Step: 0
Training loss: 0.4366433024406433
Validation loss: 1.8481242707980576

Epoch: 5| Step: 1
Training loss: 0.43703117966651917
Validation loss: 1.8965196173678163

Epoch: 5| Step: 2
Training loss: 0.9922440648078918
Validation loss: 1.8942547177755704

Epoch: 5| Step: 3
Training loss: 0.810408890247345
Validation loss: 1.886899955811039

Epoch: 5| Step: 4
Training loss: 0.6941601634025574
Validation loss: 1.8743976290507982

Epoch: 5| Step: 5
Training loss: 0.647867739200592
Validation loss: 1.840545064659529

Epoch: 5| Step: 6
Training loss: 0.4668888449668884
Validation loss: 1.8016266079359158

Epoch: 5| Step: 7
Training loss: 0.592583179473877
Validation loss: 1.800726274008392

Epoch: 5| Step: 8
Training loss: 0.5004888772964478
Validation loss: 1.788127686387749

Epoch: 5| Step: 9
Training loss: 0.3649877905845642
Validation loss: 1.8038613039960143

Epoch: 5| Step: 10
Training loss: 0.4137991964817047
Validation loss: 1.7612065358828473

Epoch: 303| Step: 0
Training loss: 0.45271745324134827
Validation loss: 1.7404269813209452

Epoch: 5| Step: 1
Training loss: 0.5778764486312866
Validation loss: 1.775407068191036

Epoch: 5| Step: 2
Training loss: 0.4477457106113434
Validation loss: 1.741012127168717

Epoch: 5| Step: 3
Training loss: 0.7886505126953125
Validation loss: 1.7735028497634395

Epoch: 5| Step: 4
Training loss: 0.8968706130981445
Validation loss: 1.7781433392596502

Epoch: 5| Step: 5
Training loss: 0.3494466543197632
Validation loss: 1.8205783751703077

Epoch: 5| Step: 6
Training loss: 0.5904061198234558
Validation loss: 1.8207931159644999

Epoch: 5| Step: 7
Training loss: 0.4726288914680481
Validation loss: 1.8316505916656987

Epoch: 5| Step: 8
Training loss: 0.7122410535812378
Validation loss: 1.848576643133676

Epoch: 5| Step: 9
Training loss: 0.40206384658813477
Validation loss: 1.8886458155929402

Epoch: 5| Step: 10
Training loss: 0.394701212644577
Validation loss: 1.8661109144969652

Epoch: 304| Step: 0
Training loss: 0.4913955330848694
Validation loss: 1.797078562039201

Epoch: 5| Step: 1
Training loss: 0.6179859638214111
Validation loss: 1.7413070714601906

Epoch: 5| Step: 2
Training loss: 0.3478788733482361
Validation loss: 1.7381336567222432

Epoch: 5| Step: 3
Training loss: 0.5397188663482666
Validation loss: 1.7506764755454114

Epoch: 5| Step: 4
Training loss: 0.6761494874954224
Validation loss: 1.7413707651117796

Epoch: 5| Step: 5
Training loss: 0.22226586937904358
Validation loss: 1.7456035947286954

Epoch: 5| Step: 6
Training loss: 0.6238900423049927
Validation loss: 1.7521304058772262

Epoch: 5| Step: 7
Training loss: 0.5548126101493835
Validation loss: 1.754494841380786

Epoch: 5| Step: 8
Training loss: 0.4869346618652344
Validation loss: 1.765575224353421

Epoch: 5| Step: 9
Training loss: 0.519612193107605
Validation loss: 1.8125537274986185

Epoch: 5| Step: 10
Training loss: 0.8201169967651367
Validation loss: 1.799059820431535

Epoch: 305| Step: 0
Training loss: 0.6384986639022827
Validation loss: 1.832909405872386

Epoch: 5| Step: 1
Training loss: 0.5240352749824524
Validation loss: 1.8115284955629738

Epoch: 5| Step: 2
Training loss: 0.28955984115600586
Validation loss: 1.8220409193346578

Epoch: 5| Step: 3
Training loss: 0.6232286691665649
Validation loss: 1.7938989900773572

Epoch: 5| Step: 4
Training loss: 0.5379940867424011
Validation loss: 1.7933058200343963

Epoch: 5| Step: 5
Training loss: 0.48453712463378906
Validation loss: 1.7969320563859836

Epoch: 5| Step: 6
Training loss: 0.611290454864502
Validation loss: 1.7569386087438112

Epoch: 5| Step: 7
Training loss: 0.610116720199585
Validation loss: 1.720474244445883

Epoch: 5| Step: 8
Training loss: 0.43470197916030884
Validation loss: 1.7265540784405125

Epoch: 5| Step: 9
Training loss: 0.38010963797569275
Validation loss: 1.733316175399288

Epoch: 5| Step: 10
Training loss: 0.7081957459449768
Validation loss: 1.7456209762122041

Epoch: 306| Step: 0
Training loss: 0.32418516278266907
Validation loss: 1.7575747095128542

Epoch: 5| Step: 1
Training loss: 0.37911462783813477
Validation loss: 1.8115511222552227

Epoch: 5| Step: 2
Training loss: 0.4522887170314789
Validation loss: 1.8029184828522384

Epoch: 5| Step: 3
Training loss: 0.5886876583099365
Validation loss: 1.8085635169859855

Epoch: 5| Step: 4
Training loss: 0.4915374219417572
Validation loss: 1.7945508521090272

Epoch: 5| Step: 5
Training loss: 0.47979918122291565
Validation loss: 1.8100300860661331

Epoch: 5| Step: 6
Training loss: 0.5288651585578918
Validation loss: 1.7887218498414563

Epoch: 5| Step: 7
Training loss: 0.32964110374450684
Validation loss: 1.7995485259640602

Epoch: 5| Step: 8
Training loss: 0.881689727306366
Validation loss: 1.836102206219909

Epoch: 5| Step: 9
Training loss: 0.5158703923225403
Validation loss: 1.8038396937872774

Epoch: 5| Step: 10
Training loss: 0.6658549308776855
Validation loss: 1.7783777457411571

Epoch: 307| Step: 0
Training loss: 0.5390021204948425
Validation loss: 1.8061494570906445

Epoch: 5| Step: 1
Training loss: 0.5027837157249451
Validation loss: 1.797580607475773

Epoch: 5| Step: 2
Training loss: 0.5403514504432678
Validation loss: 1.7865153410101449

Epoch: 5| Step: 3
Training loss: 0.5347174406051636
Validation loss: 1.8048880254068682

Epoch: 5| Step: 4
Training loss: 0.4396359920501709
Validation loss: 1.819501046211489

Epoch: 5| Step: 5
Training loss: 0.6651725172996521
Validation loss: 1.817251936081917

Epoch: 5| Step: 6
Training loss: 0.4349449574947357
Validation loss: 1.793254626694546

Epoch: 5| Step: 7
Training loss: 0.507999062538147
Validation loss: 1.803813503634545

Epoch: 5| Step: 8
Training loss: 0.45770493149757385
Validation loss: 1.7899327431955645

Epoch: 5| Step: 9
Training loss: 0.45453619956970215
Validation loss: 1.7546403023504442

Epoch: 5| Step: 10
Training loss: 0.48424506187438965
Validation loss: 1.7656710301676104

Epoch: 308| Step: 0
Training loss: 0.4406113028526306
Validation loss: 1.7816667479853476

Epoch: 5| Step: 1
Training loss: 0.47800689935684204
Validation loss: 1.8071180094954788

Epoch: 5| Step: 2
Training loss: 0.3905385136604309
Validation loss: 1.7957878048701952

Epoch: 5| Step: 3
Training loss: 0.4569181501865387
Validation loss: 1.7953851376810381

Epoch: 5| Step: 4
Training loss: 0.43567633628845215
Validation loss: 1.8032665867959299

Epoch: 5| Step: 5
Training loss: 0.7186204195022583
Validation loss: 1.7942260144859232

Epoch: 5| Step: 6
Training loss: 0.5616083741188049
Validation loss: 1.8067759275436401

Epoch: 5| Step: 7
Training loss: 0.6823678612709045
Validation loss: 1.8067389611274964

Epoch: 5| Step: 8
Training loss: 0.5971776247024536
Validation loss: 1.7920738561179048

Epoch: 5| Step: 9
Training loss: 0.4019504189491272
Validation loss: 1.7746760922093545

Epoch: 5| Step: 10
Training loss: 0.6283986568450928
Validation loss: 1.7386657461043327

Epoch: 309| Step: 0
Training loss: 0.6198562979698181
Validation loss: 1.726452031443196

Epoch: 5| Step: 1
Training loss: 0.21679134666919708
Validation loss: 1.6963195775144844

Epoch: 5| Step: 2
Training loss: 0.738828182220459
Validation loss: 1.7433802197056432

Epoch: 5| Step: 3
Training loss: 0.5414481163024902
Validation loss: 1.7165964008659444

Epoch: 5| Step: 4
Training loss: 0.2661626935005188
Validation loss: 1.750547170639038

Epoch: 5| Step: 5
Training loss: 0.38529282808303833
Validation loss: 1.7799997893712853

Epoch: 5| Step: 6
Training loss: 0.48519858717918396
Validation loss: 1.8240963899961082

Epoch: 5| Step: 7
Training loss: 0.7093741297721863
Validation loss: 1.86820815455529

Epoch: 5| Step: 8
Training loss: 0.5096338987350464
Validation loss: 1.8350235813407487

Epoch: 5| Step: 9
Training loss: 0.3211938440799713
Validation loss: 1.8069416681925456

Epoch: 5| Step: 10
Training loss: 0.6574177742004395
Validation loss: 1.7514849478198635

Epoch: 310| Step: 0
Training loss: 0.2934933304786682
Validation loss: 1.7455747806897728

Epoch: 5| Step: 1
Training loss: 0.6063705682754517
Validation loss: 1.7147423554492254

Epoch: 5| Step: 2
Training loss: 0.5999872088432312
Validation loss: 1.6897827374037875

Epoch: 5| Step: 3
Training loss: 0.5549546480178833
Validation loss: 1.6660433392370901

Epoch: 5| Step: 4
Training loss: 0.3720340430736542
Validation loss: 1.7132695285222863

Epoch: 5| Step: 5
Training loss: 0.39134204387664795
Validation loss: 1.7272124751921623

Epoch: 5| Step: 6
Training loss: 0.5325337648391724
Validation loss: 1.7450165658868768

Epoch: 5| Step: 7
Training loss: 0.6736856698989868
Validation loss: 1.7698571656339912

Epoch: 5| Step: 8
Training loss: 0.49191659688949585
Validation loss: 1.803918953864805

Epoch: 5| Step: 9
Training loss: 0.48032450675964355
Validation loss: 1.8525670215647707

Epoch: 5| Step: 10
Training loss: 0.38725781440734863
Validation loss: 1.8734817286973358

Epoch: 311| Step: 0
Training loss: 0.6185221076011658
Validation loss: 1.899669825389821

Epoch: 5| Step: 1
Training loss: 0.5591005086898804
Validation loss: 1.924095396072634

Epoch: 5| Step: 2
Training loss: 0.6314435005187988
Validation loss: 1.8785555490883448

Epoch: 5| Step: 3
Training loss: 0.5881379842758179
Validation loss: 1.843026053520941

Epoch: 5| Step: 4
Training loss: 0.21716363728046417
Validation loss: 1.8144211884467834

Epoch: 5| Step: 5
Training loss: 0.6440843939781189
Validation loss: 1.7843998183486283

Epoch: 5| Step: 6
Training loss: 0.3087141215801239
Validation loss: 1.7793278104515486

Epoch: 5| Step: 7
Training loss: 0.6299117803573608
Validation loss: 1.7442407313213553

Epoch: 5| Step: 8
Training loss: 0.8321104049682617
Validation loss: 1.7728139431245866

Epoch: 5| Step: 9
Training loss: 0.5614531636238098
Validation loss: 1.7464452776857602

Epoch: 5| Step: 10
Training loss: 0.22492210566997528
Validation loss: 1.8028170049831431

Epoch: 312| Step: 0
Training loss: 0.6295410990715027
Validation loss: 1.8665672720119517

Epoch: 5| Step: 1
Training loss: 0.6979120969772339
Validation loss: 1.8726523076334307

Epoch: 5| Step: 2
Training loss: 0.5767117142677307
Validation loss: 1.9019075042457991

Epoch: 5| Step: 3
Training loss: 0.3916918635368347
Validation loss: 1.8944630161408456

Epoch: 5| Step: 4
Training loss: 0.3394041955471039
Validation loss: 1.8645753270836287

Epoch: 5| Step: 5
Training loss: 0.37224724888801575
Validation loss: 1.7874201484905776

Epoch: 5| Step: 6
Training loss: 0.4135825037956238
Validation loss: 1.8045864579498128

Epoch: 5| Step: 7
Training loss: 0.632757842540741
Validation loss: 1.748185678835838

Epoch: 5| Step: 8
Training loss: 0.5392026901245117
Validation loss: 1.7116868880487257

Epoch: 5| Step: 9
Training loss: 0.7690414190292358
Validation loss: 1.7306553061290453

Epoch: 5| Step: 10
Training loss: 0.334407240152359
Validation loss: 1.7532439526691233

Epoch: 313| Step: 0
Training loss: 0.4962158799171448
Validation loss: 1.7718894532931748

Epoch: 5| Step: 1
Training loss: 0.5656090974807739
Validation loss: 1.815603748444588

Epoch: 5| Step: 2
Training loss: 0.6204007267951965
Validation loss: 1.77926621642164

Epoch: 5| Step: 3
Training loss: 0.642372727394104
Validation loss: 1.7986003045112855

Epoch: 5| Step: 4
Training loss: 0.6117647290229797
Validation loss: 1.78410554188554

Epoch: 5| Step: 5
Training loss: 0.6161574721336365
Validation loss: 1.8455386059258574

Epoch: 5| Step: 6
Training loss: 0.3470214009284973
Validation loss: 1.864505797304133

Epoch: 5| Step: 7
Training loss: 0.4959927201271057
Validation loss: 1.859411028123671

Epoch: 5| Step: 8
Training loss: 0.6275777816772461
Validation loss: 1.9008828401565552

Epoch: 5| Step: 9
Training loss: 0.6792887449264526
Validation loss: 1.9079100316570652

Epoch: 5| Step: 10
Training loss: 0.5248572826385498
Validation loss: 1.8771530005239672

Epoch: 314| Step: 0
Training loss: 0.4291674494743347
Validation loss: 1.895372804775033

Epoch: 5| Step: 1
Training loss: 0.21676070988178253
Validation loss: 1.8533706921403126

Epoch: 5| Step: 2
Training loss: 0.6169018745422363
Validation loss: 1.857835279997959

Epoch: 5| Step: 3
Training loss: 0.5461238026618958
Validation loss: 1.8328804867241972

Epoch: 5| Step: 4
Training loss: 0.5307327508926392
Validation loss: 1.7732651374673332

Epoch: 5| Step: 5
Training loss: 0.6344144940376282
Validation loss: 1.7745672861735027

Epoch: 5| Step: 6
Training loss: 0.6722371578216553
Validation loss: 1.750306890856835

Epoch: 5| Step: 7
Training loss: 0.4780459403991699
Validation loss: 1.7678537496956446

Epoch: 5| Step: 8
Training loss: 0.34856733679771423
Validation loss: 1.7607766018118909

Epoch: 5| Step: 9
Training loss: 0.40818339586257935
Validation loss: 1.7556952686719998

Epoch: 5| Step: 10
Training loss: 0.4874737560749054
Validation loss: 1.7711420084840508

Epoch: 315| Step: 0
Training loss: 0.438023179769516
Validation loss: 1.774947508688896

Epoch: 5| Step: 1
Training loss: 0.6591156721115112
Validation loss: 1.7892059292844547

Epoch: 5| Step: 2
Training loss: 0.37920767068862915
Validation loss: 1.8235169456851097

Epoch: 5| Step: 3
Training loss: 0.4390118718147278
Validation loss: 1.807719438306747

Epoch: 5| Step: 4
Training loss: 0.4339686334133148
Validation loss: 1.7800222058450021

Epoch: 5| Step: 5
Training loss: 0.3777727484703064
Validation loss: 1.8080329702746483

Epoch: 5| Step: 6
Training loss: 0.4603036940097809
Validation loss: 1.772891157416887

Epoch: 5| Step: 7
Training loss: 0.4461461901664734
Validation loss: 1.7815107530163181

Epoch: 5| Step: 8
Training loss: 0.6220517754554749
Validation loss: 1.769098065232718

Epoch: 5| Step: 9
Training loss: 0.3884415924549103
Validation loss: 1.7819020619956396

Epoch: 5| Step: 10
Training loss: 0.2519580125808716
Validation loss: 1.7598883759590886

Epoch: 316| Step: 0
Training loss: 0.4877985119819641
Validation loss: 1.7262807610214397

Epoch: 5| Step: 1
Training loss: 0.30522340536117554
Validation loss: 1.7237102600835985

Epoch: 5| Step: 2
Training loss: 0.5170639753341675
Validation loss: 1.7226564615003523

Epoch: 5| Step: 3
Training loss: 0.4078856408596039
Validation loss: 1.7247512071363387

Epoch: 5| Step: 4
Training loss: 0.44860440492630005
Validation loss: 1.732043368842012

Epoch: 5| Step: 5
Training loss: 0.4508674740791321
Validation loss: 1.7639499992452643

Epoch: 5| Step: 6
Training loss: 0.4972878396511078
Validation loss: 1.77000561324499

Epoch: 5| Step: 7
Training loss: 0.6747070550918579
Validation loss: 1.7894112012719596

Epoch: 5| Step: 8
Training loss: 0.2241782397031784
Validation loss: 1.751176325223779

Epoch: 5| Step: 9
Training loss: 0.4909234046936035
Validation loss: 1.77667627667868

Epoch: 5| Step: 10
Training loss: 0.3949580192565918
Validation loss: 1.7431054730569162

Epoch: 317| Step: 0
Training loss: 0.4193861484527588
Validation loss: 1.777707108887293

Epoch: 5| Step: 1
Training loss: 0.3573370575904846
Validation loss: 1.7814118887788506

Epoch: 5| Step: 2
Training loss: 0.4208233952522278
Validation loss: 1.7989962049709853

Epoch: 5| Step: 3
Training loss: 0.4287540018558502
Validation loss: 1.815630769216886

Epoch: 5| Step: 4
Training loss: 0.41206103563308716
Validation loss: 1.8388506622724636

Epoch: 5| Step: 5
Training loss: 0.5023047924041748
Validation loss: 1.8421991973794916

Epoch: 5| Step: 6
Training loss: 0.5496615767478943
Validation loss: 1.8514608606215446

Epoch: 5| Step: 7
Training loss: 0.4765844941139221
Validation loss: 1.8544202491801272

Epoch: 5| Step: 8
Training loss: 0.41129550337791443
Validation loss: 1.776074917085709

Epoch: 5| Step: 9
Training loss: 0.4404805600643158
Validation loss: 1.7810759057280838

Epoch: 5| Step: 10
Training loss: 0.37332040071487427
Validation loss: 1.8055515673852736

Epoch: 318| Step: 0
Training loss: 0.3137965202331543
Validation loss: 1.7854321092687628

Epoch: 5| Step: 1
Training loss: 0.7546259760856628
Validation loss: 1.7945775793444725

Epoch: 5| Step: 2
Training loss: 0.27914372086524963
Validation loss: 1.7795988244395102

Epoch: 5| Step: 3
Training loss: 0.48468342423439026
Validation loss: 1.7478014935729325

Epoch: 5| Step: 4
Training loss: 0.3689522445201874
Validation loss: 1.7826041188291324

Epoch: 5| Step: 5
Training loss: 0.45440229773521423
Validation loss: 1.771274507686656

Epoch: 5| Step: 6
Training loss: 0.36653149127960205
Validation loss: 1.7581269324466746

Epoch: 5| Step: 7
Training loss: 0.3196990191936493
Validation loss: 1.748496029966621

Epoch: 5| Step: 8
Training loss: 0.5217088460922241
Validation loss: 1.7749157804314808

Epoch: 5| Step: 9
Training loss: 0.3796726167201996
Validation loss: 1.7526004557968469

Epoch: 5| Step: 10
Training loss: 0.27779078483581543
Validation loss: 1.8274027006600493

Epoch: 319| Step: 0
Training loss: 0.2932634949684143
Validation loss: 1.8287393444327897

Epoch: 5| Step: 1
Training loss: 0.3520074188709259
Validation loss: 1.8521843789726176

Epoch: 5| Step: 2
Training loss: 0.5975386500358582
Validation loss: 1.8770245326462613

Epoch: 5| Step: 3
Training loss: 0.2537252604961395
Validation loss: 1.8216410721501997

Epoch: 5| Step: 4
Training loss: 0.3174043297767639
Validation loss: 1.7963626820554015

Epoch: 5| Step: 5
Training loss: 0.4056874215602875
Validation loss: 1.7793815879411594

Epoch: 5| Step: 6
Training loss: 0.6014850735664368
Validation loss: 1.7907119451030609

Epoch: 5| Step: 7
Training loss: 0.5212875008583069
Validation loss: 1.804126944593204

Epoch: 5| Step: 8
Training loss: 0.476532518863678
Validation loss: 1.8073185464387298

Epoch: 5| Step: 9
Training loss: 0.2640058100223541
Validation loss: 1.74193908322242

Epoch: 5| Step: 10
Training loss: 0.5116865038871765
Validation loss: 1.7671602874673822

Epoch: 320| Step: 0
Training loss: 0.34171992540359497
Validation loss: 1.7700823789001794

Epoch: 5| Step: 1
Training loss: 0.22760429978370667
Validation loss: 1.7337038619543916

Epoch: 5| Step: 2
Training loss: 0.3010721206665039
Validation loss: 1.7598035040722098

Epoch: 5| Step: 3
Training loss: 0.5373048782348633
Validation loss: 1.8223352252796132

Epoch: 5| Step: 4
Training loss: 0.5233076810836792
Validation loss: 1.8761868015412362

Epoch: 5| Step: 5
Training loss: 0.3066510856151581
Validation loss: 1.8347493012746174

Epoch: 5| Step: 6
Training loss: 0.48735079169273376
Validation loss: 1.817988698200513

Epoch: 5| Step: 7
Training loss: 0.403695672750473
Validation loss: 1.7329999118722894

Epoch: 5| Step: 8
Training loss: 0.517616868019104
Validation loss: 1.7438106113864529

Epoch: 5| Step: 9
Training loss: 0.4111904203891754
Validation loss: 1.787532957651282

Epoch: 5| Step: 10
Training loss: 0.5615655183792114
Validation loss: 1.7508809681861632

Epoch: 321| Step: 0
Training loss: 0.6354885697364807
Validation loss: 1.781245143182816

Epoch: 5| Step: 1
Training loss: 0.37983211874961853
Validation loss: 1.7406355988594793

Epoch: 5| Step: 2
Training loss: 0.5408965945243835
Validation loss: 1.754764651739469

Epoch: 5| Step: 3
Training loss: 0.4512127935886383
Validation loss: 1.7597385221912014

Epoch: 5| Step: 4
Training loss: 0.45716553926467896
Validation loss: 1.8133900780831613

Epoch: 5| Step: 5
Training loss: 0.3359563946723938
Validation loss: 1.8455650614153953

Epoch: 5| Step: 6
Training loss: 0.26463642716407776
Validation loss: 1.8704568314295944

Epoch: 5| Step: 7
Training loss: 0.5037323236465454
Validation loss: 1.8335721159494052

Epoch: 5| Step: 8
Training loss: 0.674380898475647
Validation loss: 1.865866784126528

Epoch: 5| Step: 9
Training loss: 0.36904358863830566
Validation loss: 1.8641842026864328

Epoch: 5| Step: 10
Training loss: 0.39481568336486816
Validation loss: 1.815611954658262

Epoch: 322| Step: 0
Training loss: 0.400380939245224
Validation loss: 1.8038333936404156

Epoch: 5| Step: 1
Training loss: 0.38611918687820435
Validation loss: 1.806564756619033

Epoch: 5| Step: 2
Training loss: 0.3052056133747101
Validation loss: 1.7696805538669709

Epoch: 5| Step: 3
Training loss: 0.39501333236694336
Validation loss: 1.808574689331875

Epoch: 5| Step: 4
Training loss: 0.4982895851135254
Validation loss: 1.793753174043471

Epoch: 5| Step: 5
Training loss: 0.6014547348022461
Validation loss: 1.7612824683548303

Epoch: 5| Step: 6
Training loss: 0.6019077301025391
Validation loss: 1.721183023145122

Epoch: 5| Step: 7
Training loss: 0.6631195545196533
Validation loss: 1.781369334907942

Epoch: 5| Step: 8
Training loss: 0.38719746470451355
Validation loss: 1.7685774526288431

Epoch: 5| Step: 9
Training loss: 0.5501089096069336
Validation loss: 1.7879792003221409

Epoch: 5| Step: 10
Training loss: 0.1394294947385788
Validation loss: 1.7909011546001639

Epoch: 323| Step: 0
Training loss: 0.3607194721698761
Validation loss: 1.7796347794994232

Epoch: 5| Step: 1
Training loss: 0.44302695989608765
Validation loss: 1.8322028165222497

Epoch: 5| Step: 2
Training loss: 0.47067564725875854
Validation loss: 1.8532655649287726

Epoch: 5| Step: 3
Training loss: 0.4692705273628235
Validation loss: 1.8167535463968914

Epoch: 5| Step: 4
Training loss: 0.38901472091674805
Validation loss: 1.791586938724723

Epoch: 5| Step: 5
Training loss: 0.4865637719631195
Validation loss: 1.7540091647896716

Epoch: 5| Step: 6
Training loss: 0.5598733425140381
Validation loss: 1.7186367216930594

Epoch: 5| Step: 7
Training loss: 0.44909143447875977
Validation loss: 1.7075876599998885

Epoch: 5| Step: 8
Training loss: 0.450523316860199
Validation loss: 1.7105943208099694

Epoch: 5| Step: 9
Training loss: 0.3272944986820221
Validation loss: 1.7275763480894026

Epoch: 5| Step: 10
Training loss: 0.564516544342041
Validation loss: 1.7677626039392205

Epoch: 324| Step: 0
Training loss: 0.4444813132286072
Validation loss: 1.7854692538579304

Epoch: 5| Step: 1
Training loss: 0.354669988155365
Validation loss: 1.8103894725922616

Epoch: 5| Step: 2
Training loss: 0.4917811453342438
Validation loss: 1.8464506390274211

Epoch: 5| Step: 3
Training loss: 0.5430620312690735
Validation loss: 1.8992217176703996

Epoch: 5| Step: 4
Training loss: 0.3813115656375885
Validation loss: 1.895549572924132

Epoch: 5| Step: 5
Training loss: 0.37434881925582886
Validation loss: 1.8719987625716834

Epoch: 5| Step: 6
Training loss: 0.40725308656692505
Validation loss: 1.8306900429469284

Epoch: 5| Step: 7
Training loss: 0.5538236498832703
Validation loss: 1.8087032853916127

Epoch: 5| Step: 8
Training loss: 0.5770449042320251
Validation loss: 1.8064967124692854

Epoch: 5| Step: 9
Training loss: 0.5253289341926575
Validation loss: 1.7751749741133822

Epoch: 5| Step: 10
Training loss: 0.2745988965034485
Validation loss: 1.7742654982433523

Epoch: 325| Step: 0
Training loss: 0.5559414625167847
Validation loss: 1.7481316661321988

Epoch: 5| Step: 1
Training loss: 0.3790661692619324
Validation loss: 1.7621297080029723

Epoch: 5| Step: 2
Training loss: 0.4186571538448334
Validation loss: 1.762059662931709

Epoch: 5| Step: 3
Training loss: 0.7064388990402222
Validation loss: 1.7767089425876577

Epoch: 5| Step: 4
Training loss: 0.36634427309036255
Validation loss: 1.7827600561162478

Epoch: 5| Step: 5
Training loss: 0.4401000440120697
Validation loss: 1.7922300779691307

Epoch: 5| Step: 6
Training loss: 0.40757837891578674
Validation loss: 1.7883786065604097

Epoch: 5| Step: 7
Training loss: 0.4739162027835846
Validation loss: 1.8193443411140031

Epoch: 5| Step: 8
Training loss: 0.3419725000858307
Validation loss: 1.7829311727195658

Epoch: 5| Step: 9
Training loss: 0.2534353733062744
Validation loss: 1.755993845642254

Epoch: 5| Step: 10
Training loss: 0.44764041900634766
Validation loss: 1.7800896731756066

Epoch: 326| Step: 0
Training loss: 0.5601154565811157
Validation loss: 1.7573333812016312

Epoch: 5| Step: 1
Training loss: 0.28816285729408264
Validation loss: 1.7727724608554636

Epoch: 5| Step: 2
Training loss: 0.45106154680252075
Validation loss: 1.7685247287955335

Epoch: 5| Step: 3
Training loss: 0.3361824154853821
Validation loss: 1.7058786961340136

Epoch: 5| Step: 4
Training loss: 0.7872050404548645
Validation loss: 1.7165334801520071

Epoch: 5| Step: 5
Training loss: 0.38871246576309204
Validation loss: 1.7616610815448146

Epoch: 5| Step: 6
Training loss: 0.36319446563720703
Validation loss: 1.796840072959982

Epoch: 5| Step: 7
Training loss: 0.4629487097263336
Validation loss: 1.8453971314173874

Epoch: 5| Step: 8
Training loss: 0.3925451338291168
Validation loss: 1.8969511844778573

Epoch: 5| Step: 9
Training loss: 0.46113210916519165
Validation loss: 1.8926738257049232

Epoch: 5| Step: 10
Training loss: 0.4657362699508667
Validation loss: 1.8925164335517473

Epoch: 327| Step: 0
Training loss: 0.5134737491607666
Validation loss: 1.885316684681882

Epoch: 5| Step: 1
Training loss: 0.32468923926353455
Validation loss: 1.7930175668449813

Epoch: 5| Step: 2
Training loss: 0.5433597564697266
Validation loss: 1.7597990625648088

Epoch: 5| Step: 3
Training loss: 0.690975546836853
Validation loss: 1.7684833388174734

Epoch: 5| Step: 4
Training loss: 0.5991033315658569
Validation loss: 1.7377243067628594

Epoch: 5| Step: 5
Training loss: 0.4936645030975342
Validation loss: 1.7428652368566042

Epoch: 5| Step: 6
Training loss: 0.2812190353870392
Validation loss: 1.7406379920180126

Epoch: 5| Step: 7
Training loss: 0.1574425846338272
Validation loss: 1.698968473301139

Epoch: 5| Step: 8
Training loss: 0.3603915572166443
Validation loss: 1.706923165628987

Epoch: 5| Step: 9
Training loss: 0.5414168238639832
Validation loss: 1.7121350393500379

Epoch: 5| Step: 10
Training loss: 0.278658002614975
Validation loss: 1.7465025596721198

Epoch: 328| Step: 0
Training loss: 0.28454285860061646
Validation loss: 1.799694932917113

Epoch: 5| Step: 1
Training loss: 0.3342708647251129
Validation loss: 1.8063143325108353

Epoch: 5| Step: 2
Training loss: 0.4660886824131012
Validation loss: 1.8358700326693955

Epoch: 5| Step: 3
Training loss: 0.4904418885707855
Validation loss: 1.8313218688452115

Epoch: 5| Step: 4
Training loss: 0.48459357023239136
Validation loss: 1.812714902303552

Epoch: 5| Step: 5
Training loss: 0.6003194451332092
Validation loss: 1.8110074330401678

Epoch: 5| Step: 6
Training loss: 0.45146656036376953
Validation loss: 1.8003766203439364

Epoch: 5| Step: 7
Training loss: 0.3360929489135742
Validation loss: 1.7911660389233661

Epoch: 5| Step: 8
Training loss: 0.28355082869529724
Validation loss: 1.7637280674390896

Epoch: 5| Step: 9
Training loss: 0.49250859022140503
Validation loss: 1.7775803817215787

Epoch: 5| Step: 10
Training loss: 0.4073917865753174
Validation loss: 1.7987922160856185

Epoch: 329| Step: 0
Training loss: 0.34921613335609436
Validation loss: 1.7810056440291866

Epoch: 5| Step: 1
Training loss: 0.42203983664512634
Validation loss: 1.804593457970568

Epoch: 5| Step: 2
Training loss: 0.3032984733581543
Validation loss: 1.837843579630698

Epoch: 5| Step: 3
Training loss: 0.2720997631549835
Validation loss: 1.8831446862989856

Epoch: 5| Step: 4
Training loss: 0.31246107816696167
Validation loss: 1.8450745613344255

Epoch: 5| Step: 5
Training loss: 0.3727741837501526
Validation loss: 1.8440827784999725

Epoch: 5| Step: 6
Training loss: 0.3762565553188324
Validation loss: 1.8744963868971793

Epoch: 5| Step: 7
Training loss: 0.29197531938552856
Validation loss: 1.868495398952115

Epoch: 5| Step: 8
Training loss: 0.4385453164577484
Validation loss: 1.841325976515329

Epoch: 5| Step: 9
Training loss: 0.49815207719802856
Validation loss: 1.8854023243791314

Epoch: 5| Step: 10
Training loss: 0.7291794419288635
Validation loss: 1.8940503033258582

Epoch: 330| Step: 0
Training loss: 0.5255283117294312
Validation loss: 1.8546256032041324

Epoch: 5| Step: 1
Training loss: 0.38418155908584595
Validation loss: 1.8443207753601896

Epoch: 5| Step: 2
Training loss: 0.3390559256076813
Validation loss: 1.832929567624164

Epoch: 5| Step: 3
Training loss: 0.41431307792663574
Validation loss: 1.7903391238181823

Epoch: 5| Step: 4
Training loss: 0.45642900466918945
Validation loss: 1.781784826709378

Epoch: 5| Step: 5
Training loss: 0.35201939940452576
Validation loss: 1.7772322098414104

Epoch: 5| Step: 6
Training loss: 0.2369280755519867
Validation loss: 1.775719727239301

Epoch: 5| Step: 7
Training loss: 0.36598721146583557
Validation loss: 1.7549330226836666

Epoch: 5| Step: 8
Training loss: 0.5187916159629822
Validation loss: 1.7678628826654086

Epoch: 5| Step: 9
Training loss: 0.3166187107563019
Validation loss: 1.799699766661531

Epoch: 5| Step: 10
Training loss: 0.42320287227630615
Validation loss: 1.8392267509173321

Epoch: 331| Step: 0
Training loss: 0.2539796829223633
Validation loss: 1.814380987997978

Epoch: 5| Step: 1
Training loss: 0.3879934847354889
Validation loss: 1.78812026721175

Epoch: 5| Step: 2
Training loss: 0.5326764583587646
Validation loss: 1.7860248229836906

Epoch: 5| Step: 3
Training loss: 0.3303787112236023
Validation loss: 1.7605674958998156

Epoch: 5| Step: 4
Training loss: 0.45763152837753296
Validation loss: 1.770676443653722

Epoch: 5| Step: 5
Training loss: 0.5430012345314026
Validation loss: 1.7804153042454873

Epoch: 5| Step: 6
Training loss: 0.25939053297042847
Validation loss: 1.7831014433214742

Epoch: 5| Step: 7
Training loss: 0.32360711693763733
Validation loss: 1.8169544307134484

Epoch: 5| Step: 8
Training loss: 0.5046884417533875
Validation loss: 1.8865331372907084

Epoch: 5| Step: 9
Training loss: 0.4131309390068054
Validation loss: 1.8973589635664416

Epoch: 5| Step: 10
Training loss: 0.2591342031955719
Validation loss: 1.965269398945634

Epoch: 332| Step: 0
Training loss: 0.4578472077846527
Validation loss: 1.9620059997804704

Epoch: 5| Step: 1
Training loss: 0.48548832535743713
Validation loss: 1.9466439639368365

Epoch: 5| Step: 2
Training loss: 0.24099664390087128
Validation loss: 1.9426312984958771

Epoch: 5| Step: 3
Training loss: 0.47830694913864136
Validation loss: 1.911961857990552

Epoch: 5| Step: 4
Training loss: 0.27173298597335815
Validation loss: 1.8408697241096086

Epoch: 5| Step: 5
Training loss: 0.3054217994213104
Validation loss: 1.8414968982819588

Epoch: 5| Step: 6
Training loss: 0.5196541547775269
Validation loss: 1.8293172313321022

Epoch: 5| Step: 7
Training loss: 0.4551970362663269
Validation loss: 1.7969085734377626

Epoch: 5| Step: 8
Training loss: 0.4442299008369446
Validation loss: 1.8022563008851902

Epoch: 5| Step: 9
Training loss: 0.4056861996650696
Validation loss: 1.8217385981672554

Epoch: 5| Step: 10
Training loss: 0.45848605036735535
Validation loss: 1.7809937602730208

Epoch: 333| Step: 0
Training loss: 0.28307420015335083
Validation loss: 1.8589954735130392

Epoch: 5| Step: 1
Training loss: 0.31057193875312805
Validation loss: 1.8719266383878645

Epoch: 5| Step: 2
Training loss: 0.504927933216095
Validation loss: 1.9006766234674761

Epoch: 5| Step: 3
Training loss: 0.5516918301582336
Validation loss: 1.9575285988469278

Epoch: 5| Step: 4
Training loss: 0.5245882272720337
Validation loss: 1.9628651116483955

Epoch: 5| Step: 5
Training loss: 0.5006412267684937
Validation loss: 1.8994197230185232

Epoch: 5| Step: 6
Training loss: 0.29760605096817017
Validation loss: 1.8460278523865568

Epoch: 5| Step: 7
Training loss: 0.1949874758720398
Validation loss: 1.8529433447827575

Epoch: 5| Step: 8
Training loss: 0.3210577964782715
Validation loss: 1.8684197753988288

Epoch: 5| Step: 9
Training loss: 0.33061933517456055
Validation loss: 1.8259912639535882

Epoch: 5| Step: 10
Training loss: 0.33202239871025085
Validation loss: 1.8351205382295834

Epoch: 334| Step: 0
Training loss: 0.4528915286064148
Validation loss: 1.8490850528081257

Epoch: 5| Step: 1
Training loss: 0.29766330122947693
Validation loss: 1.8528821686262726

Epoch: 5| Step: 2
Training loss: 0.3205007314682007
Validation loss: 1.8524886023613714

Epoch: 5| Step: 3
Training loss: 0.4805060923099518
Validation loss: 1.8935165841092345

Epoch: 5| Step: 4
Training loss: 0.5449574589729309
Validation loss: 1.89316523972378

Epoch: 5| Step: 5
Training loss: 0.46108126640319824
Validation loss: 1.850422937382934

Epoch: 5| Step: 6
Training loss: 0.4296664297580719
Validation loss: 1.8770643818762995

Epoch: 5| Step: 7
Training loss: 0.2778876721858978
Validation loss: 1.891107697640696

Epoch: 5| Step: 8
Training loss: 0.36086171865463257
Validation loss: 1.8786152319241596

Epoch: 5| Step: 9
Training loss: 0.45057258009910583
Validation loss: 1.8654742497269825

Epoch: 5| Step: 10
Training loss: 0.26160693168640137
Validation loss: 1.8223429059469571

Epoch: 335| Step: 0
Training loss: 0.5426152944564819
Validation loss: 1.8929205299705587

Epoch: 5| Step: 1
Training loss: 0.29973936080932617
Validation loss: 1.8803652627493745

Epoch: 5| Step: 2
Training loss: 0.30952590703964233
Validation loss: 1.8507359745681926

Epoch: 5| Step: 3
Training loss: 0.32593804597854614
Validation loss: 1.8469534535561838

Epoch: 5| Step: 4
Training loss: 0.29092687368392944
Validation loss: 1.8635968162167458

Epoch: 5| Step: 5
Training loss: 0.4603179097175598
Validation loss: 1.8608301480611165

Epoch: 5| Step: 6
Training loss: 0.18773843348026276
Validation loss: 1.814042987362031

Epoch: 5| Step: 7
Training loss: 0.5841361284255981
Validation loss: 1.8286999335853003

Epoch: 5| Step: 8
Training loss: 0.323867529630661
Validation loss: 1.8250556645854827

Epoch: 5| Step: 9
Training loss: 0.43807679414749146
Validation loss: 1.8101044906082975

Epoch: 5| Step: 10
Training loss: 0.4761386215686798
Validation loss: 1.841062658576555

Epoch: 336| Step: 0
Training loss: 0.43810781836509705
Validation loss: 1.857663364820583

Epoch: 5| Step: 1
Training loss: 0.27232885360717773
Validation loss: 1.8813043563596663

Epoch: 5| Step: 2
Training loss: 0.2781091034412384
Validation loss: 1.8829563048578077

Epoch: 5| Step: 3
Training loss: 0.46965891122817993
Validation loss: 1.8613302335944226

Epoch: 5| Step: 4
Training loss: 0.34937530755996704
Validation loss: 1.8826583534158685

Epoch: 5| Step: 5
Training loss: 0.5978620648384094
Validation loss: 1.8738321335084978

Epoch: 5| Step: 6
Training loss: 0.4429085850715637
Validation loss: 1.8532610247212071

Epoch: 5| Step: 7
Training loss: 0.37920790910720825
Validation loss: 1.8386133024769444

Epoch: 5| Step: 8
Training loss: 0.29931509494781494
Validation loss: 1.8769807008004957

Epoch: 5| Step: 9
Training loss: 0.3389343321323395
Validation loss: 1.8573973973592122

Epoch: 5| Step: 10
Training loss: 0.2094927579164505
Validation loss: 1.8611086235251477

Epoch: 337| Step: 0
Training loss: 0.5498436093330383
Validation loss: 1.833611640878903

Epoch: 5| Step: 1
Training loss: 0.4098423421382904
Validation loss: 1.891397996615338

Epoch: 5| Step: 2
Training loss: 0.2936111092567444
Validation loss: 1.841982973519192

Epoch: 5| Step: 3
Training loss: 0.37010303139686584
Validation loss: 1.8589811568619103

Epoch: 5| Step: 4
Training loss: 0.30681726336479187
Validation loss: 1.833061364389235

Epoch: 5| Step: 5
Training loss: 0.2530362606048584
Validation loss: 1.8208580875909457

Epoch: 5| Step: 6
Training loss: 0.24742074310779572
Validation loss: 1.7934216145546205

Epoch: 5| Step: 7
Training loss: 0.38186153769493103
Validation loss: 1.7848239380826232

Epoch: 5| Step: 8
Training loss: 0.3839797079563141
Validation loss: 1.7941125503150366

Epoch: 5| Step: 9
Training loss: 0.44579535722732544
Validation loss: 1.7994932410537556

Epoch: 5| Step: 10
Training loss: 0.3792509138584137
Validation loss: 1.8288546441703715

Epoch: 338| Step: 0
Training loss: 0.281807005405426
Validation loss: 1.854942544814079

Epoch: 5| Step: 1
Training loss: 0.30466514825820923
Validation loss: 1.871395921194425

Epoch: 5| Step: 2
Training loss: 0.376727432012558
Validation loss: 1.9140095428753925

Epoch: 5| Step: 3
Training loss: 0.44354376196861267
Validation loss: 1.9198170272252892

Epoch: 5| Step: 4
Training loss: 0.21609266102313995
Validation loss: 1.8722013286364976

Epoch: 5| Step: 5
Training loss: 0.27410298585891724
Validation loss: 1.8675217763070138

Epoch: 5| Step: 6
Training loss: 0.3235486149787903
Validation loss: 1.8364617722008818

Epoch: 5| Step: 7
Training loss: 0.47216692566871643
Validation loss: 1.8089762926101685

Epoch: 5| Step: 8
Training loss: 0.33860528469085693
Validation loss: 1.7705898220821092

Epoch: 5| Step: 9
Training loss: 0.5192939639091492
Validation loss: 1.7836799672854844

Epoch: 5| Step: 10
Training loss: 0.3919956386089325
Validation loss: 1.7455083618881881

Epoch: 339| Step: 0
Training loss: 0.4365900456905365
Validation loss: 1.7658687586425452

Epoch: 5| Step: 1
Training loss: 0.3971705436706543
Validation loss: 1.7500174609563683

Epoch: 5| Step: 2
Training loss: 0.20534658432006836
Validation loss: 1.801988991357947

Epoch: 5| Step: 3
Training loss: 0.27437809109687805
Validation loss: 1.8694317392123643

Epoch: 5| Step: 4
Training loss: 0.21504530310630798
Validation loss: 1.8811377581729685

Epoch: 5| Step: 5
Training loss: 0.29581692814826965
Validation loss: 1.896041177934216

Epoch: 5| Step: 6
Training loss: 0.5120689868927002
Validation loss: 1.8418049402134393

Epoch: 5| Step: 7
Training loss: 0.28806638717651367
Validation loss: 1.8116321115083591

Epoch: 5| Step: 8
Training loss: 0.3804555833339691
Validation loss: 1.7750959588635353

Epoch: 5| Step: 9
Training loss: 0.4228695333003998
Validation loss: 1.7445350129117247

Epoch: 5| Step: 10
Training loss: 0.39461004734039307
Validation loss: 1.7691447696378153

Epoch: 340| Step: 0
Training loss: 0.5894080400466919
Validation loss: 1.7507948926700059

Epoch: 5| Step: 1
Training loss: 0.38697853684425354
Validation loss: 1.7837936621840282

Epoch: 5| Step: 2
Training loss: 0.2690737247467041
Validation loss: 1.783682507212444

Epoch: 5| Step: 3
Training loss: 0.4185260832309723
Validation loss: 1.8238993447314027

Epoch: 5| Step: 4
Training loss: 0.36803075671195984
Validation loss: 1.8691869666499477

Epoch: 5| Step: 5
Training loss: 0.335988849401474
Validation loss: 1.8612776058976368

Epoch: 5| Step: 6
Training loss: 0.28276363015174866
Validation loss: 1.8565048812538065

Epoch: 5| Step: 7
Training loss: 0.24140802025794983
Validation loss: 1.8608679335604432

Epoch: 5| Step: 8
Training loss: 0.34693488478660583
Validation loss: 1.871456717932096

Epoch: 5| Step: 9
Training loss: 0.3055187165737152
Validation loss: 1.8601153358336417

Epoch: 5| Step: 10
Training loss: 0.3524753153324127
Validation loss: 1.8356417891799763

Epoch: 341| Step: 0
Training loss: 0.3740437626838684
Validation loss: 1.8424152161485405

Epoch: 5| Step: 1
Training loss: 0.2855176627635956
Validation loss: 1.8285277453801965

Epoch: 5| Step: 2
Training loss: 0.29825854301452637
Validation loss: 1.8572510775699411

Epoch: 5| Step: 3
Training loss: 0.4339448809623718
Validation loss: 1.860119221031025

Epoch: 5| Step: 4
Training loss: 0.21141782402992249
Validation loss: 1.8730142424183507

Epoch: 5| Step: 5
Training loss: 0.3551812767982483
Validation loss: 1.8596524602623397

Epoch: 5| Step: 6
Training loss: 0.3089013993740082
Validation loss: 1.8030644437318206

Epoch: 5| Step: 7
Training loss: 0.31765979528427124
Validation loss: 1.809382389950496

Epoch: 5| Step: 8
Training loss: 0.2722892463207245
Validation loss: 1.8104315316805275

Epoch: 5| Step: 9
Training loss: 0.3147095739841461
Validation loss: 1.787045769794013

Epoch: 5| Step: 10
Training loss: 0.6250246167182922
Validation loss: 1.7901766031019148

Epoch: 342| Step: 0
Training loss: 0.20185856521129608
Validation loss: 1.7845892162733181

Epoch: 5| Step: 1
Training loss: 0.40554991364479065
Validation loss: 1.787946980486634

Epoch: 5| Step: 2
Training loss: 0.2591710686683655
Validation loss: 1.7703740750589678

Epoch: 5| Step: 3
Training loss: 0.3537081778049469
Validation loss: 1.8219840590671827

Epoch: 5| Step: 4
Training loss: 0.33158785104751587
Validation loss: 1.8656354988774946

Epoch: 5| Step: 5
Training loss: 0.3833962380886078
Validation loss: 1.8392931210097445

Epoch: 5| Step: 6
Training loss: 0.26100534200668335
Validation loss: 1.8419926358807472

Epoch: 5| Step: 7
Training loss: 0.40498867630958557
Validation loss: 1.8377479391713296

Epoch: 5| Step: 8
Training loss: 0.2371918261051178
Validation loss: 1.857517485977501

Epoch: 5| Step: 9
Training loss: 0.630668044090271
Validation loss: 1.8305949036793043

Epoch: 5| Step: 10
Training loss: 0.2580200433731079
Validation loss: 1.8017971438746299

Epoch: 343| Step: 0
Training loss: 0.2763596475124359
Validation loss: 1.80473695775514

Epoch: 5| Step: 1
Training loss: 0.3172650635242462
Validation loss: 1.7798650598013273

Epoch: 5| Step: 2
Training loss: 0.3034546375274658
Validation loss: 1.794500688070892

Epoch: 5| Step: 3
Training loss: 0.20276936888694763
Validation loss: 1.815222272308924

Epoch: 5| Step: 4
Training loss: 0.37583523988723755
Validation loss: 1.8202457658706173

Epoch: 5| Step: 5
Training loss: 0.254544198513031
Validation loss: 1.8286649014360161

Epoch: 5| Step: 6
Training loss: 0.4442318379878998
Validation loss: 1.8301603947916338

Epoch: 5| Step: 7
Training loss: 0.26641952991485596
Validation loss: 1.8783851387680217

Epoch: 5| Step: 8
Training loss: 0.4021071791648865
Validation loss: 1.8525858207415509

Epoch: 5| Step: 9
Training loss: 0.568344235420227
Validation loss: 1.8570767025793753

Epoch: 5| Step: 10
Training loss: 0.3138081431388855
Validation loss: 1.843333198178199

Epoch: 344| Step: 0
Training loss: 0.21274344623088837
Validation loss: 1.8811409293964345

Epoch: 5| Step: 1
Training loss: 0.2860559821128845
Validation loss: 1.875204873341386

Epoch: 5| Step: 2
Training loss: 0.4704403877258301
Validation loss: 1.9013212701325775

Epoch: 5| Step: 3
Training loss: 0.33335810899734497
Validation loss: 1.8653232615481141

Epoch: 5| Step: 4
Training loss: 0.22442762553691864
Validation loss: 1.8954860625728485

Epoch: 5| Step: 5
Training loss: 0.5161198377609253
Validation loss: 1.8419203476239276

Epoch: 5| Step: 6
Training loss: 0.32130759954452515
Validation loss: 1.8364296292745939

Epoch: 5| Step: 7
Training loss: 0.22263804078102112
Validation loss: 1.8329681363157047

Epoch: 5| Step: 8
Training loss: 0.2242727279663086
Validation loss: 1.783300451053086

Epoch: 5| Step: 9
Training loss: 0.42914897203445435
Validation loss: 1.8238980654747254

Epoch: 5| Step: 10
Training loss: 0.45637986063957214
Validation loss: 1.774076307973554

Epoch: 345| Step: 0
Training loss: 0.534416675567627
Validation loss: 1.7786875732483403

Epoch: 5| Step: 1
Training loss: 0.33795636892318726
Validation loss: 1.8100783542920185

Epoch: 5| Step: 2
Training loss: 0.30272069573402405
Validation loss: 1.842680920836746

Epoch: 5| Step: 3
Training loss: 0.23965828120708466
Validation loss: 1.8553335525656258

Epoch: 5| Step: 4
Training loss: 0.278511106967926
Validation loss: 1.8618970788935179

Epoch: 5| Step: 5
Training loss: 0.37721118330955505
Validation loss: 1.908700180310075

Epoch: 5| Step: 6
Training loss: 0.23036129772663116
Validation loss: 1.910126055440595

Epoch: 5| Step: 7
Training loss: 0.2095310240983963
Validation loss: 1.927626076564994

Epoch: 5| Step: 8
Training loss: 0.27430224418640137
Validation loss: 1.8827644137925998

Epoch: 5| Step: 9
Training loss: 0.42456158995628357
Validation loss: 1.845841206530089

Epoch: 5| Step: 10
Training loss: 0.2727104127407074
Validation loss: 1.8690366821904336

Epoch: 346| Step: 0
Training loss: 0.39743226766586304
Validation loss: 1.8532821439927625

Epoch: 5| Step: 1
Training loss: 0.3165663182735443
Validation loss: 1.8452136542207451

Epoch: 5| Step: 2
Training loss: 0.12536361813545227
Validation loss: 1.8303675241367792

Epoch: 5| Step: 3
Training loss: 0.399329274892807
Validation loss: 1.8392678870949695

Epoch: 5| Step: 4
Training loss: 0.3304252028465271
Validation loss: 1.812128569490166

Epoch: 5| Step: 5
Training loss: 0.1890951544046402
Validation loss: 1.8262018003771383

Epoch: 5| Step: 6
Training loss: 0.2615582346916199
Validation loss: 1.8020787033983456

Epoch: 5| Step: 7
Training loss: 0.19570119678974152
Validation loss: 1.8019489934367519

Epoch: 5| Step: 8
Training loss: 0.49492305517196655
Validation loss: 1.764709803365892

Epoch: 5| Step: 9
Training loss: 0.28913629055023193
Validation loss: 1.7433860827517766

Epoch: 5| Step: 10
Training loss: 0.5529233813285828
Validation loss: 1.7606724103291829

Epoch: 347| Step: 0
Training loss: 0.1794138252735138
Validation loss: 1.7758716434560797

Epoch: 5| Step: 1
Training loss: 0.3294702470302582
Validation loss: 1.7902818136317755

Epoch: 5| Step: 2
Training loss: 0.2979218363761902
Validation loss: 1.7928581417247813

Epoch: 5| Step: 3
Training loss: 0.35945120453834534
Validation loss: 1.8492008845011394

Epoch: 5| Step: 4
Training loss: 0.20908355712890625
Validation loss: 1.8723366132346533

Epoch: 5| Step: 5
Training loss: 0.2960471510887146
Validation loss: 1.8884184821959464

Epoch: 5| Step: 6
Training loss: 0.3782081604003906
Validation loss: 1.9132862065428047

Epoch: 5| Step: 7
Training loss: 0.4976367950439453
Validation loss: 1.904429671584919

Epoch: 5| Step: 8
Training loss: 0.33612123131752014
Validation loss: 1.9164366017105758

Epoch: 5| Step: 9
Training loss: 0.3585713505744934
Validation loss: 1.8798443053358345

Epoch: 5| Step: 10
Training loss: 0.34113699197769165
Validation loss: 1.867183986530509

Epoch: 348| Step: 0
Training loss: 0.3326473832130432
Validation loss: 1.8133045281133344

Epoch: 5| Step: 1
Training loss: 0.3306898772716522
Validation loss: 1.7789447076859013

Epoch: 5| Step: 2
Training loss: 0.3878551125526428
Validation loss: 1.7630883416821879

Epoch: 5| Step: 3
Training loss: 0.2277851104736328
Validation loss: 1.7505872416239914

Epoch: 5| Step: 4
Training loss: 0.27321141958236694
Validation loss: 1.7944804622280983

Epoch: 5| Step: 5
Training loss: 0.3320426940917969
Validation loss: 1.8203108951609621

Epoch: 5| Step: 6
Training loss: 0.313274085521698
Validation loss: 1.8174702121365456

Epoch: 5| Step: 7
Training loss: 0.40381431579589844
Validation loss: 1.819219946861267

Epoch: 5| Step: 8
Training loss: 0.204575777053833
Validation loss: 1.8787272040561964

Epoch: 5| Step: 9
Training loss: 0.5197691917419434
Validation loss: 1.9343875197954075

Epoch: 5| Step: 10
Training loss: 0.28318560123443604
Validation loss: 1.9321995576222737

Epoch: 349| Step: 0
Training loss: 0.2657466232776642
Validation loss: 1.914189712975615

Epoch: 5| Step: 1
Training loss: 0.6051157712936401
Validation loss: 1.9376957531898253

Epoch: 5| Step: 2
Training loss: 0.3589228391647339
Validation loss: 1.9097028060625958

Epoch: 5| Step: 3
Training loss: 0.20838093757629395
Validation loss: 1.849831437551847

Epoch: 5| Step: 4
Training loss: 0.2677932679653168
Validation loss: 1.8464209084869714

Epoch: 5| Step: 5
Training loss: 0.4021492898464203
Validation loss: 1.8134333831007763

Epoch: 5| Step: 6
Training loss: 0.3815469741821289
Validation loss: 1.8041468076808478

Epoch: 5| Step: 7
Training loss: 0.17286178469657898
Validation loss: 1.7844860041013328

Epoch: 5| Step: 8
Training loss: 0.4167637825012207
Validation loss: 1.7671124076330533

Epoch: 5| Step: 9
Training loss: 0.3326221704483032
Validation loss: 1.7770283068380048

Epoch: 5| Step: 10
Training loss: 0.2660841941833496
Validation loss: 1.7875669669079524

Epoch: 350| Step: 0
Training loss: 0.36800599098205566
Validation loss: 1.7918881062538392

Epoch: 5| Step: 1
Training loss: 0.419224351644516
Validation loss: 1.8298212302628385

Epoch: 5| Step: 2
Training loss: 0.15319904685020447
Validation loss: 1.808844522763324

Epoch: 5| Step: 3
Training loss: 0.2956356108188629
Validation loss: 1.8271032462837875

Epoch: 5| Step: 4
Training loss: 0.30989891290664673
Validation loss: 1.8054196283381472

Epoch: 5| Step: 5
Training loss: 0.40576058626174927
Validation loss: 1.7460313202232443

Epoch: 5| Step: 6
Training loss: 0.38262325525283813
Validation loss: 1.7857011979626072

Epoch: 5| Step: 7
Training loss: 0.22562885284423828
Validation loss: 1.7676540984902331

Epoch: 5| Step: 8
Training loss: 0.4340147078037262
Validation loss: 1.737102170144358

Epoch: 5| Step: 9
Training loss: 0.2854798138141632
Validation loss: 1.7458454242316626

Epoch: 5| Step: 10
Training loss: 0.24090424180030823
Validation loss: 1.7706273524991927

Epoch: 351| Step: 0
Training loss: 0.31822866201400757
Validation loss: 1.8140607803098616

Epoch: 5| Step: 1
Training loss: 0.3359602987766266
Validation loss: 1.8758131739913777

Epoch: 5| Step: 2
Training loss: 0.2456282377243042
Validation loss: 1.8287634670093496

Epoch: 5| Step: 3
Training loss: 0.17813916504383087
Validation loss: 1.8374256510888376

Epoch: 5| Step: 4
Training loss: 0.4274919629096985
Validation loss: 1.8174547226198259

Epoch: 5| Step: 5
Training loss: 0.2569747567176819
Validation loss: 1.825603392816359

Epoch: 5| Step: 6
Training loss: 0.34358417987823486
Validation loss: 1.8070197028498496

Epoch: 5| Step: 7
Training loss: 0.314797967672348
Validation loss: 1.786749211690759

Epoch: 5| Step: 8
Training loss: 0.2547144293785095
Validation loss: 1.8180666674849808

Epoch: 5| Step: 9
Training loss: 0.26312097907066345
Validation loss: 1.792497440051007

Epoch: 5| Step: 10
Training loss: 0.4228137731552124
Validation loss: 1.7810202080716369

Epoch: 352| Step: 0
Training loss: 0.43744921684265137
Validation loss: 1.8468813178359822

Epoch: 5| Step: 1
Training loss: 0.21178360283374786
Validation loss: 1.812636039590323

Epoch: 5| Step: 2
Training loss: 0.19083841145038605
Validation loss: 1.7732251703098256

Epoch: 5| Step: 3
Training loss: 0.33373749256134033
Validation loss: 1.7950249077171407

Epoch: 5| Step: 4
Training loss: 0.23894146084785461
Validation loss: 1.8068511037416355

Epoch: 5| Step: 5
Training loss: 0.4074879586696625
Validation loss: 1.8047432104746501

Epoch: 5| Step: 6
Training loss: 0.3019872307777405
Validation loss: 1.8221169133340158

Epoch: 5| Step: 7
Training loss: 0.2776360511779785
Validation loss: 1.81713750157305

Epoch: 5| Step: 8
Training loss: 0.2767040431499481
Validation loss: 1.8056936264038086

Epoch: 5| Step: 9
Training loss: 0.3194596767425537
Validation loss: 1.7890994382160965

Epoch: 5| Step: 10
Training loss: 0.35563230514526367
Validation loss: 1.7784681666281916

Epoch: 353| Step: 0
Training loss: 0.32074373960494995
Validation loss: 1.7222953778441235

Epoch: 5| Step: 1
Training loss: 0.3185405433177948
Validation loss: 1.7343042166002336

Epoch: 5| Step: 2
Training loss: 0.41274675726890564
Validation loss: 1.7313685340266074

Epoch: 5| Step: 3
Training loss: 0.5256834626197815
Validation loss: 1.755792458852132

Epoch: 5| Step: 4
Training loss: 0.35861191153526306
Validation loss: 1.7921716910536571

Epoch: 5| Step: 5
Training loss: 0.2200518101453781
Validation loss: 1.8343642719330326

Epoch: 5| Step: 6
Training loss: 0.27617090940475464
Validation loss: 1.865421538711876

Epoch: 5| Step: 7
Training loss: 0.2821272015571594
Validation loss: 1.9083807596596338

Epoch: 5| Step: 8
Training loss: 0.33239060640335083
Validation loss: 1.8554393322237077

Epoch: 5| Step: 9
Training loss: 0.2457176148891449
Validation loss: 1.8432484096096409

Epoch: 5| Step: 10
Training loss: 0.4744310975074768
Validation loss: 1.7695837841239026

Epoch: 354| Step: 0
Training loss: 0.24193763732910156
Validation loss: 1.7994351694660802

Epoch: 5| Step: 1
Training loss: 0.48186102509498596
Validation loss: 1.7671791686806628

Epoch: 5| Step: 2
Training loss: 0.43216457962989807
Validation loss: 1.7926027031355007

Epoch: 5| Step: 3
Training loss: 0.30400413274765015
Validation loss: 1.7629046760579592

Epoch: 5| Step: 4
Training loss: 0.3466314673423767
Validation loss: 1.7823412764456965

Epoch: 5| Step: 5
Training loss: 0.6061773300170898
Validation loss: 1.818324100586676

Epoch: 5| Step: 6
Training loss: 0.20258061587810516
Validation loss: 1.843767512229181

Epoch: 5| Step: 7
Training loss: 0.2916039824485779
Validation loss: 1.8628797749037385

Epoch: 5| Step: 8
Training loss: 0.2940134108066559
Validation loss: 1.8312494665063836

Epoch: 5| Step: 9
Training loss: 0.22590896487236023
Validation loss: 1.8058349868302703

Epoch: 5| Step: 10
Training loss: 0.2312706559896469
Validation loss: 1.8340227091184227

Epoch: 355| Step: 0
Training loss: 0.204844668507576
Validation loss: 1.810483733812968

Epoch: 5| Step: 1
Training loss: 0.2239089459180832
Validation loss: 1.8134037538241314

Epoch: 5| Step: 2
Training loss: 0.5694948434829712
Validation loss: 1.83311548156123

Epoch: 5| Step: 3
Training loss: 0.4618036150932312
Validation loss: 1.8157574079369987

Epoch: 5| Step: 4
Training loss: 0.2579721212387085
Validation loss: 1.7660243844473233

Epoch: 5| Step: 5
Training loss: 0.32246702909469604
Validation loss: 1.7947436904394498

Epoch: 5| Step: 6
Training loss: 0.17862823605537415
Validation loss: 1.7785755075434202

Epoch: 5| Step: 7
Training loss: 0.233488991856575
Validation loss: 1.761400531697017

Epoch: 5| Step: 8
Training loss: 0.4044317603111267
Validation loss: 1.7737990374206214

Epoch: 5| Step: 9
Training loss: 0.28763020038604736
Validation loss: 1.7788272826902327

Epoch: 5| Step: 10
Training loss: 0.18834905326366425
Validation loss: 1.767161657733302

Epoch: 356| Step: 0
Training loss: 0.2943476438522339
Validation loss: 1.7705278665788713

Epoch: 5| Step: 1
Training loss: 0.28661248087882996
Validation loss: 1.7885859166422198

Epoch: 5| Step: 2
Training loss: 0.32531866431236267
Validation loss: 1.808980954590664

Epoch: 5| Step: 3
Training loss: 0.2309042513370514
Validation loss: 1.7998813326640795

Epoch: 5| Step: 4
Training loss: 0.26131972670555115
Validation loss: 1.8132407588343467

Epoch: 5| Step: 5
Training loss: 0.2519649565219879
Validation loss: 1.8338715607120144

Epoch: 5| Step: 6
Training loss: 0.2668965756893158
Validation loss: 1.8234586997698712

Epoch: 5| Step: 7
Training loss: 0.32946258783340454
Validation loss: 1.8648942414150442

Epoch: 5| Step: 8
Training loss: 0.31984978914260864
Validation loss: 1.8274467529789094

Epoch: 5| Step: 9
Training loss: 0.329642117023468
Validation loss: 1.8230711875423309

Epoch: 5| Step: 10
Training loss: 0.15694336593151093
Validation loss: 1.7709039129236692

Epoch: 357| Step: 0
Training loss: 0.2865295112133026
Validation loss: 1.7620558969436153

Epoch: 5| Step: 1
Training loss: 0.36656513810157776
Validation loss: 1.7597088698417909

Epoch: 5| Step: 2
Training loss: 0.40782713890075684
Validation loss: 1.7522372250915856

Epoch: 5| Step: 3
Training loss: 0.2567161023616791
Validation loss: 1.751670652820218

Epoch: 5| Step: 4
Training loss: 0.3723224997520447
Validation loss: 1.7817160032128776

Epoch: 5| Step: 5
Training loss: 0.19225971400737762
Validation loss: 1.7715749291963474

Epoch: 5| Step: 6
Training loss: 0.2696117162704468
Validation loss: 1.7503045579438568

Epoch: 5| Step: 7
Training loss: 0.22769613564014435
Validation loss: 1.7890150034299461

Epoch: 5| Step: 8
Training loss: 0.22830982506275177
Validation loss: 1.7913736733057166

Epoch: 5| Step: 9
Training loss: 0.24383287131786346
Validation loss: 1.7902167035687355

Epoch: 5| Step: 10
Training loss: 0.31520533561706543
Validation loss: 1.8078423571842972

Epoch: 358| Step: 0
Training loss: 0.3296748995780945
Validation loss: 1.769419381695409

Epoch: 5| Step: 1
Training loss: 0.29786092042922974
Validation loss: 1.7550959369187713

Epoch: 5| Step: 2
Training loss: 0.3267120122909546
Validation loss: 1.789923297461643

Epoch: 5| Step: 3
Training loss: 0.34538424015045166
Validation loss: 1.771813851530834

Epoch: 5| Step: 4
Training loss: 0.5396807789802551
Validation loss: 1.7457463023483113

Epoch: 5| Step: 5
Training loss: 0.2204858511686325
Validation loss: 1.7901472481348182

Epoch: 5| Step: 6
Training loss: 0.28555139899253845
Validation loss: 1.757380299670722

Epoch: 5| Step: 7
Training loss: 0.383710652589798
Validation loss: 1.8073125334196194

Epoch: 5| Step: 8
Training loss: 0.18558213114738464
Validation loss: 1.7808422914115332

Epoch: 5| Step: 9
Training loss: 0.2713254988193512
Validation loss: 1.8113895398314281

Epoch: 5| Step: 10
Training loss: 0.2138698846101761
Validation loss: 1.7977029251795944

Epoch: 359| Step: 0
Training loss: 0.25024908781051636
Validation loss: 1.8176018627741004

Epoch: 5| Step: 1
Training loss: 0.18465003371238708
Validation loss: 1.8512218344596125

Epoch: 5| Step: 2
Training loss: 0.2685362696647644
Validation loss: 1.8524747215291506

Epoch: 5| Step: 3
Training loss: 0.3364224433898926
Validation loss: 1.8269864859119538

Epoch: 5| Step: 4
Training loss: 0.25040847063064575
Validation loss: 1.8307874805183821

Epoch: 5| Step: 5
Training loss: 0.33233141899108887
Validation loss: 1.841089871621901

Epoch: 5| Step: 6
Training loss: 0.18994811177253723
Validation loss: 1.807812911207958

Epoch: 5| Step: 7
Training loss: 0.2965822219848633
Validation loss: 1.7828447793119697

Epoch: 5| Step: 8
Training loss: 0.3478166162967682
Validation loss: 1.783614077875691

Epoch: 5| Step: 9
Training loss: 0.1566961407661438
Validation loss: 1.8008812191665813

Epoch: 5| Step: 10
Training loss: 0.42573708295822144
Validation loss: 1.7776034109054073

Epoch: 360| Step: 0
Training loss: 0.27766403555870056
Validation loss: 1.800870769767351

Epoch: 5| Step: 1
Training loss: 0.3594823181629181
Validation loss: 1.79240571811635

Epoch: 5| Step: 2
Training loss: 0.21490438282489777
Validation loss: 1.805233436246072

Epoch: 5| Step: 3
Training loss: 0.3165082037448883
Validation loss: 1.8349895400385703

Epoch: 5| Step: 4
Training loss: 0.27995988726615906
Validation loss: 1.8561051584059192

Epoch: 5| Step: 5
Training loss: 0.18643486499786377
Validation loss: 1.9102687604965702

Epoch: 5| Step: 6
Training loss: 0.32060471177101135
Validation loss: 1.8995270088154783

Epoch: 5| Step: 7
Training loss: 0.3151876926422119
Validation loss: 1.8857097048913278

Epoch: 5| Step: 8
Training loss: 0.49587732553482056
Validation loss: 1.8785568719269128

Epoch: 5| Step: 9
Training loss: 0.2641735374927521
Validation loss: 1.887845831532632

Epoch: 5| Step: 10
Training loss: 0.30542194843292236
Validation loss: 1.837758961544242

Epoch: 361| Step: 0
Training loss: 0.1740235686302185
Validation loss: 1.8051726356629403

Epoch: 5| Step: 1
Training loss: 0.5175589323043823
Validation loss: 1.7653062471779444

Epoch: 5| Step: 2
Training loss: 0.33400392532348633
Validation loss: 1.7544639700202531

Epoch: 5| Step: 3
Training loss: 0.24894113838672638
Validation loss: 1.7463624887568976

Epoch: 5| Step: 4
Training loss: 0.3042442798614502
Validation loss: 1.7723514597903016

Epoch: 5| Step: 5
Training loss: 0.28199368715286255
Validation loss: 1.7711546446687432

Epoch: 5| Step: 6
Training loss: 0.2612972855567932
Validation loss: 1.78425000047171

Epoch: 5| Step: 7
Training loss: 0.20811502635478973
Validation loss: 1.8373992853267218

Epoch: 5| Step: 8
Training loss: 0.30214205384254456
Validation loss: 1.8400262965950915

Epoch: 5| Step: 9
Training loss: 0.18285050988197327
Validation loss: 1.8614109254652453

Epoch: 5| Step: 10
Training loss: 0.25414755940437317
Validation loss: 1.8513622360844766

Epoch: 362| Step: 0
Training loss: 0.2391670197248459
Validation loss: 1.8512871444866221

Epoch: 5| Step: 1
Training loss: 0.41613954305648804
Validation loss: 1.8818472264915385

Epoch: 5| Step: 2
Training loss: 0.26563572883605957
Validation loss: 1.8785879778605636

Epoch: 5| Step: 3
Training loss: 0.16089724004268646
Validation loss: 1.8306038738578878

Epoch: 5| Step: 4
Training loss: 0.22929880023002625
Validation loss: 1.8181006241870183

Epoch: 5| Step: 5
Training loss: 0.17489081621170044
Validation loss: 1.7502412052564724

Epoch: 5| Step: 6
Training loss: 0.23072588443756104
Validation loss: 1.7657813333695935

Epoch: 5| Step: 7
Training loss: 0.32092446088790894
Validation loss: 1.7807047033822665

Epoch: 5| Step: 8
Training loss: 0.31854233145713806
Validation loss: 1.7412554974197059

Epoch: 5| Step: 9
Training loss: 0.5640244483947754
Validation loss: 1.7619992968856648

Epoch: 5| Step: 10
Training loss: 0.2612816393375397
Validation loss: 1.7629366267111994

Epoch: 363| Step: 0
Training loss: 0.21694421768188477
Validation loss: 1.7468430226848972

Epoch: 5| Step: 1
Training loss: 0.27162498235702515
Validation loss: 1.7276560773131668

Epoch: 5| Step: 2
Training loss: 0.2946504056453705
Validation loss: 1.7856350021977578

Epoch: 5| Step: 3
Training loss: 0.15900684893131256
Validation loss: 1.7793761427684496

Epoch: 5| Step: 4
Training loss: 0.22037844359874725
Validation loss: 1.8399898903344267

Epoch: 5| Step: 5
Training loss: 0.1851414442062378
Validation loss: 1.8482700881137644

Epoch: 5| Step: 6
Training loss: 0.5321668982505798
Validation loss: 1.8698733750210013

Epoch: 5| Step: 7
Training loss: 0.313247948884964
Validation loss: 1.809793371026234

Epoch: 5| Step: 8
Training loss: 0.4727732241153717
Validation loss: 1.826418859984285

Epoch: 5| Step: 9
Training loss: 0.29502880573272705
Validation loss: 1.7575027327383719

Epoch: 5| Step: 10
Training loss: 0.24748709797859192
Validation loss: 1.7464201757984776

Epoch: 364| Step: 0
Training loss: 0.259899377822876
Validation loss: 1.7314197863301923

Epoch: 5| Step: 1
Training loss: 0.3237478733062744
Validation loss: 1.7006051899284444

Epoch: 5| Step: 2
Training loss: 0.3202744722366333
Validation loss: 1.6974792711196407

Epoch: 5| Step: 3
Training loss: 0.3200124204158783
Validation loss: 1.7205303599757533

Epoch: 5| Step: 4
Training loss: 0.17703160643577576
Validation loss: 1.7521254247234714

Epoch: 5| Step: 5
Training loss: 0.41735878586769104
Validation loss: 1.7958650550534647

Epoch: 5| Step: 6
Training loss: 0.2471572905778885
Validation loss: 1.7974112815754388

Epoch: 5| Step: 7
Training loss: 0.26764416694641113
Validation loss: 1.8516832295284475

Epoch: 5| Step: 8
Training loss: 0.28856685757637024
Validation loss: 1.8531192989759548

Epoch: 5| Step: 9
Training loss: 0.18974563479423523
Validation loss: 1.8828724058725501

Epoch: 5| Step: 10
Training loss: 0.37573033571243286
Validation loss: 1.883884770895845

Epoch: 365| Step: 0
Training loss: 0.28774747252464294
Validation loss: 1.8912367615648495

Epoch: 5| Step: 1
Training loss: 0.254543662071228
Validation loss: 1.8554951965167958

Epoch: 5| Step: 2
Training loss: 0.2619751989841461
Validation loss: 1.8457642511654926

Epoch: 5| Step: 3
Training loss: 0.31476980447769165
Validation loss: 1.8105977209665443

Epoch: 5| Step: 4
Training loss: 0.27722516655921936
Validation loss: 1.8302409059257918

Epoch: 5| Step: 5
Training loss: 0.3136439919471741
Validation loss: 1.81382849267734

Epoch: 5| Step: 6
Training loss: 0.3504638075828552
Validation loss: 1.82975035841747

Epoch: 5| Step: 7
Training loss: 0.23269876837730408
Validation loss: 1.84277404251919

Epoch: 5| Step: 8
Training loss: 0.2531875967979431
Validation loss: 1.8398682148225847

Epoch: 5| Step: 9
Training loss: 0.27766841650009155
Validation loss: 1.7954719169165498

Epoch: 5| Step: 10
Training loss: 0.22314655780792236
Validation loss: 1.8172669320978143

Epoch: 366| Step: 0
Training loss: 0.19592717289924622
Validation loss: 1.7977315597636725

Epoch: 5| Step: 1
Training loss: 0.3348633646965027
Validation loss: 1.8531851768493652

Epoch: 5| Step: 2
Training loss: 0.40446728467941284
Validation loss: 1.8419739597587175

Epoch: 5| Step: 3
Training loss: 0.3376864790916443
Validation loss: 1.8376605779893938

Epoch: 5| Step: 4
Training loss: 0.1833292841911316
Validation loss: 1.8747441602009598

Epoch: 5| Step: 5
Training loss: 0.18841426074504852
Validation loss: 1.8506844197550127

Epoch: 5| Step: 6
Training loss: 0.3029491603374481
Validation loss: 1.8771036042962024

Epoch: 5| Step: 7
Training loss: 0.21224167943000793
Validation loss: 1.911448609444403

Epoch: 5| Step: 8
Training loss: 0.2990368902683258
Validation loss: 1.9130330034481582

Epoch: 5| Step: 9
Training loss: 0.2599468529224396
Validation loss: 1.8625254695133497

Epoch: 5| Step: 10
Training loss: 0.3611905574798584
Validation loss: 1.8543864668056529

Epoch: 367| Step: 0
Training loss: 0.3568597435951233
Validation loss: 1.8446090887951594

Epoch: 5| Step: 1
Training loss: 0.1645442098379135
Validation loss: 1.8298773227199432

Epoch: 5| Step: 2
Training loss: 0.15496137738227844
Validation loss: 1.8275488512490385

Epoch: 5| Step: 3
Training loss: 0.260712206363678
Validation loss: 1.8909857375647432

Epoch: 5| Step: 4
Training loss: 0.2624132037162781
Validation loss: 1.8571317606074835

Epoch: 5| Step: 5
Training loss: 0.26812419295310974
Validation loss: 1.8725289196096442

Epoch: 5| Step: 6
Training loss: 0.32250645756721497
Validation loss: 1.8220140869899462

Epoch: 5| Step: 7
Training loss: 0.22141234576702118
Validation loss: 1.8015030789118942

Epoch: 5| Step: 8
Training loss: 0.2648826837539673
Validation loss: 1.8041844432071974

Epoch: 5| Step: 9
Training loss: 0.3483564257621765
Validation loss: 1.821831500658425

Epoch: 5| Step: 10
Training loss: 0.30024459958076477
Validation loss: 1.7650948878257506

Epoch: 368| Step: 0
Training loss: 0.3628664016723633
Validation loss: 1.8053632346532678

Epoch: 5| Step: 1
Training loss: 0.34555143117904663
Validation loss: 1.7739781948827928

Epoch: 5| Step: 2
Training loss: 0.35089534521102905
Validation loss: 1.8289591637990807

Epoch: 5| Step: 3
Training loss: 0.29324018955230713
Validation loss: 1.7830452867733535

Epoch: 5| Step: 4
Training loss: 0.4264194071292877
Validation loss: 1.7790295757273191

Epoch: 5| Step: 5
Training loss: 0.280478298664093
Validation loss: 1.7885351386121524

Epoch: 5| Step: 6
Training loss: 0.24814167618751526
Validation loss: 1.7992473122894124

Epoch: 5| Step: 7
Training loss: 0.22029678523540497
Validation loss: 1.7799236364262079

Epoch: 5| Step: 8
Training loss: 0.2845216691493988
Validation loss: 1.818784060016755

Epoch: 5| Step: 9
Training loss: 0.2723158299922943
Validation loss: 1.8468986442012172

Epoch: 5| Step: 10
Training loss: 0.19132398068904877
Validation loss: 1.8547058848924534

Epoch: 369| Step: 0
Training loss: 0.2991856336593628
Validation loss: 1.865716621439944

Epoch: 5| Step: 1
Training loss: 0.2875862717628479
Validation loss: 1.8640913463407947

Epoch: 5| Step: 2
Training loss: 0.3975480794906616
Validation loss: 1.8172029090184036

Epoch: 5| Step: 3
Training loss: 0.25821876525878906
Validation loss: 1.841545686926893

Epoch: 5| Step: 4
Training loss: 0.2404773235321045
Validation loss: 1.8313168876914567

Epoch: 5| Step: 5
Training loss: 0.3572039008140564
Validation loss: 1.807885382765083

Epoch: 5| Step: 6
Training loss: 0.3254031240940094
Validation loss: 1.7921027214296403

Epoch: 5| Step: 7
Training loss: 0.18578624725341797
Validation loss: 1.793503951000911

Epoch: 5| Step: 8
Training loss: 0.20833444595336914
Validation loss: 1.7927625281836397

Epoch: 5| Step: 9
Training loss: 0.1791035681962967
Validation loss: 1.789460173217199

Epoch: 5| Step: 10
Training loss: 0.20566348731517792
Validation loss: 1.7861490582907071

Epoch: 370| Step: 0
Training loss: 0.17403949797153473
Validation loss: 1.7851553552894182

Epoch: 5| Step: 1
Training loss: 0.13244260847568512
Validation loss: 1.790535391017955

Epoch: 5| Step: 2
Training loss: 0.29094773530960083
Validation loss: 1.8090630116001252

Epoch: 5| Step: 3
Training loss: 0.27120715379714966
Validation loss: 1.8147245094340334

Epoch: 5| Step: 4
Training loss: 0.4829856753349304
Validation loss: 1.8458149151135517

Epoch: 5| Step: 5
Training loss: 0.2042846977710724
Validation loss: 1.8116933197103522

Epoch: 5| Step: 6
Training loss: 0.3506610095500946
Validation loss: 1.7557846269299906

Epoch: 5| Step: 7
Training loss: 0.20193831622600555
Validation loss: 1.77700037212782

Epoch: 5| Step: 8
Training loss: 0.12570568919181824
Validation loss: 1.7446112273841776

Epoch: 5| Step: 9
Training loss: 0.3556133806705475
Validation loss: 1.7625176701494443

Epoch: 5| Step: 10
Training loss: 0.31272292137145996
Validation loss: 1.743465208238171

Epoch: 371| Step: 0
Training loss: 0.20324258506298065
Validation loss: 1.7883293859420284

Epoch: 5| Step: 1
Training loss: 0.16606561839580536
Validation loss: 1.7833697052412136

Epoch: 5| Step: 2
Training loss: 0.16501590609550476
Validation loss: 1.8073734391120173

Epoch: 5| Step: 3
Training loss: 0.27630218863487244
Validation loss: 1.8616128583108225

Epoch: 5| Step: 4
Training loss: 0.22462964057922363
Validation loss: 1.8545508846159904

Epoch: 5| Step: 5
Training loss: 0.26295602321624756
Validation loss: 1.844021761289207

Epoch: 5| Step: 6
Training loss: 0.2936544418334961
Validation loss: 1.7987678422722766

Epoch: 5| Step: 7
Training loss: 0.2459222376346588
Validation loss: 1.7629302586278608

Epoch: 5| Step: 8
Training loss: 0.3067936301231384
Validation loss: 1.7736372159373375

Epoch: 5| Step: 9
Training loss: 0.36033663153648376
Validation loss: 1.7774318828377673

Epoch: 5| Step: 10
Training loss: 0.29837727546691895
Validation loss: 1.789487108107536

Epoch: 372| Step: 0
Training loss: 0.2745867967605591
Validation loss: 1.7606970392247683

Epoch: 5| Step: 1
Training loss: 0.2582912743091583
Validation loss: 1.7784104244683379

Epoch: 5| Step: 2
Training loss: 0.21164265275001526
Validation loss: 1.7965682616797827

Epoch: 5| Step: 3
Training loss: 0.2860870957374573
Validation loss: 1.7944722149961738

Epoch: 5| Step: 4
Training loss: 0.23347163200378418
Validation loss: 1.8659769860647057

Epoch: 5| Step: 5
Training loss: 0.2518724501132965
Validation loss: 1.85495465032516

Epoch: 5| Step: 6
Training loss: 0.15067985653877258
Validation loss: 1.8103898366292317

Epoch: 5| Step: 7
Training loss: 0.19362790882587433
Validation loss: 1.8264688420039352

Epoch: 5| Step: 8
Training loss: 0.363225519657135
Validation loss: 1.8395665076471144

Epoch: 5| Step: 9
Training loss: 0.3357695937156677
Validation loss: 1.8219412014048586

Epoch: 5| Step: 10
Training loss: 0.21611998975276947
Validation loss: 1.847148128735122

Epoch: 373| Step: 0
Training loss: 0.42922496795654297
Validation loss: 1.810940255400955

Epoch: 5| Step: 1
Training loss: 0.1691538393497467
Validation loss: 1.8003879362537014

Epoch: 5| Step: 2
Training loss: 0.19302316009998322
Validation loss: 1.7682927334180443

Epoch: 5| Step: 3
Training loss: 0.16978085041046143
Validation loss: 1.8236929139783304

Epoch: 5| Step: 4
Training loss: 0.3226073384284973
Validation loss: 1.7942766912521855

Epoch: 5| Step: 5
Training loss: 0.20253333449363708
Validation loss: 1.8437056977261779

Epoch: 5| Step: 6
Training loss: 0.2647086977958679
Validation loss: 1.813356887909674

Epoch: 5| Step: 7
Training loss: 0.3163517415523529
Validation loss: 1.791714641355699

Epoch: 5| Step: 8
Training loss: 0.21299394965171814
Validation loss: 1.838698999856108

Epoch: 5| Step: 9
Training loss: 0.36750006675720215
Validation loss: 1.7881700185037428

Epoch: 5| Step: 10
Training loss: 0.11708427965641022
Validation loss: 1.804637970462922

Epoch: 374| Step: 0
Training loss: 0.31318801641464233
Validation loss: 1.781087863829828

Epoch: 5| Step: 1
Training loss: 0.19132187962532043
Validation loss: 1.7921649153514574

Epoch: 5| Step: 2
Training loss: 0.18250493705272675
Validation loss: 1.786730674005324

Epoch: 5| Step: 3
Training loss: 0.33686667680740356
Validation loss: 1.7801197421166204

Epoch: 5| Step: 4
Training loss: 0.13627350330352783
Validation loss: 1.804482231857956

Epoch: 5| Step: 5
Training loss: 0.22851333022117615
Validation loss: 1.7924210973965224

Epoch: 5| Step: 6
Training loss: 0.36546269059181213
Validation loss: 1.7996404683718117

Epoch: 5| Step: 7
Training loss: 0.18648937344551086
Validation loss: 1.8172260997115925

Epoch: 5| Step: 8
Training loss: 0.25157079100608826
Validation loss: 1.8211453037877237

Epoch: 5| Step: 9
Training loss: 0.3241986632347107
Validation loss: 1.806550295122208

Epoch: 5| Step: 10
Training loss: 0.34774792194366455
Validation loss: 1.784818467273507

Epoch: 375| Step: 0
Training loss: 0.2673741579055786
Validation loss: 1.772502996588266

Epoch: 5| Step: 1
Training loss: 0.30054640769958496
Validation loss: 1.8084042264569191

Epoch: 5| Step: 2
Training loss: 0.19921231269836426
Validation loss: 1.8304674010122977

Epoch: 5| Step: 3
Training loss: 0.28120121359825134
Validation loss: 1.8182678568747737

Epoch: 5| Step: 4
Training loss: 0.2565949261188507
Validation loss: 1.80902906387083

Epoch: 5| Step: 5
Training loss: 0.14600710570812225
Validation loss: 1.8207594015265023

Epoch: 5| Step: 6
Training loss: 0.2737930715084076
Validation loss: 1.8134241898854573

Epoch: 5| Step: 7
Training loss: 0.19707676768302917
Validation loss: 1.8268523895612327

Epoch: 5| Step: 8
Training loss: 0.33548176288604736
Validation loss: 1.8034038941065471

Epoch: 5| Step: 9
Training loss: 0.18634775280952454
Validation loss: 1.7844549097040647

Epoch: 5| Step: 10
Training loss: 0.1847829818725586
Validation loss: 1.7933313705587899

Epoch: 376| Step: 0
Training loss: 0.2726667523384094
Validation loss: 1.8149486369984125

Epoch: 5| Step: 1
Training loss: 0.19341059029102325
Validation loss: 1.7835702383390037

Epoch: 5| Step: 2
Training loss: 0.22812554240226746
Validation loss: 1.759902677228374

Epoch: 5| Step: 3
Training loss: 0.3708418607711792
Validation loss: 1.7690635317115373

Epoch: 5| Step: 4
Training loss: 0.23087123036384583
Validation loss: 1.7664975709812616

Epoch: 5| Step: 5
Training loss: 0.22080159187316895
Validation loss: 1.7401759521935576

Epoch: 5| Step: 6
Training loss: 0.33811861276626587
Validation loss: 1.8142680275824763

Epoch: 5| Step: 7
Training loss: 0.24601531028747559
Validation loss: 1.8146994203649542

Epoch: 5| Step: 8
Training loss: 0.3487411439418793
Validation loss: 1.8118304411570232

Epoch: 5| Step: 9
Training loss: 0.18647153675556183
Validation loss: 1.819872340848369

Epoch: 5| Step: 10
Training loss: 0.2401634156703949
Validation loss: 1.8021421150494648

Epoch: 377| Step: 0
Training loss: 0.41399067640304565
Validation loss: 1.8342308536652596

Epoch: 5| Step: 1
Training loss: 0.18569472432136536
Validation loss: 1.7900496990449968

Epoch: 5| Step: 2
Training loss: 0.15893985331058502
Validation loss: 1.8481602348307127

Epoch: 5| Step: 3
Training loss: 0.19987276196479797
Validation loss: 1.8454575230998378

Epoch: 5| Step: 4
Training loss: 0.20335638523101807
Validation loss: 1.8382155574778074

Epoch: 5| Step: 5
Training loss: 0.10937179625034332
Validation loss: 1.8357233206431072

Epoch: 5| Step: 6
Training loss: 0.2620117664337158
Validation loss: 1.815718884109169

Epoch: 5| Step: 7
Training loss: 0.18044093251228333
Validation loss: 1.820422908311249

Epoch: 5| Step: 8
Training loss: 0.32064276933670044
Validation loss: 1.7851193438294113

Epoch: 5| Step: 9
Training loss: 0.2912158668041229
Validation loss: 1.8344660600026448

Epoch: 5| Step: 10
Training loss: 0.15016961097717285
Validation loss: 1.805624924680238

Epoch: 378| Step: 0
Training loss: 0.29533514380455017
Validation loss: 1.798319770443824

Epoch: 5| Step: 1
Training loss: 0.3682538568973541
Validation loss: 1.79362149905133

Epoch: 5| Step: 2
Training loss: 0.19725081324577332
Validation loss: 1.7984012173068138

Epoch: 5| Step: 3
Training loss: 0.3217439353466034
Validation loss: 1.8453352784597745

Epoch: 5| Step: 4
Training loss: 0.14534325897693634
Validation loss: 1.8130976987141434

Epoch: 5| Step: 5
Training loss: 0.2895054221153259
Validation loss: 1.8863467426710232

Epoch: 5| Step: 6
Training loss: 0.2689703702926636
Validation loss: 1.8921289508060744

Epoch: 5| Step: 7
Training loss: 0.30958104133605957
Validation loss: 1.8950103848211226

Epoch: 5| Step: 8
Training loss: 0.26939821243286133
Validation loss: 1.9099791870322278

Epoch: 5| Step: 9
Training loss: 0.26063451170921326
Validation loss: 1.8596794041254188

Epoch: 5| Step: 10
Training loss: 0.20034177601337433
Validation loss: 1.843530096033568

Epoch: 379| Step: 0
Training loss: 0.19512388110160828
Validation loss: 1.806822052565954

Epoch: 5| Step: 1
Training loss: 0.3740329146385193
Validation loss: 1.7681589241950744

Epoch: 5| Step: 2
Training loss: 0.21670547127723694
Validation loss: 1.8223785674700173

Epoch: 5| Step: 3
Training loss: 0.3246825039386749
Validation loss: 1.769398073996267

Epoch: 5| Step: 4
Training loss: 0.2890661954879761
Validation loss: 1.7687762386055403

Epoch: 5| Step: 5
Training loss: 0.2164367437362671
Validation loss: 1.7849313443706882

Epoch: 5| Step: 6
Training loss: 0.3309277892112732
Validation loss: 1.8107591405991585

Epoch: 5| Step: 7
Training loss: 0.3243183493614197
Validation loss: 1.827874388746036

Epoch: 5| Step: 8
Training loss: 0.49506649374961853
Validation loss: 1.8126241494250555

Epoch: 5| Step: 9
Training loss: 0.18419571220874786
Validation loss: 1.8247124879590926

Epoch: 5| Step: 10
Training loss: 0.3084716796875
Validation loss: 1.8552157725057294

Epoch: 380| Step: 0
Training loss: 0.2616046667098999
Validation loss: 1.876545956057887

Epoch: 5| Step: 1
Training loss: 0.30156970024108887
Validation loss: 1.8685795357150417

Epoch: 5| Step: 2
Training loss: 0.20185700058937073
Validation loss: 1.8686626367671515

Epoch: 5| Step: 3
Training loss: 0.1843089759349823
Validation loss: 1.8699278549481464

Epoch: 5| Step: 4
Training loss: 0.16092205047607422
Validation loss: 1.849478333227096

Epoch: 5| Step: 5
Training loss: 0.3060153126716614
Validation loss: 1.7843488493273336

Epoch: 5| Step: 6
Training loss: 0.2458718717098236
Validation loss: 1.7986913240084084

Epoch: 5| Step: 7
Training loss: 0.294750839471817
Validation loss: 1.7351223166270922

Epoch: 5| Step: 8
Training loss: 0.28644776344299316
Validation loss: 1.748821045762749

Epoch: 5| Step: 9
Training loss: 0.23131418228149414
Validation loss: 1.7319271256846767

Epoch: 5| Step: 10
Training loss: 0.628434956073761
Validation loss: 1.7359452606529318

Epoch: 381| Step: 0
Training loss: 0.28602829575538635
Validation loss: 1.7751564184824626

Epoch: 5| Step: 1
Training loss: 0.2801455557346344
Validation loss: 1.7322209201833254

Epoch: 5| Step: 2
Training loss: 0.3401128947734833
Validation loss: 1.770759795301704

Epoch: 5| Step: 3
Training loss: 0.3274213671684265
Validation loss: 1.8400835965269355

Epoch: 5| Step: 4
Training loss: 0.10121726989746094
Validation loss: 1.8297479973044446

Epoch: 5| Step: 5
Training loss: 0.44392362236976624
Validation loss: 1.8070574627127698

Epoch: 5| Step: 6
Training loss: 0.21116241812705994
Validation loss: 1.8319899766675887

Epoch: 5| Step: 7
Training loss: 0.15470890700817108
Validation loss: 1.8173611574275519

Epoch: 5| Step: 8
Training loss: 0.2110508680343628
Validation loss: 1.8218035069845055

Epoch: 5| Step: 9
Training loss: 0.24901700019836426
Validation loss: 1.7823041869748024

Epoch: 5| Step: 10
Training loss: 0.20234577357769012
Validation loss: 1.766972485408988

Epoch: 382| Step: 0
Training loss: 0.36765366792678833
Validation loss: 1.8138178010140695

Epoch: 5| Step: 1
Training loss: 0.1107940822839737
Validation loss: 1.7884021882087953

Epoch: 5| Step: 2
Training loss: 0.25371408462524414
Validation loss: 1.7990940873340895

Epoch: 5| Step: 3
Training loss: 0.18278992176055908
Validation loss: 1.772592088227631

Epoch: 5| Step: 4
Training loss: 0.3116649091243744
Validation loss: 1.7752169114287182

Epoch: 5| Step: 5
Training loss: 0.20123791694641113
Validation loss: 1.7714825471242268

Epoch: 5| Step: 6
Training loss: 0.27171945571899414
Validation loss: 1.7641359452278382

Epoch: 5| Step: 7
Training loss: 0.12804090976715088
Validation loss: 1.7484348909829253

Epoch: 5| Step: 8
Training loss: 0.3023764491081238
Validation loss: 1.762802356032915

Epoch: 5| Step: 9
Training loss: 0.28022050857543945
Validation loss: 1.7278256685503068

Epoch: 5| Step: 10
Training loss: 0.23378337919712067
Validation loss: 1.7665079396258119

Epoch: 383| Step: 0
Training loss: 0.2571028172969818
Validation loss: 1.7774672226239276

Epoch: 5| Step: 1
Training loss: 0.26927345991134644
Validation loss: 1.797380519169633

Epoch: 5| Step: 2
Training loss: 0.2183171957731247
Validation loss: 1.8085193352032733

Epoch: 5| Step: 3
Training loss: 0.3645295202732086
Validation loss: 1.8008848954272527

Epoch: 5| Step: 4
Training loss: 0.1969139575958252
Validation loss: 1.8702138457247006

Epoch: 5| Step: 5
Training loss: 0.23503994941711426
Validation loss: 1.861455576394194

Epoch: 5| Step: 6
Training loss: 0.19028842449188232
Validation loss: 1.8443827911089825

Epoch: 5| Step: 7
Training loss: 0.17829158902168274
Validation loss: 1.831492930330256

Epoch: 5| Step: 8
Training loss: 0.22256815433502197
Validation loss: 1.7982219829354236

Epoch: 5| Step: 9
Training loss: 0.13255886733531952
Validation loss: 1.7868294600517518

Epoch: 5| Step: 10
Training loss: 0.28179559111595154
Validation loss: 1.8000582828316638

Epoch: 384| Step: 0
Training loss: 0.18059054017066956
Validation loss: 1.8092803929441719

Epoch: 5| Step: 1
Training loss: 0.17578229308128357
Validation loss: 1.7925854370158205

Epoch: 5| Step: 2
Training loss: 0.405785471200943
Validation loss: 1.760452239744125

Epoch: 5| Step: 3
Training loss: 0.17427971959114075
Validation loss: 1.7908251029188915

Epoch: 5| Step: 4
Training loss: 0.14256277680397034
Validation loss: 1.7790657897149362

Epoch: 5| Step: 5
Training loss: 0.1930581033229828
Validation loss: 1.8156123584316624

Epoch: 5| Step: 6
Training loss: 0.16882909834384918
Validation loss: 1.7913020759500482

Epoch: 5| Step: 7
Training loss: 0.36768800020217896
Validation loss: 1.7918533125231344

Epoch: 5| Step: 8
Training loss: 0.23177523910999298
Validation loss: 1.788477893798582

Epoch: 5| Step: 9
Training loss: 0.18436476588249207
Validation loss: 1.839630869127089

Epoch: 5| Step: 10
Training loss: 0.32474637031555176
Validation loss: 1.829610110611044

Epoch: 385| Step: 0
Training loss: 0.3267604410648346
Validation loss: 1.8325331903273059

Epoch: 5| Step: 1
Training loss: 0.1408260017633438
Validation loss: 1.8350195295067244

Epoch: 5| Step: 2
Training loss: 0.23309478163719177
Validation loss: 1.8520774764399375

Epoch: 5| Step: 3
Training loss: 0.16698826849460602
Validation loss: 1.8337006991909397

Epoch: 5| Step: 4
Training loss: 0.2831569015979767
Validation loss: 1.78209819844974

Epoch: 5| Step: 5
Training loss: 0.22538581490516663
Validation loss: 1.7998248864245672

Epoch: 5| Step: 6
Training loss: 0.1693611443042755
Validation loss: 1.8028900392593876

Epoch: 5| Step: 7
Training loss: 0.36258283257484436
Validation loss: 1.8087162010131344

Epoch: 5| Step: 8
Training loss: 0.17311252653598785
Validation loss: 1.824497115227484

Epoch: 5| Step: 9
Training loss: 0.24744363129138947
Validation loss: 1.8053976361469557

Epoch: 5| Step: 10
Training loss: 0.17350059747695923
Validation loss: 1.8088964659680602

Epoch: 386| Step: 0
Training loss: 0.15215721726417542
Validation loss: 1.7989659347841818

Epoch: 5| Step: 1
Training loss: 0.28601592779159546
Validation loss: 1.7693726862630537

Epoch: 5| Step: 2
Training loss: 0.17784909904003143
Validation loss: 1.7784303285742318

Epoch: 5| Step: 3
Training loss: 0.2542116045951843
Validation loss: 1.7812072487287625

Epoch: 5| Step: 4
Training loss: 0.24423417448997498
Validation loss: 1.779958027665333

Epoch: 5| Step: 5
Training loss: 0.2031870186328888
Validation loss: 1.7874533976277998

Epoch: 5| Step: 6
Training loss: 0.23158228397369385
Validation loss: 1.7619671719048613

Epoch: 5| Step: 7
Training loss: 0.25689852237701416
Validation loss: 1.7823657886956328

Epoch: 5| Step: 8
Training loss: 0.33213895559310913
Validation loss: 1.7762844716348956

Epoch: 5| Step: 9
Training loss: 0.1649237424135208
Validation loss: 1.776370507414623

Epoch: 5| Step: 10
Training loss: 0.18559476733207703
Validation loss: 1.7432097734943512

Epoch: 387| Step: 0
Training loss: 0.23749251663684845
Validation loss: 1.7542476730961953

Epoch: 5| Step: 1
Training loss: 0.41213446855545044
Validation loss: 1.7710047088643557

Epoch: 5| Step: 2
Training loss: 0.24637973308563232
Validation loss: 1.7489644263380317

Epoch: 5| Step: 3
Training loss: 0.24872565269470215
Validation loss: 1.7472458757380003

Epoch: 5| Step: 4
Training loss: 0.1149340271949768
Validation loss: 1.7642980416615803

Epoch: 5| Step: 5
Training loss: 0.16617634892463684
Validation loss: 1.7634498791028095

Epoch: 5| Step: 6
Training loss: 0.32681727409362793
Validation loss: 1.7792324289198844

Epoch: 5| Step: 7
Training loss: 0.1703277826309204
Validation loss: 1.7844784554614816

Epoch: 5| Step: 8
Training loss: 0.18505828082561493
Validation loss: 1.7892433340831468

Epoch: 5| Step: 9
Training loss: 0.09378204494714737
Validation loss: 1.8176411159576908

Epoch: 5| Step: 10
Training loss: 0.3676859140396118
Validation loss: 1.7913664438391244

Epoch: 388| Step: 0
Training loss: 0.13960525393486023
Validation loss: 1.7891525658228065

Epoch: 5| Step: 1
Training loss: 0.1323358118534088
Validation loss: 1.8289676456041233

Epoch: 5| Step: 2
Training loss: 0.2592533826828003
Validation loss: 1.8390147660368232

Epoch: 5| Step: 3
Training loss: 0.17050743103027344
Validation loss: 1.8290162483851116

Epoch: 5| Step: 4
Training loss: 0.2105448693037033
Validation loss: 1.8663784842337332

Epoch: 5| Step: 5
Training loss: 0.19632533192634583
Validation loss: 1.831583199962493

Epoch: 5| Step: 6
Training loss: 0.1911613643169403
Validation loss: 1.8611034142073763

Epoch: 5| Step: 7
Training loss: 0.3223821520805359
Validation loss: 1.818719910037133

Epoch: 5| Step: 8
Training loss: 0.3156154155731201
Validation loss: 1.82869900426557

Epoch: 5| Step: 9
Training loss: 0.21176843345165253
Validation loss: 1.7958635642964353

Epoch: 5| Step: 10
Training loss: 0.14962442219257355
Validation loss: 1.7256621250542261

Epoch: 389| Step: 0
Training loss: 0.1743805855512619
Validation loss: 1.7744702164844801

Epoch: 5| Step: 1
Training loss: 0.17211461067199707
Validation loss: 1.7436420738056142

Epoch: 5| Step: 2
Training loss: 0.17569246888160706
Validation loss: 1.76552475331932

Epoch: 5| Step: 3
Training loss: 0.21062573790550232
Validation loss: 1.7707615924137894

Epoch: 5| Step: 4
Training loss: 0.24637646973133087
Validation loss: 1.8221853535662416

Epoch: 5| Step: 5
Training loss: 0.29726946353912354
Validation loss: 1.8449494672077957

Epoch: 5| Step: 6
Training loss: 0.25447744131088257
Validation loss: 1.8537227966452157

Epoch: 5| Step: 7
Training loss: 0.32782888412475586
Validation loss: 1.8263694368382937

Epoch: 5| Step: 8
Training loss: 0.16654366254806519
Validation loss: 1.8211533920739287

Epoch: 5| Step: 9
Training loss: 0.29413264989852905
Validation loss: 1.8214740740355624

Epoch: 5| Step: 10
Training loss: 0.17969554662704468
Validation loss: 1.8128165263001637

Epoch: 390| Step: 0
Training loss: 0.10255344212055206
Validation loss: 1.8199233816516014

Epoch: 5| Step: 1
Training loss: 0.29442912340164185
Validation loss: 1.7905643255479875

Epoch: 5| Step: 2
Training loss: 0.12475645542144775
Validation loss: 1.7969855185477965

Epoch: 5| Step: 3
Training loss: 0.35674771666526794
Validation loss: 1.8152136174581384

Epoch: 5| Step: 4
Training loss: 0.23584803938865662
Validation loss: 1.780910515016125

Epoch: 5| Step: 5
Training loss: 0.14840462803840637
Validation loss: 1.83825558488087

Epoch: 5| Step: 6
Training loss: 0.256694495677948
Validation loss: 1.819011337013655

Epoch: 5| Step: 7
Training loss: 0.2008344829082489
Validation loss: 1.8413333713367421

Epoch: 5| Step: 8
Training loss: 0.307740181684494
Validation loss: 1.8737754539776874

Epoch: 5| Step: 9
Training loss: 0.2348633110523224
Validation loss: 1.8517718161306074

Epoch: 5| Step: 10
Training loss: 0.2599509358406067
Validation loss: 1.8309930857791696

Epoch: 391| Step: 0
Training loss: 0.19426670670509338
Validation loss: 1.832199599153252

Epoch: 5| Step: 1
Training loss: 0.19777333736419678
Validation loss: 1.7789842505608835

Epoch: 5| Step: 2
Training loss: 0.27336829900741577
Validation loss: 1.7529309693203177

Epoch: 5| Step: 3
Training loss: 0.3033449947834015
Validation loss: 1.816010481567793

Epoch: 5| Step: 4
Training loss: 0.2220800369977951
Validation loss: 1.7603416327507264

Epoch: 5| Step: 5
Training loss: 0.4944358468055725
Validation loss: 1.7390925961156045

Epoch: 5| Step: 6
Training loss: 0.28583016991615295
Validation loss: 1.6929235253282773

Epoch: 5| Step: 7
Training loss: 0.15904048085212708
Validation loss: 1.7399953744744743

Epoch: 5| Step: 8
Training loss: 0.28149324655532837
Validation loss: 1.760701084649691

Epoch: 5| Step: 9
Training loss: 0.1685231477022171
Validation loss: 1.786011601007113

Epoch: 5| Step: 10
Training loss: 0.28143906593322754
Validation loss: 1.8332577315709924

Epoch: 392| Step: 0
Training loss: 0.2526312470436096
Validation loss: 1.803901332680897

Epoch: 5| Step: 1
Training loss: 0.1458873301744461
Validation loss: 1.8112426457866546

Epoch: 5| Step: 2
Training loss: 0.17962780594825745
Validation loss: 1.8007282313480173

Epoch: 5| Step: 3
Training loss: 0.2092485874891281
Validation loss: 1.8204152199529833

Epoch: 5| Step: 4
Training loss: 0.21385595202445984
Validation loss: 1.7992532086628739

Epoch: 5| Step: 5
Training loss: 0.16721782088279724
Validation loss: 1.7505525568480134

Epoch: 5| Step: 6
Training loss: 0.31930315494537354
Validation loss: 1.753889977291066

Epoch: 5| Step: 7
Training loss: 0.2660120129585266
Validation loss: 1.7726287687978437

Epoch: 5| Step: 8
Training loss: 0.21201229095458984
Validation loss: 1.7570209221173358

Epoch: 5| Step: 9
Training loss: 0.2493559867143631
Validation loss: 1.7651343371278496

Epoch: 5| Step: 10
Training loss: 0.28251731395721436
Validation loss: 1.775994928934241

Epoch: 393| Step: 0
Training loss: 0.16662895679473877
Validation loss: 1.7652446864753641

Epoch: 5| Step: 1
Training loss: 0.15858232975006104
Validation loss: 1.7766739732475691

Epoch: 5| Step: 2
Training loss: 0.28422585129737854
Validation loss: 1.7604251817990375

Epoch: 5| Step: 3
Training loss: 0.19279184937477112
Validation loss: 1.7599353341646091

Epoch: 5| Step: 4
Training loss: 0.25340527296066284
Validation loss: 1.7922473620342951

Epoch: 5| Step: 5
Training loss: 0.24013662338256836
Validation loss: 1.7879885704286638

Epoch: 5| Step: 6
Training loss: 0.2697483003139496
Validation loss: 1.8075163210591962

Epoch: 5| Step: 7
Training loss: 0.26488056778907776
Validation loss: 1.8145103352044218

Epoch: 5| Step: 8
Training loss: 0.34107470512390137
Validation loss: 1.8027644413773731

Epoch: 5| Step: 9
Training loss: 0.20231613516807556
Validation loss: 1.8102117533324866

Epoch: 5| Step: 10
Training loss: 0.20194801688194275
Validation loss: 1.833114170259045

Epoch: 394| Step: 0
Training loss: 0.34260812401771545
Validation loss: 1.779069128856864

Epoch: 5| Step: 1
Training loss: 0.28344154357910156
Validation loss: 1.8059804106271395

Epoch: 5| Step: 2
Training loss: 0.16709664463996887
Validation loss: 1.7655374696177821

Epoch: 5| Step: 3
Training loss: 0.27378687262535095
Validation loss: 1.774484198580506

Epoch: 5| Step: 4
Training loss: 0.23263423144817352
Validation loss: 1.798945971714553

Epoch: 5| Step: 5
Training loss: 0.18061606585979462
Validation loss: 1.758486819523637

Epoch: 5| Step: 6
Training loss: 0.27859336137771606
Validation loss: 1.7528981431838004

Epoch: 5| Step: 7
Training loss: 0.2718808352947235
Validation loss: 1.7538500626881917

Epoch: 5| Step: 8
Training loss: 0.22703289985656738
Validation loss: 1.7495990119954592

Epoch: 5| Step: 9
Training loss: 0.1800663024187088
Validation loss: 1.7380055849270155

Epoch: 5| Step: 10
Training loss: 0.19239479303359985
Validation loss: 1.716978403829759

Epoch: 395| Step: 0
Training loss: 0.3040553629398346
Validation loss: 1.7720444151150283

Epoch: 5| Step: 1
Training loss: 0.27334439754486084
Validation loss: 1.7963708100780365

Epoch: 5| Step: 2
Training loss: 0.2960197329521179
Validation loss: 1.83677577587866

Epoch: 5| Step: 3
Training loss: 0.1933411806821823
Validation loss: 1.7972854920612868

Epoch: 5| Step: 4
Training loss: 0.21289686858654022
Validation loss: 1.7883983376205608

Epoch: 5| Step: 5
Training loss: 0.25280946493148804
Validation loss: 1.7523481692037275

Epoch: 5| Step: 6
Training loss: 0.1851780265569687
Validation loss: 1.7598942415688628

Epoch: 5| Step: 7
Training loss: 0.27644219994544983
Validation loss: 1.7245533709884973

Epoch: 5| Step: 8
Training loss: 0.16807492077350616
Validation loss: 1.7433607039913055

Epoch: 5| Step: 9
Training loss: 0.22792501747608185
Validation loss: 1.7455415418071132

Epoch: 5| Step: 10
Training loss: 0.2906809151172638
Validation loss: 1.7219435322669245

Epoch: 396| Step: 0
Training loss: 0.15853627026081085
Validation loss: 1.7005233803103048

Epoch: 5| Step: 1
Training loss: 0.1216742992401123
Validation loss: 1.7414171208617508

Epoch: 5| Step: 2
Training loss: 0.17662793397903442
Validation loss: 1.7608111314876105

Epoch: 5| Step: 3
Training loss: 0.2662701904773712
Validation loss: 1.8229875872212071

Epoch: 5| Step: 4
Training loss: 0.17921964824199677
Validation loss: 1.7945183861640193

Epoch: 5| Step: 5
Training loss: 0.3916970491409302
Validation loss: 1.8620333992024904

Epoch: 5| Step: 6
Training loss: 0.2421375811100006
Validation loss: 1.867380262703024

Epoch: 5| Step: 7
Training loss: 0.25551334023475647
Validation loss: 1.8760712877396615

Epoch: 5| Step: 8
Training loss: 0.24388213455677032
Validation loss: 1.84314682919492

Epoch: 5| Step: 9
Training loss: 0.13669607043266296
Validation loss: 1.835625289588846

Epoch: 5| Step: 10
Training loss: 0.1829550713300705
Validation loss: 1.8191285235907442

Epoch: 397| Step: 0
Training loss: 0.18674582242965698
Validation loss: 1.8261848239488498

Epoch: 5| Step: 1
Training loss: 0.13131186366081238
Validation loss: 1.8075232685253184

Epoch: 5| Step: 2
Training loss: 0.18053919076919556
Validation loss: 1.8026044778926398

Epoch: 5| Step: 3
Training loss: 0.3270339071750641
Validation loss: 1.7736700529693274

Epoch: 5| Step: 4
Training loss: 0.20539669692516327
Validation loss: 1.7678659936433196

Epoch: 5| Step: 5
Training loss: 0.25222283601760864
Validation loss: 1.7405924938058341

Epoch: 5| Step: 6
Training loss: 0.16362448036670685
Validation loss: 1.7097393017943188

Epoch: 5| Step: 7
Training loss: 0.16179558634757996
Validation loss: 1.7192310466561267

Epoch: 5| Step: 8
Training loss: 0.2069920301437378
Validation loss: 1.7528171846943517

Epoch: 5| Step: 9
Training loss: 0.33987683057785034
Validation loss: 1.7636120037365985

Epoch: 5| Step: 10
Training loss: 0.1645645946264267
Validation loss: 1.7835981333127586

Epoch: 398| Step: 0
Training loss: 0.14555040001869202
Validation loss: 1.8150285866952711

Epoch: 5| Step: 1
Training loss: 0.22170868515968323
Validation loss: 1.857099280562452

Epoch: 5| Step: 2
Training loss: 0.14582282304763794
Validation loss: 1.8656090638970817

Epoch: 5| Step: 3
Training loss: 0.2763320803642273
Validation loss: 1.8592823525910736

Epoch: 5| Step: 4
Training loss: 0.25656864047050476
Validation loss: 1.8302316358012538

Epoch: 5| Step: 5
Training loss: 0.22013382613658905
Validation loss: 1.8184587519655946

Epoch: 5| Step: 6
Training loss: 0.21206089854240417
Validation loss: 1.8080851800980107

Epoch: 5| Step: 7
Training loss: 0.22407980263233185
Validation loss: 1.8126185991430794

Epoch: 5| Step: 8
Training loss: 0.26872557401657104
Validation loss: 1.7578084161204677

Epoch: 5| Step: 9
Training loss: 0.148819237947464
Validation loss: 1.7986774521489297

Epoch: 5| Step: 10
Training loss: 0.13238950073719025
Validation loss: 1.7845900263837589

Epoch: 399| Step: 0
Training loss: 0.2057439088821411
Validation loss: 1.8192291913493988

Epoch: 5| Step: 1
Training loss: 0.29264530539512634
Validation loss: 1.7530841853028984

Epoch: 5| Step: 2
Training loss: 0.3941003680229187
Validation loss: 1.7643471494797738

Epoch: 5| Step: 3
Training loss: 0.17901793122291565
Validation loss: 1.7483992743235763

Epoch: 5| Step: 4
Training loss: 0.1392134726047516
Validation loss: 1.7697424516882947

Epoch: 5| Step: 5
Training loss: 0.36278030276298523
Validation loss: 1.7556776141607633

Epoch: 5| Step: 6
Training loss: 0.2025156021118164
Validation loss: 1.7928260680167907

Epoch: 5| Step: 7
Training loss: 0.2608461081981659
Validation loss: 1.7855372210984588

Epoch: 5| Step: 8
Training loss: 0.323508083820343
Validation loss: 1.8129995343505696

Epoch: 5| Step: 9
Training loss: 0.1281662881374359
Validation loss: 1.8243697740698372

Epoch: 5| Step: 10
Training loss: 0.20136238634586334
Validation loss: 1.8175382268044256

Epoch: 400| Step: 0
Training loss: 0.2176520824432373
Validation loss: 1.852393557948451

Epoch: 5| Step: 1
Training loss: 0.2049599587917328
Validation loss: 1.8084782554257302

Epoch: 5| Step: 2
Training loss: 0.27665072679519653
Validation loss: 1.7878169295608357

Epoch: 5| Step: 3
Training loss: 0.21214476227760315
Validation loss: 1.762817696858478

Epoch: 5| Step: 4
Training loss: 0.16858235001564026
Validation loss: 1.7438003927148797

Epoch: 5| Step: 5
Training loss: 0.2147665023803711
Validation loss: 1.760144837440983

Epoch: 5| Step: 6
Training loss: 0.2999684810638428
Validation loss: 1.7175022068844046

Epoch: 5| Step: 7
Training loss: 0.19855192303657532
Validation loss: 1.6921707930103425

Epoch: 5| Step: 8
Training loss: 0.252676784992218
Validation loss: 1.708879255479382

Epoch: 5| Step: 9
Training loss: 0.16215059161186218
Validation loss: 1.7477553403505715

Epoch: 5| Step: 10
Training loss: 0.18984355032444
Validation loss: 1.770017780283446

Epoch: 401| Step: 0
Training loss: 0.21316909790039062
Validation loss: 1.7459230704974102

Epoch: 5| Step: 1
Training loss: 0.2848948538303375
Validation loss: 1.7492274853491014

Epoch: 5| Step: 2
Training loss: 0.13839466869831085
Validation loss: 1.7591923770084177

Epoch: 5| Step: 3
Training loss: 0.291441410779953
Validation loss: 1.7633518006211968

Epoch: 5| Step: 4
Training loss: 0.17541146278381348
Validation loss: 1.754031127498996

Epoch: 5| Step: 5
Training loss: 0.17112044990062714
Validation loss: 1.736164980037238

Epoch: 5| Step: 6
Training loss: 0.14736728370189667
Validation loss: 1.7317992448806763

Epoch: 5| Step: 7
Training loss: 0.21124644577503204
Validation loss: 1.7446287267951555

Epoch: 5| Step: 8
Training loss: 0.2861855626106262
Validation loss: 1.752116645536115

Epoch: 5| Step: 9
Training loss: 0.14098340272903442
Validation loss: 1.7515401455663866

Epoch: 5| Step: 10
Training loss: 0.21237409114837646
Validation loss: 1.6991800941446775

Epoch: 402| Step: 0
Training loss: 0.28756585717201233
Validation loss: 1.7294447216936337

Epoch: 5| Step: 1
Training loss: 0.18911734223365784
Validation loss: 1.7057470890783495

Epoch: 5| Step: 2
Training loss: 0.2596408426761627
Validation loss: 1.7285810029634865

Epoch: 5| Step: 3
Training loss: 0.14088129997253418
Validation loss: 1.7668059513133059

Epoch: 5| Step: 4
Training loss: 0.4472399353981018
Validation loss: 1.7723192912276073

Epoch: 5| Step: 5
Training loss: 0.20414991676807404
Validation loss: 1.761410423504409

Epoch: 5| Step: 6
Training loss: 0.2174443006515503
Validation loss: 1.7485591365445046

Epoch: 5| Step: 7
Training loss: 0.12364505231380463
Validation loss: 1.7341204663758636

Epoch: 5| Step: 8
Training loss: 0.15357491374015808
Validation loss: 1.734933614730835

Epoch: 5| Step: 9
Training loss: 0.15419594943523407
Validation loss: 1.729054763752927

Epoch: 5| Step: 10
Training loss: 0.168091282248497
Validation loss: 1.7830285692727694

Epoch: 403| Step: 0
Training loss: 0.21370506286621094
Validation loss: 1.756674564012917

Epoch: 5| Step: 1
Training loss: 0.17674937844276428
Validation loss: 1.7760096403860277

Epoch: 5| Step: 2
Training loss: 0.19247093796730042
Validation loss: 1.7754198287122993

Epoch: 5| Step: 3
Training loss: 0.14075900614261627
Validation loss: 1.7767275559004916

Epoch: 5| Step: 4
Training loss: 0.26313072443008423
Validation loss: 1.7618226723004413

Epoch: 5| Step: 5
Training loss: 0.21338658034801483
Validation loss: 1.7865128709423927

Epoch: 5| Step: 6
Training loss: 0.14924296736717224
Validation loss: 1.7825603472289218

Epoch: 5| Step: 7
Training loss: 0.21972830593585968
Validation loss: 1.7752733743318947

Epoch: 5| Step: 8
Training loss: 0.2800271809101105
Validation loss: 1.7993974147304412

Epoch: 5| Step: 9
Training loss: 0.2281349152326584
Validation loss: 1.8014139077996696

Epoch: 5| Step: 10
Training loss: 0.1841985136270523
Validation loss: 1.811982234319051

Epoch: 404| Step: 0
Training loss: 0.2761380970478058
Validation loss: 1.8062792811342465

Epoch: 5| Step: 1
Training loss: 0.16427108645439148
Validation loss: 1.7909120378955719

Epoch: 5| Step: 2
Training loss: 0.2419908493757248
Validation loss: 1.8455237368101716

Epoch: 5| Step: 3
Training loss: 0.24450917541980743
Validation loss: 1.8509312470753987

Epoch: 5| Step: 4
Training loss: 0.12853609025478363
Validation loss: 1.844111019565213

Epoch: 5| Step: 5
Training loss: 0.1219826191663742
Validation loss: 1.8469894650161907

Epoch: 5| Step: 6
Training loss: 0.2000616490840912
Validation loss: 1.7938255020367202

Epoch: 5| Step: 7
Training loss: 0.2496688812971115
Validation loss: 1.8039232248901038

Epoch: 5| Step: 8
Training loss: 0.21754896640777588
Validation loss: 1.822859505171417

Epoch: 5| Step: 9
Training loss: 0.300369530916214
Validation loss: 1.7802724466528943

Epoch: 5| Step: 10
Training loss: 0.18637478351593018
Validation loss: 1.8089209423270276

Epoch: 405| Step: 0
Training loss: 0.2760137915611267
Validation loss: 1.7589197004995039

Epoch: 5| Step: 1
Training loss: 0.18170978128910065
Validation loss: 1.7777486296110256

Epoch: 5| Step: 2
Training loss: 0.16509690880775452
Validation loss: 1.7940566411582373

Epoch: 5| Step: 3
Training loss: 0.16489115357398987
Validation loss: 1.7932445951687392

Epoch: 5| Step: 4
Training loss: 0.2718833386898041
Validation loss: 1.7963348409181

Epoch: 5| Step: 5
Training loss: 0.28006479144096375
Validation loss: 1.7905748416018743

Epoch: 5| Step: 6
Training loss: 0.16048845648765564
Validation loss: 1.7791429309434788

Epoch: 5| Step: 7
Training loss: 0.2138478010892868
Validation loss: 1.8030953791833693

Epoch: 5| Step: 8
Training loss: 0.2008470594882965
Validation loss: 1.7797719342734224

Epoch: 5| Step: 9
Training loss: 0.2269313782453537
Validation loss: 1.7801185730964906

Epoch: 5| Step: 10
Training loss: 0.1372493952512741
Validation loss: 1.824736043971072

Epoch: 406| Step: 0
Training loss: 0.18065620958805084
Validation loss: 1.8056241068788754

Epoch: 5| Step: 1
Training loss: 0.1257491111755371
Validation loss: 1.7935455076156124

Epoch: 5| Step: 2
Training loss: 0.17402319610118866
Validation loss: 1.7772923182415705

Epoch: 5| Step: 3
Training loss: 0.1994277536869049
Validation loss: 1.7859763765847811

Epoch: 5| Step: 4
Training loss: 0.21855835616588593
Validation loss: 1.7870152265794816

Epoch: 5| Step: 5
Training loss: 0.12055543810129166
Validation loss: 1.7776917821617537

Epoch: 5| Step: 6
Training loss: 0.16865545511245728
Validation loss: 1.8041975703290714

Epoch: 5| Step: 7
Training loss: 0.38749462366104126
Validation loss: 1.7889534337546236

Epoch: 5| Step: 8
Training loss: 0.14309200644493103
Validation loss: 1.8222314670521726

Epoch: 5| Step: 9
Training loss: 0.19596686959266663
Validation loss: 1.808507292501388

Epoch: 5| Step: 10
Training loss: 0.23620930314064026
Validation loss: 1.8485120445169427

Epoch: 407| Step: 0
Training loss: 0.15669527649879456
Validation loss: 1.8202153713472429

Epoch: 5| Step: 1
Training loss: 0.282755970954895
Validation loss: 1.82973615841199

Epoch: 5| Step: 2
Training loss: 0.13188371062278748
Validation loss: 1.8357698430297196

Epoch: 5| Step: 3
Training loss: 0.24008341133594513
Validation loss: 1.816792626534739

Epoch: 5| Step: 4
Training loss: 0.09914703667163849
Validation loss: 1.8462575251056301

Epoch: 5| Step: 5
Training loss: 0.18173447251319885
Validation loss: 1.8457401516616985

Epoch: 5| Step: 6
Training loss: 0.16285285353660583
Validation loss: 1.8291289832002373

Epoch: 5| Step: 7
Training loss: 0.17660591006278992
Validation loss: 1.8182861202506608

Epoch: 5| Step: 8
Training loss: 0.32668283581733704
Validation loss: 1.7718301896126039

Epoch: 5| Step: 9
Training loss: 0.18050681054592133
Validation loss: 1.770077113182314

Epoch: 5| Step: 10
Training loss: 0.1674681007862091
Validation loss: 1.733122077039493

Epoch: 408| Step: 0
Training loss: 0.18276649713516235
Validation loss: 1.7361475216445101

Epoch: 5| Step: 1
Training loss: 0.18577656149864197
Validation loss: 1.7373048708003054

Epoch: 5| Step: 2
Training loss: 0.1825096309185028
Validation loss: 1.762126063787809

Epoch: 5| Step: 3
Training loss: 0.2068163901567459
Validation loss: 1.7456307449648458

Epoch: 5| Step: 4
Training loss: 0.2197379320859909
Validation loss: 1.7713214607648953

Epoch: 5| Step: 5
Training loss: 0.28528863191604614
Validation loss: 1.8286179701487224

Epoch: 5| Step: 6
Training loss: 0.17320066690444946
Validation loss: 1.8361548992895311

Epoch: 5| Step: 7
Training loss: 0.16985444724559784
Validation loss: 1.871576092576468

Epoch: 5| Step: 8
Training loss: 0.19106745719909668
Validation loss: 1.8300397793451946

Epoch: 5| Step: 9
Training loss: 0.17699357867240906
Validation loss: 1.806728066936616

Epoch: 5| Step: 10
Training loss: 0.1384814828634262
Validation loss: 1.7977065578583749

Epoch: 409| Step: 0
Training loss: 0.1468690037727356
Validation loss: 1.7878550996062577

Epoch: 5| Step: 1
Training loss: 0.21380086243152618
Validation loss: 1.7866323699233353

Epoch: 5| Step: 2
Training loss: 0.15475070476531982
Validation loss: 1.7756777348056916

Epoch: 5| Step: 3
Training loss: 0.2311217337846756
Validation loss: 1.7861776249383086

Epoch: 5| Step: 4
Training loss: 0.13411808013916016
Validation loss: 1.7707728185961324

Epoch: 5| Step: 5
Training loss: 0.26572296023368835
Validation loss: 1.7284491651801652

Epoch: 5| Step: 6
Training loss: 0.15406207740306854
Validation loss: 1.7868863433919928

Epoch: 5| Step: 7
Training loss: 0.12198289483785629
Validation loss: 1.776332692433429

Epoch: 5| Step: 8
Training loss: 0.13053090870380402
Validation loss: 1.7419985468669603

Epoch: 5| Step: 9
Training loss: 0.1046421155333519
Validation loss: 1.765690606127503

Epoch: 5| Step: 10
Training loss: 0.283294677734375
Validation loss: 1.785659279874576

Epoch: 410| Step: 0
Training loss: 0.26681777834892273
Validation loss: 1.7922504621167337

Epoch: 5| Step: 1
Training loss: 0.08644809573888779
Validation loss: 1.7872412743106965

Epoch: 5| Step: 2
Training loss: 0.2028638869524002
Validation loss: 1.8009504477183025

Epoch: 5| Step: 3
Training loss: 0.15342840552330017
Validation loss: 1.8348311993383593

Epoch: 5| Step: 4
Training loss: 0.1460297554731369
Validation loss: 1.8727080693808935

Epoch: 5| Step: 5
Training loss: 0.20807978510856628
Validation loss: 1.850729178356868

Epoch: 5| Step: 6
Training loss: 0.18863597512245178
Validation loss: 1.858547261966172

Epoch: 5| Step: 7
Training loss: 0.18797698616981506
Validation loss: 1.8429346417868009

Epoch: 5| Step: 8
Training loss: 0.16809919476509094
Validation loss: 1.8295786303858603

Epoch: 5| Step: 9
Training loss: 0.14953181147575378
Validation loss: 1.7904222267930225

Epoch: 5| Step: 10
Training loss: 0.17400199174880981
Validation loss: 1.8197961879032913

Epoch: 411| Step: 0
Training loss: 0.24221058189868927
Validation loss: 1.7828340274031445

Epoch: 5| Step: 1
Training loss: 0.1357521265745163
Validation loss: 1.8147324644109255

Epoch: 5| Step: 2
Training loss: 0.18656206130981445
Validation loss: 1.7940414054419405

Epoch: 5| Step: 3
Training loss: 0.2870464324951172
Validation loss: 1.8249835468107654

Epoch: 5| Step: 4
Training loss: 0.15816427767276764
Validation loss: 1.7990292477351364

Epoch: 5| Step: 5
Training loss: 0.1341996192932129
Validation loss: 1.8257534568027785

Epoch: 5| Step: 6
Training loss: 0.22250866889953613
Validation loss: 1.8290534057924825

Epoch: 5| Step: 7
Training loss: 0.1286594420671463
Validation loss: 1.8519145622048327

Epoch: 5| Step: 8
Training loss: 0.1114540547132492
Validation loss: 1.7955208234889533

Epoch: 5| Step: 9
Training loss: 0.10159729421138763
Validation loss: 1.8197585946770125

Epoch: 5| Step: 10
Training loss: 0.18166308104991913
Validation loss: 1.8050777963412705

Epoch: 412| Step: 0
Training loss: 0.15697956085205078
Validation loss: 1.8042623958280009

Epoch: 5| Step: 1
Training loss: 0.1623632162809372
Validation loss: 1.7973584795510897

Epoch: 5| Step: 2
Training loss: 0.19563508033752441
Validation loss: 1.8293881198411346

Epoch: 5| Step: 3
Training loss: 0.1319439709186554
Validation loss: 1.811334095975404

Epoch: 5| Step: 4
Training loss: 0.20323213934898376
Validation loss: 1.783636725077065

Epoch: 5| Step: 5
Training loss: 0.11284152418375015
Validation loss: 1.811386385271626

Epoch: 5| Step: 6
Training loss: 0.21024659276008606
Validation loss: 1.8275518289176367

Epoch: 5| Step: 7
Training loss: 0.15620091557502747
Validation loss: 1.7973290797202819

Epoch: 5| Step: 8
Training loss: 0.1182800680398941
Validation loss: 1.853077773124941

Epoch: 5| Step: 9
Training loss: 0.22209087014198303
Validation loss: 1.861093331408757

Epoch: 5| Step: 10
Training loss: 0.14554107189178467
Validation loss: 1.8709605342598372

Epoch: 413| Step: 0
Training loss: 0.21753473579883575
Validation loss: 1.924781193015396

Epoch: 5| Step: 1
Training loss: 0.24777397513389587
Validation loss: 1.9198622652279433

Epoch: 5| Step: 2
Training loss: 0.26931530237197876
Validation loss: 1.8793185859598138

Epoch: 5| Step: 3
Training loss: 0.18926894664764404
Validation loss: 1.8190208993932253

Epoch: 5| Step: 4
Training loss: 0.1394975185394287
Validation loss: 1.7819831960944719

Epoch: 5| Step: 5
Training loss: 0.19546309113502502
Validation loss: 1.7661914158892889

Epoch: 5| Step: 6
Training loss: 0.204708069562912
Validation loss: 1.7571911863101426

Epoch: 5| Step: 7
Training loss: 0.14859437942504883
Validation loss: 1.7464734251781175

Epoch: 5| Step: 8
Training loss: 0.11302874237298965
Validation loss: 1.7672281008894726

Epoch: 5| Step: 9
Training loss: 0.2280701845884323
Validation loss: 1.7403408993956864

Epoch: 5| Step: 10
Training loss: 0.12900377810001373
Validation loss: 1.7630595366160076

Epoch: 414| Step: 0
Training loss: 0.13841930031776428
Validation loss: 1.7989851428616432

Epoch: 5| Step: 1
Training loss: 0.23692281544208527
Validation loss: 1.7904720742215392

Epoch: 5| Step: 2
Training loss: 0.17133183777332306
Validation loss: 1.794168040316592

Epoch: 5| Step: 3
Training loss: 0.2155068814754486
Validation loss: 1.815212667629283

Epoch: 5| Step: 4
Training loss: 0.14536800980567932
Validation loss: 1.8374924390546736

Epoch: 5| Step: 5
Training loss: 0.14657846093177795
Validation loss: 1.8082405341568815

Epoch: 5| Step: 6
Training loss: 0.14173801243305206
Validation loss: 1.8140430347893828

Epoch: 5| Step: 7
Training loss: 0.1924699991941452
Validation loss: 1.8118906059572775

Epoch: 5| Step: 8
Training loss: 0.2350820004940033
Validation loss: 1.8059273214750393

Epoch: 5| Step: 9
Training loss: 0.1485508382320404
Validation loss: 1.796716159389865

Epoch: 5| Step: 10
Training loss: 0.22615574300289154
Validation loss: 1.7717424233754475

Epoch: 415| Step: 0
Training loss: 0.19213059544563293
Validation loss: 1.8139345043448991

Epoch: 5| Step: 1
Training loss: 0.22331492602825165
Validation loss: 1.827396074930827

Epoch: 5| Step: 2
Training loss: 0.21832530200481415
Validation loss: 1.8271514779777938

Epoch: 5| Step: 3
Training loss: 0.18957935273647308
Validation loss: 1.827103950644052

Epoch: 5| Step: 4
Training loss: 0.21565064787864685
Validation loss: 1.7802713712056477

Epoch: 5| Step: 5
Training loss: 0.25593429803848267
Validation loss: 1.7854352869013304

Epoch: 5| Step: 6
Training loss: 0.15793845057487488
Validation loss: 1.7733691212951497

Epoch: 5| Step: 7
Training loss: 0.22002382576465607
Validation loss: 1.7751377474877141

Epoch: 5| Step: 8
Training loss: 0.19748222827911377
Validation loss: 1.788234536365796

Epoch: 5| Step: 9
Training loss: 0.2501954436302185
Validation loss: 1.7603202160968576

Epoch: 5| Step: 10
Training loss: 0.14992423355579376
Validation loss: 1.7918775132907334

Epoch: 416| Step: 0
Training loss: 0.21959146857261658
Validation loss: 1.7638707173767911

Epoch: 5| Step: 1
Training loss: 0.11648956686258316
Validation loss: 1.7443777284314554

Epoch: 5| Step: 2
Training loss: 0.10258247703313828
Validation loss: 1.7750593475116196

Epoch: 5| Step: 3
Training loss: 0.19685375690460205
Validation loss: 1.7621201046051518

Epoch: 5| Step: 4
Training loss: 0.2524039149284363
Validation loss: 1.791212906119644

Epoch: 5| Step: 5
Training loss: 0.2654736638069153
Validation loss: 1.8512300188823412

Epoch: 5| Step: 6
Training loss: 0.17542146146297455
Validation loss: 1.846426244704954

Epoch: 5| Step: 7
Training loss: 0.18666592240333557
Validation loss: 1.848327608518703

Epoch: 5| Step: 8
Training loss: 0.28213271498680115
Validation loss: 1.8975768896841234

Epoch: 5| Step: 9
Training loss: 0.1716892421245575
Validation loss: 1.8897623195443103

Epoch: 5| Step: 10
Training loss: 0.19150197505950928
Validation loss: 1.8625768692262712

Epoch: 417| Step: 0
Training loss: 0.19832977652549744
Validation loss: 1.8323590024825065

Epoch: 5| Step: 1
Training loss: 0.13724851608276367
Validation loss: 1.7994753378693775

Epoch: 5| Step: 2
Training loss: 0.17439952492713928
Validation loss: 1.771270344334264

Epoch: 5| Step: 3
Training loss: 0.26413002610206604
Validation loss: 1.7683641769552743

Epoch: 5| Step: 4
Training loss: 0.25253230333328247
Validation loss: 1.7357537131155691

Epoch: 5| Step: 5
Training loss: 0.21747398376464844
Validation loss: 1.7225316352741693

Epoch: 5| Step: 6
Training loss: 0.29986271262168884
Validation loss: 1.7657551406532206

Epoch: 5| Step: 7
Training loss: 0.26951560378074646
Validation loss: 1.766224390716963

Epoch: 5| Step: 8
Training loss: 0.13112576305866241
Validation loss: 1.8017323350393644

Epoch: 5| Step: 9
Training loss: 0.17660993337631226
Validation loss: 1.828585474721847

Epoch: 5| Step: 10
Training loss: 0.22663477063179016
Validation loss: 1.8464054702430643

Epoch: 418| Step: 0
Training loss: 0.20167946815490723
Validation loss: 1.870289546187206

Epoch: 5| Step: 1
Training loss: 0.2662418484687805
Validation loss: 1.8846083430833713

Epoch: 5| Step: 2
Training loss: 0.3519889712333679
Validation loss: 1.8427828076065227

Epoch: 5| Step: 3
Training loss: 0.2413773089647293
Validation loss: 1.829418065727398

Epoch: 5| Step: 4
Training loss: 0.17727288603782654
Validation loss: 1.8225475024151545

Epoch: 5| Step: 5
Training loss: 0.19810737669467926
Validation loss: 1.7856830371323453

Epoch: 5| Step: 6
Training loss: 0.1546245813369751
Validation loss: 1.780393845291548

Epoch: 5| Step: 7
Training loss: 0.19971917569637299
Validation loss: 1.7576457633767077

Epoch: 5| Step: 8
Training loss: 0.2379724234342575
Validation loss: 1.7260312867420975

Epoch: 5| Step: 9
Training loss: 0.20685796439647675
Validation loss: 1.735040795418524

Epoch: 5| Step: 10
Training loss: 0.2031194120645523
Validation loss: 1.7541861354663808

Epoch: 419| Step: 0
Training loss: 0.2541506588459015
Validation loss: 1.7625078796058573

Epoch: 5| Step: 1
Training loss: 0.2413133829832077
Validation loss: 1.7691342343566239

Epoch: 5| Step: 2
Training loss: 0.16194435954093933
Validation loss: 1.815397956038034

Epoch: 5| Step: 3
Training loss: 0.1429806649684906
Validation loss: 1.825483939980948

Epoch: 5| Step: 4
Training loss: 0.2654770016670227
Validation loss: 1.833824683261174

Epoch: 5| Step: 5
Training loss: 0.1541782170534134
Validation loss: 1.8428338573824974

Epoch: 5| Step: 6
Training loss: 0.26618337631225586
Validation loss: 1.8386563998396679

Epoch: 5| Step: 7
Training loss: 0.149524986743927
Validation loss: 1.8382652062241749

Epoch: 5| Step: 8
Training loss: 0.1971937119960785
Validation loss: 1.7790065773071781

Epoch: 5| Step: 9
Training loss: 0.1728098839521408
Validation loss: 1.793583300805861

Epoch: 5| Step: 10
Training loss: 0.10183554887771606
Validation loss: 1.779721571553138

Epoch: 420| Step: 0
Training loss: 0.15969516336917877
Validation loss: 1.762800294865844

Epoch: 5| Step: 1
Training loss: 0.11498715728521347
Validation loss: 1.7275515499935354

Epoch: 5| Step: 2
Training loss: 0.2236015796661377
Validation loss: 1.7304521555541663

Epoch: 5| Step: 3
Training loss: 0.18911585211753845
Validation loss: 1.7342612910014328

Epoch: 5| Step: 4
Training loss: 0.2351786345243454
Validation loss: 1.7187938369730467

Epoch: 5| Step: 5
Training loss: 0.21789026260375977
Validation loss: 1.7163814344713766

Epoch: 5| Step: 6
Training loss: 0.15127773582935333
Validation loss: 1.753594950322182

Epoch: 5| Step: 7
Training loss: 0.2413872480392456
Validation loss: 1.7634375018458213

Epoch: 5| Step: 8
Training loss: 0.1474592536687851
Validation loss: 1.8003501058906637

Epoch: 5| Step: 9
Training loss: 0.13502201437950134
Validation loss: 1.8339767558600313

Epoch: 5| Step: 10
Training loss: 0.13905292749404907
Validation loss: 1.8917396504391906

Epoch: 421| Step: 0
Training loss: 0.2165941745042801
Validation loss: 1.8429043767272786

Epoch: 5| Step: 1
Training loss: 0.13253997266292572
Validation loss: 1.8394924581691783

Epoch: 5| Step: 2
Training loss: 0.20445451140403748
Validation loss: 1.805460104378321

Epoch: 5| Step: 3
Training loss: 0.23780886828899384
Validation loss: 1.7943998639301588

Epoch: 5| Step: 4
Training loss: 0.17007464170455933
Validation loss: 1.7615871019260858

Epoch: 5| Step: 5
Training loss: 0.1382950246334076
Validation loss: 1.7039802048795967

Epoch: 5| Step: 6
Training loss: 0.1826803833246231
Validation loss: 1.7177141584375852

Epoch: 5| Step: 7
Training loss: 0.15533867478370667
Validation loss: 1.7086152940668085

Epoch: 5| Step: 8
Training loss: 0.3574928641319275
Validation loss: 1.7041781064002746

Epoch: 5| Step: 9
Training loss: 0.18768885731697083
Validation loss: 1.697828741483791

Epoch: 5| Step: 10
Training loss: 0.1422206610441208
Validation loss: 1.7349341915499779

Epoch: 422| Step: 0
Training loss: 0.20210929214954376
Validation loss: 1.7417836086724394

Epoch: 5| Step: 1
Training loss: 0.14812727272510529
Validation loss: 1.774955516220421

Epoch: 5| Step: 2
Training loss: 0.15626811981201172
Validation loss: 1.767320797007571

Epoch: 5| Step: 3
Training loss: 0.15026411414146423
Validation loss: 1.7979170199363463

Epoch: 5| Step: 4
Training loss: 0.21100863814353943
Validation loss: 1.7941539954113703

Epoch: 5| Step: 5
Training loss: 0.20536652207374573
Validation loss: 1.8203808722957489

Epoch: 5| Step: 6
Training loss: 0.18050041794776917
Validation loss: 1.840092300086893

Epoch: 5| Step: 7
Training loss: 0.21936377882957458
Validation loss: 1.8425843843849756

Epoch: 5| Step: 8
Training loss: 0.17993055284023285
Validation loss: 1.8473266683599001

Epoch: 5| Step: 9
Training loss: 0.15807205438613892
Validation loss: 1.8478968220372354

Epoch: 5| Step: 10
Training loss: 0.19438016414642334
Validation loss: 1.7921329621345765

Epoch: 423| Step: 0
Training loss: 0.20748940110206604
Validation loss: 1.7707909076444563

Epoch: 5| Step: 1
Training loss: 0.15376225113868713
Validation loss: 1.7577062242774553

Epoch: 5| Step: 2
Training loss: 0.16471517086029053
Validation loss: 1.7426541338684738

Epoch: 5| Step: 3
Training loss: 0.10723556578159332
Validation loss: 1.8132163696391608

Epoch: 5| Step: 4
Training loss: 0.21336862444877625
Validation loss: 1.7762086032539286

Epoch: 5| Step: 5
Training loss: 0.17964327335357666
Validation loss: 1.7900703337884718

Epoch: 5| Step: 6
Training loss: 0.08969391882419586
Validation loss: 1.8058221147906395

Epoch: 5| Step: 7
Training loss: 0.28747040033340454
Validation loss: 1.8004135752236972

Epoch: 5| Step: 8
Training loss: 0.2535073161125183
Validation loss: 1.8436799754378617

Epoch: 5| Step: 9
Training loss: 0.20788760483264923
Validation loss: 1.8374204071619178

Epoch: 5| Step: 10
Training loss: 0.26683181524276733
Validation loss: 1.825047331471597

Epoch: 424| Step: 0
Training loss: 0.11725322902202606
Validation loss: 1.822461805035991

Epoch: 5| Step: 1
Training loss: 0.15218190848827362
Validation loss: 1.8129031247990106

Epoch: 5| Step: 2
Training loss: 0.3371641933917999
Validation loss: 1.8089337169483144

Epoch: 5| Step: 3
Training loss: 0.172923281788826
Validation loss: 1.7930949298284387

Epoch: 5| Step: 4
Training loss: 0.16530533134937286
Validation loss: 1.8112257014038742

Epoch: 5| Step: 5
Training loss: 0.11436178535223007
Validation loss: 1.7915656130800965

Epoch: 5| Step: 6
Training loss: 0.11822481453418732
Validation loss: 1.7984731222993584

Epoch: 5| Step: 7
Training loss: 0.10912410914897919
Validation loss: 1.8054464683737805

Epoch: 5| Step: 8
Training loss: 0.2524246871471405
Validation loss: 1.7901504296128468

Epoch: 5| Step: 9
Training loss: 0.2597714066505432
Validation loss: 1.8026175550235215

Epoch: 5| Step: 10
Training loss: 0.18610258400440216
Validation loss: 1.8001648738820066

Epoch: 425| Step: 0
Training loss: 0.18772061169147491
Validation loss: 1.7992828302485968

Epoch: 5| Step: 1
Training loss: 0.15323524177074432
Validation loss: 1.8060565994631859

Epoch: 5| Step: 2
Training loss: 0.16204436123371124
Validation loss: 1.8022966295160272

Epoch: 5| Step: 3
Training loss: 0.15455622971057892
Validation loss: 1.79923842799279

Epoch: 5| Step: 4
Training loss: 0.23997700214385986
Validation loss: 1.7887800842203119

Epoch: 5| Step: 5
Training loss: 0.18385694921016693
Validation loss: 1.7870163097176501

Epoch: 5| Step: 6
Training loss: 0.2070918083190918
Validation loss: 1.7884086126922278

Epoch: 5| Step: 7
Training loss: 0.12350018322467804
Validation loss: 1.807618228338098

Epoch: 5| Step: 8
Training loss: 0.23107628524303436
Validation loss: 1.791777608215168

Epoch: 5| Step: 9
Training loss: 0.22760280966758728
Validation loss: 1.7904445227756296

Epoch: 5| Step: 10
Training loss: 0.14102452993392944
Validation loss: 1.7759663392138738

Epoch: 426| Step: 0
Training loss: 0.14797478914260864
Validation loss: 1.8020218110853625

Epoch: 5| Step: 1
Training loss: 0.16382722556591034
Validation loss: 1.8033657214974845

Epoch: 5| Step: 2
Training loss: 0.18771934509277344
Validation loss: 1.806057991520051

Epoch: 5| Step: 3
Training loss: 0.20493507385253906
Validation loss: 1.798324614442805

Epoch: 5| Step: 4
Training loss: 0.13131892681121826
Validation loss: 1.8075574444186302

Epoch: 5| Step: 5
Training loss: 0.11036817729473114
Validation loss: 1.8224108296055948

Epoch: 5| Step: 6
Training loss: 0.13189636170864105
Validation loss: 1.8107535223807059

Epoch: 5| Step: 7
Training loss: 0.31876638531684875
Validation loss: 1.8188912009680143

Epoch: 5| Step: 8
Training loss: 0.2688775658607483
Validation loss: 1.8081565108350528

Epoch: 5| Step: 9
Training loss: 0.16727711260318756
Validation loss: 1.8008930708772393

Epoch: 5| Step: 10
Training loss: 0.1710716336965561
Validation loss: 1.7989836277500275

Epoch: 427| Step: 0
Training loss: 0.07807980477809906
Validation loss: 1.7883360642258839

Epoch: 5| Step: 1
Training loss: 0.11983764171600342
Validation loss: 1.7939165074338195

Epoch: 5| Step: 2
Training loss: 0.18440289795398712
Validation loss: 1.828881057359839

Epoch: 5| Step: 3
Training loss: 0.07484734803438187
Validation loss: 1.8435326007104689

Epoch: 5| Step: 4
Training loss: 0.1159941777586937
Validation loss: 1.8706339213155931

Epoch: 5| Step: 5
Training loss: 0.19111725687980652
Validation loss: 1.8721427122751872

Epoch: 5| Step: 6
Training loss: 0.12977531552314758
Validation loss: 1.8582169394339285

Epoch: 5| Step: 7
Training loss: 0.13004277646541595
Validation loss: 1.8278604656137445

Epoch: 5| Step: 8
Training loss: 0.10565819591283798
Validation loss: 1.808912363103641

Epoch: 5| Step: 9
Training loss: 0.2726595401763916
Validation loss: 1.7577072702428347

Epoch: 5| Step: 10
Training loss: 0.30547383427619934
Validation loss: 1.7313935346500848

Epoch: 428| Step: 0
Training loss: 0.13624413311481476
Validation loss: 1.7407913515644688

Epoch: 5| Step: 1
Training loss: 0.10391547530889511
Validation loss: 1.7320857150580293

Epoch: 5| Step: 2
Training loss: 0.1836564540863037
Validation loss: 1.7466620360651324

Epoch: 5| Step: 3
Training loss: 0.2641450762748718
Validation loss: 1.77106172807755

Epoch: 5| Step: 4
Training loss: 0.18798694014549255
Validation loss: 1.7908814543037004

Epoch: 5| Step: 5
Training loss: 0.1667235642671585
Validation loss: 1.8460245388810352

Epoch: 5| Step: 6
Training loss: 0.1330377608537674
Validation loss: 1.8320500299494753

Epoch: 5| Step: 7
Training loss: 0.11297404766082764
Validation loss: 1.8358859631323046

Epoch: 5| Step: 8
Training loss: 0.15492171049118042
Validation loss: 1.8165383672201505

Epoch: 5| Step: 9
Training loss: 0.12740382552146912
Validation loss: 1.8353277996022215

Epoch: 5| Step: 10
Training loss: 0.18115241825580597
Validation loss: 1.841265555351011

Epoch: 429| Step: 0
Training loss: 0.0758143812417984
Validation loss: 1.8783529163688741

Epoch: 5| Step: 1
Training loss: 0.14014406502246857
Validation loss: 1.855760298749452

Epoch: 5| Step: 2
Training loss: 0.10609638690948486
Validation loss: 1.8018908013579666

Epoch: 5| Step: 3
Training loss: 0.1830485612154007
Validation loss: 1.7872661544430641

Epoch: 5| Step: 4
Training loss: 0.18434837460517883
Validation loss: 1.8032435396666169

Epoch: 5| Step: 5
Training loss: 0.29420310258865356
Validation loss: 1.732817380659042

Epoch: 5| Step: 6
Training loss: 0.17713765799999237
Validation loss: 1.742947168247674

Epoch: 5| Step: 7
Training loss: 0.19193515181541443
Validation loss: 1.7346166308208177

Epoch: 5| Step: 8
Training loss: 0.22039660811424255
Validation loss: 1.799637666312597

Epoch: 5| Step: 9
Training loss: 0.1690129041671753
Validation loss: 1.8348665186153945

Epoch: 5| Step: 10
Training loss: 0.12314734607934952
Validation loss: 1.8486787452492663

Epoch: 430| Step: 0
Training loss: 0.20063433051109314
Validation loss: 1.8892032689945673

Epoch: 5| Step: 1
Training loss: 0.20370054244995117
Validation loss: 1.8908131443044192

Epoch: 5| Step: 2
Training loss: 0.24666455388069153
Validation loss: 1.90238715628142

Epoch: 5| Step: 3
Training loss: 0.2767968475818634
Validation loss: 1.9042393904860302

Epoch: 5| Step: 4
Training loss: 0.15384383499622345
Validation loss: 1.8579047341500559

Epoch: 5| Step: 5
Training loss: 0.08777153491973877
Validation loss: 1.8377571208502657

Epoch: 5| Step: 6
Training loss: 0.10142570734024048
Validation loss: 1.7889781254594044

Epoch: 5| Step: 7
Training loss: 0.22987857460975647
Validation loss: 1.7891185104206044

Epoch: 5| Step: 8
Training loss: 0.33608099818229675
Validation loss: 1.7794700822522562

Epoch: 5| Step: 9
Training loss: 0.18972072005271912
Validation loss: 1.787009403269778

Epoch: 5| Step: 10
Training loss: 0.17593568563461304
Validation loss: 1.7690726621176607

Epoch: 431| Step: 0
Training loss: 0.11377009004354477
Validation loss: 1.8022182474854171

Epoch: 5| Step: 1
Training loss: 0.11420819908380508
Validation loss: 1.7997517060208064

Epoch: 5| Step: 2
Training loss: 0.17535929381847382
Validation loss: 1.8491622196730746

Epoch: 5| Step: 3
Training loss: 0.22566673159599304
Validation loss: 1.894116001744424

Epoch: 5| Step: 4
Training loss: 0.25493910908699036
Validation loss: 1.8962064699460102

Epoch: 5| Step: 5
Training loss: 0.32299768924713135
Validation loss: 1.891796624788674

Epoch: 5| Step: 6
Training loss: 0.1945996731519699
Validation loss: 1.8839948613156554

Epoch: 5| Step: 7
Training loss: 0.14190424978733063
Validation loss: 1.8750366805702128

Epoch: 5| Step: 8
Training loss: 0.2442503720521927
Validation loss: 1.804860835434288

Epoch: 5| Step: 9
Training loss: 0.16041859984397888
Validation loss: 1.7741925716400146

Epoch: 5| Step: 10
Training loss: 0.21012389659881592
Validation loss: 1.7207555155600271

Epoch: 432| Step: 0
Training loss: 0.12289576232433319
Validation loss: 1.6905712363540486

Epoch: 5| Step: 1
Training loss: 0.171078160405159
Validation loss: 1.7059869509871288

Epoch: 5| Step: 2
Training loss: 0.1883619725704193
Validation loss: 1.683862465684132

Epoch: 5| Step: 3
Training loss: 0.17556986212730408
Validation loss: 1.7050110934883036

Epoch: 5| Step: 4
Training loss: 0.1553223729133606
Validation loss: 1.739982679326047

Epoch: 5| Step: 5
Training loss: 0.1959521323442459
Validation loss: 1.76857780256579

Epoch: 5| Step: 6
Training loss: 0.1741495281457901
Validation loss: 1.760743510338568

Epoch: 5| Step: 7
Training loss: 0.14254972338676453
Validation loss: 1.7908073971348424

Epoch: 5| Step: 8
Training loss: 0.22692780196666718
Validation loss: 1.821258214212233

Epoch: 5| Step: 9
Training loss: 0.17021484673023224
Validation loss: 1.838576639852216

Epoch: 5| Step: 10
Training loss: 0.20558074116706848
Validation loss: 1.845628564075757

Epoch: 433| Step: 0
Training loss: 0.1466769278049469
Validation loss: 1.8462191922690279

Epoch: 5| Step: 1
Training loss: 0.15259568393230438
Validation loss: 1.8207116998651975

Epoch: 5| Step: 2
Training loss: 0.17635762691497803
Validation loss: 1.802659378256849

Epoch: 5| Step: 3
Training loss: 0.13909156620502472
Validation loss: 1.8129405898432578

Epoch: 5| Step: 4
Training loss: 0.08279716968536377
Validation loss: 1.7967605834366174

Epoch: 5| Step: 5
Training loss: 0.2204771786928177
Validation loss: 1.7806554276456115

Epoch: 5| Step: 6
Training loss: 0.11645686626434326
Validation loss: 1.7579890489578247

Epoch: 5| Step: 7
Training loss: 0.16402825713157654
Validation loss: 1.7705572394914524

Epoch: 5| Step: 8
Training loss: 0.33287298679351807
Validation loss: 1.7316304176084456

Epoch: 5| Step: 9
Training loss: 0.142582967877388
Validation loss: 1.7393910320856238

Epoch: 5| Step: 10
Training loss: 0.1863553524017334
Validation loss: 1.7549933720660467

Epoch: 434| Step: 0
Training loss: 0.19310840964317322
Validation loss: 1.7842968766407301

Epoch: 5| Step: 1
Training loss: 0.11779718101024628
Validation loss: 1.7806216593711608

Epoch: 5| Step: 2
Training loss: 0.23476096987724304
Validation loss: 1.795977105376541

Epoch: 5| Step: 3
Training loss: 0.2744445204734802
Validation loss: 1.8156454217049383

Epoch: 5| Step: 4
Training loss: 0.17938604950904846
Validation loss: 1.8079270560254332

Epoch: 5| Step: 5
Training loss: 0.1495874673128128
Validation loss: 1.7900390778818438

Epoch: 5| Step: 6
Training loss: 0.14323996007442474
Validation loss: 1.7893375965856737

Epoch: 5| Step: 7
Training loss: 0.16486772894859314
Validation loss: 1.7497200478789627

Epoch: 5| Step: 8
Training loss: 0.13006646931171417
Validation loss: 1.7118576572787376

Epoch: 5| Step: 9
Training loss: 0.14883874356746674
Validation loss: 1.7285629344242874

Epoch: 5| Step: 10
Training loss: 0.22369077801704407
Validation loss: 1.7458678573690436

Epoch: 435| Step: 0
Training loss: 0.16283027827739716
Validation loss: 1.7081151700788928

Epoch: 5| Step: 1
Training loss: 0.14909479022026062
Validation loss: 1.7384302308482509

Epoch: 5| Step: 2
Training loss: 0.1707468181848526
Validation loss: 1.6737852814376994

Epoch: 5| Step: 3
Training loss: 0.07247839868068695
Validation loss: 1.7212662261019471

Epoch: 5| Step: 4
Training loss: 0.2802203893661499
Validation loss: 1.6996559814740253

Epoch: 5| Step: 5
Training loss: 0.1710672527551651
Validation loss: 1.7076651191198697

Epoch: 5| Step: 6
Training loss: 0.1671002358198166
Validation loss: 1.73940485395411

Epoch: 5| Step: 7
Training loss: 0.1114121824502945
Validation loss: 1.7680909505454443

Epoch: 5| Step: 8
Training loss: 0.10072167217731476
Validation loss: 1.7978218101686048

Epoch: 5| Step: 9
Training loss: 0.2225455790758133
Validation loss: 1.7914240667896886

Epoch: 5| Step: 10
Training loss: 0.20263443887233734
Validation loss: 1.8405953171432659

Epoch: 436| Step: 0
Training loss: 0.18080802261829376
Validation loss: 1.7910934686660767

Epoch: 5| Step: 1
Training loss: 0.11281907558441162
Validation loss: 1.7827344274008146

Epoch: 5| Step: 2
Training loss: 0.19452685117721558
Validation loss: 1.7553181699527207

Epoch: 5| Step: 3
Training loss: 0.16526028513908386
Validation loss: 1.7600839778941164

Epoch: 5| Step: 4
Training loss: 0.1263262927532196
Validation loss: 1.7147648411412393

Epoch: 5| Step: 5
Training loss: 0.1309487372636795
Validation loss: 1.7082310312537736

Epoch: 5| Step: 6
Training loss: 0.1523575484752655
Validation loss: 1.7123912495951499

Epoch: 5| Step: 7
Training loss: 0.132206529378891
Validation loss: 1.7583600628760554

Epoch: 5| Step: 8
Training loss: 0.24055635929107666
Validation loss: 1.7436852647412209

Epoch: 5| Step: 9
Training loss: 0.11505647003650665
Validation loss: 1.7712899972033758

Epoch: 5| Step: 10
Training loss: 0.10646595805883408
Validation loss: 1.7539083855126494

Epoch: 437| Step: 0
Training loss: 0.09621472656726837
Validation loss: 1.7742607715309306

Epoch: 5| Step: 1
Training loss: 0.14168743789196014
Validation loss: 1.782623129506265

Epoch: 5| Step: 2
Training loss: 0.20255105197429657
Validation loss: 1.7629168469418761

Epoch: 5| Step: 3
Training loss: 0.15051047503948212
Validation loss: 1.7472425045505646

Epoch: 5| Step: 4
Training loss: 0.1349487453699112
Validation loss: 1.7568187098349295

Epoch: 5| Step: 5
Training loss: 0.15317489206790924
Validation loss: 1.7448397259558401

Epoch: 5| Step: 6
Training loss: 0.10651024430990219
Validation loss: 1.7667235546214606

Epoch: 5| Step: 7
Training loss: 0.0870242491364479
Validation loss: 1.746893334132369

Epoch: 5| Step: 8
Training loss: 0.12541541457176208
Validation loss: 1.7477810395661222

Epoch: 5| Step: 9
Training loss: 0.22404973208904266
Validation loss: 1.7208956133934759

Epoch: 5| Step: 10
Training loss: 0.086947500705719
Validation loss: 1.728067148116327

Epoch: 438| Step: 0
Training loss: 0.11703427881002426
Validation loss: 1.751577861847416

Epoch: 5| Step: 1
Training loss: 0.12059102207422256
Validation loss: 1.7557628552118938

Epoch: 5| Step: 2
Training loss: 0.1721268594264984
Validation loss: 1.7364831880856586

Epoch: 5| Step: 3
Training loss: 0.1300467997789383
Validation loss: 1.7642897329022806

Epoch: 5| Step: 4
Training loss: 0.15738508105278015
Validation loss: 1.7495441513676797

Epoch: 5| Step: 5
Training loss: 0.12481536716222763
Validation loss: 1.785801472202424

Epoch: 5| Step: 6
Training loss: 0.2229601889848709
Validation loss: 1.789362661300167

Epoch: 5| Step: 7
Training loss: 0.10840821266174316
Validation loss: 1.789200271329572

Epoch: 5| Step: 8
Training loss: 0.14039865136146545
Validation loss: 1.7563637764223161

Epoch: 5| Step: 9
Training loss: 0.1115131825208664
Validation loss: 1.7700873703084967

Epoch: 5| Step: 10
Training loss: 0.1958170086145401
Validation loss: 1.7606432143078055

Epoch: 439| Step: 0
Training loss: 0.12625254690647125
Validation loss: 1.7590315059948993

Epoch: 5| Step: 1
Training loss: 0.1646399050951004
Validation loss: 1.7550631415459417

Epoch: 5| Step: 2
Training loss: 0.14896340668201447
Validation loss: 1.776730275923206

Epoch: 5| Step: 3
Training loss: 0.28080612421035767
Validation loss: 1.7319087905268515

Epoch: 5| Step: 4
Training loss: 0.19530823826789856
Validation loss: 1.75962164966009

Epoch: 5| Step: 5
Training loss: 0.16577067971229553
Validation loss: 1.8006019028284217

Epoch: 5| Step: 6
Training loss: 0.14423422515392303
Validation loss: 1.7452198254164828

Epoch: 5| Step: 7
Training loss: 0.11155589669942856
Validation loss: 1.7404678278071906

Epoch: 5| Step: 8
Training loss: 0.13659696280956268
Validation loss: 1.7389659279136247

Epoch: 5| Step: 9
Training loss: 0.14317114651203156
Validation loss: 1.7322313003642584

Epoch: 5| Step: 10
Training loss: 0.10621953755617142
Validation loss: 1.7534920041279127

Epoch: 440| Step: 0
Training loss: 0.12067188322544098
Validation loss: 1.7512668973656111

Epoch: 5| Step: 1
Training loss: 0.1418319195508957
Validation loss: 1.7204824288686116

Epoch: 5| Step: 2
Training loss: 0.16659007966518402
Validation loss: 1.7089342994074668

Epoch: 5| Step: 3
Training loss: 0.1424117386341095
Validation loss: 1.7297992475571171

Epoch: 5| Step: 4
Training loss: 0.09531676769256592
Validation loss: 1.735358831703022

Epoch: 5| Step: 5
Training loss: 0.13934960961341858
Validation loss: 1.7404329969036965

Epoch: 5| Step: 6
Training loss: 0.1395404189825058
Validation loss: 1.7544294864900651

Epoch: 5| Step: 7
Training loss: 0.11607728153467178
Validation loss: 1.7609167304090274

Epoch: 5| Step: 8
Training loss: 0.15550872683525085
Validation loss: 1.7818193922760666

Epoch: 5| Step: 9
Training loss: 0.1386304348707199
Validation loss: 1.7773439294548445

Epoch: 5| Step: 10
Training loss: 0.359770268201828
Validation loss: 1.7622107690380466

Epoch: 441| Step: 0
Training loss: 0.12956245243549347
Validation loss: 1.7574443676138436

Epoch: 5| Step: 1
Training loss: 0.09207469969987869
Validation loss: 1.7645150493550044

Epoch: 5| Step: 2
Training loss: 0.16090282797813416
Validation loss: 1.7353715204423474

Epoch: 5| Step: 3
Training loss: 0.1759396195411682
Validation loss: 1.7295604252046155

Epoch: 5| Step: 4
Training loss: 0.17980483174324036
Validation loss: 1.7226826362712409

Epoch: 5| Step: 5
Training loss: 0.15937449038028717
Validation loss: 1.7243342502142793

Epoch: 5| Step: 6
Training loss: 0.10821745544672012
Validation loss: 1.7229403731643513

Epoch: 5| Step: 7
Training loss: 0.13100497424602509
Validation loss: 1.7066545691541446

Epoch: 5| Step: 8
Training loss: 0.14675194025039673
Validation loss: 1.6997539586918329

Epoch: 5| Step: 9
Training loss: 0.1204301118850708
Validation loss: 1.6786305019932408

Epoch: 5| Step: 10
Training loss: 0.14283576607704163
Validation loss: 1.6923804821506623

Epoch: 442| Step: 0
Training loss: 0.12516184151172638
Validation loss: 1.6626337266737414

Epoch: 5| Step: 1
Training loss: 0.10803256928920746
Validation loss: 1.6830933363206926

Epoch: 5| Step: 2
Training loss: 0.24288959801197052
Validation loss: 1.701730211575826

Epoch: 5| Step: 3
Training loss: 0.17782747745513916
Validation loss: 1.7365730231808079

Epoch: 5| Step: 4
Training loss: 0.189021036028862
Validation loss: 1.7409109992365683

Epoch: 5| Step: 5
Training loss: 0.11213097721338272
Validation loss: 1.7064044770374094

Epoch: 5| Step: 6
Training loss: 0.13486655056476593
Validation loss: 1.7193858085140106

Epoch: 5| Step: 7
Training loss: 0.07381528615951538
Validation loss: 1.7174502726524108

Epoch: 5| Step: 8
Training loss: 0.10683629661798477
Validation loss: 1.7276371409816127

Epoch: 5| Step: 9
Training loss: 0.1463489681482315
Validation loss: 1.7408275347883984

Epoch: 5| Step: 10
Training loss: 0.1351713091135025
Validation loss: 1.7287586799231909

Epoch: 443| Step: 0
Training loss: 0.2353154718875885
Validation loss: 1.7461031162610618

Epoch: 5| Step: 1
Training loss: 0.13826599717140198
Validation loss: 1.764385824562401

Epoch: 5| Step: 2
Training loss: 0.14791545271873474
Validation loss: 1.7597257962790869

Epoch: 5| Step: 3
Training loss: 0.17724552750587463
Validation loss: 1.768912169241136

Epoch: 5| Step: 4
Training loss: 0.13583417236804962
Validation loss: 1.7555525200341338

Epoch: 5| Step: 5
Training loss: 0.12335171550512314
Validation loss: 1.7219262315380959

Epoch: 5| Step: 6
Training loss: 0.1669904887676239
Validation loss: 1.7366868834341727

Epoch: 5| Step: 7
Training loss: 0.2592673599720001
Validation loss: 1.7241384367788992

Epoch: 5| Step: 8
Training loss: 0.11622369289398193
Validation loss: 1.6928678366445726

Epoch: 5| Step: 9
Training loss: 0.1516166478395462
Validation loss: 1.7135794983115247

Epoch: 5| Step: 10
Training loss: 0.1743750125169754
Validation loss: 1.6728699361124346

Epoch: 444| Step: 0
Training loss: 0.22410699725151062
Validation loss: 1.7223425526772775

Epoch: 5| Step: 1
Training loss: 0.12496598064899445
Validation loss: 1.7212423380985056

Epoch: 5| Step: 2
Training loss: 0.09267959743738174
Validation loss: 1.7402819946248045

Epoch: 5| Step: 3
Training loss: 0.2590157389640808
Validation loss: 1.7355033505347468

Epoch: 5| Step: 4
Training loss: 0.17944101989269257
Validation loss: 1.764630872716186

Epoch: 5| Step: 5
Training loss: 0.10808961093425751
Validation loss: 1.7274285477976645

Epoch: 5| Step: 6
Training loss: 0.17529472708702087
Validation loss: 1.7586291682335637

Epoch: 5| Step: 7
Training loss: 0.13715414702892303
Validation loss: 1.7683133591887772

Epoch: 5| Step: 8
Training loss: 0.1559644192457199
Validation loss: 1.7356623103541713

Epoch: 5| Step: 9
Training loss: 0.1051214188337326
Validation loss: 1.7183320881218038

Epoch: 5| Step: 10
Training loss: 0.11090017110109329
Validation loss: 1.7137357560537194

Epoch: 445| Step: 0
Training loss: 0.15842901170253754
Validation loss: 1.7100471578618532

Epoch: 5| Step: 1
Training loss: 0.1316702663898468
Validation loss: 1.7164573079796248

Epoch: 5| Step: 2
Training loss: 0.1554957628250122
Validation loss: 1.7054896713584982

Epoch: 5| Step: 3
Training loss: 0.234787255525589
Validation loss: 1.6938927840161067

Epoch: 5| Step: 4
Training loss: 0.16889387369155884
Validation loss: 1.7333422655700355

Epoch: 5| Step: 5
Training loss: 0.29955294728279114
Validation loss: 1.7428480886643933

Epoch: 5| Step: 6
Training loss: 0.13220849633216858
Validation loss: 1.7593581612392137

Epoch: 5| Step: 7
Training loss: 0.10555882751941681
Validation loss: 1.7723975796853342

Epoch: 5| Step: 8
Training loss: 0.20279856026172638
Validation loss: 1.7742588609777472

Epoch: 5| Step: 9
Training loss: 0.16280576586723328
Validation loss: 1.7634666760762532

Epoch: 5| Step: 10
Training loss: 0.18897584080696106
Validation loss: 1.7169462019397366

Epoch: 446| Step: 0
Training loss: 0.3321835994720459
Validation loss: 1.7150406850281583

Epoch: 5| Step: 1
Training loss: 0.15241879224777222
Validation loss: 1.6960781851122457

Epoch: 5| Step: 2
Training loss: 0.14856581389904022
Validation loss: 1.6906450307497414

Epoch: 5| Step: 3
Training loss: 0.18326671421527863
Validation loss: 1.6759646374692199

Epoch: 5| Step: 4
Training loss: 0.1286386102437973
Validation loss: 1.6978811781893495

Epoch: 5| Step: 5
Training loss: 0.1403501331806183
Validation loss: 1.7227214555586539

Epoch: 5| Step: 6
Training loss: 0.15650078654289246
Validation loss: 1.735236680635842

Epoch: 5| Step: 7
Training loss: 0.1770928055047989
Validation loss: 1.7650822080591673

Epoch: 5| Step: 8
Training loss: 0.17531974613666534
Validation loss: 1.739815224883377

Epoch: 5| Step: 9
Training loss: 0.21476157009601593
Validation loss: 1.7469801236224431

Epoch: 5| Step: 10
Training loss: 0.11958427727222443
Validation loss: 1.6972328783363424

Epoch: 447| Step: 0
Training loss: 0.09539794921875
Validation loss: 1.765908689909084

Epoch: 5| Step: 1
Training loss: 0.26370736956596375
Validation loss: 1.7648606518263459

Epoch: 5| Step: 2
Training loss: 0.11569733917713165
Validation loss: 1.780675693224835

Epoch: 5| Step: 3
Training loss: 0.15154454112052917
Validation loss: 1.7810571450059132

Epoch: 5| Step: 4
Training loss: 0.24359536170959473
Validation loss: 1.7754732690831667

Epoch: 5| Step: 5
Training loss: 0.10131950676441193
Validation loss: 1.7392775704783778

Epoch: 5| Step: 6
Training loss: 0.22976446151733398
Validation loss: 1.7740962107976277

Epoch: 5| Step: 7
Training loss: 0.09954993426799774
Validation loss: 1.7639777250187372

Epoch: 5| Step: 8
Training loss: 0.10585417598485947
Validation loss: 1.7842251370030064

Epoch: 5| Step: 9
Training loss: 0.08713207393884659
Validation loss: 1.747349682674613

Epoch: 5| Step: 10
Training loss: 0.14342132210731506
Validation loss: 1.7871343961326025

Epoch: 448| Step: 0
Training loss: 0.1469384729862213
Validation loss: 1.7654476088862265

Epoch: 5| Step: 1
Training loss: 0.2473757565021515
Validation loss: 1.8031601495640253

Epoch: 5| Step: 2
Training loss: 0.16807512938976288
Validation loss: 1.7565708980765393

Epoch: 5| Step: 3
Training loss: 0.11417832225561142
Validation loss: 1.754267918166294

Epoch: 5| Step: 4
Training loss: 0.12962843477725983
Validation loss: 1.767908234750071

Epoch: 5| Step: 5
Training loss: 0.1575952023267746
Validation loss: 1.7635192768548125

Epoch: 5| Step: 6
Training loss: 0.12469925731420517
Validation loss: 1.740959398208126

Epoch: 5| Step: 7
Training loss: 0.11129267513751984
Validation loss: 1.7751404598195066

Epoch: 5| Step: 8
Training loss: 0.10891512781381607
Validation loss: 1.7526819423962665

Epoch: 5| Step: 9
Training loss: 0.18967047333717346
Validation loss: 1.774141183463476

Epoch: 5| Step: 10
Training loss: 0.12719830870628357
Validation loss: 1.7926704217028875

Epoch: 449| Step: 0
Training loss: 0.11791901290416718
Validation loss: 1.7648279538718603

Epoch: 5| Step: 1
Training loss: 0.1119694709777832
Validation loss: 1.7902160293312483

Epoch: 5| Step: 2
Training loss: 0.17764000594615936
Validation loss: 1.7998530364805652

Epoch: 5| Step: 3
Training loss: 0.15736761689186096
Validation loss: 1.7992001528381019

Epoch: 5| Step: 4
Training loss: 0.14109636843204498
Validation loss: 1.7746460066046765

Epoch: 5| Step: 5
Training loss: 0.13626708090305328
Validation loss: 1.8244279020576066

Epoch: 5| Step: 6
Training loss: 0.1896965652704239
Validation loss: 1.8152772342005083

Epoch: 5| Step: 7
Training loss: 0.13000738620758057
Validation loss: 1.7876839637756348

Epoch: 5| Step: 8
Training loss: 0.1477101892232895
Validation loss: 1.778325524381412

Epoch: 5| Step: 9
Training loss: 0.14496764540672302
Validation loss: 1.7416408600345734

Epoch: 5| Step: 10
Training loss: 0.14286819100379944
Validation loss: 1.7780422882367206

Epoch: 450| Step: 0
Training loss: 0.1199120506644249
Validation loss: 1.7768669487327657

Epoch: 5| Step: 1
Training loss: 0.24394099414348602
Validation loss: 1.7686206012643793

Epoch: 5| Step: 2
Training loss: 0.12647779285907745
Validation loss: 1.736062736921413

Epoch: 5| Step: 3
Training loss: 0.20865795016288757
Validation loss: 1.7438397176804081

Epoch: 5| Step: 4
Training loss: 0.171260803937912
Validation loss: 1.743769843091247

Epoch: 5| Step: 5
Training loss: 0.10189513862133026
Validation loss: 1.75313861139359

Epoch: 5| Step: 6
Training loss: 0.11894333362579346
Validation loss: 1.7007253234104445

Epoch: 5| Step: 7
Training loss: 0.1712426245212555
Validation loss: 1.7181919877247145

Epoch: 5| Step: 8
Training loss: 0.13960370421409607
Validation loss: 1.7355438265749203

Epoch: 5| Step: 9
Training loss: 0.12541744112968445
Validation loss: 1.7576757348993772

Epoch: 5| Step: 10
Training loss: 0.09133661538362503
Validation loss: 1.7823890550162202

Epoch: 451| Step: 0
Training loss: 0.14867278933525085
Validation loss: 1.789994978135632

Epoch: 5| Step: 1
Training loss: 0.1139460951089859
Validation loss: 1.7540261565998037

Epoch: 5| Step: 2
Training loss: 0.11622284352779388
Validation loss: 1.7666431973057408

Epoch: 5| Step: 3
Training loss: 0.08881939947605133
Validation loss: 1.7345337572918142

Epoch: 5| Step: 4
Training loss: 0.17724473774433136
Validation loss: 1.7320004522159536

Epoch: 5| Step: 5
Training loss: 0.0837414562702179
Validation loss: 1.7259493745783323

Epoch: 5| Step: 6
Training loss: 0.14221982657909393
Validation loss: 1.7018271447509847

Epoch: 5| Step: 7
Training loss: 0.12023264169692993
Validation loss: 1.732920003193681

Epoch: 5| Step: 8
Training loss: 0.11992832273244858
Validation loss: 1.7080832835166686

Epoch: 5| Step: 9
Training loss: 0.12730015814304352
Validation loss: 1.7622599089017479

Epoch: 5| Step: 10
Training loss: 0.16387955844402313
Validation loss: 1.7472528526859898

Epoch: 452| Step: 0
Training loss: 0.11398608982563019
Validation loss: 1.747936923016784

Epoch: 5| Step: 1
Training loss: 0.13739672303199768
Validation loss: 1.7322736940076273

Epoch: 5| Step: 2
Training loss: 0.17305150628089905
Validation loss: 1.7382412546424455

Epoch: 5| Step: 3
Training loss: 0.1026594415307045
Validation loss: 1.7425827262222127

Epoch: 5| Step: 4
Training loss: 0.10388574749231339
Validation loss: 1.751641555499005

Epoch: 5| Step: 5
Training loss: 0.1324213296175003
Validation loss: 1.7645616275008007

Epoch: 5| Step: 6
Training loss: 0.19260898232460022
Validation loss: 1.7426904055380052

Epoch: 5| Step: 7
Training loss: 0.1139296293258667
Validation loss: 1.7122597489305722

Epoch: 5| Step: 8
Training loss: 0.22838909924030304
Validation loss: 1.7057653652724398

Epoch: 5| Step: 9
Training loss: 0.09710879623889923
Validation loss: 1.7039779117030482

Epoch: 5| Step: 10
Training loss: 0.23414090275764465
Validation loss: 1.730657151950303

Epoch: 453| Step: 0
Training loss: 0.1002836674451828
Validation loss: 1.6800911644453644

Epoch: 5| Step: 1
Training loss: 0.09192010015249252
Validation loss: 1.7106909341709589

Epoch: 5| Step: 2
Training loss: 0.1422051191329956
Validation loss: 1.6933411064968313

Epoch: 5| Step: 3
Training loss: 0.09495599567890167
Validation loss: 1.6775453449577413

Epoch: 5| Step: 4
Training loss: 0.13203179836273193
Validation loss: 1.702426355372193

Epoch: 5| Step: 5
Training loss: 0.111439548432827
Validation loss: 1.6924023884598927

Epoch: 5| Step: 6
Training loss: 0.13237500190734863
Validation loss: 1.7047193832294916

Epoch: 5| Step: 7
Training loss: 0.20432844758033752
Validation loss: 1.702621183087749

Epoch: 5| Step: 8
Training loss: 0.15607978403568268
Validation loss: 1.7262833259438957

Epoch: 5| Step: 9
Training loss: 0.15625301003456116
Validation loss: 1.7541019788352392

Epoch: 5| Step: 10
Training loss: 0.09733426570892334
Validation loss: 1.7545669796646282

Epoch: 454| Step: 0
Training loss: 0.14112281799316406
Validation loss: 1.763193945730886

Epoch: 5| Step: 1
Training loss: 0.11598465591669083
Validation loss: 1.743582006423704

Epoch: 5| Step: 2
Training loss: 0.16079019010066986
Validation loss: 1.7110447319605018

Epoch: 5| Step: 3
Training loss: 0.15449750423431396
Validation loss: 1.6915099954092374

Epoch: 5| Step: 4
Training loss: 0.1834588348865509
Validation loss: 1.7043272884943153

Epoch: 5| Step: 5
Training loss: 0.12698622047901154
Validation loss: 1.7022680236447243

Epoch: 5| Step: 6
Training loss: 0.14816860854625702
Validation loss: 1.6899142060228574

Epoch: 5| Step: 7
Training loss: 0.1000823974609375
Validation loss: 1.7170406977335613

Epoch: 5| Step: 8
Training loss: 0.09004147350788116
Validation loss: 1.7210049078028689

Epoch: 5| Step: 9
Training loss: 0.253140389919281
Validation loss: 1.7141942811268631

Epoch: 5| Step: 10
Training loss: 0.06679820269346237
Validation loss: 1.7075312009421728

Epoch: 455| Step: 0
Training loss: 0.0768357515335083
Validation loss: 1.7278053798983175

Epoch: 5| Step: 1
Training loss: 0.13001562654972076
Validation loss: 1.686789890771271

Epoch: 5| Step: 2
Training loss: 0.13374528288841248
Validation loss: 1.7250339010710358

Epoch: 5| Step: 3
Training loss: 0.17658552527427673
Validation loss: 1.7142260869344075

Epoch: 5| Step: 4
Training loss: 0.1288641393184662
Validation loss: 1.6809534642004198

Epoch: 5| Step: 5
Training loss: 0.17438361048698425
Validation loss: 1.7009012417126728

Epoch: 5| Step: 6
Training loss: 0.16104458272457123
Validation loss: 1.6903613562225013

Epoch: 5| Step: 7
Training loss: 0.22651508450508118
Validation loss: 1.6994606743576706

Epoch: 5| Step: 8
Training loss: 0.18176235258579254
Validation loss: 1.6996171461638583

Epoch: 5| Step: 9
Training loss: 0.23744885623455048
Validation loss: 1.7128618109610774

Epoch: 5| Step: 10
Training loss: 0.1852654218673706
Validation loss: 1.6851965304343932

Epoch: 456| Step: 0
Training loss: 0.11612441390752792
Validation loss: 1.75798548037006

Epoch: 5| Step: 1
Training loss: 0.20117740333080292
Validation loss: 1.7406363782062326

Epoch: 5| Step: 2
Training loss: 0.23816867172718048
Validation loss: 1.7575399619276806

Epoch: 5| Step: 3
Training loss: 0.18256954848766327
Validation loss: 1.8031277682191582

Epoch: 5| Step: 4
Training loss: 0.13245807588100433
Validation loss: 1.8025063199381675

Epoch: 5| Step: 5
Training loss: 0.17653164267539978
Validation loss: 1.8103080808475454

Epoch: 5| Step: 6
Training loss: 0.16654542088508606
Validation loss: 1.813837984556793

Epoch: 5| Step: 7
Training loss: 0.16936048865318298
Validation loss: 1.8049922732896702

Epoch: 5| Step: 8
Training loss: 0.27176541090011597
Validation loss: 1.747567363964614

Epoch: 5| Step: 9
Training loss: 0.18519024550914764
Validation loss: 1.7448160853437198

Epoch: 5| Step: 10
Training loss: 0.2516357898712158
Validation loss: 1.7192199883922454

Epoch: 457| Step: 0
Training loss: 0.12110128253698349
Validation loss: 1.6915329630656908

Epoch: 5| Step: 1
Training loss: 0.18800431489944458
Validation loss: 1.6658277165505193

Epoch: 5| Step: 2
Training loss: 0.19446468353271484
Validation loss: 1.6802772142553841

Epoch: 5| Step: 3
Training loss: 0.19514644145965576
Validation loss: 1.6843414921914377

Epoch: 5| Step: 4
Training loss: 0.13328245282173157
Validation loss: 1.679629348939465

Epoch: 5| Step: 5
Training loss: 0.16871801018714905
Validation loss: 1.6995183293537428

Epoch: 5| Step: 6
Training loss: 0.11262421309947968
Validation loss: 1.7143234117056734

Epoch: 5| Step: 7
Training loss: 0.0977284163236618
Validation loss: 1.6966445574196436

Epoch: 5| Step: 8
Training loss: 0.22021766006946564
Validation loss: 1.7236278044280184

Epoch: 5| Step: 9
Training loss: 0.22481970489025116
Validation loss: 1.7356562037621774

Epoch: 5| Step: 10
Training loss: 0.13279058039188385
Validation loss: 1.7601702097923524

Epoch: 458| Step: 0
Training loss: 0.19745007157325745
Validation loss: 1.7194197459887433

Epoch: 5| Step: 1
Training loss: 0.09951549768447876
Validation loss: 1.7139889745302097

Epoch: 5| Step: 2
Training loss: 0.07359877228736877
Validation loss: 1.7321652789269724

Epoch: 5| Step: 3
Training loss: 0.170570969581604
Validation loss: 1.7844962727638982

Epoch: 5| Step: 4
Training loss: 0.1790708750486374
Validation loss: 1.7363016143921883

Epoch: 5| Step: 5
Training loss: 0.23234815895557404
Validation loss: 1.7492178652876167

Epoch: 5| Step: 6
Training loss: 0.18919594585895538
Validation loss: 1.7749251986062655

Epoch: 5| Step: 7
Training loss: 0.172108992934227
Validation loss: 1.7798612374131397

Epoch: 5| Step: 8
Training loss: 0.2098890244960785
Validation loss: 1.7479259493530437

Epoch: 5| Step: 9
Training loss: 0.16314473748207092
Validation loss: 1.711664802925561

Epoch: 5| Step: 10
Training loss: 0.24903170764446259
Validation loss: 1.7565536076022732

Epoch: 459| Step: 0
Training loss: 0.2051953822374344
Validation loss: 1.7392756746661278

Epoch: 5| Step: 1
Training loss: 0.15022733807563782
Validation loss: 1.770619265494808

Epoch: 5| Step: 2
Training loss: 0.21636560559272766
Validation loss: 1.7449405552238546

Epoch: 5| Step: 3
Training loss: 0.16091671586036682
Validation loss: 1.7518426641341178

Epoch: 5| Step: 4
Training loss: 0.08129765093326569
Validation loss: 1.7576375212720645

Epoch: 5| Step: 5
Training loss: 0.1482149064540863
Validation loss: 1.7407982003304265

Epoch: 5| Step: 6
Training loss: 0.1766120344400406
Validation loss: 1.7751197238122263

Epoch: 5| Step: 7
Training loss: 0.16997317969799042
Validation loss: 1.7763008481712752

Epoch: 5| Step: 8
Training loss: 0.10905562341213226
Validation loss: 1.7761526838425667

Epoch: 5| Step: 9
Training loss: 0.1101340502500534
Validation loss: 1.7457239986747823

Epoch: 5| Step: 10
Training loss: 0.18763278424739838
Validation loss: 1.720887686616631

Epoch: 460| Step: 0
Training loss: 0.09968876093626022
Validation loss: 1.7438972611581125

Epoch: 5| Step: 1
Training loss: 0.1372043341398239
Validation loss: 1.7374159802672684

Epoch: 5| Step: 2
Training loss: 0.11917676031589508
Validation loss: 1.7198296734081802

Epoch: 5| Step: 3
Training loss: 0.1427687704563141
Validation loss: 1.7537409887518933

Epoch: 5| Step: 4
Training loss: 0.08212746679782867
Validation loss: 1.744618264577722

Epoch: 5| Step: 5
Training loss: 0.13399171829223633
Validation loss: 1.758596299796976

Epoch: 5| Step: 6
Training loss: 0.15812574326992035
Validation loss: 1.74738904224929

Epoch: 5| Step: 7
Training loss: 0.34387558698654175
Validation loss: 1.7720795882645475

Epoch: 5| Step: 8
Training loss: 0.19011375308036804
Validation loss: 1.7617418150747977

Epoch: 5| Step: 9
Training loss: 0.13716807961463928
Validation loss: 1.7425384367665937

Epoch: 5| Step: 10
Training loss: 0.12248639762401581
Validation loss: 1.7289427711117653

Epoch: 461| Step: 0
Training loss: 0.10264599323272705
Validation loss: 1.7313667625509284

Epoch: 5| Step: 1
Training loss: 0.16753730177879333
Validation loss: 1.7228317312015

Epoch: 5| Step: 2
Training loss: 0.22103309631347656
Validation loss: 1.7493465074928858

Epoch: 5| Step: 3
Training loss: 0.16940300166606903
Validation loss: 1.7484018783415518

Epoch: 5| Step: 4
Training loss: 0.2057594358921051
Validation loss: 1.7764999699848953

Epoch: 5| Step: 5
Training loss: 0.13125021755695343
Validation loss: 1.7743856214707898

Epoch: 5| Step: 6
Training loss: 0.11010819673538208
Validation loss: 1.781735263844972

Epoch: 5| Step: 7
Training loss: 0.13386270403862
Validation loss: 1.800560498750338

Epoch: 5| Step: 8
Training loss: 0.08842908591032028
Validation loss: 1.7577283023506083

Epoch: 5| Step: 9
Training loss: 0.1489252746105194
Validation loss: 1.8023837612521263

Epoch: 5| Step: 10
Training loss: 0.19889205694198608
Validation loss: 1.807973506630108

Epoch: 462| Step: 0
Training loss: 0.17123980820178986
Validation loss: 1.767638696137295

Epoch: 5| Step: 1
Training loss: 0.10612638294696808
Validation loss: 1.736387591208181

Epoch: 5| Step: 2
Training loss: 0.15611104667186737
Validation loss: 1.718300187459556

Epoch: 5| Step: 3
Training loss: 0.14963503181934357
Validation loss: 1.7056656409335393

Epoch: 5| Step: 4
Training loss: 0.14101608097553253
Validation loss: 1.6882395910960373

Epoch: 5| Step: 5
Training loss: 0.17370478808879852
Validation loss: 1.6736144096620622

Epoch: 5| Step: 6
Training loss: 0.20664498209953308
Validation loss: 1.6762301537298387

Epoch: 5| Step: 7
Training loss: 0.1372900903224945
Validation loss: 1.6961058980675154

Epoch: 5| Step: 8
Training loss: 0.12898313999176025
Validation loss: 1.680438321123841

Epoch: 5| Step: 9
Training loss: 0.130392387509346
Validation loss: 1.703092836564587

Epoch: 5| Step: 10
Training loss: 0.12248840183019638
Validation loss: 1.7059086163838704

Epoch: 463| Step: 0
Training loss: 0.18560752272605896
Validation loss: 1.7459663050149077

Epoch: 5| Step: 1
Training loss: 0.10702898353338242
Validation loss: 1.743669653451571

Epoch: 5| Step: 2
Training loss: 0.13898524641990662
Validation loss: 1.7611036928751136

Epoch: 5| Step: 3
Training loss: 0.1857997328042984
Validation loss: 1.7976352296849734

Epoch: 5| Step: 4
Training loss: 0.1477929651737213
Validation loss: 1.752630232482828

Epoch: 5| Step: 5
Training loss: 0.15511949360370636
Validation loss: 1.7306692279795164

Epoch: 5| Step: 6
Training loss: 0.1464880108833313
Validation loss: 1.7197003967018538

Epoch: 5| Step: 7
Training loss: 0.21132954955101013
Validation loss: 1.7130067630480694

Epoch: 5| Step: 8
Training loss: 0.11497509479522705
Validation loss: 1.6799308805055515

Epoch: 5| Step: 9
Training loss: 0.14441291987895966
Validation loss: 1.7034464510538245

Epoch: 5| Step: 10
Training loss: 0.15432438254356384
Validation loss: 1.6775897651590326

Epoch: 464| Step: 0
Training loss: 0.12476430833339691
Validation loss: 1.6905151438969437

Epoch: 5| Step: 1
Training loss: 0.12147346884012222
Validation loss: 1.6909297941833414

Epoch: 5| Step: 2
Training loss: 0.07015234231948853
Validation loss: 1.7009852650345012

Epoch: 5| Step: 3
Training loss: 0.12289713323116302
Validation loss: 1.7642436591527795

Epoch: 5| Step: 4
Training loss: 0.09832537174224854
Validation loss: 1.7777629590803576

Epoch: 5| Step: 5
Training loss: 0.1066996306180954
Validation loss: 1.7595972015011696

Epoch: 5| Step: 6
Training loss: 0.13926807045936584
Validation loss: 1.7514098382765246

Epoch: 5| Step: 7
Training loss: 0.17747168242931366
Validation loss: 1.772321056294185

Epoch: 5| Step: 8
Training loss: 0.20132672786712646
Validation loss: 1.7557633910127866

Epoch: 5| Step: 9
Training loss: 0.1882379800081253
Validation loss: 1.7503515661403697

Epoch: 5| Step: 10
Training loss: 0.0998104065656662
Validation loss: 1.7337006997036677

Epoch: 465| Step: 0
Training loss: 0.10108886659145355
Validation loss: 1.6966144782240673

Epoch: 5| Step: 1
Training loss: 0.14452901482582092
Validation loss: 1.6922170385237663

Epoch: 5| Step: 2
Training loss: 0.1036921963095665
Validation loss: 1.68007880257022

Epoch: 5| Step: 3
Training loss: 0.13330939412117004
Validation loss: 1.6975247142135457

Epoch: 5| Step: 4
Training loss: 0.08173756301403046
Validation loss: 1.7074180559445453

Epoch: 5| Step: 5
Training loss: 0.12497659027576447
Validation loss: 1.7001586998662641

Epoch: 5| Step: 6
Training loss: 0.10844794660806656
Validation loss: 1.7086315078120078

Epoch: 5| Step: 7
Training loss: 0.1296074241399765
Validation loss: 1.744740201580909

Epoch: 5| Step: 8
Training loss: 0.14045321941375732
Validation loss: 1.7483573049627326

Epoch: 5| Step: 9
Training loss: 0.2004787027835846
Validation loss: 1.7775247917380383

Epoch: 5| Step: 10
Training loss: 0.13424603641033173
Validation loss: 1.7689380684206564

Epoch: 466| Step: 0
Training loss: 0.1426132470369339
Validation loss: 1.7602761227597472

Epoch: 5| Step: 1
Training loss: 0.13711616396903992
Validation loss: 1.73819730102375

Epoch: 5| Step: 2
Training loss: 0.07204173505306244
Validation loss: 1.7093384368445284

Epoch: 5| Step: 3
Training loss: 0.12685851752758026
Validation loss: 1.6784415424510997

Epoch: 5| Step: 4
Training loss: 0.11881254613399506
Validation loss: 1.703255284217096

Epoch: 5| Step: 5
Training loss: 0.2088487595319748
Validation loss: 1.6922051342584754

Epoch: 5| Step: 6
Training loss: 0.15941141545772552
Validation loss: 1.6973148033183107

Epoch: 5| Step: 7
Training loss: 0.07337780296802521
Validation loss: 1.691519901316653

Epoch: 5| Step: 8
Training loss: 0.1477195918560028
Validation loss: 1.6826254552410496

Epoch: 5| Step: 9
Training loss: 0.14429713785648346
Validation loss: 1.675431877054194

Epoch: 5| Step: 10
Training loss: 0.11165113747119904
Validation loss: 1.6866659720738728

Epoch: 467| Step: 0
Training loss: 0.09280020743608475
Validation loss: 1.7227965183155511

Epoch: 5| Step: 1
Training loss: 0.09194698929786682
Validation loss: 1.719712024093956

Epoch: 5| Step: 2
Training loss: 0.10594981908798218
Validation loss: 1.7535900198003298

Epoch: 5| Step: 3
Training loss: 0.1294364035129547
Validation loss: 1.7336829118831183

Epoch: 5| Step: 4
Training loss: 0.1425083726644516
Validation loss: 1.742730043267691

Epoch: 5| Step: 5
Training loss: 0.1373806893825531
Validation loss: 1.7113233458611272

Epoch: 5| Step: 6
Training loss: 0.13053882122039795
Validation loss: 1.7123452924912976

Epoch: 5| Step: 7
Training loss: 0.21897561848163605
Validation loss: 1.7243278411126906

Epoch: 5| Step: 8
Training loss: 0.06810808926820755
Validation loss: 1.7042722112389022

Epoch: 5| Step: 9
Training loss: 0.10787089914083481
Validation loss: 1.7131025598895164

Epoch: 5| Step: 10
Training loss: 0.12643873691558838
Validation loss: 1.7290031012668405

Epoch: 468| Step: 0
Training loss: 0.1256512552499771
Validation loss: 1.7386323457123132

Epoch: 5| Step: 1
Training loss: 0.11047904193401337
Validation loss: 1.70101236912512

Epoch: 5| Step: 2
Training loss: 0.057281702756881714
Validation loss: 1.7322079417526082

Epoch: 5| Step: 3
Training loss: 0.12544581294059753
Validation loss: 1.7506969808250346

Epoch: 5| Step: 4
Training loss: 0.13998493552207947
Validation loss: 1.7646086062154462

Epoch: 5| Step: 5
Training loss: 0.13915862143039703
Validation loss: 1.827362669411526

Epoch: 5| Step: 6
Training loss: 0.13150754570960999
Validation loss: 1.7741368842381302

Epoch: 5| Step: 7
Training loss: 0.2210340052843094
Validation loss: 1.7503006278827626

Epoch: 5| Step: 8
Training loss: 0.15449324250221252
Validation loss: 1.7565246429494632

Epoch: 5| Step: 9
Training loss: 0.17245979607105255
Validation loss: 1.744289667375626

Epoch: 5| Step: 10
Training loss: 0.12584379315376282
Validation loss: 1.7393404565831667

Epoch: 469| Step: 0
Training loss: 0.07873855531215668
Validation loss: 1.7439026499307284

Epoch: 5| Step: 1
Training loss: 0.11427611112594604
Validation loss: 1.7764570584861181

Epoch: 5| Step: 2
Training loss: 0.10126576572656631
Validation loss: 1.7285554242390457

Epoch: 5| Step: 3
Training loss: 0.1344098597764969
Validation loss: 1.7222064464322981

Epoch: 5| Step: 4
Training loss: 0.12920956313610077
Validation loss: 1.7414133600009385

Epoch: 5| Step: 5
Training loss: 0.11561338603496552
Validation loss: 1.7531099537367463

Epoch: 5| Step: 6
Training loss: 0.12058796733617783
Validation loss: 1.7316057579491728

Epoch: 5| Step: 7
Training loss: 0.11728843301534653
Validation loss: 1.7673708213272916

Epoch: 5| Step: 8
Training loss: 0.21343982219696045
Validation loss: 1.7835193385360062

Epoch: 5| Step: 9
Training loss: 0.09080645442008972
Validation loss: 1.7854249554295694

Epoch: 5| Step: 10
Training loss: 0.1315440982580185
Validation loss: 1.7772372858498686

Epoch: 470| Step: 0
Training loss: 0.06823471188545227
Validation loss: 1.755859589063993

Epoch: 5| Step: 1
Training loss: 0.06932894140481949
Validation loss: 1.7464920205454673

Epoch: 5| Step: 2
Training loss: 0.1038934737443924
Validation loss: 1.7268007519424602

Epoch: 5| Step: 3
Training loss: 0.13011384010314941
Validation loss: 1.744936586708151

Epoch: 5| Step: 4
Training loss: 0.11039962619543076
Validation loss: 1.7219885690237886

Epoch: 5| Step: 5
Training loss: 0.10274600982666016
Validation loss: 1.76595550967801

Epoch: 5| Step: 6
Training loss: 0.14718422293663025
Validation loss: 1.7507322206292102

Epoch: 5| Step: 7
Training loss: 0.17920348048210144
Validation loss: 1.7742836244644657

Epoch: 5| Step: 8
Training loss: 0.14315874874591827
Validation loss: 1.774564012404411

Epoch: 5| Step: 9
Training loss: 0.16113607585430145
Validation loss: 1.7755000822005733

Epoch: 5| Step: 10
Training loss: 0.2000609189271927
Validation loss: 1.7574725330516856

Epoch: 471| Step: 0
Training loss: 0.14762136340141296
Validation loss: 1.7652063856842697

Epoch: 5| Step: 1
Training loss: 0.10397882759571075
Validation loss: 1.7624731948298793

Epoch: 5| Step: 2
Training loss: 0.11168547719717026
Validation loss: 1.7063144253146263

Epoch: 5| Step: 3
Training loss: 0.1892586052417755
Validation loss: 1.7123639481042021

Epoch: 5| Step: 4
Training loss: 0.09180549532175064
Validation loss: 1.7063494754093949

Epoch: 5| Step: 5
Training loss: 0.10596451908349991
Validation loss: 1.6896837321660851

Epoch: 5| Step: 6
Training loss: 0.11482810974121094
Validation loss: 1.6611999401482203

Epoch: 5| Step: 7
Training loss: 0.11983346939086914
Validation loss: 1.6742963175619803

Epoch: 5| Step: 8
Training loss: 0.15359637141227722
Validation loss: 1.6873191364349858

Epoch: 5| Step: 9
Training loss: 0.13448850810527802
Validation loss: 1.7234093886549755

Epoch: 5| Step: 10
Training loss: 0.1992989182472229
Validation loss: 1.7304010737326838

Epoch: 472| Step: 0
Training loss: 0.11033453792333603
Validation loss: 1.7707866032918294

Epoch: 5| Step: 1
Training loss: 0.12480900436639786
Validation loss: 1.748998603513164

Epoch: 5| Step: 2
Training loss: 0.1862131804227829
Validation loss: 1.7620134263910272

Epoch: 5| Step: 3
Training loss: 0.12718477845191956
Validation loss: 1.799818451686572

Epoch: 5| Step: 4
Training loss: 0.13077911734580994
Validation loss: 1.7605914646579373

Epoch: 5| Step: 5
Training loss: 0.23172327876091003
Validation loss: 1.7238617744497073

Epoch: 5| Step: 6
Training loss: 0.11201760917901993
Validation loss: 1.7385495798562163

Epoch: 5| Step: 7
Training loss: 0.12419243901968002
Validation loss: 1.7093270337709816

Epoch: 5| Step: 8
Training loss: 0.17766322195529938
Validation loss: 1.692844929233674

Epoch: 5| Step: 9
Training loss: 0.09468179941177368
Validation loss: 1.7128740920815417

Epoch: 5| Step: 10
Training loss: 0.08795130252838135
Validation loss: 1.6839687337157547

Epoch: 473| Step: 0
Training loss: 0.16285361349582672
Validation loss: 1.6966919078621814

Epoch: 5| Step: 1
Training loss: 0.13930253684520721
Validation loss: 1.6897443930308025

Epoch: 5| Step: 2
Training loss: 0.14335523545742035
Validation loss: 1.6909580269167501

Epoch: 5| Step: 3
Training loss: 0.14088095724582672
Validation loss: 1.731395144616404

Epoch: 5| Step: 4
Training loss: 0.11311419308185577
Validation loss: 1.7080091994295838

Epoch: 5| Step: 5
Training loss: 0.15740442276000977
Validation loss: 1.735460126271812

Epoch: 5| Step: 6
Training loss: 0.1896471530199051
Validation loss: 1.756539644733552

Epoch: 5| Step: 7
Training loss: 0.150546595454216
Validation loss: 1.7528107576472785

Epoch: 5| Step: 8
Training loss: 0.19381356239318848
Validation loss: 1.7412519724138322

Epoch: 5| Step: 9
Training loss: 0.16457228362560272
Validation loss: 1.7303903666875695

Epoch: 5| Step: 10
Training loss: 0.1428452581167221
Validation loss: 1.7252120638406405

Epoch: 474| Step: 0
Training loss: 0.1236763447523117
Validation loss: 1.6924198686435659

Epoch: 5| Step: 1
Training loss: 0.12492815405130386
Validation loss: 1.6944385587528188

Epoch: 5| Step: 2
Training loss: 0.16244284808635712
Validation loss: 1.640037316147999

Epoch: 5| Step: 3
Training loss: 0.20102271437644958
Validation loss: 1.6560432654555126

Epoch: 5| Step: 4
Training loss: 0.11986563354730606
Validation loss: 1.660594404384654

Epoch: 5| Step: 5
Training loss: 0.14870503544807434
Validation loss: 1.6964363462181502

Epoch: 5| Step: 6
Training loss: 0.20654802024364471
Validation loss: 1.6781454624668244

Epoch: 5| Step: 7
Training loss: 0.12651929259300232
Validation loss: 1.7236427850620721

Epoch: 5| Step: 8
Training loss: 0.14468878507614136
Validation loss: 1.751571721928094

Epoch: 5| Step: 9
Training loss: 0.1382252424955368
Validation loss: 1.7562824885050456

Epoch: 5| Step: 10
Training loss: 0.09483816474676132
Validation loss: 1.799161002200137

Epoch: 475| Step: 0
Training loss: 0.1341988891363144
Validation loss: 1.8228762970175794

Epoch: 5| Step: 1
Training loss: 0.17344948649406433
Validation loss: 1.7929675297070575

Epoch: 5| Step: 2
Training loss: 0.16971266269683838
Validation loss: 1.8008705210942093

Epoch: 5| Step: 3
Training loss: 0.13770300149917603
Validation loss: 1.7444122593889955

Epoch: 5| Step: 4
Training loss: 0.07795549929141998
Validation loss: 1.7344970292942499

Epoch: 5| Step: 5
Training loss: 0.16441574692726135
Validation loss: 1.6924587923993346

Epoch: 5| Step: 6
Training loss: 0.1113847941160202
Validation loss: 1.7076285731407903

Epoch: 5| Step: 7
Training loss: 0.13782861828804016
Validation loss: 1.683053720381952

Epoch: 5| Step: 8
Training loss: 0.24985401332378387
Validation loss: 1.7096663534000356

Epoch: 5| Step: 9
Training loss: 0.18501679599285126
Validation loss: 1.695111620810724

Epoch: 5| Step: 10
Training loss: 0.1453040987253189
Validation loss: 1.642932063789778

Epoch: 476| Step: 0
Training loss: 0.13773614168167114
Validation loss: 1.6704162333601265

Epoch: 5| Step: 1
Training loss: 0.11679090559482574
Validation loss: 1.6702078221946635

Epoch: 5| Step: 2
Training loss: 0.11743030697107315
Validation loss: 1.6869828201109363

Epoch: 5| Step: 3
Training loss: 0.13823461532592773
Validation loss: 1.6902556086099276

Epoch: 5| Step: 4
Training loss: 0.10709977149963379
Validation loss: 1.7122631303725704

Epoch: 5| Step: 5
Training loss: 0.1629190742969513
Validation loss: 1.7222562169515958

Epoch: 5| Step: 6
Training loss: 0.1256401538848877
Validation loss: 1.74022203107034

Epoch: 5| Step: 7
Training loss: 0.07849438488483429
Validation loss: 1.7282363022527387

Epoch: 5| Step: 8
Training loss: 0.08497459441423416
Validation loss: 1.750810146331787

Epoch: 5| Step: 9
Training loss: 0.13758547604084015
Validation loss: 1.7750908931096394

Epoch: 5| Step: 10
Training loss: 0.1807372123003006
Validation loss: 1.7296976261241461

Epoch: 477| Step: 0
Training loss: 0.11854654550552368
Validation loss: 1.7056824507251862

Epoch: 5| Step: 1
Training loss: 0.10165286064147949
Validation loss: 1.72377489202766

Epoch: 5| Step: 2
Training loss: 0.17533335089683533
Validation loss: 1.719261174560875

Epoch: 5| Step: 3
Training loss: 0.15568801760673523
Validation loss: 1.7480239406708749

Epoch: 5| Step: 4
Training loss: 0.109510138630867
Validation loss: 1.7498753122104111

Epoch: 5| Step: 5
Training loss: 0.08974550664424896
Validation loss: 1.7288473357436478

Epoch: 5| Step: 6
Training loss: 0.092441126704216
Validation loss: 1.7354639537872807

Epoch: 5| Step: 7
Training loss: 0.10238303244113922
Validation loss: 1.7522227635947607

Epoch: 5| Step: 8
Training loss: 0.18217916786670685
Validation loss: 1.737972831213346

Epoch: 5| Step: 9
Training loss: 0.09045587480068207
Validation loss: 1.7360870761256064

Epoch: 5| Step: 10
Training loss: 0.256803035736084
Validation loss: 1.7148439230457428

Epoch: 478| Step: 0
Training loss: 0.11165682971477509
Validation loss: 1.6968367702217513

Epoch: 5| Step: 1
Training loss: 0.1278253048658371
Validation loss: 1.6903633456076346

Epoch: 5| Step: 2
Training loss: 0.16516585648059845
Validation loss: 1.6588163670673166

Epoch: 5| Step: 3
Training loss: 0.12768885493278503
Validation loss: 1.6617788499401462

Epoch: 5| Step: 4
Training loss: 0.1625339686870575
Validation loss: 1.6565815415433658

Epoch: 5| Step: 5
Training loss: 0.13355155289173126
Validation loss: 1.6706412505078059

Epoch: 5| Step: 6
Training loss: 0.2048943042755127
Validation loss: 1.6851387395653674

Epoch: 5| Step: 7
Training loss: 0.18192829191684723
Validation loss: 1.7096229650641

Epoch: 5| Step: 8
Training loss: 0.2850353717803955
Validation loss: 1.7606920542255524

Epoch: 5| Step: 9
Training loss: 0.22103050351142883
Validation loss: 1.721543501782161

Epoch: 5| Step: 10
Training loss: 0.2618204355239868
Validation loss: 1.7577091929733113

Epoch: 479| Step: 0
Training loss: 0.09832537174224854
Validation loss: 1.7575987833802418

Epoch: 5| Step: 1
Training loss: 0.19624760746955872
Validation loss: 1.742150596393052

Epoch: 5| Step: 2
Training loss: 0.1635841280221939
Validation loss: 1.7308671077092488

Epoch: 5| Step: 3
Training loss: 0.19841210544109344
Validation loss: 1.718736328104491

Epoch: 5| Step: 4
Training loss: 0.0839775949716568
Validation loss: 1.7265204678299606

Epoch: 5| Step: 5
Training loss: 0.17306146025657654
Validation loss: 1.7297235958037838

Epoch: 5| Step: 6
Training loss: 0.1353895366191864
Validation loss: 1.6793044254343996

Epoch: 5| Step: 7
Training loss: 0.09462183713912964
Validation loss: 1.7086796324740174

Epoch: 5| Step: 8
Training loss: 0.15114186704158783
Validation loss: 1.6856385802709928

Epoch: 5| Step: 9
Training loss: 0.09880135208368301
Validation loss: 1.6812039280450473

Epoch: 5| Step: 10
Training loss: 0.12901848554611206
Validation loss: 1.6470808380393571

Epoch: 480| Step: 0
Training loss: 0.0952838659286499
Validation loss: 1.6815938468902343

Epoch: 5| Step: 1
Training loss: 0.1113823875784874
Validation loss: 1.7008220611080047

Epoch: 5| Step: 2
Training loss: 0.12279759347438812
Validation loss: 1.6914795085948

Epoch: 5| Step: 3
Training loss: 0.13312402367591858
Validation loss: 1.6753856212862077

Epoch: 5| Step: 4
Training loss: 0.1269705444574356
Validation loss: 1.6738178576192548

Epoch: 5| Step: 5
Training loss: 0.07340789586305618
Validation loss: 1.6547503074010212

Epoch: 5| Step: 6
Training loss: 0.10500144958496094
Validation loss: 1.672303322822817

Epoch: 5| Step: 7
Training loss: 0.1384386122226715
Validation loss: 1.653461394771453

Epoch: 5| Step: 8
Training loss: 0.20707838237285614
Validation loss: 1.657100026325513

Epoch: 5| Step: 9
Training loss: 0.15097668766975403
Validation loss: 1.6743729742624427

Epoch: 5| Step: 10
Training loss: 0.10081082582473755
Validation loss: 1.689152350989721

Epoch: 481| Step: 0
Training loss: 0.15622270107269287
Validation loss: 1.6874742366934334

Epoch: 5| Step: 1
Training loss: 0.10392377525568008
Validation loss: 1.6886427197405087

Epoch: 5| Step: 2
Training loss: 0.16508054733276367
Validation loss: 1.6902796145408385

Epoch: 5| Step: 3
Training loss: 0.12229998409748077
Validation loss: 1.7353167341601463

Epoch: 5| Step: 4
Training loss: 0.13264815509319305
Validation loss: 1.7466692911681307

Epoch: 5| Step: 5
Training loss: 0.19135749340057373
Validation loss: 1.7337602710211149

Epoch: 5| Step: 6
Training loss: 0.14460192620754242
Validation loss: 1.7167622761059833

Epoch: 5| Step: 7
Training loss: 0.1667957901954651
Validation loss: 1.727014183998108

Epoch: 5| Step: 8
Training loss: 0.1298244744539261
Validation loss: 1.696222819948709

Epoch: 5| Step: 9
Training loss: 0.13998833298683167
Validation loss: 1.6688085127902288

Epoch: 5| Step: 10
Training loss: 0.2491993010044098
Validation loss: 1.653738034668789

Epoch: 482| Step: 0
Training loss: 0.14837944507598877
Validation loss: 1.644979646128993

Epoch: 5| Step: 1
Training loss: 0.15073946118354797
Validation loss: 1.6227278837593653

Epoch: 5| Step: 2
Training loss: 0.1351352483034134
Validation loss: 1.650616217685002

Epoch: 5| Step: 3
Training loss: 0.18828342854976654
Validation loss: 1.6485309549557265

Epoch: 5| Step: 4
Training loss: 0.14220446348190308
Validation loss: 1.623671882896013

Epoch: 5| Step: 5
Training loss: 0.21068818867206573
Validation loss: 1.6442090529267506

Epoch: 5| Step: 6
Training loss: 0.1418335884809494
Validation loss: 1.653958808991217

Epoch: 5| Step: 7
Training loss: 0.11805985122919083
Validation loss: 1.648089660111294

Epoch: 5| Step: 8
Training loss: 0.12398083508014679
Validation loss: 1.662837137458145

Epoch: 5| Step: 9
Training loss: 0.13153354823589325
Validation loss: 1.6777695468676987

Epoch: 5| Step: 10
Training loss: 0.15799926221370697
Validation loss: 1.6909402660144273

Epoch: 483| Step: 0
Training loss: 0.10274209082126617
Validation loss: 1.7157130831031389

Epoch: 5| Step: 1
Training loss: 0.1541641652584076
Validation loss: 1.6968002755154845

Epoch: 5| Step: 2
Training loss: 0.08259586989879608
Validation loss: 1.7407967480280067

Epoch: 5| Step: 3
Training loss: 0.14400513470172882
Validation loss: 1.75255698157895

Epoch: 5| Step: 4
Training loss: 0.2308875024318695
Validation loss: 1.7436868977803055

Epoch: 5| Step: 5
Training loss: 0.12800279259681702
Validation loss: 1.7353663162518573

Epoch: 5| Step: 6
Training loss: 0.09628506749868393
Validation loss: 1.7141297735193723

Epoch: 5| Step: 7
Training loss: 0.09044500440359116
Validation loss: 1.7267968436723113

Epoch: 5| Step: 8
Training loss: 0.05270810052752495
Validation loss: 1.6871789706650602

Epoch: 5| Step: 9
Training loss: 0.130528062582016
Validation loss: 1.7205749609137093

Epoch: 5| Step: 10
Training loss: 0.1598501205444336
Validation loss: 1.7187865472608996

Epoch: 484| Step: 0
Training loss: 0.21228699386119843
Validation loss: 1.6979363810631536

Epoch: 5| Step: 1
Training loss: 0.10689152777194977
Validation loss: 1.6943767621953

Epoch: 5| Step: 2
Training loss: 0.09016380459070206
Validation loss: 1.6669430373817362

Epoch: 5| Step: 3
Training loss: 0.10909578949213028
Validation loss: 1.6875880341376028

Epoch: 5| Step: 4
Training loss: 0.1606035679578781
Validation loss: 1.6919390296423307

Epoch: 5| Step: 5
Training loss: 0.10030541568994522
Validation loss: 1.7086476843844178

Epoch: 5| Step: 6
Training loss: 0.13056299090385437
Validation loss: 1.6865166848705662

Epoch: 5| Step: 7
Training loss: 0.14624585211277008
Validation loss: 1.689453940237722

Epoch: 5| Step: 8
Training loss: 0.08723168075084686
Validation loss: 1.6964220180306384

Epoch: 5| Step: 9
Training loss: 0.14450064301490784
Validation loss: 1.7161548855484172

Epoch: 5| Step: 10
Training loss: 0.10590117424726486
Validation loss: 1.711516700765138

Epoch: 485| Step: 0
Training loss: 0.09605799615383148
Validation loss: 1.7014236168194843

Epoch: 5| Step: 1
Training loss: 0.11800529807806015
Validation loss: 1.6748384532108103

Epoch: 5| Step: 2
Training loss: 0.10054326057434082
Validation loss: 1.6707431090775358

Epoch: 5| Step: 3
Training loss: 0.11669989675283432
Validation loss: 1.6719207827762892

Epoch: 5| Step: 4
Training loss: 0.13876362144947052
Validation loss: 1.651817076949663

Epoch: 5| Step: 5
Training loss: 0.12470674514770508
Validation loss: 1.6438019480756534

Epoch: 5| Step: 6
Training loss: 0.15140974521636963
Validation loss: 1.6451559682046213

Epoch: 5| Step: 7
Training loss: 0.11579505354166031
Validation loss: 1.6348682782983268

Epoch: 5| Step: 8
Training loss: 0.16176548600196838
Validation loss: 1.618675213347199

Epoch: 5| Step: 9
Training loss: 0.06889445334672928
Validation loss: 1.6705655333816365

Epoch: 5| Step: 10
Training loss: 0.09686263650655746
Validation loss: 1.6401393144361434

Epoch: 486| Step: 0
Training loss: 0.12756875157356262
Validation loss: 1.6632875806541854

Epoch: 5| Step: 1
Training loss: 0.1228751689195633
Validation loss: 1.6685644606108307

Epoch: 5| Step: 2
Training loss: 0.14781954884529114
Validation loss: 1.7062280280615694

Epoch: 5| Step: 3
Training loss: 0.1467805802822113
Validation loss: 1.708678319890012

Epoch: 5| Step: 4
Training loss: 0.10788228362798691
Validation loss: 1.6991498303669754

Epoch: 5| Step: 5
Training loss: 0.10926838219165802
Validation loss: 1.6665910520861227

Epoch: 5| Step: 6
Training loss: 0.0871698185801506
Validation loss: 1.660954257493378

Epoch: 5| Step: 7
Training loss: 0.06435583531856537
Validation loss: 1.6606987778858473

Epoch: 5| Step: 8
Training loss: 0.1223665252327919
Validation loss: 1.6419185656373219

Epoch: 5| Step: 9
Training loss: 0.11080144345760345
Validation loss: 1.6563623746236165

Epoch: 5| Step: 10
Training loss: 0.18649451434612274
Validation loss: 1.6435076882762294

Epoch: 487| Step: 0
Training loss: 0.09138728678226471
Validation loss: 1.6266432654473089

Epoch: 5| Step: 1
Training loss: 0.16017594933509827
Validation loss: 1.6312665888058242

Epoch: 5| Step: 2
Training loss: 0.10067294538021088
Validation loss: 1.640382937205735

Epoch: 5| Step: 3
Training loss: 0.10044358670711517
Validation loss: 1.6693664635381391

Epoch: 5| Step: 4
Training loss: 0.16696712374687195
Validation loss: 1.6556597102072932

Epoch: 5| Step: 5
Training loss: 0.1046953946352005
Validation loss: 1.6835806421054307

Epoch: 5| Step: 6
Training loss: 0.126337930560112
Validation loss: 1.6770895655437181

Epoch: 5| Step: 7
Training loss: 0.10958918184041977
Validation loss: 1.715034181071866

Epoch: 5| Step: 8
Training loss: 0.07981692254543304
Validation loss: 1.7218758085722565

Epoch: 5| Step: 9
Training loss: 0.1655166745185852
Validation loss: 1.7365725706982356

Epoch: 5| Step: 10
Training loss: 0.09941564500331879
Validation loss: 1.7296657664801485

Epoch: 488| Step: 0
Training loss: 0.15179632604122162
Validation loss: 1.7342098887248705

Epoch: 5| Step: 1
Training loss: 0.08337687700986862
Validation loss: 1.7459499669331375

Epoch: 5| Step: 2
Training loss: 0.1839861124753952
Validation loss: 1.6971922882141606

Epoch: 5| Step: 3
Training loss: 0.15605948865413666
Validation loss: 1.7195619472893335

Epoch: 5| Step: 4
Training loss: 0.11413363367319107
Validation loss: 1.7096462993211643

Epoch: 5| Step: 5
Training loss: 0.08008670061826706
Validation loss: 1.6992841689817366

Epoch: 5| Step: 6
Training loss: 0.15305957198143005
Validation loss: 1.6944044969415153

Epoch: 5| Step: 7
Training loss: 0.08698738366365433
Validation loss: 1.6525066103986514

Epoch: 5| Step: 8
Training loss: 0.14591094851493835
Validation loss: 1.650869842498533

Epoch: 5| Step: 9
Training loss: 0.12350723892450333
Validation loss: 1.6539368052636423

Epoch: 5| Step: 10
Training loss: 0.05730520933866501
Validation loss: 1.6526716460463822

Epoch: 489| Step: 0
Training loss: 0.10447976738214493
Validation loss: 1.6552088722105949

Epoch: 5| Step: 1
Training loss: 0.08222195506095886
Validation loss: 1.6581404824410715

Epoch: 5| Step: 2
Training loss: 0.15730991959571838
Validation loss: 1.6523603354730914

Epoch: 5| Step: 3
Training loss: 0.10276241600513458
Validation loss: 1.6817091408596243

Epoch: 5| Step: 4
Training loss: 0.22195279598236084
Validation loss: 1.693682204010666

Epoch: 5| Step: 5
Training loss: 0.09060101211071014
Validation loss: 1.696377133810392

Epoch: 5| Step: 6
Training loss: 0.13801883161067963
Validation loss: 1.6781631708145142

Epoch: 5| Step: 7
Training loss: 0.12875044345855713
Validation loss: 1.689063605441842

Epoch: 5| Step: 8
Training loss: 0.17019471526145935
Validation loss: 1.648419705770349

Epoch: 5| Step: 9
Training loss: 0.13289250433444977
Validation loss: 1.6704681047829248

Epoch: 5| Step: 10
Training loss: 0.09933384507894516
Validation loss: 1.6358200228342445

Epoch: 490| Step: 0
Training loss: 0.14187340438365936
Validation loss: 1.6355806294307913

Epoch: 5| Step: 1
Training loss: 0.10173336416482925
Validation loss: 1.6576078425171554

Epoch: 5| Step: 2
Training loss: 0.10286054760217667
Validation loss: 1.6395824622082453

Epoch: 5| Step: 3
Training loss: 0.08298546075820923
Validation loss: 1.6486981902071225

Epoch: 5| Step: 4
Training loss: 0.13946083188056946
Validation loss: 1.65949539215334

Epoch: 5| Step: 5
Training loss: 0.22859995067119598
Validation loss: 1.6877512367822791

Epoch: 5| Step: 6
Training loss: 0.15763340890407562
Validation loss: 1.7134545439033098

Epoch: 5| Step: 7
Training loss: 0.09275119006633759
Validation loss: 1.6863137175959926

Epoch: 5| Step: 8
Training loss: 0.09657805413007736
Validation loss: 1.6966882021196428

Epoch: 5| Step: 9
Training loss: 0.09516189247369766
Validation loss: 1.672916240589593

Epoch: 5| Step: 10
Training loss: 0.1366061270236969
Validation loss: 1.671442485624744

Epoch: 491| Step: 0
Training loss: 0.12248384952545166
Validation loss: 1.7036265173266012

Epoch: 5| Step: 1
Training loss: 0.07051588594913483
Validation loss: 1.6733037464080318

Epoch: 5| Step: 2
Training loss: 0.10472327470779419
Validation loss: 1.6933561102036507

Epoch: 5| Step: 3
Training loss: 0.07807557284832001
Validation loss: 1.6810645082945466

Epoch: 5| Step: 4
Training loss: 0.11061348766088486
Validation loss: 1.6961882293865245

Epoch: 5| Step: 5
Training loss: 0.09691686183214188
Validation loss: 1.6960671358211066

Epoch: 5| Step: 6
Training loss: 0.09418682008981705
Validation loss: 1.734587025898759

Epoch: 5| Step: 7
Training loss: 0.14015480875968933
Validation loss: 1.7642236717285649

Epoch: 5| Step: 8
Training loss: 0.14327433705329895
Validation loss: 1.7548090796316824

Epoch: 5| Step: 9
Training loss: 0.13882781565189362
Validation loss: 1.7750734488169353

Epoch: 5| Step: 10
Training loss: 0.18919391930103302
Validation loss: 1.7667824658014442

Epoch: 492| Step: 0
Training loss: 0.13310840725898743
Validation loss: 1.7162285594530002

Epoch: 5| Step: 1
Training loss: 0.11095839738845825
Validation loss: 1.6994893153508503

Epoch: 5| Step: 2
Training loss: 0.09619125723838806
Validation loss: 1.669019401714366

Epoch: 5| Step: 3
Training loss: 0.10874686390161514
Validation loss: 1.6573743640735585

Epoch: 5| Step: 4
Training loss: 0.17891137301921844
Validation loss: 1.6570494726140013

Epoch: 5| Step: 5
Training loss: 0.11004023253917694
Validation loss: 1.6520188982768724

Epoch: 5| Step: 6
Training loss: 0.09635854512453079
Validation loss: 1.641393946063134

Epoch: 5| Step: 7
Training loss: 0.09493711590766907
Validation loss: 1.6605600246819117

Epoch: 5| Step: 8
Training loss: 0.10342571884393692
Validation loss: 1.6760128223767845

Epoch: 5| Step: 9
Training loss: 0.13589340448379517
Validation loss: 1.6544959096498386

Epoch: 5| Step: 10
Training loss: 0.07001252472400665
Validation loss: 1.6845447222391765

Epoch: 493| Step: 0
Training loss: 0.09329722076654434
Validation loss: 1.7227535004256873

Epoch: 5| Step: 1
Training loss: 0.09609811007976532
Validation loss: 1.7102392527364916

Epoch: 5| Step: 2
Training loss: 0.12668989598751068
Validation loss: 1.7203614993761944

Epoch: 5| Step: 3
Training loss: 0.07187730073928833
Validation loss: 1.7050014311267483

Epoch: 5| Step: 4
Training loss: 0.09590259194374084
Validation loss: 1.7189639601656186

Epoch: 5| Step: 5
Training loss: 0.16089266538619995
Validation loss: 1.6930454245177649

Epoch: 5| Step: 6
Training loss: 0.1068873181939125
Validation loss: 1.6718412368528304

Epoch: 5| Step: 7
Training loss: 0.04569626599550247
Validation loss: 1.6499315359259163

Epoch: 5| Step: 8
Training loss: 0.09805857390165329
Validation loss: 1.5971502450204664

Epoch: 5| Step: 9
Training loss: 0.1380693018436432
Validation loss: 1.5721586993945542

Epoch: 5| Step: 10
Training loss: 0.19204318523406982
Validation loss: 1.570424856678132

Epoch: 494| Step: 0
Training loss: 0.14037922024726868
Validation loss: 1.5677124800220612

Epoch: 5| Step: 1
Training loss: 0.1184091717004776
Validation loss: 1.5371219868301063

Epoch: 5| Step: 2
Training loss: 0.1743290275335312
Validation loss: 1.5650403320148427

Epoch: 5| Step: 3
Training loss: 0.1578267365694046
Validation loss: 1.5512337312903455

Epoch: 5| Step: 4
Training loss: 0.1450527161359787
Validation loss: 1.5644112633120628

Epoch: 5| Step: 5
Training loss: 0.09671402722597122
Validation loss: 1.6137739227664085

Epoch: 5| Step: 6
Training loss: 0.12216172367334366
Validation loss: 1.6492403297014133

Epoch: 5| Step: 7
Training loss: 0.07282508909702301
Validation loss: 1.684687013267189

Epoch: 5| Step: 8
Training loss: 0.1142411082983017
Validation loss: 1.6963969187069965

Epoch: 5| Step: 9
Training loss: 0.1751825511455536
Validation loss: 1.753628833319551

Epoch: 5| Step: 10
Training loss: 0.14895114302635193
Validation loss: 1.7966176232983988

Epoch: 495| Step: 0
Training loss: 0.11895348131656647
Validation loss: 1.7598826295586043

Epoch: 5| Step: 1
Training loss: 0.11592326313257217
Validation loss: 1.7563071609825216

Epoch: 5| Step: 2
Training loss: 0.11482174694538116
Validation loss: 1.6775883820749098

Epoch: 5| Step: 3
Training loss: 0.24048466980457306
Validation loss: 1.716084885340865

Epoch: 5| Step: 4
Training loss: 0.08256004750728607
Validation loss: 1.6623551435368036

Epoch: 5| Step: 5
Training loss: 0.12292519956827164
Validation loss: 1.6480152632600518

Epoch: 5| Step: 6
Training loss: 0.09386324137449265
Validation loss: 1.6071732428766066

Epoch: 5| Step: 7
Training loss: 0.14718572795391083
Validation loss: 1.5919561668108868

Epoch: 5| Step: 8
Training loss: 0.19749715924263
Validation loss: 1.6051101248751405

Epoch: 5| Step: 9
Training loss: 0.15232327580451965
Validation loss: 1.6084561540234474

Epoch: 5| Step: 10
Training loss: 0.1248864009976387
Validation loss: 1.6123992320029967

Epoch: 496| Step: 0
Training loss: 0.1383049488067627
Validation loss: 1.5796705420299242

Epoch: 5| Step: 1
Training loss: 0.22545798122882843
Validation loss: 1.622563749231318

Epoch: 5| Step: 2
Training loss: 0.06965702772140503
Validation loss: 1.64049102926767

Epoch: 5| Step: 3
Training loss: 0.09337925165891647
Validation loss: 1.6822744377197758

Epoch: 5| Step: 4
Training loss: 0.14496436715126038
Validation loss: 1.6872655678820867

Epoch: 5| Step: 5
Training loss: 0.10274437814950943
Validation loss: 1.6521849593808573

Epoch: 5| Step: 6
Training loss: 0.11450745910406113
Validation loss: 1.6673834734065558

Epoch: 5| Step: 7
Training loss: 0.10205712169408798
Validation loss: 1.6646861389119139

Epoch: 5| Step: 8
Training loss: 0.11749525368213654
Validation loss: 1.6587845176778815

Epoch: 5| Step: 9
Training loss: 0.15487180650234222
Validation loss: 1.6571757139698151

Epoch: 5| Step: 10
Training loss: 0.08808726072311401
Validation loss: 1.6371007273274083

Epoch: 497| Step: 0
Training loss: 0.12623348832130432
Validation loss: 1.6501326778883576

Epoch: 5| Step: 1
Training loss: 0.12475929409265518
Validation loss: 1.6386919867607854

Epoch: 5| Step: 2
Training loss: 0.1285410374403
Validation loss: 1.6587887899850005

Epoch: 5| Step: 3
Training loss: 0.09114135801792145
Validation loss: 1.6426382590365667

Epoch: 5| Step: 4
Training loss: 0.0820276290178299
Validation loss: 1.6255412652928343

Epoch: 5| Step: 5
Training loss: 0.11642066389322281
Validation loss: 1.652044721828994

Epoch: 5| Step: 6
Training loss: 0.11824425309896469
Validation loss: 1.6489711551256077

Epoch: 5| Step: 7
Training loss: 0.13926520943641663
Validation loss: 1.6469499449576102

Epoch: 5| Step: 8
Training loss: 0.12310576438903809
Validation loss: 1.6424954879668452

Epoch: 5| Step: 9
Training loss: 0.18025773763656616
Validation loss: 1.6607466205473869

Epoch: 5| Step: 10
Training loss: 0.13633081316947937
Validation loss: 1.6740226719969062

Epoch: 498| Step: 0
Training loss: 0.11317522823810577
Validation loss: 1.6757264060358847

Epoch: 5| Step: 1
Training loss: 0.21234102547168732
Validation loss: 1.6637305290468278

Epoch: 5| Step: 2
Training loss: 0.10977005958557129
Validation loss: 1.6576602843499952

Epoch: 5| Step: 3
Training loss: 0.1725841462612152
Validation loss: 1.643503140377742

Epoch: 5| Step: 4
Training loss: 0.09444631636142731
Validation loss: 1.6363251286168252

Epoch: 5| Step: 5
Training loss: 0.13973547518253326
Validation loss: 1.6348473243815924

Epoch: 5| Step: 6
Training loss: 0.10744526237249374
Validation loss: 1.6462108165987077

Epoch: 5| Step: 7
Training loss: 0.08229877799749374
Validation loss: 1.6815456908236268

Epoch: 5| Step: 8
Training loss: 0.15283046662807465
Validation loss: 1.6586308005035564

Epoch: 5| Step: 9
Training loss: 0.1255350559949875
Validation loss: 1.6949487886121195

Epoch: 5| Step: 10
Training loss: 0.12170850485563278
Validation loss: 1.6827159107372325

Epoch: 499| Step: 0
Training loss: 0.07585623860359192
Validation loss: 1.6884599295995568

Epoch: 5| Step: 1
Training loss: 0.12294789403676987
Validation loss: 1.6955101297747703

Epoch: 5| Step: 2
Training loss: 0.11007127910852432
Validation loss: 1.7147278042249783

Epoch: 5| Step: 3
Training loss: 0.1852971464395523
Validation loss: 1.7027087109063261

Epoch: 5| Step: 4
Training loss: 0.10755608230829239
Validation loss: 1.710299902064826

Epoch: 5| Step: 5
Training loss: 0.06332392990589142
Validation loss: 1.6933766161241839

Epoch: 5| Step: 6
Training loss: 0.16397640109062195
Validation loss: 1.6854274990738078

Epoch: 5| Step: 7
Training loss: 0.12847675383090973
Validation loss: 1.6680740207754157

Epoch: 5| Step: 8
Training loss: 0.16732646524906158
Validation loss: 1.6309276178318968

Epoch: 5| Step: 9
Training loss: 0.14793500304222107
Validation loss: 1.6477084364942325

Epoch: 5| Step: 10
Training loss: 0.20111183822155
Validation loss: 1.6323536813900035

Epoch: 500| Step: 0
Training loss: 0.10333038866519928
Validation loss: 1.645529955945989

Epoch: 5| Step: 1
Training loss: 0.15045247972011566
Validation loss: 1.61862902743842

Epoch: 5| Step: 2
Training loss: 0.14812710881233215
Validation loss: 1.650531449625569

Epoch: 5| Step: 3
Training loss: 0.08431050926446915
Validation loss: 1.6568174580092072

Epoch: 5| Step: 4
Training loss: 0.17046301066875458
Validation loss: 1.6528351460733721

Epoch: 5| Step: 5
Training loss: 0.09013251215219498
Validation loss: 1.683711128850137

Epoch: 5| Step: 6
Training loss: 0.12839257717132568
Validation loss: 1.6756186382744902

Epoch: 5| Step: 7
Training loss: 0.07262367010116577
Validation loss: 1.6643143789742583

Epoch: 5| Step: 8
Training loss: 0.12480894476175308
Validation loss: 1.6781452112300421

Epoch: 5| Step: 9
Training loss: 0.10643474757671356
Validation loss: 1.653154118086702

Epoch: 5| Step: 10
Training loss: 0.08746565878391266
Validation loss: 1.6727430243645944

Epoch: 501| Step: 0
Training loss: 0.1832490712404251
Validation loss: 1.6637509958718413

Epoch: 5| Step: 1
Training loss: 0.11082147061824799
Validation loss: 1.6910860077027352

Epoch: 5| Step: 2
Training loss: 0.10465376079082489
Validation loss: 1.6437400746089157

Epoch: 5| Step: 3
Training loss: 0.1069873571395874
Validation loss: 1.6508057053371141

Epoch: 5| Step: 4
Training loss: 0.10985472053289413
Validation loss: 1.680648628101554

Epoch: 5| Step: 5
Training loss: 0.06980004161596298
Validation loss: 1.6652364423198085

Epoch: 5| Step: 6
Training loss: 0.08731921017169952
Validation loss: 1.6825400193532307

Epoch: 5| Step: 7
Training loss: 0.1585463583469391
Validation loss: 1.7137089378090316

Epoch: 5| Step: 8
Training loss: 0.13344714045524597
Validation loss: 1.6875047260715115

Epoch: 5| Step: 9
Training loss: 0.1249971017241478
Validation loss: 1.6574864823331115

Epoch: 5| Step: 10
Training loss: 0.08848850429058075
Validation loss: 1.6228704631969493

Epoch: 502| Step: 0
Training loss: 0.10317923873662949
Validation loss: 1.6316687035304245

Epoch: 5| Step: 1
Training loss: 0.11100392043590546
Validation loss: 1.6424331703493673

Epoch: 5| Step: 2
Training loss: 0.12515796720981598
Validation loss: 1.6474335232088644

Epoch: 5| Step: 3
Training loss: 0.18974575400352478
Validation loss: 1.651344117297921

Epoch: 5| Step: 4
Training loss: 0.094366654753685
Validation loss: 1.6529305493959816

Epoch: 5| Step: 5
Training loss: 0.07769908756017685
Validation loss: 1.6715914985185027

Epoch: 5| Step: 6
Training loss: 0.08500849455595016
Validation loss: 1.675037036659897

Epoch: 5| Step: 7
Training loss: 0.1367710530757904
Validation loss: 1.6554736039971794

Epoch: 5| Step: 8
Training loss: 0.1452656090259552
Validation loss: 1.6650192481215282

Epoch: 5| Step: 9
Training loss: 0.06883472204208374
Validation loss: 1.6724304178709626

Epoch: 5| Step: 10
Training loss: 0.11595448106527328
Validation loss: 1.658254583676656

Epoch: 503| Step: 0
Training loss: 0.07887372374534607
Validation loss: 1.6657746017620128

Epoch: 5| Step: 1
Training loss: 0.12610502541065216
Validation loss: 1.7033857145617086

Epoch: 5| Step: 2
Training loss: 0.13166892528533936
Validation loss: 1.6725711784055155

Epoch: 5| Step: 3
Training loss: 0.10414161533117294
Validation loss: 1.6806083251071233

Epoch: 5| Step: 4
Training loss: 0.07830632477998734
Validation loss: 1.6718479401321822

Epoch: 5| Step: 5
Training loss: 0.14609353244304657
Validation loss: 1.6749511713622718

Epoch: 5| Step: 6
Training loss: 0.11540879309177399
Validation loss: 1.662951179729995

Epoch: 5| Step: 7
Training loss: 0.09469033032655716
Validation loss: 1.6539907250353085

Epoch: 5| Step: 8
Training loss: 0.14760854840278625
Validation loss: 1.6730927036654564

Epoch: 5| Step: 9
Training loss: 0.11128009855747223
Validation loss: 1.6802698719886042

Epoch: 5| Step: 10
Training loss: 0.13579323887825012
Validation loss: 1.6795530024395193

Epoch: 504| Step: 0
Training loss: 0.0905972570180893
Validation loss: 1.6743063388332244

Epoch: 5| Step: 1
Training loss: 0.07622615993022919
Validation loss: 1.7013414534189368

Epoch: 5| Step: 2
Training loss: 0.1701706200838089
Validation loss: 1.7007565165078768

Epoch: 5| Step: 3
Training loss: 0.15014079213142395
Validation loss: 1.7094240368053477

Epoch: 5| Step: 4
Training loss: 0.13210701942443848
Validation loss: 1.6924167166474045

Epoch: 5| Step: 5
Training loss: 0.08219791203737259
Validation loss: 1.6669483159178047

Epoch: 5| Step: 6
Training loss: 0.0999472364783287
Validation loss: 1.6585996996971868

Epoch: 5| Step: 7
Training loss: 0.11634720861911774
Validation loss: 1.694619071099066

Epoch: 5| Step: 8
Training loss: 0.1533302366733551
Validation loss: 1.6698658979067238

Epoch: 5| Step: 9
Training loss: 0.1610293686389923
Validation loss: 1.6595827943535262

Epoch: 5| Step: 10
Training loss: 0.07482404261827469
Validation loss: 1.663361700632239

Epoch: 505| Step: 0
Training loss: 0.08278963714838028
Validation loss: 1.6364210997858355

Epoch: 5| Step: 1
Training loss: 0.06715251505374908
Validation loss: 1.678327565552086

Epoch: 5| Step: 2
Training loss: 0.1374506950378418
Validation loss: 1.6364670120259768

Epoch: 5| Step: 3
Training loss: 0.07595251500606537
Validation loss: 1.6643929148233065

Epoch: 5| Step: 4
Training loss: 0.16143622994422913
Validation loss: 1.642224205437527

Epoch: 5| Step: 5
Training loss: 0.0843370109796524
Validation loss: 1.631816619185991

Epoch: 5| Step: 6
Training loss: 0.13531358540058136
Validation loss: 1.6049982655432917

Epoch: 5| Step: 7
Training loss: 0.08939443528652191
Validation loss: 1.6348847189257223

Epoch: 5| Step: 8
Training loss: 0.09769508987665176
Validation loss: 1.6466074541050901

Epoch: 5| Step: 9
Training loss: 0.08468558639287949
Validation loss: 1.6427111369307323

Epoch: 5| Step: 10
Training loss: 0.11732398718595505
Validation loss: 1.6420045232260099

Epoch: 506| Step: 0
Training loss: 0.09460122883319855
Validation loss: 1.6523566592124201

Epoch: 5| Step: 1
Training loss: 0.0839722752571106
Validation loss: 1.678657259992374

Epoch: 5| Step: 2
Training loss: 0.10759900510311127
Validation loss: 1.6629931978000108

Epoch: 5| Step: 3
Training loss: 0.09377872943878174
Validation loss: 1.682793023765728

Epoch: 5| Step: 4
Training loss: 0.1400853395462036
Validation loss: 1.6902411689040482

Epoch: 5| Step: 5
Training loss: 0.17987333238124847
Validation loss: 1.6679276612497145

Epoch: 5| Step: 6
Training loss: 0.09563793241977692
Validation loss: 1.6656971061101524

Epoch: 5| Step: 7
Training loss: 0.10517022758722305
Validation loss: 1.670041463708365

Epoch: 5| Step: 8
Training loss: 0.08079316467046738
Validation loss: 1.669180352200744

Epoch: 5| Step: 9
Training loss: 0.0949709415435791
Validation loss: 1.6715520697255288

Epoch: 5| Step: 10
Training loss: 0.15165752172470093
Validation loss: 1.6656846666848788

Epoch: 507| Step: 0
Training loss: 0.10706639289855957
Validation loss: 1.6561898467361287

Epoch: 5| Step: 1
Training loss: 0.16096891462802887
Validation loss: 1.6254622474793465

Epoch: 5| Step: 2
Training loss: 0.11843831837177277
Validation loss: 1.6350141122776976

Epoch: 5| Step: 3
Training loss: 0.09380361437797546
Validation loss: 1.6453859370241883

Epoch: 5| Step: 4
Training loss: 0.08292828500270844
Validation loss: 1.6476549897142636

Epoch: 5| Step: 5
Training loss: 0.18495242297649384
Validation loss: 1.6556598883803173

Epoch: 5| Step: 6
Training loss: 0.07925514131784439
Validation loss: 1.672700943485383

Epoch: 5| Step: 7
Training loss: 0.06627994775772095
Validation loss: 1.7135195783389512

Epoch: 5| Step: 8
Training loss: 0.08462142944335938
Validation loss: 1.6846870645400016

Epoch: 5| Step: 9
Training loss: 0.07553307712078094
Validation loss: 1.6649805333024712

Epoch: 5| Step: 10
Training loss: 0.1296251267194748
Validation loss: 1.7118619872677712

Epoch: 508| Step: 0
Training loss: 0.05937087535858154
Validation loss: 1.711259029244864

Epoch: 5| Step: 1
Training loss: 0.07451776415109634
Validation loss: 1.67018287797128

Epoch: 5| Step: 2
Training loss: 0.15382711589336395
Validation loss: 1.6298428491879535

Epoch: 5| Step: 3
Training loss: 0.08653683960437775
Validation loss: 1.6474469361766693

Epoch: 5| Step: 4
Training loss: 0.08222483098506927
Validation loss: 1.6391645605846117

Epoch: 5| Step: 5
Training loss: 0.07659288495779037
Validation loss: 1.6381254132075975

Epoch: 5| Step: 6
Training loss: 0.09199925512075424
Validation loss: 1.6217894118319276

Epoch: 5| Step: 7
Training loss: 0.09070707857608795
Validation loss: 1.6549786162632767

Epoch: 5| Step: 8
Training loss: 0.13827788829803467
Validation loss: 1.634636837949035

Epoch: 5| Step: 9
Training loss: 0.13246259093284607
Validation loss: 1.673162034762803

Epoch: 5| Step: 10
Training loss: 0.15460190176963806
Validation loss: 1.6613882395528978

Epoch: 509| Step: 0
Training loss: 0.0994296595454216
Validation loss: 1.6794710748939103

Epoch: 5| Step: 1
Training loss: 0.09893905371427536
Validation loss: 1.7067816744568527

Epoch: 5| Step: 2
Training loss: 0.09544586390256882
Validation loss: 1.6994076492965862

Epoch: 5| Step: 3
Training loss: 0.117825947701931
Validation loss: 1.6958662386863463

Epoch: 5| Step: 4
Training loss: 0.10656575858592987
Validation loss: 1.6959496903163132

Epoch: 5| Step: 5
Training loss: 0.15867425501346588
Validation loss: 1.6979207454189178

Epoch: 5| Step: 6
Training loss: 0.1184883862733841
Validation loss: 1.712495985851493

Epoch: 5| Step: 7
Training loss: 0.10081019252538681
Validation loss: 1.7041706269787205

Epoch: 5| Step: 8
Training loss: 0.1582976132631302
Validation loss: 1.7157955823406097

Epoch: 5| Step: 9
Training loss: 0.15630598366260529
Validation loss: 1.7377306158824632

Epoch: 5| Step: 10
Training loss: 0.1622132807970047
Validation loss: 1.6955217828032791

Epoch: 510| Step: 0
Training loss: 0.11684948205947876
Validation loss: 1.7265122757163098

Epoch: 5| Step: 1
Training loss: 0.09834777563810349
Validation loss: 1.705521902730388

Epoch: 5| Step: 2
Training loss: 0.06977038830518723
Validation loss: 1.6806178349320606

Epoch: 5| Step: 3
Training loss: 0.1700228601694107
Validation loss: 1.7067567635607976

Epoch: 5| Step: 4
Training loss: 0.11298131942749023
Validation loss: 1.7213979139122912

Epoch: 5| Step: 5
Training loss: 0.17170877754688263
Validation loss: 1.6816737190369637

Epoch: 5| Step: 6
Training loss: 0.057819776237010956
Validation loss: 1.67439309371415

Epoch: 5| Step: 7
Training loss: 0.09224388748407364
Validation loss: 1.7010510903532787

Epoch: 5| Step: 8
Training loss: 0.08065888285636902
Validation loss: 1.7000426323183122

Epoch: 5| Step: 9
Training loss: 0.15319406986236572
Validation loss: 1.7297069257305515

Epoch: 5| Step: 10
Training loss: 0.09469395130872726
Validation loss: 1.6901003455602994

Epoch: 511| Step: 0
Training loss: 0.09158855676651001
Validation loss: 1.7086746923385128

Epoch: 5| Step: 1
Training loss: 0.11737561225891113
Validation loss: 1.7000896981967393

Epoch: 5| Step: 2
Training loss: 0.11752916872501373
Validation loss: 1.7153163776602796

Epoch: 5| Step: 3
Training loss: 0.08798263221979141
Validation loss: 1.7146533253372356

Epoch: 5| Step: 4
Training loss: 0.08371338993310928
Validation loss: 1.6850608676992438

Epoch: 5| Step: 5
Training loss: 0.12342564016580582
Validation loss: 1.7192536220755628

Epoch: 5| Step: 6
Training loss: 0.11357803642749786
Validation loss: 1.7154364226966776

Epoch: 5| Step: 7
Training loss: 0.1166423112154007
Validation loss: 1.7092057812598445

Epoch: 5| Step: 8
Training loss: 0.1252100169658661
Validation loss: 1.7158016363779705

Epoch: 5| Step: 9
Training loss: 0.09786756336688995
Validation loss: 1.7152573754710536

Epoch: 5| Step: 10
Training loss: 0.16163241863250732
Validation loss: 1.6923922774612263

Epoch: 512| Step: 0
Training loss: 0.05339469760656357
Validation loss: 1.6993942004378124

Epoch: 5| Step: 1
Training loss: 0.09228815138339996
Validation loss: 1.7013832446067565

Epoch: 5| Step: 2
Training loss: 0.12543494999408722
Validation loss: 1.6765166174980901

Epoch: 5| Step: 3
Training loss: 0.13147015869617462
Validation loss: 1.6853970596867223

Epoch: 5| Step: 4
Training loss: 0.0948895663022995
Validation loss: 1.6636405068059121

Epoch: 5| Step: 5
Training loss: 0.06397511810064316
Validation loss: 1.669192849948842

Epoch: 5| Step: 6
Training loss: 0.09639852494001389
Validation loss: 1.6677103709149104

Epoch: 5| Step: 7
Training loss: 0.1150699108839035
Validation loss: 1.660457327801694

Epoch: 5| Step: 8
Training loss: 0.13275980949401855
Validation loss: 1.6628680524005686

Epoch: 5| Step: 9
Training loss: 0.14144717156887054
Validation loss: 1.6689926373061312

Epoch: 5| Step: 10
Training loss: 0.12973499298095703
Validation loss: 1.6992583390205138

Epoch: 513| Step: 0
Training loss: 0.08171968907117844
Validation loss: 1.6615948330971502

Epoch: 5| Step: 1
Training loss: 0.07011114060878754
Validation loss: 1.6557682329608547

Epoch: 5| Step: 2
Training loss: 0.08877139538526535
Validation loss: 1.7073075091967018

Epoch: 5| Step: 3
Training loss: 0.0630289763212204
Validation loss: 1.6860580969882268

Epoch: 5| Step: 4
Training loss: 0.08012058585882187
Validation loss: 1.6954079610045238

Epoch: 5| Step: 5
Training loss: 0.11078008264303207
Validation loss: 1.687716717361122

Epoch: 5| Step: 6
Training loss: 0.056360553950071335
Validation loss: 1.725039824362724

Epoch: 5| Step: 7
Training loss: 0.10494953393936157
Validation loss: 1.717575091187672

Epoch: 5| Step: 8
Training loss: 0.12909477949142456
Validation loss: 1.726862572854565

Epoch: 5| Step: 9
Training loss: 0.10904937982559204
Validation loss: 1.718404157187349

Epoch: 5| Step: 10
Training loss: 0.07496334612369537
Validation loss: 1.7108195520216418

Epoch: 514| Step: 0
Training loss: 0.09496686607599258
Validation loss: 1.7058490527573453

Epoch: 5| Step: 1
Training loss: 0.10232262313365936
Validation loss: 1.7135146164125012

Epoch: 5| Step: 2
Training loss: 0.1459433138370514
Validation loss: 1.6983035969477829

Epoch: 5| Step: 3
Training loss: 0.07582308351993561
Validation loss: 1.6831317755483812

Epoch: 5| Step: 4
Training loss: 0.12127146869897842
Validation loss: 1.6744285398913967

Epoch: 5| Step: 5
Training loss: 0.1209583654999733
Validation loss: 1.628116165438006

Epoch: 5| Step: 6
Training loss: 0.12857601046562195
Validation loss: 1.6459031720315256

Epoch: 5| Step: 7
Training loss: 0.14744232594966888
Validation loss: 1.6590625727048485

Epoch: 5| Step: 8
Training loss: 0.2606878876686096
Validation loss: 1.664326383221534

Epoch: 5| Step: 9
Training loss: 0.09395521879196167
Validation loss: 1.659372543775907

Epoch: 5| Step: 10
Training loss: 0.09902619570493698
Validation loss: 1.661343401478183

Epoch: 515| Step: 0
Training loss: 0.12011794745922089
Validation loss: 1.6777259867678407

Epoch: 5| Step: 1
Training loss: 0.10676626861095428
Validation loss: 1.679826505722538

Epoch: 5| Step: 2
Training loss: 0.08893650025129318
Validation loss: 1.7145403162125619

Epoch: 5| Step: 3
Training loss: 0.14569130539894104
Validation loss: 1.715238203284561

Epoch: 5| Step: 4
Training loss: 0.1124386340379715
Validation loss: 1.7063611797107163

Epoch: 5| Step: 5
Training loss: 0.09646445512771606
Validation loss: 1.7116481796387704

Epoch: 5| Step: 6
Training loss: 0.08538733422756195
Validation loss: 1.6613460792008268

Epoch: 5| Step: 7
Training loss: 0.09641735255718231
Validation loss: 1.6263107766387284

Epoch: 5| Step: 8
Training loss: 0.06105906888842583
Validation loss: 1.6298642337963145

Epoch: 5| Step: 9
Training loss: 0.14530478417873383
Validation loss: 1.6338083795321885

Epoch: 5| Step: 10
Training loss: 0.05894695222377777
Validation loss: 1.6099468572165376

Epoch: 516| Step: 0
Training loss: 0.13815061748027802
Validation loss: 1.6175053517023723

Epoch: 5| Step: 1
Training loss: 0.07931511104106903
Validation loss: 1.606595309831763

Epoch: 5| Step: 2
Training loss: 0.11971692740917206
Validation loss: 1.6072780944967782

Epoch: 5| Step: 3
Training loss: 0.10008814185857773
Validation loss: 1.6187241910606303

Epoch: 5| Step: 4
Training loss: 0.1451069563627243
Validation loss: 1.6379647677944553

Epoch: 5| Step: 5
Training loss: 0.10979070514440536
Validation loss: 1.6287593328824608

Epoch: 5| Step: 6
Training loss: 0.06476136296987534
Validation loss: 1.6980839313999299

Epoch: 5| Step: 7
Training loss: 0.1671265959739685
Validation loss: 1.7164364130266252

Epoch: 5| Step: 8
Training loss: 0.1259426772594452
Validation loss: 1.725133603618991

Epoch: 5| Step: 9
Training loss: 0.08371608704328537
Validation loss: 1.7057551856963866

Epoch: 5| Step: 10
Training loss: 0.0918266698718071
Validation loss: 1.685918258082482

Epoch: 517| Step: 0
Training loss: 0.09370935708284378
Validation loss: 1.6828024143813758

Epoch: 5| Step: 1
Training loss: 0.093353271484375
Validation loss: 1.6530514019791798

Epoch: 5| Step: 2
Training loss: 0.0859554260969162
Validation loss: 1.629508287675919

Epoch: 5| Step: 3
Training loss: 0.0705602765083313
Validation loss: 1.6619081176737303

Epoch: 5| Step: 4
Training loss: 0.08021523058414459
Validation loss: 1.622210999970795

Epoch: 5| Step: 5
Training loss: 0.09996159374713898
Validation loss: 1.6317101011994064

Epoch: 5| Step: 6
Training loss: 0.12014291435480118
Validation loss: 1.596129164900831

Epoch: 5| Step: 7
Training loss: 0.09621845185756683
Validation loss: 1.6007471033321914

Epoch: 5| Step: 8
Training loss: 0.09495270252227783
Validation loss: 1.619245534302086

Epoch: 5| Step: 9
Training loss: 0.18360507488250732
Validation loss: 1.6027989592603458

Epoch: 5| Step: 10
Training loss: 0.12453791499137878
Validation loss: 1.5971215053271222

Epoch: 518| Step: 0
Training loss: 0.12130334228277206
Validation loss: 1.6263352722250006

Epoch: 5| Step: 1
Training loss: 0.12950339913368225
Validation loss: 1.6383307454406575

Epoch: 5| Step: 2
Training loss: 0.09804408252239227
Validation loss: 1.649582096325454

Epoch: 5| Step: 3
Training loss: 0.10532569885253906
Validation loss: 1.64708875584346

Epoch: 5| Step: 4
Training loss: 0.11630942672491074
Validation loss: 1.6590125919670187

Epoch: 5| Step: 5
Training loss: 0.1014881357550621
Validation loss: 1.6585651225941156

Epoch: 5| Step: 6
Training loss: 0.11034683138132095
Validation loss: 1.7015543035281602

Epoch: 5| Step: 7
Training loss: 0.0830644816160202
Validation loss: 1.666925654616407

Epoch: 5| Step: 8
Training loss: 0.1419578194618225
Validation loss: 1.6701323883507841

Epoch: 5| Step: 9
Training loss: 0.14261272549629211
Validation loss: 1.660380022500151

Epoch: 5| Step: 10
Training loss: 0.15606261789798737
Validation loss: 1.6481322652550154

Epoch: 519| Step: 0
Training loss: 0.11783058941364288
Validation loss: 1.7050238117094962

Epoch: 5| Step: 1
Training loss: 0.1524907946586609
Validation loss: 1.6983370755308418

Epoch: 5| Step: 2
Training loss: 0.11461182683706284
Validation loss: 1.689366961038241

Epoch: 5| Step: 3
Training loss: 0.14826369285583496
Validation loss: 1.691916738787005

Epoch: 5| Step: 4
Training loss: 0.09045274555683136
Validation loss: 1.7093839671022149

Epoch: 5| Step: 5
Training loss: 0.11259974539279938
Validation loss: 1.6661840356806272

Epoch: 5| Step: 6
Training loss: 0.09017542749643326
Validation loss: 1.7084009519187353

Epoch: 5| Step: 7
Training loss: 0.1086103692650795
Validation loss: 1.6722296514818746

Epoch: 5| Step: 8
Training loss: 0.10167715698480606
Validation loss: 1.660959461683868

Epoch: 5| Step: 9
Training loss: 0.07619495689868927
Validation loss: 1.6654383110743698

Epoch: 5| Step: 10
Training loss: 0.06480882316827774
Validation loss: 1.6688663113501765

Epoch: 520| Step: 0
Training loss: 0.07684393227100372
Validation loss: 1.6667803128560383

Epoch: 5| Step: 1
Training loss: 0.07626388221979141
Validation loss: 1.6504218655247842

Epoch: 5| Step: 2
Training loss: 0.09803186357021332
Validation loss: 1.6739908110710882

Epoch: 5| Step: 3
Training loss: 0.18090467154979706
Validation loss: 1.651104074652477

Epoch: 5| Step: 4
Training loss: 0.13923673331737518
Validation loss: 1.629103922074841

Epoch: 5| Step: 5
Training loss: 0.1529839038848877
Validation loss: 1.5818819358784666

Epoch: 5| Step: 6
Training loss: 0.08598891645669937
Validation loss: 1.58212960022752

Epoch: 5| Step: 7
Training loss: 0.12481649219989777
Validation loss: 1.5799177500509447

Epoch: 5| Step: 8
Training loss: 0.16206637024879456
Validation loss: 1.6147614358573832

Epoch: 5| Step: 9
Training loss: 0.14108553528785706
Validation loss: 1.572045039105159

Epoch: 5| Step: 10
Training loss: 0.13611726462841034
Validation loss: 1.5916607674732004

Epoch: 521| Step: 0
Training loss: 0.11199881136417389
Validation loss: 1.6073263909227105

Epoch: 5| Step: 1
Training loss: 0.14658527076244354
Validation loss: 1.6026232819403372

Epoch: 5| Step: 2
Training loss: 0.1308540403842926
Validation loss: 1.6389914943325905

Epoch: 5| Step: 3
Training loss: 0.09284576773643494
Validation loss: 1.6574290490919543

Epoch: 5| Step: 4
Training loss: 0.09542743861675262
Validation loss: 1.5925903781767814

Epoch: 5| Step: 5
Training loss: 0.11648891121149063
Validation loss: 1.659798058130408

Epoch: 5| Step: 6
Training loss: 0.14505860209465027
Validation loss: 1.657140289583514

Epoch: 5| Step: 7
Training loss: 0.08048610389232635
Validation loss: 1.6723957318131641

Epoch: 5| Step: 8
Training loss: 0.08438100665807724
Validation loss: 1.6765980464155956

Epoch: 5| Step: 9
Training loss: 0.15313999354839325
Validation loss: 1.7130840798859954

Epoch: 5| Step: 10
Training loss: 0.17529213428497314
Validation loss: 1.6782142423814344

Epoch: 522| Step: 0
Training loss: 0.12331916391849518
Validation loss: 1.6978236090752385

Epoch: 5| Step: 1
Training loss: 0.12376414239406586
Validation loss: 1.685610273832916

Epoch: 5| Step: 2
Training loss: 0.12569701671600342
Validation loss: 1.6768617283913396

Epoch: 5| Step: 3
Training loss: 0.1887960284948349
Validation loss: 1.7069322268168132

Epoch: 5| Step: 4
Training loss: 0.1389254778623581
Validation loss: 1.72996780180162

Epoch: 5| Step: 5
Training loss: 0.14058616757392883
Validation loss: 1.6897882825584822

Epoch: 5| Step: 6
Training loss: 0.1438342183828354
Validation loss: 1.7199361901129446

Epoch: 5| Step: 7
Training loss: 0.1388310045003891
Validation loss: 1.6916469502192673

Epoch: 5| Step: 8
Training loss: 0.0743044912815094
Validation loss: 1.6950846384930354

Epoch: 5| Step: 9
Training loss: 0.1483352780342102
Validation loss: 1.6714016276021157

Epoch: 5| Step: 10
Training loss: 0.08546239137649536
Validation loss: 1.685600640953228

Epoch: 523| Step: 0
Training loss: 0.10506526380777359
Validation loss: 1.7055427156468874

Epoch: 5| Step: 1
Training loss: 0.09302758425474167
Validation loss: 1.6674602185526202

Epoch: 5| Step: 2
Training loss: 0.08866214752197266
Validation loss: 1.6592176409177883

Epoch: 5| Step: 3
Training loss: 0.09946165978908539
Validation loss: 1.6657466606427265

Epoch: 5| Step: 4
Training loss: 0.09283319860696793
Validation loss: 1.6466414390071746

Epoch: 5| Step: 5
Training loss: 0.08563891053199768
Validation loss: 1.6522316817314393

Epoch: 5| Step: 6
Training loss: 0.1814604550600052
Validation loss: 1.6383537079698296

Epoch: 5| Step: 7
Training loss: 0.08322657644748688
Validation loss: 1.6384390451574837

Epoch: 5| Step: 8
Training loss: 0.15638887882232666
Validation loss: 1.6533133445247528

Epoch: 5| Step: 9
Training loss: 0.08046737313270569
Validation loss: 1.6370940874981623

Epoch: 5| Step: 10
Training loss: 0.0868270993232727
Validation loss: 1.6233678363984632

Epoch: 524| Step: 0
Training loss: 0.12379445135593414
Validation loss: 1.6128730594470937

Epoch: 5| Step: 1
Training loss: 0.11036832630634308
Validation loss: 1.6209726025981288

Epoch: 5| Step: 2
Training loss: 0.10832538455724716
Validation loss: 1.6210840709747807

Epoch: 5| Step: 3
Training loss: 0.10823949426412582
Validation loss: 1.6295955975850422

Epoch: 5| Step: 4
Training loss: 0.12316226959228516
Validation loss: 1.619634127104154

Epoch: 5| Step: 5
Training loss: 0.0816752165555954
Validation loss: 1.6346508546542096

Epoch: 5| Step: 6
Training loss: 0.14249606430530548
Validation loss: 1.609984791407021

Epoch: 5| Step: 7
Training loss: 0.06432903558015823
Validation loss: 1.6295889257102885

Epoch: 5| Step: 8
Training loss: 0.08888556808233261
Validation loss: 1.6242511259612216

Epoch: 5| Step: 9
Training loss: 0.1404227316379547
Validation loss: 1.6661167965140393

Epoch: 5| Step: 10
Training loss: 0.13086551427841187
Validation loss: 1.6708423065882858

Epoch: 525| Step: 0
Training loss: 0.11761293560266495
Validation loss: 1.661819584908024

Epoch: 5| Step: 1
Training loss: 0.06229044124484062
Validation loss: 1.6778633158694032

Epoch: 5| Step: 2
Training loss: 0.15116631984710693
Validation loss: 1.6973253257812992

Epoch: 5| Step: 3
Training loss: 0.0767354741692543
Validation loss: 1.667961392351376

Epoch: 5| Step: 4
Training loss: 0.08129718154668808
Validation loss: 1.6739429107276342

Epoch: 5| Step: 5
Training loss: 0.11725795269012451
Validation loss: 1.6620222278820571

Epoch: 5| Step: 6
Training loss: 0.11192003637552261
Validation loss: 1.6693292023033224

Epoch: 5| Step: 7
Training loss: 0.09728051722049713
Validation loss: 1.6538757918983378

Epoch: 5| Step: 8
Training loss: 0.06808330118656158
Validation loss: 1.6190715323212326

Epoch: 5| Step: 9
Training loss: 0.16158388555049896
Validation loss: 1.6509355101534116

Epoch: 5| Step: 10
Training loss: 0.10653273016214371
Validation loss: 1.6306823940687283

Epoch: 526| Step: 0
Training loss: 0.12501472234725952
Validation loss: 1.6544043017971901

Epoch: 5| Step: 1
Training loss: 0.11457552760839462
Validation loss: 1.599445519908782

Epoch: 5| Step: 2
Training loss: 0.10195355117321014
Validation loss: 1.6028784090472805

Epoch: 5| Step: 3
Training loss: 0.12680122256278992
Validation loss: 1.616441640802609

Epoch: 5| Step: 4
Training loss: 0.11206261813640594
Validation loss: 1.6290149099083358

Epoch: 5| Step: 5
Training loss: 0.16070882976055145
Validation loss: 1.586749722880702

Epoch: 5| Step: 6
Training loss: 0.11196156591176987
Validation loss: 1.6314455680949713

Epoch: 5| Step: 7
Training loss: 0.08682398498058319
Validation loss: 1.6103484656221123

Epoch: 5| Step: 8
Training loss: 0.13824009895324707
Validation loss: 1.634776578154615

Epoch: 5| Step: 9
Training loss: 0.11296826601028442
Validation loss: 1.6611951820312008

Epoch: 5| Step: 10
Training loss: 0.11174601316452026
Validation loss: 1.6277821961269583

Epoch: 527| Step: 0
Training loss: 0.10663183778524399
Validation loss: 1.6228027702659689

Epoch: 5| Step: 1
Training loss: 0.07871836423873901
Validation loss: 1.594383567892095

Epoch: 5| Step: 2
Training loss: 0.13763828575611115
Validation loss: 1.6116608394089567

Epoch: 5| Step: 3
Training loss: 0.0802801325917244
Validation loss: 1.576106466272826

Epoch: 5| Step: 4
Training loss: 0.18684004247188568
Validation loss: 1.5828335721005675

Epoch: 5| Step: 5
Training loss: 0.10567303001880646
Validation loss: 1.5818418302843649

Epoch: 5| Step: 6
Training loss: 0.12015750259160995
Validation loss: 1.5672401382077126

Epoch: 5| Step: 7
Training loss: 0.1229277104139328
Validation loss: 1.5907634060869935

Epoch: 5| Step: 8
Training loss: 0.0797533243894577
Validation loss: 1.6134346121100969

Epoch: 5| Step: 9
Training loss: 0.08037112653255463
Validation loss: 1.5724373837952972

Epoch: 5| Step: 10
Training loss: 0.10871477425098419
Validation loss: 1.5982489637149278

Epoch: 528| Step: 0
Training loss: 0.12323224544525146
Validation loss: 1.6076847378925612

Epoch: 5| Step: 1
Training loss: 0.0907820388674736
Validation loss: 1.6106395849617579

Epoch: 5| Step: 2
Training loss: 0.1191035732626915
Validation loss: 1.625971935128653

Epoch: 5| Step: 3
Training loss: 0.11780134588479996
Validation loss: 1.6132738564604072

Epoch: 5| Step: 4
Training loss: 0.10322773456573486
Validation loss: 1.6063553030772875

Epoch: 5| Step: 5
Training loss: 0.07470232993364334
Validation loss: 1.6126810286634712

Epoch: 5| Step: 6
Training loss: 0.1272076815366745
Validation loss: 1.6327728782930682

Epoch: 5| Step: 7
Training loss: 0.07124648243188858
Validation loss: 1.6232526007518973

Epoch: 5| Step: 8
Training loss: 0.09328572452068329
Validation loss: 1.6128554010903964

Epoch: 5| Step: 9
Training loss: 0.18356731534004211
Validation loss: 1.6165834883207917

Epoch: 5| Step: 10
Training loss: 0.1305755376815796
Validation loss: 1.625795784816947

Epoch: 529| Step: 0
Training loss: 0.13839367032051086
Validation loss: 1.6040816204522246

Epoch: 5| Step: 1
Training loss: 0.10997774451971054
Validation loss: 1.6296133200327556

Epoch: 5| Step: 2
Training loss: 0.07783543318510056
Validation loss: 1.5986051277447773

Epoch: 5| Step: 3
Training loss: 0.13617636263370514
Validation loss: 1.6532560471565492

Epoch: 5| Step: 4
Training loss: 0.06905736029148102
Validation loss: 1.6609904612264326

Epoch: 5| Step: 5
Training loss: 0.15236884355545044
Validation loss: 1.6932569319202053

Epoch: 5| Step: 6
Training loss: 0.14745047688484192
Validation loss: 1.7042947789674163

Epoch: 5| Step: 7
Training loss: 0.09579431265592575
Validation loss: 1.707187214205342

Epoch: 5| Step: 8
Training loss: 0.0883684754371643
Validation loss: 1.6641077290299118

Epoch: 5| Step: 9
Training loss: 0.09264390915632248
Validation loss: 1.6399028262784403

Epoch: 5| Step: 10
Training loss: 0.0478803776204586
Validation loss: 1.6265864205616776

Epoch: 530| Step: 0
Training loss: 0.0900183916091919
Validation loss: 1.6176930153241722

Epoch: 5| Step: 1
Training loss: 0.09769876301288605
Validation loss: 1.592307254832278

Epoch: 5| Step: 2
Training loss: 0.12531262636184692
Validation loss: 1.5942142189189952

Epoch: 5| Step: 3
Training loss: 0.12745437026023865
Validation loss: 1.6113970395057433

Epoch: 5| Step: 4
Training loss: 0.15608614683151245
Validation loss: 1.6041369175398221

Epoch: 5| Step: 5
Training loss: 0.1300383061170578
Validation loss: 1.619274280404532

Epoch: 5| Step: 6
Training loss: 0.08179140090942383
Validation loss: 1.6111352828241163

Epoch: 5| Step: 7
Training loss: 0.09282533824443817
Validation loss: 1.617653832640699

Epoch: 5| Step: 8
Training loss: 0.07777272164821625
Validation loss: 1.5810814403718518

Epoch: 5| Step: 9
Training loss: 0.08543021976947784
Validation loss: 1.6465908301773893

Epoch: 5| Step: 10
Training loss: 0.13882283866405487
Validation loss: 1.6294369107933455

Epoch: 531| Step: 0
Training loss: 0.06562034785747528
Validation loss: 1.6345304186626146

Epoch: 5| Step: 1
Training loss: 0.0863308310508728
Validation loss: 1.6452030058830016

Epoch: 5| Step: 2
Training loss: 0.09240993112325668
Validation loss: 1.6429300961955902

Epoch: 5| Step: 3
Training loss: 0.152061328291893
Validation loss: 1.667524665914556

Epoch: 5| Step: 4
Training loss: 0.10626959800720215
Validation loss: 1.689494647646463

Epoch: 5| Step: 5
Training loss: 0.08355318754911423
Validation loss: 1.652704240173422

Epoch: 5| Step: 6
Training loss: 0.12792323529720306
Validation loss: 1.654076563414707

Epoch: 5| Step: 7
Training loss: 0.14765048027038574
Validation loss: 1.627360434942348

Epoch: 5| Step: 8
Training loss: 0.1196230873465538
Validation loss: 1.6336060506041332

Epoch: 5| Step: 9
Training loss: 0.09500458836555481
Validation loss: 1.6094212314134002

Epoch: 5| Step: 10
Training loss: 0.07490303367376328
Validation loss: 1.5756209217092043

Epoch: 532| Step: 0
Training loss: 0.10967080295085907
Validation loss: 1.6514773330380839

Epoch: 5| Step: 1
Training loss: 0.1092560663819313
Validation loss: 1.6268836772570046

Epoch: 5| Step: 2
Training loss: 0.07546491920948029
Validation loss: 1.6404924181199843

Epoch: 5| Step: 3
Training loss: 0.11446277797222137
Validation loss: 1.646366548794572

Epoch: 5| Step: 4
Training loss: 0.10086655616760254
Validation loss: 1.6605916805164789

Epoch: 5| Step: 5
Training loss: 0.0802277997136116
Validation loss: 1.6395382663255096

Epoch: 5| Step: 6
Training loss: 0.10343316942453384
Validation loss: 1.6459870556349396

Epoch: 5| Step: 7
Training loss: 0.10087491571903229
Validation loss: 1.6613238062909854

Epoch: 5| Step: 8
Training loss: 0.09847858548164368
Validation loss: 1.642506904499505

Epoch: 5| Step: 9
Training loss: 0.10151199251413345
Validation loss: 1.6296215070191251

Epoch: 5| Step: 10
Training loss: 0.06650999933481216
Validation loss: 1.6441524951688704

Epoch: 533| Step: 0
Training loss: 0.10805539786815643
Validation loss: 1.6488787256261355

Epoch: 5| Step: 1
Training loss: 0.08960600942373276
Validation loss: 1.6052618219006447

Epoch: 5| Step: 2
Training loss: 0.0900576189160347
Validation loss: 1.6076089425753521

Epoch: 5| Step: 3
Training loss: 0.071292445063591
Validation loss: 1.6183644046065628

Epoch: 5| Step: 4
Training loss: 0.07165779173374176
Validation loss: 1.5945426610208326

Epoch: 5| Step: 5
Training loss: 0.0860355868935585
Validation loss: 1.6080548019819363

Epoch: 5| Step: 6
Training loss: 0.07040444016456604
Validation loss: 1.6214971683358634

Epoch: 5| Step: 7
Training loss: 0.1388251781463623
Validation loss: 1.6051573189355994

Epoch: 5| Step: 8
Training loss: 0.11951538175344467
Validation loss: 1.591393623300778

Epoch: 5| Step: 9
Training loss: 0.12635651230812073
Validation loss: 1.608249665588461

Epoch: 5| Step: 10
Training loss: 0.15026116371154785
Validation loss: 1.6305025239144602

Epoch: 534| Step: 0
Training loss: 0.10374414920806885
Validation loss: 1.651401823566806

Epoch: 5| Step: 1
Training loss: 0.13378199934959412
Validation loss: 1.6669449370394471

Epoch: 5| Step: 2
Training loss: 0.1164378896355629
Validation loss: 1.7002130285386117

Epoch: 5| Step: 3
Training loss: 0.07882575690746307
Validation loss: 1.689554964342425

Epoch: 5| Step: 4
Training loss: 0.08901350200176239
Validation loss: 1.706245316613105

Epoch: 5| Step: 5
Training loss: 0.09050643444061279
Validation loss: 1.7076335196853967

Epoch: 5| Step: 6
Training loss: 0.10996220260858536
Validation loss: 1.7062498664343229

Epoch: 5| Step: 7
Training loss: 0.14364774525165558
Validation loss: 1.6884253255782589

Epoch: 5| Step: 8
Training loss: 0.09653621912002563
Validation loss: 1.6864097746469642

Epoch: 5| Step: 9
Training loss: 0.1200047954916954
Validation loss: 1.6929466711577548

Epoch: 5| Step: 10
Training loss: 0.10481572151184082
Validation loss: 1.6923677844385947

Epoch: 535| Step: 0
Training loss: 0.1335195004940033
Validation loss: 1.662940365011974

Epoch: 5| Step: 1
Training loss: 0.23157481849193573
Validation loss: 1.6585472835007535

Epoch: 5| Step: 2
Training loss: 0.07473780959844589
Validation loss: 1.663205623626709

Epoch: 5| Step: 3
Training loss: 0.10515055805444717
Validation loss: 1.6710946098450692

Epoch: 5| Step: 4
Training loss: 0.06341539323329926
Validation loss: 1.6583743146670762

Epoch: 5| Step: 5
Training loss: 0.13129960000514984
Validation loss: 1.6392325970434374

Epoch: 5| Step: 6
Training loss: 0.06197844818234444
Validation loss: 1.6697659812947756

Epoch: 5| Step: 7
Training loss: 0.13442973792552948
Validation loss: 1.628665893308578

Epoch: 5| Step: 8
Training loss: 0.16135211288928986
Validation loss: 1.6374758405070151

Epoch: 5| Step: 9
Training loss: 0.09458130598068237
Validation loss: 1.6490900413964384

Epoch: 5| Step: 10
Training loss: 0.10533701628446579
Validation loss: 1.6414386495467155

Epoch: 536| Step: 0
Training loss: 0.07478354871273041
Validation loss: 1.6293505673767419

Epoch: 5| Step: 1
Training loss: 0.07130670547485352
Validation loss: 1.5894974688048005

Epoch: 5| Step: 2
Training loss: 0.0507625937461853
Validation loss: 1.616192724115105

Epoch: 5| Step: 3
Training loss: 0.07117204368114471
Validation loss: 1.5962482395992483

Epoch: 5| Step: 4
Training loss: 0.12721695005893707
Validation loss: 1.6157287410510484

Epoch: 5| Step: 5
Training loss: 0.13446439802646637
Validation loss: 1.6159316493618874

Epoch: 5| Step: 6
Training loss: 0.0806988924741745
Validation loss: 1.6213252159856981

Epoch: 5| Step: 7
Training loss: 0.08838535845279694
Validation loss: 1.590656562518048

Epoch: 5| Step: 8
Training loss: 0.1119135394692421
Validation loss: 1.619643444656044

Epoch: 5| Step: 9
Training loss: 0.08107873797416687
Validation loss: 1.6542592638282365

Epoch: 5| Step: 10
Training loss: 0.12735429406166077
Validation loss: 1.6884357628001962

Epoch: 537| Step: 0
Training loss: 0.10640823841094971
Validation loss: 1.6823292957839144

Epoch: 5| Step: 1
Training loss: 0.09298821538686752
Validation loss: 1.666811050907258

Epoch: 5| Step: 2
Training loss: 0.09553828835487366
Validation loss: 1.6551939902767059

Epoch: 5| Step: 3
Training loss: 0.08407558500766754
Validation loss: 1.6264009680799258

Epoch: 5| Step: 4
Training loss: 0.08444562554359436
Validation loss: 1.623100862708143

Epoch: 5| Step: 5
Training loss: 0.1443418264389038
Validation loss: 1.6309794572091871

Epoch: 5| Step: 6
Training loss: 0.13680079579353333
Validation loss: 1.6700702764654671

Epoch: 5| Step: 7
Training loss: 0.11370415985584259
Validation loss: 1.6400110106314383

Epoch: 5| Step: 8
Training loss: 0.15720976889133453
Validation loss: 1.633548476362741

Epoch: 5| Step: 9
Training loss: 0.1476437747478485
Validation loss: 1.6570454323163597

Epoch: 5| Step: 10
Training loss: 0.12122945487499237
Validation loss: 1.620386726112776

Epoch: 538| Step: 0
Training loss: 0.14842383563518524
Validation loss: 1.6140747567017872

Epoch: 5| Step: 1
Training loss: 0.07013458013534546
Validation loss: 1.628706673140167

Epoch: 5| Step: 2
Training loss: 0.11745333671569824
Validation loss: 1.5981858199642551

Epoch: 5| Step: 3
Training loss: 0.09320462495088577
Validation loss: 1.6174716013734058

Epoch: 5| Step: 4
Training loss: 0.08828265219926834
Validation loss: 1.5682015008823846

Epoch: 5| Step: 5
Training loss: 0.08519729226827621
Validation loss: 1.6115586962751163

Epoch: 5| Step: 6
Training loss: 0.13430356979370117
Validation loss: 1.6327053975033503

Epoch: 5| Step: 7
Training loss: 0.07745162397623062
Validation loss: 1.6223809603721864

Epoch: 5| Step: 8
Training loss: 0.11580689251422882
Validation loss: 1.6397985053318802

Epoch: 5| Step: 9
Training loss: 0.1878911703824997
Validation loss: 1.6215997998432448

Epoch: 5| Step: 10
Training loss: 0.12722148001194
Validation loss: 1.6261735065009004

Epoch: 539| Step: 0
Training loss: 0.08231095224618912
Validation loss: 1.6462409906489874

Epoch: 5| Step: 1
Training loss: 0.11113127321004868
Validation loss: 1.6395669726915256

Epoch: 5| Step: 2
Training loss: 0.1989659070968628
Validation loss: 1.685508075580802

Epoch: 5| Step: 3
Training loss: 0.11783663183450699
Validation loss: 1.6965166894338464

Epoch: 5| Step: 4
Training loss: 0.05915694683790207
Validation loss: 1.71927511179319

Epoch: 5| Step: 5
Training loss: 0.10314188152551651
Validation loss: 1.6922170154510006

Epoch: 5| Step: 6
Training loss: 0.07989861071109772
Validation loss: 1.6812787248242287

Epoch: 5| Step: 7
Training loss: 0.04822578281164169
Validation loss: 1.7026415614671604

Epoch: 5| Step: 8
Training loss: 0.09352218359708786
Validation loss: 1.6800878188943351

Epoch: 5| Step: 9
Training loss: 0.07574351131916046
Validation loss: 1.6605587825980237

Epoch: 5| Step: 10
Training loss: 0.09585148096084595
Validation loss: 1.6660730608047978

Epoch: 540| Step: 0
Training loss: 0.08445495367050171
Validation loss: 1.6694968772190872

Epoch: 5| Step: 1
Training loss: 0.1279606819152832
Validation loss: 1.6368173437733804

Epoch: 5| Step: 2
Training loss: 0.10078072547912598
Validation loss: 1.6298428325242893

Epoch: 5| Step: 3
Training loss: 0.11829707771539688
Validation loss: 1.6201201895231843

Epoch: 5| Step: 4
Training loss: 0.09863634407520294
Validation loss: 1.6339468597083964

Epoch: 5| Step: 5
Training loss: 0.07437455654144287
Validation loss: 1.6210471353223246

Epoch: 5| Step: 6
Training loss: 0.07662928849458694
Validation loss: 1.622130649064177

Epoch: 5| Step: 7
Training loss: 0.06148415803909302
Validation loss: 1.6647186247251367

Epoch: 5| Step: 8
Training loss: 0.0979684442281723
Validation loss: 1.6743064554788734

Epoch: 5| Step: 9
Training loss: 0.12829692661762238
Validation loss: 1.6729472798685874

Epoch: 5| Step: 10
Training loss: 0.09801556915044785
Validation loss: 1.6749113093140304

Epoch: 541| Step: 0
Training loss: 0.0850299745798111
Validation loss: 1.6604975115868352

Epoch: 5| Step: 1
Training loss: 0.09225662052631378
Validation loss: 1.6314737809601652

Epoch: 5| Step: 2
Training loss: 0.09420634806156158
Validation loss: 1.6218495445866739

Epoch: 5| Step: 3
Training loss: 0.06904041022062302
Validation loss: 1.6422954297834826

Epoch: 5| Step: 4
Training loss: 0.07381891459226608
Validation loss: 1.6145378620393815

Epoch: 5| Step: 5
Training loss: 0.09804525226354599
Validation loss: 1.6101846271945583

Epoch: 5| Step: 6
Training loss: 0.0775609239935875
Validation loss: 1.6127074098074308

Epoch: 5| Step: 7
Training loss: 0.09158629179000854
Validation loss: 1.6239507352152178

Epoch: 5| Step: 8
Training loss: 0.07121334224939346
Validation loss: 1.597875586120031

Epoch: 5| Step: 9
Training loss: 0.14133813977241516
Validation loss: 1.6292144367771764

Epoch: 5| Step: 10
Training loss: 0.05480162054300308
Validation loss: 1.6237322143329087

Epoch: 542| Step: 0
Training loss: 0.06659511476755142
Validation loss: 1.6247500809290076

Epoch: 5| Step: 1
Training loss: 0.057563502341508865
Validation loss: 1.6360132771153604

Epoch: 5| Step: 2
Training loss: 0.10186021029949188
Validation loss: 1.636228447639814

Epoch: 5| Step: 3
Training loss: 0.12102494388818741
Validation loss: 1.630773469965945

Epoch: 5| Step: 4
Training loss: 0.08116932213306427
Validation loss: 1.633545135938993

Epoch: 5| Step: 5
Training loss: 0.10945737361907959
Validation loss: 1.6392707183796873

Epoch: 5| Step: 6
Training loss: 0.07420837879180908
Validation loss: 1.6405215481276154

Epoch: 5| Step: 7
Training loss: 0.07170463353395462
Validation loss: 1.6803444239401049

Epoch: 5| Step: 8
Training loss: 0.08780752122402191
Validation loss: 1.6863999930761193

Epoch: 5| Step: 9
Training loss: 0.14577044546604156
Validation loss: 1.6373582219564786

Epoch: 5| Step: 10
Training loss: 0.12975330650806427
Validation loss: 1.6685590026199177

Epoch: 543| Step: 0
Training loss: 0.16855090856552124
Validation loss: 1.6192370217333558

Epoch: 5| Step: 1
Training loss: 0.09033366292715073
Validation loss: 1.5945782430710331

Epoch: 5| Step: 2
Training loss: 0.10182802379131317
Validation loss: 1.617909441712082

Epoch: 5| Step: 3
Training loss: 0.08076395094394684
Validation loss: 1.6096030999255437

Epoch: 5| Step: 4
Training loss: 0.0862891897559166
Validation loss: 1.5854822397232056

Epoch: 5| Step: 5
Training loss: 0.07461631298065186
Validation loss: 1.60283798556174

Epoch: 5| Step: 6
Training loss: 0.08144189417362213
Validation loss: 1.5814183527423489

Epoch: 5| Step: 7
Training loss: 0.059357721358537674
Validation loss: 1.5786775337752474

Epoch: 5| Step: 8
Training loss: 0.09241265803575516
Validation loss: 1.572202592767695

Epoch: 5| Step: 9
Training loss: 0.08895878493785858
Validation loss: 1.6147475870706702

Epoch: 5| Step: 10
Training loss: 0.07082588970661163
Validation loss: 1.6146161684425928

Epoch: 544| Step: 0
Training loss: 0.08158227056264877
Validation loss: 1.6020691228169266

Epoch: 5| Step: 1
Training loss: 0.08935990184545517
Validation loss: 1.6190501630947154

Epoch: 5| Step: 2
Training loss: 0.10380309820175171
Validation loss: 1.614597838412049

Epoch: 5| Step: 3
Training loss: 0.08046065270900726
Validation loss: 1.6164535245587748

Epoch: 5| Step: 4
Training loss: 0.10122184455394745
Validation loss: 1.6471456455928024

Epoch: 5| Step: 5
Training loss: 0.0856100469827652
Validation loss: 1.6427038472185853

Epoch: 5| Step: 6
Training loss: 0.0667334571480751
Validation loss: 1.6347554114557081

Epoch: 5| Step: 7
Training loss: 0.08232725411653519
Validation loss: 1.6561855321289392

Epoch: 5| Step: 8
Training loss: 0.12676391005516052
Validation loss: 1.6460777533951627

Epoch: 5| Step: 9
Training loss: 0.08789049834012985
Validation loss: 1.6496981311869878

Epoch: 5| Step: 10
Training loss: 0.08070774376392365
Validation loss: 1.6327312851464877

Epoch: 545| Step: 0
Training loss: 0.07259009778499603
Validation loss: 1.624701000029041

Epoch: 5| Step: 1
Training loss: 0.08598989993333817
Validation loss: 1.6206177370522612

Epoch: 5| Step: 2
Training loss: 0.12009105831384659
Validation loss: 1.6070517557923512

Epoch: 5| Step: 3
Training loss: 0.1147904247045517
Validation loss: 1.619808631558572

Epoch: 5| Step: 4
Training loss: 0.0882955938577652
Validation loss: 1.6268724190291537

Epoch: 5| Step: 5
Training loss: 0.08564149588346481
Validation loss: 1.6104897658030193

Epoch: 5| Step: 6
Training loss: 0.0798112154006958
Validation loss: 1.6239400166337208

Epoch: 5| Step: 7
Training loss: 0.07166190445423126
Validation loss: 1.6415587855923561

Epoch: 5| Step: 8
Training loss: 0.0730627179145813
Validation loss: 1.6683063712171329

Epoch: 5| Step: 9
Training loss: 0.06780693680047989
Validation loss: 1.698607519108762

Epoch: 5| Step: 10
Training loss: 0.08156637847423553
Validation loss: 1.621580930166347

Epoch: 546| Step: 0
Training loss: 0.08319790661334991
Validation loss: 1.6984132925669353

Epoch: 5| Step: 1
Training loss: 0.09600739926099777
Validation loss: 1.6499490443096365

Epoch: 5| Step: 2
Training loss: 0.056017059832811356
Validation loss: 1.6479987944326093

Epoch: 5| Step: 3
Training loss: 0.09220929443836212
Validation loss: 1.6534363492842643

Epoch: 5| Step: 4
Training loss: 0.09115993976593018
Validation loss: 1.6387060585842337

Epoch: 5| Step: 5
Training loss: 0.08869422972202301
Validation loss: 1.5965328293461953

Epoch: 5| Step: 6
Training loss: 0.09949233382940292
Validation loss: 1.59707393441149

Epoch: 5| Step: 7
Training loss: 0.09555317461490631
Validation loss: 1.575432135212806

Epoch: 5| Step: 8
Training loss: 0.10010592639446259
Validation loss: 1.5856629956153132

Epoch: 5| Step: 9
Training loss: 0.140068918466568
Validation loss: 1.5932749163719915

Epoch: 5| Step: 10
Training loss: 0.12922564148902893
Validation loss: 1.590642524021928

Epoch: 547| Step: 0
Training loss: 0.13043174147605896
Validation loss: 1.5980568175674768

Epoch: 5| Step: 1
Training loss: 0.11330469697713852
Validation loss: 1.6125243735569779

Epoch: 5| Step: 2
Training loss: 0.10026945918798447
Validation loss: 1.6176041736397693

Epoch: 5| Step: 3
Training loss: 0.1171514168381691
Validation loss: 1.6038714032019339

Epoch: 5| Step: 4
Training loss: 0.05579141527414322
Validation loss: 1.6345636690816572

Epoch: 5| Step: 5
Training loss: 0.13468050956726074
Validation loss: 1.6073616320087063

Epoch: 5| Step: 6
Training loss: 0.13290837407112122
Validation loss: 1.6332742552603445

Epoch: 5| Step: 7
Training loss: 0.08553837239742279
Validation loss: 1.6223784659498481

Epoch: 5| Step: 8
Training loss: 0.08154939115047455
Validation loss: 1.6277951835304179

Epoch: 5| Step: 9
Training loss: 0.16188010573387146
Validation loss: 1.5921063115519862

Epoch: 5| Step: 10
Training loss: 0.07607728987932205
Validation loss: 1.6104007382546701

Epoch: 548| Step: 0
Training loss: 0.09049184620380402
Validation loss: 1.5974984079278924

Epoch: 5| Step: 1
Training loss: 0.11793122440576553
Validation loss: 1.564180035744944

Epoch: 5| Step: 2
Training loss: 0.08982051908969879
Validation loss: 1.5919268900348293

Epoch: 5| Step: 3
Training loss: 0.08936427533626556
Validation loss: 1.6147691254974694

Epoch: 5| Step: 4
Training loss: 0.07808665931224823
Validation loss: 1.6120599149375834

Epoch: 5| Step: 5
Training loss: 0.08457525074481964
Validation loss: 1.6482512835533387

Epoch: 5| Step: 6
Training loss: 0.13291357457637787
Validation loss: 1.6566513853688394

Epoch: 5| Step: 7
Training loss: 0.08255726099014282
Validation loss: 1.6728109262322868

Epoch: 5| Step: 8
Training loss: 0.07910613715648651
Validation loss: 1.6658224610872165

Epoch: 5| Step: 9
Training loss: 0.12639710307121277
Validation loss: 1.666373610496521

Epoch: 5| Step: 10
Training loss: 0.08454406261444092
Validation loss: 1.6835044481421029

Epoch: 549| Step: 0
Training loss: 0.15177325904369354
Validation loss: 1.6563235662316764

Epoch: 5| Step: 1
Training loss: 0.07128476351499557
Validation loss: 1.646833877409658

Epoch: 5| Step: 2
Training loss: 0.05567566305398941
Validation loss: 1.644989118781141

Epoch: 5| Step: 3
Training loss: 0.07385177910327911
Validation loss: 1.6059805834165184

Epoch: 5| Step: 4
Training loss: 0.10325440019369125
Validation loss: 1.6395370011688561

Epoch: 5| Step: 5
Training loss: 0.08128001540899277
Validation loss: 1.623104186468227

Epoch: 5| Step: 6
Training loss: 0.06577883660793304
Validation loss: 1.6450741278227938

Epoch: 5| Step: 7
Training loss: 0.12047312408685684
Validation loss: 1.630659519985158

Epoch: 5| Step: 8
Training loss: 0.07785823196172714
Validation loss: 1.6395784565197524

Epoch: 5| Step: 9
Training loss: 0.08561570197343826
Validation loss: 1.6189006361910092

Epoch: 5| Step: 10
Training loss: 0.09775352478027344
Validation loss: 1.6223130418408302

Epoch: 550| Step: 0
Training loss: 0.08772877603769302
Validation loss: 1.624771116882242

Epoch: 5| Step: 1
Training loss: 0.08339617401361465
Validation loss: 1.6091543807778308

Epoch: 5| Step: 2
Training loss: 0.0586872324347496
Validation loss: 1.6007532637606385

Epoch: 5| Step: 3
Training loss: 0.06347876042127609
Validation loss: 1.609432174313453

Epoch: 5| Step: 4
Training loss: 0.07950705289840698
Validation loss: 1.5856174679212673

Epoch: 5| Step: 5
Training loss: 0.07125993072986603
Validation loss: 1.619981800356219

Epoch: 5| Step: 6
Training loss: 0.11431829631328583
Validation loss: 1.6364164044780116

Epoch: 5| Step: 7
Training loss: 0.09702236950397491
Validation loss: 1.6138443229019002

Epoch: 5| Step: 8
Training loss: 0.1377583146095276
Validation loss: 1.637649296432413

Epoch: 5| Step: 9
Training loss: 0.14963103830814362
Validation loss: 1.6208187303235453

Epoch: 5| Step: 10
Training loss: 0.0680265724658966
Validation loss: 1.614310836279264

Epoch: 551| Step: 0
Training loss: 0.06481269001960754
Validation loss: 1.6624703432924004

Epoch: 5| Step: 1
Training loss: 0.05498896911740303
Validation loss: 1.6554650927102694

Epoch: 5| Step: 2
Training loss: 0.0910254716873169
Validation loss: 1.67222729293249

Epoch: 5| Step: 3
Training loss: 0.1685289442539215
Validation loss: 1.6635249583951888

Epoch: 5| Step: 4
Training loss: 0.18157003819942474
Validation loss: 1.6712446776769494

Epoch: 5| Step: 5
Training loss: 0.11142165958881378
Validation loss: 1.6492766282891715

Epoch: 5| Step: 6
Training loss: 0.08620164543390274
Validation loss: 1.6246933975527365

Epoch: 5| Step: 7
Training loss: 0.07198597490787506
Validation loss: 1.6392717874178322

Epoch: 5| Step: 8
Training loss: 0.0991407111287117
Validation loss: 1.6616477581762499

Epoch: 5| Step: 9
Training loss: 0.08679723739624023
Validation loss: 1.642152556809046

Epoch: 5| Step: 10
Training loss: 0.09049879759550095
Validation loss: 1.6276603116784045

Epoch: 552| Step: 0
Training loss: 0.08428086340427399
Validation loss: 1.6628340777530466

Epoch: 5| Step: 1
Training loss: 0.18240250647068024
Validation loss: 1.6601632628389584

Epoch: 5| Step: 2
Training loss: 0.13773983716964722
Validation loss: 1.6503462535078808

Epoch: 5| Step: 3
Training loss: 0.05815806984901428
Validation loss: 1.6494656865314772

Epoch: 5| Step: 4
Training loss: 0.05822800472378731
Validation loss: 1.6308706268187492

Epoch: 5| Step: 5
Training loss: 0.07876203209161758
Validation loss: 1.5998456029481785

Epoch: 5| Step: 6
Training loss: 0.08937112987041473
Validation loss: 1.5856836918861634

Epoch: 5| Step: 7
Training loss: 0.0915570855140686
Validation loss: 1.6129313899624733

Epoch: 5| Step: 8
Training loss: 0.07925723493099213
Validation loss: 1.6238579512924276

Epoch: 5| Step: 9
Training loss: 0.19075824320316315
Validation loss: 1.6163669132417249

Epoch: 5| Step: 10
Training loss: 0.11247064918279648
Validation loss: 1.6189242319394184

Epoch: 553| Step: 0
Training loss: 0.07380954921245575
Validation loss: 1.6421027234805528

Epoch: 5| Step: 1
Training loss: 0.06866556406021118
Validation loss: 1.6531488459597352

Epoch: 5| Step: 2
Training loss: 0.10803775489330292
Validation loss: 1.6511766654188915

Epoch: 5| Step: 3
Training loss: 0.09502141922712326
Validation loss: 1.649021937001136

Epoch: 5| Step: 4
Training loss: 0.07951456308364868
Validation loss: 1.6545130181056198

Epoch: 5| Step: 5
Training loss: 0.09597505629062653
Validation loss: 1.6542134002972675

Epoch: 5| Step: 6
Training loss: 0.08384925872087479
Validation loss: 1.6751246221603886

Epoch: 5| Step: 7
Training loss: 0.0645165890455246
Validation loss: 1.6836310355894026

Epoch: 5| Step: 8
Training loss: 0.09619554132223129
Validation loss: 1.6527310943090787

Epoch: 5| Step: 9
Training loss: 0.09171108901500702
Validation loss: 1.6723945640748548

Epoch: 5| Step: 10
Training loss: 0.10183307528495789
Validation loss: 1.6794354697709442

Epoch: 554| Step: 0
Training loss: 0.11802111566066742
Validation loss: 1.671681955296506

Epoch: 5| Step: 1
Training loss: 0.09577417373657227
Validation loss: 1.716540837800631

Epoch: 5| Step: 2
Training loss: 0.07484940439462662
Validation loss: 1.685532610903504

Epoch: 5| Step: 3
Training loss: 0.10571782290935516
Validation loss: 1.685108660369791

Epoch: 5| Step: 4
Training loss: 0.08190075308084488
Validation loss: 1.6692187042646511

Epoch: 5| Step: 5
Training loss: 0.06292262673377991
Validation loss: 1.662950897729525

Epoch: 5| Step: 6
Training loss: 0.08663583546876907
Validation loss: 1.6410420274221769

Epoch: 5| Step: 7
Training loss: 0.11062415689229965
Validation loss: 1.6824544988652712

Epoch: 5| Step: 8
Training loss: 0.10199855268001556
Validation loss: 1.6379066154520998

Epoch: 5| Step: 9
Training loss: 0.07247807830572128
Validation loss: 1.679148381756198

Epoch: 5| Step: 10
Training loss: 0.05200406163930893
Validation loss: 1.6539186277697164

Epoch: 555| Step: 0
Training loss: 0.1032433733344078
Validation loss: 1.6399948520045127

Epoch: 5| Step: 1
Training loss: 0.0680815801024437
Validation loss: 1.6595722289495571

Epoch: 5| Step: 2
Training loss: 0.0771690383553505
Validation loss: 1.6297961281191917

Epoch: 5| Step: 3
Training loss: 0.07236479222774506
Validation loss: 1.6283761000120511

Epoch: 5| Step: 4
Training loss: 0.05848899483680725
Validation loss: 1.5962846356053506

Epoch: 5| Step: 5
Training loss: 0.06631548702716827
Validation loss: 1.6248051402389363

Epoch: 5| Step: 6
Training loss: 0.05559874325990677
Validation loss: 1.630730471303386

Epoch: 5| Step: 7
Training loss: 0.06421416997909546
Validation loss: 1.610031012565859

Epoch: 5| Step: 8
Training loss: 0.10017840564250946
Validation loss: 1.6229231831847981

Epoch: 5| Step: 9
Training loss: 0.13499990105628967
Validation loss: 1.635499006958418

Epoch: 5| Step: 10
Training loss: 0.08393827825784683
Validation loss: 1.6462966280598794

Epoch: 556| Step: 0
Training loss: 0.09657172858715057
Validation loss: 1.65356409036985

Epoch: 5| Step: 1
Training loss: 0.09832225739955902
Validation loss: 1.660265181654243

Epoch: 5| Step: 2
Training loss: 0.05751221254467964
Validation loss: 1.6409739704542263

Epoch: 5| Step: 3
Training loss: 0.11763586103916168
Validation loss: 1.6724657320207166

Epoch: 5| Step: 4
Training loss: 0.06671638786792755
Validation loss: 1.6486784565833308

Epoch: 5| Step: 5
Training loss: 0.07167565077543259
Validation loss: 1.6347918330982167

Epoch: 5| Step: 6
Training loss: 0.10007145255804062
Validation loss: 1.6577099318145423

Epoch: 5| Step: 7
Training loss: 0.06280010938644409
Validation loss: 1.6688682468988563

Epoch: 5| Step: 8
Training loss: 0.09314844012260437
Validation loss: 1.6589331383346229

Epoch: 5| Step: 9
Training loss: 0.1432100385427475
Validation loss: 1.6552649928677468

Epoch: 5| Step: 10
Training loss: 0.07976064085960388
Validation loss: 1.645804064248198

Epoch: 557| Step: 0
Training loss: 0.07732856273651123
Validation loss: 1.6672317584355671

Epoch: 5| Step: 1
Training loss: 0.11037856340408325
Validation loss: 1.6552364044291998

Epoch: 5| Step: 2
Training loss: 0.08932284265756607
Validation loss: 1.6434203437579575

Epoch: 5| Step: 3
Training loss: 0.09198789298534393
Validation loss: 1.6468445434365222

Epoch: 5| Step: 4
Training loss: 0.12180161476135254
Validation loss: 1.6386476934597056

Epoch: 5| Step: 5
Training loss: 0.09563998878002167
Validation loss: 1.6257286597323675

Epoch: 5| Step: 6
Training loss: 0.1344151645898819
Validation loss: 1.6370813500496648

Epoch: 5| Step: 7
Training loss: 0.09027458727359772
Validation loss: 1.6479305759552987

Epoch: 5| Step: 8
Training loss: 0.07262243330478668
Validation loss: 1.6491026263083182

Epoch: 5| Step: 9
Training loss: 0.1703205555677414
Validation loss: 1.633817466356421

Epoch: 5| Step: 10
Training loss: 0.1174938827753067
Validation loss: 1.648674113776094

Epoch: 558| Step: 0
Training loss: 0.07810571789741516
Validation loss: 1.6603068228690856

Epoch: 5| Step: 1
Training loss: 0.07045596837997437
Validation loss: 1.65383622723241

Epoch: 5| Step: 2
Training loss: 0.10549421608448029
Validation loss: 1.6370232002709502

Epoch: 5| Step: 3
Training loss: 0.058029741048812866
Validation loss: 1.6273224853700208

Epoch: 5| Step: 4
Training loss: 0.0841759592294693
Validation loss: 1.618401800432513

Epoch: 5| Step: 5
Training loss: 0.0980474129319191
Validation loss: 1.6370124227257186

Epoch: 5| Step: 6
Training loss: 0.06781859695911407
Validation loss: 1.6240489841789327

Epoch: 5| Step: 7
Training loss: 0.09176070243120193
Validation loss: 1.6020164899928595

Epoch: 5| Step: 8
Training loss: 0.05652092769742012
Validation loss: 1.6347727826846543

Epoch: 5| Step: 9
Training loss: 0.09815957397222519
Validation loss: 1.6360198938718407

Epoch: 5| Step: 10
Training loss: 0.13549284636974335
Validation loss: 1.658655196107844

Epoch: 559| Step: 0
Training loss: 0.07893059402704239
Validation loss: 1.6360026726158716

Epoch: 5| Step: 1
Training loss: 0.04971408098936081
Validation loss: 1.6226151117714502

Epoch: 5| Step: 2
Training loss: 0.052095942199230194
Validation loss: 1.6075105333840976

Epoch: 5| Step: 3
Training loss: 0.10547922551631927
Validation loss: 1.5859039175894953

Epoch: 5| Step: 4
Training loss: 0.08333829045295715
Validation loss: 1.5736590457218949

Epoch: 5| Step: 5
Training loss: 0.08531355857849121
Validation loss: 1.5741028657523535

Epoch: 5| Step: 6
Training loss: 0.10699588060379028
Validation loss: 1.5745794491101337

Epoch: 5| Step: 7
Training loss: 0.09807685762643814
Validation loss: 1.5751952983999764

Epoch: 5| Step: 8
Training loss: 0.0941447764635086
Validation loss: 1.558832351879407

Epoch: 5| Step: 9
Training loss: 0.10075235366821289
Validation loss: 1.5863634444052173

Epoch: 5| Step: 10
Training loss: 0.09567564725875854
Validation loss: 1.6098763468444988

Epoch: 560| Step: 0
Training loss: 0.0911734476685524
Validation loss: 1.606292329808717

Epoch: 5| Step: 1
Training loss: 0.07574941217899323
Validation loss: 1.6305900901876471

Epoch: 5| Step: 2
Training loss: 0.06732715666294098
Validation loss: 1.6318020974436114

Epoch: 5| Step: 3
Training loss: 0.10763625055551529
Validation loss: 1.632247204421669

Epoch: 5| Step: 4
Training loss: 0.09003385901451111
Validation loss: 1.6127106451219129

Epoch: 5| Step: 5
Training loss: 0.06329275667667389
Validation loss: 1.6261965856757215

Epoch: 5| Step: 6
Training loss: 0.11841724067926407
Validation loss: 1.6462724157558974

Epoch: 5| Step: 7
Training loss: 0.06838751584291458
Validation loss: 1.586222517874933

Epoch: 5| Step: 8
Training loss: 0.13909706473350525
Validation loss: 1.5827108006323538

Epoch: 5| Step: 9
Training loss: 0.07602499425411224
Validation loss: 1.609487279768913

Epoch: 5| Step: 10
Training loss: 0.08242350816726685
Validation loss: 1.5900751762492682

Epoch: 561| Step: 0
Training loss: 0.07146985828876495
Validation loss: 1.6037711033257105

Epoch: 5| Step: 1
Training loss: 0.0992642492055893
Validation loss: 1.5927829691158828

Epoch: 5| Step: 2
Training loss: 0.09359875321388245
Validation loss: 1.5910280699371009

Epoch: 5| Step: 3
Training loss: 0.09672833979129791
Validation loss: 1.6105762015106857

Epoch: 5| Step: 4
Training loss: 0.08519881218671799
Validation loss: 1.6243015425179594

Epoch: 5| Step: 5
Training loss: 0.052353329956531525
Validation loss: 1.606675063410113

Epoch: 5| Step: 6
Training loss: 0.09130257368087769
Validation loss: 1.6238039783252183

Epoch: 5| Step: 7
Training loss: 0.07093197852373123
Validation loss: 1.6341892250122563

Epoch: 5| Step: 8
Training loss: 0.07649669051170349
Validation loss: 1.6354426325008433

Epoch: 5| Step: 9
Training loss: 0.09494936466217041
Validation loss: 1.630822886702835

Epoch: 5| Step: 10
Training loss: 0.12266802787780762
Validation loss: 1.6123499139662711

Epoch: 562| Step: 0
Training loss: 0.06415069103240967
Validation loss: 1.6300209068482923

Epoch: 5| Step: 1
Training loss: 0.08217091113328934
Validation loss: 1.6662112179622854

Epoch: 5| Step: 2
Training loss: 0.0942613035440445
Validation loss: 1.608800813715945

Epoch: 5| Step: 3
Training loss: 0.059151679277420044
Validation loss: 1.6046093881771128

Epoch: 5| Step: 4
Training loss: 0.0877988189458847
Validation loss: 1.626964710092032

Epoch: 5| Step: 5
Training loss: 0.13418611884117126
Validation loss: 1.6138468788516136

Epoch: 5| Step: 6
Training loss: 0.1286754459142685
Validation loss: 1.6099849349708968

Epoch: 5| Step: 7
Training loss: 0.08296021074056625
Validation loss: 1.6079310935030702

Epoch: 5| Step: 8
Training loss: 0.09741129726171494
Validation loss: 1.5947293555864723

Epoch: 5| Step: 9
Training loss: 0.08787186443805695
Validation loss: 1.5942920254122825

Epoch: 5| Step: 10
Training loss: 0.07524380087852478
Validation loss: 1.589745242108581

Epoch: 563| Step: 0
Training loss: 0.07176855206489563
Validation loss: 1.6078635595178092

Epoch: 5| Step: 1
Training loss: 0.08268820494413376
Validation loss: 1.5924485780859505

Epoch: 5| Step: 2
Training loss: 0.11070270836353302
Validation loss: 1.6081649359836374

Epoch: 5| Step: 3
Training loss: 0.10048091411590576
Validation loss: 1.5994626937373992

Epoch: 5| Step: 4
Training loss: 0.12869851291179657
Validation loss: 1.6297161066403953

Epoch: 5| Step: 5
Training loss: 0.055873192846775055
Validation loss: 1.645234029780152

Epoch: 5| Step: 6
Training loss: 0.1092863529920578
Validation loss: 1.658176399046375

Epoch: 5| Step: 7
Training loss: 0.08107184618711472
Validation loss: 1.6855911875283847

Epoch: 5| Step: 8
Training loss: 0.11014065891504288
Validation loss: 1.7221605072739303

Epoch: 5| Step: 9
Training loss: 0.0657411441206932
Validation loss: 1.7294769453746017

Epoch: 5| Step: 10
Training loss: 0.12591513991355896
Validation loss: 1.6981051173261417

Epoch: 564| Step: 0
Training loss: 0.11120946705341339
Validation loss: 1.6693355344956922

Epoch: 5| Step: 1
Training loss: 0.08775925636291504
Validation loss: 1.6074730644943893

Epoch: 5| Step: 2
Training loss: 0.10510935634374619
Validation loss: 1.6099261506911247

Epoch: 5| Step: 3
Training loss: 0.06998706609010696
Validation loss: 1.565357054433515

Epoch: 5| Step: 4
Training loss: 0.12724563479423523
Validation loss: 1.6112542921496975

Epoch: 5| Step: 5
Training loss: 0.0805826261639595
Validation loss: 1.610210193100796

Epoch: 5| Step: 6
Training loss: 0.1689341813325882
Validation loss: 1.5797883541353288

Epoch: 5| Step: 7
Training loss: 0.09029828011989594
Validation loss: 1.6115514091266099

Epoch: 5| Step: 8
Training loss: 0.10362203419208527
Validation loss: 1.6198085841312204

Epoch: 5| Step: 9
Training loss: 0.1241530179977417
Validation loss: 1.6065515472042946

Epoch: 5| Step: 10
Training loss: 0.09159218519926071
Validation loss: 1.6196767591661023

Epoch: 565| Step: 0
Training loss: 0.12152932584285736
Validation loss: 1.6337412634203512

Epoch: 5| Step: 1
Training loss: 0.09923842549324036
Validation loss: 1.6504233678181965

Epoch: 5| Step: 2
Training loss: 0.14792826771736145
Validation loss: 1.6651948305868334

Epoch: 5| Step: 3
Training loss: 0.09104101359844208
Validation loss: 1.675387320979949

Epoch: 5| Step: 4
Training loss: 0.14749163389205933
Validation loss: 1.6613063671255623

Epoch: 5| Step: 5
Training loss: 0.08243177831172943
Validation loss: 1.6493936405386975

Epoch: 5| Step: 6
Training loss: 0.106420136988163
Validation loss: 1.621280586847695

Epoch: 5| Step: 7
Training loss: 0.1086219772696495
Validation loss: 1.6270380853324808

Epoch: 5| Step: 8
Training loss: 0.06957607716321945
Validation loss: 1.6169337418771559

Epoch: 5| Step: 9
Training loss: 0.13309891521930695
Validation loss: 1.5958781729462326

Epoch: 5| Step: 10
Training loss: 0.13281115889549255
Validation loss: 1.5838952615696897

Epoch: 566| Step: 0
Training loss: 0.07060237228870392
Validation loss: 1.5857571235267065

Epoch: 5| Step: 1
Training loss: 0.10164511203765869
Validation loss: 1.589772037280503

Epoch: 5| Step: 2
Training loss: 0.09429242461919785
Validation loss: 1.6032991563120196

Epoch: 5| Step: 3
Training loss: 0.09064128249883652
Validation loss: 1.6134025486566688

Epoch: 5| Step: 4
Training loss: 0.08011271804571152
Validation loss: 1.6442038807817685

Epoch: 5| Step: 5
Training loss: 0.16799691319465637
Validation loss: 1.6497420059737338

Epoch: 5| Step: 6
Training loss: 0.1682938039302826
Validation loss: 1.6629181959295785

Epoch: 5| Step: 7
Training loss: 0.08779580891132355
Validation loss: 1.6671839696104809

Epoch: 5| Step: 8
Training loss: 0.10589151084423065
Validation loss: 1.6651669676585863

Epoch: 5| Step: 9
Training loss: 0.06719814240932465
Validation loss: 1.641816919849765

Epoch: 5| Step: 10
Training loss: 0.08920592069625854
Validation loss: 1.6710505767535138

Epoch: 567| Step: 0
Training loss: 0.13913872838020325
Validation loss: 1.6746378996038949

Epoch: 5| Step: 1
Training loss: 0.11212049424648285
Validation loss: 1.6521062338224022

Epoch: 5| Step: 2
Training loss: 0.05253045633435249
Validation loss: 1.6172683610711047

Epoch: 5| Step: 3
Training loss: 0.11461929976940155
Validation loss: 1.590286047227921

Epoch: 5| Step: 4
Training loss: 0.1342250406742096
Validation loss: 1.6117510923775293

Epoch: 5| Step: 5
Training loss: 0.10035903751850128
Validation loss: 1.639401170515245

Epoch: 5| Step: 6
Training loss: 0.12424954026937485
Validation loss: 1.5977476207158898

Epoch: 5| Step: 7
Training loss: 0.13949725031852722
Validation loss: 1.6204461166935582

Epoch: 5| Step: 8
Training loss: 0.10242478549480438
Validation loss: 1.5975304547176565

Epoch: 5| Step: 9
Training loss: 0.09267062693834305
Validation loss: 1.6440708534691924

Epoch: 5| Step: 10
Training loss: 0.07713395357131958
Validation loss: 1.622104121792701

Epoch: 568| Step: 0
Training loss: 0.05675671249628067
Validation loss: 1.6443237040632515

Epoch: 5| Step: 1
Training loss: 0.087086983025074
Validation loss: 1.6103563257443008

Epoch: 5| Step: 2
Training loss: 0.0765586718916893
Validation loss: 1.6430013423324914

Epoch: 5| Step: 3
Training loss: 0.0621991828083992
Validation loss: 1.6341623798493417

Epoch: 5| Step: 4
Training loss: 0.10455465316772461
Validation loss: 1.581130450771701

Epoch: 5| Step: 5
Training loss: 0.08848516643047333
Validation loss: 1.5932084988522273

Epoch: 5| Step: 6
Training loss: 0.07046933472156525
Validation loss: 1.5824200543024207

Epoch: 5| Step: 7
Training loss: 0.06651385128498077
Validation loss: 1.616181642778458

Epoch: 5| Step: 8
Training loss: 0.09888265281915665
Validation loss: 1.5852704432702833

Epoch: 5| Step: 9
Training loss: 0.07386218756437302
Validation loss: 1.5836606769151584

Epoch: 5| Step: 10
Training loss: 0.0784716010093689
Validation loss: 1.5695750085256432

Epoch: 569| Step: 0
Training loss: 0.0794733315706253
Validation loss: 1.6075310578910254

Epoch: 5| Step: 1
Training loss: 0.06777717173099518
Validation loss: 1.5858840750109764

Epoch: 5| Step: 2
Training loss: 0.09439931809902191
Validation loss: 1.6363448417314919

Epoch: 5| Step: 3
Training loss: 0.11146204173564911
Validation loss: 1.6242898535984818

Epoch: 5| Step: 4
Training loss: 0.12849530577659607
Validation loss: 1.6633284976405482

Epoch: 5| Step: 5
Training loss: 0.10312674194574356
Validation loss: 1.6509685772721485

Epoch: 5| Step: 6
Training loss: 0.12952466309070587
Validation loss: 1.6194876714419293

Epoch: 5| Step: 7
Training loss: 0.10711797326803207
Validation loss: 1.638041901332076

Epoch: 5| Step: 8
Training loss: 0.06269620358943939
Validation loss: 1.6311518748601277

Epoch: 5| Step: 9
Training loss: 0.09111133962869644
Validation loss: 1.6062409102275808

Epoch: 5| Step: 10
Training loss: 0.059775661677122116
Validation loss: 1.6093097226594084

Epoch: 570| Step: 0
Training loss: 0.14673063158988953
Validation loss: 1.5662486809556202

Epoch: 5| Step: 1
Training loss: 0.09440979361534119
Validation loss: 1.608364946098738

Epoch: 5| Step: 2
Training loss: 0.09618966281414032
Validation loss: 1.6386834793193366

Epoch: 5| Step: 3
Training loss: 0.15174078941345215
Validation loss: 1.6231712154162827

Epoch: 5| Step: 4
Training loss: 0.12399375438690186
Validation loss: 1.6520649861263972

Epoch: 5| Step: 5
Training loss: 0.09188078343868256
Validation loss: 1.6428029485928115

Epoch: 5| Step: 6
Training loss: 0.09002677351236343
Validation loss: 1.6598143475030058

Epoch: 5| Step: 7
Training loss: 0.13190500438213348
Validation loss: 1.6993428930159538

Epoch: 5| Step: 8
Training loss: 0.18536964058876038
Validation loss: 1.7111851412762877

Epoch: 5| Step: 9
Training loss: 0.07821841537952423
Validation loss: 1.7010721506610993

Epoch: 5| Step: 10
Training loss: 0.07329346984624863
Validation loss: 1.7153651111869401

Epoch: 571| Step: 0
Training loss: 0.072567418217659
Validation loss: 1.6895199424477034

Epoch: 5| Step: 1
Training loss: 0.08062754571437836
Validation loss: 1.6581154266993205

Epoch: 5| Step: 2
Training loss: 0.1241832748055458
Validation loss: 1.6518004350764777

Epoch: 5| Step: 3
Training loss: 0.10912764072418213
Validation loss: 1.6179764296418877

Epoch: 5| Step: 4
Training loss: 0.11142786592245102
Validation loss: 1.618655684173748

Epoch: 5| Step: 5
Training loss: 0.12276063859462738
Validation loss: 1.618830415510362

Epoch: 5| Step: 6
Training loss: 0.14635738730430603
Validation loss: 1.6392188738751154

Epoch: 5| Step: 7
Training loss: 0.10575679689645767
Validation loss: 1.6542918438552527

Epoch: 5| Step: 8
Training loss: 0.16532102227210999
Validation loss: 1.6263268481018722

Epoch: 5| Step: 9
Training loss: 0.12122341245412827
Validation loss: 1.6634201900933379

Epoch: 5| Step: 10
Training loss: 0.10582466423511505
Validation loss: 1.6524107699753137

Epoch: 572| Step: 0
Training loss: 0.07360148429870605
Validation loss: 1.6485889316886984

Epoch: 5| Step: 1
Training loss: 0.09763877093791962
Validation loss: 1.6910787064542052

Epoch: 5| Step: 2
Training loss: 0.09607500582933426
Validation loss: 1.6700221620580202

Epoch: 5| Step: 3
Training loss: 0.11402406543493271
Validation loss: 1.673829395283935

Epoch: 5| Step: 4
Training loss: 0.09698311984539032
Validation loss: 1.650584509295802

Epoch: 5| Step: 5
Training loss: 0.1515330672264099
Validation loss: 1.6573939579789356

Epoch: 5| Step: 6
Training loss: 0.12706875801086426
Validation loss: 1.6276644750307965

Epoch: 5| Step: 7
Training loss: 0.16408702731132507
Validation loss: 1.6261432709232453

Epoch: 5| Step: 8
Training loss: 0.0820518285036087
Validation loss: 1.6370274123325144

Epoch: 5| Step: 9
Training loss: 0.08242666721343994
Validation loss: 1.6317142600654273

Epoch: 5| Step: 10
Training loss: 0.11186780780553818
Validation loss: 1.6030645876802423

Epoch: 573| Step: 0
Training loss: 0.13677334785461426
Validation loss: 1.6338776798658474

Epoch: 5| Step: 1
Training loss: 0.08510555326938629
Validation loss: 1.620746022911482

Epoch: 5| Step: 2
Training loss: 0.14065858721733093
Validation loss: 1.6420888952029649

Epoch: 5| Step: 3
Training loss: 0.19491705298423767
Validation loss: 1.6554693906537947

Epoch: 5| Step: 4
Training loss: 0.13889339566230774
Validation loss: 1.6777107061878327

Epoch: 5| Step: 5
Training loss: 0.11758150905370712
Validation loss: 1.671105114362573

Epoch: 5| Step: 6
Training loss: 0.1153651624917984
Validation loss: 1.6720380347262147

Epoch: 5| Step: 7
Training loss: 0.09251393377780914
Validation loss: 1.6601395632631035

Epoch: 5| Step: 8
Training loss: 0.10350002348423004
Validation loss: 1.6639626077426377

Epoch: 5| Step: 9
Training loss: 0.09290271997451782
Validation loss: 1.6138385239467825

Epoch: 5| Step: 10
Training loss: 0.22330480813980103
Validation loss: 1.6176372349903148

Epoch: 574| Step: 0
Training loss: 0.1547047346830368
Validation loss: 1.5758743574542384

Epoch: 5| Step: 1
Training loss: 0.16942328214645386
Validation loss: 1.5862467699153449

Epoch: 5| Step: 2
Training loss: 0.11839447170495987
Validation loss: 1.593234549286545

Epoch: 5| Step: 3
Training loss: 0.11092665046453476
Validation loss: 1.577815833912101

Epoch: 5| Step: 4
Training loss: 0.07087469100952148
Validation loss: 1.6118817034588064

Epoch: 5| Step: 5
Training loss: 0.053933870047330856
Validation loss: 1.6413955714112969

Epoch: 5| Step: 6
Training loss: 0.13698029518127441
Validation loss: 1.6654020458139398

Epoch: 5| Step: 7
Training loss: 0.15803369879722595
Validation loss: 1.6683951359923168

Epoch: 5| Step: 8
Training loss: 0.09225887060165405
Validation loss: 1.6957972049713135

Epoch: 5| Step: 9
Training loss: 0.10335197299718857
Validation loss: 1.7055943166055987

Epoch: 5| Step: 10
Training loss: 0.1381750851869583
Validation loss: 1.710462716317946

Epoch: 575| Step: 0
Training loss: 0.07138010859489441
Validation loss: 1.7386201017646379

Epoch: 5| Step: 1
Training loss: 0.11519193649291992
Validation loss: 1.720889272228364

Epoch: 5| Step: 2
Training loss: 0.11075596511363983
Validation loss: 1.7220185905374505

Epoch: 5| Step: 3
Training loss: 0.08505379408597946
Validation loss: 1.672169759709348

Epoch: 5| Step: 4
Training loss: 0.09180434048175812
Validation loss: 1.6668770749081847

Epoch: 5| Step: 5
Training loss: 0.07670946419239044
Validation loss: 1.6154946755337458

Epoch: 5| Step: 6
Training loss: 0.0789310485124588
Validation loss: 1.606380029391217

Epoch: 5| Step: 7
Training loss: 0.07817070186138153
Validation loss: 1.6082732421095653

Epoch: 5| Step: 8
Training loss: 0.08996834605932236
Validation loss: 1.5656221079569992

Epoch: 5| Step: 9
Training loss: 0.07337537407875061
Validation loss: 1.5666092185563938

Epoch: 5| Step: 10
Training loss: 0.12201275676488876
Validation loss: 1.5819999402569187

Epoch: 576| Step: 0
Training loss: 0.07376496493816376
Validation loss: 1.5776021839469991

Epoch: 5| Step: 1
Training loss: 0.12656286358833313
Validation loss: 1.591756054150161

Epoch: 5| Step: 2
Training loss: 0.09749317914247513
Validation loss: 1.6044332468381493

Epoch: 5| Step: 3
Training loss: 0.080937460064888
Validation loss: 1.59593338863824

Epoch: 5| Step: 4
Training loss: 0.09780150651931763
Validation loss: 1.5998081494403142

Epoch: 5| Step: 5
Training loss: 0.05580567196011543
Validation loss: 1.587694857069241

Epoch: 5| Step: 6
Training loss: 0.08497337996959686
Validation loss: 1.6084937434042654

Epoch: 5| Step: 7
Training loss: 0.1153942123055458
Validation loss: 1.6510732878920853

Epoch: 5| Step: 8
Training loss: 0.07199224084615707
Validation loss: 1.6518206904011388

Epoch: 5| Step: 9
Training loss: 0.081265889108181
Validation loss: 1.6305993346757786

Epoch: 5| Step: 10
Training loss: 0.09465903043746948
Validation loss: 1.6230920566025602

Epoch: 577| Step: 0
Training loss: 0.09803013503551483
Validation loss: 1.619028493922244

Epoch: 5| Step: 1
Training loss: 0.12077067047357559
Validation loss: 1.611440166350334

Epoch: 5| Step: 2
Training loss: 0.08163906633853912
Validation loss: 1.6036368416201683

Epoch: 5| Step: 3
Training loss: 0.06213366985321045
Validation loss: 1.6158758145506664

Epoch: 5| Step: 4
Training loss: 0.09583384543657303
Validation loss: 1.5940689707315097

Epoch: 5| Step: 5
Training loss: 0.09371904283761978
Validation loss: 1.5967019604098411

Epoch: 5| Step: 6
Training loss: 0.07823675125837326
Validation loss: 1.6079997618993123

Epoch: 5| Step: 7
Training loss: 0.09000331163406372
Validation loss: 1.59206400955877

Epoch: 5| Step: 8
Training loss: 0.09408082067966461
Validation loss: 1.6278623034877162

Epoch: 5| Step: 9
Training loss: 0.14195039868354797
Validation loss: 1.6138711398647678

Epoch: 5| Step: 10
Training loss: 0.08922845125198364
Validation loss: 1.613102764211675

Epoch: 578| Step: 0
Training loss: 0.10801143944263458
Validation loss: 1.6403451632427912

Epoch: 5| Step: 1
Training loss: 0.08474602550268173
Validation loss: 1.6290904520660319

Epoch: 5| Step: 2
Training loss: 0.06827991455793381
Validation loss: 1.642931838189402

Epoch: 5| Step: 3
Training loss: 0.11771844327449799
Validation loss: 1.6672699425810127

Epoch: 5| Step: 4
Training loss: 0.09592131525278091
Validation loss: 1.6715574649072462

Epoch: 5| Step: 5
Training loss: 0.11287333816289902
Validation loss: 1.6544694580057615

Epoch: 5| Step: 6
Training loss: 0.06250366568565369
Validation loss: 1.6753453644373084

Epoch: 5| Step: 7
Training loss: 0.1122802272439003
Validation loss: 1.639001283594357

Epoch: 5| Step: 8
Training loss: 0.11908574402332306
Validation loss: 1.6634060695607176

Epoch: 5| Step: 9
Training loss: 0.07139284163713455
Validation loss: 1.6545773436946254

Epoch: 5| Step: 10
Training loss: 0.11763094365596771
Validation loss: 1.6493196307971913

Epoch: 579| Step: 0
Training loss: 0.07876547425985336
Validation loss: 1.687479913875621

Epoch: 5| Step: 1
Training loss: 0.08370694518089294
Validation loss: 1.6879370276645949

Epoch: 5| Step: 2
Training loss: 0.16598272323608398
Validation loss: 1.6633865115463093

Epoch: 5| Step: 3
Training loss: 0.12689192593097687
Validation loss: 1.6822469157557334

Epoch: 5| Step: 4
Training loss: 0.10616850852966309
Validation loss: 1.6878705780993226

Epoch: 5| Step: 5
Training loss: 0.08729719370603561
Validation loss: 1.66030716383329

Epoch: 5| Step: 6
Training loss: 0.05718367546796799
Validation loss: 1.675860684405091

Epoch: 5| Step: 7
Training loss: 0.07801152020692825
Validation loss: 1.6631058005876438

Epoch: 5| Step: 8
Training loss: 0.06413651257753372
Validation loss: 1.6702838854123188

Epoch: 5| Step: 9
Training loss: 0.0599910244345665
Validation loss: 1.6415433870848788

Epoch: 5| Step: 10
Training loss: 0.07787899672985077
Validation loss: 1.6442936030767297

Epoch: 580| Step: 0
Training loss: 0.0861368477344513
Validation loss: 1.6428302590565016

Epoch: 5| Step: 1
Training loss: 0.07324422895908356
Validation loss: 1.621986295587273

Epoch: 5| Step: 2
Training loss: 0.08035113662481308
Validation loss: 1.650001787370251

Epoch: 5| Step: 3
Training loss: 0.11361648887395859
Validation loss: 1.6282519627642889

Epoch: 5| Step: 4
Training loss: 0.05347885936498642
Validation loss: 1.624820408000741

Epoch: 5| Step: 5
Training loss: 0.06945835053920746
Validation loss: 1.6366497419213737

Epoch: 5| Step: 6
Training loss: 0.07869067043066025
Validation loss: 1.6063376511296918

Epoch: 5| Step: 7
Training loss: 0.10101272910833359
Validation loss: 1.6235600210005237

Epoch: 5| Step: 8
Training loss: 0.08546195924282074
Validation loss: 1.6086459646942795

Epoch: 5| Step: 9
Training loss: 0.06989948451519012
Validation loss: 1.5951777299245198

Epoch: 5| Step: 10
Training loss: 0.12506620585918427
Validation loss: 1.6095446027735227

Epoch: 581| Step: 0
Training loss: 0.06309729814529419
Validation loss: 1.6272339667043378

Epoch: 5| Step: 1
Training loss: 0.047006361186504364
Validation loss: 1.6542969416546565

Epoch: 5| Step: 2
Training loss: 0.08805794268846512
Validation loss: 1.6585123615880166

Epoch: 5| Step: 3
Training loss: 0.13570952415466309
Validation loss: 1.6399513918866393

Epoch: 5| Step: 4
Training loss: 0.142236590385437
Validation loss: 1.6267139091286609

Epoch: 5| Step: 5
Training loss: 0.11654504388570786
Validation loss: 1.6360407824157386

Epoch: 5| Step: 6
Training loss: 0.10833045095205307
Validation loss: 1.6297844199724094

Epoch: 5| Step: 7
Training loss: 0.08404793590307236
Validation loss: 1.5985760355508456

Epoch: 5| Step: 8
Training loss: 0.067601777613163
Validation loss: 1.6496125895489928

Epoch: 5| Step: 9
Training loss: 0.10459737479686737
Validation loss: 1.6218666158696657

Epoch: 5| Step: 10
Training loss: 0.10009809583425522
Validation loss: 1.6478050678007063

Epoch: 582| Step: 0
Training loss: 0.10484179109334946
Validation loss: 1.679323496357087

Epoch: 5| Step: 1
Training loss: 0.0810772106051445
Validation loss: 1.6452888134987123

Epoch: 5| Step: 2
Training loss: 0.06926187872886658
Validation loss: 1.6111468243342575

Epoch: 5| Step: 3
Training loss: 0.0930698961019516
Validation loss: 1.6377743610771753

Epoch: 5| Step: 4
Training loss: 0.0944419875741005
Validation loss: 1.6342497974313714

Epoch: 5| Step: 5
Training loss: 0.13118651509284973
Validation loss: 1.6305430909638763

Epoch: 5| Step: 6
Training loss: 0.09932651370763779
Validation loss: 1.6556136774760422

Epoch: 5| Step: 7
Training loss: 0.09174267947673798
Validation loss: 1.6414535430169874

Epoch: 5| Step: 8
Training loss: 0.10787065327167511
Validation loss: 1.6825258757478447

Epoch: 5| Step: 9
Training loss: 0.09665475785732269
Validation loss: 1.6451358179892264

Epoch: 5| Step: 10
Training loss: 0.06436652690172195
Validation loss: 1.653673155333406

Epoch: 583| Step: 0
Training loss: 0.10302212089300156
Validation loss: 1.6440317515403993

Epoch: 5| Step: 1
Training loss: 0.11208655685186386
Validation loss: 1.6329738414415749

Epoch: 5| Step: 2
Training loss: 0.14756183326244354
Validation loss: 1.6583039504225536

Epoch: 5| Step: 3
Training loss: 0.06439525634050369
Validation loss: 1.66271791150493

Epoch: 5| Step: 4
Training loss: 0.09243934601545334
Validation loss: 1.6537625020550144

Epoch: 5| Step: 5
Training loss: 0.05689654499292374
Validation loss: 1.6419994190175047

Epoch: 5| Step: 6
Training loss: 0.058007996529340744
Validation loss: 1.6255585403852566

Epoch: 5| Step: 7
Training loss: 0.09283469617366791
Validation loss: 1.6321012038056568

Epoch: 5| Step: 8
Training loss: 0.09555592387914658
Validation loss: 1.6391389831419914

Epoch: 5| Step: 9
Training loss: 0.04102157801389694
Validation loss: 1.6043308018356242

Epoch: 5| Step: 10
Training loss: 0.06460859626531601
Validation loss: 1.5946347187924128

Epoch: 584| Step: 0
Training loss: 0.06779457628726959
Validation loss: 1.6089670581202353

Epoch: 5| Step: 1
Training loss: 0.11047868430614471
Validation loss: 1.5924702972494147

Epoch: 5| Step: 2
Training loss: 0.04406069219112396
Validation loss: 1.6337807306679346

Epoch: 5| Step: 3
Training loss: 0.06883718818426132
Validation loss: 1.6420097908666056

Epoch: 5| Step: 4
Training loss: 0.08090128749608994
Validation loss: 1.6555505798709007

Epoch: 5| Step: 5
Training loss: 0.04326952248811722
Validation loss: 1.6288562243984592

Epoch: 5| Step: 6
Training loss: 0.10804655402898788
Validation loss: 1.6440481062858336

Epoch: 5| Step: 7
Training loss: 0.08923381567001343
Validation loss: 1.6432578832872453

Epoch: 5| Step: 8
Training loss: 0.07040782272815704
Validation loss: 1.6417570460227229

Epoch: 5| Step: 9
Training loss: 0.058439821004867554
Validation loss: 1.644630870511455

Epoch: 5| Step: 10
Training loss: 0.09271196275949478
Validation loss: 1.6183163671083347

Epoch: 585| Step: 0
Training loss: 0.11994681507349014
Validation loss: 1.6323513061769548

Epoch: 5| Step: 1
Training loss: 0.061001747846603394
Validation loss: 1.6368306016409269

Epoch: 5| Step: 2
Training loss: 0.06476174294948578
Validation loss: 1.6378829222853466

Epoch: 5| Step: 3
Training loss: 0.07213522493839264
Validation loss: 1.663295316439803

Epoch: 5| Step: 4
Training loss: 0.07157450169324875
Validation loss: 1.6465267942797752

Epoch: 5| Step: 5
Training loss: 0.06169203668832779
Validation loss: 1.6815705709559943

Epoch: 5| Step: 6
Training loss: 0.10223517566919327
Validation loss: 1.693409550574518

Epoch: 5| Step: 7
Training loss: 0.0445760115981102
Validation loss: 1.6893083254496257

Epoch: 5| Step: 8
Training loss: 0.07666319608688354
Validation loss: 1.6949706641576623

Epoch: 5| Step: 9
Training loss: 0.12284090369939804
Validation loss: 1.6984511742027857

Epoch: 5| Step: 10
Training loss: 0.08956777304410934
Validation loss: 1.6899980255352554

Epoch: 586| Step: 0
Training loss: 0.06113658472895622
Validation loss: 1.6493796404971872

Epoch: 5| Step: 1
Training loss: 0.06170683354139328
Validation loss: 1.6585498215049825

Epoch: 5| Step: 2
Training loss: 0.06450605392456055
Validation loss: 1.6511863303440872

Epoch: 5| Step: 3
Training loss: 0.12219437211751938
Validation loss: 1.6567111611366272

Epoch: 5| Step: 4
Training loss: 0.09545932710170746
Validation loss: 1.6355539444954164

Epoch: 5| Step: 5
Training loss: 0.09865660220384598
Validation loss: 1.6106311557113484

Epoch: 5| Step: 6
Training loss: 0.09045971184968948
Validation loss: 1.6221574788452477

Epoch: 5| Step: 7
Training loss: 0.0808519572019577
Validation loss: 1.6338215079358829

Epoch: 5| Step: 8
Training loss: 0.15467122197151184
Validation loss: 1.6339074527063677

Epoch: 5| Step: 9
Training loss: 0.08365541696548462
Validation loss: 1.5968678138589347

Epoch: 5| Step: 10
Training loss: 0.08039681613445282
Validation loss: 1.613880067743281

Epoch: 587| Step: 0
Training loss: 0.06714796274900436
Validation loss: 1.6625514838003344

Epoch: 5| Step: 1
Training loss: 0.09241889417171478
Validation loss: 1.6373326265683739

Epoch: 5| Step: 2
Training loss: 0.07155551761388779
Validation loss: 1.6541321944164973

Epoch: 5| Step: 3
Training loss: 0.1333010494709015
Validation loss: 1.6311881247387137

Epoch: 5| Step: 4
Training loss: 0.07248833030462265
Validation loss: 1.6386840843385266

Epoch: 5| Step: 5
Training loss: 0.13031157851219177
Validation loss: 1.6144088622062438

Epoch: 5| Step: 6
Training loss: 0.12372493743896484
Validation loss: 1.6091214168456294

Epoch: 5| Step: 7
Training loss: 0.0700865164399147
Validation loss: 1.5932724104132703

Epoch: 5| Step: 8
Training loss: 0.05322877690196037
Validation loss: 1.587628609390669

Epoch: 5| Step: 9
Training loss: 0.07482530176639557
Validation loss: 1.5948014688748184

Epoch: 5| Step: 10
Training loss: 0.05689968541264534
Validation loss: 1.631654139487974

Epoch: 588| Step: 0
Training loss: 0.08664979040622711
Validation loss: 1.6466074643596527

Epoch: 5| Step: 1
Training loss: 0.0928739458322525
Validation loss: 1.6275227838946926

Epoch: 5| Step: 2
Training loss: 0.09783203899860382
Validation loss: 1.6376276990418792

Epoch: 5| Step: 3
Training loss: 0.11526963859796524
Validation loss: 1.6802126284568542

Epoch: 5| Step: 4
Training loss: 0.10795754194259644
Validation loss: 1.6775965511157949

Epoch: 5| Step: 5
Training loss: 0.11884181201457977
Validation loss: 1.665281093248757

Epoch: 5| Step: 6
Training loss: 0.058877646923065186
Validation loss: 1.69406327637293

Epoch: 5| Step: 7
Training loss: 0.06849896907806396
Validation loss: 1.6737038653383973

Epoch: 5| Step: 8
Training loss: 0.10001151263713837
Validation loss: 1.681583244313476

Epoch: 5| Step: 9
Training loss: 0.07761886715888977
Validation loss: 1.6584335193839124

Epoch: 5| Step: 10
Training loss: 0.08514100313186646
Validation loss: 1.599119024892007

Epoch: 589| Step: 0
Training loss: 0.08094628900289536
Validation loss: 1.6069977821842316

Epoch: 5| Step: 1
Training loss: 0.1118444949388504
Validation loss: 1.6246045930411226

Epoch: 5| Step: 2
Training loss: 0.12561534345149994
Validation loss: 1.604255594233031

Epoch: 5| Step: 3
Training loss: 0.06108985096216202
Validation loss: 1.619171304087485

Epoch: 5| Step: 4
Training loss: 0.09278671443462372
Validation loss: 1.620986400112029

Epoch: 5| Step: 5
Training loss: 0.057967592030763626
Validation loss: 1.614314090821051

Epoch: 5| Step: 6
Training loss: 0.06692451238632202
Validation loss: 1.602412894207944

Epoch: 5| Step: 7
Training loss: 0.08227352052927017
Validation loss: 1.6625688640020226

Epoch: 5| Step: 8
Training loss: 0.10527149587869644
Validation loss: 1.6504662318896222

Epoch: 5| Step: 9
Training loss: 0.08674003183841705
Validation loss: 1.656639185003055

Epoch: 5| Step: 10
Training loss: 0.07980113476514816
Validation loss: 1.6360939959044098

Epoch: 590| Step: 0
Training loss: 0.13930538296699524
Validation loss: 1.6171323842899774

Epoch: 5| Step: 1
Training loss: 0.08269327133893967
Validation loss: 1.6051004843045307

Epoch: 5| Step: 2
Training loss: 0.05584657937288284
Validation loss: 1.617441261968305

Epoch: 5| Step: 3
Training loss: 0.08022628724575043
Validation loss: 1.628333773664249

Epoch: 5| Step: 4
Training loss: 0.059051044285297394
Validation loss: 1.6241205225708664

Epoch: 5| Step: 5
Training loss: 0.08358670771121979
Validation loss: 1.6101170816729147

Epoch: 5| Step: 6
Training loss: 0.06889237463474274
Validation loss: 1.6116836083832609

Epoch: 5| Step: 7
Training loss: 0.0965064987540245
Validation loss: 1.6051339974967382

Epoch: 5| Step: 8
Training loss: 0.06113226339221001
Validation loss: 1.6139897505442302

Epoch: 5| Step: 9
Training loss: 0.11549391597509384
Validation loss: 1.6223757536180559

Epoch: 5| Step: 10
Training loss: 0.10929743200540543
Validation loss: 1.622009172875394

Epoch: 591| Step: 0
Training loss: 0.05659527704119682
Validation loss: 1.6344348948488954

Epoch: 5| Step: 1
Training loss: 0.07631389796733856
Validation loss: 1.6078606331220238

Epoch: 5| Step: 2
Training loss: 0.07818587124347687
Validation loss: 1.6371575350402503

Epoch: 5| Step: 3
Training loss: 0.0949043482542038
Validation loss: 1.6137340030362528

Epoch: 5| Step: 4
Training loss: 0.10122175514698029
Validation loss: 1.6175606866036691

Epoch: 5| Step: 5
Training loss: 0.08118648082017899
Validation loss: 1.6010249519860873

Epoch: 5| Step: 6
Training loss: 0.10956554114818573
Validation loss: 1.6014653982654694

Epoch: 5| Step: 7
Training loss: 0.09770508110523224
Validation loss: 1.5952969135776642

Epoch: 5| Step: 8
Training loss: 0.08576126396656036
Validation loss: 1.5791627002018753

Epoch: 5| Step: 9
Training loss: 0.08016376197338104
Validation loss: 1.6136723461971487

Epoch: 5| Step: 10
Training loss: 0.06608179211616516
Validation loss: 1.6175898710886638

Epoch: 592| Step: 0
Training loss: 0.0867452621459961
Validation loss: 1.6400101364299815

Epoch: 5| Step: 1
Training loss: 0.08749891817569733
Validation loss: 1.6557023320146786

Epoch: 5| Step: 2
Training loss: 0.09349498897790909
Validation loss: 1.704347119536451

Epoch: 5| Step: 3
Training loss: 0.07643071562051773
Validation loss: 1.7035494145526682

Epoch: 5| Step: 4
Training loss: 0.11629422008991241
Validation loss: 1.6752369352566299

Epoch: 5| Step: 5
Training loss: 0.17517836391925812
Validation loss: 1.6825296942905714

Epoch: 5| Step: 6
Training loss: 0.10185738652944565
Validation loss: 1.6765901286114928

Epoch: 5| Step: 7
Training loss: 0.07066754996776581
Validation loss: 1.6612670126781668

Epoch: 5| Step: 8
Training loss: 0.05979553982615471
Validation loss: 1.6775926736093336

Epoch: 5| Step: 9
Training loss: 0.06446953862905502
Validation loss: 1.6245137568443053

Epoch: 5| Step: 10
Training loss: 0.07156972587108612
Validation loss: 1.62216813846301

Epoch: 593| Step: 0
Training loss: 0.09565077722072601
Validation loss: 1.628424330424237

Epoch: 5| Step: 1
Training loss: 0.07975137233734131
Validation loss: 1.5832626050518406

Epoch: 5| Step: 2
Training loss: 0.07850777357816696
Validation loss: 1.6040349583471976

Epoch: 5| Step: 3
Training loss: 0.08199578523635864
Validation loss: 1.6366505981773458

Epoch: 5| Step: 4
Training loss: 0.06392870843410492
Validation loss: 1.6261384384606474

Epoch: 5| Step: 5
Training loss: 0.05821043998003006
Validation loss: 1.628495870097991

Epoch: 5| Step: 6
Training loss: 0.052125103771686554
Validation loss: 1.6205257779808455

Epoch: 5| Step: 7
Training loss: 0.1127006784081459
Validation loss: 1.6373938565613122

Epoch: 5| Step: 8
Training loss: 0.061096083372831345
Validation loss: 1.6407900869205434

Epoch: 5| Step: 9
Training loss: 0.0892232283949852
Validation loss: 1.6420482550897906

Epoch: 5| Step: 10
Training loss: 0.08626969903707504
Validation loss: 1.6598904440479894

Epoch: 594| Step: 0
Training loss: 0.10995879024267197
Validation loss: 1.654774644041574

Epoch: 5| Step: 1
Training loss: 0.10116694122552872
Validation loss: 1.637466170454538

Epoch: 5| Step: 2
Training loss: 0.0625850185751915
Validation loss: 1.6546943918351205

Epoch: 5| Step: 3
Training loss: 0.08036109805107117
Validation loss: 1.5877648335631176

Epoch: 5| Step: 4
Training loss: 0.11109113693237305
Validation loss: 1.6210111071986537

Epoch: 5| Step: 5
Training loss: 0.11710246652364731
Validation loss: 1.6146685974572295

Epoch: 5| Step: 6
Training loss: 0.10166488587856293
Validation loss: 1.6092873247720862

Epoch: 5| Step: 7
Training loss: 0.05841461941599846
Validation loss: 1.6506318110291676

Epoch: 5| Step: 8
Training loss: 0.06429953873157501
Validation loss: 1.6126346639407578

Epoch: 5| Step: 9
Training loss: 0.05525030940771103
Validation loss: 1.6320508487762944

Epoch: 5| Step: 10
Training loss: 0.05728084221482277
Validation loss: 1.64255771329326

Epoch: 595| Step: 0
Training loss: 0.10865116119384766
Validation loss: 1.649833998372478

Epoch: 5| Step: 1
Training loss: 0.086257204413414
Validation loss: 1.6516158529507217

Epoch: 5| Step: 2
Training loss: 0.06448427587747574
Validation loss: 1.6483767160805323

Epoch: 5| Step: 3
Training loss: 0.06676959991455078
Validation loss: 1.6358890238628592

Epoch: 5| Step: 4
Training loss: 0.05456836149096489
Validation loss: 1.60919016022836

Epoch: 5| Step: 5
Training loss: 0.08463507890701294
Validation loss: 1.6215047272302772

Epoch: 5| Step: 6
Training loss: 0.061529725790023804
Validation loss: 1.5943664299544467

Epoch: 5| Step: 7
Training loss: 0.09901745617389679
Validation loss: 1.591182215239412

Epoch: 5| Step: 8
Training loss: 0.1366821825504303
Validation loss: 1.5635765214120187

Epoch: 5| Step: 9
Training loss: 0.11067497730255127
Validation loss: 1.5900602340698242

Epoch: 5| Step: 10
Training loss: 0.07556144148111343
Validation loss: 1.6108465348520586

Epoch: 596| Step: 0
Training loss: 0.07370766997337341
Validation loss: 1.6172772498540982

Epoch: 5| Step: 1
Training loss: 0.08020615577697754
Validation loss: 1.616667991043419

Epoch: 5| Step: 2
Training loss: 0.10052766650915146
Validation loss: 1.6019078608482116

Epoch: 5| Step: 3
Training loss: 0.05918879434466362
Validation loss: 1.6349527630754697

Epoch: 5| Step: 4
Training loss: 0.07984016835689545
Validation loss: 1.6175601995119484

Epoch: 5| Step: 5
Training loss: 0.08240675926208496
Validation loss: 1.6270767283696

Epoch: 5| Step: 6
Training loss: 0.09985380619764328
Validation loss: 1.6487935525114819

Epoch: 5| Step: 7
Training loss: 0.0841766893863678
Validation loss: 1.6359311470421412

Epoch: 5| Step: 8
Training loss: 0.10249362140893936
Validation loss: 1.666810853506929

Epoch: 5| Step: 9
Training loss: 0.07049807906150818
Validation loss: 1.6491521020089426

Epoch: 5| Step: 10
Training loss: 0.05560852959752083
Validation loss: 1.6154603355674333

Epoch: 597| Step: 0
Training loss: 0.09454025328159332
Validation loss: 1.620651807836307

Epoch: 5| Step: 1
Training loss: 0.054936982691287994
Validation loss: 1.6173015038172405

Epoch: 5| Step: 2
Training loss: 0.061350345611572266
Validation loss: 1.6100621889996272

Epoch: 5| Step: 3
Training loss: 0.09544068574905396
Validation loss: 1.6137108213158065

Epoch: 5| Step: 4
Training loss: 0.08003684878349304
Validation loss: 1.6342454430877522

Epoch: 5| Step: 5
Training loss: 0.08950068056583405
Validation loss: 1.5960805916017102

Epoch: 5| Step: 6
Training loss: 0.10266487300395966
Validation loss: 1.6306603826502317

Epoch: 5| Step: 7
Training loss: 0.07909411191940308
Validation loss: 1.623247120970039

Epoch: 5| Step: 8
Training loss: 0.09541387856006622
Validation loss: 1.6359061425732029

Epoch: 5| Step: 9
Training loss: 0.08959199488162994
Validation loss: 1.6319326918612245

Epoch: 5| Step: 10
Training loss: 0.10536515712738037
Validation loss: 1.6436989179221533

Epoch: 598| Step: 0
Training loss: 0.0987086221575737
Validation loss: 1.6568871275071175

Epoch: 5| Step: 1
Training loss: 0.07055948674678802
Validation loss: 1.6375077754579566

Epoch: 5| Step: 2
Training loss: 0.11607383191585541
Validation loss: 1.6130798978190268

Epoch: 5| Step: 3
Training loss: 0.06784441322088242
Validation loss: 1.5961805671773932

Epoch: 5| Step: 4
Training loss: 0.09230886399745941
Validation loss: 1.5952903878304265

Epoch: 5| Step: 5
Training loss: 0.1252814680337906
Validation loss: 1.6004769020183112

Epoch: 5| Step: 6
Training loss: 0.11033429950475693
Validation loss: 1.5916880907550934

Epoch: 5| Step: 7
Training loss: 0.06216859817504883
Validation loss: 1.597833228367631

Epoch: 5| Step: 8
Training loss: 0.07503443211317062
Validation loss: 1.6126082469058294

Epoch: 5| Step: 9
Training loss: 0.07118137180805206
Validation loss: 1.6169370079553256

Epoch: 5| Step: 10
Training loss: 0.06561216711997986
Validation loss: 1.6100536328490063

Epoch: 599| Step: 0
Training loss: 0.09266936779022217
Validation loss: 1.6159555168562039

Epoch: 5| Step: 1
Training loss: 0.0921453982591629
Validation loss: 1.6172557671864827

Epoch: 5| Step: 2
Training loss: 0.09159406274557114
Validation loss: 1.6290465734338249

Epoch: 5| Step: 3
Training loss: 0.09317849576473236
Validation loss: 1.6427199507272372

Epoch: 5| Step: 4
Training loss: 0.08276054263114929
Validation loss: 1.643180190875966

Epoch: 5| Step: 5
Training loss: 0.09832407534122467
Validation loss: 1.6354946795330252

Epoch: 5| Step: 6
Training loss: 0.049471549689769745
Validation loss: 1.637738350898989

Epoch: 5| Step: 7
Training loss: 0.07838782668113708
Validation loss: 1.6453729611571117

Epoch: 5| Step: 8
Training loss: 0.0962287187576294
Validation loss: 1.6606836447151758

Epoch: 5| Step: 9
Training loss: 0.09319448471069336
Validation loss: 1.6912943393953386

Epoch: 5| Step: 10
Training loss: 0.0570313036441803
Validation loss: 1.6648946526230022

Epoch: 600| Step: 0
Training loss: 0.09338463842868805
Validation loss: 1.683603435434321

Epoch: 5| Step: 1
Training loss: 0.060538314282894135
Validation loss: 1.6758699006931757

Epoch: 5| Step: 2
Training loss: 0.07416902482509613
Validation loss: 1.6432861922889628

Epoch: 5| Step: 3
Training loss: 0.07474876195192337
Validation loss: 1.6559588473330262

Epoch: 5| Step: 4
Training loss: 0.08222924172878265
Validation loss: 1.6301509282922233

Epoch: 5| Step: 5
Training loss: 0.10382868349552155
Validation loss: 1.6529306801416541

Epoch: 5| Step: 6
Training loss: 0.08983330428600311
Validation loss: 1.6587508660490795

Epoch: 5| Step: 7
Training loss: 0.06495925784111023
Validation loss: 1.6468511012292677

Epoch: 5| Step: 8
Training loss: 0.09232564270496368
Validation loss: 1.6447447551194059

Epoch: 5| Step: 9
Training loss: 0.05463053658604622
Validation loss: 1.671520266481625

Epoch: 5| Step: 10
Training loss: 0.08509484678506851
Validation loss: 1.650953399237766

Epoch: 601| Step: 0
Training loss: 0.12234722077846527
Validation loss: 1.680639023421913

Epoch: 5| Step: 1
Training loss: 0.05533454567193985
Validation loss: 1.6765949085194578

Epoch: 5| Step: 2
Training loss: 0.08913521468639374
Validation loss: 1.6634844656913512

Epoch: 5| Step: 3
Training loss: 0.06295058131217957
Validation loss: 1.6335370784164758

Epoch: 5| Step: 4
Training loss: 0.1042468398809433
Validation loss: 1.6117230717853834

Epoch: 5| Step: 5
Training loss: 0.06350331008434296
Validation loss: 1.5993245487572045

Epoch: 5| Step: 6
Training loss: 0.06414921581745148
Validation loss: 1.615594026862934

Epoch: 5| Step: 7
Training loss: 0.09701468795537949
Validation loss: 1.6187794182890205

Epoch: 5| Step: 8
Training loss: 0.0728880912065506
Validation loss: 1.6051577560363277

Epoch: 5| Step: 9
Training loss: 0.07755660265684128
Validation loss: 1.621969844705315

Epoch: 5| Step: 10
Training loss: 0.06377528607845306
Validation loss: 1.6059537574809084

Epoch: 602| Step: 0
Training loss: 0.09856712818145752
Validation loss: 1.6031690662907017

Epoch: 5| Step: 1
Training loss: 0.060401253402233124
Validation loss: 1.5942750669294787

Epoch: 5| Step: 2
Training loss: 0.072543665766716
Validation loss: 1.5776004496441092

Epoch: 5| Step: 3
Training loss: 0.12816829979419708
Validation loss: 1.6071006405738093

Epoch: 5| Step: 4
Training loss: 0.08622495830059052
Validation loss: 1.5864866850196675

Epoch: 5| Step: 5
Training loss: 0.06328336894512177
Validation loss: 1.577738029982454

Epoch: 5| Step: 6
Training loss: 0.046905823051929474
Validation loss: 1.6520408109952045

Epoch: 5| Step: 7
Training loss: 0.05632155016064644
Validation loss: 1.5910424455519645

Epoch: 5| Step: 8
Training loss: 0.06945375353097916
Validation loss: 1.5975628104261173

Epoch: 5| Step: 9
Training loss: 0.12058104574680328
Validation loss: 1.6513872261970275

Epoch: 5| Step: 10
Training loss: 0.06171642988920212
Validation loss: 1.6191329815054452

Epoch: 603| Step: 0
Training loss: 0.08647540956735611
Validation loss: 1.6044047929907357

Epoch: 5| Step: 1
Training loss: 0.055159199982881546
Validation loss: 1.6205798458027583

Epoch: 5| Step: 2
Training loss: 0.06817759573459625
Validation loss: 1.6050701525903517

Epoch: 5| Step: 3
Training loss: 0.05027792602777481
Validation loss: 1.6209706785858318

Epoch: 5| Step: 4
Training loss: 0.08115274459123611
Validation loss: 1.5768401417680966

Epoch: 5| Step: 5
Training loss: 0.0652519017457962
Validation loss: 1.6234847922478952

Epoch: 5| Step: 6
Training loss: 0.08924618363380432
Validation loss: 1.6171351273854573

Epoch: 5| Step: 7
Training loss: 0.08117612451314926
Validation loss: 1.6292443852270804

Epoch: 5| Step: 8
Training loss: 0.09305566549301147
Validation loss: 1.638502413226712

Epoch: 5| Step: 9
Training loss: 0.06775237619876862
Validation loss: 1.6344040747611754

Epoch: 5| Step: 10
Training loss: 0.04158703237771988
Validation loss: 1.6235825707835536

Epoch: 604| Step: 0
Training loss: 0.10156558454036713
Validation loss: 1.6754537282451507

Epoch: 5| Step: 1
Training loss: 0.039931729435920715
Validation loss: 1.6679252757821033

Epoch: 5| Step: 2
Training loss: 0.05879401043057442
Validation loss: 1.6940203110376995

Epoch: 5| Step: 3
Training loss: 0.11426527798175812
Validation loss: 1.6549466982964547

Epoch: 5| Step: 4
Training loss: 0.05749720335006714
Validation loss: 1.6394835800252936

Epoch: 5| Step: 5
Training loss: 0.09638051688671112
Validation loss: 1.5865755952814573

Epoch: 5| Step: 6
Training loss: 0.10879828780889511
Validation loss: 1.6116602087533602

Epoch: 5| Step: 7
Training loss: 0.05473672226071358
Validation loss: 1.5906306530839653

Epoch: 5| Step: 8
Training loss: 0.09014560282230377
Validation loss: 1.5840941603465746

Epoch: 5| Step: 9
Training loss: 0.08676482737064362
Validation loss: 1.6080889753116074

Epoch: 5| Step: 10
Training loss: 0.10834630578756332
Validation loss: 1.6061421555857505

Epoch: 605| Step: 0
Training loss: 0.06225604563951492
Validation loss: 1.6208932169022099

Epoch: 5| Step: 1
Training loss: 0.05995947867631912
Validation loss: 1.6639942494771813

Epoch: 5| Step: 2
Training loss: 0.10173114389181137
Validation loss: 1.6585687475819741

Epoch: 5| Step: 3
Training loss: 0.07477346062660217
Validation loss: 1.6731611964523152

Epoch: 5| Step: 4
Training loss: 0.08286842703819275
Validation loss: 1.7021385738926549

Epoch: 5| Step: 5
Training loss: 0.10797744989395142
Validation loss: 1.7431778254047516

Epoch: 5| Step: 6
Training loss: 0.11940856277942657
Validation loss: 1.7517294678636777

Epoch: 5| Step: 7
Training loss: 0.10295073688030243
Validation loss: 1.758168033374253

Epoch: 5| Step: 8
Training loss: 0.09448553621768951
Validation loss: 1.7336156804074523

Epoch: 5| Step: 9
Training loss: 0.0997694805264473
Validation loss: 1.6957397435301094

Epoch: 5| Step: 10
Training loss: 0.08592960983514786
Validation loss: 1.667571452356154

Epoch: 606| Step: 0
Training loss: 0.08773890137672424
Validation loss: 1.632281449533278

Epoch: 5| Step: 1
Training loss: 0.07527219504117966
Validation loss: 1.6402249413151895

Epoch: 5| Step: 2
Training loss: 0.1398371309041977
Validation loss: 1.6299384934927827

Epoch: 5| Step: 3
Training loss: 0.08055119216442108
Validation loss: 1.59684004065811

Epoch: 5| Step: 4
Training loss: 0.07737840712070465
Validation loss: 1.5999261320278209

Epoch: 5| Step: 5
Training loss: 0.0995311290025711
Validation loss: 1.5956581049068

Epoch: 5| Step: 6
Training loss: 0.09335523098707199
Validation loss: 1.6241163425548102

Epoch: 5| Step: 7
Training loss: 0.06315451860427856
Validation loss: 1.5940939726368073

Epoch: 5| Step: 8
Training loss: 0.08540357649326324
Validation loss: 1.6457386170664141

Epoch: 5| Step: 9
Training loss: 0.0758906751871109
Validation loss: 1.6398835182189941

Epoch: 5| Step: 10
Training loss: 0.07913562655448914
Validation loss: 1.657125880641322

Epoch: 607| Step: 0
Training loss: 0.05203186348080635
Validation loss: 1.6702785927762267

Epoch: 5| Step: 1
Training loss: 0.1014317125082016
Validation loss: 1.6360824543942687

Epoch: 5| Step: 2
Training loss: 0.07925579696893692
Validation loss: 1.636895090021113

Epoch: 5| Step: 3
Training loss: 0.08986862003803253
Validation loss: 1.6338537751987416

Epoch: 5| Step: 4
Training loss: 0.06274823099374771
Validation loss: 1.6320908966884817

Epoch: 5| Step: 5
Training loss: 0.050401609390974045
Validation loss: 1.6365911499146493

Epoch: 5| Step: 6
Training loss: 0.06542835384607315
Validation loss: 1.641146557305449

Epoch: 5| Step: 7
Training loss: 0.08710678666830063
Validation loss: 1.655865773077934

Epoch: 5| Step: 8
Training loss: 0.0567910373210907
Validation loss: 1.64990351405195

Epoch: 5| Step: 9
Training loss: 0.03991100192070007
Validation loss: 1.660637035164782

Epoch: 5| Step: 10
Training loss: 0.09408526867628098
Validation loss: 1.6623248182317263

Epoch: 608| Step: 0
Training loss: 0.041600801050662994
Validation loss: 1.6739394414809443

Epoch: 5| Step: 1
Training loss: 0.06310366094112396
Validation loss: 1.649347400152555

Epoch: 5| Step: 2
Training loss: 0.09103148430585861
Validation loss: 1.630772598328129

Epoch: 5| Step: 3
Training loss: 0.0973072499036789
Validation loss: 1.6594518589717087

Epoch: 5| Step: 4
Training loss: 0.10232754051685333
Validation loss: 1.6537041753850958

Epoch: 5| Step: 5
Training loss: 0.04765181243419647
Validation loss: 1.6241672692760345

Epoch: 5| Step: 6
Training loss: 0.04893425107002258
Validation loss: 1.6155079436558548

Epoch: 5| Step: 7
Training loss: 0.09612580388784409
Validation loss: 1.6119866082745213

Epoch: 5| Step: 8
Training loss: 0.07367359101772308
Validation loss: 1.596676465003721

Epoch: 5| Step: 9
Training loss: 0.05025315284729004
Validation loss: 1.59815840823676

Epoch: 5| Step: 10
Training loss: 0.10593651235103607
Validation loss: 1.5947849481336531

Epoch: 609| Step: 0
Training loss: 0.060908712446689606
Validation loss: 1.6045237689889886

Epoch: 5| Step: 1
Training loss: 0.0815114974975586
Validation loss: 1.5932601985111032

Epoch: 5| Step: 2
Training loss: 0.07855930179357529
Validation loss: 1.5932077566782634

Epoch: 5| Step: 3
Training loss: 0.11303160339593887
Validation loss: 1.6121079255175847

Epoch: 5| Step: 4
Training loss: 0.06855521351099014
Validation loss: 1.550683540682639

Epoch: 5| Step: 5
Training loss: 0.06849844753742218
Validation loss: 1.597917502926242

Epoch: 5| Step: 6
Training loss: 0.051302719861269
Validation loss: 1.5910881283462688

Epoch: 5| Step: 7
Training loss: 0.08081622421741486
Validation loss: 1.600268889498967

Epoch: 5| Step: 8
Training loss: 0.05289224535226822
Validation loss: 1.5824529714481805

Epoch: 5| Step: 9
Training loss: 0.09921924769878387
Validation loss: 1.6245010937413862

Epoch: 5| Step: 10
Training loss: 0.05348123982548714
Validation loss: 1.6048366972195205

Epoch: 610| Step: 0
Training loss: 0.0654558539390564
Validation loss: 1.6405686486151911

Epoch: 5| Step: 1
Training loss: 0.07102598249912262
Validation loss: 1.6275471115625033

Epoch: 5| Step: 2
Training loss: 0.0930718332529068
Validation loss: 1.6127102592939973

Epoch: 5| Step: 3
Training loss: 0.06359517574310303
Validation loss: 1.6615358526988695

Epoch: 5| Step: 4
Training loss: 0.07646847516298294
Validation loss: 1.6311650571002756

Epoch: 5| Step: 5
Training loss: 0.06372449547052383
Validation loss: 1.6262092513422812

Epoch: 5| Step: 6
Training loss: 0.12928342819213867
Validation loss: 1.6065306458421933

Epoch: 5| Step: 7
Training loss: 0.0747750923037529
Validation loss: 1.6118028087000693

Epoch: 5| Step: 8
Training loss: 0.07361986488103867
Validation loss: 1.605753356410611

Epoch: 5| Step: 9
Training loss: 0.046820659190416336
Validation loss: 1.595967528640583

Epoch: 5| Step: 10
Training loss: 0.06670179218053818
Validation loss: 1.588472943793061

Epoch: 611| Step: 0
Training loss: 0.05247843265533447
Validation loss: 1.5954619402526526

Epoch: 5| Step: 1
Training loss: 0.10495153814554214
Validation loss: 1.5479016714198615

Epoch: 5| Step: 2
Training loss: 0.05526575446128845
Validation loss: 1.570642348258726

Epoch: 5| Step: 3
Training loss: 0.0716109499335289
Validation loss: 1.5797043692681096

Epoch: 5| Step: 4
Training loss: 0.08642908185720444
Validation loss: 1.5867952505747478

Epoch: 5| Step: 5
Training loss: 0.11017914116382599
Validation loss: 1.5669543089405182

Epoch: 5| Step: 6
Training loss: 0.09440389275550842
Validation loss: 1.571653401979836

Epoch: 5| Step: 7
Training loss: 0.08016426861286163
Validation loss: 1.5796822219766595

Epoch: 5| Step: 8
Training loss: 0.06491216272115707
Validation loss: 1.6085295766912482

Epoch: 5| Step: 9
Training loss: 0.0796440988779068
Validation loss: 1.6513768498615553

Epoch: 5| Step: 10
Training loss: 0.066403329372406
Validation loss: 1.6520896227129045

Epoch: 612| Step: 0
Training loss: 0.0929584950208664
Validation loss: 1.6420860892982894

Epoch: 5| Step: 1
Training loss: 0.08164498209953308
Validation loss: 1.6539249573984454

Epoch: 5| Step: 2
Training loss: 0.05981408804655075
Validation loss: 1.5865010651209022

Epoch: 5| Step: 3
Training loss: 0.0695190280675888
Validation loss: 1.5727912661849812

Epoch: 5| Step: 4
Training loss: 0.09960703551769257
Validation loss: 1.5506632315215243

Epoch: 5| Step: 5
Training loss: 0.12021224200725555
Validation loss: 1.5630866378866217

Epoch: 5| Step: 6
Training loss: 0.1402851641178131
Validation loss: 1.5459370933553225

Epoch: 5| Step: 7
Training loss: 0.13472287356853485
Validation loss: 1.5852814976887037

Epoch: 5| Step: 8
Training loss: 0.10608808696269989
Validation loss: 1.5545065377348213

Epoch: 5| Step: 9
Training loss: 0.08785565197467804
Validation loss: 1.5539596414053312

Epoch: 5| Step: 10
Training loss: 0.10475986450910568
Validation loss: 1.5763729131349953

Epoch: 613| Step: 0
Training loss: 0.06757567822933197
Validation loss: 1.5898689377692439

Epoch: 5| Step: 1
Training loss: 0.061768077313899994
Validation loss: 1.6156430769992132

Epoch: 5| Step: 2
Training loss: 0.0798906460404396
Validation loss: 1.6524403479791456

Epoch: 5| Step: 3
Training loss: 0.11965620517730713
Validation loss: 1.665392142470165

Epoch: 5| Step: 4
Training loss: 0.10685600340366364
Validation loss: 1.7044422395767704

Epoch: 5| Step: 5
Training loss: 0.07594434916973114
Validation loss: 1.7019849849003617

Epoch: 5| Step: 6
Training loss: 0.10328865051269531
Validation loss: 1.6806571957885579

Epoch: 5| Step: 7
Training loss: 0.061234183609485626
Validation loss: 1.6605097875800183

Epoch: 5| Step: 8
Training loss: 0.07157699763774872
Validation loss: 1.6735035027227094

Epoch: 5| Step: 9
Training loss: 0.0968293696641922
Validation loss: 1.661816184238721

Epoch: 5| Step: 10
Training loss: 0.10646549612283707
Validation loss: 1.6487294089409612

Epoch: 614| Step: 0
Training loss: 0.06750917434692383
Validation loss: 1.6370563853171565

Epoch: 5| Step: 1
Training loss: 0.07721011340618134
Validation loss: 1.6380610645458262

Epoch: 5| Step: 2
Training loss: 0.131395623087883
Validation loss: 1.6054554972597348

Epoch: 5| Step: 3
Training loss: 0.06954233348369598
Validation loss: 1.6038967601714595

Epoch: 5| Step: 4
Training loss: 0.07557980716228485
Validation loss: 1.6051758399573706

Epoch: 5| Step: 5
Training loss: 0.06410986930131912
Validation loss: 1.581575673113587

Epoch: 5| Step: 6
Training loss: 0.05695418268442154
Validation loss: 1.6139079242624261

Epoch: 5| Step: 7
Training loss: 0.0889052152633667
Validation loss: 1.5794714317526868

Epoch: 5| Step: 8
Training loss: 0.1144193559885025
Validation loss: 1.602101631062005

Epoch: 5| Step: 9
Training loss: 0.09660955518484116
Validation loss: 1.5745776571253294

Epoch: 5| Step: 10
Training loss: 0.06314881891012192
Validation loss: 1.5957205090471493

Epoch: 615| Step: 0
Training loss: 0.06457295268774033
Validation loss: 1.6074008275103826

Epoch: 5| Step: 1
Training loss: 0.07871908694505692
Validation loss: 1.615275006140432

Epoch: 5| Step: 2
Training loss: 0.050638336688280106
Validation loss: 1.606138590843447

Epoch: 5| Step: 3
Training loss: 0.06871934235095978
Validation loss: 1.599688946559865

Epoch: 5| Step: 4
Training loss: 0.06729685515165329
Validation loss: 1.6148326948124876

Epoch: 5| Step: 5
Training loss: 0.06743760406970978
Validation loss: 1.569595475350657

Epoch: 5| Step: 6
Training loss: 0.09465451538562775
Validation loss: 1.5650817348111061

Epoch: 5| Step: 7
Training loss: 0.12283674627542496
Validation loss: 1.5693283388691563

Epoch: 5| Step: 8
Training loss: 0.10825464874505997
Validation loss: 1.5595277278654036

Epoch: 5| Step: 9
Training loss: 0.06222246214747429
Validation loss: 1.5518553180079306

Epoch: 5| Step: 10
Training loss: 0.04905489459633827
Validation loss: 1.5632117538041965

Epoch: 616| Step: 0
Training loss: 0.08209826052188873
Validation loss: 1.587819081480785

Epoch: 5| Step: 1
Training loss: 0.055315516889095306
Validation loss: 1.5878732614619757

Epoch: 5| Step: 2
Training loss: 0.08856651932001114
Validation loss: 1.6088136447373258

Epoch: 5| Step: 3
Training loss: 0.09929011017084122
Validation loss: 1.6219436865980907

Epoch: 5| Step: 4
Training loss: 0.09025005251169205
Validation loss: 1.5918112595876057

Epoch: 5| Step: 5
Training loss: 0.0727003738284111
Validation loss: 1.65006576302231

Epoch: 5| Step: 6
Training loss: 0.1679583489894867
Validation loss: 1.6566571022874566

Epoch: 5| Step: 7
Training loss: 0.0659060999751091
Validation loss: 1.6361031275923534

Epoch: 5| Step: 8
Training loss: 0.05832727625966072
Validation loss: 1.6015162673047794

Epoch: 5| Step: 9
Training loss: 0.0643884688615799
Validation loss: 1.6421476769190964

Epoch: 5| Step: 10
Training loss: 0.07949574291706085
Validation loss: 1.6215500703421972

Epoch: 617| Step: 0
Training loss: 0.0748567059636116
Validation loss: 1.5900550644884828

Epoch: 5| Step: 1
Training loss: 0.06010463088750839
Validation loss: 1.5941540400187175

Epoch: 5| Step: 2
Training loss: 0.07632321119308472
Validation loss: 1.631173127440996

Epoch: 5| Step: 3
Training loss: 0.08317714929580688
Validation loss: 1.6115205621206632

Epoch: 5| Step: 4
Training loss: 0.0958748310804367
Validation loss: 1.587714059378511

Epoch: 5| Step: 5
Training loss: 0.09111177921295166
Validation loss: 1.598962115985091

Epoch: 5| Step: 6
Training loss: 0.0884619802236557
Validation loss: 1.6281091692627117

Epoch: 5| Step: 7
Training loss: 0.06653978675603867
Validation loss: 1.5875272315035585

Epoch: 5| Step: 8
Training loss: 0.10122847557067871
Validation loss: 1.6237398629547448

Epoch: 5| Step: 9
Training loss: 0.047294896095991135
Validation loss: 1.6542515344517206

Epoch: 5| Step: 10
Training loss: 0.07810524851083755
Validation loss: 1.6833301487789358

Epoch: 618| Step: 0
Training loss: 0.11879533529281616
Validation loss: 1.6970484000380321

Epoch: 5| Step: 1
Training loss: 0.0913996547460556
Validation loss: 1.6881820950456845

Epoch: 5| Step: 2
Training loss: 0.07179230451583862
Validation loss: 1.6684489698820217

Epoch: 5| Step: 3
Training loss: 0.0582738034427166
Validation loss: 1.6637282166429745

Epoch: 5| Step: 4
Training loss: 0.09283366799354553
Validation loss: 1.6521917773831276

Epoch: 5| Step: 5
Training loss: 0.0672152116894722
Validation loss: 1.641821744621441

Epoch: 5| Step: 6
Training loss: 0.05863718315958977
Validation loss: 1.6244786452221613

Epoch: 5| Step: 7
Training loss: 0.09839484840631485
Validation loss: 1.5986905097961426

Epoch: 5| Step: 8
Training loss: 0.07400251924991608
Validation loss: 1.6043064273813719

Epoch: 5| Step: 9
Training loss: 0.08805285394191742
Validation loss: 1.5819339688106249

Epoch: 5| Step: 10
Training loss: 0.08198858797550201
Validation loss: 1.585004606554585

Epoch: 619| Step: 0
Training loss: 0.060616590082645416
Validation loss: 1.6125662224267119

Epoch: 5| Step: 1
Training loss: 0.1159369945526123
Validation loss: 1.6152938796627907

Epoch: 5| Step: 2
Training loss: 0.06370256841182709
Validation loss: 1.627070257740636

Epoch: 5| Step: 3
Training loss: 0.07568778097629547
Validation loss: 1.6502856926251483

Epoch: 5| Step: 4
Training loss: 0.08807715773582458
Validation loss: 1.651217729814591

Epoch: 5| Step: 5
Training loss: 0.11180548369884491
Validation loss: 1.714977474622829

Epoch: 5| Step: 6
Training loss: 0.11703908443450928
Validation loss: 1.7118960401063323

Epoch: 5| Step: 7
Training loss: 0.12777376174926758
Validation loss: 1.7183399200439453

Epoch: 5| Step: 8
Training loss: 0.12830521166324615
Validation loss: 1.6992034783927343

Epoch: 5| Step: 9
Training loss: 0.05730525404214859
Validation loss: 1.695697876714891

Epoch: 5| Step: 10
Training loss: 0.0991179347038269
Validation loss: 1.6698923649326447

Epoch: 620| Step: 0
Training loss: 0.08074042201042175
Validation loss: 1.659150783733655

Epoch: 5| Step: 1
Training loss: 0.12404842674732208
Validation loss: 1.632270234887318

Epoch: 5| Step: 2
Training loss: 0.1194625049829483
Validation loss: 1.6110574417216803

Epoch: 5| Step: 3
Training loss: 0.10477826744318008
Validation loss: 1.5866244685265325

Epoch: 5| Step: 4
Training loss: 0.10483603179454803
Validation loss: 1.6374866295886297

Epoch: 5| Step: 5
Training loss: 0.06631183624267578
Validation loss: 1.5915695621121315

Epoch: 5| Step: 6
Training loss: 0.08114936202764511
Validation loss: 1.6536453872598627

Epoch: 5| Step: 7
Training loss: 0.1017773374915123
Validation loss: 1.6307013316821026

Epoch: 5| Step: 8
Training loss: 0.07118141651153564
Validation loss: 1.627185049877372

Epoch: 5| Step: 9
Training loss: 0.09513168781995773
Validation loss: 1.6533237247056858

Epoch: 5| Step: 10
Training loss: 0.1169135719537735
Validation loss: 1.6649815510678034

Epoch: 621| Step: 0
Training loss: 0.11887399852275848
Validation loss: 1.6665402625196724

Epoch: 5| Step: 1
Training loss: 0.07188082486391068
Validation loss: 1.649435056153164

Epoch: 5| Step: 2
Training loss: 0.06516189873218536
Validation loss: 1.6324994589692803

Epoch: 5| Step: 3
Training loss: 0.07108409702777863
Validation loss: 1.638635878921837

Epoch: 5| Step: 4
Training loss: 0.0729983001947403
Validation loss: 1.6312740156727452

Epoch: 5| Step: 5
Training loss: 0.07421716302633286
Validation loss: 1.6307935868540118

Epoch: 5| Step: 6
Training loss: 0.06412103027105331
Validation loss: 1.6566689565617552

Epoch: 5| Step: 7
Training loss: 0.0988035649061203
Validation loss: 1.6553409048306045

Epoch: 5| Step: 8
Training loss: 0.09827135503292084
Validation loss: 1.6068637960700578

Epoch: 5| Step: 9
Training loss: 0.0696670189499855
Validation loss: 1.6253811338896393

Epoch: 5| Step: 10
Training loss: 0.10261986404657364
Validation loss: 1.5991224229976695

Epoch: 622| Step: 0
Training loss: 0.06022864580154419
Validation loss: 1.6291387132419053

Epoch: 5| Step: 1
Training loss: 0.09671657532453537
Validation loss: 1.62901948600687

Epoch: 5| Step: 2
Training loss: 0.06257389485836029
Validation loss: 1.6427323401615184

Epoch: 5| Step: 3
Training loss: 0.10804369300603867
Validation loss: 1.599034252987113

Epoch: 5| Step: 4
Training loss: 0.08599269390106201
Validation loss: 1.6202090453076106

Epoch: 5| Step: 5
Training loss: 0.06506861001253128
Validation loss: 1.6001667809742752

Epoch: 5| Step: 6
Training loss: 0.06338296830654144
Validation loss: 1.6227394227058656

Epoch: 5| Step: 7
Training loss: 0.10832609981298447
Validation loss: 1.5942652020403134

Epoch: 5| Step: 8
Training loss: 0.07008405029773712
Validation loss: 1.5884903195083782

Epoch: 5| Step: 9
Training loss: 0.05087580159306526
Validation loss: 1.5918119069068664

Epoch: 5| Step: 10
Training loss: 0.10776764154434204
Validation loss: 1.6325396542908044

Epoch: 623| Step: 0
Training loss: 0.11664922535419464
Validation loss: 1.618285322061149

Epoch: 5| Step: 1
Training loss: 0.08707214891910553
Validation loss: 1.6077556610107422

Epoch: 5| Step: 2
Training loss: 0.058941710740327835
Validation loss: 1.5906777625442834

Epoch: 5| Step: 3
Training loss: 0.0835665613412857
Validation loss: 1.6174317521433677

Epoch: 5| Step: 4
Training loss: 0.08224411308765411
Validation loss: 1.6090392284495856

Epoch: 5| Step: 5
Training loss: 0.09554515033960342
Validation loss: 1.6300073503166117

Epoch: 5| Step: 6
Training loss: 0.09242214262485504
Validation loss: 1.6320013256483181

Epoch: 5| Step: 7
Training loss: 0.05846847966313362
Validation loss: 1.617605673369541

Epoch: 5| Step: 8
Training loss: 0.05684604495763779
Validation loss: 1.6287651728558283

Epoch: 5| Step: 9
Training loss: 0.05054836347699165
Validation loss: 1.6190821252843386

Epoch: 5| Step: 10
Training loss: 0.11477833241224289
Validation loss: 1.6247513345492783

Epoch: 624| Step: 0
Training loss: 0.08344145119190216
Validation loss: 1.6155712655795518

Epoch: 5| Step: 1
Training loss: 0.0879141315817833
Validation loss: 1.6146540923785138

Epoch: 5| Step: 2
Training loss: 0.06582512706518173
Validation loss: 1.6274523811955606

Epoch: 5| Step: 3
Training loss: 0.059418629854917526
Validation loss: 1.6164221943065684

Epoch: 5| Step: 4
Training loss: 0.10989594459533691
Validation loss: 1.5824721436346731

Epoch: 5| Step: 5
Training loss: 0.07602546364068985
Validation loss: 1.5878425157198341

Epoch: 5| Step: 6
Training loss: 0.14410650730133057
Validation loss: 1.5809189465738112

Epoch: 5| Step: 7
Training loss: 0.04637319967150688
Validation loss: 1.6148422213010891

Epoch: 5| Step: 8
Training loss: 0.10235689580440521
Validation loss: 1.578092622500594

Epoch: 5| Step: 9
Training loss: 0.14338207244873047
Validation loss: 1.604348995352304

Epoch: 5| Step: 10
Training loss: 0.0803106278181076
Validation loss: 1.6041983583922028

Epoch: 625| Step: 0
Training loss: 0.04850738123059273
Validation loss: 1.5959642587169525

Epoch: 5| Step: 1
Training loss: 0.06231030076742172
Validation loss: 1.6051332437863914

Epoch: 5| Step: 2
Training loss: 0.05069870874285698
Validation loss: 1.6009753750216575

Epoch: 5| Step: 3
Training loss: 0.08354469388723373
Validation loss: 1.594379175093866

Epoch: 5| Step: 4
Training loss: 0.07687200605869293
Validation loss: 1.5947787018232449

Epoch: 5| Step: 5
Training loss: 0.06315113604068756
Validation loss: 1.5949139005394393

Epoch: 5| Step: 6
Training loss: 0.11517424881458282
Validation loss: 1.6242914802284651

Epoch: 5| Step: 7
Training loss: 0.076434426009655
Validation loss: 1.662283101389485

Epoch: 5| Step: 8
Training loss: 0.11100729554891586
Validation loss: 1.6343468094384799

Epoch: 5| Step: 9
Training loss: 0.14190471172332764
Validation loss: 1.6785840693340506

Epoch: 5| Step: 10
Training loss: 0.07444591820240021
Validation loss: 1.639609606035294

Epoch: 626| Step: 0
Training loss: 0.05603306367993355
Validation loss: 1.6933174274301017

Epoch: 5| Step: 1
Training loss: 0.03802623227238655
Validation loss: 1.6619939778440742

Epoch: 5| Step: 2
Training loss: 0.06468214094638824
Validation loss: 1.6830413649159093

Epoch: 5| Step: 3
Training loss: 0.09415778517723083
Validation loss: 1.6592667833451302

Epoch: 5| Step: 4
Training loss: 0.08063336461782455
Validation loss: 1.6236200871006135

Epoch: 5| Step: 5
Training loss: 0.08997171372175217
Validation loss: 1.6444893972848051

Epoch: 5| Step: 6
Training loss: 0.06107660382986069
Validation loss: 1.6324728611976869

Epoch: 5| Step: 7
Training loss: 0.054474640637636185
Validation loss: 1.6458177515255508

Epoch: 5| Step: 8
Training loss: 0.06754420697689056
Validation loss: 1.6178066204952937

Epoch: 5| Step: 9
Training loss: 0.10281304270029068
Validation loss: 1.6036062971238167

Epoch: 5| Step: 10
Training loss: 0.0904553234577179
Validation loss: 1.6134142593670917

Epoch: 627| Step: 0
Training loss: 0.06779147684574127
Validation loss: 1.6068189797862884

Epoch: 5| Step: 1
Training loss: 0.06643782556056976
Validation loss: 1.6012380302593272

Epoch: 5| Step: 2
Training loss: 0.10049571841955185
Validation loss: 1.6098459215574368

Epoch: 5| Step: 3
Training loss: 0.08799974620342255
Validation loss: 1.6413238958645893

Epoch: 5| Step: 4
Training loss: 0.059323377907276154
Validation loss: 1.6461491148958924

Epoch: 5| Step: 5
Training loss: 0.09510965645313263
Validation loss: 1.643255982347714

Epoch: 5| Step: 6
Training loss: 0.09410405904054642
Validation loss: 1.6442327807026524

Epoch: 5| Step: 7
Training loss: 0.05336727946996689
Validation loss: 1.6515500801865772

Epoch: 5| Step: 8
Training loss: 0.08554636687040329
Validation loss: 1.6383190103756484

Epoch: 5| Step: 9
Training loss: 0.05232229828834534
Validation loss: 1.6378619414503857

Epoch: 5| Step: 10
Training loss: 0.03944092243909836
Validation loss: 1.6339650179750176

Epoch: 628| Step: 0
Training loss: 0.07617195695638657
Validation loss: 1.6039339368061354

Epoch: 5| Step: 1
Training loss: 0.07905055582523346
Validation loss: 1.6128418522496377

Epoch: 5| Step: 2
Training loss: 0.05520740896463394
Validation loss: 1.6182344139263194

Epoch: 5| Step: 3
Training loss: 0.05521121621131897
Validation loss: 1.6418249453267744

Epoch: 5| Step: 4
Training loss: 0.08251962810754776
Validation loss: 1.6226601959556661

Epoch: 5| Step: 5
Training loss: 0.06716129928827286
Validation loss: 1.6455599390050417

Epoch: 5| Step: 6
Training loss: 0.09368865191936493
Validation loss: 1.619745982590542

Epoch: 5| Step: 7
Training loss: 0.08386795967817307
Validation loss: 1.6205184049503778

Epoch: 5| Step: 8
Training loss: 0.06350312381982803
Validation loss: 1.621741593524974

Epoch: 5| Step: 9
Training loss: 0.08121858537197113
Validation loss: 1.6427707313209452

Epoch: 5| Step: 10
Training loss: 0.06850062310695648
Validation loss: 1.6409070543063584

Epoch: 629| Step: 0
Training loss: 0.06567168980836868
Validation loss: 1.6542476530997985

Epoch: 5| Step: 1
Training loss: 0.06425116956233978
Validation loss: 1.6439991074223672

Epoch: 5| Step: 2
Training loss: 0.05264263227581978
Validation loss: 1.653113736901232

Epoch: 5| Step: 3
Training loss: 0.08831346035003662
Validation loss: 1.6459364455233338

Epoch: 5| Step: 4
Training loss: 0.09687194973230362
Validation loss: 1.6638270103803245

Epoch: 5| Step: 5
Training loss: 0.0591546967625618
Validation loss: 1.6861867007388864

Epoch: 5| Step: 6
Training loss: 0.06916282325983047
Validation loss: 1.6737569826905445

Epoch: 5| Step: 7
Training loss: 0.05775605887174606
Validation loss: 1.6282070048393742

Epoch: 5| Step: 8
Training loss: 0.07212266325950623
Validation loss: 1.6422197575210242

Epoch: 5| Step: 9
Training loss: 0.11553192138671875
Validation loss: 1.6384607002299318

Epoch: 5| Step: 10
Training loss: 0.11752905696630478
Validation loss: 1.6597565553521598

Epoch: 630| Step: 0
Training loss: 0.05951061099767685
Validation loss: 1.626124361509918

Epoch: 5| Step: 1
Training loss: 0.07906443625688553
Validation loss: 1.6269035993083831

Epoch: 5| Step: 2
Training loss: 0.05883068963885307
Validation loss: 1.6513859571949128

Epoch: 5| Step: 3
Training loss: 0.08437798917293549
Validation loss: 1.6561942305616153

Epoch: 5| Step: 4
Training loss: 0.05765072628855705
Validation loss: 1.6626136161947762

Epoch: 5| Step: 5
Training loss: 0.08950648456811905
Validation loss: 1.6338250226871942

Epoch: 5| Step: 6
Training loss: 0.08937864005565643
Validation loss: 1.6101117595549552

Epoch: 5| Step: 7
Training loss: 0.08926792442798615
Validation loss: 1.6412821764587073

Epoch: 5| Step: 8
Training loss: 0.0901150181889534
Validation loss: 1.639033584184544

Epoch: 5| Step: 9
Training loss: 0.07324180006980896
Validation loss: 1.614328420290383

Epoch: 5| Step: 10
Training loss: 0.05958119407296181
Validation loss: 1.6439704228472967

Epoch: 631| Step: 0
Training loss: 0.06160770729184151
Validation loss: 1.6372612163584719

Epoch: 5| Step: 1
Training loss: 0.07506310194730759
Validation loss: 1.640757345384167

Epoch: 5| Step: 2
Training loss: 0.06329236924648285
Validation loss: 1.6365447480191466

Epoch: 5| Step: 3
Training loss: 0.09229627996683121
Validation loss: 1.635684226148872

Epoch: 5| Step: 4
Training loss: 0.05766202136874199
Validation loss: 1.5968439963556105

Epoch: 5| Step: 5
Training loss: 0.08041437715291977
Validation loss: 1.5710818459910731

Epoch: 5| Step: 6
Training loss: 0.06995917856693268
Validation loss: 1.59925324942476

Epoch: 5| Step: 7
Training loss: 0.08343899250030518
Validation loss: 1.6116581283589846

Epoch: 5| Step: 8
Training loss: 0.09881079196929932
Validation loss: 1.645007300120528

Epoch: 5| Step: 9
Training loss: 0.06655657291412354
Validation loss: 1.6043644489780549

Epoch: 5| Step: 10
Training loss: 0.055562179535627365
Validation loss: 1.638082750381962

Epoch: 632| Step: 0
Training loss: 0.10319056361913681
Validation loss: 1.630373586890518

Epoch: 5| Step: 1
Training loss: 0.06883925944566727
Validation loss: 1.629619618897797

Epoch: 5| Step: 2
Training loss: 0.06819131225347519
Validation loss: 1.5881694850101267

Epoch: 5| Step: 3
Training loss: 0.06414254009723663
Validation loss: 1.628169112308051

Epoch: 5| Step: 4
Training loss: 0.07856102287769318
Validation loss: 1.5750665587763633

Epoch: 5| Step: 5
Training loss: 0.06412913650274277
Validation loss: 1.5879865846326273

Epoch: 5| Step: 6
Training loss: 0.07932133972644806
Validation loss: 1.5881756762022614

Epoch: 5| Step: 7
Training loss: 0.06734997034072876
Validation loss: 1.6015864841399654

Epoch: 5| Step: 8
Training loss: 0.055205099284648895
Validation loss: 1.607070352441521

Epoch: 5| Step: 9
Training loss: 0.07408595085144043
Validation loss: 1.5952448255272322

Epoch: 5| Step: 10
Training loss: 0.07731428742408752
Validation loss: 1.5915301717737669

Epoch: 633| Step: 0
Training loss: 0.04873430356383324
Validation loss: 1.562967336306008

Epoch: 5| Step: 1
Training loss: 0.06625264883041382
Validation loss: 1.6383100299425022

Epoch: 5| Step: 2
Training loss: 0.06771238893270493
Validation loss: 1.628059192370343

Epoch: 5| Step: 3
Training loss: 0.058639757335186005
Validation loss: 1.649850167253966

Epoch: 5| Step: 4
Training loss: 0.07781719416379929
Validation loss: 1.63680007637188

Epoch: 5| Step: 5
Training loss: 0.0887402892112732
Validation loss: 1.6478623754234725

Epoch: 5| Step: 6
Training loss: 0.07192226499319077
Validation loss: 1.6414873394914853

Epoch: 5| Step: 7
Training loss: 0.1052272766828537
Validation loss: 1.6561974171669251

Epoch: 5| Step: 8
Training loss: 0.04808676987886429
Validation loss: 1.6379385725144417

Epoch: 5| Step: 9
Training loss: 0.09906742721796036
Validation loss: 1.6201871351529193

Epoch: 5| Step: 10
Training loss: 0.03945758938789368
Validation loss: 1.6092048345073577

Epoch: 634| Step: 0
Training loss: 0.04722651466727257
Validation loss: 1.6060528627005957

Epoch: 5| Step: 1
Training loss: 0.05216263607144356
Validation loss: 1.566285047479855

Epoch: 5| Step: 2
Training loss: 0.09826632589101791
Validation loss: 1.5738823285666845

Epoch: 5| Step: 3
Training loss: 0.09000630676746368
Validation loss: 1.5889732953040832

Epoch: 5| Step: 4
Training loss: 0.05069386959075928
Validation loss: 1.5757567690264793

Epoch: 5| Step: 5
Training loss: 0.06473227590322495
Validation loss: 1.5759577904978106

Epoch: 5| Step: 6
Training loss: 0.04582725092768669
Validation loss: 1.5684897822718467

Epoch: 5| Step: 7
Training loss: 0.07050786912441254
Validation loss: 1.5764505260734147

Epoch: 5| Step: 8
Training loss: 0.09390329569578171
Validation loss: 1.6119345541923278

Epoch: 5| Step: 9
Training loss: 0.09067149460315704
Validation loss: 1.5692155361175537

Epoch: 5| Step: 10
Training loss: 0.08908665925264359
Validation loss: 1.5977545707456526

Epoch: 635| Step: 0
Training loss: 0.07298658788204193
Validation loss: 1.5980719802200154

Epoch: 5| Step: 1
Training loss: 0.06940142810344696
Validation loss: 1.6003116766611736

Epoch: 5| Step: 2
Training loss: 0.07023273408412933
Validation loss: 1.6051024134441088

Epoch: 5| Step: 3
Training loss: 0.08297953754663467
Validation loss: 1.614363863903989

Epoch: 5| Step: 4
Training loss: 0.04374167323112488
Validation loss: 1.5950849120334913

Epoch: 5| Step: 5
Training loss: 0.07895686477422714
Validation loss: 1.6074604142096736

Epoch: 5| Step: 6
Training loss: 0.09617457538843155
Validation loss: 1.609975730219195

Epoch: 5| Step: 7
Training loss: 0.08973036706447601
Validation loss: 1.5968674075218938

Epoch: 5| Step: 8
Training loss: 0.06869965046644211
Validation loss: 1.5807473031423425

Epoch: 5| Step: 9
Training loss: 0.08877549320459366
Validation loss: 1.5673942745372813

Epoch: 5| Step: 10
Training loss: 0.07322166115045547
Validation loss: 1.5685148495499805

Epoch: 636| Step: 0
Training loss: 0.08661938458681107
Validation loss: 1.6016492292445192

Epoch: 5| Step: 1
Training loss: 0.10263612121343613
Validation loss: 1.6233554065868419

Epoch: 5| Step: 2
Training loss: 0.08812731504440308
Validation loss: 1.614268115771714

Epoch: 5| Step: 3
Training loss: 0.08852305263280869
Validation loss: 1.623290454187701

Epoch: 5| Step: 4
Training loss: 0.084821417927742
Validation loss: 1.627989617727136

Epoch: 5| Step: 5
Training loss: 0.08460506051778793
Validation loss: 1.6366996265226794

Epoch: 5| Step: 6
Training loss: 0.0850754827260971
Validation loss: 1.6613127262361589

Epoch: 5| Step: 7
Training loss: 0.09110553562641144
Validation loss: 1.624938649515952

Epoch: 5| Step: 8
Training loss: 0.0790330022573471
Validation loss: 1.629101917307864

Epoch: 5| Step: 9
Training loss: 0.07347323000431061
Validation loss: 1.6467540046220184

Epoch: 5| Step: 10
Training loss: 0.0985928550362587
Validation loss: 1.6483946449013167

Epoch: 637| Step: 0
Training loss: 0.12052037566900253
Validation loss: 1.5863836849889448

Epoch: 5| Step: 1
Training loss: 0.06539099663496017
Validation loss: 1.5750641104995564

Epoch: 5| Step: 2
Training loss: 0.06693108379840851
Validation loss: 1.5874561340578142

Epoch: 5| Step: 3
Training loss: 0.06311091780662537
Validation loss: 1.6083748238061064

Epoch: 5| Step: 4
Training loss: 0.06949865818023682
Validation loss: 1.6146362173941828

Epoch: 5| Step: 5
Training loss: 0.05393779277801514
Validation loss: 1.5885104479328278

Epoch: 5| Step: 6
Training loss: 0.11632859706878662
Validation loss: 1.6378453982773649

Epoch: 5| Step: 7
Training loss: 0.05470384284853935
Validation loss: 1.6122375662608812

Epoch: 5| Step: 8
Training loss: 0.105088971555233
Validation loss: 1.617590376125869

Epoch: 5| Step: 9
Training loss: 0.0677926167845726
Validation loss: 1.6045572078356178

Epoch: 5| Step: 10
Training loss: 0.10750611871480942
Validation loss: 1.6247529278519333

Epoch: 638| Step: 0
Training loss: 0.08111879974603653
Validation loss: 1.5970134850471251

Epoch: 5| Step: 1
Training loss: 0.06518810242414474
Validation loss: 1.6072283162865588

Epoch: 5| Step: 2
Training loss: 0.0557364746928215
Validation loss: 1.60589087265794

Epoch: 5| Step: 3
Training loss: 0.06310774385929108
Validation loss: 1.623673944063084

Epoch: 5| Step: 4
Training loss: 0.0685805082321167
Validation loss: 1.605005943646995

Epoch: 5| Step: 5
Training loss: 0.04779892414808273
Validation loss: 1.58200877968983

Epoch: 5| Step: 6
Training loss: 0.0711415708065033
Validation loss: 1.5983632700417632

Epoch: 5| Step: 7
Training loss: 0.09105844050645828
Validation loss: 1.6222448246453398

Epoch: 5| Step: 8
Training loss: 0.10875992476940155
Validation loss: 1.6287418539806078

Epoch: 5| Step: 9
Training loss: 0.09809719026088715
Validation loss: 1.637914816538493

Epoch: 5| Step: 10
Training loss: 0.07266741991043091
Validation loss: 1.6489886506911247

Epoch: 639| Step: 0
Training loss: 0.06600890308618546
Validation loss: 1.6269225279490154

Epoch: 5| Step: 1
Training loss: 0.11169949918985367
Validation loss: 1.629544077381011

Epoch: 5| Step: 2
Training loss: 0.047342460602521896
Validation loss: 1.6414624414136332

Epoch: 5| Step: 3
Training loss: 0.08884644508361816
Validation loss: 1.6360593675285258

Epoch: 5| Step: 4
Training loss: 0.06393291801214218
Validation loss: 1.6354121309454723

Epoch: 5| Step: 5
Training loss: 0.05547384172677994
Validation loss: 1.653847639278699

Epoch: 5| Step: 6
Training loss: 0.06825290620326996
Validation loss: 1.658610607988091

Epoch: 5| Step: 7
Training loss: 0.08783173561096191
Validation loss: 1.6670072719614992

Epoch: 5| Step: 8
Training loss: 0.09115031361579895
Validation loss: 1.6219753764008964

Epoch: 5| Step: 9
Training loss: 0.08557341992855072
Validation loss: 1.6146066727176789

Epoch: 5| Step: 10
Training loss: 0.0761372372508049
Validation loss: 1.6045082128176125

Epoch: 640| Step: 0
Training loss: 0.05104459077119827
Validation loss: 1.5963341395060222

Epoch: 5| Step: 1
Training loss: 0.060856737196445465
Validation loss: 1.5661662746501226

Epoch: 5| Step: 2
Training loss: 0.09332466125488281
Validation loss: 1.568907973586872

Epoch: 5| Step: 3
Training loss: 0.06745560467243195
Validation loss: 1.5688966435770835

Epoch: 5| Step: 4
Training loss: 0.10155079513788223
Validation loss: 1.5938997909586916

Epoch: 5| Step: 5
Training loss: 0.061960816383361816
Validation loss: 1.5909221569697063

Epoch: 5| Step: 6
Training loss: 0.07704875618219376
Validation loss: 1.6157756159382481

Epoch: 5| Step: 7
Training loss: 0.09007500112056732
Validation loss: 1.643392239847491

Epoch: 5| Step: 8
Training loss: 0.09136979281902313
Validation loss: 1.6403835063339562

Epoch: 5| Step: 9
Training loss: 0.11092813313007355
Validation loss: 1.645552812084075

Epoch: 5| Step: 10
Training loss: 0.07757578790187836
Validation loss: 1.674593174329368

Epoch: 641| Step: 0
Training loss: 0.06446366012096405
Validation loss: 1.6513838691096152

Epoch: 5| Step: 1
Training loss: 0.09587518125772476
Validation loss: 1.6584162417278494

Epoch: 5| Step: 2
Training loss: 0.086083322763443
Validation loss: 1.6545576344254196

Epoch: 5| Step: 3
Training loss: 0.07615308463573456
Validation loss: 1.6495265217237576

Epoch: 5| Step: 4
Training loss: 0.07535866647958755
Validation loss: 1.6559984401990009

Epoch: 5| Step: 5
Training loss: 0.05902836471796036
Validation loss: 1.655464163390539

Epoch: 5| Step: 6
Training loss: 0.07029962539672852
Validation loss: 1.609744461633826

Epoch: 5| Step: 7
Training loss: 0.04940832406282425
Validation loss: 1.6181345473053634

Epoch: 5| Step: 8
Training loss: 0.05215822532773018
Validation loss: 1.6101145975051387

Epoch: 5| Step: 9
Training loss: 0.06260807812213898
Validation loss: 1.6092640187150689

Epoch: 5| Step: 10
Training loss: 0.08175715059041977
Validation loss: 1.6181546744479929

Epoch: 642| Step: 0
Training loss: 0.07543997466564178
Validation loss: 1.6370870887592275

Epoch: 5| Step: 1
Training loss: 0.07569704949855804
Validation loss: 1.6389622111474313

Epoch: 5| Step: 2
Training loss: 0.09526659548282623
Validation loss: 1.656040132686656

Epoch: 5| Step: 3
Training loss: 0.06423167139291763
Validation loss: 1.6404403883923766

Epoch: 5| Step: 4
Training loss: 0.05549795553088188
Validation loss: 1.6263740363941397

Epoch: 5| Step: 5
Training loss: 0.04427389055490494
Validation loss: 1.643102353618991

Epoch: 5| Step: 6
Training loss: 0.06655874103307724
Validation loss: 1.6307954570298553

Epoch: 5| Step: 7
Training loss: 0.06561491638422012
Validation loss: 1.6228448908816102

Epoch: 5| Step: 8
Training loss: 0.06690795719623566
Validation loss: 1.6111996455859112

Epoch: 5| Step: 9
Training loss: 0.073066346347332
Validation loss: 1.5964981778975456

Epoch: 5| Step: 10
Training loss: 0.06469126045703888
Validation loss: 1.599504405452359

Epoch: 643| Step: 0
Training loss: 0.09002658724784851
Validation loss: 1.6032494960292694

Epoch: 5| Step: 1
Training loss: 0.05872794985771179
Validation loss: 1.5977705153085853

Epoch: 5| Step: 2
Training loss: 0.06148352101445198
Validation loss: 1.6106587507391488

Epoch: 5| Step: 3
Training loss: 0.07031543552875519
Validation loss: 1.6392186969839118

Epoch: 5| Step: 4
Training loss: 0.056023456156253815
Validation loss: 1.6269319890647806

Epoch: 5| Step: 5
Training loss: 0.04188479855656624
Validation loss: 1.6629083002767255

Epoch: 5| Step: 6
Training loss: 0.08275501430034637
Validation loss: 1.6580469454488447

Epoch: 5| Step: 7
Training loss: 0.07279424369335175
Validation loss: 1.6609350635159401

Epoch: 5| Step: 8
Training loss: 0.08552956581115723
Validation loss: 1.6706308600723103

Epoch: 5| Step: 9
Training loss: 0.04203386977314949
Validation loss: 1.6554222952935003

Epoch: 5| Step: 10
Training loss: 0.06760929524898529
Validation loss: 1.6633794012890066

Epoch: 644| Step: 0
Training loss: 0.0811721459031105
Validation loss: 1.6480192369030369

Epoch: 5| Step: 1
Training loss: 0.05466229468584061
Validation loss: 1.6442952809795257

Epoch: 5| Step: 2
Training loss: 0.08974136412143707
Validation loss: 1.663249570836303

Epoch: 5| Step: 3
Training loss: 0.05679363012313843
Validation loss: 1.6751438597197175

Epoch: 5| Step: 4
Training loss: 0.07899510860443115
Validation loss: 1.681853881446264

Epoch: 5| Step: 5
Training loss: 0.06078469753265381
Validation loss: 1.6852376512301865

Epoch: 5| Step: 6
Training loss: 0.06882618367671967
Validation loss: 1.6973811144469886

Epoch: 5| Step: 7
Training loss: 0.11130554974079132
Validation loss: 1.6940037300509792

Epoch: 5| Step: 8
Training loss: 0.14853450655937195
Validation loss: 1.7116674582163494

Epoch: 5| Step: 9
Training loss: 0.0644829273223877
Validation loss: 1.6904596949136386

Epoch: 5| Step: 10
Training loss: 0.08647866547107697
Validation loss: 1.6940884410694081

Epoch: 645| Step: 0
Training loss: 0.08318054676055908
Validation loss: 1.6837207309661373

Epoch: 5| Step: 1
Training loss: 0.08461827784776688
Validation loss: 1.6970076817338184

Epoch: 5| Step: 2
Training loss: 0.07103224843740463
Validation loss: 1.7018045212632866

Epoch: 5| Step: 3
Training loss: 0.08008550107479095
Validation loss: 1.6778432117995394

Epoch: 5| Step: 4
Training loss: 0.06650452315807343
Validation loss: 1.644228941650801

Epoch: 5| Step: 5
Training loss: 0.09443449974060059
Validation loss: 1.653508637541084

Epoch: 5| Step: 6
Training loss: 0.08858947455883026
Validation loss: 1.632487040694042

Epoch: 5| Step: 7
Training loss: 0.10585496574640274
Validation loss: 1.605271215079933

Epoch: 5| Step: 8
Training loss: 0.06501839309930801
Validation loss: 1.5878264301566667

Epoch: 5| Step: 9
Training loss: 0.06110162287950516
Validation loss: 1.589141627793671

Epoch: 5| Step: 10
Training loss: 0.07812084257602692
Validation loss: 1.6243800706760858

Epoch: 646| Step: 0
Training loss: 0.05362170189619064
Validation loss: 1.630075821312525

Epoch: 5| Step: 1
Training loss: 0.10052633285522461
Validation loss: 1.6279105165953278

Epoch: 5| Step: 2
Training loss: 0.056359291076660156
Validation loss: 1.646043239101287

Epoch: 5| Step: 3
Training loss: 0.09474749118089676
Validation loss: 1.6323130246131652

Epoch: 5| Step: 4
Training loss: 0.0804445892572403
Validation loss: 1.6395275567167549

Epoch: 5| Step: 5
Training loss: 0.1097651943564415
Validation loss: 1.6449626658552436

Epoch: 5| Step: 6
Training loss: 0.061404578387737274
Validation loss: 1.6788490792756439

Epoch: 5| Step: 7
Training loss: 0.07215861231088638
Validation loss: 1.64989516299258

Epoch: 5| Step: 8
Training loss: 0.09018658101558685
Validation loss: 1.6402420581028025

Epoch: 5| Step: 9
Training loss: 0.08671073615550995
Validation loss: 1.6158498474346694

Epoch: 5| Step: 10
Training loss: 0.04686832055449486
Validation loss: 1.6149735463562833

Epoch: 647| Step: 0
Training loss: 0.07701065391302109
Validation loss: 1.625884647010475

Epoch: 5| Step: 1
Training loss: 0.08939144015312195
Validation loss: 1.628618981248589

Epoch: 5| Step: 2
Training loss: 0.10316196829080582
Validation loss: 1.611160619284517

Epoch: 5| Step: 3
Training loss: 0.08968818187713623
Validation loss: 1.5934258814780944

Epoch: 5| Step: 4
Training loss: 0.08695869147777557
Validation loss: 1.5937822954629057

Epoch: 5| Step: 5
Training loss: 0.07756001502275467
Validation loss: 1.6276122652074343

Epoch: 5| Step: 6
Training loss: 0.1121731847524643
Validation loss: 1.6447476571606052

Epoch: 5| Step: 7
Training loss: 0.13905325531959534
Validation loss: 1.657253731963455

Epoch: 5| Step: 8
Training loss: 0.060739658772945404
Validation loss: 1.6426408495954288

Epoch: 5| Step: 9
Training loss: 0.08364661782979965
Validation loss: 1.6596235113759195

Epoch: 5| Step: 10
Training loss: 0.08644258975982666
Validation loss: 1.6507686261207826

Epoch: 648| Step: 0
Training loss: 0.0801076889038086
Validation loss: 1.671401527620131

Epoch: 5| Step: 1
Training loss: 0.06698337197303772
Validation loss: 1.697496198838757

Epoch: 5| Step: 2
Training loss: 0.08739521354436874
Validation loss: 1.6738075774203065

Epoch: 5| Step: 3
Training loss: 0.11398307979106903
Validation loss: 1.6731198603107083

Epoch: 5| Step: 4
Training loss: 0.10381176322698593
Validation loss: 1.6688747841824767

Epoch: 5| Step: 5
Training loss: 0.053617529571056366
Validation loss: 1.627418443720828

Epoch: 5| Step: 6
Training loss: 0.09009207785129547
Validation loss: 1.6070192539563743

Epoch: 5| Step: 7
Training loss: 0.07018346339464188
Validation loss: 1.6226215080548358

Epoch: 5| Step: 8
Training loss: 0.13157698512077332
Validation loss: 1.6089138741134315

Epoch: 5| Step: 9
Training loss: 0.09561623632907867
Validation loss: 1.6021914789753575

Epoch: 5| Step: 10
Training loss: 0.10220666974782944
Validation loss: 1.615750265377824

Epoch: 649| Step: 0
Training loss: 0.06612356752157211
Validation loss: 1.6442679551339918

Epoch: 5| Step: 1
Training loss: 0.09051728993654251
Validation loss: 1.6282945852125845

Epoch: 5| Step: 2
Training loss: 0.11309224367141724
Validation loss: 1.6360831940045921

Epoch: 5| Step: 3
Training loss: 0.09175552427768707
Validation loss: 1.6340655537061795

Epoch: 5| Step: 4
Training loss: 0.0824097990989685
Validation loss: 1.6417809096715783

Epoch: 5| Step: 5
Training loss: 0.11470963805913925
Validation loss: 1.6656096981417747

Epoch: 5| Step: 6
Training loss: 0.0643976703286171
Validation loss: 1.662878433863322

Epoch: 5| Step: 7
Training loss: 0.06683573871850967
Validation loss: 1.6539220733027304

Epoch: 5| Step: 8
Training loss: 0.10475404560565948
Validation loss: 1.665339103309057

Epoch: 5| Step: 9
Training loss: 0.0818471759557724
Validation loss: 1.6854409351143786

Epoch: 5| Step: 10
Training loss: 0.08897623419761658
Validation loss: 1.649054483700824

Epoch: 650| Step: 0
Training loss: 0.0961952805519104
Validation loss: 1.6332810719807942

Epoch: 5| Step: 1
Training loss: 0.089998260140419
Validation loss: 1.6166460078249696

Epoch: 5| Step: 2
Training loss: 0.08123484998941422
Validation loss: 1.5812784664092525

Epoch: 5| Step: 3
Training loss: 0.1369505077600479
Validation loss: 1.6024131608265701

Epoch: 5| Step: 4
Training loss: 0.10237232595682144
Validation loss: 1.58850222761913

Epoch: 5| Step: 5
Training loss: 0.07137332856655121
Validation loss: 1.606942371655536

Epoch: 5| Step: 6
Training loss: 0.09283670037984848
Validation loss: 1.6287831683312692

Epoch: 5| Step: 7
Training loss: 0.09515728056430817
Validation loss: 1.6317358016967773

Epoch: 5| Step: 8
Training loss: 0.08484483510255814
Validation loss: 1.6576370609703885

Epoch: 5| Step: 9
Training loss: 0.07092632353305817
Validation loss: 1.6463156464279338

Epoch: 5| Step: 10
Training loss: 0.0701294094324112
Validation loss: 1.6326257451888053

Testing loss: 2.196642425325182
