Epoch: 1| Step: 0
Training loss: 5.639146327972412
Validation loss: 5.19140661403697

Epoch: 5| Step: 1
Training loss: 5.3786845207214355
Validation loss: 5.171240155414869

Epoch: 5| Step: 2
Training loss: 4.413981914520264
Validation loss: 5.155426240736438

Epoch: 5| Step: 3
Training loss: 5.16376256942749
Validation loss: 5.138756234158752

Epoch: 5| Step: 4
Training loss: 5.091912746429443
Validation loss: 5.120264135381227

Epoch: 5| Step: 5
Training loss: 4.713837623596191
Validation loss: 5.09867484595186

Epoch: 5| Step: 6
Training loss: 5.329976558685303
Validation loss: 5.074291531757642

Epoch: 5| Step: 7
Training loss: 4.657535076141357
Validation loss: 5.046775940925844

Epoch: 5| Step: 8
Training loss: 4.358046531677246
Validation loss: 5.015686968321441

Epoch: 5| Step: 9
Training loss: 4.445130348205566
Validation loss: 4.979942091049686

Epoch: 5| Step: 10
Training loss: 4.437623500823975
Validation loss: 4.940249007235291

Epoch: 2| Step: 0
Training loss: 4.727058410644531
Validation loss: 4.8959516094576925

Epoch: 5| Step: 1
Training loss: 4.775290489196777
Validation loss: 4.846549295609997

Epoch: 5| Step: 2
Training loss: 4.80434513092041
Validation loss: 4.792862871641754

Epoch: 5| Step: 3
Training loss: 4.052809238433838
Validation loss: 4.731679929200039

Epoch: 5| Step: 4
Training loss: 3.8448805809020996
Validation loss: 4.666036631471368

Epoch: 5| Step: 5
Training loss: 5.602347373962402
Validation loss: 4.595050504130702

Epoch: 5| Step: 6
Training loss: 3.3827743530273438
Validation loss: 4.521463424928727

Epoch: 5| Step: 7
Training loss: 4.20694637298584
Validation loss: 4.446055842984107

Epoch: 5| Step: 8
Training loss: 4.060515403747559
Validation loss: 4.369170624722717

Epoch: 5| Step: 9
Training loss: 4.155155658721924
Validation loss: 4.2930648198691745

Epoch: 5| Step: 10
Training loss: 4.470929145812988
Validation loss: 4.21900951221425

Epoch: 3| Step: 0
Training loss: 3.4034621715545654
Validation loss: 4.145540780918573

Epoch: 5| Step: 1
Training loss: 4.195591926574707
Validation loss: 4.071613311767578

Epoch: 5| Step: 2
Training loss: 4.146613597869873
Validation loss: 3.998778507273684

Epoch: 5| Step: 3
Training loss: 2.869293212890625
Validation loss: 3.9316733678181968

Epoch: 5| Step: 4
Training loss: 3.869762420654297
Validation loss: 3.8774793122404363

Epoch: 5| Step: 5
Training loss: 4.229881763458252
Validation loss: 3.830496521406276

Epoch: 5| Step: 6
Training loss: 3.107166290283203
Validation loss: 3.7856965398275726

Epoch: 5| Step: 7
Training loss: 2.8498592376708984
Validation loss: 3.7500107724179506

Epoch: 5| Step: 8
Training loss: 3.832660675048828
Validation loss: 3.719969703305152

Epoch: 5| Step: 9
Training loss: 4.899787425994873
Validation loss: 3.6919634393466416

Epoch: 5| Step: 10
Training loss: 3.850250244140625
Validation loss: 3.6702199110420803

Epoch: 4| Step: 0
Training loss: 2.659485340118408
Validation loss: 3.6429514731130292

Epoch: 5| Step: 1
Training loss: 3.2854743003845215
Validation loss: 3.6286226549456195

Epoch: 5| Step: 2
Training loss: 4.347553253173828
Validation loss: 3.6153714682466243

Epoch: 5| Step: 3
Training loss: 2.3139824867248535
Validation loss: 3.59866859323235

Epoch: 5| Step: 4
Training loss: 3.391845703125
Validation loss: 3.580309421785416

Epoch: 5| Step: 5
Training loss: 4.011011123657227
Validation loss: 3.5564963048504246

Epoch: 5| Step: 6
Training loss: 3.4824206829071045
Validation loss: 3.556838381674982

Epoch: 5| Step: 7
Training loss: 2.687156915664673
Validation loss: 3.538302734333982

Epoch: 5| Step: 8
Training loss: 4.00370454788208
Validation loss: 3.516260254767633

Epoch: 5| Step: 9
Training loss: 4.094424247741699
Validation loss: 3.497553930487684

Epoch: 5| Step: 10
Training loss: 4.171827793121338
Validation loss: 3.4856041964664253

Epoch: 5| Step: 0
Training loss: 2.9583988189697266
Validation loss: 3.466028398083102

Epoch: 5| Step: 1
Training loss: 3.3157386779785156
Validation loss: 3.452267928790021

Epoch: 5| Step: 2
Training loss: 3.3919384479522705
Validation loss: 3.4453628550293627

Epoch: 5| Step: 3
Training loss: 3.1649723052978516
Validation loss: 3.437161402035785

Epoch: 5| Step: 4
Training loss: 4.502805709838867
Validation loss: 3.4200389308314167

Epoch: 5| Step: 5
Training loss: 3.8613433837890625
Validation loss: 3.399959853900376

Epoch: 5| Step: 6
Training loss: 3.198976755142212
Validation loss: 3.3819382831614506

Epoch: 5| Step: 7
Training loss: 2.8616843223571777
Validation loss: 3.375675839762534

Epoch: 5| Step: 8
Training loss: 3.158825635910034
Validation loss: 3.374569426300705

Epoch: 5| Step: 9
Training loss: 3.3427231311798096
Validation loss: 3.359110391268166

Epoch: 5| Step: 10
Training loss: 3.1630001068115234
Validation loss: 3.3557410547810216

Epoch: 6| Step: 0
Training loss: 3.020881175994873
Validation loss: 3.3486962626057286

Epoch: 5| Step: 1
Training loss: 3.3283629417419434
Validation loss: 3.3413174049828642

Epoch: 5| Step: 2
Training loss: 3.6690917015075684
Validation loss: 3.328337005389634

Epoch: 5| Step: 3
Training loss: 2.8464105129241943
Validation loss: 3.3222080610131703

Epoch: 5| Step: 4
Training loss: 3.8554985523223877
Validation loss: 3.3203277792981876

Epoch: 5| Step: 5
Training loss: 3.3094124794006348
Validation loss: 3.31043069337004

Epoch: 5| Step: 6
Training loss: 2.3516135215759277
Validation loss: 3.297541526056105

Epoch: 5| Step: 7
Training loss: 2.9858546257019043
Validation loss: 3.2938479249195387

Epoch: 5| Step: 8
Training loss: 3.4101402759552
Validation loss: 3.295151772037629

Epoch: 5| Step: 9
Training loss: 4.307505130767822
Validation loss: 3.290237044775358

Epoch: 5| Step: 10
Training loss: 2.965088367462158
Validation loss: 3.2789869898109028

Epoch: 7| Step: 0
Training loss: 3.3448538780212402
Validation loss: 3.2656054496765137

Epoch: 5| Step: 1
Training loss: 3.6836459636688232
Validation loss: 3.252847020344068

Epoch: 5| Step: 2
Training loss: 2.9501090049743652
Validation loss: 3.2440099716186523

Epoch: 5| Step: 3
Training loss: 3.5270495414733887
Validation loss: 3.2368667407702376

Epoch: 5| Step: 4
Training loss: 3.5325164794921875
Validation loss: 3.229633185171312

Epoch: 5| Step: 5
Training loss: 3.280456066131592
Validation loss: 3.226107748605872

Epoch: 5| Step: 6
Training loss: 2.7760748863220215
Validation loss: 3.2188751928267942

Epoch: 5| Step: 7
Training loss: 3.0063395500183105
Validation loss: 3.2396483267507246

Epoch: 5| Step: 8
Training loss: 4.041831016540527
Validation loss: 3.211132090578797

Epoch: 5| Step: 9
Training loss: 2.357236623764038
Validation loss: 3.207796694130026

Epoch: 5| Step: 10
Training loss: 2.9173879623413086
Validation loss: 3.204833294755669

Epoch: 8| Step: 0
Training loss: 2.8383307456970215
Validation loss: 3.204057490953835

Epoch: 5| Step: 1
Training loss: 3.06187105178833
Validation loss: 3.1881282201377292

Epoch: 5| Step: 2
Training loss: 3.1596884727478027
Validation loss: 3.1787254425787155

Epoch: 5| Step: 3
Training loss: 3.3644938468933105
Validation loss: 3.1733716662212084

Epoch: 5| Step: 4
Training loss: 2.8259081840515137
Validation loss: 3.1691586689282487

Epoch: 5| Step: 5
Training loss: 3.7180962562561035
Validation loss: 3.1671370844687186

Epoch: 5| Step: 6
Training loss: 2.9064078330993652
Validation loss: 3.1511697153891287

Epoch: 5| Step: 7
Training loss: 3.5854244232177734
Validation loss: 3.138928346736457

Epoch: 5| Step: 8
Training loss: 3.1614151000976562
Validation loss: 3.1346831270443496

Epoch: 5| Step: 9
Training loss: 3.2553069591522217
Validation loss: 3.1389608998452463

Epoch: 5| Step: 10
Training loss: 2.991110324859619
Validation loss: 3.137628875752931

Epoch: 9| Step: 0
Training loss: 2.57509183883667
Validation loss: 3.1278079504607827

Epoch: 5| Step: 1
Training loss: 3.5867791175842285
Validation loss: 3.1228009910993677

Epoch: 5| Step: 2
Training loss: 2.293835401535034
Validation loss: 3.1084251455081406

Epoch: 5| Step: 3
Training loss: 3.7088286876678467
Validation loss: 3.1237580878760225

Epoch: 5| Step: 4
Training loss: 2.772169351577759
Validation loss: 3.096111887244768

Epoch: 5| Step: 5
Training loss: 3.42814564704895
Validation loss: 3.0929315577271166

Epoch: 5| Step: 6
Training loss: 3.3566184043884277
Validation loss: 3.0963979664669243

Epoch: 5| Step: 7
Training loss: 2.3098158836364746
Validation loss: 3.0910123138017553

Epoch: 5| Step: 8
Training loss: 4.093379020690918
Validation loss: 3.088653487543906

Epoch: 5| Step: 9
Training loss: 3.204869031906128
Validation loss: 3.078748256929459

Epoch: 5| Step: 10
Training loss: 3.0869383811950684
Validation loss: 3.067886749903361

Epoch: 10| Step: 0
Training loss: 2.5542657375335693
Validation loss: 3.0615812117053616

Epoch: 5| Step: 1
Training loss: 3.6531219482421875
Validation loss: 3.0586457355048067

Epoch: 5| Step: 2
Training loss: 2.6314921379089355
Validation loss: 3.059106288417693

Epoch: 5| Step: 3
Training loss: 2.7708523273468018
Validation loss: 3.056594364104732

Epoch: 5| Step: 4
Training loss: 2.502340316772461
Validation loss: 3.0511148283558507

Epoch: 5| Step: 5
Training loss: 2.882519483566284
Validation loss: 3.0459231356138825

Epoch: 5| Step: 6
Training loss: 2.8584020137786865
Validation loss: 3.0419628184328795

Epoch: 5| Step: 7
Training loss: 3.4575881958007812
Validation loss: 3.0351414398480485

Epoch: 5| Step: 8
Training loss: 3.6462066173553467
Validation loss: 3.0277819018210135

Epoch: 5| Step: 9
Training loss: 3.204441547393799
Validation loss: 3.023492408055131

Epoch: 5| Step: 10
Training loss: 3.9904465675354004
Validation loss: 3.022344340560257

Epoch: 11| Step: 0
Training loss: 2.909193277359009
Validation loss: 3.0190298147098993

Epoch: 5| Step: 1
Training loss: 3.1498093605041504
Validation loss: 3.0103338251831713

Epoch: 5| Step: 2
Training loss: 3.2927327156066895
Validation loss: 3.0040189502059773

Epoch: 5| Step: 3
Training loss: 3.648345947265625
Validation loss: 2.997716521704069

Epoch: 5| Step: 4
Training loss: 3.1073832511901855
Validation loss: 2.9925070347324496

Epoch: 5| Step: 5
Training loss: 3.0510497093200684
Validation loss: 2.991176115569248

Epoch: 5| Step: 6
Training loss: 3.086383581161499
Validation loss: 2.982763918497229

Epoch: 5| Step: 7
Training loss: 2.5120697021484375
Validation loss: 2.9796227562812065

Epoch: 5| Step: 8
Training loss: 3.1251304149627686
Validation loss: 2.976901646583311

Epoch: 5| Step: 9
Training loss: 2.7084269523620605
Validation loss: 2.984529064547631

Epoch: 5| Step: 10
Training loss: 3.0799624919891357
Validation loss: 2.976845251616611

Epoch: 12| Step: 0
Training loss: 3.9167943000793457
Validation loss: 2.9664466739982687

Epoch: 5| Step: 1
Training loss: 3.340031385421753
Validation loss: 2.9574694864211546

Epoch: 5| Step: 2
Training loss: 2.973527193069458
Validation loss: 2.9526838153921147

Epoch: 5| Step: 3
Training loss: 3.2129275798797607
Validation loss: 2.949927865817983

Epoch: 5| Step: 4
Training loss: 3.0975937843322754
Validation loss: 2.9458354442350325

Epoch: 5| Step: 5
Training loss: 2.148982286453247
Validation loss: 2.939892356113721

Epoch: 5| Step: 6
Training loss: 2.728395462036133
Validation loss: 2.9356944894277923

Epoch: 5| Step: 7
Training loss: 2.926041841506958
Validation loss: 2.9267505881606892

Epoch: 5| Step: 8
Training loss: 2.8652076721191406
Validation loss: 2.9234882093244985

Epoch: 5| Step: 9
Training loss: 3.093900680541992
Validation loss: 2.9186859130859375

Epoch: 5| Step: 10
Training loss: 2.9607598781585693
Validation loss: 2.912141558944538

Epoch: 13| Step: 0
Training loss: 3.3150100708007812
Validation loss: 2.907176520234795

Epoch: 5| Step: 1
Training loss: 3.187472343444824
Validation loss: 2.9011716586287304

Epoch: 5| Step: 2
Training loss: 2.593966484069824
Validation loss: 2.897073940564227

Epoch: 5| Step: 3
Training loss: 3.204676866531372
Validation loss: 2.8966226039394254

Epoch: 5| Step: 4
Training loss: 2.614989757537842
Validation loss: 2.893124993129443

Epoch: 5| Step: 5
Training loss: 3.0187222957611084
Validation loss: 2.8887883283758677

Epoch: 5| Step: 6
Training loss: 2.4845457077026367
Validation loss: 2.8895629170120403

Epoch: 5| Step: 7
Training loss: 3.312206983566284
Validation loss: 2.8795284302003923

Epoch: 5| Step: 8
Training loss: 2.843086004257202
Validation loss: 2.8736992959053285

Epoch: 5| Step: 9
Training loss: 3.1836702823638916
Validation loss: 2.870983026360953

Epoch: 5| Step: 10
Training loss: 3.1341116428375244
Validation loss: 2.8671431618352092

Epoch: 14| Step: 0
Training loss: 2.9706029891967773
Validation loss: 2.8652957998296267

Epoch: 5| Step: 1
Training loss: 3.979987621307373
Validation loss: 2.8638189787505777

Epoch: 5| Step: 2
Training loss: 2.4717934131622314
Validation loss: 2.8576091874030327

Epoch: 5| Step: 3
Training loss: 3.1086084842681885
Validation loss: 2.8612503056885092

Epoch: 5| Step: 4
Training loss: 3.337127208709717
Validation loss: 2.8692486465618177

Epoch: 5| Step: 5
Training loss: 2.8989052772521973
Validation loss: 2.8812997930793354

Epoch: 5| Step: 6
Training loss: 3.150397777557373
Validation loss: 2.8608014609224055

Epoch: 5| Step: 7
Training loss: 2.6771488189697266
Validation loss: 2.8584422834457888

Epoch: 5| Step: 8
Training loss: 1.507918119430542
Validation loss: 2.848300349327826

Epoch: 5| Step: 9
Training loss: 2.916290760040283
Validation loss: 2.8516470924500497

Epoch: 5| Step: 10
Training loss: 3.760200023651123
Validation loss: 2.8560385447676464

Epoch: 15| Step: 0
Training loss: 2.3020005226135254
Validation loss: 2.862028616730885

Epoch: 5| Step: 1
Training loss: 3.9142603874206543
Validation loss: 2.858597986159786

Epoch: 5| Step: 2
Training loss: 3.591271162033081
Validation loss: 2.8495918140616467

Epoch: 5| Step: 3
Training loss: 2.6146762371063232
Validation loss: 2.8420897324879966

Epoch: 5| Step: 4
Training loss: 2.375664234161377
Validation loss: 2.8295523530693463

Epoch: 5| Step: 5
Training loss: 2.469348192214966
Validation loss: 2.8242037270658757

Epoch: 5| Step: 6
Training loss: 3.1129300594329834
Validation loss: 2.8210181010666715

Epoch: 5| Step: 7
Training loss: 2.4606618881225586
Validation loss: 2.8236973388220674

Epoch: 5| Step: 8
Training loss: 2.7651219367980957
Validation loss: 2.8146362407233125

Epoch: 5| Step: 9
Training loss: 3.5179290771484375
Validation loss: 2.807312842338316

Epoch: 5| Step: 10
Training loss: 3.4115793704986572
Validation loss: 2.799913775536322

Epoch: 16| Step: 0
Training loss: 1.91133713722229
Validation loss: 2.7938908710274646

Epoch: 5| Step: 1
Training loss: 3.0944676399230957
Validation loss: 2.7972340763256116

Epoch: 5| Step: 2
Training loss: 2.840146780014038
Validation loss: 2.790157997480003

Epoch: 5| Step: 3
Training loss: 2.6138055324554443
Validation loss: 2.806659993305001

Epoch: 5| Step: 4
Training loss: 2.933279037475586
Validation loss: 2.804045687439621

Epoch: 5| Step: 5
Training loss: 3.1891863346099854
Validation loss: 2.7950306989813365

Epoch: 5| Step: 6
Training loss: 3.1948609352111816
Validation loss: 2.792254868374076

Epoch: 5| Step: 7
Training loss: 3.155843734741211
Validation loss: 2.7782902973954395

Epoch: 5| Step: 8
Training loss: 2.5193493366241455
Validation loss: 2.774842467359317

Epoch: 5| Step: 9
Training loss: 3.1365370750427246
Validation loss: 2.7729004403596282

Epoch: 5| Step: 10
Training loss: 3.661121368408203
Validation loss: 2.7773534918344147

Epoch: 17| Step: 0
Training loss: 3.075451374053955
Validation loss: 2.770390841268724

Epoch: 5| Step: 1
Training loss: 2.9050545692443848
Validation loss: 2.7639846929939846

Epoch: 5| Step: 2
Training loss: 2.822465658187866
Validation loss: 2.7609693901513213

Epoch: 5| Step: 3
Training loss: 2.7525410652160645
Validation loss: 2.7565336201780584

Epoch: 5| Step: 4
Training loss: 1.9444284439086914
Validation loss: 2.75450466012442

Epoch: 5| Step: 5
Training loss: 3.107062816619873
Validation loss: 2.7690759730595413

Epoch: 5| Step: 6
Training loss: 3.214043378829956
Validation loss: 2.77089350710633

Epoch: 5| Step: 7
Training loss: 3.0473179817199707
Validation loss: 2.758023162041941

Epoch: 5| Step: 8
Training loss: 2.8878352642059326
Validation loss: 2.747423138669742

Epoch: 5| Step: 9
Training loss: 3.3784050941467285
Validation loss: 2.751048598238217

Epoch: 5| Step: 10
Training loss: 2.7742185592651367
Validation loss: 2.7512148785334762

Epoch: 18| Step: 0
Training loss: 3.531109571456909
Validation loss: 2.754175042593351

Epoch: 5| Step: 1
Training loss: 3.477722644805908
Validation loss: 2.7460278182901363

Epoch: 5| Step: 2
Training loss: 2.7076380252838135
Validation loss: 2.7420044124767347

Epoch: 5| Step: 3
Training loss: 3.010911464691162
Validation loss: 2.742652570047686

Epoch: 5| Step: 4
Training loss: 2.9225950241088867
Validation loss: 2.745221068782191

Epoch: 5| Step: 5
Training loss: 3.123931884765625
Validation loss: 2.7442487234710367

Epoch: 5| Step: 6
Training loss: 2.557971715927124
Validation loss: 2.739715858172345

Epoch: 5| Step: 7
Training loss: 2.5214779376983643
Validation loss: 2.739027107915571

Epoch: 5| Step: 8
Training loss: 2.867540121078491
Validation loss: 2.7352607814214562

Epoch: 5| Step: 9
Training loss: 2.4952399730682373
Validation loss: 2.734135522637316

Epoch: 5| Step: 10
Training loss: 2.5809266567230225
Validation loss: 2.7310711337674047

Epoch: 19| Step: 0
Training loss: 3.5939202308654785
Validation loss: 2.729443109163674

Epoch: 5| Step: 1
Training loss: 2.588747262954712
Validation loss: 2.725762462103239

Epoch: 5| Step: 2
Training loss: 3.5410666465759277
Validation loss: 2.7423753866585354

Epoch: 5| Step: 3
Training loss: 3.7279765605926514
Validation loss: 2.7299103813786663

Epoch: 5| Step: 4
Training loss: 2.8553378582000732
Validation loss: 2.7302788611381286

Epoch: 5| Step: 5
Training loss: 2.556509494781494
Validation loss: 2.7262215357954784

Epoch: 5| Step: 6
Training loss: 2.520508289337158
Validation loss: 2.746319314484955

Epoch: 5| Step: 7
Training loss: 2.5589795112609863
Validation loss: 2.788073606388543

Epoch: 5| Step: 8
Training loss: 2.888842821121216
Validation loss: 2.7772152423858643

Epoch: 5| Step: 9
Training loss: 2.0285356044769287
Validation loss: 2.7467876326653267

Epoch: 5| Step: 10
Training loss: 2.9639201164245605
Validation loss: 2.7360257666598082

Epoch: 20| Step: 0
Training loss: 3.4988067150115967
Validation loss: 2.7254519283130603

Epoch: 5| Step: 1
Training loss: 3.279573917388916
Validation loss: 2.730031164743567

Epoch: 5| Step: 2
Training loss: 3.7917702198028564
Validation loss: 2.724220037460327

Epoch: 5| Step: 3
Training loss: 2.454765796661377
Validation loss: 2.7189080510088193

Epoch: 5| Step: 4
Training loss: 2.8646202087402344
Validation loss: 2.7183620929718018

Epoch: 5| Step: 5
Training loss: 2.991936206817627
Validation loss: 2.7140015837966756

Epoch: 5| Step: 6
Training loss: 2.649200439453125
Validation loss: 2.7111794076940066

Epoch: 5| Step: 7
Training loss: 2.618367910385132
Validation loss: 2.705792534735895

Epoch: 5| Step: 8
Training loss: 2.2385287284851074
Validation loss: 2.7059327761332193

Epoch: 5| Step: 9
Training loss: 2.899854898452759
Validation loss: 2.7048816732181016

Epoch: 5| Step: 10
Training loss: 2.2342276573181152
Validation loss: 2.7031382745312107

Epoch: 21| Step: 0
Training loss: 2.441153049468994
Validation loss: 2.7005855319320515

Epoch: 5| Step: 1
Training loss: 3.0677285194396973
Validation loss: 2.705086754214379

Epoch: 5| Step: 2
Training loss: 3.152061939239502
Validation loss: 2.6996817409351306

Epoch: 5| Step: 3
Training loss: 2.7673654556274414
Validation loss: 2.697585910879156

Epoch: 5| Step: 4
Training loss: 3.6956310272216797
Validation loss: 2.687162217273507

Epoch: 5| Step: 5
Training loss: 2.5505568981170654
Validation loss: 2.68763973892376

Epoch: 5| Step: 6
Training loss: 2.7376866340637207
Validation loss: 2.6811330472269366

Epoch: 5| Step: 7
Training loss: 2.60368013381958
Validation loss: 2.6788200486090874

Epoch: 5| Step: 8
Training loss: 2.2985081672668457
Validation loss: 2.676500848544541

Epoch: 5| Step: 9
Training loss: 2.9897682666778564
Validation loss: 2.6759964394313034

Epoch: 5| Step: 10
Training loss: 3.063148260116577
Validation loss: 2.6759882075812227

Epoch: 22| Step: 0
Training loss: 2.5028820037841797
Validation loss: 2.6758060096412577

Epoch: 5| Step: 1
Training loss: 2.9802117347717285
Validation loss: 2.7184458804386917

Epoch: 5| Step: 2
Training loss: 3.195261001586914
Validation loss: 2.7400005991740892

Epoch: 5| Step: 3
Training loss: 2.4715311527252197
Validation loss: 2.703002240068169

Epoch: 5| Step: 4
Training loss: 2.873922824859619
Validation loss: 2.6920826127452235

Epoch: 5| Step: 5
Training loss: 2.774928569793701
Validation loss: 2.6868840802100395

Epoch: 5| Step: 6
Training loss: 3.1377968788146973
Validation loss: 2.682490446234262

Epoch: 5| Step: 7
Training loss: 2.774348020553589
Validation loss: 2.685712372103045

Epoch: 5| Step: 8
Training loss: 3.250046968460083
Validation loss: 2.7562874465860348

Epoch: 5| Step: 9
Training loss: 2.665555238723755
Validation loss: 2.744149748997022

Epoch: 5| Step: 10
Training loss: 2.6911213397979736
Validation loss: 2.671293722685947

Epoch: 23| Step: 0
Training loss: 2.6581454277038574
Validation loss: 2.674421889807588

Epoch: 5| Step: 1
Training loss: 2.8340420722961426
Validation loss: 2.694052496264058

Epoch: 5| Step: 2
Training loss: 2.416860580444336
Validation loss: 2.7184798256043465

Epoch: 5| Step: 3
Training loss: 3.297783613204956
Validation loss: 2.7270120779673257

Epoch: 5| Step: 4
Training loss: 2.51517391204834
Validation loss: 2.6918889143133677

Epoch: 5| Step: 5
Training loss: 2.0772206783294678
Validation loss: 2.702798328092021

Epoch: 5| Step: 6
Training loss: 3.3532586097717285
Validation loss: 2.721486712014803

Epoch: 5| Step: 7
Training loss: 2.6396536827087402
Validation loss: 2.711344757387715

Epoch: 5| Step: 8
Training loss: 2.5270121097564697
Validation loss: 2.6850121072543565

Epoch: 5| Step: 9
Training loss: 3.385251522064209
Validation loss: 2.6689064348897626

Epoch: 5| Step: 10
Training loss: 3.714046001434326
Validation loss: 2.66613983338879

Epoch: 24| Step: 0
Training loss: 2.357938528060913
Validation loss: 2.675789702323175

Epoch: 5| Step: 1
Training loss: 1.8591346740722656
Validation loss: 2.670569125042167

Epoch: 5| Step: 2
Training loss: 2.4811182022094727
Validation loss: 2.6672889955582155

Epoch: 5| Step: 3
Training loss: 3.165656328201294
Validation loss: 2.6600379097846245

Epoch: 5| Step: 4
Training loss: 3.040437698364258
Validation loss: 2.663209469087662

Epoch: 5| Step: 5
Training loss: 3.6184322834014893
Validation loss: 2.664273073596339

Epoch: 5| Step: 6
Training loss: 2.7306742668151855
Validation loss: 2.6693800956972185

Epoch: 5| Step: 7
Training loss: 2.677978515625
Validation loss: 2.658690778158044

Epoch: 5| Step: 8
Training loss: 3.169532299041748
Validation loss: 2.6562178468191497

Epoch: 5| Step: 9
Training loss: 3.3200454711914062
Validation loss: 2.6532673220480643

Epoch: 5| Step: 10
Training loss: 2.703028917312622
Validation loss: 2.6561437524775022

Epoch: 25| Step: 0
Training loss: 2.5316710472106934
Validation loss: 2.6562668328644126

Epoch: 5| Step: 1
Training loss: 2.8685898780822754
Validation loss: 2.6546736366005352

Epoch: 5| Step: 2
Training loss: 3.1378257274627686
Validation loss: 2.64795026727902

Epoch: 5| Step: 3
Training loss: 3.0099282264709473
Validation loss: 2.6469605533025597

Epoch: 5| Step: 4
Training loss: 2.9400010108947754
Validation loss: 2.640782827972084

Epoch: 5| Step: 5
Training loss: 2.778881549835205
Validation loss: 2.6393822085472847

Epoch: 5| Step: 6
Training loss: 2.8870320320129395
Validation loss: 2.643055531286424

Epoch: 5| Step: 7
Training loss: 2.75543212890625
Validation loss: 2.650120727477535

Epoch: 5| Step: 8
Training loss: 2.6277709007263184
Validation loss: 2.652356909167382

Epoch: 5| Step: 9
Training loss: 2.8345203399658203
Validation loss: 2.6522364949667327

Epoch: 5| Step: 10
Training loss: 2.577204942703247
Validation loss: 2.635265391360047

Epoch: 26| Step: 0
Training loss: 2.8678276538848877
Validation loss: 2.634100914001465

Epoch: 5| Step: 1
Training loss: 2.5555009841918945
Validation loss: 2.6374147015233196

Epoch: 5| Step: 2
Training loss: 2.992645740509033
Validation loss: 2.6463077452874955

Epoch: 5| Step: 3
Training loss: 2.22983717918396
Validation loss: 2.642696636979298

Epoch: 5| Step: 4
Training loss: 3.077364683151245
Validation loss: 2.634858913319085

Epoch: 5| Step: 5
Training loss: 3.3062946796417236
Validation loss: 2.6405899011960594

Epoch: 5| Step: 6
Training loss: 2.816324234008789
Validation loss: 2.6358938422254337

Epoch: 5| Step: 7
Training loss: 3.440493106842041
Validation loss: 2.6335430273445706

Epoch: 5| Step: 8
Training loss: 2.764699697494507
Validation loss: 2.628883356689125

Epoch: 5| Step: 9
Training loss: 2.2852091789245605
Validation loss: 2.6376219872505433

Epoch: 5| Step: 10
Training loss: 2.587376594543457
Validation loss: 2.6581399697129444

Epoch: 27| Step: 0
Training loss: 2.9820640087127686
Validation loss: 2.6655558616884294

Epoch: 5| Step: 1
Training loss: 3.341712236404419
Validation loss: 2.663924135187621

Epoch: 5| Step: 2
Training loss: 2.6234545707702637
Validation loss: 2.659774136799638

Epoch: 5| Step: 3
Training loss: 2.416262149810791
Validation loss: 2.6289277691994943

Epoch: 5| Step: 4
Training loss: 2.17401385307312
Validation loss: 2.616660823104202

Epoch: 5| Step: 5
Training loss: 2.8499724864959717
Validation loss: 2.6231467441845964

Epoch: 5| Step: 6
Training loss: 2.7254743576049805
Validation loss: 2.634944300497732

Epoch: 5| Step: 7
Training loss: 2.146914482116699
Validation loss: 2.6648109292471283

Epoch: 5| Step: 8
Training loss: 3.608158826828003
Validation loss: 2.6502766814283145

Epoch: 5| Step: 9
Training loss: 3.2269294261932373
Validation loss: 2.6401556845634215

Epoch: 5| Step: 10
Training loss: 2.8719730377197266
Validation loss: 2.638742664808868

Epoch: 28| Step: 0
Training loss: 3.045945882797241
Validation loss: 2.6269438779482277

Epoch: 5| Step: 1
Training loss: 3.060594320297241
Validation loss: 2.6247192480230845

Epoch: 5| Step: 2
Training loss: 3.096243381500244
Validation loss: 2.6272167236574235

Epoch: 5| Step: 3
Training loss: 2.5247464179992676
Validation loss: 2.614470140908354

Epoch: 5| Step: 4
Training loss: 2.0736241340637207
Validation loss: 2.6114218388834307

Epoch: 5| Step: 5
Training loss: 2.8577873706817627
Validation loss: 2.6087613631320257

Epoch: 5| Step: 6
Training loss: 3.190546751022339
Validation loss: 2.6416478028861423

Epoch: 5| Step: 7
Training loss: 2.676933765411377
Validation loss: 2.686069147561186

Epoch: 5| Step: 8
Training loss: 2.560337543487549
Validation loss: 2.645190559407716

Epoch: 5| Step: 9
Training loss: 3.0539214611053467
Validation loss: 2.619713839664254

Epoch: 5| Step: 10
Training loss: 2.6015117168426514
Validation loss: 2.6028254903772825

Epoch: 29| Step: 0
Training loss: 3.2795841693878174
Validation loss: 2.6176823467336674

Epoch: 5| Step: 1
Training loss: 2.6286442279815674
Validation loss: 2.6181543950111634

Epoch: 5| Step: 2
Training loss: 2.8153069019317627
Validation loss: 2.627810106482557

Epoch: 5| Step: 3
Training loss: 3.3784916400909424
Validation loss: 2.6570719672787573

Epoch: 5| Step: 4
Training loss: 2.4031245708465576
Validation loss: 2.622017204120595

Epoch: 5| Step: 5
Training loss: 3.112578868865967
Validation loss: 2.6552497802242154

Epoch: 5| Step: 6
Training loss: 2.232015371322632
Validation loss: 2.622687793547107

Epoch: 5| Step: 7
Training loss: 3.179314374923706
Validation loss: 2.603918716471682

Epoch: 5| Step: 8
Training loss: 2.547579288482666
Validation loss: 2.6005085104255268

Epoch: 5| Step: 9
Training loss: 2.497081756591797
Validation loss: 2.629126215493807

Epoch: 5| Step: 10
Training loss: 2.5873262882232666
Validation loss: 2.6162743517147597

Epoch: 30| Step: 0
Training loss: 3.4452414512634277
Validation loss: 2.6152543047423005

Epoch: 5| Step: 1
Training loss: 3.0693254470825195
Validation loss: 2.5933870871861777

Epoch: 5| Step: 2
Training loss: 2.879794120788574
Validation loss: 2.5909606102974183

Epoch: 5| Step: 3
Training loss: 2.2528347969055176
Validation loss: 2.591550175861646

Epoch: 5| Step: 4
Training loss: 2.711503028869629
Validation loss: 2.584142541372648

Epoch: 5| Step: 5
Training loss: 2.1886253356933594
Validation loss: 2.5814143252629105

Epoch: 5| Step: 6
Training loss: 3.0129384994506836
Validation loss: 2.5812716766070296

Epoch: 5| Step: 7
Training loss: 2.607616662979126
Validation loss: 2.5819526487781155

Epoch: 5| Step: 8
Training loss: 2.778616428375244
Validation loss: 2.5770807676417853

Epoch: 5| Step: 9
Training loss: 2.363407611846924
Validation loss: 2.584418673669138

Epoch: 5| Step: 10
Training loss: 3.1867411136627197
Validation loss: 2.590106471892326

Epoch: 31| Step: 0
Training loss: 3.0378384590148926
Validation loss: 2.5853228415212324

Epoch: 5| Step: 1
Training loss: 3.039454221725464
Validation loss: 2.584429863960512

Epoch: 5| Step: 2
Training loss: 2.60145902633667
Validation loss: 2.578372019593434

Epoch: 5| Step: 3
Training loss: 2.741083860397339
Validation loss: 2.5781633546275478

Epoch: 5| Step: 4
Training loss: 2.9093329906463623
Validation loss: 2.5721635177571285

Epoch: 5| Step: 5
Training loss: 2.6526591777801514
Validation loss: 2.566046440473167

Epoch: 5| Step: 6
Training loss: 3.0573220252990723
Validation loss: 2.559889301176994

Epoch: 5| Step: 7
Training loss: 2.6670477390289307
Validation loss: 2.561037989072902

Epoch: 5| Step: 8
Training loss: 2.5604281425476074
Validation loss: 2.5605126119429067

Epoch: 5| Step: 9
Training loss: 2.63773775100708
Validation loss: 2.559898794338267

Epoch: 5| Step: 10
Training loss: 2.3009321689605713
Validation loss: 2.5589037479892855

Epoch: 32| Step: 0
Training loss: 2.8936455249786377
Validation loss: 2.555683705114549

Epoch: 5| Step: 1
Training loss: 2.929039716720581
Validation loss: 2.5517424973108436

Epoch: 5| Step: 2
Training loss: 2.7549331188201904
Validation loss: 2.54791998094128

Epoch: 5| Step: 3
Training loss: 3.282413959503174
Validation loss: 2.5500500125269734

Epoch: 5| Step: 4
Training loss: 2.262420654296875
Validation loss: 2.5570173237913396

Epoch: 5| Step: 5
Training loss: 2.5518288612365723
Validation loss: 2.5568499231851227

Epoch: 5| Step: 6
Training loss: 2.93701434135437
Validation loss: 2.555986242909585

Epoch: 5| Step: 7
Training loss: 2.6923859119415283
Validation loss: 2.5474147283902733

Epoch: 5| Step: 8
Training loss: 2.858375072479248
Validation loss: 2.54504108172591

Epoch: 5| Step: 9
Training loss: 2.4742283821105957
Validation loss: 2.5433403856010846

Epoch: 5| Step: 10
Training loss: 2.441579818725586
Validation loss: 2.5427604618892876

Epoch: 33| Step: 0
Training loss: 3.0160508155822754
Validation loss: 2.538978902242517

Epoch: 5| Step: 1
Training loss: 3.0356085300445557
Validation loss: 2.5414367414289907

Epoch: 5| Step: 2
Training loss: 2.9442508220672607
Validation loss: 2.5414422635109193

Epoch: 5| Step: 3
Training loss: 3.1800646781921387
Validation loss: 2.541209077322355

Epoch: 5| Step: 4
Training loss: 2.277431011199951
Validation loss: 2.54052234208712

Epoch: 5| Step: 5
Training loss: 2.2062857151031494
Validation loss: 2.5366003359517744

Epoch: 5| Step: 6
Training loss: 2.765594959259033
Validation loss: 2.535440585946524

Epoch: 5| Step: 7
Training loss: 2.556623935699463
Validation loss: 2.5354968834948797

Epoch: 5| Step: 8
Training loss: 2.8064799308776855
Validation loss: 2.5338845381172757

Epoch: 5| Step: 9
Training loss: 2.6264681816101074
Validation loss: 2.5450085696353706

Epoch: 5| Step: 10
Training loss: 2.6004905700683594
Validation loss: 2.553766237792148

Epoch: 34| Step: 0
Training loss: 2.8472869396209717
Validation loss: 2.5611408474624797

Epoch: 5| Step: 1
Training loss: 2.8051140308380127
Validation loss: 2.582661380050003

Epoch: 5| Step: 2
Training loss: 2.5409693717956543
Validation loss: 2.5836085939920075

Epoch: 5| Step: 3
Training loss: 3.158845901489258
Validation loss: 2.5609081381110737

Epoch: 5| Step: 4
Training loss: 2.777193069458008
Validation loss: 2.5505373298480944

Epoch: 5| Step: 5
Training loss: 2.7729427814483643
Validation loss: 2.534653220125424

Epoch: 5| Step: 6
Training loss: 3.042271137237549
Validation loss: 2.5242794688029955

Epoch: 5| Step: 7
Training loss: 2.4137063026428223
Validation loss: 2.5295547772479314

Epoch: 5| Step: 8
Training loss: 2.6913769245147705
Validation loss: 2.5243230968393306

Epoch: 5| Step: 9
Training loss: 2.4586052894592285
Validation loss: 2.5272247637471845

Epoch: 5| Step: 10
Training loss: 2.4021027088165283
Validation loss: 2.526402550358926

Epoch: 35| Step: 0
Training loss: 2.3234448432922363
Validation loss: 2.5279185695032917

Epoch: 5| Step: 1
Training loss: 2.8375792503356934
Validation loss: 2.5303670488378054

Epoch: 5| Step: 2
Training loss: 1.79167902469635
Validation loss: 2.5254806318590717

Epoch: 5| Step: 3
Training loss: 3.640860080718994
Validation loss: 2.530502232172156

Epoch: 5| Step: 4
Training loss: 2.7306458950042725
Validation loss: 2.523726572272598

Epoch: 5| Step: 5
Training loss: 3.003546714782715
Validation loss: 2.5318322566247757

Epoch: 5| Step: 6
Training loss: 3.1316771507263184
Validation loss: 2.5344291963884906

Epoch: 5| Step: 7
Training loss: 2.6773509979248047
Validation loss: 2.5378221901514197

Epoch: 5| Step: 8
Training loss: 2.201186418533325
Validation loss: 2.5306077285479476

Epoch: 5| Step: 9
Training loss: 2.7882020473480225
Validation loss: 2.529682864425003

Epoch: 5| Step: 10
Training loss: 2.808532238006592
Validation loss: 2.536100713155603

Epoch: 36| Step: 0
Training loss: 3.451655626296997
Validation loss: 2.5396412828917145

Epoch: 5| Step: 1
Training loss: 3.044342517852783
Validation loss: 2.536488152319385

Epoch: 5| Step: 2
Training loss: 2.6046688556671143
Validation loss: 2.5336315657502864

Epoch: 5| Step: 3
Training loss: 2.822784900665283
Validation loss: 2.5248406035925752

Epoch: 5| Step: 4
Training loss: 2.6266233921051025
Validation loss: 2.529099859217162

Epoch: 5| Step: 5
Training loss: 3.119551181793213
Validation loss: 2.5296461607820246

Epoch: 5| Step: 6
Training loss: 2.761690855026245
Validation loss: 2.520740068087014

Epoch: 5| Step: 7
Training loss: 2.632664203643799
Validation loss: 2.5185368291793333

Epoch: 5| Step: 8
Training loss: 1.8630272150039673
Validation loss: 2.5186790830345562

Epoch: 5| Step: 9
Training loss: 2.787238597869873
Validation loss: 2.5309889239649617

Epoch: 5| Step: 10
Training loss: 2.062373638153076
Validation loss: 2.5342123841726654

Epoch: 37| Step: 0
Training loss: 2.5861620903015137
Validation loss: 2.523032575525263

Epoch: 5| Step: 1
Training loss: 2.7501132488250732
Validation loss: 2.5205581444565968

Epoch: 5| Step: 2
Training loss: 3.505296230316162
Validation loss: 2.5176241397857666

Epoch: 5| Step: 3
Training loss: 2.6375465393066406
Validation loss: 2.523429298913607

Epoch: 5| Step: 4
Training loss: 2.959559917449951
Validation loss: 2.518753379903814

Epoch: 5| Step: 5
Training loss: 2.6686437129974365
Validation loss: 2.518480247066867

Epoch: 5| Step: 6
Training loss: 2.892508029937744
Validation loss: 2.525669241464266

Epoch: 5| Step: 7
Training loss: 2.2436602115631104
Validation loss: 2.524594096727269

Epoch: 5| Step: 8
Training loss: 3.364593505859375
Validation loss: 2.5204228496038787

Epoch: 5| Step: 9
Training loss: 2.1560559272766113
Validation loss: 2.5199097869216756

Epoch: 5| Step: 10
Training loss: 2.0440921783447266
Validation loss: 2.51966437473092

Epoch: 38| Step: 0
Training loss: 2.347033977508545
Validation loss: 2.5213977829102547

Epoch: 5| Step: 1
Training loss: 2.9170174598693848
Validation loss: 2.5271180060602005

Epoch: 5| Step: 2
Training loss: 2.570629119873047
Validation loss: 2.528395773262106

Epoch: 5| Step: 3
Training loss: 2.722393751144409
Validation loss: 2.5279272166631555

Epoch: 5| Step: 4
Training loss: 2.2738211154937744
Validation loss: 2.533928184099095

Epoch: 5| Step: 5
Training loss: 2.993499517440796
Validation loss: 2.525262935187227

Epoch: 5| Step: 6
Training loss: 2.18774151802063
Validation loss: 2.5191226223463654

Epoch: 5| Step: 7
Training loss: 2.833648204803467
Validation loss: 2.52128360091999

Epoch: 5| Step: 8
Training loss: 3.3855044841766357
Validation loss: 2.509386339495259

Epoch: 5| Step: 9
Training loss: 2.827744960784912
Validation loss: 2.507530523884681

Epoch: 5| Step: 10
Training loss: 2.755042791366577
Validation loss: 2.5111126925355647

Epoch: 39| Step: 0
Training loss: 2.0418617725372314
Validation loss: 2.510179632453508

Epoch: 5| Step: 1
Training loss: 2.777695894241333
Validation loss: 2.5151083366845244

Epoch: 5| Step: 2
Training loss: 3.025573968887329
Validation loss: 2.50606583779858

Epoch: 5| Step: 3
Training loss: 2.924943447113037
Validation loss: 2.517708255398658

Epoch: 5| Step: 4
Training loss: 1.9196176528930664
Validation loss: 2.499171087818761

Epoch: 5| Step: 5
Training loss: 3.1744141578674316
Validation loss: 2.4992831881328295

Epoch: 5| Step: 6
Training loss: 3.085388422012329
Validation loss: 2.5051071054192

Epoch: 5| Step: 7
Training loss: 2.7666265964508057
Validation loss: 2.515553605171942

Epoch: 5| Step: 8
Training loss: 2.588139057159424
Validation loss: 2.5203130424663587

Epoch: 5| Step: 9
Training loss: 3.194828510284424
Validation loss: 2.5129804047205115

Epoch: 5| Step: 10
Training loss: 2.2666828632354736
Validation loss: 2.500412271868798

Epoch: 40| Step: 0
Training loss: 2.156850814819336
Validation loss: 2.499462781413909

Epoch: 5| Step: 1
Training loss: 2.5017337799072266
Validation loss: 2.4969961848310245

Epoch: 5| Step: 2
Training loss: 2.4697561264038086
Validation loss: 2.4922946627422045

Epoch: 5| Step: 3
Training loss: 3.0022635459899902
Validation loss: 2.4906953765499975

Epoch: 5| Step: 4
Training loss: 3.3694777488708496
Validation loss: 2.489503670764226

Epoch: 5| Step: 5
Training loss: 2.877542018890381
Validation loss: 2.4960155256332888

Epoch: 5| Step: 6
Training loss: 3.354058027267456
Validation loss: 2.512655432506274

Epoch: 5| Step: 7
Training loss: 2.412747859954834
Validation loss: 2.5383021498239167

Epoch: 5| Step: 8
Training loss: 2.1752476692199707
Validation loss: 2.5634270175810783

Epoch: 5| Step: 9
Training loss: 3.1347789764404297
Validation loss: 2.526526925384357

Epoch: 5| Step: 10
Training loss: 2.266061305999756
Validation loss: 2.512229932251797

Epoch: 41| Step: 0
Training loss: 3.025139093399048
Validation loss: 2.491094684088102

Epoch: 5| Step: 1
Training loss: 2.348538637161255
Validation loss: 2.4803006136289207

Epoch: 5| Step: 2
Training loss: 2.6070165634155273
Validation loss: 2.4766856367870043

Epoch: 5| Step: 3
Training loss: 2.885141372680664
Validation loss: 2.477939003257341

Epoch: 5| Step: 4
Training loss: 2.917746067047119
Validation loss: 2.4789870144218527

Epoch: 5| Step: 5
Training loss: 2.74065899848938
Validation loss: 2.4747726865994033

Epoch: 5| Step: 6
Training loss: 2.323975086212158
Validation loss: 2.4702189353204544

Epoch: 5| Step: 7
Training loss: 2.8705055713653564
Validation loss: 2.467690549870973

Epoch: 5| Step: 8
Training loss: 2.7617347240448
Validation loss: 2.4709801007342596

Epoch: 5| Step: 9
Training loss: 2.54773211479187
Validation loss: 2.469132077309393

Epoch: 5| Step: 10
Training loss: 2.4313716888427734
Validation loss: 2.4729826142711024

Epoch: 42| Step: 0
Training loss: 3.0437886714935303
Validation loss: 2.4669562693565124

Epoch: 5| Step: 1
Training loss: 2.4287588596343994
Validation loss: 2.4719117226139193

Epoch: 5| Step: 2
Training loss: 2.530824661254883
Validation loss: 2.4747175016710834

Epoch: 5| Step: 3
Training loss: 3.245163679122925
Validation loss: 2.474488091725175

Epoch: 5| Step: 4
Training loss: 2.292672634124756
Validation loss: 2.4659475613665838

Epoch: 5| Step: 5
Training loss: 2.165306806564331
Validation loss: 2.4582030209161903

Epoch: 5| Step: 6
Training loss: 2.5062625408172607
Validation loss: 2.4585914355452343

Epoch: 5| Step: 7
Training loss: 2.7520556449890137
Validation loss: 2.45930548637144

Epoch: 5| Step: 8
Training loss: 2.6953086853027344
Validation loss: 2.467135339654902

Epoch: 5| Step: 9
Training loss: 3.1585018634796143
Validation loss: 2.4707279359140704

Epoch: 5| Step: 10
Training loss: 2.731236457824707
Validation loss: 2.473082924401888

Epoch: 43| Step: 0
Training loss: 2.9705746173858643
Validation loss: 2.4654730237940305

Epoch: 5| Step: 1
Training loss: 2.9524173736572266
Validation loss: 2.4660813859713975

Epoch: 5| Step: 2
Training loss: 2.6670756340026855
Validation loss: 2.474344486831337

Epoch: 5| Step: 3
Training loss: 2.5188610553741455
Validation loss: 2.4975574657481205

Epoch: 5| Step: 4
Training loss: 2.211771249771118
Validation loss: 2.5230624239931823

Epoch: 5| Step: 5
Training loss: 3.0068511962890625
Validation loss: 2.5312650203704834

Epoch: 5| Step: 6
Training loss: 2.0864005088806152
Validation loss: 2.5017590804766585

Epoch: 5| Step: 7
Training loss: 2.4484870433807373
Validation loss: 2.467643384010561

Epoch: 5| Step: 8
Training loss: 2.7119345664978027
Validation loss: 2.4513757151942097

Epoch: 5| Step: 9
Training loss: 2.7182304859161377
Validation loss: 2.462666634590395

Epoch: 5| Step: 10
Training loss: 3.401498556137085
Validation loss: 2.462799500393611

Epoch: 44| Step: 0
Training loss: 2.3462936878204346
Validation loss: 2.469047172095186

Epoch: 5| Step: 1
Training loss: 2.2956583499908447
Validation loss: 2.4721144142971245

Epoch: 5| Step: 2
Training loss: 2.0955405235290527
Validation loss: 2.469386359696747

Epoch: 5| Step: 3
Training loss: 3.158906936645508
Validation loss: 2.4563425715251634

Epoch: 5| Step: 4
Training loss: 2.616844892501831
Validation loss: 2.458669606075492

Epoch: 5| Step: 5
Training loss: 2.9327876567840576
Validation loss: 2.444523460121565

Epoch: 5| Step: 6
Training loss: 2.765901803970337
Validation loss: 2.445091729523033

Epoch: 5| Step: 7
Training loss: 3.2590606212615967
Validation loss: 2.44943053748018

Epoch: 5| Step: 8
Training loss: 2.531294584274292
Validation loss: 2.453556796555878

Epoch: 5| Step: 9
Training loss: 2.5048654079437256
Validation loss: 2.455941459184052

Epoch: 5| Step: 10
Training loss: 3.1098194122314453
Validation loss: 2.4502961827862646

Epoch: 45| Step: 0
Training loss: 2.501774549484253
Validation loss: 2.4427716808934368

Epoch: 5| Step: 1
Training loss: 2.6263089179992676
Validation loss: 2.441814668716923

Epoch: 5| Step: 2
Training loss: 2.5561776161193848
Validation loss: 2.4398944890627297

Epoch: 5| Step: 3
Training loss: 2.1459641456604004
Validation loss: 2.443059734118882

Epoch: 5| Step: 4
Training loss: 2.749647378921509
Validation loss: 2.4390443730097946

Epoch: 5| Step: 5
Training loss: 2.4557137489318848
Validation loss: 2.4368872693789903

Epoch: 5| Step: 6
Training loss: 2.8440101146698
Validation loss: 2.4424217349739483

Epoch: 5| Step: 7
Training loss: 2.534045696258545
Validation loss: 2.447923575678179

Epoch: 5| Step: 8
Training loss: 2.8246779441833496
Validation loss: 2.455133125346194

Epoch: 5| Step: 9
Training loss: 3.0060157775878906
Validation loss: 2.4693498534540974

Epoch: 5| Step: 10
Training loss: 3.2053067684173584
Validation loss: 2.4891479886988157

Epoch: 46| Step: 0
Training loss: 2.7911291122436523
Validation loss: 2.4793729987195743

Epoch: 5| Step: 1
Training loss: 3.031006097793579
Validation loss: 2.4725565089974353

Epoch: 5| Step: 2
Training loss: 3.118746519088745
Validation loss: 2.4618626781689223

Epoch: 5| Step: 3
Training loss: 2.8087010383605957
Validation loss: 2.4611342696733374

Epoch: 5| Step: 4
Training loss: 2.487863540649414
Validation loss: 2.4452118412140877

Epoch: 5| Step: 5
Training loss: 2.2701926231384277
Validation loss: 2.4376996383872083

Epoch: 5| Step: 6
Training loss: 2.2192554473876953
Validation loss: 2.4330603820021435

Epoch: 5| Step: 7
Training loss: 2.274697780609131
Validation loss: 2.4369906430603354

Epoch: 5| Step: 8
Training loss: 2.8148765563964844
Validation loss: 2.4337770682509228

Epoch: 5| Step: 9
Training loss: 2.0869624614715576
Validation loss: 2.4357957698965587

Epoch: 5| Step: 10
Training loss: 3.6862998008728027
Validation loss: 2.43330813992408

Epoch: 47| Step: 0
Training loss: 2.8052477836608887
Validation loss: 2.4323628128215833

Epoch: 5| Step: 1
Training loss: 2.198030471801758
Validation loss: 2.430629017532513

Epoch: 5| Step: 2
Training loss: 2.410921812057495
Validation loss: 2.42883494336118

Epoch: 5| Step: 3
Training loss: 2.2679638862609863
Validation loss: 2.434761493436752

Epoch: 5| Step: 4
Training loss: 2.6757616996765137
Validation loss: 2.443607058576358

Epoch: 5| Step: 5
Training loss: 2.5888333320617676
Validation loss: 2.446870001413489

Epoch: 5| Step: 6
Training loss: 2.9449563026428223
Validation loss: 2.4570639287271807

Epoch: 5| Step: 7
Training loss: 2.8610920906066895
Validation loss: 2.4577352308457896

Epoch: 5| Step: 8
Training loss: 2.925570249557495
Validation loss: 2.477551532048051

Epoch: 5| Step: 9
Training loss: 2.8713066577911377
Validation loss: 2.4881892563194357

Epoch: 5| Step: 10
Training loss: 2.8636980056762695
Validation loss: 2.502791134260034

Epoch: 48| Step: 0
Training loss: 3.088428497314453
Validation loss: 2.484890114876532

Epoch: 5| Step: 1
Training loss: 2.242244243621826
Validation loss: 2.452623398073258

Epoch: 5| Step: 2
Training loss: 2.9434990882873535
Validation loss: 2.43263554316695

Epoch: 5| Step: 3
Training loss: 2.8280818462371826
Validation loss: 2.4234769113602175

Epoch: 5| Step: 4
Training loss: 2.3626136779785156
Validation loss: 2.418505225130307

Epoch: 5| Step: 5
Training loss: 2.8141391277313232
Validation loss: 2.4151505372857534

Epoch: 5| Step: 6
Training loss: 2.8294177055358887
Validation loss: 2.416445691098449

Epoch: 5| Step: 7
Training loss: 2.028423547744751
Validation loss: 2.422657330830892

Epoch: 5| Step: 8
Training loss: 2.6935439109802246
Validation loss: 2.425293137950282

Epoch: 5| Step: 9
Training loss: 2.9532909393310547
Validation loss: 2.424486329478602

Epoch: 5| Step: 10
Training loss: 2.61765456199646
Validation loss: 2.419333524601434

Epoch: 49| Step: 0
Training loss: 3.2639546394348145
Validation loss: 2.4154699233270462

Epoch: 5| Step: 1
Training loss: 1.9995968341827393
Validation loss: 2.4152210361214093

Epoch: 5| Step: 2
Training loss: 2.5411229133605957
Validation loss: 2.4108789556769916

Epoch: 5| Step: 3
Training loss: 2.4006142616271973
Validation loss: 2.4112019103060485

Epoch: 5| Step: 4
Training loss: 2.379899501800537
Validation loss: 2.4165316499689573

Epoch: 5| Step: 5
Training loss: 2.556398391723633
Validation loss: 2.418464632444484

Epoch: 5| Step: 6
Training loss: 2.650111198425293
Validation loss: 2.4355049261482815

Epoch: 5| Step: 7
Training loss: 3.7309517860412598
Validation loss: 2.4594867242279874

Epoch: 5| Step: 8
Training loss: 2.495375156402588
Validation loss: 2.4539941203209663

Epoch: 5| Step: 9
Training loss: 2.545358180999756
Validation loss: 2.4537406582986154

Epoch: 5| Step: 10
Training loss: 2.7269883155822754
Validation loss: 2.450196196956019

Epoch: 50| Step: 0
Training loss: 2.9410805702209473
Validation loss: 2.4445724128395

Epoch: 5| Step: 1
Training loss: 2.7286298274993896
Validation loss: 2.4316594549404678

Epoch: 5| Step: 2
Training loss: 2.945382833480835
Validation loss: 2.4207850912565827

Epoch: 5| Step: 3
Training loss: 2.2761435508728027
Validation loss: 2.4149297873179116

Epoch: 5| Step: 4
Training loss: 2.250511646270752
Validation loss: 2.406602721060476

Epoch: 5| Step: 5
Training loss: 2.175576686859131
Validation loss: 2.4060667509673745

Epoch: 5| Step: 6
Training loss: 2.5227532386779785
Validation loss: 2.407394791162142

Epoch: 5| Step: 7
Training loss: 2.8217077255249023
Validation loss: 2.4071446862272037

Epoch: 5| Step: 8
Training loss: 2.5644805431365967
Validation loss: 2.4080651780610443

Epoch: 5| Step: 9
Training loss: 3.033386707305908
Validation loss: 2.4035223043093117

Epoch: 5| Step: 10
Training loss: 3.061591863632202
Validation loss: 2.402471157812303

Epoch: 51| Step: 0
Training loss: 2.871915340423584
Validation loss: 2.403134653645177

Epoch: 5| Step: 1
Training loss: 2.8977441787719727
Validation loss: 2.4049938519795737

Epoch: 5| Step: 2
Training loss: 2.9199042320251465
Validation loss: 2.4123720584377164

Epoch: 5| Step: 3
Training loss: 2.7344727516174316
Validation loss: 2.4176890516793854

Epoch: 5| Step: 4
Training loss: 2.928732395172119
Validation loss: 2.4125417893932712

Epoch: 5| Step: 5
Training loss: 2.929091691970825
Validation loss: 2.4063155189637215

Epoch: 5| Step: 6
Training loss: 2.244868516921997
Validation loss: 2.3989262196325485

Epoch: 5| Step: 7
Training loss: 2.37003755569458
Validation loss: 2.3947191699858634

Epoch: 5| Step: 8
Training loss: 1.8764543533325195
Validation loss: 2.3939811619379188

Epoch: 5| Step: 9
Training loss: 1.9962213039398193
Validation loss: 2.399901569530528

Epoch: 5| Step: 10
Training loss: 3.4103214740753174
Validation loss: 2.432444149448026

Epoch: 52| Step: 0
Training loss: 2.6158366203308105
Validation loss: 2.4657325180627967

Epoch: 5| Step: 1
Training loss: 2.8880362510681152
Validation loss: 2.484160651442825

Epoch: 5| Step: 2
Training loss: 3.024982452392578
Validation loss: 2.4821746298061904

Epoch: 5| Step: 3
Training loss: 2.8714396953582764
Validation loss: 2.4450606530712498

Epoch: 5| Step: 4
Training loss: 2.341003179550171
Validation loss: 2.4345006994021836

Epoch: 5| Step: 5
Training loss: 2.734116792678833
Validation loss: 2.4139053334472

Epoch: 5| Step: 6
Training loss: 2.732386589050293
Validation loss: 2.397441094921481

Epoch: 5| Step: 7
Training loss: 3.062835693359375
Validation loss: 2.3928322279325096

Epoch: 5| Step: 8
Training loss: 2.937561511993408
Validation loss: 2.387839173757902

Epoch: 5| Step: 9
Training loss: 2.2965545654296875
Validation loss: 2.388169933390874

Epoch: 5| Step: 10
Training loss: 1.6472569704055786
Validation loss: 2.3938214804536555

Epoch: 53| Step: 0
Training loss: 2.6722397804260254
Validation loss: 2.401014656148931

Epoch: 5| Step: 1
Training loss: 3.0059847831726074
Validation loss: 2.412789402469512

Epoch: 5| Step: 2
Training loss: 2.3302817344665527
Validation loss: 2.424075142029793

Epoch: 5| Step: 3
Training loss: 2.7126576900482178
Validation loss: 2.431366059087938

Epoch: 5| Step: 4
Training loss: 2.828573226928711
Validation loss: 2.455650293698875

Epoch: 5| Step: 5
Training loss: 2.951981544494629
Validation loss: 2.4720553069986324

Epoch: 5| Step: 6
Training loss: 1.6401937007904053
Validation loss: 2.4728028569170224

Epoch: 5| Step: 7
Training loss: 3.2599620819091797
Validation loss: 2.424681314858057

Epoch: 5| Step: 8
Training loss: 2.74676775932312
Validation loss: 2.3982296720627816

Epoch: 5| Step: 9
Training loss: 2.3425192832946777
Validation loss: 2.3821132439439014

Epoch: 5| Step: 10
Training loss: 2.7792930603027344
Validation loss: 2.3858797268200944

Epoch: 54| Step: 0
Training loss: 2.802708864212036
Validation loss: 2.397055051660025

Epoch: 5| Step: 1
Training loss: 3.154716730117798
Validation loss: 2.4021190058800483

Epoch: 5| Step: 2
Training loss: 1.9630448818206787
Validation loss: 2.3835902701142015

Epoch: 5| Step: 3
Training loss: 2.7996444702148438
Validation loss: 2.380223435740317

Epoch: 5| Step: 4
Training loss: 2.508491039276123
Validation loss: 2.3745153104105303

Epoch: 5| Step: 5
Training loss: 2.093656063079834
Validation loss: 2.370928209315064

Epoch: 5| Step: 6
Training loss: 2.5878853797912598
Validation loss: 2.3750904426779798

Epoch: 5| Step: 7
Training loss: 2.9409213066101074
Validation loss: 2.36731582303201

Epoch: 5| Step: 8
Training loss: 2.6012954711914062
Validation loss: 2.362304428572296

Epoch: 5| Step: 9
Training loss: 2.765958309173584
Validation loss: 2.364506092122806

Epoch: 5| Step: 10
Training loss: 2.873596429824829
Validation loss: 2.378792965283958

Epoch: 55| Step: 0
Training loss: 2.75842547416687
Validation loss: 2.377464891761862

Epoch: 5| Step: 1
Training loss: 2.0845255851745605
Validation loss: 2.367660686533938

Epoch: 5| Step: 2
Training loss: 2.508302688598633
Validation loss: 2.3648788646985124

Epoch: 5| Step: 3
Training loss: 2.8429784774780273
Validation loss: 2.3604936240821757

Epoch: 5| Step: 4
Training loss: 2.5909931659698486
Validation loss: 2.3565429820809314

Epoch: 5| Step: 5
Training loss: 2.6054847240448
Validation loss: 2.357097436023015

Epoch: 5| Step: 6
Training loss: 2.7166991233825684
Validation loss: 2.361605674989762

Epoch: 5| Step: 7
Training loss: 2.985377788543701
Validation loss: 2.3692142809590986

Epoch: 5| Step: 8
Training loss: 3.2463104724884033
Validation loss: 2.36695441379342

Epoch: 5| Step: 9
Training loss: 1.948664665222168
Validation loss: 2.3668386346550396

Epoch: 5| Step: 10
Training loss: 2.668973445892334
Validation loss: 2.3728388893988823

Epoch: 56| Step: 0
Training loss: 2.9173367023468018
Validation loss: 2.386518391229773

Epoch: 5| Step: 1
Training loss: 2.8392081260681152
Validation loss: 2.396280442514727

Epoch: 5| Step: 2
Training loss: 3.2560906410217285
Validation loss: 2.4038823650729273

Epoch: 5| Step: 3
Training loss: 2.2303225994110107
Validation loss: 2.378111159929665

Epoch: 5| Step: 4
Training loss: 2.5794143676757812
Validation loss: 2.36098046969342

Epoch: 5| Step: 5
Training loss: 2.5983190536499023
Validation loss: 2.3523381935652865

Epoch: 5| Step: 6
Training loss: 2.982004404067993
Validation loss: 2.3569555987593946

Epoch: 5| Step: 7
Training loss: 1.9162509441375732
Validation loss: 2.3744701531625565

Epoch: 5| Step: 8
Training loss: 2.9017724990844727
Validation loss: 2.400538306082449

Epoch: 5| Step: 9
Training loss: 1.663026213645935
Validation loss: 2.3909682663538123

Epoch: 5| Step: 10
Training loss: 2.9686169624328613
Validation loss: 2.415675773415514

Epoch: 57| Step: 0
Training loss: 2.658738613128662
Validation loss: 2.4326899743849233

Epoch: 5| Step: 1
Training loss: 3.133718967437744
Validation loss: 2.4545984447643323

Epoch: 5| Step: 2
Training loss: 3.047780990600586
Validation loss: 2.463417063477219

Epoch: 5| Step: 3
Training loss: 2.0932421684265137
Validation loss: 2.4388075823424966

Epoch: 5| Step: 4
Training loss: 2.705767869949341
Validation loss: 2.4210914258033998

Epoch: 5| Step: 5
Training loss: 2.7890312671661377
Validation loss: 2.382901204529629

Epoch: 5| Step: 6
Training loss: 2.4967827796936035
Validation loss: 2.3648994866237847

Epoch: 5| Step: 7
Training loss: 2.7330360412597656
Validation loss: 2.361852184418709

Epoch: 5| Step: 8
Training loss: 1.8707120418548584
Validation loss: 2.3469906058362735

Epoch: 5| Step: 9
Training loss: 2.702937602996826
Validation loss: 2.3454006615505425

Epoch: 5| Step: 10
Training loss: 2.6394717693328857
Validation loss: 2.3459095416530484

Epoch: 58| Step: 0
Training loss: 3.069648265838623
Validation loss: 2.351373959613103

Epoch: 5| Step: 1
Training loss: 2.5348687171936035
Validation loss: 2.350115758116527

Epoch: 5| Step: 2
Training loss: 3.0406219959259033
Validation loss: 2.347835830462876

Epoch: 5| Step: 3
Training loss: 1.9974539279937744
Validation loss: 2.342690008942799

Epoch: 5| Step: 4
Training loss: 2.7207939624786377
Validation loss: 2.3378734614259455

Epoch: 5| Step: 5
Training loss: 3.0133886337280273
Validation loss: 2.3332789533881733

Epoch: 5| Step: 6
Training loss: 2.6871871948242188
Validation loss: 2.337426454790177

Epoch: 5| Step: 7
Training loss: 2.5436973571777344
Validation loss: 2.348983751830234

Epoch: 5| Step: 8
Training loss: 2.4389610290527344
Validation loss: 2.3530570332722

Epoch: 5| Step: 9
Training loss: 2.481293201446533
Validation loss: 2.3719075854106615

Epoch: 5| Step: 10
Training loss: 2.3663554191589355
Validation loss: 2.372900847465761

Epoch: 59| Step: 0
Training loss: 2.76708722114563
Validation loss: 2.359209111941758

Epoch: 5| Step: 1
Training loss: 2.546779155731201
Validation loss: 2.3558479175772717

Epoch: 5| Step: 2
Training loss: 2.2478556632995605
Validation loss: 2.3577802924699682

Epoch: 5| Step: 3
Training loss: 2.8910629749298096
Validation loss: 2.356843258744927

Epoch: 5| Step: 4
Training loss: 3.0311858654022217
Validation loss: 2.3663749207732496

Epoch: 5| Step: 5
Training loss: 3.033416748046875
Validation loss: 2.3688277582968436

Epoch: 5| Step: 6
Training loss: 2.6349072456359863
Validation loss: 2.3439474592926683

Epoch: 5| Step: 7
Training loss: 2.517307758331299
Validation loss: 2.3310770142462944

Epoch: 5| Step: 8
Training loss: 2.722151041030884
Validation loss: 2.332325040653188

Epoch: 5| Step: 9
Training loss: 1.8749198913574219
Validation loss: 2.3270205631051013

Epoch: 5| Step: 10
Training loss: 2.3621387481689453
Validation loss: 2.332911309375558

Epoch: 60| Step: 0
Training loss: 3.0184128284454346
Validation loss: 2.334873625027236

Epoch: 5| Step: 1
Training loss: 2.97267746925354
Validation loss: 2.3376779043546287

Epoch: 5| Step: 2
Training loss: 2.8030266761779785
Validation loss: 2.3240191423764793

Epoch: 5| Step: 3
Training loss: 2.877077579498291
Validation loss: 2.3177362257434475

Epoch: 5| Step: 4
Training loss: 2.6330418586730957
Validation loss: 2.3195466508147535

Epoch: 5| Step: 5
Training loss: 2.094113826751709
Validation loss: 2.3259092043804865

Epoch: 5| Step: 6
Training loss: 2.718611240386963
Validation loss: 2.318558649350238

Epoch: 5| Step: 7
Training loss: 2.1145150661468506
Validation loss: 2.3321829970164965

Epoch: 5| Step: 8
Training loss: 2.64151930809021
Validation loss: 2.340448059061522

Epoch: 5| Step: 9
Training loss: 2.0953826904296875
Validation loss: 2.340858012117365

Epoch: 5| Step: 10
Training loss: 2.653029680252075
Validation loss: 2.34104989164619

Epoch: 61| Step: 0
Training loss: 2.4104995727539062
Validation loss: 2.3528417438589115

Epoch: 5| Step: 1
Training loss: 2.4898486137390137
Validation loss: 2.346198897207937

Epoch: 5| Step: 2
Training loss: 3.425713300704956
Validation loss: 2.3575752114736908

Epoch: 5| Step: 3
Training loss: 2.9804065227508545
Validation loss: 2.3528002769716325

Epoch: 5| Step: 4
Training loss: 2.4351353645324707
Validation loss: 2.340178935758529

Epoch: 5| Step: 5
Training loss: 2.594238758087158
Validation loss: 2.326754705880278

Epoch: 5| Step: 6
Training loss: 3.378253936767578
Validation loss: 2.3210489416635163

Epoch: 5| Step: 7
Training loss: 2.049018621444702
Validation loss: 2.315299362264654

Epoch: 5| Step: 8
Training loss: 2.417879343032837
Validation loss: 2.314340309430194

Epoch: 5| Step: 9
Training loss: 2.4787278175354004
Validation loss: 2.312220581116215

Epoch: 5| Step: 10
Training loss: 1.806832194328308
Validation loss: 2.30847752991543

Epoch: 62| Step: 0
Training loss: 2.6410319805145264
Validation loss: 2.313379427438141

Epoch: 5| Step: 1
Training loss: 2.7065491676330566
Validation loss: 2.3156816779926257

Epoch: 5| Step: 2
Training loss: 1.7660636901855469
Validation loss: 2.312301212741483

Epoch: 5| Step: 3
Training loss: 2.822335958480835
Validation loss: 2.308659763746364

Epoch: 5| Step: 4
Training loss: 2.5394184589385986
Validation loss: 2.309628455869613

Epoch: 5| Step: 5
Training loss: 2.279435396194458
Validation loss: 2.3152467102132817

Epoch: 5| Step: 6
Training loss: 2.0631134510040283
Validation loss: 2.321509130539433

Epoch: 5| Step: 7
Training loss: 2.417724609375
Validation loss: 2.33351759500401

Epoch: 5| Step: 8
Training loss: 2.7063610553741455
Validation loss: 2.3516242504119873

Epoch: 5| Step: 9
Training loss: 3.6038832664489746
Validation loss: 2.37202791501117

Epoch: 5| Step: 10
Training loss: 3.0273847579956055
Validation loss: 2.3754783112515687

Epoch: 63| Step: 0
Training loss: 2.6070327758789062
Validation loss: 2.3633396369154736

Epoch: 5| Step: 1
Training loss: 2.951315402984619
Validation loss: 2.3685637776569655

Epoch: 5| Step: 2
Training loss: 2.4270694255828857
Validation loss: 2.3753428074621383

Epoch: 5| Step: 3
Training loss: 2.57850980758667
Validation loss: 2.3875692659808743

Epoch: 5| Step: 4
Training loss: 3.1054303646087646
Validation loss: 2.383891692725561

Epoch: 5| Step: 5
Training loss: 2.9378607273101807
Validation loss: 2.3770662969158542

Epoch: 5| Step: 6
Training loss: 2.461385726928711
Validation loss: 2.3450313691169984

Epoch: 5| Step: 7
Training loss: 2.5348267555236816
Validation loss: 2.3345809675032094

Epoch: 5| Step: 8
Training loss: 2.6440365314483643
Validation loss: 2.323988345361525

Epoch: 5| Step: 9
Training loss: 2.1562843322753906
Validation loss: 2.3254531686024

Epoch: 5| Step: 10
Training loss: 1.9926022291183472
Validation loss: 2.3269307075008268

Epoch: 64| Step: 0
Training loss: 2.789447546005249
Validation loss: 2.3229505349231023

Epoch: 5| Step: 1
Training loss: 2.2008883953094482
Validation loss: 2.31904439772329

Epoch: 5| Step: 2
Training loss: 2.5983214378356934
Validation loss: 2.3150271343928512

Epoch: 5| Step: 3
Training loss: 3.037858009338379
Validation loss: 2.3200693566312074

Epoch: 5| Step: 4
Training loss: 2.36470890045166
Validation loss: 2.315706758088963

Epoch: 5| Step: 5
Training loss: 2.6342029571533203
Validation loss: 2.317332234433902

Epoch: 5| Step: 6
Training loss: 2.9997894763946533
Validation loss: 2.32445119145096

Epoch: 5| Step: 7
Training loss: 2.207805871963501
Validation loss: 2.3369640945106425

Epoch: 5| Step: 8
Training loss: 2.3684871196746826
Validation loss: 2.3384082471170733

Epoch: 5| Step: 9
Training loss: 2.436410427093506
Validation loss: 2.319307250361289

Epoch: 5| Step: 10
Training loss: 2.731210231781006
Validation loss: 2.320163542224515

Epoch: 65| Step: 0
Training loss: 2.652008533477783
Validation loss: 2.325630613552627

Epoch: 5| Step: 1
Training loss: 2.081186532974243
Validation loss: 2.3144578010805192

Epoch: 5| Step: 2
Training loss: 2.8548972606658936
Validation loss: 2.310068481711931

Epoch: 5| Step: 3
Training loss: 2.5933172702789307
Validation loss: 2.31143029018115

Epoch: 5| Step: 4
Training loss: 2.6012320518493652
Validation loss: 2.3134601654544955

Epoch: 5| Step: 5
Training loss: 2.2392845153808594
Validation loss: 2.313814519554056

Epoch: 5| Step: 6
Training loss: 2.771195411682129
Validation loss: 2.3112434110333844

Epoch: 5| Step: 7
Training loss: 2.5224366188049316
Validation loss: 2.310971677944224

Epoch: 5| Step: 8
Training loss: 2.473050117492676
Validation loss: 2.310022847626799

Epoch: 5| Step: 9
Training loss: 2.7461931705474854
Validation loss: 2.3149269344986125

Epoch: 5| Step: 10
Training loss: 2.783352851867676
Validation loss: 2.3269727281344834

Epoch: 66| Step: 0
Training loss: 2.8765742778778076
Validation loss: 2.3394658232247956

Epoch: 5| Step: 1
Training loss: 2.8620409965515137
Validation loss: 2.35207712265753

Epoch: 5| Step: 2
Training loss: 2.8746044635772705
Validation loss: 2.3513153599154566

Epoch: 5| Step: 3
Training loss: 2.0824027061462402
Validation loss: 2.345504956860696

Epoch: 5| Step: 4
Training loss: 2.4931302070617676
Validation loss: 2.3366220381952103

Epoch: 5| Step: 5
Training loss: 2.4676156044006348
Validation loss: 2.3205024119346374

Epoch: 5| Step: 6
Training loss: 2.858517646789551
Validation loss: 2.3053478194821264

Epoch: 5| Step: 7
Training loss: 2.5364112854003906
Validation loss: 2.2958959584595053

Epoch: 5| Step: 8
Training loss: 2.4788737297058105
Validation loss: 2.295460216460689

Epoch: 5| Step: 9
Training loss: 2.245420455932617
Validation loss: 2.2999513226170696

Epoch: 5| Step: 10
Training loss: 2.5465056896209717
Validation loss: 2.2969837880903676

Epoch: 67| Step: 0
Training loss: 2.2264275550842285
Validation loss: 2.296272659814486

Epoch: 5| Step: 1
Training loss: 3.235210418701172
Validation loss: 2.2945477680493425

Epoch: 5| Step: 2
Training loss: 2.5923447608947754
Validation loss: 2.2827872691615934

Epoch: 5| Step: 3
Training loss: 2.759748697280884
Validation loss: 2.278882234327255

Epoch: 5| Step: 4
Training loss: 2.7501556873321533
Validation loss: 2.288159696004724

Epoch: 5| Step: 5
Training loss: 3.050203323364258
Validation loss: 2.2895700931549072

Epoch: 5| Step: 6
Training loss: 2.761427640914917
Validation loss: 2.289930761501353

Epoch: 5| Step: 7
Training loss: 1.9970791339874268
Validation loss: 2.301804424614035

Epoch: 5| Step: 8
Training loss: 1.9460229873657227
Validation loss: 2.290802924863754

Epoch: 5| Step: 9
Training loss: 2.148495674133301
Validation loss: 2.2960567884547736

Epoch: 5| Step: 10
Training loss: 2.8598241806030273
Validation loss: 2.2965880747764342

Epoch: 68| Step: 0
Training loss: 2.3452885150909424
Validation loss: 2.305883140974147

Epoch: 5| Step: 1
Training loss: 2.921875476837158
Validation loss: 2.307378597156976

Epoch: 5| Step: 2
Training loss: 3.1227917671203613
Validation loss: 2.2936502554083384

Epoch: 5| Step: 3
Training loss: 2.2161638736724854
Validation loss: 2.276511617886123

Epoch: 5| Step: 4
Training loss: 2.5152335166931152
Validation loss: 2.2818030695761404

Epoch: 5| Step: 5
Training loss: 2.9336676597595215
Validation loss: 2.287143268892842

Epoch: 5| Step: 6
Training loss: 2.6059656143188477
Validation loss: 2.2906803930959394

Epoch: 5| Step: 7
Training loss: 2.4182190895080566
Validation loss: 2.29930309326418

Epoch: 5| Step: 8
Training loss: 2.1777243614196777
Validation loss: 2.3091322324609243

Epoch: 5| Step: 9
Training loss: 2.7318172454833984
Validation loss: 2.3173874655077533

Epoch: 5| Step: 10
Training loss: 2.16733717918396
Validation loss: 2.3331821041722454

Epoch: 69| Step: 0
Training loss: 2.3432462215423584
Validation loss: 2.335723853880359

Epoch: 5| Step: 1
Training loss: 2.331406593322754
Validation loss: 2.3384689156727125

Epoch: 5| Step: 2
Training loss: 2.895423650741577
Validation loss: 2.345366883021529

Epoch: 5| Step: 3
Training loss: 2.3434641361236572
Validation loss: 2.3321591115766958

Epoch: 5| Step: 4
Training loss: 2.9052021503448486
Validation loss: 2.307124440388013

Epoch: 5| Step: 5
Training loss: 2.109429359436035
Validation loss: 2.281630144324354

Epoch: 5| Step: 6
Training loss: 2.6415882110595703
Validation loss: 2.273339468945739

Epoch: 5| Step: 7
Training loss: 3.548828601837158
Validation loss: 2.2780813247926774

Epoch: 5| Step: 8
Training loss: 1.7083232402801514
Validation loss: 2.2885249891588764

Epoch: 5| Step: 9
Training loss: 2.906848430633545
Validation loss: 2.2929792173447145

Epoch: 5| Step: 10
Training loss: 2.717435598373413
Validation loss: 2.3036362817210536

Epoch: 70| Step: 0
Training loss: 2.940647602081299
Validation loss: 2.308543743625764

Epoch: 5| Step: 1
Training loss: 2.3834567070007324
Validation loss: 2.2994162267254246

Epoch: 5| Step: 2
Training loss: 2.353656530380249
Validation loss: 2.2992768415840725

Epoch: 5| Step: 3
Training loss: 2.5598504543304443
Validation loss: 2.2927574034660094

Epoch: 5| Step: 4
Training loss: 3.443480968475342
Validation loss: 2.281019159542617

Epoch: 5| Step: 5
Training loss: 2.493786573410034
Validation loss: 2.2695867605106805

Epoch: 5| Step: 6
Training loss: 2.838834762573242
Validation loss: 2.283535603554018

Epoch: 5| Step: 7
Training loss: 2.9791200160980225
Validation loss: 2.3118184381915676

Epoch: 5| Step: 8
Training loss: 1.7306150197982788
Validation loss: 2.3785183609172864

Epoch: 5| Step: 9
Training loss: 2.2149596214294434
Validation loss: 2.3937904424564813

Epoch: 5| Step: 10
Training loss: 2.187311887741089
Validation loss: 2.441826307645408

Epoch: 71| Step: 0
Training loss: 2.273489236831665
Validation loss: 2.436523901518955

Epoch: 5| Step: 1
Training loss: 2.333767890930176
Validation loss: 2.4232266397886377

Epoch: 5| Step: 2
Training loss: 2.846954822540283
Validation loss: 2.402988854274955

Epoch: 5| Step: 3
Training loss: 2.9945595264434814
Validation loss: 2.3570265000866306

Epoch: 5| Step: 4
Training loss: 2.067155122756958
Validation loss: 2.3158941653466996

Epoch: 5| Step: 5
Training loss: 2.921247959136963
Validation loss: 2.3024706071422947

Epoch: 5| Step: 6
Training loss: 2.7767062187194824
Validation loss: 2.287070953717796

Epoch: 5| Step: 7
Training loss: 2.528782367706299
Validation loss: 2.287309673524672

Epoch: 5| Step: 8
Training loss: 2.3358309268951416
Validation loss: 2.296560113148023

Epoch: 5| Step: 9
Training loss: 2.562760353088379
Validation loss: 2.2941260440375215

Epoch: 5| Step: 10
Training loss: 2.6395697593688965
Validation loss: 2.2927228404629614

Epoch: 72| Step: 0
Training loss: 3.169408082962036
Validation loss: 2.2893332435238745

Epoch: 5| Step: 1
Training loss: 3.071136474609375
Validation loss: 2.2871837615966797

Epoch: 5| Step: 2
Training loss: 2.030043125152588
Validation loss: 2.288005954475813

Epoch: 5| Step: 3
Training loss: 2.7481091022491455
Validation loss: 2.28474743904606

Epoch: 5| Step: 4
Training loss: 2.763957977294922
Validation loss: 2.2795688285622546

Epoch: 5| Step: 5
Training loss: 2.6807808876037598
Validation loss: 2.2651353292567755

Epoch: 5| Step: 6
Training loss: 1.808571219444275
Validation loss: 2.2567121803119616

Epoch: 5| Step: 7
Training loss: 2.5884721279144287
Validation loss: 2.2599712956336235

Epoch: 5| Step: 8
Training loss: 2.9412386417388916
Validation loss: 2.268068782744869

Epoch: 5| Step: 9
Training loss: 1.742863655090332
Validation loss: 2.283359066132576

Epoch: 5| Step: 10
Training loss: 2.740426540374756
Validation loss: 2.2849499961381317

Epoch: 73| Step: 0
Training loss: 2.036463975906372
Validation loss: 2.275468590439007

Epoch: 5| Step: 1
Training loss: 2.8118300437927246
Validation loss: 2.2778522968292236

Epoch: 5| Step: 2
Training loss: 3.0447452068328857
Validation loss: 2.275278176030805

Epoch: 5| Step: 3
Training loss: 2.3230483531951904
Validation loss: 2.2709271779624363

Epoch: 5| Step: 4
Training loss: 2.5458035469055176
Validation loss: 2.254000771430231

Epoch: 5| Step: 5
Training loss: 2.6730027198791504
Validation loss: 2.2563395448910293

Epoch: 5| Step: 6
Training loss: 2.804868221282959
Validation loss: 2.2617988522334764

Epoch: 5| Step: 7
Training loss: 2.761361598968506
Validation loss: 2.267369608725271

Epoch: 5| Step: 8
Training loss: 2.388150453567505
Validation loss: 2.285252232705393

Epoch: 5| Step: 9
Training loss: 2.119579792022705
Validation loss: 2.3049289898205827

Epoch: 5| Step: 10
Training loss: 2.4305078983306885
Validation loss: 2.2927924715062624

Epoch: 74| Step: 0
Training loss: 2.2855594158172607
Validation loss: 2.2882704914257093

Epoch: 5| Step: 1
Training loss: 2.4939398765563965
Validation loss: 2.2768176601779078

Epoch: 5| Step: 2
Training loss: 2.3125743865966797
Validation loss: 2.2648157355605916

Epoch: 5| Step: 3
Training loss: 2.7920727729797363
Validation loss: 2.2603526576872794

Epoch: 5| Step: 4
Training loss: 2.606228828430176
Validation loss: 2.2469850355579006

Epoch: 5| Step: 5
Training loss: 3.0380892753601074
Validation loss: 2.239058203594659

Epoch: 5| Step: 6
Training loss: 1.9397891759872437
Validation loss: 2.24173721959514

Epoch: 5| Step: 7
Training loss: 2.290532350540161
Validation loss: 2.2371503883792507

Epoch: 5| Step: 8
Training loss: 2.9046809673309326
Validation loss: 2.239454242490953

Epoch: 5| Step: 9
Training loss: 2.7124295234680176
Validation loss: 2.2398285327419156

Epoch: 5| Step: 10
Training loss: 2.307077646255493
Validation loss: 2.2383034818915912

Epoch: 75| Step: 0
Training loss: 1.9504528045654297
Validation loss: 2.238332812504102

Epoch: 5| Step: 1
Training loss: 2.951157331466675
Validation loss: 2.2538542850043184

Epoch: 5| Step: 2
Training loss: 2.9940288066864014
Validation loss: 2.26226818689736

Epoch: 5| Step: 3
Training loss: 2.643744707107544
Validation loss: 2.2616907473533385

Epoch: 5| Step: 4
Training loss: 2.7808549404144287
Validation loss: 2.264962680878178

Epoch: 5| Step: 5
Training loss: 2.901808261871338
Validation loss: 2.25423675967801

Epoch: 5| Step: 6
Training loss: 1.935225248336792
Validation loss: 2.2460935064541396

Epoch: 5| Step: 7
Training loss: 2.6204452514648438
Validation loss: 2.2543574404972855

Epoch: 5| Step: 8
Training loss: 2.2021613121032715
Validation loss: 2.2494505566935383

Epoch: 5| Step: 9
Training loss: 2.002101421356201
Validation loss: 2.2430742325321322

Epoch: 5| Step: 10
Training loss: 2.841024160385132
Validation loss: 2.2430696205426286

Epoch: 76| Step: 0
Training loss: 2.351022243499756
Validation loss: 2.2333191146132765

Epoch: 5| Step: 1
Training loss: 2.478637218475342
Validation loss: 2.231487415170157

Epoch: 5| Step: 2
Training loss: 2.8756439685821533
Validation loss: 2.2273880461210847

Epoch: 5| Step: 3
Training loss: 2.4113945960998535
Validation loss: 2.2235903201564664

Epoch: 5| Step: 4
Training loss: 3.012129306793213
Validation loss: 2.224633288639848

Epoch: 5| Step: 5
Training loss: 2.2315425872802734
Validation loss: 2.2296399326734644

Epoch: 5| Step: 6
Training loss: 2.536214590072632
Validation loss: 2.228360588832568

Epoch: 5| Step: 7
Training loss: 2.1231956481933594
Validation loss: 2.234964647600728

Epoch: 5| Step: 8
Training loss: 2.9628963470458984
Validation loss: 2.2317929806247836

Epoch: 5| Step: 9
Training loss: 2.554678201675415
Validation loss: 2.228403042721492

Epoch: 5| Step: 10
Training loss: 2.0363643169403076
Validation loss: 2.2293762699250252

Epoch: 77| Step: 0
Training loss: 2.205315113067627
Validation loss: 2.2288927339738414

Epoch: 5| Step: 1
Training loss: 3.0037403106689453
Validation loss: 2.2252936593947874

Epoch: 5| Step: 2
Training loss: 2.1934118270874023
Validation loss: 2.2345388474002963

Epoch: 5| Step: 3
Training loss: 3.001664876937866
Validation loss: 2.23498091390056

Epoch: 5| Step: 4
Training loss: 2.257099151611328
Validation loss: 2.2353800714656873

Epoch: 5| Step: 5
Training loss: 2.6526544094085693
Validation loss: 2.2384142260397635

Epoch: 5| Step: 6
Training loss: 2.8411495685577393
Validation loss: 2.236997341596952

Epoch: 5| Step: 7
Training loss: 2.4820868968963623
Validation loss: 2.2265054897595475

Epoch: 5| Step: 8
Training loss: 2.4435455799102783
Validation loss: 2.2337128987876316

Epoch: 5| Step: 9
Training loss: 2.02970552444458
Validation loss: 2.2326405099643174

Epoch: 5| Step: 10
Training loss: 2.573364734649658
Validation loss: 2.2437982405385664

Epoch: 78| Step: 0
Training loss: 3.3401038646698
Validation loss: 2.266814242127121

Epoch: 5| Step: 1
Training loss: 2.3739514350891113
Validation loss: 2.2862922376202

Epoch: 5| Step: 2
Training loss: 1.9926906824111938
Validation loss: 2.3009867309242167

Epoch: 5| Step: 3
Training loss: 2.6122238636016846
Validation loss: 2.280954312252742

Epoch: 5| Step: 4
Training loss: 1.8342609405517578
Validation loss: 2.2647978554489794

Epoch: 5| Step: 5
Training loss: 2.1002602577209473
Validation loss: 2.2435856634570706

Epoch: 5| Step: 6
Training loss: 2.637260675430298
Validation loss: 2.225876424902229

Epoch: 5| Step: 7
Training loss: 2.389007091522217
Validation loss: 2.2266458208842943

Epoch: 5| Step: 8
Training loss: 2.7344348430633545
Validation loss: 2.225651220608783

Epoch: 5| Step: 9
Training loss: 2.860201835632324
Validation loss: 2.219104684809203

Epoch: 5| Step: 10
Training loss: 2.691147565841675
Validation loss: 2.2250463372917584

Epoch: 79| Step: 0
Training loss: 2.567667007446289
Validation loss: 2.228972940034764

Epoch: 5| Step: 1
Training loss: 2.226086139678955
Validation loss: 2.2383585155651136

Epoch: 5| Step: 2
Training loss: 2.9303109645843506
Validation loss: 2.235323175307243

Epoch: 5| Step: 3
Training loss: 2.3360848426818848
Validation loss: 2.2295057363407587

Epoch: 5| Step: 4
Training loss: 2.380635976791382
Validation loss: 2.2283971694207962

Epoch: 5| Step: 5
Training loss: 2.5993075370788574
Validation loss: 2.2234082068166425

Epoch: 5| Step: 6
Training loss: 2.422907829284668
Validation loss: 2.2340279676580943

Epoch: 5| Step: 7
Training loss: 2.3063337802886963
Validation loss: 2.237450204869752

Epoch: 5| Step: 8
Training loss: 2.7570807933807373
Validation loss: 2.232662508564611

Epoch: 5| Step: 9
Training loss: 2.4575469493865967
Validation loss: 2.226907919811946

Epoch: 5| Step: 10
Training loss: 2.467628240585327
Validation loss: 2.221777218644337

Epoch: 80| Step: 0
Training loss: 2.5738308429718018
Validation loss: 2.2229338333170903

Epoch: 5| Step: 1
Training loss: 2.7260334491729736
Validation loss: 2.2164768313848846

Epoch: 5| Step: 2
Training loss: 2.5085058212280273
Validation loss: 2.211382407014088

Epoch: 5| Step: 3
Training loss: 2.609754800796509
Validation loss: 2.2120889284277476

Epoch: 5| Step: 4
Training loss: 2.3734874725341797
Validation loss: 2.216541092882874

Epoch: 5| Step: 5
Training loss: 2.3660120964050293
Validation loss: 2.2149165266303608

Epoch: 5| Step: 6
Training loss: 1.9351098537445068
Validation loss: 2.205097706087174

Epoch: 5| Step: 7
Training loss: 2.4593052864074707
Validation loss: 2.2100594594914424

Epoch: 5| Step: 8
Training loss: 2.141496181488037
Validation loss: 2.2105632059035765

Epoch: 5| Step: 9
Training loss: 2.8832504749298096
Validation loss: 2.220566629081644

Epoch: 5| Step: 10
Training loss: 2.868036985397339
Validation loss: 2.217317606813164

Epoch: 81| Step: 0
Training loss: 2.209834575653076
Validation loss: 2.222492774327596

Epoch: 5| Step: 1
Training loss: 2.976353406906128
Validation loss: 2.222350246162825

Epoch: 5| Step: 2
Training loss: 2.6847481727600098
Validation loss: 2.2125001030583538

Epoch: 5| Step: 3
Training loss: 3.520667314529419
Validation loss: 2.2004999858076855

Epoch: 5| Step: 4
Training loss: 1.6769578456878662
Validation loss: 2.1987806430426975

Epoch: 5| Step: 5
Training loss: 2.3684322834014893
Validation loss: 2.1958789645984607

Epoch: 5| Step: 6
Training loss: 2.0350542068481445
Validation loss: 2.197447789612637

Epoch: 5| Step: 7
Training loss: 2.2574777603149414
Validation loss: 2.2036287874303837

Epoch: 5| Step: 8
Training loss: 2.482114315032959
Validation loss: 2.2147450190718456

Epoch: 5| Step: 9
Training loss: 2.2098982334136963
Validation loss: 2.215349605006556

Epoch: 5| Step: 10
Training loss: 2.9995486736297607
Validation loss: 2.2189475054381997

Epoch: 82| Step: 0
Training loss: 2.4544458389282227
Validation loss: 2.2143863311377903

Epoch: 5| Step: 1
Training loss: 2.681027889251709
Validation loss: 2.210208723621984

Epoch: 5| Step: 2
Training loss: 2.1431570053100586
Validation loss: 2.2044454748912523

Epoch: 5| Step: 3
Training loss: 3.120314121246338
Validation loss: 2.208439116836876

Epoch: 5| Step: 4
Training loss: 3.007948160171509
Validation loss: 2.1996157835888606

Epoch: 5| Step: 5
Training loss: 2.7445685863494873
Validation loss: 2.202025194321909

Epoch: 5| Step: 6
Training loss: 2.726452350616455
Validation loss: 2.193715498011599

Epoch: 5| Step: 7
Training loss: 2.492204189300537
Validation loss: 2.1864580236455446

Epoch: 5| Step: 8
Training loss: 2.036557674407959
Validation loss: 2.1911163176259687

Epoch: 5| Step: 9
Training loss: 1.6049989461898804
Validation loss: 2.204006709078307

Epoch: 5| Step: 10
Training loss: 2.328504800796509
Validation loss: 2.21252211447685

Epoch: 83| Step: 0
Training loss: 2.1235358715057373
Validation loss: 2.2353641358754968

Epoch: 5| Step: 1
Training loss: 3.0206639766693115
Validation loss: 2.2604208248917774

Epoch: 5| Step: 2
Training loss: 2.656247138977051
Validation loss: 2.2642582231952297

Epoch: 5| Step: 3
Training loss: 2.748859405517578
Validation loss: 2.2445141397496706

Epoch: 5| Step: 4
Training loss: 1.9665714502334595
Validation loss: 2.2358162223651843

Epoch: 5| Step: 5
Training loss: 2.521211624145508
Validation loss: 2.2200544393190773

Epoch: 5| Step: 6
Training loss: 3.0015883445739746
Validation loss: 2.207288484419546

Epoch: 5| Step: 7
Training loss: 2.184494972229004
Validation loss: 2.1876254812363656

Epoch: 5| Step: 8
Training loss: 2.749809980392456
Validation loss: 2.175317404090717

Epoch: 5| Step: 9
Training loss: 2.628854274749756
Validation loss: 2.1784773642016995

Epoch: 5| Step: 10
Training loss: 1.710504412651062
Validation loss: 2.1708547863908993

Epoch: 84| Step: 0
Training loss: 2.951625347137451
Validation loss: 2.179182078248711

Epoch: 5| Step: 1
Training loss: 2.4741644859313965
Validation loss: 2.182507630317442

Epoch: 5| Step: 2
Training loss: 2.2629590034484863
Validation loss: 2.1810283096887733

Epoch: 5| Step: 3
Training loss: 2.1119298934936523
Validation loss: 2.17457656193805

Epoch: 5| Step: 4
Training loss: 2.2232484817504883
Validation loss: 2.181137187506563

Epoch: 5| Step: 5
Training loss: 3.1396541595458984
Validation loss: 2.1775825100560344

Epoch: 5| Step: 6
Training loss: 2.1473805904388428
Validation loss: 2.1954232979846258

Epoch: 5| Step: 7
Training loss: 2.9222373962402344
Validation loss: 2.203833938926779

Epoch: 5| Step: 8
Training loss: 2.024768352508545
Validation loss: 2.2290320345150527

Epoch: 5| Step: 9
Training loss: 2.2989916801452637
Validation loss: 2.2547351647448797

Epoch: 5| Step: 10
Training loss: 2.666546583175659
Validation loss: 2.2436188831124255

Epoch: 85| Step: 0
Training loss: 2.5500004291534424
Validation loss: 2.2345834855110414

Epoch: 5| Step: 1
Training loss: 2.505469560623169
Validation loss: 2.213372161311488

Epoch: 5| Step: 2
Training loss: 2.4046785831451416
Validation loss: 2.193274518494965

Epoch: 5| Step: 3
Training loss: 2.7179760932922363
Validation loss: 2.1860462439957487

Epoch: 5| Step: 4
Training loss: 2.1519381999969482
Validation loss: 2.184223364758235

Epoch: 5| Step: 5
Training loss: 3.093561887741089
Validation loss: 2.1945599868733394

Epoch: 5| Step: 6
Training loss: 2.2644741535186768
Validation loss: 2.2128369269832486

Epoch: 5| Step: 7
Training loss: 2.8766236305236816
Validation loss: 2.217012425904633

Epoch: 5| Step: 8
Training loss: 2.2627508640289307
Validation loss: 2.2320749041854695

Epoch: 5| Step: 9
Training loss: 2.379133701324463
Validation loss: 2.2305904357664046

Epoch: 5| Step: 10
Training loss: 1.9995707273483276
Validation loss: 2.252741623950261

Epoch: 86| Step: 0
Training loss: 2.811455249786377
Validation loss: 2.2793533904578096

Epoch: 5| Step: 1
Training loss: 2.7796826362609863
Validation loss: 2.2868864382466962

Epoch: 5| Step: 2
Training loss: 2.3796515464782715
Validation loss: 2.294315994426768

Epoch: 5| Step: 3
Training loss: 2.5955824851989746
Validation loss: 2.3009311845225673

Epoch: 5| Step: 4
Training loss: 2.6057329177856445
Validation loss: 2.267511422916125

Epoch: 5| Step: 5
Training loss: 2.405604124069214
Validation loss: 2.2359730107809908

Epoch: 5| Step: 6
Training loss: 2.7869315147399902
Validation loss: 2.2158870184293358

Epoch: 5| Step: 7
Training loss: 2.13908052444458
Validation loss: 2.2149026906618507

Epoch: 5| Step: 8
Training loss: 2.5535051822662354
Validation loss: 2.227306542858001

Epoch: 5| Step: 9
Training loss: 2.265446901321411
Validation loss: 2.233858523830291

Epoch: 5| Step: 10
Training loss: 2.2380800247192383
Validation loss: 2.2468360649642123

Epoch: 87| Step: 0
Training loss: 2.5670478343963623
Validation loss: 2.3046191866679857

Epoch: 5| Step: 1
Training loss: 2.749499797821045
Validation loss: 2.3892592114786946

Epoch: 5| Step: 2
Training loss: 2.463967800140381
Validation loss: 2.3921750053282707

Epoch: 5| Step: 3
Training loss: 2.5293335914611816
Validation loss: 2.2977565873053765

Epoch: 5| Step: 4
Training loss: 2.749220371246338
Validation loss: 2.2359753013938986

Epoch: 5| Step: 5
Training loss: 2.321470260620117
Validation loss: 2.211060098422471

Epoch: 5| Step: 6
Training loss: 2.2116267681121826
Validation loss: 2.219473079968524

Epoch: 5| Step: 7
Training loss: 2.76761794090271
Validation loss: 2.270920388160213

Epoch: 5| Step: 8
Training loss: 2.1264731884002686
Validation loss: 2.3056357419618996

Epoch: 5| Step: 9
Training loss: 2.492476463317871
Validation loss: 2.307259282758159

Epoch: 5| Step: 10
Training loss: 3.149812698364258
Validation loss: 2.2625444576304448

Epoch: 88| Step: 0
Training loss: 2.5376956462860107
Validation loss: 2.2213324193031556

Epoch: 5| Step: 1
Training loss: 2.2259573936462402
Validation loss: 2.205656623327604

Epoch: 5| Step: 2
Training loss: 2.6506426334381104
Validation loss: 2.203019301096598

Epoch: 5| Step: 3
Training loss: 2.3081421852111816
Validation loss: 2.1887690585146666

Epoch: 5| Step: 4
Training loss: 2.3751375675201416
Validation loss: 2.1738331728084113

Epoch: 5| Step: 5
Training loss: 2.023190975189209
Validation loss: 2.177554504845732

Epoch: 5| Step: 6
Training loss: 2.2427761554718018
Validation loss: 2.1783821095702467

Epoch: 5| Step: 7
Training loss: 2.7675511837005615
Validation loss: 2.1826488048799577

Epoch: 5| Step: 8
Training loss: 2.5231544971466064
Validation loss: 2.1725316701396817

Epoch: 5| Step: 9
Training loss: 3.0741639137268066
Validation loss: 2.176713643535491

Epoch: 5| Step: 10
Training loss: 2.418060779571533
Validation loss: 2.1747960159855504

Epoch: 89| Step: 0
Training loss: 2.4017069339752197
Validation loss: 2.1630634902625956

Epoch: 5| Step: 1
Training loss: 3.0127055644989014
Validation loss: 2.1692660213798605

Epoch: 5| Step: 2
Training loss: 3.1792070865631104
Validation loss: 2.178928793117564

Epoch: 5| Step: 3
Training loss: 2.407489538192749
Validation loss: 2.1604000214607484

Epoch: 5| Step: 4
Training loss: 2.028318405151367
Validation loss: 2.15779600861252

Epoch: 5| Step: 5
Training loss: 2.579725503921509
Validation loss: 2.159355407120079

Epoch: 5| Step: 6
Training loss: 2.328828811645508
Validation loss: 2.1628647247950235

Epoch: 5| Step: 7
Training loss: 2.007918357849121
Validation loss: 2.1574007464993383

Epoch: 5| Step: 8
Training loss: 2.3034300804138184
Validation loss: 2.163273475503409

Epoch: 5| Step: 9
Training loss: 2.2596211433410645
Validation loss: 2.1684333791014967

Epoch: 5| Step: 10
Training loss: 2.614993095397949
Validation loss: 2.1680985701981412

Epoch: 90| Step: 0
Training loss: 2.4737582206726074
Validation loss: 2.177230822142734

Epoch: 5| Step: 1
Training loss: 2.6960952281951904
Validation loss: 2.1733739542704757

Epoch: 5| Step: 2
Training loss: 2.009803056716919
Validation loss: 2.182542267666068

Epoch: 5| Step: 3
Training loss: 2.4787533283233643
Validation loss: 2.1728705898407967

Epoch: 5| Step: 4
Training loss: 2.631746530532837
Validation loss: 2.2131128106065976

Epoch: 5| Step: 5
Training loss: 2.8264689445495605
Validation loss: 2.2573164252824682

Epoch: 5| Step: 6
Training loss: 3.169466018676758
Validation loss: 2.2594680222131873

Epoch: 5| Step: 7
Training loss: 1.8227418661117554
Validation loss: 2.259259021410378

Epoch: 5| Step: 8
Training loss: 2.3147075176239014
Validation loss: 2.244208617876935

Epoch: 5| Step: 9
Training loss: 2.436227321624756
Validation loss: 2.212944825490316

Epoch: 5| Step: 10
Training loss: 2.2838382720947266
Validation loss: 2.190150285279879

Epoch: 91| Step: 0
Training loss: 2.291321039199829
Validation loss: 2.1755885821516796

Epoch: 5| Step: 1
Training loss: 2.5504117012023926
Validation loss: 2.1677460811471425

Epoch: 5| Step: 2
Training loss: 2.5332114696502686
Validation loss: 2.1757671935583955

Epoch: 5| Step: 3
Training loss: 2.3764281272888184
Validation loss: 2.1956119883445

Epoch: 5| Step: 4
Training loss: 2.664909839630127
Validation loss: 2.1983438973785727

Epoch: 5| Step: 5
Training loss: 2.808825969696045
Validation loss: 2.2318332400373233

Epoch: 5| Step: 6
Training loss: 2.3535237312316895
Validation loss: 2.2361021144415743

Epoch: 5| Step: 7
Training loss: 2.1080660820007324
Validation loss: 2.2155782227875083

Epoch: 5| Step: 8
Training loss: 2.5825066566467285
Validation loss: 2.2114857332680815

Epoch: 5| Step: 9
Training loss: 2.56316876411438
Validation loss: 2.2441524382560485

Epoch: 5| Step: 10
Training loss: 2.5587873458862305
Validation loss: 2.2291166679833525

Epoch: 92| Step: 0
Training loss: 2.0460212230682373
Validation loss: 2.1945693646707842

Epoch: 5| Step: 1
Training loss: 1.9927446842193604
Validation loss: 2.1635848834950435

Epoch: 5| Step: 2
Training loss: 2.498530387878418
Validation loss: 2.1548770422576577

Epoch: 5| Step: 3
Training loss: 2.439227342605591
Validation loss: 2.1462734655667375

Epoch: 5| Step: 4
Training loss: 2.95383882522583
Validation loss: 2.155295064372401

Epoch: 5| Step: 5
Training loss: 2.704557418823242
Validation loss: 2.1549132459907123

Epoch: 5| Step: 6
Training loss: 2.159701108932495
Validation loss: 2.1482370899569605

Epoch: 5| Step: 7
Training loss: 2.6244778633117676
Validation loss: 2.142780452646235

Epoch: 5| Step: 8
Training loss: 2.2341434955596924
Validation loss: 2.140093177877447

Epoch: 5| Step: 9
Training loss: 2.814204454421997
Validation loss: 2.1385556831154773

Epoch: 5| Step: 10
Training loss: 2.379783868789673
Validation loss: 2.1451199490536927

Epoch: 93| Step: 0
Training loss: 2.367819309234619
Validation loss: 2.134828982814666

Epoch: 5| Step: 1
Training loss: 2.457792282104492
Validation loss: 2.1447576861227713

Epoch: 5| Step: 2
Training loss: 2.47965931892395
Validation loss: 2.159880917559388

Epoch: 5| Step: 3
Training loss: 2.680103063583374
Validation loss: 2.168447233015491

Epoch: 5| Step: 4
Training loss: 1.9316332340240479
Validation loss: 2.176573025282993

Epoch: 5| Step: 5
Training loss: 3.000471353530884
Validation loss: 2.186770475038918

Epoch: 5| Step: 6
Training loss: 2.224879503250122
Validation loss: 2.1810105616046536

Epoch: 5| Step: 7
Training loss: 1.702988862991333
Validation loss: 2.182099393619004

Epoch: 5| Step: 8
Training loss: 2.904972791671753
Validation loss: 2.182208186836653

Epoch: 5| Step: 9
Training loss: 2.693566083908081
Validation loss: 2.186165427648893

Epoch: 5| Step: 10
Training loss: 2.3918814659118652
Validation loss: 2.1666258945259997

Epoch: 94| Step: 0
Training loss: 1.9630237817764282
Validation loss: 2.1698208573043987

Epoch: 5| Step: 1
Training loss: 2.7095940113067627
Validation loss: 2.193572974974109

Epoch: 5| Step: 2
Training loss: 2.7591986656188965
Validation loss: 2.2427310379602576

Epoch: 5| Step: 3
Training loss: 1.8718541860580444
Validation loss: 2.2762118257502073

Epoch: 5| Step: 4
Training loss: 2.276236057281494
Validation loss: 2.2926369277379846

Epoch: 5| Step: 5
Training loss: 3.0781025886535645
Validation loss: 2.2825159795822634

Epoch: 5| Step: 6
Training loss: 2.5644989013671875
Validation loss: 2.2384965932497414

Epoch: 5| Step: 7
Training loss: 2.809962272644043
Validation loss: 2.2024978194185483

Epoch: 5| Step: 8
Training loss: 2.7503662109375
Validation loss: 2.1900833704138316

Epoch: 5| Step: 9
Training loss: 2.044058084487915
Validation loss: 2.140420413786365

Epoch: 5| Step: 10
Training loss: 2.307098627090454
Validation loss: 2.1452661778337214

Epoch: 95| Step: 0
Training loss: 2.0304927825927734
Validation loss: 2.1539056301116943

Epoch: 5| Step: 1
Training loss: 3.3138344287872314
Validation loss: 2.1531727647268646

Epoch: 5| Step: 2
Training loss: 2.3183000087738037
Validation loss: 2.1595268710967033

Epoch: 5| Step: 3
Training loss: 2.835376024246216
Validation loss: 2.167830285205636

Epoch: 5| Step: 4
Training loss: 2.4447474479675293
Validation loss: 2.170081579557029

Epoch: 5| Step: 5
Training loss: 1.9513896703720093
Validation loss: 2.1498596027333248

Epoch: 5| Step: 6
Training loss: 2.4288735389709473
Validation loss: 2.1471778910647155

Epoch: 5| Step: 7
Training loss: 2.359126567840576
Validation loss: 2.1516194074384627

Epoch: 5| Step: 8
Training loss: 2.7151846885681152
Validation loss: 2.173647165298462

Epoch: 5| Step: 9
Training loss: 2.2961950302124023
Validation loss: 2.1892679276004916

Epoch: 5| Step: 10
Training loss: 2.235553026199341
Validation loss: 2.2143806565192437

Epoch: 96| Step: 0
Training loss: 2.566380262374878
Validation loss: 2.219498590756488

Epoch: 5| Step: 1
Training loss: 2.9516074657440186
Validation loss: 2.1863029131325344

Epoch: 5| Step: 2
Training loss: 2.353804349899292
Validation loss: 2.183079746461684

Epoch: 5| Step: 3
Training loss: 2.4491629600524902
Validation loss: 2.161486000143072

Epoch: 5| Step: 4
Training loss: 2.376654863357544
Validation loss: 2.135338653800308

Epoch: 5| Step: 5
Training loss: 2.8608248233795166
Validation loss: 2.1191941948347193

Epoch: 5| Step: 6
Training loss: 2.0029826164245605
Validation loss: 2.122141904728387

Epoch: 5| Step: 7
Training loss: 1.7544023990631104
Validation loss: 2.1185428916767077

Epoch: 5| Step: 8
Training loss: 2.679999589920044
Validation loss: 2.116470524059829

Epoch: 5| Step: 9
Training loss: 2.2641425132751465
Validation loss: 2.114373342965239

Epoch: 5| Step: 10
Training loss: 2.5298004150390625
Validation loss: 2.1117548122200915

Epoch: 97| Step: 0
Training loss: 2.8991382122039795
Validation loss: 2.107244996614354

Epoch: 5| Step: 1
Training loss: 2.663830280303955
Validation loss: 2.1017375082098027

Epoch: 5| Step: 2
Training loss: 1.80976140499115
Validation loss: 2.1151290555154123

Epoch: 5| Step: 3
Training loss: 2.7208034992218018
Validation loss: 2.1040491827072634

Epoch: 5| Step: 4
Training loss: 2.1212897300720215
Validation loss: 2.1226199980705016

Epoch: 5| Step: 5
Training loss: 2.4864180088043213
Validation loss: 2.1353875155090005

Epoch: 5| Step: 6
Training loss: 2.554863929748535
Validation loss: 2.1360965518541235

Epoch: 5| Step: 7
Training loss: 2.2640135288238525
Validation loss: 2.127747731824075

Epoch: 5| Step: 8
Training loss: 1.9173991680145264
Validation loss: 2.107536933755362

Epoch: 5| Step: 9
Training loss: 2.621030569076538
Validation loss: 2.098342505834436

Epoch: 5| Step: 10
Training loss: 2.571770191192627
Validation loss: 2.0891720466716315

Epoch: 98| Step: 0
Training loss: 2.5956780910491943
Validation loss: 2.0830242044182232

Epoch: 5| Step: 1
Training loss: 2.3048489093780518
Validation loss: 2.087345774455737

Epoch: 5| Step: 2
Training loss: 1.8359781503677368
Validation loss: 2.08350730711414

Epoch: 5| Step: 3
Training loss: 2.7455546855926514
Validation loss: 2.080324988211355

Epoch: 5| Step: 4
Training loss: 2.1914169788360596
Validation loss: 2.0842160486405894

Epoch: 5| Step: 5
Training loss: 2.9879517555236816
Validation loss: 2.085041360188556

Epoch: 5| Step: 6
Training loss: 2.0025014877319336
Validation loss: 2.084780554617605

Epoch: 5| Step: 7
Training loss: 2.6617469787597656
Validation loss: 2.1085616901356685

Epoch: 5| Step: 8
Training loss: 2.3430428504943848
Validation loss: 2.128299920789657

Epoch: 5| Step: 9
Training loss: 2.5187828540802
Validation loss: 2.1503742407726985

Epoch: 5| Step: 10
Training loss: 2.341024398803711
Validation loss: 2.161781241816859

Epoch: 99| Step: 0
Training loss: 2.6988589763641357
Validation loss: 2.159211325389083

Epoch: 5| Step: 1
Training loss: 1.7916247844696045
Validation loss: 2.1438387799006637

Epoch: 5| Step: 2
Training loss: 2.561973810195923
Validation loss: 2.1213465941849576

Epoch: 5| Step: 3
Training loss: 2.488541841506958
Validation loss: 2.119621002545921

Epoch: 5| Step: 4
Training loss: 2.0439867973327637
Validation loss: 2.09709967208165

Epoch: 5| Step: 5
Training loss: 2.8145694732666016
Validation loss: 2.092528922583467

Epoch: 5| Step: 6
Training loss: 1.7088701725006104
Validation loss: 2.092702534890944

Epoch: 5| Step: 7
Training loss: 3.086277484893799
Validation loss: 2.0859332212837796

Epoch: 5| Step: 8
Training loss: 2.207876205444336
Validation loss: 2.0961268153241885

Epoch: 5| Step: 9
Training loss: 2.6098735332489014
Validation loss: 2.077041277321436

Epoch: 5| Step: 10
Training loss: 2.482471466064453
Validation loss: 2.0795859111252653

Epoch: 100| Step: 0
Training loss: 2.1008241176605225
Validation loss: 2.083283765341646

Epoch: 5| Step: 1
Training loss: 3.189624071121216
Validation loss: 2.079514807270419

Epoch: 5| Step: 2
Training loss: 2.2711098194122314
Validation loss: 2.074542510894037

Epoch: 5| Step: 3
Training loss: 1.8913414478302002
Validation loss: 2.0752047249065932

Epoch: 5| Step: 4
Training loss: 2.039231061935425
Validation loss: 2.0781404972076416

Epoch: 5| Step: 5
Training loss: 2.5978689193725586
Validation loss: 2.0990781809694026

Epoch: 5| Step: 6
Training loss: 2.5115036964416504
Validation loss: 2.118726867501454

Epoch: 5| Step: 7
Training loss: 2.4097087383270264
Validation loss: 2.1311720122573194

Epoch: 5| Step: 8
Training loss: 2.192563772201538
Validation loss: 2.192621382333899

Epoch: 5| Step: 9
Training loss: 2.1004478931427
Validation loss: 2.23042365043394

Epoch: 5| Step: 10
Training loss: 2.9696617126464844
Validation loss: 2.2515660921732583

Epoch: 101| Step: 0
Training loss: 2.4332449436187744
Validation loss: 2.1734627959548787

Epoch: 5| Step: 1
Training loss: 2.431387424468994
Validation loss: 2.161968841347643

Epoch: 5| Step: 2
Training loss: 2.10994815826416
Validation loss: 2.1445040818183654

Epoch: 5| Step: 3
Training loss: 2.686415672302246
Validation loss: 2.104809832829301

Epoch: 5| Step: 4
Training loss: 1.9845842123031616
Validation loss: 2.0933326751955095

Epoch: 5| Step: 5
Training loss: 2.348550319671631
Validation loss: 2.0891600975426297

Epoch: 5| Step: 6
Training loss: 2.5658810138702393
Validation loss: 2.0845810649215535

Epoch: 5| Step: 7
Training loss: 2.9623830318450928
Validation loss: 2.0791954866019626

Epoch: 5| Step: 8
Training loss: 2.2208948135375977
Validation loss: 2.0884967183554046

Epoch: 5| Step: 9
Training loss: 2.602154493331909
Validation loss: 2.0999592247829644

Epoch: 5| Step: 10
Training loss: 1.831002950668335
Validation loss: 2.105590046093028

Epoch: 102| Step: 0
Training loss: 2.2845866680145264
Validation loss: 2.09753204161121

Epoch: 5| Step: 1
Training loss: 1.9467140436172485
Validation loss: 2.078660108709848

Epoch: 5| Step: 2
Training loss: 2.3334598541259766
Validation loss: 2.0736413553196895

Epoch: 5| Step: 3
Training loss: 2.315668821334839
Validation loss: 2.0732947600785123

Epoch: 5| Step: 4
Training loss: 2.6832706928253174
Validation loss: 2.0899910747364

Epoch: 5| Step: 5
Training loss: 2.2899279594421387
Validation loss: 2.103792075187929

Epoch: 5| Step: 6
Training loss: 2.5227084159851074
Validation loss: 2.129449672596429

Epoch: 5| Step: 7
Training loss: 2.2184040546417236
Validation loss: 2.130607871599095

Epoch: 5| Step: 8
Training loss: 2.4942405223846436
Validation loss: 2.126985578126805

Epoch: 5| Step: 9
Training loss: 2.739436149597168
Validation loss: 2.1561547735685944

Epoch: 5| Step: 10
Training loss: 2.4826903343200684
Validation loss: 2.141747646434333

Epoch: 103| Step: 0
Training loss: 2.4301674365997314
Validation loss: 2.1195066577644757

Epoch: 5| Step: 1
Training loss: 2.377476453781128
Validation loss: 2.0791923179421374

Epoch: 5| Step: 2
Training loss: 2.1507010459899902
Validation loss: 2.062084677398846

Epoch: 5| Step: 3
Training loss: 2.287407636642456
Validation loss: 2.054265773424538

Epoch: 5| Step: 4
Training loss: 2.667536497116089
Validation loss: 2.060678211591577

Epoch: 5| Step: 5
Training loss: 2.1893017292022705
Validation loss: 2.1038144749979817

Epoch: 5| Step: 6
Training loss: 2.422736644744873
Validation loss: 2.0640859808973087

Epoch: 5| Step: 7
Training loss: 2.666999578475952
Validation loss: 2.0672714671780987

Epoch: 5| Step: 8
Training loss: 1.9687535762786865
Validation loss: 2.0677182494953112

Epoch: 5| Step: 9
Training loss: 2.3922805786132812
Validation loss: 2.0643717524825886

Epoch: 5| Step: 10
Training loss: 2.640895366668701
Validation loss: 2.0614774586052023

Epoch: 104| Step: 0
Training loss: 2.2336668968200684
Validation loss: 2.068201227854657

Epoch: 5| Step: 1
Training loss: 2.6261444091796875
Validation loss: 2.092527466435586

Epoch: 5| Step: 2
Training loss: 1.8011701107025146
Validation loss: 2.13172887345796

Epoch: 5| Step: 3
Training loss: 1.6852976083755493
Validation loss: 2.1213619145013953

Epoch: 5| Step: 4
Training loss: 2.3402018547058105
Validation loss: 2.122683293075972

Epoch: 5| Step: 5
Training loss: 2.8623878955841064
Validation loss: 2.154829509796635

Epoch: 5| Step: 6
Training loss: 2.1811423301696777
Validation loss: 2.158856508552387

Epoch: 5| Step: 7
Training loss: 3.2748947143554688
Validation loss: 2.1509073882974605

Epoch: 5| Step: 8
Training loss: 2.2757792472839355
Validation loss: 2.1542320213010235

Epoch: 5| Step: 9
Training loss: 1.986364722251892
Validation loss: 2.1715365417541994

Epoch: 5| Step: 10
Training loss: 2.712287425994873
Validation loss: 2.2051242359222902

Epoch: 105| Step: 0
Training loss: 2.9007315635681152
Validation loss: 2.1660728569953673

Epoch: 5| Step: 1
Training loss: 1.8430789709091187
Validation loss: 2.127515523664413

Epoch: 5| Step: 2
Training loss: 2.7707862854003906
Validation loss: 2.088730578781456

Epoch: 5| Step: 3
Training loss: 2.488856792449951
Validation loss: 2.0572227175517748

Epoch: 5| Step: 4
Training loss: 1.6926352977752686
Validation loss: 2.0498356511515956

Epoch: 5| Step: 5
Training loss: 1.9634101390838623
Validation loss: 2.044248439932382

Epoch: 5| Step: 6
Training loss: 2.6137897968292236
Validation loss: 2.048765581141236

Epoch: 5| Step: 7
Training loss: 2.901625394821167
Validation loss: 2.046406147300556

Epoch: 5| Step: 8
Training loss: 2.058525562286377
Validation loss: 2.0592996407580633

Epoch: 5| Step: 9
Training loss: 2.3720717430114746
Validation loss: 2.059936208109702

Epoch: 5| Step: 10
Training loss: 2.2250239849090576
Validation loss: 2.0874420904344126

Epoch: 106| Step: 0
Training loss: 2.6791863441467285
Validation loss: 2.09952760383647

Epoch: 5| Step: 1
Training loss: 2.2394490242004395
Validation loss: 2.1435794394503356

Epoch: 5| Step: 2
Training loss: 2.809171199798584
Validation loss: 2.1468502731733423

Epoch: 5| Step: 3
Training loss: 2.6662914752960205
Validation loss: 2.1857235406034734

Epoch: 5| Step: 4
Training loss: 2.5971474647521973
Validation loss: 2.194982285140663

Epoch: 5| Step: 5
Training loss: 1.835991621017456
Validation loss: 2.230704456247309

Epoch: 5| Step: 6
Training loss: 1.791935920715332
Validation loss: 2.2241400005996868

Epoch: 5| Step: 7
Training loss: 3.014275550842285
Validation loss: 2.2352649370829263

Epoch: 5| Step: 8
Training loss: 2.233750581741333
Validation loss: 2.2011738208032425

Epoch: 5| Step: 9
Training loss: 2.505751848220825
Validation loss: 2.1551434147742485

Epoch: 5| Step: 10
Training loss: 1.7690722942352295
Validation loss: 2.112914744243827

Epoch: 107| Step: 0
Training loss: 2.2743630409240723
Validation loss: 2.0934974865246843

Epoch: 5| Step: 1
Training loss: 2.007145404815674
Validation loss: 2.0798252654331986

Epoch: 5| Step: 2
Training loss: 2.6443278789520264
Validation loss: 2.080748881063154

Epoch: 5| Step: 3
Training loss: 2.4714200496673584
Validation loss: 2.067398186652891

Epoch: 5| Step: 4
Training loss: 2.4920883178710938
Validation loss: 2.073914697093348

Epoch: 5| Step: 5
Training loss: 2.4080588817596436
Validation loss: 2.0813489613994474

Epoch: 5| Step: 6
Training loss: 2.2096292972564697
Validation loss: 2.103968717718637

Epoch: 5| Step: 7
Training loss: 2.5933358669281006
Validation loss: 2.12434402332511

Epoch: 5| Step: 8
Training loss: 2.1912710666656494
Validation loss: 2.1268313674516577

Epoch: 5| Step: 9
Training loss: 2.4344699382781982
Validation loss: 2.114435326668524

Epoch: 5| Step: 10
Training loss: 2.134418487548828
Validation loss: 2.1039260971930718

Epoch: 108| Step: 0
Training loss: 1.9830251932144165
Validation loss: 2.1037384207530687

Epoch: 5| Step: 1
Training loss: 2.0381195545196533
Validation loss: 2.094874994729155

Epoch: 5| Step: 2
Training loss: 2.1229782104492188
Validation loss: 2.1295620113290767

Epoch: 5| Step: 3
Training loss: 1.8952581882476807
Validation loss: 2.150329221961319

Epoch: 5| Step: 4
Training loss: 2.1638388633728027
Validation loss: 2.1495694550134803

Epoch: 5| Step: 5
Training loss: 2.2932491302490234
Validation loss: 2.1456663890551497

Epoch: 5| Step: 6
Training loss: 2.949669599533081
Validation loss: 2.1108935186939854

Epoch: 5| Step: 7
Training loss: 2.007061243057251
Validation loss: 2.0799952412164338

Epoch: 5| Step: 8
Training loss: 2.7271804809570312
Validation loss: 2.0636076106820056

Epoch: 5| Step: 9
Training loss: 3.1586692333221436
Validation loss: 2.059341405027656

Epoch: 5| Step: 10
Training loss: 2.335186004638672
Validation loss: 2.056612189098071

Epoch: 109| Step: 0
Training loss: 2.6777713298797607
Validation loss: 2.043263505863887

Epoch: 5| Step: 1
Training loss: 2.325287342071533
Validation loss: 2.0411767677594255

Epoch: 5| Step: 2
Training loss: 2.385939836502075
Validation loss: 2.0326732589352514

Epoch: 5| Step: 3
Training loss: 1.8978023529052734
Validation loss: 2.0484690845653577

Epoch: 5| Step: 4
Training loss: 2.2013325691223145
Validation loss: 2.0561760138439875

Epoch: 5| Step: 5
Training loss: 1.8535206317901611
Validation loss: 2.089980294627528

Epoch: 5| Step: 6
Training loss: 2.4743261337280273
Validation loss: 2.1350642865703953

Epoch: 5| Step: 7
Training loss: 2.629199981689453
Validation loss: 2.161313005672988

Epoch: 5| Step: 8
Training loss: 2.8575987815856934
Validation loss: 2.176707540788958

Epoch: 5| Step: 9
Training loss: 2.447537422180176
Validation loss: 2.172088958883798

Epoch: 5| Step: 10
Training loss: 1.744503140449524
Validation loss: 2.11120544966831

Epoch: 110| Step: 0
Training loss: 2.154226303100586
Validation loss: 2.055052429117182

Epoch: 5| Step: 1
Training loss: 2.20788311958313
Validation loss: 2.0303112665812173

Epoch: 5| Step: 2
Training loss: 2.197052478790283
Validation loss: 2.0233111355894353

Epoch: 5| Step: 3
Training loss: 2.1540591716766357
Validation loss: 2.023945623828519

Epoch: 5| Step: 4
Training loss: 2.3970742225646973
Validation loss: 2.0305714978966662

Epoch: 5| Step: 5
Training loss: 2.6298844814300537
Validation loss: 2.0311816071951263

Epoch: 5| Step: 6
Training loss: 2.287396192550659
Validation loss: 2.0141556314242783

Epoch: 5| Step: 7
Training loss: 2.231248617172241
Validation loss: 2.0144531265381844

Epoch: 5| Step: 8
Training loss: 2.2027788162231445
Validation loss: 2.032135348166189

Epoch: 5| Step: 9
Training loss: 2.7383272647857666
Validation loss: 2.0486859224175893

Epoch: 5| Step: 10
Training loss: 2.0249791145324707
Validation loss: 2.06117667177672

Epoch: 111| Step: 0
Training loss: 2.789870023727417
Validation loss: 2.11318898970081

Epoch: 5| Step: 1
Training loss: 2.3950600624084473
Validation loss: 2.131030877431234

Epoch: 5| Step: 2
Training loss: 1.9131004810333252
Validation loss: 2.130416544534827

Epoch: 5| Step: 3
Training loss: 2.1607890129089355
Validation loss: 2.117428118182767

Epoch: 5| Step: 4
Training loss: 2.484908103942871
Validation loss: 2.0891179576996834

Epoch: 5| Step: 5
Training loss: 2.214761257171631
Validation loss: 2.089028740441927

Epoch: 5| Step: 6
Training loss: 1.9342279434204102
Validation loss: 2.093887916175268

Epoch: 5| Step: 7
Training loss: 2.7568564414978027
Validation loss: 2.085135186872175

Epoch: 5| Step: 8
Training loss: 2.4959990978240967
Validation loss: 2.051618247903803

Epoch: 5| Step: 9
Training loss: 2.0711264610290527
Validation loss: 2.0337642110804075

Epoch: 5| Step: 10
Training loss: 1.8830041885375977
Validation loss: 2.04890634423943

Epoch: 112| Step: 0
Training loss: 2.345416784286499
Validation loss: 2.0471899355611494

Epoch: 5| Step: 1
Training loss: 2.684598445892334
Validation loss: 2.0653031000527005

Epoch: 5| Step: 2
Training loss: 2.2800650596618652
Validation loss: 2.0605875112677134

Epoch: 5| Step: 3
Training loss: 2.069258213043213
Validation loss: 2.0821687918837353

Epoch: 5| Step: 4
Training loss: 2.575498580932617
Validation loss: 2.0780451349032822

Epoch: 5| Step: 5
Training loss: 2.039869785308838
Validation loss: 2.1007870602351364

Epoch: 5| Step: 6
Training loss: 2.186702013015747
Validation loss: 2.1092718134644213

Epoch: 5| Step: 7
Training loss: 2.2395195960998535
Validation loss: 2.123590418087539

Epoch: 5| Step: 8
Training loss: 2.1206414699554443
Validation loss: 2.0971755981445312

Epoch: 5| Step: 9
Training loss: 2.1642963886260986
Validation loss: 2.0577739156702513

Epoch: 5| Step: 10
Training loss: 2.369847536087036
Validation loss: 2.019028545707785

Epoch: 113| Step: 0
Training loss: 2.5048320293426514
Validation loss: 2.016014333694212

Epoch: 5| Step: 1
Training loss: 2.4976675510406494
Validation loss: 2.01464291157261

Epoch: 5| Step: 2
Training loss: 2.251171588897705
Validation loss: 2.0069607650080035

Epoch: 5| Step: 3
Training loss: 1.9411613941192627
Validation loss: 2.011600837912611

Epoch: 5| Step: 4
Training loss: 1.8947765827178955
Validation loss: 2.0119201431992235

Epoch: 5| Step: 5
Training loss: 2.161435604095459
Validation loss: 2.01673456673981

Epoch: 5| Step: 6
Training loss: 1.465116262435913
Validation loss: 2.0508738974089264

Epoch: 5| Step: 7
Training loss: 3.0371830463409424
Validation loss: 2.080390143138106

Epoch: 5| Step: 8
Training loss: 2.3098461627960205
Validation loss: 2.129924313996428

Epoch: 5| Step: 9
Training loss: 2.6511600017547607
Validation loss: 2.112949445683469

Epoch: 5| Step: 10
Training loss: 2.3123393058776855
Validation loss: 2.134191534852469

Epoch: 114| Step: 0
Training loss: 2.5643398761749268
Validation loss: 2.1489186030562206

Epoch: 5| Step: 1
Training loss: 2.1541943550109863
Validation loss: 2.127886736264793

Epoch: 5| Step: 2
Training loss: 1.494270920753479
Validation loss: 2.1048340746151504

Epoch: 5| Step: 3
Training loss: 1.6482136249542236
Validation loss: 2.072371618722075

Epoch: 5| Step: 4
Training loss: 2.4631614685058594
Validation loss: 2.0707692689793085

Epoch: 5| Step: 5
Training loss: 2.5345795154571533
Validation loss: 2.06823302853492

Epoch: 5| Step: 6
Training loss: 2.7610549926757812
Validation loss: 2.0732957214437504

Epoch: 5| Step: 7
Training loss: 1.9607082605361938
Validation loss: 2.058754664595409

Epoch: 5| Step: 8
Training loss: 1.9581226110458374
Validation loss: 2.054549019823792

Epoch: 5| Step: 9
Training loss: 2.7879281044006348
Validation loss: 2.0651586542847338

Epoch: 5| Step: 10
Training loss: 2.812272071838379
Validation loss: 2.0823574373798985

Epoch: 115| Step: 0
Training loss: 2.4418275356292725
Validation loss: 2.0754192285640265

Epoch: 5| Step: 1
Training loss: 2.037479877471924
Validation loss: 2.070921354396369

Epoch: 5| Step: 2
Training loss: 1.9485477209091187
Validation loss: 2.0705368518829346

Epoch: 5| Step: 3
Training loss: 2.353513240814209
Validation loss: 2.082203230550212

Epoch: 5| Step: 4
Training loss: 2.3212883472442627
Validation loss: 2.134812972878897

Epoch: 5| Step: 5
Training loss: 1.929857850074768
Validation loss: 2.1413178725909163

Epoch: 5| Step: 6
Training loss: 2.2293732166290283
Validation loss: 2.177858142442601

Epoch: 5| Step: 7
Training loss: 2.7465999126434326
Validation loss: 2.127928344152307

Epoch: 5| Step: 8
Training loss: 2.311309337615967
Validation loss: 2.029260778939852

Epoch: 5| Step: 9
Training loss: 2.1451945304870605
Validation loss: 2.0039993819370063

Epoch: 5| Step: 10
Training loss: 2.1750192642211914
Validation loss: 1.9947395273434219

Epoch: 116| Step: 0
Training loss: 2.1947813034057617
Validation loss: 1.9948788368573753

Epoch: 5| Step: 1
Training loss: 2.8647682666778564
Validation loss: 2.012652120282573

Epoch: 5| Step: 2
Training loss: 2.619986057281494
Validation loss: 2.0314480489300144

Epoch: 5| Step: 3
Training loss: 2.1413753032684326
Validation loss: 2.023159207836274

Epoch: 5| Step: 4
Training loss: 1.5723191499710083
Validation loss: 1.991539773120675

Epoch: 5| Step: 5
Training loss: 2.751297950744629
Validation loss: 2.0083896242162234

Epoch: 5| Step: 6
Training loss: 2.162076950073242
Validation loss: 2.0079921676266577

Epoch: 5| Step: 7
Training loss: 2.1682372093200684
Validation loss: 2.0072359192755913

Epoch: 5| Step: 8
Training loss: 2.449824810028076
Validation loss: 2.031827208816364

Epoch: 5| Step: 9
Training loss: 2.1662063598632812
Validation loss: 2.0456177906323503

Epoch: 5| Step: 10
Training loss: 1.4334306716918945
Validation loss: 2.0772556079331266

Epoch: 117| Step: 0
Training loss: 2.6432511806488037
Validation loss: 2.084413739942735

Epoch: 5| Step: 1
Training loss: 2.3984289169311523
Validation loss: 2.0933708913864626

Epoch: 5| Step: 2
Training loss: 2.369878053665161
Validation loss: 2.0954810214299027

Epoch: 5| Step: 3
Training loss: 1.379764437675476
Validation loss: 2.098551437418948

Epoch: 5| Step: 4
Training loss: 2.814330577850342
Validation loss: 2.0967833726636824

Epoch: 5| Step: 5
Training loss: 2.573185443878174
Validation loss: 2.099211528737058

Epoch: 5| Step: 6
Training loss: 2.0104832649230957
Validation loss: 2.1135654910918205

Epoch: 5| Step: 7
Training loss: 2.4984257221221924
Validation loss: 2.145275592803955

Epoch: 5| Step: 8
Training loss: 1.4507774114608765
Validation loss: 2.116478894346504

Epoch: 5| Step: 9
Training loss: 2.6278529167175293
Validation loss: 2.106206654220499

Epoch: 5| Step: 10
Training loss: 1.3885743618011475
Validation loss: 2.0726132649247364

Epoch: 118| Step: 0
Training loss: 1.7004249095916748
Validation loss: 2.0824245919463453

Epoch: 5| Step: 1
Training loss: 1.8618932962417603
Validation loss: 2.1283743586591495

Epoch: 5| Step: 2
Training loss: 2.0739777088165283
Validation loss: 2.125715740265385

Epoch: 5| Step: 3
Training loss: 2.5190224647521973
Validation loss: 2.06662239310562

Epoch: 5| Step: 4
Training loss: 2.7058615684509277
Validation loss: 2.0477849552708287

Epoch: 5| Step: 5
Training loss: 1.924472451210022
Validation loss: 2.0285979816990514

Epoch: 5| Step: 6
Training loss: 2.2915940284729004
Validation loss: 2.0581443899421283

Epoch: 5| Step: 7
Training loss: 2.5043628215789795
Validation loss: 2.068028969149436

Epoch: 5| Step: 8
Training loss: 2.1794943809509277
Validation loss: 2.0647227148855887

Epoch: 5| Step: 9
Training loss: 2.586627244949341
Validation loss: 2.0674481930271273

Epoch: 5| Step: 10
Training loss: 2.1783053874969482
Validation loss: 2.0631942595205

Epoch: 119| Step: 0
Training loss: 2.4485721588134766
Validation loss: 2.0564287067741476

Epoch: 5| Step: 1
Training loss: 1.8531566858291626
Validation loss: 2.050318473128862

Epoch: 5| Step: 2
Training loss: 2.123692274093628
Validation loss: 2.035655531831967

Epoch: 5| Step: 3
Training loss: 2.414055347442627
Validation loss: 2.038335032360528

Epoch: 5| Step: 4
Training loss: 2.074702739715576
Validation loss: 2.042415645814711

Epoch: 5| Step: 5
Training loss: 2.348661184310913
Validation loss: 2.059182797708819

Epoch: 5| Step: 6
Training loss: 2.327895402908325
Validation loss: 2.069500466828705

Epoch: 5| Step: 7
Training loss: 2.548182964324951
Validation loss: 2.0717937843773955

Epoch: 5| Step: 8
Training loss: 1.5389753580093384
Validation loss: 2.044263611557663

Epoch: 5| Step: 9
Training loss: 2.369140386581421
Validation loss: 2.061187026321247

Epoch: 5| Step: 10
Training loss: 2.0593245029449463
Validation loss: 2.0501481153631724

Epoch: 120| Step: 0
Training loss: 1.7847919464111328
Validation loss: 2.06998416941653

Epoch: 5| Step: 1
Training loss: 1.846785306930542
Validation loss: 2.0972595419935

Epoch: 5| Step: 2
Training loss: 1.747193694114685
Validation loss: 2.1160687759358394

Epoch: 5| Step: 3
Training loss: 3.239598035812378
Validation loss: 2.138198216756185

Epoch: 5| Step: 4
Training loss: 2.188645839691162
Validation loss: 2.1709964275360107

Epoch: 5| Step: 5
Training loss: 2.758849859237671
Validation loss: 2.1798153538857736

Epoch: 5| Step: 6
Training loss: 2.245995044708252
Validation loss: 2.159127469985716

Epoch: 5| Step: 7
Training loss: 1.5940356254577637
Validation loss: 2.1433545838120165

Epoch: 5| Step: 8
Training loss: 2.4903743267059326
Validation loss: 2.0974109531730734

Epoch: 5| Step: 9
Training loss: 2.2917771339416504
Validation loss: 2.0796619320428498

Epoch: 5| Step: 10
Training loss: 1.8544530868530273
Validation loss: 2.0668173118304183

Epoch: 121| Step: 0
Training loss: 1.2376313209533691
Validation loss: 2.043401969376431

Epoch: 5| Step: 1
Training loss: 2.86464786529541
Validation loss: 2.018845368457097

Epoch: 5| Step: 2
Training loss: 1.4969285726547241
Validation loss: 2.0149718100024807

Epoch: 5| Step: 3
Training loss: 2.2575843334198
Validation loss: 2.0292138156070503

Epoch: 5| Step: 4
Training loss: 2.5153911113739014
Validation loss: 2.0766512719533776

Epoch: 5| Step: 5
Training loss: 2.041567087173462
Validation loss: 2.1174170073642524

Epoch: 5| Step: 6
Training loss: 2.0929691791534424
Validation loss: 2.125377739629438

Epoch: 5| Step: 7
Training loss: 2.817082643508911
Validation loss: 2.122767689407513

Epoch: 5| Step: 8
Training loss: 2.129692792892456
Validation loss: 2.1019291288109234

Epoch: 5| Step: 9
Training loss: 2.139200210571289
Validation loss: 2.0841577206888506

Epoch: 5| Step: 10
Training loss: 2.4526865482330322
Validation loss: 2.061569180539859

Epoch: 122| Step: 0
Training loss: 2.261030912399292
Validation loss: 2.0627910347395044

Epoch: 5| Step: 1
Training loss: 2.5371384620666504
Validation loss: 2.0624282590804563

Epoch: 5| Step: 2
Training loss: 1.9709316492080688
Validation loss: 2.035455479416796

Epoch: 5| Step: 3
Training loss: 2.2659194469451904
Validation loss: 2.0325134018416047

Epoch: 5| Step: 4
Training loss: 1.6965147256851196
Validation loss: 2.0279223534368698

Epoch: 5| Step: 5
Training loss: 2.4928793907165527
Validation loss: 2.0405672186164447

Epoch: 5| Step: 6
Training loss: 2.0784003734588623
Validation loss: 2.0894480546315513

Epoch: 5| Step: 7
Training loss: 1.7843526601791382
Validation loss: 2.202008903667491

Epoch: 5| Step: 8
Training loss: 2.4528725147247314
Validation loss: 2.244567778802687

Epoch: 5| Step: 9
Training loss: 2.418144464492798
Validation loss: 2.2438115176334175

Epoch: 5| Step: 10
Training loss: 2.3284687995910645
Validation loss: 2.236085669968718

Epoch: 123| Step: 0
Training loss: 2.227407693862915
Validation loss: 2.1860584674342984

Epoch: 5| Step: 1
Training loss: 2.4939675331115723
Validation loss: 2.147313710181944

Epoch: 5| Step: 2
Training loss: 1.7672462463378906
Validation loss: 2.1091942300078688

Epoch: 5| Step: 3
Training loss: 2.4868531227111816
Validation loss: 2.1028496449993503

Epoch: 5| Step: 4
Training loss: 2.0179619789123535
Validation loss: 2.0903105889597247

Epoch: 5| Step: 5
Training loss: 2.306486129760742
Validation loss: 2.056353617739934

Epoch: 5| Step: 6
Training loss: 2.49763560295105
Validation loss: 2.04119231623988

Epoch: 5| Step: 7
Training loss: 2.9035983085632324
Validation loss: 2.0209175002190376

Epoch: 5| Step: 8
Training loss: 1.3790048360824585
Validation loss: 2.0257312713130826

Epoch: 5| Step: 9
Training loss: 2.0301899909973145
Validation loss: 2.0457800075572026

Epoch: 5| Step: 10
Training loss: 1.6369218826293945
Validation loss: 2.0658265313794537

Epoch: 124| Step: 0
Training loss: 2.3745319843292236
Validation loss: 2.0900674635364163

Epoch: 5| Step: 1
Training loss: 1.7228724956512451
Validation loss: 2.10188453812753

Epoch: 5| Step: 2
Training loss: 2.205930471420288
Validation loss: 2.111957614139844

Epoch: 5| Step: 3
Training loss: 2.239117383956909
Validation loss: 2.1101649576617825

Epoch: 5| Step: 4
Training loss: 2.099626064300537
Validation loss: 2.100030264546794

Epoch: 5| Step: 5
Training loss: 1.7844264507293701
Validation loss: 2.0680970555992535

Epoch: 5| Step: 6
Training loss: 1.9361549615859985
Validation loss: 2.0549494861274638

Epoch: 5| Step: 7
Training loss: 2.1044068336486816
Validation loss: 2.0392378171284995

Epoch: 5| Step: 8
Training loss: 2.224332332611084
Validation loss: 2.041556344237379

Epoch: 5| Step: 9
Training loss: 2.6452789306640625
Validation loss: 2.0462180081234185

Epoch: 5| Step: 10
Training loss: 1.9564599990844727
Validation loss: 2.0597041191593295

Epoch: 125| Step: 0
Training loss: 1.926979660987854
Validation loss: 2.109658125908144

Epoch: 5| Step: 1
Training loss: 2.5938405990600586
Validation loss: 2.1334342495087655

Epoch: 5| Step: 2
Training loss: 2.667440891265869
Validation loss: 2.1850527307038665

Epoch: 5| Step: 3
Training loss: 2.1430211067199707
Validation loss: 2.2247663300524474

Epoch: 5| Step: 4
Training loss: 2.262378692626953
Validation loss: 2.2203973339449976

Epoch: 5| Step: 5
Training loss: 2.17305326461792
Validation loss: 2.2118951056593206

Epoch: 5| Step: 6
Training loss: 2.025893211364746
Validation loss: 2.198667344226632

Epoch: 5| Step: 7
Training loss: 1.4156824350357056
Validation loss: 2.1241482585989018

Epoch: 5| Step: 8
Training loss: 2.4660756587982178
Validation loss: 2.0629837615515596

Epoch: 5| Step: 9
Training loss: 2.1376793384552
Validation loss: 2.0166190375563917

Epoch: 5| Step: 10
Training loss: 1.8101245164871216
Validation loss: 1.9977935796142907

Epoch: 126| Step: 0
Training loss: 2.58746600151062
Validation loss: 2.006018450183253

Epoch: 5| Step: 1
Training loss: 1.7301700115203857
Validation loss: 2.016038361416068

Epoch: 5| Step: 2
Training loss: 2.8310937881469727
Validation loss: 2.021605791584138

Epoch: 5| Step: 3
Training loss: 2.389754295349121
Validation loss: 2.0339778905273764

Epoch: 5| Step: 4
Training loss: 1.9716224670410156
Validation loss: 2.043808726854222

Epoch: 5| Step: 5
Training loss: 2.0292165279388428
Validation loss: 2.063889954679756

Epoch: 5| Step: 6
Training loss: 1.6696536540985107
Validation loss: 2.0960022467438892

Epoch: 5| Step: 7
Training loss: 2.0671679973602295
Validation loss: 2.141128291365921

Epoch: 5| Step: 8
Training loss: 2.275686740875244
Validation loss: 2.1630241204333562

Epoch: 5| Step: 9
Training loss: 1.186941385269165
Validation loss: 2.1645992391852924

Epoch: 5| Step: 10
Training loss: 2.4927892684936523
Validation loss: 2.123401123990295

Epoch: 127| Step: 0
Training loss: 2.2989113330841064
Validation loss: 2.0942883337697675

Epoch: 5| Step: 1
Training loss: 1.9612385034561157
Validation loss: 2.0560999365263086

Epoch: 5| Step: 2
Training loss: 1.7501016855239868
Validation loss: 2.0285833420292025

Epoch: 5| Step: 3
Training loss: 1.8322471380233765
Validation loss: 2.0143783515499485

Epoch: 5| Step: 4
Training loss: 2.103928804397583
Validation loss: 2.0145089062311317

Epoch: 5| Step: 5
Training loss: 2.5432846546173096
Validation loss: 2.002339880953553

Epoch: 5| Step: 6
Training loss: 2.251464366912842
Validation loss: 2.0014648334954375

Epoch: 5| Step: 7
Training loss: 2.487652063369751
Validation loss: 2.0511466610816216

Epoch: 5| Step: 8
Training loss: 2.2248871326446533
Validation loss: 2.0862352309688443

Epoch: 5| Step: 9
Training loss: 1.236211895942688
Validation loss: 2.114507685425461

Epoch: 5| Step: 10
Training loss: 2.3976166248321533
Validation loss: 2.144112648502473

Epoch: 128| Step: 0
Training loss: 2.213606357574463
Validation loss: 2.1615455381331907

Epoch: 5| Step: 1
Training loss: 2.2918026447296143
Validation loss: 2.1831782581985637

Epoch: 5| Step: 2
Training loss: 2.652801036834717
Validation loss: 2.1283218783717

Epoch: 5| Step: 3
Training loss: 2.6525585651397705
Validation loss: 2.0936304420553227

Epoch: 5| Step: 4
Training loss: 1.7826248407363892
Validation loss: 2.058174988274933

Epoch: 5| Step: 5
Training loss: 1.7055689096450806
Validation loss: 2.0245432725516697

Epoch: 5| Step: 6
Training loss: 2.0031540393829346
Validation loss: 2.018316844458221

Epoch: 5| Step: 7
Training loss: 2.2383816242218018
Validation loss: 1.99167162628584

Epoch: 5| Step: 8
Training loss: 2.1913774013519287
Validation loss: 2.005616044485441

Epoch: 5| Step: 9
Training loss: 1.8426735401153564
Validation loss: 2.0237660561838458

Epoch: 5| Step: 10
Training loss: 1.463425636291504
Validation loss: 2.046706889265327

Epoch: 129| Step: 0
Training loss: 1.7979682683944702
Validation loss: 2.0780613448030207

Epoch: 5| Step: 1
Training loss: 1.8316367864608765
Validation loss: 2.101421803556463

Epoch: 5| Step: 2
Training loss: 2.313950300216675
Validation loss: 2.1046649922606764

Epoch: 5| Step: 3
Training loss: 1.9215538501739502
Validation loss: 2.103527097291844

Epoch: 5| Step: 4
Training loss: 1.930164098739624
Validation loss: 2.0782869400516635

Epoch: 5| Step: 5
Training loss: 1.9610389471054077
Validation loss: 2.042543880401119

Epoch: 5| Step: 6
Training loss: 1.9600671529769897
Validation loss: 2.028867070392896

Epoch: 5| Step: 7
Training loss: 2.4955239295959473
Validation loss: 2.033212128505912

Epoch: 5| Step: 8
Training loss: 1.9427993297576904
Validation loss: 2.0262665876778225

Epoch: 5| Step: 9
Training loss: 2.7109508514404297
Validation loss: 2.0314291728440153

Epoch: 5| Step: 10
Training loss: 1.7782049179077148
Validation loss: 2.016259644621162

Epoch: 130| Step: 0
Training loss: 2.3987174034118652
Validation loss: 2.0099773176254763

Epoch: 5| Step: 1
Training loss: 2.0797553062438965
Validation loss: 2.004385150888915

Epoch: 5| Step: 2
Training loss: 2.4273383617401123
Validation loss: 2.0147445983784174

Epoch: 5| Step: 3
Training loss: 2.606466770172119
Validation loss: 2.0155026297415457

Epoch: 5| Step: 4
Training loss: 2.1038386821746826
Validation loss: 2.041202101656186

Epoch: 5| Step: 5
Training loss: 2.0787250995635986
Validation loss: 2.060466886848532

Epoch: 5| Step: 6
Training loss: 2.147995710372925
Validation loss: 2.0818709481147026

Epoch: 5| Step: 7
Training loss: 1.852155327796936
Validation loss: 2.075829006010486

Epoch: 5| Step: 8
Training loss: 1.7999744415283203
Validation loss: 2.0779777034636466

Epoch: 5| Step: 9
Training loss: 1.207525610923767
Validation loss: 2.060326330123409

Epoch: 5| Step: 10
Training loss: 1.8259835243225098
Validation loss: 2.040879205990863

Epoch: 131| Step: 0
Training loss: 2.147617816925049
Validation loss: 2.0175217915606756

Epoch: 5| Step: 1
Training loss: 1.4630175828933716
Validation loss: 1.994459948232097

Epoch: 5| Step: 2
Training loss: 1.5287539958953857
Validation loss: 1.970470202866421

Epoch: 5| Step: 3
Training loss: 1.6380599737167358
Validation loss: 1.973223417035995

Epoch: 5| Step: 4
Training loss: 1.739797592163086
Validation loss: 1.9739422170064782

Epoch: 5| Step: 5
Training loss: 3.066534996032715
Validation loss: 1.9872402196289392

Epoch: 5| Step: 6
Training loss: 2.0390090942382812
Validation loss: 1.9928568358062415

Epoch: 5| Step: 7
Training loss: 2.672126054763794
Validation loss: 2.0015439525727303

Epoch: 5| Step: 8
Training loss: 2.1068625450134277
Validation loss: 2.011037039500411

Epoch: 5| Step: 9
Training loss: 2.3162405490875244
Validation loss: 2.0570253659320135

Epoch: 5| Step: 10
Training loss: 2.083170175552368
Validation loss: 2.1060096410013016

Epoch: 132| Step: 0
Training loss: 2.207448720932007
Validation loss: 2.148640554438355

Epoch: 5| Step: 1
Training loss: 2.0195553302764893
Validation loss: 2.1576891163344025

Epoch: 5| Step: 2
Training loss: 1.3846333026885986
Validation loss: 2.112645036430769

Epoch: 5| Step: 3
Training loss: 2.9167087078094482
Validation loss: 2.0833943838714273

Epoch: 5| Step: 4
Training loss: 1.4929686784744263
Validation loss: 2.028922830858538

Epoch: 5| Step: 5
Training loss: 1.9656856060028076
Validation loss: 1.9963607506085468

Epoch: 5| Step: 6
Training loss: 1.7048108577728271
Validation loss: 1.9958205658902404

Epoch: 5| Step: 7
Training loss: 1.9650039672851562
Validation loss: 1.982668589520198

Epoch: 5| Step: 8
Training loss: 2.1301541328430176
Validation loss: 1.9847574490372852

Epoch: 5| Step: 9
Training loss: 2.3964669704437256
Validation loss: 1.9980382406583397

Epoch: 5| Step: 10
Training loss: 2.475074052810669
Validation loss: 2.0205650944863596

Epoch: 133| Step: 0
Training loss: 1.9887946844100952
Validation loss: 2.051849719016783

Epoch: 5| Step: 1
Training loss: 1.594301462173462
Validation loss: 2.0773989872265886

Epoch: 5| Step: 2
Training loss: 2.1474456787109375
Validation loss: 2.078312479039674

Epoch: 5| Step: 3
Training loss: 1.7989866733551025
Validation loss: 2.0783830278663227

Epoch: 5| Step: 4
Training loss: 2.3440470695495605
Validation loss: 2.0919338810828423

Epoch: 5| Step: 5
Training loss: 2.419177293777466
Validation loss: 2.0655315447879095

Epoch: 5| Step: 6
Training loss: 2.186537265777588
Validation loss: 2.0518225803170154

Epoch: 5| Step: 7
Training loss: 2.100870132446289
Validation loss: 2.0323215825583345

Epoch: 5| Step: 8
Training loss: 1.922518014907837
Validation loss: 2.0227419304591354

Epoch: 5| Step: 9
Training loss: 2.0368716716766357
Validation loss: 2.010568739265524

Epoch: 5| Step: 10
Training loss: 1.5585753917694092
Validation loss: 1.9982815904002036

Epoch: 134| Step: 0
Training loss: 2.5155506134033203
Validation loss: 1.9956795105370142

Epoch: 5| Step: 1
Training loss: 1.6672284603118896
Validation loss: 1.984114795602778

Epoch: 5| Step: 2
Training loss: 2.365103006362915
Validation loss: 2.0049923632734563

Epoch: 5| Step: 3
Training loss: 2.3199079036712646
Validation loss: 2.030887035913365

Epoch: 5| Step: 4
Training loss: 2.297640800476074
Validation loss: 2.069660776404924

Epoch: 5| Step: 5
Training loss: 1.7643190622329712
Validation loss: 2.08727999015521

Epoch: 5| Step: 6
Training loss: 1.3400490283966064
Validation loss: 2.104323830655826

Epoch: 5| Step: 7
Training loss: 1.8514597415924072
Validation loss: 2.0914229577587498

Epoch: 5| Step: 8
Training loss: 2.3036656379699707
Validation loss: 2.065223850229735

Epoch: 5| Step: 9
Training loss: 1.782196283340454
Validation loss: 2.0374122934956707

Epoch: 5| Step: 10
Training loss: 1.5988397598266602
Validation loss: 2.0304902817613337

Epoch: 135| Step: 0
Training loss: 2.493223190307617
Validation loss: 2.0141097448205434

Epoch: 5| Step: 1
Training loss: 2.31127667427063
Validation loss: 2.0152713303924887

Epoch: 5| Step: 2
Training loss: 1.950406789779663
Validation loss: 2.0058584290166057

Epoch: 5| Step: 3
Training loss: 1.978006362915039
Validation loss: 2.001339994451051

Epoch: 5| Step: 4
Training loss: 1.9019867181777954
Validation loss: 2.0057300624027046

Epoch: 5| Step: 5
Training loss: 2.057224750518799
Validation loss: 2.0293373497583533

Epoch: 5| Step: 6
Training loss: 1.8337135314941406
Validation loss: 2.041042567581259

Epoch: 5| Step: 7
Training loss: 2.315192699432373
Validation loss: 2.080748373462308

Epoch: 5| Step: 8
Training loss: 1.6038318872451782
Validation loss: 2.1150020924947595

Epoch: 5| Step: 9
Training loss: 1.7076565027236938
Validation loss: 2.091399226137387

Epoch: 5| Step: 10
Training loss: 2.018423557281494
Validation loss: 2.099221278262395

Epoch: 136| Step: 0
Training loss: 1.5442136526107788
Validation loss: 2.0635122099230365

Epoch: 5| Step: 1
Training loss: 2.361870527267456
Validation loss: 2.0183576371080134

Epoch: 5| Step: 2
Training loss: 1.7704417705535889
Validation loss: 2.020200034623505

Epoch: 5| Step: 3
Training loss: 2.0120065212249756
Validation loss: 2.0031620097416702

Epoch: 5| Step: 4
Training loss: 2.1323297023773193
Validation loss: 2.0142665319545294

Epoch: 5| Step: 5
Training loss: 1.832803726196289
Validation loss: 2.000985162232512

Epoch: 5| Step: 6
Training loss: 1.8392736911773682
Validation loss: 2.0025388425396335

Epoch: 5| Step: 7
Training loss: 2.6007704734802246
Validation loss: 2.006614710695

Epoch: 5| Step: 8
Training loss: 1.8390127420425415
Validation loss: 2.016721160181107

Epoch: 5| Step: 9
Training loss: 1.6513097286224365
Validation loss: 2.009931041348365

Epoch: 5| Step: 10
Training loss: 2.1389904022216797
Validation loss: 2.0256016472334504

Epoch: 137| Step: 0
Training loss: 2.4870612621307373
Validation loss: 2.0939114606508644

Epoch: 5| Step: 1
Training loss: 1.626490592956543
Validation loss: 2.1424055381487777

Epoch: 5| Step: 2
Training loss: 2.3562207221984863
Validation loss: 2.1715377530744

Epoch: 5| Step: 3
Training loss: 1.4560664892196655
Validation loss: 2.196748407938147

Epoch: 5| Step: 4
Training loss: 2.150603771209717
Validation loss: 2.2085536654277513

Epoch: 5| Step: 5
Training loss: 2.0814411640167236
Validation loss: 2.2001902185460573

Epoch: 5| Step: 6
Training loss: 1.955651044845581
Validation loss: 2.2252582914085797

Epoch: 5| Step: 7
Training loss: 2.0278711318969727
Validation loss: 2.192784106859597

Epoch: 5| Step: 8
Training loss: 1.8509193658828735
Validation loss: 2.1646638531838693

Epoch: 5| Step: 9
Training loss: 2.170785427093506
Validation loss: 2.139479298745432

Epoch: 5| Step: 10
Training loss: 2.1864945888519287
Validation loss: 2.0778473397736907

Epoch: 138| Step: 0
Training loss: 1.8716531991958618
Validation loss: 1.9856265142399778

Epoch: 5| Step: 1
Training loss: 2.240692615509033
Validation loss: 1.9674568970998128

Epoch: 5| Step: 2
Training loss: 2.390932559967041
Validation loss: 1.9567751833187637

Epoch: 5| Step: 3
Training loss: 2.307373523712158
Validation loss: 1.9771015669709893

Epoch: 5| Step: 4
Training loss: 2.1563467979431152
Validation loss: 1.9914280265890143

Epoch: 5| Step: 5
Training loss: 2.116656541824341
Validation loss: 2.0139901432939755

Epoch: 5| Step: 6
Training loss: 1.7099984884262085
Validation loss: 1.9925000795754053

Epoch: 5| Step: 7
Training loss: 1.662161111831665
Validation loss: 2.001148117485867

Epoch: 5| Step: 8
Training loss: 2.4536337852478027
Validation loss: 2.0150231174243394

Epoch: 5| Step: 9
Training loss: 1.7044299840927124
Validation loss: 2.047459865129122

Epoch: 5| Step: 10
Training loss: 1.3224576711654663
Validation loss: 2.0777483396632697

Epoch: 139| Step: 0
Training loss: 1.7752443552017212
Validation loss: 2.113203448633994

Epoch: 5| Step: 1
Training loss: 2.052459239959717
Validation loss: 2.131952679285439

Epoch: 5| Step: 2
Training loss: 1.7304039001464844
Validation loss: 2.1361033070471978

Epoch: 5| Step: 3
Training loss: 2.324894905090332
Validation loss: 2.123152086811681

Epoch: 5| Step: 4
Training loss: 1.9962761402130127
Validation loss: 2.135068021794801

Epoch: 5| Step: 5
Training loss: 2.0360236167907715
Validation loss: 2.1411434501729985

Epoch: 5| Step: 6
Training loss: 1.510388970375061
Validation loss: 2.129852279540031

Epoch: 5| Step: 7
Training loss: 2.1571192741394043
Validation loss: 2.111977351609097

Epoch: 5| Step: 8
Training loss: 1.8784420490264893
Validation loss: 2.084712351522138

Epoch: 5| Step: 9
Training loss: 1.8372275829315186
Validation loss: 2.043126094725824

Epoch: 5| Step: 10
Training loss: 2.3943428993225098
Validation loss: 2.004011514366314

Epoch: 140| Step: 0
Training loss: 1.3507388830184937
Validation loss: 1.9857750220965313

Epoch: 5| Step: 1
Training loss: 1.9170243740081787
Validation loss: 1.9567900114161993

Epoch: 5| Step: 2
Training loss: 1.3961271047592163
Validation loss: 1.9652915667462092

Epoch: 5| Step: 3
Training loss: 2.2975521087646484
Validation loss: 1.9560219369908816

Epoch: 5| Step: 4
Training loss: 2.2588672637939453
Validation loss: 1.9736779223206222

Epoch: 5| Step: 5
Training loss: 1.535005807876587
Validation loss: 1.9859159710586711

Epoch: 5| Step: 6
Training loss: 2.2887418270111084
Validation loss: 1.975152938596664

Epoch: 5| Step: 7
Training loss: 1.944250464439392
Validation loss: 1.9831171933040823

Epoch: 5| Step: 8
Training loss: 1.82157301902771
Validation loss: 1.9700235794949275

Epoch: 5| Step: 9
Training loss: 2.4024856090545654
Validation loss: 2.000381318471765

Epoch: 5| Step: 10
Training loss: 2.3871045112609863
Validation loss: 2.014472761461812

Epoch: 141| Step: 0
Training loss: 1.8130851984024048
Validation loss: 2.0733477761668544

Epoch: 5| Step: 1
Training loss: 1.8718847036361694
Validation loss: 2.1087144010810444

Epoch: 5| Step: 2
Training loss: 2.3223633766174316
Validation loss: 2.107067382463845

Epoch: 5| Step: 3
Training loss: 2.0592103004455566
Validation loss: 2.081279594411132

Epoch: 5| Step: 4
Training loss: 2.204094648361206
Validation loss: 2.0758145932228333

Epoch: 5| Step: 5
Training loss: 1.4610579013824463
Validation loss: 2.060572744697653

Epoch: 5| Step: 6
Training loss: 1.8273251056671143
Validation loss: 2.0590447661697224

Epoch: 5| Step: 7
Training loss: 2.379561185836792
Validation loss: 2.100229905497643

Epoch: 5| Step: 8
Training loss: 1.709642767906189
Validation loss: 2.094524621963501

Epoch: 5| Step: 9
Training loss: 1.8662302494049072
Validation loss: 2.0719020187213855

Epoch: 5| Step: 10
Training loss: 1.741847038269043
Validation loss: 2.064587696906059

Epoch: 142| Step: 0
Training loss: 2.185946464538574
Validation loss: 2.063802052569646

Epoch: 5| Step: 1
Training loss: 1.7854855060577393
Validation loss: 2.0148988180263068

Epoch: 5| Step: 2
Training loss: 2.141148090362549
Validation loss: 2.0015619647118355

Epoch: 5| Step: 3
Training loss: 1.6551830768585205
Validation loss: 1.9940624134514922

Epoch: 5| Step: 4
Training loss: 2.1475930213928223
Validation loss: 1.9850333480424778

Epoch: 5| Step: 5
Training loss: 2.0043258666992188
Validation loss: 1.9908993987626926

Epoch: 5| Step: 6
Training loss: 2.4637765884399414
Validation loss: 1.9743261337280273

Epoch: 5| Step: 7
Training loss: 1.9694408178329468
Validation loss: 1.9766397860742384

Epoch: 5| Step: 8
Training loss: 1.4814850091934204
Validation loss: 1.97515038136513

Epoch: 5| Step: 9
Training loss: 1.6293327808380127
Validation loss: 2.0040158943463395

Epoch: 5| Step: 10
Training loss: 1.6953860521316528
Validation loss: 2.030636633596113

Epoch: 143| Step: 0
Training loss: 2.282305955886841
Validation loss: 2.0796895911616664

Epoch: 5| Step: 1
Training loss: 1.9146225452423096
Validation loss: 2.127820637918288

Epoch: 5| Step: 2
Training loss: 1.9883800745010376
Validation loss: 2.167485042284894

Epoch: 5| Step: 3
Training loss: 2.059197425842285
Validation loss: 2.1211434025918283

Epoch: 5| Step: 4
Training loss: 1.6553266048431396
Validation loss: 2.09222315460123

Epoch: 5| Step: 5
Training loss: 2.378786563873291
Validation loss: 2.081617364319422

Epoch: 5| Step: 6
Training loss: 1.603463888168335
Validation loss: 2.066787535144437

Epoch: 5| Step: 7
Training loss: 1.9419339895248413
Validation loss: 2.0574504380585044

Epoch: 5| Step: 8
Training loss: 1.6598148345947266
Validation loss: 2.033449213991883

Epoch: 5| Step: 9
Training loss: 1.9386764764785767
Validation loss: 2.046801765759786

Epoch: 5| Step: 10
Training loss: 1.522918939590454
Validation loss: 2.044528668926608

Epoch: 144| Step: 0
Training loss: 2.2526803016662598
Validation loss: 2.0426233853063276

Epoch: 5| Step: 1
Training loss: 2.230038642883301
Validation loss: 2.0330886622910858

Epoch: 5| Step: 2
Training loss: 1.800727128982544
Validation loss: 2.0008488265416955

Epoch: 5| Step: 3
Training loss: 2.23589825630188
Validation loss: 1.9770112576023224

Epoch: 5| Step: 4
Training loss: 2.047469139099121
Validation loss: 2.003728582013038

Epoch: 5| Step: 5
Training loss: 1.6526362895965576
Validation loss: 2.0560996122257684

Epoch: 5| Step: 6
Training loss: 2.646341323852539
Validation loss: 2.063645937109506

Epoch: 5| Step: 7
Training loss: 2.1724982261657715
Validation loss: 2.0882752339045205

Epoch: 5| Step: 8
Training loss: 1.6554704904556274
Validation loss: 2.0742695767392396

Epoch: 5| Step: 9
Training loss: 1.344455361366272
Validation loss: 2.0936579729921077

Epoch: 5| Step: 10
Training loss: 1.0304263830184937
Validation loss: 2.1012533198120775

Epoch: 145| Step: 0
Training loss: 2.312215805053711
Validation loss: 2.0878048917298675

Epoch: 5| Step: 1
Training loss: 1.7452760934829712
Validation loss: 2.068685221415694

Epoch: 5| Step: 2
Training loss: 2.008255958557129
Validation loss: 2.068820227858841

Epoch: 5| Step: 3
Training loss: 2.0440003871917725
Validation loss: 2.08291603801071

Epoch: 5| Step: 4
Training loss: 1.0204108953475952
Validation loss: 2.1114160219828286

Epoch: 5| Step: 5
Training loss: 2.1222071647644043
Validation loss: 2.152370055516561

Epoch: 5| Step: 6
Training loss: 2.47127366065979
Validation loss: 2.1506911516189575

Epoch: 5| Step: 7
Training loss: 1.4389374256134033
Validation loss: 2.145061774920392

Epoch: 5| Step: 8
Training loss: 1.6255842447280884
Validation loss: 2.120554344628447

Epoch: 5| Step: 9
Training loss: 2.271155834197998
Validation loss: 2.0706000097336306

Epoch: 5| Step: 10
Training loss: 1.509697437286377
Validation loss: 2.038458852357762

Epoch: 146| Step: 0
Training loss: 1.748758316040039
Validation loss: 2.044807000826764

Epoch: 5| Step: 1
Training loss: 1.572288990020752
Validation loss: 2.036973138009348

Epoch: 5| Step: 2
Training loss: 1.7803500890731812
Validation loss: 2.0315394529732327

Epoch: 5| Step: 3
Training loss: 2.113379716873169
Validation loss: 2.025496780231435

Epoch: 5| Step: 4
Training loss: 2.0873215198516846
Validation loss: 2.0057542657339447

Epoch: 5| Step: 5
Training loss: 2.0271005630493164
Validation loss: 1.9895658569951211

Epoch: 5| Step: 6
Training loss: 1.8121709823608398
Validation loss: 1.997782503404925

Epoch: 5| Step: 7
Training loss: 2.0511465072631836
Validation loss: 2.0132357471732685

Epoch: 5| Step: 8
Training loss: 1.9305540323257446
Validation loss: 2.017636420906231

Epoch: 5| Step: 9
Training loss: 1.2750657796859741
Validation loss: 2.0303126458198792

Epoch: 5| Step: 10
Training loss: 1.9991142749786377
Validation loss: 2.04506427754638

Epoch: 147| Step: 0
Training loss: 1.6280313730239868
Validation loss: 2.0343663256655455

Epoch: 5| Step: 1
Training loss: 2.369755506515503
Validation loss: 2.0452104127535256

Epoch: 5| Step: 2
Training loss: 1.6933839321136475
Validation loss: 2.0720391247862127

Epoch: 5| Step: 3
Training loss: 1.6063467264175415
Validation loss: 2.0477891468232676

Epoch: 5| Step: 4
Training loss: 1.7051126956939697
Validation loss: 2.0467728927571285

Epoch: 5| Step: 5
Training loss: 1.9849058389663696
Validation loss: 2.0372116681068175

Epoch: 5| Step: 6
Training loss: 1.5781904458999634
Validation loss: 2.033483233503116

Epoch: 5| Step: 7
Training loss: 2.3243508338928223
Validation loss: 2.0284544319234867

Epoch: 5| Step: 8
Training loss: 1.4168778657913208
Validation loss: 2.05061750770897

Epoch: 5| Step: 9
Training loss: 1.4591045379638672
Validation loss: 2.0603413517757128

Epoch: 5| Step: 10
Training loss: 2.2993812561035156
Validation loss: 2.056219195806852

Epoch: 148| Step: 0
Training loss: 2.263288974761963
Validation loss: 2.08036522839659

Epoch: 5| Step: 1
Training loss: 1.6919037103652954
Validation loss: 2.0625498781922045

Epoch: 5| Step: 2
Training loss: 1.7317039966583252
Validation loss: 2.0470629994587233

Epoch: 5| Step: 3
Training loss: 1.755805253982544
Validation loss: 2.0438198633091424

Epoch: 5| Step: 4
Training loss: 1.7199640274047852
Validation loss: 2.0649625537216023

Epoch: 5| Step: 5
Training loss: 1.5507664680480957
Validation loss: 2.05519865405175

Epoch: 5| Step: 6
Training loss: 1.5522328615188599
Validation loss: 2.0665905475616455

Epoch: 5| Step: 7
Training loss: 1.41634202003479
Validation loss: 2.048113638354886

Epoch: 5| Step: 8
Training loss: 1.7610794305801392
Validation loss: 2.048297579570483

Epoch: 5| Step: 9
Training loss: 2.0875587463378906
Validation loss: 2.009100857601371

Epoch: 5| Step: 10
Training loss: 2.180351734161377
Validation loss: 2.012916111177014

Epoch: 149| Step: 0
Training loss: 1.8132579326629639
Validation loss: 2.014342390080934

Epoch: 5| Step: 1
Training loss: 2.0335628986358643
Validation loss: 2.0544761714114936

Epoch: 5| Step: 2
Training loss: 1.4780133962631226
Validation loss: 2.0823606650034585

Epoch: 5| Step: 3
Training loss: 1.1917811632156372
Validation loss: 2.12896216300226

Epoch: 5| Step: 4
Training loss: 1.2146694660186768
Validation loss: 2.140961811106692

Epoch: 5| Step: 5
Training loss: 1.9757026433944702
Validation loss: 2.141929175264092

Epoch: 5| Step: 6
Training loss: 2.0999693870544434
Validation loss: 2.140864949072561

Epoch: 5| Step: 7
Training loss: 2.064293622970581
Validation loss: 2.1070871583877073

Epoch: 5| Step: 8
Training loss: 1.5931589603424072
Validation loss: 2.085679474697318

Epoch: 5| Step: 9
Training loss: 1.9820797443389893
Validation loss: 2.0848697449571345

Epoch: 5| Step: 10
Training loss: 2.1900076866149902
Validation loss: 2.041690477760889

Epoch: 150| Step: 0
Training loss: 1.9249513149261475
Validation loss: 2.0210382425656883

Epoch: 5| Step: 1
Training loss: 2.060425281524658
Validation loss: 1.977061640831732

Epoch: 5| Step: 2
Training loss: 2.060337781906128
Validation loss: 1.9672898502760037

Epoch: 5| Step: 3
Training loss: 1.5158735513687134
Validation loss: 1.973768288089383

Epoch: 5| Step: 4
Training loss: 1.6394164562225342
Validation loss: 1.9684635567408737

Epoch: 5| Step: 5
Training loss: 2.0750861167907715
Validation loss: 1.983888304361733

Epoch: 5| Step: 6
Training loss: 1.5988929271697998
Validation loss: 1.9900324447180635

Epoch: 5| Step: 7
Training loss: 1.800366759300232
Validation loss: 2.035977284113566

Epoch: 5| Step: 8
Training loss: 1.173834204673767
Validation loss: 2.049305518468221

Epoch: 5| Step: 9
Training loss: 1.5070464611053467
Validation loss: 2.0636696584763063

Epoch: 5| Step: 10
Training loss: 1.8939117193222046
Validation loss: 2.080413446631483

Epoch: 151| Step: 0
Training loss: 1.750126600265503
Validation loss: 2.097823626251631

Epoch: 5| Step: 1
Training loss: 1.5075503587722778
Validation loss: 2.0813050859717914

Epoch: 5| Step: 2
Training loss: 1.6863429546356201
Validation loss: 2.1227799666825162

Epoch: 5| Step: 3
Training loss: 2.007253885269165
Validation loss: 2.106332322602631

Epoch: 5| Step: 4
Training loss: 2.0459914207458496
Validation loss: 2.0918257903027278

Epoch: 5| Step: 5
Training loss: 1.8551156520843506
Validation loss: 2.0735908400627876

Epoch: 5| Step: 6
Training loss: 1.9036645889282227
Validation loss: 2.0340650940454132

Epoch: 5| Step: 7
Training loss: 1.404032826423645
Validation loss: 2.022066352187946

Epoch: 5| Step: 8
Training loss: 1.6304633617401123
Validation loss: 2.02400125739395

Epoch: 5| Step: 9
Training loss: 1.1602520942687988
Validation loss: 2.0030213555982037

Epoch: 5| Step: 10
Training loss: 1.8035963773727417
Validation loss: 1.9984382775522047

Epoch: 152| Step: 0
Training loss: 1.5284286737442017
Validation loss: 2.0085416122149398

Epoch: 5| Step: 1
Training loss: 1.8997455835342407
Validation loss: 1.9656101760043894

Epoch: 5| Step: 2
Training loss: 2.1805217266082764
Validation loss: 1.9584227608096214

Epoch: 5| Step: 3
Training loss: 1.4854751825332642
Validation loss: 1.9853044761124479

Epoch: 5| Step: 4
Training loss: 2.112016201019287
Validation loss: 2.009607638082197

Epoch: 5| Step: 5
Training loss: 1.1439756155014038
Validation loss: 2.0412548254894953

Epoch: 5| Step: 6
Training loss: 1.441573143005371
Validation loss: 2.0499075984442108

Epoch: 5| Step: 7
Training loss: 2.1734719276428223
Validation loss: 2.0768600727922175

Epoch: 5| Step: 8
Training loss: 1.5677525997161865
Validation loss: 2.105694063248173

Epoch: 5| Step: 9
Training loss: 1.5055210590362549
Validation loss: 2.1935800429313415

Epoch: 5| Step: 10
Training loss: 1.7554806470870972
Validation loss: 2.2458509783590994

Epoch: 153| Step: 0
Training loss: 1.898543357849121
Validation loss: 2.250720654764483

Epoch: 5| Step: 1
Training loss: 1.7219082117080688
Validation loss: 2.17015847083061

Epoch: 5| Step: 2
Training loss: 1.6825850009918213
Validation loss: 2.087705228918342

Epoch: 5| Step: 3
Training loss: 1.499602198600769
Validation loss: 2.0798716724559827

Epoch: 5| Step: 4
Training loss: 2.1423850059509277
Validation loss: 2.0924424740575973

Epoch: 5| Step: 5
Training loss: 1.6965291500091553
Validation loss: 2.1014587392089186

Epoch: 5| Step: 6
Training loss: 1.3071644306182861
Validation loss: 2.077315870151725

Epoch: 5| Step: 7
Training loss: 1.5616018772125244
Validation loss: 2.049135119684281

Epoch: 5| Step: 8
Training loss: 1.3543938398361206
Validation loss: 2.0469003441513225

Epoch: 5| Step: 9
Training loss: 1.946422815322876
Validation loss: 2.08669376373291

Epoch: 5| Step: 10
Training loss: 2.4268343448638916
Validation loss: 2.1691419232276177

Epoch: 154| Step: 0
Training loss: 1.5716041326522827
Validation loss: 2.191320562875399

Epoch: 5| Step: 1
Training loss: 2.133788824081421
Validation loss: 2.216157869626117

Epoch: 5| Step: 2
Training loss: 1.4635686874389648
Validation loss: 2.229657934558007

Epoch: 5| Step: 3
Training loss: 2.1076064109802246
Validation loss: 2.204746743684174

Epoch: 5| Step: 4
Training loss: 1.3568761348724365
Validation loss: 2.1428982891062254

Epoch: 5| Step: 5
Training loss: 1.3785216808319092
Validation loss: 2.1067784729824273

Epoch: 5| Step: 6
Training loss: 2.070094347000122
Validation loss: 2.0962987869016585

Epoch: 5| Step: 7
Training loss: 1.9103893041610718
Validation loss: 2.106393457740866

Epoch: 5| Step: 8
Training loss: 1.5880622863769531
Validation loss: 2.1025920439791936

Epoch: 5| Step: 9
Training loss: 1.6079216003417969
Validation loss: 2.0584678085901404

Epoch: 5| Step: 10
Training loss: 1.5749725103378296
Validation loss: 2.016085236303268

Epoch: 155| Step: 0
Training loss: 1.6796588897705078
Validation loss: 1.9933701356252034

Epoch: 5| Step: 1
Training loss: 2.085102081298828
Validation loss: 2.01244524217421

Epoch: 5| Step: 2
Training loss: 1.421518325805664
Validation loss: 2.0325708312373005

Epoch: 5| Step: 3
Training loss: 1.3137621879577637
Validation loss: 2.088847111630183

Epoch: 5| Step: 4
Training loss: 1.4672667980194092
Validation loss: 2.1565597006069717

Epoch: 5| Step: 5
Training loss: 1.9511702060699463
Validation loss: 2.1972710932454755

Epoch: 5| Step: 6
Training loss: 1.3042590618133545
Validation loss: 2.240058091378981

Epoch: 5| Step: 7
Training loss: 2.764808416366577
Validation loss: 2.2836748335951116

Epoch: 5| Step: 8
Training loss: 1.548827886581421
Validation loss: 2.2477447243146997

Epoch: 5| Step: 9
Training loss: 1.3567225933074951
Validation loss: 2.2053323766236663

Epoch: 5| Step: 10
Training loss: 1.7518854141235352
Validation loss: 2.1639985499843473

Epoch: 156| Step: 0
Training loss: 2.0327582359313965
Validation loss: 2.117469190269388

Epoch: 5| Step: 1
Training loss: 1.7860071659088135
Validation loss: 2.079131744241202

Epoch: 5| Step: 2
Training loss: 1.5755505561828613
Validation loss: 2.0392706701832433

Epoch: 5| Step: 3
Training loss: 1.6667118072509766
Validation loss: 2.0225879812753327

Epoch: 5| Step: 4
Training loss: 1.4859778881072998
Validation loss: 1.9965384583319388

Epoch: 5| Step: 5
Training loss: 1.529536485671997
Validation loss: 2.0023251579653834

Epoch: 5| Step: 6
Training loss: 1.4408725500106812
Validation loss: 2.023017450045514

Epoch: 5| Step: 7
Training loss: 1.5537166595458984
Validation loss: 2.05300816669259

Epoch: 5| Step: 8
Training loss: 1.9683834314346313
Validation loss: 2.102549442680933

Epoch: 5| Step: 9
Training loss: 1.4567760229110718
Validation loss: 2.1337219579245454

Epoch: 5| Step: 10
Training loss: 1.1887261867523193
Validation loss: 2.162364790516515

Epoch: 157| Step: 0
Training loss: 1.942753791809082
Validation loss: 2.2095385213052072

Epoch: 5| Step: 1
Training loss: 1.5515613555908203
Validation loss: 2.2521609490917576

Epoch: 5| Step: 2
Training loss: 1.6747767925262451
Validation loss: 2.260782523821759

Epoch: 5| Step: 3
Training loss: 1.134425401687622
Validation loss: 2.260470264701433

Epoch: 5| Step: 4
Training loss: 1.560948371887207
Validation loss: 2.2382165744740474

Epoch: 5| Step: 5
Training loss: 1.873620629310608
Validation loss: 2.1918405371327556

Epoch: 5| Step: 6
Training loss: 1.9326708316802979
Validation loss: 2.099013441352434

Epoch: 5| Step: 7
Training loss: 1.1006736755371094
Validation loss: 2.0455365719333773

Epoch: 5| Step: 8
Training loss: 1.1517939567565918
Validation loss: 1.9816827453592771

Epoch: 5| Step: 9
Training loss: 2.0681772232055664
Validation loss: 1.9702369128504107

Epoch: 5| Step: 10
Training loss: 1.8556342124938965
Validation loss: 1.9496918750065628

Epoch: 158| Step: 0
Training loss: 1.9086382389068604
Validation loss: 1.9404800027929328

Epoch: 5| Step: 1
Training loss: 1.3010411262512207
Validation loss: 1.9488795124074465

Epoch: 5| Step: 2
Training loss: 1.4213263988494873
Validation loss: 1.9697768457474247

Epoch: 5| Step: 3
Training loss: 1.8937041759490967
Validation loss: 1.9933908498415382

Epoch: 5| Step: 4
Training loss: 1.514235258102417
Validation loss: 2.046089779946112

Epoch: 5| Step: 5
Training loss: 1.4511557817459106
Validation loss: 2.109084076778863

Epoch: 5| Step: 6
Training loss: 1.1407111883163452
Validation loss: 2.2173269307741554

Epoch: 5| Step: 7
Training loss: 2.0217278003692627
Validation loss: 2.25676731909475

Epoch: 5| Step: 8
Training loss: 1.8322429656982422
Validation loss: 2.266228304114393

Epoch: 5| Step: 9
Training loss: 2.0828707218170166
Validation loss: 2.2050368196220806

Epoch: 5| Step: 10
Training loss: 1.2513515949249268
Validation loss: 2.1102426077729914

Epoch: 159| Step: 0
Training loss: 1.2756459712982178
Validation loss: 2.069012306069815

Epoch: 5| Step: 1
Training loss: 1.3683547973632812
Validation loss: 2.0137949643596524

Epoch: 5| Step: 2
Training loss: 1.609209656715393
Validation loss: 2.0070979454184092

Epoch: 5| Step: 3
Training loss: 1.929168701171875
Validation loss: 1.9849104496740526

Epoch: 5| Step: 4
Training loss: 1.9727041721343994
Validation loss: 1.9892433651031987

Epoch: 5| Step: 5
Training loss: 1.709238052368164
Validation loss: 2.032896782762261

Epoch: 5| Step: 6
Training loss: 1.7235435247421265
Validation loss: 2.0406225932541715

Epoch: 5| Step: 7
Training loss: 1.0186622142791748
Validation loss: 2.086127109425042

Epoch: 5| Step: 8
Training loss: 2.0710954666137695
Validation loss: 2.0786200800249652

Epoch: 5| Step: 9
Training loss: 1.6132442951202393
Validation loss: 2.0841478070905133

Epoch: 5| Step: 10
Training loss: 1.2302353382110596
Validation loss: 2.1117715938116914

Epoch: 160| Step: 0
Training loss: 1.2023181915283203
Validation loss: 2.1349710392695602

Epoch: 5| Step: 1
Training loss: 1.5422649383544922
Validation loss: 2.1373467419737127

Epoch: 5| Step: 2
Training loss: 1.7687435150146484
Validation loss: 2.130978504816691

Epoch: 5| Step: 3
Training loss: 1.9621431827545166
Validation loss: 2.1381666839763684

Epoch: 5| Step: 4
Training loss: 1.7203155755996704
Validation loss: 2.130643658740546

Epoch: 5| Step: 5
Training loss: 1.1034646034240723
Validation loss: 2.098644397592032

Epoch: 5| Step: 6
Training loss: 1.455431580543518
Validation loss: 2.0805975737110263

Epoch: 5| Step: 7
Training loss: 1.4186584949493408
Validation loss: 2.089037569620276

Epoch: 5| Step: 8
Training loss: 1.5028645992279053
Validation loss: 2.098147984473936

Epoch: 5| Step: 9
Training loss: 1.517478585243225
Validation loss: 2.092832806289837

Epoch: 5| Step: 10
Training loss: 1.8378653526306152
Validation loss: 2.117128141464726

Epoch: 161| Step: 0
Training loss: 1.4652130603790283
Validation loss: 2.1188729706630913

Epoch: 5| Step: 1
Training loss: 1.7164499759674072
Validation loss: 2.105333089828491

Epoch: 5| Step: 2
Training loss: 1.8475010395050049
Validation loss: 2.116395406825568

Epoch: 5| Step: 3
Training loss: 1.35708749294281
Validation loss: 2.0868153995083225

Epoch: 5| Step: 4
Training loss: 1.2083052396774292
Validation loss: 2.0639248496742657

Epoch: 5| Step: 5
Training loss: 0.6704322099685669
Validation loss: 2.0751525535378406

Epoch: 5| Step: 6
Training loss: 1.8981784582138062
Validation loss: 2.035245341639365

Epoch: 5| Step: 7
Training loss: 1.5118377208709717
Validation loss: 2.0249569031500045

Epoch: 5| Step: 8
Training loss: 1.8037359714508057
Validation loss: 1.973357601832318

Epoch: 5| Step: 9
Training loss: 1.5206204652786255
Validation loss: 1.9455066445053264

Epoch: 5| Step: 10
Training loss: 1.6363422870635986
Validation loss: 1.9421026822059386

Epoch: 162| Step: 0
Training loss: 1.5260835886001587
Validation loss: 1.9751255871147237

Epoch: 5| Step: 1
Training loss: 1.4777517318725586
Validation loss: 2.0020510714541198

Epoch: 5| Step: 2
Training loss: 1.4194931983947754
Validation loss: 2.0654168410967757

Epoch: 5| Step: 3
Training loss: 1.345391869544983
Validation loss: 2.135790494180495

Epoch: 5| Step: 4
Training loss: 1.1826306581497192
Validation loss: 2.2097683209244923

Epoch: 5| Step: 5
Training loss: 1.760312795639038
Validation loss: 2.1861316209198325

Epoch: 5| Step: 6
Training loss: 2.276151657104492
Validation loss: 2.1367673258627615

Epoch: 5| Step: 7
Training loss: 1.629756212234497
Validation loss: 2.0636757701955815

Epoch: 5| Step: 8
Training loss: 1.5109165906906128
Validation loss: 2.0239111851620417

Epoch: 5| Step: 9
Training loss: 1.1879183053970337
Validation loss: 1.9877433802491875

Epoch: 5| Step: 10
Training loss: 1.597947359085083
Validation loss: 1.9737653693845194

Epoch: 163| Step: 0
Training loss: 1.397840142250061
Validation loss: 1.941872888995755

Epoch: 5| Step: 1
Training loss: 1.4069044589996338
Validation loss: 1.9883073914435603

Epoch: 5| Step: 2
Training loss: 1.1474058628082275
Validation loss: 2.0090652486329437

Epoch: 5| Step: 3
Training loss: 1.7180233001708984
Validation loss: 2.033349255079864

Epoch: 5| Step: 4
Training loss: 1.8066003322601318
Validation loss: 2.063139514256549

Epoch: 5| Step: 5
Training loss: 1.0417323112487793
Validation loss: 2.120237465827696

Epoch: 5| Step: 6
Training loss: 1.327106237411499
Validation loss: 2.141515560047601

Epoch: 5| Step: 7
Training loss: 2.0432422161102295
Validation loss: 2.138784541878649

Epoch: 5| Step: 8
Training loss: 1.7136484384536743
Validation loss: 2.184303747710361

Epoch: 5| Step: 9
Training loss: 1.5006787776947021
Validation loss: 2.172340213611562

Epoch: 5| Step: 10
Training loss: 1.4399818181991577
Validation loss: 2.178840862807407

Epoch: 164| Step: 0
Training loss: 1.1837971210479736
Validation loss: 2.102970902637769

Epoch: 5| Step: 1
Training loss: 2.0747597217559814
Validation loss: 2.077075383996451

Epoch: 5| Step: 2
Training loss: 1.8700196743011475
Validation loss: 2.0687912817924254

Epoch: 5| Step: 3
Training loss: 1.5313196182250977
Validation loss: 2.040425703089724

Epoch: 5| Step: 4
Training loss: 1.3194819688796997
Validation loss: 2.0257954033472205

Epoch: 5| Step: 5
Training loss: 1.540621042251587
Validation loss: 2.0143986261019142

Epoch: 5| Step: 6
Training loss: 1.1956188678741455
Validation loss: 2.014287966553883

Epoch: 5| Step: 7
Training loss: 1.0268352031707764
Validation loss: 2.0175896203646095

Epoch: 5| Step: 8
Training loss: 1.1978521347045898
Validation loss: 2.0737665930101947

Epoch: 5| Step: 9
Training loss: 1.991750955581665
Validation loss: 2.0808723306143158

Epoch: 5| Step: 10
Training loss: 1.3967536687850952
Validation loss: 2.0844583254988476

Epoch: 165| Step: 0
Training loss: 1.5338575839996338
Validation loss: 2.0741215034197737

Epoch: 5| Step: 1
Training loss: 1.1341406106948853
Validation loss: 2.080408670568979

Epoch: 5| Step: 2
Training loss: 1.6813167333602905
Validation loss: 2.095054921283517

Epoch: 5| Step: 3
Training loss: 1.0835652351379395
Validation loss: 2.099185105293028

Epoch: 5| Step: 4
Training loss: 1.6870825290679932
Validation loss: 2.0804675779035016

Epoch: 5| Step: 5
Training loss: 1.0376437902450562
Validation loss: 2.094270337012506

Epoch: 5| Step: 6
Training loss: 1.1417580842971802
Validation loss: 2.0626873982849943

Epoch: 5| Step: 7
Training loss: 1.5304791927337646
Validation loss: 2.0489609164576374

Epoch: 5| Step: 8
Training loss: 1.7120081186294556
Validation loss: 2.0229651594674714

Epoch: 5| Step: 9
Training loss: 1.7872165441513062
Validation loss: 2.0241584418922343

Epoch: 5| Step: 10
Training loss: 1.395532250404358
Validation loss: 1.9912221406095771

Epoch: 166| Step: 0
Training loss: 1.6096909046173096
Validation loss: 2.0105371500856135

Epoch: 5| Step: 1
Training loss: 1.575656533241272
Validation loss: 2.0623243265254523

Epoch: 5| Step: 2
Training loss: 1.16935133934021
Validation loss: 2.090176938682474

Epoch: 5| Step: 3
Training loss: 1.4471428394317627
Validation loss: 2.161929533045779

Epoch: 5| Step: 4
Training loss: 1.3426249027252197
Validation loss: 2.23666020875336

Epoch: 5| Step: 5
Training loss: 1.3402223587036133
Validation loss: 2.2234236053241196

Epoch: 5| Step: 6
Training loss: 1.188562035560608
Validation loss: 2.1676790919355167

Epoch: 5| Step: 7
Training loss: 1.8493239879608154
Validation loss: 2.129084207678354

Epoch: 5| Step: 8
Training loss: 1.5040584802627563
Validation loss: 2.117292005528686

Epoch: 5| Step: 9
Training loss: 0.9313582181930542
Validation loss: 2.043877896442208

Epoch: 5| Step: 10
Training loss: 1.6962116956710815
Validation loss: 1.9919717158040693

Epoch: 167| Step: 0
Training loss: 1.6817386150360107
Validation loss: 1.9678001775536487

Epoch: 5| Step: 1
Training loss: 1.9009311199188232
Validation loss: 1.963739396423422

Epoch: 5| Step: 2
Training loss: 1.086463212966919
Validation loss: 1.9480443962158696

Epoch: 5| Step: 3
Training loss: 1.4367897510528564
Validation loss: 1.9302853256143548

Epoch: 5| Step: 4
Training loss: 1.422123908996582
Validation loss: 1.9730638842428885

Epoch: 5| Step: 5
Training loss: 1.4580644369125366
Validation loss: 1.9898577082541682

Epoch: 5| Step: 6
Training loss: 1.3438925743103027
Validation loss: 2.0323556905151694

Epoch: 5| Step: 7
Training loss: 1.3793230056762695
Validation loss: 2.0988241370006273

Epoch: 5| Step: 8
Training loss: 1.256406545639038
Validation loss: 2.1110636752138854

Epoch: 5| Step: 9
Training loss: 1.1672275066375732
Validation loss: 2.1268880264733427

Epoch: 5| Step: 10
Training loss: 1.5021449327468872
Validation loss: 2.1593898791138844

Epoch: 168| Step: 0
Training loss: 1.0498552322387695
Validation loss: 2.1617906990871636

Epoch: 5| Step: 1
Training loss: 1.4836326837539673
Validation loss: 2.1622307454386065

Epoch: 5| Step: 2
Training loss: 1.3186535835266113
Validation loss: 2.165078399001911

Epoch: 5| Step: 3
Training loss: 0.8698158264160156
Validation loss: 2.152778139678381

Epoch: 5| Step: 4
Training loss: 1.1729707717895508
Validation loss: 2.0854993866335962

Epoch: 5| Step: 5
Training loss: 1.2522801160812378
Validation loss: 2.0757071869347685

Epoch: 5| Step: 6
Training loss: 1.4707813262939453
Validation loss: 1.9997580141149542

Epoch: 5| Step: 7
Training loss: 1.5409234762191772
Validation loss: 1.9710263923932148

Epoch: 5| Step: 8
Training loss: 1.5407040119171143
Validation loss: 1.9840755180646015

Epoch: 5| Step: 9
Training loss: 1.7599502801895142
Validation loss: 1.9639424841891053

Epoch: 5| Step: 10
Training loss: 1.9431065320968628
Validation loss: 1.9776475634626163

Epoch: 169| Step: 0
Training loss: 0.9333004951477051
Validation loss: 1.9952429622732184

Epoch: 5| Step: 1
Training loss: 1.510413646697998
Validation loss: 2.003139043367037

Epoch: 5| Step: 2
Training loss: 1.499141812324524
Validation loss: 2.019135998141381

Epoch: 5| Step: 3
Training loss: 0.9980437159538269
Validation loss: 2.0617107729757986

Epoch: 5| Step: 4
Training loss: 1.4235813617706299
Validation loss: 2.0417609689056233

Epoch: 5| Step: 5
Training loss: 1.7477613687515259
Validation loss: 2.0524946540914555

Epoch: 5| Step: 6
Training loss: 1.3721625804901123
Validation loss: 2.0366548427971463

Epoch: 5| Step: 7
Training loss: 1.4223883152008057
Validation loss: 2.041217311736076

Epoch: 5| Step: 8
Training loss: 1.1663830280303955
Validation loss: 2.042561084993424

Epoch: 5| Step: 9
Training loss: 1.1227669715881348
Validation loss: 2.059399281778643

Epoch: 5| Step: 10
Training loss: 1.8736571073532104
Validation loss: 2.076809319116736

Epoch: 170| Step: 0
Training loss: 1.656805396080017
Validation loss: 2.0636515771189043

Epoch: 5| Step: 1
Training loss: 1.594761610031128
Validation loss: 2.048702491227017

Epoch: 5| Step: 2
Training loss: 1.5342968702316284
Validation loss: 2.0669178244888142

Epoch: 5| Step: 3
Training loss: 1.4183733463287354
Validation loss: 2.0497327414892053

Epoch: 5| Step: 4
Training loss: 1.886587381362915
Validation loss: 2.046542718846311

Epoch: 5| Step: 5
Training loss: 1.5919299125671387
Validation loss: 2.0635963024631625

Epoch: 5| Step: 6
Training loss: 1.3912261724472046
Validation loss: 2.0533259632766887

Epoch: 5| Step: 7
Training loss: 0.5971626043319702
Validation loss: 2.079568213032138

Epoch: 5| Step: 8
Training loss: 0.9874851107597351
Validation loss: 2.085455773979105

Epoch: 5| Step: 9
Training loss: 1.1629077196121216
Validation loss: 2.0884302982719998

Epoch: 5| Step: 10
Training loss: 1.291608452796936
Validation loss: 2.0858773787816367

Epoch: 171| Step: 0
Training loss: 1.5643885135650635
Validation loss: 2.131981361296869

Epoch: 5| Step: 1
Training loss: 0.944566547870636
Validation loss: 2.1006590166399555

Epoch: 5| Step: 2
Training loss: 1.1930408477783203
Validation loss: 2.06737272713774

Epoch: 5| Step: 3
Training loss: 1.1404154300689697
Validation loss: 2.074953809861214

Epoch: 5| Step: 4
Training loss: 2.0090460777282715
Validation loss: 2.0173030860962404

Epoch: 5| Step: 5
Training loss: 0.8505299687385559
Validation loss: 2.014897149096253

Epoch: 5| Step: 6
Training loss: 1.4542502164840698
Validation loss: 2.0045374272972025

Epoch: 5| Step: 7
Training loss: 1.3307442665100098
Validation loss: 2.020581086476644

Epoch: 5| Step: 8
Training loss: 1.4265238046646118
Validation loss: 2.0554050668593375

Epoch: 5| Step: 9
Training loss: 1.0840742588043213
Validation loss: 2.065739377852409

Epoch: 5| Step: 10
Training loss: 1.914996862411499
Validation loss: 2.069152080884544

Epoch: 172| Step: 0
Training loss: 1.2638927698135376
Validation loss: 2.068354668155793

Epoch: 5| Step: 1
Training loss: 0.9663909077644348
Validation loss: 2.0553138204800185

Epoch: 5| Step: 2
Training loss: 1.4445463418960571
Validation loss: 2.062350719205795

Epoch: 5| Step: 3
Training loss: 1.5243831872940063
Validation loss: 2.0378623700911

Epoch: 5| Step: 4
Training loss: 1.4280039072036743
Validation loss: 2.057241680801556

Epoch: 5| Step: 5
Training loss: 0.9389537572860718
Validation loss: 2.0176114561737224

Epoch: 5| Step: 6
Training loss: 1.0920336246490479
Validation loss: 2.032131459123345

Epoch: 5| Step: 7
Training loss: 1.6720914840698242
Validation loss: 2.0618755766140517

Epoch: 5| Step: 8
Training loss: 1.9288451671600342
Validation loss: 2.1065911785248788

Epoch: 5| Step: 9
Training loss: 1.1662737131118774
Validation loss: 2.1263993734954507

Epoch: 5| Step: 10
Training loss: 1.0230613946914673
Validation loss: 2.1059024936409405

Epoch: 173| Step: 0
Training loss: 1.271789789199829
Validation loss: 2.1098410262856433

Epoch: 5| Step: 1
Training loss: 1.3824474811553955
Validation loss: 2.0916016614565285

Epoch: 5| Step: 2
Training loss: 1.4468193054199219
Validation loss: 2.0744579991986676

Epoch: 5| Step: 3
Training loss: 1.3199632167816162
Validation loss: 2.0757344409983647

Epoch: 5| Step: 4
Training loss: 1.443079948425293
Validation loss: 2.062689886298231

Epoch: 5| Step: 5
Training loss: 1.5566219091415405
Validation loss: 2.061047424552261

Epoch: 5| Step: 6
Training loss: 1.1015689373016357
Validation loss: 2.0540915727615356

Epoch: 5| Step: 7
Training loss: 1.4013193845748901
Validation loss: 2.0593434879856725

Epoch: 5| Step: 8
Training loss: 1.655978798866272
Validation loss: 2.0476876048631567

Epoch: 5| Step: 9
Training loss: 0.8483540415763855
Validation loss: 2.016933330925562

Epoch: 5| Step: 10
Training loss: 0.9224876165390015
Validation loss: 2.0162933103499876

Epoch: 174| Step: 0
Training loss: 1.5307190418243408
Validation loss: 1.996265854886783

Epoch: 5| Step: 1
Training loss: 1.2461585998535156
Validation loss: 2.0366513036912486

Epoch: 5| Step: 2
Training loss: 1.2423204183578491
Validation loss: 2.033170957719126

Epoch: 5| Step: 3
Training loss: 0.8922010660171509
Validation loss: 2.095780159837456

Epoch: 5| Step: 4
Training loss: 1.4680044651031494
Validation loss: 2.132956181803057

Epoch: 5| Step: 5
Training loss: 0.9910104870796204
Validation loss: 2.150529174394505

Epoch: 5| Step: 6
Training loss: 0.559773325920105
Validation loss: 2.103252803125689

Epoch: 5| Step: 7
Training loss: 1.3252203464508057
Validation loss: 2.0678943280250794

Epoch: 5| Step: 8
Training loss: 1.545659065246582
Validation loss: 2.042990247408549

Epoch: 5| Step: 9
Training loss: 1.5625
Validation loss: 2.0850389785664056

Epoch: 5| Step: 10
Training loss: 1.8660085201263428
Validation loss: 2.0863101431118545

Epoch: 175| Step: 0
Training loss: 0.9703941345214844
Validation loss: 2.0444231828053794

Epoch: 5| Step: 1
Training loss: 1.3912038803100586
Validation loss: 2.030497033108947

Epoch: 5| Step: 2
Training loss: 0.939163327217102
Validation loss: 2.029919607664949

Epoch: 5| Step: 3
Training loss: 1.0817478895187378
Validation loss: 2.062736144629858

Epoch: 5| Step: 4
Training loss: 1.3485697507858276
Validation loss: 2.022717384881871

Epoch: 5| Step: 5
Training loss: 1.8701709508895874
Validation loss: 2.058293814300209

Epoch: 5| Step: 6
Training loss: 0.6897786259651184
Validation loss: 2.021799055478906

Epoch: 5| Step: 7
Training loss: 1.5951989889144897
Validation loss: 1.997322746502456

Epoch: 5| Step: 8
Training loss: 1.4970959424972534
Validation loss: 1.9716954461989864

Epoch: 5| Step: 9
Training loss: 1.276935338973999
Validation loss: 1.9720345581731489

Epoch: 5| Step: 10
Training loss: 1.290189266204834
Validation loss: 1.9854316634516562

Epoch: 176| Step: 0
Training loss: 1.1889612674713135
Validation loss: 1.9750499033158826

Epoch: 5| Step: 1
Training loss: 1.4199939966201782
Validation loss: 2.039419307503649

Epoch: 5| Step: 2
Training loss: 1.1321802139282227
Validation loss: 2.044337252134918

Epoch: 5| Step: 3
Training loss: 1.795342206954956
Validation loss: 2.0725847956954793

Epoch: 5| Step: 4
Training loss: 0.8191676139831543
Validation loss: 2.0860223590686755

Epoch: 5| Step: 5
Training loss: 0.8378011584281921
Validation loss: 2.105284139674197

Epoch: 5| Step: 6
Training loss: 1.7288602590560913
Validation loss: 2.1156807971257034

Epoch: 5| Step: 7
Training loss: 1.1548978090286255
Validation loss: 2.1167674526091544

Epoch: 5| Step: 8
Training loss: 1.065152883529663
Validation loss: 2.056321444049958

Epoch: 5| Step: 9
Training loss: 1.2640186548233032
Validation loss: 2.0354763307879047

Epoch: 5| Step: 10
Training loss: 1.218380093574524
Validation loss: 2.003935181966392

Epoch: 177| Step: 0
Training loss: 1.5650278329849243
Validation loss: 2.02008282625547

Epoch: 5| Step: 1
Training loss: 1.3784077167510986
Validation loss: 2.0402922937946935

Epoch: 5| Step: 2
Training loss: 1.1687339544296265
Validation loss: 2.061600713319676

Epoch: 5| Step: 3
Training loss: 1.1720393896102905
Validation loss: 2.0812353011100524

Epoch: 5| Step: 4
Training loss: 1.036982774734497
Validation loss: 2.0902471875631683

Epoch: 5| Step: 5
Training loss: 1.6081565618515015
Validation loss: 2.115784850171817

Epoch: 5| Step: 6
Training loss: 1.0758769512176514
Validation loss: 2.107132923218512

Epoch: 5| Step: 7
Training loss: 1.1426750421524048
Validation loss: 2.0725023374762586

Epoch: 5| Step: 8
Training loss: 1.4492323398590088
Validation loss: 2.0450449105231994

Epoch: 5| Step: 9
Training loss: 1.039394736289978
Validation loss: 2.057388062118202

Epoch: 5| Step: 10
Training loss: 0.8496804237365723
Validation loss: 2.039176348716982

Epoch: 178| Step: 0
Training loss: 1.2229197025299072
Validation loss: 2.0202743571291686

Epoch: 5| Step: 1
Training loss: 1.3202893733978271
Validation loss: 1.988773399783719

Epoch: 5| Step: 2
Training loss: 0.9956837892532349
Validation loss: 2.0014165947514195

Epoch: 5| Step: 3
Training loss: 0.6030709147453308
Validation loss: 2.023957170465941

Epoch: 5| Step: 4
Training loss: 1.3300899267196655
Validation loss: 2.073801435450072

Epoch: 5| Step: 5
Training loss: 1.5255367755889893
Validation loss: 2.138177256430349

Epoch: 5| Step: 6
Training loss: 1.5145797729492188
Validation loss: 2.1626744065233456

Epoch: 5| Step: 7
Training loss: 0.9176464080810547
Validation loss: 2.1630084206981044

Epoch: 5| Step: 8
Training loss: 1.3366860151290894
Validation loss: 2.0507731386410293

Epoch: 5| Step: 9
Training loss: 1.3458809852600098
Validation loss: 2.0010473061633367

Epoch: 5| Step: 10
Training loss: 1.2669395208358765
Validation loss: 1.9758778887410318

Epoch: 179| Step: 0
Training loss: 1.2501407861709595
Validation loss: 1.9639137380866594

Epoch: 5| Step: 1
Training loss: 1.4455287456512451
Validation loss: 1.9649994052866453

Epoch: 5| Step: 2
Training loss: 1.0144784450531006
Validation loss: 1.9703284437938402

Epoch: 5| Step: 3
Training loss: 1.6152403354644775
Validation loss: 1.983053397106868

Epoch: 5| Step: 4
Training loss: 0.9362174868583679
Validation loss: 2.0128090971259662

Epoch: 5| Step: 5
Training loss: 1.2038017511367798
Validation loss: 2.0549068822655627

Epoch: 5| Step: 6
Training loss: 1.3100409507751465
Validation loss: 2.0934037162411596

Epoch: 5| Step: 7
Training loss: 1.54881751537323
Validation loss: 2.112675110499064

Epoch: 5| Step: 8
Training loss: 0.8729864358901978
Validation loss: 2.1187643671548493

Epoch: 5| Step: 9
Training loss: 1.19728422164917
Validation loss: 2.1169609869680097

Epoch: 5| Step: 10
Training loss: 1.3381322622299194
Validation loss: 2.1080405789036907

Epoch: 180| Step: 0
Training loss: 1.4041497707366943
Validation loss: 2.1198226969729186

Epoch: 5| Step: 1
Training loss: 1.5983924865722656
Validation loss: 2.1188414327559935

Epoch: 5| Step: 2
Training loss: 0.7515960931777954
Validation loss: 2.1121246301999657

Epoch: 5| Step: 3
Training loss: 1.0815484523773193
Validation loss: 2.1105788830787904

Epoch: 5| Step: 4
Training loss: 1.1035325527191162
Validation loss: 2.0795024979499077

Epoch: 5| Step: 5
Training loss: 1.1797983646392822
Validation loss: 2.0210425725547214

Epoch: 5| Step: 6
Training loss: 1.4633241891860962
Validation loss: 2.010738011329405

Epoch: 5| Step: 7
Training loss: 1.1701291799545288
Validation loss: 2.004253891206557

Epoch: 5| Step: 8
Training loss: 1.54417085647583
Validation loss: 2.0158352813413067

Epoch: 5| Step: 9
Training loss: 0.7994627952575684
Validation loss: 1.9734352147707375

Epoch: 5| Step: 10
Training loss: 1.4445018768310547
Validation loss: 2.0257262081228276

Epoch: 181| Step: 0
Training loss: 1.0342954397201538
Validation loss: 2.0865631308606876

Epoch: 5| Step: 1
Training loss: 0.9945747256278992
Validation loss: 2.1134598473066926

Epoch: 5| Step: 2
Training loss: 1.0706489086151123
Validation loss: 2.084756535868491

Epoch: 5| Step: 3
Training loss: 1.296845555305481
Validation loss: 2.1094055688509377

Epoch: 5| Step: 4
Training loss: 1.5317198038101196
Validation loss: 2.104184212223176

Epoch: 5| Step: 5
Training loss: 1.217320203781128
Validation loss: 2.0957422012923868

Epoch: 5| Step: 6
Training loss: 1.2823503017425537
Validation loss: 2.0503739221121675

Epoch: 5| Step: 7
Training loss: 0.8861827850341797
Validation loss: 2.0516449328391784

Epoch: 5| Step: 8
Training loss: 1.069525122642517
Validation loss: 2.044126796466048

Epoch: 5| Step: 9
Training loss: 1.3514585494995117
Validation loss: 2.038468881319928

Epoch: 5| Step: 10
Training loss: 1.278357982635498
Validation loss: 2.035107615173504

Epoch: 182| Step: 0
Training loss: 1.3589614629745483
Validation loss: 2.062657457526012

Epoch: 5| Step: 1
Training loss: 0.893337070941925
Validation loss: 2.0714627209530083

Epoch: 5| Step: 2
Training loss: 1.2557705640792847
Validation loss: 2.09956294362263

Epoch: 5| Step: 3
Training loss: 1.0452609062194824
Validation loss: 2.0903504676716302

Epoch: 5| Step: 4
Training loss: 1.2815477848052979
Validation loss: 2.0561426429338354

Epoch: 5| Step: 5
Training loss: 1.2822116613388062
Validation loss: 2.0688981215159097

Epoch: 5| Step: 6
Training loss: 1.1471433639526367
Validation loss: 2.0385473210324525

Epoch: 5| Step: 7
Training loss: 1.0046837329864502
Validation loss: 2.051209895841537

Epoch: 5| Step: 8
Training loss: 0.92671138048172
Validation loss: 2.057866414388021

Epoch: 5| Step: 9
Training loss: 1.8355216979980469
Validation loss: 2.0686592837815643

Epoch: 5| Step: 10
Training loss: 1.22779381275177
Validation loss: 2.071226586577713

Epoch: 183| Step: 0
Training loss: 1.259502649307251
Validation loss: 2.0336719123266076

Epoch: 5| Step: 1
Training loss: 1.2560114860534668
Validation loss: 1.9613328185132755

Epoch: 5| Step: 2
Training loss: 1.4240634441375732
Validation loss: 1.9428338427697458

Epoch: 5| Step: 3
Training loss: 1.1705684661865234
Validation loss: 1.9416190232000043

Epoch: 5| Step: 4
Training loss: 1.4721019268035889
Validation loss: 2.012573670315486

Epoch: 5| Step: 5
Training loss: 1.0413439273834229
Validation loss: 2.067100999175861

Epoch: 5| Step: 6
Training loss: 0.956264317035675
Validation loss: 2.0705285085144864

Epoch: 5| Step: 7
Training loss: 1.3508344888687134
Validation loss: 2.060090652076147

Epoch: 5| Step: 8
Training loss: 1.0240824222564697
Validation loss: 2.1235146009793846

Epoch: 5| Step: 9
Training loss: 1.3415368795394897
Validation loss: 2.111658061704328

Epoch: 5| Step: 10
Training loss: 0.7741739153862
Validation loss: 2.052315678647769

Epoch: 184| Step: 0
Training loss: 1.3589115142822266
Validation loss: 2.0189713662670505

Epoch: 5| Step: 1
Training loss: 0.9121443033218384
Validation loss: 1.96041472752889

Epoch: 5| Step: 2
Training loss: 1.7522073984146118
Validation loss: 1.9652527378451439

Epoch: 5| Step: 3
Training loss: 0.955826461315155
Validation loss: 1.9789156285665368

Epoch: 5| Step: 4
Training loss: 0.9512385129928589
Validation loss: 2.043063635467201

Epoch: 5| Step: 5
Training loss: 1.0861599445343018
Validation loss: 2.0881863242836407

Epoch: 5| Step: 6
Training loss: 0.8563182950019836
Validation loss: 2.096735797902589

Epoch: 5| Step: 7
Training loss: 1.3040564060211182
Validation loss: 2.107008863520879

Epoch: 5| Step: 8
Training loss: 1.2872045040130615
Validation loss: 2.094209376201835

Epoch: 5| Step: 9
Training loss: 1.176418423652649
Validation loss: 2.031042516872447

Epoch: 5| Step: 10
Training loss: 1.468032956123352
Validation loss: 2.0026838792267667

Epoch: 185| Step: 0
Training loss: 0.9219830632209778
Validation loss: 1.9401419598569152

Epoch: 5| Step: 1
Training loss: 1.691107153892517
Validation loss: 1.9291669245689147

Epoch: 5| Step: 2
Training loss: 1.1387627124786377
Validation loss: 1.9198345202271656

Epoch: 5| Step: 3
Training loss: 1.7570403814315796
Validation loss: 1.9025419373666086

Epoch: 5| Step: 4
Training loss: 1.3231096267700195
Validation loss: 1.8891025307357951

Epoch: 5| Step: 5
Training loss: 1.3790509700775146
Validation loss: 1.9252215431582542

Epoch: 5| Step: 6
Training loss: 0.9805725812911987
Validation loss: 1.939679761086741

Epoch: 5| Step: 7
Training loss: 0.5592671632766724
Validation loss: 2.0175434594513266

Epoch: 5| Step: 8
Training loss: 1.0836576223373413
Validation loss: 2.0545973547043337

Epoch: 5| Step: 9
Training loss: 0.9261028170585632
Validation loss: 2.0763650427582445

Epoch: 5| Step: 10
Training loss: 1.1845440864562988
Validation loss: 2.103206567866828

Epoch: 186| Step: 0
Training loss: 1.4174083471298218
Validation loss: 2.0986467330686507

Epoch: 5| Step: 1
Training loss: 1.0767556428909302
Validation loss: 2.0813384402182793

Epoch: 5| Step: 2
Training loss: 1.3001083135604858
Validation loss: 2.0498671121494745

Epoch: 5| Step: 3
Training loss: 1.2161179780960083
Validation loss: 1.9421320987004105

Epoch: 5| Step: 4
Training loss: 1.0973200798034668
Validation loss: 1.8815327882766724

Epoch: 5| Step: 5
Training loss: 1.223261833190918
Validation loss: 1.8391199919485277

Epoch: 5| Step: 6
Training loss: 1.538896083831787
Validation loss: 1.8150889642776982

Epoch: 5| Step: 7
Training loss: 1.149083137512207
Validation loss: 1.8672105753293602

Epoch: 5| Step: 8
Training loss: 1.176354169845581
Validation loss: 1.9414848319945797

Epoch: 5| Step: 9
Training loss: 0.730750322341919
Validation loss: 2.0436287874816568

Epoch: 5| Step: 10
Training loss: 0.9393050074577332
Validation loss: 2.1380709294349916

Epoch: 187| Step: 0
Training loss: 1.2563287019729614
Validation loss: 2.2043319209929435

Epoch: 5| Step: 1
Training loss: 1.4670733213424683
Validation loss: 2.248406405090004

Epoch: 5| Step: 2
Training loss: 0.829559326171875
Validation loss: 2.27040123298604

Epoch: 5| Step: 3
Training loss: 1.2456800937652588
Validation loss: 2.2341570546550136

Epoch: 5| Step: 4
Training loss: 1.1544902324676514
Validation loss: 2.1858723202059345

Epoch: 5| Step: 5
Training loss: 1.502219557762146
Validation loss: 2.0905435098114835

Epoch: 5| Step: 6
Training loss: 1.3525667190551758
Validation loss: 1.9870309675893476

Epoch: 5| Step: 7
Training loss: 1.007287859916687
Validation loss: 1.9860891654927244

Epoch: 5| Step: 8
Training loss: 1.135338544845581
Validation loss: 1.928354626060814

Epoch: 5| Step: 9
Training loss: 0.8065882921218872
Validation loss: 1.9376799534725886

Epoch: 5| Step: 10
Training loss: 1.0006446838378906
Validation loss: 1.9453852010029618

Epoch: 188| Step: 0
Training loss: 1.0162802934646606
Validation loss: 2.019424587167719

Epoch: 5| Step: 1
Training loss: 1.4041779041290283
Validation loss: 2.051225910904587

Epoch: 5| Step: 2
Training loss: 1.198326826095581
Validation loss: 2.0561220376722273

Epoch: 5| Step: 3
Training loss: 1.1553685665130615
Validation loss: 2.0221616414285477

Epoch: 5| Step: 4
Training loss: 1.2208654880523682
Validation loss: 2.0302740450828307

Epoch: 5| Step: 5
Training loss: 0.6122227907180786
Validation loss: 2.046897462619248

Epoch: 5| Step: 6
Training loss: 1.1637685298919678
Validation loss: 2.0096509328452488

Epoch: 5| Step: 7
Training loss: 0.9326665997505188
Validation loss: 1.96819390660973

Epoch: 5| Step: 8
Training loss: 1.4809386730194092
Validation loss: 1.9586229965250979

Epoch: 5| Step: 9
Training loss: 0.9220744371414185
Validation loss: 1.9456860429497176

Epoch: 5| Step: 10
Training loss: 0.9331537485122681
Validation loss: 1.9530018093765422

Epoch: 189| Step: 0
Training loss: 1.1734342575073242
Validation loss: 1.9848579616956814

Epoch: 5| Step: 1
Training loss: 1.2928154468536377
Validation loss: 1.9908903824385775

Epoch: 5| Step: 2
Training loss: 1.0230859518051147
Validation loss: 2.023564459175192

Epoch: 5| Step: 3
Training loss: 1.0401747226715088
Validation loss: 2.0199552710338304

Epoch: 5| Step: 4
Training loss: 1.206071138381958
Validation loss: 2.0289669011228826

Epoch: 5| Step: 5
Training loss: 1.106081247329712
Validation loss: 2.0104914249912387

Epoch: 5| Step: 6
Training loss: 0.9697176814079285
Validation loss: 2.0129210077306277

Epoch: 5| Step: 7
Training loss: 1.0275226831436157
Validation loss: 1.9692798006919123

Epoch: 5| Step: 8
Training loss: 1.2097948789596558
Validation loss: 1.9638800544123496

Epoch: 5| Step: 9
Training loss: 1.1639792919158936
Validation loss: 1.9386270482053038

Epoch: 5| Step: 10
Training loss: 0.6217005252838135
Validation loss: 1.937663185981012

Epoch: 190| Step: 0
Training loss: 1.0478503704071045
Validation loss: 1.9926562437447168

Epoch: 5| Step: 1
Training loss: 1.089807152748108
Validation loss: 2.0658445230094333

Epoch: 5| Step: 2
Training loss: 1.12405526638031
Validation loss: 2.0672965626562796

Epoch: 5| Step: 3
Training loss: 1.226194977760315
Validation loss: 2.0433275071523522

Epoch: 5| Step: 4
Training loss: 1.2013542652130127
Validation loss: 2.0558067931923816

Epoch: 5| Step: 5
Training loss: 0.727729856967926
Validation loss: 2.047401761495939

Epoch: 5| Step: 6
Training loss: 1.0538651943206787
Validation loss: 2.0242843986839376

Epoch: 5| Step: 7
Training loss: 1.205639123916626
Validation loss: 2.02227532991799

Epoch: 5| Step: 8
Training loss: 0.9013479351997375
Validation loss: 1.992363727220925

Epoch: 5| Step: 9
Training loss: 1.123154640197754
Validation loss: 1.9928100083463935

Epoch: 5| Step: 10
Training loss: 1.5034373998641968
Validation loss: 1.9633551131012619

Epoch: 191| Step: 0
Training loss: 1.0756287574768066
Validation loss: 1.9881110319527246

Epoch: 5| Step: 1
Training loss: 0.8733108639717102
Validation loss: 1.9687193926944528

Epoch: 5| Step: 2
Training loss: 0.9166147112846375
Validation loss: 2.0003331656097085

Epoch: 5| Step: 3
Training loss: 1.5656073093414307
Validation loss: 2.0000503704112065

Epoch: 5| Step: 4
Training loss: 0.37153175473213196
Validation loss: 2.0291014640561995

Epoch: 5| Step: 5
Training loss: 1.6400028467178345
Validation loss: 2.061824232019404

Epoch: 5| Step: 6
Training loss: 1.280124306678772
Validation loss: 2.0612285547359015

Epoch: 5| Step: 7
Training loss: 1.1944029331207275
Validation loss: 2.0169592108777774

Epoch: 5| Step: 8
Training loss: 0.9357808232307434
Validation loss: 2.004455966334189

Epoch: 5| Step: 9
Training loss: 1.5105911493301392
Validation loss: 1.9412548490749892

Epoch: 5| Step: 10
Training loss: 0.30232593417167664
Validation loss: 1.9031688244112077

Epoch: 192| Step: 0
Training loss: 1.372225284576416
Validation loss: 1.9417944364650275

Epoch: 5| Step: 1
Training loss: 0.7517990469932556
Validation loss: 2.0070923810364096

Epoch: 5| Step: 2
Training loss: 1.0060254335403442
Validation loss: 2.0691886845455376

Epoch: 5| Step: 3
Training loss: 1.1690404415130615
Validation loss: 2.0603426579506166

Epoch: 5| Step: 4
Training loss: 0.9784366488456726
Validation loss: 2.0510809344630085

Epoch: 5| Step: 5
Training loss: 1.1702314615249634
Validation loss: 2.0410362443616314

Epoch: 5| Step: 6
Training loss: 1.133535623550415
Validation loss: 1.9940969803000008

Epoch: 5| Step: 7
Training loss: 1.1857936382293701
Validation loss: 2.0135968282658565

Epoch: 5| Step: 8
Training loss: 1.3345063924789429
Validation loss: 1.9968375980213124

Epoch: 5| Step: 9
Training loss: 0.5730826258659363
Validation loss: 1.9663421338604343

Epoch: 5| Step: 10
Training loss: 0.9881815314292908
Validation loss: 1.9934600399386497

Epoch: 193| Step: 0
Training loss: 0.6309908032417297
Validation loss: 1.9947113875419862

Epoch: 5| Step: 1
Training loss: 0.9118014574050903
Validation loss: 2.0037154331002185

Epoch: 5| Step: 2
Training loss: 1.3541557788848877
Validation loss: 2.0165732816983293

Epoch: 5| Step: 3
Training loss: 0.6728627681732178
Validation loss: 2.058688320139403

Epoch: 5| Step: 4
Training loss: 1.1986579895019531
Validation loss: 2.089251951504779

Epoch: 5| Step: 5
Training loss: 0.9364274740219116
Validation loss: 2.117383389062779

Epoch: 5| Step: 6
Training loss: 0.8180424571037292
Validation loss: 2.108881050540555

Epoch: 5| Step: 7
Training loss: 1.7232091426849365
Validation loss: 2.1036961027370986

Epoch: 5| Step: 8
Training loss: 1.2010257244110107
Validation loss: 2.05699001332765

Epoch: 5| Step: 9
Training loss: 1.2036635875701904
Validation loss: 2.0148817723797214

Epoch: 5| Step: 10
Training loss: 0.953877866268158
Validation loss: 1.9642395357931814

Epoch: 194| Step: 0
Training loss: 1.037121295928955
Validation loss: 1.9412599455925725

Epoch: 5| Step: 1
Training loss: 1.2554200887680054
Validation loss: 1.9334841293673362

Epoch: 5| Step: 2
Training loss: 1.2048852443695068
Validation loss: 1.9857247029581377

Epoch: 5| Step: 3
Training loss: 0.9876285791397095
Validation loss: 1.9898613857966598

Epoch: 5| Step: 4
Training loss: 0.9724211692810059
Validation loss: 1.990132930458233

Epoch: 5| Step: 5
Training loss: 1.2849489450454712
Validation loss: 2.0247913406741236

Epoch: 5| Step: 6
Training loss: 0.8071094751358032
Validation loss: 2.0646014751926547

Epoch: 5| Step: 7
Training loss: 1.4655640125274658
Validation loss: 2.1244561082573346

Epoch: 5| Step: 8
Training loss: 1.0736665725708008
Validation loss: 2.103248296245452

Epoch: 5| Step: 9
Training loss: 0.5747509002685547
Validation loss: 2.1179837308904177

Epoch: 5| Step: 10
Training loss: 0.7012541890144348
Validation loss: 2.0719601556818974

Epoch: 195| Step: 0
Training loss: 1.3580634593963623
Validation loss: 2.0549401057663785

Epoch: 5| Step: 1
Training loss: 1.0301883220672607
Validation loss: 2.0152437071646414

Epoch: 5| Step: 2
Training loss: 1.1744868755340576
Validation loss: 2.0108441332335114

Epoch: 5| Step: 3
Training loss: 0.9437335133552551
Validation loss: 1.9769600809261363

Epoch: 5| Step: 4
Training loss: 0.7486801147460938
Validation loss: 1.9684686763312227

Epoch: 5| Step: 5
Training loss: 0.8151780962944031
Validation loss: 1.9566833716566845

Epoch: 5| Step: 6
Training loss: 1.2700402736663818
Validation loss: 1.94662763995509

Epoch: 5| Step: 7
Training loss: 0.979190468788147
Validation loss: 1.9441352736565374

Epoch: 5| Step: 8
Training loss: 1.1043319702148438
Validation loss: 1.9259840339742682

Epoch: 5| Step: 9
Training loss: 0.840438961982727
Validation loss: 1.943778307207169

Epoch: 5| Step: 10
Training loss: 0.9088203310966492
Validation loss: 1.9818150638252177

Epoch: 196| Step: 0
Training loss: 1.5420920848846436
Validation loss: 2.0384099816763275

Epoch: 5| Step: 1
Training loss: 0.7403495907783508
Validation loss: 2.0074846103627193

Epoch: 5| Step: 2
Training loss: 0.7282079458236694
Validation loss: 2.013399152345555

Epoch: 5| Step: 3
Training loss: 1.0199635028839111
Validation loss: 1.9851279566364903

Epoch: 5| Step: 4
Training loss: 0.9725220799446106
Validation loss: 1.9628073964067685

Epoch: 5| Step: 5
Training loss: 0.9979404211044312
Validation loss: 1.9421392179304553

Epoch: 5| Step: 6
Training loss: 0.9170986413955688
Validation loss: 1.8940833435263684

Epoch: 5| Step: 7
Training loss: 1.3163193464279175
Validation loss: 1.886359776220014

Epoch: 5| Step: 8
Training loss: 0.9707473516464233
Validation loss: 1.916067756632323

Epoch: 5| Step: 9
Training loss: 0.7948417067527771
Validation loss: 1.9518465188241774

Epoch: 5| Step: 10
Training loss: 1.1444149017333984
Validation loss: 1.9409017793593868

Epoch: 197| Step: 0
Training loss: 0.550735592842102
Validation loss: 1.9696941183459373

Epoch: 5| Step: 1
Training loss: 0.8040930032730103
Validation loss: 1.9981477722044914

Epoch: 5| Step: 2
Training loss: 1.269995927810669
Validation loss: 1.9821033349601171

Epoch: 5| Step: 3
Training loss: 0.8024500608444214
Validation loss: 1.9697411265424503

Epoch: 5| Step: 4
Training loss: 0.801831841468811
Validation loss: 1.9670038889813166

Epoch: 5| Step: 5
Training loss: 1.1979857683181763
Validation loss: 1.9831253277358187

Epoch: 5| Step: 6
Training loss: 1.0675235986709595
Validation loss: 1.9452346358247983

Epoch: 5| Step: 7
Training loss: 1.2718898057937622
Validation loss: 1.9918502723017046

Epoch: 5| Step: 8
Training loss: 0.684106171131134
Validation loss: 1.9914819296970163

Epoch: 5| Step: 9
Training loss: 1.316325306892395
Validation loss: 1.9451605440467916

Epoch: 5| Step: 10
Training loss: 0.839465320110321
Validation loss: 1.8845983025848225

Epoch: 198| Step: 0
Training loss: 0.7983036041259766
Validation loss: 1.8829055140095372

Epoch: 5| Step: 1
Training loss: 0.4631931185722351
Validation loss: 1.8998837701735958

Epoch: 5| Step: 2
Training loss: 0.5994932651519775
Validation loss: 1.8932292948486984

Epoch: 5| Step: 3
Training loss: 0.6480746269226074
Validation loss: 1.975368498474039

Epoch: 5| Step: 4
Training loss: 1.3211281299591064
Validation loss: 2.0403324891162176

Epoch: 5| Step: 5
Training loss: 1.083146333694458
Validation loss: 2.0711749856190016

Epoch: 5| Step: 6
Training loss: 1.6071056127548218
Validation loss: 2.0969729167158886

Epoch: 5| Step: 7
Training loss: 1.1707569360733032
Validation loss: 2.0812568920914845

Epoch: 5| Step: 8
Training loss: 1.0728261470794678
Validation loss: 2.027366239537475

Epoch: 5| Step: 9
Training loss: 1.4543622732162476
Validation loss: 2.024524099083357

Epoch: 5| Step: 10
Training loss: 0.59172123670578
Validation loss: 1.9913980499390633

Epoch: 199| Step: 0
Training loss: 1.1392827033996582
Validation loss: 1.9831257712456487

Epoch: 5| Step: 1
Training loss: 0.8703683018684387
Validation loss: 1.9436869646913262

Epoch: 5| Step: 2
Training loss: 0.8984476327896118
Validation loss: 1.9194388927951935

Epoch: 5| Step: 3
Training loss: 0.9090941548347473
Validation loss: 1.9642014670115646

Epoch: 5| Step: 4
Training loss: 0.9835273623466492
Validation loss: 1.9253841856474518

Epoch: 5| Step: 5
Training loss: 1.090799331665039
Validation loss: 1.9642855531425887

Epoch: 5| Step: 6
Training loss: 0.8900381922721863
Validation loss: 1.9378055231545561

Epoch: 5| Step: 7
Training loss: 0.9229022860527039
Validation loss: 1.9886114738320793

Epoch: 5| Step: 8
Training loss: 0.9105730056762695
Validation loss: 2.028917284422023

Epoch: 5| Step: 9
Training loss: 1.2588640451431274
Validation loss: 2.0716336209286927

Epoch: 5| Step: 10
Training loss: 1.0655491352081299
Validation loss: 2.0653585413450837

Epoch: 200| Step: 0
Training loss: 1.3838926553726196
Validation loss: 2.0622931488098635

Epoch: 5| Step: 1
Training loss: 0.6388986110687256
Validation loss: 2.0290350888365056

Epoch: 5| Step: 2
Training loss: 1.3042410612106323
Validation loss: 1.9843420238905056

Epoch: 5| Step: 3
Training loss: 1.1739610433578491
Validation loss: 1.9481403443121141

Epoch: 5| Step: 4
Training loss: 0.6746488213539124
Validation loss: 1.9200000275847733

Epoch: 5| Step: 5
Training loss: 1.1127122640609741
Validation loss: 1.9119728560088782

Epoch: 5| Step: 6
Training loss: 0.6613790392875671
Validation loss: 1.8844426780618646

Epoch: 5| Step: 7
Training loss: 1.1185590028762817
Validation loss: 1.8882607490785661

Epoch: 5| Step: 8
Training loss: 0.9709399938583374
Validation loss: 1.9003485377116869

Epoch: 5| Step: 9
Training loss: 0.8608814477920532
Validation loss: 1.870336886375181

Epoch: 5| Step: 10
Training loss: 0.9176599979400635
Validation loss: 1.8836962574271745

Epoch: 201| Step: 0
Training loss: 0.8480497598648071
Validation loss: 1.9021275235760597

Epoch: 5| Step: 1
Training loss: 1.2755125761032104
Validation loss: 1.9276946372883295

Epoch: 5| Step: 2
Training loss: 0.7291366457939148
Validation loss: 1.9308605219728203

Epoch: 5| Step: 3
Training loss: 1.082646131515503
Validation loss: 1.968456801547799

Epoch: 5| Step: 4
Training loss: 0.5171122550964355
Validation loss: 1.978502550432759

Epoch: 5| Step: 5
Training loss: 1.3267699480056763
Validation loss: 2.0163601111340266

Epoch: 5| Step: 6
Training loss: 0.7482897043228149
Validation loss: 2.0278186272549372

Epoch: 5| Step: 7
Training loss: 1.0685172080993652
Validation loss: 2.008496775422045

Epoch: 5| Step: 8
Training loss: 0.9583622217178345
Validation loss: 1.9754245755493

Epoch: 5| Step: 9
Training loss: 0.9496151208877563
Validation loss: 1.9632353936472247

Epoch: 5| Step: 10
Training loss: 0.9270361065864563
Validation loss: 1.9425236153346237

Epoch: 202| Step: 0
Training loss: 0.955822765827179
Validation loss: 1.9194124001328663

Epoch: 5| Step: 1
Training loss: 1.1675817966461182
Validation loss: 1.924890322069968

Epoch: 5| Step: 2
Training loss: 1.150847315788269
Validation loss: 1.9299749533335369

Epoch: 5| Step: 3
Training loss: 0.8529629707336426
Validation loss: 1.9175947763586556

Epoch: 5| Step: 4
Training loss: 0.9439985156059265
Validation loss: 1.9003931847951745

Epoch: 5| Step: 5
Training loss: 0.5574259757995605
Validation loss: 1.9438379182610461

Epoch: 5| Step: 6
Training loss: 0.9746062159538269
Validation loss: 2.003861196579472

Epoch: 5| Step: 7
Training loss: 1.0271880626678467
Validation loss: 2.0250669474242837

Epoch: 5| Step: 8
Training loss: 0.7579649686813354
Validation loss: 1.9763138640311457

Epoch: 5| Step: 9
Training loss: 1.3875706195831299
Validation loss: 1.9976928452009797

Epoch: 5| Step: 10
Training loss: 0.6943044066429138
Validation loss: 1.9590295912117086

Epoch: 203| Step: 0
Training loss: 1.217498540878296
Validation loss: 1.9782043246812717

Epoch: 5| Step: 1
Training loss: 1.1458300352096558
Validation loss: 2.0363928220605336

Epoch: 5| Step: 2
Training loss: 1.0376542806625366
Validation loss: 2.0859079207143476

Epoch: 5| Step: 3
Training loss: 0.7194260954856873
Validation loss: 2.0438677751889793

Epoch: 5| Step: 4
Training loss: 0.8603426218032837
Validation loss: 2.0432113626951813

Epoch: 5| Step: 5
Training loss: 0.6962023973464966
Validation loss: 2.027172347550751

Epoch: 5| Step: 6
Training loss: 0.7363952398300171
Validation loss: 2.021799328506634

Epoch: 5| Step: 7
Training loss: 0.8837870359420776
Validation loss: 1.9967768000018211

Epoch: 5| Step: 8
Training loss: 0.9753574132919312
Validation loss: 1.955239757414787

Epoch: 5| Step: 9
Training loss: 1.1764403581619263
Validation loss: 1.9495536870853876

Epoch: 5| Step: 10
Training loss: 0.7622213363647461
Validation loss: 1.9625530140374297

Epoch: 204| Step: 0
Training loss: 0.4650062620639801
Validation loss: 1.9756005707607474

Epoch: 5| Step: 1
Training loss: 0.9791954159736633
Validation loss: 1.9881790517478861

Epoch: 5| Step: 2
Training loss: 1.0809009075164795
Validation loss: 1.948613933337632

Epoch: 5| Step: 3
Training loss: 1.2777290344238281
Validation loss: 1.9712251514516852

Epoch: 5| Step: 4
Training loss: 0.5621078014373779
Validation loss: 1.9847068017528904

Epoch: 5| Step: 5
Training loss: 1.1707180738449097
Validation loss: 1.9853031071283485

Epoch: 5| Step: 6
Training loss: 0.6595409512519836
Validation loss: 1.9351650271364438

Epoch: 5| Step: 7
Training loss: 1.0489435195922852
Validation loss: 1.9284438023003199

Epoch: 5| Step: 8
Training loss: 1.076053500175476
Validation loss: 1.9327485869007726

Epoch: 5| Step: 9
Training loss: 0.9656464457511902
Validation loss: 1.942088815473741

Epoch: 5| Step: 10
Training loss: 0.695791482925415
Validation loss: 1.9720383049339376

Epoch: 205| Step: 0
Training loss: 0.7404466867446899
Validation loss: 1.941347942557386

Epoch: 5| Step: 1
Training loss: 0.48027506470680237
Validation loss: 1.9666545749992452

Epoch: 5| Step: 2
Training loss: 0.7296846508979797
Validation loss: 1.9613672225706038

Epoch: 5| Step: 3
Training loss: 1.3478758335113525
Validation loss: 2.000681971990934

Epoch: 5| Step: 4
Training loss: 0.8153030276298523
Validation loss: 1.9740172278496526

Epoch: 5| Step: 5
Training loss: 1.1861011981964111
Validation loss: 1.9794136337054673

Epoch: 5| Step: 6
Training loss: 0.8776559829711914
Validation loss: 1.9599618283651208

Epoch: 5| Step: 7
Training loss: 1.198253870010376
Validation loss: 1.9558409465256559

Epoch: 5| Step: 8
Training loss: 0.8762523531913757
Validation loss: 1.9228004768330564

Epoch: 5| Step: 9
Training loss: 0.8681648373603821
Validation loss: 1.9116218987331595

Epoch: 5| Step: 10
Training loss: 0.9881492853164673
Validation loss: 1.8902401706223846

Epoch: 206| Step: 0
Training loss: 0.6124793291091919
Validation loss: 1.9191992282867432

Epoch: 5| Step: 1
Training loss: 1.0451924800872803
Validation loss: 1.8893853925889539

Epoch: 5| Step: 2
Training loss: 1.042895793914795
Validation loss: 1.9057754162819154

Epoch: 5| Step: 3
Training loss: 1.0191514492034912
Validation loss: 1.9022680815830026

Epoch: 5| Step: 4
Training loss: 1.3519188165664673
Validation loss: 1.9074469112580823

Epoch: 5| Step: 5
Training loss: 0.6005346775054932
Validation loss: 1.9104957208838513

Epoch: 5| Step: 6
Training loss: 0.765969455242157
Validation loss: 1.8912951753985496

Epoch: 5| Step: 7
Training loss: 1.0180244445800781
Validation loss: 1.9334760071128927

Epoch: 5| Step: 8
Training loss: 1.1308485269546509
Validation loss: 1.9530786134863412

Epoch: 5| Step: 9
Training loss: 0.7727838158607483
Validation loss: 1.9876271165827268

Epoch: 5| Step: 10
Training loss: 0.8279003500938416
Validation loss: 2.029176163417037

Epoch: 207| Step: 0
Training loss: 0.7311764359474182
Validation loss: 1.9794964380161737

Epoch: 5| Step: 1
Training loss: 1.042078971862793
Validation loss: 1.9342362893524991

Epoch: 5| Step: 2
Training loss: 0.5767649412155151
Validation loss: 1.9266312878618959

Epoch: 5| Step: 3
Training loss: 1.367691993713379
Validation loss: 1.8864927394415743

Epoch: 5| Step: 4
Training loss: 0.9194717407226562
Validation loss: 1.8909866348389657

Epoch: 5| Step: 5
Training loss: 0.8577896356582642
Validation loss: 1.8798737423394316

Epoch: 5| Step: 6
Training loss: 1.0005807876586914
Validation loss: 1.8877546018169773

Epoch: 5| Step: 7
Training loss: 0.5575352907180786
Validation loss: 1.929270951978622

Epoch: 5| Step: 8
Training loss: 1.085493803024292
Validation loss: 1.972552627645513

Epoch: 5| Step: 9
Training loss: 0.7857633829116821
Validation loss: 1.9725397363785775

Epoch: 5| Step: 10
Training loss: 0.9996088743209839
Validation loss: 2.017540693283081

Epoch: 208| Step: 0
Training loss: 0.5541184544563293
Validation loss: 2.009570232001684

Epoch: 5| Step: 1
Training loss: 0.9577910304069519
Validation loss: 1.974334184841443

Epoch: 5| Step: 2
Training loss: 0.8259812593460083
Validation loss: 1.9383853302207044

Epoch: 5| Step: 3
Training loss: 1.0716701745986938
Validation loss: 1.8907352750019362

Epoch: 5| Step: 4
Training loss: 0.7281046509742737
Validation loss: 1.910746515438121

Epoch: 5| Step: 5
Training loss: 0.9431034326553345
Validation loss: 1.8825165610159598

Epoch: 5| Step: 6
Training loss: 1.1011451482772827
Validation loss: 1.8869991033307967

Epoch: 5| Step: 7
Training loss: 0.8076226115226746
Validation loss: 1.9106188692072386

Epoch: 5| Step: 8
Training loss: 0.9583187103271484
Validation loss: 1.9156313429596603

Epoch: 5| Step: 9
Training loss: 1.2033672332763672
Validation loss: 1.9642800656698083

Epoch: 5| Step: 10
Training loss: 0.5817469358444214
Validation loss: 1.9328283263790993

Epoch: 209| Step: 0
Training loss: 0.7094405889511108
Validation loss: 1.9487863740613383

Epoch: 5| Step: 1
Training loss: 0.6242040395736694
Validation loss: 1.9750207354945521

Epoch: 5| Step: 2
Training loss: 1.1258429288864136
Validation loss: 1.943982333265325

Epoch: 5| Step: 3
Training loss: 1.1535977125167847
Validation loss: 1.89700496837657

Epoch: 5| Step: 4
Training loss: 0.7055937051773071
Validation loss: 1.9103646624472834

Epoch: 5| Step: 5
Training loss: 0.9066444635391235
Validation loss: 1.9213124603353522

Epoch: 5| Step: 6
Training loss: 0.5460664629936218
Validation loss: 1.9139138037158596

Epoch: 5| Step: 7
Training loss: 0.9986133575439453
Validation loss: 1.9082495704773934

Epoch: 5| Step: 8
Training loss: 1.107365369796753
Validation loss: 1.906483273352346

Epoch: 5| Step: 9
Training loss: 0.7447574138641357
Validation loss: 1.9179851880637548

Epoch: 5| Step: 10
Training loss: 0.8817586302757263
Validation loss: 1.8697098794803824

Epoch: 210| Step: 0
Training loss: 1.0445849895477295
Validation loss: 1.9020841942038587

Epoch: 5| Step: 1
Training loss: 0.505590558052063
Validation loss: 1.901375501386581

Epoch: 5| Step: 2
Training loss: 0.8583548665046692
Validation loss: 1.907805791465185

Epoch: 5| Step: 3
Training loss: 0.6206822991371155
Validation loss: 1.9411450227101643

Epoch: 5| Step: 4
Training loss: 1.2844312191009521
Validation loss: 1.9104014058266916

Epoch: 5| Step: 5
Training loss: 0.9248550534248352
Validation loss: 1.9319797844015143

Epoch: 5| Step: 6
Training loss: 0.7428525686264038
Validation loss: 1.9111226258739349

Epoch: 5| Step: 7
Training loss: 0.8373827934265137
Validation loss: 1.8936476322912401

Epoch: 5| Step: 8
Training loss: 0.9395995140075684
Validation loss: 1.8864573048007103

Epoch: 5| Step: 9
Training loss: 0.8739103078842163
Validation loss: 1.920612145495671

Epoch: 5| Step: 10
Training loss: 0.6230949759483337
Validation loss: 1.866296637442804

Epoch: 211| Step: 0
Training loss: 0.9136756658554077
Validation loss: 1.9238863298969884

Epoch: 5| Step: 1
Training loss: 0.8147857785224915
Validation loss: 1.9281917656621625

Epoch: 5| Step: 2
Training loss: 0.8132011294364929
Validation loss: 1.9168251675944175

Epoch: 5| Step: 3
Training loss: 0.6961492300033569
Validation loss: 1.9030678182519891

Epoch: 5| Step: 4
Training loss: 1.4189367294311523
Validation loss: 1.9195753425680182

Epoch: 5| Step: 5
Training loss: 0.8209055662155151
Validation loss: 1.8820358194330686

Epoch: 5| Step: 6
Training loss: 0.6701430082321167
Validation loss: 1.9351279530473935

Epoch: 5| Step: 7
Training loss: 0.8005936741828918
Validation loss: 1.932789542341745

Epoch: 5| Step: 8
Training loss: 0.7029112577438354
Validation loss: 1.9219418212931643

Epoch: 5| Step: 9
Training loss: 0.882599949836731
Validation loss: 1.8966528882262528

Epoch: 5| Step: 10
Training loss: 0.694991946220398
Validation loss: 1.8383715537286573

Epoch: 212| Step: 0
Training loss: 0.7650806307792664
Validation loss: 1.8241957925981092

Epoch: 5| Step: 1
Training loss: 0.8553255796432495
Validation loss: 1.8304644425710042

Epoch: 5| Step: 2
Training loss: 0.553991436958313
Validation loss: 1.8239659083786832

Epoch: 5| Step: 3
Training loss: 1.1668956279754639
Validation loss: 1.8401735508313743

Epoch: 5| Step: 4
Training loss: 1.0629057884216309
Validation loss: 1.8240713073361305

Epoch: 5| Step: 5
Training loss: 0.9972337484359741
Validation loss: 1.8582865794499714

Epoch: 5| Step: 6
Training loss: 0.656905472278595
Validation loss: 1.8821402595889183

Epoch: 5| Step: 7
Training loss: 0.9417327046394348
Validation loss: 1.9305484089800107

Epoch: 5| Step: 8
Training loss: 0.9210430383682251
Validation loss: 1.9543085508449103

Epoch: 5| Step: 9
Training loss: 0.8664796948432922
Validation loss: 1.9720202927948327

Epoch: 5| Step: 10
Training loss: 0.5343327522277832
Validation loss: 1.9965155816847278

Epoch: 213| Step: 0
Training loss: 0.661590039730072
Validation loss: 1.9856283331430087

Epoch: 5| Step: 1
Training loss: 1.2743202447891235
Validation loss: 1.965276454084663

Epoch: 5| Step: 2
Training loss: 0.9094918966293335
Validation loss: 1.9012655058214742

Epoch: 5| Step: 3
Training loss: 0.8160468935966492
Validation loss: 1.9152744277831046

Epoch: 5| Step: 4
Training loss: 0.7994933128356934
Validation loss: 1.9067446736879246

Epoch: 5| Step: 5
Training loss: 0.8995790481567383
Validation loss: 1.8940767626608572

Epoch: 5| Step: 6
Training loss: 0.7470477819442749
Validation loss: 1.9088456951161867

Epoch: 5| Step: 7
Training loss: 0.6076188087463379
Validation loss: 1.9327230966219338

Epoch: 5| Step: 8
Training loss: 0.8147363662719727
Validation loss: 1.9800161264275993

Epoch: 5| Step: 9
Training loss: 0.7347612380981445
Validation loss: 1.9775156513337167

Epoch: 5| Step: 10
Training loss: 0.8728157877922058
Validation loss: 1.9769626471304125

Epoch: 214| Step: 0
Training loss: 0.9857248067855835
Validation loss: 1.9981934690988192

Epoch: 5| Step: 1
Training loss: 0.6220114827156067
Validation loss: 2.0187474053393126

Epoch: 5| Step: 2
Training loss: 0.8708375692367554
Validation loss: 2.0238507870704896

Epoch: 5| Step: 3
Training loss: 1.1321653127670288
Validation loss: 2.0123984044597996

Epoch: 5| Step: 4
Training loss: 0.4269696772098541
Validation loss: 1.989252294263532

Epoch: 5| Step: 5
Training loss: 1.1810572147369385
Validation loss: 2.0253428771931636

Epoch: 5| Step: 6
Training loss: 0.6553239822387695
Validation loss: 1.984727580060241

Epoch: 5| Step: 7
Training loss: 0.6838189363479614
Validation loss: 1.9833866716713033

Epoch: 5| Step: 8
Training loss: 0.990428626537323
Validation loss: 1.932296338901725

Epoch: 5| Step: 9
Training loss: 0.9900985956192017
Validation loss: 1.9324976808281356

Epoch: 5| Step: 10
Training loss: 0.865150511264801
Validation loss: 1.907673833190754

Epoch: 215| Step: 0
Training loss: 0.7427141666412354
Validation loss: 1.9395701923678

Epoch: 5| Step: 1
Training loss: 0.7589665651321411
Validation loss: 1.9408198172046291

Epoch: 5| Step: 2
Training loss: 0.955417811870575
Validation loss: 1.9287383582002373

Epoch: 5| Step: 3
Training loss: 0.5322198271751404
Validation loss: 1.9334429502487183

Epoch: 5| Step: 4
Training loss: 0.7539353966712952
Validation loss: 1.9564728659968222

Epoch: 5| Step: 5
Training loss: 1.166579246520996
Validation loss: 1.978794684974096

Epoch: 5| Step: 6
Training loss: 1.0058575868606567
Validation loss: 1.9969294712107668

Epoch: 5| Step: 7
Training loss: 1.0756210088729858
Validation loss: 1.9686482875577864

Epoch: 5| Step: 8
Training loss: 0.6710939407348633
Validation loss: 1.9800126257763113

Epoch: 5| Step: 9
Training loss: 0.32664769887924194
Validation loss: 1.9295350364459458

Epoch: 5| Step: 10
Training loss: 1.069495439529419
Validation loss: 1.9057538432459677

Epoch: 216| Step: 0
Training loss: 0.9415315389633179
Validation loss: 1.8820591011355001

Epoch: 5| Step: 1
Training loss: 1.2837544679641724
Validation loss: 1.8639826979688419

Epoch: 5| Step: 2
Training loss: 0.5042476058006287
Validation loss: 1.8561520320112987

Epoch: 5| Step: 3
Training loss: 0.4653438627719879
Validation loss: 1.8873482288852814

Epoch: 5| Step: 4
Training loss: 0.6220699548721313
Validation loss: 1.9124728902693717

Epoch: 5| Step: 5
Training loss: 0.7623726725578308
Validation loss: 1.931366705125378

Epoch: 5| Step: 6
Training loss: 0.9510694742202759
Validation loss: 1.9355537353023406

Epoch: 5| Step: 7
Training loss: 1.193979263305664
Validation loss: 1.9494504159496677

Epoch: 5| Step: 8
Training loss: 0.850627064704895
Validation loss: 1.9129160283714213

Epoch: 5| Step: 9
Training loss: 0.7773140668869019
Validation loss: 1.905657309357838

Epoch: 5| Step: 10
Training loss: 0.9294525980949402
Validation loss: 1.9521900223147484

Epoch: 217| Step: 0
Training loss: 0.7276145219802856
Validation loss: 1.917652553127658

Epoch: 5| Step: 1
Training loss: 0.740251362323761
Validation loss: 1.931565776948006

Epoch: 5| Step: 2
Training loss: 0.7075833678245544
Validation loss: 1.9340012791336223

Epoch: 5| Step: 3
Training loss: 0.7019756436347961
Validation loss: 1.9142037860808834

Epoch: 5| Step: 4
Training loss: 0.649811863899231
Validation loss: 1.900923982743294

Epoch: 5| Step: 5
Training loss: 0.8688174486160278
Validation loss: 1.90559353879703

Epoch: 5| Step: 6
Training loss: 0.746695876121521
Validation loss: 1.9191711897491126

Epoch: 5| Step: 7
Training loss: 1.2017276287078857
Validation loss: 1.9205159564172067

Epoch: 5| Step: 8
Training loss: 0.6974220275878906
Validation loss: 1.9469245890135407

Epoch: 5| Step: 9
Training loss: 1.164657473564148
Validation loss: 2.005006362033147

Epoch: 5| Step: 10
Training loss: 0.809938907623291
Validation loss: 2.003174388280479

Epoch: 218| Step: 0
Training loss: 0.7322235703468323
Validation loss: 2.024995908942274

Epoch: 5| Step: 1
Training loss: 0.6299881339073181
Validation loss: 1.9444815856154247

Epoch: 5| Step: 2
Training loss: 0.8717519044876099
Validation loss: 1.9291877874764063

Epoch: 5| Step: 3
Training loss: 0.7720506191253662
Validation loss: 1.9114810830803328

Epoch: 5| Step: 4
Training loss: 1.0840262174606323
Validation loss: 1.9169892290587067

Epoch: 5| Step: 5
Training loss: 1.0230000019073486
Validation loss: 1.9083740736848565

Epoch: 5| Step: 6
Training loss: 0.9272688627243042
Validation loss: 1.9102251427147978

Epoch: 5| Step: 7
Training loss: 0.7118909955024719
Validation loss: 1.9158905270279094

Epoch: 5| Step: 8
Training loss: 0.8513882756233215
Validation loss: 1.9346751307928434

Epoch: 5| Step: 9
Training loss: 0.5405426025390625
Validation loss: 1.9451904143056562

Epoch: 5| Step: 10
Training loss: 0.7804264426231384
Validation loss: 1.9665120032525831

Epoch: 219| Step: 0
Training loss: 1.0719478130340576
Validation loss: 1.9574965020661712

Epoch: 5| Step: 1
Training loss: 0.9798694849014282
Validation loss: 1.9900422403889317

Epoch: 5| Step: 2
Training loss: 1.1264941692352295
Validation loss: 1.9580117605065788

Epoch: 5| Step: 3
Training loss: 0.8187681436538696
Validation loss: 1.9510384592958676

Epoch: 5| Step: 4
Training loss: 0.7548528909683228
Validation loss: 1.9126750781971922

Epoch: 5| Step: 5
Training loss: 0.6034501791000366
Validation loss: 1.8892834135281142

Epoch: 5| Step: 6
Training loss: 0.7177305221557617
Validation loss: 1.9114601535181845

Epoch: 5| Step: 7
Training loss: 0.4716988205909729
Validation loss: 1.853041333536948

Epoch: 5| Step: 8
Training loss: 0.8215084075927734
Validation loss: 1.8654613097508748

Epoch: 5| Step: 9
Training loss: 0.8552085161209106
Validation loss: 1.8351041591295632

Epoch: 5| Step: 10
Training loss: 0.7431879639625549
Validation loss: 1.8269002488864365

Epoch: 220| Step: 0
Training loss: 0.7765902876853943
Validation loss: 1.8176064016998454

Epoch: 5| Step: 1
Training loss: 0.8022106289863586
Validation loss: 1.8402885019138295

Epoch: 5| Step: 2
Training loss: 0.5962896347045898
Validation loss: 1.8374595116543513

Epoch: 5| Step: 3
Training loss: 0.4084227979183197
Validation loss: 1.8489411415592316

Epoch: 5| Step: 4
Training loss: 0.7576664686203003
Validation loss: 1.8731042415865007

Epoch: 5| Step: 5
Training loss: 1.0882058143615723
Validation loss: 1.9189232767269175

Epoch: 5| Step: 6
Training loss: 0.6551226377487183
Validation loss: 1.8882683259184643

Epoch: 5| Step: 7
Training loss: 0.7374600768089294
Validation loss: 1.9198733452827699

Epoch: 5| Step: 8
Training loss: 1.411869764328003
Validation loss: 1.9133365320903

Epoch: 5| Step: 9
Training loss: 0.8879324197769165
Validation loss: 1.9279472238274031

Epoch: 5| Step: 10
Training loss: 0.24535734951496124
Validation loss: 1.9604611422425957

Epoch: 221| Step: 0
Training loss: 0.6589779853820801
Validation loss: 1.9367082195897256

Epoch: 5| Step: 1
Training loss: 1.2132662534713745
Validation loss: 1.9476690599995274

Epoch: 5| Step: 2
Training loss: 0.7326949238777161
Validation loss: 1.8993459824592835

Epoch: 5| Step: 3
Training loss: 0.8151504397392273
Validation loss: 1.90914241344698

Epoch: 5| Step: 4
Training loss: 0.4899226129055023
Validation loss: 1.8921167824857978

Epoch: 5| Step: 5
Training loss: 0.8604057431221008
Validation loss: 1.8909613240149714

Epoch: 5| Step: 6
Training loss: 0.4357563555240631
Validation loss: 1.862546267048005

Epoch: 5| Step: 7
Training loss: 0.8511503338813782
Validation loss: 1.8591153493491552

Epoch: 5| Step: 8
Training loss: 0.8545196652412415
Validation loss: 1.8710040751323904

Epoch: 5| Step: 9
Training loss: 0.8870660662651062
Validation loss: 1.8684289109322332

Epoch: 5| Step: 10
Training loss: 0.8189396858215332
Validation loss: 1.8717247709151237

Epoch: 222| Step: 0
Training loss: 0.6919220089912415
Validation loss: 1.8557726990792058

Epoch: 5| Step: 1
Training loss: 0.7881141901016235
Validation loss: 1.8888656477774344

Epoch: 5| Step: 2
Training loss: 1.2173092365264893
Validation loss: 1.8562627633412678

Epoch: 5| Step: 3
Training loss: 0.8172239065170288
Validation loss: 1.8801301064029816

Epoch: 5| Step: 4
Training loss: 0.6390198469161987
Validation loss: 1.8695895876935733

Epoch: 5| Step: 5
Training loss: 0.7053067684173584
Validation loss: 1.8669212633563625

Epoch: 5| Step: 6
Training loss: 0.6147400736808777
Validation loss: 1.8837234691907

Epoch: 5| Step: 7
Training loss: 1.0420925617218018
Validation loss: 1.890438715616862

Epoch: 5| Step: 8
Training loss: 0.8396695852279663
Validation loss: 1.9195855881578179

Epoch: 5| Step: 9
Training loss: 0.36866921186447144
Validation loss: 1.9611695517775833

Epoch: 5| Step: 10
Training loss: 0.8578009009361267
Validation loss: 1.961489749211137

Epoch: 223| Step: 0
Training loss: 0.7311731576919556
Validation loss: 1.9562591237406577

Epoch: 5| Step: 1
Training loss: 0.7348934412002563
Validation loss: 1.9368768276706818

Epoch: 5| Step: 2
Training loss: 0.9395171999931335
Validation loss: 1.9439022297500281

Epoch: 5| Step: 3
Training loss: 0.9952510595321655
Validation loss: 1.9054916494636125

Epoch: 5| Step: 4
Training loss: 0.643197238445282
Validation loss: 1.87129904249663

Epoch: 5| Step: 5
Training loss: 0.536887526512146
Validation loss: 1.8651158925025695

Epoch: 5| Step: 6
Training loss: 0.6970515847206116
Validation loss: 1.8852391601890646

Epoch: 5| Step: 7
Training loss: 0.5683470368385315
Validation loss: 1.8719279432809481

Epoch: 5| Step: 8
Training loss: 0.753091037273407
Validation loss: 1.8813835677280222

Epoch: 5| Step: 9
Training loss: 0.9093037843704224
Validation loss: 1.9088869197394258

Epoch: 5| Step: 10
Training loss: 0.6577326059341431
Validation loss: 1.9021294322065128

Epoch: 224| Step: 0
Training loss: 0.7054886817932129
Validation loss: 1.9053528103777158

Epoch: 5| Step: 1
Training loss: 0.4450903534889221
Validation loss: 1.878215104021052

Epoch: 5| Step: 2
Training loss: 1.0854170322418213
Validation loss: 1.887904933703843

Epoch: 5| Step: 3
Training loss: 0.8685060739517212
Validation loss: 1.8921691781731063

Epoch: 5| Step: 4
Training loss: 0.6403270363807678
Validation loss: 1.9051686012616722

Epoch: 5| Step: 5
Training loss: 0.9028494954109192
Validation loss: 1.8826336399201424

Epoch: 5| Step: 6
Training loss: 1.0820729732513428
Validation loss: 1.8869902228796354

Epoch: 5| Step: 7
Training loss: 0.8754361867904663
Validation loss: 1.8888928531318583

Epoch: 5| Step: 8
Training loss: 0.7349286079406738
Validation loss: 1.8928807525224582

Epoch: 5| Step: 9
Training loss: 0.5563872456550598
Validation loss: 1.9062682274849183

Epoch: 5| Step: 10
Training loss: 0.569489061832428
Validation loss: 1.9691328002560524

Epoch: 225| Step: 0
Training loss: 0.6576531529426575
Validation loss: 1.9703799319523636

Epoch: 5| Step: 1
Training loss: 0.8174891471862793
Validation loss: 1.981089771434825

Epoch: 5| Step: 2
Training loss: 0.7436740398406982
Validation loss: 1.9505966709506126

Epoch: 5| Step: 3
Training loss: 0.4952622354030609
Validation loss: 1.901572023668597

Epoch: 5| Step: 4
Training loss: 0.9335783123970032
Validation loss: 1.8753891478302658

Epoch: 5| Step: 5
Training loss: 0.6555887460708618
Validation loss: 1.8539281557965022

Epoch: 5| Step: 6
Training loss: 0.7884206771850586
Validation loss: 1.9120942085020003

Epoch: 5| Step: 7
Training loss: 0.6020581126213074
Validation loss: 1.9074025871933147

Epoch: 5| Step: 8
Training loss: 0.8825761675834656
Validation loss: 1.9159496215081984

Epoch: 5| Step: 9
Training loss: 0.46055707335472107
Validation loss: 1.9353584794587986

Epoch: 5| Step: 10
Training loss: 1.0956628322601318
Validation loss: 1.9284607800104285

Epoch: 226| Step: 0
Training loss: 0.4882632791996002
Validation loss: 1.9115491644028695

Epoch: 5| Step: 1
Training loss: 0.5755746960639954
Validation loss: 1.9062017112649896

Epoch: 5| Step: 2
Training loss: 0.4113125205039978
Validation loss: 1.9055982969140495

Epoch: 5| Step: 3
Training loss: 0.841975212097168
Validation loss: 1.8979948028441398

Epoch: 5| Step: 4
Training loss: 1.2345962524414062
Validation loss: 1.8742608754865584

Epoch: 5| Step: 5
Training loss: 0.8182204365730286
Validation loss: 1.8361393687545613

Epoch: 5| Step: 6
Training loss: 0.4830220639705658
Validation loss: 1.809043158767044

Epoch: 5| Step: 7
Training loss: 0.7321699261665344
Validation loss: 1.8143893493119108

Epoch: 5| Step: 8
Training loss: 1.2292516231536865
Validation loss: 1.7806118572911909

Epoch: 5| Step: 9
Training loss: 0.8622804880142212
Validation loss: 1.791935900206207

Epoch: 5| Step: 10
Training loss: 0.5522825717926025
Validation loss: 1.8285729680010068

Epoch: 227| Step: 0
Training loss: 0.48050642013549805
Validation loss: 1.7979559283102713

Epoch: 5| Step: 1
Training loss: 0.7668502926826477
Validation loss: 1.8578059519490888

Epoch: 5| Step: 2
Training loss: 0.6667084097862244
Validation loss: 1.8578776198048745

Epoch: 5| Step: 3
Training loss: 1.0401448011398315
Validation loss: 1.9319188082089989

Epoch: 5| Step: 4
Training loss: 0.8835095167160034
Validation loss: 1.9402780532836914

Epoch: 5| Step: 5
Training loss: 0.7996150255203247
Validation loss: 1.9250199705041864

Epoch: 5| Step: 6
Training loss: 0.7028911709785461
Validation loss: 1.9053775418189265

Epoch: 5| Step: 7
Training loss: 0.6615403294563293
Validation loss: 1.8647222954739806

Epoch: 5| Step: 8
Training loss: 0.5635639429092407
Validation loss: 1.8334777086011824

Epoch: 5| Step: 9
Training loss: 0.6779231429100037
Validation loss: 1.810100273419452

Epoch: 5| Step: 10
Training loss: 0.6351405382156372
Validation loss: 1.7976047851706063

Epoch: 228| Step: 0
Training loss: 0.7740122675895691
Validation loss: 1.7903562617558304

Epoch: 5| Step: 1
Training loss: 0.4407455325126648
Validation loss: 1.7858556239835677

Epoch: 5| Step: 2
Training loss: 0.6681402921676636
Validation loss: 1.7697157680347402

Epoch: 5| Step: 3
Training loss: 0.5603343844413757
Validation loss: 1.8422388543364823

Epoch: 5| Step: 4
Training loss: 0.8684422373771667
Validation loss: 1.8221139856564101

Epoch: 5| Step: 5
Training loss: 0.9945142865180969
Validation loss: 1.8521787120449928

Epoch: 5| Step: 6
Training loss: 0.527126133441925
Validation loss: 1.9037421839211577

Epoch: 5| Step: 7
Training loss: 0.766098141670227
Validation loss: 1.870705077725072

Epoch: 5| Step: 8
Training loss: 0.687530517578125
Validation loss: 1.9059136362485989

Epoch: 5| Step: 9
Training loss: 0.6051998138427734
Validation loss: 1.916966889494209

Epoch: 5| Step: 10
Training loss: 0.9446384310722351
Validation loss: 1.9091888076515608

Epoch: 229| Step: 0
Training loss: 0.36738884449005127
Validation loss: 1.8844466799048967

Epoch: 5| Step: 1
Training loss: 0.5437448620796204
Validation loss: 1.8412797451019287

Epoch: 5| Step: 2
Training loss: 0.8131335377693176
Validation loss: 1.830213286543405

Epoch: 5| Step: 3
Training loss: 1.1068708896636963
Validation loss: 1.8082540201884445

Epoch: 5| Step: 4
Training loss: 0.7431846857070923
Validation loss: 1.8258305698312738

Epoch: 5| Step: 5
Training loss: 0.7908986806869507
Validation loss: 1.8389285700295561

Epoch: 5| Step: 6
Training loss: 0.8700854182243347
Validation loss: 1.8480216508270593

Epoch: 5| Step: 7
Training loss: 0.7339050769805908
Validation loss: 1.8296322873843613

Epoch: 5| Step: 8
Training loss: 0.3434050977230072
Validation loss: 1.8356594090820642

Epoch: 5| Step: 9
Training loss: 0.765745997428894
Validation loss: 1.8573954207922823

Epoch: 5| Step: 10
Training loss: 0.7222664952278137
Validation loss: 1.8320088796718146

Epoch: 230| Step: 0
Training loss: 0.7438277006149292
Validation loss: 1.8545990118416407

Epoch: 5| Step: 1
Training loss: 0.6262047290802002
Validation loss: 1.8811784662226194

Epoch: 5| Step: 2
Training loss: 0.47482576966285706
Validation loss: 1.8621909951650968

Epoch: 5| Step: 3
Training loss: 1.026497483253479
Validation loss: 1.8800669254795197

Epoch: 5| Step: 4
Training loss: 0.9029046893119812
Validation loss: 1.905171468693723

Epoch: 5| Step: 5
Training loss: 0.6922063231468201
Validation loss: 1.9301220063240296

Epoch: 5| Step: 6
Training loss: 0.7497178912162781
Validation loss: 1.9129413456045172

Epoch: 5| Step: 7
Training loss: 1.0284124612808228
Validation loss: 1.855769952138265

Epoch: 5| Step: 8
Training loss: 0.6101606488227844
Validation loss: 1.8524441795964395

Epoch: 5| Step: 9
Training loss: 0.7108116745948792
Validation loss: 1.8667826293617167

Epoch: 5| Step: 10
Training loss: 0.5670781135559082
Validation loss: 1.8174477623355003

Epoch: 231| Step: 0
Training loss: 0.9260834455490112
Validation loss: 1.7976985208449825

Epoch: 5| Step: 1
Training loss: 0.5950524210929871
Validation loss: 1.7994955778121948

Epoch: 5| Step: 2
Training loss: 0.6915618777275085
Validation loss: 1.7485031876512753

Epoch: 5| Step: 3
Training loss: 0.6826080083847046
Validation loss: 1.7364142165389111

Epoch: 5| Step: 4
Training loss: 0.7158576250076294
Validation loss: 1.7691449490926598

Epoch: 5| Step: 5
Training loss: 0.533692479133606
Validation loss: 1.8371450708758446

Epoch: 5| Step: 6
Training loss: 0.6125558614730835
Validation loss: 1.8484609896136868

Epoch: 5| Step: 7
Training loss: 0.8346000909805298
Validation loss: 1.8546635079127487

Epoch: 5| Step: 8
Training loss: 0.54517662525177
Validation loss: 1.8629388674612968

Epoch: 5| Step: 9
Training loss: 0.939853847026825
Validation loss: 1.8310503011108727

Epoch: 5| Step: 10
Training loss: 0.7072241306304932
Validation loss: 1.8449668499731249

Epoch: 232| Step: 0
Training loss: 0.6172365546226501
Validation loss: 1.8392413764871576

Epoch: 5| Step: 1
Training loss: 0.9209268689155579
Validation loss: 1.891946920784571

Epoch: 5| Step: 2
Training loss: 0.8005874752998352
Validation loss: 1.9185627762989332

Epoch: 5| Step: 3
Training loss: 0.7349117398262024
Validation loss: 1.92648192374937

Epoch: 5| Step: 4
Training loss: 0.5858089327812195
Validation loss: 1.9251864007724229

Epoch: 5| Step: 5
Training loss: 0.5897525548934937
Validation loss: 1.9235944235196678

Epoch: 5| Step: 6
Training loss: 0.5298519730567932
Validation loss: 1.8344078679238596

Epoch: 5| Step: 7
Training loss: 0.508327841758728
Validation loss: 1.7839460526743243

Epoch: 5| Step: 8
Training loss: 0.9182750582695007
Validation loss: 1.7167660613213815

Epoch: 5| Step: 9
Training loss: 0.9932864308357239
Validation loss: 1.7388722230029363

Epoch: 5| Step: 10
Training loss: 0.6528844237327576
Validation loss: 1.7229353522741666

Epoch: 233| Step: 0
Training loss: 0.7758524417877197
Validation loss: 1.7278980273072437

Epoch: 5| Step: 1
Training loss: 0.6743900179862976
Validation loss: 1.713306220628882

Epoch: 5| Step: 2
Training loss: 0.8272668719291687
Validation loss: 1.7242203374062814

Epoch: 5| Step: 3
Training loss: 0.5737349390983582
Validation loss: 1.7157640405880508

Epoch: 5| Step: 4
Training loss: 0.6470025181770325
Validation loss: 1.745899320930563

Epoch: 5| Step: 5
Training loss: 0.5655936002731323
Validation loss: 1.7380589387750114

Epoch: 5| Step: 6
Training loss: 0.6348437070846558
Validation loss: 1.7854449108082762

Epoch: 5| Step: 7
Training loss: 0.7240970134735107
Validation loss: 1.8516817323623165

Epoch: 5| Step: 8
Training loss: 0.7843486070632935
Validation loss: 1.9089758985786027

Epoch: 5| Step: 9
Training loss: 0.7260451316833496
Validation loss: 1.9518970686902282

Epoch: 5| Step: 10
Training loss: 0.8438999056816101
Validation loss: 1.9860289609560402

Epoch: 234| Step: 0
Training loss: 0.9530256390571594
Validation loss: 1.925460418065389

Epoch: 5| Step: 1
Training loss: 0.6182903051376343
Validation loss: 1.8348068498796033

Epoch: 5| Step: 2
Training loss: 0.5807073712348938
Validation loss: 1.7869081394646757

Epoch: 5| Step: 3
Training loss: 0.9582816958427429
Validation loss: 1.777405838812551

Epoch: 5| Step: 4
Training loss: 0.5717085599899292
Validation loss: 1.7396161684425928

Epoch: 5| Step: 5
Training loss: 0.6149393320083618
Validation loss: 1.737794485143436

Epoch: 5| Step: 6
Training loss: 0.6948108673095703
Validation loss: 1.759809294054585

Epoch: 5| Step: 7
Training loss: 1.0305407047271729
Validation loss: 1.7559350344442552

Epoch: 5| Step: 8
Training loss: 0.5944598913192749
Validation loss: 1.7791107290534562

Epoch: 5| Step: 9
Training loss: 0.4583287835121155
Validation loss: 1.7987589297756073

Epoch: 5| Step: 10
Training loss: 0.7226376533508301
Validation loss: 1.8061741680227301

Epoch: 235| Step: 0
Training loss: 0.6924744844436646
Validation loss: 1.8269431783306984

Epoch: 5| Step: 1
Training loss: 0.49715274572372437
Validation loss: 1.8364697502505394

Epoch: 5| Step: 2
Training loss: 0.28779321908950806
Validation loss: 1.848218996037719

Epoch: 5| Step: 3
Training loss: 0.5794148445129395
Validation loss: 1.825271814100204

Epoch: 5| Step: 4
Training loss: 0.6631134748458862
Validation loss: 1.766228058004892

Epoch: 5| Step: 5
Training loss: 1.059840440750122
Validation loss: 1.743028498465015

Epoch: 5| Step: 6
Training loss: 0.8210498690605164
Validation loss: 1.7507058420488912

Epoch: 5| Step: 7
Training loss: 0.7586618065834045
Validation loss: 1.728060697996488

Epoch: 5| Step: 8
Training loss: 0.9751712679862976
Validation loss: 1.7646436178556053

Epoch: 5| Step: 9
Training loss: 0.5518701076507568
Validation loss: 1.7514770902613157

Epoch: 5| Step: 10
Training loss: 0.8306618332862854
Validation loss: 1.8028039009340349

Epoch: 236| Step: 0
Training loss: 0.4987821578979492
Validation loss: 1.8631483867604246

Epoch: 5| Step: 1
Training loss: 0.9263003468513489
Validation loss: 1.8319021066029866

Epoch: 5| Step: 2
Training loss: 0.5287966132164001
Validation loss: 1.882852465875687

Epoch: 5| Step: 3
Training loss: 0.694232702255249
Validation loss: 1.8672874140483078

Epoch: 5| Step: 4
Training loss: 0.6251163482666016
Validation loss: 1.884137620208084

Epoch: 5| Step: 5
Training loss: 0.6898890733718872
Validation loss: 1.869986459773074

Epoch: 5| Step: 6
Training loss: 0.741065502166748
Validation loss: 1.827926399887249

Epoch: 5| Step: 7
Training loss: 0.8755513429641724
Validation loss: 1.8737518941202471

Epoch: 5| Step: 8
Training loss: 0.37083274126052856
Validation loss: 1.8413056500496403

Epoch: 5| Step: 9
Training loss: 0.3956589698791504
Validation loss: 1.8507658243179321

Epoch: 5| Step: 10
Training loss: 0.9649568200111389
Validation loss: 1.8310945226300148

Epoch: 237| Step: 0
Training loss: 0.6992937326431274
Validation loss: 1.8300631917932981

Epoch: 5| Step: 1
Training loss: 0.4957084655761719
Validation loss: 1.8547311059890255

Epoch: 5| Step: 2
Training loss: 0.5742954611778259
Validation loss: 1.858652840378464

Epoch: 5| Step: 3
Training loss: 0.7299451231956482
Validation loss: 1.8531176928550965

Epoch: 5| Step: 4
Training loss: 0.8737697601318359
Validation loss: 1.868094257129136

Epoch: 5| Step: 5
Training loss: 0.5722476243972778
Validation loss: 1.9033609628677368

Epoch: 5| Step: 6
Training loss: 0.7522159218788147
Validation loss: 1.8653683649596347

Epoch: 5| Step: 7
Training loss: 0.8047773241996765
Validation loss: 1.8509660613152288

Epoch: 5| Step: 8
Training loss: 0.45353689789772034
Validation loss: 1.8562490247911023

Epoch: 5| Step: 9
Training loss: 0.8607343435287476
Validation loss: 1.8358497734992736

Epoch: 5| Step: 10
Training loss: 0.4832600951194763
Validation loss: 1.8114752513106152

Epoch: 238| Step: 0
Training loss: 0.8113421201705933
Validation loss: 1.8204866481083695

Epoch: 5| Step: 1
Training loss: 0.5833386778831482
Validation loss: 1.7753536278201687

Epoch: 5| Step: 2
Training loss: 0.7173441052436829
Validation loss: 1.8239519852463917

Epoch: 5| Step: 3
Training loss: 0.6452303528785706
Validation loss: 1.8077943786498039

Epoch: 5| Step: 4
Training loss: 0.8464601635932922
Validation loss: 1.7960583702210458

Epoch: 5| Step: 5
Training loss: 0.8406100273132324
Validation loss: 1.7936675138370965

Epoch: 5| Step: 6
Training loss: 0.8635653257369995
Validation loss: 1.8240553717459402

Epoch: 5| Step: 7
Training loss: 0.40974265336990356
Validation loss: 1.8005291479890064

Epoch: 5| Step: 8
Training loss: 0.3165876865386963
Validation loss: 1.84359634307123

Epoch: 5| Step: 9
Training loss: 0.5596277117729187
Validation loss: 1.8409429673225648

Epoch: 5| Step: 10
Training loss: 0.4943809509277344
Validation loss: 1.8558598205607424

Epoch: 239| Step: 0
Training loss: 0.7336076498031616
Validation loss: 1.8310573536862609

Epoch: 5| Step: 1
Training loss: 0.7469546794891357
Validation loss: 1.8215397737359489

Epoch: 5| Step: 2
Training loss: 0.8004626035690308
Validation loss: 1.8021739067569855

Epoch: 5| Step: 3
Training loss: 0.3118881285190582
Validation loss: 1.786584783625859

Epoch: 5| Step: 4
Training loss: 0.5558249950408936
Validation loss: 1.7780433418930217

Epoch: 5| Step: 5
Training loss: 0.4993131756782532
Validation loss: 1.7723498652058263

Epoch: 5| Step: 6
Training loss: 0.6778602600097656
Validation loss: 1.7753796961999708

Epoch: 5| Step: 7
Training loss: 0.6128012537956238
Validation loss: 1.7856718276136665

Epoch: 5| Step: 8
Training loss: 0.590327262878418
Validation loss: 1.8151891923719836

Epoch: 5| Step: 9
Training loss: 0.5026021599769592
Validation loss: 1.840353271012665

Epoch: 5| Step: 10
Training loss: 0.9291772246360779
Validation loss: 1.92655518234417

Epoch: 240| Step: 0
Training loss: 0.3537643551826477
Validation loss: 1.9316699453579482

Epoch: 5| Step: 1
Training loss: 0.40141797065734863
Validation loss: 1.9333938565305484

Epoch: 5| Step: 2
Training loss: 0.7797205448150635
Validation loss: 1.9342785368683517

Epoch: 5| Step: 3
Training loss: 0.7984739542007446
Validation loss: 1.8885281752514582

Epoch: 5| Step: 4
Training loss: 0.5487473607063293
Validation loss: 1.8512907066652853

Epoch: 5| Step: 5
Training loss: 0.6641973257064819
Validation loss: 1.8181485411941365

Epoch: 5| Step: 6
Training loss: 0.6672548651695251
Validation loss: 1.8324392469980384

Epoch: 5| Step: 7
Training loss: 0.988314151763916
Validation loss: 1.7957137502649778

Epoch: 5| Step: 8
Training loss: 0.7149978876113892
Validation loss: 1.7551232691734069

Epoch: 5| Step: 9
Training loss: 0.5376912951469421
Validation loss: 1.7914749089107718

Epoch: 5| Step: 10
Training loss: 0.6263871192932129
Validation loss: 1.7559553884690808

Epoch: 241| Step: 0
Training loss: 0.8155353665351868
Validation loss: 1.7663374203507618

Epoch: 5| Step: 1
Training loss: 0.6956111192703247
Validation loss: 1.7660604548710648

Epoch: 5| Step: 2
Training loss: 0.42226967215538025
Validation loss: 1.7858297517222743

Epoch: 5| Step: 3
Training loss: 0.4096243977546692
Validation loss: 1.8193469932002406

Epoch: 5| Step: 4
Training loss: 0.4571760594844818
Validation loss: 1.8261875401261032

Epoch: 5| Step: 5
Training loss: 0.5120670199394226
Validation loss: 1.826329920881538

Epoch: 5| Step: 6
Training loss: 1.020453929901123
Validation loss: 1.8223014172687326

Epoch: 5| Step: 7
Training loss: 0.6338487863540649
Validation loss: 1.8610120742551741

Epoch: 5| Step: 8
Training loss: 0.9521753191947937
Validation loss: 1.8176463983392204

Epoch: 5| Step: 9
Training loss: 0.7240025997161865
Validation loss: 1.8059490547385266

Epoch: 5| Step: 10
Training loss: 0.26646673679351807
Validation loss: 1.8190464640176425

Epoch: 242| Step: 0
Training loss: 0.832391083240509
Validation loss: 1.8501587644700082

Epoch: 5| Step: 1
Training loss: 0.43644532561302185
Validation loss: 1.8753605427280549

Epoch: 5| Step: 2
Training loss: 0.6689175367355347
Validation loss: 1.8790996356676983

Epoch: 5| Step: 3
Training loss: 0.7991205453872681
Validation loss: 1.8609210060488792

Epoch: 5| Step: 4
Training loss: 0.7040303945541382
Validation loss: 1.8426730619963778

Epoch: 5| Step: 5
Training loss: 0.7505173683166504
Validation loss: 1.8542873551768642

Epoch: 5| Step: 6
Training loss: 0.6353796720504761
Validation loss: 1.825719823119461

Epoch: 5| Step: 7
Training loss: 0.2038925439119339
Validation loss: 1.7719563181682298

Epoch: 5| Step: 8
Training loss: 0.4787012040615082
Validation loss: 1.8085208336512248

Epoch: 5| Step: 9
Training loss: 0.6728702783584595
Validation loss: 1.7742896541472404

Epoch: 5| Step: 10
Training loss: 0.5017358064651489
Validation loss: 1.7935931746677687

Epoch: 243| Step: 0
Training loss: 0.65647953748703
Validation loss: 1.845378432222592

Epoch: 5| Step: 1
Training loss: 0.4333348274230957
Validation loss: 1.8201122630027033

Epoch: 5| Step: 2
Training loss: 0.7241593599319458
Validation loss: 1.8853153144159625

Epoch: 5| Step: 3
Training loss: 0.8680845499038696
Validation loss: 1.8646899192563948

Epoch: 5| Step: 4
Training loss: 0.7652287483215332
Validation loss: 1.8135573376891434

Epoch: 5| Step: 5
Training loss: 0.44888249039649963
Validation loss: 1.8059893551693167

Epoch: 5| Step: 6
Training loss: 0.543035626411438
Validation loss: 1.7881658346422258

Epoch: 5| Step: 7
Training loss: 0.5438513159751892
Validation loss: 1.7849704834722704

Epoch: 5| Step: 8
Training loss: 0.4501432478427887
Validation loss: 1.7916019552497453

Epoch: 5| Step: 9
Training loss: 0.6739266514778137
Validation loss: 1.8361528073587725

Epoch: 5| Step: 10
Training loss: 0.5254339575767517
Validation loss: 1.8479861931134296

Epoch: 244| Step: 0
Training loss: 0.2269233763217926
Validation loss: 1.892095273540866

Epoch: 5| Step: 1
Training loss: 0.46459707617759705
Validation loss: 1.8653697352255545

Epoch: 5| Step: 2
Training loss: 0.949859619140625
Validation loss: 1.8566580549363167

Epoch: 5| Step: 3
Training loss: 0.59901362657547
Validation loss: 1.871956766292613

Epoch: 5| Step: 4
Training loss: 0.6903289556503296
Validation loss: 1.8412358081468971

Epoch: 5| Step: 5
Training loss: 0.7737911343574524
Validation loss: 1.852924935279354

Epoch: 5| Step: 6
Training loss: 0.6203233003616333
Validation loss: 1.830955816853431

Epoch: 5| Step: 7
Training loss: 0.7214652299880981
Validation loss: 1.7961691092419367

Epoch: 5| Step: 8
Training loss: 0.505651593208313
Validation loss: 1.7874523606351627

Epoch: 5| Step: 9
Training loss: 0.42435431480407715
Validation loss: 1.7693619471724316

Epoch: 5| Step: 10
Training loss: 0.6452955603599548
Validation loss: 1.7650585725743284

Epoch: 245| Step: 0
Training loss: 0.7866703271865845
Validation loss: 1.808231822906002

Epoch: 5| Step: 1
Training loss: 0.5712016224861145
Validation loss: 1.7692502878045524

Epoch: 5| Step: 2
Training loss: 0.4149453639984131
Validation loss: 1.7940874702186995

Epoch: 5| Step: 3
Training loss: 0.530215322971344
Validation loss: 1.817671695063191

Epoch: 5| Step: 4
Training loss: 0.6027799248695374
Validation loss: 1.8273920115604196

Epoch: 5| Step: 5
Training loss: 0.3529174029827118
Validation loss: 1.8200683337385937

Epoch: 5| Step: 6
Training loss: 0.6874868273735046
Validation loss: 1.7972366912390596

Epoch: 5| Step: 7
Training loss: 0.550236165523529
Validation loss: 1.7920317726750528

Epoch: 5| Step: 8
Training loss: 0.9347743988037109
Validation loss: 1.8529863075543476

Epoch: 5| Step: 9
Training loss: 0.8005040287971497
Validation loss: 1.8043006491917435

Epoch: 5| Step: 10
Training loss: 0.3706498146057129
Validation loss: 1.813235491834661

Epoch: 246| Step: 0
Training loss: 0.5113357305526733
Validation loss: 1.8370863981144403

Epoch: 5| Step: 1
Training loss: 0.5534371137619019
Validation loss: 1.8819709708613734

Epoch: 5| Step: 2
Training loss: 0.4782279133796692
Validation loss: 1.877417274700698

Epoch: 5| Step: 3
Training loss: 0.4437370300292969
Validation loss: 1.862514675304454

Epoch: 5| Step: 4
Training loss: 0.8031196594238281
Validation loss: 1.8340809332427157

Epoch: 5| Step: 5
Training loss: 0.7661026120185852
Validation loss: 1.7758163072729622

Epoch: 5| Step: 6
Training loss: 0.6055417060852051
Validation loss: 1.7689694589184177

Epoch: 5| Step: 7
Training loss: 0.4588429927825928
Validation loss: 1.7305003263617074

Epoch: 5| Step: 8
Training loss: 0.8034396171569824
Validation loss: 1.6989818978053268

Epoch: 5| Step: 9
Training loss: 0.586430013179779
Validation loss: 1.6729052976895404

Epoch: 5| Step: 10
Training loss: 0.6374415159225464
Validation loss: 1.6741250304765598

Epoch: 247| Step: 0
Training loss: 0.6447150111198425
Validation loss: 1.675079595658087

Epoch: 5| Step: 1
Training loss: 0.7074726819992065
Validation loss: 1.6959059866525794

Epoch: 5| Step: 2
Training loss: 0.616868793964386
Validation loss: 1.7603445745283557

Epoch: 5| Step: 3
Training loss: 0.5246590375900269
Validation loss: 1.835675137017363

Epoch: 5| Step: 4
Training loss: 0.6699003577232361
Validation loss: 1.8395210132803967

Epoch: 5| Step: 5
Training loss: 0.8235815167427063
Validation loss: 1.848206473935035

Epoch: 5| Step: 6
Training loss: 0.6797782778739929
Validation loss: 1.8207219775005052

Epoch: 5| Step: 7
Training loss: 0.5320020914077759
Validation loss: 1.7686983795576199

Epoch: 5| Step: 8
Training loss: 0.3404799699783325
Validation loss: 1.7477315151563255

Epoch: 5| Step: 9
Training loss: 0.683258593082428
Validation loss: 1.7199093064954203

Epoch: 5| Step: 10
Training loss: 0.767919659614563
Validation loss: 1.7437842917698685

Epoch: 248| Step: 0
Training loss: 0.6188077926635742
Validation loss: 1.7910310068438131

Epoch: 5| Step: 1
Training loss: 0.775147557258606
Validation loss: 1.789037904431743

Epoch: 5| Step: 2
Training loss: 0.7019671201705933
Validation loss: 1.8582829929167224

Epoch: 5| Step: 3
Training loss: 0.6910399198532104
Validation loss: 1.857943691233153

Epoch: 5| Step: 4
Training loss: 0.4217134118080139
Validation loss: 1.8321023512912054

Epoch: 5| Step: 5
Training loss: 0.6353744268417358
Validation loss: 1.842264816325198

Epoch: 5| Step: 6
Training loss: 0.6743413805961609
Validation loss: 1.8457832144152733

Epoch: 5| Step: 7
Training loss: 0.54590904712677
Validation loss: 1.7969970369851718

Epoch: 5| Step: 8
Training loss: 0.6856967806816101
Validation loss: 1.8088444676450504

Epoch: 5| Step: 9
Training loss: 0.6211665868759155
Validation loss: 1.8137283914832658

Epoch: 5| Step: 10
Training loss: 0.3212363123893738
Validation loss: 1.806012963735929

Epoch: 249| Step: 0
Training loss: 0.5498875379562378
Validation loss: 1.815122967125267

Epoch: 5| Step: 1
Training loss: 0.6698024868965149
Validation loss: 1.8353497623115458

Epoch: 5| Step: 2
Training loss: 0.5563986897468567
Validation loss: 1.8109236225005119

Epoch: 5| Step: 3
Training loss: 0.5864639282226562
Validation loss: 1.7966603412423083

Epoch: 5| Step: 4
Training loss: 0.5550781488418579
Validation loss: 1.7951074595092444

Epoch: 5| Step: 5
Training loss: 0.615939736366272
Validation loss: 1.7817593159214142

Epoch: 5| Step: 6
Training loss: 0.495197594165802
Validation loss: 1.8057734145913074

Epoch: 5| Step: 7
Training loss: 0.6454657316207886
Validation loss: 1.794912080610952

Epoch: 5| Step: 8
Training loss: 0.9758740663528442
Validation loss: 1.809663341891381

Epoch: 5| Step: 9
Training loss: 0.34676599502563477
Validation loss: 1.8604080933396534

Epoch: 5| Step: 10
Training loss: 0.6688000559806824
Validation loss: 1.8286842376955095

Epoch: 250| Step: 0
Training loss: 0.366081565618515
Validation loss: 1.855010353108888

Epoch: 5| Step: 1
Training loss: 0.6539713740348816
Validation loss: 1.8469359400451824

Epoch: 5| Step: 2
Training loss: 0.5242787599563599
Validation loss: 1.8479209228228497

Epoch: 5| Step: 3
Training loss: 0.27371081709861755
Validation loss: 1.8444305671158658

Epoch: 5| Step: 4
Training loss: 0.6885082125663757
Validation loss: 1.8220158264201174

Epoch: 5| Step: 5
Training loss: 0.597093403339386
Validation loss: 1.7823156297847789

Epoch: 5| Step: 6
Training loss: 0.5783027410507202
Validation loss: 1.7238906839842438

Epoch: 5| Step: 7
Training loss: 0.5489829778671265
Validation loss: 1.738620808047633

Epoch: 5| Step: 8
Training loss: 0.46322160959243774
Validation loss: 1.7673798812332975

Epoch: 5| Step: 9
Training loss: 0.7944501042366028
Validation loss: 1.7864478211249075

Epoch: 5| Step: 10
Training loss: 0.9096910953521729
Validation loss: 1.7811014447160947

Epoch: 251| Step: 0
Training loss: 0.44848155975341797
Validation loss: 1.81055054613339

Epoch: 5| Step: 1
Training loss: 0.7136025428771973
Validation loss: 1.80889267306174

Epoch: 5| Step: 2
Training loss: 0.6215597987174988
Validation loss: 1.7801822039388842

Epoch: 5| Step: 3
Training loss: 0.3857906460762024
Validation loss: 1.7719542723830028

Epoch: 5| Step: 4
Training loss: 0.6298383474349976
Validation loss: 1.804998823391494

Epoch: 5| Step: 5
Training loss: 0.5216411352157593
Validation loss: 1.8116676884312783

Epoch: 5| Step: 6
Training loss: 0.46211957931518555
Validation loss: 1.7935618879974529

Epoch: 5| Step: 7
Training loss: 0.4477972090244293
Validation loss: 1.7748888948912263

Epoch: 5| Step: 8
Training loss: 0.7161968350410461
Validation loss: 1.7338349998638194

Epoch: 5| Step: 9
Training loss: 0.45600494742393494
Validation loss: 1.6995802502478323

Epoch: 5| Step: 10
Training loss: 0.48855191469192505
Validation loss: 1.7242516971403552

Epoch: 252| Step: 0
Training loss: 0.33045855164527893
Validation loss: 1.7304841113346878

Epoch: 5| Step: 1
Training loss: 0.38619038462638855
Validation loss: 1.7052261457648328

Epoch: 5| Step: 2
Training loss: 0.7810139656066895
Validation loss: 1.7340918279463244

Epoch: 5| Step: 3
Training loss: 0.48864802718162537
Validation loss: 1.7719001667473906

Epoch: 5| Step: 4
Training loss: 0.5829242467880249
Validation loss: 1.7957375523864583

Epoch: 5| Step: 5
Training loss: 0.6004875302314758
Validation loss: 1.7830478927140594

Epoch: 5| Step: 6
Training loss: 0.573933482170105
Validation loss: 1.78190234655975

Epoch: 5| Step: 7
Training loss: 0.6626202464103699
Validation loss: 1.7906250594764628

Epoch: 5| Step: 8
Training loss: 0.6985472440719604
Validation loss: 1.8122105201085408

Epoch: 5| Step: 9
Training loss: 0.5717662572860718
Validation loss: 1.8389947222125145

Epoch: 5| Step: 10
Training loss: 0.4623068571090698
Validation loss: 1.762259534610215

Epoch: 253| Step: 0
Training loss: 0.6666817665100098
Validation loss: 1.768531035351497

Epoch: 5| Step: 1
Training loss: 0.5324382781982422
Validation loss: 1.7757240277464672

Epoch: 5| Step: 2
Training loss: 0.2174120396375656
Validation loss: 1.7474617676068378

Epoch: 5| Step: 3
Training loss: 0.4920639991760254
Validation loss: 1.7843756957720684

Epoch: 5| Step: 4
Training loss: 0.642002284526825
Validation loss: 1.8036225200981222

Epoch: 5| Step: 5
Training loss: 0.4969029426574707
Validation loss: 1.8029322726752168

Epoch: 5| Step: 6
Training loss: 0.7736732959747314
Validation loss: 1.8389770728285595

Epoch: 5| Step: 7
Training loss: 0.5559039115905762
Validation loss: 1.805141883511697

Epoch: 5| Step: 8
Training loss: 0.2586649954319
Validation loss: 1.8226804656367148

Epoch: 5| Step: 9
Training loss: 0.5403052568435669
Validation loss: 1.7679422901522728

Epoch: 5| Step: 10
Training loss: 0.7491707801818848
Validation loss: 1.7542810106790194

Epoch: 254| Step: 0
Training loss: 0.5341852903366089
Validation loss: 1.7652543142277708

Epoch: 5| Step: 1
Training loss: 0.8728113174438477
Validation loss: 1.7494089641878683

Epoch: 5| Step: 2
Training loss: 0.9489367604255676
Validation loss: 1.7962346935784945

Epoch: 5| Step: 3
Training loss: 0.7013240456581116
Validation loss: 1.7525264627190047

Epoch: 5| Step: 4
Training loss: 0.38834530115127563
Validation loss: 1.7901241971600441

Epoch: 5| Step: 5
Training loss: 0.19090715050697327
Validation loss: 1.7432020684724212

Epoch: 5| Step: 6
Training loss: 0.4723799228668213
Validation loss: 1.749253071764464

Epoch: 5| Step: 7
Training loss: 0.41483020782470703
Validation loss: 1.716186758010618

Epoch: 5| Step: 8
Training loss: 0.41377443075180054
Validation loss: 1.7209054962281258

Epoch: 5| Step: 9
Training loss: 0.3991948962211609
Validation loss: 1.7530028909765265

Epoch: 5| Step: 10
Training loss: 0.5762479305267334
Validation loss: 1.7590212155413885

Epoch: 255| Step: 0
Training loss: 0.39981335401535034
Validation loss: 1.7667328234641784

Epoch: 5| Step: 1
Training loss: 0.37524670362472534
Validation loss: 1.7211095774045555

Epoch: 5| Step: 2
Training loss: 0.4774321913719177
Validation loss: 1.7461986323838592

Epoch: 5| Step: 3
Training loss: 0.6679529547691345
Validation loss: 1.6943885972422938

Epoch: 5| Step: 4
Training loss: 0.6215605139732361
Validation loss: 1.709500567887419

Epoch: 5| Step: 5
Training loss: 0.42746153473854065
Validation loss: 1.735138197099009

Epoch: 5| Step: 6
Training loss: 0.6464294195175171
Validation loss: 1.7587454485636886

Epoch: 5| Step: 7
Training loss: 0.4860667288303375
Validation loss: 1.75961636471492

Epoch: 5| Step: 8
Training loss: 0.6883688569068909
Validation loss: 1.7731890165677635

Epoch: 5| Step: 9
Training loss: 0.38045501708984375
Validation loss: 1.824390439577

Epoch: 5| Step: 10
Training loss: 0.6383883357048035
Validation loss: 1.7639664706363474

Epoch: 256| Step: 0
Training loss: 0.7462795376777649
Validation loss: 1.7049573224077943

Epoch: 5| Step: 1
Training loss: 0.5541266798973083
Validation loss: 1.742964357458135

Epoch: 5| Step: 2
Training loss: 0.46463146805763245
Validation loss: 1.724895667004329

Epoch: 5| Step: 3
Training loss: 0.5972528457641602
Validation loss: 1.742265562857351

Epoch: 5| Step: 4
Training loss: 0.29144182801246643
Validation loss: 1.7650174774149412

Epoch: 5| Step: 5
Training loss: 0.6326899528503418
Validation loss: 1.8019667517754339

Epoch: 5| Step: 6
Training loss: 0.36735087633132935
Validation loss: 1.7925859138529787

Epoch: 5| Step: 7
Training loss: 0.5818285942077637
Validation loss: 1.830850314068538

Epoch: 5| Step: 8
Training loss: 0.5365897417068481
Validation loss: 1.8038176631414762

Epoch: 5| Step: 9
Training loss: 0.47951093316078186
Validation loss: 1.8001161506099086

Epoch: 5| Step: 10
Training loss: 0.6201379299163818
Validation loss: 1.7565767521499305

Epoch: 257| Step: 0
Training loss: 0.35944420099258423
Validation loss: 1.7313529394006217

Epoch: 5| Step: 1
Training loss: 0.38310787081718445
Validation loss: 1.727082585775724

Epoch: 5| Step: 2
Training loss: 0.4894465506076813
Validation loss: 1.7188259901538971

Epoch: 5| Step: 3
Training loss: 0.46892014145851135
Validation loss: 1.7390932882985761

Epoch: 5| Step: 4
Training loss: 0.726101279258728
Validation loss: 1.733246672538019

Epoch: 5| Step: 5
Training loss: 0.39526572823524475
Validation loss: 1.7399922186328518

Epoch: 5| Step: 6
Training loss: 0.37259477376937866
Validation loss: 1.7931775175115114

Epoch: 5| Step: 7
Training loss: 0.6261829137802124
Validation loss: 1.7880736358704106

Epoch: 5| Step: 8
Training loss: 0.6947464942932129
Validation loss: 1.8464134277835969

Epoch: 5| Step: 9
Training loss: 0.636662483215332
Validation loss: 1.853921014775512

Epoch: 5| Step: 10
Training loss: 0.6737979650497437
Validation loss: 1.8405429624742078

Epoch: 258| Step: 0
Training loss: 0.6824458241462708
Validation loss: 1.8229243319521669

Epoch: 5| Step: 1
Training loss: 0.47275882959365845
Validation loss: 1.7699864731040051

Epoch: 5| Step: 2
Training loss: 0.5593643188476562
Validation loss: 1.7320723251629901

Epoch: 5| Step: 3
Training loss: 0.4289318025112152
Validation loss: 1.7510216530933176

Epoch: 5| Step: 4
Training loss: 0.5893823504447937
Validation loss: 1.7316514676617039

Epoch: 5| Step: 5
Training loss: 0.5257683396339417
Validation loss: 1.7764659133008731

Epoch: 5| Step: 6
Training loss: 0.42645955085754395
Validation loss: 1.7706597883214232

Epoch: 5| Step: 7
Training loss: 0.49524861574172974
Validation loss: 1.7597720174379246

Epoch: 5| Step: 8
Training loss: 0.6248579025268555
Validation loss: 1.8653051917270949

Epoch: 5| Step: 9
Training loss: 0.3568132817745209
Validation loss: 1.8094093953409502

Epoch: 5| Step: 10
Training loss: 0.5119063258171082
Validation loss: 1.8051205732489144

Epoch: 259| Step: 0
Training loss: 0.44822096824645996
Validation loss: 1.7979198681410922

Epoch: 5| Step: 1
Training loss: 0.7704121470451355
Validation loss: 1.796476238517351

Epoch: 5| Step: 2
Training loss: 0.4518671929836273
Validation loss: 1.792068568609094

Epoch: 5| Step: 3
Training loss: 0.42044854164123535
Validation loss: 1.7515535175159413

Epoch: 5| Step: 4
Training loss: 0.5774465799331665
Validation loss: 1.7368409031180925

Epoch: 5| Step: 5
Training loss: 0.4429500997066498
Validation loss: 1.7418238039939635

Epoch: 5| Step: 6
Training loss: 0.6490033268928528
Validation loss: 1.7727438595987135

Epoch: 5| Step: 7
Training loss: 0.40449148416519165
Validation loss: 1.7533667869465326

Epoch: 5| Step: 8
Training loss: 0.39108917117118835
Validation loss: 1.7596494831064695

Epoch: 5| Step: 9
Training loss: 0.4995848536491394
Validation loss: 1.8130290995361984

Epoch: 5| Step: 10
Training loss: 0.5303971171379089
Validation loss: 1.8135220953213271

Epoch: 260| Step: 0
Training loss: 0.6632018089294434
Validation loss: 1.7760188810286983

Epoch: 5| Step: 1
Training loss: 0.6744773387908936
Validation loss: 1.7753057633676836

Epoch: 5| Step: 2
Training loss: 0.3789420425891876
Validation loss: 1.7732959703732563

Epoch: 5| Step: 3
Training loss: 0.41376346349716187
Validation loss: 1.7491145415972638

Epoch: 5| Step: 4
Training loss: 0.6577087640762329
Validation loss: 1.7586009681865733

Epoch: 5| Step: 5
Training loss: 0.49150222539901733
Validation loss: 1.7741388018413256

Epoch: 5| Step: 6
Training loss: 0.24726399779319763
Validation loss: 1.7840316385351203

Epoch: 5| Step: 7
Training loss: 0.4683431088924408
Validation loss: 1.7786272046386555

Epoch: 5| Step: 8
Training loss: 0.4924567639827728
Validation loss: 1.7422906019354378

Epoch: 5| Step: 9
Training loss: 0.42398032546043396
Validation loss: 1.7717380818500315

Epoch: 5| Step: 10
Training loss: 0.6072658896446228
Validation loss: 1.7682838593759844

Epoch: 261| Step: 0
Training loss: 0.39889395236968994
Validation loss: 1.7776682389679777

Epoch: 5| Step: 1
Training loss: 0.4306538701057434
Validation loss: 1.7725685681066206

Epoch: 5| Step: 2
Training loss: 0.4194445013999939
Validation loss: 1.7655448862301406

Epoch: 5| Step: 3
Training loss: 0.6707721948623657
Validation loss: 1.753198109647279

Epoch: 5| Step: 4
Training loss: 0.38638097047805786
Validation loss: 1.7550821535048946

Epoch: 5| Step: 5
Training loss: 0.4687497615814209
Validation loss: 1.7808990440061014

Epoch: 5| Step: 6
Training loss: 0.49028724431991577
Validation loss: 1.7995033392342188

Epoch: 5| Step: 7
Training loss: 0.6810251474380493
Validation loss: 1.786876304175264

Epoch: 5| Step: 8
Training loss: 0.47359952330589294
Validation loss: 1.8507538200706564

Epoch: 5| Step: 9
Training loss: 0.6318696141242981
Validation loss: 1.7877572531341224

Epoch: 5| Step: 10
Training loss: 0.30298367142677307
Validation loss: 1.7830604994168846

Epoch: 262| Step: 0
Training loss: 0.6064056754112244
Validation loss: 1.7676240141673754

Epoch: 5| Step: 1
Training loss: 0.5076798796653748
Validation loss: 1.7807946025684316

Epoch: 5| Step: 2
Training loss: 0.429708868265152
Validation loss: 1.7584329189792756

Epoch: 5| Step: 3
Training loss: 0.5128454566001892
Validation loss: 1.724166359952701

Epoch: 5| Step: 4
Training loss: 0.4140617847442627
Validation loss: 1.7145354427317137

Epoch: 5| Step: 5
Training loss: 0.5376080274581909
Validation loss: 1.6931875674955306

Epoch: 5| Step: 6
Training loss: 0.43054699897766113
Validation loss: 1.6604564151456278

Epoch: 5| Step: 7
Training loss: 0.34462347626686096
Validation loss: 1.65001130360429

Epoch: 5| Step: 8
Training loss: 0.7040340304374695
Validation loss: 1.6705539277804795

Epoch: 5| Step: 9
Training loss: 0.379061758518219
Validation loss: 1.6198561768377981

Epoch: 5| Step: 10
Training loss: 0.3222154974937439
Validation loss: 1.669135529507873

Epoch: 263| Step: 0
Training loss: 0.36567753553390503
Validation loss: 1.70747201032536

Epoch: 5| Step: 1
Training loss: 0.8466261029243469
Validation loss: 1.722045708728093

Epoch: 5| Step: 2
Training loss: 0.4669530987739563
Validation loss: 1.7111842722021124

Epoch: 5| Step: 3
Training loss: 0.32719799876213074
Validation loss: 1.7382587027806107

Epoch: 5| Step: 4
Training loss: 0.3627840280532837
Validation loss: 1.7048322282811648

Epoch: 5| Step: 5
Training loss: 0.35237616300582886
Validation loss: 1.727435040217574

Epoch: 5| Step: 6
Training loss: 0.523546576499939
Validation loss: 1.7354955288671678

Epoch: 5| Step: 7
Training loss: 0.4401988089084625
Validation loss: 1.7604419415996921

Epoch: 5| Step: 8
Training loss: 0.33914560079574585
Validation loss: 1.7661377947817567

Epoch: 5| Step: 9
Training loss: 0.7499103546142578
Validation loss: 1.7289280993964082

Epoch: 5| Step: 10
Training loss: 0.36159011721611023
Validation loss: 1.7292187021624656

Epoch: 264| Step: 0
Training loss: 0.4477599561214447
Validation loss: 1.7785761971627512

Epoch: 5| Step: 1
Training loss: 0.5218713879585266
Validation loss: 1.785645140114651

Epoch: 5| Step: 2
Training loss: 0.24691149592399597
Validation loss: 1.7850064641685897

Epoch: 5| Step: 3
Training loss: 0.4446975290775299
Validation loss: 1.7614734019002607

Epoch: 5| Step: 4
Training loss: 0.4961943030357361
Validation loss: 1.7711873182686426

Epoch: 5| Step: 5
Training loss: 0.3512367308139801
Validation loss: 1.7321817067361647

Epoch: 5| Step: 6
Training loss: 0.4891880452632904
Validation loss: 1.7428622867471428

Epoch: 5| Step: 7
Training loss: 0.7136869430541992
Validation loss: 1.7115482437995173

Epoch: 5| Step: 8
Training loss: 0.43781137466430664
Validation loss: 1.6825915985209967

Epoch: 5| Step: 9
Training loss: 0.38131505250930786
Validation loss: 1.7107554827966998

Epoch: 5| Step: 10
Training loss: 0.6957650780677795
Validation loss: 1.6898181951174172

Epoch: 265| Step: 0
Training loss: 0.18607382476329803
Validation loss: 1.7081179593199043

Epoch: 5| Step: 1
Training loss: 0.35976606607437134
Validation loss: 1.7305670348546838

Epoch: 5| Step: 2
Training loss: 0.7363916039466858
Validation loss: 1.754322882621519

Epoch: 5| Step: 3
Training loss: 0.6226503849029541
Validation loss: 1.802324955181409

Epoch: 5| Step: 4
Training loss: 0.4265385568141937
Validation loss: 1.7568308281642135

Epoch: 5| Step: 5
Training loss: 0.1475057154893875
Validation loss: 1.7824927504344652

Epoch: 5| Step: 6
Training loss: 0.25797513127326965
Validation loss: 1.7632509719940923

Epoch: 5| Step: 7
Training loss: 0.24874965846538544
Validation loss: 1.7601131521245486

Epoch: 5| Step: 8
Training loss: 0.5063225030899048
Validation loss: 1.7179034256166028

Epoch: 5| Step: 9
Training loss: 0.717123806476593
Validation loss: 1.710502875748501

Epoch: 5| Step: 10
Training loss: 0.8613584041595459
Validation loss: 1.65514753454475

Epoch: 266| Step: 0
Training loss: 0.33736974000930786
Validation loss: 1.691914596865254

Epoch: 5| Step: 1
Training loss: 0.6152171492576599
Validation loss: 1.6859079125106975

Epoch: 5| Step: 2
Training loss: 0.5533853769302368
Validation loss: 1.6999524152407082

Epoch: 5| Step: 3
Training loss: 0.35757946968078613
Validation loss: 1.6957503781523755

Epoch: 5| Step: 4
Training loss: 0.4845094084739685
Validation loss: 1.6959590463228122

Epoch: 5| Step: 5
Training loss: 0.4809790551662445
Validation loss: 1.7495977596570087

Epoch: 5| Step: 6
Training loss: 0.5025392174720764
Validation loss: 1.752076401505419

Epoch: 5| Step: 7
Training loss: 0.3845823407173157
Validation loss: 1.8026270033210836

Epoch: 5| Step: 8
Training loss: 0.48628249764442444
Validation loss: 1.802382989596295

Epoch: 5| Step: 9
Training loss: 0.4246130883693695
Validation loss: 1.8255086586039553

Epoch: 5| Step: 10
Training loss: 0.4376216232776642
Validation loss: 1.8286232358665877

Epoch: 267| Step: 0
Training loss: 0.34671884775161743
Validation loss: 1.7646205322716826

Epoch: 5| Step: 1
Training loss: 0.44575056433677673
Validation loss: 1.780152964335616

Epoch: 5| Step: 2
Training loss: 0.5763180255889893
Validation loss: 1.7548686150581605

Epoch: 5| Step: 3
Training loss: 0.5195028781890869
Validation loss: 1.691866409394049

Epoch: 5| Step: 4
Training loss: 0.589114785194397
Validation loss: 1.6991164197203934

Epoch: 5| Step: 5
Training loss: 0.18404582142829895
Validation loss: 1.6517211365443405

Epoch: 5| Step: 6
Training loss: 0.5409834980964661
Validation loss: 1.634064280858604

Epoch: 5| Step: 7
Training loss: 0.28360888361930847
Validation loss: 1.6746495962142944

Epoch: 5| Step: 8
Training loss: 0.6024953126907349
Validation loss: 1.7060421871882614

Epoch: 5| Step: 9
Training loss: 0.432403564453125
Validation loss: 1.7299112696801462

Epoch: 5| Step: 10
Training loss: 0.4015878140926361
Validation loss: 1.7671559267146613

Epoch: 268| Step: 0
Training loss: 0.43625155091285706
Validation loss: 1.7867621260304605

Epoch: 5| Step: 1
Training loss: 0.6480712890625
Validation loss: 1.8107870599274993

Epoch: 5| Step: 2
Training loss: 0.2624428868293762
Validation loss: 1.7708057254873297

Epoch: 5| Step: 3
Training loss: 0.6052445769309998
Validation loss: 1.7537587509360364

Epoch: 5| Step: 4
Training loss: 0.2157127410173416
Validation loss: 1.7321215207858751

Epoch: 5| Step: 5
Training loss: 0.7144593000411987
Validation loss: 1.6980471200840448

Epoch: 5| Step: 6
Training loss: 0.5709446668624878
Validation loss: 1.6889193250286965

Epoch: 5| Step: 7
Training loss: 0.46585384011268616
Validation loss: 1.644487052835444

Epoch: 5| Step: 8
Training loss: 0.5760966539382935
Validation loss: 1.6737729823717507

Epoch: 5| Step: 9
Training loss: 0.4263645112514496
Validation loss: 1.6951577099420692

Epoch: 5| Step: 10
Training loss: 0.17775140702724457
Validation loss: 1.7076889109867874

Epoch: 269| Step: 0
Training loss: 0.431305468082428
Validation loss: 1.7111340440729612

Epoch: 5| Step: 1
Training loss: 0.12904128432273865
Validation loss: 1.723833821794038

Epoch: 5| Step: 2
Training loss: 0.5402434468269348
Validation loss: 1.7056396815084642

Epoch: 5| Step: 3
Training loss: 0.21918615698814392
Validation loss: 1.719453893682008

Epoch: 5| Step: 4
Training loss: 0.9009939432144165
Validation loss: 1.7094956354428363

Epoch: 5| Step: 5
Training loss: 0.4173119068145752
Validation loss: 1.6683922557420627

Epoch: 5| Step: 6
Training loss: 0.4660964906215668
Validation loss: 1.6803926139749505

Epoch: 5| Step: 7
Training loss: 0.40325289964675903
Validation loss: 1.6663524373885124

Epoch: 5| Step: 8
Training loss: 0.3905773162841797
Validation loss: 1.6712407783795429

Epoch: 5| Step: 9
Training loss: 0.2587573826313019
Validation loss: 1.6666153682175504

Epoch: 5| Step: 10
Training loss: 0.6471397280693054
Validation loss: 1.6808516966399325

Epoch: 270| Step: 0
Training loss: 0.2860882580280304
Validation loss: 1.729734291312515

Epoch: 5| Step: 1
Training loss: 0.3893345892429352
Validation loss: 1.8075614744617092

Epoch: 5| Step: 2
Training loss: 0.5621706247329712
Validation loss: 1.8317152736007527

Epoch: 5| Step: 3
Training loss: 0.4005783200263977
Validation loss: 1.7769206236767512

Epoch: 5| Step: 4
Training loss: 0.5200567841529846
Validation loss: 1.7823338380423925

Epoch: 5| Step: 5
Training loss: 0.528070330619812
Validation loss: 1.738706919454759

Epoch: 5| Step: 6
Training loss: 0.5358162522315979
Validation loss: 1.7075855193599578

Epoch: 5| Step: 7
Training loss: 0.4532749056816101
Validation loss: 1.6710847680286696

Epoch: 5| Step: 8
Training loss: 0.37963172793388367
Validation loss: 1.6522955650924354

Epoch: 5| Step: 9
Training loss: 0.47157707810401917
Validation loss: 1.646593984737191

Epoch: 5| Step: 10
Training loss: 0.38971003890037537
Validation loss: 1.6478544640284714

Epoch: 271| Step: 0
Training loss: 0.3251637816429138
Validation loss: 1.6653166752989574

Epoch: 5| Step: 1
Training loss: 0.7490586638450623
Validation loss: 1.6957301849959998

Epoch: 5| Step: 2
Training loss: 0.46318334341049194
Validation loss: 1.7255617034050725

Epoch: 5| Step: 3
Training loss: 0.6032795310020447
Validation loss: 1.7402547508157709

Epoch: 5| Step: 4
Training loss: 0.5698990821838379
Validation loss: 1.8099945181159562

Epoch: 5| Step: 5
Training loss: 0.24761204421520233
Validation loss: 1.8264301361576203

Epoch: 5| Step: 6
Training loss: 0.4163338243961334
Validation loss: 1.859377222676431

Epoch: 5| Step: 7
Training loss: 0.5356917381286621
Validation loss: 1.832843372898717

Epoch: 5| Step: 8
Training loss: 0.6439213752746582
Validation loss: 1.7930413215391097

Epoch: 5| Step: 9
Training loss: 0.1382143199443817
Validation loss: 1.7286732940263645

Epoch: 5| Step: 10
Training loss: 0.48505699634552
Validation loss: 1.6904713646058114

Epoch: 272| Step: 0
Training loss: 0.5357361435890198
Validation loss: 1.6701928877061414

Epoch: 5| Step: 1
Training loss: 0.5769244432449341
Validation loss: 1.6492952018655755

Epoch: 5| Step: 2
Training loss: 0.4511691629886627
Validation loss: 1.654993813524964

Epoch: 5| Step: 3
Training loss: 0.19362778961658478
Validation loss: 1.6681526066154562

Epoch: 5| Step: 4
Training loss: 0.4201239049434662
Validation loss: 1.7144939771262548

Epoch: 5| Step: 5
Training loss: 0.5400387644767761
Validation loss: 1.7386590293658677

Epoch: 5| Step: 6
Training loss: 0.303533136844635
Validation loss: 1.7280892325985817

Epoch: 5| Step: 7
Training loss: 0.4041768014431
Validation loss: 1.7623784548492842

Epoch: 5| Step: 8
Training loss: 0.5118425488471985
Validation loss: 1.7818189449207757

Epoch: 5| Step: 9
Training loss: 0.4833359718322754
Validation loss: 1.730376979356171

Epoch: 5| Step: 10
Training loss: 0.35193783044815063
Validation loss: 1.7244103531683646

Epoch: 273| Step: 0
Training loss: 0.21623392403125763
Validation loss: 1.6664138070998653

Epoch: 5| Step: 1
Training loss: 0.5427985787391663
Validation loss: 1.6698055036606327

Epoch: 5| Step: 2
Training loss: 0.21366015076637268
Validation loss: 1.6705380614085863

Epoch: 5| Step: 3
Training loss: 0.4660658836364746
Validation loss: 1.6528155508861746

Epoch: 5| Step: 4
Training loss: 0.40038713812828064
Validation loss: 1.6738668064917288

Epoch: 5| Step: 5
Training loss: 0.40130534768104553
Validation loss: 1.669904903698993

Epoch: 5| Step: 6
Training loss: 0.48543524742126465
Validation loss: 1.6501830585541264

Epoch: 5| Step: 7
Training loss: 0.45665445923805237
Validation loss: 1.6774629572386384

Epoch: 5| Step: 8
Training loss: 0.5613195300102234
Validation loss: 1.6978147991241948

Epoch: 5| Step: 9
Training loss: 0.375296950340271
Validation loss: 1.7010285239065848

Epoch: 5| Step: 10
Training loss: 0.7891649603843689
Validation loss: 1.7156333641339374

Epoch: 274| Step: 0
Training loss: 0.40405839681625366
Validation loss: 1.7014462806845223

Epoch: 5| Step: 1
Training loss: 0.5533398389816284
Validation loss: 1.6920972895878617

Epoch: 5| Step: 2
Training loss: 0.2973645031452179
Validation loss: 1.67713394664949

Epoch: 5| Step: 3
Training loss: 0.6015459299087524
Validation loss: 1.6629293208481164

Epoch: 5| Step: 4
Training loss: 0.29403066635131836
Validation loss: 1.6616776886806692

Epoch: 5| Step: 5
Training loss: 0.4242163598537445
Validation loss: 1.6329167094281924

Epoch: 5| Step: 6
Training loss: 0.40447670221328735
Validation loss: 1.6481055803196405

Epoch: 5| Step: 7
Training loss: 0.3159247040748596
Validation loss: 1.6327448846191488

Epoch: 5| Step: 8
Training loss: 0.44325321912765503
Validation loss: 1.634818019405488

Epoch: 5| Step: 9
Training loss: 0.5287114977836609
Validation loss: 1.6451795485711866

Epoch: 5| Step: 10
Training loss: 0.4482632279396057
Validation loss: 1.6700052753571542

Epoch: 275| Step: 0
Training loss: 0.40613073110580444
Validation loss: 1.6567986844688334

Epoch: 5| Step: 1
Training loss: 0.49511975049972534
Validation loss: 1.7508394102896414

Epoch: 5| Step: 2
Training loss: 0.4825995862483978
Validation loss: 1.7481004038164694

Epoch: 5| Step: 3
Training loss: 0.348080575466156
Validation loss: 1.7593523533113542

Epoch: 5| Step: 4
Training loss: 0.3527241051197052
Validation loss: 1.7787232642532678

Epoch: 5| Step: 5
Training loss: 0.3079400360584259
Validation loss: 1.7546322557233995

Epoch: 5| Step: 6
Training loss: 0.3998000919818878
Validation loss: 1.7194145366709719

Epoch: 5| Step: 7
Training loss: 0.4567317068576813
Validation loss: 1.7229063639076807

Epoch: 5| Step: 8
Training loss: 0.27717915177345276
Validation loss: 1.6906635838170205

Epoch: 5| Step: 9
Training loss: 0.7399130463600159
Validation loss: 1.6830579003980082

Epoch: 5| Step: 10
Training loss: 0.47153186798095703
Validation loss: 1.673431364438867

Epoch: 276| Step: 0
Training loss: 0.2080046683549881
Validation loss: 1.6561477466296124

Epoch: 5| Step: 1
Training loss: 0.4254373610019684
Validation loss: 1.6792597796327324

Epoch: 5| Step: 2
Training loss: 0.3028549551963806
Validation loss: 1.656300038419744

Epoch: 5| Step: 3
Training loss: 0.3695824146270752
Validation loss: 1.6470305996556436

Epoch: 5| Step: 4
Training loss: 0.4944440424442291
Validation loss: 1.6982840145787885

Epoch: 5| Step: 5
Training loss: 0.32157784700393677
Validation loss: 1.719279158499933

Epoch: 5| Step: 6
Training loss: 0.5847939252853394
Validation loss: 1.7686383249939128

Epoch: 5| Step: 7
Training loss: 0.6152817606925964
Validation loss: 1.7768066634414017

Epoch: 5| Step: 8
Training loss: 0.4906136393547058
Validation loss: 1.8042484996139363

Epoch: 5| Step: 9
Training loss: 0.35196104645729065
Validation loss: 1.80936594804128

Epoch: 5| Step: 10
Training loss: 0.39486145973205566
Validation loss: 1.78816367349317

Epoch: 277| Step: 0
Training loss: 0.46845388412475586
Validation loss: 1.7696336546251852

Epoch: 5| Step: 1
Training loss: 0.5315335988998413
Validation loss: 1.7042053713593432

Epoch: 5| Step: 2
Training loss: 0.32698673009872437
Validation loss: 1.6877253670846262

Epoch: 5| Step: 3
Training loss: 0.4842957556247711
Validation loss: 1.6326656751735236

Epoch: 5| Step: 4
Training loss: 0.3070361018180847
Validation loss: 1.6437444379252772

Epoch: 5| Step: 5
Training loss: 0.5210898518562317
Validation loss: 1.6211293089774348

Epoch: 5| Step: 6
Training loss: 0.4622584283351898
Validation loss: 1.6527701603469027

Epoch: 5| Step: 7
Training loss: 0.6184033155441284
Validation loss: 1.6909909056079002

Epoch: 5| Step: 8
Training loss: 0.4416586756706238
Validation loss: 1.7516516895704373

Epoch: 5| Step: 9
Training loss: 0.5017157793045044
Validation loss: 1.7251033834231797

Epoch: 5| Step: 10
Training loss: 0.24482740461826324
Validation loss: 1.7285535373995382

Epoch: 278| Step: 0
Training loss: 0.44519272446632385
Validation loss: 1.7153055308967509

Epoch: 5| Step: 1
Training loss: 0.26917243003845215
Validation loss: 1.6811570762306132

Epoch: 5| Step: 2
Training loss: 0.658194363117218
Validation loss: 1.6614170164190314

Epoch: 5| Step: 3
Training loss: 0.56219083070755
Validation loss: 1.6044322547092233

Epoch: 5| Step: 4
Training loss: 0.46706604957580566
Validation loss: 1.681034682899393

Epoch: 5| Step: 5
Training loss: 0.522631824016571
Validation loss: 1.686799439050818

Epoch: 5| Step: 6
Training loss: 0.2017471343278885
Validation loss: 1.7040426218381493

Epoch: 5| Step: 7
Training loss: 0.4625253677368164
Validation loss: 1.740644379328656

Epoch: 5| Step: 8
Training loss: 0.34010186791419983
Validation loss: 1.7393714766348563

Epoch: 5| Step: 9
Training loss: 0.472072035074234
Validation loss: 1.752224600443276

Epoch: 5| Step: 10
Training loss: 0.16900266706943512
Validation loss: 1.7597132062399259

Epoch: 279| Step: 0
Training loss: 0.5426028966903687
Validation loss: 1.7221009667201708

Epoch: 5| Step: 1
Training loss: 0.38846972584724426
Validation loss: 1.725725523887142

Epoch: 5| Step: 2
Training loss: 0.2327890694141388
Validation loss: 1.7125314153650755

Epoch: 5| Step: 3
Training loss: 0.4861554205417633
Validation loss: 1.734051364724354

Epoch: 5| Step: 4
Training loss: 0.40658465027809143
Validation loss: 1.7430648919074767

Epoch: 5| Step: 5
Training loss: 0.39565756916999817
Validation loss: 1.7185572270424134

Epoch: 5| Step: 6
Training loss: 0.37101781368255615
Validation loss: 1.7011022093475505

Epoch: 5| Step: 7
Training loss: 0.524420440196991
Validation loss: 1.7329361361842002

Epoch: 5| Step: 8
Training loss: 0.24586300551891327
Validation loss: 1.7218288272939704

Epoch: 5| Step: 9
Training loss: 0.7015398740768433
Validation loss: 1.6902968575877528

Epoch: 5| Step: 10
Training loss: 0.42866575717926025
Validation loss: 1.7231038142276067

Epoch: 280| Step: 0
Training loss: 0.26371318101882935
Validation loss: 1.7115301560330134

Epoch: 5| Step: 1
Training loss: 0.6849934458732605
Validation loss: 1.771084100969376

Epoch: 5| Step: 2
Training loss: 0.4096664488315582
Validation loss: 1.7649645830995293

Epoch: 5| Step: 3
Training loss: 0.3652059733867645
Validation loss: 1.7970288915018882

Epoch: 5| Step: 4
Training loss: 0.3789976239204407
Validation loss: 1.7580036399185017

Epoch: 5| Step: 5
Training loss: 0.4462631344795227
Validation loss: 1.7438031678558679

Epoch: 5| Step: 6
Training loss: 0.3132154047489166
Validation loss: 1.6926370692509476

Epoch: 5| Step: 7
Training loss: 0.34072184562683105
Validation loss: 1.6564466325185632

Epoch: 5| Step: 8
Training loss: 0.3623497486114502
Validation loss: 1.6349270215598486

Epoch: 5| Step: 9
Training loss: 0.3909991383552551
Validation loss: 1.6635553862458916

Epoch: 5| Step: 10
Training loss: 0.5371724367141724
Validation loss: 1.674082527878464

Epoch: 281| Step: 0
Training loss: 0.37168413400650024
Validation loss: 1.6382292534715386

Epoch: 5| Step: 1
Training loss: 0.6253079175949097
Validation loss: 1.7136454812942012

Epoch: 5| Step: 2
Training loss: 0.36027026176452637
Validation loss: 1.7156552883886522

Epoch: 5| Step: 3
Training loss: 0.3257383704185486
Validation loss: 1.706321268953303

Epoch: 5| Step: 4
Training loss: 0.47129756212234497
Validation loss: 1.7823359927823466

Epoch: 5| Step: 5
Training loss: 0.496192991733551
Validation loss: 1.7579216918637675

Epoch: 5| Step: 6
Training loss: 0.2900449335575104
Validation loss: 1.7719656600747058

Epoch: 5| Step: 7
Training loss: 0.5327333211898804
Validation loss: 1.707268311131385

Epoch: 5| Step: 8
Training loss: 0.6208731532096863
Validation loss: 1.690729437335845

Epoch: 5| Step: 9
Training loss: 0.30815809965133667
Validation loss: 1.6529635396054996

Epoch: 5| Step: 10
Training loss: 0.3735401928424835
Validation loss: 1.6883060791159188

Epoch: 282| Step: 0
Training loss: 0.49025288224220276
Validation loss: 1.6792716890253045

Epoch: 5| Step: 1
Training loss: 0.4504915177822113
Validation loss: 1.698872794387161

Epoch: 5| Step: 2
Training loss: 0.35710984468460083
Validation loss: 1.693486439284458

Epoch: 5| Step: 3
Training loss: 0.4216430187225342
Validation loss: 1.7159366376938359

Epoch: 5| Step: 4
Training loss: 0.6677032709121704
Validation loss: 1.7214669976183163

Epoch: 5| Step: 5
Training loss: 0.3936634659767151
Validation loss: 1.7030609730751283

Epoch: 5| Step: 6
Training loss: 0.31537961959838867
Validation loss: 1.7093836312652917

Epoch: 5| Step: 7
Training loss: 0.3481244444847107
Validation loss: 1.7394188873229488

Epoch: 5| Step: 8
Training loss: 0.35032376646995544
Validation loss: 1.7524475871875722

Epoch: 5| Step: 9
Training loss: 0.3063134551048279
Validation loss: 1.8212811690504833

Epoch: 5| Step: 10
Training loss: 0.3527756333351135
Validation loss: 1.852847905569179

Epoch: 283| Step: 0
Training loss: 0.3019586205482483
Validation loss: 1.8663459016430763

Epoch: 5| Step: 1
Training loss: 0.3341572880744934
Validation loss: 1.8892935309358823

Epoch: 5| Step: 2
Training loss: 0.5426828265190125
Validation loss: 1.8541999824585453

Epoch: 5| Step: 3
Training loss: 0.4217516779899597
Validation loss: 1.7979233085468251

Epoch: 5| Step: 4
Training loss: 0.4228678345680237
Validation loss: 1.7341594426862654

Epoch: 5| Step: 5
Training loss: 0.5362052917480469
Validation loss: 1.72515780438659

Epoch: 5| Step: 6
Training loss: 0.40492504835128784
Validation loss: 1.7085514376240392

Epoch: 5| Step: 7
Training loss: 0.31699639558792114
Validation loss: 1.676012385276056

Epoch: 5| Step: 8
Training loss: 0.4465336799621582
Validation loss: 1.6883567738276657

Epoch: 5| Step: 9
Training loss: 0.20001891255378723
Validation loss: 1.6711391851466189

Epoch: 5| Step: 10
Training loss: 0.8057072758674622
Validation loss: 1.6328513160828622

Epoch: 284| Step: 0
Training loss: 0.38095569610595703
Validation loss: 1.6352344776994439

Epoch: 5| Step: 1
Training loss: 0.5266788601875305
Validation loss: 1.6535864209616056

Epoch: 5| Step: 2
Training loss: 0.6575936079025269
Validation loss: 1.6334618368456442

Epoch: 5| Step: 3
Training loss: 0.26218926906585693
Validation loss: 1.647795013202134

Epoch: 5| Step: 4
Training loss: 0.331521213054657
Validation loss: 1.6645535897183161

Epoch: 5| Step: 5
Training loss: 0.2835272252559662
Validation loss: 1.6562160317615797

Epoch: 5| Step: 6
Training loss: 0.6719844937324524
Validation loss: 1.6882144174268168

Epoch: 5| Step: 7
Training loss: 0.3700573444366455
Validation loss: 1.683218199719665

Epoch: 5| Step: 8
Training loss: 0.3840112090110779
Validation loss: 1.693873506720348

Epoch: 5| Step: 9
Training loss: 0.3495066165924072
Validation loss: 1.7008479551602436

Epoch: 5| Step: 10
Training loss: 0.5546629428863525
Validation loss: 1.7374653572677283

Epoch: 285| Step: 0
Training loss: 0.5928221344947815
Validation loss: 1.7343642173274871

Epoch: 5| Step: 1
Training loss: 0.3739699721336365
Validation loss: 1.7370441818750033

Epoch: 5| Step: 2
Training loss: 0.6188350319862366
Validation loss: 1.7050220120337702

Epoch: 5| Step: 3
Training loss: 0.23587611317634583
Validation loss: 1.7272033601678827

Epoch: 5| Step: 4
Training loss: 0.3588821291923523
Validation loss: 1.7400350057950584

Epoch: 5| Step: 5
Training loss: 0.17076370120048523
Validation loss: 1.706931746134194

Epoch: 5| Step: 6
Training loss: 0.6332911849021912
Validation loss: 1.638250748316447

Epoch: 5| Step: 7
Training loss: 0.2946539521217346
Validation loss: 1.6002245410796134

Epoch: 5| Step: 8
Training loss: 0.30855458974838257
Validation loss: 1.5827859050484114

Epoch: 5| Step: 9
Training loss: 0.27540677785873413
Validation loss: 1.6205269034190843

Epoch: 5| Step: 10
Training loss: 0.4285949468612671
Validation loss: 1.6253723457295408

Epoch: 286| Step: 0
Training loss: 0.42152610421180725
Validation loss: 1.6376548967053812

Epoch: 5| Step: 1
Training loss: 0.6947458982467651
Validation loss: 1.6224762175672798

Epoch: 5| Step: 2
Training loss: 0.25728267431259155
Validation loss: 1.6679334102138397

Epoch: 5| Step: 3
Training loss: 0.44426098465919495
Validation loss: 1.6488438460134691

Epoch: 5| Step: 4
Training loss: 0.37036868929862976
Validation loss: 1.653525749842326

Epoch: 5| Step: 5
Training loss: 0.2389184981584549
Validation loss: 1.6325695610815478

Epoch: 5| Step: 6
Training loss: 0.45148006081581116
Validation loss: 1.6092151493154547

Epoch: 5| Step: 7
Training loss: 0.4116983413696289
Validation loss: 1.6272633280805362

Epoch: 5| Step: 8
Training loss: 0.4528822898864746
Validation loss: 1.6692747800580916

Epoch: 5| Step: 9
Training loss: 0.43822336196899414
Validation loss: 1.683427732477906

Epoch: 5| Step: 10
Training loss: 0.30436062812805176
Validation loss: 1.6681955540052025

Epoch: 287| Step: 0
Training loss: 0.46390366554260254
Validation loss: 1.6708272464813725

Epoch: 5| Step: 1
Training loss: 0.4011022448539734
Validation loss: 1.7425830569318546

Epoch: 5| Step: 2
Training loss: 0.4184293746948242
Validation loss: 1.7163288426655594

Epoch: 5| Step: 3
Training loss: 0.5253382921218872
Validation loss: 1.7555200643436883

Epoch: 5| Step: 4
Training loss: 0.40147703886032104
Validation loss: 1.7097441175932526

Epoch: 5| Step: 5
Training loss: 0.35941463708877563
Validation loss: 1.7034932131408362

Epoch: 5| Step: 6
Training loss: 0.4662621021270752
Validation loss: 1.7567215299093595

Epoch: 5| Step: 7
Training loss: 0.3808574080467224
Validation loss: 1.716094675884452

Epoch: 5| Step: 8
Training loss: 0.23712995648384094
Validation loss: 1.7080009034884873

Epoch: 5| Step: 9
Training loss: 0.34996768832206726
Validation loss: 1.7167851450622722

Epoch: 5| Step: 10
Training loss: 0.1956687718629837
Validation loss: 1.693541012784486

Epoch: 288| Step: 0
Training loss: 0.2945699393749237
Validation loss: 1.6711155906800301

Epoch: 5| Step: 1
Training loss: 0.36576882004737854
Validation loss: 1.687755456534765

Epoch: 5| Step: 2
Training loss: 0.4803794324398041
Validation loss: 1.6970198410813526

Epoch: 5| Step: 3
Training loss: 0.23403076827526093
Validation loss: 1.7450163543865245

Epoch: 5| Step: 4
Training loss: 0.35313501954078674
Validation loss: 1.7299701039509108

Epoch: 5| Step: 5
Training loss: 0.39066198468208313
Validation loss: 1.7572573487476637

Epoch: 5| Step: 6
Training loss: 0.26969680190086365
Validation loss: 1.6981215002716228

Epoch: 5| Step: 7
Training loss: 0.20131579041481018
Validation loss: 1.73620956431153

Epoch: 5| Step: 8
Training loss: 0.579475998878479
Validation loss: 1.7299900029295234

Epoch: 5| Step: 9
Training loss: 0.33893436193466187
Validation loss: 1.7224782102851457

Epoch: 5| Step: 10
Training loss: 0.6868929862976074
Validation loss: 1.7454868452523344

Epoch: 289| Step: 0
Training loss: 0.42812490463256836
Validation loss: 1.7059274899062289

Epoch: 5| Step: 1
Training loss: 0.6005465984344482
Validation loss: 1.6969564986485306

Epoch: 5| Step: 2
Training loss: 0.31029197573661804
Validation loss: 1.6677550320984216

Epoch: 5| Step: 3
Training loss: 0.2983359396457672
Validation loss: 1.6650376153248612

Epoch: 5| Step: 4
Training loss: 0.4974890649318695
Validation loss: 1.661136991234236

Epoch: 5| Step: 5
Training loss: 0.22416570782661438
Validation loss: 1.6656180863739343

Epoch: 5| Step: 6
Training loss: 0.39925485849380493
Validation loss: 1.645410559510672

Epoch: 5| Step: 7
Training loss: 0.37996965646743774
Validation loss: 1.6933102018089705

Epoch: 5| Step: 8
Training loss: 0.3312143385410309
Validation loss: 1.6960125789847424

Epoch: 5| Step: 9
Training loss: 0.2474803924560547
Validation loss: 1.6900783610600296

Epoch: 5| Step: 10
Training loss: 0.3521631360054016
Validation loss: 1.7302055410159531

Epoch: 290| Step: 0
Training loss: 0.5939931869506836
Validation loss: 1.7472964486768168

Epoch: 5| Step: 1
Training loss: 0.3505067229270935
Validation loss: 1.7357018602791654

Epoch: 5| Step: 2
Training loss: 0.35829871892929077
Validation loss: 1.7100686437340193

Epoch: 5| Step: 3
Training loss: 0.32312461733818054
Validation loss: 1.7011501058455436

Epoch: 5| Step: 4
Training loss: 0.460160493850708
Validation loss: 1.6614947601031231

Epoch: 5| Step: 5
Training loss: 0.506144642829895
Validation loss: 1.6493474552708287

Epoch: 5| Step: 6
Training loss: 0.40475353598594666
Validation loss: 1.6800227677950295

Epoch: 5| Step: 7
Training loss: 0.39887183904647827
Validation loss: 1.6340355847471504

Epoch: 5| Step: 8
Training loss: 0.3523584008216858
Validation loss: 1.6491074113435642

Epoch: 5| Step: 9
Training loss: 0.30844032764434814
Validation loss: 1.6384488382647115

Epoch: 5| Step: 10
Training loss: 0.23104141652584076
Validation loss: 1.6459557061554284

Epoch: 291| Step: 0
Training loss: 0.35960617661476135
Validation loss: 1.6734896141995665

Epoch: 5| Step: 1
Training loss: 0.36438292264938354
Validation loss: 1.705681404759807

Epoch: 5| Step: 2
Training loss: 0.263702929019928
Validation loss: 1.732949156914988

Epoch: 5| Step: 3
Training loss: 0.5571245551109314
Validation loss: 1.7250944260627992

Epoch: 5| Step: 4
Training loss: 0.4294191002845764
Validation loss: 1.741338591421804

Epoch: 5| Step: 5
Training loss: 0.3879498541355133
Validation loss: 1.7006707986195881

Epoch: 5| Step: 6
Training loss: 0.2140098363161087
Validation loss: 1.6902988610729095

Epoch: 5| Step: 7
Training loss: 0.5109443068504333
Validation loss: 1.7222778886877081

Epoch: 5| Step: 8
Training loss: 0.2582095265388489
Validation loss: 1.7310407571895148

Epoch: 5| Step: 9
Training loss: 0.3334830105304718
Validation loss: 1.7454516067299792

Epoch: 5| Step: 10
Training loss: 0.49625086784362793
Validation loss: 1.6838171776904856

Epoch: 292| Step: 0
Training loss: 0.46716275811195374
Validation loss: 1.7180698123029483

Epoch: 5| Step: 1
Training loss: 0.486243337392807
Validation loss: 1.7169533429607269

Epoch: 5| Step: 2
Training loss: 0.25587067008018494
Validation loss: 1.6783465839201404

Epoch: 5| Step: 3
Training loss: 0.22557242214679718
Validation loss: 1.6441222070365824

Epoch: 5| Step: 4
Training loss: 0.30841168761253357
Validation loss: 1.6478500853302658

Epoch: 5| Step: 5
Training loss: 0.3704430162906647
Validation loss: 1.5821080810280257

Epoch: 5| Step: 6
Training loss: 0.4083728790283203
Validation loss: 1.5782694406406854

Epoch: 5| Step: 7
Training loss: 0.3518950343132019
Validation loss: 1.587915951205838

Epoch: 5| Step: 8
Training loss: 0.563474714756012
Validation loss: 1.5783543086821032

Epoch: 5| Step: 9
Training loss: 0.4471949636936188
Validation loss: 1.6355223463427635

Epoch: 5| Step: 10
Training loss: 0.32452157139778137
Validation loss: 1.5821582694207468

Epoch: 293| Step: 0
Training loss: 0.35225313901901245
Validation loss: 1.636493541861093

Epoch: 5| Step: 1
Training loss: 0.37836161255836487
Validation loss: 1.6593464330960346

Epoch: 5| Step: 2
Training loss: 0.2667006552219391
Validation loss: 1.6792394025351411

Epoch: 5| Step: 3
Training loss: 0.19884571433067322
Validation loss: 1.7095653369862547

Epoch: 5| Step: 4
Training loss: 0.44582700729370117
Validation loss: 1.7341451068078317

Epoch: 5| Step: 5
Training loss: 0.43313366174697876
Validation loss: 1.7383847044360252

Epoch: 5| Step: 6
Training loss: 0.37396830320358276
Validation loss: 1.7261603968117827

Epoch: 5| Step: 7
Training loss: 0.36622464656829834
Validation loss: 1.698852704417321

Epoch: 5| Step: 8
Training loss: 0.32010507583618164
Validation loss: 1.7109125711584603

Epoch: 5| Step: 9
Training loss: 0.42228516936302185
Validation loss: 1.6998565812264719

Epoch: 5| Step: 10
Training loss: 0.42895761132240295
Validation loss: 1.632600090836966

Epoch: 294| Step: 0
Training loss: 0.42193907499313354
Validation loss: 1.6337469726480462

Epoch: 5| Step: 1
Training loss: 0.15707774460315704
Validation loss: 1.6592618380823443

Epoch: 5| Step: 2
Training loss: 0.39218950271606445
Validation loss: 1.6854033021516697

Epoch: 5| Step: 3
Training loss: 0.496123731136322
Validation loss: 1.7118459106773458

Epoch: 5| Step: 4
Training loss: 0.44430655241012573
Validation loss: 1.7591389122829642

Epoch: 5| Step: 5
Training loss: 0.4090563654899597
Validation loss: 1.7848077499738304

Epoch: 5| Step: 6
Training loss: 0.39876124262809753
Validation loss: 1.798902960233791

Epoch: 5| Step: 7
Training loss: 0.37600940465927124
Validation loss: 1.746111225056392

Epoch: 5| Step: 8
Training loss: 0.3349902033805847
Validation loss: 1.7653726364976616

Epoch: 5| Step: 9
Training loss: 0.36187171936035156
Validation loss: 1.7436219505084458

Epoch: 5| Step: 10
Training loss: 0.28066518902778625
Validation loss: 1.7103948695685274

Epoch: 295| Step: 0
Training loss: 0.32963672280311584
Validation loss: 1.6686339916721467

Epoch: 5| Step: 1
Training loss: 0.37944352626800537
Validation loss: 1.6457719649038007

Epoch: 5| Step: 2
Training loss: 0.22085443139076233
Validation loss: 1.6390794528427945

Epoch: 5| Step: 3
Training loss: 0.4463140070438385
Validation loss: 1.6561314700752177

Epoch: 5| Step: 4
Training loss: 0.329048216342926
Validation loss: 1.614237234156619

Epoch: 5| Step: 5
Training loss: 0.36533644795417786
Validation loss: 1.6224233014609224

Epoch: 5| Step: 6
Training loss: 0.43664103746414185
Validation loss: 1.6412405570348103

Epoch: 5| Step: 7
Training loss: 0.4207451343536377
Validation loss: 1.6475227379029798

Epoch: 5| Step: 8
Training loss: 0.31984013319015503
Validation loss: 1.6219377594609414

Epoch: 5| Step: 9
Training loss: 0.3090333044528961
Validation loss: 1.6267495437334942

Epoch: 5| Step: 10
Training loss: 0.2981286346912384
Validation loss: 1.6145083455629246

Epoch: 296| Step: 0
Training loss: 0.4303723871707916
Validation loss: 1.636273722494802

Epoch: 5| Step: 1
Training loss: 0.29510247707366943
Validation loss: 1.6320496079742268

Epoch: 5| Step: 2
Training loss: 0.38735419511795044
Validation loss: 1.646969315826252

Epoch: 5| Step: 3
Training loss: 0.2524365186691284
Validation loss: 1.7080970656487249

Epoch: 5| Step: 4
Training loss: 0.321137011051178
Validation loss: 1.6867008888593285

Epoch: 5| Step: 5
Training loss: 0.2760523557662964
Validation loss: 1.667758439176826

Epoch: 5| Step: 6
Training loss: 0.3143818974494934
Validation loss: 1.6244041048070437

Epoch: 5| Step: 7
Training loss: 0.3319639265537262
Validation loss: 1.6290626788652072

Epoch: 5| Step: 8
Training loss: 0.33613231778144836
Validation loss: 1.6253128577304143

Epoch: 5| Step: 9
Training loss: 0.4325699210166931
Validation loss: 1.6397077857807119

Epoch: 5| Step: 10
Training loss: 0.33835741877555847
Validation loss: 1.6197069024526944

Epoch: 297| Step: 0
Training loss: 0.3621641993522644
Validation loss: 1.6191048314494472

Epoch: 5| Step: 1
Training loss: 0.4284214377403259
Validation loss: 1.6406451681608796

Epoch: 5| Step: 2
Training loss: 0.23175060749053955
Validation loss: 1.610985211146775

Epoch: 5| Step: 3
Training loss: 0.39910173416137695
Validation loss: 1.6455603978967155

Epoch: 5| Step: 4
Training loss: 0.3854757845401764
Validation loss: 1.66381480937363

Epoch: 5| Step: 5
Training loss: 0.2715345025062561
Validation loss: 1.6434538748956495

Epoch: 5| Step: 6
Training loss: 0.3937610983848572
Validation loss: 1.6658503317063855

Epoch: 5| Step: 7
Training loss: 0.31803303956985474
Validation loss: 1.6582930370043683

Epoch: 5| Step: 8
Training loss: 0.2039407193660736
Validation loss: 1.6761484274300196

Epoch: 5| Step: 9
Training loss: 0.49385419487953186
Validation loss: 1.6526496653915734

Epoch: 5| Step: 10
Training loss: 0.15277957916259766
Validation loss: 1.6650403430384975

Epoch: 298| Step: 0
Training loss: 0.4164883494377136
Validation loss: 1.64521163253374

Epoch: 5| Step: 1
Training loss: 0.43494749069213867
Validation loss: 1.6438098235796856

Epoch: 5| Step: 2
Training loss: 0.22872500121593475
Validation loss: 1.6096011669405046

Epoch: 5| Step: 3
Training loss: 0.4012506604194641
Validation loss: 1.5946752108553404

Epoch: 5| Step: 4
Training loss: 0.2739480435848236
Validation loss: 1.6237834692001343

Epoch: 5| Step: 5
Training loss: 0.217572882771492
Validation loss: 1.604571403995637

Epoch: 5| Step: 6
Training loss: 0.2967202067375183
Validation loss: 1.6078157501835977

Epoch: 5| Step: 7
Training loss: 0.44478359818458557
Validation loss: 1.6437959504383866

Epoch: 5| Step: 8
Training loss: 0.3046891987323761
Validation loss: 1.6628720068162488

Epoch: 5| Step: 9
Training loss: 0.4127199649810791
Validation loss: 1.6756525860037854

Epoch: 5| Step: 10
Training loss: 0.4101613759994507
Validation loss: 1.7300710498645742

Epoch: 299| Step: 0
Training loss: 0.36280903220176697
Validation loss: 1.7853619590882333

Epoch: 5| Step: 1
Training loss: 0.5462533831596375
Validation loss: 1.7676313923251243

Epoch: 5| Step: 2
Training loss: 0.25942105054855347
Validation loss: 1.7272285787008141

Epoch: 5| Step: 3
Training loss: 0.2776428759098053
Validation loss: 1.721176403825001

Epoch: 5| Step: 4
Training loss: 0.5696504712104797
Validation loss: 1.689887559542092

Epoch: 5| Step: 5
Training loss: 0.26173633337020874
Validation loss: 1.6539080476248136

Epoch: 5| Step: 6
Training loss: 0.4748836159706116
Validation loss: 1.6041359619427753

Epoch: 5| Step: 7
Training loss: 0.5183508396148682
Validation loss: 1.5683608132023965

Epoch: 5| Step: 8
Training loss: 0.2076277732849121
Validation loss: 1.58495335296918

Epoch: 5| Step: 9
Training loss: 0.3276931643486023
Validation loss: 1.5754633975285355

Epoch: 5| Step: 10
Training loss: 0.2214563935995102
Validation loss: 1.6244782132487143

Epoch: 300| Step: 0
Training loss: 0.2899346649646759
Validation loss: 1.6202681602970246

Epoch: 5| Step: 1
Training loss: 0.44181594252586365
Validation loss: 1.6495991868357505

Epoch: 5| Step: 2
Training loss: 0.27502644062042236
Validation loss: 1.6570687858007287

Epoch: 5| Step: 3
Training loss: 0.39191529154777527
Validation loss: 1.695560747577298

Epoch: 5| Step: 4
Training loss: 0.37496820092201233
Validation loss: 1.6847194087120794

Epoch: 5| Step: 5
Training loss: 0.3052000105381012
Validation loss: 1.6780197620391846

Epoch: 5| Step: 6
Training loss: 0.4172326922416687
Validation loss: 1.678337190740852

Epoch: 5| Step: 7
Training loss: 0.26403823494911194
Validation loss: 1.6506424411650626

Epoch: 5| Step: 8
Training loss: 0.5172920227050781
Validation loss: 1.6262453550933509

Epoch: 5| Step: 9
Training loss: 0.2882041931152344
Validation loss: 1.6374823342087448

Epoch: 5| Step: 10
Training loss: 0.2933294177055359
Validation loss: 1.5946967486412293

Testing loss: 2.0446757475535073
