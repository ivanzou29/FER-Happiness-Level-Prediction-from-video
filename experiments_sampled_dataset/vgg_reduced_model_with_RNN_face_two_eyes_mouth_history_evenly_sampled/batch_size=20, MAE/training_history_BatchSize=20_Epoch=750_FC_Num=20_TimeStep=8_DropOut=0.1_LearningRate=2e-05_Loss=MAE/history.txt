Epoch: 1| Step: 0
Training loss: 5.494088649749756
Validation loss: 5.176839515727053

Epoch: 5| Step: 1
Training loss: 4.940980911254883
Validation loss: 5.15057558654457

Epoch: 5| Step: 2
Training loss: 5.037134170532227
Validation loss: 5.125961657493345

Epoch: 5| Step: 3
Training loss: 4.708892822265625
Validation loss: 5.099899927775065

Epoch: 5| Step: 4
Training loss: 6.117987632751465
Validation loss: 5.070496369433659

Epoch: 5| Step: 5
Training loss: 5.710866451263428
Validation loss: 5.038237546079902

Epoch: 5| Step: 6
Training loss: 4.1516947746276855
Validation loss: 5.003393988455495

Epoch: 5| Step: 7
Training loss: 3.1719908714294434
Validation loss: 4.962522875878118

Epoch: 5| Step: 8
Training loss: 4.337642669677734
Validation loss: 4.919144112576721

Epoch: 5| Step: 9
Training loss: 4.725250720977783
Validation loss: 4.868677241827852

Epoch: 5| Step: 10
Training loss: 4.5576629638671875
Validation loss: 4.8145044798492105

Epoch: 2| Step: 0
Training loss: 4.814196586608887
Validation loss: 4.756428426311862

Epoch: 5| Step: 1
Training loss: 4.467411041259766
Validation loss: 4.694070005929598

Epoch: 5| Step: 2
Training loss: 4.9504594802856445
Validation loss: 4.629422318550848

Epoch: 5| Step: 3
Training loss: 5.166057586669922
Validation loss: 4.5616635455880115

Epoch: 5| Step: 4
Training loss: 3.8009753227233887
Validation loss: 4.490285088939052

Epoch: 5| Step: 5
Training loss: 4.310977458953857
Validation loss: 4.4179437570674445

Epoch: 5| Step: 6
Training loss: 3.4898459911346436
Validation loss: 4.348644420664797

Epoch: 5| Step: 7
Training loss: 4.5915141105651855
Validation loss: 4.283826097365348

Epoch: 5| Step: 8
Training loss: 3.809504985809326
Validation loss: 4.22199805577596

Epoch: 5| Step: 9
Training loss: 3.45347261428833
Validation loss: 4.164605232977098

Epoch: 5| Step: 10
Training loss: 3.637110948562622
Validation loss: 4.106228720757269

Epoch: 3| Step: 0
Training loss: 3.9751312732696533
Validation loss: 4.050730305333292

Epoch: 5| Step: 1
Training loss: 2.9044041633605957
Validation loss: 3.9930747580784622

Epoch: 5| Step: 2
Training loss: 3.8578553199768066
Validation loss: 3.935939299162998

Epoch: 5| Step: 3
Training loss: 4.47477912902832
Validation loss: 3.885436975827781

Epoch: 5| Step: 4
Training loss: 3.8823254108428955
Validation loss: 3.8387482499563568

Epoch: 5| Step: 5
Training loss: 3.9791646003723145
Validation loss: 3.796220992201118

Epoch: 5| Step: 6
Training loss: 4.177663326263428
Validation loss: 3.75816927161268

Epoch: 5| Step: 7
Training loss: 3.585606336593628
Validation loss: 3.7218177421118623

Epoch: 5| Step: 8
Training loss: 3.6038641929626465
Validation loss: 3.6933873238102084

Epoch: 5| Step: 9
Training loss: 3.3937084674835205
Validation loss: 3.664451247902327

Epoch: 5| Step: 10
Training loss: 2.8148460388183594
Validation loss: 3.636477598579981

Epoch: 4| Step: 0
Training loss: 3.524350643157959
Validation loss: 3.6089477667244534

Epoch: 5| Step: 1
Training loss: 3.5645594596862793
Validation loss: 3.586920271637619

Epoch: 5| Step: 2
Training loss: 3.8084194660186768
Validation loss: 3.5631411152501262

Epoch: 5| Step: 3
Training loss: 4.1323418617248535
Validation loss: 3.540516035531157

Epoch: 5| Step: 4
Training loss: 3.2357897758483887
Validation loss: 3.5167059411284742

Epoch: 5| Step: 5
Training loss: 3.2777187824249268
Validation loss: 3.485454761853782

Epoch: 5| Step: 6
Training loss: 2.847071886062622
Validation loss: 3.4571247485376175

Epoch: 5| Step: 7
Training loss: 2.601196765899658
Validation loss: 3.4334964316378356

Epoch: 5| Step: 8
Training loss: 3.173434019088745
Validation loss: 3.414948396785285

Epoch: 5| Step: 9
Training loss: 4.014388084411621
Validation loss: 3.39042483093918

Epoch: 5| Step: 10
Training loss: 3.5629849433898926
Validation loss: 3.363962270880258

Epoch: 5| Step: 0
Training loss: 4.215067386627197
Validation loss: 3.3438924204918647

Epoch: 5| Step: 1
Training loss: 3.3100273609161377
Validation loss: 3.3206982817701114

Epoch: 5| Step: 2
Training loss: 3.7832534313201904
Validation loss: 3.3059540974196566

Epoch: 5| Step: 3
Training loss: 3.4938290119171143
Validation loss: 3.291289144946683

Epoch: 5| Step: 4
Training loss: 4.968705177307129
Validation loss: 3.2764223621737574

Epoch: 5| Step: 5
Training loss: 3.3703274726867676
Validation loss: 3.2579221597281833

Epoch: 5| Step: 6
Training loss: 2.626460552215576
Validation loss: 3.2467652110643286

Epoch: 5| Step: 7
Training loss: 2.6280508041381836
Validation loss: 3.234723867908601

Epoch: 5| Step: 8
Training loss: 2.792008876800537
Validation loss: 3.2241760684597875

Epoch: 5| Step: 9
Training loss: 2.157362937927246
Validation loss: 3.2093831595554145

Epoch: 5| Step: 10
Training loss: 2.282540798187256
Validation loss: 3.199208149345972

Epoch: 6| Step: 0
Training loss: 3.107206106185913
Validation loss: 3.1834414953826577

Epoch: 5| Step: 1
Training loss: 3.795436143875122
Validation loss: 3.1660614808400473

Epoch: 5| Step: 2
Training loss: 2.589459180831909
Validation loss: 3.152136469400057

Epoch: 5| Step: 3
Training loss: 3.3987278938293457
Validation loss: 3.1545727252960205

Epoch: 5| Step: 4
Training loss: 2.7480366230010986
Validation loss: 3.1524627439437376

Epoch: 5| Step: 5
Training loss: 2.855226993560791
Validation loss: 3.1177592687709357

Epoch: 5| Step: 6
Training loss: 3.834073543548584
Validation loss: 3.1072623601523777

Epoch: 5| Step: 7
Training loss: 4.004846572875977
Validation loss: 3.108128506650207

Epoch: 5| Step: 8
Training loss: 2.710391044616699
Validation loss: 3.0907709777996106

Epoch: 5| Step: 9
Training loss: 2.167276382446289
Validation loss: 3.0746963511231127

Epoch: 5| Step: 10
Training loss: 3.4901859760284424
Validation loss: 3.0656515705970024

Epoch: 7| Step: 0
Training loss: 2.3724074363708496
Validation loss: 3.0621219629882486

Epoch: 5| Step: 1
Training loss: 3.196753978729248
Validation loss: 3.0579870234253588

Epoch: 5| Step: 2
Training loss: 2.955169439315796
Validation loss: 3.044688001755745

Epoch: 5| Step: 3
Training loss: 3.5880203247070312
Validation loss: 3.0396466485915647

Epoch: 5| Step: 4
Training loss: 2.9268994331359863
Validation loss: 3.0252900815779165

Epoch: 5| Step: 5
Training loss: 3.0268142223358154
Validation loss: 3.0175018361819688

Epoch: 5| Step: 6
Training loss: 3.5296528339385986
Validation loss: 3.0074823312861945

Epoch: 5| Step: 7
Training loss: 2.7804789543151855
Validation loss: 3.0001411412351873

Epoch: 5| Step: 8
Training loss: 3.0486435890197754
Validation loss: 2.992506016967117

Epoch: 5| Step: 9
Training loss: 3.104342222213745
Validation loss: 2.9894287816939817

Epoch: 5| Step: 10
Training loss: 3.308195114135742
Validation loss: 2.973427777649254

Epoch: 8| Step: 0
Training loss: 3.008070468902588
Validation loss: 2.9612648128181376

Epoch: 5| Step: 1
Training loss: 2.0408518314361572
Validation loss: 2.961371435913988

Epoch: 5| Step: 2
Training loss: 3.038299083709717
Validation loss: 2.955091976350354

Epoch: 5| Step: 3
Training loss: 2.88958477973938
Validation loss: 2.9473387810491745

Epoch: 5| Step: 4
Training loss: 2.9436488151550293
Validation loss: 2.9364663298412035

Epoch: 5| Step: 5
Training loss: 3.5334980487823486
Validation loss: 2.9314025294396187

Epoch: 5| Step: 6
Training loss: 2.6439807415008545
Validation loss: 2.9205580090963714

Epoch: 5| Step: 7
Training loss: 2.810962438583374
Validation loss: 2.92022285410153

Epoch: 5| Step: 8
Training loss: 3.73628306388855
Validation loss: 2.921041137428694

Epoch: 5| Step: 9
Training loss: 2.6125917434692383
Validation loss: 2.911307229790636

Epoch: 5| Step: 10
Training loss: 4.024381637573242
Validation loss: 2.9023849348868094

Epoch: 9| Step: 0
Training loss: 3.449591875076294
Validation loss: 2.8876991425791094

Epoch: 5| Step: 1
Training loss: 3.564532518386841
Validation loss: 2.87901779144041

Epoch: 5| Step: 2
Training loss: 3.523646593093872
Validation loss: 2.8735525172243834

Epoch: 5| Step: 3
Training loss: 2.8137001991271973
Validation loss: 2.8678183914512716

Epoch: 5| Step: 4
Training loss: 2.5703539848327637
Validation loss: 2.865169758437782

Epoch: 5| Step: 5
Training loss: 3.3722565174102783
Validation loss: 2.8625690860133015

Epoch: 5| Step: 6
Training loss: 2.8270750045776367
Validation loss: 2.8662261193798435

Epoch: 5| Step: 7
Training loss: 3.1861090660095215
Validation loss: 2.8730880034867154

Epoch: 5| Step: 8
Training loss: 3.049755811691284
Validation loss: 2.8603593713493756

Epoch: 5| Step: 9
Training loss: 1.879159927368164
Validation loss: 2.8602537134642243

Epoch: 5| Step: 10
Training loss: 2.3587021827697754
Validation loss: 2.847896255472655

Epoch: 10| Step: 0
Training loss: 3.1103932857513428
Validation loss: 2.8296467386266237

Epoch: 5| Step: 1
Training loss: 3.869997501373291
Validation loss: 2.828313337859287

Epoch: 5| Step: 2
Training loss: 2.9580674171447754
Validation loss: 2.8230200377843713

Epoch: 5| Step: 3
Training loss: 2.8671913146972656
Validation loss: 2.8218751184401976

Epoch: 5| Step: 4
Training loss: 2.5921523571014404
Validation loss: 2.816789311747397

Epoch: 5| Step: 5
Training loss: 3.1816983222961426
Validation loss: 2.813219354998681

Epoch: 5| Step: 6
Training loss: 2.2442831993103027
Validation loss: 2.8106948432101997

Epoch: 5| Step: 7
Training loss: 2.3941550254821777
Validation loss: 2.811254027069256

Epoch: 5| Step: 8
Training loss: 2.934441089630127
Validation loss: 2.815539385682793

Epoch: 5| Step: 9
Training loss: 2.995016574859619
Validation loss: 2.80891018016364

Epoch: 5| Step: 10
Training loss: 3.2591350078582764
Validation loss: 2.805398787221601

Epoch: 11| Step: 0
Training loss: 2.6039977073669434
Validation loss: 2.797416676757156

Epoch: 5| Step: 1
Training loss: 2.255946397781372
Validation loss: 2.797698651590655

Epoch: 5| Step: 2
Training loss: 2.680213689804077
Validation loss: 2.786215836001981

Epoch: 5| Step: 3
Training loss: 3.0664515495300293
Validation loss: 2.7824904944307063

Epoch: 5| Step: 4
Training loss: 2.5498623847961426
Validation loss: 2.780214307128742

Epoch: 5| Step: 5
Training loss: 3.1583149433135986
Validation loss: 2.7764968359342186

Epoch: 5| Step: 6
Training loss: 3.701417922973633
Validation loss: 2.775297892990933

Epoch: 5| Step: 7
Training loss: 3.2383759021759033
Validation loss: 2.7683111672760337

Epoch: 5| Step: 8
Training loss: 2.5326972007751465
Validation loss: 2.7739557732817945

Epoch: 5| Step: 9
Training loss: 2.869105339050293
Validation loss: 2.7778779973265944

Epoch: 5| Step: 10
Training loss: 3.5257961750030518
Validation loss: 2.779056138889764

Epoch: 12| Step: 0
Training loss: 3.1450181007385254
Validation loss: 2.7706680067123903

Epoch: 5| Step: 1
Training loss: 2.8110711574554443
Validation loss: 2.7568642221471316

Epoch: 5| Step: 2
Training loss: 3.0999667644500732
Validation loss: 2.749587138493856

Epoch: 5| Step: 3
Training loss: 2.830111265182495
Validation loss: 2.7521584290330128

Epoch: 5| Step: 4
Training loss: 2.4784140586853027
Validation loss: 2.749428995193974

Epoch: 5| Step: 5
Training loss: 2.505481004714966
Validation loss: 2.7507851149446223

Epoch: 5| Step: 6
Training loss: 3.3162388801574707
Validation loss: 2.753831899294289

Epoch: 5| Step: 7
Training loss: 2.9819846153259277
Validation loss: 2.748232961982809

Epoch: 5| Step: 8
Training loss: 2.652830123901367
Validation loss: 2.758494584791122

Epoch: 5| Step: 9
Training loss: 2.981894016265869
Validation loss: 2.743795969152963

Epoch: 5| Step: 10
Training loss: 3.0813543796539307
Validation loss: 2.738033240841281

Epoch: 13| Step: 0
Training loss: 2.7943148612976074
Validation loss: 2.8099680715991604

Epoch: 5| Step: 1
Training loss: 3.270430088043213
Validation loss: 2.7967856648147746

Epoch: 5| Step: 2
Training loss: 2.4173521995544434
Validation loss: 2.7328634749176683

Epoch: 5| Step: 3
Training loss: 2.8426852226257324
Validation loss: 2.873798229361093

Epoch: 5| Step: 4
Training loss: 2.3076224327087402
Validation loss: 3.0464745054962816

Epoch: 5| Step: 5
Training loss: 3.4901223182678223
Validation loss: 3.0645036543569257

Epoch: 5| Step: 6
Training loss: 3.234083652496338
Validation loss: 3.0106842133306686

Epoch: 5| Step: 7
Training loss: 3.291125535964966
Validation loss: 2.9191175276233303

Epoch: 5| Step: 8
Training loss: 3.2764904499053955
Validation loss: 2.8043912815791305

Epoch: 5| Step: 9
Training loss: 2.796297550201416
Validation loss: 2.7916215978642946

Epoch: 5| Step: 10
Training loss: 3.4330332279205322
Validation loss: 2.8852418545753724

Epoch: 14| Step: 0
Training loss: 2.078612804412842
Validation loss: 2.931026017794045

Epoch: 5| Step: 1
Training loss: 2.631657361984253
Validation loss: 2.9064509022620415

Epoch: 5| Step: 2
Training loss: 3.1012706756591797
Validation loss: 2.857857314489221

Epoch: 5| Step: 3
Training loss: 3.49324369430542
Validation loss: 2.8361096843596427

Epoch: 5| Step: 4
Training loss: 2.873769998550415
Validation loss: 2.793855615841445

Epoch: 5| Step: 5
Training loss: 3.3109118938446045
Validation loss: 2.7428862433279715

Epoch: 5| Step: 6
Training loss: 3.0045254230499268
Validation loss: 2.7348040688422417

Epoch: 5| Step: 7
Training loss: 2.542149782180786
Validation loss: 2.7510966690637733

Epoch: 5| Step: 8
Training loss: 3.240435838699341
Validation loss: 2.7701341054772817

Epoch: 5| Step: 9
Training loss: 2.9607510566711426
Validation loss: 2.802919154526085

Epoch: 5| Step: 10
Training loss: 3.0073819160461426
Validation loss: 2.8210111433459866

Epoch: 15| Step: 0
Training loss: 2.8449594974517822
Validation loss: 2.8049547697908137

Epoch: 5| Step: 1
Training loss: 3.496755599975586
Validation loss: 2.7864116596919235

Epoch: 5| Step: 2
Training loss: 2.701472043991089
Validation loss: 2.7733888703007854

Epoch: 5| Step: 3
Training loss: 3.0151617527008057
Validation loss: 2.7666318596050306

Epoch: 5| Step: 4
Training loss: 2.858048915863037
Validation loss: 2.763268816855646

Epoch: 5| Step: 5
Training loss: 3.2683887481689453
Validation loss: 2.762757219294066

Epoch: 5| Step: 6
Training loss: 2.664750337600708
Validation loss: 2.765888116692984

Epoch: 5| Step: 7
Training loss: 3.4415619373321533
Validation loss: 2.7736472698949997

Epoch: 5| Step: 8
Training loss: 3.379287004470825
Validation loss: 2.771269513714698

Epoch: 5| Step: 9
Training loss: 2.0236873626708984
Validation loss: 2.7614650675045547

Epoch: 5| Step: 10
Training loss: 2.17453932762146
Validation loss: 2.754477805988763

Epoch: 16| Step: 0
Training loss: 2.895423650741577
Validation loss: 2.753516617641654

Epoch: 5| Step: 1
Training loss: 3.1443569660186768
Validation loss: 2.751851866322179

Epoch: 5| Step: 2
Training loss: 3.1527161598205566
Validation loss: 2.746301976583337

Epoch: 5| Step: 3
Training loss: 3.308884382247925
Validation loss: 2.741977440413608

Epoch: 5| Step: 4
Training loss: 2.2034833431243896
Validation loss: 2.738608714072935

Epoch: 5| Step: 5
Training loss: 3.4411635398864746
Validation loss: 2.738750455200031

Epoch: 5| Step: 6
Training loss: 1.9499889612197876
Validation loss: 2.7353128387082006

Epoch: 5| Step: 7
Training loss: 2.058133840560913
Validation loss: 2.7355397978136615

Epoch: 5| Step: 8
Training loss: 3.3514366149902344
Validation loss: 2.731301430732973

Epoch: 5| Step: 9
Training loss: 3.420318603515625
Validation loss: 2.73626095761535

Epoch: 5| Step: 10
Training loss: 2.86301326751709
Validation loss: 2.7288578351338706

Epoch: 17| Step: 0
Training loss: 3.1587812900543213
Validation loss: 2.7274370347299883

Epoch: 5| Step: 1
Training loss: 3.6041951179504395
Validation loss: 2.71824614719678

Epoch: 5| Step: 2
Training loss: 3.024519443511963
Validation loss: 2.7047944735455256

Epoch: 5| Step: 3
Training loss: 2.999584674835205
Validation loss: 2.676955851175452

Epoch: 5| Step: 4
Training loss: 2.7744240760803223
Validation loss: 2.677870865791075

Epoch: 5| Step: 5
Training loss: 3.077906608581543
Validation loss: 2.690196887139351

Epoch: 5| Step: 6
Training loss: 2.2730984687805176
Validation loss: 2.7086918712944112

Epoch: 5| Step: 7
Training loss: 2.6648547649383545
Validation loss: 2.7021939780122493

Epoch: 5| Step: 8
Training loss: 2.3542418479919434
Validation loss: 2.6761465636632775

Epoch: 5| Step: 9
Training loss: 2.4698293209075928
Validation loss: 2.6720825267094437

Epoch: 5| Step: 10
Training loss: 3.0544276237487793
Validation loss: 2.6674076049558577

Epoch: 18| Step: 0
Training loss: 3.7091689109802246
Validation loss: 2.6660777958490516

Epoch: 5| Step: 1
Training loss: 2.7104008197784424
Validation loss: 2.6642680783425607

Epoch: 5| Step: 2
Training loss: 2.493398666381836
Validation loss: 2.6612678727796

Epoch: 5| Step: 3
Training loss: 2.9745380878448486
Validation loss: 2.6630812844922467

Epoch: 5| Step: 4
Training loss: 2.778562068939209
Validation loss: 2.6610772814801944

Epoch: 5| Step: 5
Training loss: 2.693103313446045
Validation loss: 2.6607254756394254

Epoch: 5| Step: 6
Training loss: 2.844059705734253
Validation loss: 2.6601341052721907

Epoch: 5| Step: 7
Training loss: 2.694089889526367
Validation loss: 2.6531360354474796

Epoch: 5| Step: 8
Training loss: 2.7748332023620605
Validation loss: 2.6407067288634596

Epoch: 5| Step: 9
Training loss: 2.692841053009033
Validation loss: 2.6450577333409298

Epoch: 5| Step: 10
Training loss: 2.7596912384033203
Validation loss: 2.647165826571885

Epoch: 19| Step: 0
Training loss: 3.2301888465881348
Validation loss: 2.6460895076874764

Epoch: 5| Step: 1
Training loss: 2.984090805053711
Validation loss: 2.6448868295197845

Epoch: 5| Step: 2
Training loss: 3.1025304794311523
Validation loss: 2.642808183546989

Epoch: 5| Step: 3
Training loss: 2.6331591606140137
Validation loss: 2.639980564835251

Epoch: 5| Step: 4
Training loss: 2.205705404281616
Validation loss: 2.638312150073308

Epoch: 5| Step: 5
Training loss: 2.360844135284424
Validation loss: 2.6339757211746706

Epoch: 5| Step: 6
Training loss: 3.055410861968994
Validation loss: 2.636070918011409

Epoch: 5| Step: 7
Training loss: 3.027052640914917
Validation loss: 2.6395537237967215

Epoch: 5| Step: 8
Training loss: 3.222966432571411
Validation loss: 2.6374841069662445

Epoch: 5| Step: 9
Training loss: 2.543574810028076
Validation loss: 2.629971009428783

Epoch: 5| Step: 10
Training loss: 2.6035313606262207
Validation loss: 2.6200876030870663

Epoch: 20| Step: 0
Training loss: 3.4525413513183594
Validation loss: 2.619105795378326

Epoch: 5| Step: 1
Training loss: 2.4763100147247314
Validation loss: 2.6234742723485476

Epoch: 5| Step: 2
Training loss: 2.879425048828125
Validation loss: 2.6248400518971104

Epoch: 5| Step: 3
Training loss: 2.7615528106689453
Validation loss: 2.6285465122551046

Epoch: 5| Step: 4
Training loss: 2.9126827716827393
Validation loss: 2.629239495082568

Epoch: 5| Step: 5
Training loss: 2.548466205596924
Validation loss: 2.6246754072045766

Epoch: 5| Step: 6
Training loss: 2.854945421218872
Validation loss: 2.6249753223952426

Epoch: 5| Step: 7
Training loss: 3.761439561843872
Validation loss: 2.622057637860698

Epoch: 5| Step: 8
Training loss: 2.30359148979187
Validation loss: 2.6177954186675367

Epoch: 5| Step: 9
Training loss: 2.664107084274292
Validation loss: 2.6153200364881948

Epoch: 5| Step: 10
Training loss: 2.266937494277954
Validation loss: 2.6120243226328204

Epoch: 21| Step: 0
Training loss: 2.794980525970459
Validation loss: 2.61378248019885

Epoch: 5| Step: 1
Training loss: 2.8686764240264893
Validation loss: 2.618472981196578

Epoch: 5| Step: 2
Training loss: 3.1257147789001465
Validation loss: 2.6162070587117183

Epoch: 5| Step: 3
Training loss: 2.8671514987945557
Validation loss: 2.6121664175423245

Epoch: 5| Step: 4
Training loss: 3.5894222259521484
Validation loss: 2.6067314737586567

Epoch: 5| Step: 5
Training loss: 2.0347485542297363
Validation loss: 2.608483076095581

Epoch: 5| Step: 6
Training loss: 2.723846673965454
Validation loss: 2.6088286638259888

Epoch: 5| Step: 7
Training loss: 2.7297215461730957
Validation loss: 2.6066588842740623

Epoch: 5| Step: 8
Training loss: 3.254906177520752
Validation loss: 2.603185853650493

Epoch: 5| Step: 9
Training loss: 2.9418530464172363
Validation loss: 2.6038603167380057

Epoch: 5| Step: 10
Training loss: 1.637447714805603
Validation loss: 2.602862194020261

Epoch: 22| Step: 0
Training loss: 2.115201473236084
Validation loss: 2.601310673580375

Epoch: 5| Step: 1
Training loss: 3.3850371837615967
Validation loss: 2.604385050394202

Epoch: 5| Step: 2
Training loss: 2.774374008178711
Validation loss: 2.6104691900232786

Epoch: 5| Step: 3
Training loss: 2.2870373725891113
Validation loss: 2.6091338075617307

Epoch: 5| Step: 4
Training loss: 2.758942127227783
Validation loss: 2.607305275496616

Epoch: 5| Step: 5
Training loss: 3.0888731479644775
Validation loss: 2.6004844634763655

Epoch: 5| Step: 6
Training loss: 2.6447224617004395
Validation loss: 2.5983233733843734

Epoch: 5| Step: 7
Training loss: 2.4351918697357178
Validation loss: 2.5979717982712613

Epoch: 5| Step: 8
Training loss: 2.196655511856079
Validation loss: 2.5955860230230514

Epoch: 5| Step: 9
Training loss: 3.436920642852783
Validation loss: 2.593781440488754

Epoch: 5| Step: 10
Training loss: 3.6262972354888916
Validation loss: 2.5924054448322584

Epoch: 23| Step: 0
Training loss: 2.8402607440948486
Validation loss: 2.594121115182036

Epoch: 5| Step: 1
Training loss: 2.6092257499694824
Validation loss: 2.5945995725611204

Epoch: 5| Step: 2
Training loss: 2.8900630474090576
Validation loss: 2.5918227934068248

Epoch: 5| Step: 3
Training loss: 3.6191132068634033
Validation loss: 2.587054537188622

Epoch: 5| Step: 4
Training loss: 2.8605592250823975
Validation loss: 2.592189650381765

Epoch: 5| Step: 5
Training loss: 2.6838197708129883
Validation loss: 2.585115755757978

Epoch: 5| Step: 6
Training loss: 2.3625471591949463
Validation loss: 2.585360780838997

Epoch: 5| Step: 7
Training loss: 2.370035171508789
Validation loss: 2.582477028651904

Epoch: 5| Step: 8
Training loss: 2.7442822456359863
Validation loss: 2.5861979069248324

Epoch: 5| Step: 9
Training loss: 3.1149673461914062
Validation loss: 2.5829449879225863

Epoch: 5| Step: 10
Training loss: 2.4067935943603516
Validation loss: 2.5816005327368297

Epoch: 24| Step: 0
Training loss: 2.6383585929870605
Validation loss: 2.5796947466429843

Epoch: 5| Step: 1
Training loss: 3.208721160888672
Validation loss: 2.5759407269057406

Epoch: 5| Step: 2
Training loss: 2.9022717475891113
Validation loss: 2.577720267798311

Epoch: 5| Step: 3
Training loss: 2.697023868560791
Validation loss: 2.5791558988632692

Epoch: 5| Step: 4
Training loss: 2.7641475200653076
Validation loss: 2.5778193012360604

Epoch: 5| Step: 5
Training loss: 3.127558946609497
Validation loss: 2.575339481394778

Epoch: 5| Step: 6
Training loss: 3.4357070922851562
Validation loss: 2.5771118082026

Epoch: 5| Step: 7
Training loss: 2.7617294788360596
Validation loss: 2.576109581096198

Epoch: 5| Step: 8
Training loss: 2.308074712753296
Validation loss: 2.5804264904350362

Epoch: 5| Step: 9
Training loss: 2.232273578643799
Validation loss: 2.5761556112638084

Epoch: 5| Step: 10
Training loss: 2.2697737216949463
Validation loss: 2.5784251356637604

Epoch: 25| Step: 0
Training loss: 3.031959056854248
Validation loss: 2.5708070365331506

Epoch: 5| Step: 1
Training loss: 2.904430866241455
Validation loss: 2.5739534055033038

Epoch: 5| Step: 2
Training loss: 3.493116855621338
Validation loss: 2.594121471528084

Epoch: 5| Step: 3
Training loss: 2.6351311206817627
Validation loss: 2.600071625042987

Epoch: 5| Step: 4
Training loss: 1.954908013343811
Validation loss: 2.5743055933265278

Epoch: 5| Step: 5
Training loss: 2.4995193481445312
Validation loss: 2.5640790975222023

Epoch: 5| Step: 6
Training loss: 2.95857572555542
Validation loss: 2.5631902397319837

Epoch: 5| Step: 7
Training loss: 2.6189582347869873
Validation loss: 2.5682447366817023

Epoch: 5| Step: 8
Training loss: 2.7135605812072754
Validation loss: 2.565158433811639

Epoch: 5| Step: 9
Training loss: 3.050095558166504
Validation loss: 2.5644078280336116

Epoch: 5| Step: 10
Training loss: 2.5932939052581787
Validation loss: 2.5670598322345364

Epoch: 26| Step: 0
Training loss: 2.9413342475891113
Validation loss: 2.5650269395561627

Epoch: 5| Step: 1
Training loss: 2.627481460571289
Validation loss: 2.5666640907205562

Epoch: 5| Step: 2
Training loss: 3.0557351112365723
Validation loss: 2.558809293213711

Epoch: 5| Step: 3
Training loss: 3.260545015335083
Validation loss: 2.5620009386411278

Epoch: 5| Step: 4
Training loss: 3.568662166595459
Validation loss: 2.5624748942672566

Epoch: 5| Step: 5
Training loss: 2.5545220375061035
Validation loss: 2.562715873923353

Epoch: 5| Step: 6
Training loss: 2.4507250785827637
Validation loss: 2.55949761918796

Epoch: 5| Step: 7
Training loss: 2.7149853706359863
Validation loss: 2.5483525286438646

Epoch: 5| Step: 8
Training loss: 2.8671622276306152
Validation loss: 2.547797700410248

Epoch: 5| Step: 9
Training loss: 1.9601917266845703
Validation loss: 2.549241768416538

Epoch: 5| Step: 10
Training loss: 2.2816708087921143
Validation loss: 2.5474762608928065

Epoch: 27| Step: 0
Training loss: 2.938861131668091
Validation loss: 2.5507988250383766

Epoch: 5| Step: 1
Training loss: 3.169132947921753
Validation loss: 2.5534619003213863

Epoch: 5| Step: 2
Training loss: 2.901596784591675
Validation loss: 2.546992817232686

Epoch: 5| Step: 3
Training loss: 3.219259738922119
Validation loss: 2.5456120660228114

Epoch: 5| Step: 4
Training loss: 2.0719518661499023
Validation loss: 2.543664842523554

Epoch: 5| Step: 5
Training loss: 2.7533538341522217
Validation loss: 2.545748038958478

Epoch: 5| Step: 6
Training loss: 2.602386951446533
Validation loss: 2.540886104747813

Epoch: 5| Step: 7
Training loss: 2.608670711517334
Validation loss: 2.5407609055119176

Epoch: 5| Step: 8
Training loss: 2.813303232192993
Validation loss: 2.5448016633269606

Epoch: 5| Step: 9
Training loss: 2.1047587394714355
Validation loss: 2.5427153982141966

Epoch: 5| Step: 10
Training loss: 3.0643415451049805
Validation loss: 2.547382075299499

Epoch: 28| Step: 0
Training loss: 2.452094316482544
Validation loss: 2.5504257358530515

Epoch: 5| Step: 1
Training loss: 2.8344943523406982
Validation loss: 2.5495265581274547

Epoch: 5| Step: 2
Training loss: 2.558218002319336
Validation loss: 2.544226313150057

Epoch: 5| Step: 3
Training loss: 2.866036891937256
Validation loss: 2.538856408929312

Epoch: 5| Step: 4
Training loss: 2.4443118572235107
Validation loss: 2.5396812346673783

Epoch: 5| Step: 5
Training loss: 2.2770886421203613
Validation loss: 2.542916335085387

Epoch: 5| Step: 6
Training loss: 2.745722770690918
Validation loss: 2.542172844691943

Epoch: 5| Step: 7
Training loss: 3.108924388885498
Validation loss: 2.5567466494857625

Epoch: 5| Step: 8
Training loss: 3.202420711517334
Validation loss: 2.558496523928899

Epoch: 5| Step: 9
Training loss: 2.7502827644348145
Validation loss: 2.5535229764958864

Epoch: 5| Step: 10
Training loss: 2.8715105056762695
Validation loss: 2.5471397446047876

Epoch: 29| Step: 0
Training loss: 2.1736605167388916
Validation loss: 2.5402575077549105

Epoch: 5| Step: 1
Training loss: 2.462719440460205
Validation loss: 2.5358225120011197

Epoch: 5| Step: 2
Training loss: 2.5036919116973877
Validation loss: 2.5337329141555296

Epoch: 5| Step: 3
Training loss: 3.0867116451263428
Validation loss: 2.5499593314304145

Epoch: 5| Step: 4
Training loss: 2.668076276779175
Validation loss: 2.545100829934561

Epoch: 5| Step: 5
Training loss: 2.9948360919952393
Validation loss: 2.5445246081198416

Epoch: 5| Step: 6
Training loss: 2.3540873527526855
Validation loss: 2.539018302835444

Epoch: 5| Step: 7
Training loss: 3.0293655395507812
Validation loss: 2.535826744571809

Epoch: 5| Step: 8
Training loss: 3.2190074920654297
Validation loss: 2.536789668503628

Epoch: 5| Step: 9
Training loss: 3.0956075191497803
Validation loss: 2.5346565220945623

Epoch: 5| Step: 10
Training loss: 2.4624216556549072
Validation loss: 2.5344776927783923

Epoch: 30| Step: 0
Training loss: 2.661266326904297
Validation loss: 2.5348723319268998

Epoch: 5| Step: 1
Training loss: 2.484679698944092
Validation loss: 2.538444754897907

Epoch: 5| Step: 2
Training loss: 2.909214735031128
Validation loss: 2.535541001186576

Epoch: 5| Step: 3
Training loss: 2.7253220081329346
Validation loss: 2.5332831669879217

Epoch: 5| Step: 4
Training loss: 2.1902999877929688
Validation loss: 2.54440821883499

Epoch: 5| Step: 5
Training loss: 3.361173629760742
Validation loss: 2.540998856226603

Epoch: 5| Step: 6
Training loss: 2.3652281761169434
Validation loss: 2.5373319887345835

Epoch: 5| Step: 7
Training loss: 3.4106345176696777
Validation loss: 2.5379619213842575

Epoch: 5| Step: 8
Training loss: 2.5092694759368896
Validation loss: 2.5406689284950175

Epoch: 5| Step: 9
Training loss: 2.7133262157440186
Validation loss: 2.5398305308434272

Epoch: 5| Step: 10
Training loss: 2.6061275005340576
Validation loss: 2.5451653208783878

Epoch: 31| Step: 0
Training loss: 2.7309722900390625
Validation loss: 2.54712499085293

Epoch: 5| Step: 1
Training loss: 3.032498598098755
Validation loss: 2.5491661794724

Epoch: 5| Step: 2
Training loss: 3.0954153537750244
Validation loss: 2.5544425261917936

Epoch: 5| Step: 3
Training loss: 3.0449960231781006
Validation loss: 2.554588299925609

Epoch: 5| Step: 4
Training loss: 1.9967529773712158
Validation loss: 2.5617231527964273

Epoch: 5| Step: 5
Training loss: 2.317202091217041
Validation loss: 2.5523764164217058

Epoch: 5| Step: 6
Training loss: 2.5420424938201904
Validation loss: 2.561505030560237

Epoch: 5| Step: 7
Training loss: 2.4247024059295654
Validation loss: 2.541417080868957

Epoch: 5| Step: 8
Training loss: 2.9483482837677
Validation loss: 2.5283607103491343

Epoch: 5| Step: 9
Training loss: 3.049098491668701
Validation loss: 2.522523623640819

Epoch: 5| Step: 10
Training loss: 2.7159602642059326
Validation loss: 2.5258004434647097

Epoch: 32| Step: 0
Training loss: 2.35366153717041
Validation loss: 2.5265427430470786

Epoch: 5| Step: 1
Training loss: 2.2796874046325684
Validation loss: 2.54339333503477

Epoch: 5| Step: 2
Training loss: 2.992067813873291
Validation loss: 2.5565853400896956

Epoch: 5| Step: 3
Training loss: 2.7623088359832764
Validation loss: 2.545241025186354

Epoch: 5| Step: 4
Training loss: 2.5486741065979004
Validation loss: 2.5279079534674205

Epoch: 5| Step: 5
Training loss: 2.8824715614318848
Validation loss: 2.524701213323942

Epoch: 5| Step: 6
Training loss: 2.683842182159424
Validation loss: 2.514607178267612

Epoch: 5| Step: 7
Training loss: 2.7296841144561768
Validation loss: 2.5147859973292195

Epoch: 5| Step: 8
Training loss: 2.9742960929870605
Validation loss: 2.520806194633566

Epoch: 5| Step: 9
Training loss: 3.3426127433776855
Validation loss: 2.518468205646802

Epoch: 5| Step: 10
Training loss: 2.284036636352539
Validation loss: 2.5245650276061027

Epoch: 33| Step: 0
Training loss: 3.1779539585113525
Validation loss: 2.52039267939906

Epoch: 5| Step: 1
Training loss: 2.6586265563964844
Validation loss: 2.5192658157758814

Epoch: 5| Step: 2
Training loss: 2.844510555267334
Validation loss: 2.5117812310495684

Epoch: 5| Step: 3
Training loss: 2.783806085586548
Validation loss: 2.5127763158531597

Epoch: 5| Step: 4
Training loss: 2.3698251247406006
Validation loss: 2.5181814470598773

Epoch: 5| Step: 5
Training loss: 2.9744949340820312
Validation loss: 2.5272057953701226

Epoch: 5| Step: 6
Training loss: 1.8700708150863647
Validation loss: 2.538951163650841

Epoch: 5| Step: 7
Training loss: 2.55279803276062
Validation loss: 2.5276699322526173

Epoch: 5| Step: 8
Training loss: 2.866603136062622
Validation loss: 2.519647385484429

Epoch: 5| Step: 9
Training loss: 2.5863897800445557
Validation loss: 2.5067912993892545

Epoch: 5| Step: 10
Training loss: 3.2715048789978027
Validation loss: 2.507387327891524

Epoch: 34| Step: 0
Training loss: 3.2813003063201904
Validation loss: 2.5047659284325055

Epoch: 5| Step: 1
Training loss: 2.6699249744415283
Validation loss: 2.5008924058688584

Epoch: 5| Step: 2
Training loss: 2.7622241973876953
Validation loss: 2.4999979926693823

Epoch: 5| Step: 3
Training loss: 2.4665496349334717
Validation loss: 2.496162091532061

Epoch: 5| Step: 4
Training loss: 2.296701669692993
Validation loss: 2.499983802918465

Epoch: 5| Step: 5
Training loss: 2.7579503059387207
Validation loss: 2.499646181701332

Epoch: 5| Step: 6
Training loss: 3.1539382934570312
Validation loss: 2.501441030092137

Epoch: 5| Step: 7
Training loss: 2.225837230682373
Validation loss: 2.4989481228654102

Epoch: 5| Step: 8
Training loss: 2.5080533027648926
Validation loss: 2.500551208373039

Epoch: 5| Step: 9
Training loss: 3.0494964122772217
Validation loss: 2.4967890067767073

Epoch: 5| Step: 10
Training loss: 2.5070712566375732
Validation loss: 2.4986247708720546

Epoch: 35| Step: 0
Training loss: 3.262596607208252
Validation loss: 2.4997870768270185

Epoch: 5| Step: 1
Training loss: 2.911778211593628
Validation loss: 2.501261167628791

Epoch: 5| Step: 2
Training loss: 2.3309710025787354
Validation loss: 2.4945077178298787

Epoch: 5| Step: 3
Training loss: 2.882702350616455
Validation loss: 2.4963616760828162

Epoch: 5| Step: 4
Training loss: 2.666926860809326
Validation loss: 2.494994273749731

Epoch: 5| Step: 5
Training loss: 2.360661029815674
Validation loss: 2.4944846066095496

Epoch: 5| Step: 6
Training loss: 2.0346457958221436
Validation loss: 2.491875604916644

Epoch: 5| Step: 7
Training loss: 2.86051082611084
Validation loss: 2.487039468621695

Epoch: 5| Step: 8
Training loss: 2.385006904602051
Validation loss: 2.4954964063500844

Epoch: 5| Step: 9
Training loss: 2.699676036834717
Validation loss: 2.4959282464878534

Epoch: 5| Step: 10
Training loss: 3.2596912384033203
Validation loss: 2.4918521411957277

Epoch: 36| Step: 0
Training loss: 2.4530584812164307
Validation loss: 2.5002563820090344

Epoch: 5| Step: 1
Training loss: 2.5883736610412598
Validation loss: 2.5029086553922264

Epoch: 5| Step: 2
Training loss: 2.3253426551818848
Validation loss: 2.5273250226051576

Epoch: 5| Step: 3
Training loss: 2.836238384246826
Validation loss: 2.5520256232189875

Epoch: 5| Step: 4
Training loss: 3.2728333473205566
Validation loss: 2.531267886520714

Epoch: 5| Step: 5
Training loss: 2.9142260551452637
Validation loss: 2.500944483664728

Epoch: 5| Step: 6
Training loss: 2.971137762069702
Validation loss: 2.4924723922565417

Epoch: 5| Step: 7
Training loss: 2.4462013244628906
Validation loss: 2.490147354782269

Epoch: 5| Step: 8
Training loss: 2.7716822624206543
Validation loss: 2.4805597207879506

Epoch: 5| Step: 9
Training loss: 2.277167558670044
Validation loss: 2.4829746548847487

Epoch: 5| Step: 10
Training loss: 2.7418501377105713
Validation loss: 2.4822113975401847

Epoch: 37| Step: 0
Training loss: 2.793494701385498
Validation loss: 2.4822421330277638

Epoch: 5| Step: 1
Training loss: 2.8528010845184326
Validation loss: 2.488100033934398

Epoch: 5| Step: 2
Training loss: 2.297694683074951
Validation loss: 2.48698264809065

Epoch: 5| Step: 3
Training loss: 3.332120895385742
Validation loss: 2.491958292581702

Epoch: 5| Step: 4
Training loss: 2.665208578109741
Validation loss: 2.489160737683696

Epoch: 5| Step: 5
Training loss: 2.0778918266296387
Validation loss: 2.4806698368441675

Epoch: 5| Step: 6
Training loss: 2.8202133178710938
Validation loss: 2.477418291953302

Epoch: 5| Step: 7
Training loss: 2.5534756183624268
Validation loss: 2.4748384978181575

Epoch: 5| Step: 8
Training loss: 2.9936490058898926
Validation loss: 2.4783792521363948

Epoch: 5| Step: 9
Training loss: 2.336592197418213
Validation loss: 2.474873653022192

Epoch: 5| Step: 10
Training loss: 2.9841222763061523
Validation loss: 2.4790796438852944

Epoch: 38| Step: 0
Training loss: 2.566915988922119
Validation loss: 2.4841182411357923

Epoch: 5| Step: 1
Training loss: 2.4387643337249756
Validation loss: 2.4955750332083753

Epoch: 5| Step: 2
Training loss: 2.7502574920654297
Validation loss: 2.5014615776718303

Epoch: 5| Step: 3
Training loss: 1.9635099172592163
Validation loss: 2.506846753499841

Epoch: 5| Step: 4
Training loss: 3.0224671363830566
Validation loss: 2.523912460573258

Epoch: 5| Step: 5
Training loss: 3.2764194011688232
Validation loss: 2.6007304076225526

Epoch: 5| Step: 6
Training loss: 2.9819860458374023
Validation loss: 2.671081833941962

Epoch: 5| Step: 7
Training loss: 3.002393960952759
Validation loss: 2.69678694458418

Epoch: 5| Step: 8
Training loss: 2.647307872772217
Validation loss: 2.565652306361865

Epoch: 5| Step: 9
Training loss: 2.892159938812256
Validation loss: 2.4909911796610844

Epoch: 5| Step: 10
Training loss: 2.6309399604797363
Validation loss: 2.467879431222075

Epoch: 39| Step: 0
Training loss: 2.924776315689087
Validation loss: 2.4755277890031055

Epoch: 5| Step: 1
Training loss: 2.452265501022339
Validation loss: 2.4928978463654876

Epoch: 5| Step: 2
Training loss: 2.4593796730041504
Validation loss: 2.5122045932277555

Epoch: 5| Step: 3
Training loss: 2.828352451324463
Validation loss: 2.522629835272348

Epoch: 5| Step: 4
Training loss: 2.934966564178467
Validation loss: 2.5213456141051425

Epoch: 5| Step: 5
Training loss: 2.5276026725769043
Validation loss: 2.5219987900026384

Epoch: 5| Step: 6
Training loss: 2.2931056022644043
Validation loss: 2.5270317882619877

Epoch: 5| Step: 7
Training loss: 3.257115125656128
Validation loss: 2.5276108992997037

Epoch: 5| Step: 8
Training loss: 2.7796685695648193
Validation loss: 2.5177959370356735

Epoch: 5| Step: 9
Training loss: 3.1057913303375244
Validation loss: 2.5062929379042758

Epoch: 5| Step: 10
Training loss: 2.648815393447876
Validation loss: 2.505090998065087

Epoch: 40| Step: 0
Training loss: 2.5231003761291504
Validation loss: 2.495563627571188

Epoch: 5| Step: 1
Training loss: 3.2617897987365723
Validation loss: 2.4935575300647366

Epoch: 5| Step: 2
Training loss: 2.801651954650879
Validation loss: 2.4805930199161654

Epoch: 5| Step: 3
Training loss: 2.810314893722534
Validation loss: 2.4718057852919384

Epoch: 5| Step: 4
Training loss: 2.9433979988098145
Validation loss: 2.4792282171146844

Epoch: 5| Step: 5
Training loss: 2.3795790672302246
Validation loss: 2.5094070280751875

Epoch: 5| Step: 6
Training loss: 3.2314085960388184
Validation loss: 2.5582395087006273

Epoch: 5| Step: 7
Training loss: 2.058988094329834
Validation loss: 2.5949355889392156

Epoch: 5| Step: 8
Training loss: 2.9498133659362793
Validation loss: 2.6135062709931405

Epoch: 5| Step: 9
Training loss: 2.718461513519287
Validation loss: 2.602672520504203

Epoch: 5| Step: 10
Training loss: 2.179884433746338
Validation loss: 2.5827652638958347

Epoch: 41| Step: 0
Training loss: 2.4870903491973877
Validation loss: 2.547161650914018

Epoch: 5| Step: 1
Training loss: 3.1677074432373047
Validation loss: 2.4962262671480895

Epoch: 5| Step: 2
Training loss: 2.4879941940307617
Validation loss: 2.478480577468872

Epoch: 5| Step: 3
Training loss: 2.6671700477600098
Validation loss: 2.4641888692814815

Epoch: 5| Step: 4
Training loss: 2.4439187049865723
Validation loss: 2.463689511822116

Epoch: 5| Step: 5
Training loss: 3.0087547302246094
Validation loss: 2.459190691671064

Epoch: 5| Step: 6
Training loss: 2.6589086055755615
Validation loss: 2.453686514208394

Epoch: 5| Step: 7
Training loss: 2.94111967086792
Validation loss: 2.4483597816959506

Epoch: 5| Step: 8
Training loss: 2.7066900730133057
Validation loss: 2.4455282380503993

Epoch: 5| Step: 9
Training loss: 2.6392436027526855
Validation loss: 2.444756879601427

Epoch: 5| Step: 10
Training loss: 2.235463857650757
Validation loss: 2.442710079172606

Epoch: 42| Step: 0
Training loss: 2.7299203872680664
Validation loss: 2.440702117899413

Epoch: 5| Step: 1
Training loss: 2.9800686836242676
Validation loss: 2.4449489962670112

Epoch: 5| Step: 2
Training loss: 2.7272067070007324
Validation loss: 2.4470545143209477

Epoch: 5| Step: 3
Training loss: 3.1408112049102783
Validation loss: 2.450879452049091

Epoch: 5| Step: 4
Training loss: 2.551720142364502
Validation loss: 2.4520417644131567

Epoch: 5| Step: 5
Training loss: 3.272552490234375
Validation loss: 2.449858223238299

Epoch: 5| Step: 6
Training loss: 2.398165225982666
Validation loss: 2.440380670691049

Epoch: 5| Step: 7
Training loss: 2.556614398956299
Validation loss: 2.4361236620974798

Epoch: 5| Step: 8
Training loss: 2.479227066040039
Validation loss: 2.437076848040345

Epoch: 5| Step: 9
Training loss: 2.3599162101745605
Validation loss: 2.4374235496726087

Epoch: 5| Step: 10
Training loss: 2.1326286792755127
Validation loss: 2.438050821263303

Epoch: 43| Step: 0
Training loss: 3.0195021629333496
Validation loss: 2.438079736566031

Epoch: 5| Step: 1
Training loss: 3.1438145637512207
Validation loss: 2.439583497662698

Epoch: 5| Step: 2
Training loss: 2.6709580421447754
Validation loss: 2.442681650961599

Epoch: 5| Step: 3
Training loss: 2.3146703243255615
Validation loss: 2.4382142020810034

Epoch: 5| Step: 4
Training loss: 1.8097703456878662
Validation loss: 2.439079805087018

Epoch: 5| Step: 5
Training loss: 3.012892007827759
Validation loss: 2.438772083610617

Epoch: 5| Step: 6
Training loss: 2.4370229244232178
Validation loss: 2.438876885239796

Epoch: 5| Step: 7
Training loss: 3.1736998558044434
Validation loss: 2.437301569087531

Epoch: 5| Step: 8
Training loss: 2.404109477996826
Validation loss: 2.4345550562745784

Epoch: 5| Step: 9
Training loss: 2.592590570449829
Validation loss: 2.4390307370052544

Epoch: 5| Step: 10
Training loss: 2.7196261882781982
Validation loss: 2.4312926876929497

Epoch: 44| Step: 0
Training loss: 2.319650650024414
Validation loss: 2.4340663725329983

Epoch: 5| Step: 1
Training loss: 2.694596767425537
Validation loss: 2.4350972149961736

Epoch: 5| Step: 2
Training loss: 2.5506415367126465
Validation loss: 2.432196363326042

Epoch: 5| Step: 3
Training loss: 2.4025139808654785
Validation loss: 2.428412196456745

Epoch: 5| Step: 4
Training loss: 2.820612907409668
Validation loss: 2.436772684897146

Epoch: 5| Step: 5
Training loss: 3.0686540603637695
Validation loss: 2.431838643166327

Epoch: 5| Step: 6
Training loss: 2.600348711013794
Validation loss: 2.431162449621385

Epoch: 5| Step: 7
Training loss: 2.7784249782562256
Validation loss: 2.426233540299118

Epoch: 5| Step: 8
Training loss: 3.128366231918335
Validation loss: 2.424994594307356

Epoch: 5| Step: 9
Training loss: 2.4406323432922363
Validation loss: 2.427647113800049

Epoch: 5| Step: 10
Training loss: 2.400453567504883
Validation loss: 2.4239005786116405

Epoch: 45| Step: 0
Training loss: 3.2621970176696777
Validation loss: 2.426471902478126

Epoch: 5| Step: 1
Training loss: 2.663151741027832
Validation loss: 2.42745941428728

Epoch: 5| Step: 2
Training loss: 3.076218843460083
Validation loss: 2.4239867861552904

Epoch: 5| Step: 3
Training loss: 2.7548179626464844
Validation loss: 2.426023160257647

Epoch: 5| Step: 4
Training loss: 1.9186480045318604
Validation loss: 2.4234811516218286

Epoch: 5| Step: 5
Training loss: 2.7729203701019287
Validation loss: 2.43298311643703

Epoch: 5| Step: 6
Training loss: 3.087392807006836
Validation loss: 2.4339905810612503

Epoch: 5| Step: 7
Training loss: 2.6778571605682373
Validation loss: 2.431394423207929

Epoch: 5| Step: 8
Training loss: 2.592252254486084
Validation loss: 2.4348255613798737

Epoch: 5| Step: 9
Training loss: 2.1255202293395996
Validation loss: 2.43269375319122

Epoch: 5| Step: 10
Training loss: 2.1957614421844482
Validation loss: 2.4341390594359367

Epoch: 46| Step: 0
Training loss: 2.1379218101501465
Validation loss: 2.437802186576269

Epoch: 5| Step: 1
Training loss: 2.8025219440460205
Validation loss: 2.438253184800507

Epoch: 5| Step: 2
Training loss: 2.6741509437561035
Validation loss: 2.4436772126023487

Epoch: 5| Step: 3
Training loss: 2.8284082412719727
Validation loss: 2.444171900390297

Epoch: 5| Step: 4
Training loss: 2.990922451019287
Validation loss: 2.4262534982414654

Epoch: 5| Step: 5
Training loss: 2.8038601875305176
Validation loss: 2.416442765984484

Epoch: 5| Step: 6
Training loss: 2.4246420860290527
Validation loss: 2.4106730312429447

Epoch: 5| Step: 7
Training loss: 3.2217013835906982
Validation loss: 2.410165935434321

Epoch: 5| Step: 8
Training loss: 2.062208652496338
Validation loss: 2.4094671587790213

Epoch: 5| Step: 9
Training loss: 1.966512680053711
Validation loss: 2.4066698294813915

Epoch: 5| Step: 10
Training loss: 3.3599727153778076
Validation loss: 2.4085089852732997

Epoch: 47| Step: 0
Training loss: 2.6960277557373047
Validation loss: 2.409817491808245

Epoch: 5| Step: 1
Training loss: 2.7651164531707764
Validation loss: 2.4074822702715473

Epoch: 5| Step: 2
Training loss: 2.83962345123291
Validation loss: 2.4118413181715113

Epoch: 5| Step: 3
Training loss: 2.5887043476104736
Validation loss: 2.4126775803104525

Epoch: 5| Step: 4
Training loss: 2.3559489250183105
Validation loss: 2.410260405591739

Epoch: 5| Step: 5
Training loss: 2.691561222076416
Validation loss: 2.4150915966239026

Epoch: 5| Step: 6
Training loss: 2.7356903553009033
Validation loss: 2.4344720891726914

Epoch: 5| Step: 7
Training loss: 2.7027485370635986
Validation loss: 2.460481825695243

Epoch: 5| Step: 8
Training loss: 2.430393695831299
Validation loss: 2.485006983562182

Epoch: 5| Step: 9
Training loss: 2.711587429046631
Validation loss: 2.4794145873797837

Epoch: 5| Step: 10
Training loss: 2.682739734649658
Validation loss: 2.4513728003348074

Epoch: 48| Step: 0
Training loss: 2.189405918121338
Validation loss: 2.4340246646634993

Epoch: 5| Step: 1
Training loss: 2.775672197341919
Validation loss: 2.423313361342235

Epoch: 5| Step: 2
Training loss: 2.3171753883361816
Validation loss: 2.4244752494237756

Epoch: 5| Step: 3
Training loss: 2.904320478439331
Validation loss: 2.4167242383444183

Epoch: 5| Step: 4
Training loss: 3.0226211547851562
Validation loss: 2.4147644760788127

Epoch: 5| Step: 5
Training loss: 2.6283249855041504
Validation loss: 2.4091007760775986

Epoch: 5| Step: 6
Training loss: 2.8568904399871826
Validation loss: 2.4066275883746404

Epoch: 5| Step: 7
Training loss: 2.3214242458343506
Validation loss: 2.4059366705597087

Epoch: 5| Step: 8
Training loss: 2.99611496925354
Validation loss: 2.402373566422411

Epoch: 5| Step: 9
Training loss: 2.472268581390381
Validation loss: 2.3977156736517466

Epoch: 5| Step: 10
Training loss: 2.6101834774017334
Validation loss: 2.4010111875431512

Epoch: 49| Step: 0
Training loss: 2.8271679878234863
Validation loss: 2.4003478019468245

Epoch: 5| Step: 1
Training loss: 2.5330910682678223
Validation loss: 2.405399412237188

Epoch: 5| Step: 2
Training loss: 3.0543570518493652
Validation loss: 2.4067658890960035

Epoch: 5| Step: 3
Training loss: 2.2400145530700684
Validation loss: 2.409651207667525

Epoch: 5| Step: 4
Training loss: 3.476702928543091
Validation loss: 2.4227859666270595

Epoch: 5| Step: 5
Training loss: 2.619353771209717
Validation loss: 2.4185628621808943

Epoch: 5| Step: 6
Training loss: 2.304866313934326
Validation loss: 2.423996812553816

Epoch: 5| Step: 7
Training loss: 2.5364222526550293
Validation loss: 2.43255788792846

Epoch: 5| Step: 8
Training loss: 2.2598769664764404
Validation loss: 2.430974304035146

Epoch: 5| Step: 9
Training loss: 2.539527416229248
Validation loss: 2.4359554090807514

Epoch: 5| Step: 10
Training loss: 2.7072863578796387
Validation loss: 2.4313009990158903

Epoch: 50| Step: 0
Training loss: 2.914935350418091
Validation loss: 2.408667423391855

Epoch: 5| Step: 1
Training loss: 1.9641317129135132
Validation loss: 2.403636465790451

Epoch: 5| Step: 2
Training loss: 3.0429818630218506
Validation loss: 2.399258372604206

Epoch: 5| Step: 3
Training loss: 2.4688539505004883
Validation loss: 2.3952260914669243

Epoch: 5| Step: 4
Training loss: 3.2427914142608643
Validation loss: 2.39372153692348

Epoch: 5| Step: 5
Training loss: 2.5138535499572754
Validation loss: 2.392345247730132

Epoch: 5| Step: 6
Training loss: 2.5150396823883057
Validation loss: 2.3906287454789683

Epoch: 5| Step: 7
Training loss: 2.652595043182373
Validation loss: 2.393008333380504

Epoch: 5| Step: 8
Training loss: 2.203216075897217
Validation loss: 2.3879875854779313

Epoch: 5| Step: 9
Training loss: 2.9038708209991455
Validation loss: 2.389353623954199

Epoch: 5| Step: 10
Training loss: 2.695641279220581
Validation loss: 2.3927324254025697

Epoch: 51| Step: 0
Training loss: 2.982370138168335
Validation loss: 2.390541943170691

Epoch: 5| Step: 1
Training loss: 2.8654675483703613
Validation loss: 2.391342265631563

Epoch: 5| Step: 2
Training loss: 2.674408435821533
Validation loss: 2.3908657771284862

Epoch: 5| Step: 3
Training loss: 2.520158052444458
Validation loss: 2.3871481572428057

Epoch: 5| Step: 4
Training loss: 2.4917523860931396
Validation loss: 2.392957846323649

Epoch: 5| Step: 5
Training loss: 2.5635242462158203
Validation loss: 2.4023472211694203

Epoch: 5| Step: 6
Training loss: 2.481414318084717
Validation loss: 2.4230602582295737

Epoch: 5| Step: 7
Training loss: 1.9281336069107056
Validation loss: 2.4607051572492047

Epoch: 5| Step: 8
Training loss: 2.8702659606933594
Validation loss: 2.5037733739422214

Epoch: 5| Step: 9
Training loss: 3.056734561920166
Validation loss: 2.5229122689975205

Epoch: 5| Step: 10
Training loss: 2.7130064964294434
Validation loss: 2.5025084172525713

Epoch: 52| Step: 0
Training loss: 2.7552530765533447
Validation loss: 2.462296098791143

Epoch: 5| Step: 1
Training loss: 2.59228777885437
Validation loss: 2.445822528613511

Epoch: 5| Step: 2
Training loss: 2.3775010108947754
Validation loss: 2.4191869945936304

Epoch: 5| Step: 3
Training loss: 3.413283109664917
Validation loss: 2.396201733619936

Epoch: 5| Step: 4
Training loss: 2.4473938941955566
Validation loss: 2.3871260509696057

Epoch: 5| Step: 5
Training loss: 2.780108690261841
Validation loss: 2.3936888940872683

Epoch: 5| Step: 6
Training loss: 2.3598320484161377
Validation loss: 2.4109942861782607

Epoch: 5| Step: 7
Training loss: 2.50579833984375
Validation loss: 2.401772040192799

Epoch: 5| Step: 8
Training loss: 2.838927745819092
Validation loss: 2.3971787293752036

Epoch: 5| Step: 9
Training loss: 2.2837777137756348
Validation loss: 2.3844036773968766

Epoch: 5| Step: 10
Training loss: 2.752725601196289
Validation loss: 2.3854553930221067

Epoch: 53| Step: 0
Training loss: 2.360957384109497
Validation loss: 2.3887620049138225

Epoch: 5| Step: 1
Training loss: 2.8096165657043457
Validation loss: 2.392966713956607

Epoch: 5| Step: 2
Training loss: 3.240734815597534
Validation loss: 2.3940757961683374

Epoch: 5| Step: 3
Training loss: 2.1868882179260254
Validation loss: 2.4008564308125484

Epoch: 5| Step: 4
Training loss: 2.1909356117248535
Validation loss: 2.4040601996965307

Epoch: 5| Step: 5
Training loss: 2.805727481842041
Validation loss: 2.4341999177009828

Epoch: 5| Step: 6
Training loss: 2.3874590396881104
Validation loss: 2.481889819586149

Epoch: 5| Step: 7
Training loss: 2.7444205284118652
Validation loss: 2.5188377980263

Epoch: 5| Step: 8
Training loss: 2.6051712036132812
Validation loss: 2.4937262612004436

Epoch: 5| Step: 9
Training loss: 2.429717540740967
Validation loss: 2.4488031171983287

Epoch: 5| Step: 10
Training loss: 3.610673427581787
Validation loss: 2.3994945685068765

Epoch: 54| Step: 0
Training loss: 2.527573823928833
Validation loss: 2.3786796908224783

Epoch: 5| Step: 1
Training loss: 2.817780017852783
Validation loss: 2.3733414475635817

Epoch: 5| Step: 2
Training loss: 2.283552885055542
Validation loss: 2.382465121566608

Epoch: 5| Step: 3
Training loss: 2.5234527587890625
Validation loss: 2.3737024466196694

Epoch: 5| Step: 4
Training loss: 2.2755234241485596
Validation loss: 2.3759788915675175

Epoch: 5| Step: 5
Training loss: 2.41227650642395
Validation loss: 2.380447195422265

Epoch: 5| Step: 6
Training loss: 2.749114513397217
Validation loss: 2.3816369630957164

Epoch: 5| Step: 7
Training loss: 3.0400848388671875
Validation loss: 2.3901607887719267

Epoch: 5| Step: 8
Training loss: 3.300328493118286
Validation loss: 2.4044751774880195

Epoch: 5| Step: 9
Training loss: 2.1544570922851562
Validation loss: 2.413872359901346

Epoch: 5| Step: 10
Training loss: 2.8665695190429688
Validation loss: 2.4219746743479083

Epoch: 55| Step: 0
Training loss: 3.3114845752716064
Validation loss: 2.4178425522260767

Epoch: 5| Step: 1
Training loss: 2.3502769470214844
Validation loss: 2.4153245213211223

Epoch: 5| Step: 2
Training loss: 2.4086079597473145
Validation loss: 2.4058494478143673

Epoch: 5| Step: 3
Training loss: 3.09679913520813
Validation loss: 2.4008165867097917

Epoch: 5| Step: 4
Training loss: 2.1874191761016846
Validation loss: 2.3842958506717475

Epoch: 5| Step: 5
Training loss: 2.121044635772705
Validation loss: 2.375551954392464

Epoch: 5| Step: 6
Training loss: 2.8339953422546387
Validation loss: 2.3685478574486187

Epoch: 5| Step: 7
Training loss: 2.2057137489318848
Validation loss: 2.361357437667026

Epoch: 5| Step: 8
Training loss: 2.8523802757263184
Validation loss: 2.3633113497047016

Epoch: 5| Step: 9
Training loss: 2.809784412384033
Validation loss: 2.36024832981889

Epoch: 5| Step: 10
Training loss: 2.8069186210632324
Validation loss: 2.3628931224987073

Epoch: 56| Step: 0
Training loss: 2.445087432861328
Validation loss: 2.3625878505809332

Epoch: 5| Step: 1
Training loss: 2.574171543121338
Validation loss: 2.361981466252317

Epoch: 5| Step: 2
Training loss: 2.466860294342041
Validation loss: 2.3618385150868404

Epoch: 5| Step: 3
Training loss: 2.9157257080078125
Validation loss: 2.361334172628259

Epoch: 5| Step: 4
Training loss: 2.6959176063537598
Validation loss: 2.363404873878725

Epoch: 5| Step: 5
Training loss: 2.6771161556243896
Validation loss: 2.3626666684304514

Epoch: 5| Step: 6
Training loss: 2.4397506713867188
Validation loss: 2.367936747048491

Epoch: 5| Step: 7
Training loss: 2.3362553119659424
Validation loss: 2.371942489377914

Epoch: 5| Step: 8
Training loss: 2.5769028663635254
Validation loss: 2.377005466850855

Epoch: 5| Step: 9
Training loss: 2.4817774295806885
Validation loss: 2.3702605488479778

Epoch: 5| Step: 10
Training loss: 3.4500179290771484
Validation loss: 2.3712353552541425

Epoch: 57| Step: 0
Training loss: 2.672452926635742
Validation loss: 2.3661673094636653

Epoch: 5| Step: 1
Training loss: 2.728860855102539
Validation loss: 2.3546613980365056

Epoch: 5| Step: 2
Training loss: 2.387561798095703
Validation loss: 2.3555008519080376

Epoch: 5| Step: 3
Training loss: 2.816005229949951
Validation loss: 2.35317962913103

Epoch: 5| Step: 4
Training loss: 2.26348876953125
Validation loss: 2.357139002892279

Epoch: 5| Step: 5
Training loss: 3.4245808124542236
Validation loss: 2.3615017680711645

Epoch: 5| Step: 6
Training loss: 2.700000762939453
Validation loss: 2.3682611193708194

Epoch: 5| Step: 7
Training loss: 2.6833252906799316
Validation loss: 2.354053831869556

Epoch: 5| Step: 8
Training loss: 2.6239075660705566
Validation loss: 2.3518603591508764

Epoch: 5| Step: 9
Training loss: 1.7525991201400757
Validation loss: 2.3466866939298567

Epoch: 5| Step: 10
Training loss: 2.778237819671631
Validation loss: 2.3529238367593415

Epoch: 58| Step: 0
Training loss: 2.236910104751587
Validation loss: 2.3500927366236204

Epoch: 5| Step: 1
Training loss: 2.7863478660583496
Validation loss: 2.35072801702766

Epoch: 5| Step: 2
Training loss: 2.281172275543213
Validation loss: 2.3552836987280075

Epoch: 5| Step: 3
Training loss: 3.18389630317688
Validation loss: 2.3604097840606526

Epoch: 5| Step: 4
Training loss: 2.486215114593506
Validation loss: 2.359794839735954

Epoch: 5| Step: 5
Training loss: 2.7386813163757324
Validation loss: 2.3626055127830914

Epoch: 5| Step: 6
Training loss: 2.891047239303589
Validation loss: 2.3513228765097995

Epoch: 5| Step: 7
Training loss: 2.957658290863037
Validation loss: 2.351494543014034

Epoch: 5| Step: 8
Training loss: 2.215230941772461
Validation loss: 2.36013985449268

Epoch: 5| Step: 9
Training loss: 2.666428804397583
Validation loss: 2.357271663604244

Epoch: 5| Step: 10
Training loss: 2.2162439823150635
Validation loss: 2.356670561657157

Epoch: 59| Step: 0
Training loss: 2.8819432258605957
Validation loss: 2.3547237867950113

Epoch: 5| Step: 1
Training loss: 1.7943451404571533
Validation loss: 2.354624168847197

Epoch: 5| Step: 2
Training loss: 1.947201132774353
Validation loss: 2.348796962409891

Epoch: 5| Step: 3
Training loss: 2.4024271965026855
Validation loss: 2.349850400801628

Epoch: 5| Step: 4
Training loss: 2.914764165878296
Validation loss: 2.3469179086787726

Epoch: 5| Step: 5
Training loss: 3.0203354358673096
Validation loss: 2.3449723284731627

Epoch: 5| Step: 6
Training loss: 2.269503116607666
Validation loss: 2.3480699908348823

Epoch: 5| Step: 7
Training loss: 2.868199586868286
Validation loss: 2.3523516962605138

Epoch: 5| Step: 8
Training loss: 2.2655515670776367
Validation loss: 2.3453364320980605

Epoch: 5| Step: 9
Training loss: 3.4276440143585205
Validation loss: 2.3475956532262985

Epoch: 5| Step: 10
Training loss: 2.8927571773529053
Validation loss: 2.346147285994663

Epoch: 60| Step: 0
Training loss: 1.6802260875701904
Validation loss: 2.3462532668985348

Epoch: 5| Step: 1
Training loss: 2.84599232673645
Validation loss: 2.3534712611988025

Epoch: 5| Step: 2
Training loss: 3.0896964073181152
Validation loss: 2.3591434724869265

Epoch: 5| Step: 3
Training loss: 2.3354101181030273
Validation loss: 2.3631759382063344

Epoch: 5| Step: 4
Training loss: 2.6338958740234375
Validation loss: 2.364328457463172

Epoch: 5| Step: 5
Training loss: 1.8706481456756592
Validation loss: 2.3684783879146782

Epoch: 5| Step: 6
Training loss: 2.797497272491455
Validation loss: 2.365079479832803

Epoch: 5| Step: 7
Training loss: 2.8496296405792236
Validation loss: 2.355626536953834

Epoch: 5| Step: 8
Training loss: 2.695197582244873
Validation loss: 2.3458429792875886

Epoch: 5| Step: 9
Training loss: 2.8351643085479736
Validation loss: 2.350480710306475

Epoch: 5| Step: 10
Training loss: 3.1716997623443604
Validation loss: 2.3465177628301803

Epoch: 61| Step: 0
Training loss: 3.333754777908325
Validation loss: 2.345174809937836

Epoch: 5| Step: 1
Training loss: 2.7930235862731934
Validation loss: 2.342476314113986

Epoch: 5| Step: 2
Training loss: 2.5603203773498535
Validation loss: 2.3434990939273628

Epoch: 5| Step: 3
Training loss: 2.3706297874450684
Validation loss: 2.3397249765293573

Epoch: 5| Step: 4
Training loss: 2.511869430541992
Validation loss: 2.3505264097644436

Epoch: 5| Step: 5
Training loss: 2.5711467266082764
Validation loss: 2.3589860316245788

Epoch: 5| Step: 6
Training loss: 2.3725028038024902
Validation loss: 2.367160448464014

Epoch: 5| Step: 7
Training loss: 2.7111592292785645
Validation loss: 2.371179137178647

Epoch: 5| Step: 8
Training loss: 2.447173595428467
Validation loss: 2.382963275396696

Epoch: 5| Step: 9
Training loss: 2.573199987411499
Validation loss: 2.371231227792719

Epoch: 5| Step: 10
Training loss: 2.373879909515381
Validation loss: 2.3539510708983227

Epoch: 62| Step: 0
Training loss: 2.9939630031585693
Validation loss: 2.3524393343156382

Epoch: 5| Step: 1
Training loss: 2.3654580116271973
Validation loss: 2.352101746425834

Epoch: 5| Step: 2
Training loss: 3.3225760459899902
Validation loss: 2.358816300669024

Epoch: 5| Step: 3
Training loss: 1.9464277029037476
Validation loss: 2.367236550136279

Epoch: 5| Step: 4
Training loss: 3.1035635471343994
Validation loss: 2.358789736224759

Epoch: 5| Step: 5
Training loss: 2.0850634574890137
Validation loss: 2.3699276985660678

Epoch: 5| Step: 6
Training loss: 3.4190475940704346
Validation loss: 2.3421500549521497

Epoch: 5| Step: 7
Training loss: 2.2032299041748047
Validation loss: 2.33680744324961

Epoch: 5| Step: 8
Training loss: 2.3890748023986816
Validation loss: 2.335523020836615

Epoch: 5| Step: 9
Training loss: 2.4881303310394287
Validation loss: 2.3240989946549937

Epoch: 5| Step: 10
Training loss: 2.0837247371673584
Validation loss: 2.323155851774318

Epoch: 63| Step: 0
Training loss: 2.8226096630096436
Validation loss: 2.319461291836154

Epoch: 5| Step: 1
Training loss: 3.294722318649292
Validation loss: 2.3184916998750422

Epoch: 5| Step: 2
Training loss: 1.9388700723648071
Validation loss: 2.319838608464887

Epoch: 5| Step: 3
Training loss: 2.401216506958008
Validation loss: 2.341775002018098

Epoch: 5| Step: 4
Training loss: 3.2374229431152344
Validation loss: 2.360664882967549

Epoch: 5| Step: 5
Training loss: 2.6515145301818848
Validation loss: 2.3848710188301663

Epoch: 5| Step: 6
Training loss: 2.226151704788208
Validation loss: 2.3830366416644027

Epoch: 5| Step: 7
Training loss: 2.699708938598633
Validation loss: 2.3581541661293275

Epoch: 5| Step: 8
Training loss: 2.619622230529785
Validation loss: 2.3370823398713143

Epoch: 5| Step: 9
Training loss: 2.3088183403015137
Validation loss: 2.3229703146924257

Epoch: 5| Step: 10
Training loss: 2.419867753982544
Validation loss: 2.314963279231902

Epoch: 64| Step: 0
Training loss: 2.5629584789276123
Validation loss: 2.3124149230218705

Epoch: 5| Step: 1
Training loss: 2.882742166519165
Validation loss: 2.31109223827239

Epoch: 5| Step: 2
Training loss: 2.4768056869506836
Validation loss: 2.3114219634763655

Epoch: 5| Step: 3
Training loss: 2.34665584564209
Validation loss: 2.3108180774155485

Epoch: 5| Step: 4
Training loss: 2.133291244506836
Validation loss: 2.314572636799146

Epoch: 5| Step: 5
Training loss: 3.0968587398529053
Validation loss: 2.3143842245942805

Epoch: 5| Step: 6
Training loss: 2.500195264816284
Validation loss: 2.3179307394130255

Epoch: 5| Step: 7
Training loss: 1.9515619277954102
Validation loss: 2.3090407925267376

Epoch: 5| Step: 8
Training loss: 2.677196979522705
Validation loss: 2.314077695210775

Epoch: 5| Step: 9
Training loss: 3.147756576538086
Validation loss: 2.3112468796391643

Epoch: 5| Step: 10
Training loss: 2.6328420639038086
Validation loss: 2.310227527413317

Epoch: 65| Step: 0
Training loss: 2.7475638389587402
Validation loss: 2.309761466518525

Epoch: 5| Step: 1
Training loss: 2.137073040008545
Validation loss: 2.321171247830955

Epoch: 5| Step: 2
Training loss: 2.7540111541748047
Validation loss: 2.318110507021668

Epoch: 5| Step: 3
Training loss: 2.100059747695923
Validation loss: 2.320040164455291

Epoch: 5| Step: 4
Training loss: 2.033964157104492
Validation loss: 2.3286501182022916

Epoch: 5| Step: 5
Training loss: 2.063211679458618
Validation loss: 2.334981538916147

Epoch: 5| Step: 6
Training loss: 2.339561939239502
Validation loss: 2.355944105373916

Epoch: 5| Step: 7
Training loss: 2.884129762649536
Validation loss: 2.3823699746080624

Epoch: 5| Step: 8
Training loss: 3.1629223823547363
Validation loss: 2.378003884387273

Epoch: 5| Step: 9
Training loss: 3.4221606254577637
Validation loss: 2.3539026860267884

Epoch: 5| Step: 10
Training loss: 2.868577718734741
Validation loss: 2.3178915362204275

Epoch: 66| Step: 0
Training loss: 2.2535219192504883
Validation loss: 2.3072732110177316

Epoch: 5| Step: 1
Training loss: 2.580319881439209
Validation loss: 2.294366980111727

Epoch: 5| Step: 2
Training loss: 2.950549364089966
Validation loss: 2.295131834604407

Epoch: 5| Step: 3
Training loss: 2.722094774246216
Validation loss: 2.2984376633039085

Epoch: 5| Step: 4
Training loss: 2.5462708473205566
Validation loss: 2.302633270140617

Epoch: 5| Step: 5
Training loss: 3.0480966567993164
Validation loss: 2.3015202860678396

Epoch: 5| Step: 6
Training loss: 3.040334701538086
Validation loss: 2.304072859466717

Epoch: 5| Step: 7
Training loss: 2.232191562652588
Validation loss: 2.303981432350733

Epoch: 5| Step: 8
Training loss: 2.65744948387146
Validation loss: 2.301614366551881

Epoch: 5| Step: 9
Training loss: 2.3217904567718506
Validation loss: 2.3032371280013875

Epoch: 5| Step: 10
Training loss: 2.1542444229125977
Validation loss: 2.2969191510190248

Epoch: 67| Step: 0
Training loss: 2.747981309890747
Validation loss: 2.2952861478251796

Epoch: 5| Step: 1
Training loss: 2.2547922134399414
Validation loss: 2.290065514144077

Epoch: 5| Step: 2
Training loss: 2.1295366287231445
Validation loss: 2.2954231962080924

Epoch: 5| Step: 3
Training loss: 2.416322946548462
Validation loss: 2.3037901027228243

Epoch: 5| Step: 4
Training loss: 2.4505581855773926
Validation loss: 2.3221674016726914

Epoch: 5| Step: 5
Training loss: 2.2707014083862305
Validation loss: 2.32419579644357

Epoch: 5| Step: 6
Training loss: 2.965730905532837
Validation loss: 2.3384381519850863

Epoch: 5| Step: 7
Training loss: 2.653674602508545
Validation loss: 2.3465181473762757

Epoch: 5| Step: 8
Training loss: 2.9950783252716064
Validation loss: 2.3420824991759432

Epoch: 5| Step: 9
Training loss: 3.1605887413024902
Validation loss: 2.3503047343223327

Epoch: 5| Step: 10
Training loss: 2.2801761627197266
Validation loss: 2.3680082854404243

Epoch: 68| Step: 0
Training loss: 2.76900053024292
Validation loss: 2.3577467215958463

Epoch: 5| Step: 1
Training loss: 2.2836947441101074
Validation loss: 2.3276012302726827

Epoch: 5| Step: 2
Training loss: 2.4502341747283936
Validation loss: 2.3081126264346543

Epoch: 5| Step: 3
Training loss: 2.195368528366089
Validation loss: 2.307775838400728

Epoch: 5| Step: 4
Training loss: 2.6728427410125732
Validation loss: 2.300619879076558

Epoch: 5| Step: 5
Training loss: 2.177649736404419
Validation loss: 2.294181098220169

Epoch: 5| Step: 6
Training loss: 2.8506970405578613
Validation loss: 2.296411673227946

Epoch: 5| Step: 7
Training loss: 2.392102003097534
Validation loss: 2.3015300740477858

Epoch: 5| Step: 8
Training loss: 2.6942293643951416
Validation loss: 2.3012988644261516

Epoch: 5| Step: 9
Training loss: 2.9112863540649414
Validation loss: 2.2975735215730566

Epoch: 5| Step: 10
Training loss: 3.113877296447754
Validation loss: 2.295574079277695

Epoch: 69| Step: 0
Training loss: 2.5471138954162598
Validation loss: 2.294860383515717

Epoch: 5| Step: 1
Training loss: 2.0925774574279785
Validation loss: 2.297541723456434

Epoch: 5| Step: 2
Training loss: 2.602146863937378
Validation loss: 2.29708602095163

Epoch: 5| Step: 3
Training loss: 2.8077328205108643
Validation loss: 2.303100355209843

Epoch: 5| Step: 4
Training loss: 2.8292715549468994
Validation loss: 2.3140672868297947

Epoch: 5| Step: 5
Training loss: 2.3574271202087402
Validation loss: 2.345255897891137

Epoch: 5| Step: 6
Training loss: 2.846752166748047
Validation loss: 2.3666445106588383

Epoch: 5| Step: 7
Training loss: 1.9976253509521484
Validation loss: 2.3903331474591325

Epoch: 5| Step: 8
Training loss: 3.006854295730591
Validation loss: 2.385256013562602

Epoch: 5| Step: 9
Training loss: 2.265688896179199
Validation loss: 2.3520543806014524

Epoch: 5| Step: 10
Training loss: 3.152672290802002
Validation loss: 2.3221413896929834

Epoch: 70| Step: 0
Training loss: 2.619947910308838
Validation loss: 2.316424218557214

Epoch: 5| Step: 1
Training loss: 2.596052646636963
Validation loss: 2.3212761391875563

Epoch: 5| Step: 2
Training loss: 2.9825387001037598
Validation loss: 2.3211776005324496

Epoch: 5| Step: 3
Training loss: 2.3972511291503906
Validation loss: 2.332977884559221

Epoch: 5| Step: 4
Training loss: 2.595083236694336
Validation loss: 2.327888616951563

Epoch: 5| Step: 5
Training loss: 2.084613084793091
Validation loss: 2.3136382615694435

Epoch: 5| Step: 6
Training loss: 2.550555467605591
Validation loss: 2.3082178228644916

Epoch: 5| Step: 7
Training loss: 3.2036185264587402
Validation loss: 2.2992245189605223

Epoch: 5| Step: 8
Training loss: 2.5964512825012207
Validation loss: 2.2808649668129544

Epoch: 5| Step: 9
Training loss: 2.3150994777679443
Validation loss: 2.2808457420718287

Epoch: 5| Step: 10
Training loss: 2.1671314239501953
Validation loss: 2.273884588672269

Epoch: 71| Step: 0
Training loss: 2.1875522136688232
Validation loss: 2.2794019560660086

Epoch: 5| Step: 1
Training loss: 2.888901472091675
Validation loss: 2.28565719819838

Epoch: 5| Step: 2
Training loss: 2.386134624481201
Validation loss: 2.3331427163975214

Epoch: 5| Step: 3
Training loss: 2.3809337615966797
Validation loss: 2.3624283780333815

Epoch: 5| Step: 4
Training loss: 3.1612210273742676
Validation loss: 2.3441215586918656

Epoch: 5| Step: 5
Training loss: 2.2673628330230713
Validation loss: 2.307160351866035

Epoch: 5| Step: 6
Training loss: 2.24542498588562
Validation loss: 2.28442245657726

Epoch: 5| Step: 7
Training loss: 2.9143548011779785
Validation loss: 2.276981874178815

Epoch: 5| Step: 8
Training loss: 2.976396083831787
Validation loss: 2.2795711871116393

Epoch: 5| Step: 9
Training loss: 2.235250234603882
Validation loss: 2.2770701633986605

Epoch: 5| Step: 10
Training loss: 2.9368128776550293
Validation loss: 2.279039470098352

Epoch: 72| Step: 0
Training loss: 2.1671335697174072
Validation loss: 2.295970223283255

Epoch: 5| Step: 1
Training loss: 2.90966534614563
Validation loss: 2.304274910239763

Epoch: 5| Step: 2
Training loss: 2.728463649749756
Validation loss: 2.333832017837032

Epoch: 5| Step: 3
Training loss: 2.2805819511413574
Validation loss: 2.3429990032667756

Epoch: 5| Step: 4
Training loss: 2.507235288619995
Validation loss: 2.3413013104469544

Epoch: 5| Step: 5
Training loss: 2.8465120792388916
Validation loss: 2.3125064116652294

Epoch: 5| Step: 6
Training loss: 2.283651828765869
Validation loss: 2.2841343597699235

Epoch: 5| Step: 7
Training loss: 2.780667781829834
Validation loss: 2.2804893857689312

Epoch: 5| Step: 8
Training loss: 2.7149062156677246
Validation loss: 2.270511850234001

Epoch: 5| Step: 9
Training loss: 2.3734099864959717
Validation loss: 2.2720088522921325

Epoch: 5| Step: 10
Training loss: 2.5711889266967773
Validation loss: 2.266970912615458

Epoch: 73| Step: 0
Training loss: 2.1824183464050293
Validation loss: 2.2643536662542694

Epoch: 5| Step: 1
Training loss: 3.0575954914093018
Validation loss: 2.256993706508349

Epoch: 5| Step: 2
Training loss: 2.3465189933776855
Validation loss: 2.255789715756652

Epoch: 5| Step: 3
Training loss: 1.961663007736206
Validation loss: 2.2575936112352597

Epoch: 5| Step: 4
Training loss: 2.704697370529175
Validation loss: 2.2591232689478065

Epoch: 5| Step: 5
Training loss: 2.93281888961792
Validation loss: 2.2658669820395847

Epoch: 5| Step: 6
Training loss: 2.6572043895721436
Validation loss: 2.2605583552391297

Epoch: 5| Step: 7
Training loss: 2.6523399353027344
Validation loss: 2.2607810125556043

Epoch: 5| Step: 8
Training loss: 3.0079774856567383
Validation loss: 2.2533397674560547

Epoch: 5| Step: 9
Training loss: 3.100353479385376
Validation loss: 2.253232744432265

Epoch: 5| Step: 10
Training loss: 1.4577115774154663
Validation loss: 2.2537949469781693

Epoch: 74| Step: 0
Training loss: 2.685215473175049
Validation loss: 2.2601082632618565

Epoch: 5| Step: 1
Training loss: 2.192077159881592
Validation loss: 2.2654521157664638

Epoch: 5| Step: 2
Training loss: 2.8106913566589355
Validation loss: 2.28322922542531

Epoch: 5| Step: 3
Training loss: 2.2042009830474854
Validation loss: 2.2860172179437455

Epoch: 5| Step: 4
Training loss: 2.7607388496398926
Validation loss: 2.3192724784215293

Epoch: 5| Step: 5
Training loss: 2.6977739334106445
Validation loss: 2.338195175252935

Epoch: 5| Step: 6
Training loss: 2.4117558002471924
Validation loss: 2.3533659673506215

Epoch: 5| Step: 7
Training loss: 2.729325771331787
Validation loss: 2.3822640654861287

Epoch: 5| Step: 8
Training loss: 2.342878818511963
Validation loss: 2.3970339810976418

Epoch: 5| Step: 9
Training loss: 2.6087708473205566
Validation loss: 2.3959240708299863

Epoch: 5| Step: 10
Training loss: 2.8944091796875
Validation loss: 2.3841689171329623

Epoch: 75| Step: 0
Training loss: 2.3707873821258545
Validation loss: 2.3368194897969565

Epoch: 5| Step: 1
Training loss: 3.0813021659851074
Validation loss: 2.300512113878804

Epoch: 5| Step: 2
Training loss: 2.470348834991455
Validation loss: 2.295322364376437

Epoch: 5| Step: 3
Training loss: 2.7945716381073
Validation loss: 2.283275845230267

Epoch: 5| Step: 4
Training loss: 2.4162256717681885
Validation loss: 2.271215510624711

Epoch: 5| Step: 5
Training loss: 2.0608115196228027
Validation loss: 2.25088369846344

Epoch: 5| Step: 6
Training loss: 2.30450701713562
Validation loss: 2.2498238830156225

Epoch: 5| Step: 7
Training loss: 2.4624900817871094
Validation loss: 2.2465846948726202

Epoch: 5| Step: 8
Training loss: 2.4968039989471436
Validation loss: 2.243231278593822

Epoch: 5| Step: 9
Training loss: 3.0009360313415527
Validation loss: 2.2411662301709576

Epoch: 5| Step: 10
Training loss: 2.4511945247650146
Validation loss: 2.2407459635888376

Epoch: 76| Step: 0
Training loss: 2.8985729217529297
Validation loss: 2.242879201007146

Epoch: 5| Step: 1
Training loss: 2.5653884410858154
Validation loss: 2.2420880820161555

Epoch: 5| Step: 2
Training loss: 2.799377918243408
Validation loss: 2.2427564013388848

Epoch: 5| Step: 3
Training loss: 2.4419665336608887
Validation loss: 2.242624810946885

Epoch: 5| Step: 4
Training loss: 3.258157253265381
Validation loss: 2.239736892843759

Epoch: 5| Step: 5
Training loss: 1.9952833652496338
Validation loss: 2.236424961397725

Epoch: 5| Step: 6
Training loss: 2.2067360877990723
Validation loss: 2.2370071026586715

Epoch: 5| Step: 7
Training loss: 3.225194215774536
Validation loss: 2.238553571444686

Epoch: 5| Step: 8
Training loss: 2.433170795440674
Validation loss: 2.245204858882453

Epoch: 5| Step: 9
Training loss: 1.8846194744110107
Validation loss: 2.2500612197383756

Epoch: 5| Step: 10
Training loss: 2.254837989807129
Validation loss: 2.2632085251551803

Epoch: 77| Step: 0
Training loss: 2.5247864723205566
Validation loss: 2.2683542005477415

Epoch: 5| Step: 1
Training loss: 2.5078346729278564
Validation loss: 2.2889046079369

Epoch: 5| Step: 2
Training loss: 3.222480058670044
Validation loss: 2.29900860786438

Epoch: 5| Step: 3
Training loss: 2.732499361038208
Validation loss: 2.2876990533644155

Epoch: 5| Step: 4
Training loss: 2.2163405418395996
Validation loss: 2.288706753843574

Epoch: 5| Step: 5
Training loss: 2.9370737075805664
Validation loss: 2.2637666502306537

Epoch: 5| Step: 6
Training loss: 2.200793743133545
Validation loss: 2.261093206303094

Epoch: 5| Step: 7
Training loss: 2.7304491996765137
Validation loss: 2.2483691964098202

Epoch: 5| Step: 8
Training loss: 2.1232852935791016
Validation loss: 2.2429774730436263

Epoch: 5| Step: 9
Training loss: 2.1101794242858887
Validation loss: 2.2410221740763676

Epoch: 5| Step: 10
Training loss: 2.6622374057769775
Validation loss: 2.2343205111001128

Epoch: 78| Step: 0
Training loss: 2.892197847366333
Validation loss: 2.232909764012983

Epoch: 5| Step: 1
Training loss: 2.643916368484497
Validation loss: 2.2332506282355196

Epoch: 5| Step: 2
Training loss: 2.968168258666992
Validation loss: 2.2388291717857443

Epoch: 5| Step: 3
Training loss: 2.124162197113037
Validation loss: 2.241070483320503

Epoch: 5| Step: 4
Training loss: 2.46539044380188
Validation loss: 2.2371510459530737

Epoch: 5| Step: 5
Training loss: 2.4124228954315186
Validation loss: 2.2405477698131273

Epoch: 5| Step: 6
Training loss: 2.434849262237549
Validation loss: 2.239572173805647

Epoch: 5| Step: 7
Training loss: 2.2370810508728027
Validation loss: 2.246709085279895

Epoch: 5| Step: 8
Training loss: 2.0576682090759277
Validation loss: 2.2490222864253546

Epoch: 5| Step: 9
Training loss: 2.3653552532196045
Validation loss: 2.2560041719867336

Epoch: 5| Step: 10
Training loss: 3.494917154312134
Validation loss: 2.2792888046592794

Epoch: 79| Step: 0
Training loss: 2.413860321044922
Validation loss: 2.2607045558191117

Epoch: 5| Step: 1
Training loss: 2.3879857063293457
Validation loss: 2.239019973303682

Epoch: 5| Step: 2
Training loss: 2.5354628562927246
Validation loss: 2.2290291888739473

Epoch: 5| Step: 3
Training loss: 2.336390495300293
Validation loss: 2.225217298794818

Epoch: 5| Step: 4
Training loss: 2.9208786487579346
Validation loss: 2.2259335620428926

Epoch: 5| Step: 5
Training loss: 2.8143062591552734
Validation loss: 2.22136539541265

Epoch: 5| Step: 6
Training loss: 2.3503360748291016
Validation loss: 2.225622805215979

Epoch: 5| Step: 7
Training loss: 2.4750289916992188
Validation loss: 2.2277120005699897

Epoch: 5| Step: 8
Training loss: 2.5958452224731445
Validation loss: 2.2307889692244993

Epoch: 5| Step: 9
Training loss: 2.534881353378296
Validation loss: 2.243448393319243

Epoch: 5| Step: 10
Training loss: 2.4056262969970703
Validation loss: 2.2539590533061693

Epoch: 80| Step: 0
Training loss: 3.631314754486084
Validation loss: 2.2617632150650024

Epoch: 5| Step: 1
Training loss: 2.656334400177002
Validation loss: 2.2549530049806

Epoch: 5| Step: 2
Training loss: 2.4349865913391113
Validation loss: 2.26165416420147

Epoch: 5| Step: 3
Training loss: 2.327355146408081
Validation loss: 2.262761667210569

Epoch: 5| Step: 4
Training loss: 2.3122692108154297
Validation loss: 2.255375034065657

Epoch: 5| Step: 5
Training loss: 2.8407561779022217
Validation loss: 2.2640458819686726

Epoch: 5| Step: 6
Training loss: 2.7656569480895996
Validation loss: 2.245225852535617

Epoch: 5| Step: 7
Training loss: 2.3461670875549316
Validation loss: 2.2409966222701536

Epoch: 5| Step: 8
Training loss: 2.023902416229248
Validation loss: 2.2389544056307886

Epoch: 5| Step: 9
Training loss: 1.8473536968231201
Validation loss: 2.2362580196831816

Epoch: 5| Step: 10
Training loss: 2.4598827362060547
Validation loss: 2.23715038453379

Epoch: 81| Step: 0
Training loss: 2.4650769233703613
Validation loss: 2.2370431628278507

Epoch: 5| Step: 1
Training loss: 2.806236982345581
Validation loss: 2.223188054177069

Epoch: 5| Step: 2
Training loss: 2.508974075317383
Validation loss: 2.2223761466241654

Epoch: 5| Step: 3
Training loss: 2.4279212951660156
Validation loss: 2.233279722993092

Epoch: 5| Step: 4
Training loss: 2.4733269214630127
Validation loss: 2.218883563113469

Epoch: 5| Step: 5
Training loss: 2.593682289123535
Validation loss: 2.2180798130650676

Epoch: 5| Step: 6
Training loss: 2.303302049636841
Validation loss: 2.2144157194322154

Epoch: 5| Step: 7
Training loss: 2.1657586097717285
Validation loss: 2.2190470695495605

Epoch: 5| Step: 8
Training loss: 2.1441140174865723
Validation loss: 2.23176170164539

Epoch: 5| Step: 9
Training loss: 2.9902119636535645
Validation loss: 2.232089134954637

Epoch: 5| Step: 10
Training loss: 2.715597629547119
Validation loss: 2.23528738047487

Epoch: 82| Step: 0
Training loss: 2.9711403846740723
Validation loss: 2.214054904958253

Epoch: 5| Step: 1
Training loss: 2.4814250469207764
Validation loss: 2.2153062038524176

Epoch: 5| Step: 2
Training loss: 1.7985961437225342
Validation loss: 2.20754171699606

Epoch: 5| Step: 3
Training loss: 2.184995651245117
Validation loss: 2.216416674275552

Epoch: 5| Step: 4
Training loss: 2.598034620285034
Validation loss: 2.2132423129133

Epoch: 5| Step: 5
Training loss: 2.6009600162506104
Validation loss: 2.2258845606157855

Epoch: 5| Step: 6
Training loss: 2.987468957901001
Validation loss: 2.2351280412366314

Epoch: 5| Step: 7
Training loss: 2.253868341445923
Validation loss: 2.237882507744656

Epoch: 5| Step: 8
Training loss: 2.7592926025390625
Validation loss: 2.2422617276509604

Epoch: 5| Step: 9
Training loss: 2.462057113647461
Validation loss: 2.22931565776948

Epoch: 5| Step: 10
Training loss: 2.3680076599121094
Validation loss: 2.209738451947448

Epoch: 83| Step: 0
Training loss: 2.21384859085083
Validation loss: 2.2074857604119087

Epoch: 5| Step: 1
Training loss: 2.766775369644165
Validation loss: 2.2073447332587293

Epoch: 5| Step: 2
Training loss: 3.0866873264312744
Validation loss: 2.211337330520794

Epoch: 5| Step: 3
Training loss: 2.096503734588623
Validation loss: 2.2143265560109127

Epoch: 5| Step: 4
Training loss: 2.8562064170837402
Validation loss: 2.2063926612177203

Epoch: 5| Step: 5
Training loss: 2.3987925052642822
Validation loss: 2.2031733707715104

Epoch: 5| Step: 6
Training loss: 2.5829877853393555
Validation loss: 2.2038069566090903

Epoch: 5| Step: 7
Training loss: 2.2228610515594482
Validation loss: 2.2039236778854043

Epoch: 5| Step: 8
Training loss: 1.778111219406128
Validation loss: 2.207540040375084

Epoch: 5| Step: 9
Training loss: 2.187825918197632
Validation loss: 2.2124615894850863

Epoch: 5| Step: 10
Training loss: 3.479642391204834
Validation loss: 2.2238330687246015

Epoch: 84| Step: 0
Training loss: 2.4398555755615234
Validation loss: 2.227447666147704

Epoch: 5| Step: 1
Training loss: 2.412198543548584
Validation loss: 2.223681911345451

Epoch: 5| Step: 2
Training loss: 3.315819501876831
Validation loss: 2.2209606965382895

Epoch: 5| Step: 3
Training loss: 1.9299196004867554
Validation loss: 2.2185512153051232

Epoch: 5| Step: 4
Training loss: 2.7668471336364746
Validation loss: 2.210588639782321

Epoch: 5| Step: 5
Training loss: 2.575777769088745
Validation loss: 2.2144693738670758

Epoch: 5| Step: 6
Training loss: 1.9249780178070068
Validation loss: 2.2131206297105357

Epoch: 5| Step: 7
Training loss: 2.278240919113159
Validation loss: 2.2123705571697605

Epoch: 5| Step: 8
Training loss: 2.910299777984619
Validation loss: 2.2124034999519266

Epoch: 5| Step: 9
Training loss: 2.434457540512085
Validation loss: 2.2031375515845513

Epoch: 5| Step: 10
Training loss: 2.318197727203369
Validation loss: 2.198088079370478

Epoch: 85| Step: 0
Training loss: 2.71004056930542
Validation loss: 2.2028652673126548

Epoch: 5| Step: 1
Training loss: 2.3523929119110107
Validation loss: 2.2008280984817015

Epoch: 5| Step: 2
Training loss: 2.147510290145874
Validation loss: 2.2022618503980738

Epoch: 5| Step: 3
Training loss: 3.037855625152588
Validation loss: 2.212198733001627

Epoch: 5| Step: 4
Training loss: 2.2067015171051025
Validation loss: 2.228326041211364

Epoch: 5| Step: 5
Training loss: 2.949449062347412
Validation loss: 2.2353019842537503

Epoch: 5| Step: 6
Training loss: 1.9169048070907593
Validation loss: 2.238107876111102

Epoch: 5| Step: 7
Training loss: 2.7650609016418457
Validation loss: 2.2367338262578493

Epoch: 5| Step: 8
Training loss: 2.0849242210388184
Validation loss: 2.2204353629901843

Epoch: 5| Step: 9
Training loss: 2.8210666179656982
Validation loss: 2.212635596593221

Epoch: 5| Step: 10
Training loss: 2.3165066242218018
Validation loss: 2.1989124231441046

Epoch: 86| Step: 0
Training loss: 2.4540460109710693
Validation loss: 2.1986508625809864

Epoch: 5| Step: 1
Training loss: 2.2826790809631348
Validation loss: 2.1925151437841435

Epoch: 5| Step: 2
Training loss: 2.394996166229248
Validation loss: 2.2046711829400834

Epoch: 5| Step: 3
Training loss: 2.575336456298828
Validation loss: 2.198798224490176

Epoch: 5| Step: 4
Training loss: 2.2173080444335938
Validation loss: 2.199906802946521

Epoch: 5| Step: 5
Training loss: 1.7100368738174438
Validation loss: 2.2031734989535425

Epoch: 5| Step: 6
Training loss: 2.7838830947875977
Validation loss: 2.2018373986726165

Epoch: 5| Step: 7
Training loss: 2.682136297225952
Validation loss: 2.2067994327955347

Epoch: 5| Step: 8
Training loss: 3.0088400840759277
Validation loss: 2.239850540314951

Epoch: 5| Step: 9
Training loss: 2.433475971221924
Validation loss: 2.2462080165904057

Epoch: 5| Step: 10
Training loss: 2.7515649795532227
Validation loss: 2.2322325873118576

Epoch: 87| Step: 0
Training loss: 2.3732523918151855
Validation loss: 2.2211122794817855

Epoch: 5| Step: 1
Training loss: 1.8360226154327393
Validation loss: 2.2205626810750654

Epoch: 5| Step: 2
Training loss: 2.5202863216400146
Validation loss: 2.2230731415492233

Epoch: 5| Step: 3
Training loss: 2.4715795516967773
Validation loss: 2.19809651759363

Epoch: 5| Step: 4
Training loss: 2.399292469024658
Validation loss: 2.1864021439706125

Epoch: 5| Step: 5
Training loss: 3.1470913887023926
Validation loss: 2.179949196436072

Epoch: 5| Step: 6
Training loss: 2.624833345413208
Validation loss: 2.1850818716069704

Epoch: 5| Step: 7
Training loss: 2.251534938812256
Validation loss: 2.180828522610408

Epoch: 5| Step: 8
Training loss: 2.3781399726867676
Validation loss: 2.183702384271929

Epoch: 5| Step: 9
Training loss: 2.915879726409912
Validation loss: 2.183054240801001

Epoch: 5| Step: 10
Training loss: 2.349477529525757
Validation loss: 2.18334617922383

Epoch: 88| Step: 0
Training loss: 2.1986947059631348
Validation loss: 2.1810370363214964

Epoch: 5| Step: 1
Training loss: 2.3489832878112793
Validation loss: 2.1832694661232734

Epoch: 5| Step: 2
Training loss: 2.436328411102295
Validation loss: 2.2005715703451507

Epoch: 5| Step: 3
Training loss: 2.809782028198242
Validation loss: 2.255114524595199

Epoch: 5| Step: 4
Training loss: 2.4724979400634766
Validation loss: 2.3097254307039323

Epoch: 5| Step: 5
Training loss: 3.04512095451355
Validation loss: 2.3221231609262447

Epoch: 5| Step: 6
Training loss: 1.8081605434417725
Validation loss: 2.2997646665060394

Epoch: 5| Step: 7
Training loss: 2.626131296157837
Validation loss: 2.240629542258478

Epoch: 5| Step: 8
Training loss: 2.450293779373169
Validation loss: 2.1965278681888374

Epoch: 5| Step: 9
Training loss: 2.696875810623169
Validation loss: 2.1775751203619023

Epoch: 5| Step: 10
Training loss: 2.6427063941955566
Validation loss: 2.168861066141436

Epoch: 89| Step: 0
Training loss: 2.6521658897399902
Validation loss: 2.1827866313278035

Epoch: 5| Step: 1
Training loss: 2.0571706295013428
Validation loss: 2.1935390733903453

Epoch: 5| Step: 2
Training loss: 3.1005501747131348
Validation loss: 2.195734344502931

Epoch: 5| Step: 3
Training loss: 2.6438651084899902
Validation loss: 2.1927027228058025

Epoch: 5| Step: 4
Training loss: 2.9582901000976562
Validation loss: 2.192821284776093

Epoch: 5| Step: 5
Training loss: 2.2896604537963867
Validation loss: 2.1914076164204586

Epoch: 5| Step: 6
Training loss: 2.313366413116455
Validation loss: 2.186920876144081

Epoch: 5| Step: 7
Training loss: 2.6090025901794434
Validation loss: 2.1869140876236783

Epoch: 5| Step: 8
Training loss: 1.7525533437728882
Validation loss: 2.1829767304082073

Epoch: 5| Step: 9
Training loss: 2.7293765544891357
Validation loss: 2.1842825771659933

Epoch: 5| Step: 10
Training loss: 2.3629441261291504
Validation loss: 2.19266507446125

Epoch: 90| Step: 0
Training loss: 2.6871819496154785
Validation loss: 2.2221511717765563

Epoch: 5| Step: 1
Training loss: 2.6053466796875
Validation loss: 2.251912247750067

Epoch: 5| Step: 2
Training loss: 2.2720417976379395
Validation loss: 2.2603888998749437

Epoch: 5| Step: 3
Training loss: 2.0568110942840576
Validation loss: 2.279423080464845

Epoch: 5| Step: 4
Training loss: 2.692854404449463
Validation loss: 2.286642115603211

Epoch: 5| Step: 5
Training loss: 2.311558246612549
Validation loss: 2.3070809430973505

Epoch: 5| Step: 6
Training loss: 3.0943386554718018
Validation loss: 2.3057322168862946

Epoch: 5| Step: 7
Training loss: 2.419165849685669
Validation loss: 2.272841135660807

Epoch: 5| Step: 8
Training loss: 1.7922163009643555
Validation loss: 2.2399468909027758

Epoch: 5| Step: 9
Training loss: 2.8856654167175293
Validation loss: 2.2060902259683095

Epoch: 5| Step: 10
Training loss: 2.511652708053589
Validation loss: 2.17469532515413

Epoch: 91| Step: 0
Training loss: 2.3767199516296387
Validation loss: 2.163157557928434

Epoch: 5| Step: 1
Training loss: 2.532163143157959
Validation loss: 2.157438616598806

Epoch: 5| Step: 2
Training loss: 1.8714373111724854
Validation loss: 2.156809478677729

Epoch: 5| Step: 3
Training loss: 2.7337117195129395
Validation loss: 2.1547966926328597

Epoch: 5| Step: 4
Training loss: 2.3207907676696777
Validation loss: 2.1504268415512575

Epoch: 5| Step: 5
Training loss: 2.6578166484832764
Validation loss: 2.1553749410055016

Epoch: 5| Step: 6
Training loss: 2.598294496536255
Validation loss: 2.166027776656612

Epoch: 5| Step: 7
Training loss: 2.531461715698242
Validation loss: 2.179609878088838

Epoch: 5| Step: 8
Training loss: 2.0187828540802
Validation loss: 2.1854297807139735

Epoch: 5| Step: 9
Training loss: 3.171337842941284
Validation loss: 2.195325477148897

Epoch: 5| Step: 10
Training loss: 2.2879831790924072
Validation loss: 2.2244253338024182

Epoch: 92| Step: 0
Training loss: 2.391472578048706
Validation loss: 2.224747186066002

Epoch: 5| Step: 1
Training loss: 2.403059482574463
Validation loss: 2.1955387387224423

Epoch: 5| Step: 2
Training loss: 2.765130043029785
Validation loss: 2.1869996158025597

Epoch: 5| Step: 3
Training loss: 1.8775570392608643
Validation loss: 2.194671271949686

Epoch: 5| Step: 4
Training loss: 1.8642055988311768
Validation loss: 2.1898376864771687

Epoch: 5| Step: 5
Training loss: 2.1098053455352783
Validation loss: 2.2087829651371127

Epoch: 5| Step: 6
Training loss: 2.550584077835083
Validation loss: 2.2299901849480084

Epoch: 5| Step: 7
Training loss: 2.71321702003479
Validation loss: 2.2468611142968618

Epoch: 5| Step: 8
Training loss: 2.874706745147705
Validation loss: 2.21796158564988

Epoch: 5| Step: 9
Training loss: 2.1333649158477783
Validation loss: 2.1942208479809504

Epoch: 5| Step: 10
Training loss: 3.5140271186828613
Validation loss: 2.177096600173622

Epoch: 93| Step: 0
Training loss: 2.2226452827453613
Validation loss: 2.1902009876825477

Epoch: 5| Step: 1
Training loss: 2.097292423248291
Validation loss: 2.189919883205045

Epoch: 5| Step: 2
Training loss: 2.814875602722168
Validation loss: 2.2134015585786555

Epoch: 5| Step: 3
Training loss: 2.5794312953948975
Validation loss: 2.228996302491875

Epoch: 5| Step: 4
Training loss: 2.549867630004883
Validation loss: 2.220667923650434

Epoch: 5| Step: 5
Training loss: 2.27526593208313
Validation loss: 2.208962691727505

Epoch: 5| Step: 6
Training loss: 2.5369789600372314
Validation loss: 2.2007503150611796

Epoch: 5| Step: 7
Training loss: 2.004427671432495
Validation loss: 2.1792422315125823

Epoch: 5| Step: 8
Training loss: 2.832702159881592
Validation loss: 2.169215412550075

Epoch: 5| Step: 9
Training loss: 2.4966189861297607
Validation loss: 2.1679729159160326

Epoch: 5| Step: 10
Training loss: 2.5982205867767334
Validation loss: 2.167214898652928

Epoch: 94| Step: 0
Training loss: 2.290405035018921
Validation loss: 2.156424532654465

Epoch: 5| Step: 1
Training loss: 2.710911512374878
Validation loss: 2.1600819967126332

Epoch: 5| Step: 2
Training loss: 2.7921595573425293
Validation loss: 2.155390598440683

Epoch: 5| Step: 3
Training loss: 2.259840965270996
Validation loss: 2.143221776972535

Epoch: 5| Step: 4
Training loss: 1.8923801183700562
Validation loss: 2.1524808483739055

Epoch: 5| Step: 5
Training loss: 2.435875415802002
Validation loss: 2.1521507232419905

Epoch: 5| Step: 6
Training loss: 2.412787437438965
Validation loss: 2.147063592428802

Epoch: 5| Step: 7
Training loss: 2.837543487548828
Validation loss: 2.1568747592228714

Epoch: 5| Step: 8
Training loss: 2.3156285285949707
Validation loss: 2.1545568589241273

Epoch: 5| Step: 9
Training loss: 2.3060126304626465
Validation loss: 2.163086937319848

Epoch: 5| Step: 10
Training loss: 2.623450517654419
Validation loss: 2.164999182506274

Epoch: 95| Step: 0
Training loss: 2.768847942352295
Validation loss: 2.1593982263277938

Epoch: 5| Step: 1
Training loss: 2.6203789710998535
Validation loss: 2.1633889982777257

Epoch: 5| Step: 2
Training loss: 2.8077845573425293
Validation loss: 2.1589893423100954

Epoch: 5| Step: 3
Training loss: 2.0649521350860596
Validation loss: 2.1622937815163725

Epoch: 5| Step: 4
Training loss: 3.1733202934265137
Validation loss: 2.1640160904135755

Epoch: 5| Step: 5
Training loss: 2.1292498111724854
Validation loss: 2.168637275695801

Epoch: 5| Step: 6
Training loss: 2.466524839401245
Validation loss: 2.170032757584767

Epoch: 5| Step: 7
Training loss: 2.588043451309204
Validation loss: 2.1616718128163326

Epoch: 5| Step: 8
Training loss: 1.6868492364883423
Validation loss: 2.169532820742617

Epoch: 5| Step: 9
Training loss: 2.0034873485565186
Validation loss: 2.1811049856165403

Epoch: 5| Step: 10
Training loss: 2.361959934234619
Validation loss: 2.1902484022161013

Epoch: 96| Step: 0
Training loss: 2.7525665760040283
Validation loss: 2.179564033785174

Epoch: 5| Step: 1
Training loss: 2.246476411819458
Validation loss: 2.162839428071053

Epoch: 5| Step: 2
Training loss: 2.5275638103485107
Validation loss: 2.155848439021777

Epoch: 5| Step: 3
Training loss: 2.410212516784668
Validation loss: 2.1612221528125066

Epoch: 5| Step: 4
Training loss: 1.6941654682159424
Validation loss: 2.1585951953805904

Epoch: 5| Step: 5
Training loss: 2.7031829357147217
Validation loss: 2.1581163508917696

Epoch: 5| Step: 6
Training loss: 2.13517689704895
Validation loss: 2.1616475710304837

Epoch: 5| Step: 7
Training loss: 2.9011826515197754
Validation loss: 2.158001915101082

Epoch: 5| Step: 8
Training loss: 2.350874423980713
Validation loss: 2.150733296589185

Epoch: 5| Step: 9
Training loss: 2.399810791015625
Validation loss: 2.144700796373429

Epoch: 5| Step: 10
Training loss: 2.492558717727661
Validation loss: 2.140896445961409

Epoch: 97| Step: 0
Training loss: 2.3825273513793945
Validation loss: 2.138145564704813

Epoch: 5| Step: 1
Training loss: 2.4623939990997314
Validation loss: 2.1447616751476

Epoch: 5| Step: 2
Training loss: 1.9853827953338623
Validation loss: 2.143783992336642

Epoch: 5| Step: 3
Training loss: 2.123300552368164
Validation loss: 2.1611365297789216

Epoch: 5| Step: 4
Training loss: 2.879479169845581
Validation loss: 2.16293651698738

Epoch: 5| Step: 5
Training loss: 3.002732753753662
Validation loss: 2.16243754407411

Epoch: 5| Step: 6
Training loss: 2.149168014526367
Validation loss: 2.155135816143405

Epoch: 5| Step: 7
Training loss: 2.644962787628174
Validation loss: 2.146093681294431

Epoch: 5| Step: 8
Training loss: 2.0695624351501465
Validation loss: 2.1478145840347453

Epoch: 5| Step: 9
Training loss: 2.4284865856170654
Validation loss: 2.147066577788322

Epoch: 5| Step: 10
Training loss: 2.3819313049316406
Validation loss: 2.146119902210851

Epoch: 98| Step: 0
Training loss: 2.2682576179504395
Validation loss: 2.133921892412247

Epoch: 5| Step: 1
Training loss: 2.7854533195495605
Validation loss: 2.132226820914976

Epoch: 5| Step: 2
Training loss: 2.678835391998291
Validation loss: 2.14433148343076

Epoch: 5| Step: 3
Training loss: 2.681161403656006
Validation loss: 2.137452939505218

Epoch: 5| Step: 4
Training loss: 2.134812593460083
Validation loss: 2.1493833693124915

Epoch: 5| Step: 5
Training loss: 2.629406452178955
Validation loss: 2.144507090250651

Epoch: 5| Step: 6
Training loss: 1.9992605447769165
Validation loss: 2.1423664644200313

Epoch: 5| Step: 7
Training loss: 2.408909320831299
Validation loss: 2.1488968262108425

Epoch: 5| Step: 8
Training loss: 2.659914493560791
Validation loss: 2.143769253966629

Epoch: 5| Step: 9
Training loss: 2.332627058029175
Validation loss: 2.149114103727443

Epoch: 5| Step: 10
Training loss: 2.07357120513916
Validation loss: 2.1528440060154086

Epoch: 99| Step: 0
Training loss: 2.4857139587402344
Validation loss: 2.1667990479418027

Epoch: 5| Step: 1
Training loss: 2.131744861602783
Validation loss: 2.1815859092179166

Epoch: 5| Step: 2
Training loss: 2.805987596511841
Validation loss: 2.1922474753472114

Epoch: 5| Step: 3
Training loss: 2.30118727684021
Validation loss: 2.1862619000096477

Epoch: 5| Step: 4
Training loss: 2.4371304512023926
Validation loss: 2.152530775275282

Epoch: 5| Step: 5
Training loss: 2.3762714862823486
Validation loss: 2.1406311578648065

Epoch: 5| Step: 6
Training loss: 1.9855196475982666
Validation loss: 2.1308809377813853

Epoch: 5| Step: 7
Training loss: 2.1089935302734375
Validation loss: 2.133489474173515

Epoch: 5| Step: 8
Training loss: 2.768342971801758
Validation loss: 2.128479193615657

Epoch: 5| Step: 9
Training loss: 3.203200578689575
Validation loss: 2.1236714291316208

Epoch: 5| Step: 10
Training loss: 1.827573299407959
Validation loss: 2.1252849063565655

Epoch: 100| Step: 0
Training loss: 2.4998459815979004
Validation loss: 2.1285631349009853

Epoch: 5| Step: 1
Training loss: 2.146538734436035
Validation loss: 2.12378845419935

Epoch: 5| Step: 2
Training loss: 2.2370238304138184
Validation loss: 2.125711743549634

Epoch: 5| Step: 3
Training loss: 1.819911241531372
Validation loss: 2.1241755588080293

Epoch: 5| Step: 4
Training loss: 2.034611225128174
Validation loss: 2.125698794600784

Epoch: 5| Step: 5
Training loss: 3.0497028827667236
Validation loss: 2.1368279367364864

Epoch: 5| Step: 6
Training loss: 2.7382099628448486
Validation loss: 2.1311904281698246

Epoch: 5| Step: 7
Training loss: 2.390495777130127
Validation loss: 2.134011548052552

Epoch: 5| Step: 8
Training loss: 2.432955265045166
Validation loss: 2.156301377921976

Epoch: 5| Step: 9
Training loss: 2.4643471240997314
Validation loss: 2.1723277440635105

Epoch: 5| Step: 10
Training loss: 2.681209087371826
Validation loss: 2.177249062445856

Epoch: 101| Step: 0
Training loss: 2.4119439125061035
Validation loss: 2.1845346214950725

Epoch: 5| Step: 1
Training loss: 1.9833228588104248
Validation loss: 2.1611436054270756

Epoch: 5| Step: 2
Training loss: 2.497847080230713
Validation loss: 2.1373165858689176

Epoch: 5| Step: 3
Training loss: 3.000535488128662
Validation loss: 2.1295153735786356

Epoch: 5| Step: 4
Training loss: 2.2560126781463623
Validation loss: 2.122794953725671

Epoch: 5| Step: 5
Training loss: 2.0540335178375244
Validation loss: 2.1223701405268844

Epoch: 5| Step: 6
Training loss: 2.8615341186523438
Validation loss: 2.1155074693823375

Epoch: 5| Step: 7
Training loss: 2.5583510398864746
Validation loss: 2.120136462232118

Epoch: 5| Step: 8
Training loss: 2.0934834480285645
Validation loss: 2.1252581688665573

Epoch: 5| Step: 9
Training loss: 2.1916394233703613
Validation loss: 2.1379770514785603

Epoch: 5| Step: 10
Training loss: 2.6473488807678223
Validation loss: 2.1484516333508235

Epoch: 102| Step: 0
Training loss: 2.1775615215301514
Validation loss: 2.1618885532502206

Epoch: 5| Step: 1
Training loss: 2.8793270587921143
Validation loss: 2.1684599179093555

Epoch: 5| Step: 2
Training loss: 3.253830671310425
Validation loss: 2.165966700482112

Epoch: 5| Step: 3
Training loss: 2.0347256660461426
Validation loss: 2.1734545410320325

Epoch: 5| Step: 4
Training loss: 1.7171318531036377
Validation loss: 2.1879206113917853

Epoch: 5| Step: 5
Training loss: 2.515803813934326
Validation loss: 2.1828035949378886

Epoch: 5| Step: 6
Training loss: 2.2485909461975098
Validation loss: 2.1624981946842645

Epoch: 5| Step: 7
Training loss: 2.8228113651275635
Validation loss: 2.143227215736143

Epoch: 5| Step: 8
Training loss: 2.301071882247925
Validation loss: 2.124022824789888

Epoch: 5| Step: 9
Training loss: 2.429316282272339
Validation loss: 2.1309201819922334

Epoch: 5| Step: 10
Training loss: 2.080212116241455
Validation loss: 2.1289965388595418

Epoch: 103| Step: 0
Training loss: 1.9995590448379517
Validation loss: 2.129222895509453

Epoch: 5| Step: 1
Training loss: 2.467921733856201
Validation loss: 2.1258333036976476

Epoch: 5| Step: 2
Training loss: 2.4208600521087646
Validation loss: 2.1408149862802155

Epoch: 5| Step: 3
Training loss: 3.0154051780700684
Validation loss: 2.152749833240304

Epoch: 5| Step: 4
Training loss: 2.3757433891296387
Validation loss: 2.159838076560728

Epoch: 5| Step: 5
Training loss: 2.6199562549591064
Validation loss: 2.177764155531442

Epoch: 5| Step: 6
Training loss: 1.8810575008392334
Validation loss: 2.1688624351255354

Epoch: 5| Step: 7
Training loss: 2.1305031776428223
Validation loss: 2.168511905977803

Epoch: 5| Step: 8
Training loss: 2.7227420806884766
Validation loss: 2.151845201369255

Epoch: 5| Step: 9
Training loss: 2.9482505321502686
Validation loss: 2.1213374317333265

Epoch: 5| Step: 10
Training loss: 1.6058565378189087
Validation loss: 2.1093571160429265

Epoch: 104| Step: 0
Training loss: 2.3966991901397705
Validation loss: 2.1084733368248068

Epoch: 5| Step: 1
Training loss: 2.7520878314971924
Validation loss: 2.1011995474497476

Epoch: 5| Step: 2
Training loss: 2.3868918418884277
Validation loss: 2.0993658573396745

Epoch: 5| Step: 3
Training loss: 2.3285574913024902
Validation loss: 2.097397688896425

Epoch: 5| Step: 4
Training loss: 2.578965902328491
Validation loss: 2.096736600322108

Epoch: 5| Step: 5
Training loss: 2.9346344470977783
Validation loss: 2.0958137589116252

Epoch: 5| Step: 6
Training loss: 2.1918647289276123
Validation loss: 2.0990221000486806

Epoch: 5| Step: 7
Training loss: 1.8900668621063232
Validation loss: 2.0990440614761843

Epoch: 5| Step: 8
Training loss: 2.0090060234069824
Validation loss: 2.1300423196567

Epoch: 5| Step: 9
Training loss: 1.9397796392440796
Validation loss: 2.138861479297761

Epoch: 5| Step: 10
Training loss: 2.9952950477600098
Validation loss: 2.154771502299975

Epoch: 105| Step: 0
Training loss: 2.3049230575561523
Validation loss: 2.145382711964269

Epoch: 5| Step: 1
Training loss: 2.599748373031616
Validation loss: 2.1644612307189615

Epoch: 5| Step: 2
Training loss: 3.2681736946105957
Validation loss: 2.1528106094688497

Epoch: 5| Step: 3
Training loss: 2.5717015266418457
Validation loss: 2.1272703473285963

Epoch: 5| Step: 4
Training loss: 1.967442274093628
Validation loss: 2.1163923560932116

Epoch: 5| Step: 5
Training loss: 1.8879855871200562
Validation loss: 2.1079178356355235

Epoch: 5| Step: 6
Training loss: 2.5575802326202393
Validation loss: 2.1037324295249036

Epoch: 5| Step: 7
Training loss: 1.8334897756576538
Validation loss: 2.110860765621226

Epoch: 5| Step: 8
Training loss: 2.6500039100646973
Validation loss: 2.10273733703039

Epoch: 5| Step: 9
Training loss: 2.217592477798462
Validation loss: 2.114032099323888

Epoch: 5| Step: 10
Training loss: 2.3269760608673096
Validation loss: 2.120498937945212

Epoch: 106| Step: 0
Training loss: 2.839609384536743
Validation loss: 2.139690381224437

Epoch: 5| Step: 1
Training loss: 2.962308883666992
Validation loss: 2.149857582584504

Epoch: 5| Step: 2
Training loss: 2.858903408050537
Validation loss: 2.122756245315716

Epoch: 5| Step: 3
Training loss: 1.6992725133895874
Validation loss: 2.1088458107363794

Epoch: 5| Step: 4
Training loss: 2.120790958404541
Validation loss: 2.106650208914152

Epoch: 5| Step: 5
Training loss: 2.55468487739563
Validation loss: 2.1075747090001262

Epoch: 5| Step: 6
Training loss: 2.81438946723938
Validation loss: 2.1090004597940752

Epoch: 5| Step: 7
Training loss: 2.6942732334136963
Validation loss: 2.120339898652928

Epoch: 5| Step: 8
Training loss: 1.7808942794799805
Validation loss: 2.175031841442149

Epoch: 5| Step: 9
Training loss: 1.969115972518921
Validation loss: 2.2577362086183284

Epoch: 5| Step: 10
Training loss: 2.1053531169891357
Validation loss: 2.237767688689693

Epoch: 107| Step: 0
Training loss: 2.2025063037872314
Validation loss: 2.1927745675527923

Epoch: 5| Step: 1
Training loss: 2.6728551387786865
Validation loss: 2.1650981198075

Epoch: 5| Step: 2
Training loss: 2.638587236404419
Validation loss: 2.135545035844208

Epoch: 5| Step: 3
Training loss: 1.9707508087158203
Validation loss: 2.1265150141972367

Epoch: 5| Step: 4
Training loss: 2.2005012035369873
Validation loss: 2.114406101165279

Epoch: 5| Step: 5
Training loss: 3.2060446739196777
Validation loss: 2.1198276499266266

Epoch: 5| Step: 6
Training loss: 2.576014995574951
Validation loss: 2.122085604616391

Epoch: 5| Step: 7
Training loss: 1.6655582189559937
Validation loss: 2.1531386016517557

Epoch: 5| Step: 8
Training loss: 1.8045917749404907
Validation loss: 2.13526060247934

Epoch: 5| Step: 9
Training loss: 2.19836163520813
Validation loss: 2.1259539588805167

Epoch: 5| Step: 10
Training loss: 3.2173593044281006
Validation loss: 2.1243130366007485

Epoch: 108| Step: 0
Training loss: 2.2515876293182373
Validation loss: 2.1123194899610294

Epoch: 5| Step: 1
Training loss: 1.9471228122711182
Validation loss: 2.116313156261239

Epoch: 5| Step: 2
Training loss: 2.407932758331299
Validation loss: 2.118975629088699

Epoch: 5| Step: 3
Training loss: 2.4704830646514893
Validation loss: 2.1267917002401044

Epoch: 5| Step: 4
Training loss: 2.335334062576294
Validation loss: 2.1266267453470538

Epoch: 5| Step: 5
Training loss: 2.371056079864502
Validation loss: 2.1143935239443215

Epoch: 5| Step: 6
Training loss: 2.245166063308716
Validation loss: 2.109437588722475

Epoch: 5| Step: 7
Training loss: 2.380496025085449
Validation loss: 2.1157949842432493

Epoch: 5| Step: 8
Training loss: 2.6591546535491943
Validation loss: 2.1255793494562947

Epoch: 5| Step: 9
Training loss: 2.9508368968963623
Validation loss: 2.1398056014891593

Epoch: 5| Step: 10
Training loss: 2.300281286239624
Validation loss: 2.1346750233763006

Epoch: 109| Step: 0
Training loss: 1.2133241891860962
Validation loss: 2.1351182588966946

Epoch: 5| Step: 1
Training loss: 3.3339900970458984
Validation loss: 2.141154207209105

Epoch: 5| Step: 2
Training loss: 2.389946699142456
Validation loss: 2.1371786414936023

Epoch: 5| Step: 3
Training loss: 2.517958164215088
Validation loss: 2.1260070044507264

Epoch: 5| Step: 4
Training loss: 2.688389301300049
Validation loss: 2.134347023502473

Epoch: 5| Step: 5
Training loss: 3.3879234790802
Validation loss: 2.1147257128069477

Epoch: 5| Step: 6
Training loss: 2.2587249279022217
Validation loss: 2.10761603488717

Epoch: 5| Step: 7
Training loss: 2.3872923851013184
Validation loss: 2.1049162316065964

Epoch: 5| Step: 8
Training loss: 1.611406922340393
Validation loss: 2.098323598984749

Epoch: 5| Step: 9
Training loss: 2.176598310470581
Validation loss: 2.085710440912554

Epoch: 5| Step: 10
Training loss: 1.996192455291748
Validation loss: 2.082308546189339

Epoch: 110| Step: 0
Training loss: 2.7792067527770996
Validation loss: 2.086336197391633

Epoch: 5| Step: 1
Training loss: 2.1637868881225586
Validation loss: 2.0873214057696763

Epoch: 5| Step: 2
Training loss: 2.453547954559326
Validation loss: 2.088600292000719

Epoch: 5| Step: 3
Training loss: 2.3905951976776123
Validation loss: 2.1021237232351817

Epoch: 5| Step: 4
Training loss: 1.9971435070037842
Validation loss: 2.101705389638101

Epoch: 5| Step: 5
Training loss: 2.112914800643921
Validation loss: 2.0884896785982194

Epoch: 5| Step: 6
Training loss: 2.5264220237731934
Validation loss: 2.079717514335468

Epoch: 5| Step: 7
Training loss: 2.2113404273986816
Validation loss: 2.0778139047725226

Epoch: 5| Step: 8
Training loss: 2.48808217048645
Validation loss: 2.0779913586954915

Epoch: 5| Step: 9
Training loss: 2.6723437309265137
Validation loss: 2.0813988870190037

Epoch: 5| Step: 10
Training loss: 2.0163910388946533
Validation loss: 2.0816568482306694

Epoch: 111| Step: 0
Training loss: 2.133479356765747
Validation loss: 2.075383614468318

Epoch: 5| Step: 1
Training loss: 2.400756597518921
Validation loss: 2.0733469827200777

Epoch: 5| Step: 2
Training loss: 2.691176176071167
Validation loss: 2.0793589776562107

Epoch: 5| Step: 3
Training loss: 2.005896806716919
Validation loss: 2.076425826677712

Epoch: 5| Step: 4
Training loss: 2.8278350830078125
Validation loss: 2.073505896393971

Epoch: 5| Step: 5
Training loss: 1.8101394176483154
Validation loss: 2.0835116063394854

Epoch: 5| Step: 6
Training loss: 2.4503703117370605
Validation loss: 2.0898669124931417

Epoch: 5| Step: 7
Training loss: 2.8814985752105713
Validation loss: 2.097870421665971

Epoch: 5| Step: 8
Training loss: 1.9646155834197998
Validation loss: 2.1028637578410487

Epoch: 5| Step: 9
Training loss: 2.316781759262085
Validation loss: 2.112948968846311

Epoch: 5| Step: 10
Training loss: 2.2376596927642822
Validation loss: 2.1137507295095794

Epoch: 112| Step: 0
Training loss: 2.013824462890625
Validation loss: 2.092025383826225

Epoch: 5| Step: 1
Training loss: 2.4591171741485596
Validation loss: 2.0942485614489486

Epoch: 5| Step: 2
Training loss: 1.9754326343536377
Validation loss: 2.0903737980832338

Epoch: 5| Step: 3
Training loss: 2.5658719539642334
Validation loss: 2.0905278382762784

Epoch: 5| Step: 4
Training loss: 2.494194746017456
Validation loss: 2.0926916855637745

Epoch: 5| Step: 5
Training loss: 2.8566577434539795
Validation loss: 2.0969297193711802

Epoch: 5| Step: 6
Training loss: 2.4407265186309814
Validation loss: 2.1060553135410434

Epoch: 5| Step: 7
Training loss: 1.755836844444275
Validation loss: 2.104140614950529

Epoch: 5| Step: 8
Training loss: 2.402308940887451
Validation loss: 2.1039043395749983

Epoch: 5| Step: 9
Training loss: 2.109999895095825
Validation loss: 2.0941392593486334

Epoch: 5| Step: 10
Training loss: 2.6548051834106445
Validation loss: 2.094433815248551

Epoch: 113| Step: 0
Training loss: 2.2125401496887207
Validation loss: 2.094095055774976

Epoch: 5| Step: 1
Training loss: 2.269991636276245
Validation loss: 2.095892221696915

Epoch: 5| Step: 2
Training loss: 2.2651448249816895
Validation loss: 2.0916376806074575

Epoch: 5| Step: 3
Training loss: 2.1029810905456543
Validation loss: 2.1050944174489667

Epoch: 5| Step: 4
Training loss: 2.708944797515869
Validation loss: 2.105251021282647

Epoch: 5| Step: 5
Training loss: 1.7949069738388062
Validation loss: 2.103695697681878

Epoch: 5| Step: 6
Training loss: 2.8261594772338867
Validation loss: 2.1066181813516924

Epoch: 5| Step: 7
Training loss: 2.6329827308654785
Validation loss: 2.1008302242525163

Epoch: 5| Step: 8
Training loss: 2.3013179302215576
Validation loss: 2.101529716163553

Epoch: 5| Step: 9
Training loss: 1.9457966089248657
Validation loss: 2.1013148394964074

Epoch: 5| Step: 10
Training loss: 2.381235122680664
Validation loss: 2.104504951866724

Epoch: 114| Step: 0
Training loss: 1.92550790309906
Validation loss: 2.0966463242807696

Epoch: 5| Step: 1
Training loss: 2.2686169147491455
Validation loss: 2.0859885754123813

Epoch: 5| Step: 2
Training loss: 2.2590110301971436
Validation loss: 2.082425835312054

Epoch: 5| Step: 3
Training loss: 3.502551317214966
Validation loss: 2.0633264305771037

Epoch: 5| Step: 4
Training loss: 1.7150148153305054
Validation loss: 2.074425055134681

Epoch: 5| Step: 5
Training loss: 2.2094783782958984
Validation loss: 2.074113166460427

Epoch: 5| Step: 6
Training loss: 2.194453477859497
Validation loss: 2.0835704726557576

Epoch: 5| Step: 7
Training loss: 2.248704195022583
Validation loss: 2.077844624878258

Epoch: 5| Step: 8
Training loss: 2.4168145656585693
Validation loss: 2.0887468732813352

Epoch: 5| Step: 9
Training loss: 1.7759387493133545
Validation loss: 2.0758511584292174

Epoch: 5| Step: 10
Training loss: 2.909952402114868
Validation loss: 2.0837111306446854

Epoch: 115| Step: 0
Training loss: 2.163361072540283
Validation loss: 2.101989811466586

Epoch: 5| Step: 1
Training loss: 2.4737672805786133
Validation loss: 2.119166945898405

Epoch: 5| Step: 2
Training loss: 1.9014837741851807
Validation loss: 2.149029944532661

Epoch: 5| Step: 3
Training loss: 1.9377329349517822
Validation loss: 2.15884643472651

Epoch: 5| Step: 4
Training loss: 2.2818522453308105
Validation loss: 2.171569570418327

Epoch: 5| Step: 5
Training loss: 2.377833843231201
Validation loss: 2.1604583212124404

Epoch: 5| Step: 6
Training loss: 2.168179988861084
Validation loss: 2.1129845573056127

Epoch: 5| Step: 7
Training loss: 2.674525737762451
Validation loss: 2.088664521453201

Epoch: 5| Step: 8
Training loss: 2.7512683868408203
Validation loss: 2.0843619608109996

Epoch: 5| Step: 9
Training loss: 2.4197304248809814
Validation loss: 2.0783688893882175

Epoch: 5| Step: 10
Training loss: 2.7429275512695312
Validation loss: 2.077743261091171

Epoch: 116| Step: 0
Training loss: 2.2889716625213623
Validation loss: 2.0729166384666198

Epoch: 5| Step: 1
Training loss: 2.2497241497039795
Validation loss: 2.0844280899211927

Epoch: 5| Step: 2
Training loss: 2.8433837890625
Validation loss: 2.091446686816472

Epoch: 5| Step: 3
Training loss: 2.189357042312622
Validation loss: 2.1163335692497993

Epoch: 5| Step: 4
Training loss: 1.674820899963379
Validation loss: 2.124735827087074

Epoch: 5| Step: 5
Training loss: 2.7589306831359863
Validation loss: 2.1277134777397237

Epoch: 5| Step: 6
Training loss: 2.5595498085021973
Validation loss: 2.116990645726522

Epoch: 5| Step: 7
Training loss: 2.603384494781494
Validation loss: 2.0830152316759993

Epoch: 5| Step: 8
Training loss: 1.9693591594696045
Validation loss: 2.080330502602362

Epoch: 5| Step: 9
Training loss: 2.6391208171844482
Validation loss: 2.069901811179294

Epoch: 5| Step: 10
Training loss: 1.7562357187271118
Validation loss: 2.070950778581763

Epoch: 117| Step: 0
Training loss: 2.462920665740967
Validation loss: 2.083626049821095

Epoch: 5| Step: 1
Training loss: 3.140063524246216
Validation loss: 2.0943917792330504

Epoch: 5| Step: 2
Training loss: 1.978167176246643
Validation loss: 2.0947347251317834

Epoch: 5| Step: 3
Training loss: 2.225820541381836
Validation loss: 2.0766090834012596

Epoch: 5| Step: 4
Training loss: 1.9039065837860107
Validation loss: 2.0842346888716503

Epoch: 5| Step: 5
Training loss: 1.8336169719696045
Validation loss: 2.093956849908316

Epoch: 5| Step: 6
Training loss: 2.1722664833068848
Validation loss: 2.110635257536365

Epoch: 5| Step: 7
Training loss: 2.202828884124756
Validation loss: 2.1697516159344743

Epoch: 5| Step: 8
Training loss: 3.3440468311309814
Validation loss: 2.1916567728083622

Epoch: 5| Step: 9
Training loss: 2.649379014968872
Validation loss: 2.1729113901815107

Epoch: 5| Step: 10
Training loss: 2.2017629146575928
Validation loss: 2.1356770838460615

Epoch: 118| Step: 0
Training loss: 2.3690381050109863
Validation loss: 2.1330092876188216

Epoch: 5| Step: 1
Training loss: 2.195263385772705
Validation loss: 2.107447173005791

Epoch: 5| Step: 2
Training loss: 2.0807676315307617
Validation loss: 2.090245980088429

Epoch: 5| Step: 3
Training loss: 2.4968628883361816
Validation loss: 2.0820097513096307

Epoch: 5| Step: 4
Training loss: 2.3179574012756348
Validation loss: 2.0841649937373337

Epoch: 5| Step: 5
Training loss: 2.414078712463379
Validation loss: 2.0907238247574016

Epoch: 5| Step: 6
Training loss: 1.6425203084945679
Validation loss: 2.1175041147457656

Epoch: 5| Step: 7
Training loss: 2.4432644844055176
Validation loss: 2.144265715793897

Epoch: 5| Step: 8
Training loss: 2.7631678581237793
Validation loss: 2.151936064484299

Epoch: 5| Step: 9
Training loss: 2.6344997882843018
Validation loss: 2.1132815345641105

Epoch: 5| Step: 10
Training loss: 2.2969980239868164
Validation loss: 2.1040894946744366

Epoch: 119| Step: 0
Training loss: 1.6882317066192627
Validation loss: 2.0763683498546643

Epoch: 5| Step: 1
Training loss: 2.6067404747009277
Validation loss: 2.0625142538419334

Epoch: 5| Step: 2
Training loss: 2.666670799255371
Validation loss: 2.066658937802879

Epoch: 5| Step: 3
Training loss: 2.330562114715576
Validation loss: 2.058423465298068

Epoch: 5| Step: 4
Training loss: 1.859014868736267
Validation loss: 2.055492963842166

Epoch: 5| Step: 5
Training loss: 2.00394868850708
Validation loss: 2.0561061841185375

Epoch: 5| Step: 6
Training loss: 2.417868137359619
Validation loss: 2.0644849397802867

Epoch: 5| Step: 7
Training loss: 2.4902546405792236
Validation loss: 2.081348575571532

Epoch: 5| Step: 8
Training loss: 2.3418540954589844
Validation loss: 2.0843041430237474

Epoch: 5| Step: 9
Training loss: 2.7764525413513184
Validation loss: 2.0890357007262526

Epoch: 5| Step: 10
Training loss: 2.025439739227295
Validation loss: 2.0948111908410185

Epoch: 120| Step: 0
Training loss: 2.5098330974578857
Validation loss: 2.0858901623756654

Epoch: 5| Step: 1
Training loss: 1.614192247390747
Validation loss: 2.0746862785790556

Epoch: 5| Step: 2
Training loss: 3.018843650817871
Validation loss: 2.0649590261520876

Epoch: 5| Step: 3
Training loss: 1.9707298278808594
Validation loss: 2.061922514310447

Epoch: 5| Step: 4
Training loss: 2.1659343242645264
Validation loss: 2.056605908178514

Epoch: 5| Step: 5
Training loss: 1.563743233680725
Validation loss: 2.054758130863149

Epoch: 5| Step: 6
Training loss: 2.4366774559020996
Validation loss: 2.0527830841720744

Epoch: 5| Step: 7
Training loss: 2.0175704956054688
Validation loss: 2.051437453557086

Epoch: 5| Step: 8
Training loss: 3.4437050819396973
Validation loss: 2.063955198052109

Epoch: 5| Step: 9
Training loss: 2.106417179107666
Validation loss: 2.0717136808620986

Epoch: 5| Step: 10
Training loss: 2.3484175205230713
Validation loss: 2.093145929357057

Epoch: 121| Step: 0
Training loss: 2.0098626613616943
Validation loss: 2.1010454290656635

Epoch: 5| Step: 1
Training loss: 2.412306070327759
Validation loss: 2.1578209015630905

Epoch: 5| Step: 2
Training loss: 3.00465726852417
Validation loss: 2.2520704577046056

Epoch: 5| Step: 3
Training loss: 1.7024848461151123
Validation loss: 2.206048855217554

Epoch: 5| Step: 4
Training loss: 2.449007272720337
Validation loss: 2.159799732187743

Epoch: 5| Step: 5
Training loss: 2.246209144592285
Validation loss: 2.1410350658560313

Epoch: 5| Step: 6
Training loss: 2.309931516647339
Validation loss: 2.108240177554469

Epoch: 5| Step: 7
Training loss: 2.3555564880371094
Validation loss: 2.0956785268681024

Epoch: 5| Step: 8
Training loss: 1.7177921533584595
Validation loss: 2.086506771784957

Epoch: 5| Step: 9
Training loss: 2.6331167221069336
Validation loss: 2.087941054374941

Epoch: 5| Step: 10
Training loss: 2.948798418045044
Validation loss: 2.0815394924532984

Epoch: 122| Step: 0
Training loss: 2.9173953533172607
Validation loss: 2.076211747302804

Epoch: 5| Step: 1
Training loss: 2.442274808883667
Validation loss: 2.0759614718857633

Epoch: 5| Step: 2
Training loss: 2.692474842071533
Validation loss: 2.089919149234731

Epoch: 5| Step: 3
Training loss: 2.5026192665100098
Validation loss: 2.102328926004389

Epoch: 5| Step: 4
Training loss: 1.5044713020324707
Validation loss: 2.142195527271558

Epoch: 5| Step: 5
Training loss: 2.5462403297424316
Validation loss: 2.1698789519648396

Epoch: 5| Step: 6
Training loss: 1.9077043533325195
Validation loss: 2.201406125099428

Epoch: 5| Step: 7
Training loss: 2.5128931999206543
Validation loss: 2.1803572946979153

Epoch: 5| Step: 8
Training loss: 1.9789680242538452
Validation loss: 2.147688874634363

Epoch: 5| Step: 9
Training loss: 1.61135733127594
Validation loss: 2.1004154912887083

Epoch: 5| Step: 10
Training loss: 3.222041606903076
Validation loss: 2.073292930920919

Epoch: 123| Step: 0
Training loss: 2.782613515853882
Validation loss: 2.0609407296744724

Epoch: 5| Step: 1
Training loss: 2.0510005950927734
Validation loss: 2.0570801816960818

Epoch: 5| Step: 2
Training loss: 2.416914701461792
Validation loss: 2.0547732050700853

Epoch: 5| Step: 3
Training loss: 2.4420244693756104
Validation loss: 2.0476246815855785

Epoch: 5| Step: 4
Training loss: 2.5219414234161377
Validation loss: 2.052259950227635

Epoch: 5| Step: 5
Training loss: 2.1843743324279785
Validation loss: 2.041761072733069

Epoch: 5| Step: 6
Training loss: 1.9613186120986938
Validation loss: 2.038918677196708

Epoch: 5| Step: 7
Training loss: 1.953508734703064
Validation loss: 2.022176642571726

Epoch: 5| Step: 8
Training loss: 2.566567897796631
Validation loss: 2.020488782595563

Epoch: 5| Step: 9
Training loss: 2.3172645568847656
Validation loss: 2.0161097318895402

Epoch: 5| Step: 10
Training loss: 1.9815263748168945
Validation loss: 2.0208009596793883

Epoch: 124| Step: 0
Training loss: 2.6943728923797607
Validation loss: 2.0135612346792735

Epoch: 5| Step: 1
Training loss: 2.263896942138672
Validation loss: 2.012682855770152

Epoch: 5| Step: 2
Training loss: 1.5798505544662476
Validation loss: 2.006042242050171

Epoch: 5| Step: 3
Training loss: 1.844008207321167
Validation loss: 1.9992862004105763

Epoch: 5| Step: 4
Training loss: 2.269015073776245
Validation loss: 2.0005982152877317

Epoch: 5| Step: 5
Training loss: 1.8496863842010498
Validation loss: 2.001528875802153

Epoch: 5| Step: 6
Training loss: 2.7545294761657715
Validation loss: 2.011925147425744

Epoch: 5| Step: 7
Training loss: 2.00364351272583
Validation loss: 2.012820397653887

Epoch: 5| Step: 8
Training loss: 2.270606517791748
Validation loss: 2.022733885754821

Epoch: 5| Step: 9
Training loss: 2.7742297649383545
Validation loss: 2.0464687937049457

Epoch: 5| Step: 10
Training loss: 2.541020154953003
Validation loss: 2.085011072056268

Epoch: 125| Step: 0
Training loss: 2.9457621574401855
Validation loss: 2.1034765256348478

Epoch: 5| Step: 1
Training loss: 1.968227744102478
Validation loss: 2.1061280696622786

Epoch: 5| Step: 2
Training loss: 2.451028823852539
Validation loss: 2.053508250944076

Epoch: 5| Step: 3
Training loss: 1.7366310358047485
Validation loss: 2.013093508699889

Epoch: 5| Step: 4
Training loss: 2.4711506366729736
Validation loss: 2.0084274930338704

Epoch: 5| Step: 5
Training loss: 1.9674123525619507
Validation loss: 2.010534122426023

Epoch: 5| Step: 6
Training loss: 1.9298824071884155
Validation loss: 2.0152159749820666

Epoch: 5| Step: 7
Training loss: 2.4173312187194824
Validation loss: 2.0336063664446593

Epoch: 5| Step: 8
Training loss: 2.4825196266174316
Validation loss: 2.0384449048708846

Epoch: 5| Step: 9
Training loss: 1.7342548370361328
Validation loss: 2.0356576724718978

Epoch: 5| Step: 10
Training loss: 3.1034352779388428
Validation loss: 2.0520556203780638

Epoch: 126| Step: 0
Training loss: 2.778874158859253
Validation loss: 2.057355183427052

Epoch: 5| Step: 1
Training loss: 1.9543501138687134
Validation loss: 2.112504105414114

Epoch: 5| Step: 2
Training loss: 1.8008754253387451
Validation loss: 2.1302972685906196

Epoch: 5| Step: 3
Training loss: 2.298100233078003
Validation loss: 2.1821777243768015

Epoch: 5| Step: 4
Training loss: 2.6670665740966797
Validation loss: 2.2062660186521468

Epoch: 5| Step: 5
Training loss: 2.138693332672119
Validation loss: 2.1725274798690632

Epoch: 5| Step: 6
Training loss: 2.118147373199463
Validation loss: 2.113764114277337

Epoch: 5| Step: 7
Training loss: 1.923783540725708
Validation loss: 2.099646883626138

Epoch: 5| Step: 8
Training loss: 2.795163631439209
Validation loss: 2.081119134861936

Epoch: 5| Step: 9
Training loss: 2.659306287765503
Validation loss: 2.0936436217318297

Epoch: 5| Step: 10
Training loss: 2.4050791263580322
Validation loss: 2.0947331920746834

Epoch: 127| Step: 0
Training loss: 2.587672233581543
Validation loss: 2.0903347820364018

Epoch: 5| Step: 1
Training loss: 2.7037384510040283
Validation loss: 2.0956866997544483

Epoch: 5| Step: 2
Training loss: 2.093496561050415
Validation loss: 2.0867193693755777

Epoch: 5| Step: 3
Training loss: 2.9994187355041504
Validation loss: 2.051542483350282

Epoch: 5| Step: 4
Training loss: 1.5042804479599
Validation loss: 2.0395135494970504

Epoch: 5| Step: 5
Training loss: 2.0671632289886475
Validation loss: 2.0748714234239314

Epoch: 5| Step: 6
Training loss: 1.7931737899780273
Validation loss: 2.092632257810203

Epoch: 5| Step: 7
Training loss: 2.3774380683898926
Validation loss: 2.1362500677826586

Epoch: 5| Step: 8
Training loss: 2.489905595779419
Validation loss: 2.158260617204892

Epoch: 5| Step: 9
Training loss: 2.6742968559265137
Validation loss: 2.1716985202604726

Epoch: 5| Step: 10
Training loss: 2.190286636352539
Validation loss: 2.152449543758105

Epoch: 128| Step: 0
Training loss: 2.8718714714050293
Validation loss: 2.13215394173899

Epoch: 5| Step: 1
Training loss: 2.081761598587036
Validation loss: 2.069357059335196

Epoch: 5| Step: 2
Training loss: 1.9497514963150024
Validation loss: 2.0251464779658983

Epoch: 5| Step: 3
Training loss: 1.9366137981414795
Validation loss: 1.9969522132668445

Epoch: 5| Step: 4
Training loss: 2.386528491973877
Validation loss: 1.991928159549672

Epoch: 5| Step: 5
Training loss: 2.120697498321533
Validation loss: 2.005107725820234

Epoch: 5| Step: 6
Training loss: 2.73371958732605
Validation loss: 2.014378119540471

Epoch: 5| Step: 7
Training loss: 2.2062251567840576
Validation loss: 2.0150704935032833

Epoch: 5| Step: 8
Training loss: 2.466780424118042
Validation loss: 2.032565075864074

Epoch: 5| Step: 9
Training loss: 1.7694743871688843
Validation loss: 2.0429755359567623

Epoch: 5| Step: 10
Training loss: 2.386819839477539
Validation loss: 2.072817046155212

Epoch: 129| Step: 0
Training loss: 3.280579090118408
Validation loss: 2.0704961476787442

Epoch: 5| Step: 1
Training loss: 2.054616928100586
Validation loss: 2.0654649388405586

Epoch: 5| Step: 2
Training loss: 2.4514098167419434
Validation loss: 2.0739010867252143

Epoch: 5| Step: 3
Training loss: 2.067470073699951
Validation loss: 2.063375337149507

Epoch: 5| Step: 4
Training loss: 1.86859929561615
Validation loss: 2.051864508659609

Epoch: 5| Step: 5
Training loss: 1.7393566370010376
Validation loss: 2.024313299886642

Epoch: 5| Step: 6
Training loss: 2.116328239440918
Validation loss: 2.0251345339641778

Epoch: 5| Step: 7
Training loss: 1.8684263229370117
Validation loss: 2.023585614337716

Epoch: 5| Step: 8
Training loss: 2.7147536277770996
Validation loss: 2.0276536121163318

Epoch: 5| Step: 9
Training loss: 2.304156541824341
Validation loss: 2.0344091589732836

Epoch: 5| Step: 10
Training loss: 1.9721733331680298
Validation loss: 2.0472350889636624

Epoch: 130| Step: 0
Training loss: 2.1864171028137207
Validation loss: 2.0545156796773276

Epoch: 5| Step: 1
Training loss: 2.1462416648864746
Validation loss: 2.0701881198472876

Epoch: 5| Step: 2
Training loss: 2.7870068550109863
Validation loss: 2.0827963736749466

Epoch: 5| Step: 3
Training loss: 2.456505060195923
Validation loss: 2.1033398553889286

Epoch: 5| Step: 4
Training loss: 2.2124364376068115
Validation loss: 2.111213682800211

Epoch: 5| Step: 5
Training loss: 1.8181511163711548
Validation loss: 2.100204575446344

Epoch: 5| Step: 6
Training loss: 1.834716796875
Validation loss: 2.086447549122636

Epoch: 5| Step: 7
Training loss: 2.152147054672241
Validation loss: 2.0719299380497267

Epoch: 5| Step: 8
Training loss: 1.4199185371398926
Validation loss: 2.0724909254299697

Epoch: 5| Step: 9
Training loss: 2.404611110687256
Validation loss: 2.057625444986487

Epoch: 5| Step: 10
Training loss: 3.1555073261260986
Validation loss: 2.055597065597452

Epoch: 131| Step: 0
Training loss: 2.2986743450164795
Validation loss: 2.047133182966581

Epoch: 5| Step: 1
Training loss: 1.4585195779800415
Validation loss: 2.0194528307966007

Epoch: 5| Step: 2
Training loss: 2.1415603160858154
Validation loss: 2.010528809280806

Epoch: 5| Step: 3
Training loss: 1.8771259784698486
Validation loss: 2.002257844453217

Epoch: 5| Step: 4
Training loss: 2.207768201828003
Validation loss: 2.0020628731737853

Epoch: 5| Step: 5
Training loss: 2.4686028957366943
Validation loss: 2.0004867328110563

Epoch: 5| Step: 6
Training loss: 2.3058581352233887
Validation loss: 1.9863741961858605

Epoch: 5| Step: 7
Training loss: 2.432892084121704
Validation loss: 1.9816888096512004

Epoch: 5| Step: 8
Training loss: 2.2949347496032715
Validation loss: 1.9826025142464587

Epoch: 5| Step: 9
Training loss: 2.115438938140869
Validation loss: 1.9877787918172858

Epoch: 5| Step: 10
Training loss: 2.615028142929077
Validation loss: 2.0033867359161377

Epoch: 132| Step: 0
Training loss: 2.159986972808838
Validation loss: 2.031219555485633

Epoch: 5| Step: 1
Training loss: 2.220846652984619
Validation loss: 2.039070875413956

Epoch: 5| Step: 2
Training loss: 2.6291556358337402
Validation loss: 2.057324124920753

Epoch: 5| Step: 3
Training loss: 1.9752880334854126
Validation loss: 2.0678488798038934

Epoch: 5| Step: 4
Training loss: 2.2934422492980957
Validation loss: 2.0521137252930672

Epoch: 5| Step: 5
Training loss: 2.1677937507629395
Validation loss: 2.0399270788315804

Epoch: 5| Step: 6
Training loss: 1.870883584022522
Validation loss: 2.0028424686001194

Epoch: 5| Step: 7
Training loss: 2.0759692192077637
Validation loss: 1.9776503116853776

Epoch: 5| Step: 8
Training loss: 2.680208444595337
Validation loss: 1.9726465953293668

Epoch: 5| Step: 9
Training loss: 2.100618362426758
Validation loss: 1.971365055730266

Epoch: 5| Step: 10
Training loss: 2.2889199256896973
Validation loss: 1.9671469760197464

Epoch: 133| Step: 0
Training loss: 2.016674518585205
Validation loss: 1.9707022225984963

Epoch: 5| Step: 1
Training loss: 1.7483278512954712
Validation loss: 1.9728394657052972

Epoch: 5| Step: 2
Training loss: 2.382136106491089
Validation loss: 1.9648579615418629

Epoch: 5| Step: 3
Training loss: 2.6609814167022705
Validation loss: 1.962905659470507

Epoch: 5| Step: 4
Training loss: 1.8845046758651733
Validation loss: 1.990025766434208

Epoch: 5| Step: 5
Training loss: 2.7007904052734375
Validation loss: 2.0107558875955562

Epoch: 5| Step: 6
Training loss: 2.1890206336975098
Validation loss: 2.0077711202765025

Epoch: 5| Step: 7
Training loss: 1.5747127532958984
Validation loss: 2.0238540582759406

Epoch: 5| Step: 8
Training loss: 2.3950366973876953
Validation loss: 2.030362526575724

Epoch: 5| Step: 9
Training loss: 2.728297472000122
Validation loss: 2.019667581845355

Epoch: 5| Step: 10
Training loss: 1.7998658418655396
Validation loss: 2.013894009333785

Epoch: 134| Step: 0
Training loss: 2.434027910232544
Validation loss: 1.9880425289113035

Epoch: 5| Step: 1
Training loss: 2.492934465408325
Validation loss: 1.977593957736928

Epoch: 5| Step: 2
Training loss: 1.5096217393875122
Validation loss: 1.9875096300596833

Epoch: 5| Step: 3
Training loss: 2.016293525695801
Validation loss: 1.9900763624457902

Epoch: 5| Step: 4
Training loss: 2.103703737258911
Validation loss: 1.9894431893543532

Epoch: 5| Step: 5
Training loss: 2.2726855278015137
Validation loss: 1.9954159144432313

Epoch: 5| Step: 6
Training loss: 2.8102869987487793
Validation loss: 2.018902163351736

Epoch: 5| Step: 7
Training loss: 2.252366542816162
Validation loss: 2.026544314558788

Epoch: 5| Step: 8
Training loss: 1.9295680522918701
Validation loss: 2.0537261232253043

Epoch: 5| Step: 9
Training loss: 2.304779052734375
Validation loss: 2.0471444693944787

Epoch: 5| Step: 10
Training loss: 1.95367431640625
Validation loss: 2.0534413117234425

Epoch: 135| Step: 0
Training loss: 2.8548526763916016
Validation loss: 2.0439963994487638

Epoch: 5| Step: 1
Training loss: 2.156599760055542
Validation loss: 2.023068825403849

Epoch: 5| Step: 2
Training loss: 1.9190524816513062
Validation loss: 2.0157406407017864

Epoch: 5| Step: 3
Training loss: 2.9594225883483887
Validation loss: 2.0152878376745407

Epoch: 5| Step: 4
Training loss: 2.3447024822235107
Validation loss: 2.0076899861776702

Epoch: 5| Step: 5
Training loss: 2.2586734294891357
Validation loss: 1.9975119508722776

Epoch: 5| Step: 6
Training loss: 2.2474591732025146
Validation loss: 1.9915764895818566

Epoch: 5| Step: 7
Training loss: 1.3227825164794922
Validation loss: 1.9789128611164708

Epoch: 5| Step: 8
Training loss: 1.866071343421936
Validation loss: 1.9816622093159666

Epoch: 5| Step: 9
Training loss: 1.961404800415039
Validation loss: 1.9738996131445772

Epoch: 5| Step: 10
Training loss: 2.0219223499298096
Validation loss: 1.9786462399267382

Epoch: 136| Step: 0
Training loss: 1.0690839290618896
Validation loss: 1.9844183383449432

Epoch: 5| Step: 1
Training loss: 2.428278684616089
Validation loss: 1.990126779002528

Epoch: 5| Step: 2
Training loss: 2.3193821907043457
Validation loss: 2.000413424225264

Epoch: 5| Step: 3
Training loss: 1.6519454717636108
Validation loss: 2.014943822737663

Epoch: 5| Step: 4
Training loss: 2.092491865158081
Validation loss: 2.0278825875251525

Epoch: 5| Step: 5
Training loss: 1.8283491134643555
Validation loss: 2.051317048329179

Epoch: 5| Step: 6
Training loss: 2.4205329418182373
Validation loss: 2.0633304503656205

Epoch: 5| Step: 7
Training loss: 2.8718793392181396
Validation loss: 2.0561565006932905

Epoch: 5| Step: 8
Training loss: 2.3653194904327393
Validation loss: 2.028608663107759

Epoch: 5| Step: 9
Training loss: 2.400977611541748
Validation loss: 1.9900145646064513

Epoch: 5| Step: 10
Training loss: 2.3956222534179688
Validation loss: 1.9841264037675754

Epoch: 137| Step: 0
Training loss: 1.9153861999511719
Validation loss: 1.983616364899502

Epoch: 5| Step: 1
Training loss: 2.2894206047058105
Validation loss: 1.979684998912196

Epoch: 5| Step: 2
Training loss: 1.8903087377548218
Validation loss: 1.9827612984564997

Epoch: 5| Step: 3
Training loss: 2.5172479152679443
Validation loss: 1.9779050439916632

Epoch: 5| Step: 4
Training loss: 1.9804439544677734
Validation loss: 1.9884371885689356

Epoch: 5| Step: 5
Training loss: 2.755103588104248
Validation loss: 2.0055043043628817

Epoch: 5| Step: 6
Training loss: 2.5384936332702637
Validation loss: 2.027124733053228

Epoch: 5| Step: 7
Training loss: 1.4219799041748047
Validation loss: 2.030799836240789

Epoch: 5| Step: 8
Training loss: 2.323763370513916
Validation loss: 2.021254547180668

Epoch: 5| Step: 9
Training loss: 2.4706835746765137
Validation loss: 2.0131727380137288

Epoch: 5| Step: 10
Training loss: 1.5873527526855469
Validation loss: 2.0089717142043577

Epoch: 138| Step: 0
Training loss: 2.3510098457336426
Validation loss: 2.0128565834414576

Epoch: 5| Step: 1
Training loss: 1.9839357137680054
Validation loss: 2.0038954737365886

Epoch: 5| Step: 2
Training loss: 2.565516233444214
Validation loss: 1.9993237295458395

Epoch: 5| Step: 3
Training loss: 1.9800125360488892
Validation loss: 1.996492567882743

Epoch: 5| Step: 4
Training loss: 1.7548391819000244
Validation loss: 1.9911541323507986

Epoch: 5| Step: 5
Training loss: 2.269387722015381
Validation loss: 1.9936810744706022

Epoch: 5| Step: 6
Training loss: 2.013270616531372
Validation loss: 1.9791119919028333

Epoch: 5| Step: 7
Training loss: 2.4018683433532715
Validation loss: 1.991517190010317

Epoch: 5| Step: 8
Training loss: 1.7942955493927002
Validation loss: 2.003816730232649

Epoch: 5| Step: 9
Training loss: 2.2660460472106934
Validation loss: 2.0099400063996673

Epoch: 5| Step: 10
Training loss: 2.522660732269287
Validation loss: 2.0018054759630592

Epoch: 139| Step: 0
Training loss: 2.540576457977295
Validation loss: 2.006492535273234

Epoch: 5| Step: 1
Training loss: 1.504669189453125
Validation loss: 2.015723825782858

Epoch: 5| Step: 2
Training loss: 1.9846522808074951
Validation loss: 1.9961234472131217

Epoch: 5| Step: 3
Training loss: 2.8234610557556152
Validation loss: 1.9805567315829697

Epoch: 5| Step: 4
Training loss: 2.480229616165161
Validation loss: 1.9857419601050756

Epoch: 5| Step: 5
Training loss: 2.071859836578369
Validation loss: 1.9868959303825133

Epoch: 5| Step: 6
Training loss: 1.683749794960022
Validation loss: 1.981072554024317

Epoch: 5| Step: 7
Training loss: 2.3163681030273438
Validation loss: 1.9889783218342771

Epoch: 5| Step: 8
Training loss: 1.6354221105575562
Validation loss: 1.9970233491671983

Epoch: 5| Step: 9
Training loss: 2.208479404449463
Validation loss: 2.0307760379647695

Epoch: 5| Step: 10
Training loss: 2.5101561546325684
Validation loss: 2.081568310337682

Epoch: 140| Step: 0
Training loss: 1.8465324640274048
Validation loss: 2.0866926395764915

Epoch: 5| Step: 1
Training loss: 2.36006760597229
Validation loss: 2.1006402379723004

Epoch: 5| Step: 2
Training loss: 2.4289755821228027
Validation loss: 2.086537781582084

Epoch: 5| Step: 3
Training loss: 2.2449774742126465
Validation loss: 2.0559590093551146

Epoch: 5| Step: 4
Training loss: 2.1450271606445312
Validation loss: 2.0423266797937374

Epoch: 5| Step: 5
Training loss: 2.1388680934906006
Validation loss: 2.0125761903742307

Epoch: 5| Step: 6
Training loss: 1.883238434791565
Validation loss: 2.0008807310494046

Epoch: 5| Step: 7
Training loss: 1.2394919395446777
Validation loss: 2.006773981996762

Epoch: 5| Step: 8
Training loss: 2.872161865234375
Validation loss: 2.0024239170935845

Epoch: 5| Step: 9
Training loss: 1.888859510421753
Validation loss: 2.00794154854231

Epoch: 5| Step: 10
Training loss: 2.576650381088257
Validation loss: 1.9939716195547452

Epoch: 141| Step: 0
Training loss: 2.244108200073242
Validation loss: 1.9985551577742382

Epoch: 5| Step: 1
Training loss: 1.3457517623901367
Validation loss: 1.9876527273526756

Epoch: 5| Step: 2
Training loss: 2.0636308193206787
Validation loss: 1.9829187867461995

Epoch: 5| Step: 3
Training loss: 1.8024415969848633
Validation loss: 1.9948901950672109

Epoch: 5| Step: 4
Training loss: 1.8736350536346436
Validation loss: 1.9978444653172647

Epoch: 5| Step: 5
Training loss: 1.5273863077163696
Validation loss: 2.009525792573088

Epoch: 5| Step: 6
Training loss: 2.4369943141937256
Validation loss: 2.03772186463879

Epoch: 5| Step: 7
Training loss: 2.752293109893799
Validation loss: 2.026958454039789

Epoch: 5| Step: 8
Training loss: 2.433446168899536
Validation loss: 2.0347871729122695

Epoch: 5| Step: 9
Training loss: 2.290726661682129
Validation loss: 2.0206538425978793

Epoch: 5| Step: 10
Training loss: 2.4925034046173096
Validation loss: 2.0258731957404845

Epoch: 142| Step: 0
Training loss: 2.0213706493377686
Validation loss: 2.02501360318994

Epoch: 5| Step: 1
Training loss: 2.5128185749053955
Validation loss: 2.058385720816992

Epoch: 5| Step: 2
Training loss: 1.5272185802459717
Validation loss: 2.058691822072511

Epoch: 5| Step: 3
Training loss: 2.039945602416992
Validation loss: 2.0552105160169702

Epoch: 5| Step: 4
Training loss: 1.4640944004058838
Validation loss: 2.060580271546559

Epoch: 5| Step: 5
Training loss: 2.5571601390838623
Validation loss: 2.065405843078449

Epoch: 5| Step: 6
Training loss: 1.9780075550079346
Validation loss: 2.06013140883497

Epoch: 5| Step: 7
Training loss: 2.5589663982391357
Validation loss: 2.0610126128760715

Epoch: 5| Step: 8
Training loss: 1.9608405828475952
Validation loss: 2.05823847298981

Epoch: 5| Step: 9
Training loss: 2.222385883331299
Validation loss: 2.0378585400119906

Epoch: 5| Step: 10
Training loss: 2.323209762573242
Validation loss: 2.005764848442488

Epoch: 143| Step: 0
Training loss: 2.56426739692688
Validation loss: 1.9908385892068186

Epoch: 5| Step: 1
Training loss: 1.814976692199707
Validation loss: 1.9887520600390691

Epoch: 5| Step: 2
Training loss: 1.9996188879013062
Validation loss: 1.972415974063258

Epoch: 5| Step: 3
Training loss: 2.249229907989502
Validation loss: 1.965625197656693

Epoch: 5| Step: 4
Training loss: 2.0186352729797363
Validation loss: 1.9749936467857772

Epoch: 5| Step: 5
Training loss: 2.5767226219177246
Validation loss: 1.9722821379220614

Epoch: 5| Step: 6
Training loss: 1.541632890701294
Validation loss: 1.980027796119772

Epoch: 5| Step: 7
Training loss: 2.698497772216797
Validation loss: 1.9892551104227703

Epoch: 5| Step: 8
Training loss: 1.861985206604004
Validation loss: 1.9859498816151773

Epoch: 5| Step: 9
Training loss: 1.9140422344207764
Validation loss: 1.9822198242269538

Epoch: 5| Step: 10
Training loss: 1.769047737121582
Validation loss: 2.0122751933272167

Epoch: 144| Step: 0
Training loss: 2.0653767585754395
Validation loss: 2.046306630616547

Epoch: 5| Step: 1
Training loss: 2.0387625694274902
Validation loss: 2.041187810641463

Epoch: 5| Step: 2
Training loss: 2.4096474647521973
Validation loss: 2.0231347391682286

Epoch: 5| Step: 3
Training loss: 2.3825926780700684
Validation loss: 2.0329144513735207

Epoch: 5| Step: 4
Training loss: 1.1314834356307983
Validation loss: 2.026594210696477

Epoch: 5| Step: 5
Training loss: 2.9431405067443848
Validation loss: 2.0118393923646662

Epoch: 5| Step: 6
Training loss: 1.7663272619247437
Validation loss: 2.012098163686773

Epoch: 5| Step: 7
Training loss: 2.227245807647705
Validation loss: 2.0107039533635622

Epoch: 5| Step: 8
Training loss: 1.9238592386245728
Validation loss: 2.022309963421155

Epoch: 5| Step: 9
Training loss: 2.0752146244049072
Validation loss: 2.044085210369479

Epoch: 5| Step: 10
Training loss: 2.0935730934143066
Validation loss: 2.0535487436479136

Epoch: 145| Step: 0
Training loss: 2.17334246635437
Validation loss: 2.059406384345024

Epoch: 5| Step: 1
Training loss: 2.32267689704895
Validation loss: 2.0616625380772415

Epoch: 5| Step: 2
Training loss: 2.0664029121398926
Validation loss: 2.0546526370509977

Epoch: 5| Step: 3
Training loss: 2.1101129055023193
Validation loss: 2.06473050578948

Epoch: 5| Step: 4
Training loss: 2.538609027862549
Validation loss: 2.0638658923487507

Epoch: 5| Step: 5
Training loss: 1.5678602457046509
Validation loss: 2.05423592880208

Epoch: 5| Step: 6
Training loss: 2.005256414413452
Validation loss: 2.0476942959652153

Epoch: 5| Step: 7
Training loss: 1.535172462463379
Validation loss: 2.0490277480053645

Epoch: 5| Step: 8
Training loss: 1.995345115661621
Validation loss: 2.0502291597345823

Epoch: 5| Step: 9
Training loss: 2.191710948944092
Validation loss: 2.0536307070844915

Epoch: 5| Step: 10
Training loss: 2.4133856296539307
Validation loss: 2.0476846592400664

Epoch: 146| Step: 0
Training loss: 2.139737844467163
Validation loss: 2.03140155858891

Epoch: 5| Step: 1
Training loss: 2.2369415760040283
Validation loss: 2.0262804774827856

Epoch: 5| Step: 2
Training loss: 2.0612072944641113
Validation loss: 2.0251638966221965

Epoch: 5| Step: 3
Training loss: 1.804111123085022
Validation loss: 2.011199633280436

Epoch: 5| Step: 4
Training loss: 2.093289852142334
Validation loss: 2.007908764705863

Epoch: 5| Step: 5
Training loss: 2.0751843452453613
Validation loss: 2.006729551540908

Epoch: 5| Step: 6
Training loss: 1.7095502614974976
Validation loss: 2.0023723263894357

Epoch: 5| Step: 7
Training loss: 2.0050148963928223
Validation loss: 2.0047276814778647

Epoch: 5| Step: 8
Training loss: 2.203204870223999
Validation loss: 2.013724673178888

Epoch: 5| Step: 9
Training loss: 2.5281920433044434
Validation loss: 2.0108646141585482

Epoch: 5| Step: 10
Training loss: 2.0107383728027344
Validation loss: 2.028020397309334

Epoch: 147| Step: 0
Training loss: 2.1842832565307617
Validation loss: 2.0222718651576708

Epoch: 5| Step: 1
Training loss: 2.446887254714966
Validation loss: 2.0207964681809947

Epoch: 5| Step: 2
Training loss: 2.0874783992767334
Validation loss: 2.02152338335591

Epoch: 5| Step: 3
Training loss: 2.052311420440674
Validation loss: 1.9998589715650004

Epoch: 5| Step: 4
Training loss: 1.8455126285552979
Validation loss: 2.0110034058170934

Epoch: 5| Step: 5
Training loss: 1.9707748889923096
Validation loss: 2.0148041543140205

Epoch: 5| Step: 6
Training loss: 2.1722378730773926
Validation loss: 2.0164547645917503

Epoch: 5| Step: 7
Training loss: 2.0631325244903564
Validation loss: 2.0199471263475317

Epoch: 5| Step: 8
Training loss: 2.1183650493621826
Validation loss: 2.046782857628279

Epoch: 5| Step: 9
Training loss: 2.181633472442627
Validation loss: 2.039117008127192

Epoch: 5| Step: 10
Training loss: 1.7028623819351196
Validation loss: 2.056065619632762

Epoch: 148| Step: 0
Training loss: 2.5382280349731445
Validation loss: 2.0560226466066096

Epoch: 5| Step: 1
Training loss: 2.1510071754455566
Validation loss: 2.0488652644618863

Epoch: 5| Step: 2
Training loss: 1.8591721057891846
Validation loss: 2.0464275165270736

Epoch: 5| Step: 3
Training loss: 1.8528578281402588
Validation loss: 2.0483339358401556

Epoch: 5| Step: 4
Training loss: 2.225512742996216
Validation loss: 2.038152369119788

Epoch: 5| Step: 5
Training loss: 2.165501117706299
Validation loss: 2.0206155930795977

Epoch: 5| Step: 6
Training loss: 1.9543052911758423
Validation loss: 2.009468488795783

Epoch: 5| Step: 7
Training loss: 2.5467588901519775
Validation loss: 2.0032481057669527

Epoch: 5| Step: 8
Training loss: 1.683223009109497
Validation loss: 2.0119219633840744

Epoch: 5| Step: 9
Training loss: 2.0238964557647705
Validation loss: 2.015942177464885

Epoch: 5| Step: 10
Training loss: 1.7015794515609741
Validation loss: 2.0114435393323182

Epoch: 149| Step: 0
Training loss: 2.482072353363037
Validation loss: 2.0146745840708413

Epoch: 5| Step: 1
Training loss: 2.1005406379699707
Validation loss: 2.016513696280859

Epoch: 5| Step: 2
Training loss: 1.9103667736053467
Validation loss: 2.032448127705564

Epoch: 5| Step: 3
Training loss: 2.004026412963867
Validation loss: 2.022639113087808

Epoch: 5| Step: 4
Training loss: 2.904717445373535
Validation loss: 2.0221898850574287

Epoch: 5| Step: 5
Training loss: 1.6417992115020752
Validation loss: 2.029030555038042

Epoch: 5| Step: 6
Training loss: 1.7549442052841187
Validation loss: 2.0150519365905435

Epoch: 5| Step: 7
Training loss: 2.0330734252929688
Validation loss: 2.0162896033256286

Epoch: 5| Step: 8
Training loss: 1.3942323923110962
Validation loss: 2.003095060266474

Epoch: 5| Step: 9
Training loss: 2.0838804244995117
Validation loss: 2.0107524766716907

Epoch: 5| Step: 10
Training loss: 2.157423973083496
Validation loss: 2.010785787336288

Epoch: 150| Step: 0
Training loss: 2.0000548362731934
Validation loss: 1.985438298153621

Epoch: 5| Step: 1
Training loss: 2.0622830390930176
Validation loss: 1.9869290308285785

Epoch: 5| Step: 2
Training loss: 1.7343673706054688
Validation loss: 1.9700336405026015

Epoch: 5| Step: 3
Training loss: 1.989501953125
Validation loss: 1.9969430328697286

Epoch: 5| Step: 4
Training loss: 1.9558703899383545
Validation loss: 1.9995162743394093

Epoch: 5| Step: 5
Training loss: 2.408057451248169
Validation loss: 1.9949360009162658

Epoch: 5| Step: 6
Training loss: 2.1355793476104736
Validation loss: 1.9959887150795228

Epoch: 5| Step: 7
Training loss: 1.855036973953247
Validation loss: 1.9882400240949405

Epoch: 5| Step: 8
Training loss: 2.1114964485168457
Validation loss: 1.982764067188386

Epoch: 5| Step: 9
Training loss: 2.0281434059143066
Validation loss: 1.9997181379666893

Epoch: 5| Step: 10
Training loss: 2.032395362854004
Validation loss: 1.9933926982264365

Epoch: 151| Step: 0
Training loss: 2.0298829078674316
Validation loss: 1.9963442548628776

Epoch: 5| Step: 1
Training loss: 2.2472331523895264
Validation loss: 1.9916396051324823

Epoch: 5| Step: 2
Training loss: 2.4370436668395996
Validation loss: 1.9999943215359923

Epoch: 5| Step: 3
Training loss: 2.2189741134643555
Validation loss: 1.9985792431780087

Epoch: 5| Step: 4
Training loss: 1.9227352142333984
Validation loss: 1.9865242101812874

Epoch: 5| Step: 5
Training loss: 1.694714903831482
Validation loss: 1.986599406888408

Epoch: 5| Step: 6
Training loss: 1.3128288984298706
Validation loss: 2.0025346227871474

Epoch: 5| Step: 7
Training loss: 1.7659391164779663
Validation loss: 2.010033958701677

Epoch: 5| Step: 8
Training loss: 2.5316097736358643
Validation loss: 2.008837248689385

Epoch: 5| Step: 9
Training loss: 2.095651388168335
Validation loss: 2.022965003085393

Epoch: 5| Step: 10
Training loss: 1.8844597339630127
Validation loss: 2.0323244679358696

Epoch: 152| Step: 0
Training loss: 1.898999810218811
Validation loss: 2.040923337782583

Epoch: 5| Step: 1
Training loss: 1.9896913766860962
Validation loss: 2.0390601901597876

Epoch: 5| Step: 2
Training loss: 2.2934069633483887
Validation loss: 2.04001860977501

Epoch: 5| Step: 3
Training loss: 1.8083534240722656
Validation loss: 2.040149551565929

Epoch: 5| Step: 4
Training loss: 1.7519028186798096
Validation loss: 2.0239019624648558

Epoch: 5| Step: 5
Training loss: 1.9002975225448608
Validation loss: 1.9986483179112917

Epoch: 5| Step: 6
Training loss: 2.1698379516601562
Validation loss: 1.989110218581333

Epoch: 5| Step: 7
Training loss: 2.123624801635742
Validation loss: 1.9870573089968773

Epoch: 5| Step: 8
Training loss: 1.9483381509780884
Validation loss: 1.9866005912903817

Epoch: 5| Step: 9
Training loss: 2.1504907608032227
Validation loss: 1.987139239106127

Epoch: 5| Step: 10
Training loss: 1.9825266599655151
Validation loss: 2.011504086115027

Epoch: 153| Step: 0
Training loss: 2.1544227600097656
Validation loss: 2.0217288565892044

Epoch: 5| Step: 1
Training loss: 2.166616678237915
Validation loss: 2.0347735625441357

Epoch: 5| Step: 2
Training loss: 2.7216575145721436
Validation loss: 2.0430693652040217

Epoch: 5| Step: 3
Training loss: 1.6704657077789307
Validation loss: 2.0380403675058836

Epoch: 5| Step: 4
Training loss: 2.018430709838867
Validation loss: 2.0322420981622513

Epoch: 5| Step: 5
Training loss: 2.6970553398132324
Validation loss: 2.0147463506267917

Epoch: 5| Step: 6
Training loss: 1.8901748657226562
Validation loss: 2.0173756102079987

Epoch: 5| Step: 7
Training loss: 1.7262017726898193
Validation loss: 2.0028306732895556

Epoch: 5| Step: 8
Training loss: 2.1508285999298096
Validation loss: 2.020226886195521

Epoch: 5| Step: 9
Training loss: 1.3372697830200195
Validation loss: 2.0159392497872792

Epoch: 5| Step: 10
Training loss: 1.4310216903686523
Validation loss: 2.0132041528660762

Epoch: 154| Step: 0
Training loss: 2.1306042671203613
Validation loss: 2.0239745391312467

Epoch: 5| Step: 1
Training loss: 2.2249913215637207
Validation loss: 2.0228065367667907

Epoch: 5| Step: 2
Training loss: 1.6256132125854492
Validation loss: 2.025413869529642

Epoch: 5| Step: 3
Training loss: 1.7908499240875244
Validation loss: 2.0232592449393323

Epoch: 5| Step: 4
Training loss: 1.1871159076690674
Validation loss: 2.017727603194534

Epoch: 5| Step: 5
Training loss: 2.307077407836914
Validation loss: 2.0204918589643253

Epoch: 5| Step: 6
Training loss: 2.5402369499206543
Validation loss: 2.0152218418736614

Epoch: 5| Step: 7
Training loss: 2.198467969894409
Validation loss: 2.0164118710384575

Epoch: 5| Step: 8
Training loss: 1.5722943544387817
Validation loss: 2.0257089432849678

Epoch: 5| Step: 9
Training loss: 2.0950229167938232
Validation loss: 2.0124738139490925

Epoch: 5| Step: 10
Training loss: 1.953992247581482
Validation loss: 2.0142221271350818

Epoch: 155| Step: 0
Training loss: 2.200573682785034
Validation loss: 2.0121591450065694

Epoch: 5| Step: 1
Training loss: 2.326561450958252
Validation loss: 2.0095874904304423

Epoch: 5| Step: 2
Training loss: 1.8982365131378174
Validation loss: 2.0210480792548067

Epoch: 5| Step: 3
Training loss: 1.7247626781463623
Validation loss: 2.0266154581500637

Epoch: 5| Step: 4
Training loss: 1.5502204895019531
Validation loss: 2.023005243270628

Epoch: 5| Step: 5
Training loss: 1.911415696144104
Validation loss: 2.02259801536478

Epoch: 5| Step: 6
Training loss: 2.1361565589904785
Validation loss: 2.024691735544512

Epoch: 5| Step: 7
Training loss: 1.7072961330413818
Validation loss: 1.9962459776991157

Epoch: 5| Step: 8
Training loss: 2.057506561279297
Validation loss: 1.999332058814264

Epoch: 5| Step: 9
Training loss: 2.153313159942627
Validation loss: 2.0016160459928614

Epoch: 5| Step: 10
Training loss: 1.8970842361450195
Validation loss: 2.0148713460532566

Epoch: 156| Step: 0
Training loss: 1.7429488897323608
Validation loss: 2.027453258473386

Epoch: 5| Step: 1
Training loss: 1.836475133895874
Validation loss: 2.013818411416905

Epoch: 5| Step: 2
Training loss: 2.632988691329956
Validation loss: 2.005474482813189

Epoch: 5| Step: 3
Training loss: 1.816216230392456
Validation loss: 2.0054691389042842

Epoch: 5| Step: 4
Training loss: 2.05314040184021
Validation loss: 2.012349174868676

Epoch: 5| Step: 5
Training loss: 2.169572591781616
Validation loss: 2.0213874668203373

Epoch: 5| Step: 6
Training loss: 1.6953232288360596
Validation loss: 2.0391017172926214

Epoch: 5| Step: 7
Training loss: 2.2563748359680176
Validation loss: 2.033213435962636

Epoch: 5| Step: 8
Training loss: 1.4302833080291748
Validation loss: 2.011554302707795

Epoch: 5| Step: 9
Training loss: 1.8345003128051758
Validation loss: 2.012833619630465

Epoch: 5| Step: 10
Training loss: 2.203057289123535
Validation loss: 2.006543154357582

Epoch: 157| Step: 0
Training loss: 1.3801106214523315
Validation loss: 2.0222800367621967

Epoch: 5| Step: 1
Training loss: 1.3208509683609009
Validation loss: 2.0173207867530083

Epoch: 5| Step: 2
Training loss: 1.4292287826538086
Validation loss: 2.0233309679133917

Epoch: 5| Step: 3
Training loss: 2.533273696899414
Validation loss: 2.0288074093480266

Epoch: 5| Step: 4
Training loss: 1.884558081626892
Validation loss: 2.0424334285079793

Epoch: 5| Step: 5
Training loss: 1.7024341821670532
Validation loss: 2.0562602281570435

Epoch: 5| Step: 6
Training loss: 2.620720624923706
Validation loss: 2.070277275577668

Epoch: 5| Step: 7
Training loss: 2.11360239982605
Validation loss: 2.0617803142916773

Epoch: 5| Step: 8
Training loss: 1.9162099361419678
Validation loss: 2.037893408088274

Epoch: 5| Step: 9
Training loss: 2.5086112022399902
Validation loss: 1.9999663573439403

Epoch: 5| Step: 10
Training loss: 2.1605560779571533
Validation loss: 1.9881565109375985

Epoch: 158| Step: 0
Training loss: 3.0025925636291504
Validation loss: 1.9807962166365756

Epoch: 5| Step: 1
Training loss: 1.9881023168563843
Validation loss: 1.9933107822172103

Epoch: 5| Step: 2
Training loss: 1.3375227451324463
Validation loss: 1.9972354391569733

Epoch: 5| Step: 3
Training loss: 2.2159249782562256
Validation loss: 2.0166159957967777

Epoch: 5| Step: 4
Training loss: 1.7217328548431396
Validation loss: 2.0210066572312386

Epoch: 5| Step: 5
Training loss: 2.234104633331299
Validation loss: 2.03441212895096

Epoch: 5| Step: 6
Training loss: 1.6640455722808838
Validation loss: 2.0182129618942097

Epoch: 5| Step: 7
Training loss: 2.3900535106658936
Validation loss: 1.9952540115643573

Epoch: 5| Step: 8
Training loss: 1.5854072570800781
Validation loss: 1.982725138305336

Epoch: 5| Step: 9
Training loss: 1.5823978185653687
Validation loss: 1.9881897793021253

Epoch: 5| Step: 10
Training loss: 1.8620550632476807
Validation loss: 1.989455597375029

Epoch: 159| Step: 0
Training loss: 1.9402539730072021
Validation loss: 2.000804942141297

Epoch: 5| Step: 1
Training loss: 1.8908965587615967
Validation loss: 2.0059878492868073

Epoch: 5| Step: 2
Training loss: 2.375070571899414
Validation loss: 2.024312409021521

Epoch: 5| Step: 3
Training loss: 1.8769880533218384
Validation loss: 2.057964348023938

Epoch: 5| Step: 4
Training loss: 2.1608073711395264
Validation loss: 2.0911018386963875

Epoch: 5| Step: 5
Training loss: 2.325047254562378
Validation loss: 2.165846509318198

Epoch: 5| Step: 6
Training loss: 2.1564126014709473
Validation loss: 2.13701460694754

Epoch: 5| Step: 7
Training loss: 1.3618857860565186
Validation loss: 2.0770438281438683

Epoch: 5| Step: 8
Training loss: 2.6932592391967773
Validation loss: 2.051825375967128

Epoch: 5| Step: 9
Training loss: 1.498376488685608
Validation loss: 2.032625321419008

Epoch: 5| Step: 10
Training loss: 1.7220451831817627
Validation loss: 2.0423719242054927

Epoch: 160| Step: 0
Training loss: 1.994747519493103
Validation loss: 2.0496645101936917

Epoch: 5| Step: 1
Training loss: 2.580030918121338
Validation loss: 2.052810848400157

Epoch: 5| Step: 2
Training loss: 1.5498071908950806
Validation loss: 2.049798603980772

Epoch: 5| Step: 3
Training loss: 2.048328399658203
Validation loss: 2.0331561052671043

Epoch: 5| Step: 4
Training loss: 2.4301953315734863
Validation loss: 2.0253715233136247

Epoch: 5| Step: 5
Training loss: 1.815108060836792
Validation loss: 1.9963793395667948

Epoch: 5| Step: 6
Training loss: 2.057389259338379
Validation loss: 1.9767684821159608

Epoch: 5| Step: 7
Training loss: 1.8084691762924194
Validation loss: 1.9852178148044053

Epoch: 5| Step: 8
Training loss: 1.5053459405899048
Validation loss: 2.0002052348147155

Epoch: 5| Step: 9
Training loss: 2.441863536834717
Validation loss: 2.0199602278329993

Epoch: 5| Step: 10
Training loss: 1.7684946060180664
Validation loss: 2.018446035282586

Epoch: 161| Step: 0
Training loss: 1.9634069204330444
Validation loss: 2.0551648780863774

Epoch: 5| Step: 1
Training loss: 1.294640064239502
Validation loss: 2.0522663336928173

Epoch: 5| Step: 2
Training loss: 2.0952305793762207
Validation loss: 2.0576687807677896

Epoch: 5| Step: 3
Training loss: 1.4446252584457397
Validation loss: 2.041945219039917

Epoch: 5| Step: 4
Training loss: 1.7153819799423218
Validation loss: 2.040626384878671

Epoch: 5| Step: 5
Training loss: 2.3302929401397705
Validation loss: 2.0384974851403186

Epoch: 5| Step: 6
Training loss: 2.1004385948181152
Validation loss: 2.029930696692518

Epoch: 5| Step: 7
Training loss: 1.9994561672210693
Validation loss: 2.0076947519856114

Epoch: 5| Step: 8
Training loss: 2.2007319927215576
Validation loss: 1.9976977917455858

Epoch: 5| Step: 9
Training loss: 2.546151876449585
Validation loss: 1.9820834013723558

Epoch: 5| Step: 10
Training loss: 1.543190836906433
Validation loss: 1.979465046236592

Epoch: 162| Step: 0
Training loss: 1.9078327417373657
Validation loss: 1.9536885215390114

Epoch: 5| Step: 1
Training loss: 1.9417660236358643
Validation loss: 1.9643079952527118

Epoch: 5| Step: 2
Training loss: 1.7154114246368408
Validation loss: 1.975792597698909

Epoch: 5| Step: 3
Training loss: 1.6337801218032837
Validation loss: 1.9877754142207484

Epoch: 5| Step: 4
Training loss: 2.057323455810547
Validation loss: 1.9832018242087415

Epoch: 5| Step: 5
Training loss: 2.3425326347351074
Validation loss: 1.995827967120755

Epoch: 5| Step: 6
Training loss: 1.8339073657989502
Validation loss: 1.9838753900220316

Epoch: 5| Step: 7
Training loss: 2.1340174674987793
Validation loss: 1.964191068885147

Epoch: 5| Step: 8
Training loss: 2.3798837661743164
Validation loss: 1.9681784901567685

Epoch: 5| Step: 9
Training loss: 1.5632613897323608
Validation loss: 1.9696599706526725

Epoch: 5| Step: 10
Training loss: 1.4601937532424927
Validation loss: 1.9650855807847873

Epoch: 163| Step: 0
Training loss: 2.100656032562256
Validation loss: 1.959691616796678

Epoch: 5| Step: 1
Training loss: 1.784745454788208
Validation loss: 1.9697812218819895

Epoch: 5| Step: 2
Training loss: 2.3809080123901367
Validation loss: 1.994448188812502

Epoch: 5| Step: 3
Training loss: 2.3865392208099365
Validation loss: 1.992393046297053

Epoch: 5| Step: 4
Training loss: 1.5817371606826782
Validation loss: 2.0031931374662664

Epoch: 5| Step: 5
Training loss: 1.894178032875061
Validation loss: 2.0107157679014307

Epoch: 5| Step: 6
Training loss: 1.787398099899292
Validation loss: 2.0264751577890046

Epoch: 5| Step: 7
Training loss: 2.300802707672119
Validation loss: 2.0545161154962357

Epoch: 5| Step: 8
Training loss: 1.8624792098999023
Validation loss: 2.06697678565979

Epoch: 5| Step: 9
Training loss: 1.34469473361969
Validation loss: 2.0622796461146367

Epoch: 5| Step: 10
Training loss: 1.5712538957595825
Validation loss: 2.052844447474326

Epoch: 164| Step: 0
Training loss: 1.6018701791763306
Validation loss: 2.0440968890343942

Epoch: 5| Step: 1
Training loss: 2.0081772804260254
Validation loss: 2.0139120471092964

Epoch: 5| Step: 2
Training loss: 1.894317626953125
Validation loss: 2.001436002792851

Epoch: 5| Step: 3
Training loss: 2.024306535720825
Validation loss: 1.999475497071461

Epoch: 5| Step: 4
Training loss: 2.2130773067474365
Validation loss: 2.0027865671342417

Epoch: 5| Step: 5
Training loss: 1.563159704208374
Validation loss: 2.007467371161266

Epoch: 5| Step: 6
Training loss: 1.8720823526382446
Validation loss: 2.0039677594297673

Epoch: 5| Step: 7
Training loss: 1.980017900466919
Validation loss: 1.9932903294922204

Epoch: 5| Step: 8
Training loss: 2.49178147315979
Validation loss: 1.996845281252297

Epoch: 5| Step: 9
Training loss: 1.505310297012329
Validation loss: 1.9946366228083128

Epoch: 5| Step: 10
Training loss: 1.7149776220321655
Validation loss: 1.9884153514780023

Epoch: 165| Step: 0
Training loss: 2.330732822418213
Validation loss: 1.9676916009636336

Epoch: 5| Step: 1
Training loss: 2.156045436859131
Validation loss: 1.9769641712147703

Epoch: 5| Step: 2
Training loss: 1.8756065368652344
Validation loss: 1.9813683904627317

Epoch: 5| Step: 3
Training loss: 1.6753785610198975
Validation loss: 1.9930007034732449

Epoch: 5| Step: 4
Training loss: 1.908156156539917
Validation loss: 1.9890925397155106

Epoch: 5| Step: 5
Training loss: 1.612951636314392
Validation loss: 1.9896552203803934

Epoch: 5| Step: 6
Training loss: 1.5884860754013062
Validation loss: 1.9828611368774085

Epoch: 5| Step: 7
Training loss: 1.5715073347091675
Validation loss: 2.0015796025594077

Epoch: 5| Step: 8
Training loss: 1.7914243936538696
Validation loss: 2.03100941001728

Epoch: 5| Step: 9
Training loss: 2.1356863975524902
Validation loss: 2.0553384724483696

Epoch: 5| Step: 10
Training loss: 2.0489392280578613
Validation loss: 2.071397210962029

Epoch: 166| Step: 0
Training loss: 2.0565645694732666
Validation loss: 2.06343275244518

Epoch: 5| Step: 1
Training loss: 1.999582052230835
Validation loss: 2.0419174830118814

Epoch: 5| Step: 2
Training loss: 2.093444585800171
Validation loss: 2.02034584424829

Epoch: 5| Step: 3
Training loss: 1.7352145910263062
Validation loss: 2.0142571836389522

Epoch: 5| Step: 4
Training loss: 1.6730350255966187
Validation loss: 2.005525049342904

Epoch: 5| Step: 5
Training loss: 1.3667422533035278
Validation loss: 2.024460784850582

Epoch: 5| Step: 6
Training loss: 1.8076655864715576
Validation loss: 2.016799142283778

Epoch: 5| Step: 7
Training loss: 1.8754050731658936
Validation loss: 2.0332172173325733

Epoch: 5| Step: 8
Training loss: 2.3318893909454346
Validation loss: 2.0408472502103416

Epoch: 5| Step: 9
Training loss: 2.05686616897583
Validation loss: 2.0241998844249274

Epoch: 5| Step: 10
Training loss: 2.144435167312622
Validation loss: 2.003951488002654

Epoch: 167| Step: 0
Training loss: 1.7812740802764893
Validation loss: 2.019734280083769

Epoch: 5| Step: 1
Training loss: 1.4504821300506592
Validation loss: 2.0171309081456994

Epoch: 5| Step: 2
Training loss: 2.3683040142059326
Validation loss: 2.019598554539424

Epoch: 5| Step: 3
Training loss: 1.8703327178955078
Validation loss: 2.017989432939919

Epoch: 5| Step: 4
Training loss: 1.7136234045028687
Validation loss: 1.991460015696864

Epoch: 5| Step: 5
Training loss: 1.8815892934799194
Validation loss: 1.9688001704472367

Epoch: 5| Step: 6
Training loss: 2.1189701557159424
Validation loss: 1.9568574172194286

Epoch: 5| Step: 7
Training loss: 1.8363351821899414
Validation loss: 1.964553694571218

Epoch: 5| Step: 8
Training loss: 1.8054252862930298
Validation loss: 1.962816620385775

Epoch: 5| Step: 9
Training loss: 1.738258719444275
Validation loss: 1.975108500449888

Epoch: 5| Step: 10
Training loss: 1.9248608350753784
Validation loss: 1.9704159203396048

Epoch: 168| Step: 0
Training loss: 1.983146071434021
Validation loss: 1.9775854567045807

Epoch: 5| Step: 1
Training loss: 1.230323076248169
Validation loss: 1.9728220842217887

Epoch: 5| Step: 2
Training loss: 2.100332260131836
Validation loss: 1.9771598872318064

Epoch: 5| Step: 3
Training loss: 2.0541934967041016
Validation loss: 2.0052711284288796

Epoch: 5| Step: 4
Training loss: 1.6346938610076904
Validation loss: 2.005898929411365

Epoch: 5| Step: 5
Training loss: 2.4326324462890625
Validation loss: 1.9945148524417673

Epoch: 5| Step: 6
Training loss: 1.5631053447723389
Validation loss: 1.9905163844426472

Epoch: 5| Step: 7
Training loss: 1.4409211874008179
Validation loss: 1.9835185504728747

Epoch: 5| Step: 8
Training loss: 2.0505874156951904
Validation loss: 1.9782459940961612

Epoch: 5| Step: 9
Training loss: 1.7360759973526
Validation loss: 1.9649469096173522

Epoch: 5| Step: 10
Training loss: 1.9865834712982178
Validation loss: 1.9502809791154758

Epoch: 169| Step: 0
Training loss: 2.0421366691589355
Validation loss: 1.9614340489910496

Epoch: 5| Step: 1
Training loss: 1.8353831768035889
Validation loss: 1.9568069519535187

Epoch: 5| Step: 2
Training loss: 1.6298389434814453
Validation loss: 1.9492237388446767

Epoch: 5| Step: 3
Training loss: 2.2009801864624023
Validation loss: 1.9592688134921494

Epoch: 5| Step: 4
Training loss: 2.3266453742980957
Validation loss: 1.9502821917174964

Epoch: 5| Step: 5
Training loss: 1.8940922021865845
Validation loss: 1.9568251179110618

Epoch: 5| Step: 6
Training loss: 2.1558756828308105
Validation loss: 1.9813187840164348

Epoch: 5| Step: 7
Training loss: 1.4320976734161377
Validation loss: 1.9828730680609261

Epoch: 5| Step: 8
Training loss: 1.5035908222198486
Validation loss: 1.9876305031520065

Epoch: 5| Step: 9
Training loss: 1.2313495874404907
Validation loss: 2.0027891602567447

Epoch: 5| Step: 10
Training loss: 1.8075538873672485
Validation loss: 2.0128010806216987

Epoch: 170| Step: 0
Training loss: 2.259871244430542
Validation loss: 2.0266028450381373

Epoch: 5| Step: 1
Training loss: 1.5207512378692627
Validation loss: 2.0267272726182015

Epoch: 5| Step: 2
Training loss: 2.0037238597869873
Validation loss: 2.0148201834770942

Epoch: 5| Step: 3
Training loss: 1.7499732971191406
Validation loss: 2.0234333751022175

Epoch: 5| Step: 4
Training loss: 1.5876200199127197
Validation loss: 2.0241310647738877

Epoch: 5| Step: 5
Training loss: 1.5977609157562256
Validation loss: 2.0132085636097896

Epoch: 5| Step: 6
Training loss: 1.6338365077972412
Validation loss: 2.0128577575888684

Epoch: 5| Step: 7
Training loss: 2.058523654937744
Validation loss: 1.9983270296486475

Epoch: 5| Step: 8
Training loss: 1.893310546875
Validation loss: 1.9695677885445215

Epoch: 5| Step: 9
Training loss: 1.9255424737930298
Validation loss: 1.963182444213539

Epoch: 5| Step: 10
Training loss: 1.946625828742981
Validation loss: 1.958232439974303

Epoch: 171| Step: 0
Training loss: 1.5817761421203613
Validation loss: 1.9468328991243917

Epoch: 5| Step: 1
Training loss: 2.1648683547973633
Validation loss: 1.9467083510532175

Epoch: 5| Step: 2
Training loss: 1.6401112079620361
Validation loss: 1.9258779569338726

Epoch: 5| Step: 3
Training loss: 1.5135157108306885
Validation loss: 1.9327212277279104

Epoch: 5| Step: 4
Training loss: 1.7349491119384766
Validation loss: 1.9397428779191868

Epoch: 5| Step: 5
Training loss: 2.545382022857666
Validation loss: 1.9456471448303552

Epoch: 5| Step: 6
Training loss: 2.058835506439209
Validation loss: 1.9582427932370094

Epoch: 5| Step: 7
Training loss: 1.8453586101531982
Validation loss: 1.9503453290590675

Epoch: 5| Step: 8
Training loss: 1.4622652530670166
Validation loss: 1.9775718514637282

Epoch: 5| Step: 9
Training loss: 1.9588009119033813
Validation loss: 1.9896427751869283

Epoch: 5| Step: 10
Training loss: 1.8852640390396118
Validation loss: 1.9996372922774284

Epoch: 172| Step: 0
Training loss: 1.2420260906219482
Validation loss: 2.0264770318103094

Epoch: 5| Step: 1
Training loss: 1.5856424570083618
Validation loss: 2.010940859394689

Epoch: 5| Step: 2
Training loss: 1.5356738567352295
Validation loss: 1.9981195798484228

Epoch: 5| Step: 3
Training loss: 1.5997053384780884
Validation loss: 1.97001096253754

Epoch: 5| Step: 4
Training loss: 1.7466808557510376
Validation loss: 1.9321697322271203

Epoch: 5| Step: 5
Training loss: 2.254594087600708
Validation loss: 1.9250510559287122

Epoch: 5| Step: 6
Training loss: 2.0316710472106934
Validation loss: 1.9213739877106042

Epoch: 5| Step: 7
Training loss: 2.020512819290161
Validation loss: 1.8989425013142247

Epoch: 5| Step: 8
Training loss: 2.01399302482605
Validation loss: 1.9192164521063528

Epoch: 5| Step: 9
Training loss: 1.9641563892364502
Validation loss: 1.9158332245324248

Epoch: 5| Step: 10
Training loss: 2.1167163848876953
Validation loss: 1.9281471762605893

Epoch: 173| Step: 0
Training loss: 0.8807112574577332
Validation loss: 1.9616288677338631

Epoch: 5| Step: 1
Training loss: 2.506518840789795
Validation loss: 1.971648403393325

Epoch: 5| Step: 2
Training loss: 1.4412428140640259
Validation loss: 1.9563714637551257

Epoch: 5| Step: 3
Training loss: 1.8671073913574219
Validation loss: 1.9562431689231627

Epoch: 5| Step: 4
Training loss: 1.8276970386505127
Validation loss: 1.9500864321185696

Epoch: 5| Step: 5
Training loss: 1.8651756048202515
Validation loss: 1.9276894228432768

Epoch: 5| Step: 6
Training loss: 1.9225921630859375
Validation loss: 1.9441769097440986

Epoch: 5| Step: 7
Training loss: 2.3888001441955566
Validation loss: 1.9782676927505

Epoch: 5| Step: 8
Training loss: 1.7076094150543213
Validation loss: 1.9850120339342343

Epoch: 5| Step: 9
Training loss: 1.9100525379180908
Validation loss: 1.9917063738710137

Epoch: 5| Step: 10
Training loss: 1.533093810081482
Validation loss: 1.9949460606421194

Epoch: 174| Step: 0
Training loss: 1.846673607826233
Validation loss: 2.0187653444146596

Epoch: 5| Step: 1
Training loss: 1.8313407897949219
Validation loss: 2.0233380358706237

Epoch: 5| Step: 2
Training loss: 1.1341882944107056
Validation loss: 2.0109230805468816

Epoch: 5| Step: 3
Training loss: 1.581101894378662
Validation loss: 1.9788790351601058

Epoch: 5| Step: 4
Training loss: 1.4906814098358154
Validation loss: 1.9710918472659202

Epoch: 5| Step: 5
Training loss: 2.102933168411255
Validation loss: 1.9751821820453932

Epoch: 5| Step: 6
Training loss: 2.0834178924560547
Validation loss: 1.9516252125463178

Epoch: 5| Step: 7
Training loss: 1.9640254974365234
Validation loss: 1.9464890931242256

Epoch: 5| Step: 8
Training loss: 1.6177829504013062
Validation loss: 1.9382384964214858

Epoch: 5| Step: 9
Training loss: 2.1620118618011475
Validation loss: 1.9241081386484125

Epoch: 5| Step: 10
Training loss: 1.7256481647491455
Validation loss: 1.9233466245794808

Epoch: 175| Step: 0
Training loss: 1.638685941696167
Validation loss: 1.9503496769935853

Epoch: 5| Step: 1
Training loss: 1.5460867881774902
Validation loss: 1.968179415631038

Epoch: 5| Step: 2
Training loss: 1.8302249908447266
Validation loss: 1.9575608417552004

Epoch: 5| Step: 3
Training loss: 2.175654888153076
Validation loss: 1.9491638201539234

Epoch: 5| Step: 4
Training loss: 1.4620296955108643
Validation loss: 1.9328782891714444

Epoch: 5| Step: 5
Training loss: 1.8061898946762085
Validation loss: 1.9359609798718524

Epoch: 5| Step: 6
Training loss: 1.5792068243026733
Validation loss: 1.9389243997553343

Epoch: 5| Step: 7
Training loss: 1.8981386423110962
Validation loss: 1.9520499142267371

Epoch: 5| Step: 8
Training loss: 2.236370801925659
Validation loss: 1.9585633636802755

Epoch: 5| Step: 9
Training loss: 1.7152822017669678
Validation loss: 1.9765612515070106

Epoch: 5| Step: 10
Training loss: 1.8101072311401367
Validation loss: 1.9638481332409767

Epoch: 176| Step: 0
Training loss: 1.6635468006134033
Validation loss: 1.9784130152835642

Epoch: 5| Step: 1
Training loss: 2.0021884441375732
Validation loss: 2.012744067817606

Epoch: 5| Step: 2
Training loss: 1.4804069995880127
Validation loss: 2.049054571377334

Epoch: 5| Step: 3
Training loss: 1.693786859512329
Validation loss: 2.0525814410178893

Epoch: 5| Step: 4
Training loss: 1.801324486732483
Validation loss: 2.049939070978472

Epoch: 5| Step: 5
Training loss: 2.2885775566101074
Validation loss: 2.0262287765420894

Epoch: 5| Step: 6
Training loss: 1.8472511768341064
Validation loss: 1.9934968448454333

Epoch: 5| Step: 7
Training loss: 1.6646015644073486
Validation loss: 1.9680212095219602

Epoch: 5| Step: 8
Training loss: 1.6669740676879883
Validation loss: 1.9698339175152522

Epoch: 5| Step: 9
Training loss: 1.8922011852264404
Validation loss: 1.9596131053022159

Epoch: 5| Step: 10
Training loss: 1.4803141355514526
Validation loss: 1.9499487620528027

Epoch: 177| Step: 0
Training loss: 1.0171335935592651
Validation loss: 1.9438626945659678

Epoch: 5| Step: 1
Training loss: 2.014901876449585
Validation loss: 1.9574456983996975

Epoch: 5| Step: 2
Training loss: 1.8496954441070557
Validation loss: 1.9839856073420534

Epoch: 5| Step: 3
Training loss: 1.7908604145050049
Validation loss: 1.9836516816128966

Epoch: 5| Step: 4
Training loss: 1.9030048847198486
Validation loss: 1.9878004699624994

Epoch: 5| Step: 5
Training loss: 1.5021178722381592
Validation loss: 1.9969066009726575

Epoch: 5| Step: 6
Training loss: 2.2364602088928223
Validation loss: 1.985469013132075

Epoch: 5| Step: 7
Training loss: 1.4768812656402588
Validation loss: 1.9743609710406231

Epoch: 5| Step: 8
Training loss: 1.7613871097564697
Validation loss: 1.9390826071462324

Epoch: 5| Step: 9
Training loss: 1.5846474170684814
Validation loss: 1.958227571620736

Epoch: 5| Step: 10
Training loss: 2.1980714797973633
Validation loss: 1.9545558985843454

Epoch: 178| Step: 0
Training loss: 1.3228299617767334
Validation loss: 1.9748231928835633

Epoch: 5| Step: 1
Training loss: 1.815866470336914
Validation loss: 1.969736159488719

Epoch: 5| Step: 2
Training loss: 1.8297770023345947
Validation loss: 1.9689254760742188

Epoch: 5| Step: 3
Training loss: 0.9452520608901978
Validation loss: 1.9765150752118839

Epoch: 5| Step: 4
Training loss: 1.843625783920288
Validation loss: 1.9853578895650885

Epoch: 5| Step: 5
Training loss: 1.9951114654541016
Validation loss: 2.0136950759477514

Epoch: 5| Step: 6
Training loss: 1.9721615314483643
Validation loss: 2.005964538102509

Epoch: 5| Step: 7
Training loss: 1.8577735424041748
Validation loss: 2.030060096453595

Epoch: 5| Step: 8
Training loss: 1.7886962890625
Validation loss: 2.0275244930739045

Epoch: 5| Step: 9
Training loss: 1.8434479236602783
Validation loss: 2.006050649509635

Epoch: 5| Step: 10
Training loss: 2.00058650970459
Validation loss: 2.015849591583334

Epoch: 179| Step: 0
Training loss: 2.197939872741699
Validation loss: 2.015002750581311

Epoch: 5| Step: 1
Training loss: 1.7679344415664673
Validation loss: 1.9748015275565527

Epoch: 5| Step: 2
Training loss: 1.8065435886383057
Validation loss: 1.9546793647991714

Epoch: 5| Step: 3
Training loss: 1.182123064994812
Validation loss: 1.9105320233170704

Epoch: 5| Step: 4
Training loss: 1.8840997219085693
Validation loss: 1.9084220188920216

Epoch: 5| Step: 5
Training loss: 1.7705281972885132
Validation loss: 1.8791970309390817

Epoch: 5| Step: 6
Training loss: 1.395586371421814
Validation loss: 1.8790121091309415

Epoch: 5| Step: 7
Training loss: 1.7654424905776978
Validation loss: 1.8938034606236283

Epoch: 5| Step: 8
Training loss: 2.2570319175720215
Validation loss: 1.9232129640476678

Epoch: 5| Step: 9
Training loss: 1.4454405307769775
Validation loss: 1.960908628279163

Epoch: 5| Step: 10
Training loss: 1.7334604263305664
Validation loss: 1.958878344105136

Epoch: 180| Step: 0
Training loss: 1.3511782884597778
Validation loss: 1.9638215123966176

Epoch: 5| Step: 1
Training loss: 1.616309404373169
Validation loss: 1.9652228893772248

Epoch: 5| Step: 2
Training loss: 1.6899477243423462
Validation loss: 1.9703704439183718

Epoch: 5| Step: 3
Training loss: 1.8793957233428955
Validation loss: 1.9652799688359743

Epoch: 5| Step: 4
Training loss: 1.6934058666229248
Validation loss: 1.9531416905823575

Epoch: 5| Step: 5
Training loss: 1.7507473230361938
Validation loss: 1.9479028089072115

Epoch: 5| Step: 6
Training loss: 0.98249351978302
Validation loss: 1.94512519913335

Epoch: 5| Step: 7
Training loss: 1.824403166770935
Validation loss: 1.963079919097244

Epoch: 5| Step: 8
Training loss: 2.0495903491973877
Validation loss: 1.9821531926431963

Epoch: 5| Step: 9
Training loss: 2.0444788932800293
Validation loss: 1.9500654641018118

Epoch: 5| Step: 10
Training loss: 1.779441237449646
Validation loss: 1.9653520379015195

Epoch: 181| Step: 0
Training loss: 1.7811195850372314
Validation loss: 1.955207319669826

Epoch: 5| Step: 1
Training loss: 1.5299689769744873
Validation loss: 1.947555003627654

Epoch: 5| Step: 2
Training loss: 1.8740761280059814
Validation loss: 1.9484336055735105

Epoch: 5| Step: 3
Training loss: 1.5210199356079102
Validation loss: 1.9370783926338278

Epoch: 5| Step: 4
Training loss: 1.6553417444229126
Validation loss: 1.9270797032181934

Epoch: 5| Step: 5
Training loss: 1.9451510906219482
Validation loss: 1.9224209388097127

Epoch: 5| Step: 6
Training loss: 0.96198570728302
Validation loss: 1.9222290938900364

Epoch: 5| Step: 7
Training loss: 1.6410739421844482
Validation loss: 1.92982820797992

Epoch: 5| Step: 8
Training loss: 1.9512202739715576
Validation loss: 1.9409858270358014

Epoch: 5| Step: 9
Training loss: 1.8428694009780884
Validation loss: 1.9422679049994356

Epoch: 5| Step: 10
Training loss: 1.7741113901138306
Validation loss: 1.967956002040576

Epoch: 182| Step: 0
Training loss: 1.3115593194961548
Validation loss: 1.9787897935477636

Epoch: 5| Step: 1
Training loss: 1.9353326559066772
Validation loss: 2.01153209388897

Epoch: 5| Step: 2
Training loss: 1.3193620443344116
Validation loss: 2.0199139861650366

Epoch: 5| Step: 3
Training loss: 1.3914313316345215
Validation loss: 1.9660564302116312

Epoch: 5| Step: 4
Training loss: 1.4670319557189941
Validation loss: 1.9419814925039969

Epoch: 5| Step: 5
Training loss: 2.1730923652648926
Validation loss: 1.9116314944400583

Epoch: 5| Step: 6
Training loss: 1.8242948055267334
Validation loss: 1.9114084205319803

Epoch: 5| Step: 7
Training loss: 1.630944848060608
Validation loss: 1.9525311531559113

Epoch: 5| Step: 8
Training loss: 1.7311376333236694
Validation loss: 1.9633101135171869

Epoch: 5| Step: 9
Training loss: 2.3826026916503906
Validation loss: 1.941847970408778

Epoch: 5| Step: 10
Training loss: 1.6299337148666382
Validation loss: 1.9080265132329797

Epoch: 183| Step: 0
Training loss: 1.10297429561615
Validation loss: 1.905267402689944

Epoch: 5| Step: 1
Training loss: 1.7913296222686768
Validation loss: 1.9143715814877582

Epoch: 5| Step: 2
Training loss: 1.5899145603179932
Validation loss: 1.9659426148219774

Epoch: 5| Step: 3
Training loss: 1.7346384525299072
Validation loss: 2.045863475850833

Epoch: 5| Step: 4
Training loss: 1.4033355712890625
Validation loss: 2.0707567789221324

Epoch: 5| Step: 5
Training loss: 1.623841643333435
Validation loss: 2.0496188978995047

Epoch: 5| Step: 6
Training loss: 1.66958487033844
Validation loss: 2.0102600487329627

Epoch: 5| Step: 7
Training loss: 2.563953399658203
Validation loss: 1.9858923599284182

Epoch: 5| Step: 8
Training loss: 1.9879601001739502
Validation loss: 1.9778426770241029

Epoch: 5| Step: 9
Training loss: 1.8362829685211182
Validation loss: 1.9840417805538382

Epoch: 5| Step: 10
Training loss: 1.622033715248108
Validation loss: 1.953482453541089

Epoch: 184| Step: 0
Training loss: 1.9870494604110718
Validation loss: 1.9423848505943053

Epoch: 5| Step: 1
Training loss: 1.7344672679901123
Validation loss: 1.9160799287980603

Epoch: 5| Step: 2
Training loss: 1.344020962715149
Validation loss: 1.898463979844124

Epoch: 5| Step: 3
Training loss: 1.3089392185211182
Validation loss: 1.915961621910013

Epoch: 5| Step: 4
Training loss: 1.8497498035430908
Validation loss: 1.9324694615538403

Epoch: 5| Step: 5
Training loss: 1.2916418313980103
Validation loss: 1.948438500845304

Epoch: 5| Step: 6
Training loss: 1.924899697303772
Validation loss: 1.9719527472731888

Epoch: 5| Step: 7
Training loss: 1.9533214569091797
Validation loss: 1.9764138088431409

Epoch: 5| Step: 8
Training loss: 1.3595938682556152
Validation loss: 1.9566629304680774

Epoch: 5| Step: 9
Training loss: 1.8689606189727783
Validation loss: 1.9335735459481516

Epoch: 5| Step: 10
Training loss: 1.8758631944656372
Validation loss: 1.9252011468333583

Epoch: 185| Step: 0
Training loss: 1.5105679035186768
Validation loss: 1.9498537842945387

Epoch: 5| Step: 1
Training loss: 2.136385202407837
Validation loss: 1.9718554789020168

Epoch: 5| Step: 2
Training loss: 2.2521212100982666
Validation loss: 2.000746359107315

Epoch: 5| Step: 3
Training loss: 1.8013054132461548
Validation loss: 1.975812804314398

Epoch: 5| Step: 4
Training loss: 1.7086862325668335
Validation loss: 1.9851795255496938

Epoch: 5| Step: 5
Training loss: 1.6446387767791748
Validation loss: 1.9671357857283724

Epoch: 5| Step: 6
Training loss: 1.1674271821975708
Validation loss: 1.9728382595123783

Epoch: 5| Step: 7
Training loss: 1.540282130241394
Validation loss: 2.0040336449941

Epoch: 5| Step: 8
Training loss: 1.6686508655548096
Validation loss: 1.9904988991316928

Epoch: 5| Step: 9
Training loss: 1.1589395999908447
Validation loss: 1.965850927496469

Epoch: 5| Step: 10
Training loss: 2.0795106887817383
Validation loss: 1.9252919394482848

Epoch: 186| Step: 0
Training loss: 1.3725731372833252
Validation loss: 1.9028532171762118

Epoch: 5| Step: 1
Training loss: 1.4408400058746338
Validation loss: 1.8946772890706216

Epoch: 5| Step: 2
Training loss: 1.6141510009765625
Validation loss: 1.9114365475152129

Epoch: 5| Step: 3
Training loss: 1.8457558155059814
Validation loss: 1.9212738160164125

Epoch: 5| Step: 4
Training loss: 2.7554619312286377
Validation loss: 1.922199067249093

Epoch: 5| Step: 5
Training loss: 1.2556980848312378
Validation loss: 1.9226977850801201

Epoch: 5| Step: 6
Training loss: 1.9673845767974854
Validation loss: 1.9201065596713816

Epoch: 5| Step: 7
Training loss: 1.372725486755371
Validation loss: 1.890621002002429

Epoch: 5| Step: 8
Training loss: 1.531686544418335
Validation loss: 1.9039064068948068

Epoch: 5| Step: 9
Training loss: 1.77030348777771
Validation loss: 1.9217559983653407

Epoch: 5| Step: 10
Training loss: 1.61885404586792
Validation loss: 1.957258552633306

Epoch: 187| Step: 0
Training loss: 1.5857117176055908
Validation loss: 1.9631799010820286

Epoch: 5| Step: 1
Training loss: 1.3031126260757446
Validation loss: 1.9731048460929625

Epoch: 5| Step: 2
Training loss: 2.2998154163360596
Validation loss: 1.9544099671866304

Epoch: 5| Step: 3
Training loss: 1.527119517326355
Validation loss: 1.9495901676916307

Epoch: 5| Step: 4
Training loss: 1.72653067111969
Validation loss: 1.9457702470082108

Epoch: 5| Step: 5
Training loss: 1.8488667011260986
Validation loss: 1.9252525529553812

Epoch: 5| Step: 6
Training loss: 1.7555921077728271
Validation loss: 1.9039478237910936

Epoch: 5| Step: 7
Training loss: 1.3428890705108643
Validation loss: 1.9093631954603298

Epoch: 5| Step: 8
Training loss: 2.0378241539001465
Validation loss: 1.9295965394666117

Epoch: 5| Step: 9
Training loss: 1.5167855024337769
Validation loss: 1.9179103028389715

Epoch: 5| Step: 10
Training loss: 1.079300045967102
Validation loss: 1.9156595788976198

Epoch: 188| Step: 0
Training loss: 1.2070163488388062
Validation loss: 1.9242714579387377

Epoch: 5| Step: 1
Training loss: 1.5263698101043701
Validation loss: 1.9133499207035187

Epoch: 5| Step: 2
Training loss: 1.7820860147476196
Validation loss: 1.9106890886060652

Epoch: 5| Step: 3
Training loss: 1.6412436962127686
Validation loss: 1.9153667034641388

Epoch: 5| Step: 4
Training loss: 1.6378339529037476
Validation loss: 1.906486339466546

Epoch: 5| Step: 5
Training loss: 2.105344533920288
Validation loss: 1.9126285147923294

Epoch: 5| Step: 6
Training loss: 1.988945722579956
Validation loss: 1.9485675878422235

Epoch: 5| Step: 7
Training loss: 1.5043442249298096
Validation loss: 1.9697974830545404

Epoch: 5| Step: 8
Training loss: 1.3887262344360352
Validation loss: 1.948602250827256

Epoch: 5| Step: 9
Training loss: 1.3663947582244873
Validation loss: 1.963127299021649

Epoch: 5| Step: 10
Training loss: 1.5685956478118896
Validation loss: 1.95473950652666

Epoch: 189| Step: 0
Training loss: 1.8183577060699463
Validation loss: 1.9648794768958964

Epoch: 5| Step: 1
Training loss: 1.503893256187439
Validation loss: 1.9845436772992533

Epoch: 5| Step: 2
Training loss: 1.2159373760223389
Validation loss: 1.9981422526862032

Epoch: 5| Step: 3
Training loss: 1.4571635723114014
Validation loss: 1.9901961613726873

Epoch: 5| Step: 4
Training loss: 1.5153610706329346
Validation loss: 1.9563509033572288

Epoch: 5| Step: 5
Training loss: 1.8195102214813232
Validation loss: 1.9492875017145628

Epoch: 5| Step: 6
Training loss: 1.1139861345291138
Validation loss: 1.930931947564566

Epoch: 5| Step: 7
Training loss: 1.6707369089126587
Validation loss: 1.9180190422201668

Epoch: 5| Step: 8
Training loss: 1.5344088077545166
Validation loss: 1.9064103275217035

Epoch: 5| Step: 9
Training loss: 1.9954595565795898
Validation loss: 1.883424159019224

Epoch: 5| Step: 10
Training loss: 1.8156957626342773
Validation loss: 1.8954448469223515

Epoch: 190| Step: 0
Training loss: 1.428863525390625
Validation loss: 1.886379639307658

Epoch: 5| Step: 1
Training loss: 1.520073652267456
Validation loss: 1.9026468838414838

Epoch: 5| Step: 2
Training loss: 1.8924528360366821
Validation loss: 1.8929095011885448

Epoch: 5| Step: 3
Training loss: 1.422453761100769
Validation loss: 1.907197121650942

Epoch: 5| Step: 4
Training loss: 1.460824728012085
Validation loss: 1.89860777701101

Epoch: 5| Step: 5
Training loss: 1.5648313760757446
Validation loss: 1.920810591789984

Epoch: 5| Step: 6
Training loss: 2.1191654205322266
Validation loss: 1.904405637453961

Epoch: 5| Step: 7
Training loss: 1.3771474361419678
Validation loss: 1.9268850267574351

Epoch: 5| Step: 8
Training loss: 1.3958295583724976
Validation loss: 1.9451433253544632

Epoch: 5| Step: 9
Training loss: 1.6135724782943726
Validation loss: 1.9318904389617264

Epoch: 5| Step: 10
Training loss: 1.468329906463623
Validation loss: 1.9273531770193448

Epoch: 191| Step: 0
Training loss: 1.482966661453247
Validation loss: 1.9481161948173278

Epoch: 5| Step: 1
Training loss: 0.8998287916183472
Validation loss: 1.9420907241041943

Epoch: 5| Step: 2
Training loss: 1.7497961521148682
Validation loss: 1.9719068375966882

Epoch: 5| Step: 3
Training loss: 1.5573011636734009
Validation loss: 1.966951306148242

Epoch: 5| Step: 4
Training loss: 1.775773286819458
Validation loss: 1.964968696717293

Epoch: 5| Step: 5
Training loss: 1.6418266296386719
Validation loss: 1.9729306159480926

Epoch: 5| Step: 6
Training loss: 1.6406437158584595
Validation loss: 1.9741578948113225

Epoch: 5| Step: 7
Training loss: 1.6592642068862915
Validation loss: 1.951573903842639

Epoch: 5| Step: 8
Training loss: 1.6258513927459717
Validation loss: 1.9472314593612507

Epoch: 5| Step: 9
Training loss: 1.1764979362487793
Validation loss: 1.9498942180346417

Epoch: 5| Step: 10
Training loss: 1.797775387763977
Validation loss: 1.9287616463117703

Epoch: 192| Step: 0
Training loss: 1.4464424848556519
Validation loss: 1.921801318404495

Epoch: 5| Step: 1
Training loss: 1.7871894836425781
Validation loss: 1.912380080069265

Epoch: 5| Step: 2
Training loss: 1.3064749240875244
Validation loss: 1.9264661099321099

Epoch: 5| Step: 3
Training loss: 1.4669249057769775
Validation loss: 1.9254146711800688

Epoch: 5| Step: 4
Training loss: 1.4841320514678955
Validation loss: 1.9252500405875586

Epoch: 5| Step: 5
Training loss: 1.3815431594848633
Validation loss: 1.9389866475136048

Epoch: 5| Step: 6
Training loss: 1.3999568223953247
Validation loss: 1.9579341732045656

Epoch: 5| Step: 7
Training loss: 1.965410590171814
Validation loss: 1.9659199894115489

Epoch: 5| Step: 8
Training loss: 2.1333398818969727
Validation loss: 1.9662390152613323

Epoch: 5| Step: 9
Training loss: 1.441725730895996
Validation loss: 1.9669036185869606

Epoch: 5| Step: 10
Training loss: 1.1715726852416992
Validation loss: 1.9762246224188036

Epoch: 193| Step: 0
Training loss: 1.9591366052627563
Validation loss: 1.972618297864032

Epoch: 5| Step: 1
Training loss: 1.4573564529418945
Validation loss: 1.9773542534920476

Epoch: 5| Step: 2
Training loss: 1.1898800134658813
Validation loss: 1.9515919185453845

Epoch: 5| Step: 3
Training loss: 1.6075198650360107
Validation loss: 1.9616725778066983

Epoch: 5| Step: 4
Training loss: 2.0218234062194824
Validation loss: 1.9399246682402909

Epoch: 5| Step: 5
Training loss: 2.0163207054138184
Validation loss: 1.9426807562510173

Epoch: 5| Step: 6
Training loss: 1.039844274520874
Validation loss: 1.9564661377219743

Epoch: 5| Step: 7
Training loss: 1.2740269899368286
Validation loss: 1.9473517581980715

Epoch: 5| Step: 8
Training loss: 1.5972365140914917
Validation loss: 1.9610220027226273

Epoch: 5| Step: 9
Training loss: 1.6880782842636108
Validation loss: 1.9609330431107552

Epoch: 5| Step: 10
Training loss: 1.3745698928833008
Validation loss: 1.9466180442481913

Epoch: 194| Step: 0
Training loss: 1.7053254842758179
Validation loss: 1.9615437010283112

Epoch: 5| Step: 1
Training loss: 1.7020152807235718
Validation loss: 1.973659376944265

Epoch: 5| Step: 2
Training loss: 1.6357265710830688
Validation loss: 1.9700794040515859

Epoch: 5| Step: 3
Training loss: 1.5616796016693115
Validation loss: 1.9725921794932375

Epoch: 5| Step: 4
Training loss: 1.16914963722229
Validation loss: 1.9496920954796575

Epoch: 5| Step: 5
Training loss: 1.397053599357605
Validation loss: 1.9473372787557623

Epoch: 5| Step: 6
Training loss: 1.4976691007614136
Validation loss: 1.9418226160028929

Epoch: 5| Step: 7
Training loss: 1.850085973739624
Validation loss: 1.9439047203269055

Epoch: 5| Step: 8
Training loss: 1.3733762502670288
Validation loss: 1.9354697363350981

Epoch: 5| Step: 9
Training loss: 1.3789266347885132
Validation loss: 1.9382147173727713

Epoch: 5| Step: 10
Training loss: 1.4623368978500366
Validation loss: 1.9636945032304334

Epoch: 195| Step: 0
Training loss: 1.5861518383026123
Validation loss: 1.9720768646527362

Epoch: 5| Step: 1
Training loss: 1.50882089138031
Validation loss: 1.9908259594312279

Epoch: 5| Step: 2
Training loss: 1.8674598932266235
Validation loss: 1.9999264106955579

Epoch: 5| Step: 3
Training loss: 1.3822928667068481
Validation loss: 1.9776784463595318

Epoch: 5| Step: 4
Training loss: 0.7924517393112183
Validation loss: 1.9736215222266413

Epoch: 5| Step: 5
Training loss: 1.4954367876052856
Validation loss: 1.9681012861190303

Epoch: 5| Step: 6
Training loss: 1.216705083847046
Validation loss: 1.9661249037711852

Epoch: 5| Step: 7
Training loss: 1.2981812953948975
Validation loss: 1.965070269441092

Epoch: 5| Step: 8
Training loss: 1.5142924785614014
Validation loss: 1.969050952183303

Epoch: 5| Step: 9
Training loss: 1.9262802600860596
Validation loss: 1.9482924515201199

Epoch: 5| Step: 10
Training loss: 1.9840632677078247
Validation loss: 1.9455029579900927

Epoch: 196| Step: 0
Training loss: 1.4201654195785522
Validation loss: 1.9423634441949988

Epoch: 5| Step: 1
Training loss: 1.67433762550354
Validation loss: 1.9383584376304381

Epoch: 5| Step: 2
Training loss: 1.9511525630950928
Validation loss: 1.9425986069504932

Epoch: 5| Step: 3
Training loss: 1.1569786071777344
Validation loss: 1.9340159123943699

Epoch: 5| Step: 4
Training loss: 1.530787706375122
Validation loss: 1.9209980977478849

Epoch: 5| Step: 5
Training loss: 1.5060949325561523
Validation loss: 1.912607657012119

Epoch: 5| Step: 6
Training loss: 1.5009117126464844
Validation loss: 1.9065569626387728

Epoch: 5| Step: 7
Training loss: 0.845971941947937
Validation loss: 1.9079027727086058

Epoch: 5| Step: 8
Training loss: 1.8430898189544678
Validation loss: 1.9314130365207631

Epoch: 5| Step: 9
Training loss: 0.9620571136474609
Validation loss: 1.9501568707086707

Epoch: 5| Step: 10
Training loss: 1.9120252132415771
Validation loss: 1.9536421478435557

Epoch: 197| Step: 0
Training loss: 1.4726148843765259
Validation loss: 1.9779018753318376

Epoch: 5| Step: 1
Training loss: 1.2621320486068726
Validation loss: 1.984824586940068

Epoch: 5| Step: 2
Training loss: 1.1312388181686401
Validation loss: 1.9825479317736883

Epoch: 5| Step: 3
Training loss: 1.0218440294265747
Validation loss: 2.0023709830417427

Epoch: 5| Step: 4
Training loss: 2.0127172470092773
Validation loss: 1.979025863832043

Epoch: 5| Step: 5
Training loss: 1.2640178203582764
Validation loss: 1.9734639736913866

Epoch: 5| Step: 6
Training loss: 1.2588495016098022
Validation loss: 1.9166492544194704

Epoch: 5| Step: 7
Training loss: 1.5171034336090088
Validation loss: 1.8768979413535005

Epoch: 5| Step: 8
Training loss: 1.9106180667877197
Validation loss: 1.8700281509789087

Epoch: 5| Step: 9
Training loss: 1.5832936763763428
Validation loss: 1.8508309882174256

Epoch: 5| Step: 10
Training loss: 1.7641664743423462
Validation loss: 1.8726572734053417

Epoch: 198| Step: 0
Training loss: 0.9704126119613647
Validation loss: 1.880859560863946

Epoch: 5| Step: 1
Training loss: 1.3998140096664429
Validation loss: 1.881913906784468

Epoch: 5| Step: 2
Training loss: 1.479479193687439
Validation loss: 1.8856098010975828

Epoch: 5| Step: 3
Training loss: 1.6069869995117188
Validation loss: 1.900550450048139

Epoch: 5| Step: 4
Training loss: 1.2005164623260498
Validation loss: 1.9146921429582822

Epoch: 5| Step: 5
Training loss: 1.5370118618011475
Validation loss: 1.930069975955512

Epoch: 5| Step: 6
Training loss: 1.912583589553833
Validation loss: 1.9704409055812384

Epoch: 5| Step: 7
Training loss: 2.070201873779297
Validation loss: 1.9741736637648715

Epoch: 5| Step: 8
Training loss: 1.521785020828247
Validation loss: 1.969714346752372

Epoch: 5| Step: 9
Training loss: 1.171739935874939
Validation loss: 1.9604480189661826

Epoch: 5| Step: 10
Training loss: 1.1343859434127808
Validation loss: 1.9433379429642872

Epoch: 199| Step: 0
Training loss: 1.6474956274032593
Validation loss: 1.9186632940846104

Epoch: 5| Step: 1
Training loss: 1.2597771883010864
Validation loss: 1.9071232247096237

Epoch: 5| Step: 2
Training loss: 1.1296862363815308
Validation loss: 1.8862752606791835

Epoch: 5| Step: 3
Training loss: 1.587586522102356
Validation loss: 1.911979825265946

Epoch: 5| Step: 4
Training loss: 1.2940740585327148
Validation loss: 1.9194602530489686

Epoch: 5| Step: 5
Training loss: 1.585984468460083
Validation loss: 1.9209928820210118

Epoch: 5| Step: 6
Training loss: 1.3938895463943481
Validation loss: 1.893042225991526

Epoch: 5| Step: 7
Training loss: 1.5422751903533936
Validation loss: 1.881866890897033

Epoch: 5| Step: 8
Training loss: 2.003239393234253
Validation loss: 1.8747551441192627

Epoch: 5| Step: 9
Training loss: 1.3572602272033691
Validation loss: 1.863567977823237

Epoch: 5| Step: 10
Training loss: 1.0458590984344482
Validation loss: 1.8700656326868201

Epoch: 200| Step: 0
Training loss: 1.6183046102523804
Validation loss: 1.8772220355208202

Epoch: 5| Step: 1
Training loss: 1.1933187246322632
Validation loss: 1.8951593419556976

Epoch: 5| Step: 2
Training loss: 1.0734481811523438
Validation loss: 1.9148850825525099

Epoch: 5| Step: 3
Training loss: 2.0007481575012207
Validation loss: 1.9468617387997207

Epoch: 5| Step: 4
Training loss: 0.8891494870185852
Validation loss: 1.9839099222613918

Epoch: 5| Step: 5
Training loss: 1.6448787450790405
Validation loss: 1.96302092459894

Epoch: 5| Step: 6
Training loss: 1.3045446872711182
Validation loss: 1.9591074515414495

Epoch: 5| Step: 7
Training loss: 1.0135390758514404
Validation loss: 1.9374047222957815

Epoch: 5| Step: 8
Training loss: 1.6428091526031494
Validation loss: 1.9662097064397668

Epoch: 5| Step: 9
Training loss: 2.0705459117889404
Validation loss: 2.006130113396593

Epoch: 5| Step: 10
Training loss: 1.79091215133667
Validation loss: 1.9831665792772848

Epoch: 201| Step: 0
Training loss: 1.8668502569198608
Validation loss: 1.9617838513466619

Epoch: 5| Step: 1
Training loss: 0.9158769845962524
Validation loss: 1.9334993259881132

Epoch: 5| Step: 2
Training loss: 1.9877831935882568
Validation loss: 1.927188898927422

Epoch: 5| Step: 3
Training loss: 1.1905070543289185
Validation loss: 1.8786922539434125

Epoch: 5| Step: 4
Training loss: 2.204698324203491
Validation loss: 1.8588488178868448

Epoch: 5| Step: 5
Training loss: 1.2519547939300537
Validation loss: 1.8633886691062682

Epoch: 5| Step: 6
Training loss: 1.9034134149551392
Validation loss: 1.8709834647435013

Epoch: 5| Step: 7
Training loss: 1.2255752086639404
Validation loss: 1.8878179339952366

Epoch: 5| Step: 8
Training loss: 1.2481348514556885
Validation loss: 1.899453729711553

Epoch: 5| Step: 9
Training loss: 1.5122501850128174
Validation loss: 1.9097632195359917

Epoch: 5| Step: 10
Training loss: 1.3536186218261719
Validation loss: 1.902662225948867

Epoch: 202| Step: 0
Training loss: 1.5458176136016846
Validation loss: 1.9463530791703092

Epoch: 5| Step: 1
Training loss: 1.0626399517059326
Validation loss: 1.9841972243401311

Epoch: 5| Step: 2
Training loss: 1.7853736877441406
Validation loss: 2.057126200327309

Epoch: 5| Step: 3
Training loss: 1.307389736175537
Validation loss: 2.0813618424118205

Epoch: 5| Step: 4
Training loss: 0.7348614931106567
Validation loss: 2.016160252273724

Epoch: 5| Step: 5
Training loss: 1.3948322534561157
Validation loss: 1.9641344803635792

Epoch: 5| Step: 6
Training loss: 1.7969253063201904
Validation loss: 1.9066756361274309

Epoch: 5| Step: 7
Training loss: 1.92281174659729
Validation loss: 1.9024200183089062

Epoch: 5| Step: 8
Training loss: 1.4620168209075928
Validation loss: 1.8677221549454557

Epoch: 5| Step: 9
Training loss: 1.7214891910552979
Validation loss: 1.8678917154189079

Epoch: 5| Step: 10
Training loss: 1.4947917461395264
Validation loss: 1.854041685340225

Epoch: 203| Step: 0
Training loss: 1.4137041568756104
Validation loss: 1.8353521016336256

Epoch: 5| Step: 1
Training loss: 1.164790391921997
Validation loss: 1.8511892467416742

Epoch: 5| Step: 2
Training loss: 1.050257682800293
Validation loss: 1.8472222858859646

Epoch: 5| Step: 3
Training loss: 1.5704892873764038
Validation loss: 1.888759595091625

Epoch: 5| Step: 4
Training loss: 0.7649633288383484
Validation loss: 1.8946430631863174

Epoch: 5| Step: 5
Training loss: 1.6981170177459717
Validation loss: 1.924104735415469

Epoch: 5| Step: 6
Training loss: 1.995561957359314
Validation loss: 1.93169036475561

Epoch: 5| Step: 7
Training loss: 0.8299530148506165
Validation loss: 1.9761386558573732

Epoch: 5| Step: 8
Training loss: 1.7209008932113647
Validation loss: 1.979804042846926

Epoch: 5| Step: 9
Training loss: 1.3977711200714111
Validation loss: 1.9945091047594625

Epoch: 5| Step: 10
Training loss: 2.2214722633361816
Validation loss: 1.9780056835502706

Epoch: 204| Step: 0
Training loss: 1.413965106010437
Validation loss: 1.9829721886624572

Epoch: 5| Step: 1
Training loss: 1.5607473850250244
Validation loss: 1.970118579044137

Epoch: 5| Step: 2
Training loss: 1.332377552986145
Validation loss: 1.9883179805612052

Epoch: 5| Step: 3
Training loss: 1.0112788677215576
Validation loss: 1.9619120064602102

Epoch: 5| Step: 4
Training loss: 1.877353310585022
Validation loss: 1.9686328403411373

Epoch: 5| Step: 5
Training loss: 1.7504005432128906
Validation loss: 1.948066044879216

Epoch: 5| Step: 6
Training loss: 1.5498183965682983
Validation loss: 1.9293566160304572

Epoch: 5| Step: 7
Training loss: 1.627750039100647
Validation loss: 1.937695687816989

Epoch: 5| Step: 8
Training loss: 0.6859244108200073
Validation loss: 1.9490690808142386

Epoch: 5| Step: 9
Training loss: 1.2481626272201538
Validation loss: 1.913854588744461

Epoch: 5| Step: 10
Training loss: 1.2225375175476074
Validation loss: 1.9147196937632818

Epoch: 205| Step: 0
Training loss: 1.3414989709854126
Validation loss: 1.8945049496107205

Epoch: 5| Step: 1
Training loss: 1.2632386684417725
Validation loss: 1.9202748754973054

Epoch: 5| Step: 2
Training loss: 1.5412237644195557
Validation loss: 1.9252933148414857

Epoch: 5| Step: 3
Training loss: 1.4391318559646606
Validation loss: 1.922980300841793

Epoch: 5| Step: 4
Training loss: 1.6838871240615845
Validation loss: 1.9585149185631865

Epoch: 5| Step: 5
Training loss: 1.6833175420761108
Validation loss: 1.9483730754544657

Epoch: 5| Step: 6
Training loss: 1.1112312078475952
Validation loss: 1.9347756972876928

Epoch: 5| Step: 7
Training loss: 1.4006052017211914
Validation loss: 1.9238978624343872

Epoch: 5| Step: 8
Training loss: 1.112113356590271
Validation loss: 1.9296143618963097

Epoch: 5| Step: 9
Training loss: 0.9510944485664368
Validation loss: 1.9442300053053005

Epoch: 5| Step: 10
Training loss: 1.505127191543579
Validation loss: 1.9468240609733007

Epoch: 206| Step: 0
Training loss: 1.6497058868408203
Validation loss: 1.9589711337961175

Epoch: 5| Step: 1
Training loss: 0.8745611310005188
Validation loss: 1.96266847015709

Epoch: 5| Step: 2
Training loss: 1.0866217613220215
Validation loss: 1.965966711762131

Epoch: 5| Step: 3
Training loss: 1.23273766040802
Validation loss: 1.9508761693072576

Epoch: 5| Step: 4
Training loss: 1.4741624593734741
Validation loss: 1.946227773543327

Epoch: 5| Step: 5
Training loss: 1.6663951873779297
Validation loss: 1.9441757663603751

Epoch: 5| Step: 6
Training loss: 1.3979600667953491
Validation loss: 1.9208762107356903

Epoch: 5| Step: 7
Training loss: 1.4646432399749756
Validation loss: 1.920147083138907

Epoch: 5| Step: 8
Training loss: 0.8472429513931274
Validation loss: 1.9221680074609735

Epoch: 5| Step: 9
Training loss: 1.3818223476409912
Validation loss: 1.9252671234069332

Epoch: 5| Step: 10
Training loss: 1.8361570835113525
Validation loss: 1.920627373521046

Epoch: 207| Step: 0
Training loss: 1.304640531539917
Validation loss: 1.9159475218865178

Epoch: 5| Step: 1
Training loss: 1.016907811164856
Validation loss: 1.9162708738798737

Epoch: 5| Step: 2
Training loss: 1.286128282546997
Validation loss: 1.9117824980007705

Epoch: 5| Step: 3
Training loss: 1.5140565633773804
Validation loss: 1.9004356989296534

Epoch: 5| Step: 4
Training loss: 1.4227383136749268
Validation loss: 1.890104716823947

Epoch: 5| Step: 5
Training loss: 1.0470285415649414
Validation loss: 1.8892462099752119

Epoch: 5| Step: 6
Training loss: 1.2598590850830078
Validation loss: 1.8891261367387668

Epoch: 5| Step: 7
Training loss: 1.2895548343658447
Validation loss: 1.8823424436712777

Epoch: 5| Step: 8
Training loss: 1.3237695693969727
Validation loss: 1.881586517057111

Epoch: 5| Step: 9
Training loss: 1.7160056829452515
Validation loss: 1.8763235666418587

Epoch: 5| Step: 10
Training loss: 1.3665636777877808
Validation loss: 1.8965748125506985

Epoch: 208| Step: 0
Training loss: 1.2084705829620361
Validation loss: 1.867269459591117

Epoch: 5| Step: 1
Training loss: 1.2102127075195312
Validation loss: 1.8809368738564112

Epoch: 5| Step: 2
Training loss: 1.711251974105835
Validation loss: 1.881846268971761

Epoch: 5| Step: 3
Training loss: 1.4812015295028687
Validation loss: 1.8913742573030534

Epoch: 5| Step: 4
Training loss: 0.9938195943832397
Validation loss: 1.9124027618797876

Epoch: 5| Step: 5
Training loss: 1.6194477081298828
Validation loss: 1.9248641742173063

Epoch: 5| Step: 6
Training loss: 1.345483422279358
Validation loss: 1.923364016317552

Epoch: 5| Step: 7
Training loss: 0.963811993598938
Validation loss: 1.9367427492654452

Epoch: 5| Step: 8
Training loss: 1.5530991554260254
Validation loss: 1.9193538619625954

Epoch: 5| Step: 9
Training loss: 1.2490167617797852
Validation loss: 1.8893414697339457

Epoch: 5| Step: 10
Training loss: 0.9708300232887268
Validation loss: 1.8762978507626442

Epoch: 209| Step: 0
Training loss: 1.0634714365005493
Validation loss: 1.8547810149449173

Epoch: 5| Step: 1
Training loss: 1.1402556896209717
Validation loss: 1.8620415810615785

Epoch: 5| Step: 2
Training loss: 1.3056955337524414
Validation loss: 1.8522204404236169

Epoch: 5| Step: 3
Training loss: 1.4733186960220337
Validation loss: 1.8643840307830482

Epoch: 5| Step: 4
Training loss: 1.087691068649292
Validation loss: 1.8643810197871218

Epoch: 5| Step: 5
Training loss: 1.0630290508270264
Validation loss: 1.891059248678146

Epoch: 5| Step: 6
Training loss: 1.4880163669586182
Validation loss: 1.8911587076802407

Epoch: 5| Step: 7
Training loss: 1.6860589981079102
Validation loss: 1.8975044578634284

Epoch: 5| Step: 8
Training loss: 1.4114195108413696
Validation loss: 1.9094504053874681

Epoch: 5| Step: 9
Training loss: 1.159464955329895
Validation loss: 1.9093868411997312

Epoch: 5| Step: 10
Training loss: 1.361262321472168
Validation loss: 1.878515197384742

Epoch: 210| Step: 0
Training loss: 1.4572480916976929
Validation loss: 1.888535056062924

Epoch: 5| Step: 1
Training loss: 1.481871247291565
Validation loss: 1.8953526020050049

Epoch: 5| Step: 2
Training loss: 0.9823409914970398
Validation loss: 1.9044498807640486

Epoch: 5| Step: 3
Training loss: 1.3588800430297852
Validation loss: 1.8769231944955804

Epoch: 5| Step: 4
Training loss: 1.3627245426177979
Validation loss: 1.893273517649661

Epoch: 5| Step: 5
Training loss: 1.2003430128097534
Validation loss: 1.8741527500972952

Epoch: 5| Step: 6
Training loss: 0.9619328379631042
Validation loss: 1.8635897905595842

Epoch: 5| Step: 7
Training loss: 1.2972365617752075
Validation loss: 1.8837941590175833

Epoch: 5| Step: 8
Training loss: 1.2095903158187866
Validation loss: 1.9013320489596295

Epoch: 5| Step: 9
Training loss: 1.1295161247253418
Validation loss: 1.936117083795609

Epoch: 5| Step: 10
Training loss: 1.462774395942688
Validation loss: 1.954202845532407

Epoch: 211| Step: 0
Training loss: 1.350433588027954
Validation loss: 1.9353286476545437

Epoch: 5| Step: 1
Training loss: 0.8558578491210938
Validation loss: 1.921804666519165

Epoch: 5| Step: 2
Training loss: 1.1878917217254639
Validation loss: 1.9088683064265917

Epoch: 5| Step: 3
Training loss: 1.1291773319244385
Validation loss: 1.8974606093539987

Epoch: 5| Step: 4
Training loss: 2.0232326984405518
Validation loss: 1.8837678342737176

Epoch: 5| Step: 5
Training loss: 0.9922815561294556
Validation loss: 1.8692568835391794

Epoch: 5| Step: 6
Training loss: 1.1812825202941895
Validation loss: 1.8597812665406095

Epoch: 5| Step: 7
Training loss: 1.281158208847046
Validation loss: 1.876106277588875

Epoch: 5| Step: 8
Training loss: 1.763296127319336
Validation loss: 1.8623665058484642

Epoch: 5| Step: 9
Training loss: 1.025978684425354
Validation loss: 1.8642859125650058

Epoch: 5| Step: 10
Training loss: 0.9623991847038269
Validation loss: 1.8913906953668083

Epoch: 212| Step: 0
Training loss: 1.553879976272583
Validation loss: 1.9046003626238914

Epoch: 5| Step: 1
Training loss: 1.2901365756988525
Validation loss: 1.8812204496834868

Epoch: 5| Step: 2
Training loss: 1.0829793214797974
Validation loss: 1.8818914736470869

Epoch: 5| Step: 3
Training loss: 1.1868776082992554
Validation loss: 1.8841924346903318

Epoch: 5| Step: 4
Training loss: 1.380561113357544
Validation loss: 1.879175889876581

Epoch: 5| Step: 5
Training loss: 1.5728332996368408
Validation loss: 1.898729984478284

Epoch: 5| Step: 6
Training loss: 0.8825322985649109
Validation loss: 1.904356159189696

Epoch: 5| Step: 7
Training loss: 0.8794976472854614
Validation loss: 1.942730926698254

Epoch: 5| Step: 8
Training loss: 1.9008128643035889
Validation loss: 1.9268701858417963

Epoch: 5| Step: 9
Training loss: 0.8692556619644165
Validation loss: 1.9113524818933139

Epoch: 5| Step: 10
Training loss: 1.23764169216156
Validation loss: 1.8961174385522002

Epoch: 213| Step: 0
Training loss: 1.4059765338897705
Validation loss: 1.8902268666093067

Epoch: 5| Step: 1
Training loss: 1.0796552896499634
Validation loss: 1.8782547468780189

Epoch: 5| Step: 2
Training loss: 0.8861198425292969
Validation loss: 1.8967206221754833

Epoch: 5| Step: 3
Training loss: 1.1541144847869873
Validation loss: 1.8916623541103896

Epoch: 5| Step: 4
Training loss: 1.0809786319732666
Validation loss: 1.8332643508911133

Epoch: 5| Step: 5
Training loss: 1.0597699880599976
Validation loss: 1.8371396859486897

Epoch: 5| Step: 6
Training loss: 1.0938050746917725
Validation loss: 1.838583871882449

Epoch: 5| Step: 7
Training loss: 1.6984189748764038
Validation loss: 1.824861652107649

Epoch: 5| Step: 8
Training loss: 1.6153491735458374
Validation loss: 1.8424595953315817

Epoch: 5| Step: 9
Training loss: 1.3187386989593506
Validation loss: 1.862683723049779

Epoch: 5| Step: 10
Training loss: 1.2260791063308716
Validation loss: 1.880911498941401

Epoch: 214| Step: 0
Training loss: 1.0085043907165527
Validation loss: 1.8901052603157618

Epoch: 5| Step: 1
Training loss: 1.406740427017212
Validation loss: 1.893634016795825

Epoch: 5| Step: 2
Training loss: 1.2699949741363525
Validation loss: 1.8761806154763827

Epoch: 5| Step: 3
Training loss: 1.3568028211593628
Validation loss: 1.8623535709996377

Epoch: 5| Step: 4
Training loss: 1.4593093395233154
Validation loss: 1.8549650535788587

Epoch: 5| Step: 5
Training loss: 1.1258538961410522
Validation loss: 1.8395843992951095

Epoch: 5| Step: 6
Training loss: 1.52461838722229
Validation loss: 1.8497022941548338

Epoch: 5| Step: 7
Training loss: 1.1528992652893066
Validation loss: 1.8525498682452786

Epoch: 5| Step: 8
Training loss: 1.2388036251068115
Validation loss: 1.8678405207972373

Epoch: 5| Step: 9
Training loss: 1.0281782150268555
Validation loss: 1.878878076871236

Epoch: 5| Step: 10
Training loss: 0.9704127311706543
Validation loss: 1.8963506042316396

Epoch: 215| Step: 0
Training loss: 1.2938652038574219
Validation loss: 1.9146750614207277

Epoch: 5| Step: 1
Training loss: 1.1238594055175781
Validation loss: 1.9493572365853093

Epoch: 5| Step: 2
Training loss: 0.97465580701828
Validation loss: 1.9752483778102423

Epoch: 5| Step: 3
Training loss: 1.1934311389923096
Validation loss: 1.9712159838727725

Epoch: 5| Step: 4
Training loss: 1.3912670612335205
Validation loss: 1.9486457083814888

Epoch: 5| Step: 5
Training loss: 1.359184980392456
Validation loss: 1.9411361435408234

Epoch: 5| Step: 6
Training loss: 1.132655143737793
Validation loss: 1.916357127569055

Epoch: 5| Step: 7
Training loss: 1.2488372325897217
Validation loss: 1.8915331081677509

Epoch: 5| Step: 8
Training loss: 0.952656626701355
Validation loss: 1.8799901841789164

Epoch: 5| Step: 9
Training loss: 1.2183362245559692
Validation loss: 1.867940923219086

Epoch: 5| Step: 10
Training loss: 1.3479171991348267
Validation loss: 1.8432540021916872

Epoch: 216| Step: 0
Training loss: 1.0564420223236084
Validation loss: 1.8298923456540672

Epoch: 5| Step: 1
Training loss: 0.837299644947052
Validation loss: 1.8331543040531937

Epoch: 5| Step: 2
Training loss: 1.8851667642593384
Validation loss: 1.8352536578332224

Epoch: 5| Step: 3
Training loss: 1.2228095531463623
Validation loss: 1.841671210463329

Epoch: 5| Step: 4
Training loss: 1.5035480260849
Validation loss: 1.8416928270811677

Epoch: 5| Step: 5
Training loss: 0.9283035397529602
Validation loss: 1.868422269821167

Epoch: 5| Step: 6
Training loss: 0.9433556795120239
Validation loss: 1.8773056050782562

Epoch: 5| Step: 7
Training loss: 0.8637818098068237
Validation loss: 1.890274578525174

Epoch: 5| Step: 8
Training loss: 1.6939647197723389
Validation loss: 1.8786936908639886

Epoch: 5| Step: 9
Training loss: 1.120110273361206
Validation loss: 1.887212025221958

Epoch: 5| Step: 10
Training loss: 1.1734795570373535
Validation loss: 1.8786801035686205

Epoch: 217| Step: 0
Training loss: 1.2411954402923584
Validation loss: 1.8737276984799294

Epoch: 5| Step: 1
Training loss: 0.9594141840934753
Validation loss: 1.881320620095858

Epoch: 5| Step: 2
Training loss: 1.334809422492981
Validation loss: 1.8687298477336924

Epoch: 5| Step: 3
Training loss: 1.084924340248108
Validation loss: 1.8500645878494426

Epoch: 5| Step: 4
Training loss: 1.4221059083938599
Validation loss: 1.8200194207570886

Epoch: 5| Step: 5
Training loss: 1.384885549545288
Validation loss: 1.8010427951812744

Epoch: 5| Step: 6
Training loss: 0.9018338918685913
Validation loss: 1.801608354814591

Epoch: 5| Step: 7
Training loss: 1.2127739191055298
Validation loss: 1.7885514561847975

Epoch: 5| Step: 8
Training loss: 1.2439508438110352
Validation loss: 1.7958586562064387

Epoch: 5| Step: 9
Training loss: 1.3489853143692017
Validation loss: 1.7849433191360966

Epoch: 5| Step: 10
Training loss: 0.8674387335777283
Validation loss: 1.7992592383456487

Epoch: 218| Step: 0
Training loss: 1.3026435375213623
Validation loss: 1.815654496992788

Epoch: 5| Step: 1
Training loss: 1.1383264064788818
Validation loss: 1.8549749992227043

Epoch: 5| Step: 2
Training loss: 1.5102829933166504
Validation loss: 1.9163505415762625

Epoch: 5| Step: 3
Training loss: 1.626704216003418
Validation loss: 1.9478720888014762

Epoch: 5| Step: 4
Training loss: 0.9784284830093384
Validation loss: 1.9579063230945217

Epoch: 5| Step: 5
Training loss: 1.0702625513076782
Validation loss: 1.9584080685851395

Epoch: 5| Step: 6
Training loss: 1.2115333080291748
Validation loss: 1.9451498805835683

Epoch: 5| Step: 7
Training loss: 0.9690428972244263
Validation loss: 1.9111777582476217

Epoch: 5| Step: 8
Training loss: 1.1502221822738647
Validation loss: 1.9189412209295458

Epoch: 5| Step: 9
Training loss: 1.1666477918624878
Validation loss: 1.9195500650713522

Epoch: 5| Step: 10
Training loss: 0.9944579005241394
Validation loss: 1.882078379713079

Epoch: 219| Step: 0
Training loss: 0.9110211133956909
Validation loss: 1.8592716852823894

Epoch: 5| Step: 1
Training loss: 1.0587127208709717
Validation loss: 1.8204480653168054

Epoch: 5| Step: 2
Training loss: 0.9810444712638855
Validation loss: 1.8077606206299157

Epoch: 5| Step: 3
Training loss: 1.244256854057312
Validation loss: 1.7986006275300057

Epoch: 5| Step: 4
Training loss: 1.3793318271636963
Validation loss: 1.8370183565283333

Epoch: 5| Step: 5
Training loss: 1.1031103134155273
Validation loss: 1.8397288912086076

Epoch: 5| Step: 6
Training loss: 1.8577287197113037
Validation loss: 1.8513025570941228

Epoch: 5| Step: 7
Training loss: 1.344541072845459
Validation loss: 1.874572164268904

Epoch: 5| Step: 8
Training loss: 0.768843948841095
Validation loss: 1.8756907165691417

Epoch: 5| Step: 9
Training loss: 1.231910228729248
Validation loss: 1.8782710490688201

Epoch: 5| Step: 10
Training loss: 1.0804328918457031
Validation loss: 1.9048502560584777

Epoch: 220| Step: 0
Training loss: 1.602417230606079
Validation loss: 1.946373096076391

Epoch: 5| Step: 1
Training loss: 1.2018579244613647
Validation loss: 1.9473971679646482

Epoch: 5| Step: 2
Training loss: 1.175972580909729
Validation loss: 1.9136142384621404

Epoch: 5| Step: 3
Training loss: 0.9297822713851929
Validation loss: 1.8839316470648653

Epoch: 5| Step: 4
Training loss: 1.2036874294281006
Validation loss: 1.8458136358568746

Epoch: 5| Step: 5
Training loss: 1.3546078205108643
Validation loss: 1.8342428412488712

Epoch: 5| Step: 6
Training loss: 1.2477524280548096
Validation loss: 1.8194618366097892

Epoch: 5| Step: 7
Training loss: 1.2950938940048218
Validation loss: 1.8057794135103944

Epoch: 5| Step: 8
Training loss: 1.008093237876892
Validation loss: 1.8068282706763155

Epoch: 5| Step: 9
Training loss: 1.0381238460540771
Validation loss: 1.7897352159664195

Epoch: 5| Step: 10
Training loss: 0.8161546587944031
Validation loss: 1.78429566660235

Epoch: 221| Step: 0
Training loss: 1.24592924118042
Validation loss: 1.7799741657831336

Epoch: 5| Step: 1
Training loss: 1.765058159828186
Validation loss: 1.7908229084425076

Epoch: 5| Step: 2
Training loss: 1.0259207487106323
Validation loss: 1.785344268686028

Epoch: 5| Step: 3
Training loss: 0.8901497721672058
Validation loss: 1.7912693818410237

Epoch: 5| Step: 4
Training loss: 0.9370955228805542
Validation loss: 1.8205195767905122

Epoch: 5| Step: 5
Training loss: 1.24160897731781
Validation loss: 1.8238782831417617

Epoch: 5| Step: 6
Training loss: 1.052908182144165
Validation loss: 1.8312139793108868

Epoch: 5| Step: 7
Training loss: 1.1619727611541748
Validation loss: 1.854854437612718

Epoch: 5| Step: 8
Training loss: 1.0627620220184326
Validation loss: 1.878655146527034

Epoch: 5| Step: 9
Training loss: 1.1656125783920288
Validation loss: 1.8697797662468367

Epoch: 5| Step: 10
Training loss: 1.1551880836486816
Validation loss: 1.8401627309860722

Epoch: 222| Step: 0
Training loss: 0.8597049713134766
Validation loss: 1.7831705718912103

Epoch: 5| Step: 1
Training loss: 1.2466548681259155
Validation loss: 1.8143460724943428

Epoch: 5| Step: 2
Training loss: 1.08122718334198
Validation loss: 1.7967328230539958

Epoch: 5| Step: 3
Training loss: 1.3834861516952515
Validation loss: 1.7917543072854318

Epoch: 5| Step: 4
Training loss: 1.2330422401428223
Validation loss: 1.7902555029879335

Epoch: 5| Step: 5
Training loss: 0.9748740196228027
Validation loss: 1.790752419220504

Epoch: 5| Step: 6
Training loss: 1.147325038909912
Validation loss: 1.7951155221590431

Epoch: 5| Step: 7
Training loss: 1.2480418682098389
Validation loss: 1.8215721179080266

Epoch: 5| Step: 8
Training loss: 1.009549617767334
Validation loss: 1.8114578249633952

Epoch: 5| Step: 9
Training loss: 1.3341262340545654
Validation loss: 1.8353818642195834

Epoch: 5| Step: 10
Training loss: 0.8824726343154907
Validation loss: 1.8481307491179435

Epoch: 223| Step: 0
Training loss: 1.2712185382843018
Validation loss: 1.8460926676309237

Epoch: 5| Step: 1
Training loss: 0.8833087086677551
Validation loss: 1.8493104224563928

Epoch: 5| Step: 2
Training loss: 0.9134131669998169
Validation loss: 1.8404579880417034

Epoch: 5| Step: 3
Training loss: 0.801060676574707
Validation loss: 1.8224288737902077

Epoch: 5| Step: 4
Training loss: 1.2044140100479126
Validation loss: 1.8391602795611146

Epoch: 5| Step: 5
Training loss: 0.8224982023239136
Validation loss: 1.8624960927553074

Epoch: 5| Step: 6
Training loss: 1.519652009010315
Validation loss: 1.8800062402602165

Epoch: 5| Step: 7
Training loss: 1.3392152786254883
Validation loss: 1.868794007967877

Epoch: 5| Step: 8
Training loss: 0.7128762006759644
Validation loss: 1.8634369821958645

Epoch: 5| Step: 9
Training loss: 1.5105998516082764
Validation loss: 1.8638123581486363

Epoch: 5| Step: 10
Training loss: 1.6821551322937012
Validation loss: 1.870387000422324

Epoch: 224| Step: 0
Training loss: 1.329217553138733
Validation loss: 1.8866180284048921

Epoch: 5| Step: 1
Training loss: 1.272153615951538
Validation loss: 1.8841020189305788

Epoch: 5| Step: 2
Training loss: 0.9318517446517944
Validation loss: 1.8762910917241087

Epoch: 5| Step: 3
Training loss: 1.2061761617660522
Validation loss: 1.888857009590313

Epoch: 5| Step: 4
Training loss: 1.132939338684082
Validation loss: 1.9126944221476072

Epoch: 5| Step: 5
Training loss: 0.7995312809944153
Validation loss: 1.8861616542262416

Epoch: 5| Step: 6
Training loss: 1.4287208318710327
Validation loss: 1.8483286442295197

Epoch: 5| Step: 7
Training loss: 0.8239970207214355
Validation loss: 1.845710967176704

Epoch: 5| Step: 8
Training loss: 1.2981555461883545
Validation loss: 1.8559928517187796

Epoch: 5| Step: 9
Training loss: 1.3157795667648315
Validation loss: 1.8692168868998045

Epoch: 5| Step: 10
Training loss: 1.050910472869873
Validation loss: 1.8498736543040122

Epoch: 225| Step: 0
Training loss: 1.1073156595230103
Validation loss: 1.8633121418696579

Epoch: 5| Step: 1
Training loss: 1.1881357431411743
Validation loss: 1.8625001907348633

Epoch: 5| Step: 2
Training loss: 0.7107916474342346
Validation loss: 1.876626613319561

Epoch: 5| Step: 3
Training loss: 0.9398515820503235
Validation loss: 1.869464241048341

Epoch: 5| Step: 4
Training loss: 1.2285988330841064
Validation loss: 1.9024605007581814

Epoch: 5| Step: 5
Training loss: 1.2039674520492554
Validation loss: 1.8943928608330347

Epoch: 5| Step: 6
Training loss: 1.0230623483657837
Validation loss: 1.883893028382332

Epoch: 5| Step: 7
Training loss: 1.1548874378204346
Validation loss: 1.8760994634320658

Epoch: 5| Step: 8
Training loss: 1.1250033378601074
Validation loss: 1.8619428437243226

Epoch: 5| Step: 9
Training loss: 1.0960426330566406
Validation loss: 1.8195331814468547

Epoch: 5| Step: 10
Training loss: 1.4265786409378052
Validation loss: 1.8049469045413438

Epoch: 226| Step: 0
Training loss: 0.882419764995575
Validation loss: 1.7882232537833593

Epoch: 5| Step: 1
Training loss: 1.1012306213378906
Validation loss: 1.7918342313458842

Epoch: 5| Step: 2
Training loss: 1.1071853637695312
Validation loss: 1.811843474706014

Epoch: 5| Step: 3
Training loss: 0.778617799282074
Validation loss: 1.8310644549708213

Epoch: 5| Step: 4
Training loss: 1.0082900524139404
Validation loss: 1.8671606433007024

Epoch: 5| Step: 5
Training loss: 1.4295525550842285
Validation loss: 1.8571994394384406

Epoch: 5| Step: 6
Training loss: 1.2832252979278564
Validation loss: 1.8828104003783195

Epoch: 5| Step: 7
Training loss: 0.9095994234085083
Validation loss: 1.8810750925412743

Epoch: 5| Step: 8
Training loss: 0.9613234400749207
Validation loss: 1.8961055509505733

Epoch: 5| Step: 9
Training loss: 1.70245361328125
Validation loss: 1.8688076696088236

Epoch: 5| Step: 10
Training loss: 0.5571088194847107
Validation loss: 1.8265895330777733

Epoch: 227| Step: 0
Training loss: 1.0005437135696411
Validation loss: 1.8075506764073526

Epoch: 5| Step: 1
Training loss: 0.9189971685409546
Validation loss: 1.7789713772394324

Epoch: 5| Step: 2
Training loss: 1.1720044612884521
Validation loss: 1.7704622386604227

Epoch: 5| Step: 3
Training loss: 0.8532031774520874
Validation loss: 1.782305436749612

Epoch: 5| Step: 4
Training loss: 1.2997996807098389
Validation loss: 1.7874725390506048

Epoch: 5| Step: 5
Training loss: 1.0311501026153564
Validation loss: 1.8116191330776419

Epoch: 5| Step: 6
Training loss: 1.413643717765808
Validation loss: 1.848510456341569

Epoch: 5| Step: 7
Training loss: 1.1364085674285889
Validation loss: 1.849940376897012

Epoch: 5| Step: 8
Training loss: 0.9919623136520386
Validation loss: 1.8492561796660065

Epoch: 5| Step: 9
Training loss: 0.913931667804718
Validation loss: 1.8615078746631581

Epoch: 5| Step: 10
Training loss: 0.956951379776001
Validation loss: 1.852110764031769

Epoch: 228| Step: 0
Training loss: 0.8574151992797852
Validation loss: 1.8321203121574976

Epoch: 5| Step: 1
Training loss: 1.3250576257705688
Validation loss: 1.8301237116577804

Epoch: 5| Step: 2
Training loss: 1.0515875816345215
Validation loss: 1.8230842127594897

Epoch: 5| Step: 3
Training loss: 1.3540270328521729
Validation loss: 1.8170428417062248

Epoch: 5| Step: 4
Training loss: 0.9004968404769897
Validation loss: 1.803447973343634

Epoch: 5| Step: 5
Training loss: 1.1230071783065796
Validation loss: 1.8239184682087233

Epoch: 5| Step: 6
Training loss: 1.2182868719100952
Validation loss: 1.818168015890224

Epoch: 5| Step: 7
Training loss: 0.6365397572517395
Validation loss: 1.8096227568964804

Epoch: 5| Step: 8
Training loss: 1.0632556676864624
Validation loss: 1.8122722666750672

Epoch: 5| Step: 9
Training loss: 1.1563551425933838
Validation loss: 1.8138350184245775

Epoch: 5| Step: 10
Training loss: 0.9810030460357666
Validation loss: 1.812164742459533

Epoch: 229| Step: 0
Training loss: 0.9531656503677368
Validation loss: 1.8171950206961682

Epoch: 5| Step: 1
Training loss: 1.1607893705368042
Validation loss: 1.8517186385329052

Epoch: 5| Step: 2
Training loss: 1.2157886028289795
Validation loss: 1.8689423863605787

Epoch: 5| Step: 3
Training loss: 0.6090449094772339
Validation loss: 1.9010621270825785

Epoch: 5| Step: 4
Training loss: 1.1650484800338745
Validation loss: 1.8898239981743596

Epoch: 5| Step: 5
Training loss: 0.7205613255500793
Validation loss: 1.8685258908938336

Epoch: 5| Step: 6
Training loss: 1.2446719408035278
Validation loss: 1.8587966298544278

Epoch: 5| Step: 7
Training loss: 1.1372495889663696
Validation loss: 1.8363095739836335

Epoch: 5| Step: 8
Training loss: 1.075676679611206
Validation loss: 1.8467474329856135

Epoch: 5| Step: 9
Training loss: 1.114472508430481
Validation loss: 1.8202147535098496

Epoch: 5| Step: 10
Training loss: 1.1045209169387817
Validation loss: 1.8121390765713108

Epoch: 230| Step: 0
Training loss: 0.9048102498054504
Validation loss: 1.8137092923605314

Epoch: 5| Step: 1
Training loss: 1.3898587226867676
Validation loss: 1.800891872375242

Epoch: 5| Step: 2
Training loss: 1.2431294918060303
Validation loss: 1.8207002032187678

Epoch: 5| Step: 3
Training loss: 0.855148196220398
Validation loss: 1.7972881178702078

Epoch: 5| Step: 4
Training loss: 0.8860006332397461
Validation loss: 1.8069690119835637

Epoch: 5| Step: 5
Training loss: 0.6373847126960754
Validation loss: 1.8155239564116283

Epoch: 5| Step: 6
Training loss: 0.6445710062980652
Validation loss: 1.8094363507404123

Epoch: 5| Step: 7
Training loss: 1.691075325012207
Validation loss: 1.8411219004661805

Epoch: 5| Step: 8
Training loss: 0.589242160320282
Validation loss: 1.8264126175193376

Epoch: 5| Step: 9
Training loss: 1.1378161907196045
Validation loss: 1.8361166741258355

Epoch: 5| Step: 10
Training loss: 1.5482511520385742
Validation loss: 1.841770278510227

Epoch: 231| Step: 0
Training loss: 1.12028169631958
Validation loss: 1.8523015873406523

Epoch: 5| Step: 1
Training loss: 1.1870161294937134
Validation loss: 1.8355299990664247

Epoch: 5| Step: 2
Training loss: 0.8701010942459106
Validation loss: 1.828572016890331

Epoch: 5| Step: 3
Training loss: 1.2093908786773682
Validation loss: 1.8135447912318732

Epoch: 5| Step: 4
Training loss: 0.9445955157279968
Validation loss: 1.810872527860826

Epoch: 5| Step: 5
Training loss: 0.9656327962875366
Validation loss: 1.7913991917846024

Epoch: 5| Step: 6
Training loss: 1.2441580295562744
Validation loss: 1.800000884199655

Epoch: 5| Step: 7
Training loss: 0.9810492396354675
Validation loss: 1.800083327037032

Epoch: 5| Step: 8
Training loss: 0.8644908666610718
Validation loss: 1.7927767756164714

Epoch: 5| Step: 9
Training loss: 0.9786270260810852
Validation loss: 1.8022368966892202

Epoch: 5| Step: 10
Training loss: 0.8058121800422668
Validation loss: 1.7894099784153763

Epoch: 232| Step: 0
Training loss: 1.1972025632858276
Validation loss: 1.7844464919900382

Epoch: 5| Step: 1
Training loss: 0.8142585754394531
Validation loss: 1.7762424369012155

Epoch: 5| Step: 2
Training loss: 1.1748120784759521
Validation loss: 1.7887533377575617

Epoch: 5| Step: 3
Training loss: 0.9811446070671082
Validation loss: 1.7855266640263219

Epoch: 5| Step: 4
Training loss: 0.9617778658866882
Validation loss: 1.7948393398715603

Epoch: 5| Step: 5
Training loss: 1.2988758087158203
Validation loss: 1.7861782581575456

Epoch: 5| Step: 6
Training loss: 0.8417495489120483
Validation loss: 1.8177678854234758

Epoch: 5| Step: 7
Training loss: 1.0331252813339233
Validation loss: 1.8354463500361289

Epoch: 5| Step: 8
Training loss: 0.9616848230361938
Validation loss: 1.8933385533671225

Epoch: 5| Step: 9
Training loss: 0.9417043924331665
Validation loss: 1.915217104778495

Epoch: 5| Step: 10
Training loss: 1.0869364738464355
Validation loss: 1.916071504674932

Epoch: 233| Step: 0
Training loss: 1.0466123819351196
Validation loss: 1.9003981941489763

Epoch: 5| Step: 1
Training loss: 0.8637012243270874
Validation loss: 1.856524758441474

Epoch: 5| Step: 2
Training loss: 0.8970301747322083
Validation loss: 1.8101699083082137

Epoch: 5| Step: 3
Training loss: 0.5334974527359009
Validation loss: 1.7885805060786586

Epoch: 5| Step: 4
Training loss: 1.1112067699432373
Validation loss: 1.775954508012341

Epoch: 5| Step: 5
Training loss: 1.1250317096710205
Validation loss: 1.789099944535122

Epoch: 5| Step: 6
Training loss: 0.9824779629707336
Validation loss: 1.7821823076535297

Epoch: 5| Step: 7
Training loss: 1.0218207836151123
Validation loss: 1.8011367756833312

Epoch: 5| Step: 8
Training loss: 1.338304877281189
Validation loss: 1.8333463873914493

Epoch: 5| Step: 9
Training loss: 1.2666550874710083
Validation loss: 1.805189953055433

Epoch: 5| Step: 10
Training loss: 1.1503269672393799
Validation loss: 1.8458494652983963

Epoch: 234| Step: 0
Training loss: 1.1923245191574097
Validation loss: 1.832726567022262

Epoch: 5| Step: 1
Training loss: 1.156762719154358
Validation loss: 1.8252462776758338

Epoch: 5| Step: 2
Training loss: 1.0957443714141846
Validation loss: 1.8230886459350586

Epoch: 5| Step: 3
Training loss: 0.8785459399223328
Validation loss: 1.831806380261657

Epoch: 5| Step: 4
Training loss: 0.8819792866706848
Validation loss: 1.8295854368517477

Epoch: 5| Step: 5
Training loss: 1.2471095323562622
Validation loss: 1.8362645795268397

Epoch: 5| Step: 6
Training loss: 1.0121742486953735
Validation loss: 1.8347228803942282

Epoch: 5| Step: 7
Training loss: 0.795877993106842
Validation loss: 1.8327792562464231

Epoch: 5| Step: 8
Training loss: 0.5166959762573242
Validation loss: 1.8303137017834572

Epoch: 5| Step: 9
Training loss: 0.9719764590263367
Validation loss: 1.8238586277090094

Epoch: 5| Step: 10
Training loss: 1.4311002492904663
Validation loss: 1.827545004506265

Epoch: 235| Step: 0
Training loss: 0.9321664571762085
Validation loss: 1.826869692853702

Epoch: 5| Step: 1
Training loss: 0.7720037698745728
Validation loss: 1.7832272245037941

Epoch: 5| Step: 2
Training loss: 0.9575288891792297
Validation loss: 1.7846563657124836

Epoch: 5| Step: 3
Training loss: 1.2556962966918945
Validation loss: 1.7905528558197843

Epoch: 5| Step: 4
Training loss: 1.066743016242981
Validation loss: 1.7985815617345995

Epoch: 5| Step: 5
Training loss: 0.5565455555915833
Validation loss: 1.8085371127692602

Epoch: 5| Step: 6
Training loss: 1.0078855752944946
Validation loss: 1.8355983803349156

Epoch: 5| Step: 7
Training loss: 1.2762600183486938
Validation loss: 1.8238935419308242

Epoch: 5| Step: 8
Training loss: 1.4407269954681396
Validation loss: 1.8346777833918089

Epoch: 5| Step: 9
Training loss: 0.6388923525810242
Validation loss: 1.8616501567184285

Epoch: 5| Step: 10
Training loss: 0.9156747460365295
Validation loss: 1.8456999512128933

Epoch: 236| Step: 0
Training loss: 0.971982479095459
Validation loss: 1.8263388423509495

Epoch: 5| Step: 1
Training loss: 1.1683446168899536
Validation loss: 1.8337919865885088

Epoch: 5| Step: 2
Training loss: 1.0844576358795166
Validation loss: 1.7990258047657628

Epoch: 5| Step: 3
Training loss: 1.010419249534607
Validation loss: 1.7954465625106648

Epoch: 5| Step: 4
Training loss: 0.782103419303894
Validation loss: 1.7711426288850847

Epoch: 5| Step: 5
Training loss: 1.182379961013794
Validation loss: 1.7659755137658888

Epoch: 5| Step: 6
Training loss: 0.7816156148910522
Validation loss: 1.753905056625284

Epoch: 5| Step: 7
Training loss: 0.8454979062080383
Validation loss: 1.7742285959182247

Epoch: 5| Step: 8
Training loss: 1.060705304145813
Validation loss: 1.820579118626092

Epoch: 5| Step: 9
Training loss: 0.9436723589897156
Validation loss: 1.8291546196065924

Epoch: 5| Step: 10
Training loss: 0.8591995239257812
Validation loss: 1.8173390408997894

Epoch: 237| Step: 0
Training loss: 0.6347610354423523
Validation loss: 1.8216685659141951

Epoch: 5| Step: 1
Training loss: 0.9338449239730835
Validation loss: 1.814164048881941

Epoch: 5| Step: 2
Training loss: 0.9466744661331177
Validation loss: 1.806378173571761

Epoch: 5| Step: 3
Training loss: 1.3095554113388062
Validation loss: 1.8184927253312961

Epoch: 5| Step: 4
Training loss: 1.0838021039962769
Validation loss: 1.8351294327807683

Epoch: 5| Step: 5
Training loss: 1.107891321182251
Validation loss: 1.8089878238657469

Epoch: 5| Step: 6
Training loss: 0.6207514405250549
Validation loss: 1.8186688141156269

Epoch: 5| Step: 7
Training loss: 0.927821934223175
Validation loss: 1.7971155976736417

Epoch: 5| Step: 8
Training loss: 0.9707025289535522
Validation loss: 1.8191404342651367

Epoch: 5| Step: 9
Training loss: 0.767402172088623
Validation loss: 1.81031052015161

Epoch: 5| Step: 10
Training loss: 1.1415258646011353
Validation loss: 1.81433266849928

Epoch: 238| Step: 0
Training loss: 0.954709529876709
Validation loss: 1.8188632970215173

Epoch: 5| Step: 1
Training loss: 1.1015105247497559
Validation loss: 1.8012584652951968

Epoch: 5| Step: 2
Training loss: 1.0297911167144775
Validation loss: 1.8169767190051336

Epoch: 5| Step: 3
Training loss: 0.8614999055862427
Validation loss: 1.825315462645664

Epoch: 5| Step: 4
Training loss: 1.1970570087432861
Validation loss: 1.8220938597956011

Epoch: 5| Step: 5
Training loss: 0.6941475868225098
Validation loss: 1.8321218644419024

Epoch: 5| Step: 6
Training loss: 0.8881166577339172
Validation loss: 1.8076252450225174

Epoch: 5| Step: 7
Training loss: 0.7552345991134644
Validation loss: 1.7938051839028635

Epoch: 5| Step: 8
Training loss: 0.45840463042259216
Validation loss: 1.7944817632757208

Epoch: 5| Step: 9
Training loss: 1.2259101867675781
Validation loss: 1.7785905432957474

Epoch: 5| Step: 10
Training loss: 1.016309142112732
Validation loss: 1.7763451709542224

Epoch: 239| Step: 0
Training loss: 0.9937555193901062
Validation loss: 1.7550736409361645

Epoch: 5| Step: 1
Training loss: 0.7448902130126953
Validation loss: 1.737871935290675

Epoch: 5| Step: 2
Training loss: 1.2325080633163452
Validation loss: 1.7638263958756641

Epoch: 5| Step: 3
Training loss: 0.6494843363761902
Validation loss: 1.779921616277387

Epoch: 5| Step: 4
Training loss: 1.5063302516937256
Validation loss: 1.7437561391502299

Epoch: 5| Step: 5
Training loss: 1.0076287984848022
Validation loss: 1.7655205662532518

Epoch: 5| Step: 6
Training loss: 1.1236356496810913
Validation loss: 1.795514734842444

Epoch: 5| Step: 7
Training loss: 0.6948164701461792
Validation loss: 1.8020155417021884

Epoch: 5| Step: 8
Training loss: 0.6505007743835449
Validation loss: 1.816646647709672

Epoch: 5| Step: 9
Training loss: 0.8309734463691711
Validation loss: 1.7955542969447311

Epoch: 5| Step: 10
Training loss: 0.6792382597923279
Validation loss: 1.8159772055123442

Epoch: 240| Step: 0
Training loss: 0.8819878697395325
Validation loss: 1.8098108806917745

Epoch: 5| Step: 1
Training loss: 0.9876087307929993
Validation loss: 1.8320590411463091

Epoch: 5| Step: 2
Training loss: 0.7642914652824402
Validation loss: 1.8382037788309076

Epoch: 5| Step: 3
Training loss: 0.9713262319564819
Validation loss: 1.8543528049222884

Epoch: 5| Step: 4
Training loss: 0.8754028081893921
Validation loss: 1.8462910729069864

Epoch: 5| Step: 5
Training loss: 1.0941098928451538
Validation loss: 1.8229665576770742

Epoch: 5| Step: 6
Training loss: 1.2325993776321411
Validation loss: 1.8034449815750122

Epoch: 5| Step: 7
Training loss: 0.7873086333274841
Validation loss: 1.8059045473734539

Epoch: 5| Step: 8
Training loss: 0.9820946455001831
Validation loss: 1.7713340072221653

Epoch: 5| Step: 9
Training loss: 0.9896917343139648
Validation loss: 1.7807866642552037

Epoch: 5| Step: 10
Training loss: 0.6931903958320618
Validation loss: 1.7900422888417398

Epoch: 241| Step: 0
Training loss: 1.2845903635025024
Validation loss: 1.7787167026150612

Epoch: 5| Step: 1
Training loss: 0.665416955947876
Validation loss: 1.7540758732826478

Epoch: 5| Step: 2
Training loss: 1.1845182180404663
Validation loss: 1.7879579746594993

Epoch: 5| Step: 3
Training loss: 1.0472042560577393
Validation loss: 1.76898616872808

Epoch: 5| Step: 4
Training loss: 0.8964311480522156
Validation loss: 1.7796198552654636

Epoch: 5| Step: 5
Training loss: 0.6923056840896606
Validation loss: 1.7896510503625358

Epoch: 5| Step: 6
Training loss: 0.9444150924682617
Validation loss: 1.8157002195235221

Epoch: 5| Step: 7
Training loss: 1.0298402309417725
Validation loss: 1.8137948948849913

Epoch: 5| Step: 8
Training loss: 0.7163631319999695
Validation loss: 1.8033777154901975

Epoch: 5| Step: 9
Training loss: 0.6611942052841187
Validation loss: 1.7948598810421523

Epoch: 5| Step: 10
Training loss: 0.8070040345191956
Validation loss: 1.7871758143107097

Epoch: 242| Step: 0
Training loss: 1.1839722394943237
Validation loss: 1.7841291081520818

Epoch: 5| Step: 1
Training loss: 0.8310278654098511
Validation loss: 1.8011386330409715

Epoch: 5| Step: 2
Training loss: 0.8814307451248169
Validation loss: 1.793208702918022

Epoch: 5| Step: 3
Training loss: 0.9637219309806824
Validation loss: 1.80516178249031

Epoch: 5| Step: 4
Training loss: 0.919562041759491
Validation loss: 1.8062162450564805

Epoch: 5| Step: 5
Training loss: 0.732357382774353
Validation loss: 1.801549675644085

Epoch: 5| Step: 6
Training loss: 0.7071240544319153
Validation loss: 1.805961052576701

Epoch: 5| Step: 7
Training loss: 1.1811037063598633
Validation loss: 1.829531684998543

Epoch: 5| Step: 8
Training loss: 0.8163390159606934
Validation loss: 1.8054994665166384

Epoch: 5| Step: 9
Training loss: 0.6254898905754089
Validation loss: 1.8139677419457385

Epoch: 5| Step: 10
Training loss: 1.0975755453109741
Validation loss: 1.8132562009237145

Epoch: 243| Step: 0
Training loss: 1.5068978071212769
Validation loss: 1.802269874080535

Epoch: 5| Step: 1
Training loss: 0.7134736180305481
Validation loss: 1.7875337293071132

Epoch: 5| Step: 2
Training loss: 0.7626401782035828
Validation loss: 1.7843144439881848

Epoch: 5| Step: 3
Training loss: 0.7846977710723877
Validation loss: 1.78277668645305

Epoch: 5| Step: 4
Training loss: 0.8504988551139832
Validation loss: 1.782088464306247

Epoch: 5| Step: 5
Training loss: 1.0369417667388916
Validation loss: 1.7749133802229358

Epoch: 5| Step: 6
Training loss: 0.8094356656074524
Validation loss: 1.7960087125019362

Epoch: 5| Step: 7
Training loss: 0.8213117718696594
Validation loss: 1.8127562358815184

Epoch: 5| Step: 8
Training loss: 0.9150919914245605
Validation loss: 1.8078483355942594

Epoch: 5| Step: 9
Training loss: 1.096253514289856
Validation loss: 1.8077519093790362

Epoch: 5| Step: 10
Training loss: 0.5312478542327881
Validation loss: 1.803443548499897

Epoch: 244| Step: 0
Training loss: 0.9554225206375122
Validation loss: 1.8155821151630853

Epoch: 5| Step: 1
Training loss: 0.6489137411117554
Validation loss: 1.8140435141901816

Epoch: 5| Step: 2
Training loss: 0.80645751953125
Validation loss: 1.8274440996108516

Epoch: 5| Step: 3
Training loss: 0.7910541296005249
Validation loss: 1.8410275956635833

Epoch: 5| Step: 4
Training loss: 1.072006106376648
Validation loss: 1.8193007130776682

Epoch: 5| Step: 5
Training loss: 0.8955842852592468
Validation loss: 1.8419977721347605

Epoch: 5| Step: 6
Training loss: 0.6952508687973022
Validation loss: 1.8275060166594803

Epoch: 5| Step: 7
Training loss: 0.8717962503433228
Validation loss: 1.8110818452732538

Epoch: 5| Step: 8
Training loss: 0.7827197313308716
Validation loss: 1.822907099159815

Epoch: 5| Step: 9
Training loss: 1.013380765914917
Validation loss: 1.8112428278051398

Epoch: 5| Step: 10
Training loss: 1.1704435348510742
Validation loss: 1.8187397846611597

Epoch: 245| Step: 0
Training loss: 0.8997095227241516
Validation loss: 1.811959587117677

Epoch: 5| Step: 1
Training loss: 0.8662838935852051
Validation loss: 1.7636844304300123

Epoch: 5| Step: 2
Training loss: 0.9744318723678589
Validation loss: 1.7578543950152654

Epoch: 5| Step: 3
Training loss: 0.8070493936538696
Validation loss: 1.7494424645618727

Epoch: 5| Step: 4
Training loss: 1.0190073251724243
Validation loss: 1.7444785743631341

Epoch: 5| Step: 5
Training loss: 0.7606500387191772
Validation loss: 1.762179369567543

Epoch: 5| Step: 6
Training loss: 0.9594470262527466
Validation loss: 1.76215051451037

Epoch: 5| Step: 7
Training loss: 0.5725809335708618
Validation loss: 1.7852559871571039

Epoch: 5| Step: 8
Training loss: 0.6717261672019958
Validation loss: 1.8041203765458957

Epoch: 5| Step: 9
Training loss: 0.8574768304824829
Validation loss: 1.825690402779528

Epoch: 5| Step: 10
Training loss: 1.0116628408432007
Validation loss: 1.84557512498671

Epoch: 246| Step: 0
Training loss: 0.8677911758422852
Validation loss: 1.8385397221452446

Epoch: 5| Step: 1
Training loss: 0.7625715136528015
Validation loss: 1.8593888667321974

Epoch: 5| Step: 2
Training loss: 0.7562929391860962
Validation loss: 1.8201215972182572

Epoch: 5| Step: 3
Training loss: 0.7043020725250244
Validation loss: 1.8112569701287053

Epoch: 5| Step: 4
Training loss: 0.7324994206428528
Validation loss: 1.8008201609375656

Epoch: 5| Step: 5
Training loss: 1.0158146619796753
Validation loss: 1.7934809307898245

Epoch: 5| Step: 6
Training loss: 0.9561113119125366
Validation loss: 1.7906180248465589

Epoch: 5| Step: 7
Training loss: 0.8451385498046875
Validation loss: 1.7811412029368903

Epoch: 5| Step: 8
Training loss: 0.6177207231521606
Validation loss: 1.7599975960229033

Epoch: 5| Step: 9
Training loss: 0.8881753087043762
Validation loss: 1.7469591966239355

Epoch: 5| Step: 10
Training loss: 1.2705024480819702
Validation loss: 1.7507755064195203

Epoch: 247| Step: 0
Training loss: 0.7019221186637878
Validation loss: 1.7419207967737669

Epoch: 5| Step: 1
Training loss: 0.9832946062088013
Validation loss: 1.7674777046326668

Epoch: 5| Step: 2
Training loss: 0.9069307446479797
Validation loss: 1.7647376316849903

Epoch: 5| Step: 3
Training loss: 1.0007141828536987
Validation loss: 1.7731097949448453

Epoch: 5| Step: 4
Training loss: 0.9949496388435364
Validation loss: 1.7963852818294237

Epoch: 5| Step: 5
Training loss: 0.37972745299339294
Validation loss: 1.8201008227563673

Epoch: 5| Step: 6
Training loss: 1.0574901103973389
Validation loss: 1.8269026638359152

Epoch: 5| Step: 7
Training loss: 0.951994776725769
Validation loss: 1.853121103778962

Epoch: 5| Step: 8
Training loss: 1.0587762594223022
Validation loss: 1.8458315672412995

Epoch: 5| Step: 9
Training loss: 0.6328639984130859
Validation loss: 1.8111987472862325

Epoch: 5| Step: 10
Training loss: 0.8745627403259277
Validation loss: 1.8231032125411495

Epoch: 248| Step: 0
Training loss: 0.49297505617141724
Validation loss: 1.7756644115653089

Epoch: 5| Step: 1
Training loss: 0.8808690905570984
Validation loss: 1.7763464758473058

Epoch: 5| Step: 2
Training loss: 0.9082313776016235
Validation loss: 1.767062105158324

Epoch: 5| Step: 3
Training loss: 0.7418280839920044
Validation loss: 1.7524397386017667

Epoch: 5| Step: 4
Training loss: 0.7209142446517944
Validation loss: 1.75747162295926

Epoch: 5| Step: 5
Training loss: 0.8202495574951172
Validation loss: 1.7762874839126424

Epoch: 5| Step: 6
Training loss: 1.0277736186981201
Validation loss: 1.7874796467442666

Epoch: 5| Step: 7
Training loss: 1.0222073793411255
Validation loss: 1.8013820135465233

Epoch: 5| Step: 8
Training loss: 0.7980515360832214
Validation loss: 1.8101466189148605

Epoch: 5| Step: 9
Training loss: 1.0564528703689575
Validation loss: 1.819002814190362

Epoch: 5| Step: 10
Training loss: 1.0064094066619873
Validation loss: 1.7935163654306883

Epoch: 249| Step: 0
Training loss: 0.821206271648407
Validation loss: 1.7955389125372774

Epoch: 5| Step: 1
Training loss: 0.9663146734237671
Validation loss: 1.7883774542039441

Epoch: 5| Step: 2
Training loss: 1.2385843992233276
Validation loss: 1.784207631182927

Epoch: 5| Step: 3
Training loss: 0.5451652407646179
Validation loss: 1.8004047575817312

Epoch: 5| Step: 4
Training loss: 0.7853406071662903
Validation loss: 1.7996024713721326

Epoch: 5| Step: 5
Training loss: 0.7342116236686707
Validation loss: 1.8126686388446438

Epoch: 5| Step: 6
Training loss: 0.920245349407196
Validation loss: 1.7941135552621656

Epoch: 5| Step: 7
Training loss: 0.7309601306915283
Validation loss: 1.8048180687812068

Epoch: 5| Step: 8
Training loss: 0.5324417352676392
Validation loss: 1.789085716329595

Epoch: 5| Step: 9
Training loss: 0.8622241020202637
Validation loss: 1.8025502235658708

Epoch: 5| Step: 10
Training loss: 1.1574628353118896
Validation loss: 1.7958111788636895

Epoch: 250| Step: 0
Training loss: 0.5207934379577637
Validation loss: 1.7792230011314474

Epoch: 5| Step: 1
Training loss: 0.7229549288749695
Validation loss: 1.736529460517309

Epoch: 5| Step: 2
Training loss: 1.0386583805084229
Validation loss: 1.7357833846922843

Epoch: 5| Step: 3
Training loss: 1.1526360511779785
Validation loss: 1.7450901898004676

Epoch: 5| Step: 4
Training loss: 0.9801856279373169
Validation loss: 1.7489820936674714

Epoch: 5| Step: 5
Training loss: 0.555639386177063
Validation loss: 1.737424155717255

Epoch: 5| Step: 6
Training loss: 0.740893542766571
Validation loss: 1.7369193402669763

Epoch: 5| Step: 7
Training loss: 0.9588096737861633
Validation loss: 1.745685241555655

Epoch: 5| Step: 8
Training loss: 0.515245258808136
Validation loss: 1.739549171540045

Epoch: 5| Step: 9
Training loss: 0.9197998046875
Validation loss: 1.7362495878691315

Epoch: 5| Step: 10
Training loss: 1.0971438884735107
Validation loss: 1.7404505334874636

Epoch: 251| Step: 0
Training loss: 0.8836786150932312
Validation loss: 1.774371911120671

Epoch: 5| Step: 1
Training loss: 0.684111475944519
Validation loss: 1.7631019187229935

Epoch: 5| Step: 2
Training loss: 0.6830466985702515
Validation loss: 1.7685028686318347

Epoch: 5| Step: 3
Training loss: 0.8052476048469543
Validation loss: 1.7589197761269026

Epoch: 5| Step: 4
Training loss: 0.6431378722190857
Validation loss: 1.7599613217897312

Epoch: 5| Step: 5
Training loss: 0.8556734919548035
Validation loss: 1.773323953792613

Epoch: 5| Step: 6
Training loss: 1.019838571548462
Validation loss: 1.7921539019512873

Epoch: 5| Step: 7
Training loss: 0.8576290011405945
Validation loss: 1.800344144144366

Epoch: 5| Step: 8
Training loss: 0.5060725808143616
Validation loss: 1.8086627273149387

Epoch: 5| Step: 9
Training loss: 0.9014225006103516
Validation loss: 1.792607884253225

Epoch: 5| Step: 10
Training loss: 1.2712879180908203
Validation loss: 1.802281464299848

Epoch: 252| Step: 0
Training loss: 1.1375516653060913
Validation loss: 1.8189144660067815

Epoch: 5| Step: 1
Training loss: 0.6908915638923645
Validation loss: 1.7766762266876877

Epoch: 5| Step: 2
Training loss: 0.6109534502029419
Validation loss: 1.7567847390328684

Epoch: 5| Step: 3
Training loss: 1.002217411994934
Validation loss: 1.7569280888444634

Epoch: 5| Step: 4
Training loss: 0.7073544263839722
Validation loss: 1.7790203350846485

Epoch: 5| Step: 5
Training loss: 0.7729421854019165
Validation loss: 1.7724027172211678

Epoch: 5| Step: 6
Training loss: 0.8071807026863098
Validation loss: 1.7832375290573284

Epoch: 5| Step: 7
Training loss: 1.0599651336669922
Validation loss: 1.7892609052760626

Epoch: 5| Step: 8
Training loss: 0.8748458623886108
Validation loss: 1.7907125796041181

Epoch: 5| Step: 9
Training loss: 0.586373507976532
Validation loss: 1.8004868825276692

Epoch: 5| Step: 10
Training loss: 1.0252492427825928
Validation loss: 1.805237849553426

Epoch: 253| Step: 0
Training loss: 0.7205506563186646
Validation loss: 1.796564475182564

Epoch: 5| Step: 1
Training loss: 0.7282565832138062
Validation loss: 1.7805311679840088

Epoch: 5| Step: 2
Training loss: 0.799996018409729
Validation loss: 1.7775737329195904

Epoch: 5| Step: 3
Training loss: 0.8009327054023743
Validation loss: 1.7481803881224764

Epoch: 5| Step: 4
Training loss: 0.8956365585327148
Validation loss: 1.7684716845071444

Epoch: 5| Step: 5
Training loss: 0.8936858177185059
Validation loss: 1.768187484433574

Epoch: 5| Step: 6
Training loss: 0.6620801687240601
Validation loss: 1.7749479457896242

Epoch: 5| Step: 7
Training loss: 0.7989735007286072
Validation loss: 1.724472221507821

Epoch: 5| Step: 8
Training loss: 1.0774904489517212
Validation loss: 1.748163733431088

Epoch: 5| Step: 9
Training loss: 0.8550534248352051
Validation loss: 1.7298630206815657

Epoch: 5| Step: 10
Training loss: 0.8194258809089661
Validation loss: 1.7412146752880466

Epoch: 254| Step: 0
Training loss: 0.6162912249565125
Validation loss: 1.775451156400865

Epoch: 5| Step: 1
Training loss: 0.7204128503799438
Validation loss: 1.7799219482688493

Epoch: 5| Step: 2
Training loss: 0.6402896046638489
Validation loss: 1.7938523933451662

Epoch: 5| Step: 3
Training loss: 0.7233797907829285
Validation loss: 1.797000801691445

Epoch: 5| Step: 4
Training loss: 1.1389297246932983
Validation loss: 1.8000348562835364

Epoch: 5| Step: 5
Training loss: 1.021069884300232
Validation loss: 1.7961245429131292

Epoch: 5| Step: 6
Training loss: 0.8000872731208801
Validation loss: 1.7988214531252462

Epoch: 5| Step: 7
Training loss: 1.0702203512191772
Validation loss: 1.7870636524692658

Epoch: 5| Step: 8
Training loss: 0.5195251107215881
Validation loss: 1.7696370924672773

Epoch: 5| Step: 9
Training loss: 1.1609359979629517
Validation loss: 1.7763916638589674

Epoch: 5| Step: 10
Training loss: 0.6546630859375
Validation loss: 1.7490212404599754

Epoch: 255| Step: 0
Training loss: 0.809746265411377
Validation loss: 1.7489162029758576

Epoch: 5| Step: 1
Training loss: 0.5648438334465027
Validation loss: 1.7381141493397374

Epoch: 5| Step: 2
Training loss: 0.9433673024177551
Validation loss: 1.741458946658719

Epoch: 5| Step: 3
Training loss: 0.6982089281082153
Validation loss: 1.756651488683557

Epoch: 5| Step: 4
Training loss: 1.0946897268295288
Validation loss: 1.765624479580951

Epoch: 5| Step: 5
Training loss: 1.005759596824646
Validation loss: 1.7509780212115216

Epoch: 5| Step: 6
Training loss: 0.604625940322876
Validation loss: 1.759449298663806

Epoch: 5| Step: 7
Training loss: 0.44875115156173706
Validation loss: 1.7648986488260248

Epoch: 5| Step: 8
Training loss: 0.8186680674552917
Validation loss: 1.7703785588664394

Epoch: 5| Step: 9
Training loss: 0.649043083190918
Validation loss: 1.7773747418516426

Epoch: 5| Step: 10
Training loss: 1.3864004611968994
Validation loss: 1.7935003260130524

Epoch: 256| Step: 0
Training loss: 0.7464010715484619
Validation loss: 1.7980022994420861

Epoch: 5| Step: 1
Training loss: 0.6190230250358582
Validation loss: 1.7868340707594348

Epoch: 5| Step: 2
Training loss: 0.8525382876396179
Validation loss: 1.7795067923043364

Epoch: 5| Step: 3
Training loss: 0.9666569828987122
Validation loss: 1.7663655511794552

Epoch: 5| Step: 4
Training loss: 1.2892043590545654
Validation loss: 1.7723263873848865

Epoch: 5| Step: 5
Training loss: 0.7124441862106323
Validation loss: 1.7642621840200117

Epoch: 5| Step: 6
Training loss: 0.6289358735084534
Validation loss: 1.7589095971917594

Epoch: 5| Step: 7
Training loss: 0.48007768392562866
Validation loss: 1.7892541244465818

Epoch: 5| Step: 8
Training loss: 1.1217130422592163
Validation loss: 1.7688714752915085

Epoch: 5| Step: 9
Training loss: 0.8571995496749878
Validation loss: 1.779701796911096

Epoch: 5| Step: 10
Training loss: 0.40664318203926086
Validation loss: 1.7685560321295133

Epoch: 257| Step: 0
Training loss: 0.8774778246879578
Validation loss: 1.771068149997342

Epoch: 5| Step: 1
Training loss: 1.0341639518737793
Validation loss: 1.7478297192563292

Epoch: 5| Step: 2
Training loss: 0.6774425506591797
Validation loss: 1.691398428332421

Epoch: 5| Step: 3
Training loss: 0.45728760957717896
Validation loss: 1.7090510245292418

Epoch: 5| Step: 4
Training loss: 0.6641222834587097
Validation loss: 1.6930958840154833

Epoch: 5| Step: 5
Training loss: 1.2035282850265503
Validation loss: 1.7123250012756677

Epoch: 5| Step: 6
Training loss: 0.8447020649909973
Validation loss: 1.6956357289386053

Epoch: 5| Step: 7
Training loss: 0.6801577806472778
Validation loss: 1.6994059470392042

Epoch: 5| Step: 8
Training loss: 1.2191846370697021
Validation loss: 1.724981729702283

Epoch: 5| Step: 9
Training loss: 0.3933172821998596
Validation loss: 1.7437217491929249

Epoch: 5| Step: 10
Training loss: 0.7065169215202332
Validation loss: 1.739509844010876

Epoch: 258| Step: 0
Training loss: 0.8519285917282104
Validation loss: 1.8059529886450818

Epoch: 5| Step: 1
Training loss: 0.4827679693698883
Validation loss: 1.8363107378764818

Epoch: 5| Step: 2
Training loss: 0.39045092463493347
Validation loss: 1.8408530412181732

Epoch: 5| Step: 3
Training loss: 0.9612756967544556
Validation loss: 1.8002517338721984

Epoch: 5| Step: 4
Training loss: 0.5091568827629089
Validation loss: 1.795191437967362

Epoch: 5| Step: 5
Training loss: 1.0160125494003296
Validation loss: 1.7933926518245409

Epoch: 5| Step: 6
Training loss: 1.2266013622283936
Validation loss: 1.7589921143747145

Epoch: 5| Step: 7
Training loss: 0.7596767544746399
Validation loss: 1.7388544749188166

Epoch: 5| Step: 8
Training loss: 1.0280978679656982
Validation loss: 1.753792138509853

Epoch: 5| Step: 9
Training loss: 0.9069468379020691
Validation loss: 1.7413417728998328

Epoch: 5| Step: 10
Training loss: 0.7375739216804504
Validation loss: 1.7887622566633328

Epoch: 259| Step: 0
Training loss: 1.0486481189727783
Validation loss: 1.7942085304567892

Epoch: 5| Step: 1
Training loss: 1.108970046043396
Validation loss: 1.82019547236863

Epoch: 5| Step: 2
Training loss: 1.0078774690628052
Validation loss: 1.8149256693419589

Epoch: 5| Step: 3
Training loss: 0.561682403087616
Validation loss: 1.8031936512198499

Epoch: 5| Step: 4
Training loss: 0.7234208583831787
Validation loss: 1.7882055877357401

Epoch: 5| Step: 5
Training loss: 0.7900761961936951
Validation loss: 1.750357581723121

Epoch: 5| Step: 6
Training loss: 0.9343056678771973
Validation loss: 1.749804796711091

Epoch: 5| Step: 7
Training loss: 0.7579591870307922
Validation loss: 1.7660894086284022

Epoch: 5| Step: 8
Training loss: 0.806726336479187
Validation loss: 1.749385304348443

Epoch: 5| Step: 9
Training loss: 0.4363384246826172
Validation loss: 1.7650330656318254

Epoch: 5| Step: 10
Training loss: 0.6515334844589233
Validation loss: 1.7643205388899772

Epoch: 260| Step: 0
Training loss: 0.8305425643920898
Validation loss: 1.7501010510229296

Epoch: 5| Step: 1
Training loss: 0.7771450281143188
Validation loss: 1.745326900994906

Epoch: 5| Step: 2
Training loss: 0.49793490767478943
Validation loss: 1.7544958809370637

Epoch: 5| Step: 3
Training loss: 0.7972405552864075
Validation loss: 1.7675778173631238

Epoch: 5| Step: 4
Training loss: 1.0081369876861572
Validation loss: 1.765631119410197

Epoch: 5| Step: 5
Training loss: 0.3792714476585388
Validation loss: 1.7176525964531848

Epoch: 5| Step: 6
Training loss: 0.7331892848014832
Validation loss: 1.7429607670794252

Epoch: 5| Step: 7
Training loss: 0.9743606448173523
Validation loss: 1.7169215666350497

Epoch: 5| Step: 8
Training loss: 0.8721802830696106
Validation loss: 1.7312126069940545

Epoch: 5| Step: 9
Training loss: 0.6999723315238953
Validation loss: 1.7638758254307572

Epoch: 5| Step: 10
Training loss: 1.0702875852584839
Validation loss: 1.7837779098941433

Epoch: 261| Step: 0
Training loss: 0.9431775212287903
Validation loss: 1.8053317890372327

Epoch: 5| Step: 1
Training loss: 0.7513775825500488
Validation loss: 1.8175636799104753

Epoch: 5| Step: 2
Training loss: 0.9827669858932495
Validation loss: 1.826892190082099

Epoch: 5| Step: 3
Training loss: 0.8470478057861328
Validation loss: 1.7993107700860629

Epoch: 5| Step: 4
Training loss: 0.8931394815444946
Validation loss: 1.7739142813990194

Epoch: 5| Step: 5
Training loss: 0.6300951838493347
Validation loss: 1.7683891391241422

Epoch: 5| Step: 6
Training loss: 0.7467249631881714
Validation loss: 1.7648694835683352

Epoch: 5| Step: 7
Training loss: 0.49152499437332153
Validation loss: 1.7698067862500426

Epoch: 5| Step: 8
Training loss: 0.5985285043716431
Validation loss: 1.7454980727164977

Epoch: 5| Step: 9
Training loss: 0.9025061726570129
Validation loss: 1.7260085664769655

Epoch: 5| Step: 10
Training loss: 0.8901584148406982
Validation loss: 1.7327213133535078

Epoch: 262| Step: 0
Training loss: 0.7162522673606873
Validation loss: 1.710854696971114

Epoch: 5| Step: 1
Training loss: 1.0157344341278076
Validation loss: 1.7304590222656087

Epoch: 5| Step: 2
Training loss: 0.758100152015686
Validation loss: 1.748443575315578

Epoch: 5| Step: 3
Training loss: 0.6735129952430725
Validation loss: 1.7549099806816346

Epoch: 5| Step: 4
Training loss: 1.0720880031585693
Validation loss: 1.7852952570043585

Epoch: 5| Step: 5
Training loss: 0.7282668948173523
Validation loss: 1.7855992881200646

Epoch: 5| Step: 6
Training loss: 0.6316438317298889
Validation loss: 1.763156424286545

Epoch: 5| Step: 7
Training loss: 0.8374126553535461
Validation loss: 1.739165036909042

Epoch: 5| Step: 8
Training loss: 0.6950300931930542
Validation loss: 1.746916247952369

Epoch: 5| Step: 9
Training loss: 0.4454089105129242
Validation loss: 1.7360474627505067

Epoch: 5| Step: 10
Training loss: 0.8838067650794983
Validation loss: 1.7411659366341048

Epoch: 263| Step: 0
Training loss: 0.7562626600265503
Validation loss: 1.7678697903951008

Epoch: 5| Step: 1
Training loss: 0.7448452711105347
Validation loss: 1.7465777140791698

Epoch: 5| Step: 2
Training loss: 0.6487786769866943
Validation loss: 1.752754888226909

Epoch: 5| Step: 3
Training loss: 0.9072965383529663
Validation loss: 1.7536392455459924

Epoch: 5| Step: 4
Training loss: 0.8237468600273132
Validation loss: 1.7464297843235794

Epoch: 5| Step: 5
Training loss: 0.8021129369735718
Validation loss: 1.7334665406134822

Epoch: 5| Step: 6
Training loss: 0.6965440511703491
Validation loss: 1.7165765198328162

Epoch: 5| Step: 7
Training loss: 0.48471754789352417
Validation loss: 1.7249673105055285

Epoch: 5| Step: 8
Training loss: 0.8738394975662231
Validation loss: 1.716448219873572

Epoch: 5| Step: 9
Training loss: 0.551864743232727
Validation loss: 1.7201650950216478

Epoch: 5| Step: 10
Training loss: 0.7288616299629211
Validation loss: 1.7337109452934676

Epoch: 264| Step: 0
Training loss: 0.7706183195114136
Validation loss: 1.7409011804929344

Epoch: 5| Step: 1
Training loss: 0.5648165345191956
Validation loss: 1.7647650767398138

Epoch: 5| Step: 2
Training loss: 0.7363254427909851
Validation loss: 1.7623886010980094

Epoch: 5| Step: 3
Training loss: 0.9143353700637817
Validation loss: 1.7769924145872875

Epoch: 5| Step: 4
Training loss: 0.697101891040802
Validation loss: 1.7808535368211809

Epoch: 5| Step: 5
Training loss: 0.754172682762146
Validation loss: 1.7811663689151886

Epoch: 5| Step: 6
Training loss: 0.5747195482254028
Validation loss: 1.765747973995824

Epoch: 5| Step: 7
Training loss: 0.774329662322998
Validation loss: 1.7453609807516939

Epoch: 5| Step: 8
Training loss: 0.6389602422714233
Validation loss: 1.7372611466274466

Epoch: 5| Step: 9
Training loss: 0.8655719757080078
Validation loss: 1.6987889479565363

Epoch: 5| Step: 10
Training loss: 0.8140694499015808
Validation loss: 1.718198703181359

Epoch: 265| Step: 0
Training loss: 0.7206071615219116
Validation loss: 1.7111132516655871

Epoch: 5| Step: 1
Training loss: 0.7285553216934204
Validation loss: 1.7304861340471493

Epoch: 5| Step: 2
Training loss: 0.572681725025177
Validation loss: 1.738414232448865

Epoch: 5| Step: 3
Training loss: 0.922640323638916
Validation loss: 1.7351077948847125

Epoch: 5| Step: 4
Training loss: 0.7510470747947693
Validation loss: 1.745593354266177

Epoch: 5| Step: 5
Training loss: 0.8128424882888794
Validation loss: 1.7515083564225065

Epoch: 5| Step: 6
Training loss: 0.8424173593521118
Validation loss: 1.7604954345251924

Epoch: 5| Step: 7
Training loss: 0.7911648750305176
Validation loss: 1.7695633057625062

Epoch: 5| Step: 8
Training loss: 1.0702903270721436
Validation loss: 1.7554006743174728

Epoch: 5| Step: 9
Training loss: 0.6270082592964172
Validation loss: 1.7402390369804956

Epoch: 5| Step: 10
Training loss: 0.34703800082206726
Validation loss: 1.7529961665471394

Epoch: 266| Step: 0
Training loss: 0.8005743026733398
Validation loss: 1.7618574147583337

Epoch: 5| Step: 1
Training loss: 0.4212911128997803
Validation loss: 1.751695821362157

Epoch: 5| Step: 2
Training loss: 0.442593514919281
Validation loss: 1.7374179786251438

Epoch: 5| Step: 3
Training loss: 0.7512739300727844
Validation loss: 1.7310189124076598

Epoch: 5| Step: 4
Training loss: 0.9113275408744812
Validation loss: 1.6941353633839598

Epoch: 5| Step: 5
Training loss: 0.611235499382019
Validation loss: 1.700955920321967

Epoch: 5| Step: 6
Training loss: 0.9671516418457031
Validation loss: 1.695885842846286

Epoch: 5| Step: 7
Training loss: 0.8148669004440308
Validation loss: 1.698037919177804

Epoch: 5| Step: 8
Training loss: 0.7436311841011047
Validation loss: 1.7054373192530807

Epoch: 5| Step: 9
Training loss: 0.7853859066963196
Validation loss: 1.7053640632219211

Epoch: 5| Step: 10
Training loss: 0.8475403785705566
Validation loss: 1.7453082312819779

Epoch: 267| Step: 0
Training loss: 0.22597818076610565
Validation loss: 1.7704330490481468

Epoch: 5| Step: 1
Training loss: 1.0369694232940674
Validation loss: 1.7734106189461165

Epoch: 5| Step: 2
Training loss: 0.6789100766181946
Validation loss: 1.7783571174067836

Epoch: 5| Step: 3
Training loss: 0.8008670806884766
Validation loss: 1.7932522963452082

Epoch: 5| Step: 4
Training loss: 0.6728197336196899
Validation loss: 1.7829158357394639

Epoch: 5| Step: 5
Training loss: 0.5128041505813599
Validation loss: 1.76969055462909

Epoch: 5| Step: 6
Training loss: 0.9240110516548157
Validation loss: 1.750619157668083

Epoch: 5| Step: 7
Training loss: 0.7646937370300293
Validation loss: 1.7453297594542145

Epoch: 5| Step: 8
Training loss: 0.7252750992774963
Validation loss: 1.7171481783672045

Epoch: 5| Step: 9
Training loss: 0.6677597165107727
Validation loss: 1.7448064550276725

Epoch: 5| Step: 10
Training loss: 0.7037444114685059
Validation loss: 1.7414693242760115

Epoch: 268| Step: 0
Training loss: 0.7995562553405762
Validation loss: 1.7312347812037314

Epoch: 5| Step: 1
Training loss: 0.5871891975402832
Validation loss: 1.7790809292947092

Epoch: 5| Step: 2
Training loss: 0.7503839731216431
Validation loss: 1.7796612619071879

Epoch: 5| Step: 3
Training loss: 0.7412068843841553
Validation loss: 1.7804374682006014

Epoch: 5| Step: 4
Training loss: 0.7337751388549805
Validation loss: 1.794511628407304

Epoch: 5| Step: 5
Training loss: 0.7822296023368835
Validation loss: 1.800219287154495

Epoch: 5| Step: 6
Training loss: 0.7113140225410461
Validation loss: 1.7942652266512635

Epoch: 5| Step: 7
Training loss: 0.6789762377738953
Validation loss: 1.8104782886402582

Epoch: 5| Step: 8
Training loss: 0.7633696794509888
Validation loss: 1.775875909354097

Epoch: 5| Step: 9
Training loss: 0.7191449403762817
Validation loss: 1.7716520781158118

Epoch: 5| Step: 10
Training loss: 0.6551550626754761
Validation loss: 1.7252230131497948

Epoch: 269| Step: 0
Training loss: 0.5363928079605103
Validation loss: 1.758343388957362

Epoch: 5| Step: 1
Training loss: 0.837948203086853
Validation loss: 1.7447734045725998

Epoch: 5| Step: 2
Training loss: 0.8190973997116089
Validation loss: 1.7586575233808128

Epoch: 5| Step: 3
Training loss: 0.314883828163147
Validation loss: 1.7532896149543025

Epoch: 5| Step: 4
Training loss: 0.4890308976173401
Validation loss: 1.7629043491937781

Epoch: 5| Step: 5
Training loss: 0.6498024463653564
Validation loss: 1.7847946651520268

Epoch: 5| Step: 6
Training loss: 0.5119467973709106
Validation loss: 1.7906921243154874

Epoch: 5| Step: 7
Training loss: 0.8514560461044312
Validation loss: 1.8107395402846798

Epoch: 5| Step: 8
Training loss: 1.2274656295776367
Validation loss: 1.7936036279124599

Epoch: 5| Step: 9
Training loss: 0.7837283611297607
Validation loss: 1.7797140049678024

Epoch: 5| Step: 10
Training loss: 0.9131083488464355
Validation loss: 1.761845254128979

Epoch: 270| Step: 0
Training loss: 0.3344360589981079
Validation loss: 1.7334651101020075

Epoch: 5| Step: 1
Training loss: 0.5384488105773926
Validation loss: 1.7491551035193986

Epoch: 5| Step: 2
Training loss: 0.688567578792572
Validation loss: 1.7465725368069065

Epoch: 5| Step: 3
Training loss: 1.0175955295562744
Validation loss: 1.740072952803745

Epoch: 5| Step: 4
Training loss: 0.8696296811103821
Validation loss: 1.7592994256686139

Epoch: 5| Step: 5
Training loss: 0.9913274049758911
Validation loss: 1.7597361136508245

Epoch: 5| Step: 6
Training loss: 0.7582486271858215
Validation loss: 1.8049527355419692

Epoch: 5| Step: 7
Training loss: 0.6245651245117188
Validation loss: 1.8029972635289675

Epoch: 5| Step: 8
Training loss: 0.5830950736999512
Validation loss: 1.7639765918895762

Epoch: 5| Step: 9
Training loss: 0.9453582763671875
Validation loss: 1.772613110080842

Epoch: 5| Step: 10
Training loss: 0.432536780834198
Validation loss: 1.7453448464793544

Epoch: 271| Step: 0
Training loss: 0.7190311551094055
Validation loss: 1.74525926702766

Epoch: 5| Step: 1
Training loss: 0.5533651113510132
Validation loss: 1.7255014437501148

Epoch: 5| Step: 2
Training loss: 1.0062261819839478
Validation loss: 1.7391595058543707

Epoch: 5| Step: 3
Training loss: 0.5194669961929321
Validation loss: 1.732882131812393

Epoch: 5| Step: 4
Training loss: 0.6900116801261902
Validation loss: 1.7339996586563766

Epoch: 5| Step: 5
Training loss: 0.7957044839859009
Validation loss: 1.7270535922819568

Epoch: 5| Step: 6
Training loss: 0.6452955007553101
Validation loss: 1.7384932015531807

Epoch: 5| Step: 7
Training loss: 0.8636912107467651
Validation loss: 1.7365177754432923

Epoch: 5| Step: 8
Training loss: 0.639999270439148
Validation loss: 1.754302591405889

Epoch: 5| Step: 9
Training loss: 0.7055944204330444
Validation loss: 1.8009329559982463

Epoch: 5| Step: 10
Training loss: 0.5792418122291565
Validation loss: 1.8057320515314739

Epoch: 272| Step: 0
Training loss: 0.6925684213638306
Validation loss: 1.806888271403569

Epoch: 5| Step: 1
Training loss: 0.7199661731719971
Validation loss: 1.7910969129172705

Epoch: 5| Step: 2
Training loss: 0.5531331896781921
Validation loss: 1.76456404501392

Epoch: 5| Step: 3
Training loss: 0.9922171831130981
Validation loss: 1.7764806632072694

Epoch: 5| Step: 4
Training loss: 0.7265883684158325
Validation loss: 1.780185644344617

Epoch: 5| Step: 5
Training loss: 0.7786667943000793
Validation loss: 1.7975210848674978

Epoch: 5| Step: 6
Training loss: 0.648290753364563
Validation loss: 1.797675322460872

Epoch: 5| Step: 7
Training loss: 0.709247350692749
Validation loss: 1.7760730020461544

Epoch: 5| Step: 8
Training loss: 0.303427129983902
Validation loss: 1.7883433693198747

Epoch: 5| Step: 9
Training loss: 0.8926496505737305
Validation loss: 1.7633066754187308

Epoch: 5| Step: 10
Training loss: 1.058269739151001
Validation loss: 1.7289646158936203

Epoch: 273| Step: 0
Training loss: 0.5796597003936768
Validation loss: 1.750906898129371

Epoch: 5| Step: 1
Training loss: 0.6841644048690796
Validation loss: 1.7819569418507237

Epoch: 5| Step: 2
Training loss: 0.503259003162384
Validation loss: 1.775786998451397

Epoch: 5| Step: 3
Training loss: 0.5450600385665894
Validation loss: 1.7841758420390468

Epoch: 5| Step: 4
Training loss: 0.7869085073471069
Validation loss: 1.770908159594382

Epoch: 5| Step: 5
Training loss: 0.8016179800033569
Validation loss: 1.7434061752852572

Epoch: 5| Step: 6
Training loss: 0.38208067417144775
Validation loss: 1.7477130518164685

Epoch: 5| Step: 7
Training loss: 0.9367012977600098
Validation loss: 1.746162587596524

Epoch: 5| Step: 8
Training loss: 0.7933516502380371
Validation loss: 1.777805603960509

Epoch: 5| Step: 9
Training loss: 0.9897536039352417
Validation loss: 1.7767118600107008

Epoch: 5| Step: 10
Training loss: 0.7215521931648254
Validation loss: 1.7766796401751939

Epoch: 274| Step: 0
Training loss: 0.5532866716384888
Validation loss: 1.7590130631641676

Epoch: 5| Step: 1
Training loss: 0.8832670450210571
Validation loss: 1.7227587481980682

Epoch: 5| Step: 2
Training loss: 0.634055495262146
Validation loss: 1.7362018631350609

Epoch: 5| Step: 3
Training loss: 0.6999667286872864
Validation loss: 1.7074238625905847

Epoch: 5| Step: 4
Training loss: 0.5802152752876282
Validation loss: 1.6972822630277244

Epoch: 5| Step: 5
Training loss: 0.7430161237716675
Validation loss: 1.6981803217241842

Epoch: 5| Step: 6
Training loss: 0.7714699506759644
Validation loss: 1.7015654874104325

Epoch: 5| Step: 7
Training loss: 0.5623597502708435
Validation loss: 1.706430967136096

Epoch: 5| Step: 8
Training loss: 0.8167521357536316
Validation loss: 1.7318689246331491

Epoch: 5| Step: 9
Training loss: 0.5018211603164673
Validation loss: 1.7432399180627638

Epoch: 5| Step: 10
Training loss: 0.9062342047691345
Validation loss: 1.7673661772922804

Epoch: 275| Step: 0
Training loss: 0.8603911399841309
Validation loss: 1.7521244531036706

Epoch: 5| Step: 1
Training loss: 0.5415218472480774
Validation loss: 1.7620851032195552

Epoch: 5| Step: 2
Training loss: 0.3894818425178528
Validation loss: 1.7628478593723749

Epoch: 5| Step: 3
Training loss: 0.8095709681510925
Validation loss: 1.7807970495634182

Epoch: 5| Step: 4
Training loss: 0.6079975366592407
Validation loss: 1.7937463432229974

Epoch: 5| Step: 5
Training loss: 0.8648961186408997
Validation loss: 1.7989461678330616

Epoch: 5| Step: 6
Training loss: 0.5658695101737976
Validation loss: 1.799867231358764

Epoch: 5| Step: 7
Training loss: 0.8511337041854858
Validation loss: 1.7534941870679137

Epoch: 5| Step: 8
Training loss: 0.7434045076370239
Validation loss: 1.755087806332496

Epoch: 5| Step: 9
Training loss: 0.34746718406677246
Validation loss: 1.7126428529780398

Epoch: 5| Step: 10
Training loss: 0.8913233876228333
Validation loss: 1.6940657297770183

Epoch: 276| Step: 0
Training loss: 0.4789181351661682
Validation loss: 1.6798564310996764

Epoch: 5| Step: 1
Training loss: 0.5768339037895203
Validation loss: 1.6912133629604051

Epoch: 5| Step: 2
Training loss: 0.6812312602996826
Validation loss: 1.6763189031231789

Epoch: 5| Step: 3
Training loss: 0.8345743417739868
Validation loss: 1.6744820584533036

Epoch: 5| Step: 4
Training loss: 0.5022428631782532
Validation loss: 1.6676980949217273

Epoch: 5| Step: 5
Training loss: 1.0688121318817139
Validation loss: 1.695366269798689

Epoch: 5| Step: 6
Training loss: 0.3909034729003906
Validation loss: 1.6826273343896354

Epoch: 5| Step: 7
Training loss: 0.8634741902351379
Validation loss: 1.7146080129890031

Epoch: 5| Step: 8
Training loss: 0.5709407329559326
Validation loss: 1.7201331687229935

Epoch: 5| Step: 9
Training loss: 0.7248004674911499
Validation loss: 1.7190105094704577

Epoch: 5| Step: 10
Training loss: 0.4929742217063904
Validation loss: 1.7444061886879705

Epoch: 277| Step: 0
Training loss: 0.6599501371383667
Validation loss: 1.755855482111695

Epoch: 5| Step: 1
Training loss: 0.44007349014282227
Validation loss: 1.7597124794478058

Epoch: 5| Step: 2
Training loss: 0.6735600233078003
Validation loss: 1.7532104035859466

Epoch: 5| Step: 3
Training loss: 0.5471035242080688
Validation loss: 1.748414187021153

Epoch: 5| Step: 4
Training loss: 0.807282567024231
Validation loss: 1.7463594175154162

Epoch: 5| Step: 5
Training loss: 0.5272931456565857
Validation loss: 1.7440603651026243

Epoch: 5| Step: 6
Training loss: 0.632678747177124
Validation loss: 1.7229352702376663

Epoch: 5| Step: 7
Training loss: 0.7375818490982056
Validation loss: 1.684286581572666

Epoch: 5| Step: 8
Training loss: 0.8220189809799194
Validation loss: 1.689149595076038

Epoch: 5| Step: 9
Training loss: 0.5968326330184937
Validation loss: 1.6921806412358438

Epoch: 5| Step: 10
Training loss: 0.8881133794784546
Validation loss: 1.6826849624674807

Epoch: 278| Step: 0
Training loss: 0.5587859749794006
Validation loss: 1.698379014127998

Epoch: 5| Step: 1
Training loss: 0.553062379360199
Validation loss: 1.7207449238787416

Epoch: 5| Step: 2
Training loss: 0.5247934460639954
Validation loss: 1.7070633467807566

Epoch: 5| Step: 3
Training loss: 0.7981980443000793
Validation loss: 1.7167799421536025

Epoch: 5| Step: 4
Training loss: 0.6056469678878784
Validation loss: 1.709523397107278

Epoch: 5| Step: 5
Training loss: 0.8879469633102417
Validation loss: 1.7270213070736136

Epoch: 5| Step: 6
Training loss: 0.544411838054657
Validation loss: 1.7416416252813032

Epoch: 5| Step: 7
Training loss: 0.7379895448684692
Validation loss: 1.7535784449628604

Epoch: 5| Step: 8
Training loss: 0.7349561452865601
Validation loss: 1.7633862751786427

Epoch: 5| Step: 9
Training loss: 0.5692644119262695
Validation loss: 1.7529908059745707

Epoch: 5| Step: 10
Training loss: 0.7056736946105957
Validation loss: 1.789789101128937

Epoch: 279| Step: 0
Training loss: 0.3196975588798523
Validation loss: 1.7847891674246839

Epoch: 5| Step: 1
Training loss: 0.5205883383750916
Validation loss: 1.775662011997674

Epoch: 5| Step: 2
Training loss: 0.8469507098197937
Validation loss: 1.7746891026855798

Epoch: 5| Step: 3
Training loss: 0.8180460929870605
Validation loss: 1.769946370073544

Epoch: 5| Step: 4
Training loss: 0.5814181566238403
Validation loss: 1.7693079261369602

Epoch: 5| Step: 5
Training loss: 0.9308261871337891
Validation loss: 1.7522804147453719

Epoch: 5| Step: 6
Training loss: 0.595421314239502
Validation loss: 1.7569196736940773

Epoch: 5| Step: 7
Training loss: 0.571593165397644
Validation loss: 1.7441980326047508

Epoch: 5| Step: 8
Training loss: 0.452843576669693
Validation loss: 1.7360094824144918

Epoch: 5| Step: 9
Training loss: 0.6359637975692749
Validation loss: 1.7633811081609418

Epoch: 5| Step: 10
Training loss: 1.0168349742889404
Validation loss: 1.7773938922471897

Epoch: 280| Step: 0
Training loss: 0.7490789294242859
Validation loss: 1.7613223009212042

Epoch: 5| Step: 1
Training loss: 0.5363661646842957
Validation loss: 1.7333719371467509

Epoch: 5| Step: 2
Training loss: 0.6568710207939148
Validation loss: 1.7139443171921598

Epoch: 5| Step: 3
Training loss: 0.8344364166259766
Validation loss: 1.7203111392195507

Epoch: 5| Step: 4
Training loss: 0.5587071180343628
Validation loss: 1.6971038131303684

Epoch: 5| Step: 5
Training loss: 0.4627891182899475
Validation loss: 1.6969307122691986

Epoch: 5| Step: 6
Training loss: 0.48413047194480896
Validation loss: 1.7444799638563586

Epoch: 5| Step: 7
Training loss: 0.5548762083053589
Validation loss: 1.747731081901058

Epoch: 5| Step: 8
Training loss: 0.7053705453872681
Validation loss: 1.7794667764376568

Epoch: 5| Step: 9
Training loss: 0.762416660785675
Validation loss: 1.7739421180499497

Epoch: 5| Step: 10
Training loss: 1.1935709714889526
Validation loss: 1.791891239022696

Epoch: 281| Step: 0
Training loss: 0.5191012620925903
Validation loss: 1.746846216981129

Epoch: 5| Step: 1
Training loss: 0.6082107424736023
Validation loss: 1.7101581083830966

Epoch: 5| Step: 2
Training loss: 0.7014764547348022
Validation loss: 1.6916622115719704

Epoch: 5| Step: 3
Training loss: 0.806750476360321
Validation loss: 1.6805927407357

Epoch: 5| Step: 4
Training loss: 0.8894013166427612
Validation loss: 1.6895374008404311

Epoch: 5| Step: 5
Training loss: 1.1998738050460815
Validation loss: 1.7099524697949808

Epoch: 5| Step: 6
Training loss: 0.4075945019721985
Validation loss: 1.7098548155958935

Epoch: 5| Step: 7
Training loss: 0.4969543516635895
Validation loss: 1.7279947585957025

Epoch: 5| Step: 8
Training loss: 0.5473535060882568
Validation loss: 1.7302689744580177

Epoch: 5| Step: 9
Training loss: 0.6783754229545593
Validation loss: 1.7733903636214554

Epoch: 5| Step: 10
Training loss: 0.5585477352142334
Validation loss: 1.7916455076586815

Epoch: 282| Step: 0
Training loss: 0.5514270067214966
Validation loss: 1.8230232423351658

Epoch: 5| Step: 1
Training loss: 0.6204435229301453
Validation loss: 1.7830106955702587

Epoch: 5| Step: 2
Training loss: 0.9082474708557129
Validation loss: 1.7970920070525138

Epoch: 5| Step: 3
Training loss: 0.5418769121170044
Validation loss: 1.7539806712058283

Epoch: 5| Step: 4
Training loss: 0.5501721501350403
Validation loss: 1.7179546856111096

Epoch: 5| Step: 5
Training loss: 0.9075152277946472
Validation loss: 1.6917330052262993

Epoch: 5| Step: 6
Training loss: 0.6407267451286316
Validation loss: 1.6596300025140085

Epoch: 5| Step: 7
Training loss: 0.4738129675388336
Validation loss: 1.6350420251969369

Epoch: 5| Step: 8
Training loss: 0.7103887796401978
Validation loss: 1.6196423089632423

Epoch: 5| Step: 9
Training loss: 0.6992365121841431
Validation loss: 1.6350277226458314

Epoch: 5| Step: 10
Training loss: 0.3627297878265381
Validation loss: 1.662549872552195

Epoch: 283| Step: 0
Training loss: 0.8049288988113403
Validation loss: 1.6573256959197342

Epoch: 5| Step: 1
Training loss: 0.716900646686554
Validation loss: 1.7089679548817296

Epoch: 5| Step: 2
Training loss: 0.4507802128791809
Validation loss: 1.7008380556619296

Epoch: 5| Step: 3
Training loss: 0.4378058910369873
Validation loss: 1.7185502629126272

Epoch: 5| Step: 4
Training loss: 0.9599941372871399
Validation loss: 1.6930826428116008

Epoch: 5| Step: 5
Training loss: 0.6929477453231812
Validation loss: 1.710463293137089

Epoch: 5| Step: 6
Training loss: 0.575321614742279
Validation loss: 1.722617756935858

Epoch: 5| Step: 7
Training loss: 0.5655679702758789
Validation loss: 1.7170633859531854

Epoch: 5| Step: 8
Training loss: 0.8224284052848816
Validation loss: 1.7127740742057882

Epoch: 5| Step: 9
Training loss: 0.5262594223022461
Validation loss: 1.7096045145424463

Epoch: 5| Step: 10
Training loss: 0.5630283355712891
Validation loss: 1.7275987953268073

Epoch: 284| Step: 0
Training loss: 0.8917848467826843
Validation loss: 1.7364072543318554

Epoch: 5| Step: 1
Training loss: 0.5726794600486755
Validation loss: 1.7140790775258055

Epoch: 5| Step: 2
Training loss: 0.3662416338920593
Validation loss: 1.732319870302754

Epoch: 5| Step: 3
Training loss: 0.4212028384208679
Validation loss: 1.7559012700152654

Epoch: 5| Step: 4
Training loss: 0.6614079475402832
Validation loss: 1.7379282072026243

Epoch: 5| Step: 5
Training loss: 0.40955036878585815
Validation loss: 1.726580141693033

Epoch: 5| Step: 6
Training loss: 0.6270044445991516
Validation loss: 1.7224195695692492

Epoch: 5| Step: 7
Training loss: 0.7685807347297668
Validation loss: 1.6882819873030468

Epoch: 5| Step: 8
Training loss: 0.5949158072471619
Validation loss: 1.6804002151694348

Epoch: 5| Step: 9
Training loss: 0.9039801359176636
Validation loss: 1.6670240458621775

Epoch: 5| Step: 10
Training loss: 0.63017737865448
Validation loss: 1.665974892595763

Epoch: 285| Step: 0
Training loss: 0.47969213128089905
Validation loss: 1.6620826669918594

Epoch: 5| Step: 1
Training loss: 0.5709066390991211
Validation loss: 1.6800144000719952

Epoch: 5| Step: 2
Training loss: 0.6661583185195923
Validation loss: 1.6894068576956307

Epoch: 5| Step: 3
Training loss: 0.3963238298892975
Validation loss: 1.7151045940255607

Epoch: 5| Step: 4
Training loss: 0.8678157925605774
Validation loss: 1.7401840520161453

Epoch: 5| Step: 5
Training loss: 0.7971680760383606
Validation loss: 1.7426426750357433

Epoch: 5| Step: 6
Training loss: 0.7913296222686768
Validation loss: 1.7252500211038897

Epoch: 5| Step: 7
Training loss: 0.575801432132721
Validation loss: 1.7177068238617272

Epoch: 5| Step: 8
Training loss: 0.4697425961494446
Validation loss: 1.7167475646541965

Epoch: 5| Step: 9
Training loss: 0.3958323895931244
Validation loss: 1.7133604723920104

Epoch: 5| Step: 10
Training loss: 0.8530230522155762
Validation loss: 1.683335781097412

Epoch: 286| Step: 0
Training loss: 0.5277830362319946
Validation loss: 1.6575077259412376

Epoch: 5| Step: 1
Training loss: 0.5062328577041626
Validation loss: 1.6522967751308153

Epoch: 5| Step: 2
Training loss: 0.798432469367981
Validation loss: 1.6336059865131174

Epoch: 5| Step: 3
Training loss: 0.6461551785469055
Validation loss: 1.6334250075842744

Epoch: 5| Step: 4
Training loss: 0.7062345743179321
Validation loss: 1.6590781686126546

Epoch: 5| Step: 5
Training loss: 0.5550576448440552
Validation loss: 1.6446797001746394

Epoch: 5| Step: 6
Training loss: 0.39853277802467346
Validation loss: 1.6789142790661062

Epoch: 5| Step: 7
Training loss: 0.8595134019851685
Validation loss: 1.7081726892020113

Epoch: 5| Step: 8
Training loss: 0.7501808404922485
Validation loss: 1.7233951578858078

Epoch: 5| Step: 9
Training loss: 0.5606573820114136
Validation loss: 1.7218282709839523

Epoch: 5| Step: 10
Training loss: 0.4498070478439331
Validation loss: 1.7365044598938317

Epoch: 287| Step: 0
Training loss: 0.3545173406600952
Validation loss: 1.7233491469455022

Epoch: 5| Step: 1
Training loss: 0.7158227562904358
Validation loss: 1.6941333611806233

Epoch: 5| Step: 2
Training loss: 0.6120408773422241
Validation loss: 1.6814525486320577

Epoch: 5| Step: 3
Training loss: 0.5199316143989563
Validation loss: 1.6814663012822468

Epoch: 5| Step: 4
Training loss: 0.6970852613449097
Validation loss: 1.6657946007226103

Epoch: 5| Step: 5
Training loss: 0.5216737389564514
Validation loss: 1.6698099720862605

Epoch: 5| Step: 6
Training loss: 0.7042792439460754
Validation loss: 1.667387782886464

Epoch: 5| Step: 7
Training loss: 0.5845238566398621
Validation loss: 1.653587996318776

Epoch: 5| Step: 8
Training loss: 0.49736708402633667
Validation loss: 1.6747030622215682

Epoch: 5| Step: 9
Training loss: 0.7406779527664185
Validation loss: 1.6783437600699804

Epoch: 5| Step: 10
Training loss: 0.48909130692481995
Validation loss: 1.673314243234614

Epoch: 288| Step: 0
Training loss: 0.3438881039619446
Validation loss: 1.675052039084896

Epoch: 5| Step: 1
Training loss: 0.33071833848953247
Validation loss: 1.6671573269751765

Epoch: 5| Step: 2
Training loss: 0.4509904384613037
Validation loss: 1.6448947985967

Epoch: 5| Step: 3
Training loss: 0.7253006100654602
Validation loss: 1.6616435371419436

Epoch: 5| Step: 4
Training loss: 0.45970243215560913
Validation loss: 1.6607491495788738

Epoch: 5| Step: 5
Training loss: 0.7397551536560059
Validation loss: 1.6649287657071186

Epoch: 5| Step: 6
Training loss: 0.9194938540458679
Validation loss: 1.6782156831474715

Epoch: 5| Step: 7
Training loss: 0.5791472792625427
Validation loss: 1.653192489377914

Epoch: 5| Step: 8
Training loss: 0.6964799761772156
Validation loss: 1.6761232793972056

Epoch: 5| Step: 9
Training loss: 0.3244704604148865
Validation loss: 1.6843249362002137

Epoch: 5| Step: 10
Training loss: 0.7356905937194824
Validation loss: 1.6770065971600112

Epoch: 289| Step: 0
Training loss: 0.3392612636089325
Validation loss: 1.6341177289203932

Epoch: 5| Step: 1
Training loss: 0.3332888185977936
Validation loss: 1.6211333249204902

Epoch: 5| Step: 2
Training loss: 0.33481764793395996
Validation loss: 1.6375946242322204

Epoch: 5| Step: 3
Training loss: 0.7461686730384827
Validation loss: 1.6165497174827002

Epoch: 5| Step: 4
Training loss: 0.5983335375785828
Validation loss: 1.6274005828365203

Epoch: 5| Step: 5
Training loss: 0.4566938877105713
Validation loss: 1.6431564669455252

Epoch: 5| Step: 6
Training loss: 0.4984002113342285
Validation loss: 1.6635433012439358

Epoch: 5| Step: 7
Training loss: 0.6341555714607239
Validation loss: 1.6609395319415676

Epoch: 5| Step: 8
Training loss: 0.596699059009552
Validation loss: 1.6949172045594902

Epoch: 5| Step: 9
Training loss: 0.8709679841995239
Validation loss: 1.7012684127335906

Epoch: 5| Step: 10
Training loss: 0.7896181344985962
Validation loss: 1.696857202437616

Epoch: 290| Step: 0
Training loss: 0.5006483793258667
Validation loss: 1.701252414334205

Epoch: 5| Step: 1
Training loss: 0.5003644824028015
Validation loss: 1.6894400363327355

Epoch: 5| Step: 2
Training loss: 0.40753188729286194
Validation loss: 1.6928914195747786

Epoch: 5| Step: 3
Training loss: 0.5418714880943298
Validation loss: 1.6939410753147577

Epoch: 5| Step: 4
Training loss: 0.341919869184494
Validation loss: 1.63166404667721

Epoch: 5| Step: 5
Training loss: 0.454683780670166
Validation loss: 1.6273040245938044

Epoch: 5| Step: 6
Training loss: 1.2146923542022705
Validation loss: 1.6265989157461351

Epoch: 5| Step: 7
Training loss: 0.6501162648200989
Validation loss: 1.6450846784858293

Epoch: 5| Step: 8
Training loss: 0.5409747362136841
Validation loss: 1.646370421173752

Epoch: 5| Step: 9
Training loss: 0.5324997901916504
Validation loss: 1.645454183701546

Epoch: 5| Step: 10
Training loss: 0.5073934197425842
Validation loss: 1.6504878433801795

Epoch: 291| Step: 0
Training loss: 0.3915671706199646
Validation loss: 1.688004913509533

Epoch: 5| Step: 1
Training loss: 0.5732917785644531
Validation loss: 1.713910561735912

Epoch: 5| Step: 2
Training loss: 0.7150946855545044
Validation loss: 1.7114635770038893

Epoch: 5| Step: 3
Training loss: 0.49000081419944763
Validation loss: 1.7190621335019347

Epoch: 5| Step: 4
Training loss: 0.7236615419387817
Validation loss: 1.7061101582742506

Epoch: 5| Step: 5
Training loss: 0.5240883231163025
Validation loss: 1.7158718378313127

Epoch: 5| Step: 6
Training loss: 0.4828964173793793
Validation loss: 1.7227188284679125

Epoch: 5| Step: 7
Training loss: 0.527656614780426
Validation loss: 1.705266769214343

Epoch: 5| Step: 8
Training loss: 0.7048883438110352
Validation loss: 1.699287538887352

Epoch: 5| Step: 9
Training loss: 0.4426252245903015
Validation loss: 1.6921601628744474

Epoch: 5| Step: 10
Training loss: 0.5719076991081238
Validation loss: 1.6795727437542332

Epoch: 292| Step: 0
Training loss: 0.5422927141189575
Validation loss: 1.6695562178088772

Epoch: 5| Step: 1
Training loss: 0.5208198428153992
Validation loss: 1.6655361998465754

Epoch: 5| Step: 2
Training loss: 0.5447747707366943
Validation loss: 1.6584628961419547

Epoch: 5| Step: 3
Training loss: 0.7598446011543274
Validation loss: 1.663506596319137

Epoch: 5| Step: 4
Training loss: 0.3777430057525635
Validation loss: 1.667103926340739

Epoch: 5| Step: 5
Training loss: 0.689069926738739
Validation loss: 1.6716099708311019

Epoch: 5| Step: 6
Training loss: 0.8054483532905579
Validation loss: 1.6674636089673607

Epoch: 5| Step: 7
Training loss: 0.3696809709072113
Validation loss: 1.664286369918495

Epoch: 5| Step: 8
Training loss: 0.43729788064956665
Validation loss: 1.6695085366566975

Epoch: 5| Step: 9
Training loss: 0.41886982321739197
Validation loss: 1.6383346434562438

Epoch: 5| Step: 10
Training loss: 0.5918810963630676
Validation loss: 1.6528647535590715

Epoch: 293| Step: 0
Training loss: 0.6449363827705383
Validation loss: 1.6476970206024826

Epoch: 5| Step: 1
Training loss: 0.7060396075248718
Validation loss: 1.6706447139863045

Epoch: 5| Step: 2
Training loss: 0.6395496129989624
Validation loss: 1.654676098977366

Epoch: 5| Step: 3
Training loss: 0.39141646027565
Validation loss: 1.6585371468656807

Epoch: 5| Step: 4
Training loss: 0.7485443949699402
Validation loss: 1.690289770403216

Epoch: 5| Step: 5
Training loss: 0.5973623991012573
Validation loss: 1.6877868175506592

Epoch: 5| Step: 6
Training loss: 0.8713765144348145
Validation loss: 1.6715302595528223

Epoch: 5| Step: 7
Training loss: 0.4006410241127014
Validation loss: 1.6402761910551338

Epoch: 5| Step: 8
Training loss: 0.5373930931091309
Validation loss: 1.6355791373919415

Epoch: 5| Step: 9
Training loss: 0.3420487940311432
Validation loss: 1.6327437662309217

Epoch: 5| Step: 10
Training loss: 0.41032716631889343
Validation loss: 1.6462404445935321

Epoch: 294| Step: 0
Training loss: 0.7002414464950562
Validation loss: 1.675204106556472

Epoch: 5| Step: 1
Training loss: 0.7785786390304565
Validation loss: 1.6921737758062219

Epoch: 5| Step: 2
Training loss: 0.5114916563034058
Validation loss: 1.682642500887635

Epoch: 5| Step: 3
Training loss: 0.31059250235557556
Validation loss: 1.6592239808010798

Epoch: 5| Step: 4
Training loss: 0.6717995405197144
Validation loss: 1.6429661717466129

Epoch: 5| Step: 5
Training loss: 0.4426129460334778
Validation loss: 1.644246357743458

Epoch: 5| Step: 6
Training loss: 0.65167236328125
Validation loss: 1.6209530163836736

Epoch: 5| Step: 7
Training loss: 0.5241191983222961
Validation loss: 1.6571963320496261

Epoch: 5| Step: 8
Training loss: 0.22255420684814453
Validation loss: 1.64543620873523

Epoch: 5| Step: 9
Training loss: 0.8520814776420593
Validation loss: 1.633783318663156

Epoch: 5| Step: 10
Training loss: 0.41282933950424194
Validation loss: 1.6327894797889135

Epoch: 295| Step: 0
Training loss: 0.6432350873947144
Validation loss: 1.638497870455506

Epoch: 5| Step: 1
Training loss: 0.5027850866317749
Validation loss: 1.6540060107425978

Epoch: 5| Step: 2
Training loss: 0.572737991809845
Validation loss: 1.65425242018956

Epoch: 5| Step: 3
Training loss: 0.4727412760257721
Validation loss: 1.6686582872944493

Epoch: 5| Step: 4
Training loss: 0.7723661065101624
Validation loss: 1.6823991421730287

Epoch: 5| Step: 5
Training loss: 0.6835756301879883
Validation loss: 1.6721125879595358

Epoch: 5| Step: 6
Training loss: 0.544908881187439
Validation loss: 1.6688737907717306

Epoch: 5| Step: 7
Training loss: 0.5708063244819641
Validation loss: 1.6833934681389922

Epoch: 5| Step: 8
Training loss: 0.4308749735355377
Validation loss: 1.6852564927070373

Epoch: 5| Step: 9
Training loss: 0.38306665420532227
Validation loss: 1.695798348355037

Epoch: 5| Step: 10
Training loss: 0.25794386863708496
Validation loss: 1.7049114076040124

Epoch: 296| Step: 0
Training loss: 0.35870543122291565
Validation loss: 1.6944831378998295

Epoch: 5| Step: 1
Training loss: 0.7168561816215515
Validation loss: 1.685161699530899

Epoch: 5| Step: 2
Training loss: 0.4968903660774231
Validation loss: 1.6562076960840533

Epoch: 5| Step: 3
Training loss: 0.7138378024101257
Validation loss: 1.6686072657185216

Epoch: 5| Step: 4
Training loss: 0.36441126465797424
Validation loss: 1.6685768737587878

Epoch: 5| Step: 5
Training loss: 0.6047857403755188
Validation loss: 1.682041903977753

Epoch: 5| Step: 6
Training loss: 0.7733964920043945
Validation loss: 1.674119661572159

Epoch: 5| Step: 7
Training loss: 0.45571890473365784
Validation loss: 1.6853138285298501

Epoch: 5| Step: 8
Training loss: 0.4298866391181946
Validation loss: 1.6682686805725098

Epoch: 5| Step: 9
Training loss: 0.40585923194885254
Validation loss: 1.6840998741888231

Epoch: 5| Step: 10
Training loss: 0.698632001876831
Validation loss: 1.6969416795238372

Epoch: 297| Step: 0
Training loss: 0.601564347743988
Validation loss: 1.7057608622376637

Epoch: 5| Step: 1
Training loss: 0.5938909649848938
Validation loss: 1.6494999252339846

Epoch: 5| Step: 2
Training loss: 0.48987269401550293
Validation loss: 1.659814501321444

Epoch: 5| Step: 3
Training loss: 0.22718539834022522
Validation loss: 1.6634756762494323

Epoch: 5| Step: 4
Training loss: 0.45340901613235474
Validation loss: 1.6736852097254928

Epoch: 5| Step: 5
Training loss: 0.632282555103302
Validation loss: 1.6660522286609938

Epoch: 5| Step: 6
Training loss: 0.5728866457939148
Validation loss: 1.670673870271252

Epoch: 5| Step: 7
Training loss: 0.6579678654670715
Validation loss: 1.6606890847606044

Epoch: 5| Step: 8
Training loss: 0.6247532963752747
Validation loss: 1.6623984972635906

Epoch: 5| Step: 9
Training loss: 0.5905362963676453
Validation loss: 1.6401933188079505

Epoch: 5| Step: 10
Training loss: 0.6253211498260498
Validation loss: 1.637304139393632

Epoch: 298| Step: 0
Training loss: 0.4808211326599121
Validation loss: 1.6342848462443198

Epoch: 5| Step: 1
Training loss: 0.4073515832424164
Validation loss: 1.658015469069122

Epoch: 5| Step: 2
Training loss: 0.4542027413845062
Validation loss: 1.682208530364498

Epoch: 5| Step: 3
Training loss: 0.6905654072761536
Validation loss: 1.7175194383949361

Epoch: 5| Step: 4
Training loss: 0.5529581904411316
Validation loss: 1.744617755695056

Epoch: 5| Step: 5
Training loss: 0.5651298761367798
Validation loss: 1.744031310081482

Epoch: 5| Step: 6
Training loss: 0.6249909400939941
Validation loss: 1.7396433494424308

Epoch: 5| Step: 7
Training loss: 0.6891177892684937
Validation loss: 1.7093867653159684

Epoch: 5| Step: 8
Training loss: 0.5684574842453003
Validation loss: 1.674985288291849

Epoch: 5| Step: 9
Training loss: 0.35554638504981995
Validation loss: 1.6574629032483665

Epoch: 5| Step: 10
Training loss: 0.764397144317627
Validation loss: 1.631233722932877

Epoch: 299| Step: 0
Training loss: 0.5666884779930115
Validation loss: 1.6451462353429487

Epoch: 5| Step: 1
Training loss: 0.46153002977371216
Validation loss: 1.6528894978184854

Epoch: 5| Step: 2
Training loss: 0.27821940183639526
Validation loss: 1.6129465474877307

Epoch: 5| Step: 3
Training loss: 0.6424917578697205
Validation loss: 1.6642618512594571

Epoch: 5| Step: 4
Training loss: 0.5860798954963684
Validation loss: 1.6478081813422583

Epoch: 5| Step: 5
Training loss: 0.318899929523468
Validation loss: 1.6609804514915711

Epoch: 5| Step: 6
Training loss: 0.6564916968345642
Validation loss: 1.711019387809179

Epoch: 5| Step: 7
Training loss: 0.4858986735343933
Validation loss: 1.7206589701355144

Epoch: 5| Step: 8
Training loss: 0.5148829221725464
Validation loss: 1.740336912934498

Epoch: 5| Step: 9
Training loss: 0.8008823394775391
Validation loss: 1.7243833323960662

Epoch: 5| Step: 10
Training loss: 0.7644014358520508
Validation loss: 1.731893152318975

Epoch: 300| Step: 0
Training loss: 0.4114483892917633
Validation loss: 1.6789416036298197

Epoch: 5| Step: 1
Training loss: 0.5316807627677917
Validation loss: 1.6591197303546372

Epoch: 5| Step: 2
Training loss: 0.5235679745674133
Validation loss: 1.6391196943098498

Epoch: 5| Step: 3
Training loss: 0.6616321206092834
Validation loss: 1.641706967866549

Epoch: 5| Step: 4
Training loss: 0.7002973556518555
Validation loss: 1.6386819219076505

Epoch: 5| Step: 5
Training loss: 0.5082743763923645
Validation loss: 1.6199397079406246

Epoch: 5| Step: 6
Training loss: 0.5977566242218018
Validation loss: 1.609192100904321

Epoch: 5| Step: 7
Training loss: 0.5264378190040588
Validation loss: 1.59690039004049

Epoch: 5| Step: 8
Training loss: 0.3956509232521057
Validation loss: 1.601845532335261

Epoch: 5| Step: 9
Training loss: 0.5388685464859009
Validation loss: 1.6132732232411702

Epoch: 5| Step: 10
Training loss: 0.2656206488609314
Validation loss: 1.6939010094570857

Epoch: 301| Step: 0
Training loss: 0.6654665470123291
Validation loss: 1.719537119711599

Epoch: 5| Step: 1
Training loss: 0.4475499987602234
Validation loss: 1.7471896461261216

Epoch: 5| Step: 2
Training loss: 0.4100986123085022
Validation loss: 1.778415403058452

Epoch: 5| Step: 3
Training loss: 0.8800857663154602
Validation loss: 1.7475788862474504

Epoch: 5| Step: 4
Training loss: 0.21428625285625458
Validation loss: 1.742045925509545

Epoch: 5| Step: 5
Training loss: 0.7070719003677368
Validation loss: 1.7688478885158416

Epoch: 5| Step: 6
Training loss: 0.6340173482894897
Validation loss: 1.7168658907695482

Epoch: 5| Step: 7
Training loss: 0.5922682285308838
Validation loss: 1.7044161365878197

Epoch: 5| Step: 8
Training loss: 0.37301865220069885
Validation loss: 1.7163961702777493

Epoch: 5| Step: 9
Training loss: 0.4320743680000305
Validation loss: 1.6910057913872503

Epoch: 5| Step: 10
Training loss: 0.4849492311477661
Validation loss: 1.680010655874847

Epoch: 302| Step: 0
Training loss: 0.7060126066207886
Validation loss: 1.6619360472566338

Epoch: 5| Step: 1
Training loss: 0.5237515568733215
Validation loss: 1.6499604896832538

Epoch: 5| Step: 2
Training loss: 0.45385923981666565
Validation loss: 1.665168543015757

Epoch: 5| Step: 3
Training loss: 0.6641145944595337
Validation loss: 1.663195833083122

Epoch: 5| Step: 4
Training loss: 0.30322298407554626
Validation loss: 1.6651717270574262

Epoch: 5| Step: 5
Training loss: 0.4545080065727234
Validation loss: 1.6564300585818548

Epoch: 5| Step: 6
Training loss: 0.613847017288208
Validation loss: 1.6814130583117086

Epoch: 5| Step: 7
Training loss: 0.37064307928085327
Validation loss: 1.6547056103265414

Epoch: 5| Step: 8
Training loss: 0.6387038230895996
Validation loss: 1.6573596526217718

Epoch: 5| Step: 9
Training loss: 0.6186288595199585
Validation loss: 1.6189881294004378

Epoch: 5| Step: 10
Training loss: 0.3917710781097412
Validation loss: 1.622474342264155

Epoch: 303| Step: 0
Training loss: 0.5216053128242493
Validation loss: 1.651330404384162

Epoch: 5| Step: 1
Training loss: 0.24550271034240723
Validation loss: 1.6547171287639166

Epoch: 5| Step: 2
Training loss: 0.5845485925674438
Validation loss: 1.6274017095565796

Epoch: 5| Step: 3
Training loss: 0.5447189807891846
Validation loss: 1.624521186274867

Epoch: 5| Step: 4
Training loss: 0.5660273432731628
Validation loss: 1.6482536600482078

Epoch: 5| Step: 5
Training loss: 0.35479485988616943
Validation loss: 1.6301668420914681

Epoch: 5| Step: 6
Training loss: 0.5817631483078003
Validation loss: 1.6319950556242337

Epoch: 5| Step: 7
Training loss: 0.4319738447666168
Validation loss: 1.6060833700241581

Epoch: 5| Step: 8
Training loss: 0.7787500619888306
Validation loss: 1.5891977099962131

Epoch: 5| Step: 9
Training loss: 0.6332394480705261
Validation loss: 1.6130036461737849

Epoch: 5| Step: 10
Training loss: 0.4314272403717041
Validation loss: 1.62796341219256

Epoch: 304| Step: 0
Training loss: 0.5889022946357727
Validation loss: 1.6204523527494041

Epoch: 5| Step: 1
Training loss: 0.3316240906715393
Validation loss: 1.6512495548494401

Epoch: 5| Step: 2
Training loss: 0.31326156854629517
Validation loss: 1.6882315528008245

Epoch: 5| Step: 3
Training loss: 0.3278689980506897
Validation loss: 1.7118348370316208

Epoch: 5| Step: 4
Training loss: 0.6045359373092651
Validation loss: 1.721162171774013

Epoch: 5| Step: 5
Training loss: 0.5611385107040405
Validation loss: 1.708369170465777

Epoch: 5| Step: 6
Training loss: 0.4311027526855469
Validation loss: 1.7004364626381987

Epoch: 5| Step: 7
Training loss: 1.0371265411376953
Validation loss: 1.6936028003692627

Epoch: 5| Step: 8
Training loss: 0.429997056722641
Validation loss: 1.6282063927701724

Epoch: 5| Step: 9
Training loss: 0.49326062202453613
Validation loss: 1.6327953351441251

Epoch: 5| Step: 10
Training loss: 0.5131312608718872
Validation loss: 1.6430749226641912

Epoch: 305| Step: 0
Training loss: 0.3599548935890198
Validation loss: 1.6287048273189093

Epoch: 5| Step: 1
Training loss: 0.6502957344055176
Validation loss: 1.6041008900570612

Epoch: 5| Step: 2
Training loss: 0.32675737142562866
Validation loss: 1.5946470691311745

Epoch: 5| Step: 3
Training loss: 0.3764408230781555
Validation loss: 1.6009119838796637

Epoch: 5| Step: 4
Training loss: 0.7774220705032349
Validation loss: 1.6203356571094965

Epoch: 5| Step: 5
Training loss: 0.426603227853775
Validation loss: 1.622440258661906

Epoch: 5| Step: 6
Training loss: 0.7195066213607788
Validation loss: 1.6206811961307321

Epoch: 5| Step: 7
Training loss: 0.37614622712135315
Validation loss: 1.655021236788842

Epoch: 5| Step: 8
Training loss: 0.509648859500885
Validation loss: 1.6540747829662856

Epoch: 5| Step: 9
Training loss: 0.28476792573928833
Validation loss: 1.6583696360229163

Epoch: 5| Step: 10
Training loss: 0.6851286292076111
Validation loss: 1.6449267313044558

Epoch: 306| Step: 0
Training loss: 0.35658949613571167
Validation loss: 1.6482199725284372

Epoch: 5| Step: 1
Training loss: 0.5621910095214844
Validation loss: 1.645248936068627

Epoch: 5| Step: 2
Training loss: 0.4584573805332184
Validation loss: 1.6431290885453582

Epoch: 5| Step: 3
Training loss: 0.6243245005607605
Validation loss: 1.6520815639085666

Epoch: 5| Step: 4
Training loss: 0.18908265233039856
Validation loss: 1.6776689047454505

Epoch: 5| Step: 5
Training loss: 0.46923524141311646
Validation loss: 1.6641210240702475

Epoch: 5| Step: 6
Training loss: 0.5009975433349609
Validation loss: 1.6214936061572003

Epoch: 5| Step: 7
Training loss: 0.5893236398696899
Validation loss: 1.6621918627010879

Epoch: 5| Step: 8
Training loss: 0.7282200455665588
Validation loss: 1.6461254601837487

Epoch: 5| Step: 9
Training loss: 0.32463255524635315
Validation loss: 1.6303952278629426

Epoch: 5| Step: 10
Training loss: 0.4201585650444031
Validation loss: 1.6434890403542468

Epoch: 307| Step: 0
Training loss: 0.6050220727920532
Validation loss: 1.6252037709759128

Epoch: 5| Step: 1
Training loss: 0.25743818283081055
Validation loss: 1.6662694920775711

Epoch: 5| Step: 2
Training loss: 0.28028425574302673
Validation loss: 1.6582300637357978

Epoch: 5| Step: 3
Training loss: 0.4272923469543457
Validation loss: 1.6463538324961098

Epoch: 5| Step: 4
Training loss: 0.5472390055656433
Validation loss: 1.6304047953697942

Epoch: 5| Step: 5
Training loss: 0.44528406858444214
Validation loss: 1.632161989006945

Epoch: 5| Step: 6
Training loss: 0.7102051973342896
Validation loss: 1.6386216109798801

Epoch: 5| Step: 7
Training loss: 0.3429234027862549
Validation loss: 1.6241732233314103

Epoch: 5| Step: 8
Training loss: 0.5574582815170288
Validation loss: 1.595004241953614

Epoch: 5| Step: 9
Training loss: 0.6332582235336304
Validation loss: 1.607571259621651

Epoch: 5| Step: 10
Training loss: 0.3190772235393524
Validation loss: 1.6213410823575911

Epoch: 308| Step: 0
Training loss: 0.7775080800056458
Validation loss: 1.6211917416382862

Epoch: 5| Step: 1
Training loss: 0.269704669713974
Validation loss: 1.6069273384668494

Epoch: 5| Step: 2
Training loss: 0.660386323928833
Validation loss: 1.5785050738242365

Epoch: 5| Step: 3
Training loss: 0.4594174921512604
Validation loss: 1.591501038561585

Epoch: 5| Step: 4
Training loss: 0.344438374042511
Validation loss: 1.6006779145169001

Epoch: 5| Step: 5
Training loss: 0.446829617023468
Validation loss: 1.6163256937457668

Epoch: 5| Step: 6
Training loss: 0.5527421832084656
Validation loss: 1.6250640640976608

Epoch: 5| Step: 7
Training loss: 0.4161683917045593
Validation loss: 1.654243795461552

Epoch: 5| Step: 8
Training loss: 0.5847598314285278
Validation loss: 1.645104492223391

Epoch: 5| Step: 9
Training loss: 0.44061654806137085
Validation loss: 1.6397922564578313

Epoch: 5| Step: 10
Training loss: 0.2333713322877884
Validation loss: 1.6483053853434901

Epoch: 309| Step: 0
Training loss: 0.35438647866249084
Validation loss: 1.6701105948417418

Epoch: 5| Step: 1
Training loss: 0.39490142464637756
Validation loss: 1.6551885745858634

Epoch: 5| Step: 2
Training loss: 0.560867190361023
Validation loss: 1.6452756549722405

Epoch: 5| Step: 3
Training loss: 0.39118462800979614
Validation loss: 1.6136622762167325

Epoch: 5| Step: 4
Training loss: 0.4106055200099945
Validation loss: 1.6069054065212127

Epoch: 5| Step: 5
Training loss: 0.33077627420425415
Validation loss: 1.6082154563678208

Epoch: 5| Step: 6
Training loss: 0.45380648970603943
Validation loss: 1.5858904661670807

Epoch: 5| Step: 7
Training loss: 0.592723548412323
Validation loss: 1.5723255392043822

Epoch: 5| Step: 8
Training loss: 0.49626582860946655
Validation loss: 1.5768947050135622

Epoch: 5| Step: 9
Training loss: 0.6178484559059143
Validation loss: 1.5835104578284807

Epoch: 5| Step: 10
Training loss: 0.6350057125091553
Validation loss: 1.5805953484709545

Epoch: 310| Step: 0
Training loss: 0.27998122572898865
Validation loss: 1.640170210151262

Epoch: 5| Step: 1
Training loss: 0.5150497555732727
Validation loss: 1.653202429894478

Epoch: 5| Step: 2
Training loss: 0.8011981248855591
Validation loss: 1.6655926255769626

Epoch: 5| Step: 3
Training loss: 0.549103856086731
Validation loss: 1.6795320895410353

Epoch: 5| Step: 4
Training loss: 0.34517166018486023
Validation loss: 1.6776581284820393

Epoch: 5| Step: 5
Training loss: 0.6235426664352417
Validation loss: 1.6722081053641535

Epoch: 5| Step: 6
Training loss: 0.5504356622695923
Validation loss: 1.6363026044702018

Epoch: 5| Step: 7
Training loss: 0.3537459075450897
Validation loss: 1.6396420847985052

Epoch: 5| Step: 8
Training loss: 0.29067468643188477
Validation loss: 1.6325919730688936

Epoch: 5| Step: 9
Training loss: 0.27655261754989624
Validation loss: 1.593264465690941

Epoch: 5| Step: 10
Training loss: 0.48619818687438965
Validation loss: 1.6328950056465723

Epoch: 311| Step: 0
Training loss: 0.5855891108512878
Validation loss: 1.623675799497994

Epoch: 5| Step: 1
Training loss: 0.5463026762008667
Validation loss: 1.6349574071104809

Epoch: 5| Step: 2
Training loss: 0.576468288898468
Validation loss: 1.6435965376515542

Epoch: 5| Step: 3
Training loss: 0.38245469331741333
Validation loss: 1.661528407886464

Epoch: 5| Step: 4
Training loss: 0.37473565340042114
Validation loss: 1.6765642858320666

Epoch: 5| Step: 5
Training loss: 0.39971017837524414
Validation loss: 1.6644601514262538

Epoch: 5| Step: 6
Training loss: 0.4968467652797699
Validation loss: 1.6666594929592584

Epoch: 5| Step: 7
Training loss: 0.39236170053482056
Validation loss: 1.6564119964517572

Epoch: 5| Step: 8
Training loss: 0.5523437261581421
Validation loss: 1.6248308304817445

Epoch: 5| Step: 9
Training loss: 0.3119203746318817
Validation loss: 1.6148485778480448

Epoch: 5| Step: 10
Training loss: 0.45866572856903076
Validation loss: 1.610174576441447

Epoch: 312| Step: 0
Training loss: 0.4798528254032135
Validation loss: 1.5943721673821891

Epoch: 5| Step: 1
Training loss: 0.394989550113678
Validation loss: 1.607470638008528

Epoch: 5| Step: 2
Training loss: 0.6223582029342651
Validation loss: 1.6165130702398156

Epoch: 5| Step: 3
Training loss: 0.752528965473175
Validation loss: 1.5924275440554465

Epoch: 5| Step: 4
Training loss: 0.35780325531959534
Validation loss: 1.6114397843678792

Epoch: 5| Step: 5
Training loss: 0.2520991265773773
Validation loss: 1.5982439159065165

Epoch: 5| Step: 6
Training loss: 0.4023650288581848
Validation loss: 1.6131218133434173

Epoch: 5| Step: 7
Training loss: 0.3623726963996887
Validation loss: 1.6439267845563992

Epoch: 5| Step: 8
Training loss: 0.6451149582862854
Validation loss: 1.6478412164154874

Epoch: 5| Step: 9
Training loss: 0.39128679037094116
Validation loss: 1.6686096742588987

Epoch: 5| Step: 10
Training loss: 0.22358198463916779
Validation loss: 1.6864061996500979

Epoch: 313| Step: 0
Training loss: 0.4902675747871399
Validation loss: 1.6378818917018112

Epoch: 5| Step: 1
Training loss: 0.5230959057807922
Validation loss: 1.6481850301065752

Epoch: 5| Step: 2
Training loss: 0.4192069470882416
Validation loss: 1.607447131987541

Epoch: 5| Step: 3
Training loss: 0.3474559783935547
Validation loss: 1.5972551030497397

Epoch: 5| Step: 4
Training loss: 0.5817911624908447
Validation loss: 1.624316607752154

Epoch: 5| Step: 5
Training loss: 0.43612250685691833
Validation loss: 1.613939210932742

Epoch: 5| Step: 6
Training loss: 0.44455042481422424
Validation loss: 1.6134212183695968

Epoch: 5| Step: 7
Training loss: 0.3419034481048584
Validation loss: 1.6107050090707757

Epoch: 5| Step: 8
Training loss: 0.3539602756500244
Validation loss: 1.6248007038588166

Epoch: 5| Step: 9
Training loss: 0.4640846848487854
Validation loss: 1.6226789195050475

Epoch: 5| Step: 10
Training loss: 0.4933752119541168
Validation loss: 1.6250232547842047

Epoch: 314| Step: 0
Training loss: 0.6585274934768677
Validation loss: 1.6211770132023802

Epoch: 5| Step: 1
Training loss: 0.5031567215919495
Validation loss: 1.6411469572333879

Epoch: 5| Step: 2
Training loss: 0.4477643072605133
Validation loss: 1.6360373035553963

Epoch: 5| Step: 3
Training loss: 0.7651054859161377
Validation loss: 1.6156538019898117

Epoch: 5| Step: 4
Training loss: 0.30080118775367737
Validation loss: 1.615540366018972

Epoch: 5| Step: 5
Training loss: 0.2910047471523285
Validation loss: 1.6416241866286083

Epoch: 5| Step: 6
Training loss: 0.5046488046646118
Validation loss: 1.6452079280730216

Epoch: 5| Step: 7
Training loss: 0.2939075231552124
Validation loss: 1.649541381225791

Epoch: 5| Step: 8
Training loss: 0.4475374221801758
Validation loss: 1.6631680086094847

Epoch: 5| Step: 9
Training loss: 0.2426256239414215
Validation loss: 1.6905017796383108

Epoch: 5| Step: 10
Training loss: 0.4333437383174896
Validation loss: 1.6818172136942546

Epoch: 315| Step: 0
Training loss: 0.598275363445282
Validation loss: 1.7145685739414667

Epoch: 5| Step: 1
Training loss: 0.3062960207462311
Validation loss: 1.6954911011521534

Epoch: 5| Step: 2
Training loss: 0.38867858052253723
Validation loss: 1.6754046665724887

Epoch: 5| Step: 3
Training loss: 0.39068204164505005
Validation loss: 1.6701231797536213

Epoch: 5| Step: 4
Training loss: 0.3663667142391205
Validation loss: 1.651594356823993

Epoch: 5| Step: 5
Training loss: 0.4791445732116699
Validation loss: 1.627668434573758

Epoch: 5| Step: 6
Training loss: 0.4915103018283844
Validation loss: 1.628284373591023

Epoch: 5| Step: 7
Training loss: 0.21630167961120605
Validation loss: 1.6143662416806785

Epoch: 5| Step: 8
Training loss: 0.5229411125183105
Validation loss: 1.6096112125663347

Epoch: 5| Step: 9
Training loss: 0.42472967505455017
Validation loss: 1.607320116412255

Epoch: 5| Step: 10
Training loss: 0.7107892036437988
Validation loss: 1.6082813368048718

Epoch: 316| Step: 0
Training loss: 0.45671454071998596
Validation loss: 1.606058887256089

Epoch: 5| Step: 1
Training loss: 0.3768579065799713
Validation loss: 1.6174870562809769

Epoch: 5| Step: 2
Training loss: 0.5255441665649414
Validation loss: 1.6269486668289348

Epoch: 5| Step: 3
Training loss: 0.5686837434768677
Validation loss: 1.6251894004883305

Epoch: 5| Step: 4
Training loss: 0.31012818217277527
Validation loss: 1.630882505447634

Epoch: 5| Step: 5
Training loss: 0.6889775395393372
Validation loss: 1.6619517598100888

Epoch: 5| Step: 6
Training loss: 0.2660312056541443
Validation loss: 1.6530521890168548

Epoch: 5| Step: 7
Training loss: 0.4577783942222595
Validation loss: 1.687438613624983

Epoch: 5| Step: 8
Training loss: 0.48999127745628357
Validation loss: 1.6669407224142423

Epoch: 5| Step: 9
Training loss: 0.3573307693004608
Validation loss: 1.672962373302829

Epoch: 5| Step: 10
Training loss: 0.3427254855632782
Validation loss: 1.641306689990464

Epoch: 317| Step: 0
Training loss: 0.5788407921791077
Validation loss: 1.6667467266000726

Epoch: 5| Step: 1
Training loss: 0.6741198301315308
Validation loss: 1.6518775801504813

Epoch: 5| Step: 2
Training loss: 0.4962496757507324
Validation loss: 1.6545303470344954

Epoch: 5| Step: 3
Training loss: 0.29452115297317505
Validation loss: 1.6252219548789404

Epoch: 5| Step: 4
Training loss: 0.4821280539035797
Validation loss: 1.6105697706181517

Epoch: 5| Step: 5
Training loss: 0.35116586089134216
Validation loss: 1.6184755986736667

Epoch: 5| Step: 6
Training loss: 0.22424128651618958
Validation loss: 1.6226805333168275

Epoch: 5| Step: 7
Training loss: 0.3956966996192932
Validation loss: 1.622389260158744

Epoch: 5| Step: 8
Training loss: 0.39252811670303345
Validation loss: 1.626088188540551

Epoch: 5| Step: 9
Training loss: 0.31382259726524353
Validation loss: 1.6501430414056266

Epoch: 5| Step: 10
Training loss: 0.6023828983306885
Validation loss: 1.6452688786291307

Epoch: 318| Step: 0
Training loss: 0.3570716977119446
Validation loss: 1.6413807612593456

Epoch: 5| Step: 1
Training loss: 0.49883610010147095
Validation loss: 1.6398244493751115

Epoch: 5| Step: 2
Training loss: 0.7946764826774597
Validation loss: 1.6407481528097583

Epoch: 5| Step: 3
Training loss: 0.4730028212070465
Validation loss: 1.6280837097475607

Epoch: 5| Step: 4
Training loss: 0.19056563079357147
Validation loss: 1.6284348644236082

Epoch: 5| Step: 5
Training loss: 0.3796549439430237
Validation loss: 1.6095554828643799

Epoch: 5| Step: 6
Training loss: 0.5185431241989136
Validation loss: 1.6104207897699008

Epoch: 5| Step: 7
Training loss: 0.42059025168418884
Validation loss: 1.6218363931102138

Epoch: 5| Step: 8
Training loss: 0.26991337537765503
Validation loss: 1.622339589621431

Epoch: 5| Step: 9
Training loss: 0.4635142683982849
Validation loss: 1.613757796184991

Epoch: 5| Step: 10
Training loss: 0.5445020198822021
Validation loss: 1.6183479767973705

Epoch: 319| Step: 0
Training loss: 0.6202868223190308
Validation loss: 1.6236327335398684

Epoch: 5| Step: 1
Training loss: 0.45310431718826294
Validation loss: 1.5915185027225043

Epoch: 5| Step: 2
Training loss: 0.5433624386787415
Validation loss: 1.610856512541412

Epoch: 5| Step: 3
Training loss: 0.3962745666503906
Validation loss: 1.6513303954114196

Epoch: 5| Step: 4
Training loss: 0.3996141254901886
Validation loss: 1.6249476478945823

Epoch: 5| Step: 5
Training loss: 0.34528258442878723
Validation loss: 1.6431960431478356

Epoch: 5| Step: 6
Training loss: 0.3855532705783844
Validation loss: 1.6581320903634513

Epoch: 5| Step: 7
Training loss: 0.22977125644683838
Validation loss: 1.6518819626941477

Epoch: 5| Step: 8
Training loss: 0.46904927492141724
Validation loss: 1.6348499392950406

Epoch: 5| Step: 9
Training loss: 0.44145169854164124
Validation loss: 1.6024592512397355

Epoch: 5| Step: 10
Training loss: 0.3535488247871399
Validation loss: 1.6041485981274677

Epoch: 320| Step: 0
Training loss: 0.31265488266944885
Validation loss: 1.5829732059150614

Epoch: 5| Step: 1
Training loss: 0.22147104144096375
Validation loss: 1.5829861587093723

Epoch: 5| Step: 2
Training loss: 0.46654877066612244
Validation loss: 1.570504859570534

Epoch: 5| Step: 3
Training loss: 0.4661136567592621
Validation loss: 1.5858315229415894

Epoch: 5| Step: 4
Training loss: 0.21998381614685059
Validation loss: 1.586153043213711

Epoch: 5| Step: 5
Training loss: 0.3188591003417969
Validation loss: 1.5679516664115332

Epoch: 5| Step: 6
Training loss: 0.5606801509857178
Validation loss: 1.6047073692403815

Epoch: 5| Step: 7
Training loss: 0.5000177025794983
Validation loss: 1.637069248384045

Epoch: 5| Step: 8
Training loss: 0.6452894806861877
Validation loss: 1.6445053213386125

Epoch: 5| Step: 9
Training loss: 0.6704049706459045
Validation loss: 1.6385805145386727

Epoch: 5| Step: 10
Training loss: 0.2918463945388794
Validation loss: 1.6593274736917147

Epoch: 321| Step: 0
Training loss: 0.42006760835647583
Validation loss: 1.6366869839288856

Epoch: 5| Step: 1
Training loss: 0.3548280596733093
Validation loss: 1.6602246299866708

Epoch: 5| Step: 2
Training loss: 0.36691373586654663
Validation loss: 1.6671710603980607

Epoch: 5| Step: 3
Training loss: 0.5057275295257568
Validation loss: 1.6532594132167038

Epoch: 5| Step: 4
Training loss: 0.479935884475708
Validation loss: 1.649545511891765

Epoch: 5| Step: 5
Training loss: 0.38635963201522827
Validation loss: 1.647854640919675

Epoch: 5| Step: 6
Training loss: 0.4963817000389099
Validation loss: 1.6673934049503778

Epoch: 5| Step: 7
Training loss: 0.48209577798843384
Validation loss: 1.6451591343008063

Epoch: 5| Step: 8
Training loss: 0.33355194330215454
Validation loss: 1.625492763775651

Epoch: 5| Step: 9
Training loss: 0.24479803442955017
Validation loss: 1.6005743242079211

Epoch: 5| Step: 10
Training loss: 0.36339327692985535
Validation loss: 1.6021565262989332

Epoch: 322| Step: 0
Training loss: 0.3312920928001404
Validation loss: 1.6232249121512137

Epoch: 5| Step: 1
Training loss: 0.5554912686347961
Validation loss: 1.6272064255129906

Epoch: 5| Step: 2
Training loss: 0.17515742778778076
Validation loss: 1.6295717326543664

Epoch: 5| Step: 3
Training loss: 0.4332354962825775
Validation loss: 1.6135407340142034

Epoch: 5| Step: 4
Training loss: 0.3368786871433258
Validation loss: 1.6107149675328245

Epoch: 5| Step: 5
Training loss: 0.47471070289611816
Validation loss: 1.6261172756072013

Epoch: 5| Step: 6
Training loss: 0.630245566368103
Validation loss: 1.6193026791336715

Epoch: 5| Step: 7
Training loss: 0.29559358954429626
Validation loss: 1.6363623565243137

Epoch: 5| Step: 8
Training loss: 0.2406742125749588
Validation loss: 1.618756377568809

Epoch: 5| Step: 9
Training loss: 0.4037831425666809
Validation loss: 1.630399287387889

Epoch: 5| Step: 10
Training loss: 0.46166932582855225
Validation loss: 1.639654290291571

Epoch: 323| Step: 0
Training loss: 0.5717724561691284
Validation loss: 1.6315570249352405

Epoch: 5| Step: 1
Training loss: 0.41822582483291626
Validation loss: 1.6558632158464002

Epoch: 5| Step: 2
Training loss: 0.5918986797332764
Validation loss: 1.6409905841273646

Epoch: 5| Step: 3
Training loss: 0.20493395626544952
Validation loss: 1.6383322361976869

Epoch: 5| Step: 4
Training loss: 0.35909730195999146
Validation loss: 1.6604286022083734

Epoch: 5| Step: 5
Training loss: 0.4223960041999817
Validation loss: 1.6650636952410462

Epoch: 5| Step: 6
Training loss: 0.2146194875240326
Validation loss: 1.6922468921189666

Epoch: 5| Step: 7
Training loss: 0.6574606895446777
Validation loss: 1.7057099278255174

Epoch: 5| Step: 8
Training loss: 0.48175162076950073
Validation loss: 1.702160935248098

Epoch: 5| Step: 9
Training loss: 0.41774964332580566
Validation loss: 1.694227828774401

Epoch: 5| Step: 10
Training loss: 0.26835697889328003
Validation loss: 1.64337840003352

Epoch: 324| Step: 0
Training loss: 0.26567140221595764
Validation loss: 1.597369642667873

Epoch: 5| Step: 1
Training loss: 0.40748530626296997
Validation loss: 1.5669448144974247

Epoch: 5| Step: 2
Training loss: 0.45957428216934204
Validation loss: 1.5694199646672895

Epoch: 5| Step: 3
Training loss: 0.4897550940513611
Validation loss: 1.564631886379693

Epoch: 5| Step: 4
Training loss: 0.40811237692832947
Validation loss: 1.564945485002251

Epoch: 5| Step: 5
Training loss: 0.23422101140022278
Validation loss: 1.5513548645921933

Epoch: 5| Step: 6
Training loss: 0.48302286863327026
Validation loss: 1.5776375532150269

Epoch: 5| Step: 7
Training loss: 0.1981416642665863
Validation loss: 1.5959891401311403

Epoch: 5| Step: 8
Training loss: 0.704335629940033
Validation loss: 1.607831863946812

Epoch: 5| Step: 9
Training loss: 0.3568103313446045
Validation loss: 1.597470082262511

Epoch: 5| Step: 10
Training loss: 0.30007433891296387
Validation loss: 1.6125119886090677

Epoch: 325| Step: 0
Training loss: 0.4811342656612396
Validation loss: 1.633873075567266

Epoch: 5| Step: 1
Training loss: 0.19813719391822815
Validation loss: 1.6485045725299465

Epoch: 5| Step: 2
Training loss: 0.6124522089958191
Validation loss: 1.6334324831603675

Epoch: 5| Step: 3
Training loss: 0.32643017172813416
Validation loss: 1.5963200497370895

Epoch: 5| Step: 4
Training loss: 0.359564870595932
Validation loss: 1.5920513573513235

Epoch: 5| Step: 5
Training loss: 0.1663929522037506
Validation loss: 1.5659843106423654

Epoch: 5| Step: 6
Training loss: 0.22840909659862518
Validation loss: 1.5902328837302424

Epoch: 5| Step: 7
Training loss: 0.5857970118522644
Validation loss: 1.5557460554184452

Epoch: 5| Step: 8
Training loss: 0.3342769742012024
Validation loss: 1.551712598851932

Epoch: 5| Step: 9
Training loss: 0.6681526899337769
Validation loss: 1.5894484135412401

Epoch: 5| Step: 10
Training loss: 0.5662882328033447
Validation loss: 1.5602081744901595

Epoch: 326| Step: 0
Training loss: 0.5410469174385071
Validation loss: 1.6107536990155455

Epoch: 5| Step: 1
Training loss: 0.29288196563720703
Validation loss: 1.59663228706647

Epoch: 5| Step: 2
Training loss: 0.5600944757461548
Validation loss: 1.595674084078881

Epoch: 5| Step: 3
Training loss: 0.5147122740745544
Validation loss: 1.6144907089971727

Epoch: 5| Step: 4
Training loss: 0.2794616222381592
Validation loss: 1.6091726210809523

Epoch: 5| Step: 5
Training loss: 0.2851632535457611
Validation loss: 1.6435634564327937

Epoch: 5| Step: 6
Training loss: 0.4816726744174957
Validation loss: 1.6018542320497575

Epoch: 5| Step: 7
Training loss: 0.3714507520198822
Validation loss: 1.5994701449589064

Epoch: 5| Step: 8
Training loss: 0.522513747215271
Validation loss: 1.5702073868884836

Epoch: 5| Step: 9
Training loss: 0.30885401368141174
Validation loss: 1.5877566683676936

Epoch: 5| Step: 10
Training loss: 0.2531207799911499
Validation loss: 1.5929697111088743

Epoch: 327| Step: 0
Training loss: 0.3369637727737427
Validation loss: 1.5846058835265457

Epoch: 5| Step: 1
Training loss: 0.7189301252365112
Validation loss: 1.5980157339444725

Epoch: 5| Step: 2
Training loss: 0.3886401355266571
Validation loss: 1.6188469894470707

Epoch: 5| Step: 3
Training loss: 0.4323464334011078
Validation loss: 1.6305057848653486

Epoch: 5| Step: 4
Training loss: 0.3376964032649994
Validation loss: 1.6352661514794955

Epoch: 5| Step: 5
Training loss: 0.29744309186935425
Validation loss: 1.6318707619943926

Epoch: 5| Step: 6
Training loss: 0.32650867104530334
Validation loss: 1.6462133981848275

Epoch: 5| Step: 7
Training loss: 0.3659423887729645
Validation loss: 1.6351306566628077

Epoch: 5| Step: 8
Training loss: 0.2587747573852539
Validation loss: 1.5883776782661356

Epoch: 5| Step: 9
Training loss: 0.2255166471004486
Validation loss: 1.5898566476760372

Epoch: 5| Step: 10
Training loss: 0.5342470407485962
Validation loss: 1.5935858846992574

Epoch: 328| Step: 0
Training loss: 0.4088164269924164
Validation loss: 1.615575368686389

Epoch: 5| Step: 1
Training loss: 0.47596120834350586
Validation loss: 1.634309704585742

Epoch: 5| Step: 2
Training loss: 0.49132901430130005
Validation loss: 1.6406287467607887

Epoch: 5| Step: 3
Training loss: 0.45033663511276245
Validation loss: 1.6575814882914226

Epoch: 5| Step: 4
Training loss: 0.3854045569896698
Validation loss: 1.6555134455362956

Epoch: 5| Step: 5
Training loss: 0.27685627341270447
Validation loss: 1.6271788958580262

Epoch: 5| Step: 6
Training loss: 0.24403294920921326
Validation loss: 1.6121340079974102

Epoch: 5| Step: 7
Training loss: 0.20633240044116974
Validation loss: 1.6015936943792528

Epoch: 5| Step: 8
Training loss: 0.425804078578949
Validation loss: 1.601224745473554

Epoch: 5| Step: 9
Training loss: 0.39996233582496643
Validation loss: 1.5999037424723308

Epoch: 5| Step: 10
Training loss: 0.6335577964782715
Validation loss: 1.602321784983399

Epoch: 329| Step: 0
Training loss: 0.32768648862838745
Validation loss: 1.629221740589347

Epoch: 5| Step: 1
Training loss: 0.3975444734096527
Validation loss: 1.633200648010418

Epoch: 5| Step: 2
Training loss: 0.31188732385635376
Validation loss: 1.62561704779184

Epoch: 5| Step: 3
Training loss: 0.2820066809654236
Validation loss: 1.6370982546960153

Epoch: 5| Step: 4
Training loss: 0.4822227358818054
Validation loss: 1.626029037660168

Epoch: 5| Step: 5
Training loss: 0.12031199038028717
Validation loss: 1.6161493203973258

Epoch: 5| Step: 6
Training loss: 0.3998648226261139
Validation loss: 1.6478645378543484

Epoch: 5| Step: 7
Training loss: 0.43442201614379883
Validation loss: 1.6283044520244803

Epoch: 5| Step: 8
Training loss: 0.6301554441452026
Validation loss: 1.6030751569296724

Epoch: 5| Step: 9
Training loss: 0.35237517952919006
Validation loss: 1.5812627487285162

Epoch: 5| Step: 10
Training loss: 0.46217432618141174
Validation loss: 1.5606867421057917

Epoch: 330| Step: 0
Training loss: 0.24563200771808624
Validation loss: 1.578735851472424

Epoch: 5| Step: 1
Training loss: 0.4384443759918213
Validation loss: 1.6010427423702773

Epoch: 5| Step: 2
Training loss: 0.27283233404159546
Validation loss: 1.617476878627654

Epoch: 5| Step: 3
Training loss: 0.43465113639831543
Validation loss: 1.5899463763801

Epoch: 5| Step: 4
Training loss: 0.5603084564208984
Validation loss: 1.6081219539847424

Epoch: 5| Step: 5
Training loss: 0.5813356637954712
Validation loss: 1.5921865676039009

Epoch: 5| Step: 6
Training loss: 0.27876561880111694
Validation loss: 1.6574729168286888

Epoch: 5| Step: 7
Training loss: 0.34641405940055847
Validation loss: 1.650918081242551

Epoch: 5| Step: 8
Training loss: 0.4163053631782532
Validation loss: 1.6488446497148084

Epoch: 5| Step: 9
Training loss: 0.40908122062683105
Validation loss: 1.6761742586730628

Epoch: 5| Step: 10
Training loss: 0.3957943022251129
Validation loss: 1.6636928102021575

Epoch: 331| Step: 0
Training loss: 0.2994937002658844
Validation loss: 1.6468569540208386

Epoch: 5| Step: 1
Training loss: 0.48401278257369995
Validation loss: 1.619950326540137

Epoch: 5| Step: 2
Training loss: 0.5811850428581238
Validation loss: 1.591023357965613

Epoch: 5| Step: 3
Training loss: 0.5186258554458618
Validation loss: 1.5739977308498916

Epoch: 5| Step: 4
Training loss: 0.18779614567756653
Validation loss: 1.5595785879319715

Epoch: 5| Step: 5
Training loss: 0.392747163772583
Validation loss: 1.557807776235765

Epoch: 5| Step: 6
Training loss: 0.5215510129928589
Validation loss: 1.564285183465609

Epoch: 5| Step: 7
Training loss: 0.34709545969963074
Validation loss: 1.5827840271816458

Epoch: 5| Step: 8
Training loss: 0.34251469373703003
Validation loss: 1.562633466976945

Epoch: 5| Step: 9
Training loss: 0.408325731754303
Validation loss: 1.595503576340214

Epoch: 5| Step: 10
Training loss: 0.3264871835708618
Validation loss: 1.579177951300016

Epoch: 332| Step: 0
Training loss: 0.3359731137752533
Validation loss: 1.606534847649195

Epoch: 5| Step: 1
Training loss: 0.268292099237442
Validation loss: 1.6293073443956272

Epoch: 5| Step: 2
Training loss: 0.2311580628156662
Validation loss: 1.628295338282021

Epoch: 5| Step: 3
Training loss: 0.36526262760162354
Validation loss: 1.6190598421199347

Epoch: 5| Step: 4
Training loss: 0.23301637172698975
Validation loss: 1.615555049270712

Epoch: 5| Step: 5
Training loss: 0.5455873608589172
Validation loss: 1.6122351666932464

Epoch: 5| Step: 6
Training loss: 0.536917507648468
Validation loss: 1.6096963126172301

Epoch: 5| Step: 7
Training loss: 0.32334405183792114
Validation loss: 1.6056744270427252

Epoch: 5| Step: 8
Training loss: 0.3948710858821869
Validation loss: 1.6251970850011355

Epoch: 5| Step: 9
Training loss: 0.6444278359413147
Validation loss: 1.6170571145190988

Epoch: 5| Step: 10
Training loss: 0.41706588864326477
Validation loss: 1.605786177419847

Epoch: 333| Step: 0
Training loss: 0.30802735686302185
Validation loss: 1.6312878849685832

Epoch: 5| Step: 1
Training loss: 0.5990909934043884
Validation loss: 1.639068272805983

Epoch: 5| Step: 2
Training loss: 0.3321722149848938
Validation loss: 1.6460536455595365

Epoch: 5| Step: 3
Training loss: 0.3859606981277466
Validation loss: 1.638042849879111

Epoch: 5| Step: 4
Training loss: 0.5228437185287476
Validation loss: 1.638758465807925

Epoch: 5| Step: 5
Training loss: 0.25107795000076294
Validation loss: 1.630503785225653

Epoch: 5| Step: 6
Training loss: 0.3867911994457245
Validation loss: 1.6284169791847147

Epoch: 5| Step: 7
Training loss: 0.5301674008369446
Validation loss: 1.6109079673726072

Epoch: 5| Step: 8
Training loss: 0.5276868939399719
Validation loss: 1.614492859891666

Epoch: 5| Step: 9
Training loss: 0.4245986044406891
Validation loss: 1.5781577274363527

Epoch: 5| Step: 10
Training loss: 0.4490199089050293
Validation loss: 1.5756133679420716

Epoch: 334| Step: 0
Training loss: 0.5846765041351318
Validation loss: 1.588474178186027

Epoch: 5| Step: 1
Training loss: 0.3469821512699127
Validation loss: 1.5688620139193792

Epoch: 5| Step: 2
Training loss: 0.5240697860717773
Validation loss: 1.567170649446467

Epoch: 5| Step: 3
Training loss: 0.35814163088798523
Validation loss: 1.5788603162252774

Epoch: 5| Step: 4
Training loss: 0.3249327838420868
Validation loss: 1.600156258511287

Epoch: 5| Step: 5
Training loss: 0.2909262180328369
Validation loss: 1.611512380261575

Epoch: 5| Step: 6
Training loss: 0.3220127522945404
Validation loss: 1.6173292988090104

Epoch: 5| Step: 7
Training loss: 0.63613361120224
Validation loss: 1.6441048845168083

Epoch: 5| Step: 8
Training loss: 0.30664700269699097
Validation loss: 1.6268401786845217

Epoch: 5| Step: 9
Training loss: 0.2662818729877472
Validation loss: 1.6077715004644086

Epoch: 5| Step: 10
Training loss: 0.42974206805229187
Validation loss: 1.588597463023278

Epoch: 335| Step: 0
Training loss: 0.38797813653945923
Validation loss: 1.6134580322491225

Epoch: 5| Step: 1
Training loss: 0.3892405331134796
Validation loss: 1.6052907025942238

Epoch: 5| Step: 2
Training loss: 0.21239474415779114
Validation loss: 1.6147899025229997

Epoch: 5| Step: 3
Training loss: 0.3967805504798889
Validation loss: 1.6230927026400002

Epoch: 5| Step: 4
Training loss: 0.20156565308570862
Validation loss: 1.6287531801449355

Epoch: 5| Step: 5
Training loss: 0.3548763692378998
Validation loss: 1.625668211649823

Epoch: 5| Step: 6
Training loss: 0.4570108950138092
Validation loss: 1.6441982946088236

Epoch: 5| Step: 7
Training loss: 0.4692297875881195
Validation loss: 1.6406508620067308

Epoch: 5| Step: 8
Training loss: 0.5764032602310181
Validation loss: 1.6326270206000215

Epoch: 5| Step: 9
Training loss: 0.43150854110717773
Validation loss: 1.610809164662515

Epoch: 5| Step: 10
Training loss: 0.4861272871494293
Validation loss: 1.5991749545579315

Epoch: 336| Step: 0
Training loss: 0.39423123002052307
Validation loss: 1.5787625364077988

Epoch: 5| Step: 1
Training loss: 0.26702529191970825
Validation loss: 1.5744483265825497

Epoch: 5| Step: 2
Training loss: 0.4247615933418274
Validation loss: 1.615770686057306

Epoch: 5| Step: 3
Training loss: 0.44258204102516174
Validation loss: 1.627126968035134

Epoch: 5| Step: 4
Training loss: 0.332711398601532
Validation loss: 1.5989162306631766

Epoch: 5| Step: 5
Training loss: 0.3551134765148163
Validation loss: 1.592686217318299

Epoch: 5| Step: 6
Training loss: 0.24083828926086426
Validation loss: 1.5748778479073637

Epoch: 5| Step: 7
Training loss: 0.42953625321388245
Validation loss: 1.5885841654193016

Epoch: 5| Step: 8
Training loss: 0.6601214408874512
Validation loss: 1.5823425349368845

Epoch: 5| Step: 9
Training loss: 0.28586655855178833
Validation loss: 1.6080981774996685

Epoch: 5| Step: 10
Training loss: 0.348993182182312
Validation loss: 1.6285512408902567

Epoch: 337| Step: 0
Training loss: 0.5539926886558533
Validation loss: 1.6303268209580453

Epoch: 5| Step: 1
Training loss: 0.3502693176269531
Validation loss: 1.6002235758689143

Epoch: 5| Step: 2
Training loss: 0.4396299421787262
Validation loss: 1.610354399168363

Epoch: 5| Step: 3
Training loss: 0.3817596435546875
Validation loss: 1.6002602769482521

Epoch: 5| Step: 4
Training loss: 0.3144870698451996
Validation loss: 1.5732116532582108

Epoch: 5| Step: 5
Training loss: 0.3394748270511627
Validation loss: 1.562440961919805

Epoch: 5| Step: 6
Training loss: 0.2703855633735657
Validation loss: 1.5641540596562047

Epoch: 5| Step: 7
Training loss: 0.3164210021495819
Validation loss: 1.5666377980221984

Epoch: 5| Step: 8
Training loss: 0.33237817883491516
Validation loss: 1.5653588220637331

Epoch: 5| Step: 9
Training loss: 0.5492935180664062
Validation loss: 1.5687303325181365

Epoch: 5| Step: 10
Training loss: 0.3040975034236908
Validation loss: 1.5247343445336947

Epoch: 338| Step: 0
Training loss: 0.18813414871692657
Validation loss: 1.5275732291642057

Epoch: 5| Step: 1
Training loss: 0.5651296377182007
Validation loss: 1.5208053178684686

Epoch: 5| Step: 2
Training loss: 0.2702886462211609
Validation loss: 1.532402310320126

Epoch: 5| Step: 3
Training loss: 0.4807049334049225
Validation loss: 1.5259956903355096

Epoch: 5| Step: 4
Training loss: 0.3540650010108948
Validation loss: 1.5345442077165008

Epoch: 5| Step: 5
Training loss: 0.3958788514137268
Validation loss: 1.5310472570439821

Epoch: 5| Step: 6
Training loss: 0.26675835251808167
Validation loss: 1.4895242221893803

Epoch: 5| Step: 7
Training loss: 0.3487395942211151
Validation loss: 1.5011964895391976

Epoch: 5| Step: 8
Training loss: 0.36864718794822693
Validation loss: 1.5679385418532996

Epoch: 5| Step: 9
Training loss: 0.4034693241119385
Validation loss: 1.533368101683996

Epoch: 5| Step: 10
Training loss: 0.3232279121875763
Validation loss: 1.5531952111951766

Epoch: 339| Step: 0
Training loss: 0.41728687286376953
Validation loss: 1.5800752152678788

Epoch: 5| Step: 1
Training loss: 0.3070281147956848
Validation loss: 1.5607917552353234

Epoch: 5| Step: 2
Training loss: 0.44903913140296936
Validation loss: 1.5727135442918347

Epoch: 5| Step: 3
Training loss: 0.30513036251068115
Validation loss: 1.5989026164495816

Epoch: 5| Step: 4
Training loss: 0.32333165407180786
Validation loss: 1.6355848094468475

Epoch: 5| Step: 5
Training loss: 0.5494394302368164
Validation loss: 1.6025442564359276

Epoch: 5| Step: 6
Training loss: 0.4557825028896332
Validation loss: 1.6131421635227818

Epoch: 5| Step: 7
Training loss: 0.3018490672111511
Validation loss: 1.608936240596156

Epoch: 5| Step: 8
Training loss: 0.3169647753238678
Validation loss: 1.5868173042933147

Epoch: 5| Step: 9
Training loss: 0.21485444903373718
Validation loss: 1.580904955505043

Epoch: 5| Step: 10
Training loss: 0.12841905653476715
Validation loss: 1.5756812159733107

Epoch: 340| Step: 0
Training loss: 0.4482521116733551
Validation loss: 1.5886406052497126

Epoch: 5| Step: 1
Training loss: 0.41262927651405334
Validation loss: 1.5874665667933803

Epoch: 5| Step: 2
Training loss: 0.5049596428871155
Validation loss: 1.5606239149647374

Epoch: 5| Step: 3
Training loss: 0.3009358048439026
Validation loss: 1.555264901089412

Epoch: 5| Step: 4
Training loss: 0.45390066504478455
Validation loss: 1.5299771396062707

Epoch: 5| Step: 5
Training loss: 0.29067033529281616
Validation loss: 1.549863564070835

Epoch: 5| Step: 6
Training loss: 0.42531663179397583
Validation loss: 1.5554746902117165

Epoch: 5| Step: 7
Training loss: 0.2853092551231384
Validation loss: 1.5886260463345436

Epoch: 5| Step: 8
Training loss: 0.33967968821525574
Validation loss: 1.6201993201368599

Epoch: 5| Step: 9
Training loss: 0.3899366855621338
Validation loss: 1.6337311062761533

Epoch: 5| Step: 10
Training loss: 0.334380567073822
Validation loss: 1.5927863069759902

Epoch: 341| Step: 0
Training loss: 0.3155723512172699
Validation loss: 1.5733103957227481

Epoch: 5| Step: 1
Training loss: 0.3651241362094879
Validation loss: 1.543125210269805

Epoch: 5| Step: 2
Training loss: 0.5128470659255981
Validation loss: 1.5191114077004053

Epoch: 5| Step: 3
Training loss: 0.34696289896965027
Validation loss: 1.5327736536661785

Epoch: 5| Step: 4
Training loss: 0.48991888761520386
Validation loss: 1.5580409496061263

Epoch: 5| Step: 5
Training loss: 0.22015473246574402
Validation loss: 1.5431957193600234

Epoch: 5| Step: 6
Training loss: 0.634222686290741
Validation loss: 1.547863530856307

Epoch: 5| Step: 7
Training loss: 0.20713241398334503
Validation loss: 1.5337968410984162

Epoch: 5| Step: 8
Training loss: 0.2818261981010437
Validation loss: 1.5469587156849522

Epoch: 5| Step: 9
Training loss: 0.3349999785423279
Validation loss: 1.580504709674466

Epoch: 5| Step: 10
Training loss: 0.20120327174663544
Validation loss: 1.5506543677340272

Epoch: 342| Step: 0
Training loss: 0.3216959834098816
Validation loss: 1.5671653356603397

Epoch: 5| Step: 1
Training loss: 0.30663785338401794
Validation loss: 1.5767736550300353

Epoch: 5| Step: 2
Training loss: 0.4122050404548645
Validation loss: 1.5719027762771935

Epoch: 5| Step: 3
Training loss: 0.285130113363266
Validation loss: 1.6045240804713259

Epoch: 5| Step: 4
Training loss: 0.4060123562812805
Validation loss: 1.6078242986432967

Epoch: 5| Step: 5
Training loss: 0.41159963607788086
Validation loss: 1.617414491150969

Epoch: 5| Step: 6
Training loss: 0.3885316848754883
Validation loss: 1.6170952384189894

Epoch: 5| Step: 7
Training loss: 0.2802681624889374
Validation loss: 1.593483853083785

Epoch: 5| Step: 8
Training loss: 0.17175325751304626
Validation loss: 1.5761803811596287

Epoch: 5| Step: 9
Training loss: 0.4257611334323883
Validation loss: 1.603728727627826

Epoch: 5| Step: 10
Training loss: 0.15546995401382446
Validation loss: 1.5815318246041574

Epoch: 343| Step: 0
Training loss: 0.30463510751724243
Validation loss: 1.5867253862401491

Epoch: 5| Step: 1
Training loss: 0.546096920967102
Validation loss: 1.5863237047708163

Epoch: 5| Step: 2
Training loss: 0.2187100648880005
Validation loss: 1.5668641418539069

Epoch: 5| Step: 3
Training loss: 0.3016206622123718
Validation loss: 1.5694068683091031

Epoch: 5| Step: 4
Training loss: 0.28240519762039185
Validation loss: 1.5392009776125672

Epoch: 5| Step: 5
Training loss: 0.2832506000995636
Validation loss: 1.567614818132052

Epoch: 5| Step: 6
Training loss: 0.44999876618385315
Validation loss: 1.5449757370897519

Epoch: 5| Step: 7
Training loss: 0.300237238407135
Validation loss: 1.555884659931224

Epoch: 5| Step: 8
Training loss: 0.2184096872806549
Validation loss: 1.5333058834075928

Epoch: 5| Step: 9
Training loss: 0.31212514638900757
Validation loss: 1.569411680262576

Epoch: 5| Step: 10
Training loss: 0.49770426750183105
Validation loss: 1.557358439250659

Epoch: 344| Step: 0
Training loss: 0.3210892677307129
Validation loss: 1.5781440824590705

Epoch: 5| Step: 1
Training loss: 0.6541523933410645
Validation loss: 1.5730763327690862

Epoch: 5| Step: 2
Training loss: 0.3108362555503845
Validation loss: 1.5892813667174308

Epoch: 5| Step: 3
Training loss: 0.2499806433916092
Validation loss: 1.573653958177054

Epoch: 5| Step: 4
Training loss: 0.20902800559997559
Validation loss: 1.600932111022293

Epoch: 5| Step: 5
Training loss: 0.32512032985687256
Validation loss: 1.6081065682954685

Epoch: 5| Step: 6
Training loss: 0.21151849627494812
Validation loss: 1.606374338109006

Epoch: 5| Step: 7
Training loss: 0.41081875562667847
Validation loss: 1.6377380804349018

Epoch: 5| Step: 8
Training loss: 0.3358701169490814
Validation loss: 1.6409123020787393

Epoch: 5| Step: 9
Training loss: 0.3749082088470459
Validation loss: 1.6112296068540184

Epoch: 5| Step: 10
Training loss: 0.2406051605939865
Validation loss: 1.6130780737887147

Epoch: 345| Step: 0
Training loss: 0.4668629765510559
Validation loss: 1.5719644433708602

Epoch: 5| Step: 1
Training loss: 0.22366580367088318
Validation loss: 1.5875927607218425

Epoch: 5| Step: 2
Training loss: 0.3362331986427307
Validation loss: 1.5381833013667856

Epoch: 5| Step: 3
Training loss: 0.4606742262840271
Validation loss: 1.5516573857235652

Epoch: 5| Step: 4
Training loss: 0.2606182098388672
Validation loss: 1.5307815786330932

Epoch: 5| Step: 5
Training loss: 0.27776628732681274
Validation loss: 1.5255347387765044

Epoch: 5| Step: 6
Training loss: 0.3864895701408386
Validation loss: 1.5242228943814513

Epoch: 5| Step: 7
Training loss: 0.3137517273426056
Validation loss: 1.539311598705989

Epoch: 5| Step: 8
Training loss: 0.28299587965011597
Validation loss: 1.5262392092776556

Epoch: 5| Step: 9
Training loss: 0.3368091881275177
Validation loss: 1.5500523851763817

Epoch: 5| Step: 10
Training loss: 0.2530752122402191
Validation loss: 1.5540357507685179

Epoch: 346| Step: 0
Training loss: 0.345132976770401
Validation loss: 1.5549566809849074

Epoch: 5| Step: 1
Training loss: 0.5838595628738403
Validation loss: 1.5709584566854662

Epoch: 5| Step: 2
Training loss: 0.18459363281726837
Validation loss: 1.5843187121934788

Epoch: 5| Step: 3
Training loss: 0.3393401503562927
Validation loss: 1.5784740268543203

Epoch: 5| Step: 4
Training loss: 0.29084691405296326
Validation loss: 1.5795475282976705

Epoch: 5| Step: 5
Training loss: 0.30019330978393555
Validation loss: 1.5825150589789114

Epoch: 5| Step: 6
Training loss: 0.4069115221500397
Validation loss: 1.589666917759885

Epoch: 5| Step: 7
Training loss: 0.2668818235397339
Validation loss: 1.5989848618866296

Epoch: 5| Step: 8
Training loss: 0.2470453679561615
Validation loss: 1.62162697058852

Epoch: 5| Step: 9
Training loss: 0.2687256634235382
Validation loss: 1.642682711283366

Epoch: 5| Step: 10
Training loss: 0.46525371074676514
Validation loss: 1.577942180377181

Epoch: 347| Step: 0
Training loss: 0.4949062466621399
Validation loss: 1.5797594644690072

Epoch: 5| Step: 1
Training loss: 0.2670036554336548
Validation loss: 1.564602336575908

Epoch: 5| Step: 2
Training loss: 0.28911536931991577
Validation loss: 1.5702885261145971

Epoch: 5| Step: 3
Training loss: 0.34613290429115295
Validation loss: 1.566497900152719

Epoch: 5| Step: 4
Training loss: 0.27574434876441956
Validation loss: 1.5567661472546157

Epoch: 5| Step: 5
Training loss: 0.3866526782512665
Validation loss: 1.574098462699562

Epoch: 5| Step: 6
Training loss: 0.23903822898864746
Validation loss: 1.576493404244864

Epoch: 5| Step: 7
Training loss: 0.4753905236721039
Validation loss: 1.5686382311646656

Epoch: 5| Step: 8
Training loss: 0.23910291492938995
Validation loss: 1.5539434789329447

Epoch: 5| Step: 9
Training loss: 0.36082926392555237
Validation loss: 1.5514136783538326

Epoch: 5| Step: 10
Training loss: 0.10996251553297043
Validation loss: 1.5318927226528045

Epoch: 348| Step: 0
Training loss: 0.2467895746231079
Validation loss: 1.5381471598020164

Epoch: 5| Step: 1
Training loss: 0.4480103552341461
Validation loss: 1.5445858842583113

Epoch: 5| Step: 2
Training loss: 0.2012597769498825
Validation loss: 1.5615538768870856

Epoch: 5| Step: 3
Training loss: 0.629912257194519
Validation loss: 1.5536305622387958

Epoch: 5| Step: 4
Training loss: 0.15051977336406708
Validation loss: 1.599439408189507

Epoch: 5| Step: 5
Training loss: 0.3484629988670349
Validation loss: 1.580716859909796

Epoch: 5| Step: 6
Training loss: 0.12666907906532288
Validation loss: 1.57686431946293

Epoch: 5| Step: 7
Training loss: 0.2803167402744293
Validation loss: 1.5949523743762766

Epoch: 5| Step: 8
Training loss: 0.32774654030799866
Validation loss: 1.582949899858044

Epoch: 5| Step: 9
Training loss: 0.29308682680130005
Validation loss: 1.5853610372030607

Epoch: 5| Step: 10
Training loss: 0.33501681685447693
Validation loss: 1.5976503100446475

Epoch: 349| Step: 0
Training loss: 0.29687532782554626
Validation loss: 1.6264411672469108

Epoch: 5| Step: 1
Training loss: 0.169956773519516
Validation loss: 1.6225957268027849

Epoch: 5| Step: 2
Training loss: 0.32445424795150757
Validation loss: 1.6228502911906089

Epoch: 5| Step: 3
Training loss: 0.3314489722251892
Validation loss: 1.6090141086168186

Epoch: 5| Step: 4
Training loss: 0.3271985650062561
Validation loss: 1.5991022074094383

Epoch: 5| Step: 5
Training loss: 0.3069990277290344
Validation loss: 1.6048549067589544

Epoch: 5| Step: 6
Training loss: 0.2932513356208801
Validation loss: 1.5835521355752022

Epoch: 5| Step: 7
Training loss: 0.29649853706359863
Validation loss: 1.5927610422975274

Epoch: 5| Step: 8
Training loss: 0.2565692067146301
Validation loss: 1.5883017842487623

Epoch: 5| Step: 9
Training loss: 0.3310306966304779
Validation loss: 1.5884082060988232

Epoch: 5| Step: 10
Training loss: 0.6444999575614929
Validation loss: 1.596659420638956

Epoch: 350| Step: 0
Training loss: 0.40922054648399353
Validation loss: 1.5906245323919481

Epoch: 5| Step: 1
Training loss: 0.3947012722492218
Validation loss: 1.6190280978397658

Epoch: 5| Step: 2
Training loss: 0.3269210457801819
Validation loss: 1.609923654986966

Epoch: 5| Step: 3
Training loss: 0.3533138334751129
Validation loss: 1.5883942009300314

Epoch: 5| Step: 4
Training loss: 0.3267970681190491
Validation loss: 1.5905413127714587

Epoch: 5| Step: 5
Training loss: 0.239694744348526
Validation loss: 1.566392538368061

Epoch: 5| Step: 6
Training loss: 0.3175150752067566
Validation loss: 1.5728911379332184

Epoch: 5| Step: 7
Training loss: 0.2687924802303314
Validation loss: 1.5779015441094675

Epoch: 5| Step: 8
Training loss: 0.18584486842155457
Validation loss: 1.5669784571534844

Epoch: 5| Step: 9
Training loss: 0.3812646269798279
Validation loss: 1.5372409743647422

Epoch: 5| Step: 10
Training loss: 0.3051125705242157
Validation loss: 1.563970361986468

Epoch: 351| Step: 0
Training loss: 0.41043099761009216
Validation loss: 1.52308625559653

Epoch: 5| Step: 1
Training loss: 0.4413195252418518
Validation loss: 1.5261718521835983

Epoch: 5| Step: 2
Training loss: 0.2143273800611496
Validation loss: 1.5322017297949841

Epoch: 5| Step: 3
Training loss: 0.42937469482421875
Validation loss: 1.5250581400368803

Epoch: 5| Step: 4
Training loss: 0.2282702475786209
Validation loss: 1.5360269520872383

Epoch: 5| Step: 5
Training loss: 0.3942340016365051
Validation loss: 1.5150913602562361

Epoch: 5| Step: 6
Training loss: 0.32664361596107483
Validation loss: 1.5447323014659267

Epoch: 5| Step: 7
Training loss: 0.1639355719089508
Validation loss: 1.5557538578587193

Epoch: 5| Step: 8
Training loss: 0.18849603831768036
Validation loss: 1.5533168085159794

Epoch: 5| Step: 9
Training loss: 0.3681305944919586
Validation loss: 1.5250838341251496

Epoch: 5| Step: 10
Training loss: 0.2795334458351135
Validation loss: 1.5419332071017193

Epoch: 352| Step: 0
Training loss: 0.19723574817180634
Validation loss: 1.5397412148855065

Epoch: 5| Step: 1
Training loss: 0.3804585039615631
Validation loss: 1.5414614030109939

Epoch: 5| Step: 2
Training loss: 0.3071780800819397
Validation loss: 1.5291071514929495

Epoch: 5| Step: 3
Training loss: 0.27658382058143616
Validation loss: 1.5055214205095846

Epoch: 5| Step: 4
Training loss: 0.29809460043907166
Validation loss: 1.5082118536836358

Epoch: 5| Step: 5
Training loss: 0.37940630316734314
Validation loss: 1.5221445137454617

Epoch: 5| Step: 6
Training loss: 0.41175350546836853
Validation loss: 1.4973515451595347

Epoch: 5| Step: 7
Training loss: 0.28219878673553467
Validation loss: 1.5123021025811472

Epoch: 5| Step: 8
Training loss: 0.22163614630699158
Validation loss: 1.5039298149847216

Epoch: 5| Step: 9
Training loss: 0.2489447295665741
Validation loss: 1.5186549707125592

Epoch: 5| Step: 10
Training loss: 0.3006981909275055
Validation loss: 1.521895166366331

Epoch: 353| Step: 0
Training loss: 0.35833540558815
Validation loss: 1.5441111646672732

Epoch: 5| Step: 1
Training loss: 0.22304216027259827
Validation loss: 1.5505553201962543

Epoch: 5| Step: 2
Training loss: 0.3613046705722809
Validation loss: 1.5295348731420373

Epoch: 5| Step: 3
Training loss: 0.11302997916936874
Validation loss: 1.5735647934739307

Epoch: 5| Step: 4
Training loss: 0.20895615220069885
Validation loss: 1.540107109213388

Epoch: 5| Step: 5
Training loss: 0.3681336045265198
Validation loss: 1.5725967243153562

Epoch: 5| Step: 6
Training loss: 0.36648672819137573
Validation loss: 1.5592325220825851

Epoch: 5| Step: 7
Training loss: 0.3939169645309448
Validation loss: 1.5478608198063348

Epoch: 5| Step: 8
Training loss: 0.3090035319328308
Validation loss: 1.5464247298497025

Epoch: 5| Step: 9
Training loss: 0.31082868576049805
Validation loss: 1.5269216260602396

Epoch: 5| Step: 10
Training loss: 0.26025640964508057
Validation loss: 1.5235614122882966

Epoch: 354| Step: 0
Training loss: 0.2349703013896942
Validation loss: 1.5139044920603435

Epoch: 5| Step: 1
Training loss: 0.4108508229255676
Validation loss: 1.5244432623668382

Epoch: 5| Step: 2
Training loss: 0.26869329810142517
Validation loss: 1.5024668196196198

Epoch: 5| Step: 3
Training loss: 0.3160458505153656
Validation loss: 1.495343445449747

Epoch: 5| Step: 4
Training loss: 0.1700950711965561
Validation loss: 1.5074302432357625

Epoch: 5| Step: 5
Training loss: 0.5019679069519043
Validation loss: 1.5166017304184616

Epoch: 5| Step: 6
Training loss: 0.24577240645885468
Validation loss: 1.492731555815666

Epoch: 5| Step: 7
Training loss: 0.36397045850753784
Validation loss: 1.5107043148368917

Epoch: 5| Step: 8
Training loss: 0.2203577756881714
Validation loss: 1.5006415767054404

Epoch: 5| Step: 9
Training loss: 0.25563111901283264
Validation loss: 1.5184453174632082

Epoch: 5| Step: 10
Training loss: 0.23071801662445068
Validation loss: 1.5518847293751215

Epoch: 355| Step: 0
Training loss: 0.5540988445281982
Validation loss: 1.5741782598598029

Epoch: 5| Step: 1
Training loss: 0.44460687041282654
Validation loss: 1.5724738977288688

Epoch: 5| Step: 2
Training loss: 0.29528799653053284
Validation loss: 1.599948420319506

Epoch: 5| Step: 3
Training loss: 0.2638182044029236
Validation loss: 1.5508469176548783

Epoch: 5| Step: 4
Training loss: 0.11581919342279434
Validation loss: 1.5467929173541326

Epoch: 5| Step: 5
Training loss: 0.32761484384536743
Validation loss: 1.5565101280007312

Epoch: 5| Step: 6
Training loss: 0.21893474459648132
Validation loss: 1.5561854416324246

Epoch: 5| Step: 7
Training loss: 0.2806919813156128
Validation loss: 1.5503437634437316

Epoch: 5| Step: 8
Training loss: 0.2967832088470459
Validation loss: 1.567402023141102

Epoch: 5| Step: 9
Training loss: 0.2511630058288574
Validation loss: 1.5500202768592424

Epoch: 5| Step: 10
Training loss: 0.40223604440689087
Validation loss: 1.5590621655987156

Epoch: 356| Step: 0
Training loss: 0.29549795389175415
Validation loss: 1.5644907900082168

Epoch: 5| Step: 1
Training loss: 0.3413829207420349
Validation loss: 1.547874350701609

Epoch: 5| Step: 2
Training loss: 0.14114895462989807
Validation loss: 1.556620599121176

Epoch: 5| Step: 3
Training loss: 0.28747671842575073
Validation loss: 1.5645314967760475

Epoch: 5| Step: 4
Training loss: 0.32644152641296387
Validation loss: 1.5918123158075477

Epoch: 5| Step: 5
Training loss: 0.3636544942855835
Validation loss: 1.6489198669310539

Epoch: 5| Step: 6
Training loss: 0.3237888813018799
Validation loss: 1.6385625305996145

Epoch: 5| Step: 7
Training loss: 0.23750576376914978
Validation loss: 1.606171178561385

Epoch: 5| Step: 8
Training loss: 0.38369959592819214
Validation loss: 1.5839875526325677

Epoch: 5| Step: 9
Training loss: 0.4133980870246887
Validation loss: 1.5836209507398709

Epoch: 5| Step: 10
Training loss: 0.30865567922592163
Validation loss: 1.5661872074168215

Epoch: 357| Step: 0
Training loss: 0.4342249035835266
Validation loss: 1.5798211571990803

Epoch: 5| Step: 1
Training loss: 0.3582896590232849
Validation loss: 1.5708879258043023

Epoch: 5| Step: 2
Training loss: 0.4314742088317871
Validation loss: 1.5742603655784362

Epoch: 5| Step: 3
Training loss: 0.2549525499343872
Validation loss: 1.533912850964454

Epoch: 5| Step: 4
Training loss: 0.18451419472694397
Validation loss: 1.5342062506624448

Epoch: 5| Step: 5
Training loss: 0.4774903357028961
Validation loss: 1.5244002880588654

Epoch: 5| Step: 6
Training loss: 0.4295960068702698
Validation loss: 1.5103915852885093

Epoch: 5| Step: 7
Training loss: 0.24231569468975067
Validation loss: 1.5166523007936374

Epoch: 5| Step: 8
Training loss: 0.1973448097705841
Validation loss: 1.5186096288824593

Epoch: 5| Step: 9
Training loss: 0.1742393672466278
Validation loss: 1.5478721818616312

Epoch: 5| Step: 10
Training loss: 0.2465217262506485
Validation loss: 1.57156357970289

Epoch: 358| Step: 0
Training loss: 0.2541794776916504
Validation loss: 1.5541072724967875

Epoch: 5| Step: 1
Training loss: 0.27532848715782166
Validation loss: 1.5744763087200861

Epoch: 5| Step: 2
Training loss: 0.39709821343421936
Validation loss: 1.5791286518496852

Epoch: 5| Step: 3
Training loss: 0.2982295751571655
Validation loss: 1.602224697348892

Epoch: 5| Step: 4
Training loss: 0.1900438368320465
Validation loss: 1.580768741587157

Epoch: 5| Step: 5
Training loss: 0.5235437154769897
Validation loss: 1.5884181145698792

Epoch: 5| Step: 6
Training loss: 0.17550688982009888
Validation loss: 1.580407246466606

Epoch: 5| Step: 7
Training loss: 0.2603519856929779
Validation loss: 1.6013642280332503

Epoch: 5| Step: 8
Training loss: 0.3512178063392639
Validation loss: 1.5945383989682762

Epoch: 5| Step: 9
Training loss: 0.3219098448753357
Validation loss: 1.5789438652735885

Epoch: 5| Step: 10
Training loss: 0.3369380831718445
Validation loss: 1.5847512111868909

Epoch: 359| Step: 0
Training loss: 0.2824484407901764
Validation loss: 1.5824296833366476

Epoch: 5| Step: 1
Training loss: 0.2765498161315918
Validation loss: 1.5635710070210118

Epoch: 5| Step: 2
Training loss: 0.30931657552719116
Validation loss: 1.5943921407063801

Epoch: 5| Step: 3
Training loss: 0.20299944281578064
Validation loss: 1.5778768344592022

Epoch: 5| Step: 4
Training loss: 0.2586415410041809
Validation loss: 1.5806545237059235

Epoch: 5| Step: 5
Training loss: 0.3481277525424957
Validation loss: 1.5482476424145442

Epoch: 5| Step: 6
Training loss: 0.20541858673095703
Validation loss: 1.5604041391803372

Epoch: 5| Step: 7
Training loss: 0.40024417638778687
Validation loss: 1.5625290152847127

Epoch: 5| Step: 8
Training loss: 0.24776652455329895
Validation loss: 1.5662849051977998

Epoch: 5| Step: 9
Training loss: 0.24002201855182648
Validation loss: 1.5439794345568585

Epoch: 5| Step: 10
Training loss: 0.4180760681629181
Validation loss: 1.545874144441338

Epoch: 360| Step: 0
Training loss: 0.440721333026886
Validation loss: 1.5114544476232221

Epoch: 5| Step: 1
Training loss: 0.3590661585330963
Validation loss: 1.509815195555328

Epoch: 5| Step: 2
Training loss: 0.37913572788238525
Validation loss: 1.5373870313808482

Epoch: 5| Step: 3
Training loss: 0.2710944414138794
Validation loss: 1.5134052461193455

Epoch: 5| Step: 4
Training loss: 0.29352515935897827
Validation loss: 1.526674626975931

Epoch: 5| Step: 5
Training loss: 0.22651052474975586
Validation loss: 1.5102779564037119

Epoch: 5| Step: 6
Training loss: 0.2712765336036682
Validation loss: 1.504395446469707

Epoch: 5| Step: 7
Training loss: 0.19669750332832336
Validation loss: 1.5072313342043149

Epoch: 5| Step: 8
Training loss: 0.2271381914615631
Validation loss: 1.4992594270295994

Epoch: 5| Step: 9
Training loss: 0.23822645843029022
Validation loss: 1.4888042608896892

Epoch: 5| Step: 10
Training loss: 0.18663334846496582
Validation loss: 1.5027522399861326

Epoch: 361| Step: 0
Training loss: 0.34106549620628357
Validation loss: 1.5117319181401243

Epoch: 5| Step: 1
Training loss: 0.3429562449455261
Validation loss: 1.505464243632491

Epoch: 5| Step: 2
Training loss: 0.18843701481819153
Validation loss: 1.5176579106238581

Epoch: 5| Step: 3
Training loss: 0.2685006260871887
Validation loss: 1.5292574795343543

Epoch: 5| Step: 4
Training loss: 0.2215609848499298
Validation loss: 1.5160793758207751

Epoch: 5| Step: 5
Training loss: 0.39095401763916016
Validation loss: 1.5212033205134894

Epoch: 5| Step: 6
Training loss: 0.4315299093723297
Validation loss: 1.5385682134218113

Epoch: 5| Step: 7
Training loss: 0.1315147578716278
Validation loss: 1.5206366213419105

Epoch: 5| Step: 8
Training loss: 0.30444246530532837
Validation loss: 1.5147901004360569

Epoch: 5| Step: 9
Training loss: 0.22130990028381348
Validation loss: 1.528099634314096

Epoch: 5| Step: 10
Training loss: 0.1421525925397873
Validation loss: 1.5211483816946707

Epoch: 362| Step: 0
Training loss: 0.20055851340293884
Validation loss: 1.524782028249515

Epoch: 5| Step: 1
Training loss: 0.4072917401790619
Validation loss: 1.5388162725715226

Epoch: 5| Step: 2
Training loss: 0.2392190396785736
Validation loss: 1.5238836401252336

Epoch: 5| Step: 3
Training loss: 0.22698815166950226
Validation loss: 1.5282577545412126

Epoch: 5| Step: 4
Training loss: 0.2376995086669922
Validation loss: 1.504471202050486

Epoch: 5| Step: 5
Training loss: 0.3149123191833496
Validation loss: 1.4944945560988558

Epoch: 5| Step: 6
Training loss: 0.20387792587280273
Validation loss: 1.4912771794103807

Epoch: 5| Step: 7
Training loss: 0.2116279900074005
Validation loss: 1.4934447529495403

Epoch: 5| Step: 8
Training loss: 0.49904459714889526
Validation loss: 1.5011546304149013

Epoch: 5| Step: 9
Training loss: 0.2608700692653656
Validation loss: 1.5064812988363288

Epoch: 5| Step: 10
Training loss: 0.24938958883285522
Validation loss: 1.5186012432139406

Epoch: 363| Step: 0
Training loss: 0.16594883799552917
Validation loss: 1.510291995540742

Epoch: 5| Step: 1
Training loss: 0.27289023995399475
Validation loss: 1.5131468490887714

Epoch: 5| Step: 2
Training loss: 0.2407020777463913
Validation loss: 1.5183777937325098

Epoch: 5| Step: 3
Training loss: 0.242040753364563
Validation loss: 1.531680961449941

Epoch: 5| Step: 4
Training loss: 0.31956037878990173
Validation loss: 1.5540558343292565

Epoch: 5| Step: 5
Training loss: 0.20791873335838318
Validation loss: 1.5430192101386286

Epoch: 5| Step: 6
Training loss: 0.26309794187545776
Validation loss: 1.528063097307759

Epoch: 5| Step: 7
Training loss: 0.1833208203315735
Validation loss: 1.560154193191118

Epoch: 5| Step: 8
Training loss: 0.36472925543785095
Validation loss: 1.5645694207119685

Epoch: 5| Step: 9
Training loss: 0.1600780338048935
Validation loss: 1.5806555568530996

Epoch: 5| Step: 10
Training loss: 0.5150589346885681
Validation loss: 1.5712364963305894

Epoch: 364| Step: 0
Training loss: 0.319595605134964
Validation loss: 1.5723854675087878

Epoch: 5| Step: 1
Training loss: 0.39774054288864136
Validation loss: 1.5902334932358033

Epoch: 5| Step: 2
Training loss: 0.19383645057678223
Validation loss: 1.5904682592679096

Epoch: 5| Step: 3
Training loss: 0.13249507546424866
Validation loss: 1.5815311747212564

Epoch: 5| Step: 4
Training loss: 0.4061216413974762
Validation loss: 1.588363250096639

Epoch: 5| Step: 5
Training loss: 0.23295870423316956
Validation loss: 1.6089267358984998

Epoch: 5| Step: 6
Training loss: 0.2852688133716583
Validation loss: 1.5889857469066497

Epoch: 5| Step: 7
Training loss: 0.23178410530090332
Validation loss: 1.5998036066691081

Epoch: 5| Step: 8
Training loss: 0.24777522683143616
Validation loss: 1.6136556158783615

Epoch: 5| Step: 9
Training loss: 0.4399656355381012
Validation loss: 1.611660280535298

Epoch: 5| Step: 10
Training loss: 0.14412406086921692
Validation loss: 1.5980655249728952

Epoch: 365| Step: 0
Training loss: 0.33617618680000305
Validation loss: 1.521830875386474

Epoch: 5| Step: 1
Training loss: 0.32916468381881714
Validation loss: 1.5094529262153051

Epoch: 5| Step: 2
Training loss: 0.2695215940475464
Validation loss: 1.4915366723973265

Epoch: 5| Step: 3
Training loss: 0.16196852922439575
Validation loss: 1.4685637694533153

Epoch: 5| Step: 4
Training loss: 0.23554906249046326
Validation loss: 1.4740652845751854

Epoch: 5| Step: 5
Training loss: 0.2814015746116638
Validation loss: 1.4733135892498879

Epoch: 5| Step: 6
Training loss: 0.16105642914772034
Validation loss: 1.4967013212942308

Epoch: 5| Step: 7
Training loss: 0.29958510398864746
Validation loss: 1.5216715297391337

Epoch: 5| Step: 8
Training loss: 0.4683406352996826
Validation loss: 1.5237504384850944

Epoch: 5| Step: 9
Training loss: 0.2702271640300751
Validation loss: 1.5368645742375364

Epoch: 5| Step: 10
Training loss: 0.2494204193353653
Validation loss: 1.538595030384679

Epoch: 366| Step: 0
Training loss: 0.35090816020965576
Validation loss: 1.5471879269487114

Epoch: 5| Step: 1
Training loss: 0.26170238852500916
Validation loss: 1.5562900932886268

Epoch: 5| Step: 2
Training loss: 0.19372041523456573
Validation loss: 1.5742718711976083

Epoch: 5| Step: 3
Training loss: 0.22761039435863495
Validation loss: 1.5696845862173265

Epoch: 5| Step: 4
Training loss: 0.3486230969429016
Validation loss: 1.5602583667283416

Epoch: 5| Step: 5
Training loss: 0.15093672275543213
Validation loss: 1.5661212475069108

Epoch: 5| Step: 6
Training loss: 0.2938847243785858
Validation loss: 1.5840888151558496

Epoch: 5| Step: 7
Training loss: 0.5049718618392944
Validation loss: 1.5549847823317333

Epoch: 5| Step: 8
Training loss: 0.3632599115371704
Validation loss: 1.5832300788612776

Epoch: 5| Step: 9
Training loss: 0.34283480048179626
Validation loss: 1.5737475297784294

Epoch: 5| Step: 10
Training loss: 0.306029349565506
Validation loss: 1.5832949851148872

Epoch: 367| Step: 0
Training loss: 0.15267325937747955
Validation loss: 1.5631009135195004

Epoch: 5| Step: 1
Training loss: 0.35040900111198425
Validation loss: 1.55109885046559

Epoch: 5| Step: 2
Training loss: 0.3699868321418762
Validation loss: 1.5570981861442648

Epoch: 5| Step: 3
Training loss: 0.31474921107292175
Validation loss: 1.5496201592106973

Epoch: 5| Step: 4
Training loss: 0.2945675551891327
Validation loss: 1.52707992317856

Epoch: 5| Step: 5
Training loss: 0.3161226809024811
Validation loss: 1.5330989681264406

Epoch: 5| Step: 6
Training loss: 0.3934105336666107
Validation loss: 1.552845214002876

Epoch: 5| Step: 7
Training loss: 0.29490190744400024
Validation loss: 1.544966697692871

Epoch: 5| Step: 8
Training loss: 0.3106532692909241
Validation loss: 1.5451274610334826

Epoch: 5| Step: 9
Training loss: 0.19914773106575012
Validation loss: 1.5143442589749572

Epoch: 5| Step: 10
Training loss: 0.4021121859550476
Validation loss: 1.539738420517214

Epoch: 368| Step: 0
Training loss: 0.34174737334251404
Validation loss: 1.5233671972828526

Epoch: 5| Step: 1
Training loss: 0.21577925980091095
Validation loss: 1.5321418457133795

Epoch: 5| Step: 2
Training loss: 0.36148056387901306
Validation loss: 1.518325718500281

Epoch: 5| Step: 3
Training loss: 0.24327869713306427
Validation loss: 1.5080844727895593

Epoch: 5| Step: 4
Training loss: 0.4092786908149719
Validation loss: 1.5462521820939996

Epoch: 5| Step: 5
Training loss: 0.2360997200012207
Validation loss: 1.5318875517896426

Epoch: 5| Step: 6
Training loss: 0.17536672949790955
Validation loss: 1.5498849384246334

Epoch: 5| Step: 7
Training loss: 0.26063117384910583
Validation loss: 1.5247236964523152

Epoch: 5| Step: 8
Training loss: 0.2323591262102127
Validation loss: 1.5259413078267088

Epoch: 5| Step: 9
Training loss: 0.40426430106163025
Validation loss: 1.5369650420322214

Epoch: 5| Step: 10
Training loss: 0.2868969440460205
Validation loss: 1.5417188752082087

Epoch: 369| Step: 0
Training loss: 0.1483674794435501
Validation loss: 1.5153320861119095

Epoch: 5| Step: 1
Training loss: 0.24806809425354004
Validation loss: 1.4986527119913409

Epoch: 5| Step: 2
Training loss: 0.2356923520565033
Validation loss: 1.515636654310329

Epoch: 5| Step: 3
Training loss: 0.2830527126789093
Validation loss: 1.5274509883696032

Epoch: 5| Step: 4
Training loss: 0.293956995010376
Validation loss: 1.5415548272030328

Epoch: 5| Step: 5
Training loss: 0.28067272901535034
Validation loss: 1.5601052212458786

Epoch: 5| Step: 6
Training loss: 0.4112909436225891
Validation loss: 1.5394020753522073

Epoch: 5| Step: 7
Training loss: 0.3633747696876526
Validation loss: 1.5218855719412527

Epoch: 5| Step: 8
Training loss: 0.2569229006767273
Validation loss: 1.5406491974348664

Epoch: 5| Step: 9
Training loss: 0.23976865410804749
Validation loss: 1.522390773219447

Epoch: 5| Step: 10
Training loss: 0.25534942746162415
Validation loss: 1.5346802690977692

Epoch: 370| Step: 0
Training loss: 0.19411739706993103
Validation loss: 1.5497466248850669

Epoch: 5| Step: 1
Training loss: 0.3069426715373993
Validation loss: 1.5469201790389193

Epoch: 5| Step: 2
Training loss: 0.24825206398963928
Validation loss: 1.5571707038469211

Epoch: 5| Step: 3
Training loss: 0.4119086265563965
Validation loss: 1.558987130400955

Epoch: 5| Step: 4
Training loss: 0.2507990896701813
Validation loss: 1.5711352004799792

Epoch: 5| Step: 5
Training loss: 0.302337110042572
Validation loss: 1.5647466426254601

Epoch: 5| Step: 6
Training loss: 0.18287920951843262
Validation loss: 1.5335515699078959

Epoch: 5| Step: 7
Training loss: 0.13574248552322388
Validation loss: 1.5403770721086891

Epoch: 5| Step: 8
Training loss: 0.3112567961215973
Validation loss: 1.5476376497617332

Epoch: 5| Step: 9
Training loss: 0.1793929934501648
Validation loss: 1.5645068883895874

Epoch: 5| Step: 10
Training loss: 0.2926834225654602
Validation loss: 1.5372411012649536

Epoch: 371| Step: 0
Training loss: 0.3637961745262146
Validation loss: 1.5263566637551913

Epoch: 5| Step: 1
Training loss: 0.33097580075263977
Validation loss: 1.5322924249915666

Epoch: 5| Step: 2
Training loss: 0.2295425832271576
Validation loss: 1.533107187158318

Epoch: 5| Step: 3
Training loss: 0.15759775042533875
Validation loss: 1.5499540580216276

Epoch: 5| Step: 4
Training loss: 0.2611744999885559
Validation loss: 1.5347022837208164

Epoch: 5| Step: 5
Training loss: 0.18711693584918976
Validation loss: 1.5248771893080844

Epoch: 5| Step: 6
Training loss: 0.2900209128856659
Validation loss: 1.5410770600841892

Epoch: 5| Step: 7
Training loss: 0.3069167137145996
Validation loss: 1.5258068730754237

Epoch: 5| Step: 8
Training loss: 0.26924118399620056
Validation loss: 1.5614884117598176

Epoch: 5| Step: 9
Training loss: 0.14358821511268616
Validation loss: 1.5552903298408753

Epoch: 5| Step: 10
Training loss: 0.17572332918643951
Validation loss: 1.5489964228804394

Epoch: 372| Step: 0
Training loss: 0.12585271894931793
Validation loss: 1.5231210429181334

Epoch: 5| Step: 1
Training loss: 0.34096193313598633
Validation loss: 1.551408802309344

Epoch: 5| Step: 2
Training loss: 0.15307721495628357
Validation loss: 1.529396048156164

Epoch: 5| Step: 3
Training loss: 0.2154533863067627
Validation loss: 1.5517431702665103

Epoch: 5| Step: 4
Training loss: 0.24806006252765656
Validation loss: 1.5824340440893685

Epoch: 5| Step: 5
Training loss: 0.2354814112186432
Validation loss: 1.5445043976588915

Epoch: 5| Step: 6
Training loss: 0.3269982933998108
Validation loss: 1.5709068903359034

Epoch: 5| Step: 7
Training loss: 0.33456936478614807
Validation loss: 1.5808092868456276

Epoch: 5| Step: 8
Training loss: 0.220608189702034
Validation loss: 1.5690793106632848

Epoch: 5| Step: 9
Training loss: 0.24268122017383575
Validation loss: 1.554057498132029

Epoch: 5| Step: 10
Training loss: 0.17201580107212067
Validation loss: 1.5906508173993839

Epoch: 373| Step: 0
Training loss: 0.1180851086974144
Validation loss: 1.5879138823478454

Epoch: 5| Step: 1
Training loss: 0.30650752782821655
Validation loss: 1.5965577838241414

Epoch: 5| Step: 2
Training loss: 0.1565428376197815
Validation loss: 1.579225665779524

Epoch: 5| Step: 3
Training loss: 0.12546637654304504
Validation loss: 1.5640625453764392

Epoch: 5| Step: 4
Training loss: 0.4367818832397461
Validation loss: 1.5540860006886144

Epoch: 5| Step: 5
Training loss: 0.4518612027168274
Validation loss: 1.5789639052524362

Epoch: 5| Step: 6
Training loss: 0.22382298111915588
Validation loss: 1.5850207779997139

Epoch: 5| Step: 7
Training loss: 0.2124629020690918
Validation loss: 1.5621773901806082

Epoch: 5| Step: 8
Training loss: 0.226795956492424
Validation loss: 1.5585266787518737

Epoch: 5| Step: 9
Training loss: 0.2390984296798706
Validation loss: 1.5443769943329595

Epoch: 5| Step: 10
Training loss: 0.1098909080028534
Validation loss: 1.5604107726004817

Epoch: 374| Step: 0
Training loss: 0.24777932465076447
Validation loss: 1.5490774364881619

Epoch: 5| Step: 1
Training loss: 0.2450689822435379
Validation loss: 1.5463731032545849

Epoch: 5| Step: 2
Training loss: 0.3501705527305603
Validation loss: 1.5649466886315295

Epoch: 5| Step: 3
Training loss: 0.24396610260009766
Validation loss: 1.540342894933557

Epoch: 5| Step: 4
Training loss: 0.14123284816741943
Validation loss: 1.5226936558241486

Epoch: 5| Step: 5
Training loss: 0.32977157831192017
Validation loss: 1.5185641319521013

Epoch: 5| Step: 6
Training loss: 0.21995703876018524
Validation loss: 1.524442385601741

Epoch: 5| Step: 7
Training loss: 0.26808273792266846
Validation loss: 1.5130762271983649

Epoch: 5| Step: 8
Training loss: 0.2139596939086914
Validation loss: 1.4942367025600967

Epoch: 5| Step: 9
Training loss: 0.2913443148136139
Validation loss: 1.476320360296516

Epoch: 5| Step: 10
Training loss: 0.29465043544769287
Validation loss: 1.4683250150372904

Epoch: 375| Step: 0
Training loss: 0.11022527515888214
Validation loss: 1.4600582840622112

Epoch: 5| Step: 1
Training loss: 0.46576938033103943
Validation loss: 1.4699811973879415

Epoch: 5| Step: 2
Training loss: 0.37044477462768555
Validation loss: 1.4848411942041049

Epoch: 5| Step: 3
Training loss: 0.26361793279647827
Validation loss: 1.4765543450591385

Epoch: 5| Step: 4
Training loss: 0.22108416259288788
Validation loss: 1.50496494641868

Epoch: 5| Step: 5
Training loss: 0.21845531463623047
Validation loss: 1.532142029013685

Epoch: 5| Step: 6
Training loss: 0.2861531376838684
Validation loss: 1.5471891023779427

Epoch: 5| Step: 7
Training loss: 0.23580248653888702
Validation loss: 1.5912671550627677

Epoch: 5| Step: 8
Training loss: 0.3053824305534363
Validation loss: 1.6020986610843289

Epoch: 5| Step: 9
Training loss: 0.2881737947463989
Validation loss: 1.598969958161795

Epoch: 5| Step: 10
Training loss: 0.30672115087509155
Validation loss: 1.5918724062622234

Epoch: 376| Step: 0
Training loss: 0.20215579867362976
Validation loss: 1.5904333924734464

Epoch: 5| Step: 1
Training loss: 0.34131455421447754
Validation loss: 1.5849049514339817

Epoch: 5| Step: 2
Training loss: 0.3269248604774475
Validation loss: 1.5721586494035618

Epoch: 5| Step: 3
Training loss: 0.42892688512802124
Validation loss: 1.5703475347129248

Epoch: 5| Step: 4
Training loss: 0.1369861513376236
Validation loss: 1.5599530602014193

Epoch: 5| Step: 5
Training loss: 0.235731840133667
Validation loss: 1.5466833370988087

Epoch: 5| Step: 6
Training loss: 0.2072606086730957
Validation loss: 1.5313449021308654

Epoch: 5| Step: 7
Training loss: 0.21201784908771515
Validation loss: 1.535054728549014

Epoch: 5| Step: 8
Training loss: 0.2047228068113327
Validation loss: 1.5422764849919144

Epoch: 5| Step: 9
Training loss: 0.2345864474773407
Validation loss: 1.5160646207870976

Epoch: 5| Step: 10
Training loss: 0.21228310465812683
Validation loss: 1.5320088273735457

Epoch: 377| Step: 0
Training loss: 0.10233869403600693
Validation loss: 1.517024427331904

Epoch: 5| Step: 1
Training loss: 0.21041052043437958
Validation loss: 1.5160845056656869

Epoch: 5| Step: 2
Training loss: 0.33397340774536133
Validation loss: 1.5463409609692071

Epoch: 5| Step: 3
Training loss: 0.31077954173088074
Validation loss: 1.5657091435565744

Epoch: 5| Step: 4
Training loss: 0.2408744841814041
Validation loss: 1.5375471807295276

Epoch: 5| Step: 5
Training loss: 0.25823426246643066
Validation loss: 1.561087385300667

Epoch: 5| Step: 6
Training loss: 0.4466319978237152
Validation loss: 1.542277338684246

Epoch: 5| Step: 7
Training loss: 0.22103652358055115
Validation loss: 1.5310745341803438

Epoch: 5| Step: 8
Training loss: 0.15182022750377655
Validation loss: 1.5328048582999938

Epoch: 5| Step: 9
Training loss: 0.15208183228969574
Validation loss: 1.5372478872217157

Epoch: 5| Step: 10
Training loss: 0.1393302083015442
Validation loss: 1.5291872114263556

Epoch: 378| Step: 0
Training loss: 0.23293080925941467
Validation loss: 1.5541288865509855

Epoch: 5| Step: 1
Training loss: 0.25030165910720825
Validation loss: 1.5484817617683

Epoch: 5| Step: 2
Training loss: 0.21327510476112366
Validation loss: 1.5337373646356727

Epoch: 5| Step: 3
Training loss: 0.1800317019224167
Validation loss: 1.536355959471836

Epoch: 5| Step: 4
Training loss: 0.2895725965499878
Validation loss: 1.5036632130222936

Epoch: 5| Step: 5
Training loss: 0.1646287590265274
Validation loss: 1.5063072366099204

Epoch: 5| Step: 6
Training loss: 0.30495691299438477
Validation loss: 1.4810457665433165

Epoch: 5| Step: 7
Training loss: 0.13374021649360657
Validation loss: 1.4522044004932526

Epoch: 5| Step: 8
Training loss: 0.38337478041648865
Validation loss: 1.4917159734233734

Epoch: 5| Step: 9
Training loss: 0.21905820071697235
Validation loss: 1.451066090214637

Epoch: 5| Step: 10
Training loss: 0.24523970484733582
Validation loss: 1.4468461749374226

Epoch: 379| Step: 0
Training loss: 0.27465614676475525
Validation loss: 1.461583314403411

Epoch: 5| Step: 1
Training loss: 0.31908610463142395
Validation loss: 1.445715001834336

Epoch: 5| Step: 2
Training loss: 0.2311689555644989
Validation loss: 1.4635694308947491

Epoch: 5| Step: 3
Training loss: 0.31072312593460083
Validation loss: 1.4787504621731338

Epoch: 5| Step: 4
Training loss: 0.2878969609737396
Validation loss: 1.5076813749087754

Epoch: 5| Step: 5
Training loss: 0.25560489296913147
Validation loss: 1.5090934858527234

Epoch: 5| Step: 6
Training loss: 0.34586256742477417
Validation loss: 1.4951299198212162

Epoch: 5| Step: 7
Training loss: 0.22336196899414062
Validation loss: 1.5164641340573628

Epoch: 5| Step: 8
Training loss: 0.14559593796730042
Validation loss: 1.5259766694038146

Epoch: 5| Step: 9
Training loss: 0.12210120260715485
Validation loss: 1.5226865045485958

Epoch: 5| Step: 10
Training loss: 0.11589956283569336
Validation loss: 1.53889419955592

Epoch: 380| Step: 0
Training loss: 0.21488793194293976
Validation loss: 1.5328513332592544

Epoch: 5| Step: 1
Training loss: 0.17663662135601044
Validation loss: 1.5523591105655958

Epoch: 5| Step: 2
Training loss: 0.27736037969589233
Validation loss: 1.5507792554875857

Epoch: 5| Step: 3
Training loss: 0.39034491777420044
Validation loss: 1.537422244266797

Epoch: 5| Step: 4
Training loss: 0.2128872126340866
Validation loss: 1.5376366889604958

Epoch: 5| Step: 5
Training loss: 0.3024856150150299
Validation loss: 1.4934343022684897

Epoch: 5| Step: 6
Training loss: 0.0976683720946312
Validation loss: 1.497713206916727

Epoch: 5| Step: 7
Training loss: 0.24197211861610413
Validation loss: 1.484179526247004

Epoch: 5| Step: 8
Training loss: 0.23715730011463165
Validation loss: 1.4812880305833713

Epoch: 5| Step: 9
Training loss: 0.20652851462364197
Validation loss: 1.5055921308455928

Epoch: 5| Step: 10
Training loss: 0.21621590852737427
Validation loss: 1.4887338312723304

Epoch: 381| Step: 0
Training loss: 0.20695213973522186
Validation loss: 1.489227097521546

Epoch: 5| Step: 1
Training loss: 0.3969229757785797
Validation loss: 1.4548862775166829

Epoch: 5| Step: 2
Training loss: 0.14970512688159943
Validation loss: 1.4646456895336029

Epoch: 5| Step: 3
Training loss: 0.3081390857696533
Validation loss: 1.4695540564034575

Epoch: 5| Step: 4
Training loss: 0.17960742115974426
Validation loss: 1.4842162016899354

Epoch: 5| Step: 5
Training loss: 0.2679545283317566
Validation loss: 1.5021995588015484

Epoch: 5| Step: 6
Training loss: 0.33380264043807983
Validation loss: 1.4837642267186155

Epoch: 5| Step: 7
Training loss: 0.16336177289485931
Validation loss: 1.5066120701451455

Epoch: 5| Step: 8
Training loss: 0.11257598549127579
Validation loss: 1.4838446096707416

Epoch: 5| Step: 9
Training loss: 0.22839340567588806
Validation loss: 1.4655620385241765

Epoch: 5| Step: 10
Training loss: 0.21528781950473785
Validation loss: 1.5152711394012615

Epoch: 382| Step: 0
Training loss: 0.09335631132125854
Validation loss: 1.5587887661431425

Epoch: 5| Step: 1
Training loss: 0.17900784313678741
Validation loss: 1.5409455478832286

Epoch: 5| Step: 2
Training loss: 0.2423313558101654
Validation loss: 1.553587362330447

Epoch: 5| Step: 3
Training loss: 0.3474268317222595
Validation loss: 1.5347589741470993

Epoch: 5| Step: 4
Training loss: 0.18639890849590302
Validation loss: 1.5419133722141225

Epoch: 5| Step: 5
Training loss: 0.2377890646457672
Validation loss: 1.5270598844815326

Epoch: 5| Step: 6
Training loss: 0.2731207013130188
Validation loss: 1.5062947324527207

Epoch: 5| Step: 7
Training loss: 0.21029618382453918
Validation loss: 1.4858324079103367

Epoch: 5| Step: 8
Training loss: 0.21135346591472626
Validation loss: 1.4936088092865483

Epoch: 5| Step: 9
Training loss: 0.21238012611865997
Validation loss: 1.5069964252492434

Epoch: 5| Step: 10
Training loss: 0.3659032881259918
Validation loss: 1.4838461138868844

Epoch: 383| Step: 0
Training loss: 0.2026398628950119
Validation loss: 1.5265976126476

Epoch: 5| Step: 1
Training loss: 0.3001337945461273
Validation loss: 1.5310375626369188

Epoch: 5| Step: 2
Training loss: 0.2026146650314331
Validation loss: 1.5095169710856613

Epoch: 5| Step: 3
Training loss: 0.30171042680740356
Validation loss: 1.5053492464045042

Epoch: 5| Step: 4
Training loss: 0.17249171435832977
Validation loss: 1.4965342065339446

Epoch: 5| Step: 5
Training loss: 0.22281937301158905
Validation loss: 1.516224879090504

Epoch: 5| Step: 6
Training loss: 0.1978333592414856
Validation loss: 1.5286065583587976

Epoch: 5| Step: 7
Training loss: 0.16735222935676575
Validation loss: 1.516915673850685

Epoch: 5| Step: 8
Training loss: 0.22837424278259277
Validation loss: 1.5252382332278835

Epoch: 5| Step: 9
Training loss: 0.2008136510848999
Validation loss: 1.5211766804418256

Epoch: 5| Step: 10
Training loss: 0.17310193181037903
Validation loss: 1.5021398176429093

Epoch: 384| Step: 0
Training loss: 0.24439549446105957
Validation loss: 1.507754018229823

Epoch: 5| Step: 1
Training loss: 0.22953172028064728
Validation loss: 1.5040703601734613

Epoch: 5| Step: 2
Training loss: 0.16003330051898956
Validation loss: 1.498853010516013

Epoch: 5| Step: 3
Training loss: 0.1778687685728073
Validation loss: 1.5007634470539708

Epoch: 5| Step: 4
Training loss: 0.343144029378891
Validation loss: 1.4883614099153908

Epoch: 5| Step: 5
Training loss: 0.10358478873968124
Validation loss: 1.504309945209052

Epoch: 5| Step: 6
Training loss: 0.10306964069604874
Validation loss: 1.4981808354777675

Epoch: 5| Step: 7
Training loss: 0.2203816920518875
Validation loss: 1.5282603002363635

Epoch: 5| Step: 8
Training loss: 0.35499799251556396
Validation loss: 1.5245457772285707

Epoch: 5| Step: 9
Training loss: 0.2252601683139801
Validation loss: 1.5552465056860318

Epoch: 5| Step: 10
Training loss: 0.197701096534729
Validation loss: 1.5598680883325555

Epoch: 385| Step: 0
Training loss: 0.25622037053108215
Validation loss: 1.5432054060761646

Epoch: 5| Step: 1
Training loss: 0.19004297256469727
Validation loss: 1.5697478222590622

Epoch: 5| Step: 2
Training loss: 0.2841164469718933
Validation loss: 1.538046318997619

Epoch: 5| Step: 3
Training loss: 0.18028497695922852
Validation loss: 1.5357085774021764

Epoch: 5| Step: 4
Training loss: 0.10011474788188934
Validation loss: 1.51237988984713

Epoch: 5| Step: 5
Training loss: 0.1670764982700348
Validation loss: 1.5044958027460242

Epoch: 5| Step: 6
Training loss: 0.3934680223464966
Validation loss: 1.472740875777378

Epoch: 5| Step: 7
Training loss: 0.17582878470420837
Validation loss: 1.4682065863763132

Epoch: 5| Step: 8
Training loss: 0.24281027913093567
Validation loss: 1.4836925345082437

Epoch: 5| Step: 9
Training loss: 0.2763485312461853
Validation loss: 1.4706519803693217

Epoch: 5| Step: 10
Training loss: 0.1607947051525116
Validation loss: 1.4678903228493148

Epoch: 386| Step: 0
Training loss: 0.2465074509382248
Validation loss: 1.457990240025264

Epoch: 5| Step: 1
Training loss: 0.21785500645637512
Validation loss: 1.479108436774182

Epoch: 5| Step: 2
Training loss: 0.14421498775482178
Validation loss: 1.487827435616524

Epoch: 5| Step: 3
Training loss: 0.22060450911521912
Validation loss: 1.4788300824421707

Epoch: 5| Step: 4
Training loss: 0.200971320271492
Validation loss: 1.467521918717251

Epoch: 5| Step: 5
Training loss: 0.18454734981060028
Validation loss: 1.5084218735335975

Epoch: 5| Step: 6
Training loss: 0.21618394553661346
Validation loss: 1.4750123728987992

Epoch: 5| Step: 7
Training loss: 0.2193770408630371
Validation loss: 1.50798188999135

Epoch: 5| Step: 8
Training loss: 0.12787458300590515
Validation loss: 1.5071136272081764

Epoch: 5| Step: 9
Training loss: 0.2785000503063202
Validation loss: 1.5027579517774685

Epoch: 5| Step: 10
Training loss: 0.1917228400707245
Validation loss: 1.5250805385651127

Epoch: 387| Step: 0
Training loss: 0.19771155714988708
Validation loss: 1.5428346433947164

Epoch: 5| Step: 1
Training loss: 0.16108809411525726
Validation loss: 1.5464757610392827

Epoch: 5| Step: 2
Training loss: 0.18021872639656067
Validation loss: 1.5546713311185119

Epoch: 5| Step: 3
Training loss: 0.2546840310096741
Validation loss: 1.5483255937535276

Epoch: 5| Step: 4
Training loss: 0.23437726497650146
Validation loss: 1.5370948891485892

Epoch: 5| Step: 5
Training loss: 0.2292381227016449
Validation loss: 1.512063544283631

Epoch: 5| Step: 6
Training loss: 0.1957990974187851
Validation loss: 1.521968045542317

Epoch: 5| Step: 7
Training loss: 0.12475241720676422
Validation loss: 1.4924026548221547

Epoch: 5| Step: 8
Training loss: 0.27336350083351135
Validation loss: 1.493209756189777

Epoch: 5| Step: 9
Training loss: 0.22230911254882812
Validation loss: 1.4952523054615143

Epoch: 5| Step: 10
Training loss: 0.310401052236557
Validation loss: 1.49927423461791

Epoch: 388| Step: 0
Training loss: 0.2782706916332245
Validation loss: 1.499239957460793

Epoch: 5| Step: 1
Training loss: 0.22214654088020325
Validation loss: 1.510829024417426

Epoch: 5| Step: 2
Training loss: 0.2546319365501404
Validation loss: 1.4942702016522806

Epoch: 5| Step: 3
Training loss: 0.19163629412651062
Validation loss: 1.4708652912929494

Epoch: 5| Step: 4
Training loss: 0.09149150550365448
Validation loss: 1.483487645785014

Epoch: 5| Step: 5
Training loss: 0.1344558149576187
Validation loss: 1.504954211173519

Epoch: 5| Step: 6
Training loss: 0.22210364043712616
Validation loss: 1.484298639400031

Epoch: 5| Step: 7
Training loss: 0.2526295781135559
Validation loss: 1.4896169503529866

Epoch: 5| Step: 8
Training loss: 0.27647802233695984
Validation loss: 1.4714729978192238

Epoch: 5| Step: 9
Training loss: 0.18264015018939972
Validation loss: 1.4865710363593152

Epoch: 5| Step: 10
Training loss: 0.14806091785430908
Validation loss: 1.4922305691626765

Epoch: 389| Step: 0
Training loss: 0.23841127753257751
Validation loss: 1.4689388352055703

Epoch: 5| Step: 1
Training loss: 0.15568500757217407
Validation loss: 1.4664079258518834

Epoch: 5| Step: 2
Training loss: 0.15718290209770203
Validation loss: 1.446903060841304

Epoch: 5| Step: 3
Training loss: 0.1969493180513382
Validation loss: 1.4501292218444168

Epoch: 5| Step: 4
Training loss: 0.27675139904022217
Validation loss: 1.4539004404057738

Epoch: 5| Step: 5
Training loss: 0.16396541893482208
Validation loss: 1.447253902112284

Epoch: 5| Step: 6
Training loss: 0.1868312507867813
Validation loss: 1.473968800678048

Epoch: 5| Step: 7
Training loss: 0.2355918139219284
Validation loss: 1.4697781070586173

Epoch: 5| Step: 8
Training loss: 0.24380221962928772
Validation loss: 1.503746747970581

Epoch: 5| Step: 9
Training loss: 0.30326512455940247
Validation loss: 1.5101710647665045

Epoch: 5| Step: 10
Training loss: 0.20813491940498352
Validation loss: 1.4800674729449774

Epoch: 390| Step: 0
Training loss: 0.18066327273845673
Validation loss: 1.519189033457028

Epoch: 5| Step: 1
Training loss: 0.24341797828674316
Validation loss: 1.5153525388368996

Epoch: 5| Step: 2
Training loss: 0.220289945602417
Validation loss: 1.5533564802139037

Epoch: 5| Step: 3
Training loss: 0.2763139605522156
Validation loss: 1.532220035470942

Epoch: 5| Step: 4
Training loss: 0.19865548610687256
Validation loss: 1.5839002100370263

Epoch: 5| Step: 5
Training loss: 0.1631595939397812
Validation loss: 1.5589649049184655

Epoch: 5| Step: 6
Training loss: 0.1442369520664215
Validation loss: 1.5434367528525732

Epoch: 5| Step: 7
Training loss: 0.30505603551864624
Validation loss: 1.5456448190955705

Epoch: 5| Step: 8
Training loss: 0.24420027434825897
Validation loss: 1.5265338414458818

Epoch: 5| Step: 9
Training loss: 0.17030705511569977
Validation loss: 1.538094053986252

Epoch: 5| Step: 10
Training loss: 0.1443174034357071
Validation loss: 1.5402592292395971

Epoch: 391| Step: 0
Training loss: 0.20757432281970978
Validation loss: 1.545179522165688

Epoch: 5| Step: 1
Training loss: 0.18724516034126282
Validation loss: 1.538974699153695

Epoch: 5| Step: 2
Training loss: 0.17891843616962433
Validation loss: 1.5490071709438036

Epoch: 5| Step: 3
Training loss: 0.1915484219789505
Validation loss: 1.5188020807440563

Epoch: 5| Step: 4
Training loss: 0.16536477208137512
Validation loss: 1.5392957143886115

Epoch: 5| Step: 5
Training loss: 0.1724873036146164
Validation loss: 1.5333677671288932

Epoch: 5| Step: 6
Training loss: 0.21292296051979065
Validation loss: 1.5238407933583824

Epoch: 5| Step: 7
Training loss: 0.16984625160694122
Validation loss: 1.516476474782472

Epoch: 5| Step: 8
Training loss: 0.3379898965358734
Validation loss: 1.5061183501315374

Epoch: 5| Step: 9
Training loss: 0.1953696459531784
Validation loss: 1.5253188328076435

Epoch: 5| Step: 10
Training loss: 0.24891191720962524
Validation loss: 1.5225206318721975

Epoch: 392| Step: 0
Training loss: 0.17394138872623444
Validation loss: 1.5050457574987923

Epoch: 5| Step: 1
Training loss: 0.19447550177574158
Validation loss: 1.5180364744637602

Epoch: 5| Step: 2
Training loss: 0.13665135204792023
Validation loss: 1.5125322700828634

Epoch: 5| Step: 3
Training loss: 0.10561023652553558
Validation loss: 1.5285438529906734

Epoch: 5| Step: 4
Training loss: 0.2973577380180359
Validation loss: 1.531834497246691

Epoch: 5| Step: 5
Training loss: 0.22259068489074707
Validation loss: 1.529402575185222

Epoch: 5| Step: 6
Training loss: 0.3213821053504944
Validation loss: 1.5221005870449928

Epoch: 5| Step: 7
Training loss: 0.17197543382644653
Validation loss: 1.5300455516384495

Epoch: 5| Step: 8
Training loss: 0.2869024872779846
Validation loss: 1.5354918235091752

Epoch: 5| Step: 9
Training loss: 0.21293208003044128
Validation loss: 1.5127543685256795

Epoch: 5| Step: 10
Training loss: 0.12373790889978409
Validation loss: 1.524056137249034

Epoch: 393| Step: 0
Training loss: 0.20455089211463928
Validation loss: 1.5077258899647703

Epoch: 5| Step: 1
Training loss: 0.2519987225532532
Validation loss: 1.4930592429253362

Epoch: 5| Step: 2
Training loss: 0.12080752849578857
Validation loss: 1.5143343889585106

Epoch: 5| Step: 3
Training loss: 0.2443506270647049
Validation loss: 1.5069797115941201

Epoch: 5| Step: 4
Training loss: 0.1361543983221054
Validation loss: 1.5172299313288864

Epoch: 5| Step: 5
Training loss: 0.32708606123924255
Validation loss: 1.511527669045233

Epoch: 5| Step: 6
Training loss: 0.17526762187480927
Validation loss: 1.4966183554741643

Epoch: 5| Step: 7
Training loss: 0.20555344223976135
Validation loss: 1.5004896361340758

Epoch: 5| Step: 8
Training loss: 0.19607123732566833
Validation loss: 1.5463334283521097

Epoch: 5| Step: 9
Training loss: 0.20368671417236328
Validation loss: 1.5359577965992752

Epoch: 5| Step: 10
Training loss: 0.10644280165433884
Validation loss: 1.5251891869370655

Epoch: 394| Step: 0
Training loss: 0.26895231008529663
Validation loss: 1.5504859403897358

Epoch: 5| Step: 1
Training loss: 0.20714564621448517
Validation loss: 1.5611970642561555

Epoch: 5| Step: 2
Training loss: 0.19315242767333984
Validation loss: 1.571673092021737

Epoch: 5| Step: 3
Training loss: 0.166932612657547
Validation loss: 1.5730946871542162

Epoch: 5| Step: 4
Training loss: 0.20937983691692352
Validation loss: 1.5625243161314277

Epoch: 5| Step: 5
Training loss: 0.17611141502857208
Validation loss: 1.5684111772045013

Epoch: 5| Step: 6
Training loss: 0.16753742098808289
Validation loss: 1.552785873413086

Epoch: 5| Step: 7
Training loss: 0.19678924977779388
Validation loss: 1.5464628409313899

Epoch: 5| Step: 8
Training loss: 0.21014735102653503
Validation loss: 1.5435329509037796

Epoch: 5| Step: 9
Training loss: 0.20727117359638214
Validation loss: 1.5439849335660216

Epoch: 5| Step: 10
Training loss: 0.19369547069072723
Validation loss: 1.5419869307548768

Epoch: 395| Step: 0
Training loss: 0.2499733865261078
Validation loss: 1.5209904050314298

Epoch: 5| Step: 1
Training loss: 0.13597266376018524
Validation loss: 1.4894637933341406

Epoch: 5| Step: 2
Training loss: 0.2741924822330475
Validation loss: 1.5047888114888182

Epoch: 5| Step: 3
Training loss: 0.10659116506576538
Validation loss: 1.5395705366647372

Epoch: 5| Step: 4
Training loss: 0.22876694798469543
Validation loss: 1.5017068514259913

Epoch: 5| Step: 5
Training loss: 0.1690341830253601
Validation loss: 1.5305679767362532

Epoch: 5| Step: 6
Training loss: 0.18119436502456665
Validation loss: 1.5375850854381439

Epoch: 5| Step: 7
Training loss: 0.2744102478027344
Validation loss: 1.562311577540572

Epoch: 5| Step: 8
Training loss: 0.309034138917923
Validation loss: 1.5336340447907806

Epoch: 5| Step: 9
Training loss: 0.17069955170154572
Validation loss: 1.4975770916990054

Epoch: 5| Step: 10
Training loss: 0.12895822525024414
Validation loss: 1.517497189583317

Epoch: 396| Step: 0
Training loss: 0.2049751579761505
Validation loss: 1.505088642079343

Epoch: 5| Step: 1
Training loss: 0.15909245610237122
Validation loss: 1.5226877389415618

Epoch: 5| Step: 2
Training loss: 0.2213222235441208
Validation loss: 1.5166414232664212

Epoch: 5| Step: 3
Training loss: 0.16140516102313995
Validation loss: 1.4917247205652215

Epoch: 5| Step: 4
Training loss: 0.25457021594047546
Validation loss: 1.5122163308564054

Epoch: 5| Step: 5
Training loss: 0.11027791351079941
Validation loss: 1.5230702148970736

Epoch: 5| Step: 6
Training loss: 0.19374914467334747
Validation loss: 1.5100723479383735

Epoch: 5| Step: 7
Training loss: 0.22709746658802032
Validation loss: 1.537476776748575

Epoch: 5| Step: 8
Training loss: 0.24641311168670654
Validation loss: 1.5330568693017448

Epoch: 5| Step: 9
Training loss: 0.22631557285785675
Validation loss: 1.5238375522757088

Epoch: 5| Step: 10
Training loss: 0.24071550369262695
Validation loss: 1.5603788911655385

Epoch: 397| Step: 0
Training loss: 0.3357223868370056
Validation loss: 1.5601607215019964

Epoch: 5| Step: 1
Training loss: 0.2913786768913269
Validation loss: 1.5494402839291481

Epoch: 5| Step: 2
Training loss: 0.1680828332901001
Validation loss: 1.5666014673889324

Epoch: 5| Step: 3
Training loss: 0.16188304126262665
Validation loss: 1.5623173739320488

Epoch: 5| Step: 4
Training loss: 0.09876689314842224
Validation loss: 1.5334151496169388

Epoch: 5| Step: 5
Training loss: 0.12839239835739136
Validation loss: 1.5184680146555747

Epoch: 5| Step: 6
Training loss: 0.2466251403093338
Validation loss: 1.5274204618187361

Epoch: 5| Step: 7
Training loss: 0.1390746533870697
Validation loss: 1.516971536861953

Epoch: 5| Step: 8
Training loss: 0.2977125644683838
Validation loss: 1.5259849147130085

Epoch: 5| Step: 9
Training loss: 0.18374119699001312
Validation loss: 1.510681236943891

Epoch: 5| Step: 10
Training loss: 0.17824935913085938
Validation loss: 1.4981161227790258

Epoch: 398| Step: 0
Training loss: 0.26260918378829956
Validation loss: 1.5242196923942977

Epoch: 5| Step: 1
Training loss: 0.18244969844818115
Validation loss: 1.5219692607079782

Epoch: 5| Step: 2
Training loss: 0.21455290913581848
Validation loss: 1.5273616480570968

Epoch: 5| Step: 3
Training loss: 0.21120008826255798
Validation loss: 1.5059474437467513

Epoch: 5| Step: 4
Training loss: 0.15590523183345795
Validation loss: 1.5222455083682973

Epoch: 5| Step: 5
Training loss: 0.28314971923828125
Validation loss: 1.5222708986651512

Epoch: 5| Step: 6
Training loss: 0.2002285271883011
Validation loss: 1.5303028488671908

Epoch: 5| Step: 7
Training loss: 0.24804642796516418
Validation loss: 1.5391808530335784

Epoch: 5| Step: 8
Training loss: 0.21094460785388947
Validation loss: 1.5186613939141715

Epoch: 5| Step: 9
Training loss: 0.15464802086353302
Validation loss: 1.531732537413156

Epoch: 5| Step: 10
Training loss: 0.173118457198143
Validation loss: 1.5291332288454937

Epoch: 399| Step: 0
Training loss: 0.14298564195632935
Validation loss: 1.5554059000425442

Epoch: 5| Step: 1
Training loss: 0.13892480731010437
Validation loss: 1.5257076268555017

Epoch: 5| Step: 2
Training loss: 0.4502261281013489
Validation loss: 1.532666330696434

Epoch: 5| Step: 3
Training loss: 0.13877911865711212
Validation loss: 1.5402265402578539

Epoch: 5| Step: 4
Training loss: 0.27308279275894165
Validation loss: 1.506734235312349

Epoch: 5| Step: 5
Training loss: 0.11200498044490814
Validation loss: 1.5148200309404762

Epoch: 5| Step: 6
Training loss: 0.20499281585216522
Validation loss: 1.51256723173203

Epoch: 5| Step: 7
Training loss: 0.14281848073005676
Validation loss: 1.507623436630413

Epoch: 5| Step: 8
Training loss: 0.2702938914299011
Validation loss: 1.5253712541313582

Epoch: 5| Step: 9
Training loss: 0.34867146611213684
Validation loss: 1.4946931267297396

Epoch: 5| Step: 10
Training loss: 0.141903817653656
Validation loss: 1.518227252268022

Epoch: 400| Step: 0
Training loss: 0.13270094990730286
Validation loss: 1.4941129171720116

Epoch: 5| Step: 1
Training loss: 0.16482731699943542
Validation loss: 1.5202291678356867

Epoch: 5| Step: 2
Training loss: 0.20279236137866974
Validation loss: 1.4881982546980663

Epoch: 5| Step: 3
Training loss: 0.2864686846733093
Validation loss: 1.5006852226872598

Epoch: 5| Step: 4
Training loss: 0.18529827892780304
Validation loss: 1.5276830542472102

Epoch: 5| Step: 5
Training loss: 0.22778365015983582
Validation loss: 1.5275035558208343

Epoch: 5| Step: 6
Training loss: 0.24716000258922577
Validation loss: 1.525594715149172

Epoch: 5| Step: 7
Training loss: 0.17623765766620636
Validation loss: 1.533599768915484

Epoch: 5| Step: 8
Training loss: 0.1727500855922699
Validation loss: 1.5163017229367328

Epoch: 5| Step: 9
Training loss: 0.20374222099781036
Validation loss: 1.4907369421374412

Epoch: 5| Step: 10
Training loss: 0.17957286536693573
Validation loss: 1.4920835392449492

Epoch: 401| Step: 0
Training loss: 0.15063050389289856
Validation loss: 1.4903188187588927

Epoch: 5| Step: 1
Training loss: 0.12257268279790878
Validation loss: 1.4804027144626906

Epoch: 5| Step: 2
Training loss: 0.2611690163612366
Validation loss: 1.4815411567687988

Epoch: 5| Step: 3
Training loss: 0.19568054378032684
Validation loss: 1.4806720954115673

Epoch: 5| Step: 4
Training loss: 0.21712276339530945
Validation loss: 1.4614280276401068

Epoch: 5| Step: 5
Training loss: 0.18206970393657684
Validation loss: 1.4537553441139959

Epoch: 5| Step: 6
Training loss: 0.18702225387096405
Validation loss: 1.4836840084804002

Epoch: 5| Step: 7
Training loss: 0.20931723713874817
Validation loss: 1.4599330476535264

Epoch: 5| Step: 8
Training loss: 0.1913992464542389
Validation loss: 1.495017760543413

Epoch: 5| Step: 9
Training loss: 0.20929975807666779
Validation loss: 1.499363887694574

Epoch: 5| Step: 10
Training loss: 0.23876705765724182
Validation loss: 1.5260895990556287

Epoch: 402| Step: 0
Training loss: 0.35703036189079285
Validation loss: 1.501805047835073

Epoch: 5| Step: 1
Training loss: 0.20878532528877258
Validation loss: 1.4815560771572975

Epoch: 5| Step: 2
Training loss: 0.13840720057487488
Validation loss: 1.486076307553117

Epoch: 5| Step: 3
Training loss: 0.17464902997016907
Validation loss: 1.461503263442747

Epoch: 5| Step: 4
Training loss: 0.09391561895608902
Validation loss: 1.4651122541837795

Epoch: 5| Step: 5
Training loss: 0.23203866183757782
Validation loss: 1.4678933043633737

Epoch: 5| Step: 6
Training loss: 0.1538587063550949
Validation loss: 1.4748331526274323

Epoch: 5| Step: 7
Training loss: 0.2436593770980835
Validation loss: 1.5119605782211467

Epoch: 5| Step: 8
Training loss: 0.240746408700943
Validation loss: 1.4789297247445712

Epoch: 5| Step: 9
Training loss: 0.2054096758365631
Validation loss: 1.48471745111609

Epoch: 5| Step: 10
Training loss: 0.17134989798069
Validation loss: 1.4953829831974481

Epoch: 403| Step: 0
Training loss: 0.19015099108219147
Validation loss: 1.484310774392979

Epoch: 5| Step: 1
Training loss: 0.2265883982181549
Validation loss: 1.5119082645703388

Epoch: 5| Step: 2
Training loss: 0.19544851779937744
Validation loss: 1.5033118878641436

Epoch: 5| Step: 3
Training loss: 0.15883895754814148
Validation loss: 1.4982619971357367

Epoch: 5| Step: 4
Training loss: 0.30507415533065796
Validation loss: 1.5040707158785995

Epoch: 5| Step: 5
Training loss: 0.18282470107078552
Validation loss: 1.5157672615461453

Epoch: 5| Step: 6
Training loss: 0.22552832961082458
Validation loss: 1.5241153586295344

Epoch: 5| Step: 7
Training loss: 0.13656237721443176
Validation loss: 1.5440162535636657

Epoch: 5| Step: 8
Training loss: 0.12787660956382751
Validation loss: 1.5430792018931399

Epoch: 5| Step: 9
Training loss: 0.14827904105186462
Validation loss: 1.526131078761111

Epoch: 5| Step: 10
Training loss: 0.19354207813739777
Validation loss: 1.520967306629304

Epoch: 404| Step: 0
Training loss: 0.20963755249977112
Validation loss: 1.5303339086553103

Epoch: 5| Step: 1
Training loss: 0.2566693127155304
Validation loss: 1.528252649050887

Epoch: 5| Step: 2
Training loss: 0.16526737809181213
Validation loss: 1.499041385548089

Epoch: 5| Step: 3
Training loss: 0.2476908266544342
Validation loss: 1.5012980443175121

Epoch: 5| Step: 4
Training loss: 0.13841116428375244
Validation loss: 1.5014233076444237

Epoch: 5| Step: 5
Training loss: 0.10339327156543732
Validation loss: 1.5023036253067754

Epoch: 5| Step: 6
Training loss: 0.17007990181446075
Validation loss: 1.5047514771902433

Epoch: 5| Step: 7
Training loss: 0.28902196884155273
Validation loss: 1.5074467312905095

Epoch: 5| Step: 8
Training loss: 0.19394460320472717
Validation loss: 1.4747367648668186

Epoch: 5| Step: 9
Training loss: 0.14819121360778809
Validation loss: 1.4982402286221903

Epoch: 5| Step: 10
Training loss: 0.17292693257331848
Validation loss: 1.4858886746950046

Epoch: 405| Step: 0
Training loss: 0.18713347613811493
Validation loss: 1.4804353867807696

Epoch: 5| Step: 1
Training loss: 0.1654559224843979
Validation loss: 1.4793775504635227

Epoch: 5| Step: 2
Training loss: 0.14584150910377502
Validation loss: 1.4345987009745773

Epoch: 5| Step: 3
Training loss: 0.21266674995422363
Validation loss: 1.4835509343813824

Epoch: 5| Step: 4
Training loss: 0.0822053924202919
Validation loss: 1.48314667260775

Epoch: 5| Step: 5
Training loss: 0.1391124427318573
Validation loss: 1.4748971782704836

Epoch: 5| Step: 6
Training loss: 0.18155071139335632
Validation loss: 1.4771171846697408

Epoch: 5| Step: 7
Training loss: 0.18216779828071594
Validation loss: 1.4868635580103884

Epoch: 5| Step: 8
Training loss: 0.16720004379749298
Validation loss: 1.498938811081712

Epoch: 5| Step: 9
Training loss: 0.2815327048301697
Validation loss: 1.468480521632779

Epoch: 5| Step: 10
Training loss: 0.15088023245334625
Validation loss: 1.5010286492686118

Epoch: 406| Step: 0
Training loss: 0.19467121362686157
Validation loss: 1.4752139788801952

Epoch: 5| Step: 1
Training loss: 0.22739958763122559
Validation loss: 1.4790388871264715

Epoch: 5| Step: 2
Training loss: 0.14833612740039825
Validation loss: 1.4537440525588168

Epoch: 5| Step: 3
Training loss: 0.18689937889575958
Validation loss: 1.485128462955516

Epoch: 5| Step: 4
Training loss: 0.14973315596580505
Validation loss: 1.5033756661158737

Epoch: 5| Step: 5
Training loss: 0.19603170454502106
Validation loss: 1.4787717852541196

Epoch: 5| Step: 6
Training loss: 0.2582661211490631
Validation loss: 1.4693914754416353

Epoch: 5| Step: 7
Training loss: 0.1568090170621872
Validation loss: 1.5023102401405253

Epoch: 5| Step: 8
Training loss: 0.0784536749124527
Validation loss: 1.5054205412505774

Epoch: 5| Step: 9
Training loss: 0.24861383438110352
Validation loss: 1.5368318903830744

Epoch: 5| Step: 10
Training loss: 0.15318559110164642
Validation loss: 1.5198538072647587

Epoch: 407| Step: 0
Training loss: 0.12298133224248886
Validation loss: 1.5361535254345144

Epoch: 5| Step: 1
Training loss: 0.11266420036554337
Validation loss: 1.5287695738577074

Epoch: 5| Step: 2
Training loss: 0.1575627475976944
Validation loss: 1.4963813943247641

Epoch: 5| Step: 3
Training loss: 0.18146401643753052
Validation loss: 1.5172659709889402

Epoch: 5| Step: 4
Training loss: 0.18321962654590607
Validation loss: 1.5012798309326172

Epoch: 5| Step: 5
Training loss: 0.1856001317501068
Validation loss: 1.485574919690368

Epoch: 5| Step: 6
Training loss: 0.2005171775817871
Validation loss: 1.4953235759530017

Epoch: 5| Step: 7
Training loss: 0.1588107943534851
Validation loss: 1.4723510267913982

Epoch: 5| Step: 8
Training loss: 0.1751881241798401
Validation loss: 1.4609747843075824

Epoch: 5| Step: 9
Training loss: 0.28772109746932983
Validation loss: 1.4840468052894837

Epoch: 5| Step: 10
Training loss: 0.1979435682296753
Validation loss: 1.488065593345191

Epoch: 408| Step: 0
Training loss: 0.09965508431196213
Validation loss: 1.4688711076654413

Epoch: 5| Step: 1
Training loss: 0.25406593084335327
Validation loss: 1.4565806247854745

Epoch: 5| Step: 2
Training loss: 0.22120237350463867
Validation loss: 1.4509193833156298

Epoch: 5| Step: 3
Training loss: 0.14226382970809937
Validation loss: 1.462155967630366

Epoch: 5| Step: 4
Training loss: 0.15503564476966858
Validation loss: 1.4462786207916916

Epoch: 5| Step: 5
Training loss: 0.23702339828014374
Validation loss: 1.4397948954695015

Epoch: 5| Step: 6
Training loss: 0.18187452852725983
Validation loss: 1.4505862933333202

Epoch: 5| Step: 7
Training loss: 0.13304874300956726
Validation loss: 1.4359269577969787

Epoch: 5| Step: 8
Training loss: 0.2787880003452301
Validation loss: 1.447308219889159

Epoch: 5| Step: 9
Training loss: 0.18779167532920837
Validation loss: 1.440956381059462

Epoch: 5| Step: 10
Training loss: 0.2687425911426544
Validation loss: 1.4447638924403856

Epoch: 409| Step: 0
Training loss: 0.11641915142536163
Validation loss: 1.451704364950939

Epoch: 5| Step: 1
Training loss: 0.1987769901752472
Validation loss: 1.4513527424104753

Epoch: 5| Step: 2
Training loss: 0.1429760754108429
Validation loss: 1.4271070162455242

Epoch: 5| Step: 3
Training loss: 0.20715181529521942
Validation loss: 1.4295908340843775

Epoch: 5| Step: 4
Training loss: 0.13561072945594788
Validation loss: 1.455559019119509

Epoch: 5| Step: 5
Training loss: 0.18834662437438965
Validation loss: 1.4739537072438065

Epoch: 5| Step: 6
Training loss: 0.21416644752025604
Validation loss: 1.4705543197611326

Epoch: 5| Step: 7
Training loss: 0.1481344848871231
Validation loss: 1.469154275873656

Epoch: 5| Step: 8
Training loss: 0.2288966178894043
Validation loss: 1.474515357325154

Epoch: 5| Step: 9
Training loss: 0.1320226490497589
Validation loss: 1.4657576084136963

Epoch: 5| Step: 10
Training loss: 0.26936185359954834
Validation loss: 1.4772217953076927

Epoch: 410| Step: 0
Training loss: 0.20202907919883728
Validation loss: 1.4672764655082458

Epoch: 5| Step: 1
Training loss: 0.1713489592075348
Validation loss: 1.469769106116346

Epoch: 5| Step: 2
Training loss: 0.24220041930675507
Validation loss: 1.4462061364163634

Epoch: 5| Step: 3
Training loss: 0.16658943891525269
Validation loss: 1.4642087644146335

Epoch: 5| Step: 4
Training loss: 0.12571683526039124
Validation loss: 1.4385283749590638

Epoch: 5| Step: 5
Training loss: 0.2340584695339203
Validation loss: 1.4577826569157262

Epoch: 5| Step: 6
Training loss: 0.2652595043182373
Validation loss: 1.470527066979357

Epoch: 5| Step: 7
Training loss: 0.1959644854068756
Validation loss: 1.4549480381832327

Epoch: 5| Step: 8
Training loss: 0.20704197883605957
Validation loss: 1.456013374431159

Epoch: 5| Step: 9
Training loss: 0.20153279602527618
Validation loss: 1.4739869666355911

Epoch: 5| Step: 10
Training loss: 0.10123957693576813
Validation loss: 1.4659012709894488

Epoch: 411| Step: 0
Training loss: 0.14201989769935608
Validation loss: 1.454150572258939

Epoch: 5| Step: 1
Training loss: 0.2078239917755127
Validation loss: 1.465335262719021

Epoch: 5| Step: 2
Training loss: 0.26033931970596313
Validation loss: 1.4716442554227767

Epoch: 5| Step: 3
Training loss: 0.19087082147598267
Validation loss: 1.4667664612493208

Epoch: 5| Step: 4
Training loss: 0.3040834367275238
Validation loss: 1.4893085597663798

Epoch: 5| Step: 5
Training loss: 0.10688011348247528
Validation loss: 1.461159542042722

Epoch: 5| Step: 6
Training loss: 0.19716665148735046
Validation loss: 1.490354662300438

Epoch: 5| Step: 7
Training loss: 0.18463748693466187
Validation loss: 1.4785153519722722

Epoch: 5| Step: 8
Training loss: 0.15923413634300232
Validation loss: 1.4723255403580204

Epoch: 5| Step: 9
Training loss: 0.16755184531211853
Validation loss: 1.456765547875435

Epoch: 5| Step: 10
Training loss: 0.1515526920557022
Validation loss: 1.4728056397489322

Epoch: 412| Step: 0
Training loss: 0.15977293252944946
Validation loss: 1.5125594241644746

Epoch: 5| Step: 1
Training loss: 0.18901434540748596
Validation loss: 1.4761279975214312

Epoch: 5| Step: 2
Training loss: 0.09508738666772842
Validation loss: 1.478032240303614

Epoch: 5| Step: 3
Training loss: 0.1441234052181244
Validation loss: 1.4832833838719193

Epoch: 5| Step: 4
Training loss: 0.27537113428115845
Validation loss: 1.4985201909977903

Epoch: 5| Step: 5
Training loss: 0.1414201706647873
Validation loss: 1.4830687533142746

Epoch: 5| Step: 6
Training loss: 0.2115602046251297
Validation loss: 1.4965196412096742

Epoch: 5| Step: 7
Training loss: 0.18204964697360992
Validation loss: 1.4696170463356921

Epoch: 5| Step: 8
Training loss: 0.1947246640920639
Validation loss: 1.4776336275121218

Epoch: 5| Step: 9
Training loss: 0.24416808784008026
Validation loss: 1.4635232738269273

Epoch: 5| Step: 10
Training loss: 0.1614016443490982
Validation loss: 1.4491249976619598

Epoch: 413| Step: 0
Training loss: 0.21882669627666473
Validation loss: 1.4594478940451017

Epoch: 5| Step: 1
Training loss: 0.17090710997581482
Validation loss: 1.450160736678749

Epoch: 5| Step: 2
Training loss: 0.17259453237056732
Validation loss: 1.458409567033091

Epoch: 5| Step: 3
Training loss: 0.16356050968170166
Validation loss: 1.476589431044876

Epoch: 5| Step: 4
Training loss: 0.21163861453533173
Validation loss: 1.4720840864284064

Epoch: 5| Step: 5
Training loss: 0.11613540351390839
Validation loss: 1.5025662183761597

Epoch: 5| Step: 6
Training loss: 0.2542242109775543
Validation loss: 1.4944652665045954

Epoch: 5| Step: 7
Training loss: 0.25148454308509827
Validation loss: 1.5101354750253821

Epoch: 5| Step: 8
Training loss: 0.22728975117206573
Validation loss: 1.5258581728063605

Epoch: 5| Step: 9
Training loss: 0.18220117688179016
Validation loss: 1.5146802702257711

Epoch: 5| Step: 10
Training loss: 0.14827914535999298
Validation loss: 1.5244807081837808

Epoch: 414| Step: 0
Training loss: 0.16395720839500427
Validation loss: 1.5346990170017365

Epoch: 5| Step: 1
Training loss: 0.21873410046100616
Validation loss: 1.5042968885872954

Epoch: 5| Step: 2
Training loss: 0.17894068360328674
Validation loss: 1.4936347840934672

Epoch: 5| Step: 3
Training loss: 0.21518048644065857
Validation loss: 1.481343860267311

Epoch: 5| Step: 4
Training loss: 0.17657789587974548
Validation loss: 1.4729261141951366

Epoch: 5| Step: 5
Training loss: 0.1614890992641449
Validation loss: 1.4578940637650029

Epoch: 5| Step: 6
Training loss: 0.22270646691322327
Validation loss: 1.4778625170389812

Epoch: 5| Step: 7
Training loss: 0.2222682535648346
Validation loss: 1.4504496833329559

Epoch: 5| Step: 8
Training loss: 0.20197072625160217
Validation loss: 1.463923333793558

Epoch: 5| Step: 9
Training loss: 0.20778663456439972
Validation loss: 1.4421790312695246

Epoch: 5| Step: 10
Training loss: 0.17754052579402924
Validation loss: 1.4479896009609263

Epoch: 415| Step: 0
Training loss: 0.09122955799102783
Validation loss: 1.4886440769318612

Epoch: 5| Step: 1
Training loss: 0.13178077340126038
Validation loss: 1.4781049438702163

Epoch: 5| Step: 2
Training loss: 0.10661715269088745
Validation loss: 1.4663961843777729

Epoch: 5| Step: 3
Training loss: 0.2598455250263214
Validation loss: 1.498693102149553

Epoch: 5| Step: 4
Training loss: 0.16986003518104553
Validation loss: 1.473949247790921

Epoch: 5| Step: 5
Training loss: 0.27353429794311523
Validation loss: 1.497138105412965

Epoch: 5| Step: 6
Training loss: 0.18399915099143982
Validation loss: 1.4685091292986305

Epoch: 5| Step: 7
Training loss: 0.20399613678455353
Validation loss: 1.468468810922356

Epoch: 5| Step: 8
Training loss: 0.19328710436820984
Validation loss: 1.4676493316568353

Epoch: 5| Step: 9
Training loss: 0.23782646656036377
Validation loss: 1.4900745076517905

Epoch: 5| Step: 10
Training loss: 0.15220485627651215
Validation loss: 1.4788194087243849

Epoch: 416| Step: 0
Training loss: 0.17523446679115295
Validation loss: 1.4746844678796747

Epoch: 5| Step: 1
Training loss: 0.1296062171459198
Validation loss: 1.490479689772411

Epoch: 5| Step: 2
Training loss: 0.11872086673974991
Validation loss: 1.472563055253798

Epoch: 5| Step: 3
Training loss: 0.1414782553911209
Validation loss: 1.4521325608735443

Epoch: 5| Step: 4
Training loss: 0.12070057541131973
Validation loss: 1.4757165972904494

Epoch: 5| Step: 5
Training loss: 0.13419213891029358
Validation loss: 1.5029777275618685

Epoch: 5| Step: 6
Training loss: 0.10411103069782257
Validation loss: 1.4843990700219267

Epoch: 5| Step: 7
Training loss: 0.3438824713230133
Validation loss: 1.4724836221305273

Epoch: 5| Step: 8
Training loss: 0.21619300544261932
Validation loss: 1.463560140261086

Epoch: 5| Step: 9
Training loss: 0.19113431870937347
Validation loss: 1.4411191837761992

Epoch: 5| Step: 10
Training loss: 0.2492443323135376
Validation loss: 1.4606879167659308

Epoch: 417| Step: 0
Training loss: 0.2004266083240509
Validation loss: 1.4633722356570664

Epoch: 5| Step: 1
Training loss: 0.16204805672168732
Validation loss: 1.4358741070634575

Epoch: 5| Step: 2
Training loss: 0.18736431002616882
Validation loss: 1.4641252038299397

Epoch: 5| Step: 3
Training loss: 0.26768267154693604
Validation loss: 1.4683728141169394

Epoch: 5| Step: 4
Training loss: 0.14169654250144958
Validation loss: 1.4806868581361667

Epoch: 5| Step: 5
Training loss: 0.24949805438518524
Validation loss: 1.4678005005723687

Epoch: 5| Step: 6
Training loss: 0.17268522083759308
Validation loss: 1.4861394884765788

Epoch: 5| Step: 7
Training loss: 0.1836075484752655
Validation loss: 1.4540163804126043

Epoch: 5| Step: 8
Training loss: 0.17112699151039124
Validation loss: 1.5005766191790182

Epoch: 5| Step: 9
Training loss: 0.1646852195262909
Validation loss: 1.4964171994117

Epoch: 5| Step: 10
Training loss: 0.17499591410160065
Validation loss: 1.4843933889942784

Epoch: 418| Step: 0
Training loss: 0.21015694737434387
Validation loss: 1.494571121790076

Epoch: 5| Step: 1
Training loss: 0.2091454565525055
Validation loss: 1.4828014899325628

Epoch: 5| Step: 2
Training loss: 0.09123661369085312
Validation loss: 1.4424989479844288

Epoch: 5| Step: 3
Training loss: 0.16935445368289948
Validation loss: 1.4368590360046716

Epoch: 5| Step: 4
Training loss: 0.1818799525499344
Validation loss: 1.4298896872869102

Epoch: 5| Step: 5
Training loss: 0.136705681681633
Validation loss: 1.4333410032333866

Epoch: 5| Step: 6
Training loss: 0.13470646739006042
Validation loss: 1.4192691015940841

Epoch: 5| Step: 7
Training loss: 0.2173270881175995
Validation loss: 1.427038409376657

Epoch: 5| Step: 8
Training loss: 0.22313761711120605
Validation loss: 1.4244102752336891

Epoch: 5| Step: 9
Training loss: 0.11902399361133575
Validation loss: 1.416981509936753

Epoch: 5| Step: 10
Training loss: 0.17649900913238525
Validation loss: 1.4033935095674248

Epoch: 419| Step: 0
Training loss: 0.3077794015407562
Validation loss: 1.4175302315783758

Epoch: 5| Step: 1
Training loss: 0.18477098643779755
Validation loss: 1.470660804420389

Epoch: 5| Step: 2
Training loss: 0.2646545171737671
Validation loss: 1.4428130913806219

Epoch: 5| Step: 3
Training loss: 0.12017320096492767
Validation loss: 1.4413102467854817

Epoch: 5| Step: 4
Training loss: 0.1075119599699974
Validation loss: 1.4644968208446298

Epoch: 5| Step: 5
Training loss: 0.19678157567977905
Validation loss: 1.4659413471016833

Epoch: 5| Step: 6
Training loss: 0.17631608247756958
Validation loss: 1.4744566755910073

Epoch: 5| Step: 7
Training loss: 0.13139839470386505
Validation loss: 1.469895101362659

Epoch: 5| Step: 8
Training loss: 0.20252713561058044
Validation loss: 1.470892595988448

Epoch: 5| Step: 9
Training loss: 0.13116946816444397
Validation loss: 1.481709171366948

Epoch: 5| Step: 10
Training loss: 0.20684874057769775
Validation loss: 1.5032546084414247

Epoch: 420| Step: 0
Training loss: 0.19563713669776917
Validation loss: 1.496433356756805

Epoch: 5| Step: 1
Training loss: 0.1170939952135086
Validation loss: 1.4872556835092523

Epoch: 5| Step: 2
Training loss: 0.319030225276947
Validation loss: 1.4986930303676154

Epoch: 5| Step: 3
Training loss: 0.10427477210760117
Validation loss: 1.496693362471878

Epoch: 5| Step: 4
Training loss: 0.12273333221673965
Validation loss: 1.4810369565922727

Epoch: 5| Step: 5
Training loss: 0.12591350078582764
Validation loss: 1.4705433460973925

Epoch: 5| Step: 6
Training loss: 0.18264994025230408
Validation loss: 1.4814400544730566

Epoch: 5| Step: 7
Training loss: 0.12376949936151505
Validation loss: 1.4781903605307303

Epoch: 5| Step: 8
Training loss: 0.16967765986919403
Validation loss: 1.4645126827301518

Epoch: 5| Step: 9
Training loss: 0.24823930859565735
Validation loss: 1.458815977137576

Epoch: 5| Step: 10
Training loss: 0.21769776940345764
Validation loss: 1.4744581227661462

Epoch: 421| Step: 0
Training loss: 0.20477087795734406
Validation loss: 1.4806889898033553

Epoch: 5| Step: 1
Training loss: 0.18907883763313293
Validation loss: 1.4984507817094044

Epoch: 5| Step: 2
Training loss: 0.10227581113576889
Validation loss: 1.446346297699918

Epoch: 5| Step: 3
Training loss: 0.3324372470378876
Validation loss: 1.4784200076133973

Epoch: 5| Step: 4
Training loss: 0.10586613416671753
Validation loss: 1.467394446813932

Epoch: 5| Step: 5
Training loss: 0.13921990990638733
Validation loss: 1.473384109876489

Epoch: 5| Step: 6
Training loss: 0.18026211857795715
Validation loss: 1.4608126494192308

Epoch: 5| Step: 7
Training loss: 0.08817611634731293
Validation loss: 1.4707459044712845

Epoch: 5| Step: 8
Training loss: 0.13870997726917267
Validation loss: 1.4484529354239022

Epoch: 5| Step: 9
Training loss: 0.1053939238190651
Validation loss: 1.4317649974617908

Epoch: 5| Step: 10
Training loss: 0.16572526097297668
Validation loss: 1.4437882964329054

Epoch: 422| Step: 0
Training loss: 0.20247845351696014
Validation loss: 1.4345322770457114

Epoch: 5| Step: 1
Training loss: 0.1745598167181015
Validation loss: 1.435368222575034

Epoch: 5| Step: 2
Training loss: 0.1421189308166504
Validation loss: 1.4244238868836434

Epoch: 5| Step: 3
Training loss: 0.11121542751789093
Validation loss: 1.4394455725146877

Epoch: 5| Step: 4
Training loss: 0.20897884666919708
Validation loss: 1.4294820036939395

Epoch: 5| Step: 5
Training loss: 0.28055936098098755
Validation loss: 1.4341455146830568

Epoch: 5| Step: 6
Training loss: 0.16517508029937744
Validation loss: 1.432246119745316

Epoch: 5| Step: 7
Training loss: 0.17912155389785767
Validation loss: 1.4209218255935177

Epoch: 5| Step: 8
Training loss: 0.21106906235218048
Validation loss: 1.4280255789397864

Epoch: 5| Step: 9
Training loss: 0.17032071948051453
Validation loss: 1.436797518883982

Epoch: 5| Step: 10
Training loss: 0.15273065865039825
Validation loss: 1.478696571883335

Epoch: 423| Step: 0
Training loss: 0.12997424602508545
Validation loss: 1.4655804634094238

Epoch: 5| Step: 1
Training loss: 0.18691107630729675
Validation loss: 1.4827049586080736

Epoch: 5| Step: 2
Training loss: 0.14331980049610138
Validation loss: 1.4769227408593701

Epoch: 5| Step: 3
Training loss: 0.17041859030723572
Validation loss: 1.4845410393130394

Epoch: 5| Step: 4
Training loss: 0.1425812989473343
Validation loss: 1.5022881389946066

Epoch: 5| Step: 5
Training loss: 0.13918332755565643
Validation loss: 1.4842387360911216

Epoch: 5| Step: 6
Training loss: 0.13579875230789185
Validation loss: 1.4580800879386164

Epoch: 5| Step: 7
Training loss: 0.18439176678657532
Validation loss: 1.4657522093865178

Epoch: 5| Step: 8
Training loss: 0.12483855336904526
Validation loss: 1.4481915773883942

Epoch: 5| Step: 9
Training loss: 0.24458375573158264
Validation loss: 1.4660457936666345

Epoch: 5| Step: 10
Training loss: 0.2095196396112442
Validation loss: 1.4682691930442728

Epoch: 424| Step: 0
Training loss: 0.14792919158935547
Validation loss: 1.4535251355940295

Epoch: 5| Step: 1
Training loss: 0.1645500510931015
Validation loss: 1.4723973222958144

Epoch: 5| Step: 2
Training loss: 0.12121675163507462
Validation loss: 1.449705364883587

Epoch: 5| Step: 3
Training loss: 0.24151811003684998
Validation loss: 1.4605958090033582

Epoch: 5| Step: 4
Training loss: 0.1262574940919876
Validation loss: 1.4498117380244757

Epoch: 5| Step: 5
Training loss: 0.13503775000572205
Validation loss: 1.4531483701480332

Epoch: 5| Step: 6
Training loss: 0.10130064189434052
Validation loss: 1.4533034793792232

Epoch: 5| Step: 7
Training loss: 0.10106978565454483
Validation loss: 1.469414641780238

Epoch: 5| Step: 8
Training loss: 0.1533403843641281
Validation loss: 1.4661478457912323

Epoch: 5| Step: 9
Training loss: 0.26859405636787415
Validation loss: 1.440246347458132

Epoch: 5| Step: 10
Training loss: 0.15709882974624634
Validation loss: 1.4504257940476941

Epoch: 425| Step: 0
Training loss: 0.0957111120223999
Validation loss: 1.4657829346195344

Epoch: 5| Step: 1
Training loss: 0.14872634410858154
Validation loss: 1.4304918794221775

Epoch: 5| Step: 2
Training loss: 0.17670777440071106
Validation loss: 1.469809534729168

Epoch: 5| Step: 3
Training loss: 0.13090266287326813
Validation loss: 1.4450072344913278

Epoch: 5| Step: 4
Training loss: 0.15581466257572174
Validation loss: 1.4608017424101472

Epoch: 5| Step: 5
Training loss: 0.180562362074852
Validation loss: 1.444552013950963

Epoch: 5| Step: 6
Training loss: 0.08903267979621887
Validation loss: 1.4355939357511458

Epoch: 5| Step: 7
Training loss: 0.18780715763568878
Validation loss: 1.4467476862733082

Epoch: 5| Step: 8
Training loss: 0.16156238317489624
Validation loss: 1.418943852506658

Epoch: 5| Step: 9
Training loss: 0.2461598664522171
Validation loss: 1.4483534482217604

Epoch: 5| Step: 10
Training loss: 0.17805051803588867
Validation loss: 1.4380138176743702

Epoch: 426| Step: 0
Training loss: 0.1506306529045105
Validation loss: 1.439676441172118

Epoch: 5| Step: 1
Training loss: 0.08877173811197281
Validation loss: 1.4608250125761955

Epoch: 5| Step: 2
Training loss: 0.24562768638134003
Validation loss: 1.4407822688420613

Epoch: 5| Step: 3
Training loss: 0.16272149980068207
Validation loss: 1.4552168294947634

Epoch: 5| Step: 4
Training loss: 0.17381179332733154
Validation loss: 1.4620830781998173

Epoch: 5| Step: 5
Training loss: 0.10541768372058868
Validation loss: 1.442799764294778

Epoch: 5| Step: 6
Training loss: 0.1621764600276947
Validation loss: 1.4747254322933894

Epoch: 5| Step: 7
Training loss: 0.08103542774915695
Validation loss: 1.4783380877587102

Epoch: 5| Step: 8
Training loss: 0.1963672786951065
Validation loss: 1.4520022253836355

Epoch: 5| Step: 9
Training loss: 0.24055397510528564
Validation loss: 1.48818289977248

Epoch: 5| Step: 10
Training loss: 0.1214708685874939
Validation loss: 1.4866746689683648

Epoch: 427| Step: 0
Training loss: 0.08248342573642731
Validation loss: 1.4916193792896886

Epoch: 5| Step: 1
Training loss: 0.06811010837554932
Validation loss: 1.4627308794247207

Epoch: 5| Step: 2
Training loss: 0.07032682001590729
Validation loss: 1.430940334514905

Epoch: 5| Step: 3
Training loss: 0.19218377768993378
Validation loss: 1.4271064740355297

Epoch: 5| Step: 4
Training loss: 0.14116376638412476
Validation loss: 1.4331418686015631

Epoch: 5| Step: 5
Training loss: 0.22692808508872986
Validation loss: 1.4326580416771673

Epoch: 5| Step: 6
Training loss: 0.28018298745155334
Validation loss: 1.4439200457706247

Epoch: 5| Step: 7
Training loss: 0.1592463105916977
Validation loss: 1.4368827842896985

Epoch: 5| Step: 8
Training loss: 0.17909333109855652
Validation loss: 1.4539883482840754

Epoch: 5| Step: 9
Training loss: 0.195515438914299
Validation loss: 1.4783565113621373

Epoch: 5| Step: 10
Training loss: 0.21137869358062744
Validation loss: 1.4733895012127456

Epoch: 428| Step: 0
Training loss: 0.1429312527179718
Validation loss: 1.4764274025476107

Epoch: 5| Step: 1
Training loss: 0.1662641316652298
Validation loss: 1.4790736616298716

Epoch: 5| Step: 2
Training loss: 0.20161128044128418
Validation loss: 1.498587030236439

Epoch: 5| Step: 3
Training loss: 0.14086732268333435
Validation loss: 1.4929932919881677

Epoch: 5| Step: 4
Training loss: 0.1976221799850464
Validation loss: 1.493005999954798

Epoch: 5| Step: 5
Training loss: 0.10282242298126221
Validation loss: 1.526728973593763

Epoch: 5| Step: 6
Training loss: 0.1429397612810135
Validation loss: 1.5013764084026378

Epoch: 5| Step: 7
Training loss: 0.18853279948234558
Validation loss: 1.5152993599573772

Epoch: 5| Step: 8
Training loss: 0.11828949302434921
Validation loss: 1.4970123370488484

Epoch: 5| Step: 9
Training loss: 0.13002753257751465
Validation loss: 1.4788886001033168

Epoch: 5| Step: 10
Training loss: 0.19758498668670654
Validation loss: 1.4849109931658673

Epoch: 429| Step: 0
Training loss: 0.20220282673835754
Validation loss: 1.4754497248639342

Epoch: 5| Step: 1
Training loss: 0.09111201763153076
Validation loss: 1.4447237278825493

Epoch: 5| Step: 2
Training loss: 0.2150530368089676
Validation loss: 1.4498442962605467

Epoch: 5| Step: 3
Training loss: 0.1218661293387413
Validation loss: 1.434354245021779

Epoch: 5| Step: 4
Training loss: 0.1805151104927063
Validation loss: 1.4318605469119163

Epoch: 5| Step: 5
Training loss: 0.13394883275032043
Validation loss: 1.4211217767448836

Epoch: 5| Step: 6
Training loss: 0.1333620399236679
Validation loss: 1.4119466453470209

Epoch: 5| Step: 7
Training loss: 0.2070905864238739
Validation loss: 1.4153543223616898

Epoch: 5| Step: 8
Training loss: 0.12397390604019165
Validation loss: 1.4313112202511038

Epoch: 5| Step: 9
Training loss: 0.13512861728668213
Validation loss: 1.4392756364678825

Epoch: 5| Step: 10
Training loss: 0.1459500938653946
Validation loss: 1.4339923858642578

Epoch: 430| Step: 0
Training loss: 0.08977620303630829
Validation loss: 1.4408117584002915

Epoch: 5| Step: 1
Training loss: 0.15459223091602325
Validation loss: 1.4506781344772668

Epoch: 5| Step: 2
Training loss: 0.13890232145786285
Validation loss: 1.4663004029181697

Epoch: 5| Step: 3
Training loss: 0.20524382591247559
Validation loss: 1.4582408089791574

Epoch: 5| Step: 4
Training loss: 0.13565431535243988
Validation loss: 1.4595063899153022

Epoch: 5| Step: 5
Training loss: 0.1263502538204193
Validation loss: 1.4397475155450965

Epoch: 5| Step: 6
Training loss: 0.18465274572372437
Validation loss: 1.4728434355028215

Epoch: 5| Step: 7
Training loss: 0.10097217559814453
Validation loss: 1.4595844361089891

Epoch: 5| Step: 8
Training loss: 0.15199510753154755
Validation loss: 1.4635490320062126

Epoch: 5| Step: 9
Training loss: 0.15299256145954132
Validation loss: 1.4775402904838644

Epoch: 5| Step: 10
Training loss: 0.10487615317106247
Validation loss: 1.4671810186037453

Epoch: 431| Step: 0
Training loss: 0.1651512086391449
Validation loss: 1.4533898843232023

Epoch: 5| Step: 1
Training loss: 0.13496319949626923
Validation loss: 1.4690030133852394

Epoch: 5| Step: 2
Training loss: 0.1264648139476776
Validation loss: 1.4772291696199806

Epoch: 5| Step: 3
Training loss: 0.1974141150712967
Validation loss: 1.4412174179989805

Epoch: 5| Step: 4
Training loss: 0.13389283418655396
Validation loss: 1.457852771205287

Epoch: 5| Step: 5
Training loss: 0.1253298819065094
Validation loss: 1.4472076290397233

Epoch: 5| Step: 6
Training loss: 0.1741156280040741
Validation loss: 1.4565557177348802

Epoch: 5| Step: 7
Training loss: 0.16064989566802979
Validation loss: 1.4383954963376444

Epoch: 5| Step: 8
Training loss: 0.14620748162269592
Validation loss: 1.4734518521575517

Epoch: 5| Step: 9
Training loss: 0.12200522422790527
Validation loss: 1.4676074539461443

Epoch: 5| Step: 10
Training loss: 0.1937548965215683
Validation loss: 1.462813591444364

Epoch: 432| Step: 0
Training loss: 0.09640349447727203
Validation loss: 1.462539093468779

Epoch: 5| Step: 1
Training loss: 0.17618748545646667
Validation loss: 1.456463090835079

Epoch: 5| Step: 2
Training loss: 0.13641704618930817
Validation loss: 1.4759534905033727

Epoch: 5| Step: 3
Training loss: 0.2444925606250763
Validation loss: 1.4579063743673346

Epoch: 5| Step: 4
Training loss: 0.189045250415802
Validation loss: 1.4873279986842987

Epoch: 5| Step: 5
Training loss: 0.15488532185554504
Validation loss: 1.4829778248263943

Epoch: 5| Step: 6
Training loss: 0.07317769527435303
Validation loss: 1.4830189225494221

Epoch: 5| Step: 7
Training loss: 0.16722476482391357
Validation loss: 1.450593053653676

Epoch: 5| Step: 8
Training loss: 0.14127975702285767
Validation loss: 1.4590641093510452

Epoch: 5| Step: 9
Training loss: 0.13486304879188538
Validation loss: 1.4354641796440206

Epoch: 5| Step: 10
Training loss: 0.13489024341106415
Validation loss: 1.4657959284320954

Epoch: 433| Step: 0
Training loss: 0.17894884943962097
Validation loss: 1.4800215011001916

Epoch: 5| Step: 1
Training loss: 0.10576413571834564
Validation loss: 1.4492351826160186

Epoch: 5| Step: 2
Training loss: 0.16990692913532257
Validation loss: 1.4660620625301073

Epoch: 5| Step: 3
Training loss: 0.12168595939874649
Validation loss: 1.415803067145809

Epoch: 5| Step: 4
Training loss: 0.08950100839138031
Validation loss: 1.4364521529084893

Epoch: 5| Step: 5
Training loss: 0.21343913674354553
Validation loss: 1.4425770980055614

Epoch: 5| Step: 6
Training loss: 0.14469800889492035
Validation loss: 1.4567856788635254

Epoch: 5| Step: 7
Training loss: 0.16913239657878876
Validation loss: 1.4318838350234493

Epoch: 5| Step: 8
Training loss: 0.1666240394115448
Validation loss: 1.4348983726193827

Epoch: 5| Step: 9
Training loss: 0.1663246899843216
Validation loss: 1.4260262045809018

Epoch: 5| Step: 10
Training loss: 0.23105598986148834
Validation loss: 1.4416012058975876

Epoch: 434| Step: 0
Training loss: 0.17074617743492126
Validation loss: 1.436913990205334

Epoch: 5| Step: 1
Training loss: 0.10214158147573471
Validation loss: 1.4502543287892495

Epoch: 5| Step: 2
Training loss: 0.16610583662986755
Validation loss: 1.4568940542077506

Epoch: 5| Step: 3
Training loss: 0.21882788836956024
Validation loss: 1.4929761066231677

Epoch: 5| Step: 4
Training loss: 0.154245987534523
Validation loss: 1.5052819790378693

Epoch: 5| Step: 5
Training loss: 0.17133529484272003
Validation loss: 1.5046512388413953

Epoch: 5| Step: 6
Training loss: 0.1555761694908142
Validation loss: 1.5269669063629643

Epoch: 5| Step: 7
Training loss: 0.19817659258842468
Validation loss: 1.5078163493064143

Epoch: 5| Step: 8
Training loss: 0.08905421197414398
Validation loss: 1.517959398608054

Epoch: 5| Step: 9
Training loss: 0.18831995129585266
Validation loss: 1.5420558760243077

Epoch: 5| Step: 10
Training loss: 0.258129745721817
Validation loss: 1.5192040294729254

Epoch: 435| Step: 0
Training loss: 0.1315419226884842
Validation loss: 1.4956046163394887

Epoch: 5| Step: 1
Training loss: 0.261918842792511
Validation loss: 1.517388750788986

Epoch: 5| Step: 2
Training loss: 0.18603584170341492
Validation loss: 1.5046269803918817

Epoch: 5| Step: 3
Training loss: 0.20830023288726807
Validation loss: 1.4766241863209715

Epoch: 5| Step: 4
Training loss: 0.16205474734306335
Validation loss: 1.4739975967714865

Epoch: 5| Step: 5
Training loss: 0.19156305491924286
Validation loss: 1.442576095622073

Epoch: 5| Step: 6
Training loss: 0.19123610854148865
Validation loss: 1.4285286818781207

Epoch: 5| Step: 7
Training loss: 0.16212205588817596
Validation loss: 1.4396594557710873

Epoch: 5| Step: 8
Training loss: 0.11939194053411484
Validation loss: 1.4046854357565604

Epoch: 5| Step: 9
Training loss: 0.1214413195848465
Validation loss: 1.4232298686940184

Epoch: 5| Step: 10
Training loss: 0.3678368330001831
Validation loss: 1.4064305546463176

Epoch: 436| Step: 0
Training loss: 0.20633535087108612
Validation loss: 1.4061620286715928

Epoch: 5| Step: 1
Training loss: 0.18053525686264038
Validation loss: 1.4104595697054298

Epoch: 5| Step: 2
Training loss: 0.19109754264354706
Validation loss: 1.411086836168843

Epoch: 5| Step: 3
Training loss: 0.09777294099330902
Validation loss: 1.422453111217868

Epoch: 5| Step: 4
Training loss: 0.11182741075754166
Validation loss: 1.4226243502350264

Epoch: 5| Step: 5
Training loss: 0.09773305058479309
Validation loss: 1.4002063735838859

Epoch: 5| Step: 6
Training loss: 0.08844967186450958
Validation loss: 1.4031244349736038

Epoch: 5| Step: 7
Training loss: 0.16915759444236755
Validation loss: 1.396572744974526

Epoch: 5| Step: 8
Training loss: 0.2084360122680664
Validation loss: 1.3888715749145837

Epoch: 5| Step: 9
Training loss: 0.2808552384376526
Validation loss: 1.4129028909949846

Epoch: 5| Step: 10
Training loss: 0.13515186309814453
Validation loss: 1.4302387417003672

Epoch: 437| Step: 0
Training loss: 0.09391961991786957
Validation loss: 1.4061850238871831

Epoch: 5| Step: 1
Training loss: 0.2366674244403839
Validation loss: 1.414430268349186

Epoch: 5| Step: 2
Training loss: 0.12638972699642181
Validation loss: 1.426159502357565

Epoch: 5| Step: 3
Training loss: 0.1706421971321106
Validation loss: 1.4180053741701188

Epoch: 5| Step: 4
Training loss: 0.24879047274589539
Validation loss: 1.44182034461729

Epoch: 5| Step: 5
Training loss: 0.21091285347938538
Validation loss: 1.4306856829632995

Epoch: 5| Step: 6
Training loss: 0.14002558588981628
Validation loss: 1.4354500270658923

Epoch: 5| Step: 7
Training loss: 0.17875084280967712
Validation loss: 1.4402624323803892

Epoch: 5| Step: 8
Training loss: 0.11261947453022003
Validation loss: 1.4665262596581572

Epoch: 5| Step: 9
Training loss: 0.2593194544315338
Validation loss: 1.5018904657774075

Epoch: 5| Step: 10
Training loss: 0.1598856896162033
Validation loss: 1.4960666439866508

Epoch: 438| Step: 0
Training loss: 0.19623848795890808
Validation loss: 1.488163016816621

Epoch: 5| Step: 1
Training loss: 0.2373141050338745
Validation loss: 1.504182606615046

Epoch: 5| Step: 2
Training loss: 0.11825452744960785
Validation loss: 1.5033159627709338

Epoch: 5| Step: 3
Training loss: 0.2632065713405609
Validation loss: 1.4711081443294403

Epoch: 5| Step: 4
Training loss: 0.1480071246623993
Validation loss: 1.462671237607156

Epoch: 5| Step: 5
Training loss: 0.13933512568473816
Validation loss: 1.4510480588482273

Epoch: 5| Step: 6
Training loss: 0.1671627163887024
Validation loss: 1.442576995459936

Epoch: 5| Step: 7
Training loss: 0.23151925206184387
Validation loss: 1.433010519191783

Epoch: 5| Step: 8
Training loss: 0.14620886743068695
Validation loss: 1.452351975184615

Epoch: 5| Step: 9
Training loss: 0.16356196999549866
Validation loss: 1.4428983837045648

Epoch: 5| Step: 10
Training loss: 0.22025299072265625
Validation loss: 1.4478696648792555

Epoch: 439| Step: 0
Training loss: 0.15228796005249023
Validation loss: 1.4636773627291444

Epoch: 5| Step: 1
Training loss: 0.13496805727481842
Validation loss: 1.433496908474994

Epoch: 5| Step: 2
Training loss: 0.23490557074546814
Validation loss: 1.4407290156169603

Epoch: 5| Step: 3
Training loss: 0.15734480321407318
Validation loss: 1.4426043084872666

Epoch: 5| Step: 4
Training loss: 0.19141405820846558
Validation loss: 1.4562024275461833

Epoch: 5| Step: 5
Training loss: 0.2003643959760666
Validation loss: 1.465892776366203

Epoch: 5| Step: 6
Training loss: 0.16878776252269745
Validation loss: 1.4544849434206564

Epoch: 5| Step: 7
Training loss: 0.22053608298301697
Validation loss: 1.4971876246954805

Epoch: 5| Step: 8
Training loss: 0.10008609294891357
Validation loss: 1.4754203301604076

Epoch: 5| Step: 9
Training loss: 0.12057048082351685
Validation loss: 1.5147430954440948

Epoch: 5| Step: 10
Training loss: 0.1549779176712036
Validation loss: 1.4979490336551462

Epoch: 440| Step: 0
Training loss: 0.12259584665298462
Validation loss: 1.5054952752205633

Epoch: 5| Step: 1
Training loss: 0.1651977002620697
Validation loss: 1.4798305573001984

Epoch: 5| Step: 2
Training loss: 0.11547885090112686
Validation loss: 1.4747637766663746

Epoch: 5| Step: 3
Training loss: 0.094834104180336
Validation loss: 1.4801237070432274

Epoch: 5| Step: 4
Training loss: 0.1439511626958847
Validation loss: 1.445387671070714

Epoch: 5| Step: 5
Training loss: 0.21848006546497345
Validation loss: 1.4337198554828603

Epoch: 5| Step: 6
Training loss: 0.12411975860595703
Validation loss: 1.424856396131618

Epoch: 5| Step: 7
Training loss: 0.1332530677318573
Validation loss: 1.4402565815115487

Epoch: 5| Step: 8
Training loss: 0.3025668263435364
Validation loss: 1.4442013989212692

Epoch: 5| Step: 9
Training loss: 0.13041731715202332
Validation loss: 1.417152162521116

Epoch: 5| Step: 10
Training loss: 0.11798973381519318
Validation loss: 1.4319154459943053

Epoch: 441| Step: 0
Training loss: 0.18915759027004242
Validation loss: 1.427707532400726

Epoch: 5| Step: 1
Training loss: 0.14533373713493347
Validation loss: 1.4181512043040285

Epoch: 5| Step: 2
Training loss: 0.1484086811542511
Validation loss: 1.4229000742717455

Epoch: 5| Step: 3
Training loss: 0.1788000762462616
Validation loss: 1.4379917139648108

Epoch: 5| Step: 4
Training loss: 0.12672977149486542
Validation loss: 1.4248168571020967

Epoch: 5| Step: 5
Training loss: 0.2058715522289276
Validation loss: 1.4129891985206193

Epoch: 5| Step: 6
Training loss: 0.13677439093589783
Validation loss: 1.4089963013126003

Epoch: 5| Step: 7
Training loss: 0.14388780295848846
Validation loss: 1.40127226614183

Epoch: 5| Step: 8
Training loss: 0.12958058714866638
Validation loss: 1.3806598596675421

Epoch: 5| Step: 9
Training loss: 0.12487862259149551
Validation loss: 1.3955426844217445

Epoch: 5| Step: 10
Training loss: 0.13837380707263947
Validation loss: 1.376169007311585

Epoch: 442| Step: 0
Training loss: 0.18620340526103973
Validation loss: 1.3886863698241532

Epoch: 5| Step: 1
Training loss: 0.16382762789726257
Validation loss: 1.3774820117540256

Epoch: 5| Step: 2
Training loss: 0.13639041781425476
Validation loss: 1.387295884470786

Epoch: 5| Step: 3
Training loss: 0.1370094269514084
Validation loss: 1.3831524118300407

Epoch: 5| Step: 4
Training loss: 0.20255310833454132
Validation loss: 1.3865664864099154

Epoch: 5| Step: 5
Training loss: 0.14401459693908691
Validation loss: 1.3950696875972133

Epoch: 5| Step: 6
Training loss: 0.13363370299339294
Validation loss: 1.4086841947288924

Epoch: 5| Step: 7
Training loss: 0.16804298758506775
Validation loss: 1.4178130267768778

Epoch: 5| Step: 8
Training loss: 0.1682816743850708
Validation loss: 1.418307556900927

Epoch: 5| Step: 9
Training loss: 0.10216506570577621
Validation loss: 1.4523636278926686

Epoch: 5| Step: 10
Training loss: 0.2669610381126404
Validation loss: 1.4376551822949482

Epoch: 443| Step: 0
Training loss: 0.18972823023796082
Validation loss: 1.450094226867922

Epoch: 5| Step: 1
Training loss: 0.12161701917648315
Validation loss: 1.4453611450810586

Epoch: 5| Step: 2
Training loss: 0.22843389213085175
Validation loss: 1.4535796796121905

Epoch: 5| Step: 3
Training loss: 0.17174655199050903
Validation loss: 1.4599591980698288

Epoch: 5| Step: 4
Training loss: 0.14604452252388
Validation loss: 1.45924590223579

Epoch: 5| Step: 5
Training loss: 0.21262864768505096
Validation loss: 1.4975899201567455

Epoch: 5| Step: 6
Training loss: 0.12086047977209091
Validation loss: 1.4853309790293376

Epoch: 5| Step: 7
Training loss: 0.19020745158195496
Validation loss: 1.473157536598944

Epoch: 5| Step: 8
Training loss: 0.104964479804039
Validation loss: 1.4649761428115189

Epoch: 5| Step: 9
Training loss: 0.22400705516338348
Validation loss: 1.4593983709171254

Epoch: 5| Step: 10
Training loss: 0.17065781354904175
Validation loss: 1.4442903675058836

Epoch: 444| Step: 0
Training loss: 0.14875733852386475
Validation loss: 1.4545335551743865

Epoch: 5| Step: 1
Training loss: 0.11903102695941925
Validation loss: 1.4561444213313441

Epoch: 5| Step: 2
Training loss: 0.20682871341705322
Validation loss: 1.4559534762495308

Epoch: 5| Step: 3
Training loss: 0.11600975692272186
Validation loss: 1.4519151154384817

Epoch: 5| Step: 4
Training loss: 0.14137177169322968
Validation loss: 1.4627333046287618

Epoch: 5| Step: 5
Training loss: 0.17500755190849304
Validation loss: 1.4361644585927327

Epoch: 5| Step: 6
Training loss: 0.23061725497245789
Validation loss: 1.451744774336456

Epoch: 5| Step: 7
Training loss: 0.1425422877073288
Validation loss: 1.4308796595501643

Epoch: 5| Step: 8
Training loss: 0.1469775140285492
Validation loss: 1.3937965798121628

Epoch: 5| Step: 9
Training loss: 0.19210493564605713
Validation loss: 1.4157976706822712

Epoch: 5| Step: 10
Training loss: 0.1384965181350708
Validation loss: 1.4330448219853062

Epoch: 445| Step: 0
Training loss: 0.12409188598394394
Validation loss: 1.4004208990322646

Epoch: 5| Step: 1
Training loss: 0.16697588562965393
Validation loss: 1.3985415915007233

Epoch: 5| Step: 2
Training loss: 0.1715574562549591
Validation loss: 1.4318000437110983

Epoch: 5| Step: 3
Training loss: 0.15241922438144684
Validation loss: 1.4399291879387313

Epoch: 5| Step: 4
Training loss: 0.1263127624988556
Validation loss: 1.4334874332592051

Epoch: 5| Step: 5
Training loss: 0.09760964661836624
Validation loss: 1.420206569856213

Epoch: 5| Step: 6
Training loss: 0.10641612857580185
Validation loss: 1.4438377054788734

Epoch: 5| Step: 7
Training loss: 0.15140800178050995
Validation loss: 1.4602171541542135

Epoch: 5| Step: 8
Training loss: 0.10156059265136719
Validation loss: 1.4409824455938032

Epoch: 5| Step: 9
Training loss: 0.23494572937488556
Validation loss: 1.4519093754470989

Epoch: 5| Step: 10
Training loss: 0.119438536465168
Validation loss: 1.4488812569648988

Epoch: 446| Step: 0
Training loss: 0.10528677701950073
Validation loss: 1.46976024681522

Epoch: 5| Step: 1
Training loss: 0.1300269067287445
Validation loss: 1.4576203592361943

Epoch: 5| Step: 2
Training loss: 0.15174975991249084
Validation loss: 1.4673677041966429

Epoch: 5| Step: 3
Training loss: 0.08118942379951477
Validation loss: 1.485643370177156

Epoch: 5| Step: 4
Training loss: 0.1007409319281578
Validation loss: 1.4899620702189784

Epoch: 5| Step: 5
Training loss: 0.20846518874168396
Validation loss: 1.4842470179321945

Epoch: 5| Step: 6
Training loss: 0.13723114132881165
Validation loss: 1.508105472851825

Epoch: 5| Step: 7
Training loss: 0.19583778083324432
Validation loss: 1.484004702619327

Epoch: 5| Step: 8
Training loss: 0.15966936945915222
Validation loss: 1.493113777970755

Epoch: 5| Step: 9
Training loss: 0.12064634263515472
Validation loss: 1.50239315853324

Epoch: 5| Step: 10
Training loss: 0.19964352250099182
Validation loss: 1.4885658448742283

Epoch: 447| Step: 0
Training loss: 0.0994035080075264
Validation loss: 1.4672381262625418

Epoch: 5| Step: 1
Training loss: 0.14214980602264404
Validation loss: 1.456944739946755

Epoch: 5| Step: 2
Training loss: 0.18799039721488953
Validation loss: 1.4700185252774147

Epoch: 5| Step: 3
Training loss: 0.1370229870080948
Validation loss: 1.4590418607957902

Epoch: 5| Step: 4
Training loss: 0.11103905737400055
Validation loss: 1.4519874395862702

Epoch: 5| Step: 5
Training loss: 0.12866298854351044
Validation loss: 1.466352024386006

Epoch: 5| Step: 6
Training loss: 0.16073906421661377
Validation loss: 1.4404732770817255

Epoch: 5| Step: 7
Training loss: 0.1150888055562973
Validation loss: 1.4440130943893104

Epoch: 5| Step: 8
Training loss: 0.11582469940185547
Validation loss: 1.4481835108931347

Epoch: 5| Step: 9
Training loss: 0.12301087379455566
Validation loss: 1.4292535910042383

Epoch: 5| Step: 10
Training loss: 0.202843576669693
Validation loss: 1.4561092853546143

Epoch: 448| Step: 0
Training loss: 0.09919622540473938
Validation loss: 1.43852698802948

Epoch: 5| Step: 1
Training loss: 0.1330634206533432
Validation loss: 1.4434459260714951

Epoch: 5| Step: 2
Training loss: 0.13178090751171112
Validation loss: 1.4711117923900645

Epoch: 5| Step: 3
Training loss: 0.10533256828784943
Validation loss: 1.4513408381451842

Epoch: 5| Step: 4
Training loss: 0.20395231246948242
Validation loss: 1.4594424014450402

Epoch: 5| Step: 5
Training loss: 0.16969181597232819
Validation loss: 1.4594071334408176

Epoch: 5| Step: 6
Training loss: 0.14553189277648926
Validation loss: 1.451551498264395

Epoch: 5| Step: 7
Training loss: 0.11948908865451813
Validation loss: 1.4394981438113796

Epoch: 5| Step: 8
Training loss: 0.11323748528957367
Validation loss: 1.463768643717612

Epoch: 5| Step: 9
Training loss: 0.08140683174133301
Validation loss: 1.4552751151464318

Epoch: 5| Step: 10
Training loss: 0.21729156374931335
Validation loss: 1.444984725726548

Epoch: 449| Step: 0
Training loss: 0.20423564314842224
Validation loss: 1.4526884466089227

Epoch: 5| Step: 1
Training loss: 0.11547619104385376
Validation loss: 1.4449865536023212

Epoch: 5| Step: 2
Training loss: 0.08942018449306488
Validation loss: 1.4516234192796933

Epoch: 5| Step: 3
Training loss: 0.09307838976383209
Validation loss: 1.4277144042394494

Epoch: 5| Step: 4
Training loss: 0.06796646118164062
Validation loss: 1.3977420740230109

Epoch: 5| Step: 5
Training loss: 0.1530875712633133
Validation loss: 1.411492451544731

Epoch: 5| Step: 6
Training loss: 0.14399242401123047
Validation loss: 1.4492659914878108

Epoch: 5| Step: 7
Training loss: 0.10225947201251984
Validation loss: 1.4243656217411

Epoch: 5| Step: 8
Training loss: 0.14302462339401245
Validation loss: 1.4509992714851134

Epoch: 5| Step: 9
Training loss: 0.14523449540138245
Validation loss: 1.4528773023236183

Epoch: 5| Step: 10
Training loss: 0.14280910789966583
Validation loss: 1.4276361644908946

Epoch: 450| Step: 0
Training loss: 0.1246895045042038
Validation loss: 1.3970489066134217

Epoch: 5| Step: 1
Training loss: 0.20098944008350372
Validation loss: 1.4408088268772248

Epoch: 5| Step: 2
Training loss: 0.11329732090234756
Validation loss: 1.4126988495549848

Epoch: 5| Step: 3
Training loss: 0.1157064437866211
Validation loss: 1.4235396244192635

Epoch: 5| Step: 4
Training loss: 0.08927099406719208
Validation loss: 1.4458764163396691

Epoch: 5| Step: 5
Training loss: 0.10391607135534286
Validation loss: 1.4430869099914387

Epoch: 5| Step: 6
Training loss: 0.1391337662935257
Validation loss: 1.4416888221617667

Epoch: 5| Step: 7
Training loss: 0.1220637708902359
Validation loss: 1.4414413411130187

Epoch: 5| Step: 8
Training loss: 0.12438876926898956
Validation loss: 1.4647236344634846

Epoch: 5| Step: 9
Training loss: 0.14451909065246582
Validation loss: 1.4605411887168884

Epoch: 5| Step: 10
Training loss: 0.15164412558078766
Validation loss: 1.460535341693509

Epoch: 451| Step: 0
Training loss: 0.1418651044368744
Validation loss: 1.482070437041662

Epoch: 5| Step: 1
Training loss: 0.14889106154441833
Validation loss: 1.429716157656844

Epoch: 5| Step: 2
Training loss: 0.12334789335727692
Validation loss: 1.4574682225463211

Epoch: 5| Step: 3
Training loss: 0.13383829593658447
Validation loss: 1.436612222784309

Epoch: 5| Step: 4
Training loss: 0.19546429812908173
Validation loss: 1.4316288989077333

Epoch: 5| Step: 5
Training loss: 0.22587338089942932
Validation loss: 1.4625452077516945

Epoch: 5| Step: 6
Training loss: 0.154314786195755
Validation loss: 1.4434227687056347

Epoch: 5| Step: 7
Training loss: 0.1317962110042572
Validation loss: 1.4610175009696715

Epoch: 5| Step: 8
Training loss: 0.131027951836586
Validation loss: 1.4523017374418115

Epoch: 5| Step: 9
Training loss: 0.10255700349807739
Validation loss: 1.4439425263353574

Epoch: 5| Step: 10
Training loss: 0.0936923697590828
Validation loss: 1.4424280735754198

Epoch: 452| Step: 0
Training loss: 0.17899355292320251
Validation loss: 1.4357971388806579

Epoch: 5| Step: 1
Training loss: 0.12925423681735992
Validation loss: 1.4611958342213784

Epoch: 5| Step: 2
Training loss: 0.1421058028936386
Validation loss: 1.4689826119330622

Epoch: 5| Step: 3
Training loss: 0.12264547497034073
Validation loss: 1.4784663293951301

Epoch: 5| Step: 4
Training loss: 0.17749501764774323
Validation loss: 1.4893410898024035

Epoch: 5| Step: 5
Training loss: 0.12298516184091568
Validation loss: 1.486780607572166

Epoch: 5| Step: 6
Training loss: 0.17165637016296387
Validation loss: 1.4707920012935516

Epoch: 5| Step: 7
Training loss: 0.08282417804002762
Validation loss: 1.4612244277872064

Epoch: 5| Step: 8
Training loss: 0.08984221518039703
Validation loss: 1.447571942883153

Epoch: 5| Step: 9
Training loss: 0.12334181368350983
Validation loss: 1.4522141372003863

Epoch: 5| Step: 10
Training loss: 0.07073911279439926
Validation loss: 1.4275286056662118

Epoch: 453| Step: 0
Training loss: 0.15201085805892944
Validation loss: 1.4296432977081628

Epoch: 5| Step: 1
Training loss: 0.15676870942115784
Validation loss: 1.457886375406737

Epoch: 5| Step: 2
Training loss: 0.15022552013397217
Validation loss: 1.4421672962045158

Epoch: 5| Step: 3
Training loss: 0.12002861499786377
Validation loss: 1.434533897266593

Epoch: 5| Step: 4
Training loss: 0.20940366387367249
Validation loss: 1.4354042660805486

Epoch: 5| Step: 5
Training loss: 0.17821553349494934
Validation loss: 1.4202392896016438

Epoch: 5| Step: 6
Training loss: 0.08305006474256516
Validation loss: 1.4751901139495194

Epoch: 5| Step: 7
Training loss: 0.106958769261837
Validation loss: 1.452937231268934

Epoch: 5| Step: 8
Training loss: 0.11006154119968414
Validation loss: 1.4870603879292805

Epoch: 5| Step: 9
Training loss: 0.10821995884180069
Validation loss: 1.4864285287036691

Epoch: 5| Step: 10
Training loss: 0.1408383846282959
Validation loss: 1.489706790575417

Epoch: 454| Step: 0
Training loss: 0.19813799858093262
Validation loss: 1.4937407560245965

Epoch: 5| Step: 1
Training loss: 0.11686104536056519
Validation loss: 1.4980297575714767

Epoch: 5| Step: 2
Training loss: 0.08519791066646576
Validation loss: 1.5088601407184397

Epoch: 5| Step: 3
Training loss: 0.16599702835083008
Validation loss: 1.4913438058668567

Epoch: 5| Step: 4
Training loss: 0.09489595144987106
Validation loss: 1.452184538687429

Epoch: 5| Step: 5
Training loss: 0.11194418370723724
Validation loss: 1.454195794238839

Epoch: 5| Step: 6
Training loss: 0.12675510346889496
Validation loss: 1.4668216154139528

Epoch: 5| Step: 7
Training loss: 0.10598615556955338
Validation loss: 1.446553684050037

Epoch: 5| Step: 8
Training loss: 0.14927765727043152
Validation loss: 1.459080703796879

Epoch: 5| Step: 9
Training loss: 0.17182199656963348
Validation loss: 1.3937162532601306

Epoch: 5| Step: 10
Training loss: 0.15319114923477173
Validation loss: 1.3997042025289228

Epoch: 455| Step: 0
Training loss: 0.11002743244171143
Validation loss: 1.4174583881132063

Epoch: 5| Step: 1
Training loss: 0.08560940623283386
Validation loss: 1.4072839393410632

Epoch: 5| Step: 2
Training loss: 0.18338876962661743
Validation loss: 1.4184273750551286

Epoch: 5| Step: 3
Training loss: 0.1992686539888382
Validation loss: 1.4189340273539226

Epoch: 5| Step: 4
Training loss: 0.16084440052509308
Validation loss: 1.420255430283085

Epoch: 5| Step: 5
Training loss: 0.17734792828559875
Validation loss: 1.4022599176693988

Epoch: 5| Step: 6
Training loss: 0.1310250461101532
Validation loss: 1.4153044390422043

Epoch: 5| Step: 7
Training loss: 0.18980112671852112
Validation loss: 1.4014721557658205

Epoch: 5| Step: 8
Training loss: 0.11361708492040634
Validation loss: 1.410735050837199

Epoch: 5| Step: 9
Training loss: 0.15108957886695862
Validation loss: 1.430877576592148

Epoch: 5| Step: 10
Training loss: 0.16463804244995117
Validation loss: 1.4397530094269784

Epoch: 456| Step: 0
Training loss: 0.12794315814971924
Validation loss: 1.4456004526025505

Epoch: 5| Step: 1
Training loss: 0.21815378963947296
Validation loss: 1.4582105503287366

Epoch: 5| Step: 2
Training loss: 0.0807720422744751
Validation loss: 1.4762795458557785

Epoch: 5| Step: 3
Training loss: 0.09837363660335541
Validation loss: 1.4462819445517756

Epoch: 5| Step: 4
Training loss: 0.19528129696846008
Validation loss: 1.4799171827172721

Epoch: 5| Step: 5
Training loss: 0.1353655755519867
Validation loss: 1.4644374219320153

Epoch: 5| Step: 6
Training loss: 0.1458173543214798
Validation loss: 1.4412144178985267

Epoch: 5| Step: 7
Training loss: 0.20327182114124298
Validation loss: 1.4647899737922094

Epoch: 5| Step: 8
Training loss: 0.17165851593017578
Validation loss: 1.4552239384702457

Epoch: 5| Step: 9
Training loss: 0.1242544874548912
Validation loss: 1.4858468578707786

Epoch: 5| Step: 10
Training loss: 0.10561958700418472
Validation loss: 1.4919327914073903

Epoch: 457| Step: 0
Training loss: 0.10330146551132202
Validation loss: 1.48024320602417

Epoch: 5| Step: 1
Training loss: 0.16478231549263
Validation loss: 1.5107329032754386

Epoch: 5| Step: 2
Training loss: 0.1395246982574463
Validation loss: 1.5112887479925667

Epoch: 5| Step: 3
Training loss: 0.10690297931432724
Validation loss: 1.4819191104622298

Epoch: 5| Step: 4
Training loss: 0.17215119302272797
Validation loss: 1.4752298452520882

Epoch: 5| Step: 5
Training loss: 0.11240427196025848
Validation loss: 1.470689332613381

Epoch: 5| Step: 6
Training loss: 0.054784856736660004
Validation loss: 1.4640206944557927

Epoch: 5| Step: 7
Training loss: 0.12467722594738007
Validation loss: 1.4537498630503172

Epoch: 5| Step: 8
Training loss: 0.15607045590877533
Validation loss: 1.4611167382168513

Epoch: 5| Step: 9
Training loss: 0.1889529526233673
Validation loss: 1.4308034643050163

Epoch: 5| Step: 10
Training loss: 0.14706014096736908
Validation loss: 1.4499322265707038

Epoch: 458| Step: 0
Training loss: 0.15854580700397491
Validation loss: 1.4526589814052786

Epoch: 5| Step: 1
Training loss: 0.10948622226715088
Validation loss: 1.4489776870255828

Epoch: 5| Step: 2
Training loss: 0.18196730315685272
Validation loss: 1.4718970560258435

Epoch: 5| Step: 3
Training loss: 0.15410205721855164
Validation loss: 1.5038116183332217

Epoch: 5| Step: 4
Training loss: 0.15114639699459076
Validation loss: 1.470862264274269

Epoch: 5| Step: 5
Training loss: 0.16944661736488342
Validation loss: 1.495340460090227

Epoch: 5| Step: 6
Training loss: 0.11968398094177246
Validation loss: 1.4761815737652522

Epoch: 5| Step: 7
Training loss: 0.10557301342487335
Validation loss: 1.4769802510097463

Epoch: 5| Step: 8
Training loss: 0.1380959451198578
Validation loss: 1.4807069660514913

Epoch: 5| Step: 9
Training loss: 0.08710755407810211
Validation loss: 1.4520694030228483

Epoch: 5| Step: 10
Training loss: 0.1035771518945694
Validation loss: 1.4620976460877286

Epoch: 459| Step: 0
Training loss: 0.15536363422870636
Validation loss: 1.4662439784696024

Epoch: 5| Step: 1
Training loss: 0.0828869566321373
Validation loss: 1.4726425627226472

Epoch: 5| Step: 2
Training loss: 0.10384222120046616
Validation loss: 1.4716291799340198

Epoch: 5| Step: 3
Training loss: 0.1419142782688141
Validation loss: 1.4589199212289625

Epoch: 5| Step: 4
Training loss: 0.08329639583826065
Validation loss: 1.4633522277237268

Epoch: 5| Step: 5
Training loss: 0.12295284122228622
Validation loss: 1.4589296643451979

Epoch: 5| Step: 6
Training loss: 0.1724812239408493
Validation loss: 1.4360252657244283

Epoch: 5| Step: 7
Training loss: 0.11379945278167725
Validation loss: 1.4334631889097151

Epoch: 5| Step: 8
Training loss: 0.2474760115146637
Validation loss: 1.4313410943554294

Epoch: 5| Step: 9
Training loss: 0.09250158071517944
Validation loss: 1.4452011790326846

Epoch: 5| Step: 10
Training loss: 0.10292249917984009
Validation loss: 1.4359551616894302

Epoch: 460| Step: 0
Training loss: 0.05547978729009628
Validation loss: 1.4352042239199403

Epoch: 5| Step: 1
Training loss: 0.12980015575885773
Validation loss: 1.4308745579052997

Epoch: 5| Step: 2
Training loss: 0.07852290570735931
Validation loss: 1.4199367466793265

Epoch: 5| Step: 3
Training loss: 0.0854722410440445
Validation loss: 1.3988909631647088

Epoch: 5| Step: 4
Training loss: 0.19810481369495392
Validation loss: 1.3926420070791756

Epoch: 5| Step: 5
Training loss: 0.08525022864341736
Validation loss: 1.3995540372786983

Epoch: 5| Step: 6
Training loss: 0.15599605441093445
Validation loss: 1.388797313936295

Epoch: 5| Step: 7
Training loss: 0.15123844146728516
Validation loss: 1.3972789984877392

Epoch: 5| Step: 8
Training loss: 0.11271746456623077
Validation loss: 1.409468626463285

Epoch: 5| Step: 9
Training loss: 0.12496109306812286
Validation loss: 1.4241197455313899

Epoch: 5| Step: 10
Training loss: 0.1945415586233139
Validation loss: 1.4153796908675984

Epoch: 461| Step: 0
Training loss: 0.08895249664783478
Validation loss: 1.4118766976941017

Epoch: 5| Step: 1
Training loss: 0.11619309335947037
Validation loss: 1.4040211823678785

Epoch: 5| Step: 2
Training loss: 0.1465837061405182
Validation loss: 1.4207076488002655

Epoch: 5| Step: 3
Training loss: 0.14077851176261902
Validation loss: 1.396810886680439

Epoch: 5| Step: 4
Training loss: 0.11258896440267563
Validation loss: 1.410028958833346

Epoch: 5| Step: 5
Training loss: 0.12605950236320496
Validation loss: 1.4019360093660251

Epoch: 5| Step: 6
Training loss: 0.1304112672805786
Validation loss: 1.4016823537888066

Epoch: 5| Step: 7
Training loss: 0.08522527664899826
Validation loss: 1.4242101074546896

Epoch: 5| Step: 8
Training loss: 0.11772821098566055
Validation loss: 1.4373656652306999

Epoch: 5| Step: 9
Training loss: 0.16348063945770264
Validation loss: 1.4420255589228805

Epoch: 5| Step: 10
Training loss: 0.1266152709722519
Validation loss: 1.4746866982470277

Epoch: 462| Step: 0
Training loss: 0.09897410124540329
Validation loss: 1.48818084245087

Epoch: 5| Step: 1
Training loss: 0.11692063510417938
Validation loss: 1.500186239519427

Epoch: 5| Step: 2
Training loss: 0.11727674305438995
Validation loss: 1.5223553693422707

Epoch: 5| Step: 3
Training loss: 0.13942080736160278
Validation loss: 1.5118694311829024

Epoch: 5| Step: 4
Training loss: 0.1287592202425003
Validation loss: 1.4754781325658162

Epoch: 5| Step: 5
Training loss: 0.09331263601779938
Validation loss: 1.4519111699955438

Epoch: 5| Step: 6
Training loss: 0.12134365737438202
Validation loss: 1.4839667222833122

Epoch: 5| Step: 7
Training loss: 0.09542925655841827
Validation loss: 1.4857782407473492

Epoch: 5| Step: 8
Training loss: 0.15228791534900665
Validation loss: 1.4740839824881604

Epoch: 5| Step: 9
Training loss: 0.18904706835746765
Validation loss: 1.4642101692897018

Epoch: 5| Step: 10
Training loss: 0.160461887717247
Validation loss: 1.4615048939181912

Epoch: 463| Step: 0
Training loss: 0.1460082232952118
Validation loss: 1.4734890922423332

Epoch: 5| Step: 1
Training loss: 0.13770663738250732
Validation loss: 1.4645190713226155

Epoch: 5| Step: 2
Training loss: 0.1681482493877411
Validation loss: 1.4687464006485478

Epoch: 5| Step: 3
Training loss: 0.11039171367883682
Validation loss: 1.4620559766728392

Epoch: 5| Step: 4
Training loss: 0.11187276989221573
Validation loss: 1.4730324514450566

Epoch: 5| Step: 5
Training loss: 0.19026921689510345
Validation loss: 1.478180029058969

Epoch: 5| Step: 6
Training loss: 0.1812652200460434
Validation loss: 1.4938885704163583

Epoch: 5| Step: 7
Training loss: 0.07886078953742981
Validation loss: 1.4935553176428682

Epoch: 5| Step: 8
Training loss: 0.0846065953373909
Validation loss: 1.472404937590322

Epoch: 5| Step: 9
Training loss: 0.12340055406093597
Validation loss: 1.4688889877770537

Epoch: 5| Step: 10
Training loss: 0.15927089750766754
Validation loss: 1.468328583625055

Epoch: 464| Step: 0
Training loss: 0.08127819746732712
Validation loss: 1.4521369934082031

Epoch: 5| Step: 1
Training loss: 0.1964472532272339
Validation loss: 1.475264981228818

Epoch: 5| Step: 2
Training loss: 0.1192145124077797
Validation loss: 1.4511079057570426

Epoch: 5| Step: 3
Training loss: 0.10358107089996338
Validation loss: 1.4618930278285858

Epoch: 5| Step: 4
Training loss: 0.13443049788475037
Validation loss: 1.4531870849670903

Epoch: 5| Step: 5
Training loss: 0.18887881934642792
Validation loss: 1.4425357964731031

Epoch: 5| Step: 6
Training loss: 0.13253049552440643
Validation loss: 1.457843380589639

Epoch: 5| Step: 7
Training loss: 0.11301858723163605
Validation loss: 1.440916835620839

Epoch: 5| Step: 8
Training loss: 0.13855576515197754
Validation loss: 1.459742861409341

Epoch: 5| Step: 9
Training loss: 0.0843888372182846
Validation loss: 1.4412298394787697

Epoch: 5| Step: 10
Training loss: 0.13177217543125153
Validation loss: 1.4455287828240344

Epoch: 465| Step: 0
Training loss: 0.11722109466791153
Validation loss: 1.4318027163064608

Epoch: 5| Step: 1
Training loss: 0.08270497620105743
Validation loss: 1.4258314909473542

Epoch: 5| Step: 2
Training loss: 0.12284266948699951
Validation loss: 1.436165423803432

Epoch: 5| Step: 3
Training loss: 0.16831226646900177
Validation loss: 1.4489267782498432

Epoch: 5| Step: 4
Training loss: 0.11411521583795547
Validation loss: 1.4324827835124025

Epoch: 5| Step: 5
Training loss: 0.16382133960723877
Validation loss: 1.4612933230656449

Epoch: 5| Step: 6
Training loss: 0.16998839378356934
Validation loss: 1.4439680589142667

Epoch: 5| Step: 7
Training loss: 0.14535313844680786
Validation loss: 1.443916650228603

Epoch: 5| Step: 8
Training loss: 0.10996246337890625
Validation loss: 1.4482667356409051

Epoch: 5| Step: 9
Training loss: 0.08538639545440674
Validation loss: 1.4549342778421217

Epoch: 5| Step: 10
Training loss: 0.10200494527816772
Validation loss: 1.4779873035287345

Epoch: 466| Step: 0
Training loss: 0.10080032050609589
Validation loss: 1.4654641741065568

Epoch: 5| Step: 1
Training loss: 0.1390555202960968
Validation loss: 1.4792892074072233

Epoch: 5| Step: 2
Training loss: 0.2238883525133133
Validation loss: 1.4844798657201952

Epoch: 5| Step: 3
Training loss: 0.16324996948242188
Validation loss: 1.4642957077231458

Epoch: 5| Step: 4
Training loss: 0.21094810962677002
Validation loss: 1.4497260419271325

Epoch: 5| Step: 5
Training loss: 0.12292711436748505
Validation loss: 1.4403300682703655

Epoch: 5| Step: 6
Training loss: 0.1140061616897583
Validation loss: 1.4349329984316261

Epoch: 5| Step: 7
Training loss: 0.06260235607624054
Validation loss: 1.4478255805148874

Epoch: 5| Step: 8
Training loss: 0.0984276533126831
Validation loss: 1.4469544124859635

Epoch: 5| Step: 9
Training loss: 0.10009155422449112
Validation loss: 1.4231050065768662

Epoch: 5| Step: 10
Training loss: 0.12985950708389282
Validation loss: 1.4325854893653625

Epoch: 467| Step: 0
Training loss: 0.12526093423366547
Validation loss: 1.4342096659444994

Epoch: 5| Step: 1
Training loss: 0.09702229499816895
Validation loss: 1.4257661975840086

Epoch: 5| Step: 2
Training loss: 0.1309746950864792
Validation loss: 1.4300508101781209

Epoch: 5| Step: 3
Training loss: 0.16046766936779022
Validation loss: 1.418464506826093

Epoch: 5| Step: 4
Training loss: 0.11992867290973663
Validation loss: 1.4196898219405965

Epoch: 5| Step: 5
Training loss: 0.08572159707546234
Validation loss: 1.4415994023764005

Epoch: 5| Step: 6
Training loss: 0.13110320270061493
Validation loss: 1.4616789330718338

Epoch: 5| Step: 7
Training loss: 0.12693814933300018
Validation loss: 1.43682469988382

Epoch: 5| Step: 8
Training loss: 0.1596830040216446
Validation loss: 1.4421712570292975

Epoch: 5| Step: 9
Training loss: 0.07085300981998444
Validation loss: 1.4329360441495014

Epoch: 5| Step: 10
Training loss: 0.07512766122817993
Validation loss: 1.45243513712319

Epoch: 468| Step: 0
Training loss: 0.08528107404708862
Validation loss: 1.4341663814360095

Epoch: 5| Step: 1
Training loss: 0.14120613038539886
Validation loss: 1.4372938897020073

Epoch: 5| Step: 2
Training loss: 0.0709453672170639
Validation loss: 1.4382976075654388

Epoch: 5| Step: 3
Training loss: 0.09890222549438477
Validation loss: 1.4306079879883797

Epoch: 5| Step: 4
Training loss: 0.0764482244849205
Validation loss: 1.4452025095621746

Epoch: 5| Step: 5
Training loss: 0.1191553846001625
Validation loss: 1.4367314032329026

Epoch: 5| Step: 6
Training loss: 0.07562825828790665
Validation loss: 1.4378591506711897

Epoch: 5| Step: 7
Training loss: 0.2044343650341034
Validation loss: 1.4501439730326335

Epoch: 5| Step: 8
Training loss: 0.11742564290761948
Validation loss: 1.4342686963337723

Epoch: 5| Step: 9
Training loss: 0.11049308627843857
Validation loss: 1.4639612461930962

Epoch: 5| Step: 10
Training loss: 0.22239309549331665
Validation loss: 1.4537777259785643

Epoch: 469| Step: 0
Training loss: 0.1032945066690445
Validation loss: 1.4216448433937565

Epoch: 5| Step: 1
Training loss: 0.1535867303609848
Validation loss: 1.4489142587107997

Epoch: 5| Step: 2
Training loss: 0.14682617783546448
Validation loss: 1.441636008601035

Epoch: 5| Step: 3
Training loss: 0.08041547983884811
Validation loss: 1.4423177790257238

Epoch: 5| Step: 4
Training loss: 0.12639501690864563
Validation loss: 1.4171868690880396

Epoch: 5| Step: 5
Training loss: 0.0781126394867897
Validation loss: 1.4306129781148766

Epoch: 5| Step: 6
Training loss: 0.09206811338663101
Validation loss: 1.4419202112382459

Epoch: 5| Step: 7
Training loss: 0.11759614944458008
Validation loss: 1.4414184888203938

Epoch: 5| Step: 8
Training loss: 0.14409887790679932
Validation loss: 1.4298352926008162

Epoch: 5| Step: 9
Training loss: 0.1120472326874733
Validation loss: 1.4230920935189852

Epoch: 5| Step: 10
Training loss: 0.18520955741405487
Validation loss: 1.4283116568801224

Epoch: 470| Step: 0
Training loss: 0.11889448016881943
Validation loss: 1.4056180715560913

Epoch: 5| Step: 1
Training loss: 0.14528772234916687
Validation loss: 1.4034791018373223

Epoch: 5| Step: 2
Training loss: 0.10603686422109604
Validation loss: 1.431071868506811

Epoch: 5| Step: 3
Training loss: 0.08735036849975586
Validation loss: 1.450120734912093

Epoch: 5| Step: 4
Training loss: 0.10431291908025742
Validation loss: 1.4528775163876113

Epoch: 5| Step: 5
Training loss: 0.1595146507024765
Validation loss: 1.4767041821633615

Epoch: 5| Step: 6
Training loss: 0.13179390132427216
Validation loss: 1.5026671104533698

Epoch: 5| Step: 7
Training loss: 0.09656192362308502
Validation loss: 1.5036841169480355

Epoch: 5| Step: 8
Training loss: 0.1588565856218338
Validation loss: 1.5042150020599365

Epoch: 5| Step: 9
Training loss: 0.20379862189292908
Validation loss: 1.5049580886799803

Epoch: 5| Step: 10
Training loss: 0.117421954870224
Validation loss: 1.517957059285974

Epoch: 471| Step: 0
Training loss: 0.14871427416801453
Validation loss: 1.504999856795034

Epoch: 5| Step: 1
Training loss: 0.10498426109552383
Validation loss: 1.5262890631152737

Epoch: 5| Step: 2
Training loss: 0.09934721887111664
Validation loss: 1.5120241577907274

Epoch: 5| Step: 3
Training loss: 0.11775393784046173
Validation loss: 1.5378975829770487

Epoch: 5| Step: 4
Training loss: 0.10991089046001434
Validation loss: 1.5219385508568055

Epoch: 5| Step: 5
Training loss: 0.1378679722547531
Validation loss: 1.530765523192703

Epoch: 5| Step: 6
Training loss: 0.18472537398338318
Validation loss: 1.5145621594562326

Epoch: 5| Step: 7
Training loss: 0.09916474670171738
Validation loss: 1.5133234108647993

Epoch: 5| Step: 8
Training loss: 0.11813678592443466
Validation loss: 1.4817062321529593

Epoch: 5| Step: 9
Training loss: 0.09297309815883636
Validation loss: 1.4780256389289774

Epoch: 5| Step: 10
Training loss: 0.14299872517585754
Validation loss: 1.4554830725475023

Epoch: 472| Step: 0
Training loss: 0.12278374284505844
Validation loss: 1.453328791485038

Epoch: 5| Step: 1
Training loss: 0.09413586556911469
Validation loss: 1.4614978528791858

Epoch: 5| Step: 2
Training loss: 0.10941250622272491
Validation loss: 1.454775107804165

Epoch: 5| Step: 3
Training loss: 0.10602225363254547
Validation loss: 1.433608792161429

Epoch: 5| Step: 4
Training loss: 0.14988189935684204
Validation loss: 1.4356498474715857

Epoch: 5| Step: 5
Training loss: 0.11678612232208252
Validation loss: 1.441854408992234

Epoch: 5| Step: 6
Training loss: 0.14207977056503296
Validation loss: 1.41683393204084

Epoch: 5| Step: 7
Training loss: 0.1730913519859314
Validation loss: 1.436030968543022

Epoch: 5| Step: 8
Training loss: 0.13246110081672668
Validation loss: 1.404110594462323

Epoch: 5| Step: 9
Training loss: 0.11702965199947357
Validation loss: 1.434237516054543

Epoch: 5| Step: 10
Training loss: 0.09319812804460526
Validation loss: 1.4331093026745705

Epoch: 473| Step: 0
Training loss: 0.1177828460931778
Validation loss: 1.4452330675176395

Epoch: 5| Step: 1
Training loss: 0.09776224941015244
Validation loss: 1.438308318456014

Epoch: 5| Step: 2
Training loss: 0.18612147867679596
Validation loss: 1.4369805935890443

Epoch: 5| Step: 3
Training loss: 0.15130703151226044
Validation loss: 1.4381893322031984

Epoch: 5| Step: 4
Training loss: 0.0926843211054802
Validation loss: 1.4398397809715682

Epoch: 5| Step: 5
Training loss: 0.15694758296012878
Validation loss: 1.4414751773239465

Epoch: 5| Step: 6
Training loss: 0.07591591030359268
Validation loss: 1.4094312114100302

Epoch: 5| Step: 7
Training loss: 0.10146437585353851
Validation loss: 1.451142471323731

Epoch: 5| Step: 8
Training loss: 0.13860972225666046
Validation loss: 1.4320469056406329

Epoch: 5| Step: 9
Training loss: 0.08644761145114899
Validation loss: 1.4287749631430513

Epoch: 5| Step: 10
Training loss: 0.08540543168783188
Validation loss: 1.4122079213460286

Epoch: 474| Step: 0
Training loss: 0.14937995374202728
Validation loss: 1.4346167733592372

Epoch: 5| Step: 1
Training loss: 0.09120702743530273
Validation loss: 1.4481457426983824

Epoch: 5| Step: 2
Training loss: 0.15005704760551453
Validation loss: 1.4324976795463151

Epoch: 5| Step: 3
Training loss: 0.11571898311376572
Validation loss: 1.4537144412276566

Epoch: 5| Step: 4
Training loss: 0.08766167610883713
Validation loss: 1.45283341920504

Epoch: 5| Step: 5
Training loss: 0.13403935730457306
Validation loss: 1.473562535419259

Epoch: 5| Step: 6
Training loss: 0.07894933223724365
Validation loss: 1.471398941932186

Epoch: 5| Step: 7
Training loss: 0.11558288335800171
Validation loss: 1.4591965188262284

Epoch: 5| Step: 8
Training loss: 0.11501946300268173
Validation loss: 1.447841461627714

Epoch: 5| Step: 9
Training loss: 0.13371476531028748
Validation loss: 1.4641854442575926

Epoch: 5| Step: 10
Training loss: 0.1230650246143341
Validation loss: 1.4634747659006426

Epoch: 475| Step: 0
Training loss: 0.15849100053310394
Validation loss: 1.4376964364000546

Epoch: 5| Step: 1
Training loss: 0.1572657823562622
Validation loss: 1.4602380939709243

Epoch: 5| Step: 2
Training loss: 0.13484296202659607
Validation loss: 1.4619951504533009

Epoch: 5| Step: 3
Training loss: 0.16589075326919556
Validation loss: 1.42615254335506

Epoch: 5| Step: 4
Training loss: 0.11011351644992828
Validation loss: 1.460627221292065

Epoch: 5| Step: 5
Training loss: 0.09506097435951233
Validation loss: 1.4277369681225027

Epoch: 5| Step: 6
Training loss: 0.09744609892368317
Validation loss: 1.4383680576919227

Epoch: 5| Step: 7
Training loss: 0.08534133434295654
Validation loss: 1.4420646288061654

Epoch: 5| Step: 8
Training loss: 0.1361667811870575
Validation loss: 1.428437481644333

Epoch: 5| Step: 9
Training loss: 0.08212008327245712
Validation loss: 1.419917025873738

Epoch: 5| Step: 10
Training loss: 0.0671519786119461
Validation loss: 1.4156350179385113

Epoch: 476| Step: 0
Training loss: 0.11357758939266205
Validation loss: 1.4344656839165637

Epoch: 5| Step: 1
Training loss: 0.09430889040231705
Validation loss: 1.4462027870198733

Epoch: 5| Step: 2
Training loss: 0.10368714481592178
Validation loss: 1.4507684323095507

Epoch: 5| Step: 3
Training loss: 0.08208077400922775
Validation loss: 1.4707790247855648

Epoch: 5| Step: 4
Training loss: 0.16184084117412567
Validation loss: 1.4724765798097015

Epoch: 5| Step: 5
Training loss: 0.10034428536891937
Validation loss: 1.4834860281277729

Epoch: 5| Step: 6
Training loss: 0.06496305018663406
Validation loss: 1.4926856076845558

Epoch: 5| Step: 7
Training loss: 0.10589935630559921
Validation loss: 1.4962755069937757

Epoch: 5| Step: 8
Training loss: 0.12717874348163605
Validation loss: 1.4884507617642802

Epoch: 5| Step: 9
Training loss: 0.17806804180145264
Validation loss: 1.4884847389754428

Epoch: 5| Step: 10
Training loss: 0.10896819829940796
Validation loss: 1.4798636257007558

Epoch: 477| Step: 0
Training loss: 0.15288715064525604
Validation loss: 1.479633959390784

Epoch: 5| Step: 1
Training loss: 0.1303727626800537
Validation loss: 1.4915658235549927

Epoch: 5| Step: 2
Training loss: 0.11003363132476807
Validation loss: 1.5053787282718125

Epoch: 5| Step: 3
Training loss: 0.1764563024044037
Validation loss: 1.456137511038011

Epoch: 5| Step: 4
Training loss: 0.10915446281433105
Validation loss: 1.4661281326765656

Epoch: 5| Step: 5
Training loss: 0.1027979850769043
Validation loss: 1.478045585334942

Epoch: 5| Step: 6
Training loss: 0.08283346146345139
Validation loss: 1.4839102862983622

Epoch: 5| Step: 7
Training loss: 0.13896366953849792
Validation loss: 1.4894976718451387

Epoch: 5| Step: 8
Training loss: 0.097967229783535
Validation loss: 1.473625757360971

Epoch: 5| Step: 9
Training loss: 0.16007044911384583
Validation loss: 1.450781265894572

Epoch: 5| Step: 10
Training loss: 0.10465162992477417
Validation loss: 1.4354815662548106

Epoch: 478| Step: 0
Training loss: 0.11026593297719955
Validation loss: 1.3877361846226517

Epoch: 5| Step: 1
Training loss: 0.13249413669109344
Validation loss: 1.3951999679688485

Epoch: 5| Step: 2
Training loss: 0.1819799840450287
Validation loss: 1.4206899032797864

Epoch: 5| Step: 3
Training loss: 0.11678510904312134
Validation loss: 1.388620057413655

Epoch: 5| Step: 4
Training loss: 0.16397252678871155
Validation loss: 1.3952906285562823

Epoch: 5| Step: 5
Training loss: 0.11843466758728027
Validation loss: 1.386801476119667

Epoch: 5| Step: 6
Training loss: 0.14865140616893768
Validation loss: 1.4025211359864922

Epoch: 5| Step: 7
Training loss: 0.12915083765983582
Validation loss: 1.4031792430467502

Epoch: 5| Step: 8
Training loss: 0.12813472747802734
Validation loss: 1.3985177316973287

Epoch: 5| Step: 9
Training loss: 0.09050970524549484
Validation loss: 1.4138313262693343

Epoch: 5| Step: 10
Training loss: 0.07893256843090057
Validation loss: 1.4049766102144796

Epoch: 479| Step: 0
Training loss: 0.07676158845424652
Validation loss: 1.4178150264165734

Epoch: 5| Step: 1
Training loss: 0.14721600711345673
Validation loss: 1.44428079230811

Epoch: 5| Step: 2
Training loss: 0.1183323860168457
Validation loss: 1.43149140573317

Epoch: 5| Step: 3
Training loss: 0.10526560246944427
Validation loss: 1.4518504604216544

Epoch: 5| Step: 4
Training loss: 0.18528582155704498
Validation loss: 1.4308756512980307

Epoch: 5| Step: 5
Training loss: 0.09177341312170029
Validation loss: 1.434334190942908

Epoch: 5| Step: 6
Training loss: 0.11378554999828339
Validation loss: 1.4528858982106692

Epoch: 5| Step: 7
Training loss: 0.11067433655261993
Validation loss: 1.4552524166722451

Epoch: 5| Step: 8
Training loss: 0.10239050537347794
Validation loss: 1.4308391655645063

Epoch: 5| Step: 9
Training loss: 0.12623050808906555
Validation loss: 1.463526257904627

Epoch: 5| Step: 10
Training loss: 0.14709581434726715
Validation loss: 1.4462663371075866

Epoch: 480| Step: 0
Training loss: 0.137896329164505
Validation loss: 1.4693585147139847

Epoch: 5| Step: 1
Training loss: 0.11601965129375458
Validation loss: 1.4625069402879285

Epoch: 5| Step: 2
Training loss: 0.12004170566797256
Validation loss: 1.4656704292502454

Epoch: 5| Step: 3
Training loss: 0.07236610352993011
Validation loss: 1.4501269017496417

Epoch: 5| Step: 4
Training loss: 0.11904986202716827
Validation loss: 1.4701845415176884

Epoch: 5| Step: 5
Training loss: 0.13414394855499268
Validation loss: 1.478223172567224

Epoch: 5| Step: 6
Training loss: 0.19130222499370575
Validation loss: 1.4766627973125828

Epoch: 5| Step: 7
Training loss: 0.1498394012451172
Validation loss: 1.4748327270630868

Epoch: 5| Step: 8
Training loss: 0.17474408447742462
Validation loss: 1.477179447168945

Epoch: 5| Step: 9
Training loss: 0.12019910663366318
Validation loss: 1.4629801242582259

Epoch: 5| Step: 10
Training loss: 0.1141868457198143
Validation loss: 1.4801076445528256

Epoch: 481| Step: 0
Training loss: 0.12329838424921036
Validation loss: 1.4936303284860426

Epoch: 5| Step: 1
Training loss: 0.19523470103740692
Validation loss: 1.4743831516594015

Epoch: 5| Step: 2
Training loss: 0.1284065544605255
Validation loss: 1.4882826587205291

Epoch: 5| Step: 3
Training loss: 0.12371070683002472
Validation loss: 1.4659777431077854

Epoch: 5| Step: 4
Training loss: 0.13521717488765717
Validation loss: 1.4771883692792667

Epoch: 5| Step: 5
Training loss: 0.164637491106987
Validation loss: 1.4601637637743385

Epoch: 5| Step: 6
Training loss: 0.10293598473072052
Validation loss: 1.466231297421199

Epoch: 5| Step: 7
Training loss: 0.10883443057537079
Validation loss: 1.495150532773746

Epoch: 5| Step: 8
Training loss: 0.13937655091285706
Validation loss: 1.4526199422856814

Epoch: 5| Step: 9
Training loss: 0.13122625648975372
Validation loss: 1.4786217776677941

Epoch: 5| Step: 10
Training loss: 0.08218790590763092
Validation loss: 1.443359451909219

Epoch: 482| Step: 0
Training loss: 0.07320564240217209
Validation loss: 1.4525725380066903

Epoch: 5| Step: 1
Training loss: 0.11918608844280243
Validation loss: 1.438550422268529

Epoch: 5| Step: 2
Training loss: 0.1316043734550476
Validation loss: 1.465304664386216

Epoch: 5| Step: 3
Training loss: 0.1322595626115799
Validation loss: 1.4516507656343522

Epoch: 5| Step: 4
Training loss: 0.10364778339862823
Validation loss: 1.4560405144127466

Epoch: 5| Step: 5
Training loss: 0.14471547305583954
Validation loss: 1.4561187221157936

Epoch: 5| Step: 6
Training loss: 0.12600672245025635
Validation loss: 1.4375007562739874

Epoch: 5| Step: 7
Training loss: 0.0739886611700058
Validation loss: 1.467790388291882

Epoch: 5| Step: 8
Training loss: 0.10583369433879852
Validation loss: 1.4408891431746944

Epoch: 5| Step: 9
Training loss: 0.13115468621253967
Validation loss: 1.4362031695663289

Epoch: 5| Step: 10
Training loss: 0.14584603905677795
Validation loss: 1.456535472664782

Epoch: 483| Step: 0
Training loss: 0.11643006652593613
Validation loss: 1.4880857890652073

Epoch: 5| Step: 1
Training loss: 0.141153484582901
Validation loss: 1.4570172858494583

Epoch: 5| Step: 2
Training loss: 0.10396212339401245
Validation loss: 1.462586728475427

Epoch: 5| Step: 3
Training loss: 0.08645134419202805
Validation loss: 1.4791797117520404

Epoch: 5| Step: 4
Training loss: 0.09495515376329422
Validation loss: 1.5114687860652964

Epoch: 5| Step: 5
Training loss: 0.1572740375995636
Validation loss: 1.4826855992758146

Epoch: 5| Step: 6
Training loss: 0.10931148380041122
Validation loss: 1.4639161902089273

Epoch: 5| Step: 7
Training loss: 0.13329914212226868
Validation loss: 1.4500654051380772

Epoch: 5| Step: 8
Training loss: 0.13277041912078857
Validation loss: 1.4540395646966913

Epoch: 5| Step: 9
Training loss: 0.092459537088871
Validation loss: 1.4738395854990969

Epoch: 5| Step: 10
Training loss: 0.11834312975406647
Validation loss: 1.4549960718359998

Epoch: 484| Step: 0
Training loss: 0.14285996556282043
Validation loss: 1.4367039306189424

Epoch: 5| Step: 1
Training loss: 0.11745025962591171
Validation loss: 1.4302712537909066

Epoch: 5| Step: 2
Training loss: 0.07603709399700165
Validation loss: 1.430496665739244

Epoch: 5| Step: 3
Training loss: 0.11700019985437393
Validation loss: 1.4459479726770872

Epoch: 5| Step: 4
Training loss: 0.12721040844917297
Validation loss: 1.4482184199876682

Epoch: 5| Step: 5
Training loss: 0.19317471981048584
Validation loss: 1.4553187213918215

Epoch: 5| Step: 6
Training loss: 0.1944483518600464
Validation loss: 1.4584560368650703

Epoch: 5| Step: 7
Training loss: 0.09904732555150986
Validation loss: 1.503911187571864

Epoch: 5| Step: 8
Training loss: 0.10956382751464844
Validation loss: 1.4904079751301837

Epoch: 5| Step: 9
Training loss: 0.13315485417842865
Validation loss: 1.5065805950472433

Epoch: 5| Step: 10
Training loss: 0.09050792455673218
Validation loss: 1.5072578332757438

Epoch: 485| Step: 0
Training loss: 0.16457661986351013
Validation loss: 1.493261141161765

Epoch: 5| Step: 1
Training loss: 0.11101219803094864
Validation loss: 1.491355626813827

Epoch: 5| Step: 2
Training loss: 0.0683332234621048
Validation loss: 1.4733946669486262

Epoch: 5| Step: 3
Training loss: 0.1173078790307045
Validation loss: 1.4745868341897124

Epoch: 5| Step: 4
Training loss: 0.10140422731637955
Validation loss: 1.4725358665630381

Epoch: 5| Step: 5
Training loss: 0.1255841702222824
Validation loss: 1.4824507697936027

Epoch: 5| Step: 6
Training loss: 0.12378539890050888
Validation loss: 1.4814878817527526

Epoch: 5| Step: 7
Training loss: 0.08654666692018509
Validation loss: 1.4683357938643424

Epoch: 5| Step: 8
Training loss: 0.14770229160785675
Validation loss: 1.4788648377182663

Epoch: 5| Step: 9
Training loss: 0.09887832403182983
Validation loss: 1.468626582494346

Epoch: 5| Step: 10
Training loss: 0.15070690214633942
Validation loss: 1.4566415317596928

Epoch: 486| Step: 0
Training loss: 0.09145379811525345
Validation loss: 1.4551751613616943

Epoch: 5| Step: 1
Training loss: 0.11176440864801407
Validation loss: 1.4845659284181492

Epoch: 5| Step: 2
Training loss: 0.1682870090007782
Validation loss: 1.4745015918567617

Epoch: 5| Step: 3
Training loss: 0.15476253628730774
Validation loss: 1.5183476863368865

Epoch: 5| Step: 4
Training loss: 0.16508714854717255
Validation loss: 1.490837001031445

Epoch: 5| Step: 5
Training loss: 0.09300067275762558
Validation loss: 1.4849838608054704

Epoch: 5| Step: 6
Training loss: 0.1529655009508133
Validation loss: 1.4509291148954822

Epoch: 5| Step: 7
Training loss: 0.14122474193572998
Validation loss: 1.4712665311751827

Epoch: 5| Step: 8
Training loss: 0.10265401750802994
Validation loss: 1.4360142587333597

Epoch: 5| Step: 9
Training loss: 0.15609228610992432
Validation loss: 1.423549021444013

Epoch: 5| Step: 10
Training loss: 0.11386773735284805
Validation loss: 1.4261776067877328

Epoch: 487| Step: 0
Training loss: 0.11181054264307022
Validation loss: 1.4114948370123421

Epoch: 5| Step: 1
Training loss: 0.10963058471679688
Validation loss: 1.4206605194717326

Epoch: 5| Step: 2
Training loss: 0.09523279964923859
Validation loss: 1.418874208645154

Epoch: 5| Step: 3
Training loss: 0.13689711689949036
Validation loss: 1.4286831130263626

Epoch: 5| Step: 4
Training loss: 0.17349590361118317
Validation loss: 1.4302341649609227

Epoch: 5| Step: 5
Training loss: 0.2004503756761551
Validation loss: 1.420581663167605

Epoch: 5| Step: 6
Training loss: 0.17407909035682678
Validation loss: 1.4390873806450957

Epoch: 5| Step: 7
Training loss: 0.15678521990776062
Validation loss: 1.4407813933587843

Epoch: 5| Step: 8
Training loss: 0.17750166356563568
Validation loss: 1.4682902661702966

Epoch: 5| Step: 9
Training loss: 0.09404585510492325
Validation loss: 1.4911007573527675

Epoch: 5| Step: 10
Training loss: 0.11731203645467758
Validation loss: 1.498193097370927

Epoch: 488| Step: 0
Training loss: 0.1410062611103058
Validation loss: 1.4927374342436432

Epoch: 5| Step: 1
Training loss: 0.12261076271533966
Validation loss: 1.4752615280048822

Epoch: 5| Step: 2
Training loss: 0.08567741513252258
Validation loss: 1.4737643195736794

Epoch: 5| Step: 3
Training loss: 0.06671429425477982
Validation loss: 1.4606996877219087

Epoch: 5| Step: 4
Training loss: 0.12842854857444763
Validation loss: 1.4519713450503606

Epoch: 5| Step: 5
Training loss: 0.1199125200510025
Validation loss: 1.4383371645404446

Epoch: 5| Step: 6
Training loss: 0.11724333465099335
Validation loss: 1.4129146504145798

Epoch: 5| Step: 7
Training loss: 0.12140920013189316
Validation loss: 1.4172090830341462

Epoch: 5| Step: 8
Training loss: 0.17675617337226868
Validation loss: 1.4311196457955144

Epoch: 5| Step: 9
Training loss: 0.14346301555633545
Validation loss: 1.4327394795674149

Epoch: 5| Step: 10
Training loss: 0.17705190181732178
Validation loss: 1.4606151619265157

Epoch: 489| Step: 0
Training loss: 0.11298104375600815
Validation loss: 1.4436593811999086

Epoch: 5| Step: 1
Training loss: 0.13671033084392548
Validation loss: 1.474595421744931

Epoch: 5| Step: 2
Training loss: 0.09111533313989639
Validation loss: 1.4746653444023543

Epoch: 5| Step: 3
Training loss: 0.1050429716706276
Validation loss: 1.4722552299499512

Epoch: 5| Step: 4
Training loss: 0.18463583290576935
Validation loss: 1.4721391342019523

Epoch: 5| Step: 5
Training loss: 0.15950162708759308
Validation loss: 1.4699613945458525

Epoch: 5| Step: 6
Training loss: 0.10549955070018768
Validation loss: 1.453905677282682

Epoch: 5| Step: 7
Training loss: 0.08953074365854263
Validation loss: 1.45018865600709

Epoch: 5| Step: 8
Training loss: 0.06805785000324249
Validation loss: 1.431619974874681

Epoch: 5| Step: 9
Training loss: 0.12117090076208115
Validation loss: 1.396284403339509

Epoch: 5| Step: 10
Training loss: 0.080039381980896
Validation loss: 1.3962499185275006

Epoch: 490| Step: 0
Training loss: 0.12324820458889008
Validation loss: 1.4135620299205984

Epoch: 5| Step: 1
Training loss: 0.08549590408802032
Validation loss: 1.397242179480932

Epoch: 5| Step: 2
Training loss: 0.1611584573984146
Validation loss: 1.3966120391763666

Epoch: 5| Step: 3
Training loss: 0.0792461484670639
Validation loss: 1.4023313265974804

Epoch: 5| Step: 4
Training loss: 0.16644349694252014
Validation loss: 1.4005093215614237

Epoch: 5| Step: 5
Training loss: 0.07986573874950409
Validation loss: 1.4257157951272943

Epoch: 5| Step: 6
Training loss: 0.1335262954235077
Validation loss: 1.3977357059396722

Epoch: 5| Step: 7
Training loss: 0.08998353779315948
Validation loss: 1.4183553508532944

Epoch: 5| Step: 8
Training loss: 0.10257697105407715
Validation loss: 1.4427111264198058

Epoch: 5| Step: 9
Training loss: 0.09230412542819977
Validation loss: 1.4404362324745423

Epoch: 5| Step: 10
Training loss: 0.11437948793172836
Validation loss: 1.4865870347587011

Epoch: 491| Step: 0
Training loss: 0.14493556320667267
Validation loss: 1.499101278602436

Epoch: 5| Step: 1
Training loss: 0.11837911605834961
Validation loss: 1.4963632796400337

Epoch: 5| Step: 2
Training loss: 0.15771737694740295
Validation loss: 1.5032681995822537

Epoch: 5| Step: 3
Training loss: 0.1355600655078888
Validation loss: 1.5002086188203545

Epoch: 5| Step: 4
Training loss: 0.10022282600402832
Validation loss: 1.47806974123883

Epoch: 5| Step: 5
Training loss: 0.0810035914182663
Validation loss: 1.4459637698306833

Epoch: 5| Step: 6
Training loss: 0.08039100468158722
Validation loss: 1.4528834242974558

Epoch: 5| Step: 7
Training loss: 0.13972225785255432
Validation loss: 1.4099594662266393

Epoch: 5| Step: 8
Training loss: 0.13808950781822205
Validation loss: 1.4431293523439797

Epoch: 5| Step: 9
Training loss: 0.10593909025192261
Validation loss: 1.4584120909372966

Epoch: 5| Step: 10
Training loss: 0.15751692652702332
Validation loss: 1.450197155757617

Epoch: 492| Step: 0
Training loss: 0.1994568407535553
Validation loss: 1.4355501128781227

Epoch: 5| Step: 1
Training loss: 0.12704257667064667
Validation loss: 1.448523045868002

Epoch: 5| Step: 2
Training loss: 0.07281254231929779
Validation loss: 1.435634809155618

Epoch: 5| Step: 3
Training loss: 0.0917339101433754
Validation loss: 1.4602535399057532

Epoch: 5| Step: 4
Training loss: 0.08989379554986954
Validation loss: 1.4525417589372205

Epoch: 5| Step: 5
Training loss: 0.1339881420135498
Validation loss: 1.4341521019576697

Epoch: 5| Step: 6
Training loss: 0.17815139889717102
Validation loss: 1.4706144114976287

Epoch: 5| Step: 7
Training loss: 0.12483364343643188
Validation loss: 1.4638581481031192

Epoch: 5| Step: 8
Training loss: 0.10048506408929825
Validation loss: 1.4808425800774687

Epoch: 5| Step: 9
Training loss: 0.169354647397995
Validation loss: 1.455215759174798

Epoch: 5| Step: 10
Training loss: 0.058470409363508224
Validation loss: 1.4384121433381112

Epoch: 493| Step: 0
Training loss: 0.12232331931591034
Validation loss: 1.43188641917321

Epoch: 5| Step: 1
Training loss: 0.12635460495948792
Validation loss: 1.4200368196733537

Epoch: 5| Step: 2
Training loss: 0.11196668446063995
Validation loss: 1.4190966185703073

Epoch: 5| Step: 3
Training loss: 0.17846764624118805
Validation loss: 1.4139226021305207

Epoch: 5| Step: 4
Training loss: 0.11076293140649796
Validation loss: 1.3751534697830037

Epoch: 5| Step: 5
Training loss: 0.15258857607841492
Validation loss: 1.4089597540517007

Epoch: 5| Step: 6
Training loss: 0.1067890077829361
Validation loss: 1.3920645213896228

Epoch: 5| Step: 7
Training loss: 0.13773222267627716
Validation loss: 1.4188568989435832

Epoch: 5| Step: 8
Training loss: 0.09411303699016571
Validation loss: 1.4130236448780182

Epoch: 5| Step: 9
Training loss: 0.15267357230186462
Validation loss: 1.4542976515267485

Epoch: 5| Step: 10
Training loss: 0.12646137177944183
Validation loss: 1.4599070472102011

Epoch: 494| Step: 0
Training loss: 0.09249220788478851
Validation loss: 1.4546506071603427

Epoch: 5| Step: 1
Training loss: 0.14712944626808167
Validation loss: 1.4758831493316158

Epoch: 5| Step: 2
Training loss: 0.12660948932170868
Validation loss: 1.4971598117582259

Epoch: 5| Step: 3
Training loss: 0.12105731666088104
Validation loss: 1.4846212043557117

Epoch: 5| Step: 4
Training loss: 0.10987645387649536
Validation loss: 1.493098546099919

Epoch: 5| Step: 5
Training loss: 0.08613990247249603
Validation loss: 1.470645764822601

Epoch: 5| Step: 6
Training loss: 0.10839353501796722
Validation loss: 1.4924857513878935

Epoch: 5| Step: 7
Training loss: 0.115830197930336
Validation loss: 1.468573534360496

Epoch: 5| Step: 8
Training loss: 0.10172231495380402
Validation loss: 1.4346154569297709

Epoch: 5| Step: 9
Training loss: 0.1047034040093422
Validation loss: 1.4337387674598283

Epoch: 5| Step: 10
Training loss: 0.11225584149360657
Validation loss: 1.4603563688134635

Epoch: 495| Step: 0
Training loss: 0.1799522340297699
Validation loss: 1.462281673185287

Epoch: 5| Step: 1
Training loss: 0.10666348785161972
Validation loss: 1.4663227174871711

Epoch: 5| Step: 2
Training loss: 0.13697290420532227
Validation loss: 1.4472427509164298

Epoch: 5| Step: 3
Training loss: 0.20776014029979706
Validation loss: 1.4360682246505574

Epoch: 5| Step: 4
Training loss: 0.14343944191932678
Validation loss: 1.4529983433344031

Epoch: 5| Step: 5
Training loss: 0.06517480313777924
Validation loss: 1.4474907972479378

Epoch: 5| Step: 6
Training loss: 0.13326451182365417
Validation loss: 1.4517419594590382

Epoch: 5| Step: 7
Training loss: 0.08454902470111847
Validation loss: 1.474227451509045

Epoch: 5| Step: 8
Training loss: 0.1269092708826065
Validation loss: 1.4826972414088506

Epoch: 5| Step: 9
Training loss: 0.10543195903301239
Validation loss: 1.4682952921877626

Epoch: 5| Step: 10
Training loss: 0.09681672602891922
Validation loss: 1.4703686583426692

Epoch: 496| Step: 0
Training loss: 0.11131860315799713
Validation loss: 1.4662766354058379

Epoch: 5| Step: 1
Training loss: 0.12907423079013824
Validation loss: 1.4298864077496272

Epoch: 5| Step: 2
Training loss: 0.07495186477899551
Validation loss: 1.422665451162605

Epoch: 5| Step: 3
Training loss: 0.11480876058340073
Validation loss: 1.3998081453384892

Epoch: 5| Step: 4
Training loss: 0.17879772186279297
Validation loss: 1.394859625447181

Epoch: 5| Step: 5
Training loss: 0.13574159145355225
Validation loss: 1.3903413126545567

Epoch: 5| Step: 6
Training loss: 0.12382297217845917
Validation loss: 1.3937673674475761

Epoch: 5| Step: 7
Training loss: 0.10519711673259735
Validation loss: 1.3659533762162732

Epoch: 5| Step: 8
Training loss: 0.13570871949195862
Validation loss: 1.3985804319381714

Epoch: 5| Step: 9
Training loss: 0.10911047458648682
Validation loss: 1.405326932989141

Epoch: 5| Step: 10
Training loss: 0.07525234669446945
Validation loss: 1.363428988764363

Epoch: 497| Step: 0
Training loss: 0.1107560396194458
Validation loss: 1.4112419966728456

Epoch: 5| Step: 1
Training loss: 0.10257194191217422
Validation loss: 1.4106663145044798

Epoch: 5| Step: 2
Training loss: 0.10870351642370224
Validation loss: 1.4317570546621918

Epoch: 5| Step: 3
Training loss: 0.09820105135440826
Validation loss: 1.438963545266018

Epoch: 5| Step: 4
Training loss: 0.1348515748977661
Validation loss: 1.4721076655131515

Epoch: 5| Step: 5
Training loss: 0.09001240879297256
Validation loss: 1.468121563234637

Epoch: 5| Step: 6
Training loss: 0.07081319391727448
Validation loss: 1.4532629277116509

Epoch: 5| Step: 7
Training loss: 0.09680341929197311
Validation loss: 1.4542823555648967

Epoch: 5| Step: 8
Training loss: 0.09246978163719177
Validation loss: 1.4668766324238112

Epoch: 5| Step: 9
Training loss: 0.1086525171995163
Validation loss: 1.4461452775104071

Epoch: 5| Step: 10
Training loss: 0.1024542897939682
Validation loss: 1.4323660224996588

Epoch: 498| Step: 0
Training loss: 0.09311234951019287
Validation loss: 1.4416865059124526

Epoch: 5| Step: 1
Training loss: 0.15263138711452484
Validation loss: 1.4223045367066578

Epoch: 5| Step: 2
Training loss: 0.08343107253313065
Validation loss: 1.4261603099043652

Epoch: 5| Step: 3
Training loss: 0.08489076048135757
Validation loss: 1.4372822725644676

Epoch: 5| Step: 4
Training loss: 0.1453970968723297
Validation loss: 1.4526704985608336

Epoch: 5| Step: 5
Training loss: 0.09353388845920563
Validation loss: 1.4726283152898152

Epoch: 5| Step: 6
Training loss: 0.10240195691585541
Validation loss: 1.4780437190045592

Epoch: 5| Step: 7
Training loss: 0.10652454197406769
Validation loss: 1.4681791913124822

Epoch: 5| Step: 8
Training loss: 0.11307030916213989
Validation loss: 1.4722305843907018

Epoch: 5| Step: 9
Training loss: 0.12249908596277237
Validation loss: 1.475239763977707

Epoch: 5| Step: 10
Training loss: 0.19984033703804016
Validation loss: 1.4994785490856375

Epoch: 499| Step: 0
Training loss: 0.11208047717809677
Validation loss: 1.4885680201233074

Epoch: 5| Step: 1
Training loss: 0.15480737388134003
Validation loss: 1.4779091676076253

Epoch: 5| Step: 2
Training loss: 0.12565143406391144
Validation loss: 1.4968747669650662

Epoch: 5| Step: 3
Training loss: 0.13769520819187164
Validation loss: 1.478956360970774

Epoch: 5| Step: 4
Training loss: 0.06183576583862305
Validation loss: 1.46329475538705

Epoch: 5| Step: 5
Training loss: 0.08239959180355072
Validation loss: 1.4698202058833132

Epoch: 5| Step: 6
Training loss: 0.11039690673351288
Validation loss: 1.4591361425256217

Epoch: 5| Step: 7
Training loss: 0.12140953540802002
Validation loss: 1.4543077356071883

Epoch: 5| Step: 8
Training loss: 0.10946444422006607
Validation loss: 1.4476266881471038

Epoch: 5| Step: 9
Training loss: 0.13689708709716797
Validation loss: 1.4475833286521256

Epoch: 5| Step: 10
Training loss: 0.12078069150447845
Validation loss: 1.4434147880923363

Epoch: 500| Step: 0
Training loss: 0.11323346197605133
Validation loss: 1.4812967969525246

Epoch: 5| Step: 1
Training loss: 0.12466847896575928
Validation loss: 1.4496168603179276

Epoch: 5| Step: 2
Training loss: 0.1407964825630188
Validation loss: 1.441001651107624

Epoch: 5| Step: 3
Training loss: 0.12044768035411835
Validation loss: 1.4755490556839974

Epoch: 5| Step: 4
Training loss: 0.09596401453018188
Validation loss: 1.480347841016708

Epoch: 5| Step: 5
Training loss: 0.1002812385559082
Validation loss: 1.4666121339285245

Epoch: 5| Step: 6
Training loss: 0.1323046237230301
Validation loss: 1.4776468584614415

Epoch: 5| Step: 7
Training loss: 0.14120323956012726
Validation loss: 1.4855691925171883

Epoch: 5| Step: 8
Training loss: 0.08054704964160919
Validation loss: 1.4829646233589417

Epoch: 5| Step: 9
Training loss: 0.12188433110713959
Validation loss: 1.4747597594414987

Epoch: 5| Step: 10
Training loss: 0.08865758776664734
Validation loss: 1.4807487316029047

Epoch: 501| Step: 0
Training loss: 0.1378389447927475
Validation loss: 1.4754125559201805

Epoch: 5| Step: 1
Training loss: 0.12433884292840958
Validation loss: 1.4507328041138188

Epoch: 5| Step: 2
Training loss: 0.06849562376737595
Validation loss: 1.4527984050012404

Epoch: 5| Step: 3
Training loss: 0.12013909965753555
Validation loss: 1.4307338614617624

Epoch: 5| Step: 4
Training loss: 0.1296200007200241
Validation loss: 1.419141539963343

Epoch: 5| Step: 5
Training loss: 0.07663658261299133
Validation loss: 1.4259378262745437

Epoch: 5| Step: 6
Training loss: 0.08919917792081833
Validation loss: 1.463983799821587

Epoch: 5| Step: 7
Training loss: 0.1387021541595459
Validation loss: 1.456386762280618

Epoch: 5| Step: 8
Training loss: 0.11588092148303986
Validation loss: 1.4519725640614827

Epoch: 5| Step: 9
Training loss: 0.05509448051452637
Validation loss: 1.4470519006893199

Epoch: 5| Step: 10
Training loss: 0.12052507698535919
Validation loss: 1.4975177831547235

Epoch: 502| Step: 0
Training loss: 0.09981473535299301
Validation loss: 1.5124234678924724

Epoch: 5| Step: 1
Training loss: 0.09465669840574265
Validation loss: 1.4971464507041439

Epoch: 5| Step: 2
Training loss: 0.1055169552564621
Validation loss: 1.4940386254300353

Epoch: 5| Step: 3
Training loss: 0.11415068805217743
Validation loss: 1.5251415660304408

Epoch: 5| Step: 4
Training loss: 0.08028887212276459
Validation loss: 1.482957665638257

Epoch: 5| Step: 5
Training loss: 0.07694187760353088
Validation loss: 1.490468321948923

Epoch: 5| Step: 6
Training loss: 0.068821482360363
Validation loss: 1.4800923421818724

Epoch: 5| Step: 7
Training loss: 0.10559649765491486
Validation loss: 1.4491504969135407

Epoch: 5| Step: 8
Training loss: 0.11477597057819366
Validation loss: 1.4835580343841224

Epoch: 5| Step: 9
Training loss: 0.07264385372400284
Validation loss: 1.4643056854124992

Epoch: 5| Step: 10
Training loss: 0.15170271694660187
Validation loss: 1.468591708008961

Epoch: 503| Step: 0
Training loss: 0.08439880609512329
Validation loss: 1.4703703304772735

Epoch: 5| Step: 1
Training loss: 0.10091491043567657
Validation loss: 1.4559842591644616

Epoch: 5| Step: 2
Training loss: 0.13926124572753906
Validation loss: 1.455179193968414

Epoch: 5| Step: 3
Training loss: 0.0496666245162487
Validation loss: 1.450680031571337

Epoch: 5| Step: 4
Training loss: 0.07125227153301239
Validation loss: 1.4563628319771058

Epoch: 5| Step: 5
Training loss: 0.10419747978448868
Validation loss: 1.4554448627656507

Epoch: 5| Step: 6
Training loss: 0.10364779084920883
Validation loss: 1.4794100394812963

Epoch: 5| Step: 7
Training loss: 0.09372849762439728
Validation loss: 1.457914121689335

Epoch: 5| Step: 8
Training loss: 0.0997353047132492
Validation loss: 1.4814659498071159

Epoch: 5| Step: 9
Training loss: 0.10717573016881943
Validation loss: 1.4684392841913367

Epoch: 5| Step: 10
Training loss: 0.11324164271354675
Validation loss: 1.451122009625999

Epoch: 504| Step: 0
Training loss: 0.0695107951760292
Validation loss: 1.4553051071782266

Epoch: 5| Step: 1
Training loss: 0.08863145112991333
Validation loss: 1.4480746023116573

Epoch: 5| Step: 2
Training loss: 0.08975394070148468
Validation loss: 1.4535702569510347

Epoch: 5| Step: 3
Training loss: 0.08669676631689072
Validation loss: 1.438101181419947

Epoch: 5| Step: 4
Training loss: 0.13851197063922882
Validation loss: 1.4341114253126166

Epoch: 5| Step: 5
Training loss: 0.11416711658239365
Validation loss: 1.4005928642006331

Epoch: 5| Step: 6
Training loss: 0.12624278664588928
Validation loss: 1.3859381483447166

Epoch: 5| Step: 7
Training loss: 0.10247085988521576
Validation loss: 1.3629984573651386

Epoch: 5| Step: 8
Training loss: 0.07483844459056854
Validation loss: 1.3625013815459384

Epoch: 5| Step: 9
Training loss: 0.13095803558826447
Validation loss: 1.3741921519720426

Epoch: 5| Step: 10
Training loss: 0.08235485851764679
Validation loss: 1.3821091575007285

Epoch: 505| Step: 0
Training loss: 0.09549161046743393
Validation loss: 1.3705089976710658

Epoch: 5| Step: 1
Training loss: 0.1273493468761444
Validation loss: 1.395069605560713

Epoch: 5| Step: 2
Training loss: 0.13484326004981995
Validation loss: 1.4020457536943498

Epoch: 5| Step: 3
Training loss: 0.09408791363239288
Validation loss: 1.418691066003615

Epoch: 5| Step: 4
Training loss: 0.09744463860988617
Validation loss: 1.3978143539479984

Epoch: 5| Step: 5
Training loss: 0.06761357188224792
Validation loss: 1.4055116612424132

Epoch: 5| Step: 6
Training loss: 0.09796784818172455
Validation loss: 1.444761066026585

Epoch: 5| Step: 7
Training loss: 0.06432060897350311
Validation loss: 1.4209176058410316

Epoch: 5| Step: 8
Training loss: 0.12054654210805893
Validation loss: 1.4390918253570475

Epoch: 5| Step: 9
Training loss: 0.1172441691160202
Validation loss: 1.4395755696040329

Epoch: 5| Step: 10
Training loss: 0.09147945046424866
Validation loss: 1.4253110590801443

Epoch: 506| Step: 0
Training loss: 0.08915382623672485
Validation loss: 1.417744034080095

Epoch: 5| Step: 1
Training loss: 0.08779456466436386
Validation loss: 1.4271750155315603

Epoch: 5| Step: 2
Training loss: 0.0707334578037262
Validation loss: 1.421118861885481

Epoch: 5| Step: 3
Training loss: 0.07480506598949432
Validation loss: 1.4090755959992767

Epoch: 5| Step: 4
Training loss: 0.07831045240163803
Validation loss: 1.4191472440637567

Epoch: 5| Step: 5
Training loss: 0.15074190497398376
Validation loss: 1.394899715659439

Epoch: 5| Step: 6
Training loss: 0.1747717261314392
Validation loss: 1.4314504567012991

Epoch: 5| Step: 7
Training loss: 0.14409784972667694
Validation loss: 1.4174331503529702

Epoch: 5| Step: 8
Training loss: 0.1032506451010704
Validation loss: 1.4324130294143513

Epoch: 5| Step: 9
Training loss: 0.1797606348991394
Validation loss: 1.4460143453331404

Epoch: 5| Step: 10
Training loss: 0.0897061824798584
Validation loss: 1.441089129576119

Epoch: 507| Step: 0
Training loss: 0.0651431754231453
Validation loss: 1.4090068148028465

Epoch: 5| Step: 1
Training loss: 0.07080057263374329
Validation loss: 1.4322170403695875

Epoch: 5| Step: 2
Training loss: 0.055879849940538406
Validation loss: 1.4008590713624032

Epoch: 5| Step: 3
Training loss: 0.16393491625785828
Validation loss: 1.3927125212966756

Epoch: 5| Step: 4
Training loss: 0.11752712726593018
Validation loss: 1.4180401871281285

Epoch: 5| Step: 5
Training loss: 0.1306077539920807
Validation loss: 1.4060342260586318

Epoch: 5| Step: 6
Training loss: 0.108027383685112
Validation loss: 1.399472705779537

Epoch: 5| Step: 7
Training loss: 0.08698082715272903
Validation loss: 1.395465104169743

Epoch: 5| Step: 8
Training loss: 0.06301142275333405
Validation loss: 1.4261496772048294

Epoch: 5| Step: 9
Training loss: 0.15706610679626465
Validation loss: 1.4267820555676696

Epoch: 5| Step: 10
Training loss: 0.06867188960313797
Validation loss: 1.415608375303207

Epoch: 508| Step: 0
Training loss: 0.045949436724185944
Validation loss: 1.4324903988069104

Epoch: 5| Step: 1
Training loss: 0.06482997536659241
Validation loss: 1.404403055867841

Epoch: 5| Step: 2
Training loss: 0.13417553901672363
Validation loss: 1.4135182083293956

Epoch: 5| Step: 3
Training loss: 0.09354697167873383
Validation loss: 1.4192976720871464

Epoch: 5| Step: 4
Training loss: 0.09090837091207504
Validation loss: 1.4580191578916324

Epoch: 5| Step: 5
Training loss: 0.08352575451135635
Validation loss: 1.4265837246371853

Epoch: 5| Step: 6
Training loss: 0.09616938978433609
Validation loss: 1.4224645976097352

Epoch: 5| Step: 7
Training loss: 0.0986698716878891
Validation loss: 1.4480010565891062

Epoch: 5| Step: 8
Training loss: 0.0956626757979393
Validation loss: 1.4262607917990735

Epoch: 5| Step: 9
Training loss: 0.10379819571971893
Validation loss: 1.443349229392185

Epoch: 5| Step: 10
Training loss: 0.045197032392024994
Validation loss: 1.4216347868724535

Epoch: 509| Step: 0
Training loss: 0.06483453512191772
Validation loss: 1.443108643254926

Epoch: 5| Step: 1
Training loss: 0.08125988394021988
Validation loss: 1.4352044956658476

Epoch: 5| Step: 2
Training loss: 0.08990832418203354
Validation loss: 1.4304241313729236

Epoch: 5| Step: 3
Training loss: 0.12504896521568298
Validation loss: 1.4368157655962053

Epoch: 5| Step: 4
Training loss: 0.0651686042547226
Validation loss: 1.4290500135831936

Epoch: 5| Step: 5
Training loss: 0.08725243806838989
Validation loss: 1.4232920331339682

Epoch: 5| Step: 6
Training loss: 0.10213480144739151
Validation loss: 1.4178458516315748

Epoch: 5| Step: 7
Training loss: 0.10908647626638412
Validation loss: 1.4287216688997002

Epoch: 5| Step: 8
Training loss: 0.06278965622186661
Validation loss: 1.4449291101066015

Epoch: 5| Step: 9
Training loss: 0.0626736506819725
Validation loss: 1.4339358229790964

Epoch: 5| Step: 10
Training loss: 0.18735173344612122
Validation loss: 1.4593651666436145

Epoch: 510| Step: 0
Training loss: 0.0680348128080368
Validation loss: 1.4587032442451806

Epoch: 5| Step: 1
Training loss: 0.09256236255168915
Validation loss: 1.4391971422779946

Epoch: 5| Step: 2
Training loss: 0.12323349714279175
Validation loss: 1.4408266557160245

Epoch: 5| Step: 3
Training loss: 0.048575688153505325
Validation loss: 1.4436110258102417

Epoch: 5| Step: 4
Training loss: 0.10619243234395981
Validation loss: 1.434694085069882

Epoch: 5| Step: 5
Training loss: 0.10274479538202286
Validation loss: 1.461505995001844

Epoch: 5| Step: 6
Training loss: 0.08238226920366287
Validation loss: 1.4341223329626105

Epoch: 5| Step: 7
Training loss: 0.12192080914974213
Validation loss: 1.431285838926992

Epoch: 5| Step: 8
Training loss: 0.0998837798833847
Validation loss: 1.4251755283724876

Epoch: 5| Step: 9
Training loss: 0.07450789213180542
Validation loss: 1.4406134877153622

Epoch: 5| Step: 10
Training loss: 0.0852937176823616
Validation loss: 1.4219707109594857

Epoch: 511| Step: 0
Training loss: 0.10648590326309204
Validation loss: 1.4273098707199097

Epoch: 5| Step: 1
Training loss: 0.0700245276093483
Validation loss: 1.4221133608971872

Epoch: 5| Step: 2
Training loss: 0.11765997111797333
Validation loss: 1.4310076941726029

Epoch: 5| Step: 3
Training loss: 0.08179396390914917
Validation loss: 1.4422795798188897

Epoch: 5| Step: 4
Training loss: 0.06051870062947273
Validation loss: 1.4333219835835118

Epoch: 5| Step: 5
Training loss: 0.09676928073167801
Validation loss: 1.4492440095511816

Epoch: 5| Step: 6
Training loss: 0.07727095484733582
Validation loss: 1.4381677284035632

Epoch: 5| Step: 7
Training loss: 0.09567848592996597
Validation loss: 1.4233113642661803

Epoch: 5| Step: 8
Training loss: 0.11715340614318848
Validation loss: 1.417957894263729

Epoch: 5| Step: 9
Training loss: 0.09629111737012863
Validation loss: 1.421648492095291

Epoch: 5| Step: 10
Training loss: 0.11963504552841187
Validation loss: 1.434723461827924

Epoch: 512| Step: 0
Training loss: 0.09091158211231232
Validation loss: 1.4176461453078895

Epoch: 5| Step: 1
Training loss: 0.10824288427829742
Validation loss: 1.3952389865793207

Epoch: 5| Step: 2
Training loss: 0.11366629600524902
Validation loss: 1.4047566767661803

Epoch: 5| Step: 3
Training loss: 0.13033263385295868
Validation loss: 1.434990591900323

Epoch: 5| Step: 4
Training loss: 0.08592337369918823
Validation loss: 1.3916181915549821

Epoch: 5| Step: 5
Training loss: 0.14718642830848694
Validation loss: 1.4152923425038655

Epoch: 5| Step: 6
Training loss: 0.07202121615409851
Validation loss: 1.431148373952476

Epoch: 5| Step: 7
Training loss: 0.12349779903888702
Validation loss: 1.4158438649228824

Epoch: 5| Step: 8
Training loss: 0.063851498067379
Validation loss: 1.4142197024437688

Epoch: 5| Step: 9
Training loss: 0.10891421139240265
Validation loss: 1.4357416181154148

Epoch: 5| Step: 10
Training loss: 0.08757233619689941
Validation loss: 1.4445910287159744

Epoch: 513| Step: 0
Training loss: 0.15587756037712097
Validation loss: 1.4370255483094083

Epoch: 5| Step: 1
Training loss: 0.0894019678235054
Validation loss: 1.4671888332213125

Epoch: 5| Step: 2
Training loss: 0.08559047430753708
Validation loss: 1.4530950387318928

Epoch: 5| Step: 3
Training loss: 0.07262220233678818
Validation loss: 1.4484175302649056

Epoch: 5| Step: 4
Training loss: 0.07033540308475494
Validation loss: 1.4434005855232157

Epoch: 5| Step: 5
Training loss: 0.07643655687570572
Validation loss: 1.4557815764539985

Epoch: 5| Step: 6
Training loss: 0.060632579028606415
Validation loss: 1.450399782067986

Epoch: 5| Step: 7
Training loss: 0.06220216676592827
Validation loss: 1.4453309543671147

Epoch: 5| Step: 8
Training loss: 0.10771270096302032
Validation loss: 1.451742538841822

Epoch: 5| Step: 9
Training loss: 0.05684388801455498
Validation loss: 1.4810314370739845

Epoch: 5| Step: 10
Training loss: 0.08801586180925369
Validation loss: 1.4627316536441926

Epoch: 514| Step: 0
Training loss: 0.08506268262863159
Validation loss: 1.4499010014277633

Epoch: 5| Step: 1
Training loss: 0.10362778604030609
Validation loss: 1.464990613281086

Epoch: 5| Step: 2
Training loss: 0.0924372598528862
Validation loss: 1.4592828160973006

Epoch: 5| Step: 3
Training loss: 0.08753542602062225
Validation loss: 1.4797879393382738

Epoch: 5| Step: 4
Training loss: 0.15128865838050842
Validation loss: 1.4536546891735447

Epoch: 5| Step: 5
Training loss: 0.1054515689611435
Validation loss: 1.4719204889830722

Epoch: 5| Step: 6
Training loss: 0.1847383677959442
Validation loss: 1.4584243130940262

Epoch: 5| Step: 7
Training loss: 0.07774578779935837
Validation loss: 1.4435568112199024

Epoch: 5| Step: 8
Training loss: 0.10029418766498566
Validation loss: 1.4332002901261853

Epoch: 5| Step: 9
Training loss: 0.11791399866342545
Validation loss: 1.4417091120955765

Epoch: 5| Step: 10
Training loss: 0.1361813247203827
Validation loss: 1.4310359422878554

Epoch: 515| Step: 0
Training loss: 0.10305629670619965
Validation loss: 1.4832306626022502

Epoch: 5| Step: 1
Training loss: 0.10404734313488007
Validation loss: 1.453449180049281

Epoch: 5| Step: 2
Training loss: 0.12410514056682587
Validation loss: 1.4196163531272643

Epoch: 5| Step: 3
Training loss: 0.08796536922454834
Validation loss: 1.4285908181180236

Epoch: 5| Step: 4
Training loss: 0.11610684543848038
Validation loss: 1.4366103756812312

Epoch: 5| Step: 5
Training loss: 0.0978974848985672
Validation loss: 1.4227203399904313

Epoch: 5| Step: 6
Training loss: 0.07753678411245346
Validation loss: 1.458224973370952

Epoch: 5| Step: 7
Training loss: 0.10663459450006485
Validation loss: 1.4331503971930473

Epoch: 5| Step: 8
Training loss: 0.16568711400032043
Validation loss: 1.44662094372575

Epoch: 5| Step: 9
Training loss: 0.11182539165019989
Validation loss: 1.4313320056084664

Epoch: 5| Step: 10
Training loss: 0.0774158239364624
Validation loss: 1.4737662166677497

Epoch: 516| Step: 0
Training loss: 0.1402127891778946
Validation loss: 1.4595229779520342

Epoch: 5| Step: 1
Training loss: 0.13742008805274963
Validation loss: 1.4433010765301284

Epoch: 5| Step: 2
Training loss: 0.08842556178569794
Validation loss: 1.4776732408872215

Epoch: 5| Step: 3
Training loss: 0.11633031070232391
Validation loss: 1.4442108715734174

Epoch: 5| Step: 4
Training loss: 0.09451393783092499
Validation loss: 1.4600858175626366

Epoch: 5| Step: 5
Training loss: 0.09091313183307648
Validation loss: 1.4715498596109369

Epoch: 5| Step: 6
Training loss: 0.10706142336130142
Validation loss: 1.4520548082167102

Epoch: 5| Step: 7
Training loss: 0.1775229126214981
Validation loss: 1.4767903089523315

Epoch: 5| Step: 8
Training loss: 0.09687047451734543
Validation loss: 1.4594106520375898

Epoch: 5| Step: 9
Training loss: 0.10002493858337402
Validation loss: 1.4493152313334967

Epoch: 5| Step: 10
Training loss: 0.13934385776519775
Validation loss: 1.4646470187812723

Epoch: 517| Step: 0
Training loss: 0.12503978610038757
Validation loss: 1.443650414866786

Epoch: 5| Step: 1
Training loss: 0.08989446610212326
Validation loss: 1.466572758972004

Epoch: 5| Step: 2
Training loss: 0.12096254527568817
Validation loss: 1.461290971566272

Epoch: 5| Step: 3
Training loss: 0.04716781899333
Validation loss: 1.4492701227946947

Epoch: 5| Step: 4
Training loss: 0.11209598928689957
Validation loss: 1.4433576342880086

Epoch: 5| Step: 5
Training loss: 0.11265561729669571
Validation loss: 1.4336827672937864

Epoch: 5| Step: 6
Training loss: 0.07339812815189362
Validation loss: 1.435523876579859

Epoch: 5| Step: 7
Training loss: 0.10032255947589874
Validation loss: 1.4309521387982111

Epoch: 5| Step: 8
Training loss: 0.13631972670555115
Validation loss: 1.403316492675453

Epoch: 5| Step: 9
Training loss: 0.08306381851434708
Validation loss: 1.4370736883532615

Epoch: 5| Step: 10
Training loss: 0.09959157556295395
Validation loss: 1.4360165865190568

Epoch: 518| Step: 0
Training loss: 0.06073421239852905
Validation loss: 1.4420685409217753

Epoch: 5| Step: 1
Training loss: 0.07726672291755676
Validation loss: 1.4098033751210859

Epoch: 5| Step: 2
Training loss: 0.08268584311008453
Validation loss: 1.4245879483479325

Epoch: 5| Step: 3
Training loss: 0.10499083995819092
Validation loss: 1.4303086701259817

Epoch: 5| Step: 4
Training loss: 0.09557437896728516
Validation loss: 1.4368644632318968

Epoch: 5| Step: 5
Training loss: 0.0836133062839508
Validation loss: 1.4552978789934548

Epoch: 5| Step: 6
Training loss: 0.10087833553552628
Validation loss: 1.4788862684721589

Epoch: 5| Step: 7
Training loss: 0.0680142194032669
Validation loss: 1.4616183734709216

Epoch: 5| Step: 8
Training loss: 0.0826767086982727
Validation loss: 1.4812189520046275

Epoch: 5| Step: 9
Training loss: 0.08442965894937515
Validation loss: 1.4929689181748258

Epoch: 5| Step: 10
Training loss: 0.09902725368738174
Validation loss: 1.4761771117487261

Epoch: 519| Step: 0
Training loss: 0.10776933282613754
Validation loss: 1.4856740056827504

Epoch: 5| Step: 1
Training loss: 0.11272051185369492
Validation loss: 1.4721247701234714

Epoch: 5| Step: 2
Training loss: 0.10222705453634262
Validation loss: 1.4684390009090464

Epoch: 5| Step: 3
Training loss: 0.06581640988588333
Validation loss: 1.4739728896848616

Epoch: 5| Step: 4
Training loss: 0.10242986679077148
Validation loss: 1.4660415726323281

Epoch: 5| Step: 5
Training loss: 0.08294801414012909
Validation loss: 1.4405918339247346

Epoch: 5| Step: 6
Training loss: 0.08991827815771103
Validation loss: 1.46524130528973

Epoch: 5| Step: 7
Training loss: 0.05733949691057205
Validation loss: 1.4722608532956851

Epoch: 5| Step: 8
Training loss: 0.07690224796533585
Validation loss: 1.4576782539326658

Epoch: 5| Step: 9
Training loss: 0.12382962554693222
Validation loss: 1.4696739168577297

Epoch: 5| Step: 10
Training loss: 0.08010773360729218
Validation loss: 1.464462262327953

Epoch: 520| Step: 0
Training loss: 0.0843968391418457
Validation loss: 1.4201089310389694

Epoch: 5| Step: 1
Training loss: 0.07734672725200653
Validation loss: 1.463975328271107

Epoch: 5| Step: 2
Training loss: 0.0810343474149704
Validation loss: 1.4506721188945155

Epoch: 5| Step: 3
Training loss: 0.11436937004327774
Validation loss: 1.4456542332967122

Epoch: 5| Step: 4
Training loss: 0.06661687791347504
Validation loss: 1.4596934010905604

Epoch: 5| Step: 5
Training loss: 0.09108950197696686
Validation loss: 1.4645562248845254

Epoch: 5| Step: 6
Training loss: 0.10020103305578232
Validation loss: 1.4613458764168523

Epoch: 5| Step: 7
Training loss: 0.0506691038608551
Validation loss: 1.487030461270322

Epoch: 5| Step: 8
Training loss: 0.11640213429927826
Validation loss: 1.4712344113216604

Epoch: 5| Step: 9
Training loss: 0.09854535013437271
Validation loss: 1.484061559041341

Epoch: 5| Step: 10
Training loss: 0.11857851594686508
Validation loss: 1.4830289220297208

Epoch: 521| Step: 0
Training loss: 0.12015624344348907
Validation loss: 1.491164856059577

Epoch: 5| Step: 1
Training loss: 0.07846573740243912
Validation loss: 1.4631777053238244

Epoch: 5| Step: 2
Training loss: 0.07915817201137543
Validation loss: 1.4773113945479035

Epoch: 5| Step: 3
Training loss: 0.07255303114652634
Validation loss: 1.4533677037044237

Epoch: 5| Step: 4
Training loss: 0.06492939591407776
Validation loss: 1.4784597376341462

Epoch: 5| Step: 5
Training loss: 0.08412919193506241
Validation loss: 1.467553274605864

Epoch: 5| Step: 6
Training loss: 0.0699390396475792
Validation loss: 1.4857096736149122

Epoch: 5| Step: 7
Training loss: 0.08383078128099442
Validation loss: 1.4740209169285272

Epoch: 5| Step: 8
Training loss: 0.09972664713859558
Validation loss: 1.475328932526291

Epoch: 5| Step: 9
Training loss: 0.048633478581905365
Validation loss: 1.471033416768556

Epoch: 5| Step: 10
Training loss: 0.0528734028339386
Validation loss: 1.4733684960231985

Epoch: 522| Step: 0
Training loss: 0.06724709272384644
Validation loss: 1.4531608743052329

Epoch: 5| Step: 1
Training loss: 0.08559831976890564
Validation loss: 1.4376552002404326

Epoch: 5| Step: 2
Training loss: 0.05089142173528671
Validation loss: 1.448806478131202

Epoch: 5| Step: 3
Training loss: 0.13172531127929688
Validation loss: 1.4600134857239262

Epoch: 5| Step: 4
Training loss: 0.054764438420534134
Validation loss: 1.4654410449407433

Epoch: 5| Step: 5
Training loss: 0.08268053829669952
Validation loss: 1.4680378039677937

Epoch: 5| Step: 6
Training loss: 0.11952213943004608
Validation loss: 1.4767243733970068

Epoch: 5| Step: 7
Training loss: 0.07683096081018448
Validation loss: 1.4758584140449442

Epoch: 5| Step: 8
Training loss: 0.052284471690654755
Validation loss: 1.4810499222047868

Epoch: 5| Step: 9
Training loss: 0.10424450784921646
Validation loss: 1.4822018197787705

Epoch: 5| Step: 10
Training loss: 0.07817597687244415
Validation loss: 1.4912338532427305

Epoch: 523| Step: 0
Training loss: 0.1267380565404892
Validation loss: 1.4956054136317263

Epoch: 5| Step: 1
Training loss: 0.048930227756500244
Validation loss: 1.5153057447043798

Epoch: 5| Step: 2
Training loss: 0.08890806138515472
Validation loss: 1.5199367320665749

Epoch: 5| Step: 3
Training loss: 0.08161140978336334
Validation loss: 1.496810575967194

Epoch: 5| Step: 4
Training loss: 0.10471950471401215
Validation loss: 1.4765303416918683

Epoch: 5| Step: 5
Training loss: 0.09474692493677139
Validation loss: 1.4834507806326753

Epoch: 5| Step: 6
Training loss: 0.079316645860672
Validation loss: 1.4811147073263764

Epoch: 5| Step: 7
Training loss: 0.09618569165468216
Validation loss: 1.4690741710765387

Epoch: 5| Step: 8
Training loss: 0.0829649493098259
Validation loss: 1.4613371767023557

Epoch: 5| Step: 9
Training loss: 0.10133161395788193
Validation loss: 1.4619515903534428

Epoch: 5| Step: 10
Training loss: 0.09204906970262527
Validation loss: 1.4559026584830335

Epoch: 524| Step: 0
Training loss: 0.08627090603113174
Validation loss: 1.4590324612074002

Epoch: 5| Step: 1
Training loss: 0.06745314598083496
Validation loss: 1.4463830750475648

Epoch: 5| Step: 2
Training loss: 0.06910388916730881
Validation loss: 1.471183810182797

Epoch: 5| Step: 3
Training loss: 0.0764368325471878
Validation loss: 1.465638030600804

Epoch: 5| Step: 4
Training loss: 0.14114835858345032
Validation loss: 1.4673581148988457

Epoch: 5| Step: 5
Training loss: 0.09665694087743759
Validation loss: 1.4702590537327591

Epoch: 5| Step: 6
Training loss: 0.10166249424219131
Validation loss: 1.4787717737177366

Epoch: 5| Step: 7
Training loss: 0.10911066830158234
Validation loss: 1.5054263248238513

Epoch: 5| Step: 8
Training loss: 0.10553908348083496
Validation loss: 1.4787465359575005

Epoch: 5| Step: 9
Training loss: 0.09634120762348175
Validation loss: 1.5296290010534308

Epoch: 5| Step: 10
Training loss: 0.07485789060592651
Validation loss: 1.5160990562490237

Epoch: 525| Step: 0
Training loss: 0.09011757373809814
Validation loss: 1.5118905011043753

Epoch: 5| Step: 1
Training loss: 0.15597303211688995
Validation loss: 1.5174756691020022

Epoch: 5| Step: 2
Training loss: 0.12358260154724121
Validation loss: 1.502285361289978

Epoch: 5| Step: 3
Training loss: 0.07182492315769196
Validation loss: 1.5047019912350563

Epoch: 5| Step: 4
Training loss: 0.07961823791265488
Validation loss: 1.4664112124391782

Epoch: 5| Step: 5
Training loss: 0.07905689626932144
Validation loss: 1.4535382921977709

Epoch: 5| Step: 6
Training loss: 0.0723772794008255
Validation loss: 1.4508994221687317

Epoch: 5| Step: 7
Training loss: 0.07210612297058105
Validation loss: 1.4647586691764094

Epoch: 5| Step: 8
Training loss: 0.07333206385374069
Validation loss: 1.4468639416079367

Epoch: 5| Step: 9
Training loss: 0.10986864566802979
Validation loss: 1.4310390000702233

Epoch: 5| Step: 10
Training loss: 0.08356895297765732
Validation loss: 1.4608885319002214

Epoch: 526| Step: 0
Training loss: 0.08149518072605133
Validation loss: 1.457848705271239

Epoch: 5| Step: 1
Training loss: 0.11416347324848175
Validation loss: 1.4525480065294492

Epoch: 5| Step: 2
Training loss: 0.14604513347148895
Validation loss: 1.4558657958943357

Epoch: 5| Step: 3
Training loss: 0.12626414000988007
Validation loss: 1.4440136622357111

Epoch: 5| Step: 4
Training loss: 0.15548376739025116
Validation loss: 1.4299830980198358

Epoch: 5| Step: 5
Training loss: 0.08980952948331833
Validation loss: 1.4250416307039158

Epoch: 5| Step: 6
Training loss: 0.1008729487657547
Validation loss: 1.4260327508372646

Epoch: 5| Step: 7
Training loss: 0.1273329257965088
Validation loss: 1.4274364556035688

Epoch: 5| Step: 8
Training loss: 0.09951264411211014
Validation loss: 1.4184872373457877

Epoch: 5| Step: 9
Training loss: 0.09126587212085724
Validation loss: 1.4420407523391068

Epoch: 5| Step: 10
Training loss: 0.13238853216171265
Validation loss: 1.4391578564079859

Epoch: 527| Step: 0
Training loss: 0.11931729316711426
Validation loss: 1.4592382933503838

Epoch: 5| Step: 1
Training loss: 0.1234440803527832
Validation loss: 1.4539456213674238

Epoch: 5| Step: 2
Training loss: 0.10109833627939224
Validation loss: 1.4588889973137968

Epoch: 5| Step: 3
Training loss: 0.09848447144031525
Validation loss: 1.4688630680884085

Epoch: 5| Step: 4
Training loss: 0.09291156381368637
Validation loss: 1.4652335175903894

Epoch: 5| Step: 5
Training loss: 0.13431064784526825
Validation loss: 1.4553343698542605

Epoch: 5| Step: 6
Training loss: 0.12403859943151474
Validation loss: 1.4358554770869594

Epoch: 5| Step: 7
Training loss: 0.12601213157176971
Validation loss: 1.439531462166899

Epoch: 5| Step: 8
Training loss: 0.11103973537683487
Validation loss: 1.4264760530123146

Epoch: 5| Step: 9
Training loss: 0.07898344099521637
Validation loss: 1.4423474470774333

Epoch: 5| Step: 10
Training loss: 0.11981520801782608
Validation loss: 1.4404718004247195

Epoch: 528| Step: 0
Training loss: 0.10680005699396133
Validation loss: 1.4261658896682083

Epoch: 5| Step: 1
Training loss: 0.08510886132717133
Validation loss: 1.4456515491649669

Epoch: 5| Step: 2
Training loss: 0.12167000770568848
Validation loss: 1.459986266910389

Epoch: 5| Step: 3
Training loss: 0.07414083927869797
Validation loss: 1.4801640446468065

Epoch: 5| Step: 4
Training loss: 0.14517608284950256
Validation loss: 1.4770318333820631

Epoch: 5| Step: 5
Training loss: 0.14330098032951355
Validation loss: 1.4861356660883913

Epoch: 5| Step: 6
Training loss: 0.14289239048957825
Validation loss: 1.4954036871592205

Epoch: 5| Step: 7
Training loss: 0.14343729615211487
Validation loss: 1.4925706771112257

Epoch: 5| Step: 8
Training loss: 0.09489364176988602
Validation loss: 1.5029639441479918

Epoch: 5| Step: 9
Training loss: 0.11466703563928604
Validation loss: 1.4842935300642444

Epoch: 5| Step: 10
Training loss: 0.06523189693689346
Validation loss: 1.456387927455287

Epoch: 529| Step: 0
Training loss: 0.06535669416189194
Validation loss: 1.455030821984814

Epoch: 5| Step: 1
Training loss: 0.08762781322002411
Validation loss: 1.4514927735892675

Epoch: 5| Step: 2
Training loss: 0.07957103103399277
Validation loss: 1.4366299433092917

Epoch: 5| Step: 3
Training loss: 0.08076850324869156
Validation loss: 1.4181856339977634

Epoch: 5| Step: 4
Training loss: 0.09619373828172684
Validation loss: 1.4344642123868387

Epoch: 5| Step: 5
Training loss: 0.1164635643362999
Validation loss: 1.413944931440456

Epoch: 5| Step: 6
Training loss: 0.08677277714014053
Validation loss: 1.4391039494545228

Epoch: 5| Step: 7
Training loss: 0.11330501735210419
Validation loss: 1.4368378295693347

Epoch: 5| Step: 8
Training loss: 0.09414704889059067
Validation loss: 1.4341386941171461

Epoch: 5| Step: 9
Training loss: 0.10038803517818451
Validation loss: 1.4351241844956593

Epoch: 5| Step: 10
Training loss: 0.09192197769880295
Validation loss: 1.4538449254087222

Epoch: 530| Step: 0
Training loss: 0.050087083131074905
Validation loss: 1.4754612080512508

Epoch: 5| Step: 1
Training loss: 0.13827559351921082
Validation loss: 1.478284466651178

Epoch: 5| Step: 2
Training loss: 0.05708320066332817
Validation loss: 1.442279319609365

Epoch: 5| Step: 3
Training loss: 0.10766507685184479
Validation loss: 1.432256975481587

Epoch: 5| Step: 4
Training loss: 0.1161486878991127
Validation loss: 1.4486945149719075

Epoch: 5| Step: 5
Training loss: 0.08311114460229874
Validation loss: 1.4172258710348478

Epoch: 5| Step: 6
Training loss: 0.11952836811542511
Validation loss: 1.4264655664402952

Epoch: 5| Step: 7
Training loss: 0.07593240588903427
Validation loss: 1.4368502266945378

Epoch: 5| Step: 8
Training loss: 0.06593825668096542
Validation loss: 1.4348033012882355

Epoch: 5| Step: 9
Training loss: 0.09830093383789062
Validation loss: 1.4358721792056997

Epoch: 5| Step: 10
Training loss: 0.06704695522785187
Validation loss: 1.4305234211747364

Epoch: 531| Step: 0
Training loss: 0.07503850758075714
Validation loss: 1.4181366697434457

Epoch: 5| Step: 1
Training loss: 0.09279022365808487
Validation loss: 1.424549553983955

Epoch: 5| Step: 2
Training loss: 0.04970914125442505
Validation loss: 1.437844726347154

Epoch: 5| Step: 3
Training loss: 0.08971143513917923
Validation loss: 1.4265772591355026

Epoch: 5| Step: 4
Training loss: 0.06771205365657806
Validation loss: 1.433230052712143

Epoch: 5| Step: 5
Training loss: 0.07775072753429413
Validation loss: 1.4206215079112718

Epoch: 5| Step: 6
Training loss: 0.06008658558130264
Validation loss: 1.4399608437732985

Epoch: 5| Step: 7
Training loss: 0.06600028276443481
Validation loss: 1.4182165771402337

Epoch: 5| Step: 8
Training loss: 0.10826077312231064
Validation loss: 1.3954481309460056

Epoch: 5| Step: 9
Training loss: 0.08582434803247452
Validation loss: 1.4035361447641928

Epoch: 5| Step: 10
Training loss: 0.11178156733512878
Validation loss: 1.445031346813325

Epoch: 532| Step: 0
Training loss: 0.08397118747234344
Validation loss: 1.4406640850087649

Epoch: 5| Step: 1
Training loss: 0.11246390640735626
Validation loss: 1.424143281034244

Epoch: 5| Step: 2
Training loss: 0.07861728966236115
Validation loss: 1.4226900851854714

Epoch: 5| Step: 3
Training loss: 0.11579015105962753
Validation loss: 1.4358714876636383

Epoch: 5| Step: 4
Training loss: 0.05418219417333603
Validation loss: 1.445481183708355

Epoch: 5| Step: 5
Training loss: 0.05690283700823784
Validation loss: 1.4484305074138026

Epoch: 5| Step: 6
Training loss: 0.08856328576803207
Validation loss: 1.454287367482339

Epoch: 5| Step: 7
Training loss: 0.10296578705310822
Validation loss: 1.4466377605674088

Epoch: 5| Step: 8
Training loss: 0.0550788938999176
Validation loss: 1.4497458896329325

Epoch: 5| Step: 9
Training loss: 0.06942666321992874
Validation loss: 1.4556285931218056

Epoch: 5| Step: 10
Training loss: 0.059301700443029404
Validation loss: 1.440120138147826

Epoch: 533| Step: 0
Training loss: 0.086871437728405
Validation loss: 1.4637572367986043

Epoch: 5| Step: 1
Training loss: 0.09043915569782257
Validation loss: 1.457857939504808

Epoch: 5| Step: 2
Training loss: 0.050102777779102325
Validation loss: 1.4675150263694026

Epoch: 5| Step: 3
Training loss: 0.05113445967435837
Validation loss: 1.4687053529165124

Epoch: 5| Step: 4
Training loss: 0.09911797940731049
Validation loss: 1.4650054490694435

Epoch: 5| Step: 5
Training loss: 0.10832337290048599
Validation loss: 1.4426342671917332

Epoch: 5| Step: 6
Training loss: 0.0875987857580185
Validation loss: 1.4525686169183383

Epoch: 5| Step: 7
Training loss: 0.05497617647051811
Validation loss: 1.4584099310700611

Epoch: 5| Step: 8
Training loss: 0.0685276985168457
Validation loss: 1.4666438987178188

Epoch: 5| Step: 9
Training loss: 0.0966128259897232
Validation loss: 1.4431551502596947

Epoch: 5| Step: 10
Training loss: 0.09154863655567169
Validation loss: 1.4493049703618532

Epoch: 534| Step: 0
Training loss: 0.11396102607250214
Validation loss: 1.4480579937658002

Epoch: 5| Step: 1
Training loss: 0.11972012370824814
Validation loss: 1.452573977490907

Epoch: 5| Step: 2
Training loss: 0.11995768547058105
Validation loss: 1.4609016295402282

Epoch: 5| Step: 3
Training loss: 0.09465577453374863
Validation loss: 1.457777471952541

Epoch: 5| Step: 4
Training loss: 0.10703333467245102
Validation loss: 1.45443263617895

Epoch: 5| Step: 5
Training loss: 0.09496693313121796
Validation loss: 1.4406659244209208

Epoch: 5| Step: 6
Training loss: 0.05837716907262802
Validation loss: 1.4191622593069588

Epoch: 5| Step: 7
Training loss: 0.0745180994272232
Validation loss: 1.445921564614901

Epoch: 5| Step: 8
Training loss: 0.08103619515895844
Validation loss: 1.4426760468431699

Epoch: 5| Step: 9
Training loss: 0.10057709366083145
Validation loss: 1.443692761082803

Epoch: 5| Step: 10
Training loss: 0.12512366473674774
Validation loss: 1.43641685798604

Epoch: 535| Step: 0
Training loss: 0.08142735064029694
Validation loss: 1.4151130004595684

Epoch: 5| Step: 1
Training loss: 0.10767717659473419
Validation loss: 1.4225619121264386

Epoch: 5| Step: 2
Training loss: 0.10249301046133041
Validation loss: 1.4295264867044264

Epoch: 5| Step: 3
Training loss: 0.07768188416957855
Validation loss: 1.4586617459533036

Epoch: 5| Step: 4
Training loss: 0.15682010352611542
Validation loss: 1.4069818501831384

Epoch: 5| Step: 5
Training loss: 0.09505990892648697
Validation loss: 1.445917623017424

Epoch: 5| Step: 6
Training loss: 0.1353941261768341
Validation loss: 1.4556475864943637

Epoch: 5| Step: 7
Training loss: 0.07967711985111237
Validation loss: 1.451544992385372

Epoch: 5| Step: 8
Training loss: 0.06312956660985947
Validation loss: 1.4838969669034403

Epoch: 5| Step: 9
Training loss: 0.07040926069021225
Validation loss: 1.4630131772769395

Epoch: 5| Step: 10
Training loss: 0.07239241898059845
Validation loss: 1.4793981082977787

Epoch: 536| Step: 0
Training loss: 0.06345397233963013
Validation loss: 1.466038639186531

Epoch: 5| Step: 1
Training loss: 0.09166468679904938
Validation loss: 1.4763277115360383

Epoch: 5| Step: 2
Training loss: 0.09252077341079712
Validation loss: 1.467166139233497

Epoch: 5| Step: 3
Training loss: 0.11621977388858795
Validation loss: 1.4415338052216398

Epoch: 5| Step: 4
Training loss: 0.1033407598733902
Validation loss: 1.4222312120981113

Epoch: 5| Step: 5
Training loss: 0.06164367124438286
Validation loss: 1.443211640081098

Epoch: 5| Step: 6
Training loss: 0.11561711877584457
Validation loss: 1.449369248523507

Epoch: 5| Step: 7
Training loss: 0.07583256810903549
Validation loss: 1.4446667599421676

Epoch: 5| Step: 8
Training loss: 0.11391837894916534
Validation loss: 1.455893842122888

Epoch: 5| Step: 9
Training loss: 0.09940614551305771
Validation loss: 1.457971275493663

Epoch: 5| Step: 10
Training loss: 0.19751186668872833
Validation loss: 1.4618145445341706

Epoch: 537| Step: 0
Training loss: 0.12491334974765778
Validation loss: 1.4575853475960352

Epoch: 5| Step: 1
Training loss: 0.11828817427158356
Validation loss: 1.466292219777261

Epoch: 5| Step: 2
Training loss: 0.13294491171836853
Validation loss: 1.4730700549258982

Epoch: 5| Step: 3
Training loss: 0.0834023505449295
Validation loss: 1.4644292669911538

Epoch: 5| Step: 4
Training loss: 0.10000930726528168
Validation loss: 1.4851658023813719

Epoch: 5| Step: 5
Training loss: 0.057632189244031906
Validation loss: 1.4675810567794307

Epoch: 5| Step: 6
Training loss: 0.08891654759645462
Validation loss: 1.4694808401087278

Epoch: 5| Step: 7
Training loss: 0.11579267680644989
Validation loss: 1.435485189960849

Epoch: 5| Step: 8
Training loss: 0.11994063854217529
Validation loss: 1.4293608697511817

Epoch: 5| Step: 9
Training loss: 0.07480017840862274
Validation loss: 1.4230132974604124

Epoch: 5| Step: 10
Training loss: 0.07425873726606369
Validation loss: 1.4140943070893646

Epoch: 538| Step: 0
Training loss: 0.11598458141088486
Validation loss: 1.3866935391579904

Epoch: 5| Step: 1
Training loss: 0.1265898197889328
Validation loss: 1.4138329426447551

Epoch: 5| Step: 2
Training loss: 0.09023682773113251
Validation loss: 1.4258678100442375

Epoch: 5| Step: 3
Training loss: 0.06998509168624878
Validation loss: 1.4159595466429187

Epoch: 5| Step: 4
Training loss: 0.08731336891651154
Validation loss: 1.443475014419966

Epoch: 5| Step: 5
Training loss: 0.13320821523666382
Validation loss: 1.432243647113923

Epoch: 5| Step: 6
Training loss: 0.11244680732488632
Validation loss: 1.4546358457175634

Epoch: 5| Step: 7
Training loss: 0.10004565864801407
Validation loss: 1.4756554813795193

Epoch: 5| Step: 8
Training loss: 0.09863012284040451
Validation loss: 1.4996109047243673

Epoch: 5| Step: 9
Training loss: 0.10573776066303253
Validation loss: 1.4816890608879827

Epoch: 5| Step: 10
Training loss: 0.05310850962996483
Validation loss: 1.495323218325133

Epoch: 539| Step: 0
Training loss: 0.12000508606433868
Validation loss: 1.5256685133903258

Epoch: 5| Step: 1
Training loss: 0.09116005152463913
Validation loss: 1.4958442859752203

Epoch: 5| Step: 2
Training loss: 0.04409913718700409
Validation loss: 1.504318098868093

Epoch: 5| Step: 3
Training loss: 0.05475149303674698
Validation loss: 1.4755262174913961

Epoch: 5| Step: 4
Training loss: 0.10061495006084442
Validation loss: 1.4738374166591193

Epoch: 5| Step: 5
Training loss: 0.0971289798617363
Validation loss: 1.4600701268001268

Epoch: 5| Step: 6
Training loss: 0.08426203578710556
Validation loss: 1.4616082240176458

Epoch: 5| Step: 7
Training loss: 0.07633914053440094
Validation loss: 1.4457815436906711

Epoch: 5| Step: 8
Training loss: 0.13327232003211975
Validation loss: 1.451983287770261

Epoch: 5| Step: 9
Training loss: 0.07865507900714874
Validation loss: 1.4487141434864332

Epoch: 5| Step: 10
Training loss: 0.07046042382717133
Validation loss: 1.5025684602798954

Epoch: 540| Step: 0
Training loss: 0.10177856683731079
Validation loss: 1.4757546058265112

Epoch: 5| Step: 1
Training loss: 0.0889376848936081
Validation loss: 1.4684235677924207

Epoch: 5| Step: 2
Training loss: 0.09413234889507294
Validation loss: 1.4801729789344213

Epoch: 5| Step: 3
Training loss: 0.08594696968793869
Validation loss: 1.4864243384330504

Epoch: 5| Step: 4
Training loss: 0.0657244473695755
Validation loss: 1.4659269189321866

Epoch: 5| Step: 5
Training loss: 0.08178301155567169
Validation loss: 1.4473466616804882

Epoch: 5| Step: 6
Training loss: 0.059790778905153275
Validation loss: 1.4326421471052273

Epoch: 5| Step: 7
Training loss: 0.06273532658815384
Validation loss: 1.464056461088119

Epoch: 5| Step: 8
Training loss: 0.07667958736419678
Validation loss: 1.434672688925138

Epoch: 5| Step: 9
Training loss: 0.06700839847326279
Validation loss: 1.4371665370079778

Epoch: 5| Step: 10
Training loss: 0.0954802930355072
Validation loss: 1.4295422210488269

Epoch: 541| Step: 0
Training loss: 0.08646250516176224
Validation loss: 1.4574846683009979

Epoch: 5| Step: 1
Training loss: 0.11329860985279083
Validation loss: 1.4540988168408793

Epoch: 5| Step: 2
Training loss: 0.10512389242649078
Validation loss: 1.4944211629129225

Epoch: 5| Step: 3
Training loss: 0.11598128080368042
Validation loss: 1.48116764971005

Epoch: 5| Step: 4
Training loss: 0.06520788371562958
Validation loss: 1.4874913141291628

Epoch: 5| Step: 5
Training loss: 0.1316460818052292
Validation loss: 1.4645911352608794

Epoch: 5| Step: 6
Training loss: 0.06928280740976334
Validation loss: 1.450708999428698

Epoch: 5| Step: 7
Training loss: 0.09581136703491211
Validation loss: 1.4626294028374456

Epoch: 5| Step: 8
Training loss: 0.08937903493642807
Validation loss: 1.4806051510636524

Epoch: 5| Step: 9
Training loss: 0.08902116119861603
Validation loss: 1.4687958443036644

Epoch: 5| Step: 10
Training loss: 0.06652477383613586
Validation loss: 1.4856869661679832

Epoch: 542| Step: 0
Training loss: 0.13782374560832977
Validation loss: 1.4818590597439838

Epoch: 5| Step: 1
Training loss: 0.14456790685653687
Validation loss: 1.4653721765805316

Epoch: 5| Step: 2
Training loss: 0.07773247361183167
Validation loss: 1.436258235285359

Epoch: 5| Step: 3
Training loss: 0.10527364164590836
Validation loss: 1.438629509300314

Epoch: 5| Step: 4
Training loss: 0.14257186651229858
Validation loss: 1.4497344711775422

Epoch: 5| Step: 5
Training loss: 0.10525834560394287
Validation loss: 1.4280280977167108

Epoch: 5| Step: 6
Training loss: 0.09641001373529434
Validation loss: 1.4358658482951503

Epoch: 5| Step: 7
Training loss: 0.07954833656549454
Validation loss: 1.444952763536925

Epoch: 5| Step: 8
Training loss: 0.11142220348119736
Validation loss: 1.437091286464404

Epoch: 5| Step: 9
Training loss: 0.07276622205972672
Validation loss: 1.4283523572388517

Epoch: 5| Step: 10
Training loss: 0.10548041760921478
Validation loss: 1.4196298609497726

Epoch: 543| Step: 0
Training loss: 0.118119016289711
Validation loss: 1.435433837675279

Epoch: 5| Step: 1
Training loss: 0.08040042221546173
Validation loss: 1.4396197385685419

Epoch: 5| Step: 2
Training loss: 0.11899030208587646
Validation loss: 1.446163849164081

Epoch: 5| Step: 3
Training loss: 0.1454300880432129
Validation loss: 1.4524983039466284

Epoch: 5| Step: 4
Training loss: 0.08781912922859192
Validation loss: 1.4597860805449947

Epoch: 5| Step: 5
Training loss: 0.0671503096818924
Validation loss: 1.436695271922696

Epoch: 5| Step: 6
Training loss: 0.05780733749270439
Validation loss: 1.4225204061436396

Epoch: 5| Step: 7
Training loss: 0.0683547705411911
Validation loss: 1.4680060955785936

Epoch: 5| Step: 8
Training loss: 0.11937697231769562
Validation loss: 1.4719296309255785

Epoch: 5| Step: 9
Training loss: 0.08881352096796036
Validation loss: 1.4672790073579358

Epoch: 5| Step: 10
Training loss: 0.09572725743055344
Validation loss: 1.4667163895022484

Epoch: 544| Step: 0
Training loss: 0.08332371711730957
Validation loss: 1.4659498160885227

Epoch: 5| Step: 1
Training loss: 0.06946508586406708
Validation loss: 1.445779477396319

Epoch: 5| Step: 2
Training loss: 0.12679600715637207
Validation loss: 1.4562221483517719

Epoch: 5| Step: 3
Training loss: 0.1059361919760704
Validation loss: 1.4768987714603383

Epoch: 5| Step: 4
Training loss: 0.0632011666893959
Validation loss: 1.4650086561838787

Epoch: 5| Step: 5
Training loss: 0.09547658264636993
Validation loss: 1.4668419527751144

Epoch: 5| Step: 6
Training loss: 0.08999716490507126
Validation loss: 1.4610656487044467

Epoch: 5| Step: 7
Training loss: 0.07558263838291168
Validation loss: 1.4710963938825874

Epoch: 5| Step: 8
Training loss: 0.07689999043941498
Validation loss: 1.4596968427781136

Epoch: 5| Step: 9
Training loss: 0.09789340198040009
Validation loss: 1.4511404075930197

Epoch: 5| Step: 10
Training loss: 0.09282097965478897
Validation loss: 1.4585734259697698

Epoch: 545| Step: 0
Training loss: 0.0795886218547821
Validation loss: 1.4575052479261994

Epoch: 5| Step: 1
Training loss: 0.0826566070318222
Validation loss: 1.440822474418148

Epoch: 5| Step: 2
Training loss: 0.0662812814116478
Validation loss: 1.4284109325819119

Epoch: 5| Step: 3
Training loss: 0.09109312295913696
Validation loss: 1.4046051297136533

Epoch: 5| Step: 4
Training loss: 0.049006856977939606
Validation loss: 1.4156485475519651

Epoch: 5| Step: 5
Training loss: 0.13204732537269592
Validation loss: 1.4411077371207617

Epoch: 5| Step: 6
Training loss: 0.08663146197795868
Validation loss: 1.4263364166341803

Epoch: 5| Step: 7
Training loss: 0.09006597101688385
Validation loss: 1.419041827160825

Epoch: 5| Step: 8
Training loss: 0.07507695257663727
Validation loss: 1.4395818453963085

Epoch: 5| Step: 9
Training loss: 0.07927223294973373
Validation loss: 1.4561581752633537

Epoch: 5| Step: 10
Training loss: 0.12363018840551376
Validation loss: 1.4508967091960292

Epoch: 546| Step: 0
Training loss: 0.06789279729127884
Validation loss: 1.4784199678769676

Epoch: 5| Step: 1
Training loss: 0.09191649407148361
Validation loss: 1.4837227316312893

Epoch: 5| Step: 2
Training loss: 0.0711045190691948
Validation loss: 1.4915921867534678

Epoch: 5| Step: 3
Training loss: 0.10672086477279663
Validation loss: 1.5103805244609874

Epoch: 5| Step: 4
Training loss: 0.14569896459579468
Validation loss: 1.4989430789024598

Epoch: 5| Step: 5
Training loss: 0.05254911258816719
Validation loss: 1.494907553477954

Epoch: 5| Step: 6
Training loss: 0.05628851801156998
Validation loss: 1.5072314482863232

Epoch: 5| Step: 7
Training loss: 0.0910523384809494
Validation loss: 1.5035996795982443

Epoch: 5| Step: 8
Training loss: 0.06301571428775787
Validation loss: 1.4860951515936083

Epoch: 5| Step: 9
Training loss: 0.09188475459814072
Validation loss: 1.4688807533633323

Epoch: 5| Step: 10
Training loss: 0.08022570610046387
Validation loss: 1.4632836400821645

Epoch: 547| Step: 0
Training loss: 0.08418123424053192
Validation loss: 1.4693530631321732

Epoch: 5| Step: 1
Training loss: 0.06052107736468315
Validation loss: 1.4694747911986483

Epoch: 5| Step: 2
Training loss: 0.07102195918560028
Validation loss: 1.4503561771044167

Epoch: 5| Step: 3
Training loss: 0.1166149228811264
Validation loss: 1.4585027681883944

Epoch: 5| Step: 4
Training loss: 0.08009153604507446
Validation loss: 1.4504472132652038

Epoch: 5| Step: 5
Training loss: 0.09778934717178345
Validation loss: 1.4409299524881507

Epoch: 5| Step: 6
Training loss: 0.09455116093158722
Validation loss: 1.462344261907762

Epoch: 5| Step: 7
Training loss: 0.09345147758722305
Validation loss: 1.476586828949631

Epoch: 5| Step: 8
Training loss: 0.061791133135557175
Validation loss: 1.4669764452083136

Epoch: 5| Step: 9
Training loss: 0.08632658421993256
Validation loss: 1.4465835825089486

Epoch: 5| Step: 10
Training loss: 0.07485701143741608
Validation loss: 1.4438447260087537

Epoch: 548| Step: 0
Training loss: 0.05367342755198479
Validation loss: 1.4762993038341563

Epoch: 5| Step: 1
Training loss: 0.09148254245519638
Validation loss: 1.4782126731770013

Epoch: 5| Step: 2
Training loss: 0.106356680393219
Validation loss: 1.4585766715388144

Epoch: 5| Step: 3
Training loss: 0.04937819391489029
Validation loss: 1.4553019769730107

Epoch: 5| Step: 4
Training loss: 0.09137706458568573
Validation loss: 1.4614466646666169

Epoch: 5| Step: 5
Training loss: 0.07946296781301498
Validation loss: 1.476163366789459

Epoch: 5| Step: 6
Training loss: 0.07208793610334396
Validation loss: 1.437223921539963

Epoch: 5| Step: 7
Training loss: 0.07486698776483536
Validation loss: 1.4554828687380719

Epoch: 5| Step: 8
Training loss: 0.12799768149852753
Validation loss: 1.4415508034408733

Epoch: 5| Step: 9
Training loss: 0.0939948707818985
Validation loss: 1.4589678741270495

Epoch: 5| Step: 10
Training loss: 0.05265854299068451
Validation loss: 1.4835257991667716

Epoch: 549| Step: 0
Training loss: 0.06230410188436508
Validation loss: 1.4632047030233568

Epoch: 5| Step: 1
Training loss: 0.08977013826370239
Validation loss: 1.4710964861736502

Epoch: 5| Step: 2
Training loss: 0.06260543316602707
Validation loss: 1.4607711991956156

Epoch: 5| Step: 3
Training loss: 0.06460434198379517
Validation loss: 1.496951042323984

Epoch: 5| Step: 4
Training loss: 0.07881853729486465
Validation loss: 1.4867300038696618

Epoch: 5| Step: 5
Training loss: 0.11934053897857666
Validation loss: 1.4634493153582337

Epoch: 5| Step: 6
Training loss: 0.08299686759710312
Validation loss: 1.460355334384467

Epoch: 5| Step: 7
Training loss: 0.06513173878192902
Validation loss: 1.4689917666937715

Epoch: 5| Step: 8
Training loss: 0.0666080042719841
Validation loss: 1.4588552758257876

Epoch: 5| Step: 9
Training loss: 0.13368737697601318
Validation loss: 1.4407857195023568

Epoch: 5| Step: 10
Training loss: 0.08363863080739975
Validation loss: 1.4496270571985552

Epoch: 550| Step: 0
Training loss: 0.08038493245840073
Validation loss: 1.4432626270478772

Epoch: 5| Step: 1
Training loss: 0.07586844265460968
Validation loss: 1.451293199293075

Epoch: 5| Step: 2
Training loss: 0.08463037759065628
Validation loss: 1.4428023586991012

Epoch: 5| Step: 3
Training loss: 0.06338073313236237
Validation loss: 1.4839433739262242

Epoch: 5| Step: 4
Training loss: 0.10236432403326035
Validation loss: 1.458552332334621

Epoch: 5| Step: 5
Training loss: 0.10152025520801544
Validation loss: 1.468493506472598

Epoch: 5| Step: 6
Training loss: 0.08466251939535141
Validation loss: 1.4629171561169367

Epoch: 5| Step: 7
Training loss: 0.08600227534770966
Validation loss: 1.4773146670351747

Epoch: 5| Step: 8
Training loss: 0.049359533935785294
Validation loss: 1.4620306030396493

Epoch: 5| Step: 9
Training loss: 0.11224508285522461
Validation loss: 1.4869538289244457

Epoch: 5| Step: 10
Training loss: 0.05799159035086632
Validation loss: 1.4668457815724034

Epoch: 551| Step: 0
Training loss: 0.10079006850719452
Validation loss: 1.4635555539079892

Epoch: 5| Step: 1
Training loss: 0.06514936685562134
Validation loss: 1.4879411894788024

Epoch: 5| Step: 2
Training loss: 0.12286455929279327
Validation loss: 1.5067525550883303

Epoch: 5| Step: 3
Training loss: 0.07485951483249664
Validation loss: 1.5081823718163274

Epoch: 5| Step: 4
Training loss: 0.04017831012606621
Validation loss: 1.4941444717427736

Epoch: 5| Step: 5
Training loss: 0.07783795148134232
Validation loss: 1.4971933403322775

Epoch: 5| Step: 6
Training loss: 0.07579962909221649
Validation loss: 1.4958125698950984

Epoch: 5| Step: 7
Training loss: 0.10486046224832535
Validation loss: 1.44873422063807

Epoch: 5| Step: 8
Training loss: 0.08165447413921356
Validation loss: 1.4704709950313772

Epoch: 5| Step: 9
Training loss: 0.10826754570007324
Validation loss: 1.4758322783695754

Epoch: 5| Step: 10
Training loss: 0.08782324939966202
Validation loss: 1.456773970716743

Epoch: 552| Step: 0
Training loss: 0.0932939350605011
Validation loss: 1.4567044781100364

Epoch: 5| Step: 1
Training loss: 0.10818056762218475
Validation loss: 1.465928267407161

Epoch: 5| Step: 2
Training loss: 0.08243964612483978
Validation loss: 1.4866635081588582

Epoch: 5| Step: 3
Training loss: 0.07116930931806564
Validation loss: 1.4686549825053061

Epoch: 5| Step: 4
Training loss: 0.05755283683538437
Validation loss: 1.4992749332099833

Epoch: 5| Step: 5
Training loss: 0.08245201408863068
Validation loss: 1.5000293011306434

Epoch: 5| Step: 6
Training loss: 0.13781553506851196
Validation loss: 1.4956265476442152

Epoch: 5| Step: 7
Training loss: 0.15462221205234528
Validation loss: 1.4848240229391283

Epoch: 5| Step: 8
Training loss: 0.09852973371744156
Validation loss: 1.4694568277687154

Epoch: 5| Step: 9
Training loss: 0.0996706634759903
Validation loss: 1.4560593443532144

Epoch: 5| Step: 10
Training loss: 0.07482974976301193
Validation loss: 1.4448074435675016

Epoch: 553| Step: 0
Training loss: 0.09779606759548187
Validation loss: 1.4468125104904175

Epoch: 5| Step: 1
Training loss: 0.11406457424163818
Validation loss: 1.4493630547677316

Epoch: 5| Step: 2
Training loss: 0.07318642735481262
Validation loss: 1.4356173110264603

Epoch: 5| Step: 3
Training loss: 0.05709853023290634
Validation loss: 1.4232290150016866

Epoch: 5| Step: 4
Training loss: 0.09693010151386261
Validation loss: 1.4095701299687868

Epoch: 5| Step: 5
Training loss: 0.07156787812709808
Validation loss: 1.4266720907662505

Epoch: 5| Step: 6
Training loss: 0.09244464337825775
Validation loss: 1.4026093572698615

Epoch: 5| Step: 7
Training loss: 0.1534276306629181
Validation loss: 1.3980962909677976

Epoch: 5| Step: 8
Training loss: 0.07270399481058121
Validation loss: 1.4238572505212599

Epoch: 5| Step: 9
Training loss: 0.04219922423362732
Validation loss: 1.4238874002169537

Epoch: 5| Step: 10
Training loss: 0.0639534592628479
Validation loss: 1.4198496046886648

Epoch: 554| Step: 0
Training loss: 0.08772864192724228
Validation loss: 1.4196636580651807

Epoch: 5| Step: 1
Training loss: 0.07526488602161407
Validation loss: 1.4001486455240557

Epoch: 5| Step: 2
Training loss: 0.1223631277680397
Validation loss: 1.4313676555951436

Epoch: 5| Step: 3
Training loss: 0.07292071729898453
Validation loss: 1.4309737996388507

Epoch: 5| Step: 4
Training loss: 0.07844413071870804
Validation loss: 1.4173069141244377

Epoch: 5| Step: 5
Training loss: 0.09622751176357269
Validation loss: 1.4299002424363167

Epoch: 5| Step: 6
Training loss: 0.08075341582298279
Validation loss: 1.455356764537032

Epoch: 5| Step: 7
Training loss: 0.041901588439941406
Validation loss: 1.4569244384765625

Epoch: 5| Step: 8
Training loss: 0.05689524486660957
Validation loss: 1.455995504574109

Epoch: 5| Step: 9
Training loss: 0.07989004999399185
Validation loss: 1.4595158209082901

Epoch: 5| Step: 10
Training loss: 0.06270718574523926
Validation loss: 1.4194809480379986

Epoch: 555| Step: 0
Training loss: 0.06510511785745621
Validation loss: 1.4547782880003735

Epoch: 5| Step: 1
Training loss: 0.06339443475008011
Validation loss: 1.4447404120558052

Epoch: 5| Step: 2
Training loss: 0.09220489114522934
Validation loss: 1.4405601191264328

Epoch: 5| Step: 3
Training loss: 0.0843709260225296
Validation loss: 1.4140060999060189

Epoch: 5| Step: 4
Training loss: 0.0644281655550003
Validation loss: 1.426759034074763

Epoch: 5| Step: 5
Training loss: 0.09017608314752579
Validation loss: 1.4299568078851188

Epoch: 5| Step: 6
Training loss: 0.048031266778707504
Validation loss: 1.4538919951326104

Epoch: 5| Step: 7
Training loss: 0.06655063480138779
Validation loss: 1.4321614388496644

Epoch: 5| Step: 8
Training loss: 0.06655635684728622
Validation loss: 1.4234699574849938

Epoch: 5| Step: 9
Training loss: 0.0697726458311081
Validation loss: 1.4553875436065018

Epoch: 5| Step: 10
Training loss: 0.06070290505886078
Validation loss: 1.439532700405326

Epoch: 556| Step: 0
Training loss: 0.0987686812877655
Validation loss: 1.430716802996974

Epoch: 5| Step: 1
Training loss: 0.053686708211898804
Validation loss: 1.436672459366501

Epoch: 5| Step: 2
Training loss: 0.07159662991762161
Validation loss: 1.4257484841090378

Epoch: 5| Step: 3
Training loss: 0.04932735487818718
Validation loss: 1.437580588043377

Epoch: 5| Step: 4
Training loss: 0.08588800579309464
Validation loss: 1.439770999775138

Epoch: 5| Step: 5
Training loss: 0.0783771350979805
Validation loss: 1.4504588496300481

Epoch: 5| Step: 6
Training loss: 0.05197131633758545
Validation loss: 1.4382549934489752

Epoch: 5| Step: 7
Training loss: 0.08075928688049316
Validation loss: 1.4413269514678626

Epoch: 5| Step: 8
Training loss: 0.07885395735502243
Validation loss: 1.44308651134532

Epoch: 5| Step: 9
Training loss: 0.11138670146465302
Validation loss: 1.438954940406225

Epoch: 5| Step: 10
Training loss: 0.059826698154211044
Validation loss: 1.4542103454630861

Epoch: 557| Step: 0
Training loss: 0.06914154440164566
Validation loss: 1.4560926421996085

Epoch: 5| Step: 1
Training loss: 0.08368057012557983
Validation loss: 1.4570259060910953

Epoch: 5| Step: 2
Training loss: 0.04990434646606445
Validation loss: 1.4547087248935495

Epoch: 5| Step: 3
Training loss: 0.07615239918231964
Validation loss: 1.4346082389995616

Epoch: 5| Step: 4
Training loss: 0.10422845184803009
Validation loss: 1.4637999688425372

Epoch: 5| Step: 5
Training loss: 0.08693643659353256
Validation loss: 1.4692737376818092

Epoch: 5| Step: 6
Training loss: 0.08860521763563156
Validation loss: 1.479085527440553

Epoch: 5| Step: 7
Training loss: 0.0884169191122055
Validation loss: 1.4661449168318061

Epoch: 5| Step: 8
Training loss: 0.13738855719566345
Validation loss: 1.4792604497683945

Epoch: 5| Step: 9
Training loss: 0.06434069573879242
Validation loss: 1.4722883175778132

Epoch: 5| Step: 10
Training loss: 0.07190477102994919
Validation loss: 1.454201763676059

Epoch: 558| Step: 0
Training loss: 0.05884281545877457
Validation loss: 1.4502411298854376

Epoch: 5| Step: 1
Training loss: 0.05639835074543953
Validation loss: 1.4479551071761756

Epoch: 5| Step: 2
Training loss: 0.07141032069921494
Validation loss: 1.4603367582444222

Epoch: 5| Step: 3
Training loss: 0.06576830893754959
Validation loss: 1.4607734218720467

Epoch: 5| Step: 4
Training loss: 0.06370984762907028
Validation loss: 1.4559723689991941

Epoch: 5| Step: 5
Training loss: 0.08349541574716568
Validation loss: 1.45353881261682

Epoch: 5| Step: 6
Training loss: 0.06172746419906616
Validation loss: 1.4509760000372445

Epoch: 5| Step: 7
Training loss: 0.07288844883441925
Validation loss: 1.4362549499798847

Epoch: 5| Step: 8
Training loss: 0.09268144518136978
Validation loss: 1.4419242720450125

Epoch: 5| Step: 9
Training loss: 0.12808454036712646
Validation loss: 1.451664706712128

Epoch: 5| Step: 10
Training loss: 0.07955878973007202
Validation loss: 1.462323510518638

Epoch: 559| Step: 0
Training loss: 0.09064237773418427
Validation loss: 1.4410456175445228

Epoch: 5| Step: 1
Training loss: 0.07211419939994812
Validation loss: 1.4690306507131106

Epoch: 5| Step: 2
Training loss: 0.12013538926839828
Validation loss: 1.4583957849010345

Epoch: 5| Step: 3
Training loss: 0.09530923515558243
Validation loss: 1.4639269767269012

Epoch: 5| Step: 4
Training loss: 0.054544370621442795
Validation loss: 1.4887379510428316

Epoch: 5| Step: 5
Training loss: 0.07472385466098785
Validation loss: 1.4804332628045032

Epoch: 5| Step: 6
Training loss: 0.09059923887252808
Validation loss: 1.4851287552105483

Epoch: 5| Step: 7
Training loss: 0.12343798577785492
Validation loss: 1.476957930031643

Epoch: 5| Step: 8
Training loss: 0.06562571227550507
Validation loss: 1.4715852878426994

Epoch: 5| Step: 9
Training loss: 0.04623407870531082
Validation loss: 1.4655155917649627

Epoch: 5| Step: 10
Training loss: 0.07820314168930054
Validation loss: 1.4218517285521313

Epoch: 560| Step: 0
Training loss: 0.09481821209192276
Validation loss: 1.4447227075535765

Epoch: 5| Step: 1
Training loss: 0.10369893163442612
Validation loss: 1.4386095231579197

Epoch: 5| Step: 2
Training loss: 0.12051711231470108
Validation loss: 1.4664990389218895

Epoch: 5| Step: 3
Training loss: 0.10276617854833603
Validation loss: 1.4515786555505568

Epoch: 5| Step: 4
Training loss: 0.09981302917003632
Validation loss: 1.454048268256649

Epoch: 5| Step: 5
Training loss: 0.06746581196784973
Validation loss: 1.4463713181916105

Epoch: 5| Step: 6
Training loss: 0.08689673990011215
Validation loss: 1.4397061153124737

Epoch: 5| Step: 7
Training loss: 0.06701549887657166
Validation loss: 1.4642769546918972

Epoch: 5| Step: 8
Training loss: 0.08733798563480377
Validation loss: 1.467438304296104

Epoch: 5| Step: 9
Training loss: 0.05580507963895798
Validation loss: 1.4507282613426127

Epoch: 5| Step: 10
Training loss: 0.11428241431713104
Validation loss: 1.4690718266271776

Epoch: 561| Step: 0
Training loss: 0.07867644727230072
Validation loss: 1.4607574324454031

Epoch: 5| Step: 1
Training loss: 0.09359864890575409
Validation loss: 1.4376601890851093

Epoch: 5| Step: 2
Training loss: 0.0634184256196022
Validation loss: 1.4443468560454666

Epoch: 5| Step: 3
Training loss: 0.09162376821041107
Validation loss: 1.446180606401095

Epoch: 5| Step: 4
Training loss: 0.0770961344242096
Validation loss: 1.428645210881387

Epoch: 5| Step: 5
Training loss: 0.08675028383731842
Validation loss: 1.4263850578697779

Epoch: 5| Step: 6
Training loss: 0.10096082836389542
Validation loss: 1.4253195357579056

Epoch: 5| Step: 7
Training loss: 0.06245095655322075
Validation loss: 1.4526360945035053

Epoch: 5| Step: 8
Training loss: 0.0701594352722168
Validation loss: 1.4188248431810768

Epoch: 5| Step: 9
Training loss: 0.13740447163581848
Validation loss: 1.449956399779166

Epoch: 5| Step: 10
Training loss: 0.050779327750205994
Validation loss: 1.4623913047134236

Epoch: 562| Step: 0
Training loss: 0.13159383833408356
Validation loss: 1.4679032256526332

Epoch: 5| Step: 1
Training loss: 0.09456511586904526
Validation loss: 1.4890795394938479

Epoch: 5| Step: 2
Training loss: 0.07592737674713135
Validation loss: 1.4751550830820555

Epoch: 5| Step: 3
Training loss: 0.11116556823253632
Validation loss: 1.4837487410473567

Epoch: 5| Step: 4
Training loss: 0.09039737284183502
Validation loss: 1.4494799080715384

Epoch: 5| Step: 5
Training loss: 0.07190894335508347
Validation loss: 1.4872492897895075

Epoch: 5| Step: 6
Training loss: 0.07632432132959366
Validation loss: 1.4564545039207704

Epoch: 5| Step: 7
Training loss: 0.08894471824169159
Validation loss: 1.463330925151866

Epoch: 5| Step: 8
Training loss: 0.07481781393289566
Validation loss: 1.4441974342510264

Epoch: 5| Step: 9
Training loss: 0.07985160499811172
Validation loss: 1.4510318559985007

Epoch: 5| Step: 10
Training loss: 0.07357051968574524
Validation loss: 1.456370965127022

Epoch: 563| Step: 0
Training loss: 0.06821898370981216
Validation loss: 1.4512678051507601

Epoch: 5| Step: 1
Training loss: 0.060982029885053635
Validation loss: 1.4598571049269808

Epoch: 5| Step: 2
Training loss: 0.09179270267486572
Validation loss: 1.481318659679864

Epoch: 5| Step: 3
Training loss: 0.1025879755616188
Validation loss: 1.445689788428686

Epoch: 5| Step: 4
Training loss: 0.05261804535984993
Validation loss: 1.4665379242230487

Epoch: 5| Step: 5
Training loss: 0.07900149375200272
Validation loss: 1.4719868565118441

Epoch: 5| Step: 6
Training loss: 0.05013229325413704
Validation loss: 1.480640749777517

Epoch: 5| Step: 7
Training loss: 0.10067889839410782
Validation loss: 1.4662484161315426

Epoch: 5| Step: 8
Training loss: 0.1008806824684143
Validation loss: 1.4703660857292913

Epoch: 5| Step: 9
Training loss: 0.07356807589530945
Validation loss: 1.464473274446303

Epoch: 5| Step: 10
Training loss: 0.07905007898807526
Validation loss: 1.4565756756772277

Epoch: 564| Step: 0
Training loss: 0.08936470746994019
Validation loss: 1.4575399685931463

Epoch: 5| Step: 1
Training loss: 0.0664018988609314
Validation loss: 1.431056922481906

Epoch: 5| Step: 2
Training loss: 0.05773981288075447
Validation loss: 1.4544216753334127

Epoch: 5| Step: 3
Training loss: 0.09820200502872467
Validation loss: 1.4435250605306318

Epoch: 5| Step: 4
Training loss: 0.07212595641613007
Validation loss: 1.4442810845631424

Epoch: 5| Step: 5
Training loss: 0.11367316544055939
Validation loss: 1.4404964562385314

Epoch: 5| Step: 6
Training loss: 0.08276957273483276
Validation loss: 1.4464678213160524

Epoch: 5| Step: 7
Training loss: 0.08947961032390594
Validation loss: 1.438649187805832

Epoch: 5| Step: 8
Training loss: 0.08994650840759277
Validation loss: 1.4223402527070814

Epoch: 5| Step: 9
Training loss: 0.07690518349409103
Validation loss: 1.4144801683323358

Epoch: 5| Step: 10
Training loss: 0.05646488443017006
Validation loss: 1.4324565959233109

Epoch: 565| Step: 0
Training loss: 0.08051423728466034
Validation loss: 1.4280515306739396

Epoch: 5| Step: 1
Training loss: 0.07249052822589874
Validation loss: 1.4418454067681425

Epoch: 5| Step: 2
Training loss: 0.08920782804489136
Validation loss: 1.4455518177760545

Epoch: 5| Step: 3
Training loss: 0.1381016969680786
Validation loss: 1.4240062954605266

Epoch: 5| Step: 4
Training loss: 0.09594567865133286
Validation loss: 1.4388870013657438

Epoch: 5| Step: 5
Training loss: 0.05750121548771858
Validation loss: 1.4205495029367425

Epoch: 5| Step: 6
Training loss: 0.08370605856180191
Validation loss: 1.4286287292357414

Epoch: 5| Step: 7
Training loss: 0.0611724779009819
Validation loss: 1.441504729691372

Epoch: 5| Step: 8
Training loss: 0.07372613251209259
Validation loss: 1.4113361015114734

Epoch: 5| Step: 9
Training loss: 0.06510074436664581
Validation loss: 1.4219953001186412

Epoch: 5| Step: 10
Training loss: 0.057167865335941315
Validation loss: 1.4304859868941768

Epoch: 566| Step: 0
Training loss: 0.12497963756322861
Validation loss: 1.4402496814727783

Epoch: 5| Step: 1
Training loss: 0.08034642040729523
Validation loss: 1.4423648349700435

Epoch: 5| Step: 2
Training loss: 0.09526938199996948
Validation loss: 1.4175546541008899

Epoch: 5| Step: 3
Training loss: 0.042833950370550156
Validation loss: 1.4423802527048255

Epoch: 5| Step: 4
Training loss: 0.1491939127445221
Validation loss: 1.4497946205959524

Epoch: 5| Step: 5
Training loss: 0.06042953208088875
Validation loss: 1.426181888067594

Epoch: 5| Step: 6
Training loss: 0.06463193148374557
Validation loss: 1.4373509960789834

Epoch: 5| Step: 7
Training loss: 0.0748792439699173
Validation loss: 1.424186768070344

Epoch: 5| Step: 8
Training loss: 0.11453795433044434
Validation loss: 1.4532481854961765

Epoch: 5| Step: 9
Training loss: 0.0649629533290863
Validation loss: 1.4435274075436335

Epoch: 5| Step: 10
Training loss: 0.07592014968395233
Validation loss: 1.4593533033965735

Epoch: 567| Step: 0
Training loss: 0.07263614982366562
Validation loss: 1.460865577061971

Epoch: 5| Step: 1
Training loss: 0.052341707050800323
Validation loss: 1.4650307099024455

Epoch: 5| Step: 2
Training loss: 0.07906350493431091
Validation loss: 1.4556655012151247

Epoch: 5| Step: 3
Training loss: 0.08293406665325165
Validation loss: 1.4897667361843971

Epoch: 5| Step: 4
Training loss: 0.05089827626943588
Validation loss: 1.4581414038135159

Epoch: 5| Step: 5
Training loss: 0.11369125545024872
Validation loss: 1.4767198101166756

Epoch: 5| Step: 6
Training loss: 0.05828246474266052
Validation loss: 1.4852386879664596

Epoch: 5| Step: 7
Training loss: 0.06812570989131927
Validation loss: 1.4936326947263492

Epoch: 5| Step: 8
Training loss: 0.12060119956731796
Validation loss: 1.4551971561165267

Epoch: 5| Step: 9
Training loss: 0.14047056436538696
Validation loss: 1.4278510911490327

Epoch: 5| Step: 10
Training loss: 0.1311466246843338
Validation loss: 1.4682331444114767

Epoch: 568| Step: 0
Training loss: 0.061584800481796265
Validation loss: 1.4504452572073987

Epoch: 5| Step: 1
Training loss: 0.12319189310073853
Validation loss: 1.4455362712183306

Epoch: 5| Step: 2
Training loss: 0.0803626999258995
Validation loss: 1.410207975295282

Epoch: 5| Step: 3
Training loss: 0.08572200685739517
Validation loss: 1.4556454227816673

Epoch: 5| Step: 4
Training loss: 0.1046895757317543
Validation loss: 1.4368589706318353

Epoch: 5| Step: 5
Training loss: 0.10125784575939178
Validation loss: 1.4288159288385862

Epoch: 5| Step: 6
Training loss: 0.10679354518651962
Validation loss: 1.4276936695139895

Epoch: 5| Step: 7
Training loss: 0.08353333175182343
Validation loss: 1.4520114224444154

Epoch: 5| Step: 8
Training loss: 0.06666974723339081
Validation loss: 1.4440430082300657

Epoch: 5| Step: 9
Training loss: 0.10254202038049698
Validation loss: 1.4477555341618036

Epoch: 5| Step: 10
Training loss: 0.07552365958690643
Validation loss: 1.4606186023322485

Epoch: 569| Step: 0
Training loss: 0.08837355673313141
Validation loss: 1.4664599818568076

Epoch: 5| Step: 1
Training loss: 0.0632736012339592
Validation loss: 1.4517676945655578

Epoch: 5| Step: 2
Training loss: 0.08897773921489716
Validation loss: 1.4428298332357918

Epoch: 5| Step: 3
Training loss: 0.13859215378761292
Validation loss: 1.469954881616818

Epoch: 5| Step: 4
Training loss: 0.11953280121088028
Validation loss: 1.4897000969097178

Epoch: 5| Step: 5
Training loss: 0.07716395705938339
Validation loss: 1.4889043787474274

Epoch: 5| Step: 6
Training loss: 0.06731224060058594
Validation loss: 1.4700061762204735

Epoch: 5| Step: 7
Training loss: 0.06010545417666435
Validation loss: 1.4490030965497416

Epoch: 5| Step: 8
Training loss: 0.11301169544458389
Validation loss: 1.4525042233928558

Epoch: 5| Step: 9
Training loss: 0.10450383275747299
Validation loss: 1.4493783058658722

Epoch: 5| Step: 10
Training loss: 0.06615643203258514
Validation loss: 1.447887638563751

Epoch: 570| Step: 0
Training loss: 0.06372609734535217
Validation loss: 1.4429070475280925

Epoch: 5| Step: 1
Training loss: 0.10622556507587433
Validation loss: 1.436937903845182

Epoch: 5| Step: 2
Training loss: 0.07212714850902557
Validation loss: 1.426377837375928

Epoch: 5| Step: 3
Training loss: 0.13343319296836853
Validation loss: 1.4465360615843086

Epoch: 5| Step: 4
Training loss: 0.09360945224761963
Validation loss: 1.4414988884361841

Epoch: 5| Step: 5
Training loss: 0.09346523135900497
Validation loss: 1.4578253735778153

Epoch: 5| Step: 6
Training loss: 0.07133758813142776
Validation loss: 1.4966474252362405

Epoch: 5| Step: 7
Training loss: 0.09598194062709808
Validation loss: 1.4833416759326894

Epoch: 5| Step: 8
Training loss: 0.08106313645839691
Validation loss: 1.485898192210864

Epoch: 5| Step: 9
Training loss: 0.07714883983135223
Validation loss: 1.4779361601798766

Epoch: 5| Step: 10
Training loss: 0.0873623713850975
Validation loss: 1.4894752297350156

Epoch: 571| Step: 0
Training loss: 0.08474849164485931
Validation loss: 1.4725451430966776

Epoch: 5| Step: 1
Training loss: 0.1296590119600296
Validation loss: 1.4686895275628695

Epoch: 5| Step: 2
Training loss: 0.07004415988922119
Validation loss: 1.4754191726766608

Epoch: 5| Step: 3
Training loss: 0.12089069187641144
Validation loss: 1.4701196775641492

Epoch: 5| Step: 4
Training loss: 0.08002762496471405
Validation loss: 1.4459851557208645

Epoch: 5| Step: 5
Training loss: 0.10116446018218994
Validation loss: 1.4444934129714966

Epoch: 5| Step: 6
Training loss: 0.08948886394500732
Validation loss: 1.41806197679171

Epoch: 5| Step: 7
Training loss: 0.06386372447013855
Validation loss: 1.4611796409853044

Epoch: 5| Step: 8
Training loss: 0.0644192099571228
Validation loss: 1.4605998992919922

Epoch: 5| Step: 9
Training loss: 0.07203307002782822
Validation loss: 1.4491173323764597

Epoch: 5| Step: 10
Training loss: 0.060805052518844604
Validation loss: 1.4469018405483616

Epoch: 572| Step: 0
Training loss: 0.08491529524326324
Validation loss: 1.4544963067577732

Epoch: 5| Step: 1
Training loss: 0.04967142269015312
Validation loss: 1.459840060562216

Epoch: 5| Step: 2
Training loss: 0.06677182018756866
Validation loss: 1.475575138163823

Epoch: 5| Step: 3
Training loss: 0.05412256717681885
Validation loss: 1.4778376112702072

Epoch: 5| Step: 4
Training loss: 0.08308883011341095
Validation loss: 1.4852384726206462

Epoch: 5| Step: 5
Training loss: 0.0920613557100296
Validation loss: 1.4802040143679547

Epoch: 5| Step: 6
Training loss: 0.043880581855773926
Validation loss: 1.5101723183867752

Epoch: 5| Step: 7
Training loss: 0.08959417045116425
Validation loss: 1.471454131987787

Epoch: 5| Step: 8
Training loss: 0.08093585073947906
Validation loss: 1.5007621626700125

Epoch: 5| Step: 9
Training loss: 0.10371484607458115
Validation loss: 1.5099043077038181

Epoch: 5| Step: 10
Training loss: 0.06360334157943726
Validation loss: 1.4945266035295302

Epoch: 573| Step: 0
Training loss: 0.08497700095176697
Validation loss: 1.4726937740079817

Epoch: 5| Step: 1
Training loss: 0.08542968332767487
Validation loss: 1.4895298942442863

Epoch: 5| Step: 2
Training loss: 0.12056281417608261
Validation loss: 1.4791830457666868

Epoch: 5| Step: 3
Training loss: 0.11779382079839706
Validation loss: 1.467127179586759

Epoch: 5| Step: 4
Training loss: 0.10136151313781738
Validation loss: 1.4970037039890085

Epoch: 5| Step: 5
Training loss: 0.07529839128255844
Validation loss: 1.4868208554483229

Epoch: 5| Step: 6
Training loss: 0.04819590970873833
Validation loss: 1.499818617297757

Epoch: 5| Step: 7
Training loss: 0.08401049673557281
Validation loss: 1.4988342318483578

Epoch: 5| Step: 8
Training loss: 0.06663452088832855
Validation loss: 1.5035131656995384

Epoch: 5| Step: 9
Training loss: 0.05415499210357666
Validation loss: 1.4987490484791417

Epoch: 5| Step: 10
Training loss: 0.058313123881816864
Validation loss: 1.4987927982884068

Epoch: 574| Step: 0
Training loss: 0.07820583879947662
Validation loss: 1.5105857695302656

Epoch: 5| Step: 1
Training loss: 0.08323648571968079
Validation loss: 1.4915192550228489

Epoch: 5| Step: 2
Training loss: 0.07337511330842972
Validation loss: 1.4662489045050837

Epoch: 5| Step: 3
Training loss: 0.061363399028778076
Validation loss: 1.4597929011109054

Epoch: 5| Step: 4
Training loss: 0.07897413522005081
Validation loss: 1.4560641216975387

Epoch: 5| Step: 5
Training loss: 0.08338483422994614
Validation loss: 1.4540610979962092

Epoch: 5| Step: 6
Training loss: 0.07699582725763321
Validation loss: 1.4589861990303121

Epoch: 5| Step: 7
Training loss: 0.10066165775060654
Validation loss: 1.4374812905506422

Epoch: 5| Step: 8
Training loss: 0.06577861309051514
Validation loss: 1.4606978527961239

Epoch: 5| Step: 9
Training loss: 0.05450820177793503
Validation loss: 1.464472246426408

Epoch: 5| Step: 10
Training loss: 0.06109952926635742
Validation loss: 1.433257104889039

Epoch: 575| Step: 0
Training loss: 0.06808967888355255
Validation loss: 1.4523427089055378

Epoch: 5| Step: 1
Training loss: 0.05786651372909546
Validation loss: 1.4684392418912662

Epoch: 5| Step: 2
Training loss: 0.08039281517267227
Validation loss: 1.4531204854288409

Epoch: 5| Step: 3
Training loss: 0.1094004362821579
Validation loss: 1.472246031607351

Epoch: 5| Step: 4
Training loss: 0.07071740925312042
Validation loss: 1.4617328515616796

Epoch: 5| Step: 5
Training loss: 0.07961948961019516
Validation loss: 1.4327494341840026

Epoch: 5| Step: 6
Training loss: 0.05742368847131729
Validation loss: 1.4537287078877932

Epoch: 5| Step: 7
Training loss: 0.04383402690291405
Validation loss: 1.458130588454585

Epoch: 5| Step: 8
Training loss: 0.07235153019428253
Validation loss: 1.4552094244187879

Epoch: 5| Step: 9
Training loss: 0.0333985835313797
Validation loss: 1.4443964548008417

Epoch: 5| Step: 10
Training loss: 0.06179618835449219
Validation loss: 1.4355313098558815

Epoch: 576| Step: 0
Training loss: 0.04698948189616203
Validation loss: 1.4517458100472727

Epoch: 5| Step: 1
Training loss: 0.057716161012649536
Validation loss: 1.4252576699820898

Epoch: 5| Step: 2
Training loss: 0.1213882714509964
Validation loss: 1.4236903652068107

Epoch: 5| Step: 3
Training loss: 0.08889801055192947
Validation loss: 1.4400620934783772

Epoch: 5| Step: 4
Training loss: 0.04530487209558487
Validation loss: 1.4164839438212815

Epoch: 5| Step: 5
Training loss: 0.06895733624696732
Validation loss: 1.4345873068737727

Epoch: 5| Step: 6
Training loss: 0.056086111813783646
Validation loss: 1.4345093068256174

Epoch: 5| Step: 7
Training loss: 0.06282736361026764
Validation loss: 1.4023151750205665

Epoch: 5| Step: 8
Training loss: 0.04072175174951553
Validation loss: 1.4041186289120746

Epoch: 5| Step: 9
Training loss: 0.09755954891443253
Validation loss: 1.4131502284798572

Epoch: 5| Step: 10
Training loss: 0.05303088575601578
Validation loss: 1.4223337070916289

Epoch: 577| Step: 0
Training loss: 0.06946864724159241
Validation loss: 1.4212929241118892

Epoch: 5| Step: 1
Training loss: 0.04506293684244156
Validation loss: 1.4205051006809357

Epoch: 5| Step: 2
Training loss: 0.08477754890918732
Validation loss: 1.4050032349042996

Epoch: 5| Step: 3
Training loss: 0.05535807088017464
Validation loss: 1.4542920204900927

Epoch: 5| Step: 4
Training loss: 0.06019364669919014
Validation loss: 1.429180855392128

Epoch: 5| Step: 5
Training loss: 0.053055476397275925
Validation loss: 1.412084371812882

Epoch: 5| Step: 6
Training loss: 0.06881298124790192
Validation loss: 1.4186998310909475

Epoch: 5| Step: 7
Training loss: 0.09371055662631989
Validation loss: 1.421188385255875

Epoch: 5| Step: 8
Training loss: 0.04005046933889389
Validation loss: 1.441879536515923

Epoch: 5| Step: 9
Training loss: 0.07624314725399017
Validation loss: 1.4337489553677139

Epoch: 5| Step: 10
Training loss: 0.08231323957443237
Validation loss: 1.4238439612491156

Epoch: 578| Step: 0
Training loss: 0.061274223029613495
Validation loss: 1.4308751770245132

Epoch: 5| Step: 1
Training loss: 0.08943157643079758
Validation loss: 1.4491780188775831

Epoch: 5| Step: 2
Training loss: 0.05761394649744034
Validation loss: 1.420194472036054

Epoch: 5| Step: 3
Training loss: 0.03951628878712654
Validation loss: 1.4299750251154746

Epoch: 5| Step: 4
Training loss: 0.10360698401927948
Validation loss: 1.4192827414440852

Epoch: 5| Step: 5
Training loss: 0.11821921914815903
Validation loss: 1.3999743000153573

Epoch: 5| Step: 6
Training loss: 0.08344189077615738
Validation loss: 1.4027143511720883

Epoch: 5| Step: 7
Training loss: 0.058113496750593185
Validation loss: 1.4072175359213224

Epoch: 5| Step: 8
Training loss: 0.0743681788444519
Validation loss: 1.4117689747964182

Epoch: 5| Step: 9
Training loss: 0.08748729526996613
Validation loss: 1.416394277285504

Epoch: 5| Step: 10
Training loss: 0.051476772874593735
Validation loss: 1.4101058718978718

Epoch: 579| Step: 0
Training loss: 0.08780456334352493
Validation loss: 1.4239067749310566

Epoch: 5| Step: 1
Training loss: 0.05407627671957016
Validation loss: 1.432065736862921

Epoch: 5| Step: 2
Training loss: 0.08991606533527374
Validation loss: 1.4204874634742737

Epoch: 5| Step: 3
Training loss: 0.058725036680698395
Validation loss: 1.4137135974822506

Epoch: 5| Step: 4
Training loss: 0.05291712284088135
Validation loss: 1.4444597075062413

Epoch: 5| Step: 5
Training loss: 0.0909205824136734
Validation loss: 1.4270605848681541

Epoch: 5| Step: 6
Training loss: 0.0775141492486
Validation loss: 1.4188670368604763

Epoch: 5| Step: 7
Training loss: 0.0771268680691719
Validation loss: 1.4214226289462017

Epoch: 5| Step: 8
Training loss: 0.06588653475046158
Validation loss: 1.440663533826028

Epoch: 5| Step: 9
Training loss: 0.055742181837558746
Validation loss: 1.4306371263278428

Epoch: 5| Step: 10
Training loss: 0.0754610225558281
Validation loss: 1.4456935415985763

Epoch: 580| Step: 0
Training loss: 0.060138095170259476
Validation loss: 1.4413921307492

Epoch: 5| Step: 1
Training loss: 0.05216660350561142
Validation loss: 1.4484500603009296

Epoch: 5| Step: 2
Training loss: 0.0885404571890831
Validation loss: 1.457308203943314

Epoch: 5| Step: 3
Training loss: 0.0731939747929573
Validation loss: 1.469246959173551

Epoch: 5| Step: 4
Training loss: 0.06217235326766968
Validation loss: 1.4750890526720273

Epoch: 5| Step: 5
Training loss: 0.12689410150051117
Validation loss: 1.4604593989669636

Epoch: 5| Step: 6
Training loss: 0.07338567078113556
Validation loss: 1.4694410626606276

Epoch: 5| Step: 7
Training loss: 0.08216241747140884
Validation loss: 1.4769769560906194

Epoch: 5| Step: 8
Training loss: 0.07376562058925629
Validation loss: 1.4797279116927937

Epoch: 5| Step: 9
Training loss: 0.06943526864051819
Validation loss: 1.4878393719273229

Epoch: 5| Step: 10
Training loss: 0.068889319896698
Validation loss: 1.4672155662249493

Epoch: 581| Step: 0
Training loss: 0.08810397237539291
Validation loss: 1.4604328319590578

Epoch: 5| Step: 1
Training loss: 0.07631491869688034
Validation loss: 1.4759878304696852

Epoch: 5| Step: 2
Training loss: 0.05355898290872574
Validation loss: 1.4488281716582596

Epoch: 5| Step: 3
Training loss: 0.052109695971012115
Validation loss: 1.4557324609448832

Epoch: 5| Step: 4
Training loss: 0.10734565556049347
Validation loss: 1.424857754861155

Epoch: 5| Step: 5
Training loss: 0.05720170587301254
Validation loss: 1.4346069225700953

Epoch: 5| Step: 6
Training loss: 0.06194489076733589
Validation loss: 1.419659265907862

Epoch: 5| Step: 7
Training loss: 0.06153212860226631
Validation loss: 1.4018940361597205

Epoch: 5| Step: 8
Training loss: 0.10795293003320694
Validation loss: 1.4183769886211683

Epoch: 5| Step: 9
Training loss: 0.06902631372213364
Validation loss: 1.3929372859257523

Epoch: 5| Step: 10
Training loss: 0.07989112287759781
Validation loss: 1.372432751040305

Epoch: 582| Step: 0
Training loss: 0.0552801787853241
Validation loss: 1.350876659475347

Epoch: 5| Step: 1
Training loss: 0.055409274995326996
Validation loss: 1.398165157405279

Epoch: 5| Step: 2
Training loss: 0.07205349951982498
Validation loss: 1.3658852115754159

Epoch: 5| Step: 3
Training loss: 0.09431612491607666
Validation loss: 1.3936395568232383

Epoch: 5| Step: 4
Training loss: 0.08386939764022827
Validation loss: 1.3794730594081264

Epoch: 5| Step: 5
Training loss: 0.09633402526378632
Validation loss: 1.3991250748275428

Epoch: 5| Step: 6
Training loss: 0.06872563064098358
Validation loss: 1.4041310497509536

Epoch: 5| Step: 7
Training loss: 0.044381409883499146
Validation loss: 1.4164022694351852

Epoch: 5| Step: 8
Training loss: 0.07242331653833389
Validation loss: 1.4057439911750056

Epoch: 5| Step: 9
Training loss: 0.06241621449589729
Validation loss: 1.398653753342167

Epoch: 5| Step: 10
Training loss: 0.06355993449687958
Validation loss: 1.4112750432824577

Epoch: 583| Step: 0
Training loss: 0.10102001577615738
Validation loss: 1.4453299763382121

Epoch: 5| Step: 1
Training loss: 0.10071875900030136
Validation loss: 1.4130095871545936

Epoch: 5| Step: 2
Training loss: 0.06275144964456558
Validation loss: 1.4518285207850958

Epoch: 5| Step: 3
Training loss: 0.11065272241830826
Validation loss: 1.454162020837107

Epoch: 5| Step: 4
Training loss: 0.06808892637491226
Validation loss: 1.446899874235994

Epoch: 5| Step: 5
Training loss: 0.06415805965662003
Validation loss: 1.431553816282621

Epoch: 5| Step: 6
Training loss: 0.07643429934978485
Validation loss: 1.4303391146403488

Epoch: 5| Step: 7
Training loss: 0.053067706525325775
Validation loss: 1.4367030205265168

Epoch: 5| Step: 8
Training loss: 0.0671275183558464
Validation loss: 1.4534919992569955

Epoch: 5| Step: 9
Training loss: 0.05461932346224785
Validation loss: 1.455005245824014

Epoch: 5| Step: 10
Training loss: 0.08098460733890533
Validation loss: 1.4424129968048425

Epoch: 584| Step: 0
Training loss: 0.06445952504873276
Validation loss: 1.4508797635314286

Epoch: 5| Step: 1
Training loss: 0.06554542481899261
Validation loss: 1.4747303301288235

Epoch: 5| Step: 2
Training loss: 0.11537381261587143
Validation loss: 1.4663346121388097

Epoch: 5| Step: 3
Training loss: 0.07951784133911133
Validation loss: 1.4432967529501965

Epoch: 5| Step: 4
Training loss: 0.05548661947250366
Validation loss: 1.4480843050505525

Epoch: 5| Step: 5
Training loss: 0.08937960863113403
Validation loss: 1.4304400900358796

Epoch: 5| Step: 6
Training loss: 0.0670223981142044
Validation loss: 1.4543645753655383

Epoch: 5| Step: 7
Training loss: 0.07928520441055298
Validation loss: 1.4280165318519837

Epoch: 5| Step: 8
Training loss: 0.04734545201063156
Validation loss: 1.4298581166933941

Epoch: 5| Step: 9
Training loss: 0.059441566467285156
Validation loss: 1.439154303202065

Epoch: 5| Step: 10
Training loss: 0.09498272836208344
Validation loss: 1.4184672114669636

Epoch: 585| Step: 0
Training loss: 0.08759891986846924
Validation loss: 1.3868997135469991

Epoch: 5| Step: 1
Training loss: 0.04249601811170578
Validation loss: 1.4213755278177158

Epoch: 5| Step: 2
Training loss: 0.07390885055065155
Validation loss: 1.4358194169177805

Epoch: 5| Step: 3
Training loss: 0.062242187559604645
Validation loss: 1.4472332731370003

Epoch: 5| Step: 4
Training loss: 0.05401608347892761
Validation loss: 1.4451591096898562

Epoch: 5| Step: 5
Training loss: 0.051011454313993454
Validation loss: 1.446481586784445

Epoch: 5| Step: 6
Training loss: 0.0759134590625763
Validation loss: 1.4683300628457019

Epoch: 5| Step: 7
Training loss: 0.10769833624362946
Validation loss: 1.4576384662300028

Epoch: 5| Step: 8
Training loss: 0.076199971139431
Validation loss: 1.4324810043458016

Epoch: 5| Step: 9
Training loss: 0.08978600800037384
Validation loss: 1.4345354880056074

Epoch: 5| Step: 10
Training loss: 0.07383959740400314
Validation loss: 1.4270332333862141

Epoch: 586| Step: 0
Training loss: 0.07387860119342804
Validation loss: 1.4363168106284192

Epoch: 5| Step: 1
Training loss: 0.10510220378637314
Validation loss: 1.4248436340080795

Epoch: 5| Step: 2
Training loss: 0.09482035785913467
Validation loss: 1.427648268720155

Epoch: 5| Step: 3
Training loss: 0.08736281096935272
Validation loss: 1.4192570858104254

Epoch: 5| Step: 4
Training loss: 0.0661737471818924
Validation loss: 1.404153553388452

Epoch: 5| Step: 5
Training loss: 0.05997408553957939
Validation loss: 1.4222599921687957

Epoch: 5| Step: 6
Training loss: 0.11437971889972687
Validation loss: 1.4120509118162177

Epoch: 5| Step: 7
Training loss: 0.0739128440618515
Validation loss: 1.3941304414503035

Epoch: 5| Step: 8
Training loss: 0.07147075235843658
Validation loss: 1.4254889693311465

Epoch: 5| Step: 9
Training loss: 0.04919036477804184
Validation loss: 1.429780376213853

Epoch: 5| Step: 10
Training loss: 0.048769935965538025
Validation loss: 1.4202058456277336

Epoch: 587| Step: 0
Training loss: 0.07670523226261139
Validation loss: 1.4209561963235178

Epoch: 5| Step: 1
Training loss: 0.05793549865484238
Validation loss: 1.4173420392056948

Epoch: 5| Step: 2
Training loss: 0.06357958912849426
Validation loss: 1.4175243992959299

Epoch: 5| Step: 3
Training loss: 0.07807672023773193
Validation loss: 1.4295428260680167

Epoch: 5| Step: 4
Training loss: 0.09382037818431854
Validation loss: 1.4312576760527909

Epoch: 5| Step: 5
Training loss: 0.0795324295759201
Validation loss: 1.409144211840886

Epoch: 5| Step: 6
Training loss: 0.06514746695756912
Validation loss: 1.4074016540281233

Epoch: 5| Step: 7
Training loss: 0.04588872939348221
Validation loss: 1.4205922388261365

Epoch: 5| Step: 8
Training loss: 0.07461477816104889
Validation loss: 1.4182390948777557

Epoch: 5| Step: 9
Training loss: 0.08338494598865509
Validation loss: 1.4127241411516744

Epoch: 5| Step: 10
Training loss: 0.10231746733188629
Validation loss: 1.4055130507356377

Epoch: 588| Step: 0
Training loss: 0.07822462916374207
Validation loss: 1.429225920349039

Epoch: 5| Step: 1
Training loss: 0.06892893463373184
Validation loss: 1.42422011334409

Epoch: 5| Step: 2
Training loss: 0.06340055912733078
Validation loss: 1.4163665822757188

Epoch: 5| Step: 3
Training loss: 0.06312847137451172
Validation loss: 1.435661941446284

Epoch: 5| Step: 4
Training loss: 0.12386877834796906
Validation loss: 1.4328519298184303

Epoch: 5| Step: 5
Training loss: 0.048877499997615814
Validation loss: 1.431532456028846

Epoch: 5| Step: 6
Training loss: 0.05759141594171524
Validation loss: 1.4498835904623872

Epoch: 5| Step: 7
Training loss: 0.07464146614074707
Validation loss: 1.4520182878740373

Epoch: 5| Step: 8
Training loss: 0.07855566591024399
Validation loss: 1.4554817522725751

Epoch: 5| Step: 9
Training loss: 0.06264292448759079
Validation loss: 1.4582790841338455

Epoch: 5| Step: 10
Training loss: 0.07828929275274277
Validation loss: 1.450841587076905

Epoch: 589| Step: 0
Training loss: 0.07676864415407181
Validation loss: 1.427864049070625

Epoch: 5| Step: 1
Training loss: 0.0806116834282875
Validation loss: 1.4059830519460863

Epoch: 5| Step: 2
Training loss: 0.05945136398077011
Validation loss: 1.3973591122575986

Epoch: 5| Step: 3
Training loss: 0.07032876461744308
Validation loss: 1.3955253221655404

Epoch: 5| Step: 4
Training loss: 0.08072354644536972
Validation loss: 1.3862312019512217

Epoch: 5| Step: 5
Training loss: 0.08854711055755615
Validation loss: 1.4018030089716758

Epoch: 5| Step: 6
Training loss: 0.08327188342809677
Validation loss: 1.425441231778873

Epoch: 5| Step: 7
Training loss: 0.07532252371311188
Validation loss: 1.3980700944059639

Epoch: 5| Step: 8
Training loss: 0.0790369063615799
Validation loss: 1.4249001908045944

Epoch: 5| Step: 9
Training loss: 0.08361446112394333
Validation loss: 1.4486144499112201

Epoch: 5| Step: 10
Training loss: 0.07601464539766312
Validation loss: 1.440483489344197

Epoch: 590| Step: 0
Training loss: 0.09600962698459625
Validation loss: 1.4538697734955819

Epoch: 5| Step: 1
Training loss: 0.052788954228162766
Validation loss: 1.4397792123979138

Epoch: 5| Step: 2
Training loss: 0.06978283822536469
Validation loss: 1.438371221224467

Epoch: 5| Step: 3
Training loss: 0.09217885881662369
Validation loss: 1.4501327647957751

Epoch: 5| Step: 4
Training loss: 0.07551689445972443
Validation loss: 1.4278309665700442

Epoch: 5| Step: 5
Training loss: 0.10508527606725693
Validation loss: 1.4227800676899571

Epoch: 5| Step: 6
Training loss: 0.05965675041079521
Validation loss: 1.4294177671914459

Epoch: 5| Step: 7
Training loss: 0.05887019634246826
Validation loss: 1.4254599155918244

Epoch: 5| Step: 8
Training loss: 0.07069820165634155
Validation loss: 1.4270272562580724

Epoch: 5| Step: 9
Training loss: 0.06304998695850372
Validation loss: 1.4234951362814954

Epoch: 5| Step: 10
Training loss: 0.0603608600795269
Validation loss: 1.4538944229002921

Epoch: 591| Step: 0
Training loss: 0.09185633808374405
Validation loss: 1.447625639618084

Epoch: 5| Step: 1
Training loss: 0.11070074886083603
Validation loss: 1.4398934969338038

Epoch: 5| Step: 2
Training loss: 0.07752417027950287
Validation loss: 1.4246958474959097

Epoch: 5| Step: 3
Training loss: 0.0705672949552536
Validation loss: 1.426997269994469

Epoch: 5| Step: 4
Training loss: 0.10619594901800156
Validation loss: 1.4102306160875546

Epoch: 5| Step: 5
Training loss: 0.07674150168895721
Validation loss: 1.4181237156673143

Epoch: 5| Step: 6
Training loss: 0.06815703958272934
Validation loss: 1.432326562942997

Epoch: 5| Step: 7
Training loss: 0.11584877967834473
Validation loss: 1.4272510864401375

Epoch: 5| Step: 8
Training loss: 0.06716068089008331
Validation loss: 1.4096405262588172

Epoch: 5| Step: 9
Training loss: 0.06779304146766663
Validation loss: 1.4153793768216205

Epoch: 5| Step: 10
Training loss: 0.05520301312208176
Validation loss: 1.4044964980053645

Epoch: 592| Step: 0
Training loss: 0.05468645691871643
Validation loss: 1.432763086852207

Epoch: 5| Step: 1
Training loss: 0.08069531619548798
Validation loss: 1.4317549172268118

Epoch: 5| Step: 2
Training loss: 0.08419261127710342
Validation loss: 1.4276999273607809

Epoch: 5| Step: 3
Training loss: 0.07915158569812775
Validation loss: 1.4194063512227868

Epoch: 5| Step: 4
Training loss: 0.07320061326026917
Validation loss: 1.4397600299568587

Epoch: 5| Step: 5
Training loss: 0.055551595985889435
Validation loss: 1.4311057521450905

Epoch: 5| Step: 6
Training loss: 0.06665517389774323
Validation loss: 1.4520589126053678

Epoch: 5| Step: 7
Training loss: 0.041989874094724655
Validation loss: 1.4292016888177523

Epoch: 5| Step: 8
Training loss: 0.08669832348823547
Validation loss: 1.4261135132082048

Epoch: 5| Step: 9
Training loss: 0.07826922088861465
Validation loss: 1.4311149581786125

Epoch: 5| Step: 10
Training loss: 0.05793621018528938
Validation loss: 1.4501907928015596

Epoch: 593| Step: 0
Training loss: 0.09374108165502548
Validation loss: 1.4709372879356466

Epoch: 5| Step: 1
Training loss: 0.07103857398033142
Validation loss: 1.4610768646322272

Epoch: 5| Step: 2
Training loss: 0.10409202426671982
Validation loss: 1.4643104999296126

Epoch: 5| Step: 3
Training loss: 0.06966595351696014
Validation loss: 1.4563730891032884

Epoch: 5| Step: 4
Training loss: 0.09095431864261627
Validation loss: 1.4552261726830595

Epoch: 5| Step: 5
Training loss: 0.06732318550348282
Validation loss: 1.4314750163785872

Epoch: 5| Step: 6
Training loss: 0.059620749205350876
Validation loss: 1.4238630789582447

Epoch: 5| Step: 7
Training loss: 0.07524441182613373
Validation loss: 1.4183490635246359

Epoch: 5| Step: 8
Training loss: 0.08927235752344131
Validation loss: 1.4388625942250735

Epoch: 5| Step: 9
Training loss: 0.06171715259552002
Validation loss: 1.4286447122532835

Epoch: 5| Step: 10
Training loss: 0.07208026945590973
Validation loss: 1.4334030164185392

Epoch: 594| Step: 0
Training loss: 0.08681406825780869
Validation loss: 1.4295300572149214

Epoch: 5| Step: 1
Training loss: 0.04881330579519272
Validation loss: 1.4359066345358407

Epoch: 5| Step: 2
Training loss: 0.07015620917081833
Validation loss: 1.4281008781925324

Epoch: 5| Step: 3
Training loss: 0.07601495087146759
Validation loss: 1.418302874411306

Epoch: 5| Step: 4
Training loss: 0.06146080419421196
Validation loss: 1.4273404203435427

Epoch: 5| Step: 5
Training loss: 0.08860526978969574
Validation loss: 1.4323436643487664

Epoch: 5| Step: 6
Training loss: 0.08856847137212753
Validation loss: 1.422663175931541

Epoch: 5| Step: 7
Training loss: 0.13782139122486115
Validation loss: 1.4504919821216213

Epoch: 5| Step: 8
Training loss: 0.06523708254098892
Validation loss: 1.4191979759482927

Epoch: 5| Step: 9
Training loss: 0.05513251945376396
Validation loss: 1.4229556501552623

Epoch: 5| Step: 10
Training loss: 0.06262707710266113
Validation loss: 1.4135008294095275

Epoch: 595| Step: 0
Training loss: 0.11981523036956787
Validation loss: 1.3991891658434303

Epoch: 5| Step: 1
Training loss: 0.046371519565582275
Validation loss: 1.4053445259730022

Epoch: 5| Step: 2
Training loss: 0.047332316637039185
Validation loss: 1.388684061265761

Epoch: 5| Step: 3
Training loss: 0.05485501140356064
Validation loss: 1.4038157309255292

Epoch: 5| Step: 4
Training loss: 0.047271978110075
Validation loss: 1.3862650586712746

Epoch: 5| Step: 5
Training loss: 0.06506753712892532
Validation loss: 1.4015053228665424

Epoch: 5| Step: 6
Training loss: 0.06472989916801453
Validation loss: 1.4032313862154562

Epoch: 5| Step: 7
Training loss: 0.07279674708843231
Validation loss: 1.4084341103030789

Epoch: 5| Step: 8
Training loss: 0.08935047686100006
Validation loss: 1.3840637655668362

Epoch: 5| Step: 9
Training loss: 0.07022681087255478
Validation loss: 1.394274547535886

Epoch: 5| Step: 10
Training loss: 0.12756788730621338
Validation loss: 1.4084448173481932

Epoch: 596| Step: 0
Training loss: 0.10722844302654266
Validation loss: 1.3906460026259064

Epoch: 5| Step: 1
Training loss: 0.06740090996026993
Validation loss: 1.4076626858403605

Epoch: 5| Step: 2
Training loss: 0.09333696961402893
Validation loss: 1.412296187493109

Epoch: 5| Step: 3
Training loss: 0.10287334769964218
Validation loss: 1.4443283952692503

Epoch: 5| Step: 4
Training loss: 0.05663350969552994
Validation loss: 1.4149389138785742

Epoch: 5| Step: 5
Training loss: 0.06411036103963852
Validation loss: 1.432623637619839

Epoch: 5| Step: 6
Training loss: 0.059855084866285324
Validation loss: 1.4381355547135877

Epoch: 5| Step: 7
Training loss: 0.06227518990635872
Validation loss: 1.4538037789765226

Epoch: 5| Step: 8
Training loss: 0.05350620672106743
Validation loss: 1.41189577246225

Epoch: 5| Step: 9
Training loss: 0.09505481272935867
Validation loss: 1.3910149528134255

Epoch: 5| Step: 10
Training loss: 0.10018996149301529
Validation loss: 1.4135242944122643

Epoch: 597| Step: 0
Training loss: 0.07817619293928146
Validation loss: 1.4062699746060114

Epoch: 5| Step: 1
Training loss: 0.05241569131612778
Validation loss: 1.4161691845104258

Epoch: 5| Step: 2
Training loss: 0.07657646387815475
Validation loss: 1.415848773012879

Epoch: 5| Step: 3
Training loss: 0.049689341336488724
Validation loss: 1.3976412857732465

Epoch: 5| Step: 4
Training loss: 0.055106859654188156
Validation loss: 1.4277782222276092

Epoch: 5| Step: 5
Training loss: 0.07955639064311981
Validation loss: 1.404403901869251

Epoch: 5| Step: 6
Training loss: 0.07118430733680725
Validation loss: 1.4253752731507825

Epoch: 5| Step: 7
Training loss: 0.08290928602218628
Validation loss: 1.4280620980006393

Epoch: 5| Step: 8
Training loss: 0.043208494782447815
Validation loss: 1.4077745304312757

Epoch: 5| Step: 9
Training loss: 0.07102009654045105
Validation loss: 1.420855643928692

Epoch: 5| Step: 10
Training loss: 0.05542406067252159
Validation loss: 1.4063151395449074

Epoch: 598| Step: 0
Training loss: 0.07943284511566162
Validation loss: 1.3930075514701106

Epoch: 5| Step: 1
Training loss: 0.07630352675914764
Validation loss: 1.40985361606844

Epoch: 5| Step: 2
Training loss: 0.054851509630680084
Validation loss: 1.4176009842144546

Epoch: 5| Step: 3
Training loss: 0.0776248350739479
Validation loss: 1.4145556649854105

Epoch: 5| Step: 4
Training loss: 0.07696831971406937
Validation loss: 1.4139131237101812

Epoch: 5| Step: 5
Training loss: 0.055600494146347046
Validation loss: 1.4442795002332298

Epoch: 5| Step: 6
Training loss: 0.06264688074588776
Validation loss: 1.427355065140673

Epoch: 5| Step: 7
Training loss: 0.05822836235165596
Validation loss: 1.4614155933421145

Epoch: 5| Step: 8
Training loss: 0.08686858415603638
Validation loss: 1.4585849585071686

Epoch: 5| Step: 9
Training loss: 0.06652289628982544
Validation loss: 1.4449936766778269

Epoch: 5| Step: 10
Training loss: 0.08714395016431808
Validation loss: 1.4230838725643773

Epoch: 599| Step: 0
Training loss: 0.0963960736989975
Validation loss: 1.4458433543482134

Epoch: 5| Step: 1
Training loss: 0.07647199928760529
Validation loss: 1.4191490411758423

Epoch: 5| Step: 2
Training loss: 0.06463980674743652
Validation loss: 1.4264825287685599

Epoch: 5| Step: 3
Training loss: 0.05754639580845833
Validation loss: 1.4019307372390584

Epoch: 5| Step: 4
Training loss: 0.048781074583530426
Validation loss: 1.4249237378438313

Epoch: 5| Step: 5
Training loss: 0.05303870886564255
Validation loss: 1.4355485029118036

Epoch: 5| Step: 6
Training loss: 0.08209624886512756
Validation loss: 1.4166078247049803

Epoch: 5| Step: 7
Training loss: 0.07299892604351044
Validation loss: 1.4257215479368806

Epoch: 5| Step: 8
Training loss: 0.121836818754673
Validation loss: 1.4146160861497283

Epoch: 5| Step: 9
Training loss: 0.06399445235729218
Validation loss: 1.4260140285697034

Epoch: 5| Step: 10
Training loss: 0.10201796144247055
Validation loss: 1.432413734415526

Epoch: 600| Step: 0
Training loss: 0.06568969786167145
Validation loss: 1.4377195950477355

Epoch: 5| Step: 1
Training loss: 0.0617188885807991
Validation loss: 1.4441030692028742

Epoch: 5| Step: 2
Training loss: 0.07368211448192596
Validation loss: 1.4339937856120448

Epoch: 5| Step: 3
Training loss: 0.07250291109085083
Validation loss: 1.4761990911217147

Epoch: 5| Step: 4
Training loss: 0.0874280333518982
Validation loss: 1.442757425769683

Epoch: 5| Step: 5
Training loss: 0.07168213278055191
Validation loss: 1.4678628611308273

Epoch: 5| Step: 6
Training loss: 0.04662589728832245
Validation loss: 1.44629116083986

Epoch: 5| Step: 7
Training loss: 0.08360504359006882
Validation loss: 1.4438888616459344

Epoch: 5| Step: 8
Training loss: 0.09370285272598267
Validation loss: 1.4440450693971367

Epoch: 5| Step: 9
Training loss: 0.06281586736440659
Validation loss: 1.4465304613113403

Epoch: 5| Step: 10
Training loss: 0.06504394114017487
Validation loss: 1.424162805721324

Epoch: 601| Step: 0
Training loss: 0.059873007237911224
Validation loss: 1.4428014716794413

Epoch: 5| Step: 1
Training loss: 0.07264266908168793
Validation loss: 1.4418221519839378

Epoch: 5| Step: 2
Training loss: 0.07856322079896927
Validation loss: 1.4463633157873665

Epoch: 5| Step: 3
Training loss: 0.10759837925434113
Validation loss: 1.4438607974718976

Epoch: 5| Step: 4
Training loss: 0.11260094493627548
Validation loss: 1.4482156461285007

Epoch: 5| Step: 5
Training loss: 0.04396387189626694
Validation loss: 1.4268600979158956

Epoch: 5| Step: 6
Training loss: 0.08005298674106598
Validation loss: 1.460018011831468

Epoch: 5| Step: 7
Training loss: 0.05824749916791916
Validation loss: 1.4497168076935636

Epoch: 5| Step: 8
Training loss: 0.06521773338317871
Validation loss: 1.4256747820044076

Epoch: 5| Step: 9
Training loss: 0.07551417499780655
Validation loss: 1.4339983629923996

Epoch: 5| Step: 10
Training loss: 0.08978026360273361
Validation loss: 1.4617709011159918

Epoch: 602| Step: 0
Training loss: 0.14568880200386047
Validation loss: 1.4665722167620094

Epoch: 5| Step: 1
Training loss: 0.04888712242245674
Validation loss: 1.4403988738213815

Epoch: 5| Step: 2
Training loss: 0.10000620037317276
Validation loss: 1.446307925767796

Epoch: 5| Step: 3
Training loss: 0.078157439827919
Validation loss: 1.4598095378568094

Epoch: 5| Step: 4
Training loss: 0.10763289779424667
Validation loss: 1.4506929356564757

Epoch: 5| Step: 5
Training loss: 0.07505808770656586
Validation loss: 1.4259460946565032

Epoch: 5| Step: 6
Training loss: 0.08206675201654434
Validation loss: 1.4201327126513246

Epoch: 5| Step: 7
Training loss: 0.07423730194568634
Validation loss: 1.4131855509614433

Epoch: 5| Step: 8
Training loss: 0.061039842665195465
Validation loss: 1.4385024507840474

Epoch: 5| Step: 9
Training loss: 0.11444447189569473
Validation loss: 1.4267019232114155

Epoch: 5| Step: 10
Training loss: 0.05968679487705231
Validation loss: 1.4321473868944312

Epoch: 603| Step: 0
Training loss: 0.08583837747573853
Validation loss: 1.4113912556761055

Epoch: 5| Step: 1
Training loss: 0.07001657783985138
Validation loss: 1.4198501648441437

Epoch: 5| Step: 2
Training loss: 0.10100636631250381
Validation loss: 1.4294617329874346

Epoch: 5| Step: 3
Training loss: 0.08031497150659561
Validation loss: 1.4169464060055312

Epoch: 5| Step: 4
Training loss: 0.0836331844329834
Validation loss: 1.4304456999225001

Epoch: 5| Step: 5
Training loss: 0.09656569361686707
Validation loss: 1.4234133702452465

Epoch: 5| Step: 6
Training loss: 0.04038689285516739
Validation loss: 1.4136527328081028

Epoch: 5| Step: 7
Training loss: 0.08458378911018372
Validation loss: 1.4309799312263407

Epoch: 5| Step: 8
Training loss: 0.04979237914085388
Validation loss: 1.432468650161579

Epoch: 5| Step: 9
Training loss: 0.052826445549726486
Validation loss: 1.4480898040597157

Epoch: 5| Step: 10
Training loss: 0.04990112781524658
Validation loss: 1.458798167526081

Epoch: 604| Step: 0
Training loss: 0.09098329395055771
Validation loss: 1.4704741188274917

Epoch: 5| Step: 1
Training loss: 0.10056717693805695
Validation loss: 1.4556551697433635

Epoch: 5| Step: 2
Training loss: 0.057283759117126465
Validation loss: 1.432557343154825

Epoch: 5| Step: 3
Training loss: 0.03829718381166458
Validation loss: 1.4197441890675535

Epoch: 5| Step: 4
Training loss: 0.06255286931991577
Validation loss: 1.4335034008949035

Epoch: 5| Step: 5
Training loss: 0.07102493941783905
Validation loss: 1.398166851330829

Epoch: 5| Step: 6
Training loss: 0.06252385675907135
Validation loss: 1.4044177442468622

Epoch: 5| Step: 7
Training loss: 0.050455231219530106
Validation loss: 1.4144679090028167

Epoch: 5| Step: 8
Training loss: 0.04974273592233658
Validation loss: 1.4204428862499934

Epoch: 5| Step: 9
Training loss: 0.04752328246831894
Validation loss: 1.4235554305456017

Epoch: 5| Step: 10
Training loss: 0.06434495002031326
Validation loss: 1.417161758868925

Epoch: 605| Step: 0
Training loss: 0.05523524433374405
Validation loss: 1.3989155997512162

Epoch: 5| Step: 1
Training loss: 0.07957293838262558
Validation loss: 1.4039927669750747

Epoch: 5| Step: 2
Training loss: 0.08798740804195404
Validation loss: 1.400461014880929

Epoch: 5| Step: 3
Training loss: 0.0767248123884201
Validation loss: 1.403462459964137

Epoch: 5| Step: 4
Training loss: 0.07183603942394257
Validation loss: 1.4002987620651082

Epoch: 5| Step: 5
Training loss: 0.0804482102394104
Validation loss: 1.408979146711288

Epoch: 5| Step: 6
Training loss: 0.05823855847120285
Validation loss: 1.419738995131626

Epoch: 5| Step: 7
Training loss: 0.0530477873980999
Validation loss: 1.419631725998335

Epoch: 5| Step: 8
Training loss: 0.07885804772377014
Validation loss: 1.4151868076734646

Epoch: 5| Step: 9
Training loss: 0.08724414557218552
Validation loss: 1.4154126131406395

Epoch: 5| Step: 10
Training loss: 0.060031015425920486
Validation loss: 1.4091970843653525

Epoch: 606| Step: 0
Training loss: 0.05347704142332077
Validation loss: 1.4329574665715616

Epoch: 5| Step: 1
Training loss: 0.047916799783706665
Validation loss: 1.4148338930581206

Epoch: 5| Step: 2
Training loss: 0.05325838178396225
Validation loss: 1.4137191029005154

Epoch: 5| Step: 3
Training loss: 0.0656166821718216
Validation loss: 1.4236974921277774

Epoch: 5| Step: 4
Training loss: 0.0759631022810936
Validation loss: 1.4104757731960667

Epoch: 5| Step: 5
Training loss: 0.06287360191345215
Validation loss: 1.4203416698722429

Epoch: 5| Step: 6
Training loss: 0.06070350483059883
Validation loss: 1.4176482603114138

Epoch: 5| Step: 7
Training loss: 0.07196050137281418
Validation loss: 1.4199259620840832

Epoch: 5| Step: 8
Training loss: 0.061493825167417526
Validation loss: 1.4100732726435508

Epoch: 5| Step: 9
Training loss: 0.03922616317868233
Validation loss: 1.4051535501275012

Epoch: 5| Step: 10
Training loss: 0.0850713923573494
Validation loss: 1.3970632373645742

Epoch: 607| Step: 0
Training loss: 0.04837984964251518
Validation loss: 1.4155286576158257

Epoch: 5| Step: 1
Training loss: 0.04891039431095123
Validation loss: 1.424269474321796

Epoch: 5| Step: 2
Training loss: 0.08896949142217636
Validation loss: 1.384679086746708

Epoch: 5| Step: 3
Training loss: 0.05381004139780998
Validation loss: 1.4047357446403914

Epoch: 5| Step: 4
Training loss: 0.06632298231124878
Validation loss: 1.4046629641645698

Epoch: 5| Step: 5
Training loss: 0.08459992706775665
Validation loss: 1.412134797342362

Epoch: 5| Step: 6
Training loss: 0.07935429364442825
Validation loss: 1.4129977995349514

Epoch: 5| Step: 7
Training loss: 0.10733024775981903
Validation loss: 1.4081631578424925

Epoch: 5| Step: 8
Training loss: 0.06897132098674774
Validation loss: 1.4422257574655677

Epoch: 5| Step: 9
Training loss: 0.05521364137530327
Validation loss: 1.4301131841956929

Epoch: 5| Step: 10
Training loss: 0.06036761403083801
Validation loss: 1.4270319720750213

Epoch: 608| Step: 0
Training loss: 0.08307023346424103
Validation loss: 1.4499531151146017

Epoch: 5| Step: 1
Training loss: 0.08093400299549103
Validation loss: 1.4559986963067004

Epoch: 5| Step: 2
Training loss: 0.07810819894075394
Validation loss: 1.4562275512244112

Epoch: 5| Step: 3
Training loss: 0.06296571344137192
Validation loss: 1.4582119500765236

Epoch: 5| Step: 4
Training loss: 0.07606812566518784
Validation loss: 1.4417135510393368

Epoch: 5| Step: 5
Training loss: 0.06890237331390381
Validation loss: 1.4350869251835732

Epoch: 5| Step: 6
Training loss: 0.07356280833482742
Validation loss: 1.4348773828116796

Epoch: 5| Step: 7
Training loss: 0.0722760260105133
Validation loss: 1.4264647178752448

Epoch: 5| Step: 8
Training loss: 0.046638503670692444
Validation loss: 1.4116527098481373

Epoch: 5| Step: 9
Training loss: 0.06709858030080795
Validation loss: 1.410375834793173

Epoch: 5| Step: 10
Training loss: 0.07115934044122696
Validation loss: 1.404678343444742

Epoch: 609| Step: 0
Training loss: 0.03904617205262184
Validation loss: 1.4076412057363858

Epoch: 5| Step: 1
Training loss: 0.04738108441233635
Validation loss: 1.4233170183756019

Epoch: 5| Step: 2
Training loss: 0.04599510878324509
Validation loss: 1.4194756912928757

Epoch: 5| Step: 3
Training loss: 0.0766306221485138
Validation loss: 1.4116633322931105

Epoch: 5| Step: 4
Training loss: 0.06182584911584854
Validation loss: 1.4082961518277404

Epoch: 5| Step: 5
Training loss: 0.07970539480447769
Validation loss: 1.3987999949403989

Epoch: 5| Step: 6
Training loss: 0.09399380534887314
Validation loss: 1.418313354574224

Epoch: 5| Step: 7
Training loss: 0.09128639847040176
Validation loss: 1.4107665477260467

Epoch: 5| Step: 8
Training loss: 0.053173381835222244
Validation loss: 1.4270992509780391

Epoch: 5| Step: 9
Training loss: 0.062100838869810104
Validation loss: 1.419619825578505

Epoch: 5| Step: 10
Training loss: 0.08865951746702194
Validation loss: 1.4432074946741904

Epoch: 610| Step: 0
Training loss: 0.06660718470811844
Validation loss: 1.447439678253666

Epoch: 5| Step: 1
Training loss: 0.1140691488981247
Validation loss: 1.4068379479069864

Epoch: 5| Step: 2
Training loss: 0.06703869998455048
Validation loss: 1.4148165064473306

Epoch: 5| Step: 3
Training loss: 0.07658161967992783
Validation loss: 1.4031669491080827

Epoch: 5| Step: 4
Training loss: 0.04410713165998459
Validation loss: 1.408166886657797

Epoch: 5| Step: 5
Training loss: 0.05919059365987778
Validation loss: 1.3885465475820726

Epoch: 5| Step: 6
Training loss: 0.08733989298343658
Validation loss: 1.3803609289148802

Epoch: 5| Step: 7
Training loss: 0.06918179988861084
Validation loss: 1.4093132147225

Epoch: 5| Step: 8
Training loss: 0.05561931058764458
Validation loss: 1.4060497463390391

Epoch: 5| Step: 9
Training loss: 0.07155656814575195
Validation loss: 1.4041081872037662

Epoch: 5| Step: 10
Training loss: 0.07439332455396652
Validation loss: 1.4263753057808004

Epoch: 611| Step: 0
Training loss: 0.07284524291753769
Validation loss: 1.4059558606916858

Epoch: 5| Step: 1
Training loss: 0.09110275655984879
Validation loss: 1.402546566019776

Epoch: 5| Step: 2
Training loss: 0.06557996571063995
Validation loss: 1.412007103684128

Epoch: 5| Step: 3
Training loss: 0.0632200539112091
Validation loss: 1.4087919112174743

Epoch: 5| Step: 4
Training loss: 0.07769298553466797
Validation loss: 1.411444672333297

Epoch: 5| Step: 5
Training loss: 0.06630722433328629
Validation loss: 1.4281998283119612

Epoch: 5| Step: 6
Training loss: 0.07159663736820221
Validation loss: 1.4307604585924456

Epoch: 5| Step: 7
Training loss: 0.039411336183547974
Validation loss: 1.4213129410179712

Epoch: 5| Step: 8
Training loss: 0.06810043007135391
Validation loss: 1.4192501319352018

Epoch: 5| Step: 9
Training loss: 0.07039743661880493
Validation loss: 1.4482686032531082

Epoch: 5| Step: 10
Training loss: 0.05741770938038826
Validation loss: 1.435693129416435

Epoch: 612| Step: 0
Training loss: 0.049962736666202545
Validation loss: 1.4592032028782753

Epoch: 5| Step: 1
Training loss: 0.06478694081306458
Validation loss: 1.4635443597711542

Epoch: 5| Step: 2
Training loss: 0.05522340536117554
Validation loss: 1.4704927564949117

Epoch: 5| Step: 3
Training loss: 0.11059395223855972
Validation loss: 1.4961802728714482

Epoch: 5| Step: 4
Training loss: 0.05569584295153618
Validation loss: 1.4762945187989103

Epoch: 5| Step: 5
Training loss: 0.10356704145669937
Validation loss: 1.4626146734401744

Epoch: 5| Step: 6
Training loss: 0.050704360008239746
Validation loss: 1.4630541096451462

Epoch: 5| Step: 7
Training loss: 0.05171038582921028
Validation loss: 1.449033155236193

Epoch: 5| Step: 8
Training loss: 0.0573490746319294
Validation loss: 1.4365065084990634

Epoch: 5| Step: 9
Training loss: 0.0714932233095169
Validation loss: 1.4468125797087146

Epoch: 5| Step: 10
Training loss: 0.0329810231924057
Validation loss: 1.415936743059466

Epoch: 613| Step: 0
Training loss: 0.11196336895227432
Validation loss: 1.4354107033821843

Epoch: 5| Step: 1
Training loss: 0.050256311893463135
Validation loss: 1.4497614246542736

Epoch: 5| Step: 2
Training loss: 0.10776448249816895
Validation loss: 1.4381066996564147

Epoch: 5| Step: 3
Training loss: 0.0689966157078743
Validation loss: 1.4138223342998053

Epoch: 5| Step: 4
Training loss: 0.04476714879274368
Validation loss: 1.4250886222367645

Epoch: 5| Step: 5
Training loss: 0.057245515286922455
Validation loss: 1.412805441887148

Epoch: 5| Step: 6
Training loss: 0.049680184572935104
Validation loss: 1.4335289257828907

Epoch: 5| Step: 7
Training loss: 0.033441249281167984
Validation loss: 1.4421082171060706

Epoch: 5| Step: 8
Training loss: 0.05021049454808235
Validation loss: 1.4242209433227457

Epoch: 5| Step: 9
Training loss: 0.07052559405565262
Validation loss: 1.4337016036433559

Epoch: 5| Step: 10
Training loss: 0.06094377115368843
Validation loss: 1.414440119138328

Epoch: 614| Step: 0
Training loss: 0.053282707929611206
Validation loss: 1.430880682442778

Epoch: 5| Step: 1
Training loss: 0.06782672554254532
Validation loss: 1.4331970445571407

Epoch: 5| Step: 2
Training loss: 0.05313616991043091
Validation loss: 1.4283473927487609

Epoch: 5| Step: 3
Training loss: 0.05016132444143295
Validation loss: 1.4084916473716818

Epoch: 5| Step: 4
Training loss: 0.04883872717618942
Validation loss: 1.4282299318621237

Epoch: 5| Step: 5
Training loss: 0.06862764060497284
Validation loss: 1.4155082234772303

Epoch: 5| Step: 6
Training loss: 0.06353744119405746
Validation loss: 1.4164579651689018

Epoch: 5| Step: 7
Training loss: 0.06027359515428543
Validation loss: 1.4346399217523553

Epoch: 5| Step: 8
Training loss: 0.04687304422259331
Validation loss: 1.414228226548882

Epoch: 5| Step: 9
Training loss: 0.06976517289876938
Validation loss: 1.4158211440168402

Epoch: 5| Step: 10
Training loss: 0.06128492206335068
Validation loss: 1.4208721883835331

Epoch: 615| Step: 0
Training loss: 0.063209168612957
Validation loss: 1.4262620185011177

Epoch: 5| Step: 1
Training loss: 0.04461544007062912
Validation loss: 1.4355303536179245

Epoch: 5| Step: 2
Training loss: 0.07695644348859787
Validation loss: 1.4256651247701337

Epoch: 5| Step: 3
Training loss: 0.037063244730234146
Validation loss: 1.427418396037112

Epoch: 5| Step: 4
Training loss: 0.050877589732408524
Validation loss: 1.4287416294056883

Epoch: 5| Step: 5
Training loss: 0.08329291641712189
Validation loss: 1.4492337549886396

Epoch: 5| Step: 6
Training loss: 0.06045961380004883
Validation loss: 1.4218658016573997

Epoch: 5| Step: 7
Training loss: 0.03808467462658882
Validation loss: 1.4355800985008158

Epoch: 5| Step: 8
Training loss: 0.06510983407497406
Validation loss: 1.4359502535994335

Epoch: 5| Step: 9
Training loss: 0.1069239154458046
Validation loss: 1.4498620930538382

Epoch: 5| Step: 10
Training loss: 0.05608257278800011
Validation loss: 1.4474774906712193

Epoch: 616| Step: 0
Training loss: 0.08331246674060822
Validation loss: 1.4370432464025353

Epoch: 5| Step: 1
Training loss: 0.051080476492643356
Validation loss: 1.4413054745684388

Epoch: 5| Step: 2
Training loss: 0.043003249913454056
Validation loss: 1.4336019587773148

Epoch: 5| Step: 3
Training loss: 0.07128500193357468
Validation loss: 1.4189999142000753

Epoch: 5| Step: 4
Training loss: 0.06549785286188126
Validation loss: 1.4471213099777058

Epoch: 5| Step: 5
Training loss: 0.049862563610076904
Validation loss: 1.4160782406407018

Epoch: 5| Step: 6
Training loss: 0.051428668200969696
Validation loss: 1.4468377418415521

Epoch: 5| Step: 7
Training loss: 0.07140934467315674
Validation loss: 1.4408947934386551

Epoch: 5| Step: 8
Training loss: 0.04905688017606735
Validation loss: 1.4250345614648634

Epoch: 5| Step: 9
Training loss: 0.058548152446746826
Validation loss: 1.435592092493529

Epoch: 5| Step: 10
Training loss: 0.07748017460107803
Validation loss: 1.4552974047199372

Epoch: 617| Step: 0
Training loss: 0.07203837484121323
Validation loss: 1.441796075913214

Epoch: 5| Step: 1
Training loss: 0.080764040350914
Validation loss: 1.446212109058134

Epoch: 5| Step: 2
Training loss: 0.062114667147397995
Validation loss: 1.4425545007951799

Epoch: 5| Step: 3
Training loss: 0.06943027675151825
Validation loss: 1.446958427788109

Epoch: 5| Step: 4
Training loss: 0.05050993710756302
Validation loss: 1.4740848874533048

Epoch: 5| Step: 5
Training loss: 0.07508071511983871
Validation loss: 1.4499023601573

Epoch: 5| Step: 6
Training loss: 0.06513775140047073
Validation loss: 1.4607385275184468

Epoch: 5| Step: 7
Training loss: 0.07708562165498734
Validation loss: 1.47705659045968

Epoch: 5| Step: 8
Training loss: 0.05347590520977974
Validation loss: 1.4688055361470869

Epoch: 5| Step: 9
Training loss: 0.05590926855802536
Validation loss: 1.4958458318505237

Epoch: 5| Step: 10
Training loss: 0.053040482103824615
Validation loss: 1.4753851070198962

Epoch: 618| Step: 0
Training loss: 0.05386769771575928
Validation loss: 1.4465210271138016

Epoch: 5| Step: 1
Training loss: 0.09876575320959091
Validation loss: 1.4536449152936217

Epoch: 5| Step: 2
Training loss: 0.05020444467663765
Validation loss: 1.4553752176223262

Epoch: 5| Step: 3
Training loss: 0.04805828258395195
Validation loss: 1.4659591669677405

Epoch: 5| Step: 4
Training loss: 0.05654240399599075
Validation loss: 1.450096567471822

Epoch: 5| Step: 5
Training loss: 0.059630971401929855
Validation loss: 1.4479694686910158

Epoch: 5| Step: 6
Training loss: 0.04549163579940796
Validation loss: 1.460800575953658

Epoch: 5| Step: 7
Training loss: 0.08840096741914749
Validation loss: 1.4473919958196662

Epoch: 5| Step: 8
Training loss: 0.0809783935546875
Validation loss: 1.4643577080900951

Epoch: 5| Step: 9
Training loss: 0.058602429926395416
Validation loss: 1.4318147692629086

Epoch: 5| Step: 10
Training loss: 0.06950221210718155
Validation loss: 1.4401223544151551

Epoch: 619| Step: 0
Training loss: 0.059845346957445145
Validation loss: 1.397552852989525

Epoch: 5| Step: 1
Training loss: 0.059315573424100876
Validation loss: 1.3963304245343773

Epoch: 5| Step: 2
Training loss: 0.039859361946582794
Validation loss: 1.4056317242242957

Epoch: 5| Step: 3
Training loss: 0.059400271624326706
Validation loss: 1.4133819412159663

Epoch: 5| Step: 4
Training loss: 0.06695069372653961
Validation loss: 1.412859953859801

Epoch: 5| Step: 5
Training loss: 0.08000205457210541
Validation loss: 1.420678807843116

Epoch: 5| Step: 6
Training loss: 0.07645904272794724
Validation loss: 1.4231651765044018

Epoch: 5| Step: 7
Training loss: 0.04966477304697037
Validation loss: 1.4121467631350282

Epoch: 5| Step: 8
Training loss: 0.03476845473051071
Validation loss: 1.4381909216603925

Epoch: 5| Step: 9
Training loss: 0.09922806173563004
Validation loss: 1.4026916462888

Epoch: 5| Step: 10
Training loss: 0.08017541468143463
Validation loss: 1.4149223924964986

Epoch: 620| Step: 0
Training loss: 0.040519703179597855
Validation loss: 1.4136909015717045

Epoch: 5| Step: 1
Training loss: 0.05507286638021469
Validation loss: 1.4305270435989543

Epoch: 5| Step: 2
Training loss: 0.053872644901275635
Validation loss: 1.4195640433219172

Epoch: 5| Step: 3
Training loss: 0.09614808857440948
Validation loss: 1.4131302051646735

Epoch: 5| Step: 4
Training loss: 0.05553731322288513
Validation loss: 1.4063334580390685

Epoch: 5| Step: 5
Training loss: 0.08056142181158066
Validation loss: 1.424219915943761

Epoch: 5| Step: 6
Training loss: 0.07604601234197617
Validation loss: 1.4060663805213025

Epoch: 5| Step: 7
Training loss: 0.04631106182932854
Validation loss: 1.3925477112493208

Epoch: 5| Step: 8
Training loss: 0.03971106559038162
Validation loss: 1.4161794788093978

Epoch: 5| Step: 9
Training loss: 0.05655365064740181
Validation loss: 1.4152224281782746

Epoch: 5| Step: 10
Training loss: 0.04680698737502098
Validation loss: 1.4120936252737557

Epoch: 621| Step: 0
Training loss: 0.08449022471904755
Validation loss: 1.4011434502499078

Epoch: 5| Step: 1
Training loss: 0.05334467813372612
Validation loss: 1.4401707546685332

Epoch: 5| Step: 2
Training loss: 0.05143161863088608
Validation loss: 1.4250837231195101

Epoch: 5| Step: 3
Training loss: 0.054903894662857056
Validation loss: 1.4393696823427755

Epoch: 5| Step: 4
Training loss: 0.05541587993502617
Validation loss: 1.456793660758644

Epoch: 5| Step: 5
Training loss: 0.047267716377973557
Validation loss: 1.4494422789542907

Epoch: 5| Step: 6
Training loss: 0.0412328839302063
Validation loss: 1.4557835581482097

Epoch: 5| Step: 7
Training loss: 0.10606309026479721
Validation loss: 1.4539478581438783

Epoch: 5| Step: 8
Training loss: 0.06256566941738129
Validation loss: 1.4585864428550965

Epoch: 5| Step: 9
Training loss: 0.051531411707401276
Validation loss: 1.4478320152528825

Epoch: 5| Step: 10
Training loss: 0.05264517292380333
Validation loss: 1.439243176931976

Epoch: 622| Step: 0
Training loss: 0.06846441328525543
Validation loss: 1.4255766266135759

Epoch: 5| Step: 1
Training loss: 0.05134923383593559
Validation loss: 1.4513401626258768

Epoch: 5| Step: 2
Training loss: 0.04636792466044426
Validation loss: 1.4499765967810025

Epoch: 5| Step: 3
Training loss: 0.05618922784924507
Validation loss: 1.4368806180133615

Epoch: 5| Step: 4
Training loss: 0.0674169510602951
Validation loss: 1.4390660127003987

Epoch: 5| Step: 5
Training loss: 0.03991367667913437
Validation loss: 1.426182512314089

Epoch: 5| Step: 6
Training loss: 0.04573408141732216
Validation loss: 1.4430433306642758

Epoch: 5| Step: 7
Training loss: 0.041548777371644974
Validation loss: 1.4189018023911344

Epoch: 5| Step: 8
Training loss: 0.06542177498340607
Validation loss: 1.4241920363518499

Epoch: 5| Step: 9
Training loss: 0.08527672290802002
Validation loss: 1.4391182340601438

Epoch: 5| Step: 10
Training loss: 0.08825426548719406
Validation loss: 1.4284139679324241

Epoch: 623| Step: 0
Training loss: 0.06013369560241699
Validation loss: 1.4416267218128327

Epoch: 5| Step: 1
Training loss: 0.08263591676950455
Validation loss: 1.420005972667407

Epoch: 5| Step: 2
Training loss: 0.03563792258501053
Validation loss: 1.4389920760226507

Epoch: 5| Step: 3
Training loss: 0.03519638255238533
Validation loss: 1.427905277539325

Epoch: 5| Step: 4
Training loss: 0.031752318143844604
Validation loss: 1.4383429775955856

Epoch: 5| Step: 5
Training loss: 0.04667360335588455
Validation loss: 1.4349055559404436

Epoch: 5| Step: 6
Training loss: 0.07642271369695663
Validation loss: 1.417834452403489

Epoch: 5| Step: 7
Training loss: 0.04169419780373573
Validation loss: 1.4528413306000412

Epoch: 5| Step: 8
Training loss: 0.0754869133234024
Validation loss: 1.4518985658563592

Epoch: 5| Step: 9
Training loss: 0.08246251195669174
Validation loss: 1.4421689843618741

Epoch: 5| Step: 10
Training loss: 0.06836719810962677
Validation loss: 1.4663103677893197

Epoch: 624| Step: 0
Training loss: 0.05996714159846306
Validation loss: 1.4404736180459299

Epoch: 5| Step: 1
Training loss: 0.05707239359617233
Validation loss: 1.4523312212318502

Epoch: 5| Step: 2
Training loss: 0.06050333380699158
Validation loss: 1.4553728385638165

Epoch: 5| Step: 3
Training loss: 0.0569816529750824
Validation loss: 1.440925641726422

Epoch: 5| Step: 4
Training loss: 0.09115256369113922
Validation loss: 1.442855510660397

Epoch: 5| Step: 5
Training loss: 0.0644843727350235
Validation loss: 1.4443178484516759

Epoch: 5| Step: 6
Training loss: 0.06392332166433334
Validation loss: 1.4373421643369941

Epoch: 5| Step: 7
Training loss: 0.05666544288396835
Validation loss: 1.4465585754763695

Epoch: 5| Step: 8
Training loss: 0.06585661321878433
Validation loss: 1.4202614535567581

Epoch: 5| Step: 9
Training loss: 0.06220925971865654
Validation loss: 1.4375923538720736

Epoch: 5| Step: 10
Training loss: 0.05829095095396042
Validation loss: 1.4395586905940887

Epoch: 625| Step: 0
Training loss: 0.06341437995433807
Validation loss: 1.4374348027731783

Epoch: 5| Step: 1
Training loss: 0.051559172570705414
Validation loss: 1.4183014733816988

Epoch: 5| Step: 2
Training loss: 0.04609459638595581
Validation loss: 1.4307571559823968

Epoch: 5| Step: 3
Training loss: 0.08244366198778152
Validation loss: 1.4272933416469122

Epoch: 5| Step: 4
Training loss: 0.03291388601064682
Validation loss: 1.426829573928669

Epoch: 5| Step: 5
Training loss: 0.04492542892694473
Validation loss: 1.4225148795753397

Epoch: 5| Step: 6
Training loss: 0.06563897430896759
Validation loss: 1.4041790744309783

Epoch: 5| Step: 7
Training loss: 0.05087984725832939
Validation loss: 1.4205136799043225

Epoch: 5| Step: 8
Training loss: 0.06219843775033951
Validation loss: 1.4214803467514694

Epoch: 5| Step: 9
Training loss: 0.11170642077922821
Validation loss: 1.4156387429083548

Epoch: 5| Step: 10
Training loss: 0.043608859181404114
Validation loss: 1.4469518379498554

Epoch: 626| Step: 0
Training loss: 0.06783737987279892
Validation loss: 1.4372055126774697

Epoch: 5| Step: 1
Training loss: 0.03092784248292446
Validation loss: 1.4454334397469797

Epoch: 5| Step: 2
Training loss: 0.07013417035341263
Validation loss: 1.4380952414645944

Epoch: 5| Step: 3
Training loss: 0.0974826067686081
Validation loss: 1.43690521999072

Epoch: 5| Step: 4
Training loss: 0.05331086367368698
Validation loss: 1.4453553025440504

Epoch: 5| Step: 5
Training loss: 0.06883658468723297
Validation loss: 1.4274208276502547

Epoch: 5| Step: 6
Training loss: 0.03653138875961304
Validation loss: 1.4394943509050595

Epoch: 5| Step: 7
Training loss: 0.058654434978961945
Validation loss: 1.4279958060992661

Epoch: 5| Step: 8
Training loss: 0.05307631567120552
Validation loss: 1.434499612418554

Epoch: 5| Step: 9
Training loss: 0.06708179414272308
Validation loss: 1.439038861182428

Epoch: 5| Step: 10
Training loss: 0.05938917025923729
Validation loss: 1.4296555083285096

Epoch: 627| Step: 0
Training loss: 0.06372211873531342
Validation loss: 1.4506817594651253

Epoch: 5| Step: 1
Training loss: 0.08272305130958557
Validation loss: 1.4449842283802647

Epoch: 5| Step: 2
Training loss: 0.06266099214553833
Validation loss: 1.4261492952223747

Epoch: 5| Step: 3
Training loss: 0.07649637758731842
Validation loss: 1.411022283697641

Epoch: 5| Step: 4
Training loss: 0.052794359624385834
Validation loss: 1.4202128648757935

Epoch: 5| Step: 5
Training loss: 0.047854699194431305
Validation loss: 1.3956680887488908

Epoch: 5| Step: 6
Training loss: 0.09282456338405609
Validation loss: 1.4109334612405429

Epoch: 5| Step: 7
Training loss: 0.062386613339185715
Validation loss: 1.4098764939974713

Epoch: 5| Step: 8
Training loss: 0.06452502310276031
Validation loss: 1.4197666465595205

Epoch: 5| Step: 9
Training loss: 0.05495123192667961
Validation loss: 1.421660215623917

Epoch: 5| Step: 10
Training loss: 0.04722939431667328
Validation loss: 1.4298993938712663

Epoch: 628| Step: 0
Training loss: 0.05138815566897392
Validation loss: 1.3993051731458275

Epoch: 5| Step: 1
Training loss: 0.04417669028043747
Validation loss: 1.3990343437399915

Epoch: 5| Step: 2
Training loss: 0.08745624870061874
Validation loss: 1.427357962695501

Epoch: 5| Step: 3
Training loss: 0.051994502544403076
Validation loss: 1.4447782821552728

Epoch: 5| Step: 4
Training loss: 0.05939190834760666
Validation loss: 1.4361102247750888

Epoch: 5| Step: 5
Training loss: 0.05039414018392563
Validation loss: 1.443361093280136

Epoch: 5| Step: 6
Training loss: 0.06441434472799301
Validation loss: 1.4549311630187496

Epoch: 5| Step: 7
Training loss: 0.07179670035839081
Validation loss: 1.442242940266927

Epoch: 5| Step: 8
Training loss: 0.03196891024708748
Validation loss: 1.4557714571235

Epoch: 5| Step: 9
Training loss: 0.047207027673721313
Validation loss: 1.436954657236735

Epoch: 5| Step: 10
Training loss: 0.05421396717429161
Validation loss: 1.4272563918944328

Epoch: 629| Step: 0
Training loss: 0.07757101207971573
Validation loss: 1.4427838287045878

Epoch: 5| Step: 1
Training loss: 0.11518476158380508
Validation loss: 1.4460957665597238

Epoch: 5| Step: 2
Training loss: 0.03908548131585121
Validation loss: 1.441047958148423

Epoch: 5| Step: 3
Training loss: 0.06269077211618423
Validation loss: 1.4207523753566127

Epoch: 5| Step: 4
Training loss: 0.060058820992708206
Validation loss: 1.416417388505833

Epoch: 5| Step: 5
Training loss: 0.06819663196802139
Validation loss: 1.4377442547070083

Epoch: 5| Step: 6
Training loss: 0.04036585986614227
Validation loss: 1.4233153020181963

Epoch: 5| Step: 7
Training loss: 0.09275336563587189
Validation loss: 1.3965766801629016

Epoch: 5| Step: 8
Training loss: 0.057980358600616455
Validation loss: 1.4211598288628362

Epoch: 5| Step: 9
Training loss: 0.05026046559214592
Validation loss: 1.4211909040327995

Epoch: 5| Step: 10
Training loss: 0.060901641845703125
Validation loss: 1.4194865534382481

Epoch: 630| Step: 0
Training loss: 0.06404443830251694
Validation loss: 1.4316642255552354

Epoch: 5| Step: 1
Training loss: 0.05836426094174385
Validation loss: 1.4212500446586198

Epoch: 5| Step: 2
Training loss: 0.08627929538488388
Validation loss: 1.4320267490161362

Epoch: 5| Step: 3
Training loss: 0.10087548196315765
Validation loss: 1.4168797859581568

Epoch: 5| Step: 4
Training loss: 0.0804315060377121
Validation loss: 1.4447474172038417

Epoch: 5| Step: 5
Training loss: 0.03639967367053032
Validation loss: 1.462010911715928

Epoch: 5| Step: 6
Training loss: 0.08065921813249588
Validation loss: 1.4632632040208386

Epoch: 5| Step: 7
Training loss: 0.0693124383687973
Validation loss: 1.4595382162319717

Epoch: 5| Step: 8
Training loss: 0.1075504869222641
Validation loss: 1.4426650988158358

Epoch: 5| Step: 9
Training loss: 0.05895588546991348
Validation loss: 1.4677637418111165

Epoch: 5| Step: 10
Training loss: 0.056811317801475525
Validation loss: 1.4522169700232885

Epoch: 631| Step: 0
Training loss: 0.06561334431171417
Validation loss: 1.4496814012527466

Epoch: 5| Step: 1
Training loss: 0.062223680317401886
Validation loss: 1.438737150161497

Epoch: 5| Step: 2
Training loss: 0.07749716937541962
Validation loss: 1.4352279145230529

Epoch: 5| Step: 3
Training loss: 0.06953434646129608
Validation loss: 1.42439373911068

Epoch: 5| Step: 4
Training loss: 0.07094703614711761
Validation loss: 1.44951553498545

Epoch: 5| Step: 5
Training loss: 0.08469152450561523
Validation loss: 1.4407736716731903

Epoch: 5| Step: 6
Training loss: 0.06260742992162704
Validation loss: 1.4351782824403496

Epoch: 5| Step: 7
Training loss: 0.09778483957052231
Validation loss: 1.4295762597873647

Epoch: 5| Step: 8
Training loss: 0.06360691040754318
Validation loss: 1.4245903094609578

Epoch: 5| Step: 9
Training loss: 0.05816314369440079
Validation loss: 1.4471212535776117

Epoch: 5| Step: 10
Training loss: 0.04997292160987854
Validation loss: 1.4407696723937988

Epoch: 632| Step: 0
Training loss: 0.05263693258166313
Validation loss: 1.4281665317473873

Epoch: 5| Step: 1
Training loss: 0.07862310111522675
Validation loss: 1.4270387990500337

Epoch: 5| Step: 2
Training loss: 0.06325574964284897
Validation loss: 1.4652236546239545

Epoch: 5| Step: 3
Training loss: 0.08279690146446228
Validation loss: 1.4502070770468762

Epoch: 5| Step: 4
Training loss: 0.047844599932432175
Validation loss: 1.451100487862864

Epoch: 5| Step: 5
Training loss: 0.09330341964960098
Validation loss: 1.4522050849853023

Epoch: 5| Step: 6
Training loss: 0.057100486010313034
Validation loss: 1.449647020268184

Epoch: 5| Step: 7
Training loss: 0.050547122955322266
Validation loss: 1.4554471931149882

Epoch: 5| Step: 8
Training loss: 0.054638247936964035
Validation loss: 1.423777876361724

Epoch: 5| Step: 9
Training loss: 0.07842989265918732
Validation loss: 1.4470991505089628

Epoch: 5| Step: 10
Training loss: 0.06484859436750412
Validation loss: 1.4174084817209551

Epoch: 633| Step: 0
Training loss: 0.06598947942256927
Validation loss: 1.4629576488207745

Epoch: 5| Step: 1
Training loss: 0.04601944610476494
Validation loss: 1.4743722279866536

Epoch: 5| Step: 2
Training loss: 0.08447062969207764
Validation loss: 1.4774277940873177

Epoch: 5| Step: 3
Training loss: 0.08268329501152039
Validation loss: 1.469212721752864

Epoch: 5| Step: 4
Training loss: 0.07141067832708359
Validation loss: 1.463417169227395

Epoch: 5| Step: 5
Training loss: 0.0467802956700325
Validation loss: 1.4802114002166256

Epoch: 5| Step: 6
Training loss: 0.06640646606683731
Validation loss: 1.446498687549304

Epoch: 5| Step: 7
Training loss: 0.04101480543613434
Validation loss: 1.455582896868388

Epoch: 5| Step: 8
Training loss: 0.04420823976397514
Validation loss: 1.420433025206289

Epoch: 5| Step: 9
Training loss: 0.09674081951379776
Validation loss: 1.4344366109499367

Epoch: 5| Step: 10
Training loss: 0.043638214468955994
Validation loss: 1.423114666374781

Epoch: 634| Step: 0
Training loss: 0.05469367653131485
Validation loss: 1.4148309448713898

Epoch: 5| Step: 1
Training loss: 0.061351098120212555
Validation loss: 1.4139159860149506

Epoch: 5| Step: 2
Training loss: 0.08598630130290985
Validation loss: 1.41142866944754

Epoch: 5| Step: 3
Training loss: 0.045316558331251144
Validation loss: 1.4221546342295985

Epoch: 5| Step: 4
Training loss: 0.07010477036237717
Validation loss: 1.438026056494764

Epoch: 5| Step: 5
Training loss: 0.055146653205156326
Validation loss: 1.4340277551322855

Epoch: 5| Step: 6
Training loss: 0.052364498376846313
Validation loss: 1.415315128141834

Epoch: 5| Step: 7
Training loss: 0.058920394629240036
Validation loss: 1.4290106168357275

Epoch: 5| Step: 8
Training loss: 0.05413573235273361
Validation loss: 1.4268295482922626

Epoch: 5| Step: 9
Training loss: 0.06515394151210785
Validation loss: 1.4354094779619606

Epoch: 5| Step: 10
Training loss: 0.08045583218336105
Validation loss: 1.4229940419555993

Epoch: 635| Step: 0
Training loss: 0.045362163335084915
Validation loss: 1.42190267321884

Epoch: 5| Step: 1
Training loss: 0.03880215436220169
Validation loss: 1.394754744345142

Epoch: 5| Step: 2
Training loss: 0.03273283690214157
Validation loss: 1.4021089512814757

Epoch: 5| Step: 3
Training loss: 0.06750175356864929
Validation loss: 1.4149299129363029

Epoch: 5| Step: 4
Training loss: 0.052996791899204254
Validation loss: 1.4151066195580266

Epoch: 5| Step: 5
Training loss: 0.055761564522981644
Validation loss: 1.4027947328423942

Epoch: 5| Step: 6
Training loss: 0.06374481320381165
Validation loss: 1.3875500438033894

Epoch: 5| Step: 7
Training loss: 0.080954410135746
Validation loss: 1.4142814797739829

Epoch: 5| Step: 8
Training loss: 0.07501643151044846
Validation loss: 1.373877251660952

Epoch: 5| Step: 9
Training loss: 0.058204106986522675
Validation loss: 1.3986887483186619

Epoch: 5| Step: 10
Training loss: 0.07017312198877335
Validation loss: 1.3997772662870345

Epoch: 636| Step: 0
Training loss: 0.06168843060731888
Validation loss: 1.4038998106474518

Epoch: 5| Step: 1
Training loss: 0.06882894039154053
Validation loss: 1.4185295771527033

Epoch: 5| Step: 2
Training loss: 0.04528253525495529
Validation loss: 1.4334356772002352

Epoch: 5| Step: 3
Training loss: 0.06974135339260101
Validation loss: 1.4346919290481075

Epoch: 5| Step: 4
Training loss: 0.05212201923131943
Validation loss: 1.425438029791719

Epoch: 5| Step: 5
Training loss: 0.04973044991493225
Validation loss: 1.4232200614867672

Epoch: 5| Step: 6
Training loss: 0.053640108555555344
Validation loss: 1.4378083816138647

Epoch: 5| Step: 7
Training loss: 0.07203088700771332
Validation loss: 1.4289209394044773

Epoch: 5| Step: 8
Training loss: 0.03868941590189934
Validation loss: 1.3934814430052234

Epoch: 5| Step: 9
Training loss: 0.057045839726924896
Validation loss: 1.4239800091712707

Epoch: 5| Step: 10
Training loss: 0.09202674776315689
Validation loss: 1.4328625894361926

Epoch: 637| Step: 0
Training loss: 0.060373879969120026
Validation loss: 1.4451483654719528

Epoch: 5| Step: 1
Training loss: 0.05817375332117081
Validation loss: 1.4335985657989339

Epoch: 5| Step: 2
Training loss: 0.07083278149366379
Validation loss: 1.437182508489137

Epoch: 5| Step: 3
Training loss: 0.07052818685770035
Validation loss: 1.4201550265794158

Epoch: 5| Step: 4
Training loss: 0.04958934709429741
Validation loss: 1.4064209973940285

Epoch: 5| Step: 5
Training loss: 0.061490416526794434
Validation loss: 1.4316529509841756

Epoch: 5| Step: 6
Training loss: 0.06062550097703934
Validation loss: 1.4466374702351068

Epoch: 5| Step: 7
Training loss: 0.06265677511692047
Validation loss: 1.4241597303139266

Epoch: 5| Step: 8
Training loss: 0.06331481039524078
Validation loss: 1.4401428571311377

Epoch: 5| Step: 9
Training loss: 0.03557787090539932
Validation loss: 1.4433105530277375

Epoch: 5| Step: 10
Training loss: 0.0596160963177681
Validation loss: 1.4578446880463631

Epoch: 638| Step: 0
Training loss: 0.07341491430997849
Validation loss: 1.4575437166357552

Epoch: 5| Step: 1
Training loss: 0.08332572877407074
Validation loss: 1.4676991188397972

Epoch: 5| Step: 2
Training loss: 0.05830994248390198
Validation loss: 1.4791577381472434

Epoch: 5| Step: 3
Training loss: 0.06082793325185776
Validation loss: 1.461350340356109

Epoch: 5| Step: 4
Training loss: 0.05526398494839668
Validation loss: 1.4541287242725331

Epoch: 5| Step: 5
Training loss: 0.04589077830314636
Validation loss: 1.4196181117847402

Epoch: 5| Step: 6
Training loss: 0.041865043342113495
Validation loss: 1.4552418596001082

Epoch: 5| Step: 7
Training loss: 0.0472649410367012
Validation loss: 1.4428441473232803

Epoch: 5| Step: 8
Training loss: 0.06683720648288727
Validation loss: 1.435765847083061

Epoch: 5| Step: 9
Training loss: 0.050483085215091705
Validation loss: 1.4282748314642137

Epoch: 5| Step: 10
Training loss: 0.03662427142262459
Validation loss: 1.4461998580604472

Epoch: 639| Step: 0
Training loss: 0.044103074818849564
Validation loss: 1.4221145247900358

Epoch: 5| Step: 1
Training loss: 0.06215550750494003
Validation loss: 1.418471295346496

Epoch: 5| Step: 2
Training loss: 0.07384493947029114
Validation loss: 1.4203964830726705

Epoch: 5| Step: 3
Training loss: 0.07668425142765045
Validation loss: 1.4316501950704923

Epoch: 5| Step: 4
Training loss: 0.05235246941447258
Validation loss: 1.3904608411173667

Epoch: 5| Step: 5
Training loss: 0.03445259854197502
Validation loss: 1.4104050282509095

Epoch: 5| Step: 6
Training loss: 0.06343832612037659
Validation loss: 1.4276517950078493

Epoch: 5| Step: 7
Training loss: 0.09843705594539642
Validation loss: 1.426267590574039

Epoch: 5| Step: 8
Training loss: 0.060969553887844086
Validation loss: 1.427293182701193

Epoch: 5| Step: 9
Training loss: 0.06604862213134766
Validation loss: 1.4225628055552

Epoch: 5| Step: 10
Training loss: 0.09970183670520782
Validation loss: 1.4645666640291932

Epoch: 640| Step: 0
Training loss: 0.08784820139408112
Validation loss: 1.4759230613708496

Epoch: 5| Step: 1
Training loss: 0.09224780648946762
Validation loss: 1.5018800227872786

Epoch: 5| Step: 2
Training loss: 0.06622080504894257
Validation loss: 1.469826336829893

Epoch: 5| Step: 3
Training loss: 0.0408906564116478
Validation loss: 1.446668274940983

Epoch: 5| Step: 4
Training loss: 0.05506012588739395
Validation loss: 1.4346391424056022

Epoch: 5| Step: 5
Training loss: 0.062036335468292236
Validation loss: 1.440324737179664

Epoch: 5| Step: 6
Training loss: 0.0907425582408905
Validation loss: 1.4359276172935322

Epoch: 5| Step: 7
Training loss: 0.05991508811712265
Validation loss: 1.4065514969569382

Epoch: 5| Step: 8
Training loss: 0.06932298094034195
Validation loss: 1.4293314795340262

Epoch: 5| Step: 9
Training loss: 0.0756630152463913
Validation loss: 1.415211586542027

Epoch: 5| Step: 10
Training loss: 0.05581348016858101
Validation loss: 1.4193765988913916

Epoch: 641| Step: 0
Training loss: 0.06205831095576286
Validation loss: 1.4388908211902907

Epoch: 5| Step: 1
Training loss: 0.07049953192472458
Validation loss: 1.3922704304418256

Epoch: 5| Step: 2
Training loss: 0.07251571118831635
Validation loss: 1.4054385821024578

Epoch: 5| Step: 3
Training loss: 0.08462293446063995
Validation loss: 1.4304809762585549

Epoch: 5| Step: 4
Training loss: 0.10660131275653839
Validation loss: 1.4166230860576834

Epoch: 5| Step: 5
Training loss: 0.0857497975230217
Validation loss: 1.435603246893934

Epoch: 5| Step: 6
Training loss: 0.06985677033662796
Validation loss: 1.4565824565067087

Epoch: 5| Step: 7
Training loss: 0.10296420007944107
Validation loss: 1.480805065042229

Epoch: 5| Step: 8
Training loss: 0.07751702517271042
Validation loss: 1.4731426777378205

Epoch: 5| Step: 9
Training loss: 0.07705158740282059
Validation loss: 1.498596437515751

Epoch: 5| Step: 10
Training loss: 0.061808403581380844
Validation loss: 1.5004913524914814

Epoch: 642| Step: 0
Training loss: 0.06314466893672943
Validation loss: 1.48176041213415

Epoch: 5| Step: 1
Training loss: 0.10290858894586563
Validation loss: 1.4714869901698122

Epoch: 5| Step: 2
Training loss: 0.05199063941836357
Validation loss: 1.4816516118664895

Epoch: 5| Step: 3
Training loss: 0.08549389988183975
Validation loss: 1.4671963760929723

Epoch: 5| Step: 4
Training loss: 0.04464646428823471
Validation loss: 1.4607207050887487

Epoch: 5| Step: 5
Training loss: 0.04663544148206711
Validation loss: 1.4699086194397302

Epoch: 5| Step: 6
Training loss: 0.0793856829404831
Validation loss: 1.4625852364365772

Epoch: 5| Step: 7
Training loss: 0.04854194447398186
Validation loss: 1.4546447287323654

Epoch: 5| Step: 8
Training loss: 0.04754192754626274
Validation loss: 1.4599351267660818

Epoch: 5| Step: 9
Training loss: 0.07300572097301483
Validation loss: 1.461206861721572

Epoch: 5| Step: 10
Training loss: 0.02858029119670391
Validation loss: 1.458084253854649

Epoch: 643| Step: 0
Training loss: 0.06622584909200668
Validation loss: 1.4409856629628006

Epoch: 5| Step: 1
Training loss: 0.04425244778394699
Validation loss: 1.4572306884232389

Epoch: 5| Step: 2
Training loss: 0.07243391126394272
Validation loss: 1.4260279215792173

Epoch: 5| Step: 3
Training loss: 0.08085216581821442
Validation loss: 1.4529169861988356

Epoch: 5| Step: 4
Training loss: 0.0477340891957283
Validation loss: 1.4184505779256102

Epoch: 5| Step: 5
Training loss: 0.07893434911966324
Validation loss: 1.439404623482817

Epoch: 5| Step: 6
Training loss: 0.048297055065631866
Validation loss: 1.428754815491297

Epoch: 5| Step: 7
Training loss: 0.05505567044019699
Validation loss: 1.4044980496488593

Epoch: 5| Step: 8
Training loss: 0.0464467890560627
Validation loss: 1.411197659789875

Epoch: 5| Step: 9
Training loss: 0.0579463467001915
Validation loss: 1.4081629283966557

Epoch: 5| Step: 10
Training loss: 0.05279389023780823
Validation loss: 1.412284315273326

Epoch: 644| Step: 0
Training loss: 0.08083969354629517
Validation loss: 1.4198259602310837

Epoch: 5| Step: 1
Training loss: 0.04070444032549858
Validation loss: 1.4125415125200826

Epoch: 5| Step: 2
Training loss: 0.07748685777187347
Validation loss: 1.4152515139631046

Epoch: 5| Step: 3
Training loss: 0.08279931545257568
Validation loss: 1.4062729766291957

Epoch: 5| Step: 4
Training loss: 0.06270326673984528
Validation loss: 1.4286709780334144

Epoch: 5| Step: 5
Training loss: 0.05283479765057564
Validation loss: 1.4242931565930765

Epoch: 5| Step: 6
Training loss: 0.04441871494054794
Validation loss: 1.4059034137315647

Epoch: 5| Step: 7
Training loss: 0.04825112596154213
Validation loss: 1.4404052726684078

Epoch: 5| Step: 8
Training loss: 0.07320244610309601
Validation loss: 1.4201850077157379

Epoch: 5| Step: 9
Training loss: 0.05484656244516373
Validation loss: 1.4481246445768623

Epoch: 5| Step: 10
Training loss: 0.05447777733206749
Validation loss: 1.4303433408019364

Epoch: 645| Step: 0
Training loss: 0.04716261103749275
Validation loss: 1.440249676345497

Epoch: 5| Step: 1
Training loss: 0.0915239229798317
Validation loss: 1.43569133486799

Epoch: 5| Step: 2
Training loss: 0.07348429411649704
Validation loss: 1.4308034604595554

Epoch: 5| Step: 3
Training loss: 0.08403493463993073
Validation loss: 1.447023642960415

Epoch: 5| Step: 4
Training loss: 0.04746450111269951
Validation loss: 1.4168196628170628

Epoch: 5| Step: 5
Training loss: 0.06931208819150925
Validation loss: 1.4157464959288155

Epoch: 5| Step: 6
Training loss: 0.06933186948299408
Validation loss: 1.4148223118115497

Epoch: 5| Step: 7
Training loss: 0.06025420501828194
Validation loss: 1.4384645518436228

Epoch: 5| Step: 8
Training loss: 0.08513715118169785
Validation loss: 1.439094808793837

Epoch: 5| Step: 9
Training loss: 0.12045510858297348
Validation loss: 1.435193064392254

Epoch: 5| Step: 10
Training loss: 0.07769977301359177
Validation loss: 1.4484468685683383

Epoch: 646| Step: 0
Training loss: 0.06226039677858353
Validation loss: 1.431892136091827

Epoch: 5| Step: 1
Training loss: 0.05346645787358284
Validation loss: 1.4349656181950723

Epoch: 5| Step: 2
Training loss: 0.10744820535182953
Validation loss: 1.446461163541322

Epoch: 5| Step: 3
Training loss: 0.04827084764838219
Validation loss: 1.4745648387939698

Epoch: 5| Step: 4
Training loss: 0.04020242020487785
Validation loss: 1.4656819297421364

Epoch: 5| Step: 5
Training loss: 0.08210143446922302
Validation loss: 1.4598371110936648

Epoch: 5| Step: 6
Training loss: 0.08035732805728912
Validation loss: 1.4528710342222644

Epoch: 5| Step: 7
Training loss: 0.03826874494552612
Validation loss: 1.4403155811371342

Epoch: 5| Step: 8
Training loss: 0.06783615052700043
Validation loss: 1.4402297901850876

Epoch: 5| Step: 9
Training loss: 0.03693866357207298
Validation loss: 1.4479495748396842

Epoch: 5| Step: 10
Training loss: 0.05637839436531067
Validation loss: 1.4632028918112479

Epoch: 647| Step: 0
Training loss: 0.07984607666730881
Validation loss: 1.457064260718643

Epoch: 5| Step: 1
Training loss: 0.07548445463180542
Validation loss: 1.4304762181415354

Epoch: 5| Step: 2
Training loss: 0.05612953379750252
Validation loss: 1.4184962152152933

Epoch: 5| Step: 3
Training loss: 0.07253735512495041
Validation loss: 1.4311442862274826

Epoch: 5| Step: 4
Training loss: 0.046550873667001724
Validation loss: 1.4221970330002487

Epoch: 5| Step: 5
Training loss: 0.11105415970087051
Validation loss: 1.4249193501728836

Epoch: 5| Step: 6
Training loss: 0.054216496646404266
Validation loss: 1.4191936023773686

Epoch: 5| Step: 7
Training loss: 0.06589410454034805
Validation loss: 1.4137079023545789

Epoch: 5| Step: 8
Training loss: 0.05759458988904953
Validation loss: 1.3984972450041002

Epoch: 5| Step: 9
Training loss: 0.0598764643073082
Validation loss: 1.4218911060722925

Epoch: 5| Step: 10
Training loss: 0.09429025650024414
Validation loss: 1.4329527360136791

Epoch: 648| Step: 0
Training loss: 0.04718790203332901
Validation loss: 1.4500479935317911

Epoch: 5| Step: 1
Training loss: 0.049045272171497345
Validation loss: 1.4452318478656072

Epoch: 5| Step: 2
Training loss: 0.07783690840005875
Validation loss: 1.4450063051715973

Epoch: 5| Step: 3
Training loss: 0.056880246847867966
Validation loss: 1.445526861375378

Epoch: 5| Step: 4
Training loss: 0.06589603424072266
Validation loss: 1.4506227957305087

Epoch: 5| Step: 5
Training loss: 0.08334580808877945
Validation loss: 1.435053571577995

Epoch: 5| Step: 6
Training loss: 0.08145558089017868
Validation loss: 1.427324019452577

Epoch: 5| Step: 7
Training loss: 0.061969269067049026
Validation loss: 1.423733075459798

Epoch: 5| Step: 8
Training loss: 0.08325566351413727
Validation loss: 1.422330576886413

Epoch: 5| Step: 9
Training loss: 0.04954001307487488
Validation loss: 1.421663325320008

Epoch: 5| Step: 10
Training loss: 0.06758857518434525
Validation loss: 1.4310507091783708

Epoch: 649| Step: 0
Training loss: 0.05776331573724747
Validation loss: 1.4114932437096872

Epoch: 5| Step: 1
Training loss: 0.058088283985853195
Validation loss: 1.3910463026133917

Epoch: 5| Step: 2
Training loss: 0.039070699363946915
Validation loss: 1.4241900661940217

Epoch: 5| Step: 3
Training loss: 0.06750563532114029
Validation loss: 1.423897462506448

Epoch: 5| Step: 4
Training loss: 0.053454287350177765
Validation loss: 1.4024874574394637

Epoch: 5| Step: 5
Training loss: 0.07594551146030426
Validation loss: 1.4040190955644012

Epoch: 5| Step: 6
Training loss: 0.043800145387649536
Validation loss: 1.3687762034836637

Epoch: 5| Step: 7
Training loss: 0.06445012986660004
Validation loss: 1.4000109985310545

Epoch: 5| Step: 8
Training loss: 0.07102957367897034
Validation loss: 1.4070156030757452

Epoch: 5| Step: 9
Training loss: 0.05437648296356201
Validation loss: 1.4060234818407285

Epoch: 5| Step: 10
Training loss: 0.0357111394405365
Validation loss: 1.4035198560325048

Epoch: 650| Step: 0
Training loss: 0.07535991817712784
Validation loss: 1.4189153223909357

Epoch: 5| Step: 1
Training loss: 0.05792676657438278
Validation loss: 1.4026785178851056

Epoch: 5| Step: 2
Training loss: 0.050602853298187256
Validation loss: 1.4147205122055546

Epoch: 5| Step: 3
Training loss: 0.037414345890283585
Validation loss: 1.4127634545808196

Epoch: 5| Step: 4
Training loss: 0.06592853367328644
Validation loss: 1.4297657294939923

Epoch: 5| Step: 5
Training loss: 0.06645341217517853
Validation loss: 1.4116003833791262

Epoch: 5| Step: 6
Training loss: 0.055762141942977905
Validation loss: 1.4274044934139456

Epoch: 5| Step: 7
Training loss: 0.06735764443874359
Validation loss: 1.4177682438204366

Epoch: 5| Step: 8
Training loss: 0.08399166911840439
Validation loss: 1.400431747718524

Epoch: 5| Step: 9
Training loss: 0.0629812702536583
Validation loss: 1.4088157133389545

Epoch: 5| Step: 10
Training loss: 0.07885046303272247
Validation loss: 1.398041489303753

Epoch: 651| Step: 0
Training loss: 0.06470578908920288
Validation loss: 1.3955596759114215

Epoch: 5| Step: 1
Training loss: 0.07320059835910797
Validation loss: 1.3722573608480475

Epoch: 5| Step: 2
Training loss: 0.059025924652814865
Validation loss: 1.394696827857725

Epoch: 5| Step: 3
Training loss: 0.04373631626367569
Validation loss: 1.3850821346364997

Epoch: 5| Step: 4
Training loss: 0.06831194460391998
Validation loss: 1.398387106516028

Epoch: 5| Step: 5
Training loss: 0.061545707285404205
Validation loss: 1.3877483670429518

Epoch: 5| Step: 6
Training loss: 0.06202083081007004
Validation loss: 1.3832019195761731

Epoch: 5| Step: 7
Training loss: 0.06692737340927124
Validation loss: 1.3885143918375815

Epoch: 5| Step: 8
Training loss: 0.04868563264608383
Validation loss: 1.392063602324455

Epoch: 5| Step: 9
Training loss: 0.10899430513381958
Validation loss: 1.4028117772071593

Epoch: 5| Step: 10
Training loss: 0.05497080832719803
Validation loss: 1.4272617768215876

Epoch: 652| Step: 0
Training loss: 0.08207683265209198
Validation loss: 1.4293063943104078

Epoch: 5| Step: 1
Training loss: 0.0664777159690857
Validation loss: 1.437109899777238

Epoch: 5| Step: 2
Training loss: 0.08064388483762741
Validation loss: 1.412885255711053

Epoch: 5| Step: 3
Training loss: 0.04532343149185181
Validation loss: 1.4535541085786716

Epoch: 5| Step: 4
Training loss: 0.06782074272632599
Validation loss: 1.4460124020935388

Epoch: 5| Step: 5
Training loss: 0.056184321641922
Validation loss: 1.433451582026738

Epoch: 5| Step: 6
Training loss: 0.0709558054804802
Validation loss: 1.4305313402606594

Epoch: 5| Step: 7
Training loss: 0.04883648082613945
Validation loss: 1.4401195959378315

Epoch: 5| Step: 8
Training loss: 0.04227561503648758
Validation loss: 1.4363641021072224

Epoch: 5| Step: 9
Training loss: 0.06501956284046173
Validation loss: 1.4292885513715847

Epoch: 5| Step: 10
Training loss: 0.029206888750195503
Validation loss: 1.4391722691956388

Epoch: 653| Step: 0
Training loss: 0.05927107483148575
Validation loss: 1.4313830893526795

Epoch: 5| Step: 1
Training loss: 0.04412959888577461
Validation loss: 1.4165271712887673

Epoch: 5| Step: 2
Training loss: 0.0762571319937706
Validation loss: 1.4098606590301759

Epoch: 5| Step: 3
Training loss: 0.050538789480924606
Validation loss: 1.425435737896991

Epoch: 5| Step: 4
Training loss: 0.0463143065571785
Validation loss: 1.4229274693355765

Epoch: 5| Step: 5
Training loss: 0.041146863251924515
Validation loss: 1.4181909996976134

Epoch: 5| Step: 6
Training loss: 0.032900359481573105
Validation loss: 1.4347448989909182

Epoch: 5| Step: 7
Training loss: 0.07201819866895676
Validation loss: 1.4095232204724384

Epoch: 5| Step: 8
Training loss: 0.0379275381565094
Validation loss: 1.4260426708447036

Epoch: 5| Step: 9
Training loss: 0.06349369883537292
Validation loss: 1.423862124002108

Epoch: 5| Step: 10
Training loss: 0.041303928941488266
Validation loss: 1.4312850608620593

Epoch: 654| Step: 0
Training loss: 0.07104657590389252
Validation loss: 1.4396882031553535

Epoch: 5| Step: 1
Training loss: 0.04780048877000809
Validation loss: 1.422110721629153

Epoch: 5| Step: 2
Training loss: 0.04997418448328972
Validation loss: 1.4282616287149408

Epoch: 5| Step: 3
Training loss: 0.03791741281747818
Validation loss: 1.4248909219618766

Epoch: 5| Step: 4
Training loss: 0.0815843716263771
Validation loss: 1.4292123766355618

Epoch: 5| Step: 5
Training loss: 0.04407305270433426
Validation loss: 1.4184606280378116

Epoch: 5| Step: 6
Training loss: 0.06152027100324631
Validation loss: 1.4091549560587893

Epoch: 5| Step: 7
Training loss: 0.07101617753505707
Validation loss: 1.419418087569616

Epoch: 5| Step: 8
Training loss: 0.061701737344264984
Validation loss: 1.413342934782787

Epoch: 5| Step: 9
Training loss: 0.050608061254024506
Validation loss: 1.4184160950363323

Epoch: 5| Step: 10
Training loss: 0.04724668711423874
Validation loss: 1.4373439364535834

Epoch: 655| Step: 0
Training loss: 0.045985620468854904
Validation loss: 1.4249742518189132

Epoch: 5| Step: 1
Training loss: 0.06606141477823257
Validation loss: 1.4107742104479062

Epoch: 5| Step: 2
Training loss: 0.059222687035799026
Validation loss: 1.40939675992535

Epoch: 5| Step: 3
Training loss: 0.05124223232269287
Validation loss: 1.4193182427396056

Epoch: 5| Step: 4
Training loss: 0.033631328493356705
Validation loss: 1.407483794355905

Epoch: 5| Step: 5
Training loss: 0.04232364520430565
Validation loss: 1.4207881125070716

Epoch: 5| Step: 6
Training loss: 0.04466940835118294
Validation loss: 1.434265076473195

Epoch: 5| Step: 7
Training loss: 0.040304213762283325
Validation loss: 1.4350861016140188

Epoch: 5| Step: 8
Training loss: 0.07650847733020782
Validation loss: 1.4413805136116602

Epoch: 5| Step: 9
Training loss: 0.03392292931675911
Validation loss: 1.438791242978906

Epoch: 5| Step: 10
Training loss: 0.07130208611488342
Validation loss: 1.4705687613897427

Epoch: 656| Step: 0
Training loss: 0.05939318612217903
Validation loss: 1.436153611829204

Epoch: 5| Step: 1
Training loss: 0.06820344924926758
Validation loss: 1.4524338681210753

Epoch: 5| Step: 2
Training loss: 0.09219726175069809
Validation loss: 1.473693641283179

Epoch: 5| Step: 3
Training loss: 0.043709896504879
Validation loss: 1.4482087922352616

Epoch: 5| Step: 4
Training loss: 0.04973052442073822
Validation loss: 1.474951458233659

Epoch: 5| Step: 5
Training loss: 0.0392284169793129
Validation loss: 1.452229788226466

Epoch: 5| Step: 6
Training loss: 0.05524598807096481
Validation loss: 1.44066571932967

Epoch: 5| Step: 7
Training loss: 0.056902527809143066
Validation loss: 1.4391631721168436

Epoch: 5| Step: 8
Training loss: 0.06727525591850281
Validation loss: 1.4261614353426042

Epoch: 5| Step: 9
Training loss: 0.05736122280359268
Validation loss: 1.4305566267300678

Epoch: 5| Step: 10
Training loss: 0.041151273995637894
Validation loss: 1.4550247820474769

Epoch: 657| Step: 0
Training loss: 0.05656394362449646
Validation loss: 1.454237748217839

Epoch: 5| Step: 1
Training loss: 0.041395045816898346
Validation loss: 1.430490691174743

Epoch: 5| Step: 2
Training loss: 0.030604714527726173
Validation loss: 1.437774560784781

Epoch: 5| Step: 3
Training loss: 0.05625868961215019
Validation loss: 1.4389060665202398

Epoch: 5| Step: 4
Training loss: 0.058179449290037155
Validation loss: 1.4396322388802805

Epoch: 5| Step: 5
Training loss: 0.06398705393075943
Validation loss: 1.45349117120107

Epoch: 5| Step: 6
Training loss: 0.07999441772699356
Validation loss: 1.461444785518031

Epoch: 5| Step: 7
Training loss: 0.051963068544864655
Validation loss: 1.4372437513002785

Epoch: 5| Step: 8
Training loss: 0.06278003007173538
Validation loss: 1.4569171615826186

Epoch: 5| Step: 9
Training loss: 0.06503285467624664
Validation loss: 1.4190343951666227

Epoch: 5| Step: 10
Training loss: 0.042588140815496445
Validation loss: 1.4332151361691055

Epoch: 658| Step: 0
Training loss: 0.036453671753406525
Validation loss: 1.4108397460752917

Epoch: 5| Step: 1
Training loss: 0.08118291199207306
Validation loss: 1.3980027411573677

Epoch: 5| Step: 2
Training loss: 0.07644794881343842
Validation loss: 1.3761287030353342

Epoch: 5| Step: 3
Training loss: 0.10055772215127945
Validation loss: 1.3596216388927993

Epoch: 5| Step: 4
Training loss: 0.062093086540699005
Validation loss: 1.3609517607637631

Epoch: 5| Step: 5
Training loss: 0.06402385234832764
Validation loss: 1.4002769595833235

Epoch: 5| Step: 6
Training loss: 0.04589501768350601
Validation loss: 1.4028335437979749

Epoch: 5| Step: 7
Training loss: 0.0323311984539032
Validation loss: 1.3985432219761673

Epoch: 5| Step: 8
Training loss: 0.05171321704983711
Validation loss: 1.4188828961823576

Epoch: 5| Step: 9
Training loss: 0.03206450864672661
Validation loss: 1.4226757903252878

Epoch: 5| Step: 10
Training loss: 0.061803676187992096
Validation loss: 1.419153001359714

Epoch: 659| Step: 0
Training loss: 0.0452568419277668
Validation loss: 1.4213010418799616

Epoch: 5| Step: 1
Training loss: 0.055562324821949005
Validation loss: 1.4278206325346423

Epoch: 5| Step: 2
Training loss: 0.05501013994216919
Validation loss: 1.417033690278248

Epoch: 5| Step: 3
Training loss: 0.0474056676030159
Validation loss: 1.4277458934373752

Epoch: 5| Step: 4
Training loss: 0.047893621027469635
Validation loss: 1.4464453753604685

Epoch: 5| Step: 5
Training loss: 0.06272099167108536
Validation loss: 1.4153449125187372

Epoch: 5| Step: 6
Training loss: 0.05261998251080513
Validation loss: 1.4238084823854509

Epoch: 5| Step: 7
Training loss: 0.06747329980134964
Validation loss: 1.427198565134438

Epoch: 5| Step: 8
Training loss: 0.05518827959895134
Validation loss: 1.4194586283417159

Epoch: 5| Step: 9
Training loss: 0.07786808907985687
Validation loss: 1.4234878504148094

Epoch: 5| Step: 10
Training loss: 0.056989070028066635
Validation loss: 1.4140010456885062

Epoch: 660| Step: 0
Training loss: 0.07643364369869232
Validation loss: 1.4483281540614303

Epoch: 5| Step: 1
Training loss: 0.030700426548719406
Validation loss: 1.4133158024921213

Epoch: 5| Step: 2
Training loss: 0.0401802659034729
Validation loss: 1.4151965520715202

Epoch: 5| Step: 3
Training loss: 0.028828512877225876
Validation loss: 1.4224275209570443

Epoch: 5| Step: 4
Training loss: 0.09172765165567398
Validation loss: 1.4338976401154713

Epoch: 5| Step: 5
Training loss: 0.047298938035964966
Validation loss: 1.4305333963004492

Epoch: 5| Step: 6
Training loss: 0.056004781275987625
Validation loss: 1.4510809106211509

Epoch: 5| Step: 7
Training loss: 0.05531972646713257
Validation loss: 1.4410907786379579

Epoch: 5| Step: 8
Training loss: 0.04115211218595505
Validation loss: 1.4368809923048942

Epoch: 5| Step: 9
Training loss: 0.06656239926815033
Validation loss: 1.4163051330915062

Epoch: 5| Step: 10
Training loss: 0.0603288970887661
Validation loss: 1.422158730927334

Epoch: 661| Step: 0
Training loss: 0.03113534487783909
Validation loss: 1.4367642800013225

Epoch: 5| Step: 1
Training loss: 0.05537367984652519
Validation loss: 1.436270877879153

Epoch: 5| Step: 2
Training loss: 0.09820298850536346
Validation loss: 1.4146430902583624

Epoch: 5| Step: 3
Training loss: 0.05003155395388603
Validation loss: 1.4292158452413415

Epoch: 5| Step: 4
Training loss: 0.03780055791139603
Validation loss: 1.441794330073941

Epoch: 5| Step: 5
Training loss: 0.09093038737773895
Validation loss: 1.4383747116211922

Epoch: 5| Step: 6
Training loss: 0.046632714569568634
Validation loss: 1.4436916048808763

Epoch: 5| Step: 7
Training loss: 0.05923786759376526
Validation loss: 1.44385394998776

Epoch: 5| Step: 8
Training loss: 0.03651482239365578
Validation loss: 1.4247309905226513

Epoch: 5| Step: 9
Training loss: 0.03838352486491203
Validation loss: 1.436882354238982

Epoch: 5| Step: 10
Training loss: 0.04437653347849846
Validation loss: 1.4171876035710818

Epoch: 662| Step: 0
Training loss: 0.04469069465994835
Validation loss: 1.4408900096852293

Epoch: 5| Step: 1
Training loss: 0.042393434792757034
Validation loss: 1.4339897530053252

Epoch: 5| Step: 2
Training loss: 0.06928227841854095
Validation loss: 1.4269820464554654

Epoch: 5| Step: 3
Training loss: 0.05483759194612503
Validation loss: 1.4389497490339382

Epoch: 5| Step: 4
Training loss: 0.0633058249950409
Validation loss: 1.4091122291421379

Epoch: 5| Step: 5
Training loss: 0.07965084165334702
Validation loss: 1.415288091987692

Epoch: 5| Step: 6
Training loss: 0.038477443158626556
Validation loss: 1.430885753323955

Epoch: 5| Step: 7
Training loss: 0.08346967399120331
Validation loss: 1.4266308373020542

Epoch: 5| Step: 8
Training loss: 0.03978483006358147
Validation loss: 1.3923518567956903

Epoch: 5| Step: 9
Training loss: 0.05637945979833603
Validation loss: 1.418392172423742

Epoch: 5| Step: 10
Training loss: 0.03863748535513878
Validation loss: 1.410255652602001

Epoch: 663| Step: 0
Training loss: 0.0717366486787796
Validation loss: 1.4251048705911125

Epoch: 5| Step: 1
Training loss: 0.0963844507932663
Validation loss: 1.3958591389399704

Epoch: 5| Step: 2
Training loss: 0.05832541733980179
Validation loss: 1.3950530047057776

Epoch: 5| Step: 3
Training loss: 0.05662340670824051
Validation loss: 1.40310368358448

Epoch: 5| Step: 4
Training loss: 0.08364294469356537
Validation loss: 1.418043368606157

Epoch: 5| Step: 5
Training loss: 0.05795162171125412
Validation loss: 1.4156906207402546

Epoch: 5| Step: 6
Training loss: 0.0462922677397728
Validation loss: 1.4390124967021327

Epoch: 5| Step: 7
Training loss: 0.045579589903354645
Validation loss: 1.44530140712697

Epoch: 5| Step: 8
Training loss: 0.06174959987401962
Validation loss: 1.4552104396204795

Epoch: 5| Step: 9
Training loss: 0.06657600402832031
Validation loss: 1.4509023748418337

Epoch: 5| Step: 10
Training loss: 0.05268385261297226
Validation loss: 1.4606154452088058

Epoch: 664| Step: 0
Training loss: 0.06039164215326309
Validation loss: 1.4385950719156573

Epoch: 5| Step: 1
Training loss: 0.052263569086790085
Validation loss: 1.4593379343709638

Epoch: 5| Step: 2
Training loss: 0.04718034714460373
Validation loss: 1.4405813652981994

Epoch: 5| Step: 3
Training loss: 0.04287827014923096
Validation loss: 1.4378919973168323

Epoch: 5| Step: 4
Training loss: 0.06815484911203384
Validation loss: 1.4327076840144333

Epoch: 5| Step: 5
Training loss: 0.052636753767728806
Validation loss: 1.4315835134957426

Epoch: 5| Step: 6
Training loss: 0.03306053206324577
Validation loss: 1.4335889239465036

Epoch: 5| Step: 7
Training loss: 0.07033385336399078
Validation loss: 1.4160195191701253

Epoch: 5| Step: 8
Training loss: 0.05787258222699165
Validation loss: 1.395080045987201

Epoch: 5| Step: 9
Training loss: 0.05180228874087334
Validation loss: 1.4088426764293382

Epoch: 5| Step: 10
Training loss: 0.06624263525009155
Validation loss: 1.4229876924586553

Epoch: 665| Step: 0
Training loss: 0.05352409556508064
Validation loss: 1.4150934873088714

Epoch: 5| Step: 1
Training loss: 0.07042884081602097
Validation loss: 1.4105568829403128

Epoch: 5| Step: 2
Training loss: 0.046372074633836746
Validation loss: 1.4073526500373759

Epoch: 5| Step: 3
Training loss: 0.06349022686481476
Validation loss: 1.430676898648662

Epoch: 5| Step: 4
Training loss: 0.04332950711250305
Validation loss: 1.4241999580014137

Epoch: 5| Step: 5
Training loss: 0.030328232795000076
Validation loss: 1.4387980968721452

Epoch: 5| Step: 6
Training loss: 0.07038115710020065
Validation loss: 1.4447252904215167

Epoch: 5| Step: 7
Training loss: 0.07141976803541183
Validation loss: 1.4435601759982366

Epoch: 5| Step: 8
Training loss: 0.05435055494308472
Validation loss: 1.4239984814838698

Epoch: 5| Step: 9
Training loss: 0.07038923352956772
Validation loss: 1.4306494651302215

Epoch: 5| Step: 10
Training loss: 0.040051087737083435
Validation loss: 1.4299764851088166

Epoch: 666| Step: 0
Training loss: 0.04604896157979965
Validation loss: 1.4273681986716487

Epoch: 5| Step: 1
Training loss: 0.07507918030023575
Validation loss: 1.428522430440431

Epoch: 5| Step: 2
Training loss: 0.03595399856567383
Validation loss: 1.4353516281292003

Epoch: 5| Step: 3
Training loss: 0.058767158538103104
Validation loss: 1.4373363551273142

Epoch: 5| Step: 4
Training loss: 0.04444097355008125
Validation loss: 1.4070450759703113

Epoch: 5| Step: 5
Training loss: 0.07006870210170746
Validation loss: 1.4222307538473478

Epoch: 5| Step: 6
Training loss: 0.06333903968334198
Validation loss: 1.4170152064292663

Epoch: 5| Step: 7
Training loss: 0.06615326553583145
Validation loss: 1.4343844972630984

Epoch: 5| Step: 8
Training loss: 0.05656924098730087
Validation loss: 1.4073313410564134

Epoch: 5| Step: 9
Training loss: 0.08097346872091293
Validation loss: 1.4074049008789884

Epoch: 5| Step: 10
Training loss: 0.04060451313853264
Validation loss: 1.428971798830135

Epoch: 667| Step: 0
Training loss: 0.03208991512656212
Validation loss: 1.4218861185094362

Epoch: 5| Step: 1
Training loss: 0.04498492181301117
Validation loss: 1.4022323880144345

Epoch: 5| Step: 2
Training loss: 0.05083218961954117
Validation loss: 1.4137576126283216

Epoch: 5| Step: 3
Training loss: 0.035827867686748505
Validation loss: 1.4321410335520262

Epoch: 5| Step: 4
Training loss: 0.06669829040765762
Validation loss: 1.4317854040412492

Epoch: 5| Step: 5
Training loss: 0.05462644249200821
Validation loss: 1.4394846603434572

Epoch: 5| Step: 6
Training loss: 0.02283778414130211
Validation loss: 1.4474156338681456

Epoch: 5| Step: 7
Training loss: 0.07172583043575287
Validation loss: 1.4422346366349088

Epoch: 5| Step: 8
Training loss: 0.06509427726268768
Validation loss: 1.4401184948541785

Epoch: 5| Step: 9
Training loss: 0.040496595203876495
Validation loss: 1.4360028710416568

Epoch: 5| Step: 10
Training loss: 0.057329267263412476
Validation loss: 1.4422816973860546

Epoch: 668| Step: 0
Training loss: 0.04284759610891342
Validation loss: 1.4413819697595411

Epoch: 5| Step: 1
Training loss: 0.06295619904994965
Validation loss: 1.4525716099687802

Epoch: 5| Step: 2
Training loss: 0.04368031769990921
Validation loss: 1.4379131819612236

Epoch: 5| Step: 3
Training loss: 0.04925757646560669
Validation loss: 1.4300462686887352

Epoch: 5| Step: 4
Training loss: 0.07278092205524445
Validation loss: 1.4414902438399613

Epoch: 5| Step: 5
Training loss: 0.05230317264795303
Validation loss: 1.4223828290098457

Epoch: 5| Step: 6
Training loss: 0.03960607573390007
Validation loss: 1.4338219447802472

Epoch: 5| Step: 7
Training loss: 0.08820223808288574
Validation loss: 1.4388478500868684

Epoch: 5| Step: 8
Training loss: 0.09718409925699234
Validation loss: 1.4480827290524718

Epoch: 5| Step: 9
Training loss: 0.05349675565958023
Validation loss: 1.46490062949478

Epoch: 5| Step: 10
Training loss: 0.05752379819750786
Validation loss: 1.4555718770591162

Epoch: 669| Step: 0
Training loss: 0.03967839479446411
Validation loss: 1.4715568006679576

Epoch: 5| Step: 1
Training loss: 0.080912284553051
Validation loss: 1.4775700376879783

Epoch: 5| Step: 2
Training loss: 0.047105949372053146
Validation loss: 1.4835454635722662

Epoch: 5| Step: 3
Training loss: 0.08589540421962738
Validation loss: 1.4611437333527433

Epoch: 5| Step: 4
Training loss: 0.05188484117388725
Validation loss: 1.4575384034905383

Epoch: 5| Step: 5
Training loss: 0.05745718628168106
Validation loss: 1.4668122260801253

Epoch: 5| Step: 6
Training loss: 0.04740481823682785
Validation loss: 1.451269800944995

Epoch: 5| Step: 7
Training loss: 0.08217573910951614
Validation loss: 1.4604269535310808

Epoch: 5| Step: 8
Training loss: 0.04700516536831856
Validation loss: 1.4493924738258444

Epoch: 5| Step: 9
Training loss: 0.05910761281847954
Validation loss: 1.4547862891227967

Epoch: 5| Step: 10
Training loss: 0.0581543892621994
Validation loss: 1.4417235556469168

Epoch: 670| Step: 0
Training loss: 0.04448210448026657
Validation loss: 1.4498102165037585

Epoch: 5| Step: 1
Training loss: 0.052518557757139206
Validation loss: 1.4447470852123794

Epoch: 5| Step: 2
Training loss: 0.07022823393344879
Validation loss: 1.4411088100043676

Epoch: 5| Step: 3
Training loss: 0.043155498802661896
Validation loss: 1.427842793926116

Epoch: 5| Step: 4
Training loss: 0.041277654469013214
Validation loss: 1.427750474663191

Epoch: 5| Step: 5
Training loss: 0.039957813918590546
Validation loss: 1.4443576515361827

Epoch: 5| Step: 6
Training loss: 0.040193360298871994
Validation loss: 1.4249206755750923

Epoch: 5| Step: 7
Training loss: 0.05818070098757744
Validation loss: 1.439248965632531

Epoch: 5| Step: 8
Training loss: 0.03683707118034363
Validation loss: 1.433901563767464

Epoch: 5| Step: 9
Training loss: 0.08772865682840347
Validation loss: 1.432709563163019

Epoch: 5| Step: 10
Training loss: 0.03585025295615196
Validation loss: 1.4343329334771762

Epoch: 671| Step: 0
Training loss: 0.051576387137174606
Validation loss: 1.4638444480075632

Epoch: 5| Step: 1
Training loss: 0.060191232711076736
Validation loss: 1.4328479177208358

Epoch: 5| Step: 2
Training loss: 0.037912290543317795
Validation loss: 1.4460960959875455

Epoch: 5| Step: 3
Training loss: 0.07580927014350891
Validation loss: 1.453388458939009

Epoch: 5| Step: 4
Training loss: 0.039164453744888306
Validation loss: 1.4337440434322561

Epoch: 5| Step: 5
Training loss: 0.05047035217285156
Validation loss: 1.444196815131813

Epoch: 5| Step: 6
Training loss: 0.06253113597631454
Validation loss: 1.4566229222923197

Epoch: 5| Step: 7
Training loss: 0.07613586634397507
Validation loss: 1.463417455714236

Epoch: 5| Step: 8
Training loss: 0.047544918954372406
Validation loss: 1.4437198408188359

Epoch: 5| Step: 9
Training loss: 0.04687079042196274
Validation loss: 1.457140061163133

Epoch: 5| Step: 10
Training loss: 0.04098563268780708
Validation loss: 1.4355993309328634

Epoch: 672| Step: 0
Training loss: 0.05032549053430557
Validation loss: 1.431992062958338

Epoch: 5| Step: 1
Training loss: 0.03901000693440437
Validation loss: 1.440289394829863

Epoch: 5| Step: 2
Training loss: 0.02668222226202488
Validation loss: 1.4318352976152975

Epoch: 5| Step: 3
Training loss: 0.034832485020160675
Validation loss: 1.4355723447697137

Epoch: 5| Step: 4
Training loss: 0.03346260264515877
Validation loss: 1.4479070965961744

Epoch: 5| Step: 5
Training loss: 0.10265161097049713
Validation loss: 1.4394097405095254

Epoch: 5| Step: 6
Training loss: 0.06027807667851448
Validation loss: 1.4252338845242736

Epoch: 5| Step: 7
Training loss: 0.04193953052163124
Validation loss: 1.4237840970357258

Epoch: 5| Step: 8
Training loss: 0.05992959812283516
Validation loss: 1.418479254168849

Epoch: 5| Step: 9
Training loss: 0.04059848189353943
Validation loss: 1.4038145849781651

Epoch: 5| Step: 10
Training loss: 0.057966481894254684
Validation loss: 1.41395983388347

Epoch: 673| Step: 0
Training loss: 0.04041846841573715
Validation loss: 1.4028901207831599

Epoch: 5| Step: 1
Training loss: 0.07220297306776047
Validation loss: 1.4051477909088135

Epoch: 5| Step: 2
Training loss: 0.06840738654136658
Validation loss: 1.4275943181848014

Epoch: 5| Step: 3
Training loss: 0.038510240614414215
Validation loss: 1.436849581938918

Epoch: 5| Step: 4
Training loss: 0.05574597045779228
Validation loss: 1.4209640397820422

Epoch: 5| Step: 5
Training loss: 0.03632853925228119
Validation loss: 1.4268865944236837

Epoch: 5| Step: 6
Training loss: 0.04184570163488388
Validation loss: 1.4433630999698435

Epoch: 5| Step: 7
Training loss: 0.04626015946269035
Validation loss: 1.4373705220478836

Epoch: 5| Step: 8
Training loss: 0.08194556832313538
Validation loss: 1.4360018007216915

Epoch: 5| Step: 9
Training loss: 0.051556408405303955
Validation loss: 1.4275233309756044

Epoch: 5| Step: 10
Training loss: 0.03909654542803764
Validation loss: 1.444969839947198

Epoch: 674| Step: 0
Training loss: 0.08923862129449844
Validation loss: 1.441929805663324

Epoch: 5| Step: 1
Training loss: 0.061733998358249664
Validation loss: 1.4444352490927583

Epoch: 5| Step: 2
Training loss: 0.0698222741484642
Validation loss: 1.442915963870223

Epoch: 5| Step: 3
Training loss: 0.03857383877038956
Validation loss: 1.457708401064719

Epoch: 5| Step: 4
Training loss: 0.030988460406661034
Validation loss: 1.4498091782293012

Epoch: 5| Step: 5
Training loss: 0.04649984836578369
Validation loss: 1.430821144452659

Epoch: 5| Step: 6
Training loss: 0.026493709534406662
Validation loss: 1.4354088280790596

Epoch: 5| Step: 7
Training loss: 0.07276563346385956
Validation loss: 1.4358502857146724

Epoch: 5| Step: 8
Training loss: 0.02595561183989048
Validation loss: 1.4414136038031629

Epoch: 5| Step: 9
Training loss: 0.05305241793394089
Validation loss: 1.4245028662425216

Epoch: 5| Step: 10
Training loss: 0.050886113196611404
Validation loss: 1.4447744418216009

Epoch: 675| Step: 0
Training loss: 0.038434263318777084
Validation loss: 1.4419488022404332

Epoch: 5| Step: 1
Training loss: 0.09224940836429596
Validation loss: 1.445439789884834

Epoch: 5| Step: 2
Training loss: 0.04707802087068558
Validation loss: 1.4244003782990158

Epoch: 5| Step: 3
Training loss: 0.04652968421578407
Validation loss: 1.4345707265279626

Epoch: 5| Step: 4
Training loss: 0.08513940870761871
Validation loss: 1.4460314486616401

Epoch: 5| Step: 5
Training loss: 0.038458697497844696
Validation loss: 1.4250253951677712

Epoch: 5| Step: 6
Training loss: 0.052831195294857025
Validation loss: 1.4524832887034262

Epoch: 5| Step: 7
Training loss: 0.051843784749507904
Validation loss: 1.466922797182555

Epoch: 5| Step: 8
Training loss: 0.03252197802066803
Validation loss: 1.4713777367786696

Epoch: 5| Step: 9
Training loss: 0.04244957119226456
Validation loss: 1.4532832932728592

Epoch: 5| Step: 10
Training loss: 0.05286942049860954
Validation loss: 1.4726545733790244

Epoch: 676| Step: 0
Training loss: 0.057839203625917435
Validation loss: 1.4606457448774768

Epoch: 5| Step: 1
Training loss: 0.04515852779150009
Validation loss: 1.4336185160503592

Epoch: 5| Step: 2
Training loss: 0.05601419135928154
Validation loss: 1.4408705144800165

Epoch: 5| Step: 3
Training loss: 0.04235834628343582
Validation loss: 1.470899776745868

Epoch: 5| Step: 4
Training loss: 0.04449249431490898
Validation loss: 1.4644586898947274

Epoch: 5| Step: 5
Training loss: 0.07841809093952179
Validation loss: 1.4926127105630853

Epoch: 5| Step: 6
Training loss: 0.056060779839754105
Validation loss: 1.4647677784324975

Epoch: 5| Step: 7
Training loss: 0.05589308217167854
Validation loss: 1.4571058378424695

Epoch: 5| Step: 8
Training loss: 0.03292975574731827
Validation loss: 1.45096452518176

Epoch: 5| Step: 9
Training loss: 0.05614205077290535
Validation loss: 1.4700342724400182

Epoch: 5| Step: 10
Training loss: 0.047045134007930756
Validation loss: 1.4516780991708078

Epoch: 677| Step: 0
Training loss: 0.04829506203532219
Validation loss: 1.4364222454768356

Epoch: 5| Step: 1
Training loss: 0.045589882880449295
Validation loss: 1.4146347058716642

Epoch: 5| Step: 2
Training loss: 0.04392702877521515
Validation loss: 1.4231424434210664

Epoch: 5| Step: 3
Training loss: 0.040497880429029465
Validation loss: 1.4300037673724595

Epoch: 5| Step: 4
Training loss: 0.039490751922130585
Validation loss: 1.4199591311075355

Epoch: 5| Step: 5
Training loss: 0.03623349964618683
Validation loss: 1.4580997427304585

Epoch: 5| Step: 6
Training loss: 0.04465555399656296
Validation loss: 1.4777256442654518

Epoch: 5| Step: 7
Training loss: 0.06750933080911636
Validation loss: 1.4572759546259397

Epoch: 5| Step: 8
Training loss: 0.07661972939968109
Validation loss: 1.4815517638319282

Epoch: 5| Step: 9
Training loss: 0.0744895190000534
Validation loss: 1.4821891553940312

Epoch: 5| Step: 10
Training loss: 0.04592486843466759
Validation loss: 1.4845340662105109

Epoch: 678| Step: 0
Training loss: 0.05663678050041199
Validation loss: 1.464645170396374

Epoch: 5| Step: 1
Training loss: 0.07722488790750504
Validation loss: 1.4557661625646776

Epoch: 5| Step: 2
Training loss: 0.06481538712978363
Validation loss: 1.4412577165070402

Epoch: 5| Step: 3
Training loss: 0.04699181020259857
Validation loss: 1.4455409383261075

Epoch: 5| Step: 4
Training loss: 0.043382592499256134
Validation loss: 1.4383159247777795

Epoch: 5| Step: 5
Training loss: 0.03958859294652939
Validation loss: 1.4379138113349996

Epoch: 5| Step: 6
Training loss: 0.06262581795454025
Validation loss: 1.4234370941756873

Epoch: 5| Step: 7
Training loss: 0.05634518712759018
Validation loss: 1.4280550684980167

Epoch: 5| Step: 8
Training loss: 0.050168465822935104
Validation loss: 1.4408591895975091

Epoch: 5| Step: 9
Training loss: 0.04294222965836525
Validation loss: 1.429024257967549

Epoch: 5| Step: 10
Training loss: 0.07769635319709778
Validation loss: 1.4547102214187704

Epoch: 679| Step: 0
Training loss: 0.07944445312023163
Validation loss: 1.4403581862808557

Epoch: 5| Step: 1
Training loss: 0.04803990200161934
Validation loss: 1.4487445380098076

Epoch: 5| Step: 2
Training loss: 0.036060579121112823
Validation loss: 1.4549918174743652

Epoch: 5| Step: 3
Training loss: 0.03679903596639633
Validation loss: 1.4704826339598625

Epoch: 5| Step: 4
Training loss: 0.06294535100460052
Validation loss: 1.4734532025552565

Epoch: 5| Step: 5
Training loss: 0.041067369282245636
Validation loss: 1.4443625192488394

Epoch: 5| Step: 6
Training loss: 0.060110170394182205
Validation loss: 1.4475113320094284

Epoch: 5| Step: 7
Training loss: 0.05354710668325424
Validation loss: 1.4619677182166808

Epoch: 5| Step: 8
Training loss: 0.04661871865391731
Validation loss: 1.453190912482559

Epoch: 5| Step: 9
Training loss: 0.03549162298440933
Validation loss: 1.4523829196089058

Epoch: 5| Step: 10
Training loss: 0.09713345021009445
Validation loss: 1.451372831098495

Epoch: 680| Step: 0
Training loss: 0.051865868270397186
Validation loss: 1.4266128498379902

Epoch: 5| Step: 1
Training loss: 0.03706642985343933
Validation loss: 1.443516049333798

Epoch: 5| Step: 2
Training loss: 0.0421685166656971
Validation loss: 1.442449850420798

Epoch: 5| Step: 3
Training loss: 0.026707420125603676
Validation loss: 1.4223012180738552

Epoch: 5| Step: 4
Training loss: 0.0877845287322998
Validation loss: 1.435752550760905

Epoch: 5| Step: 5
Training loss: 0.06077545881271362
Validation loss: 1.4318222230480564

Epoch: 5| Step: 6
Training loss: 0.047216858714818954
Validation loss: 1.4268697846320368

Epoch: 5| Step: 7
Training loss: 0.034594275057315826
Validation loss: 1.4291773476908285

Epoch: 5| Step: 8
Training loss: 0.03277203440666199
Validation loss: 1.439403877463392

Epoch: 5| Step: 9
Training loss: 0.04062389209866524
Validation loss: 1.4365220992795882

Epoch: 5| Step: 10
Training loss: 0.0730012059211731
Validation loss: 1.4539623414316485

Epoch: 681| Step: 0
Training loss: 0.07267345488071442
Validation loss: 1.4375072320302327

Epoch: 5| Step: 1
Training loss: 0.03746166080236435
Validation loss: 1.4499414338860461

Epoch: 5| Step: 2
Training loss: 0.08359440416097641
Validation loss: 1.4445802114343131

Epoch: 5| Step: 3
Training loss: 0.06329464167356491
Validation loss: 1.4526529812043714

Epoch: 5| Step: 4
Training loss: 0.044416241347789764
Validation loss: 1.459133691044264

Epoch: 5| Step: 5
Training loss: 0.04317253828048706
Validation loss: 1.4431991442557304

Epoch: 5| Step: 6
Training loss: 0.04348225146532059
Validation loss: 1.4667503205678796

Epoch: 5| Step: 7
Training loss: 0.04362625628709793
Validation loss: 1.447176044987094

Epoch: 5| Step: 8
Training loss: 0.04875532537698746
Validation loss: 1.4648144398966143

Epoch: 5| Step: 9
Training loss: 0.055294156074523926
Validation loss: 1.444921475584789

Epoch: 5| Step: 10
Training loss: 0.06798502802848816
Validation loss: 1.447334147268726

Epoch: 682| Step: 0
Training loss: 0.03606889769434929
Validation loss: 1.4350065569723807

Epoch: 5| Step: 1
Training loss: 0.07284943014383316
Validation loss: 1.4385536127193

Epoch: 5| Step: 2
Training loss: 0.03824778273701668
Validation loss: 1.427116209460843

Epoch: 5| Step: 3
Training loss: 0.0752105861902237
Validation loss: 1.440723556344227

Epoch: 5| Step: 4
Training loss: 0.033676616847515106
Validation loss: 1.4395762989597936

Epoch: 5| Step: 5
Training loss: 0.02890750765800476
Validation loss: 1.4222121469436153

Epoch: 5| Step: 6
Training loss: 0.038086164742708206
Validation loss: 1.424357480900262

Epoch: 5| Step: 7
Training loss: 0.03517312929034233
Validation loss: 1.4342289868221487

Epoch: 5| Step: 8
Training loss: 0.05393929034471512
Validation loss: 1.4265494590164514

Epoch: 5| Step: 9
Training loss: 0.048387229442596436
Validation loss: 1.441238139265327

Epoch: 5| Step: 10
Training loss: 0.028041835874319077
Validation loss: 1.4606477073443833

Epoch: 683| Step: 0
Training loss: 0.03757231682538986
Validation loss: 1.4560272373178953

Epoch: 5| Step: 1
Training loss: 0.032643262296915054
Validation loss: 1.4558091612272366

Epoch: 5| Step: 2
Training loss: 0.06652837991714478
Validation loss: 1.4471382966605566

Epoch: 5| Step: 3
Training loss: 0.040284425020217896
Validation loss: 1.4265529788950437

Epoch: 5| Step: 4
Training loss: 0.04288988560438156
Validation loss: 1.4411444510183027

Epoch: 5| Step: 5
Training loss: 0.03757476061582565
Validation loss: 1.4414235468833678

Epoch: 5| Step: 6
Training loss: 0.04423079639673233
Validation loss: 1.4250570279295727

Epoch: 5| Step: 7
Training loss: 0.11566106230020523
Validation loss: 1.4174418167401386

Epoch: 5| Step: 8
Training loss: 0.06368476152420044
Validation loss: 1.428823048068631

Epoch: 5| Step: 9
Training loss: 0.037330061197280884
Validation loss: 1.420529782131154

Epoch: 5| Step: 10
Training loss: 0.0709901675581932
Validation loss: 1.4086099606688305

Epoch: 684| Step: 0
Training loss: 0.0452708899974823
Validation loss: 1.4199518824136386

Epoch: 5| Step: 1
Training loss: 0.04922829568386078
Validation loss: 1.4428508961072533

Epoch: 5| Step: 2
Training loss: 0.0401400625705719
Validation loss: 1.4356711244070401

Epoch: 5| Step: 3
Training loss: 0.0708417072892189
Validation loss: 1.4672371418245378

Epoch: 5| Step: 4
Training loss: 0.05251878499984741
Validation loss: 1.473659606390102

Epoch: 5| Step: 5
Training loss: 0.06448344141244888
Validation loss: 1.4624121125026415

Epoch: 5| Step: 6
Training loss: 0.04663534462451935
Validation loss: 1.4822274318305395

Epoch: 5| Step: 7
Training loss: 0.05496145039796829
Validation loss: 1.4672507957745624

Epoch: 5| Step: 8
Training loss: 0.03183561936020851
Validation loss: 1.4705022560652865

Epoch: 5| Step: 9
Training loss: 0.043808359652757645
Validation loss: 1.473726180291945

Epoch: 5| Step: 10
Training loss: 0.05517043173313141
Validation loss: 1.4563012905018304

Epoch: 685| Step: 0
Training loss: 0.0593998059630394
Validation loss: 1.4666463957037976

Epoch: 5| Step: 1
Training loss: 0.042470939457416534
Validation loss: 1.4421075121048959

Epoch: 5| Step: 2
Training loss: 0.08451895415782928
Validation loss: 1.4342732689073008

Epoch: 5| Step: 3
Training loss: 0.05790487676858902
Validation loss: 1.4196477961796585

Epoch: 5| Step: 4
Training loss: 0.032470542937517166
Validation loss: 1.4421490982014646

Epoch: 5| Step: 5
Training loss: 0.046682488173246384
Validation loss: 1.4308959284136373

Epoch: 5| Step: 6
Training loss: 0.06676701456308365
Validation loss: 1.447285767524473

Epoch: 5| Step: 7
Training loss: 0.04906146228313446
Validation loss: 1.4481805268154349

Epoch: 5| Step: 8
Training loss: 0.047382235527038574
Validation loss: 1.421555564608625

Epoch: 5| Step: 9
Training loss: 0.04013027250766754
Validation loss: 1.4441839161739554

Epoch: 5| Step: 10
Training loss: 0.05479492247104645
Validation loss: 1.4485633520669834

Epoch: 686| Step: 0
Training loss: 0.07412353903055191
Validation loss: 1.4707175852150045

Epoch: 5| Step: 1
Training loss: 0.04980457201600075
Validation loss: 1.4647616378722652

Epoch: 5| Step: 2
Training loss: 0.03602221608161926
Validation loss: 1.461204751845329

Epoch: 5| Step: 3
Training loss: 0.04389585182070732
Validation loss: 1.4534989582595004

Epoch: 5| Step: 4
Training loss: 0.05762866139411926
Validation loss: 1.4263487862002464

Epoch: 5| Step: 5
Training loss: 0.060970328748226166
Validation loss: 1.4487626699991123

Epoch: 5| Step: 6
Training loss: 0.06717995554208755
Validation loss: 1.4320577165131927

Epoch: 5| Step: 7
Training loss: 0.04380471259355545
Validation loss: 1.4264213949121454

Epoch: 5| Step: 8
Training loss: 0.0455392524600029
Validation loss: 1.434324755463549

Epoch: 5| Step: 9
Training loss: 0.062093090265989304
Validation loss: 1.4302979874354538

Epoch: 5| Step: 10
Training loss: 0.03469979017972946
Validation loss: 1.4163949822866788

Epoch: 687| Step: 0
Training loss: 0.044593557715415955
Validation loss: 1.426471265413428

Epoch: 5| Step: 1
Training loss: 0.04128168150782585
Validation loss: 1.423439762925589

Epoch: 5| Step: 2
Training loss: 0.04576173797249794
Validation loss: 1.4495027167822725

Epoch: 5| Step: 3
Training loss: 0.043042104691267014
Validation loss: 1.4264409567720147

Epoch: 5| Step: 4
Training loss: 0.061646342277526855
Validation loss: 1.4077125717234868

Epoch: 5| Step: 5
Training loss: 0.0582752525806427
Validation loss: 1.3987718448844007

Epoch: 5| Step: 6
Training loss: 0.048672448843717575
Validation loss: 1.384459130225643

Epoch: 5| Step: 7
Training loss: 0.0698753148317337
Validation loss: 1.4010398516090967

Epoch: 5| Step: 8
Training loss: 0.05280425399541855
Validation loss: 1.4073145825375792

Epoch: 5| Step: 9
Training loss: 0.04204629361629486
Validation loss: 1.4081019047767884

Epoch: 5| Step: 10
Training loss: 0.0424211248755455
Validation loss: 1.413582278836158

Epoch: 688| Step: 0
Training loss: 0.06393013894557953
Validation loss: 1.4213539028680453

Epoch: 5| Step: 1
Training loss: 0.053840022534132004
Validation loss: 1.431080167011548

Epoch: 5| Step: 2
Training loss: 0.053447894752025604
Validation loss: 1.433507155346614

Epoch: 5| Step: 3
Training loss: 0.04339993745088577
Validation loss: 1.4127217185112737

Epoch: 5| Step: 4
Training loss: 0.05032236501574516
Validation loss: 1.4388611034680439

Epoch: 5| Step: 5
Training loss: 0.030655231326818466
Validation loss: 1.4594938408943914

Epoch: 5| Step: 6
Training loss: 0.03887004405260086
Validation loss: 1.4403386398028302

Epoch: 5| Step: 7
Training loss: 0.061864256858825684
Validation loss: 1.4567066751500612

Epoch: 5| Step: 8
Training loss: 0.06077507138252258
Validation loss: 1.4277384543931613

Epoch: 5| Step: 9
Training loss: 0.05782746151089668
Validation loss: 1.450892536870895

Epoch: 5| Step: 10
Training loss: 0.05231325700879097
Validation loss: 1.4388278210034935

Epoch: 689| Step: 0
Training loss: 0.05312080308794975
Validation loss: 1.4437864339479836

Epoch: 5| Step: 1
Training loss: 0.06858789175748825
Validation loss: 1.4447125747639646

Epoch: 5| Step: 2
Training loss: 0.06483345478773117
Validation loss: 1.4423149042232062

Epoch: 5| Step: 3
Training loss: 0.038389723747968674
Validation loss: 1.4111618431665565

Epoch: 5| Step: 4
Training loss: 0.05854937434196472
Validation loss: 1.4237290595167427

Epoch: 5| Step: 5
Training loss: 0.06931513547897339
Validation loss: 1.4133692069720196

Epoch: 5| Step: 6
Training loss: 0.054725147783756256
Validation loss: 1.3892270506069224

Epoch: 5| Step: 7
Training loss: 0.04381765052676201
Validation loss: 1.4247600070891842

Epoch: 5| Step: 8
Training loss: 0.04283670708537102
Validation loss: 1.4230637383717362

Epoch: 5| Step: 9
Training loss: 0.04266868904232979
Validation loss: 1.407540294431871

Epoch: 5| Step: 10
Training loss: 0.04031167924404144
Validation loss: 1.4016727619273688

Epoch: 690| Step: 0
Training loss: 0.06612648069858551
Validation loss: 1.4105183648806747

Epoch: 5| Step: 1
Training loss: 0.027933394536376
Validation loss: 1.4132611059373426

Epoch: 5| Step: 2
Training loss: 0.040083516389131546
Validation loss: 1.3869522976618942

Epoch: 5| Step: 3
Training loss: 0.05401032045483589
Validation loss: 1.3700131165084017

Epoch: 5| Step: 4
Training loss: 0.06131521612405777
Validation loss: 1.3870601295143046

Epoch: 5| Step: 5
Training loss: 0.060524605214595795
Validation loss: 1.3757001898622

Epoch: 5| Step: 6
Training loss: 0.033425312489271164
Validation loss: 1.3663113078763407

Epoch: 5| Step: 7
Training loss: 0.060601092875003815
Validation loss: 1.3746429553595922

Epoch: 5| Step: 8
Training loss: 0.04503179341554642
Validation loss: 1.3841248814777662

Epoch: 5| Step: 9
Training loss: 0.039655134081840515
Validation loss: 1.409636600043184

Epoch: 5| Step: 10
Training loss: 0.05568291246891022
Validation loss: 1.4229874790355723

Epoch: 691| Step: 0
Training loss: 0.03253345564007759
Validation loss: 1.3997480356565086

Epoch: 5| Step: 1
Training loss: 0.05875127390027046
Validation loss: 1.4180544191791165

Epoch: 5| Step: 2
Training loss: 0.04826124757528305
Validation loss: 1.4164338932242444

Epoch: 5| Step: 3
Training loss: 0.04938647896051407
Validation loss: 1.4150538611155685

Epoch: 5| Step: 4
Training loss: 0.0795038565993309
Validation loss: 1.4287545886091007

Epoch: 5| Step: 5
Training loss: 0.04805769398808479
Validation loss: 1.4463846286137898

Epoch: 5| Step: 6
Training loss: 0.03829527273774147
Validation loss: 1.4311372580066803

Epoch: 5| Step: 7
Training loss: 0.03400350734591484
Validation loss: 1.421183761729989

Epoch: 5| Step: 8
Training loss: 0.06825815141201019
Validation loss: 1.4098742315846104

Epoch: 5| Step: 9
Training loss: 0.03563125059008598
Validation loss: 1.4115247598258398

Epoch: 5| Step: 10
Training loss: 0.05306908115744591
Validation loss: 1.4236219807337689

Epoch: 692| Step: 0
Training loss: 0.0694212019443512
Validation loss: 1.4009784472885953

Epoch: 5| Step: 1
Training loss: 0.04721815884113312
Validation loss: 1.417424822366366

Epoch: 5| Step: 2
Training loss: 0.04746655374765396
Validation loss: 1.4236005788208337

Epoch: 5| Step: 3
Training loss: 0.07194073498249054
Validation loss: 1.423298168566919

Epoch: 5| Step: 4
Training loss: 0.05933431535959244
Validation loss: 1.4236910958443918

Epoch: 5| Step: 5
Training loss: 0.05180088430643082
Validation loss: 1.4260002028557561

Epoch: 5| Step: 6
Training loss: 0.07181373238563538
Validation loss: 1.4270056332311323

Epoch: 5| Step: 7
Training loss: 0.0473184660077095
Validation loss: 1.4283349328143622

Epoch: 5| Step: 8
Training loss: 0.05689491704106331
Validation loss: 1.4433886030668854

Epoch: 5| Step: 9
Training loss: 0.0440874919295311
Validation loss: 1.4536075252358631

Epoch: 5| Step: 10
Training loss: 0.060756176710128784
Validation loss: 1.4420289929195116

Epoch: 693| Step: 0
Training loss: 0.03863026574254036
Validation loss: 1.4381788687039447

Epoch: 5| Step: 1
Training loss: 0.03465787321329117
Validation loss: 1.4835202975939679

Epoch: 5| Step: 2
Training loss: 0.07325636595487595
Validation loss: 1.4567896396883073

Epoch: 5| Step: 3
Training loss: 0.06881488859653473
Validation loss: 1.4564707407387354

Epoch: 5| Step: 4
Training loss: 0.05166225507855415
Validation loss: 1.446588344471429

Epoch: 5| Step: 5
Training loss: 0.06433741748332977
Validation loss: 1.4424919479636735

Epoch: 5| Step: 6
Training loss: 0.0539361946284771
Validation loss: 1.458950860525972

Epoch: 5| Step: 7
Training loss: 0.05660253018140793
Validation loss: 1.4656553691433323

Epoch: 5| Step: 8
Training loss: 0.05603165552020073
Validation loss: 1.4613030943819272

Epoch: 5| Step: 9
Training loss: 0.07045646011829376
Validation loss: 1.4682683521701443

Epoch: 5| Step: 10
Training loss: 0.06478479504585266
Validation loss: 1.4702401391921505

Epoch: 694| Step: 0
Training loss: 0.03955177217721939
Validation loss: 1.4518132780187873

Epoch: 5| Step: 1
Training loss: 0.04998917132616043
Validation loss: 1.4310210263857277

Epoch: 5| Step: 2
Training loss: 0.041928116232156754
Validation loss: 1.4543429427249457

Epoch: 5| Step: 3
Training loss: 0.03919190913438797
Validation loss: 1.4472726468117005

Epoch: 5| Step: 4
Training loss: 0.049785714596509933
Validation loss: 1.4399553550186979

Epoch: 5| Step: 5
Training loss: 0.04698863625526428
Validation loss: 1.440004748682822

Epoch: 5| Step: 6
Training loss: 0.05954496189951897
Validation loss: 1.4409538417734125

Epoch: 5| Step: 7
Training loss: 0.0594402439892292
Validation loss: 1.4333451768403411

Epoch: 5| Step: 8
Training loss: 0.054822277277708054
Validation loss: 1.4345594734273932

Epoch: 5| Step: 9
Training loss: 0.08171802014112473
Validation loss: 1.4503749096265404

Epoch: 5| Step: 10
Training loss: 0.06092473492026329
Validation loss: 1.4445545301642468

Epoch: 695| Step: 0
Training loss: 0.07597462832927704
Validation loss: 1.4358203010533446

Epoch: 5| Step: 1
Training loss: 0.041887033730745316
Validation loss: 1.440010920647652

Epoch: 5| Step: 2
Training loss: 0.04687587916851044
Validation loss: 1.4377531838673416

Epoch: 5| Step: 3
Training loss: 0.03707516938447952
Validation loss: 1.4526034708945983

Epoch: 5| Step: 4
Training loss: 0.059141822159290314
Validation loss: 1.4365667091902865

Epoch: 5| Step: 5
Training loss: 0.037558723241090775
Validation loss: 1.4340642395839895

Epoch: 5| Step: 6
Training loss: 0.04042581096291542
Validation loss: 1.421907986364057

Epoch: 5| Step: 7
Training loss: 0.05219532176852226
Validation loss: 1.4236279892665085

Epoch: 5| Step: 8
Training loss: 0.03945934772491455
Validation loss: 1.4164242436808925

Epoch: 5| Step: 9
Training loss: 0.029791617766022682
Validation loss: 1.4131552352700183

Epoch: 5| Step: 10
Training loss: 0.05952857434749603
Validation loss: 1.4258557199150004

Epoch: 696| Step: 0
Training loss: 0.05547691136598587
Validation loss: 1.4106571648710517

Epoch: 5| Step: 1
Training loss: 0.06653987616300583
Validation loss: 1.4145622535418438

Epoch: 5| Step: 2
Training loss: 0.05102067440748215
Validation loss: 1.3937758130411948

Epoch: 5| Step: 3
Training loss: 0.05703418329358101
Validation loss: 1.4111276647096038

Epoch: 5| Step: 4
Training loss: 0.03200117498636246
Validation loss: 1.4114014179475847

Epoch: 5| Step: 5
Training loss: 0.03830622136592865
Validation loss: 1.3983318562148719

Epoch: 5| Step: 6
Training loss: 0.05313285440206528
Validation loss: 1.4118083997439312

Epoch: 5| Step: 7
Training loss: 0.047698941081762314
Validation loss: 1.4202352352039789

Epoch: 5| Step: 8
Training loss: 0.03525320813059807
Validation loss: 1.4068435481799546

Epoch: 5| Step: 9
Training loss: 0.06940686702728271
Validation loss: 1.386876457480974

Epoch: 5| Step: 10
Training loss: 0.04463976249098778
Validation loss: 1.3942776174955471

Epoch: 697| Step: 0
Training loss: 0.03809314966201782
Validation loss: 1.3967763249592116

Epoch: 5| Step: 1
Training loss: 0.03221847862005234
Validation loss: 1.405167346359581

Epoch: 5| Step: 2
Training loss: 0.03296633064746857
Validation loss: 1.4062462609301332

Epoch: 5| Step: 3
Training loss: 0.06539648026227951
Validation loss: 1.4018814397114578

Epoch: 5| Step: 4
Training loss: 0.09282569587230682
Validation loss: 1.4260251470791396

Epoch: 5| Step: 5
Training loss: 0.05276304483413696
Validation loss: 1.4280729063095585

Epoch: 5| Step: 6
Training loss: 0.037648871541023254
Validation loss: 1.433591946478813

Epoch: 5| Step: 7
Training loss: 0.05093567445874214
Validation loss: 1.44793007322537

Epoch: 5| Step: 8
Training loss: 0.033670131117105484
Validation loss: 1.4154971421405833

Epoch: 5| Step: 9
Training loss: 0.043425969779491425
Validation loss: 1.444695806631478

Epoch: 5| Step: 10
Training loss: 0.046975430101156235
Validation loss: 1.4509502585216234

Epoch: 698| Step: 0
Training loss: 0.026996541768312454
Validation loss: 1.4654558217653664

Epoch: 5| Step: 1
Training loss: 0.0679374635219574
Validation loss: 1.4846602947481218

Epoch: 5| Step: 2
Training loss: 0.05103183537721634
Validation loss: 1.4694211162546629

Epoch: 5| Step: 3
Training loss: 0.0800643265247345
Validation loss: 1.4566433993718957

Epoch: 5| Step: 4
Training loss: 0.06905348598957062
Validation loss: 1.4693235364011539

Epoch: 5| Step: 5
Training loss: 0.0450909361243248
Validation loss: 1.471648491838927

Epoch: 5| Step: 6
Training loss: 0.03686460107564926
Validation loss: 1.4712356828874158

Epoch: 5| Step: 7
Training loss: 0.03720295801758766
Validation loss: 1.464746658520032

Epoch: 5| Step: 8
Training loss: 0.04812764376401901
Validation loss: 1.4755308974173762

Epoch: 5| Step: 9
Training loss: 0.04643665999174118
Validation loss: 1.4618919895541282

Epoch: 5| Step: 10
Training loss: 0.04914107918739319
Validation loss: 1.4619472847189954

Epoch: 699| Step: 0
Training loss: 0.04384550079703331
Validation loss: 1.4595206809300247

Epoch: 5| Step: 1
Training loss: 0.054212044924497604
Validation loss: 1.472455164437653

Epoch: 5| Step: 2
Training loss: 0.03688180819153786
Validation loss: 1.4463633670601794

Epoch: 5| Step: 3
Training loss: 0.045260146260261536
Validation loss: 1.4248844859420613

Epoch: 5| Step: 4
Training loss: 0.049021266400814056
Validation loss: 1.4436880478294947

Epoch: 5| Step: 5
Training loss: 0.0909615159034729
Validation loss: 1.4355358641634706

Epoch: 5| Step: 6
Training loss: 0.06676013022661209
Validation loss: 1.4394588669141133

Epoch: 5| Step: 7
Training loss: 0.05746670812368393
Validation loss: 1.434898631547087

Epoch: 5| Step: 8
Training loss: 0.03768254444003105
Validation loss: 1.4347027847843785

Epoch: 5| Step: 9
Training loss: 0.056730855256319046
Validation loss: 1.4343032644641014

Epoch: 5| Step: 10
Training loss: 0.06493916362524033
Validation loss: 1.4647201594486032

Epoch: 700| Step: 0
Training loss: 0.05458535999059677
Validation loss: 1.4873365291985132

Epoch: 5| Step: 1
Training loss: 0.061257876455783844
Validation loss: 1.4773117701212566

Epoch: 5| Step: 2
Training loss: 0.047606997191905975
Validation loss: 1.5003207857890795

Epoch: 5| Step: 3
Training loss: 0.05927062779664993
Validation loss: 1.4795389963734535

Epoch: 5| Step: 4
Training loss: 0.04783131927251816
Validation loss: 1.4901945616609307

Epoch: 5| Step: 5
Training loss: 0.0318278968334198
Validation loss: 1.4716588220288676

Epoch: 5| Step: 6
Training loss: 0.03688676655292511
Validation loss: 1.4646098331738544

Epoch: 5| Step: 7
Training loss: 0.049524109810590744
Validation loss: 1.451214792907879

Epoch: 5| Step: 8
Training loss: 0.05116800218820572
Validation loss: 1.447511875501243

Epoch: 5| Step: 9
Training loss: 0.05633651092648506
Validation loss: 1.428845706806388

Epoch: 5| Step: 10
Training loss: 0.05369775369763374
Validation loss: 1.417671957323628

Epoch: 701| Step: 0
Training loss: 0.030996600165963173
Validation loss: 1.4211540760532502

Epoch: 5| Step: 1
Training loss: 0.04697992280125618
Validation loss: 1.419305573227585

Epoch: 5| Step: 2
Training loss: 0.04888973757624626
Validation loss: 1.42550080309632

Epoch: 5| Step: 3
Training loss: 0.06767667829990387
Validation loss: 1.4235494444447179

Epoch: 5| Step: 4
Training loss: 0.06045876070857048
Validation loss: 1.431396354911148

Epoch: 5| Step: 5
Training loss: 0.03485824912786484
Validation loss: 1.4134283411887385

Epoch: 5| Step: 6
Training loss: 0.029491132125258446
Validation loss: 1.420475455381537

Epoch: 5| Step: 7
Training loss: 0.04191857948899269
Validation loss: 1.3894343965797014

Epoch: 5| Step: 8
Training loss: 0.039970558136701584
Validation loss: 1.4017699969712125

Epoch: 5| Step: 9
Training loss: 0.07735700905323029
Validation loss: 1.4064953275906142

Epoch: 5| Step: 10
Training loss: 0.0303701963275671
Validation loss: 1.4178773241658365

Epoch: 702| Step: 0
Training loss: 0.02977653406560421
Validation loss: 1.447086852083924

Epoch: 5| Step: 1
Training loss: 0.035475559532642365
Validation loss: 1.4342147688711844

Epoch: 5| Step: 2
Training loss: 0.07492022216320038
Validation loss: 1.4400399846415366

Epoch: 5| Step: 3
Training loss: 0.06804534047842026
Validation loss: 1.4320319749975716

Epoch: 5| Step: 4
Training loss: 0.048807207494974136
Validation loss: 1.4575776566741288

Epoch: 5| Step: 5
Training loss: 0.0430530421435833
Validation loss: 1.4566420432059997

Epoch: 5| Step: 6
Training loss: 0.048966631293296814
Validation loss: 1.4655803249728294

Epoch: 5| Step: 7
Training loss: 0.03706562519073486
Validation loss: 1.4295528293937765

Epoch: 5| Step: 8
Training loss: 0.04179397597908974
Validation loss: 1.433080623226781

Epoch: 5| Step: 9
Training loss: 0.041005413979291916
Validation loss: 1.4304457210725354

Epoch: 5| Step: 10
Training loss: 0.080752894282341
Validation loss: 1.4209024316521102

Epoch: 703| Step: 0
Training loss: 0.06182786077260971
Validation loss: 1.4217476357695877

Epoch: 5| Step: 1
Training loss: 0.030397048220038414
Validation loss: 1.4338610005635086

Epoch: 5| Step: 2
Training loss: 0.05136861652135849
Validation loss: 1.4197134253799275

Epoch: 5| Step: 3
Training loss: 0.03631504625082016
Validation loss: 1.4147978636526293

Epoch: 5| Step: 4
Training loss: 0.04932847246527672
Validation loss: 1.4269438994828092

Epoch: 5| Step: 5
Training loss: 0.053000617772340775
Validation loss: 1.4061822301598006

Epoch: 5| Step: 6
Training loss: 0.04936467856168747
Validation loss: 1.420913980853173

Epoch: 5| Step: 7
Training loss: 0.04460998252034187
Validation loss: 1.4351729359678043

Epoch: 5| Step: 8
Training loss: 0.04519776999950409
Validation loss: 1.432757031533026

Epoch: 5| Step: 9
Training loss: 0.0451383963227272
Validation loss: 1.442664918079171

Epoch: 5| Step: 10
Training loss: 0.06386161595582962
Validation loss: 1.4486905942040105

Epoch: 704| Step: 0
Training loss: 0.028915639966726303
Validation loss: 1.4361095633558048

Epoch: 5| Step: 1
Training loss: 0.046004436910152435
Validation loss: 1.4374238778186101

Epoch: 5| Step: 2
Training loss: 0.06910280138254166
Validation loss: 1.4492598746412544

Epoch: 5| Step: 3
Training loss: 0.02654530107975006
Validation loss: 1.448799963920347

Epoch: 5| Step: 4
Training loss: 0.04714149236679077
Validation loss: 1.4505801047048261

Epoch: 5| Step: 5
Training loss: 0.056222788989543915
Validation loss: 1.4434316363385928

Epoch: 5| Step: 6
Training loss: 0.04641043394804001
Validation loss: 1.43298081685138

Epoch: 5| Step: 7
Training loss: 0.05022621154785156
Validation loss: 1.4437011185512747

Epoch: 5| Step: 8
Training loss: 0.03772009536623955
Validation loss: 1.459079033585005

Epoch: 5| Step: 9
Training loss: 0.046906378120183945
Validation loss: 1.4674200396383963

Epoch: 5| Step: 10
Training loss: 0.05385411158204079
Validation loss: 1.4766606515453709

Epoch: 705| Step: 0
Training loss: 0.04123429208993912
Validation loss: 1.463601484093615

Epoch: 5| Step: 1
Training loss: 0.04171418026089668
Validation loss: 1.4840592318965542

Epoch: 5| Step: 2
Training loss: 0.049685798585414886
Validation loss: 1.4609454972769624

Epoch: 5| Step: 3
Training loss: 0.03746487945318222
Validation loss: 1.4531478843381327

Epoch: 5| Step: 4
Training loss: 0.02988523803651333
Validation loss: 1.4415485782008017

Epoch: 5| Step: 5
Training loss: 0.030942827463150024
Validation loss: 1.4357519111325663

Epoch: 5| Step: 6
Training loss: 0.03629878908395767
Validation loss: 1.4226128773022724

Epoch: 5| Step: 7
Training loss: 0.04293522983789444
Validation loss: 1.4211505882201656

Epoch: 5| Step: 8
Training loss: 0.06734277307987213
Validation loss: 1.3978555753666868

Epoch: 5| Step: 9
Training loss: 0.04091161489486694
Validation loss: 1.4070407190630514

Epoch: 5| Step: 10
Training loss: 0.08541286736726761
Validation loss: 1.4009210473747664

Epoch: 706| Step: 0
Training loss: 0.0604315884411335
Validation loss: 1.4230315864727061

Epoch: 5| Step: 1
Training loss: 0.04097507521510124
Validation loss: 1.4186725872819141

Epoch: 5| Step: 2
Training loss: 0.036483876407146454
Validation loss: 1.4179151378652102

Epoch: 5| Step: 3
Training loss: 0.05132312700152397
Validation loss: 1.4228399927898119

Epoch: 5| Step: 4
Training loss: 0.07196782529354095
Validation loss: 1.4584271702715146

Epoch: 5| Step: 5
Training loss: 0.04643024131655693
Validation loss: 1.4696900921483194

Epoch: 5| Step: 6
Training loss: 0.06568532437086105
Validation loss: 1.464428549171776

Epoch: 5| Step: 7
Training loss: 0.04845735430717468
Validation loss: 1.4574905005834435

Epoch: 5| Step: 8
Training loss: 0.04490882158279419
Validation loss: 1.4492145046111076

Epoch: 5| Step: 9
Training loss: 0.03912421315908432
Validation loss: 1.4621668297757384

Epoch: 5| Step: 10
Training loss: 0.08540315181016922
Validation loss: 1.4702146322496477

Epoch: 707| Step: 0
Training loss: 0.05660531669855118
Validation loss: 1.4281827890744774

Epoch: 5| Step: 1
Training loss: 0.043198831379413605
Validation loss: 1.4232622910571355

Epoch: 5| Step: 2
Training loss: 0.040547240525484085
Validation loss: 1.4175626718869774

Epoch: 5| Step: 3
Training loss: 0.04944469407200813
Validation loss: 1.4356661304350822

Epoch: 5| Step: 4
Training loss: 0.045045364648103714
Validation loss: 1.413052100007252

Epoch: 5| Step: 5
Training loss: 0.09326998144388199
Validation loss: 1.4318289538865447

Epoch: 5| Step: 6
Training loss: 0.038273558020591736
Validation loss: 1.4296874807726951

Epoch: 5| Step: 7
Training loss: 0.04561132937669754
Validation loss: 1.4390255328147643

Epoch: 5| Step: 8
Training loss: 0.049554817378520966
Validation loss: 1.4443617507975588

Epoch: 5| Step: 9
Training loss: 0.049839459359645844
Validation loss: 1.449908177057902

Epoch: 5| Step: 10
Training loss: 0.06527891010046005
Validation loss: 1.4544035542395808

Epoch: 708| Step: 0
Training loss: 0.038700420409440994
Validation loss: 1.4292786262368644

Epoch: 5| Step: 1
Training loss: 0.062323473393917084
Validation loss: 1.4467326325754966

Epoch: 5| Step: 2
Training loss: 0.058139584958553314
Validation loss: 1.4666970724700599

Epoch: 5| Step: 3
Training loss: 0.045370738953351974
Validation loss: 1.4557858359429143

Epoch: 5| Step: 4
Training loss: 0.036610595881938934
Validation loss: 1.4612482337541477

Epoch: 5| Step: 5
Training loss: 0.0793401449918747
Validation loss: 1.4427796672749262

Epoch: 5| Step: 6
Training loss: 0.031122863292694092
Validation loss: 1.4612786154593191

Epoch: 5| Step: 7
Training loss: 0.036094117909669876
Validation loss: 1.4587182716656757

Epoch: 5| Step: 8
Training loss: 0.05183953791856766
Validation loss: 1.4532653093338013

Epoch: 5| Step: 9
Training loss: 0.039402417838573456
Validation loss: 1.478558289107456

Epoch: 5| Step: 10
Training loss: 0.05541682243347168
Validation loss: 1.4459230226855124

Epoch: 709| Step: 0
Training loss: 0.04666982218623161
Validation loss: 1.448553995419574

Epoch: 5| Step: 1
Training loss: 0.036665964871644974
Validation loss: 1.452208871482521

Epoch: 5| Step: 2
Training loss: 0.06128004193305969
Validation loss: 1.4571803551848217

Epoch: 5| Step: 3
Training loss: 0.04180634021759033
Validation loss: 1.460424804559318

Epoch: 5| Step: 4
Training loss: 0.07114948332309723
Validation loss: 1.4579280384125248

Epoch: 5| Step: 5
Training loss: 0.062070198357105255
Validation loss: 1.449588579516257

Epoch: 5| Step: 6
Training loss: 0.037279803305864334
Validation loss: 1.4540080062804683

Epoch: 5| Step: 7
Training loss: 0.07345863431692123
Validation loss: 1.434816784756158

Epoch: 5| Step: 8
Training loss: 0.05737043172121048
Validation loss: 1.4500393104809586

Epoch: 5| Step: 9
Training loss: 0.0688958615064621
Validation loss: 1.44617711728619

Epoch: 5| Step: 10
Training loss: 0.053033988922834396
Validation loss: 1.4589209697579826

Epoch: 710| Step: 0
Training loss: 0.04704786464571953
Validation loss: 1.4610492696044266

Epoch: 5| Step: 1
Training loss: 0.04667750746011734
Validation loss: 1.439229501191006

Epoch: 5| Step: 2
Training loss: 0.06917048245668411
Validation loss: 1.45853828999304

Epoch: 5| Step: 3
Training loss: 0.061574749648571014
Validation loss: 1.446964890726151

Epoch: 5| Step: 4
Training loss: 0.037449516355991364
Validation loss: 1.4586020861902544

Epoch: 5| Step: 5
Training loss: 0.052743732929229736
Validation loss: 1.4489420114024993

Epoch: 5| Step: 6
Training loss: 0.04653846472501755
Validation loss: 1.4229843283212313

Epoch: 5| Step: 7
Training loss: 0.045649223029613495
Validation loss: 1.4681770698998564

Epoch: 5| Step: 8
Training loss: 0.07392994314432144
Validation loss: 1.445207284342858

Epoch: 5| Step: 9
Training loss: 0.0698414146900177
Validation loss: 1.4492738644282024

Epoch: 5| Step: 10
Training loss: 0.049928538501262665
Validation loss: 1.4618013725485852

Epoch: 711| Step: 0
Training loss: 0.02438567578792572
Validation loss: 1.4542418128700667

Epoch: 5| Step: 1
Training loss: 0.05005091428756714
Validation loss: 1.457648188837113

Epoch: 5| Step: 2
Training loss: 0.05098062753677368
Validation loss: 1.4484611236920921

Epoch: 5| Step: 3
Training loss: 0.03183514624834061
Validation loss: 1.44639846586412

Epoch: 5| Step: 4
Training loss: 0.06716456264257431
Validation loss: 1.4725324466664305

Epoch: 5| Step: 5
Training loss: 0.07538503408432007
Validation loss: 1.4677587125890998

Epoch: 5| Step: 6
Training loss: 0.05095233768224716
Validation loss: 1.4543427190473002

Epoch: 5| Step: 7
Training loss: 0.07224038988351822
Validation loss: 1.4769742924679992

Epoch: 5| Step: 8
Training loss: 0.07728246599435806
Validation loss: 1.4778681634574808

Epoch: 5| Step: 9
Training loss: 0.07468806952238083
Validation loss: 1.4594739816522087

Epoch: 5| Step: 10
Training loss: 0.03609137237071991
Validation loss: 1.4576988694488362

Epoch: 712| Step: 0
Training loss: 0.03930913656949997
Validation loss: 1.4711081725294872

Epoch: 5| Step: 1
Training loss: 0.03725278005003929
Validation loss: 1.4634047554385277

Epoch: 5| Step: 2
Training loss: 0.051646459847688675
Validation loss: 1.4514748178502566

Epoch: 5| Step: 3
Training loss: 0.07192904502153397
Validation loss: 1.4679614497769264

Epoch: 5| Step: 4
Training loss: 0.06130550056695938
Validation loss: 1.4572825060095838

Epoch: 5| Step: 5
Training loss: 0.05747479945421219
Validation loss: 1.4690337052909277

Epoch: 5| Step: 6
Training loss: 0.07997091114521027
Validation loss: 1.480490581963652

Epoch: 5| Step: 7
Training loss: 0.05422203615307808
Validation loss: 1.4578266656526955

Epoch: 5| Step: 8
Training loss: 0.08580202609300613
Validation loss: 1.4714882617355676

Epoch: 5| Step: 9
Training loss: 0.04642864316701889
Validation loss: 1.4693753796239053

Epoch: 5| Step: 10
Training loss: 0.04717347025871277
Validation loss: 1.460629282459136

Epoch: 713| Step: 0
Training loss: 0.059851180762052536
Validation loss: 1.4455529233460784

Epoch: 5| Step: 1
Training loss: 0.05796998739242554
Validation loss: 1.4452113297677809

Epoch: 5| Step: 2
Training loss: 0.037311069667339325
Validation loss: 1.437884214744773

Epoch: 5| Step: 3
Training loss: 0.05716541409492493
Validation loss: 1.4587587163012514

Epoch: 5| Step: 4
Training loss: 0.07612526416778564
Validation loss: 1.45818466524924

Epoch: 5| Step: 5
Training loss: 0.051597487181425095
Validation loss: 1.4347286455092891

Epoch: 5| Step: 6
Training loss: 0.04389187693595886
Validation loss: 1.4588353992790304

Epoch: 5| Step: 7
Training loss: 0.06640929728746414
Validation loss: 1.4538019882735385

Epoch: 5| Step: 8
Training loss: 0.06384603679180145
Validation loss: 1.4770059559934883

Epoch: 5| Step: 9
Training loss: 0.06427095830440521
Validation loss: 1.481947648909784

Epoch: 5| Step: 10
Training loss: 0.06657964736223221
Validation loss: 1.474669021944846

Epoch: 714| Step: 0
Training loss: 0.05630166456103325
Validation loss: 1.4734040421824302

Epoch: 5| Step: 1
Training loss: 0.07078061252832413
Validation loss: 1.4812176573661067

Epoch: 5| Step: 2
Training loss: 0.03893734887242317
Validation loss: 1.475844673572048

Epoch: 5| Step: 3
Training loss: 0.05496332049369812
Validation loss: 1.4607106357492425

Epoch: 5| Step: 4
Training loss: 0.03666464239358902
Validation loss: 1.4622463744173768

Epoch: 5| Step: 5
Training loss: 0.056773602962493896
Validation loss: 1.44231463696367

Epoch: 5| Step: 6
Training loss: 0.0469929501414299
Validation loss: 1.431402406384868

Epoch: 5| Step: 7
Training loss: 0.06283939629793167
Validation loss: 1.417772154654226

Epoch: 5| Step: 8
Training loss: 0.06305886805057526
Validation loss: 1.4317038110507432

Epoch: 5| Step: 9
Training loss: 0.06350328028202057
Validation loss: 1.413066279503607

Epoch: 5| Step: 10
Training loss: 0.04394733905792236
Validation loss: 1.3893646572225837

Epoch: 715| Step: 0
Training loss: 0.04633273929357529
Validation loss: 1.4001165897615495

Epoch: 5| Step: 1
Training loss: 0.07709286361932755
Validation loss: 1.4000742755910403

Epoch: 5| Step: 2
Training loss: 0.03779236227273941
Validation loss: 1.4034029604286276

Epoch: 5| Step: 3
Training loss: 0.05304403230547905
Validation loss: 1.395246107091186

Epoch: 5| Step: 4
Training loss: 0.06873615086078644
Validation loss: 1.3979818961953605

Epoch: 5| Step: 5
Training loss: 0.09104133397340775
Validation loss: 1.399978099330779

Epoch: 5| Step: 6
Training loss: 0.023347467184066772
Validation loss: 1.4211321428257933

Epoch: 5| Step: 7
Training loss: 0.042829133570194244
Validation loss: 1.4141185373388312

Epoch: 5| Step: 8
Training loss: 0.06795202195644379
Validation loss: 1.4527598747643091

Epoch: 5| Step: 9
Training loss: 0.0524434857070446
Validation loss: 1.427802949823359

Epoch: 5| Step: 10
Training loss: 0.06226178631186485
Validation loss: 1.4405778813105758

Epoch: 716| Step: 0
Training loss: 0.0690380185842514
Validation loss: 1.4410398070530226

Epoch: 5| Step: 1
Training loss: 0.04492752254009247
Validation loss: 1.4451262668896747

Epoch: 5| Step: 2
Training loss: 0.03384377434849739
Validation loss: 1.4188155602383357

Epoch: 5| Step: 3
Training loss: 0.06673938035964966
Validation loss: 1.4177162057609969

Epoch: 5| Step: 4
Training loss: 0.07432994246482849
Validation loss: 1.432919358694425

Epoch: 5| Step: 5
Training loss: 0.06844012439250946
Validation loss: 1.4376920653927712

Epoch: 5| Step: 6
Training loss: 0.05141439288854599
Validation loss: 1.4265938317903908

Epoch: 5| Step: 7
Training loss: 0.052174706012010574
Validation loss: 1.4122070227899859

Epoch: 5| Step: 8
Training loss: 0.03237985819578171
Validation loss: 1.4242344684498285

Epoch: 5| Step: 9
Training loss: 0.029301200062036514
Validation loss: 1.4112577284536054

Epoch: 5| Step: 10
Training loss: 0.0375925712287426
Validation loss: 1.4495398626532605

Epoch: 717| Step: 0
Training loss: 0.05371919274330139
Validation loss: 1.4474835882904709

Epoch: 5| Step: 1
Training loss: 0.0364590659737587
Validation loss: 1.4306692282358806

Epoch: 5| Step: 2
Training loss: 0.06781265884637833
Validation loss: 1.4256377015062558

Epoch: 5| Step: 3
Training loss: 0.05433736369013786
Validation loss: 1.4330992173123103

Epoch: 5| Step: 4
Training loss: 0.09648137539625168
Validation loss: 1.4287509161938903

Epoch: 5| Step: 5
Training loss: 0.03615038841962814
Validation loss: 1.4171669854912707

Epoch: 5| Step: 6
Training loss: 0.02885010838508606
Validation loss: 1.4017810949715235

Epoch: 5| Step: 7
Training loss: 0.03718804195523262
Validation loss: 1.405169347281097

Epoch: 5| Step: 8
Training loss: 0.040429309010505676
Validation loss: 1.4111979956267982

Epoch: 5| Step: 9
Training loss: 0.06258616596460342
Validation loss: 1.4033375235014065

Epoch: 5| Step: 10
Training loss: 0.07720249146223068
Validation loss: 1.4002621430222706

Epoch: 718| Step: 0
Training loss: 0.062368087470531464
Validation loss: 1.3871788901667441

Epoch: 5| Step: 1
Training loss: 0.06925830990076065
Validation loss: 1.4043901876736713

Epoch: 5| Step: 2
Training loss: 0.04474879056215286
Validation loss: 1.4086341588727889

Epoch: 5| Step: 3
Training loss: 0.04238496720790863
Validation loss: 1.4211564602390412

Epoch: 5| Step: 4
Training loss: 0.04919692128896713
Validation loss: 1.4239531707379125

Epoch: 5| Step: 5
Training loss: 0.04931776598095894
Validation loss: 1.417606963906237

Epoch: 5| Step: 6
Training loss: 0.07054983079433441
Validation loss: 1.423485429056229

Epoch: 5| Step: 7
Training loss: 0.04588653892278671
Validation loss: 1.4083269475608744

Epoch: 5| Step: 8
Training loss: 0.036252785474061966
Validation loss: 1.4239058943204983

Epoch: 5| Step: 9
Training loss: 0.06955921649932861
Validation loss: 1.4429449906913183

Epoch: 5| Step: 10
Training loss: 0.04835429787635803
Validation loss: 1.4216819642692484

Epoch: 719| Step: 0
Training loss: 0.04471071809530258
Validation loss: 1.4410806727665726

Epoch: 5| Step: 1
Training loss: 0.05411072447896004
Validation loss: 1.439255020951712

Epoch: 5| Step: 2
Training loss: 0.05116196721792221
Validation loss: 1.4456335036985335

Epoch: 5| Step: 3
Training loss: 0.06450948864221573
Validation loss: 1.4197308209634596

Epoch: 5| Step: 4
Training loss: 0.03791326284408569
Validation loss: 1.4273930365039456

Epoch: 5| Step: 5
Training loss: 0.05486499145627022
Validation loss: 1.4377030646929176

Epoch: 5| Step: 6
Training loss: 0.03343595936894417
Validation loss: 1.4354013294302008

Epoch: 5| Step: 7
Training loss: 0.04418458789587021
Validation loss: 1.43826634781335

Epoch: 5| Step: 8
Training loss: 0.06259499490261078
Validation loss: 1.4169527369160806

Epoch: 5| Step: 9
Training loss: 0.03044545277953148
Validation loss: 1.43319304784139

Epoch: 5| Step: 10
Training loss: 0.0484745167195797
Validation loss: 1.4456343086816932

Epoch: 720| Step: 0
Training loss: 0.05338703468441963
Validation loss: 1.4363038591159287

Epoch: 5| Step: 1
Training loss: 0.06749577820301056
Validation loss: 1.4330094107376632

Epoch: 5| Step: 2
Training loss: 0.061372868716716766
Validation loss: 1.4208072878981148

Epoch: 5| Step: 3
Training loss: 0.05835815519094467
Validation loss: 1.4041316624610656

Epoch: 5| Step: 4
Training loss: 0.05137314274907112
Validation loss: 1.4324304801161571

Epoch: 5| Step: 5
Training loss: 0.08209383487701416
Validation loss: 1.4225149045708358

Epoch: 5| Step: 6
Training loss: 0.031897105276584625
Validation loss: 1.403988992014239

Epoch: 5| Step: 7
Training loss: 0.029449710622429848
Validation loss: 1.4184222887921076

Epoch: 5| Step: 8
Training loss: 0.040968157351017
Validation loss: 1.4369241883677821

Epoch: 5| Step: 9
Training loss: 0.06716956943273544
Validation loss: 1.4200811757836291

Epoch: 5| Step: 10
Training loss: 0.03587007522583008
Validation loss: 1.404129921749074

Epoch: 721| Step: 0
Training loss: 0.03495095297694206
Validation loss: 1.4084713279560048

Epoch: 5| Step: 1
Training loss: 0.0456014983355999
Validation loss: 1.4304393452982749

Epoch: 5| Step: 2
Training loss: 0.06837750971317291
Validation loss: 1.4141407455167463

Epoch: 5| Step: 3
Training loss: 0.05652143806219101
Validation loss: 1.4303989038672498

Epoch: 5| Step: 4
Training loss: 0.04445146769285202
Validation loss: 1.4245940241762387

Epoch: 5| Step: 5
Training loss: 0.06031503155827522
Validation loss: 1.4350207403141966

Epoch: 5| Step: 6
Training loss: 0.04159408062696457
Validation loss: 1.4389678470550045

Epoch: 5| Step: 7
Training loss: 0.07034455239772797
Validation loss: 1.4328838561170845

Epoch: 5| Step: 8
Training loss: 0.05035213753581047
Validation loss: 1.4469661571646248

Epoch: 5| Step: 9
Training loss: 0.045812346041202545
Validation loss: 1.4253508711373934

Epoch: 5| Step: 10
Training loss: 0.03891034796833992
Validation loss: 1.416803947059057

Epoch: 722| Step: 0
Training loss: 0.04357841983437538
Validation loss: 1.415911034230263

Epoch: 5| Step: 1
Training loss: 0.050509922206401825
Validation loss: 1.4199503416656165

Epoch: 5| Step: 2
Training loss: 0.03856527805328369
Validation loss: 1.4379164800849011

Epoch: 5| Step: 3
Training loss: 0.054988205432891846
Validation loss: 1.4143102284400695

Epoch: 5| Step: 4
Training loss: 0.050785988569259644
Validation loss: 1.4429776822367022

Epoch: 5| Step: 5
Training loss: 0.03392903134226799
Validation loss: 1.4279430732932141

Epoch: 5| Step: 6
Training loss: 0.03125155717134476
Validation loss: 1.4237590195030294

Epoch: 5| Step: 7
Training loss: 0.03238774091005325
Validation loss: 1.415751899442365

Epoch: 5| Step: 8
Training loss: 0.052560191601514816
Validation loss: 1.4198976998688073

Epoch: 5| Step: 9
Training loss: 0.06618516892194748
Validation loss: 1.419026570935403

Epoch: 5| Step: 10
Training loss: 0.049762897193431854
Validation loss: 1.430519700050354

Epoch: 723| Step: 0
Training loss: 0.052987128496170044
Validation loss: 1.4089872170520086

Epoch: 5| Step: 1
Training loss: 0.06742659211158752
Validation loss: 1.4164948886440647

Epoch: 5| Step: 2
Training loss: 0.03426012396812439
Validation loss: 1.4097163882306827

Epoch: 5| Step: 3
Training loss: 0.07522983849048615
Validation loss: 1.4369889177301878

Epoch: 5| Step: 4
Training loss: 0.03103557601571083
Validation loss: 1.415881860640741

Epoch: 5| Step: 5
Training loss: 0.04905403405427933
Validation loss: 1.4205945025208175

Epoch: 5| Step: 6
Training loss: 0.055284284055233
Validation loss: 1.4015643417194326

Epoch: 5| Step: 7
Training loss: 0.03398848697543144
Validation loss: 1.4266516854686122

Epoch: 5| Step: 8
Training loss: 0.03879843279719353
Validation loss: 1.4153534712329987

Epoch: 5| Step: 9
Training loss: 0.03544727712869644
Validation loss: 1.4170696927655129

Epoch: 5| Step: 10
Training loss: 0.0471663735806942
Validation loss: 1.4251750438444075

Epoch: 724| Step: 0
Training loss: 0.03412679210305214
Validation loss: 1.4361330975768387

Epoch: 5| Step: 1
Training loss: 0.06994586437940598
Validation loss: 1.4399395309468752

Epoch: 5| Step: 2
Training loss: 0.0482960008084774
Validation loss: 1.4240480058936662

Epoch: 5| Step: 3
Training loss: 0.08841194957494736
Validation loss: 1.4337474492288405

Epoch: 5| Step: 4
Training loss: 0.055397313088178635
Validation loss: 1.4248321556275891

Epoch: 5| Step: 5
Training loss: 0.05091334134340286
Validation loss: 1.4061372382666475

Epoch: 5| Step: 6
Training loss: 0.04187363386154175
Validation loss: 1.4113713490065707

Epoch: 5| Step: 7
Training loss: 0.03831162676215172
Validation loss: 1.3871512265615566

Epoch: 5| Step: 8
Training loss: 0.030332405120134354
Validation loss: 1.409953107116043

Epoch: 5| Step: 9
Training loss: 0.0579337477684021
Validation loss: 1.4008257427523214

Epoch: 5| Step: 10
Training loss: 0.055929508060216904
Validation loss: 1.4126447977558259

Epoch: 725| Step: 0
Training loss: 0.0647953525185585
Validation loss: 1.4013251578936012

Epoch: 5| Step: 1
Training loss: 0.06570222973823547
Validation loss: 1.4212577445532686

Epoch: 5| Step: 2
Training loss: 0.061344511806964874
Validation loss: 1.4170965866375995

Epoch: 5| Step: 3
Training loss: 0.03159663826227188
Validation loss: 1.4174913622999703

Epoch: 5| Step: 4
Training loss: 0.04794647917151451
Validation loss: 1.4205592011892667

Epoch: 5| Step: 5
Training loss: 0.061827998608350754
Validation loss: 1.4490443378366449

Epoch: 5| Step: 6
Training loss: 0.0352962389588356
Validation loss: 1.4328723261433263

Epoch: 5| Step: 7
Training loss: 0.047910187393426895
Validation loss: 1.4347017183098743

Epoch: 5| Step: 8
Training loss: 0.028706718236207962
Validation loss: 1.4289322950506722

Epoch: 5| Step: 9
Training loss: 0.0377335250377655
Validation loss: 1.4160497803841867

Epoch: 5| Step: 10
Training loss: 0.06568995118141174
Validation loss: 1.4325333385057346

Epoch: 726| Step: 0
Training loss: 0.05084950476884842
Validation loss: 1.424445125364488

Epoch: 5| Step: 1
Training loss: 0.09535536170005798
Validation loss: 1.4585097066817745

Epoch: 5| Step: 2
Training loss: 0.04050435125827789
Validation loss: 1.4500940390812453

Epoch: 5| Step: 3
Training loss: 0.05473799630999565
Validation loss: 1.4568604294971754

Epoch: 5| Step: 4
Training loss: 0.021814730018377304
Validation loss: 1.4356492373251146

Epoch: 5| Step: 5
Training loss: 0.05176372453570366
Validation loss: 1.4307174118616248

Epoch: 5| Step: 6
Training loss: 0.03132646530866623
Validation loss: 1.4215879747944493

Epoch: 5| Step: 7
Training loss: 0.04535212367773056
Validation loss: 1.4433251606520785

Epoch: 5| Step: 8
Training loss: 0.038357384502887726
Validation loss: 1.4338539133789718

Epoch: 5| Step: 9
Training loss: 0.038480594754219055
Validation loss: 1.4410628285459293

Epoch: 5| Step: 10
Training loss: 0.07499650120735168
Validation loss: 1.4412753556364326

Epoch: 727| Step: 0
Training loss: 0.04335801303386688
Validation loss: 1.4514091002043856

Epoch: 5| Step: 1
Training loss: 0.07029296457767487
Validation loss: 1.4558868664567188

Epoch: 5| Step: 2
Training loss: 0.06004961207509041
Validation loss: 1.431262380333357

Epoch: 5| Step: 3
Training loss: 0.06111676245927811
Validation loss: 1.433072446494974

Epoch: 5| Step: 4
Training loss: 0.06307345628738403
Validation loss: 1.413315382055057

Epoch: 5| Step: 5
Training loss: 0.046264417469501495
Validation loss: 1.4074957575849307

Epoch: 5| Step: 6
Training loss: 0.0422615222632885
Validation loss: 1.4092202917222054

Epoch: 5| Step: 7
Training loss: 0.05708956718444824
Validation loss: 1.4072950815641752

Epoch: 5| Step: 8
Training loss: 0.06446120142936707
Validation loss: 1.4276758573388542

Epoch: 5| Step: 9
Training loss: 0.07975023239850998
Validation loss: 1.4121312531091834

Epoch: 5| Step: 10
Training loss: 0.07743678241968155
Validation loss: 1.4213268346683954

Epoch: 728| Step: 0
Training loss: 0.0636802688241005
Validation loss: 1.418509130836815

Epoch: 5| Step: 1
Training loss: 0.05395369604229927
Validation loss: 1.4206613532958492

Epoch: 5| Step: 2
Training loss: 0.040634118020534515
Validation loss: 1.414523256722317

Epoch: 5| Step: 3
Training loss: 0.07442484050989151
Validation loss: 1.4483500488342778

Epoch: 5| Step: 4
Training loss: 0.047084324061870575
Validation loss: 1.427243394236411

Epoch: 5| Step: 5
Training loss: 0.06471981108188629
Validation loss: 1.4266045734446535

Epoch: 5| Step: 6
Training loss: 0.05880206823348999
Validation loss: 1.4256000172707342

Epoch: 5| Step: 7
Training loss: 0.037693288177251816
Validation loss: 1.4196237979396698

Epoch: 5| Step: 8
Training loss: 0.03937411308288574
Validation loss: 1.4266949994589693

Epoch: 5| Step: 9
Training loss: 0.06240340322256088
Validation loss: 1.4265951918017479

Epoch: 5| Step: 10
Training loss: 0.05772751197218895
Validation loss: 1.4356259351135583

Epoch: 729| Step: 0
Training loss: 0.05049086734652519
Validation loss: 1.426586627960205

Epoch: 5| Step: 1
Training loss: 0.04297361895442009
Validation loss: 1.412285033092704

Epoch: 5| Step: 2
Training loss: 0.049756817519664764
Validation loss: 1.398759441991006

Epoch: 5| Step: 3
Training loss: 0.053912945091724396
Validation loss: 1.3936495857854043

Epoch: 5| Step: 4
Training loss: 0.040769439190626144
Validation loss: 1.3948191583797496

Epoch: 5| Step: 5
Training loss: 0.04195615276694298
Validation loss: 1.402541837384624

Epoch: 5| Step: 6
Training loss: 0.04453949257731438
Validation loss: 1.398142175007892

Epoch: 5| Step: 7
Training loss: 0.08213536441326141
Validation loss: 1.3972778012675624

Epoch: 5| Step: 8
Training loss: 0.06537215411663055
Validation loss: 1.3971677211023146

Epoch: 5| Step: 9
Training loss: 0.051451753824949265
Validation loss: 1.4117866767350065

Epoch: 5| Step: 10
Training loss: 0.055232007056474686
Validation loss: 1.398372031027271

Epoch: 730| Step: 0
Training loss: 0.0337945893406868
Validation loss: 1.4094177279421078

Epoch: 5| Step: 1
Training loss: 0.037364471703767776
Validation loss: 1.434449529135099

Epoch: 5| Step: 2
Training loss: 0.037842296063899994
Validation loss: 1.4287409602954824

Epoch: 5| Step: 3
Training loss: 0.037175942212343216
Validation loss: 1.435894388024525

Epoch: 5| Step: 4
Training loss: 0.03836226463317871
Validation loss: 1.4419875106503885

Epoch: 5| Step: 5
Training loss: 0.07337991893291473
Validation loss: 1.4552990467317644

Epoch: 5| Step: 6
Training loss: 0.046704504638910294
Validation loss: 1.4798808636203888

Epoch: 5| Step: 7
Training loss: 0.05307680368423462
Validation loss: 1.4513717787240141

Epoch: 5| Step: 8
Training loss: 0.03750936686992645
Validation loss: 1.4487206935882568

Epoch: 5| Step: 9
Training loss: 0.048196740448474884
Validation loss: 1.4683295860085437

Epoch: 5| Step: 10
Training loss: 0.1131894588470459
Validation loss: 1.4560500383377075

Epoch: 731| Step: 0
Training loss: 0.07416882365942001
Validation loss: 1.469096863141624

Epoch: 5| Step: 1
Training loss: 0.05523927882313728
Validation loss: 1.4675102592796407

Epoch: 5| Step: 2
Training loss: 0.05245652049779892
Validation loss: 1.4619940109150384

Epoch: 5| Step: 3
Training loss: 0.056539006531238556
Validation loss: 1.4740163036572036

Epoch: 5| Step: 4
Training loss: 0.062186338007450104
Validation loss: 1.4704354168266378

Epoch: 5| Step: 5
Training loss: 0.03299165517091751
Validation loss: 1.4454512724312403

Epoch: 5| Step: 6
Training loss: 0.045363981276750565
Validation loss: 1.4434649354668074

Epoch: 5| Step: 7
Training loss: 0.07042801380157471
Validation loss: 1.4566179180657992

Epoch: 5| Step: 8
Training loss: 0.07595705986022949
Validation loss: 1.4321942149951894

Epoch: 5| Step: 9
Training loss: 0.04945291578769684
Validation loss: 1.4425031651732743

Epoch: 5| Step: 10
Training loss: 0.06585963815450668
Validation loss: 1.4474184013182116

Epoch: 732| Step: 0
Training loss: 0.056989558041095734
Validation loss: 1.4338958827398156

Epoch: 5| Step: 1
Training loss: 0.0506611168384552
Validation loss: 1.4516073619165728

Epoch: 5| Step: 2
Training loss: 0.058756567537784576
Validation loss: 1.4337926257041194

Epoch: 5| Step: 3
Training loss: 0.09163389354944229
Validation loss: 1.4514820293713642

Epoch: 5| Step: 4
Training loss: 0.031918998807668686
Validation loss: 1.4638566047914567

Epoch: 5| Step: 5
Training loss: 0.051494695246219635
Validation loss: 1.4689322735673638

Epoch: 5| Step: 6
Training loss: 0.06518391519784927
Validation loss: 1.4695099130753548

Epoch: 5| Step: 7
Training loss: 0.042593151330947876
Validation loss: 1.4853475209205382

Epoch: 5| Step: 8
Training loss: 0.03834124282002449
Validation loss: 1.5092220370487501

Epoch: 5| Step: 9
Training loss: 0.058099400252103806
Validation loss: 1.478212732140736

Epoch: 5| Step: 10
Training loss: 0.052251700311899185
Validation loss: 1.4927043158520934

Epoch: 733| Step: 0
Training loss: 0.07264401018619537
Validation loss: 1.4752708801659205

Epoch: 5| Step: 1
Training loss: 0.04329308867454529
Validation loss: 1.4790353377660115

Epoch: 5| Step: 2
Training loss: 0.03251149505376816
Validation loss: 1.4339707461736535

Epoch: 5| Step: 3
Training loss: 0.03913196921348572
Validation loss: 1.4790395703367007

Epoch: 5| Step: 4
Training loss: 0.06301756203174591
Validation loss: 1.4542148651615265

Epoch: 5| Step: 5
Training loss: 0.08265314996242523
Validation loss: 1.4818465248230965

Epoch: 5| Step: 6
Training loss: 0.049801044166088104
Validation loss: 1.4671742871243467

Epoch: 5| Step: 7
Training loss: 0.03687582537531853
Validation loss: 1.4676298300425212

Epoch: 5| Step: 8
Training loss: 0.04969242215156555
Validation loss: 1.4715004422331368

Epoch: 5| Step: 9
Training loss: 0.03895902261137962
Validation loss: 1.453678297740157

Epoch: 5| Step: 10
Training loss: 0.05333034694194794
Validation loss: 1.465633426943133

Epoch: 734| Step: 0
Training loss: 0.06468765437602997
Validation loss: 1.4381041180702947

Epoch: 5| Step: 1
Training loss: 0.05024157091975212
Validation loss: 1.4441356338480467

Epoch: 5| Step: 2
Training loss: 0.04515177756547928
Validation loss: 1.4169285156393563

Epoch: 5| Step: 3
Training loss: 0.03259774297475815
Validation loss: 1.423600519857099

Epoch: 5| Step: 4
Training loss: 0.031109536066651344
Validation loss: 1.440227787981751

Epoch: 5| Step: 5
Training loss: 0.050114165991544724
Validation loss: 1.4421228234485914

Epoch: 5| Step: 6
Training loss: 0.08663982897996902
Validation loss: 1.4625353890080606

Epoch: 5| Step: 7
Training loss: 0.05865051597356796
Validation loss: 1.4619202319011892

Epoch: 5| Step: 8
Training loss: 0.059238649904727936
Validation loss: 1.4418433033010012

Epoch: 5| Step: 9
Training loss: 0.049531757831573486
Validation loss: 1.4600519851971698

Epoch: 5| Step: 10
Training loss: 0.03922424465417862
Validation loss: 1.4589474688294113

Epoch: 735| Step: 0
Training loss: 0.04474901780486107
Validation loss: 1.4595279834603752

Epoch: 5| Step: 1
Training loss: 0.03263666480779648
Validation loss: 1.449164867401123

Epoch: 5| Step: 2
Training loss: 0.06556522101163864
Validation loss: 1.4519432103762062

Epoch: 5| Step: 3
Training loss: 0.04244980961084366
Validation loss: 1.466488959968731

Epoch: 5| Step: 4
Training loss: 0.030504945665597916
Validation loss: 1.4585952284515544

Epoch: 5| Step: 5
Training loss: 0.05723557621240616
Validation loss: 1.446305828709756

Epoch: 5| Step: 6
Training loss: 0.05361692234873772
Validation loss: 1.4516769468143422

Epoch: 5| Step: 7
Training loss: 0.055518556386232376
Validation loss: 1.404668636860386

Epoch: 5| Step: 8
Training loss: 0.07506392896175385
Validation loss: 1.4142616628318705

Epoch: 5| Step: 9
Training loss: 0.077028289437294
Validation loss: 1.4080764016797465

Epoch: 5| Step: 10
Training loss: 0.050680555403232574
Validation loss: 1.4161552613781345

Epoch: 736| Step: 0
Training loss: 0.03460089489817619
Validation loss: 1.3981534998903993

Epoch: 5| Step: 1
Training loss: 0.062444306910037994
Validation loss: 1.3886179385646698

Epoch: 5| Step: 2
Training loss: 0.06241810321807861
Validation loss: 1.395140564569863

Epoch: 5| Step: 3
Training loss: 0.04312056303024292
Validation loss: 1.421920213648068

Epoch: 5| Step: 4
Training loss: 0.04016375541687012
Validation loss: 1.4055394908433319

Epoch: 5| Step: 5
Training loss: 0.056383371353149414
Validation loss: 1.4300744712993663

Epoch: 5| Step: 6
Training loss: 0.056023359298706055
Validation loss: 1.4455644674198602

Epoch: 5| Step: 7
Training loss: 0.05308813974261284
Validation loss: 1.4475002250363749

Epoch: 5| Step: 8
Training loss: 0.04619581252336502
Validation loss: 1.462263277781907

Epoch: 5| Step: 9
Training loss: 0.04394778981804848
Validation loss: 1.4854379571894163

Epoch: 5| Step: 10
Training loss: 0.05317248776555061
Validation loss: 1.4805310028855518

Epoch: 737| Step: 0
Training loss: 0.038788776844739914
Validation loss: 1.5079437872414947

Epoch: 5| Step: 1
Training loss: 0.04904372990131378
Validation loss: 1.4843262446823942

Epoch: 5| Step: 2
Training loss: 0.06512759625911713
Validation loss: 1.4775289861104821

Epoch: 5| Step: 3
Training loss: 0.03407193720340729
Validation loss: 1.4592153923485869

Epoch: 5| Step: 4
Training loss: 0.04697754234075546
Validation loss: 1.4561251010946048

Epoch: 5| Step: 5
Training loss: 0.05491788312792778
Validation loss: 1.4628454985157135

Epoch: 5| Step: 6
Training loss: 0.034758053719997406
Validation loss: 1.440331882046115

Epoch: 5| Step: 7
Training loss: 0.05376267433166504
Validation loss: 1.4623237130462483

Epoch: 5| Step: 8
Training loss: 0.05188540369272232
Validation loss: 1.4401119280886907

Epoch: 5| Step: 9
Training loss: 0.06686891615390778
Validation loss: 1.4300663445585517

Epoch: 5| Step: 10
Training loss: 0.042740508913993835
Validation loss: 1.4498869219133932

Epoch: 738| Step: 0
Training loss: 0.05042215436697006
Validation loss: 1.4360271333366312

Epoch: 5| Step: 1
Training loss: 0.06084970384836197
Validation loss: 1.450293117953885

Epoch: 5| Step: 2
Training loss: 0.03648066520690918
Validation loss: 1.451020989366757

Epoch: 5| Step: 3
Training loss: 0.041488438844680786
Validation loss: 1.4422034525102185

Epoch: 5| Step: 4
Training loss: 0.027238618582487106
Validation loss: 1.460579461948846

Epoch: 5| Step: 5
Training loss: 0.05474932864308357
Validation loss: 1.459135950252574

Epoch: 5| Step: 6
Training loss: 0.046428240835666656
Validation loss: 1.4404070172258603

Epoch: 5| Step: 7
Training loss: 0.05972328782081604
Validation loss: 1.4629345491368284

Epoch: 5| Step: 8
Training loss: 0.04162575677037239
Validation loss: 1.4619101324389059

Epoch: 5| Step: 9
Training loss: 0.031151067465543747
Validation loss: 1.4516317472662976

Epoch: 5| Step: 10
Training loss: 0.05976970121264458
Validation loss: 1.4301043774491997

Epoch: 739| Step: 0
Training loss: 0.04083247855305672
Validation loss: 1.443913794332935

Epoch: 5| Step: 1
Training loss: 0.047247372567653656
Validation loss: 1.443513012060555

Epoch: 5| Step: 2
Training loss: 0.06890533119440079
Validation loss: 1.4238228823549004

Epoch: 5| Step: 3
Training loss: 0.043443404138088226
Validation loss: 1.420659213937739

Epoch: 5| Step: 4
Training loss: 0.04715465009212494
Validation loss: 1.4404446950522802

Epoch: 5| Step: 5
Training loss: 0.058931268751621246
Validation loss: 1.4265263824052707

Epoch: 5| Step: 6
Training loss: 0.04540249705314636
Validation loss: 1.4172027828872844

Epoch: 5| Step: 7
Training loss: 0.07263411581516266
Validation loss: 1.4179178758334088

Epoch: 5| Step: 8
Training loss: 0.06756877899169922
Validation loss: 1.410709455449094

Epoch: 5| Step: 9
Training loss: 0.04728803411126137
Validation loss: 1.4282254698455974

Epoch: 5| Step: 10
Training loss: 0.04114062339067459
Validation loss: 1.414224534906367

Epoch: 740| Step: 0
Training loss: 0.04045847803354263
Validation loss: 1.406673740315181

Epoch: 5| Step: 1
Training loss: 0.03943624719977379
Validation loss: 1.434841226505977

Epoch: 5| Step: 2
Training loss: 0.04297653213143349
Validation loss: 1.4133979902472547

Epoch: 5| Step: 3
Training loss: 0.04340009763836861
Validation loss: 1.4329166848172423

Epoch: 5| Step: 4
Training loss: 0.05412306636571884
Validation loss: 1.4071227363360825

Epoch: 5| Step: 5
Training loss: 0.04542876407504082
Validation loss: 1.4431926755494968

Epoch: 5| Step: 6
Training loss: 0.04552071541547775
Validation loss: 1.4228274642780263

Epoch: 5| Step: 7
Training loss: 0.036207474768161774
Validation loss: 1.4314172267913818

Epoch: 5| Step: 8
Training loss: 0.08362782746553421
Validation loss: 1.432044626564108

Epoch: 5| Step: 9
Training loss: 0.05059364438056946
Validation loss: 1.4409719359490178

Epoch: 5| Step: 10
Training loss: 0.05972529202699661
Validation loss: 1.4286901002289147

Epoch: 741| Step: 0
Training loss: 0.02589409425854683
Validation loss: 1.4158765885137743

Epoch: 5| Step: 1
Training loss: 0.03938755393028259
Validation loss: 1.389585728286415

Epoch: 5| Step: 2
Training loss: 0.04032238945364952
Validation loss: 1.4008183992037209

Epoch: 5| Step: 3
Training loss: 0.03501114249229431
Validation loss: 1.4244275144351426

Epoch: 5| Step: 4
Training loss: 0.06736160814762115
Validation loss: 1.4131763019869406

Epoch: 5| Step: 5
Training loss: 0.04597955197095871
Validation loss: 1.4109582926637383

Epoch: 5| Step: 6
Training loss: 0.05235977843403816
Validation loss: 1.4385540126472391

Epoch: 5| Step: 7
Training loss: 0.02989942952990532
Validation loss: 1.4296796770506008

Epoch: 5| Step: 8
Training loss: 0.05937577411532402
Validation loss: 1.428540677152654

Epoch: 5| Step: 9
Training loss: 0.056099213659763336
Validation loss: 1.4371979890331146

Epoch: 5| Step: 10
Training loss: 0.06072132661938667
Validation loss: 1.4254402825909276

Epoch: 742| Step: 0
Training loss: 0.04533260315656662
Validation loss: 1.4490775818465857

Epoch: 5| Step: 1
Training loss: 0.04846983402967453
Validation loss: 1.431061069170634

Epoch: 5| Step: 2
Training loss: 0.0453663095831871
Validation loss: 1.4318088946803924

Epoch: 5| Step: 3
Training loss: 0.051638878881931305
Validation loss: 1.4514546842985256

Epoch: 5| Step: 4
Training loss: 0.04825376346707344
Validation loss: 1.4633660226739862

Epoch: 5| Step: 5
Training loss: 0.10958150774240494
Validation loss: 1.4504098289756364

Epoch: 5| Step: 6
Training loss: 0.04855116456747055
Validation loss: 1.4453931739253383

Epoch: 5| Step: 7
Training loss: 0.04932742938399315
Validation loss: 1.4207435654055687

Epoch: 5| Step: 8
Training loss: 0.040911681950092316
Validation loss: 1.4263611711481565

Epoch: 5| Step: 9
Training loss: 0.07451125234365463
Validation loss: 1.4315674343416769

Epoch: 5| Step: 10
Training loss: 0.05873824656009674
Validation loss: 1.4438742578670543

Epoch: 743| Step: 0
Training loss: 0.03522922843694687
Validation loss: 1.4170823417684084

Epoch: 5| Step: 1
Training loss: 0.02950671687722206
Validation loss: 1.4069347689228673

Epoch: 5| Step: 2
Training loss: 0.042737215757369995
Validation loss: 1.400168688066544

Epoch: 5| Step: 3
Training loss: 0.04515635967254639
Validation loss: 1.3991022353531213

Epoch: 5| Step: 4
Training loss: 0.06460998952388763
Validation loss: 1.3931973826500677

Epoch: 5| Step: 5
Training loss: 0.06535293161869049
Validation loss: 1.3972701609775584

Epoch: 5| Step: 6
Training loss: 0.04142677038908005
Validation loss: 1.38725193085209

Epoch: 5| Step: 7
Training loss: 0.027432013303041458
Validation loss: 1.4131280561929107

Epoch: 5| Step: 8
Training loss: 0.045752931386232376
Validation loss: 1.406208606176479

Epoch: 5| Step: 9
Training loss: 0.04407375305891037
Validation loss: 1.4103668441054642

Epoch: 5| Step: 10
Training loss: 0.059304624795913696
Validation loss: 1.4452650867482668

Epoch: 744| Step: 0
Training loss: 0.0595407597720623
Validation loss: 1.4344291187101794

Epoch: 5| Step: 1
Training loss: 0.04890396445989609
Validation loss: 1.4386328163967337

Epoch: 5| Step: 2
Training loss: 0.06485222280025482
Validation loss: 1.455581800271106

Epoch: 5| Step: 3
Training loss: 0.038385916501283646
Validation loss: 1.4486340688120933

Epoch: 5| Step: 4
Training loss: 0.04730500653386116
Validation loss: 1.4238439336899789

Epoch: 5| Step: 5
Training loss: 0.03290834277868271
Validation loss: 1.437684005306613

Epoch: 5| Step: 6
Training loss: 0.04196859151124954
Validation loss: 1.4398884234889862

Epoch: 5| Step: 7
Training loss: 0.048048071563243866
Validation loss: 1.4550932094614992

Epoch: 5| Step: 8
Training loss: 0.06724165380001068
Validation loss: 1.4569121740197624

Epoch: 5| Step: 9
Training loss: 0.047079719603061676
Validation loss: 1.4590565248202252

Epoch: 5| Step: 10
Training loss: 0.05250485613942146
Validation loss: 1.4388795873170257

Epoch: 745| Step: 0
Training loss: 0.04724918678402901
Validation loss: 1.424954536140606

Epoch: 5| Step: 1
Training loss: 0.08543125540018082
Validation loss: 1.4707225625232985

Epoch: 5| Step: 2
Training loss: 0.045187823474407196
Validation loss: 1.4666631119225615

Epoch: 5| Step: 3
Training loss: 0.030888602137565613
Validation loss: 1.4497685932344007

Epoch: 5| Step: 4
Training loss: 0.05264725536108017
Validation loss: 1.4425473636196506

Epoch: 5| Step: 5
Training loss: 0.07577304542064667
Validation loss: 1.454025415964024

Epoch: 5| Step: 6
Training loss: 0.05352740362286568
Validation loss: 1.4443825406412925

Epoch: 5| Step: 7
Training loss: 0.05526083707809448
Validation loss: 1.427732975252213

Epoch: 5| Step: 8
Training loss: 0.04151398688554764
Validation loss: 1.436895324337867

Epoch: 5| Step: 9
Training loss: 0.05601777881383896
Validation loss: 1.4122225110248854

Epoch: 5| Step: 10
Training loss: 0.03971485421061516
Validation loss: 1.4033207790825957

Epoch: 746| Step: 0
Training loss: 0.06049653887748718
Validation loss: 1.4290843215039981

Epoch: 5| Step: 1
Training loss: 0.054816119372844696
Validation loss: 1.4225345683354202

Epoch: 5| Step: 2
Training loss: 0.02471437118947506
Validation loss: 1.4419596861767512

Epoch: 5| Step: 3
Training loss: 0.04596290364861488
Validation loss: 1.4512353853512836

Epoch: 5| Step: 4
Training loss: 0.05029697343707085
Validation loss: 1.43504842763306

Epoch: 5| Step: 5
Training loss: 0.04490924999117851
Validation loss: 1.421068008228015

Epoch: 5| Step: 6
Training loss: 0.05792985111474991
Validation loss: 1.4356451303728166

Epoch: 5| Step: 7
Training loss: 0.03143879026174545
Validation loss: 1.4450614618998703

Epoch: 5| Step: 8
Training loss: 0.03814356401562691
Validation loss: 1.416540918811675

Epoch: 5| Step: 9
Training loss: 0.048396602272987366
Validation loss: 1.4320418309139948

Epoch: 5| Step: 10
Training loss: 0.03764233738183975
Validation loss: 1.4342336500844648

Epoch: 747| Step: 0
Training loss: 0.037444449961185455
Validation loss: 1.4687121273368917

Epoch: 5| Step: 1
Training loss: 0.059415172785520554
Validation loss: 1.4346562059976722

Epoch: 5| Step: 2
Training loss: 0.07749709486961365
Validation loss: 1.4284605986328536

Epoch: 5| Step: 3
Training loss: 0.07567088305950165
Validation loss: 1.4435475193044192

Epoch: 5| Step: 4
Training loss: 0.04793009161949158
Validation loss: 1.4364345073699951

Epoch: 5| Step: 5
Training loss: 0.05364123731851578
Validation loss: 1.4418556613306845

Epoch: 5| Step: 6
Training loss: 0.046516768634319305
Validation loss: 1.438350894117868

Epoch: 5| Step: 7
Training loss: 0.03274696320295334
Validation loss: 1.4641814872782717

Epoch: 5| Step: 8
Training loss: 0.04098998382687569
Validation loss: 1.4458502761779293

Epoch: 5| Step: 9
Training loss: 0.049628280103206635
Validation loss: 1.4546205330920476

Epoch: 5| Step: 10
Training loss: 0.03566453605890274
Validation loss: 1.4389857899758123

Epoch: 748| Step: 0
Training loss: 0.057968009263277054
Validation loss: 1.4477593501408894

Epoch: 5| Step: 1
Training loss: 0.049470268189907074
Validation loss: 1.4338399030828988

Epoch: 5| Step: 2
Training loss: 0.05501735210418701
Validation loss: 1.446584750247258

Epoch: 5| Step: 3
Training loss: 0.055151402950286865
Validation loss: 1.420301551459938

Epoch: 5| Step: 4
Training loss: 0.03728792816400528
Validation loss: 1.4140814273588118

Epoch: 5| Step: 5
Training loss: 0.05286400392651558
Validation loss: 1.4055298374545189

Epoch: 5| Step: 6
Training loss: 0.029582876712083817
Validation loss: 1.4228759093951153

Epoch: 5| Step: 7
Training loss: 0.026299864053726196
Validation loss: 1.4141747733598113

Epoch: 5| Step: 8
Training loss: 0.03829063102602959
Validation loss: 1.4379473860545824

Epoch: 5| Step: 9
Training loss: 0.047314755618572235
Validation loss: 1.40540159902265

Epoch: 5| Step: 10
Training loss: 0.044349879026412964
Validation loss: 1.4193514957222888

Epoch: 749| Step: 0
Training loss: 0.036560095846652985
Validation loss: 1.4092101012506792

Epoch: 5| Step: 1
Training loss: 0.035146988928318024
Validation loss: 1.4086590543870003

Epoch: 5| Step: 2
Training loss: 0.03429873660206795
Validation loss: 1.411029827210211

Epoch: 5| Step: 3
Training loss: 0.037027161568403244
Validation loss: 1.4440170693141159

Epoch: 5| Step: 4
Training loss: 0.05171886831521988
Validation loss: 1.426255561972177

Epoch: 5| Step: 5
Training loss: 0.026590321213006973
Validation loss: 1.427368737036182

Epoch: 5| Step: 6
Training loss: 0.04337911680340767
Validation loss: 1.438968143155498

Epoch: 5| Step: 7
Training loss: 0.04709271714091301
Validation loss: 1.4404047137947493

Epoch: 5| Step: 8
Training loss: 0.03415953367948532
Validation loss: 1.4452957107174782

Epoch: 5| Step: 9
Training loss: 0.05232682079076767
Validation loss: 1.434912807197981

Epoch: 5| Step: 10
Training loss: 0.07625722140073776
Validation loss: 1.4313896086908156

Epoch: 750| Step: 0
Training loss: 0.04913468658924103
Validation loss: 1.4064485776808955

Epoch: 5| Step: 1
Training loss: 0.05513400956988335
Validation loss: 1.4179506096788632

Epoch: 5| Step: 2
Training loss: 0.0672474354505539
Validation loss: 1.3991539568029425

Epoch: 5| Step: 3
Training loss: 0.040959496051073074
Validation loss: 1.412185795845524

Epoch: 5| Step: 4
Training loss: 0.04256653040647507
Validation loss: 1.3994484370754612

Epoch: 5| Step: 5
Training loss: 0.04846804216504097
Validation loss: 1.3917441477057755

Epoch: 5| Step: 6
Training loss: 0.051090825349092484
Validation loss: 1.4051612288721147

Epoch: 5| Step: 7
Training loss: 0.039394132792949677
Validation loss: 1.4109229272411716

Epoch: 5| Step: 8
Training loss: 0.04365868866443634
Validation loss: 1.4305445109644244

Epoch: 5| Step: 9
Training loss: 0.04343004897236824
Validation loss: 1.4395568601546749

Epoch: 5| Step: 10
Training loss: 0.04445848986506462
Validation loss: 1.436140138615844

Testing loss: 1.942899955643548
