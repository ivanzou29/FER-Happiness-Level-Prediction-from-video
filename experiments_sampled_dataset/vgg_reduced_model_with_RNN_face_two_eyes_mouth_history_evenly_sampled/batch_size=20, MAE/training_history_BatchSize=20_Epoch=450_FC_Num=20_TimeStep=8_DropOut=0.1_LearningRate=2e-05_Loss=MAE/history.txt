Epoch: 1| Step: 0
Training loss: 4.586590766906738
Validation loss: 5.203703670091526

Epoch: 5| Step: 1
Training loss: 3.4738070964813232
Validation loss: 5.1723543238896195

Epoch: 5| Step: 2
Training loss: 5.093003273010254
Validation loss: 5.144361029389084

Epoch: 5| Step: 3
Training loss: 4.916834831237793
Validation loss: 5.115004744580997

Epoch: 5| Step: 4
Training loss: 5.240837574005127
Validation loss: 5.081978074965939

Epoch: 5| Step: 5
Training loss: 5.267439365386963
Validation loss: 5.045182663907287

Epoch: 5| Step: 6
Training loss: 4.921144008636475
Validation loss: 5.003468149451799

Epoch: 5| Step: 7
Training loss: 5.275787830352783
Validation loss: 4.956229209899902

Epoch: 5| Step: 8
Training loss: 4.837523460388184
Validation loss: 4.90366607071251

Epoch: 5| Step: 9
Training loss: 4.657166481018066
Validation loss: 4.845421693658316

Epoch: 5| Step: 10
Training loss: 4.709727764129639
Validation loss: 4.78215693402034

Epoch: 2| Step: 0
Training loss: 4.007776260375977
Validation loss: 4.712152342642507

Epoch: 5| Step: 1
Training loss: 4.017061233520508
Validation loss: 4.6386622613476165

Epoch: 5| Step: 2
Training loss: 4.329583168029785
Validation loss: 4.562377663068874

Epoch: 5| Step: 3
Training loss: 3.6401753425598145
Validation loss: 4.4808239013917985

Epoch: 5| Step: 4
Training loss: 4.409885406494141
Validation loss: 4.402539847999491

Epoch: 5| Step: 5
Training loss: 5.04721736907959
Validation loss: 4.326292684001308

Epoch: 5| Step: 6
Training loss: 4.7783074378967285
Validation loss: 4.254600614629766

Epoch: 5| Step: 7
Training loss: 4.475788116455078
Validation loss: 4.186601274756975

Epoch: 5| Step: 8
Training loss: 3.6278910636901855
Validation loss: 4.122259624542728

Epoch: 5| Step: 9
Training loss: 3.2738394737243652
Validation loss: 4.055440097726802

Epoch: 5| Step: 10
Training loss: 3.8272364139556885
Validation loss: 3.996168767252276

Epoch: 3| Step: 0
Training loss: 3.337536573410034
Validation loss: 3.9293345379573044

Epoch: 5| Step: 1
Training loss: 3.80680513381958
Validation loss: 3.8656565681580575

Epoch: 5| Step: 2
Training loss: 3.9097213745117188
Validation loss: 3.7958679865765315

Epoch: 5| Step: 3
Training loss: 4.510346412658691
Validation loss: 3.729423902368033

Epoch: 5| Step: 4
Training loss: 3.2095947265625
Validation loss: 3.6719697213942006

Epoch: 5| Step: 5
Training loss: 2.9392447471618652
Validation loss: 3.622799914370301

Epoch: 5| Step: 6
Training loss: 4.443448543548584
Validation loss: 3.574856247953189

Epoch: 5| Step: 7
Training loss: 3.0945324897766113
Validation loss: 3.5326663447964575

Epoch: 5| Step: 8
Training loss: 2.9446895122528076
Validation loss: 3.4918927556724957

Epoch: 5| Step: 9
Training loss: 2.567314863204956
Validation loss: 3.4541913514496176

Epoch: 5| Step: 10
Training loss: 4.63227653503418
Validation loss: 3.4178193384601223

Epoch: 4| Step: 0
Training loss: 4.045985221862793
Validation loss: 3.382807198391166

Epoch: 5| Step: 1
Training loss: 3.7499337196350098
Validation loss: 3.352262379020773

Epoch: 5| Step: 2
Training loss: 3.198087215423584
Validation loss: 3.320213997235862

Epoch: 5| Step: 3
Training loss: 3.0796680450439453
Validation loss: 3.293071477643905

Epoch: 5| Step: 4
Training loss: 2.971296787261963
Validation loss: 3.266242960447906

Epoch: 5| Step: 5
Training loss: 3.109135627746582
Validation loss: 3.2455360607434343

Epoch: 5| Step: 6
Training loss: 2.5298538208007812
Validation loss: 3.2238270954419206

Epoch: 5| Step: 7
Training loss: 3.0095343589782715
Validation loss: 3.1975197766416814

Epoch: 5| Step: 8
Training loss: 3.387467861175537
Validation loss: 3.1698162812058643

Epoch: 5| Step: 9
Training loss: 2.619029998779297
Validation loss: 3.148715055117043

Epoch: 5| Step: 10
Training loss: 4.017244815826416
Validation loss: 3.125854907497283

Epoch: 5| Step: 0
Training loss: 3.4348576068878174
Validation loss: 3.103679515982187

Epoch: 5| Step: 1
Training loss: 2.051703691482544
Validation loss: 3.0802987493494505

Epoch: 5| Step: 2
Training loss: 2.643460750579834
Validation loss: 3.057557595673428

Epoch: 5| Step: 3
Training loss: 2.9934134483337402
Validation loss: 3.038506015654533

Epoch: 5| Step: 4
Training loss: 3.183290481567383
Validation loss: 3.0228334601207445

Epoch: 5| Step: 5
Training loss: 3.5747764110565186
Validation loss: 3.0118012120646815

Epoch: 5| Step: 6
Training loss: 3.7120327949523926
Validation loss: 2.992783392629316

Epoch: 5| Step: 7
Training loss: 2.358577013015747
Validation loss: 2.993505352286882

Epoch: 5| Step: 8
Training loss: 3.6228790283203125
Validation loss: 3.031295138020669

Epoch: 5| Step: 9
Training loss: 2.5788893699645996
Validation loss: 3.024321715037028

Epoch: 5| Step: 10
Training loss: 3.9184646606445312
Validation loss: 3.0124881831548547

Epoch: 6| Step: 0
Training loss: 3.5261542797088623
Validation loss: 2.990902659713581

Epoch: 5| Step: 1
Training loss: 3.3972649574279785
Validation loss: 2.9721153218259095

Epoch: 5| Step: 2
Training loss: 3.3977980613708496
Validation loss: 2.9567254999632477

Epoch: 5| Step: 3
Training loss: 3.527968168258667
Validation loss: 2.945146160741006

Epoch: 5| Step: 4
Training loss: 2.2317371368408203
Validation loss: 2.9358900054808585

Epoch: 5| Step: 5
Training loss: 3.179600238800049
Validation loss: 2.927867676622124

Epoch: 5| Step: 6
Training loss: 2.7004034519195557
Validation loss: 2.9134308394565376

Epoch: 5| Step: 7
Training loss: 2.787707805633545
Validation loss: 2.904218853160899

Epoch: 5| Step: 8
Training loss: 3.1588611602783203
Validation loss: 2.8954696450182187

Epoch: 5| Step: 9
Training loss: 2.5453238487243652
Validation loss: 2.92316601609671

Epoch: 5| Step: 10
Training loss: 2.842691659927368
Validation loss: 2.8897613325426654

Epoch: 7| Step: 0
Training loss: 3.1139628887176514
Validation loss: 2.8675346502693753

Epoch: 5| Step: 1
Training loss: 3.262427806854248
Validation loss: 2.8639523495909986

Epoch: 5| Step: 2
Training loss: 2.5520408153533936
Validation loss: 2.866328795750936

Epoch: 5| Step: 3
Training loss: 2.9835872650146484
Validation loss: 2.8536426098115983

Epoch: 5| Step: 4
Training loss: 2.55924916267395
Validation loss: 2.8421302303191154

Epoch: 5| Step: 5
Training loss: 2.709857940673828
Validation loss: 2.8414838467874834

Epoch: 5| Step: 6
Training loss: 3.394268751144409
Validation loss: 2.8375137108628468

Epoch: 5| Step: 7
Training loss: 3.1521670818328857
Validation loss: 2.830060141060942

Epoch: 5| Step: 8
Training loss: 2.4633426666259766
Validation loss: 2.8207005300829486

Epoch: 5| Step: 9
Training loss: 3.802677869796753
Validation loss: 2.8154605101513606

Epoch: 5| Step: 10
Training loss: 2.4512827396392822
Validation loss: 2.808689917287519

Epoch: 8| Step: 0
Training loss: 2.5717594623565674
Validation loss: 2.801502655911189

Epoch: 5| Step: 1
Training loss: 3.038747787475586
Validation loss: 2.7931357250418714

Epoch: 5| Step: 2
Training loss: 3.375096082687378
Validation loss: 2.7881227257431194

Epoch: 5| Step: 3
Training loss: 1.9880907535552979
Validation loss: 2.7792544621293263

Epoch: 5| Step: 4
Training loss: 3.465956211090088
Validation loss: 2.7721140641038136

Epoch: 5| Step: 5
Training loss: 2.804781675338745
Validation loss: 2.769551766816006

Epoch: 5| Step: 6
Training loss: 2.7594892978668213
Validation loss: 2.7660783721554663

Epoch: 5| Step: 7
Training loss: 2.7591910362243652
Validation loss: 2.7571614916606615

Epoch: 5| Step: 8
Training loss: 3.849266767501831
Validation loss: 2.755423040800197

Epoch: 5| Step: 9
Training loss: 3.055032253265381
Validation loss: 2.7530261239697857

Epoch: 5| Step: 10
Training loss: 2.329742670059204
Validation loss: 2.749008491475095

Epoch: 9| Step: 0
Training loss: 2.932281494140625
Validation loss: 2.7472238515013006

Epoch: 5| Step: 1
Training loss: 3.1798181533813477
Validation loss: 2.7431590070006666

Epoch: 5| Step: 2
Training loss: 3.220471143722534
Validation loss: 2.7412227866470174

Epoch: 5| Step: 3
Training loss: 3.2074737548828125
Validation loss: 2.7329319984682146

Epoch: 5| Step: 4
Training loss: 3.401318311691284
Validation loss: 2.731856151293683

Epoch: 5| Step: 5
Training loss: 2.573265314102173
Validation loss: 2.728513079304849

Epoch: 5| Step: 6
Training loss: 3.3248450756073
Validation loss: 2.7272446078638874

Epoch: 5| Step: 7
Training loss: 2.657925605773926
Validation loss: 2.723416728358115

Epoch: 5| Step: 8
Training loss: 2.1989805698394775
Validation loss: 2.7199896330474527

Epoch: 5| Step: 9
Training loss: 2.8354852199554443
Validation loss: 2.7156439186424337

Epoch: 5| Step: 10
Training loss: 2.150480270385742
Validation loss: 2.711098683777676

Epoch: 10| Step: 0
Training loss: 1.9636995792388916
Validation loss: 2.7140020708883963

Epoch: 5| Step: 1
Training loss: 3.1802890300750732
Validation loss: 2.7144323318235335

Epoch: 5| Step: 2
Training loss: 3.2616753578186035
Validation loss: 2.7148578884781047

Epoch: 5| Step: 3
Training loss: 2.762009859085083
Validation loss: 2.7145784285760697

Epoch: 5| Step: 4
Training loss: 2.2774434089660645
Validation loss: 2.712313567438433

Epoch: 5| Step: 5
Training loss: 3.489776611328125
Validation loss: 2.7336455058026057

Epoch: 5| Step: 6
Training loss: 2.786728620529175
Validation loss: 2.699503985784387

Epoch: 5| Step: 7
Training loss: 3.1315579414367676
Validation loss: 2.6982018896328506

Epoch: 5| Step: 8
Training loss: 2.64990234375
Validation loss: 2.702791257571149

Epoch: 5| Step: 9
Training loss: 3.4829494953155518
Validation loss: 2.7183975865764003

Epoch: 5| Step: 10
Training loss: 2.619093656539917
Validation loss: 2.712949191370318

Epoch: 11| Step: 0
Training loss: 2.86639142036438
Validation loss: 2.696935853650493

Epoch: 5| Step: 1
Training loss: 3.2946877479553223
Validation loss: 2.6913606915422665

Epoch: 5| Step: 2
Training loss: 2.044233798980713
Validation loss: 2.686352583669847

Epoch: 5| Step: 3
Training loss: 3.1904654502868652
Validation loss: 2.6938550164622646

Epoch: 5| Step: 4
Training loss: 3.449064254760742
Validation loss: 2.683694649768132

Epoch: 5| Step: 5
Training loss: 2.021538257598877
Validation loss: 2.6871689519574566

Epoch: 5| Step: 6
Training loss: 3.437490463256836
Validation loss: 2.6948042531167307

Epoch: 5| Step: 7
Training loss: 2.793201446533203
Validation loss: 2.6846472114645024

Epoch: 5| Step: 8
Training loss: 2.550718307495117
Validation loss: 2.678411632455805

Epoch: 5| Step: 9
Training loss: 2.698180675506592
Validation loss: 2.671460208072457

Epoch: 5| Step: 10
Training loss: 3.153902053833008
Validation loss: 2.673176711605441

Epoch: 12| Step: 0
Training loss: 2.853890895843506
Validation loss: 2.6690681390864874

Epoch: 5| Step: 1
Training loss: 3.371434450149536
Validation loss: 2.66784248300778

Epoch: 5| Step: 2
Training loss: 3.164210796356201
Validation loss: 2.665825282373736

Epoch: 5| Step: 3
Training loss: 3.0150742530822754
Validation loss: 2.6578413927426903

Epoch: 5| Step: 4
Training loss: 2.605234146118164
Validation loss: 2.652861705390356

Epoch: 5| Step: 5
Training loss: 2.420483112335205
Validation loss: 2.645722072611573

Epoch: 5| Step: 6
Training loss: 2.6048471927642822
Validation loss: 2.6501300078566357

Epoch: 5| Step: 7
Training loss: 2.899101972579956
Validation loss: 2.6599806752256168

Epoch: 5| Step: 8
Training loss: 2.215379238128662
Validation loss: 2.6618010305589244

Epoch: 5| Step: 9
Training loss: 3.3055922985076904
Validation loss: 2.6447594063256377

Epoch: 5| Step: 10
Training loss: 2.844047784805298
Validation loss: 2.6431062913710073

Epoch: 13| Step: 0
Training loss: 2.4690732955932617
Validation loss: 2.645307135838334

Epoch: 5| Step: 1
Training loss: 3.304393768310547
Validation loss: 2.653291158778693

Epoch: 5| Step: 2
Training loss: 1.881514549255371
Validation loss: 2.6546799059837096

Epoch: 5| Step: 3
Training loss: 2.7547924518585205
Validation loss: 2.6484488697462183

Epoch: 5| Step: 4
Training loss: 3.3704867362976074
Validation loss: 2.6398319634058143

Epoch: 5| Step: 5
Training loss: 2.9377145767211914
Validation loss: 2.6388161413131224

Epoch: 5| Step: 6
Training loss: 3.051517963409424
Validation loss: 2.6400936367691203

Epoch: 5| Step: 7
Training loss: 2.6678457260131836
Validation loss: 2.646369239335419

Epoch: 5| Step: 8
Training loss: 3.193572521209717
Validation loss: 2.658646957848662

Epoch: 5| Step: 9
Training loss: 2.728961229324341
Validation loss: 2.6355037099571637

Epoch: 5| Step: 10
Training loss: 2.7083303928375244
Validation loss: 2.6291438379595355

Epoch: 14| Step: 0
Training loss: 2.869776964187622
Validation loss: 2.6295359262856106

Epoch: 5| Step: 1
Training loss: 2.519646167755127
Validation loss: 2.624303194784349

Epoch: 5| Step: 2
Training loss: 2.0305838584899902
Validation loss: 2.6289215677527973

Epoch: 5| Step: 3
Training loss: 2.9331576824188232
Validation loss: 2.6286178045375372

Epoch: 5| Step: 4
Training loss: 3.1097559928894043
Validation loss: 2.6257166221577632

Epoch: 5| Step: 5
Training loss: 2.1642417907714844
Validation loss: 2.6214091700892292

Epoch: 5| Step: 6
Training loss: 3.0284323692321777
Validation loss: 2.617027582660798

Epoch: 5| Step: 7
Training loss: 3.1134796142578125
Validation loss: 2.6135567849682224

Epoch: 5| Step: 8
Training loss: 3.0274498462677
Validation loss: 2.6085021342000654

Epoch: 5| Step: 9
Training loss: 2.828683376312256
Validation loss: 2.6014249094070925

Epoch: 5| Step: 10
Training loss: 3.412651538848877
Validation loss: 2.596635439062631

Epoch: 15| Step: 0
Training loss: 2.7509377002716064
Validation loss: 2.595199610597344

Epoch: 5| Step: 1
Training loss: 2.1069583892822266
Validation loss: 2.596512871403848

Epoch: 5| Step: 2
Training loss: 2.7778706550598145
Validation loss: 2.5889896423585954

Epoch: 5| Step: 3
Training loss: 2.970968246459961
Validation loss: 2.5903077074276504

Epoch: 5| Step: 4
Training loss: 2.922694683074951
Validation loss: 2.591988830156224

Epoch: 5| Step: 5
Training loss: 2.5183279514312744
Validation loss: 2.5941329848381782

Epoch: 5| Step: 6
Training loss: 2.5260062217712402
Validation loss: 2.5862441447473343

Epoch: 5| Step: 7
Training loss: 3.072932243347168
Validation loss: 2.5857207134205806

Epoch: 5| Step: 8
Training loss: 3.1726012229919434
Validation loss: 2.583401113428095

Epoch: 5| Step: 9
Training loss: 3.5014426708221436
Validation loss: 2.581308969887354

Epoch: 5| Step: 10
Training loss: 2.3505914211273193
Validation loss: 2.5827097636397167

Epoch: 16| Step: 0
Training loss: 2.9169135093688965
Validation loss: 2.5789299113776094

Epoch: 5| Step: 1
Training loss: 3.231586456298828
Validation loss: 2.580494062874907

Epoch: 5| Step: 2
Training loss: 2.5027596950531006
Validation loss: 2.581317999029672

Epoch: 5| Step: 3
Training loss: 3.0414555072784424
Validation loss: 2.5930402637809835

Epoch: 5| Step: 4
Training loss: 2.4972541332244873
Validation loss: 2.6016541604072816

Epoch: 5| Step: 5
Training loss: 3.044339418411255
Validation loss: 2.675551281180433

Epoch: 5| Step: 6
Training loss: 2.5080037117004395
Validation loss: 2.640262080777076

Epoch: 5| Step: 7
Training loss: 2.8664968013763428
Validation loss: 2.6425851673208256

Epoch: 5| Step: 8
Training loss: 3.0624091625213623
Validation loss: 2.5817188703885643

Epoch: 5| Step: 9
Training loss: 2.396440267562866
Validation loss: 2.555359714774675

Epoch: 5| Step: 10
Training loss: 2.5996596813201904
Validation loss: 2.5684193564999487

Epoch: 17| Step: 0
Training loss: 2.537646770477295
Validation loss: 2.5977859958525626

Epoch: 5| Step: 1
Training loss: 3.173504590988159
Validation loss: 2.593518175104613

Epoch: 5| Step: 2
Training loss: 2.8750503063201904
Validation loss: 2.564653968298307

Epoch: 5| Step: 3
Training loss: 2.3305070400238037
Validation loss: 2.556476644290391

Epoch: 5| Step: 4
Training loss: 3.2667832374572754
Validation loss: 2.546860751285348

Epoch: 5| Step: 5
Training loss: 2.529390811920166
Validation loss: 2.5447484165109615

Epoch: 5| Step: 6
Training loss: 2.9314334392547607
Validation loss: 2.539183880693169

Epoch: 5| Step: 7
Training loss: 2.2316181659698486
Validation loss: 2.541956014530633

Epoch: 5| Step: 8
Training loss: 2.8817532062530518
Validation loss: 2.5562828715129564

Epoch: 5| Step: 9
Training loss: 2.4538516998291016
Validation loss: 2.573092827232935

Epoch: 5| Step: 10
Training loss: 3.341491460800171
Validation loss: 2.5732588844914592

Epoch: 18| Step: 0
Training loss: 2.4167799949645996
Validation loss: 2.576922757651216

Epoch: 5| Step: 1
Training loss: 3.2637691497802734
Validation loss: 2.5912958370741976

Epoch: 5| Step: 2
Training loss: 3.2345287799835205
Validation loss: 2.59260888766217

Epoch: 5| Step: 3
Training loss: 2.4674580097198486
Validation loss: 2.5846247621761855

Epoch: 5| Step: 4
Training loss: 2.4495201110839844
Validation loss: 2.6025159487160305

Epoch: 5| Step: 5
Training loss: 2.828486442565918
Validation loss: 2.57078222561908

Epoch: 5| Step: 6
Training loss: 2.1120352745056152
Validation loss: 2.5510280593749015

Epoch: 5| Step: 7
Training loss: 2.5717687606811523
Validation loss: 2.536252837027273

Epoch: 5| Step: 8
Training loss: 2.709390163421631
Validation loss: 2.527810678687147

Epoch: 5| Step: 9
Training loss: 2.926373243331909
Validation loss: 2.524118443971039

Epoch: 5| Step: 10
Training loss: 3.2526681423187256
Validation loss: 2.5186564896696355

Epoch: 19| Step: 0
Training loss: 2.6977245807647705
Validation loss: 2.515382005322364

Epoch: 5| Step: 1
Training loss: 3.2020936012268066
Validation loss: 2.512718918502972

Epoch: 5| Step: 2
Training loss: 2.4308629035949707
Validation loss: 2.5182990874013593

Epoch: 5| Step: 3
Training loss: 3.0398802757263184
Validation loss: 2.5126936974064

Epoch: 5| Step: 4
Training loss: 2.3351521492004395
Validation loss: 2.509114606406099

Epoch: 5| Step: 5
Training loss: 2.5649852752685547
Validation loss: 2.50643632488866

Epoch: 5| Step: 6
Training loss: 2.9268155097961426
Validation loss: 2.5052658383564284

Epoch: 5| Step: 7
Training loss: 3.3647258281707764
Validation loss: 2.5158563249854633

Epoch: 5| Step: 8
Training loss: 2.527123212814331
Validation loss: 2.517087892819476

Epoch: 5| Step: 9
Training loss: 2.294869899749756
Validation loss: 2.5124194622039795

Epoch: 5| Step: 10
Training loss: 2.522900342941284
Validation loss: 2.4987315106135544

Epoch: 20| Step: 0
Training loss: 2.0868217945098877
Validation loss: 2.4944610108611402

Epoch: 5| Step: 1
Training loss: 2.246107816696167
Validation loss: 2.493343630144673

Epoch: 5| Step: 2
Training loss: 2.6016743183135986
Validation loss: 2.497246347447877

Epoch: 5| Step: 3
Training loss: 3.136333465576172
Validation loss: 2.5048671178920294

Epoch: 5| Step: 4
Training loss: 2.9613170623779297
Validation loss: 2.536613723283173

Epoch: 5| Step: 5
Training loss: 2.793285846710205
Validation loss: 2.5348715320710213

Epoch: 5| Step: 6
Training loss: 3.4381015300750732
Validation loss: 2.5268285120687177

Epoch: 5| Step: 7
Training loss: 2.6913533210754395
Validation loss: 2.5233588423780215

Epoch: 5| Step: 8
Training loss: 3.0088789463043213
Validation loss: 2.5071125953428206

Epoch: 5| Step: 9
Training loss: 2.6356797218322754
Validation loss: 2.495092738059259

Epoch: 5| Step: 10
Training loss: 2.1676883697509766
Validation loss: 2.487361692613171

Epoch: 21| Step: 0
Training loss: 2.896601438522339
Validation loss: 2.489405491018808

Epoch: 5| Step: 1
Training loss: 2.976036548614502
Validation loss: 2.4981565706191526

Epoch: 5| Step: 2
Training loss: 2.6511104106903076
Validation loss: 2.4987474013400335

Epoch: 5| Step: 3
Training loss: 2.521131992340088
Validation loss: 2.490327009590723

Epoch: 5| Step: 4
Training loss: 3.4840023517608643
Validation loss: 2.4861648877461753

Epoch: 5| Step: 5
Training loss: 2.1476035118103027
Validation loss: 2.482509723273657

Epoch: 5| Step: 6
Training loss: 2.5018932819366455
Validation loss: 2.4840725775687926

Epoch: 5| Step: 7
Training loss: 2.821652889251709
Validation loss: 2.4879704931730866

Epoch: 5| Step: 8
Training loss: 2.713575601577759
Validation loss: 2.4893727635824554

Epoch: 5| Step: 9
Training loss: 2.5089924335479736
Validation loss: 2.487581863198229

Epoch: 5| Step: 10
Training loss: 2.606419324874878
Validation loss: 2.4921894740032893

Epoch: 22| Step: 0
Training loss: 3.0418896675109863
Validation loss: 2.4880016208976827

Epoch: 5| Step: 1
Training loss: 2.84513783454895
Validation loss: 2.4877754513935377

Epoch: 5| Step: 2
Training loss: 3.011186122894287
Validation loss: 2.4897229338204987

Epoch: 5| Step: 3
Training loss: 3.1582701206207275
Validation loss: 2.483168799390075

Epoch: 5| Step: 4
Training loss: 2.8282666206359863
Validation loss: 2.4818984949460594

Epoch: 5| Step: 5
Training loss: 2.0166068077087402
Validation loss: 2.4810196584270847

Epoch: 5| Step: 6
Training loss: 2.8506264686584473
Validation loss: 2.479815601020731

Epoch: 5| Step: 7
Training loss: 2.394860029220581
Validation loss: 2.4776979056737756

Epoch: 5| Step: 8
Training loss: 2.8949294090270996
Validation loss: 2.477378886233094

Epoch: 5| Step: 9
Training loss: 2.5172464847564697
Validation loss: 2.467139397898028

Epoch: 5| Step: 10
Training loss: 1.952642798423767
Validation loss: 2.4657312157333537

Epoch: 23| Step: 0
Training loss: 2.567155361175537
Validation loss: 2.470844166253203

Epoch: 5| Step: 1
Training loss: 2.9882118701934814
Validation loss: 2.4889156638935046

Epoch: 5| Step: 2
Training loss: 2.5249741077423096
Validation loss: 2.483303731487643

Epoch: 5| Step: 3
Training loss: 2.720424175262451
Validation loss: 2.466007632593955

Epoch: 5| Step: 4
Training loss: 2.556497812271118
Validation loss: 2.4583139009373163

Epoch: 5| Step: 5
Training loss: 2.9321751594543457
Validation loss: 2.4523908297220864

Epoch: 5| Step: 6
Training loss: 3.007153272628784
Validation loss: 2.451602076971403

Epoch: 5| Step: 7
Training loss: 2.7937071323394775
Validation loss: 2.482177457501811

Epoch: 5| Step: 8
Training loss: 2.015598773956299
Validation loss: 2.513135535742647

Epoch: 5| Step: 9
Training loss: 2.4514782428741455
Validation loss: 2.5067208402900287

Epoch: 5| Step: 10
Training loss: 3.16436505317688
Validation loss: 2.523994222764046

Epoch: 24| Step: 0
Training loss: 3.0387721061706543
Validation loss: 2.5235242792355117

Epoch: 5| Step: 1
Training loss: 3.4836032390594482
Validation loss: 2.5074924166484545

Epoch: 5| Step: 2
Training loss: 2.485461473464966
Validation loss: 2.4719703582025345

Epoch: 5| Step: 3
Training loss: 2.3743762969970703
Validation loss: 2.4467667943687847

Epoch: 5| Step: 4
Training loss: 2.7567951679229736
Validation loss: 2.441401917447326

Epoch: 5| Step: 5
Training loss: 2.963862657546997
Validation loss: 2.444347091900405

Epoch: 5| Step: 6
Training loss: 2.568042755126953
Validation loss: 2.4485463660250426

Epoch: 5| Step: 7
Training loss: 2.755403757095337
Validation loss: 2.450412529771046

Epoch: 5| Step: 8
Training loss: 2.731626510620117
Validation loss: 2.4519093908289427

Epoch: 5| Step: 9
Training loss: 2.397517442703247
Validation loss: 2.451775784133583

Epoch: 5| Step: 10
Training loss: 1.8961262702941895
Validation loss: 2.4520026586389028

Epoch: 25| Step: 0
Training loss: 2.61204195022583
Validation loss: 2.448400330799882

Epoch: 5| Step: 1
Training loss: 2.52309250831604
Validation loss: 2.4438926660886375

Epoch: 5| Step: 2
Training loss: 3.1189446449279785
Validation loss: 2.4401100630401285

Epoch: 5| Step: 3
Training loss: 2.490272283554077
Validation loss: 2.4370531907645603

Epoch: 5| Step: 4
Training loss: 2.332787275314331
Validation loss: 2.439448833465576

Epoch: 5| Step: 5
Training loss: 2.710315227508545
Validation loss: 2.4404751741757957

Epoch: 5| Step: 6
Training loss: 2.857205629348755
Validation loss: 2.4418735170877106

Epoch: 5| Step: 7
Training loss: 2.8084604740142822
Validation loss: 2.4371650706055346

Epoch: 5| Step: 8
Training loss: 2.913182497024536
Validation loss: 2.429562448173441

Epoch: 5| Step: 9
Training loss: 2.716909885406494
Validation loss: 2.427024761835734

Epoch: 5| Step: 10
Training loss: 2.331787347793579
Validation loss: 2.428111445519232

Epoch: 26| Step: 0
Training loss: 3.1346993446350098
Validation loss: 2.4277180753728396

Epoch: 5| Step: 1
Training loss: 1.9630870819091797
Validation loss: 2.427540950877692

Epoch: 5| Step: 2
Training loss: 2.3603122234344482
Validation loss: 2.425472920940768

Epoch: 5| Step: 3
Training loss: 2.754429578781128
Validation loss: 2.427788319126252

Epoch: 5| Step: 4
Training loss: 2.749547243118286
Validation loss: 2.4275447553203953

Epoch: 5| Step: 5
Training loss: 2.902132511138916
Validation loss: 2.4259131570016184

Epoch: 5| Step: 6
Training loss: 2.4003894329071045
Validation loss: 2.4299360065050024

Epoch: 5| Step: 7
Training loss: 2.8572564125061035
Validation loss: 2.438542071209159

Epoch: 5| Step: 8
Training loss: 2.338111400604248
Validation loss: 2.452389032610001

Epoch: 5| Step: 9
Training loss: 3.0318846702575684
Validation loss: 2.4739863077799478

Epoch: 5| Step: 10
Training loss: 2.9602935314178467
Validation loss: 2.4714982073794127

Epoch: 27| Step: 0
Training loss: 3.261683225631714
Validation loss: 2.4682012988675024

Epoch: 5| Step: 1
Training loss: 2.580033540725708
Validation loss: 2.4556816111328783

Epoch: 5| Step: 2
Training loss: 2.509953737258911
Validation loss: 2.4486403542180217

Epoch: 5| Step: 3
Training loss: 2.657496213912964
Validation loss: 2.4420288993466284

Epoch: 5| Step: 4
Training loss: 2.5288023948669434
Validation loss: 2.434812209939444

Epoch: 5| Step: 5
Training loss: 2.7077980041503906
Validation loss: 2.4363118576747116

Epoch: 5| Step: 6
Training loss: 2.158021926879883
Validation loss: 2.4382355341347317

Epoch: 5| Step: 7
Training loss: 2.583303928375244
Validation loss: 2.44359851396212

Epoch: 5| Step: 8
Training loss: 2.7612252235412598
Validation loss: 2.4486412361104

Epoch: 5| Step: 9
Training loss: 2.502190113067627
Validation loss: 2.4573219437753

Epoch: 5| Step: 10
Training loss: 3.1706676483154297
Validation loss: 2.487172688207319

Epoch: 28| Step: 0
Training loss: 2.0369579792022705
Validation loss: 2.469143165055142

Epoch: 5| Step: 1
Training loss: 2.20273756980896
Validation loss: 2.4935154479037047

Epoch: 5| Step: 2
Training loss: 2.1015191078186035
Validation loss: 2.493378826366958

Epoch: 5| Step: 3
Training loss: 2.853968381881714
Validation loss: 2.4470842192249913

Epoch: 5| Step: 4
Training loss: 2.9643781185150146
Validation loss: 2.419890965184858

Epoch: 5| Step: 5
Training loss: 2.5449984073638916
Validation loss: 2.4517934476175616

Epoch: 5| Step: 6
Training loss: 2.8838348388671875
Validation loss: 2.4794491311555267

Epoch: 5| Step: 7
Training loss: 2.6341207027435303
Validation loss: 2.5201039980816584

Epoch: 5| Step: 8
Training loss: 3.5386970043182373
Validation loss: 2.520878194480814

Epoch: 5| Step: 9
Training loss: 3.1974921226501465
Validation loss: 2.467948236773091

Epoch: 5| Step: 10
Training loss: 2.750606060028076
Validation loss: 2.4431354512450514

Epoch: 29| Step: 0
Training loss: 2.8152852058410645
Validation loss: 2.4396874238086004

Epoch: 5| Step: 1
Training loss: 2.5197691917419434
Validation loss: 2.415471887075773

Epoch: 5| Step: 2
Training loss: 2.491126537322998
Validation loss: 2.4352745086916032

Epoch: 5| Step: 3
Training loss: 1.811036467552185
Validation loss: 2.445161614366757

Epoch: 5| Step: 4
Training loss: 2.668433666229248
Validation loss: 2.443530515957904

Epoch: 5| Step: 5
Training loss: 3.253589630126953
Validation loss: 2.4403524091166835

Epoch: 5| Step: 6
Training loss: 3.341723918914795
Validation loss: 2.4386796746202695

Epoch: 5| Step: 7
Training loss: 2.8791067600250244
Validation loss: 2.4295714311702277

Epoch: 5| Step: 8
Training loss: 2.2545604705810547
Validation loss: 2.4322730495083715

Epoch: 5| Step: 9
Training loss: 2.6271474361419678
Validation loss: 2.4379310607910156

Epoch: 5| Step: 10
Training loss: 2.5650835037231445
Validation loss: 2.4288955144984747

Epoch: 30| Step: 0
Training loss: 2.733973979949951
Validation loss: 2.4339160329552105

Epoch: 5| Step: 1
Training loss: 1.914698600769043
Validation loss: 2.4185950499708935

Epoch: 5| Step: 2
Training loss: 2.469475269317627
Validation loss: 2.413354450656522

Epoch: 5| Step: 3
Training loss: 2.9539828300476074
Validation loss: 2.4126075096027826

Epoch: 5| Step: 4
Training loss: 2.3807036876678467
Validation loss: 2.4059205798692602

Epoch: 5| Step: 5
Training loss: 3.0657222270965576
Validation loss: 2.433895262338782

Epoch: 5| Step: 6
Training loss: 2.1447298526763916
Validation loss: 2.428912144835277

Epoch: 5| Step: 7
Training loss: 2.794250011444092
Validation loss: 2.420980591927805

Epoch: 5| Step: 8
Training loss: 3.1786835193634033
Validation loss: 2.399400338049858

Epoch: 5| Step: 9
Training loss: 2.4566855430603027
Validation loss: 2.396502817830732

Epoch: 5| Step: 10
Training loss: 3.2099688053131104
Validation loss: 2.3985050801307923

Epoch: 31| Step: 0
Training loss: 2.9010977745056152
Validation loss: 2.40402417285468

Epoch: 5| Step: 1
Training loss: 2.6492669582366943
Validation loss: 2.409149856977565

Epoch: 5| Step: 2
Training loss: 2.633479118347168
Validation loss: 2.4235065291004796

Epoch: 5| Step: 3
Training loss: 2.590181589126587
Validation loss: 2.4138512867753223

Epoch: 5| Step: 4
Training loss: 2.7677810192108154
Validation loss: 2.4155997768525155

Epoch: 5| Step: 5
Training loss: 2.7900073528289795
Validation loss: 2.406113624572754

Epoch: 5| Step: 6
Training loss: 2.317207098007202
Validation loss: 2.41470588919937

Epoch: 5| Step: 7
Training loss: 2.285914659500122
Validation loss: 2.4084137767873783

Epoch: 5| Step: 8
Training loss: 2.945133924484253
Validation loss: 2.4102885210385887

Epoch: 5| Step: 9
Training loss: 2.747089385986328
Validation loss: 2.4034936607524915

Epoch: 5| Step: 10
Training loss: 2.4148197174072266
Validation loss: 2.3969259800449496

Epoch: 32| Step: 0
Training loss: 2.5557804107666016
Validation loss: 2.3914390533201155

Epoch: 5| Step: 1
Training loss: 3.240130662918091
Validation loss: 2.388243873914083

Epoch: 5| Step: 2
Training loss: 3.1885459423065186
Validation loss: 2.3897683287179596

Epoch: 5| Step: 3
Training loss: 2.6373634338378906
Validation loss: 2.3837284298353296

Epoch: 5| Step: 4
Training loss: 2.502534866333008
Validation loss: 2.3836991889502412

Epoch: 5| Step: 5
Training loss: 2.424647808074951
Validation loss: 2.3878238560051046

Epoch: 5| Step: 6
Training loss: 2.3451645374298096
Validation loss: 2.385035794268372

Epoch: 5| Step: 7
Training loss: 2.000333309173584
Validation loss: 2.382349398828322

Epoch: 5| Step: 8
Training loss: 2.636395215988159
Validation loss: 2.3836348902794624

Epoch: 5| Step: 9
Training loss: 2.9709582328796387
Validation loss: 2.3869852096803728

Epoch: 5| Step: 10
Training loss: 2.5149993896484375
Validation loss: 2.383631876719895

Epoch: 33| Step: 0
Training loss: 2.78407883644104
Validation loss: 2.390460519380467

Epoch: 5| Step: 1
Training loss: 2.5567996501922607
Validation loss: 2.405351028647474

Epoch: 5| Step: 2
Training loss: 2.9192614555358887
Validation loss: 2.411957940747661

Epoch: 5| Step: 3
Training loss: 2.3321690559387207
Validation loss: 2.40995277384276

Epoch: 5| Step: 4
Training loss: 2.5521655082702637
Validation loss: 2.4054692919536302

Epoch: 5| Step: 5
Training loss: 2.481666088104248
Validation loss: 2.393197057067707

Epoch: 5| Step: 6
Training loss: 2.7633821964263916
Validation loss: 2.389848127160021

Epoch: 5| Step: 7
Training loss: 2.5874385833740234
Validation loss: 2.3839934769497124

Epoch: 5| Step: 8
Training loss: 1.8866859674453735
Validation loss: 2.38459599402643

Epoch: 5| Step: 9
Training loss: 3.5640883445739746
Validation loss: 2.3853727335570962

Epoch: 5| Step: 10
Training loss: 2.550865411758423
Validation loss: 2.378807501126361

Epoch: 34| Step: 0
Training loss: 2.3842105865478516
Validation loss: 2.389313787542364

Epoch: 5| Step: 1
Training loss: 2.771040439605713
Validation loss: 2.4050018018291843

Epoch: 5| Step: 2
Training loss: 3.590747833251953
Validation loss: 2.418298316258256

Epoch: 5| Step: 3
Training loss: 2.6298305988311768
Validation loss: 2.413622353666572

Epoch: 5| Step: 4
Training loss: 2.2580807209014893
Validation loss: 2.4014344599939164

Epoch: 5| Step: 5
Training loss: 2.670711040496826
Validation loss: 2.384158319042575

Epoch: 5| Step: 6
Training loss: 2.5212626457214355
Validation loss: 2.363877647666521

Epoch: 5| Step: 7
Training loss: 2.400897264480591
Validation loss: 2.357655530334801

Epoch: 5| Step: 8
Training loss: 2.3130578994750977
Validation loss: 2.3568125591483167

Epoch: 5| Step: 9
Training loss: 2.581291437149048
Validation loss: 2.3581795589898222

Epoch: 5| Step: 10
Training loss: 2.929227590560913
Validation loss: 2.3560403957161853

Epoch: 35| Step: 0
Training loss: 3.8561348915100098
Validation loss: 2.352011062765634

Epoch: 5| Step: 1
Training loss: 1.8390264511108398
Validation loss: 2.3485351865009596

Epoch: 5| Step: 2
Training loss: 2.87492299079895
Validation loss: 2.3552484614874727

Epoch: 5| Step: 3
Training loss: 2.4401962757110596
Validation loss: 2.3648390129048336

Epoch: 5| Step: 4
Training loss: 2.4774298667907715
Validation loss: 2.3779504760619132

Epoch: 5| Step: 5
Training loss: 2.7989015579223633
Validation loss: 2.3868126446200955

Epoch: 5| Step: 6
Training loss: 2.554701328277588
Validation loss: 2.3974964900683333

Epoch: 5| Step: 7
Training loss: 2.624246120452881
Validation loss: 2.3915472511322267

Epoch: 5| Step: 8
Training loss: 2.693629741668701
Validation loss: 2.3770031006105485

Epoch: 5| Step: 9
Training loss: 2.250664234161377
Validation loss: 2.3652454960730767

Epoch: 5| Step: 10
Training loss: 2.4007043838500977
Validation loss: 2.355834509736748

Epoch: 36| Step: 0
Training loss: 2.1079697608947754
Validation loss: 2.3549331183074624

Epoch: 5| Step: 1
Training loss: 2.8268895149230957
Validation loss: 2.348480363045969

Epoch: 5| Step: 2
Training loss: 1.8901431560516357
Validation loss: 2.345478973081035

Epoch: 5| Step: 3
Training loss: 2.8391194343566895
Validation loss: 2.3435186724508963

Epoch: 5| Step: 4
Training loss: 3.2295379638671875
Validation loss: 2.3438366292625346

Epoch: 5| Step: 5
Training loss: 2.983415126800537
Validation loss: 2.34231315376938

Epoch: 5| Step: 6
Training loss: 2.866527557373047
Validation loss: 2.342491139647781

Epoch: 5| Step: 7
Training loss: 2.953103542327881
Validation loss: 2.344133456548055

Epoch: 5| Step: 8
Training loss: 2.6257271766662598
Validation loss: 2.3509474877388246

Epoch: 5| Step: 9
Training loss: 2.0073864459991455
Validation loss: 2.3547554118658907

Epoch: 5| Step: 10
Training loss: 2.346219778060913
Validation loss: 2.3759947130756993

Epoch: 37| Step: 0
Training loss: 2.680926561355591
Validation loss: 2.4075818497647523

Epoch: 5| Step: 1
Training loss: 2.9916062355041504
Validation loss: 2.4386091642482306

Epoch: 5| Step: 2
Training loss: 2.41989803314209
Validation loss: 2.4775677419477895

Epoch: 5| Step: 3
Training loss: 1.9842684268951416
Validation loss: 2.4545996291663057

Epoch: 5| Step: 4
Training loss: 3.522876739501953
Validation loss: 2.4059365205867316

Epoch: 5| Step: 5
Training loss: 2.1349265575408936
Validation loss: 2.359853934216243

Epoch: 5| Step: 6
Training loss: 2.7249255180358887
Validation loss: 2.3309078985644924

Epoch: 5| Step: 7
Training loss: 2.873504161834717
Validation loss: 2.3294443930349042

Epoch: 5| Step: 8
Training loss: 2.8940353393554688
Validation loss: 2.3351548076957784

Epoch: 5| Step: 9
Training loss: 2.1795780658721924
Validation loss: 2.334937172551309

Epoch: 5| Step: 10
Training loss: 2.6080596446990967
Validation loss: 2.3328433959714827

Epoch: 38| Step: 0
Training loss: 2.1268177032470703
Validation loss: 2.332815980398527

Epoch: 5| Step: 1
Training loss: 3.2494969367980957
Validation loss: 2.3277795442970852

Epoch: 5| Step: 2
Training loss: 2.8077969551086426
Validation loss: 2.324802432008969

Epoch: 5| Step: 3
Training loss: 2.167593479156494
Validation loss: 2.3276579764581498

Epoch: 5| Step: 4
Training loss: 2.2024340629577637
Validation loss: 2.335862317392903

Epoch: 5| Step: 5
Training loss: 2.5174593925476074
Validation loss: 2.352969302926012

Epoch: 5| Step: 6
Training loss: 2.52135968208313
Validation loss: 2.376583017328734

Epoch: 5| Step: 7
Training loss: 2.586775541305542
Validation loss: 2.415538998060329

Epoch: 5| Step: 8
Training loss: 3.035005569458008
Validation loss: 2.4411540595434045

Epoch: 5| Step: 9
Training loss: 2.426039218902588
Validation loss: 2.4341944686828123

Epoch: 5| Step: 10
Training loss: 3.234527349472046
Validation loss: 2.4206053492843465

Epoch: 39| Step: 0
Training loss: 2.5703675746917725
Validation loss: 2.3687396357136388

Epoch: 5| Step: 1
Training loss: 3.0736942291259766
Validation loss: 2.3477878698738675

Epoch: 5| Step: 2
Training loss: 3.0507583618164062
Validation loss: 2.334931832487865

Epoch: 5| Step: 3
Training loss: 2.9096853733062744
Validation loss: 2.325720730648246

Epoch: 5| Step: 4
Training loss: 2.1778266429901123
Validation loss: 2.319345138406241

Epoch: 5| Step: 5
Training loss: 2.593899726867676
Validation loss: 2.323746617122363

Epoch: 5| Step: 6
Training loss: 2.751155376434326
Validation loss: 2.3199974388204594

Epoch: 5| Step: 7
Training loss: 2.6570804119110107
Validation loss: 2.322235761150237

Epoch: 5| Step: 8
Training loss: 1.8159987926483154
Validation loss: 2.320020793586649

Epoch: 5| Step: 9
Training loss: 2.604125499725342
Validation loss: 2.3225804836519304

Epoch: 5| Step: 10
Training loss: 2.3663041591644287
Validation loss: 2.3256403553870415

Epoch: 40| Step: 0
Training loss: 2.7796432971954346
Validation loss: 2.3322860399881997

Epoch: 5| Step: 1
Training loss: 2.3591105937957764
Validation loss: 2.3453658973017046

Epoch: 5| Step: 2
Training loss: 2.56042742729187
Validation loss: 2.35566415966198

Epoch: 5| Step: 3
Training loss: 2.441357135772705
Validation loss: 2.338170031065582

Epoch: 5| Step: 4
Training loss: 2.8277382850646973
Validation loss: 2.3631218505162064

Epoch: 5| Step: 5
Training loss: 2.2601640224456787
Validation loss: 2.337351824647637

Epoch: 5| Step: 6
Training loss: 3.1063623428344727
Validation loss: 2.3286919363083376

Epoch: 5| Step: 7
Training loss: 2.8885245323181152
Validation loss: 2.3291795894663823

Epoch: 5| Step: 8
Training loss: 2.6490864753723145
Validation loss: 2.3386861995984147

Epoch: 5| Step: 9
Training loss: 2.828564405441284
Validation loss: 2.3519669963467504

Epoch: 5| Step: 10
Training loss: 1.7708545923233032
Validation loss: 2.35307506592043

Epoch: 41| Step: 0
Training loss: 2.9335129261016846
Validation loss: 2.3611422392629806

Epoch: 5| Step: 1
Training loss: 2.7135214805603027
Validation loss: 2.3489388291553785

Epoch: 5| Step: 2
Training loss: 2.5423171520233154
Validation loss: 2.341173618070541

Epoch: 5| Step: 3
Training loss: 2.6126344203948975
Validation loss: 2.332772611289896

Epoch: 5| Step: 4
Training loss: 2.391759157180786
Validation loss: 2.337511998350902

Epoch: 5| Step: 5
Training loss: 2.141779899597168
Validation loss: 2.3344517446333364

Epoch: 5| Step: 6
Training loss: 2.813586473464966
Validation loss: 2.344681796207223

Epoch: 5| Step: 7
Training loss: 2.7275547981262207
Validation loss: 2.35037293998144

Epoch: 5| Step: 8
Training loss: 2.2602102756500244
Validation loss: 2.3433411018822783

Epoch: 5| Step: 9
Training loss: 2.6649458408355713
Validation loss: 2.326902989418276

Epoch: 5| Step: 10
Training loss: 2.827885627746582
Validation loss: 2.317743568010228

Epoch: 42| Step: 0
Training loss: 2.757143497467041
Validation loss: 2.3165956056246193

Epoch: 5| Step: 1
Training loss: 2.6545300483703613
Validation loss: 2.309827544355905

Epoch: 5| Step: 2
Training loss: 2.4412951469421387
Validation loss: 2.310148387826899

Epoch: 5| Step: 3
Training loss: 2.4980874061584473
Validation loss: 2.3129110233758086

Epoch: 5| Step: 4
Training loss: 2.3887572288513184
Validation loss: 2.3175396227067515

Epoch: 5| Step: 5
Training loss: 2.677949905395508
Validation loss: 2.319714933313349

Epoch: 5| Step: 6
Training loss: 2.347292184829712
Validation loss: 2.3224322334412606

Epoch: 5| Step: 7
Training loss: 2.6069564819335938
Validation loss: 2.314020336315196

Epoch: 5| Step: 8
Training loss: 2.5211424827575684
Validation loss: 2.311458110809326

Epoch: 5| Step: 9
Training loss: 3.1755576133728027
Validation loss: 2.311682149928103

Epoch: 5| Step: 10
Training loss: 2.364069938659668
Validation loss: 2.3135715300037014

Epoch: 43| Step: 0
Training loss: 2.5245108604431152
Validation loss: 2.3133230363169024

Epoch: 5| Step: 1
Training loss: 2.572274923324585
Validation loss: 2.3144090662720385

Epoch: 5| Step: 2
Training loss: 2.5307040214538574
Validation loss: 2.307333566809213

Epoch: 5| Step: 3
Training loss: 2.7887375354766846
Validation loss: 2.304726642947043

Epoch: 5| Step: 4
Training loss: 2.8016295433044434
Validation loss: 2.3029809908200334

Epoch: 5| Step: 5
Training loss: 2.2293825149536133
Validation loss: 2.302438538561585

Epoch: 5| Step: 6
Training loss: 3.2215182781219482
Validation loss: 2.303559023846862

Epoch: 5| Step: 7
Training loss: 2.8671088218688965
Validation loss: 2.302695935772311

Epoch: 5| Step: 8
Training loss: 2.6842334270477295
Validation loss: 2.3070974119247927

Epoch: 5| Step: 9
Training loss: 1.757444977760315
Validation loss: 2.2952561199024157

Epoch: 5| Step: 10
Training loss: 2.3502769470214844
Validation loss: 2.2979227368549635

Epoch: 44| Step: 0
Training loss: 2.7363829612731934
Validation loss: 2.306945152180169

Epoch: 5| Step: 1
Training loss: 2.310704469680786
Validation loss: 2.3078032924282934

Epoch: 5| Step: 2
Training loss: 2.6145520210266113
Validation loss: 2.3062350519241823

Epoch: 5| Step: 3
Training loss: 2.232485055923462
Validation loss: 2.298294731365737

Epoch: 5| Step: 4
Training loss: 2.9620931148529053
Validation loss: 2.3176096639325543

Epoch: 5| Step: 5
Training loss: 2.6585440635681152
Validation loss: 2.3170947759382186

Epoch: 5| Step: 6
Training loss: 2.466787338256836
Validation loss: 2.3205872979215396

Epoch: 5| Step: 7
Training loss: 3.2460334300994873
Validation loss: 2.319502656177808

Epoch: 5| Step: 8
Training loss: 2.6470272541046143
Validation loss: 2.316551662260486

Epoch: 5| Step: 9
Training loss: 1.840754508972168
Validation loss: 2.3144488437201387

Epoch: 5| Step: 10
Training loss: 2.567209005355835
Validation loss: 2.3020298865533646

Epoch: 45| Step: 0
Training loss: 2.4669737815856934
Validation loss: 2.3100074183556343

Epoch: 5| Step: 1
Training loss: 2.884573459625244
Validation loss: 2.299604674821259

Epoch: 5| Step: 2
Training loss: 2.9274611473083496
Validation loss: 2.2939401980369323

Epoch: 5| Step: 3
Training loss: 1.9074687957763672
Validation loss: 2.295429419445735

Epoch: 5| Step: 4
Training loss: 2.1656360626220703
Validation loss: 2.2902482427576536

Epoch: 5| Step: 5
Training loss: 2.4751524925231934
Validation loss: 2.3003889322280884

Epoch: 5| Step: 6
Training loss: 2.34810471534729
Validation loss: 2.293619148192867

Epoch: 5| Step: 7
Training loss: 2.9426462650299072
Validation loss: 2.304627528754614

Epoch: 5| Step: 8
Training loss: 2.400171995162964
Validation loss: 2.311715531092818

Epoch: 5| Step: 9
Training loss: 2.8912479877471924
Validation loss: 2.3100799514401342

Epoch: 5| Step: 10
Training loss: 2.894287109375
Validation loss: 2.308964293490174

Epoch: 46| Step: 0
Training loss: 2.879530906677246
Validation loss: 2.2929522939907607

Epoch: 5| Step: 1
Training loss: 2.055830240249634
Validation loss: 2.2871756015285367

Epoch: 5| Step: 2
Training loss: 1.9700891971588135
Validation loss: 2.281894547964937

Epoch: 5| Step: 3
Training loss: 2.7202157974243164
Validation loss: 2.2790361399291665

Epoch: 5| Step: 4
Training loss: 2.531630039215088
Validation loss: 2.2765537564472487

Epoch: 5| Step: 5
Training loss: 2.8458449840545654
Validation loss: 2.2818114219173307

Epoch: 5| Step: 6
Training loss: 3.0133562088012695
Validation loss: 2.2819825859480005

Epoch: 5| Step: 7
Training loss: 3.3415839672088623
Validation loss: 2.292898908738167

Epoch: 5| Step: 8
Training loss: 1.8772236108779907
Validation loss: 2.305143674214681

Epoch: 5| Step: 9
Training loss: 2.1525402069091797
Validation loss: 2.3250618032229844

Epoch: 5| Step: 10
Training loss: 2.921175718307495
Validation loss: 2.3149944889929985

Epoch: 47| Step: 0
Training loss: 2.6704394817352295
Validation loss: 2.2877625470520346

Epoch: 5| Step: 1
Training loss: 2.8906359672546387
Validation loss: 2.2780679207976147

Epoch: 5| Step: 2
Training loss: 3.0231049060821533
Validation loss: 2.27308084887843

Epoch: 5| Step: 3
Training loss: 2.0956881046295166
Validation loss: 2.2737226563115276

Epoch: 5| Step: 4
Training loss: 2.117823839187622
Validation loss: 2.2728825615298365

Epoch: 5| Step: 5
Training loss: 2.1619925498962402
Validation loss: 2.268323988042852

Epoch: 5| Step: 6
Training loss: 2.827355146408081
Validation loss: 2.2734011142484603

Epoch: 5| Step: 7
Training loss: 2.8702385425567627
Validation loss: 2.2856000008121615

Epoch: 5| Step: 8
Training loss: 3.0355453491210938
Validation loss: 2.3004407498144333

Epoch: 5| Step: 9
Training loss: 2.187725067138672
Validation loss: 2.303514189617608

Epoch: 5| Step: 10
Training loss: 2.3716559410095215
Validation loss: 2.3043049894353396

Epoch: 48| Step: 0
Training loss: 2.665417432785034
Validation loss: 2.2996957891730854

Epoch: 5| Step: 1
Training loss: 2.945305109024048
Validation loss: 2.2790809344219904

Epoch: 5| Step: 2
Training loss: 2.352618455886841
Validation loss: 2.278092299738238

Epoch: 5| Step: 3
Training loss: 2.034991502761841
Validation loss: 2.2786072556690504

Epoch: 5| Step: 4
Training loss: 3.0073885917663574
Validation loss: 2.2879990864825506

Epoch: 5| Step: 5
Training loss: 1.8026460409164429
Validation loss: 2.310484395232252

Epoch: 5| Step: 6
Training loss: 3.154463291168213
Validation loss: 2.3650915879075245

Epoch: 5| Step: 7
Training loss: 2.9002833366394043
Validation loss: 2.358746305588753

Epoch: 5| Step: 8
Training loss: 2.2114779949188232
Validation loss: 2.3083793091517624

Epoch: 5| Step: 9
Training loss: 2.1342215538024902
Validation loss: 2.3003595772609917

Epoch: 5| Step: 10
Training loss: 2.987675666809082
Validation loss: 2.2899551673602034

Epoch: 49| Step: 0
Training loss: 2.522090196609497
Validation loss: 2.276165508454846

Epoch: 5| Step: 1
Training loss: 2.8323376178741455
Validation loss: 2.2665390327412593

Epoch: 5| Step: 2
Training loss: 2.5300920009613037
Validation loss: 2.259382870889479

Epoch: 5| Step: 3
Training loss: 2.578634738922119
Validation loss: 2.257979649369435

Epoch: 5| Step: 4
Training loss: 1.9360179901123047
Validation loss: 2.259235638444142

Epoch: 5| Step: 5
Training loss: 2.5888049602508545
Validation loss: 2.2576333809924383

Epoch: 5| Step: 6
Training loss: 2.9054930210113525
Validation loss: 2.259131080360823

Epoch: 5| Step: 7
Training loss: 2.097578763961792
Validation loss: 2.2645870767613894

Epoch: 5| Step: 8
Training loss: 2.2574050426483154
Validation loss: 2.2869575356924408

Epoch: 5| Step: 9
Training loss: 3.0690464973449707
Validation loss: 2.281698275637883

Epoch: 5| Step: 10
Training loss: 2.934237003326416
Validation loss: 2.2828776656940417

Epoch: 50| Step: 0
Training loss: 2.6859688758850098
Validation loss: 2.2881443808155675

Epoch: 5| Step: 1
Training loss: 3.1222357749938965
Validation loss: 2.289128224054972

Epoch: 5| Step: 2
Training loss: 2.223339319229126
Validation loss: 2.288189987982473

Epoch: 5| Step: 3
Training loss: 2.535499334335327
Validation loss: 2.2867013049382034

Epoch: 5| Step: 4
Training loss: 2.396465301513672
Validation loss: 2.2722830169944355

Epoch: 5| Step: 5
Training loss: 2.888953447341919
Validation loss: 2.271744155114697

Epoch: 5| Step: 6
Training loss: 2.423964500427246
Validation loss: 2.278062937080219

Epoch: 5| Step: 7
Training loss: 2.151228189468384
Validation loss: 2.271748440240019

Epoch: 5| Step: 8
Training loss: 2.521091938018799
Validation loss: 2.2746449209028676

Epoch: 5| Step: 9
Training loss: 2.5474629402160645
Validation loss: 2.277642383370348

Epoch: 5| Step: 10
Training loss: 2.4686477184295654
Validation loss: 2.289195975949687

Epoch: 51| Step: 0
Training loss: 2.557648181915283
Validation loss: 2.2924225381625596

Epoch: 5| Step: 1
Training loss: 2.9998044967651367
Validation loss: 2.30276749467337

Epoch: 5| Step: 2
Training loss: 2.8694679737091064
Validation loss: 2.2782498636553363

Epoch: 5| Step: 3
Training loss: 2.480151414871216
Validation loss: 2.258840319930866

Epoch: 5| Step: 4
Training loss: 2.570880889892578
Validation loss: 2.2493251728755173

Epoch: 5| Step: 5
Training loss: 2.2600221633911133
Validation loss: 2.244296130313668

Epoch: 5| Step: 6
Training loss: 3.2786736488342285
Validation loss: 2.24371087679299

Epoch: 5| Step: 7
Training loss: 2.541869640350342
Validation loss: 2.2499743225753948

Epoch: 5| Step: 8
Training loss: 2.3387274742126465
Validation loss: 2.2427670289111394

Epoch: 5| Step: 9
Training loss: 2.352573871612549
Validation loss: 2.2452919983094737

Epoch: 5| Step: 10
Training loss: 1.799621820449829
Validation loss: 2.2460630529670307

Epoch: 52| Step: 0
Training loss: 2.4775843620300293
Validation loss: 2.2594868342081704

Epoch: 5| Step: 1
Training loss: 1.970067024230957
Validation loss: 2.2784319718678794

Epoch: 5| Step: 2
Training loss: 2.543519973754883
Validation loss: 2.341038660336566

Epoch: 5| Step: 3
Training loss: 2.403716564178467
Validation loss: 2.4420200599137174

Epoch: 5| Step: 4
Training loss: 2.535893678665161
Validation loss: 2.4091973894385883

Epoch: 5| Step: 5
Training loss: 2.6185810565948486
Validation loss: 2.345109380701537

Epoch: 5| Step: 6
Training loss: 3.2999000549316406
Validation loss: 2.273993102453088

Epoch: 5| Step: 7
Training loss: 2.3748230934143066
Validation loss: 2.2474115510140695

Epoch: 5| Step: 8
Training loss: 2.166067600250244
Validation loss: 2.238433552044694

Epoch: 5| Step: 9
Training loss: 2.399934768676758
Validation loss: 2.23983988582447

Epoch: 5| Step: 10
Training loss: 3.6771531105041504
Validation loss: 2.2516280925402077

Epoch: 53| Step: 0
Training loss: 3.2727859020233154
Validation loss: 2.2532320458401918

Epoch: 5| Step: 1
Training loss: 2.334510087966919
Validation loss: 2.258070807303152

Epoch: 5| Step: 2
Training loss: 3.121591091156006
Validation loss: 2.277903610660184

Epoch: 5| Step: 3
Training loss: 3.1728034019470215
Validation loss: 2.2630389018725325

Epoch: 5| Step: 4
Training loss: 1.963931679725647
Validation loss: 2.247889203409995

Epoch: 5| Step: 5
Training loss: 2.3930859565734863
Validation loss: 2.239857604426722

Epoch: 5| Step: 6
Training loss: 2.159947395324707
Validation loss: 2.2453178359616186

Epoch: 5| Step: 7
Training loss: 2.0701968669891357
Validation loss: 2.258658928255881

Epoch: 5| Step: 8
Training loss: 2.6996378898620605
Validation loss: 2.291578021100772

Epoch: 5| Step: 9
Training loss: 2.9429662227630615
Validation loss: 2.321002128303692

Epoch: 5| Step: 10
Training loss: 1.892046570777893
Validation loss: 2.333556628996326

Epoch: 54| Step: 0
Training loss: 2.0995049476623535
Validation loss: 2.324503396147041

Epoch: 5| Step: 1
Training loss: 2.4944686889648438
Validation loss: 2.2985333781088553

Epoch: 5| Step: 2
Training loss: 2.457834243774414
Validation loss: 2.2590707220057005

Epoch: 5| Step: 3
Training loss: 2.197632312774658
Validation loss: 2.236404904755213

Epoch: 5| Step: 4
Training loss: 3.3450980186462402
Validation loss: 2.22741017546705

Epoch: 5| Step: 5
Training loss: 2.4392499923706055
Validation loss: 2.2280367369292886

Epoch: 5| Step: 6
Training loss: 2.5527420043945312
Validation loss: 2.232405234408635

Epoch: 5| Step: 7
Training loss: 2.419201135635376
Validation loss: 2.2395743862275155

Epoch: 5| Step: 8
Training loss: 2.556413412094116
Validation loss: 2.2486604311132945

Epoch: 5| Step: 9
Training loss: 2.8664822578430176
Validation loss: 2.2587758212961178

Epoch: 5| Step: 10
Training loss: 2.713141679763794
Validation loss: 2.2596396451355307

Epoch: 55| Step: 0
Training loss: 2.0739986896514893
Validation loss: 2.270601835302127

Epoch: 5| Step: 1
Training loss: 2.3320469856262207
Validation loss: 2.2733630159849763

Epoch: 5| Step: 2
Training loss: 2.631706714630127
Validation loss: 2.270986562134117

Epoch: 5| Step: 3
Training loss: 2.6822376251220703
Validation loss: 2.2762432995662896

Epoch: 5| Step: 4
Training loss: 2.7244906425476074
Validation loss: 2.294252969885385

Epoch: 5| Step: 5
Training loss: 3.1864309310913086
Validation loss: 2.3100517744659097

Epoch: 5| Step: 6
Training loss: 3.0641090869903564
Validation loss: 2.3301938554292083

Epoch: 5| Step: 7
Training loss: 2.514411211013794
Validation loss: 2.331638352845305

Epoch: 5| Step: 8
Training loss: 2.433304786682129
Validation loss: 2.290472533113213

Epoch: 5| Step: 9
Training loss: 1.739246129989624
Validation loss: 2.264139293342508

Epoch: 5| Step: 10
Training loss: 2.520230531692505
Validation loss: 2.2475773698540142

Epoch: 56| Step: 0
Training loss: 2.5180914402008057
Validation loss: 2.234879970550537

Epoch: 5| Step: 1
Training loss: 2.714627742767334
Validation loss: 2.2306605385195826

Epoch: 5| Step: 2
Training loss: 2.3477988243103027
Validation loss: 2.2296523894033125

Epoch: 5| Step: 3
Training loss: 2.3477916717529297
Validation loss: 2.229009847487173

Epoch: 5| Step: 4
Training loss: 2.8604350090026855
Validation loss: 2.223788721587068

Epoch: 5| Step: 5
Training loss: 2.6737890243530273
Validation loss: 2.221214391851938

Epoch: 5| Step: 6
Training loss: 2.6861002445220947
Validation loss: 2.219009362241273

Epoch: 5| Step: 7
Training loss: 2.3940577507019043
Validation loss: 2.2186667034702916

Epoch: 5| Step: 8
Training loss: 2.81061053276062
Validation loss: 2.2315027226683912

Epoch: 5| Step: 9
Training loss: 2.222095251083374
Validation loss: 2.2534240266328216

Epoch: 5| Step: 10
Training loss: 2.2707676887512207
Validation loss: 2.2903086652037916

Epoch: 57| Step: 0
Training loss: 2.3121445178985596
Validation loss: 2.325578087119646

Epoch: 5| Step: 1
Training loss: 3.2217414379119873
Validation loss: 2.348151801734842

Epoch: 5| Step: 2
Training loss: 2.773249387741089
Validation loss: 2.345493321777672

Epoch: 5| Step: 3
Training loss: 2.426105260848999
Validation loss: 2.3106056362070064

Epoch: 5| Step: 4
Training loss: 2.0255444049835205
Validation loss: 2.2640829752850276

Epoch: 5| Step: 5
Training loss: 2.502507209777832
Validation loss: 2.2386483633390037

Epoch: 5| Step: 6
Training loss: 1.7713232040405273
Validation loss: 2.2217209928779194

Epoch: 5| Step: 7
Training loss: 2.4959683418273926
Validation loss: 2.2146645361377346

Epoch: 5| Step: 8
Training loss: 3.092912197113037
Validation loss: 2.2191578367704987

Epoch: 5| Step: 9
Training loss: 2.5073459148406982
Validation loss: 2.210546475584789

Epoch: 5| Step: 10
Training loss: 2.6754231452941895
Validation loss: 2.2089024615544144

Epoch: 58| Step: 0
Training loss: 2.2480063438415527
Validation loss: 2.2070148170635266

Epoch: 5| Step: 1
Training loss: 2.4497337341308594
Validation loss: 2.2073043290004937

Epoch: 5| Step: 2
Training loss: 2.803539514541626
Validation loss: 2.2107184651077434

Epoch: 5| Step: 3
Training loss: 1.9502172470092773
Validation loss: 2.222641137338454

Epoch: 5| Step: 4
Training loss: 2.9251222610473633
Validation loss: 2.2338986012243454

Epoch: 5| Step: 5
Training loss: 2.4605250358581543
Validation loss: 2.247520428831859

Epoch: 5| Step: 6
Training loss: 2.368631362915039
Validation loss: 2.267444408068093

Epoch: 5| Step: 7
Training loss: 1.975679636001587
Validation loss: 2.2691937902922272

Epoch: 5| Step: 8
Training loss: 3.3628182411193848
Validation loss: 2.2773132452400784

Epoch: 5| Step: 9
Training loss: 2.3140506744384766
Validation loss: 2.269613837683073

Epoch: 5| Step: 10
Training loss: 3.024118423461914
Validation loss: 2.2408003473794587

Epoch: 59| Step: 0
Training loss: 2.71781587600708
Validation loss: 2.2176806721636044

Epoch: 5| Step: 1
Training loss: 3.092684507369995
Validation loss: 2.2139308324424167

Epoch: 5| Step: 2
Training loss: 2.0133919715881348
Validation loss: 2.2004668840798

Epoch: 5| Step: 3
Training loss: 2.487013339996338
Validation loss: 2.2044245671200495

Epoch: 5| Step: 4
Training loss: 2.951930522918701
Validation loss: 2.200380024089608

Epoch: 5| Step: 5
Training loss: 2.4366750717163086
Validation loss: 2.2044452082726265

Epoch: 5| Step: 6
Training loss: 2.132966995239258
Validation loss: 2.213041244014617

Epoch: 5| Step: 7
Training loss: 2.633805751800537
Validation loss: 2.222934353736139

Epoch: 5| Step: 8
Training loss: 2.4604339599609375
Validation loss: 2.229258568056168

Epoch: 5| Step: 9
Training loss: 2.2844271659851074
Validation loss: 2.2377893565803446

Epoch: 5| Step: 10
Training loss: 2.360661506652832
Validation loss: 2.2279828850940993

Epoch: 60| Step: 0
Training loss: 2.5462539196014404
Validation loss: 2.2260985169359433

Epoch: 5| Step: 1
Training loss: 1.865017294883728
Validation loss: 2.233172042395479

Epoch: 5| Step: 2
Training loss: 2.6159987449645996
Validation loss: 2.2438211107766755

Epoch: 5| Step: 3
Training loss: 1.8681262731552124
Validation loss: 2.2385690366068194

Epoch: 5| Step: 4
Training loss: 2.5648562908172607
Validation loss: 2.21615997950236

Epoch: 5| Step: 5
Training loss: 2.4998879432678223
Validation loss: 2.2095999128075055

Epoch: 5| Step: 6
Training loss: 2.939404010772705
Validation loss: 2.1940936708963044

Epoch: 5| Step: 7
Training loss: 3.393451690673828
Validation loss: 2.1907465637371106

Epoch: 5| Step: 8
Training loss: 1.9083515405654907
Validation loss: 2.188845811351653

Epoch: 5| Step: 9
Training loss: 2.597275972366333
Validation loss: 2.1937066252513597

Epoch: 5| Step: 10
Training loss: 2.689274549484253
Validation loss: 2.1886158630412114

Epoch: 61| Step: 0
Training loss: 2.2535951137542725
Validation loss: 2.1938345047735397

Epoch: 5| Step: 1
Training loss: 2.575228214263916
Validation loss: 2.2011171361451507

Epoch: 5| Step: 2
Training loss: 2.533396005630493
Validation loss: 2.2161537165282876

Epoch: 5| Step: 3
Training loss: 2.621926784515381
Validation loss: 2.2339589313794206

Epoch: 5| Step: 4
Training loss: 2.8330702781677246
Validation loss: 2.2767863632530294

Epoch: 5| Step: 5
Training loss: 3.1606125831604004
Validation loss: 2.2812241046659407

Epoch: 5| Step: 6
Training loss: 1.8014854192733765
Validation loss: 2.280041494677144

Epoch: 5| Step: 7
Training loss: 2.4050612449645996
Validation loss: 2.226181758347378

Epoch: 5| Step: 8
Training loss: 2.071086883544922
Validation loss: 2.1956422918586322

Epoch: 5| Step: 9
Training loss: 2.5228993892669678
Validation loss: 2.1792028309196554

Epoch: 5| Step: 10
Training loss: 2.791602373123169
Validation loss: 2.17726658749324

Epoch: 62| Step: 0
Training loss: 2.427445888519287
Validation loss: 2.179964837207589

Epoch: 5| Step: 1
Training loss: 2.4775519371032715
Validation loss: 2.182394012328117

Epoch: 5| Step: 2
Training loss: 2.3606925010681152
Validation loss: 2.1770871736670054

Epoch: 5| Step: 3
Training loss: 2.5095009803771973
Validation loss: 2.180672809641848

Epoch: 5| Step: 4
Training loss: 2.709338665008545
Validation loss: 2.1744737727667696

Epoch: 5| Step: 5
Training loss: 3.287993907928467
Validation loss: 2.175773875687712

Epoch: 5| Step: 6
Training loss: 2.445662260055542
Validation loss: 2.174446851976456

Epoch: 5| Step: 7
Training loss: 2.107036828994751
Validation loss: 2.1749254657376196

Epoch: 5| Step: 8
Training loss: 2.7292673587799072
Validation loss: 2.18284950845985

Epoch: 5| Step: 9
Training loss: 2.019519805908203
Validation loss: 2.1900824423759215

Epoch: 5| Step: 10
Training loss: 2.4259226322174072
Validation loss: 2.2019253110372894

Epoch: 63| Step: 0
Training loss: 2.414522886276245
Validation loss: 2.2338340641349874

Epoch: 5| Step: 1
Training loss: 2.279447555541992
Validation loss: 2.247179910700808

Epoch: 5| Step: 2
Training loss: 2.4363577365875244
Validation loss: 2.258803485542215

Epoch: 5| Step: 3
Training loss: 2.711376905441284
Validation loss: 2.255424476438953

Epoch: 5| Step: 4
Training loss: 2.019512891769409
Validation loss: 2.2562771804871096

Epoch: 5| Step: 5
Training loss: 2.9557228088378906
Validation loss: 2.237146178881327

Epoch: 5| Step: 6
Training loss: 2.560849905014038
Validation loss: 2.2263609645187215

Epoch: 5| Step: 7
Training loss: 2.2857182025909424
Validation loss: 2.212256334161246

Epoch: 5| Step: 8
Training loss: 2.7488327026367188
Validation loss: 2.204315577783892

Epoch: 5| Step: 9
Training loss: 2.1655795574188232
Validation loss: 2.1923397177009174

Epoch: 5| Step: 10
Training loss: 2.710890293121338
Validation loss: 2.197895070557953

Epoch: 64| Step: 0
Training loss: 2.604473114013672
Validation loss: 2.2159706828414754

Epoch: 5| Step: 1
Training loss: 2.550793170928955
Validation loss: 2.2042366894342567

Epoch: 5| Step: 2
Training loss: 2.6061713695526123
Validation loss: 2.2001936768972747

Epoch: 5| Step: 3
Training loss: 2.2286410331726074
Validation loss: 2.1952691514004945

Epoch: 5| Step: 4
Training loss: 2.8404204845428467
Validation loss: 2.188686150376515

Epoch: 5| Step: 5
Training loss: 2.349722385406494
Validation loss: 2.1886197290112896

Epoch: 5| Step: 6
Training loss: 2.463240146636963
Validation loss: 2.185563902701101

Epoch: 5| Step: 7
Training loss: 2.1231656074523926
Validation loss: 2.1757111690377675

Epoch: 5| Step: 8
Training loss: 2.247335910797119
Validation loss: 2.168462135458505

Epoch: 5| Step: 9
Training loss: 2.800584316253662
Validation loss: 2.1669427117993756

Epoch: 5| Step: 10
Training loss: 2.2967934608459473
Validation loss: 2.168910798206124

Epoch: 65| Step: 0
Training loss: 3.0612428188323975
Validation loss: 2.173710546185893

Epoch: 5| Step: 1
Training loss: 1.8350324630737305
Validation loss: 2.17760605196799

Epoch: 5| Step: 2
Training loss: 2.246199607849121
Validation loss: 2.1987031070134972

Epoch: 5| Step: 3
Training loss: 2.258409261703491
Validation loss: 2.2060817826178765

Epoch: 5| Step: 4
Training loss: 2.7072112560272217
Validation loss: 2.2711357070553686

Epoch: 5| Step: 5
Training loss: 2.078526020050049
Validation loss: 2.3170520926034577

Epoch: 5| Step: 6
Training loss: 2.7970757484436035
Validation loss: 2.3586023981853197

Epoch: 5| Step: 7
Training loss: 2.7375359535217285
Validation loss: 2.2744560703154533

Epoch: 5| Step: 8
Training loss: 3.074376344680786
Validation loss: 2.2104864902393793

Epoch: 5| Step: 9
Training loss: 1.990180253982544
Validation loss: 2.1779495208494124

Epoch: 5| Step: 10
Training loss: 2.5743916034698486
Validation loss: 2.16117141836433

Epoch: 66| Step: 0
Training loss: 2.653608798980713
Validation loss: 2.168894749815746

Epoch: 5| Step: 1
Training loss: 2.520148515701294
Validation loss: 2.171368507928746

Epoch: 5| Step: 2
Training loss: 2.8520450592041016
Validation loss: 2.182408635334302

Epoch: 5| Step: 3
Training loss: 3.091712474822998
Validation loss: 2.183285249176846

Epoch: 5| Step: 4
Training loss: 2.3566222190856934
Validation loss: 2.1759391728267876

Epoch: 5| Step: 5
Training loss: 2.1907031536102295
Validation loss: 2.1680761127061743

Epoch: 5| Step: 6
Training loss: 3.1185498237609863
Validation loss: 2.1670749290015108

Epoch: 5| Step: 7
Training loss: 1.9981377124786377
Validation loss: 2.1647628250942437

Epoch: 5| Step: 8
Training loss: 2.6486470699310303
Validation loss: 2.168127308609665

Epoch: 5| Step: 9
Training loss: 2.136622190475464
Validation loss: 2.1604603695613083

Epoch: 5| Step: 10
Training loss: 2.1482155323028564
Validation loss: 2.175788658921437

Epoch: 67| Step: 0
Training loss: 2.7133076190948486
Validation loss: 2.1804926856871574

Epoch: 5| Step: 1
Training loss: 2.385849714279175
Validation loss: 2.1891943998234247

Epoch: 5| Step: 2
Training loss: 2.522277355194092
Validation loss: 2.20600058955531

Epoch: 5| Step: 3
Training loss: 2.5493876934051514
Validation loss: 2.212748617254278

Epoch: 5| Step: 4
Training loss: 3.2621192932128906
Validation loss: 2.2194440313564834

Epoch: 5| Step: 5
Training loss: 2.078796625137329
Validation loss: 2.244462446499896

Epoch: 5| Step: 6
Training loss: 2.825568675994873
Validation loss: 2.263295829937022

Epoch: 5| Step: 7
Training loss: 1.8667844533920288
Validation loss: 2.2642020897198747

Epoch: 5| Step: 8
Training loss: 2.9205775260925293
Validation loss: 2.2480331082497873

Epoch: 5| Step: 9
Training loss: 2.259087085723877
Validation loss: 2.2121882797569357

Epoch: 5| Step: 10
Training loss: 1.6922169923782349
Validation loss: 2.1971023967189174

Epoch: 68| Step: 0
Training loss: 2.8782424926757812
Validation loss: 2.1648793476884083

Epoch: 5| Step: 1
Training loss: 2.0942654609680176
Validation loss: 2.163611840176326

Epoch: 5| Step: 2
Training loss: 2.4622654914855957
Validation loss: 2.1676537298387095

Epoch: 5| Step: 3
Training loss: 2.4726548194885254
Validation loss: 2.171607748154671

Epoch: 5| Step: 4
Training loss: 2.8693346977233887
Validation loss: 2.1730018200412875

Epoch: 5| Step: 5
Training loss: 2.1789803504943848
Validation loss: 2.1753397577552387

Epoch: 5| Step: 6
Training loss: 2.5888917446136475
Validation loss: 2.1744223179355746

Epoch: 5| Step: 7
Training loss: 2.686924695968628
Validation loss: 2.1649496093873055

Epoch: 5| Step: 8
Training loss: 2.4568934440612793
Validation loss: 2.158187520119452

Epoch: 5| Step: 9
Training loss: 2.2119646072387695
Validation loss: 2.1544075473662345

Epoch: 5| Step: 10
Training loss: 2.432716131210327
Validation loss: 2.162190168134628

Epoch: 69| Step: 0
Training loss: 3.141554117202759
Validation loss: 2.1536293978332193

Epoch: 5| Step: 1
Training loss: 2.221587896347046
Validation loss: 2.1673425884657007

Epoch: 5| Step: 2
Training loss: 2.4495019912719727
Validation loss: 2.1761333160502936

Epoch: 5| Step: 3
Training loss: 2.8259541988372803
Validation loss: 2.1987204295332714

Epoch: 5| Step: 4
Training loss: 2.0228254795074463
Validation loss: 2.241272508457143

Epoch: 5| Step: 5
Training loss: 2.559954881668091
Validation loss: 2.2960215178869103

Epoch: 5| Step: 6
Training loss: 2.393216848373413
Validation loss: 2.2741445931055213

Epoch: 5| Step: 7
Training loss: 2.2066330909729004
Validation loss: 2.2540380352286884

Epoch: 5| Step: 8
Training loss: 2.1303391456604004
Validation loss: 2.217680841363886

Epoch: 5| Step: 9
Training loss: 2.8301520347595215
Validation loss: 2.1776541804754608

Epoch: 5| Step: 10
Training loss: 2.1951541900634766
Validation loss: 2.1604113412159744

Epoch: 70| Step: 0
Training loss: 3.132132053375244
Validation loss: 2.15285683960043

Epoch: 5| Step: 1
Training loss: 2.5206704139709473
Validation loss: 2.155214709620322

Epoch: 5| Step: 2
Training loss: 2.1503000259399414
Validation loss: 2.1482992582423712

Epoch: 5| Step: 3
Training loss: 2.542936325073242
Validation loss: 2.144506726213681

Epoch: 5| Step: 4
Training loss: 2.2857565879821777
Validation loss: 2.141029809110908

Epoch: 5| Step: 5
Training loss: 2.6856422424316406
Validation loss: 2.1411033189424904

Epoch: 5| Step: 6
Training loss: 2.51641845703125
Validation loss: 2.1426048406990628

Epoch: 5| Step: 7
Training loss: 1.9247770309448242
Validation loss: 2.1340768337249756

Epoch: 5| Step: 8
Training loss: 2.519151449203491
Validation loss: 2.1488942330883396

Epoch: 5| Step: 9
Training loss: 2.0972461700439453
Validation loss: 2.152000537482641

Epoch: 5| Step: 10
Training loss: 2.8301539421081543
Validation loss: 2.186776429094294

Epoch: 71| Step: 0
Training loss: 2.401043653488159
Validation loss: 2.2263157393342707

Epoch: 5| Step: 1
Training loss: 2.312100648880005
Validation loss: 2.2571069835334696

Epoch: 5| Step: 2
Training loss: 2.6948204040527344
Validation loss: 2.277948256461851

Epoch: 5| Step: 3
Training loss: 2.8297550678253174
Validation loss: 2.2425731817881265

Epoch: 5| Step: 4
Training loss: 2.2725577354431152
Validation loss: 2.1896933791457966

Epoch: 5| Step: 5
Training loss: 2.648574113845825
Validation loss: 2.1335221926371255

Epoch: 5| Step: 6
Training loss: 2.658432722091675
Validation loss: 2.135040110157382

Epoch: 5| Step: 7
Training loss: 1.9996683597564697
Validation loss: 2.141332059778193

Epoch: 5| Step: 8
Training loss: 2.5648467540740967
Validation loss: 2.144474808887769

Epoch: 5| Step: 9
Training loss: 2.599128007888794
Validation loss: 2.153729292654222

Epoch: 5| Step: 10
Training loss: 2.4135582447052
Validation loss: 2.163868304221861

Epoch: 72| Step: 0
Training loss: 2.5425446033477783
Validation loss: 2.1835065964729554

Epoch: 5| Step: 1
Training loss: 2.3968615531921387
Validation loss: 2.189197935083861

Epoch: 5| Step: 2
Training loss: 2.362356185913086
Validation loss: 2.1677416037487727

Epoch: 5| Step: 3
Training loss: 3.6120433807373047
Validation loss: 2.1742130992233113

Epoch: 5| Step: 4
Training loss: 1.7925666570663452
Validation loss: 2.1424943772695397

Epoch: 5| Step: 5
Training loss: 2.6733593940734863
Validation loss: 2.1467557671249553

Epoch: 5| Step: 6
Training loss: 1.9922767877578735
Validation loss: 2.138136266380228

Epoch: 5| Step: 7
Training loss: 3.249979019165039
Validation loss: 2.165674331367657

Epoch: 5| Step: 8
Training loss: 2.6044719219207764
Validation loss: 2.1995723606437765

Epoch: 5| Step: 9
Training loss: 2.033336639404297
Validation loss: 2.2235346942819576

Epoch: 5| Step: 10
Training loss: 2.0471436977386475
Validation loss: 2.209504449239341

Epoch: 73| Step: 0
Training loss: 2.7326369285583496
Validation loss: 2.180301140713435

Epoch: 5| Step: 1
Training loss: 2.50042986869812
Validation loss: 2.149400923841743

Epoch: 5| Step: 2
Training loss: 2.3318684101104736
Validation loss: 2.1358208041037283

Epoch: 5| Step: 3
Training loss: 2.1432461738586426
Validation loss: 2.1427980238391506

Epoch: 5| Step: 4
Training loss: 2.468623161315918
Validation loss: 2.142713059661209

Epoch: 5| Step: 5
Training loss: 2.3246893882751465
Validation loss: 2.1559664818548385

Epoch: 5| Step: 6
Training loss: 2.4862663745880127
Validation loss: 2.1781360205783638

Epoch: 5| Step: 7
Training loss: 2.692188024520874
Validation loss: 2.2235755125681558

Epoch: 5| Step: 8
Training loss: 2.316189765930176
Validation loss: 2.1787229814837055

Epoch: 5| Step: 9
Training loss: 2.755124807357788
Validation loss: 2.1371656233264553

Epoch: 5| Step: 10
Training loss: 2.286985158920288
Validation loss: 2.150654649221769

Epoch: 74| Step: 0
Training loss: 2.829362392425537
Validation loss: 2.194043045402855

Epoch: 5| Step: 1
Training loss: 2.330864667892456
Validation loss: 2.2332697940129105

Epoch: 5| Step: 2
Training loss: 2.683969020843506
Validation loss: 2.310051933411629

Epoch: 5| Step: 3
Training loss: 2.587125539779663
Validation loss: 2.3356126482768724

Epoch: 5| Step: 4
Training loss: 2.4275062084198
Validation loss: 2.289949442750664

Epoch: 5| Step: 5
Training loss: 2.5646567344665527
Validation loss: 2.2490688062483266

Epoch: 5| Step: 6
Training loss: 2.8006694316864014
Validation loss: 2.196750110195529

Epoch: 5| Step: 7
Training loss: 2.947028398513794
Validation loss: 2.164503892262777

Epoch: 5| Step: 8
Training loss: 1.6192783117294312
Validation loss: 2.1504894213009904

Epoch: 5| Step: 9
Training loss: 2.060551166534424
Validation loss: 2.141635764029718

Epoch: 5| Step: 10
Training loss: 2.461050271987915
Validation loss: 2.136992331474058

Epoch: 75| Step: 0
Training loss: 2.1771161556243896
Validation loss: 2.134448858999437

Epoch: 5| Step: 1
Training loss: 1.9303991794586182
Validation loss: 2.1315259036197456

Epoch: 5| Step: 2
Training loss: 2.4635376930236816
Validation loss: 2.1288381327864943

Epoch: 5| Step: 3
Training loss: 2.997282028198242
Validation loss: 2.1290601299655054

Epoch: 5| Step: 4
Training loss: 2.0899250507354736
Validation loss: 2.142880376949105

Epoch: 5| Step: 5
Training loss: 2.0592408180236816
Validation loss: 2.1444195983230427

Epoch: 5| Step: 6
Training loss: 2.9874956607818604
Validation loss: 2.1651284002488658

Epoch: 5| Step: 7
Training loss: 2.5510177612304688
Validation loss: 2.207260404863665

Epoch: 5| Step: 8
Training loss: 2.539926052093506
Validation loss: 2.2324877169824417

Epoch: 5| Step: 9
Training loss: 3.4569802284240723
Validation loss: 2.22981152226848

Epoch: 5| Step: 10
Training loss: 1.6395857334136963
Validation loss: 2.208844164366363

Epoch: 76| Step: 0
Training loss: 2.2821271419525146
Validation loss: 2.156210086678946

Epoch: 5| Step: 1
Training loss: 3.182861804962158
Validation loss: 2.133534464784848

Epoch: 5| Step: 2
Training loss: 2.432579517364502
Validation loss: 2.131022645581153

Epoch: 5| Step: 3
Training loss: 2.6459383964538574
Validation loss: 2.126509786933981

Epoch: 5| Step: 4
Training loss: 2.9083385467529297
Validation loss: 2.1281053353381414

Epoch: 5| Step: 5
Training loss: 1.838862657546997
Validation loss: 2.12920819815769

Epoch: 5| Step: 6
Training loss: 2.6234471797943115
Validation loss: 2.122376330437199

Epoch: 5| Step: 7
Training loss: 2.6983799934387207
Validation loss: 2.1243524089936288

Epoch: 5| Step: 8
Training loss: 1.9712499380111694
Validation loss: 2.1221240528168215

Epoch: 5| Step: 9
Training loss: 1.8741477727890015
Validation loss: 2.121534944862448

Epoch: 5| Step: 10
Training loss: 2.6848278045654297
Validation loss: 2.130666027786911

Epoch: 77| Step: 0
Training loss: 2.2737834453582764
Validation loss: 2.178982162988314

Epoch: 5| Step: 1
Training loss: 3.0258843898773193
Validation loss: 2.2135240544555006

Epoch: 5| Step: 2
Training loss: 2.912337064743042
Validation loss: 2.2145526947513705

Epoch: 5| Step: 3
Training loss: 2.1745176315307617
Validation loss: 2.184814550543344

Epoch: 5| Step: 4
Training loss: 1.987844705581665
Validation loss: 2.183808336975754

Epoch: 5| Step: 5
Training loss: 2.6144421100616455
Validation loss: 2.1615259532005555

Epoch: 5| Step: 6
Training loss: 2.167898416519165
Validation loss: 2.1524556324046147

Epoch: 5| Step: 7
Training loss: 2.779481887817383
Validation loss: 2.1469821417203514

Epoch: 5| Step: 8
Training loss: 2.2795982360839844
Validation loss: 2.139500835890411

Epoch: 5| Step: 9
Training loss: 2.0887229442596436
Validation loss: 2.1371498107910156

Epoch: 5| Step: 10
Training loss: 2.3881287574768066
Validation loss: 2.1320663075293265

Epoch: 78| Step: 0
Training loss: 2.4477651119232178
Validation loss: 2.1254833488054174

Epoch: 5| Step: 1
Training loss: 2.203881025314331
Validation loss: 2.1138533892170077

Epoch: 5| Step: 2
Training loss: 2.2517952919006348
Validation loss: 2.114029412628502

Epoch: 5| Step: 3
Training loss: 1.8295478820800781
Validation loss: 2.1320370397260113

Epoch: 5| Step: 4
Training loss: 2.2953927516937256
Validation loss: 2.1669005065835933

Epoch: 5| Step: 5
Training loss: 2.2161076068878174
Validation loss: 2.201836370652722

Epoch: 5| Step: 6
Training loss: 2.513333320617676
Validation loss: 2.2307517759261595

Epoch: 5| Step: 7
Training loss: 3.297948122024536
Validation loss: 2.2542697973148798

Epoch: 5| Step: 8
Training loss: 2.292921543121338
Validation loss: 2.240573203691872

Epoch: 5| Step: 9
Training loss: 2.6428418159484863
Validation loss: 2.2171782267990934

Epoch: 5| Step: 10
Training loss: 3.0134642124176025
Validation loss: 2.2184776234370407

Epoch: 79| Step: 0
Training loss: 2.3026533126831055
Validation loss: 2.1876406541434665

Epoch: 5| Step: 1
Training loss: 2.486011505126953
Validation loss: 2.1620165481362292

Epoch: 5| Step: 2
Training loss: 2.081756830215454
Validation loss: 2.1438378800628004

Epoch: 5| Step: 3
Training loss: 2.376088857650757
Validation loss: 2.1365647879979943

Epoch: 5| Step: 4
Training loss: 2.3841054439544678
Validation loss: 2.132667036466701

Epoch: 5| Step: 5
Training loss: 2.5096352100372314
Validation loss: 2.1231497410804994

Epoch: 5| Step: 6
Training loss: 2.7914814949035645
Validation loss: 2.1219174323543424

Epoch: 5| Step: 7
Training loss: 2.017753839492798
Validation loss: 2.132715863566245

Epoch: 5| Step: 8
Training loss: 2.1986770629882812
Validation loss: 2.159635273359155

Epoch: 5| Step: 9
Training loss: 2.47577166557312
Validation loss: 2.149414518828033

Epoch: 5| Step: 10
Training loss: 3.119049549102783
Validation loss: 2.1329405666679464

Epoch: 80| Step: 0
Training loss: 2.596252918243408
Validation loss: 2.1291830796067432

Epoch: 5| Step: 1
Training loss: 2.506943464279175
Validation loss: 2.130771220371287

Epoch: 5| Step: 2
Training loss: 1.535504698753357
Validation loss: 2.114396724649655

Epoch: 5| Step: 3
Training loss: 2.237032175064087
Validation loss: 2.1253156251804803

Epoch: 5| Step: 4
Training loss: 2.4593443870544434
Validation loss: 2.1398710268799976

Epoch: 5| Step: 5
Training loss: 2.2886695861816406
Validation loss: 2.1433854974726194

Epoch: 5| Step: 6
Training loss: 2.037022829055786
Validation loss: 2.161185068468894

Epoch: 5| Step: 7
Training loss: 2.3513705730438232
Validation loss: 2.16827199023257

Epoch: 5| Step: 8
Training loss: 2.450054407119751
Validation loss: 2.1387845546968522

Epoch: 5| Step: 9
Training loss: 3.1123690605163574
Validation loss: 2.1217511161681144

Epoch: 5| Step: 10
Training loss: 3.068621873855591
Validation loss: 2.1049548631073325

Epoch: 81| Step: 0
Training loss: 2.125816822052002
Validation loss: 2.089546495868314

Epoch: 5| Step: 1
Training loss: 2.3598835468292236
Validation loss: 2.0921968798483572

Epoch: 5| Step: 2
Training loss: 2.3437085151672363
Validation loss: 2.0888789289741108

Epoch: 5| Step: 3
Training loss: 2.681962251663208
Validation loss: 2.0946125702191423

Epoch: 5| Step: 4
Training loss: 2.640594005584717
Validation loss: 2.0866393337967577

Epoch: 5| Step: 5
Training loss: 2.94169282913208
Validation loss: 2.0902553245585453

Epoch: 5| Step: 6
Training loss: 1.7187389135360718
Validation loss: 2.098901823002805

Epoch: 5| Step: 7
Training loss: 2.708569288253784
Validation loss: 2.0926528976809595

Epoch: 5| Step: 8
Training loss: 1.8524024486541748
Validation loss: 2.104196809953259

Epoch: 5| Step: 9
Training loss: 2.4747164249420166
Validation loss: 2.10463273397056

Epoch: 5| Step: 10
Training loss: 2.3489065170288086
Validation loss: 2.124283839297551

Epoch: 82| Step: 0
Training loss: 1.825505256652832
Validation loss: 2.1290188938058834

Epoch: 5| Step: 1
Training loss: 3.2757937908172607
Validation loss: 2.1407185190467426

Epoch: 5| Step: 2
Training loss: 2.843165159225464
Validation loss: 2.131121071436072

Epoch: 5| Step: 3
Training loss: 2.081026792526245
Validation loss: 2.1222681973570134

Epoch: 5| Step: 4
Training loss: 2.2066190242767334
Validation loss: 2.105892604397189

Epoch: 5| Step: 5
Training loss: 2.4254112243652344
Validation loss: 2.0982271625149633

Epoch: 5| Step: 6
Training loss: 2.2830069065093994
Validation loss: 2.099724664483019

Epoch: 5| Step: 7
Training loss: 2.009518623352051
Validation loss: 2.1010991117005706

Epoch: 5| Step: 8
Training loss: 2.7973074913024902
Validation loss: 2.116271895747031

Epoch: 5| Step: 9
Training loss: 2.0914759635925293
Validation loss: 2.109592891508533

Epoch: 5| Step: 10
Training loss: 2.4728660583496094
Validation loss: 2.102868454430693

Epoch: 83| Step: 0
Training loss: 1.8368552923202515
Validation loss: 2.1041629545150267

Epoch: 5| Step: 1
Training loss: 3.0416414737701416
Validation loss: 2.119675987510271

Epoch: 5| Step: 2
Training loss: 2.5601232051849365
Validation loss: 2.1384878927661526

Epoch: 5| Step: 3
Training loss: 2.1635217666625977
Validation loss: 2.1488070462339666

Epoch: 5| Step: 4
Training loss: 2.8089942932128906
Validation loss: 2.1235795149239163

Epoch: 5| Step: 5
Training loss: 2.2827703952789307
Validation loss: 2.1333243180346746

Epoch: 5| Step: 6
Training loss: 2.3419032096862793
Validation loss: 2.164033870543203

Epoch: 5| Step: 7
Training loss: 2.8089160919189453
Validation loss: 2.1767527185460573

Epoch: 5| Step: 8
Training loss: 2.449793577194214
Validation loss: 2.1573192906636063

Epoch: 5| Step: 9
Training loss: 2.0586705207824707
Validation loss: 2.1243319357595136

Epoch: 5| Step: 10
Training loss: 2.063554525375366
Validation loss: 2.111237382376066

Epoch: 84| Step: 0
Training loss: 3.328235626220703
Validation loss: 2.099324914716905

Epoch: 5| Step: 1
Training loss: 2.8587756156921387
Validation loss: 2.091701220440608

Epoch: 5| Step: 2
Training loss: 2.398073196411133
Validation loss: 2.087491871208273

Epoch: 5| Step: 3
Training loss: 2.5315985679626465
Validation loss: 2.086047733983686

Epoch: 5| Step: 4
Training loss: 2.0300135612487793
Validation loss: 2.0845591970669326

Epoch: 5| Step: 5
Training loss: 2.6396279335021973
Validation loss: 2.0968831431481147

Epoch: 5| Step: 6
Training loss: 2.1960251331329346
Validation loss: 2.089817977720691

Epoch: 5| Step: 7
Training loss: 2.439204692840576
Validation loss: 2.096589134585473

Epoch: 5| Step: 8
Training loss: 2.182451009750366
Validation loss: 2.0990055363665343

Epoch: 5| Step: 9
Training loss: 1.8662731647491455
Validation loss: 2.094091889678791

Epoch: 5| Step: 10
Training loss: 1.4904115200042725
Validation loss: 2.0992504627473894

Epoch: 85| Step: 0
Training loss: 2.9407191276550293
Validation loss: 2.11421565599339

Epoch: 5| Step: 1
Training loss: 2.830974578857422
Validation loss: 2.1095237321751092

Epoch: 5| Step: 2
Training loss: 2.010806083679199
Validation loss: 2.1059562595941688

Epoch: 5| Step: 3
Training loss: 2.473684310913086
Validation loss: 2.1057486662300686

Epoch: 5| Step: 4
Training loss: 2.5802714824676514
Validation loss: 2.0943620948381323

Epoch: 5| Step: 5
Training loss: 2.4820456504821777
Validation loss: 2.0899782155149724

Epoch: 5| Step: 6
Training loss: 1.8981164693832397
Validation loss: 2.0894648580140966

Epoch: 5| Step: 7
Training loss: 2.065217971801758
Validation loss: 2.086281781555504

Epoch: 5| Step: 8
Training loss: 2.0988264083862305
Validation loss: 2.087610880533854

Epoch: 5| Step: 9
Training loss: 2.0453851222991943
Validation loss: 2.1022125444104596

Epoch: 5| Step: 10
Training loss: 2.5396201610565186
Validation loss: 2.1133807884749545

Epoch: 86| Step: 0
Training loss: 2.0463013648986816
Validation loss: 2.1255775574714906

Epoch: 5| Step: 1
Training loss: 1.835625410079956
Validation loss: 2.1201034412589124

Epoch: 5| Step: 2
Training loss: 2.3830533027648926
Validation loss: 2.122178336625458

Epoch: 5| Step: 3
Training loss: 2.665321111679077
Validation loss: 2.101542704848833

Epoch: 5| Step: 4
Training loss: 2.2637462615966797
Validation loss: 2.088426136201428

Epoch: 5| Step: 5
Training loss: 3.0093801021575928
Validation loss: 2.101946024484532

Epoch: 5| Step: 6
Training loss: 1.9934495687484741
Validation loss: 2.1084684018165833

Epoch: 5| Step: 7
Training loss: 2.1344523429870605
Validation loss: 2.138340947448566

Epoch: 5| Step: 8
Training loss: 2.3972551822662354
Validation loss: 2.1791756627380208

Epoch: 5| Step: 9
Training loss: 2.6306939125061035
Validation loss: 2.1955599874578495

Epoch: 5| Step: 10
Training loss: 2.623218297958374
Validation loss: 2.2505500572983936

Epoch: 87| Step: 0
Training loss: 2.200514554977417
Validation loss: 2.221094410906556

Epoch: 5| Step: 1
Training loss: 1.8360474109649658
Validation loss: 2.1635922975437616

Epoch: 5| Step: 2
Training loss: 2.956322193145752
Validation loss: 2.102037291372976

Epoch: 5| Step: 3
Training loss: 2.2778754234313965
Validation loss: 2.080085999222212

Epoch: 5| Step: 4
Training loss: 2.724256992340088
Validation loss: 2.0715254327302337

Epoch: 5| Step: 5
Training loss: 2.396646022796631
Validation loss: 2.077529784171812

Epoch: 5| Step: 6
Training loss: 2.273109197616577
Validation loss: 2.08044090706815

Epoch: 5| Step: 7
Training loss: 2.321824550628662
Validation loss: 2.0723819476301952

Epoch: 5| Step: 8
Training loss: 2.785184144973755
Validation loss: 2.072355480604274

Epoch: 5| Step: 9
Training loss: 1.9352630376815796
Validation loss: 2.0639707157688756

Epoch: 5| Step: 10
Training loss: 2.120969772338867
Validation loss: 2.065396879308967

Epoch: 88| Step: 0
Training loss: 2.6662099361419678
Validation loss: 2.090040337654852

Epoch: 5| Step: 1
Training loss: 1.9921882152557373
Validation loss: 2.134362191282293

Epoch: 5| Step: 2
Training loss: 2.0009896755218506
Validation loss: 2.1588995020876647

Epoch: 5| Step: 3
Training loss: 2.6994168758392334
Validation loss: 2.1989036208839825

Epoch: 5| Step: 4
Training loss: 2.8606224060058594
Validation loss: 2.2128099754292476

Epoch: 5| Step: 5
Training loss: 2.0664591789245605
Validation loss: 2.167595649278292

Epoch: 5| Step: 6
Training loss: 2.4442265033721924
Validation loss: 2.1495291917554793

Epoch: 5| Step: 7
Training loss: 2.4538445472717285
Validation loss: 2.1298802206593175

Epoch: 5| Step: 8
Training loss: 2.553722620010376
Validation loss: 2.1202884592035764

Epoch: 5| Step: 9
Training loss: 1.999261498451233
Validation loss: 2.119666281566825

Epoch: 5| Step: 10
Training loss: 2.274904251098633
Validation loss: 2.1264298782553723

Epoch: 89| Step: 0
Training loss: 2.4094347953796387
Validation loss: 2.144592482556579

Epoch: 5| Step: 1
Training loss: 1.8921092748641968
Validation loss: 2.153014657317951

Epoch: 5| Step: 2
Training loss: 2.9814369678497314
Validation loss: 2.125989052557176

Epoch: 5| Step: 3
Training loss: 1.8595138788223267
Validation loss: 2.1358205836306334

Epoch: 5| Step: 4
Training loss: 2.252980947494507
Validation loss: 2.1427678805525585

Epoch: 5| Step: 5
Training loss: 2.295975923538208
Validation loss: 2.1576059992595384

Epoch: 5| Step: 6
Training loss: 2.304718494415283
Validation loss: 2.164089556663267

Epoch: 5| Step: 7
Training loss: 2.5157289505004883
Validation loss: 2.167195307311191

Epoch: 5| Step: 8
Training loss: 2.6185412406921387
Validation loss: 2.142319613887418

Epoch: 5| Step: 9
Training loss: 2.374866008758545
Validation loss: 2.1098202966874644

Epoch: 5| Step: 10
Training loss: 2.6211841106414795
Validation loss: 2.079176346460978

Epoch: 90| Step: 0
Training loss: 2.318019151687622
Validation loss: 2.055468192664526

Epoch: 5| Step: 1
Training loss: 2.583188772201538
Validation loss: 2.037429699333765

Epoch: 5| Step: 2
Training loss: 2.2689027786254883
Validation loss: 2.0322500223754556

Epoch: 5| Step: 3
Training loss: 2.3929781913757324
Validation loss: 2.045999619268602

Epoch: 5| Step: 4
Training loss: 2.199272394180298
Validation loss: 2.0424300163022933

Epoch: 5| Step: 5
Training loss: 2.9967074394226074
Validation loss: 2.0549789013401156

Epoch: 5| Step: 6
Training loss: 2.477522134780884
Validation loss: 2.0552675326665244

Epoch: 5| Step: 7
Training loss: 1.854143500328064
Validation loss: 2.065948768328595

Epoch: 5| Step: 8
Training loss: 2.5355992317199707
Validation loss: 2.0789127734399613

Epoch: 5| Step: 9
Training loss: 2.21168851852417
Validation loss: 2.079440205327926

Epoch: 5| Step: 10
Training loss: 1.923277497291565
Validation loss: 2.0929272290199035

Epoch: 91| Step: 0
Training loss: 1.9128787517547607
Validation loss: 2.090878627633536

Epoch: 5| Step: 1
Training loss: 2.9525113105773926
Validation loss: 2.0830347743085635

Epoch: 5| Step: 2
Training loss: 1.9440600872039795
Validation loss: 2.0686026670599498

Epoch: 5| Step: 3
Training loss: 3.0110816955566406
Validation loss: 2.069466362717331

Epoch: 5| Step: 4
Training loss: 2.3335678577423096
Validation loss: 2.0596219890861103

Epoch: 5| Step: 5
Training loss: 1.5575578212738037
Validation loss: 2.074932236825266

Epoch: 5| Step: 6
Training loss: 2.5733189582824707
Validation loss: 2.0944024029598443

Epoch: 5| Step: 7
Training loss: 2.306323289871216
Validation loss: 2.095485797492407

Epoch: 5| Step: 8
Training loss: 2.8962628841400146
Validation loss: 2.082681732793008

Epoch: 5| Step: 9
Training loss: 2.2974164485931396
Validation loss: 2.1209683982274865

Epoch: 5| Step: 10
Training loss: 1.449574589729309
Validation loss: 2.1068027788592922

Epoch: 92| Step: 0
Training loss: 2.044454336166382
Validation loss: 2.1011741802256596

Epoch: 5| Step: 1
Training loss: 2.7543280124664307
Validation loss: 2.091871187251101

Epoch: 5| Step: 2
Training loss: 2.1273016929626465
Validation loss: 2.10100652581902

Epoch: 5| Step: 3
Training loss: 2.3122406005859375
Validation loss: 2.0801017771485033

Epoch: 5| Step: 4
Training loss: 2.5812625885009766
Validation loss: 2.0621455023365636

Epoch: 5| Step: 5
Training loss: 2.319044589996338
Validation loss: 2.0552442176367647

Epoch: 5| Step: 6
Training loss: 2.4916319847106934
Validation loss: 2.0539857828488914

Epoch: 5| Step: 7
Training loss: 2.514894723892212
Validation loss: 2.068439878443236

Epoch: 5| Step: 8
Training loss: 1.9771835803985596
Validation loss: 2.070416445373207

Epoch: 5| Step: 9
Training loss: 2.284191608428955
Validation loss: 2.090131404579327

Epoch: 5| Step: 10
Training loss: 1.6866509914398193
Validation loss: 2.1226313370530323

Epoch: 93| Step: 0
Training loss: 2.600252866744995
Validation loss: 2.143784130773237

Epoch: 5| Step: 1
Training loss: 2.3404674530029297
Validation loss: 2.1100514691363097

Epoch: 5| Step: 2
Training loss: 1.5485728979110718
Validation loss: 2.09379945775514

Epoch: 5| Step: 3
Training loss: 1.7625782489776611
Validation loss: 2.0679598815979494

Epoch: 5| Step: 4
Training loss: 2.2350821495056152
Validation loss: 2.0510624813777145

Epoch: 5| Step: 5
Training loss: 2.187276840209961
Validation loss: 2.052736092639226

Epoch: 5| Step: 6
Training loss: 2.112419605255127
Validation loss: 2.056116984736535

Epoch: 5| Step: 7
Training loss: 2.328108310699463
Validation loss: 2.058759504748929

Epoch: 5| Step: 8
Training loss: 2.666627883911133
Validation loss: 2.075354835038544

Epoch: 5| Step: 9
Training loss: 3.0958659648895264
Validation loss: 2.08421342859986

Epoch: 5| Step: 10
Training loss: 2.625603675842285
Validation loss: 2.093189715057291

Epoch: 94| Step: 0
Training loss: 3.077897310256958
Validation loss: 2.1240465512839695

Epoch: 5| Step: 1
Training loss: 2.1960113048553467
Validation loss: 2.1720699994794783

Epoch: 5| Step: 2
Training loss: 2.2822508811950684
Validation loss: 2.2312239626402497

Epoch: 5| Step: 3
Training loss: 2.2160511016845703
Validation loss: 2.33037894387399

Epoch: 5| Step: 4
Training loss: 2.137890577316284
Validation loss: 2.3462922188543502

Epoch: 5| Step: 5
Training loss: 2.3314049243927
Validation loss: 2.288311473784908

Epoch: 5| Step: 6
Training loss: 2.572953701019287
Validation loss: 2.251280964061778

Epoch: 5| Step: 7
Training loss: 2.1186258792877197
Validation loss: 2.1803534825642905

Epoch: 5| Step: 8
Training loss: 1.8533769845962524
Validation loss: 2.0911243115701983

Epoch: 5| Step: 9
Training loss: 2.1394155025482178
Validation loss: 2.0407894657504175

Epoch: 5| Step: 10
Training loss: 2.643592357635498
Validation loss: 2.028716489832888

Epoch: 95| Step: 0
Training loss: 2.4523041248321533
Validation loss: 2.0394972216698433

Epoch: 5| Step: 1
Training loss: 2.6360623836517334
Validation loss: 2.048935797906691

Epoch: 5| Step: 2
Training loss: 1.9618552923202515
Validation loss: 2.050643878598367

Epoch: 5| Step: 3
Training loss: 2.6214377880096436
Validation loss: 2.0479049400616716

Epoch: 5| Step: 4
Training loss: 2.6625123023986816
Validation loss: 2.033002540629397

Epoch: 5| Step: 5
Training loss: 2.161571741104126
Validation loss: 2.025159507669428

Epoch: 5| Step: 6
Training loss: 2.6903939247131348
Validation loss: 2.028999237604039

Epoch: 5| Step: 7
Training loss: 2.517693519592285
Validation loss: 2.0717653728300527

Epoch: 5| Step: 8
Training loss: 2.1793606281280518
Validation loss: 2.113771879544822

Epoch: 5| Step: 9
Training loss: 2.5509114265441895
Validation loss: 2.165016697299096

Epoch: 5| Step: 10
Training loss: 1.4721269607543945
Validation loss: 2.189970165170649

Epoch: 96| Step: 0
Training loss: 2.6064581871032715
Validation loss: 2.1862620051189134

Epoch: 5| Step: 1
Training loss: 1.805742859840393
Validation loss: 2.2026748349589687

Epoch: 5| Step: 2
Training loss: 2.1771576404571533
Validation loss: 2.1249338875534716

Epoch: 5| Step: 3
Training loss: 2.398756742477417
Validation loss: 2.1088787304457797

Epoch: 5| Step: 4
Training loss: 2.4624950885772705
Validation loss: 2.097494207402711

Epoch: 5| Step: 5
Training loss: 2.528843402862549
Validation loss: 2.112088511067052

Epoch: 5| Step: 6
Training loss: 2.3917627334594727
Validation loss: 2.133067438679357

Epoch: 5| Step: 7
Training loss: 2.646329402923584
Validation loss: 2.1644070071558796

Epoch: 5| Step: 8
Training loss: 2.355452299118042
Validation loss: 2.1841774012452815

Epoch: 5| Step: 9
Training loss: 1.7737373113632202
Validation loss: 2.1867246191988707

Epoch: 5| Step: 10
Training loss: 2.3161633014678955
Validation loss: 2.138545859244562

Epoch: 97| Step: 0
Training loss: 2.566460132598877
Validation loss: 2.1053233569668186

Epoch: 5| Step: 1
Training loss: 2.390073299407959
Validation loss: 2.098420112363754

Epoch: 5| Step: 2
Training loss: 2.243046283721924
Validation loss: 2.108226499249858

Epoch: 5| Step: 3
Training loss: 2.2637295722961426
Validation loss: 2.1230668867788007

Epoch: 5| Step: 4
Training loss: 1.8089284896850586
Validation loss: 2.130318457080472

Epoch: 5| Step: 5
Training loss: 1.954615592956543
Validation loss: 2.147031786621258

Epoch: 5| Step: 6
Training loss: 2.9612114429473877
Validation loss: 2.1234225598714684

Epoch: 5| Step: 7
Training loss: 2.655794382095337
Validation loss: 2.107119511532527

Epoch: 5| Step: 8
Training loss: 1.854997992515564
Validation loss: 2.0869854829644643

Epoch: 5| Step: 9
Training loss: 2.2699368000030518
Validation loss: 2.055126897750362

Epoch: 5| Step: 10
Training loss: 2.063781976699829
Validation loss: 2.0475124312985327

Epoch: 98| Step: 0
Training loss: 2.3265411853790283
Validation loss: 2.046781647589899

Epoch: 5| Step: 1
Training loss: 2.573530435562134
Validation loss: 2.0500764295619023

Epoch: 5| Step: 2
Training loss: 2.014033794403076
Validation loss: 2.05927025887274

Epoch: 5| Step: 3
Training loss: 1.7347581386566162
Validation loss: 2.061720645555886

Epoch: 5| Step: 4
Training loss: 1.7962360382080078
Validation loss: 2.0583144913437548

Epoch: 5| Step: 5
Training loss: 2.4332916736602783
Validation loss: 2.070376516670309

Epoch: 5| Step: 6
Training loss: 2.9657607078552246
Validation loss: 2.0635641467186714

Epoch: 5| Step: 7
Training loss: 2.351292371749878
Validation loss: 2.084107178513722

Epoch: 5| Step: 8
Training loss: 2.2167551517486572
Validation loss: 2.1267040198849094

Epoch: 5| Step: 9
Training loss: 2.207155466079712
Validation loss: 2.1743289091253795

Epoch: 5| Step: 10
Training loss: 1.9840881824493408
Validation loss: 2.2730829023545787

Epoch: 99| Step: 0
Training loss: 2.423558235168457
Validation loss: 2.369477052842417

Epoch: 5| Step: 1
Training loss: 2.465132713317871
Validation loss: 2.413912139913087

Epoch: 5| Step: 2
Training loss: 2.948497772216797
Validation loss: 2.3446170847903014

Epoch: 5| Step: 3
Training loss: 2.13432240486145
Validation loss: 2.232921823378532

Epoch: 5| Step: 4
Training loss: 1.5761730670928955
Validation loss: 2.144963709256982

Epoch: 5| Step: 5
Training loss: 1.8704582452774048
Validation loss: 2.1052556576267367

Epoch: 5| Step: 6
Training loss: 1.7393954992294312
Validation loss: 2.1074116665829896

Epoch: 5| Step: 7
Training loss: 3.028308868408203
Validation loss: 2.13750809238803

Epoch: 5| Step: 8
Training loss: 2.6598782539367676
Validation loss: 2.1626819282449703

Epoch: 5| Step: 9
Training loss: 2.44498610496521
Validation loss: 2.1678345677673176

Epoch: 5| Step: 10
Training loss: 2.497629165649414
Validation loss: 2.1120263517543836

Epoch: 100| Step: 0
Training loss: 1.9353183507919312
Validation loss: 2.0643619286116732

Epoch: 5| Step: 1
Training loss: 2.4022774696350098
Validation loss: 2.062211769883351

Epoch: 5| Step: 2
Training loss: 2.293698310852051
Validation loss: 2.0594698754690026

Epoch: 5| Step: 3
Training loss: 2.2609446048736572
Validation loss: 2.065353653764212

Epoch: 5| Step: 4
Training loss: 2.2913661003112793
Validation loss: 2.076975030283774

Epoch: 5| Step: 5
Training loss: 2.5461673736572266
Validation loss: 2.079716077414892

Epoch: 5| Step: 6
Training loss: 2.0557961463928223
Validation loss: 2.0852539564973567

Epoch: 5| Step: 7
Training loss: 2.661907196044922
Validation loss: 2.0863545504949426

Epoch: 5| Step: 8
Training loss: 2.22615647315979
Validation loss: 2.0989380921086958

Epoch: 5| Step: 9
Training loss: 2.4423317909240723
Validation loss: 2.0913356119586575

Epoch: 5| Step: 10
Training loss: 1.8264098167419434
Validation loss: 2.0742075494540635

Epoch: 101| Step: 0
Training loss: 2.4972243309020996
Validation loss: 2.06880517672467

Epoch: 5| Step: 1
Training loss: 1.8712371587753296
Validation loss: 2.085446410281684

Epoch: 5| Step: 2
Training loss: 2.9564905166625977
Validation loss: 2.0935571180876864

Epoch: 5| Step: 3
Training loss: 2.253328800201416
Validation loss: 2.1386139674853255

Epoch: 5| Step: 4
Training loss: 2.355344295501709
Validation loss: 2.1682170796137985

Epoch: 5| Step: 5
Training loss: 2.0581278800964355
Validation loss: 2.169480385318879

Epoch: 5| Step: 6
Training loss: 2.269115924835205
Validation loss: 2.1353994492561585

Epoch: 5| Step: 7
Training loss: 2.022207260131836
Validation loss: 2.114394208436371

Epoch: 5| Step: 8
Training loss: 2.3578686714172363
Validation loss: 2.0943773843908824

Epoch: 5| Step: 9
Training loss: 2.2043120861053467
Validation loss: 2.0866642408473517

Epoch: 5| Step: 10
Training loss: 2.093027114868164
Validation loss: 2.069136481131277

Epoch: 102| Step: 0
Training loss: 1.4191523790359497
Validation loss: 2.068640414104667

Epoch: 5| Step: 1
Training loss: 2.5949172973632812
Validation loss: 2.06502115854653

Epoch: 5| Step: 2
Training loss: 2.3925859928131104
Validation loss: 2.0562053290746545

Epoch: 5| Step: 3
Training loss: 1.9306914806365967
Validation loss: 2.061491524019549

Epoch: 5| Step: 4
Training loss: 2.0238900184631348
Validation loss: 2.057337030287712

Epoch: 5| Step: 5
Training loss: 2.7742278575897217
Validation loss: 2.0437585628160866

Epoch: 5| Step: 6
Training loss: 2.2657840251922607
Validation loss: 2.0450517451891335

Epoch: 5| Step: 7
Training loss: 2.7895755767822266
Validation loss: 2.053367381454796

Epoch: 5| Step: 8
Training loss: 2.323457717895508
Validation loss: 2.0781226555506387

Epoch: 5| Step: 9
Training loss: 1.855018973350525
Validation loss: 2.104881255857406

Epoch: 5| Step: 10
Training loss: 2.0514297485351562
Validation loss: 2.112542465168943

Epoch: 103| Step: 0
Training loss: 2.26646089553833
Validation loss: 2.1378382405927105

Epoch: 5| Step: 1
Training loss: 2.4814231395721436
Validation loss: 2.1562075627747403

Epoch: 5| Step: 2
Training loss: 1.5098600387573242
Validation loss: 2.144369891894761

Epoch: 5| Step: 3
Training loss: 2.2822420597076416
Validation loss: 2.1088375737590175

Epoch: 5| Step: 4
Training loss: 2.604749917984009
Validation loss: 2.0785308473853656

Epoch: 5| Step: 5
Training loss: 2.1671905517578125
Validation loss: 2.054883039125832

Epoch: 5| Step: 6
Training loss: 2.3613791465759277
Validation loss: 2.035956612197302

Epoch: 5| Step: 7
Training loss: 2.1025235652923584
Validation loss: 2.0325392805119997

Epoch: 5| Step: 8
Training loss: 2.3146467208862305
Validation loss: 2.030535782537153

Epoch: 5| Step: 9
Training loss: 2.2387282848358154
Validation loss: 2.0236560785642235

Epoch: 5| Step: 10
Training loss: 1.8384525775909424
Validation loss: 2.026810384565784

Epoch: 104| Step: 0
Training loss: 2.4099762439727783
Validation loss: 2.0420440396954938

Epoch: 5| Step: 1
Training loss: 2.3907761573791504
Validation loss: 2.0640528612239386

Epoch: 5| Step: 2
Training loss: 2.2300662994384766
Validation loss: 2.103262669296675

Epoch: 5| Step: 3
Training loss: 2.81421160697937
Validation loss: 2.1522428399773053

Epoch: 5| Step: 4
Training loss: 2.241603136062622
Validation loss: 2.223829887246573

Epoch: 5| Step: 5
Training loss: 1.902311086654663
Validation loss: 2.2245205730520268

Epoch: 5| Step: 6
Training loss: 2.67718768119812
Validation loss: 2.209436091043616

Epoch: 5| Step: 7
Training loss: 1.674957513809204
Validation loss: 2.172924218639251

Epoch: 5| Step: 8
Training loss: 2.212158203125
Validation loss: 2.1253063909469114

Epoch: 5| Step: 9
Training loss: 1.6097965240478516
Validation loss: 2.0976799072757846

Epoch: 5| Step: 10
Training loss: 1.8289662599563599
Validation loss: 2.0620307563453593

Epoch: 105| Step: 0
Training loss: 1.6052039861679077
Validation loss: 2.059995130826068

Epoch: 5| Step: 1
Training loss: 2.15006947517395
Validation loss: 2.0490848095186296

Epoch: 5| Step: 2
Training loss: 2.468332052230835
Validation loss: 2.048454669214064

Epoch: 5| Step: 3
Training loss: 2.1198291778564453
Validation loss: 2.0475015819713636

Epoch: 5| Step: 4
Training loss: 2.2912683486938477
Validation loss: 2.0526642491740565

Epoch: 5| Step: 5
Training loss: 2.306572437286377
Validation loss: 2.0537837218212824

Epoch: 5| Step: 6
Training loss: 2.0121517181396484
Validation loss: 2.067323843638102

Epoch: 5| Step: 7
Training loss: 1.9833062887191772
Validation loss: 2.0681728073345718

Epoch: 5| Step: 8
Training loss: 1.8380542993545532
Validation loss: 2.084890442509805

Epoch: 5| Step: 9
Training loss: 2.7871551513671875
Validation loss: 2.090851224878783

Epoch: 5| Step: 10
Training loss: 2.265320301055908
Validation loss: 2.0737613272923294

Epoch: 106| Step: 0
Training loss: 2.3928780555725098
Validation loss: 2.0464468079228557

Epoch: 5| Step: 1
Training loss: 2.685194730758667
Validation loss: 2.049391369665823

Epoch: 5| Step: 2
Training loss: 1.981869101524353
Validation loss: 2.0484230287613405

Epoch: 5| Step: 3
Training loss: 1.9356552362442017
Validation loss: 2.057331021114062

Epoch: 5| Step: 4
Training loss: 2.1938114166259766
Validation loss: 2.0541234990601898

Epoch: 5| Step: 5
Training loss: 2.7400431632995605
Validation loss: 2.0477993026856454

Epoch: 5| Step: 6
Training loss: 1.2860316038131714
Validation loss: 2.0551947060451714

Epoch: 5| Step: 7
Training loss: 1.4919660091400146
Validation loss: 2.0705333653316704

Epoch: 5| Step: 8
Training loss: 2.3319907188415527
Validation loss: 2.105054416964131

Epoch: 5| Step: 9
Training loss: 2.3322765827178955
Validation loss: 2.1401900809298278

Epoch: 5| Step: 10
Training loss: 2.3110053539276123
Validation loss: 2.161304917386783

Epoch: 107| Step: 0
Training loss: 2.5304324626922607
Validation loss: 2.1902445439369447

Epoch: 5| Step: 1
Training loss: 2.6155147552490234
Validation loss: 2.20579574185033

Epoch: 5| Step: 2
Training loss: 1.7449535131454468
Validation loss: 2.1818175072311075

Epoch: 5| Step: 3
Training loss: 2.04569935798645
Validation loss: 2.17176902678705

Epoch: 5| Step: 4
Training loss: 2.025028705596924
Validation loss: 2.142310233526332

Epoch: 5| Step: 5
Training loss: 2.391902446746826
Validation loss: 2.103323213515743

Epoch: 5| Step: 6
Training loss: 2.513979434967041
Validation loss: 2.0750551633937384

Epoch: 5| Step: 7
Training loss: 2.1257405281066895
Validation loss: 2.0632709803119784

Epoch: 5| Step: 8
Training loss: 2.38419508934021
Validation loss: 2.0730152950491956

Epoch: 5| Step: 9
Training loss: 1.8623052835464478
Validation loss: 2.0882092919400943

Epoch: 5| Step: 10
Training loss: 1.9779483079910278
Validation loss: 2.101371911264235

Epoch: 108| Step: 0
Training loss: 2.014024019241333
Validation loss: 2.1003428838586293

Epoch: 5| Step: 1
Training loss: 2.2976698875427246
Validation loss: 2.092420031947474

Epoch: 5| Step: 2
Training loss: 1.8719141483306885
Validation loss: 2.1031948789473502

Epoch: 5| Step: 3
Training loss: 2.346247911453247
Validation loss: 2.1150809257261214

Epoch: 5| Step: 4
Training loss: 2.5074658393859863
Validation loss: 2.1267159138956377

Epoch: 5| Step: 5
Training loss: 1.9286201000213623
Validation loss: 2.128620829633487

Epoch: 5| Step: 6
Training loss: 2.6007091999053955
Validation loss: 2.137994361180131

Epoch: 5| Step: 7
Training loss: 2.0259299278259277
Validation loss: 2.142122571186353

Epoch: 5| Step: 8
Training loss: 1.9048137664794922
Validation loss: 2.1411886958665747

Epoch: 5| Step: 9
Training loss: 1.6733649969100952
Validation loss: 2.1058025770289923

Epoch: 5| Step: 10
Training loss: 2.378905773162842
Validation loss: 2.086700648389837

Epoch: 109| Step: 0
Training loss: 1.856907844543457
Validation loss: 2.086380668865737

Epoch: 5| Step: 1
Training loss: 1.9152275323867798
Validation loss: 2.073905852533156

Epoch: 5| Step: 2
Training loss: 2.1040937900543213
Validation loss: 2.0688659606441373

Epoch: 5| Step: 3
Training loss: 1.9610624313354492
Validation loss: 2.0558539923801216

Epoch: 5| Step: 4
Training loss: 1.7860065698623657
Validation loss: 2.0553614144684165

Epoch: 5| Step: 5
Training loss: 2.666144609451294
Validation loss: 2.05029938169705

Epoch: 5| Step: 6
Training loss: 1.9712278842926025
Validation loss: 2.0653906932441135

Epoch: 5| Step: 7
Training loss: 2.244006633758545
Validation loss: 2.081645809194093

Epoch: 5| Step: 8
Training loss: 2.4064431190490723
Validation loss: 2.098499708278205

Epoch: 5| Step: 9
Training loss: 2.376110553741455
Validation loss: 2.128542974431028

Epoch: 5| Step: 10
Training loss: 2.3034329414367676
Validation loss: 2.151202619716685

Epoch: 110| Step: 0
Training loss: 1.7854080200195312
Validation loss: 2.1547453788018998

Epoch: 5| Step: 1
Training loss: 1.4038130044937134
Validation loss: 2.161696857021701

Epoch: 5| Step: 2
Training loss: 2.453904628753662
Validation loss: 2.146492801686769

Epoch: 5| Step: 3
Training loss: 1.9839061498641968
Validation loss: 2.1058807206410233

Epoch: 5| Step: 4
Training loss: 1.900516152381897
Validation loss: 2.0890975575293265

Epoch: 5| Step: 5
Training loss: 2.2734789848327637
Validation loss: 2.0742025708639495

Epoch: 5| Step: 6
Training loss: 1.7883113622665405
Validation loss: 2.0724065252529678

Epoch: 5| Step: 7
Training loss: 2.938241720199585
Validation loss: 2.0647383582207466

Epoch: 5| Step: 8
Training loss: 2.1336510181427
Validation loss: 2.0744976023192048

Epoch: 5| Step: 9
Training loss: 1.655853271484375
Validation loss: 2.080876194020753

Epoch: 5| Step: 10
Training loss: 2.897766590118408
Validation loss: 2.0985881410619265

Epoch: 111| Step: 0
Training loss: 2.1876235008239746
Validation loss: 2.1053746284977084

Epoch: 5| Step: 1
Training loss: 1.667507529258728
Validation loss: 2.1033398387252644

Epoch: 5| Step: 2
Training loss: 2.1716907024383545
Validation loss: 2.0891069904450448

Epoch: 5| Step: 3
Training loss: 2.184678554534912
Validation loss: 2.096917231877645

Epoch: 5| Step: 4
Training loss: 1.6029694080352783
Validation loss: 2.0871489919641966

Epoch: 5| Step: 5
Training loss: 1.8257707357406616
Validation loss: 2.085711112586401

Epoch: 5| Step: 6
Training loss: 2.43530011177063
Validation loss: 2.0889878183282833

Epoch: 5| Step: 7
Training loss: 2.289079427719116
Validation loss: 2.089267376930483

Epoch: 5| Step: 8
Training loss: 2.1395106315612793
Validation loss: 2.096470021432446

Epoch: 5| Step: 9
Training loss: 2.2722132205963135
Validation loss: 2.108102830507422

Epoch: 5| Step: 10
Training loss: 1.792169213294983
Validation loss: 2.11443894140182

Epoch: 112| Step: 0
Training loss: 1.9365400075912476
Validation loss: 2.116449845734463

Epoch: 5| Step: 1
Training loss: 1.6135002374649048
Validation loss: 2.1224157861483994

Epoch: 5| Step: 2
Training loss: 1.9716278314590454
Validation loss: 2.1283247522128526

Epoch: 5| Step: 3
Training loss: 1.9706060886383057
Validation loss: 2.1250722600567724

Epoch: 5| Step: 4
Training loss: 2.1909003257751465
Validation loss: 2.1347351176764375

Epoch: 5| Step: 5
Training loss: 2.3742191791534424
Validation loss: 2.124446052376942

Epoch: 5| Step: 6
Training loss: 2.0071988105773926
Validation loss: 2.114967297482234

Epoch: 5| Step: 7
Training loss: 1.9968715906143188
Validation loss: 2.1036559868884344

Epoch: 5| Step: 8
Training loss: 1.9727321863174438
Validation loss: 2.0980087031600294

Epoch: 5| Step: 9
Training loss: 2.1830601692199707
Validation loss: 2.1022272725259104

Epoch: 5| Step: 10
Training loss: 2.23625111579895
Validation loss: 2.093271593893728

Epoch: 113| Step: 0
Training loss: 2.1488804817199707
Validation loss: 2.110112008228097

Epoch: 5| Step: 1
Training loss: 1.696528673171997
Validation loss: 2.110854853865921

Epoch: 5| Step: 2
Training loss: 2.6701064109802246
Validation loss: 2.1283109752080773

Epoch: 5| Step: 3
Training loss: 2.3807473182678223
Validation loss: 2.1312839677256923

Epoch: 5| Step: 4
Training loss: 1.8026946783065796
Validation loss: 2.143831688870666

Epoch: 5| Step: 5
Training loss: 1.7062181234359741
Validation loss: 2.143439687708373

Epoch: 5| Step: 6
Training loss: 2.1721720695495605
Validation loss: 2.1568360713220414

Epoch: 5| Step: 7
Training loss: 2.134615898132324
Validation loss: 2.163744341942572

Epoch: 5| Step: 8
Training loss: 2.0050063133239746
Validation loss: 2.145280538066741

Epoch: 5| Step: 9
Training loss: 1.4090118408203125
Validation loss: 2.1201007750726517

Epoch: 5| Step: 10
Training loss: 2.2730770111083984
Validation loss: 2.119336594817459

Epoch: 114| Step: 0
Training loss: 2.2234976291656494
Validation loss: 2.1011965402992825

Epoch: 5| Step: 1
Training loss: 1.9532945156097412
Validation loss: 2.084143364301292

Epoch: 5| Step: 2
Training loss: 2.187321424484253
Validation loss: 2.0743491970082766

Epoch: 5| Step: 3
Training loss: 1.9998430013656616
Validation loss: 2.0644044004460818

Epoch: 5| Step: 4
Training loss: 1.893622636795044
Validation loss: 2.077188512330414

Epoch: 5| Step: 5
Training loss: 1.373456358909607
Validation loss: 2.0673845134755617

Epoch: 5| Step: 6
Training loss: 2.424372911453247
Validation loss: 2.0575600952230473

Epoch: 5| Step: 7
Training loss: 1.8673769235610962
Validation loss: 2.0766561723524526

Epoch: 5| Step: 8
Training loss: 1.632004737854004
Validation loss: 2.095850024172055

Epoch: 5| Step: 9
Training loss: 2.3908066749572754
Validation loss: 2.116071936904743

Epoch: 5| Step: 10
Training loss: 2.205915689468384
Validation loss: 2.132569420722223

Epoch: 115| Step: 0
Training loss: 1.8464305400848389
Validation loss: 2.1441715071278233

Epoch: 5| Step: 1
Training loss: 1.8030459880828857
Validation loss: 2.152930105886152

Epoch: 5| Step: 2
Training loss: 1.357100009918213
Validation loss: 2.145733965340481

Epoch: 5| Step: 3
Training loss: 2.534003973007202
Validation loss: 2.1501065787448677

Epoch: 5| Step: 4
Training loss: 1.6226640939712524
Validation loss: 2.1243418544851322

Epoch: 5| Step: 5
Training loss: 2.9219818115234375
Validation loss: 2.140912353351552

Epoch: 5| Step: 6
Training loss: 1.6448074579238892
Validation loss: 2.138587477386639

Epoch: 5| Step: 7
Training loss: 2.0573556423187256
Validation loss: 2.105787913004557

Epoch: 5| Step: 8
Training loss: 2.3499629497528076
Validation loss: 2.084203771365586

Epoch: 5| Step: 9
Training loss: 2.2331461906433105
Validation loss: 2.055110501986678

Epoch: 5| Step: 10
Training loss: 1.8586212396621704
Validation loss: 2.060934602573354

Epoch: 116| Step: 0
Training loss: 2.7289621829986572
Validation loss: 2.053602813392557

Epoch: 5| Step: 1
Training loss: 1.7720451354980469
Validation loss: 2.0624921911506244

Epoch: 5| Step: 2
Training loss: 1.857866644859314
Validation loss: 2.07086407625547

Epoch: 5| Step: 3
Training loss: 2.2127580642700195
Validation loss: 2.0503985061440417

Epoch: 5| Step: 4
Training loss: 1.7247432470321655
Validation loss: 2.058118038280036

Epoch: 5| Step: 5
Training loss: 2.035788059234619
Validation loss: 2.0622944626756894

Epoch: 5| Step: 6
Training loss: 1.4690380096435547
Validation loss: 2.10760659428053

Epoch: 5| Step: 7
Training loss: 2.4558846950531006
Validation loss: 2.1288255440291537

Epoch: 5| Step: 8
Training loss: 1.799886703491211
Validation loss: 2.1405380156732376

Epoch: 5| Step: 9
Training loss: 2.2116875648498535
Validation loss: 2.1375716873394546

Epoch: 5| Step: 10
Training loss: 2.0868823528289795
Validation loss: 2.1346894310366724

Epoch: 117| Step: 0
Training loss: 2.215923547744751
Validation loss: 2.1339183686881937

Epoch: 5| Step: 1
Training loss: 2.9007515907287598
Validation loss: 2.1492482974965084

Epoch: 5| Step: 2
Training loss: 2.2541680335998535
Validation loss: 2.1849158681848997

Epoch: 5| Step: 3
Training loss: 1.7118537425994873
Validation loss: 2.1765369945956814

Epoch: 5| Step: 4
Training loss: 1.9046300649642944
Validation loss: 2.1782234381603938

Epoch: 5| Step: 5
Training loss: 1.9174821376800537
Validation loss: 2.149781273257348

Epoch: 5| Step: 6
Training loss: 1.725785255432129
Validation loss: 2.1076468806112967

Epoch: 5| Step: 7
Training loss: 2.233516216278076
Validation loss: 2.0765974983092277

Epoch: 5| Step: 8
Training loss: 1.9158217906951904
Validation loss: 2.0573661993908625

Epoch: 5| Step: 9
Training loss: 2.0005011558532715
Validation loss: 2.0614112936040407

Epoch: 5| Step: 10
Training loss: 1.520214319229126
Validation loss: 2.0727345007722096

Epoch: 118| Step: 0
Training loss: 1.970965027809143
Validation loss: 2.093944631597047

Epoch: 5| Step: 1
Training loss: 1.5507948398590088
Validation loss: 2.090786980044457

Epoch: 5| Step: 2
Training loss: 1.9047740697860718
Validation loss: 2.0985085630929596

Epoch: 5| Step: 3
Training loss: 2.2715675830841064
Validation loss: 2.098543435014704

Epoch: 5| Step: 4
Training loss: 2.009849786758423
Validation loss: 2.0748705492224744

Epoch: 5| Step: 5
Training loss: 1.5661624670028687
Validation loss: 2.0707682204502884

Epoch: 5| Step: 6
Training loss: 2.1423258781433105
Validation loss: 2.076994803643996

Epoch: 5| Step: 7
Training loss: 2.334662914276123
Validation loss: 2.0916829032282673

Epoch: 5| Step: 8
Training loss: 2.123892307281494
Validation loss: 2.0772730970895417

Epoch: 5| Step: 9
Training loss: 1.8496501445770264
Validation loss: 2.0854092746652584

Epoch: 5| Step: 10
Training loss: 2.163283109664917
Validation loss: 2.109076287156792

Epoch: 119| Step: 0
Training loss: 2.091844081878662
Validation loss: 2.1074676795672347

Epoch: 5| Step: 1
Training loss: 2.3578853607177734
Validation loss: 2.0938471004527104

Epoch: 5| Step: 2
Training loss: 1.573501706123352
Validation loss: 2.1087569139337026

Epoch: 5| Step: 3
Training loss: 2.027880907058716
Validation loss: 2.1027536751121603

Epoch: 5| Step: 4
Training loss: 2.1407225131988525
Validation loss: 2.110296926190776

Epoch: 5| Step: 5
Training loss: 2.0505337715148926
Validation loss: 2.07015376065367

Epoch: 5| Step: 6
Training loss: 1.281529188156128
Validation loss: 2.063375191021991

Epoch: 5| Step: 7
Training loss: 2.6051602363586426
Validation loss: 2.0512270427519277

Epoch: 5| Step: 8
Training loss: 1.5561347007751465
Validation loss: 2.067947640213915

Epoch: 5| Step: 9
Training loss: 2.0735230445861816
Validation loss: 2.0565077489422214

Epoch: 5| Step: 10
Training loss: 1.7580662965774536
Validation loss: 2.079459012195628

Epoch: 120| Step: 0
Training loss: 2.4020190238952637
Validation loss: 2.0732667215408815

Epoch: 5| Step: 1
Training loss: 1.9424831867218018
Validation loss: 2.081092398653748

Epoch: 5| Step: 2
Training loss: 1.8535470962524414
Validation loss: 2.104670137487432

Epoch: 5| Step: 3
Training loss: 1.4539307355880737
Validation loss: 2.086177900273313

Epoch: 5| Step: 4
Training loss: 1.5319103002548218
Validation loss: 2.109333433130736

Epoch: 5| Step: 5
Training loss: 1.3862802982330322
Validation loss: 2.105613436750186

Epoch: 5| Step: 6
Training loss: 2.9063639640808105
Validation loss: 2.1009239688996346

Epoch: 5| Step: 7
Training loss: 1.655874490737915
Validation loss: 2.100203485899074

Epoch: 5| Step: 8
Training loss: 2.093865156173706
Validation loss: 2.103368887337305

Epoch: 5| Step: 9
Training loss: 2.1877245903015137
Validation loss: 2.091537440976789

Epoch: 5| Step: 10
Training loss: 1.8247414827346802
Validation loss: 2.0884482219655025

Epoch: 121| Step: 0
Training loss: 1.7053264379501343
Validation loss: 2.096805654546266

Epoch: 5| Step: 1
Training loss: 1.6149284839630127
Validation loss: 2.0865633321064774

Epoch: 5| Step: 2
Training loss: 1.7405658960342407
Validation loss: 2.0850607015753306

Epoch: 5| Step: 3
Training loss: 1.6830799579620361
Validation loss: 2.073297336537351

Epoch: 5| Step: 4
Training loss: 1.4057023525238037
Validation loss: 2.0728661078278736

Epoch: 5| Step: 5
Training loss: 2.6101584434509277
Validation loss: 2.0554014123896116

Epoch: 5| Step: 6
Training loss: 2.7089266777038574
Validation loss: 2.0542920020318802

Epoch: 5| Step: 7
Training loss: 1.843062400817871
Validation loss: 2.0521740990300334

Epoch: 5| Step: 8
Training loss: 1.8131468296051025
Validation loss: 2.064898539614934

Epoch: 5| Step: 9
Training loss: 2.1001720428466797
Validation loss: 2.0901432473172425

Epoch: 5| Step: 10
Training loss: 1.9237385988235474
Validation loss: 2.1032235571133193

Epoch: 122| Step: 0
Training loss: 1.8076260089874268
Validation loss: 2.120670073775835

Epoch: 5| Step: 1
Training loss: 1.6770899295806885
Validation loss: 2.124728605311404

Epoch: 5| Step: 2
Training loss: 1.8264186382293701
Validation loss: 2.122792174739222

Epoch: 5| Step: 3
Training loss: 2.4251976013183594
Validation loss: 2.119023407659223

Epoch: 5| Step: 4
Training loss: 1.6932485103607178
Validation loss: 2.1230226242414085

Epoch: 5| Step: 5
Training loss: 2.1153156757354736
Validation loss: 2.13824535441655

Epoch: 5| Step: 6
Training loss: 1.8204988241195679
Validation loss: 2.161976796324535

Epoch: 5| Step: 7
Training loss: 2.490595817565918
Validation loss: 2.1654460430145264

Epoch: 5| Step: 8
Training loss: 2.0759658813476562
Validation loss: 2.146400643933204

Epoch: 5| Step: 9
Training loss: 2.039135694503784
Validation loss: 2.137204034354097

Epoch: 5| Step: 10
Training loss: 1.2142127752304077
Validation loss: 2.114519155153664

Epoch: 123| Step: 0
Training loss: 1.9155267477035522
Validation loss: 2.0888676745917207

Epoch: 5| Step: 1
Training loss: 2.5474865436553955
Validation loss: 2.0670779033373763

Epoch: 5| Step: 2
Training loss: 2.2237658500671387
Validation loss: 2.04960266108154

Epoch: 5| Step: 3
Training loss: 1.9083964824676514
Validation loss: 2.0468033180441907

Epoch: 5| Step: 4
Training loss: 1.4589722156524658
Validation loss: 2.054761435395928

Epoch: 5| Step: 5
Training loss: 1.8627780675888062
Validation loss: 2.0599441502683904

Epoch: 5| Step: 6
Training loss: 2.192256212234497
Validation loss: 2.0769621390168385

Epoch: 5| Step: 7
Training loss: 1.942542314529419
Validation loss: 2.0770636963587936

Epoch: 5| Step: 8
Training loss: 2.0570871829986572
Validation loss: 2.0960334616322673

Epoch: 5| Step: 9
Training loss: 1.875036597251892
Validation loss: 2.093842956327623

Epoch: 5| Step: 10
Training loss: 1.3216969966888428
Validation loss: 2.071904887435257

Epoch: 124| Step: 0
Training loss: 2.019369125366211
Validation loss: 2.069908834272815

Epoch: 5| Step: 1
Training loss: 2.092761993408203
Validation loss: 2.058650638467522

Epoch: 5| Step: 2
Training loss: 2.0074026584625244
Validation loss: 2.0776239492559947

Epoch: 5| Step: 3
Training loss: 2.094637393951416
Validation loss: 2.0911496326487553

Epoch: 5| Step: 4
Training loss: 1.6272735595703125
Validation loss: 2.095061627767419

Epoch: 5| Step: 5
Training loss: 2.5413143634796143
Validation loss: 2.0973217923154115

Epoch: 5| Step: 6
Training loss: 1.9793269634246826
Validation loss: 2.082731999376769

Epoch: 5| Step: 7
Training loss: 1.0166347026824951
Validation loss: 2.0900610134165776

Epoch: 5| Step: 8
Training loss: 2.2171711921691895
Validation loss: 2.0908840446061987

Epoch: 5| Step: 9
Training loss: 1.8037662506103516
Validation loss: 2.115629167966945

Epoch: 5| Step: 10
Training loss: 1.673363208770752
Validation loss: 2.110195179139414

Epoch: 125| Step: 0
Training loss: 2.238215208053589
Validation loss: 2.1423138597960114

Epoch: 5| Step: 1
Training loss: 1.8075039386749268
Validation loss: 2.141804443892612

Epoch: 5| Step: 2
Training loss: 1.7046972513198853
Validation loss: 2.1150116459015877

Epoch: 5| Step: 3
Training loss: 1.8300145864486694
Validation loss: 2.113518390604245

Epoch: 5| Step: 4
Training loss: 1.9117664098739624
Validation loss: 2.127347964112477

Epoch: 5| Step: 5
Training loss: 1.8839858770370483
Validation loss: 2.1232028263871388

Epoch: 5| Step: 6
Training loss: 2.029529571533203
Validation loss: 2.1382461863179363

Epoch: 5| Step: 7
Training loss: 2.179424285888672
Validation loss: 2.1417861420621156

Epoch: 5| Step: 8
Training loss: 2.3430986404418945
Validation loss: 2.1265254033509122

Epoch: 5| Step: 9
Training loss: 1.3101800680160522
Validation loss: 2.105393337947066

Epoch: 5| Step: 10
Training loss: 1.8928382396697998
Validation loss: 2.0947126444949897

Epoch: 126| Step: 0
Training loss: 2.4826321601867676
Validation loss: 2.086198752926242

Epoch: 5| Step: 1
Training loss: 1.8870176076889038
Validation loss: 2.08147684989437

Epoch: 5| Step: 2
Training loss: 1.6263105869293213
Validation loss: 2.0812888594083887

Epoch: 5| Step: 3
Training loss: 1.953719139099121
Validation loss: 2.1198132063752864

Epoch: 5| Step: 4
Training loss: 1.7211326360702515
Validation loss: 2.136622436584965

Epoch: 5| Step: 5
Training loss: 1.8279516696929932
Validation loss: 2.1924404815960954

Epoch: 5| Step: 6
Training loss: 1.0564820766448975
Validation loss: 2.201828443875877

Epoch: 5| Step: 7
Training loss: 2.3299591541290283
Validation loss: 2.2253995864622054

Epoch: 5| Step: 8
Training loss: 2.246607542037964
Validation loss: 2.2020312073410198

Epoch: 5| Step: 9
Training loss: 2.260780096054077
Validation loss: 2.163234617120476

Epoch: 5| Step: 10
Training loss: 1.6467887163162231
Validation loss: 2.111237697703864

Epoch: 127| Step: 0
Training loss: 2.250056505203247
Validation loss: 2.0912902611558155

Epoch: 5| Step: 1
Training loss: 1.8461662530899048
Validation loss: 2.087019330711775

Epoch: 5| Step: 2
Training loss: 1.9424279928207397
Validation loss: 2.108140471161053

Epoch: 5| Step: 3
Training loss: 2.1588258743286133
Validation loss: 2.1136096997927596

Epoch: 5| Step: 4
Training loss: 1.2227801084518433
Validation loss: 2.112491656375188

Epoch: 5| Step: 5
Training loss: 1.6627016067504883
Validation loss: 2.122425445946314

Epoch: 5| Step: 6
Training loss: 1.309178113937378
Validation loss: 2.1184074237782466

Epoch: 5| Step: 7
Training loss: 2.584177255630493
Validation loss: 2.1377759671980336

Epoch: 5| Step: 8
Training loss: 1.8308115005493164
Validation loss: 2.144119824132612

Epoch: 5| Step: 9
Training loss: 2.275211811065674
Validation loss: 2.135835765510477

Epoch: 5| Step: 10
Training loss: 1.648931622505188
Validation loss: 2.143791247439641

Epoch: 128| Step: 0
Training loss: 1.4877923727035522
Validation loss: 2.1512864699927707

Epoch: 5| Step: 1
Training loss: 1.7816104888916016
Validation loss: 2.162493262239682

Epoch: 5| Step: 2
Training loss: 2.424482822418213
Validation loss: 2.1650762481074177

Epoch: 5| Step: 3
Training loss: 1.9251741170883179
Validation loss: 2.1239007108954975

Epoch: 5| Step: 4
Training loss: 1.706787347793579
Validation loss: 2.099281700708533

Epoch: 5| Step: 5
Training loss: 2.068239688873291
Validation loss: 2.116287944137409

Epoch: 5| Step: 6
Training loss: 1.4160417318344116
Validation loss: 2.093162977567283

Epoch: 5| Step: 7
Training loss: 2.0774760246276855
Validation loss: 2.086382555705245

Epoch: 5| Step: 8
Training loss: 1.8358337879180908
Validation loss: 2.0804396983115905

Epoch: 5| Step: 9
Training loss: 1.9251302480697632
Validation loss: 2.0965436453460367

Epoch: 5| Step: 10
Training loss: 1.844693660736084
Validation loss: 2.1164398424087034

Epoch: 129| Step: 0
Training loss: 1.9369550943374634
Validation loss: 2.1377079717574583

Epoch: 5| Step: 1
Training loss: 2.5239462852478027
Validation loss: 2.14242656512927

Epoch: 5| Step: 2
Training loss: 1.6929632425308228
Validation loss: 2.1120759646097818

Epoch: 5| Step: 3
Training loss: 1.8803764581680298
Validation loss: 2.1029731406960437

Epoch: 5| Step: 4
Training loss: 1.684826135635376
Validation loss: 2.093738394398843

Epoch: 5| Step: 5
Training loss: 1.738014817237854
Validation loss: 2.086441839894941

Epoch: 5| Step: 6
Training loss: 2.118950366973877
Validation loss: 2.0853180423859627

Epoch: 5| Step: 7
Training loss: 1.7026960849761963
Validation loss: 2.0700434074606946

Epoch: 5| Step: 8
Training loss: 1.9365307092666626
Validation loss: 2.076696757347353

Epoch: 5| Step: 9
Training loss: 1.2574745416641235
Validation loss: 2.08783806011241

Epoch: 5| Step: 10
Training loss: 1.7517369985580444
Validation loss: 2.1130330126772643

Epoch: 130| Step: 0
Training loss: 1.893893837928772
Validation loss: 2.1369572890702115

Epoch: 5| Step: 1
Training loss: 1.916175127029419
Validation loss: 2.153247202596357

Epoch: 5| Step: 2
Training loss: 1.7871925830841064
Validation loss: 2.189095676586192

Epoch: 5| Step: 3
Training loss: 2.006195545196533
Validation loss: 2.18620196465523

Epoch: 5| Step: 4
Training loss: 1.570419430732727
Validation loss: 2.1728267426131875

Epoch: 5| Step: 5
Training loss: 1.319716215133667
Validation loss: 2.154916363377725

Epoch: 5| Step: 6
Training loss: 2.002476930618286
Validation loss: 2.113068652409379

Epoch: 5| Step: 7
Training loss: 1.444193720817566
Validation loss: 2.0985248588746592

Epoch: 5| Step: 8
Training loss: 1.6194394826889038
Validation loss: 2.0777651802186043

Epoch: 5| Step: 9
Training loss: 2.630171298980713
Validation loss: 2.078543919388966

Epoch: 5| Step: 10
Training loss: 1.9582008123397827
Validation loss: 2.0726932171852357

Epoch: 131| Step: 0
Training loss: 1.4419745206832886
Validation loss: 2.0785405212833035

Epoch: 5| Step: 1
Training loss: 0.95086270570755
Validation loss: 2.116866014337027

Epoch: 5| Step: 2
Training loss: 1.8373346328735352
Validation loss: 2.136395174969909

Epoch: 5| Step: 3
Training loss: 2.2918360233306885
Validation loss: 2.15567042750697

Epoch: 5| Step: 4
Training loss: 1.5585227012634277
Validation loss: 2.1185323205045474

Epoch: 5| Step: 5
Training loss: 1.6763817071914673
Validation loss: 2.115733097958308

Epoch: 5| Step: 6
Training loss: 2.6277859210968018
Validation loss: 2.118473901543566

Epoch: 5| Step: 7
Training loss: 2.1749682426452637
Validation loss: 2.1206393523882796

Epoch: 5| Step: 8
Training loss: 1.6541742086410522
Validation loss: 2.1399805545806885

Epoch: 5| Step: 9
Training loss: 1.8358583450317383
Validation loss: 2.1127959964095906

Epoch: 5| Step: 10
Training loss: 2.150710344314575
Validation loss: 2.09512419854441

Epoch: 132| Step: 0
Training loss: 1.9392852783203125
Validation loss: 2.0916220885451122

Epoch: 5| Step: 1
Training loss: 1.4460395574569702
Validation loss: 2.072722222215386

Epoch: 5| Step: 2
Training loss: 1.8609085083007812
Validation loss: 2.0454408584102506

Epoch: 5| Step: 3
Training loss: 1.790557861328125
Validation loss: 2.0407903014972644

Epoch: 5| Step: 4
Training loss: 1.6844854354858398
Validation loss: 2.0525073761581094

Epoch: 5| Step: 5
Training loss: 1.5173604488372803
Validation loss: 2.0557521658559

Epoch: 5| Step: 6
Training loss: 2.0082199573516846
Validation loss: 2.099106027233985

Epoch: 5| Step: 7
Training loss: 1.458774209022522
Validation loss: 2.109681534510787

Epoch: 5| Step: 8
Training loss: 2.409592866897583
Validation loss: 2.107766979484148

Epoch: 5| Step: 9
Training loss: 1.780143141746521
Validation loss: 2.097557512662744

Epoch: 5| Step: 10
Training loss: 2.0232479572296143
Validation loss: 2.072916010374664

Epoch: 133| Step: 0
Training loss: 2.1781907081604004
Validation loss: 2.0670276611082015

Epoch: 5| Step: 1
Training loss: 1.9732707738876343
Validation loss: 2.060108143796203

Epoch: 5| Step: 2
Training loss: 2.049642562866211
Validation loss: 2.061129541807277

Epoch: 5| Step: 3
Training loss: 1.985241174697876
Validation loss: 2.079275705481088

Epoch: 5| Step: 4
Training loss: 1.5208989381790161
Validation loss: 2.0667286175553516

Epoch: 5| Step: 5
Training loss: 1.277574896812439
Validation loss: 2.075833949991452

Epoch: 5| Step: 6
Training loss: 2.118725299835205
Validation loss: 2.1045129452982256

Epoch: 5| Step: 7
Training loss: 1.7135686874389648
Validation loss: 2.1099479454819874

Epoch: 5| Step: 8
Training loss: 1.5378327369689941
Validation loss: 2.123637104547152

Epoch: 5| Step: 9
Training loss: 2.05353045463562
Validation loss: 2.1556674049746607

Epoch: 5| Step: 10
Training loss: 1.2462393045425415
Validation loss: 2.142041672942459

Epoch: 134| Step: 0
Training loss: 1.2312862873077393
Validation loss: 2.1400826310598724

Epoch: 5| Step: 1
Training loss: 1.2793620824813843
Validation loss: 2.130872372658022

Epoch: 5| Step: 2
Training loss: 1.7420713901519775
Validation loss: 2.1201690678955405

Epoch: 5| Step: 3
Training loss: 1.5606744289398193
Validation loss: 2.10962127870129

Epoch: 5| Step: 4
Training loss: 1.8829625844955444
Validation loss: 2.147403227385654

Epoch: 5| Step: 5
Training loss: 2.4713449478149414
Validation loss: 2.1824959375525035

Epoch: 5| Step: 6
Training loss: 2.3665664196014404
Validation loss: 2.2421210004437353

Epoch: 5| Step: 7
Training loss: 1.5963689088821411
Validation loss: 2.203141168881488

Epoch: 5| Step: 8
Training loss: 1.456468939781189
Validation loss: 2.1503534983563166

Epoch: 5| Step: 9
Training loss: 1.988337755203247
Validation loss: 2.1063883778869466

Epoch: 5| Step: 10
Training loss: 2.3953003883361816
Validation loss: 2.075647202871179

Epoch: 135| Step: 0
Training loss: 1.460978388786316
Validation loss: 2.077268938864431

Epoch: 5| Step: 1
Training loss: 1.689058542251587
Validation loss: 2.0579703648885093

Epoch: 5| Step: 2
Training loss: 1.7661365270614624
Validation loss: 2.064721817611366

Epoch: 5| Step: 3
Training loss: 1.9809459447860718
Validation loss: 2.063461372929235

Epoch: 5| Step: 4
Training loss: 1.534798502922058
Validation loss: 2.0659684724705194

Epoch: 5| Step: 5
Training loss: 2.4249660968780518
Validation loss: 2.0745875527781825

Epoch: 5| Step: 6
Training loss: 1.3011060953140259
Validation loss: 2.103292901028869

Epoch: 5| Step: 7
Training loss: 1.443582534790039
Validation loss: 2.1235767884921004

Epoch: 5| Step: 8
Training loss: 1.9314438104629517
Validation loss: 2.140351031416206

Epoch: 5| Step: 9
Training loss: 2.2382454872131348
Validation loss: 2.1474906193312777

Epoch: 5| Step: 10
Training loss: 1.9950637817382812
Validation loss: 2.1625102514861734

Epoch: 136| Step: 0
Training loss: 1.7677230834960938
Validation loss: 2.1277741091225737

Epoch: 5| Step: 1
Training loss: 1.1650631427764893
Validation loss: 2.110724392757621

Epoch: 5| Step: 2
Training loss: 1.6037709712982178
Validation loss: 2.091160494794128

Epoch: 5| Step: 3
Training loss: 1.7890996932983398
Validation loss: 2.0859301602968605

Epoch: 5| Step: 4
Training loss: 2.049905300140381
Validation loss: 2.068180195746883

Epoch: 5| Step: 5
Training loss: 1.4737889766693115
Validation loss: 2.053983473008679

Epoch: 5| Step: 6
Training loss: 2.211716413497925
Validation loss: 2.0519255797068277

Epoch: 5| Step: 7
Training loss: 1.6180284023284912
Validation loss: 2.034036769661852

Epoch: 5| Step: 8
Training loss: 1.818014144897461
Validation loss: 2.0239647844786286

Epoch: 5| Step: 9
Training loss: 1.9160575866699219
Validation loss: 2.0626062782861854

Epoch: 5| Step: 10
Training loss: 1.8519407510757446
Validation loss: 2.0957284537694787

Epoch: 137| Step: 0
Training loss: 2.108556032180786
Validation loss: 2.076546097314486

Epoch: 5| Step: 1
Training loss: 1.7386970520019531
Validation loss: 2.0888599964880172

Epoch: 5| Step: 2
Training loss: 2.838907241821289
Validation loss: 2.0981055280213714

Epoch: 5| Step: 3
Training loss: 1.1669621467590332
Validation loss: 2.1047770541201354

Epoch: 5| Step: 4
Training loss: 1.086183786392212
Validation loss: 2.097584729553551

Epoch: 5| Step: 5
Training loss: 1.5699474811553955
Validation loss: 2.1004737525857906

Epoch: 5| Step: 6
Training loss: 1.6631046533584595
Validation loss: 2.090648930559876

Epoch: 5| Step: 7
Training loss: 2.084774971008301
Validation loss: 2.0990122864323277

Epoch: 5| Step: 8
Training loss: 1.0340495109558105
Validation loss: 2.0816880836281726

Epoch: 5| Step: 9
Training loss: 1.791599988937378
Validation loss: 2.084506771897757

Epoch: 5| Step: 10
Training loss: 2.070161819458008
Validation loss: 2.0671156529457337

Epoch: 138| Step: 0
Training loss: 1.5276391506195068
Validation loss: 2.099568168322245

Epoch: 5| Step: 1
Training loss: 2.220149517059326
Validation loss: 2.0941009726575626

Epoch: 5| Step: 2
Training loss: 1.7048466205596924
Validation loss: 2.1168234937934467

Epoch: 5| Step: 3
Training loss: 1.27737295627594
Validation loss: 2.114290278445008

Epoch: 5| Step: 4
Training loss: 1.941357970237732
Validation loss: 2.0914953959885465

Epoch: 5| Step: 5
Training loss: 1.6572881937026978
Validation loss: 2.0901792203226397

Epoch: 5| Step: 6
Training loss: 1.6806081533432007
Validation loss: 2.111280272083898

Epoch: 5| Step: 7
Training loss: 1.9564182758331299
Validation loss: 2.0916477595606158

Epoch: 5| Step: 8
Training loss: 1.215092658996582
Validation loss: 2.0719737929682576

Epoch: 5| Step: 9
Training loss: 1.997785210609436
Validation loss: 2.08742457051431

Epoch: 5| Step: 10
Training loss: 1.8238744735717773
Validation loss: 2.0858357016758253

Epoch: 139| Step: 0
Training loss: 1.5491838455200195
Validation loss: 2.074617801174041

Epoch: 5| Step: 1
Training loss: 1.2391653060913086
Validation loss: 2.0928401344565937

Epoch: 5| Step: 2
Training loss: 1.1945610046386719
Validation loss: 2.093443497534721

Epoch: 5| Step: 3
Training loss: 1.7173335552215576
Validation loss: 2.1086856370331137

Epoch: 5| Step: 4
Training loss: 1.5812873840332031
Validation loss: 2.1036621806442097

Epoch: 5| Step: 5
Training loss: 1.5808467864990234
Validation loss: 2.092203090267797

Epoch: 5| Step: 6
Training loss: 1.916666030883789
Validation loss: 2.056875213499992

Epoch: 5| Step: 7
Training loss: 2.89050555229187
Validation loss: 2.0793759540844987

Epoch: 5| Step: 8
Training loss: 1.4261045455932617
Validation loss: 2.1113221260809127

Epoch: 5| Step: 9
Training loss: 1.9809372425079346
Validation loss: 2.138283778262395

Epoch: 5| Step: 10
Training loss: 1.8945276737213135
Validation loss: 2.1520049161808465

Epoch: 140| Step: 0
Training loss: 1.9082069396972656
Validation loss: 2.145423694323468

Epoch: 5| Step: 1
Training loss: 1.8139806985855103
Validation loss: 2.1109582454927507

Epoch: 5| Step: 2
Training loss: 1.9597444534301758
Validation loss: 2.0984004056581886

Epoch: 5| Step: 3
Training loss: 1.2392500638961792
Validation loss: 2.0866421486741755

Epoch: 5| Step: 4
Training loss: 1.798290491104126
Validation loss: 2.0754479746664725

Epoch: 5| Step: 5
Training loss: 1.5552300214767456
Validation loss: 2.0465240158060545

Epoch: 5| Step: 6
Training loss: 1.3631298542022705
Validation loss: 2.0569459725451726

Epoch: 5| Step: 7
Training loss: 1.3554868698120117
Validation loss: 2.0789404171769337

Epoch: 5| Step: 8
Training loss: 2.000613212585449
Validation loss: 2.088793896859692

Epoch: 5| Step: 9
Training loss: 1.3336807489395142
Validation loss: 2.114184107831729

Epoch: 5| Step: 10
Training loss: 2.060661792755127
Validation loss: 2.1289314121328373

Epoch: 141| Step: 0
Training loss: 1.4630048274993896
Validation loss: 2.162414417471937

Epoch: 5| Step: 1
Training loss: 2.1903624534606934
Validation loss: 2.2161095219273723

Epoch: 5| Step: 2
Training loss: 1.6438391208648682
Validation loss: 2.158941857276424

Epoch: 5| Step: 3
Training loss: 1.564224362373352
Validation loss: 2.1238208970715924

Epoch: 5| Step: 4
Training loss: 2.30900239944458
Validation loss: 2.0785549097163702

Epoch: 5| Step: 5
Training loss: 1.955550193786621
Validation loss: 2.052999081150178

Epoch: 5| Step: 6
Training loss: 1.6481916904449463
Validation loss: 2.0528010886202575

Epoch: 5| Step: 7
Training loss: 1.0290337800979614
Validation loss: 2.02527295133119

Epoch: 5| Step: 8
Training loss: 1.5654783248901367
Validation loss: 2.0246087812608287

Epoch: 5| Step: 9
Training loss: 1.4628194570541382
Validation loss: 2.0188564767119703

Epoch: 5| Step: 10
Training loss: 1.8898348808288574
Validation loss: 2.0398616278043358

Epoch: 142| Step: 0
Training loss: 1.70246160030365
Validation loss: 2.1022834598377185

Epoch: 5| Step: 1
Training loss: 1.7846368551254272
Validation loss: 2.1614235921572615

Epoch: 5| Step: 2
Training loss: 1.571213960647583
Validation loss: 2.1566315697085474

Epoch: 5| Step: 3
Training loss: 2.082271099090576
Validation loss: 2.1049309725402505

Epoch: 5| Step: 4
Training loss: 1.6330372095108032
Validation loss: 2.0809059322521253

Epoch: 5| Step: 5
Training loss: 1.7489759922027588
Validation loss: 2.068011822239045

Epoch: 5| Step: 6
Training loss: 1.2284612655639648
Validation loss: 2.0884181760972544

Epoch: 5| Step: 7
Training loss: 1.8523041009902954
Validation loss: 2.090658482684884

Epoch: 5| Step: 8
Training loss: 1.564406394958496
Validation loss: 2.131868867463963

Epoch: 5| Step: 9
Training loss: 1.158795714378357
Validation loss: 2.137932017285337

Epoch: 5| Step: 10
Training loss: 2.2674877643585205
Validation loss: 2.181649064504972

Epoch: 143| Step: 0
Training loss: 1.5362350940704346
Validation loss: 2.175480363189533

Epoch: 5| Step: 1
Training loss: 1.3605177402496338
Validation loss: 2.1265048506439372

Epoch: 5| Step: 2
Training loss: 1.1571824550628662
Validation loss: 2.0889857738248763

Epoch: 5| Step: 3
Training loss: 2.244032859802246
Validation loss: 2.059977205850745

Epoch: 5| Step: 4
Training loss: 1.9478288888931274
Validation loss: 2.0635795170261013

Epoch: 5| Step: 5
Training loss: 2.131786823272705
Validation loss: 2.03618686942644

Epoch: 5| Step: 6
Training loss: 2.0031611919403076
Validation loss: 2.0414153529751684

Epoch: 5| Step: 7
Training loss: 1.4286653995513916
Validation loss: 2.060916277670091

Epoch: 5| Step: 8
Training loss: 1.6364294290542603
Validation loss: 2.0710276416552964

Epoch: 5| Step: 9
Training loss: 2.0065762996673584
Validation loss: 2.1037432121974167

Epoch: 5| Step: 10
Training loss: 0.9682769775390625
Validation loss: 2.116070075701642

Epoch: 144| Step: 0
Training loss: 1.593217134475708
Validation loss: 2.1381868905918573

Epoch: 5| Step: 1
Training loss: 1.6131207942962646
Validation loss: 2.207268235503986

Epoch: 5| Step: 2
Training loss: 1.7830995321273804
Validation loss: 2.2002898326484104

Epoch: 5| Step: 3
Training loss: 1.290197491645813
Validation loss: 2.1547481500974266

Epoch: 5| Step: 4
Training loss: 1.2472813129425049
Validation loss: 2.1078584655638664

Epoch: 5| Step: 5
Training loss: 2.2864348888397217
Validation loss: 2.082733272224344

Epoch: 5| Step: 6
Training loss: 0.9683748483657837
Validation loss: 2.0636260227490495

Epoch: 5| Step: 7
Training loss: 1.2646185159683228
Validation loss: 2.051455013213619

Epoch: 5| Step: 8
Training loss: 2.024277687072754
Validation loss: 2.0675026703906316

Epoch: 5| Step: 9
Training loss: 2.1651923656463623
Validation loss: 2.052237331226308

Epoch: 5| Step: 10
Training loss: 1.9968730211257935
Validation loss: 2.0516890069489837

Epoch: 145| Step: 0
Training loss: 1.8938528299331665
Validation loss: 2.0493004937325754

Epoch: 5| Step: 1
Training loss: 2.089540958404541
Validation loss: 2.0169193949750674

Epoch: 5| Step: 2
Training loss: 1.5455962419509888
Validation loss: 2.034722897314256

Epoch: 5| Step: 3
Training loss: 1.5390381813049316
Validation loss: 2.0424306226033035

Epoch: 5| Step: 4
Training loss: 1.613315224647522
Validation loss: 2.0710280890105874

Epoch: 5| Step: 5
Training loss: 1.6580145359039307
Validation loss: 2.1049970708867556

Epoch: 5| Step: 6
Training loss: 1.5901587009429932
Validation loss: 2.1115438451049147

Epoch: 5| Step: 7
Training loss: 1.4867205619812012
Validation loss: 2.166722056686237

Epoch: 5| Step: 8
Training loss: 1.89711594581604
Validation loss: 2.1518706544753043

Epoch: 5| Step: 9
Training loss: 1.3653764724731445
Validation loss: 2.169701947960802

Epoch: 5| Step: 10
Training loss: 1.50953209400177
Validation loss: 2.1401689924219602

Epoch: 146| Step: 0
Training loss: 1.3501479625701904
Validation loss: 2.10749884574644

Epoch: 5| Step: 1
Training loss: 1.0819661617279053
Validation loss: 2.073917777307572

Epoch: 5| Step: 2
Training loss: 1.9451173543930054
Validation loss: 2.0956129130496772

Epoch: 5| Step: 3
Training loss: 1.6112098693847656
Validation loss: 2.0863225447234286

Epoch: 5| Step: 4
Training loss: 1.5813367366790771
Validation loss: 2.0685473231859106

Epoch: 5| Step: 5
Training loss: 1.6473987102508545
Validation loss: 2.08018692334493

Epoch: 5| Step: 6
Training loss: 1.875272512435913
Validation loss: 2.084017344700393

Epoch: 5| Step: 7
Training loss: 1.6693036556243896
Validation loss: 2.1109996546981153

Epoch: 5| Step: 8
Training loss: 1.7795337438583374
Validation loss: 2.1039838021801365

Epoch: 5| Step: 9
Training loss: 1.9805456399917603
Validation loss: 2.0674513437414683

Epoch: 5| Step: 10
Training loss: 1.1002895832061768
Validation loss: 2.044877347125802

Epoch: 147| Step: 0
Training loss: 1.4811736345291138
Validation loss: 2.0360760560599704

Epoch: 5| Step: 1
Training loss: 1.7529598474502563
Validation loss: 2.0441821570037515

Epoch: 5| Step: 2
Training loss: 1.873212456703186
Validation loss: 2.0659559029404835

Epoch: 5| Step: 3
Training loss: 1.3143399953842163
Validation loss: 2.0839710761142034

Epoch: 5| Step: 4
Training loss: 1.7962322235107422
Validation loss: 2.096900942505047

Epoch: 5| Step: 5
Training loss: 1.39701247215271
Validation loss: 2.114437513453986

Epoch: 5| Step: 6
Training loss: 2.2825706005096436
Validation loss: 2.1079819561332784

Epoch: 5| Step: 7
Training loss: 1.4972811937332153
Validation loss: 2.0911467011256883

Epoch: 5| Step: 8
Training loss: 1.3835989236831665
Validation loss: 2.061379175032339

Epoch: 5| Step: 9
Training loss: 1.5807832479476929
Validation loss: 2.0591402271742463

Epoch: 5| Step: 10
Training loss: 1.3685778379440308
Validation loss: 2.0498709806831936

Epoch: 148| Step: 0
Training loss: 1.491971492767334
Validation loss: 2.062621657566358

Epoch: 5| Step: 1
Training loss: 1.2902791500091553
Validation loss: 2.057084680885397

Epoch: 5| Step: 2
Training loss: 1.1186109781265259
Validation loss: 2.086229396122758

Epoch: 5| Step: 3
Training loss: 2.1263842582702637
Validation loss: 2.0854720530971402

Epoch: 5| Step: 4
Training loss: 1.8111989498138428
Validation loss: 2.1335129327671503

Epoch: 5| Step: 5
Training loss: 1.397831916809082
Validation loss: 2.0831750823605444

Epoch: 5| Step: 6
Training loss: 1.5700490474700928
Validation loss: 2.051321748764284

Epoch: 5| Step: 7
Training loss: 1.6748743057250977
Validation loss: 2.0362536176558463

Epoch: 5| Step: 8
Training loss: 1.5313284397125244
Validation loss: 2.02210166377406

Epoch: 5| Step: 9
Training loss: 1.915616750717163
Validation loss: 2.029838651739141

Epoch: 5| Step: 10
Training loss: 2.0472209453582764
Validation loss: 2.0483275023839806

Epoch: 149| Step: 0
Training loss: 1.9344871044158936
Validation loss: 2.068497957721833

Epoch: 5| Step: 1
Training loss: 1.7717311382293701
Validation loss: 2.10149448661394

Epoch: 5| Step: 2
Training loss: 1.3658854961395264
Validation loss: 2.103471403480858

Epoch: 5| Step: 3
Training loss: 1.7477983236312866
Validation loss: 2.093695443163636

Epoch: 5| Step: 4
Training loss: 2.0816023349761963
Validation loss: 2.086539537675919

Epoch: 5| Step: 5
Training loss: 1.8521020412445068
Validation loss: 2.094129862323884

Epoch: 5| Step: 6
Training loss: 1.4969899654388428
Validation loss: 2.098262502301124

Epoch: 5| Step: 7
Training loss: 1.2244638204574585
Validation loss: 2.1412846554992018

Epoch: 5| Step: 8
Training loss: 1.2711113691329956
Validation loss: 2.1772190191412486

Epoch: 5| Step: 9
Training loss: 1.2234766483306885
Validation loss: 2.172658428069084

Epoch: 5| Step: 10
Training loss: 1.7599583864212036
Validation loss: 2.064487703384892

Epoch: 150| Step: 0
Training loss: 2.37160062789917
Validation loss: 2.0255925168273268

Epoch: 5| Step: 1
Training loss: 1.5160858631134033
Validation loss: 1.9983086714180567

Epoch: 5| Step: 2
Training loss: 1.8623294830322266
Validation loss: 2.016416351000468

Epoch: 5| Step: 3
Training loss: 1.0216330289840698
Validation loss: 2.0320539384759884

Epoch: 5| Step: 4
Training loss: 1.4621683359146118
Validation loss: 2.0696600380764214

Epoch: 5| Step: 5
Training loss: 1.5623595714569092
Validation loss: 2.0941504304127028

Epoch: 5| Step: 6
Training loss: 1.1179956197738647
Validation loss: 2.0771506345400246

Epoch: 5| Step: 7
Training loss: 1.813286542892456
Validation loss: 2.05998908576145

Epoch: 5| Step: 8
Training loss: 1.552789568901062
Validation loss: 2.0353645868198846

Epoch: 5| Step: 9
Training loss: 1.5423376560211182
Validation loss: 2.0192270330203477

Epoch: 5| Step: 10
Training loss: 1.7630501985549927
Validation loss: 2.0169781254183863

Epoch: 151| Step: 0
Training loss: 1.306935429573059
Validation loss: 2.0153784854437715

Epoch: 5| Step: 1
Training loss: 1.5330569744110107
Validation loss: 2.039482706336565

Epoch: 5| Step: 2
Training loss: 1.1219898462295532
Validation loss: 2.0627128257546374

Epoch: 5| Step: 3
Training loss: 1.8171577453613281
Validation loss: 2.0940663147998113

Epoch: 5| Step: 4
Training loss: 1.3864376544952393
Validation loss: 2.101725055325416

Epoch: 5| Step: 5
Training loss: 1.536280870437622
Validation loss: 2.1381289676953386

Epoch: 5| Step: 6
Training loss: 1.7201118469238281
Validation loss: 2.168107868522726

Epoch: 5| Step: 7
Training loss: 1.3190425634384155
Validation loss: 2.1316143210216234

Epoch: 5| Step: 8
Training loss: 1.5694308280944824
Validation loss: 2.142234374118108

Epoch: 5| Step: 9
Training loss: 1.5904840230941772
Validation loss: 2.076778855375064

Epoch: 5| Step: 10
Training loss: 2.3107683658599854
Validation loss: 2.0315268462704075

Epoch: 152| Step: 0
Training loss: 1.2445247173309326
Validation loss: 1.9973691714707242

Epoch: 5| Step: 1
Training loss: 1.7368465662002563
Validation loss: 2.0040454877320157

Epoch: 5| Step: 2
Training loss: 1.9315321445465088
Validation loss: 2.0191615550748763

Epoch: 5| Step: 3
Training loss: 1.946441411972046
Validation loss: 2.0643102994529148

Epoch: 5| Step: 4
Training loss: 1.46211838722229
Validation loss: 2.0840727821473153

Epoch: 5| Step: 5
Training loss: 1.3685883283615112
Validation loss: 2.115741793827344

Epoch: 5| Step: 6
Training loss: 1.5344346761703491
Validation loss: 2.15634665694288

Epoch: 5| Step: 7
Training loss: 1.0958411693572998
Validation loss: 2.1790286866567468

Epoch: 5| Step: 8
Training loss: 1.7860031127929688
Validation loss: 2.114051374056006

Epoch: 5| Step: 9
Training loss: 1.6238254308700562
Validation loss: 2.100581493428958

Epoch: 5| Step: 10
Training loss: 1.3133059740066528
Validation loss: 2.056223843687324

Epoch: 153| Step: 0
Training loss: 1.3556691408157349
Validation loss: 2.029816391647503

Epoch: 5| Step: 1
Training loss: 1.5609863996505737
Validation loss: 2.0103076991214546

Epoch: 5| Step: 2
Training loss: 1.7575275897979736
Validation loss: 2.0080629317991194

Epoch: 5| Step: 3
Training loss: 1.443616509437561
Validation loss: 2.02353496192604

Epoch: 5| Step: 4
Training loss: 1.1901381015777588
Validation loss: 2.0376868914532404

Epoch: 5| Step: 5
Training loss: 1.5208003520965576
Validation loss: 2.0825625440125823

Epoch: 5| Step: 6
Training loss: 2.085355520248413
Validation loss: 2.1057892691704536

Epoch: 5| Step: 7
Training loss: 1.2261217832565308
Validation loss: 2.1030184222805883

Epoch: 5| Step: 8
Training loss: 1.3925292491912842
Validation loss: 2.091501666653541

Epoch: 5| Step: 9
Training loss: 1.6536359786987305
Validation loss: 2.12423566849001

Epoch: 5| Step: 10
Training loss: 1.6594945192337036
Validation loss: 2.129143403422448

Epoch: 154| Step: 0
Training loss: 2.06119966506958
Validation loss: 2.126374106253347

Epoch: 5| Step: 1
Training loss: 1.8217382431030273
Validation loss: 2.044957865950882

Epoch: 5| Step: 2
Training loss: 1.19773530960083
Validation loss: 2.0261246055685063

Epoch: 5| Step: 3
Training loss: 1.1563830375671387
Validation loss: 2.0139694239503596

Epoch: 5| Step: 4
Training loss: 1.5516083240509033
Validation loss: 2.03315447479166

Epoch: 5| Step: 5
Training loss: 1.6969095468521118
Validation loss: 2.0292402390510804

Epoch: 5| Step: 6
Training loss: 1.5672177076339722
Validation loss: 2.06443424635036

Epoch: 5| Step: 7
Training loss: 1.5159142017364502
Validation loss: 2.0659160831923127

Epoch: 5| Step: 8
Training loss: 1.0330302715301514
Validation loss: 2.1100161152501262

Epoch: 5| Step: 9
Training loss: 1.4331895112991333
Validation loss: 2.09137366279479

Epoch: 5| Step: 10
Training loss: 1.6196107864379883
Validation loss: 2.1083174597832466

Epoch: 155| Step: 0
Training loss: 1.6942096948623657
Validation loss: 2.0668850970524613

Epoch: 5| Step: 1
Training loss: 1.4354146718978882
Validation loss: 2.051968809097044

Epoch: 5| Step: 2
Training loss: 1.2077462673187256
Validation loss: 2.045426082867448

Epoch: 5| Step: 3
Training loss: 1.2594678401947021
Validation loss: 2.050446702587989

Epoch: 5| Step: 4
Training loss: 1.6193920373916626
Validation loss: 2.0678776105244956

Epoch: 5| Step: 5
Training loss: 1.4402016401290894
Validation loss: 2.0865311084255094

Epoch: 5| Step: 6
Training loss: 1.6404838562011719
Validation loss: 2.0769399724980837

Epoch: 5| Step: 7
Training loss: 1.260573387145996
Validation loss: 2.044407808652488

Epoch: 5| Step: 8
Training loss: 2.113959550857544
Validation loss: 2.023395326829726

Epoch: 5| Step: 9
Training loss: 1.3155696392059326
Validation loss: 2.0586962494798886

Epoch: 5| Step: 10
Training loss: 1.225185751914978
Validation loss: 2.0545893061545586

Epoch: 156| Step: 0
Training loss: 1.7456080913543701
Validation loss: 2.0537759796265633

Epoch: 5| Step: 1
Training loss: 1.6653773784637451
Validation loss: 2.0476932884544454

Epoch: 5| Step: 2
Training loss: 1.365599274635315
Validation loss: 2.051304337798908

Epoch: 5| Step: 3
Training loss: 1.2086482048034668
Validation loss: 2.0266403831461424

Epoch: 5| Step: 4
Training loss: 1.671329140663147
Validation loss: 2.0297707255168627

Epoch: 5| Step: 5
Training loss: 1.4103975296020508
Validation loss: 2.028430954102547

Epoch: 5| Step: 6
Training loss: 1.5441745519638062
Validation loss: 2.026524641180551

Epoch: 5| Step: 7
Training loss: 1.6523786783218384
Validation loss: 2.043287613058603

Epoch: 5| Step: 8
Training loss: 1.5429461002349854
Validation loss: 2.0550481298918366

Epoch: 5| Step: 9
Training loss: 1.0834566354751587
Validation loss: 2.0696618480067097

Epoch: 5| Step: 10
Training loss: 1.4065829515457153
Validation loss: 2.102155855906907

Epoch: 157| Step: 0
Training loss: 1.7238327264785767
Validation loss: 2.158787594046644

Epoch: 5| Step: 1
Training loss: 0.9972828030586243
Validation loss: 2.1819061220333142

Epoch: 5| Step: 2
Training loss: 1.201660394668579
Validation loss: 2.1451930538300545

Epoch: 5| Step: 3
Training loss: 1.2250845432281494
Validation loss: 2.131675317723264

Epoch: 5| Step: 4
Training loss: 1.7919766902923584
Validation loss: 2.153309376009049

Epoch: 5| Step: 5
Training loss: 2.3363635540008545
Validation loss: 2.1140493590344667

Epoch: 5| Step: 6
Training loss: 1.2907953262329102
Validation loss: 2.027186632156372

Epoch: 5| Step: 7
Training loss: 1.2044471502304077
Validation loss: 2.015146595175548

Epoch: 5| Step: 8
Training loss: 1.292167067527771
Validation loss: 2.0101454360510713

Epoch: 5| Step: 9
Training loss: 1.5830628871917725
Validation loss: 1.996416449546814

Epoch: 5| Step: 10
Training loss: 1.8980987071990967
Validation loss: 2.016525060899796

Epoch: 158| Step: 0
Training loss: 1.9935476779937744
Validation loss: 2.067791595253893

Epoch: 5| Step: 1
Training loss: 1.1895126104354858
Validation loss: 2.0954891353525142

Epoch: 5| Step: 2
Training loss: 1.4233686923980713
Validation loss: 2.120445038682671

Epoch: 5| Step: 3
Training loss: 1.2222247123718262
Validation loss: 2.1039044600661083

Epoch: 5| Step: 4
Training loss: 1.142258644104004
Validation loss: 2.110989897481857

Epoch: 5| Step: 5
Training loss: 1.4949322938919067
Validation loss: 2.1316029499935847

Epoch: 5| Step: 6
Training loss: 1.2092643976211548
Validation loss: 2.1428224143161567

Epoch: 5| Step: 7
Training loss: 1.603583574295044
Validation loss: 2.1206578003462924

Epoch: 5| Step: 8
Training loss: 1.7706692218780518
Validation loss: 2.0955028687753985

Epoch: 5| Step: 9
Training loss: 1.3776508569717407
Validation loss: 2.0883324517998645

Epoch: 5| Step: 10
Training loss: 1.5381965637207031
Validation loss: 2.0616904202327935

Epoch: 159| Step: 0
Training loss: 1.293466329574585
Validation loss: 2.0587402236077095

Epoch: 5| Step: 1
Training loss: 1.5774352550506592
Validation loss: 2.0189746541361653

Epoch: 5| Step: 2
Training loss: 1.5804369449615479
Validation loss: 2.0369305918293614

Epoch: 5| Step: 3
Training loss: 1.463924765586853
Validation loss: 2.0183043095373336

Epoch: 5| Step: 4
Training loss: 1.4661771059036255
Validation loss: 2.01866138878689

Epoch: 5| Step: 5
Training loss: 1.3453350067138672
Validation loss: 2.0576717751000517

Epoch: 5| Step: 6
Training loss: 1.3022053241729736
Validation loss: 2.1358318431403047

Epoch: 5| Step: 7
Training loss: 1.5887925624847412
Validation loss: 2.1821735225698

Epoch: 5| Step: 8
Training loss: 1.3986307382583618
Validation loss: 2.210013879242764

Epoch: 5| Step: 9
Training loss: 1.5309686660766602
Validation loss: 2.197687247748016

Epoch: 5| Step: 10
Training loss: 1.3868242502212524
Validation loss: 2.1334849455023326

Epoch: 160| Step: 0
Training loss: 1.2381136417388916
Validation loss: 2.0484021389356224

Epoch: 5| Step: 1
Training loss: 1.0899790525436401
Validation loss: 2.0129857806749243

Epoch: 5| Step: 2
Training loss: 1.6926791667938232
Validation loss: 1.9746468733715754

Epoch: 5| Step: 3
Training loss: 1.5583765506744385
Validation loss: 1.9803338896843694

Epoch: 5| Step: 4
Training loss: 0.965961754322052
Validation loss: 1.990809057348518

Epoch: 5| Step: 5
Training loss: 1.0565706491470337
Validation loss: 1.9912182041393813

Epoch: 5| Step: 6
Training loss: 1.8062222003936768
Validation loss: 2.0066980161974506

Epoch: 5| Step: 7
Training loss: 1.449947714805603
Validation loss: 2.0452906623963387

Epoch: 5| Step: 8
Training loss: 2.1002132892608643
Validation loss: 2.070390078329271

Epoch: 5| Step: 9
Training loss: 1.6821333169937134
Validation loss: 2.103258168825539

Epoch: 5| Step: 10
Training loss: 1.2193206548690796
Validation loss: 2.1022596231070896

Epoch: 161| Step: 0
Training loss: 1.1747934818267822
Validation loss: 2.1095116664004583

Epoch: 5| Step: 1
Training loss: 1.6838204860687256
Validation loss: 2.0873326332338396

Epoch: 5| Step: 2
Training loss: 1.487381935119629
Validation loss: 2.0546597011627687

Epoch: 5| Step: 3
Training loss: 1.2791606187820435
Validation loss: 2.012965904769077

Epoch: 5| Step: 4
Training loss: 1.3950154781341553
Validation loss: 2.001310481820055

Epoch: 5| Step: 5
Training loss: 1.5727685689926147
Validation loss: 2.006213599635709

Epoch: 5| Step: 6
Training loss: 1.1952533721923828
Validation loss: 2.0160006246259137

Epoch: 5| Step: 7
Training loss: 1.3570654392242432
Validation loss: 2.0908662478129068

Epoch: 5| Step: 8
Training loss: 2.109987258911133
Validation loss: 2.1731236160442395

Epoch: 5| Step: 9
Training loss: 1.0059223175048828
Validation loss: 2.2117903437665714

Epoch: 5| Step: 10
Training loss: 1.4854001998901367
Validation loss: 2.2466528723316808

Epoch: 162| Step: 0
Training loss: 1.593888521194458
Validation loss: 2.222052187047979

Epoch: 5| Step: 1
Training loss: 1.6471534967422485
Validation loss: 2.136058852236758

Epoch: 5| Step: 2
Training loss: 1.2975866794586182
Validation loss: 2.0894246588471117

Epoch: 5| Step: 3
Training loss: 1.5221484899520874
Validation loss: 2.026900150442636

Epoch: 5| Step: 4
Training loss: 1.5709186792373657
Validation loss: 1.9996259007402646

Epoch: 5| Step: 5
Training loss: 1.5042104721069336
Validation loss: 1.988020827693324

Epoch: 5| Step: 6
Training loss: 1.3945602178573608
Validation loss: 1.9959024895903885

Epoch: 5| Step: 7
Training loss: 1.0995908975601196
Validation loss: 2.0151703844788256

Epoch: 5| Step: 8
Training loss: 1.2633099555969238
Validation loss: 2.0351416090483307

Epoch: 5| Step: 9
Training loss: 1.0343650579452515
Validation loss: 2.1025325380345827

Epoch: 5| Step: 10
Training loss: 1.4745774269104004
Validation loss: 2.1656161662070983

Epoch: 163| Step: 0
Training loss: 1.1986143589019775
Validation loss: 2.192252923083562

Epoch: 5| Step: 1
Training loss: 1.7305519580841064
Validation loss: 2.1718905894987044

Epoch: 5| Step: 2
Training loss: 1.612607717514038
Validation loss: 2.11427128699518

Epoch: 5| Step: 3
Training loss: 0.8507356643676758
Validation loss: 2.0623342913966023

Epoch: 5| Step: 4
Training loss: 1.6968857049942017
Validation loss: 2.015846244750484

Epoch: 5| Step: 5
Training loss: 1.3782429695129395
Validation loss: 1.9956108395771315

Epoch: 5| Step: 6
Training loss: 1.6911159753799438
Validation loss: 1.9895276690042147

Epoch: 5| Step: 7
Training loss: 1.5877907276153564
Validation loss: 1.9715950309589345

Epoch: 5| Step: 8
Training loss: 1.1465260982513428
Validation loss: 1.9663162539082188

Epoch: 5| Step: 9
Training loss: 1.2877122163772583
Validation loss: 1.9669564449658958

Epoch: 5| Step: 10
Training loss: 1.4512262344360352
Validation loss: 1.9732511710095149

Epoch: 164| Step: 0
Training loss: 1.309173822402954
Validation loss: 2.0044782366803897

Epoch: 5| Step: 1
Training loss: 1.7742936611175537
Validation loss: 2.067018388420023

Epoch: 5| Step: 2
Training loss: 1.669987678527832
Validation loss: 2.099804296288439

Epoch: 5| Step: 3
Training loss: 1.3774460554122925
Validation loss: 2.075907958451138

Epoch: 5| Step: 4
Training loss: 0.9677397012710571
Validation loss: 2.0662268207919214

Epoch: 5| Step: 5
Training loss: 0.8696902990341187
Validation loss: 2.065602852452186

Epoch: 5| Step: 6
Training loss: 1.2477468252182007
Validation loss: 2.066070524595117

Epoch: 5| Step: 7
Training loss: 1.105857491493225
Validation loss: 2.047992572989515

Epoch: 5| Step: 8
Training loss: 0.9344148635864258
Validation loss: 2.0618398997091476

Epoch: 5| Step: 9
Training loss: 2.2808237075805664
Validation loss: 2.0423090509189072

Epoch: 5| Step: 10
Training loss: 1.3881864547729492
Validation loss: 2.0382931168361376

Epoch: 165| Step: 0
Training loss: 1.474848985671997
Validation loss: 2.0377867657651185

Epoch: 5| Step: 1
Training loss: 1.4042441844940186
Validation loss: 2.035539860366493

Epoch: 5| Step: 2
Training loss: 0.7385476231575012
Validation loss: 2.0634508799481135

Epoch: 5| Step: 3
Training loss: 1.5511027574539185
Validation loss: 2.0707063392926286

Epoch: 5| Step: 4
Training loss: 1.581502914428711
Validation loss: 2.107789190866614

Epoch: 5| Step: 5
Training loss: 1.8877604007720947
Validation loss: 2.0754023341722387

Epoch: 5| Step: 6
Training loss: 0.7317416071891785
Validation loss: 2.066340687454388

Epoch: 5| Step: 7
Training loss: 1.7152585983276367
Validation loss: 2.0702197551727295

Epoch: 5| Step: 8
Training loss: 1.365962266921997
Validation loss: 2.0900376253230597

Epoch: 5| Step: 9
Training loss: 1.228264570236206
Validation loss: 2.064458267663115

Epoch: 5| Step: 10
Training loss: 1.1589406728744507
Validation loss: 2.059622259550197

Epoch: 166| Step: 0
Training loss: 1.5599091053009033
Validation loss: 2.069060743495982

Epoch: 5| Step: 1
Training loss: 1.295414924621582
Validation loss: 2.092964676118666

Epoch: 5| Step: 2
Training loss: 1.1078161001205444
Validation loss: 2.1346826591799335

Epoch: 5| Step: 3
Training loss: 1.446773648262024
Validation loss: 2.136808136458038

Epoch: 5| Step: 4
Training loss: 1.7185462713241577
Validation loss: 2.0391844869941793

Epoch: 5| Step: 5
Training loss: 1.521754503250122
Validation loss: 2.023310663879559

Epoch: 5| Step: 6
Training loss: 1.1718343496322632
Validation loss: 1.9964336938755487

Epoch: 5| Step: 7
Training loss: 1.1126524209976196
Validation loss: 1.9819212728931057

Epoch: 5| Step: 8
Training loss: 1.4823442697525024
Validation loss: 1.9916859403733285

Epoch: 5| Step: 9
Training loss: 1.0711301565170288
Validation loss: 1.9856795469919841

Epoch: 5| Step: 10
Training loss: 1.442725419998169
Validation loss: 1.9724022009039437

Epoch: 167| Step: 0
Training loss: 1.3960298299789429
Validation loss: 1.998594714749244

Epoch: 5| Step: 1
Training loss: 1.2320888042449951
Validation loss: 2.0136082569758096

Epoch: 5| Step: 2
Training loss: 0.7989563941955566
Validation loss: 2.0477874202112996

Epoch: 5| Step: 3
Training loss: 1.5048636198043823
Validation loss: 2.1087690732812368

Epoch: 5| Step: 4
Training loss: 1.2742483615875244
Validation loss: 2.150171983626581

Epoch: 5| Step: 5
Training loss: 1.6943957805633545
Validation loss: 2.146695262642317

Epoch: 5| Step: 6
Training loss: 1.3034263849258423
Validation loss: 2.128616033061858

Epoch: 5| Step: 7
Training loss: 1.1764099597930908
Validation loss: 2.0649339101647817

Epoch: 5| Step: 8
Training loss: 1.049412727355957
Validation loss: 2.045115254258597

Epoch: 5| Step: 9
Training loss: 1.4151118993759155
Validation loss: 2.0261262719349196

Epoch: 5| Step: 10
Training loss: 2.08497953414917
Validation loss: 2.0151854509948404

Epoch: 168| Step: 0
Training loss: 0.7986341714859009
Validation loss: 2.0340215019000474

Epoch: 5| Step: 1
Training loss: 1.823077917098999
Validation loss: 2.0690966921467937

Epoch: 5| Step: 2
Training loss: 1.4950358867645264
Validation loss: 2.1054818925037178

Epoch: 5| Step: 3
Training loss: 1.4213643074035645
Validation loss: 2.1193617377229916

Epoch: 5| Step: 4
Training loss: 0.859488844871521
Validation loss: 2.10859695301261

Epoch: 5| Step: 5
Training loss: 1.4088373184204102
Validation loss: 2.073736286932422

Epoch: 5| Step: 6
Training loss: 1.3421666622161865
Validation loss: 2.0798330050642773

Epoch: 5| Step: 7
Training loss: 1.630979299545288
Validation loss: 2.035343731603315

Epoch: 5| Step: 8
Training loss: 1.6457297801971436
Validation loss: 2.0219071603590444

Epoch: 5| Step: 9
Training loss: 0.8942616581916809
Validation loss: 2.0220462429908013

Epoch: 5| Step: 10
Training loss: 1.106673240661621
Validation loss: 2.058463999020156

Epoch: 169| Step: 0
Training loss: 1.6780763864517212
Validation loss: 2.0917685980437906

Epoch: 5| Step: 1
Training loss: 1.4805768728256226
Validation loss: 2.1041626878964004

Epoch: 5| Step: 2
Training loss: 1.1209568977355957
Validation loss: 2.118878259453722

Epoch: 5| Step: 3
Training loss: 0.8695797920227051
Validation loss: 2.1234137012112524

Epoch: 5| Step: 4
Training loss: 1.541886568069458
Validation loss: 2.1327787445437525

Epoch: 5| Step: 5
Training loss: 0.9632749557495117
Validation loss: 2.095325025179053

Epoch: 5| Step: 6
Training loss: 1.4142359495162964
Validation loss: 2.0535273872396

Epoch: 5| Step: 7
Training loss: 1.2301161289215088
Validation loss: 2.01941131776379

Epoch: 5| Step: 8
Training loss: 1.044756531715393
Validation loss: 1.9943422155995523

Epoch: 5| Step: 9
Training loss: 1.8090851306915283
Validation loss: 2.001426307103967

Epoch: 5| Step: 10
Training loss: 1.31820547580719
Validation loss: 2.008870070980441

Epoch: 170| Step: 0
Training loss: 1.501861333847046
Validation loss: 2.027071952819824

Epoch: 5| Step: 1
Training loss: 0.8980829119682312
Validation loss: 2.067014173794818

Epoch: 5| Step: 2
Training loss: 1.211313009262085
Validation loss: 2.119610604419503

Epoch: 5| Step: 3
Training loss: 0.8904343843460083
Validation loss: 2.1247384317459597

Epoch: 5| Step: 4
Training loss: 1.0248048305511475
Validation loss: 2.0980890079211165

Epoch: 5| Step: 5
Training loss: 1.7666075229644775
Validation loss: 2.0792233661938737

Epoch: 5| Step: 6
Training loss: 1.2535059452056885
Validation loss: 2.0401593639004614

Epoch: 5| Step: 7
Training loss: 1.2069138288497925
Validation loss: 2.0172812566962293

Epoch: 5| Step: 8
Training loss: 1.7475566864013672
Validation loss: 1.976137549646439

Epoch: 5| Step: 9
Training loss: 1.5577304363250732
Validation loss: 1.9827135673133276

Epoch: 5| Step: 10
Training loss: 1.2035253047943115
Validation loss: 2.0066202827679214

Epoch: 171| Step: 0
Training loss: 1.0209728479385376
Validation loss: 2.030493915721934

Epoch: 5| Step: 1
Training loss: 1.286527395248413
Validation loss: 2.049982714396651

Epoch: 5| Step: 2
Training loss: 0.8002346754074097
Validation loss: 2.083275424536838

Epoch: 5| Step: 3
Training loss: 1.651242971420288
Validation loss: 2.146054503738239

Epoch: 5| Step: 4
Training loss: 1.4375065565109253
Validation loss: 2.1667976789577033

Epoch: 5| Step: 5
Training loss: 1.1080023050308228
Validation loss: 2.165506898715932

Epoch: 5| Step: 6
Training loss: 1.9155727624893188
Validation loss: 2.1621704204108125

Epoch: 5| Step: 7
Training loss: 1.6144148111343384
Validation loss: 2.1245441539313203

Epoch: 5| Step: 8
Training loss: 1.0934324264526367
Validation loss: 2.0626627399075415

Epoch: 5| Step: 9
Training loss: 1.3405358791351318
Validation loss: 2.0398528973261514

Epoch: 5| Step: 10
Training loss: 1.0580320358276367
Validation loss: 2.0188218034723753

Epoch: 172| Step: 0
Training loss: 1.5694936513900757
Validation loss: 2.0201998884959886

Epoch: 5| Step: 1
Training loss: 0.8624985814094543
Validation loss: 1.9797652588095715

Epoch: 5| Step: 2
Training loss: 1.086014986038208
Validation loss: 2.0351532915587067

Epoch: 5| Step: 3
Training loss: 1.1699738502502441
Validation loss: 2.0607980605094665

Epoch: 5| Step: 4
Training loss: 1.2614163160324097
Validation loss: 2.115952084141393

Epoch: 5| Step: 5
Training loss: 1.556248426437378
Validation loss: 2.154292952629828

Epoch: 5| Step: 6
Training loss: 1.4404994249343872
Validation loss: 2.1309414448276645

Epoch: 5| Step: 7
Training loss: 1.2785805463790894
Validation loss: 2.0871063791295534

Epoch: 5| Step: 8
Training loss: 1.4597299098968506
Validation loss: 2.0874046356447282

Epoch: 5| Step: 9
Training loss: 1.3256314992904663
Validation loss: 2.040559641776546

Epoch: 5| Step: 10
Training loss: 1.10273277759552
Validation loss: 2.036870292437974

Epoch: 173| Step: 0
Training loss: 1.2359133958816528
Validation loss: 2.045053848656275

Epoch: 5| Step: 1
Training loss: 1.2854597568511963
Validation loss: 2.053655271889061

Epoch: 5| Step: 2
Training loss: 1.3709790706634521
Validation loss: 2.0486985201476724

Epoch: 5| Step: 3
Training loss: 1.537092924118042
Validation loss: 2.0269981199695217

Epoch: 5| Step: 4
Training loss: 0.9940704107284546
Validation loss: 2.0021461722671345

Epoch: 5| Step: 5
Training loss: 1.2582470178604126
Validation loss: 1.9584809810884538

Epoch: 5| Step: 6
Training loss: 0.9528474807739258
Validation loss: 1.9687107429709485

Epoch: 5| Step: 7
Training loss: 1.516296148300171
Validation loss: 1.9516184842714699

Epoch: 5| Step: 8
Training loss: 1.564186692237854
Validation loss: 1.9600836743590653

Epoch: 5| Step: 9
Training loss: 1.1778042316436768
Validation loss: 2.004960798448132

Epoch: 5| Step: 10
Training loss: 1.2231603860855103
Validation loss: 2.0784609010142665

Epoch: 174| Step: 0
Training loss: 1.154371976852417
Validation loss: 2.11321626170989

Epoch: 5| Step: 1
Training loss: 1.2145442962646484
Validation loss: 2.1177216370900473

Epoch: 5| Step: 2
Training loss: 0.9516274333000183
Validation loss: 2.089609638337166

Epoch: 5| Step: 3
Training loss: 1.5308693647384644
Validation loss: 2.073389219981368

Epoch: 5| Step: 4
Training loss: 0.990287184715271
Validation loss: 2.0714561375238563

Epoch: 5| Step: 5
Training loss: 1.3034923076629639
Validation loss: 2.060424999524188

Epoch: 5| Step: 6
Training loss: 1.5269174575805664
Validation loss: 2.0420937268964705

Epoch: 5| Step: 7
Training loss: 1.334052324295044
Validation loss: 1.9649792717349144

Epoch: 5| Step: 8
Training loss: 1.2665750980377197
Validation loss: 1.9607206877841745

Epoch: 5| Step: 9
Training loss: 1.2327096462249756
Validation loss: 1.9685977338462748

Epoch: 5| Step: 10
Training loss: 1.5291684865951538
Validation loss: 1.982525642200183

Epoch: 175| Step: 0
Training loss: 1.2293682098388672
Validation loss: 1.9512869568281277

Epoch: 5| Step: 1
Training loss: 1.149003028869629
Validation loss: 1.968896447971303

Epoch: 5| Step: 2
Training loss: 1.5408304929733276
Validation loss: 2.0246227120840423

Epoch: 5| Step: 3
Training loss: 0.9128255844116211
Validation loss: 2.0459181608692294

Epoch: 5| Step: 4
Training loss: 1.3802324533462524
Validation loss: 2.0983538063623572

Epoch: 5| Step: 5
Training loss: 1.3615610599517822
Validation loss: 2.0799756011655255

Epoch: 5| Step: 6
Training loss: 1.1657326221466064
Validation loss: 2.073294396041542

Epoch: 5| Step: 7
Training loss: 1.255030870437622
Validation loss: 2.0067613086392804

Epoch: 5| Step: 8
Training loss: 1.6982107162475586
Validation loss: 2.0331907810703402

Epoch: 5| Step: 9
Training loss: 0.9028832316398621
Validation loss: 2.0141558980429046

Epoch: 5| Step: 10
Training loss: 1.1557480096817017
Validation loss: 2.030805451895601

Epoch: 176| Step: 0
Training loss: 1.2185120582580566
Validation loss: 2.0213360119891424

Epoch: 5| Step: 1
Training loss: 0.7233497500419617
Validation loss: 2.0354166569248324

Epoch: 5| Step: 2
Training loss: 1.3807092905044556
Validation loss: 2.060997701460315

Epoch: 5| Step: 3
Training loss: 1.047958254814148
Validation loss: 2.0673984250714703

Epoch: 5| Step: 4
Training loss: 1.2574255466461182
Validation loss: 2.0632673117422287

Epoch: 5| Step: 5
Training loss: 1.3860653638839722
Validation loss: 2.0319104169004705

Epoch: 5| Step: 6
Training loss: 1.3645970821380615
Validation loss: 1.996810079902731

Epoch: 5| Step: 7
Training loss: 1.2900949716567993
Validation loss: 1.9852101700280302

Epoch: 5| Step: 8
Training loss: 1.2358160018920898
Validation loss: 1.9804226121594828

Epoch: 5| Step: 9
Training loss: 1.4925103187561035
Validation loss: 2.007013738796275

Epoch: 5| Step: 10
Training loss: 1.4200944900512695
Validation loss: 2.043269200991559

Epoch: 177| Step: 0
Training loss: 0.9689559936523438
Validation loss: 2.0767268365429294

Epoch: 5| Step: 1
Training loss: 1.6689151525497437
Validation loss: 2.104696012312366

Epoch: 5| Step: 2
Training loss: 1.4974873065948486
Validation loss: 2.1222755319328717

Epoch: 5| Step: 3
Training loss: 0.8102623820304871
Validation loss: 2.1282264391581216

Epoch: 5| Step: 4
Training loss: 1.1459393501281738
Validation loss: 2.0815753436857656

Epoch: 5| Step: 5
Training loss: 1.347084403038025
Validation loss: 2.0795069894483014

Epoch: 5| Step: 6
Training loss: 1.317899465560913
Validation loss: 2.0456399904784335

Epoch: 5| Step: 7
Training loss: 1.4185234308242798
Validation loss: 2.0465647674375966

Epoch: 5| Step: 8
Training loss: 1.3833619356155396
Validation loss: 2.030049552199661

Epoch: 5| Step: 9
Training loss: 1.0098819732666016
Validation loss: 2.0009456347393733

Epoch: 5| Step: 10
Training loss: 1.087676763534546
Validation loss: 2.0154804029772357

Epoch: 178| Step: 0
Training loss: 1.7807762622833252
Validation loss: 2.0414350237897647

Epoch: 5| Step: 1
Training loss: 1.386777400970459
Validation loss: 2.1041285568667996

Epoch: 5| Step: 2
Training loss: 1.0262914896011353
Validation loss: 2.123446838830107

Epoch: 5| Step: 3
Training loss: 1.4452323913574219
Validation loss: 2.1114324318465365

Epoch: 5| Step: 4
Training loss: 0.7684382200241089
Validation loss: 2.0636811871682443

Epoch: 5| Step: 5
Training loss: 1.2151285409927368
Validation loss: 2.0289123955593316

Epoch: 5| Step: 6
Training loss: 1.4454662799835205
Validation loss: 2.016728106365409

Epoch: 5| Step: 7
Training loss: 0.9217764735221863
Validation loss: 2.0327477852503457

Epoch: 5| Step: 8
Training loss: 1.010793685913086
Validation loss: 2.036475622525779

Epoch: 5| Step: 9
Training loss: 1.626125693321228
Validation loss: 2.0475546621507212

Epoch: 5| Step: 10
Training loss: 0.8797600865364075
Validation loss: 2.0361517372951714

Epoch: 179| Step: 0
Training loss: 1.3165464401245117
Validation loss: 1.9811066709538943

Epoch: 5| Step: 1
Training loss: 1.3067630529403687
Validation loss: 1.9781111260896087

Epoch: 5| Step: 2
Training loss: 0.59596848487854
Validation loss: 1.9727294380946825

Epoch: 5| Step: 3
Training loss: 0.9759820699691772
Validation loss: 1.9842821462180025

Epoch: 5| Step: 4
Training loss: 1.4386723041534424
Validation loss: 2.003169218699137

Epoch: 5| Step: 5
Training loss: 1.3532438278198242
Validation loss: 2.104790943925099

Epoch: 5| Step: 6
Training loss: 1.3810698986053467
Validation loss: 2.1574123444095736

Epoch: 5| Step: 7
Training loss: 1.1174640655517578
Validation loss: 2.220270610624744

Epoch: 5| Step: 8
Training loss: 0.9563857316970825
Validation loss: 2.251086281191918

Epoch: 5| Step: 9
Training loss: 1.7888572216033936
Validation loss: 2.245915743612474

Epoch: 5| Step: 10
Training loss: 1.4773693084716797
Validation loss: 2.1438581071874148

Epoch: 180| Step: 0
Training loss: 1.2882980108261108
Validation loss: 2.0391515942030054

Epoch: 5| Step: 1
Training loss: 1.1163804531097412
Validation loss: 1.9674848407827399

Epoch: 5| Step: 2
Training loss: 1.1740593910217285
Validation loss: 1.9633646318989415

Epoch: 5| Step: 3
Training loss: 1.5925180912017822
Validation loss: 1.9664814549107705

Epoch: 5| Step: 4
Training loss: 0.8284704089164734
Validation loss: 1.9507550475417927

Epoch: 5| Step: 5
Training loss: 1.5899245738983154
Validation loss: 1.9907329492671515

Epoch: 5| Step: 6
Training loss: 0.7737919688224792
Validation loss: 2.0066170564261814

Epoch: 5| Step: 7
Training loss: 1.785584807395935
Validation loss: 2.0506671449189544

Epoch: 5| Step: 8
Training loss: 1.1954667568206787
Validation loss: 2.081382636101015

Epoch: 5| Step: 9
Training loss: 0.9207547307014465
Validation loss: 2.132058125670238

Epoch: 5| Step: 10
Training loss: 1.774637222290039
Validation loss: 2.2154736980315177

Epoch: 181| Step: 0
Training loss: 1.4450762271881104
Validation loss: 2.227580749860374

Epoch: 5| Step: 1
Training loss: 1.6507148742675781
Validation loss: 2.166313527732767

Epoch: 5| Step: 2
Training loss: 1.246469259262085
Validation loss: 2.1031780935102895

Epoch: 5| Step: 3
Training loss: 1.0979212522506714
Validation loss: 2.0398435951561056

Epoch: 5| Step: 4
Training loss: 1.1896827220916748
Validation loss: 2.05381005553789

Epoch: 5| Step: 5
Training loss: 0.8469797372817993
Validation loss: 2.0312317648241596

Epoch: 5| Step: 6
Training loss: 1.462950348854065
Validation loss: 2.0563150977575653

Epoch: 5| Step: 7
Training loss: 1.0176165103912354
Validation loss: 2.057439106766896

Epoch: 5| Step: 8
Training loss: 0.8939873576164246
Validation loss: 2.0991397160355763

Epoch: 5| Step: 9
Training loss: 1.2139676809310913
Validation loss: 2.1281132377604

Epoch: 5| Step: 10
Training loss: 1.4801925420761108
Validation loss: 2.138658533814133

Epoch: 182| Step: 0
Training loss: 1.255046010017395
Validation loss: 2.1721932926485614

Epoch: 5| Step: 1
Training loss: 1.1287586688995361
Validation loss: 2.13105208258475

Epoch: 5| Step: 2
Training loss: 0.8950069546699524
Validation loss: 2.1141608530475247

Epoch: 5| Step: 3
Training loss: 1.6767727136611938
Validation loss: 2.0580639851990568

Epoch: 5| Step: 4
Training loss: 0.6575645804405212
Validation loss: 2.0097644739253546

Epoch: 5| Step: 5
Training loss: 1.2244806289672852
Validation loss: 1.9808435465699883

Epoch: 5| Step: 6
Training loss: 1.1230672597885132
Validation loss: 1.9517044123782907

Epoch: 5| Step: 7
Training loss: 1.498579978942871
Validation loss: 1.9620437878434376

Epoch: 5| Step: 8
Training loss: 1.362239122390747
Validation loss: 1.951852108842583

Epoch: 5| Step: 9
Training loss: 1.492985486984253
Validation loss: 1.9511843060934415

Epoch: 5| Step: 10
Training loss: 0.7899718284606934
Validation loss: 1.9924299050402898

Epoch: 183| Step: 0
Training loss: 0.7693785429000854
Validation loss: 2.0212424955060406

Epoch: 5| Step: 1
Training loss: 1.788104772567749
Validation loss: 2.0971217232365764

Epoch: 5| Step: 2
Training loss: 0.6345065236091614
Validation loss: 2.1208521525065103

Epoch: 5| Step: 3
Training loss: 1.8278954029083252
Validation loss: 2.0851753732209564

Epoch: 5| Step: 4
Training loss: 1.4737224578857422
Validation loss: 2.0440596149813746

Epoch: 5| Step: 5
Training loss: 0.6389707326889038
Validation loss: 1.9978559247909053

Epoch: 5| Step: 6
Training loss: 0.7902995944023132
Validation loss: 1.9707451405063752

Epoch: 5| Step: 7
Training loss: 1.6525949239730835
Validation loss: 1.975697918604779

Epoch: 5| Step: 8
Training loss: 1.1920808553695679
Validation loss: 1.9780166020957373

Epoch: 5| Step: 9
Training loss: 1.230898141860962
Validation loss: 2.0341662642776326

Epoch: 5| Step: 10
Training loss: 1.1462175846099854
Validation loss: 2.01073230338353

Epoch: 184| Step: 0
Training loss: 0.8942655324935913
Validation loss: 2.0529705478299047

Epoch: 5| Step: 1
Training loss: 1.2054561376571655
Validation loss: 2.0501399796496154

Epoch: 5| Step: 2
Training loss: 1.2501908540725708
Validation loss: 2.0438007590591267

Epoch: 5| Step: 3
Training loss: 0.7665523290634155
Validation loss: 2.0843809778972338

Epoch: 5| Step: 4
Training loss: 1.4753155708312988
Validation loss: 2.093562022332222

Epoch: 5| Step: 5
Training loss: 1.1915185451507568
Validation loss: 2.0877650399361887

Epoch: 5| Step: 6
Training loss: 1.1007869243621826
Validation loss: 2.0549961136233423

Epoch: 5| Step: 7
Training loss: 1.0394904613494873
Validation loss: 2.018778767637027

Epoch: 5| Step: 8
Training loss: 1.1920387744903564
Validation loss: 1.9861432916374617

Epoch: 5| Step: 9
Training loss: 1.0814241170883179
Validation loss: 1.989939784490934

Epoch: 5| Step: 10
Training loss: 1.7423079013824463
Validation loss: 2.009914513557188

Epoch: 185| Step: 0
Training loss: 1.1560649871826172
Validation loss: 2.001621735993252

Epoch: 5| Step: 1
Training loss: 0.7902844548225403
Validation loss: 2.002779842704855

Epoch: 5| Step: 2
Training loss: 0.8372203707695007
Validation loss: 2.030271976224838

Epoch: 5| Step: 3
Training loss: 0.8057478666305542
Validation loss: 2.020606965147039

Epoch: 5| Step: 4
Training loss: 1.5700349807739258
Validation loss: 2.08585254351298

Epoch: 5| Step: 5
Training loss: 1.2949495315551758
Validation loss: 2.1259538486439693

Epoch: 5| Step: 6
Training loss: 1.3079458475112915
Validation loss: 2.105016932692579

Epoch: 5| Step: 7
Training loss: 1.3042621612548828
Validation loss: 2.0889791186137865

Epoch: 5| Step: 8
Training loss: 0.9229087829589844
Validation loss: 2.0670388744723414

Epoch: 5| Step: 9
Training loss: 1.4069156646728516
Validation loss: 2.01736924084284

Epoch: 5| Step: 10
Training loss: 1.7106096744537354
Validation loss: 1.999261813779031

Epoch: 186| Step: 0
Training loss: 1.712152123451233
Validation loss: 2.009498626955094

Epoch: 5| Step: 1
Training loss: 0.6398596167564392
Validation loss: 1.9860937851731495

Epoch: 5| Step: 2
Training loss: 1.6404317617416382
Validation loss: 2.005184970876222

Epoch: 5| Step: 3
Training loss: 1.2439861297607422
Validation loss: 2.0335790803355556

Epoch: 5| Step: 4
Training loss: 0.6167319416999817
Validation loss: 2.0377612319043887

Epoch: 5| Step: 5
Training loss: 1.2142430543899536
Validation loss: 2.0474426079821844

Epoch: 5| Step: 6
Training loss: 1.214642882347107
Validation loss: 2.0245929738526702

Epoch: 5| Step: 7
Training loss: 1.1253454685211182
Validation loss: 2.02197362274252

Epoch: 5| Step: 8
Training loss: 0.8261203765869141
Validation loss: 2.029597346500684

Epoch: 5| Step: 9
Training loss: 1.001085638999939
Validation loss: 2.0369302252287507

Epoch: 5| Step: 10
Training loss: 1.3449968099594116
Validation loss: 2.0029649401223786

Epoch: 187| Step: 0
Training loss: 0.9188189506530762
Validation loss: 1.9763362958867063

Epoch: 5| Step: 1
Training loss: 0.9881917238235474
Validation loss: 1.968068790692155

Epoch: 5| Step: 2
Training loss: 1.113969326019287
Validation loss: 1.9780759132036598

Epoch: 5| Step: 3
Training loss: 1.0716497898101807
Validation loss: 1.985968061672744

Epoch: 5| Step: 4
Training loss: 1.2810531854629517
Validation loss: 2.0066755330690773

Epoch: 5| Step: 5
Training loss: 1.1435343027114868
Validation loss: 2.0366137181558917

Epoch: 5| Step: 6
Training loss: 1.1658556461334229
Validation loss: 2.0947157054819088

Epoch: 5| Step: 7
Training loss: 1.5291225910186768
Validation loss: 2.0795730403674546

Epoch: 5| Step: 8
Training loss: 1.4352738857269287
Validation loss: 2.0375433352685746

Epoch: 5| Step: 9
Training loss: 0.9234281778335571
Validation loss: 2.0282339331924275

Epoch: 5| Step: 10
Training loss: 0.8650460243225098
Validation loss: 1.980753347437869

Epoch: 188| Step: 0
Training loss: 0.9921488761901855
Validation loss: 1.977854492843792

Epoch: 5| Step: 1
Training loss: 1.4081130027770996
Validation loss: 1.974549683191443

Epoch: 5| Step: 2
Training loss: 1.063024878501892
Validation loss: 2.0148288537097234

Epoch: 5| Step: 3
Training loss: 0.9222032427787781
Validation loss: 2.00240828657663

Epoch: 5| Step: 4
Training loss: 1.729140281677246
Validation loss: 2.004936574607767

Epoch: 5| Step: 5
Training loss: 1.2603404521942139
Validation loss: 2.0251699198958693

Epoch: 5| Step: 6
Training loss: 0.9761971235275269
Validation loss: 2.054065298008662

Epoch: 5| Step: 7
Training loss: 0.948016345500946
Validation loss: 2.0295147818903767

Epoch: 5| Step: 8
Training loss: 1.2562534809112549
Validation loss: 1.9861300709427043

Epoch: 5| Step: 9
Training loss: 1.174934983253479
Validation loss: 1.954021543584844

Epoch: 5| Step: 10
Training loss: 0.8108919858932495
Validation loss: 1.9619287970245525

Epoch: 189| Step: 0
Training loss: 1.308200478553772
Validation loss: 1.9754836033749323

Epoch: 5| Step: 1
Training loss: 0.8996251821517944
Validation loss: 1.98397155474591

Epoch: 5| Step: 2
Training loss: 0.8995873332023621
Validation loss: 1.9776147821898102

Epoch: 5| Step: 3
Training loss: 0.8588021993637085
Validation loss: 2.0146507781039

Epoch: 5| Step: 4
Training loss: 1.0190073251724243
Validation loss: 2.008972382032743

Epoch: 5| Step: 5
Training loss: 1.2228012084960938
Validation loss: 1.9716980649578957

Epoch: 5| Step: 6
Training loss: 1.0647010803222656
Validation loss: 1.9798404196257233

Epoch: 5| Step: 7
Training loss: 1.3743244409561157
Validation loss: 1.951182109053417

Epoch: 5| Step: 8
Training loss: 1.2572907209396362
Validation loss: 1.9690841833750408

Epoch: 5| Step: 9
Training loss: 1.3018522262573242
Validation loss: 2.018205968282556

Epoch: 5| Step: 10
Training loss: 1.16920804977417
Validation loss: 2.0531975748718425

Epoch: 190| Step: 0
Training loss: 1.0548491477966309
Validation loss: 2.1200538014852874

Epoch: 5| Step: 1
Training loss: 1.184199333190918
Validation loss: 2.1191068823619554

Epoch: 5| Step: 2
Training loss: 1.2819278240203857
Validation loss: 2.1143659468620055

Epoch: 5| Step: 3
Training loss: 1.3745431900024414
Validation loss: 2.027272862772788

Epoch: 5| Step: 4
Training loss: 1.6660254001617432
Validation loss: 1.9667555234765495

Epoch: 5| Step: 5
Training loss: 0.8216554522514343
Validation loss: 1.926476792622638

Epoch: 5| Step: 6
Training loss: 0.7468658685684204
Validation loss: 1.921171235781844

Epoch: 5| Step: 7
Training loss: 0.7482352256774902
Validation loss: 1.9372663651743243

Epoch: 5| Step: 8
Training loss: 1.11594557762146
Validation loss: 1.9620707445247199

Epoch: 5| Step: 9
Training loss: 1.5203346014022827
Validation loss: 2.049057710555292

Epoch: 5| Step: 10
Training loss: 1.3493140935897827
Validation loss: 2.1271539888074322

Epoch: 191| Step: 0
Training loss: 1.0980181694030762
Validation loss: 2.1843550333412747

Epoch: 5| Step: 1
Training loss: 1.1024067401885986
Validation loss: 2.1710004652700117

Epoch: 5| Step: 2
Training loss: 1.0890536308288574
Validation loss: 2.098564346631368

Epoch: 5| Step: 3
Training loss: 0.9665017127990723
Validation loss: 2.0090203259580877

Epoch: 5| Step: 4
Training loss: 1.4794175624847412
Validation loss: 1.9903891932579778

Epoch: 5| Step: 5
Training loss: 1.3218891620635986
Validation loss: 1.9791852299885084

Epoch: 5| Step: 6
Training loss: 1.0735323429107666
Validation loss: 1.9716718401960147

Epoch: 5| Step: 7
Training loss: 1.3218448162078857
Validation loss: 1.9790397677370297

Epoch: 5| Step: 8
Training loss: 1.1399681568145752
Validation loss: 1.984021290656059

Epoch: 5| Step: 9
Training loss: 0.9560357332229614
Validation loss: 1.9699680779569892

Epoch: 5| Step: 10
Training loss: 1.2048072814941406
Validation loss: 1.9642691125151932

Epoch: 192| Step: 0
Training loss: 1.1553815603256226
Validation loss: 1.9512773559939476

Epoch: 5| Step: 1
Training loss: 0.6716960668563843
Validation loss: 1.992580465091172

Epoch: 5| Step: 2
Training loss: 1.3689756393432617
Validation loss: 2.001380507664014

Epoch: 5| Step: 3
Training loss: 1.4117639064788818
Validation loss: 2.016561177469069

Epoch: 5| Step: 4
Training loss: 0.8694690465927124
Validation loss: 2.0543941913112516

Epoch: 5| Step: 5
Training loss: 0.9106143712997437
Validation loss: 2.037186679019723

Epoch: 5| Step: 6
Training loss: 0.8377870321273804
Validation loss: 2.052900814240979

Epoch: 5| Step: 7
Training loss: 1.2520216703414917
Validation loss: 2.0461113555457002

Epoch: 5| Step: 8
Training loss: 0.8832961320877075
Validation loss: 2.0315947122471307

Epoch: 5| Step: 9
Training loss: 1.3448750972747803
Validation loss: 2.0290765813601914

Epoch: 5| Step: 10
Training loss: 1.404179334640503
Validation loss: 1.9901014758694557

Epoch: 193| Step: 0
Training loss: 1.1518175601959229
Validation loss: 2.002384829264815

Epoch: 5| Step: 1
Training loss: 0.7065865397453308
Validation loss: 1.9537170343501593

Epoch: 5| Step: 2
Training loss: 1.2679678201675415
Validation loss: 1.9710791854448215

Epoch: 5| Step: 3
Training loss: 0.8030109405517578
Validation loss: 2.016306677172261

Epoch: 5| Step: 4
Training loss: 1.0871168375015259
Validation loss: 2.0340332908015095

Epoch: 5| Step: 5
Training loss: 1.359253168106079
Validation loss: 2.120052058209655

Epoch: 5| Step: 6
Training loss: 0.9315556287765503
Validation loss: 2.145945769484325

Epoch: 5| Step: 7
Training loss: 1.467272400856018
Validation loss: 2.153110634896063

Epoch: 5| Step: 8
Training loss: 1.1333850622177124
Validation loss: 2.0897901353015693

Epoch: 5| Step: 9
Training loss: 1.1060845851898193
Validation loss: 1.9848811626434326

Epoch: 5| Step: 10
Training loss: 1.160405158996582
Validation loss: 1.9586859415936213

Epoch: 194| Step: 0
Training loss: 0.9971112012863159
Validation loss: 1.9281491502638786

Epoch: 5| Step: 1
Training loss: 1.4035489559173584
Validation loss: 1.9333777581491778

Epoch: 5| Step: 2
Training loss: 1.1356465816497803
Validation loss: 1.9564397501689132

Epoch: 5| Step: 3
Training loss: 1.0262181758880615
Validation loss: 1.9614407195839831

Epoch: 5| Step: 4
Training loss: 0.8966884613037109
Validation loss: 2.054843730823968

Epoch: 5| Step: 5
Training loss: 1.4229605197906494
Validation loss: 2.139229912911692

Epoch: 5| Step: 6
Training loss: 1.1868691444396973
Validation loss: 2.190274856423819

Epoch: 5| Step: 7
Training loss: 0.8536392450332642
Validation loss: 2.2115853986432477

Epoch: 5| Step: 8
Training loss: 1.583581805229187
Validation loss: 2.1717805490698865

Epoch: 5| Step: 9
Training loss: 0.9660261273384094
Validation loss: 2.11379841578904

Epoch: 5| Step: 10
Training loss: 0.7088890075683594
Validation loss: 2.0172534950317873

Epoch: 195| Step: 0
Training loss: 1.3467180728912354
Validation loss: 1.989367433773574

Epoch: 5| Step: 1
Training loss: 1.2668681144714355
Validation loss: 1.9649630182532853

Epoch: 5| Step: 2
Training loss: 1.0077409744262695
Validation loss: 1.9308816989262898

Epoch: 5| Step: 3
Training loss: 1.1642820835113525
Validation loss: 1.9277356927112868

Epoch: 5| Step: 4
Training loss: 1.0560072660446167
Validation loss: 1.936691907144362

Epoch: 5| Step: 5
Training loss: 1.6245872974395752
Validation loss: 1.9563279921008694

Epoch: 5| Step: 6
Training loss: 1.4693292379379272
Validation loss: 2.0022332514486005

Epoch: 5| Step: 7
Training loss: 0.9729054570198059
Validation loss: 2.034135769772273

Epoch: 5| Step: 8
Training loss: 1.0705177783966064
Validation loss: 2.0062869876943608

Epoch: 5| Step: 9
Training loss: 0.5150388479232788
Validation loss: 2.032075153884067

Epoch: 5| Step: 10
Training loss: 0.9697109460830688
Validation loss: 2.0656398188683296

Epoch: 196| Step: 0
Training loss: 1.0382596254348755
Validation loss: 2.1188428504492647

Epoch: 5| Step: 1
Training loss: 0.7980174422264099
Validation loss: 2.1959257023308867

Epoch: 5| Step: 2
Training loss: 1.0114390850067139
Validation loss: 2.2186552093875025

Epoch: 5| Step: 3
Training loss: 1.0913844108581543
Validation loss: 2.2251322500167356

Epoch: 5| Step: 4
Training loss: 0.8091422915458679
Validation loss: 2.14231365214112

Epoch: 5| Step: 5
Training loss: 1.0955966711044312
Validation loss: 2.032469851996309

Epoch: 5| Step: 6
Training loss: 1.4507572650909424
Validation loss: 1.9818988935921782

Epoch: 5| Step: 7
Training loss: 0.9667917490005493
Validation loss: 1.9519191313815374

Epoch: 5| Step: 8
Training loss: 1.0539300441741943
Validation loss: 1.953981453372586

Epoch: 5| Step: 9
Training loss: 1.0893275737762451
Validation loss: 1.949653019187271

Epoch: 5| Step: 10
Training loss: 1.9339454174041748
Validation loss: 1.9772565608383508

Epoch: 197| Step: 0
Training loss: 0.7258108854293823
Validation loss: 2.006362602274905

Epoch: 5| Step: 1
Training loss: 1.2694638967514038
Validation loss: 1.9800063256294496

Epoch: 5| Step: 2
Training loss: 1.309264063835144
Validation loss: 1.99231767910783

Epoch: 5| Step: 3
Training loss: 0.9976126551628113
Validation loss: 1.9341131410291117

Epoch: 5| Step: 4
Training loss: 1.091196060180664
Validation loss: 1.8947862707158571

Epoch: 5| Step: 5
Training loss: 1.5668997764587402
Validation loss: 1.8791668479160597

Epoch: 5| Step: 6
Training loss: 1.0788028240203857
Validation loss: 1.903914959199967

Epoch: 5| Step: 7
Training loss: 1.1991883516311646
Validation loss: 1.9696812552790488

Epoch: 5| Step: 8
Training loss: 1.4046881198883057
Validation loss: 2.045249363427521

Epoch: 5| Step: 9
Training loss: 0.9038693308830261
Validation loss: 2.160529177675965

Epoch: 5| Step: 10
Training loss: 1.0049760341644287
Validation loss: 2.2133659880648375

Epoch: 198| Step: 0
Training loss: 1.5375770330429077
Validation loss: 2.22212472269612

Epoch: 5| Step: 1
Training loss: 0.9471392631530762
Validation loss: 2.170031214273104

Epoch: 5| Step: 2
Training loss: 1.0842567682266235
Validation loss: 2.1029473222712034

Epoch: 5| Step: 3
Training loss: 0.998620331287384
Validation loss: 2.034244241253022

Epoch: 5| Step: 4
Training loss: 0.8496769666671753
Validation loss: 1.9979559093393304

Epoch: 5| Step: 5
Training loss: 0.7173815965652466
Validation loss: 1.956249911298034

Epoch: 5| Step: 6
Training loss: 0.7447319030761719
Validation loss: 1.9164724939612932

Epoch: 5| Step: 7
Training loss: 1.5033013820648193
Validation loss: 1.952079039747997

Epoch: 5| Step: 8
Training loss: 1.2751891613006592
Validation loss: 1.9311569993213942

Epoch: 5| Step: 9
Training loss: 1.4490966796875
Validation loss: 1.9320453546380485

Epoch: 5| Step: 10
Training loss: 1.147721767425537
Validation loss: 1.93417775887315

Epoch: 199| Step: 0
Training loss: 0.5675585865974426
Validation loss: 1.9293198149691346

Epoch: 5| Step: 1
Training loss: 1.4843919277191162
Validation loss: 1.9720510757097633

Epoch: 5| Step: 2
Training loss: 0.8719111680984497
Validation loss: 1.9958174715759933

Epoch: 5| Step: 3
Training loss: 0.8933814764022827
Validation loss: 2.0616124983756774

Epoch: 5| Step: 4
Training loss: 1.056204080581665
Validation loss: 2.107620059802968

Epoch: 5| Step: 5
Training loss: 1.4747029542922974
Validation loss: 2.1413403852011568

Epoch: 5| Step: 6
Training loss: 0.7433010339736938
Validation loss: 2.122844171780412

Epoch: 5| Step: 7
Training loss: 1.0984938144683838
Validation loss: 2.1026076027142104

Epoch: 5| Step: 8
Training loss: 0.9435823559761047
Validation loss: 2.057490543652606

Epoch: 5| Step: 9
Training loss: 1.331419587135315
Validation loss: 2.033838015730663

Epoch: 5| Step: 10
Training loss: 1.4706138372421265
Validation loss: 1.9548038128883607

Epoch: 200| Step: 0
Training loss: 0.8197070360183716
Validation loss: 1.9296444692919332

Epoch: 5| Step: 1
Training loss: 0.9818994402885437
Validation loss: 1.9011254746426818

Epoch: 5| Step: 2
Training loss: 1.0748318433761597
Validation loss: 1.9389468418654574

Epoch: 5| Step: 3
Training loss: 0.9249067306518555
Validation loss: 1.9401154056672127

Epoch: 5| Step: 4
Training loss: 1.5205265283584595
Validation loss: 1.9694543833373694

Epoch: 5| Step: 5
Training loss: 0.9248340725898743
Validation loss: 1.9754944668021253

Epoch: 5| Step: 6
Training loss: 1.2336654663085938
Validation loss: 2.000962911113616

Epoch: 5| Step: 7
Training loss: 0.9448955655097961
Validation loss: 2.0211312488843034

Epoch: 5| Step: 8
Training loss: 1.2130041122436523
Validation loss: 2.04791590411176

Epoch: 5| Step: 9
Training loss: 0.8108345866203308
Validation loss: 2.0469982572781142

Epoch: 5| Step: 10
Training loss: 0.8963959813117981
Validation loss: 2.041100181559081

Epoch: 201| Step: 0
Training loss: 0.9603274464607239
Validation loss: 2.0024398142291653

Epoch: 5| Step: 1
Training loss: 0.9143772125244141
Validation loss: 1.9982503332117552

Epoch: 5| Step: 2
Training loss: 1.0243207216262817
Validation loss: 1.988753326477543

Epoch: 5| Step: 3
Training loss: 0.884402871131897
Validation loss: 1.9882884410119825

Epoch: 5| Step: 4
Training loss: 1.2831240892410278
Validation loss: 1.9912452031207342

Epoch: 5| Step: 5
Training loss: 1.0660079717636108
Validation loss: 1.9902888728726296

Epoch: 5| Step: 6
Training loss: 0.9779103994369507
Validation loss: 2.0125391957580403

Epoch: 5| Step: 7
Training loss: 1.1699225902557373
Validation loss: 1.9964575152243338

Epoch: 5| Step: 8
Training loss: 1.2321287393569946
Validation loss: 1.9856779498438681

Epoch: 5| Step: 9
Training loss: 0.6311416625976562
Validation loss: 1.9992747396551154

Epoch: 5| Step: 10
Training loss: 0.7307610511779785
Validation loss: 1.9812196352148568

Epoch: 202| Step: 0
Training loss: 1.0182902812957764
Validation loss: 1.956263699839192

Epoch: 5| Step: 1
Training loss: 0.8903783559799194
Validation loss: 1.9577527981932445

Epoch: 5| Step: 2
Training loss: 1.3196656703948975
Validation loss: 1.9612761107824181

Epoch: 5| Step: 3
Training loss: 1.3718750476837158
Validation loss: 1.9795387380866594

Epoch: 5| Step: 4
Training loss: 1.3748137950897217
Validation loss: 1.9699131699018582

Epoch: 5| Step: 5
Training loss: 0.44030699133872986
Validation loss: 2.016136330942954

Epoch: 5| Step: 6
Training loss: 0.9833680987358093
Validation loss: 2.0323583541377896

Epoch: 5| Step: 7
Training loss: 0.8420675992965698
Validation loss: 2.0691021104012766

Epoch: 5| Step: 8
Training loss: 0.8567585945129395
Validation loss: 2.0744983252658638

Epoch: 5| Step: 9
Training loss: 1.0702368021011353
Validation loss: 2.08983612573275

Epoch: 5| Step: 10
Training loss: 0.6106098294258118
Validation loss: 2.0458189287493305

Epoch: 203| Step: 0
Training loss: 0.9048210978507996
Validation loss: 2.009924206682431

Epoch: 5| Step: 1
Training loss: 0.7551161050796509
Validation loss: 1.9741912477759904

Epoch: 5| Step: 2
Training loss: 0.935336709022522
Validation loss: 2.001417713780557

Epoch: 5| Step: 3
Training loss: 0.9031238555908203
Validation loss: 1.9661187638518631

Epoch: 5| Step: 4
Training loss: 0.7385605573654175
Validation loss: 1.9743496538490377

Epoch: 5| Step: 5
Training loss: 1.0942260026931763
Validation loss: 1.99292976497322

Epoch: 5| Step: 6
Training loss: 0.833732008934021
Validation loss: 1.9741326044964533

Epoch: 5| Step: 7
Training loss: 1.1166036128997803
Validation loss: 1.9849584166721632

Epoch: 5| Step: 8
Training loss: 1.5549590587615967
Validation loss: 1.9906622850766746

Epoch: 5| Step: 9
Training loss: 1.1030628681182861
Validation loss: 1.9608180753646358

Epoch: 5| Step: 10
Training loss: 0.9571142792701721
Validation loss: 1.955339793236025

Epoch: 204| Step: 0
Training loss: 1.1957273483276367
Validation loss: 1.9368353120742305

Epoch: 5| Step: 1
Training loss: 0.7088310122489929
Validation loss: 1.932180848172916

Epoch: 5| Step: 2
Training loss: 0.9693916440010071
Validation loss: 1.961972052051175

Epoch: 5| Step: 3
Training loss: 0.6128745079040527
Validation loss: 1.9770582722079368

Epoch: 5| Step: 4
Training loss: 0.9661043882369995
Validation loss: 1.9595404619811683

Epoch: 5| Step: 5
Training loss: 0.7759329080581665
Validation loss: 1.9798569204986736

Epoch: 5| Step: 6
Training loss: 1.2525088787078857
Validation loss: 1.9901640569010088

Epoch: 5| Step: 7
Training loss: 0.7082415819168091
Validation loss: 1.9564766037848689

Epoch: 5| Step: 8
Training loss: 1.0541212558746338
Validation loss: 1.9894166133737052

Epoch: 5| Step: 9
Training loss: 1.2222001552581787
Validation loss: 1.983772167595484

Epoch: 5| Step: 10
Training loss: 1.1575032472610474
Validation loss: 1.9928083368526992

Epoch: 205| Step: 0
Training loss: 1.080554485321045
Validation loss: 2.0015316483795003

Epoch: 5| Step: 1
Training loss: 0.46783000230789185
Validation loss: 2.031484683354696

Epoch: 5| Step: 2
Training loss: 1.2823524475097656
Validation loss: 2.033535785572503

Epoch: 5| Step: 3
Training loss: 0.8194280862808228
Validation loss: 2.024806995545664

Epoch: 5| Step: 4
Training loss: 1.2323617935180664
Validation loss: 2.0330068860002743

Epoch: 5| Step: 5
Training loss: 0.9937297701835632
Validation loss: 2.0076636819429297

Epoch: 5| Step: 6
Training loss: 1.2375530004501343
Validation loss: 2.0249992468023814

Epoch: 5| Step: 7
Training loss: 1.1300904750823975
Validation loss: 1.9756637645024124

Epoch: 5| Step: 8
Training loss: 0.754197895526886
Validation loss: 1.963019254387066

Epoch: 5| Step: 9
Training loss: 1.0621658563613892
Validation loss: 1.9628890970701813

Epoch: 5| Step: 10
Training loss: 0.8263382911682129
Validation loss: 1.975611538015386

Epoch: 206| Step: 0
Training loss: 1.170036792755127
Validation loss: 1.9581632421862694

Epoch: 5| Step: 1
Training loss: 0.950583279132843
Validation loss: 1.9733396883933776

Epoch: 5| Step: 2
Training loss: 0.6805304288864136
Validation loss: 1.9763747581871607

Epoch: 5| Step: 3
Training loss: 1.0686136484146118
Validation loss: 1.9668063297066638

Epoch: 5| Step: 4
Training loss: 1.003843903541565
Validation loss: 1.9851882303914716

Epoch: 5| Step: 5
Training loss: 1.0680882930755615
Validation loss: 2.0203943457654727

Epoch: 5| Step: 6
Training loss: 1.052425742149353
Validation loss: 2.0617428236110236

Epoch: 5| Step: 7
Training loss: 1.1213738918304443
Validation loss: 2.0551727253903627

Epoch: 5| Step: 8
Training loss: 0.6281423568725586
Validation loss: 2.04550140519296

Epoch: 5| Step: 9
Training loss: 0.8604095578193665
Validation loss: 2.043901446045086

Epoch: 5| Step: 10
Training loss: 0.9464833736419678
Validation loss: 2.036028044198149

Epoch: 207| Step: 0
Training loss: 1.1847009658813477
Validation loss: 2.0344240127071256

Epoch: 5| Step: 1
Training loss: 0.7691954970359802
Validation loss: 2.031486067720639

Epoch: 5| Step: 2
Training loss: 1.262805700302124
Validation loss: 2.0078558101448962

Epoch: 5| Step: 3
Training loss: 0.643568217754364
Validation loss: 1.9866532664145193

Epoch: 5| Step: 4
Training loss: 0.6443485021591187
Validation loss: 1.947537866971826

Epoch: 5| Step: 5
Training loss: 1.0133843421936035
Validation loss: 1.9455145738458122

Epoch: 5| Step: 6
Training loss: 1.385380506515503
Validation loss: 1.9400380183291692

Epoch: 5| Step: 7
Training loss: 0.9503397941589355
Validation loss: 1.9702773658178185

Epoch: 5| Step: 8
Training loss: 0.7238367795944214
Validation loss: 2.001701221671156

Epoch: 5| Step: 9
Training loss: 0.6253722310066223
Validation loss: 1.99945947816295

Epoch: 5| Step: 10
Training loss: 0.9991203546524048
Validation loss: 1.9870321942913918

Epoch: 208| Step: 0
Training loss: 0.9425384402275085
Validation loss: 1.9768641917936263

Epoch: 5| Step: 1
Training loss: 0.8210317492485046
Validation loss: 1.9650562732450423

Epoch: 5| Step: 2
Training loss: 0.8193947076797485
Validation loss: 1.9633286447935208

Epoch: 5| Step: 3
Training loss: 1.145504355430603
Validation loss: 1.9325757231763614

Epoch: 5| Step: 4
Training loss: 1.1605215072631836
Validation loss: 1.981796149284609

Epoch: 5| Step: 5
Training loss: 0.84894859790802
Validation loss: 1.982907602863927

Epoch: 5| Step: 6
Training loss: 0.8295506238937378
Validation loss: 1.9762664866703812

Epoch: 5| Step: 7
Training loss: 1.201899766921997
Validation loss: 1.9650129118273336

Epoch: 5| Step: 8
Training loss: 0.8093471527099609
Validation loss: 1.9437349803986088

Epoch: 5| Step: 9
Training loss: 1.1210371255874634
Validation loss: 1.9576216872020433

Epoch: 5| Step: 10
Training loss: 0.5280987024307251
Validation loss: 2.0017610493526665

Epoch: 209| Step: 0
Training loss: 0.9934905171394348
Validation loss: 2.01304373433513

Epoch: 5| Step: 1
Training loss: 1.210996389389038
Validation loss: 2.0191176886199624

Epoch: 5| Step: 2
Training loss: 1.2846410274505615
Validation loss: 2.0230682537119877

Epoch: 5| Step: 3
Training loss: 0.7132815718650818
Validation loss: 2.0284828626981346

Epoch: 5| Step: 4
Training loss: 0.7715303301811218
Validation loss: 2.021536707878113

Epoch: 5| Step: 5
Training loss: 0.6422192454338074
Validation loss: 2.0374520081345753

Epoch: 5| Step: 6
Training loss: 1.3377307653427124
Validation loss: 2.0460551554156887

Epoch: 5| Step: 7
Training loss: 0.7181165814399719
Validation loss: 2.0260650509147236

Epoch: 5| Step: 8
Training loss: 1.0440804958343506
Validation loss: 1.9558605417128532

Epoch: 5| Step: 9
Training loss: 0.8540754318237305
Validation loss: 1.9354244252686859

Epoch: 5| Step: 10
Training loss: 0.8746407628059387
Validation loss: 1.9160691461255472

Epoch: 210| Step: 0
Training loss: 1.0187722444534302
Validation loss: 1.950552619913573

Epoch: 5| Step: 1
Training loss: 0.7346686124801636
Validation loss: 2.0029014874530096

Epoch: 5| Step: 2
Training loss: 1.197801113128662
Validation loss: 2.026729558103828

Epoch: 5| Step: 3
Training loss: 0.8600668907165527
Validation loss: 2.0390404603814565

Epoch: 5| Step: 4
Training loss: 0.8835989832878113
Validation loss: 2.0803762071876117

Epoch: 5| Step: 5
Training loss: 1.0640861988067627
Validation loss: 2.0594356585574407

Epoch: 5| Step: 6
Training loss: 0.8056076169013977
Validation loss: 2.0440637347518757

Epoch: 5| Step: 7
Training loss: 0.5786710381507874
Validation loss: 1.9710059294136621

Epoch: 5| Step: 8
Training loss: 0.9398164749145508
Validation loss: 1.93475511253521

Epoch: 5| Step: 9
Training loss: 0.673523485660553
Validation loss: 1.926661688794372

Epoch: 5| Step: 10
Training loss: 1.3536765575408936
Validation loss: 1.9523731482926237

Epoch: 211| Step: 0
Training loss: 0.8962885737419128
Validation loss: 2.015679361999676

Epoch: 5| Step: 1
Training loss: 1.0238577127456665
Validation loss: 2.0441870266391384

Epoch: 5| Step: 2
Training loss: 0.7809724807739258
Validation loss: 2.045658398700017

Epoch: 5| Step: 3
Training loss: 0.7831999063491821
Validation loss: 2.0511262545021633

Epoch: 5| Step: 4
Training loss: 0.987011730670929
Validation loss: 2.0495630900065103

Epoch: 5| Step: 5
Training loss: 0.8600364923477173
Validation loss: 2.0025343202775523

Epoch: 5| Step: 6
Training loss: 1.249456763267517
Validation loss: 1.9880959962003975

Epoch: 5| Step: 7
Training loss: 0.5120532512664795
Validation loss: 1.974223344556747

Epoch: 5| Step: 8
Training loss: 0.9534443020820618
Validation loss: 2.0238536634752826

Epoch: 5| Step: 9
Training loss: 0.8599006533622742
Validation loss: 2.014465852450299

Epoch: 5| Step: 10
Training loss: 1.070168375968933
Validation loss: 2.0634615690477434

Epoch: 212| Step: 0
Training loss: 1.1086432933807373
Validation loss: 2.1119984196078394

Epoch: 5| Step: 1
Training loss: 1.0654423236846924
Validation loss: 2.1586823514712754

Epoch: 5| Step: 2
Training loss: 1.1046850681304932
Validation loss: 2.1596008962200535

Epoch: 5| Step: 3
Training loss: 1.0091675519943237
Validation loss: 2.0987781427239858

Epoch: 5| Step: 4
Training loss: 0.8367447853088379
Validation loss: 2.0401935090300856

Epoch: 5| Step: 5
Training loss: 1.210784673690796
Validation loss: 1.9508995625280565

Epoch: 5| Step: 6
Training loss: 0.6773471832275391
Validation loss: 1.912881858887211

Epoch: 5| Step: 7
Training loss: 0.8314350247383118
Validation loss: 1.8884844395422167

Epoch: 5| Step: 8
Training loss: 0.4831339716911316
Validation loss: 1.9101852191391813

Epoch: 5| Step: 9
Training loss: 0.8651254773139954
Validation loss: 1.9173985142861643

Epoch: 5| Step: 10
Training loss: 1.1095913648605347
Validation loss: 1.9550291915093698

Epoch: 213| Step: 0
Training loss: 0.9189794659614563
Validation loss: 2.0302350521087646

Epoch: 5| Step: 1
Training loss: 1.0037015676498413
Validation loss: 2.0994768988701606

Epoch: 5| Step: 2
Training loss: 1.2188007831573486
Validation loss: 2.1671403556741695

Epoch: 5| Step: 3
Training loss: 1.3233710527420044
Validation loss: 2.177133644780805

Epoch: 5| Step: 4
Training loss: 0.7429064512252808
Validation loss: 2.1219159915883052

Epoch: 5| Step: 5
Training loss: 1.3760353326797485
Validation loss: 2.115428602823647

Epoch: 5| Step: 6
Training loss: 0.7400914430618286
Validation loss: 2.0461085278500795

Epoch: 5| Step: 7
Training loss: 0.5179444551467896
Validation loss: 1.9935407792368243

Epoch: 5| Step: 8
Training loss: 0.8880316615104675
Validation loss: 1.9328504018886115

Epoch: 5| Step: 9
Training loss: 1.036897897720337
Validation loss: 1.9262211822694348

Epoch: 5| Step: 10
Training loss: 0.6175699830055237
Validation loss: 1.916028953367664

Epoch: 214| Step: 0
Training loss: 0.2699419856071472
Validation loss: 1.928237577920319

Epoch: 5| Step: 1
Training loss: 0.5230752825737
Validation loss: 1.9111271763360629

Epoch: 5| Step: 2
Training loss: 1.22810959815979
Validation loss: 1.9555732780887234

Epoch: 5| Step: 3
Training loss: 0.6525167226791382
Validation loss: 1.9613526841645599

Epoch: 5| Step: 4
Training loss: 1.5732847452163696
Validation loss: 1.904038510014934

Epoch: 5| Step: 5
Training loss: 0.8553321957588196
Validation loss: 1.922512028806953

Epoch: 5| Step: 6
Training loss: 0.9935666918754578
Validation loss: 1.955934114353631

Epoch: 5| Step: 7
Training loss: 0.8169366717338562
Validation loss: 1.996444543202718

Epoch: 5| Step: 8
Training loss: 1.1998740434646606
Validation loss: 2.061216059551444

Epoch: 5| Step: 9
Training loss: 1.1292498111724854
Validation loss: 2.0838233219679965

Epoch: 5| Step: 10
Training loss: 0.8272215127944946
Validation loss: 2.077419832188596

Epoch: 215| Step: 0
Training loss: 1.0900568962097168
Validation loss: 2.060374104848472

Epoch: 5| Step: 1
Training loss: 1.138136863708496
Validation loss: 2.0078040015312935

Epoch: 5| Step: 2
Training loss: 0.7599037885665894
Validation loss: 1.9694227044300368

Epoch: 5| Step: 3
Training loss: 1.0497150421142578
Validation loss: 1.9519307331372333

Epoch: 5| Step: 4
Training loss: 1.30611252784729
Validation loss: 1.95191123536838

Epoch: 5| Step: 5
Training loss: 0.7588880658149719
Validation loss: 1.9973410393602105

Epoch: 5| Step: 6
Training loss: 1.00074303150177
Validation loss: 2.0526585450736423

Epoch: 5| Step: 7
Training loss: 0.8659248352050781
Validation loss: 2.152674239168885

Epoch: 5| Step: 8
Training loss: 1.024979591369629
Validation loss: 2.1847287224185084

Epoch: 5| Step: 9
Training loss: 0.6070826649665833
Validation loss: 2.207431541976108

Epoch: 5| Step: 10
Training loss: 0.8242539167404175
Validation loss: 2.2107104280943513

Epoch: 216| Step: 0
Training loss: 0.7961186170578003
Validation loss: 2.1501395151179326

Epoch: 5| Step: 1
Training loss: 0.5401330590248108
Validation loss: 2.083325788538943

Epoch: 5| Step: 2
Training loss: 0.7048737406730652
Validation loss: 2.025248404472105

Epoch: 5| Step: 3
Training loss: 0.781407356262207
Validation loss: 2.000916507936293

Epoch: 5| Step: 4
Training loss: 0.8753345608711243
Validation loss: 1.9600764551470358

Epoch: 5| Step: 5
Training loss: 1.149236798286438
Validation loss: 1.9201483649592246

Epoch: 5| Step: 6
Training loss: 0.929996132850647
Validation loss: 1.9313616675715293

Epoch: 5| Step: 7
Training loss: 0.8908787965774536
Validation loss: 1.9157080150419665

Epoch: 5| Step: 8
Training loss: 0.8500563502311707
Validation loss: 1.9170419580192977

Epoch: 5| Step: 9
Training loss: 0.9881303906440735
Validation loss: 1.9666281156642462

Epoch: 5| Step: 10
Training loss: 1.3153964281082153
Validation loss: 2.001558783233807

Epoch: 217| Step: 0
Training loss: 0.6404474973678589
Validation loss: 2.0079295763405423

Epoch: 5| Step: 1
Training loss: 0.6978064775466919
Validation loss: 2.01775808359987

Epoch: 5| Step: 2
Training loss: 0.882860541343689
Validation loss: 2.007155867033107

Epoch: 5| Step: 3
Training loss: 0.9653209447860718
Validation loss: 1.960079235415305

Epoch: 5| Step: 4
Training loss: 0.9646576642990112
Validation loss: 1.8927598166209396

Epoch: 5| Step: 5
Training loss: 1.24616277217865
Validation loss: 1.9272786417315084

Epoch: 5| Step: 6
Training loss: 0.9572738409042358
Validation loss: 1.9071502839365313

Epoch: 5| Step: 7
Training loss: 1.0193841457366943
Validation loss: 1.9066384582109348

Epoch: 5| Step: 8
Training loss: 0.7056882381439209
Validation loss: 1.9215895898880497

Epoch: 5| Step: 9
Training loss: 0.6624807715415955
Validation loss: 1.9540403350707023

Epoch: 5| Step: 10
Training loss: 0.9344930648803711
Validation loss: 1.955214823445966

Epoch: 218| Step: 0
Training loss: 0.9893823862075806
Validation loss: 2.0206221393359605

Epoch: 5| Step: 1
Training loss: 0.7426841259002686
Validation loss: 2.05904435342358

Epoch: 5| Step: 2
Training loss: 0.6352395415306091
Validation loss: 2.06053332103196

Epoch: 5| Step: 3
Training loss: 0.9708662033081055
Validation loss: 2.0681909027919976

Epoch: 5| Step: 4
Training loss: 0.8725387454032898
Validation loss: 2.0525155836536038

Epoch: 5| Step: 5
Training loss: 0.8490196466445923
Validation loss: 2.0625632347599154

Epoch: 5| Step: 6
Training loss: 1.133965253829956
Validation loss: 2.0389364880900227

Epoch: 5| Step: 7
Training loss: 0.7977181673049927
Validation loss: 1.982009413421795

Epoch: 5| Step: 8
Training loss: 0.7822358012199402
Validation loss: 1.9728118206865044

Epoch: 5| Step: 9
Training loss: 0.8869715929031372
Validation loss: 1.9430244327873312

Epoch: 5| Step: 10
Training loss: 0.9446325898170471
Validation loss: 1.9829865719682427

Epoch: 219| Step: 0
Training loss: 1.1380159854888916
Validation loss: 2.0316863611180294

Epoch: 5| Step: 1
Training loss: 0.9898900985717773
Validation loss: 2.0272548865246516

Epoch: 5| Step: 2
Training loss: 1.1399853229522705
Validation loss: 2.0496540902763285

Epoch: 5| Step: 3
Training loss: 0.472850501537323
Validation loss: 2.0716682300772717

Epoch: 5| Step: 4
Training loss: 1.1563918590545654
Validation loss: 2.001193890007593

Epoch: 5| Step: 5
Training loss: 0.6825178861618042
Validation loss: 1.9782617566406087

Epoch: 5| Step: 6
Training loss: 0.7303819060325623
Validation loss: 1.9395080651006391

Epoch: 5| Step: 7
Training loss: 0.8722950220108032
Validation loss: 1.9335561926646898

Epoch: 5| Step: 8
Training loss: 0.8684471845626831
Validation loss: 1.944049850586922

Epoch: 5| Step: 9
Training loss: 0.865373969078064
Validation loss: 1.9228768899876585

Epoch: 5| Step: 10
Training loss: 1.0213994979858398
Validation loss: 1.9291757819473103

Epoch: 220| Step: 0
Training loss: 1.018471360206604
Validation loss: 1.9522792882816766

Epoch: 5| Step: 1
Training loss: 0.6372398138046265
Validation loss: 1.9715991148384668

Epoch: 5| Step: 2
Training loss: 0.7507553696632385
Validation loss: 2.000420726755614

Epoch: 5| Step: 3
Training loss: 0.7376527190208435
Validation loss: 2.0254056735705306

Epoch: 5| Step: 4
Training loss: 0.938535213470459
Validation loss: 2.057811188441451

Epoch: 5| Step: 5
Training loss: 0.9359081983566284
Validation loss: 2.064742006281371

Epoch: 5| Step: 6
Training loss: 0.8047443628311157
Validation loss: 2.0780975510997157

Epoch: 5| Step: 7
Training loss: 1.0257604122161865
Validation loss: 2.09134401300902

Epoch: 5| Step: 8
Training loss: 0.8844181299209595
Validation loss: 2.08664257039306

Epoch: 5| Step: 9
Training loss: 0.8112560510635376
Validation loss: 2.090514798318186

Epoch: 5| Step: 10
Training loss: 0.8302397131919861
Validation loss: 2.033316755807528

Epoch: 221| Step: 0
Training loss: 0.8848918676376343
Validation loss: 2.0074015625061525

Epoch: 5| Step: 1
Training loss: 1.0676815509796143
Validation loss: 2.0060841139926704

Epoch: 5| Step: 2
Training loss: 0.9839008450508118
Validation loss: 1.985646423473153

Epoch: 5| Step: 3
Training loss: 0.4840989112854004
Validation loss: 1.9632868664239043

Epoch: 5| Step: 4
Training loss: 0.9476500749588013
Validation loss: 1.962207676261984

Epoch: 5| Step: 5
Training loss: 1.042845368385315
Validation loss: 1.9381269639538181

Epoch: 5| Step: 6
Training loss: 0.9464647173881531
Validation loss: 1.9603052728919572

Epoch: 5| Step: 7
Training loss: 0.9556372761726379
Validation loss: 1.9629600304429249

Epoch: 5| Step: 8
Training loss: 0.7100821137428284
Validation loss: 2.0190992227164646

Epoch: 5| Step: 9
Training loss: 0.6209326982498169
Validation loss: 2.0617380372939573

Epoch: 5| Step: 10
Training loss: 0.5495598912239075
Validation loss: 2.0855732182020783

Epoch: 222| Step: 0
Training loss: 0.7279309034347534
Validation loss: 2.09565120614985

Epoch: 5| Step: 1
Training loss: 1.1135036945343018
Validation loss: 2.0814655532119093

Epoch: 5| Step: 2
Training loss: 0.7581335306167603
Validation loss: 2.01640074740174

Epoch: 5| Step: 3
Training loss: 1.045082449913025
Validation loss: 1.9951963258045975

Epoch: 5| Step: 4
Training loss: 0.5706402659416199
Validation loss: 1.9855948545599496

Epoch: 5| Step: 5
Training loss: 0.7861803770065308
Validation loss: 1.9195590660136232

Epoch: 5| Step: 6
Training loss: 0.7196404337882996
Validation loss: 1.9258472252917547

Epoch: 5| Step: 7
Training loss: 0.8464239239692688
Validation loss: 1.9356178186273063

Epoch: 5| Step: 8
Training loss: 0.7158563137054443
Validation loss: 1.946313661913718

Epoch: 5| Step: 9
Training loss: 0.9146650433540344
Validation loss: 1.983110999548307

Epoch: 5| Step: 10
Training loss: 0.9450761079788208
Validation loss: 2.004361516685896

Epoch: 223| Step: 0
Training loss: 0.7466166615486145
Validation loss: 2.0212395947466613

Epoch: 5| Step: 1
Training loss: 0.5751035809516907
Validation loss: 2.052814460569812

Epoch: 5| Step: 2
Training loss: 0.6781167984008789
Validation loss: 2.0640172240554646

Epoch: 5| Step: 3
Training loss: 0.5165894031524658
Validation loss: 2.0325201839529057

Epoch: 5| Step: 4
Training loss: 1.1963977813720703
Validation loss: 2.0377021643423263

Epoch: 5| Step: 5
Training loss: 0.4838787913322449
Validation loss: 2.0481873109776485

Epoch: 5| Step: 6
Training loss: 1.0267428159713745
Validation loss: 2.020594076443744

Epoch: 5| Step: 7
Training loss: 0.9261603355407715
Validation loss: 1.9884077002925258

Epoch: 5| Step: 8
Training loss: 0.9880725741386414
Validation loss: 1.9632266670145013

Epoch: 5| Step: 9
Training loss: 0.9664363861083984
Validation loss: 1.986877343987906

Epoch: 5| Step: 10
Training loss: 0.9171531200408936
Validation loss: 2.0008653184419036

Epoch: 224| Step: 0
Training loss: 0.4358242154121399
Validation loss: 1.953904249334848

Epoch: 5| Step: 1
Training loss: 0.8159307241439819
Validation loss: 1.931462308411957

Epoch: 5| Step: 2
Training loss: 0.8712233304977417
Validation loss: 1.9359996267544326

Epoch: 5| Step: 3
Training loss: 0.7082494497299194
Validation loss: 1.9421175526034447

Epoch: 5| Step: 4
Training loss: 1.0267915725708008
Validation loss: 1.9314454768293647

Epoch: 5| Step: 5
Training loss: 0.8538384437561035
Validation loss: 1.916787806377616

Epoch: 5| Step: 6
Training loss: 0.5998193621635437
Validation loss: 1.87935181074245

Epoch: 5| Step: 7
Training loss: 0.5995756387710571
Validation loss: 1.9086584301405056

Epoch: 5| Step: 8
Training loss: 1.181742548942566
Validation loss: 1.9420433582798127

Epoch: 5| Step: 9
Training loss: 0.6845259666442871
Validation loss: 1.9277921774054085

Epoch: 5| Step: 10
Training loss: 0.9588371515274048
Validation loss: 1.9514801322772939

Epoch: 225| Step: 0
Training loss: 0.9885527491569519
Validation loss: 1.9487703307982414

Epoch: 5| Step: 1
Training loss: 0.5514000654220581
Validation loss: 2.00299084314736

Epoch: 5| Step: 2
Training loss: 0.3843136131763458
Validation loss: 2.013148553909794

Epoch: 5| Step: 3
Training loss: 0.637576162815094
Validation loss: 2.048138241614065

Epoch: 5| Step: 4
Training loss: 0.808496356010437
Validation loss: 2.058527495271416

Epoch: 5| Step: 5
Training loss: 0.7464553713798523
Validation loss: 2.0284336959162066

Epoch: 5| Step: 6
Training loss: 0.7997469902038574
Validation loss: 1.988996167336741

Epoch: 5| Step: 7
Training loss: 1.1593749523162842
Validation loss: 1.9382966256910754

Epoch: 5| Step: 8
Training loss: 0.8329802751541138
Validation loss: 1.907477528818192

Epoch: 5| Step: 9
Training loss: 0.8838071823120117
Validation loss: 1.8908805667713124

Epoch: 5| Step: 10
Training loss: 0.7444978356361389
Validation loss: 1.8882961709012267

Epoch: 226| Step: 0
Training loss: 0.7382471561431885
Validation loss: 1.9303033531353038

Epoch: 5| Step: 1
Training loss: 0.677270233631134
Validation loss: 1.9501838427717968

Epoch: 5| Step: 2
Training loss: 0.7549920082092285
Validation loss: 2.0079210906900387

Epoch: 5| Step: 3
Training loss: 0.9797624349594116
Validation loss: 2.0384420297479116

Epoch: 5| Step: 4
Training loss: 0.8074819445610046
Validation loss: 2.0383380074654855

Epoch: 5| Step: 5
Training loss: 0.802478015422821
Validation loss: 2.0662917731910624

Epoch: 5| Step: 6
Training loss: 0.9610662460327148
Validation loss: 2.0360019976092922

Epoch: 5| Step: 7
Training loss: 0.7119086980819702
Validation loss: 1.9741126196358794

Epoch: 5| Step: 8
Training loss: 0.6616677641868591
Validation loss: 1.9152918784849104

Epoch: 5| Step: 9
Training loss: 0.6017948389053345
Validation loss: 1.8965009643185524

Epoch: 5| Step: 10
Training loss: 0.9772382378578186
Validation loss: 1.86674972503416

Epoch: 227| Step: 0
Training loss: 0.7672808766365051
Validation loss: 1.8579093871578094

Epoch: 5| Step: 1
Training loss: 0.6612848043441772
Validation loss: 1.8315756346589775

Epoch: 5| Step: 2
Training loss: 0.7747935056686401
Validation loss: 1.8353427545998686

Epoch: 5| Step: 3
Training loss: 0.8504778146743774
Validation loss: 1.8365270809460712

Epoch: 5| Step: 4
Training loss: 0.5317206382751465
Validation loss: 1.8811855469980547

Epoch: 5| Step: 5
Training loss: 0.5988883972167969
Validation loss: 1.911251316788376

Epoch: 5| Step: 6
Training loss: 1.0667647123336792
Validation loss: 1.940229017247436

Epoch: 5| Step: 7
Training loss: 0.905432403087616
Validation loss: 1.9030936969223844

Epoch: 5| Step: 8
Training loss: 0.6834756135940552
Validation loss: 1.9699321228970763

Epoch: 5| Step: 9
Training loss: 0.6723061203956604
Validation loss: 1.9882509926313996

Epoch: 5| Step: 10
Training loss: 1.1063181161880493
Validation loss: 1.9863950462751492

Epoch: 228| Step: 0
Training loss: 0.8882619142532349
Validation loss: 2.0062437083131526

Epoch: 5| Step: 1
Training loss: 0.655007004737854
Validation loss: 1.9934385566301243

Epoch: 5| Step: 2
Training loss: 0.6298958659172058
Validation loss: 1.991602583598065

Epoch: 5| Step: 3
Training loss: 0.5369600057601929
Validation loss: 1.9839447134284562

Epoch: 5| Step: 4
Training loss: 0.8062925338745117
Validation loss: 1.9897753961624638

Epoch: 5| Step: 5
Training loss: 0.5911208987236023
Validation loss: 1.9715483726993683

Epoch: 5| Step: 6
Training loss: 0.8118538856506348
Validation loss: 2.002190520686488

Epoch: 5| Step: 7
Training loss: 1.06363046169281
Validation loss: 1.9991351378861295

Epoch: 5| Step: 8
Training loss: 1.0232625007629395
Validation loss: 2.0015415735142206

Epoch: 5| Step: 9
Training loss: 0.6418063044548035
Validation loss: 1.9846832444590907

Epoch: 5| Step: 10
Training loss: 0.7899500727653503
Validation loss: 1.987409346847124

Epoch: 229| Step: 0
Training loss: 0.7847476601600647
Validation loss: 1.9516341186338855

Epoch: 5| Step: 1
Training loss: 0.764320433139801
Validation loss: 1.9498439335053968

Epoch: 5| Step: 2
Training loss: 0.8704622387886047
Validation loss: 1.9227781488049416

Epoch: 5| Step: 3
Training loss: 1.0870386362075806
Validation loss: 1.9297995310957714

Epoch: 5| Step: 4
Training loss: 0.6009043455123901
Validation loss: 1.938090612811427

Epoch: 5| Step: 5
Training loss: 0.910356879234314
Validation loss: 1.9046253952928769

Epoch: 5| Step: 6
Training loss: 0.6238760352134705
Validation loss: 1.9068026581118185

Epoch: 5| Step: 7
Training loss: 0.5943912863731384
Validation loss: 1.9238853608408282

Epoch: 5| Step: 8
Training loss: 0.4925600588321686
Validation loss: 1.9527108951281476

Epoch: 5| Step: 9
Training loss: 0.8569393157958984
Validation loss: 2.0417143119278776

Epoch: 5| Step: 10
Training loss: 1.1530691385269165
Validation loss: 2.0899692286727247

Epoch: 230| Step: 0
Training loss: 0.9874668121337891
Validation loss: 2.089791856786256

Epoch: 5| Step: 1
Training loss: 0.8255797624588013
Validation loss: 2.0968734718138173

Epoch: 5| Step: 2
Training loss: 0.6798385977745056
Validation loss: 2.0552617273023053

Epoch: 5| Step: 3
Training loss: 0.35740548372268677
Validation loss: 2.0207339307313323

Epoch: 5| Step: 4
Training loss: 0.7666704654693604
Validation loss: 1.9595743328012445

Epoch: 5| Step: 5
Training loss: 0.35326042771339417
Validation loss: 1.9198412779838807

Epoch: 5| Step: 6
Training loss: 0.9166349172592163
Validation loss: 1.8498676374394407

Epoch: 5| Step: 7
Training loss: 0.7903746366500854
Validation loss: 1.8457178197881228

Epoch: 5| Step: 8
Training loss: 0.7943295240402222
Validation loss: 1.8499952413702523

Epoch: 5| Step: 9
Training loss: 0.8158117532730103
Validation loss: 1.8430067044432445

Epoch: 5| Step: 10
Training loss: 1.247913122177124
Validation loss: 1.8423854907353718

Epoch: 231| Step: 0
Training loss: 0.3368980884552002
Validation loss: 1.8516341665739655

Epoch: 5| Step: 1
Training loss: 0.896560788154602
Validation loss: 1.8778070531865603

Epoch: 5| Step: 2
Training loss: 0.8006621599197388
Validation loss: 1.9152322635855725

Epoch: 5| Step: 3
Training loss: 0.7666411399841309
Validation loss: 1.9585700188913653

Epoch: 5| Step: 4
Training loss: 0.6554168462753296
Validation loss: 1.9982768207468011

Epoch: 5| Step: 5
Training loss: 1.1520421504974365
Validation loss: 2.0517477527741463

Epoch: 5| Step: 6
Training loss: 0.5882318019866943
Validation loss: 2.0403681698665825

Epoch: 5| Step: 7
Training loss: 0.8295947909355164
Validation loss: 1.974587381526988

Epoch: 5| Step: 8
Training loss: 1.268158197402954
Validation loss: 1.9353440089892315

Epoch: 5| Step: 9
Training loss: 0.6138033866882324
Validation loss: 1.9116265876318819

Epoch: 5| Step: 10
Training loss: 0.828384518623352
Validation loss: 1.9035685728955012

Epoch: 232| Step: 0
Training loss: 0.8781245946884155
Validation loss: 1.898377541572817

Epoch: 5| Step: 1
Training loss: 0.8300455212593079
Validation loss: 1.9252326103948778

Epoch: 5| Step: 2
Training loss: 0.9240239262580872
Validation loss: 1.911444866529075

Epoch: 5| Step: 3
Training loss: 0.7948466539382935
Validation loss: 1.9480898585370792

Epoch: 5| Step: 4
Training loss: 0.824303925037384
Validation loss: 1.9857284061370357

Epoch: 5| Step: 5
Training loss: 0.6935752034187317
Validation loss: 2.0384801241659347

Epoch: 5| Step: 6
Training loss: 0.5101562738418579
Validation loss: 2.049699282133451

Epoch: 5| Step: 7
Training loss: 0.9665234684944153
Validation loss: 2.0564444475276495

Epoch: 5| Step: 8
Training loss: 0.6473559737205505
Validation loss: 2.0653466563070975

Epoch: 5| Step: 9
Training loss: 0.7108481526374817
Validation loss: 2.0410547846107074

Epoch: 5| Step: 10
Training loss: 0.5337262749671936
Validation loss: 2.0306737064033427

Epoch: 233| Step: 0
Training loss: 0.7358226776123047
Validation loss: 2.0538916408374743

Epoch: 5| Step: 1
Training loss: 0.5506585836410522
Validation loss: 2.044019724733086

Epoch: 5| Step: 2
Training loss: 1.0189570188522339
Validation loss: 2.0447970872284262

Epoch: 5| Step: 3
Training loss: 0.5589242577552795
Validation loss: 2.0327924246429117

Epoch: 5| Step: 4
Training loss: 0.8227499723434448
Validation loss: 2.0033500386822607

Epoch: 5| Step: 5
Training loss: 0.8514171838760376
Validation loss: 1.9843856878178094

Epoch: 5| Step: 6
Training loss: 0.5047167539596558
Validation loss: 1.9852647768553866

Epoch: 5| Step: 7
Training loss: 1.0229753255844116
Validation loss: 1.9908724984815043

Epoch: 5| Step: 8
Training loss: 0.8435490727424622
Validation loss: 1.984155680543633

Epoch: 5| Step: 9
Training loss: 0.56587815284729
Validation loss: 2.0250220811495216

Epoch: 5| Step: 10
Training loss: 0.7659251093864441
Validation loss: 2.0826705617289387

Epoch: 234| Step: 0
Training loss: 0.8629026412963867
Validation loss: 2.032443772080124

Epoch: 5| Step: 1
Training loss: 0.7353366017341614
Validation loss: 2.0310127799228956

Epoch: 5| Step: 2
Training loss: 0.6760941743850708
Validation loss: 2.0382736754673783

Epoch: 5| Step: 3
Training loss: 0.7800143361091614
Validation loss: 2.008481776842507

Epoch: 5| Step: 4
Training loss: 0.6909445524215698
Validation loss: 1.9906316226528538

Epoch: 5| Step: 5
Training loss: 0.728662371635437
Validation loss: 1.9490925496624363

Epoch: 5| Step: 6
Training loss: 0.9522703886032104
Validation loss: 1.9418004943478493

Epoch: 5| Step: 7
Training loss: 0.6343083381652832
Validation loss: 1.949174727163007

Epoch: 5| Step: 8
Training loss: 0.4385947287082672
Validation loss: 1.9578060924365956

Epoch: 5| Step: 9
Training loss: 0.8994849324226379
Validation loss: 1.9820941071356497

Epoch: 5| Step: 10
Training loss: 0.49799644947052
Validation loss: 1.9703073347768476

Epoch: 235| Step: 0
Training loss: 0.6006183624267578
Validation loss: 1.9681037779777282

Epoch: 5| Step: 1
Training loss: 0.772397518157959
Validation loss: 1.9600918715999973

Epoch: 5| Step: 2
Training loss: 0.7131054997444153
Validation loss: 1.97081006726911

Epoch: 5| Step: 3
Training loss: 0.45431384444236755
Validation loss: 2.014078729896135

Epoch: 5| Step: 4
Training loss: 0.8104807734489441
Validation loss: 2.019945135680578

Epoch: 5| Step: 5
Training loss: 0.5981951951980591
Validation loss: 1.9911562652998074

Epoch: 5| Step: 6
Training loss: 0.8474337458610535
Validation loss: 1.972180574811915

Epoch: 5| Step: 7
Training loss: 1.4073069095611572
Validation loss: 2.0176726579666138

Epoch: 5| Step: 8
Training loss: 0.46382689476013184
Validation loss: 2.0107912119998725

Epoch: 5| Step: 9
Training loss: 0.6458431482315063
Validation loss: 2.0150468785275697

Epoch: 5| Step: 10
Training loss: 0.5171112418174744
Validation loss: 2.0280713419760428

Epoch: 236| Step: 0
Training loss: 0.8704522252082825
Validation loss: 2.019921753996162

Epoch: 5| Step: 1
Training loss: 0.8154910802841187
Validation loss: 2.030667519056669

Epoch: 5| Step: 2
Training loss: 0.6486445069313049
Validation loss: 2.0283408908433813

Epoch: 5| Step: 3
Training loss: 0.8127856254577637
Validation loss: 1.992767059674827

Epoch: 5| Step: 4
Training loss: 0.6178444623947144
Validation loss: 1.9547619153094549

Epoch: 5| Step: 5
Training loss: 0.5962862372398376
Validation loss: 1.9347086132213633

Epoch: 5| Step: 6
Training loss: 0.5038630366325378
Validation loss: 1.884511581031225

Epoch: 5| Step: 7
Training loss: 0.7942266464233398
Validation loss: 1.9071795684035107

Epoch: 5| Step: 8
Training loss: 0.4912549555301666
Validation loss: 1.9464581486999348

Epoch: 5| Step: 9
Training loss: 0.9889397621154785
Validation loss: 1.9939212799072266

Epoch: 5| Step: 10
Training loss: 0.6725773811340332
Validation loss: 2.0456976249653804

Epoch: 237| Step: 0
Training loss: 0.42954230308532715
Validation loss: 2.083803738317182

Epoch: 5| Step: 1
Training loss: 0.8601251840591431
Validation loss: 2.1089162775265273

Epoch: 5| Step: 2
Training loss: 0.7334367632865906
Validation loss: 2.1163390336498136

Epoch: 5| Step: 3
Training loss: 0.8502017259597778
Validation loss: 2.084290776201474

Epoch: 5| Step: 4
Training loss: 0.9339081645011902
Validation loss: 2.0592036426708265

Epoch: 5| Step: 5
Training loss: 0.5306798815727234
Validation loss: 1.9761144063806022

Epoch: 5| Step: 6
Training loss: 0.6149367094039917
Validation loss: 1.907114605749807

Epoch: 5| Step: 7
Training loss: 0.5600017309188843
Validation loss: 1.880432859543831

Epoch: 5| Step: 8
Training loss: 0.710658848285675
Validation loss: 1.8633074504072948

Epoch: 5| Step: 9
Training loss: 0.7327560782432556
Validation loss: 1.8770997267897411

Epoch: 5| Step: 10
Training loss: 1.1329227685928345
Validation loss: 1.8549973785236318

Epoch: 238| Step: 0
Training loss: 0.7778145670890808
Validation loss: 1.8758565507909304

Epoch: 5| Step: 1
Training loss: 0.5602750182151794
Validation loss: 1.8902200229706303

Epoch: 5| Step: 2
Training loss: 0.8973183631896973
Validation loss: 1.9299399647661435

Epoch: 5| Step: 3
Training loss: 0.8386303782463074
Validation loss: 1.9723351014557706

Epoch: 5| Step: 4
Training loss: 0.5536633729934692
Validation loss: 2.0276870419902187

Epoch: 5| Step: 5
Training loss: 0.6682072877883911
Validation loss: 1.99502904312585

Epoch: 5| Step: 6
Training loss: 0.5531615018844604
Validation loss: 1.970914561261413

Epoch: 5| Step: 7
Training loss: 0.8697242736816406
Validation loss: 1.9331363362650718

Epoch: 5| Step: 8
Training loss: 0.5928283929824829
Validation loss: 1.917161476227545

Epoch: 5| Step: 9
Training loss: 0.9997264742851257
Validation loss: 1.9392173777344406

Epoch: 5| Step: 10
Training loss: 0.6712844967842102
Validation loss: 1.9619156006843812

Epoch: 239| Step: 0
Training loss: 0.6367776989936829
Validation loss: 1.9549792658898137

Epoch: 5| Step: 1
Training loss: 0.992185115814209
Validation loss: 1.9804689627821728

Epoch: 5| Step: 2
Training loss: 0.6738781332969666
Validation loss: 1.9957663551453622

Epoch: 5| Step: 3
Training loss: 0.865141749382019
Validation loss: 1.9960471109677387

Epoch: 5| Step: 4
Training loss: 0.5565664768218994
Validation loss: 2.0062278739867674

Epoch: 5| Step: 5
Training loss: 1.0180505514144897
Validation loss: 2.0031162333744827

Epoch: 5| Step: 6
Training loss: 0.6063491702079773
Validation loss: 2.0191073712482246

Epoch: 5| Step: 7
Training loss: 0.6079210638999939
Validation loss: 1.9875985230168989

Epoch: 5| Step: 8
Training loss: 0.28959810733795166
Validation loss: 1.9888123184122064

Epoch: 5| Step: 9
Training loss: 0.6022727489471436
Validation loss: 2.00527105023784

Epoch: 5| Step: 10
Training loss: 0.9460650086402893
Validation loss: 1.9596422128779913

Epoch: 240| Step: 0
Training loss: 0.9397333860397339
Validation loss: 1.9168796488033828

Epoch: 5| Step: 1
Training loss: 0.6322848200798035
Validation loss: 1.8972699026907645

Epoch: 5| Step: 2
Training loss: 1.0114638805389404
Validation loss: 1.884500362539804

Epoch: 5| Step: 3
Training loss: 0.5011817812919617
Validation loss: 1.8915121670692199

Epoch: 5| Step: 4
Training loss: 0.5715559124946594
Validation loss: 1.8820118878477363

Epoch: 5| Step: 5
Training loss: 0.7474035024642944
Validation loss: 1.9112907263540453

Epoch: 5| Step: 6
Training loss: 0.6460939645767212
Validation loss: 1.9337637885924308

Epoch: 5| Step: 7
Training loss: 0.7212575078010559
Validation loss: 1.944206133965523

Epoch: 5| Step: 8
Training loss: 0.8523808717727661
Validation loss: 2.0050992581152145

Epoch: 5| Step: 9
Training loss: 0.528983473777771
Validation loss: 2.0418077720108854

Epoch: 5| Step: 10
Training loss: 0.514366865158081
Validation loss: 2.062119876184771

Epoch: 241| Step: 0
Training loss: 0.8069086074829102
Validation loss: 2.053763844633615

Epoch: 5| Step: 1
Training loss: 0.5578166842460632
Validation loss: 2.007225173775868

Epoch: 5| Step: 2
Training loss: 0.6067260503768921
Validation loss: 2.0559930698845976

Epoch: 5| Step: 3
Training loss: 1.0020349025726318
Validation loss: 1.9994641221979612

Epoch: 5| Step: 4
Training loss: 0.5992168188095093
Validation loss: 1.969693273626348

Epoch: 5| Step: 5
Training loss: 0.8240011930465698
Validation loss: 1.976837186403172

Epoch: 5| Step: 6
Training loss: 0.5815402269363403
Validation loss: 1.9616962658461703

Epoch: 5| Step: 7
Training loss: 0.5005649328231812
Validation loss: 1.9752561212867819

Epoch: 5| Step: 8
Training loss: 0.8323294520378113
Validation loss: 1.9864253690165858

Epoch: 5| Step: 9
Training loss: 0.5870771408081055
Validation loss: 2.001161672735727

Epoch: 5| Step: 10
Training loss: 0.5494826436042786
Validation loss: 1.9763992858189408

Epoch: 242| Step: 0
Training loss: 0.8818519711494446
Validation loss: 1.9906674328670706

Epoch: 5| Step: 1
Training loss: 0.3855922222137451
Validation loss: 2.0058962234886746

Epoch: 5| Step: 2
Training loss: 0.9207577705383301
Validation loss: 2.017463352090569

Epoch: 5| Step: 3
Training loss: 0.5311114192008972
Validation loss: 2.0217869858587942

Epoch: 5| Step: 4
Training loss: 0.8765900731086731
Validation loss: 1.9732813553143573

Epoch: 5| Step: 5
Training loss: 0.6546851992607117
Validation loss: 1.9367026808441326

Epoch: 5| Step: 6
Training loss: 0.6626880168914795
Validation loss: 1.9346579813188123

Epoch: 5| Step: 7
Training loss: 0.7425154447555542
Validation loss: 1.954397577111439

Epoch: 5| Step: 8
Training loss: 0.5776468515396118
Validation loss: 1.9449536697838896

Epoch: 5| Step: 9
Training loss: 0.7622631788253784
Validation loss: 1.9247833657008346

Epoch: 5| Step: 10
Training loss: 0.6071399450302124
Validation loss: 1.9230363112623974

Epoch: 243| Step: 0
Training loss: 0.6862956285476685
Validation loss: 1.893731403094466

Epoch: 5| Step: 1
Training loss: 0.23344950377941132
Validation loss: 1.9242565183229343

Epoch: 5| Step: 2
Training loss: 1.3595950603485107
Validation loss: 1.9084958671241679

Epoch: 5| Step: 3
Training loss: 0.4719432294368744
Validation loss: 1.918806847705636

Epoch: 5| Step: 4
Training loss: 0.6298991441726685
Validation loss: 1.9470749747368596

Epoch: 5| Step: 5
Training loss: 0.7022101283073425
Validation loss: 1.9828585758004138

Epoch: 5| Step: 6
Training loss: 0.6582855582237244
Validation loss: 2.01424120062141

Epoch: 5| Step: 7
Training loss: 0.44801053404808044
Validation loss: 2.033327994808074

Epoch: 5| Step: 8
Training loss: 0.8551095128059387
Validation loss: 2.0576271421165875

Epoch: 5| Step: 9
Training loss: 0.6790162920951843
Validation loss: 2.0408306326917423

Epoch: 5| Step: 10
Training loss: 0.8510846495628357
Validation loss: 2.0291686878409436

Epoch: 244| Step: 0
Training loss: 0.7076224088668823
Validation loss: 1.9994731398038967

Epoch: 5| Step: 1
Training loss: 0.9390031695365906
Validation loss: 1.9636562908849409

Epoch: 5| Step: 2
Training loss: 0.5065472722053528
Validation loss: 1.9017152863164102

Epoch: 5| Step: 3
Training loss: 0.7316827178001404
Validation loss: 1.8843024610191264

Epoch: 5| Step: 4
Training loss: 0.5671185255050659
Validation loss: 1.8730715654229606

Epoch: 5| Step: 5
Training loss: 1.3408548831939697
Validation loss: 1.8666583440637077

Epoch: 5| Step: 6
Training loss: 0.5987199544906616
Validation loss: 1.9121454018418507

Epoch: 5| Step: 7
Training loss: 0.6973940134048462
Validation loss: 1.9577956763646935

Epoch: 5| Step: 8
Training loss: 0.5155991911888123
Validation loss: 1.981412850400453

Epoch: 5| Step: 9
Training loss: 0.44578561186790466
Validation loss: 2.0344992581234185

Epoch: 5| Step: 10
Training loss: 0.34838762879371643
Validation loss: 2.0435638581552813

Epoch: 245| Step: 0
Training loss: 0.9231823086738586
Validation loss: 2.044644650592599

Epoch: 5| Step: 1
Training loss: 0.49103522300720215
Validation loss: 2.0531492502458635

Epoch: 5| Step: 2
Training loss: 0.6259133219718933
Validation loss: 2.0433944374002437

Epoch: 5| Step: 3
Training loss: 0.8133237957954407
Validation loss: 2.0260598121150846

Epoch: 5| Step: 4
Training loss: 0.5599849820137024
Validation loss: 1.987243374188741

Epoch: 5| Step: 5
Training loss: 0.6846426725387573
Validation loss: 1.9537667356511599

Epoch: 5| Step: 6
Training loss: 0.7370160222053528
Validation loss: 1.9245706860737135

Epoch: 5| Step: 7
Training loss: 0.8211883306503296
Validation loss: 1.8975349228869203

Epoch: 5| Step: 8
Training loss: 0.5978325009346008
Validation loss: 1.8892573938574841

Epoch: 5| Step: 9
Training loss: 0.561991810798645
Validation loss: 1.8779259010027813

Epoch: 5| Step: 10
Training loss: 0.5538102984428406
Validation loss: 1.89525983923225

Epoch: 246| Step: 0
Training loss: 0.7531726956367493
Validation loss: 1.955399146644018

Epoch: 5| Step: 1
Training loss: 0.3090140223503113
Validation loss: 2.084590963138047

Epoch: 5| Step: 2
Training loss: 0.53014075756073
Validation loss: 2.125568428347188

Epoch: 5| Step: 3
Training loss: 1.2421667575836182
Validation loss: 2.1691796728359756

Epoch: 5| Step: 4
Training loss: 0.9585176706314087
Validation loss: 2.215865845321327

Epoch: 5| Step: 5
Training loss: 0.934042751789093
Validation loss: 2.171787936200378

Epoch: 5| Step: 6
Training loss: 0.5831124186515808
Validation loss: 2.100374537129556

Epoch: 5| Step: 7
Training loss: 0.5271664261817932
Validation loss: 2.028658696400222

Epoch: 5| Step: 8
Training loss: 0.609408974647522
Validation loss: 1.9718760572453982

Epoch: 5| Step: 9
Training loss: 0.5762691497802734
Validation loss: 1.911619419692665

Epoch: 5| Step: 10
Training loss: 0.7235872745513916
Validation loss: 1.90014809818678

Epoch: 247| Step: 0
Training loss: 0.46531468629837036
Validation loss: 1.856060718977323

Epoch: 5| Step: 1
Training loss: 0.9645570516586304
Validation loss: 1.8413221374634774

Epoch: 5| Step: 2
Training loss: 0.46092477440834045
Validation loss: 1.8500318834858556

Epoch: 5| Step: 3
Training loss: 0.5551594495773315
Validation loss: 1.8619538917336413

Epoch: 5| Step: 4
Training loss: 0.8029516339302063
Validation loss: 1.877695962946902

Epoch: 5| Step: 5
Training loss: 0.7368951439857483
Validation loss: 1.9233487357375443

Epoch: 5| Step: 6
Training loss: 0.7930272817611694
Validation loss: 1.9212074382330782

Epoch: 5| Step: 7
Training loss: 0.73060542345047
Validation loss: 1.9215407679157872

Epoch: 5| Step: 8
Training loss: 0.6583055853843689
Validation loss: 1.962479899006505

Epoch: 5| Step: 9
Training loss: 0.5667858123779297
Validation loss: 1.92959120709409

Epoch: 5| Step: 10
Training loss: 0.40928027033805847
Validation loss: 1.9651092803606423

Epoch: 248| Step: 0
Training loss: 0.49985751509666443
Validation loss: 1.9468654765877673

Epoch: 5| Step: 1
Training loss: 0.531965970993042
Validation loss: 1.9540965493007372

Epoch: 5| Step: 2
Training loss: 0.6408647298812866
Validation loss: 1.9354128786312637

Epoch: 5| Step: 3
Training loss: 0.4792935252189636
Validation loss: 1.9471066087804816

Epoch: 5| Step: 4
Training loss: 0.9040643572807312
Validation loss: 1.9156575113214471

Epoch: 5| Step: 5
Training loss: 0.4119020402431488
Validation loss: 1.8803881227329213

Epoch: 5| Step: 6
Training loss: 0.8473876118659973
Validation loss: 1.8629556766120337

Epoch: 5| Step: 7
Training loss: 0.9608576893806458
Validation loss: 1.8707697776056105

Epoch: 5| Step: 8
Training loss: 0.6195932626724243
Validation loss: 1.8423499163760935

Epoch: 5| Step: 9
Training loss: 0.7054299712181091
Validation loss: 1.8403170518977667

Epoch: 5| Step: 10
Training loss: 0.5158989429473877
Validation loss: 1.8441750452082644

Epoch: 249| Step: 0
Training loss: 0.9437289237976074
Validation loss: 1.868102604343045

Epoch: 5| Step: 1
Training loss: 0.3565745949745178
Validation loss: 1.8761898779099988

Epoch: 5| Step: 2
Training loss: 0.46453800797462463
Validation loss: 1.9054570159604471

Epoch: 5| Step: 3
Training loss: 0.689781665802002
Validation loss: 1.952847444882957

Epoch: 5| Step: 4
Training loss: 0.6047285795211792
Validation loss: 1.9590792309853338

Epoch: 5| Step: 5
Training loss: 0.8444412350654602
Validation loss: 1.995596867735668

Epoch: 5| Step: 6
Training loss: 0.48500609397888184
Validation loss: 2.024260263289175

Epoch: 5| Step: 7
Training loss: 0.8214331865310669
Validation loss: 1.9867031305067

Epoch: 5| Step: 8
Training loss: 0.7425141334533691
Validation loss: 1.987438601832236

Epoch: 5| Step: 9
Training loss: 0.5227304100990295
Validation loss: 1.938451502912788

Epoch: 5| Step: 10
Training loss: 0.22927318513393402
Validation loss: 1.9058599190045429

Epoch: 250| Step: 0
Training loss: 0.6126554012298584
Validation loss: 1.9030614386322677

Epoch: 5| Step: 1
Training loss: 0.825425922870636
Validation loss: 1.9230562768956667

Epoch: 5| Step: 2
Training loss: 0.531702995300293
Validation loss: 1.920856673230407

Epoch: 5| Step: 3
Training loss: 0.8621460199356079
Validation loss: 1.9595318122576642

Epoch: 5| Step: 4
Training loss: 0.5533331036567688
Validation loss: 1.9586554355518793

Epoch: 5| Step: 5
Training loss: 0.5373960137367249
Validation loss: 2.009750784084361

Epoch: 5| Step: 6
Training loss: 0.6336839199066162
Validation loss: 1.9820771883892756

Epoch: 5| Step: 7
Training loss: 0.5945640802383423
Validation loss: 1.9861455784049085

Epoch: 5| Step: 8
Training loss: 0.5848630666732788
Validation loss: 1.9643691355182278

Epoch: 5| Step: 9
Training loss: 0.6192057132720947
Validation loss: 1.991551831204404

Epoch: 5| Step: 10
Training loss: 0.6729011535644531
Validation loss: 1.9523340091910413

Epoch: 251| Step: 0
Training loss: 0.3462609648704529
Validation loss: 1.9367010298595633

Epoch: 5| Step: 1
Training loss: 0.7147547006607056
Validation loss: 1.8958737234915457

Epoch: 5| Step: 2
Training loss: 0.4541512429714203
Validation loss: 1.8667763971513318

Epoch: 5| Step: 3
Training loss: 0.6029733419418335
Validation loss: 1.8578461857252224

Epoch: 5| Step: 4
Training loss: 0.7146089673042297
Validation loss: 1.9044620144751765

Epoch: 5| Step: 5
Training loss: 0.9662199020385742
Validation loss: 1.9247557399093465

Epoch: 5| Step: 6
Training loss: 0.3002830147743225
Validation loss: 1.9204159795597036

Epoch: 5| Step: 7
Training loss: 0.7823540568351746
Validation loss: 1.9535211081145911

Epoch: 5| Step: 8
Training loss: 0.4831036627292633
Validation loss: 1.9921480096796507

Epoch: 5| Step: 9
Training loss: 0.8089755773544312
Validation loss: 2.014823341882357

Epoch: 5| Step: 10
Training loss: 0.5714027285575867
Validation loss: 2.03690367872997

Epoch: 252| Step: 0
Training loss: 0.7376250624656677
Validation loss: 2.0304670820954027

Epoch: 5| Step: 1
Training loss: 0.8665720224380493
Validation loss: 2.0352013072659894

Epoch: 5| Step: 2
Training loss: 0.5172484517097473
Validation loss: 2.0055082459603586

Epoch: 5| Step: 3
Training loss: 0.7385365962982178
Validation loss: 1.9884971623779626

Epoch: 5| Step: 4
Training loss: 0.5626351237297058
Validation loss: 1.95710253202787

Epoch: 5| Step: 5
Training loss: 0.8427833318710327
Validation loss: 1.9250227007814633

Epoch: 5| Step: 6
Training loss: 0.2912134826183319
Validation loss: 1.9456085210205407

Epoch: 5| Step: 7
Training loss: 0.4832018315792084
Validation loss: 1.927850736725715

Epoch: 5| Step: 8
Training loss: 0.5826918482780457
Validation loss: 1.9450151612681728

Epoch: 5| Step: 9
Training loss: 0.318558007478714
Validation loss: 1.9660784608574324

Epoch: 5| Step: 10
Training loss: 0.6202706694602966
Validation loss: 1.9635718560987903

Epoch: 253| Step: 0
Training loss: 0.3703066408634186
Validation loss: 1.9981029700207453

Epoch: 5| Step: 1
Training loss: 0.6685439348220825
Validation loss: 1.9731086736084313

Epoch: 5| Step: 2
Training loss: 0.5020428895950317
Validation loss: 1.9755093730906004

Epoch: 5| Step: 3
Training loss: 0.7081793546676636
Validation loss: 1.940392699292911

Epoch: 5| Step: 4
Training loss: 0.36628302931785583
Validation loss: 1.9724908400607366

Epoch: 5| Step: 5
Training loss: 0.7411225438117981
Validation loss: 1.9455488856120775

Epoch: 5| Step: 6
Training loss: 0.47877606749534607
Validation loss: 1.9650397839084748

Epoch: 5| Step: 7
Training loss: 0.559467077255249
Validation loss: 1.9118880046311246

Epoch: 5| Step: 8
Training loss: 0.5439521074295044
Validation loss: 1.8695713473904518

Epoch: 5| Step: 9
Training loss: 0.6089476346969604
Validation loss: 1.8605880737304688

Epoch: 5| Step: 10
Training loss: 1.102735161781311
Validation loss: 1.8520348200234034

Epoch: 254| Step: 0
Training loss: 0.5611656904220581
Validation loss: 1.877313990746775

Epoch: 5| Step: 1
Training loss: 0.45936012268066406
Validation loss: 1.9001987877712454

Epoch: 5| Step: 2
Training loss: 0.48874521255493164
Validation loss: 1.9332158411702802

Epoch: 5| Step: 3
Training loss: 0.7542948722839355
Validation loss: 1.9237588477391068

Epoch: 5| Step: 4
Training loss: 0.9791731834411621
Validation loss: 1.9492574250826271

Epoch: 5| Step: 5
Training loss: 0.6392285823822021
Validation loss: 1.9513819909864856

Epoch: 5| Step: 6
Training loss: 0.7865614891052246
Validation loss: 1.9568709622147262

Epoch: 5| Step: 7
Training loss: 0.36393946409225464
Validation loss: 1.9398965733025664

Epoch: 5| Step: 8
Training loss: 0.49055153131484985
Validation loss: 1.924664323047925

Epoch: 5| Step: 9
Training loss: 0.5482888221740723
Validation loss: 1.9193674287488383

Epoch: 5| Step: 10
Training loss: 0.5908268690109253
Validation loss: 1.9017484059897802

Epoch: 255| Step: 0
Training loss: 0.6928293108940125
Validation loss: 1.9192044222226707

Epoch: 5| Step: 1
Training loss: 0.6392654180526733
Validation loss: 1.9215695909274522

Epoch: 5| Step: 2
Training loss: 0.3883594572544098
Validation loss: 1.9400253398444063

Epoch: 5| Step: 3
Training loss: 0.5439375042915344
Validation loss: 1.9504993782248548

Epoch: 5| Step: 4
Training loss: 0.6689852476119995
Validation loss: 1.9756703927952757

Epoch: 5| Step: 5
Training loss: 0.8272029757499695
Validation loss: 1.9711941672909645

Epoch: 5| Step: 6
Training loss: 0.14192141592502594
Validation loss: 1.9715392653660109

Epoch: 5| Step: 7
Training loss: 0.724458634853363
Validation loss: 1.9604597527493712

Epoch: 5| Step: 8
Training loss: 0.614692747592926
Validation loss: 1.9702413210304834

Epoch: 5| Step: 9
Training loss: 0.4490010142326355
Validation loss: 1.9988333230377526

Epoch: 5| Step: 10
Training loss: 0.6139016151428223
Validation loss: 1.9843996570956322

Epoch: 256| Step: 0
Training loss: 0.6655764579772949
Validation loss: 2.015468615357594

Epoch: 5| Step: 1
Training loss: 0.49784421920776367
Validation loss: 1.9824469397144933

Epoch: 5| Step: 2
Training loss: 0.5395092368125916
Validation loss: 1.949763213434527

Epoch: 5| Step: 3
Training loss: 0.7852126955986023
Validation loss: 1.9423593359608804

Epoch: 5| Step: 4
Training loss: 0.37240561842918396
Validation loss: 1.925977817145727

Epoch: 5| Step: 5
Training loss: 0.6826465129852295
Validation loss: 1.9165792760028635

Epoch: 5| Step: 6
Training loss: 0.5346870422363281
Validation loss: 1.9387426696797854

Epoch: 5| Step: 7
Training loss: 0.45263928174972534
Validation loss: 1.9284461877679313

Epoch: 5| Step: 8
Training loss: 0.6073666214942932
Validation loss: 1.9201099590588642

Epoch: 5| Step: 9
Training loss: 0.4649001955986023
Validation loss: 1.9239295528781029

Epoch: 5| Step: 10
Training loss: 0.7056105136871338
Validation loss: 1.9254776867487098

Epoch: 257| Step: 0
Training loss: 0.5710989832878113
Validation loss: 1.9266626091413601

Epoch: 5| Step: 1
Training loss: 0.3761088252067566
Validation loss: 1.945902096327915

Epoch: 5| Step: 2
Training loss: 0.4447755813598633
Validation loss: 1.9786515389719317

Epoch: 5| Step: 3
Training loss: 0.5908988118171692
Validation loss: 1.9888274708101827

Epoch: 5| Step: 4
Training loss: 0.3780639171600342
Validation loss: 1.945118882322824

Epoch: 5| Step: 5
Training loss: 0.73524010181427
Validation loss: 1.9664871359384188

Epoch: 5| Step: 6
Training loss: 0.7078894376754761
Validation loss: 1.9047634011955672

Epoch: 5| Step: 7
Training loss: 0.7848984003067017
Validation loss: 1.9200516644344534

Epoch: 5| Step: 8
Training loss: 0.5686808824539185
Validation loss: 1.912994412965672

Epoch: 5| Step: 9
Training loss: 0.38555222749710083
Validation loss: 1.9412532519268733

Epoch: 5| Step: 10
Training loss: 0.7937077879905701
Validation loss: 1.9639437916458293

Epoch: 258| Step: 0
Training loss: 0.3546968102455139
Validation loss: 1.9199132470674412

Epoch: 5| Step: 1
Training loss: 0.6098463535308838
Validation loss: 1.9481660025094145

Epoch: 5| Step: 2
Training loss: 0.6542762517929077
Validation loss: 1.9059410069578437

Epoch: 5| Step: 3
Training loss: 0.350521981716156
Validation loss: 1.912157202279696

Epoch: 5| Step: 4
Training loss: 0.6067476868629456
Validation loss: 1.869093164320915

Epoch: 5| Step: 5
Training loss: 0.694312572479248
Validation loss: 1.8509376113132765

Epoch: 5| Step: 6
Training loss: 0.5437237024307251
Validation loss: 1.8541308449160667

Epoch: 5| Step: 7
Training loss: 0.5145761370658875
Validation loss: 1.8231825226096696

Epoch: 5| Step: 8
Training loss: 0.6591870188713074
Validation loss: 1.8162615068497197

Epoch: 5| Step: 9
Training loss: 0.5963736176490784
Validation loss: 1.8103306165305517

Epoch: 5| Step: 10
Training loss: 0.7830768823623657
Validation loss: 1.858623722548126

Epoch: 259| Step: 0
Training loss: 0.3883368968963623
Validation loss: 1.9351631236332718

Epoch: 5| Step: 1
Training loss: 0.6186385750770569
Validation loss: 1.9346282661602061

Epoch: 5| Step: 2
Training loss: 0.5186051726341248
Validation loss: 1.9880647351664882

Epoch: 5| Step: 3
Training loss: 0.3770975172519684
Validation loss: 2.02165073861358

Epoch: 5| Step: 4
Training loss: 0.6453309059143066
Validation loss: 2.0099592093498475

Epoch: 5| Step: 5
Training loss: 0.5582624673843384
Validation loss: 1.973971479682512

Epoch: 5| Step: 6
Training loss: 0.7780241370201111
Validation loss: 1.9440129892800444

Epoch: 5| Step: 7
Training loss: 0.5940119028091431
Validation loss: 1.9323949903570197

Epoch: 5| Step: 8
Training loss: 0.6477406620979309
Validation loss: 1.9035450156017015

Epoch: 5| Step: 9
Training loss: 0.7682548761367798
Validation loss: 1.886920529027139

Epoch: 5| Step: 10
Training loss: 0.6077026128768921
Validation loss: 1.8858799126840406

Epoch: 260| Step: 0
Training loss: 0.7194325923919678
Validation loss: 1.9141820194900676

Epoch: 5| Step: 1
Training loss: 0.40370312333106995
Validation loss: 1.940816722890382

Epoch: 5| Step: 2
Training loss: 0.9314996004104614
Validation loss: 1.9576560322956373

Epoch: 5| Step: 3
Training loss: 0.5622744560241699
Validation loss: 1.9758808600005282

Epoch: 5| Step: 4
Training loss: 0.4465537667274475
Validation loss: 2.0119285609132502

Epoch: 5| Step: 5
Training loss: 0.4933319687843323
Validation loss: 2.009582181130686

Epoch: 5| Step: 6
Training loss: 0.6790732145309448
Validation loss: 1.9982704565089235

Epoch: 5| Step: 7
Training loss: 0.7188507318496704
Validation loss: 2.0090278938252437

Epoch: 5| Step: 8
Training loss: 0.5822988748550415
Validation loss: 1.9820211100321945

Epoch: 5| Step: 9
Training loss: 0.25419357419013977
Validation loss: 1.9592367782387683

Epoch: 5| Step: 10
Training loss: 0.42719417810440063
Validation loss: 1.9336764825287687

Epoch: 261| Step: 0
Training loss: 0.74012291431427
Validation loss: 1.9127693996634534

Epoch: 5| Step: 1
Training loss: 0.22702667117118835
Validation loss: 1.9126920674436836

Epoch: 5| Step: 2
Training loss: 0.45278844237327576
Validation loss: 1.8953575536768923

Epoch: 5| Step: 3
Training loss: 0.633837103843689
Validation loss: 1.9236360044889553

Epoch: 5| Step: 4
Training loss: 0.3929761052131653
Validation loss: 1.920324376834336

Epoch: 5| Step: 5
Training loss: 0.6170068979263306
Validation loss: 1.934932654903781

Epoch: 5| Step: 6
Training loss: 0.32522308826446533
Validation loss: 1.9597497806754163

Epoch: 5| Step: 7
Training loss: 0.5192969441413879
Validation loss: 1.967062698897495

Epoch: 5| Step: 8
Training loss: 0.8382524251937866
Validation loss: 1.9847310768660678

Epoch: 5| Step: 9
Training loss: 0.67158442735672
Validation loss: 1.9735557930443877

Epoch: 5| Step: 10
Training loss: 0.6468706727027893
Validation loss: 1.9851446177369805

Epoch: 262| Step: 0
Training loss: 0.620194673538208
Validation loss: 1.9706695720713625

Epoch: 5| Step: 1
Training loss: 0.5490435361862183
Validation loss: 1.987191710420834

Epoch: 5| Step: 2
Training loss: 0.5021249055862427
Validation loss: 1.9771433696951917

Epoch: 5| Step: 3
Training loss: 0.7761752009391785
Validation loss: 1.9610028061815488

Epoch: 5| Step: 4
Training loss: 0.6483567953109741
Validation loss: 1.934845898741035

Epoch: 5| Step: 5
Training loss: 0.5635033845901489
Validation loss: 1.9208791653315227

Epoch: 5| Step: 6
Training loss: 0.42805415391921997
Validation loss: 1.9026583369060228

Epoch: 5| Step: 7
Training loss: 0.44574540853500366
Validation loss: 1.8874466150037703

Epoch: 5| Step: 8
Training loss: 0.4546318054199219
Validation loss: 1.8674890097751413

Epoch: 5| Step: 9
Training loss: 0.5218610763549805
Validation loss: 1.8805782192496843

Epoch: 5| Step: 10
Training loss: 0.5292723178863525
Validation loss: 1.8844281781104304

Epoch: 263| Step: 0
Training loss: 0.32632723450660706
Validation loss: 1.848619367486687

Epoch: 5| Step: 1
Training loss: 0.32609498500823975
Validation loss: 1.8612083465822282

Epoch: 5| Step: 2
Training loss: 0.699809193611145
Validation loss: 1.8822593560782812

Epoch: 5| Step: 3
Training loss: 0.6163318157196045
Validation loss: 1.9183442438802412

Epoch: 5| Step: 4
Training loss: 0.6226428151130676
Validation loss: 1.9302316801522368

Epoch: 5| Step: 5
Training loss: 0.4293261468410492
Validation loss: 1.9472682860589796

Epoch: 5| Step: 6
Training loss: 0.8898216485977173
Validation loss: 1.9402692215417021

Epoch: 5| Step: 7
Training loss: 0.55024254322052
Validation loss: 1.9115705579839728

Epoch: 5| Step: 8
Training loss: 0.5903644561767578
Validation loss: 1.914226419182234

Epoch: 5| Step: 9
Training loss: 0.5176216959953308
Validation loss: 1.8959378773166287

Epoch: 5| Step: 10
Training loss: 0.6611135005950928
Validation loss: 1.9135595983074558

Epoch: 264| Step: 0
Training loss: 0.23567843437194824
Validation loss: 1.908932150051158

Epoch: 5| Step: 1
Training loss: 0.42280760407447815
Validation loss: 1.923664621127549

Epoch: 5| Step: 2
Training loss: 0.7937122583389282
Validation loss: 1.9088947567888486

Epoch: 5| Step: 3
Training loss: 0.6231220364570618
Validation loss: 1.9306119052312707

Epoch: 5| Step: 4
Training loss: 0.3724866807460785
Validation loss: 1.9671891248354347

Epoch: 5| Step: 5
Training loss: 0.516935408115387
Validation loss: 1.9451543643910398

Epoch: 5| Step: 6
Training loss: 0.3701512813568115
Validation loss: 1.9280436000516337

Epoch: 5| Step: 7
Training loss: 0.571502685546875
Validation loss: 1.9223411019130419

Epoch: 5| Step: 8
Training loss: 0.7330589294433594
Validation loss: 1.8992933265624508

Epoch: 5| Step: 9
Training loss: 0.5097678899765015
Validation loss: 1.936344221074094

Epoch: 5| Step: 10
Training loss: 0.6800214052200317
Validation loss: 1.9367959524995537

Epoch: 265| Step: 0
Training loss: 0.757825493812561
Validation loss: 1.9403656516023862

Epoch: 5| Step: 1
Training loss: 0.6160751581192017
Validation loss: 1.9295577554292576

Epoch: 5| Step: 2
Training loss: 0.535895824432373
Validation loss: 1.9584255269778672

Epoch: 5| Step: 3
Training loss: 0.6024910807609558
Validation loss: 1.975627440278248

Epoch: 5| Step: 4
Training loss: 0.3582606911659241
Validation loss: 1.9694033925251295

Epoch: 5| Step: 5
Training loss: 0.5533163547515869
Validation loss: 1.9469417679694392

Epoch: 5| Step: 6
Training loss: 0.3092958927154541
Validation loss: 1.916113188189845

Epoch: 5| Step: 7
Training loss: 0.5645706653594971
Validation loss: 1.9056010002730994

Epoch: 5| Step: 8
Training loss: 0.5623853206634521
Validation loss: 1.9278668985571912

Epoch: 5| Step: 9
Training loss: 0.8431037664413452
Validation loss: 1.937435947438722

Epoch: 5| Step: 10
Training loss: 0.35548830032348633
Validation loss: 1.9166332162836546

Epoch: 266| Step: 0
Training loss: 0.5247541666030884
Validation loss: 1.9777092472199471

Epoch: 5| Step: 1
Training loss: 0.3312844932079315
Validation loss: 1.9557631400323683

Epoch: 5| Step: 2
Training loss: 0.4023653566837311
Validation loss: 1.974505882109365

Epoch: 5| Step: 3
Training loss: 0.8006466031074524
Validation loss: 1.9484572718220372

Epoch: 5| Step: 4
Training loss: 0.4015088677406311
Validation loss: 1.9633688016604351

Epoch: 5| Step: 5
Training loss: 0.7510477304458618
Validation loss: 1.9291187934978034

Epoch: 5| Step: 6
Training loss: 0.3845726549625397
Validation loss: 1.9257303540424635

Epoch: 5| Step: 7
Training loss: 0.44891658425331116
Validation loss: 1.921022843289119

Epoch: 5| Step: 8
Training loss: 0.5758568048477173
Validation loss: 1.9263572180142967

Epoch: 5| Step: 9
Training loss: 0.6090425252914429
Validation loss: 1.9288596901842343

Epoch: 5| Step: 10
Training loss: 0.644748330116272
Validation loss: 1.9811348351099158

Epoch: 267| Step: 0
Training loss: 0.6921772360801697
Validation loss: 1.9633693310522264

Epoch: 5| Step: 1
Training loss: 0.42287588119506836
Validation loss: 1.9478153438978298

Epoch: 5| Step: 2
Training loss: 0.4360010623931885
Validation loss: 1.9487944508111605

Epoch: 5| Step: 3
Training loss: 0.6490223407745361
Validation loss: 1.972846479826076

Epoch: 5| Step: 4
Training loss: 0.38944029808044434
Validation loss: 1.9105437622275403

Epoch: 5| Step: 5
Training loss: 0.7168046832084656
Validation loss: 1.9186859771769533

Epoch: 5| Step: 6
Training loss: 0.6343631744384766
Validation loss: 1.922335119657619

Epoch: 5| Step: 7
Training loss: 0.53133624792099
Validation loss: 1.9280342491724158

Epoch: 5| Step: 8
Training loss: 0.38411298394203186
Validation loss: 1.9319218563777145

Epoch: 5| Step: 9
Training loss: 0.4131191670894623
Validation loss: 1.91524653345026

Epoch: 5| Step: 10
Training loss: 0.6354101896286011
Validation loss: 1.9543532415102887

Epoch: 268| Step: 0
Training loss: 0.432624876499176
Validation loss: 1.9415126257045294

Epoch: 5| Step: 1
Training loss: 0.8578629493713379
Validation loss: 1.918766915157277

Epoch: 5| Step: 2
Training loss: 0.6133653521537781
Validation loss: 1.9363508070668867

Epoch: 5| Step: 3
Training loss: 0.5842947363853455
Validation loss: 1.9398262346944501

Epoch: 5| Step: 4
Training loss: 0.26885658502578735
Validation loss: 1.9144918534063524

Epoch: 5| Step: 5
Training loss: 0.5880188941955566
Validation loss: 1.8951570244245632

Epoch: 5| Step: 6
Training loss: 0.4125925898551941
Validation loss: 1.9008480553985925

Epoch: 5| Step: 7
Training loss: 0.4172336161136627
Validation loss: 1.8933481529194822

Epoch: 5| Step: 8
Training loss: 0.6771162152290344
Validation loss: 1.9121027761890041

Epoch: 5| Step: 9
Training loss: 0.719886064529419
Validation loss: 1.9208485477714128

Epoch: 5| Step: 10
Training loss: 0.24979984760284424
Validation loss: 1.9121476475910475

Epoch: 269| Step: 0
Training loss: 0.4509352743625641
Validation loss: 1.9325012942796111

Epoch: 5| Step: 1
Training loss: 0.4944733679294586
Validation loss: 1.9418235389135217

Epoch: 5| Step: 2
Training loss: 0.5663870573043823
Validation loss: 1.9485052170292023

Epoch: 5| Step: 3
Training loss: 0.5530701875686646
Validation loss: 1.9531952745171004

Epoch: 5| Step: 4
Training loss: 0.48572665452957153
Validation loss: 1.9508782817471413

Epoch: 5| Step: 5
Training loss: 0.4093349874019623
Validation loss: 1.9015751372101486

Epoch: 5| Step: 6
Training loss: 0.5512358546257019
Validation loss: 1.8679553744613484

Epoch: 5| Step: 7
Training loss: 0.495222270488739
Validation loss: 1.8610503737644484

Epoch: 5| Step: 8
Training loss: 0.5920159816741943
Validation loss: 1.825462515636157

Epoch: 5| Step: 9
Training loss: 0.6954834461212158
Validation loss: 1.8200855703764065

Epoch: 5| Step: 10
Training loss: 0.4605582356452942
Validation loss: 1.8470347542916574

Epoch: 270| Step: 0
Training loss: 0.5180301070213318
Validation loss: 1.8924589362195743

Epoch: 5| Step: 1
Training loss: 0.5133198499679565
Validation loss: 1.9505780153377081

Epoch: 5| Step: 2
Training loss: 0.3349417448043823
Validation loss: 1.9852626272427139

Epoch: 5| Step: 3
Training loss: 0.2823459804058075
Validation loss: 2.02615196986865

Epoch: 5| Step: 4
Training loss: 0.38091689348220825
Validation loss: 1.9916291083059003

Epoch: 5| Step: 5
Training loss: 0.7345033288002014
Validation loss: 1.9959502861063967

Epoch: 5| Step: 6
Training loss: 0.7348574995994568
Validation loss: 1.9476805861278246

Epoch: 5| Step: 7
Training loss: 0.6453755497932434
Validation loss: 1.937573003512557

Epoch: 5| Step: 8
Training loss: 0.8289281725883484
Validation loss: 1.8651995940874981

Epoch: 5| Step: 9
Training loss: 0.4935458302497864
Validation loss: 1.82267455644505

Epoch: 5| Step: 10
Training loss: 0.4852715730667114
Validation loss: 1.803561549032888

Epoch: 271| Step: 0
Training loss: 0.5686320662498474
Validation loss: 1.8009201198495843

Epoch: 5| Step: 1
Training loss: 0.47549915313720703
Validation loss: 1.8212088384935934

Epoch: 5| Step: 2
Training loss: 0.6357256174087524
Validation loss: 1.8280963231158514

Epoch: 5| Step: 3
Training loss: 0.3600800037384033
Validation loss: 1.836925862937845

Epoch: 5| Step: 4
Training loss: 0.3457949757575989
Validation loss: 1.920281328180785

Epoch: 5| Step: 5
Training loss: 0.8383556604385376
Validation loss: 1.9183645556049962

Epoch: 5| Step: 6
Training loss: 0.8882497549057007
Validation loss: 1.9874466824275192

Epoch: 5| Step: 7
Training loss: 0.5813467502593994
Validation loss: 1.988050368524367

Epoch: 5| Step: 8
Training loss: 0.29531198740005493
Validation loss: 1.9758079282699093

Epoch: 5| Step: 9
Training loss: 0.5284884572029114
Validation loss: 1.9814115134618615

Epoch: 5| Step: 10
Training loss: 0.3810928463935852
Validation loss: 1.9445110649190924

Epoch: 272| Step: 0
Training loss: 0.3304310739040375
Validation loss: 1.9477353839464084

Epoch: 5| Step: 1
Training loss: 0.30495890974998474
Validation loss: 1.9076579296460716

Epoch: 5| Step: 2
Training loss: 0.5587259531021118
Validation loss: 1.8675600905572214

Epoch: 5| Step: 3
Training loss: 0.577255368232727
Validation loss: 1.8645801544189453

Epoch: 5| Step: 4
Training loss: 0.7677983641624451
Validation loss: 1.8639520457995835

Epoch: 5| Step: 5
Training loss: 0.8116739988327026
Validation loss: 1.8321237089813396

Epoch: 5| Step: 6
Training loss: 0.8038872480392456
Validation loss: 1.8392785044126614

Epoch: 5| Step: 7
Training loss: 0.6530316472053528
Validation loss: 1.826047912720711

Epoch: 5| Step: 8
Training loss: 0.45738130807876587
Validation loss: 1.8452720436998593

Epoch: 5| Step: 9
Training loss: 0.7531899213790894
Validation loss: 1.8729349631135181

Epoch: 5| Step: 10
Training loss: 0.24598923325538635
Validation loss: 1.9329071865286878

Epoch: 273| Step: 0
Training loss: 0.7835597395896912
Validation loss: 1.9936075851481447

Epoch: 5| Step: 1
Training loss: 0.6111024618148804
Validation loss: 1.991729587636968

Epoch: 5| Step: 2
Training loss: 0.5565805435180664
Validation loss: 1.963446887590552

Epoch: 5| Step: 3
Training loss: 0.5136246681213379
Validation loss: 1.9021415261812107

Epoch: 5| Step: 4
Training loss: 0.6085387468338013
Validation loss: 1.8489565631394744

Epoch: 5| Step: 5
Training loss: 0.5270223021507263
Validation loss: 1.8446103834336804

Epoch: 5| Step: 6
Training loss: 0.5468990206718445
Validation loss: 1.8035553809135192

Epoch: 5| Step: 7
Training loss: 0.38147515058517456
Validation loss: 1.8434341005099717

Epoch: 5| Step: 8
Training loss: 0.36127954721450806
Validation loss: 1.832719006846028

Epoch: 5| Step: 9
Training loss: 0.4056828022003174
Validation loss: 1.8463637239189559

Epoch: 5| Step: 10
Training loss: 0.45498305559158325
Validation loss: 1.865568745520807

Epoch: 274| Step: 0
Training loss: 0.5511716604232788
Validation loss: 1.8961486175496092

Epoch: 5| Step: 1
Training loss: 0.5453475117683411
Validation loss: 1.9476060636581913

Epoch: 5| Step: 2
Training loss: 0.4755609631538391
Validation loss: 1.940141507374343

Epoch: 5| Step: 3
Training loss: 0.6292566657066345
Validation loss: 1.9303633756535028

Epoch: 5| Step: 4
Training loss: 0.4150078296661377
Validation loss: 1.9242588025267406

Epoch: 5| Step: 5
Training loss: 0.48589572310447693
Validation loss: 1.8823366908616916

Epoch: 5| Step: 6
Training loss: 0.454759418964386
Validation loss: 1.8613438324261737

Epoch: 5| Step: 7
Training loss: 0.7525650858879089
Validation loss: 1.8199636013277116

Epoch: 5| Step: 8
Training loss: 0.5032669901847839
Validation loss: 1.8002073405891337

Epoch: 5| Step: 9
Training loss: 0.46418333053588867
Validation loss: 1.7977896262240667

Epoch: 5| Step: 10
Training loss: 0.4262757897377014
Validation loss: 1.8284147824010542

Epoch: 275| Step: 0
Training loss: 0.3120078444480896
Validation loss: 1.8270236612648092

Epoch: 5| Step: 1
Training loss: 0.30948805809020996
Validation loss: 1.86348589774101

Epoch: 5| Step: 2
Training loss: 0.18146686255931854
Validation loss: 1.8972038697170954

Epoch: 5| Step: 3
Training loss: 0.5371419787406921
Validation loss: 1.9325572277909966

Epoch: 5| Step: 4
Training loss: 0.3876948356628418
Validation loss: 1.9105763230272519

Epoch: 5| Step: 5
Training loss: 0.39497190713882446
Validation loss: 1.901974654966785

Epoch: 5| Step: 6
Training loss: 0.8337811231613159
Validation loss: 1.912187530148414

Epoch: 5| Step: 7
Training loss: 0.5450388193130493
Validation loss: 1.9257092680982364

Epoch: 5| Step: 8
Training loss: 0.6054709553718567
Validation loss: 1.9020157449988908

Epoch: 5| Step: 9
Training loss: 0.6039129495620728
Validation loss: 1.88489241497491

Epoch: 5| Step: 10
Training loss: 0.6110473871231079
Validation loss: 1.887621315576697

Epoch: 276| Step: 0
Training loss: 0.5518454313278198
Validation loss: 1.88435721781946

Epoch: 5| Step: 1
Training loss: 0.35577070713043213
Validation loss: 1.8447439785926574

Epoch: 5| Step: 2
Training loss: 0.4735623002052307
Validation loss: 1.8557096886378464

Epoch: 5| Step: 3
Training loss: 0.6991983652114868
Validation loss: 1.8308224447311894

Epoch: 5| Step: 4
Training loss: 0.3453952670097351
Validation loss: 1.8613179768285444

Epoch: 5| Step: 5
Training loss: 0.4857698976993561
Validation loss: 1.8827620552432152

Epoch: 5| Step: 6
Training loss: 0.6239265203475952
Validation loss: 1.8676031174198273

Epoch: 5| Step: 7
Training loss: 0.5102385878562927
Validation loss: 1.9005815572636102

Epoch: 5| Step: 8
Training loss: 0.6428450345993042
Validation loss: 1.9152835005073137

Epoch: 5| Step: 9
Training loss: 0.44224023818969727
Validation loss: 1.9163908778980214

Epoch: 5| Step: 10
Training loss: 0.3983990252017975
Validation loss: 1.9249091122740059

Epoch: 277| Step: 0
Training loss: 0.9062849283218384
Validation loss: 1.944546663632957

Epoch: 5| Step: 1
Training loss: 0.7144550085067749
Validation loss: 1.9762059155330862

Epoch: 5| Step: 2
Training loss: 0.5798857808113098
Validation loss: 1.990262564792428

Epoch: 5| Step: 3
Training loss: 0.42817622423171997
Validation loss: 1.967300752157806

Epoch: 5| Step: 4
Training loss: 0.44205737113952637
Validation loss: 1.968574332934554

Epoch: 5| Step: 5
Training loss: 0.3925360143184662
Validation loss: 1.9528953798355595

Epoch: 5| Step: 6
Training loss: 0.33480286598205566
Validation loss: 1.9878200779679

Epoch: 5| Step: 7
Training loss: 0.48863667249679565
Validation loss: 1.9062073653744114

Epoch: 5| Step: 8
Training loss: 0.4778473973274231
Validation loss: 1.9298176150168143

Epoch: 5| Step: 9
Training loss: 0.3190847337245941
Validation loss: 1.924071273496074

Epoch: 5| Step: 10
Training loss: 0.4802454710006714
Validation loss: 1.900460135552191

Epoch: 278| Step: 0
Training loss: 0.39388036727905273
Validation loss: 1.9183249473571777

Epoch: 5| Step: 1
Training loss: 0.6712408661842346
Validation loss: 1.930072574205296

Epoch: 5| Step: 2
Training loss: 0.4054221510887146
Validation loss: 1.9629016307092482

Epoch: 5| Step: 3
Training loss: 0.49328312277793884
Validation loss: 1.975563685099284

Epoch: 5| Step: 4
Training loss: 0.5036647319793701
Validation loss: 1.9786985869048743

Epoch: 5| Step: 5
Training loss: 0.3874574601650238
Validation loss: 1.953687544791929

Epoch: 5| Step: 6
Training loss: 0.5285364389419556
Validation loss: 1.9215116718763947

Epoch: 5| Step: 7
Training loss: 0.5218376517295837
Validation loss: 1.9009366458462131

Epoch: 5| Step: 8
Training loss: 0.5580368638038635
Validation loss: 1.8867619652901926

Epoch: 5| Step: 9
Training loss: 0.5620009303092957
Validation loss: 1.832367673996956

Epoch: 5| Step: 10
Training loss: 0.3890122175216675
Validation loss: 1.8269479120931318

Epoch: 279| Step: 0
Training loss: 0.4051222801208496
Validation loss: 1.8347918051545338

Epoch: 5| Step: 1
Training loss: 0.44588127732276917
Validation loss: 1.8542596063306254

Epoch: 5| Step: 2
Training loss: 0.5518138408660889
Validation loss: 1.8620251609433083

Epoch: 5| Step: 3
Training loss: 0.492575466632843
Validation loss: 1.9172424590715798

Epoch: 5| Step: 4
Training loss: 0.3249669075012207
Validation loss: 1.9526484115149385

Epoch: 5| Step: 5
Training loss: 0.36501187086105347
Validation loss: 1.9605552560539656

Epoch: 5| Step: 6
Training loss: 0.5008605122566223
Validation loss: 1.921272252195625

Epoch: 5| Step: 7
Training loss: 0.6114780306816101
Validation loss: 1.9055920570127425

Epoch: 5| Step: 8
Training loss: 0.38423752784729004
Validation loss: 1.8914297857592184

Epoch: 5| Step: 9
Training loss: 0.4998767375946045
Validation loss: 1.898499540103379

Epoch: 5| Step: 10
Training loss: 0.5884446501731873
Validation loss: 1.8982869066217893

Epoch: 280| Step: 0
Training loss: 0.43903571367263794
Validation loss: 1.9225551953879736

Epoch: 5| Step: 1
Training loss: 0.5432893633842468
Validation loss: 1.9092234693547732

Epoch: 5| Step: 2
Training loss: 0.6217140555381775
Validation loss: 1.8903071764976747

Epoch: 5| Step: 3
Training loss: 0.2473299205303192
Validation loss: 1.8879010831156084

Epoch: 5| Step: 4
Training loss: 0.2693457305431366
Validation loss: 1.8714663841391121

Epoch: 5| Step: 5
Training loss: 0.31458401679992676
Validation loss: 1.8571341396659933

Epoch: 5| Step: 6
Training loss: 0.47851142287254333
Validation loss: 1.8626664684664818

Epoch: 5| Step: 7
Training loss: 0.6372450590133667
Validation loss: 1.8550889863762805

Epoch: 5| Step: 8
Training loss: 0.5541065335273743
Validation loss: 1.8552704254786174

Epoch: 5| Step: 9
Training loss: 0.7272247672080994
Validation loss: 1.8270848297303723

Epoch: 5| Step: 10
Training loss: 0.5879461169242859
Validation loss: 1.8622496768992434

Epoch: 281| Step: 0
Training loss: 0.6433674097061157
Validation loss: 1.8678249210439704

Epoch: 5| Step: 1
Training loss: 0.2439127415418625
Validation loss: 1.8902073496131486

Epoch: 5| Step: 2
Training loss: 0.7124870419502258
Validation loss: 1.8921841600889802

Epoch: 5| Step: 3
Training loss: 0.4711126685142517
Validation loss: 1.9381081801588818

Epoch: 5| Step: 4
Training loss: 0.5732298493385315
Validation loss: 1.919659512017363

Epoch: 5| Step: 5
Training loss: 0.25577273964881897
Validation loss: 1.9204864860862814

Epoch: 5| Step: 6
Training loss: 0.5503554344177246
Validation loss: 1.868634808448053

Epoch: 5| Step: 7
Training loss: 0.4337947368621826
Validation loss: 1.8708602920655282

Epoch: 5| Step: 8
Training loss: 0.2695809304714203
Validation loss: 1.8315167965427521

Epoch: 5| Step: 9
Training loss: 0.4656716287136078
Validation loss: 1.855542670014084

Epoch: 5| Step: 10
Training loss: 0.5037584900856018
Validation loss: 1.8619570232206775

Epoch: 282| Step: 0
Training loss: 0.667153000831604
Validation loss: 1.8595929863632366

Epoch: 5| Step: 1
Training loss: 0.5510004162788391
Validation loss: 1.8593423020455144

Epoch: 5| Step: 2
Training loss: 0.5218831896781921
Validation loss: 1.8937788355735041

Epoch: 5| Step: 3
Training loss: 0.3084750771522522
Validation loss: 1.8984533509900492

Epoch: 5| Step: 4
Training loss: 0.6136250495910645
Validation loss: 1.8788634038740588

Epoch: 5| Step: 5
Training loss: 0.5881994962692261
Validation loss: 1.8683558407650198

Epoch: 5| Step: 6
Training loss: 0.27293816208839417
Validation loss: 1.8687801130356327

Epoch: 5| Step: 7
Training loss: 0.2842171788215637
Validation loss: 1.8664693268396522

Epoch: 5| Step: 8
Training loss: 0.19194892048835754
Validation loss: 1.846737761651316

Epoch: 5| Step: 9
Training loss: 0.5664545297622681
Validation loss: 1.8633302885998961

Epoch: 5| Step: 10
Training loss: 0.23217147588729858
Validation loss: 1.8372653171580324

Epoch: 283| Step: 0
Training loss: 0.31252366304397583
Validation loss: 1.8172373784485685

Epoch: 5| Step: 1
Training loss: 0.7265328168869019
Validation loss: 1.8186278958474436

Epoch: 5| Step: 2
Training loss: 0.33079999685287476
Validation loss: 1.8528895493476623

Epoch: 5| Step: 3
Training loss: 0.49738988280296326
Validation loss: 1.8469546841036888

Epoch: 5| Step: 4
Training loss: 0.2645915150642395
Validation loss: 1.85011076670821

Epoch: 5| Step: 5
Training loss: 0.32029637694358826
Validation loss: 1.883361433141975

Epoch: 5| Step: 6
Training loss: 0.3713342249393463
Validation loss: 1.8871522654769242

Epoch: 5| Step: 7
Training loss: 0.5227069854736328
Validation loss: 1.8985539738849928

Epoch: 5| Step: 8
Training loss: 0.4777028560638428
Validation loss: 1.8923598617635748

Epoch: 5| Step: 9
Training loss: 0.37682363390922546
Validation loss: 1.8447909483345606

Epoch: 5| Step: 10
Training loss: 0.5449578166007996
Validation loss: 1.8641281807294456

Epoch: 284| Step: 0
Training loss: 0.2875767648220062
Validation loss: 1.8846146240029285

Epoch: 5| Step: 1
Training loss: 0.5025879740715027
Validation loss: 1.852152902592895

Epoch: 5| Step: 2
Training loss: 0.3800550401210785
Validation loss: 1.9025393980805592

Epoch: 5| Step: 3
Training loss: 0.6447234153747559
Validation loss: 1.8966060633300452

Epoch: 5| Step: 4
Training loss: 0.4419400691986084
Validation loss: 1.8851636071358957

Epoch: 5| Step: 5
Training loss: 0.23822414875030518
Validation loss: 1.8859575704861713

Epoch: 5| Step: 6
Training loss: 0.5581890940666199
Validation loss: 1.877560748848864

Epoch: 5| Step: 7
Training loss: 0.35637739300727844
Validation loss: 1.8735714766287035

Epoch: 5| Step: 8
Training loss: 0.45419150590896606
Validation loss: 1.8647587735165831

Epoch: 5| Step: 9
Training loss: 0.4732948839664459
Validation loss: 1.8282214928698797

Epoch: 5| Step: 10
Training loss: 0.5453292727470398
Validation loss: 1.861992984689692

Epoch: 285| Step: 0
Training loss: 0.3826943337917328
Validation loss: 1.865591062012539

Epoch: 5| Step: 1
Training loss: 0.696625292301178
Validation loss: 1.8717540335911576

Epoch: 5| Step: 2
Training loss: 0.4536917805671692
Validation loss: 1.8745930502491612

Epoch: 5| Step: 3
Training loss: 0.5653020739555359
Validation loss: 1.8877811021702264

Epoch: 5| Step: 4
Training loss: 0.3935289680957794
Validation loss: 1.859367157823296

Epoch: 5| Step: 5
Training loss: 0.4914766848087311
Validation loss: 1.8750674070850495

Epoch: 5| Step: 6
Training loss: 0.3358239531517029
Validation loss: 1.8417169522213679

Epoch: 5| Step: 7
Training loss: 0.24393776059150696
Validation loss: 1.823528785859385

Epoch: 5| Step: 8
Training loss: 0.4100525379180908
Validation loss: 1.8644003663011777

Epoch: 5| Step: 9
Training loss: 0.4149613380432129
Validation loss: 1.8349795636310373

Epoch: 5| Step: 10
Training loss: 0.3728632628917694
Validation loss: 1.8743389101438626

Epoch: 286| Step: 0
Training loss: 0.5231751203536987
Validation loss: 1.857169420488419

Epoch: 5| Step: 1
Training loss: 0.2981553077697754
Validation loss: 1.8372889180337229

Epoch: 5| Step: 2
Training loss: 0.2837745249271393
Validation loss: 1.8467497107803181

Epoch: 5| Step: 3
Training loss: 0.4832790493965149
Validation loss: 1.8122060247646865

Epoch: 5| Step: 4
Training loss: 0.4761241376399994
Validation loss: 1.856165450106385

Epoch: 5| Step: 5
Training loss: 0.3240278661251068
Validation loss: 1.8519233811286189

Epoch: 5| Step: 6
Training loss: 0.3488547205924988
Validation loss: 1.8327954584552395

Epoch: 5| Step: 7
Training loss: 0.3909650444984436
Validation loss: 1.8823510831402195

Epoch: 5| Step: 8
Training loss: 0.659504234790802
Validation loss: 1.8616517705302085

Epoch: 5| Step: 9
Training loss: 0.6700000762939453
Validation loss: 1.8982846531816708

Epoch: 5| Step: 10
Training loss: 0.3984675407409668
Validation loss: 1.862707261116274

Epoch: 287| Step: 0
Training loss: 0.465798556804657
Validation loss: 1.875213679446969

Epoch: 5| Step: 1
Training loss: 0.4808456301689148
Validation loss: 1.9014249296598538

Epoch: 5| Step: 2
Training loss: 0.22924745082855225
Validation loss: 1.8936415256992463

Epoch: 5| Step: 3
Training loss: 0.24963441491127014
Validation loss: 1.8814621074225313

Epoch: 5| Step: 4
Training loss: 0.31531694531440735
Validation loss: 1.8376700782006787

Epoch: 5| Step: 5
Training loss: 0.35907095670700073
Validation loss: 1.8583617582116077

Epoch: 5| Step: 6
Training loss: 0.46977943181991577
Validation loss: 1.8427005198694044

Epoch: 5| Step: 7
Training loss: 0.6078685522079468
Validation loss: 1.8153996070226033

Epoch: 5| Step: 8
Training loss: 0.5226953029632568
Validation loss: 1.8650544381910754

Epoch: 5| Step: 9
Training loss: 0.6110047101974487
Validation loss: 1.8668900920498757

Epoch: 5| Step: 10
Training loss: 0.3938271701335907
Validation loss: 1.8596538894919938

Epoch: 288| Step: 0
Training loss: 0.2721387445926666
Validation loss: 1.8819785425739903

Epoch: 5| Step: 1
Training loss: 0.8124933242797852
Validation loss: 1.8631325819159066

Epoch: 5| Step: 2
Training loss: 0.3257783055305481
Validation loss: 1.9003799012912217

Epoch: 5| Step: 3
Training loss: 0.20273342728614807
Validation loss: 1.8745904660994006

Epoch: 5| Step: 4
Training loss: 0.6238091588020325
Validation loss: 1.9238995646917691

Epoch: 5| Step: 5
Training loss: 0.4312041401863098
Validation loss: 1.9201650619506836

Epoch: 5| Step: 6
Training loss: 0.6189990043640137
Validation loss: 1.9666141656137281

Epoch: 5| Step: 7
Training loss: 0.42924952507019043
Validation loss: 1.9577969146031204

Epoch: 5| Step: 8
Training loss: 0.34760555624961853
Validation loss: 1.9322382070684945

Epoch: 5| Step: 9
Training loss: 0.3787599205970764
Validation loss: 1.9091255562279814

Epoch: 5| Step: 10
Training loss: 0.35249266028404236
Validation loss: 1.8432204569539716

Epoch: 289| Step: 0
Training loss: 0.2547862231731415
Validation loss: 1.826835242650842

Epoch: 5| Step: 1
Training loss: 0.4384841322898865
Validation loss: 1.7443423335270216

Epoch: 5| Step: 2
Training loss: 0.7959823608398438
Validation loss: 1.7383261214020431

Epoch: 5| Step: 3
Training loss: 0.5172327756881714
Validation loss: 1.7293684174937587

Epoch: 5| Step: 4
Training loss: 0.4765424132347107
Validation loss: 1.7370090792256017

Epoch: 5| Step: 5
Training loss: 0.4016202390193939
Validation loss: 1.7713947014142108

Epoch: 5| Step: 6
Training loss: 0.5248997211456299
Validation loss: 1.7934643478803738

Epoch: 5| Step: 7
Training loss: 0.5915067791938782
Validation loss: 1.8738667964935303

Epoch: 5| Step: 8
Training loss: 0.4738844335079193
Validation loss: 1.885430492380614

Epoch: 5| Step: 9
Training loss: 0.3739803433418274
Validation loss: 1.9219737001644668

Epoch: 5| Step: 10
Training loss: 0.3954506814479828
Validation loss: 1.9615910617254113

Epoch: 290| Step: 0
Training loss: 0.35174304246902466
Validation loss: 1.9382663414042482

Epoch: 5| Step: 1
Training loss: 0.6442643404006958
Validation loss: 1.9114034765510148

Epoch: 5| Step: 2
Training loss: 0.3870212137699127
Validation loss: 1.86737391384699

Epoch: 5| Step: 3
Training loss: 0.25402218103408813
Validation loss: 1.8413894458483624

Epoch: 5| Step: 4
Training loss: 0.3793235421180725
Validation loss: 1.8467495069708875

Epoch: 5| Step: 5
Training loss: 0.5089112520217896
Validation loss: 1.8559760970454062

Epoch: 5| Step: 6
Training loss: 0.4781431257724762
Validation loss: 1.8716902963576778

Epoch: 5| Step: 7
Training loss: 0.3168676197528839
Validation loss: 1.8573103720141995

Epoch: 5| Step: 8
Training loss: 0.6770685911178589
Validation loss: 1.890759660351661

Epoch: 5| Step: 9
Training loss: 0.43312758207321167
Validation loss: 1.8916639461312243

Epoch: 5| Step: 10
Training loss: 0.5958921313285828
Validation loss: 1.893901257104771

Epoch: 291| Step: 0
Training loss: 0.36036258935928345
Validation loss: 1.8889725426191926

Epoch: 5| Step: 1
Training loss: 0.3610078692436218
Validation loss: 1.874422880911058

Epoch: 5| Step: 2
Training loss: 0.5238571166992188
Validation loss: 1.8514155700642576

Epoch: 5| Step: 3
Training loss: 0.4398042559623718
Validation loss: 1.8483632726054038

Epoch: 5| Step: 4
Training loss: 0.4628441333770752
Validation loss: 1.8567790562106716

Epoch: 5| Step: 5
Training loss: 0.3850999176502228
Validation loss: 1.8725593948876986

Epoch: 5| Step: 6
Training loss: 0.6122112274169922
Validation loss: 1.872468222853958

Epoch: 5| Step: 7
Training loss: 0.44187456369400024
Validation loss: 1.8301475355702062

Epoch: 5| Step: 8
Training loss: 0.39037802815437317
Validation loss: 1.7968170437761533

Epoch: 5| Step: 9
Training loss: 0.44803547859191895
Validation loss: 1.8307372049618793

Epoch: 5| Step: 10
Training loss: 0.4370708167552948
Validation loss: 1.8550381993734708

Epoch: 292| Step: 0
Training loss: 0.6922137141227722
Validation loss: 1.8442474475470922

Epoch: 5| Step: 1
Training loss: 0.43862563371658325
Validation loss: 1.8563410774354012

Epoch: 5| Step: 2
Training loss: 0.30685681104660034
Validation loss: 1.878796177525674

Epoch: 5| Step: 3
Training loss: 0.4718445837497711
Validation loss: 1.8838119173562655

Epoch: 5| Step: 4
Training loss: 0.5352565050125122
Validation loss: 1.8601700131611159

Epoch: 5| Step: 5
Training loss: 0.3577043414115906
Validation loss: 1.8844997870024813

Epoch: 5| Step: 6
Training loss: 0.2944560647010803
Validation loss: 1.8805816891372844

Epoch: 5| Step: 7
Training loss: 0.33927538990974426
Validation loss: 1.8931808446043281

Epoch: 5| Step: 8
Training loss: 0.32256707549095154
Validation loss: 1.8999750370620399

Epoch: 5| Step: 9
Training loss: 0.45760631561279297
Validation loss: 1.8703256858292447

Epoch: 5| Step: 10
Training loss: 0.49538174271583557
Validation loss: 1.8484217120755104

Epoch: 293| Step: 0
Training loss: 0.2922983765602112
Validation loss: 1.841611990364649

Epoch: 5| Step: 1
Training loss: 0.2220393866300583
Validation loss: 1.8086224781569613

Epoch: 5| Step: 2
Training loss: 0.4614782929420471
Validation loss: 1.811316474791496

Epoch: 5| Step: 3
Training loss: 0.6783367991447449
Validation loss: 1.786050845217961

Epoch: 5| Step: 4
Training loss: 0.42215538024902344
Validation loss: 1.8186621473681541

Epoch: 5| Step: 5
Training loss: 0.6982824802398682
Validation loss: 1.8123492220396638

Epoch: 5| Step: 6
Training loss: 0.362196683883667
Validation loss: 1.8690183598508117

Epoch: 5| Step: 7
Training loss: 0.42676496505737305
Validation loss: 1.8845489589116906

Epoch: 5| Step: 8
Training loss: 0.40082263946533203
Validation loss: 1.879519401058074

Epoch: 5| Step: 9
Training loss: 0.44533103704452515
Validation loss: 1.9044205757879442

Epoch: 5| Step: 10
Training loss: 0.093941330909729
Validation loss: 1.910551881277433

Epoch: 294| Step: 0
Training loss: 0.26193344593048096
Validation loss: 1.9326431084704656

Epoch: 5| Step: 1
Training loss: 0.518761932849884
Validation loss: 1.9446482760931856

Epoch: 5| Step: 2
Training loss: 0.36255139112472534
Validation loss: 1.9261392213964974

Epoch: 5| Step: 3
Training loss: 0.236445814371109
Validation loss: 1.9345808067629415

Epoch: 5| Step: 4
Training loss: 0.480942964553833
Validation loss: 1.8860854294992262

Epoch: 5| Step: 5
Training loss: 0.6101411581039429
Validation loss: 1.8470228231081398

Epoch: 5| Step: 6
Training loss: 0.4121568202972412
Validation loss: 1.8215065874079222

Epoch: 5| Step: 7
Training loss: 0.4018703103065491
Validation loss: 1.8032528943912958

Epoch: 5| Step: 8
Training loss: 0.26707202196121216
Validation loss: 1.8280648069996988

Epoch: 5| Step: 9
Training loss: 0.4814489483833313
Validation loss: 1.8137189252402193

Epoch: 5| Step: 10
Training loss: 0.5241765975952148
Validation loss: 1.8283293388223136

Epoch: 295| Step: 0
Training loss: 0.4400444030761719
Validation loss: 1.863750744891423

Epoch: 5| Step: 1
Training loss: 0.18011203408241272
Validation loss: 1.8513837924567602

Epoch: 5| Step: 2
Training loss: 0.43596357107162476
Validation loss: 1.919106315541011

Epoch: 5| Step: 3
Training loss: 0.512782096862793
Validation loss: 1.9723881649714645

Epoch: 5| Step: 4
Training loss: 0.5133923888206482
Validation loss: 1.9955518373879053

Epoch: 5| Step: 5
Training loss: 0.4281400740146637
Validation loss: 2.009807764842946

Epoch: 5| Step: 6
Training loss: 0.4629538655281067
Validation loss: 1.9978355515387751

Epoch: 5| Step: 7
Training loss: 0.5104320645332336
Validation loss: 1.953272306790916

Epoch: 5| Step: 8
Training loss: 0.4412282109260559
Validation loss: 1.9233594402190177

Epoch: 5| Step: 9
Training loss: 0.43386778235435486
Validation loss: 1.9179444313049316

Epoch: 5| Step: 10
Training loss: 0.4307558238506317
Validation loss: 1.8727238639708488

Epoch: 296| Step: 0
Training loss: 0.4647241234779358
Validation loss: 1.8798984878806657

Epoch: 5| Step: 1
Training loss: 0.6796202063560486
Validation loss: 1.881114476470537

Epoch: 5| Step: 2
Training loss: 0.44559937715530396
Validation loss: 1.8637657293709375

Epoch: 5| Step: 3
Training loss: 0.38108405470848083
Validation loss: 1.9011269025905158

Epoch: 5| Step: 4
Training loss: 0.4110424518585205
Validation loss: 1.8992755182327763

Epoch: 5| Step: 5
Training loss: 0.25974395871162415
Validation loss: 1.894896032989666

Epoch: 5| Step: 6
Training loss: 0.2035295069217682
Validation loss: 1.9145532487541117

Epoch: 5| Step: 7
Training loss: 0.3080684542655945
Validation loss: 1.9343749361653482

Epoch: 5| Step: 8
Training loss: 0.4982619285583496
Validation loss: 1.93326553990764

Epoch: 5| Step: 9
Training loss: 0.7295964360237122
Validation loss: 1.8938158814625075

Epoch: 5| Step: 10
Training loss: 0.46964308619499207
Validation loss: 1.8621600686862905

Epoch: 297| Step: 0
Training loss: 0.44669264554977417
Validation loss: 1.8520795734979774

Epoch: 5| Step: 1
Training loss: 0.39372316002845764
Validation loss: 1.8227479457855225

Epoch: 5| Step: 2
Training loss: 0.31782856583595276
Validation loss: 1.824738602484426

Epoch: 5| Step: 3
Training loss: 0.33888697624206543
Validation loss: 1.8125034993694675

Epoch: 5| Step: 4
Training loss: 0.35698139667510986
Validation loss: 1.8418015074986283

Epoch: 5| Step: 5
Training loss: 0.294050008058548
Validation loss: 1.8212201236396708

Epoch: 5| Step: 6
Training loss: 0.276696115732193
Validation loss: 1.8111087711908485

Epoch: 5| Step: 7
Training loss: 0.41430407762527466
Validation loss: 1.866864296697801

Epoch: 5| Step: 8
Training loss: 0.31529760360717773
Validation loss: 1.893095101079633

Epoch: 5| Step: 9
Training loss: 0.6770306825637817
Validation loss: 1.9086063267082296

Epoch: 5| Step: 10
Training loss: 0.6905691623687744
Validation loss: 1.9412241481965589

Epoch: 298| Step: 0
Training loss: 0.4771241545677185
Validation loss: 1.9370741318630915

Epoch: 5| Step: 1
Training loss: 0.4753802418708801
Validation loss: 1.9386577836928829

Epoch: 5| Step: 2
Training loss: 0.35742107033729553
Validation loss: 1.985896163089301

Epoch: 5| Step: 3
Training loss: 0.4721851348876953
Validation loss: 2.0084765354792276

Epoch: 5| Step: 4
Training loss: 0.34196677803993225
Validation loss: 1.9745741031503166

Epoch: 5| Step: 5
Training loss: 0.4760153889656067
Validation loss: 1.9595965454655309

Epoch: 5| Step: 6
Training loss: 0.5674667954444885
Validation loss: 1.914201977432415

Epoch: 5| Step: 7
Training loss: 0.3658629059791565
Validation loss: 1.8904567662105765

Epoch: 5| Step: 8
Training loss: 0.34080901741981506
Validation loss: 1.8818760700123285

Epoch: 5| Step: 9
Training loss: 0.38073062896728516
Validation loss: 1.8660064256319435

Epoch: 5| Step: 10
Training loss: 0.4526495933532715
Validation loss: 1.8392810026804607

Epoch: 299| Step: 0
Training loss: 0.2885841429233551
Validation loss: 1.8726603779741513

Epoch: 5| Step: 1
Training loss: 0.4634335935115814
Validation loss: 1.8493120029408445

Epoch: 5| Step: 2
Training loss: 0.335811972618103
Validation loss: 1.894867750906175

Epoch: 5| Step: 3
Training loss: 0.22792422771453857
Validation loss: 1.8759769624279392

Epoch: 5| Step: 4
Training loss: 0.3780898451805115
Validation loss: 1.8474766592825613

Epoch: 5| Step: 5
Training loss: 0.5096973776817322
Validation loss: 1.8457039107558548

Epoch: 5| Step: 6
Training loss: 0.6633113622665405
Validation loss: 1.842714471201743

Epoch: 5| Step: 7
Training loss: 0.606658935546875
Validation loss: 1.8791115463420909

Epoch: 5| Step: 8
Training loss: 0.519077718257904
Validation loss: 1.8412773852707238

Epoch: 5| Step: 9
Training loss: 0.35899975895881653
Validation loss: 1.8657155626563615

Epoch: 5| Step: 10
Training loss: 0.33866631984710693
Validation loss: 1.89588471381895

Epoch: 300| Step: 0
Training loss: 0.4378223419189453
Validation loss: 1.8863501625676309

Epoch: 5| Step: 1
Training loss: 0.3941097855567932
Validation loss: 1.8960329717205417

Epoch: 5| Step: 2
Training loss: 0.3616243898868561
Validation loss: 1.8766175649499381

Epoch: 5| Step: 3
Training loss: 0.5126625299453735
Validation loss: 1.8705381193468649

Epoch: 5| Step: 4
Training loss: 0.3972831964492798
Validation loss: 1.8517235543138237

Epoch: 5| Step: 5
Training loss: 0.477565199136734
Validation loss: 1.8955270897957586

Epoch: 5| Step: 6
Training loss: 0.3311157822608948
Validation loss: 1.8890544637556999

Epoch: 5| Step: 7
Training loss: 0.21840760111808777
Validation loss: 1.8726283119570823

Epoch: 5| Step: 8
Training loss: 0.4417148530483246
Validation loss: 1.8545247470178912

Epoch: 5| Step: 9
Training loss: 0.4708000719547272
Validation loss: 1.8421425332305252

Epoch: 5| Step: 10
Training loss: 0.4310970902442932
Validation loss: 1.8164717317909322

Epoch: 301| Step: 0
Training loss: 0.24406008422374725
Validation loss: 1.8367858112499278

Epoch: 5| Step: 1
Training loss: 0.4278560280799866
Validation loss: 1.8249297936757405

Epoch: 5| Step: 2
Training loss: 0.2862699627876282
Validation loss: 1.7826918991663123

Epoch: 5| Step: 3
Training loss: 0.1707541048526764
Validation loss: 1.8031391943654707

Epoch: 5| Step: 4
Training loss: 0.7186490297317505
Validation loss: 1.7980751209361578

Epoch: 5| Step: 5
Training loss: 0.34468644857406616
Validation loss: 1.806329668209117

Epoch: 5| Step: 6
Training loss: 0.42555731534957886
Validation loss: 1.8137369098201874

Epoch: 5| Step: 7
Training loss: 0.4768868386745453
Validation loss: 1.8213776644840036

Epoch: 5| Step: 8
Training loss: 0.3376206159591675
Validation loss: 1.8323767877394153

Epoch: 5| Step: 9
Training loss: 0.29730165004730225
Validation loss: 1.8099564147251908

Epoch: 5| Step: 10
Training loss: 0.43084716796875
Validation loss: 1.8378509629157282

Epoch: 302| Step: 0
Training loss: 0.39265045523643494
Validation loss: 1.8241366686359528

Epoch: 5| Step: 1
Training loss: 0.5052367448806763
Validation loss: 1.8630967088924941

Epoch: 5| Step: 2
Training loss: 0.4434415400028229
Validation loss: 1.8423503521950013

Epoch: 5| Step: 3
Training loss: 0.42790231108665466
Validation loss: 1.8369878286956458

Epoch: 5| Step: 4
Training loss: 0.25006330013275146
Validation loss: 1.8341482993095153

Epoch: 5| Step: 5
Training loss: 0.310502827167511
Validation loss: 1.8309873919333182

Epoch: 5| Step: 6
Training loss: 0.3344540596008301
Validation loss: 1.7854928060244488

Epoch: 5| Step: 7
Training loss: 0.4433495104312897
Validation loss: 1.7781500265162478

Epoch: 5| Step: 8
Training loss: 0.4590640962123871
Validation loss: 1.7758392544202908

Epoch: 5| Step: 9
Training loss: 0.19110774993896484
Validation loss: 1.78460870891489

Epoch: 5| Step: 10
Training loss: 0.29803666472435
Validation loss: 1.8083331738748858

Epoch: 303| Step: 0
Training loss: 0.3021868169307709
Validation loss: 1.8227778634717386

Epoch: 5| Step: 1
Training loss: 0.2819107472896576
Validation loss: 1.8576741167294082

Epoch: 5| Step: 2
Training loss: 0.45489436388015747
Validation loss: 1.824610387125323

Epoch: 5| Step: 3
Training loss: 0.28510016202926636
Validation loss: 1.8738699805351995

Epoch: 5| Step: 4
Training loss: 0.4229850172996521
Validation loss: 1.883187379888309

Epoch: 5| Step: 5
Training loss: 0.33858928084373474
Validation loss: 1.8538373772815993

Epoch: 5| Step: 6
Training loss: 0.45171037316322327
Validation loss: 1.8646176925269506

Epoch: 5| Step: 7
Training loss: 0.42961105704307556
Validation loss: 1.825954096291655

Epoch: 5| Step: 8
Training loss: 0.5356453657150269
Validation loss: 1.874206535277828

Epoch: 5| Step: 9
Training loss: 0.3729162812232971
Validation loss: 1.8643387927803943

Epoch: 5| Step: 10
Training loss: 0.3378854990005493
Validation loss: 1.833797703507126

Epoch: 304| Step: 0
Training loss: 0.2311520129442215
Validation loss: 1.839363951836863

Epoch: 5| Step: 1
Training loss: 0.3772062361240387
Validation loss: 1.8439182286621423

Epoch: 5| Step: 2
Training loss: 0.40263882279396057
Validation loss: 1.8200383493977208

Epoch: 5| Step: 3
Training loss: 0.4176134169101715
Validation loss: 1.8540473535496702

Epoch: 5| Step: 4
Training loss: 0.5149115324020386
Validation loss: 1.7996796305461595

Epoch: 5| Step: 5
Training loss: 0.6850627660751343
Validation loss: 1.8509435166594803

Epoch: 5| Step: 6
Training loss: 0.3717673420906067
Validation loss: 1.821034646803333

Epoch: 5| Step: 7
Training loss: 0.19512823224067688
Validation loss: 1.806177923756261

Epoch: 5| Step: 8
Training loss: 0.22811511158943176
Validation loss: 1.831608069840298

Epoch: 5| Step: 9
Training loss: 0.38875269889831543
Validation loss: 1.8408002686756912

Epoch: 5| Step: 10
Training loss: 0.2861192226409912
Validation loss: 1.8481080019345848

Epoch: 305| Step: 0
Training loss: 0.3176329731941223
Validation loss: 1.8335910740719046

Epoch: 5| Step: 1
Training loss: 0.18087176978588104
Validation loss: 1.8412213863865021

Epoch: 5| Step: 2
Training loss: 0.5326067805290222
Validation loss: 1.8090224496779903

Epoch: 5| Step: 3
Training loss: 0.34696295857429504
Validation loss: 1.8147476937181206

Epoch: 5| Step: 4
Training loss: 0.2783448100090027
Validation loss: 1.7797988166091263

Epoch: 5| Step: 5
Training loss: 0.3467664122581482
Validation loss: 1.776421188026346

Epoch: 5| Step: 6
Training loss: 0.3868764340877533
Validation loss: 1.81153840403403

Epoch: 5| Step: 7
Training loss: 0.472515732049942
Validation loss: 1.8238206640366585

Epoch: 5| Step: 8
Training loss: 0.5274492502212524
Validation loss: 1.8273362395583943

Epoch: 5| Step: 9
Training loss: 0.28110092878341675
Validation loss: 1.832544348573172

Epoch: 5| Step: 10
Training loss: 0.2816176414489746
Validation loss: 1.8357955871089813

Epoch: 306| Step: 0
Training loss: 0.3026129901409149
Validation loss: 1.8168910805897047

Epoch: 5| Step: 1
Training loss: 0.262550413608551
Validation loss: 1.8161302740855882

Epoch: 5| Step: 2
Training loss: 0.7208651304244995
Validation loss: 1.8026774903779388

Epoch: 5| Step: 3
Training loss: 0.18335141241550446
Validation loss: 1.781272211382466

Epoch: 5| Step: 4
Training loss: 0.3275505006313324
Validation loss: 1.7864797717781478

Epoch: 5| Step: 5
Training loss: 0.31673330068588257
Validation loss: 1.8142343772354947

Epoch: 5| Step: 6
Training loss: 0.30046993494033813
Validation loss: 1.7990454012347805

Epoch: 5| Step: 7
Training loss: 0.21498307585716248
Validation loss: 1.8192902713693597

Epoch: 5| Step: 8
Training loss: 0.47588911652565
Validation loss: 1.808251291192988

Epoch: 5| Step: 9
Training loss: 0.2781587243080139
Validation loss: 1.8343712052991312

Epoch: 5| Step: 10
Training loss: 0.39334455132484436
Validation loss: 1.8282317756324686

Epoch: 307| Step: 0
Training loss: 0.38104647397994995
Validation loss: 1.8678776307772564

Epoch: 5| Step: 1
Training loss: 0.5310623049736023
Validation loss: 1.8317040140910814

Epoch: 5| Step: 2
Training loss: 0.27183738350868225
Validation loss: 1.8173898650753884

Epoch: 5| Step: 3
Training loss: 0.22245529294013977
Validation loss: 1.807228015315148

Epoch: 5| Step: 4
Training loss: 0.23456302285194397
Validation loss: 1.7843101921901907

Epoch: 5| Step: 5
Training loss: 0.3981149196624756
Validation loss: 1.7789301385161698

Epoch: 5| Step: 6
Training loss: 0.38438159227371216
Validation loss: 1.8078948810536375

Epoch: 5| Step: 7
Training loss: 0.2373274564743042
Validation loss: 1.7854968117129417

Epoch: 5| Step: 8
Training loss: 0.4276549220085144
Validation loss: 1.8114780879789782

Epoch: 5| Step: 9
Training loss: 0.2894762456417084
Validation loss: 1.8044477483277679

Epoch: 5| Step: 10
Training loss: 0.419207364320755
Validation loss: 1.8246504670830184

Epoch: 308| Step: 0
Training loss: 0.45898884534835815
Validation loss: 1.844017408227408

Epoch: 5| Step: 1
Training loss: 0.31898707151412964
Validation loss: 1.8542048546575731

Epoch: 5| Step: 2
Training loss: 0.2153283804655075
Validation loss: 1.8073553526273338

Epoch: 5| Step: 3
Training loss: 0.3784972131252289
Validation loss: 1.8002705548399238

Epoch: 5| Step: 4
Training loss: 0.5067864060401917
Validation loss: 1.7837877453014415

Epoch: 5| Step: 5
Training loss: 0.34198474884033203
Validation loss: 1.7815495780719224

Epoch: 5| Step: 6
Training loss: 0.4563443064689636
Validation loss: 1.784795307344006

Epoch: 5| Step: 7
Training loss: 0.3497529923915863
Validation loss: 1.8012442896443028

Epoch: 5| Step: 8
Training loss: 0.4078567922115326
Validation loss: 1.8359251983704106

Epoch: 5| Step: 9
Training loss: 0.2095833569765091
Validation loss: 1.8093465733271774

Epoch: 5| Step: 10
Training loss: 0.20838358998298645
Validation loss: 1.8744788298042871

Epoch: 309| Step: 0
Training loss: 0.3481965959072113
Validation loss: 1.8753981205724901

Epoch: 5| Step: 1
Training loss: 0.24014118313789368
Validation loss: 1.8564334556620607

Epoch: 5| Step: 2
Training loss: 0.30860695242881775
Validation loss: 1.827879758291347

Epoch: 5| Step: 3
Training loss: 0.33916038274765015
Validation loss: 1.82016590205572

Epoch: 5| Step: 4
Training loss: 0.24710097908973694
Validation loss: 1.8528850565674484

Epoch: 5| Step: 5
Training loss: 0.42724180221557617
Validation loss: 1.803948438295754

Epoch: 5| Step: 6
Training loss: 0.5431528091430664
Validation loss: 1.7817935046329294

Epoch: 5| Step: 7
Training loss: 0.34471604228019714
Validation loss: 1.777269237784929

Epoch: 5| Step: 8
Training loss: 0.42366641759872437
Validation loss: 1.709099756774082

Epoch: 5| Step: 9
Training loss: 0.21509549021720886
Validation loss: 1.7469425150143203

Epoch: 5| Step: 10
Training loss: 0.3261129856109619
Validation loss: 1.7353631911739227

Epoch: 310| Step: 0
Training loss: 0.3504059314727783
Validation loss: 1.7392625385715115

Epoch: 5| Step: 1
Training loss: 0.5767822265625
Validation loss: 1.7213779623790453

Epoch: 5| Step: 2
Training loss: 0.2636439800262451
Validation loss: 1.783543793104028

Epoch: 5| Step: 3
Training loss: 0.40654340386390686
Validation loss: 1.8272445176237373

Epoch: 5| Step: 4
Training loss: 0.24452117085456848
Validation loss: 1.8371367351983183

Epoch: 5| Step: 5
Training loss: 0.35726672410964966
Validation loss: 1.804838639433666

Epoch: 5| Step: 6
Training loss: 0.2665717601776123
Validation loss: 1.8260763255498742

Epoch: 5| Step: 7
Training loss: 0.33847400546073914
Validation loss: 1.8224879195613246

Epoch: 5| Step: 8
Training loss: 0.29820024967193604
Validation loss: 1.8375144953368812

Epoch: 5| Step: 9
Training loss: 0.20200666785240173
Validation loss: 1.7894779994923582

Epoch: 5| Step: 10
Training loss: 0.529129683971405
Validation loss: 1.807037550915954

Epoch: 311| Step: 0
Training loss: 0.22087259590625763
Validation loss: 1.7985140303129792

Epoch: 5| Step: 1
Training loss: 0.27347487211227417
Validation loss: 1.786935592210421

Epoch: 5| Step: 2
Training loss: 0.4918120801448822
Validation loss: 1.8147025595429123

Epoch: 5| Step: 3
Training loss: 0.5436619520187378
Validation loss: 1.8189495763471049

Epoch: 5| Step: 4
Training loss: 0.21216244995594025
Validation loss: 1.8636195480182607

Epoch: 5| Step: 5
Training loss: 0.14859411120414734
Validation loss: 1.8594537460675804

Epoch: 5| Step: 6
Training loss: 0.2616392970085144
Validation loss: 1.8654693518915484

Epoch: 5| Step: 7
Training loss: 0.5666163563728333
Validation loss: 1.857696828021798

Epoch: 5| Step: 8
Training loss: 0.36263617873191833
Validation loss: 1.842629123759526

Epoch: 5| Step: 9
Training loss: 0.45688676834106445
Validation loss: 1.8592914778699157

Epoch: 5| Step: 10
Training loss: 0.20602715015411377
Validation loss: 1.8246693713690645

Epoch: 312| Step: 0
Training loss: 0.46583470702171326
Validation loss: 1.795313876162293

Epoch: 5| Step: 1
Training loss: 0.2964106500148773
Validation loss: 1.8074556691672212

Epoch: 5| Step: 2
Training loss: 0.3474558889865875
Validation loss: 1.810663382212321

Epoch: 5| Step: 3
Training loss: 0.2652833163738251
Validation loss: 1.778171871298103

Epoch: 5| Step: 4
Training loss: 0.7371217608451843
Validation loss: 1.7577023006254626

Epoch: 5| Step: 5
Training loss: 0.19286301732063293
Validation loss: 1.7771899994983469

Epoch: 5| Step: 6
Training loss: 0.31817710399627686
Validation loss: 1.7628013036584342

Epoch: 5| Step: 7
Training loss: 0.3144075274467468
Validation loss: 1.8048973493678595

Epoch: 5| Step: 8
Training loss: 0.2147834300994873
Validation loss: 1.8021178642908733

Epoch: 5| Step: 9
Training loss: 0.13866212964057922
Validation loss: 1.8492955776952928

Epoch: 5| Step: 10
Training loss: 0.2819031774997711
Validation loss: 1.827643871307373

Epoch: 313| Step: 0
Training loss: 0.2552749216556549
Validation loss: 1.845698268182816

Epoch: 5| Step: 1
Training loss: 0.3335300087928772
Validation loss: 1.8296968654919696

Epoch: 5| Step: 2
Training loss: 0.2086910754442215
Validation loss: 1.830051229846093

Epoch: 5| Step: 3
Training loss: 0.4289925694465637
Validation loss: 1.8296307594545427

Epoch: 5| Step: 4
Training loss: 0.25153738260269165
Validation loss: 1.761890834377658

Epoch: 5| Step: 5
Training loss: 0.39926421642303467
Validation loss: 1.7363636134773173

Epoch: 5| Step: 6
Training loss: 0.29827243089675903
Validation loss: 1.7348803704784763

Epoch: 5| Step: 7
Training loss: 0.41180339455604553
Validation loss: 1.7568916889929003

Epoch: 5| Step: 8
Training loss: 0.46220502257347107
Validation loss: 1.7680246932532198

Epoch: 5| Step: 9
Training loss: 0.3640003800392151
Validation loss: 1.7564021900135984

Epoch: 5| Step: 10
Training loss: 0.40614405274391174
Validation loss: 1.7774881419315134

Epoch: 314| Step: 0
Training loss: 0.415616512298584
Validation loss: 1.821890813048168

Epoch: 5| Step: 1
Training loss: 0.6259728670120239
Validation loss: 1.8186838024406022

Epoch: 5| Step: 2
Training loss: 0.3710872232913971
Validation loss: 1.8490290308511386

Epoch: 5| Step: 3
Training loss: 0.2148762196302414
Validation loss: 1.8603245442913425

Epoch: 5| Step: 4
Training loss: 0.34793609380722046
Validation loss: 1.8731683992570447

Epoch: 5| Step: 5
Training loss: 0.3872367739677429
Validation loss: 1.894916344714421

Epoch: 5| Step: 6
Training loss: 0.2602863907814026
Validation loss: 1.8538597629916282

Epoch: 5| Step: 7
Training loss: 0.2945578694343567
Validation loss: 1.8350997688949748

Epoch: 5| Step: 8
Training loss: 0.34221869707107544
Validation loss: 1.8319836393479378

Epoch: 5| Step: 9
Training loss: 0.44759637117385864
Validation loss: 1.8506015398169076

Epoch: 5| Step: 10
Training loss: 0.38470274209976196
Validation loss: 1.7897413507584603

Epoch: 315| Step: 0
Training loss: 0.2048552930355072
Validation loss: 1.7882071028473556

Epoch: 5| Step: 1
Training loss: 0.42063388228416443
Validation loss: 1.8056170555853075

Epoch: 5| Step: 2
Training loss: 0.29216673970222473
Validation loss: 1.793570415948027

Epoch: 5| Step: 3
Training loss: 0.8329477310180664
Validation loss: 1.7839846726386779

Epoch: 5| Step: 4
Training loss: 0.29079705476760864
Validation loss: 1.8127109683969969

Epoch: 5| Step: 5
Training loss: 0.2513672709465027
Validation loss: 1.8224177796353576

Epoch: 5| Step: 6
Training loss: 0.20183280110359192
Validation loss: 1.8059071930505897

Epoch: 5| Step: 7
Training loss: 0.3283711075782776
Validation loss: 1.7916289003946448

Epoch: 5| Step: 8
Training loss: 0.15312650799751282
Validation loss: 1.7697882383100447

Epoch: 5| Step: 9
Training loss: 0.42482370138168335
Validation loss: 1.7305090132580008

Epoch: 5| Step: 10
Training loss: 0.41814491152763367
Validation loss: 1.729309505031955

Epoch: 316| Step: 0
Training loss: 0.2535024881362915
Validation loss: 1.7246440328577513

Epoch: 5| Step: 1
Training loss: 0.3939487338066101
Validation loss: 1.767641491787408

Epoch: 5| Step: 2
Training loss: 0.31845635175704956
Validation loss: 1.7493337610716462

Epoch: 5| Step: 3
Training loss: 0.36302638053894043
Validation loss: 1.745041642137753

Epoch: 5| Step: 4
Training loss: 0.2756763994693756
Validation loss: 1.7807297475876347

Epoch: 5| Step: 5
Training loss: 0.42349204421043396
Validation loss: 1.825454081258466

Epoch: 5| Step: 6
Training loss: 0.3397447168827057
Validation loss: 1.8169163606500114

Epoch: 5| Step: 7
Training loss: 0.29382631182670593
Validation loss: 1.8080624521419566

Epoch: 5| Step: 8
Training loss: 0.3391013741493225
Validation loss: 1.8268266070273615

Epoch: 5| Step: 9
Training loss: 0.32399243116378784
Validation loss: 1.8478744363272062

Epoch: 5| Step: 10
Training loss: 0.36223796010017395
Validation loss: 1.865404890429589

Epoch: 317| Step: 0
Training loss: 0.2898530662059784
Validation loss: 1.8396265763108448

Epoch: 5| Step: 1
Training loss: 0.2943285405635834
Validation loss: 1.8100403701105425

Epoch: 5| Step: 2
Training loss: 0.39195188879966736
Validation loss: 1.7963519557829826

Epoch: 5| Step: 3
Training loss: 0.30267271399497986
Validation loss: 1.7803996916740172

Epoch: 5| Step: 4
Training loss: 0.3969001770019531
Validation loss: 1.8195998181578934

Epoch: 5| Step: 5
Training loss: 0.29135164618492126
Validation loss: 1.8167104310886835

Epoch: 5| Step: 6
Training loss: 0.28163737058639526
Validation loss: 1.8336725401621994

Epoch: 5| Step: 7
Training loss: 0.25032612681388855
Validation loss: 1.8166679002905404

Epoch: 5| Step: 8
Training loss: 0.5901248455047607
Validation loss: 1.8145278256426576

Epoch: 5| Step: 9
Training loss: 0.3151364028453827
Validation loss: 1.8466708660125732

Epoch: 5| Step: 10
Training loss: 0.24148054420948029
Validation loss: 1.846484920029999

Epoch: 318| Step: 0
Training loss: 0.443250834941864
Validation loss: 1.8648628650173065

Epoch: 5| Step: 1
Training loss: 0.407949298620224
Validation loss: 1.8494458160092753

Epoch: 5| Step: 2
Training loss: 0.38032668828964233
Validation loss: 1.8571878415282055

Epoch: 5| Step: 3
Training loss: 0.6030555963516235
Validation loss: 1.8642581509005638

Epoch: 5| Step: 4
Training loss: 0.2889934480190277
Validation loss: 1.8525785451294274

Epoch: 5| Step: 5
Training loss: 0.19729237258434296
Validation loss: 1.8406007174522645

Epoch: 5| Step: 6
Training loss: 0.2078477442264557
Validation loss: 1.8177463495603172

Epoch: 5| Step: 7
Training loss: 0.2742084860801697
Validation loss: 1.798488232397264

Epoch: 5| Step: 8
Training loss: 0.29179343581199646
Validation loss: 1.8312677439822946

Epoch: 5| Step: 9
Training loss: 0.28030529618263245
Validation loss: 1.8026447449961016

Epoch: 5| Step: 10
Training loss: 0.2615049481391907
Validation loss: 1.8166942199071248

Epoch: 319| Step: 0
Training loss: 0.3599606454372406
Validation loss: 1.837731820280834

Epoch: 5| Step: 1
Training loss: 0.2522246241569519
Validation loss: 1.8760926249206706

Epoch: 5| Step: 2
Training loss: 0.2163621485233307
Validation loss: 1.8768534737248574

Epoch: 5| Step: 3
Training loss: 0.40881186723709106
Validation loss: 1.9020378307629657

Epoch: 5| Step: 4
Training loss: 0.41154932975769043
Validation loss: 1.8657993167959235

Epoch: 5| Step: 5
Training loss: 0.19783174991607666
Validation loss: 1.8160335979154032

Epoch: 5| Step: 6
Training loss: 0.34106749296188354
Validation loss: 1.807876144686053

Epoch: 5| Step: 7
Training loss: 0.527838408946991
Validation loss: 1.815528667101296

Epoch: 5| Step: 8
Training loss: 0.3866364359855652
Validation loss: 1.7559956991544334

Epoch: 5| Step: 9
Training loss: 0.384280264377594
Validation loss: 1.7907821157927155

Epoch: 5| Step: 10
Training loss: 0.14921090006828308
Validation loss: 1.7826947524983396

Epoch: 320| Step: 0
Training loss: 0.186025470495224
Validation loss: 1.7987337625154884

Epoch: 5| Step: 1
Training loss: 0.2991841435432434
Validation loss: 1.8200984347251155

Epoch: 5| Step: 2
Training loss: 0.32682862877845764
Validation loss: 1.7811790461181312

Epoch: 5| Step: 3
Training loss: 0.22852282226085663
Validation loss: 1.836257973024922

Epoch: 5| Step: 4
Training loss: 0.34265226125717163
Validation loss: 1.8493746608816168

Epoch: 5| Step: 5
Training loss: 0.24793212115764618
Validation loss: 1.8929493799004504

Epoch: 5| Step: 6
Training loss: 0.20325331389904022
Validation loss: 1.871767342731517

Epoch: 5| Step: 7
Training loss: 0.40091338753700256
Validation loss: 1.8679968298122447

Epoch: 5| Step: 8
Training loss: 0.25906282663345337
Validation loss: 1.8692295833300518

Epoch: 5| Step: 9
Training loss: 0.21433106064796448
Validation loss: 1.841046408940387

Epoch: 5| Step: 10
Training loss: 0.6802644729614258
Validation loss: 1.7997701475697179

Epoch: 321| Step: 0
Training loss: 0.3039379119873047
Validation loss: 1.8042181999452653

Epoch: 5| Step: 1
Training loss: 0.2508697509765625
Validation loss: 1.8230562286992227

Epoch: 5| Step: 2
Training loss: 0.37747877836227417
Validation loss: 1.8060573865008611

Epoch: 5| Step: 3
Training loss: 0.2583736777305603
Validation loss: 1.8085801139954598

Epoch: 5| Step: 4
Training loss: 0.26720741391181946
Validation loss: 1.7946596914722073

Epoch: 5| Step: 5
Training loss: 0.2393241673707962
Validation loss: 1.8005277559321413

Epoch: 5| Step: 6
Training loss: 0.27695128321647644
Validation loss: 1.798671499375374

Epoch: 5| Step: 7
Training loss: 0.35896003246307373
Validation loss: 1.8001703049546929

Epoch: 5| Step: 8
Training loss: 0.31496429443359375
Validation loss: 1.7823992941969184

Epoch: 5| Step: 9
Training loss: 0.40449246764183044
Validation loss: 1.7877398229414416

Epoch: 5| Step: 10
Training loss: 0.21251462399959564
Validation loss: 1.8058389207368255

Epoch: 322| Step: 0
Training loss: 0.309969961643219
Validation loss: 1.8630729862438735

Epoch: 5| Step: 1
Training loss: 0.36984166502952576
Validation loss: 1.8839031034900295

Epoch: 5| Step: 2
Training loss: 0.3317069411277771
Validation loss: 1.8876926668228642

Epoch: 5| Step: 3
Training loss: 0.22965911030769348
Validation loss: 1.8645460631257744

Epoch: 5| Step: 4
Training loss: 0.4532023072242737
Validation loss: 1.8486034665056454

Epoch: 5| Step: 5
Training loss: 0.24817797541618347
Validation loss: 1.8659933010737102

Epoch: 5| Step: 6
Training loss: 0.37161797285079956
Validation loss: 1.8332126768686439

Epoch: 5| Step: 7
Training loss: 0.18069860339164734
Validation loss: 1.8239543636639912

Epoch: 5| Step: 8
Training loss: 0.2704979479312897
Validation loss: 1.7925948391678512

Epoch: 5| Step: 9
Training loss: 0.3604587912559509
Validation loss: 1.7718500180910992

Epoch: 5| Step: 10
Training loss: 0.23271989822387695
Validation loss: 1.7792448984679354

Epoch: 323| Step: 0
Training loss: 0.2975257337093353
Validation loss: 1.775068227962781

Epoch: 5| Step: 1
Training loss: 0.366443932056427
Validation loss: 1.7849960545057892

Epoch: 5| Step: 2
Training loss: 0.27997612953186035
Validation loss: 1.8009968367956017

Epoch: 5| Step: 3
Training loss: 0.31752634048461914
Validation loss: 1.8444237760318223

Epoch: 5| Step: 4
Training loss: 0.4008117616176605
Validation loss: 1.8342298179544427

Epoch: 5| Step: 5
Training loss: 0.24310913681983948
Validation loss: 1.836055935070079

Epoch: 5| Step: 6
Training loss: 0.29108256101608276
Validation loss: 1.845602249586454

Epoch: 5| Step: 7
Training loss: 0.1847347766160965
Validation loss: 1.8407030554227932

Epoch: 5| Step: 8
Training loss: 0.3389158248901367
Validation loss: 1.8134935209828038

Epoch: 5| Step: 9
Training loss: 0.269112765789032
Validation loss: 1.8232125338687692

Epoch: 5| Step: 10
Training loss: 0.5343003869056702
Validation loss: 1.8185500803814139

Epoch: 324| Step: 0
Training loss: 0.3524613380432129
Validation loss: 1.8012347029101463

Epoch: 5| Step: 1
Training loss: 0.3433825373649597
Validation loss: 1.7910162248919088

Epoch: 5| Step: 2
Training loss: 0.297635555267334
Validation loss: 1.7569544892157278

Epoch: 5| Step: 3
Training loss: 0.4514142870903015
Validation loss: 1.7532544341138614

Epoch: 5| Step: 4
Training loss: 0.23101310431957245
Validation loss: 1.7702662406429168

Epoch: 5| Step: 5
Training loss: 0.2914179563522339
Validation loss: 1.7768543330571984

Epoch: 5| Step: 6
Training loss: 0.24139174818992615
Validation loss: 1.792216134327714

Epoch: 5| Step: 7
Training loss: 0.3053271472454071
Validation loss: 1.8218607338525916

Epoch: 5| Step: 8
Training loss: 0.28905388712882996
Validation loss: 1.8305563631878103

Epoch: 5| Step: 9
Training loss: 0.20580410957336426
Validation loss: 1.8078890654348558

Epoch: 5| Step: 10
Training loss: 0.3198552131652832
Validation loss: 1.8004649672456967

Epoch: 325| Step: 0
Training loss: 0.3339037001132965
Validation loss: 1.7900325559800672

Epoch: 5| Step: 1
Training loss: 0.2829075753688812
Validation loss: 1.7810385868113527

Epoch: 5| Step: 2
Training loss: 0.3175678849220276
Validation loss: 1.8166294687537736

Epoch: 5| Step: 3
Training loss: 0.3614109456539154
Validation loss: 1.8102022396620883

Epoch: 5| Step: 4
Training loss: 0.2170654982328415
Validation loss: 1.8052833029018935

Epoch: 5| Step: 5
Training loss: 0.3795117437839508
Validation loss: 1.7804814359193206

Epoch: 5| Step: 6
Training loss: 0.30592259764671326
Validation loss: 1.7867933345097367

Epoch: 5| Step: 7
Training loss: 0.28651732206344604
Validation loss: 1.7880413634802705

Epoch: 5| Step: 8
Training loss: 0.17326775193214417
Validation loss: 1.767950197701813

Epoch: 5| Step: 9
Training loss: 0.3497675657272339
Validation loss: 1.7738496513776882

Epoch: 5| Step: 10
Training loss: 0.2784937024116516
Validation loss: 1.7957113404427805

Epoch: 326| Step: 0
Training loss: 0.3251078724861145
Validation loss: 1.7845991375625774

Epoch: 5| Step: 1
Training loss: 0.4008500576019287
Validation loss: 1.7803198547773464

Epoch: 5| Step: 2
Training loss: 0.23935489356517792
Validation loss: 1.7754092549764982

Epoch: 5| Step: 3
Training loss: 0.38300085067749023
Validation loss: 1.7672509833048748

Epoch: 5| Step: 4
Training loss: 0.3038978576660156
Validation loss: 1.801841955031118

Epoch: 5| Step: 5
Training loss: 0.4248138964176178
Validation loss: 1.8303200685849754

Epoch: 5| Step: 6
Training loss: 0.32089075446128845
Validation loss: 1.802473723247487

Epoch: 5| Step: 7
Training loss: 0.3372858166694641
Validation loss: 1.777866772426072

Epoch: 5| Step: 8
Training loss: 0.22439797222614288
Validation loss: 1.756841177581459

Epoch: 5| Step: 9
Training loss: 0.24450376629829407
Validation loss: 1.7512027525132703

Epoch: 5| Step: 10
Training loss: 0.21364876627922058
Validation loss: 1.7366524127221876

Epoch: 327| Step: 0
Training loss: 0.20602862536907196
Validation loss: 1.7266532682603406

Epoch: 5| Step: 1
Training loss: 0.3347087502479553
Validation loss: 1.753103051134335

Epoch: 5| Step: 2
Training loss: 0.26553401350975037
Validation loss: 1.7510551547491422

Epoch: 5| Step: 3
Training loss: 0.530913233757019
Validation loss: 1.7445580087682253

Epoch: 5| Step: 4
Training loss: 0.2530566155910492
Validation loss: 1.7844789976714759

Epoch: 5| Step: 5
Training loss: 0.2836684584617615
Validation loss: 1.779632329940796

Epoch: 5| Step: 6
Training loss: 0.31140604615211487
Validation loss: 1.8193641862561625

Epoch: 5| Step: 7
Training loss: 0.25041884183883667
Validation loss: 1.8186827410933792

Epoch: 5| Step: 8
Training loss: 0.199676975607872
Validation loss: 1.7782584377514419

Epoch: 5| Step: 9
Training loss: 0.33897751569747925
Validation loss: 1.784753434119686

Epoch: 5| Step: 10
Training loss: 0.26107606291770935
Validation loss: 1.7541930611415575

Epoch: 328| Step: 0
Training loss: 0.21969759464263916
Validation loss: 1.7698360194442093

Epoch: 5| Step: 1
Training loss: 0.3930816352367401
Validation loss: 1.7727311759866693

Epoch: 5| Step: 2
Training loss: 0.17944307625293732
Validation loss: 1.7659007605685983

Epoch: 5| Step: 3
Training loss: 0.18412894010543823
Validation loss: 1.7890759527042348

Epoch: 5| Step: 4
Training loss: 0.28834325075149536
Validation loss: 1.8014454751886346

Epoch: 5| Step: 5
Training loss: 0.28317373991012573
Validation loss: 1.8192295669227518

Epoch: 5| Step: 6
Training loss: 0.3090766668319702
Validation loss: 1.8174961689979798

Epoch: 5| Step: 7
Training loss: 0.3128644526004791
Validation loss: 1.8151963962021695

Epoch: 5| Step: 8
Training loss: 0.21616871654987335
Validation loss: 1.7752467573329966

Epoch: 5| Step: 9
Training loss: 0.39861583709716797
Validation loss: 1.7532940205707346

Epoch: 5| Step: 10
Training loss: 0.4208414554595947
Validation loss: 1.7605683431830457

Epoch: 329| Step: 0
Training loss: 0.18258920311927795
Validation loss: 1.7495860207465388

Epoch: 5| Step: 1
Training loss: 0.2666989266872406
Validation loss: 1.7264685118070213

Epoch: 5| Step: 2
Training loss: 0.29773977398872375
Validation loss: 1.7540965836535218

Epoch: 5| Step: 3
Training loss: 0.20025238394737244
Validation loss: 1.7808776824705062

Epoch: 5| Step: 4
Training loss: 0.2906012535095215
Validation loss: 1.7803797439862323

Epoch: 5| Step: 5
Training loss: 0.2757987082004547
Validation loss: 1.7899701697852022

Epoch: 5| Step: 6
Training loss: 0.440623939037323
Validation loss: 1.799937645594279

Epoch: 5| Step: 7
Training loss: 0.5069150328636169
Validation loss: 1.7842971009592856

Epoch: 5| Step: 8
Training loss: 0.21940454840660095
Validation loss: 1.8537287084005212

Epoch: 5| Step: 9
Training loss: 0.1914951503276825
Validation loss: 1.8306131055278163

Epoch: 5| Step: 10
Training loss: 0.37918922305107117
Validation loss: 1.8474991154927078

Epoch: 330| Step: 0
Training loss: 0.30784764885902405
Validation loss: 1.8432572272516066

Epoch: 5| Step: 1
Training loss: 0.32640498876571655
Validation loss: 1.8240964463962022

Epoch: 5| Step: 2
Training loss: 0.24341981112957
Validation loss: 1.8274345141585155

Epoch: 5| Step: 3
Training loss: 0.1931321918964386
Validation loss: 1.7747763023581555

Epoch: 5| Step: 4
Training loss: 0.17277325689792633
Validation loss: 1.739887491349251

Epoch: 5| Step: 5
Training loss: 0.36375054717063904
Validation loss: 1.7189280179239088

Epoch: 5| Step: 6
Training loss: 0.5185046792030334
Validation loss: 1.7047366096127419

Epoch: 5| Step: 7
Training loss: 0.2930797338485718
Validation loss: 1.7210453966612458

Epoch: 5| Step: 8
Training loss: 0.3979935944080353
Validation loss: 1.7387804382590837

Epoch: 5| Step: 9
Training loss: 0.2990838587284088
Validation loss: 1.8054993242345831

Epoch: 5| Step: 10
Training loss: 0.16822198033332825
Validation loss: 1.8151813168679514

Epoch: 331| Step: 0
Training loss: 0.16689437627792358
Validation loss: 1.8516781253199424

Epoch: 5| Step: 1
Training loss: 0.27036333084106445
Validation loss: 1.888421489346412

Epoch: 5| Step: 2
Training loss: 0.41182565689086914
Validation loss: 1.9079902338725265

Epoch: 5| Step: 3
Training loss: 0.17151109874248505
Validation loss: 1.914046492627872

Epoch: 5| Step: 4
Training loss: 0.35397884249687195
Validation loss: 1.918792466963491

Epoch: 5| Step: 5
Training loss: 0.3772931694984436
Validation loss: 1.9083098852506248

Epoch: 5| Step: 6
Training loss: 0.3574979901313782
Validation loss: 1.851320194941695

Epoch: 5| Step: 7
Training loss: 0.24739284813404083
Validation loss: 1.8392518335773098

Epoch: 5| Step: 8
Training loss: 0.32912346720695496
Validation loss: 1.7564804835986065

Epoch: 5| Step: 9
Training loss: 0.5477240681648254
Validation loss: 1.7385974212359356

Epoch: 5| Step: 10
Training loss: 0.20050717890262604
Validation loss: 1.7361490739289152

Epoch: 332| Step: 0
Training loss: 0.3217795491218567
Validation loss: 1.7287949900473318

Epoch: 5| Step: 1
Training loss: 0.2613552510738373
Validation loss: 1.751955932186496

Epoch: 5| Step: 2
Training loss: 0.31518498063087463
Validation loss: 1.7984622037538918

Epoch: 5| Step: 3
Training loss: 0.36087357997894287
Validation loss: 1.8106910297947545

Epoch: 5| Step: 4
Training loss: 0.31200140714645386
Validation loss: 1.8787198861440022

Epoch: 5| Step: 5
Training loss: 0.304537832736969
Validation loss: 1.864683529382111

Epoch: 5| Step: 6
Training loss: 0.42171135544776917
Validation loss: 1.8279416291944441

Epoch: 5| Step: 7
Training loss: 0.21652767062187195
Validation loss: 1.8136055084966844

Epoch: 5| Step: 8
Training loss: 0.2112894505262375
Validation loss: 1.7892626588062575

Epoch: 5| Step: 9
Training loss: 0.21052122116088867
Validation loss: 1.7785714819867124

Epoch: 5| Step: 10
Training loss: 0.13532279431819916
Validation loss: 1.7219374064476258

Epoch: 333| Step: 0
Training loss: 0.2876037657260895
Validation loss: 1.7398456809341267

Epoch: 5| Step: 1
Training loss: 0.2511233687400818
Validation loss: 1.7364083925882976

Epoch: 5| Step: 2
Training loss: 0.14204716682434082
Validation loss: 1.7800069957651117

Epoch: 5| Step: 3
Training loss: 0.2958241105079651
Validation loss: 1.7403827662109046

Epoch: 5| Step: 4
Training loss: 0.266218900680542
Validation loss: 1.808413363272144

Epoch: 5| Step: 5
Training loss: 0.5029538869857788
Validation loss: 1.7795264861916984

Epoch: 5| Step: 6
Training loss: 0.22931066155433655
Validation loss: 1.7807320382005425

Epoch: 5| Step: 7
Training loss: 0.20058517158031464
Validation loss: 1.7844330969677176

Epoch: 5| Step: 8
Training loss: 0.19777658581733704
Validation loss: 1.7756843771985782

Epoch: 5| Step: 9
Training loss: 0.17486797273159027
Validation loss: 1.7685005626370829

Epoch: 5| Step: 10
Training loss: 0.3818204402923584
Validation loss: 1.7704253914535686

Epoch: 334| Step: 0
Training loss: 0.2930731773376465
Validation loss: 1.745018256607876

Epoch: 5| Step: 1
Training loss: 0.2850646376609802
Validation loss: 1.760004484525291

Epoch: 5| Step: 2
Training loss: 0.18094870448112488
Validation loss: 1.7326391102165304

Epoch: 5| Step: 3
Training loss: 0.5183178782463074
Validation loss: 1.7406481799258982

Epoch: 5| Step: 4
Training loss: 0.27993080019950867
Validation loss: 1.7621039703328123

Epoch: 5| Step: 5
Training loss: 0.26455238461494446
Validation loss: 1.7661796077605216

Epoch: 5| Step: 6
Training loss: 0.21055451035499573
Validation loss: 1.7526770445608324

Epoch: 5| Step: 7
Training loss: 0.2475396692752838
Validation loss: 1.7775745802028204

Epoch: 5| Step: 8
Training loss: 0.2505359649658203
Validation loss: 1.7933321076054727

Epoch: 5| Step: 9
Training loss: 0.1582094132900238
Validation loss: 1.777136992382747

Epoch: 5| Step: 10
Training loss: 0.13963696360588074
Validation loss: 1.7852840961948517

Epoch: 335| Step: 0
Training loss: 0.18705587089061737
Validation loss: 1.8296065791960685

Epoch: 5| Step: 1
Training loss: 0.2636311948299408
Validation loss: 1.8123948779157413

Epoch: 5| Step: 2
Training loss: 0.35448160767555237
Validation loss: 1.8195896725500784

Epoch: 5| Step: 3
Training loss: 0.30206140875816345
Validation loss: 1.788778192253523

Epoch: 5| Step: 4
Training loss: 0.2935817539691925
Validation loss: 1.7888600518626552

Epoch: 5| Step: 5
Training loss: 0.1824667751789093
Validation loss: 1.7533429848250521

Epoch: 5| Step: 6
Training loss: 0.22015292942523956
Validation loss: 1.7473151453079716

Epoch: 5| Step: 7
Training loss: 0.1949167251586914
Validation loss: 1.732647507421432

Epoch: 5| Step: 8
Training loss: 0.19571025669574738
Validation loss: 1.7652505418305755

Epoch: 5| Step: 9
Training loss: 0.33078840374946594
Validation loss: 1.781877807391587

Epoch: 5| Step: 10
Training loss: 0.5405373573303223
Validation loss: 1.8057940531802434

Epoch: 336| Step: 0
Training loss: 0.5113596320152283
Validation loss: 1.8078781366348267

Epoch: 5| Step: 1
Training loss: 0.32511094212532043
Validation loss: 1.8230890484266384

Epoch: 5| Step: 2
Training loss: 0.3126716613769531
Validation loss: 1.7793340631710586

Epoch: 5| Step: 3
Training loss: 0.15290161967277527
Validation loss: 1.7999648381304998

Epoch: 5| Step: 4
Training loss: 0.30747711658477783
Validation loss: 1.7844604599860407

Epoch: 5| Step: 5
Training loss: 0.19217650592327118
Validation loss: 1.7474314166653542

Epoch: 5| Step: 6
Training loss: 0.23228910565376282
Validation loss: 1.740823495772577

Epoch: 5| Step: 7
Training loss: 0.26047253608703613
Validation loss: 1.7027235415674025

Epoch: 5| Step: 8
Training loss: 0.16016480326652527
Validation loss: 1.70588332094172

Epoch: 5| Step: 9
Training loss: 0.20895612239837646
Validation loss: 1.709360699499807

Epoch: 5| Step: 10
Training loss: 0.30248957872390747
Validation loss: 1.7087448463645032

Epoch: 337| Step: 0
Training loss: 0.30473536252975464
Validation loss: 1.720272882010347

Epoch: 5| Step: 1
Training loss: 0.259708970785141
Validation loss: 1.7701133733154626

Epoch: 5| Step: 2
Training loss: 0.4067513048648834
Validation loss: 1.7439970188243414

Epoch: 5| Step: 3
Training loss: 0.2905677855014801
Validation loss: 1.753303571413922

Epoch: 5| Step: 4
Training loss: 0.17006781697273254
Validation loss: 1.7464115145385906

Epoch: 5| Step: 5
Training loss: 0.21997924149036407
Validation loss: 1.754995071759788

Epoch: 5| Step: 6
Training loss: 0.21824736893177032
Validation loss: 1.6997403919055898

Epoch: 5| Step: 7
Training loss: 0.3247622549533844
Validation loss: 1.6704486313686575

Epoch: 5| Step: 8
Training loss: 0.2349025011062622
Validation loss: 1.691540536060128

Epoch: 5| Step: 9
Training loss: 0.3867385983467102
Validation loss: 1.6860266475267307

Epoch: 5| Step: 10
Training loss: 0.45233896374702454
Validation loss: 1.6657626808330577

Epoch: 338| Step: 0
Training loss: 0.5513771772384644
Validation loss: 1.7303225789018857

Epoch: 5| Step: 1
Training loss: 0.3167967200279236
Validation loss: 1.7504378941751295

Epoch: 5| Step: 2
Training loss: 0.22903189063072205
Validation loss: 1.817401844968078

Epoch: 5| Step: 3
Training loss: 0.27042993903160095
Validation loss: 1.8415793744466638

Epoch: 5| Step: 4
Training loss: 0.18653175234794617
Validation loss: 1.8600219193325247

Epoch: 5| Step: 5
Training loss: 0.16438665986061096
Validation loss: 1.8316523849323232

Epoch: 5| Step: 6
Training loss: 0.32052382826805115
Validation loss: 1.7887963594928864

Epoch: 5| Step: 7
Training loss: 0.27610883116722107
Validation loss: 1.7859422468370008

Epoch: 5| Step: 8
Training loss: 0.2523308992385864
Validation loss: 1.7155533381687698

Epoch: 5| Step: 9
Training loss: 0.2796231508255005
Validation loss: 1.69236768445661

Epoch: 5| Step: 10
Training loss: 0.3441298007965088
Validation loss: 1.724587381526988

Epoch: 339| Step: 0
Training loss: 0.2543380558490753
Validation loss: 1.7095944266165457

Epoch: 5| Step: 1
Training loss: 0.3906799852848053
Validation loss: 1.7540070856771162

Epoch: 5| Step: 2
Training loss: 0.2519577443599701
Validation loss: 1.7190138575851277

Epoch: 5| Step: 3
Training loss: 0.3848488926887512
Validation loss: 1.7689839934790006

Epoch: 5| Step: 4
Training loss: 0.4736473560333252
Validation loss: 1.7526640020390993

Epoch: 5| Step: 5
Training loss: 0.2025701105594635
Validation loss: 1.7830119453450686

Epoch: 5| Step: 6
Training loss: 0.2518056333065033
Validation loss: 1.8034878943556099

Epoch: 5| Step: 7
Training loss: 0.21213598549365997
Validation loss: 1.8059209085279895

Epoch: 5| Step: 8
Training loss: 0.3501227796077728
Validation loss: 1.813984565837409

Epoch: 5| Step: 9
Training loss: 0.26110437512397766
Validation loss: 1.8213915183979978

Epoch: 5| Step: 10
Training loss: 0.26814743876457214
Validation loss: 1.829070859057929

Epoch: 340| Step: 0
Training loss: 0.1905929297208786
Validation loss: 1.7994614608826176

Epoch: 5| Step: 1
Training loss: 0.22403676807880402
Validation loss: 1.785210882463763

Epoch: 5| Step: 2
Training loss: 0.21666023135185242
Validation loss: 1.7824121162455568

Epoch: 5| Step: 3
Training loss: 0.22166545689105988
Validation loss: 1.7442259480876308

Epoch: 5| Step: 4
Training loss: 0.20660939812660217
Validation loss: 1.7311524793665896

Epoch: 5| Step: 5
Training loss: 0.25585195422172546
Validation loss: 1.735358686857326

Epoch: 5| Step: 6
Training loss: 0.4618097245693207
Validation loss: 1.7103608833846224

Epoch: 5| Step: 7
Training loss: 0.2132369577884674
Validation loss: 1.707319651880572

Epoch: 5| Step: 8
Training loss: 0.47469013929367065
Validation loss: 1.6944493170707458

Epoch: 5| Step: 9
Training loss: 0.34701305627822876
Validation loss: 1.7187934690906155

Epoch: 5| Step: 10
Training loss: 0.29278141260147095
Validation loss: 1.7067797747991418

Epoch: 341| Step: 0
Training loss: 0.2329862117767334
Validation loss: 1.7540708946925339

Epoch: 5| Step: 1
Training loss: 0.21920251846313477
Validation loss: 1.7639001671985914

Epoch: 5| Step: 2
Training loss: 0.3065020442008972
Validation loss: 1.8733458903528029

Epoch: 5| Step: 3
Training loss: 0.4271079897880554
Validation loss: 1.8814267086726364

Epoch: 5| Step: 4
Training loss: 0.4250200390815735
Validation loss: 1.9036395729229014

Epoch: 5| Step: 5
Training loss: 0.28237462043762207
Validation loss: 1.9155830837065173

Epoch: 5| Step: 6
Training loss: 0.3507286012172699
Validation loss: 1.9087211137176843

Epoch: 5| Step: 7
Training loss: 0.4340518116950989
Validation loss: 1.8620828620849117

Epoch: 5| Step: 8
Training loss: 0.2380480319261551
Validation loss: 1.8568517597772742

Epoch: 5| Step: 9
Training loss: 0.2530858814716339
Validation loss: 1.7868574178347023

Epoch: 5| Step: 10
Training loss: 0.2352162003517151
Validation loss: 1.7287650569792716

Epoch: 342| Step: 0
Training loss: 0.31213846802711487
Validation loss: 1.7302368199953468

Epoch: 5| Step: 1
Training loss: 0.2249508798122406
Validation loss: 1.7211644764869445

Epoch: 5| Step: 2
Training loss: 0.44423311948776245
Validation loss: 1.716688585537736

Epoch: 5| Step: 3
Training loss: 0.3681443929672241
Validation loss: 1.719980001449585

Epoch: 5| Step: 4
Training loss: 0.31239253282546997
Validation loss: 1.7093774503277195

Epoch: 5| Step: 5
Training loss: 0.39162677526474
Validation loss: 1.7227109183547318

Epoch: 5| Step: 6
Training loss: 0.1862146258354187
Validation loss: 1.6929565450196624

Epoch: 5| Step: 7
Training loss: 0.46858811378479004
Validation loss: 1.7112821327742709

Epoch: 5| Step: 8
Training loss: 0.26818734407424927
Validation loss: 1.7057753750073013

Epoch: 5| Step: 9
Training loss: 0.16804412007331848
Validation loss: 1.7352327403201853

Epoch: 5| Step: 10
Training loss: 0.34987810254096985
Validation loss: 1.7533059363724084

Epoch: 343| Step: 0
Training loss: 0.20033851265907288
Validation loss: 1.7865638066363592

Epoch: 5| Step: 1
Training loss: 0.27894505858421326
Validation loss: 1.7861879410282258

Epoch: 5| Step: 2
Training loss: 0.21743114292621613
Validation loss: 1.7993019652623001

Epoch: 5| Step: 3
Training loss: 0.2747684121131897
Validation loss: 1.7829321635666715

Epoch: 5| Step: 4
Training loss: 0.3116348385810852
Validation loss: 1.7650256156921387

Epoch: 5| Step: 5
Training loss: 0.19632497429847717
Validation loss: 1.7250956502012027

Epoch: 5| Step: 6
Training loss: 0.33351776003837585
Validation loss: 1.7256406904548727

Epoch: 5| Step: 7
Training loss: 0.3591175675392151
Validation loss: 1.6990621192480928

Epoch: 5| Step: 8
Training loss: 0.25467413663864136
Validation loss: 1.7095683287548762

Epoch: 5| Step: 9
Training loss: 0.44078224897384644
Validation loss: 1.720708021553614

Epoch: 5| Step: 10
Training loss: 0.3293509781360626
Validation loss: 1.7053609663440334

Epoch: 344| Step: 0
Training loss: 0.2836402952671051
Validation loss: 1.719847253573838

Epoch: 5| Step: 1
Training loss: 0.25559136271476746
Validation loss: 1.7469141649943527

Epoch: 5| Step: 2
Training loss: 0.3144757151603699
Validation loss: 1.7347350402544903

Epoch: 5| Step: 3
Training loss: 0.43423232436180115
Validation loss: 1.7758040607616465

Epoch: 5| Step: 4
Training loss: 0.24983704090118408
Validation loss: 1.7923718780599616

Epoch: 5| Step: 5
Training loss: 0.2161014974117279
Validation loss: 1.8309778821083806

Epoch: 5| Step: 6
Training loss: 0.2782534956932068
Validation loss: 1.818856131645941

Epoch: 5| Step: 7
Training loss: 0.17765586078166962
Validation loss: 1.79197568790887

Epoch: 5| Step: 8
Training loss: 0.3531179428100586
Validation loss: 1.7821678846113143

Epoch: 5| Step: 9
Training loss: 0.21784432232379913
Validation loss: 1.7456158361127299

Epoch: 5| Step: 10
Training loss: 0.27036988735198975
Validation loss: 1.7375672299374816

Epoch: 345| Step: 0
Training loss: 0.24593119323253632
Validation loss: 1.7429600479782268

Epoch: 5| Step: 1
Training loss: 0.23723670840263367
Validation loss: 1.7324066367200626

Epoch: 5| Step: 2
Training loss: 0.3569534420967102
Validation loss: 1.7383133313989128

Epoch: 5| Step: 3
Training loss: 0.2378098964691162
Validation loss: 1.7320144176483154

Epoch: 5| Step: 4
Training loss: 0.33425116539001465
Validation loss: 1.7509033474870908

Epoch: 5| Step: 5
Training loss: 0.29686233401298523
Validation loss: 1.7643536470269645

Epoch: 5| Step: 6
Training loss: 0.2808501124382019
Validation loss: 1.8165535503818142

Epoch: 5| Step: 7
Training loss: 0.3672865331172943
Validation loss: 1.832949379438995

Epoch: 5| Step: 8
Training loss: 0.49187931418418884
Validation loss: 1.9029721675380584

Epoch: 5| Step: 9
Training loss: 0.21281294524669647
Validation loss: 1.921673164572767

Epoch: 5| Step: 10
Training loss: 0.43688178062438965
Validation loss: 1.9098593547780027

Epoch: 346| Step: 0
Training loss: 0.4920472204685211
Validation loss: 1.884226534956245

Epoch: 5| Step: 1
Training loss: 0.20660224556922913
Validation loss: 1.825478273053323

Epoch: 5| Step: 2
Training loss: 0.16261963546276093
Validation loss: 1.8154411982464533

Epoch: 5| Step: 3
Training loss: 0.3032136857509613
Validation loss: 1.7671663043319539

Epoch: 5| Step: 4
Training loss: 0.15846876800060272
Validation loss: 1.7044881351532475

Epoch: 5| Step: 5
Training loss: 0.2744685411453247
Validation loss: 1.6768139921208864

Epoch: 5| Step: 6
Training loss: 0.25996917486190796
Validation loss: 1.6477894629201582

Epoch: 5| Step: 7
Training loss: 0.33492204546928406
Validation loss: 1.6412227640869796

Epoch: 5| Step: 8
Training loss: 0.294993132352829
Validation loss: 1.660893226182589

Epoch: 5| Step: 9
Training loss: 0.2429623156785965
Validation loss: 1.639840252296899

Epoch: 5| Step: 10
Training loss: 0.2868063747882843
Validation loss: 1.6699532706250426

Epoch: 347| Step: 0
Training loss: 0.18054074048995972
Validation loss: 1.6826557702915643

Epoch: 5| Step: 1
Training loss: 0.22164516150951385
Validation loss: 1.6977545997147918

Epoch: 5| Step: 2
Training loss: 0.24068768322467804
Validation loss: 1.7129137939022434

Epoch: 5| Step: 3
Training loss: 0.3467860817909241
Validation loss: 1.7443971685183945

Epoch: 5| Step: 4
Training loss: 0.24182970821857452
Validation loss: 1.7593813762869885

Epoch: 5| Step: 5
Training loss: 0.3631284832954407
Validation loss: 1.775700343552456

Epoch: 5| Step: 6
Training loss: 0.2789798378944397
Validation loss: 1.8012945434098602

Epoch: 5| Step: 7
Training loss: 0.19304943084716797
Validation loss: 1.7769585706854378

Epoch: 5| Step: 8
Training loss: 0.26282352209091187
Validation loss: 1.783900381416403

Epoch: 5| Step: 9
Training loss: 0.15482433140277863
Validation loss: 1.7610457122966807

Epoch: 5| Step: 10
Training loss: 0.20572373270988464
Validation loss: 1.7515610187284407

Epoch: 348| Step: 0
Training loss: 0.3233087658882141
Validation loss: 1.7437078209333523

Epoch: 5| Step: 1
Training loss: 0.39634591341018677
Validation loss: 1.6775062891744799

Epoch: 5| Step: 2
Training loss: 0.25164031982421875
Validation loss: 1.6795516385827014

Epoch: 5| Step: 3
Training loss: 0.2500767111778259
Validation loss: 1.6897950890243694

Epoch: 5| Step: 4
Training loss: 0.15872588753700256
Validation loss: 1.717293922619153

Epoch: 5| Step: 5
Training loss: 0.18772055208683014
Validation loss: 1.7216387487226916

Epoch: 5| Step: 6
Training loss: 0.20116367936134338
Validation loss: 1.7269261754969114

Epoch: 5| Step: 7
Training loss: 0.22400455176830292
Validation loss: 1.7095626272181028

Epoch: 5| Step: 8
Training loss: 0.1985793113708496
Validation loss: 1.7330739857048116

Epoch: 5| Step: 9
Training loss: 0.30158761143684387
Validation loss: 1.718201675722676

Epoch: 5| Step: 10
Training loss: 0.2606681287288666
Validation loss: 1.7391259413893505

Epoch: 349| Step: 0
Training loss: 0.1972770392894745
Validation loss: 1.720846055656351

Epoch: 5| Step: 1
Training loss: 0.19225254654884338
Validation loss: 1.737554927026072

Epoch: 5| Step: 2
Training loss: 0.24891304969787598
Validation loss: 1.7130696132618894

Epoch: 5| Step: 3
Training loss: 0.18515971302986145
Validation loss: 1.7122757588663409

Epoch: 5| Step: 4
Training loss: 0.28224247694015503
Validation loss: 1.745282325693356

Epoch: 5| Step: 5
Training loss: 0.23380358517169952
Validation loss: 1.8136160489051574

Epoch: 5| Step: 6
Training loss: 0.23778247833251953
Validation loss: 1.7752775761388964

Epoch: 5| Step: 7
Training loss: 0.4701833724975586
Validation loss: 1.798502024783883

Epoch: 5| Step: 8
Training loss: 0.21066513657569885
Validation loss: 1.7436827228915306

Epoch: 5| Step: 9
Training loss: 0.3883682191371918
Validation loss: 1.744224307357624

Epoch: 5| Step: 10
Training loss: 0.28212323784828186
Validation loss: 1.7386060222502677

Epoch: 350| Step: 0
Training loss: 0.2700905203819275
Validation loss: 1.7569211067691926

Epoch: 5| Step: 1
Training loss: 0.3564864695072174
Validation loss: 1.7741137044404143

Epoch: 5| Step: 2
Training loss: 0.20679643750190735
Validation loss: 1.8046095871156262

Epoch: 5| Step: 3
Training loss: 0.26993972063064575
Validation loss: 1.796728664828885

Epoch: 5| Step: 4
Training loss: 0.27582013607025146
Validation loss: 1.8214394251505535

Epoch: 5| Step: 5
Training loss: 0.2441394329071045
Validation loss: 1.8536842907628706

Epoch: 5| Step: 6
Training loss: 0.22014522552490234
Validation loss: 1.8331901565674813

Epoch: 5| Step: 7
Training loss: 0.2900712490081787
Validation loss: 1.8308968979825255

Epoch: 5| Step: 8
Training loss: 0.21745257079601288
Validation loss: 1.7879879192639423

Epoch: 5| Step: 9
Training loss: 0.2779853940010071
Validation loss: 1.7862583334727953

Epoch: 5| Step: 10
Training loss: 0.3485586941242218
Validation loss: 1.847127422209709

Epoch: 351| Step: 0
Training loss: 0.22845789790153503
Validation loss: 1.8025032986876786

Epoch: 5| Step: 1
Training loss: 0.25733041763305664
Validation loss: 1.7519472042719524

Epoch: 5| Step: 2
Training loss: 0.1691884696483612
Validation loss: 1.7348337840008479

Epoch: 5| Step: 3
Training loss: 0.27942991256713867
Validation loss: 1.6435382827635734

Epoch: 5| Step: 4
Training loss: 0.1934419870376587
Validation loss: 1.6564702167305896

Epoch: 5| Step: 5
Training loss: 0.13838844001293182
Validation loss: 1.6923791823848602

Epoch: 5| Step: 6
Training loss: 0.29054009914398193
Validation loss: 1.6603184758975942

Epoch: 5| Step: 7
Training loss: 0.3353463113307953
Validation loss: 1.6638688836046445

Epoch: 5| Step: 8
Training loss: 0.29485946893692017
Validation loss: 1.6693026045317292

Epoch: 5| Step: 9
Training loss: 0.22903554141521454
Validation loss: 1.6968529391032394

Epoch: 5| Step: 10
Training loss: 0.28190991282463074
Validation loss: 1.696672163983827

Epoch: 352| Step: 0
Training loss: 0.2384755164384842
Validation loss: 1.7121497251654183

Epoch: 5| Step: 1
Training loss: 0.25431185960769653
Validation loss: 1.7156194307470833

Epoch: 5| Step: 2
Training loss: 0.21933016180992126
Validation loss: 1.7158727825328868

Epoch: 5| Step: 3
Training loss: 0.19115015864372253
Validation loss: 1.669943851809348

Epoch: 5| Step: 4
Training loss: 0.2579191327095032
Validation loss: 1.6550860725423342

Epoch: 5| Step: 5
Training loss: 0.28053560853004456
Validation loss: 1.6369042845182522

Epoch: 5| Step: 6
Training loss: 0.47141727805137634
Validation loss: 1.6719353557914816

Epoch: 5| Step: 7
Training loss: 0.16532915830612183
Validation loss: 1.6849697533474173

Epoch: 5| Step: 8
Training loss: 0.18085958063602448
Validation loss: 1.714369052199907

Epoch: 5| Step: 9
Training loss: 0.17183668911457062
Validation loss: 1.728622882596908

Epoch: 5| Step: 10
Training loss: 0.3010082244873047
Validation loss: 1.7506470321327128

Epoch: 353| Step: 0
Training loss: 0.34985730051994324
Validation loss: 1.756466673266503

Epoch: 5| Step: 1
Training loss: 0.220126673579216
Validation loss: 1.810912186099637

Epoch: 5| Step: 2
Training loss: 0.33005350828170776
Validation loss: 1.8090583368014264

Epoch: 5| Step: 3
Training loss: 0.28207236528396606
Validation loss: 1.8142290730630197

Epoch: 5| Step: 4
Training loss: 0.2574920058250427
Validation loss: 1.8192710427827732

Epoch: 5| Step: 5
Training loss: 0.30550312995910645
Validation loss: 1.8215949996825187

Epoch: 5| Step: 6
Training loss: 0.10285349935293198
Validation loss: 1.775562588886548

Epoch: 5| Step: 7
Training loss: 0.2757187485694885
Validation loss: 1.741985362063172

Epoch: 5| Step: 8
Training loss: 0.2221030741930008
Validation loss: 1.7314217077788485

Epoch: 5| Step: 9
Training loss: 0.21569092571735382
Validation loss: 1.7071264443858978

Epoch: 5| Step: 10
Training loss: 0.2930237054824829
Validation loss: 1.6878491165817424

Epoch: 354| Step: 0
Training loss: 0.23085752129554749
Validation loss: 1.6887948096439402

Epoch: 5| Step: 1
Training loss: 0.20419840514659882
Validation loss: 1.7080525275199645

Epoch: 5| Step: 2
Training loss: 0.2539449632167816
Validation loss: 1.7208360472033102

Epoch: 5| Step: 3
Training loss: 0.31489500403404236
Validation loss: 1.7717557991704633

Epoch: 5| Step: 4
Training loss: 0.1737179011106491
Validation loss: 1.7758989385379258

Epoch: 5| Step: 5
Training loss: 0.2976262867450714
Validation loss: 1.7766466474020353

Epoch: 5| Step: 6
Training loss: 0.18591582775115967
Validation loss: 1.7903666009185135

Epoch: 5| Step: 7
Training loss: 0.25918152928352356
Validation loss: 1.773666097271827

Epoch: 5| Step: 8
Training loss: 0.48118719458580017
Validation loss: 1.779030607592675

Epoch: 5| Step: 9
Training loss: 0.21703751385211945
Validation loss: 1.7486776408328806

Epoch: 5| Step: 10
Training loss: 0.26345011591911316
Validation loss: 1.7364300271516204

Epoch: 355| Step: 0
Training loss: 0.18384316563606262
Validation loss: 1.7327412815504177

Epoch: 5| Step: 1
Training loss: 0.1639283448457718
Validation loss: 1.7214888231728667

Epoch: 5| Step: 2
Training loss: 0.22279253602027893
Validation loss: 1.7089885934706657

Epoch: 5| Step: 3
Training loss: 0.23041629791259766
Validation loss: 1.744479763892389

Epoch: 5| Step: 4
Training loss: 0.20306634902954102
Validation loss: 1.7413546616031277

Epoch: 5| Step: 5
Training loss: 0.2886511981487274
Validation loss: 1.747382918993632

Epoch: 5| Step: 6
Training loss: 0.2526983618736267
Validation loss: 1.7319384928672545

Epoch: 5| Step: 7
Training loss: 0.3601057827472687
Validation loss: 1.7234251640176261

Epoch: 5| Step: 8
Training loss: 0.27909988164901733
Validation loss: 1.738333015031712

Epoch: 5| Step: 9
Training loss: 0.23044435679912567
Validation loss: 1.7744532144197853

Epoch: 5| Step: 10
Training loss: 0.27083620429039
Validation loss: 1.7367903314610964

Epoch: 356| Step: 0
Training loss: 0.17210768163204193
Validation loss: 1.7524774971828665

Epoch: 5| Step: 1
Training loss: 0.345203161239624
Validation loss: 1.7443536250822005

Epoch: 5| Step: 2
Training loss: 0.16348566114902496
Validation loss: 1.744458742039178

Epoch: 5| Step: 3
Training loss: 0.334389865398407
Validation loss: 1.736042691815284

Epoch: 5| Step: 4
Training loss: 0.2408420592546463
Validation loss: 1.694477403035728

Epoch: 5| Step: 5
Training loss: 0.22112612426280975
Validation loss: 1.7195575993548158

Epoch: 5| Step: 6
Training loss: 0.15420867502689362
Validation loss: 1.7110347722166328

Epoch: 5| Step: 7
Training loss: 0.2639363408088684
Validation loss: 1.715968535792443

Epoch: 5| Step: 8
Training loss: 0.2543160617351532
Validation loss: 1.7369586524143015

Epoch: 5| Step: 9
Training loss: 0.48028331995010376
Validation loss: 1.7647551836506012

Epoch: 5| Step: 10
Training loss: 0.15012170374393463
Validation loss: 1.7850024084891043

Epoch: 357| Step: 0
Training loss: 0.23154854774475098
Validation loss: 1.7768875296397875

Epoch: 5| Step: 1
Training loss: 0.20376083254814148
Validation loss: 1.7767104423174294

Epoch: 5| Step: 2
Training loss: 0.21673035621643066
Validation loss: 1.7448768128630936

Epoch: 5| Step: 3
Training loss: 0.2818365693092346
Validation loss: 1.7323164196424587

Epoch: 5| Step: 4
Training loss: 0.1942843496799469
Validation loss: 1.7281933189720236

Epoch: 5| Step: 5
Training loss: 0.2078438699245453
Validation loss: 1.71429491812183

Epoch: 5| Step: 6
Training loss: 0.2615857720375061
Validation loss: 1.6835798678859588

Epoch: 5| Step: 7
Training loss: 0.42796602845191956
Validation loss: 1.6795100371042888

Epoch: 5| Step: 8
Training loss: 0.23949730396270752
Validation loss: 1.686858360485364

Epoch: 5| Step: 9
Training loss: 0.23454880714416504
Validation loss: 1.6598418220396964

Epoch: 5| Step: 10
Training loss: 0.2089388519525528
Validation loss: 1.6477711687805832

Epoch: 358| Step: 0
Training loss: 0.16288363933563232
Validation loss: 1.6708457034121278

Epoch: 5| Step: 1
Training loss: 0.21341681480407715
Validation loss: 1.7032242218653362

Epoch: 5| Step: 2
Training loss: 0.270995557308197
Validation loss: 1.7229461349466795

Epoch: 5| Step: 3
Training loss: 0.24202747642993927
Validation loss: 1.724314292271932

Epoch: 5| Step: 4
Training loss: 0.18929152190685272
Validation loss: 1.7451443261997674

Epoch: 5| Step: 5
Training loss: 0.30142006278038025
Validation loss: 1.7613401521918595

Epoch: 5| Step: 6
Training loss: 0.2494823932647705
Validation loss: 1.7503045399983723

Epoch: 5| Step: 7
Training loss: 0.3568207919597626
Validation loss: 1.7241705656051636

Epoch: 5| Step: 8
Training loss: 0.2561430037021637
Validation loss: 1.7430343653566094

Epoch: 5| Step: 9
Training loss: 0.17729470133781433
Validation loss: 1.7627019337428513

Epoch: 5| Step: 10
Training loss: 0.13347086310386658
Validation loss: 1.7214550382347518

Epoch: 359| Step: 0
Training loss: 0.06784216314554214
Validation loss: 1.7413255296727663

Epoch: 5| Step: 1
Training loss: 0.1705867499113083
Validation loss: 1.7294303896606609

Epoch: 5| Step: 2
Training loss: 0.3179897367954254
Validation loss: 1.7315732330404303

Epoch: 5| Step: 3
Training loss: 0.1919964849948883
Validation loss: 1.7150443164251183

Epoch: 5| Step: 4
Training loss: 0.20386724174022675
Validation loss: 1.732295185007075

Epoch: 5| Step: 5
Training loss: 0.1680907905101776
Validation loss: 1.718274167788926

Epoch: 5| Step: 6
Training loss: 0.3156960904598236
Validation loss: 1.7463021457836192

Epoch: 5| Step: 7
Training loss: 0.31263890862464905
Validation loss: 1.7202026703024422

Epoch: 5| Step: 8
Training loss: 0.19407378137111664
Validation loss: 1.7361826755667245

Epoch: 5| Step: 9
Training loss: 0.18444159626960754
Validation loss: 1.7365954960546186

Epoch: 5| Step: 10
Training loss: 0.2496728003025055
Validation loss: 1.7333843182492

Epoch: 360| Step: 0
Training loss: 0.3286772072315216
Validation loss: 1.7464651318006619

Epoch: 5| Step: 1
Training loss: 0.19307760894298553
Validation loss: 1.7175065176461333

Epoch: 5| Step: 2
Training loss: 0.2264564484357834
Validation loss: 1.7287322769882858

Epoch: 5| Step: 3
Training loss: 0.1609117090702057
Validation loss: 1.726130763689677

Epoch: 5| Step: 4
Training loss: 0.23569519817829132
Validation loss: 1.7321238645943262

Epoch: 5| Step: 5
Training loss: 0.27076253294944763
Validation loss: 1.7444808111395886

Epoch: 5| Step: 6
Training loss: 0.2651594579219818
Validation loss: 1.7667209230443484

Epoch: 5| Step: 7
Training loss: 0.27451008558273315
Validation loss: 1.716757316743174

Epoch: 5| Step: 8
Training loss: 0.13737192749977112
Validation loss: 1.7364645875910276

Epoch: 5| Step: 9
Training loss: 0.17852862179279327
Validation loss: 1.7055613943325576

Epoch: 5| Step: 10
Training loss: 0.20814959704875946
Validation loss: 1.6966668328931254

Epoch: 361| Step: 0
Training loss: 0.21471290290355682
Validation loss: 1.705779420432224

Epoch: 5| Step: 1
Training loss: 0.20316310226917267
Validation loss: 1.6836300537150393

Epoch: 5| Step: 2
Training loss: 0.1485554277896881
Validation loss: 1.699459284864446

Epoch: 5| Step: 3
Training loss: 0.33331307768821716
Validation loss: 1.7215848007509786

Epoch: 5| Step: 4
Training loss: 0.27122753858566284
Validation loss: 1.6895752312034689

Epoch: 5| Step: 5
Training loss: 0.2887052595615387
Validation loss: 1.6892400659540647

Epoch: 5| Step: 6
Training loss: 0.22483977675437927
Validation loss: 1.7076732099697154

Epoch: 5| Step: 7
Training loss: 0.15809108316898346
Validation loss: 1.7317116491256221

Epoch: 5| Step: 8
Training loss: 0.18683215975761414
Validation loss: 1.750736641627486

Epoch: 5| Step: 9
Training loss: 0.2726263403892517
Validation loss: 1.7268395321343535

Epoch: 5| Step: 10
Training loss: 0.3225555717945099
Validation loss: 1.7696262303219046

Epoch: 362| Step: 0
Training loss: 0.21673643589019775
Validation loss: 1.729946082638156

Epoch: 5| Step: 1
Training loss: 0.20669059455394745
Validation loss: 1.7489126305426321

Epoch: 5| Step: 2
Training loss: 0.27826330065727234
Validation loss: 1.739543136729989

Epoch: 5| Step: 3
Training loss: 0.25006338953971863
Validation loss: 1.6818112429752146

Epoch: 5| Step: 4
Training loss: 0.27571865916252136
Validation loss: 1.682718244932031

Epoch: 5| Step: 5
Training loss: 0.09334088861942291
Validation loss: 1.6944489325246503

Epoch: 5| Step: 6
Training loss: 0.19245056807994843
Validation loss: 1.6795409059011808

Epoch: 5| Step: 7
Training loss: 0.1596992313861847
Validation loss: 1.689039687956533

Epoch: 5| Step: 8
Training loss: 0.271592915058136
Validation loss: 1.6912028840793076

Epoch: 5| Step: 9
Training loss: 0.2880740761756897
Validation loss: 1.6870361335815922

Epoch: 5| Step: 10
Training loss: 0.20290111005306244
Validation loss: 1.7122724761245072

Epoch: 363| Step: 0
Training loss: 0.13273850083351135
Validation loss: 1.7097918166909167

Epoch: 5| Step: 1
Training loss: 0.35569852590560913
Validation loss: 1.7263525019409836

Epoch: 5| Step: 2
Training loss: 0.2114085704088211
Validation loss: 1.7289659566776727

Epoch: 5| Step: 3
Training loss: 0.16686637699604034
Validation loss: 1.7370727305771203

Epoch: 5| Step: 4
Training loss: 0.2399558126926422
Validation loss: 1.750337218725553

Epoch: 5| Step: 5
Training loss: 0.20091331005096436
Validation loss: 1.762207886224152

Epoch: 5| Step: 6
Training loss: 0.22369155287742615
Validation loss: 1.7267767819025184

Epoch: 5| Step: 7
Training loss: 0.17588774859905243
Validation loss: 1.767408879854346

Epoch: 5| Step: 8
Training loss: 0.14942464232444763
Validation loss: 1.7609832991835892

Epoch: 5| Step: 9
Training loss: 0.2157469242811203
Validation loss: 1.76266784052695

Epoch: 5| Step: 10
Training loss: 0.23262673616409302
Validation loss: 1.7847303728903494

Epoch: 364| Step: 0
Training loss: 0.26044270396232605
Validation loss: 1.7923824325684579

Epoch: 5| Step: 1
Training loss: 0.11413837969303131
Validation loss: 1.7964753732886365

Epoch: 5| Step: 2
Training loss: 0.19498386979103088
Validation loss: 1.815393473512383

Epoch: 5| Step: 3
Training loss: 0.2864225506782532
Validation loss: 1.7943870098360124

Epoch: 5| Step: 4
Training loss: 0.42936834692955017
Validation loss: 1.8274412257696993

Epoch: 5| Step: 5
Training loss: 0.15925940871238708
Validation loss: 1.7778030005834435

Epoch: 5| Step: 6
Training loss: 0.18185821175575256
Validation loss: 1.7881650104317615

Epoch: 5| Step: 7
Training loss: 0.25052446126937866
Validation loss: 1.7688980422994143

Epoch: 5| Step: 8
Training loss: 0.13406316936016083
Validation loss: 1.7178507633106683

Epoch: 5| Step: 9
Training loss: 0.1752014309167862
Validation loss: 1.6982943345141668

Epoch: 5| Step: 10
Training loss: 0.281312495470047
Validation loss: 1.6583042862594768

Epoch: 365| Step: 0
Training loss: 0.22735543549060822
Validation loss: 1.6400525249460691

Epoch: 5| Step: 1
Training loss: 0.36716461181640625
Validation loss: 1.6048008844416628

Epoch: 5| Step: 2
Training loss: 0.23135881125926971
Validation loss: 1.6340260813313146

Epoch: 5| Step: 3
Training loss: 0.1606844961643219
Validation loss: 1.6449154935857302

Epoch: 5| Step: 4
Training loss: 0.14177349209785461
Validation loss: 1.6702476188700686

Epoch: 5| Step: 5
Training loss: 0.13556402921676636
Validation loss: 1.6743352054267802

Epoch: 5| Step: 6
Training loss: 0.2013208419084549
Validation loss: 1.6908629286673762

Epoch: 5| Step: 7
Training loss: 0.32402628660202026
Validation loss: 1.6965502603079683

Epoch: 5| Step: 8
Training loss: 0.2636958062648773
Validation loss: 1.6912434870196926

Epoch: 5| Step: 9
Training loss: 0.18514391779899597
Validation loss: 1.6959050393873645

Epoch: 5| Step: 10
Training loss: 0.08388472348451614
Validation loss: 1.6818150999725505

Epoch: 366| Step: 0
Training loss: 0.1311112344264984
Validation loss: 1.6892137988921134

Epoch: 5| Step: 1
Training loss: 0.2929721474647522
Validation loss: 1.681047442138836

Epoch: 5| Step: 2
Training loss: 0.15013818442821503
Validation loss: 1.6602882621108845

Epoch: 5| Step: 3
Training loss: 0.3058016896247864
Validation loss: 1.668713051785705

Epoch: 5| Step: 4
Training loss: 0.169931560754776
Validation loss: 1.671410111970799

Epoch: 5| Step: 5
Training loss: 0.17799103260040283
Validation loss: 1.6501603664890412

Epoch: 5| Step: 6
Training loss: 0.21744167804718018
Validation loss: 1.6647383538625573

Epoch: 5| Step: 7
Training loss: 0.28645503520965576
Validation loss: 1.6397174712150329

Epoch: 5| Step: 8
Training loss: 0.1892862468957901
Validation loss: 1.6489922936244676

Epoch: 5| Step: 9
Training loss: 0.2621133625507355
Validation loss: 1.6468968955419396

Epoch: 5| Step: 10
Training loss: 0.14261843264102936
Validation loss: 1.6639644638184579

Epoch: 367| Step: 0
Training loss: 0.18965795636177063
Validation loss: 1.6875882430743145

Epoch: 5| Step: 1
Training loss: 0.2739422917366028
Validation loss: 1.7019899301631476

Epoch: 5| Step: 2
Training loss: 0.10774459689855576
Validation loss: 1.7000649808555521

Epoch: 5| Step: 3
Training loss: 0.2532579004764557
Validation loss: 1.663775005648213

Epoch: 5| Step: 4
Training loss: 0.2058020532131195
Validation loss: 1.6744562913012762

Epoch: 5| Step: 5
Training loss: 0.16869759559631348
Validation loss: 1.68252149961328

Epoch: 5| Step: 6
Training loss: 0.21373817324638367
Validation loss: 1.7164367296362435

Epoch: 5| Step: 7
Training loss: 0.21342892944812775
Validation loss: 1.7116719932966336

Epoch: 5| Step: 8
Training loss: 0.250932902097702
Validation loss: 1.6907850439830492

Epoch: 5| Step: 9
Training loss: 0.29931825399398804
Validation loss: 1.6994975279736262

Epoch: 5| Step: 10
Training loss: 0.2086583375930786
Validation loss: 1.687767251845329

Epoch: 368| Step: 0
Training loss: 0.19890092313289642
Validation loss: 1.709567459680701

Epoch: 5| Step: 1
Training loss: 0.158603236079216
Validation loss: 1.6956365467399679

Epoch: 5| Step: 2
Training loss: 0.3181142508983612
Validation loss: 1.7345864401068738

Epoch: 5| Step: 3
Training loss: 0.21658320724964142
Validation loss: 1.7386574065813454

Epoch: 5| Step: 4
Training loss: 0.34697288274765015
Validation loss: 1.7203513447956373

Epoch: 5| Step: 5
Training loss: 0.19617320597171783
Validation loss: 1.69921907301872

Epoch: 5| Step: 6
Training loss: 0.19433598220348358
Validation loss: 1.708173519180667

Epoch: 5| Step: 7
Training loss: 0.312120258808136
Validation loss: 1.7144694661581388

Epoch: 5| Step: 8
Training loss: 0.24574236571788788
Validation loss: 1.6997519654612387

Epoch: 5| Step: 9
Training loss: 0.13571171462535858
Validation loss: 1.7037344260882306

Epoch: 5| Step: 10
Training loss: 0.1252972036600113
Validation loss: 1.7395697793652933

Epoch: 369| Step: 0
Training loss: 0.1872483789920807
Validation loss: 1.7527950220210577

Epoch: 5| Step: 1
Training loss: 0.18137410283088684
Validation loss: 1.8017512111253635

Epoch: 5| Step: 2
Training loss: 0.21442833542823792
Validation loss: 1.8122430129717755

Epoch: 5| Step: 3
Training loss: 0.22015896439552307
Validation loss: 1.8129131197929382

Epoch: 5| Step: 4
Training loss: 0.2455856055021286
Validation loss: 1.8071010804945422

Epoch: 5| Step: 5
Training loss: 0.21279151737689972
Validation loss: 1.7657722324453375

Epoch: 5| Step: 6
Training loss: 0.4125064015388489
Validation loss: 1.7367843184419858

Epoch: 5| Step: 7
Training loss: 0.21272464096546173
Validation loss: 1.7199298553569342

Epoch: 5| Step: 8
Training loss: 0.17144611477851868
Validation loss: 1.708266620994896

Epoch: 5| Step: 9
Training loss: 0.15656700730323792
Validation loss: 1.6957930288007181

Epoch: 5| Step: 10
Training loss: 0.204166442155838
Validation loss: 1.6981927130811958

Epoch: 370| Step: 0
Training loss: 0.18743093311786652
Validation loss: 1.7216864273112307

Epoch: 5| Step: 1
Training loss: 0.14471028745174408
Validation loss: 1.7430381736447733

Epoch: 5| Step: 2
Training loss: 0.2136508971452713
Validation loss: 1.7261151152272378

Epoch: 5| Step: 3
Training loss: 0.2267284393310547
Validation loss: 1.69232117232456

Epoch: 5| Step: 4
Training loss: 0.2702682614326477
Validation loss: 1.7124841649045226

Epoch: 5| Step: 5
Training loss: 0.16319996118545532
Validation loss: 1.6810945233991068

Epoch: 5| Step: 6
Training loss: 0.22269919514656067
Validation loss: 1.7223999859184347

Epoch: 5| Step: 7
Training loss: 0.20521727204322815
Validation loss: 1.7571616480427403

Epoch: 5| Step: 8
Training loss: 0.22128944098949432
Validation loss: 1.7801121896313084

Epoch: 5| Step: 9
Training loss: 0.40467697381973267
Validation loss: 1.7664124593939832

Epoch: 5| Step: 10
Training loss: 0.21295250952243805
Validation loss: 1.7663190441746865

Epoch: 371| Step: 0
Training loss: 0.13669607043266296
Validation loss: 1.7524277702454598

Epoch: 5| Step: 1
Training loss: 0.11671491712331772
Validation loss: 1.7321231929204797

Epoch: 5| Step: 2
Training loss: 0.14606256783008575
Validation loss: 1.694958786810598

Epoch: 5| Step: 3
Training loss: 0.23866935074329376
Validation loss: 1.685080344958972

Epoch: 5| Step: 4
Training loss: 0.178266242146492
Validation loss: 1.6650396829010339

Epoch: 5| Step: 5
Training loss: 0.2576771676540375
Validation loss: 1.7060325966086438

Epoch: 5| Step: 6
Training loss: 0.32229989767074585
Validation loss: 1.6553830613372147

Epoch: 5| Step: 7
Training loss: 0.18304049968719482
Validation loss: 1.680299138510099

Epoch: 5| Step: 8
Training loss: 0.22923102974891663
Validation loss: 1.6878255131424114

Epoch: 5| Step: 9
Training loss: 0.21195948123931885
Validation loss: 1.6790851098234936

Epoch: 5| Step: 10
Training loss: 0.20039527118206024
Validation loss: 1.712650458017985

Epoch: 372| Step: 0
Training loss: 0.18171778321266174
Validation loss: 1.6818824070756153

Epoch: 5| Step: 1
Training loss: 0.13425317406654358
Validation loss: 1.7309157784267137

Epoch: 5| Step: 2
Training loss: 0.24035851657390594
Validation loss: 1.7365719361971783

Epoch: 5| Step: 3
Training loss: 0.24301819503307343
Validation loss: 1.764139921434464

Epoch: 5| Step: 4
Training loss: 0.17467239499092102
Validation loss: 1.770630354522377

Epoch: 5| Step: 5
Training loss: 0.1533108353614807
Validation loss: 1.7324509864212365

Epoch: 5| Step: 6
Training loss: 0.26403868198394775
Validation loss: 1.7019989336690595

Epoch: 5| Step: 7
Training loss: 0.18957968056201935
Validation loss: 1.6976127765511955

Epoch: 5| Step: 8
Training loss: 0.2705623507499695
Validation loss: 1.6912225779666696

Epoch: 5| Step: 9
Training loss: 0.18427030742168427
Validation loss: 1.6280328996719853

Epoch: 5| Step: 10
Training loss: 0.12281554937362671
Validation loss: 1.645191966846425

Epoch: 373| Step: 0
Training loss: 0.16988417506217957
Validation loss: 1.6075601475213164

Epoch: 5| Step: 1
Training loss: 0.26604682207107544
Validation loss: 1.6105937880854453

Epoch: 5| Step: 2
Training loss: 0.2381383627653122
Validation loss: 1.6251936253680979

Epoch: 5| Step: 3
Training loss: 0.17215584218502045
Validation loss: 1.5994300021920154

Epoch: 5| Step: 4
Training loss: 0.3160889446735382
Validation loss: 1.5914265301919752

Epoch: 5| Step: 5
Training loss: 0.1933322250843048
Validation loss: 1.6464949987267936

Epoch: 5| Step: 6
Training loss: 0.1410783976316452
Validation loss: 1.6706244868616904

Epoch: 5| Step: 7
Training loss: 0.21689581871032715
Validation loss: 1.7226911642218148

Epoch: 5| Step: 8
Training loss: 0.13049714267253876
Validation loss: 1.7496782707911667

Epoch: 5| Step: 9
Training loss: 0.18972665071487427
Validation loss: 1.7491752691166376

Epoch: 5| Step: 10
Training loss: 0.21414229273796082
Validation loss: 1.7149881137314664

Epoch: 374| Step: 0
Training loss: 0.2959020137786865
Validation loss: 1.7083603259055846

Epoch: 5| Step: 1
Training loss: 0.20480258762836456
Validation loss: 1.6792858967217066

Epoch: 5| Step: 2
Training loss: 0.17299462854862213
Validation loss: 1.679601502674882

Epoch: 5| Step: 3
Training loss: 0.21350841224193573
Validation loss: 1.6754276842199347

Epoch: 5| Step: 4
Training loss: 0.14772644639015198
Validation loss: 1.6598059054343932

Epoch: 5| Step: 5
Training loss: 0.20276427268981934
Validation loss: 1.683226748179364

Epoch: 5| Step: 6
Training loss: 0.22260236740112305
Validation loss: 1.6838195375216904

Epoch: 5| Step: 7
Training loss: 0.29489797353744507
Validation loss: 1.6780440076704948

Epoch: 5| Step: 8
Training loss: 0.2922138273715973
Validation loss: 1.6758692187647666

Epoch: 5| Step: 9
Training loss: 0.17979776859283447
Validation loss: 1.620921891222718

Epoch: 5| Step: 10
Training loss: 0.19918391108512878
Validation loss: 1.6313132906472811

Epoch: 375| Step: 0
Training loss: 0.19863104820251465
Validation loss: 1.6127411691091393

Epoch: 5| Step: 1
Training loss: 0.23766008019447327
Validation loss: 1.6408970304714736

Epoch: 5| Step: 2
Training loss: 0.22905179858207703
Validation loss: 1.650061381760464

Epoch: 5| Step: 3
Training loss: 0.15629342198371887
Validation loss: 1.6720234232564126

Epoch: 5| Step: 4
Training loss: 0.19502831995487213
Validation loss: 1.6617138103772235

Epoch: 5| Step: 5
Training loss: 0.12856292724609375
Validation loss: 1.696373833763984

Epoch: 5| Step: 6
Training loss: 0.24149122834205627
Validation loss: 1.7082133216242636

Epoch: 5| Step: 7
Training loss: 0.10589520633220673
Validation loss: 1.7234335612225276

Epoch: 5| Step: 8
Training loss: 0.36460065841674805
Validation loss: 1.70777883965482

Epoch: 5| Step: 9
Training loss: 0.23013488948345184
Validation loss: 1.7355323030102638

Epoch: 5| Step: 10
Training loss: 0.16762377321720123
Validation loss: 1.7085593342781067

Epoch: 376| Step: 0
Training loss: 0.16913127899169922
Validation loss: 1.6567947287713327

Epoch: 5| Step: 1
Training loss: 0.35077011585235596
Validation loss: 1.6729338348552745

Epoch: 5| Step: 2
Training loss: 0.16284748911857605
Validation loss: 1.662523805454213

Epoch: 5| Step: 3
Training loss: 0.2239340841770172
Validation loss: 1.6409230744966896

Epoch: 5| Step: 4
Training loss: 0.17441344261169434
Validation loss: 1.6459748027145222

Epoch: 5| Step: 5
Training loss: 0.2483665496110916
Validation loss: 1.6682047792660293

Epoch: 5| Step: 6
Training loss: 0.18859685957431793
Validation loss: 1.6817112186903596

Epoch: 5| Step: 7
Training loss: 0.24179907143115997
Validation loss: 1.6882212162017822

Epoch: 5| Step: 8
Training loss: 0.149418443441391
Validation loss: 1.6747159983522149

Epoch: 5| Step: 9
Training loss: 0.14177733659744263
Validation loss: 1.650683872161373

Epoch: 5| Step: 10
Training loss: 0.14263758063316345
Validation loss: 1.661405146762889

Epoch: 377| Step: 0
Training loss: 0.13592085242271423
Validation loss: 1.6307085637123353

Epoch: 5| Step: 1
Training loss: 0.2631508708000183
Validation loss: 1.6536356979800808

Epoch: 5| Step: 2
Training loss: 0.10722122341394424
Validation loss: 1.644348696995807

Epoch: 5| Step: 3
Training loss: 0.24338750541210175
Validation loss: 1.6323033481515863

Epoch: 5| Step: 4
Training loss: 0.22611960768699646
Validation loss: 1.6179140293469993

Epoch: 5| Step: 5
Training loss: 0.2712068557739258
Validation loss: 1.6073737605925529

Epoch: 5| Step: 6
Training loss: 0.18893639743328094
Validation loss: 1.6353961895870905

Epoch: 5| Step: 7
Training loss: 0.22799372673034668
Validation loss: 1.6177327171448739

Epoch: 5| Step: 8
Training loss: 0.24560876190662384
Validation loss: 1.6807631202923354

Epoch: 5| Step: 9
Training loss: 0.2088029384613037
Validation loss: 1.6765002524980934

Epoch: 5| Step: 10
Training loss: 0.1748199164867401
Validation loss: 1.7145532433704664

Epoch: 378| Step: 0
Training loss: 0.17031940817832947
Validation loss: 1.7497751764071885

Epoch: 5| Step: 1
Training loss: 0.21869853138923645
Validation loss: 1.7615834448927192

Epoch: 5| Step: 2
Training loss: 0.1609695851802826
Validation loss: 1.719381647725259

Epoch: 5| Step: 3
Training loss: 0.25033727288246155
Validation loss: 1.6875143320329729

Epoch: 5| Step: 4
Training loss: 0.22671246528625488
Validation loss: 1.7078345732022358

Epoch: 5| Step: 5
Training loss: 0.2785261869430542
Validation loss: 1.6701220555972027

Epoch: 5| Step: 6
Training loss: 0.15439075231552124
Validation loss: 1.637351671854655

Epoch: 5| Step: 7
Training loss: 0.228657528758049
Validation loss: 1.660627084393655

Epoch: 5| Step: 8
Training loss: 0.2808721363544464
Validation loss: 1.6334909277577554

Epoch: 5| Step: 9
Training loss: 0.3348556458950043
Validation loss: 1.6572656785288165

Epoch: 5| Step: 10
Training loss: 0.2846243381500244
Validation loss: 1.6808519453130744

Epoch: 379| Step: 0
Training loss: 0.12828317284584045
Validation loss: 1.7037749085375058

Epoch: 5| Step: 1
Training loss: 0.18017593026161194
Validation loss: 1.7514750598579325

Epoch: 5| Step: 2
Training loss: 0.19086292386054993
Validation loss: 1.7840990148564821

Epoch: 5| Step: 3
Training loss: 0.2878451943397522
Validation loss: 1.8236289261489786

Epoch: 5| Step: 4
Training loss: 0.21311549842357635
Validation loss: 1.8071239673963158

Epoch: 5| Step: 5
Training loss: 0.23877255618572235
Validation loss: 1.820415235334827

Epoch: 5| Step: 6
Training loss: 0.33310994505882263
Validation loss: 1.7645256327044578

Epoch: 5| Step: 7
Training loss: 0.166416198015213
Validation loss: 1.7076421681270804

Epoch: 5| Step: 8
Training loss: 0.23709750175476074
Validation loss: 1.6531446467163742

Epoch: 5| Step: 9
Training loss: 0.2059023678302765
Validation loss: 1.6331855635489188

Epoch: 5| Step: 10
Training loss: 0.26396214962005615
Validation loss: 1.5899764914666452

Epoch: 380| Step: 0
Training loss: 0.2505030035972595
Validation loss: 1.5953990003114105

Epoch: 5| Step: 1
Training loss: 0.29384011030197144
Validation loss: 1.591849055341495

Epoch: 5| Step: 2
Training loss: 0.1523362398147583
Validation loss: 1.5896217105209187

Epoch: 5| Step: 3
Training loss: 0.1949964463710785
Validation loss: 1.5772881866783224

Epoch: 5| Step: 4
Training loss: 0.22403588891029358
Validation loss: 1.6101571923942977

Epoch: 5| Step: 5
Training loss: 0.18828341364860535
Validation loss: 1.6560020715959611

Epoch: 5| Step: 6
Training loss: 0.2621426582336426
Validation loss: 1.7195195036549722

Epoch: 5| Step: 7
Training loss: 0.2689730226993561
Validation loss: 1.772163780786658

Epoch: 5| Step: 8
Training loss: 0.35966670513153076
Validation loss: 1.7626591638852191

Epoch: 5| Step: 9
Training loss: 0.27422061562538147
Validation loss: 1.7575205884953982

Epoch: 5| Step: 10
Training loss: 0.17640820145606995
Validation loss: 1.7508422354216218

Epoch: 381| Step: 0
Training loss: 0.1961871236562729
Validation loss: 1.7553426117025397

Epoch: 5| Step: 1
Training loss: 0.1437285840511322
Validation loss: 1.7575043055319017

Epoch: 5| Step: 2
Training loss: 0.320090651512146
Validation loss: 1.7512872706177414

Epoch: 5| Step: 3
Training loss: 0.20008715987205505
Validation loss: 1.7459953292723625

Epoch: 5| Step: 4
Training loss: 0.24322375655174255
Validation loss: 1.6861734005712694

Epoch: 5| Step: 5
Training loss: 0.23982617259025574
Validation loss: 1.6967386071399977

Epoch: 5| Step: 6
Training loss: 0.20303845405578613
Validation loss: 1.6773704591617788

Epoch: 5| Step: 7
Training loss: 0.2153429090976715
Validation loss: 1.6845386848654798

Epoch: 5| Step: 8
Training loss: 0.16214457154273987
Validation loss: 1.6578968545441986

Epoch: 5| Step: 9
Training loss: 0.17434152960777283
Validation loss: 1.6489384020528486

Epoch: 5| Step: 10
Training loss: 0.2701093256473541
Validation loss: 1.6548162647472915

Epoch: 382| Step: 0
Training loss: 0.1452721506357193
Validation loss: 1.632154437803453

Epoch: 5| Step: 1
Training loss: 0.213099405169487
Validation loss: 1.6221091106373777

Epoch: 5| Step: 2
Training loss: 0.16186583042144775
Validation loss: 1.6307876712532454

Epoch: 5| Step: 3
Training loss: 0.21673235297203064
Validation loss: 1.631546361472017

Epoch: 5| Step: 4
Training loss: 0.17935916781425476
Validation loss: 1.6538187816578855

Epoch: 5| Step: 5
Training loss: 0.24895386397838593
Validation loss: 1.6937768459320068

Epoch: 5| Step: 6
Training loss: 0.16229791939258575
Validation loss: 1.6983412696469216

Epoch: 5| Step: 7
Training loss: 0.14524856209754944
Validation loss: 1.718412910738299

Epoch: 5| Step: 8
Training loss: 0.2175549566745758
Validation loss: 1.6971690321481356

Epoch: 5| Step: 9
Training loss: 0.3246302306652069
Validation loss: 1.6904005363423338

Epoch: 5| Step: 10
Training loss: 0.27732232213020325
Validation loss: 1.6922813025853967

Epoch: 383| Step: 0
Training loss: 0.21411137282848358
Validation loss: 1.6456359970954157

Epoch: 5| Step: 1
Training loss: 0.17764288187026978
Validation loss: 1.6464697660938385

Epoch: 5| Step: 2
Training loss: 0.1109561175107956
Validation loss: 1.6513270870331795

Epoch: 5| Step: 3
Training loss: 0.22247925400733948
Validation loss: 1.6605420638156194

Epoch: 5| Step: 4
Training loss: 0.16087080538272858
Validation loss: 1.6403564637707126

Epoch: 5| Step: 5
Training loss: 0.20768645405769348
Validation loss: 1.658586113683639

Epoch: 5| Step: 6
Training loss: 0.18279854953289032
Validation loss: 1.6971515840099705

Epoch: 5| Step: 7
Training loss: 0.1695324033498764
Validation loss: 1.700699895940801

Epoch: 5| Step: 8
Training loss: 0.2374579906463623
Validation loss: 1.678250398687137

Epoch: 5| Step: 9
Training loss: 0.15655680000782013
Validation loss: 1.650130259093418

Epoch: 5| Step: 10
Training loss: 0.20163626968860626
Validation loss: 1.6574982584163707

Epoch: 384| Step: 0
Training loss: 0.1593608260154724
Validation loss: 1.6329566624856764

Epoch: 5| Step: 1
Training loss: 0.25622767210006714
Validation loss: 1.6300144169920234

Epoch: 5| Step: 2
Training loss: 0.18345527350902557
Validation loss: 1.6547995716012933

Epoch: 5| Step: 3
Training loss: 0.14798466861248016
Validation loss: 1.6748763463830436

Epoch: 5| Step: 4
Training loss: 0.32692331075668335
Validation loss: 1.6365709253536758

Epoch: 5| Step: 5
Training loss: 0.22891025245189667
Validation loss: 1.674842934454641

Epoch: 5| Step: 6
Training loss: 0.2263735979795456
Validation loss: 1.6773568731482311

Epoch: 5| Step: 7
Training loss: 0.09044661372900009
Validation loss: 1.6972073098664642

Epoch: 5| Step: 8
Training loss: 0.17736157774925232
Validation loss: 1.7230740952235397

Epoch: 5| Step: 9
Training loss: 0.2437678873538971
Validation loss: 1.6936162684553413

Epoch: 5| Step: 10
Training loss: 0.28966885805130005
Validation loss: 1.7096163149802917

Epoch: 385| Step: 0
Training loss: 0.21061408519744873
Validation loss: 1.7341173874434603

Epoch: 5| Step: 1
Training loss: 0.14260199666023254
Validation loss: 1.7313128350883402

Epoch: 5| Step: 2
Training loss: 0.2075098305940628
Validation loss: 1.7045754392941792

Epoch: 5| Step: 3
Training loss: 0.3250669538974762
Validation loss: 1.7019500732421875

Epoch: 5| Step: 4
Training loss: 0.22519683837890625
Validation loss: 1.6626816513717815

Epoch: 5| Step: 5
Training loss: 0.12022911012172699
Validation loss: 1.6665155874785555

Epoch: 5| Step: 6
Training loss: 0.16711995005607605
Validation loss: 1.6476370429479947

Epoch: 5| Step: 7
Training loss: 0.23431964218616486
Validation loss: 1.6303312304199382

Epoch: 5| Step: 8
Training loss: 0.24565784633159637
Validation loss: 1.6450839991210608

Epoch: 5| Step: 9
Training loss: 0.16079410910606384
Validation loss: 1.6182722301893337

Epoch: 5| Step: 10
Training loss: 0.16126517951488495
Validation loss: 1.6370774507522583

Epoch: 386| Step: 0
Training loss: 0.194536954164505
Validation loss: 1.6763906786518712

Epoch: 5| Step: 1
Training loss: 0.2537739872932434
Validation loss: 1.6708515959401284

Epoch: 5| Step: 2
Training loss: 0.20305299758911133
Validation loss: 1.6615305139172463

Epoch: 5| Step: 3
Training loss: 0.17515254020690918
Validation loss: 1.6712639742000128

Epoch: 5| Step: 4
Training loss: 0.1711837500333786
Validation loss: 1.6715387227714702

Epoch: 5| Step: 5
Training loss: 0.13648675382137299
Validation loss: 1.6783781372090822

Epoch: 5| Step: 6
Training loss: 0.16196687519550323
Validation loss: 1.6672437357646164

Epoch: 5| Step: 7
Training loss: 0.13598506152629852
Validation loss: 1.672769828509259

Epoch: 5| Step: 8
Training loss: 0.16800197958946228
Validation loss: 1.6605072265030236

Epoch: 5| Step: 9
Training loss: 0.23771576583385468
Validation loss: 1.6527633615719375

Epoch: 5| Step: 10
Training loss: 0.15419930219650269
Validation loss: 1.6052711356070735

Epoch: 387| Step: 0
Training loss: 0.10014374554157257
Validation loss: 1.622207401901163

Epoch: 5| Step: 1
Training loss: 0.13583223521709442
Validation loss: 1.6321344426883164

Epoch: 5| Step: 2
Training loss: 0.20672063529491425
Validation loss: 1.6520492466547156

Epoch: 5| Step: 3
Training loss: 0.13211311399936676
Validation loss: 1.6616199529299172

Epoch: 5| Step: 4
Training loss: 0.1945168673992157
Validation loss: 1.6673587022289154

Epoch: 5| Step: 5
Training loss: 0.16827590763568878
Validation loss: 1.677709392322007

Epoch: 5| Step: 6
Training loss: 0.2102808952331543
Validation loss: 1.7354478092603787

Epoch: 5| Step: 7
Training loss: 0.29274940490722656
Validation loss: 1.7185546275108092

Epoch: 5| Step: 8
Training loss: 0.11246182769536972
Validation loss: 1.7070083323345389

Epoch: 5| Step: 9
Training loss: 0.2268257588148117
Validation loss: 1.7282841846507082

Epoch: 5| Step: 10
Training loss: 0.1853981763124466
Validation loss: 1.7699711579148487

Epoch: 388| Step: 0
Training loss: 0.20311105251312256
Validation loss: 1.6822111747598136

Epoch: 5| Step: 1
Training loss: 0.17105209827423096
Validation loss: 1.6945040879711029

Epoch: 5| Step: 2
Training loss: 0.12060680240392685
Validation loss: 1.6659855035043531

Epoch: 5| Step: 3
Training loss: 0.0935472697019577
Validation loss: 1.6365901295856764

Epoch: 5| Step: 4
Training loss: 0.12321704626083374
Validation loss: 1.5982464692925895

Epoch: 5| Step: 5
Training loss: 0.10136930644512177
Validation loss: 1.6011284871767926

Epoch: 5| Step: 6
Training loss: 0.2210342437028885
Validation loss: 1.6107377813708397

Epoch: 5| Step: 7
Training loss: 0.27510306239128113
Validation loss: 1.5789394737571798

Epoch: 5| Step: 8
Training loss: 0.22274437546730042
Validation loss: 1.610723603156305

Epoch: 5| Step: 9
Training loss: 0.21454782783985138
Validation loss: 1.6273755155583864

Epoch: 5| Step: 10
Training loss: 0.24974088370800018
Validation loss: 1.6195681518123997

Epoch: 389| Step: 0
Training loss: 0.22080501914024353
Validation loss: 1.676311650583821

Epoch: 5| Step: 1
Training loss: 0.10319945961236954
Validation loss: 1.7175826731548514

Epoch: 5| Step: 2
Training loss: 0.13785283267498016
Validation loss: 1.6881404064034904

Epoch: 5| Step: 3
Training loss: 0.17703261971473694
Validation loss: 1.6894970709277737

Epoch: 5| Step: 4
Training loss: 0.1569357067346573
Validation loss: 1.688474832042571

Epoch: 5| Step: 5
Training loss: 0.17815634608268738
Validation loss: 1.6779691980731102

Epoch: 5| Step: 6
Training loss: 0.25669625401496887
Validation loss: 1.6642773958944506

Epoch: 5| Step: 7
Training loss: 0.2545595169067383
Validation loss: 1.6929832479005218

Epoch: 5| Step: 8
Training loss: 0.25168824195861816
Validation loss: 1.6433310816364903

Epoch: 5| Step: 9
Training loss: 0.15807686746120453
Validation loss: 1.650202497359245

Epoch: 5| Step: 10
Training loss: 0.16128571331501007
Validation loss: 1.6704550712339339

Epoch: 390| Step: 0
Training loss: 0.19007226824760437
Validation loss: 1.7040463673171176

Epoch: 5| Step: 1
Training loss: 0.15723362565040588
Validation loss: 1.69197129946883

Epoch: 5| Step: 2
Training loss: 0.2868741452693939
Validation loss: 1.7305028579568351

Epoch: 5| Step: 3
Training loss: 0.19774679839611053
Validation loss: 1.7597578526825033

Epoch: 5| Step: 4
Training loss: 0.22723102569580078
Validation loss: 1.7239888803933257

Epoch: 5| Step: 5
Training loss: 0.17920485138893127
Validation loss: 1.7319110003850793

Epoch: 5| Step: 6
Training loss: 0.16612029075622559
Validation loss: 1.7468726583706435

Epoch: 5| Step: 7
Training loss: 0.2749536335468292
Validation loss: 1.7292242370625979

Epoch: 5| Step: 8
Training loss: 0.2192991077899933
Validation loss: 1.744468545400968

Epoch: 5| Step: 9
Training loss: 0.20613794028759003
Validation loss: 1.7591257749065277

Epoch: 5| Step: 10
Training loss: 0.14837388694286346
Validation loss: 1.7513443346946471

Epoch: 391| Step: 0
Training loss: 0.24524526298046112
Validation loss: 1.7226977245782011

Epoch: 5| Step: 1
Training loss: 0.10984386503696442
Validation loss: 1.6892114300881662

Epoch: 5| Step: 2
Training loss: 0.2815297842025757
Validation loss: 1.6575198481159825

Epoch: 5| Step: 3
Training loss: 0.14949914813041687
Validation loss: 1.684131472341476

Epoch: 5| Step: 4
Training loss: 0.21528327465057373
Validation loss: 1.6631690943112938

Epoch: 5| Step: 5
Training loss: 0.09616744518280029
Validation loss: 1.7020254250495666

Epoch: 5| Step: 6
Training loss: 0.1867186427116394
Validation loss: 1.6932416192946895

Epoch: 5| Step: 7
Training loss: 0.12197639793157578
Validation loss: 1.6550444095365462

Epoch: 5| Step: 8
Training loss: 0.14092114567756653
Validation loss: 1.62760155816232

Epoch: 5| Step: 9
Training loss: 0.20930282771587372
Validation loss: 1.6509333925862466

Epoch: 5| Step: 10
Training loss: 0.3195030689239502
Validation loss: 1.613781318869642

Epoch: 392| Step: 0
Training loss: 0.15245647728443146
Validation loss: 1.617176140508344

Epoch: 5| Step: 1
Training loss: 0.14964817464351654
Validation loss: 1.6472754042635682

Epoch: 5| Step: 2
Training loss: 0.24125516414642334
Validation loss: 1.649534983019675

Epoch: 5| Step: 3
Training loss: 0.33138442039489746
Validation loss: 1.643936481527103

Epoch: 5| Step: 4
Training loss: 0.1842721402645111
Validation loss: 1.6808604655727264

Epoch: 5| Step: 5
Training loss: 0.25964871048927307
Validation loss: 1.7000794602978615

Epoch: 5| Step: 6
Training loss: 0.1461135596036911
Validation loss: 1.7094674187321817

Epoch: 5| Step: 7
Training loss: 0.2226579636335373
Validation loss: 1.7278363140680457

Epoch: 5| Step: 8
Training loss: 0.11268168687820435
Validation loss: 1.7319906462905228

Epoch: 5| Step: 9
Training loss: 0.12914513051509857
Validation loss: 1.7229573367744364

Epoch: 5| Step: 10
Training loss: 0.1488504558801651
Validation loss: 1.7008778587464364

Epoch: 393| Step: 0
Training loss: 0.18618126213550568
Validation loss: 1.708392341931661

Epoch: 5| Step: 1
Training loss: 0.17225900292396545
Validation loss: 1.6718508787052606

Epoch: 5| Step: 2
Training loss: 0.22096581757068634
Validation loss: 1.6365571611671037

Epoch: 5| Step: 3
Training loss: 0.19815784692764282
Validation loss: 1.6372038587447135

Epoch: 5| Step: 4
Training loss: 0.1565178483724594
Validation loss: 1.603846993497623

Epoch: 5| Step: 5
Training loss: 0.22867055237293243
Validation loss: 1.6102463711974442

Epoch: 5| Step: 6
Training loss: 0.21983055770397186
Validation loss: 1.5992358602503294

Epoch: 5| Step: 7
Training loss: 0.1718602180480957
Validation loss: 1.6443849866108229

Epoch: 5| Step: 8
Training loss: 0.22006741166114807
Validation loss: 1.6130931428683701

Epoch: 5| Step: 9
Training loss: 0.14299723505973816
Validation loss: 1.6540757789406726

Epoch: 5| Step: 10
Training loss: 0.23356860876083374
Validation loss: 1.648490471224631

Epoch: 394| Step: 0
Training loss: 0.1855771392583847
Validation loss: 1.6491138935089111

Epoch: 5| Step: 1
Training loss: 0.13930366933345795
Validation loss: 1.6480342277916529

Epoch: 5| Step: 2
Training loss: 0.22775287926197052
Validation loss: 1.6883001276241836

Epoch: 5| Step: 3
Training loss: 0.20244979858398438
Validation loss: 1.670185806930706

Epoch: 5| Step: 4
Training loss: 0.28634312748908997
Validation loss: 1.6919181872439641

Epoch: 5| Step: 5
Training loss: 0.16573090851306915
Validation loss: 1.6762252969126548

Epoch: 5| Step: 6
Training loss: 0.1715913563966751
Validation loss: 1.6227627108173985

Epoch: 5| Step: 7
Training loss: 0.13203644752502441
Validation loss: 1.6191790924277356

Epoch: 5| Step: 8
Training loss: 0.16632838547229767
Validation loss: 1.6094526167838805

Epoch: 5| Step: 9
Training loss: 0.15347373485565186
Validation loss: 1.599783033453008

Epoch: 5| Step: 10
Training loss: 0.18693256378173828
Validation loss: 1.5778170516414027

Epoch: 395| Step: 0
Training loss: 0.2737325429916382
Validation loss: 1.626379273271048

Epoch: 5| Step: 1
Training loss: 0.17812106013298035
Validation loss: 1.6085256863665838

Epoch: 5| Step: 2
Training loss: 0.14572516083717346
Validation loss: 1.6476854585832166

Epoch: 5| Step: 3
Training loss: 0.1360897570848465
Validation loss: 1.6697233774328744

Epoch: 5| Step: 4
Training loss: 0.1291033774614334
Validation loss: 1.711920383796897

Epoch: 5| Step: 5
Training loss: 0.22300858795642853
Validation loss: 1.726774270816516

Epoch: 5| Step: 6
Training loss: 0.18092377483844757
Validation loss: 1.719683434373589

Epoch: 5| Step: 7
Training loss: 0.23876813054084778
Validation loss: 1.741694728533427

Epoch: 5| Step: 8
Training loss: 0.1302015781402588
Validation loss: 1.7497623364130657

Epoch: 5| Step: 9
Training loss: 0.18126270174980164
Validation loss: 1.6976160516021073

Epoch: 5| Step: 10
Training loss: 0.13767538964748383
Validation loss: 1.6902902715949601

Epoch: 396| Step: 0
Training loss: 0.17207244038581848
Validation loss: 1.6490274443421313

Epoch: 5| Step: 1
Training loss: 0.1419535130262375
Validation loss: 1.679160015557402

Epoch: 5| Step: 2
Training loss: 0.13775458931922913
Validation loss: 1.6700234131146503

Epoch: 5| Step: 3
Training loss: 0.1596178561449051
Validation loss: 1.6461636186927877

Epoch: 5| Step: 4
Training loss: 0.13641344010829926
Validation loss: 1.6493397848580473

Epoch: 5| Step: 5
Training loss: 0.20813791453838348
Validation loss: 1.62187276476173

Epoch: 5| Step: 6
Training loss: 0.16389057040214539
Validation loss: 1.6255868391324115

Epoch: 5| Step: 7
Training loss: 0.1713133156299591
Validation loss: 1.6252108107330978

Epoch: 5| Step: 8
Training loss: 0.23945972323417664
Validation loss: 1.6213650229156658

Epoch: 5| Step: 9
Training loss: 0.18401607871055603
Validation loss: 1.653936005407764

Epoch: 5| Step: 10
Training loss: 0.1341317743062973
Validation loss: 1.6838558130366827

Epoch: 397| Step: 0
Training loss: 0.16799671947956085
Validation loss: 1.6458671874897455

Epoch: 5| Step: 1
Training loss: 0.19893784821033478
Validation loss: 1.6347782791301768

Epoch: 5| Step: 2
Training loss: 0.16561581194400787
Validation loss: 1.6231473363855833

Epoch: 5| Step: 3
Training loss: 0.2204602211713791
Validation loss: 1.620952404955382

Epoch: 5| Step: 4
Training loss: 0.145646870136261
Validation loss: 1.6570078916447137

Epoch: 5| Step: 5
Training loss: 0.22346743941307068
Validation loss: 1.6469700618456768

Epoch: 5| Step: 6
Training loss: 0.3126915991306305
Validation loss: 1.6587109540098457

Epoch: 5| Step: 7
Training loss: 0.19044506549835205
Validation loss: 1.671738605345449

Epoch: 5| Step: 8
Training loss: 0.10527937114238739
Validation loss: 1.6943689828277917

Epoch: 5| Step: 9
Training loss: 0.15911488234996796
Validation loss: 1.729591727256775

Epoch: 5| Step: 10
Training loss: 0.12151996046304703
Validation loss: 1.7169540518073625

Epoch: 398| Step: 0
Training loss: 0.184778094291687
Validation loss: 1.6949795522997457

Epoch: 5| Step: 1
Training loss: 0.1375555545091629
Validation loss: 1.6856855564219977

Epoch: 5| Step: 2
Training loss: 0.17252324521541595
Validation loss: 1.6788589210920437

Epoch: 5| Step: 3
Training loss: 0.24790331721305847
Validation loss: 1.6937856904921993

Epoch: 5| Step: 4
Training loss: 0.1988043338060379
Validation loss: 1.6379195310736214

Epoch: 5| Step: 5
Training loss: 0.20767207443714142
Validation loss: 1.641933237352679

Epoch: 5| Step: 6
Training loss: 0.11610668897628784
Validation loss: 1.6650516179300123

Epoch: 5| Step: 7
Training loss: 0.24980731308460236
Validation loss: 1.6290508880410144

Epoch: 5| Step: 8
Training loss: 0.09643112123012543
Validation loss: 1.6209638964745305

Epoch: 5| Step: 9
Training loss: 0.2258802354335785
Validation loss: 1.6127726403615807

Epoch: 5| Step: 10
Training loss: 0.06968685239553452
Validation loss: 1.634494097002091

Epoch: 399| Step: 0
Training loss: 0.15296080708503723
Validation loss: 1.6204226222089542

Epoch: 5| Step: 1
Training loss: 0.18660029768943787
Validation loss: 1.5988333866160402

Epoch: 5| Step: 2
Training loss: 0.09751339256763458
Validation loss: 1.5683890645221998

Epoch: 5| Step: 3
Training loss: 0.20366592705249786
Validation loss: 1.57393559973727

Epoch: 5| Step: 4
Training loss: 0.18046119809150696
Validation loss: 1.593241044270095

Epoch: 5| Step: 5
Training loss: 0.21281258761882782
Validation loss: 1.615634838740031

Epoch: 5| Step: 6
Training loss: 0.12487120926380157
Validation loss: 1.6050312224254812

Epoch: 5| Step: 7
Training loss: 0.127518430352211
Validation loss: 1.5883350744042346

Epoch: 5| Step: 8
Training loss: 0.20390567183494568
Validation loss: 1.5761135726846673

Epoch: 5| Step: 9
Training loss: 0.14698603749275208
Validation loss: 1.5443679748042938

Epoch: 5| Step: 10
Training loss: 0.16613832116127014
Validation loss: 1.5512063195628505

Epoch: 400| Step: 0
Training loss: 0.10853902995586395
Validation loss: 1.5698474645614624

Epoch: 5| Step: 1
Training loss: 0.11204592138528824
Validation loss: 1.5401021639506023

Epoch: 5| Step: 2
Training loss: 0.22949621081352234
Validation loss: 1.5621471020483202

Epoch: 5| Step: 3
Training loss: 0.22189465165138245
Validation loss: 1.5442223484798143

Epoch: 5| Step: 4
Training loss: 0.17150327563285828
Validation loss: 1.5774766655378445

Epoch: 5| Step: 5
Training loss: 0.1719318926334381
Validation loss: 1.5797460284284366

Epoch: 5| Step: 6
Training loss: 0.1528158038854599
Validation loss: 1.5955116979537471

Epoch: 5| Step: 7
Training loss: 0.1311454474925995
Validation loss: 1.5974150216707619

Epoch: 5| Step: 8
Training loss: 0.17955316603183746
Validation loss: 1.608277145252433

Epoch: 5| Step: 9
Training loss: 0.09539592266082764
Validation loss: 1.61567977423309

Epoch: 5| Step: 10
Training loss: 0.17784970998764038
Validation loss: 1.5940052437525924

Epoch: 401| Step: 0
Training loss: 0.22083131968975067
Validation loss: 1.5903879442522604

Epoch: 5| Step: 1
Training loss: 0.1046873927116394
Validation loss: 1.5983009748561408

Epoch: 5| Step: 2
Training loss: 0.12422838062047958
Validation loss: 1.606895233995171

Epoch: 5| Step: 3
Training loss: 0.14977818727493286
Validation loss: 1.6263712234394525

Epoch: 5| Step: 4
Training loss: 0.2435164451599121
Validation loss: 1.6540381485416042

Epoch: 5| Step: 5
Training loss: 0.17885121703147888
Validation loss: 1.6597289654516405

Epoch: 5| Step: 6
Training loss: 0.1233283132314682
Validation loss: 1.6609170359949912

Epoch: 5| Step: 7
Training loss: 0.17688165605068207
Validation loss: 1.6808984177086943

Epoch: 5| Step: 8
Training loss: 0.14201834797859192
Validation loss: 1.6698078981009863

Epoch: 5| Step: 9
Training loss: 0.19429798424243927
Validation loss: 1.65736618093265

Epoch: 5| Step: 10
Training loss: 0.3036819398403168
Validation loss: 1.6283395764648274

Epoch: 402| Step: 0
Training loss: 0.206753209233284
Validation loss: 1.5987700621287029

Epoch: 5| Step: 1
Training loss: 0.11435098946094513
Validation loss: 1.6248260595465218

Epoch: 5| Step: 2
Training loss: 0.22003164887428284
Validation loss: 1.595912068120895

Epoch: 5| Step: 3
Training loss: 0.16855505108833313
Validation loss: 1.619084435124551

Epoch: 5| Step: 4
Training loss: 0.15357831120491028
Validation loss: 1.5948264034845496

Epoch: 5| Step: 5
Training loss: 0.1407671570777893
Validation loss: 1.6269544016930364

Epoch: 5| Step: 6
Training loss: 0.1467897593975067
Validation loss: 1.6191899597003896

Epoch: 5| Step: 7
Training loss: 0.11171413958072662
Validation loss: 1.641961141299176

Epoch: 5| Step: 8
Training loss: 0.3798429071903229
Validation loss: 1.6606971192103561

Epoch: 5| Step: 9
Training loss: 0.12418390810489655
Validation loss: 1.6809934775034587

Epoch: 5| Step: 10
Training loss: 0.1452694684267044
Validation loss: 1.6833839660049768

Epoch: 403| Step: 0
Training loss: 0.13807885348796844
Validation loss: 1.6443811962681432

Epoch: 5| Step: 1
Training loss: 0.16083446145057678
Validation loss: 1.6471652394981795

Epoch: 5| Step: 2
Training loss: 0.18713033199310303
Validation loss: 1.640503228351634

Epoch: 5| Step: 3
Training loss: 0.14197561144828796
Validation loss: 1.6095736962492748

Epoch: 5| Step: 4
Training loss: 0.13795270025730133
Validation loss: 1.6155665407898605

Epoch: 5| Step: 5
Training loss: 0.15564760565757751
Validation loss: 1.652050454129455

Epoch: 5| Step: 6
Training loss: 0.19244632124900818
Validation loss: 1.631920950387114

Epoch: 5| Step: 7
Training loss: 0.17088469862937927
Validation loss: 1.6393368987626926

Epoch: 5| Step: 8
Training loss: 0.12673144042491913
Validation loss: 1.6296912777808406

Epoch: 5| Step: 9
Training loss: 0.14529730379581451
Validation loss: 1.6317640683984245

Epoch: 5| Step: 10
Training loss: 0.18360987305641174
Validation loss: 1.6372339251220867

Epoch: 404| Step: 0
Training loss: 0.09227874875068665
Validation loss: 1.6444796375049058

Epoch: 5| Step: 1
Training loss: 0.12305428087711334
Validation loss: 1.6635646473976873

Epoch: 5| Step: 2
Training loss: 0.22643332183361053
Validation loss: 1.7179986892207977

Epoch: 5| Step: 3
Training loss: 0.21116945147514343
Validation loss: 1.663524088039193

Epoch: 5| Step: 4
Training loss: 0.16124464571475983
Validation loss: 1.6494392823147517

Epoch: 5| Step: 5
Training loss: 0.29291287064552307
Validation loss: 1.6527377841293172

Epoch: 5| Step: 6
Training loss: 0.21049824357032776
Validation loss: 1.664978983581707

Epoch: 5| Step: 7
Training loss: 0.1327439695596695
Validation loss: 1.6828265510579592

Epoch: 5| Step: 8
Training loss: 0.15567903220653534
Validation loss: 1.6492123450002363

Epoch: 5| Step: 9
Training loss: 0.12610206007957458
Validation loss: 1.677065057139243

Epoch: 5| Step: 10
Training loss: 0.19089215993881226
Validation loss: 1.664715338778752

Epoch: 405| Step: 0
Training loss: 0.19395606219768524
Validation loss: 1.635252893611949

Epoch: 5| Step: 1
Training loss: 0.15492211282253265
Validation loss: 1.6255317413678734

Epoch: 5| Step: 2
Training loss: 0.15467746555805206
Validation loss: 1.6550429149340558

Epoch: 5| Step: 3
Training loss: 0.16090145707130432
Validation loss: 1.6753400192465833

Epoch: 5| Step: 4
Training loss: 0.2296399176120758
Validation loss: 1.674982896415136

Epoch: 5| Step: 5
Training loss: 0.1570608913898468
Validation loss: 1.6964229396594468

Epoch: 5| Step: 6
Training loss: 0.187054842710495
Validation loss: 1.6880007930981216

Epoch: 5| Step: 7
Training loss: 0.08374085277318954
Validation loss: 1.692390877072529

Epoch: 5| Step: 8
Training loss: 0.09732751548290253
Validation loss: 1.6625731516909856

Epoch: 5| Step: 9
Training loss: 0.18819394707679749
Validation loss: 1.661891439268666

Epoch: 5| Step: 10
Training loss: 0.18868805468082428
Validation loss: 1.687322876786673

Epoch: 406| Step: 0
Training loss: 0.13787779211997986
Validation loss: 1.6346390452436221

Epoch: 5| Step: 1
Training loss: 0.09805162250995636
Validation loss: 1.6473839385535127

Epoch: 5| Step: 2
Training loss: 0.13878172636032104
Validation loss: 1.6690989822469733

Epoch: 5| Step: 3
Training loss: 0.19504114985466003
Validation loss: 1.6530269345929545

Epoch: 5| Step: 4
Training loss: 0.1632218360900879
Validation loss: 1.7077745570931384

Epoch: 5| Step: 5
Training loss: 0.19797058403491974
Validation loss: 1.6669928143101354

Epoch: 5| Step: 6
Training loss: 0.12281365692615509
Validation loss: 1.6638135333215036

Epoch: 5| Step: 7
Training loss: 0.1980387419462204
Validation loss: 1.6736186345418294

Epoch: 5| Step: 8
Training loss: 0.08139758557081223
Validation loss: 1.6990722264012983

Epoch: 5| Step: 9
Training loss: 0.14007532596588135
Validation loss: 1.689531651876306

Epoch: 5| Step: 10
Training loss: 0.19268028438091278
Validation loss: 1.7146704004656883

Epoch: 407| Step: 0
Training loss: 0.1634732484817505
Validation loss: 1.6771334678896013

Epoch: 5| Step: 1
Training loss: 0.16121815145015717
Validation loss: 1.6774888859000257

Epoch: 5| Step: 2
Training loss: 0.15054664015769958
Validation loss: 1.6635218672854926

Epoch: 5| Step: 3
Training loss: 0.11668574810028076
Validation loss: 1.6357028561253701

Epoch: 5| Step: 4
Training loss: 0.17213356494903564
Validation loss: 1.6483313204139791

Epoch: 5| Step: 5
Training loss: 0.18225574493408203
Validation loss: 1.6477665221819313

Epoch: 5| Step: 6
Training loss: 0.16056540608406067
Validation loss: 1.6253012559747184

Epoch: 5| Step: 7
Training loss: 0.20233917236328125
Validation loss: 1.6207438053623322

Epoch: 5| Step: 8
Training loss: 0.1437569409608841
Validation loss: 1.5644808405189103

Epoch: 5| Step: 9
Training loss: 0.13086988031864166
Validation loss: 1.5810427947710919

Epoch: 5| Step: 10
Training loss: 0.13555029034614563
Validation loss: 1.5947695021988244

Epoch: 408| Step: 0
Training loss: 0.19009093940258026
Validation loss: 1.5650613743771788

Epoch: 5| Step: 1
Training loss: 0.06119673326611519
Validation loss: 1.581131056431801

Epoch: 5| Step: 2
Training loss: 0.143878772854805
Validation loss: 1.587235531499309

Epoch: 5| Step: 3
Training loss: 0.13014575839042664
Validation loss: 1.6008145040081394

Epoch: 5| Step: 4
Training loss: 0.11653602123260498
Validation loss: 1.6173195967110254

Epoch: 5| Step: 5
Training loss: 0.13599663972854614
Validation loss: 1.588856190763494

Epoch: 5| Step: 6
Training loss: 0.22657255828380585
Validation loss: 1.6155550787525792

Epoch: 5| Step: 7
Training loss: 0.10453279316425323
Validation loss: 1.6160086495901949

Epoch: 5| Step: 8
Training loss: 0.06947468221187592
Validation loss: 1.6282904917193997

Epoch: 5| Step: 9
Training loss: 0.11235131323337555
Validation loss: 1.6266099663190945

Epoch: 5| Step: 10
Training loss: 0.25551801919937134
Validation loss: 1.6147412728237849

Epoch: 409| Step: 0
Training loss: 0.1905020773410797
Validation loss: 1.6061241806194346

Epoch: 5| Step: 1
Training loss: 0.20513808727264404
Validation loss: 1.5883588765257148

Epoch: 5| Step: 2
Training loss: 0.18964165449142456
Validation loss: 1.5874508427035423

Epoch: 5| Step: 3
Training loss: 0.13508747518062592
Validation loss: 1.566902381117626

Epoch: 5| Step: 4
Training loss: 0.13424555957317352
Validation loss: 1.5718292164546188

Epoch: 5| Step: 5
Training loss: 0.16039973497390747
Validation loss: 1.5849664262546006

Epoch: 5| Step: 6
Training loss: 0.16543914377689362
Validation loss: 1.562367429015457

Epoch: 5| Step: 7
Training loss: 0.1811036765575409
Validation loss: 1.573874951690756

Epoch: 5| Step: 8
Training loss: 0.20469841361045837
Validation loss: 1.5929964460352415

Epoch: 5| Step: 9
Training loss: 0.1831604689359665
Validation loss: 1.5750216296924058

Epoch: 5| Step: 10
Training loss: 0.23666130006313324
Validation loss: 1.5905917575282436

Epoch: 410| Step: 0
Training loss: 0.24865278601646423
Validation loss: 1.6081900276163572

Epoch: 5| Step: 1
Training loss: 0.17852629721164703
Validation loss: 1.6174785680668329

Epoch: 5| Step: 2
Training loss: 0.17250409722328186
Validation loss: 1.6565855472318587

Epoch: 5| Step: 3
Training loss: 0.15547320246696472
Validation loss: 1.619270593889298

Epoch: 5| Step: 4
Training loss: 0.12220045179128647
Validation loss: 1.6571773213724936

Epoch: 5| Step: 5
Training loss: 0.13324232399463654
Validation loss: 1.6498328280705277

Epoch: 5| Step: 6
Training loss: 0.1421574354171753
Validation loss: 1.626939522322788

Epoch: 5| Step: 7
Training loss: 0.15714576840400696
Validation loss: 1.59037991492979

Epoch: 5| Step: 8
Training loss: 0.19274631142616272
Validation loss: 1.5826903568801058

Epoch: 5| Step: 9
Training loss: 0.1850457489490509
Validation loss: 1.5734351270942277

Epoch: 5| Step: 10
Training loss: 0.2807777523994446
Validation loss: 1.5719847550956152

Epoch: 411| Step: 0
Training loss: 0.2444925755262375
Validation loss: 1.5582069145735873

Epoch: 5| Step: 1
Training loss: 0.20255891978740692
Validation loss: 1.5591270667250439

Epoch: 5| Step: 2
Training loss: 0.208017498254776
Validation loss: 1.5479992705006753

Epoch: 5| Step: 3
Training loss: 0.15757633745670319
Validation loss: 1.5587444407965547

Epoch: 5| Step: 4
Training loss: 0.1056278795003891
Validation loss: 1.5830917717308126

Epoch: 5| Step: 5
Training loss: 0.1133190169930458
Validation loss: 1.5917533879639

Epoch: 5| Step: 6
Training loss: 0.19970472157001495
Validation loss: 1.6770966411918722

Epoch: 5| Step: 7
Training loss: 0.14534611999988556
Validation loss: 1.6781297447860881

Epoch: 5| Step: 8
Training loss: 0.27487459778785706
Validation loss: 1.7142322941492962

Epoch: 5| Step: 9
Training loss: 0.1415349543094635
Validation loss: 1.6893282295555196

Epoch: 5| Step: 10
Training loss: 0.20714958012104034
Validation loss: 1.6169604562943982

Epoch: 412| Step: 0
Training loss: 0.08707135170698166
Validation loss: 1.6291014609798309

Epoch: 5| Step: 1
Training loss: 0.17599812150001526
Validation loss: 1.5996220329756379

Epoch: 5| Step: 2
Training loss: 0.13967038691043854
Validation loss: 1.6221165400679394

Epoch: 5| Step: 3
Training loss: 0.2139725685119629
Validation loss: 1.6240975446598505

Epoch: 5| Step: 4
Training loss: 0.20820260047912598
Validation loss: 1.6266386483305244

Epoch: 5| Step: 5
Training loss: 0.13415077328681946
Validation loss: 1.60369142922022

Epoch: 5| Step: 6
Training loss: 0.18340304493904114
Validation loss: 1.619940524460167

Epoch: 5| Step: 7
Training loss: 0.17717215418815613
Validation loss: 1.625379325241171

Epoch: 5| Step: 8
Training loss: 0.18995317816734314
Validation loss: 1.6494264243751444

Epoch: 5| Step: 9
Training loss: 0.13056299090385437
Validation loss: 1.6491312057741228

Epoch: 5| Step: 10
Training loss: 0.1333925575017929
Validation loss: 1.6500423806969837

Epoch: 413| Step: 0
Training loss: 0.14257171750068665
Validation loss: 1.6430825751314881

Epoch: 5| Step: 1
Training loss: 0.14657071232795715
Validation loss: 1.670333538004147

Epoch: 5| Step: 2
Training loss: 0.21031208336353302
Validation loss: 1.6502219890394518

Epoch: 5| Step: 3
Training loss: 0.11080155521631241
Validation loss: 1.6532648750530776

Epoch: 5| Step: 4
Training loss: 0.1335107386112213
Validation loss: 1.6499292517221102

Epoch: 5| Step: 5
Training loss: 0.1020570769906044
Validation loss: 1.6445746831996466

Epoch: 5| Step: 6
Training loss: 0.15151065587997437
Validation loss: 1.6567697422478789

Epoch: 5| Step: 7
Training loss: 0.1654892861843109
Validation loss: 1.6465762353712512

Epoch: 5| Step: 8
Training loss: 0.1665354073047638
Validation loss: 1.6519651438600274

Epoch: 5| Step: 9
Training loss: 0.21633219718933105
Validation loss: 1.6590010504568777

Epoch: 5| Step: 10
Training loss: 0.10744458436965942
Validation loss: 1.6650500900001937

Epoch: 414| Step: 0
Training loss: 0.15146200358867645
Validation loss: 1.7207825978597004

Epoch: 5| Step: 1
Training loss: 0.2525842487812042
Validation loss: 1.7043617681790424

Epoch: 5| Step: 2
Training loss: 0.12312191724777222
Validation loss: 1.670320160927311

Epoch: 5| Step: 3
Training loss: 0.10094626247882843
Validation loss: 1.640815560535718

Epoch: 5| Step: 4
Training loss: 0.18889100849628448
Validation loss: 1.6099209785461426

Epoch: 5| Step: 5
Training loss: 0.2222972810268402
Validation loss: 1.5957158675757788

Epoch: 5| Step: 6
Training loss: 0.19129987061023712
Validation loss: 1.5961240722287087

Epoch: 5| Step: 7
Training loss: 0.15009914338588715
Validation loss: 1.58052142717505

Epoch: 5| Step: 8
Training loss: 0.12236783653497696
Validation loss: 1.5866645074659778

Epoch: 5| Step: 9
Training loss: 0.12702614068984985
Validation loss: 1.594366478663619

Epoch: 5| Step: 10
Training loss: 0.15516680479049683
Validation loss: 1.5696149295376194

Epoch: 415| Step: 0
Training loss: 0.18985235691070557
Validation loss: 1.601828686652645

Epoch: 5| Step: 1
Training loss: 0.11603248119354248
Validation loss: 1.6348748924911662

Epoch: 5| Step: 2
Training loss: 0.15164992213249207
Validation loss: 1.632943699436803

Epoch: 5| Step: 3
Training loss: 0.18289214372634888
Validation loss: 1.6398485091424757

Epoch: 5| Step: 4
Training loss: 0.11233606189489365
Validation loss: 1.6345223983128865

Epoch: 5| Step: 5
Training loss: 0.1792926788330078
Validation loss: 1.6295873247167116

Epoch: 5| Step: 6
Training loss: 0.12774674594402313
Validation loss: 1.6001282648373676

Epoch: 5| Step: 7
Training loss: 0.14181537926197052
Validation loss: 1.6203221595415505

Epoch: 5| Step: 8
Training loss: 0.12291363626718521
Validation loss: 1.5799442055404826

Epoch: 5| Step: 9
Training loss: 0.1715632975101471
Validation loss: 1.5786168844469133

Epoch: 5| Step: 10
Training loss: 0.18443256616592407
Validation loss: 1.5416678728595856

Epoch: 416| Step: 0
Training loss: 0.1527116298675537
Validation loss: 1.564479374757377

Epoch: 5| Step: 1
Training loss: 0.13758054375648499
Validation loss: 1.5100773431921517

Epoch: 5| Step: 2
Training loss: 0.13453558087348938
Validation loss: 1.5414876104683004

Epoch: 5| Step: 3
Training loss: 0.2248508483171463
Validation loss: 1.5124320490385896

Epoch: 5| Step: 4
Training loss: 0.13068756461143494
Validation loss: 1.521375319009186

Epoch: 5| Step: 5
Training loss: 0.13486841320991516
Validation loss: 1.5592855804709977

Epoch: 5| Step: 6
Training loss: 0.15275755524635315
Validation loss: 1.535482096415694

Epoch: 5| Step: 7
Training loss: 0.1708376258611679
Validation loss: 1.5909630906197332

Epoch: 5| Step: 8
Training loss: 0.16591575741767883
Validation loss: 1.5858379025613107

Epoch: 5| Step: 9
Training loss: 0.13009098172187805
Validation loss: 1.6011684171615108

Epoch: 5| Step: 10
Training loss: 0.1311282515525818
Validation loss: 1.620141577977006

Epoch: 417| Step: 0
Training loss: 0.13637244701385498
Validation loss: 1.5779462629748928

Epoch: 5| Step: 1
Training loss: 0.11847162246704102
Validation loss: 1.5819026962403329

Epoch: 5| Step: 2
Training loss: 0.1467202752828598
Validation loss: 1.5974773771019393

Epoch: 5| Step: 3
Training loss: 0.15633539855480194
Validation loss: 1.5958065614905408

Epoch: 5| Step: 4
Training loss: 0.1730058491230011
Validation loss: 1.5943991253452916

Epoch: 5| Step: 5
Training loss: 0.0691596269607544
Validation loss: 1.602998472029163

Epoch: 5| Step: 6
Training loss: 0.1259710043668747
Validation loss: 1.6026841901963758

Epoch: 5| Step: 7
Training loss: 0.053233515471220016
Validation loss: 1.60819459730579

Epoch: 5| Step: 8
Training loss: 0.1292804777622223
Validation loss: 1.6027408312725764

Epoch: 5| Step: 9
Training loss: 0.17176012694835663
Validation loss: 1.6222021220832743

Epoch: 5| Step: 10
Training loss: 0.17920692265033722
Validation loss: 1.5943755206241403

Epoch: 418| Step: 0
Training loss: 0.08461999148130417
Validation loss: 1.5915778093440558

Epoch: 5| Step: 1
Training loss: 0.10307067632675171
Validation loss: 1.561372140402435

Epoch: 5| Step: 2
Training loss: 0.13744693994522095
Validation loss: 1.567441160960864

Epoch: 5| Step: 3
Training loss: 0.11158023029565811
Validation loss: 1.5734674571662821

Epoch: 5| Step: 4
Training loss: 0.1505786031484604
Validation loss: 1.5632493918941868

Epoch: 5| Step: 5
Training loss: 0.14709973335266113
Validation loss: 1.554161294814079

Epoch: 5| Step: 6
Training loss: 0.1786489486694336
Validation loss: 1.5529514986981627

Epoch: 5| Step: 7
Training loss: 0.0626872330904007
Validation loss: 1.5399127096258185

Epoch: 5| Step: 8
Training loss: 0.19504614174365997
Validation loss: 1.550053006859236

Epoch: 5| Step: 9
Training loss: 0.13611023128032684
Validation loss: 1.5224861534692908

Epoch: 5| Step: 10
Training loss: 0.13528595864772797
Validation loss: 1.5383875088025165

Epoch: 419| Step: 0
Training loss: 0.16219820082187653
Validation loss: 1.5453929478122341

Epoch: 5| Step: 1
Training loss: 0.14590631425380707
Validation loss: 1.5568967326994865

Epoch: 5| Step: 2
Training loss: 0.15010417997837067
Validation loss: 1.587475638876679

Epoch: 5| Step: 3
Training loss: 0.21027907729148865
Validation loss: 1.5839549867055749

Epoch: 5| Step: 4
Training loss: 0.07782043516635895
Validation loss: 1.6276216801776682

Epoch: 5| Step: 5
Training loss: 0.10364614427089691
Validation loss: 1.6298877321263796

Epoch: 5| Step: 6
Training loss: 0.15561433136463165
Validation loss: 1.651935822220259

Epoch: 5| Step: 7
Training loss: 0.12372227758169174
Validation loss: 1.6309322746851111

Epoch: 5| Step: 8
Training loss: 0.15899482369422913
Validation loss: 1.630103748972698

Epoch: 5| Step: 9
Training loss: 0.13968463242053986
Validation loss: 1.6216590468601515

Epoch: 5| Step: 10
Training loss: 0.080999456346035
Validation loss: 1.5898620338850125

Epoch: 420| Step: 0
Training loss: 0.12404068559408188
Validation loss: 1.5994752799310992

Epoch: 5| Step: 1
Training loss: 0.20731130242347717
Validation loss: 1.5777551486927976

Epoch: 5| Step: 2
Training loss: 0.19159606099128723
Validation loss: 1.5758252746315413

Epoch: 5| Step: 3
Training loss: 0.1902943253517151
Validation loss: 1.5786669972122356

Epoch: 5| Step: 4
Training loss: 0.1764417439699173
Validation loss: 1.5558101720707391

Epoch: 5| Step: 5
Training loss: 0.09801006317138672
Validation loss: 1.5703141125299598

Epoch: 5| Step: 6
Training loss: 0.10305621474981308
Validation loss: 1.5860324559673187

Epoch: 5| Step: 7
Training loss: 0.19203166663646698
Validation loss: 1.6116715554268128

Epoch: 5| Step: 8
Training loss: 0.09049680083990097
Validation loss: 1.5853593272547568

Epoch: 5| Step: 9
Training loss: 0.13322952389717102
Validation loss: 1.572059960775478

Epoch: 5| Step: 10
Training loss: 0.13486921787261963
Validation loss: 1.576061607688986

Epoch: 421| Step: 0
Training loss: 0.13002029061317444
Validation loss: 1.5922493896176737

Epoch: 5| Step: 1
Training loss: 0.16855227947235107
Validation loss: 1.559331560647616

Epoch: 5| Step: 2
Training loss: 0.10577984154224396
Validation loss: 1.545721677041823

Epoch: 5| Step: 3
Training loss: 0.16498076915740967
Validation loss: 1.5546470688235374

Epoch: 5| Step: 4
Training loss: 0.13620682060718536
Validation loss: 1.5642875003558334

Epoch: 5| Step: 5
Training loss: 0.09397905319929123
Validation loss: 1.560854967563383

Epoch: 5| Step: 6
Training loss: 0.18085217475891113
Validation loss: 1.590453831739323

Epoch: 5| Step: 7
Training loss: 0.0781913548707962
Validation loss: 1.6037077903747559

Epoch: 5| Step: 8
Training loss: 0.14942440390586853
Validation loss: 1.6381291830411522

Epoch: 5| Step: 9
Training loss: 0.11358731985092163
Validation loss: 1.6621275153211368

Epoch: 5| Step: 10
Training loss: 0.09534084051847458
Validation loss: 1.6454800815992459

Epoch: 422| Step: 0
Training loss: 0.17063312232494354
Validation loss: 1.6320799525066088

Epoch: 5| Step: 1
Training loss: 0.16401326656341553
Validation loss: 1.5908832293684765

Epoch: 5| Step: 2
Training loss: 0.14341764152050018
Validation loss: 1.5736772526976883

Epoch: 5| Step: 3
Training loss: 0.12776871025562286
Validation loss: 1.5287176767985027

Epoch: 5| Step: 4
Training loss: 0.14371493458747864
Validation loss: 1.5253815356121267

Epoch: 5| Step: 5
Training loss: 0.12053000926971436
Validation loss: 1.5159366733284407

Epoch: 5| Step: 6
Training loss: 0.21038348972797394
Validation loss: 1.513708273569743

Epoch: 5| Step: 7
Training loss: 0.16777369379997253
Validation loss: 1.4751699368158977

Epoch: 5| Step: 8
Training loss: 0.14529013633728027
Validation loss: 1.467208271385521

Epoch: 5| Step: 9
Training loss: 0.15028667449951172
Validation loss: 1.5229138892184022

Epoch: 5| Step: 10
Training loss: 0.09179099649190903
Validation loss: 1.5189843793069162

Epoch: 423| Step: 0
Training loss: 0.13565871119499207
Validation loss: 1.5645499998523342

Epoch: 5| Step: 1
Training loss: 0.15644070506095886
Validation loss: 1.5803449628173665

Epoch: 5| Step: 2
Training loss: 0.07986536622047424
Validation loss: 1.5730322381501556

Epoch: 5| Step: 3
Training loss: 0.12500867247581482
Validation loss: 1.5890068290054158

Epoch: 5| Step: 4
Training loss: 0.13742545247077942
Validation loss: 1.5756743479800481

Epoch: 5| Step: 5
Training loss: 0.07699113339185715
Validation loss: 1.5672102230851368

Epoch: 5| Step: 6
Training loss: 0.18809297680854797
Validation loss: 1.5543388589735954

Epoch: 5| Step: 7
Training loss: 0.12091226875782013
Validation loss: 1.5480053911926925

Epoch: 5| Step: 8
Training loss: 0.21217961609363556
Validation loss: 1.5137552727935135

Epoch: 5| Step: 9
Training loss: 0.20572686195373535
Validation loss: 1.5403973581970378

Epoch: 5| Step: 10
Training loss: 0.1736600250005722
Validation loss: 1.5126377574859127

Epoch: 424| Step: 0
Training loss: 0.0713372677564621
Validation loss: 1.5648707023230932

Epoch: 5| Step: 1
Training loss: 0.09661926329135895
Validation loss: 1.5963420650010467

Epoch: 5| Step: 2
Training loss: 0.2748183608055115
Validation loss: 1.624071123779461

Epoch: 5| Step: 3
Training loss: 0.136905699968338
Validation loss: 1.6412926989216958

Epoch: 5| Step: 4
Training loss: 0.17752417922019958
Validation loss: 1.6382317286665722

Epoch: 5| Step: 5
Training loss: 0.1707443743944168
Validation loss: 1.643850395756383

Epoch: 5| Step: 6
Training loss: 0.17378771305084229
Validation loss: 1.6182622210953825

Epoch: 5| Step: 7
Training loss: 0.278767853975296
Validation loss: 1.6312758871304092

Epoch: 5| Step: 8
Training loss: 0.13623842597007751
Validation loss: 1.5779705573153753

Epoch: 5| Step: 9
Training loss: 0.13310742378234863
Validation loss: 1.5308925451770905

Epoch: 5| Step: 10
Training loss: 0.1786515712738037
Validation loss: 1.5320990957239622

Epoch: 425| Step: 0
Training loss: 0.1298704594373703
Validation loss: 1.4901757983751194

Epoch: 5| Step: 1
Training loss: 0.11953816562891006
Validation loss: 1.4803235659035303

Epoch: 5| Step: 2
Training loss: 0.1467992216348648
Validation loss: 1.4753406932277064

Epoch: 5| Step: 3
Training loss: 0.14005616307258606
Validation loss: 1.4756193686557073

Epoch: 5| Step: 4
Training loss: 0.11336549371480942
Validation loss: 1.4921532151519612

Epoch: 5| Step: 5
Training loss: 0.14669708907604218
Validation loss: 1.5228463795877272

Epoch: 5| Step: 6
Training loss: 0.17930850386619568
Validation loss: 1.5381111874375293

Epoch: 5| Step: 7
Training loss: 0.2385655641555786
Validation loss: 1.547878493544876

Epoch: 5| Step: 8
Training loss: 0.14352533221244812
Validation loss: 1.576234732904742

Epoch: 5| Step: 9
Training loss: 0.11939401924610138
Validation loss: 1.5898139040957215

Epoch: 5| Step: 10
Training loss: 0.19099374115467072
Validation loss: 1.6112245526365054

Epoch: 426| Step: 0
Training loss: 0.16760298609733582
Validation loss: 1.613254770155876

Epoch: 5| Step: 1
Training loss: 0.08643496036529541
Validation loss: 1.6558625800635225

Epoch: 5| Step: 2
Training loss: 0.1061711311340332
Validation loss: 1.6171608291646486

Epoch: 5| Step: 3
Training loss: 0.1272837519645691
Validation loss: 1.5695223680106543

Epoch: 5| Step: 4
Training loss: 0.1671060174703598
Validation loss: 1.558241348112783

Epoch: 5| Step: 5
Training loss: 0.1284300833940506
Validation loss: 1.5694579180850778

Epoch: 5| Step: 6
Training loss: 0.2633707523345947
Validation loss: 1.5835643974683618

Epoch: 5| Step: 7
Training loss: 0.17606326937675476
Validation loss: 1.549079377164123

Epoch: 5| Step: 8
Training loss: 0.16404755413532257
Validation loss: 1.5780798363429245

Epoch: 5| Step: 9
Training loss: 0.15537160634994507
Validation loss: 1.6249082101288663

Epoch: 5| Step: 10
Training loss: 0.13760024309158325
Validation loss: 1.6452270246321155

Epoch: 427| Step: 0
Training loss: 0.14653027057647705
Validation loss: 1.6462542869711434

Epoch: 5| Step: 1
Training loss: 0.09511715918779373
Validation loss: 1.6671144257309616

Epoch: 5| Step: 2
Training loss: 0.11340012401342392
Validation loss: 1.6922047868851693

Epoch: 5| Step: 3
Training loss: 0.13171425461769104
Validation loss: 1.70730576720289

Epoch: 5| Step: 4
Training loss: 0.1286323070526123
Validation loss: 1.71129899127509

Epoch: 5| Step: 5
Training loss: 0.15502794086933136
Validation loss: 1.7092297186133683

Epoch: 5| Step: 6
Training loss: 0.18340998888015747
Validation loss: 1.7129896699741323

Epoch: 5| Step: 7
Training loss: 0.14266200363636017
Validation loss: 1.6519743806572371

Epoch: 5| Step: 8
Training loss: 0.18722684681415558
Validation loss: 1.6109684878779995

Epoch: 5| Step: 9
Training loss: 0.16862690448760986
Validation loss: 1.5630287701083767

Epoch: 5| Step: 10
Training loss: 0.13863001763820648
Validation loss: 1.5595010134481615

Epoch: 428| Step: 0
Training loss: 0.12558165192604065
Validation loss: 1.5551102610044583

Epoch: 5| Step: 1
Training loss: 0.12813356518745422
Validation loss: 1.5519003188738258

Epoch: 5| Step: 2
Training loss: 0.14756622910499573
Validation loss: 1.5760144520831365

Epoch: 5| Step: 3
Training loss: 0.1285047084093094
Validation loss: 1.5764294080836798

Epoch: 5| Step: 4
Training loss: 0.09157104790210724
Validation loss: 1.5884331310949018

Epoch: 5| Step: 5
Training loss: 0.09694705158472061
Validation loss: 1.6332464115594023

Epoch: 5| Step: 6
Training loss: 0.19907543063163757
Validation loss: 1.6097843300911687

Epoch: 5| Step: 7
Training loss: 0.19951525330543518
Validation loss: 1.6342113466673

Epoch: 5| Step: 8
Training loss: 0.11414720118045807
Validation loss: 1.618390377490751

Epoch: 5| Step: 9
Training loss: 0.12013043463230133
Validation loss: 1.6313460565382434

Epoch: 5| Step: 10
Training loss: 0.08998548984527588
Validation loss: 1.6104856575689008

Epoch: 429| Step: 0
Training loss: 0.12026393413543701
Validation loss: 1.5924264102853753

Epoch: 5| Step: 1
Training loss: 0.14444591104984283
Validation loss: 1.5533839502642233

Epoch: 5| Step: 2
Training loss: 0.12671619653701782
Validation loss: 1.539973061571839

Epoch: 5| Step: 3
Training loss: 0.1776578277349472
Validation loss: 1.5427631985756658

Epoch: 5| Step: 4
Training loss: 0.16209717094898224
Validation loss: 1.546535111242725

Epoch: 5| Step: 5
Training loss: 0.12037799507379532
Validation loss: 1.5565687443620415

Epoch: 5| Step: 6
Training loss: 0.12673571705818176
Validation loss: 1.5460752287218649

Epoch: 5| Step: 7
Training loss: 0.14699983596801758
Validation loss: 1.5547027318708357

Epoch: 5| Step: 8
Training loss: 0.12211476266384125
Validation loss: 1.571506566898797

Epoch: 5| Step: 9
Training loss: 0.11099650710821152
Validation loss: 1.5639166985788653

Epoch: 5| Step: 10
Training loss: 0.1933523416519165
Validation loss: 1.5586720717850553

Epoch: 430| Step: 0
Training loss: 0.19066807627677917
Validation loss: 1.5885181721820627

Epoch: 5| Step: 1
Training loss: 0.1416439712047577
Validation loss: 1.541892251660747

Epoch: 5| Step: 2
Training loss: 0.10046117007732391
Validation loss: 1.5802106216389646

Epoch: 5| Step: 3
Training loss: 0.11251123249530792
Validation loss: 1.5811423217096636

Epoch: 5| Step: 4
Training loss: 0.15623971819877625
Validation loss: 1.6049453853279032

Epoch: 5| Step: 5
Training loss: 0.13324077427387238
Validation loss: 1.6093523835623136

Epoch: 5| Step: 6
Training loss: 0.14066044986248016
Validation loss: 1.5662690542077506

Epoch: 5| Step: 7
Training loss: 0.11836349964141846
Validation loss: 1.5472078079818397

Epoch: 5| Step: 8
Training loss: 0.13348893821239471
Validation loss: 1.5426313441286805

Epoch: 5| Step: 9
Training loss: 0.13958808779716492
Validation loss: 1.5302543511954687

Epoch: 5| Step: 10
Training loss: 0.0899367481470108
Validation loss: 1.555156159144576

Epoch: 431| Step: 0
Training loss: 0.11262599378824234
Validation loss: 1.5261267167265697

Epoch: 5| Step: 1
Training loss: 0.19064787030220032
Validation loss: 1.5162210079931444

Epoch: 5| Step: 2
Training loss: 0.21409030258655548
Validation loss: 1.534671095109755

Epoch: 5| Step: 3
Training loss: 0.13206800818443298
Validation loss: 1.5268141095356276

Epoch: 5| Step: 4
Training loss: 0.06688688695430756
Validation loss: 1.5503759717428556

Epoch: 5| Step: 5
Training loss: 0.10679137706756592
Validation loss: 1.5711863938198294

Epoch: 5| Step: 6
Training loss: 0.13912566006183624
Validation loss: 1.5939049425945486

Epoch: 5| Step: 7
Training loss: 0.19466754794120789
Validation loss: 1.5969666909146052

Epoch: 5| Step: 8
Training loss: 0.14924649894237518
Validation loss: 1.5989849862232004

Epoch: 5| Step: 9
Training loss: 0.1407027244567871
Validation loss: 1.5875957896632533

Epoch: 5| Step: 10
Training loss: 0.13952450454235077
Validation loss: 1.5625612146110945

Epoch: 432| Step: 0
Training loss: 0.16097429394721985
Validation loss: 1.5770548018076087

Epoch: 5| Step: 1
Training loss: 0.1408797800540924
Validation loss: 1.5599237859890025

Epoch: 5| Step: 2
Training loss: 0.12247077375650406
Validation loss: 1.561851207927991

Epoch: 5| Step: 3
Training loss: 0.12725290656089783
Validation loss: 1.5354854355576217

Epoch: 5| Step: 4
Training loss: 0.13322137296199799
Validation loss: 1.5702409821171914

Epoch: 5| Step: 5
Training loss: 0.20740418136119843
Validation loss: 1.5821566863726544

Epoch: 5| Step: 6
Training loss: 0.09289710223674774
Validation loss: 1.5879838569189912

Epoch: 5| Step: 7
Training loss: 0.10881181061267853
Validation loss: 1.6396880457478185

Epoch: 5| Step: 8
Training loss: 0.16576017439365387
Validation loss: 1.6426511362034788

Epoch: 5| Step: 9
Training loss: 0.21158814430236816
Validation loss: 1.658869489546745

Epoch: 5| Step: 10
Training loss: 0.05815894529223442
Validation loss: 1.637914816538493

Epoch: 433| Step: 0
Training loss: 0.1554812788963318
Validation loss: 1.6647262752697032

Epoch: 5| Step: 1
Training loss: 0.11468641459941864
Validation loss: 1.6894155215191584

Epoch: 5| Step: 2
Training loss: 0.11713807284832001
Validation loss: 1.6254465964532667

Epoch: 5| Step: 3
Training loss: 0.16676099598407745
Validation loss: 1.6629292093297487

Epoch: 5| Step: 4
Training loss: 0.11500298976898193
Validation loss: 1.6461882911702639

Epoch: 5| Step: 5
Training loss: 0.1346229463815689
Validation loss: 1.642174816900684

Epoch: 5| Step: 6
Training loss: 0.19880996644496918
Validation loss: 1.6704192917834046

Epoch: 5| Step: 7
Training loss: 0.11367728561162949
Validation loss: 1.6468746418594031

Epoch: 5| Step: 8
Training loss: 0.1034831628203392
Validation loss: 1.6868484430415656

Epoch: 5| Step: 9
Training loss: 0.18057605624198914
Validation loss: 1.6461942349710772

Epoch: 5| Step: 10
Training loss: 0.11350452899932861
Validation loss: 1.6256736991226033

Epoch: 434| Step: 0
Training loss: 0.169552281498909
Validation loss: 1.5671786467234294

Epoch: 5| Step: 1
Training loss: 0.15866971015930176
Validation loss: 1.5594234498598243

Epoch: 5| Step: 2
Training loss: 0.10186012834310532
Validation loss: 1.574430109352194

Epoch: 5| Step: 3
Training loss: 0.19649258255958557
Validation loss: 1.5502618717890915

Epoch: 5| Step: 4
Training loss: 0.19986192882061005
Validation loss: 1.5573057795083651

Epoch: 5| Step: 5
Training loss: 0.09725718200206757
Validation loss: 1.5246675117041475

Epoch: 5| Step: 6
Training loss: 0.19256113469600677
Validation loss: 1.5614261434924217

Epoch: 5| Step: 7
Training loss: 0.16958090662956238
Validation loss: 1.5395896870602843

Epoch: 5| Step: 8
Training loss: 0.14034634828567505
Validation loss: 1.5487412329643004

Epoch: 5| Step: 9
Training loss: 0.14317700266838074
Validation loss: 1.5705294096341698

Epoch: 5| Step: 10
Training loss: 0.1442355364561081
Validation loss: 1.5670315116964362

Epoch: 435| Step: 0
Training loss: 0.09804308414459229
Validation loss: 1.5854970614115398

Epoch: 5| Step: 1
Training loss: 0.1512082815170288
Validation loss: 1.5668127113772976

Epoch: 5| Step: 2
Training loss: 0.13566459715366364
Validation loss: 1.5743898422487321

Epoch: 5| Step: 3
Training loss: 0.13942094147205353
Validation loss: 1.5842640002568562

Epoch: 5| Step: 4
Training loss: 0.1314719170331955
Validation loss: 1.5919763324081257

Epoch: 5| Step: 5
Training loss: 0.1503029316663742
Validation loss: 1.5369658457335604

Epoch: 5| Step: 6
Training loss: 0.1044672355055809
Validation loss: 1.581165539321079

Epoch: 5| Step: 7
Training loss: 0.16026648879051208
Validation loss: 1.5789243649410944

Epoch: 5| Step: 8
Training loss: 0.1797533929347992
Validation loss: 1.5755727150106942

Epoch: 5| Step: 9
Training loss: 0.12639829516410828
Validation loss: 1.5733880881340272

Epoch: 5| Step: 10
Training loss: 0.1382061243057251
Validation loss: 1.600650559189499

Epoch: 436| Step: 0
Training loss: 0.11890967190265656
Validation loss: 1.607213544589217

Epoch: 5| Step: 1
Training loss: 0.1501123458147049
Validation loss: 1.6127141009094894

Epoch: 5| Step: 2
Training loss: 0.13013681769371033
Validation loss: 1.5794714496981712

Epoch: 5| Step: 3
Training loss: 0.17850343883037567
Validation loss: 1.5753293588597288

Epoch: 5| Step: 4
Training loss: 0.10950493812561035
Validation loss: 1.544802737492387

Epoch: 5| Step: 5
Training loss: 0.2534319758415222
Validation loss: 1.5658996451285578

Epoch: 5| Step: 6
Training loss: 0.11006306111812592
Validation loss: 1.5628070869753439

Epoch: 5| Step: 7
Training loss: 0.12481822073459625
Validation loss: 1.5640236793025848

Epoch: 5| Step: 8
Training loss: 0.11770729720592499
Validation loss: 1.558877319417974

Epoch: 5| Step: 9
Training loss: 0.09405963122844696
Validation loss: 1.5690199354643464

Epoch: 5| Step: 10
Training loss: 0.1365436315536499
Validation loss: 1.569125812540772

Epoch: 437| Step: 0
Training loss: 0.15167324244976044
Validation loss: 1.5605081569763921

Epoch: 5| Step: 1
Training loss: 0.1218775063753128
Validation loss: 1.5597095310047109

Epoch: 5| Step: 2
Training loss: 0.16669371724128723
Validation loss: 1.5538435943665043

Epoch: 5| Step: 3
Training loss: 0.12197103351354599
Validation loss: 1.5082330408916678

Epoch: 5| Step: 4
Training loss: 0.12600049376487732
Validation loss: 1.54067579648828

Epoch: 5| Step: 5
Training loss: 0.16441039741039276
Validation loss: 1.5371382057025869

Epoch: 5| Step: 6
Training loss: 0.12106083333492279
Validation loss: 1.5378851365017634

Epoch: 5| Step: 7
Training loss: 0.15337756276130676
Validation loss: 1.526232224638744

Epoch: 5| Step: 8
Training loss: 0.14993412792682648
Validation loss: 1.5407243479964554

Epoch: 5| Step: 9
Training loss: 0.20351548492908478
Validation loss: 1.5340735335503854

Epoch: 5| Step: 10
Training loss: 0.14991053938865662
Validation loss: 1.579384006479735

Epoch: 438| Step: 0
Training loss: 0.11386626958847046
Validation loss: 1.550214368809936

Epoch: 5| Step: 1
Training loss: 0.14072385430335999
Validation loss: 1.5477859115087858

Epoch: 5| Step: 2
Training loss: 0.07299140095710754
Validation loss: 1.5643918193796629

Epoch: 5| Step: 3
Training loss: 0.1322641372680664
Validation loss: 1.5347212924752185

Epoch: 5| Step: 4
Training loss: 0.12295284122228622
Validation loss: 1.549749050089108

Epoch: 5| Step: 5
Training loss: 0.12548068165779114
Validation loss: 1.5574895002508675

Epoch: 5| Step: 6
Training loss: 0.13414162397384644
Validation loss: 1.536412323674848

Epoch: 5| Step: 7
Training loss: 0.14957261085510254
Validation loss: 1.5703842152831375

Epoch: 5| Step: 8
Training loss: 0.13459192216396332
Validation loss: 1.5587109186316048

Epoch: 5| Step: 9
Training loss: 0.21416044235229492
Validation loss: 1.570330746071313

Epoch: 5| Step: 10
Training loss: 0.08107461780309677
Validation loss: 1.5863090510009437

Epoch: 439| Step: 0
Training loss: 0.18984639644622803
Validation loss: 1.5710335444378596

Epoch: 5| Step: 1
Training loss: 0.1193258985877037
Validation loss: 1.5725804926246725

Epoch: 5| Step: 2
Training loss: 0.13801209628582
Validation loss: 1.5887507597605388

Epoch: 5| Step: 3
Training loss: 0.10112418234348297
Validation loss: 1.6018780123802923

Epoch: 5| Step: 4
Training loss: 0.14522404968738556
Validation loss: 1.581956463475381

Epoch: 5| Step: 5
Training loss: 0.15909035503864288
Validation loss: 1.6102046940916328

Epoch: 5| Step: 6
Training loss: 0.0888102576136589
Validation loss: 1.5800308489030408

Epoch: 5| Step: 7
Training loss: 0.23683884739875793
Validation loss: 1.5961589954232658

Epoch: 5| Step: 8
Training loss: 0.10481607913970947
Validation loss: 1.580342633108939

Epoch: 5| Step: 9
Training loss: 0.14761188626289368
Validation loss: 1.5810891723120084

Epoch: 5| Step: 10
Training loss: 0.12892432510852814
Validation loss: 1.5661230048825663

Epoch: 440| Step: 0
Training loss: 0.1512337327003479
Validation loss: 1.5672292465804725

Epoch: 5| Step: 1
Training loss: 0.08010779321193695
Validation loss: 1.5544570376796107

Epoch: 5| Step: 2
Training loss: 0.11612126976251602
Validation loss: 1.5596730132256784

Epoch: 5| Step: 3
Training loss: 0.10868780314922333
Validation loss: 1.573632856850983

Epoch: 5| Step: 4
Training loss: 0.17360498011112213
Validation loss: 1.5831989908731112

Epoch: 5| Step: 5
Training loss: 0.11760444939136505
Validation loss: 1.5817342663324008

Epoch: 5| Step: 6
Training loss: 0.1380424052476883
Validation loss: 1.6027856937018774

Epoch: 5| Step: 7
Training loss: 0.11729227006435394
Validation loss: 1.6451884418405511

Epoch: 5| Step: 8
Training loss: 0.1390623152256012
Validation loss: 1.6463536716276599

Epoch: 5| Step: 9
Training loss: 0.11045058071613312
Validation loss: 1.6467790808728946

Epoch: 5| Step: 10
Training loss: 0.12062487751245499
Validation loss: 1.6038264792452577

Epoch: 441| Step: 0
Training loss: 0.1816316694021225
Validation loss: 1.5973022202009797

Epoch: 5| Step: 1
Training loss: 0.10313332080841064
Validation loss: 1.5897210951774352

Epoch: 5| Step: 2
Training loss: 0.13869142532348633
Validation loss: 1.584421641083174

Epoch: 5| Step: 3
Training loss: 0.10182599723339081
Validation loss: 1.5713875870550833

Epoch: 5| Step: 4
Training loss: 0.10114224255084991
Validation loss: 1.5338750987924554

Epoch: 5| Step: 5
Training loss: 0.16688045859336853
Validation loss: 1.529988770843834

Epoch: 5| Step: 6
Training loss: 0.1423865258693695
Validation loss: 1.533666209508014

Epoch: 5| Step: 7
Training loss: 0.07954971492290497
Validation loss: 1.5433408765382663

Epoch: 5| Step: 8
Training loss: 0.14527052640914917
Validation loss: 1.5769075270622008

Epoch: 5| Step: 9
Training loss: 0.17354826629161835
Validation loss: 1.5583816702647875

Epoch: 5| Step: 10
Training loss: 0.1327780783176422
Validation loss: 1.568380739099236

Epoch: 442| Step: 0
Training loss: 0.1213018074631691
Validation loss: 1.5940886979462

Epoch: 5| Step: 1
Training loss: 0.14596372842788696
Validation loss: 1.5955643282141736

Epoch: 5| Step: 2
Training loss: 0.12235049158334732
Validation loss: 1.6202077609236523

Epoch: 5| Step: 3
Training loss: 0.12031705677509308
Validation loss: 1.593276221265075

Epoch: 5| Step: 4
Training loss: 0.10697758197784424
Validation loss: 1.587016902944093

Epoch: 5| Step: 5
Training loss: 0.13745824992656708
Validation loss: 1.5498592289545203

Epoch: 5| Step: 6
Training loss: 0.12184808403253555
Validation loss: 1.5237949586683703

Epoch: 5| Step: 7
Training loss: 0.11079774051904678
Validation loss: 1.522384375654241

Epoch: 5| Step: 8
Training loss: 0.11400284618139267
Validation loss: 1.506744944921104

Epoch: 5| Step: 9
Training loss: 0.1324675977230072
Validation loss: 1.5029488866047194

Epoch: 5| Step: 10
Training loss: 0.13831932842731476
Validation loss: 1.4910029839443903

Epoch: 443| Step: 0
Training loss: 0.07537877559661865
Validation loss: 1.5242655110615555

Epoch: 5| Step: 1
Training loss: 0.060949184000492096
Validation loss: 1.5581864426212926

Epoch: 5| Step: 2
Training loss: 0.08562110364437103
Validation loss: 1.5588608954542427

Epoch: 5| Step: 3
Training loss: 0.08362630009651184
Validation loss: 1.5802641543008948

Epoch: 5| Step: 4
Training loss: 0.1207287535071373
Validation loss: 1.5885179222271006

Epoch: 5| Step: 5
Training loss: 0.16086360812187195
Validation loss: 1.5995325555083573

Epoch: 5| Step: 6
Training loss: 0.11917263269424438
Validation loss: 1.6017827192942302

Epoch: 5| Step: 7
Training loss: 0.06403892487287521
Validation loss: 1.6053373018900554

Epoch: 5| Step: 8
Training loss: 0.22488291561603546
Validation loss: 1.643289686531149

Epoch: 5| Step: 9
Training loss: 0.10720384120941162
Validation loss: 1.5976010830171647

Epoch: 5| Step: 10
Training loss: 0.16308844089508057
Validation loss: 1.585953092062345

Epoch: 444| Step: 0
Training loss: 0.1724911332130432
Validation loss: 1.566125181413466

Epoch: 5| Step: 1
Training loss: 0.09762760251760483
Validation loss: 1.5629077585794593

Epoch: 5| Step: 2
Training loss: 0.14665177464485168
Validation loss: 1.5464233467655797

Epoch: 5| Step: 3
Training loss: 0.10168254375457764
Validation loss: 1.5637763584813764

Epoch: 5| Step: 4
Training loss: 0.10280103981494904
Validation loss: 1.5555355125857937

Epoch: 5| Step: 5
Training loss: 0.08003251254558563
Validation loss: 1.55991276233427

Epoch: 5| Step: 6
Training loss: 0.10680428892374039
Validation loss: 1.5806522241202734

Epoch: 5| Step: 7
Training loss: 0.12751969695091248
Validation loss: 1.5735098072277602

Epoch: 5| Step: 8
Training loss: 0.10573999583721161
Validation loss: 1.582429188554005

Epoch: 5| Step: 9
Training loss: 0.13943326473236084
Validation loss: 1.546579691671556

Epoch: 5| Step: 10
Training loss: 0.12901639938354492
Validation loss: 1.5307118482487176

Epoch: 445| Step: 0
Training loss: 0.12616176903247833
Validation loss: 1.5401427040817917

Epoch: 5| Step: 1
Training loss: 0.08997752517461777
Validation loss: 1.5490237333441292

Epoch: 5| Step: 2
Training loss: 0.12176163494586945
Validation loss: 1.5649669670289563

Epoch: 5| Step: 3
Training loss: 0.10342655330896378
Validation loss: 1.582136909166972

Epoch: 5| Step: 4
Training loss: 0.09013435244560242
Validation loss: 1.6056336113201675

Epoch: 5| Step: 5
Training loss: 0.1507164090871811
Validation loss: 1.5946477946414743

Epoch: 5| Step: 6
Training loss: 0.18551144003868103
Validation loss: 1.6011174084037862

Epoch: 5| Step: 7
Training loss: 0.07648215442895889
Validation loss: 1.6165153416254188

Epoch: 5| Step: 8
Training loss: 0.1207178607583046
Validation loss: 1.571010156344342

Epoch: 5| Step: 9
Training loss: 0.11728833615779877
Validation loss: 1.5700580573851062

Epoch: 5| Step: 10
Training loss: 0.14690254628658295
Validation loss: 1.5521515313015188

Epoch: 446| Step: 0
Training loss: 0.12337321043014526
Validation loss: 1.5779745424947431

Epoch: 5| Step: 1
Training loss: 0.1921987384557724
Validation loss: 1.5638121520319292

Epoch: 5| Step: 2
Training loss: 0.12283805757761002
Validation loss: 1.5220250673191522

Epoch: 5| Step: 3
Training loss: 0.0865003913640976
Validation loss: 1.5453472752724924

Epoch: 5| Step: 4
Training loss: 0.1386120319366455
Validation loss: 1.584418857610354

Epoch: 5| Step: 5
Training loss: 0.09724874794483185
Validation loss: 1.5969721424964167

Epoch: 5| Step: 6
Training loss: 0.10096649825572968
Validation loss: 1.5978421075369722

Epoch: 5| Step: 7
Training loss: 0.08594313263893127
Validation loss: 1.6212691184013122

Epoch: 5| Step: 8
Training loss: 0.12795057892799377
Validation loss: 1.6143659789075133

Epoch: 5| Step: 9
Training loss: 0.12307896465063095
Validation loss: 1.6081213310200682

Epoch: 5| Step: 10
Training loss: 0.14808472990989685
Validation loss: 1.5862027457965318

Epoch: 447| Step: 0
Training loss: 0.1281641274690628
Validation loss: 1.5858868065700735

Epoch: 5| Step: 1
Training loss: 0.10343704372644424
Validation loss: 1.548820134132139

Epoch: 5| Step: 2
Training loss: 0.09300713241100311
Validation loss: 1.5432174231416436

Epoch: 5| Step: 3
Training loss: 0.2180067002773285
Validation loss: 1.5108356475830078

Epoch: 5| Step: 4
Training loss: 0.11585911363363266
Validation loss: 1.5605667047603156

Epoch: 5| Step: 5
Training loss: 0.16011956334114075
Validation loss: 1.5438342299512637

Epoch: 5| Step: 6
Training loss: 0.1099158301949501
Validation loss: 1.5356217879121021

Epoch: 5| Step: 7
Training loss: 0.08343080431222916
Validation loss: 1.5533127989820255

Epoch: 5| Step: 8
Training loss: 0.1250729262828827
Validation loss: 1.5558035258323915

Epoch: 5| Step: 9
Training loss: 0.09167344868183136
Validation loss: 1.6081393777683217

Epoch: 5| Step: 10
Training loss: 0.20041170716285706
Validation loss: 1.6258705700597456

Epoch: 448| Step: 0
Training loss: 0.1286461502313614
Validation loss: 1.6185377977227653

Epoch: 5| Step: 1
Training loss: 0.09099128097295761
Validation loss: 1.6065697413618847

Epoch: 5| Step: 2
Training loss: 0.1376151293516159
Validation loss: 1.5824595394954886

Epoch: 5| Step: 3
Training loss: 0.07297636568546295
Validation loss: 1.5938549464748752

Epoch: 5| Step: 4
Training loss: 0.10319533199071884
Validation loss: 1.541546405002635

Epoch: 5| Step: 5
Training loss: 0.1155066043138504
Validation loss: 1.5315378647978588

Epoch: 5| Step: 6
Training loss: 0.08224135637283325
Validation loss: 1.511444660925096

Epoch: 5| Step: 7
Training loss: 0.13816043734550476
Validation loss: 1.515923250106073

Epoch: 5| Step: 8
Training loss: 0.14441117644309998
Validation loss: 1.5478014484528573

Epoch: 5| Step: 9
Training loss: 0.16831742227077484
Validation loss: 1.5190792968196254

Epoch: 5| Step: 10
Training loss: 0.06388179212808609
Validation loss: 1.5349787422405776

Epoch: 449| Step: 0
Training loss: 0.11733903735876083
Validation loss: 1.537052636505455

Epoch: 5| Step: 1
Training loss: 0.05214118957519531
Validation loss: 1.5399408148181053

Epoch: 5| Step: 2
Training loss: 0.11756078898906708
Validation loss: 1.5726486072745374

Epoch: 5| Step: 3
Training loss: 0.1313473880290985
Validation loss: 1.5307375679733932

Epoch: 5| Step: 4
Training loss: 0.11402721703052521
Validation loss: 1.530793213075207

Epoch: 5| Step: 5
Training loss: 0.11279754340648651
Validation loss: 1.5064263882175568

Epoch: 5| Step: 6
Training loss: 0.11966409534215927
Validation loss: 1.4938036562294088

Epoch: 5| Step: 7
Training loss: 0.11520101130008698
Validation loss: 1.5192277841670538

Epoch: 5| Step: 8
Training loss: 0.1577208936214447
Validation loss: 1.503433588371482

Epoch: 5| Step: 9
Training loss: 0.0874563530087471
Validation loss: 1.49990326358426

Epoch: 5| Step: 10
Training loss: 0.08890652656555176
Validation loss: 1.5364836749210153

Epoch: 450| Step: 0
Training loss: 0.14692223072052002
Validation loss: 1.5252120033387215

Epoch: 5| Step: 1
Training loss: 0.12223055213689804
Validation loss: 1.5117980382775749

Epoch: 5| Step: 2
Training loss: 0.07856230437755585
Validation loss: 1.5496031212550339

Epoch: 5| Step: 3
Training loss: 0.12524159252643585
Validation loss: 1.5822163262674886

Epoch: 5| Step: 4
Training loss: 0.1398719847202301
Validation loss: 1.5646178055835027

Epoch: 5| Step: 5
Training loss: 0.09410551190376282
Validation loss: 1.5740479448790192

Epoch: 5| Step: 6
Training loss: 0.1142159253358841
Validation loss: 1.574645503874748

Epoch: 5| Step: 7
Training loss: 0.09843798726797104
Validation loss: 1.581771772394898

Epoch: 5| Step: 8
Training loss: 0.1425212323665619
Validation loss: 1.545315629692488

Epoch: 5| Step: 9
Training loss: 0.11661984026432037
Validation loss: 1.5306661026452177

Epoch: 5| Step: 10
Training loss: 0.098103366792202
Validation loss: 1.5017133835823304

Testing loss: 1.8991298940446641
