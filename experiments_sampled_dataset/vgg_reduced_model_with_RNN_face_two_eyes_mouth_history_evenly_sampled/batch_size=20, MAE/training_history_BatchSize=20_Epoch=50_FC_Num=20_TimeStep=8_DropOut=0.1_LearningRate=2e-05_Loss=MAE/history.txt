Epoch: 1| Step: 0
Training loss: 4.183959484100342
Validation loss: 5.141148946618521

Epoch: 5| Step: 1
Training loss: 5.324709415435791
Validation loss: 5.116439839845063

Epoch: 5| Step: 2
Training loss: 4.08596134185791
Validation loss: 5.091821521841069

Epoch: 5| Step: 3
Training loss: 4.297314643859863
Validation loss: 5.065215464561216

Epoch: 5| Step: 4
Training loss: 4.604994773864746
Validation loss: 5.036362222445908

Epoch: 5| Step: 5
Training loss: 5.330155372619629
Validation loss: 5.003686766470632

Epoch: 5| Step: 6
Training loss: 5.656213760375977
Validation loss: 4.967388645295174

Epoch: 5| Step: 7
Training loss: 3.9695687294006348
Validation loss: 4.928067417554958

Epoch: 5| Step: 8
Training loss: 4.659312725067139
Validation loss: 4.882990403841901

Epoch: 5| Step: 9
Training loss: 4.876425743103027
Validation loss: 4.833598500938826

Epoch: 5| Step: 10
Training loss: 5.695323467254639
Validation loss: 4.778958453926989

Epoch: 2| Step: 0
Training loss: 4.9707231521606445
Validation loss: 4.720228861736995

Epoch: 5| Step: 1
Training loss: 3.716777801513672
Validation loss: 4.6591894754799466

Epoch: 5| Step: 2
Training loss: 4.288226127624512
Validation loss: 4.592277373037031

Epoch: 5| Step: 3
Training loss: 4.861065864562988
Validation loss: 4.524539506563577

Epoch: 5| Step: 4
Training loss: 5.598299980163574
Validation loss: 4.452405847528929

Epoch: 5| Step: 5
Training loss: 3.969561815261841
Validation loss: 4.382514589576311

Epoch: 5| Step: 6
Training loss: 4.16418981552124
Validation loss: 4.314758387945032

Epoch: 5| Step: 7
Training loss: 3.182276487350464
Validation loss: 4.248785111211961

Epoch: 5| Step: 8
Training loss: 3.9665751457214355
Validation loss: 4.1798830211803475

Epoch: 5| Step: 9
Training loss: 4.222413539886475
Validation loss: 4.111084561194143

Epoch: 5| Step: 10
Training loss: 3.0634818077087402
Validation loss: 4.038306482376591

Epoch: 3| Step: 0
Training loss: 4.031347274780273
Validation loss: 3.9715460500409527

Epoch: 5| Step: 1
Training loss: 4.385679721832275
Validation loss: 3.9119016124356176

Epoch: 5| Step: 2
Training loss: 4.013354301452637
Validation loss: 3.8622221536533807

Epoch: 5| Step: 3
Training loss: 2.7361960411071777
Validation loss: 3.818666693984821

Epoch: 5| Step: 4
Training loss: 3.7049853801727295
Validation loss: 3.7856421419369277

Epoch: 5| Step: 5
Training loss: 3.072028398513794
Validation loss: 3.7569668164817234

Epoch: 5| Step: 6
Training loss: 3.9042251110076904
Validation loss: 3.7296677379197973

Epoch: 5| Step: 7
Training loss: 3.6983208656311035
Validation loss: 3.7024359549245527

Epoch: 5| Step: 8
Training loss: 3.0056145191192627
Validation loss: 3.675283016697053

Epoch: 5| Step: 9
Training loss: 3.6031136512756348
Validation loss: 3.648083181791408

Epoch: 5| Step: 10
Training loss: 4.2866291999816895
Validation loss: 3.6243380346605854

Epoch: 4| Step: 0
Training loss: 3.2164573669433594
Validation loss: 3.604990954040199

Epoch: 5| Step: 1
Training loss: 3.5689804553985596
Validation loss: 3.594454978101997

Epoch: 5| Step: 2
Training loss: 3.2771098613739014
Validation loss: 3.5747182753778275

Epoch: 5| Step: 3
Training loss: 3.365428924560547
Validation loss: 3.5487484265399236

Epoch: 5| Step: 4
Training loss: 3.063556432723999
Validation loss: 3.526738559046099

Epoch: 5| Step: 5
Training loss: 3.2018566131591797
Validation loss: 3.5089692941275974

Epoch: 5| Step: 6
Training loss: 3.193808078765869
Validation loss: 3.493112374377507

Epoch: 5| Step: 7
Training loss: 3.8148245811462402
Validation loss: 3.4746076881244616

Epoch: 5| Step: 8
Training loss: 3.8542683124542236
Validation loss: 3.4556123441265476

Epoch: 5| Step: 9
Training loss: 4.20940637588501
Validation loss: 3.4346044678841867

Epoch: 5| Step: 10
Training loss: 2.9830315113067627
Validation loss: 3.4118733636794554

Epoch: 5| Step: 0
Training loss: 3.0283596515655518
Validation loss: 3.395358826524468

Epoch: 5| Step: 1
Training loss: 3.934796094894409
Validation loss: 3.3811460028412523

Epoch: 5| Step: 2
Training loss: 2.986482620239258
Validation loss: 3.3629006288384877

Epoch: 5| Step: 3
Training loss: 3.405780792236328
Validation loss: 3.365396176615069

Epoch: 5| Step: 4
Training loss: 3.087050199508667
Validation loss: 3.3644264615992063

Epoch: 5| Step: 5
Training loss: 3.0864408016204834
Validation loss: 3.3347665904670634

Epoch: 5| Step: 6
Training loss: 3.6221230030059814
Validation loss: 3.3569291868517475

Epoch: 5| Step: 7
Training loss: 2.9699766635894775
Validation loss: 3.331477598477435

Epoch: 5| Step: 8
Training loss: 3.428511381149292
Validation loss: 3.322966714059153

Epoch: 5| Step: 9
Training loss: 3.5596420764923096
Validation loss: 3.332492754023562

Epoch: 5| Step: 10
Training loss: 3.323098659515381
Validation loss: 3.3100199058491695

Epoch: 6| Step: 0
Training loss: 3.7021231651306152
Validation loss: 3.3007044689629668

Epoch: 5| Step: 1
Training loss: 3.1931064128875732
Validation loss: 3.292328562787784

Epoch: 5| Step: 2
Training loss: 3.452448606491089
Validation loss: 3.293432799718713

Epoch: 5| Step: 3
Training loss: 2.509307861328125
Validation loss: 3.290015974352437

Epoch: 5| Step: 4
Training loss: 2.9417624473571777
Validation loss: 3.2796875661419285

Epoch: 5| Step: 5
Training loss: 4.046612739562988
Validation loss: 3.2601055278572986

Epoch: 5| Step: 6
Training loss: 3.1442244052886963
Validation loss: 3.2488523990877214

Epoch: 5| Step: 7
Training loss: 3.7341575622558594
Validation loss: 3.2398616498516453

Epoch: 5| Step: 8
Training loss: 3.3111748695373535
Validation loss: 3.230012075875395

Epoch: 5| Step: 9
Training loss: 2.938037157058716
Validation loss: 3.2212572482324417

Epoch: 5| Step: 10
Training loss: 2.5923354625701904
Validation loss: 3.2131824749772266

Epoch: 7| Step: 0
Training loss: 3.8799147605895996
Validation loss: 3.214622656504313

Epoch: 5| Step: 1
Training loss: 2.4645729064941406
Validation loss: 3.1874426334134993

Epoch: 5| Step: 2
Training loss: 3.90399432182312
Validation loss: 3.183290086766725

Epoch: 5| Step: 3
Training loss: 2.9494643211364746
Validation loss: 3.1791884104410806

Epoch: 5| Step: 4
Training loss: 3.7609169483184814
Validation loss: 3.170748136376822

Epoch: 5| Step: 5
Training loss: 2.8562047481536865
Validation loss: 3.163248303116009

Epoch: 5| Step: 6
Training loss: 2.213190793991089
Validation loss: 3.1562426244058917

Epoch: 5| Step: 7
Training loss: 2.807682514190674
Validation loss: 3.145981598925847

Epoch: 5| Step: 8
Training loss: 3.4648776054382324
Validation loss: 3.1357908171992146

Epoch: 5| Step: 9
Training loss: 2.9943671226501465
Validation loss: 3.1260814589838826

Epoch: 5| Step: 10
Training loss: 3.6420459747314453
Validation loss: 3.116127893488894

Epoch: 8| Step: 0
Training loss: 3.485196352005005
Validation loss: 3.1094193202193066

Epoch: 5| Step: 1
Training loss: 2.9905474185943604
Validation loss: 3.1106298559455463

Epoch: 5| Step: 2
Training loss: 3.1134064197540283
Validation loss: 3.099437088094732

Epoch: 5| Step: 3
Training loss: 2.714503288269043
Validation loss: 3.0873250371666363

Epoch: 5| Step: 4
Training loss: 3.423067808151245
Validation loss: 3.085674972944362

Epoch: 5| Step: 5
Training loss: 2.496687650680542
Validation loss: 3.0782319704691568

Epoch: 5| Step: 6
Training loss: 3.4182956218719482
Validation loss: 3.065646130551574

Epoch: 5| Step: 7
Training loss: 3.033909559249878
Validation loss: 3.0545213760868197

Epoch: 5| Step: 8
Training loss: 3.065469264984131
Validation loss: 3.052221662254744

Epoch: 5| Step: 9
Training loss: 3.1973087787628174
Validation loss: 3.0420729549982215

Epoch: 5| Step: 10
Training loss: 3.312981128692627
Validation loss: 3.0349890544850338

Epoch: 9| Step: 0
Training loss: 3.7941348552703857
Validation loss: 3.0261637856883388

Epoch: 5| Step: 1
Training loss: 2.774980068206787
Validation loss: 3.0172101297686176

Epoch: 5| Step: 2
Training loss: 2.808634042739868
Validation loss: 3.007793423950031

Epoch: 5| Step: 3
Training loss: 2.1637070178985596
Validation loss: 3.0079117667290474

Epoch: 5| Step: 4
Training loss: 3.4055333137512207
Validation loss: 2.9999027098378828

Epoch: 5| Step: 5
Training loss: 3.367680311203003
Validation loss: 2.985224962234497

Epoch: 5| Step: 6
Training loss: 3.6874020099639893
Validation loss: 2.9822293045700237

Epoch: 5| Step: 7
Training loss: 2.9637608528137207
Validation loss: 2.977897749152235

Epoch: 5| Step: 8
Training loss: 3.1394410133361816
Validation loss: 2.972902495373962

Epoch: 5| Step: 9
Training loss: 3.047529935836792
Validation loss: 2.9728673427335677

Epoch: 5| Step: 10
Training loss: 2.4519243240356445
Validation loss: 2.961160034261724

Epoch: 10| Step: 0
Training loss: 2.9673259258270264
Validation loss: 2.954061367178476

Epoch: 5| Step: 1
Training loss: 2.910437822341919
Validation loss: 2.945624828338623

Epoch: 5| Step: 2
Training loss: 3.387781858444214
Validation loss: 2.9376333349494526

Epoch: 5| Step: 3
Training loss: 3.4318339824676514
Validation loss: 2.9307390015612365

Epoch: 5| Step: 4
Training loss: 3.2806601524353027
Validation loss: 2.9283115325435514

Epoch: 5| Step: 5
Training loss: 2.237083673477173
Validation loss: 2.9198719916805143

Epoch: 5| Step: 6
Training loss: 3.686765670776367
Validation loss: 2.9127313065272507

Epoch: 5| Step: 7
Training loss: 3.1484181880950928
Validation loss: 2.907482857345253

Epoch: 5| Step: 8
Training loss: 1.8914283514022827
Validation loss: 2.9029682195314797

Epoch: 5| Step: 9
Training loss: 3.639509677886963
Validation loss: 2.902128214477211

Epoch: 5| Step: 10
Training loss: 2.5107741355895996
Validation loss: 2.9000940630512853

Epoch: 11| Step: 0
Training loss: 2.872370719909668
Validation loss: 2.8978007224298294

Epoch: 5| Step: 1
Training loss: 2.631401538848877
Validation loss: 2.8948677406516126

Epoch: 5| Step: 2
Training loss: 2.5510520935058594
Validation loss: 2.885411206112113

Epoch: 5| Step: 3
Training loss: 3.2442855834960938
Validation loss: 2.8788624040542112

Epoch: 5| Step: 4
Training loss: 3.169951915740967
Validation loss: 2.868970681262273

Epoch: 5| Step: 5
Training loss: 2.6729960441589355
Validation loss: 2.8611213545645438

Epoch: 5| Step: 6
Training loss: 4.03009557723999
Validation loss: 2.8541926824918358

Epoch: 5| Step: 7
Training loss: 2.8592536449432373
Validation loss: 2.8499039219271753

Epoch: 5| Step: 8
Training loss: 2.44309663772583
Validation loss: 2.8454343862431024

Epoch: 5| Step: 9
Training loss: 3.379370927810669
Validation loss: 2.841725923681772

Epoch: 5| Step: 10
Training loss: 2.8546640872955322
Validation loss: 2.8361187852838987

Epoch: 12| Step: 0
Training loss: 3.220968723297119
Validation loss: 2.8321865835497455

Epoch: 5| Step: 1
Training loss: 3.5224781036376953
Validation loss: 2.827614635549566

Epoch: 5| Step: 2
Training loss: 3.033277988433838
Validation loss: 2.823722211263513

Epoch: 5| Step: 3
Training loss: 3.5917320251464844
Validation loss: 2.8200908707034205

Epoch: 5| Step: 4
Training loss: 2.442908763885498
Validation loss: 2.81367685205193

Epoch: 5| Step: 5
Training loss: 2.621314287185669
Validation loss: 2.809333326996014

Epoch: 5| Step: 6
Training loss: 2.417377471923828
Validation loss: 2.807992366052443

Epoch: 5| Step: 7
Training loss: 2.6116089820861816
Validation loss: 2.802167143872989

Epoch: 5| Step: 8
Training loss: 2.831089735031128
Validation loss: 2.7997752081963325

Epoch: 5| Step: 9
Training loss: 2.837118148803711
Validation loss: 2.810918641346757

Epoch: 5| Step: 10
Training loss: 3.289837121963501
Validation loss: 2.7923472389098136

Epoch: 13| Step: 0
Training loss: 2.7669010162353516
Validation loss: 2.808241469885713

Epoch: 5| Step: 1
Training loss: 3.3328940868377686
Validation loss: 2.8080607768028014

Epoch: 5| Step: 2
Training loss: 2.899365186691284
Validation loss: 2.8102172831053376

Epoch: 5| Step: 3
Training loss: 2.602820873260498
Validation loss: 2.804254239605319

Epoch: 5| Step: 4
Training loss: 3.2821121215820312
Validation loss: 2.8207165297641548

Epoch: 5| Step: 5
Training loss: 2.9874768257141113
Validation loss: 2.80238066950152

Epoch: 5| Step: 6
Training loss: 3.2672908306121826
Validation loss: 2.8047202351272746

Epoch: 5| Step: 7
Training loss: 3.02856707572937
Validation loss: 2.8011158512484644

Epoch: 5| Step: 8
Training loss: 2.9738316535949707
Validation loss: 2.795311350976267

Epoch: 5| Step: 9
Training loss: 2.602771043777466
Validation loss: 2.7928280727837675

Epoch: 5| Step: 10
Training loss: 2.525014638900757
Validation loss: 2.792239612148654

Epoch: 14| Step: 0
Training loss: 3.1350111961364746
Validation loss: 2.7883986708938435

Epoch: 5| Step: 1
Training loss: 2.436511993408203
Validation loss: 2.783048368269397

Epoch: 5| Step: 2
Training loss: 2.892426013946533
Validation loss: 2.778327800894296

Epoch: 5| Step: 3
Training loss: 2.763760805130005
Validation loss: 2.765784045701386

Epoch: 5| Step: 4
Training loss: 3.4158523082733154
Validation loss: 2.762383525089551

Epoch: 5| Step: 5
Training loss: 2.828441858291626
Validation loss: 2.758926163437546

Epoch: 5| Step: 6
Training loss: 3.31853985786438
Validation loss: 2.7513737293981735

Epoch: 5| Step: 7
Training loss: 2.8769772052764893
Validation loss: 2.7495806191557195

Epoch: 5| Step: 8
Training loss: 2.64949369430542
Validation loss: 2.7477281913962415

Epoch: 5| Step: 9
Training loss: 2.693681240081787
Validation loss: 2.7423635554570023

Epoch: 5| Step: 10
Training loss: 3.038374900817871
Validation loss: 2.7401181677336335

Epoch: 15| Step: 0
Training loss: 2.5322329998016357
Validation loss: 2.732768750959827

Epoch: 5| Step: 1
Training loss: 3.4911670684814453
Validation loss: 2.7284638753501316

Epoch: 5| Step: 2
Training loss: 3.165769577026367
Validation loss: 2.7209094903802358

Epoch: 5| Step: 3
Training loss: 3.2772281169891357
Validation loss: 2.713529227882303

Epoch: 5| Step: 4
Training loss: 2.906257152557373
Validation loss: 2.710013125532417

Epoch: 5| Step: 5
Training loss: 2.6824679374694824
Validation loss: 2.7063855663422616

Epoch: 5| Step: 6
Training loss: 2.885018825531006
Validation loss: 2.7030326217733402

Epoch: 5| Step: 7
Training loss: 3.1047756671905518
Validation loss: 2.6982695415455806

Epoch: 5| Step: 8
Training loss: 2.499307632446289
Validation loss: 2.6963807587982505

Epoch: 5| Step: 9
Training loss: 2.7073893547058105
Validation loss: 2.6935402885560067

Epoch: 5| Step: 10
Training loss: 2.301151990890503
Validation loss: 2.68938531157791

Epoch: 16| Step: 0
Training loss: 3.0568277835845947
Validation loss: 2.690132769205237

Epoch: 5| Step: 1
Training loss: 2.0631699562072754
Validation loss: 2.685593807569114

Epoch: 5| Step: 2
Training loss: 3.561889171600342
Validation loss: 2.6827087863799064

Epoch: 5| Step: 3
Training loss: 2.243311882019043
Validation loss: 2.6831976085580806

Epoch: 5| Step: 4
Training loss: 3.473921537399292
Validation loss: 2.6791081915619555

Epoch: 5| Step: 5
Training loss: 2.7655930519104004
Validation loss: 2.6758887921610186

Epoch: 5| Step: 6
Training loss: 2.511021137237549
Validation loss: 2.6744763671710925

Epoch: 5| Step: 7
Training loss: 2.641294002532959
Validation loss: 2.677090839673114

Epoch: 5| Step: 8
Training loss: 2.8240106105804443
Validation loss: 2.684565487728324

Epoch: 5| Step: 9
Training loss: 3.533923625946045
Validation loss: 2.687942284409718

Epoch: 5| Step: 10
Training loss: 2.732210636138916
Validation loss: 2.6770486293300504

Epoch: 17| Step: 0
Training loss: 2.250805377960205
Validation loss: 2.666124431035852

Epoch: 5| Step: 1
Training loss: 3.505908966064453
Validation loss: 2.6625801901663504

Epoch: 5| Step: 2
Training loss: 2.8766417503356934
Validation loss: 2.6575653963191535

Epoch: 5| Step: 3
Training loss: 2.879120349884033
Validation loss: 2.653005956321634

Epoch: 5| Step: 4
Training loss: 2.6545867919921875
Validation loss: 2.6481927441012476

Epoch: 5| Step: 5
Training loss: 3.3732879161834717
Validation loss: 2.644407226193336

Epoch: 5| Step: 6
Training loss: 2.3626725673675537
Validation loss: 2.6406042242562897

Epoch: 5| Step: 7
Training loss: 3.2266979217529297
Validation loss: 2.6419840730646604

Epoch: 5| Step: 8
Training loss: 2.727180004119873
Validation loss: 2.6466638631718133

Epoch: 5| Step: 9
Training loss: 2.9419174194335938
Validation loss: 2.645019195413077

Epoch: 5| Step: 10
Training loss: 2.344757556915283
Validation loss: 2.64492690947748

Epoch: 18| Step: 0
Training loss: 1.7524805068969727
Validation loss: 2.640527679074195

Epoch: 5| Step: 1
Training loss: 3.364333391189575
Validation loss: 2.63970007434968

Epoch: 5| Step: 2
Training loss: 3.0226364135742188
Validation loss: 2.63806814019398

Epoch: 5| Step: 3
Training loss: 3.088956356048584
Validation loss: 2.6373078874362412

Epoch: 5| Step: 4
Training loss: 3.549164295196533
Validation loss: 2.635861345516738

Epoch: 5| Step: 5
Training loss: 2.4756648540496826
Validation loss: 2.6325483937417307

Epoch: 5| Step: 6
Training loss: 3.1481666564941406
Validation loss: 2.631480880962905

Epoch: 5| Step: 7
Training loss: 2.752619981765747
Validation loss: 2.6306878212959535

Epoch: 5| Step: 8
Training loss: 2.187427043914795
Validation loss: 2.6283321149887575

Epoch: 5| Step: 9
Training loss: 2.986704111099243
Validation loss: 2.6278230656859694

Epoch: 5| Step: 10
Training loss: 2.7416868209838867
Validation loss: 2.629687342592465

Epoch: 19| Step: 0
Training loss: 2.5939011573791504
Validation loss: 2.6342666354230655

Epoch: 5| Step: 1
Training loss: 2.348154067993164
Validation loss: 2.637697878704276

Epoch: 5| Step: 2
Training loss: 3.2882072925567627
Validation loss: 2.6384555037303636

Epoch: 5| Step: 3
Training loss: 2.7160613536834717
Validation loss: 2.623737104477421

Epoch: 5| Step: 4
Training loss: 2.649961471557617
Validation loss: 2.6295037269592285

Epoch: 5| Step: 5
Training loss: 2.841704845428467
Validation loss: 2.6236961733910347

Epoch: 5| Step: 6
Training loss: 3.156217336654663
Validation loss: 2.6310331077985865

Epoch: 5| Step: 7
Training loss: 2.333538293838501
Validation loss: 2.6237968629406345

Epoch: 5| Step: 8
Training loss: 3.108285665512085
Validation loss: 2.622272824728361

Epoch: 5| Step: 9
Training loss: 2.9801342487335205
Validation loss: 2.618064284324646

Epoch: 5| Step: 10
Training loss: 3.0405220985412598
Validation loss: 2.6189542995986117

Epoch: 20| Step: 0
Training loss: 3.6019420623779297
Validation loss: 2.6171311101605816

Epoch: 5| Step: 1
Training loss: 1.8634593486785889
Validation loss: 2.6127458080168693

Epoch: 5| Step: 2
Training loss: 1.9393949508666992
Validation loss: 2.619345680359871

Epoch: 5| Step: 3
Training loss: 3.2105495929718018
Validation loss: 2.6450229383284047

Epoch: 5| Step: 4
Training loss: 2.704230546951294
Validation loss: 2.6272036952357136

Epoch: 5| Step: 5
Training loss: 2.399979829788208
Validation loss: 2.6049801047130297

Epoch: 5| Step: 6
Training loss: 3.486790180206299
Validation loss: 2.605321838009742

Epoch: 5| Step: 7
Training loss: 2.751415729522705
Validation loss: 2.6160806609738256

Epoch: 5| Step: 8
Training loss: 3.0381999015808105
Validation loss: 2.6208010001849105

Epoch: 5| Step: 9
Training loss: 3.111233949661255
Validation loss: 2.625949041817778

Epoch: 5| Step: 10
Training loss: 2.847968578338623
Validation loss: 2.623428460090391

Epoch: 21| Step: 0
Training loss: 3.141846179962158
Validation loss: 2.6275664350037933

Epoch: 5| Step: 1
Training loss: 3.138969898223877
Validation loss: 2.624410219089959

Epoch: 5| Step: 2
Training loss: 2.8594954013824463
Validation loss: 2.627227939585204

Epoch: 5| Step: 3
Training loss: 2.5811104774475098
Validation loss: 2.6221782622798795

Epoch: 5| Step: 4
Training loss: 2.9987571239471436
Validation loss: 2.624098895698465

Epoch: 5| Step: 5
Training loss: 1.9453868865966797
Validation loss: 2.5914328136751728

Epoch: 5| Step: 6
Training loss: 2.567539930343628
Validation loss: 2.5832797173530824

Epoch: 5| Step: 7
Training loss: 3.3263351917266846
Validation loss: 2.5800017131272184

Epoch: 5| Step: 8
Training loss: 3.227536678314209
Validation loss: 2.583618276862688

Epoch: 5| Step: 9
Training loss: 2.602081775665283
Validation loss: 2.585952558825093

Epoch: 5| Step: 10
Training loss: 2.3613178730010986
Validation loss: 2.5814890707692792

Epoch: 22| Step: 0
Training loss: 2.3514466285705566
Validation loss: 2.604204354747649

Epoch: 5| Step: 1
Training loss: 3.6100311279296875
Validation loss: 2.7087147492234425

Epoch: 5| Step: 2
Training loss: 3.0261170864105225
Validation loss: 2.7674020567247943

Epoch: 5| Step: 3
Training loss: 2.410047769546509
Validation loss: 2.6909127825049945

Epoch: 5| Step: 4
Training loss: 2.2209415435791016
Validation loss: 2.6258917982860277

Epoch: 5| Step: 5
Training loss: 2.3375909328460693
Validation loss: 2.584705650165517

Epoch: 5| Step: 6
Training loss: 2.7747702598571777
Validation loss: 2.557683567846975

Epoch: 5| Step: 7
Training loss: 3.1349925994873047
Validation loss: 2.5547415620537213

Epoch: 5| Step: 8
Training loss: 3.093247652053833
Validation loss: 2.552012130778323

Epoch: 5| Step: 9
Training loss: 2.749028444290161
Validation loss: 2.5541106577842467

Epoch: 5| Step: 10
Training loss: 3.149019241333008
Validation loss: 2.5518750247134956

Epoch: 23| Step: 0
Training loss: 2.654905080795288
Validation loss: 2.5457051184869584

Epoch: 5| Step: 1
Training loss: 3.0492501258850098
Validation loss: 2.5407035632800032

Epoch: 5| Step: 2
Training loss: 2.845585346221924
Validation loss: 2.5432652145303707

Epoch: 5| Step: 3
Training loss: 2.9347286224365234
Validation loss: 2.5625577536962365

Epoch: 5| Step: 4
Training loss: 2.5496466159820557
Validation loss: 2.5520786341800483

Epoch: 5| Step: 5
Training loss: 2.56355619430542
Validation loss: 2.5482679028664865

Epoch: 5| Step: 6
Training loss: 3.1857521533966064
Validation loss: 2.542989851326071

Epoch: 5| Step: 7
Training loss: 2.5460877418518066
Validation loss: 2.547381129316104

Epoch: 5| Step: 8
Training loss: 2.974862575531006
Validation loss: 2.55856421942352

Epoch: 5| Step: 9
Training loss: 2.5810935497283936
Validation loss: 2.551434709179786

Epoch: 5| Step: 10
Training loss: 2.6265532970428467
Validation loss: 2.5363891534907843

Epoch: 24| Step: 0
Training loss: 3.19722580909729
Validation loss: 2.5331601327465427

Epoch: 5| Step: 1
Training loss: 2.8785319328308105
Validation loss: 2.533934239418276

Epoch: 5| Step: 2
Training loss: 2.357027769088745
Validation loss: 2.5372639574030393

Epoch: 5| Step: 3
Training loss: 2.655179738998413
Validation loss: 2.5396029769733386

Epoch: 5| Step: 4
Training loss: 2.9609408378601074
Validation loss: 2.5555491062902633

Epoch: 5| Step: 5
Training loss: 2.8117549419403076
Validation loss: 2.572634204741447

Epoch: 5| Step: 6
Training loss: 2.7543411254882812
Validation loss: 2.5585324225887174

Epoch: 5| Step: 7
Training loss: 2.406609535217285
Validation loss: 2.5210674501234487

Epoch: 5| Step: 8
Training loss: 2.5751562118530273
Validation loss: 2.5262990382409867

Epoch: 5| Step: 9
Training loss: 2.7343945503234863
Validation loss: 2.5419100638358825

Epoch: 5| Step: 10
Training loss: 3.1970295906066895
Validation loss: 2.5600060237351285

Epoch: 25| Step: 0
Training loss: 3.1402759552001953
Validation loss: 2.570882499858897

Epoch: 5| Step: 1
Training loss: 3.3272979259490967
Validation loss: 2.5639036445207495

Epoch: 5| Step: 2
Training loss: 2.908355712890625
Validation loss: 2.5481689822289253

Epoch: 5| Step: 3
Training loss: 1.8875446319580078
Validation loss: 2.536681446977841

Epoch: 5| Step: 4
Training loss: 2.396535873413086
Validation loss: 2.5364165665000997

Epoch: 5| Step: 5
Training loss: 3.237941265106201
Validation loss: 2.5612405602649977

Epoch: 5| Step: 6
Training loss: 2.8387396335601807
Validation loss: 2.5708712506037887

Epoch: 5| Step: 7
Training loss: 2.141343593597412
Validation loss: 2.5655382089717413

Epoch: 5| Step: 8
Training loss: 2.6928794384002686
Validation loss: 2.5507289068673247

Epoch: 5| Step: 9
Training loss: 3.307962417602539
Validation loss: 2.5409739120032198

Epoch: 5| Step: 10
Training loss: 2.6844558715820312
Validation loss: 2.5318864648060133

Epoch: 26| Step: 0
Training loss: 2.8903746604919434
Validation loss: 2.5360426851498183

Epoch: 5| Step: 1
Training loss: 2.090458393096924
Validation loss: 2.5411070956978747

Epoch: 5| Step: 2
Training loss: 2.2962982654571533
Validation loss: 2.540326902943273

Epoch: 5| Step: 3
Training loss: 2.92950177192688
Validation loss: 2.515698949495951

Epoch: 5| Step: 4
Training loss: 3.060412645339966
Validation loss: 2.509989235990791

Epoch: 5| Step: 5
Training loss: 3.2244694232940674
Validation loss: 2.514079988643687

Epoch: 5| Step: 6
Training loss: 2.8778693675994873
Validation loss: 2.5165264427020984

Epoch: 5| Step: 7
Training loss: 2.5181851387023926
Validation loss: 2.522599451003536

Epoch: 5| Step: 8
Training loss: 2.7344248294830322
Validation loss: 2.5153590940660044

Epoch: 5| Step: 9
Training loss: 2.7579901218414307
Validation loss: 2.5071516600988244

Epoch: 5| Step: 10
Training loss: 2.904906749725342
Validation loss: 2.506731210216399

Epoch: 27| Step: 0
Training loss: 3.2282042503356934
Validation loss: 2.5062598182309057

Epoch: 5| Step: 1
Training loss: 2.524916648864746
Validation loss: 2.51062786194586

Epoch: 5| Step: 2
Training loss: 2.015049934387207
Validation loss: 2.5274272195754515

Epoch: 5| Step: 3
Training loss: 3.2846438884735107
Validation loss: 2.5581201917381695

Epoch: 5| Step: 4
Training loss: 2.56166410446167
Validation loss: 2.5522037424067014

Epoch: 5| Step: 5
Training loss: 2.8089146614074707
Validation loss: 2.5183373112832346

Epoch: 5| Step: 6
Training loss: 3.4683241844177246
Validation loss: 2.50680600443194

Epoch: 5| Step: 7
Training loss: 2.938420057296753
Validation loss: 2.5007171400131716

Epoch: 5| Step: 8
Training loss: 2.741046905517578
Validation loss: 2.4997683801958637

Epoch: 5| Step: 9
Training loss: 1.9278520345687866
Validation loss: 2.500553946341238

Epoch: 5| Step: 10
Training loss: 2.6706597805023193
Validation loss: 2.498695071025561

Epoch: 28| Step: 0
Training loss: 2.6282167434692383
Validation loss: 2.4975411635573193

Epoch: 5| Step: 1
Training loss: 1.905118703842163
Validation loss: 2.4929194129923338

Epoch: 5| Step: 2
Training loss: 2.6185145378112793
Validation loss: 2.4952078301419496

Epoch: 5| Step: 3
Training loss: 3.1300549507141113
Validation loss: 2.4963634167948077

Epoch: 5| Step: 4
Training loss: 2.4553635120391846
Validation loss: 2.5154729350920646

Epoch: 5| Step: 5
Training loss: 3.057969570159912
Validation loss: 2.5310337056395826

Epoch: 5| Step: 6
Training loss: 2.5660626888275146
Validation loss: 2.5298209882551626

Epoch: 5| Step: 7
Training loss: 3.1192615032196045
Validation loss: 2.5220407811544274

Epoch: 5| Step: 8
Training loss: 2.922929525375366
Validation loss: 2.5137644249905824

Epoch: 5| Step: 9
Training loss: 2.7096056938171387
Validation loss: 2.4937023321787515

Epoch: 5| Step: 10
Training loss: 2.94598126411438
Validation loss: 2.4811846722838697

Epoch: 29| Step: 0
Training loss: 2.821141004562378
Validation loss: 2.4840462925613567

Epoch: 5| Step: 1
Training loss: 3.044285774230957
Validation loss: 2.488688994479436

Epoch: 5| Step: 2
Training loss: 2.5356783866882324
Validation loss: 2.485157400049189

Epoch: 5| Step: 3
Training loss: 2.683612823486328
Validation loss: 2.482095421001475

Epoch: 5| Step: 4
Training loss: 2.272099256515503
Validation loss: 2.4812113931102138

Epoch: 5| Step: 5
Training loss: 2.7218880653381348
Validation loss: 2.474393601058632

Epoch: 5| Step: 6
Training loss: 2.7707526683807373
Validation loss: 2.4745938175468036

Epoch: 5| Step: 7
Training loss: 2.649444580078125
Validation loss: 2.485605255250008

Epoch: 5| Step: 8
Training loss: 2.995668411254883
Validation loss: 2.4996255802851852

Epoch: 5| Step: 9
Training loss: 2.6700832843780518
Validation loss: 2.506948814597181

Epoch: 5| Step: 10
Training loss: 2.676877975463867
Validation loss: 2.5236713424805672

Epoch: 30| Step: 0
Training loss: 2.9779796600341797
Validation loss: 2.505706279508529

Epoch: 5| Step: 1
Training loss: 2.9762237071990967
Validation loss: 2.4917302618744555

Epoch: 5| Step: 2
Training loss: 2.3316879272460938
Validation loss: 2.4668983720964

Epoch: 5| Step: 3
Training loss: 3.271080493927002
Validation loss: 2.465412019401468

Epoch: 5| Step: 4
Training loss: 1.9196525812149048
Validation loss: 2.461210089345132

Epoch: 5| Step: 5
Training loss: 2.4014644622802734
Validation loss: 2.457849751236618

Epoch: 5| Step: 6
Training loss: 2.439423084259033
Validation loss: 2.4616532274471816

Epoch: 5| Step: 7
Training loss: 2.88911771774292
Validation loss: 2.458206463885564

Epoch: 5| Step: 8
Training loss: 2.7365665435791016
Validation loss: 2.4565452580810874

Epoch: 5| Step: 9
Training loss: 3.081904888153076
Validation loss: 2.4549523938086724

Epoch: 5| Step: 10
Training loss: 2.6398003101348877
Validation loss: 2.4606378539916007

Epoch: 31| Step: 0
Training loss: 3.1501240730285645
Validation loss: 2.4712311478071314

Epoch: 5| Step: 1
Training loss: 2.3277788162231445
Validation loss: 2.494512468255976

Epoch: 5| Step: 2
Training loss: 2.567720890045166
Validation loss: 2.4987654301428024

Epoch: 5| Step: 3
Training loss: 2.8821892738342285
Validation loss: 2.4948193232218423

Epoch: 5| Step: 4
Training loss: 2.2768139839172363
Validation loss: 2.4993634403392835

Epoch: 5| Step: 5
Training loss: 2.47786283493042
Validation loss: 2.4890959442302747

Epoch: 5| Step: 6
Training loss: 2.467045545578003
Validation loss: 2.474409270030196

Epoch: 5| Step: 7
Training loss: 2.937983274459839
Validation loss: 2.4723792332474903

Epoch: 5| Step: 8
Training loss: 2.7446374893188477
Validation loss: 2.4652121425956808

Epoch: 5| Step: 9
Training loss: 2.805216073989868
Validation loss: 2.4648602521547707

Epoch: 5| Step: 10
Training loss: 3.1470067501068115
Validation loss: 2.4592516345362507

Epoch: 32| Step: 0
Training loss: 3.2167739868164062
Validation loss: 2.4547758307508243

Epoch: 5| Step: 1
Training loss: 2.585453987121582
Validation loss: 2.447151432755173

Epoch: 5| Step: 2
Training loss: 2.6501622200012207
Validation loss: 2.443587451852778

Epoch: 5| Step: 3
Training loss: 2.86370849609375
Validation loss: 2.442236510656213

Epoch: 5| Step: 4
Training loss: 2.295419216156006
Validation loss: 2.4421403715687413

Epoch: 5| Step: 5
Training loss: 2.638566255569458
Validation loss: 2.449911335463165

Epoch: 5| Step: 6
Training loss: 2.484726905822754
Validation loss: 2.458011955343267

Epoch: 5| Step: 7
Training loss: 2.3213562965393066
Validation loss: 2.46795904508201

Epoch: 5| Step: 8
Training loss: 2.5738983154296875
Validation loss: 2.4690277217536845

Epoch: 5| Step: 9
Training loss: 3.0144600868225098
Validation loss: 2.4720590140229914

Epoch: 5| Step: 10
Training loss: 2.9077773094177246
Validation loss: 2.4651336516103437

Epoch: 33| Step: 0
Training loss: 2.9004921913146973
Validation loss: 2.4485254210810505

Epoch: 5| Step: 1
Training loss: 3.5396652221679688
Validation loss: 2.4405858901239212

Epoch: 5| Step: 2
Training loss: 2.531492233276367
Validation loss: 2.4365774072626585

Epoch: 5| Step: 3
Training loss: 2.798335313796997
Validation loss: 2.434754858734787

Epoch: 5| Step: 4
Training loss: 2.187002658843994
Validation loss: 2.4403856697902886

Epoch: 5| Step: 5
Training loss: 2.3952431678771973
Validation loss: 2.440543600307998

Epoch: 5| Step: 6
Training loss: 2.7094528675079346
Validation loss: 2.44635909347124

Epoch: 5| Step: 7
Training loss: 2.7598659992218018
Validation loss: 2.4586126599260556

Epoch: 5| Step: 8
Training loss: 3.04506254196167
Validation loss: 2.47590555426895

Epoch: 5| Step: 9
Training loss: 2.191251277923584
Validation loss: 2.4777778681888374

Epoch: 5| Step: 10
Training loss: 2.29009747505188
Validation loss: 2.4739074604485625

Epoch: 34| Step: 0
Training loss: 2.6883740425109863
Validation loss: 2.45296916397669

Epoch: 5| Step: 1
Training loss: 2.4071459770202637
Validation loss: 2.4280073488912275

Epoch: 5| Step: 2
Training loss: 3.146334171295166
Validation loss: 2.4259136620388237

Epoch: 5| Step: 3
Training loss: 2.6283020973205566
Validation loss: 2.430504696343535

Epoch: 5| Step: 4
Training loss: 2.4289612770080566
Validation loss: 2.4404077299179567

Epoch: 5| Step: 5
Training loss: 2.820646286010742
Validation loss: 2.444620068355273

Epoch: 5| Step: 6
Training loss: 2.1218221187591553
Validation loss: 2.4342705562550533

Epoch: 5| Step: 7
Training loss: 2.903658866882324
Validation loss: 2.4320562219107025

Epoch: 5| Step: 8
Training loss: 2.7339119911193848
Validation loss: 2.4254976575092604

Epoch: 5| Step: 9
Training loss: 2.6480631828308105
Validation loss: 2.4240704198037424

Epoch: 5| Step: 10
Training loss: 3.183345079421997
Validation loss: 2.417693045831496

Epoch: 35| Step: 0
Training loss: 3.2685179710388184
Validation loss: 2.418300005697435

Epoch: 5| Step: 1
Training loss: 2.35691237449646
Validation loss: 2.435099947837091

Epoch: 5| Step: 2
Training loss: 2.9728891849517822
Validation loss: 2.4447672315823135

Epoch: 5| Step: 3
Training loss: 2.227607488632202
Validation loss: 2.4647237434182117

Epoch: 5| Step: 4
Training loss: 2.6456313133239746
Validation loss: 2.474727543451453

Epoch: 5| Step: 5
Training loss: 2.4922940731048584
Validation loss: 2.4436374146451234

Epoch: 5| Step: 6
Training loss: 2.78566837310791
Validation loss: 2.428336610076248

Epoch: 5| Step: 7
Training loss: 2.2019526958465576
Validation loss: 2.425074303021995

Epoch: 5| Step: 8
Training loss: 3.3242034912109375
Validation loss: 2.425608660585137

Epoch: 5| Step: 9
Training loss: 2.4172921180725098
Validation loss: 2.423074014725224

Epoch: 5| Step: 10
Training loss: 2.724916458129883
Validation loss: 2.42216690381368

Epoch: 36| Step: 0
Training loss: 2.695220470428467
Validation loss: 2.43215182007

Epoch: 5| Step: 1
Training loss: 2.3200645446777344
Validation loss: 2.4458989430499334

Epoch: 5| Step: 2
Training loss: 2.1504197120666504
Validation loss: 2.461727347425235

Epoch: 5| Step: 3
Training loss: 2.6621673107147217
Validation loss: 2.470787189340079

Epoch: 5| Step: 4
Training loss: 2.5974690914154053
Validation loss: 2.4775091243046585

Epoch: 5| Step: 5
Training loss: 2.94938063621521
Validation loss: 2.4644195854022937

Epoch: 5| Step: 6
Training loss: 2.52423095703125
Validation loss: 2.4280517793470815

Epoch: 5| Step: 7
Training loss: 3.057579517364502
Validation loss: 2.4198251360206195

Epoch: 5| Step: 8
Training loss: 2.5975112915039062
Validation loss: 2.4118827209677747

Epoch: 5| Step: 9
Training loss: 2.324172258377075
Validation loss: 2.4075415442066808

Epoch: 5| Step: 10
Training loss: 3.585347890853882
Validation loss: 2.4080352193565777

Epoch: 37| Step: 0
Training loss: 3.2988574504852295
Validation loss: 2.409778384752171

Epoch: 5| Step: 1
Training loss: 2.8877317905426025
Validation loss: 2.408108739442723

Epoch: 5| Step: 2
Training loss: 2.25093150138855
Validation loss: 2.4118625335795905

Epoch: 5| Step: 3
Training loss: 2.212172031402588
Validation loss: 2.4182728336703394

Epoch: 5| Step: 4
Training loss: 2.078463077545166
Validation loss: 2.4287896925403225

Epoch: 5| Step: 5
Training loss: 3.212212085723877
Validation loss: 2.494617695449501

Epoch: 5| Step: 6
Training loss: 3.1124463081359863
Validation loss: 2.505138063943514

Epoch: 5| Step: 7
Training loss: 2.4326720237731934
Validation loss: 2.48794323654585

Epoch: 5| Step: 8
Training loss: 2.1519689559936523
Validation loss: 2.456528017597814

Epoch: 5| Step: 9
Training loss: 2.5072968006134033
Validation loss: 2.4497373437368744

Epoch: 5| Step: 10
Training loss: 3.3337807655334473
Validation loss: 2.458971510651291

Epoch: 38| Step: 0
Training loss: 3.3002243041992188
Validation loss: 2.4655514686338362

Epoch: 5| Step: 1
Training loss: 1.8468021154403687
Validation loss: 2.456067633885209

Epoch: 5| Step: 2
Training loss: 2.4967703819274902
Validation loss: 2.4402316257517827

Epoch: 5| Step: 3
Training loss: 2.6988377571105957
Validation loss: 2.4182257062645367

Epoch: 5| Step: 4
Training loss: 3.064591884613037
Validation loss: 2.407168144820839

Epoch: 5| Step: 5
Training loss: 3.2644190788269043
Validation loss: 2.4045877610483477

Epoch: 5| Step: 6
Training loss: 2.462268829345703
Validation loss: 2.407999489897041

Epoch: 5| Step: 7
Training loss: 2.23183274269104
Validation loss: 2.3992356792573006

Epoch: 5| Step: 8
Training loss: 2.642090320587158
Validation loss: 2.402411486512871

Epoch: 5| Step: 9
Training loss: 2.267936944961548
Validation loss: 2.4058617161166285

Epoch: 5| Step: 10
Training loss: 3.0010159015655518
Validation loss: 2.402915390588904

Epoch: 39| Step: 0
Training loss: 1.5445706844329834
Validation loss: 2.413639724895518

Epoch: 5| Step: 1
Training loss: 2.6246821880340576
Validation loss: 2.4227773874036727

Epoch: 5| Step: 2
Training loss: 2.5322232246398926
Validation loss: 2.4414634191861717

Epoch: 5| Step: 3
Training loss: 2.2940621376037598
Validation loss: 2.461142950160529

Epoch: 5| Step: 4
Training loss: 3.5188679695129395
Validation loss: 2.448417099573279

Epoch: 5| Step: 5
Training loss: 1.6091740131378174
Validation loss: 2.4230500267397974

Epoch: 5| Step: 6
Training loss: 3.0260303020477295
Validation loss: 2.413364456545922

Epoch: 5| Step: 7
Training loss: 3.0395255088806152
Validation loss: 2.405781801028918

Epoch: 5| Step: 8
Training loss: 3.0028374195098877
Validation loss: 2.4034222146516204

Epoch: 5| Step: 9
Training loss: 2.799560070037842
Validation loss: 2.3995747720041583

Epoch: 5| Step: 10
Training loss: 3.131927013397217
Validation loss: 2.4018538293018135

Epoch: 40| Step: 0
Training loss: 2.200601577758789
Validation loss: 2.4012510930338213

Epoch: 5| Step: 1
Training loss: 2.684654712677002
Validation loss: 2.3969465942792993

Epoch: 5| Step: 2
Training loss: 2.7693943977355957
Validation loss: 2.3965107804985455

Epoch: 5| Step: 3
Training loss: 3.356297016143799
Validation loss: 2.3913997911637828

Epoch: 5| Step: 4
Training loss: 2.2333407402038574
Validation loss: 2.390269943462905

Epoch: 5| Step: 5
Training loss: 2.555814266204834
Validation loss: 2.3952847552555863

Epoch: 5| Step: 6
Training loss: 2.707834243774414
Validation loss: 2.398470030036024

Epoch: 5| Step: 7
Training loss: 2.7092857360839844
Validation loss: 2.407617063932521

Epoch: 5| Step: 8
Training loss: 2.4372124671936035
Validation loss: 2.4240516411360873

Epoch: 5| Step: 9
Training loss: 2.593177318572998
Validation loss: 2.440996341807868

Epoch: 5| Step: 10
Training loss: 2.894205093383789
Validation loss: 2.4919538703016055

Epoch: 41| Step: 0
Training loss: 2.755056142807007
Validation loss: 2.4967028735786356

Epoch: 5| Step: 1
Training loss: 2.0516486167907715
Validation loss: 2.5007268613384617

Epoch: 5| Step: 2
Training loss: 2.8713340759277344
Validation loss: 2.510905155571558

Epoch: 5| Step: 3
Training loss: 2.709385871887207
Validation loss: 2.4930611477103284

Epoch: 5| Step: 4
Training loss: 3.1674983501434326
Validation loss: 2.438973460146176

Epoch: 5| Step: 5
Training loss: 2.3706088066101074
Validation loss: 2.3935383994092225

Epoch: 5| Step: 6
Training loss: 3.005798816680908
Validation loss: 2.3838443704830703

Epoch: 5| Step: 7
Training loss: 2.6868643760681152
Validation loss: 2.3859842874670543

Epoch: 5| Step: 8
Training loss: 2.357645034790039
Validation loss: 2.3874232435739167

Epoch: 5| Step: 9
Training loss: 2.395310878753662
Validation loss: 2.3888481047845658

Epoch: 5| Step: 10
Training loss: 2.770536422729492
Validation loss: 2.39672242441485

Epoch: 42| Step: 0
Training loss: 2.6498234272003174
Validation loss: 2.3991899131446757

Epoch: 5| Step: 1
Training loss: 2.726372718811035
Validation loss: 2.403072134140999

Epoch: 5| Step: 2
Training loss: 2.240907669067383
Validation loss: 2.407291482853633

Epoch: 5| Step: 3
Training loss: 2.2200052738189697
Validation loss: 2.405044114717873

Epoch: 5| Step: 4
Training loss: 2.4330432415008545
Validation loss: 2.4132850798227454

Epoch: 5| Step: 5
Training loss: 2.7722225189208984
Validation loss: 2.4176004830227105

Epoch: 5| Step: 6
Training loss: 2.5828168392181396
Validation loss: 2.442239663934195

Epoch: 5| Step: 7
Training loss: 3.0141210556030273
Validation loss: 2.4513243603449997

Epoch: 5| Step: 8
Training loss: 2.6229307651519775
Validation loss: 2.423067726114745

Epoch: 5| Step: 9
Training loss: 2.5859999656677246
Validation loss: 2.3945713735395864

Epoch: 5| Step: 10
Training loss: 3.553621292114258
Validation loss: 2.386920661054632

Epoch: 43| Step: 0
Training loss: 2.0741465091705322
Validation loss: 2.3867198087835826

Epoch: 5| Step: 1
Training loss: 2.9988930225372314
Validation loss: 2.3838996015569216

Epoch: 5| Step: 2
Training loss: 2.5805060863494873
Validation loss: 2.3820045468627766

Epoch: 5| Step: 3
Training loss: 2.58396053314209
Validation loss: 2.3805792049695085

Epoch: 5| Step: 4
Training loss: 2.778179883956909
Validation loss: 2.3828441686527704

Epoch: 5| Step: 5
Training loss: 2.462597370147705
Validation loss: 2.375434096141528

Epoch: 5| Step: 6
Training loss: 3.0578575134277344
Validation loss: 2.3827796623271

Epoch: 5| Step: 7
Training loss: 2.309791088104248
Validation loss: 2.4077541853791926

Epoch: 5| Step: 8
Training loss: 2.8651511669158936
Validation loss: 2.396487215513824

Epoch: 5| Step: 9
Training loss: 2.318502187728882
Validation loss: 2.3969005820571736

Epoch: 5| Step: 10
Training loss: 2.9218902587890625
Validation loss: 2.4121377083563034

Epoch: 44| Step: 0
Training loss: 2.459937572479248
Validation loss: 2.423067198004774

Epoch: 5| Step: 1
Training loss: 3.018188953399658
Validation loss: 2.4370964624548472

Epoch: 5| Step: 2
Training loss: 2.5301437377929688
Validation loss: 2.4282799818182506

Epoch: 5| Step: 3
Training loss: 2.6925716400146484
Validation loss: 2.40448175450807

Epoch: 5| Step: 4
Training loss: 3.227724552154541
Validation loss: 2.387277639040383

Epoch: 5| Step: 5
Training loss: 2.3785903453826904
Validation loss: 2.373497046450133

Epoch: 5| Step: 6
Training loss: 2.158238172531128
Validation loss: 2.370922580842049

Epoch: 5| Step: 7
Training loss: 2.3219871520996094
Validation loss: 2.3707116496178413

Epoch: 5| Step: 8
Training loss: 2.64223051071167
Validation loss: 2.37527326614626

Epoch: 5| Step: 9
Training loss: 2.594701051712036
Validation loss: 2.3772102017556467

Epoch: 5| Step: 10
Training loss: 2.866417169570923
Validation loss: 2.3731804996408443

Epoch: 45| Step: 0
Training loss: 2.6818594932556152
Validation loss: 2.365759834166496

Epoch: 5| Step: 1
Training loss: 3.2669684886932373
Validation loss: 2.3813153543779926

Epoch: 5| Step: 2
Training loss: 2.5411148071289062
Validation loss: 2.406128773125269

Epoch: 5| Step: 3
Training loss: 2.8887150287628174
Validation loss: 2.4530087901699926

Epoch: 5| Step: 4
Training loss: 2.289977550506592
Validation loss: 2.4857335193182832

Epoch: 5| Step: 5
Training loss: 2.3979756832122803
Validation loss: 2.4825159580476823

Epoch: 5| Step: 6
Training loss: 2.15520977973938
Validation loss: 2.412853064075593

Epoch: 5| Step: 7
Training loss: 2.6426849365234375
Validation loss: 2.377375723213278

Epoch: 5| Step: 8
Training loss: 2.3220694065093994
Validation loss: 2.361480459090202

Epoch: 5| Step: 9
Training loss: 2.55161452293396
Validation loss: 2.363856065657831

Epoch: 5| Step: 10
Training loss: 3.1779754161834717
Validation loss: 2.3831494136523177

Epoch: 46| Step: 0
Training loss: 2.2693846225738525
Validation loss: 2.3851200380632953

Epoch: 5| Step: 1
Training loss: 2.5787193775177
Validation loss: 2.4030354663889897

Epoch: 5| Step: 2
Training loss: 3.1228699684143066
Validation loss: 2.4034844034461567

Epoch: 5| Step: 3
Training loss: 2.1633918285369873
Validation loss: 2.405278464799286

Epoch: 5| Step: 4
Training loss: 2.586940288543701
Validation loss: 2.4161188756265948

Epoch: 5| Step: 5
Training loss: 2.644638776779175
Validation loss: 2.4062867805521977

Epoch: 5| Step: 6
Training loss: 3.2133917808532715
Validation loss: 2.399788692433347

Epoch: 5| Step: 7
Training loss: 2.2082886695861816
Validation loss: 2.398138033446445

Epoch: 5| Step: 8
Training loss: 2.530259609222412
Validation loss: 2.4076818163676927

Epoch: 5| Step: 9
Training loss: 2.954824924468994
Validation loss: 2.406976448592319

Epoch: 5| Step: 10
Training loss: 2.794355869293213
Validation loss: 2.41253601607456

Epoch: 47| Step: 0
Training loss: 2.4674429893493652
Validation loss: 2.433753111029184

Epoch: 5| Step: 1
Training loss: 2.706347942352295
Validation loss: 2.4481350734669673

Epoch: 5| Step: 2
Training loss: 2.998839855194092
Validation loss: 2.463542656231952

Epoch: 5| Step: 3
Training loss: 2.4661309719085693
Validation loss: 2.4242274094653387

Epoch: 5| Step: 4
Training loss: 2.97458553314209
Validation loss: 2.41137892969193

Epoch: 5| Step: 5
Training loss: 1.976461410522461
Validation loss: 2.396648771019392

Epoch: 5| Step: 6
Training loss: 2.3632707595825195
Validation loss: 2.38386546668186

Epoch: 5| Step: 7
Training loss: 2.4968364238739014
Validation loss: 2.3782291412353516

Epoch: 5| Step: 8
Training loss: 2.8063149452209473
Validation loss: 2.3728003283982635

Epoch: 5| Step: 9
Training loss: 3.1072580814361572
Validation loss: 2.374916094605641

Epoch: 5| Step: 10
Training loss: 2.660106897354126
Validation loss: 2.369151341017856

Epoch: 48| Step: 0
Training loss: 1.974457025527954
Validation loss: 2.3687146273992394

Epoch: 5| Step: 1
Training loss: 2.430259943008423
Validation loss: 2.370333963824857

Epoch: 5| Step: 2
Training loss: 2.7457363605499268
Validation loss: 2.3675491271480436

Epoch: 5| Step: 3
Training loss: 2.7110209465026855
Validation loss: 2.3670483443044845

Epoch: 5| Step: 4
Training loss: 2.7721762657165527
Validation loss: 2.3688996889257945

Epoch: 5| Step: 5
Training loss: 3.103428363800049
Validation loss: 2.367839296658834

Epoch: 5| Step: 6
Training loss: 2.278407573699951
Validation loss: 2.3694995551980953

Epoch: 5| Step: 7
Training loss: 2.647447347640991
Validation loss: 2.372389974132661

Epoch: 5| Step: 8
Training loss: 2.9582996368408203
Validation loss: 2.3833890525243615

Epoch: 5| Step: 9
Training loss: 2.6226131916046143
Validation loss: 2.3910522717301563

Epoch: 5| Step: 10
Training loss: 2.582329034805298
Validation loss: 2.404684423118509

Epoch: 49| Step: 0
Training loss: 2.3140344619750977
Validation loss: 2.425200805869154

Epoch: 5| Step: 1
Training loss: 2.5277581214904785
Validation loss: 2.437919191134873

Epoch: 5| Step: 2
Training loss: 2.696443796157837
Validation loss: 2.446957213904268

Epoch: 5| Step: 3
Training loss: 2.14229679107666
Validation loss: 2.468544416530158

Epoch: 5| Step: 4
Training loss: 2.490449905395508
Validation loss: 2.505121279788274

Epoch: 5| Step: 5
Training loss: 2.3417038917541504
Validation loss: 2.5050324970676052

Epoch: 5| Step: 6
Training loss: 2.613790988922119
Validation loss: 2.42966523221744

Epoch: 5| Step: 7
Training loss: 2.882174253463745
Validation loss: 2.384296435181813

Epoch: 5| Step: 8
Training loss: 2.8074533939361572
Validation loss: 2.364088373799478

Epoch: 5| Step: 9
Training loss: 3.408292055130005
Validation loss: 2.3607130435205277

Epoch: 5| Step: 10
Training loss: 2.838773012161255
Validation loss: 2.374368909866579

Epoch: 50| Step: 0
Training loss: 2.889681100845337
Validation loss: 2.376924309679257

Epoch: 5| Step: 1
Training loss: 2.416900873184204
Validation loss: 2.368918113811042

Epoch: 5| Step: 2
Training loss: 2.060652494430542
Validation loss: 2.369169132683867

Epoch: 5| Step: 3
Training loss: 2.816626787185669
Validation loss: 2.365130627027122

Epoch: 5| Step: 4
Training loss: 2.760291337966919
Validation loss: 2.3658527481940483

Epoch: 5| Step: 5
Training loss: 3.2645745277404785
Validation loss: 2.3597756406312347

Epoch: 5| Step: 6
Training loss: 2.8590376377105713
Validation loss: 2.3542289272431405

Epoch: 5| Step: 7
Training loss: 2.7233004570007324
Validation loss: 2.3579537894136164

Epoch: 5| Step: 8
Training loss: 2.4859683513641357
Validation loss: 2.3576886564172725

Epoch: 5| Step: 9
Training loss: 2.203575372695923
Validation loss: 2.364259030229302

Epoch: 5| Step: 10
Training loss: 2.380180597305298
Validation loss: 2.3822731946104314

Testing loss: 2.547940625084771
