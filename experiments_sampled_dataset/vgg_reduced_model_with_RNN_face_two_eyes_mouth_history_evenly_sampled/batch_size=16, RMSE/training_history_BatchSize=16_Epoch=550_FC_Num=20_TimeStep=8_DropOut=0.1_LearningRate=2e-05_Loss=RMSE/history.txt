Epoch: 1| Step: 0
Training loss: 6.098086648007025
Validation loss: 5.786643297210529

Epoch: 6| Step: 1
Training loss: 5.94745965149427
Validation loss: 5.76348732211144

Epoch: 6| Step: 2
Training loss: 5.76237747823415
Validation loss: 5.7419137402397356

Epoch: 6| Step: 3
Training loss: 5.886909588085333
Validation loss: 5.718647004263633

Epoch: 6| Step: 4
Training loss: 5.459795962143841
Validation loss: 5.692723382395293

Epoch: 6| Step: 5
Training loss: 4.9843436213256025
Validation loss: 5.662936620103601

Epoch: 6| Step: 6
Training loss: 5.62571542216903
Validation loss: 5.627984055500927

Epoch: 6| Step: 7
Training loss: 5.1224775852440905
Validation loss: 5.58814522287662

Epoch: 6| Step: 8
Training loss: 6.249589525095047
Validation loss: 5.543082498713281

Epoch: 6| Step: 9
Training loss: 5.714722262464675
Validation loss: 5.493386144890957

Epoch: 6| Step: 10
Training loss: 6.111194856628579
Validation loss: 5.438789969963789

Epoch: 6| Step: 11
Training loss: 4.574803315817847
Validation loss: 5.378447115781558

Epoch: 6| Step: 12
Training loss: 5.960757031589901
Validation loss: 5.313999035470379

Epoch: 6| Step: 13
Training loss: 4.213308484289877
Validation loss: 5.2464017437314645

Epoch: 2| Step: 0
Training loss: 5.95494071924537
Validation loss: 5.177341335494524

Epoch: 6| Step: 1
Training loss: 4.743003309988258
Validation loss: 5.105808206883143

Epoch: 6| Step: 2
Training loss: 3.943866003781839
Validation loss: 5.034951928763398

Epoch: 6| Step: 3
Training loss: 4.836765495743558
Validation loss: 4.965332732138056

Epoch: 6| Step: 4
Training loss: 4.297129786480212
Validation loss: 4.898267099767112

Epoch: 6| Step: 5
Training loss: 5.708645925757181
Validation loss: 4.833972839096424

Epoch: 6| Step: 6
Training loss: 5.152219549595246
Validation loss: 4.772136322045125

Epoch: 6| Step: 7
Training loss: 5.619241437117049
Validation loss: 4.713617967790145

Epoch: 6| Step: 8
Training loss: 5.523292636725246
Validation loss: 4.660737905161775

Epoch: 6| Step: 9
Training loss: 4.234885772641833
Validation loss: 4.61216675489709

Epoch: 6| Step: 10
Training loss: 4.463002810748064
Validation loss: 4.569758515587286

Epoch: 6| Step: 11
Training loss: 4.137034576146121
Validation loss: 4.529097923874619

Epoch: 6| Step: 12
Training loss: 4.271959680416987
Validation loss: 4.491232232191376

Epoch: 6| Step: 13
Training loss: 4.670232681914538
Validation loss: 4.454083785455277

Epoch: 3| Step: 0
Training loss: 4.47955424679733
Validation loss: 4.414184780026112

Epoch: 6| Step: 1
Training loss: 4.036928421047388
Validation loss: 4.372828093019929

Epoch: 6| Step: 2
Training loss: 4.472023145353034
Validation loss: 4.333675256653876

Epoch: 6| Step: 3
Training loss: 5.259274057109791
Validation loss: 4.301412452868265

Epoch: 6| Step: 4
Training loss: 5.422316651399289
Validation loss: 4.285570137883169

Epoch: 6| Step: 5
Training loss: 4.3964687569136185
Validation loss: 4.264583077709675

Epoch: 6| Step: 6
Training loss: 4.108222828914191
Validation loss: 4.242215811109713

Epoch: 6| Step: 7
Training loss: 4.431494719254141
Validation loss: 4.218331639288013

Epoch: 6| Step: 8
Training loss: 3.980883935121348
Validation loss: 4.19682843663042

Epoch: 6| Step: 9
Training loss: 3.37796596607976
Validation loss: 4.18248492425903

Epoch: 6| Step: 10
Training loss: 3.865379203561935
Validation loss: 4.171595508565601

Epoch: 6| Step: 11
Training loss: 3.8371207282803126
Validation loss: 4.158548925026964

Epoch: 6| Step: 12
Training loss: 5.018552692188016
Validation loss: 4.14497946887114

Epoch: 6| Step: 13
Training loss: 4.013885477512645
Validation loss: 4.129476795938559

Epoch: 4| Step: 0
Training loss: 5.517597829057737
Validation loss: 4.116867184663761

Epoch: 6| Step: 1
Training loss: 4.512295772760153
Validation loss: 4.103820905315347

Epoch: 6| Step: 2
Training loss: 4.323392739183161
Validation loss: 4.096470300750957

Epoch: 6| Step: 3
Training loss: 4.693340274487767
Validation loss: 4.07779452472747

Epoch: 6| Step: 4
Training loss: 4.148721171592415
Validation loss: 4.06296016210455

Epoch: 6| Step: 5
Training loss: 3.327560018661633
Validation loss: 4.049011685047319

Epoch: 6| Step: 6
Training loss: 2.7527210471830843
Validation loss: 4.035971035899252

Epoch: 6| Step: 7
Training loss: 4.053791277849075
Validation loss: 4.026039585295049

Epoch: 6| Step: 8
Training loss: 4.727277919126207
Validation loss: 4.013181752394963

Epoch: 6| Step: 9
Training loss: 3.7650639919400204
Validation loss: 4.001852972754416

Epoch: 6| Step: 10
Training loss: 3.9814238745360417
Validation loss: 3.9890775091873474

Epoch: 6| Step: 11
Training loss: 3.1653356933949173
Validation loss: 3.9765144266425634

Epoch: 6| Step: 12
Training loss: 4.961298507411006
Validation loss: 3.968102197259565

Epoch: 6| Step: 13
Training loss: 3.6655170343471815
Validation loss: 3.9555148199525703

Epoch: 5| Step: 0
Training loss: 3.9746204123004
Validation loss: 3.9465219023817077

Epoch: 6| Step: 1
Training loss: 4.114251206268432
Validation loss: 3.940097275811497

Epoch: 6| Step: 2
Training loss: 4.925910385338902
Validation loss: 3.928094443823538

Epoch: 6| Step: 3
Training loss: 3.7346569258120117
Validation loss: 3.914812019809856

Epoch: 6| Step: 4
Training loss: 4.30773817682473
Validation loss: 3.9068720654087885

Epoch: 6| Step: 5
Training loss: 4.166272004827924
Validation loss: 3.8949330721903466

Epoch: 6| Step: 6
Training loss: 4.325104799268822
Validation loss: 3.8839224110886916

Epoch: 6| Step: 7
Training loss: 3.295285243884361
Validation loss: 3.8711994042858393

Epoch: 6| Step: 8
Training loss: 4.645561495413231
Validation loss: 3.861271735926275

Epoch: 6| Step: 9
Training loss: 3.9466149323741324
Validation loss: 3.852265228779505

Epoch: 6| Step: 10
Training loss: 3.9410187272713655
Validation loss: 3.8425256470073923

Epoch: 6| Step: 11
Training loss: 3.883510595922846
Validation loss: 3.8310449911623468

Epoch: 6| Step: 12
Training loss: 3.9276983182628307
Validation loss: 3.823775013210257

Epoch: 6| Step: 13
Training loss: 2.2919394475251362
Validation loss: 3.8138247991698253

Epoch: 6| Step: 0
Training loss: 4.397818215173398
Validation loss: 3.807195420362615

Epoch: 6| Step: 1
Training loss: 3.6078109985718507
Validation loss: 3.799013798798304

Epoch: 6| Step: 2
Training loss: 4.040721087924826
Validation loss: 3.790788355188398

Epoch: 6| Step: 3
Training loss: 4.275786763568755
Validation loss: 3.7842327229742594

Epoch: 6| Step: 4
Training loss: 4.017989475553561
Validation loss: 3.7746684350859123

Epoch: 6| Step: 5
Training loss: 3.262185361459329
Validation loss: 3.7659550704561893

Epoch: 6| Step: 6
Training loss: 4.013489864334191
Validation loss: 3.75476071869592

Epoch: 6| Step: 7
Training loss: 3.479126813892531
Validation loss: 3.744464699400397

Epoch: 6| Step: 8
Training loss: 4.0634241080112945
Validation loss: 3.7375140790831574

Epoch: 6| Step: 9
Training loss: 4.7515119856633365
Validation loss: 3.7296881577766436

Epoch: 6| Step: 10
Training loss: 4.574854597272097
Validation loss: 3.719103588081721

Epoch: 6| Step: 11
Training loss: 1.8891684225596157
Validation loss: 3.7094702439420044

Epoch: 6| Step: 12
Training loss: 3.49276885584997
Validation loss: 3.702094705301412

Epoch: 6| Step: 13
Training loss: 4.642421387565079
Validation loss: 3.6919894377872065

Epoch: 7| Step: 0
Training loss: 2.9931251909180645
Validation loss: 3.682189212211577

Epoch: 6| Step: 1
Training loss: 3.9353599182097754
Validation loss: 3.671934805867157

Epoch: 6| Step: 2
Training loss: 3.6888541628519333
Validation loss: 3.663340970937736

Epoch: 6| Step: 3
Training loss: 4.485215802736714
Validation loss: 3.6490905884072538

Epoch: 6| Step: 4
Training loss: 3.708194144276363
Validation loss: 3.637543675406749

Epoch: 6| Step: 5
Training loss: 3.6301561713974997
Validation loss: 3.6243992308716195

Epoch: 6| Step: 6
Training loss: 3.4686161049784423
Validation loss: 3.610956347146325

Epoch: 6| Step: 7
Training loss: 4.013956517431165
Validation loss: 3.6004001160934562

Epoch: 6| Step: 8
Training loss: 4.314557013376888
Validation loss: 3.58576145929003

Epoch: 6| Step: 9
Training loss: 3.254782166113815
Validation loss: 3.5751080864462836

Epoch: 6| Step: 10
Training loss: 4.5934888285397975
Validation loss: 3.5748496441266817

Epoch: 6| Step: 11
Training loss: 3.237057075984851
Validation loss: 3.5562812687738923

Epoch: 6| Step: 12
Training loss: 3.788910097812969
Validation loss: 3.552744480222798

Epoch: 6| Step: 13
Training loss: 3.8184585285239927
Validation loss: 3.547917157132183

Epoch: 8| Step: 0
Training loss: 3.495851237660792
Validation loss: 3.536539877882726

Epoch: 6| Step: 1
Training loss: 3.553775074991434
Validation loss: 3.5262097277013034

Epoch: 6| Step: 2
Training loss: 4.565129188807043
Validation loss: 3.5179990828898244

Epoch: 6| Step: 3
Training loss: 3.437936928464029
Validation loss: 3.5064508873329463

Epoch: 6| Step: 4
Training loss: 2.519173908767949
Validation loss: 3.498694752199591

Epoch: 6| Step: 5
Training loss: 3.8140103209605445
Validation loss: 3.4887515966586107

Epoch: 6| Step: 6
Training loss: 3.8904282853366117
Validation loss: 3.4800832252300746

Epoch: 6| Step: 7
Training loss: 3.8077257624699987
Validation loss: 3.4712989013197593

Epoch: 6| Step: 8
Training loss: 3.079819575883483
Validation loss: 3.4661393611343327

Epoch: 6| Step: 9
Training loss: 4.066657887642145
Validation loss: 3.4628309903822836

Epoch: 6| Step: 10
Training loss: 3.53715938909802
Validation loss: 3.4547022840811032

Epoch: 6| Step: 11
Training loss: 3.80315354147665
Validation loss: 3.443278461397861

Epoch: 6| Step: 12
Training loss: 4.255215978284838
Validation loss: 3.438069760413999

Epoch: 6| Step: 13
Training loss: 3.269633338273276
Validation loss: 3.425808257394543

Epoch: 9| Step: 0
Training loss: 4.408248340001278
Validation loss: 3.4180091848486716

Epoch: 6| Step: 1
Training loss: 3.105801009151627
Validation loss: 3.407932743031346

Epoch: 6| Step: 2
Training loss: 4.2564157417280875
Validation loss: 3.401724867619905

Epoch: 6| Step: 3
Training loss: 4.1271848961036355
Validation loss: 3.39538946269928

Epoch: 6| Step: 4
Training loss: 3.702324245487635
Validation loss: 3.387327080322543

Epoch: 6| Step: 5
Training loss: 3.4573417222430867
Validation loss: 3.3822015430722057

Epoch: 6| Step: 6
Training loss: 3.585413144405629
Validation loss: 3.376070365580398

Epoch: 6| Step: 7
Training loss: 3.29244943960844
Validation loss: 3.368523646415758

Epoch: 6| Step: 8
Training loss: 3.8449164380739775
Validation loss: 3.3630797950982574

Epoch: 6| Step: 9
Training loss: 3.555219472127581
Validation loss: 3.3575977658122693

Epoch: 6| Step: 10
Training loss: 2.6279006553812536
Validation loss: 3.3513942326033233

Epoch: 6| Step: 11
Training loss: 3.3002313821766074
Validation loss: 3.346305936773271

Epoch: 6| Step: 12
Training loss: 3.2634398528012682
Validation loss: 3.342193656866279

Epoch: 6| Step: 13
Training loss: 3.604915225107576
Validation loss: 3.3390726752438082

Epoch: 10| Step: 0
Training loss: 4.6506469604646306
Validation loss: 3.3291079925767733

Epoch: 6| Step: 1
Training loss: 3.9210209011463535
Validation loss: 3.3222087767395663

Epoch: 6| Step: 2
Training loss: 2.1141039926724265
Validation loss: 3.321848433218193

Epoch: 6| Step: 3
Training loss: 3.548194807749117
Validation loss: 3.3384897362621957

Epoch: 6| Step: 4
Training loss: 3.3049088352112856
Validation loss: 3.3216313788091396

Epoch: 6| Step: 5
Training loss: 2.7618756930852584
Validation loss: 3.309497030073299

Epoch: 6| Step: 6
Training loss: 3.603038692185086
Validation loss: 3.317163951893506

Epoch: 6| Step: 7
Training loss: 2.7562921672199194
Validation loss: 3.3198953145193397

Epoch: 6| Step: 8
Training loss: 4.35939468871562
Validation loss: 3.3173417515888586

Epoch: 6| Step: 9
Training loss: 3.415279354884372
Validation loss: 3.2979395063991763

Epoch: 6| Step: 10
Training loss: 3.701375040804159
Validation loss: 3.2965440115958557

Epoch: 6| Step: 11
Training loss: 3.9907854757401964
Validation loss: 3.301361639154679

Epoch: 6| Step: 12
Training loss: 3.4546560630247907
Validation loss: 3.2862412547239312

Epoch: 6| Step: 13
Training loss: 3.301240606904885
Validation loss: 3.279217317685155

Epoch: 11| Step: 0
Training loss: 3.3756080362295933
Validation loss: 3.275107298102104

Epoch: 6| Step: 1
Training loss: 2.9706771217427024
Validation loss: 3.2729091704958404

Epoch: 6| Step: 2
Training loss: 2.812278993188365
Validation loss: 3.2701365351332656

Epoch: 6| Step: 3
Training loss: 3.7811639949380944
Validation loss: 3.2650648962369635

Epoch: 6| Step: 4
Training loss: 3.192225674379014
Validation loss: 3.260091766541996

Epoch: 6| Step: 5
Training loss: 3.726117825318563
Validation loss: 3.260588903646961

Epoch: 6| Step: 6
Training loss: 3.8615879401714697
Validation loss: 3.2485389880539257

Epoch: 6| Step: 7
Training loss: 3.8943884851120893
Validation loss: 3.2476587136911417

Epoch: 6| Step: 8
Training loss: 4.188619663233646
Validation loss: 3.2407664872016126

Epoch: 6| Step: 9
Training loss: 3.020584850395688
Validation loss: 3.2311446917891598

Epoch: 6| Step: 10
Training loss: 3.6135524338691667
Validation loss: 3.232626247782587

Epoch: 6| Step: 11
Training loss: 3.318952645474598
Validation loss: 3.2307062618358753

Epoch: 6| Step: 12
Training loss: 3.295024044892677
Validation loss: 3.2294495732880466

Epoch: 6| Step: 13
Training loss: 3.85720949771372
Validation loss: 3.235042795362056

Epoch: 12| Step: 0
Training loss: 4.353865666305562
Validation loss: 3.2238624766974358

Epoch: 6| Step: 1
Training loss: 3.574210745380381
Validation loss: 3.2154992112368244

Epoch: 6| Step: 2
Training loss: 2.382238700443579
Validation loss: 3.213807403947384

Epoch: 6| Step: 3
Training loss: 2.824551848927159
Validation loss: 3.2149965738885458

Epoch: 6| Step: 4
Training loss: 3.399752518117788
Validation loss: 3.214222914373127

Epoch: 6| Step: 5
Training loss: 3.7840776195912404
Validation loss: 3.2039853617035328

Epoch: 6| Step: 6
Training loss: 3.1025659585806955
Validation loss: 3.1963789666229125

Epoch: 6| Step: 7
Training loss: 2.952285728076237
Validation loss: 3.190351757547923

Epoch: 6| Step: 8
Training loss: 3.2758439352568645
Validation loss: 3.1936831614185266

Epoch: 6| Step: 9
Training loss: 3.029752695799622
Validation loss: 3.1909257100738517

Epoch: 6| Step: 10
Training loss: 3.576259343209407
Validation loss: 3.18943573421925

Epoch: 6| Step: 11
Training loss: 4.156522125284372
Validation loss: 3.1873216605277257

Epoch: 6| Step: 12
Training loss: 3.6049846683763462
Validation loss: 3.1817690703148718

Epoch: 6| Step: 13
Training loss: 4.188925656990111
Validation loss: 3.174561526745105

Epoch: 13| Step: 0
Training loss: 3.1231528354249414
Validation loss: 3.169585290534901

Epoch: 6| Step: 1
Training loss: 3.4206490606810123
Validation loss: 3.169411291269752

Epoch: 6| Step: 2
Training loss: 3.1428023804191323
Validation loss: 3.168258652716055

Epoch: 6| Step: 3
Training loss: 4.022541901990765
Validation loss: 3.1685462294734417

Epoch: 6| Step: 4
Training loss: 3.532919025122672
Validation loss: 3.1599368218185955

Epoch: 6| Step: 5
Training loss: 4.019272153639204
Validation loss: 3.1566530626388505

Epoch: 6| Step: 6
Training loss: 3.268013112904494
Validation loss: 3.1601416833666747

Epoch: 6| Step: 7
Training loss: 3.012141454103105
Validation loss: 3.1574755701255

Epoch: 6| Step: 8
Training loss: 3.3630803454712788
Validation loss: 3.15239251366381

Epoch: 6| Step: 9
Training loss: 2.9241174262977743
Validation loss: 3.139684526616298

Epoch: 6| Step: 10
Training loss: 3.2123512441429987
Validation loss: 3.1342512117886896

Epoch: 6| Step: 11
Training loss: 4.044217330601642
Validation loss: 3.1362792928982777

Epoch: 6| Step: 12
Training loss: 3.475129730218097
Validation loss: 3.135561824849769

Epoch: 6| Step: 13
Training loss: 2.8028641833506773
Validation loss: 3.131487397788175

Epoch: 14| Step: 0
Training loss: 3.735685876583557
Validation loss: 3.1286133301364507

Epoch: 6| Step: 1
Training loss: 3.0721569781726905
Validation loss: 3.1252876543121477

Epoch: 6| Step: 2
Training loss: 3.066535626251603
Validation loss: 3.122424103024427

Epoch: 6| Step: 3
Training loss: 3.321901618800628
Validation loss: 3.120961291199534

Epoch: 6| Step: 4
Training loss: 3.745517085681995
Validation loss: 3.121606313856995

Epoch: 6| Step: 5
Training loss: 3.1347747517390503
Validation loss: 3.1202584125913186

Epoch: 6| Step: 6
Training loss: 2.6004026651354413
Validation loss: 3.1131048350288997

Epoch: 6| Step: 7
Training loss: 3.0840004551512386
Validation loss: 3.110974190033625

Epoch: 6| Step: 8
Training loss: 3.4577502176542465
Validation loss: 3.109604876739735

Epoch: 6| Step: 9
Training loss: 3.7738618158009896
Validation loss: 3.106431118734591

Epoch: 6| Step: 10
Training loss: 3.5460126055274492
Validation loss: 3.106912809759552

Epoch: 6| Step: 11
Training loss: 3.294342080452786
Validation loss: 3.1050617562466587

Epoch: 6| Step: 12
Training loss: 3.5532466441512844
Validation loss: 3.1040382901029897

Epoch: 6| Step: 13
Training loss: 4.202031216592143
Validation loss: 3.1050176754019496

Epoch: 15| Step: 0
Training loss: 2.5849712675700283
Validation loss: 3.1009319674250424

Epoch: 6| Step: 1
Training loss: 3.72674470532029
Validation loss: 3.0980533515551265

Epoch: 6| Step: 2
Training loss: 3.551704244810164
Validation loss: 3.098282259521175

Epoch: 6| Step: 3
Training loss: 3.5660196953452643
Validation loss: 3.0923601403033323

Epoch: 6| Step: 4
Training loss: 2.8906278043166296
Validation loss: 3.0887628255565143

Epoch: 6| Step: 5
Training loss: 3.2289893973310244
Validation loss: 3.086063709847972

Epoch: 6| Step: 6
Training loss: 3.69673293962113
Validation loss: 3.0807027817289563

Epoch: 6| Step: 7
Training loss: 3.393758565143715
Validation loss: 3.076594538015548

Epoch: 6| Step: 8
Training loss: 3.697859872014709
Validation loss: 3.0681066976058617

Epoch: 6| Step: 9
Training loss: 2.966600784541754
Validation loss: 3.067337205612714

Epoch: 6| Step: 10
Training loss: 3.407031048462216
Validation loss: 3.075337113320452

Epoch: 6| Step: 11
Training loss: 3.789243335931189
Validation loss: 3.0748705473125426

Epoch: 6| Step: 12
Training loss: 3.1259039525111305
Validation loss: 3.0592804808103375

Epoch: 6| Step: 13
Training loss: 3.1759165304539483
Validation loss: 3.0619399877370355

Epoch: 16| Step: 0
Training loss: 3.227027397746363
Validation loss: 3.0674674853273567

Epoch: 6| Step: 1
Training loss: 3.2743090650571802
Validation loss: 3.0691964120362796

Epoch: 6| Step: 2
Training loss: 3.2685682548922927
Validation loss: 3.061372478662557

Epoch: 6| Step: 3
Training loss: 3.8332913161476685
Validation loss: 3.0526486149478855

Epoch: 6| Step: 4
Training loss: 3.410026906150652
Validation loss: 3.0491176297840656

Epoch: 6| Step: 5
Training loss: 3.257370440818898
Validation loss: 3.051525466625592

Epoch: 6| Step: 6
Training loss: 3.253716617842376
Validation loss: 3.0580109658521337

Epoch: 6| Step: 7
Training loss: 3.0681585856884244
Validation loss: 3.054291597665749

Epoch: 6| Step: 8
Training loss: 3.9260477307722277
Validation loss: 3.049594227167956

Epoch: 6| Step: 9
Training loss: 3.7989287924483097
Validation loss: 3.052156415500646

Epoch: 6| Step: 10
Training loss: 2.2164365500798313
Validation loss: 3.0434980999217123

Epoch: 6| Step: 11
Training loss: 3.0662583625265762
Validation loss: 3.0588084379587266

Epoch: 6| Step: 12
Training loss: 3.56924870041307
Validation loss: 3.083629828922168

Epoch: 6| Step: 13
Training loss: 3.326227354526666
Validation loss: 3.073132173723702

Epoch: 17| Step: 0
Training loss: 3.503349880925911
Validation loss: 3.0455963371381642

Epoch: 6| Step: 1
Training loss: 3.9691142718530217
Validation loss: 3.044803829396928

Epoch: 6| Step: 2
Training loss: 3.6990879120291815
Validation loss: 3.0561454933078886

Epoch: 6| Step: 3
Training loss: 3.408743968996057
Validation loss: 3.0641150603391436

Epoch: 6| Step: 4
Training loss: 3.8415892195325125
Validation loss: 3.0497052766597927

Epoch: 6| Step: 5
Training loss: 3.1253295724648686
Validation loss: 3.035707375441094

Epoch: 6| Step: 6
Training loss: 3.4005229996491098
Validation loss: 3.0344332012212645

Epoch: 6| Step: 7
Training loss: 3.361800484768489
Validation loss: 3.038054570335406

Epoch: 6| Step: 8
Training loss: 2.809720339994187
Validation loss: 3.0426852068498733

Epoch: 6| Step: 9
Training loss: 2.848709978974961
Validation loss: 3.0338482679196788

Epoch: 6| Step: 10
Training loss: 2.9810214548858496
Validation loss: 3.031375112384165

Epoch: 6| Step: 11
Training loss: 2.7761649461656797
Validation loss: 3.0682125341925284

Epoch: 6| Step: 12
Training loss: 3.4073912782179825
Validation loss: 3.116021809425018

Epoch: 6| Step: 13
Training loss: 3.377904842800365
Validation loss: 3.131341641649871

Epoch: 18| Step: 0
Training loss: 2.733582736088799
Validation loss: 3.126252649749629

Epoch: 6| Step: 1
Training loss: 2.9683381447457657
Validation loss: 3.1182552769159866

Epoch: 6| Step: 2
Training loss: 3.3876901045380117
Validation loss: 3.112112381206384

Epoch: 6| Step: 3
Training loss: 3.934324164512849
Validation loss: 3.1119374577946943

Epoch: 6| Step: 4
Training loss: 4.082432134920367
Validation loss: 3.1067645432659776

Epoch: 6| Step: 5
Training loss: 3.5295118256951863
Validation loss: 3.1028990738614257

Epoch: 6| Step: 6
Training loss: 3.1103613741014793
Validation loss: 3.100210369380585

Epoch: 6| Step: 7
Training loss: 3.740522743044794
Validation loss: 3.098598206089434

Epoch: 6| Step: 8
Training loss: 3.532560662290695
Validation loss: 3.100067554535681

Epoch: 6| Step: 9
Training loss: 2.8158052308448074
Validation loss: 3.0690141600626375

Epoch: 6| Step: 10
Training loss: 2.94232836045284
Validation loss: 3.0536201978533994

Epoch: 6| Step: 11
Training loss: 3.2409318445767115
Validation loss: 3.076543514670371

Epoch: 6| Step: 12
Training loss: 3.6756406264612673
Validation loss: 3.0369529497870986

Epoch: 6| Step: 13
Training loss: 2.9116899993025656
Validation loss: 3.0261780966451783

Epoch: 19| Step: 0
Training loss: 2.7868203091436166
Validation loss: 3.0214211004915614

Epoch: 6| Step: 1
Training loss: 3.552503514351875
Validation loss: 3.0310637545078647

Epoch: 6| Step: 2
Training loss: 3.1991859592718197
Validation loss: 3.0555901743275435

Epoch: 6| Step: 3
Training loss: 2.3188700189915834
Validation loss: 3.0708709937778216

Epoch: 6| Step: 4
Training loss: 3.1186990921054902
Validation loss: 3.051434273844301

Epoch: 6| Step: 5
Training loss: 3.5978060182758047
Validation loss: 3.0293007221973562

Epoch: 6| Step: 6
Training loss: 3.478562780421533
Validation loss: 3.01251256633172

Epoch: 6| Step: 7
Training loss: 3.5819219574640084
Validation loss: 3.0169890673093764

Epoch: 6| Step: 8
Training loss: 3.8118648312632084
Validation loss: 3.024335584470269

Epoch: 6| Step: 9
Training loss: 3.0481319084660186
Validation loss: 3.010505821138973

Epoch: 6| Step: 10
Training loss: 3.9714809843566474
Validation loss: 3.0043557550539433

Epoch: 6| Step: 11
Training loss: 2.7713133508498515
Validation loss: 2.99905706613254

Epoch: 6| Step: 12
Training loss: 3.118571879894443
Validation loss: 2.997339106017673

Epoch: 6| Step: 13
Training loss: 3.760854144375141
Validation loss: 2.994765671683654

Epoch: 20| Step: 0
Training loss: 3.266383762825085
Validation loss: 2.9966381388251757

Epoch: 6| Step: 1
Training loss: 3.2842123555745886
Validation loss: 3.002039462237924

Epoch: 6| Step: 2
Training loss: 2.9872331763465874
Validation loss: 3.0040090846734095

Epoch: 6| Step: 3
Training loss: 2.625162937012066
Validation loss: 3.0230010444904956

Epoch: 6| Step: 4
Training loss: 3.639626296426148
Validation loss: 3.0451349894243123

Epoch: 6| Step: 5
Training loss: 2.9105525828587
Validation loss: 3.0242263245259173

Epoch: 6| Step: 6
Training loss: 3.1852911981622407
Validation loss: 3.0197949541014717

Epoch: 6| Step: 7
Training loss: 3.705980576087046
Validation loss: 3.0094542701021436

Epoch: 6| Step: 8
Training loss: 3.6133599020155938
Validation loss: 2.996749689542933

Epoch: 6| Step: 9
Training loss: 3.629416701896918
Validation loss: 2.9948857717544373

Epoch: 6| Step: 10
Training loss: 3.179715093169586
Validation loss: 2.995155449485934

Epoch: 6| Step: 11
Training loss: 3.470462273358998
Validation loss: 2.9921145615937985

Epoch: 6| Step: 12
Training loss: 3.09952260925347
Validation loss: 2.9914463842920678

Epoch: 6| Step: 13
Training loss: 3.4868995176890256
Validation loss: 2.990720326814295

Epoch: 21| Step: 0
Training loss: 2.689446653581312
Validation loss: 2.9900044590563546

Epoch: 6| Step: 1
Training loss: 3.6046929976574758
Validation loss: 2.9945765697960054

Epoch: 6| Step: 2
Training loss: 3.612862359587103
Validation loss: 2.9961951124568422

Epoch: 6| Step: 3
Training loss: 3.3083249538004824
Validation loss: 2.9899059503321603

Epoch: 6| Step: 4
Training loss: 3.4526981417889675
Validation loss: 2.9845222978406825

Epoch: 6| Step: 5
Training loss: 3.5494644190854365
Validation loss: 2.981747972216542

Epoch: 6| Step: 6
Training loss: 3.639083339423478
Validation loss: 2.979252441763988

Epoch: 6| Step: 7
Training loss: 3.3370692457331286
Validation loss: 2.979791481200734

Epoch: 6| Step: 8
Training loss: 2.4288811526224277
Validation loss: 2.977649928797555

Epoch: 6| Step: 9
Training loss: 2.8738673093529523
Validation loss: 2.979181225241495

Epoch: 6| Step: 10
Training loss: 3.4614267111126025
Validation loss: 2.9849051165927514

Epoch: 6| Step: 11
Training loss: 2.7232527879767057
Validation loss: 2.9844524637855194

Epoch: 6| Step: 12
Training loss: 3.3248548605081734
Validation loss: 2.981551566710984

Epoch: 6| Step: 13
Training loss: 3.8302580204198677
Validation loss: 2.9738485857228807

Epoch: 22| Step: 0
Training loss: 3.779850472212513
Validation loss: 2.9746771399324916

Epoch: 6| Step: 1
Training loss: 2.4898509968369984
Validation loss: 2.9777184221973103

Epoch: 6| Step: 2
Training loss: 3.5517472064300675
Validation loss: 2.9826243636496788

Epoch: 6| Step: 3
Training loss: 2.739188007410482
Validation loss: 2.979958022468133

Epoch: 6| Step: 4
Training loss: 3.045262619244195
Validation loss: 2.974393231187098

Epoch: 6| Step: 5
Training loss: 3.6516785041295696
Validation loss: 2.969913828364027

Epoch: 6| Step: 6
Training loss: 3.583374437199905
Validation loss: 2.9683697105576163

Epoch: 6| Step: 7
Training loss: 3.353970034188495
Validation loss: 2.9682104288547446

Epoch: 6| Step: 8
Training loss: 3.5131781306963257
Validation loss: 2.9703519828479164

Epoch: 6| Step: 9
Training loss: 3.0575927031617103
Validation loss: 2.981428856357176

Epoch: 6| Step: 10
Training loss: 2.9893996196660577
Validation loss: 2.984227310028471

Epoch: 6| Step: 11
Training loss: 2.798442720869467
Validation loss: 2.9854381428406884

Epoch: 6| Step: 12
Training loss: 3.252250772320543
Validation loss: 2.9803886640967727

Epoch: 6| Step: 13
Training loss: 3.9919186257074455
Validation loss: 2.9600303395115204

Epoch: 23| Step: 0
Training loss: 3.420413467220471
Validation loss: 2.9602134469322796

Epoch: 6| Step: 1
Training loss: 3.587467972349958
Validation loss: 2.9618365571438683

Epoch: 6| Step: 2
Training loss: 3.408420116435841
Validation loss: 2.963099085771287

Epoch: 6| Step: 3
Training loss: 3.096085408671422
Validation loss: 2.9633438947194044

Epoch: 6| Step: 4
Training loss: 3.420281025901611
Validation loss: 2.9638580915167507

Epoch: 6| Step: 5
Training loss: 3.375971618948868
Validation loss: 2.96731282168544

Epoch: 6| Step: 6
Training loss: 2.709097025866117
Validation loss: 2.967405367675363

Epoch: 6| Step: 7
Training loss: 2.785376412997884
Validation loss: 2.9663317690315805

Epoch: 6| Step: 8
Training loss: 3.0981514187398815
Validation loss: 2.959661419343983

Epoch: 6| Step: 9
Training loss: 3.9147961932026507
Validation loss: 2.9601667016005715

Epoch: 6| Step: 10
Training loss: 2.715425234208389
Validation loss: 2.958990269059469

Epoch: 6| Step: 11
Training loss: 3.3949245492812503
Validation loss: 2.9563969698188073

Epoch: 6| Step: 12
Training loss: 3.7629212609375213
Validation loss: 2.959186884620401

Epoch: 6| Step: 13
Training loss: 2.162777185040134
Validation loss: 2.967085137798015

Epoch: 24| Step: 0
Training loss: 3.1671261872283583
Validation loss: 2.965749177114053

Epoch: 6| Step: 1
Training loss: 3.8366372893860605
Validation loss: 2.962170531089978

Epoch: 6| Step: 2
Training loss: 3.9537971739317044
Validation loss: 2.959876293459209

Epoch: 6| Step: 3
Training loss: 2.520176531345673
Validation loss: 2.95097661624045

Epoch: 6| Step: 4
Training loss: 3.3266053648086706
Validation loss: 2.9496997962763514

Epoch: 6| Step: 5
Training loss: 3.0440023329396273
Validation loss: 2.9505426866755156

Epoch: 6| Step: 6
Training loss: 3.046605963933488
Validation loss: 2.949459928753422

Epoch: 6| Step: 7
Training loss: 3.3636895440323875
Validation loss: 2.9470581772361686

Epoch: 6| Step: 8
Training loss: 2.796468268288273
Validation loss: 2.9481397372122644

Epoch: 6| Step: 9
Training loss: 2.8610484744955103
Validation loss: 2.947464661336132

Epoch: 6| Step: 10
Training loss: 3.306606592227403
Validation loss: 2.9469982458594517

Epoch: 6| Step: 11
Training loss: 3.3206269956755428
Validation loss: 2.9463144369845446

Epoch: 6| Step: 12
Training loss: 3.679803737092247
Validation loss: 2.958577025719256

Epoch: 6| Step: 13
Training loss: 2.793762179695906
Validation loss: 2.944968393139031

Epoch: 25| Step: 0
Training loss: 3.0114131628972634
Validation loss: 2.94410590807165

Epoch: 6| Step: 1
Training loss: 3.102017847261915
Validation loss: 2.942171405257237

Epoch: 6| Step: 2
Training loss: 3.1005055046161867
Validation loss: 2.9415032244784234

Epoch: 6| Step: 3
Training loss: 2.9090818329149326
Validation loss: 2.942390465817563

Epoch: 6| Step: 4
Training loss: 3.499974659419286
Validation loss: 2.9414255726373293

Epoch: 6| Step: 5
Training loss: 2.8638878735272146
Validation loss: 2.9418716192172356

Epoch: 6| Step: 6
Training loss: 2.9112368222467024
Validation loss: 2.9400877601927795

Epoch: 6| Step: 7
Training loss: 3.2644049450682036
Validation loss: 2.940961769894721

Epoch: 6| Step: 8
Training loss: 3.3677262939452453
Validation loss: 2.9407681115550086

Epoch: 6| Step: 9
Training loss: 3.4099109819265205
Validation loss: 2.937089893598148

Epoch: 6| Step: 10
Training loss: 4.131189961653613
Validation loss: 2.9355073015917967

Epoch: 6| Step: 11
Training loss: 3.286282703444426
Validation loss: 2.9331863557605784

Epoch: 6| Step: 12
Training loss: 3.400332989935522
Validation loss: 2.93361134311715

Epoch: 6| Step: 13
Training loss: 2.4509499012415565
Validation loss: 2.9322594251247893

Epoch: 26| Step: 0
Training loss: 3.4620150229901054
Validation loss: 2.9322301266971675

Epoch: 6| Step: 1
Training loss: 3.419409294646724
Validation loss: 2.9318075379098194

Epoch: 6| Step: 2
Training loss: 3.6816942448847354
Validation loss: 2.9318985989314843

Epoch: 6| Step: 3
Training loss: 2.656057732299343
Validation loss: 2.937060256679816

Epoch: 6| Step: 4
Training loss: 3.3079428364659162
Validation loss: 2.9372458556371432

Epoch: 6| Step: 5
Training loss: 4.047512166297728
Validation loss: 2.9344001687253107

Epoch: 6| Step: 6
Training loss: 3.1758417590618513
Validation loss: 2.9307700321697054

Epoch: 6| Step: 7
Training loss: 3.313030416379535
Validation loss: 2.9253180183806338

Epoch: 6| Step: 8
Training loss: 2.6074458317602622
Validation loss: 2.9246122340018674

Epoch: 6| Step: 9
Training loss: 2.8774630734935327
Validation loss: 2.9236570386544964

Epoch: 6| Step: 10
Training loss: 3.019224400492581
Validation loss: 2.922894156044959

Epoch: 6| Step: 11
Training loss: 3.291837486631306
Validation loss: 2.9236365866785863

Epoch: 6| Step: 12
Training loss: 3.135524726771394
Validation loss: 2.922442730430278

Epoch: 6| Step: 13
Training loss: 2.661426840121175
Validation loss: 2.9216789042490183

Epoch: 27| Step: 0
Training loss: 3.7188968148622092
Validation loss: 2.9204823656926715

Epoch: 6| Step: 1
Training loss: 3.2647698117674584
Validation loss: 2.919930784753956

Epoch: 6| Step: 2
Training loss: 3.77883228531669
Validation loss: 2.916577745362492

Epoch: 6| Step: 3
Training loss: 3.394634916875756
Validation loss: 2.9180940753597837

Epoch: 6| Step: 4
Training loss: 2.590783502494818
Validation loss: 2.91855064815015

Epoch: 6| Step: 5
Training loss: 2.920784160147486
Validation loss: 2.9210152195955055

Epoch: 6| Step: 6
Training loss: 3.4207636452444325
Validation loss: 2.92134323313034

Epoch: 6| Step: 7
Training loss: 2.85894004974008
Validation loss: 2.9186182442635196

Epoch: 6| Step: 8
Training loss: 3.120157991957361
Validation loss: 2.918889536149206

Epoch: 6| Step: 9
Training loss: 3.307898294077737
Validation loss: 2.913615323214938

Epoch: 6| Step: 10
Training loss: 3.6567609381078876
Validation loss: 2.9135008869022

Epoch: 6| Step: 11
Training loss: 2.9642505479522403
Validation loss: 2.9127334941944945

Epoch: 6| Step: 12
Training loss: 2.9628357451554748
Validation loss: 2.9137597348353723

Epoch: 6| Step: 13
Training loss: 2.578834389855761
Validation loss: 2.9102980355701984

Epoch: 28| Step: 0
Training loss: 3.0376239892590506
Validation loss: 2.9115904592913346

Epoch: 6| Step: 1
Training loss: 2.734140963756694
Validation loss: 2.91197881090027

Epoch: 6| Step: 2
Training loss: 3.6573261731261133
Validation loss: 2.9129617643185846

Epoch: 6| Step: 3
Training loss: 3.3339888087166623
Validation loss: 2.912379124489592

Epoch: 6| Step: 4
Training loss: 3.01446463441944
Validation loss: 2.90842961581746

Epoch: 6| Step: 5
Training loss: 3.029949420469026
Validation loss: 2.9158016694745266

Epoch: 6| Step: 6
Training loss: 4.599464858066732
Validation loss: 2.9115359807994

Epoch: 6| Step: 7
Training loss: 2.6665162898420327
Validation loss: 2.908747004018414

Epoch: 6| Step: 8
Training loss: 3.2446172594904774
Validation loss: 2.907984878783847

Epoch: 6| Step: 9
Training loss: 3.187050582019921
Validation loss: 2.906518045873308

Epoch: 6| Step: 10
Training loss: 3.0412316904014642
Validation loss: 2.906020971530098

Epoch: 6| Step: 11
Training loss: 3.0218544297568526
Validation loss: 2.9040427151319967

Epoch: 6| Step: 12
Training loss: 2.8771737215473108
Validation loss: 2.903897305593162

Epoch: 6| Step: 13
Training loss: 3.023355172389292
Validation loss: 2.903961725690071

Epoch: 29| Step: 0
Training loss: 3.5466612360728664
Validation loss: 2.9160521292008954

Epoch: 6| Step: 1
Training loss: 2.9861534371937197
Validation loss: 2.92901203465795

Epoch: 6| Step: 2
Training loss: 2.7411202204050853
Validation loss: 2.957566033674854

Epoch: 6| Step: 3
Training loss: 2.7681282051362435
Validation loss: 2.9563218727784824

Epoch: 6| Step: 4
Training loss: 3.697011544937792
Validation loss: 2.9697303970901925

Epoch: 6| Step: 5
Training loss: 3.2421395539564766
Validation loss: 2.944803035818359

Epoch: 6| Step: 6
Training loss: 3.2488621407118194
Validation loss: 2.9177877694517314

Epoch: 6| Step: 7
Training loss: 3.0575808508001368
Validation loss: 2.900960049363241

Epoch: 6| Step: 8
Training loss: 3.42863917567668
Validation loss: 2.8983256372035195

Epoch: 6| Step: 9
Training loss: 3.056991293782773
Validation loss: 2.8973386845538864

Epoch: 6| Step: 10
Training loss: 2.3918892503188802
Validation loss: 2.9023032539393454

Epoch: 6| Step: 11
Training loss: 3.6058490920392865
Validation loss: 2.9121387288433893

Epoch: 6| Step: 12
Training loss: 3.815575781652387
Validation loss: 2.8998856118470893

Epoch: 6| Step: 13
Training loss: 2.926076713688007
Validation loss: 2.8985300268506053

Epoch: 30| Step: 0
Training loss: 3.6740727766509256
Validation loss: 2.8960351425842616

Epoch: 6| Step: 1
Training loss: 3.1846794664193454
Validation loss: 2.8977237591354665

Epoch: 6| Step: 2
Training loss: 2.3585097387362266
Validation loss: 2.898241861773225

Epoch: 6| Step: 3
Training loss: 2.497011114618988
Validation loss: 2.897308249033673

Epoch: 6| Step: 4
Training loss: 3.0860037881033113
Validation loss: 2.9035247152083357

Epoch: 6| Step: 5
Training loss: 3.685887646954486
Validation loss: 2.8984960933700306

Epoch: 6| Step: 6
Training loss: 3.3761135666082427
Validation loss: 2.893006740107273

Epoch: 6| Step: 7
Training loss: 3.329815502382561
Validation loss: 2.8893318900188256

Epoch: 6| Step: 8
Training loss: 3.2022060657840465
Validation loss: 2.8881716244680415

Epoch: 6| Step: 9
Training loss: 3.310148736199284
Validation loss: 2.8866488163111557

Epoch: 6| Step: 10
Training loss: 3.0411777538870206
Validation loss: 2.8879265630530355

Epoch: 6| Step: 11
Training loss: 2.959869594794419
Validation loss: 2.8869190479883002

Epoch: 6| Step: 12
Training loss: 3.1510196064999145
Validation loss: 2.8886680295434206

Epoch: 6| Step: 13
Training loss: 3.8194736425651636
Validation loss: 2.8943409810635523

Epoch: 31| Step: 0
Training loss: 3.021035987808856
Validation loss: 2.8958281361098064

Epoch: 6| Step: 1
Training loss: 2.394978168841991
Validation loss: 2.8954687640799444

Epoch: 6| Step: 2
Training loss: 3.6069298590938597
Validation loss: 2.891610018702592

Epoch: 6| Step: 3
Training loss: 2.1483054380576307
Validation loss: 2.8870347279810904

Epoch: 6| Step: 4
Training loss: 3.1455554123610487
Validation loss: 2.883049875846537

Epoch: 6| Step: 5
Training loss: 3.456761719277495
Validation loss: 2.8835934884077923

Epoch: 6| Step: 6
Training loss: 4.055371647559457
Validation loss: 2.883039582317721

Epoch: 6| Step: 7
Training loss: 3.45704104319764
Validation loss: 2.879651517809439

Epoch: 6| Step: 8
Training loss: 3.1478782895515636
Validation loss: 2.879481603867229

Epoch: 6| Step: 9
Training loss: 2.9979167698764497
Validation loss: 2.8820640467653367

Epoch: 6| Step: 10
Training loss: 3.188258660481112
Validation loss: 2.8777057787712876

Epoch: 6| Step: 11
Training loss: 3.5419301252920237
Validation loss: 2.8776496431856007

Epoch: 6| Step: 12
Training loss: 3.316835409373449
Validation loss: 2.876373770680138

Epoch: 6| Step: 13
Training loss: 2.069572460416594
Validation loss: 2.8791315826471937

Epoch: 32| Step: 0
Training loss: 3.467175925580613
Validation loss: 2.878813290124454

Epoch: 6| Step: 1
Training loss: 3.4139613784724006
Validation loss: 2.876860542228687

Epoch: 6| Step: 2
Training loss: 2.913554865825725
Validation loss: 2.8828214888742827

Epoch: 6| Step: 3
Training loss: 3.1672681605301447
Validation loss: 2.8911536977367414

Epoch: 6| Step: 4
Training loss: 3.2308076360187448
Validation loss: 2.8946242524338572

Epoch: 6| Step: 5
Training loss: 3.296303071226602
Validation loss: 2.8847012107981924

Epoch: 6| Step: 6
Training loss: 2.7443030909980095
Validation loss: 2.877590011512123

Epoch: 6| Step: 7
Training loss: 2.7667328937677635
Validation loss: 2.871173573641992

Epoch: 6| Step: 8
Training loss: 2.5353460255553513
Validation loss: 2.8752958066191474

Epoch: 6| Step: 9
Training loss: 2.9814565079219872
Validation loss: 2.8784576265492725

Epoch: 6| Step: 10
Training loss: 3.448089518444884
Validation loss: 2.8947962894950456

Epoch: 6| Step: 11
Training loss: 3.621450067167744
Validation loss: 2.9295691742878076

Epoch: 6| Step: 12
Training loss: 3.3037307111716108
Validation loss: 2.894495023517577

Epoch: 6| Step: 13
Training loss: 3.812020818895648
Validation loss: 2.879504389564176

Epoch: 33| Step: 0
Training loss: 1.9227484602286502
Validation loss: 2.874913002541927

Epoch: 6| Step: 1
Training loss: 3.025830645050925
Validation loss: 2.8715654610845713

Epoch: 6| Step: 2
Training loss: 3.7039170846577454
Validation loss: 2.870374462084927

Epoch: 6| Step: 3
Training loss: 3.153902899641365
Validation loss: 2.8706325798782735

Epoch: 6| Step: 4
Training loss: 3.6717046170575696
Validation loss: 2.870751889912536

Epoch: 6| Step: 5
Training loss: 3.352714713984645
Validation loss: 2.872859749393084

Epoch: 6| Step: 6
Training loss: 2.609142178867587
Validation loss: 2.8755095388360417

Epoch: 6| Step: 7
Training loss: 2.5897360386608836
Validation loss: 2.8895214338891773

Epoch: 6| Step: 8
Training loss: 3.1134619762083044
Validation loss: 2.897719399289047

Epoch: 6| Step: 9
Training loss: 3.200979565656197
Validation loss: 2.873810693788725

Epoch: 6| Step: 10
Training loss: 3.6877119359034256
Validation loss: 2.8682230812471383

Epoch: 6| Step: 11
Training loss: 3.5422867325663137
Validation loss: 2.8647974274728525

Epoch: 6| Step: 12
Training loss: 3.2476416614343377
Validation loss: 2.86311906070021

Epoch: 6| Step: 13
Training loss: 3.0883872050901346
Validation loss: 2.8601173474129875

Epoch: 34| Step: 0
Training loss: 2.3837320523319003
Validation loss: 2.862918705402279

Epoch: 6| Step: 1
Training loss: 3.8340975511027455
Validation loss: 2.8613899080652923

Epoch: 6| Step: 2
Training loss: 4.108506491663487
Validation loss: 2.86230362166905

Epoch: 6| Step: 3
Training loss: 2.8581920740868774
Validation loss: 2.86297423482505

Epoch: 6| Step: 4
Training loss: 3.4860865747028202
Validation loss: 2.8602999423939215

Epoch: 6| Step: 5
Training loss: 3.3312346209373254
Validation loss: 2.86041275900199

Epoch: 6| Step: 6
Training loss: 3.1679696531094583
Validation loss: 2.8610028867254123

Epoch: 6| Step: 7
Training loss: 2.8376530274118243
Validation loss: 2.8600356931615454

Epoch: 6| Step: 8
Training loss: 2.732787101719187
Validation loss: 2.8611745091254717

Epoch: 6| Step: 9
Training loss: 2.5990043641156864
Validation loss: 2.8577595300703247

Epoch: 6| Step: 10
Training loss: 2.798335967146918
Validation loss: 2.8564175457161824

Epoch: 6| Step: 11
Training loss: 2.9471196870967495
Validation loss: 2.8589725660595735

Epoch: 6| Step: 12
Training loss: 3.56074574428337
Validation loss: 2.8655690115902477

Epoch: 6| Step: 13
Training loss: 3.335234449572948
Validation loss: 2.8561879590522863

Epoch: 35| Step: 0
Training loss: 3.2953290885554787
Validation loss: 2.8536096209974833

Epoch: 6| Step: 1
Training loss: 3.142128352097458
Validation loss: 2.8536656024234026

Epoch: 6| Step: 2
Training loss: 2.7677304287221
Validation loss: 2.852140041408281

Epoch: 6| Step: 3
Training loss: 2.7822588687412266
Validation loss: 2.850972962976408

Epoch: 6| Step: 4
Training loss: 2.7667219497335562
Validation loss: 2.85283484904696

Epoch: 6| Step: 5
Training loss: 3.0452168965880944
Validation loss: 2.8496077448403714

Epoch: 6| Step: 6
Training loss: 3.1867058456544926
Validation loss: 2.8472778549648496

Epoch: 6| Step: 7
Training loss: 3.581713746620734
Validation loss: 2.8472997548968375

Epoch: 6| Step: 8
Training loss: 3.5647789876732934
Validation loss: 2.8451106338894556

Epoch: 6| Step: 9
Training loss: 3.674795993669958
Validation loss: 2.8452619616791845

Epoch: 6| Step: 10
Training loss: 3.765033849637479
Validation loss: 2.844217038716736

Epoch: 6| Step: 11
Training loss: 2.698883256612762
Validation loss: 2.8435714712518103

Epoch: 6| Step: 12
Training loss: 2.8730063782411035
Validation loss: 2.84069436391115

Epoch: 6| Step: 13
Training loss: 2.5745468740932016
Validation loss: 2.8406230291017267

Epoch: 36| Step: 0
Training loss: 2.3184885376298703
Validation loss: 2.841849104538014

Epoch: 6| Step: 1
Training loss: 3.103520080678441
Validation loss: 2.859026656283934

Epoch: 6| Step: 2
Training loss: 3.4154770493638873
Validation loss: 2.9012319038099155

Epoch: 6| Step: 3
Training loss: 3.941860267341872
Validation loss: 2.855918201928062

Epoch: 6| Step: 4
Training loss: 3.089033442559813
Validation loss: 2.8361753588126764

Epoch: 6| Step: 5
Training loss: 2.894663531000216
Validation loss: 2.837665563475444

Epoch: 6| Step: 6
Training loss: 3.242951746569568
Validation loss: 2.840118078542693

Epoch: 6| Step: 7
Training loss: 2.8238669528526534
Validation loss: 2.8494906821868726

Epoch: 6| Step: 8
Training loss: 3.7472259433490014
Validation loss: 2.8566623019922197

Epoch: 6| Step: 9
Training loss: 3.270313893922526
Validation loss: 2.845059307642353

Epoch: 6| Step: 10
Training loss: 3.3353468217909303
Validation loss: 2.8378411781837336

Epoch: 6| Step: 11
Training loss: 2.2489969348878103
Validation loss: 2.8342776712379494

Epoch: 6| Step: 12
Training loss: 3.3589365118533605
Validation loss: 2.834534117075337

Epoch: 6| Step: 13
Training loss: 3.187021855413729
Validation loss: 2.8337204184374736

Epoch: 37| Step: 0
Training loss: 3.570297141010796
Validation loss: 2.836397749342411

Epoch: 6| Step: 1
Training loss: 2.599630285532918
Validation loss: 2.8382350340936835

Epoch: 6| Step: 2
Training loss: 3.1975087124107078
Validation loss: 2.8437941488169787

Epoch: 6| Step: 3
Training loss: 3.26950091458448
Validation loss: 2.8379053985326563

Epoch: 6| Step: 4
Training loss: 3.2173916811668275
Validation loss: 2.8383811764571756

Epoch: 6| Step: 5
Training loss: 2.900593821796318
Validation loss: 2.8291838938926652

Epoch: 6| Step: 6
Training loss: 3.203697041860068
Validation loss: 2.8271599700798493

Epoch: 6| Step: 7
Training loss: 3.220042885678374
Validation loss: 2.829428681024872

Epoch: 6| Step: 8
Training loss: 3.4215734340218824
Validation loss: 2.8265342737159416

Epoch: 6| Step: 9
Training loss: 3.4127103803571956
Validation loss: 2.8290740357079334

Epoch: 6| Step: 10
Training loss: 3.1710003929558988
Validation loss: 2.8297894595581683

Epoch: 6| Step: 11
Training loss: 2.842359601179448
Validation loss: 2.8259343607902423

Epoch: 6| Step: 12
Training loss: 2.5817739846186787
Validation loss: 2.8273212254029443

Epoch: 6| Step: 13
Training loss: 3.305917064727272
Validation loss: 2.8302510746251097

Epoch: 38| Step: 0
Training loss: 3.332275524778026
Validation loss: 2.8353119648452876

Epoch: 6| Step: 1
Training loss: 2.821330132586581
Validation loss: 2.8393578266600303

Epoch: 6| Step: 2
Training loss: 2.6845198675462414
Validation loss: 2.8444446020576004

Epoch: 6| Step: 3
Training loss: 2.616239825947495
Validation loss: 2.8395102167200625

Epoch: 6| Step: 4
Training loss: 3.817847956679876
Validation loss: 2.8604556889828334

Epoch: 6| Step: 5
Training loss: 3.2571529022578174
Validation loss: 2.843284311875907

Epoch: 6| Step: 6
Training loss: 3.577176030682889
Validation loss: 2.8231757784131317

Epoch: 6| Step: 7
Training loss: 2.449977045535554
Validation loss: 2.8213317845369352

Epoch: 6| Step: 8
Training loss: 3.367923240203716
Validation loss: 2.8231942911712373

Epoch: 6| Step: 9
Training loss: 3.300983346022851
Validation loss: 2.8231125397247063

Epoch: 6| Step: 10
Training loss: 3.14007138359423
Validation loss: 2.8220468482804986

Epoch: 6| Step: 11
Training loss: 2.847365711183777
Validation loss: 2.8234915011653436

Epoch: 6| Step: 12
Training loss: 3.7097762368885814
Validation loss: 2.8223006276286617

Epoch: 6| Step: 13
Training loss: 2.0278108091871996
Validation loss: 2.822563528603779

Epoch: 39| Step: 0
Training loss: 3.4512727352444914
Validation loss: 2.8215877688167494

Epoch: 6| Step: 1
Training loss: 2.661488651667811
Validation loss: 2.8205355395623943

Epoch: 6| Step: 2
Training loss: 3.511600208085103
Validation loss: 2.820530882253427

Epoch: 6| Step: 3
Training loss: 3.4211611765271113
Validation loss: 2.821178893251563

Epoch: 6| Step: 4
Training loss: 2.916062555874436
Validation loss: 2.8183688768914807

Epoch: 6| Step: 5
Training loss: 2.6769802998903405
Validation loss: 2.8205967255627185

Epoch: 6| Step: 6
Training loss: 2.9421938466121635
Validation loss: 2.8175913004519653

Epoch: 6| Step: 7
Training loss: 3.568455052254538
Validation loss: 2.819468585837654

Epoch: 6| Step: 8
Training loss: 3.132762575584123
Validation loss: 2.818877880761818

Epoch: 6| Step: 9
Training loss: 3.2509528010546473
Validation loss: 2.8153393622422627

Epoch: 6| Step: 10
Training loss: 2.6298515354793945
Validation loss: 2.815610540560778

Epoch: 6| Step: 11
Training loss: 3.0932038721036434
Validation loss: 2.8169893392194805

Epoch: 6| Step: 12
Training loss: 3.2822673855223123
Validation loss: 2.8185421757297555

Epoch: 6| Step: 13
Training loss: 3.0953198698091846
Validation loss: 2.821386058473509

Epoch: 40| Step: 0
Training loss: 2.558152861137036
Validation loss: 2.8136966032961115

Epoch: 6| Step: 1
Training loss: 2.849513156199837
Validation loss: 2.8123848676189014

Epoch: 6| Step: 2
Training loss: 3.1432029050895642
Validation loss: 2.811179088105861

Epoch: 6| Step: 3
Training loss: 3.4972017546332475
Validation loss: 2.8115866578377875

Epoch: 6| Step: 4
Training loss: 2.9986343454349464
Validation loss: 2.810653470488797

Epoch: 6| Step: 5
Training loss: 2.923372425555967
Validation loss: 2.8161380795973887

Epoch: 6| Step: 6
Training loss: 2.425798941285126
Validation loss: 2.818479125962135

Epoch: 6| Step: 7
Training loss: 3.0150017761427677
Validation loss: 2.8186432790793066

Epoch: 6| Step: 8
Training loss: 3.529631927579624
Validation loss: 2.8143648184098464

Epoch: 6| Step: 9
Training loss: 3.586635280693975
Validation loss: 2.813558272287516

Epoch: 6| Step: 10
Training loss: 2.6740178667154924
Validation loss: 2.8137700065372067

Epoch: 6| Step: 11
Training loss: 3.478098463589597
Validation loss: 2.8099650198914836

Epoch: 6| Step: 12
Training loss: 3.8548980568791524
Validation loss: 2.8105489100061543

Epoch: 6| Step: 13
Training loss: 2.7298392032596124
Validation loss: 2.8152554649241566

Epoch: 41| Step: 0
Training loss: 2.6837624575961434
Validation loss: 2.8200400947577777

Epoch: 6| Step: 1
Training loss: 3.9384024660616106
Validation loss: 2.828804725333415

Epoch: 6| Step: 2
Training loss: 3.0886485878426067
Validation loss: 2.8287167992513895

Epoch: 6| Step: 3
Training loss: 2.980524585045892
Validation loss: 2.8257562179287046

Epoch: 6| Step: 4
Training loss: 2.984644692902506
Validation loss: 2.8227402154729213

Epoch: 6| Step: 5
Training loss: 3.5592711690573413
Validation loss: 2.8126479644319664

Epoch: 6| Step: 6
Training loss: 2.8501555015571767
Validation loss: 2.8072835056211343

Epoch: 6| Step: 7
Training loss: 3.3616726846661567
Validation loss: 2.8047848872893177

Epoch: 6| Step: 8
Training loss: 2.7087442722092763
Validation loss: 2.804435980808057

Epoch: 6| Step: 9
Training loss: 3.2954368889793058
Validation loss: 2.801126875795725

Epoch: 6| Step: 10
Training loss: 2.45270627086642
Validation loss: 2.805535913362977

Epoch: 6| Step: 11
Training loss: 3.6851438333295294
Validation loss: 2.8019935296785365

Epoch: 6| Step: 12
Training loss: 2.8518823731657545
Validation loss: 2.803710557120353

Epoch: 6| Step: 13
Training loss: 2.607115355344719
Validation loss: 2.79779568114044

Epoch: 42| Step: 0
Training loss: 3.0492891577670656
Validation loss: 2.798512769231131

Epoch: 6| Step: 1
Training loss: 3.2944682950433593
Validation loss: 2.808334069994232

Epoch: 6| Step: 2
Training loss: 2.156684057803346
Validation loss: 2.8239960331112592

Epoch: 6| Step: 3
Training loss: 2.9866471354095707
Validation loss: 2.8781771339108446

Epoch: 6| Step: 4
Training loss: 2.920741223358078
Validation loss: 2.889023468144885

Epoch: 6| Step: 5
Training loss: 3.9442671495688484
Validation loss: 2.85967411005695

Epoch: 6| Step: 6
Training loss: 3.0182663808552057
Validation loss: 2.8311592250304063

Epoch: 6| Step: 7
Training loss: 3.5744874279992658
Validation loss: 2.8046826043133226

Epoch: 6| Step: 8
Training loss: 3.1304284820746626
Validation loss: 2.7926031411343963

Epoch: 6| Step: 9
Training loss: 2.769370694476728
Validation loss: 2.789322206736443

Epoch: 6| Step: 10
Training loss: 2.9511104756601
Validation loss: 2.7892527805037126

Epoch: 6| Step: 11
Training loss: 3.3694600448673553
Validation loss: 2.7904899080977805

Epoch: 6| Step: 12
Training loss: 2.7843644780945973
Validation loss: 2.795857279917523

Epoch: 6| Step: 13
Training loss: 3.5399680757968897
Validation loss: 2.796868478319772

Epoch: 43| Step: 0
Training loss: 2.8733779643841664
Validation loss: 2.795826721721533

Epoch: 6| Step: 1
Training loss: 2.9511797921903233
Validation loss: 2.799087727970708

Epoch: 6| Step: 2
Training loss: 3.5696807235577315
Validation loss: 2.7939706125453805

Epoch: 6| Step: 3
Training loss: 3.326512192201941
Validation loss: 2.790681299290887

Epoch: 6| Step: 4
Training loss: 2.530271364518159
Validation loss: 2.7865944753300202

Epoch: 6| Step: 5
Training loss: 3.5104224471922842
Validation loss: 2.783645739187614

Epoch: 6| Step: 6
Training loss: 3.5706069791456923
Validation loss: 2.787680329193301

Epoch: 6| Step: 7
Training loss: 3.162849250175148
Validation loss: 2.789515327701078

Epoch: 6| Step: 8
Training loss: 3.3018534166135005
Validation loss: 2.7949036812973547

Epoch: 6| Step: 9
Training loss: 3.1012822175879835
Validation loss: 2.8004415868507495

Epoch: 6| Step: 10
Training loss: 2.991035737758059
Validation loss: 2.7987342466480865

Epoch: 6| Step: 11
Training loss: 2.534713824068089
Validation loss: 2.8095608419874156

Epoch: 6| Step: 12
Training loss: 3.052486944147256
Validation loss: 2.823676673401823

Epoch: 6| Step: 13
Training loss: 2.7021256732981307
Validation loss: 2.81805102187015

Epoch: 44| Step: 0
Training loss: 3.3195830138442424
Validation loss: 2.8141215691585706

Epoch: 6| Step: 1
Training loss: 3.2542295077838403
Validation loss: 2.8120170196789847

Epoch: 6| Step: 2
Training loss: 3.213622815031353
Validation loss: 2.7961902285410534

Epoch: 6| Step: 3
Training loss: 2.8032425157288383
Validation loss: 2.7986647790921806

Epoch: 6| Step: 4
Training loss: 2.838209518924815
Validation loss: 2.79637124410497

Epoch: 6| Step: 5
Training loss: 2.675367604603746
Validation loss: 2.792761908474133

Epoch: 6| Step: 6
Training loss: 3.570747332314409
Validation loss: 2.7947937313928333

Epoch: 6| Step: 7
Training loss: 2.857994204793598
Validation loss: 2.786488185872546

Epoch: 6| Step: 8
Training loss: 2.9914572200582237
Validation loss: 2.792638353981534

Epoch: 6| Step: 9
Training loss: 3.224358274501863
Validation loss: 2.781389067748172

Epoch: 6| Step: 10
Training loss: 2.3160651279048214
Validation loss: 2.778486715486751

Epoch: 6| Step: 11
Training loss: 2.911711780160024
Validation loss: 2.778471728433937

Epoch: 6| Step: 12
Training loss: 3.851213853388468
Validation loss: 2.7757808543776212

Epoch: 6| Step: 13
Training loss: 3.266190913323254
Validation loss: 2.7758028307477463

Epoch: 45| Step: 0
Training loss: 2.762629206470946
Validation loss: 2.7786554205927505

Epoch: 6| Step: 1
Training loss: 3.389061211198392
Validation loss: 2.7755542497992436

Epoch: 6| Step: 2
Training loss: 3.296400858696621
Validation loss: 2.7755456829324308

Epoch: 6| Step: 3
Training loss: 2.713732594944239
Validation loss: 2.7766838618415774

Epoch: 6| Step: 4
Training loss: 3.2417777296586423
Validation loss: 2.7741233106007823

Epoch: 6| Step: 5
Training loss: 3.1469170091205902
Validation loss: 2.7738914727120165

Epoch: 6| Step: 6
Training loss: 2.47701877759054
Validation loss: 2.773653955142878

Epoch: 6| Step: 7
Training loss: 2.7935117820544537
Validation loss: 2.7724144460227507

Epoch: 6| Step: 8
Training loss: 3.407102425681816
Validation loss: 2.7792047214044286

Epoch: 6| Step: 9
Training loss: 3.3687212431464078
Validation loss: 2.7942935783765535

Epoch: 6| Step: 10
Training loss: 3.1183230977491037
Validation loss: 2.839587817987798

Epoch: 6| Step: 11
Training loss: 3.7731306689758326
Validation loss: 2.835058793176314

Epoch: 6| Step: 12
Training loss: 3.2585035730037677
Validation loss: 2.778881179089587

Epoch: 6| Step: 13
Training loss: 1.6576574571252543
Validation loss: 2.767414714119643

Epoch: 46| Step: 0
Training loss: 3.08741172633449
Validation loss: 2.773770946543433

Epoch: 6| Step: 1
Training loss: 2.6904408532549606
Validation loss: 2.7732950347586107

Epoch: 6| Step: 2
Training loss: 2.8081691033614287
Validation loss: 2.7751851097802747

Epoch: 6| Step: 3
Training loss: 3.3138879711160154
Validation loss: 2.790871536481901

Epoch: 6| Step: 4
Training loss: 3.0771665678516187
Validation loss: 2.7954039159091555

Epoch: 6| Step: 5
Training loss: 3.514591590737481
Validation loss: 2.7927913050350726

Epoch: 6| Step: 6
Training loss: 1.8678443423731017
Validation loss: 2.782229174766696

Epoch: 6| Step: 7
Training loss: 3.01036633160143
Validation loss: 2.7784661000794872

Epoch: 6| Step: 8
Training loss: 3.612679162252042
Validation loss: 2.775012433712372

Epoch: 6| Step: 9
Training loss: 3.1426115063873428
Validation loss: 2.77002722627172

Epoch: 6| Step: 10
Training loss: 2.587323419562578
Validation loss: 2.7688968419602005

Epoch: 6| Step: 11
Training loss: 3.0894583788499235
Validation loss: 2.7665000612458734

Epoch: 6| Step: 12
Training loss: 3.7751511499321433
Validation loss: 2.7632457133686654

Epoch: 6| Step: 13
Training loss: 3.5121972221662863
Validation loss: 2.764213310637923

Epoch: 47| Step: 0
Training loss: 3.0656049908559546
Validation loss: 2.761908794300163

Epoch: 6| Step: 1
Training loss: 2.6573927272559015
Validation loss: 2.763412043507131

Epoch: 6| Step: 2
Training loss: 3.3216976373214075
Validation loss: 2.7694693893910047

Epoch: 6| Step: 3
Training loss: 3.5316783003880237
Validation loss: 2.774073379601119

Epoch: 6| Step: 4
Training loss: 3.420196539602196
Validation loss: 2.76831551186222

Epoch: 6| Step: 5
Training loss: 2.527626175112871
Validation loss: 2.7786492528770483

Epoch: 6| Step: 6
Training loss: 2.9380690652456285
Validation loss: 2.7696042150097964

Epoch: 6| Step: 7
Training loss: 3.641944744279592
Validation loss: 2.7708250278962465

Epoch: 6| Step: 8
Training loss: 3.698254436415218
Validation loss: 2.767481410786735

Epoch: 6| Step: 9
Training loss: 2.797695785366682
Validation loss: 2.761346554442362

Epoch: 6| Step: 10
Training loss: 3.5021227802427926
Validation loss: 2.7631823314980495

Epoch: 6| Step: 11
Training loss: 2.4852656081649385
Validation loss: 2.754782034355885

Epoch: 6| Step: 12
Training loss: 2.279946464278134
Validation loss: 2.7523398862387953

Epoch: 6| Step: 13
Training loss: 2.437554578903676
Validation loss: 2.7497978359875512

Epoch: 48| Step: 0
Training loss: 2.540484408797179
Validation loss: 2.7495324696667804

Epoch: 6| Step: 1
Training loss: 2.6711042753750287
Validation loss: 2.7501271312633193

Epoch: 6| Step: 2
Training loss: 3.1646354250777806
Validation loss: 2.750748119598645

Epoch: 6| Step: 3
Training loss: 3.171195272139596
Validation loss: 2.7492101463508662

Epoch: 6| Step: 4
Training loss: 3.320084292479256
Validation loss: 2.752611453857673

Epoch: 6| Step: 5
Training loss: 2.600248170892912
Validation loss: 2.756843350823147

Epoch: 6| Step: 6
Training loss: 3.810503452509192
Validation loss: 2.7611792382718896

Epoch: 6| Step: 7
Training loss: 2.9835489937461217
Validation loss: 2.7751744715918383

Epoch: 6| Step: 8
Training loss: 3.1964771787657296
Validation loss: 2.7931341288526426

Epoch: 6| Step: 9
Training loss: 3.216220787914942
Validation loss: 2.7886978627551886

Epoch: 6| Step: 10
Training loss: 3.1053290185741402
Validation loss: 2.766037400573568

Epoch: 6| Step: 11
Training loss: 3.1570404875765776
Validation loss: 2.7438550133442616

Epoch: 6| Step: 12
Training loss: 2.54329949965998
Validation loss: 2.743048258277993

Epoch: 6| Step: 13
Training loss: 3.505419214186443
Validation loss: 2.7439056614695883

Epoch: 49| Step: 0
Training loss: 3.1572830473604836
Validation loss: 2.7437931288467676

Epoch: 6| Step: 1
Training loss: 2.460738885524414
Validation loss: 2.741780841792792

Epoch: 6| Step: 2
Training loss: 3.1111803803982503
Validation loss: 2.7429542316833624

Epoch: 6| Step: 3
Training loss: 3.7128949915314933
Validation loss: 2.7440985005394545

Epoch: 6| Step: 4
Training loss: 2.9085123424218966
Validation loss: 2.7425944362895383

Epoch: 6| Step: 5
Training loss: 2.555556776442674
Validation loss: 2.7423734122472765

Epoch: 6| Step: 6
Training loss: 3.2871784241485127
Validation loss: 2.742453578907167

Epoch: 6| Step: 7
Training loss: 2.8574884580310664
Validation loss: 2.7414906911300507

Epoch: 6| Step: 8
Training loss: 3.1182756938599065
Validation loss: 2.7400532689091297

Epoch: 6| Step: 9
Training loss: 3.0153063670011115
Validation loss: 2.737063953784125

Epoch: 6| Step: 10
Training loss: 3.4205290355077334
Validation loss: 2.7345232860947646

Epoch: 6| Step: 11
Training loss: 3.058340244822441
Validation loss: 2.7338177269262722

Epoch: 6| Step: 12
Training loss: 3.1612551444220327
Validation loss: 2.7366063187065977

Epoch: 6| Step: 13
Training loss: 2.985530928993789
Validation loss: 2.734137957680378

Epoch: 50| Step: 0
Training loss: 3.514451030117054
Validation loss: 2.734921788452768

Epoch: 6| Step: 1
Training loss: 2.997450539989786
Validation loss: 2.7326965993765167

Epoch: 6| Step: 2
Training loss: 2.71051083595912
Validation loss: 2.7323828912584167

Epoch: 6| Step: 3
Training loss: 3.277423043820633
Validation loss: 2.734627302633046

Epoch: 6| Step: 4
Training loss: 3.083187374749933
Validation loss: 2.7330798685379527

Epoch: 6| Step: 5
Training loss: 3.1745930568594387
Validation loss: 2.7457004423526086

Epoch: 6| Step: 6
Training loss: 3.592967470637071
Validation loss: 2.738502711040686

Epoch: 6| Step: 7
Training loss: 3.066270336856573
Validation loss: 2.7324179372451467

Epoch: 6| Step: 8
Training loss: 3.339525923748121
Validation loss: 2.7327542809883596

Epoch: 6| Step: 9
Training loss: 2.4530803895040587
Validation loss: 2.731164375979776

Epoch: 6| Step: 10
Training loss: 2.868451164820649
Validation loss: 2.727607680690141

Epoch: 6| Step: 11
Training loss: 2.8524765430926937
Validation loss: 2.7306741278724336

Epoch: 6| Step: 12
Training loss: 2.7456265265037
Validation loss: 2.729532743461565

Epoch: 6| Step: 13
Training loss: 2.9945431990451006
Validation loss: 2.726955231451146

Epoch: 51| Step: 0
Training loss: 2.489480297132474
Validation loss: 2.7273135650631266

Epoch: 6| Step: 1
Training loss: 2.318169114389137
Validation loss: 2.729678187700236

Epoch: 6| Step: 2
Training loss: 2.937019795876778
Validation loss: 2.728835680355202

Epoch: 6| Step: 3
Training loss: 3.1756657840998077
Validation loss: 2.727349008001166

Epoch: 6| Step: 4
Training loss: 2.813235292745243
Validation loss: 2.730430958961498

Epoch: 6| Step: 5
Training loss: 3.378525482068087
Validation loss: 2.7295472732066903

Epoch: 6| Step: 6
Training loss: 2.5580099823065736
Validation loss: 2.729037062827081

Epoch: 6| Step: 7
Training loss: 3.4696111211621807
Validation loss: 2.7356099358094452

Epoch: 6| Step: 8
Training loss: 3.6539192269620693
Validation loss: 2.7338430573421775

Epoch: 6| Step: 9
Training loss: 3.0173919719078244
Validation loss: 2.731301695046122

Epoch: 6| Step: 10
Training loss: 3.0971813246721527
Validation loss: 2.7264686730756287

Epoch: 6| Step: 11
Training loss: 2.6388287275271685
Validation loss: 2.7270028081740834

Epoch: 6| Step: 12
Training loss: 3.15271735075087
Validation loss: 2.723592187510275

Epoch: 6| Step: 13
Training loss: 4.189199074464956
Validation loss: 2.7240183422939

Epoch: 52| Step: 0
Training loss: 3.8460155726299536
Validation loss: 2.7238297381620646

Epoch: 6| Step: 1
Training loss: 3.0699447139769473
Validation loss: 2.722095097348591

Epoch: 6| Step: 2
Training loss: 2.8272715592793114
Validation loss: 2.7261839869318103

Epoch: 6| Step: 3
Training loss: 2.487943569487872
Validation loss: 2.72361853734676

Epoch: 6| Step: 4
Training loss: 2.8021841113794403
Validation loss: 2.7227824246280683

Epoch: 6| Step: 5
Training loss: 2.9736717785316436
Validation loss: 2.7213811366801655

Epoch: 6| Step: 6
Training loss: 3.144912146962038
Validation loss: 2.719304790192456

Epoch: 6| Step: 7
Training loss: 2.8262841572104147
Validation loss: 2.719196424841815

Epoch: 6| Step: 8
Training loss: 3.2241855391318706
Validation loss: 2.7227087481461045

Epoch: 6| Step: 9
Training loss: 3.4594631111481764
Validation loss: 2.718822028979045

Epoch: 6| Step: 10
Training loss: 2.88798889380985
Validation loss: 2.721197216659625

Epoch: 6| Step: 11
Training loss: 2.7570008550510456
Validation loss: 2.7184895584119664

Epoch: 6| Step: 12
Training loss: 3.0128205061609212
Validation loss: 2.7251436205269077

Epoch: 6| Step: 13
Training loss: 3.222297121324808
Validation loss: 2.7307619578249405

Epoch: 53| Step: 0
Training loss: 3.0205398592403587
Validation loss: 2.738954007092671

Epoch: 6| Step: 1
Training loss: 2.6460433536187073
Validation loss: 2.7499300956231405

Epoch: 6| Step: 2
Training loss: 3.2859483777644787
Validation loss: 2.7480012812187167

Epoch: 6| Step: 3
Training loss: 3.1092069187453926
Validation loss: 2.7596842528813736

Epoch: 6| Step: 4
Training loss: 3.001823189181276
Validation loss: 2.7398716661653832

Epoch: 6| Step: 5
Training loss: 2.1978411789596874
Validation loss: 2.7189830566513633

Epoch: 6| Step: 6
Training loss: 3.2252284656595545
Validation loss: 2.716500709331973

Epoch: 6| Step: 7
Training loss: 2.937786007207725
Validation loss: 2.714745514057994

Epoch: 6| Step: 8
Training loss: 3.627251550643477
Validation loss: 2.711182911839558

Epoch: 6| Step: 9
Training loss: 3.0368840664518046
Validation loss: 2.7114276490755427

Epoch: 6| Step: 10
Training loss: 2.923082234883598
Validation loss: 2.7129986780898188

Epoch: 6| Step: 11
Training loss: 2.8374812860754033
Validation loss: 2.7088693743015093

Epoch: 6| Step: 12
Training loss: 3.451631110680681
Validation loss: 2.70681669178107

Epoch: 6| Step: 13
Training loss: 3.0122028758304333
Validation loss: 2.715962594578235

Epoch: 54| Step: 0
Training loss: 2.6726986691861714
Validation loss: 2.7199603271999253

Epoch: 6| Step: 1
Training loss: 3.2647330056071033
Validation loss: 2.7113587840356415

Epoch: 6| Step: 2
Training loss: 3.3172196647676633
Validation loss: 2.7102956763589696

Epoch: 6| Step: 3
Training loss: 3.118321262773252
Validation loss: 2.7054403132847282

Epoch: 6| Step: 4
Training loss: 3.0385777888582797
Validation loss: 2.705671162212374

Epoch: 6| Step: 5
Training loss: 2.5756465211342676
Validation loss: 2.706190226522653

Epoch: 6| Step: 6
Training loss: 3.5813208554699787
Validation loss: 2.7077476688593767

Epoch: 6| Step: 7
Training loss: 2.7243979532666796
Validation loss: 2.7087970238890264

Epoch: 6| Step: 8
Training loss: 3.4421028531991826
Validation loss: 2.7080967183714693

Epoch: 6| Step: 9
Training loss: 2.7269908492043546
Validation loss: 2.7074366073376472

Epoch: 6| Step: 10
Training loss: 3.131990776837679
Validation loss: 2.70616605637429

Epoch: 6| Step: 11
Training loss: 3.150380029914763
Validation loss: 2.702715158201017

Epoch: 6| Step: 12
Training loss: 2.778214072825966
Validation loss: 2.704687449043532

Epoch: 6| Step: 13
Training loss: 2.6009513434963276
Validation loss: 2.7062737053755095

Epoch: 55| Step: 0
Training loss: 3.2296386537885953
Validation loss: 2.7103767047848173

Epoch: 6| Step: 1
Training loss: 2.8439753516479795
Validation loss: 2.710034597294294

Epoch: 6| Step: 2
Training loss: 2.6840351746723017
Validation loss: 2.7195053418589543

Epoch: 6| Step: 3
Training loss: 3.46502678182361
Validation loss: 2.7159196064140954

Epoch: 6| Step: 4
Training loss: 3.203296340453562
Validation loss: 2.7058607440132123

Epoch: 6| Step: 5
Training loss: 3.4453590026623586
Validation loss: 2.7057136840686855

Epoch: 6| Step: 6
Training loss: 3.1317355999576324
Validation loss: 2.7032202858496124

Epoch: 6| Step: 7
Training loss: 3.095340974725869
Validation loss: 2.6978651640402607

Epoch: 6| Step: 8
Training loss: 2.759470843576328
Validation loss: 2.699715094762705

Epoch: 6| Step: 9
Training loss: 2.53446266784687
Validation loss: 2.701506444565753

Epoch: 6| Step: 10
Training loss: 2.5211424414747134
Validation loss: 2.6986946988770284

Epoch: 6| Step: 11
Training loss: 3.1116706386623223
Validation loss: 2.6982765700460396

Epoch: 6| Step: 12
Training loss: 3.0770016861924296
Validation loss: 2.698094195414344

Epoch: 6| Step: 13
Training loss: 3.1448944071644687
Validation loss: 2.703130572785885

Epoch: 56| Step: 0
Training loss: 2.5203124735123312
Validation loss: 2.6994064410876444

Epoch: 6| Step: 1
Training loss: 2.940091714531361
Validation loss: 2.7025754399465

Epoch: 6| Step: 2
Training loss: 2.9779366752906307
Validation loss: 2.7008504540703986

Epoch: 6| Step: 3
Training loss: 2.6857707648150564
Validation loss: 2.709698909414522

Epoch: 6| Step: 4
Training loss: 3.0200286495037165
Validation loss: 2.722112494029017

Epoch: 6| Step: 5
Training loss: 2.6587114485728724
Validation loss: 2.7112986483746853

Epoch: 6| Step: 6
Training loss: 3.411337037393173
Validation loss: 2.721848945760939

Epoch: 6| Step: 7
Training loss: 2.5687458864350807
Validation loss: 2.719844227808587

Epoch: 6| Step: 8
Training loss: 3.8985358399733405
Validation loss: 2.7336515223674924

Epoch: 6| Step: 9
Training loss: 2.6342525901727396
Validation loss: 2.7022743686282196

Epoch: 6| Step: 10
Training loss: 2.817010526340197
Validation loss: 2.696704963146368

Epoch: 6| Step: 11
Training loss: 3.4266978378461403
Validation loss: 2.690650912890359

Epoch: 6| Step: 12
Training loss: 3.480113344210186
Validation loss: 2.693933842891389

Epoch: 6| Step: 13
Training loss: 2.8644192920300964
Validation loss: 2.6879451027310783

Epoch: 57| Step: 0
Training loss: 2.7130769318226644
Validation loss: 2.690597378578265

Epoch: 6| Step: 1
Training loss: 2.551224627670029
Validation loss: 2.691273442369321

Epoch: 6| Step: 2
Training loss: 2.980968508436648
Validation loss: 2.6893850203781864

Epoch: 6| Step: 3
Training loss: 3.504900362826984
Validation loss: 2.6894933791813544

Epoch: 6| Step: 4
Training loss: 2.6622369054192325
Validation loss: 2.6886074629871386

Epoch: 6| Step: 5
Training loss: 3.0774154232498185
Validation loss: 2.691251169161239

Epoch: 6| Step: 6
Training loss: 3.016565996320361
Validation loss: 2.6916667024528675

Epoch: 6| Step: 7
Training loss: 3.1133275046556084
Validation loss: 2.6906334604748157

Epoch: 6| Step: 8
Training loss: 3.2783627841119856
Validation loss: 2.6862485432481886

Epoch: 6| Step: 9
Training loss: 2.984221928850112
Validation loss: 2.6862663743989135

Epoch: 6| Step: 10
Training loss: 2.660815186749792
Validation loss: 2.6905135919926715

Epoch: 6| Step: 11
Training loss: 3.199912046177439
Validation loss: 2.6951195299273234

Epoch: 6| Step: 12
Training loss: 3.5330260545043592
Validation loss: 2.6992170052694666

Epoch: 6| Step: 13
Training loss: 2.6011161535859566
Validation loss: 2.7059405153883542

Epoch: 58| Step: 0
Training loss: 3.200079833465371
Validation loss: 2.710102876380693

Epoch: 6| Step: 1
Training loss: 3.2546034268688593
Validation loss: 2.725043789678358

Epoch: 6| Step: 2
Training loss: 3.336899915603243
Validation loss: 2.697954519119309

Epoch: 6| Step: 3
Training loss: 2.9191013165592405
Validation loss: 2.682243619289971

Epoch: 6| Step: 4
Training loss: 3.5568371655093016
Validation loss: 2.681106569053806

Epoch: 6| Step: 5
Training loss: 2.7116561069138334
Validation loss: 2.678605147743795

Epoch: 6| Step: 6
Training loss: 3.4788573502574005
Validation loss: 2.6791918465485183

Epoch: 6| Step: 7
Training loss: 2.3953596116700244
Validation loss: 2.680686414110548

Epoch: 6| Step: 8
Training loss: 2.3076783509932803
Validation loss: 2.68426796664915

Epoch: 6| Step: 9
Training loss: 3.599211813156369
Validation loss: 2.680655825484767

Epoch: 6| Step: 10
Training loss: 2.8018024024858863
Validation loss: 2.6845416188496682

Epoch: 6| Step: 11
Training loss: 2.6390524250242486
Validation loss: 2.6806234921101706

Epoch: 6| Step: 12
Training loss: 2.199209426670402
Validation loss: 2.6777564686368573

Epoch: 6| Step: 13
Training loss: 3.553792920572955
Validation loss: 2.684230121120601

Epoch: 59| Step: 0
Training loss: 2.9688091071418583
Validation loss: 2.6864480050866772

Epoch: 6| Step: 1
Training loss: 3.071498340942193
Validation loss: 2.689741104048512

Epoch: 6| Step: 2
Training loss: 2.5676988107583365
Validation loss: 2.6997206337547697

Epoch: 6| Step: 3
Training loss: 3.326083564593967
Validation loss: 2.7062400714432866

Epoch: 6| Step: 4
Training loss: 3.039112865354266
Validation loss: 2.7128419294918373

Epoch: 6| Step: 5
Training loss: 3.054768202708322
Validation loss: 2.705363190905311

Epoch: 6| Step: 6
Training loss: 3.2663117923139815
Validation loss: 2.689062578594875

Epoch: 6| Step: 7
Training loss: 3.237719294952877
Validation loss: 2.6824602844462277

Epoch: 6| Step: 8
Training loss: 3.0042049819964913
Validation loss: 2.681550222479311

Epoch: 6| Step: 9
Training loss: 3.1888209579031717
Validation loss: 2.674529286584639

Epoch: 6| Step: 10
Training loss: 2.8336061084563005
Validation loss: 2.676272465823177

Epoch: 6| Step: 11
Training loss: 2.7033254736501107
Validation loss: 2.672720122467453

Epoch: 6| Step: 12
Training loss: 2.5037232330613133
Validation loss: 2.675053795622528

Epoch: 6| Step: 13
Training loss: 3.3179200652314
Validation loss: 2.6748086151855093

Epoch: 60| Step: 0
Training loss: 3.229811097517465
Validation loss: 2.6730172441198072

Epoch: 6| Step: 1
Training loss: 3.8645561745127157
Validation loss: 2.673203386671321

Epoch: 6| Step: 2
Training loss: 3.4432422187422005
Validation loss: 2.6723013677223904

Epoch: 6| Step: 3
Training loss: 3.0715231801666856
Validation loss: 2.67238190294607

Epoch: 6| Step: 4
Training loss: 2.630424797794418
Validation loss: 2.6847947019871987

Epoch: 6| Step: 5
Training loss: 2.953685243133217
Validation loss: 2.6783462487969842

Epoch: 6| Step: 6
Training loss: 2.9503525733387925
Validation loss: 2.703436257962358

Epoch: 6| Step: 7
Training loss: 2.8587760923435024
Validation loss: 2.714992369157973

Epoch: 6| Step: 8
Training loss: 2.8420874797718283
Validation loss: 2.738249923814522

Epoch: 6| Step: 9
Training loss: 2.7901345124172043
Validation loss: 2.703276788870682

Epoch: 6| Step: 10
Training loss: 2.6875583731056145
Validation loss: 2.674910504884704

Epoch: 6| Step: 11
Training loss: 3.38278628156338
Validation loss: 2.6744965733654853

Epoch: 6| Step: 12
Training loss: 2.279585871480362
Validation loss: 2.663523337166191

Epoch: 6| Step: 13
Training loss: 2.543585495936864
Validation loss: 2.6610085182481353

Epoch: 61| Step: 0
Training loss: 3.362726287601646
Validation loss: 2.665740575901858

Epoch: 6| Step: 1
Training loss: 3.3824564193545803
Validation loss: 2.6675902742452746

Epoch: 6| Step: 2
Training loss: 2.801286170382102
Validation loss: 2.675956749181374

Epoch: 6| Step: 3
Training loss: 3.2198632546526116
Validation loss: 2.672084209831985

Epoch: 6| Step: 4
Training loss: 3.305370792243852
Validation loss: 2.670102613716448

Epoch: 6| Step: 5
Training loss: 2.904358935639045
Validation loss: 2.6691658367132782

Epoch: 6| Step: 6
Training loss: 2.9101806639600927
Validation loss: 2.660513828974803

Epoch: 6| Step: 7
Training loss: 2.8936388954271584
Validation loss: 2.660162002426914

Epoch: 6| Step: 8
Training loss: 3.120966024256039
Validation loss: 2.663288305524344

Epoch: 6| Step: 9
Training loss: 3.2708447369095266
Validation loss: 2.6805488892669165

Epoch: 6| Step: 10
Training loss: 2.293346575358699
Validation loss: 2.713605156821541

Epoch: 6| Step: 11
Training loss: 2.8432521174624297
Validation loss: 2.7752383130433462

Epoch: 6| Step: 12
Training loss: 2.8941154232773703
Validation loss: 2.753871536123366

Epoch: 6| Step: 13
Training loss: 2.4086047454097974
Validation loss: 2.72544180622776

Epoch: 62| Step: 0
Training loss: 2.245146072155427
Validation loss: 2.71624611327772

Epoch: 6| Step: 1
Training loss: 3.114893630953282
Validation loss: 2.683154942320091

Epoch: 6| Step: 2
Training loss: 2.3324213516370205
Validation loss: 2.670165702990682

Epoch: 6| Step: 3
Training loss: 3.047958416151998
Validation loss: 2.668826181196132

Epoch: 6| Step: 4
Training loss: 3.476024251697429
Validation loss: 2.670664989871569

Epoch: 6| Step: 5
Training loss: 2.8271039099472732
Validation loss: 2.6591850342378445

Epoch: 6| Step: 6
Training loss: 3.1628744273120195
Validation loss: 2.662428703780496

Epoch: 6| Step: 7
Training loss: 2.9153748694245927
Validation loss: 2.662929597272869

Epoch: 6| Step: 8
Training loss: 3.3394608127506844
Validation loss: 2.6620481393146727

Epoch: 6| Step: 9
Training loss: 2.7393116012432857
Validation loss: 2.6686467057473577

Epoch: 6| Step: 10
Training loss: 3.3881269824879485
Validation loss: 2.6607662849031706

Epoch: 6| Step: 11
Training loss: 2.896946279231111
Validation loss: 2.664933071518525

Epoch: 6| Step: 12
Training loss: 2.5477089481933746
Validation loss: 2.659917253566854

Epoch: 6| Step: 13
Training loss: 3.740890246223424
Validation loss: 2.6537909748776167

Epoch: 63| Step: 0
Training loss: 3.12019191885269
Validation loss: 2.6510017021795336

Epoch: 6| Step: 1
Training loss: 2.880871623384979
Validation loss: 2.65135706583842

Epoch: 6| Step: 2
Training loss: 3.2572310772758333
Validation loss: 2.6500796471899344

Epoch: 6| Step: 3
Training loss: 2.912397711926392
Validation loss: 2.649423002377011

Epoch: 6| Step: 4
Training loss: 2.9534175667328735
Validation loss: 2.6507295566263864

Epoch: 6| Step: 5
Training loss: 2.810394176923853
Validation loss: 2.682291399371027

Epoch: 6| Step: 6
Training loss: 3.1050271158063305
Validation loss: 2.7239210640374427

Epoch: 6| Step: 7
Training loss: 2.675461709649803
Validation loss: 2.7156289412987213

Epoch: 6| Step: 8
Training loss: 3.2032360522860377
Validation loss: 2.6969459837761427

Epoch: 6| Step: 9
Training loss: 3.295952979872775
Validation loss: 2.6817639400533864

Epoch: 6| Step: 10
Training loss: 2.703184799679493
Validation loss: 2.6629536371053217

Epoch: 6| Step: 11
Training loss: 2.907273307222034
Validation loss: 2.6550209884164664

Epoch: 6| Step: 12
Training loss: 2.9383696222543727
Validation loss: 2.6574901795814774

Epoch: 6| Step: 13
Training loss: 2.9847911923984296
Validation loss: 2.669671511147101

Epoch: 64| Step: 0
Training loss: 2.687227102219194
Validation loss: 2.668847907672095

Epoch: 6| Step: 1
Training loss: 2.7301318570666537
Validation loss: 2.6702919385112858

Epoch: 6| Step: 2
Training loss: 3.3213329946006542
Validation loss: 2.6749928524261875

Epoch: 6| Step: 3
Training loss: 3.0170915427375253
Validation loss: 2.672827798725148

Epoch: 6| Step: 4
Training loss: 3.2916936430650594
Validation loss: 2.6736501340269396

Epoch: 6| Step: 5
Training loss: 2.8670414775699435
Validation loss: 2.645356120148405

Epoch: 6| Step: 6
Training loss: 2.808221996677487
Validation loss: 2.6361931623153274

Epoch: 6| Step: 7
Training loss: 3.124865261987885
Validation loss: 2.6378408833311466

Epoch: 6| Step: 8
Training loss: 2.248531498113881
Validation loss: 2.638979080470917

Epoch: 6| Step: 9
Training loss: 3.1264678559474204
Validation loss: 2.6384956777891606

Epoch: 6| Step: 10
Training loss: 3.0843282245772463
Validation loss: 2.635377546963096

Epoch: 6| Step: 11
Training loss: 3.4352229119036473
Validation loss: 2.635315801021409

Epoch: 6| Step: 12
Training loss: 2.792947835777246
Validation loss: 2.635151838889064

Epoch: 6| Step: 13
Training loss: 3.2481309945229375
Validation loss: 2.635163223302467

Epoch: 65| Step: 0
Training loss: 2.6199628547772575
Validation loss: 2.640016368536796

Epoch: 6| Step: 1
Training loss: 3.0310756987177707
Validation loss: 2.643929876614421

Epoch: 6| Step: 2
Training loss: 3.314028117546923
Validation loss: 2.643348296822092

Epoch: 6| Step: 3
Training loss: 3.2176424361611193
Validation loss: 2.64964534393095

Epoch: 6| Step: 4
Training loss: 2.392525609276971
Validation loss: 2.6543801595148433

Epoch: 6| Step: 5
Training loss: 2.905095352997861
Validation loss: 2.648610866732381

Epoch: 6| Step: 6
Training loss: 2.699347265250758
Validation loss: 2.6526518181925174

Epoch: 6| Step: 7
Training loss: 2.519177883710841
Validation loss: 2.652047447090231

Epoch: 6| Step: 8
Training loss: 2.6385312780594155
Validation loss: 2.6422686145058907

Epoch: 6| Step: 9
Training loss: 2.7063868252389844
Validation loss: 2.644528966064068

Epoch: 6| Step: 10
Training loss: 3.563101332926642
Validation loss: 2.6544183330851

Epoch: 6| Step: 11
Training loss: 3.0984629173602105
Validation loss: 2.6443874347714806

Epoch: 6| Step: 12
Training loss: 3.690259127525287
Validation loss: 2.6477651916114753

Epoch: 6| Step: 13
Training loss: 2.8760874806178953
Validation loss: 2.6466078073276775

Epoch: 66| Step: 0
Training loss: 2.8644079721123323
Validation loss: 2.6488125065786225

Epoch: 6| Step: 1
Training loss: 2.7918673391004347
Validation loss: 2.6481458734668815

Epoch: 6| Step: 2
Training loss: 2.679750580781991
Validation loss: 2.639415908076114

Epoch: 6| Step: 3
Training loss: 3.0341679008360543
Validation loss: 2.6365069604402103

Epoch: 6| Step: 4
Training loss: 3.1286977634191864
Validation loss: 2.6417978032604874

Epoch: 6| Step: 5
Training loss: 2.584972558825879
Validation loss: 2.6421747807121236

Epoch: 6| Step: 6
Training loss: 3.1031442447614945
Validation loss: 2.662786601465589

Epoch: 6| Step: 7
Training loss: 2.6178113506998137
Validation loss: 2.668786506723023

Epoch: 6| Step: 8
Training loss: 3.3739776475727874
Validation loss: 2.6893009610389127

Epoch: 6| Step: 9
Training loss: 3.00135740724272
Validation loss: 2.7030374613689108

Epoch: 6| Step: 10
Training loss: 3.0686404890421377
Validation loss: 2.7139909019809516

Epoch: 6| Step: 11
Training loss: 2.365907429977792
Validation loss: 2.7611780591292043

Epoch: 6| Step: 12
Training loss: 3.4955054443474127
Validation loss: 2.784682676188473

Epoch: 6| Step: 13
Training loss: 3.89900500002685
Validation loss: 2.7266745111359785

Epoch: 67| Step: 0
Training loss: 2.8449382604996347
Validation loss: 2.653052669064691

Epoch: 6| Step: 1
Training loss: 2.733975888143841
Validation loss: 2.6285978322025274

Epoch: 6| Step: 2
Training loss: 2.795428536034009
Validation loss: 2.6546307371266042

Epoch: 6| Step: 3
Training loss: 3.328932973006445
Validation loss: 2.684072188165212

Epoch: 6| Step: 4
Training loss: 3.166328127650494
Validation loss: 2.729015646442036

Epoch: 6| Step: 5
Training loss: 3.7447633419460056
Validation loss: 2.7683902822821223

Epoch: 6| Step: 6
Training loss: 2.842967669850286
Validation loss: 2.73927348391269

Epoch: 6| Step: 7
Training loss: 2.8175698256281136
Validation loss: 2.7132811581984853

Epoch: 6| Step: 8
Training loss: 3.0709303993677928
Validation loss: 2.6599026316462173

Epoch: 6| Step: 9
Training loss: 2.797554146768488
Validation loss: 2.6423283652287943

Epoch: 6| Step: 10
Training loss: 3.034517866674458
Validation loss: 2.6350067499514886

Epoch: 6| Step: 11
Training loss: 2.8815832644546906
Validation loss: 2.628991966384223

Epoch: 6| Step: 12
Training loss: 2.79445846415905
Validation loss: 2.6465771628912553

Epoch: 6| Step: 13
Training loss: 3.586608425031486
Validation loss: 2.681644842855847

Epoch: 68| Step: 0
Training loss: 2.9282657683091324
Validation loss: 2.658520169873296

Epoch: 6| Step: 1
Training loss: 3.051117589094276
Validation loss: 2.642974334625829

Epoch: 6| Step: 2
Training loss: 2.881967973932222
Validation loss: 2.626566248240634

Epoch: 6| Step: 3
Training loss: 2.711659623855733
Validation loss: 2.6209973838272176

Epoch: 6| Step: 4
Training loss: 3.118484112675699
Validation loss: 2.6219178097577513

Epoch: 6| Step: 5
Training loss: 3.1176451535912384
Validation loss: 2.624968839617676

Epoch: 6| Step: 6
Training loss: 2.600105496246983
Validation loss: 2.621117694278885

Epoch: 6| Step: 7
Training loss: 3.149461451920596
Validation loss: 2.6227565413476945

Epoch: 6| Step: 8
Training loss: 3.026650153659806
Validation loss: 2.6223614074309367

Epoch: 6| Step: 9
Training loss: 2.745018956270062
Validation loss: 2.61915140852589

Epoch: 6| Step: 10
Training loss: 2.8476294580358306
Validation loss: 2.620163326647506

Epoch: 6| Step: 11
Training loss: 3.198512035371679
Validation loss: 2.6236376823746355

Epoch: 6| Step: 12
Training loss: 3.0750143531526364
Validation loss: 2.633939136655856

Epoch: 6| Step: 13
Training loss: 3.251480792227462
Validation loss: 2.6451832049510235

Epoch: 69| Step: 0
Training loss: 3.239030371735257
Validation loss: 2.6324310352583296

Epoch: 6| Step: 1
Training loss: 2.6697512211429344
Validation loss: 2.623589509319148

Epoch: 6| Step: 2
Training loss: 3.0836415695220913
Validation loss: 2.6206892218636044

Epoch: 6| Step: 3
Training loss: 3.3542011962124234
Validation loss: 2.6139411080317383

Epoch: 6| Step: 4
Training loss: 2.899547765263058
Validation loss: 2.616118963871692

Epoch: 6| Step: 5
Training loss: 3.707624189029303
Validation loss: 2.6125796532443957

Epoch: 6| Step: 6
Training loss: 2.40489673955908
Validation loss: 2.6150483461159886

Epoch: 6| Step: 7
Training loss: 2.708439272251344
Validation loss: 2.6136456501030656

Epoch: 6| Step: 8
Training loss: 2.8964730157713032
Validation loss: 2.612665536327329

Epoch: 6| Step: 9
Training loss: 3.0620800431028337
Validation loss: 2.6181487324922785

Epoch: 6| Step: 10
Training loss: 2.6911325966138073
Validation loss: 2.6226802611844042

Epoch: 6| Step: 11
Training loss: 2.9588528745532368
Validation loss: 2.6203366083081523

Epoch: 6| Step: 12
Training loss: 2.805478125365061
Validation loss: 2.628687828313007

Epoch: 6| Step: 13
Training loss: 2.3253538293168536
Validation loss: 2.634872840693284

Epoch: 70| Step: 0
Training loss: 3.5034056851374378
Validation loss: 2.654429859898402

Epoch: 6| Step: 1
Training loss: 3.1149674160693603
Validation loss: 2.637293440683129

Epoch: 6| Step: 2
Training loss: 3.083365534708767
Validation loss: 2.6256469333698993

Epoch: 6| Step: 3
Training loss: 2.707654916940295
Validation loss: 2.613053851113902

Epoch: 6| Step: 4
Training loss: 2.795494207592829
Validation loss: 2.6084896661443495

Epoch: 6| Step: 5
Training loss: 2.3816058996771385
Validation loss: 2.604122453539854

Epoch: 6| Step: 6
Training loss: 3.2792218434313805
Validation loss: 2.604690227094597

Epoch: 6| Step: 7
Training loss: 2.296678184329064
Validation loss: 2.6066037688833625

Epoch: 6| Step: 8
Training loss: 3.079492100788037
Validation loss: 2.606013159659381

Epoch: 6| Step: 9
Training loss: 3.0380766772500305
Validation loss: 2.606881034298236

Epoch: 6| Step: 10
Training loss: 2.742475967232378
Validation loss: 2.604176967149278

Epoch: 6| Step: 11
Training loss: 3.122279088900346
Validation loss: 2.6059212215873697

Epoch: 6| Step: 12
Training loss: 2.9685374936792353
Validation loss: 2.6044989349703425

Epoch: 6| Step: 13
Training loss: 3.1676070339602163
Validation loss: 2.604275652830104

Epoch: 71| Step: 0
Training loss: 2.7093582170400037
Validation loss: 2.6006110061071177

Epoch: 6| Step: 1
Training loss: 3.056943406778826
Validation loss: 2.601085188055714

Epoch: 6| Step: 2
Training loss: 2.812868306098313
Validation loss: 2.601778909692172

Epoch: 6| Step: 3
Training loss: 2.9414685003372996
Validation loss: 2.608482199752577

Epoch: 6| Step: 4
Training loss: 3.3462956800680934
Validation loss: 2.6283693366115926

Epoch: 6| Step: 5
Training loss: 3.155440576082366
Validation loss: 2.646534649880312

Epoch: 6| Step: 6
Training loss: 2.661497341002032
Validation loss: 2.670443394251029

Epoch: 6| Step: 7
Training loss: 2.8294640843089933
Validation loss: 2.6727834415433405

Epoch: 6| Step: 8
Training loss: 3.6096320783211033
Validation loss: 2.6661385406102154

Epoch: 6| Step: 9
Training loss: 2.60268490151886
Validation loss: 2.624847687005222

Epoch: 6| Step: 10
Training loss: 2.8028757518241108
Validation loss: 2.6076506704761924

Epoch: 6| Step: 11
Training loss: 2.651549365000429
Validation loss: 2.612499445134884

Epoch: 6| Step: 12
Training loss: 2.531379037087638
Validation loss: 2.599295134638718

Epoch: 6| Step: 13
Training loss: 3.60150623070706
Validation loss: 2.60277400984968

Epoch: 72| Step: 0
Training loss: 3.0110563942636537
Validation loss: 2.6059164571597866

Epoch: 6| Step: 1
Training loss: 3.704104137143186
Validation loss: 2.6189227328645006

Epoch: 6| Step: 2
Training loss: 2.9906623479251007
Validation loss: 2.636400056733944

Epoch: 6| Step: 3
Training loss: 2.7304231697174672
Validation loss: 2.6150083478735033

Epoch: 6| Step: 4
Training loss: 2.910561757349802
Validation loss: 2.6168567960956466

Epoch: 6| Step: 5
Training loss: 2.2527707312123946
Validation loss: 2.619183200924692

Epoch: 6| Step: 6
Training loss: 3.499957901837711
Validation loss: 2.6750942386898093

Epoch: 6| Step: 7
Training loss: 2.692219515813241
Validation loss: 2.6595574081784

Epoch: 6| Step: 8
Training loss: 2.401189064471984
Validation loss: 2.6058631349178802

Epoch: 6| Step: 9
Training loss: 2.6657453574660974
Validation loss: 2.595730623933692

Epoch: 6| Step: 10
Training loss: 3.3727757223996377
Validation loss: 2.5982127398271957

Epoch: 6| Step: 11
Training loss: 2.8909377470172037
Validation loss: 2.5977472775862274

Epoch: 6| Step: 12
Training loss: 3.5225276745046825
Validation loss: 2.6111793628782816

Epoch: 6| Step: 13
Training loss: 2.2354709098423133
Validation loss: 2.6119794899051803

Epoch: 73| Step: 0
Training loss: 2.5917061715830707
Validation loss: 2.6305711734541117

Epoch: 6| Step: 1
Training loss: 3.2262360266789702
Validation loss: 2.6520772491953166

Epoch: 6| Step: 2
Training loss: 2.9263987074280267
Validation loss: 2.650070818842668

Epoch: 6| Step: 3
Training loss: 3.1036187185421875
Validation loss: 2.6540231634590747

Epoch: 6| Step: 4
Training loss: 3.1545060882630533
Validation loss: 2.6413202372330438

Epoch: 6| Step: 5
Training loss: 2.775775364644892
Validation loss: 2.631541458023682

Epoch: 6| Step: 6
Training loss: 2.900078404123074
Validation loss: 2.613514153631093

Epoch: 6| Step: 7
Training loss: 2.604041399168136
Validation loss: 2.6024256705026705

Epoch: 6| Step: 8
Training loss: 3.018009014290606
Validation loss: 2.5980671806406024

Epoch: 6| Step: 9
Training loss: 3.180004507097613
Validation loss: 2.5956739674961264

Epoch: 6| Step: 10
Training loss: 2.976774753802425
Validation loss: 2.593182089078734

Epoch: 6| Step: 11
Training loss: 2.997603890063875
Validation loss: 2.594328189102372

Epoch: 6| Step: 12
Training loss: 2.952790094993678
Validation loss: 2.6045889438637864

Epoch: 6| Step: 13
Training loss: 2.918014995816181
Validation loss: 2.622345493884937

Epoch: 74| Step: 0
Training loss: 2.2533463918243575
Validation loss: 2.653109950617393

Epoch: 6| Step: 1
Training loss: 3.3155246097420505
Validation loss: 2.64682959404446

Epoch: 6| Step: 2
Training loss: 2.3162198433968992
Validation loss: 2.6646218387947465

Epoch: 6| Step: 3
Training loss: 3.357332824271691
Validation loss: 2.636526699812296

Epoch: 6| Step: 4
Training loss: 2.4350702940646567
Validation loss: 2.6131254049420236

Epoch: 6| Step: 5
Training loss: 2.658629126121436
Validation loss: 2.6013979990518488

Epoch: 6| Step: 6
Training loss: 2.954248608168782
Validation loss: 2.6029144452890582

Epoch: 6| Step: 7
Training loss: 2.9453133094847197
Validation loss: 2.599196424574262

Epoch: 6| Step: 8
Training loss: 3.4316335383837613
Validation loss: 2.6034644878792133

Epoch: 6| Step: 9
Training loss: 3.2770358680994853
Validation loss: 2.5971173300042025

Epoch: 6| Step: 10
Training loss: 3.1135086876322386
Validation loss: 2.600194152677522

Epoch: 6| Step: 11
Training loss: 3.002040169321966
Validation loss: 2.5959779185332095

Epoch: 6| Step: 12
Training loss: 2.729724700796524
Validation loss: 2.60422209321791

Epoch: 6| Step: 13
Training loss: 3.286307225126324
Validation loss: 2.6138235146023843

Epoch: 75| Step: 0
Training loss: 2.6154103180757264
Validation loss: 2.6185030828105647

Epoch: 6| Step: 1
Training loss: 2.6422671116002237
Validation loss: 2.608062014431223

Epoch: 6| Step: 2
Training loss: 3.2943698712364924
Validation loss: 2.5997327194684274

Epoch: 6| Step: 3
Training loss: 2.44214110034447
Validation loss: 2.603632958799361

Epoch: 6| Step: 4
Training loss: 2.4822979767836966
Validation loss: 2.592426382881774

Epoch: 6| Step: 5
Training loss: 3.065411798838773
Validation loss: 2.5870910010972694

Epoch: 6| Step: 6
Training loss: 2.8967482587460616
Validation loss: 2.584974689099099

Epoch: 6| Step: 7
Training loss: 3.2277745517343264
Validation loss: 2.5828912186637996

Epoch: 6| Step: 8
Training loss: 3.1249755858421318
Validation loss: 2.585485341701888

Epoch: 6| Step: 9
Training loss: 2.974378209890873
Validation loss: 2.583635414422368

Epoch: 6| Step: 10
Training loss: 2.703902292675792
Validation loss: 2.5806984922835823

Epoch: 6| Step: 11
Training loss: 3.5727263790132144
Validation loss: 2.5898213350069077

Epoch: 6| Step: 12
Training loss: 2.7471697721841197
Validation loss: 2.58287789815397

Epoch: 6| Step: 13
Training loss: 3.0944586048300655
Validation loss: 2.5904884553649805

Epoch: 76| Step: 0
Training loss: 2.3919243366943492
Validation loss: 2.595389136705292

Epoch: 6| Step: 1
Training loss: 3.0803984171311605
Validation loss: 2.595758185784189

Epoch: 6| Step: 2
Training loss: 3.436740305790264
Validation loss: 2.61217582341094

Epoch: 6| Step: 3
Training loss: 3.352585145237462
Validation loss: 2.6036940190436

Epoch: 6| Step: 4
Training loss: 3.6096341919415864
Validation loss: 2.5965174669927764

Epoch: 6| Step: 5
Training loss: 2.869542124307261
Validation loss: 2.5868510814851557

Epoch: 6| Step: 6
Training loss: 2.990945184642169
Validation loss: 2.59002411414326

Epoch: 6| Step: 7
Training loss: 2.9708642759133976
Validation loss: 2.5960836003048504

Epoch: 6| Step: 8
Training loss: 2.935655704798207
Validation loss: 2.5983842669513266

Epoch: 6| Step: 9
Training loss: 2.129309603776048
Validation loss: 2.608484884786277

Epoch: 6| Step: 10
Training loss: 2.302470754298924
Validation loss: 2.63711694430782

Epoch: 6| Step: 11
Training loss: 2.2826113884477546
Validation loss: 2.6585660571875396

Epoch: 6| Step: 12
Training loss: 3.569698756782197
Validation loss: 2.7269906433227247

Epoch: 6| Step: 13
Training loss: 2.3272655359950907
Validation loss: 2.622171078884451

Epoch: 77| Step: 0
Training loss: 2.572197683678235
Validation loss: 2.5926803842534145

Epoch: 6| Step: 1
Training loss: 2.348108130712482
Validation loss: 2.577554605230099

Epoch: 6| Step: 2
Training loss: 2.9032735041320032
Validation loss: 2.57631656167934

Epoch: 6| Step: 3
Training loss: 3.1575500530223284
Validation loss: 2.5838897064928728

Epoch: 6| Step: 4
Training loss: 3.3539509832250047
Validation loss: 2.5846273837723213

Epoch: 6| Step: 5
Training loss: 3.0741889690425364
Validation loss: 2.589069606678101

Epoch: 6| Step: 6
Training loss: 2.658415326933712
Validation loss: 2.592535132484166

Epoch: 6| Step: 7
Training loss: 2.9893723434446007
Validation loss: 2.589062449659195

Epoch: 6| Step: 8
Training loss: 2.326013721435432
Validation loss: 2.5934119737547734

Epoch: 6| Step: 9
Training loss: 3.7300146974984814
Validation loss: 2.5928714696045048

Epoch: 6| Step: 10
Training loss: 2.337819849662308
Validation loss: 2.5846378758594093

Epoch: 6| Step: 11
Training loss: 3.6848988814953527
Validation loss: 2.584504346044389

Epoch: 6| Step: 12
Training loss: 2.829400212382231
Validation loss: 2.5765738844322295

Epoch: 6| Step: 13
Training loss: 2.6125725439485503
Validation loss: 2.5739150242437834

Epoch: 78| Step: 0
Training loss: 2.5749984741206418
Validation loss: 2.5889469503821934

Epoch: 6| Step: 1
Training loss: 3.1029094394520955
Validation loss: 2.616873072184245

Epoch: 6| Step: 2
Training loss: 2.9649704816870255
Validation loss: 2.6509987289948893

Epoch: 6| Step: 3
Training loss: 3.6317775113359714
Validation loss: 2.6566043421974657

Epoch: 6| Step: 4
Training loss: 2.939259590545346
Validation loss: 2.612207843993018

Epoch: 6| Step: 5
Training loss: 3.0025782632275617
Validation loss: 2.5901159147419675

Epoch: 6| Step: 6
Training loss: 2.9489199455419004
Validation loss: 2.590029041429795

Epoch: 6| Step: 7
Training loss: 2.9275345279211327
Validation loss: 2.5902761133306966

Epoch: 6| Step: 8
Training loss: 3.301969091001563
Validation loss: 2.6037378449490776

Epoch: 6| Step: 9
Training loss: 2.706402946537544
Validation loss: 2.607650781569058

Epoch: 6| Step: 10
Training loss: 2.541669710084521
Validation loss: 2.6141725269805183

Epoch: 6| Step: 11
Training loss: 3.2126764568151454
Validation loss: 2.627766964969003

Epoch: 6| Step: 12
Training loss: 2.1964243181034604
Validation loss: 2.628454917376485

Epoch: 6| Step: 13
Training loss: 2.8883975132765483
Validation loss: 2.6261574019399143

Epoch: 79| Step: 0
Training loss: 3.5478014303246557
Validation loss: 2.6242379197133396

Epoch: 6| Step: 1
Training loss: 2.85526484689008
Validation loss: 2.617533297982146

Epoch: 6| Step: 2
Training loss: 2.647216335297646
Validation loss: 2.6020843554987314

Epoch: 6| Step: 3
Training loss: 2.8541923206225235
Validation loss: 2.6042417106070324

Epoch: 6| Step: 4
Training loss: 3.2913264006176646
Validation loss: 2.611172475583203

Epoch: 6| Step: 5
Training loss: 2.931110982302815
Validation loss: 2.611835145534084

Epoch: 6| Step: 6
Training loss: 3.424622429968273
Validation loss: 2.6284242105269784

Epoch: 6| Step: 7
Training loss: 3.081365283720635
Validation loss: 2.617719577265219

Epoch: 6| Step: 8
Training loss: 3.060368633131358
Validation loss: 2.62743207008024

Epoch: 6| Step: 9
Training loss: 2.3744554397280035
Validation loss: 2.6151222500826123

Epoch: 6| Step: 10
Training loss: 3.140538760087715
Validation loss: 2.608417928144822

Epoch: 6| Step: 11
Training loss: 2.166790286230011
Validation loss: 2.6076980192030494

Epoch: 6| Step: 12
Training loss: 2.699511897154676
Validation loss: 2.609478490677171

Epoch: 6| Step: 13
Training loss: 2.485911535946278
Validation loss: 2.6328283814395843

Epoch: 80| Step: 0
Training loss: 2.8885843858243643
Validation loss: 2.6165339288563403

Epoch: 6| Step: 1
Training loss: 3.1924285185241392
Validation loss: 2.607386828279918

Epoch: 6| Step: 2
Training loss: 3.417719717490271
Validation loss: 2.59855635200034

Epoch: 6| Step: 3
Training loss: 2.5711718574930305
Validation loss: 2.581637295812929

Epoch: 6| Step: 4
Training loss: 2.0061125330903957
Validation loss: 2.5662191639989262

Epoch: 6| Step: 5
Training loss: 3.578857080454504
Validation loss: 2.5643881987547905

Epoch: 6| Step: 6
Training loss: 3.052137945074993
Validation loss: 2.5627864594494385

Epoch: 6| Step: 7
Training loss: 3.104455785066933
Validation loss: 2.562682235604642

Epoch: 6| Step: 8
Training loss: 3.164149605764736
Validation loss: 2.564218964518016

Epoch: 6| Step: 9
Training loss: 2.372489807299957
Validation loss: 2.5616597219288386

Epoch: 6| Step: 10
Training loss: 2.985665726283095
Validation loss: 2.5654990971224585

Epoch: 6| Step: 11
Training loss: 2.7897004752222196
Validation loss: 2.56135453044282

Epoch: 6| Step: 12
Training loss: 2.6934293055982312
Validation loss: 2.562680968130492

Epoch: 6| Step: 13
Training loss: 2.626834591598537
Validation loss: 2.5638249611238346

Epoch: 81| Step: 0
Training loss: 2.8827360809866156
Validation loss: 2.5672555770696888

Epoch: 6| Step: 1
Training loss: 2.737007661205938
Validation loss: 2.5723658618084935

Epoch: 6| Step: 2
Training loss: 2.7291475737003346
Validation loss: 2.58368703628469

Epoch: 6| Step: 3
Training loss: 2.969122612307222
Validation loss: 2.5959598592658195

Epoch: 6| Step: 4
Training loss: 2.9900538553854625
Validation loss: 2.6020829052459526

Epoch: 6| Step: 5
Training loss: 2.4046582989224095
Validation loss: 2.6060353517663692

Epoch: 6| Step: 6
Training loss: 3.3661651829552914
Validation loss: 2.597086610957556

Epoch: 6| Step: 7
Training loss: 2.723602086848248
Validation loss: 2.585811144840431

Epoch: 6| Step: 8
Training loss: 3.3443967960155714
Validation loss: 2.5744257395617964

Epoch: 6| Step: 9
Training loss: 2.2418615655892666
Validation loss: 2.5782053219292345

Epoch: 6| Step: 10
Training loss: 3.0130028269412974
Validation loss: 2.5706436946737994

Epoch: 6| Step: 11
Training loss: 3.494312570007735
Validation loss: 2.5599529334389497

Epoch: 6| Step: 12
Training loss: 3.0593426056842796
Validation loss: 2.5609190901623298

Epoch: 6| Step: 13
Training loss: 2.2689796604742836
Validation loss: 2.564719588702131

Epoch: 82| Step: 0
Training loss: 2.6850894496800666
Validation loss: 2.564484330920043

Epoch: 6| Step: 1
Training loss: 2.9128520179820514
Validation loss: 2.562077971490369

Epoch: 6| Step: 2
Training loss: 2.8349494999553984
Validation loss: 2.5621266817188717

Epoch: 6| Step: 3
Training loss: 2.0799513514038117
Validation loss: 2.564022275343669

Epoch: 6| Step: 4
Training loss: 2.803369579043067
Validation loss: 2.5657934278570864

Epoch: 6| Step: 5
Training loss: 3.062730897256765
Validation loss: 2.568671237005608

Epoch: 6| Step: 6
Training loss: 3.1585761836618103
Validation loss: 2.5741256424901904

Epoch: 6| Step: 7
Training loss: 2.765520083059146
Validation loss: 2.5724222084163273

Epoch: 6| Step: 8
Training loss: 3.008986999280791
Validation loss: 2.580451553462925

Epoch: 6| Step: 9
Training loss: 3.1088152050853903
Validation loss: 2.5766246856430843

Epoch: 6| Step: 10
Training loss: 2.8157118365819116
Validation loss: 2.579243766942601

Epoch: 6| Step: 11
Training loss: 3.275361799683089
Validation loss: 2.6019054234746704

Epoch: 6| Step: 12
Training loss: 3.167615012329151
Validation loss: 2.5954382104985556

Epoch: 6| Step: 13
Training loss: 2.56927988940198
Validation loss: 2.5955021852035856

Epoch: 83| Step: 0
Training loss: 2.9234252733701767
Validation loss: 2.6282676500525968

Epoch: 6| Step: 1
Training loss: 2.967754478180638
Validation loss: 2.67630916232439

Epoch: 6| Step: 2
Training loss: 2.854339835675138
Validation loss: 2.6581142140296894

Epoch: 6| Step: 3
Training loss: 3.3991877988205346
Validation loss: 2.6660934153822144

Epoch: 6| Step: 4
Training loss: 2.6674329630214015
Validation loss: 2.6566662321727104

Epoch: 6| Step: 5
Training loss: 3.018193549449889
Validation loss: 2.6029990931251903

Epoch: 6| Step: 6
Training loss: 2.409900422947585
Validation loss: 2.5801675421180805

Epoch: 6| Step: 7
Training loss: 2.769333072345827
Validation loss: 2.5664717744758687

Epoch: 6| Step: 8
Training loss: 3.2176781508558494
Validation loss: 2.5522945079782144

Epoch: 6| Step: 9
Training loss: 2.8982494529737424
Validation loss: 2.5527479075344996

Epoch: 6| Step: 10
Training loss: 2.2640785990709325
Validation loss: 2.5572534891674756

Epoch: 6| Step: 11
Training loss: 3.0589130181388064
Validation loss: 2.5599516766307695

Epoch: 6| Step: 12
Training loss: 3.1713964542888484
Validation loss: 2.5574667235592616

Epoch: 6| Step: 13
Training loss: 2.888376712227524
Validation loss: 2.552296140201568

Epoch: 84| Step: 0
Training loss: 2.853659666004319
Validation loss: 2.551574763005634

Epoch: 6| Step: 1
Training loss: 2.937790551932926
Validation loss: 2.5511194571598437

Epoch: 6| Step: 2
Training loss: 3.1800986734112255
Validation loss: 2.554426317554394

Epoch: 6| Step: 3
Training loss: 3.289618438346561
Validation loss: 2.55848491042366

Epoch: 6| Step: 4
Training loss: 2.731249085170846
Validation loss: 2.5704162648524154

Epoch: 6| Step: 5
Training loss: 2.859676157616528
Validation loss: 2.586939830442112

Epoch: 6| Step: 6
Training loss: 3.5900977110250123
Validation loss: 2.617614924731203

Epoch: 6| Step: 7
Training loss: 2.001854989972777
Validation loss: 2.6409714732344045

Epoch: 6| Step: 8
Training loss: 2.8854055760212924
Validation loss: 2.6273284581762004

Epoch: 6| Step: 9
Training loss: 3.400728001912703
Validation loss: 2.5963205922095596

Epoch: 6| Step: 10
Training loss: 2.5632267363383763
Validation loss: 2.601128213268126

Epoch: 6| Step: 11
Training loss: 2.742829511210928
Validation loss: 2.594372974615053

Epoch: 6| Step: 12
Training loss: 2.6099217921265083
Validation loss: 2.582691447974404

Epoch: 6| Step: 13
Training loss: 2.777852844707467
Validation loss: 2.56852076186505

Epoch: 85| Step: 0
Training loss: 3.460763758997898
Validation loss: 2.5739095551565945

Epoch: 6| Step: 1
Training loss: 3.174037553186491
Validation loss: 2.55662755327438

Epoch: 6| Step: 2
Training loss: 2.9299228421099714
Validation loss: 2.55048595577848

Epoch: 6| Step: 3
Training loss: 3.448163226359813
Validation loss: 2.5543838947259236

Epoch: 6| Step: 4
Training loss: 2.8332919136460557
Validation loss: 2.555061077444812

Epoch: 6| Step: 5
Training loss: 2.3518625872687653
Validation loss: 2.558305789937795

Epoch: 6| Step: 6
Training loss: 2.587884544509366
Validation loss: 2.5688091925851584

Epoch: 6| Step: 7
Training loss: 2.5142922988099414
Validation loss: 2.574170781479322

Epoch: 6| Step: 8
Training loss: 2.384307292411873
Validation loss: 2.5869742474184787

Epoch: 6| Step: 9
Training loss: 3.1797317389332687
Validation loss: 2.597099501748272

Epoch: 6| Step: 10
Training loss: 2.6443013439230305
Validation loss: 2.6034326719141996

Epoch: 6| Step: 11
Training loss: 2.45279365780179
Validation loss: 2.601432038492135

Epoch: 6| Step: 12
Training loss: 3.0168596813634094
Validation loss: 2.590045454432756

Epoch: 6| Step: 13
Training loss: 3.543337498898957
Validation loss: 2.574819159277964

Epoch: 86| Step: 0
Training loss: 3.123407797507596
Validation loss: 2.5613510923746463

Epoch: 6| Step: 1
Training loss: 2.5002282038485166
Validation loss: 2.556732456099729

Epoch: 6| Step: 2
Training loss: 2.6816944136368526
Validation loss: 2.542865724182391

Epoch: 6| Step: 3
Training loss: 3.5799563855972214
Validation loss: 2.548008062583371

Epoch: 6| Step: 4
Training loss: 2.8158337650108702
Validation loss: 2.552624324460018

Epoch: 6| Step: 5
Training loss: 3.0242762621981503
Validation loss: 2.5485560052717946

Epoch: 6| Step: 6
Training loss: 3.100043474938503
Validation loss: 2.552805377074363

Epoch: 6| Step: 7
Training loss: 2.8174721741677367
Validation loss: 2.5520035437206583

Epoch: 6| Step: 8
Training loss: 2.9377459159344186
Validation loss: 2.56495178546266

Epoch: 6| Step: 9
Training loss: 2.951031947274209
Validation loss: 2.5712966239298973

Epoch: 6| Step: 10
Training loss: 3.359969117613059
Validation loss: 2.5845842802684613

Epoch: 6| Step: 11
Training loss: 2.8319372963941145
Validation loss: 2.5784221091406234

Epoch: 6| Step: 12
Training loss: 2.0658336632120355
Validation loss: 2.580031036488531

Epoch: 6| Step: 13
Training loss: 2.0500788185040246
Validation loss: 2.5835642782526476

Epoch: 87| Step: 0
Training loss: 2.6449903712250618
Validation loss: 2.5761876030719315

Epoch: 6| Step: 1
Training loss: 3.3106124106252954
Validation loss: 2.580019458485287

Epoch: 6| Step: 2
Training loss: 2.5119216860694125
Validation loss: 2.5864558959197215

Epoch: 6| Step: 3
Training loss: 2.8213182172526565
Validation loss: 2.580636758303549

Epoch: 6| Step: 4
Training loss: 2.2514597078429004
Validation loss: 2.5862589758576355

Epoch: 6| Step: 5
Training loss: 2.7425503830293785
Validation loss: 2.6042611585311928

Epoch: 6| Step: 6
Training loss: 3.594552920665224
Validation loss: 2.617412450578943

Epoch: 6| Step: 7
Training loss: 2.7211083892857806
Validation loss: 2.5963244915004626

Epoch: 6| Step: 8
Training loss: 2.824344363129781
Validation loss: 2.58535413435819

Epoch: 6| Step: 9
Training loss: 3.171463361816857
Validation loss: 2.5812781448814226

Epoch: 6| Step: 10
Training loss: 3.0644970046452147
Validation loss: 2.562202798539547

Epoch: 6| Step: 11
Training loss: 3.4134283458877186
Validation loss: 2.5607919940874253

Epoch: 6| Step: 12
Training loss: 2.23664132802665
Validation loss: 2.55950737580211

Epoch: 6| Step: 13
Training loss: 2.9071425841288843
Validation loss: 2.5554871539585755

Epoch: 88| Step: 0
Training loss: 2.8541141328826547
Validation loss: 2.551391521523825

Epoch: 6| Step: 1
Training loss: 2.4621146157094094
Validation loss: 2.552510674571924

Epoch: 6| Step: 2
Training loss: 2.904231529295975
Validation loss: 2.5516333666561253

Epoch: 6| Step: 3
Training loss: 2.9474455296318003
Validation loss: 2.542994156741056

Epoch: 6| Step: 4
Training loss: 3.1173010019083853
Validation loss: 2.5414414925554842

Epoch: 6| Step: 5
Training loss: 2.8359334646148975
Validation loss: 2.533146862389701

Epoch: 6| Step: 6
Training loss: 2.733360756372107
Validation loss: 2.538907203437126

Epoch: 6| Step: 7
Training loss: 2.372865822247053
Validation loss: 2.5366079709079568

Epoch: 6| Step: 8
Training loss: 3.436975889998738
Validation loss: 2.5390728189086738

Epoch: 6| Step: 9
Training loss: 2.5768616326295564
Validation loss: 2.552944438045675

Epoch: 6| Step: 10
Training loss: 2.7940647775708793
Validation loss: 2.5484865013640525

Epoch: 6| Step: 11
Training loss: 2.867229243086375
Validation loss: 2.5547992076888035

Epoch: 6| Step: 12
Training loss: 3.4361967910970983
Validation loss: 2.5505321222545

Epoch: 6| Step: 13
Training loss: 2.8514568152504576
Validation loss: 2.551025829157909

Epoch: 89| Step: 0
Training loss: 2.6515880289012106
Validation loss: 2.5613090144502597

Epoch: 6| Step: 1
Training loss: 3.4129416155556203
Validation loss: 2.5634232095302347

Epoch: 6| Step: 2
Training loss: 2.5537901069229014
Validation loss: 2.570463684086175

Epoch: 6| Step: 3
Training loss: 2.4475526146693367
Validation loss: 2.562519348535691

Epoch: 6| Step: 4
Training loss: 2.7027700554986898
Validation loss: 2.5881246877683872

Epoch: 6| Step: 5
Training loss: 3.4103005499968173
Validation loss: 2.6038903747344224

Epoch: 6| Step: 6
Training loss: 2.234448838514428
Validation loss: 2.5579891324281494

Epoch: 6| Step: 7
Training loss: 3.005338210941656
Validation loss: 2.540047889750875

Epoch: 6| Step: 8
Training loss: 2.5315574176748146
Validation loss: 2.536560446338028

Epoch: 6| Step: 9
Training loss: 2.909346868622807
Validation loss: 2.5316901645262417

Epoch: 6| Step: 10
Training loss: 2.994748446387628
Validation loss: 2.5372352546450303

Epoch: 6| Step: 11
Training loss: 3.3433241528441737
Validation loss: 2.5377320585651724

Epoch: 6| Step: 12
Training loss: 2.726062892840412
Validation loss: 2.5387224573917937

Epoch: 6| Step: 13
Training loss: 3.5331612874975975
Validation loss: 2.539926802546442

Epoch: 90| Step: 0
Training loss: 2.552591473082716
Validation loss: 2.545437199919436

Epoch: 6| Step: 1
Training loss: 2.5486038050834114
Validation loss: 2.544999011058661

Epoch: 6| Step: 2
Training loss: 2.552145903981581
Validation loss: 2.5595166026616183

Epoch: 6| Step: 3
Training loss: 2.6160716852404664
Validation loss: 2.5633346494896956

Epoch: 6| Step: 4
Training loss: 2.9684520371134626
Validation loss: 2.5700521403640373

Epoch: 6| Step: 5
Training loss: 3.281470881702432
Validation loss: 2.5694541152362667

Epoch: 6| Step: 6
Training loss: 2.312278530753633
Validation loss: 2.5503226144296516

Epoch: 6| Step: 7
Training loss: 3.084737887384
Validation loss: 2.548761771254663

Epoch: 6| Step: 8
Training loss: 3.040033258958884
Validation loss: 2.538624262068319

Epoch: 6| Step: 9
Training loss: 3.099374455742116
Validation loss: 2.54866760148233

Epoch: 6| Step: 10
Training loss: 3.1897787288828354
Validation loss: 2.5447444493636175

Epoch: 6| Step: 11
Training loss: 3.1093230123343147
Validation loss: 2.5500942107058617

Epoch: 6| Step: 12
Training loss: 2.9594320128607645
Validation loss: 2.5520177401228463

Epoch: 6| Step: 13
Training loss: 2.6390173719036003
Validation loss: 2.5767393125305778

Epoch: 91| Step: 0
Training loss: 3.391372387340662
Validation loss: 2.599154802503551

Epoch: 6| Step: 1
Training loss: 2.6230048817492078
Validation loss: 2.6132717754414765

Epoch: 6| Step: 2
Training loss: 3.092457819337215
Validation loss: 2.6125177031027764

Epoch: 6| Step: 3
Training loss: 2.6652839075702386
Validation loss: 2.629111678923621

Epoch: 6| Step: 4
Training loss: 2.6598934542319945
Validation loss: 2.605404814370338

Epoch: 6| Step: 5
Training loss: 3.0053042567837096
Validation loss: 2.5469235369613843

Epoch: 6| Step: 6
Training loss: 2.820189412566806
Validation loss: 2.5285594611946705

Epoch: 6| Step: 7
Training loss: 2.9395942527375336
Validation loss: 2.527300332918726

Epoch: 6| Step: 8
Training loss: 2.3588539204955667
Validation loss: 2.5330984622267017

Epoch: 6| Step: 9
Training loss: 2.8545949201599736
Validation loss: 2.529179471518324

Epoch: 6| Step: 10
Training loss: 2.9032084638836437
Validation loss: 2.532006235208542

Epoch: 6| Step: 11
Training loss: 2.9843387301972233
Validation loss: 2.5258857084353155

Epoch: 6| Step: 12
Training loss: 2.985536359333993
Validation loss: 2.5262430130881417

Epoch: 6| Step: 13
Training loss: 3.0572890498828684
Validation loss: 2.521741283709429

Epoch: 92| Step: 0
Training loss: 2.8256722452170804
Validation loss: 2.5197704535187513

Epoch: 6| Step: 1
Training loss: 3.0791432202125733
Validation loss: 2.522858617580896

Epoch: 6| Step: 2
Training loss: 3.064284602649956
Validation loss: 2.5215482099002235

Epoch: 6| Step: 3
Training loss: 2.9882628995045226
Validation loss: 2.5284442034019174

Epoch: 6| Step: 4
Training loss: 3.229240137720549
Validation loss: 2.5310028696899973

Epoch: 6| Step: 5
Training loss: 2.871830229467321
Validation loss: 2.5366077809044314

Epoch: 6| Step: 6
Training loss: 2.736684118471555
Validation loss: 2.561968278280227

Epoch: 6| Step: 7
Training loss: 2.489168928017838
Validation loss: 2.5797182183772036

Epoch: 6| Step: 8
Training loss: 2.5997223632470443
Validation loss: 2.5974712539417064

Epoch: 6| Step: 9
Training loss: 2.98065528935828
Validation loss: 2.5972578521774032

Epoch: 6| Step: 10
Training loss: 3.152850444775969
Validation loss: 2.589738334292527

Epoch: 6| Step: 11
Training loss: 2.210448409801459
Validation loss: 2.5592238209560034

Epoch: 6| Step: 12
Training loss: 2.8900711766226146
Validation loss: 2.5471304257023393

Epoch: 6| Step: 13
Training loss: 2.930390215202489
Validation loss: 2.5480686402583252

Epoch: 93| Step: 0
Training loss: 2.959169045908115
Validation loss: 2.544156933557118

Epoch: 6| Step: 1
Training loss: 2.8738835696406677
Validation loss: 2.56502327290436

Epoch: 6| Step: 2
Training loss: 2.4995276958642765
Validation loss: 2.58590237723418

Epoch: 6| Step: 3
Training loss: 2.956128727238033
Validation loss: 2.58372471041482

Epoch: 6| Step: 4
Training loss: 2.5904111398882663
Validation loss: 2.5981432667682767

Epoch: 6| Step: 5
Training loss: 3.262545360966011
Validation loss: 2.5616620061928614

Epoch: 6| Step: 6
Training loss: 3.073663101488222
Validation loss: 2.5339339467082533

Epoch: 6| Step: 7
Training loss: 2.998521599477272
Validation loss: 2.5231984470140576

Epoch: 6| Step: 8
Training loss: 3.0022110738232763
Validation loss: 2.521454205721767

Epoch: 6| Step: 9
Training loss: 2.2722838315977016
Validation loss: 2.5267086300861115

Epoch: 6| Step: 10
Training loss: 2.6493130927244612
Validation loss: 2.5203435576782396

Epoch: 6| Step: 11
Training loss: 2.83341981718428
Validation loss: 2.5282300919065355

Epoch: 6| Step: 12
Training loss: 3.102613909871879
Validation loss: 2.5290393501388015

Epoch: 6| Step: 13
Training loss: 3.0360600955729886
Validation loss: 2.5419121998027685

Epoch: 94| Step: 0
Training loss: 3.4873190446620588
Validation loss: 2.5492907844613475

Epoch: 6| Step: 1
Training loss: 2.7755316766255183
Validation loss: 2.558778352769954

Epoch: 6| Step: 2
Training loss: 2.650365437196085
Validation loss: 2.568037725862291

Epoch: 6| Step: 3
Training loss: 3.1431096056069836
Validation loss: 2.5599508193971072

Epoch: 6| Step: 4
Training loss: 3.052387903703075
Validation loss: 2.5550096688839052

Epoch: 6| Step: 5
Training loss: 2.7153528847568458
Validation loss: 2.549628252208816

Epoch: 6| Step: 6
Training loss: 2.568740874411159
Validation loss: 2.5468917837067426

Epoch: 6| Step: 7
Training loss: 3.04143112176367
Validation loss: 2.5452480961913992

Epoch: 6| Step: 8
Training loss: 2.629771754727796
Validation loss: 2.5275671938556354

Epoch: 6| Step: 9
Training loss: 2.9120363447625053
Validation loss: 2.547622678621515

Epoch: 6| Step: 10
Training loss: 2.110752249494558
Validation loss: 2.551183438856967

Epoch: 6| Step: 11
Training loss: 3.1306977780641305
Validation loss: 2.560757848918937

Epoch: 6| Step: 12
Training loss: 2.541330492477724
Validation loss: 2.5812920501771113

Epoch: 6| Step: 13
Training loss: 3.064691499054187
Validation loss: 2.5940719485731365

Epoch: 95| Step: 0
Training loss: 2.887601023306337
Validation loss: 2.6046255193922803

Epoch: 6| Step: 1
Training loss: 2.3859860158608015
Validation loss: 2.636210995562008

Epoch: 6| Step: 2
Training loss: 3.029931164957363
Validation loss: 2.671420549182943

Epoch: 6| Step: 3
Training loss: 2.259507753896187
Validation loss: 2.6642780514465976

Epoch: 6| Step: 4
Training loss: 2.813506391394287
Validation loss: 2.6422605925308216

Epoch: 6| Step: 5
Training loss: 3.257334136604692
Validation loss: 2.608865903536366

Epoch: 6| Step: 6
Training loss: 2.9924085251571357
Validation loss: 2.566917754169173

Epoch: 6| Step: 7
Training loss: 2.5459311204809048
Validation loss: 2.5443929484089964

Epoch: 6| Step: 8
Training loss: 3.340957473753694
Validation loss: 2.5305938437417623

Epoch: 6| Step: 9
Training loss: 3.369208276041811
Validation loss: 2.5245713879278795

Epoch: 6| Step: 10
Training loss: 2.8517691759434753
Validation loss: 2.52517121903204

Epoch: 6| Step: 11
Training loss: 2.892789123381363
Validation loss: 2.5218016790813484

Epoch: 6| Step: 12
Training loss: 2.8216299430078213
Validation loss: 2.5239774120733234

Epoch: 6| Step: 13
Training loss: 2.3663723489493513
Validation loss: 2.523917255660945

Epoch: 96| Step: 0
Training loss: 2.843743795870207
Validation loss: 2.536251098983201

Epoch: 6| Step: 1
Training loss: 2.995949076475675
Validation loss: 2.5421122283645783

Epoch: 6| Step: 2
Training loss: 3.375388794156719
Validation loss: 2.5516554751096865

Epoch: 6| Step: 3
Training loss: 2.894575399250011
Validation loss: 2.5710405797871063

Epoch: 6| Step: 4
Training loss: 2.157862626915389
Validation loss: 2.57848112518583

Epoch: 6| Step: 5
Training loss: 3.04551736955789
Validation loss: 2.5647554813448212

Epoch: 6| Step: 6
Training loss: 2.720307528837987
Validation loss: 2.55587869934115

Epoch: 6| Step: 7
Training loss: 2.8396437625700908
Validation loss: 2.549461251977235

Epoch: 6| Step: 8
Training loss: 2.771374518144041
Validation loss: 2.5380989269475687

Epoch: 6| Step: 9
Training loss: 3.308943512679686
Validation loss: 2.531916103430513

Epoch: 6| Step: 10
Training loss: 1.9819776817243102
Validation loss: 2.557059271930888

Epoch: 6| Step: 11
Training loss: 3.007090613199684
Validation loss: 2.5465498882270716

Epoch: 6| Step: 12
Training loss: 2.9589685823629712
Validation loss: 2.5461717665586736

Epoch: 6| Step: 13
Training loss: 2.67788021433405
Validation loss: 2.5417276288055644

Epoch: 97| Step: 0
Training loss: 2.9837052956960983
Validation loss: 2.517936108108911

Epoch: 6| Step: 1
Training loss: 2.5161048952685063
Validation loss: 2.513267466646905

Epoch: 6| Step: 2
Training loss: 3.2549491758817437
Validation loss: 2.5065848015736227

Epoch: 6| Step: 3
Training loss: 2.818926272410236
Validation loss: 2.502091201748406

Epoch: 6| Step: 4
Training loss: 3.1190651040677375
Validation loss: 2.506155484845489

Epoch: 6| Step: 5
Training loss: 3.102752687798076
Validation loss: 2.5053791247763533

Epoch: 6| Step: 6
Training loss: 2.9922673386562186
Validation loss: 2.506386062782562

Epoch: 6| Step: 7
Training loss: 2.185464838719511
Validation loss: 2.5124157946108054

Epoch: 6| Step: 8
Training loss: 2.6940945292131873
Validation loss: 2.506264533757022

Epoch: 6| Step: 9
Training loss: 2.8721551503217113
Validation loss: 2.5118430382193586

Epoch: 6| Step: 10
Training loss: 3.1871542649603244
Validation loss: 2.5140219199428553

Epoch: 6| Step: 11
Training loss: 2.795588021429317
Validation loss: 2.5221335141984245

Epoch: 6| Step: 12
Training loss: 2.3659808920429706
Validation loss: 2.5243862680633185

Epoch: 6| Step: 13
Training loss: 2.5981207181387336
Validation loss: 2.5235645258789265

Epoch: 98| Step: 0
Training loss: 2.7033500798181382
Validation loss: 2.5252318541925907

Epoch: 6| Step: 1
Training loss: 2.949256906830979
Validation loss: 2.5256601227936053

Epoch: 6| Step: 2
Training loss: 2.8589273738169294
Validation loss: 2.520011040259217

Epoch: 6| Step: 3
Training loss: 1.8229007901908145
Validation loss: 2.5162159072806736

Epoch: 6| Step: 4
Training loss: 3.385160763189713
Validation loss: 2.5172283383042777

Epoch: 6| Step: 5
Training loss: 2.8371451672756036
Validation loss: 2.5024847070612837

Epoch: 6| Step: 6
Training loss: 2.353330030285874
Validation loss: 2.5040191880372613

Epoch: 6| Step: 7
Training loss: 2.86003397034431
Validation loss: 2.511254196216163

Epoch: 6| Step: 8
Training loss: 2.953695090837277
Validation loss: 2.51284433967461

Epoch: 6| Step: 9
Training loss: 2.8380841834370223
Validation loss: 2.514724244073139

Epoch: 6| Step: 10
Training loss: 2.9105180144271032
Validation loss: 2.5212281193493165

Epoch: 6| Step: 11
Training loss: 3.215338519414961
Validation loss: 2.53241822794536

Epoch: 6| Step: 12
Training loss: 2.965825778929766
Validation loss: 2.5426775191213165

Epoch: 6| Step: 13
Training loss: 2.776264737574017
Validation loss: 2.5495751443812145

Epoch: 99| Step: 0
Training loss: 2.5852365148723995
Validation loss: 2.549004922425101

Epoch: 6| Step: 1
Training loss: 2.9228975679222695
Validation loss: 2.5489938190121535

Epoch: 6| Step: 2
Training loss: 2.807351040374467
Validation loss: 2.5206228514295774

Epoch: 6| Step: 3
Training loss: 2.2857905102690266
Validation loss: 2.5135652260520454

Epoch: 6| Step: 4
Training loss: 3.3318175843257336
Validation loss: 2.510708377640629

Epoch: 6| Step: 5
Training loss: 2.921738728492129
Validation loss: 2.5140097218218145

Epoch: 6| Step: 6
Training loss: 2.38127271586319
Validation loss: 2.518928395548696

Epoch: 6| Step: 7
Training loss: 2.2681128161458672
Validation loss: 2.510650682747639

Epoch: 6| Step: 8
Training loss: 3.3675582221420615
Validation loss: 2.5144648810923167

Epoch: 6| Step: 9
Training loss: 3.2010787754823
Validation loss: 2.521537357186503

Epoch: 6| Step: 10
Training loss: 2.7537184630954776
Validation loss: 2.514977260857761

Epoch: 6| Step: 11
Training loss: 2.7069646653742936
Validation loss: 2.528389937810846

Epoch: 6| Step: 12
Training loss: 3.2499809264577024
Validation loss: 2.5325353770194416

Epoch: 6| Step: 13
Training loss: 2.4708315608600953
Validation loss: 2.5273743064463305

Epoch: 100| Step: 0
Training loss: 3.166928347433184
Validation loss: 2.535157121685068

Epoch: 6| Step: 1
Training loss: 2.681129356817892
Validation loss: 2.5274621698936124

Epoch: 6| Step: 2
Training loss: 2.9855839542460636
Validation loss: 2.5295037586652134

Epoch: 6| Step: 3
Training loss: 2.3536738552229903
Validation loss: 2.5196785359355323

Epoch: 6| Step: 4
Training loss: 2.540020477332526
Validation loss: 2.525023674770153

Epoch: 6| Step: 5
Training loss: 3.0397493424727435
Validation loss: 2.5208546159524343

Epoch: 6| Step: 6
Training loss: 2.6882845598381704
Validation loss: 2.531121991464402

Epoch: 6| Step: 7
Training loss: 2.835176728406684
Validation loss: 2.5303828137591506

Epoch: 6| Step: 8
Training loss: 2.80222971556298
Validation loss: 2.5295292950752692

Epoch: 6| Step: 9
Training loss: 2.5091954871323328
Validation loss: 2.5422812300007975

Epoch: 6| Step: 10
Training loss: 2.918715456772472
Validation loss: 2.542290984251429

Epoch: 6| Step: 11
Training loss: 2.6989306946230878
Validation loss: 2.5481026093675

Epoch: 6| Step: 12
Training loss: 3.2254558448069504
Validation loss: 2.55409900070652

Epoch: 6| Step: 13
Training loss: 3.216979938201438
Validation loss: 2.5757405291579936

Epoch: 101| Step: 0
Training loss: 2.2727471316076846
Validation loss: 2.5373751416583246

Epoch: 6| Step: 1
Training loss: 3.1915705999220996
Validation loss: 2.513483860452395

Epoch: 6| Step: 2
Training loss: 2.6831119998925286
Validation loss: 2.4992629205438313

Epoch: 6| Step: 3
Training loss: 2.2795959119589746
Validation loss: 2.5035621563156965

Epoch: 6| Step: 4
Training loss: 2.759313158873804
Validation loss: 2.4997405240548245

Epoch: 6| Step: 5
Training loss: 3.338090045790945
Validation loss: 2.5019742522875394

Epoch: 6| Step: 6
Training loss: 3.224628598613959
Validation loss: 2.5079894360112776

Epoch: 6| Step: 7
Training loss: 2.3196768869462754
Validation loss: 2.499141111809454

Epoch: 6| Step: 8
Training loss: 2.698266486584172
Validation loss: 2.5005544057998565

Epoch: 6| Step: 9
Training loss: 3.0041367302265862
Validation loss: 2.502123992806228

Epoch: 6| Step: 10
Training loss: 3.4844060648401505
Validation loss: 2.5087079742561134

Epoch: 6| Step: 11
Training loss: 2.7328783571520767
Validation loss: 2.5285754296593765

Epoch: 6| Step: 12
Training loss: 2.6691700589145237
Validation loss: 2.548534541889995

Epoch: 6| Step: 13
Training loss: 2.8353580271655137
Validation loss: 2.5724064692813267

Epoch: 102| Step: 0
Training loss: 2.9965105425851135
Validation loss: 2.6104005288390293

Epoch: 6| Step: 1
Training loss: 2.834483212526101
Validation loss: 2.59588796165417

Epoch: 6| Step: 2
Training loss: 2.558773774081779
Validation loss: 2.5886745052767797

Epoch: 6| Step: 3
Training loss: 3.159631409696644
Validation loss: 2.5666042058056995

Epoch: 6| Step: 4
Training loss: 3.1669334667312854
Validation loss: 2.527223046193403

Epoch: 6| Step: 5
Training loss: 2.671509031697106
Validation loss: 2.5012143764492807

Epoch: 6| Step: 6
Training loss: 3.091046008989109
Validation loss: 2.5005826199399315

Epoch: 6| Step: 7
Training loss: 2.525518451001714
Validation loss: 2.5023623441606753

Epoch: 6| Step: 8
Training loss: 3.001334529323444
Validation loss: 2.501121173197338

Epoch: 6| Step: 9
Training loss: 2.935112652671872
Validation loss: 2.502786181029785

Epoch: 6| Step: 10
Training loss: 2.121229304413329
Validation loss: 2.508429457174808

Epoch: 6| Step: 11
Training loss: 2.4771272514776927
Validation loss: 2.507718975623443

Epoch: 6| Step: 12
Training loss: 3.008741042247032
Validation loss: 2.5134572486634887

Epoch: 6| Step: 13
Training loss: 3.1864724092317074
Validation loss: 2.524521228012496

Epoch: 103| Step: 0
Training loss: 2.8081499154916885
Validation loss: 2.5302573156140626

Epoch: 6| Step: 1
Training loss: 2.3892074071974023
Validation loss: 2.5730527490010062

Epoch: 6| Step: 2
Training loss: 3.337990051181565
Validation loss: 2.608930790050113

Epoch: 6| Step: 3
Training loss: 2.665192216307432
Validation loss: 2.6241956123908508

Epoch: 6| Step: 4
Training loss: 2.630696790807252
Validation loss: 2.6318657921634565

Epoch: 6| Step: 5
Training loss: 2.838214223098089
Validation loss: 2.6139542236601288

Epoch: 6| Step: 6
Training loss: 2.7299162342508994
Validation loss: 2.587338783584473

Epoch: 6| Step: 7
Training loss: 3.357594998763284
Validation loss: 2.5375351964858646

Epoch: 6| Step: 8
Training loss: 3.1279482857314713
Validation loss: 2.519236112954115

Epoch: 6| Step: 9
Training loss: 1.9993784653972562
Validation loss: 2.5011031936677974

Epoch: 6| Step: 10
Training loss: 3.3731381967769516
Validation loss: 2.4955345234877857

Epoch: 6| Step: 11
Training loss: 2.9772839410320513
Validation loss: 2.4986998735720176

Epoch: 6| Step: 12
Training loss: 2.391070953860735
Validation loss: 2.4967597574753255

Epoch: 6| Step: 13
Training loss: 2.6823498370828767
Validation loss: 2.4973446115782516

Epoch: 104| Step: 0
Training loss: 3.198707772647405
Validation loss: 2.494419989313856

Epoch: 6| Step: 1
Training loss: 2.8020580153520958
Validation loss: 2.498261955053899

Epoch: 6| Step: 2
Training loss: 2.7906838200469215
Validation loss: 2.502472889115656

Epoch: 6| Step: 3
Training loss: 2.532022240660075
Validation loss: 2.503626384692121

Epoch: 6| Step: 4
Training loss: 2.6449260107122723
Validation loss: 2.4987666030589337

Epoch: 6| Step: 5
Training loss: 2.642341101280059
Validation loss: 2.5168795399100943

Epoch: 6| Step: 6
Training loss: 2.5913335735352665
Validation loss: 2.52369311075718

Epoch: 6| Step: 7
Training loss: 3.297789821888379
Validation loss: 2.5342351072761793

Epoch: 6| Step: 8
Training loss: 2.913014077589628
Validation loss: 2.558189101457554

Epoch: 6| Step: 9
Training loss: 2.724470412562901
Validation loss: 2.593933278880614

Epoch: 6| Step: 10
Training loss: 2.2687064426749153
Validation loss: 2.5691778637980773

Epoch: 6| Step: 11
Training loss: 2.6969734713190596
Validation loss: 2.5461548582885003

Epoch: 6| Step: 12
Training loss: 3.2498559186248994
Validation loss: 2.5274184688050862

Epoch: 6| Step: 13
Training loss: 2.9473615647178866
Validation loss: 2.507023559939327

Epoch: 105| Step: 0
Training loss: 2.396743026740762
Validation loss: 2.506932959459588

Epoch: 6| Step: 1
Training loss: 3.2116897333013292
Validation loss: 2.497417914655769

Epoch: 6| Step: 2
Training loss: 2.8475889347110597
Validation loss: 2.488367926427861

Epoch: 6| Step: 3
Training loss: 3.101489625934653
Validation loss: 2.4878147093741836

Epoch: 6| Step: 4
Training loss: 2.5073050582733085
Validation loss: 2.4878306868986604

Epoch: 6| Step: 5
Training loss: 3.0979801119319315
Validation loss: 2.4862243864245044

Epoch: 6| Step: 6
Training loss: 2.9891029175709316
Validation loss: 2.4924872325469383

Epoch: 6| Step: 7
Training loss: 2.136383867260234
Validation loss: 2.493870362981271

Epoch: 6| Step: 8
Training loss: 3.033133324816646
Validation loss: 2.5110582333442677

Epoch: 6| Step: 9
Training loss: 2.7648819609516075
Validation loss: 2.5277293352484635

Epoch: 6| Step: 10
Training loss: 2.861871848670106
Validation loss: 2.5340052651324743

Epoch: 6| Step: 11
Training loss: 2.865712631033857
Validation loss: 2.548446563473013

Epoch: 6| Step: 12
Training loss: 2.9237579969253544
Validation loss: 2.539307897934029

Epoch: 6| Step: 13
Training loss: 2.2593000850683045
Validation loss: 2.5348800968127447

Epoch: 106| Step: 0
Training loss: 2.847159720461063
Validation loss: 2.5271432098414515

Epoch: 6| Step: 1
Training loss: 3.1156442593789455
Validation loss: 2.5097679049114157

Epoch: 6| Step: 2
Training loss: 2.4781317808195573
Validation loss: 2.4908470148832875

Epoch: 6| Step: 3
Training loss: 2.938415709271437
Validation loss: 2.4861640950500408

Epoch: 6| Step: 4
Training loss: 2.873223294793777
Validation loss: 2.4796126383251087

Epoch: 6| Step: 5
Training loss: 2.5714841450635055
Validation loss: 2.474571973325044

Epoch: 6| Step: 6
Training loss: 3.053140936568806
Validation loss: 2.4820758543601937

Epoch: 6| Step: 7
Training loss: 3.1420391182409935
Validation loss: 2.4829563856219923

Epoch: 6| Step: 8
Training loss: 2.8456682714921206
Validation loss: 2.4901824424583685

Epoch: 6| Step: 9
Training loss: 1.9009127081063801
Validation loss: 2.494308475924867

Epoch: 6| Step: 10
Training loss: 3.2425178083814585
Validation loss: 2.510099773364574

Epoch: 6| Step: 11
Training loss: 2.560040200484063
Validation loss: 2.5258151386779364

Epoch: 6| Step: 12
Training loss: 2.9133957823717003
Validation loss: 2.534549506729184

Epoch: 6| Step: 13
Training loss: 2.397757467977973
Validation loss: 2.5311183968659963

Epoch: 107| Step: 0
Training loss: 2.808324044850852
Validation loss: 2.518999537339563

Epoch: 6| Step: 1
Training loss: 2.976261313912373
Validation loss: 2.5169748933951475

Epoch: 6| Step: 2
Training loss: 2.2795441402672503
Validation loss: 2.5068647252114107

Epoch: 6| Step: 3
Training loss: 3.048539709492327
Validation loss: 2.5035629816573026

Epoch: 6| Step: 4
Training loss: 2.5516429806670353
Validation loss: 2.498478953833559

Epoch: 6| Step: 5
Training loss: 3.285336810399152
Validation loss: 2.4956260149324474

Epoch: 6| Step: 6
Training loss: 3.3430627134364737
Validation loss: 2.49336125900871

Epoch: 6| Step: 7
Training loss: 1.9444780513341777
Validation loss: 2.4901692638052486

Epoch: 6| Step: 8
Training loss: 2.7796584300965095
Validation loss: 2.4741847616740418

Epoch: 6| Step: 9
Training loss: 2.5573535505111553
Validation loss: 2.490127280254996

Epoch: 6| Step: 10
Training loss: 2.6010422744923405
Validation loss: 2.494106889204389

Epoch: 6| Step: 11
Training loss: 3.023246660542834
Validation loss: 2.497791218992912

Epoch: 6| Step: 12
Training loss: 2.909828526009952
Validation loss: 2.5105134433628598

Epoch: 6| Step: 13
Training loss: 2.624185254041352
Validation loss: 2.51721494377394

Epoch: 108| Step: 0
Training loss: 2.8397134491255507
Validation loss: 2.518473003650297

Epoch: 6| Step: 1
Training loss: 2.887940681154766
Validation loss: 2.5129537094071956

Epoch: 6| Step: 2
Training loss: 3.4113096403763197
Validation loss: 2.515457025931413

Epoch: 6| Step: 3
Training loss: 2.9122118762351343
Validation loss: 2.4829045656941706

Epoch: 6| Step: 4
Training loss: 2.4893074255182372
Validation loss: 2.483312115148807

Epoch: 6| Step: 5
Training loss: 3.239964469903235
Validation loss: 2.475519489308254

Epoch: 6| Step: 6
Training loss: 2.708286451276295
Validation loss: 2.4755926277860025

Epoch: 6| Step: 7
Training loss: 2.5415971048143495
Validation loss: 2.4736314030134183

Epoch: 6| Step: 8
Training loss: 2.4114037350322812
Validation loss: 2.4749875598792466

Epoch: 6| Step: 9
Training loss: 3.268759213611462
Validation loss: 2.4811803423463963

Epoch: 6| Step: 10
Training loss: 2.740228023508097
Validation loss: 2.4784610626923502

Epoch: 6| Step: 11
Training loss: 2.7837717860670756
Validation loss: 2.4789148480101497

Epoch: 6| Step: 12
Training loss: 2.2371314059505387
Validation loss: 2.4851996715170794

Epoch: 6| Step: 13
Training loss: 2.540413740507917
Validation loss: 2.4985867156183956

Epoch: 109| Step: 0
Training loss: 2.898582269800995
Validation loss: 2.5229002048070566

Epoch: 6| Step: 1
Training loss: 3.1358258222263093
Validation loss: 2.535942750087965

Epoch: 6| Step: 2
Training loss: 2.297328774398794
Validation loss: 2.5543266825068254

Epoch: 6| Step: 3
Training loss: 2.427358903644212
Validation loss: 2.5531069424071045

Epoch: 6| Step: 4
Training loss: 2.489281182461894
Validation loss: 2.5698028277565177

Epoch: 6| Step: 5
Training loss: 3.302696548146036
Validation loss: 2.5962847478837867

Epoch: 6| Step: 6
Training loss: 3.049709156114669
Validation loss: 2.591306886672972

Epoch: 6| Step: 7
Training loss: 2.573466583254376
Validation loss: 2.56147841692418

Epoch: 6| Step: 8
Training loss: 2.925916518380895
Validation loss: 2.511088499959051

Epoch: 6| Step: 9
Training loss: 2.8032084951224134
Validation loss: 2.4934486451128857

Epoch: 6| Step: 10
Training loss: 2.8788370152589056
Validation loss: 2.4777067250763736

Epoch: 6| Step: 11
Training loss: 2.798968591778924
Validation loss: 2.4760573510433064

Epoch: 6| Step: 12
Training loss: 2.628885663024193
Validation loss: 2.4921368662490284

Epoch: 6| Step: 13
Training loss: 2.888728328872798
Validation loss: 2.491297019089701

Epoch: 110| Step: 0
Training loss: 2.4857434996092436
Validation loss: 2.4806801465986505

Epoch: 6| Step: 1
Training loss: 3.0203677816211196
Validation loss: 2.4826868283003516

Epoch: 6| Step: 2
Training loss: 2.8209719745443325
Validation loss: 2.484518170721798

Epoch: 6| Step: 3
Training loss: 2.6523549861978952
Validation loss: 2.4828702962256353

Epoch: 6| Step: 4
Training loss: 2.981534234978385
Validation loss: 2.4816883760698536

Epoch: 6| Step: 5
Training loss: 2.8171318061388573
Validation loss: 2.478256871086305

Epoch: 6| Step: 6
Training loss: 2.672053370182611
Validation loss: 2.485595882975174

Epoch: 6| Step: 7
Training loss: 2.87374319718706
Validation loss: 2.507432884036464

Epoch: 6| Step: 8
Training loss: 2.4656502300562257
Validation loss: 2.532787376199697

Epoch: 6| Step: 9
Training loss: 2.8478126430605624
Validation loss: 2.583731723463597

Epoch: 6| Step: 10
Training loss: 2.9709461320932435
Validation loss: 2.587690089066233

Epoch: 6| Step: 11
Training loss: 2.7071542863284637
Validation loss: 2.5759979004953597

Epoch: 6| Step: 12
Training loss: 2.6324080431057255
Validation loss: 2.5475206480912607

Epoch: 6| Step: 13
Training loss: 3.683436207320007
Validation loss: 2.5212357709244997

Epoch: 111| Step: 0
Training loss: 2.5941317173994882
Validation loss: 2.491733547356661

Epoch: 6| Step: 1
Training loss: 3.3792773798167577
Validation loss: 2.480516439749241

Epoch: 6| Step: 2
Training loss: 2.6305497857468825
Validation loss: 2.4874325124789345

Epoch: 6| Step: 3
Training loss: 2.6536559958570636
Validation loss: 2.500474938020071

Epoch: 6| Step: 4
Training loss: 2.6746515492740692
Validation loss: 2.5077297608632594

Epoch: 6| Step: 5
Training loss: 2.1837433301434035
Validation loss: 2.5534438852224492

Epoch: 6| Step: 6
Training loss: 3.10222090259598
Validation loss: 2.557861078938237

Epoch: 6| Step: 7
Training loss: 3.1166820450945654
Validation loss: 2.577669934693834

Epoch: 6| Step: 8
Training loss: 2.73169694818172
Validation loss: 2.5831733456258688

Epoch: 6| Step: 9
Training loss: 2.8683374577843024
Validation loss: 2.535475373895126

Epoch: 6| Step: 10
Training loss: 3.108236439876207
Validation loss: 2.5200787771519706

Epoch: 6| Step: 11
Training loss: 2.924289460566811
Validation loss: 2.561009126162953

Epoch: 6| Step: 12
Training loss: 2.461761627259683
Validation loss: 2.625872018399163

Epoch: 6| Step: 13
Training loss: 3.07619249125036
Validation loss: 2.6409974941941257

Epoch: 112| Step: 0
Training loss: 2.9908112630369037
Validation loss: 2.6925354925890534

Epoch: 6| Step: 1
Training loss: 3.096253586213765
Validation loss: 2.6613781296460055

Epoch: 6| Step: 2
Training loss: 2.9542679769758795
Validation loss: 2.5984855009826084

Epoch: 6| Step: 3
Training loss: 2.9977802965766136
Validation loss: 2.58258129467421

Epoch: 6| Step: 4
Training loss: 2.4753176090403026
Validation loss: 2.5671210662121218

Epoch: 6| Step: 5
Training loss: 2.7528529540454354
Validation loss: 2.5310116322311274

Epoch: 6| Step: 6
Training loss: 2.943242567512617
Validation loss: 2.505047747450644

Epoch: 6| Step: 7
Training loss: 2.6187866791043324
Validation loss: 2.487734834639728

Epoch: 6| Step: 8
Training loss: 2.302057349517233
Validation loss: 2.4775669872181134

Epoch: 6| Step: 9
Training loss: 2.6902973786375646
Validation loss: 2.4764199656308956

Epoch: 6| Step: 10
Training loss: 2.6854052697041713
Validation loss: 2.484467718605473

Epoch: 6| Step: 11
Training loss: 2.853469503605709
Validation loss: 2.4830506026383135

Epoch: 6| Step: 12
Training loss: 2.758724418490418
Validation loss: 2.477612329162562

Epoch: 6| Step: 13
Training loss: 3.2549780354732922
Validation loss: 2.4795367301731934

Epoch: 113| Step: 0
Training loss: 2.8045978159897267
Validation loss: 2.4872653127602526

Epoch: 6| Step: 1
Training loss: 2.463674809176051
Validation loss: 2.4861467023614656

Epoch: 6| Step: 2
Training loss: 2.987681210181547
Validation loss: 2.4926464157059676

Epoch: 6| Step: 3
Training loss: 2.9618759077352084
Validation loss: 2.512678937030172

Epoch: 6| Step: 4
Training loss: 2.8164815059347905
Validation loss: 2.533044411721145

Epoch: 6| Step: 5
Training loss: 2.9965164304194025
Validation loss: 2.5324210300707257

Epoch: 6| Step: 6
Training loss: 2.539940878713203
Validation loss: 2.5363153405249026

Epoch: 6| Step: 7
Training loss: 1.8836269279225573
Validation loss: 2.5237962975727743

Epoch: 6| Step: 8
Training loss: 2.559115524087375
Validation loss: 2.51676432172827

Epoch: 6| Step: 9
Training loss: 3.011977287308165
Validation loss: 2.5040780943176024

Epoch: 6| Step: 10
Training loss: 3.18308955219454
Validation loss: 2.4932062828234836

Epoch: 6| Step: 11
Training loss: 2.747008864403397
Validation loss: 2.498196221865015

Epoch: 6| Step: 12
Training loss: 3.075963844652339
Validation loss: 2.5052464757517745

Epoch: 6| Step: 13
Training loss: 2.967218586305366
Validation loss: 2.4957693650728743

Epoch: 114| Step: 0
Training loss: 2.569947561775508
Validation loss: 2.4980232925056844

Epoch: 6| Step: 1
Training loss: 2.7841560526004883
Validation loss: 2.493768453456499

Epoch: 6| Step: 2
Training loss: 2.8621405896431455
Validation loss: 2.493395597120142

Epoch: 6| Step: 3
Training loss: 2.517510128360743
Validation loss: 2.500746022965978

Epoch: 6| Step: 4
Training loss: 1.919912809736673
Validation loss: 2.5132696862592754

Epoch: 6| Step: 5
Training loss: 3.482246604184361
Validation loss: 2.5171561789109353

Epoch: 6| Step: 6
Training loss: 2.982936972033767
Validation loss: 2.5327729819250657

Epoch: 6| Step: 7
Training loss: 3.6506785140958726
Validation loss: 2.5444543667995196

Epoch: 6| Step: 8
Training loss: 2.416210416498206
Validation loss: 2.538252145898702

Epoch: 6| Step: 9
Training loss: 2.510082892762715
Validation loss: 2.5243384077817677

Epoch: 6| Step: 10
Training loss: 3.1337082645298393
Validation loss: 2.52496508352139

Epoch: 6| Step: 11
Training loss: 2.9505966100476373
Validation loss: 2.5027527015925792

Epoch: 6| Step: 12
Training loss: 2.450935601629251
Validation loss: 2.4943877064435136

Epoch: 6| Step: 13
Training loss: 2.0583788996709513
Validation loss: 2.480939917740864

Epoch: 115| Step: 0
Training loss: 2.5539079229116575
Validation loss: 2.4782746439622056

Epoch: 6| Step: 1
Training loss: 2.326357586651648
Validation loss: 2.4776841802693648

Epoch: 6| Step: 2
Training loss: 2.666442166256146
Validation loss: 2.4810251725664916

Epoch: 6| Step: 3
Training loss: 2.8926974728501413
Validation loss: 2.4842544354081335

Epoch: 6| Step: 4
Training loss: 3.0650944521913988
Validation loss: 2.489618531205399

Epoch: 6| Step: 5
Training loss: 3.0686714115684874
Validation loss: 2.4850991126975805

Epoch: 6| Step: 6
Training loss: 2.9740686256992546
Validation loss: 2.4925181401971157

Epoch: 6| Step: 7
Training loss: 2.377457301160539
Validation loss: 2.482378853679536

Epoch: 6| Step: 8
Training loss: 2.8137422149564064
Validation loss: 2.487838181512484

Epoch: 6| Step: 9
Training loss: 2.2562571517535113
Validation loss: 2.4875102182228828

Epoch: 6| Step: 10
Training loss: 2.7263566516022513
Validation loss: 2.4919964870190503

Epoch: 6| Step: 11
Training loss: 2.906346145188046
Validation loss: 2.497190447236377

Epoch: 6| Step: 12
Training loss: 2.9654054775529888
Validation loss: 2.4989159828263268

Epoch: 6| Step: 13
Training loss: 3.0266214801199274
Validation loss: 2.5248229097190578

Epoch: 116| Step: 0
Training loss: 2.6890451292178446
Validation loss: 2.576975444163748

Epoch: 6| Step: 1
Training loss: 3.4817438840239223
Validation loss: 2.5967397487539063

Epoch: 6| Step: 2
Training loss: 2.851378719730601
Validation loss: 2.5296479805353065

Epoch: 6| Step: 3
Training loss: 3.3468064928923957
Validation loss: 2.5065694150891646

Epoch: 6| Step: 4
Training loss: 2.546186950981676
Validation loss: 2.4885960792170136

Epoch: 6| Step: 5
Training loss: 2.4982310712607427
Validation loss: 2.475511962577584

Epoch: 6| Step: 6
Training loss: 2.3086289662936332
Validation loss: 2.466056391655142

Epoch: 6| Step: 7
Training loss: 2.5848117002750715
Validation loss: 2.471531367799072

Epoch: 6| Step: 8
Training loss: 2.9984241161276337
Validation loss: 2.488830097882569

Epoch: 6| Step: 9
Training loss: 2.1600463176988804
Validation loss: 2.485511373877053

Epoch: 6| Step: 10
Training loss: 3.0667170859075927
Validation loss: 2.4826947019188146

Epoch: 6| Step: 11
Training loss: 3.3357551042422937
Validation loss: 2.4931810658804148

Epoch: 6| Step: 12
Training loss: 2.3225781204011655
Validation loss: 2.4915269708057957

Epoch: 6| Step: 13
Training loss: 2.0979485618896763
Validation loss: 2.5050509342848546

Epoch: 117| Step: 0
Training loss: 2.9293754716648563
Validation loss: 2.499413504561987

Epoch: 6| Step: 1
Training loss: 1.9229992315297766
Validation loss: 2.497787658536924

Epoch: 6| Step: 2
Training loss: 2.3865120606276515
Validation loss: 2.516002396661697

Epoch: 6| Step: 3
Training loss: 2.6807138685036116
Validation loss: 2.527856521712669

Epoch: 6| Step: 4
Training loss: 2.9957681053675858
Validation loss: 2.555970060326932

Epoch: 6| Step: 5
Training loss: 2.6796415008066767
Validation loss: 2.60378676533185

Epoch: 6| Step: 6
Training loss: 2.1920128185148013
Validation loss: 2.6399159123495903

Epoch: 6| Step: 7
Training loss: 3.049872386326349
Validation loss: 2.691054584055628

Epoch: 6| Step: 8
Training loss: 3.0351251431200352
Validation loss: 2.6505939787308335

Epoch: 6| Step: 9
Training loss: 2.9124997118511793
Validation loss: 2.595773442599854

Epoch: 6| Step: 10
Training loss: 2.821403313604778
Validation loss: 2.5610673272441686

Epoch: 6| Step: 11
Training loss: 2.6793432431644817
Validation loss: 2.5232537320558137

Epoch: 6| Step: 12
Training loss: 3.6137172456548075
Validation loss: 2.4926063580880284

Epoch: 6| Step: 13
Training loss: 2.7217198079097993
Validation loss: 2.4886088819551233

Epoch: 118| Step: 0
Training loss: 3.0338680327048118
Validation loss: 2.4935358687968523

Epoch: 6| Step: 1
Training loss: 2.5078948295602936
Validation loss: 2.5238862236346877

Epoch: 6| Step: 2
Training loss: 2.8993665332181293
Validation loss: 2.508933662274132

Epoch: 6| Step: 3
Training loss: 2.539822227084098
Validation loss: 2.5161626158905994

Epoch: 6| Step: 4
Training loss: 2.373034215822716
Validation loss: 2.5161826508551277

Epoch: 6| Step: 5
Training loss: 2.691874204573061
Validation loss: 2.4946409211561993

Epoch: 6| Step: 6
Training loss: 3.1574928178501676
Validation loss: 2.474956272750336

Epoch: 6| Step: 7
Training loss: 2.4393230369950385
Validation loss: 2.4799153638321334

Epoch: 6| Step: 8
Training loss: 2.6293033566336224
Validation loss: 2.4852287366730836

Epoch: 6| Step: 9
Training loss: 3.0248548551684964
Validation loss: 2.520874683797276

Epoch: 6| Step: 10
Training loss: 3.194722090739748
Validation loss: 2.551282332491711

Epoch: 6| Step: 11
Training loss: 2.8395596326667807
Validation loss: 2.557026799361836

Epoch: 6| Step: 12
Training loss: 2.7107244842124922
Validation loss: 2.5555868210053316

Epoch: 6| Step: 13
Training loss: 3.0471335276938065
Validation loss: 2.534447172439718

Epoch: 119| Step: 0
Training loss: 2.9665123788667604
Validation loss: 2.529327144323692

Epoch: 6| Step: 1
Training loss: 2.965140306520674
Validation loss: 2.536628249659868

Epoch: 6| Step: 2
Training loss: 3.402216631926762
Validation loss: 2.5347842821124518

Epoch: 6| Step: 3
Training loss: 2.8892736627003046
Validation loss: 2.5221218340623057

Epoch: 6| Step: 4
Training loss: 3.149602556132548
Validation loss: 2.5241249966721284

Epoch: 6| Step: 5
Training loss: 2.8508125886791444
Validation loss: 2.5209755290873526

Epoch: 6| Step: 6
Training loss: 2.908989384353482
Validation loss: 2.52858977280326

Epoch: 6| Step: 7
Training loss: 2.0782778117277116
Validation loss: 2.5470689470338224

Epoch: 6| Step: 8
Training loss: 2.472956297207937
Validation loss: 2.5429456093008103

Epoch: 6| Step: 9
Training loss: 1.9716611864148699
Validation loss: 2.5357980405442424

Epoch: 6| Step: 10
Training loss: 2.262955348944366
Validation loss: 2.520328067011065

Epoch: 6| Step: 11
Training loss: 3.1155426351207076
Validation loss: 2.5177458552252725

Epoch: 6| Step: 12
Training loss: 2.633338219199497
Validation loss: 2.5020987796725898

Epoch: 6| Step: 13
Training loss: 2.1284257539036617
Validation loss: 2.4877780065354553

Epoch: 120| Step: 0
Training loss: 2.6582537105996846
Validation loss: 2.4808357275425013

Epoch: 6| Step: 1
Training loss: 3.204167489463856
Validation loss: 2.48525916312043

Epoch: 6| Step: 2
Training loss: 2.7726496907336915
Validation loss: 2.4968385395506867

Epoch: 6| Step: 3
Training loss: 2.6039789564510016
Validation loss: 2.485965725387164

Epoch: 6| Step: 4
Training loss: 2.3577068570626696
Validation loss: 2.4955049003431506

Epoch: 6| Step: 5
Training loss: 3.1294170443706695
Validation loss: 2.4859791501030966

Epoch: 6| Step: 6
Training loss: 3.044916863770732
Validation loss: 2.494254357759567

Epoch: 6| Step: 7
Training loss: 3.424375413065059
Validation loss: 2.4881481355851607

Epoch: 6| Step: 8
Training loss: 2.2590741391184874
Validation loss: 2.491949790603959

Epoch: 6| Step: 9
Training loss: 2.6492313781815287
Validation loss: 2.4818175108883236

Epoch: 6| Step: 10
Training loss: 2.466350596600236
Validation loss: 2.488728141632435

Epoch: 6| Step: 11
Training loss: 2.5306639758250835
Validation loss: 2.5018376774479805

Epoch: 6| Step: 12
Training loss: 2.4704057959372467
Validation loss: 2.5147639106372344

Epoch: 6| Step: 13
Training loss: 2.4920830301134616
Validation loss: 2.5280387741723604

Epoch: 121| Step: 0
Training loss: 2.687346165712128
Validation loss: 2.557652570390333

Epoch: 6| Step: 1
Training loss: 2.8133541929306327
Validation loss: 2.571382895838142

Epoch: 6| Step: 2
Training loss: 2.2352575946487274
Validation loss: 2.589810816404584

Epoch: 6| Step: 3
Training loss: 2.9026810256271087
Validation loss: 2.580621194439776

Epoch: 6| Step: 4
Training loss: 2.8110811681329637
Validation loss: 2.5593872372923947

Epoch: 6| Step: 5
Training loss: 2.7879034460306635
Validation loss: 2.540552166930854

Epoch: 6| Step: 6
Training loss: 3.0709935954358496
Validation loss: 2.507191736542488

Epoch: 6| Step: 7
Training loss: 2.6073041910766586
Validation loss: 2.498551987126852

Epoch: 6| Step: 8
Training loss: 2.5258342120266497
Validation loss: 2.4705526132040028

Epoch: 6| Step: 9
Training loss: 3.0526484637823295
Validation loss: 2.4734188017846015

Epoch: 6| Step: 10
Training loss: 2.917105959553107
Validation loss: 2.4754261015488033

Epoch: 6| Step: 11
Training loss: 2.244128726034599
Validation loss: 2.483042382209577

Epoch: 6| Step: 12
Training loss: 3.0297312913851036
Validation loss: 2.4874940685890565

Epoch: 6| Step: 13
Training loss: 2.7563111105997318
Validation loss: 2.4864835190575003

Epoch: 122| Step: 0
Training loss: 2.9321957036651365
Validation loss: 2.5013412774269432

Epoch: 6| Step: 1
Training loss: 2.7814409854764985
Validation loss: 2.514075678871757

Epoch: 6| Step: 2
Training loss: 2.755275001993247
Validation loss: 2.5194312840610227

Epoch: 6| Step: 3
Training loss: 3.1194793765643887
Validation loss: 2.5260490137434637

Epoch: 6| Step: 4
Training loss: 3.224918861255602
Validation loss: 2.550132909902556

Epoch: 6| Step: 5
Training loss: 3.124177748269647
Validation loss: 2.5568417181972474

Epoch: 6| Step: 6
Training loss: 2.4209907147916074
Validation loss: 2.5529433173696687

Epoch: 6| Step: 7
Training loss: 2.7129132988725804
Validation loss: 2.5854207859666056

Epoch: 6| Step: 8
Training loss: 2.6422761348428385
Validation loss: 2.612932533593279

Epoch: 6| Step: 9
Training loss: 2.3475947062570643
Validation loss: 2.59739050920342

Epoch: 6| Step: 10
Training loss: 2.0931064128990178
Validation loss: 2.6004668913415814

Epoch: 6| Step: 11
Training loss: 2.988991407395459
Validation loss: 2.553941755130468

Epoch: 6| Step: 12
Training loss: 2.302822897570915
Validation loss: 2.522695675341517

Epoch: 6| Step: 13
Training loss: 2.478202589631515
Validation loss: 2.508494088270865

Epoch: 123| Step: 0
Training loss: 2.77073456055166
Validation loss: 2.4987814456132074

Epoch: 6| Step: 1
Training loss: 3.0609151670956596
Validation loss: 2.5031907454616262

Epoch: 6| Step: 2
Training loss: 2.081328711868489
Validation loss: 2.5063103763367027

Epoch: 6| Step: 3
Training loss: 2.6998137551109664
Validation loss: 2.519522710049436

Epoch: 6| Step: 4
Training loss: 2.905650087192059
Validation loss: 2.516652975335135

Epoch: 6| Step: 5
Training loss: 2.791520945223602
Validation loss: 2.502518660806757

Epoch: 6| Step: 6
Training loss: 2.566681032842419
Validation loss: 2.489475680581928

Epoch: 6| Step: 7
Training loss: 2.074558381114895
Validation loss: 2.4907647146786047

Epoch: 6| Step: 8
Training loss: 3.0894403206326833
Validation loss: 2.489850201957751

Epoch: 6| Step: 9
Training loss: 2.808973432616924
Validation loss: 2.4814018744224366

Epoch: 6| Step: 10
Training loss: 2.979262201515815
Validation loss: 2.4882224684145924

Epoch: 6| Step: 11
Training loss: 2.7030710203922093
Validation loss: 2.4950694172046153

Epoch: 6| Step: 12
Training loss: 2.897258508474727
Validation loss: 2.507984490653277

Epoch: 6| Step: 13
Training loss: 2.507382935427991
Validation loss: 2.5427162202920957

Epoch: 124| Step: 0
Training loss: 2.4410253609133337
Validation loss: 2.570740090538345

Epoch: 6| Step: 1
Training loss: 3.5173492950277803
Validation loss: 2.5941590699317256

Epoch: 6| Step: 2
Training loss: 2.7950043629456998
Validation loss: 2.610311957813023

Epoch: 6| Step: 3
Training loss: 2.299767366337304
Validation loss: 2.5905546106972785

Epoch: 6| Step: 4
Training loss: 2.694661291207991
Validation loss: 2.5709316279612

Epoch: 6| Step: 5
Training loss: 2.531681824572425
Validation loss: 2.564832750578423

Epoch: 6| Step: 6
Training loss: 2.859550429002059
Validation loss: 2.562268427507995

Epoch: 6| Step: 7
Training loss: 2.155803357734192
Validation loss: 2.5596921630678127

Epoch: 6| Step: 8
Training loss: 3.0813835440087765
Validation loss: 2.547103397494363

Epoch: 6| Step: 9
Training loss: 2.964709292693897
Validation loss: 2.536955793981116

Epoch: 6| Step: 10
Training loss: 2.8408248444983615
Validation loss: 2.5370845560269197

Epoch: 6| Step: 11
Training loss: 2.0358435702082804
Validation loss: 2.5133118024205023

Epoch: 6| Step: 12
Training loss: 2.0866284315528594
Validation loss: 2.504501805631991

Epoch: 6| Step: 13
Training loss: 3.2713594600685476
Validation loss: 2.4976169446767713

Epoch: 125| Step: 0
Training loss: 2.868798408847842
Validation loss: 2.4737488125655207

Epoch: 6| Step: 1
Training loss: 2.60985327808829
Validation loss: 2.480309438526978

Epoch: 6| Step: 2
Training loss: 2.9648112620708504
Validation loss: 2.470457068097598

Epoch: 6| Step: 3
Training loss: 3.039773343069165
Validation loss: 2.463719433869441

Epoch: 6| Step: 4
Training loss: 2.726693136588825
Validation loss: 2.471291023169635

Epoch: 6| Step: 5
Training loss: 2.173918277485393
Validation loss: 2.480128536933997

Epoch: 6| Step: 6
Training loss: 2.7451571390724947
Validation loss: 2.500187844223204

Epoch: 6| Step: 7
Training loss: 2.436471771120545
Validation loss: 2.5256261928952917

Epoch: 6| Step: 8
Training loss: 2.572618186615815
Validation loss: 2.559325353873218

Epoch: 6| Step: 9
Training loss: 2.6210120653138924
Validation loss: 2.5764195702836195

Epoch: 6| Step: 10
Training loss: 2.8769057218811973
Validation loss: 2.573941912342442

Epoch: 6| Step: 11
Training loss: 2.8827178856848383
Validation loss: 2.536556139844155

Epoch: 6| Step: 12
Training loss: 2.728933183617399
Validation loss: 2.5276673147189754

Epoch: 6| Step: 13
Training loss: 2.8345602595339545
Validation loss: 2.5391791234395615

Epoch: 126| Step: 0
Training loss: 2.507992366627054
Validation loss: 2.5599567929878626

Epoch: 6| Step: 1
Training loss: 2.795604566452089
Validation loss: 2.667195496177494

Epoch: 6| Step: 2
Training loss: 2.8762521090410664
Validation loss: 2.6651664738932066

Epoch: 6| Step: 3
Training loss: 2.6491970897206434
Validation loss: 2.5837342943147115

Epoch: 6| Step: 4
Training loss: 2.306449397701522
Validation loss: 2.548209583497489

Epoch: 6| Step: 5
Training loss: 2.6676191377356835
Validation loss: 2.525469826477825

Epoch: 6| Step: 6
Training loss: 2.5627925054567706
Validation loss: 2.52622530673197

Epoch: 6| Step: 7
Training loss: 2.8536108733461703
Validation loss: 2.539278756169997

Epoch: 6| Step: 8
Training loss: 2.6772201344805433
Validation loss: 2.5234595293710043

Epoch: 6| Step: 9
Training loss: 2.4444615647650854
Validation loss: 2.5605650188314804

Epoch: 6| Step: 10
Training loss: 2.7300223448121863
Validation loss: 2.539062407109438

Epoch: 6| Step: 11
Training loss: 3.4415218061083013
Validation loss: 2.5765633396078735

Epoch: 6| Step: 12
Training loss: 2.9530087402710454
Validation loss: 2.541800227321605

Epoch: 6| Step: 13
Training loss: 2.9093889901944445
Validation loss: 2.537642662050517

Epoch: 127| Step: 0
Training loss: 2.674816542421931
Validation loss: 2.492822507110827

Epoch: 6| Step: 1
Training loss: 2.584572884342076
Validation loss: 2.4819712831915375

Epoch: 6| Step: 2
Training loss: 2.263349350473231
Validation loss: 2.481147684694937

Epoch: 6| Step: 3
Training loss: 2.525643816157811
Validation loss: 2.477608381693985

Epoch: 6| Step: 4
Training loss: 2.5619137721444334
Validation loss: 2.475806971956742

Epoch: 6| Step: 5
Training loss: 3.109955853213281
Validation loss: 2.4952416266077977

Epoch: 6| Step: 6
Training loss: 3.138867242188958
Validation loss: 2.507137441441679

Epoch: 6| Step: 7
Training loss: 2.8531773841285673
Validation loss: 2.521027495404357

Epoch: 6| Step: 8
Training loss: 1.8323315860230363
Validation loss: 2.5456357198474557

Epoch: 6| Step: 9
Training loss: 2.36000790222914
Validation loss: 2.567376758330196

Epoch: 6| Step: 10
Training loss: 2.9386269862732024
Validation loss: 2.5871452839812648

Epoch: 6| Step: 11
Training loss: 2.8242511668264054
Validation loss: 2.619082356780445

Epoch: 6| Step: 12
Training loss: 3.4285831280917414
Validation loss: 2.627613274735037

Epoch: 6| Step: 13
Training loss: 2.7112826696514323
Validation loss: 2.584745774852936

Epoch: 128| Step: 0
Training loss: 2.829683327632295
Validation loss: 2.5600210545235487

Epoch: 6| Step: 1
Training loss: 2.794091059200994
Validation loss: 2.5593524082701316

Epoch: 6| Step: 2
Training loss: 2.3842998927774857
Validation loss: 2.5168911537210144

Epoch: 6| Step: 3
Training loss: 2.514853222850771
Validation loss: 2.4963182153946106

Epoch: 6| Step: 4
Training loss: 2.6461267884283686
Validation loss: 2.5023747496572573

Epoch: 6| Step: 5
Training loss: 3.549799448715185
Validation loss: 2.512401733615452

Epoch: 6| Step: 6
Training loss: 2.546290605583639
Validation loss: 2.503205881315925

Epoch: 6| Step: 7
Training loss: 2.527439781852599
Validation loss: 2.4890438114279854

Epoch: 6| Step: 8
Training loss: 3.063543647904692
Validation loss: 2.5127761945325555

Epoch: 6| Step: 9
Training loss: 1.9005947963895056
Validation loss: 2.5223782154023153

Epoch: 6| Step: 10
Training loss: 2.6703699345714966
Validation loss: 2.4909661231512557

Epoch: 6| Step: 11
Training loss: 2.539758768716329
Validation loss: 2.478854689112222

Epoch: 6| Step: 12
Training loss: 2.9274069900136306
Validation loss: 2.4665065139134335

Epoch: 6| Step: 13
Training loss: 2.385152699442575
Validation loss: 2.476993530398658

Epoch: 129| Step: 0
Training loss: 2.654702307899493
Validation loss: 2.4949093148526535

Epoch: 6| Step: 1
Training loss: 2.723528641506896
Validation loss: 2.4946949785261823

Epoch: 6| Step: 2
Training loss: 2.7434304401025726
Validation loss: 2.526494921475809

Epoch: 6| Step: 3
Training loss: 2.769108103721123
Validation loss: 2.5695299521418296

Epoch: 6| Step: 4
Training loss: 3.0350025977637345
Validation loss: 2.5970569951624687

Epoch: 6| Step: 5
Training loss: 3.072305823352322
Validation loss: 2.6067570760791567

Epoch: 6| Step: 6
Training loss: 2.659850787803501
Validation loss: 2.6344485521792764

Epoch: 6| Step: 7
Training loss: 2.1154618215810217
Validation loss: 2.634598934207464

Epoch: 6| Step: 8
Training loss: 2.4506755675955687
Validation loss: 2.592393053898425

Epoch: 6| Step: 9
Training loss: 2.6790858001923867
Validation loss: 2.5824469571652773

Epoch: 6| Step: 10
Training loss: 2.8064883090573765
Validation loss: 2.567431668718456

Epoch: 6| Step: 11
Training loss: 2.1597490530470087
Validation loss: 2.530447679433632

Epoch: 6| Step: 12
Training loss: 2.812548149544441
Validation loss: 2.509423741508195

Epoch: 6| Step: 13
Training loss: 3.1624818220860043
Validation loss: 2.4882211135564973

Epoch: 130| Step: 0
Training loss: 2.915073250165938
Validation loss: 2.479991117740038

Epoch: 6| Step: 1
Training loss: 3.003450475674047
Validation loss: 2.4853628780314425

Epoch: 6| Step: 2
Training loss: 2.662757621085915
Validation loss: 2.4824007336326614

Epoch: 6| Step: 3
Training loss: 2.6155478736143793
Validation loss: 2.4839409580405962

Epoch: 6| Step: 4
Training loss: 2.5534604359988955
Validation loss: 2.4811357434202184

Epoch: 6| Step: 5
Training loss: 2.463292233593545
Validation loss: 2.4743172513556453

Epoch: 6| Step: 6
Training loss: 2.7574797259335067
Validation loss: 2.492262910719137

Epoch: 6| Step: 7
Training loss: 2.7989833280306016
Validation loss: 2.5069423327801017

Epoch: 6| Step: 8
Training loss: 2.9912206616618793
Validation loss: 2.5043795341203072

Epoch: 6| Step: 9
Training loss: 2.732696192225529
Validation loss: 2.50246277477026

Epoch: 6| Step: 10
Training loss: 2.1562475674380526
Validation loss: 2.491322117213153

Epoch: 6| Step: 11
Training loss: 2.1449413359118177
Validation loss: 2.500290784024409

Epoch: 6| Step: 12
Training loss: 2.8564279513361295
Validation loss: 2.506678090085309

Epoch: 6| Step: 13
Training loss: 2.30095409009642
Validation loss: 2.502643390562531

Epoch: 131| Step: 0
Training loss: 2.7658956793960536
Validation loss: 2.509056392342522

Epoch: 6| Step: 1
Training loss: 2.6001590460035633
Validation loss: 2.4961400535903198

Epoch: 6| Step: 2
Training loss: 2.0536160884763435
Validation loss: 2.5023651399873477

Epoch: 6| Step: 3
Training loss: 2.7258015529918396
Validation loss: 2.50624142342723

Epoch: 6| Step: 4
Training loss: 2.5579691583177433
Validation loss: 2.5155836940281917

Epoch: 6| Step: 5
Training loss: 2.155007709392025
Validation loss: 2.5307639843049405

Epoch: 6| Step: 6
Training loss: 3.1509012658652833
Validation loss: 2.53039783356541

Epoch: 6| Step: 7
Training loss: 2.576886983765413
Validation loss: 2.5306260861622207

Epoch: 6| Step: 8
Training loss: 2.700325282247279
Validation loss: 2.543482458815733

Epoch: 6| Step: 9
Training loss: 2.26291436463278
Validation loss: 2.5501427869251883

Epoch: 6| Step: 10
Training loss: 2.92758892937381
Validation loss: 2.586572248790583

Epoch: 6| Step: 11
Training loss: 2.571201715604807
Validation loss: 2.6068573221367206

Epoch: 6| Step: 12
Training loss: 2.742937121403157
Validation loss: 2.62632715766793

Epoch: 6| Step: 13
Training loss: 3.1026941344134507
Validation loss: 2.6397005052467017

Epoch: 132| Step: 0
Training loss: 2.892308585148063
Validation loss: 2.6225972720480106

Epoch: 6| Step: 1
Training loss: 2.4335232107553764
Validation loss: 2.6038578777386565

Epoch: 6| Step: 2
Training loss: 2.2527229998046536
Validation loss: 2.590301411366667

Epoch: 6| Step: 3
Training loss: 2.9921549902362514
Validation loss: 2.5793379460089776

Epoch: 6| Step: 4
Training loss: 2.440498073271538
Validation loss: 2.585096738525358

Epoch: 6| Step: 5
Training loss: 2.2636055200180856
Validation loss: 2.563410069382125

Epoch: 6| Step: 6
Training loss: 2.2437390000437625
Validation loss: 2.550182333838992

Epoch: 6| Step: 7
Training loss: 2.1780193330591544
Validation loss: 2.5385815872864845

Epoch: 6| Step: 8
Training loss: 3.1700088197603487
Validation loss: 2.5414122829565695

Epoch: 6| Step: 9
Training loss: 2.9062509844378375
Validation loss: 2.543077548990682

Epoch: 6| Step: 10
Training loss: 2.7788529942996667
Validation loss: 2.5220708427379375

Epoch: 6| Step: 11
Training loss: 2.7226486315408565
Validation loss: 2.5215480055449047

Epoch: 6| Step: 12
Training loss: 2.304211376600289
Validation loss: 2.536760617971573

Epoch: 6| Step: 13
Training loss: 2.993047127609798
Validation loss: 2.5167976570497745

Epoch: 133| Step: 0
Training loss: 2.469247888505262
Validation loss: 2.5199667745360608

Epoch: 6| Step: 1
Training loss: 2.8050380477092784
Validation loss: 2.5188826492837966

Epoch: 6| Step: 2
Training loss: 3.1901960751535015
Validation loss: 2.5289081449131965

Epoch: 6| Step: 3
Training loss: 2.8687252733415747
Validation loss: 2.5191705983460535

Epoch: 6| Step: 4
Training loss: 2.9568451554512336
Validation loss: 2.505738475219039

Epoch: 6| Step: 5
Training loss: 2.6800167671077655
Validation loss: 2.5047852986593986

Epoch: 6| Step: 6
Training loss: 2.3298603733122847
Validation loss: 2.494309717502301

Epoch: 6| Step: 7
Training loss: 2.983615479011852
Validation loss: 2.4971830966981012

Epoch: 6| Step: 8
Training loss: 2.4430404686716476
Validation loss: 2.4900384762281953

Epoch: 6| Step: 9
Training loss: 2.0278775903299255
Validation loss: 2.503590772777871

Epoch: 6| Step: 10
Training loss: 2.165721271351211
Validation loss: 2.5271867675838617

Epoch: 6| Step: 11
Training loss: 2.21131985327072
Validation loss: 2.567430979737208

Epoch: 6| Step: 12
Training loss: 1.9858896677423141
Validation loss: 2.642071524758583

Epoch: 6| Step: 13
Training loss: 2.7399222644164865
Validation loss: 2.726887632871267

Epoch: 134| Step: 0
Training loss: 3.197615486069726
Validation loss: 2.7687405746382123

Epoch: 6| Step: 1
Training loss: 2.7418970894342207
Validation loss: 2.733370665351065

Epoch: 6| Step: 2
Training loss: 2.5684094094163923
Validation loss: 2.6348682526700005

Epoch: 6| Step: 3
Training loss: 2.906602899598531
Validation loss: 2.5567035279846357

Epoch: 6| Step: 4
Training loss: 2.1651007299798946
Validation loss: 2.5487620423279047

Epoch: 6| Step: 5
Training loss: 2.48295898389489
Validation loss: 2.5486549606217714

Epoch: 6| Step: 6
Training loss: 1.7893840384246738
Validation loss: 2.550426469851199

Epoch: 6| Step: 7
Training loss: 2.569322760739207
Validation loss: 2.5246355956333315

Epoch: 6| Step: 8
Training loss: 2.6684311651736987
Validation loss: 2.5274229450468506

Epoch: 6| Step: 9
Training loss: 3.4197284811555813
Validation loss: 2.5054966182504317

Epoch: 6| Step: 10
Training loss: 2.3596791456617976
Validation loss: 2.5059452429176483

Epoch: 6| Step: 11
Training loss: 2.3605214548265154
Validation loss: 2.517377365978257

Epoch: 6| Step: 12
Training loss: 2.5837955881645236
Validation loss: 2.523786520599516

Epoch: 6| Step: 13
Training loss: 2.9598391465994696
Validation loss: 2.547758116275824

Epoch: 135| Step: 0
Training loss: 2.7393760070868556
Validation loss: 2.5567896515849737

Epoch: 6| Step: 1
Training loss: 1.9485656010932544
Validation loss: 2.5762304977778463

Epoch: 6| Step: 2
Training loss: 2.447356226188531
Validation loss: 2.5811670130450572

Epoch: 6| Step: 3
Training loss: 2.7553386885748408
Validation loss: 2.570836589488941

Epoch: 6| Step: 4
Training loss: 2.6816784994252734
Validation loss: 2.5929717759413675

Epoch: 6| Step: 5
Training loss: 2.9245627378014007
Validation loss: 2.617635211537274

Epoch: 6| Step: 6
Training loss: 3.0209925817848706
Validation loss: 2.6457872497353865

Epoch: 6| Step: 7
Training loss: 2.738231707463513
Validation loss: 2.6285688806107586

Epoch: 6| Step: 8
Training loss: 2.3741144235829594
Validation loss: 2.6112107153045954

Epoch: 6| Step: 9
Training loss: 2.48931863141056
Validation loss: 2.5898468018055083

Epoch: 6| Step: 10
Training loss: 2.089118960180381
Validation loss: 2.571008982797047

Epoch: 6| Step: 11
Training loss: 2.5705220331280243
Validation loss: 2.5593141770352954

Epoch: 6| Step: 12
Training loss: 2.730575799548974
Validation loss: 2.5478350879830196

Epoch: 6| Step: 13
Training loss: 2.6578585971106716
Validation loss: 2.5217643943179175

Epoch: 136| Step: 0
Training loss: 2.9782325685173974
Validation loss: 2.511514940099114

Epoch: 6| Step: 1
Training loss: 2.293212357793807
Validation loss: 2.498010259898081

Epoch: 6| Step: 2
Training loss: 2.6460838099186823
Validation loss: 2.4899846173739677

Epoch: 6| Step: 3
Training loss: 2.7007961053194194
Validation loss: 2.4882348454985346

Epoch: 6| Step: 4
Training loss: 2.760348529094686
Validation loss: 2.504885647475156

Epoch: 6| Step: 5
Training loss: 2.0885939238773585
Validation loss: 2.5236754764121376

Epoch: 6| Step: 6
Training loss: 2.0625624213743032
Validation loss: 2.52962438050146

Epoch: 6| Step: 7
Training loss: 2.863975118166711
Validation loss: 2.565017249146051

Epoch: 6| Step: 8
Training loss: 2.5995620505412558
Validation loss: 2.5473915078138685

Epoch: 6| Step: 9
Training loss: 2.5931432542873254
Validation loss: 2.5566354789435484

Epoch: 6| Step: 10
Training loss: 3.109441861914603
Validation loss: 2.5393897182237986

Epoch: 6| Step: 11
Training loss: 2.5340220966474636
Validation loss: 2.505796411099044

Epoch: 6| Step: 12
Training loss: 2.896113613113027
Validation loss: 2.4981133089294296

Epoch: 6| Step: 13
Training loss: 1.5832727905878676
Validation loss: 2.511003063164343

Epoch: 137| Step: 0
Training loss: 2.431418437075343
Validation loss: 2.541241588244994

Epoch: 6| Step: 1
Training loss: 2.995715260378504
Validation loss: 2.559613624901741

Epoch: 6| Step: 2
Training loss: 2.565105695126977
Validation loss: 2.6019373083639263

Epoch: 6| Step: 3
Training loss: 2.0972855735905784
Validation loss: 2.6047166715240437

Epoch: 6| Step: 4
Training loss: 2.723639115154952
Validation loss: 2.626923104226846

Epoch: 6| Step: 5
Training loss: 2.6045229451923997
Validation loss: 2.643401290613187

Epoch: 6| Step: 6
Training loss: 2.8121968423853736
Validation loss: 2.6277440929817137

Epoch: 6| Step: 7
Training loss: 2.4529203098694063
Validation loss: 2.5587934934415255

Epoch: 6| Step: 8
Training loss: 2.500732123939044
Validation loss: 2.543329636603589

Epoch: 6| Step: 9
Training loss: 2.6625283933746364
Validation loss: 2.5449226728253027

Epoch: 6| Step: 10
Training loss: 2.906494458489719
Validation loss: 2.539390127091475

Epoch: 6| Step: 11
Training loss: 2.4678033872959997
Validation loss: 2.516957735004945

Epoch: 6| Step: 12
Training loss: 2.4333702707317686
Validation loss: 2.495174700107056

Epoch: 6| Step: 13
Training loss: 1.6852343149014073
Validation loss: 2.4856233448481806

Epoch: 138| Step: 0
Training loss: 2.084083218719643
Validation loss: 2.474952461918903

Epoch: 6| Step: 1
Training loss: 3.193025624044258
Validation loss: 2.4789843190169325

Epoch: 6| Step: 2
Training loss: 2.3437544759071844
Validation loss: 2.484543687115471

Epoch: 6| Step: 3
Training loss: 2.718211065786254
Validation loss: 2.489266193661752

Epoch: 6| Step: 4
Training loss: 3.3175685180395607
Validation loss: 2.498855788380668

Epoch: 6| Step: 5
Training loss: 2.305258263209399
Validation loss: 2.489788609370423

Epoch: 6| Step: 6
Training loss: 2.330719801104321
Validation loss: 2.493960650082774

Epoch: 6| Step: 7
Training loss: 2.7560761688846425
Validation loss: 2.4859265222854456

Epoch: 6| Step: 8
Training loss: 1.7219396644814893
Validation loss: 2.5061406450460293

Epoch: 6| Step: 9
Training loss: 2.2796263468895743
Validation loss: 2.509802513957515

Epoch: 6| Step: 10
Training loss: 2.32196623056911
Validation loss: 2.515428746768758

Epoch: 6| Step: 11
Training loss: 2.508818617691568
Validation loss: 2.537504981631284

Epoch: 6| Step: 12
Training loss: 1.8579764355580808
Validation loss: 2.5670503946825813

Epoch: 6| Step: 13
Training loss: 3.165525347844215
Validation loss: 2.6026842258098246

Epoch: 139| Step: 0
Training loss: 2.423749137040172
Validation loss: 2.6170329455266463

Epoch: 6| Step: 1
Training loss: 2.6640622315168945
Validation loss: 2.6132970814024787

Epoch: 6| Step: 2
Training loss: 1.8801917993834756
Validation loss: 2.5864538164254514

Epoch: 6| Step: 3
Training loss: 3.020931023081431
Validation loss: 2.5614047487327047

Epoch: 6| Step: 4
Training loss: 1.982378578652817
Validation loss: 2.519559166166874

Epoch: 6| Step: 5
Training loss: 2.616764410181695
Validation loss: 2.5080296251164773

Epoch: 6| Step: 6
Training loss: 2.9386662542108613
Validation loss: 2.499047499885468

Epoch: 6| Step: 7
Training loss: 3.091900205060273
Validation loss: 2.489420058867696

Epoch: 6| Step: 8
Training loss: 2.495707355136842
Validation loss: 2.4735503914224797

Epoch: 6| Step: 9
Training loss: 2.4534726230671278
Validation loss: 2.4660258509500665

Epoch: 6| Step: 10
Training loss: 2.435137263821558
Validation loss: 2.482461347216358

Epoch: 6| Step: 11
Training loss: 2.1974268604037155
Validation loss: 2.4662756170327804

Epoch: 6| Step: 12
Training loss: 2.323816498640598
Validation loss: 2.4833538133721382

Epoch: 6| Step: 13
Training loss: 1.9470359796923196
Validation loss: 2.491313021616568

Epoch: 140| Step: 0
Training loss: 1.8501642798607194
Validation loss: 2.5028196246807624

Epoch: 6| Step: 1
Training loss: 1.9750570361436421
Validation loss: 2.509391048903505

Epoch: 6| Step: 2
Training loss: 2.4777538430502912
Validation loss: 2.5509080569355396

Epoch: 6| Step: 3
Training loss: 3.128864188036568
Validation loss: 2.5743852416146993

Epoch: 6| Step: 4
Training loss: 2.7889965915105157
Validation loss: 2.616092323076627

Epoch: 6| Step: 5
Training loss: 2.6182243456902685
Validation loss: 2.6096455472649267

Epoch: 6| Step: 6
Training loss: 2.281683475645171
Validation loss: 2.5928845800842497

Epoch: 6| Step: 7
Training loss: 2.456023429535187
Validation loss: 2.5834428431243266

Epoch: 6| Step: 8
Training loss: 2.320829391704433
Validation loss: 2.595932177099029

Epoch: 6| Step: 9
Training loss: 2.6130732295289505
Validation loss: 2.5694804833066964

Epoch: 6| Step: 10
Training loss: 2.104921287460367
Validation loss: 2.532177530204257

Epoch: 6| Step: 11
Training loss: 2.788933844497419
Validation loss: 2.522326333830817

Epoch: 6| Step: 12
Training loss: 2.6014221886723887
Validation loss: 2.484514780072868

Epoch: 6| Step: 13
Training loss: 2.5739903442747085
Validation loss: 2.4869904555507083

Epoch: 141| Step: 0
Training loss: 2.632197911100281
Validation loss: 2.466911330085714

Epoch: 6| Step: 1
Training loss: 2.339974172074675
Validation loss: 2.4611741016861153

Epoch: 6| Step: 2
Training loss: 2.548780418914178
Validation loss: 2.465727763454023

Epoch: 6| Step: 3
Training loss: 2.2928620659673897
Validation loss: 2.478079039105523

Epoch: 6| Step: 4
Training loss: 2.397365069366339
Validation loss: 2.4780467761243803

Epoch: 6| Step: 5
Training loss: 2.0970196601553655
Validation loss: 2.496312688243028

Epoch: 6| Step: 6
Training loss: 2.9005218167930376
Validation loss: 2.5194227305434493

Epoch: 6| Step: 7
Training loss: 2.615788601187702
Validation loss: 2.5426743895284485

Epoch: 6| Step: 8
Training loss: 1.903778600346417
Validation loss: 2.522664702473996

Epoch: 6| Step: 9
Training loss: 2.716928683168071
Validation loss: 2.5424529086218843

Epoch: 6| Step: 10
Training loss: 2.2311683532992665
Validation loss: 2.5779937601354694

Epoch: 6| Step: 11
Training loss: 2.6721674887307474
Validation loss: 2.6231632828828806

Epoch: 6| Step: 12
Training loss: 2.8969186263106907
Validation loss: 2.671345397585375

Epoch: 6| Step: 13
Training loss: 2.7252436292738498
Validation loss: 2.650641658102612

Epoch: 142| Step: 0
Training loss: 2.486548187034406
Validation loss: 2.688742092807802

Epoch: 6| Step: 1
Training loss: 2.625036511848473
Validation loss: 2.701282999132167

Epoch: 6| Step: 2
Training loss: 2.509273115586168
Validation loss: 2.7492030677282506

Epoch: 6| Step: 3
Training loss: 2.7126273129729626
Validation loss: 2.7412518316451275

Epoch: 6| Step: 4
Training loss: 2.4906320531115824
Validation loss: 2.683712309827118

Epoch: 6| Step: 5
Training loss: 2.59509885713591
Validation loss: 2.610523168010758

Epoch: 6| Step: 6
Training loss: 2.550064897646382
Validation loss: 2.572101472012974

Epoch: 6| Step: 7
Training loss: 2.5011206975988824
Validation loss: 2.523517898553279

Epoch: 6| Step: 8
Training loss: 1.8207636589261824
Validation loss: 2.4890725031389342

Epoch: 6| Step: 9
Training loss: 2.6900090769788334
Validation loss: 2.484060784460864

Epoch: 6| Step: 10
Training loss: 2.3669403249279477
Validation loss: 2.471229196242702

Epoch: 6| Step: 11
Training loss: 2.310927810287537
Validation loss: 2.496297865927171

Epoch: 6| Step: 12
Training loss: 2.9301698821621383
Validation loss: 2.5248805295300163

Epoch: 6| Step: 13
Training loss: 2.998310726123659
Validation loss: 2.5204664349965364

Epoch: 143| Step: 0
Training loss: 2.8810301856141534
Validation loss: 2.5015490552421498

Epoch: 6| Step: 1
Training loss: 2.620314549062584
Validation loss: 2.4862510216095264

Epoch: 6| Step: 2
Training loss: 2.6361255119670894
Validation loss: 2.475090967215507

Epoch: 6| Step: 3
Training loss: 2.3687140952738313
Validation loss: 2.507632852541571

Epoch: 6| Step: 4
Training loss: 2.4589041893014674
Validation loss: 2.5060719268418987

Epoch: 6| Step: 5
Training loss: 1.8842257185934514
Validation loss: 2.513363747672072

Epoch: 6| Step: 6
Training loss: 2.3046102219896256
Validation loss: 2.5251127621750786

Epoch: 6| Step: 7
Training loss: 2.287746532892354
Validation loss: 2.5356079287732594

Epoch: 6| Step: 8
Training loss: 2.101641458495801
Validation loss: 2.5576166963459532

Epoch: 6| Step: 9
Training loss: 2.4865680348093915
Validation loss: 2.5536397989735558

Epoch: 6| Step: 10
Training loss: 2.374781949925589
Validation loss: 2.5548089071216467

Epoch: 6| Step: 11
Training loss: 2.6533472693698723
Validation loss: 2.5567263105320523

Epoch: 6| Step: 12
Training loss: 2.6648698853011035
Validation loss: 2.544894138326976

Epoch: 6| Step: 13
Training loss: 2.250993827041981
Validation loss: 2.535968599234977

Epoch: 144| Step: 0
Training loss: 2.459165680058987
Validation loss: 2.5448860018162254

Epoch: 6| Step: 1
Training loss: 2.721837712940192
Validation loss: 2.543781395961027

Epoch: 6| Step: 2
Training loss: 2.2386067471659756
Validation loss: 2.503148280805872

Epoch: 6| Step: 3
Training loss: 2.7523536147049925
Validation loss: 2.5320824414332086

Epoch: 6| Step: 4
Training loss: 2.5049106053526353
Validation loss: 2.5366638090933544

Epoch: 6| Step: 5
Training loss: 2.2209738748345855
Validation loss: 2.5621953613575603

Epoch: 6| Step: 6
Training loss: 2.004422305399076
Validation loss: 2.5661396557359915

Epoch: 6| Step: 7
Training loss: 1.7977147669346782
Validation loss: 2.5870675187892167

Epoch: 6| Step: 8
Training loss: 1.9115893520872058
Validation loss: 2.6015248644362305

Epoch: 6| Step: 9
Training loss: 2.8214181016862256
Validation loss: 2.602804908995243

Epoch: 6| Step: 10
Training loss: 2.5682365591179654
Validation loss: 2.610705186882201

Epoch: 6| Step: 11
Training loss: 2.7432026519179633
Validation loss: 2.6337513131505745

Epoch: 6| Step: 12
Training loss: 2.6093159743160275
Validation loss: 2.6234027346063575

Epoch: 6| Step: 13
Training loss: 2.120958074512344
Validation loss: 2.5921939610858376

Epoch: 145| Step: 0
Training loss: 1.8880258143567556
Validation loss: 2.5702815698091124

Epoch: 6| Step: 1
Training loss: 2.05535146914406
Validation loss: 2.5329757543987945

Epoch: 6| Step: 2
Training loss: 2.37593762812325
Validation loss: 2.5151928007035504

Epoch: 6| Step: 3
Training loss: 2.5946428531672607
Validation loss: 2.5017094438498115

Epoch: 6| Step: 4
Training loss: 2.63628468649389
Validation loss: 2.4924589247115696

Epoch: 6| Step: 5
Training loss: 2.682946095059109
Validation loss: 2.496761318191184

Epoch: 6| Step: 6
Training loss: 2.41030017787811
Validation loss: 2.489775887349494

Epoch: 6| Step: 7
Training loss: 2.574642904760995
Validation loss: 2.5171228279678766

Epoch: 6| Step: 8
Training loss: 2.6736820646396757
Validation loss: 2.503047787570801

Epoch: 6| Step: 9
Training loss: 1.8015321171523615
Validation loss: 2.5228133429590947

Epoch: 6| Step: 10
Training loss: 2.156516017260859
Validation loss: 2.5409419608300188

Epoch: 6| Step: 11
Training loss: 1.9502472696274207
Validation loss: 2.5424314209425583

Epoch: 6| Step: 12
Training loss: 3.0924328398755283
Validation loss: 2.5451000568259983

Epoch: 6| Step: 13
Training loss: 2.042700434437182
Validation loss: 2.5342702789619693

Epoch: 146| Step: 0
Training loss: 2.226095906942906
Validation loss: 2.554025039864181

Epoch: 6| Step: 1
Training loss: 2.559743561715823
Validation loss: 2.5545470747396135

Epoch: 6| Step: 2
Training loss: 2.7123310124368323
Validation loss: 2.5713967758824783

Epoch: 6| Step: 3
Training loss: 2.214184429119947
Validation loss: 2.5530782347902026

Epoch: 6| Step: 4
Training loss: 2.364616785919124
Validation loss: 2.504111960936595

Epoch: 6| Step: 5
Training loss: 2.393379967677037
Validation loss: 2.487828732607156

Epoch: 6| Step: 6
Training loss: 2.443547108220501
Validation loss: 2.4752786091107923

Epoch: 6| Step: 7
Training loss: 2.250733150139031
Validation loss: 2.507195014722766

Epoch: 6| Step: 8
Training loss: 2.030565821524137
Validation loss: 2.508962681364628

Epoch: 6| Step: 9
Training loss: 2.616808690227935
Validation loss: 2.5048058944080416

Epoch: 6| Step: 10
Training loss: 2.712617556929534
Validation loss: 2.4977868436033606

Epoch: 6| Step: 11
Training loss: 2.589072916842163
Validation loss: 2.465837936931319

Epoch: 6| Step: 12
Training loss: 2.4577571603179673
Validation loss: 2.467642844661908

Epoch: 6| Step: 13
Training loss: 2.0603421801097515
Validation loss: 2.4478291174933777

Epoch: 147| Step: 0
Training loss: 2.0630201204088907
Validation loss: 2.4587800100015222

Epoch: 6| Step: 1
Training loss: 2.677755120640142
Validation loss: 2.50206544319201

Epoch: 6| Step: 2
Training loss: 1.7979299351043103
Validation loss: 2.5401843176433014

Epoch: 6| Step: 3
Training loss: 2.2778366890192197
Validation loss: 2.5775012194217624

Epoch: 6| Step: 4
Training loss: 2.25561004185546
Validation loss: 2.6108447941042097

Epoch: 6| Step: 5
Training loss: 1.88273538138712
Validation loss: 2.62117614709499

Epoch: 6| Step: 6
Training loss: 2.944164264792067
Validation loss: 2.6330358187128557

Epoch: 6| Step: 7
Training loss: 2.702349689407637
Validation loss: 2.645511029758212

Epoch: 6| Step: 8
Training loss: 2.4176115841444736
Validation loss: 2.640054821656789

Epoch: 6| Step: 9
Training loss: 2.0913932403741216
Validation loss: 2.6288802790416783

Epoch: 6| Step: 10
Training loss: 2.3027388270936076
Validation loss: 2.5961461993474337

Epoch: 6| Step: 11
Training loss: 3.0950327054022813
Validation loss: 2.576702318282237

Epoch: 6| Step: 12
Training loss: 2.4146160984751046
Validation loss: 2.5675382668681626

Epoch: 6| Step: 13
Training loss: 1.509512145957337
Validation loss: 2.5530253794772966

Epoch: 148| Step: 0
Training loss: 2.1766092858143518
Validation loss: 2.538475650588739

Epoch: 6| Step: 1
Training loss: 2.856569007738423
Validation loss: 2.5442729708157032

Epoch: 6| Step: 2
Training loss: 2.460229777948136
Validation loss: 2.558705809155029

Epoch: 6| Step: 3
Training loss: 2.399256861392393
Validation loss: 2.5760435012847935

Epoch: 6| Step: 4
Training loss: 2.2394664881780133
Validation loss: 2.6036782503592604

Epoch: 6| Step: 5
Training loss: 3.017054876003566
Validation loss: 2.6177259312232217

Epoch: 6| Step: 6
Training loss: 2.9261577043150733
Validation loss: 2.611853767389615

Epoch: 6| Step: 7
Training loss: 2.5282711821402137
Validation loss: 2.6208701238761596

Epoch: 6| Step: 8
Training loss: 2.1919897597971723
Validation loss: 2.5693934730352637

Epoch: 6| Step: 9
Training loss: 2.105678682353476
Validation loss: 2.516353015984965

Epoch: 6| Step: 10
Training loss: 1.5757038693206646
Validation loss: 2.4877906516968022

Epoch: 6| Step: 11
Training loss: 2.1890158714322014
Validation loss: 2.4588551326432273

Epoch: 6| Step: 12
Training loss: 1.8999010261054605
Validation loss: 2.484083394206887

Epoch: 6| Step: 13
Training loss: 1.5023338916631666
Validation loss: 2.48298387255798

Epoch: 149| Step: 0
Training loss: 2.5899179485388286
Validation loss: 2.4969527161666614

Epoch: 6| Step: 1
Training loss: 2.172545185563004
Validation loss: 2.491263851927889

Epoch: 6| Step: 2
Training loss: 2.4026153659015135
Validation loss: 2.5208040535905334

Epoch: 6| Step: 3
Training loss: 2.3439330983167515
Validation loss: 2.522818287701892

Epoch: 6| Step: 4
Training loss: 2.4966293500582473
Validation loss: 2.5391577029621173

Epoch: 6| Step: 5
Training loss: 2.2525386264211513
Validation loss: 2.547917772421859

Epoch: 6| Step: 6
Training loss: 2.860565104642002
Validation loss: 2.5418035324770654

Epoch: 6| Step: 7
Training loss: 2.361364675133277
Validation loss: 2.565200150407967

Epoch: 6| Step: 8
Training loss: 2.0399396040334743
Validation loss: 2.596971910802079

Epoch: 6| Step: 9
Training loss: 1.8333761976028393
Validation loss: 2.6192853791458313

Epoch: 6| Step: 10
Training loss: 2.544697398124669
Validation loss: 2.6183801702193037

Epoch: 6| Step: 11
Training loss: 2.288801575459295
Validation loss: 2.5922001353110953

Epoch: 6| Step: 12
Training loss: 2.0040841125912294
Validation loss: 2.572802819406109

Epoch: 6| Step: 13
Training loss: 1.424749800819106
Validation loss: 2.5661934447385346

Epoch: 150| Step: 0
Training loss: 2.952162489887577
Validation loss: 2.542659811261422

Epoch: 6| Step: 1
Training loss: 1.7875965225728787
Validation loss: 2.5310065120584837

Epoch: 6| Step: 2
Training loss: 2.15245163884259
Validation loss: 2.5266581128329237

Epoch: 6| Step: 3
Training loss: 2.6880011867452454
Validation loss: 2.5320227458912408

Epoch: 6| Step: 4
Training loss: 2.5724853792507236
Validation loss: 2.5308834829954687

Epoch: 6| Step: 5
Training loss: 2.0829968244260115
Validation loss: 2.5493934832557006

Epoch: 6| Step: 6
Training loss: 2.390666487589353
Validation loss: 2.574582152767945

Epoch: 6| Step: 7
Training loss: 2.3921971356417733
Validation loss: 2.612022738072403

Epoch: 6| Step: 8
Training loss: 2.28105350850053
Validation loss: 2.592800050436712

Epoch: 6| Step: 9
Training loss: 1.99526124080335
Validation loss: 2.599647951468939

Epoch: 6| Step: 10
Training loss: 2.491831786979621
Validation loss: 2.5861535369496593

Epoch: 6| Step: 11
Training loss: 2.3047033277065085
Validation loss: 2.5741606331434936

Epoch: 6| Step: 12
Training loss: 1.8129633607186741
Validation loss: 2.5186821896702396

Epoch: 6| Step: 13
Training loss: 1.420629270037818
Validation loss: 2.4950799355227375

Epoch: 151| Step: 0
Training loss: 1.8913004275581111
Validation loss: 2.443984538275157

Epoch: 6| Step: 1
Training loss: 2.0692901966319748
Validation loss: 2.4521629579502386

Epoch: 6| Step: 2
Training loss: 2.5159676833753375
Validation loss: 2.4397581823965004

Epoch: 6| Step: 3
Training loss: 2.39973181179787
Validation loss: 2.4438050799025097

Epoch: 6| Step: 4
Training loss: 2.7068399469065296
Validation loss: 2.446753959159208

Epoch: 6| Step: 5
Training loss: 1.8941181794368955
Validation loss: 2.4671384178269724

Epoch: 6| Step: 6
Training loss: 2.16477475340304
Validation loss: 2.4629790359906614

Epoch: 6| Step: 7
Training loss: 1.9906956490955319
Validation loss: 2.4960977966172058

Epoch: 6| Step: 8
Training loss: 2.4096590144368837
Validation loss: 2.5017086804068107

Epoch: 6| Step: 9
Training loss: 1.8121866415712153
Validation loss: 2.507091192692065

Epoch: 6| Step: 10
Training loss: 2.3053522735304512
Validation loss: 2.5383517958245996

Epoch: 6| Step: 11
Training loss: 2.8598467328278474
Validation loss: 2.56394003426746

Epoch: 6| Step: 12
Training loss: 2.296884342096754
Validation loss: 2.5688669784318234

Epoch: 6| Step: 13
Training loss: 1.8434760973223725
Validation loss: 2.5899603040450563

Epoch: 152| Step: 0
Training loss: 2.0084907781319448
Validation loss: 2.590883461220522

Epoch: 6| Step: 1
Training loss: 2.3969958815748145
Validation loss: 2.6087416426158225

Epoch: 6| Step: 2
Training loss: 2.4852393224287463
Validation loss: 2.571167328793019

Epoch: 6| Step: 3
Training loss: 2.390871222288771
Validation loss: 2.5430146421399584

Epoch: 6| Step: 4
Training loss: 2.161402199870374
Validation loss: 2.5006314167330435

Epoch: 6| Step: 5
Training loss: 1.5907729524104328
Validation loss: 2.4793270114726242

Epoch: 6| Step: 6
Training loss: 2.4409407759392825
Validation loss: 2.447660802919414

Epoch: 6| Step: 7
Training loss: 2.1078415559727084
Validation loss: 2.455739972320207

Epoch: 6| Step: 8
Training loss: 2.5095486439521957
Validation loss: 2.484414140905435

Epoch: 6| Step: 9
Training loss: 1.8427992486889688
Validation loss: 2.4968272205815274

Epoch: 6| Step: 10
Training loss: 2.291277233904676
Validation loss: 2.5054737111083196

Epoch: 6| Step: 11
Training loss: 2.2044283211004783
Validation loss: 2.5535283889389633

Epoch: 6| Step: 12
Training loss: 2.4853623065828674
Validation loss: 2.5718063320803934

Epoch: 6| Step: 13
Training loss: 1.8475803093496261
Validation loss: 2.5920570344906526

Epoch: 153| Step: 0
Training loss: 1.9384379423892169
Validation loss: 2.576239336356958

Epoch: 6| Step: 1
Training loss: 2.627522301257121
Validation loss: 2.5808267457075944

Epoch: 6| Step: 2
Training loss: 1.4317432070171814
Validation loss: 2.5417258879245974

Epoch: 6| Step: 3
Training loss: 2.0812185107532444
Validation loss: 2.521420499847372

Epoch: 6| Step: 4
Training loss: 2.0333485253605534
Validation loss: 2.5066522017310096

Epoch: 6| Step: 5
Training loss: 2.063121008581665
Validation loss: 2.5037713880882118

Epoch: 6| Step: 6
Training loss: 2.342694668004159
Validation loss: 2.483674879248679

Epoch: 6| Step: 7
Training loss: 2.249129020806474
Validation loss: 2.471020414806079

Epoch: 6| Step: 8
Training loss: 2.1376138935642666
Validation loss: 2.4714754449315466

Epoch: 6| Step: 9
Training loss: 2.561158084737424
Validation loss: 2.4835599807288937

Epoch: 6| Step: 10
Training loss: 2.4608809207285627
Validation loss: 2.517480897204593

Epoch: 6| Step: 11
Training loss: 1.988378975795484
Validation loss: 2.5211988184315386

Epoch: 6| Step: 12
Training loss: 2.2137676766894443
Validation loss: 2.559904201877241

Epoch: 6| Step: 13
Training loss: 2.2550630823687943
Validation loss: 2.5869238674690735

Epoch: 154| Step: 0
Training loss: 1.6076849795115857
Validation loss: 2.564442655296763

Epoch: 6| Step: 1
Training loss: 2.5507006785824933
Validation loss: 2.5780471297778766

Epoch: 6| Step: 2
Training loss: 2.2904169547617648
Validation loss: 2.5670521967850695

Epoch: 6| Step: 3
Training loss: 2.4332911026133663
Validation loss: 2.575058948484457

Epoch: 6| Step: 4
Training loss: 2.368166579412322
Validation loss: 2.577745826260561

Epoch: 6| Step: 5
Training loss: 1.5823984732459468
Validation loss: 2.572216703123625

Epoch: 6| Step: 6
Training loss: 2.184804727309095
Validation loss: 2.583362446864716

Epoch: 6| Step: 7
Training loss: 2.2565127528832094
Validation loss: 2.577259830152944

Epoch: 6| Step: 8
Training loss: 2.254486696814439
Validation loss: 2.5586392361423136

Epoch: 6| Step: 9
Training loss: 2.314911693099887
Validation loss: 2.5844001588354306

Epoch: 6| Step: 10
Training loss: 2.1392650878916273
Validation loss: 2.5498572546656306

Epoch: 6| Step: 11
Training loss: 2.218891407933294
Validation loss: 2.506292625312106

Epoch: 6| Step: 12
Training loss: 1.6597690265321698
Validation loss: 2.50376516628148

Epoch: 6| Step: 13
Training loss: 2.280175047228216
Validation loss: 2.5044551519872376

Epoch: 155| Step: 0
Training loss: 2.586635806482938
Validation loss: 2.5471027533390393

Epoch: 6| Step: 1
Training loss: 1.499265252406446
Validation loss: 2.5351891483192435

Epoch: 6| Step: 2
Training loss: 2.62223870502112
Validation loss: 2.536519078023438

Epoch: 6| Step: 3
Training loss: 2.191461518214598
Validation loss: 2.513627745477182

Epoch: 6| Step: 4
Training loss: 2.5376890253027153
Validation loss: 2.504264142122635

Epoch: 6| Step: 5
Training loss: 1.5599015564301402
Validation loss: 2.537854477831669

Epoch: 6| Step: 6
Training loss: 2.2425696283288135
Validation loss: 2.552227469403236

Epoch: 6| Step: 7
Training loss: 2.369719004652396
Validation loss: 2.5693805919082924

Epoch: 6| Step: 8
Training loss: 2.4339213388061856
Validation loss: 2.5646382346505763

Epoch: 6| Step: 9
Training loss: 2.3233347517946017
Validation loss: 2.535194757564961

Epoch: 6| Step: 10
Training loss: 1.7229643046732637
Validation loss: 2.520300647615238

Epoch: 6| Step: 11
Training loss: 2.5590396871049546
Validation loss: 2.506258783045557

Epoch: 6| Step: 12
Training loss: 1.8969155321394195
Validation loss: 2.502789701596877

Epoch: 6| Step: 13
Training loss: 1.6533854922916813
Validation loss: 2.5110457839669547

Epoch: 156| Step: 0
Training loss: 2.209086475660426
Validation loss: 2.5478248830464763

Epoch: 6| Step: 1
Training loss: 2.2489446708213547
Validation loss: 2.6114124942200236

Epoch: 6| Step: 2
Training loss: 2.559475858794712
Validation loss: 2.6593275276852664

Epoch: 6| Step: 3
Training loss: 2.2769969852848058
Validation loss: 2.6612374799845004

Epoch: 6| Step: 4
Training loss: 2.1327090954429093
Validation loss: 2.6240748324519747

Epoch: 6| Step: 5
Training loss: 1.8397780485631559
Validation loss: 2.573569825467706

Epoch: 6| Step: 6
Training loss: 2.5272004501069465
Validation loss: 2.5670460599443166

Epoch: 6| Step: 7
Training loss: 1.5570133772846837
Validation loss: 2.541602232903226

Epoch: 6| Step: 8
Training loss: 2.36071516968179
Validation loss: 2.5444161696477408

Epoch: 6| Step: 9
Training loss: 2.089908092613474
Validation loss: 2.573670213690381

Epoch: 6| Step: 10
Training loss: 2.331499764406641
Validation loss: 2.565011861033676

Epoch: 6| Step: 11
Training loss: 1.6941665784639084
Validation loss: 2.5574407899732856

Epoch: 6| Step: 12
Training loss: 1.9936809252788368
Validation loss: 2.5316469495771696

Epoch: 6| Step: 13
Training loss: 2.199751415080116
Validation loss: 2.527420565934976

Epoch: 157| Step: 0
Training loss: 2.3186865867313315
Validation loss: 2.5050166095951525

Epoch: 6| Step: 1
Training loss: 2.0234633042741095
Validation loss: 2.501115345060024

Epoch: 6| Step: 2
Training loss: 1.550570226191619
Validation loss: 2.4918573714867187

Epoch: 6| Step: 3
Training loss: 2.29201996131846
Validation loss: 2.54215888171587

Epoch: 6| Step: 4
Training loss: 2.073348212888913
Validation loss: 2.5707044539784962

Epoch: 6| Step: 5
Training loss: 1.8898422890918094
Validation loss: 2.5478003354888124

Epoch: 6| Step: 6
Training loss: 2.0961954439783206
Validation loss: 2.539264800513574

Epoch: 6| Step: 7
Training loss: 2.4270183461756814
Validation loss: 2.5273135953834616

Epoch: 6| Step: 8
Training loss: 2.2232723086254595
Validation loss: 2.5683778708890057

Epoch: 6| Step: 9
Training loss: 2.3198747318254718
Validation loss: 2.5320537095856497

Epoch: 6| Step: 10
Training loss: 2.2940462300532083
Validation loss: 2.5253127681790413

Epoch: 6| Step: 11
Training loss: 2.0915636632515113
Validation loss: 2.521283237625941

Epoch: 6| Step: 12
Training loss: 1.6129413089563103
Validation loss: 2.5390861677986676

Epoch: 6| Step: 13
Training loss: 2.2569903820612076
Validation loss: 2.5411476406847315

Epoch: 158| Step: 0
Training loss: 2.1214395876915404
Validation loss: 2.5237043691648156

Epoch: 6| Step: 1
Training loss: 2.167233124069144
Validation loss: 2.5322800210069185

Epoch: 6| Step: 2
Training loss: 1.9031942921819478
Validation loss: 2.532218196977785

Epoch: 6| Step: 3
Training loss: 1.8973104011792197
Validation loss: 2.5399976438540963

Epoch: 6| Step: 4
Training loss: 2.1414007187514073
Validation loss: 2.567539461052306

Epoch: 6| Step: 5
Training loss: 2.1130352899553477
Validation loss: 2.5988082696101222

Epoch: 6| Step: 6
Training loss: 2.4417425549619094
Validation loss: 2.627037049012063

Epoch: 6| Step: 7
Training loss: 2.176194211714761
Validation loss: 2.619340129191728

Epoch: 6| Step: 8
Training loss: 1.5876996252747735
Validation loss: 2.5769143561858048

Epoch: 6| Step: 9
Training loss: 2.1462475521937936
Validation loss: 2.5612501492367614

Epoch: 6| Step: 10
Training loss: 1.9692703043941933
Validation loss: 2.5259449801490845

Epoch: 6| Step: 11
Training loss: 2.349758330560003
Validation loss: 2.527316388460111

Epoch: 6| Step: 12
Training loss: 2.06858851790802
Validation loss: 2.518838124550523

Epoch: 6| Step: 13
Training loss: 2.3901195116368608
Validation loss: 2.513236624440532

Epoch: 159| Step: 0
Training loss: 2.266868723483845
Validation loss: 2.505361669015858

Epoch: 6| Step: 1
Training loss: 1.9038735256583827
Validation loss: 2.4837663921086515

Epoch: 6| Step: 2
Training loss: 2.2868537531947637
Validation loss: 2.483275874331288

Epoch: 6| Step: 3
Training loss: 2.3582433550848303
Validation loss: 2.5119137622008467

Epoch: 6| Step: 4
Training loss: 1.9181986435978573
Validation loss: 2.502851175001195

Epoch: 6| Step: 5
Training loss: 2.3536989765846204
Validation loss: 2.5371007557847696

Epoch: 6| Step: 6
Training loss: 2.4837975940646313
Validation loss: 2.5737140607750812

Epoch: 6| Step: 7
Training loss: 2.1562608359244257
Validation loss: 2.6068533471422852

Epoch: 6| Step: 8
Training loss: 1.857814486593174
Validation loss: 2.6452256262904084

Epoch: 6| Step: 9
Training loss: 1.8274364641993508
Validation loss: 2.660899883912881

Epoch: 6| Step: 10
Training loss: 2.0140955837187136
Validation loss: 2.7034238533569264

Epoch: 6| Step: 11
Training loss: 1.8477286391160945
Validation loss: 2.6660418996290343

Epoch: 6| Step: 12
Training loss: 1.5451833549511498
Validation loss: 2.6802686887786273

Epoch: 6| Step: 13
Training loss: 1.704366389030076
Validation loss: 2.6720172321539946

Epoch: 160| Step: 0
Training loss: 1.4338742847003538
Validation loss: 2.6619673058990094

Epoch: 6| Step: 1
Training loss: 2.4476698947188904
Validation loss: 2.635055808791912

Epoch: 6| Step: 2
Training loss: 2.083719624628049
Validation loss: 2.601436413987893

Epoch: 6| Step: 3
Training loss: 2.032748564551103
Validation loss: 2.5785624878994877

Epoch: 6| Step: 4
Training loss: 1.3642885700272978
Validation loss: 2.5638099381599675

Epoch: 6| Step: 5
Training loss: 2.178294403187505
Validation loss: 2.5686423265731926

Epoch: 6| Step: 6
Training loss: 2.2635778188707674
Validation loss: 2.5875622303177908

Epoch: 6| Step: 7
Training loss: 1.984880998633256
Validation loss: 2.5696415403675106

Epoch: 6| Step: 8
Training loss: 2.170909419956476
Validation loss: 2.545773842184981

Epoch: 6| Step: 9
Training loss: 1.6597289489155778
Validation loss: 2.5406958610308266

Epoch: 6| Step: 10
Training loss: 2.2253934233803387
Validation loss: 2.559779234695289

Epoch: 6| Step: 11
Training loss: 1.9645219846540498
Validation loss: 2.5489285734150244

Epoch: 6| Step: 12
Training loss: 1.9700356176225693
Validation loss: 2.557087742863208

Epoch: 6| Step: 13
Training loss: 1.9111363055665573
Validation loss: 2.566825421535849

Epoch: 161| Step: 0
Training loss: 1.5056750707982258
Validation loss: 2.555060914900832

Epoch: 6| Step: 1
Training loss: 2.160295754423924
Validation loss: 2.563423846584185

Epoch: 6| Step: 2
Training loss: 2.39727596027744
Validation loss: 2.564355384113598

Epoch: 6| Step: 3
Training loss: 2.1261997202154226
Validation loss: 2.571383038407575

Epoch: 6| Step: 4
Training loss: 1.8490833795376622
Validation loss: 2.561600047624248

Epoch: 6| Step: 5
Training loss: 1.4982540778109854
Validation loss: 2.5926705451869787

Epoch: 6| Step: 6
Training loss: 2.556134948379802
Validation loss: 2.5959107173160034

Epoch: 6| Step: 7
Training loss: 2.133772525679627
Validation loss: 2.623285781775041

Epoch: 6| Step: 8
Training loss: 1.9708571284055976
Validation loss: 2.598437971559376

Epoch: 6| Step: 9
Training loss: 1.3890122051595346
Validation loss: 2.6097352411262156

Epoch: 6| Step: 10
Training loss: 1.526627238373883
Validation loss: 2.6158605271069013

Epoch: 6| Step: 11
Training loss: 1.7515621025364039
Validation loss: 2.60391379344834

Epoch: 6| Step: 12
Training loss: 2.5280434348926075
Validation loss: 2.5632737294947026

Epoch: 6| Step: 13
Training loss: 1.9798268137434654
Validation loss: 2.5787675342128025

Epoch: 162| Step: 0
Training loss: 1.556038274495308
Validation loss: 2.5894217406470523

Epoch: 6| Step: 1
Training loss: 1.7678744410209364
Validation loss: 2.582866017775428

Epoch: 6| Step: 2
Training loss: 1.785476422135239
Validation loss: 2.6280370333149623

Epoch: 6| Step: 3
Training loss: 1.5857004072988579
Validation loss: 2.637796001953932

Epoch: 6| Step: 4
Training loss: 2.4830370485181983
Validation loss: 2.635884674150014

Epoch: 6| Step: 5
Training loss: 1.7842998829544885
Validation loss: 2.675587758540812

Epoch: 6| Step: 6
Training loss: 1.3935465608612465
Validation loss: 2.658416317320133

Epoch: 6| Step: 7
Training loss: 1.9506893993382006
Validation loss: 2.668528255695036

Epoch: 6| Step: 8
Training loss: 1.370040793542462
Validation loss: 2.669357769158434

Epoch: 6| Step: 9
Training loss: 2.467819424779267
Validation loss: 2.6664512326782117

Epoch: 6| Step: 10
Training loss: 2.4205514552228777
Validation loss: 2.647656219170349

Epoch: 6| Step: 11
Training loss: 2.5748914380937986
Validation loss: 2.617434179722704

Epoch: 6| Step: 12
Training loss: 1.458841625823876
Validation loss: 2.5902774059009435

Epoch: 6| Step: 13
Training loss: 2.034327830809372
Validation loss: 2.5639225042547955

Epoch: 163| Step: 0
Training loss: 1.8911202782960215
Validation loss: 2.5406617984418283

Epoch: 6| Step: 1
Training loss: 2.333366484633592
Validation loss: 2.5367982624006316

Epoch: 6| Step: 2
Training loss: 2.3021500406626196
Validation loss: 2.5782659338611027

Epoch: 6| Step: 3
Training loss: 2.138759273328358
Validation loss: 2.6088993483177303

Epoch: 6| Step: 4
Training loss: 1.913711204210321
Validation loss: 2.5831569633918887

Epoch: 6| Step: 5
Training loss: 1.870028007113997
Validation loss: 2.605872684618982

Epoch: 6| Step: 6
Training loss: 1.9533827954866207
Validation loss: 2.630184355173351

Epoch: 6| Step: 7
Training loss: 1.4886032917497294
Validation loss: 2.6977508078372527

Epoch: 6| Step: 8
Training loss: 1.9563424426774676
Validation loss: 2.6869152383964

Epoch: 6| Step: 9
Training loss: 1.6767913690585126
Validation loss: 2.6697649594687793

Epoch: 6| Step: 10
Training loss: 1.5044423126388413
Validation loss: 2.635237747092344

Epoch: 6| Step: 11
Training loss: 1.6142464399081398
Validation loss: 2.624938438697632

Epoch: 6| Step: 12
Training loss: 2.3683440653239916
Validation loss: 2.6001295243618814

Epoch: 6| Step: 13
Training loss: 1.5438985992449006
Validation loss: 2.575201686762408

Epoch: 164| Step: 0
Training loss: 1.856174374976121
Validation loss: 2.567566636579296

Epoch: 6| Step: 1
Training loss: 1.9258104674190808
Validation loss: 2.5687089876500213

Epoch: 6| Step: 2
Training loss: 1.9404618789006902
Validation loss: 2.586076221736139

Epoch: 6| Step: 3
Training loss: 1.3413614735492323
Validation loss: 2.6008991308568397

Epoch: 6| Step: 4
Training loss: 2.0303665587485726
Validation loss: 2.592720626096379

Epoch: 6| Step: 5
Training loss: 1.7878992555129525
Validation loss: 2.5988331363710593

Epoch: 6| Step: 6
Training loss: 1.948542047432121
Validation loss: 2.599264773711433

Epoch: 6| Step: 7
Training loss: 1.9841762653467387
Validation loss: 2.5938375477768036

Epoch: 6| Step: 8
Training loss: 1.817603325930427
Validation loss: 2.620391194530142

Epoch: 6| Step: 9
Training loss: 2.144960565449058
Validation loss: 2.606184779339902

Epoch: 6| Step: 10
Training loss: 2.4177223289530607
Validation loss: 2.6068831427348034

Epoch: 6| Step: 11
Training loss: 1.7185700755877866
Validation loss: 2.6124045283371453

Epoch: 6| Step: 12
Training loss: 1.7547288083031767
Validation loss: 2.618235605918583

Epoch: 6| Step: 13
Training loss: 1.129810063848176
Validation loss: 2.6210475587641975

Epoch: 165| Step: 0
Training loss: 2.3239189916335925
Validation loss: 2.60328153141497

Epoch: 6| Step: 1
Training loss: 1.9542793219763759
Validation loss: 2.582439304293691

Epoch: 6| Step: 2
Training loss: 1.7431931950034114
Validation loss: 2.56948595483698

Epoch: 6| Step: 3
Training loss: 1.6391575381178822
Validation loss: 2.6030310306040567

Epoch: 6| Step: 4
Training loss: 2.387423097660155
Validation loss: 2.5984176443877494

Epoch: 6| Step: 5
Training loss: 1.5423701803272916
Validation loss: 2.6088230295197805

Epoch: 6| Step: 6
Training loss: 2.0301731483016323
Validation loss: 2.597689214400575

Epoch: 6| Step: 7
Training loss: 1.5564192898145368
Validation loss: 2.6151215148471003

Epoch: 6| Step: 8
Training loss: 1.4184944292348363
Validation loss: 2.626320613674284

Epoch: 6| Step: 9
Training loss: 1.9017691557155036
Validation loss: 2.633585398237843

Epoch: 6| Step: 10
Training loss: 1.3796408968320075
Validation loss: 2.649609840741841

Epoch: 6| Step: 11
Training loss: 2.365741350948451
Validation loss: 2.646421983417293

Epoch: 6| Step: 12
Training loss: 2.059960275470703
Validation loss: 2.6718363638872162

Epoch: 6| Step: 13
Training loss: 1.1790733001643026
Validation loss: 2.65176443219985

Epoch: 166| Step: 0
Training loss: 1.4847202903291705
Validation loss: 2.6561008997842483

Epoch: 6| Step: 1
Training loss: 1.6293278795693167
Validation loss: 2.6367448965437483

Epoch: 6| Step: 2
Training loss: 1.4788979120518226
Validation loss: 2.6235484423123414

Epoch: 6| Step: 3
Training loss: 2.3240295846076995
Validation loss: 2.623475324896045

Epoch: 6| Step: 4
Training loss: 1.8591885513301152
Validation loss: 2.61452797804678

Epoch: 6| Step: 5
Training loss: 1.751874600865308
Validation loss: 2.6094038393547727

Epoch: 6| Step: 6
Training loss: 2.1476878574969285
Validation loss: 2.621454471580143

Epoch: 6| Step: 7
Training loss: 2.4164592610071916
Validation loss: 2.64828349147341

Epoch: 6| Step: 8
Training loss: 1.6271861116752468
Validation loss: 2.626619822674352

Epoch: 6| Step: 9
Training loss: 1.6157939269185808
Validation loss: 2.6292577610707473

Epoch: 6| Step: 10
Training loss: 1.800473664798532
Validation loss: 2.6267753463151537

Epoch: 6| Step: 11
Training loss: 1.928660625332705
Validation loss: 2.5931258524897953

Epoch: 6| Step: 12
Training loss: 2.1599215885341123
Validation loss: 2.598577061857076

Epoch: 6| Step: 13
Training loss: 1.5733276571289947
Validation loss: 2.5707063746854883

Epoch: 167| Step: 0
Training loss: 1.5806682979254079
Validation loss: 2.5353919257395554

Epoch: 6| Step: 1
Training loss: 2.1723108746172186
Validation loss: 2.511455892829626

Epoch: 6| Step: 2
Training loss: 1.8855281888179307
Validation loss: 2.5161751999128366

Epoch: 6| Step: 3
Training loss: 2.0074213144123805
Validation loss: 2.4942626527545344

Epoch: 6| Step: 4
Training loss: 1.6862367210685398
Validation loss: 2.4768972028667067

Epoch: 6| Step: 5
Training loss: 2.031115483451569
Validation loss: 2.5141406022666533

Epoch: 6| Step: 6
Training loss: 1.9075923008416837
Validation loss: 2.5468234116043895

Epoch: 6| Step: 7
Training loss: 1.910954907167242
Validation loss: 2.563699951064137

Epoch: 6| Step: 8
Training loss: 2.0297034611709432
Validation loss: 2.562995864668491

Epoch: 6| Step: 9
Training loss: 1.361586996282327
Validation loss: 2.610867798423863

Epoch: 6| Step: 10
Training loss: 1.3480460225237725
Validation loss: 2.6483085809789193

Epoch: 6| Step: 11
Training loss: 2.3270268250391752
Validation loss: 2.643082322586511

Epoch: 6| Step: 12
Training loss: 1.6753269104283557
Validation loss: 2.648130490489522

Epoch: 6| Step: 13
Training loss: 1.9052132460619653
Validation loss: 2.6111193043664547

Epoch: 168| Step: 0
Training loss: 1.4462127356315464
Validation loss: 2.60396802050242

Epoch: 6| Step: 1
Training loss: 2.095293301829345
Validation loss: 2.588896807860742

Epoch: 6| Step: 2
Training loss: 2.090363453925378
Validation loss: 2.59208413990036

Epoch: 6| Step: 3
Training loss: 1.7641236665458886
Validation loss: 2.584229461404535

Epoch: 6| Step: 4
Training loss: 1.4349226859661524
Validation loss: 2.5901688604136694

Epoch: 6| Step: 5
Training loss: 1.6848631850257898
Validation loss: 2.6127110858716183

Epoch: 6| Step: 6
Training loss: 1.7840471223671925
Validation loss: 2.5897029413461596

Epoch: 6| Step: 7
Training loss: 1.9043375646694527
Validation loss: 2.618225274905725

Epoch: 6| Step: 8
Training loss: 2.1938517315960646
Validation loss: 2.624618772139142

Epoch: 6| Step: 9
Training loss: 1.8127640498959297
Validation loss: 2.575455295538433

Epoch: 6| Step: 10
Training loss: 1.5530928671753808
Validation loss: 2.5605715326378617

Epoch: 6| Step: 11
Training loss: 1.7235506465011952
Validation loss: 2.5334545690054227

Epoch: 6| Step: 12
Training loss: 1.6418655791373589
Validation loss: 2.5459822874292857

Epoch: 6| Step: 13
Training loss: 2.516036195497681
Validation loss: 2.5445018648344715

Epoch: 169| Step: 0
Training loss: 1.717091957051499
Validation loss: 2.502338387414474

Epoch: 6| Step: 1
Training loss: 1.5334151394762527
Validation loss: 2.5043420155671194

Epoch: 6| Step: 2
Training loss: 1.3662910356143907
Validation loss: 2.513346813511526

Epoch: 6| Step: 3
Training loss: 2.346347539273526
Validation loss: 2.520804399368205

Epoch: 6| Step: 4
Training loss: 1.38534520856475
Validation loss: 2.538799244601242

Epoch: 6| Step: 5
Training loss: 1.6541734309342428
Validation loss: 2.538333420496709

Epoch: 6| Step: 6
Training loss: 2.0994065581547896
Validation loss: 2.5599212256323596

Epoch: 6| Step: 7
Training loss: 1.9443291932721432
Validation loss: 2.5680018082157026

Epoch: 6| Step: 8
Training loss: 1.671833929110017
Validation loss: 2.5899255100224803

Epoch: 6| Step: 9
Training loss: 1.5789170496522662
Validation loss: 2.5763281563233797

Epoch: 6| Step: 10
Training loss: 1.8843614214001467
Validation loss: 2.5837870830165945

Epoch: 6| Step: 11
Training loss: 1.7487244725903441
Validation loss: 2.566919370103005

Epoch: 6| Step: 12
Training loss: 2.184520545225475
Validation loss: 2.5820422619804537

Epoch: 6| Step: 13
Training loss: 2.041812722827164
Validation loss: 2.592225695438441

Epoch: 170| Step: 0
Training loss: 2.0410642189191286
Validation loss: 2.600753825524027

Epoch: 6| Step: 1
Training loss: 1.4546221332225133
Validation loss: 2.6486467743459956

Epoch: 6| Step: 2
Training loss: 1.862677646331994
Validation loss: 2.6151264507242074

Epoch: 6| Step: 3
Training loss: 1.323101461324576
Validation loss: 2.640163795177606

Epoch: 6| Step: 4
Training loss: 2.014743345967935
Validation loss: 2.635245363374235

Epoch: 6| Step: 5
Training loss: 1.9036559919163656
Validation loss: 2.599193701342022

Epoch: 6| Step: 6
Training loss: 2.0649176790394614
Validation loss: 2.6108762860514814

Epoch: 6| Step: 7
Training loss: 0.9666910749401261
Validation loss: 2.6349570344398865

Epoch: 6| Step: 8
Training loss: 1.6487560958691772
Validation loss: 2.6350474165600426

Epoch: 6| Step: 9
Training loss: 1.7967821843598175
Validation loss: 2.6099225258800223

Epoch: 6| Step: 10
Training loss: 1.4934658147311266
Validation loss: 2.635957868470742

Epoch: 6| Step: 11
Training loss: 2.034768563684226
Validation loss: 2.6026470723778563

Epoch: 6| Step: 12
Training loss: 1.7032808704968947
Validation loss: 2.581329075976292

Epoch: 6| Step: 13
Training loss: 2.193255889978591
Validation loss: 2.55392284451724

Epoch: 171| Step: 0
Training loss: 1.8468176973234842
Validation loss: 2.5560641340755113

Epoch: 6| Step: 1
Training loss: 1.306007859269193
Validation loss: 2.5085462916885715

Epoch: 6| Step: 2
Training loss: 1.8282275700934845
Validation loss: 2.551499554430421

Epoch: 6| Step: 3
Training loss: 1.8143757946342491
Validation loss: 2.5587342136743563

Epoch: 6| Step: 4
Training loss: 1.236337044007249
Validation loss: 2.5603907338163476

Epoch: 6| Step: 5
Training loss: 1.882529716307815
Validation loss: 2.5552181101658875

Epoch: 6| Step: 6
Training loss: 1.4869510182546286
Validation loss: 2.5634090172872868

Epoch: 6| Step: 7
Training loss: 1.5294767739215043
Validation loss: 2.57352881597283

Epoch: 6| Step: 8
Training loss: 0.9460413621404802
Validation loss: 2.575293000346387

Epoch: 6| Step: 9
Training loss: 1.6827388991728058
Validation loss: 2.604964749678749

Epoch: 6| Step: 10
Training loss: 2.370207921174767
Validation loss: 2.609636607671668

Epoch: 6| Step: 11
Training loss: 1.732624992496652
Validation loss: 2.613287487219093

Epoch: 6| Step: 12
Training loss: 2.440813599942258
Validation loss: 2.580964628661184

Epoch: 6| Step: 13
Training loss: 1.663974956663287
Validation loss: 2.59824257826579

Epoch: 172| Step: 0
Training loss: 2.163448315441445
Validation loss: 2.640545243783675

Epoch: 6| Step: 1
Training loss: 1.8118427005558781
Validation loss: 2.6171661797287054

Epoch: 6| Step: 2
Training loss: 1.4621533724835152
Validation loss: 2.609237925688494

Epoch: 6| Step: 3
Training loss: 1.5169554700910426
Validation loss: 2.6088025582303707

Epoch: 6| Step: 4
Training loss: 1.4434718603094163
Validation loss: 2.585164257543373

Epoch: 6| Step: 5
Training loss: 1.8776259789189715
Validation loss: 2.5586256465944843

Epoch: 6| Step: 6
Training loss: 1.8415845665676915
Validation loss: 2.5634296205659477

Epoch: 6| Step: 7
Training loss: 1.6540106263378642
Validation loss: 2.5451628350777313

Epoch: 6| Step: 8
Training loss: 1.4945721969139965
Validation loss: 2.532441234031716

Epoch: 6| Step: 9
Training loss: 1.952718097262559
Validation loss: 2.5623466631904592

Epoch: 6| Step: 10
Training loss: 1.7036069135691758
Validation loss: 2.573502019190256

Epoch: 6| Step: 11
Training loss: 1.7376672924930205
Validation loss: 2.568346043503822

Epoch: 6| Step: 12
Training loss: 1.8174713621546275
Validation loss: 2.56752722363396

Epoch: 6| Step: 13
Training loss: 0.8091932276744553
Validation loss: 2.590182095425301

Epoch: 173| Step: 0
Training loss: 1.369537426618541
Validation loss: 2.5801896872603427

Epoch: 6| Step: 1
Training loss: 1.8636168491585199
Validation loss: 2.5911257312621716

Epoch: 6| Step: 2
Training loss: 2.2075268214357893
Validation loss: 2.6021382507326347

Epoch: 6| Step: 3
Training loss: 1.0910485830495087
Validation loss: 2.635162835131943

Epoch: 6| Step: 4
Training loss: 1.8876747884093448
Validation loss: 2.614133756884284

Epoch: 6| Step: 5
Training loss: 1.8126691541992568
Validation loss: 2.6480853769002706

Epoch: 6| Step: 6
Training loss: 1.984353853848944
Validation loss: 2.6089487998200807

Epoch: 6| Step: 7
Training loss: 1.6166495197737034
Validation loss: 2.600064731258293

Epoch: 6| Step: 8
Training loss: 1.3900468460257438
Validation loss: 2.6254616188400726

Epoch: 6| Step: 9
Training loss: 1.4826582769138255
Validation loss: 2.6340782706379344

Epoch: 6| Step: 10
Training loss: 2.012169056094128
Validation loss: 2.6064402234657

Epoch: 6| Step: 11
Training loss: 1.537376991251453
Validation loss: 2.6058648408215204

Epoch: 6| Step: 12
Training loss: 1.6583096635110084
Validation loss: 2.6478353146023648

Epoch: 6| Step: 13
Training loss: 1.4480949218945465
Validation loss: 2.6384028573475176

Epoch: 174| Step: 0
Training loss: 2.248811619896657
Validation loss: 2.6031925674968446

Epoch: 6| Step: 1
Training loss: 1.8570329036231856
Validation loss: 2.6195485827064426

Epoch: 6| Step: 2
Training loss: 1.5201202270995002
Validation loss: 2.5859446954089553

Epoch: 6| Step: 3
Training loss: 1.8333263252586744
Validation loss: 2.598719294611675

Epoch: 6| Step: 4
Training loss: 1.4842209585470363
Validation loss: 2.613111648440501

Epoch: 6| Step: 5
Training loss: 1.5021412189703525
Validation loss: 2.6261646404127874

Epoch: 6| Step: 6
Training loss: 2.21280971018908
Validation loss: 2.596595305587574

Epoch: 6| Step: 7
Training loss: 1.7355459573431204
Validation loss: 2.640339367437216

Epoch: 6| Step: 8
Training loss: 1.6599436186212297
Validation loss: 2.639909276767602

Epoch: 6| Step: 9
Training loss: 1.2610094657318816
Validation loss: 2.6390490036643373

Epoch: 6| Step: 10
Training loss: 1.4353978916632688
Validation loss: 2.6192644513066994

Epoch: 6| Step: 11
Training loss: 1.7303940044302735
Validation loss: 2.624887132928316

Epoch: 6| Step: 12
Training loss: 1.2345802522780285
Validation loss: 2.6009802752659428

Epoch: 6| Step: 13
Training loss: 1.494868640933661
Validation loss: 2.597340588909194

Epoch: 175| Step: 0
Training loss: 1.7631225406341546
Validation loss: 2.563966278068209

Epoch: 6| Step: 1
Training loss: 1.860778343127302
Validation loss: 2.541664300719447

Epoch: 6| Step: 2
Training loss: 1.9602454434684744
Validation loss: 2.5461487757945283

Epoch: 6| Step: 3
Training loss: 1.4437295028750794
Validation loss: 2.528009405149831

Epoch: 6| Step: 4
Training loss: 1.1766967251065956
Validation loss: 2.5087658292978743

Epoch: 6| Step: 5
Training loss: 1.5306505859529391
Validation loss: 2.5152107442387615

Epoch: 6| Step: 6
Training loss: 1.8668209977156907
Validation loss: 2.5039044807753803

Epoch: 6| Step: 7
Training loss: 1.451585836397451
Validation loss: 2.537143252375014

Epoch: 6| Step: 8
Training loss: 1.9228794605406982
Validation loss: 2.5420757538066625

Epoch: 6| Step: 9
Training loss: 2.0199706081102753
Validation loss: 2.571838358868761

Epoch: 6| Step: 10
Training loss: 1.5353698581856983
Validation loss: 2.5724761301441195

Epoch: 6| Step: 11
Training loss: 1.4176817043848418
Validation loss: 2.5772925023754305

Epoch: 6| Step: 12
Training loss: 1.55661305555103
Validation loss: 2.5937346749434287

Epoch: 6| Step: 13
Training loss: 1.736843860699863
Validation loss: 2.6379765199696363

Epoch: 176| Step: 0
Training loss: 1.7921543640425857
Validation loss: 2.647319102002608

Epoch: 6| Step: 1
Training loss: 1.637738695292267
Validation loss: 2.6511066613422734

Epoch: 6| Step: 2
Training loss: 1.8596428429804703
Validation loss: 2.6302833048539256

Epoch: 6| Step: 3
Training loss: 1.437427684789403
Validation loss: 2.628839233248309

Epoch: 6| Step: 4
Training loss: 1.2066008655422957
Validation loss: 2.621286866832889

Epoch: 6| Step: 5
Training loss: 2.213201112168262
Validation loss: 2.603122367582295

Epoch: 6| Step: 6
Training loss: 1.8557548864486066
Validation loss: 2.5652221279443785

Epoch: 6| Step: 7
Training loss: 1.6649140520794963
Validation loss: 2.5626415660780215

Epoch: 6| Step: 8
Training loss: 1.9778138071104985
Validation loss: 2.5781839363369583

Epoch: 6| Step: 9
Training loss: 1.3904908361973143
Validation loss: 2.5500049233514726

Epoch: 6| Step: 10
Training loss: 1.563234614296692
Validation loss: 2.5601810654479413

Epoch: 6| Step: 11
Training loss: 1.467412136378435
Validation loss: 2.536316023807777

Epoch: 6| Step: 12
Training loss: 1.1135821019614305
Validation loss: 2.5321519268510073

Epoch: 6| Step: 13
Training loss: 1.5279127851231795
Validation loss: 2.55700457292437

Epoch: 177| Step: 0
Training loss: 1.4070167146786607
Validation loss: 2.5711636057210288

Epoch: 6| Step: 1
Training loss: 1.8650970887794904
Validation loss: 2.5543748651060563

Epoch: 6| Step: 2
Training loss: 1.5603355675246497
Validation loss: 2.5791047462970274

Epoch: 6| Step: 3
Training loss: 1.1934174119288057
Validation loss: 2.5762981596023997

Epoch: 6| Step: 4
Training loss: 1.4145670459616795
Validation loss: 2.581795994839728

Epoch: 6| Step: 5
Training loss: 0.9264522326055317
Validation loss: 2.587817699777055

Epoch: 6| Step: 6
Training loss: 1.6768214414206664
Validation loss: 2.5769642165397877

Epoch: 6| Step: 7
Training loss: 2.0067067942403884
Validation loss: 2.572856585687225

Epoch: 6| Step: 8
Training loss: 1.9004258782781678
Validation loss: 2.5701869736087866

Epoch: 6| Step: 9
Training loss: 1.7486937279744563
Validation loss: 2.563684768370464

Epoch: 6| Step: 10
Training loss: 1.8785905156365112
Validation loss: 2.5650794699798873

Epoch: 6| Step: 11
Training loss: 1.533018842179474
Validation loss: 2.5854927842731543

Epoch: 6| Step: 12
Training loss: 1.7807253014596112
Validation loss: 2.6120692734155107

Epoch: 6| Step: 13
Training loss: 1.8009254248904494
Validation loss: 2.6364791818404947

Epoch: 178| Step: 0
Training loss: 2.040185494871755
Validation loss: 2.65885378034784

Epoch: 6| Step: 1
Training loss: 2.0556283399508963
Validation loss: 2.6431578393721598

Epoch: 6| Step: 2
Training loss: 0.8281826503048287
Validation loss: 2.6212579547884354

Epoch: 6| Step: 3
Training loss: 1.110867315937765
Validation loss: 2.5817094155208795

Epoch: 6| Step: 4
Training loss: 1.4807449123508345
Validation loss: 2.5923170590890785

Epoch: 6| Step: 5
Training loss: 1.5323259893947692
Validation loss: 2.5658653964120113

Epoch: 6| Step: 6
Training loss: 1.8038120540907676
Validation loss: 2.5316573675703244

Epoch: 6| Step: 7
Training loss: 1.982893082564699
Validation loss: 2.5537369430950507

Epoch: 6| Step: 8
Training loss: 2.0909647849359017
Validation loss: 2.5495463723612093

Epoch: 6| Step: 9
Training loss: 1.0692233927825376
Validation loss: 2.523489920525254

Epoch: 6| Step: 10
Training loss: 1.2086275772854727
Validation loss: 2.5155614244756954

Epoch: 6| Step: 11
Training loss: 1.9850293379760744
Validation loss: 2.541199583900418

Epoch: 6| Step: 12
Training loss: 1.465085266548277
Validation loss: 2.5902562842721406

Epoch: 6| Step: 13
Training loss: 1.664553574290888
Validation loss: 2.638780381980427

Epoch: 179| Step: 0
Training loss: 1.8257062512175564
Validation loss: 2.636163146601829

Epoch: 6| Step: 1
Training loss: 1.883922961723225
Validation loss: 2.632333616454879

Epoch: 6| Step: 2
Training loss: 1.7450846715458417
Validation loss: 2.5811531011164717

Epoch: 6| Step: 3
Training loss: 1.8478001221981395
Validation loss: 2.598299174747636

Epoch: 6| Step: 4
Training loss: 1.9473265979828411
Validation loss: 2.6042982426700427

Epoch: 6| Step: 5
Training loss: 1.2629048821883135
Validation loss: 2.5959959371859744

Epoch: 6| Step: 6
Training loss: 1.5799377907203773
Validation loss: 2.628451718255075

Epoch: 6| Step: 7
Training loss: 1.68736210012362
Validation loss: 2.5945324009908655

Epoch: 6| Step: 8
Training loss: 1.8726997252674669
Validation loss: 2.5864292499187913

Epoch: 6| Step: 9
Training loss: 1.4534614747685866
Validation loss: 2.602481101297067

Epoch: 6| Step: 10
Training loss: 1.6765021349730922
Validation loss: 2.5940007546810446

Epoch: 6| Step: 11
Training loss: 1.4573022012645651
Validation loss: 2.652575755990671

Epoch: 6| Step: 12
Training loss: 1.7433811084675583
Validation loss: 2.62702252806037

Epoch: 6| Step: 13
Training loss: 1.3652513145520082
Validation loss: 2.63353285330241

Epoch: 180| Step: 0
Training loss: 1.542782542907758
Validation loss: 2.6037151823091276

Epoch: 6| Step: 1
Training loss: 1.7501528536935007
Validation loss: 2.5835597519255495

Epoch: 6| Step: 2
Training loss: 1.4885825505480517
Validation loss: 2.5546560309057016

Epoch: 6| Step: 3
Training loss: 1.250626502391212
Validation loss: 2.572352421516642

Epoch: 6| Step: 4
Training loss: 1.512276164744988
Validation loss: 2.5413049541022055

Epoch: 6| Step: 5
Training loss: 1.6193595710587685
Validation loss: 2.5739523394229145

Epoch: 6| Step: 6
Training loss: 1.8145683588694062
Validation loss: 2.556935907261606

Epoch: 6| Step: 7
Training loss: 1.693786496828446
Validation loss: 2.5656722427568464

Epoch: 6| Step: 8
Training loss: 1.7890411775476096
Validation loss: 2.5497504914313915

Epoch: 6| Step: 9
Training loss: 1.8046025508026762
Validation loss: 2.543168195467933

Epoch: 6| Step: 10
Training loss: 1.588108024401353
Validation loss: 2.5331324974829927

Epoch: 6| Step: 11
Training loss: 1.7554825324284422
Validation loss: 2.5639004005897745

Epoch: 6| Step: 12
Training loss: 1.5382118004058203
Validation loss: 2.542791690165764

Epoch: 6| Step: 13
Training loss: 1.7393342332794992
Validation loss: 2.5735168560752766

Epoch: 181| Step: 0
Training loss: 1.6129328095122557
Validation loss: 2.5330872491137053

Epoch: 6| Step: 1
Training loss: 1.6267165874158676
Validation loss: 2.525747190225094

Epoch: 6| Step: 2
Training loss: 1.3335466015643027
Validation loss: 2.5212326533552747

Epoch: 6| Step: 3
Training loss: 1.4423608281055642
Validation loss: 2.5445359440249797

Epoch: 6| Step: 4
Training loss: 1.784416997251642
Validation loss: 2.5678876928049004

Epoch: 6| Step: 5
Training loss: 1.5435878622184296
Validation loss: 2.5878097586555198

Epoch: 6| Step: 6
Training loss: 1.1061434355018656
Validation loss: 2.574761986935301

Epoch: 6| Step: 7
Training loss: 1.602182631108546
Validation loss: 2.6009530112240133

Epoch: 6| Step: 8
Training loss: 1.5739126357440663
Validation loss: 2.6153870929739136

Epoch: 6| Step: 9
Training loss: 1.8533203536660865
Validation loss: 2.657969378327276

Epoch: 6| Step: 10
Training loss: 2.0610023609797516
Validation loss: 2.6386626626067615

Epoch: 6| Step: 11
Training loss: 1.474123196317646
Validation loss: 2.6237150368752413

Epoch: 6| Step: 12
Training loss: 1.6780401623981154
Validation loss: 2.586427696229316

Epoch: 6| Step: 13
Training loss: 1.7684385450069875
Validation loss: 2.5739847050347593

Epoch: 182| Step: 0
Training loss: 2.098968152448406
Validation loss: 2.526305467392096

Epoch: 6| Step: 1
Training loss: 1.266523254373811
Validation loss: 2.5264025514214783

Epoch: 6| Step: 2
Training loss: 1.4681994441139572
Validation loss: 2.4943229760307313

Epoch: 6| Step: 3
Training loss: 1.810596123841381
Validation loss: 2.5137751223488642

Epoch: 6| Step: 4
Training loss: 1.316960385111281
Validation loss: 2.4696731077293883

Epoch: 6| Step: 5
Training loss: 1.3996248372677376
Validation loss: 2.524305580305678

Epoch: 6| Step: 6
Training loss: 1.173573191755619
Validation loss: 2.5254196559834723

Epoch: 6| Step: 7
Training loss: 1.6714340056166848
Validation loss: 2.5286257646418067

Epoch: 6| Step: 8
Training loss: 1.6697241950567714
Validation loss: 2.538893537555327

Epoch: 6| Step: 9
Training loss: 1.599326531412582
Validation loss: 2.568221443172259

Epoch: 6| Step: 10
Training loss: 1.9738061556036048
Validation loss: 2.5929228136613376

Epoch: 6| Step: 11
Training loss: 1.5296197114444505
Validation loss: 2.6015013202525616

Epoch: 6| Step: 12
Training loss: 1.406685231991751
Validation loss: 2.597332605837042

Epoch: 6| Step: 13
Training loss: 1.2871588319761205
Validation loss: 2.6073191649992498

Epoch: 183| Step: 0
Training loss: 1.5908403951502479
Validation loss: 2.6073006031826385

Epoch: 6| Step: 1
Training loss: 1.52516827202127
Validation loss: 2.597699480038609

Epoch: 6| Step: 2
Training loss: 1.553846735747171
Validation loss: 2.559564142696705

Epoch: 6| Step: 3
Training loss: 1.6835744197293352
Validation loss: 2.554740014862515

Epoch: 6| Step: 4
Training loss: 1.3484355939761026
Validation loss: 2.5308636879865096

Epoch: 6| Step: 5
Training loss: 1.6336550934127432
Validation loss: 2.578113767438466

Epoch: 6| Step: 6
Training loss: 1.3423118880056886
Validation loss: 2.5322834135045666

Epoch: 6| Step: 7
Training loss: 1.7532597563115988
Validation loss: 2.552279397055956

Epoch: 6| Step: 8
Training loss: 1.1362364489730354
Validation loss: 2.5593582830902704

Epoch: 6| Step: 9
Training loss: 1.808183067278106
Validation loss: 2.5452889550025515

Epoch: 6| Step: 10
Training loss: 1.7202578086370892
Validation loss: 2.5378397355048614

Epoch: 6| Step: 11
Training loss: 1.5343648409070108
Validation loss: 2.581988681020765

Epoch: 6| Step: 12
Training loss: 1.5212306544406768
Validation loss: 2.590887087680953

Epoch: 6| Step: 13
Training loss: 1.251308709747944
Validation loss: 2.6302685406126494

Epoch: 184| Step: 0
Training loss: 1.6709177003839235
Validation loss: 2.6229820835677184

Epoch: 6| Step: 1
Training loss: 1.8098942672027472
Validation loss: 2.626731023469562

Epoch: 6| Step: 2
Training loss: 1.4922220116264275
Validation loss: 2.6289880862911126

Epoch: 6| Step: 3
Training loss: 1.5205034220392617
Validation loss: 2.6018769926739096

Epoch: 6| Step: 4
Training loss: 1.3200613381121649
Validation loss: 2.5827086054173614

Epoch: 6| Step: 5
Training loss: 1.7831274478225674
Validation loss: 2.5911009646681364

Epoch: 6| Step: 6
Training loss: 1.326678441960267
Validation loss: 2.5914714910143863

Epoch: 6| Step: 7
Training loss: 1.660350115059362
Validation loss: 2.5607456441657703

Epoch: 6| Step: 8
Training loss: 1.0685813993902396
Validation loss: 2.5841365330362627

Epoch: 6| Step: 9
Training loss: 2.0573241283575894
Validation loss: 2.5921199206643224

Epoch: 6| Step: 10
Training loss: 1.4535266772257263
Validation loss: 2.6015200515541332

Epoch: 6| Step: 11
Training loss: 1.5382861197856117
Validation loss: 2.5976080293610813

Epoch: 6| Step: 12
Training loss: 1.666617496083046
Validation loss: 2.6084695794674784

Epoch: 6| Step: 13
Training loss: 0.3185185461633159
Validation loss: 2.6253455101177683

Epoch: 185| Step: 0
Training loss: 1.3801555647449397
Validation loss: 2.6216727527290415

Epoch: 6| Step: 1
Training loss: 1.4795086245992863
Validation loss: 2.6189171061913585

Epoch: 6| Step: 2
Training loss: 1.5702632307987132
Validation loss: 2.6255367534045173

Epoch: 6| Step: 3
Training loss: 1.5790512841311581
Validation loss: 2.6180139487201166

Epoch: 6| Step: 4
Training loss: 1.4329696252961834
Validation loss: 2.5962997320392853

Epoch: 6| Step: 5
Training loss: 1.6591991582831562
Validation loss: 2.594345364450725

Epoch: 6| Step: 6
Training loss: 1.6864441288080267
Validation loss: 2.5896138019987043

Epoch: 6| Step: 7
Training loss: 1.4489634821142354
Validation loss: 2.581909857947866

Epoch: 6| Step: 8
Training loss: 1.6657265236780527
Validation loss: 2.590057070761333

Epoch: 6| Step: 9
Training loss: 1.2236893162083826
Validation loss: 2.555528513165044

Epoch: 6| Step: 10
Training loss: 1.5758115978278477
Validation loss: 2.61724659010169

Epoch: 6| Step: 11
Training loss: 1.5346897959939587
Validation loss: 2.572900333047965

Epoch: 6| Step: 12
Training loss: 1.6475177386519921
Validation loss: 2.553944799646811

Epoch: 6| Step: 13
Training loss: 0.9583998878146187
Validation loss: 2.5536061615322434

Epoch: 186| Step: 0
Training loss: 1.4713958284224289
Validation loss: 2.5308551862753763

Epoch: 6| Step: 1
Training loss: 1.376116429429311
Validation loss: 2.527629967384545

Epoch: 6| Step: 2
Training loss: 1.4663946054735035
Validation loss: 2.5305827993494487

Epoch: 6| Step: 3
Training loss: 1.1536660576533757
Validation loss: 2.5540777349691997

Epoch: 6| Step: 4
Training loss: 1.7335271739166709
Validation loss: 2.546811508996854

Epoch: 6| Step: 5
Training loss: 1.8582437103054186
Validation loss: 2.525944661463121

Epoch: 6| Step: 6
Training loss: 1.2597614613545536
Validation loss: 2.576826596077769

Epoch: 6| Step: 7
Training loss: 1.6602383223049562
Validation loss: 2.5887259860517435

Epoch: 6| Step: 8
Training loss: 1.3533166075755003
Validation loss: 2.588150067751207

Epoch: 6| Step: 9
Training loss: 1.2668575360562835
Validation loss: 2.59304505449901

Epoch: 6| Step: 10
Training loss: 1.6529061733278503
Validation loss: 2.599986905817516

Epoch: 6| Step: 11
Training loss: 1.7555704016936302
Validation loss: 2.606919951592848

Epoch: 6| Step: 12
Training loss: 1.7032973176068669
Validation loss: 2.5681652060420173

Epoch: 6| Step: 13
Training loss: 1.0604076540001248
Validation loss: 2.5901929242908124

Epoch: 187| Step: 0
Training loss: 1.579357534598064
Validation loss: 2.577097607817288

Epoch: 6| Step: 1
Training loss: 1.4531013732958271
Validation loss: 2.565326688309508

Epoch: 6| Step: 2
Training loss: 1.6490979069502707
Validation loss: 2.536183193087863

Epoch: 6| Step: 3
Training loss: 1.5692842827528781
Validation loss: 2.546722765903125

Epoch: 6| Step: 4
Training loss: 1.2425224764228184
Validation loss: 2.5513960803016817

Epoch: 6| Step: 5
Training loss: 1.681238496308518
Validation loss: 2.5562099769464357

Epoch: 6| Step: 6
Training loss: 1.6409381385966162
Validation loss: 2.5536768060722164

Epoch: 6| Step: 7
Training loss: 1.4342796909024507
Validation loss: 2.5441753504596627

Epoch: 6| Step: 8
Training loss: 1.3326147149611112
Validation loss: 2.563757545084625

Epoch: 6| Step: 9
Training loss: 1.2195842528570524
Validation loss: 2.5514004994045556

Epoch: 6| Step: 10
Training loss: 1.060457510370821
Validation loss: 2.5592714535782175

Epoch: 6| Step: 11
Training loss: 1.640281423287787
Validation loss: 2.5640433761156363

Epoch: 6| Step: 12
Training loss: 1.6029682224048594
Validation loss: 2.5725353194669793

Epoch: 6| Step: 13
Training loss: 1.7387203733441812
Validation loss: 2.548348464688577

Epoch: 188| Step: 0
Training loss: 1.452705732998184
Validation loss: 2.582095176616942

Epoch: 6| Step: 1
Training loss: 1.3283406699603009
Validation loss: 2.588641017069343

Epoch: 6| Step: 2
Training loss: 1.62947976241255
Validation loss: 2.56926493475418

Epoch: 6| Step: 3
Training loss: 1.3754696044087207
Validation loss: 2.5752737627138855

Epoch: 6| Step: 4
Training loss: 1.545742198111859
Validation loss: 2.5975939557925978

Epoch: 6| Step: 5
Training loss: 1.2570421217216512
Validation loss: 2.5856186056996098

Epoch: 6| Step: 6
Training loss: 1.7542867608841641
Validation loss: 2.5981686559435895

Epoch: 6| Step: 7
Training loss: 1.7464247012283545
Validation loss: 2.574788053722227

Epoch: 6| Step: 8
Training loss: 1.5242965232602756
Validation loss: 2.5787640716415514

Epoch: 6| Step: 9
Training loss: 1.234997556120273
Validation loss: 2.540290881445991

Epoch: 6| Step: 10
Training loss: 1.657721675358714
Validation loss: 2.5562127289215004

Epoch: 6| Step: 11
Training loss: 1.1116376556393286
Validation loss: 2.557073270830562

Epoch: 6| Step: 12
Training loss: 1.3989349844265335
Validation loss: 2.512445817327546

Epoch: 6| Step: 13
Training loss: 1.491768263796929
Validation loss: 2.5087310935426475

Epoch: 189| Step: 0
Training loss: 1.2281876021487017
Validation loss: 2.517701161724165

Epoch: 6| Step: 1
Training loss: 1.3560146584660928
Validation loss: 2.4811886856993453

Epoch: 6| Step: 2
Training loss: 1.4430910927087968
Validation loss: 2.4853192257898433

Epoch: 6| Step: 3
Training loss: 1.5192360873254631
Validation loss: 2.4932076678765376

Epoch: 6| Step: 4
Training loss: 1.6463717131346913
Validation loss: 2.505155617078675

Epoch: 6| Step: 5
Training loss: 1.512727149741628
Validation loss: 2.5113058997245754

Epoch: 6| Step: 6
Training loss: 1.6142799666696652
Validation loss: 2.561050327123574

Epoch: 6| Step: 7
Training loss: 1.655993171788388
Validation loss: 2.5688914733783994

Epoch: 6| Step: 8
Training loss: 1.2014454599829318
Validation loss: 2.536304488836115

Epoch: 6| Step: 9
Training loss: 1.1383456094805018
Validation loss: 2.560324535042123

Epoch: 6| Step: 10
Training loss: 1.2481819282733249
Validation loss: 2.5855877123606064

Epoch: 6| Step: 11
Training loss: 1.8233788985092172
Validation loss: 2.569605250058086

Epoch: 6| Step: 12
Training loss: 1.7302328599098211
Validation loss: 2.5552294734734504

Epoch: 6| Step: 13
Training loss: 0.7653184393780399
Validation loss: 2.565864649060464

Epoch: 190| Step: 0
Training loss: 1.7270138526011933
Validation loss: 2.51701272679427

Epoch: 6| Step: 1
Training loss: 1.5127400735791996
Validation loss: 2.524489452949794

Epoch: 6| Step: 2
Training loss: 1.6978458865650194
Validation loss: 2.5506970522761745

Epoch: 6| Step: 3
Training loss: 1.3055599744645314
Validation loss: 2.5420133289399405

Epoch: 6| Step: 4
Training loss: 1.191049090772605
Validation loss: 2.557252316244946

Epoch: 6| Step: 5
Training loss: 1.4658240534908125
Validation loss: 2.5375026927961795

Epoch: 6| Step: 6
Training loss: 1.6026314494335943
Validation loss: 2.546180135572195

Epoch: 6| Step: 7
Training loss: 1.4933063247202374
Validation loss: 2.5379452249980723

Epoch: 6| Step: 8
Training loss: 1.7185764571921402
Validation loss: 2.564067988131016

Epoch: 6| Step: 9
Training loss: 1.445144561083492
Validation loss: 2.5381849919740325

Epoch: 6| Step: 10
Training loss: 0.8932181970276766
Validation loss: 2.5552748820543223

Epoch: 6| Step: 11
Training loss: 1.7403017795237343
Validation loss: 2.5400161656026845

Epoch: 6| Step: 12
Training loss: 1.2464673669049797
Validation loss: 2.536840615505225

Epoch: 6| Step: 13
Training loss: 0.8490972268784942
Validation loss: 2.529873926514627

Epoch: 191| Step: 0
Training loss: 1.6221677600450997
Validation loss: 2.5259746512600474

Epoch: 6| Step: 1
Training loss: 1.3013377789033198
Validation loss: 2.533059280127663

Epoch: 6| Step: 2
Training loss: 1.4992767020629496
Validation loss: 2.5671950007715116

Epoch: 6| Step: 3
Training loss: 1.6489455899942838
Validation loss: 2.5871745346308463

Epoch: 6| Step: 4
Training loss: 1.2844819036020525
Validation loss: 2.564044290971752

Epoch: 6| Step: 5
Training loss: 1.511800916543242
Validation loss: 2.5497630132456566

Epoch: 6| Step: 6
Training loss: 0.843936970092815
Validation loss: 2.549609251282871

Epoch: 6| Step: 7
Training loss: 1.4599616723712616
Validation loss: 2.5730050018545567

Epoch: 6| Step: 8
Training loss: 1.248977242719831
Validation loss: 2.5716118631261558

Epoch: 6| Step: 9
Training loss: 1.881674204806469
Validation loss: 2.58832886316057

Epoch: 6| Step: 10
Training loss: 1.284524687052031
Validation loss: 2.598789067943764

Epoch: 6| Step: 11
Training loss: 0.8405517078200094
Validation loss: 2.6113823738181527

Epoch: 6| Step: 12
Training loss: 1.5725597793545258
Validation loss: 2.618335159896525

Epoch: 6| Step: 13
Training loss: 2.0035271536974553
Validation loss: 2.6110872355803516

Epoch: 192| Step: 0
Training loss: 1.4784649093173925
Validation loss: 2.603831221766981

Epoch: 6| Step: 1
Training loss: 1.0284718748669177
Validation loss: 2.5425766896469395

Epoch: 6| Step: 2
Training loss: 0.9893618620279131
Validation loss: 2.5651594518426832

Epoch: 6| Step: 3
Training loss: 1.7419467639956654
Validation loss: 2.529400401804417

Epoch: 6| Step: 4
Training loss: 1.6627803394037182
Validation loss: 2.5281907076043857

Epoch: 6| Step: 5
Training loss: 1.4390310344093222
Validation loss: 2.5279879539161727

Epoch: 6| Step: 6
Training loss: 1.4090178060306715
Validation loss: 2.5194184995636366

Epoch: 6| Step: 7
Training loss: 1.105642567910658
Validation loss: 2.5555466299278624

Epoch: 6| Step: 8
Training loss: 1.3711907333460398
Validation loss: 2.576314320758598

Epoch: 6| Step: 9
Training loss: 1.9004503419124623
Validation loss: 2.574664836543469

Epoch: 6| Step: 10
Training loss: 1.2228127278874392
Validation loss: 2.609310408474316

Epoch: 6| Step: 11
Training loss: 1.4101565036086596
Validation loss: 2.6677427319098697

Epoch: 6| Step: 12
Training loss: 1.6812382126859389
Validation loss: 2.6343865051707285

Epoch: 6| Step: 13
Training loss: 1.6551624542209356
Validation loss: 2.619752125753673

Epoch: 193| Step: 0
Training loss: 1.4916444759032481
Validation loss: 2.606158425550995

Epoch: 6| Step: 1
Training loss: 1.3139695614347675
Validation loss: 2.5967007697151705

Epoch: 6| Step: 2
Training loss: 1.2796396043917955
Validation loss: 2.5494013921965744

Epoch: 6| Step: 3
Training loss: 1.2681994216010426
Validation loss: 2.5399074423907133

Epoch: 6| Step: 4
Training loss: 1.5422237867359014
Validation loss: 2.502045539043936

Epoch: 6| Step: 5
Training loss: 1.3348105066092275
Validation loss: 2.518904141419748

Epoch: 6| Step: 6
Training loss: 1.447931257581491
Validation loss: 2.491971370997335

Epoch: 6| Step: 7
Training loss: 1.2182035933027442
Validation loss: 2.4809958670026964

Epoch: 6| Step: 8
Training loss: 1.7010457356722166
Validation loss: 2.479480239286284

Epoch: 6| Step: 9
Training loss: 1.4434072773047355
Validation loss: 2.47443417250239

Epoch: 6| Step: 10
Training loss: 1.4653020930068112
Validation loss: 2.4688610562316726

Epoch: 6| Step: 11
Training loss: 1.4952119065971494
Validation loss: 2.4755506056967107

Epoch: 6| Step: 12
Training loss: 1.24009922522733
Validation loss: 2.504337193013895

Epoch: 6| Step: 13
Training loss: 1.5763024107094885
Validation loss: 2.4898695765523002

Epoch: 194| Step: 0
Training loss: 1.39550230266746
Validation loss: 2.493558656852861

Epoch: 6| Step: 1
Training loss: 1.2087445491127418
Validation loss: 2.5009303197533552

Epoch: 6| Step: 2
Training loss: 1.306530045418979
Validation loss: 2.5060275744888125

Epoch: 6| Step: 3
Training loss: 1.1325687014560137
Validation loss: 2.5260358385163237

Epoch: 6| Step: 4
Training loss: 1.3747926035438178
Validation loss: 2.544014778233526

Epoch: 6| Step: 5
Training loss: 1.4605803027514517
Validation loss: 2.552362552224542

Epoch: 6| Step: 6
Training loss: 1.6747006931771138
Validation loss: 2.5389589632820297

Epoch: 6| Step: 7
Training loss: 1.2827037844201108
Validation loss: 2.579885499832752

Epoch: 6| Step: 8
Training loss: 1.3501464393452647
Validation loss: 2.5840429237187736

Epoch: 6| Step: 9
Training loss: 1.6855075517755134
Validation loss: 2.589346450690613

Epoch: 6| Step: 10
Training loss: 1.6116964393214257
Validation loss: 2.619503891934519

Epoch: 6| Step: 11
Training loss: 1.600663989097541
Validation loss: 2.620748193883473

Epoch: 6| Step: 12
Training loss: 1.0745761346199945
Validation loss: 2.5902535338257264

Epoch: 6| Step: 13
Training loss: 1.2681772376779796
Validation loss: 2.560562251510013

Epoch: 195| Step: 0
Training loss: 1.5655221322809132
Validation loss: 2.5563286060456862

Epoch: 6| Step: 1
Training loss: 1.1775507491204573
Validation loss: 2.532264436314445

Epoch: 6| Step: 2
Training loss: 1.2109161375068815
Validation loss: 2.5469986919335605

Epoch: 6| Step: 3
Training loss: 1.275863676567878
Validation loss: 2.541352911481606

Epoch: 6| Step: 4
Training loss: 1.0236365437780808
Validation loss: 2.5411001737778416

Epoch: 6| Step: 5
Training loss: 1.4537374374883352
Validation loss: 2.563388448346421

Epoch: 6| Step: 6
Training loss: 1.9741171686556638
Validation loss: 2.572200270044029

Epoch: 6| Step: 7
Training loss: 1.3038701220993387
Validation loss: 2.5610645154201994

Epoch: 6| Step: 8
Training loss: 1.2535435517440467
Validation loss: 2.5407506750342383

Epoch: 6| Step: 9
Training loss: 1.4974264479009207
Validation loss: 2.584715550496405

Epoch: 6| Step: 10
Training loss: 1.5355342176445073
Validation loss: 2.5738670918957705

Epoch: 6| Step: 11
Training loss: 1.089389063557789
Validation loss: 2.5737852978702978

Epoch: 6| Step: 12
Training loss: 1.2471575366697978
Validation loss: 2.6082198786842987

Epoch: 6| Step: 13
Training loss: 1.5866966497703126
Validation loss: 2.610395412160323

Epoch: 196| Step: 0
Training loss: 1.678463654116376
Validation loss: 2.6309701237715046

Epoch: 6| Step: 1
Training loss: 1.4314849061053598
Validation loss: 2.6132308768960426

Epoch: 6| Step: 2
Training loss: 1.386125163519058
Validation loss: 2.611701522071974

Epoch: 6| Step: 3
Training loss: 1.0423197923965475
Validation loss: 2.620301485815997

Epoch: 6| Step: 4
Training loss: 1.5569130767980703
Validation loss: 2.548344889359168

Epoch: 6| Step: 5
Training loss: 1.4028303316971082
Validation loss: 2.548402565832192

Epoch: 6| Step: 6
Training loss: 1.3812760260015786
Validation loss: 2.5720878155473175

Epoch: 6| Step: 7
Training loss: 1.5530480409893475
Validation loss: 2.5293863004262565

Epoch: 6| Step: 8
Training loss: 1.419809371080329
Validation loss: 2.500479845941959

Epoch: 6| Step: 9
Training loss: 1.3572315988352512
Validation loss: 2.521951408309826

Epoch: 6| Step: 10
Training loss: 0.6447455310082393
Validation loss: 2.4990620268640567

Epoch: 6| Step: 11
Training loss: 1.5095871675537227
Validation loss: 2.4886604363119567

Epoch: 6| Step: 12
Training loss: 1.1016222349162683
Validation loss: 2.5119987557159065

Epoch: 6| Step: 13
Training loss: 1.6173902006778633
Validation loss: 2.5134905788875375

Epoch: 197| Step: 0
Training loss: 1.5159120582800047
Validation loss: 2.500770594673758

Epoch: 6| Step: 1
Training loss: 1.4647753890298736
Validation loss: 2.521003083510723

Epoch: 6| Step: 2
Training loss: 0.9482593475894833
Validation loss: 2.536028974213907

Epoch: 6| Step: 3
Training loss: 1.1803198123995235
Validation loss: 2.5371590890110585

Epoch: 6| Step: 4
Training loss: 1.1922683348442744
Validation loss: 2.5317097961182102

Epoch: 6| Step: 5
Training loss: 1.4992942739351525
Validation loss: 2.581898580290809

Epoch: 6| Step: 6
Training loss: 1.124974621380547
Validation loss: 2.553102798878492

Epoch: 6| Step: 7
Training loss: 1.2779982636907063
Validation loss: 2.5968383192176216

Epoch: 6| Step: 8
Training loss: 1.270016058272116
Validation loss: 2.5929865508559513

Epoch: 6| Step: 9
Training loss: 1.6684746075676495
Validation loss: 2.6572710221124187

Epoch: 6| Step: 10
Training loss: 1.5450669327838928
Validation loss: 2.6429107989942286

Epoch: 6| Step: 11
Training loss: 1.2571717519814476
Validation loss: 2.651384323071694

Epoch: 6| Step: 12
Training loss: 1.6087157000817687
Validation loss: 2.6423262928374074

Epoch: 6| Step: 13
Training loss: 1.5731357228243683
Validation loss: 2.6029157522664255

Epoch: 198| Step: 0
Training loss: 1.5440333303303069
Validation loss: 2.595709080509761

Epoch: 6| Step: 1
Training loss: 1.7228873653603307
Validation loss: 2.531923716631018

Epoch: 6| Step: 2
Training loss: 1.2668410687261662
Validation loss: 2.5519007229259816

Epoch: 6| Step: 3
Training loss: 1.3971880227098403
Validation loss: 2.530897709739516

Epoch: 6| Step: 4
Training loss: 1.0247043601949843
Validation loss: 2.510802816815147

Epoch: 6| Step: 5
Training loss: 1.5547753697392754
Validation loss: 2.5057990250777284

Epoch: 6| Step: 6
Training loss: 0.9035377694338278
Validation loss: 2.5019019060338183

Epoch: 6| Step: 7
Training loss: 1.5206050265968547
Validation loss: 2.5242255501184814

Epoch: 6| Step: 8
Training loss: 1.5689201445088214
Validation loss: 2.5338365269871224

Epoch: 6| Step: 9
Training loss: 1.049811727810695
Validation loss: 2.554531217442714

Epoch: 6| Step: 10
Training loss: 1.1652495201321007
Validation loss: 2.5621922235866954

Epoch: 6| Step: 11
Training loss: 1.5180108866043633
Validation loss: 2.577843718785352

Epoch: 6| Step: 12
Training loss: 0.8282782574757702
Validation loss: 2.6256589174843477

Epoch: 6| Step: 13
Training loss: 1.6939170473499026
Validation loss: 2.6292257394728464

Epoch: 199| Step: 0
Training loss: 1.2580817745873147
Validation loss: 2.623379999981891

Epoch: 6| Step: 1
Training loss: 1.4906408473038149
Validation loss: 2.620676629059805

Epoch: 6| Step: 2
Training loss: 1.29706204455819
Validation loss: 2.594242201952508

Epoch: 6| Step: 3
Training loss: 1.2711792094757743
Validation loss: 2.5956335324236064

Epoch: 6| Step: 4
Training loss: 1.3297099809729735
Validation loss: 2.5833009095262667

Epoch: 6| Step: 5
Training loss: 1.1723027275236595
Validation loss: 2.5244263179934827

Epoch: 6| Step: 6
Training loss: 1.0292703527403047
Validation loss: 2.503497365126538

Epoch: 6| Step: 7
Training loss: 1.456261316345516
Validation loss: 2.5102073753412797

Epoch: 6| Step: 8
Training loss: 1.2670606782529705
Validation loss: 2.4983571243206857

Epoch: 6| Step: 9
Training loss: 1.1324861253642167
Validation loss: 2.4843515828543907

Epoch: 6| Step: 10
Training loss: 1.4675102683232841
Validation loss: 2.477611791624288

Epoch: 6| Step: 11
Training loss: 1.3415980740106277
Validation loss: 2.5037094529556843

Epoch: 6| Step: 12
Training loss: 2.0043602144786163
Validation loss: 2.4647238422224946

Epoch: 6| Step: 13
Training loss: 0.36725603640888305
Validation loss: 2.457784246383446

Epoch: 200| Step: 0
Training loss: 1.5762599083803057
Validation loss: 2.507057505387527

Epoch: 6| Step: 1
Training loss: 1.5054589121268953
Validation loss: 2.4960624162252127

Epoch: 6| Step: 2
Training loss: 0.8708116562136351
Validation loss: 2.4926616639255177

Epoch: 6| Step: 3
Training loss: 1.4482446568905953
Validation loss: 2.541366495542434

Epoch: 6| Step: 4
Training loss: 1.4463080199529843
Validation loss: 2.532910898811006

Epoch: 6| Step: 5
Training loss: 1.7254350528260969
Validation loss: 2.5594984974725454

Epoch: 6| Step: 6
Training loss: 1.1986255483296868
Validation loss: 2.5513410363075963

Epoch: 6| Step: 7
Training loss: 1.2910424026274583
Validation loss: 2.549519844379665

Epoch: 6| Step: 8
Training loss: 1.4847088890004345
Validation loss: 2.5582840315670596

Epoch: 6| Step: 9
Training loss: 1.1825563019783172
Validation loss: 2.5471766066985655

Epoch: 6| Step: 10
Training loss: 1.448605636500182
Validation loss: 2.5360728595042885

Epoch: 6| Step: 11
Training loss: 1.0197197750781162
Validation loss: 2.51444244257855

Epoch: 6| Step: 12
Training loss: 0.8152680196797285
Validation loss: 2.489599666438049

Epoch: 6| Step: 13
Training loss: 1.2506277415461424
Validation loss: 2.4871440781018825

Epoch: 201| Step: 0
Training loss: 1.255680101096118
Validation loss: 2.463530737229938

Epoch: 6| Step: 1
Training loss: 1.3995083166885898
Validation loss: 2.498983424141101

Epoch: 6| Step: 2
Training loss: 1.0897927767957545
Validation loss: 2.479244660780793

Epoch: 6| Step: 3
Training loss: 1.5460707760607963
Validation loss: 2.483853147645484

Epoch: 6| Step: 4
Training loss: 1.284002418031525
Validation loss: 2.4968773177200054

Epoch: 6| Step: 5
Training loss: 1.300756734897672
Validation loss: 2.4877265029361406

Epoch: 6| Step: 6
Training loss: 1.195766238192253
Validation loss: 2.5381596916296782

Epoch: 6| Step: 7
Training loss: 1.5526181351439512
Validation loss: 2.515920235606979

Epoch: 6| Step: 8
Training loss: 1.2998653543875414
Validation loss: 2.5521316329540964

Epoch: 6| Step: 9
Training loss: 1.5614257171189945
Validation loss: 2.5586704358198262

Epoch: 6| Step: 10
Training loss: 1.1593927510591464
Validation loss: 2.531748394581973

Epoch: 6| Step: 11
Training loss: 1.119006829644055
Validation loss: 2.558822584279276

Epoch: 6| Step: 12
Training loss: 0.7573903667945383
Validation loss: 2.55946989710268

Epoch: 6| Step: 13
Training loss: 1.8498943556443102
Validation loss: 2.616387939761392

Epoch: 202| Step: 0
Training loss: 1.262669869127479
Validation loss: 2.5871002157912266

Epoch: 6| Step: 1
Training loss: 1.1294662512186482
Validation loss: 2.584640950673609

Epoch: 6| Step: 2
Training loss: 1.691203045697208
Validation loss: 2.57866325042385

Epoch: 6| Step: 3
Training loss: 1.444584843748741
Validation loss: 2.5712466322363396

Epoch: 6| Step: 4
Training loss: 1.7911411520129636
Validation loss: 2.589244102896544

Epoch: 6| Step: 5
Training loss: 1.233073647111826
Validation loss: 2.58187128454258

Epoch: 6| Step: 6
Training loss: 0.9542375543795651
Validation loss: 2.534277285219607

Epoch: 6| Step: 7
Training loss: 1.068483000302782
Validation loss: 2.54204080962436

Epoch: 6| Step: 8
Training loss: 1.422486310065017
Validation loss: 2.5349735313173305

Epoch: 6| Step: 9
Training loss: 0.9739420408358347
Validation loss: 2.521797742838316

Epoch: 6| Step: 10
Training loss: 0.9380014350123704
Validation loss: 2.5139743477518994

Epoch: 6| Step: 11
Training loss: 1.427963718514386
Validation loss: 2.548576322740608

Epoch: 6| Step: 12
Training loss: 1.191629457670898
Validation loss: 2.5077066384789735

Epoch: 6| Step: 13
Training loss: 1.3051238101383482
Validation loss: 2.5084652385207336

Epoch: 203| Step: 0
Training loss: 1.4710325806754974
Validation loss: 2.5060336633166775

Epoch: 6| Step: 1
Training loss: 1.0972752571701705
Validation loss: 2.527083051183214

Epoch: 6| Step: 2
Training loss: 1.3712310287568117
Validation loss: 2.5495263411563336

Epoch: 6| Step: 3
Training loss: 1.3491503408259877
Validation loss: 2.538891770497116

Epoch: 6| Step: 4
Training loss: 1.105035056511781
Validation loss: 2.5260859028975253

Epoch: 6| Step: 5
Training loss: 1.268837419326345
Validation loss: 2.5378151661167747

Epoch: 6| Step: 6
Training loss: 1.105453545024353
Validation loss: 2.5845150409833177

Epoch: 6| Step: 7
Training loss: 1.2841417198225222
Validation loss: 2.5701420080354698

Epoch: 6| Step: 8
Training loss: 1.329514483481626
Validation loss: 2.538201079666129

Epoch: 6| Step: 9
Training loss: 1.3263511929750442
Validation loss: 2.5515362017254852

Epoch: 6| Step: 10
Training loss: 1.406484541937228
Validation loss: 2.522917747529505

Epoch: 6| Step: 11
Training loss: 1.7287728500786879
Validation loss: 2.554235663209192

Epoch: 6| Step: 12
Training loss: 0.8324787208197431
Validation loss: 2.5027257293443412

Epoch: 6| Step: 13
Training loss: 1.2400665409938811
Validation loss: 2.5203095185690496

Epoch: 204| Step: 0
Training loss: 1.215368519377426
Validation loss: 2.5046265707142905

Epoch: 6| Step: 1
Training loss: 1.2871999520599944
Validation loss: 2.5037456980136943

Epoch: 6| Step: 2
Training loss: 1.1495219190581012
Validation loss: 2.510091012379062

Epoch: 6| Step: 3
Training loss: 1.399420877294991
Validation loss: 2.4910572971455864

Epoch: 6| Step: 4
Training loss: 1.2285556998941112
Validation loss: 2.5292449285744603

Epoch: 6| Step: 5
Training loss: 1.607938328926815
Validation loss: 2.513888254390112

Epoch: 6| Step: 6
Training loss: 1.015689789099341
Validation loss: 2.522994039272479

Epoch: 6| Step: 7
Training loss: 1.3179016675084516
Validation loss: 2.495592126121999

Epoch: 6| Step: 8
Training loss: 1.2523367973796207
Validation loss: 2.545529499643062

Epoch: 6| Step: 9
Training loss: 1.1268033832255508
Validation loss: 2.5038580299909823

Epoch: 6| Step: 10
Training loss: 1.0438575529317604
Validation loss: 2.5499478622147653

Epoch: 6| Step: 11
Training loss: 1.8276341749372826
Validation loss: 2.53987444167041

Epoch: 6| Step: 12
Training loss: 1.1726587345063932
Validation loss: 2.5303975529263396

Epoch: 6| Step: 13
Training loss: 0.9868930520743395
Validation loss: 2.5444372718036927

Epoch: 205| Step: 0
Training loss: 0.8293185360164395
Validation loss: 2.5709777214569516

Epoch: 6| Step: 1
Training loss: 1.4723346875177095
Validation loss: 2.586896160952614

Epoch: 6| Step: 2
Training loss: 1.3690518120490207
Validation loss: 2.5294834709380094

Epoch: 6| Step: 3
Training loss: 1.1387291921647016
Validation loss: 2.573258934722262

Epoch: 6| Step: 4
Training loss: 1.005823345835313
Validation loss: 2.577287142909986

Epoch: 6| Step: 5
Training loss: 1.4027927710526085
Validation loss: 2.5654139294484204

Epoch: 6| Step: 6
Training loss: 1.6580300751916017
Validation loss: 2.6037016320888617

Epoch: 6| Step: 7
Training loss: 1.3953576724609946
Validation loss: 2.5653960777344618

Epoch: 6| Step: 8
Training loss: 0.7779199199748106
Validation loss: 2.603957721490484

Epoch: 6| Step: 9
Training loss: 1.6084998260393604
Validation loss: 2.5958250561532843

Epoch: 6| Step: 10
Training loss: 1.076053841378294
Validation loss: 2.614630251907454

Epoch: 6| Step: 11
Training loss: 1.4542120692352853
Validation loss: 2.613325343817744

Epoch: 6| Step: 12
Training loss: 1.0997697025588502
Validation loss: 2.6062167545060344

Epoch: 6| Step: 13
Training loss: 0.7920896797053022
Validation loss: 2.5856399258344474

Epoch: 206| Step: 0
Training loss: 1.1905600622695764
Validation loss: 2.574388668748771

Epoch: 6| Step: 1
Training loss: 0.7895582549072303
Validation loss: 2.5334857540094164

Epoch: 6| Step: 2
Training loss: 1.1365948901256082
Validation loss: 2.5315762680120057

Epoch: 6| Step: 3
Training loss: 1.1415053850031058
Validation loss: 2.55568379080722

Epoch: 6| Step: 4
Training loss: 1.7295910264759027
Validation loss: 2.50727731241248

Epoch: 6| Step: 5
Training loss: 1.0945562388408152
Validation loss: 2.518997808229704

Epoch: 6| Step: 6
Training loss: 1.0376274122571554
Validation loss: 2.494853982800728

Epoch: 6| Step: 7
Training loss: 1.6762404446254846
Validation loss: 2.5408101937678365

Epoch: 6| Step: 8
Training loss: 1.3227696324536964
Validation loss: 2.5232603162733467

Epoch: 6| Step: 9
Training loss: 1.0671128387920004
Validation loss: 2.5188885553902884

Epoch: 6| Step: 10
Training loss: 0.8794940254654763
Validation loss: 2.500845425718247

Epoch: 6| Step: 11
Training loss: 0.9815525888296633
Validation loss: 2.491061696704782

Epoch: 6| Step: 12
Training loss: 1.4261367145718893
Validation loss: 2.493820541592666

Epoch: 6| Step: 13
Training loss: 1.7491383474867508
Validation loss: 2.536064184200863

Epoch: 207| Step: 0
Training loss: 0.6239750325468452
Validation loss: 2.5562421058701177

Epoch: 6| Step: 1
Training loss: 1.0690777192514138
Validation loss: 2.558953859634279

Epoch: 6| Step: 2
Training loss: 1.3640731216838613
Validation loss: 2.5591337882606164

Epoch: 6| Step: 3
Training loss: 0.48819216106213015
Validation loss: 2.554210338176688

Epoch: 6| Step: 4
Training loss: 1.2615509866487236
Validation loss: 2.5727800725999046

Epoch: 6| Step: 5
Training loss: 1.1101392880243937
Validation loss: 2.548404450031023

Epoch: 6| Step: 6
Training loss: 1.2519895932127636
Validation loss: 2.5152289251306286

Epoch: 6| Step: 7
Training loss: 1.7517553109346686
Validation loss: 2.5261117600481313

Epoch: 6| Step: 8
Training loss: 1.3013408476734392
Validation loss: 2.525943309584637

Epoch: 6| Step: 9
Training loss: 1.3488510805988745
Validation loss: 2.547525922249361

Epoch: 6| Step: 10
Training loss: 1.5150013063129295
Validation loss: 2.534960010084747

Epoch: 6| Step: 11
Training loss: 1.186167169780302
Validation loss: 2.536654626449249

Epoch: 6| Step: 12
Training loss: 1.373324847673539
Validation loss: 2.534193839088734

Epoch: 6| Step: 13
Training loss: 1.1241224893232042
Validation loss: 2.5338233811235953

Epoch: 208| Step: 0
Training loss: 1.3735821089057638
Validation loss: 2.5180395369495545

Epoch: 6| Step: 1
Training loss: 1.44619501337419
Validation loss: 2.5025649028871597

Epoch: 6| Step: 2
Training loss: 1.1761889590438728
Validation loss: 2.490407046388415

Epoch: 6| Step: 3
Training loss: 1.0068422126759466
Validation loss: 2.5175686548260594

Epoch: 6| Step: 4
Training loss: 1.4952493779841745
Validation loss: 2.5015411556512586

Epoch: 6| Step: 5
Training loss: 1.3808279074357195
Validation loss: 2.5155645541688996

Epoch: 6| Step: 6
Training loss: 1.533232048393586
Validation loss: 2.500240877298843

Epoch: 6| Step: 7
Training loss: 1.188932257799095
Validation loss: 2.497786785100563

Epoch: 6| Step: 8
Training loss: 0.8813495498594616
Validation loss: 2.4992772698408197

Epoch: 6| Step: 9
Training loss: 1.496771835562914
Validation loss: 2.5020913011345263

Epoch: 6| Step: 10
Training loss: 0.7974778681108636
Validation loss: 2.490439969671616

Epoch: 6| Step: 11
Training loss: 0.951004170197049
Validation loss: 2.497609733449556

Epoch: 6| Step: 12
Training loss: 0.9733889474287138
Validation loss: 2.5385456800493262

Epoch: 6| Step: 13
Training loss: 1.0147535840535313
Validation loss: 2.5064368188305055

Epoch: 209| Step: 0
Training loss: 0.6189626925415624
Validation loss: 2.521297220619891

Epoch: 6| Step: 1
Training loss: 1.422756299224942
Validation loss: 2.519158197709164

Epoch: 6| Step: 2
Training loss: 1.1987131649718505
Validation loss: 2.5129584868599757

Epoch: 6| Step: 3
Training loss: 1.162464247943386
Validation loss: 2.4978103770122946

Epoch: 6| Step: 4
Training loss: 0.9065983858997544
Validation loss: 2.522126056441313

Epoch: 6| Step: 5
Training loss: 1.5760706759159557
Validation loss: 2.480526820310423

Epoch: 6| Step: 6
Training loss: 0.7583077375752443
Validation loss: 2.4911035708571703

Epoch: 6| Step: 7
Training loss: 1.6421980809416201
Validation loss: 2.5124990804155583

Epoch: 6| Step: 8
Training loss: 1.5029526102103845
Validation loss: 2.4817088504969753

Epoch: 6| Step: 9
Training loss: 1.3012338486694215
Validation loss: 2.4776797228111143

Epoch: 6| Step: 10
Training loss: 0.9837044142324377
Validation loss: 2.4565512752455096

Epoch: 6| Step: 11
Training loss: 1.0421446212343506
Validation loss: 2.522065053863998

Epoch: 6| Step: 12
Training loss: 1.3086221720327613
Validation loss: 2.4984884809732133

Epoch: 6| Step: 13
Training loss: 1.4118525481243656
Validation loss: 2.496321857022912

Epoch: 210| Step: 0
Training loss: 0.9510683163895394
Validation loss: 2.4953018198830046

Epoch: 6| Step: 1
Training loss: 0.7995078778573613
Validation loss: 2.4998629901628187

Epoch: 6| Step: 2
Training loss: 1.0250563885134627
Validation loss: 2.5372040652055086

Epoch: 6| Step: 3
Training loss: 0.4733415789736672
Validation loss: 2.534980239318667

Epoch: 6| Step: 4
Training loss: 1.374717033053385
Validation loss: 2.530777678890526

Epoch: 6| Step: 5
Training loss: 1.0779203690646042
Validation loss: 2.5340505522459327

Epoch: 6| Step: 6
Training loss: 1.3140115662273293
Validation loss: 2.5414705777457223

Epoch: 6| Step: 7
Training loss: 1.5316052705886787
Validation loss: 2.5293767325665084

Epoch: 6| Step: 8
Training loss: 1.4667836276293011
Validation loss: 2.5230133351363393

Epoch: 6| Step: 9
Training loss: 1.2722988069287198
Validation loss: 2.5532693139302887

Epoch: 6| Step: 10
Training loss: 1.4032539665238146
Validation loss: 2.530618177299736

Epoch: 6| Step: 11
Training loss: 0.8492808441229638
Validation loss: 2.4957437749579974

Epoch: 6| Step: 12
Training loss: 1.5973826129748931
Validation loss: 2.523872502829245

Epoch: 6| Step: 13
Training loss: 1.3137615589537108
Validation loss: 2.5285082428042656

Epoch: 211| Step: 0
Training loss: 1.0672206354093583
Validation loss: 2.5385072142266534

Epoch: 6| Step: 1
Training loss: 1.1829539669203015
Validation loss: 2.5331177448798816

Epoch: 6| Step: 2
Training loss: 0.9191272000209045
Validation loss: 2.5483940132319716

Epoch: 6| Step: 3
Training loss: 1.3649151910558488
Validation loss: 2.532898504209976

Epoch: 6| Step: 4
Training loss: 1.2387213180716699
Validation loss: 2.536333834582382

Epoch: 6| Step: 5
Training loss: 1.0120237030789185
Validation loss: 2.5535680847110833

Epoch: 6| Step: 6
Training loss: 1.060673883465908
Validation loss: 2.5496377480939727

Epoch: 6| Step: 7
Training loss: 1.126583203933663
Validation loss: 2.5656886876720066

Epoch: 6| Step: 8
Training loss: 1.1883006659231332
Validation loss: 2.6021915576799697

Epoch: 6| Step: 9
Training loss: 1.4806986205065154
Validation loss: 2.5587754903393787

Epoch: 6| Step: 10
Training loss: 1.3962026458605876
Validation loss: 2.5933448829960986

Epoch: 6| Step: 11
Training loss: 1.0918239528730733
Validation loss: 2.549883802260979

Epoch: 6| Step: 12
Training loss: 1.4856170276625331
Validation loss: 2.538682463344065

Epoch: 6| Step: 13
Training loss: 0.8728744712105801
Validation loss: 2.5460070005339523

Epoch: 212| Step: 0
Training loss: 1.067503926629521
Validation loss: 2.5332395390772775

Epoch: 6| Step: 1
Training loss: 1.130536865206933
Validation loss: 2.549787722383267

Epoch: 6| Step: 2
Training loss: 0.7481608889073345
Validation loss: 2.527454586869672

Epoch: 6| Step: 3
Training loss: 1.3608475525100103
Validation loss: 2.514666200904219

Epoch: 6| Step: 4
Training loss: 1.2202302795142133
Validation loss: 2.5849019117035668

Epoch: 6| Step: 5
Training loss: 1.0927000728521623
Validation loss: 2.5539249836248947

Epoch: 6| Step: 6
Training loss: 1.8555659539711173
Validation loss: 2.5425596425239547

Epoch: 6| Step: 7
Training loss: 1.1206441369792244
Validation loss: 2.561807536383057

Epoch: 6| Step: 8
Training loss: 1.1377497451268956
Validation loss: 2.5651939801540324

Epoch: 6| Step: 9
Training loss: 0.8880274186025341
Validation loss: 2.5994921007152505

Epoch: 6| Step: 10
Training loss: 1.33028837046337
Validation loss: 2.556214297465729

Epoch: 6| Step: 11
Training loss: 1.0763850892249418
Validation loss: 2.5736841949541924

Epoch: 6| Step: 12
Training loss: 1.4039579574071983
Validation loss: 2.518857643593502

Epoch: 6| Step: 13
Training loss: 0.7483738515783585
Validation loss: 2.4840766406143295

Epoch: 213| Step: 0
Training loss: 1.3579210859103696
Validation loss: 2.502137038822815

Epoch: 6| Step: 1
Training loss: 0.9560196804849992
Validation loss: 2.461299021584596

Epoch: 6| Step: 2
Training loss: 1.211324223939875
Validation loss: 2.490330372970109

Epoch: 6| Step: 3
Training loss: 1.486625892196897
Validation loss: 2.467811505259083

Epoch: 6| Step: 4
Training loss: 0.828824126034112
Validation loss: 2.4782368212341788

Epoch: 6| Step: 5
Training loss: 1.3065966041345638
Validation loss: 2.5384364939234705

Epoch: 6| Step: 6
Training loss: 1.4849324835896418
Validation loss: 2.5050040626472465

Epoch: 6| Step: 7
Training loss: 1.2066245767372723
Validation loss: 2.53751170112599

Epoch: 6| Step: 8
Training loss: 1.11494733386683
Validation loss: 2.519181658170777

Epoch: 6| Step: 9
Training loss: 1.1174189187830683
Validation loss: 2.577451927449946

Epoch: 6| Step: 10
Training loss: 1.0749933952306072
Validation loss: 2.56367303754557

Epoch: 6| Step: 11
Training loss: 0.917202568905207
Validation loss: 2.5696895395628676

Epoch: 6| Step: 12
Training loss: 1.1655525041796229
Validation loss: 2.5325256044276463

Epoch: 6| Step: 13
Training loss: 1.2703182656695722
Validation loss: 2.5247209518826486

Epoch: 214| Step: 0
Training loss: 1.0497197458368612
Validation loss: 2.494270944638481

Epoch: 6| Step: 1
Training loss: 1.2278312390014743
Validation loss: 2.4705597679905438

Epoch: 6| Step: 2
Training loss: 1.0062997983374096
Validation loss: 2.4482590599317517

Epoch: 6| Step: 3
Training loss: 0.7712483105262293
Validation loss: 2.454845551665629

Epoch: 6| Step: 4
Training loss: 1.4823158839435202
Validation loss: 2.465818104758706

Epoch: 6| Step: 5
Training loss: 1.0438655469519147
Validation loss: 2.4705057190059705

Epoch: 6| Step: 6
Training loss: 1.5318647435193957
Validation loss: 2.4551206118384226

Epoch: 6| Step: 7
Training loss: 0.6399038023475483
Validation loss: 2.4688358668385186

Epoch: 6| Step: 8
Training loss: 1.5724481891290145
Validation loss: 2.4831778784942125

Epoch: 6| Step: 9
Training loss: 0.7453865574285045
Validation loss: 2.5035351042115392

Epoch: 6| Step: 10
Training loss: 1.5201662595068242
Validation loss: 2.5315336420191406

Epoch: 6| Step: 11
Training loss: 0.8612242136445973
Validation loss: 2.518160445780243

Epoch: 6| Step: 12
Training loss: 1.3293396724567639
Validation loss: 2.52514794670712

Epoch: 6| Step: 13
Training loss: 0.967000982144004
Validation loss: 2.5546279372941356

Epoch: 215| Step: 0
Training loss: 0.890345144640767
Validation loss: 2.563207075088678

Epoch: 6| Step: 1
Training loss: 1.5290119397761908
Validation loss: 2.5574453058904916

Epoch: 6| Step: 2
Training loss: 0.9601777958140252
Validation loss: 2.5863741372319375

Epoch: 6| Step: 3
Training loss: 1.1435505177122953
Validation loss: 2.622568536719951

Epoch: 6| Step: 4
Training loss: 1.6444915259268487
Validation loss: 2.6043460564302525

Epoch: 6| Step: 5
Training loss: 1.1258770385059644
Validation loss: 2.5881825906133114

Epoch: 6| Step: 6
Training loss: 1.1806920807876644
Validation loss: 2.5577876583651067

Epoch: 6| Step: 7
Training loss: 1.3913444201157628
Validation loss: 2.517445647268049

Epoch: 6| Step: 8
Training loss: 0.8406409449997271
Validation loss: 2.5147132370259118

Epoch: 6| Step: 9
Training loss: 1.0099596910647888
Validation loss: 2.4806816006520163

Epoch: 6| Step: 10
Training loss: 1.4173968714584115
Validation loss: 2.44313911536472

Epoch: 6| Step: 11
Training loss: 1.0617694587190893
Validation loss: 2.466987681792272

Epoch: 6| Step: 12
Training loss: 1.075616821488492
Validation loss: 2.4754186791337416

Epoch: 6| Step: 13
Training loss: 0.6165113729323578
Validation loss: 2.478213265398897

Epoch: 216| Step: 0
Training loss: 1.465566716123138
Validation loss: 2.501883906497831

Epoch: 6| Step: 1
Training loss: 0.8960374703065488
Validation loss: 2.5053914375683215

Epoch: 6| Step: 2
Training loss: 1.4491086851208659
Validation loss: 2.5235634866327006

Epoch: 6| Step: 3
Training loss: 1.2691154855555422
Validation loss: 2.466516218597118

Epoch: 6| Step: 4
Training loss: 1.1802799682335505
Validation loss: 2.498177817986206

Epoch: 6| Step: 5
Training loss: 1.2710409255443231
Validation loss: 2.5242524576715666

Epoch: 6| Step: 6
Training loss: 0.8563441844290796
Validation loss: 2.5110177649851497

Epoch: 6| Step: 7
Training loss: 0.9097526867127902
Validation loss: 2.545788081382748

Epoch: 6| Step: 8
Training loss: 0.7535026141794037
Validation loss: 2.520720605881504

Epoch: 6| Step: 9
Training loss: 1.2061375639699228
Validation loss: 2.513864388107875

Epoch: 6| Step: 10
Training loss: 0.9556819824434682
Validation loss: 2.5211946727959833

Epoch: 6| Step: 11
Training loss: 1.2219498516287932
Validation loss: 2.514675093773465

Epoch: 6| Step: 12
Training loss: 1.5679909925494038
Validation loss: 2.5248261716073235

Epoch: 6| Step: 13
Training loss: 0.7276779963819554
Validation loss: 2.55699016759526

Epoch: 217| Step: 0
Training loss: 0.8102160410581033
Validation loss: 2.499032367569052

Epoch: 6| Step: 1
Training loss: 1.110589933684385
Validation loss: 2.5123408918632335

Epoch: 6| Step: 2
Training loss: 0.9945973244748239
Validation loss: 2.5052768616974745

Epoch: 6| Step: 3
Training loss: 1.3531019671376137
Validation loss: 2.5143281466049547

Epoch: 6| Step: 4
Training loss: 0.6803135236067425
Validation loss: 2.4677331319597373

Epoch: 6| Step: 5
Training loss: 1.3580889702418355
Validation loss: 2.4448846063058487

Epoch: 6| Step: 6
Training loss: 1.1366037002492504
Validation loss: 2.446461252789811

Epoch: 6| Step: 7
Training loss: 1.3655183030266855
Validation loss: 2.4797475673181504

Epoch: 6| Step: 8
Training loss: 1.4335569122321306
Validation loss: 2.4868286733262606

Epoch: 6| Step: 9
Training loss: 1.0407474021979997
Validation loss: 2.518099061560438

Epoch: 6| Step: 10
Training loss: 1.157779403810667
Validation loss: 2.5118586848062496

Epoch: 6| Step: 11
Training loss: 1.350640484086953
Validation loss: 2.488181934656452

Epoch: 6| Step: 12
Training loss: 0.8760633818981268
Validation loss: 2.516790801780768

Epoch: 6| Step: 13
Training loss: 1.2853329429790754
Validation loss: 2.5257501702717486

Epoch: 218| Step: 0
Training loss: 0.8840621610595657
Validation loss: 2.5560366838028923

Epoch: 6| Step: 1
Training loss: 0.9149105344090182
Validation loss: 2.551413949587348

Epoch: 6| Step: 2
Training loss: 1.6084269722015343
Validation loss: 2.605255228897906

Epoch: 6| Step: 3
Training loss: 1.553359418098807
Validation loss: 2.5422772669791494

Epoch: 6| Step: 4
Training loss: 1.3025103466479642
Validation loss: 2.5591417252013695

Epoch: 6| Step: 5
Training loss: 1.426346507439005
Validation loss: 2.580986194835439

Epoch: 6| Step: 6
Training loss: 0.9473722732128217
Validation loss: 2.505350555345906

Epoch: 6| Step: 7
Training loss: 0.9974914319045666
Validation loss: 2.510075303195686

Epoch: 6| Step: 8
Training loss: 0.9994016585811298
Validation loss: 2.457162252929592

Epoch: 6| Step: 9
Training loss: 0.7543826796702551
Validation loss: 2.4830556611516137

Epoch: 6| Step: 10
Training loss: 1.481742210536336
Validation loss: 2.4538214108927368

Epoch: 6| Step: 11
Training loss: 0.8313605242225882
Validation loss: 2.4495465307443673

Epoch: 6| Step: 12
Training loss: 0.9705791432588908
Validation loss: 2.477834033321319

Epoch: 6| Step: 13
Training loss: 0.7571393592257556
Validation loss: 2.4524956867812757

Epoch: 219| Step: 0
Training loss: 1.1599632642124964
Validation loss: 2.4635786570458698

Epoch: 6| Step: 1
Training loss: 1.1546089796074255
Validation loss: 2.4494277622340963

Epoch: 6| Step: 2
Training loss: 0.8277735054160458
Validation loss: 2.4946494209107706

Epoch: 6| Step: 3
Training loss: 1.044657108596266
Validation loss: 2.4930680975490596

Epoch: 6| Step: 4
Training loss: 1.1998692838681893
Validation loss: 2.5189527736084716

Epoch: 6| Step: 5
Training loss: 0.924379277093676
Validation loss: 2.5817705032410747

Epoch: 6| Step: 6
Training loss: 1.1095477762134425
Validation loss: 2.6141886064871196

Epoch: 6| Step: 7
Training loss: 0.828423716093356
Validation loss: 2.5598988981417103

Epoch: 6| Step: 8
Training loss: 1.271629126025066
Validation loss: 2.544790917451343

Epoch: 6| Step: 9
Training loss: 1.267403471542162
Validation loss: 2.547033773426

Epoch: 6| Step: 10
Training loss: 1.3865884209222448
Validation loss: 2.5434425144175283

Epoch: 6| Step: 11
Training loss: 1.1359299482385776
Validation loss: 2.5164829850338304

Epoch: 6| Step: 12
Training loss: 1.419789220183241
Validation loss: 2.5352870570484587

Epoch: 6| Step: 13
Training loss: 0.5776209051139363
Validation loss: 2.489363980722488

Epoch: 220| Step: 0
Training loss: 0.725533320494515
Validation loss: 2.53238881556523

Epoch: 6| Step: 1
Training loss: 1.055667337276662
Validation loss: 2.495395922134019

Epoch: 6| Step: 2
Training loss: 1.0767607972733209
Validation loss: 2.456460821168019

Epoch: 6| Step: 3
Training loss: 1.2592031243274613
Validation loss: 2.5061375787705904

Epoch: 6| Step: 4
Training loss: 1.5435632260653687
Validation loss: 2.5089032143478502

Epoch: 6| Step: 5
Training loss: 1.2255396374471539
Validation loss: 2.5589739953667836

Epoch: 6| Step: 6
Training loss: 1.1477997754370786
Validation loss: 2.529906206990106

Epoch: 6| Step: 7
Training loss: 1.490663319221132
Validation loss: 2.5360898779534797

Epoch: 6| Step: 8
Training loss: 1.0691794084923003
Validation loss: 2.567950335262889

Epoch: 6| Step: 9
Training loss: 1.037041900796182
Validation loss: 2.5386027268339593

Epoch: 6| Step: 10
Training loss: 0.502663995874622
Validation loss: 2.5588398176093037

Epoch: 6| Step: 11
Training loss: 0.9052209931524673
Validation loss: 2.522843104758262

Epoch: 6| Step: 12
Training loss: 0.8699748975048149
Validation loss: 2.507283850140386

Epoch: 6| Step: 13
Training loss: 1.3987379976632053
Validation loss: 2.516068918932815

Epoch: 221| Step: 0
Training loss: 1.2129463514711776
Validation loss: 2.504034814405108

Epoch: 6| Step: 1
Training loss: 1.0885313054858672
Validation loss: 2.462388149686455

Epoch: 6| Step: 2
Training loss: 0.9742996549318131
Validation loss: 2.4560720626062174

Epoch: 6| Step: 3
Training loss: 0.8522221521341339
Validation loss: 2.4992493835698646

Epoch: 6| Step: 4
Training loss: 1.2398603220687225
Validation loss: 2.472998583669371

Epoch: 6| Step: 5
Training loss: 1.341593186911433
Validation loss: 2.4672247631389226

Epoch: 6| Step: 6
Training loss: 1.2034966031174372
Validation loss: 2.4710475686884528

Epoch: 6| Step: 7
Training loss: 0.988237462939626
Validation loss: 2.4781214931595485

Epoch: 6| Step: 8
Training loss: 1.299308515923994
Validation loss: 2.455796069783668

Epoch: 6| Step: 9
Training loss: 1.0900830515447604
Validation loss: 2.518059301436811

Epoch: 6| Step: 10
Training loss: 1.2244812626119654
Validation loss: 2.515710200341634

Epoch: 6| Step: 11
Training loss: 0.8385163218457038
Validation loss: 2.5417724182571813

Epoch: 6| Step: 12
Training loss: 1.061504065539516
Validation loss: 2.4890861500476755

Epoch: 6| Step: 13
Training loss: 0.21589151994263361
Validation loss: 2.5384447005932764

Epoch: 222| Step: 0
Training loss: 1.046608335778974
Validation loss: 2.5264802752179145

Epoch: 6| Step: 1
Training loss: 0.6970934615242118
Validation loss: 2.506829216570006

Epoch: 6| Step: 2
Training loss: 1.1825363421349766
Validation loss: 2.5223569703703244

Epoch: 6| Step: 3
Training loss: 1.4449729726831115
Validation loss: 2.563877410816169

Epoch: 6| Step: 4
Training loss: 1.1351150788771645
Validation loss: 2.56570791024333

Epoch: 6| Step: 5
Training loss: 0.9259266799464511
Validation loss: 2.535184353097002

Epoch: 6| Step: 6
Training loss: 1.0318732834541189
Validation loss: 2.578546863793098

Epoch: 6| Step: 7
Training loss: 1.182897835277383
Validation loss: 2.5474761267577377

Epoch: 6| Step: 8
Training loss: 1.1437452305762068
Validation loss: 2.578251647324474

Epoch: 6| Step: 9
Training loss: 1.2376611161590836
Validation loss: 2.5664241626135795

Epoch: 6| Step: 10
Training loss: 0.7271948902785729
Validation loss: 2.545604881075654

Epoch: 6| Step: 11
Training loss: 0.9519449026248115
Validation loss: 2.5905846620319677

Epoch: 6| Step: 12
Training loss: 1.0292197384966362
Validation loss: 2.560775884135907

Epoch: 6| Step: 13
Training loss: 1.4969006147960466
Validation loss: 2.5366959693090165

Epoch: 223| Step: 0
Training loss: 0.9256911736942731
Validation loss: 2.544876686653061

Epoch: 6| Step: 1
Training loss: 0.9460716037064
Validation loss: 2.535369718947132

Epoch: 6| Step: 2
Training loss: 0.5013696864399826
Validation loss: 2.542028605772369

Epoch: 6| Step: 3
Training loss: 0.9000045378888487
Validation loss: 2.532037610172282

Epoch: 6| Step: 4
Training loss: 1.3571687530972503
Validation loss: 2.56919613027908

Epoch: 6| Step: 5
Training loss: 1.535674728314985
Validation loss: 2.541376159489226

Epoch: 6| Step: 6
Training loss: 1.2787660851683478
Validation loss: 2.542632128556822

Epoch: 6| Step: 7
Training loss: 0.9347875137412553
Validation loss: 2.540679867840698

Epoch: 6| Step: 8
Training loss: 1.19970464647962
Validation loss: 2.5355395976808723

Epoch: 6| Step: 9
Training loss: 0.897484580839949
Validation loss: 2.508319298402376

Epoch: 6| Step: 10
Training loss: 1.0868403023286393
Validation loss: 2.498191189391493

Epoch: 6| Step: 11
Training loss: 1.2913945690810624
Validation loss: 2.493470702957561

Epoch: 6| Step: 12
Training loss: 1.1759843112327235
Validation loss: 2.476305621855199

Epoch: 6| Step: 13
Training loss: 1.1386647036082866
Validation loss: 2.493458035194323

Epoch: 224| Step: 0
Training loss: 1.1818942215605641
Validation loss: 2.4753380512371894

Epoch: 6| Step: 1
Training loss: 1.2519508873596668
Validation loss: 2.5024895280622577

Epoch: 6| Step: 2
Training loss: 1.5974455976699986
Validation loss: 2.5096138622067916

Epoch: 6| Step: 3
Training loss: 0.8258517030455763
Validation loss: 2.521968092570446

Epoch: 6| Step: 4
Training loss: 0.8946722993881846
Validation loss: 2.5542012216254393

Epoch: 6| Step: 5
Training loss: 1.2410096636356711
Validation loss: 2.5523481588642185

Epoch: 6| Step: 6
Training loss: 0.9501738589963136
Validation loss: 2.555953212862894

Epoch: 6| Step: 7
Training loss: 0.6557094300329529
Validation loss: 2.5404436271099478

Epoch: 6| Step: 8
Training loss: 1.1573192704162312
Validation loss: 2.490098146673086

Epoch: 6| Step: 9
Training loss: 1.0622875898878612
Validation loss: 2.4593608419811868

Epoch: 6| Step: 10
Training loss: 0.8598174603377298
Validation loss: 2.417605820851663

Epoch: 6| Step: 11
Training loss: 1.1747093003409896
Validation loss: 2.4180889809780073

Epoch: 6| Step: 12
Training loss: 0.6913361379129079
Validation loss: 2.376846006240319

Epoch: 6| Step: 13
Training loss: 1.365406423923573
Validation loss: 2.430232889191753

Epoch: 225| Step: 0
Training loss: 0.9637408420112784
Validation loss: 2.4191917096451436

Epoch: 6| Step: 1
Training loss: 1.1615637259570517
Validation loss: 2.432411948876755

Epoch: 6| Step: 2
Training loss: 1.220638572511937
Validation loss: 2.4591824759810277

Epoch: 6| Step: 3
Training loss: 0.9474285811429678
Validation loss: 2.4204841316867998

Epoch: 6| Step: 4
Training loss: 1.1731874872636137
Validation loss: 2.500169125855663

Epoch: 6| Step: 5
Training loss: 0.787564659491682
Validation loss: 2.489427872057322

Epoch: 6| Step: 6
Training loss: 1.1438412197403856
Validation loss: 2.4821288716085648

Epoch: 6| Step: 7
Training loss: 1.2353926700793916
Validation loss: 2.4937640473644036

Epoch: 6| Step: 8
Training loss: 1.0563677366650468
Validation loss: 2.500997617570889

Epoch: 6| Step: 9
Training loss: 0.9133070734059011
Validation loss: 2.531350619312598

Epoch: 6| Step: 10
Training loss: 1.2509741801731316
Validation loss: 2.5454063607568007

Epoch: 6| Step: 11
Training loss: 1.412781614739318
Validation loss: 2.517618331092348

Epoch: 6| Step: 12
Training loss: 0.37569740137161534
Validation loss: 2.507943706666361

Epoch: 6| Step: 13
Training loss: 0.8921778676703892
Validation loss: 2.5590971335600816

Epoch: 226| Step: 0
Training loss: 0.9569296958136214
Validation loss: 2.5183543585501726

Epoch: 6| Step: 1
Training loss: 1.2237688066636958
Validation loss: 2.516704020405991

Epoch: 6| Step: 2
Training loss: 1.0820596739413084
Validation loss: 2.5011189253788397

Epoch: 6| Step: 3
Training loss: 0.8343247159171727
Validation loss: 2.4803928763164067

Epoch: 6| Step: 4
Training loss: 1.2259563722113245
Validation loss: 2.4654160513127

Epoch: 6| Step: 5
Training loss: 1.0966740350755937
Validation loss: 2.521307665109279

Epoch: 6| Step: 6
Training loss: 1.0315700958998482
Validation loss: 2.4985055858685694

Epoch: 6| Step: 7
Training loss: 1.2221723580062513
Validation loss: 2.5370779778771557

Epoch: 6| Step: 8
Training loss: 1.079492558547747
Validation loss: 2.537794188204748

Epoch: 6| Step: 9
Training loss: 1.0741290800642391
Validation loss: 2.5412981248432915

Epoch: 6| Step: 10
Training loss: 0.6928231758392913
Validation loss: 2.568745358486387

Epoch: 6| Step: 11
Training loss: 1.419080398335809
Validation loss: 2.537021998244025

Epoch: 6| Step: 12
Training loss: 1.050905865508755
Validation loss: 2.5339922278904097

Epoch: 6| Step: 13
Training loss: 0.5301948053499068
Validation loss: 2.5265897497301606

Epoch: 227| Step: 0
Training loss: 1.2782882325042684
Validation loss: 2.5051632425287633

Epoch: 6| Step: 1
Training loss: 1.2241004482577917
Validation loss: 2.5160631529305917

Epoch: 6| Step: 2
Training loss: 1.1065528864471212
Validation loss: 2.5078338186657256

Epoch: 6| Step: 3
Training loss: 1.2672846708659105
Validation loss: 2.5049154360129013

Epoch: 6| Step: 4
Training loss: 0.9850276418380027
Validation loss: 2.514626938556443

Epoch: 6| Step: 5
Training loss: 0.9127192939205249
Validation loss: 2.5067242196411357

Epoch: 6| Step: 6
Training loss: 1.1181573459473495
Validation loss: 2.463408007717615

Epoch: 6| Step: 7
Training loss: 1.1259526351940563
Validation loss: 2.500710585317937

Epoch: 6| Step: 8
Training loss: 0.9944060745035307
Validation loss: 2.464007928070615

Epoch: 6| Step: 9
Training loss: 1.3785614792982195
Validation loss: 2.468970431581304

Epoch: 6| Step: 10
Training loss: 0.8801320323189086
Validation loss: 2.5100067672733046

Epoch: 6| Step: 11
Training loss: 0.7828728414643114
Validation loss: 2.496117181260523

Epoch: 6| Step: 12
Training loss: 0.5161035513344168
Validation loss: 2.5420763508286344

Epoch: 6| Step: 13
Training loss: 0.8604562026785895
Validation loss: 2.53415214787107

Epoch: 228| Step: 0
Training loss: 1.084273071335617
Validation loss: 2.5084783874826813

Epoch: 6| Step: 1
Training loss: 0.817850359753509
Validation loss: 2.5311763564841194

Epoch: 6| Step: 2
Training loss: 1.1411902712247153
Validation loss: 2.4977917491093753

Epoch: 6| Step: 3
Training loss: 1.3508297030670566
Validation loss: 2.500507226371391

Epoch: 6| Step: 4
Training loss: 0.7123506774364685
Validation loss: 2.479591879843989

Epoch: 6| Step: 5
Training loss: 0.6680261241521499
Validation loss: 2.5100165345966508

Epoch: 6| Step: 6
Training loss: 1.285373286788379
Validation loss: 2.5122873774543493

Epoch: 6| Step: 7
Training loss: 1.0049249252822279
Validation loss: 2.5164317816465473

Epoch: 6| Step: 8
Training loss: 1.0573997379687226
Validation loss: 2.526933049263406

Epoch: 6| Step: 9
Training loss: 1.2491266060365238
Validation loss: 2.53493965022884

Epoch: 6| Step: 10
Training loss: 1.0459363914463355
Validation loss: 2.484544271134354

Epoch: 6| Step: 11
Training loss: 1.0016402263505186
Validation loss: 2.460261255479866

Epoch: 6| Step: 12
Training loss: 0.9499767401006078
Validation loss: 2.439939470338862

Epoch: 6| Step: 13
Training loss: 1.0543673559249804
Validation loss: 2.4454628863654695

Epoch: 229| Step: 0
Training loss: 0.8207624019112247
Validation loss: 2.3858583647429166

Epoch: 6| Step: 1
Training loss: 1.404359012337895
Validation loss: 2.421581030029325

Epoch: 6| Step: 2
Training loss: 0.9729266729119389
Validation loss: 2.398101639895046

Epoch: 6| Step: 3
Training loss: 1.048147765829643
Validation loss: 2.426623766768494

Epoch: 6| Step: 4
Training loss: 1.1011414501023675
Validation loss: 2.417390640311164

Epoch: 6| Step: 5
Training loss: 1.1338342728254613
Validation loss: 2.427194687758181

Epoch: 6| Step: 6
Training loss: 0.8153903609060934
Validation loss: 2.4340182296154262

Epoch: 6| Step: 7
Training loss: 1.5880270285864526
Validation loss: 2.4373576519979134

Epoch: 6| Step: 8
Training loss: 0.7635299277519956
Validation loss: 2.4091131933219363

Epoch: 6| Step: 9
Training loss: 0.775987448281112
Validation loss: 2.399485294634058

Epoch: 6| Step: 10
Training loss: 0.8050585881823689
Validation loss: 2.4356538982432085

Epoch: 6| Step: 11
Training loss: 0.9795533120279308
Validation loss: 2.456728798152705

Epoch: 6| Step: 12
Training loss: 0.8386705587773862
Validation loss: 2.4948195517277614

Epoch: 6| Step: 13
Training loss: 1.2406464140074474
Validation loss: 2.4780666226767063

Epoch: 230| Step: 0
Training loss: 0.35924772413696954
Validation loss: 2.5171867999550996

Epoch: 6| Step: 1
Training loss: 0.9936109229600052
Validation loss: 2.5370875369033015

Epoch: 6| Step: 2
Training loss: 1.1089942171171332
Validation loss: 2.585054082177998

Epoch: 6| Step: 3
Training loss: 1.334715970717517
Validation loss: 2.5733158176770066

Epoch: 6| Step: 4
Training loss: 0.636459859626634
Validation loss: 2.5407814365094548

Epoch: 6| Step: 5
Training loss: 1.307828537125971
Validation loss: 2.5548823490768275

Epoch: 6| Step: 6
Training loss: 0.9825470922312826
Validation loss: 2.538879405094211

Epoch: 6| Step: 7
Training loss: 1.2473653684757062
Validation loss: 2.545717653976474

Epoch: 6| Step: 8
Training loss: 0.9020948851259077
Validation loss: 2.5554872382265827

Epoch: 6| Step: 9
Training loss: 0.9894511117775394
Validation loss: 2.561000952760142

Epoch: 6| Step: 10
Training loss: 1.1913738809159462
Validation loss: 2.5305205463486815

Epoch: 6| Step: 11
Training loss: 1.0213411132248096
Validation loss: 2.5339883110897654

Epoch: 6| Step: 12
Training loss: 1.1188549589225272
Validation loss: 2.5644858284267755

Epoch: 6| Step: 13
Training loss: 0.6674090935386229
Validation loss: 2.5163030274340543

Epoch: 231| Step: 0
Training loss: 0.9475668516706406
Validation loss: 2.5299566801594713

Epoch: 6| Step: 1
Training loss: 1.424007619001601
Validation loss: 2.4951034852155693

Epoch: 6| Step: 2
Training loss: 1.0059988573268825
Validation loss: 2.491617209579901

Epoch: 6| Step: 3
Training loss: 0.9658048221591775
Validation loss: 2.483878169780449

Epoch: 6| Step: 4
Training loss: 0.9612071271544818
Validation loss: 2.4954857554438

Epoch: 6| Step: 5
Training loss: 1.0655391087973773
Validation loss: 2.4696934014955345

Epoch: 6| Step: 6
Training loss: 1.3600296987067748
Validation loss: 2.4928175481185986

Epoch: 6| Step: 7
Training loss: 0.6853324359128448
Validation loss: 2.4825802361523266

Epoch: 6| Step: 8
Training loss: 1.2102071220683894
Validation loss: 2.519520301601098

Epoch: 6| Step: 9
Training loss: 0.6697505587297468
Validation loss: 2.510885639490922

Epoch: 6| Step: 10
Training loss: 0.4012995753456415
Validation loss: 2.5513200078328713

Epoch: 6| Step: 11
Training loss: 1.005858782425493
Validation loss: 2.5859256817600573

Epoch: 6| Step: 12
Training loss: 0.9999417645663716
Validation loss: 2.5756490244098575

Epoch: 6| Step: 13
Training loss: 1.286462369389966
Validation loss: 2.6067454579516314

Epoch: 232| Step: 0
Training loss: 0.8526169434376368
Validation loss: 2.601565809049765

Epoch: 6| Step: 1
Training loss: 1.1907575498474137
Validation loss: 2.5994150678312593

Epoch: 6| Step: 2
Training loss: 1.0349044781525232
Validation loss: 2.5723594685596334

Epoch: 6| Step: 3
Training loss: 0.9857177054106981
Validation loss: 2.5695626920959977

Epoch: 6| Step: 4
Training loss: 1.334318239313603
Validation loss: 2.5858603478577837

Epoch: 6| Step: 5
Training loss: 1.0446350274357328
Validation loss: 2.562310070459482

Epoch: 6| Step: 6
Training loss: 0.3701665437747683
Validation loss: 2.5298771813837084

Epoch: 6| Step: 7
Training loss: 0.9281898424508023
Validation loss: 2.5397492399322195

Epoch: 6| Step: 8
Training loss: 0.897137472577593
Validation loss: 2.536706332205359

Epoch: 6| Step: 9
Training loss: 0.9451209891034503
Validation loss: 2.5275064742400963

Epoch: 6| Step: 10
Training loss: 1.0713507635383663
Validation loss: 2.5318477000398754

Epoch: 6| Step: 11
Training loss: 1.0808277253706677
Validation loss: 2.5227571341893973

Epoch: 6| Step: 12
Training loss: 0.9570750946589334
Validation loss: 2.548554545683063

Epoch: 6| Step: 13
Training loss: 1.501849464837591
Validation loss: 2.53696947737454

Epoch: 233| Step: 0
Training loss: 1.1794808819439495
Validation loss: 2.5553208034953396

Epoch: 6| Step: 1
Training loss: 0.7975391163694949
Validation loss: 2.5634928714918996

Epoch: 6| Step: 2
Training loss: 1.0514079214131822
Validation loss: 2.533969092728745

Epoch: 6| Step: 3
Training loss: 1.3411450086671337
Validation loss: 2.5426186541010214

Epoch: 6| Step: 4
Training loss: 1.134028446446227
Validation loss: 2.533511037279786

Epoch: 6| Step: 5
Training loss: 1.14175150386677
Validation loss: 2.518008816318175

Epoch: 6| Step: 6
Training loss: 1.085281503258347
Validation loss: 2.5261651541225447

Epoch: 6| Step: 7
Training loss: 0.8938804157846779
Validation loss: 2.5182360804592765

Epoch: 6| Step: 8
Training loss: 0.7815410072028443
Validation loss: 2.496550381678824

Epoch: 6| Step: 9
Training loss: 0.9207629268939247
Validation loss: 2.5207001086382492

Epoch: 6| Step: 10
Training loss: 0.7762838066958553
Validation loss: 2.5133624532868852

Epoch: 6| Step: 11
Training loss: 0.6902442693945654
Validation loss: 2.4710668821764523

Epoch: 6| Step: 12
Training loss: 1.1041342832506942
Validation loss: 2.500049699268813

Epoch: 6| Step: 13
Training loss: 0.6013251988420414
Validation loss: 2.4825491345544046

Epoch: 234| Step: 0
Training loss: 1.0233047049760273
Validation loss: 2.458948042010137

Epoch: 6| Step: 1
Training loss: 0.6376038233043501
Validation loss: 2.4672335932136935

Epoch: 6| Step: 2
Training loss: 0.9160471831459189
Validation loss: 2.4612155458386145

Epoch: 6| Step: 3
Training loss: 0.8947666308298189
Validation loss: 2.4765457758842326

Epoch: 6| Step: 4
Training loss: 0.41593812390745677
Validation loss: 2.4620254624881905

Epoch: 6| Step: 5
Training loss: 0.8488470406318412
Validation loss: 2.4787108251375938

Epoch: 6| Step: 6
Training loss: 0.86973249877576
Validation loss: 2.442805332484903

Epoch: 6| Step: 7
Training loss: 1.2293329234212191
Validation loss: 2.472474452505685

Epoch: 6| Step: 8
Training loss: 1.05811752361759
Validation loss: 2.471932955007087

Epoch: 6| Step: 9
Training loss: 1.45406171899115
Validation loss: 2.480900707556071

Epoch: 6| Step: 10
Training loss: 0.9041090702281641
Validation loss: 2.519281388771502

Epoch: 6| Step: 11
Training loss: 1.3460194253355846
Validation loss: 2.4621298145740824

Epoch: 6| Step: 12
Training loss: 0.5417334136430638
Validation loss: 2.487859852185503

Epoch: 6| Step: 13
Training loss: 1.162247029334145
Validation loss: 2.5420292265052016

Epoch: 235| Step: 0
Training loss: 0.7623040713621245
Validation loss: 2.5019719324854535

Epoch: 6| Step: 1
Training loss: 1.1257915890792691
Validation loss: 2.5081076765354617

Epoch: 6| Step: 2
Training loss: 0.718671794451371
Validation loss: 2.495801557655362

Epoch: 6| Step: 3
Training loss: 1.0199900796819232
Validation loss: 2.4598296099386796

Epoch: 6| Step: 4
Training loss: 1.234026799404024
Validation loss: 2.5077057460066885

Epoch: 6| Step: 5
Training loss: 0.6331305705255671
Validation loss: 2.501825846198882

Epoch: 6| Step: 6
Training loss: 1.0378025992454492
Validation loss: 2.5261918969110466

Epoch: 6| Step: 7
Training loss: 1.1398055385906851
Validation loss: 2.538198619249709

Epoch: 6| Step: 8
Training loss: 0.8334142804567622
Validation loss: 2.51473694539341

Epoch: 6| Step: 9
Training loss: 1.0873769098535437
Validation loss: 2.50162700910574

Epoch: 6| Step: 10
Training loss: 0.7751196092166834
Validation loss: 2.5525030178189505

Epoch: 6| Step: 11
Training loss: 1.3450238599398052
Validation loss: 2.490119381750247

Epoch: 6| Step: 12
Training loss: 0.7231978577727686
Validation loss: 2.5553935324925057

Epoch: 6| Step: 13
Training loss: 1.070275299094037
Validation loss: 2.526586774732431

Epoch: 236| Step: 0
Training loss: 0.7362185935557818
Validation loss: 2.568456830766647

Epoch: 6| Step: 1
Training loss: 0.8609438361126872
Validation loss: 2.5084554804870076

Epoch: 6| Step: 2
Training loss: 1.229115156398288
Validation loss: 2.533976224259063

Epoch: 6| Step: 3
Training loss: 1.0155526942410589
Validation loss: 2.5004555722936153

Epoch: 6| Step: 4
Training loss: 1.1494707403088749
Validation loss: 2.5140588994057347

Epoch: 6| Step: 5
Training loss: 1.1521623371667762
Validation loss: 2.487876487879837

Epoch: 6| Step: 6
Training loss: 0.9309278596633084
Validation loss: 2.4926108829608395

Epoch: 6| Step: 7
Training loss: 0.5871423921419158
Validation loss: 2.5023797726928443

Epoch: 6| Step: 8
Training loss: 1.0826802975316434
Validation loss: 2.4974306213576347

Epoch: 6| Step: 9
Training loss: 0.9097155048196771
Validation loss: 2.516126717815381

Epoch: 6| Step: 10
Training loss: 1.0254103885744175
Validation loss: 2.5466728354177297

Epoch: 6| Step: 11
Training loss: 0.9171679311091183
Validation loss: 2.528817244776415

Epoch: 6| Step: 12
Training loss: 1.1424761865250117
Validation loss: 2.514808633912353

Epoch: 6| Step: 13
Training loss: 0.4624675152943418
Validation loss: 2.5246217854786845

Epoch: 237| Step: 0
Training loss: 0.7900091101929947
Validation loss: 2.5096273820924315

Epoch: 6| Step: 1
Training loss: 1.162876831013881
Validation loss: 2.5041045928360126

Epoch: 6| Step: 2
Training loss: 0.7917822243191831
Validation loss: 2.512659071044348

Epoch: 6| Step: 3
Training loss: 1.1235983381945556
Validation loss: 2.5351630070682862

Epoch: 6| Step: 4
Training loss: 0.8879121656108343
Validation loss: 2.5393566592875927

Epoch: 6| Step: 5
Training loss: 1.1926076866007107
Validation loss: 2.501782934139364

Epoch: 6| Step: 6
Training loss: 1.038087889704479
Validation loss: 2.524678970197668

Epoch: 6| Step: 7
Training loss: 0.8614446859574119
Validation loss: 2.5393070438271503

Epoch: 6| Step: 8
Training loss: 0.48275279074029653
Validation loss: 2.5135293964445014

Epoch: 6| Step: 9
Training loss: 1.154878163372703
Validation loss: 2.522693112406546

Epoch: 6| Step: 10
Training loss: 1.156336497602608
Validation loss: 2.490086646752064

Epoch: 6| Step: 11
Training loss: 0.8038765978743164
Validation loss: 2.5610054603975207

Epoch: 6| Step: 12
Training loss: 1.0457309335880582
Validation loss: 2.5130481927398174

Epoch: 6| Step: 13
Training loss: 0.885379132241916
Validation loss: 2.515202037239523

Epoch: 238| Step: 0
Training loss: 0.9146891345187728
Validation loss: 2.5108840242517703

Epoch: 6| Step: 1
Training loss: 1.0477883070084868
Validation loss: 2.484827632048372

Epoch: 6| Step: 2
Training loss: 0.6193338808562682
Validation loss: 2.4872722086928283

Epoch: 6| Step: 3
Training loss: 1.3434401753787837
Validation loss: 2.4924618159887637

Epoch: 6| Step: 4
Training loss: 1.1677720532598106
Validation loss: 2.4972143435225505

Epoch: 6| Step: 5
Training loss: 1.0277505511609721
Validation loss: 2.492292967390665

Epoch: 6| Step: 6
Training loss: 0.8165259022619161
Validation loss: 2.512860238649586

Epoch: 6| Step: 7
Training loss: 0.58854704547776
Validation loss: 2.535558520026045

Epoch: 6| Step: 8
Training loss: 1.1541594086199625
Validation loss: 2.546508271950533

Epoch: 6| Step: 9
Training loss: 0.6836964993231998
Validation loss: 2.534501147512777

Epoch: 6| Step: 10
Training loss: 1.1379735778262017
Validation loss: 2.5432022360797153

Epoch: 6| Step: 11
Training loss: 0.9840530898515552
Validation loss: 2.528900157688945

Epoch: 6| Step: 12
Training loss: 0.8943653535889154
Validation loss: 2.55817015710274

Epoch: 6| Step: 13
Training loss: 0.7433704786328332
Validation loss: 2.5265950060667084

Epoch: 239| Step: 0
Training loss: 1.087995157749957
Validation loss: 2.491491362930452

Epoch: 6| Step: 1
Training loss: 1.2020984580390344
Validation loss: 2.4450707492858976

Epoch: 6| Step: 2
Training loss: 1.014656661645568
Validation loss: 2.430848758043113

Epoch: 6| Step: 3
Training loss: 1.153645339632754
Validation loss: 2.4635766767518463

Epoch: 6| Step: 4
Training loss: 0.7464365146850532
Validation loss: 2.4818388436731187

Epoch: 6| Step: 5
Training loss: 1.1262885238037048
Validation loss: 2.4755869171483025

Epoch: 6| Step: 6
Training loss: 0.8923541232444451
Validation loss: 2.5134942303143166

Epoch: 6| Step: 7
Training loss: 0.7898847997546176
Validation loss: 2.5120209746979527

Epoch: 6| Step: 8
Training loss: 0.832204523087916
Validation loss: 2.576920834634261

Epoch: 6| Step: 9
Training loss: 0.45749098323316373
Validation loss: 2.570024299840275

Epoch: 6| Step: 10
Training loss: 1.0929005185057878
Validation loss: 2.5883869907247874

Epoch: 6| Step: 11
Training loss: 0.9093945963213054
Validation loss: 2.619407799054683

Epoch: 6| Step: 12
Training loss: 0.8857438361879123
Validation loss: 2.638915114460455

Epoch: 6| Step: 13
Training loss: 0.8590006272954283
Validation loss: 2.557896973609086

Epoch: 240| Step: 0
Training loss: 0.9482224498702118
Validation loss: 2.562833248612082

Epoch: 6| Step: 1
Training loss: 1.093698118886719
Validation loss: 2.56955471613321

Epoch: 6| Step: 2
Training loss: 0.4905852168044713
Validation loss: 2.58416055288885

Epoch: 6| Step: 3
Training loss: 1.1261588591724212
Validation loss: 2.561784577864054

Epoch: 6| Step: 4
Training loss: 1.091005697181295
Validation loss: 2.5510133145472076

Epoch: 6| Step: 5
Training loss: 0.7021566504580409
Validation loss: 2.515351734313904

Epoch: 6| Step: 6
Training loss: 0.7519949368828913
Validation loss: 2.5394358835115303

Epoch: 6| Step: 7
Training loss: 0.8220529167888759
Validation loss: 2.526192323137169

Epoch: 6| Step: 8
Training loss: 0.9847190497890843
Validation loss: 2.517705714300576

Epoch: 6| Step: 9
Training loss: 1.1312698910476628
Validation loss: 2.5419190659887354

Epoch: 6| Step: 10
Training loss: 0.594807411047821
Validation loss: 2.513871293168858

Epoch: 6| Step: 11
Training loss: 0.8542932943749623
Validation loss: 2.534180241870679

Epoch: 6| Step: 12
Training loss: 1.1178129352827881
Validation loss: 2.5415260266616673

Epoch: 6| Step: 13
Training loss: 1.1670654784614873
Validation loss: 2.5321718140444727

Epoch: 241| Step: 0
Training loss: 1.1659076583180201
Validation loss: 2.5404283407462716

Epoch: 6| Step: 1
Training loss: 1.280250019525648
Validation loss: 2.5180913230791724

Epoch: 6| Step: 2
Training loss: 0.8161369500146402
Validation loss: 2.473287037227438

Epoch: 6| Step: 3
Training loss: 0.8783034228227249
Validation loss: 2.5041486516457425

Epoch: 6| Step: 4
Training loss: 0.8578692335812924
Validation loss: 2.491832655301604

Epoch: 6| Step: 5
Training loss: 0.8329167198828686
Validation loss: 2.4936699046074438

Epoch: 6| Step: 6
Training loss: 0.6948389519572347
Validation loss: 2.4832886828185226

Epoch: 6| Step: 7
Training loss: 0.9045813753542333
Validation loss: 2.505371715379066

Epoch: 6| Step: 8
Training loss: 0.8041242832089915
Validation loss: 2.51648839759101

Epoch: 6| Step: 9
Training loss: 1.0351168067183143
Validation loss: 2.5333265939449094

Epoch: 6| Step: 10
Training loss: 0.6624529911853335
Validation loss: 2.5437310282931547

Epoch: 6| Step: 11
Training loss: 0.7872781501599668
Validation loss: 2.6270936584881284

Epoch: 6| Step: 12
Training loss: 1.3517343489042621
Validation loss: 2.5986483612219975

Epoch: 6| Step: 13
Training loss: 0.8850951602120349
Validation loss: 2.6171650841037226

Epoch: 242| Step: 0
Training loss: 0.672601905426278
Validation loss: 2.5917805561762663

Epoch: 6| Step: 1
Training loss: 1.2089731835261743
Validation loss: 2.5846138882155647

Epoch: 6| Step: 2
Training loss: 1.2265114743255447
Validation loss: 2.5819372148489492

Epoch: 6| Step: 3
Training loss: 0.7632591127213357
Validation loss: 2.6255620861497198

Epoch: 6| Step: 4
Training loss: 0.8038922426358402
Validation loss: 2.5302393901285773

Epoch: 6| Step: 5
Training loss: 0.809619566151941
Validation loss: 2.5331496131072244

Epoch: 6| Step: 6
Training loss: 0.9014803896954005
Validation loss: 2.5066259116817187

Epoch: 6| Step: 7
Training loss: 1.128593427881699
Validation loss: 2.448785877227632

Epoch: 6| Step: 8
Training loss: 0.77025957061111
Validation loss: 2.43559220135645

Epoch: 6| Step: 9
Training loss: 1.2693767747063676
Validation loss: 2.4335461720517526

Epoch: 6| Step: 10
Training loss: 0.6759767635403576
Validation loss: 2.4442062551651675

Epoch: 6| Step: 11
Training loss: 0.8803896105993434
Validation loss: 2.4356238509936

Epoch: 6| Step: 12
Training loss: 1.052113535733946
Validation loss: 2.4520308807877313

Epoch: 6| Step: 13
Training loss: 0.5990678659436564
Validation loss: 2.4298773846568045

Epoch: 243| Step: 0
Training loss: 1.170935088563161
Validation loss: 2.5117069469229376

Epoch: 6| Step: 1
Training loss: 0.93103487487032
Validation loss: 2.5160266410628416

Epoch: 6| Step: 2
Training loss: 0.7823917057431449
Validation loss: 2.551782681651274

Epoch: 6| Step: 3
Training loss: 1.1498868969570255
Validation loss: 2.5606499042637636

Epoch: 6| Step: 4
Training loss: 1.1704396421993744
Validation loss: 2.5668091796615227

Epoch: 6| Step: 5
Training loss: 0.4026845211100636
Validation loss: 2.5548369455605924

Epoch: 6| Step: 6
Training loss: 1.1048839086938835
Validation loss: 2.5450052060986788

Epoch: 6| Step: 7
Training loss: 0.9732229274901035
Validation loss: 2.5334020612047707

Epoch: 6| Step: 8
Training loss: 0.6741521968239623
Validation loss: 2.551257287637989

Epoch: 6| Step: 9
Training loss: 0.6906605379100874
Validation loss: 2.5089126068746235

Epoch: 6| Step: 10
Training loss: 0.9679483357663727
Validation loss: 2.5035555238770533

Epoch: 6| Step: 11
Training loss: 0.719038159200076
Validation loss: 2.5199358067863136

Epoch: 6| Step: 12
Training loss: 0.9940153391496905
Validation loss: 2.49929469526849

Epoch: 6| Step: 13
Training loss: 0.8205761803590661
Validation loss: 2.494641525419722

Epoch: 244| Step: 0
Training loss: 1.0038453317408929
Validation loss: 2.4668593773176384

Epoch: 6| Step: 1
Training loss: 0.4449348354042794
Validation loss: 2.494379988955466

Epoch: 6| Step: 2
Training loss: 0.9045892164641434
Validation loss: 2.4894602635272056

Epoch: 6| Step: 3
Training loss: 1.2519512206255017
Validation loss: 2.494948058786495

Epoch: 6| Step: 4
Training loss: 0.9658278107231527
Validation loss: 2.5568910004227563

Epoch: 6| Step: 5
Training loss: 1.0183845590068117
Validation loss: 2.523410655380845

Epoch: 6| Step: 6
Training loss: 0.5019788030446415
Validation loss: 2.4963048565502093

Epoch: 6| Step: 7
Training loss: 0.6822784849645577
Validation loss: 2.5120243756753813

Epoch: 6| Step: 8
Training loss: 0.8235765459192121
Validation loss: 2.5301687720852715

Epoch: 6| Step: 9
Training loss: 1.1227801462295603
Validation loss: 2.53156208963883

Epoch: 6| Step: 10
Training loss: 1.0324777173092465
Validation loss: 2.5107113551157223

Epoch: 6| Step: 11
Training loss: 1.2265900043878295
Validation loss: 2.5111256941335816

Epoch: 6| Step: 12
Training loss: 0.7081300406348137
Validation loss: 2.5081017803059944

Epoch: 6| Step: 13
Training loss: 0.4096682233661865
Validation loss: 2.5137550049656183

Epoch: 245| Step: 0
Training loss: 0.6527955095664956
Validation loss: 2.5061389919685606

Epoch: 6| Step: 1
Training loss: 0.7293118377768845
Validation loss: 2.4995823398488266

Epoch: 6| Step: 2
Training loss: 1.2609982633072028
Validation loss: 2.506540735469168

Epoch: 6| Step: 3
Training loss: 0.6838449507065933
Validation loss: 2.515615580561587

Epoch: 6| Step: 4
Training loss: 1.0517009128207868
Validation loss: 2.518555946643861

Epoch: 6| Step: 5
Training loss: 0.9942699415716798
Validation loss: 2.511197533726413

Epoch: 6| Step: 6
Training loss: 0.8008802399277092
Validation loss: 2.47097896391689

Epoch: 6| Step: 7
Training loss: 0.8774583885999183
Validation loss: 2.4655310092916096

Epoch: 6| Step: 8
Training loss: 0.6963661012123756
Validation loss: 2.4702485721806426

Epoch: 6| Step: 9
Training loss: 1.1293715207880723
Validation loss: 2.4401034021599077

Epoch: 6| Step: 10
Training loss: 1.0020147531455015
Validation loss: 2.4393908957440757

Epoch: 6| Step: 11
Training loss: 0.538532826137721
Validation loss: 2.440399134933231

Epoch: 6| Step: 12
Training loss: 0.7804547267566615
Validation loss: 2.389868666825204

Epoch: 6| Step: 13
Training loss: 1.2967932342123354
Validation loss: 2.4234954927541588

Epoch: 246| Step: 0
Training loss: 0.9905218124799349
Validation loss: 2.4108692988547626

Epoch: 6| Step: 1
Training loss: 0.9912622898874471
Validation loss: 2.4240172746188926

Epoch: 6| Step: 2
Training loss: 0.882497275459039
Validation loss: 2.465422872660073

Epoch: 6| Step: 3
Training loss: 0.5237147892061798
Validation loss: 2.460518509393947

Epoch: 6| Step: 4
Training loss: 0.5379559867113767
Validation loss: 2.467253541294043

Epoch: 6| Step: 5
Training loss: 1.328408603681473
Validation loss: 2.50307016435902

Epoch: 6| Step: 6
Training loss: 0.30997945421336587
Validation loss: 2.531426463476405

Epoch: 6| Step: 7
Training loss: 0.8329074884175823
Validation loss: 2.523671216499887

Epoch: 6| Step: 8
Training loss: 0.6994280794811567
Validation loss: 2.5573130087658122

Epoch: 6| Step: 9
Training loss: 0.7151693634371147
Validation loss: 2.5344404235781597

Epoch: 6| Step: 10
Training loss: 1.3221174464176346
Validation loss: 2.5379457825867315

Epoch: 6| Step: 11
Training loss: 1.1075712234466093
Validation loss: 2.5575583385549563

Epoch: 6| Step: 12
Training loss: 0.594120512351679
Validation loss: 2.49604307326694

Epoch: 6| Step: 13
Training loss: 1.2421132191455115
Validation loss: 2.5171169044780437

Epoch: 247| Step: 0
Training loss: 1.1964214890032505
Validation loss: 2.533726712970721

Epoch: 6| Step: 1
Training loss: 0.6483392755960146
Validation loss: 2.5152367631312065

Epoch: 6| Step: 2
Training loss: 0.7859537050916174
Validation loss: 2.511083146206754

Epoch: 6| Step: 3
Training loss: 0.9890109900007609
Validation loss: 2.542246143431006

Epoch: 6| Step: 4
Training loss: 0.8728235287623409
Validation loss: 2.551377278430543

Epoch: 6| Step: 5
Training loss: 1.1608318583708899
Validation loss: 2.5609147555570746

Epoch: 6| Step: 6
Training loss: 0.5960591237421644
Validation loss: 2.578343370921346

Epoch: 6| Step: 7
Training loss: 1.0647987294633021
Validation loss: 2.530141261752336

Epoch: 6| Step: 8
Training loss: 1.1253531219684538
Validation loss: 2.525918849796398

Epoch: 6| Step: 9
Training loss: 0.5954230979249987
Validation loss: 2.5448765264807127

Epoch: 6| Step: 10
Training loss: 1.036902972873602
Validation loss: 2.540892408611911

Epoch: 6| Step: 11
Training loss: 0.8187599021371068
Validation loss: 2.541824425357585

Epoch: 6| Step: 12
Training loss: 0.6842765232112293
Validation loss: 2.5777462936887217

Epoch: 6| Step: 13
Training loss: 0.4389906760009818
Validation loss: 2.555219520799964

Epoch: 248| Step: 0
Training loss: 0.4015688238870534
Validation loss: 2.544173725118208

Epoch: 6| Step: 1
Training loss: 0.9248101013734089
Validation loss: 2.564544149035995

Epoch: 6| Step: 2
Training loss: 0.7281963067891195
Validation loss: 2.5572941561641414

Epoch: 6| Step: 3
Training loss: 1.048605044489835
Validation loss: 2.5218089182147483

Epoch: 6| Step: 4
Training loss: 1.049710490414194
Validation loss: 2.560599280206138

Epoch: 6| Step: 5
Training loss: 1.1453229750171132
Validation loss: 2.512584602042948

Epoch: 6| Step: 6
Training loss: 1.0549121193645536
Validation loss: 2.5422683294855144

Epoch: 6| Step: 7
Training loss: 0.7563973023268163
Validation loss: 2.527498856355749

Epoch: 6| Step: 8
Training loss: 0.36716931886504395
Validation loss: 2.5306458860688434

Epoch: 6| Step: 9
Training loss: 0.7136157384883848
Validation loss: 2.520057171941172

Epoch: 6| Step: 10
Training loss: 0.758689294488791
Validation loss: 2.4977555705835894

Epoch: 6| Step: 11
Training loss: 1.0325134513846994
Validation loss: 2.525351322294821

Epoch: 6| Step: 12
Training loss: 0.896234548161528
Validation loss: 2.5068221018957826

Epoch: 6| Step: 13
Training loss: 1.2823040510995227
Validation loss: 2.5044787261230805

Epoch: 249| Step: 0
Training loss: 0.881332980638723
Validation loss: 2.5575327036072806

Epoch: 6| Step: 1
Training loss: 0.7447151909537008
Validation loss: 2.5084119122633592

Epoch: 6| Step: 2
Training loss: 1.086894649527613
Validation loss: 2.5150931536305676

Epoch: 6| Step: 3
Training loss: 0.6982789996920313
Validation loss: 2.5050308000560984

Epoch: 6| Step: 4
Training loss: 0.6661180657949114
Validation loss: 2.4615285126946107

Epoch: 6| Step: 5
Training loss: 1.2824309419328284
Validation loss: 2.4901583716230835

Epoch: 6| Step: 6
Training loss: 0.7313201756509371
Validation loss: 2.5222324572456953

Epoch: 6| Step: 7
Training loss: 0.5666197538825164
Validation loss: 2.4789262032649417

Epoch: 6| Step: 8
Training loss: 1.0137066844336333
Validation loss: 2.5022996913141364

Epoch: 6| Step: 9
Training loss: 1.0118720332497453
Validation loss: 2.487528423794773

Epoch: 6| Step: 10
Training loss: 1.2002785438873178
Validation loss: 2.528258901682579

Epoch: 6| Step: 11
Training loss: 0.5420952776219223
Validation loss: 2.486145179322469

Epoch: 6| Step: 12
Training loss: 0.9001196331409282
Validation loss: 2.518999503754745

Epoch: 6| Step: 13
Training loss: 0.40105695406357905
Validation loss: 2.501704578305732

Epoch: 250| Step: 0
Training loss: 0.9308362963557291
Validation loss: 2.5360313487881307

Epoch: 6| Step: 1
Training loss: 0.7080819347649568
Validation loss: 2.5283465047272

Epoch: 6| Step: 2
Training loss: 0.8737321933137948
Validation loss: 2.5294098631536595

Epoch: 6| Step: 3
Training loss: 0.6643468584576238
Validation loss: 2.5084586149579913

Epoch: 6| Step: 4
Training loss: 1.0387503362992496
Validation loss: 2.5086658329221847

Epoch: 6| Step: 5
Training loss: 0.7304756449817678
Validation loss: 2.5510445572440643

Epoch: 6| Step: 6
Training loss: 0.8766562590204883
Validation loss: 2.4998975886626456

Epoch: 6| Step: 7
Training loss: 0.645187575507573
Validation loss: 2.534985953190926

Epoch: 6| Step: 8
Training loss: 1.095758936475466
Validation loss: 2.531239847709525

Epoch: 6| Step: 9
Training loss: 0.9237774115226182
Validation loss: 2.4935445193381023

Epoch: 6| Step: 10
Training loss: 0.9734164411737598
Validation loss: 2.5230926915083915

Epoch: 6| Step: 11
Training loss: 0.8009836824924342
Validation loss: 2.4962572768964573

Epoch: 6| Step: 12
Training loss: 0.9485806176488196
Validation loss: 2.4686828205381137

Epoch: 6| Step: 13
Training loss: 0.81715191094416
Validation loss: 2.5152048605835207

Epoch: 251| Step: 0
Training loss: 1.1325018094955708
Validation loss: 2.523138378715169

Epoch: 6| Step: 1
Training loss: 0.935308342391338
Validation loss: 2.4953293927428066

Epoch: 6| Step: 2
Training loss: 0.7173344314092908
Validation loss: 2.514366344061295

Epoch: 6| Step: 3
Training loss: 1.1495628293070697
Validation loss: 2.5435099198476454

Epoch: 6| Step: 4
Training loss: 0.9360899493796632
Validation loss: 2.4958919859753923

Epoch: 6| Step: 5
Training loss: 0.6939958042421949
Validation loss: 2.496534135465344

Epoch: 6| Step: 6
Training loss: 0.8137661531781785
Validation loss: 2.501534302896723

Epoch: 6| Step: 7
Training loss: 0.6843786910144786
Validation loss: 2.504078255052033

Epoch: 6| Step: 8
Training loss: 0.8948336760518562
Validation loss: 2.497513727352417

Epoch: 6| Step: 9
Training loss: 0.907785364687636
Validation loss: 2.4808175927287173

Epoch: 6| Step: 10
Training loss: 0.6262158250525771
Validation loss: 2.4743923063529576

Epoch: 6| Step: 11
Training loss: 0.899496499258866
Validation loss: 2.4678016612709737

Epoch: 6| Step: 12
Training loss: 0.6047495847072176
Validation loss: 2.464436253629486

Epoch: 6| Step: 13
Training loss: 1.1126293214363268
Validation loss: 2.4658657695942434

Epoch: 252| Step: 0
Training loss: 0.918932080553647
Validation loss: 2.45569629512564

Epoch: 6| Step: 1
Training loss: 0.7180395761782364
Validation loss: 2.4697186195114984

Epoch: 6| Step: 2
Training loss: 0.7939768804864401
Validation loss: 2.533618352270321

Epoch: 6| Step: 3
Training loss: 0.6356054296640923
Validation loss: 2.5016870569399137

Epoch: 6| Step: 4
Training loss: 1.1449457140718011
Validation loss: 2.5328297994094386

Epoch: 6| Step: 5
Training loss: 0.6180278995722266
Validation loss: 2.5756288025516234

Epoch: 6| Step: 6
Training loss: 0.9186877093315859
Validation loss: 2.5209112083293426

Epoch: 6| Step: 7
Training loss: 0.9210841455840543
Validation loss: 2.5174851075099642

Epoch: 6| Step: 8
Training loss: 0.897753778775282
Validation loss: 2.517827495464363

Epoch: 6| Step: 9
Training loss: 0.9223692910446416
Validation loss: 2.510957055097677

Epoch: 6| Step: 10
Training loss: 0.7551240325881123
Validation loss: 2.506866418716216

Epoch: 6| Step: 11
Training loss: 1.0723458904526804
Validation loss: 2.4918805205684675

Epoch: 6| Step: 12
Training loss: 0.9172377252555403
Validation loss: 2.521145413236728

Epoch: 6| Step: 13
Training loss: 0.5442028702886972
Validation loss: 2.489516194305355

Epoch: 253| Step: 0
Training loss: 0.5306161015711374
Validation loss: 2.506947431540868

Epoch: 6| Step: 1
Training loss: 0.762209338148635
Validation loss: 2.514586640795451

Epoch: 6| Step: 2
Training loss: 1.180792739204501
Validation loss: 2.5450815292653477

Epoch: 6| Step: 3
Training loss: 0.9006488950949297
Validation loss: 2.532611729282527

Epoch: 6| Step: 4
Training loss: 0.7069984765650132
Validation loss: 2.505891610341708

Epoch: 6| Step: 5
Training loss: 0.8441590624432567
Validation loss: 2.536326594453408

Epoch: 6| Step: 6
Training loss: 0.9830612922974867
Validation loss: 2.5145540520181946

Epoch: 6| Step: 7
Training loss: 0.6850607036577118
Validation loss: 2.526203346131568

Epoch: 6| Step: 8
Training loss: 0.92871331215604
Validation loss: 2.53718864110392

Epoch: 6| Step: 9
Training loss: 1.020561545385638
Validation loss: 2.5493044931584454

Epoch: 6| Step: 10
Training loss: 0.7369165068140244
Validation loss: 2.5405513768148484

Epoch: 6| Step: 11
Training loss: 0.7688639114465909
Validation loss: 2.530199423093211

Epoch: 6| Step: 12
Training loss: 1.0256778569057883
Validation loss: 2.502741127167217

Epoch: 6| Step: 13
Training loss: 0.35359005645023067
Validation loss: 2.5214630431320613

Epoch: 254| Step: 0
Training loss: 0.8267780361860673
Validation loss: 2.524709745732986

Epoch: 6| Step: 1
Training loss: 0.9139802031679006
Validation loss: 2.5017545531824026

Epoch: 6| Step: 2
Training loss: 0.9799725618219258
Validation loss: 2.5088630520094672

Epoch: 6| Step: 3
Training loss: 0.5211182927381474
Validation loss: 2.4743873425424203

Epoch: 6| Step: 4
Training loss: 0.7336805184657127
Validation loss: 2.5057533910635907

Epoch: 6| Step: 5
Training loss: 0.9994641895109635
Validation loss: 2.507201082310263

Epoch: 6| Step: 6
Training loss: 0.7210894533899325
Validation loss: 2.495975288023066

Epoch: 6| Step: 7
Training loss: 0.7731913550603561
Validation loss: 2.536557626550564

Epoch: 6| Step: 8
Training loss: 1.16432821838132
Validation loss: 2.4982886856045194

Epoch: 6| Step: 9
Training loss: 0.7725108597124821
Validation loss: 2.5135173943118643

Epoch: 6| Step: 10
Training loss: 0.6821785146249945
Validation loss: 2.539957133934206

Epoch: 6| Step: 11
Training loss: 0.8566776599871346
Validation loss: 2.5183196675040085

Epoch: 6| Step: 12
Training loss: 0.7638198436012277
Validation loss: 2.5212402977989767

Epoch: 6| Step: 13
Training loss: 0.9580168961804951
Validation loss: 2.512493429684016

Epoch: 255| Step: 0
Training loss: 1.0012834776235702
Validation loss: 2.5120011376973435

Epoch: 6| Step: 1
Training loss: 0.7796048963437032
Validation loss: 2.5373057821044966

Epoch: 6| Step: 2
Training loss: 0.6354247910860895
Validation loss: 2.560458302582158

Epoch: 6| Step: 3
Training loss: 0.3119219201518871
Validation loss: 2.5521996735069763

Epoch: 6| Step: 4
Training loss: 0.8587262218909211
Validation loss: 2.555417459352354

Epoch: 6| Step: 5
Training loss: 0.6074240828593566
Validation loss: 2.5637809899082686

Epoch: 6| Step: 6
Training loss: 0.5209998405057257
Validation loss: 2.5295068685741935

Epoch: 6| Step: 7
Training loss: 0.9242434062232435
Validation loss: 2.5215491767751645

Epoch: 6| Step: 8
Training loss: 0.6758361088530732
Validation loss: 2.578258720502402

Epoch: 6| Step: 9
Training loss: 1.0845555355824676
Validation loss: 2.513076106964117

Epoch: 6| Step: 10
Training loss: 0.7767126694208922
Validation loss: 2.5420259150879208

Epoch: 6| Step: 11
Training loss: 0.9816857797762193
Validation loss: 2.538585257156061

Epoch: 6| Step: 12
Training loss: 1.0863895710257758
Validation loss: 2.517018009878411

Epoch: 6| Step: 13
Training loss: 1.124320195692905
Validation loss: 2.540434078693671

Epoch: 256| Step: 0
Training loss: 0.6773386522781044
Validation loss: 2.5220882743344584

Epoch: 6| Step: 1
Training loss: 0.6891989739312977
Validation loss: 2.5487946523793554

Epoch: 6| Step: 2
Training loss: 0.6616221072481283
Validation loss: 2.5388175610198562

Epoch: 6| Step: 3
Training loss: 0.8540736628506729
Validation loss: 2.5502477363471923

Epoch: 6| Step: 4
Training loss: 0.7210231163668244
Validation loss: 2.542027559955701

Epoch: 6| Step: 5
Training loss: 1.1225703812519987
Validation loss: 2.5912361723314614

Epoch: 6| Step: 6
Training loss: 1.1680047275271175
Validation loss: 2.5804242404210433

Epoch: 6| Step: 7
Training loss: 1.2085131094919508
Validation loss: 2.552837505664919

Epoch: 6| Step: 8
Training loss: 0.5334181299698567
Validation loss: 2.5475552333274423

Epoch: 6| Step: 9
Training loss: 0.4963361643448291
Validation loss: 2.5368275347268203

Epoch: 6| Step: 10
Training loss: 0.7357750391379038
Validation loss: 2.5141495020934346

Epoch: 6| Step: 11
Training loss: 0.900817703607873
Validation loss: 2.514749623712091

Epoch: 6| Step: 12
Training loss: 0.8287770565213535
Validation loss: 2.5168112279826644

Epoch: 6| Step: 13
Training loss: 0.6751556367171719
Validation loss: 2.4694418788523023

Epoch: 257| Step: 0
Training loss: 0.8289484931903114
Validation loss: 2.4902969149819976

Epoch: 6| Step: 1
Training loss: 1.0167417402117203
Validation loss: 2.479421871496688

Epoch: 6| Step: 2
Training loss: 0.7985334155854591
Validation loss: 2.5029974887409505

Epoch: 6| Step: 3
Training loss: 0.9586346332316228
Validation loss: 2.5554516166884387

Epoch: 6| Step: 4
Training loss: 0.9022910362798696
Validation loss: 2.56330485776077

Epoch: 6| Step: 5
Training loss: 0.6789466064539119
Validation loss: 2.5690736707281983

Epoch: 6| Step: 6
Training loss: 0.616105205091752
Validation loss: 2.5580436139528526

Epoch: 6| Step: 7
Training loss: 0.742399045008526
Validation loss: 2.566877356491498

Epoch: 6| Step: 8
Training loss: 0.7186221962789643
Validation loss: 2.606320239767432

Epoch: 6| Step: 9
Training loss: 0.8685200736867047
Validation loss: 2.5663496394455207

Epoch: 6| Step: 10
Training loss: 0.6848301197238713
Validation loss: 2.57476476090004

Epoch: 6| Step: 11
Training loss: 0.8552035264605334
Validation loss: 2.487756338240994

Epoch: 6| Step: 12
Training loss: 1.0373271706266485
Validation loss: 2.5203798676568057

Epoch: 6| Step: 13
Training loss: 0.7263117121544564
Validation loss: 2.4940860447546513

Epoch: 258| Step: 0
Training loss: 0.9521156031498077
Validation loss: 2.4656610007223225

Epoch: 6| Step: 1
Training loss: 1.1958668738434286
Validation loss: 2.475718905678857

Epoch: 6| Step: 2
Training loss: 0.8619755670908348
Validation loss: 2.4738364738326495

Epoch: 6| Step: 3
Training loss: 0.33820251447164723
Validation loss: 2.475477952198424

Epoch: 6| Step: 4
Training loss: 0.9811222892312618
Validation loss: 2.4449649487665157

Epoch: 6| Step: 5
Training loss: 0.58067771159072
Validation loss: 2.4873976921553025

Epoch: 6| Step: 6
Training loss: 0.9838534896199347
Validation loss: 2.472928427203404

Epoch: 6| Step: 7
Training loss: 0.8509996286295025
Validation loss: 2.515329401045738

Epoch: 6| Step: 8
Training loss: 0.9209509275329316
Validation loss: 2.501810472459463

Epoch: 6| Step: 9
Training loss: 0.720585841945415
Validation loss: 2.47202409260122

Epoch: 6| Step: 10
Training loss: 0.8338346324556997
Validation loss: 2.494732303047121

Epoch: 6| Step: 11
Training loss: 0.5489832431514999
Validation loss: 2.5196551904944187

Epoch: 6| Step: 12
Training loss: 0.747664231723126
Validation loss: 2.5315073597254005

Epoch: 6| Step: 13
Training loss: 0.361787987955954
Validation loss: 2.5126690606827573

Epoch: 259| Step: 0
Training loss: 0.6700391972520046
Validation loss: 2.542068597599957

Epoch: 6| Step: 1
Training loss: 0.6607703788983398
Validation loss: 2.5467056730476885

Epoch: 6| Step: 2
Training loss: 0.6444844084393392
Validation loss: 2.527575151821228

Epoch: 6| Step: 3
Training loss: 1.145734863674024
Validation loss: 2.5176992046534483

Epoch: 6| Step: 4
Training loss: 0.7894360253069074
Validation loss: 2.547534682298932

Epoch: 6| Step: 5
Training loss: 1.0898635479622574
Validation loss: 2.5301865379819914

Epoch: 6| Step: 6
Training loss: 0.716246598986262
Validation loss: 2.545196608280376

Epoch: 6| Step: 7
Training loss: 0.674485303539111
Validation loss: 2.5218144443809556

Epoch: 6| Step: 8
Training loss: 1.1527242775775035
Validation loss: 2.527612164247562

Epoch: 6| Step: 9
Training loss: 0.5083753547601562
Validation loss: 2.5400092448168943

Epoch: 6| Step: 10
Training loss: 0.6414291173317869
Validation loss: 2.5198210681598097

Epoch: 6| Step: 11
Training loss: 0.7173671688510519
Validation loss: 2.5170300528650875

Epoch: 6| Step: 12
Training loss: 0.5941620952631869
Validation loss: 2.5400410129556836

Epoch: 6| Step: 13
Training loss: 1.0705082846565508
Validation loss: 2.507351186518845

Epoch: 260| Step: 0
Training loss: 0.628138743198034
Validation loss: 2.5345758404176904

Epoch: 6| Step: 1
Training loss: 0.8856812848368434
Validation loss: 2.5570009690932087

Epoch: 6| Step: 2
Training loss: 1.000105613853399
Validation loss: 2.5232369389466984

Epoch: 6| Step: 3
Training loss: 0.414005581524445
Validation loss: 2.54346966115443

Epoch: 6| Step: 4
Training loss: 0.870838521336581
Validation loss: 2.5294474436685297

Epoch: 6| Step: 5
Training loss: 0.8340895003589661
Validation loss: 2.565945218898321

Epoch: 6| Step: 6
Training loss: 0.6104727662859715
Validation loss: 2.5206520532689205

Epoch: 6| Step: 7
Training loss: 1.10647434826131
Validation loss: 2.5569738569811973

Epoch: 6| Step: 8
Training loss: 0.5005591365621667
Validation loss: 2.564064033787146

Epoch: 6| Step: 9
Training loss: 0.30765617971191844
Validation loss: 2.523619089260279

Epoch: 6| Step: 10
Training loss: 0.97616450019606
Validation loss: 2.4697668739146668

Epoch: 6| Step: 11
Training loss: 1.1931008716059868
Validation loss: 2.521075599545815

Epoch: 6| Step: 12
Training loss: 0.769396542604679
Validation loss: 2.512872877977261

Epoch: 6| Step: 13
Training loss: 0.42040625735434384
Validation loss: 2.4678781968288184

Epoch: 261| Step: 0
Training loss: 0.766598180289613
Validation loss: 2.4964217245033105

Epoch: 6| Step: 1
Training loss: 0.45190378577534746
Validation loss: 2.4643180737359827

Epoch: 6| Step: 2
Training loss: 0.8337976751465753
Validation loss: 2.520505646048909

Epoch: 6| Step: 3
Training loss: 0.9556210462789037
Validation loss: 2.4861337874355254

Epoch: 6| Step: 4
Training loss: 0.7232497793567161
Validation loss: 2.4904146742772153

Epoch: 6| Step: 5
Training loss: 0.665042109769542
Validation loss: 2.4797899943576605

Epoch: 6| Step: 6
Training loss: 1.0789134694492515
Validation loss: 2.4698939676000045

Epoch: 6| Step: 7
Training loss: 0.7293073427647436
Validation loss: 2.4925383179031897

Epoch: 6| Step: 8
Training loss: 0.7941377413613372
Validation loss: 2.480403700791048

Epoch: 6| Step: 9
Training loss: 0.6633676596207213
Validation loss: 2.5137241942375494

Epoch: 6| Step: 10
Training loss: 1.0601672200792853
Validation loss: 2.518206664301914

Epoch: 6| Step: 11
Training loss: 0.738615374166865
Validation loss: 2.4957946241721

Epoch: 6| Step: 12
Training loss: 0.8310639754066588
Validation loss: 2.5187541409670695

Epoch: 6| Step: 13
Training loss: 0.64875771762322
Validation loss: 2.4903581429338653

Epoch: 262| Step: 0
Training loss: 0.3347518757830963
Validation loss: 2.529685746009357

Epoch: 6| Step: 1
Training loss: 0.785119430665571
Validation loss: 2.5317840650825123

Epoch: 6| Step: 2
Training loss: 0.9986844051529661
Validation loss: 2.5619226886350583

Epoch: 6| Step: 3
Training loss: 0.8267780361860673
Validation loss: 2.548902600230148

Epoch: 6| Step: 4
Training loss: 0.7656346923837432
Validation loss: 2.562325053191946

Epoch: 6| Step: 5
Training loss: 1.113659389590439
Validation loss: 2.5620350089426083

Epoch: 6| Step: 6
Training loss: 0.5855478644283147
Validation loss: 2.573322079038974

Epoch: 6| Step: 7
Training loss: 0.6278378907495565
Validation loss: 2.5348012690107966

Epoch: 6| Step: 8
Training loss: 0.9010054998177046
Validation loss: 2.5410550324817023

Epoch: 6| Step: 9
Training loss: 0.583407394498781
Validation loss: 2.5155956327996387

Epoch: 6| Step: 10
Training loss: 0.8072012368693672
Validation loss: 2.5088133883599086

Epoch: 6| Step: 11
Training loss: 0.966035762936375
Validation loss: 2.5124995283513

Epoch: 6| Step: 12
Training loss: 0.7076037707571735
Validation loss: 2.536096948428223

Epoch: 6| Step: 13
Training loss: 0.7807900409917364
Validation loss: 2.5103320120809975

Epoch: 263| Step: 0
Training loss: 0.8302354371844901
Validation loss: 2.5353281213865575

Epoch: 6| Step: 1
Training loss: 1.1337108338645165
Validation loss: 2.500072765829553

Epoch: 6| Step: 2
Training loss: 0.780602682877352
Validation loss: 2.519355363709087

Epoch: 6| Step: 3
Training loss: 0.9233113753006525
Validation loss: 2.544560757821577

Epoch: 6| Step: 4
Training loss: 0.5226355145137349
Validation loss: 2.5006457222955762

Epoch: 6| Step: 5
Training loss: 0.8692896340182509
Validation loss: 2.5164804972707246

Epoch: 6| Step: 6
Training loss: 0.5832934167238324
Validation loss: 2.5661740409868736

Epoch: 6| Step: 7
Training loss: 0.29948379540667214
Validation loss: 2.540818303980316

Epoch: 6| Step: 8
Training loss: 0.7180906671695017
Validation loss: 2.5337920222016828

Epoch: 6| Step: 9
Training loss: 0.8616701861173768
Validation loss: 2.5186408289963906

Epoch: 6| Step: 10
Training loss: 1.033087567103
Validation loss: 2.5608731399700835

Epoch: 6| Step: 11
Training loss: 0.6341099095939291
Validation loss: 2.560640789614453

Epoch: 6| Step: 12
Training loss: 0.7627929937548005
Validation loss: 2.5267070209035984

Epoch: 6| Step: 13
Training loss: 0.600068752005538
Validation loss: 2.521215575799882

Epoch: 264| Step: 0
Training loss: 0.6320125091377092
Validation loss: 2.587907324977183

Epoch: 6| Step: 1
Training loss: 0.845943777894596
Validation loss: 2.516758060738065

Epoch: 6| Step: 2
Training loss: 0.7997817710415984
Validation loss: 2.568575472135224

Epoch: 6| Step: 3
Training loss: 0.7688317387242722
Validation loss: 2.530516172336376

Epoch: 6| Step: 4
Training loss: 0.88819768641754
Validation loss: 2.499355012487236

Epoch: 6| Step: 5
Training loss: 0.6122032458708143
Validation loss: 2.5306985533702826

Epoch: 6| Step: 6
Training loss: 0.47395225842393873
Validation loss: 2.5400522882255108

Epoch: 6| Step: 7
Training loss: 0.9426289133300002
Validation loss: 2.516485750910072

Epoch: 6| Step: 8
Training loss: 1.0217508293094355
Validation loss: 2.514233912243417

Epoch: 6| Step: 9
Training loss: 0.46113995777170136
Validation loss: 2.478653828278166

Epoch: 6| Step: 10
Training loss: 0.662436345479193
Validation loss: 2.5044141050281064

Epoch: 6| Step: 11
Training loss: 0.8449667175780933
Validation loss: 2.492999382009654

Epoch: 6| Step: 12
Training loss: 0.921040043709001
Validation loss: 2.4851892609590145

Epoch: 6| Step: 13
Training loss: 0.8794683735719965
Validation loss: 2.5292055438573118

Epoch: 265| Step: 0
Training loss: 0.8964898269254837
Validation loss: 2.52504302822454

Epoch: 6| Step: 1
Training loss: 0.9617503690131372
Validation loss: 2.5165453448719854

Epoch: 6| Step: 2
Training loss: 0.7888921421577939
Validation loss: 2.527863455487128

Epoch: 6| Step: 3
Training loss: 0.5192902371662532
Validation loss: 2.546600256517136

Epoch: 6| Step: 4
Training loss: 0.8388374154577503
Validation loss: 2.5692149194933718

Epoch: 6| Step: 5
Training loss: 0.5238499226540125
Validation loss: 2.5636323992371057

Epoch: 6| Step: 6
Training loss: 0.9026122251144655
Validation loss: 2.563539477754563

Epoch: 6| Step: 7
Training loss: 0.9393884711908133
Validation loss: 2.5660422818062045

Epoch: 6| Step: 8
Training loss: 0.5685449408714962
Validation loss: 2.568511539903318

Epoch: 6| Step: 9
Training loss: 0.808507721235955
Validation loss: 2.560080135258326

Epoch: 6| Step: 10
Training loss: 0.5610070018161368
Validation loss: 2.547759750399185

Epoch: 6| Step: 11
Training loss: 0.5853589062234842
Validation loss: 2.5855858230342483

Epoch: 6| Step: 12
Training loss: 0.8755542498370126
Validation loss: 2.568992623208286

Epoch: 6| Step: 13
Training loss: 0.9406980010945626
Validation loss: 2.550635969145421

Epoch: 266| Step: 0
Training loss: 1.0572036681487942
Validation loss: 2.5664436553747945

Epoch: 6| Step: 1
Training loss: 0.5364797612574171
Validation loss: 2.5495014087681707

Epoch: 6| Step: 2
Training loss: 1.0335606783811442
Validation loss: 2.601909314395996

Epoch: 6| Step: 3
Training loss: 0.4117685870530633
Validation loss: 2.575568381880426

Epoch: 6| Step: 4
Training loss: 0.7173705754533323
Validation loss: 2.5585559132338123

Epoch: 6| Step: 5
Training loss: 0.6504061585367019
Validation loss: 2.579664324798218

Epoch: 6| Step: 6
Training loss: 0.9498558261290043
Validation loss: 2.5699392781410624

Epoch: 6| Step: 7
Training loss: 0.49651781115128824
Validation loss: 2.553170680004953

Epoch: 6| Step: 8
Training loss: 0.6120701877730932
Validation loss: 2.5592073385059315

Epoch: 6| Step: 9
Training loss: 0.6548786366844666
Validation loss: 2.5472694271228784

Epoch: 6| Step: 10
Training loss: 0.9447575035493753
Validation loss: 2.5577131972837055

Epoch: 6| Step: 11
Training loss: 0.9443452158080581
Validation loss: 2.5849194784554252

Epoch: 6| Step: 12
Training loss: 0.7768107364802408
Validation loss: 2.5694517825250145

Epoch: 6| Step: 13
Training loss: 0.40533845678668223
Validation loss: 2.5371020319963273

Epoch: 267| Step: 0
Training loss: 0.37343898357910676
Validation loss: 2.5795722734997986

Epoch: 6| Step: 1
Training loss: 0.6148651468317684
Validation loss: 2.55870536730446

Epoch: 6| Step: 2
Training loss: 0.67088195691696
Validation loss: 2.553802342909235

Epoch: 6| Step: 3
Training loss: 0.5780438546634014
Validation loss: 2.5272292878511684

Epoch: 6| Step: 4
Training loss: 0.9097148823785777
Validation loss: 2.5386329286231564

Epoch: 6| Step: 5
Training loss: 0.5504070661267261
Validation loss: 2.5429009161249208

Epoch: 6| Step: 6
Training loss: 0.9905969381118334
Validation loss: 2.572858400163779

Epoch: 6| Step: 7
Training loss: 0.8159434270625228
Validation loss: 2.5792054309808123

Epoch: 6| Step: 8
Training loss: 0.5519647800864533
Validation loss: 2.558024415967319

Epoch: 6| Step: 9
Training loss: 0.8088182146999345
Validation loss: 2.580199494433407

Epoch: 6| Step: 10
Training loss: 0.977644846982149
Validation loss: 2.622030163254369

Epoch: 6| Step: 11
Training loss: 1.0694658035083016
Validation loss: 2.5797588263870384

Epoch: 6| Step: 12
Training loss: 0.6988188383147448
Validation loss: 2.5866437432797076

Epoch: 6| Step: 13
Training loss: 0.7068806482590271
Validation loss: 2.580961186916719

Epoch: 268| Step: 0
Training loss: 0.67152377862363
Validation loss: 2.57007069788567

Epoch: 6| Step: 1
Training loss: 0.8101866875488238
Validation loss: 2.550635005255684

Epoch: 6| Step: 2
Training loss: 0.2801605954447551
Validation loss: 2.548609177589791

Epoch: 6| Step: 3
Training loss: 1.0190300421998475
Validation loss: 2.540943137750293

Epoch: 6| Step: 4
Training loss: 0.6768103685105042
Validation loss: 2.564328851373682

Epoch: 6| Step: 5
Training loss: 0.8171163145026488
Validation loss: 2.544405343440314

Epoch: 6| Step: 6
Training loss: 0.7054131258879243
Validation loss: 2.5274273015899698

Epoch: 6| Step: 7
Training loss: 1.0994575355000569
Validation loss: 2.5389617299165503

Epoch: 6| Step: 8
Training loss: 0.5301803591480152
Validation loss: 2.5004539610822016

Epoch: 6| Step: 9
Training loss: 0.9342617693520325
Validation loss: 2.500757613288862

Epoch: 6| Step: 10
Training loss: 0.687950983383393
Validation loss: 2.5278103092478275

Epoch: 6| Step: 11
Training loss: 0.5415204168611202
Validation loss: 2.5750403114251403

Epoch: 6| Step: 12
Training loss: 0.6356260132007907
Validation loss: 2.5767450830402154

Epoch: 6| Step: 13
Training loss: 1.021795163550199
Validation loss: 2.592515667794537

Epoch: 269| Step: 0
Training loss: 0.6805978138015569
Validation loss: 2.582939107614543

Epoch: 6| Step: 1
Training loss: 0.7480904588875933
Validation loss: 2.5744116219151367

Epoch: 6| Step: 2
Training loss: 0.8106003709167754
Validation loss: 2.5890215845637936

Epoch: 6| Step: 3
Training loss: 0.5697579496497767
Validation loss: 2.560365070154324

Epoch: 6| Step: 4
Training loss: 0.4635091423739964
Validation loss: 2.5551851285968517

Epoch: 6| Step: 5
Training loss: 0.7636014705897578
Validation loss: 2.524969051378133

Epoch: 6| Step: 6
Training loss: 1.0266144923684142
Validation loss: 2.5079420683216247

Epoch: 6| Step: 7
Training loss: 0.8695465511542071
Validation loss: 2.520380940765002

Epoch: 6| Step: 8
Training loss: 0.9188657233608423
Validation loss: 2.521107702359226

Epoch: 6| Step: 9
Training loss: 0.7325619169502552
Validation loss: 2.488326277199642

Epoch: 6| Step: 10
Training loss: 0.5994614409326416
Validation loss: 2.4788859135929964

Epoch: 6| Step: 11
Training loss: 0.86112215862229
Validation loss: 2.476264625927652

Epoch: 6| Step: 12
Training loss: 0.7442519137249305
Validation loss: 2.4788182724648324

Epoch: 6| Step: 13
Training loss: 0.7905348835727527
Validation loss: 2.5229240912909616

Epoch: 270| Step: 0
Training loss: 0.7392166106056632
Validation loss: 2.504430185476372

Epoch: 6| Step: 1
Training loss: 0.48244547303588603
Validation loss: 2.508017528689809

Epoch: 6| Step: 2
Training loss: 1.014023971413465
Validation loss: 2.5019075560948654

Epoch: 6| Step: 3
Training loss: 0.9127667037304743
Validation loss: 2.5163782635647385

Epoch: 6| Step: 4
Training loss: 0.570032625895922
Validation loss: 2.563953623644386

Epoch: 6| Step: 5
Training loss: 0.8776053740873248
Validation loss: 2.5591964496527413

Epoch: 6| Step: 6
Training loss: 0.7033597977986644
Validation loss: 2.521296313639215

Epoch: 6| Step: 7
Training loss: 0.8635146917187793
Validation loss: 2.504642036688683

Epoch: 6| Step: 8
Training loss: 0.44455497289554946
Validation loss: 2.523888407498972

Epoch: 6| Step: 9
Training loss: 0.5549005448523449
Validation loss: 2.5150807328897864

Epoch: 6| Step: 10
Training loss: 0.591444357446774
Validation loss: 2.5097959684900837

Epoch: 6| Step: 11
Training loss: 0.9989547929644705
Validation loss: 2.5114300098319973

Epoch: 6| Step: 12
Training loss: 0.829783524238568
Validation loss: 2.523651674752324

Epoch: 6| Step: 13
Training loss: 0.2617237887680327
Validation loss: 2.5146674079629463

Epoch: 271| Step: 0
Training loss: 0.8668999753735743
Validation loss: 2.525556476166492

Epoch: 6| Step: 1
Training loss: 0.9720591355337125
Validation loss: 2.5550414266053987

Epoch: 6| Step: 2
Training loss: 0.6736750774446779
Validation loss: 2.531702041520869

Epoch: 6| Step: 3
Training loss: 0.33585936724460236
Validation loss: 2.5134213945671338

Epoch: 6| Step: 4
Training loss: 0.7511233023949502
Validation loss: 2.5467283145132753

Epoch: 6| Step: 5
Training loss: 0.7406097104711571
Validation loss: 2.533555298079869

Epoch: 6| Step: 6
Training loss: 0.992742578423492
Validation loss: 2.563903859236988

Epoch: 6| Step: 7
Training loss: 0.5035601469706736
Validation loss: 2.5352846150389436

Epoch: 6| Step: 8
Training loss: 0.4392697439104079
Validation loss: 2.5430013408386776

Epoch: 6| Step: 9
Training loss: 0.9917868458562683
Validation loss: 2.5587146070753053

Epoch: 6| Step: 10
Training loss: 0.5093344549413051
Validation loss: 2.5201610091342563

Epoch: 6| Step: 11
Training loss: 0.861562407240726
Validation loss: 2.5023000176217693

Epoch: 6| Step: 12
Training loss: 0.6970864073652705
Validation loss: 2.532539255069811

Epoch: 6| Step: 13
Training loss: 0.6326593284315346
Validation loss: 2.565341180737178

Epoch: 272| Step: 0
Training loss: 0.5451630636255723
Validation loss: 2.5603370421897624

Epoch: 6| Step: 1
Training loss: 0.9203211086110201
Validation loss: 2.498610632409769

Epoch: 6| Step: 2
Training loss: 0.9201427931472831
Validation loss: 2.5696010079244043

Epoch: 6| Step: 3
Training loss: 0.8997140191619503
Validation loss: 2.520487574926345

Epoch: 6| Step: 4
Training loss: 0.21059847891145939
Validation loss: 2.5600550122432453

Epoch: 6| Step: 5
Training loss: 0.4267797224413121
Validation loss: 2.5943833610833997

Epoch: 6| Step: 6
Training loss: 0.7105639807438813
Validation loss: 2.57438813747607

Epoch: 6| Step: 7
Training loss: 0.7601422942743735
Validation loss: 2.5310904532217937

Epoch: 6| Step: 8
Training loss: 0.8126773273922985
Validation loss: 2.55486505393227

Epoch: 6| Step: 9
Training loss: 0.8461185694723624
Validation loss: 2.5228352751466185

Epoch: 6| Step: 10
Training loss: 0.785382935552655
Validation loss: 2.531162406796387

Epoch: 6| Step: 11
Training loss: 0.5249282901472405
Validation loss: 2.51457110039039

Epoch: 6| Step: 12
Training loss: 0.9581495951999988
Validation loss: 2.4866774787668877

Epoch: 6| Step: 13
Training loss: 0.7515129088855891
Validation loss: 2.5034075177228665

Epoch: 273| Step: 0
Training loss: 1.1045140433741905
Validation loss: 2.4880890602919017

Epoch: 6| Step: 1
Training loss: 0.794191854750634
Validation loss: 2.503977241154127

Epoch: 6| Step: 2
Training loss: 0.7502317070667769
Validation loss: 2.5326031352506537

Epoch: 6| Step: 3
Training loss: 0.4745671131799556
Validation loss: 2.5621749367616595

Epoch: 6| Step: 4
Training loss: 0.6607028120657441
Validation loss: 2.5569811261243864

Epoch: 6| Step: 5
Training loss: 0.7853505667504879
Validation loss: 2.536113371828191

Epoch: 6| Step: 6
Training loss: 0.704071869667175
Validation loss: 2.5238275125284413

Epoch: 6| Step: 7
Training loss: 0.7119297188082542
Validation loss: 2.5262676361639542

Epoch: 6| Step: 8
Training loss: 0.7570818495399101
Validation loss: 2.4991673826315726

Epoch: 6| Step: 9
Training loss: 0.5767886723556824
Validation loss: 2.459794957502779

Epoch: 6| Step: 10
Training loss: 0.5451434378896489
Validation loss: 2.4969169269323963

Epoch: 6| Step: 11
Training loss: 0.8683080221307943
Validation loss: 2.458485744778894

Epoch: 6| Step: 12
Training loss: 0.7879008816839641
Validation loss: 2.4672177285662706

Epoch: 6| Step: 13
Training loss: 0.7732129782574712
Validation loss: 2.4756624534927187

Epoch: 274| Step: 0
Training loss: 0.5556855691994879
Validation loss: 2.4810041148784028

Epoch: 6| Step: 1
Training loss: 1.0792080511653883
Validation loss: 2.503483177237968

Epoch: 6| Step: 2
Training loss: 0.5345093652994912
Validation loss: 2.4964241192938363

Epoch: 6| Step: 3
Training loss: 1.0385425385242248
Validation loss: 2.5058858516130944

Epoch: 6| Step: 4
Training loss: 0.6520161977054807
Validation loss: 2.4817995035903198

Epoch: 6| Step: 5
Training loss: 0.8856958211015702
Validation loss: 2.507291881686131

Epoch: 6| Step: 6
Training loss: 0.5594079013290995
Validation loss: 2.512144017753436

Epoch: 6| Step: 7
Training loss: 0.5481934594058874
Validation loss: 2.562173007658016

Epoch: 6| Step: 8
Training loss: 0.7533812201803146
Validation loss: 2.504817448545809

Epoch: 6| Step: 9
Training loss: 0.7928591121553391
Validation loss: 2.5222886929536474

Epoch: 6| Step: 10
Training loss: 0.5839966482448414
Validation loss: 2.518934682185693

Epoch: 6| Step: 11
Training loss: 0.7602130190439276
Validation loss: 2.5330104805388847

Epoch: 6| Step: 12
Training loss: 0.6946230695724092
Validation loss: 2.5255061185849335

Epoch: 6| Step: 13
Training loss: 0.9072634193645219
Validation loss: 2.5411261359149417

Epoch: 275| Step: 0
Training loss: 0.7603893710598061
Validation loss: 2.5202374575682254

Epoch: 6| Step: 1
Training loss: 0.7273370039777618
Validation loss: 2.527085372281081

Epoch: 6| Step: 2
Training loss: 0.611868890336329
Validation loss: 2.528736681169183

Epoch: 6| Step: 3
Training loss: 0.9752980094696136
Validation loss: 2.502611943134329

Epoch: 6| Step: 4
Training loss: 0.8265220675467684
Validation loss: 2.552041160196534

Epoch: 6| Step: 5
Training loss: 0.957457840491828
Validation loss: 2.5330611828239884

Epoch: 6| Step: 6
Training loss: 0.6242909223826245
Validation loss: 2.529919784112764

Epoch: 6| Step: 7
Training loss: 0.6875150852282311
Validation loss: 2.557020725685401

Epoch: 6| Step: 8
Training loss: 0.6240450477738585
Validation loss: 2.561457089847847

Epoch: 6| Step: 9
Training loss: 0.9959349262550213
Validation loss: 2.541694778806032

Epoch: 6| Step: 10
Training loss: 0.5931118999678593
Validation loss: 2.517787356859463

Epoch: 6| Step: 11
Training loss: 0.7677816261974678
Validation loss: 2.5520293683157473

Epoch: 6| Step: 12
Training loss: 0.5112583039875489
Validation loss: 2.548593460386543

Epoch: 6| Step: 13
Training loss: 0.3618521936506948
Validation loss: 2.5486334276611444

Epoch: 276| Step: 0
Training loss: 0.6944850756096911
Validation loss: 2.5405436814959215

Epoch: 6| Step: 1
Training loss: 0.8689840454331403
Validation loss: 2.5839386633368178

Epoch: 6| Step: 2
Training loss: 0.8789825745397072
Validation loss: 2.592899099418283

Epoch: 6| Step: 3
Training loss: 0.801545648230375
Validation loss: 2.5692443004401815

Epoch: 6| Step: 4
Training loss: 0.7206009376260384
Validation loss: 2.5376380214861842

Epoch: 6| Step: 5
Training loss: 0.5178154455272671
Validation loss: 2.5435704078597383

Epoch: 6| Step: 6
Training loss: 0.859285107159284
Validation loss: 2.525391004664641

Epoch: 6| Step: 7
Training loss: 0.6699888457252292
Validation loss: 2.5088873935011624

Epoch: 6| Step: 8
Training loss: 0.7726875291130235
Validation loss: 2.547139775901901

Epoch: 6| Step: 9
Training loss: 0.704273134192169
Validation loss: 2.52425955571723

Epoch: 6| Step: 10
Training loss: 0.4696006209528991
Validation loss: 2.489886698185479

Epoch: 6| Step: 11
Training loss: 0.7244278096786816
Validation loss: 2.5206874627913627

Epoch: 6| Step: 12
Training loss: 0.693360127193419
Validation loss: 2.5174485485453695

Epoch: 6| Step: 13
Training loss: 0.6449642229877356
Validation loss: 2.476461621516956

Epoch: 277| Step: 0
Training loss: 0.5861370509806973
Validation loss: 2.5175721211175146

Epoch: 6| Step: 1
Training loss: 1.2177912535660464
Validation loss: 2.5512744514883807

Epoch: 6| Step: 2
Training loss: 0.5682978908146602
Validation loss: 2.5330948167939042

Epoch: 6| Step: 3
Training loss: 0.6728119637805664
Validation loss: 2.525827254412141

Epoch: 6| Step: 4
Training loss: 0.5070080180201901
Validation loss: 2.541701367197001

Epoch: 6| Step: 5
Training loss: 0.38036752877872476
Validation loss: 2.5115012252017515

Epoch: 6| Step: 6
Training loss: 0.6426985839359844
Validation loss: 2.545104624858527

Epoch: 6| Step: 7
Training loss: 0.7350388630823502
Validation loss: 2.500156279775748

Epoch: 6| Step: 8
Training loss: 0.669393703794203
Validation loss: 2.5108428363233517

Epoch: 6| Step: 9
Training loss: 0.6985190742867443
Validation loss: 2.5137887544717827

Epoch: 6| Step: 10
Training loss: 0.7695193604456073
Validation loss: 2.5246303772315692

Epoch: 6| Step: 11
Training loss: 0.5534675238040413
Validation loss: 2.475545860646206

Epoch: 6| Step: 12
Training loss: 0.909480552184397
Validation loss: 2.466614170674337

Epoch: 6| Step: 13
Training loss: 0.8572022106703762
Validation loss: 2.460753044824224

Epoch: 278| Step: 0
Training loss: 0.7056874735623332
Validation loss: 2.470832197923006

Epoch: 6| Step: 1
Training loss: 0.7774709089546582
Validation loss: 2.480801178381008

Epoch: 6| Step: 2
Training loss: 0.8778409138606835
Validation loss: 2.4747461151256016

Epoch: 6| Step: 3
Training loss: 0.575854508230997
Validation loss: 2.510383220400958

Epoch: 6| Step: 4
Training loss: 0.5449204530321389
Validation loss: 2.4757122778650875

Epoch: 6| Step: 5
Training loss: 1.111930804425602
Validation loss: 2.4612545061220974

Epoch: 6| Step: 6
Training loss: 0.8609438707285595
Validation loss: 2.498356970401095

Epoch: 6| Step: 7
Training loss: 0.41200287513979666
Validation loss: 2.472339853466505

Epoch: 6| Step: 8
Training loss: 0.7172418195644243
Validation loss: 2.4362090388790234

Epoch: 6| Step: 9
Training loss: 0.4507181602769866
Validation loss: 2.454957199306695

Epoch: 6| Step: 10
Training loss: 0.6279762927093802
Validation loss: 2.4623239211377927

Epoch: 6| Step: 11
Training loss: 0.6260798186124787
Validation loss: 2.4498883086932883

Epoch: 6| Step: 12
Training loss: 0.5842783006433592
Validation loss: 2.399083881899873

Epoch: 6| Step: 13
Training loss: 0.8122558226841929
Validation loss: 2.4526225361120777

Epoch: 279| Step: 0
Training loss: 0.38462699290327385
Validation loss: 2.4906852021647627

Epoch: 6| Step: 1
Training loss: 0.5582922275082124
Validation loss: 2.479187375798485

Epoch: 6| Step: 2
Training loss: 0.9952323030892972
Validation loss: 2.4981597131125337

Epoch: 6| Step: 3
Training loss: 0.5002690723735411
Validation loss: 2.5455357175627347

Epoch: 6| Step: 4
Training loss: 0.9903636599681935
Validation loss: 2.552020181188857

Epoch: 6| Step: 5
Training loss: 0.62090099390589
Validation loss: 2.5589428184252743

Epoch: 6| Step: 6
Training loss: 0.7500816141863288
Validation loss: 2.529403078553947

Epoch: 6| Step: 7
Training loss: 0.7379167656132872
Validation loss: 2.516978230131313

Epoch: 6| Step: 8
Training loss: 1.0199630232260746
Validation loss: 2.530844162269755

Epoch: 6| Step: 9
Training loss: 0.12012635948084707
Validation loss: 2.506864311038866

Epoch: 6| Step: 10
Training loss: 0.5561502270746184
Validation loss: 2.532811087453543

Epoch: 6| Step: 11
Training loss: 0.6048335527384782
Validation loss: 2.5206614894833574

Epoch: 6| Step: 12
Training loss: 0.8300617530554567
Validation loss: 2.524626546944213

Epoch: 6| Step: 13
Training loss: 0.4913936146383772
Validation loss: 2.5129976661188507

Epoch: 280| Step: 0
Training loss: 0.5542105114832389
Validation loss: 2.5238765739791815

Epoch: 6| Step: 1
Training loss: 0.5967727313880169
Validation loss: 2.537674611855569

Epoch: 6| Step: 2
Training loss: 0.5853760127096073
Validation loss: 2.5323134375686975

Epoch: 6| Step: 3
Training loss: 0.7602596686995606
Validation loss: 2.5446854044731992

Epoch: 6| Step: 4
Training loss: 0.8228741204252588
Validation loss: 2.546537788534801

Epoch: 6| Step: 5
Training loss: 0.5883866558910025
Validation loss: 2.5274810036085267

Epoch: 6| Step: 6
Training loss: 0.7605787304837562
Validation loss: 2.55978158723765

Epoch: 6| Step: 7
Training loss: 0.7191513848108478
Validation loss: 2.5599424503379637

Epoch: 6| Step: 8
Training loss: 0.3559810802985535
Validation loss: 2.497872412228488

Epoch: 6| Step: 9
Training loss: 0.6606430425859752
Validation loss: 2.518199026937799

Epoch: 6| Step: 10
Training loss: 0.8131442450225842
Validation loss: 2.5238683189235527

Epoch: 6| Step: 11
Training loss: 0.46624005997419626
Validation loss: 2.5373473497689827

Epoch: 6| Step: 12
Training loss: 0.8069937166420805
Validation loss: 2.52248075982896

Epoch: 6| Step: 13
Training loss: 1.139881571089299
Validation loss: 2.5372980951289503

Epoch: 281| Step: 0
Training loss: 0.3497044311529043
Validation loss: 2.5353998146552366

Epoch: 6| Step: 1
Training loss: 0.6172985508157567
Validation loss: 2.499378827561285

Epoch: 6| Step: 2
Training loss: 0.7144946303703079
Validation loss: 2.498147557092695

Epoch: 6| Step: 3
Training loss: 0.5868250927002078
Validation loss: 2.532169840822309

Epoch: 6| Step: 4
Training loss: 0.5892613548346822
Validation loss: 2.5087142854827733

Epoch: 6| Step: 5
Training loss: 0.6606008623778731
Validation loss: 2.489256767170031

Epoch: 6| Step: 6
Training loss: 0.9233382299157962
Validation loss: 2.487768372427168

Epoch: 6| Step: 7
Training loss: 0.6843458561374727
Validation loss: 2.5115067041264534

Epoch: 6| Step: 8
Training loss: 0.5355840212392814
Validation loss: 2.5421774149461087

Epoch: 6| Step: 9
Training loss: 0.9676375924086776
Validation loss: 2.5727197489453815

Epoch: 6| Step: 10
Training loss: 0.6522918497786077
Validation loss: 2.5093860174267277

Epoch: 6| Step: 11
Training loss: 0.7506218557426926
Validation loss: 2.527166355247955

Epoch: 6| Step: 12
Training loss: 0.8211649507236637
Validation loss: 2.5281002562507426

Epoch: 6| Step: 13
Training loss: 0.40460121752022593
Validation loss: 2.5318157789727

Epoch: 282| Step: 0
Training loss: 0.7761774563024748
Validation loss: 2.507249789147682

Epoch: 6| Step: 1
Training loss: 0.7253439744976358
Validation loss: 2.5082802279961944

Epoch: 6| Step: 2
Training loss: 0.9103634316064113
Validation loss: 2.507606863119685

Epoch: 6| Step: 3
Training loss: 0.3797678246323559
Validation loss: 2.4967981528557917

Epoch: 6| Step: 4
Training loss: 0.8562649718597606
Validation loss: 2.477268088331789

Epoch: 6| Step: 5
Training loss: 0.3902043557291041
Validation loss: 2.4957037732179552

Epoch: 6| Step: 6
Training loss: 0.6803078068022433
Validation loss: 2.4508922085783804

Epoch: 6| Step: 7
Training loss: 0.7026488069153235
Validation loss: 2.5032335371191556

Epoch: 6| Step: 8
Training loss: 0.48718696043658766
Validation loss: 2.539191844791432

Epoch: 6| Step: 9
Training loss: 0.6440886393818065
Validation loss: 2.569808435271668

Epoch: 6| Step: 10
Training loss: 0.6286668025461956
Validation loss: 2.555576868720377

Epoch: 6| Step: 11
Training loss: 0.7658278527407901
Validation loss: 2.550293664874296

Epoch: 6| Step: 12
Training loss: 0.5560305012305722
Validation loss: 2.5753137643847372

Epoch: 6| Step: 13
Training loss: 0.7982493498023276
Validation loss: 2.560555758705321

Epoch: 283| Step: 0
Training loss: 0.646435969174153
Validation loss: 2.5141218470633664

Epoch: 6| Step: 1
Training loss: 0.4298952814050411
Validation loss: 2.521628000744704

Epoch: 6| Step: 2
Training loss: 0.6958535907179889
Validation loss: 2.509752986367478

Epoch: 6| Step: 3
Training loss: 0.7483142345118112
Validation loss: 2.5205099586069912

Epoch: 6| Step: 4
Training loss: 0.6486460568650387
Validation loss: 2.4867458009597274

Epoch: 6| Step: 5
Training loss: 0.7243362282093738
Validation loss: 2.5226405045931277

Epoch: 6| Step: 6
Training loss: 0.6661594045497867
Validation loss: 2.4621627135421584

Epoch: 6| Step: 7
Training loss: 0.43128657600536696
Validation loss: 2.5221365747490365

Epoch: 6| Step: 8
Training loss: 0.9343468090895167
Validation loss: 2.500701539246786

Epoch: 6| Step: 9
Training loss: 0.6048454275578516
Validation loss: 2.5035206441490856

Epoch: 6| Step: 10
Training loss: 0.9221774752675366
Validation loss: 2.5110764672724595

Epoch: 6| Step: 11
Training loss: 0.5550052914496073
Validation loss: 2.515956399518137

Epoch: 6| Step: 12
Training loss: 0.6769581067605797
Validation loss: 2.496326403915992

Epoch: 6| Step: 13
Training loss: 0.26873070237272745
Validation loss: 2.517924307704407

Epoch: 284| Step: 0
Training loss: 0.25911152740414495
Validation loss: 2.4864895170708774

Epoch: 6| Step: 1
Training loss: 0.723210714893171
Validation loss: 2.5389544321542

Epoch: 6| Step: 2
Training loss: 0.90513252552509
Validation loss: 2.552369920629371

Epoch: 6| Step: 3
Training loss: 0.6370086945879081
Validation loss: 2.551662870673686

Epoch: 6| Step: 4
Training loss: 0.5881802171980431
Validation loss: 2.5655260349528737

Epoch: 6| Step: 5
Training loss: 0.7667725196270166
Validation loss: 2.5398437570252113

Epoch: 6| Step: 6
Training loss: 0.7531984791979881
Validation loss: 2.5864324643432393

Epoch: 6| Step: 7
Training loss: 0.7759271874358953
Validation loss: 2.5317294123688834

Epoch: 6| Step: 8
Training loss: 0.4575290902848042
Validation loss: 2.520817496171094

Epoch: 6| Step: 9
Training loss: 0.8966879686202943
Validation loss: 2.4918301779082266

Epoch: 6| Step: 10
Training loss: 0.5083299201579755
Validation loss: 2.504165470899076

Epoch: 6| Step: 11
Training loss: 0.5143553969030292
Validation loss: 2.484628658356272

Epoch: 6| Step: 12
Training loss: 0.663949485586596
Validation loss: 2.4881872264094866

Epoch: 6| Step: 13
Training loss: 0.6304419113553958
Validation loss: 2.5048710227557245

Epoch: 285| Step: 0
Training loss: 0.7274149334387557
Validation loss: 2.480056285792524

Epoch: 6| Step: 1
Training loss: 1.1557952914662057
Validation loss: 2.4880666641709044

Epoch: 6| Step: 2
Training loss: 0.6292979045648754
Validation loss: 2.476036328759469

Epoch: 6| Step: 3
Training loss: 0.39287132966757266
Validation loss: 2.5048335233342716

Epoch: 6| Step: 4
Training loss: 0.5252033452915995
Validation loss: 2.5509156456142423

Epoch: 6| Step: 5
Training loss: 0.7405160654812148
Validation loss: 2.551716099816689

Epoch: 6| Step: 6
Training loss: 0.6857126149727699
Validation loss: 2.5705735962023932

Epoch: 6| Step: 7
Training loss: 0.7547757367664115
Validation loss: 2.5617449608755263

Epoch: 6| Step: 8
Training loss: 0.6877777015587219
Validation loss: 2.570269711001109

Epoch: 6| Step: 9
Training loss: 0.6070300736777987
Validation loss: 2.557483856763211

Epoch: 6| Step: 10
Training loss: 0.5396807345798457
Validation loss: 2.6226060526044863

Epoch: 6| Step: 11
Training loss: 0.611368074421955
Validation loss: 2.590831593870271

Epoch: 6| Step: 12
Training loss: 0.7085387035047318
Validation loss: 2.5234064102607006

Epoch: 6| Step: 13
Training loss: 0.6646981058498624
Validation loss: 2.573395605316772

Epoch: 286| Step: 0
Training loss: 0.7926146745597277
Validation loss: 2.5756894422693244

Epoch: 6| Step: 1
Training loss: 0.7352118492384699
Validation loss: 2.551863857841289

Epoch: 6| Step: 2
Training loss: 0.6839131072521799
Validation loss: 2.545879674578714

Epoch: 6| Step: 3
Training loss: 0.5558349132181769
Validation loss: 2.5448993202140353

Epoch: 6| Step: 4
Training loss: 0.6506374681141107
Validation loss: 2.5589836849866576

Epoch: 6| Step: 5
Training loss: 0.4559277474221191
Validation loss: 2.5308368385676916

Epoch: 6| Step: 6
Training loss: 0.7170742236335839
Validation loss: 2.516829904066167

Epoch: 6| Step: 7
Training loss: 0.9719096616102076
Validation loss: 2.5251070990602607

Epoch: 6| Step: 8
Training loss: 0.6257860962183602
Validation loss: 2.5071144521496325

Epoch: 6| Step: 9
Training loss: 0.636877262534483
Validation loss: 2.573587978594888

Epoch: 6| Step: 10
Training loss: 0.7990584286320112
Validation loss: 2.579011722735798

Epoch: 6| Step: 11
Training loss: 0.7998310313002546
Validation loss: 2.5595089683692502

Epoch: 6| Step: 12
Training loss: 0.6352986606604798
Validation loss: 2.5335038685177365

Epoch: 6| Step: 13
Training loss: 0.6652616108881364
Validation loss: 2.5442281377208475

Epoch: 287| Step: 0
Training loss: 0.8467525464028925
Validation loss: 2.5006169624342047

Epoch: 6| Step: 1
Training loss: 0.7718980669906971
Validation loss: 2.4801917276291987

Epoch: 6| Step: 2
Training loss: 0.3817088508337337
Validation loss: 2.4453468334758965

Epoch: 6| Step: 3
Training loss: 0.31999787719216166
Validation loss: 2.393869485065577

Epoch: 6| Step: 4
Training loss: 0.7500085432837593
Validation loss: 2.427219187609124

Epoch: 6| Step: 5
Training loss: 0.4679614746343371
Validation loss: 2.4291365479256726

Epoch: 6| Step: 6
Training loss: 0.6507976964953757
Validation loss: 2.4086274535835783

Epoch: 6| Step: 7
Training loss: 0.7037893335791066
Validation loss: 2.458300288044151

Epoch: 6| Step: 8
Training loss: 0.43427981836374374
Validation loss: 2.4720618817908093

Epoch: 6| Step: 9
Training loss: 0.7200391652130913
Validation loss: 2.4898854997058772

Epoch: 6| Step: 10
Training loss: 0.978722495256495
Validation loss: 2.5597737534334555

Epoch: 6| Step: 11
Training loss: 0.8162291485283144
Validation loss: 2.5575885540638907

Epoch: 6| Step: 12
Training loss: 0.7772133492595076
Validation loss: 2.6049274181651234

Epoch: 6| Step: 13
Training loss: 0.7598007703953448
Validation loss: 2.6162125994199448

Epoch: 288| Step: 0
Training loss: 0.605721451723054
Validation loss: 2.64158882191266

Epoch: 6| Step: 1
Training loss: 0.7509492588908461
Validation loss: 2.6471859497000847

Epoch: 6| Step: 2
Training loss: 0.8916593869230015
Validation loss: 2.6199524620798407

Epoch: 6| Step: 3
Training loss: 0.6003049115441549
Validation loss: 2.571794831685604

Epoch: 6| Step: 4
Training loss: 0.6614856088576563
Validation loss: 2.5815056992383543

Epoch: 6| Step: 5
Training loss: 0.7104186795412187
Validation loss: 2.5260285323350953

Epoch: 6| Step: 6
Training loss: 0.7564591189581481
Validation loss: 2.515179207787775

Epoch: 6| Step: 7
Training loss: 1.0115239018337718
Validation loss: 2.5425501025584127

Epoch: 6| Step: 8
Training loss: 0.5850791747972257
Validation loss: 2.5748698089244084

Epoch: 6| Step: 9
Training loss: 0.363062638986554
Validation loss: 2.5246127702502137

Epoch: 6| Step: 10
Training loss: 0.39597829456520645
Validation loss: 2.502419798847018

Epoch: 6| Step: 11
Training loss: 0.478789846515037
Validation loss: 2.5152900914640863

Epoch: 6| Step: 12
Training loss: 0.7094339253827292
Validation loss: 2.5376865249909613

Epoch: 6| Step: 13
Training loss: 0.5350455844924746
Validation loss: 2.542821109249243

Epoch: 289| Step: 0
Training loss: 0.3633148834082089
Validation loss: 2.5092087538490233

Epoch: 6| Step: 1
Training loss: 0.7313771031436989
Validation loss: 2.5289890649498195

Epoch: 6| Step: 2
Training loss: 0.6507712730934362
Validation loss: 2.5716638584278604

Epoch: 6| Step: 3
Training loss: 0.6914201939787753
Validation loss: 2.511819687314927

Epoch: 6| Step: 4
Training loss: 0.856547402851117
Validation loss: 2.5017581602542953

Epoch: 6| Step: 5
Training loss: 0.8147528300486385
Validation loss: 2.4843596348771397

Epoch: 6| Step: 6
Training loss: 0.7740010221952642
Validation loss: 2.5321626930677863

Epoch: 6| Step: 7
Training loss: 0.615537514255315
Validation loss: 2.4941713713456117

Epoch: 6| Step: 8
Training loss: 0.4272285327027112
Validation loss: 2.5014518418837026

Epoch: 6| Step: 9
Training loss: 0.599284428822941
Validation loss: 2.4920549820691433

Epoch: 6| Step: 10
Training loss: 0.7578619321451188
Validation loss: 2.5034571698255736

Epoch: 6| Step: 11
Training loss: 0.5401025220894369
Validation loss: 2.504055104068809

Epoch: 6| Step: 12
Training loss: 0.5564907742289954
Validation loss: 2.5019030044870196

Epoch: 6| Step: 13
Training loss: 0.53068408556226
Validation loss: 2.4916156878270237

Epoch: 290| Step: 0
Training loss: 0.3300110336828869
Validation loss: 2.496273360080354

Epoch: 6| Step: 1
Training loss: 0.5241174409531856
Validation loss: 2.508907910615632

Epoch: 6| Step: 2
Training loss: 0.6838291743743421
Validation loss: 2.4836865987806296

Epoch: 6| Step: 3
Training loss: 0.461604508597728
Validation loss: 2.519261676611814

Epoch: 6| Step: 4
Training loss: 0.7630888916145908
Validation loss: 2.5016450063909974

Epoch: 6| Step: 5
Training loss: 0.7397563669227873
Validation loss: 2.5006121152685434

Epoch: 6| Step: 6
Training loss: 0.7610285444056866
Validation loss: 2.4882646767687393

Epoch: 6| Step: 7
Training loss: 0.6790710372142383
Validation loss: 2.4911593927035915

Epoch: 6| Step: 8
Training loss: 0.675110942059255
Validation loss: 2.4891754453323203

Epoch: 6| Step: 9
Training loss: 0.8585632652028824
Validation loss: 2.4516857369959038

Epoch: 6| Step: 10
Training loss: 0.5580034137641915
Validation loss: 2.447674261242456

Epoch: 6| Step: 11
Training loss: 0.6927474209266983
Validation loss: 2.4929497715096787

Epoch: 6| Step: 12
Training loss: 0.4573174420118783
Validation loss: 2.481710855576847

Epoch: 6| Step: 13
Training loss: 0.8014901721587403
Validation loss: 2.484292226372012

Epoch: 291| Step: 0
Training loss: 0.4465429306013572
Validation loss: 2.5109173498352053

Epoch: 6| Step: 1
Training loss: 0.8564070341805757
Validation loss: 2.4574721332879914

Epoch: 6| Step: 2
Training loss: 0.7043802289252499
Validation loss: 2.5049390539183976

Epoch: 6| Step: 3
Training loss: 0.6561263285772616
Validation loss: 2.5324177359533753

Epoch: 6| Step: 4
Training loss: 0.6601150319250294
Validation loss: 2.5039196737463056

Epoch: 6| Step: 5
Training loss: 0.7120491810111075
Validation loss: 2.512632246459786

Epoch: 6| Step: 6
Training loss: 0.6333902335539903
Validation loss: 2.5323172430683503

Epoch: 6| Step: 7
Training loss: 0.3969580916281897
Validation loss: 2.555493478064155

Epoch: 6| Step: 8
Training loss: 0.21058285888731143
Validation loss: 2.4760222754951093

Epoch: 6| Step: 9
Training loss: 0.776869471032377
Validation loss: 2.5019977432364344

Epoch: 6| Step: 10
Training loss: 0.7619799435121162
Validation loss: 2.4966516519118542

Epoch: 6| Step: 11
Training loss: 0.6835970197326936
Validation loss: 2.554718284324869

Epoch: 6| Step: 12
Training loss: 0.5601190403027667
Validation loss: 2.5199539388365575

Epoch: 6| Step: 13
Training loss: 0.5414920733356879
Validation loss: 2.5070050040725715

Epoch: 292| Step: 0
Training loss: 0.5242156038602062
Validation loss: 2.4986636609988864

Epoch: 6| Step: 1
Training loss: 0.6525155714888229
Validation loss: 2.4546534542924996

Epoch: 6| Step: 2
Training loss: 0.35242802781366245
Validation loss: 2.457501854985612

Epoch: 6| Step: 3
Training loss: 0.5437429931890727
Validation loss: 2.4653943819713513

Epoch: 6| Step: 4
Training loss: 0.7801346255544312
Validation loss: 2.4645240224906093

Epoch: 6| Step: 5
Training loss: 0.4787191152944142
Validation loss: 2.4686675122188855

Epoch: 6| Step: 6
Training loss: 0.8267220903731789
Validation loss: 2.4493655236861547

Epoch: 6| Step: 7
Training loss: 0.4089969053780923
Validation loss: 2.4871318409272183

Epoch: 6| Step: 8
Training loss: 0.9294731470038722
Validation loss: 2.527969688837725

Epoch: 6| Step: 9
Training loss: 0.3144360294789137
Validation loss: 2.5457326054620335

Epoch: 6| Step: 10
Training loss: 0.7641238072924399
Validation loss: 2.5380830466823294

Epoch: 6| Step: 11
Training loss: 0.40187337842409454
Validation loss: 2.587255138430945

Epoch: 6| Step: 12
Training loss: 0.6719388044357234
Validation loss: 2.586399692489152

Epoch: 6| Step: 13
Training loss: 0.873521134086468
Validation loss: 2.6003747246435474

Epoch: 293| Step: 0
Training loss: 0.6596225635367181
Validation loss: 2.5977633201065484

Epoch: 6| Step: 1
Training loss: 0.6459615154628019
Validation loss: 2.568925835767208

Epoch: 6| Step: 2
Training loss: 0.6467217415857719
Validation loss: 2.566785554751989

Epoch: 6| Step: 3
Training loss: 0.26343787370883776
Validation loss: 2.5374346961252265

Epoch: 6| Step: 4
Training loss: 0.7407694068192103
Validation loss: 2.5416106290673173

Epoch: 6| Step: 5
Training loss: 0.648975792329023
Validation loss: 2.499014149373646

Epoch: 6| Step: 6
Training loss: 0.6666683678803991
Validation loss: 2.5071274655514917

Epoch: 6| Step: 7
Training loss: 0.8477067361027397
Validation loss: 2.464677525704387

Epoch: 6| Step: 8
Training loss: 0.3183238120781362
Validation loss: 2.465060100528711

Epoch: 6| Step: 9
Training loss: 0.6783807404125706
Validation loss: 2.525400406929606

Epoch: 6| Step: 10
Training loss: 0.5402558979593339
Validation loss: 2.5621715878448112

Epoch: 6| Step: 11
Training loss: 0.7096800110596936
Validation loss: 2.552571681706483

Epoch: 6| Step: 12
Training loss: 0.5471303616096097
Validation loss: 2.5293643611891174

Epoch: 6| Step: 13
Training loss: 0.5835652713389112
Validation loss: 2.5218489846785377

Epoch: 294| Step: 0
Training loss: 0.6237966158080697
Validation loss: 2.515429581465958

Epoch: 6| Step: 1
Training loss: 0.6471899509797961
Validation loss: 2.539976024378879

Epoch: 6| Step: 2
Training loss: 0.667989451662029
Validation loss: 2.5367281927853322

Epoch: 6| Step: 3
Training loss: 0.5793279041460961
Validation loss: 2.52127811091545

Epoch: 6| Step: 4
Training loss: 0.6660972164886207
Validation loss: 2.4996143146103638

Epoch: 6| Step: 5
Training loss: 0.448480895730615
Validation loss: 2.540839585345359

Epoch: 6| Step: 6
Training loss: 0.30152204864850246
Validation loss: 2.512720482562362

Epoch: 6| Step: 7
Training loss: 0.686159213649748
Validation loss: 2.5398737643916176

Epoch: 6| Step: 8
Training loss: 0.5923544645837195
Validation loss: 2.546037867663255

Epoch: 6| Step: 9
Training loss: 0.5234827904536775
Validation loss: 2.4819943736761894

Epoch: 6| Step: 10
Training loss: 0.627627998838723
Validation loss: 2.53888122062913

Epoch: 6| Step: 11
Training loss: 0.8837981671449191
Validation loss: 2.521831518897457

Epoch: 6| Step: 12
Training loss: 0.43129115392058476
Validation loss: 2.506134058303271

Epoch: 6| Step: 13
Training loss: 0.8400833497815742
Validation loss: 2.5436684162744934

Epoch: 295| Step: 0
Training loss: 0.6094776702855536
Validation loss: 2.541600489919025

Epoch: 6| Step: 1
Training loss: 0.39719154920097194
Validation loss: 2.5172918554352064

Epoch: 6| Step: 2
Training loss: 0.7155081157930472
Validation loss: 2.5703162801593633

Epoch: 6| Step: 3
Training loss: 0.5646147711002324
Validation loss: 2.544515300099776

Epoch: 6| Step: 4
Training loss: 0.6548038625071935
Validation loss: 2.5465538798343834

Epoch: 6| Step: 5
Training loss: 0.42774771752297536
Validation loss: 2.555633393893519

Epoch: 6| Step: 6
Training loss: 0.606622519533033
Validation loss: 2.5408917346313182

Epoch: 6| Step: 7
Training loss: 0.6899329398918793
Validation loss: 2.575464749949894

Epoch: 6| Step: 8
Training loss: 0.1807312711507056
Validation loss: 2.5569417956548475

Epoch: 6| Step: 9
Training loss: 0.8696307225666216
Validation loss: 2.53068701913253

Epoch: 6| Step: 10
Training loss: 0.44727906785777943
Validation loss: 2.5532743974910184

Epoch: 6| Step: 11
Training loss: 0.5793273639951234
Validation loss: 2.534013944449621

Epoch: 6| Step: 12
Training loss: 0.905488088564199
Validation loss: 2.5704467102054305

Epoch: 6| Step: 13
Training loss: 0.5694034071869604
Validation loss: 2.5426393678712915

Epoch: 296| Step: 0
Training loss: 0.8585189023078129
Validation loss: 2.586617457254939

Epoch: 6| Step: 1
Training loss: 0.6705120145431044
Validation loss: 2.5292858512974887

Epoch: 6| Step: 2
Training loss: 0.6034279670140126
Validation loss: 2.508490151585695

Epoch: 6| Step: 3
Training loss: 0.46105026223601636
Validation loss: 2.5433802501003666

Epoch: 6| Step: 4
Training loss: 0.8434479490680918
Validation loss: 2.5312018977954556

Epoch: 6| Step: 5
Training loss: 0.6927739210317992
Validation loss: 2.5614334005613726

Epoch: 6| Step: 6
Training loss: 0.31814879491434817
Validation loss: 2.5150795729175925

Epoch: 6| Step: 7
Training loss: 0.44766410834054116
Validation loss: 2.527929615943229

Epoch: 6| Step: 8
Training loss: 0.6095792721447714
Validation loss: 2.4993848207841243

Epoch: 6| Step: 9
Training loss: 0.4969846280635485
Validation loss: 2.5513232936219743

Epoch: 6| Step: 10
Training loss: 0.7046419733739504
Validation loss: 2.50677959648664

Epoch: 6| Step: 11
Training loss: 0.32199975808797954
Validation loss: 2.4909807682717426

Epoch: 6| Step: 12
Training loss: 0.4134103930201784
Validation loss: 2.4931306600209897

Epoch: 6| Step: 13
Training loss: 0.9569585032938299
Validation loss: 2.534744372579883

Epoch: 297| Step: 0
Training loss: 0.8277565478334068
Validation loss: 2.5087478197394675

Epoch: 6| Step: 1
Training loss: 0.5055505111580076
Validation loss: 2.501729155969899

Epoch: 6| Step: 2
Training loss: 0.7595903444481007
Validation loss: 2.496539146634055

Epoch: 6| Step: 3
Training loss: 0.6291925951265518
Validation loss: 2.514578249212939

Epoch: 6| Step: 4
Training loss: 0.4554528425000454
Validation loss: 2.552598119720776

Epoch: 6| Step: 5
Training loss: 0.7159699703797396
Validation loss: 2.549483461722151

Epoch: 6| Step: 6
Training loss: 0.6750667079882327
Validation loss: 2.5385797957742025

Epoch: 6| Step: 7
Training loss: 0.5341395165996983
Validation loss: 2.549199916220473

Epoch: 6| Step: 8
Training loss: 0.4664363985525286
Validation loss: 2.577336996052154

Epoch: 6| Step: 9
Training loss: 0.6066513325863266
Validation loss: 2.537349134068547

Epoch: 6| Step: 10
Training loss: 0.5033240984654764
Validation loss: 2.552674477483777

Epoch: 6| Step: 11
Training loss: 0.42310396198503986
Validation loss: 2.542505379743111

Epoch: 6| Step: 12
Training loss: 0.7614249812248306
Validation loss: 2.5498288078136704

Epoch: 6| Step: 13
Training loss: 0.38796881726034305
Validation loss: 2.5215999875141955

Epoch: 298| Step: 0
Training loss: 0.7162816329281996
Validation loss: 2.5143905359253322

Epoch: 6| Step: 1
Training loss: 0.45956390804395164
Validation loss: 2.517899611182743

Epoch: 6| Step: 2
Training loss: 0.490396267729476
Validation loss: 2.5011768196423523

Epoch: 6| Step: 3
Training loss: 0.5327162703259857
Validation loss: 2.508511909052266

Epoch: 6| Step: 4
Training loss: 0.5814643505645708
Validation loss: 2.5089090417649786

Epoch: 6| Step: 5
Training loss: 0.5411265841289269
Validation loss: 2.4970500379484406

Epoch: 6| Step: 6
Training loss: 0.47844975855077054
Validation loss: 2.4959872168475763

Epoch: 6| Step: 7
Training loss: 0.42658476299834497
Validation loss: 2.4846160084521927

Epoch: 6| Step: 8
Training loss: 0.24496310737243748
Validation loss: 2.486928766366246

Epoch: 6| Step: 9
Training loss: 0.7569610689147759
Validation loss: 2.499858331255388

Epoch: 6| Step: 10
Training loss: 0.6274982827379658
Validation loss: 2.4878894045789184

Epoch: 6| Step: 11
Training loss: 0.686725179839601
Validation loss: 2.526807925622322

Epoch: 6| Step: 12
Training loss: 0.8414855168796761
Validation loss: 2.529090026614923

Epoch: 6| Step: 13
Training loss: 0.7452901936837815
Validation loss: 2.5417548463057282

Epoch: 299| Step: 0
Training loss: 0.7115286161709145
Validation loss: 2.543717054734376

Epoch: 6| Step: 1
Training loss: 0.6169364032119217
Validation loss: 2.5395498600939743

Epoch: 6| Step: 2
Training loss: 0.4909564016674798
Validation loss: 2.5872642148094904

Epoch: 6| Step: 3
Training loss: 0.7185797282337933
Validation loss: 2.5998316941478876

Epoch: 6| Step: 4
Training loss: 0.7385056573422533
Validation loss: 2.5906367144295124

Epoch: 6| Step: 5
Training loss: 0.38564737820727596
Validation loss: 2.524518754263581

Epoch: 6| Step: 6
Training loss: 0.5182351602434565
Validation loss: 2.5316946210638798

Epoch: 6| Step: 7
Training loss: 0.45013548149335764
Validation loss: 2.5309675680206065

Epoch: 6| Step: 8
Training loss: 0.43004028403300726
Validation loss: 2.4900733841988685

Epoch: 6| Step: 9
Training loss: 0.6206457093501324
Validation loss: 2.456860856497666

Epoch: 6| Step: 10
Training loss: 0.6320570215504381
Validation loss: 2.4399495507190307

Epoch: 6| Step: 11
Training loss: 0.8534338451462284
Validation loss: 2.487378842495119

Epoch: 6| Step: 12
Training loss: 0.4427914784461779
Validation loss: 2.4907165665320923

Epoch: 6| Step: 13
Training loss: 0.5097955278417449
Validation loss: 2.471990025938295

Epoch: 300| Step: 0
Training loss: 0.42863981660658135
Validation loss: 2.4767492297735454

Epoch: 6| Step: 1
Training loss: 0.5292270234246563
Validation loss: 2.502748429627399

Epoch: 6| Step: 2
Training loss: 0.645599520310681
Validation loss: 2.5577981573134676

Epoch: 6| Step: 3
Training loss: 0.5047561811358697
Validation loss: 2.5562926592660715

Epoch: 6| Step: 4
Training loss: 0.8324532311851494
Validation loss: 2.5742673116645327

Epoch: 6| Step: 5
Training loss: 0.7828788561688707
Validation loss: 2.572995276361012

Epoch: 6| Step: 6
Training loss: 0.4604613382437439
Validation loss: 2.6095073288882014

Epoch: 6| Step: 7
Training loss: 0.4020109930172291
Validation loss: 2.6100357434419124

Epoch: 6| Step: 8
Training loss: 0.24901906177939834
Validation loss: 2.5998137267319437

Epoch: 6| Step: 9
Training loss: 0.5580597572596769
Validation loss: 2.589657023739336

Epoch: 6| Step: 10
Training loss: 0.6350006138055193
Validation loss: 2.58040836430938

Epoch: 6| Step: 11
Training loss: 0.5261265022182068
Validation loss: 2.5273862615401965

Epoch: 6| Step: 12
Training loss: 0.7597918665259555
Validation loss: 2.5236662734282747

Epoch: 6| Step: 13
Training loss: 0.6593533887530625
Validation loss: 2.51821188583491

Epoch: 301| Step: 0
Training loss: 0.41820818736409626
Validation loss: 2.5049070560395363

Epoch: 6| Step: 1
Training loss: 0.5410123749232534
Validation loss: 2.4781926969195824

Epoch: 6| Step: 2
Training loss: 0.6957654870434545
Validation loss: 2.5040797610410066

Epoch: 6| Step: 3
Training loss: 0.861687686806427
Validation loss: 2.49176582474607

Epoch: 6| Step: 4
Training loss: 0.734204942208503
Validation loss: 2.5073146623022606

Epoch: 6| Step: 5
Training loss: 0.7142728600026582
Validation loss: 2.519259394098408

Epoch: 6| Step: 6
Training loss: 0.38943948138337053
Validation loss: 2.5407664271314867

Epoch: 6| Step: 7
Training loss: 0.2863717757567615
Validation loss: 2.5225802776807535

Epoch: 6| Step: 8
Training loss: 0.4158985170113681
Validation loss: 2.539068810492184

Epoch: 6| Step: 9
Training loss: 0.3052260944853313
Validation loss: 2.5735886375379966

Epoch: 6| Step: 10
Training loss: 0.5548142033248182
Validation loss: 2.513762115315353

Epoch: 6| Step: 11
Training loss: 0.4248503211054442
Validation loss: 2.5406395645550552

Epoch: 6| Step: 12
Training loss: 0.7963058832940246
Validation loss: 2.5412723014081418

Epoch: 6| Step: 13
Training loss: 0.7545731120169449
Validation loss: 2.507787145737486

Epoch: 302| Step: 0
Training loss: 0.6454258576738763
Validation loss: 2.482793181480312

Epoch: 6| Step: 1
Training loss: 0.541207234849382
Validation loss: 2.5024565491977246

Epoch: 6| Step: 2
Training loss: 0.40037519843924013
Validation loss: 2.4590644444483996

Epoch: 6| Step: 3
Training loss: 0.6487387451489216
Validation loss: 2.503131519240671

Epoch: 6| Step: 4
Training loss: 0.6487607494926345
Validation loss: 2.4723661778402497

Epoch: 6| Step: 5
Training loss: 0.5013295021650515
Validation loss: 2.5200530396869856

Epoch: 6| Step: 6
Training loss: 0.612554982695329
Validation loss: 2.516071147281786

Epoch: 6| Step: 7
Training loss: 0.817874118173046
Validation loss: 2.4772139311298007

Epoch: 6| Step: 8
Training loss: 0.571453572901378
Validation loss: 2.5086464062625877

Epoch: 6| Step: 9
Training loss: 0.35652339550363715
Validation loss: 2.515926236298688

Epoch: 6| Step: 10
Training loss: 0.7070085300567657
Validation loss: 2.5227458928948985

Epoch: 6| Step: 11
Training loss: 0.46560710450160364
Validation loss: 2.5104063063884174

Epoch: 6| Step: 12
Training loss: 0.5190218385574311
Validation loss: 2.5253689190511857

Epoch: 6| Step: 13
Training loss: 0.4246042940876309
Validation loss: 2.520522578899667

Epoch: 303| Step: 0
Training loss: 0.5008050279134875
Validation loss: 2.5514228399725507

Epoch: 6| Step: 1
Training loss: 0.47017129951952213
Validation loss: 2.5719384588260583

Epoch: 6| Step: 2
Training loss: 0.5835213244741171
Validation loss: 2.5690689577119987

Epoch: 6| Step: 3
Training loss: 0.7432369642554826
Validation loss: 2.5479158556656354

Epoch: 6| Step: 4
Training loss: 0.5169794038547472
Validation loss: 2.5518066946091955

Epoch: 6| Step: 5
Training loss: 0.774553938135694
Validation loss: 2.5334122614986674

Epoch: 6| Step: 6
Training loss: 0.4408013748340057
Validation loss: 2.551349638061871

Epoch: 6| Step: 7
Training loss: 0.4223667034385384
Validation loss: 2.5498322943452796

Epoch: 6| Step: 8
Training loss: 0.8269712219997054
Validation loss: 2.53326410123149

Epoch: 6| Step: 9
Training loss: 0.6823731997358393
Validation loss: 2.538442171737971

Epoch: 6| Step: 10
Training loss: 0.37196072143412523
Validation loss: 2.542973991761522

Epoch: 6| Step: 11
Training loss: 0.6562810845052208
Validation loss: 2.545996995697596

Epoch: 6| Step: 12
Training loss: 0.5607998904969548
Validation loss: 2.538958090882782

Epoch: 6| Step: 13
Training loss: 0.2657570931222789
Validation loss: 2.552809792733397

Epoch: 304| Step: 0
Training loss: 0.6402606625888639
Validation loss: 2.536031652054155

Epoch: 6| Step: 1
Training loss: 0.4356550586953131
Validation loss: 2.549064356040095

Epoch: 6| Step: 2
Training loss: 0.35704698340142327
Validation loss: 2.5356011703629897

Epoch: 6| Step: 3
Training loss: 0.7290437640199763
Validation loss: 2.529978404505995

Epoch: 6| Step: 4
Training loss: 0.5525810379475773
Validation loss: 2.5150470899113273

Epoch: 6| Step: 5
Training loss: 0.6096559023820196
Validation loss: 2.4946711783418496

Epoch: 6| Step: 6
Training loss: 0.6660677981706883
Validation loss: 2.523877770538468

Epoch: 6| Step: 7
Training loss: 0.47273997676558327
Validation loss: 2.51585435137083

Epoch: 6| Step: 8
Training loss: 0.1885307510827164
Validation loss: 2.495075213227735

Epoch: 6| Step: 9
Training loss: 0.6477161439596676
Validation loss: 2.4635996191357585

Epoch: 6| Step: 10
Training loss: 0.8667473922021287
Validation loss: 2.5434131937414386

Epoch: 6| Step: 11
Training loss: 0.5594977952659742
Validation loss: 2.5216683618600984

Epoch: 6| Step: 12
Training loss: 0.4392639770346636
Validation loss: 2.5200391535542193

Epoch: 6| Step: 13
Training loss: 0.5671744300450334
Validation loss: 2.5218598985700806

Epoch: 305| Step: 0
Training loss: 0.39738321130121895
Validation loss: 2.5592115117192615

Epoch: 6| Step: 1
Training loss: 0.5416953433833287
Validation loss: 2.5302505667221844

Epoch: 6| Step: 2
Training loss: 0.6694919329820325
Validation loss: 2.5220715990007334

Epoch: 6| Step: 3
Training loss: 0.5952700181756841
Validation loss: 2.5023392121352157

Epoch: 6| Step: 4
Training loss: 0.5508205318646623
Validation loss: 2.540037134751902

Epoch: 6| Step: 5
Training loss: 0.626606045967263
Validation loss: 2.5581460024460263

Epoch: 6| Step: 6
Training loss: 0.2439513350049523
Validation loss: 2.562164705891996

Epoch: 6| Step: 7
Training loss: 0.557648826543298
Validation loss: 2.5329109676359933

Epoch: 6| Step: 8
Training loss: 0.6247067478758321
Validation loss: 2.5161653719303234

Epoch: 6| Step: 9
Training loss: 0.6712130457191147
Validation loss: 2.528820238439295

Epoch: 6| Step: 10
Training loss: 0.4235795342379259
Validation loss: 2.5745874959578527

Epoch: 6| Step: 11
Training loss: 0.8537861201184173
Validation loss: 2.5607725474050915

Epoch: 6| Step: 12
Training loss: 0.38715030211306695
Validation loss: 2.5730208210221126

Epoch: 6| Step: 13
Training loss: 0.6847091512247071
Validation loss: 2.5515853372519195

Epoch: 306| Step: 0
Training loss: 0.497119758709736
Validation loss: 2.5639506090106625

Epoch: 6| Step: 1
Training loss: 0.5076452419957883
Validation loss: 2.5114545260065992

Epoch: 6| Step: 2
Training loss: 0.7065705964250079
Validation loss: 2.5312269638433236

Epoch: 6| Step: 3
Training loss: 0.50536528505682
Validation loss: 2.5360140746955224

Epoch: 6| Step: 4
Training loss: 0.4977648516239824
Validation loss: 2.537158492852875

Epoch: 6| Step: 5
Training loss: 0.8802768108810273
Validation loss: 2.525002055013497

Epoch: 6| Step: 6
Training loss: 0.6502674432898624
Validation loss: 2.5350540605452707

Epoch: 6| Step: 7
Training loss: 0.593842223182871
Validation loss: 2.532185440270894

Epoch: 6| Step: 8
Training loss: 0.7672847352106241
Validation loss: 2.5869475165765152

Epoch: 6| Step: 9
Training loss: 0.5661809802148968
Validation loss: 2.5454733699941987

Epoch: 6| Step: 10
Training loss: 0.16512333676412344
Validation loss: 2.557838642258059

Epoch: 6| Step: 11
Training loss: 0.46826136870465607
Validation loss: 2.5993154460717167

Epoch: 6| Step: 12
Training loss: 0.25621630982159266
Validation loss: 2.58728872533139

Epoch: 6| Step: 13
Training loss: 0.4662632625575337
Validation loss: 2.5783716242301082

Epoch: 307| Step: 0
Training loss: 0.6194469283880468
Validation loss: 2.562497819028697

Epoch: 6| Step: 1
Training loss: 0.5462193236914072
Validation loss: 2.569996975733808

Epoch: 6| Step: 2
Training loss: 0.6694675829249136
Validation loss: 2.568846231643129

Epoch: 6| Step: 3
Training loss: 0.44418615814023477
Validation loss: 2.6014309111109544

Epoch: 6| Step: 4
Training loss: 0.34713679521100455
Validation loss: 2.5819294035856575

Epoch: 6| Step: 5
Training loss: 0.6750805038553269
Validation loss: 2.584228443082567

Epoch: 6| Step: 6
Training loss: 0.5091573659835101
Validation loss: 2.5806560096012796

Epoch: 6| Step: 7
Training loss: 0.5900364744097442
Validation loss: 2.5677230492748224

Epoch: 6| Step: 8
Training loss: 0.4985415526455171
Validation loss: 2.540208242434225

Epoch: 6| Step: 9
Training loss: 0.7422480909811867
Validation loss: 2.5491360013982325

Epoch: 6| Step: 10
Training loss: 0.6439454161690469
Validation loss: 2.5530192792106905

Epoch: 6| Step: 11
Training loss: 0.3562398658114107
Validation loss: 2.5405761442615686

Epoch: 6| Step: 12
Training loss: 0.34543604690373125
Validation loss: 2.5370980598741584

Epoch: 6| Step: 13
Training loss: 0.6479163086042815
Validation loss: 2.5407834307910777

Epoch: 308| Step: 0
Training loss: 0.3980214995287375
Validation loss: 2.536962484614948

Epoch: 6| Step: 1
Training loss: 0.6888169333306019
Validation loss: 2.544089026563714

Epoch: 6| Step: 2
Training loss: 0.5459344677985566
Validation loss: 2.5163845219341847

Epoch: 6| Step: 3
Training loss: 0.6593912420939078
Validation loss: 2.5583338381517025

Epoch: 6| Step: 4
Training loss: 0.6446338918626323
Validation loss: 2.5475295772214372

Epoch: 6| Step: 5
Training loss: 0.5852329850654561
Validation loss: 2.5565025302133844

Epoch: 6| Step: 6
Training loss: 0.6654481679792708
Validation loss: 2.583148976183978

Epoch: 6| Step: 7
Training loss: 0.24404303316784848
Validation loss: 2.59433723875927

Epoch: 6| Step: 8
Training loss: 0.5918248991421222
Validation loss: 2.568828959656549

Epoch: 6| Step: 9
Training loss: 0.6813031429596219
Validation loss: 2.561160287869923

Epoch: 6| Step: 10
Training loss: 0.5003473446284272
Validation loss: 2.5777559386023547

Epoch: 6| Step: 11
Training loss: 0.47661236986723116
Validation loss: 2.5519208259065684

Epoch: 6| Step: 12
Training loss: 0.3496259440326459
Validation loss: 2.558290212474317

Epoch: 6| Step: 13
Training loss: 0.6871808785279558
Validation loss: 2.5364507765306903

Epoch: 309| Step: 0
Training loss: 0.4867345804300561
Validation loss: 2.5353719657227898

Epoch: 6| Step: 1
Training loss: 0.5832497559574302
Validation loss: 2.5407461334800723

Epoch: 6| Step: 2
Training loss: 0.6577179476091967
Validation loss: 2.517698969438291

Epoch: 6| Step: 3
Training loss: 0.2868793630164309
Validation loss: 2.539268512808457

Epoch: 6| Step: 4
Training loss: 0.41046165721560623
Validation loss: 2.544765512278476

Epoch: 6| Step: 5
Training loss: 0.5591175850969912
Validation loss: 2.53633737327255

Epoch: 6| Step: 6
Training loss: 0.37496503031122624
Validation loss: 2.5342739611442573

Epoch: 6| Step: 7
Training loss: 0.6791384880289448
Validation loss: 2.5799633135742566

Epoch: 6| Step: 8
Training loss: 0.5210658190332005
Validation loss: 2.5211783199919524

Epoch: 6| Step: 9
Training loss: 0.5285561364909369
Validation loss: 2.5516088853767895

Epoch: 6| Step: 10
Training loss: 0.5050338135625851
Validation loss: 2.569688771375289

Epoch: 6| Step: 11
Training loss: 0.46693057775032004
Validation loss: 2.558271186195091

Epoch: 6| Step: 12
Training loss: 0.6795397411525534
Validation loss: 2.553361544393649

Epoch: 6| Step: 13
Training loss: 0.8101972446351481
Validation loss: 2.5483304496652837

Epoch: 310| Step: 0
Training loss: 0.33868657336519215
Validation loss: 2.5366444775978865

Epoch: 6| Step: 1
Training loss: 0.4076956738745146
Validation loss: 2.5896300572592708

Epoch: 6| Step: 2
Training loss: 0.49166418441318277
Validation loss: 2.5517646140169337

Epoch: 6| Step: 3
Training loss: 0.5296679670395122
Validation loss: 2.5568909653303638

Epoch: 6| Step: 4
Training loss: 0.3847557298966067
Validation loss: 2.556285987133542

Epoch: 6| Step: 5
Training loss: 0.758421427112803
Validation loss: 2.58868444915583

Epoch: 6| Step: 6
Training loss: 0.41052133569668114
Validation loss: 2.5606460918133416

Epoch: 6| Step: 7
Training loss: 0.6687276889965299
Validation loss: 2.5765543897065797

Epoch: 6| Step: 8
Training loss: 0.3054516331396562
Validation loss: 2.532077752711159

Epoch: 6| Step: 9
Training loss: 0.8231873771187185
Validation loss: 2.548652286991763

Epoch: 6| Step: 10
Training loss: 0.5358418437683367
Validation loss: 2.5265815015099085

Epoch: 6| Step: 11
Training loss: 0.582150594265379
Validation loss: 2.5142167636976778

Epoch: 6| Step: 12
Training loss: 0.6533094556331182
Validation loss: 2.5300028280867943

Epoch: 6| Step: 13
Training loss: 0.5340045593063509
Validation loss: 2.537253462116494

Epoch: 311| Step: 0
Training loss: 0.3638255236243723
Validation loss: 2.544981231713729

Epoch: 6| Step: 1
Training loss: 0.7953068881033588
Validation loss: 2.582656514333711

Epoch: 6| Step: 2
Training loss: 0.5448764795789519
Validation loss: 2.527980703068002

Epoch: 6| Step: 3
Training loss: 0.7269709679711135
Validation loss: 2.5773184918448973

Epoch: 6| Step: 4
Training loss: 0.4531789615990996
Validation loss: 2.5831528368032117

Epoch: 6| Step: 5
Training loss: 0.3657058080400807
Validation loss: 2.5626082678852247

Epoch: 6| Step: 6
Training loss: 0.45592018120694644
Validation loss: 2.5374483031826047

Epoch: 6| Step: 7
Training loss: 0.5284019872461991
Validation loss: 2.5475794400970133

Epoch: 6| Step: 8
Training loss: 0.609685696355282
Validation loss: 2.5193885507799543

Epoch: 6| Step: 9
Training loss: 0.3590068797631778
Validation loss: 2.5290282736157863

Epoch: 6| Step: 10
Training loss: 0.4258909521605829
Validation loss: 2.529962185488684

Epoch: 6| Step: 11
Training loss: 0.5841441366537307
Validation loss: 2.502080886062428

Epoch: 6| Step: 12
Training loss: 0.6350746458964642
Validation loss: 2.5098838211725885

Epoch: 6| Step: 13
Training loss: 0.5798804720262505
Validation loss: 2.5168954113579716

Epoch: 312| Step: 0
Training loss: 0.37754413741441084
Validation loss: 2.5184118688141655

Epoch: 6| Step: 1
Training loss: 0.7274790899149114
Validation loss: 2.526532962384996

Epoch: 6| Step: 2
Training loss: 0.4216069676930956
Validation loss: 2.506294568786411

Epoch: 6| Step: 3
Training loss: 0.14732393633165414
Validation loss: 2.5389033038114426

Epoch: 6| Step: 4
Training loss: 0.52224738489339
Validation loss: 2.5374869679228937

Epoch: 6| Step: 5
Training loss: 0.7188537771521221
Validation loss: 2.505413878865098

Epoch: 6| Step: 6
Training loss: 0.4659861623271007
Validation loss: 2.5285698619994665

Epoch: 6| Step: 7
Training loss: 0.7831593641579432
Validation loss: 2.56637888437554

Epoch: 6| Step: 8
Training loss: 0.6395003984672254
Validation loss: 2.5340130319036285

Epoch: 6| Step: 9
Training loss: 0.384309682491122
Validation loss: 2.5652548015800223

Epoch: 6| Step: 10
Training loss: 0.4879230864135351
Validation loss: 2.522146698629614

Epoch: 6| Step: 11
Training loss: 0.4823079148336957
Validation loss: 2.529620087028938

Epoch: 6| Step: 12
Training loss: 0.5759401534335548
Validation loss: 2.520682648118168

Epoch: 6| Step: 13
Training loss: 0.4352968293632977
Validation loss: 2.5240550835872075

Epoch: 313| Step: 0
Training loss: 0.593429177593995
Validation loss: 2.5177002055904305

Epoch: 6| Step: 1
Training loss: 0.3398804261159207
Validation loss: 2.5552439398961604

Epoch: 6| Step: 2
Training loss: 0.556179886588892
Validation loss: 2.5333889161226057

Epoch: 6| Step: 3
Training loss: 0.3453752503837702
Validation loss: 2.5503377228729525

Epoch: 6| Step: 4
Training loss: 0.6494437763041894
Validation loss: 2.528483410377894

Epoch: 6| Step: 5
Training loss: 0.3479718051360039
Validation loss: 2.4680263081111034

Epoch: 6| Step: 6
Training loss: 0.3865121424385051
Validation loss: 2.487655314939745

Epoch: 6| Step: 7
Training loss: 0.6050027838556225
Validation loss: 2.4851714591337797

Epoch: 6| Step: 8
Training loss: 0.7004018396521154
Validation loss: 2.4614723198676938

Epoch: 6| Step: 9
Training loss: 0.5597176083336993
Validation loss: 2.481334736843933

Epoch: 6| Step: 10
Training loss: 0.4655391076251861
Validation loss: 2.498413907689217

Epoch: 6| Step: 11
Training loss: 0.5220317468124167
Validation loss: 2.486932515034994

Epoch: 6| Step: 12
Training loss: 0.4501580411166328
Validation loss: 2.495400196412756

Epoch: 6| Step: 13
Training loss: 0.793555507711127
Validation loss: 2.5233996064718176

Epoch: 314| Step: 0
Training loss: 0.6400904867905433
Validation loss: 2.517090385079446

Epoch: 6| Step: 1
Training loss: 0.44650056530958315
Validation loss: 2.516758657144783

Epoch: 6| Step: 2
Training loss: 0.5727889756753463
Validation loss: 2.4863627350112854

Epoch: 6| Step: 3
Training loss: 0.32737144726314443
Validation loss: 2.4874885846978465

Epoch: 6| Step: 4
Training loss: 0.6598678500638459
Validation loss: 2.4873245261463928

Epoch: 6| Step: 5
Training loss: 0.7251626752993274
Validation loss: 2.5191633424722086

Epoch: 6| Step: 6
Training loss: 0.48986629330781434
Validation loss: 2.5053885213054357

Epoch: 6| Step: 7
Training loss: 0.44003525218846257
Validation loss: 2.50852001791301

Epoch: 6| Step: 8
Training loss: 0.24779454861354755
Validation loss: 2.4792722819302

Epoch: 6| Step: 9
Training loss: 0.7078071257195642
Validation loss: 2.527439023138782

Epoch: 6| Step: 10
Training loss: 0.38991436213702135
Validation loss: 2.52443111334025

Epoch: 6| Step: 11
Training loss: 0.5559546543796212
Validation loss: 2.530079660056092

Epoch: 6| Step: 12
Training loss: 0.5609414443193497
Validation loss: 2.5668262165480895

Epoch: 6| Step: 13
Training loss: 0.4459091673139426
Validation loss: 2.531132009519411

Epoch: 315| Step: 0
Training loss: 0.676534023963083
Validation loss: 2.538065259293597

Epoch: 6| Step: 1
Training loss: 0.4648144496370569
Validation loss: 2.5227410049180965

Epoch: 6| Step: 2
Training loss: 0.6585943491289303
Validation loss: 2.5285194523971626

Epoch: 6| Step: 3
Training loss: 0.4072793610739094
Validation loss: 2.570231451646861

Epoch: 6| Step: 4
Training loss: 0.5192925614759919
Validation loss: 2.574030670157373

Epoch: 6| Step: 5
Training loss: 0.7341365833014926
Validation loss: 2.566545930010206

Epoch: 6| Step: 6
Training loss: 0.4523027786911721
Validation loss: 2.5362150718214793

Epoch: 6| Step: 7
Training loss: 0.3305079578921881
Validation loss: 2.5698350396268617

Epoch: 6| Step: 8
Training loss: 0.441178575386842
Validation loss: 2.5984162670713338

Epoch: 6| Step: 9
Training loss: 0.5335268428291794
Validation loss: 2.594517280151769

Epoch: 6| Step: 10
Training loss: 0.5839643698235267
Validation loss: 2.6072702145350393

Epoch: 6| Step: 11
Training loss: 0.24593782783593088
Validation loss: 2.582903363438942

Epoch: 6| Step: 12
Training loss: 0.718663666557297
Validation loss: 2.583520799782141

Epoch: 6| Step: 13
Training loss: 0.14461594110726328
Validation loss: 2.608953089994657

Epoch: 316| Step: 0
Training loss: 0.5277900502663067
Validation loss: 2.5751845639227664

Epoch: 6| Step: 1
Training loss: 0.77889794103233
Validation loss: 2.595150882212624

Epoch: 6| Step: 2
Training loss: 0.7809788042481924
Validation loss: 2.5425835863034836

Epoch: 6| Step: 3
Training loss: 0.5250421666060022
Validation loss: 2.5758477563238227

Epoch: 6| Step: 4
Training loss: 0.4721932468531645
Validation loss: 2.5810781102889266

Epoch: 6| Step: 5
Training loss: 0.4874965618696996
Validation loss: 2.5849905007195106

Epoch: 6| Step: 6
Training loss: 0.39702100095765214
Validation loss: 2.62716681084048

Epoch: 6| Step: 7
Training loss: 0.4724331636690324
Validation loss: 2.6351490059116873

Epoch: 6| Step: 8
Training loss: 0.3274471456523588
Validation loss: 2.634222528990405

Epoch: 6| Step: 9
Training loss: 0.3960789641981983
Validation loss: 2.603537603058022

Epoch: 6| Step: 10
Training loss: 0.6933707007974081
Validation loss: 2.621564937042876

Epoch: 6| Step: 11
Training loss: 0.28829902914577116
Validation loss: 2.6095027031442926

Epoch: 6| Step: 12
Training loss: 0.4427523385411026
Validation loss: 2.5815561799598616

Epoch: 6| Step: 13
Training loss: 0.3832608925054715
Validation loss: 2.6101119982968415

Epoch: 317| Step: 0
Training loss: 0.4805099345598313
Validation loss: 2.5839637406605123

Epoch: 6| Step: 1
Training loss: 0.48744496254919634
Validation loss: 2.5747450374081593

Epoch: 6| Step: 2
Training loss: 0.4323475085427019
Validation loss: 2.5814609119531644

Epoch: 6| Step: 3
Training loss: 0.6442679821209328
Validation loss: 2.541723895895377

Epoch: 6| Step: 4
Training loss: 0.4097452011327787
Validation loss: 2.54799786538258

Epoch: 6| Step: 5
Training loss: 0.5470462803327077
Validation loss: 2.5788617654644415

Epoch: 6| Step: 6
Training loss: 0.68130642368542
Validation loss: 2.537598097229695

Epoch: 6| Step: 7
Training loss: 0.3654338271672677
Validation loss: 2.53543871285904

Epoch: 6| Step: 8
Training loss: 0.4591851951693927
Validation loss: 2.5522402512754594

Epoch: 6| Step: 9
Training loss: 0.54227414057291
Validation loss: 2.537928442734247

Epoch: 6| Step: 10
Training loss: 0.4847005088777116
Validation loss: 2.554401166030616

Epoch: 6| Step: 11
Training loss: 0.4543100514227208
Validation loss: 2.578948985130534

Epoch: 6| Step: 12
Training loss: 0.6318782456160897
Validation loss: 2.5511216589125656

Epoch: 6| Step: 13
Training loss: 0.1574719332861349
Validation loss: 2.5772929639175906

Epoch: 318| Step: 0
Training loss: 0.6121533463878687
Validation loss: 2.5944382960988124

Epoch: 6| Step: 1
Training loss: 0.4178709468319771
Validation loss: 2.569394755157846

Epoch: 6| Step: 2
Training loss: 0.44634159705477366
Validation loss: 2.6253728157466902

Epoch: 6| Step: 3
Training loss: 0.4384008227482875
Validation loss: 2.599884458724404

Epoch: 6| Step: 4
Training loss: 0.5748218820263943
Validation loss: 2.5579435956386307

Epoch: 6| Step: 5
Training loss: 0.7013117403672716
Validation loss: 2.5491758525594532

Epoch: 6| Step: 6
Training loss: 0.457647234540386
Validation loss: 2.62509875250962

Epoch: 6| Step: 7
Training loss: 0.46472392421107234
Validation loss: 2.562540487694397

Epoch: 6| Step: 8
Training loss: 0.41068081689789204
Validation loss: 2.580660736225412

Epoch: 6| Step: 9
Training loss: 0.6761753057947065
Validation loss: 2.5716429283456415

Epoch: 6| Step: 10
Training loss: 0.39572811819755843
Validation loss: 2.577724315522731

Epoch: 6| Step: 11
Training loss: 0.4169623835541569
Validation loss: 2.537055325064415

Epoch: 6| Step: 12
Training loss: 0.5398801600851532
Validation loss: 2.561051863675649

Epoch: 6| Step: 13
Training loss: 0.3957145998045101
Validation loss: 2.577841861574002

Epoch: 319| Step: 0
Training loss: 0.5693096331479068
Validation loss: 2.6182010153222364

Epoch: 6| Step: 1
Training loss: 0.41740561366334394
Validation loss: 2.5845508947934883

Epoch: 6| Step: 2
Training loss: 0.45453890178031947
Validation loss: 2.5991191575460832

Epoch: 6| Step: 3
Training loss: 0.7169047178379516
Validation loss: 2.605531544678989

Epoch: 6| Step: 4
Training loss: 0.5078595653144281
Validation loss: 2.608034880942064

Epoch: 6| Step: 5
Training loss: 0.4253032871400498
Validation loss: 2.5544238155604275

Epoch: 6| Step: 6
Training loss: 0.518517444372326
Validation loss: 2.584210189109609

Epoch: 6| Step: 7
Training loss: 0.39325784321825075
Validation loss: 2.5818594268380717

Epoch: 6| Step: 8
Training loss: 0.383137817728469
Validation loss: 2.546735620701743

Epoch: 6| Step: 9
Training loss: 0.7243355287555767
Validation loss: 2.5217245410173623

Epoch: 6| Step: 10
Training loss: 0.2704226776453217
Validation loss: 2.549268441299243

Epoch: 6| Step: 11
Training loss: 0.4490536095967582
Validation loss: 2.5271014707810013

Epoch: 6| Step: 12
Training loss: 0.5114232731732705
Validation loss: 2.524961773584946

Epoch: 6| Step: 13
Training loss: 0.6290717292256429
Validation loss: 2.5395066072782697

Epoch: 320| Step: 0
Training loss: 0.4769783706919431
Validation loss: 2.580022024092615

Epoch: 6| Step: 1
Training loss: 0.5986871492452736
Validation loss: 2.561518100086509

Epoch: 6| Step: 2
Training loss: 0.4693688598972811
Validation loss: 2.5456748594331273

Epoch: 6| Step: 3
Training loss: 0.4903965108170928
Validation loss: 2.5136706644035822

Epoch: 6| Step: 4
Training loss: 0.5282179756260431
Validation loss: 2.5563036728097313

Epoch: 6| Step: 5
Training loss: 0.10908152171180723
Validation loss: 2.536017092211403

Epoch: 6| Step: 6
Training loss: 0.6837758720845114
Validation loss: 2.561506138655281

Epoch: 6| Step: 7
Training loss: 0.5250165664238904
Validation loss: 2.6015681553389034

Epoch: 6| Step: 8
Training loss: 0.5752982806800866
Validation loss: 2.6162905595253725

Epoch: 6| Step: 9
Training loss: 0.21820965515046187
Validation loss: 2.586042537798324

Epoch: 6| Step: 10
Training loss: 0.2253663121007197
Validation loss: 2.6238622822116238

Epoch: 6| Step: 11
Training loss: 0.6328249800593491
Validation loss: 2.6096525879098404

Epoch: 6| Step: 12
Training loss: 0.5679955383028163
Validation loss: 2.621005179403667

Epoch: 6| Step: 13
Training loss: 0.4277421959288289
Validation loss: 2.5918462304582475

Epoch: 321| Step: 0
Training loss: 0.3160959299703448
Validation loss: 2.5400167459506435

Epoch: 6| Step: 1
Training loss: 0.1627890345527679
Validation loss: 2.546725799923308

Epoch: 6| Step: 2
Training loss: 0.49557236434042445
Validation loss: 2.545032383510683

Epoch: 6| Step: 3
Training loss: 0.4566608460373276
Validation loss: 2.517909365197402

Epoch: 6| Step: 4
Training loss: 0.6064340341597317
Validation loss: 2.5292861016524277

Epoch: 6| Step: 5
Training loss: 0.6273538610040242
Validation loss: 2.5062891945648382

Epoch: 6| Step: 6
Training loss: 0.4676288867188312
Validation loss: 2.5031997784406945

Epoch: 6| Step: 7
Training loss: 0.5790490163601227
Validation loss: 2.5292712394456354

Epoch: 6| Step: 8
Training loss: 0.506312399421195
Validation loss: 2.532814599688183

Epoch: 6| Step: 9
Training loss: 0.6193359740710481
Validation loss: 2.5030519765764914

Epoch: 6| Step: 10
Training loss: 0.5597741253480956
Validation loss: 2.53534086458916

Epoch: 6| Step: 11
Training loss: 0.5471431074974259
Validation loss: 2.5283399489643776

Epoch: 6| Step: 12
Training loss: 0.35478624910185774
Validation loss: 2.5753681377277755

Epoch: 6| Step: 13
Training loss: 0.4574434101042441
Validation loss: 2.593374367200624

Epoch: 322| Step: 0
Training loss: 0.5890099904260676
Validation loss: 2.571707801027585

Epoch: 6| Step: 1
Training loss: 0.39506879388532834
Validation loss: 2.5779586703534423

Epoch: 6| Step: 2
Training loss: 0.40714801058160804
Validation loss: 2.5549026403184505

Epoch: 6| Step: 3
Training loss: 0.5829907643239322
Validation loss: 2.6176798646782724

Epoch: 6| Step: 4
Training loss: 0.47613584461916353
Validation loss: 2.557157224522916

Epoch: 6| Step: 5
Training loss: 0.5416637078228858
Validation loss: 2.600138595237961

Epoch: 6| Step: 6
Training loss: 0.45032094001140605
Validation loss: 2.557451441711058

Epoch: 6| Step: 7
Training loss: 0.6822787033674407
Validation loss: 2.5842603660205388

Epoch: 6| Step: 8
Training loss: 0.3125077485077578
Validation loss: 2.5676386992085884

Epoch: 6| Step: 9
Training loss: 0.49630010623346593
Validation loss: 2.565792580068868

Epoch: 6| Step: 10
Training loss: 0.40509363805040555
Validation loss: 2.5418850081928968

Epoch: 6| Step: 11
Training loss: 0.41477092383860803
Validation loss: 2.5339366085515023

Epoch: 6| Step: 12
Training loss: 0.3932635269142416
Validation loss: 2.5628237488526495

Epoch: 6| Step: 13
Training loss: 0.7096320102621558
Validation loss: 2.5316689404239074

Epoch: 323| Step: 0
Training loss: 0.28323782346533505
Validation loss: 2.528326829275999

Epoch: 6| Step: 1
Training loss: 0.7457234527231151
Validation loss: 2.5500461558307443

Epoch: 6| Step: 2
Training loss: 0.630774099532924
Validation loss: 2.552565562277506

Epoch: 6| Step: 3
Training loss: 0.4761111044654984
Validation loss: 2.548657024183421

Epoch: 6| Step: 4
Training loss: 0.4770007385432126
Validation loss: 2.581463064986183

Epoch: 6| Step: 5
Training loss: 0.39057658849179633
Validation loss: 2.606329536970323

Epoch: 6| Step: 6
Training loss: 0.6177675925312086
Validation loss: 2.6256773055829337

Epoch: 6| Step: 7
Training loss: 0.4295677885276419
Validation loss: 2.5569620705533547

Epoch: 6| Step: 8
Training loss: 0.38422058927228414
Validation loss: 2.60205354237946

Epoch: 6| Step: 9
Training loss: 0.47298919363863623
Validation loss: 2.5815744055289436

Epoch: 6| Step: 10
Training loss: 0.5954565319528475
Validation loss: 2.5566035986322673

Epoch: 6| Step: 11
Training loss: 0.4144984415574911
Validation loss: 2.5054957863833414

Epoch: 6| Step: 12
Training loss: 0.28599664878882536
Validation loss: 2.5189614152295157

Epoch: 6| Step: 13
Training loss: 0.3836899063884948
Validation loss: 2.5164018370487686

Epoch: 324| Step: 0
Training loss: 0.17878763189528962
Validation loss: 2.502367770868663

Epoch: 6| Step: 1
Training loss: 0.510172246942136
Validation loss: 2.5389996042341787

Epoch: 6| Step: 2
Training loss: 0.3485680528006587
Validation loss: 2.507030383628962

Epoch: 6| Step: 3
Training loss: 0.3418016160908624
Validation loss: 2.534620539798857

Epoch: 6| Step: 4
Training loss: 0.5368664001202385
Validation loss: 2.5178939985345297

Epoch: 6| Step: 5
Training loss: 0.5203222691990637
Validation loss: 2.5381422057718317

Epoch: 6| Step: 6
Training loss: 0.3172949801468406
Validation loss: 2.5422729469759946

Epoch: 6| Step: 7
Training loss: 0.47610905446466817
Validation loss: 2.5701212106930087

Epoch: 6| Step: 8
Training loss: 0.5395258694934764
Validation loss: 2.5790752083026978

Epoch: 6| Step: 9
Training loss: 0.6885577431291385
Validation loss: 2.571180027478997

Epoch: 6| Step: 10
Training loss: 0.6188909466437407
Validation loss: 2.5946484089746207

Epoch: 6| Step: 11
Training loss: 0.43075020895148647
Validation loss: 2.60211972683492

Epoch: 6| Step: 12
Training loss: 0.5273044712838528
Validation loss: 2.6136786207824634

Epoch: 6| Step: 13
Training loss: 0.6830212839099987
Validation loss: 2.5703604068749306

Epoch: 325| Step: 0
Training loss: 0.6002676267597723
Validation loss: 2.5808580814478406

Epoch: 6| Step: 1
Training loss: 0.5634518887358784
Validation loss: 2.658042352708115

Epoch: 6| Step: 2
Training loss: 0.46435919117363145
Validation loss: 2.617524563581193

Epoch: 6| Step: 3
Training loss: 0.5138582826928075
Validation loss: 2.6402576140237346

Epoch: 6| Step: 4
Training loss: 0.673002848898312
Validation loss: 2.6013336164716607

Epoch: 6| Step: 5
Training loss: 0.5839014919496485
Validation loss: 2.604665769596898

Epoch: 6| Step: 6
Training loss: 0.4014254154190106
Validation loss: 2.6496733719955863

Epoch: 6| Step: 7
Training loss: 0.5082951819324911
Validation loss: 2.62022461758323

Epoch: 6| Step: 8
Training loss: 0.4350649815014452
Validation loss: 2.598950717572994

Epoch: 6| Step: 9
Training loss: 0.2326617565745904
Validation loss: 2.5790900797251535

Epoch: 6| Step: 10
Training loss: 0.519228280433711
Validation loss: 2.6011917937556057

Epoch: 6| Step: 11
Training loss: 0.3686243311868514
Validation loss: 2.5532641560587024

Epoch: 6| Step: 12
Training loss: 0.3369103030672273
Validation loss: 2.5537743182077492

Epoch: 6| Step: 13
Training loss: 0.3016443872698808
Validation loss: 2.522585544023325

Epoch: 326| Step: 0
Training loss: 0.6304291950282761
Validation loss: 2.55865105341937

Epoch: 6| Step: 1
Training loss: 0.5947870183073837
Validation loss: 2.5684310081483765

Epoch: 6| Step: 2
Training loss: 0.5228076105521905
Validation loss: 2.5490104952339676

Epoch: 6| Step: 3
Training loss: 0.5677202176824553
Validation loss: 2.587671733196508

Epoch: 6| Step: 4
Training loss: 0.458822002503194
Validation loss: 2.5906638901155055

Epoch: 6| Step: 5
Training loss: 0.30444761761193523
Validation loss: 2.6460662650767524

Epoch: 6| Step: 6
Training loss: 0.4070533731785401
Validation loss: 2.6095715481225343

Epoch: 6| Step: 7
Training loss: 0.29336669597811604
Validation loss: 2.5765473919466464

Epoch: 6| Step: 8
Training loss: 0.38527289707579504
Validation loss: 2.594660382128839

Epoch: 6| Step: 9
Training loss: 0.5256023334963774
Validation loss: 2.5951455438223445

Epoch: 6| Step: 10
Training loss: 0.3646773307971107
Validation loss: 2.568230500971448

Epoch: 6| Step: 11
Training loss: 0.5840304557455653
Validation loss: 2.5760772358553505

Epoch: 6| Step: 12
Training loss: 0.48244003694146237
Validation loss: 2.571561648767837

Epoch: 6| Step: 13
Training loss: 0.38452454580874545
Validation loss: 2.5635664566771554

Epoch: 327| Step: 0
Training loss: 0.5110737178635447
Validation loss: 2.5539997579130382

Epoch: 6| Step: 1
Training loss: 0.6848654552921833
Validation loss: 2.5687900161750066

Epoch: 6| Step: 2
Training loss: 0.329271063466139
Validation loss: 2.566547695508813

Epoch: 6| Step: 3
Training loss: 0.539722480899297
Validation loss: 2.5246883664831983

Epoch: 6| Step: 4
Training loss: 0.45651858667554807
Validation loss: 2.532180303235678

Epoch: 6| Step: 5
Training loss: 0.3518828204320904
Validation loss: 2.564867572149603

Epoch: 6| Step: 6
Training loss: 0.49979488814877876
Validation loss: 2.563283910931643

Epoch: 6| Step: 7
Training loss: 0.18388695334461583
Validation loss: 2.611912873135492

Epoch: 6| Step: 8
Training loss: 0.6090868244040649
Validation loss: 2.5776963937623547

Epoch: 6| Step: 9
Training loss: 0.5445501775749518
Validation loss: 2.5622374757539896

Epoch: 6| Step: 10
Training loss: 0.4299463879353798
Validation loss: 2.5777501793063395

Epoch: 6| Step: 11
Training loss: 0.41626130492521474
Validation loss: 2.577332455307258

Epoch: 6| Step: 12
Training loss: 0.6255060531390406
Validation loss: 2.56881279032922

Epoch: 6| Step: 13
Training loss: 0.23420740334203385
Validation loss: 2.56956342652435

Epoch: 328| Step: 0
Training loss: 0.286231847295757
Validation loss: 2.571846759990827

Epoch: 6| Step: 1
Training loss: 0.5658530328867364
Validation loss: 2.592616109028025

Epoch: 6| Step: 2
Training loss: 0.45747904562776626
Validation loss: 2.5876156047201238

Epoch: 6| Step: 3
Training loss: 0.2836897254145559
Validation loss: 2.5953227203547806

Epoch: 6| Step: 4
Training loss: 0.5234023409749914
Validation loss: 2.5720766538009046

Epoch: 6| Step: 5
Training loss: 0.334057348209834
Validation loss: 2.5690141541687335

Epoch: 6| Step: 6
Training loss: 0.42792652987312385
Validation loss: 2.555987420210025

Epoch: 6| Step: 7
Training loss: 0.6425302829730516
Validation loss: 2.537178292302687

Epoch: 6| Step: 8
Training loss: 0.3708449684239417
Validation loss: 2.5482238297086237

Epoch: 6| Step: 9
Training loss: 0.49884292712015593
Validation loss: 2.5284058414403865

Epoch: 6| Step: 10
Training loss: 0.5520399604410323
Validation loss: 2.5605092052640086

Epoch: 6| Step: 11
Training loss: 0.4569352856168754
Validation loss: 2.5397736977458214

Epoch: 6| Step: 12
Training loss: 0.566743842180249
Validation loss: 2.5467185037731124

Epoch: 6| Step: 13
Training loss: 0.33643393098347285
Validation loss: 2.5546227661091767

Epoch: 329| Step: 0
Training loss: 0.429453248413801
Validation loss: 2.553106376582135

Epoch: 6| Step: 1
Training loss: 0.4536269630364426
Validation loss: 2.5320333263604375

Epoch: 6| Step: 2
Training loss: 0.4745650408096652
Validation loss: 2.5159676762427003

Epoch: 6| Step: 3
Training loss: 0.24287690208247825
Validation loss: 2.5203893359136895

Epoch: 6| Step: 4
Training loss: 0.6339107919652042
Validation loss: 2.5506223550485845

Epoch: 6| Step: 5
Training loss: 0.4118598435642129
Validation loss: 2.563970452534555

Epoch: 6| Step: 6
Training loss: 0.6194431035374648
Validation loss: 2.5911803303178003

Epoch: 6| Step: 7
Training loss: 0.45243011006004563
Validation loss: 2.61316343753437

Epoch: 6| Step: 8
Training loss: 0.4834575116060329
Validation loss: 2.569959903882433

Epoch: 6| Step: 9
Training loss: 0.6045747617363249
Validation loss: 2.617661774930004

Epoch: 6| Step: 10
Training loss: 0.26577446042493097
Validation loss: 2.628679180713752

Epoch: 6| Step: 11
Training loss: 0.4949134392384481
Validation loss: 2.6320382108548124

Epoch: 6| Step: 12
Training loss: 0.2774257001556722
Validation loss: 2.652034625218727

Epoch: 6| Step: 13
Training loss: 0.6201348249675571
Validation loss: 2.627178229855594

Epoch: 330| Step: 0
Training loss: 0.48509926637917655
Validation loss: 2.584817938748898

Epoch: 6| Step: 1
Training loss: 0.17816066970388214
Validation loss: 2.6138249818802217

Epoch: 6| Step: 2
Training loss: 0.4783188707322946
Validation loss: 2.5389734123509737

Epoch: 6| Step: 3
Training loss: 0.5153852541188159
Validation loss: 2.5690028278841712

Epoch: 6| Step: 4
Training loss: 0.543609542902354
Validation loss: 2.5766954661843418

Epoch: 6| Step: 5
Training loss: 0.5352897477534121
Validation loss: 2.5692736491211634

Epoch: 6| Step: 6
Training loss: 0.37525563666083156
Validation loss: 2.5240186101358253

Epoch: 6| Step: 7
Training loss: 0.3540902289014425
Validation loss: 2.536035215427224

Epoch: 6| Step: 8
Training loss: 0.29209315107763106
Validation loss: 2.586920411851002

Epoch: 6| Step: 9
Training loss: 0.36445176838809384
Validation loss: 2.568796076993958

Epoch: 6| Step: 10
Training loss: 0.6697818175956725
Validation loss: 2.548330234882582

Epoch: 6| Step: 11
Training loss: 0.33816188882501724
Validation loss: 2.5484966624076453

Epoch: 6| Step: 12
Training loss: 0.6696017865801464
Validation loss: 2.54746766941777

Epoch: 6| Step: 13
Training loss: 0.4313538405579832
Validation loss: 2.5781631014467377

Epoch: 331| Step: 0
Training loss: 0.1471853333311709
Validation loss: 2.573568708792438

Epoch: 6| Step: 1
Training loss: 0.41297160701506747
Validation loss: 2.5325390121224287

Epoch: 6| Step: 2
Training loss: 0.5568866386867064
Validation loss: 2.523457912021032

Epoch: 6| Step: 3
Training loss: 0.6356499483431817
Validation loss: 2.55553134412147

Epoch: 6| Step: 4
Training loss: 0.3770636757140417
Validation loss: 2.5487853846936517

Epoch: 6| Step: 5
Training loss: 0.4543861563833298
Validation loss: 2.567520228229746

Epoch: 6| Step: 6
Training loss: 0.5953304938853444
Validation loss: 2.555979125935779

Epoch: 6| Step: 7
Training loss: 0.48585841464487384
Validation loss: 2.554690966102507

Epoch: 6| Step: 8
Training loss: 0.6278589662680085
Validation loss: 2.5668614425342495

Epoch: 6| Step: 9
Training loss: 0.37534755257235064
Validation loss: 2.5390717203810564

Epoch: 6| Step: 10
Training loss: 0.493466743269483
Validation loss: 2.5458711303700023

Epoch: 6| Step: 11
Training loss: 0.3835675714265374
Validation loss: 2.5081309919829833

Epoch: 6| Step: 12
Training loss: 0.24155049998690217
Validation loss: 2.5210216980332083

Epoch: 6| Step: 13
Training loss: 0.21876762523490037
Validation loss: 2.528227630912629

Epoch: 332| Step: 0
Training loss: 0.3494052824022853
Validation loss: 2.504805098645418

Epoch: 6| Step: 1
Training loss: 0.5897206563275443
Validation loss: 2.5417804991758244

Epoch: 6| Step: 2
Training loss: 0.367289934682558
Validation loss: 2.5351476575152585

Epoch: 6| Step: 3
Training loss: 0.4295440781260718
Validation loss: 2.535542515158795

Epoch: 6| Step: 4
Training loss: 0.4479390201609341
Validation loss: 2.537425947682335

Epoch: 6| Step: 5
Training loss: 0.5458628415971798
Validation loss: 2.500819425728496

Epoch: 6| Step: 6
Training loss: 0.5629213132838268
Validation loss: 2.572921819350844

Epoch: 6| Step: 7
Training loss: 0.4692725130390529
Validation loss: 2.5440732088813394

Epoch: 6| Step: 8
Training loss: 0.3922158652758685
Validation loss: 2.5663580520421108

Epoch: 6| Step: 9
Training loss: 0.48819121484364997
Validation loss: 2.549218783428051

Epoch: 6| Step: 10
Training loss: 0.4808745182730054
Validation loss: 2.5534183655924014

Epoch: 6| Step: 11
Training loss: 0.4121693029717864
Validation loss: 2.5573541018632344

Epoch: 6| Step: 12
Training loss: 0.3553247893866179
Validation loss: 2.5768965274354425

Epoch: 6| Step: 13
Training loss: 0.2547254990390386
Validation loss: 2.5726008293400797

Epoch: 333| Step: 0
Training loss: 0.5353092058551399
Validation loss: 2.5608550318581025

Epoch: 6| Step: 1
Training loss: 0.5190568062632493
Validation loss: 2.6030162457313204

Epoch: 6| Step: 2
Training loss: 0.34735988457632805
Validation loss: 2.60420290193677

Epoch: 6| Step: 3
Training loss: 0.37234783085528933
Validation loss: 2.6103624923292656

Epoch: 6| Step: 4
Training loss: 0.49780414126479405
Validation loss: 2.603690747160221

Epoch: 6| Step: 5
Training loss: 0.5061421726919025
Validation loss: 2.5952342985675356

Epoch: 6| Step: 6
Training loss: 0.5041559177492877
Validation loss: 2.602040492876516

Epoch: 6| Step: 7
Training loss: 0.4123263759501494
Validation loss: 2.593289378511493

Epoch: 6| Step: 8
Training loss: 0.34882665635981996
Validation loss: 2.565708437817849

Epoch: 6| Step: 9
Training loss: 0.4176283546548227
Validation loss: 2.531323107645199

Epoch: 6| Step: 10
Training loss: 0.5265087722851761
Validation loss: 2.54106272019875

Epoch: 6| Step: 11
Training loss: 0.30405198356421775
Validation loss: 2.539378567720675

Epoch: 6| Step: 12
Training loss: 0.5594041720833812
Validation loss: 2.5181002511932924

Epoch: 6| Step: 13
Training loss: 0.36440448007038473
Validation loss: 2.5604160738143755

Epoch: 334| Step: 0
Training loss: 0.64586314522222
Validation loss: 2.559259156841546

Epoch: 6| Step: 1
Training loss: 0.4011847459609717
Validation loss: 2.542392945846133

Epoch: 6| Step: 2
Training loss: 0.6438394243665041
Validation loss: 2.506784282415323

Epoch: 6| Step: 3
Training loss: 0.18583442090732635
Validation loss: 2.5757968188633713

Epoch: 6| Step: 4
Training loss: 0.4043278336765493
Validation loss: 2.558979025518322

Epoch: 6| Step: 5
Training loss: 0.306596388329082
Validation loss: 2.5655571438854254

Epoch: 6| Step: 6
Training loss: 0.28060952747144774
Validation loss: 2.5540959930103875

Epoch: 6| Step: 7
Training loss: 0.2737962549140856
Validation loss: 2.5880465929237917

Epoch: 6| Step: 8
Training loss: 0.4675370098702879
Validation loss: 2.536149580364077

Epoch: 6| Step: 9
Training loss: 0.3193961737047055
Validation loss: 2.5534353984527067

Epoch: 6| Step: 10
Training loss: 0.5096928628607797
Validation loss: 2.5080225179362365

Epoch: 6| Step: 11
Training loss: 0.4567045038215439
Validation loss: 2.5307797463927186

Epoch: 6| Step: 12
Training loss: 0.5934600373016702
Validation loss: 2.5404410840983394

Epoch: 6| Step: 13
Training loss: 0.5592903115720924
Validation loss: 2.4886597378845736

Epoch: 335| Step: 0
Training loss: 0.5116698845980638
Validation loss: 2.525743793008218

Epoch: 6| Step: 1
Training loss: 0.47643201636339194
Validation loss: 2.5506497711220204

Epoch: 6| Step: 2
Training loss: 0.350231203706889
Validation loss: 2.5020597484045672

Epoch: 6| Step: 3
Training loss: 0.3937263776868551
Validation loss: 2.5298807980125932

Epoch: 6| Step: 4
Training loss: 0.35355945968736835
Validation loss: 2.5434717808313785

Epoch: 6| Step: 5
Training loss: 0.5578986424627367
Validation loss: 2.529260093746822

Epoch: 6| Step: 6
Training loss: 0.42238192654947787
Validation loss: 2.586444171237364

Epoch: 6| Step: 7
Training loss: 0.5087994301704298
Validation loss: 2.5915177162766834

Epoch: 6| Step: 8
Training loss: 0.4616366595828889
Validation loss: 2.60400263378404

Epoch: 6| Step: 9
Training loss: 0.17592101898208712
Validation loss: 2.5813364704457498

Epoch: 6| Step: 10
Training loss: 0.304280681938275
Validation loss: 2.55861068528354

Epoch: 6| Step: 11
Training loss: 0.42889548046717485
Validation loss: 2.546882337978232

Epoch: 6| Step: 12
Training loss: 0.587458226565271
Validation loss: 2.5572520806578773

Epoch: 6| Step: 13
Training loss: 0.34063255362928346
Validation loss: 2.5600653426710327

Epoch: 336| Step: 0
Training loss: 0.3080465438767467
Validation loss: 2.518115220564756

Epoch: 6| Step: 1
Training loss: 0.4104621110080828
Validation loss: 2.589143565012236

Epoch: 6| Step: 2
Training loss: 0.5957162574196034
Validation loss: 2.5597322144413477

Epoch: 6| Step: 3
Training loss: 0.40878052463354864
Validation loss: 2.572577100166221

Epoch: 6| Step: 4
Training loss: 0.45633680615219413
Validation loss: 2.5354692728592547

Epoch: 6| Step: 5
Training loss: 0.5970210021636256
Validation loss: 2.520892920959764

Epoch: 6| Step: 6
Training loss: 0.6203628654115644
Validation loss: 2.4831226453444257

Epoch: 6| Step: 7
Training loss: 0.36334045501970896
Validation loss: 2.4611938884706914

Epoch: 6| Step: 8
Training loss: 0.31848763298670596
Validation loss: 2.486672459065314

Epoch: 6| Step: 9
Training loss: 0.33402346778203
Validation loss: 2.444644899094959

Epoch: 6| Step: 10
Training loss: 0.6070126936934871
Validation loss: 2.5005423183219455

Epoch: 6| Step: 11
Training loss: 0.3996655854397981
Validation loss: 2.487078259287187

Epoch: 6| Step: 12
Training loss: 0.33029562651700844
Validation loss: 2.464512543665475

Epoch: 6| Step: 13
Training loss: 0.34580042919021436
Validation loss: 2.4420452110349147

Epoch: 337| Step: 0
Training loss: 0.3926402939492923
Validation loss: 2.523012530382881

Epoch: 6| Step: 1
Training loss: 0.2574989984779881
Validation loss: 2.506802623109131

Epoch: 6| Step: 2
Training loss: 0.38287718868595233
Validation loss: 2.507004462099308

Epoch: 6| Step: 3
Training loss: 0.4550756364353229
Validation loss: 2.53794443609072

Epoch: 6| Step: 4
Training loss: 0.44378104302797905
Validation loss: 2.5477555061036994

Epoch: 6| Step: 5
Training loss: 0.59620887674514
Validation loss: 2.536624340972106

Epoch: 6| Step: 6
Training loss: 0.5254625746233391
Validation loss: 2.5271648244682807

Epoch: 6| Step: 7
Training loss: 0.5183340346719019
Validation loss: 2.5630541766711294

Epoch: 6| Step: 8
Training loss: 0.43031710534273543
Validation loss: 2.530669610296304

Epoch: 6| Step: 9
Training loss: 0.560961420510817
Validation loss: 2.5795178660353835

Epoch: 6| Step: 10
Training loss: 0.38502720108175875
Validation loss: 2.545344292535997

Epoch: 6| Step: 11
Training loss: 0.3428394873471177
Validation loss: 2.562847583086472

Epoch: 6| Step: 12
Training loss: 0.5793992510908276
Validation loss: 2.574805587420898

Epoch: 6| Step: 13
Training loss: 0.1455486931433891
Validation loss: 2.5580898985851124

Epoch: 338| Step: 0
Training loss: 0.5750959274880091
Validation loss: 2.557831407875104

Epoch: 6| Step: 1
Training loss: 0.13444692134121777
Validation loss: 2.5511032167881633

Epoch: 6| Step: 2
Training loss: 0.4234464834463844
Validation loss: 2.565162554002947

Epoch: 6| Step: 3
Training loss: 0.3602304229155526
Validation loss: 2.5573388223494318

Epoch: 6| Step: 4
Training loss: 0.5566748892962992
Validation loss: 2.592245813044535

Epoch: 6| Step: 5
Training loss: 0.2658813725960078
Validation loss: 2.554953826271306

Epoch: 6| Step: 6
Training loss: 0.5239665361322271
Validation loss: 2.5732958499574368

Epoch: 6| Step: 7
Training loss: 0.4593161337627374
Validation loss: 2.545548632739639

Epoch: 6| Step: 8
Training loss: 0.4374991144443814
Validation loss: 2.5425761824797917

Epoch: 6| Step: 9
Training loss: 0.568920710379098
Validation loss: 2.5285802830387936

Epoch: 6| Step: 10
Training loss: 0.49914746320252384
Validation loss: 2.528245445939681

Epoch: 6| Step: 11
Training loss: 0.43430730168658094
Validation loss: 2.5546179110263267

Epoch: 6| Step: 12
Training loss: 0.2734115997036981
Validation loss: 2.557003628980769

Epoch: 6| Step: 13
Training loss: 0.20487262784155966
Validation loss: 2.5614452707538513

Epoch: 339| Step: 0
Training loss: 0.6156085859327682
Validation loss: 2.543268329148924

Epoch: 6| Step: 1
Training loss: 0.3978128211176701
Validation loss: 2.537366386947969

Epoch: 6| Step: 2
Training loss: 0.5041981228822616
Validation loss: 2.5479203351377695

Epoch: 6| Step: 3
Training loss: 0.33207725879317673
Validation loss: 2.539611440026883

Epoch: 6| Step: 4
Training loss: 0.4215654367693839
Validation loss: 2.5756997617482287

Epoch: 6| Step: 5
Training loss: 0.13902825244562547
Validation loss: 2.5621170675231966

Epoch: 6| Step: 6
Training loss: 0.32988871269302383
Validation loss: 2.549638384570398

Epoch: 6| Step: 7
Training loss: 0.37876675191034725
Validation loss: 2.6161492320953315

Epoch: 6| Step: 8
Training loss: 0.4258490342246034
Validation loss: 2.555553815103051

Epoch: 6| Step: 9
Training loss: 0.4163135661598462
Validation loss: 2.578428205483002

Epoch: 6| Step: 10
Training loss: 0.31446715140009834
Validation loss: 2.5686568881220957

Epoch: 6| Step: 11
Training loss: 0.633057817545546
Validation loss: 2.5768680216725466

Epoch: 6| Step: 12
Training loss: 0.5308386668811145
Validation loss: 2.5871407545056004

Epoch: 6| Step: 13
Training loss: 0.12226732377770361
Validation loss: 2.59547384229942

Epoch: 340| Step: 0
Training loss: 0.27926643579177834
Validation loss: 2.560743093283918

Epoch: 6| Step: 1
Training loss: 0.4429319733115705
Validation loss: 2.610018312830571

Epoch: 6| Step: 2
Training loss: 0.32917767784960106
Validation loss: 2.5926851611385935

Epoch: 6| Step: 3
Training loss: 0.26565122474913655
Validation loss: 2.567457220805473

Epoch: 6| Step: 4
Training loss: 0.1730271756603795
Validation loss: 2.5734823995845963

Epoch: 6| Step: 5
Training loss: 0.35194074628020716
Validation loss: 2.5440081242858374

Epoch: 6| Step: 6
Training loss: 0.4951727570719123
Validation loss: 2.557815641098995

Epoch: 6| Step: 7
Training loss: 0.5681246767788042
Validation loss: 2.556458261571217

Epoch: 6| Step: 8
Training loss: 0.20450363527916532
Validation loss: 2.555898388879566

Epoch: 6| Step: 9
Training loss: 0.5112121637049389
Validation loss: 2.5863865545889255

Epoch: 6| Step: 10
Training loss: 0.5261690407317701
Validation loss: 2.565240555010621

Epoch: 6| Step: 11
Training loss: 0.4179092792734086
Validation loss: 2.601559141674792

Epoch: 6| Step: 12
Training loss: 0.44098651813586026
Validation loss: 2.567243001271741

Epoch: 6| Step: 13
Training loss: 0.7085112367006806
Validation loss: 2.568722169555327

Epoch: 341| Step: 0
Training loss: 0.18493249467043266
Validation loss: 2.5586421949128635

Epoch: 6| Step: 1
Training loss: 0.44887758651451354
Validation loss: 2.532282786839423

Epoch: 6| Step: 2
Training loss: 0.39909553417989546
Validation loss: 2.5565566523377092

Epoch: 6| Step: 3
Training loss: 0.4640449584830936
Validation loss: 2.5204683349936303

Epoch: 6| Step: 4
Training loss: 0.45930940198612674
Validation loss: 2.5207247594158964

Epoch: 6| Step: 5
Training loss: 0.6242054657364033
Validation loss: 2.552186995898262

Epoch: 6| Step: 6
Training loss: 0.3092988565935028
Validation loss: 2.54936695016364

Epoch: 6| Step: 7
Training loss: 0.5230600220079921
Validation loss: 2.5174072480538303

Epoch: 6| Step: 8
Training loss: 0.48324059886145493
Validation loss: 2.551519963001625

Epoch: 6| Step: 9
Training loss: 0.20470213255377076
Validation loss: 2.5210311430330816

Epoch: 6| Step: 10
Training loss: 0.350727966356768
Validation loss: 2.52549983510965

Epoch: 6| Step: 11
Training loss: 0.33339753377084647
Validation loss: 2.5317142100916468

Epoch: 6| Step: 12
Training loss: 0.38597248783669047
Validation loss: 2.5581823941858914

Epoch: 6| Step: 13
Training loss: 0.6008849849359359
Validation loss: 2.5359066300886433

Epoch: 342| Step: 0
Training loss: 0.4297711551035159
Validation loss: 2.530030281661129

Epoch: 6| Step: 1
Training loss: 0.41300332255562555
Validation loss: 2.570566823509125

Epoch: 6| Step: 2
Training loss: 0.46829010337425875
Validation loss: 2.6112276568861525

Epoch: 6| Step: 3
Training loss: 0.5071548311308988
Validation loss: 2.5814544458916386

Epoch: 6| Step: 4
Training loss: 0.3739236843063285
Validation loss: 2.543840152444743

Epoch: 6| Step: 5
Training loss: 0.5096818409318479
Validation loss: 2.5384893490174583

Epoch: 6| Step: 6
Training loss: 0.5052010512728411
Validation loss: 2.5603752846850876

Epoch: 6| Step: 7
Training loss: 0.36372842236389596
Validation loss: 2.553035409488903

Epoch: 6| Step: 8
Training loss: 0.2576406946801591
Validation loss: 2.520875628557331

Epoch: 6| Step: 9
Training loss: 0.3749222873590884
Validation loss: 2.5069869972038172

Epoch: 6| Step: 10
Training loss: 0.3676994285730005
Validation loss: 2.465195104840129

Epoch: 6| Step: 11
Training loss: 0.32835434664048935
Validation loss: 2.4941912119062613

Epoch: 6| Step: 12
Training loss: 0.27943819645483653
Validation loss: 2.4562975416331736

Epoch: 6| Step: 13
Training loss: 0.6896245381317611
Validation loss: 2.4656642582183057

Epoch: 343| Step: 0
Training loss: 0.33945460346633044
Validation loss: 2.519185845789567

Epoch: 6| Step: 1
Training loss: 0.49454698703308175
Validation loss: 2.5071069563626907

Epoch: 6| Step: 2
Training loss: 0.4938898920513994
Validation loss: 2.5278909672835264

Epoch: 6| Step: 3
Training loss: 0.27799141172309333
Validation loss: 2.5476257095574013

Epoch: 6| Step: 4
Training loss: 0.2880855754268117
Validation loss: 2.562347913821398

Epoch: 6| Step: 5
Training loss: 0.4481701429392313
Validation loss: 2.5460277934708686

Epoch: 6| Step: 6
Training loss: 0.31393915430218255
Validation loss: 2.599520840144996

Epoch: 6| Step: 7
Training loss: 0.15010019224527515
Validation loss: 2.594900936167643

Epoch: 6| Step: 8
Training loss: 0.5507376362732744
Validation loss: 2.5635800050333764

Epoch: 6| Step: 9
Training loss: 0.4341418608036407
Validation loss: 2.5862108490166067

Epoch: 6| Step: 10
Training loss: 0.5173120354482904
Validation loss: 2.568153451760208

Epoch: 6| Step: 11
Training loss: 0.6037391075984033
Validation loss: 2.573382701385352

Epoch: 6| Step: 12
Training loss: 0.37097286463928264
Validation loss: 2.5597739477265113

Epoch: 6| Step: 13
Training loss: 0.3974411230748487
Validation loss: 2.5283151432762843

Epoch: 344| Step: 0
Training loss: 0.5745474983679412
Validation loss: 2.5604218831147643

Epoch: 6| Step: 1
Training loss: 0.19603473641621502
Validation loss: 2.509877692656813

Epoch: 6| Step: 2
Training loss: 0.4334182212134023
Validation loss: 2.5167224619786364

Epoch: 6| Step: 3
Training loss: 0.28012567539465605
Validation loss: 2.528720938788414

Epoch: 6| Step: 4
Training loss: 0.32212137403952784
Validation loss: 2.5571875425174233

Epoch: 6| Step: 5
Training loss: 0.3004446003493264
Validation loss: 2.4983806010518346

Epoch: 6| Step: 6
Training loss: 0.31511462275703944
Validation loss: 2.519561770954538

Epoch: 6| Step: 7
Training loss: 0.4005421421581671
Validation loss: 2.5216173511991107

Epoch: 6| Step: 8
Training loss: 0.4068195129097163
Validation loss: 2.5020425184685555

Epoch: 6| Step: 9
Training loss: 0.5485887107085287
Validation loss: 2.515581148305876

Epoch: 6| Step: 10
Training loss: 0.5687784439352197
Validation loss: 2.5054620254434394

Epoch: 6| Step: 11
Training loss: 0.4143132943746973
Validation loss: 2.5081456513555054

Epoch: 6| Step: 12
Training loss: 0.3896845368224474
Validation loss: 2.4673604797062803

Epoch: 6| Step: 13
Training loss: 0.5043173303451987
Validation loss: 2.50515953597859

Epoch: 345| Step: 0
Training loss: 0.4150721458264324
Validation loss: 2.4902695108243647

Epoch: 6| Step: 1
Training loss: 0.24548833795601915
Validation loss: 2.53721572137887

Epoch: 6| Step: 2
Training loss: 0.545004370129414
Validation loss: 2.4862160805934113

Epoch: 6| Step: 3
Training loss: 0.24973119500200164
Validation loss: 2.5028903188885274

Epoch: 6| Step: 4
Training loss: 0.44640322170492186
Validation loss: 2.52513697392898

Epoch: 6| Step: 5
Training loss: 0.25263000467563074
Validation loss: 2.541254972147927

Epoch: 6| Step: 6
Training loss: 0.2587195393006225
Validation loss: 2.5104089620318204

Epoch: 6| Step: 7
Training loss: 0.38646759200337133
Validation loss: 2.560083429831862

Epoch: 6| Step: 8
Training loss: 0.3756587282801461
Validation loss: 2.5416418965660927

Epoch: 6| Step: 9
Training loss: 0.5020758927718608
Validation loss: 2.555466955639652

Epoch: 6| Step: 10
Training loss: 0.30537759440315815
Validation loss: 2.528080550489199

Epoch: 6| Step: 11
Training loss: 0.44590906706148786
Validation loss: 2.5106797703170174

Epoch: 6| Step: 12
Training loss: 0.4416371644561167
Validation loss: 2.5073763059388847

Epoch: 6| Step: 13
Training loss: 0.781982498097483
Validation loss: 2.5150554778908982

Epoch: 346| Step: 0
Training loss: 0.32058774938079493
Validation loss: 2.4916593048676163

Epoch: 6| Step: 1
Training loss: 0.2428076096266866
Validation loss: 2.4863175789374083

Epoch: 6| Step: 2
Training loss: 0.3337004944164076
Validation loss: 2.4899898208704645

Epoch: 6| Step: 3
Training loss: 0.42001859748628334
Validation loss: 2.5285212794263168

Epoch: 6| Step: 4
Training loss: 0.41908514361326515
Validation loss: 2.482129059585339

Epoch: 6| Step: 5
Training loss: 0.44083800071211726
Validation loss: 2.498204787513907

Epoch: 6| Step: 6
Training loss: 0.46972919550611775
Validation loss: 2.5377269812479355

Epoch: 6| Step: 7
Training loss: 0.5256157148269105
Validation loss: 2.5035993957448706

Epoch: 6| Step: 8
Training loss: 0.41143910648797805
Validation loss: 2.525832472624819

Epoch: 6| Step: 9
Training loss: 0.4377211624812171
Validation loss: 2.5451213668542936

Epoch: 6| Step: 10
Training loss: 0.44724896662311786
Validation loss: 2.554842296931925

Epoch: 6| Step: 11
Training loss: 0.4197600474254177
Validation loss: 2.5266380026489035

Epoch: 6| Step: 12
Training loss: 0.4923752623376005
Validation loss: 2.56573802078589

Epoch: 6| Step: 13
Training loss: 0.30450487777173085
Validation loss: 2.5645389383671153

Epoch: 347| Step: 0
Training loss: 0.5612030176578477
Validation loss: 2.587060170924435

Epoch: 6| Step: 1
Training loss: 0.4160432761588918
Validation loss: 2.591498860000866

Epoch: 6| Step: 2
Training loss: 0.2997215478786589
Validation loss: 2.5736274595981556

Epoch: 6| Step: 3
Training loss: 0.43320793307416355
Validation loss: 2.5961711913407814

Epoch: 6| Step: 4
Training loss: 0.36454720545194536
Validation loss: 2.579451231850612

Epoch: 6| Step: 5
Training loss: 0.22802554666926028
Validation loss: 2.559984344430065

Epoch: 6| Step: 6
Training loss: 0.32440752255934563
Validation loss: 2.5356356537887756

Epoch: 6| Step: 7
Training loss: 0.3610713768254634
Validation loss: 2.5135057113651014

Epoch: 6| Step: 8
Training loss: 0.3877713683737853
Validation loss: 2.5651306377515226

Epoch: 6| Step: 9
Training loss: 0.3946198845436028
Validation loss: 2.513924414899373

Epoch: 6| Step: 10
Training loss: 0.6258663610140617
Validation loss: 2.5612995878594815

Epoch: 6| Step: 11
Training loss: 0.40039306267717356
Validation loss: 2.544526529851654

Epoch: 6| Step: 12
Training loss: 0.30376153015497404
Validation loss: 2.56696525400977

Epoch: 6| Step: 13
Training loss: 0.6274431636800534
Validation loss: 2.5990044563434633

Epoch: 348| Step: 0
Training loss: 0.6911566979005414
Validation loss: 2.609077176753002

Epoch: 6| Step: 1
Training loss: 0.43323041109329957
Validation loss: 2.5786356370858585

Epoch: 6| Step: 2
Training loss: 0.3371185014181126
Validation loss: 2.6094302350331837

Epoch: 6| Step: 3
Training loss: 0.3733740964239404
Validation loss: 2.625581744257965

Epoch: 6| Step: 4
Training loss: 0.45709935520412887
Validation loss: 2.6116012067333054

Epoch: 6| Step: 5
Training loss: 0.3999823745182179
Validation loss: 2.605755637124995

Epoch: 6| Step: 6
Training loss: 0.26328555876152016
Validation loss: 2.619500730325904

Epoch: 6| Step: 7
Training loss: 0.538394984616376
Validation loss: 2.566081177573164

Epoch: 6| Step: 8
Training loss: 0.3865597137807168
Validation loss: 2.5455412043052834

Epoch: 6| Step: 9
Training loss: 0.24910239669518952
Validation loss: 2.5437724662716454

Epoch: 6| Step: 10
Training loss: 0.09275082262367144
Validation loss: 2.525489167377281

Epoch: 6| Step: 11
Training loss: 0.3989035554668599
Validation loss: 2.5176179538195442

Epoch: 6| Step: 12
Training loss: 0.4316843968632388
Validation loss: 2.4898772472726844

Epoch: 6| Step: 13
Training loss: 0.2960673312879547
Validation loss: 2.5097357464264687

Epoch: 349| Step: 0
Training loss: 0.2819585748802704
Validation loss: 2.4945761243482534

Epoch: 6| Step: 1
Training loss: 0.6040899019691541
Validation loss: 2.4609735114162663

Epoch: 6| Step: 2
Training loss: 0.4302718783717018
Validation loss: 2.4377017604223674

Epoch: 6| Step: 3
Training loss: 0.1792831432261849
Validation loss: 2.478213612981248

Epoch: 6| Step: 4
Training loss: 0.276146736781483
Validation loss: 2.456500494510631

Epoch: 6| Step: 5
Training loss: 0.3051407572675523
Validation loss: 2.461306910501337

Epoch: 6| Step: 6
Training loss: 0.449208516543382
Validation loss: 2.4808247545957687

Epoch: 6| Step: 7
Training loss: 0.46066424788784505
Validation loss: 2.497263992492358

Epoch: 6| Step: 8
Training loss: 0.4625823849683379
Validation loss: 2.525049397105088

Epoch: 6| Step: 9
Training loss: 0.43799210868872707
Validation loss: 2.544425413953127

Epoch: 6| Step: 10
Training loss: 0.26138261303972593
Validation loss: 2.5507201427538626

Epoch: 6| Step: 11
Training loss: 0.5286442861550026
Validation loss: 2.5496012997500044

Epoch: 6| Step: 12
Training loss: 0.4323164193600423
Validation loss: 2.5431922323059912

Epoch: 6| Step: 13
Training loss: 0.3951791975810443
Validation loss: 2.535273862585218

Epoch: 350| Step: 0
Training loss: 0.2687047643073017
Validation loss: 2.5346486417555165

Epoch: 6| Step: 1
Training loss: 0.4761047353500602
Validation loss: 2.527327412638084

Epoch: 6| Step: 2
Training loss: 0.4213601962657375
Validation loss: 2.496926280356291

Epoch: 6| Step: 3
Training loss: 0.3185478307943833
Validation loss: 2.5303240841944024

Epoch: 6| Step: 4
Training loss: 0.4073979956851471
Validation loss: 2.501383199846229

Epoch: 6| Step: 5
Training loss: 0.3617823040292712
Validation loss: 2.50221611776428

Epoch: 6| Step: 6
Training loss: 0.5500482321311407
Validation loss: 2.461435773115977

Epoch: 6| Step: 7
Training loss: 0.2919750144782113
Validation loss: 2.4811118493324735

Epoch: 6| Step: 8
Training loss: 0.2620664820133145
Validation loss: 2.474801191306605

Epoch: 6| Step: 9
Training loss: 0.41827445570821575
Validation loss: 2.514887893415175

Epoch: 6| Step: 10
Training loss: 0.6581548565561414
Validation loss: 2.508151399784989

Epoch: 6| Step: 11
Training loss: 0.33503684471119516
Validation loss: 2.5297182229540525

Epoch: 6| Step: 12
Training loss: 0.2111562812881932
Validation loss: 2.4766128103784375

Epoch: 6| Step: 13
Training loss: 0.319839919775022
Validation loss: 2.5344834320901377

Epoch: 351| Step: 0
Training loss: 0.36677719079643206
Validation loss: 2.5428698123079734

Epoch: 6| Step: 1
Training loss: 0.2719604790801965
Validation loss: 2.520636644845419

Epoch: 6| Step: 2
Training loss: 0.46365046206669003
Validation loss: 2.5799982364825307

Epoch: 6| Step: 3
Training loss: 0.3538587601484909
Validation loss: 2.5588486361081544

Epoch: 6| Step: 4
Training loss: 0.4008230340008513
Validation loss: 2.556086881200719

Epoch: 6| Step: 5
Training loss: 0.4751005888139757
Validation loss: 2.535927216211006

Epoch: 6| Step: 6
Training loss: 0.48984785914788953
Validation loss: 2.5514550412350534

Epoch: 6| Step: 7
Training loss: 0.4881690087059826
Validation loss: 2.4990784474492176

Epoch: 6| Step: 8
Training loss: 0.237076025161892
Validation loss: 2.5137755639382044

Epoch: 6| Step: 9
Training loss: 0.3986838458082576
Validation loss: 2.5284402278177143

Epoch: 6| Step: 10
Training loss: 0.29477229335510596
Validation loss: 2.510735012183678

Epoch: 6| Step: 11
Training loss: 0.2579450266677886
Validation loss: 2.52998891043398

Epoch: 6| Step: 12
Training loss: 0.4163290642920844
Validation loss: 2.507917148789913

Epoch: 6| Step: 13
Training loss: 0.6615641551837208
Validation loss: 2.5245943132008506

Epoch: 352| Step: 0
Training loss: 0.45510710267895044
Validation loss: 2.5790525098597317

Epoch: 6| Step: 1
Training loss: 0.4895277363748167
Validation loss: 2.5406616304359253

Epoch: 6| Step: 2
Training loss: 0.374132683240137
Validation loss: 2.5680721261290396

Epoch: 6| Step: 3
Training loss: 0.30093176902630053
Validation loss: 2.5320004103249634

Epoch: 6| Step: 4
Training loss: 0.4390942612967359
Validation loss: 2.5384200532360026

Epoch: 6| Step: 5
Training loss: 0.30904912547456975
Validation loss: 2.5353393599794836

Epoch: 6| Step: 6
Training loss: 0.28491613651623143
Validation loss: 2.5569430258691246

Epoch: 6| Step: 7
Training loss: 0.5215240920583243
Validation loss: 2.5084799623692735

Epoch: 6| Step: 8
Training loss: 0.21564317571357183
Validation loss: 2.5520009177995124

Epoch: 6| Step: 9
Training loss: 0.43485002409685025
Validation loss: 2.5638940782226025

Epoch: 6| Step: 10
Training loss: 0.46777463208008185
Validation loss: 2.5585390316954033

Epoch: 6| Step: 11
Training loss: 0.47860799403948917
Validation loss: 2.599804423977374

Epoch: 6| Step: 12
Training loss: 0.31888363972514594
Validation loss: 2.572307396126923

Epoch: 6| Step: 13
Training loss: 0.05814690274651899
Validation loss: 2.5798126509149752

Epoch: 353| Step: 0
Training loss: 0.4462462557039867
Validation loss: 2.6093606755034977

Epoch: 6| Step: 1
Training loss: 0.5997601049382114
Validation loss: 2.609627918554147

Epoch: 6| Step: 2
Training loss: 0.39148286081119077
Validation loss: 2.602082264848748

Epoch: 6| Step: 3
Training loss: 0.31011926252692207
Validation loss: 2.61570395412752

Epoch: 6| Step: 4
Training loss: 0.47449636487502966
Validation loss: 2.591490936836992

Epoch: 6| Step: 5
Training loss: 0.3822244682118189
Validation loss: 2.5958692845206293

Epoch: 6| Step: 6
Training loss: 0.4334463607883495
Validation loss: 2.551449776454894

Epoch: 6| Step: 7
Training loss: 0.3490288459175208
Validation loss: 2.5833190424031294

Epoch: 6| Step: 8
Training loss: 0.19704421052953033
Validation loss: 2.5805515458190613

Epoch: 6| Step: 9
Training loss: 0.13963197731165702
Validation loss: 2.5949845047936497

Epoch: 6| Step: 10
Training loss: 0.3845287503963794
Validation loss: 2.601264553961381

Epoch: 6| Step: 11
Training loss: 0.2477457817288231
Validation loss: 2.5682271429812937

Epoch: 6| Step: 12
Training loss: 0.4993209996824457
Validation loss: 2.6119879091420137

Epoch: 6| Step: 13
Training loss: 0.07509683687931307
Validation loss: 2.575204851488734

Epoch: 354| Step: 0
Training loss: 0.5087840543123385
Validation loss: 2.5355837017428557

Epoch: 6| Step: 1
Training loss: 0.27280121750458536
Validation loss: 2.5480566051266105

Epoch: 6| Step: 2
Training loss: 0.33732228633558364
Validation loss: 2.573347265798878

Epoch: 6| Step: 3
Training loss: 0.33676155066132824
Validation loss: 2.519315874249488

Epoch: 6| Step: 4
Training loss: 0.11865309334349407
Validation loss: 2.5664953023850194

Epoch: 6| Step: 5
Training loss: 0.3061903788471547
Validation loss: 2.5059603754341673

Epoch: 6| Step: 6
Training loss: 0.37328075646822506
Validation loss: 2.5284191254824506

Epoch: 6| Step: 7
Training loss: 0.16097064093677182
Validation loss: 2.5032768472709983

Epoch: 6| Step: 8
Training loss: 0.5362402525151492
Validation loss: 2.4861454252567237

Epoch: 6| Step: 9
Training loss: 0.5077998819984338
Validation loss: 2.5249741005378943

Epoch: 6| Step: 10
Training loss: 0.5383136911125473
Validation loss: 2.540006191671478

Epoch: 6| Step: 11
Training loss: 0.28533571944750524
Validation loss: 2.540479188640509

Epoch: 6| Step: 12
Training loss: 0.43876735161164154
Validation loss: 2.524803083439996

Epoch: 6| Step: 13
Training loss: 0.30259452789153074
Validation loss: 2.491414672461538

Epoch: 355| Step: 0
Training loss: 0.3376412656743467
Validation loss: 2.545966596300826

Epoch: 6| Step: 1
Training loss: 0.48714950628700987
Validation loss: 2.5283984351371176

Epoch: 6| Step: 2
Training loss: 0.26173070624071587
Validation loss: 2.5364825594216076

Epoch: 6| Step: 3
Training loss: 0.5058963128820616
Validation loss: 2.5475778440975883

Epoch: 6| Step: 4
Training loss: 0.3202026341592337
Validation loss: 2.5433318713075415

Epoch: 6| Step: 5
Training loss: 0.5816725066947515
Validation loss: 2.5606198955801394

Epoch: 6| Step: 6
Training loss: 0.3117388515635691
Validation loss: 2.606901517726635

Epoch: 6| Step: 7
Training loss: 0.33385279779654464
Validation loss: 2.597616449779483

Epoch: 6| Step: 8
Training loss: 0.45644871355845557
Validation loss: 2.6137821421284877

Epoch: 6| Step: 9
Training loss: 0.3759081493408666
Validation loss: 2.6240423548594958

Epoch: 6| Step: 10
Training loss: 0.21767644903492142
Validation loss: 2.619109258850623

Epoch: 6| Step: 11
Training loss: 0.44487654109215224
Validation loss: 2.613699887601451

Epoch: 6| Step: 12
Training loss: 0.1943070567538262
Validation loss: 2.564108990968044

Epoch: 6| Step: 13
Training loss: 0.4395713138594341
Validation loss: 2.563066227399533

Epoch: 356| Step: 0
Training loss: 0.6205120361491763
Validation loss: 2.574529253992074

Epoch: 6| Step: 1
Training loss: 0.2528780144301075
Validation loss: 2.555476512090764

Epoch: 6| Step: 2
Training loss: 0.38702176485539735
Validation loss: 2.568743980230401

Epoch: 6| Step: 3
Training loss: 0.2477820326703388
Validation loss: 2.538129429666561

Epoch: 6| Step: 4
Training loss: 0.2133142299095756
Validation loss: 2.5526877221043858

Epoch: 6| Step: 5
Training loss: 0.5342134956666029
Validation loss: 2.531534186842441

Epoch: 6| Step: 6
Training loss: 0.5661526605591573
Validation loss: 2.526942371730557

Epoch: 6| Step: 7
Training loss: 0.38499476779131975
Validation loss: 2.549864031592734

Epoch: 6| Step: 8
Training loss: 0.30928846218214007
Validation loss: 2.5604780645371665

Epoch: 6| Step: 9
Training loss: 0.41142356902749433
Validation loss: 2.5610839728985546

Epoch: 6| Step: 10
Training loss: 0.43464987380125664
Validation loss: 2.5475725489145287

Epoch: 6| Step: 11
Training loss: 0.4043388529191391
Validation loss: 2.5348494766131555

Epoch: 6| Step: 12
Training loss: 0.19086417491559424
Validation loss: 2.5941313221010054

Epoch: 6| Step: 13
Training loss: 0.2829497157266486
Validation loss: 2.5963120411991296

Epoch: 357| Step: 0
Training loss: 0.3098646864211486
Validation loss: 2.6146437199980372

Epoch: 6| Step: 1
Training loss: 0.25671721931042973
Validation loss: 2.6180818915424067

Epoch: 6| Step: 2
Training loss: 0.4224823183106766
Validation loss: 2.616297626382387

Epoch: 6| Step: 3
Training loss: 0.2861531872053749
Validation loss: 2.6152005416785635

Epoch: 6| Step: 4
Training loss: 0.35819485986590266
Validation loss: 2.599883705374876

Epoch: 6| Step: 5
Training loss: 0.3017202187240151
Validation loss: 2.617987056937989

Epoch: 6| Step: 6
Training loss: 0.4360504318585973
Validation loss: 2.5742671702507103

Epoch: 6| Step: 7
Training loss: 0.45196145395370524
Validation loss: 2.5545968156945853

Epoch: 6| Step: 8
Training loss: 0.29623255734660925
Validation loss: 2.5748856932989894

Epoch: 6| Step: 9
Training loss: 0.42490398079642916
Validation loss: 2.587693093876417

Epoch: 6| Step: 10
Training loss: 0.29982412070249825
Validation loss: 2.540464437325962

Epoch: 6| Step: 11
Training loss: 0.42029395363883426
Validation loss: 2.553262180059975

Epoch: 6| Step: 12
Training loss: 0.4341253853292867
Validation loss: 2.52771913129184

Epoch: 6| Step: 13
Training loss: 0.6418654365161401
Validation loss: 2.5036025393675376

Epoch: 358| Step: 0
Training loss: 0.36749514414375367
Validation loss: 2.5560732479942945

Epoch: 6| Step: 1
Training loss: 0.3661538448334511
Validation loss: 2.477630572283613

Epoch: 6| Step: 2
Training loss: 0.2595648886269645
Validation loss: 2.5095698758504894

Epoch: 6| Step: 3
Training loss: 0.4360366257389677
Validation loss: 2.5164494927309216

Epoch: 6| Step: 4
Training loss: 0.426435300704784
Validation loss: 2.49621855585058

Epoch: 6| Step: 5
Training loss: 0.35663988211513664
Validation loss: 2.5303112250472966

Epoch: 6| Step: 6
Training loss: 0.353372660860916
Validation loss: 2.480013762520887

Epoch: 6| Step: 7
Training loss: 0.2891050384770221
Validation loss: 2.538724674945099

Epoch: 6| Step: 8
Training loss: 0.3976529194330763
Validation loss: 2.5656889289792186

Epoch: 6| Step: 9
Training loss: 0.30520182994297673
Validation loss: 2.5676765159534787

Epoch: 6| Step: 10
Training loss: 0.5181526881643606
Validation loss: 2.5867589717646733

Epoch: 6| Step: 11
Training loss: 0.5084869014699613
Validation loss: 2.5861361029886885

Epoch: 6| Step: 12
Training loss: 0.24613763024416438
Validation loss: 2.549614096296145

Epoch: 6| Step: 13
Training loss: 0.5683076448265673
Validation loss: 2.5730800565988443

Epoch: 359| Step: 0
Training loss: 0.3001643952312518
Validation loss: 2.5953358935237594

Epoch: 6| Step: 1
Training loss: 0.4571198434630147
Validation loss: 2.52056391581496

Epoch: 6| Step: 2
Training loss: 0.4742786840935091
Validation loss: 2.571204697807505

Epoch: 6| Step: 3
Training loss: 0.29388779492516154
Validation loss: 2.561009113149595

Epoch: 6| Step: 4
Training loss: 0.34951550805936055
Validation loss: 2.549995277025617

Epoch: 6| Step: 5
Training loss: 0.5008582259840185
Validation loss: 2.5523540588460194

Epoch: 6| Step: 6
Training loss: 0.4277800270000105
Validation loss: 2.5820110974875

Epoch: 6| Step: 7
Training loss: 0.3384183610205062
Validation loss: 2.6145795743593547

Epoch: 6| Step: 8
Training loss: 0.31427925942344265
Validation loss: 2.593706591455776

Epoch: 6| Step: 9
Training loss: 0.5664375033470674
Validation loss: 2.558770490846724

Epoch: 6| Step: 10
Training loss: 0.3688806900288778
Validation loss: 2.570629136401081

Epoch: 6| Step: 11
Training loss: 0.27601838763463515
Validation loss: 2.5649454876758684

Epoch: 6| Step: 12
Training loss: 0.2472235615223124
Validation loss: 2.5461810588603804

Epoch: 6| Step: 13
Training loss: 0.16108956768145713
Validation loss: 2.500106341653676

Epoch: 360| Step: 0
Training loss: 0.3762671994558555
Validation loss: 2.5157603851169323

Epoch: 6| Step: 1
Training loss: 0.35257906699989844
Validation loss: 2.509546979839412

Epoch: 6| Step: 2
Training loss: 0.4096058740489877
Validation loss: 2.522774943134598

Epoch: 6| Step: 3
Training loss: 0.30901971221904256
Validation loss: 2.554857640544833

Epoch: 6| Step: 4
Training loss: 0.4106701129651579
Validation loss: 2.558508440637171

Epoch: 6| Step: 5
Training loss: 0.3650039517175666
Validation loss: 2.605334472836752

Epoch: 6| Step: 6
Training loss: 0.2870218182396648
Validation loss: 2.636715958083728

Epoch: 6| Step: 7
Training loss: 0.5369300681705406
Validation loss: 2.6332041841991956

Epoch: 6| Step: 8
Training loss: 0.3564687851793525
Validation loss: 2.614585670964

Epoch: 6| Step: 9
Training loss: 0.30872528073743455
Validation loss: 2.6346999424387443

Epoch: 6| Step: 10
Training loss: 0.5086171450998634
Validation loss: 2.6699103709013543

Epoch: 6| Step: 11
Training loss: 0.4290133997307238
Validation loss: 2.602119123884858

Epoch: 6| Step: 12
Training loss: 0.5072730206529578
Validation loss: 2.632717398260519

Epoch: 6| Step: 13
Training loss: 0.2022996143677987
Validation loss: 2.6040406312694415

Epoch: 361| Step: 0
Training loss: 0.3261255585456238
Validation loss: 2.5740990839740188

Epoch: 6| Step: 1
Training loss: 0.2343740542710615
Validation loss: 2.571526945756648

Epoch: 6| Step: 2
Training loss: 0.4081253269655749
Validation loss: 2.6028986246059196

Epoch: 6| Step: 3
Training loss: 0.49554892532186684
Validation loss: 2.5481566704575447

Epoch: 6| Step: 4
Training loss: 0.4283834088248493
Validation loss: 2.569463666559267

Epoch: 6| Step: 5
Training loss: 0.3974875176467203
Validation loss: 2.5657854655310075

Epoch: 6| Step: 6
Training loss: 0.26823081167266005
Validation loss: 2.5610738758090648

Epoch: 6| Step: 7
Training loss: 0.4541467295508227
Validation loss: 2.557132809661819

Epoch: 6| Step: 8
Training loss: 0.2391630958385818
Validation loss: 2.5251730236105043

Epoch: 6| Step: 9
Training loss: 0.34727938724534174
Validation loss: 2.497847263175577

Epoch: 6| Step: 10
Training loss: 0.3848355418548443
Validation loss: 2.499315904521086

Epoch: 6| Step: 11
Training loss: 0.5339069402398305
Validation loss: 2.526606706744466

Epoch: 6| Step: 12
Training loss: 0.21496675611354019
Validation loss: 2.5155409448127473

Epoch: 6| Step: 13
Training loss: 0.4158696917111108
Validation loss: 2.528231617985196

Epoch: 362| Step: 0
Training loss: 0.17111038688873925
Validation loss: 2.5083969386416536

Epoch: 6| Step: 1
Training loss: 0.3838221800204173
Validation loss: 2.5363246173882117

Epoch: 6| Step: 2
Training loss: 0.3170652120907722
Validation loss: 2.5640765256936096

Epoch: 6| Step: 3
Training loss: 0.36736719320334676
Validation loss: 2.5859080251831816

Epoch: 6| Step: 4
Training loss: 0.40283432468570624
Validation loss: 2.571280400328297

Epoch: 6| Step: 5
Training loss: 0.27480792902462803
Validation loss: 2.572299181883211

Epoch: 6| Step: 6
Training loss: 0.3820858890956873
Validation loss: 2.5860169180438226

Epoch: 6| Step: 7
Training loss: 0.3172282502817989
Validation loss: 2.625484808526844

Epoch: 6| Step: 8
Training loss: 0.44848029766482694
Validation loss: 2.614038363955799

Epoch: 6| Step: 9
Training loss: 0.20854531272256713
Validation loss: 2.596760635006829

Epoch: 6| Step: 10
Training loss: 0.45717224163425463
Validation loss: 2.6032134590954494

Epoch: 6| Step: 11
Training loss: 0.4066552928144376
Validation loss: 2.6054531209543677

Epoch: 6| Step: 12
Training loss: 0.6105361049139046
Validation loss: 2.6171872609921554

Epoch: 6| Step: 13
Training loss: 0.15531322881078596
Validation loss: 2.5725527927828575

Epoch: 363| Step: 0
Training loss: 0.5995758494594238
Validation loss: 2.6015941456954788

Epoch: 6| Step: 1
Training loss: 0.4219678494039057
Validation loss: 2.5425401683122084

Epoch: 6| Step: 2
Training loss: 0.26578421589375595
Validation loss: 2.57773927231211

Epoch: 6| Step: 3
Training loss: 0.2600798033467916
Validation loss: 2.5486305970897973

Epoch: 6| Step: 4
Training loss: 0.31651111325041953
Validation loss: 2.544083569942981

Epoch: 6| Step: 5
Training loss: 0.25047147519728585
Validation loss: 2.5396509318828255

Epoch: 6| Step: 6
Training loss: 0.2926187586357073
Validation loss: 2.550133371333778

Epoch: 6| Step: 7
Training loss: 0.3492970803332083
Validation loss: 2.5771826112112186

Epoch: 6| Step: 8
Training loss: 0.3936281727226561
Validation loss: 2.55685674299983

Epoch: 6| Step: 9
Training loss: 0.20411811651968284
Validation loss: 2.5888434271943415

Epoch: 6| Step: 10
Training loss: 0.49053503596634734
Validation loss: 2.5895893971369848

Epoch: 6| Step: 11
Training loss: 0.32397759902598056
Validation loss: 2.6233360331443096

Epoch: 6| Step: 12
Training loss: 0.4988565931210066
Validation loss: 2.6527638837576504

Epoch: 6| Step: 13
Training loss: 0.2002205158279021
Validation loss: 2.668707603660963

Epoch: 364| Step: 0
Training loss: 0.2890736474645628
Validation loss: 2.6558759084489525

Epoch: 6| Step: 1
Training loss: 0.5137829388549586
Validation loss: 2.6508899441180094

Epoch: 6| Step: 2
Training loss: 0.3883646225023178
Validation loss: 2.593674100300807

Epoch: 6| Step: 3
Training loss: 0.2662011237794985
Validation loss: 2.5674393303771814

Epoch: 6| Step: 4
Training loss: 0.41343976822488226
Validation loss: 2.5747331658024972

Epoch: 6| Step: 5
Training loss: 0.43777637607666875
Validation loss: 2.5863242808566915

Epoch: 6| Step: 6
Training loss: 0.3560238580544925
Validation loss: 2.518284073513451

Epoch: 6| Step: 7
Training loss: 0.34793285553019776
Validation loss: 2.4972944427151424

Epoch: 6| Step: 8
Training loss: 0.31919283679080773
Validation loss: 2.498979914625717

Epoch: 6| Step: 9
Training loss: 0.5546013671193708
Validation loss: 2.4938183858815206

Epoch: 6| Step: 10
Training loss: 0.24897194124218455
Validation loss: 2.518805845738676

Epoch: 6| Step: 11
Training loss: 0.2154087613301254
Validation loss: 2.533387357732669

Epoch: 6| Step: 12
Training loss: 0.4515577705426022
Validation loss: 2.556265457154325

Epoch: 6| Step: 13
Training loss: 0.19149525188555677
Validation loss: 2.574480891447411

Epoch: 365| Step: 0
Training loss: 0.3385558883418583
Validation loss: 2.564857581411618

Epoch: 6| Step: 1
Training loss: 0.17334904176190274
Validation loss: 2.61305916861553

Epoch: 6| Step: 2
Training loss: 0.16815965360916246
Validation loss: 2.645227176942184

Epoch: 6| Step: 3
Training loss: 0.48410635851076717
Validation loss: 2.6285823884673847

Epoch: 6| Step: 4
Training loss: 0.47577840368863306
Validation loss: 2.631903759960307

Epoch: 6| Step: 5
Training loss: 0.37536765989938836
Validation loss: 2.645367623457146

Epoch: 6| Step: 6
Training loss: 0.24902648175940623
Validation loss: 2.6100056135363747

Epoch: 6| Step: 7
Training loss: 0.3642875925117179
Validation loss: 2.643742321682722

Epoch: 6| Step: 8
Training loss: 0.27807022369694584
Validation loss: 2.632334405317123

Epoch: 6| Step: 9
Training loss: 0.37175863833674905
Validation loss: 2.6023904136571407

Epoch: 6| Step: 10
Training loss: 0.43415380513159
Validation loss: 2.6082225856120025

Epoch: 6| Step: 11
Training loss: 0.44092403504854955
Validation loss: 2.581704265811344

Epoch: 6| Step: 12
Training loss: 0.37853917303542906
Validation loss: 2.5761819358024125

Epoch: 6| Step: 13
Training loss: 0.40611415205604245
Validation loss: 2.599819068355812

Epoch: 366| Step: 0
Training loss: 0.3069765838218396
Validation loss: 2.607816603532316

Epoch: 6| Step: 1
Training loss: 0.3767250240567677
Validation loss: 2.599209953896919

Epoch: 6| Step: 2
Training loss: 0.45152014959454845
Validation loss: 2.627661844035149

Epoch: 6| Step: 3
Training loss: 0.37433587314016414
Validation loss: 2.581218227405556

Epoch: 6| Step: 4
Training loss: 0.3243071538977453
Validation loss: 2.6078061811075584

Epoch: 6| Step: 5
Training loss: 0.40865071412003906
Validation loss: 2.640449034095966

Epoch: 6| Step: 6
Training loss: 0.30191867824347246
Validation loss: 2.6443003589145038

Epoch: 6| Step: 7
Training loss: 0.39421524006977837
Validation loss: 2.6290214423255285

Epoch: 6| Step: 8
Training loss: 0.32142770668700626
Validation loss: 2.599599380210768

Epoch: 6| Step: 9
Training loss: 0.3736174648580536
Validation loss: 2.598923115597815

Epoch: 6| Step: 10
Training loss: 0.2722579856468525
Validation loss: 2.619064905133286

Epoch: 6| Step: 11
Training loss: 0.3178051412812612
Validation loss: 2.6138628718873536

Epoch: 6| Step: 12
Training loss: 0.42535130202570676
Validation loss: 2.5988628818657755

Epoch: 6| Step: 13
Training loss: 0.23763641279647194
Validation loss: 2.5580467768562523

Epoch: 367| Step: 0
Training loss: 0.3549851911773762
Validation loss: 2.567983333577521

Epoch: 6| Step: 1
Training loss: 0.43868947116959495
Validation loss: 2.578203459012257

Epoch: 6| Step: 2
Training loss: 0.6408064050394815
Validation loss: 2.5406049727124893

Epoch: 6| Step: 3
Training loss: 0.38274408235092755
Validation loss: 2.491820126332582

Epoch: 6| Step: 4
Training loss: 0.3246818704823838
Validation loss: 2.5324210300707257

Epoch: 6| Step: 5
Training loss: 0.23599238231051167
Validation loss: 2.495701114767233

Epoch: 6| Step: 6
Training loss: 0.4608677956845999
Validation loss: 2.5409043888898

Epoch: 6| Step: 7
Training loss: 0.38834608983438285
Validation loss: 2.550438554110467

Epoch: 6| Step: 8
Training loss: 0.3284328469800689
Validation loss: 2.6370278677759766

Epoch: 6| Step: 9
Training loss: 0.4940784400139589
Validation loss: 2.636309763774281

Epoch: 6| Step: 10
Training loss: 0.4284836290319131
Validation loss: 2.6151525876802366

Epoch: 6| Step: 11
Training loss: 0.4636698734847643
Validation loss: 2.6872899382853284

Epoch: 6| Step: 12
Training loss: 0.5295307163698463
Validation loss: 2.6624168428072257

Epoch: 6| Step: 13
Training loss: 0.5184578383068156
Validation loss: 2.6094620024336885

Epoch: 368| Step: 0
Training loss: 0.2757270867865304
Validation loss: 2.5300101770021786

Epoch: 6| Step: 1
Training loss: 0.4898749930169333
Validation loss: 2.468564283146505

Epoch: 6| Step: 2
Training loss: 0.32782652313086874
Validation loss: 2.425044237314158

Epoch: 6| Step: 3
Training loss: 0.41691456413971567
Validation loss: 2.4165122108690653

Epoch: 6| Step: 4
Training loss: 0.44089775841779705
Validation loss: 2.3486565971658258

Epoch: 6| Step: 5
Training loss: 0.41314713045134976
Validation loss: 2.4088628609236262

Epoch: 6| Step: 6
Training loss: 0.4250108941869753
Validation loss: 2.3754579462012106

Epoch: 6| Step: 7
Training loss: 0.5627500190345086
Validation loss: 2.4103936702865636

Epoch: 6| Step: 8
Training loss: 0.5332758927208909
Validation loss: 2.439655798362481

Epoch: 6| Step: 9
Training loss: 0.37025326363685407
Validation loss: 2.456794176292077

Epoch: 6| Step: 10
Training loss: 0.38116767338373914
Validation loss: 2.525443045589317

Epoch: 6| Step: 11
Training loss: 0.2597803670959264
Validation loss: 2.546441502371573

Epoch: 6| Step: 12
Training loss: 0.4978006689338435
Validation loss: 2.607118684879651

Epoch: 6| Step: 13
Training loss: 0.5114646455436116
Validation loss: 2.697232324509706

Epoch: 369| Step: 0
Training loss: 0.37025610095914707
Validation loss: 2.6476313132652316

Epoch: 6| Step: 1
Training loss: 0.4499049377697833
Validation loss: 2.692839668187322

Epoch: 6| Step: 2
Training loss: 0.5403969322234693
Validation loss: 2.688674449783995

Epoch: 6| Step: 3
Training loss: 0.25676233085395356
Validation loss: 2.6675918849350606

Epoch: 6| Step: 4
Training loss: 0.45611642097042965
Validation loss: 2.6546437173912625

Epoch: 6| Step: 5
Training loss: 0.24016048101298137
Validation loss: 2.600582773101036

Epoch: 6| Step: 6
Training loss: 0.4172924666921584
Validation loss: 2.5636541947144784

Epoch: 6| Step: 7
Training loss: 0.28860383115797716
Validation loss: 2.521792794061241

Epoch: 6| Step: 8
Training loss: 0.3183076383525404
Validation loss: 2.5387734485102227

Epoch: 6| Step: 9
Training loss: 0.3825525646929464
Validation loss: 2.4861426003626366

Epoch: 6| Step: 10
Training loss: 0.6812821240681751
Validation loss: 2.4749139979851833

Epoch: 6| Step: 11
Training loss: 0.31207823902415105
Validation loss: 2.5020486928158316

Epoch: 6| Step: 12
Training loss: 0.27333094019152326
Validation loss: 2.4920723540969796

Epoch: 6| Step: 13
Training loss: 0.4577366691254504
Validation loss: 2.5427191159245903

Epoch: 370| Step: 0
Training loss: 0.3614628514860378
Validation loss: 2.530509381584977

Epoch: 6| Step: 1
Training loss: 0.497677475313437
Validation loss: 2.544887706284913

Epoch: 6| Step: 2
Training loss: 0.3825133965209455
Validation loss: 2.604001278127164

Epoch: 6| Step: 3
Training loss: 0.5056078075414229
Validation loss: 2.5699925157880044

Epoch: 6| Step: 4
Training loss: 0.38609423447088015
Validation loss: 2.5636468862427155

Epoch: 6| Step: 5
Training loss: 0.2472166600491625
Validation loss: 2.557743352829512

Epoch: 6| Step: 6
Training loss: 0.3845829990167842
Validation loss: 2.5359856168674786

Epoch: 6| Step: 7
Training loss: 0.3052870280632454
Validation loss: 2.5802498680692163

Epoch: 6| Step: 8
Training loss: 0.47458745960767235
Validation loss: 2.554778741022113

Epoch: 6| Step: 9
Training loss: 0.4370656923177211
Validation loss: 2.5470214757339833

Epoch: 6| Step: 10
Training loss: 0.34475074661622174
Validation loss: 2.5258792975131703

Epoch: 6| Step: 11
Training loss: 0.2747265811151579
Validation loss: 2.506722335816905

Epoch: 6| Step: 12
Training loss: 0.3334582685743564
Validation loss: 2.55117916609126

Epoch: 6| Step: 13
Training loss: 0.19863803222759707
Validation loss: 2.5593210085552225

Epoch: 371| Step: 0
Training loss: 0.2573164155128003
Validation loss: 2.5485892717983885

Epoch: 6| Step: 1
Training loss: 0.5798831702000307
Validation loss: 2.539346343551469

Epoch: 6| Step: 2
Training loss: 0.3148840208779287
Validation loss: 2.5421128979877126

Epoch: 6| Step: 3
Training loss: 0.5013748578509117
Validation loss: 2.485243181442277

Epoch: 6| Step: 4
Training loss: 0.28700926715729225
Validation loss: 2.5218694197226554

Epoch: 6| Step: 5
Training loss: 0.36222112468289597
Validation loss: 2.4976070919108975

Epoch: 6| Step: 6
Training loss: 0.5348603481667112
Validation loss: 2.533909704684429

Epoch: 6| Step: 7
Training loss: 0.4151064829201334
Validation loss: 2.5095038851654916

Epoch: 6| Step: 8
Training loss: 0.39689804445781174
Validation loss: 2.490272875622319

Epoch: 6| Step: 9
Training loss: 0.24809350303871133
Validation loss: 2.507931461859929

Epoch: 6| Step: 10
Training loss: 0.24677168096544658
Validation loss: 2.519677721977398

Epoch: 6| Step: 11
Training loss: 0.39287237270980535
Validation loss: 2.5343451900870217

Epoch: 6| Step: 12
Training loss: 0.2837434284356689
Validation loss: 2.5380739014953106

Epoch: 6| Step: 13
Training loss: 0.11988573337401177
Validation loss: 2.5467536132842787

Epoch: 372| Step: 0
Training loss: 0.3513888672040012
Validation loss: 2.562280115737564

Epoch: 6| Step: 1
Training loss: 0.4589652361836276
Validation loss: 2.5400760335994113

Epoch: 6| Step: 2
Training loss: 0.27135603087084464
Validation loss: 2.4963580994588206

Epoch: 6| Step: 3
Training loss: 0.4567907629881275
Validation loss: 2.5177710705100718

Epoch: 6| Step: 4
Training loss: 0.403084914853743
Validation loss: 2.5386366862754097

Epoch: 6| Step: 5
Training loss: 0.42089144530540157
Validation loss: 2.525049328065819

Epoch: 6| Step: 6
Training loss: 0.4191132144550875
Validation loss: 2.553982569215259

Epoch: 6| Step: 7
Training loss: 0.5687943200250305
Validation loss: 2.5997407987124714

Epoch: 6| Step: 8
Training loss: 0.25330853166443695
Validation loss: 2.580652480025322

Epoch: 6| Step: 9
Training loss: 0.3207541653978858
Validation loss: 2.5672788960819317

Epoch: 6| Step: 10
Training loss: 0.3519044061234242
Validation loss: 2.6034893495548825

Epoch: 6| Step: 11
Training loss: 0.2899145636205848
Validation loss: 2.591696063224712

Epoch: 6| Step: 12
Training loss: 0.2656736048939543
Validation loss: 2.631679155263897

Epoch: 6| Step: 13
Training loss: 0.42642371676222235
Validation loss: 2.6231132109644553

Epoch: 373| Step: 0
Training loss: 0.3433137965411363
Validation loss: 2.573954941953463

Epoch: 6| Step: 1
Training loss: 0.3355253152726573
Validation loss: 2.587516309399334

Epoch: 6| Step: 2
Training loss: 0.6109621457643479
Validation loss: 2.5823791625954007

Epoch: 6| Step: 3
Training loss: 0.28907171440903173
Validation loss: 2.605517146903938

Epoch: 6| Step: 4
Training loss: 0.26312662898848344
Validation loss: 2.5894100234535604

Epoch: 6| Step: 5
Training loss: 0.33789823225862325
Validation loss: 2.5808835909984293

Epoch: 6| Step: 6
Training loss: 0.37019560695248854
Validation loss: 2.6623546714930852

Epoch: 6| Step: 7
Training loss: 0.42145146196351424
Validation loss: 2.6162301656336298

Epoch: 6| Step: 8
Training loss: 0.3810024286252811
Validation loss: 2.649179165832433

Epoch: 6| Step: 9
Training loss: 0.33273822466022124
Validation loss: 2.6401042518201967

Epoch: 6| Step: 10
Training loss: 0.3762382686408286
Validation loss: 2.6450472972111823

Epoch: 6| Step: 11
Training loss: 0.37123253887227714
Validation loss: 2.6508791156251528

Epoch: 6| Step: 12
Training loss: 0.3712404864469789
Validation loss: 2.6108519463994564

Epoch: 6| Step: 13
Training loss: 0.29309938697100085
Validation loss: 2.644593377438637

Epoch: 374| Step: 0
Training loss: 0.3311530110682359
Validation loss: 2.614941337191914

Epoch: 6| Step: 1
Training loss: 0.42931103253471264
Validation loss: 2.603655919513612

Epoch: 6| Step: 2
Training loss: 0.276880226172041
Validation loss: 2.601727712816756

Epoch: 6| Step: 3
Training loss: 0.3651294251473845
Validation loss: 2.575255014718806

Epoch: 6| Step: 4
Training loss: 0.2789864849437018
Validation loss: 2.5741737004878416

Epoch: 6| Step: 5
Training loss: 0.3309299155096516
Validation loss: 2.570796677209137

Epoch: 6| Step: 6
Training loss: 0.31670825579533185
Validation loss: 2.564245412415237

Epoch: 6| Step: 7
Training loss: 0.37065880031108733
Validation loss: 2.5429687449593548

Epoch: 6| Step: 8
Training loss: 0.37464305658645547
Validation loss: 2.6053784497400296

Epoch: 6| Step: 9
Training loss: 0.2785965468886198
Validation loss: 2.570477016068858

Epoch: 6| Step: 10
Training loss: 0.28106284537282483
Validation loss: 2.627667545887753

Epoch: 6| Step: 11
Training loss: 0.5236427701738181
Validation loss: 2.5480699723493294

Epoch: 6| Step: 12
Training loss: 0.31437304170047886
Validation loss: 2.585224607154297

Epoch: 6| Step: 13
Training loss: 0.1938021051423422
Validation loss: 2.573198741847998

Epoch: 375| Step: 0
Training loss: 0.17969353292537743
Validation loss: 2.5547513652444107

Epoch: 6| Step: 1
Training loss: 0.2185652838516862
Validation loss: 2.5839170940245024

Epoch: 6| Step: 2
Training loss: 0.36389454991100534
Validation loss: 2.5704996919993746

Epoch: 6| Step: 3
Training loss: 0.3045757651247648
Validation loss: 2.5843365283049864

Epoch: 6| Step: 4
Training loss: 0.4455481792325846
Validation loss: 2.5552613759451814

Epoch: 6| Step: 5
Training loss: 0.3711283215932709
Validation loss: 2.5772496457368437

Epoch: 6| Step: 6
Training loss: 0.24968802835172246
Validation loss: 2.581912512032739

Epoch: 6| Step: 7
Training loss: 0.332559927616591
Validation loss: 2.595848709594472

Epoch: 6| Step: 8
Training loss: 0.2989462326117392
Validation loss: 2.5661325246773834

Epoch: 6| Step: 9
Training loss: 0.31048228233883457
Validation loss: 2.575062638048688

Epoch: 6| Step: 10
Training loss: 0.5034635506537222
Validation loss: 2.5961837223022455

Epoch: 6| Step: 11
Training loss: 0.3185273294962626
Validation loss: 2.623760577310881

Epoch: 6| Step: 12
Training loss: 0.4098367082090499
Validation loss: 2.615436780560648

Epoch: 6| Step: 13
Training loss: 0.2560699993708543
Validation loss: 2.6069821493179286

Epoch: 376| Step: 0
Training loss: 0.27329904593208015
Validation loss: 2.573474034683634

Epoch: 6| Step: 1
Training loss: 0.43498854496003075
Validation loss: 2.6100311299301096

Epoch: 6| Step: 2
Training loss: 0.40412169268523473
Validation loss: 2.5956717669910443

Epoch: 6| Step: 3
Training loss: 0.4344963267920641
Validation loss: 2.604738132573677

Epoch: 6| Step: 4
Training loss: 0.2962770840581597
Validation loss: 2.569706730942207

Epoch: 6| Step: 5
Training loss: 0.3718686696323168
Validation loss: 2.5601545264969126

Epoch: 6| Step: 6
Training loss: 0.2013502903831762
Validation loss: 2.556759398559337

Epoch: 6| Step: 7
Training loss: 0.4603236361915615
Validation loss: 2.593439438165816

Epoch: 6| Step: 8
Training loss: 0.31242143120129623
Validation loss: 2.5794728981377864

Epoch: 6| Step: 9
Training loss: 0.2609683424030931
Validation loss: 2.5303474375839254

Epoch: 6| Step: 10
Training loss: 0.27100170232794174
Validation loss: 2.530959632876563

Epoch: 6| Step: 11
Training loss: 0.2784086120810133
Validation loss: 2.5516215814308287

Epoch: 6| Step: 12
Training loss: 0.20726226118041916
Validation loss: 2.5447160337592507

Epoch: 6| Step: 13
Training loss: 0.1732915031832546
Validation loss: 2.5131507955120997

Epoch: 377| Step: 0
Training loss: 0.33346785374119614
Validation loss: 2.538002669117808

Epoch: 6| Step: 1
Training loss: 0.23256870248125722
Validation loss: 2.5390712660266637

Epoch: 6| Step: 2
Training loss: 0.37291779207169906
Validation loss: 2.521369704809835

Epoch: 6| Step: 3
Training loss: 0.34105734247701913
Validation loss: 2.5157601813105006

Epoch: 6| Step: 4
Training loss: 0.3301945994356011
Validation loss: 2.5580921684988733

Epoch: 6| Step: 5
Training loss: 0.21812652394710588
Validation loss: 2.53365514487717

Epoch: 6| Step: 6
Training loss: 0.2947385357041971
Validation loss: 2.550049740336162

Epoch: 6| Step: 7
Training loss: 0.4055885468723905
Validation loss: 2.5250381002756943

Epoch: 6| Step: 8
Training loss: 0.27887811812739793
Validation loss: 2.539724631479992

Epoch: 6| Step: 9
Training loss: 0.32108540442914485
Validation loss: 2.580393138847709

Epoch: 6| Step: 10
Training loss: 0.4475405984715503
Validation loss: 2.594358115697308

Epoch: 6| Step: 11
Training loss: 0.3049880037528171
Validation loss: 2.547792259576401

Epoch: 6| Step: 12
Training loss: 0.2923560283779847
Validation loss: 2.5769218374393232

Epoch: 6| Step: 13
Training loss: 0.33011185738915805
Validation loss: 2.5657384259543785

Epoch: 378| Step: 0
Training loss: 0.3302708689422258
Validation loss: 2.5668620617562206

Epoch: 6| Step: 1
Training loss: 0.4027614832282348
Validation loss: 2.5246153012803805

Epoch: 6| Step: 2
Training loss: 0.17160430094971596
Validation loss: 2.5347248039357946

Epoch: 6| Step: 3
Training loss: 0.3183844854831209
Validation loss: 2.5248758020501083

Epoch: 6| Step: 4
Training loss: 0.35752548216988705
Validation loss: 2.538618314019504

Epoch: 6| Step: 5
Training loss: 0.3771690185241487
Validation loss: 2.5912120068397178

Epoch: 6| Step: 6
Training loss: 0.3793864402742873
Validation loss: 2.5288998667462987

Epoch: 6| Step: 7
Training loss: 0.2959740922856744
Validation loss: 2.5359796686952616

Epoch: 6| Step: 8
Training loss: 0.4241734341747912
Validation loss: 2.534592869930033

Epoch: 6| Step: 9
Training loss: 0.3142570690006354
Validation loss: 2.540755726128937

Epoch: 6| Step: 10
Training loss: 0.3514617351660554
Validation loss: 2.5345226983789955

Epoch: 6| Step: 11
Training loss: 0.23148488861243297
Validation loss: 2.533235224913865

Epoch: 6| Step: 12
Training loss: 0.3115170038688984
Validation loss: 2.5396207169635194

Epoch: 6| Step: 13
Training loss: 0.21545767200310442
Validation loss: 2.5616104578893975

Epoch: 379| Step: 0
Training loss: 0.2643382658361932
Validation loss: 2.5651587532564624

Epoch: 6| Step: 1
Training loss: 0.3335949931244391
Validation loss: 2.5861681049774763

Epoch: 6| Step: 2
Training loss: 0.18463576634691822
Validation loss: 2.557469404013089

Epoch: 6| Step: 3
Training loss: 0.3789758520007426
Validation loss: 2.572523862192983

Epoch: 6| Step: 4
Training loss: 0.23607787762449117
Validation loss: 2.5601146980276797

Epoch: 6| Step: 5
Training loss: 0.47168054047501484
Validation loss: 2.5996176094546106

Epoch: 6| Step: 6
Training loss: 0.3917244696912804
Validation loss: 2.557681742363265

Epoch: 6| Step: 7
Training loss: 0.3110195257789821
Validation loss: 2.56966493649569

Epoch: 6| Step: 8
Training loss: 0.31365548134953114
Validation loss: 2.52681879780365

Epoch: 6| Step: 9
Training loss: 0.1992321944842542
Validation loss: 2.5442390503305026

Epoch: 6| Step: 10
Training loss: 0.2281974141922231
Validation loss: 2.5101526501346747

Epoch: 6| Step: 11
Training loss: 0.39959220364576375
Validation loss: 2.5525086382304063

Epoch: 6| Step: 12
Training loss: 0.3635877526300518
Validation loss: 2.5606425036195244

Epoch: 6| Step: 13
Training loss: 0.1741005338210917
Validation loss: 2.559200218683755

Epoch: 380| Step: 0
Training loss: 0.38908383567555943
Validation loss: 2.501380085718446

Epoch: 6| Step: 1
Training loss: 0.20853659529018406
Validation loss: 2.5380147610156274

Epoch: 6| Step: 2
Training loss: 0.4813213537006447
Validation loss: 2.5306365296318916

Epoch: 6| Step: 3
Training loss: 0.25210302166990983
Validation loss: 2.5487371939952914

Epoch: 6| Step: 4
Training loss: 0.09954947652816852
Validation loss: 2.540777402536579

Epoch: 6| Step: 5
Training loss: 0.27508674250557497
Validation loss: 2.5449087410672124

Epoch: 6| Step: 6
Training loss: 0.47679621796904137
Validation loss: 2.5208116647563137

Epoch: 6| Step: 7
Training loss: 0.34954265405351215
Validation loss: 2.5538311322302163

Epoch: 6| Step: 8
Training loss: 0.21901080218057045
Validation loss: 2.5335233408499462

Epoch: 6| Step: 9
Training loss: 0.3199336323423281
Validation loss: 2.558688725212729

Epoch: 6| Step: 10
Training loss: 0.2880328371927807
Validation loss: 2.5310523005184202

Epoch: 6| Step: 11
Training loss: 0.2501259575872664
Validation loss: 2.5688423086060435

Epoch: 6| Step: 12
Training loss: 0.273481488095625
Validation loss: 2.54193769879565

Epoch: 6| Step: 13
Training loss: 0.3590289606045772
Validation loss: 2.5519644971799815

Epoch: 381| Step: 0
Training loss: 0.1103814810308686
Validation loss: 2.5553238533914113

Epoch: 6| Step: 1
Training loss: 0.5408722725454089
Validation loss: 2.588481790883362

Epoch: 6| Step: 2
Training loss: 0.25434460580215246
Validation loss: 2.6096897683299587

Epoch: 6| Step: 3
Training loss: 0.3222984990778863
Validation loss: 2.5687393813810355

Epoch: 6| Step: 4
Training loss: 0.2667455878049264
Validation loss: 2.590871276672089

Epoch: 6| Step: 5
Training loss: 0.3520106743811514
Validation loss: 2.5950230443078546

Epoch: 6| Step: 6
Training loss: 0.2586814224661027
Validation loss: 2.5606616974945657

Epoch: 6| Step: 7
Training loss: 0.43829188886435494
Validation loss: 2.5415109546019843

Epoch: 6| Step: 8
Training loss: 0.2619446021928264
Validation loss: 2.5552680025958248

Epoch: 6| Step: 9
Training loss: 0.28232804951927243
Validation loss: 2.5991678729056797

Epoch: 6| Step: 10
Training loss: 0.2977357983361213
Validation loss: 2.6226342845947306

Epoch: 6| Step: 11
Training loss: 0.3716995314143308
Validation loss: 2.605876854916335

Epoch: 6| Step: 12
Training loss: 0.2932975195882245
Validation loss: 2.6459283331250014

Epoch: 6| Step: 13
Training loss: 0.21503397583034184
Validation loss: 2.600191028225432

Epoch: 382| Step: 0
Training loss: 0.2274014625836948
Validation loss: 2.6152325379699106

Epoch: 6| Step: 1
Training loss: 0.2540019808545556
Validation loss: 2.5790464801018205

Epoch: 6| Step: 2
Training loss: 0.3623873469817509
Validation loss: 2.5702652036522733

Epoch: 6| Step: 3
Training loss: 0.20696723596110386
Validation loss: 2.541706531386189

Epoch: 6| Step: 4
Training loss: 0.3486745259096376
Validation loss: 2.5374465472418195

Epoch: 6| Step: 5
Training loss: 0.37576605117737516
Validation loss: 2.515676070005559

Epoch: 6| Step: 6
Training loss: 0.2542781307267762
Validation loss: 2.4791134064819107

Epoch: 6| Step: 7
Training loss: 0.23331769240840303
Validation loss: 2.4877582168474484

Epoch: 6| Step: 8
Training loss: 0.2349956480470424
Validation loss: 2.466262199406984

Epoch: 6| Step: 9
Training loss: 0.5317739259316699
Validation loss: 2.4490034861837224

Epoch: 6| Step: 10
Training loss: 0.4026416860602954
Validation loss: 2.4875705903350984

Epoch: 6| Step: 11
Training loss: 0.20633008370269607
Validation loss: 2.44331681270269

Epoch: 6| Step: 12
Training loss: 0.37363674801849106
Validation loss: 2.4660111834179803

Epoch: 6| Step: 13
Training loss: 0.20623601374743497
Validation loss: 2.463241338921861

Epoch: 383| Step: 0
Training loss: 0.3452842890750442
Validation loss: 2.4781434748406714

Epoch: 6| Step: 1
Training loss: 0.15790955656052183
Validation loss: 2.539780456660944

Epoch: 6| Step: 2
Training loss: 0.341389320442626
Validation loss: 2.512152128666956

Epoch: 6| Step: 3
Training loss: 0.3589580439062533
Validation loss: 2.5579812560527113

Epoch: 6| Step: 4
Training loss: 0.21859717991491862
Validation loss: 2.5572331784842532

Epoch: 6| Step: 5
Training loss: 0.26994110127277177
Validation loss: 2.5850407534746624

Epoch: 6| Step: 6
Training loss: 0.3218259875934104
Validation loss: 2.535320081077824

Epoch: 6| Step: 7
Training loss: 0.161385586460042
Validation loss: 2.5583746242554692

Epoch: 6| Step: 8
Training loss: 0.2880265772811843
Validation loss: 2.5468943947640486

Epoch: 6| Step: 9
Training loss: 0.4874434646200423
Validation loss: 2.571260692981333

Epoch: 6| Step: 10
Training loss: 0.38006885356513676
Validation loss: 2.5618719536344914

Epoch: 6| Step: 11
Training loss: 0.2322914174139855
Validation loss: 2.548705199800935

Epoch: 6| Step: 12
Training loss: 0.3709926266670138
Validation loss: 2.555002292539476

Epoch: 6| Step: 13
Training loss: 0.22074305755438367
Validation loss: 2.5506498645956825

Epoch: 384| Step: 0
Training loss: 0.4104624921933754
Validation loss: 2.5554058922233445

Epoch: 6| Step: 1
Training loss: 0.41107896828255913
Validation loss: 2.5868201334923517

Epoch: 6| Step: 2
Training loss: 0.28601623868524756
Validation loss: 2.5639684712886806

Epoch: 6| Step: 3
Training loss: 0.3790247427115779
Validation loss: 2.5728853835011343

Epoch: 6| Step: 4
Training loss: 0.318544649846587
Validation loss: 2.573999256280438

Epoch: 6| Step: 5
Training loss: 0.33854682135936964
Validation loss: 2.5657342298845287

Epoch: 6| Step: 6
Training loss: 0.31728204154437445
Validation loss: 2.5377795086646135

Epoch: 6| Step: 7
Training loss: 0.42037194551327456
Validation loss: 2.527269678196431

Epoch: 6| Step: 8
Training loss: 0.16304640947649254
Validation loss: 2.501403487445742

Epoch: 6| Step: 9
Training loss: 0.2621113266850904
Validation loss: 2.5445925643440925

Epoch: 6| Step: 10
Training loss: 0.4006480064272986
Validation loss: 2.5294782065413925

Epoch: 6| Step: 11
Training loss: 0.2313027727637481
Validation loss: 2.5132489793213875

Epoch: 6| Step: 12
Training loss: 0.17620934174681258
Validation loss: 2.5592531212691374

Epoch: 6| Step: 13
Training loss: 0.31785167394521013
Validation loss: 2.5633535746786773

Epoch: 385| Step: 0
Training loss: 0.4150781231619377
Validation loss: 2.5251097986355813

Epoch: 6| Step: 1
Training loss: 0.5098999548002867
Validation loss: 2.5354760038156265

Epoch: 6| Step: 2
Training loss: 0.3082795897998372
Validation loss: 2.519352634054577

Epoch: 6| Step: 3
Training loss: 0.3845789693823825
Validation loss: 2.536480772491032

Epoch: 6| Step: 4
Training loss: 0.2270724706647296
Validation loss: 2.5276477105559922

Epoch: 6| Step: 5
Training loss: 0.3450047718457531
Validation loss: 2.529828780481128

Epoch: 6| Step: 6
Training loss: 0.370537913803427
Validation loss: 2.54812964810459

Epoch: 6| Step: 7
Training loss: 0.20140794217661748
Validation loss: 2.5573153234779835

Epoch: 6| Step: 8
Training loss: 0.25653839281500496
Validation loss: 2.5854859415901874

Epoch: 6| Step: 9
Training loss: 0.20305891062228537
Validation loss: 2.5686893633723726

Epoch: 6| Step: 10
Training loss: 0.3465869618374404
Validation loss: 2.5884355317079875

Epoch: 6| Step: 11
Training loss: 0.21061499100683131
Validation loss: 2.566479326125134

Epoch: 6| Step: 12
Training loss: 0.1737945288434879
Validation loss: 2.6267521807092593

Epoch: 6| Step: 13
Training loss: 0.32095826578607944
Validation loss: 2.60876666331551

Epoch: 386| Step: 0
Training loss: 0.214478294618738
Validation loss: 2.587637183823199

Epoch: 6| Step: 1
Training loss: 0.44477276132802956
Validation loss: 2.5923620563627607

Epoch: 6| Step: 2
Training loss: 0.3869033526999273
Validation loss: 2.5747678315739617

Epoch: 6| Step: 3
Training loss: 0.13656857962573052
Validation loss: 2.5906124048035584

Epoch: 6| Step: 4
Training loss: 0.376103010836201
Validation loss: 2.6057128319627143

Epoch: 6| Step: 5
Training loss: 0.22024413292557984
Validation loss: 2.571327815091691

Epoch: 6| Step: 6
Training loss: 0.18083986543761768
Validation loss: 2.604503550407165

Epoch: 6| Step: 7
Training loss: 0.4401125559110703
Validation loss: 2.5791219604022033

Epoch: 6| Step: 8
Training loss: 0.21350820015518912
Validation loss: 2.6298805743312967

Epoch: 6| Step: 9
Training loss: 0.34262379479987837
Validation loss: 2.6445324360754583

Epoch: 6| Step: 10
Training loss: 0.45994285985325023
Validation loss: 2.6303194139324253

Epoch: 6| Step: 11
Training loss: 0.26307043073757613
Validation loss: 2.6059430426134185

Epoch: 6| Step: 12
Training loss: 0.31319035331584955
Validation loss: 2.5742122129648326

Epoch: 6| Step: 13
Training loss: 0.15496515463996688
Validation loss: 2.545705211961389

Epoch: 387| Step: 0
Training loss: 0.5577290651555175
Validation loss: 2.533472089493823

Epoch: 6| Step: 1
Training loss: 0.3072592696660887
Validation loss: 2.539543116716949

Epoch: 6| Step: 2
Training loss: 0.4335468369957314
Validation loss: 2.4888852476345082

Epoch: 6| Step: 3
Training loss: 0.2509300545078374
Validation loss: 2.492422628663298

Epoch: 6| Step: 4
Training loss: 0.18587315632162943
Validation loss: 2.503167381438384

Epoch: 6| Step: 5
Training loss: 0.3339987411532407
Validation loss: 2.4965502297015885

Epoch: 6| Step: 6
Training loss: 0.4266934204406042
Validation loss: 2.5066662008869383

Epoch: 6| Step: 7
Training loss: 0.27055723379221913
Validation loss: 2.5224867149326866

Epoch: 6| Step: 8
Training loss: 0.1685896254893194
Validation loss: 2.524005195776791

Epoch: 6| Step: 9
Training loss: 0.2645880429657217
Validation loss: 2.5132286802363812

Epoch: 6| Step: 10
Training loss: 0.18658556078392946
Validation loss: 2.569025463438994

Epoch: 6| Step: 11
Training loss: 0.23124112002618255
Validation loss: 2.619037979115161

Epoch: 6| Step: 12
Training loss: 0.29130345390202467
Validation loss: 2.587694254982484

Epoch: 6| Step: 13
Training loss: 0.38173036018169315
Validation loss: 2.5992050637408894

Epoch: 388| Step: 0
Training loss: 0.2941448636908433
Validation loss: 2.5906369588556037

Epoch: 6| Step: 1
Training loss: 0.23594252599958662
Validation loss: 2.605927427233856

Epoch: 6| Step: 2
Training loss: 0.30136406155817386
Validation loss: 2.5959882936425287

Epoch: 6| Step: 3
Training loss: 0.18681914172485464
Validation loss: 2.574160776554995

Epoch: 6| Step: 4
Training loss: 0.24931471002631528
Validation loss: 2.5602353411170795

Epoch: 6| Step: 5
Training loss: 0.35857613547285716
Validation loss: 2.55242476214643

Epoch: 6| Step: 6
Training loss: 0.26758594919167766
Validation loss: 2.5626838091924347

Epoch: 6| Step: 7
Training loss: 0.40597036714652385
Validation loss: 2.52376663335719

Epoch: 6| Step: 8
Training loss: 0.34086516776486186
Validation loss: 2.534438230598893

Epoch: 6| Step: 9
Training loss: 0.3419814238278678
Validation loss: 2.535601821989987

Epoch: 6| Step: 10
Training loss: 0.24157675520916472
Validation loss: 2.5728291103103524

Epoch: 6| Step: 11
Training loss: 0.24264578374826845
Validation loss: 2.5907974299978

Epoch: 6| Step: 12
Training loss: 0.33345110744822093
Validation loss: 2.628074203366499

Epoch: 6| Step: 13
Training loss: 0.5860101527629975
Validation loss: 2.6380725127449587

Epoch: 389| Step: 0
Training loss: 0.31448655513504886
Validation loss: 2.6393888953668476

Epoch: 6| Step: 1
Training loss: 0.253739008477531
Validation loss: 2.6200689257437215

Epoch: 6| Step: 2
Training loss: 0.5394672864288504
Validation loss: 2.6007533903242694

Epoch: 6| Step: 3
Training loss: 0.40142990698917064
Validation loss: 2.622197301071949

Epoch: 6| Step: 4
Training loss: 0.2642425577817336
Validation loss: 2.5950841041264163

Epoch: 6| Step: 5
Training loss: 0.2624976964122876
Validation loss: 2.579821937814327

Epoch: 6| Step: 6
Training loss: 0.30400647567609207
Validation loss: 2.627978750661445

Epoch: 6| Step: 7
Training loss: 0.4686478662485614
Validation loss: 2.567231616743726

Epoch: 6| Step: 8
Training loss: 0.36919677145911217
Validation loss: 2.559451210633915

Epoch: 6| Step: 9
Training loss: 0.5133735167373025
Validation loss: 2.5880204566092813

Epoch: 6| Step: 10
Training loss: 0.28193014081340867
Validation loss: 2.5660760449541913

Epoch: 6| Step: 11
Training loss: 0.21421150465161554
Validation loss: 2.5666294754694103

Epoch: 6| Step: 12
Training loss: 0.2611182283652896
Validation loss: 2.5381326850594395

Epoch: 6| Step: 13
Training loss: 0.4531544478483006
Validation loss: 2.5205555919357385

Epoch: 390| Step: 0
Training loss: 0.4220845443818674
Validation loss: 2.5160965444109737

Epoch: 6| Step: 1
Training loss: 0.37696431197727637
Validation loss: 2.5506293294554436

Epoch: 6| Step: 2
Training loss: 0.11712489840208958
Validation loss: 2.560145613361091

Epoch: 6| Step: 3
Training loss: 0.5181931781892493
Validation loss: 2.594038706947373

Epoch: 6| Step: 4
Training loss: 0.4659930854456276
Validation loss: 2.6456330597992634

Epoch: 6| Step: 5
Training loss: 0.4661387189041605
Validation loss: 2.59603094807997

Epoch: 6| Step: 6
Training loss: 0.24583938865289154
Validation loss: 2.5730113456742507

Epoch: 6| Step: 7
Training loss: 0.29796453115900223
Validation loss: 2.575507742298564

Epoch: 6| Step: 8
Training loss: 0.39886156590192845
Validation loss: 2.557121393656765

Epoch: 6| Step: 9
Training loss: 0.41512565158332243
Validation loss: 2.560144736165056

Epoch: 6| Step: 10
Training loss: 0.4924698277249911
Validation loss: 2.549718436553421

Epoch: 6| Step: 11
Training loss: 0.41938786818067003
Validation loss: 2.542944084995379

Epoch: 6| Step: 12
Training loss: 0.33437803837474195
Validation loss: 2.519978969763421

Epoch: 6| Step: 13
Training loss: 0.23380222267582385
Validation loss: 2.5151902199306497

Epoch: 391| Step: 0
Training loss: 0.2543750250251626
Validation loss: 2.5508052161034858

Epoch: 6| Step: 1
Training loss: 0.28721339099721094
Validation loss: 2.5648339080399323

Epoch: 6| Step: 2
Training loss: 0.4109440821131384
Validation loss: 2.563844554640187

Epoch: 6| Step: 3
Training loss: 0.4650857119371542
Validation loss: 2.5715184917490554

Epoch: 6| Step: 4
Training loss: 0.565001963384137
Validation loss: 2.5526804575569977

Epoch: 6| Step: 5
Training loss: 0.3828252868073821
Validation loss: 2.5398131648724043

Epoch: 6| Step: 6
Training loss: 0.21800189159386324
Validation loss: 2.546719631214905

Epoch: 6| Step: 7
Training loss: 0.22853512150987765
Validation loss: 2.5078980935325808

Epoch: 6| Step: 8
Training loss: 0.4099135634559528
Validation loss: 2.483788232486844

Epoch: 6| Step: 9
Training loss: 0.28644162331596706
Validation loss: 2.515486304555782

Epoch: 6| Step: 10
Training loss: 0.24749518791973046
Validation loss: 2.511954897869968

Epoch: 6| Step: 11
Training loss: 0.26465380054402926
Validation loss: 2.4888360093813677

Epoch: 6| Step: 12
Training loss: 0.43279972057549454
Validation loss: 2.492024852573058

Epoch: 6| Step: 13
Training loss: 0.35821343410221196
Validation loss: 2.449461169337865

Epoch: 392| Step: 0
Training loss: 0.4548216985495991
Validation loss: 2.5201518909730263

Epoch: 6| Step: 1
Training loss: 0.2757580382653141
Validation loss: 2.513295169839347

Epoch: 6| Step: 2
Training loss: 0.2860729949189505
Validation loss: 2.566532912229802

Epoch: 6| Step: 3
Training loss: 0.3162763823560647
Validation loss: 2.569795170151574

Epoch: 6| Step: 4
Training loss: 0.3935015621251239
Validation loss: 2.566296783753357

Epoch: 6| Step: 5
Training loss: 0.28067739796132724
Validation loss: 2.6159697313530414

Epoch: 6| Step: 6
Training loss: 0.3324149551298928
Validation loss: 2.564750913327237

Epoch: 6| Step: 7
Training loss: 0.15255128955558578
Validation loss: 2.5364009601968487

Epoch: 6| Step: 8
Training loss: 0.35710371688536413
Validation loss: 2.5268032585648483

Epoch: 6| Step: 9
Training loss: 0.32570354166093446
Validation loss: 2.530801435310737

Epoch: 6| Step: 10
Training loss: 0.40619138148023826
Validation loss: 2.5602296986159123

Epoch: 6| Step: 11
Training loss: 0.3798151029441417
Validation loss: 2.534624894085143

Epoch: 6| Step: 12
Training loss: 0.3466496736670762
Validation loss: 2.5488481667211214

Epoch: 6| Step: 13
Training loss: 0.23722462029418162
Validation loss: 2.5265452705106477

Epoch: 393| Step: 0
Training loss: 0.2804198198486015
Validation loss: 2.545301851287461

Epoch: 6| Step: 1
Training loss: 0.4497287508910383
Validation loss: 2.5750060570145137

Epoch: 6| Step: 2
Training loss: 0.4224020526708774
Validation loss: 2.5761549675887556

Epoch: 6| Step: 3
Training loss: 0.1820439813115596
Validation loss: 2.6092831037468125

Epoch: 6| Step: 4
Training loss: 0.27006792459158074
Validation loss: 2.6210835564254062

Epoch: 6| Step: 5
Training loss: 0.2964052951779267
Validation loss: 2.5939487263033163

Epoch: 6| Step: 6
Training loss: 0.2787662213356914
Validation loss: 2.587627244836231

Epoch: 6| Step: 7
Training loss: 0.38112992678417096
Validation loss: 2.6164827982777314

Epoch: 6| Step: 8
Training loss: 0.24035291150906557
Validation loss: 2.6186512330829332

Epoch: 6| Step: 9
Training loss: 0.27796487699386857
Validation loss: 2.6119749603092024

Epoch: 6| Step: 10
Training loss: 0.3797876390811023
Validation loss: 2.579200447234108

Epoch: 6| Step: 11
Training loss: 0.481215230503189
Validation loss: 2.5933435757672907

Epoch: 6| Step: 12
Training loss: 0.18683426607609777
Validation loss: 2.569774838880258

Epoch: 6| Step: 13
Training loss: 0.15842194200531826
Validation loss: 2.54797844179052

Epoch: 394| Step: 0
Training loss: 0.3978230094869939
Validation loss: 2.573863264659898

Epoch: 6| Step: 1
Training loss: 0.22300542255830877
Validation loss: 2.5804746340097418

Epoch: 6| Step: 2
Training loss: 0.3685902726420515
Validation loss: 2.551629516620906

Epoch: 6| Step: 3
Training loss: 0.23532494517138994
Validation loss: 2.55534321161892

Epoch: 6| Step: 4
Training loss: 0.2960296944048116
Validation loss: 2.53342765900738

Epoch: 6| Step: 5
Training loss: 0.44735393735083007
Validation loss: 2.517156843969833

Epoch: 6| Step: 6
Training loss: 0.34097042985903864
Validation loss: 2.5426842078065626

Epoch: 6| Step: 7
Training loss: 0.33214542445422607
Validation loss: 2.5007374680717587

Epoch: 6| Step: 8
Training loss: 0.3242091901357916
Validation loss: 2.5351013817768435

Epoch: 6| Step: 9
Training loss: 0.3370762089297457
Validation loss: 2.5830597674765503

Epoch: 6| Step: 10
Training loss: 0.4370857559654558
Validation loss: 2.5572004760405425

Epoch: 6| Step: 11
Training loss: 0.23671473257350864
Validation loss: 2.540271402961077

Epoch: 6| Step: 12
Training loss: 0.27937558538900403
Validation loss: 2.533253593706471

Epoch: 6| Step: 13
Training loss: 0.20810343554759742
Validation loss: 2.575713862879044

Epoch: 395| Step: 0
Training loss: 0.2961093918586627
Validation loss: 2.5384641562330823

Epoch: 6| Step: 1
Training loss: 0.2686525201328909
Validation loss: 2.574408810724648

Epoch: 6| Step: 2
Training loss: 0.2850729546322434
Validation loss: 2.55438654730242

Epoch: 6| Step: 3
Training loss: 0.27461788983662316
Validation loss: 2.520018398475252

Epoch: 6| Step: 4
Training loss: 0.1509304452416328
Validation loss: 2.5688899944071952

Epoch: 6| Step: 5
Training loss: 0.4025819684316536
Validation loss: 2.5149824427152465

Epoch: 6| Step: 6
Training loss: 0.3641571233024133
Validation loss: 2.5225002679625796

Epoch: 6| Step: 7
Training loss: 0.24777159847591607
Validation loss: 2.5098743648664783

Epoch: 6| Step: 8
Training loss: 0.3248537578206297
Validation loss: 2.5259729005371625

Epoch: 6| Step: 9
Training loss: 0.25184574352478417
Validation loss: 2.5482723676386567

Epoch: 6| Step: 10
Training loss: 0.3951061705459613
Validation loss: 2.5396741954702526

Epoch: 6| Step: 11
Training loss: 0.44016799426296865
Validation loss: 2.578054513275347

Epoch: 6| Step: 12
Training loss: 0.1880907646344099
Validation loss: 2.5456922673673508

Epoch: 6| Step: 13
Training loss: 0.31651729236462467
Validation loss: 2.5749130571252827

Epoch: 396| Step: 0
Training loss: 0.4045912550842434
Validation loss: 2.5025719830540587

Epoch: 6| Step: 1
Training loss: 0.3161165771689662
Validation loss: 2.500263464796302

Epoch: 6| Step: 2
Training loss: 0.266123542237847
Validation loss: 2.494219439439114

Epoch: 6| Step: 3
Training loss: 0.28425004750086136
Validation loss: 2.496725803449625

Epoch: 6| Step: 4
Training loss: 0.3842644695369622
Validation loss: 2.496557439368231

Epoch: 6| Step: 5
Training loss: 0.3293353871623823
Validation loss: 2.4954085179054584

Epoch: 6| Step: 6
Training loss: 0.26398096688072475
Validation loss: 2.494125139133111

Epoch: 6| Step: 7
Training loss: 0.43059812633555916
Validation loss: 2.561325954801472

Epoch: 6| Step: 8
Training loss: 0.3058709124146631
Validation loss: 2.6067505616337012

Epoch: 6| Step: 9
Training loss: 0.27889903617526846
Validation loss: 2.632180373045669

Epoch: 6| Step: 10
Training loss: 0.3760181750764496
Validation loss: 2.64947305410014

Epoch: 6| Step: 11
Training loss: 0.2747606688207832
Validation loss: 2.6224691023913134

Epoch: 6| Step: 12
Training loss: 0.3119435840411581
Validation loss: 2.6429719736857273

Epoch: 6| Step: 13
Training loss: 0.11676794287036073
Validation loss: 2.624348912746193

Epoch: 397| Step: 0
Training loss: 0.1636876012216279
Validation loss: 2.5796637434319036

Epoch: 6| Step: 1
Training loss: 0.21384030874299426
Validation loss: 2.62332829237943

Epoch: 6| Step: 2
Training loss: 0.1904494250901534
Validation loss: 2.5824945446320866

Epoch: 6| Step: 3
Training loss: 0.1797039604940413
Validation loss: 2.577328231860246

Epoch: 6| Step: 4
Training loss: 0.4291344638273152
Validation loss: 2.543971403815324

Epoch: 6| Step: 5
Training loss: 0.39934839580916254
Validation loss: 2.539147624694202

Epoch: 6| Step: 6
Training loss: 0.2953009789858517
Validation loss: 2.496968550002949

Epoch: 6| Step: 7
Training loss: 0.30504047293330233
Validation loss: 2.5069888317444917

Epoch: 6| Step: 8
Training loss: 0.3271448733007512
Validation loss: 2.476826898067078

Epoch: 6| Step: 9
Training loss: 0.15360873119214288
Validation loss: 2.529017572109705

Epoch: 6| Step: 10
Training loss: 0.4060927967208588
Validation loss: 2.4901124314159735

Epoch: 6| Step: 11
Training loss: 0.25621790917588105
Validation loss: 2.5312569923360004

Epoch: 6| Step: 12
Training loss: 0.43672455457948217
Validation loss: 2.567216741536794

Epoch: 6| Step: 13
Training loss: 0.21457641615104187
Validation loss: 2.5614518033396854

Epoch: 398| Step: 0
Training loss: 0.28511138458555574
Validation loss: 2.538958005056451

Epoch: 6| Step: 1
Training loss: 0.29914323237257406
Validation loss: 2.56444495357673

Epoch: 6| Step: 2
Training loss: 0.3323025436574359
Validation loss: 2.5997848086049897

Epoch: 6| Step: 3
Training loss: 0.24770030643642846
Validation loss: 2.606237355292036

Epoch: 6| Step: 4
Training loss: 0.30914808534726157
Validation loss: 2.603131082846744

Epoch: 6| Step: 5
Training loss: 0.27490861794068866
Validation loss: 2.6266416083872373

Epoch: 6| Step: 6
Training loss: 0.22750169013254917
Validation loss: 2.639983668523859

Epoch: 6| Step: 7
Training loss: 0.2705583490752519
Validation loss: 2.617152260800377

Epoch: 6| Step: 8
Training loss: 0.40105899756829677
Validation loss: 2.6001778875413986

Epoch: 6| Step: 9
Training loss: 0.24621231008513528
Validation loss: 2.6084803913827885

Epoch: 6| Step: 10
Training loss: 0.17801565402892974
Validation loss: 2.595117460784579

Epoch: 6| Step: 11
Training loss: 0.4115136708900714
Validation loss: 2.535427149628971

Epoch: 6| Step: 12
Training loss: 0.2631795454687053
Validation loss: 2.5497285494529502

Epoch: 6| Step: 13
Training loss: 0.4840414375367462
Validation loss: 2.567172416983382

Epoch: 399| Step: 0
Training loss: 0.25216206307683225
Validation loss: 2.556733163505861

Epoch: 6| Step: 1
Training loss: 0.30958116674798886
Validation loss: 2.538614583606227

Epoch: 6| Step: 2
Training loss: 0.22615395081276307
Validation loss: 2.561913897228687

Epoch: 6| Step: 3
Training loss: 0.2027626657316315
Validation loss: 2.5279658767934365

Epoch: 6| Step: 4
Training loss: 0.26097112598874694
Validation loss: 2.5724795961961533

Epoch: 6| Step: 5
Training loss: 0.3932036355763953
Validation loss: 2.540920304996105

Epoch: 6| Step: 6
Training loss: 0.3632509567592069
Validation loss: 2.5858104439020897

Epoch: 6| Step: 7
Training loss: 0.34943205316413034
Validation loss: 2.5569629317968436

Epoch: 6| Step: 8
Training loss: 0.3014653340871053
Validation loss: 2.599311883642872

Epoch: 6| Step: 9
Training loss: 0.35373103707645803
Validation loss: 2.5992218813808936

Epoch: 6| Step: 10
Training loss: 0.21242121470139336
Validation loss: 2.5815515125728132

Epoch: 6| Step: 11
Training loss: 0.34389348720039037
Validation loss: 2.6091130831171157

Epoch: 6| Step: 12
Training loss: 0.20709394909060666
Validation loss: 2.544029286258127

Epoch: 6| Step: 13
Training loss: 0.3274407632231549
Validation loss: 2.5615494628610995

Epoch: 400| Step: 0
Training loss: 0.4792364957625151
Validation loss: 2.527704445473396

Epoch: 6| Step: 1
Training loss: 0.18492387281401534
Validation loss: 2.5493174224276465

Epoch: 6| Step: 2
Training loss: 0.27771496443380655
Validation loss: 2.516662424506763

Epoch: 6| Step: 3
Training loss: 0.19331363175434246
Validation loss: 2.547735325730286

Epoch: 6| Step: 4
Training loss: 0.3182279865640506
Validation loss: 2.5549271417127075

Epoch: 6| Step: 5
Training loss: 0.2801460082761218
Validation loss: 2.553827371838713

Epoch: 6| Step: 6
Training loss: 0.2973836256061453
Validation loss: 2.5588054720618296

Epoch: 6| Step: 7
Training loss: 0.18119763119280255
Validation loss: 2.5960544841060558

Epoch: 6| Step: 8
Training loss: 0.2326645585902125
Validation loss: 2.5276219862637834

Epoch: 6| Step: 9
Training loss: 0.13507104900352812
Validation loss: 2.5714817743157594

Epoch: 6| Step: 10
Training loss: 0.46447760322560333
Validation loss: 2.573879222477735

Epoch: 6| Step: 11
Training loss: 0.22076846311814244
Validation loss: 2.569931778555923

Epoch: 6| Step: 12
Training loss: 0.20060528900492008
Validation loss: 2.541175571594148

Epoch: 6| Step: 13
Training loss: 0.16064228763578872
Validation loss: 2.5463926390884626

Epoch: 401| Step: 0
Training loss: 0.3052700782049228
Validation loss: 2.5072510969134787

Epoch: 6| Step: 1
Training loss: 0.29121039100764556
Validation loss: 2.5372149999425107

Epoch: 6| Step: 2
Training loss: 0.32699850261998675
Validation loss: 2.4831435260745613

Epoch: 6| Step: 3
Training loss: 0.29949097264557056
Validation loss: 2.487943647800213

Epoch: 6| Step: 4
Training loss: 0.19217910244280934
Validation loss: 2.5294444456803675

Epoch: 6| Step: 5
Training loss: 0.14010713510902068
Validation loss: 2.5404763247649624

Epoch: 6| Step: 6
Training loss: 0.40167996362121877
Validation loss: 2.5792955154623813

Epoch: 6| Step: 7
Training loss: 0.41920665778977345
Validation loss: 2.5530419497863543

Epoch: 6| Step: 8
Training loss: 0.23138452689384542
Validation loss: 2.593892233554268

Epoch: 6| Step: 9
Training loss: 0.17068682512026287
Validation loss: 2.584721786226766

Epoch: 6| Step: 10
Training loss: 0.2729319121686551
Validation loss: 2.5989876900689195

Epoch: 6| Step: 11
Training loss: 0.30805156254327964
Validation loss: 2.622812442200481

Epoch: 6| Step: 12
Training loss: 0.18611074398864133
Validation loss: 2.582256921185315

Epoch: 6| Step: 13
Training loss: 0.18761445565491422
Validation loss: 2.5642775681278636

Epoch: 402| Step: 0
Training loss: 0.29718484520353156
Validation loss: 2.5870434446686428

Epoch: 6| Step: 1
Training loss: 0.368953697872642
Validation loss: 2.610246828668019

Epoch: 6| Step: 2
Training loss: 0.31670417417118807
Validation loss: 2.589648620008469

Epoch: 6| Step: 3
Training loss: 0.2405171319773947
Validation loss: 2.570904089133697

Epoch: 6| Step: 4
Training loss: 0.2618814219049273
Validation loss: 2.557939770134566

Epoch: 6| Step: 5
Training loss: 0.2744117139396761
Validation loss: 2.509459925486025

Epoch: 6| Step: 6
Training loss: 0.2432152261489762
Validation loss: 2.5386254749030472

Epoch: 6| Step: 7
Training loss: 0.2537119782436013
Validation loss: 2.540707009788798

Epoch: 6| Step: 8
Training loss: 0.29015030959071897
Validation loss: 2.5397983148071264

Epoch: 6| Step: 9
Training loss: 0.21542367693348793
Validation loss: 2.495453279868684

Epoch: 6| Step: 10
Training loss: 0.3049221724543683
Validation loss: 2.498720676455027

Epoch: 6| Step: 11
Training loss: 0.4147650678195829
Validation loss: 2.5655778358331793

Epoch: 6| Step: 12
Training loss: 0.27366484319096424
Validation loss: 2.57366186533755

Epoch: 6| Step: 13
Training loss: 0.21993195153251635
Validation loss: 2.5649117476269887

Epoch: 403| Step: 0
Training loss: 0.13589096149649862
Validation loss: 2.551201956772008

Epoch: 6| Step: 1
Training loss: 0.3357135891454218
Validation loss: 2.6025768311534767

Epoch: 6| Step: 2
Training loss: 0.18668893392476402
Validation loss: 2.5514982221204217

Epoch: 6| Step: 3
Training loss: 0.2506499038604409
Validation loss: 2.523845394166409

Epoch: 6| Step: 4
Training loss: 0.22481413919976992
Validation loss: 2.56977723215259

Epoch: 6| Step: 5
Training loss: 0.3257963794515861
Validation loss: 2.558864968585064

Epoch: 6| Step: 6
Training loss: 0.27768930211621135
Validation loss: 2.5465644663721743

Epoch: 6| Step: 7
Training loss: 0.28058654627892604
Validation loss: 2.543938645269935

Epoch: 6| Step: 8
Training loss: 0.48398742243782594
Validation loss: 2.538798211591283

Epoch: 6| Step: 9
Training loss: 0.3167976266496916
Validation loss: 2.5696556473075307

Epoch: 6| Step: 10
Training loss: 0.25020963105228605
Validation loss: 2.544923005756116

Epoch: 6| Step: 11
Training loss: 0.18674721201637395
Validation loss: 2.5516569158447973

Epoch: 6| Step: 12
Training loss: 0.2822603911614882
Validation loss: 2.565355212391131

Epoch: 6| Step: 13
Training loss: 0.1717892617173271
Validation loss: 2.60660887431813

Epoch: 404| Step: 0
Training loss: 0.3352606630741715
Validation loss: 2.6081482689092317

Epoch: 6| Step: 1
Training loss: 0.3030825059148049
Validation loss: 2.6188574351073948

Epoch: 6| Step: 2
Training loss: 0.3005358202462705
Validation loss: 2.601213544073588

Epoch: 6| Step: 3
Training loss: 0.1815997559705168
Validation loss: 2.600428790865235

Epoch: 6| Step: 4
Training loss: 0.4082004966833746
Validation loss: 2.5948547850062935

Epoch: 6| Step: 5
Training loss: 0.27642208403351465
Validation loss: 2.5876683201871606

Epoch: 6| Step: 6
Training loss: 0.18996587169152832
Validation loss: 2.5657776380677833

Epoch: 6| Step: 7
Training loss: 0.07392018900472327
Validation loss: 2.542841252757109

Epoch: 6| Step: 8
Training loss: 0.25907589832902206
Validation loss: 2.5722942226280083

Epoch: 6| Step: 9
Training loss: 0.2882611792382488
Validation loss: 2.5619432443274293

Epoch: 6| Step: 10
Training loss: 0.23398892075034805
Validation loss: 2.5480516258534354

Epoch: 6| Step: 11
Training loss: 0.20208112545052653
Validation loss: 2.52486549111767

Epoch: 6| Step: 12
Training loss: 0.33319334975076875
Validation loss: 2.5717924871418445

Epoch: 6| Step: 13
Training loss: 0.169453858804411
Validation loss: 2.576699115597831

Epoch: 405| Step: 0
Training loss: 0.20148621231785604
Validation loss: 2.551165520726893

Epoch: 6| Step: 1
Training loss: 0.3044733370756754
Validation loss: 2.6159854024268

Epoch: 6| Step: 2
Training loss: 0.26425062171191627
Validation loss: 2.5776561242331737

Epoch: 6| Step: 3
Training loss: 0.2863048517987257
Validation loss: 2.5788489927680844

Epoch: 6| Step: 4
Training loss: 0.16645167809726513
Validation loss: 2.598081268913687

Epoch: 6| Step: 5
Training loss: 0.16960302670483898
Validation loss: 2.549821327250599

Epoch: 6| Step: 6
Training loss: 0.1693613629464213
Validation loss: 2.5849539634892884

Epoch: 6| Step: 7
Training loss: 0.22907917924761595
Validation loss: 2.5779328752901227

Epoch: 6| Step: 8
Training loss: 0.2835341262141737
Validation loss: 2.581484499881185

Epoch: 6| Step: 9
Training loss: 0.458482768522253
Validation loss: 2.5752961699378702

Epoch: 6| Step: 10
Training loss: 0.33634069554388846
Validation loss: 2.56797244000762

Epoch: 6| Step: 11
Training loss: 0.36737777974211816
Validation loss: 2.5252581896179254

Epoch: 6| Step: 12
Training loss: 0.2539195864182696
Validation loss: 2.564043179146572

Epoch: 6| Step: 13
Training loss: 0.23624769528844175
Validation loss: 2.5084082237998295

Epoch: 406| Step: 0
Training loss: 0.20281484656894053
Validation loss: 2.4776896806872952

Epoch: 6| Step: 1
Training loss: 0.24455014024840446
Validation loss: 2.4776724137210837

Epoch: 6| Step: 2
Training loss: 0.29458320827202705
Validation loss: 2.4383101199061046

Epoch: 6| Step: 3
Training loss: 0.3702178254607406
Validation loss: 2.4911006388969925

Epoch: 6| Step: 4
Training loss: 0.19662812588432638
Validation loss: 2.481240844709672

Epoch: 6| Step: 5
Training loss: 0.29951744111437006
Validation loss: 2.497193127713597

Epoch: 6| Step: 6
Training loss: 0.41222788476239386
Validation loss: 2.5315583230045937

Epoch: 6| Step: 7
Training loss: 0.1665231352411185
Validation loss: 2.5350548978820866

Epoch: 6| Step: 8
Training loss: 0.18577288866276848
Validation loss: 2.551015914351335

Epoch: 6| Step: 9
Training loss: 0.2154964156920366
Validation loss: 2.5244203009476456

Epoch: 6| Step: 10
Training loss: 0.41152715912137733
Validation loss: 2.5735365625817943

Epoch: 6| Step: 11
Training loss: 0.18378410211045249
Validation loss: 2.574050548516424

Epoch: 6| Step: 12
Training loss: 0.21452397911381
Validation loss: 2.569569964910348

Epoch: 6| Step: 13
Training loss: 0.286160099954713
Validation loss: 2.5564292130233435

Epoch: 407| Step: 0
Training loss: 0.158061611791478
Validation loss: 2.5790178907461954

Epoch: 6| Step: 1
Training loss: 0.2275996884633624
Validation loss: 2.537281241899171

Epoch: 6| Step: 2
Training loss: 0.3737930703942414
Validation loss: 2.523233962027893

Epoch: 6| Step: 3
Training loss: 0.25117762189730464
Validation loss: 2.549858969886922

Epoch: 6| Step: 4
Training loss: 0.30401186738096425
Validation loss: 2.5286815114399697

Epoch: 6| Step: 5
Training loss: 0.2813736855549489
Validation loss: 2.5269280030033725

Epoch: 6| Step: 6
Training loss: 0.3191570515881688
Validation loss: 2.539210775256585

Epoch: 6| Step: 7
Training loss: 0.224543653077894
Validation loss: 2.5554033199596122

Epoch: 6| Step: 8
Training loss: 0.3488359260327555
Validation loss: 2.543041843597336

Epoch: 6| Step: 9
Training loss: 0.1400507487125533
Validation loss: 2.5464726184363884

Epoch: 6| Step: 10
Training loss: 0.41656089473337793
Validation loss: 2.5596975243195086

Epoch: 6| Step: 11
Training loss: 0.18612503523855087
Validation loss: 2.6006604205234845

Epoch: 6| Step: 12
Training loss: 0.28231160819550616
Validation loss: 2.586490296538721

Epoch: 6| Step: 13
Training loss: 0.40078563278805984
Validation loss: 2.539437618895666

Epoch: 408| Step: 0
Training loss: 0.20214567320771887
Validation loss: 2.581450114981904

Epoch: 6| Step: 1
Training loss: 0.3335689839230925
Validation loss: 2.575586780213233

Epoch: 6| Step: 2
Training loss: 0.16124759400591
Validation loss: 2.5985761394274687

Epoch: 6| Step: 3
Training loss: 0.16027550792914094
Validation loss: 2.559627947860479

Epoch: 6| Step: 4
Training loss: 0.23147228743696965
Validation loss: 2.5683451431561974

Epoch: 6| Step: 5
Training loss: 0.2612763551715035
Validation loss: 2.589081586818074

Epoch: 6| Step: 6
Training loss: 0.1691388581604332
Validation loss: 2.585710620707969

Epoch: 6| Step: 7
Training loss: 0.2629988664323433
Validation loss: 2.6018020045155352

Epoch: 6| Step: 8
Training loss: 0.4059642740630843
Validation loss: 2.6066216265509246

Epoch: 6| Step: 9
Training loss: 0.46366868439808284
Validation loss: 2.6129810807035634

Epoch: 6| Step: 10
Training loss: 0.35539613757634875
Validation loss: 2.592910785025486

Epoch: 6| Step: 11
Training loss: 0.23646580019825414
Validation loss: 2.583726817903465

Epoch: 6| Step: 12
Training loss: 0.24312728389216418
Validation loss: 2.535033639756356

Epoch: 6| Step: 13
Training loss: 0.21672723699892196
Validation loss: 2.5840875442259135

Epoch: 409| Step: 0
Training loss: 0.3506854986501832
Validation loss: 2.5339358558298635

Epoch: 6| Step: 1
Training loss: 0.184412682044695
Validation loss: 2.5351287078334632

Epoch: 6| Step: 2
Training loss: 0.12164889645613924
Validation loss: 2.5353242531634863

Epoch: 6| Step: 3
Training loss: 0.286219209510092
Validation loss: 2.554932837064168

Epoch: 6| Step: 4
Training loss: 0.3018063132804721
Validation loss: 2.561862871352444

Epoch: 6| Step: 5
Training loss: 0.29573291139738817
Validation loss: 2.566208389813041

Epoch: 6| Step: 6
Training loss: 0.3846737321052424
Validation loss: 2.547906400653337

Epoch: 6| Step: 7
Training loss: 0.22780012944860858
Validation loss: 2.5768849482819616

Epoch: 6| Step: 8
Training loss: 0.22843039789914235
Validation loss: 2.593892620982489

Epoch: 6| Step: 9
Training loss: 0.34979276269366505
Validation loss: 2.5864440047185404

Epoch: 6| Step: 10
Training loss: 0.16607784900288838
Validation loss: 2.5976239355598425

Epoch: 6| Step: 11
Training loss: 0.20975523342200963
Validation loss: 2.588943380617714

Epoch: 6| Step: 12
Training loss: 0.3118479601924375
Validation loss: 2.5747740774567958

Epoch: 6| Step: 13
Training loss: 0.1415561669029879
Validation loss: 2.5604602710248967

Epoch: 410| Step: 0
Training loss: 0.2790514928434693
Validation loss: 2.5572040194395185

Epoch: 6| Step: 1
Training loss: 0.16713756234382743
Validation loss: 2.5389183408643423

Epoch: 6| Step: 2
Training loss: 0.22407271085268046
Validation loss: 2.551288065120048

Epoch: 6| Step: 3
Training loss: 0.4369713450274767
Validation loss: 2.5348969124055287

Epoch: 6| Step: 4
Training loss: 0.2733417343286876
Validation loss: 2.5101790048662522

Epoch: 6| Step: 5
Training loss: 0.27893277424153934
Validation loss: 2.4887303594382844

Epoch: 6| Step: 6
Training loss: 0.17653762950265822
Validation loss: 2.5584910106846066

Epoch: 6| Step: 7
Training loss: 0.3249472281820703
Validation loss: 2.5368074061228616

Epoch: 6| Step: 8
Training loss: 0.1545693490569789
Validation loss: 2.5721281877034228

Epoch: 6| Step: 9
Training loss: 0.40735161414125703
Validation loss: 2.5734887412313006

Epoch: 6| Step: 10
Training loss: 0.25639953088412465
Validation loss: 2.5752763539542087

Epoch: 6| Step: 11
Training loss: 0.18426142685988323
Validation loss: 2.5910721056281

Epoch: 6| Step: 12
Training loss: 0.18956097747878028
Validation loss: 2.6070634293893624

Epoch: 6| Step: 13
Training loss: 0.26795360922787737
Validation loss: 2.59356384953566

Epoch: 411| Step: 0
Training loss: 0.2943789303268176
Validation loss: 2.5797410282263344

Epoch: 6| Step: 1
Training loss: 0.40379582561339883
Validation loss: 2.5433076432622324

Epoch: 6| Step: 2
Training loss: 0.41411189018636874
Validation loss: 2.529063631751099

Epoch: 6| Step: 3
Training loss: 0.2929772566514026
Validation loss: 2.536077948725515

Epoch: 6| Step: 4
Training loss: 0.142438598190868
Validation loss: 2.495964403203411

Epoch: 6| Step: 5
Training loss: 0.17544501784449767
Validation loss: 2.5162046770075155

Epoch: 6| Step: 6
Training loss: 0.35026820669291847
Validation loss: 2.473796615280349

Epoch: 6| Step: 7
Training loss: 0.2310856386480221
Validation loss: 2.459373563412245

Epoch: 6| Step: 8
Training loss: 0.19439263211708824
Validation loss: 2.500433711916109

Epoch: 6| Step: 9
Training loss: 0.17844887576944846
Validation loss: 2.507571199876233

Epoch: 6| Step: 10
Training loss: 0.3626336098128476
Validation loss: 2.527820556445722

Epoch: 6| Step: 11
Training loss: 0.2726834663426773
Validation loss: 2.547048440394365

Epoch: 6| Step: 12
Training loss: 0.22649620171334772
Validation loss: 2.5282737242108144

Epoch: 6| Step: 13
Training loss: 0.1724535243859332
Validation loss: 2.5659050217184145

Epoch: 412| Step: 0
Training loss: 0.3986380390308687
Validation loss: 2.5731948473649697

Epoch: 6| Step: 1
Training loss: 0.19058887968081248
Validation loss: 2.575385353415945

Epoch: 6| Step: 2
Training loss: 0.28441611349096935
Validation loss: 2.6074791797232275

Epoch: 6| Step: 3
Training loss: 0.1452832633519213
Validation loss: 2.633366246080725

Epoch: 6| Step: 4
Training loss: 0.22244830208681504
Validation loss: 2.61721563616441

Epoch: 6| Step: 5
Training loss: 0.420280888584721
Validation loss: 2.619329764853811

Epoch: 6| Step: 6
Training loss: 0.29326731409406237
Validation loss: 2.5737960672319007

Epoch: 6| Step: 7
Training loss: 0.20452181429331592
Validation loss: 2.5949171029831435

Epoch: 6| Step: 8
Training loss: 0.17310855102205233
Validation loss: 2.5601932538669394

Epoch: 6| Step: 9
Training loss: 0.41202386990513656
Validation loss: 2.5925960526363525

Epoch: 6| Step: 10
Training loss: 0.1701069240780686
Validation loss: 2.519829482978052

Epoch: 6| Step: 11
Training loss: 0.2745540438347805
Validation loss: 2.546305178668938

Epoch: 6| Step: 12
Training loss: 0.28136815132506693
Validation loss: 2.4890397708521106

Epoch: 6| Step: 13
Training loss: 0.1898306692977934
Validation loss: 2.537018488549981

Epoch: 413| Step: 0
Training loss: 0.2369031688201489
Validation loss: 2.5153340830222635

Epoch: 6| Step: 1
Training loss: 0.29655612584972735
Validation loss: 2.578708959665889

Epoch: 6| Step: 2
Training loss: 0.09676476790462664
Validation loss: 2.5686986620430914

Epoch: 6| Step: 3
Training loss: 0.3621512445401321
Validation loss: 2.587811186196754

Epoch: 6| Step: 4
Training loss: 0.38872366708699563
Validation loss: 2.587179956849823

Epoch: 6| Step: 5
Training loss: 0.2748938740430024
Validation loss: 2.6277768048183443

Epoch: 6| Step: 6
Training loss: 0.32506943749533707
Validation loss: 2.612185383402082

Epoch: 6| Step: 7
Training loss: 0.3054796948630737
Validation loss: 2.586581191780471

Epoch: 6| Step: 8
Training loss: 0.33031518312517544
Validation loss: 2.5837478222479047

Epoch: 6| Step: 9
Training loss: 0.3179085470656759
Validation loss: 2.5766215972828173

Epoch: 6| Step: 10
Training loss: 0.27364935161263537
Validation loss: 2.5663188917522763

Epoch: 6| Step: 11
Training loss: 0.343297964599847
Validation loss: 2.542389356595581

Epoch: 6| Step: 12
Training loss: 0.3583808499628174
Validation loss: 2.529352850260366

Epoch: 6| Step: 13
Training loss: 0.16755564478831392
Validation loss: 2.5549358061473955

Epoch: 414| Step: 0
Training loss: 0.34036058828766935
Validation loss: 2.5511245550535993

Epoch: 6| Step: 1
Training loss: 0.17394174120252523
Validation loss: 2.567955075290115

Epoch: 6| Step: 2
Training loss: 0.23594569956192377
Validation loss: 2.6085435676107016

Epoch: 6| Step: 3
Training loss: 0.33504856398137667
Validation loss: 2.589624582752339

Epoch: 6| Step: 4
Training loss: 0.25815848052572726
Validation loss: 2.599998543299542

Epoch: 6| Step: 5
Training loss: 0.23611615660986093
Validation loss: 2.5661100194539457

Epoch: 6| Step: 6
Training loss: 0.29649200329120623
Validation loss: 2.561496544148905

Epoch: 6| Step: 7
Training loss: 0.21647417262639845
Validation loss: 2.560634173864492

Epoch: 6| Step: 8
Training loss: 0.4141143370515557
Validation loss: 2.5367189568118107

Epoch: 6| Step: 9
Training loss: 0.19992211471906976
Validation loss: 2.5368616634517624

Epoch: 6| Step: 10
Training loss: 0.18314572718236846
Validation loss: 2.49235847568924

Epoch: 6| Step: 11
Training loss: 0.38028920850686915
Validation loss: 2.509474208558756

Epoch: 6| Step: 12
Training loss: 0.2680882373807322
Validation loss: 2.511187681158474

Epoch: 6| Step: 13
Training loss: 0.25811511399501297
Validation loss: 2.508931036234241

Epoch: 415| Step: 0
Training loss: 0.31057837464465093
Validation loss: 2.5136558934485245

Epoch: 6| Step: 1
Training loss: 0.30957411514016525
Validation loss: 2.527842383325565

Epoch: 6| Step: 2
Training loss: 0.2127143059719266
Validation loss: 2.537172390375174

Epoch: 6| Step: 3
Training loss: 0.19456964366700624
Validation loss: 2.548553133371737

Epoch: 6| Step: 4
Training loss: 0.3013095550907521
Validation loss: 2.5412015551552107

Epoch: 6| Step: 5
Training loss: 0.1471160619940921
Validation loss: 2.5557694191442972

Epoch: 6| Step: 6
Training loss: 0.24046249723577717
Validation loss: 2.553156540218812

Epoch: 6| Step: 7
Training loss: 0.18533230471482806
Validation loss: 2.519854926669935

Epoch: 6| Step: 8
Training loss: 0.31314311609000167
Validation loss: 2.5412926075029096

Epoch: 6| Step: 9
Training loss: 0.3368299075080942
Validation loss: 2.5094594586190837

Epoch: 6| Step: 10
Training loss: 0.20611865058787104
Validation loss: 2.5149031219713267

Epoch: 6| Step: 11
Training loss: 0.3912467205044225
Validation loss: 2.522022895823624

Epoch: 6| Step: 12
Training loss: 0.1848249948939402
Validation loss: 2.5386242772161336

Epoch: 6| Step: 13
Training loss: 0.1513189977415147
Validation loss: 2.493501699173961

Epoch: 416| Step: 0
Training loss: 0.3219225704817158
Validation loss: 2.5309953317127594

Epoch: 6| Step: 1
Training loss: 0.3376891136152062
Validation loss: 2.544566303086173

Epoch: 6| Step: 2
Training loss: 0.20413308151211623
Validation loss: 2.5075069099846097

Epoch: 6| Step: 3
Training loss: 0.20848301437769898
Validation loss: 2.5362662983255455

Epoch: 6| Step: 4
Training loss: 0.33923575945098117
Validation loss: 2.531363669653322

Epoch: 6| Step: 5
Training loss: 0.3546872613712802
Validation loss: 2.5289693534425144

Epoch: 6| Step: 6
Training loss: 0.26149754641787726
Validation loss: 2.552343973926741

Epoch: 6| Step: 7
Training loss: 0.21509700067389584
Validation loss: 2.5657041172990875

Epoch: 6| Step: 8
Training loss: 0.3041723003693109
Validation loss: 2.540594374711961

Epoch: 6| Step: 9
Training loss: 0.2093407186512781
Validation loss: 2.5925258046006916

Epoch: 6| Step: 10
Training loss: 0.32645908433932885
Validation loss: 2.6150469628536492

Epoch: 6| Step: 11
Training loss: 0.17583831814412684
Validation loss: 2.569089694719028

Epoch: 6| Step: 12
Training loss: 0.2821681480277762
Validation loss: 2.579853278803288

Epoch: 6| Step: 13
Training loss: 0.1203906466541605
Validation loss: 2.569492147709223

Epoch: 417| Step: 0
Training loss: 0.18833665151401777
Validation loss: 2.5556737385881525

Epoch: 6| Step: 1
Training loss: 0.3370121357024539
Validation loss: 2.542230262852751

Epoch: 6| Step: 2
Training loss: 0.22421840142678204
Validation loss: 2.540135284540509

Epoch: 6| Step: 3
Training loss: 0.25472744411999787
Validation loss: 2.5510669335893534

Epoch: 6| Step: 4
Training loss: 0.25712770490007136
Validation loss: 2.519092296898956

Epoch: 6| Step: 5
Training loss: 0.20492519852985921
Validation loss: 2.557597347808527

Epoch: 6| Step: 6
Training loss: 0.34237276879663303
Validation loss: 2.528488297392723

Epoch: 6| Step: 7
Training loss: 0.12415042518621842
Validation loss: 2.553473099253317

Epoch: 6| Step: 8
Training loss: 0.23970710452897742
Validation loss: 2.567824336980514

Epoch: 6| Step: 9
Training loss: 0.32954481029148563
Validation loss: 2.5496043846420275

Epoch: 6| Step: 10
Training loss: 0.23142268879086528
Validation loss: 2.500751388597101

Epoch: 6| Step: 11
Training loss: 0.3118717076466071
Validation loss: 2.5250389163132136

Epoch: 6| Step: 12
Training loss: 0.15906875348866958
Validation loss: 2.566110937069903

Epoch: 6| Step: 13
Training loss: 0.4139266601000216
Validation loss: 2.5765471645912665

Epoch: 418| Step: 0
Training loss: 0.23585786612382786
Validation loss: 2.5828269251427978

Epoch: 6| Step: 1
Training loss: 0.30273489182951097
Validation loss: 2.547011344033796

Epoch: 6| Step: 2
Training loss: 0.3561593358635087
Validation loss: 2.522543043044598

Epoch: 6| Step: 3
Training loss: 0.15234670880696677
Validation loss: 2.5205876301764554

Epoch: 6| Step: 4
Training loss: 0.13745701237088426
Validation loss: 2.5487690298719694

Epoch: 6| Step: 5
Training loss: 0.16021754673527755
Validation loss: 2.509813940905389

Epoch: 6| Step: 6
Training loss: 0.15346133070364565
Validation loss: 2.51883175523158

Epoch: 6| Step: 7
Training loss: 0.2788770494749096
Validation loss: 2.538889041147073

Epoch: 6| Step: 8
Training loss: 0.2778030675396001
Validation loss: 2.504694870029617

Epoch: 6| Step: 9
Training loss: 0.31162168334790397
Validation loss: 2.5066733190718335

Epoch: 6| Step: 10
Training loss: 0.24217631714136714
Validation loss: 2.4951050890936326

Epoch: 6| Step: 11
Training loss: 0.3020379824413451
Validation loss: 2.520717125613088

Epoch: 6| Step: 12
Training loss: 0.206388988769385
Validation loss: 2.5608474240803463

Epoch: 6| Step: 13
Training loss: 0.24423177924761807
Validation loss: 2.5525667815445185

Epoch: 419| Step: 0
Training loss: 0.27206198904829465
Validation loss: 2.5713740286020865

Epoch: 6| Step: 1
Training loss: 0.22140055993036473
Validation loss: 2.560884512221407

Epoch: 6| Step: 2
Training loss: 0.240981483205172
Validation loss: 2.5376212609316604

Epoch: 6| Step: 3
Training loss: 0.25625486601884734
Validation loss: 2.566768758801225

Epoch: 6| Step: 4
Training loss: 0.16578017536465792
Validation loss: 2.586836621362063

Epoch: 6| Step: 5
Training loss: 0.2115754969561615
Validation loss: 2.5706123949836295

Epoch: 6| Step: 6
Training loss: 0.3549134244926734
Validation loss: 2.551940640412988

Epoch: 6| Step: 7
Training loss: 0.2278380414854306
Validation loss: 2.5646698691453462

Epoch: 6| Step: 8
Training loss: 0.3304790567364502
Validation loss: 2.5725557779037422

Epoch: 6| Step: 9
Training loss: 0.2256049606427163
Validation loss: 2.5611072249819

Epoch: 6| Step: 10
Training loss: 0.28389870297148095
Validation loss: 2.4784399912351125

Epoch: 6| Step: 11
Training loss: 0.3694166130662795
Validation loss: 2.5108318970063994

Epoch: 6| Step: 12
Training loss: 0.16188893784718125
Validation loss: 2.5111443808539256

Epoch: 6| Step: 13
Training loss: 0.1478897894419076
Validation loss: 2.493679585823453

Epoch: 420| Step: 0
Training loss: 0.19047928188769286
Validation loss: 2.50966687741372

Epoch: 6| Step: 1
Training loss: 0.28533272965026063
Validation loss: 2.4948103558473167

Epoch: 6| Step: 2
Training loss: 0.24503956663790435
Validation loss: 2.4901985787753085

Epoch: 6| Step: 3
Training loss: 0.17536400973236865
Validation loss: 2.550788555635124

Epoch: 6| Step: 4
Training loss: 0.24083267699936484
Validation loss: 2.550096815468253

Epoch: 6| Step: 5
Training loss: 0.25604871485398245
Validation loss: 2.5414594484769792

Epoch: 6| Step: 6
Training loss: 0.278535405081246
Validation loss: 2.5714641700994867

Epoch: 6| Step: 7
Training loss: 0.3157377244755913
Validation loss: 2.5789486759765765

Epoch: 6| Step: 8
Training loss: 0.3457486505220051
Validation loss: 2.617812142469297

Epoch: 6| Step: 9
Training loss: 0.2181212466034497
Validation loss: 2.6041638377184526

Epoch: 6| Step: 10
Training loss: 0.3517974386394949
Validation loss: 2.6033771629068774

Epoch: 6| Step: 11
Training loss: 0.243807657159499
Validation loss: 2.5816376597580226

Epoch: 6| Step: 12
Training loss: 0.2331308083411503
Validation loss: 2.557373823147714

Epoch: 6| Step: 13
Training loss: 0.35596488033478974
Validation loss: 2.5615039933682096

Epoch: 421| Step: 0
Training loss: 0.21119647552776222
Validation loss: 2.5436966399979974

Epoch: 6| Step: 1
Training loss: 0.12215972677432296
Validation loss: 2.5735696501467324

Epoch: 6| Step: 2
Training loss: 0.21691990703483346
Validation loss: 2.5406812784743864

Epoch: 6| Step: 3
Training loss: 0.14880824219060954
Validation loss: 2.5233312272224944

Epoch: 6| Step: 4
Training loss: 0.2721415736522524
Validation loss: 2.467974068224

Epoch: 6| Step: 5
Training loss: 0.23616775872532836
Validation loss: 2.4949991168760954

Epoch: 6| Step: 6
Training loss: 0.3705581815805438
Validation loss: 2.4705196454024616

Epoch: 6| Step: 7
Training loss: 0.3762576155034403
Validation loss: 2.4937851258082504

Epoch: 6| Step: 8
Training loss: 0.15527185403268362
Validation loss: 2.526278451812705

Epoch: 6| Step: 9
Training loss: 0.17890602678176748
Validation loss: 2.475996243147114

Epoch: 6| Step: 10
Training loss: 0.271451152168333
Validation loss: 2.483926669801208

Epoch: 6| Step: 11
Training loss: 0.2461491704026608
Validation loss: 2.5254754024947377

Epoch: 6| Step: 12
Training loss: 0.31842294304081437
Validation loss: 2.4816080913395027

Epoch: 6| Step: 13
Training loss: 0.1311284260020419
Validation loss: 2.521506750848657

Epoch: 422| Step: 0
Training loss: 0.16323959512836095
Validation loss: 2.4832954421672575

Epoch: 6| Step: 1
Training loss: 0.1184957711382175
Validation loss: 2.5213486419251234

Epoch: 6| Step: 2
Training loss: 0.35271335425110706
Validation loss: 2.4654911610018715

Epoch: 6| Step: 3
Training loss: 0.1891043589100945
Validation loss: 2.4882709759696042

Epoch: 6| Step: 4
Training loss: 0.23221757869812637
Validation loss: 2.4911205955054463

Epoch: 6| Step: 5
Training loss: 0.2771472369027562
Validation loss: 2.5277393578751313

Epoch: 6| Step: 6
Training loss: 0.32313533526628074
Validation loss: 2.527383878336408

Epoch: 6| Step: 7
Training loss: 0.21416308344046428
Validation loss: 2.5270963929017625

Epoch: 6| Step: 8
Training loss: 0.1738891708679303
Validation loss: 2.5521567937856444

Epoch: 6| Step: 9
Training loss: 0.23478293680351534
Validation loss: 2.5319489729737152

Epoch: 6| Step: 10
Training loss: 0.19311450133443758
Validation loss: 2.5313522711171643

Epoch: 6| Step: 11
Training loss: 0.2621641781133688
Validation loss: 2.5287820220845645

Epoch: 6| Step: 12
Training loss: 0.3199350412568279
Validation loss: 2.5200767476657604

Epoch: 6| Step: 13
Training loss: 0.28847920359110824
Validation loss: 2.5448987641488996

Epoch: 423| Step: 0
Training loss: 0.19759358630278404
Validation loss: 2.5216555083890984

Epoch: 6| Step: 1
Training loss: 0.15587328559541447
Validation loss: 2.5391128643584575

Epoch: 6| Step: 2
Training loss: 0.40054948958065706
Validation loss: 2.5152506869885145

Epoch: 6| Step: 3
Training loss: 0.138483611439947
Validation loss: 2.5688792014842687

Epoch: 6| Step: 4
Training loss: 0.16955931119243922
Validation loss: 2.5122461441630546

Epoch: 6| Step: 5
Training loss: 0.21765432821111375
Validation loss: 2.5313769204503864

Epoch: 6| Step: 6
Training loss: 0.2233464519021856
Validation loss: 2.5620361666674385

Epoch: 6| Step: 7
Training loss: 0.16873330943253947
Validation loss: 2.513415682670234

Epoch: 6| Step: 8
Training loss: 0.16834467582525947
Validation loss: 2.549378686984343

Epoch: 6| Step: 9
Training loss: 0.3578743285686818
Validation loss: 2.5566538059566644

Epoch: 6| Step: 10
Training loss: 0.2153990764433419
Validation loss: 2.5628837540206404

Epoch: 6| Step: 11
Training loss: 0.436067176318098
Validation loss: 2.592967808826872

Epoch: 6| Step: 12
Training loss: 0.30904771514875584
Validation loss: 2.591838220571819

Epoch: 6| Step: 13
Training loss: 0.14562189507141807
Validation loss: 2.6078346524545912

Epoch: 424| Step: 0
Training loss: 0.20414237020558992
Validation loss: 2.6262382286315455

Epoch: 6| Step: 1
Training loss: 0.21540076268261646
Validation loss: 2.6374252008576966

Epoch: 6| Step: 2
Training loss: 0.17417693769667386
Validation loss: 2.616505179847604

Epoch: 6| Step: 3
Training loss: 0.26349954978480955
Validation loss: 2.626528059318969

Epoch: 6| Step: 4
Training loss: 0.11418654183412215
Validation loss: 2.6174015443123575

Epoch: 6| Step: 5
Training loss: 0.24753597539921418
Validation loss: 2.610468469721228

Epoch: 6| Step: 6
Training loss: 0.492346268734895
Validation loss: 2.5895452317911403

Epoch: 6| Step: 7
Training loss: 0.26010121631183925
Validation loss: 2.558623825030497

Epoch: 6| Step: 8
Training loss: 0.22235824485439606
Validation loss: 2.5308084552233687

Epoch: 6| Step: 9
Training loss: 0.1732352787605659
Validation loss: 2.4750322965236475

Epoch: 6| Step: 10
Training loss: 0.1472660570618947
Validation loss: 2.498668754080978

Epoch: 6| Step: 11
Training loss: 0.2193523101946067
Validation loss: 2.553061928555376

Epoch: 6| Step: 12
Training loss: 0.22660767170693946
Validation loss: 2.495285464855851

Epoch: 6| Step: 13
Training loss: 0.17146779177867072
Validation loss: 2.49383005723097

Epoch: 425| Step: 0
Training loss: 0.2102980812254135
Validation loss: 2.517628653376519

Epoch: 6| Step: 1
Training loss: 0.13834040610298617
Validation loss: 2.555082295365549

Epoch: 6| Step: 2
Training loss: 0.3194599902244924
Validation loss: 2.5665750068933795

Epoch: 6| Step: 3
Training loss: 0.13045280553276264
Validation loss: 2.5701999414621617

Epoch: 6| Step: 4
Training loss: 0.21282615910470654
Validation loss: 2.5661392940884977

Epoch: 6| Step: 5
Training loss: 0.352943336547992
Validation loss: 2.5628449432684954

Epoch: 6| Step: 6
Training loss: 0.1369999582106116
Validation loss: 2.5623076351943888

Epoch: 6| Step: 7
Training loss: 0.1663909260316064
Validation loss: 2.570904384297405

Epoch: 6| Step: 8
Training loss: 0.18625203704360063
Validation loss: 2.5767027033204486

Epoch: 6| Step: 9
Training loss: 0.2508403542054592
Validation loss: 2.5932429619036874

Epoch: 6| Step: 10
Training loss: 0.2223927293660616
Validation loss: 2.5591576666272733

Epoch: 6| Step: 11
Training loss: 0.17146699335037235
Validation loss: 2.5409160240525597

Epoch: 6| Step: 12
Training loss: 0.19151475322220282
Validation loss: 2.531461740517611

Epoch: 6| Step: 13
Training loss: 0.5060006316335603
Validation loss: 2.5412884472332093

Epoch: 426| Step: 0
Training loss: 0.33073985340344103
Validation loss: 2.4961499213902067

Epoch: 6| Step: 1
Training loss: 0.18416809984083912
Validation loss: 2.5366215116544786

Epoch: 6| Step: 2
Training loss: 0.3382122846082535
Validation loss: 2.5333121501115756

Epoch: 6| Step: 3
Training loss: 0.34133105552010795
Validation loss: 2.536024898311205

Epoch: 6| Step: 4
Training loss: 0.2250031543881448
Validation loss: 2.5781163110769953

Epoch: 6| Step: 5
Training loss: 0.14259260574381644
Validation loss: 2.5961276781195886

Epoch: 6| Step: 6
Training loss: 0.2877377879478684
Validation loss: 2.6023110106152916

Epoch: 6| Step: 7
Training loss: 0.23884053335004013
Validation loss: 2.6060895981248366

Epoch: 6| Step: 8
Training loss: 0.23720739277434802
Validation loss: 2.5846514863479446

Epoch: 6| Step: 9
Training loss: 0.19781990362838975
Validation loss: 2.570245678033036

Epoch: 6| Step: 10
Training loss: 0.15126245628641907
Validation loss: 2.540474879707436

Epoch: 6| Step: 11
Training loss: 0.32686516183522574
Validation loss: 2.529943934663317

Epoch: 6| Step: 12
Training loss: 0.17322155314563195
Validation loss: 2.531630715173892

Epoch: 6| Step: 13
Training loss: 0.20624026759622566
Validation loss: 2.5241315349439013

Epoch: 427| Step: 0
Training loss: 0.14319293835543004
Validation loss: 2.4970866291440688

Epoch: 6| Step: 1
Training loss: 0.29560134627735096
Validation loss: 2.4854143676906713

Epoch: 6| Step: 2
Training loss: 0.27443929807351497
Validation loss: 2.5046705057051524

Epoch: 6| Step: 3
Training loss: 0.32736921689335535
Validation loss: 2.491876456814735

Epoch: 6| Step: 4
Training loss: 0.2252124402694805
Validation loss: 2.5184165025603695

Epoch: 6| Step: 5
Training loss: 0.1871973018277054
Validation loss: 2.5285355742109576

Epoch: 6| Step: 6
Training loss: 0.1975672653490007
Validation loss: 2.541270213187099

Epoch: 6| Step: 7
Training loss: 0.18528648978738166
Validation loss: 2.5390792889036025

Epoch: 6| Step: 8
Training loss: 0.19685849582279902
Validation loss: 2.557919275477896

Epoch: 6| Step: 9
Training loss: 0.18140173143317054
Validation loss: 2.5565317343619833

Epoch: 6| Step: 10
Training loss: 0.3850308390131335
Validation loss: 2.5545439345992116

Epoch: 6| Step: 11
Training loss: 0.2254083933842721
Validation loss: 2.555864174322596

Epoch: 6| Step: 12
Training loss: 0.19595375649152968
Validation loss: 2.5408135718490343

Epoch: 6| Step: 13
Training loss: 0.3046798216023423
Validation loss: 2.559206819608551

Epoch: 428| Step: 0
Training loss: 0.09401858123485712
Validation loss: 2.523336760214534

Epoch: 6| Step: 1
Training loss: 0.2509003014980054
Validation loss: 2.513353598613525

Epoch: 6| Step: 2
Training loss: 0.3442115286313323
Validation loss: 2.506026388843359

Epoch: 6| Step: 3
Training loss: 0.26763380821731647
Validation loss: 2.49404424637461

Epoch: 6| Step: 4
Training loss: 0.26250896438550714
Validation loss: 2.4968187148927785

Epoch: 6| Step: 5
Training loss: 0.40098718999797595
Validation loss: 2.5032106640588947

Epoch: 6| Step: 6
Training loss: 0.22652591212579157
Validation loss: 2.5319047792713327

Epoch: 6| Step: 7
Training loss: 0.20870236058775968
Validation loss: 2.5598256782286675

Epoch: 6| Step: 8
Training loss: 0.21929252989853548
Validation loss: 2.6010446823621534

Epoch: 6| Step: 9
Training loss: 0.16959245034164966
Validation loss: 2.5570451977611266

Epoch: 6| Step: 10
Training loss: 0.19856682865802627
Validation loss: 2.6138290129668325

Epoch: 6| Step: 11
Training loss: 0.19953270090900466
Validation loss: 2.612442022866579

Epoch: 6| Step: 12
Training loss: 0.24246582835104272
Validation loss: 2.629057278637678

Epoch: 6| Step: 13
Training loss: 0.11385660972995933
Validation loss: 2.6168453163666436

Epoch: 429| Step: 0
Training loss: 0.2700398249527795
Validation loss: 2.6036487627125044

Epoch: 6| Step: 1
Training loss: 0.10083816902266884
Validation loss: 2.634483617921441

Epoch: 6| Step: 2
Training loss: 0.3663244249608936
Validation loss: 2.603394569544242

Epoch: 6| Step: 3
Training loss: 0.1474370621306421
Validation loss: 2.6009921828040032

Epoch: 6| Step: 4
Training loss: 0.24155152557483905
Validation loss: 2.6018175278934996

Epoch: 6| Step: 5
Training loss: 0.15808406517667625
Validation loss: 2.6597424743795774

Epoch: 6| Step: 6
Training loss: 0.1931445344285929
Validation loss: 2.6250480553700766

Epoch: 6| Step: 7
Training loss: 0.1346709084414708
Validation loss: 2.620443449739374

Epoch: 6| Step: 8
Training loss: 0.17059762911588577
Validation loss: 2.5989852373849485

Epoch: 6| Step: 9
Training loss: 0.2520967709819119
Validation loss: 2.614511614799126

Epoch: 6| Step: 10
Training loss: 0.24762372095094468
Validation loss: 2.604083136582753

Epoch: 6| Step: 11
Training loss: 0.09856173343094263
Validation loss: 2.59683965294625

Epoch: 6| Step: 12
Training loss: 0.40986290387019686
Validation loss: 2.5606364024770873

Epoch: 6| Step: 13
Training loss: 0.09114402587551713
Validation loss: 2.5464389079647205

Epoch: 430| Step: 0
Training loss: 0.2012146469126801
Validation loss: 2.5160994380738715

Epoch: 6| Step: 1
Training loss: 0.2102643327125489
Validation loss: 2.4923057614244315

Epoch: 6| Step: 2
Training loss: 0.23074203387878997
Validation loss: 2.508185457732867

Epoch: 6| Step: 3
Training loss: 0.18011765201387092
Validation loss: 2.519418676108992

Epoch: 6| Step: 4
Training loss: 0.19142726860640094
Validation loss: 2.494568132022436

Epoch: 6| Step: 5
Training loss: 0.20966755085633862
Validation loss: 2.5160155357825977

Epoch: 6| Step: 6
Training loss: 0.2759699848360382
Validation loss: 2.4729836371657115

Epoch: 6| Step: 7
Training loss: 0.32625465713114765
Validation loss: 2.459938783441698

Epoch: 6| Step: 8
Training loss: 0.1654920062039055
Validation loss: 2.5412796202562706

Epoch: 6| Step: 9
Training loss: 0.15812630613262538
Validation loss: 2.581059063769561

Epoch: 6| Step: 10
Training loss: 0.369671636452274
Validation loss: 2.533603926289959

Epoch: 6| Step: 11
Training loss: 0.25115136912692465
Validation loss: 2.593444181526374

Epoch: 6| Step: 12
Training loss: 0.3141366301773268
Validation loss: 2.6034120381027965

Epoch: 6| Step: 13
Training loss: 0.14296328763480493
Validation loss: 2.6358334277736057

Epoch: 431| Step: 0
Training loss: 0.15334454727587507
Validation loss: 2.5970147060408926

Epoch: 6| Step: 1
Training loss: 0.2476137690406704
Validation loss: 2.591033329249885

Epoch: 6| Step: 2
Training loss: 0.15546365997953382
Validation loss: 2.6007942529474777

Epoch: 6| Step: 3
Training loss: 0.2719211495353685
Validation loss: 2.5805153483381487

Epoch: 6| Step: 4
Training loss: 0.19437816295319527
Validation loss: 2.5559838059177604

Epoch: 6| Step: 5
Training loss: 0.2815771584288619
Validation loss: 2.5339527353565514

Epoch: 6| Step: 6
Training loss: 0.2950809378233614
Validation loss: 2.536181640963627

Epoch: 6| Step: 7
Training loss: 0.2354004599399619
Validation loss: 2.5165103451720348

Epoch: 6| Step: 8
Training loss: 0.1505425540361384
Validation loss: 2.512101807516257

Epoch: 6| Step: 9
Training loss: 0.20243789846469992
Validation loss: 2.495458846934684

Epoch: 6| Step: 10
Training loss: 0.20733142180829114
Validation loss: 2.5042948215043745

Epoch: 6| Step: 11
Training loss: 0.28531947755167864
Validation loss: 2.489085816343026

Epoch: 6| Step: 12
Training loss: 0.16729505301449174
Validation loss: 2.485207028615247

Epoch: 6| Step: 13
Training loss: 0.3880231993771641
Validation loss: 2.516492766951565

Epoch: 432| Step: 0
Training loss: 0.13354010983014386
Validation loss: 2.483505952474521

Epoch: 6| Step: 1
Training loss: 0.14214767511409174
Validation loss: 2.529122284658969

Epoch: 6| Step: 2
Training loss: 0.2299208189110152
Validation loss: 2.54345513179484

Epoch: 6| Step: 3
Training loss: 0.16599126524881563
Validation loss: 2.530435007329158

Epoch: 6| Step: 4
Training loss: 0.18320895513111354
Validation loss: 2.5554363759597867

Epoch: 6| Step: 5
Training loss: 0.4052799637969909
Validation loss: 2.525313508243311

Epoch: 6| Step: 6
Training loss: 0.16123715692392407
Validation loss: 2.5327068447436516

Epoch: 6| Step: 7
Training loss: 0.31720540884037685
Validation loss: 2.51833907349673

Epoch: 6| Step: 8
Training loss: 0.13980206795407582
Validation loss: 2.5682908921376

Epoch: 6| Step: 9
Training loss: 0.13325997311341783
Validation loss: 2.5363116107675063

Epoch: 6| Step: 10
Training loss: 0.3051223097686128
Validation loss: 2.5406618811834702

Epoch: 6| Step: 11
Training loss: 0.15883748300419737
Validation loss: 2.524865224078683

Epoch: 6| Step: 12
Training loss: 0.28831173081774003
Validation loss: 2.537854390957855

Epoch: 6| Step: 13
Training loss: 0.29383515990319364
Validation loss: 2.51775091428859

Epoch: 433| Step: 0
Training loss: 0.21592985799380995
Validation loss: 2.5215546577595425

Epoch: 6| Step: 1
Training loss: 0.19480327981272344
Validation loss: 2.57520527955774

Epoch: 6| Step: 2
Training loss: 0.2568112785772641
Validation loss: 2.511778970958853

Epoch: 6| Step: 3
Training loss: 0.17316132069797935
Validation loss: 2.525828925053347

Epoch: 6| Step: 4
Training loss: 0.25774959316924556
Validation loss: 2.5363119392693942

Epoch: 6| Step: 5
Training loss: 0.13570191451451347
Validation loss: 2.5959840975843687

Epoch: 6| Step: 6
Training loss: 0.15958733228594135
Validation loss: 2.5966773279082753

Epoch: 6| Step: 7
Training loss: 0.30435367783702094
Validation loss: 2.568561387209072

Epoch: 6| Step: 8
Training loss: 0.19558707011210885
Validation loss: 2.567792361962343

Epoch: 6| Step: 9
Training loss: 0.15562906266658424
Validation loss: 2.5682291389096807

Epoch: 6| Step: 10
Training loss: 0.25835007195439413
Validation loss: 2.5837729877459563

Epoch: 6| Step: 11
Training loss: 0.29322156805940436
Validation loss: 2.558866441328134

Epoch: 6| Step: 12
Training loss: 0.21206450505858865
Validation loss: 2.55312794712694

Epoch: 6| Step: 13
Training loss: 0.47730021364054204
Validation loss: 2.589503393212381

Epoch: 434| Step: 0
Training loss: 0.2215598954853375
Validation loss: 2.5484629595964003

Epoch: 6| Step: 1
Training loss: 0.2878388331085159
Validation loss: 2.524625509150615

Epoch: 6| Step: 2
Training loss: 0.2811400277983641
Validation loss: 2.512104475144234

Epoch: 6| Step: 3
Training loss: 0.15134808819776002
Validation loss: 2.5152595064448184

Epoch: 6| Step: 4
Training loss: 0.17178662151982801
Validation loss: 2.5185771443431357

Epoch: 6| Step: 5
Training loss: 0.11645921263962764
Validation loss: 2.498956322983458

Epoch: 6| Step: 6
Training loss: 0.2660151729495875
Validation loss: 2.506199502486085

Epoch: 6| Step: 7
Training loss: 0.18312907766092187
Validation loss: 2.4863143216921793

Epoch: 6| Step: 8
Training loss: 0.15362524578937706
Validation loss: 2.5024060504935832

Epoch: 6| Step: 9
Training loss: 0.4071380372646488
Validation loss: 2.487566936926121

Epoch: 6| Step: 10
Training loss: 0.260424030517732
Validation loss: 2.5115708217132795

Epoch: 6| Step: 11
Training loss: 0.17889011760089615
Validation loss: 2.497990583087188

Epoch: 6| Step: 12
Training loss: 0.19522397896334423
Validation loss: 2.4967111345269677

Epoch: 6| Step: 13
Training loss: 0.11330527429034858
Validation loss: 2.5488446594815914

Epoch: 435| Step: 0
Training loss: 0.24999529118871694
Validation loss: 2.5582739124035827

Epoch: 6| Step: 1
Training loss: 0.22283690635904652
Validation loss: 2.543871560837572

Epoch: 6| Step: 2
Training loss: 0.1604297094389197
Validation loss: 2.5547597232115367

Epoch: 6| Step: 3
Training loss: 0.36184181608069876
Validation loss: 2.564228274400905

Epoch: 6| Step: 4
Training loss: 0.3137080683557394
Validation loss: 2.5599805109598637

Epoch: 6| Step: 5
Training loss: 0.3049033818463375
Validation loss: 2.547898756727674

Epoch: 6| Step: 6
Training loss: 0.17800693782133603
Validation loss: 2.5338156679008517

Epoch: 6| Step: 7
Training loss: 0.15148174503949224
Validation loss: 2.552276141626865

Epoch: 6| Step: 8
Training loss: 0.3337021689483669
Validation loss: 2.5539469608195793

Epoch: 6| Step: 9
Training loss: 0.21008859346579234
Validation loss: 2.512702801308583

Epoch: 6| Step: 10
Training loss: 0.1636333017257695
Validation loss: 2.571824875947484

Epoch: 6| Step: 11
Training loss: 0.22421216257234447
Validation loss: 2.5455848410112325

Epoch: 6| Step: 12
Training loss: 0.20026461634471576
Validation loss: 2.5423726399687325

Epoch: 6| Step: 13
Training loss: 0.23297107147861318
Validation loss: 2.5724783295629585

Epoch: 436| Step: 0
Training loss: 0.2210953948293369
Validation loss: 2.532441429409448

Epoch: 6| Step: 1
Training loss: 0.181754701949721
Validation loss: 2.5365171496215453

Epoch: 6| Step: 2
Training loss: 0.22802619198624657
Validation loss: 2.521514921115409

Epoch: 6| Step: 3
Training loss: 0.19173158517169006
Validation loss: 2.559176529042075

Epoch: 6| Step: 4
Training loss: 0.20152520196907156
Validation loss: 2.582433739096141

Epoch: 6| Step: 5
Training loss: 0.15547318476193694
Validation loss: 2.510727888411121

Epoch: 6| Step: 6
Training loss: 0.16389108967740196
Validation loss: 2.5119539058699956

Epoch: 6| Step: 7
Training loss: 0.232461188701942
Validation loss: 2.483139887832904

Epoch: 6| Step: 8
Training loss: 0.26123731372457354
Validation loss: 2.4839182768155688

Epoch: 6| Step: 9
Training loss: 0.16902450954378512
Validation loss: 2.459457635364894

Epoch: 6| Step: 10
Training loss: 0.2878643670911525
Validation loss: 2.4509018627749284

Epoch: 6| Step: 11
Training loss: 0.1524501086921217
Validation loss: 2.4511731907213035

Epoch: 6| Step: 12
Training loss: 0.42551882995108964
Validation loss: 2.4842743056365286

Epoch: 6| Step: 13
Training loss: 0.1984761553382714
Validation loss: 2.497236077579881

Epoch: 437| Step: 0
Training loss: 0.21351783123195545
Validation loss: 2.496889103626022

Epoch: 6| Step: 1
Training loss: 0.1383234199513142
Validation loss: 2.505271467896676

Epoch: 6| Step: 2
Training loss: 0.3398650590201101
Validation loss: 2.504177922745365

Epoch: 6| Step: 3
Training loss: 0.1941633752276489
Validation loss: 2.5365789749925227

Epoch: 6| Step: 4
Training loss: 0.1801648123692337
Validation loss: 2.5441618408478948

Epoch: 6| Step: 5
Training loss: 0.21877969812704523
Validation loss: 2.5624413092150067

Epoch: 6| Step: 6
Training loss: 0.19655047986404564
Validation loss: 2.604194996013165

Epoch: 6| Step: 7
Training loss: 0.3000003784892556
Validation loss: 2.5522438311926763

Epoch: 6| Step: 8
Training loss: 0.07268953355739174
Validation loss: 2.56129418992455

Epoch: 6| Step: 9
Training loss: 0.3268557705520226
Validation loss: 2.5977368670665104

Epoch: 6| Step: 10
Training loss: 0.18791616468475295
Validation loss: 2.552043653476442

Epoch: 6| Step: 11
Training loss: 0.2390378135201935
Validation loss: 2.518980502817622

Epoch: 6| Step: 12
Training loss: 0.12115864399258523
Validation loss: 2.5691043874472954

Epoch: 6| Step: 13
Training loss: 0.1623358351179652
Validation loss: 2.5419245716317986

Epoch: 438| Step: 0
Training loss: 0.19413231960468783
Validation loss: 2.532430607181358

Epoch: 6| Step: 1
Training loss: 0.23078826803230326
Validation loss: 2.507283618038045

Epoch: 6| Step: 2
Training loss: 0.13001373690689882
Validation loss: 2.5093600497380657

Epoch: 6| Step: 3
Training loss: 0.1607498067484624
Validation loss: 2.51872994164974

Epoch: 6| Step: 4
Training loss: 0.20911281417883734
Validation loss: 2.5172561333568266

Epoch: 6| Step: 5
Training loss: 0.23355634287751395
Validation loss: 2.4960743713371287

Epoch: 6| Step: 6
Training loss: 0.30462552932048353
Validation loss: 2.471372672095486

Epoch: 6| Step: 7
Training loss: 0.17666102757615976
Validation loss: 2.5069190517843856

Epoch: 6| Step: 8
Training loss: 0.23736733916426936
Validation loss: 2.4731550842473995

Epoch: 6| Step: 9
Training loss: 0.1975030131653407
Validation loss: 2.540996425485788

Epoch: 6| Step: 10
Training loss: 0.2927344466108281
Validation loss: 2.5170030579169387

Epoch: 6| Step: 11
Training loss: 0.18011358784917533
Validation loss: 2.486847313764476

Epoch: 6| Step: 12
Training loss: 0.13515482554484412
Validation loss: 2.539607212397511

Epoch: 6| Step: 13
Training loss: 0.234151415673293
Validation loss: 2.5115463883332385

Epoch: 439| Step: 0
Training loss: 0.2700706281827047
Validation loss: 2.573303852804526

Epoch: 6| Step: 1
Training loss: 0.2549764234732577
Validation loss: 2.5386162064477604

Epoch: 6| Step: 2
Training loss: 0.15032814015887105
Validation loss: 2.550013392383298

Epoch: 6| Step: 3
Training loss: 0.21851695794417392
Validation loss: 2.5273156459392183

Epoch: 6| Step: 4
Training loss: 0.13864933421727926
Validation loss: 2.5657672117377737

Epoch: 6| Step: 5
Training loss: 0.17030627519273542
Validation loss: 2.5661882549011916

Epoch: 6| Step: 6
Training loss: 0.30757855369532183
Validation loss: 2.5332152236155063

Epoch: 6| Step: 7
Training loss: 0.17800970026705787
Validation loss: 2.5907143418093637

Epoch: 6| Step: 8
Training loss: 0.1994067968825239
Validation loss: 2.560516943704663

Epoch: 6| Step: 9
Training loss: 0.23393804030899976
Validation loss: 2.560387079180798

Epoch: 6| Step: 10
Training loss: 0.18950523564307603
Validation loss: 2.558815965832165

Epoch: 6| Step: 11
Training loss: 0.16558468930907205
Validation loss: 2.573071702345905

Epoch: 6| Step: 12
Training loss: 0.1124619668010475
Validation loss: 2.541953999742267

Epoch: 6| Step: 13
Training loss: 0.21580540704822995
Validation loss: 2.504322291255511

Epoch: 440| Step: 0
Training loss: 0.1871071315622923
Validation loss: 2.5515014574421397

Epoch: 6| Step: 1
Training loss: 0.15012632405223647
Validation loss: 2.4762632893738283

Epoch: 6| Step: 2
Training loss: 0.28498787023849126
Validation loss: 2.539253104275687

Epoch: 6| Step: 3
Training loss: 0.11819027775410643
Validation loss: 2.5299225200991047

Epoch: 6| Step: 4
Training loss: 0.2707715590647452
Validation loss: 2.5493391487216837

Epoch: 6| Step: 5
Training loss: 0.2928814948799036
Validation loss: 2.524072743719072

Epoch: 6| Step: 6
Training loss: 0.1562335124853731
Validation loss: 2.532560538182311

Epoch: 6| Step: 7
Training loss: 0.15601511227863019
Validation loss: 2.572432141372433

Epoch: 6| Step: 8
Training loss: 0.28589255495634947
Validation loss: 2.5691966840789173

Epoch: 6| Step: 9
Training loss: 0.1609434749364493
Validation loss: 2.57000107007894

Epoch: 6| Step: 10
Training loss: 0.12069666653857022
Validation loss: 2.5472030755482695

Epoch: 6| Step: 11
Training loss: 0.19247332733392197
Validation loss: 2.55622774237761

Epoch: 6| Step: 12
Training loss: 0.2688375890297019
Validation loss: 2.5155683544326184

Epoch: 6| Step: 13
Training loss: 0.14825783070288112
Validation loss: 2.547128334735362

Epoch: 441| Step: 0
Training loss: 0.1796445276872159
Validation loss: 2.5638875218623833

Epoch: 6| Step: 1
Training loss: 0.2887331400733961
Validation loss: 2.5606641288186

Epoch: 6| Step: 2
Training loss: 0.23969316383841793
Validation loss: 2.5770947418595704

Epoch: 6| Step: 3
Training loss: 0.07644441338986471
Validation loss: 2.5584114205752497

Epoch: 6| Step: 4
Training loss: 0.11491449052281123
Validation loss: 2.5574015537852

Epoch: 6| Step: 5
Training loss: 0.12421322366429391
Validation loss: 2.586523859176126

Epoch: 6| Step: 6
Training loss: 0.33029902137460654
Validation loss: 2.59279596638635

Epoch: 6| Step: 7
Training loss: 0.18784251320773984
Validation loss: 2.6106175266915543

Epoch: 6| Step: 8
Training loss: 0.1279318569086767
Validation loss: 2.583903136380911

Epoch: 6| Step: 9
Training loss: 0.2903462590934543
Validation loss: 2.5601704130506615

Epoch: 6| Step: 10
Training loss: 0.17714635812028987
Validation loss: 2.526710385372299

Epoch: 6| Step: 11
Training loss: 0.2192787438926666
Validation loss: 2.560835712293031

Epoch: 6| Step: 12
Training loss: 0.24350386168014446
Validation loss: 2.522579946882527

Epoch: 6| Step: 13
Training loss: 0.19328757600292495
Validation loss: 2.5621274651814248

Epoch: 442| Step: 0
Training loss: 0.2244820441189211
Validation loss: 2.561923812888196

Epoch: 6| Step: 1
Training loss: 0.23173697720822647
Validation loss: 2.5334934328201024

Epoch: 6| Step: 2
Training loss: 0.16896887157429463
Validation loss: 2.557779292251012

Epoch: 6| Step: 3
Training loss: 0.18603467565759774
Validation loss: 2.571299437027394

Epoch: 6| Step: 4
Training loss: 0.2309557247326533
Validation loss: 2.527587416329895

Epoch: 6| Step: 5
Training loss: 0.1814775555298687
Validation loss: 2.571949125777779

Epoch: 6| Step: 6
Training loss: 0.1846620039276626
Validation loss: 2.5713851709661877

Epoch: 6| Step: 7
Training loss: 0.31964839149800156
Validation loss: 2.5440728269662785

Epoch: 6| Step: 8
Training loss: 0.27267201768813354
Validation loss: 2.5907590129143547

Epoch: 6| Step: 9
Training loss: 0.1249740432074703
Validation loss: 2.5715695523355917

Epoch: 6| Step: 10
Training loss: 0.27022482602313863
Validation loss: 2.5287126671053533

Epoch: 6| Step: 11
Training loss: 0.1750465084331896
Validation loss: 2.533146235432143

Epoch: 6| Step: 12
Training loss: 0.11198686325621608
Validation loss: 2.5021119503084113

Epoch: 6| Step: 13
Training loss: 0.10009103148332978
Validation loss: 2.5353317772589303

Epoch: 443| Step: 0
Training loss: 0.2910737357269643
Validation loss: 2.492792937096847

Epoch: 6| Step: 1
Training loss: 0.219151928044088
Validation loss: 2.5251071609911295

Epoch: 6| Step: 2
Training loss: 0.2442481986514329
Validation loss: 2.508589437558977

Epoch: 6| Step: 3
Training loss: 0.29221361115006084
Validation loss: 2.519854761854972

Epoch: 6| Step: 4
Training loss: 0.23700366138142995
Validation loss: 2.5712378388102395

Epoch: 6| Step: 5
Training loss: 0.12998535296107425
Validation loss: 2.5438336340914343

Epoch: 6| Step: 6
Training loss: 0.1426925069730007
Validation loss: 2.5252390388235537

Epoch: 6| Step: 7
Training loss: 0.12486388201116293
Validation loss: 2.541170809862896

Epoch: 6| Step: 8
Training loss: 0.293662978025101
Validation loss: 2.5713357597569826

Epoch: 6| Step: 9
Training loss: 0.12307200856330501
Validation loss: 2.5708189160361266

Epoch: 6| Step: 10
Training loss: 0.1830492874422873
Validation loss: 2.558536062284604

Epoch: 6| Step: 11
Training loss: 0.14669038273896637
Validation loss: 2.589719102993794

Epoch: 6| Step: 12
Training loss: 0.19689889376832315
Validation loss: 2.54269632886122

Epoch: 6| Step: 13
Training loss: 0.14262762255643766
Validation loss: 2.5662827902136547

Epoch: 444| Step: 0
Training loss: 0.16432355365740545
Validation loss: 2.5624054792025714

Epoch: 6| Step: 1
Training loss: 0.29031477131689054
Validation loss: 2.545756686564831

Epoch: 6| Step: 2
Training loss: 0.16834273399901856
Validation loss: 2.559193147926926

Epoch: 6| Step: 3
Training loss: 0.29181886715212285
Validation loss: 2.5263297600593515

Epoch: 6| Step: 4
Training loss: 0.13321688740354573
Validation loss: 2.5642937325608743

Epoch: 6| Step: 5
Training loss: 0.10988097154395317
Validation loss: 2.5545592288228884

Epoch: 6| Step: 6
Training loss: 0.20918813914545284
Validation loss: 2.5088685029750364

Epoch: 6| Step: 7
Training loss: 0.1132911562698842
Validation loss: 2.502317863562175

Epoch: 6| Step: 8
Training loss: 0.3137024395446843
Validation loss: 2.5374652947263523

Epoch: 6| Step: 9
Training loss: 0.22646897950864175
Validation loss: 2.4846671527222246

Epoch: 6| Step: 10
Training loss: 0.18814826202099277
Validation loss: 2.517821866873326

Epoch: 6| Step: 11
Training loss: 0.24622287087660125
Validation loss: 2.562177121009519

Epoch: 6| Step: 12
Training loss: 0.11724728013200483
Validation loss: 2.5060886216842793

Epoch: 6| Step: 13
Training loss: 0.10104492242064143
Validation loss: 2.5099535156440966

Epoch: 445| Step: 0
Training loss: 0.16171589171606493
Validation loss: 2.543832364280404

Epoch: 6| Step: 1
Training loss: 0.13173046131268057
Validation loss: 2.4901806140672584

Epoch: 6| Step: 2
Training loss: 0.13091539493371482
Validation loss: 2.5284779388364944

Epoch: 6| Step: 3
Training loss: 0.18850411327387134
Validation loss: 2.5136346664866407

Epoch: 6| Step: 4
Training loss: 0.31737229549882784
Validation loss: 2.530138236215529

Epoch: 6| Step: 5
Training loss: 0.131177444498809
Validation loss: 2.5515308032303756

Epoch: 6| Step: 6
Training loss: 0.19468075625770237
Validation loss: 2.5751963552997474

Epoch: 6| Step: 7
Training loss: 0.18235553008781796
Validation loss: 2.553801880133232

Epoch: 6| Step: 8
Training loss: 0.1360924134041007
Validation loss: 2.5715982813206155

Epoch: 6| Step: 9
Training loss: 0.22420222656827132
Validation loss: 2.5352460582788217

Epoch: 6| Step: 10
Training loss: 0.1571273905584374
Validation loss: 2.583193673663324

Epoch: 6| Step: 11
Training loss: 0.2671798470722894
Validation loss: 2.5489763823320857

Epoch: 6| Step: 12
Training loss: 0.29462698536601667
Validation loss: 2.5436704037573454

Epoch: 6| Step: 13
Training loss: 0.21275292764289971
Validation loss: 2.5316942220921868

Epoch: 446| Step: 0
Training loss: 0.23736051993677448
Validation loss: 2.5303745839819674

Epoch: 6| Step: 1
Training loss: 0.1930041276880733
Validation loss: 2.5571750405174085

Epoch: 6| Step: 2
Training loss: 0.31171431717553094
Validation loss: 2.553387635876447

Epoch: 6| Step: 3
Training loss: 0.154126918722772
Validation loss: 2.521704756459093

Epoch: 6| Step: 4
Training loss: 0.15958324132531537
Validation loss: 2.528994542988132

Epoch: 6| Step: 5
Training loss: 0.17178769495204302
Validation loss: 2.5165416698575993

Epoch: 6| Step: 6
Training loss: 0.3324850683516533
Validation loss: 2.5284881189458748

Epoch: 6| Step: 7
Training loss: 0.1289072686935401
Validation loss: 2.5157241689642698

Epoch: 6| Step: 8
Training loss: 0.16457237758468102
Validation loss: 2.4670206650983593

Epoch: 6| Step: 9
Training loss: 0.16549259710069864
Validation loss: 2.480790004285775

Epoch: 6| Step: 10
Training loss: 0.22850628369140877
Validation loss: 2.4948285389751947

Epoch: 6| Step: 11
Training loss: 0.2242623841630868
Validation loss: 2.4619003389039498

Epoch: 6| Step: 12
Training loss: 0.13739012994007854
Validation loss: 2.47442646426903

Epoch: 6| Step: 13
Training loss: 0.07890811861299524
Validation loss: 2.4793904417996258

Epoch: 447| Step: 0
Training loss: 0.18382003717751658
Validation loss: 2.4854329197152274

Epoch: 6| Step: 1
Training loss: 0.3417459722489469
Validation loss: 2.5030857208612565

Epoch: 6| Step: 2
Training loss: 0.1751442759416897
Validation loss: 2.4840258229567556

Epoch: 6| Step: 3
Training loss: 0.2648840977590185
Validation loss: 2.4756201317599844

Epoch: 6| Step: 4
Training loss: 0.278118636026331
Validation loss: 2.4878975069782676

Epoch: 6| Step: 5
Training loss: 0.1306135302280951
Validation loss: 2.486688426402926

Epoch: 6| Step: 6
Training loss: 0.16872026084298333
Validation loss: 2.5013737436881187

Epoch: 6| Step: 7
Training loss: 0.13285083778405762
Validation loss: 2.534304100212126

Epoch: 6| Step: 8
Training loss: 0.21976540116272616
Validation loss: 2.509424917375638

Epoch: 6| Step: 9
Training loss: 0.21406820943973032
Validation loss: 2.568649795989398

Epoch: 6| Step: 10
Training loss: 0.15104506888887725
Validation loss: 2.5421358652485107

Epoch: 6| Step: 11
Training loss: 0.14841651768206587
Validation loss: 2.554700089937579

Epoch: 6| Step: 12
Training loss: 0.2700876629430488
Validation loss: 2.5228605411805143

Epoch: 6| Step: 13
Training loss: 0.13645451078690785
Validation loss: 2.56184277033453

Epoch: 448| Step: 0
Training loss: 0.1255489306705912
Validation loss: 2.599466261436768

Epoch: 6| Step: 1
Training loss: 0.3022735533927898
Validation loss: 2.583976027230037

Epoch: 6| Step: 2
Training loss: 0.22921209896452194
Validation loss: 2.579991779175978

Epoch: 6| Step: 3
Training loss: 0.22776390394612717
Validation loss: 2.6411779380215044

Epoch: 6| Step: 4
Training loss: 0.2590182027689076
Validation loss: 2.609879113248907

Epoch: 6| Step: 5
Training loss: 0.17001390157512697
Validation loss: 2.5983271059856468

Epoch: 6| Step: 6
Training loss: 0.19751664044801392
Validation loss: 2.6055767889700054

Epoch: 6| Step: 7
Training loss: 0.21559445399766453
Validation loss: 2.61069111616068

Epoch: 6| Step: 8
Training loss: 0.20364300078709138
Validation loss: 2.5909791891690594

Epoch: 6| Step: 9
Training loss: 0.17659157370146236
Validation loss: 2.56848569637563

Epoch: 6| Step: 10
Training loss: 0.3152741323214567
Validation loss: 2.5536153816044087

Epoch: 6| Step: 11
Training loss: 0.2234969830197364
Validation loss: 2.533044185015476

Epoch: 6| Step: 12
Training loss: 0.2309526277731226
Validation loss: 2.5048448010069415

Epoch: 6| Step: 13
Training loss: 0.3421809082615659
Validation loss: 2.4825080744372627

Epoch: 449| Step: 0
Training loss: 0.37788806853692464
Validation loss: 2.521816665619847

Epoch: 6| Step: 1
Training loss: 0.2225856752812161
Validation loss: 2.5345046371754716

Epoch: 6| Step: 2
Training loss: 0.2288352410254198
Validation loss: 2.48512812126048

Epoch: 6| Step: 3
Training loss: 0.2676473374895471
Validation loss: 2.4990694836921694

Epoch: 6| Step: 4
Training loss: 0.3669607801737329
Validation loss: 2.52217850930558

Epoch: 6| Step: 5
Training loss: 0.18024189054100828
Validation loss: 2.513379498521779

Epoch: 6| Step: 6
Training loss: 0.19986724023505514
Validation loss: 2.5378455601181082

Epoch: 6| Step: 7
Training loss: 0.3287433293249624
Validation loss: 2.5477236957996245

Epoch: 6| Step: 8
Training loss: 0.20877254302973047
Validation loss: 2.577760848563602

Epoch: 6| Step: 9
Training loss: 0.3237526542230744
Validation loss: 2.5398615087432725

Epoch: 6| Step: 10
Training loss: 0.3195681179947222
Validation loss: 2.5723523716859766

Epoch: 6| Step: 11
Training loss: 0.3429529095165492
Validation loss: 2.562832896501165

Epoch: 6| Step: 12
Training loss: 0.29172225263522733
Validation loss: 2.5496973640296106

Epoch: 6| Step: 13
Training loss: 0.3468207166485207
Validation loss: 2.5983635886102743

Epoch: 450| Step: 0
Training loss: 0.14712172770892173
Validation loss: 2.545063368226804

Epoch: 6| Step: 1
Training loss: 0.2828011125832704
Validation loss: 2.5459361945271684

Epoch: 6| Step: 2
Training loss: 0.18403027765707372
Validation loss: 2.578852756935048

Epoch: 6| Step: 3
Training loss: 0.276382311080304
Validation loss: 2.5331218932675283

Epoch: 6| Step: 4
Training loss: 0.22893986080898843
Validation loss: 2.540201264645789

Epoch: 6| Step: 5
Training loss: 0.17091138518195909
Validation loss: 2.5159324407685797

Epoch: 6| Step: 6
Training loss: 0.25008828869144867
Validation loss: 2.51657335630217

Epoch: 6| Step: 7
Training loss: 0.1594312119928158
Validation loss: 2.5759169922128726

Epoch: 6| Step: 8
Training loss: 0.4034004778314956
Validation loss: 2.5362645698686466

Epoch: 6| Step: 9
Training loss: 0.21861051471983772
Validation loss: 2.539165203582551

Epoch: 6| Step: 10
Training loss: 0.1430422791847466
Validation loss: 2.5350631974121174

Epoch: 6| Step: 11
Training loss: 0.22494676377399275
Validation loss: 2.5422712468046726

Epoch: 6| Step: 12
Training loss: 0.20671714490871423
Validation loss: 2.531212131263059

Epoch: 6| Step: 13
Training loss: 0.30670475137395864
Validation loss: 2.5473518501448615

Epoch: 451| Step: 0
Training loss: 0.19486590826139766
Validation loss: 2.543885385406084

Epoch: 6| Step: 1
Training loss: 0.18765409415957737
Validation loss: 2.519744847203991

Epoch: 6| Step: 2
Training loss: 0.17944831062804065
Validation loss: 2.5337952416842797

Epoch: 6| Step: 3
Training loss: 0.2869321834276898
Validation loss: 2.524197762746686

Epoch: 6| Step: 4
Training loss: 0.28156996116956023
Validation loss: 2.5508739251895856

Epoch: 6| Step: 5
Training loss: 0.27617634630697807
Validation loss: 2.547003267884387

Epoch: 6| Step: 6
Training loss: 0.23058450345888004
Validation loss: 2.5499592540348037

Epoch: 6| Step: 7
Training loss: 0.3019002559711639
Validation loss: 2.537249272995065

Epoch: 6| Step: 8
Training loss: 0.17679953741276322
Validation loss: 2.559673932424488

Epoch: 6| Step: 9
Training loss: 0.2768201452255874
Validation loss: 2.5835398450220173

Epoch: 6| Step: 10
Training loss: 0.24007711458102168
Validation loss: 2.545144133213197

Epoch: 6| Step: 11
Training loss: 0.18304100427725525
Validation loss: 2.5695351432114033

Epoch: 6| Step: 12
Training loss: 0.1843158845367599
Validation loss: 2.5394232320306704

Epoch: 6| Step: 13
Training loss: 0.20312486245077319
Validation loss: 2.5489413145011186

Epoch: 452| Step: 0
Training loss: 0.15093308003985156
Validation loss: 2.50560805013189

Epoch: 6| Step: 1
Training loss: 0.12904428547492988
Validation loss: 2.494248860980466

Epoch: 6| Step: 2
Training loss: 0.1528683762402026
Validation loss: 2.5365799674688607

Epoch: 6| Step: 3
Training loss: 0.22014899442912222
Validation loss: 2.5003350694749713

Epoch: 6| Step: 4
Training loss: 0.3234311499409964
Validation loss: 2.4946972054143695

Epoch: 6| Step: 5
Training loss: 0.22316448865329325
Validation loss: 2.5194027661174925

Epoch: 6| Step: 6
Training loss: 0.19748359384177766
Validation loss: 2.502576505274173

Epoch: 6| Step: 7
Training loss: 0.18588603293146694
Validation loss: 2.4753336206243897

Epoch: 6| Step: 8
Training loss: 0.16165057141108333
Validation loss: 2.5240878940077747

Epoch: 6| Step: 9
Training loss: 0.14666036206773414
Validation loss: 2.4815148056439638

Epoch: 6| Step: 10
Training loss: 0.242800858806477
Validation loss: 2.4925619677194

Epoch: 6| Step: 11
Training loss: 0.2468102937717126
Validation loss: 2.5152691412552426

Epoch: 6| Step: 12
Training loss: 0.27240933165404985
Validation loss: 2.500590515126121

Epoch: 6| Step: 13
Training loss: 0.10204254920282395
Validation loss: 2.5617978264216825

Epoch: 453| Step: 0
Training loss: 0.25281695943136406
Validation loss: 2.5545899705376134

Epoch: 6| Step: 1
Training loss: 0.11478690375360454
Validation loss: 2.5669506608930974

Epoch: 6| Step: 2
Training loss: 0.19389204386667613
Validation loss: 2.5303314235648595

Epoch: 6| Step: 3
Training loss: 0.14932727786617475
Validation loss: 2.5705332519894872

Epoch: 6| Step: 4
Training loss: 0.12666359678373515
Validation loss: 2.569318461265077

Epoch: 6| Step: 5
Training loss: 0.2308800550902898
Validation loss: 2.560702974626092

Epoch: 6| Step: 6
Training loss: 0.21869014874882317
Validation loss: 2.5668893068757033

Epoch: 6| Step: 7
Training loss: 0.13099799713758542
Validation loss: 2.523367972727162

Epoch: 6| Step: 8
Training loss: 0.29172967190517013
Validation loss: 2.516738071608964

Epoch: 6| Step: 9
Training loss: 0.15972985517765492
Validation loss: 2.5346183429296274

Epoch: 6| Step: 10
Training loss: 0.20676974209001853
Validation loss: 2.5543918133059393

Epoch: 6| Step: 11
Training loss: 0.22663748256710003
Validation loss: 2.536758366362245

Epoch: 6| Step: 12
Training loss: 0.10937014211356938
Validation loss: 2.52132538566461

Epoch: 6| Step: 13
Training loss: 0.2921948447298827
Validation loss: 2.5271322457267207

Epoch: 454| Step: 0
Training loss: 0.10399423025906315
Validation loss: 2.537137731304156

Epoch: 6| Step: 1
Training loss: 0.16055133980438807
Validation loss: 2.539312728781356

Epoch: 6| Step: 2
Training loss: 0.09410164370281916
Validation loss: 2.540025049453787

Epoch: 6| Step: 3
Training loss: 0.06173132786366904
Validation loss: 2.5438169249400318

Epoch: 6| Step: 4
Training loss: 0.2557836085532942
Validation loss: 2.5751234016036286

Epoch: 6| Step: 5
Training loss: 0.2691882757074301
Validation loss: 2.575844436628849

Epoch: 6| Step: 6
Training loss: 0.26690553097437686
Validation loss: 2.5688655792838024

Epoch: 6| Step: 7
Training loss: 0.10821642501287702
Validation loss: 2.5947748505193866

Epoch: 6| Step: 8
Training loss: 0.1804418485994173
Validation loss: 2.589203980293091

Epoch: 6| Step: 9
Training loss: 0.22475707132334685
Validation loss: 2.5809350260322486

Epoch: 6| Step: 10
Training loss: 0.11029761185557316
Validation loss: 2.562549663615684

Epoch: 6| Step: 11
Training loss: 0.22745076705256523
Validation loss: 2.560039486981905

Epoch: 6| Step: 12
Training loss: 0.1770617469552101
Validation loss: 2.533907677929037

Epoch: 6| Step: 13
Training loss: 0.16795766039768487
Validation loss: 2.5213371284634256

Epoch: 455| Step: 0
Training loss: 0.1612226293680878
Validation loss: 2.5294835651938437

Epoch: 6| Step: 1
Training loss: 0.18701440794283655
Validation loss: 2.529463832202274

Epoch: 6| Step: 2
Training loss: 0.331950480791075
Validation loss: 2.53189903819489

Epoch: 6| Step: 3
Training loss: 0.14200262952186604
Validation loss: 2.527275794969191

Epoch: 6| Step: 4
Training loss: 0.11556925444697884
Validation loss: 2.531004678720162

Epoch: 6| Step: 5
Training loss: 0.16167270493250585
Validation loss: 2.5194716640866064

Epoch: 6| Step: 6
Training loss: 0.1779824924940422
Validation loss: 2.5485168173881947

Epoch: 6| Step: 7
Training loss: 0.1469568199674746
Validation loss: 2.540243744184342

Epoch: 6| Step: 8
Training loss: 0.10118263990065068
Validation loss: 2.5944837972037877

Epoch: 6| Step: 9
Training loss: 0.2439273513033563
Validation loss: 2.5891337471607816

Epoch: 6| Step: 10
Training loss: 0.2808011101994548
Validation loss: 2.5669229764881294

Epoch: 6| Step: 11
Training loss: 0.1435734483565615
Validation loss: 2.5987949532473853

Epoch: 6| Step: 12
Training loss: 0.16344482086371726
Validation loss: 2.5847265837714426

Epoch: 6| Step: 13
Training loss: 0.319068890357216
Validation loss: 2.5751258207668477

Epoch: 456| Step: 0
Training loss: 0.12288271837936038
Validation loss: 2.5774801999793464

Epoch: 6| Step: 1
Training loss: 0.18481617653369484
Validation loss: 2.5362001329635895

Epoch: 6| Step: 2
Training loss: 0.3046510381155954
Validation loss: 2.537697143469673

Epoch: 6| Step: 3
Training loss: 0.18677621459938748
Validation loss: 2.528393961129321

Epoch: 6| Step: 4
Training loss: 0.17934881301622158
Validation loss: 2.5614055964719227

Epoch: 6| Step: 5
Training loss: 0.28209878741595007
Validation loss: 2.5329581760761517

Epoch: 6| Step: 6
Training loss: 0.16449651757281922
Validation loss: 2.524140944947257

Epoch: 6| Step: 7
Training loss: 0.13908551540009653
Validation loss: 2.516889185834705

Epoch: 6| Step: 8
Training loss: 0.19178440729395096
Validation loss: 2.564021139512505

Epoch: 6| Step: 9
Training loss: 0.2134072919946666
Validation loss: 2.537148652180864

Epoch: 6| Step: 10
Training loss: 0.30117239846902716
Validation loss: 2.559203481833697

Epoch: 6| Step: 11
Training loss: 0.2576423430289808
Validation loss: 2.5679469948761895

Epoch: 6| Step: 12
Training loss: 0.22465066944831694
Validation loss: 2.5827967344124896

Epoch: 6| Step: 13
Training loss: 0.37467771827585766
Validation loss: 2.530018146029421

Epoch: 457| Step: 0
Training loss: 0.19721668882808574
Validation loss: 2.5561760017448956

Epoch: 6| Step: 1
Training loss: 0.13090202006756796
Validation loss: 2.5385353993934685

Epoch: 6| Step: 2
Training loss: 0.20581068262930632
Validation loss: 2.513488373749578

Epoch: 6| Step: 3
Training loss: 0.2837300627169773
Validation loss: 2.5165620400153004

Epoch: 6| Step: 4
Training loss: 0.22660180277122013
Validation loss: 2.5151728006635787

Epoch: 6| Step: 5
Training loss: 0.290588731451047
Validation loss: 2.5190359521785495

Epoch: 6| Step: 6
Training loss: 0.10846501101734649
Validation loss: 2.551249975808678

Epoch: 6| Step: 7
Training loss: 0.16411370659023689
Validation loss: 2.5322775204163666

Epoch: 6| Step: 8
Training loss: 0.15344468314571658
Validation loss: 2.5389271710019687

Epoch: 6| Step: 9
Training loss: 0.11978442145980113
Validation loss: 2.5963763409475056

Epoch: 6| Step: 10
Training loss: 0.3112398848173041
Validation loss: 2.6139264790216945

Epoch: 6| Step: 11
Training loss: 0.18837385393311723
Validation loss: 2.6112969241911084

Epoch: 6| Step: 12
Training loss: 0.28353580797202915
Validation loss: 2.587842952500458

Epoch: 6| Step: 13
Training loss: 0.3060377353630381
Validation loss: 2.5953402417611695

Epoch: 458| Step: 0
Training loss: 0.20754459902879507
Validation loss: 2.5696915627882735

Epoch: 6| Step: 1
Training loss: 0.2530165563629956
Validation loss: 2.551102374669666

Epoch: 6| Step: 2
Training loss: 0.1865894839805843
Validation loss: 2.5149424574790595

Epoch: 6| Step: 3
Training loss: 0.18584481461692937
Validation loss: 2.4803022085047464

Epoch: 6| Step: 4
Training loss: 0.2096286983874588
Validation loss: 2.4591068462549184

Epoch: 6| Step: 5
Training loss: 0.20529522984300838
Validation loss: 2.452973125358053

Epoch: 6| Step: 6
Training loss: 0.2540064100635618
Validation loss: 2.4996702304864002

Epoch: 6| Step: 7
Training loss: 0.28325622323902333
Validation loss: 2.5384540969249443

Epoch: 6| Step: 8
Training loss: 0.22542660523526625
Validation loss: 2.48846186695523

Epoch: 6| Step: 9
Training loss: 0.1667755461731186
Validation loss: 2.5268883214361213

Epoch: 6| Step: 10
Training loss: 0.22729667556364794
Validation loss: 2.545561795598146

Epoch: 6| Step: 11
Training loss: 0.14690556056062312
Validation loss: 2.5412370077199267

Epoch: 6| Step: 12
Training loss: 0.23760990247669775
Validation loss: 2.5689991630470415

Epoch: 6| Step: 13
Training loss: 0.30858169000938174
Validation loss: 2.6304719880300853

Epoch: 459| Step: 0
Training loss: 0.18894006137834185
Validation loss: 2.6470236167547614

Epoch: 6| Step: 1
Training loss: 0.17942838022421292
Validation loss: 2.6086830625205004

Epoch: 6| Step: 2
Training loss: 0.3291198657461543
Validation loss: 2.584744070880303

Epoch: 6| Step: 3
Training loss: 0.23001258771596267
Validation loss: 2.5864670317912366

Epoch: 6| Step: 4
Training loss: 0.29813828972519185
Validation loss: 2.572026696704969

Epoch: 6| Step: 5
Training loss: 0.17262721184315527
Validation loss: 2.606209050441091

Epoch: 6| Step: 6
Training loss: 0.2051538690834153
Validation loss: 2.566509595429575

Epoch: 6| Step: 7
Training loss: 0.209957708289575
Validation loss: 2.566543762965135

Epoch: 6| Step: 8
Training loss: 0.19120008693063628
Validation loss: 2.554025408245865

Epoch: 6| Step: 9
Training loss: 0.18298576002270264
Validation loss: 2.5531244889436797

Epoch: 6| Step: 10
Training loss: 0.15928876685011661
Validation loss: 2.5252025987164997

Epoch: 6| Step: 11
Training loss: 0.1700292664468107
Validation loss: 2.508658166511943

Epoch: 6| Step: 12
Training loss: 0.14519060364836744
Validation loss: 2.542756727592348

Epoch: 6| Step: 13
Training loss: 0.16329944363217205
Validation loss: 2.5413765730811186

Epoch: 460| Step: 0
Training loss: 0.17470282778259602
Validation loss: 2.515613965302188

Epoch: 6| Step: 1
Training loss: 0.19791968661229511
Validation loss: 2.524744336791925

Epoch: 6| Step: 2
Training loss: 0.32445280979360713
Validation loss: 2.464739526338291

Epoch: 6| Step: 3
Training loss: 0.19970279679787406
Validation loss: 2.504745184414055

Epoch: 6| Step: 4
Training loss: 0.25765187143523016
Validation loss: 2.542829245309918

Epoch: 6| Step: 5
Training loss: 0.33105516011702296
Validation loss: 2.498117535970215

Epoch: 6| Step: 6
Training loss: 0.137241929255588
Validation loss: 2.5672048041608364

Epoch: 6| Step: 7
Training loss: 0.16492560962042754
Validation loss: 2.612072888128958

Epoch: 6| Step: 8
Training loss: 0.2959587866550393
Validation loss: 2.5927138618163066

Epoch: 6| Step: 9
Training loss: 0.19838928064829855
Validation loss: 2.636620594113361

Epoch: 6| Step: 10
Training loss: 0.18051545500699842
Validation loss: 2.5993968716855727

Epoch: 6| Step: 11
Training loss: 0.21374428932469694
Validation loss: 2.5733554522895603

Epoch: 6| Step: 12
Training loss: 0.19993167358272954
Validation loss: 2.563404990920353

Epoch: 6| Step: 13
Training loss: 0.20993441037115976
Validation loss: 2.5609234327687362

Epoch: 461| Step: 0
Training loss: 0.25755505278868046
Validation loss: 2.534613278592615

Epoch: 6| Step: 1
Training loss: 0.15855640244102767
Validation loss: 2.50089593440804

Epoch: 6| Step: 2
Training loss: 0.2912892840664545
Validation loss: 2.4739707676176184

Epoch: 6| Step: 3
Training loss: 0.2669989171327642
Validation loss: 2.512337804073135

Epoch: 6| Step: 4
Training loss: 0.2459294815404348
Validation loss: 2.4962319033462803

Epoch: 6| Step: 5
Training loss: 0.2007734000307898
Validation loss: 2.4922155794700234

Epoch: 6| Step: 6
Training loss: 0.25636949718620067
Validation loss: 2.5227167681364575

Epoch: 6| Step: 7
Training loss: 0.1923223875006437
Validation loss: 2.509392302429246

Epoch: 6| Step: 8
Training loss: 0.1590652229791734
Validation loss: 2.529841968889111

Epoch: 6| Step: 9
Training loss: 0.23839674167570574
Validation loss: 2.5153771193422627

Epoch: 6| Step: 10
Training loss: 0.27786528215734574
Validation loss: 2.5953444509606505

Epoch: 6| Step: 11
Training loss: 0.32922673321184504
Validation loss: 2.539103411904161

Epoch: 6| Step: 12
Training loss: 0.23229791236543693
Validation loss: 2.544625657011882

Epoch: 6| Step: 13
Training loss: 0.18759990057330048
Validation loss: 2.528843373565484

Epoch: 462| Step: 0
Training loss: 0.22975382398737512
Validation loss: 2.5260300901904844

Epoch: 6| Step: 1
Training loss: 0.3279835305193289
Validation loss: 2.530162654200551

Epoch: 6| Step: 2
Training loss: 0.2754639872779169
Validation loss: 2.514683693004372

Epoch: 6| Step: 3
Training loss: 0.1788529629038265
Validation loss: 2.5159741883319664

Epoch: 6| Step: 4
Training loss: 0.1872288412126165
Validation loss: 2.5399854947813583

Epoch: 6| Step: 5
Training loss: 0.3205308983744987
Validation loss: 2.530926684644477

Epoch: 6| Step: 6
Training loss: 0.28965631269782904
Validation loss: 2.5897764727616477

Epoch: 6| Step: 7
Training loss: 0.16274102794876344
Validation loss: 2.5408654411770466

Epoch: 6| Step: 8
Training loss: 0.16685730801961446
Validation loss: 2.5972670465938266

Epoch: 6| Step: 9
Training loss: 0.17274764002707516
Validation loss: 2.5876497283712703

Epoch: 6| Step: 10
Training loss: 0.2970732729511609
Validation loss: 2.5920016072685543

Epoch: 6| Step: 11
Training loss: 0.23400664788720713
Validation loss: 2.602779493142632

Epoch: 6| Step: 12
Training loss: 0.19781152333264052
Validation loss: 2.6724647322589163

Epoch: 6| Step: 13
Training loss: 0.1391859331852154
Validation loss: 2.63121602579628

Epoch: 463| Step: 0
Training loss: 0.12267458696638851
Validation loss: 2.633459655831052

Epoch: 6| Step: 1
Training loss: 0.3080915154684536
Validation loss: 2.667311208519629

Epoch: 6| Step: 2
Training loss: 0.29795722963159565
Validation loss: 2.6280538049708575

Epoch: 6| Step: 3
Training loss: 0.19010934539604066
Validation loss: 2.6022252015373906

Epoch: 6| Step: 4
Training loss: 0.2567001099648294
Validation loss: 2.647238374709362

Epoch: 6| Step: 5
Training loss: 0.3015550716256078
Validation loss: 2.5693263088725686

Epoch: 6| Step: 6
Training loss: 0.27100915275932264
Validation loss: 2.6055770034613372

Epoch: 6| Step: 7
Training loss: 0.1939350190749272
Validation loss: 2.5576590795860286

Epoch: 6| Step: 8
Training loss: 0.13027326792601568
Validation loss: 2.547459417345521

Epoch: 6| Step: 9
Training loss: 0.24080927220984918
Validation loss: 2.5477078473519836

Epoch: 6| Step: 10
Training loss: 0.1295377478563035
Validation loss: 2.4954609303435307

Epoch: 6| Step: 11
Training loss: 0.16706019126732488
Validation loss: 2.513265858676264

Epoch: 6| Step: 12
Training loss: 0.23407963579246813
Validation loss: 2.49263570199153

Epoch: 6| Step: 13
Training loss: 0.38182863974853615
Validation loss: 2.537993865056722

Epoch: 464| Step: 0
Training loss: 0.24132949602720008
Validation loss: 2.535744575829538

Epoch: 6| Step: 1
Training loss: 0.34270815757507334
Validation loss: 2.582454465077836

Epoch: 6| Step: 2
Training loss: 0.26411808546198384
Validation loss: 2.5927716023536527

Epoch: 6| Step: 3
Training loss: 0.27292836336497395
Validation loss: 2.6127095326021603

Epoch: 6| Step: 4
Training loss: 0.14781004273587942
Validation loss: 2.6533133944921015

Epoch: 6| Step: 5
Training loss: 0.18636166212773864
Validation loss: 2.6583462911727147

Epoch: 6| Step: 6
Training loss: 0.4120127849470124
Validation loss: 2.6111063664443486

Epoch: 6| Step: 7
Training loss: 0.3369128019889803
Validation loss: 2.61780329980567

Epoch: 6| Step: 8
Training loss: 0.25313041704762806
Validation loss: 2.621933103061793

Epoch: 6| Step: 9
Training loss: 0.20689592797257955
Validation loss: 2.574510172466528

Epoch: 6| Step: 10
Training loss: 0.25599070083410463
Validation loss: 2.5603528975725096

Epoch: 6| Step: 11
Training loss: 0.23712880088000088
Validation loss: 2.512465597247875

Epoch: 6| Step: 12
Training loss: 0.18855348312028058
Validation loss: 2.4568541908541675

Epoch: 6| Step: 13
Training loss: 0.25419677838719623
Validation loss: 2.5310822936073385

Epoch: 465| Step: 0
Training loss: 0.20095830524881245
Validation loss: 2.5401145200724367

Epoch: 6| Step: 1
Training loss: 0.2905879622618475
Validation loss: 2.540794877321831

Epoch: 6| Step: 2
Training loss: 0.257922178116078
Validation loss: 2.5429621669088713

Epoch: 6| Step: 3
Training loss: 0.22247700419695074
Validation loss: 2.600328370428282

Epoch: 6| Step: 4
Training loss: 0.16984747211410084
Validation loss: 2.594593243617698

Epoch: 6| Step: 5
Training loss: 0.16062943407907415
Validation loss: 2.559353698427867

Epoch: 6| Step: 6
Training loss: 0.17571612317223043
Validation loss: 2.5794782192705705

Epoch: 6| Step: 7
Training loss: 0.14147060521069885
Validation loss: 2.5825963191267034

Epoch: 6| Step: 8
Training loss: 0.20161807935169138
Validation loss: 2.55879955088734

Epoch: 6| Step: 9
Training loss: 0.2227236076998485
Validation loss: 2.5424420952296103

Epoch: 6| Step: 10
Training loss: 0.32989975663841314
Validation loss: 2.5614783148380766

Epoch: 6| Step: 11
Training loss: 0.17395716603015007
Validation loss: 2.573347553708758

Epoch: 6| Step: 12
Training loss: 0.2317311819140896
Validation loss: 2.5413672238703935

Epoch: 6| Step: 13
Training loss: 0.2408094578483254
Validation loss: 2.54228746695747

Epoch: 466| Step: 0
Training loss: 0.1691127674869585
Validation loss: 2.522870306499851

Epoch: 6| Step: 1
Training loss: 0.2111856625565352
Validation loss: 2.5396725016347093

Epoch: 6| Step: 2
Training loss: 0.34983474244502893
Validation loss: 2.5363417033854216

Epoch: 6| Step: 3
Training loss: 0.25138510022958654
Validation loss: 2.5516936854604118

Epoch: 6| Step: 4
Training loss: 0.09982029238573253
Validation loss: 2.552640715843612

Epoch: 6| Step: 5
Training loss: 0.2509841324076501
Validation loss: 2.59779950916588

Epoch: 6| Step: 6
Training loss: 0.19791199758108466
Validation loss: 2.6317336357827217

Epoch: 6| Step: 7
Training loss: 0.19424298234240026
Validation loss: 2.6228914459839667

Epoch: 6| Step: 8
Training loss: 0.24221218660114538
Validation loss: 2.5666031939751766

Epoch: 6| Step: 9
Training loss: 0.22249817674672046
Validation loss: 2.5730628912448554

Epoch: 6| Step: 10
Training loss: 0.21525650256832057
Validation loss: 2.57408122178114

Epoch: 6| Step: 11
Training loss: 0.2775330233470546
Validation loss: 2.554959502498726

Epoch: 6| Step: 12
Training loss: 0.30324226352858263
Validation loss: 2.547914308173207

Epoch: 6| Step: 13
Training loss: 0.15609268971866824
Validation loss: 2.5241508058618627

Epoch: 467| Step: 0
Training loss: 0.19113478581017787
Validation loss: 2.515538976379741

Epoch: 6| Step: 1
Training loss: 0.2533522210065397
Validation loss: 2.464065868186471

Epoch: 6| Step: 2
Training loss: 0.2799210942156605
Validation loss: 2.4971971407244773

Epoch: 6| Step: 3
Training loss: 0.2049842710537621
Validation loss: 2.4847550537754883

Epoch: 6| Step: 4
Training loss: 0.1300998967368224
Validation loss: 2.4751956441830063

Epoch: 6| Step: 5
Training loss: 0.12294883076528547
Validation loss: 2.484744737307517

Epoch: 6| Step: 6
Training loss: 0.1792196735068941
Validation loss: 2.4697096467687194

Epoch: 6| Step: 7
Training loss: 0.1750276731000628
Validation loss: 2.4578815566152774

Epoch: 6| Step: 8
Training loss: 0.18675755492597354
Validation loss: 2.523632991757461

Epoch: 6| Step: 9
Training loss: 0.2521423398203234
Validation loss: 2.529663990773453

Epoch: 6| Step: 10
Training loss: 0.3077443057005235
Validation loss: 2.5360738819993522

Epoch: 6| Step: 11
Training loss: 0.2601352442603587
Validation loss: 2.5491704199011074

Epoch: 6| Step: 12
Training loss: 0.21402972938129983
Validation loss: 2.49890811107485

Epoch: 6| Step: 13
Training loss: 0.15047693253092334
Validation loss: 2.487330522647083

Epoch: 468| Step: 0
Training loss: 0.18796474755355125
Validation loss: 2.525893556502372

Epoch: 6| Step: 1
Training loss: 0.17450619364884734
Validation loss: 2.5351284974941333

Epoch: 6| Step: 2
Training loss: 0.15438955276058242
Validation loss: 2.50859506744811

Epoch: 6| Step: 3
Training loss: 0.2288338328568141
Validation loss: 2.50946337743824

Epoch: 6| Step: 4
Training loss: 0.1300375382507959
Validation loss: 2.5443689339975077

Epoch: 6| Step: 5
Training loss: 0.2595374747488084
Validation loss: 2.5436042727575487

Epoch: 6| Step: 6
Training loss: 0.2696153122660758
Validation loss: 2.5247177147361515

Epoch: 6| Step: 7
Training loss: 0.20247852631022917
Validation loss: 2.587347582235148

Epoch: 6| Step: 8
Training loss: 0.22334743598606752
Validation loss: 2.545958937488636

Epoch: 6| Step: 9
Training loss: 0.31165375569744524
Validation loss: 2.587303700649079

Epoch: 6| Step: 10
Training loss: 0.20034983184418026
Validation loss: 2.5307159295910875

Epoch: 6| Step: 11
Training loss: 0.200938506086806
Validation loss: 2.55408722033399

Epoch: 6| Step: 12
Training loss: 0.17867302622755735
Validation loss: 2.5278493465494103

Epoch: 6| Step: 13
Training loss: 0.22774660689415197
Validation loss: 2.516106788370228

Epoch: 469| Step: 0
Training loss: 0.1678407536240792
Validation loss: 2.495713938067854

Epoch: 6| Step: 1
Training loss: 0.299500090103104
Validation loss: 2.4527990387062877

Epoch: 6| Step: 2
Training loss: 0.1433840145795865
Validation loss: 2.498206074359783

Epoch: 6| Step: 3
Training loss: 0.11413495884590813
Validation loss: 2.4861138856657354

Epoch: 6| Step: 4
Training loss: 0.16538954093408445
Validation loss: 2.48637473573062

Epoch: 6| Step: 5
Training loss: 0.16244163703053538
Validation loss: 2.5079063888893196

Epoch: 6| Step: 6
Training loss: 0.1749108274650444
Validation loss: 2.5020174756270044

Epoch: 6| Step: 7
Training loss: 0.1654624361593272
Validation loss: 2.5076667570277054

Epoch: 6| Step: 8
Training loss: 0.23136824922384053
Validation loss: 2.53465488131052

Epoch: 6| Step: 9
Training loss: 0.12757239059623637
Validation loss: 2.5058927428525997

Epoch: 6| Step: 10
Training loss: 0.23606752576924395
Validation loss: 2.542339043027935

Epoch: 6| Step: 11
Training loss: 0.19846769013119597
Validation loss: 2.5011150211603304

Epoch: 6| Step: 12
Training loss: 0.2823016188979814
Validation loss: 2.509668491393224

Epoch: 6| Step: 13
Training loss: 0.18698712578164894
Validation loss: 2.512147862480743

Epoch: 470| Step: 0
Training loss: 0.2670806102098096
Validation loss: 2.5044215448969465

Epoch: 6| Step: 1
Training loss: 0.10430135413706469
Validation loss: 2.5054139755613116

Epoch: 6| Step: 2
Training loss: 0.2893031124109095
Validation loss: 2.505694949788023

Epoch: 6| Step: 3
Training loss: 0.16483304748323138
Validation loss: 2.509692611580341

Epoch: 6| Step: 4
Training loss: 0.19339907845437343
Validation loss: 2.516644542000989

Epoch: 6| Step: 5
Training loss: 0.22579512866966156
Validation loss: 2.5085390142819293

Epoch: 6| Step: 6
Training loss: 0.19665116270896635
Validation loss: 2.499780539396277

Epoch: 6| Step: 7
Training loss: 0.25786272195570437
Validation loss: 2.489120064094308

Epoch: 6| Step: 8
Training loss: 0.18577431241517692
Validation loss: 2.511814249387929

Epoch: 6| Step: 9
Training loss: 0.08986796695404697
Validation loss: 2.4737282929821047

Epoch: 6| Step: 10
Training loss: 0.16917722693631118
Validation loss: 2.4904770573837602

Epoch: 6| Step: 11
Training loss: 0.10636276579151305
Validation loss: 2.468995775351597

Epoch: 6| Step: 12
Training loss: 0.21731694878288696
Validation loss: 2.4797239090099685

Epoch: 6| Step: 13
Training loss: 0.18642431891034164
Validation loss: 2.478619294729889

Epoch: 471| Step: 0
Training loss: 0.1341204749976768
Validation loss: 2.515963350804041

Epoch: 6| Step: 1
Training loss: 0.099949871850516
Validation loss: 2.484482432471594

Epoch: 6| Step: 2
Training loss: 0.2045614363948352
Validation loss: 2.5008435743696373

Epoch: 6| Step: 3
Training loss: 0.18036834640352029
Validation loss: 2.548810247643732

Epoch: 6| Step: 4
Training loss: 0.18641089993966
Validation loss: 2.543598678025314

Epoch: 6| Step: 5
Training loss: 0.2113093524710858
Validation loss: 2.489634913162785

Epoch: 6| Step: 6
Training loss: 0.1564977172347634
Validation loss: 2.482900457306491

Epoch: 6| Step: 7
Training loss: 0.21858209739804177
Validation loss: 2.49932066855174

Epoch: 6| Step: 8
Training loss: 0.08853438700407631
Validation loss: 2.4790317989556327

Epoch: 6| Step: 9
Training loss: 0.1678575214005611
Validation loss: 2.4935525427037075

Epoch: 6| Step: 10
Training loss: 0.2771822230665709
Validation loss: 2.5257211161893993

Epoch: 6| Step: 11
Training loss: 0.3440482731198288
Validation loss: 2.450553984224527

Epoch: 6| Step: 12
Training loss: 0.16949282113946096
Validation loss: 2.4665689856523034

Epoch: 6| Step: 13
Training loss: 0.13974404563442597
Validation loss: 2.4591598369297705

Epoch: 472| Step: 0
Training loss: 0.2066071683339872
Validation loss: 2.4594457993368835

Epoch: 6| Step: 1
Training loss: 0.26754788415806824
Validation loss: 2.4899865354824695

Epoch: 6| Step: 2
Training loss: 0.3020291636119127
Validation loss: 2.5095060018632136

Epoch: 6| Step: 3
Training loss: 0.20692835356057393
Validation loss: 2.5232625778955264

Epoch: 6| Step: 4
Training loss: 0.12849241354363408
Validation loss: 2.512310929118485

Epoch: 6| Step: 5
Training loss: 0.19552988352701237
Validation loss: 2.528016316194946

Epoch: 6| Step: 6
Training loss: 0.14354361926117812
Validation loss: 2.5391997501708423

Epoch: 6| Step: 7
Training loss: 0.12068856037252888
Validation loss: 2.550115541329365

Epoch: 6| Step: 8
Training loss: 0.23942525804172554
Validation loss: 2.559977167183755

Epoch: 6| Step: 9
Training loss: 0.13783733672852522
Validation loss: 2.575067422726647

Epoch: 6| Step: 10
Training loss: 0.1474297850588642
Validation loss: 2.60547820176843

Epoch: 6| Step: 11
Training loss: 0.23533233785660745
Validation loss: 2.5783330431314506

Epoch: 6| Step: 12
Training loss: 0.12547527795058933
Validation loss: 2.5687449932136923

Epoch: 6| Step: 13
Training loss: 0.17809329629141799
Validation loss: 2.6000317885945847

Epoch: 473| Step: 0
Training loss: 0.09427558081705172
Validation loss: 2.5268071474418163

Epoch: 6| Step: 1
Training loss: 0.21115869827454503
Validation loss: 2.5375086278004435

Epoch: 6| Step: 2
Training loss: 0.1400896584847006
Validation loss: 2.549675130005546

Epoch: 6| Step: 3
Training loss: 0.12534043029349273
Validation loss: 2.5637210984876218

Epoch: 6| Step: 4
Training loss: 0.23002497734365734
Validation loss: 2.527321078914916

Epoch: 6| Step: 5
Training loss: 0.22406367478534872
Validation loss: 2.535645218252281

Epoch: 6| Step: 6
Training loss: 0.23218357467927256
Validation loss: 2.516340784846387

Epoch: 6| Step: 7
Training loss: 0.24050160408525986
Validation loss: 2.5354845769877516

Epoch: 6| Step: 8
Training loss: 0.1929290491260781
Validation loss: 2.540627792912451

Epoch: 6| Step: 9
Training loss: 0.23626913169820118
Validation loss: 2.524000455992468

Epoch: 6| Step: 10
Training loss: 0.11068459279632831
Validation loss: 2.545174857704312

Epoch: 6| Step: 11
Training loss: 0.13290640372333118
Validation loss: 2.4966427749374964

Epoch: 6| Step: 12
Training loss: 0.09933750599872768
Validation loss: 2.5187683298595203

Epoch: 6| Step: 13
Training loss: 0.2534923995419168
Validation loss: 2.503932814839272

Epoch: 474| Step: 0
Training loss: 0.2028287689872306
Validation loss: 2.4999645107580575

Epoch: 6| Step: 1
Training loss: 0.2324621021496061
Validation loss: 2.5525223798633365

Epoch: 6| Step: 2
Training loss: 0.15636356518237982
Validation loss: 2.5591886581339547

Epoch: 6| Step: 3
Training loss: 0.1171598322313818
Validation loss: 2.599561314849571

Epoch: 6| Step: 4
Training loss: 0.16043581636702323
Validation loss: 2.6034261905083813

Epoch: 6| Step: 5
Training loss: 0.21708906948347925
Validation loss: 2.6128965148829475

Epoch: 6| Step: 6
Training loss: 0.25074579338812486
Validation loss: 2.606505587391685

Epoch: 6| Step: 7
Training loss: 0.19405821503716852
Validation loss: 2.560238446239746

Epoch: 6| Step: 8
Training loss: 0.232200372757518
Validation loss: 2.583928551379884

Epoch: 6| Step: 9
Training loss: 0.17188119335286678
Validation loss: 2.558492771220418

Epoch: 6| Step: 10
Training loss: 0.19398510957748574
Validation loss: 2.5032236992914134

Epoch: 6| Step: 11
Training loss: 0.17365740847514372
Validation loss: 2.5288364328470982

Epoch: 6| Step: 12
Training loss: 0.2254877743853675
Validation loss: 2.4753258836037557

Epoch: 6| Step: 13
Training loss: 0.12911400525819117
Validation loss: 2.426995574520831

Epoch: 475| Step: 0
Training loss: 0.24736978075816096
Validation loss: 2.413558697122044

Epoch: 6| Step: 1
Training loss: 0.2572390507683986
Validation loss: 2.4125040340671458

Epoch: 6| Step: 2
Training loss: 0.1525177695326118
Validation loss: 2.4292666949203325

Epoch: 6| Step: 3
Training loss: 0.13866536031114934
Validation loss: 2.4135217057900173

Epoch: 6| Step: 4
Training loss: 0.16416372854690522
Validation loss: 2.5187719410651828

Epoch: 6| Step: 5
Training loss: 0.1613178924197236
Validation loss: 2.51713420487912

Epoch: 6| Step: 6
Training loss: 0.15295290813300125
Validation loss: 2.5472989394162022

Epoch: 6| Step: 7
Training loss: 0.2831093205285011
Validation loss: 2.5535705017063246

Epoch: 6| Step: 8
Training loss: 0.2543969913883565
Validation loss: 2.592266281574366

Epoch: 6| Step: 9
Training loss: 0.14648480733171879
Validation loss: 2.5546493921306745

Epoch: 6| Step: 10
Training loss: 0.17487600672440948
Validation loss: 2.5194921275703512

Epoch: 6| Step: 11
Training loss: 0.24079534891625298
Validation loss: 2.5465776340470008

Epoch: 6| Step: 12
Training loss: 0.13436616214254732
Validation loss: 2.475990076828866

Epoch: 6| Step: 13
Training loss: 0.17995109090659872
Validation loss: 2.5108368245037687

Epoch: 476| Step: 0
Training loss: 0.16195678423415563
Validation loss: 2.4510833189529566

Epoch: 6| Step: 1
Training loss: 0.1525386211960352
Validation loss: 2.5022636686363997

Epoch: 6| Step: 2
Training loss: 0.11513127547865863
Validation loss: 2.4164954907391873

Epoch: 6| Step: 3
Training loss: 0.11099468876051663
Validation loss: 2.426713942746537

Epoch: 6| Step: 4
Training loss: 0.12158231084094398
Validation loss: 2.4550712508929164

Epoch: 6| Step: 5
Training loss: 0.1569480917784827
Validation loss: 2.463582043209681

Epoch: 6| Step: 6
Training loss: 0.11591502590027195
Validation loss: 2.4763777903898965

Epoch: 6| Step: 7
Training loss: 0.11839647529962097
Validation loss: 2.488596399080238

Epoch: 6| Step: 8
Training loss: 0.29336521026049855
Validation loss: 2.4845895032893495

Epoch: 6| Step: 9
Training loss: 0.17292196919649006
Validation loss: 2.50522302754538

Epoch: 6| Step: 10
Training loss: 0.27112245105443944
Validation loss: 2.4699387165807023

Epoch: 6| Step: 11
Training loss: 0.17120287889945265
Validation loss: 2.5174466900581765

Epoch: 6| Step: 12
Training loss: 0.20251245940107782
Validation loss: 2.547245087576902

Epoch: 6| Step: 13
Training loss: 0.23354638968741603
Validation loss: 2.5209143222282977

Epoch: 477| Step: 0
Training loss: 0.11642599642406866
Validation loss: 2.525657967867318

Epoch: 6| Step: 1
Training loss: 0.2273649441779735
Validation loss: 2.5245060290415107

Epoch: 6| Step: 2
Training loss: 0.16809417787743156
Validation loss: 2.552247138895114

Epoch: 6| Step: 3
Training loss: 0.14677095989423086
Validation loss: 2.5303131784422734

Epoch: 6| Step: 4
Training loss: 0.1788397153045651
Validation loss: 2.5388166572689084

Epoch: 6| Step: 5
Training loss: 0.15357700654407622
Validation loss: 2.5697344791341683

Epoch: 6| Step: 6
Training loss: 0.27631412711157327
Validation loss: 2.543289617229057

Epoch: 6| Step: 7
Training loss: 0.16233284610738655
Validation loss: 2.5230396083667848

Epoch: 6| Step: 8
Training loss: 0.25401058987539954
Validation loss: 2.4922540078264146

Epoch: 6| Step: 9
Training loss: 0.08012004080926696
Validation loss: 2.4910386629966106

Epoch: 6| Step: 10
Training loss: 0.24796628769323287
Validation loss: 2.481580402179583

Epoch: 6| Step: 11
Training loss: 0.17666694244289766
Validation loss: 2.50790619671131

Epoch: 6| Step: 12
Training loss: 0.1910292454799556
Validation loss: 2.529305650546412

Epoch: 6| Step: 13
Training loss: 0.12923748634696938
Validation loss: 2.4933643595034747

Epoch: 478| Step: 0
Training loss: 0.1419127891645104
Validation loss: 2.5405570388029144

Epoch: 6| Step: 1
Training loss: 0.2037610402948369
Validation loss: 2.5609761450966104

Epoch: 6| Step: 2
Training loss: 0.17635074129024522
Validation loss: 2.553762928347922

Epoch: 6| Step: 3
Training loss: 0.17401846633472606
Validation loss: 2.5547587478324623

Epoch: 6| Step: 4
Training loss: 0.15553097989053324
Validation loss: 2.563353693191945

Epoch: 6| Step: 5
Training loss: 0.13655763397014822
Validation loss: 2.5626431877094706

Epoch: 6| Step: 6
Training loss: 0.23595627779477607
Validation loss: 2.5565905116759686

Epoch: 6| Step: 7
Training loss: 0.08236515683487108
Validation loss: 2.528203289556276

Epoch: 6| Step: 8
Training loss: 0.18453302965589966
Validation loss: 2.5253807201993386

Epoch: 6| Step: 9
Training loss: 0.25597370301536615
Validation loss: 2.5657902914889026

Epoch: 6| Step: 10
Training loss: 0.11279743978383014
Validation loss: 2.5632115458408693

Epoch: 6| Step: 11
Training loss: 0.24088295943922847
Validation loss: 2.5751617047543918

Epoch: 6| Step: 12
Training loss: 0.15749918362239398
Validation loss: 2.5527105676078574

Epoch: 6| Step: 13
Training loss: 0.09466647179019932
Validation loss: 2.561223113884888

Epoch: 479| Step: 0
Training loss: 0.1457098447973366
Validation loss: 2.5592286552803483

Epoch: 6| Step: 1
Training loss: 0.16163281401120203
Validation loss: 2.593234919753679

Epoch: 6| Step: 2
Training loss: 0.22232896609559094
Validation loss: 2.573396931271009

Epoch: 6| Step: 3
Training loss: 0.15978501489024757
Validation loss: 2.6079756912394783

Epoch: 6| Step: 4
Training loss: 0.17281527057413457
Validation loss: 2.5980725603915102

Epoch: 6| Step: 5
Training loss: 0.1472484118168711
Validation loss: 2.5947011347036244

Epoch: 6| Step: 6
Training loss: 0.1337241829929365
Validation loss: 2.562527060397111

Epoch: 6| Step: 7
Training loss: 0.15803036852940222
Validation loss: 2.556520540296726

Epoch: 6| Step: 8
Training loss: 0.20672186640828966
Validation loss: 2.551920868099455

Epoch: 6| Step: 9
Training loss: 0.1619241357023611
Validation loss: 2.5516465061636837

Epoch: 6| Step: 10
Training loss: 0.2693453576181272
Validation loss: 2.555301151643487

Epoch: 6| Step: 11
Training loss: 0.1919901563472937
Validation loss: 2.54098918552621

Epoch: 6| Step: 12
Training loss: 0.17299389770941426
Validation loss: 2.5531566225555298

Epoch: 6| Step: 13
Training loss: 0.13731291951101096
Validation loss: 2.5553059372063838

Epoch: 480| Step: 0
Training loss: 0.21059492337926958
Validation loss: 2.5360416224099525

Epoch: 6| Step: 1
Training loss: 0.19045934201695802
Validation loss: 2.5467067219765145

Epoch: 6| Step: 2
Training loss: 0.12606787514184692
Validation loss: 2.5721080762085036

Epoch: 6| Step: 3
Training loss: 0.1658716587328063
Validation loss: 2.6047904926590593

Epoch: 6| Step: 4
Training loss: 0.24856277192484347
Validation loss: 2.6341063898896366

Epoch: 6| Step: 5
Training loss: 0.15582482186785707
Validation loss: 2.6012647732431975

Epoch: 6| Step: 6
Training loss: 0.23259293648401855
Validation loss: 2.5314983639545052

Epoch: 6| Step: 7
Training loss: 0.10183849339557266
Validation loss: 2.569976834593023

Epoch: 6| Step: 8
Training loss: 0.12666214093584988
Validation loss: 2.5864465064644984

Epoch: 6| Step: 9
Training loss: 0.2551356994005808
Validation loss: 2.5860768378442227

Epoch: 6| Step: 10
Training loss: 0.20642706141642025
Validation loss: 2.5639881541960903

Epoch: 6| Step: 11
Training loss: 0.20495485506507546
Validation loss: 2.5693140101193923

Epoch: 6| Step: 12
Training loss: 0.18395265034386168
Validation loss: 2.55782888215055

Epoch: 6| Step: 13
Training loss: 0.3028052339380849
Validation loss: 2.542844061543878

Epoch: 481| Step: 0
Training loss: 0.15953328929946478
Validation loss: 2.536234003278356

Epoch: 6| Step: 1
Training loss: 0.15388784637405994
Validation loss: 2.5234274351426667

Epoch: 6| Step: 2
Training loss: 0.20082862977763055
Validation loss: 2.478155537087012

Epoch: 6| Step: 3
Training loss: 0.15333892320554132
Validation loss: 2.4397100090709154

Epoch: 6| Step: 4
Training loss: 0.24872961474759914
Validation loss: 2.4574916275324608

Epoch: 6| Step: 5
Training loss: 0.22307278337340314
Validation loss: 2.428132446558912

Epoch: 6| Step: 6
Training loss: 0.27409452792748684
Validation loss: 2.400329100440811

Epoch: 6| Step: 7
Training loss: 0.2437142272521744
Validation loss: 2.4360896053830374

Epoch: 6| Step: 8
Training loss: 0.22696620227214184
Validation loss: 2.4602072261664194

Epoch: 6| Step: 9
Training loss: 0.15238327345085295
Validation loss: 2.462500611983888

Epoch: 6| Step: 10
Training loss: 0.16008989773936416
Validation loss: 2.5292211362485393

Epoch: 6| Step: 11
Training loss: 0.20751785277641516
Validation loss: 2.5382613520534387

Epoch: 6| Step: 12
Training loss: 0.11380571600341292
Validation loss: 2.555673540974029

Epoch: 6| Step: 13
Training loss: 0.32903445320841834
Validation loss: 2.54625795037399

Epoch: 482| Step: 0
Training loss: 0.12126946774746938
Validation loss: 2.5675051839523158

Epoch: 6| Step: 1
Training loss: 0.1928027261207392
Validation loss: 2.5513809419526434

Epoch: 6| Step: 2
Training loss: 0.28125003973642704
Validation loss: 2.547200732524189

Epoch: 6| Step: 3
Training loss: 0.14058623839333173
Validation loss: 2.5267262184044528

Epoch: 6| Step: 4
Training loss: 0.25438173228922223
Validation loss: 2.5336131124019143

Epoch: 6| Step: 5
Training loss: 0.12017482832207349
Validation loss: 2.546511831234134

Epoch: 6| Step: 6
Training loss: 0.188437719740352
Validation loss: 2.503069244628624

Epoch: 6| Step: 7
Training loss: 0.1525830809788863
Validation loss: 2.4877439531085757

Epoch: 6| Step: 8
Training loss: 0.21097758583367338
Validation loss: 2.4661075026718016

Epoch: 6| Step: 9
Training loss: 0.21042291251125272
Validation loss: 2.4833058229838496

Epoch: 6| Step: 10
Training loss: 0.2629705922452663
Validation loss: 2.4304553637580586

Epoch: 6| Step: 11
Training loss: 0.25392520540346863
Validation loss: 2.4388438859374344

Epoch: 6| Step: 12
Training loss: 0.26299831400990825
Validation loss: 2.443074794201978

Epoch: 6| Step: 13
Training loss: 0.1300776747962103
Validation loss: 2.431049501316566

Epoch: 483| Step: 0
Training loss: 0.19200995664745468
Validation loss: 2.4640455722900403

Epoch: 6| Step: 1
Training loss: 0.13423061598171426
Validation loss: 2.4830049872782487

Epoch: 6| Step: 2
Training loss: 0.12049414249583591
Validation loss: 2.528726858413597

Epoch: 6| Step: 3
Training loss: 0.1833392774004838
Validation loss: 2.535800948120525

Epoch: 6| Step: 4
Training loss: 0.14346461162443974
Validation loss: 2.588858780214975

Epoch: 6| Step: 5
Training loss: 0.1397485707488018
Validation loss: 2.5686602555309057

Epoch: 6| Step: 6
Training loss: 0.25279638835554336
Validation loss: 2.5746740190403306

Epoch: 6| Step: 7
Training loss: 0.13164582143199852
Validation loss: 2.5762490436333474

Epoch: 6| Step: 8
Training loss: 0.2682122978288623
Validation loss: 2.573657133828576

Epoch: 6| Step: 9
Training loss: 0.1979531497122752
Validation loss: 2.572305911146685

Epoch: 6| Step: 10
Training loss: 0.11556659911866346
Validation loss: 2.5459730407213166

Epoch: 6| Step: 11
Training loss: 0.2567648408485834
Validation loss: 2.58068792557021

Epoch: 6| Step: 12
Training loss: 0.13847447166424726
Validation loss: 2.57163828682973

Epoch: 6| Step: 13
Training loss: 0.1831041463168391
Validation loss: 2.547096226224732

Epoch: 484| Step: 0
Training loss: 0.15113956810983858
Validation loss: 2.5269079436650084

Epoch: 6| Step: 1
Training loss: 0.14667566525040382
Validation loss: 2.491185188904058

Epoch: 6| Step: 2
Training loss: 0.23990648269343895
Validation loss: 2.5192826811331996

Epoch: 6| Step: 3
Training loss: 0.15856825524975757
Validation loss: 2.524676182834398

Epoch: 6| Step: 4
Training loss: 0.2335896845690253
Validation loss: 2.524016024167411

Epoch: 6| Step: 5
Training loss: 0.20889516512864514
Validation loss: 2.5120117861677183

Epoch: 6| Step: 6
Training loss: 0.12705802251776696
Validation loss: 2.477213320545409

Epoch: 6| Step: 7
Training loss: 0.09649804902575204
Validation loss: 2.500650831844586

Epoch: 6| Step: 8
Training loss: 0.10523975201401642
Validation loss: 2.5091468834541995

Epoch: 6| Step: 9
Training loss: 0.173480758341379
Validation loss: 2.506069418514058

Epoch: 6| Step: 10
Training loss: 0.18005057639286906
Validation loss: 2.4774110333593904

Epoch: 6| Step: 11
Training loss: 0.1068985589870127
Validation loss: 2.4875209181993285

Epoch: 6| Step: 12
Training loss: 0.14485770164505007
Validation loss: 2.5189635687604244

Epoch: 6| Step: 13
Training loss: 0.24617883180299663
Validation loss: 2.51077140827828

Epoch: 485| Step: 0
Training loss: 0.1718833552843908
Validation loss: 2.4911821788294066

Epoch: 6| Step: 1
Training loss: 0.11775897081132297
Validation loss: 2.4975931933786897

Epoch: 6| Step: 2
Training loss: 0.21738607227660953
Validation loss: 2.509013212609364

Epoch: 6| Step: 3
Training loss: 0.11553213878621969
Validation loss: 2.5153628241793413

Epoch: 6| Step: 4
Training loss: 0.15995116594066408
Validation loss: 2.492819883638565

Epoch: 6| Step: 5
Training loss: 0.09505343327369292
Validation loss: 2.5208445336637038

Epoch: 6| Step: 6
Training loss: 0.11224823237622493
Validation loss: 2.5385217678663228

Epoch: 6| Step: 7
Training loss: 0.21400371530964207
Validation loss: 2.529373065553041

Epoch: 6| Step: 8
Training loss: 0.28930394939989695
Validation loss: 2.5248200004157817

Epoch: 6| Step: 9
Training loss: 0.14284526933134517
Validation loss: 2.5364807805766936

Epoch: 6| Step: 10
Training loss: 0.19562519791017216
Validation loss: 2.50740458032205

Epoch: 6| Step: 11
Training loss: 0.20923453359061603
Validation loss: 2.5034778993843423

Epoch: 6| Step: 12
Training loss: 0.16771068265307987
Validation loss: 2.5057123837875053

Epoch: 6| Step: 13
Training loss: 0.11090814695754043
Validation loss: 2.522978949987016

Epoch: 486| Step: 0
Training loss: 0.18396227961080738
Validation loss: 2.5147171211519956

Epoch: 6| Step: 1
Training loss: 0.23265634458602713
Validation loss: 2.5007218436531677

Epoch: 6| Step: 2
Training loss: 0.24995108215246958
Validation loss: 2.473159660775174

Epoch: 6| Step: 3
Training loss: 0.10541436771322345
Validation loss: 2.517883466067303

Epoch: 6| Step: 4
Training loss: 0.13052279329566216
Validation loss: 2.5211015451994236

Epoch: 6| Step: 5
Training loss: 0.26581640920358884
Validation loss: 2.4965624361140106

Epoch: 6| Step: 6
Training loss: 0.2541129664589671
Validation loss: 2.512622962725857

Epoch: 6| Step: 7
Training loss: 0.12572521448310509
Validation loss: 2.515861381401016

Epoch: 6| Step: 8
Training loss: 0.12098210325476723
Validation loss: 2.5265855439427827

Epoch: 6| Step: 9
Training loss: 0.1405750556840537
Validation loss: 2.5667644505544756

Epoch: 6| Step: 10
Training loss: 0.21004992528787858
Validation loss: 2.5542725904143873

Epoch: 6| Step: 11
Training loss: 0.12805956879421948
Validation loss: 2.5466524151823307

Epoch: 6| Step: 12
Training loss: 0.10039874129382594
Validation loss: 2.5645394606840415

Epoch: 6| Step: 13
Training loss: 0.2262617861459825
Validation loss: 2.517169504498585

Epoch: 487| Step: 0
Training loss: 0.21304462707251254
Validation loss: 2.510780722342645

Epoch: 6| Step: 1
Training loss: 0.17135599192388298
Validation loss: 2.535026627498817

Epoch: 6| Step: 2
Training loss: 0.11628312185103855
Validation loss: 2.536728258474924

Epoch: 6| Step: 3
Training loss: 0.16735859877159098
Validation loss: 2.5389656112775625

Epoch: 6| Step: 4
Training loss: 0.08046666242150803
Validation loss: 2.4964452861846507

Epoch: 6| Step: 5
Training loss: 0.2612627811590801
Validation loss: 2.4879814393996846

Epoch: 6| Step: 6
Training loss: 0.14022786967455525
Validation loss: 2.5367358435901046

Epoch: 6| Step: 7
Training loss: 0.12493657947046591
Validation loss: 2.5019667744019056

Epoch: 6| Step: 8
Training loss: 0.1070963348419574
Validation loss: 2.578344591918514

Epoch: 6| Step: 9
Training loss: 0.24900482706576962
Validation loss: 2.5513460370447962

Epoch: 6| Step: 10
Training loss: 0.25633918384901705
Validation loss: 2.569947401669387

Epoch: 6| Step: 11
Training loss: 0.13936918521306613
Validation loss: 2.597162827975971

Epoch: 6| Step: 12
Training loss: 0.16268380205668356
Validation loss: 2.5747779536203663

Epoch: 6| Step: 13
Training loss: 0.12539807651043117
Validation loss: 2.6260005920982805

Epoch: 488| Step: 0
Training loss: 0.0932882730517533
Validation loss: 2.5552773982640633

Epoch: 6| Step: 1
Training loss: 0.11834169073154086
Validation loss: 2.583293767289336

Epoch: 6| Step: 2
Training loss: 0.24092740217093728
Validation loss: 2.544367405003115

Epoch: 6| Step: 3
Training loss: 0.1903819293265791
Validation loss: 2.5692614658621378

Epoch: 6| Step: 4
Training loss: 0.22607187883719215
Validation loss: 2.565114221240328

Epoch: 6| Step: 5
Training loss: 0.15859263353941358
Validation loss: 2.5593501815444983

Epoch: 6| Step: 6
Training loss: 0.10966576092502654
Validation loss: 2.563297336764661

Epoch: 6| Step: 7
Training loss: 0.12327708175028414
Validation loss: 2.6086262304142833

Epoch: 6| Step: 8
Training loss: 0.12334648244332921
Validation loss: 2.5720598490442304

Epoch: 6| Step: 9
Training loss: 0.13715659602667615
Validation loss: 2.584363113548391

Epoch: 6| Step: 10
Training loss: 0.18396591450271982
Validation loss: 2.560978217249441

Epoch: 6| Step: 11
Training loss: 0.23298929977098431
Validation loss: 2.545722502871592

Epoch: 6| Step: 12
Training loss: 0.10915135611422552
Validation loss: 2.5198706094765138

Epoch: 6| Step: 13
Training loss: 0.19488372467616627
Validation loss: 2.539201460475742

Epoch: 489| Step: 0
Training loss: 0.14479482304839894
Validation loss: 2.4898978654341732

Epoch: 6| Step: 1
Training loss: 0.12423066226054265
Validation loss: 2.4908316742457006

Epoch: 6| Step: 2
Training loss: 0.24972557861287062
Validation loss: 2.457915822471855

Epoch: 6| Step: 3
Training loss: 0.19393294449599818
Validation loss: 2.490881106680486

Epoch: 6| Step: 4
Training loss: 0.1508172597529249
Validation loss: 2.536540923035594

Epoch: 6| Step: 5
Training loss: 0.24707432317682557
Validation loss: 2.5437883669523265

Epoch: 6| Step: 6
Training loss: 0.1920746790025147
Validation loss: 2.537222553795401

Epoch: 6| Step: 7
Training loss: 0.1419709156898969
Validation loss: 2.568432024249507

Epoch: 6| Step: 8
Training loss: 0.17179231388686553
Validation loss: 2.5874876560929123

Epoch: 6| Step: 9
Training loss: 0.16668991706520314
Validation loss: 2.5668620178114407

Epoch: 6| Step: 10
Training loss: 0.2551468106805526
Validation loss: 2.591114162268622

Epoch: 6| Step: 11
Training loss: 0.11209208225501659
Validation loss: 2.5724387626574763

Epoch: 6| Step: 12
Training loss: 0.15514558050497795
Validation loss: 2.5716087936683034

Epoch: 6| Step: 13
Training loss: 0.11825370540922536
Validation loss: 2.579453829826943

Epoch: 490| Step: 0
Training loss: 0.10614823523802777
Validation loss: 2.59221189329767

Epoch: 6| Step: 1
Training loss: 0.15202588763880412
Validation loss: 2.5569007946907094

Epoch: 6| Step: 2
Training loss: 0.13516412778177764
Validation loss: 2.5503582563403357

Epoch: 6| Step: 3
Training loss: 0.17298723812075179
Validation loss: 2.531775817583338

Epoch: 6| Step: 4
Training loss: 0.12807066625991745
Validation loss: 2.5473930566302663

Epoch: 6| Step: 5
Training loss: 0.2128959620095522
Validation loss: 2.5273892660271495

Epoch: 6| Step: 6
Training loss: 0.1347096160932708
Validation loss: 2.5453960856530076

Epoch: 6| Step: 7
Training loss: 0.1723699919607295
Validation loss: 2.542649089996214

Epoch: 6| Step: 8
Training loss: 0.12580153408337574
Validation loss: 2.533398952535608

Epoch: 6| Step: 9
Training loss: 0.32633602557437175
Validation loss: 2.5522603063810867

Epoch: 6| Step: 10
Training loss: 0.11933207372975392
Validation loss: 2.529902866024843

Epoch: 6| Step: 11
Training loss: 0.2506011500390418
Validation loss: 2.5248168794030867

Epoch: 6| Step: 12
Training loss: 0.16094258957750013
Validation loss: 2.5291872297954843

Epoch: 6| Step: 13
Training loss: 0.1245760022440296
Validation loss: 2.507519446453708

Epoch: 491| Step: 0
Training loss: 0.23215678669067327
Validation loss: 2.5456803952214857

Epoch: 6| Step: 1
Training loss: 0.1019665128314583
Validation loss: 2.4882934217657087

Epoch: 6| Step: 2
Training loss: 0.16321888946572527
Validation loss: 2.5209934126501974

Epoch: 6| Step: 3
Training loss: 0.13377089272629308
Validation loss: 2.4797517936168774

Epoch: 6| Step: 4
Training loss: 0.10713833756082176
Validation loss: 2.5186691092460833

Epoch: 6| Step: 5
Training loss: 0.24780088527346586
Validation loss: 2.454724630180746

Epoch: 6| Step: 6
Training loss: 0.21779369892924694
Validation loss: 2.4787428902077635

Epoch: 6| Step: 7
Training loss: 0.18372962874419926
Validation loss: 2.5030613726239035

Epoch: 6| Step: 8
Training loss: 0.14430885990106818
Validation loss: 2.5530525136882125

Epoch: 6| Step: 9
Training loss: 0.1368731308291239
Validation loss: 2.5491652426735314

Epoch: 6| Step: 10
Training loss: 0.11179537346269403
Validation loss: 2.567626437302024

Epoch: 6| Step: 11
Training loss: 0.13149169908276123
Validation loss: 2.5601937219964

Epoch: 6| Step: 12
Training loss: 0.19246345611280766
Validation loss: 2.5593398241897294

Epoch: 6| Step: 13
Training loss: 0.15970047786031447
Validation loss: 2.561422215907247

Epoch: 492| Step: 0
Training loss: 0.1583502168082068
Validation loss: 2.5512760150299294

Epoch: 6| Step: 1
Training loss: 0.13034736045806813
Validation loss: 2.5921002075796604

Epoch: 6| Step: 2
Training loss: 0.11602723403929073
Validation loss: 2.56923543280792

Epoch: 6| Step: 3
Training loss: 0.11467832227801636
Validation loss: 2.558879477572011

Epoch: 6| Step: 4
Training loss: 0.09758930772912751
Validation loss: 2.5488824674101407

Epoch: 6| Step: 5
Training loss: 0.11989150517017676
Validation loss: 2.523105250111372

Epoch: 6| Step: 6
Training loss: 0.24141675068260507
Validation loss: 2.4876169350884525

Epoch: 6| Step: 7
Training loss: 0.2154927940314478
Validation loss: 2.515368514328429

Epoch: 6| Step: 8
Training loss: 0.2704791112333283
Validation loss: 2.512889864811135

Epoch: 6| Step: 9
Training loss: 0.1588105678658499
Validation loss: 2.4843405691970077

Epoch: 6| Step: 10
Training loss: 0.1987146094740136
Validation loss: 2.5043431472432505

Epoch: 6| Step: 11
Training loss: 0.1433333682551822
Validation loss: 2.482403392385212

Epoch: 6| Step: 12
Training loss: 0.15568251075698158
Validation loss: 2.4941776669351032

Epoch: 6| Step: 13
Training loss: 0.19042822030309187
Validation loss: 2.527555198032213

Epoch: 493| Step: 0
Training loss: 0.10386505618998568
Validation loss: 2.5644580874224667

Epoch: 6| Step: 1
Training loss: 0.09415938479335577
Validation loss: 2.5683024870790034

Epoch: 6| Step: 2
Training loss: 0.1874910590901107
Validation loss: 2.642318006166279

Epoch: 6| Step: 3
Training loss: 0.1589997509074959
Validation loss: 2.5854890372099097

Epoch: 6| Step: 4
Training loss: 0.26138751576768243
Validation loss: 2.579462127630529

Epoch: 6| Step: 5
Training loss: 0.24763310080559406
Validation loss: 2.5989442072343127

Epoch: 6| Step: 6
Training loss: 0.09390462601030218
Validation loss: 2.5614665879201044

Epoch: 6| Step: 7
Training loss: 0.13710674000786516
Validation loss: 2.567993765884411

Epoch: 6| Step: 8
Training loss: 0.20736750700188414
Validation loss: 2.5570825716398873

Epoch: 6| Step: 9
Training loss: 0.23323056236918296
Validation loss: 2.498447384727165

Epoch: 6| Step: 10
Training loss: 0.17763022630601305
Validation loss: 2.4926098796626674

Epoch: 6| Step: 11
Training loss: 0.14923166224151177
Validation loss: 2.4679484875089153

Epoch: 6| Step: 12
Training loss: 0.11003102953362473
Validation loss: 2.447968111215457

Epoch: 6| Step: 13
Training loss: 0.173136809812135
Validation loss: 2.4128395798381823

Epoch: 494| Step: 0
Training loss: 0.3086744999562742
Validation loss: 2.408747092907353

Epoch: 6| Step: 1
Training loss: 0.1555851141438306
Validation loss: 2.4234257047410623

Epoch: 6| Step: 2
Training loss: 0.1851126861024975
Validation loss: 2.4245727407510684

Epoch: 6| Step: 3
Training loss: 0.15611949477327913
Validation loss: 2.434903605467745

Epoch: 6| Step: 4
Training loss: 0.26797696481908445
Validation loss: 2.4820471055262003

Epoch: 6| Step: 5
Training loss: 0.11540743392235829
Validation loss: 2.5109554832962058

Epoch: 6| Step: 6
Training loss: 0.1194253630153073
Validation loss: 2.5187908468840514

Epoch: 6| Step: 7
Training loss: 0.2693936922973942
Validation loss: 2.5742577876254167

Epoch: 6| Step: 8
Training loss: 0.13453253338918264
Validation loss: 2.5650344248655643

Epoch: 6| Step: 9
Training loss: 0.14045625735053593
Validation loss: 2.559280666262732

Epoch: 6| Step: 10
Training loss: 0.16228188677037902
Validation loss: 2.5494470684897546

Epoch: 6| Step: 11
Training loss: 0.14173540827076256
Validation loss: 2.5921333815925736

Epoch: 6| Step: 12
Training loss: 0.19499303440038615
Validation loss: 2.595589397820513

Epoch: 6| Step: 13
Training loss: 0.19068769924687293
Validation loss: 2.560512783632409

Epoch: 495| Step: 0
Training loss: 0.18869904743023894
Validation loss: 2.5661962249685435

Epoch: 6| Step: 1
Training loss: 0.16372818035249811
Validation loss: 2.5597283565568727

Epoch: 6| Step: 2
Training loss: 0.16304603819547833
Validation loss: 2.51739096586473

Epoch: 6| Step: 3
Training loss: 0.33955847067981404
Validation loss: 2.517889446807639

Epoch: 6| Step: 4
Training loss: 0.1850071536111574
Validation loss: 2.499851557723814

Epoch: 6| Step: 5
Training loss: 0.2474079012018851
Validation loss: 2.4781580084954173

Epoch: 6| Step: 6
Training loss: 0.22715409912243512
Validation loss: 2.450956833976531

Epoch: 6| Step: 7
Training loss: 0.1273732423272681
Validation loss: 2.457379525429746

Epoch: 6| Step: 8
Training loss: 0.19631046918603764
Validation loss: 2.452500076072337

Epoch: 6| Step: 9
Training loss: 0.18881745221078164
Validation loss: 2.496831901572909

Epoch: 6| Step: 10
Training loss: 0.20232260383663345
Validation loss: 2.4829190696731924

Epoch: 6| Step: 11
Training loss: 0.2255213921755121
Validation loss: 2.5065208157197265

Epoch: 6| Step: 12
Training loss: 0.1711874887961544
Validation loss: 2.5575973538227044

Epoch: 6| Step: 13
Training loss: 0.2928462344536332
Validation loss: 2.5718238492250167

Epoch: 496| Step: 0
Training loss: 0.18990538385459557
Validation loss: 2.5913814558541106

Epoch: 6| Step: 1
Training loss: 0.1455877839573439
Validation loss: 2.5981254850213737

Epoch: 6| Step: 2
Training loss: 0.230655828614852
Validation loss: 2.5764747207826737

Epoch: 6| Step: 3
Training loss: 0.34565162275055633
Validation loss: 2.5474993611521457

Epoch: 6| Step: 4
Training loss: 0.196717283866091
Validation loss: 2.588664569282198

Epoch: 6| Step: 5
Training loss: 0.24748924231991765
Validation loss: 2.5836619900117976

Epoch: 6| Step: 6
Training loss: 0.17500104478115466
Validation loss: 2.5203330064579923

Epoch: 6| Step: 7
Training loss: 0.16151120232919247
Validation loss: 2.466338891360218

Epoch: 6| Step: 8
Training loss: 0.23839510089477614
Validation loss: 2.4729196381969403

Epoch: 6| Step: 9
Training loss: 0.18284432672120507
Validation loss: 2.4882678510981555

Epoch: 6| Step: 10
Training loss: 0.13708833060195139
Validation loss: 2.4859266645995466

Epoch: 6| Step: 11
Training loss: 0.182733254088788
Validation loss: 2.448051486276897

Epoch: 6| Step: 12
Training loss: 0.2513583652279001
Validation loss: 2.4419664039433693

Epoch: 6| Step: 13
Training loss: 0.14077280806740458
Validation loss: 2.4843017315535962

Epoch: 497| Step: 0
Training loss: 0.1718019200061739
Validation loss: 2.4728661798799516

Epoch: 6| Step: 1
Training loss: 0.15919385156627106
Validation loss: 2.4404904910541805

Epoch: 6| Step: 2
Training loss: 0.1915026441471231
Validation loss: 2.4444782315184823

Epoch: 6| Step: 3
Training loss: 0.1602722190050093
Validation loss: 2.4402483324955537

Epoch: 6| Step: 4
Training loss: 0.22654724069706975
Validation loss: 2.4660526647903978

Epoch: 6| Step: 5
Training loss: 0.12371031966685998
Validation loss: 2.441321033459008

Epoch: 6| Step: 6
Training loss: 0.20018781322296345
Validation loss: 2.4558903579669007

Epoch: 6| Step: 7
Training loss: 0.09777308151174215
Validation loss: 2.477321128788373

Epoch: 6| Step: 8
Training loss: 0.15551390112058744
Validation loss: 2.4836540680146975

Epoch: 6| Step: 9
Training loss: 0.20595162874301526
Validation loss: 2.4786138392985357

Epoch: 6| Step: 10
Training loss: 0.13602888581666261
Validation loss: 2.486152219116438

Epoch: 6| Step: 11
Training loss: 0.23182704686742495
Validation loss: 2.529152411629022

Epoch: 6| Step: 12
Training loss: 0.13210149792288303
Validation loss: 2.4978553207015732

Epoch: 6| Step: 13
Training loss: 0.11615460096147767
Validation loss: 2.524823761618065

Epoch: 498| Step: 0
Training loss: 0.1738951264600081
Validation loss: 2.5696838025928157

Epoch: 6| Step: 1
Training loss: 0.1310611990435224
Validation loss: 2.569711681473463

Epoch: 6| Step: 2
Training loss: 0.11553700762175063
Validation loss: 2.5723467707130245

Epoch: 6| Step: 3
Training loss: 0.10085763623949805
Validation loss: 2.607225040928657

Epoch: 6| Step: 4
Training loss: 0.1507407114154859
Validation loss: 2.5792483848324967

Epoch: 6| Step: 5
Training loss: 0.20199540468574115
Validation loss: 2.6071546636946663

Epoch: 6| Step: 6
Training loss: 0.23401928770167918
Validation loss: 2.593004150334848

Epoch: 6| Step: 7
Training loss: 0.22061314056552483
Validation loss: 2.5723289372136415

Epoch: 6| Step: 8
Training loss: 0.17407780300069856
Validation loss: 2.583194374567391

Epoch: 6| Step: 9
Training loss: 0.15506017782870327
Validation loss: 2.5666475693107156

Epoch: 6| Step: 10
Training loss: 0.14190536662433523
Validation loss: 2.504072472701183

Epoch: 6| Step: 11
Training loss: 0.1607233683067029
Validation loss: 2.5391648239581968

Epoch: 6| Step: 12
Training loss: 0.18169692407803573
Validation loss: 2.5049141577310383

Epoch: 6| Step: 13
Training loss: 0.07451102467684875
Validation loss: 2.488407726721036

Epoch: 499| Step: 0
Training loss: 0.18346520245578501
Validation loss: 2.493561142810009

Epoch: 6| Step: 1
Training loss: 0.21292540064968063
Validation loss: 2.495097070720477

Epoch: 6| Step: 2
Training loss: 0.20570751068157303
Validation loss: 2.5084293345335738

Epoch: 6| Step: 3
Training loss: 0.13152281699559645
Validation loss: 2.5271302320494793

Epoch: 6| Step: 4
Training loss: 0.2498158581393227
Validation loss: 2.507820282466143

Epoch: 6| Step: 5
Training loss: 0.14694503828853941
Validation loss: 2.501162469968402

Epoch: 6| Step: 6
Training loss: 0.14527421800814538
Validation loss: 2.532816386168775

Epoch: 6| Step: 7
Training loss: 0.2178469478234019
Validation loss: 2.4949705940174316

Epoch: 6| Step: 8
Training loss: 0.14377755750969348
Validation loss: 2.542387049469641

Epoch: 6| Step: 9
Training loss: 0.1552325860752186
Validation loss: 2.536898261481874

Epoch: 6| Step: 10
Training loss: 0.22186847663745854
Validation loss: 2.5709900581199965

Epoch: 6| Step: 11
Training loss: 0.1336848695548831
Validation loss: 2.537207704734182

Epoch: 6| Step: 12
Training loss: 0.13445186024790806
Validation loss: 2.5403131229259084

Epoch: 6| Step: 13
Training loss: 0.23952120860055104
Validation loss: 2.521696985327614

Epoch: 500| Step: 0
Training loss: 0.1777457977648584
Validation loss: 2.565209189893127

Epoch: 6| Step: 1
Training loss: 0.12180661138092108
Validation loss: 2.547978231505807

Epoch: 6| Step: 2
Training loss: 0.21504098335260535
Validation loss: 2.519049742071266

Epoch: 6| Step: 3
Training loss: 0.08963277135525702
Validation loss: 2.578256776088867

Epoch: 6| Step: 4
Training loss: 0.20506878786175337
Validation loss: 2.471828164244118

Epoch: 6| Step: 5
Training loss: 0.14695453215213836
Validation loss: 2.50574139925949

Epoch: 6| Step: 6
Training loss: 0.17584563241862522
Validation loss: 2.5204701058140437

Epoch: 6| Step: 7
Training loss: 0.18416041316840723
Validation loss: 2.478864797398356

Epoch: 6| Step: 8
Training loss: 0.15157035605726535
Validation loss: 2.4906346047778842

Epoch: 6| Step: 9
Training loss: 0.19724042183800466
Validation loss: 2.476827003642215

Epoch: 6| Step: 10
Training loss: 0.1783510660014794
Validation loss: 2.5135348097521955

Epoch: 6| Step: 11
Training loss: 0.23894512218288783
Validation loss: 2.534926487836792

Epoch: 6| Step: 12
Training loss: 0.15860372615311918
Validation loss: 2.494379618959434

Epoch: 6| Step: 13
Training loss: 0.1253000918925756
Validation loss: 2.54400493788219

Epoch: 501| Step: 0
Training loss: 0.19697716839699844
Validation loss: 2.55174308318531

Epoch: 6| Step: 1
Training loss: 0.17125330457144228
Validation loss: 2.5213774159443076

Epoch: 6| Step: 2
Training loss: 0.16378584310222968
Validation loss: 2.549589806785002

Epoch: 6| Step: 3
Training loss: 0.21145886873700492
Validation loss: 2.507228053959815

Epoch: 6| Step: 4
Training loss: 0.2316058443149442
Validation loss: 2.5449992870656426

Epoch: 6| Step: 5
Training loss: 0.14773415523615588
Validation loss: 2.5101755263230734

Epoch: 6| Step: 6
Training loss: 0.08601708953158073
Validation loss: 2.5450992379033135

Epoch: 6| Step: 7
Training loss: 0.20608385611812438
Validation loss: 2.5462881247931164

Epoch: 6| Step: 8
Training loss: 0.20044848552987168
Validation loss: 2.5518246398830016

Epoch: 6| Step: 9
Training loss: 0.0901196173235746
Validation loss: 2.56958232828584

Epoch: 6| Step: 10
Training loss: 0.2004584095548449
Validation loss: 2.5633867811818787

Epoch: 6| Step: 11
Training loss: 0.1377274225549916
Validation loss: 2.574823758220565

Epoch: 6| Step: 12
Training loss: 0.14598966348323555
Validation loss: 2.5370123611627564

Epoch: 6| Step: 13
Training loss: 0.11794759295385815
Validation loss: 2.5857854697514844

Epoch: 502| Step: 0
Training loss: 0.15648871901906006
Validation loss: 2.5875612355994173

Epoch: 6| Step: 1
Training loss: 0.2296808968457703
Validation loss: 2.609640352480835

Epoch: 6| Step: 2
Training loss: 0.19049444809154956
Validation loss: 2.574408948147421

Epoch: 6| Step: 3
Training loss: 0.153486611145811
Validation loss: 2.547550854851229

Epoch: 6| Step: 4
Training loss: 0.11270253159988076
Validation loss: 2.5385199621732832

Epoch: 6| Step: 5
Training loss: 0.20168804871750773
Validation loss: 2.5502054063585895

Epoch: 6| Step: 6
Training loss: 0.09475693756436797
Validation loss: 2.556128722143406

Epoch: 6| Step: 7
Training loss: 0.23177624635411706
Validation loss: 2.5436548954035607

Epoch: 6| Step: 8
Training loss: 0.14900340574327722
Validation loss: 2.5633970531784436

Epoch: 6| Step: 9
Training loss: 0.11584142634009059
Validation loss: 2.5689084435639695

Epoch: 6| Step: 10
Training loss: 0.12010188896945262
Validation loss: 2.5668298560230927

Epoch: 6| Step: 11
Training loss: 0.15754247404907432
Validation loss: 2.5727247771331623

Epoch: 6| Step: 12
Training loss: 0.1708142209313551
Validation loss: 2.5522872337738147

Epoch: 6| Step: 13
Training loss: 0.11729770485277133
Validation loss: 2.5458574313808353

Epoch: 503| Step: 0
Training loss: 0.1235131443903795
Validation loss: 2.546264829005105

Epoch: 6| Step: 1
Training loss: 0.19313107122982892
Validation loss: 2.569303451464109

Epoch: 6| Step: 2
Training loss: 0.06941982352715577
Validation loss: 2.5319611150449477

Epoch: 6| Step: 3
Training loss: 0.0935747176929183
Validation loss: 2.5377649320795865

Epoch: 6| Step: 4
Training loss: 0.24402969892128332
Validation loss: 2.5470904579930624

Epoch: 6| Step: 5
Training loss: 0.09174952401783518
Validation loss: 2.556228023189576

Epoch: 6| Step: 6
Training loss: 0.14742924179083355
Validation loss: 2.5627685114065266

Epoch: 6| Step: 7
Training loss: 0.12260107238930208
Validation loss: 2.520256260335565

Epoch: 6| Step: 8
Training loss: 0.13326262182885493
Validation loss: 2.541259269670211

Epoch: 6| Step: 9
Training loss: 0.16715335318978713
Validation loss: 2.5663692736228616

Epoch: 6| Step: 10
Training loss: 0.14299829834312394
Validation loss: 2.5179214986094567

Epoch: 6| Step: 11
Training loss: 0.23550996949927028
Validation loss: 2.5416579785157305

Epoch: 6| Step: 12
Training loss: 0.1113374982200756
Validation loss: 2.563493979555527

Epoch: 6| Step: 13
Training loss: 0.2756026108183821
Validation loss: 2.5482342387838983

Epoch: 504| Step: 0
Training loss: 0.110621278849749
Validation loss: 2.540279213144019

Epoch: 6| Step: 1
Training loss: 0.07582094588253464
Validation loss: 2.557262375291283

Epoch: 6| Step: 2
Training loss: 0.15422395600766184
Validation loss: 2.535181171782598

Epoch: 6| Step: 3
Training loss: 0.15310014114230108
Validation loss: 2.5202126140905836

Epoch: 6| Step: 4
Training loss: 0.22559027234160742
Validation loss: 2.5494252948477705

Epoch: 6| Step: 5
Training loss: 0.08523900468771993
Validation loss: 2.5343151698616615

Epoch: 6| Step: 6
Training loss: 0.11799224862632135
Validation loss: 2.524960558248298

Epoch: 6| Step: 7
Training loss: 0.18182354607241405
Validation loss: 2.5387416003871843

Epoch: 6| Step: 8
Training loss: 0.14444238276174362
Validation loss: 2.555749147323018

Epoch: 6| Step: 9
Training loss: 0.12865076612238116
Validation loss: 2.530393399059205

Epoch: 6| Step: 10
Training loss: 0.24179950521637783
Validation loss: 2.563179084202079

Epoch: 6| Step: 11
Training loss: 0.1555732495658011
Validation loss: 2.5276515479289543

Epoch: 6| Step: 12
Training loss: 0.1108460319572912
Validation loss: 2.5131067068245563

Epoch: 6| Step: 13
Training loss: 0.1872354369484768
Validation loss: 2.523121157077382

Epoch: 505| Step: 0
Training loss: 0.23311404534852032
Validation loss: 2.515647569617674

Epoch: 6| Step: 1
Training loss: 0.1134256191113904
Validation loss: 2.5277615949369725

Epoch: 6| Step: 2
Training loss: 0.1153114715584584
Validation loss: 2.5556115626130285

Epoch: 6| Step: 3
Training loss: 0.10730058151154868
Validation loss: 2.5251142546037246

Epoch: 6| Step: 4
Training loss: 0.10778942517737079
Validation loss: 2.509452884163033

Epoch: 6| Step: 5
Training loss: 0.1156957812428888
Validation loss: 2.5039176004471937

Epoch: 6| Step: 6
Training loss: 0.1346896206031661
Validation loss: 2.540368266100959

Epoch: 6| Step: 7
Training loss: 0.2445826001226709
Validation loss: 2.514874565931844

Epoch: 6| Step: 8
Training loss: 0.22297265342765463
Validation loss: 2.539585344801573

Epoch: 6| Step: 9
Training loss: 0.1299980770711632
Validation loss: 2.5269253956636204

Epoch: 6| Step: 10
Training loss: 0.1779384698804518
Validation loss: 2.5340585991119355

Epoch: 6| Step: 11
Training loss: 0.14227511593720601
Validation loss: 2.551589888650437

Epoch: 6| Step: 12
Training loss: 0.10597888879300262
Validation loss: 2.553837034809023

Epoch: 6| Step: 13
Training loss: 0.056405087429968304
Validation loss: 2.5505041500733836

Epoch: 506| Step: 0
Training loss: 0.07771488968645777
Validation loss: 2.502185398551633

Epoch: 6| Step: 1
Training loss: 0.1530527099930253
Validation loss: 2.4925716511816414

Epoch: 6| Step: 2
Training loss: 0.09451504324079545
Validation loss: 2.5305365850045067

Epoch: 6| Step: 3
Training loss: 0.09601816077022701
Validation loss: 2.5165708884931277

Epoch: 6| Step: 4
Training loss: 0.12865450147108193
Validation loss: 2.5127940109611746

Epoch: 6| Step: 5
Training loss: 0.15036265620956787
Validation loss: 2.490841448831272

Epoch: 6| Step: 6
Training loss: 0.22333267427253506
Validation loss: 2.4828780567167623

Epoch: 6| Step: 7
Training loss: 0.10457125462053138
Validation loss: 2.4936484931236533

Epoch: 6| Step: 8
Training loss: 0.22953567904411856
Validation loss: 2.4722868803494

Epoch: 6| Step: 9
Training loss: 0.16254569704083108
Validation loss: 2.500764712411987

Epoch: 6| Step: 10
Training loss: 0.09274485298293672
Validation loss: 2.552692808831904

Epoch: 6| Step: 11
Training loss: 0.2318931142718252
Validation loss: 2.52830222625462

Epoch: 6| Step: 12
Training loss: 0.16431611191090564
Validation loss: 2.564683183765304

Epoch: 6| Step: 13
Training loss: 0.12055534989387184
Validation loss: 2.5472522121314913

Epoch: 507| Step: 0
Training loss: 0.14707622490861869
Validation loss: 2.58227613260653

Epoch: 6| Step: 1
Training loss: 0.24495656803585336
Validation loss: 2.566133935305847

Epoch: 6| Step: 2
Training loss: 0.14037809949732702
Validation loss: 2.5597744124273683

Epoch: 6| Step: 3
Training loss: 0.15719008763081274
Validation loss: 2.553987439558797

Epoch: 6| Step: 4
Training loss: 0.1668045316899744
Validation loss: 2.579691879423674

Epoch: 6| Step: 5
Training loss: 0.2277524054376177
Validation loss: 2.5710720168513235

Epoch: 6| Step: 6
Training loss: 0.14279617332063202
Validation loss: 2.552750398115593

Epoch: 6| Step: 7
Training loss: 0.1364096348682281
Validation loss: 2.5676322362795467

Epoch: 6| Step: 8
Training loss: 0.1534895297189426
Validation loss: 2.5479061219427472

Epoch: 6| Step: 9
Training loss: 0.14882484517525968
Validation loss: 2.5277746830766206

Epoch: 6| Step: 10
Training loss: 0.14430148316126398
Validation loss: 2.4952888768280883

Epoch: 6| Step: 11
Training loss: 0.22266200543376916
Validation loss: 2.530127242523197

Epoch: 6| Step: 12
Training loss: 0.1534695961551569
Validation loss: 2.4585958778283015

Epoch: 6| Step: 13
Training loss: 0.07041917761627724
Validation loss: 2.4991007715576843

Epoch: 508| Step: 0
Training loss: 0.14223044606234
Validation loss: 2.4694667630809803

Epoch: 6| Step: 1
Training loss: 0.14040846843397525
Validation loss: 2.5218077994594275

Epoch: 6| Step: 2
Training loss: 0.14499714225797525
Validation loss: 2.474499701876721

Epoch: 6| Step: 3
Training loss: 0.2110876855607357
Validation loss: 2.5427435572705526

Epoch: 6| Step: 4
Training loss: 0.10143514130506584
Validation loss: 2.49168876898523

Epoch: 6| Step: 5
Training loss: 0.12190989062142114
Validation loss: 2.514472976363017

Epoch: 6| Step: 6
Training loss: 0.13484073701854
Validation loss: 2.5304293368761837

Epoch: 6| Step: 7
Training loss: 0.14254442888038765
Validation loss: 2.538489553018861

Epoch: 6| Step: 8
Training loss: 0.21258789376521656
Validation loss: 2.5358033865998717

Epoch: 6| Step: 9
Training loss: 0.1686654501606146
Validation loss: 2.538020229673911

Epoch: 6| Step: 10
Training loss: 0.25945834578740784
Validation loss: 2.5339692867240364

Epoch: 6| Step: 11
Training loss: 0.12774795990778126
Validation loss: 2.5152682310816696

Epoch: 6| Step: 12
Training loss: 0.11599028500055085
Validation loss: 2.545576346167732

Epoch: 6| Step: 13
Training loss: 0.1572890128033902
Validation loss: 2.5412538806164617

Epoch: 509| Step: 0
Training loss: 0.15474190694394777
Validation loss: 2.544674087773995

Epoch: 6| Step: 1
Training loss: 0.08204727640727587
Validation loss: 2.5766493953768115

Epoch: 6| Step: 2
Training loss: 0.14104858155980865
Validation loss: 2.5682468349255902

Epoch: 6| Step: 3
Training loss: 0.10469200512458664
Validation loss: 2.545549805012278

Epoch: 6| Step: 4
Training loss: 0.07452467559512227
Validation loss: 2.5424050244260616

Epoch: 6| Step: 5
Training loss: 0.16799364349070636
Validation loss: 2.5433664298419716

Epoch: 6| Step: 6
Training loss: 0.10346333514584294
Validation loss: 2.5218496637484287

Epoch: 6| Step: 7
Training loss: 0.11565555767984877
Validation loss: 2.554331039331888

Epoch: 6| Step: 8
Training loss: 0.13644656608042816
Validation loss: 2.5546868196237966

Epoch: 6| Step: 9
Training loss: 0.13329749749579026
Validation loss: 2.52127110513991

Epoch: 6| Step: 10
Training loss: 0.21430231708398964
Validation loss: 2.5570390313895843

Epoch: 6| Step: 11
Training loss: 0.12396221827648778
Validation loss: 2.5508101608556846

Epoch: 6| Step: 12
Training loss: 0.09001422858185569
Validation loss: 2.55701605662456

Epoch: 6| Step: 13
Training loss: 0.32117206101167417
Validation loss: 2.557615212859688

Epoch: 510| Step: 0
Training loss: 0.12103448463488753
Validation loss: 2.518701017788936

Epoch: 6| Step: 1
Training loss: 0.23840079670013284
Validation loss: 2.543882108149662

Epoch: 6| Step: 2
Training loss: 0.11291095623161214
Validation loss: 2.549635215258093

Epoch: 6| Step: 3
Training loss: 0.07843284157107772
Validation loss: 2.5889062191266676

Epoch: 6| Step: 4
Training loss: 0.15955709404982685
Validation loss: 2.5808281045975208

Epoch: 6| Step: 5
Training loss: 0.10421107706451965
Validation loss: 2.5496777301686904

Epoch: 6| Step: 6
Training loss: 0.16799007324781556
Validation loss: 2.603227965136518

Epoch: 6| Step: 7
Training loss: 0.07591038226591254
Validation loss: 2.5608626871647853

Epoch: 6| Step: 8
Training loss: 0.10361458888114121
Validation loss: 2.5830905957722137

Epoch: 6| Step: 9
Training loss: 0.2762116577544739
Validation loss: 2.5410112271839886

Epoch: 6| Step: 10
Training loss: 0.16177022455677736
Validation loss: 2.569861947968287

Epoch: 6| Step: 11
Training loss: 0.1170055526652202
Validation loss: 2.5784780927383713

Epoch: 6| Step: 12
Training loss: 0.11674989214643035
Validation loss: 2.5356590179098855

Epoch: 6| Step: 13
Training loss: 0.17269894494924173
Validation loss: 2.5513990766110144

Epoch: 511| Step: 0
Training loss: 0.08002850693318073
Validation loss: 2.5265056813578814

Epoch: 6| Step: 1
Training loss: 0.26121175823764436
Validation loss: 2.539886414637673

Epoch: 6| Step: 2
Training loss: 0.11153710142964536
Validation loss: 2.5281633592869914

Epoch: 6| Step: 3
Training loss: 0.13578452678102249
Validation loss: 2.5556615065460693

Epoch: 6| Step: 4
Training loss: 0.11633561762857425
Validation loss: 2.5436397230775913

Epoch: 6| Step: 5
Training loss: 0.15415366685567883
Validation loss: 2.5301533233339737

Epoch: 6| Step: 6
Training loss: 0.12204295805570949
Validation loss: 2.5429590638777713

Epoch: 6| Step: 7
Training loss: 0.12836043080541712
Validation loss: 2.564527990179996

Epoch: 6| Step: 8
Training loss: 0.12549510150588047
Validation loss: 2.542876466209788

Epoch: 6| Step: 9
Training loss: 0.1352940441301974
Validation loss: 2.545801814983332

Epoch: 6| Step: 10
Training loss: 0.11180666502120083
Validation loss: 2.5416135320113997

Epoch: 6| Step: 11
Training loss: 0.2165319783306824
Validation loss: 2.547787143946574

Epoch: 6| Step: 12
Training loss: 0.09454780110574029
Validation loss: 2.5675246255714166

Epoch: 6| Step: 13
Training loss: 0.11360106868333564
Validation loss: 2.5694556103454227

Epoch: 512| Step: 0
Training loss: 0.12843620692945698
Validation loss: 2.554432850025284

Epoch: 6| Step: 1
Training loss: 0.11192218491403377
Validation loss: 2.6097743781386975

Epoch: 6| Step: 2
Training loss: 0.15690887531864126
Validation loss: 2.604299089243815

Epoch: 6| Step: 3
Training loss: 0.21459934898595018
Validation loss: 2.5760854430280036

Epoch: 6| Step: 4
Training loss: 0.13794446277804992
Validation loss: 2.591138289592066

Epoch: 6| Step: 5
Training loss: 0.13917130542731512
Validation loss: 2.5574003799281386

Epoch: 6| Step: 6
Training loss: 0.1658914999592503
Validation loss: 2.553271648373318

Epoch: 6| Step: 7
Training loss: 0.20792008282645935
Validation loss: 2.573156861649249

Epoch: 6| Step: 8
Training loss: 0.15062457626726372
Validation loss: 2.546863989973249

Epoch: 6| Step: 9
Training loss: 0.22337648118738926
Validation loss: 2.5761949202497645

Epoch: 6| Step: 10
Training loss: 0.1110230079386484
Validation loss: 2.519266605429406

Epoch: 6| Step: 11
Training loss: 0.11657116460172359
Validation loss: 2.5380303447415007

Epoch: 6| Step: 12
Training loss: 0.09795488947753071
Validation loss: 2.5599056720195104

Epoch: 6| Step: 13
Training loss: 0.15480325996112276
Validation loss: 2.5435412403472157

Epoch: 513| Step: 0
Training loss: 0.10313102061585587
Validation loss: 2.556337282778827

Epoch: 6| Step: 1
Training loss: 0.09718489858850032
Validation loss: 2.502779269969072

Epoch: 6| Step: 2
Training loss: 0.09553629093702795
Validation loss: 2.5438109346119817

Epoch: 6| Step: 3
Training loss: 0.1261954439075499
Validation loss: 2.534927208407468

Epoch: 6| Step: 4
Training loss: 0.20518591636525316
Validation loss: 2.5800627485442766

Epoch: 6| Step: 5
Training loss: 0.27898624459064575
Validation loss: 2.5378994962502706

Epoch: 6| Step: 6
Training loss: 0.13798756393386558
Validation loss: 2.6128664012862735

Epoch: 6| Step: 7
Training loss: 0.14597287200680675
Validation loss: 2.5646518982971775

Epoch: 6| Step: 8
Training loss: 0.11444844539046044
Validation loss: 2.574388559705929

Epoch: 6| Step: 9
Training loss: 0.15395024150167852
Validation loss: 2.622873462553571

Epoch: 6| Step: 10
Training loss: 0.11480110959827686
Validation loss: 2.6307170527435595

Epoch: 6| Step: 11
Training loss: 0.09092623676111056
Validation loss: 2.5932373032379843

Epoch: 6| Step: 12
Training loss: 0.18285222151812128
Validation loss: 2.5678551764669044

Epoch: 6| Step: 13
Training loss: 0.22222606192854455
Validation loss: 2.566161354492355

Epoch: 514| Step: 0
Training loss: 0.21136399703260733
Validation loss: 2.58674743973202

Epoch: 6| Step: 1
Training loss: 0.09931265824859284
Validation loss: 2.532771131646013

Epoch: 6| Step: 2
Training loss: 0.08912517492282496
Validation loss: 2.5596465193618854

Epoch: 6| Step: 3
Training loss: 0.19484614963476318
Validation loss: 2.516963525439979

Epoch: 6| Step: 4
Training loss: 0.16717847951280318
Validation loss: 2.558678423292914

Epoch: 6| Step: 5
Training loss: 0.2028006843951535
Validation loss: 2.5466295299287687

Epoch: 6| Step: 6
Training loss: 0.1485412511133139
Validation loss: 2.573323617229623

Epoch: 6| Step: 7
Training loss: 0.08591412096194145
Validation loss: 2.5293555103365626

Epoch: 6| Step: 8
Training loss: 0.1166184037792264
Validation loss: 2.5533215959062248

Epoch: 6| Step: 9
Training loss: 0.06606770921170108
Validation loss: 2.5892496742485536

Epoch: 6| Step: 10
Training loss: 0.23798754053701057
Validation loss: 2.541162539864585

Epoch: 6| Step: 11
Training loss: 0.12966631291144265
Validation loss: 2.527644463972653

Epoch: 6| Step: 12
Training loss: 0.22150230873338433
Validation loss: 2.480116578348152

Epoch: 6| Step: 13
Training loss: 0.12888234812769686
Validation loss: 2.525421433483367

Epoch: 515| Step: 0
Training loss: 0.11241680850925409
Validation loss: 2.4956640790081233

Epoch: 6| Step: 1
Training loss: 0.11757497307997924
Validation loss: 2.4767365354850206

Epoch: 6| Step: 2
Training loss: 0.09949164819889508
Validation loss: 2.4471350943104286

Epoch: 6| Step: 3
Training loss: 0.28507004048704243
Validation loss: 2.522666526629728

Epoch: 6| Step: 4
Training loss: 0.11361935326343528
Validation loss: 2.516616981367399

Epoch: 6| Step: 5
Training loss: 0.16196572016951843
Validation loss: 2.5254759067516224

Epoch: 6| Step: 6
Training loss: 0.20694950577252239
Validation loss: 2.5469099802745108

Epoch: 6| Step: 7
Training loss: 0.21673046847718277
Validation loss: 2.523265862628892

Epoch: 6| Step: 8
Training loss: 0.11198481325580337
Validation loss: 2.4897380071485276

Epoch: 6| Step: 9
Training loss: 0.1547949092933092
Validation loss: 2.5307886910299753

Epoch: 6| Step: 10
Training loss: 0.2187693961944858
Validation loss: 2.5065104604762882

Epoch: 6| Step: 11
Training loss: 0.15745689272387675
Validation loss: 2.506605399923306

Epoch: 6| Step: 12
Training loss: 0.13847640862073002
Validation loss: 2.48479647294692

Epoch: 6| Step: 13
Training loss: 0.07358017185715451
Validation loss: 2.503260373320463

Epoch: 516| Step: 0
Training loss: 0.1542197106958553
Validation loss: 2.514265026695242

Epoch: 6| Step: 1
Training loss: 0.17288514258289103
Validation loss: 2.532826036178697

Epoch: 6| Step: 2
Training loss: 0.1311367781229525
Validation loss: 2.499774596604901

Epoch: 6| Step: 3
Training loss: 0.19850995625790838
Validation loss: 2.5327862466048425

Epoch: 6| Step: 4
Training loss: 0.08272182622034593
Validation loss: 2.531410492741747

Epoch: 6| Step: 5
Training loss: 0.13633853632130083
Validation loss: 2.5463781042579274

Epoch: 6| Step: 6
Training loss: 0.16408933124938505
Validation loss: 2.5532173009819683

Epoch: 6| Step: 7
Training loss: 0.20832655220121837
Validation loss: 2.5514960327497636

Epoch: 6| Step: 8
Training loss: 0.21618857401602837
Validation loss: 2.5279230849595673

Epoch: 6| Step: 9
Training loss: 0.08839343673377045
Validation loss: 2.537725941740229

Epoch: 6| Step: 10
Training loss: 0.09065171456390876
Validation loss: 2.5357984873972814

Epoch: 6| Step: 11
Training loss: 0.09821459418719015
Validation loss: 2.550538132479184

Epoch: 6| Step: 12
Training loss: 0.22916894427525944
Validation loss: 2.5472962532923407

Epoch: 6| Step: 13
Training loss: 0.12663737425258975
Validation loss: 2.5627192021578202

Epoch: 517| Step: 0
Training loss: 0.26297753358475057
Validation loss: 2.525809879069107

Epoch: 6| Step: 1
Training loss: 0.10638684233015211
Validation loss: 2.5354699098590463

Epoch: 6| Step: 2
Training loss: 0.12942654195732423
Validation loss: 2.534738997994214

Epoch: 6| Step: 3
Training loss: 0.18523602799056535
Validation loss: 2.5098899037096993

Epoch: 6| Step: 4
Training loss: 0.15863052961129476
Validation loss: 2.5389582241660196

Epoch: 6| Step: 5
Training loss: 0.17654029360522255
Validation loss: 2.5381575978176745

Epoch: 6| Step: 6
Training loss: 0.18567341956491573
Validation loss: 2.529745090325677

Epoch: 6| Step: 7
Training loss: 0.12266696075277
Validation loss: 2.5362536643903266

Epoch: 6| Step: 8
Training loss: 0.1949181294511371
Validation loss: 2.519384456096624

Epoch: 6| Step: 9
Training loss: 0.1209566740242937
Validation loss: 2.5596057965929475

Epoch: 6| Step: 10
Training loss: 0.1714964784161232
Validation loss: 2.551974146108005

Epoch: 6| Step: 11
Training loss: 0.11482772764037777
Validation loss: 2.527847375023953

Epoch: 6| Step: 12
Training loss: 0.14084294437544528
Validation loss: 2.5281350402336558

Epoch: 6| Step: 13
Training loss: 0.16563723019662938
Validation loss: 2.529610959385163

Epoch: 518| Step: 0
Training loss: 0.09843427675510477
Validation loss: 2.5202644880597687

Epoch: 6| Step: 1
Training loss: 0.23430770861696637
Validation loss: 2.541637560353148

Epoch: 6| Step: 2
Training loss: 0.20906884277883145
Validation loss: 2.5169782892065777

Epoch: 6| Step: 3
Training loss: 0.1750302750506335
Validation loss: 2.5291799884672415

Epoch: 6| Step: 4
Training loss: 0.12987898340532417
Validation loss: 2.5358093139551072

Epoch: 6| Step: 5
Training loss: 0.13444191990719953
Validation loss: 2.522465786382904

Epoch: 6| Step: 6
Training loss: 0.19274173696224928
Validation loss: 2.509399351584343

Epoch: 6| Step: 7
Training loss: 0.13632102745621155
Validation loss: 2.5255820611160003

Epoch: 6| Step: 8
Training loss: 0.13649798007184924
Validation loss: 2.529881689248869

Epoch: 6| Step: 9
Training loss: 0.10744328718926197
Validation loss: 2.5571547873582023

Epoch: 6| Step: 10
Training loss: 0.1299522544108826
Validation loss: 2.5627947922122787

Epoch: 6| Step: 11
Training loss: 0.11103992217076078
Validation loss: 2.5629983052811576

Epoch: 6| Step: 12
Training loss: 0.18748313112670487
Validation loss: 2.557333243630033

Epoch: 6| Step: 13
Training loss: 0.09042923311321219
Validation loss: 2.576840194100937

Epoch: 519| Step: 0
Training loss: 0.2150697646367738
Validation loss: 2.546869208115832

Epoch: 6| Step: 1
Training loss: 0.10039188592022419
Validation loss: 2.5481897953121795

Epoch: 6| Step: 2
Training loss: 0.08650645031162715
Validation loss: 2.527674711500858

Epoch: 6| Step: 3
Training loss: 0.13123212221412348
Validation loss: 2.536094099821283

Epoch: 6| Step: 4
Training loss: 0.18861174800171002
Validation loss: 2.5608243548414906

Epoch: 6| Step: 5
Training loss: 0.10343619664169144
Validation loss: 2.5672888549292185

Epoch: 6| Step: 6
Training loss: 0.11682122528488985
Validation loss: 2.5843543662399098

Epoch: 6| Step: 7
Training loss: 0.11250158547237893
Validation loss: 2.602361679812103

Epoch: 6| Step: 8
Training loss: 0.2107057711414235
Validation loss: 2.5710889377458535

Epoch: 6| Step: 9
Training loss: 0.13516514065337132
Validation loss: 2.547513934870221

Epoch: 6| Step: 10
Training loss: 0.13252480284874626
Validation loss: 2.5434249610600315

Epoch: 6| Step: 11
Training loss: 0.1578301755052328
Validation loss: 2.557477645589078

Epoch: 6| Step: 12
Training loss: 0.10732081167490004
Validation loss: 2.5121231525427867

Epoch: 6| Step: 13
Training loss: 0.12130789510746547
Validation loss: 2.527764070583307

Epoch: 520| Step: 0
Training loss: 0.2180512371330794
Validation loss: 2.5499745184509726

Epoch: 6| Step: 1
Training loss: 0.160400048056691
Validation loss: 2.5262207441386515

Epoch: 6| Step: 2
Training loss: 0.1598508877805924
Validation loss: 2.5629399359920235

Epoch: 6| Step: 3
Training loss: 0.11974093582724651
Validation loss: 2.505858075715418

Epoch: 6| Step: 4
Training loss: 0.12759841367507554
Validation loss: 2.545648916495959

Epoch: 6| Step: 5
Training loss: 0.11922062079935376
Validation loss: 2.5196595350317654

Epoch: 6| Step: 6
Training loss: 0.14453918847629646
Validation loss: 2.516138928088661

Epoch: 6| Step: 7
Training loss: 0.19249779997224872
Validation loss: 2.536158702164964

Epoch: 6| Step: 8
Training loss: 0.2056410194232614
Validation loss: 2.529093346353439

Epoch: 6| Step: 9
Training loss: 0.14946706617093986
Validation loss: 2.5503919446602388

Epoch: 6| Step: 10
Training loss: 0.07182917053788596
Validation loss: 2.5844384514682304

Epoch: 6| Step: 11
Training loss: 0.13508137740394507
Validation loss: 2.5832383207485985

Epoch: 6| Step: 12
Training loss: 0.1204411008229248
Validation loss: 2.56392998742111

Epoch: 6| Step: 13
Training loss: 0.1295397105979823
Validation loss: 2.5578254684093524

Epoch: 521| Step: 0
Training loss: 0.13940716955962956
Validation loss: 2.5505211335430156

Epoch: 6| Step: 1
Training loss: 0.2081083941063848
Validation loss: 2.549443287553858

Epoch: 6| Step: 2
Training loss: 0.11804380287272839
Validation loss: 2.573583362999993

Epoch: 6| Step: 3
Training loss: 0.16589271820284132
Validation loss: 2.5354925080814272

Epoch: 6| Step: 4
Training loss: 0.06772815623549544
Validation loss: 2.507597331263139

Epoch: 6| Step: 5
Training loss: 0.18335913825131553
Validation loss: 2.5453983054495763

Epoch: 6| Step: 6
Training loss: 0.10009971244374853
Validation loss: 2.500117112564809

Epoch: 6| Step: 7
Training loss: 0.08597103461624078
Validation loss: 2.5268223495655153

Epoch: 6| Step: 8
Training loss: 0.09369920308090743
Validation loss: 2.514702161626623

Epoch: 6| Step: 9
Training loss: 0.11381635398194531
Validation loss: 2.5102229550168533

Epoch: 6| Step: 10
Training loss: 0.18315656839058952
Validation loss: 2.5431718778718255

Epoch: 6| Step: 11
Training loss: 0.09774967493127593
Validation loss: 2.5278067555780495

Epoch: 6| Step: 12
Training loss: 0.14972525334550957
Validation loss: 2.531669617366105

Epoch: 6| Step: 13
Training loss: 0.14371508117201612
Validation loss: 2.522224293368948

Epoch: 522| Step: 0
Training loss: 0.12937915638683253
Validation loss: 2.533644041988765

Epoch: 6| Step: 1
Training loss: 0.09894953759739794
Validation loss: 2.5500681398131992

Epoch: 6| Step: 2
Training loss: 0.17353002296974313
Validation loss: 2.5537977352225183

Epoch: 6| Step: 3
Training loss: 0.13805390057823333
Validation loss: 2.525617041174458

Epoch: 6| Step: 4
Training loss: 0.20586553814111366
Validation loss: 2.5594392540669686

Epoch: 6| Step: 5
Training loss: 0.09790054283225387
Validation loss: 2.558962751875403

Epoch: 6| Step: 6
Training loss: 0.10165178977259197
Validation loss: 2.5545322772081733

Epoch: 6| Step: 7
Training loss: 0.18470786282550936
Validation loss: 2.578008522442834

Epoch: 6| Step: 8
Training loss: 0.1072514612789129
Validation loss: 2.553593288111421

Epoch: 6| Step: 9
Training loss: 0.11889093061005038
Validation loss: 2.5430527580212403

Epoch: 6| Step: 10
Training loss: 0.23504267005884313
Validation loss: 2.5514586815356846

Epoch: 6| Step: 11
Training loss: 0.09533221517747151
Validation loss: 2.5359508495831014

Epoch: 6| Step: 12
Training loss: 0.14683883378972182
Validation loss: 2.5306499412570065

Epoch: 6| Step: 13
Training loss: 0.12779611792656714
Validation loss: 2.5440759487927185

Epoch: 523| Step: 0
Training loss: 0.16348364300815993
Validation loss: 2.4927073216341857

Epoch: 6| Step: 1
Training loss: 0.2715057803710113
Validation loss: 2.4793575320592733

Epoch: 6| Step: 2
Training loss: 0.08433584755242955
Validation loss: 2.4650005582375214

Epoch: 6| Step: 3
Training loss: 0.06575943993023774
Validation loss: 2.478887318023502

Epoch: 6| Step: 4
Training loss: 0.08298930354486354
Validation loss: 2.5255344671166124

Epoch: 6| Step: 5
Training loss: 0.16146981803492091
Validation loss: 2.4957541825779703

Epoch: 6| Step: 6
Training loss: 0.15262697253409255
Validation loss: 2.5148723100184287

Epoch: 6| Step: 7
Training loss: 0.1188961828020411
Validation loss: 2.532915695300876

Epoch: 6| Step: 8
Training loss: 0.14653800618359963
Validation loss: 2.53122840405236

Epoch: 6| Step: 9
Training loss: 0.12053251183383154
Validation loss: 2.5297104951876364

Epoch: 6| Step: 10
Training loss: 0.09165796463022961
Validation loss: 2.5798800752009443

Epoch: 6| Step: 11
Training loss: 0.11414086641446693
Validation loss: 2.5589265485594628

Epoch: 6| Step: 12
Training loss: 0.11510412484451615
Validation loss: 2.5466849279250954

Epoch: 6| Step: 13
Training loss: 0.2548437855976017
Validation loss: 2.5034746276010424

Epoch: 524| Step: 0
Training loss: 0.1387766522829387
Validation loss: 2.5375880642912603

Epoch: 6| Step: 1
Training loss: 0.2540540851686878
Validation loss: 2.5533347698996827

Epoch: 6| Step: 2
Training loss: 0.13143873779269102
Validation loss: 2.5459192836855244

Epoch: 6| Step: 3
Training loss: 0.08588468218152559
Validation loss: 2.505499582478152

Epoch: 6| Step: 4
Training loss: 0.13026493193442149
Validation loss: 2.5185862473387783

Epoch: 6| Step: 5
Training loss: 0.24289753873058265
Validation loss: 2.561722704321388

Epoch: 6| Step: 6
Training loss: 0.07914089473026927
Validation loss: 2.522230454902873

Epoch: 6| Step: 7
Training loss: 0.08875899488408466
Validation loss: 2.514761383454344

Epoch: 6| Step: 8
Training loss: 0.14589912485882522
Validation loss: 2.513220585037958

Epoch: 6| Step: 9
Training loss: 0.12355090406560633
Validation loss: 2.5610368985201117

Epoch: 6| Step: 10
Training loss: 0.12984307477158058
Validation loss: 2.515826251943256

Epoch: 6| Step: 11
Training loss: 0.19580781120180296
Validation loss: 2.475153497278382

Epoch: 6| Step: 12
Training loss: 0.11457388109176452
Validation loss: 2.5054203339686842

Epoch: 6| Step: 13
Training loss: 0.10080116818122241
Validation loss: 2.5345038411282017

Epoch: 525| Step: 0
Training loss: 0.16238435151245142
Validation loss: 2.5281437964900264

Epoch: 6| Step: 1
Training loss: 0.09226525813747667
Validation loss: 2.527136203079687

Epoch: 6| Step: 2
Training loss: 0.14451698284354716
Validation loss: 2.5279810813295467

Epoch: 6| Step: 3
Training loss: 0.10618009687003346
Validation loss: 2.55531590659867

Epoch: 6| Step: 4
Training loss: 0.09875909822235272
Validation loss: 2.5835997205634547

Epoch: 6| Step: 5
Training loss: 0.1367123942941468
Validation loss: 2.549417574024319

Epoch: 6| Step: 6
Training loss: 0.1676123519658691
Validation loss: 2.569477183820641

Epoch: 6| Step: 7
Training loss: 0.25324821299066475
Validation loss: 2.566468488103046

Epoch: 6| Step: 8
Training loss: 0.1639433269003293
Validation loss: 2.538364088050869

Epoch: 6| Step: 9
Training loss: 0.12760405556680424
Validation loss: 2.5597529559791363

Epoch: 6| Step: 10
Training loss: 0.1428875374603823
Validation loss: 2.5750180314003472

Epoch: 6| Step: 11
Training loss: 0.11846625880995834
Validation loss: 2.569991726742884

Epoch: 6| Step: 12
Training loss: 0.09501232225724919
Validation loss: 2.58150999033172

Epoch: 6| Step: 13
Training loss: 0.25050176989430734
Validation loss: 2.5752053432703303

Epoch: 526| Step: 0
Training loss: 0.1790673916999029
Validation loss: 2.5583856819453823

Epoch: 6| Step: 1
Training loss: 0.1608724918825755
Validation loss: 2.5381300306469443

Epoch: 6| Step: 2
Training loss: 0.18378876413448816
Validation loss: 2.570295136130597

Epoch: 6| Step: 3
Training loss: 0.1356090469031129
Validation loss: 2.579136263488758

Epoch: 6| Step: 4
Training loss: 0.13246743872754616
Validation loss: 2.5782285985830464

Epoch: 6| Step: 5
Training loss: 0.19461044017204684
Validation loss: 2.5605986990165825

Epoch: 6| Step: 6
Training loss: 0.15393191646396182
Validation loss: 2.549598785982558

Epoch: 6| Step: 7
Training loss: 0.1908375797639114
Validation loss: 2.5893429220699264

Epoch: 6| Step: 8
Training loss: 0.0666639153588322
Validation loss: 2.5880468049057073

Epoch: 6| Step: 9
Training loss: 0.10581206147677047
Validation loss: 2.5752514707719385

Epoch: 6| Step: 10
Training loss: 0.18181659009626877
Validation loss: 2.564554562844666

Epoch: 6| Step: 11
Training loss: 0.11790160516678744
Validation loss: 2.561636700536947

Epoch: 6| Step: 12
Training loss: 0.11259930155363419
Validation loss: 2.5804494810517973

Epoch: 6| Step: 13
Training loss: 0.11245519255698173
Validation loss: 2.6099607549385455

Epoch: 527| Step: 0
Training loss: 0.14159518260395249
Validation loss: 2.5842889578925576

Epoch: 6| Step: 1
Training loss: 0.15282476121472574
Validation loss: 2.5554443038185615

Epoch: 6| Step: 2
Training loss: 0.09630232191580637
Validation loss: 2.5448267859311176

Epoch: 6| Step: 3
Training loss: 0.08127580780731865
Validation loss: 2.529068846073771

Epoch: 6| Step: 4
Training loss: 0.1782395446300511
Validation loss: 2.5512238720101696

Epoch: 6| Step: 5
Training loss: 0.2256720324946726
Validation loss: 2.517329692217824

Epoch: 6| Step: 6
Training loss: 0.20828777152781328
Validation loss: 2.48547827649069

Epoch: 6| Step: 7
Training loss: 0.10836468420244312
Validation loss: 2.5181520579626957

Epoch: 6| Step: 8
Training loss: 0.10256809550206632
Validation loss: 2.4968105500614497

Epoch: 6| Step: 9
Training loss: 0.1295132146710678
Validation loss: 2.5142112055370798

Epoch: 6| Step: 10
Training loss: 0.15525681028770602
Validation loss: 2.5485094851220915

Epoch: 6| Step: 11
Training loss: 0.08210425023801274
Validation loss: 2.5218828749224627

Epoch: 6| Step: 12
Training loss: 0.23449842858703043
Validation loss: 2.5042182078266637

Epoch: 6| Step: 13
Training loss: 0.05363941849660956
Validation loss: 2.5110555462278668

Epoch: 528| Step: 0
Training loss: 0.13059479740724164
Validation loss: 2.5757348161160936

Epoch: 6| Step: 1
Training loss: 0.25822433176832243
Validation loss: 2.5401789929186047

Epoch: 6| Step: 2
Training loss: 0.2195931941164211
Validation loss: 2.556254985006264

Epoch: 6| Step: 3
Training loss: 0.06166038144903954
Validation loss: 2.6130104483191503

Epoch: 6| Step: 4
Training loss: 0.16185118325121772
Validation loss: 2.559719660271037

Epoch: 6| Step: 5
Training loss: 0.1778715044818801
Validation loss: 2.579044440358565

Epoch: 6| Step: 6
Training loss: 0.17350066340770368
Validation loss: 2.554366098405567

Epoch: 6| Step: 7
Training loss: 0.1431533432157231
Validation loss: 2.5488247977733915

Epoch: 6| Step: 8
Training loss: 0.12151786152558465
Validation loss: 2.5286763693141365

Epoch: 6| Step: 9
Training loss: 0.08962767990247578
Validation loss: 2.521074986364881

Epoch: 6| Step: 10
Training loss: 0.12308807288871672
Validation loss: 2.5562259632325066

Epoch: 6| Step: 11
Training loss: 0.11934664767164437
Validation loss: 2.544626265525262

Epoch: 6| Step: 12
Training loss: 0.13610497714134717
Validation loss: 2.544742787110879

Epoch: 6| Step: 13
Training loss: 0.09133874425995926
Validation loss: 2.52257053664569

Epoch: 529| Step: 0
Training loss: 0.2365314302739865
Validation loss: 2.509375663279831

Epoch: 6| Step: 1
Training loss: 0.12372050497376574
Validation loss: 2.4996691187449263

Epoch: 6| Step: 2
Training loss: 0.134098655409156
Validation loss: 2.5390691810437973

Epoch: 6| Step: 3
Training loss: 0.13602179949843768
Validation loss: 2.56049568321146

Epoch: 6| Step: 4
Training loss: 0.1220295418364558
Validation loss: 2.5407953172421216

Epoch: 6| Step: 5
Training loss: 0.15347924468739813
Validation loss: 2.557227239884686

Epoch: 6| Step: 6
Training loss: 0.17574860481607837
Validation loss: 2.537550259830986

Epoch: 6| Step: 7
Training loss: 0.18235742994900042
Validation loss: 2.5309512054305774

Epoch: 6| Step: 8
Training loss: 0.13669694999188886
Validation loss: 2.55596380359877

Epoch: 6| Step: 9
Training loss: 0.10042446564311897
Validation loss: 2.5272020640473634

Epoch: 6| Step: 10
Training loss: 0.12850379251661243
Validation loss: 2.541567654415167

Epoch: 6| Step: 11
Training loss: 0.20594983800533007
Validation loss: 2.526137771698077

Epoch: 6| Step: 12
Training loss: 0.07383340004336879
Validation loss: 2.532866042739767

Epoch: 6| Step: 13
Training loss: 0.1434294095593794
Validation loss: 2.500539215962382

Epoch: 530| Step: 0
Training loss: 0.19757434557780168
Validation loss: 2.48001459466561

Epoch: 6| Step: 1
Training loss: 0.20217756162918982
Validation loss: 2.4963143786366544

Epoch: 6| Step: 2
Training loss: 0.16144644529405341
Validation loss: 2.5085440055570642

Epoch: 6| Step: 3
Training loss: 0.11161717318694095
Validation loss: 2.50110318136775

Epoch: 6| Step: 4
Training loss: 0.15028605603239312
Validation loss: 2.5018933356230644

Epoch: 6| Step: 5
Training loss: 0.1321396754937657
Validation loss: 2.519690209083698

Epoch: 6| Step: 6
Training loss: 0.11465114154908655
Validation loss: 2.5116523258387113

Epoch: 6| Step: 7
Training loss: 0.16216682656965706
Validation loss: 2.500467289557733

Epoch: 6| Step: 8
Training loss: 0.17632367895400305
Validation loss: 2.5453944651197165

Epoch: 6| Step: 9
Training loss: 0.12609455585813104
Validation loss: 2.537524791006209

Epoch: 6| Step: 10
Training loss: 0.1052932780718908
Validation loss: 2.577343850423218

Epoch: 6| Step: 11
Training loss: 0.1329881124149438
Validation loss: 2.5541039380782093

Epoch: 6| Step: 12
Training loss: 0.1429268869488985
Validation loss: 2.5657842955096206

Epoch: 6| Step: 13
Training loss: 0.21108321172752398
Validation loss: 2.5553125948424995

Epoch: 531| Step: 0
Training loss: 0.1989807502407447
Validation loss: 2.547902581208814

Epoch: 6| Step: 1
Training loss: 0.16812967199087947
Validation loss: 2.532595357069928

Epoch: 6| Step: 2
Training loss: 0.1419877278547174
Validation loss: 2.4907742733835105

Epoch: 6| Step: 3
Training loss: 0.14480572490459453
Validation loss: 2.4833088756407675

Epoch: 6| Step: 4
Training loss: 0.1755025031048487
Validation loss: 2.4756001599670188

Epoch: 6| Step: 5
Training loss: 0.12800078563942682
Validation loss: 2.4530289370348997

Epoch: 6| Step: 6
Training loss: 0.22883694221177303
Validation loss: 2.4515605573079764

Epoch: 6| Step: 7
Training loss: 0.2686723901999399
Validation loss: 2.419796030517204

Epoch: 6| Step: 8
Training loss: 0.1442821133905645
Validation loss: 2.4278190494474496

Epoch: 6| Step: 9
Training loss: 0.17886124215509858
Validation loss: 2.4462722445993808

Epoch: 6| Step: 10
Training loss: 0.12505780314061987
Validation loss: 2.4557651566768905

Epoch: 6| Step: 11
Training loss: 0.11488509180116022
Validation loss: 2.5141909335945964

Epoch: 6| Step: 12
Training loss: 0.10622225146626314
Validation loss: 2.5349801513350467

Epoch: 6| Step: 13
Training loss: 0.1095290504117709
Validation loss: 2.5090683907814944

Epoch: 532| Step: 0
Training loss: 0.07288888596487163
Validation loss: 2.530894348811398

Epoch: 6| Step: 1
Training loss: 0.11278249848885798
Validation loss: 2.5508096668834113

Epoch: 6| Step: 2
Training loss: 0.13557213484687297
Validation loss: 2.550925375893382

Epoch: 6| Step: 3
Training loss: 0.1332981612398663
Validation loss: 2.53477878675074

Epoch: 6| Step: 4
Training loss: 0.28470562903323304
Validation loss: 2.534068631860927

Epoch: 6| Step: 5
Training loss: 0.1552305282227499
Validation loss: 2.578532643437582

Epoch: 6| Step: 6
Training loss: 0.09562642079276436
Validation loss: 2.523439791941309

Epoch: 6| Step: 7
Training loss: 0.20587555389237142
Validation loss: 2.5032095794933564

Epoch: 6| Step: 8
Training loss: 0.17444533700979978
Validation loss: 2.5283670611489732

Epoch: 6| Step: 9
Training loss: 0.1562131063296912
Validation loss: 2.4952757498018494

Epoch: 6| Step: 10
Training loss: 0.10857295688006348
Validation loss: 2.503868706949192

Epoch: 6| Step: 11
Training loss: 0.15603249431444766
Validation loss: 2.5145876970052856

Epoch: 6| Step: 12
Training loss: 0.10257708434937472
Validation loss: 2.4944504238947736

Epoch: 6| Step: 13
Training loss: 0.16779288799793252
Validation loss: 2.5261061773170175

Epoch: 533| Step: 0
Training loss: 0.19330183772206672
Validation loss: 2.5261520221244274

Epoch: 6| Step: 1
Training loss: 0.12159240249459682
Validation loss: 2.559093400190769

Epoch: 6| Step: 2
Training loss: 0.1033784389142951
Validation loss: 2.517564301588991

Epoch: 6| Step: 3
Training loss: 0.11060635513308859
Validation loss: 2.518069665691515

Epoch: 6| Step: 4
Training loss: 0.1234655372551151
Validation loss: 2.523490580359225

Epoch: 6| Step: 5
Training loss: 0.13945773915796905
Validation loss: 2.512854322455236

Epoch: 6| Step: 6
Training loss: 0.08606184016271197
Validation loss: 2.5574942005838186

Epoch: 6| Step: 7
Training loss: 0.07042812073266594
Validation loss: 2.5588999064308093

Epoch: 6| Step: 8
Training loss: 0.19571490794818552
Validation loss: 2.582937101713699

Epoch: 6| Step: 9
Training loss: 0.12076300783686286
Validation loss: 2.5614263965214894

Epoch: 6| Step: 10
Training loss: 0.10706831227730189
Validation loss: 2.5405828672378403

Epoch: 6| Step: 11
Training loss: 0.17799161802605212
Validation loss: 2.51845722587013

Epoch: 6| Step: 12
Training loss: 0.1254353021786492
Validation loss: 2.5523093114524986

Epoch: 6| Step: 13
Training loss: 0.116886180684584
Validation loss: 2.541120704206638

Epoch: 534| Step: 0
Training loss: 0.08128322130762136
Validation loss: 2.5624139802842785

Epoch: 6| Step: 1
Training loss: 0.20069263372920726
Validation loss: 2.556769817002999

Epoch: 6| Step: 2
Training loss: 0.11514471898259512
Validation loss: 2.5699092225588376

Epoch: 6| Step: 3
Training loss: 0.17767609699276146
Validation loss: 2.5852744262301943

Epoch: 6| Step: 4
Training loss: 0.16099508931018913
Validation loss: 2.563518732852064

Epoch: 6| Step: 5
Training loss: 0.08927638301027817
Validation loss: 2.553176549971283

Epoch: 6| Step: 6
Training loss: 0.1534586361430579
Validation loss: 2.568378800171658

Epoch: 6| Step: 7
Training loss: 0.19530822749233143
Validation loss: 2.550624100913569

Epoch: 6| Step: 8
Training loss: 0.07943478498745123
Validation loss: 2.5475758073352055

Epoch: 6| Step: 9
Training loss: 0.1955343131321861
Validation loss: 2.5317934466434475

Epoch: 6| Step: 10
Training loss: 0.13302841587107883
Validation loss: 2.5146959796078696

Epoch: 6| Step: 11
Training loss: 0.19157096042899183
Validation loss: 2.4986008841133054

Epoch: 6| Step: 12
Training loss: 0.14389385975650143
Validation loss: 2.4833517466466235

Epoch: 6| Step: 13
Training loss: 0.10156433397251147
Validation loss: 2.501446977888289

Epoch: 535| Step: 0
Training loss: 0.15509263794681125
Validation loss: 2.504564693578633

Epoch: 6| Step: 1
Training loss: 0.10942531177854581
Validation loss: 2.4996157227786484

Epoch: 6| Step: 2
Training loss: 0.17783440929249417
Validation loss: 2.5053621632512093

Epoch: 6| Step: 3
Training loss: 0.17472038154065433
Validation loss: 2.485735301493461

Epoch: 6| Step: 4
Training loss: 0.25971531201472625
Validation loss: 2.5389966760879448

Epoch: 6| Step: 5
Training loss: 0.2503799888506138
Validation loss: 2.509357914527852

Epoch: 6| Step: 6
Training loss: 0.23926047498817524
Validation loss: 2.4853233539039286

Epoch: 6| Step: 7
Training loss: 0.15620658986746783
Validation loss: 2.489038853147117

Epoch: 6| Step: 8
Training loss: 0.157600816304267
Validation loss: 2.4894254643576366

Epoch: 6| Step: 9
Training loss: 0.12591247998690666
Validation loss: 2.520123287086666

Epoch: 6| Step: 10
Training loss: 0.14460469003896012
Validation loss: 2.503718362727252

Epoch: 6| Step: 11
Training loss: 0.2600426308362857
Validation loss: 2.5411589458496096

Epoch: 6| Step: 12
Training loss: 0.3188434033891573
Validation loss: 2.500446691394124

Epoch: 6| Step: 13
Training loss: 0.15259320669450505
Validation loss: 2.5502444270567546

Epoch: 536| Step: 0
Training loss: 0.2568499630191547
Validation loss: 2.54383778616752

Epoch: 6| Step: 1
Training loss: 0.1671714489798854
Validation loss: 2.5584709307711333

Epoch: 6| Step: 2
Training loss: 0.2469196387869632
Validation loss: 2.572808937533261

Epoch: 6| Step: 3
Training loss: 0.2758020479610679
Validation loss: 2.5403707405625795

Epoch: 6| Step: 4
Training loss: 0.14014315175034797
Validation loss: 2.617590154126049

Epoch: 6| Step: 5
Training loss: 0.12241775657917578
Validation loss: 2.6159003966765746

Epoch: 6| Step: 6
Training loss: 0.14895570798263177
Validation loss: 2.5924276298796

Epoch: 6| Step: 7
Training loss: 0.16116894403585683
Validation loss: 2.595554826425211

Epoch: 6| Step: 8
Training loss: 0.26733167116044004
Validation loss: 2.6076841799989996

Epoch: 6| Step: 9
Training loss: 0.15299465436455809
Validation loss: 2.5574373942589244

Epoch: 6| Step: 10
Training loss: 0.2054979749571668
Validation loss: 2.4980574762228343

Epoch: 6| Step: 11
Training loss: 0.14500513230070566
Validation loss: 2.4766293974039937

Epoch: 6| Step: 12
Training loss: 0.21577133727732278
Validation loss: 2.4684706696440313

Epoch: 6| Step: 13
Training loss: 0.23989621063966904
Validation loss: 2.4264880168564447

Epoch: 537| Step: 0
Training loss: 0.24118052611360138
Validation loss: 2.4257535217686184

Epoch: 6| Step: 1
Training loss: 0.17408537313753897
Validation loss: 2.41669628166183

Epoch: 6| Step: 2
Training loss: 0.15518118559043112
Validation loss: 2.3953583840896027

Epoch: 6| Step: 3
Training loss: 0.31592504384344733
Validation loss: 2.3994876285805327

Epoch: 6| Step: 4
Training loss: 0.19624299604831805
Validation loss: 2.4558362617212013

Epoch: 6| Step: 5
Training loss: 0.09361472900913838
Validation loss: 2.497889536480781

Epoch: 6| Step: 6
Training loss: 0.16673463066495436
Validation loss: 2.5041376922991243

Epoch: 6| Step: 7
Training loss: 0.21468543375123142
Validation loss: 2.5706439659327907

Epoch: 6| Step: 8
Training loss: 0.17454912375040607
Validation loss: 2.5470189312376665

Epoch: 6| Step: 9
Training loss: 0.15675599898261983
Validation loss: 2.5270042832401565

Epoch: 6| Step: 10
Training loss: 0.227230091457759
Validation loss: 2.5492426566163693

Epoch: 6| Step: 11
Training loss: 0.22679008365966136
Validation loss: 2.5631646195570945

Epoch: 6| Step: 12
Training loss: 0.1177196579172329
Validation loss: 2.568427161583113

Epoch: 6| Step: 13
Training loss: 0.1675815388525177
Validation loss: 2.5174869491662983

Epoch: 538| Step: 0
Training loss: 0.12681322458924102
Validation loss: 2.5058217783425785

Epoch: 6| Step: 1
Training loss: 0.12150161259026482
Validation loss: 2.4839868049408507

Epoch: 6| Step: 2
Training loss: 0.21220384289048694
Validation loss: 2.408778917533568

Epoch: 6| Step: 3
Training loss: 0.1881901734433651
Validation loss: 2.396462029944967

Epoch: 6| Step: 4
Training loss: 0.25526911958809156
Validation loss: 2.4354905711267043

Epoch: 6| Step: 5
Training loss: 0.13575299995226753
Validation loss: 2.403039660479297

Epoch: 6| Step: 6
Training loss: 0.15118427299699977
Validation loss: 2.430073660226951

Epoch: 6| Step: 7
Training loss: 0.10091704435166927
Validation loss: 2.4637996506676556

Epoch: 6| Step: 8
Training loss: 0.16463328028154314
Validation loss: 2.5020002366904732

Epoch: 6| Step: 9
Training loss: 0.23791864822022357
Validation loss: 2.5035048947614835

Epoch: 6| Step: 10
Training loss: 0.17701192893493828
Validation loss: 2.5355377484096415

Epoch: 6| Step: 11
Training loss: 0.18828655211711448
Validation loss: 2.5408498183372874

Epoch: 6| Step: 12
Training loss: 0.13673892553510328
Validation loss: 2.5874856755155053

Epoch: 6| Step: 13
Training loss: 0.21046311405624962
Validation loss: 2.5263538809987316

Epoch: 539| Step: 0
Training loss: 0.1153903769992134
Validation loss: 2.5735289987677676

Epoch: 6| Step: 1
Training loss: 0.27308266641160744
Validation loss: 2.5431677710788585

Epoch: 6| Step: 2
Training loss: 0.15622881507308323
Validation loss: 2.5029750083671485

Epoch: 6| Step: 3
Training loss: 0.15972810598492004
Validation loss: 2.508021654197297

Epoch: 6| Step: 4
Training loss: 0.22297005541391912
Validation loss: 2.4586652483349565

Epoch: 6| Step: 5
Training loss: 0.22198965441379398
Validation loss: 2.4733839422407162

Epoch: 6| Step: 6
Training loss: 0.1187447474597957
Validation loss: 2.4502483656399203

Epoch: 6| Step: 7
Training loss: 0.20668229798806237
Validation loss: 2.4609570990929694

Epoch: 6| Step: 8
Training loss: 0.27329840528275534
Validation loss: 2.4364720825699075

Epoch: 6| Step: 9
Training loss: 0.16246814553114788
Validation loss: 2.450992146375751

Epoch: 6| Step: 10
Training loss: 0.12745001460558306
Validation loss: 2.5403782179228838

Epoch: 6| Step: 11
Training loss: 0.17136327469069276
Validation loss: 2.505825870122943

Epoch: 6| Step: 12
Training loss: 0.17419460860660763
Validation loss: 2.547029579253376

Epoch: 6| Step: 13
Training loss: 0.13728690622375492
Validation loss: 2.5632897277344386

Epoch: 540| Step: 0
Training loss: 0.22392021268765677
Validation loss: 2.5840376219068397

Epoch: 6| Step: 1
Training loss: 0.20829089249013433
Validation loss: 2.5683082026791

Epoch: 6| Step: 2
Training loss: 0.1532844088362078
Validation loss: 2.5870383214322175

Epoch: 6| Step: 3
Training loss: 0.22823947947323947
Validation loss: 2.5566260270989276

Epoch: 6| Step: 4
Training loss: 0.13324410767347308
Validation loss: 2.5676241478604944

Epoch: 6| Step: 5
Training loss: 0.12923474072199487
Validation loss: 2.505311571157132

Epoch: 6| Step: 6
Training loss: 0.16862235318942198
Validation loss: 2.4998659785043302

Epoch: 6| Step: 7
Training loss: 0.28408157647582655
Validation loss: 2.482993703849304

Epoch: 6| Step: 8
Training loss: 0.140507947366505
Validation loss: 2.4296535002489255

Epoch: 6| Step: 9
Training loss: 0.19648500408276667
Validation loss: 2.3862343433809574

Epoch: 6| Step: 10
Training loss: 0.1358171983021191
Validation loss: 2.3413360404187142

Epoch: 6| Step: 11
Training loss: 0.16817732547113687
Validation loss: 2.3193241148184804

Epoch: 6| Step: 12
Training loss: 0.16816833747631418
Validation loss: 2.319651440786986

Epoch: 6| Step: 13
Training loss: 0.19389320626294046
Validation loss: 2.316224123469538

Epoch: 541| Step: 0
Training loss: 0.2030502878851166
Validation loss: 2.2941376058201315

Epoch: 6| Step: 1
Training loss: 0.21523095697641717
Validation loss: 2.3261918050314594

Epoch: 6| Step: 2
Training loss: 0.14702282173007114
Validation loss: 2.3842865772485213

Epoch: 6| Step: 3
Training loss: 0.16829104331270933
Validation loss: 2.425349147857516

Epoch: 6| Step: 4
Training loss: 0.14884881704268502
Validation loss: 2.4679459710777025

Epoch: 6| Step: 5
Training loss: 0.2313154475929523
Validation loss: 2.5048180365373107

Epoch: 6| Step: 6
Training loss: 0.11990967325022019
Validation loss: 2.4978737813519283

Epoch: 6| Step: 7
Training loss: 0.17777547256354345
Validation loss: 2.5214498124233238

Epoch: 6| Step: 8
Training loss: 0.1999713296009997
Validation loss: 2.5494219191272394

Epoch: 6| Step: 9
Training loss: 0.09824098051630366
Validation loss: 2.564136543786315

Epoch: 6| Step: 10
Training loss: 0.18183779526037055
Validation loss: 2.509957674739456

Epoch: 6| Step: 11
Training loss: 0.18135620737945268
Validation loss: 2.5704112032251554

Epoch: 6| Step: 12
Training loss: 0.18694118833075815
Validation loss: 2.573679375331469

Epoch: 6| Step: 13
Training loss: 0.12266173335289361
Validation loss: 2.538982479579361

Epoch: 542| Step: 0
Training loss: 0.1483063620475948
Validation loss: 2.539807666764965

Epoch: 6| Step: 1
Training loss: 0.09071137960791273
Validation loss: 2.5312425488466506

Epoch: 6| Step: 2
Training loss: 0.19135805418509177
Validation loss: 2.5143799077249462

Epoch: 6| Step: 3
Training loss: 0.1359404549880416
Validation loss: 2.5277490838088634

Epoch: 6| Step: 4
Training loss: 0.18220982530929367
Validation loss: 2.5045098880672882

Epoch: 6| Step: 5
Training loss: 0.13743832462092898
Validation loss: 2.5025087966068544

Epoch: 6| Step: 6
Training loss: 0.16103521338948196
Validation loss: 2.484418419631178

Epoch: 6| Step: 7
Training loss: 0.13396695415804988
Validation loss: 2.492052374248506

Epoch: 6| Step: 8
Training loss: 0.13477108432934906
Validation loss: 2.495223599061917

Epoch: 6| Step: 9
Training loss: 0.2033431275802145
Validation loss: 2.5219487429653324

Epoch: 6| Step: 10
Training loss: 0.20481995271947315
Validation loss: 2.531828716546192

Epoch: 6| Step: 11
Training loss: 0.18358370570850513
Validation loss: 2.548607287506925

Epoch: 6| Step: 12
Training loss: 0.170201816377658
Validation loss: 2.544077607450398

Epoch: 6| Step: 13
Training loss: 0.12609296049227764
Validation loss: 2.537879416554355

Epoch: 543| Step: 0
Training loss: 0.20117317125217618
Validation loss: 2.506610786251326

Epoch: 6| Step: 1
Training loss: 0.10545704917993756
Validation loss: 2.5104860867975414

Epoch: 6| Step: 2
Training loss: 0.2471105067914334
Validation loss: 2.5167753404322144

Epoch: 6| Step: 3
Training loss: 0.10418859390103297
Validation loss: 2.5081769057265952

Epoch: 6| Step: 4
Training loss: 0.11088307415679977
Validation loss: 2.5464040206374703

Epoch: 6| Step: 5
Training loss: 0.23263260560462556
Validation loss: 2.530169511742409

Epoch: 6| Step: 6
Training loss: 0.14757235530400853
Validation loss: 2.5537296398713014

Epoch: 6| Step: 7
Training loss: 0.16613220721506106
Validation loss: 2.5324479396298005

Epoch: 6| Step: 8
Training loss: 0.1346878712022804
Validation loss: 2.514278195287952

Epoch: 6| Step: 9
Training loss: 0.12628620742699717
Validation loss: 2.5118013924405083

Epoch: 6| Step: 10
Training loss: 0.11676024991806669
Validation loss: 2.5365940258241575

Epoch: 6| Step: 11
Training loss: 0.1849365838683379
Validation loss: 2.4932800268313158

Epoch: 6| Step: 12
Training loss: 0.12344451262678025
Validation loss: 2.4861241536583076

Epoch: 6| Step: 13
Training loss: 0.11709755783822628
Validation loss: 2.5013091689537688

Epoch: 544| Step: 0
Training loss: 0.10036677956797005
Validation loss: 2.501676173914919

Epoch: 6| Step: 1
Training loss: 0.1799080573145746
Validation loss: 2.5252957314132147

Epoch: 6| Step: 2
Training loss: 0.17665236578739751
Validation loss: 2.538078479143296

Epoch: 6| Step: 3
Training loss: 0.08558284665145473
Validation loss: 2.4915658609676092

Epoch: 6| Step: 4
Training loss: 0.17823181128829702
Validation loss: 2.517319869761018

Epoch: 6| Step: 5
Training loss: 0.14975707877962108
Validation loss: 2.483756314092447

Epoch: 6| Step: 6
Training loss: 0.1501179799881127
Validation loss: 2.523406285299535

Epoch: 6| Step: 7
Training loss: 0.2041548974106081
Validation loss: 2.49851895423715

Epoch: 6| Step: 8
Training loss: 0.1285019661506195
Validation loss: 2.468498932696824

Epoch: 6| Step: 9
Training loss: 0.1674871081935201
Validation loss: 2.445910072062666

Epoch: 6| Step: 10
Training loss: 0.2319568501909232
Validation loss: 2.496869454942464

Epoch: 6| Step: 11
Training loss: 0.16159098825951498
Validation loss: 2.458019854659557

Epoch: 6| Step: 12
Training loss: 0.1977730164889775
Validation loss: 2.448276122823203

Epoch: 6| Step: 13
Training loss: 0.10472208650949032
Validation loss: 2.4583492259420345

Epoch: 545| Step: 0
Training loss: 0.23352009304107507
Validation loss: 2.4503466300868686

Epoch: 6| Step: 1
Training loss: 0.21040527876325676
Validation loss: 2.450564270970146

Epoch: 6| Step: 2
Training loss: 0.1285948315061605
Validation loss: 2.4642457111885525

Epoch: 6| Step: 3
Training loss: 0.19287785385453202
Validation loss: 2.4817599872751144

Epoch: 6| Step: 4
Training loss: 0.1669994709590424
Validation loss: 2.481813739515517

Epoch: 6| Step: 5
Training loss: 0.18467902962871524
Validation loss: 2.5420165112847655

Epoch: 6| Step: 6
Training loss: 0.17990513765548802
Validation loss: 2.523419598200619

Epoch: 6| Step: 7
Training loss: 0.16420075290725988
Validation loss: 2.557548578380136

Epoch: 6| Step: 8
Training loss: 0.22941640860801352
Validation loss: 2.55647669113781

Epoch: 6| Step: 9
Training loss: 0.13323629307520998
Validation loss: 2.557390897829865

Epoch: 6| Step: 10
Training loss: 0.1482032759991944
Validation loss: 2.579363254419287

Epoch: 6| Step: 11
Training loss: 0.10596426486448766
Validation loss: 2.548550725198056

Epoch: 6| Step: 12
Training loss: 0.14570365757371864
Validation loss: 2.519292305645366

Epoch: 6| Step: 13
Training loss: 0.12200954068925002
Validation loss: 2.5078775814457868

Epoch: 546| Step: 0
Training loss: 0.20129157643864617
Validation loss: 2.494618988757635

Epoch: 6| Step: 1
Training loss: 0.14306740874372129
Validation loss: 2.472598724766577

Epoch: 6| Step: 2
Training loss: 0.2375537052418388
Validation loss: 2.48490064047846

Epoch: 6| Step: 3
Training loss: 0.28974205762561084
Validation loss: 2.472931440836433

Epoch: 6| Step: 4
Training loss: 0.18584668883056985
Validation loss: 2.4631710315245794

Epoch: 6| Step: 5
Training loss: 0.09644509280316099
Validation loss: 2.4341896523334334

Epoch: 6| Step: 6
Training loss: 0.1049345048927983
Validation loss: 2.5049862435193853

Epoch: 6| Step: 7
Training loss: 0.14734168630714228
Validation loss: 2.4918595175774714

Epoch: 6| Step: 8
Training loss: 0.13734014170032877
Validation loss: 2.5098171942103447

Epoch: 6| Step: 9
Training loss: 0.14143341867776002
Validation loss: 2.549256774868755

Epoch: 6| Step: 10
Training loss: 0.09810065716945991
Validation loss: 2.491021471065697

Epoch: 6| Step: 11
Training loss: 0.09164630431636443
Validation loss: 2.5251195867293412

Epoch: 6| Step: 12
Training loss: 0.09746691469505256
Validation loss: 2.5438618620285247

Epoch: 6| Step: 13
Training loss: 0.18582011733045867
Validation loss: 2.53504648202774

Epoch: 547| Step: 0
Training loss: 0.10340840707006435
Validation loss: 2.5303917263659037

Epoch: 6| Step: 1
Training loss: 0.13842715577773287
Validation loss: 2.5434187551153347

Epoch: 6| Step: 2
Training loss: 0.14368967599411656
Validation loss: 2.527930466795293

Epoch: 6| Step: 3
Training loss: 0.1495004665892155
Validation loss: 2.542125105468901

Epoch: 6| Step: 4
Training loss: 0.1037346977918946
Validation loss: 2.528719981752317

Epoch: 6| Step: 5
Training loss: 0.146244545747255
Validation loss: 2.5224611346670827

Epoch: 6| Step: 6
Training loss: 0.2231836013480142
Validation loss: 2.538566662354972

Epoch: 6| Step: 7
Training loss: 0.12431864260739411
Validation loss: 2.522015279164663

Epoch: 6| Step: 8
Training loss: 0.12081928836106019
Validation loss: 2.5455973289336127

Epoch: 6| Step: 9
Training loss: 0.32683779643357513
Validation loss: 2.549511493870619

Epoch: 6| Step: 10
Training loss: 0.13153970426885592
Validation loss: 2.5456663346781947

Epoch: 6| Step: 11
Training loss: 0.13889204599514238
Validation loss: 2.5298805578499497

Epoch: 6| Step: 12
Training loss: 0.16202665424542792
Validation loss: 2.5393533358038813

Epoch: 6| Step: 13
Training loss: 0.19916150261623183
Validation loss: 2.5329543614182857

Epoch: 548| Step: 0
Training loss: 0.23404439815405312
Validation loss: 2.5237660944755502

Epoch: 6| Step: 1
Training loss: 0.15767401057411184
Validation loss: 2.5704605382069032

Epoch: 6| Step: 2
Training loss: 0.22581415068674787
Validation loss: 2.552796606992504

Epoch: 6| Step: 3
Training loss: 0.16072385504972372
Validation loss: 2.5894836295181367

Epoch: 6| Step: 4
Training loss: 0.09501483646881759
Validation loss: 2.55117081247197

Epoch: 6| Step: 5
Training loss: 0.19467193464753912
Validation loss: 2.4850408185951154

Epoch: 6| Step: 6
Training loss: 0.14781429571952176
Validation loss: 2.4799923923285108

Epoch: 6| Step: 7
Training loss: 0.12008898101482846
Validation loss: 2.5047656013791375

Epoch: 6| Step: 8
Training loss: 0.14032147022026925
Validation loss: 2.42378090060203

Epoch: 6| Step: 9
Training loss: 0.11269613956564435
Validation loss: 2.45042076314954

Epoch: 6| Step: 10
Training loss: 0.1576909853247294
Validation loss: 2.4285511822751467

Epoch: 6| Step: 11
Training loss: 0.2069994884095343
Validation loss: 2.465589047745891

Epoch: 6| Step: 12
Training loss: 0.18495001916774415
Validation loss: 2.4230508004334426

Epoch: 6| Step: 13
Training loss: 0.2394689756937717
Validation loss: 2.4527161932087793

Epoch: 549| Step: 0
Training loss: 0.12658214652078728
Validation loss: 2.4685726109829402

Epoch: 6| Step: 1
Training loss: 0.1365485357918418
Validation loss: 2.486625893607796

Epoch: 6| Step: 2
Training loss: 0.26985411725121966
Validation loss: 2.4940029998022006

Epoch: 6| Step: 3
Training loss: 0.23754439001848027
Validation loss: 2.468755197370278

Epoch: 6| Step: 4
Training loss: 0.2538772566454171
Validation loss: 2.4958272524627834

Epoch: 6| Step: 5
Training loss: 0.19572173161483813
Validation loss: 2.532988277158682

Epoch: 6| Step: 6
Training loss: 0.24175860513473063
Validation loss: 2.5307795833022104

Epoch: 6| Step: 7
Training loss: 0.17512573829722608
Validation loss: 2.5209627023374948

Epoch: 6| Step: 8
Training loss: 0.16470828003954474
Validation loss: 2.528807318928758

Epoch: 6| Step: 9
Training loss: 0.14332919023892068
Validation loss: 2.5105921257164447

Epoch: 6| Step: 10
Training loss: 0.09660972606996793
Validation loss: 2.529867683781558

Epoch: 6| Step: 11
Training loss: 0.1456109967579949
Validation loss: 2.521175798221911

Epoch: 6| Step: 12
Training loss: 0.17864629483140182
Validation loss: 2.52861373835545

Epoch: 6| Step: 13
Training loss: 0.33880564105985395
Validation loss: 2.5221229887627077

Epoch: 550| Step: 0
Training loss: 0.21645918312371001
Validation loss: 2.5122107748541485

Epoch: 6| Step: 1
Training loss: 0.15457271112292573
Validation loss: 2.513421644972317

Epoch: 6| Step: 2
Training loss: 0.1725244929885932
Validation loss: 2.4597481698428556

Epoch: 6| Step: 3
Training loss: 0.1462007510677522
Validation loss: 2.5121152037969297

Epoch: 6| Step: 4
Training loss: 0.16375913842924128
Validation loss: 2.465254180192894

Epoch: 6| Step: 5
Training loss: 0.20742801218957194
Validation loss: 2.5193088976155877

Epoch: 6| Step: 6
Training loss: 0.11380293769064713
Validation loss: 2.510964972796525

Epoch: 6| Step: 7
Training loss: 0.14569520085036097
Validation loss: 2.5228788341026362

Epoch: 6| Step: 8
Training loss: 0.1533391236349185
Validation loss: 2.4986866495542244

Epoch: 6| Step: 9
Training loss: 0.18322584137457282
Validation loss: 2.4951046668042487

Epoch: 6| Step: 10
Training loss: 0.15375533619978918
Validation loss: 2.513157064978986

Epoch: 6| Step: 11
Training loss: 0.19569338852348056
Validation loss: 2.519732319671432

Epoch: 6| Step: 12
Training loss: 0.13325928821273292
Validation loss: 2.5245729466824387

Epoch: 6| Step: 13
Training loss: 0.1420381917505592
Validation loss: 2.5312715218298902

Testing loss: 2.803032428106429
