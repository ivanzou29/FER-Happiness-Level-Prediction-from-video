Epoch: 1| Step: 0
Training loss: 6.846649531139015
Validation loss: 5.834156738858507

Epoch: 6| Step: 1
Training loss: 6.142597066246631
Validation loss: 5.808567180484921

Epoch: 6| Step: 2
Training loss: 6.3930716086640125
Validation loss: 5.7877839374155435

Epoch: 6| Step: 3
Training loss: 5.253665915739144
Validation loss: 5.769509336826087

Epoch: 6| Step: 4
Training loss: 4.478694920500611
Validation loss: 5.749583820906096

Epoch: 6| Step: 5
Training loss: 5.501313312827543
Validation loss: 5.728215458307527

Epoch: 6| Step: 6
Training loss: 6.264638009661041
Validation loss: 5.703380094097385

Epoch: 6| Step: 7
Training loss: 5.25013187787768
Validation loss: 5.674633807315783

Epoch: 6| Step: 8
Training loss: 5.497122965777544
Validation loss: 5.641361620585808

Epoch: 6| Step: 9
Training loss: 5.830202770338414
Validation loss: 5.6037699539965224

Epoch: 6| Step: 10
Training loss: 6.733409980614653
Validation loss: 5.560884156905515

Epoch: 6| Step: 11
Training loss: 4.698562385972229
Validation loss: 5.515751742845233

Epoch: 6| Step: 12
Training loss: 5.757517006070874
Validation loss: 5.468312933313498

Epoch: 6| Step: 13
Training loss: 3.677626241025148
Validation loss: 5.415861409094141

Epoch: 2| Step: 0
Training loss: 4.796417711560319
Validation loss: 5.36560786788464

Epoch: 6| Step: 1
Training loss: 5.261738324713032
Validation loss: 5.312925893274961

Epoch: 6| Step: 2
Training loss: 4.769533649415858
Validation loss: 5.260126643885553

Epoch: 6| Step: 3
Training loss: 5.104309183842873
Validation loss: 5.204033620994066

Epoch: 6| Step: 4
Training loss: 4.377286041276969
Validation loss: 5.1486246165040415

Epoch: 6| Step: 5
Training loss: 5.2296647927572275
Validation loss: 5.091389193348119

Epoch: 6| Step: 6
Training loss: 5.501058996725014
Validation loss: 5.034624972688398

Epoch: 6| Step: 7
Training loss: 5.2169983259728125
Validation loss: 4.977199534341071

Epoch: 6| Step: 8
Training loss: 5.455345947596631
Validation loss: 4.917695389225061

Epoch: 6| Step: 9
Training loss: 6.085206601248869
Validation loss: 4.858666444195469

Epoch: 6| Step: 10
Training loss: 5.449755657913209
Validation loss: 4.802151714629349

Epoch: 6| Step: 11
Training loss: 4.408720581891015
Validation loss: 4.7461116724094925

Epoch: 6| Step: 12
Training loss: 4.753690390282076
Validation loss: 4.6927818527582135

Epoch: 6| Step: 13
Training loss: 3.674493513433005
Validation loss: 4.6474163673503845

Epoch: 3| Step: 0
Training loss: 5.593652308799091
Validation loss: 4.606588467360044

Epoch: 6| Step: 1
Training loss: 4.162875065215595
Validation loss: 4.571273313708061

Epoch: 6| Step: 2
Training loss: 3.537310235962395
Validation loss: 4.53880062628879

Epoch: 6| Step: 3
Training loss: 5.094468516592554
Validation loss: 4.509318661459519

Epoch: 6| Step: 4
Training loss: 5.006776794834279
Validation loss: 4.4810226101960415

Epoch: 6| Step: 5
Training loss: 4.699620966135652
Validation loss: 4.448527569552354

Epoch: 6| Step: 6
Training loss: 4.205235741864339
Validation loss: 4.418498674880968

Epoch: 6| Step: 7
Training loss: 3.6575935699112674
Validation loss: 4.387345786058109

Epoch: 6| Step: 8
Training loss: 4.339944393663114
Validation loss: 4.358929731358373

Epoch: 6| Step: 9
Training loss: 4.3531447432728205
Validation loss: 4.327901959220667

Epoch: 6| Step: 10
Training loss: 4.553632087196645
Validation loss: 4.297185870696448

Epoch: 6| Step: 11
Training loss: 3.8591155300872435
Validation loss: 4.265314393092109

Epoch: 6| Step: 12
Training loss: 5.4733335632683495
Validation loss: 4.235938804014001

Epoch: 6| Step: 13
Training loss: 4.0930519964930925
Validation loss: 4.211528742276641

Epoch: 4| Step: 0
Training loss: 3.6490922295457873
Validation loss: 4.1844715327252375

Epoch: 6| Step: 1
Training loss: 4.342220778198766
Validation loss: 4.159291072275548

Epoch: 6| Step: 2
Training loss: 4.419800612151172
Validation loss: 4.133105816138308

Epoch: 6| Step: 3
Training loss: 4.849975522952893
Validation loss: 4.109327023027753

Epoch: 6| Step: 4
Training loss: 3.36419360538331
Validation loss: 4.084753696472195

Epoch: 6| Step: 5
Training loss: 3.458022567084097
Validation loss: 4.057764243524935

Epoch: 6| Step: 6
Training loss: 4.2843799148631545
Validation loss: 4.0226427296227545

Epoch: 6| Step: 7
Training loss: 4.993623673198289
Validation loss: 3.962105983063038

Epoch: 6| Step: 8
Training loss: 3.857535228753804
Validation loss: 3.926485538993024

Epoch: 6| Step: 9
Training loss: 4.129085944676544
Validation loss: 3.9265774545497854

Epoch: 6| Step: 10
Training loss: 4.2072314088149865
Validation loss: 3.9336519816349576

Epoch: 6| Step: 11
Training loss: 3.7969406812975732
Validation loss: 3.912361127458107

Epoch: 6| Step: 12
Training loss: 4.412029399037222
Validation loss: 3.8961764036461677

Epoch: 6| Step: 13
Training loss: 4.188238733520911
Validation loss: 3.874977590738918

Epoch: 5| Step: 0
Training loss: 4.230422536609888
Validation loss: 3.8439473013900485

Epoch: 6| Step: 1
Training loss: 3.362230657404591
Validation loss: 3.834934687067034

Epoch: 6| Step: 2
Training loss: 4.618832987244993
Validation loss: 3.833816999834989

Epoch: 6| Step: 3
Training loss: 3.8647591412939106
Validation loss: 3.8184299947234335

Epoch: 6| Step: 4
Training loss: 3.122130335235894
Validation loss: 3.796103216693057

Epoch: 6| Step: 5
Training loss: 4.091397840029785
Validation loss: 3.7700451820564345

Epoch: 6| Step: 6
Training loss: 4.201942249073729
Validation loss: 3.754828715215074

Epoch: 6| Step: 7
Training loss: 2.7023241918583403
Validation loss: 3.7402620330647274

Epoch: 6| Step: 8
Training loss: 3.9861128065317577
Validation loss: 3.7347999022443332

Epoch: 6| Step: 9
Training loss: 3.574661244168331
Validation loss: 3.7217269333359093

Epoch: 6| Step: 10
Training loss: 5.420762533340775
Validation loss: 3.7148952330249423

Epoch: 6| Step: 11
Training loss: 3.008949124475055
Validation loss: 3.6944261025589173

Epoch: 6| Step: 12
Training loss: 3.6473120315572114
Validation loss: 3.684618734112001

Epoch: 6| Step: 13
Training loss: 4.78902645626475
Validation loss: 3.6861310461411

Epoch: 6| Step: 0
Training loss: 3.9401186757683053
Validation loss: 3.663033415566938

Epoch: 6| Step: 1
Training loss: 4.626320727677859
Validation loss: 3.657799252913976

Epoch: 6| Step: 2
Training loss: 4.272466183032495
Validation loss: 3.6552407458413

Epoch: 6| Step: 3
Training loss: 3.9270515474336687
Validation loss: 3.6489874804318667

Epoch: 6| Step: 4
Training loss: 2.804579198759896
Validation loss: 3.6404399772877363

Epoch: 6| Step: 5
Training loss: 3.6805048397256783
Validation loss: 3.6379416316033115

Epoch: 6| Step: 6
Training loss: 3.820135506428481
Validation loss: 3.6268679410439213

Epoch: 6| Step: 7
Training loss: 3.2352074183102615
Validation loss: 3.6150959943706082

Epoch: 6| Step: 8
Training loss: 3.7690300326589283
Validation loss: 3.6051476482165294

Epoch: 6| Step: 9
Training loss: 3.7695345389396273
Validation loss: 3.595173978533114

Epoch: 6| Step: 10
Training loss: 3.7509572396827218
Validation loss: 3.5882499263448593

Epoch: 6| Step: 11
Training loss: 3.7560668189754556
Validation loss: 3.5864343458280707

Epoch: 6| Step: 12
Training loss: 4.598023794516663
Validation loss: 3.5873887698155733

Epoch: 6| Step: 13
Training loss: 2.4045623211319094
Validation loss: 3.5785863592967946

Epoch: 7| Step: 0
Training loss: 4.174093163964489
Validation loss: 3.5677138615113213

Epoch: 6| Step: 1
Training loss: 3.9356580997775614
Validation loss: 3.5608363718856784

Epoch: 6| Step: 2
Training loss: 3.2099572237676264
Validation loss: 3.550373849070998

Epoch: 6| Step: 3
Training loss: 3.7333985652220094
Validation loss: 3.548644089738032

Epoch: 6| Step: 4
Training loss: 3.6299433709553615
Validation loss: 3.5416570852730347

Epoch: 6| Step: 5
Training loss: 3.144284066857004
Validation loss: 3.5367190833215156

Epoch: 6| Step: 6
Training loss: 4.058124944727133
Validation loss: 3.534762206274741

Epoch: 6| Step: 7
Training loss: 3.7938479063670316
Validation loss: 3.5204706201174156

Epoch: 6| Step: 8
Training loss: 3.621319052920418
Validation loss: 3.515815054109978

Epoch: 6| Step: 9
Training loss: 3.5927264538923023
Validation loss: 3.513057667711317

Epoch: 6| Step: 10
Training loss: 3.927075589254149
Validation loss: 3.5080055994714145

Epoch: 6| Step: 11
Training loss: 3.32298605596307
Validation loss: 3.5041420974583186

Epoch: 6| Step: 12
Training loss: 4.00705240340366
Validation loss: 3.4990592738271586

Epoch: 6| Step: 13
Training loss: 4.1800283703000956
Validation loss: 3.4916195321891554

Epoch: 8| Step: 0
Training loss: 3.9933000720065968
Validation loss: 3.4938988752013267

Epoch: 6| Step: 1
Training loss: 3.6233486491993543
Validation loss: 3.4910400866510476

Epoch: 6| Step: 2
Training loss: 3.6864914888930183
Validation loss: 3.4863283161887013

Epoch: 6| Step: 3
Training loss: 3.8084379976165366
Validation loss: 3.4928256775857545

Epoch: 6| Step: 4
Training loss: 3.8626744301923908
Validation loss: 3.4924642563271555

Epoch: 6| Step: 5
Training loss: 3.5698447557562214
Validation loss: 3.4883764205962056

Epoch: 6| Step: 6
Training loss: 4.042339360732127
Validation loss: 3.481888294857868

Epoch: 6| Step: 7
Training loss: 3.388745608888016
Validation loss: 3.475179075341287

Epoch: 6| Step: 8
Training loss: 2.8015276181740285
Validation loss: 3.4721549292712464

Epoch: 6| Step: 9
Training loss: 3.8941385727390143
Validation loss: 3.4729179079717056

Epoch: 6| Step: 10
Training loss: 4.328601356485619
Validation loss: 3.4730543040905624

Epoch: 6| Step: 11
Training loss: 3.2670594491771965
Validation loss: 3.4637808349005206

Epoch: 6| Step: 12
Training loss: 3.668840168717322
Validation loss: 3.4592279808273396

Epoch: 6| Step: 13
Training loss: 3.438119728404714
Validation loss: 3.4565928191406594

Epoch: 9| Step: 0
Training loss: 3.016716161782019
Validation loss: 3.4605372335466247

Epoch: 6| Step: 1
Training loss: 3.92900549732347
Validation loss: 3.4655094273296316

Epoch: 6| Step: 2
Training loss: 2.3635493859380357
Validation loss: 3.4575257043376326

Epoch: 6| Step: 3
Training loss: 3.4449282754150206
Validation loss: 3.4507988091020905

Epoch: 6| Step: 4
Training loss: 3.6636643833970877
Validation loss: 3.4496317640938026

Epoch: 6| Step: 5
Training loss: 4.05534530919159
Validation loss: 3.4442416675952323

Epoch: 6| Step: 6
Training loss: 3.89858647675329
Validation loss: 3.441994451909626

Epoch: 6| Step: 7
Training loss: 3.8487456817454055
Validation loss: 3.441294240512095

Epoch: 6| Step: 8
Training loss: 3.2757216612119837
Validation loss: 3.43837883865429

Epoch: 6| Step: 9
Training loss: 4.000025749123666
Validation loss: 3.4396365658350536

Epoch: 6| Step: 10
Training loss: 3.50235478341796
Validation loss: 3.4351012331545956

Epoch: 6| Step: 11
Training loss: 3.5413678809897537
Validation loss: 3.434157015128713

Epoch: 6| Step: 12
Training loss: 3.889237244459248
Validation loss: 3.4322780117324907

Epoch: 6| Step: 13
Training loss: 4.928757859489101
Validation loss: 3.4308009466255527

Epoch: 10| Step: 0
Training loss: 2.9761618196833517
Validation loss: 3.434362521591134

Epoch: 6| Step: 1
Training loss: 4.3516492852095565
Validation loss: 3.435332813415025

Epoch: 6| Step: 2
Training loss: 2.3150862588322147
Validation loss: 3.4304729960616505

Epoch: 6| Step: 3
Training loss: 2.6835957933887324
Validation loss: 3.4242673160424166

Epoch: 6| Step: 4
Training loss: 3.6081957191027034
Validation loss: 3.4247231843080668

Epoch: 6| Step: 5
Training loss: 3.5363357515209652
Validation loss: 3.4256820040408598

Epoch: 6| Step: 6
Training loss: 3.7449806954429983
Validation loss: 3.424915547591323

Epoch: 6| Step: 7
Training loss: 4.223755530189761
Validation loss: 3.4212096170429036

Epoch: 6| Step: 8
Training loss: 4.318922264097309
Validation loss: 3.417443096940419

Epoch: 6| Step: 9
Training loss: 3.339592746872861
Validation loss: 3.4165997552410006

Epoch: 6| Step: 10
Training loss: 3.49173168646849
Validation loss: 3.415373127879218

Epoch: 6| Step: 11
Training loss: 4.226254718172
Validation loss: 3.4117275336914497

Epoch: 6| Step: 12
Training loss: 3.94413319704411
Validation loss: 3.4122037309792317

Epoch: 6| Step: 13
Training loss: 3.6161980150997843
Validation loss: 3.410911447964061

Epoch: 11| Step: 0
Training loss: 3.496975000228294
Validation loss: 3.409524202526418

Epoch: 6| Step: 1
Training loss: 3.996991456626559
Validation loss: 3.406616615690465

Epoch: 6| Step: 2
Training loss: 3.8600921582303886
Validation loss: 3.4048941740841117

Epoch: 6| Step: 3
Training loss: 3.5150055063999504
Validation loss: 3.4049700563481524

Epoch: 6| Step: 4
Training loss: 4.09575178984262
Validation loss: 3.401117195690632

Epoch: 6| Step: 5
Training loss: 2.6723300479416525
Validation loss: 3.399031114814259

Epoch: 6| Step: 6
Training loss: 3.5826366249966766
Validation loss: 3.397581738355411

Epoch: 6| Step: 7
Training loss: 3.6927083620287524
Validation loss: 3.3946531867129783

Epoch: 6| Step: 8
Training loss: 3.4259713793270037
Validation loss: 3.3931033189563244

Epoch: 6| Step: 9
Training loss: 3.600079344828736
Validation loss: 3.388563720891209

Epoch: 6| Step: 10
Training loss: 3.5704591416309
Validation loss: 3.387688889194379

Epoch: 6| Step: 11
Training loss: 2.907935033447694
Validation loss: 3.3821877296191185

Epoch: 6| Step: 12
Training loss: 4.537326290283954
Validation loss: 3.379524298387989

Epoch: 6| Step: 13
Training loss: 3.2686038507936153
Validation loss: 3.3734843817216986

Epoch: 12| Step: 0
Training loss: 3.6475600304477807
Validation loss: 3.372047843784718

Epoch: 6| Step: 1
Training loss: 3.091036136076583
Validation loss: 3.3695334155042307

Epoch: 6| Step: 2
Training loss: 4.052941448023092
Validation loss: 3.367584641354368

Epoch: 6| Step: 3
Training loss: 3.966421330235268
Validation loss: 3.3681496754220883

Epoch: 6| Step: 4
Training loss: 4.266177410644883
Validation loss: 3.365239584194708

Epoch: 6| Step: 5
Training loss: 3.0814544176614067
Validation loss: 3.3641454077099766

Epoch: 6| Step: 6
Training loss: 4.14684016335982
Validation loss: 3.358897968524414

Epoch: 6| Step: 7
Training loss: 2.8405015438097796
Validation loss: 3.356037646582613

Epoch: 6| Step: 8
Training loss: 3.4255796958239646
Validation loss: 3.3545188915045188

Epoch: 6| Step: 9
Training loss: 3.2849074551858752
Validation loss: 3.3526299855248904

Epoch: 6| Step: 10
Training loss: 3.791259128900411
Validation loss: 3.3515655519858956

Epoch: 6| Step: 11
Training loss: 3.953268056097924
Validation loss: 3.34893506907894

Epoch: 6| Step: 12
Training loss: 2.825563229478636
Validation loss: 3.3500460474445997

Epoch: 6| Step: 13
Training loss: 3.4645939578873866
Validation loss: 3.346248275724092

Epoch: 13| Step: 0
Training loss: 2.7184883079424713
Validation loss: 3.343208651747971

Epoch: 6| Step: 1
Training loss: 3.5457043837616196
Validation loss: 3.3428784855173754

Epoch: 6| Step: 2
Training loss: 3.8387391217747457
Validation loss: 3.340461314339326

Epoch: 6| Step: 3
Training loss: 4.147712371153328
Validation loss: 3.33802196376514

Epoch: 6| Step: 4
Training loss: 3.6361891281996868
Validation loss: 3.3377410915276577

Epoch: 6| Step: 5
Training loss: 2.757118375487385
Validation loss: 3.336186789427499

Epoch: 6| Step: 6
Training loss: 4.277880602725125
Validation loss: 3.3367538680909203

Epoch: 6| Step: 7
Training loss: 3.9452436082320568
Validation loss: 3.339898844299715

Epoch: 6| Step: 8
Training loss: 3.81672934157261
Validation loss: 3.332592151644966

Epoch: 6| Step: 9
Training loss: 3.4809632982852303
Validation loss: 3.332668537070747

Epoch: 6| Step: 10
Training loss: 3.348124272181033
Validation loss: 3.3320628380383863

Epoch: 6| Step: 11
Training loss: 3.3950874742073336
Validation loss: 3.3351404126786077

Epoch: 6| Step: 12
Training loss: 3.345998560593336
Validation loss: 3.3275202351368414

Epoch: 6| Step: 13
Training loss: 3.267037848060408
Validation loss: 3.323105114337256

Epoch: 14| Step: 0
Training loss: 3.8461462475628254
Validation loss: 3.3219626442637824

Epoch: 6| Step: 1
Training loss: 2.9866480933474726
Validation loss: 3.3174210808456244

Epoch: 6| Step: 2
Training loss: 3.164075912635538
Validation loss: 3.3173158611530345

Epoch: 6| Step: 3
Training loss: 3.6915674567974426
Validation loss: 3.3125720055946637

Epoch: 6| Step: 4
Training loss: 2.4762604827119796
Validation loss: 3.3065242324915967

Epoch: 6| Step: 5
Training loss: 3.778949005913474
Validation loss: 3.3042028509998262

Epoch: 6| Step: 6
Training loss: 3.3206165129662417
Validation loss: 3.3032323105677377

Epoch: 6| Step: 7
Training loss: 3.193030850838165
Validation loss: 3.3028734423268897

Epoch: 6| Step: 8
Training loss: 3.92849598106168
Validation loss: 3.297964284992522

Epoch: 6| Step: 9
Training loss: 3.7771426505333405
Validation loss: 3.298265930548953

Epoch: 6| Step: 10
Training loss: 3.6332657069874204
Validation loss: 3.298378272021833

Epoch: 6| Step: 11
Training loss: 3.822984256545331
Validation loss: 3.3000829948486894

Epoch: 6| Step: 12
Training loss: 4.026957747778412
Validation loss: 3.290821118450942

Epoch: 6| Step: 13
Training loss: 3.7656675470884724
Validation loss: 3.286504753963755

Epoch: 15| Step: 0
Training loss: 3.25125303321823
Validation loss: 3.2895266418511886

Epoch: 6| Step: 1
Training loss: 3.769233715589201
Validation loss: 3.288424433425413

Epoch: 6| Step: 2
Training loss: 3.170741437732445
Validation loss: 3.285419939260738

Epoch: 6| Step: 3
Training loss: 3.270330370158414
Validation loss: 3.2839053994601937

Epoch: 6| Step: 4
Training loss: 2.770439311146448
Validation loss: 3.2820990913638943

Epoch: 6| Step: 5
Training loss: 3.4785642882878367
Validation loss: 3.2813283314220403

Epoch: 6| Step: 6
Training loss: 3.8574409117410005
Validation loss: 3.2800922497928333

Epoch: 6| Step: 7
Training loss: 3.2426338348180086
Validation loss: 3.27915657482733

Epoch: 6| Step: 8
Training loss: 3.9852955670992727
Validation loss: 3.2808409100369715

Epoch: 6| Step: 9
Training loss: 3.9410095317641094
Validation loss: 3.2772567694262857

Epoch: 6| Step: 10
Training loss: 3.249150678724617
Validation loss: 3.2796930528697397

Epoch: 6| Step: 11
Training loss: 4.0279437560745075
Validation loss: 3.278159470289297

Epoch: 6| Step: 12
Training loss: 3.4169282735520103
Validation loss: 3.274984696743964

Epoch: 6| Step: 13
Training loss: 3.803847703935625
Validation loss: 3.2726022955531286

Epoch: 16| Step: 0
Training loss: 3.1572259583783833
Validation loss: 3.269182545110394

Epoch: 6| Step: 1
Training loss: 3.773970224753266
Validation loss: 3.270889707076494

Epoch: 6| Step: 2
Training loss: 3.071242640497739
Validation loss: 3.269396901051959

Epoch: 6| Step: 3
Training loss: 2.5651164769427535
Validation loss: 3.2674583960016994

Epoch: 6| Step: 4
Training loss: 3.104987801790464
Validation loss: 3.266310093847904

Epoch: 6| Step: 5
Training loss: 3.477154010643318
Validation loss: 3.2648184242859584

Epoch: 6| Step: 6
Training loss: 3.7108506363188964
Validation loss: 3.2644102868899534

Epoch: 6| Step: 7
Training loss: 3.8835166123870932
Validation loss: 3.2627621329884473

Epoch: 6| Step: 8
Training loss: 4.066518351450728
Validation loss: 3.2645833479187636

Epoch: 6| Step: 9
Training loss: 3.8550217513325484
Validation loss: 3.2600286785560133

Epoch: 6| Step: 10
Training loss: 3.366877778361767
Validation loss: 3.2630377072746666

Epoch: 6| Step: 11
Training loss: 3.233769161962382
Validation loss: 3.2568126186827406

Epoch: 6| Step: 12
Training loss: 3.70878908307112
Validation loss: 3.259510420052682

Epoch: 6| Step: 13
Training loss: 4.144666088905763
Validation loss: 3.2577289720007436

Epoch: 17| Step: 0
Training loss: 4.206935814188535
Validation loss: 3.258374936189896

Epoch: 6| Step: 1
Training loss: 3.796061361912281
Validation loss: 3.2555517512482903

Epoch: 6| Step: 2
Training loss: 3.817963984084272
Validation loss: 3.2527763018817204

Epoch: 6| Step: 3
Training loss: 3.9169645534349953
Validation loss: 3.251708937366773

Epoch: 6| Step: 4
Training loss: 3.0974371930051814
Validation loss: 3.2510734864533433

Epoch: 6| Step: 5
Training loss: 3.2409180143603855
Validation loss: 3.249066406489792

Epoch: 6| Step: 6
Training loss: 2.755082548812112
Validation loss: 3.250424929180664

Epoch: 6| Step: 7
Training loss: 3.747596097379524
Validation loss: 3.249049723791955

Epoch: 6| Step: 8
Training loss: 3.3378326250263703
Validation loss: 3.2504855093837217

Epoch: 6| Step: 9
Training loss: 3.1543432840529424
Validation loss: 3.2480632400319944

Epoch: 6| Step: 10
Training loss: 3.2526301965010456
Validation loss: 3.2512625079224984

Epoch: 6| Step: 11
Training loss: 3.6292746760299455
Validation loss: 3.2555192688464714

Epoch: 6| Step: 12
Training loss: 3.5464485348998593
Validation loss: 3.24524128929297

Epoch: 6| Step: 13
Training loss: 3.053939532637532
Validation loss: 3.240720939230661

Epoch: 18| Step: 0
Training loss: 3.1419946521249735
Validation loss: 3.2476076576944997

Epoch: 6| Step: 1
Training loss: 3.2112772592447056
Validation loss: 3.2514827255142844

Epoch: 6| Step: 2
Training loss: 4.5497425383781165
Validation loss: 3.243575742711276

Epoch: 6| Step: 3
Training loss: 4.103391751685166
Validation loss: 3.2424573220432404

Epoch: 6| Step: 4
Training loss: 3.7091561308309546
Validation loss: 3.2409719316204604

Epoch: 6| Step: 5
Training loss: 4.1213496847364155
Validation loss: 3.2420463735893916

Epoch: 6| Step: 6
Training loss: 4.121279801783645
Validation loss: 3.2379628464334913

Epoch: 6| Step: 7
Training loss: 2.980678645951235
Validation loss: 3.236785722646633

Epoch: 6| Step: 8
Training loss: 3.4250445731945067
Validation loss: 3.233311844646401

Epoch: 6| Step: 9
Training loss: 2.345024677789323
Validation loss: 3.232718218298107

Epoch: 6| Step: 10
Training loss: 2.5034318257278136
Validation loss: 3.234615593406638

Epoch: 6| Step: 11
Training loss: 3.185667520994821
Validation loss: 3.233635407513737

Epoch: 6| Step: 12
Training loss: 3.5726405594058055
Validation loss: 3.2352154201499506

Epoch: 6| Step: 13
Training loss: 2.9010529349545986
Validation loss: 3.2381481775309915

Epoch: 19| Step: 0
Training loss: 3.3747533072275897
Validation loss: 3.2351695119209545

Epoch: 6| Step: 1
Training loss: 2.9543102650967543
Validation loss: 3.231986449265164

Epoch: 6| Step: 2
Training loss: 3.7051218821546335
Validation loss: 3.229723467078049

Epoch: 6| Step: 3
Training loss: 2.401861672762749
Validation loss: 3.228438006123002

Epoch: 6| Step: 4
Training loss: 3.453623601897222
Validation loss: 3.2294915492673755

Epoch: 6| Step: 5
Training loss: 4.237526034384903
Validation loss: 3.228180248322704

Epoch: 6| Step: 6
Training loss: 3.7633842671148763
Validation loss: 3.2271672775813562

Epoch: 6| Step: 7
Training loss: 2.5755413634456223
Validation loss: 3.2286968295612506

Epoch: 6| Step: 8
Training loss: 3.573406856857505
Validation loss: 3.2255287507718395

Epoch: 6| Step: 9
Training loss: 3.895579664706174
Validation loss: 3.2243593685393788

Epoch: 6| Step: 10
Training loss: 3.311655188740417
Validation loss: 3.2280631718727717

Epoch: 6| Step: 11
Training loss: 4.141336631801427
Validation loss: 3.2278318432240134

Epoch: 6| Step: 12
Training loss: 4.007956221533672
Validation loss: 3.221868285858462

Epoch: 6| Step: 13
Training loss: 1.7642667153804346
Validation loss: 3.2217255126288977

Epoch: 20| Step: 0
Training loss: 4.06133687901817
Validation loss: 3.21691902826733

Epoch: 6| Step: 1
Training loss: 3.7211447306009346
Validation loss: 3.221974634979826

Epoch: 6| Step: 2
Training loss: 3.591076461789549
Validation loss: 3.221043043235983

Epoch: 6| Step: 3
Training loss: 3.695695466083122
Validation loss: 3.217725044812898

Epoch: 6| Step: 4
Training loss: 3.9573568377743613
Validation loss: 3.216658547827028

Epoch: 6| Step: 5
Training loss: 2.757500390392563
Validation loss: 3.2146673389731037

Epoch: 6| Step: 6
Training loss: 3.0072303109450074
Validation loss: 3.211489229700687

Epoch: 6| Step: 7
Training loss: 3.1755151766229823
Validation loss: 3.2130582771005614

Epoch: 6| Step: 8
Training loss: 3.3473410174199247
Validation loss: 3.214827785238739

Epoch: 6| Step: 9
Training loss: 3.873394048831016
Validation loss: 3.2118807676304417

Epoch: 6| Step: 10
Training loss: 3.218527036185001
Validation loss: 3.2156891136044647

Epoch: 6| Step: 11
Training loss: 3.3452624171577985
Validation loss: 3.2159044570820687

Epoch: 6| Step: 12
Training loss: 3.380791957101494
Validation loss: 3.2175029581392285

Epoch: 6| Step: 13
Training loss: 2.9701507476156848
Validation loss: 3.2246182379111947

Epoch: 21| Step: 0
Training loss: 2.700172178641859
Validation loss: 3.215631666363615

Epoch: 6| Step: 1
Training loss: 3.863416031047534
Validation loss: 3.211628303163539

Epoch: 6| Step: 2
Training loss: 3.105503144463621
Validation loss: 3.2085135566029366

Epoch: 6| Step: 3
Training loss: 3.7314400731528905
Validation loss: 3.204433404637798

Epoch: 6| Step: 4
Training loss: 3.844158492053095
Validation loss: 3.204924417807259

Epoch: 6| Step: 5
Training loss: 3.7723414880859307
Validation loss: 3.200568654181464

Epoch: 6| Step: 6
Training loss: 2.697970906501607
Validation loss: 3.2010790109373986

Epoch: 6| Step: 7
Training loss: 3.7294308162173566
Validation loss: 3.2024330670378824

Epoch: 6| Step: 8
Training loss: 3.2441886884515294
Validation loss: 3.199987216508619

Epoch: 6| Step: 9
Training loss: 2.895176289252454
Validation loss: 3.20144843147111

Epoch: 6| Step: 10
Training loss: 3.484139609832072
Validation loss: 3.202808436315976

Epoch: 6| Step: 11
Training loss: 3.8664263968521877
Validation loss: 3.2003402341941256

Epoch: 6| Step: 12
Training loss: 3.734029969432767
Validation loss: 3.19957023716243

Epoch: 6| Step: 13
Training loss: 3.3726170922631273
Validation loss: 3.1991837515750876

Epoch: 22| Step: 0
Training loss: 3.5967230399318435
Validation loss: 3.1977733999370375

Epoch: 6| Step: 1
Training loss: 4.067930846370131
Validation loss: 3.1981703252232894

Epoch: 6| Step: 2
Training loss: 3.702335579342509
Validation loss: 3.19829258231299

Epoch: 6| Step: 3
Training loss: 2.514534186573242
Validation loss: 3.193436012930218

Epoch: 6| Step: 4
Training loss: 3.1089078466009936
Validation loss: 3.1920073118886574

Epoch: 6| Step: 5
Training loss: 3.202850478899311
Validation loss: 3.190659695996158

Epoch: 6| Step: 6
Training loss: 3.0343244240000127
Validation loss: 3.1905447251577264

Epoch: 6| Step: 7
Training loss: 3.20808584736711
Validation loss: 3.1914645012075114

Epoch: 6| Step: 8
Training loss: 3.5390342054435986
Validation loss: 3.192337557141579

Epoch: 6| Step: 9
Training loss: 4.090963798696597
Validation loss: 3.1911404880677536

Epoch: 6| Step: 10
Training loss: 3.9932569650173613
Validation loss: 3.1885812555368065

Epoch: 6| Step: 11
Training loss: 2.6684283953890087
Validation loss: 3.1888049882749705

Epoch: 6| Step: 12
Training loss: 3.6438614371845808
Validation loss: 3.1954879481909675

Epoch: 6| Step: 13
Training loss: 3.459728710145166
Validation loss: 3.214387877826993

Epoch: 23| Step: 0
Training loss: 3.413182474716652
Validation loss: 3.2008686593403444

Epoch: 6| Step: 1
Training loss: 4.0530485100392575
Validation loss: 3.1987599489583816

Epoch: 6| Step: 2
Training loss: 3.8688574065796595
Validation loss: 3.184545546789263

Epoch: 6| Step: 3
Training loss: 3.8299186397107965
Validation loss: 3.195141410203627

Epoch: 6| Step: 4
Training loss: 3.882750359082096
Validation loss: 3.189169475281375

Epoch: 6| Step: 5
Training loss: 3.5072751047762845
Validation loss: 3.185756477549335

Epoch: 6| Step: 6
Training loss: 2.750710482284283
Validation loss: 3.1822084421670027

Epoch: 6| Step: 7
Training loss: 2.7212384991803615
Validation loss: 3.190326462970408

Epoch: 6| Step: 8
Training loss: 3.690731636851803
Validation loss: 3.223037438444179

Epoch: 6| Step: 9
Training loss: 3.695370308744443
Validation loss: 3.2123425229600504

Epoch: 6| Step: 10
Training loss: 3.5228210045210955
Validation loss: 3.186846161549435

Epoch: 6| Step: 11
Training loss: 2.6508878552097292
Validation loss: 3.180300198398154

Epoch: 6| Step: 12
Training loss: 3.2478674714622544
Validation loss: 3.181134125475074

Epoch: 6| Step: 13
Training loss: 2.614506501263232
Validation loss: 3.190075360943055

Epoch: 24| Step: 0
Training loss: 3.4161859189614017
Validation loss: 3.2072365405209173

Epoch: 6| Step: 1
Training loss: 3.2757017184646178
Validation loss: 3.206110586379162

Epoch: 6| Step: 2
Training loss: 3.645528609847253
Validation loss: 3.207675702365645

Epoch: 6| Step: 3
Training loss: 3.6738831568180244
Validation loss: 3.2043124379233703

Epoch: 6| Step: 4
Training loss: 2.5338439836653577
Validation loss: 3.2029851011013273

Epoch: 6| Step: 5
Training loss: 3.1831473757236206
Validation loss: 3.2030011633088153

Epoch: 6| Step: 6
Training loss: 3.2766016414343673
Validation loss: 3.203168121295746

Epoch: 6| Step: 7
Training loss: 3.777373036662578
Validation loss: 3.207905378966512

Epoch: 6| Step: 8
Training loss: 3.0381934485055413
Validation loss: 3.2272339551034452

Epoch: 6| Step: 9
Training loss: 3.5636256263355293
Validation loss: 3.201726026590797

Epoch: 6| Step: 10
Training loss: 3.453326465374022
Validation loss: 3.196705472201366

Epoch: 6| Step: 11
Training loss: 3.830555047236584
Validation loss: 3.1769896484204496

Epoch: 6| Step: 12
Training loss: 4.251873725286448
Validation loss: 3.176098201425325

Epoch: 6| Step: 13
Training loss: 2.5385794312103873
Validation loss: 3.1765214804842454

Epoch: 25| Step: 0
Training loss: 3.2050162337869508
Validation loss: 3.1728392793724693

Epoch: 6| Step: 1
Training loss: 3.298428571680834
Validation loss: 3.1728676754478427

Epoch: 6| Step: 2
Training loss: 3.734229942920168
Validation loss: 3.1707568539428577

Epoch: 6| Step: 3
Training loss: 3.2036611713027168
Validation loss: 3.1678082578582463

Epoch: 6| Step: 4
Training loss: 3.740697129907766
Validation loss: 3.17041711720303

Epoch: 6| Step: 5
Training loss: 4.299015801928899
Validation loss: 3.169259394849529

Epoch: 6| Step: 6
Training loss: 3.4645082124207276
Validation loss: 3.168369545883349

Epoch: 6| Step: 7
Training loss: 3.406448498462976
Validation loss: 3.1670511532595964

Epoch: 6| Step: 8
Training loss: 3.0367290884302727
Validation loss: 3.167913611281072

Epoch: 6| Step: 9
Training loss: 3.3842339117312092
Validation loss: 3.166908708809309

Epoch: 6| Step: 10
Training loss: 3.4174180638970273
Validation loss: 3.167264560241363

Epoch: 6| Step: 11
Training loss: 2.982833384245413
Validation loss: 3.1649172138034323

Epoch: 6| Step: 12
Training loss: 2.8207021850871756
Validation loss: 3.1644332087231746

Epoch: 6| Step: 13
Training loss: 3.8164850888655013
Validation loss: 3.161906954933539

Epoch: 26| Step: 0
Training loss: 3.880957668923808
Validation loss: 3.1598518959495747

Epoch: 6| Step: 1
Training loss: 3.6655780447759874
Validation loss: 3.1612874657419407

Epoch: 6| Step: 2
Training loss: 3.480926860283138
Validation loss: 3.158134740012904

Epoch: 6| Step: 3
Training loss: 3.162214478883655
Validation loss: 3.162535871991089

Epoch: 6| Step: 4
Training loss: 3.311788230575694
Validation loss: 3.1589708584234466

Epoch: 6| Step: 5
Training loss: 2.6973527787897207
Validation loss: 3.1590767889760825

Epoch: 6| Step: 6
Training loss: 3.3784379755897884
Validation loss: 3.1546086238972078

Epoch: 6| Step: 7
Training loss: 3.7622683431591506
Validation loss: 3.152186730464188

Epoch: 6| Step: 8
Training loss: 2.838173901359878
Validation loss: 3.1495861043933426

Epoch: 6| Step: 9
Training loss: 3.525957580795927
Validation loss: 3.1500388409833535

Epoch: 6| Step: 10
Training loss: 3.3999544813811653
Validation loss: 3.1503230209089703

Epoch: 6| Step: 11
Training loss: 3.5057527403699376
Validation loss: 3.1489675504123844

Epoch: 6| Step: 12
Training loss: 3.041777116694931
Validation loss: 3.1498677549063308

Epoch: 6| Step: 13
Training loss: 4.115814153659144
Validation loss: 3.1491367430078614

Epoch: 27| Step: 0
Training loss: 3.8142813601400096
Validation loss: 3.1518575570897784

Epoch: 6| Step: 1
Training loss: 3.6111488112087455
Validation loss: 3.1552627856860993

Epoch: 6| Step: 2
Training loss: 3.2005074575510433
Validation loss: 3.1569649442899546

Epoch: 6| Step: 3
Training loss: 3.089583857393295
Validation loss: 3.146428046635701

Epoch: 6| Step: 4
Training loss: 3.552458951150509
Validation loss: 3.1449659975009934

Epoch: 6| Step: 5
Training loss: 3.518715817978262
Validation loss: 3.1417000345422124

Epoch: 6| Step: 6
Training loss: 2.70649332974449
Validation loss: 3.141216139386159

Epoch: 6| Step: 7
Training loss: 2.4495473638200296
Validation loss: 3.14129469417811

Epoch: 6| Step: 8
Training loss: 4.311406535964728
Validation loss: 3.1385188935673924

Epoch: 6| Step: 9
Training loss: 2.7197383092766967
Validation loss: 3.1403450561283246

Epoch: 6| Step: 10
Training loss: 2.853875546795389
Validation loss: 3.140851605208742

Epoch: 6| Step: 11
Training loss: 4.122098885125149
Validation loss: 3.1395908482161667

Epoch: 6| Step: 12
Training loss: 3.5722379938874655
Validation loss: 3.1370796146519813

Epoch: 6| Step: 13
Training loss: 3.519783375099865
Validation loss: 3.136664793016081

Epoch: 28| Step: 0
Training loss: 3.279020442069442
Validation loss: 3.1359788459274047

Epoch: 6| Step: 1
Training loss: 3.3939253394704934
Validation loss: 3.1363240427613635

Epoch: 6| Step: 2
Training loss: 3.842641158777941
Validation loss: 3.1350849093154403

Epoch: 6| Step: 3
Training loss: 2.9676977601716015
Validation loss: 3.135059253873012

Epoch: 6| Step: 4
Training loss: 3.3359083402194525
Validation loss: 3.1335703200424763

Epoch: 6| Step: 5
Training loss: 2.8180625161735247
Validation loss: 3.132863971855177

Epoch: 6| Step: 6
Training loss: 3.685082111660164
Validation loss: 3.1300574595227104

Epoch: 6| Step: 7
Training loss: 3.3658047910536184
Validation loss: 3.128215248158551

Epoch: 6| Step: 8
Training loss: 3.9447463431959986
Validation loss: 3.1276756677974684

Epoch: 6| Step: 9
Training loss: 3.9122975647447142
Validation loss: 3.1286394415867855

Epoch: 6| Step: 10
Training loss: 3.067762718733264
Validation loss: 3.128510612822915

Epoch: 6| Step: 11
Training loss: 2.83430993321944
Validation loss: 3.12883310167326

Epoch: 6| Step: 12
Training loss: 3.54716214937587
Validation loss: 3.1282147203864583

Epoch: 6| Step: 13
Training loss: 2.906476575981812
Validation loss: 3.1293837172103056

Epoch: 29| Step: 0
Training loss: 3.1650810956885698
Validation loss: 3.1543404882482693

Epoch: 6| Step: 1
Training loss: 3.7162898284594714
Validation loss: 3.1894060251513334

Epoch: 6| Step: 2
Training loss: 2.6375890129219197
Validation loss: 3.139944712312334

Epoch: 6| Step: 3
Training loss: 3.439990441952224
Validation loss: 3.127806182504115

Epoch: 6| Step: 4
Training loss: 3.3654777983456117
Validation loss: 3.1226039240586427

Epoch: 6| Step: 5
Training loss: 3.794652845866416
Validation loss: 3.1215916313921164

Epoch: 6| Step: 6
Training loss: 3.5674275902695496
Validation loss: 3.12133177367981

Epoch: 6| Step: 7
Training loss: 3.3803592093739705
Validation loss: 3.120086299102653

Epoch: 6| Step: 8
Training loss: 2.9006396870651217
Validation loss: 3.1204610318755703

Epoch: 6| Step: 9
Training loss: 3.6952162361107113
Validation loss: 3.1202731424100554

Epoch: 6| Step: 10
Training loss: 3.1012851389286107
Validation loss: 3.1205462788857585

Epoch: 6| Step: 11
Training loss: 3.779443482702239
Validation loss: 3.1197713905743973

Epoch: 6| Step: 12
Training loss: 2.798734504960081
Validation loss: 3.115776164210377

Epoch: 6| Step: 13
Training loss: 4.073482516398146
Validation loss: 3.1159562273831267

Epoch: 30| Step: 0
Training loss: 3.3619333860479927
Validation loss: 3.114594792082823

Epoch: 6| Step: 1
Training loss: 3.131586686419609
Validation loss: 3.115106901145982

Epoch: 6| Step: 2
Training loss: 3.8097226391857473
Validation loss: 3.1156323431550152

Epoch: 6| Step: 3
Training loss: 3.4806158888826535
Validation loss: 3.112098971975914

Epoch: 6| Step: 4
Training loss: 3.322581657973415
Validation loss: 3.113213834823825

Epoch: 6| Step: 5
Training loss: 2.4820469919101145
Validation loss: 3.1113007806156827

Epoch: 6| Step: 6
Training loss: 3.340927358705948
Validation loss: 3.1105343858609187

Epoch: 6| Step: 7
Training loss: 2.907591807391162
Validation loss: 3.1120755571693137

Epoch: 6| Step: 8
Training loss: 2.935649207610065
Validation loss: 3.1182243478770064

Epoch: 6| Step: 9
Training loss: 3.5523338490556435
Validation loss: 3.128370486323963

Epoch: 6| Step: 10
Training loss: 2.96112494768636
Validation loss: 3.10779075438628

Epoch: 6| Step: 11
Training loss: 4.447127094213729
Validation loss: 3.1064204422139703

Epoch: 6| Step: 12
Training loss: 3.367310842569459
Validation loss: 3.1076026680810553

Epoch: 6| Step: 13
Training loss: 3.767698231666754
Validation loss: 3.1053364246791224

Epoch: 31| Step: 0
Training loss: 3.1046702000021273
Validation loss: 3.108797343420408

Epoch: 6| Step: 1
Training loss: 3.1521772035756017
Validation loss: 3.105583264651662

Epoch: 6| Step: 2
Training loss: 3.5375543543006303
Validation loss: 3.1144737610965096

Epoch: 6| Step: 3
Training loss: 2.6732918178477227
Validation loss: 3.1053977763684077

Epoch: 6| Step: 4
Training loss: 3.394006545906296
Validation loss: 3.104324859290387

Epoch: 6| Step: 5
Training loss: 3.2195635017569857
Validation loss: 3.102005796048091

Epoch: 6| Step: 6
Training loss: 2.938207987425016
Validation loss: 3.1015208359233224

Epoch: 6| Step: 7
Training loss: 3.8209792103405236
Validation loss: 3.1023494265322427

Epoch: 6| Step: 8
Training loss: 3.373632648542881
Validation loss: 3.1018097436112955

Epoch: 6| Step: 9
Training loss: 3.5009046475354415
Validation loss: 3.1054341256570708

Epoch: 6| Step: 10
Training loss: 2.686095735816472
Validation loss: 3.103195731213189

Epoch: 6| Step: 11
Training loss: 4.048088215903324
Validation loss: 3.102460037078116

Epoch: 6| Step: 12
Training loss: 3.843636611878756
Validation loss: 3.098337472401657

Epoch: 6| Step: 13
Training loss: 3.5080972738578846
Validation loss: 3.0965247283415125

Epoch: 32| Step: 0
Training loss: 3.54377429556886
Validation loss: 3.0961130513833046

Epoch: 6| Step: 1
Training loss: 2.813205545726242
Validation loss: 3.0994727540773037

Epoch: 6| Step: 2
Training loss: 2.8493217129587154
Validation loss: 3.0980723575278524

Epoch: 6| Step: 3
Training loss: 3.915107876788282
Validation loss: 3.0994411992304447

Epoch: 6| Step: 4
Training loss: 3.480747678392498
Validation loss: 3.095810089225018

Epoch: 6| Step: 5
Training loss: 3.708811582665381
Validation loss: 3.0913981720084673

Epoch: 6| Step: 6
Training loss: 2.8000999909666837
Validation loss: 3.0903820135635742

Epoch: 6| Step: 7
Training loss: 3.741961956195735
Validation loss: 3.0919103023993233

Epoch: 6| Step: 8
Training loss: 3.3848112689868186
Validation loss: 3.090983499915952

Epoch: 6| Step: 9
Training loss: 3.5300126059850108
Validation loss: 3.0990218077015603

Epoch: 6| Step: 10
Training loss: 2.7863481066046285
Validation loss: 3.0903164946462143

Epoch: 6| Step: 11
Training loss: 2.8129202634682646
Validation loss: 3.09022780546942

Epoch: 6| Step: 12
Training loss: 3.4939891426254004
Validation loss: 3.1025269703427654

Epoch: 6| Step: 13
Training loss: 3.9454638159410855
Validation loss: 3.088767982276817

Epoch: 33| Step: 0
Training loss: 3.3874240655587777
Validation loss: 3.085735018136067

Epoch: 6| Step: 1
Training loss: 2.267685367699823
Validation loss: 3.089283703781117

Epoch: 6| Step: 2
Training loss: 3.1002451215246833
Validation loss: 3.089342041652385

Epoch: 6| Step: 3
Training loss: 3.5468024023751505
Validation loss: 3.095632676945313

Epoch: 6| Step: 4
Training loss: 3.473789026041842
Validation loss: 3.1086364386729617

Epoch: 6| Step: 5
Training loss: 2.791324243373874
Validation loss: 3.1044354192710855

Epoch: 6| Step: 6
Training loss: 4.063414016018571
Validation loss: 3.099190265969

Epoch: 6| Step: 7
Training loss: 4.083286103474998
Validation loss: 3.090118868468553

Epoch: 6| Step: 8
Training loss: 3.717310522672629
Validation loss: 3.0908340529223066

Epoch: 6| Step: 9
Training loss: 2.523952372553503
Validation loss: 3.0836494126369454

Epoch: 6| Step: 10
Training loss: 3.4906041867857422
Validation loss: 3.0815298170919245

Epoch: 6| Step: 11
Training loss: 3.805207453923507
Validation loss: 3.0807830559238694

Epoch: 6| Step: 12
Training loss: 3.448923307836433
Validation loss: 3.0794223674623677

Epoch: 6| Step: 13
Training loss: 1.843081466248643
Validation loss: 3.079427673024823

Epoch: 34| Step: 0
Training loss: 3.931172569980028
Validation loss: 3.0836112394089725

Epoch: 6| Step: 1
Training loss: 3.6463418369804903
Validation loss: 3.085049146537739

Epoch: 6| Step: 2
Training loss: 2.7974827281974393
Validation loss: 3.0818602766160765

Epoch: 6| Step: 3
Training loss: 3.482349029138548
Validation loss: 3.087426044072744

Epoch: 6| Step: 4
Training loss: 3.571546078519947
Validation loss: 3.078604085861879

Epoch: 6| Step: 5
Training loss: 2.5114780150477842
Validation loss: 3.075863346449699

Epoch: 6| Step: 6
Training loss: 3.0188938272462558
Validation loss: 3.072691707118083

Epoch: 6| Step: 7
Training loss: 3.713714395851226
Validation loss: 3.070252389409957

Epoch: 6| Step: 8
Training loss: 3.758438534050198
Validation loss: 3.0708356253677365

Epoch: 6| Step: 9
Training loss: 3.5641630875149777
Validation loss: 3.0661111301281996

Epoch: 6| Step: 10
Training loss: 3.370453491940366
Validation loss: 3.067582149965259

Epoch: 6| Step: 11
Training loss: 3.017863495304906
Validation loss: 3.064723449331627

Epoch: 6| Step: 12
Training loss: 3.0335324532964267
Validation loss: 3.0658183750561583

Epoch: 6| Step: 13
Training loss: 2.5204917318961075
Validation loss: 3.0627325646480337

Epoch: 35| Step: 0
Training loss: 3.8119169946381612
Validation loss: 3.0609372462605493

Epoch: 6| Step: 1
Training loss: 3.801262224272441
Validation loss: 3.0596638794978115

Epoch: 6| Step: 2
Training loss: 3.3469436937650143
Validation loss: 3.057774888032838

Epoch: 6| Step: 3
Training loss: 3.137499872336822
Validation loss: 3.0595674518783023

Epoch: 6| Step: 4
Training loss: 2.994048095388175
Validation loss: 3.0575682622271385

Epoch: 6| Step: 5
Training loss: 3.220348368689738
Validation loss: 3.0533385724511155

Epoch: 6| Step: 6
Training loss: 3.3330890724968265
Validation loss: 3.0539595921556657

Epoch: 6| Step: 7
Training loss: 3.4055719663201427
Validation loss: 3.054623687944571

Epoch: 6| Step: 8
Training loss: 3.0446766282930646
Validation loss: 3.0549658591931257

Epoch: 6| Step: 9
Training loss: 2.7861801341330477
Validation loss: 3.0524914222407227

Epoch: 6| Step: 10
Training loss: 3.066653801711367
Validation loss: 3.051647366953057

Epoch: 6| Step: 11
Training loss: 3.214922212220296
Validation loss: 3.0527536488454308

Epoch: 6| Step: 12
Training loss: 3.503597726496832
Validation loss: 3.0545511325702526

Epoch: 6| Step: 13
Training loss: 3.881127342951977
Validation loss: 3.049610459230848

Epoch: 36| Step: 0
Training loss: 2.276496114397828
Validation loss: 3.050227561569624

Epoch: 6| Step: 1
Training loss: 3.249395167483908
Validation loss: 3.0491353727371076

Epoch: 6| Step: 2
Training loss: 3.2574408522745113
Validation loss: 3.0499348873381154

Epoch: 6| Step: 3
Training loss: 3.41467838275314
Validation loss: 3.051445022612775

Epoch: 6| Step: 4
Training loss: 3.2990981285669667
Validation loss: 3.0487909183558877

Epoch: 6| Step: 5
Training loss: 2.4247600476030917
Validation loss: 3.0515403400335646

Epoch: 6| Step: 6
Training loss: 3.86297081605541
Validation loss: 3.053295704569939

Epoch: 6| Step: 7
Training loss: 3.783475362881752
Validation loss: 3.05385212411657

Epoch: 6| Step: 8
Training loss: 3.286128024002826
Validation loss: 3.0522167665642024

Epoch: 6| Step: 9
Training loss: 3.126232056930403
Validation loss: 3.050005020831417

Epoch: 6| Step: 10
Training loss: 4.139440748616136
Validation loss: 3.0515605094149643

Epoch: 6| Step: 11
Training loss: 3.308509005887851
Validation loss: 3.046821762473877

Epoch: 6| Step: 12
Training loss: 3.238906855139859
Validation loss: 3.046093034592819

Epoch: 6| Step: 13
Training loss: 3.197209100800372
Validation loss: 3.043949178240622

Epoch: 37| Step: 0
Training loss: 2.8846667769328973
Validation loss: 3.0474269201936104

Epoch: 6| Step: 1
Training loss: 3.4844514983807526
Validation loss: 3.0456294363798664

Epoch: 6| Step: 2
Training loss: 3.341790596684634
Validation loss: 3.0465337544847046

Epoch: 6| Step: 3
Training loss: 3.816702605721014
Validation loss: 3.046787205375955

Epoch: 6| Step: 4
Training loss: 2.8925837298434893
Validation loss: 3.039729275204112

Epoch: 6| Step: 5
Training loss: 3.7175113955376315
Validation loss: 3.037126782093112

Epoch: 6| Step: 6
Training loss: 3.2055671128259884
Validation loss: 3.0333367148804995

Epoch: 6| Step: 7
Training loss: 3.2258101872453286
Validation loss: 3.036428387470901

Epoch: 6| Step: 8
Training loss: 3.8153876953313715
Validation loss: 3.033086086396218

Epoch: 6| Step: 9
Training loss: 2.5404569112768276
Validation loss: 3.0332700821039027

Epoch: 6| Step: 10
Training loss: 2.7179394971781554
Validation loss: 3.033946951980168

Epoch: 6| Step: 11
Training loss: 3.3702377346413543
Validation loss: 3.0334332402231214

Epoch: 6| Step: 12
Training loss: 3.3908171006029226
Validation loss: 3.0330414383170083

Epoch: 6| Step: 13
Training loss: 3.7840207879945122
Validation loss: 3.0318258060223156

Epoch: 38| Step: 0
Training loss: 3.190365569115804
Validation loss: 3.0322733484667146

Epoch: 6| Step: 1
Training loss: 3.6637446869597214
Validation loss: 3.032003440373964

Epoch: 6| Step: 2
Training loss: 3.3833782612741223
Validation loss: 3.0289052426584733

Epoch: 6| Step: 3
Training loss: 3.134482682908477
Validation loss: 3.0290845657716456

Epoch: 6| Step: 4
Training loss: 3.3356327391161744
Validation loss: 3.026185004335743

Epoch: 6| Step: 5
Training loss: 2.687860509068679
Validation loss: 3.0275566605753275

Epoch: 6| Step: 6
Training loss: 4.026746022871922
Validation loss: 3.0255046303905493

Epoch: 6| Step: 7
Training loss: 3.7599495186359126
Validation loss: 3.0252342005998396

Epoch: 6| Step: 8
Training loss: 3.294689448400466
Validation loss: 3.0242236983460997

Epoch: 6| Step: 9
Training loss: 3.186199745808544
Validation loss: 3.0242247003297598

Epoch: 6| Step: 10
Training loss: 3.008370642461516
Validation loss: 3.0218203778228543

Epoch: 6| Step: 11
Training loss: 3.153713302247596
Validation loss: 3.0252641262028273

Epoch: 6| Step: 12
Training loss: 3.050169430388605
Validation loss: 3.0220892383530886

Epoch: 6| Step: 13
Training loss: 2.8390322946590776
Validation loss: 3.0243481231891414

Epoch: 39| Step: 0
Training loss: 3.1991621112584037
Validation loss: 3.0265647836039236

Epoch: 6| Step: 1
Training loss: 3.3861966374143613
Validation loss: 3.028954641068117

Epoch: 6| Step: 2
Training loss: 3.243809305872682
Validation loss: 3.0306995874451457

Epoch: 6| Step: 3
Training loss: 3.3875183780636156
Validation loss: 3.0256606400370734

Epoch: 6| Step: 4
Training loss: 3.2028546475084387
Validation loss: 3.026187316214432

Epoch: 6| Step: 5
Training loss: 3.747295803337057
Validation loss: 3.0216371577820946

Epoch: 6| Step: 6
Training loss: 3.6534141563144185
Validation loss: 3.0164042766698755

Epoch: 6| Step: 7
Training loss: 3.0630610983518314
Validation loss: 3.0136432685292123

Epoch: 6| Step: 8
Training loss: 3.138116698429787
Validation loss: 3.011822711328194

Epoch: 6| Step: 9
Training loss: 3.9678995017122696
Validation loss: 3.014334759949968

Epoch: 6| Step: 10
Training loss: 2.3061633540885533
Validation loss: 3.012872563565314

Epoch: 6| Step: 11
Training loss: 3.0990592021180268
Validation loss: 3.013349059021506

Epoch: 6| Step: 12
Training loss: 3.3921710589839367
Validation loss: 3.0105754647048975

Epoch: 6| Step: 13
Training loss: 2.6645629054865494
Validation loss: 3.01315893680856

Epoch: 40| Step: 0
Training loss: 3.2187295561206035
Validation loss: 3.012748793973264

Epoch: 6| Step: 1
Training loss: 3.2242840349202795
Validation loss: 3.015847881109443

Epoch: 6| Step: 2
Training loss: 2.6794961132513246
Validation loss: 3.00970495762465

Epoch: 6| Step: 3
Training loss: 3.827828158333261
Validation loss: 3.009673996553573

Epoch: 6| Step: 4
Training loss: 2.4473518423372744
Validation loss: 3.007170064711836

Epoch: 6| Step: 5
Training loss: 2.7614328109576727
Validation loss: 3.007281686806124

Epoch: 6| Step: 6
Training loss: 3.538312483043454
Validation loss: 3.006213250356758

Epoch: 6| Step: 7
Training loss: 3.060780723805806
Validation loss: 3.0037693984787275

Epoch: 6| Step: 8
Training loss: 3.0227087754304836
Validation loss: 3.0001485695505714

Epoch: 6| Step: 9
Training loss: 3.2874711416160003
Validation loss: 3.0017422253942248

Epoch: 6| Step: 10
Training loss: 4.324849896775456
Validation loss: 3.0006055912857477

Epoch: 6| Step: 11
Training loss: 3.4053153059245003
Validation loss: 2.9986133823294567

Epoch: 6| Step: 12
Training loss: 3.4034458482048158
Validation loss: 2.996528727930775

Epoch: 6| Step: 13
Training loss: 3.1846661405583547
Validation loss: 2.994894853965904

Epoch: 41| Step: 0
Training loss: 3.9909391298978494
Validation loss: 2.9952270761982587

Epoch: 6| Step: 1
Training loss: 3.1553376644944895
Validation loss: 2.993686928886339

Epoch: 6| Step: 2
Training loss: 2.575946326573299
Validation loss: 2.990368547053208

Epoch: 6| Step: 3
Training loss: 3.6081395532554725
Validation loss: 2.9926939123726033

Epoch: 6| Step: 4
Training loss: 3.741473868542232
Validation loss: 2.9927611196237227

Epoch: 6| Step: 5
Training loss: 3.1810024082686787
Validation loss: 2.996743799600512

Epoch: 6| Step: 6
Training loss: 3.1707797860943128
Validation loss: 3.0296560515018847

Epoch: 6| Step: 7
Training loss: 3.335560690260065
Validation loss: 2.998301257524899

Epoch: 6| Step: 8
Training loss: 2.0954266567552136
Validation loss: 2.989831087018778

Epoch: 6| Step: 9
Training loss: 3.2859788515660675
Validation loss: 2.989642170361427

Epoch: 6| Step: 10
Training loss: 3.2021804533413976
Validation loss: 2.98724184586068

Epoch: 6| Step: 11
Training loss: 2.7990270252456333
Validation loss: 2.987576935654013

Epoch: 6| Step: 12
Training loss: 3.3743097517810003
Validation loss: 2.986740428192075

Epoch: 6| Step: 13
Training loss: 4.048558890062452
Validation loss: 2.9878167650589065

Epoch: 42| Step: 0
Training loss: 3.429065413310841
Validation loss: 2.9875394132669926

Epoch: 6| Step: 1
Training loss: 2.2968226835559737
Validation loss: 2.98691452120486

Epoch: 6| Step: 2
Training loss: 3.4088365725808054
Validation loss: 2.984553311959061

Epoch: 6| Step: 3
Training loss: 3.146497862566142
Validation loss: 2.984559876197707

Epoch: 6| Step: 4
Training loss: 3.4241743331629015
Validation loss: 2.983776892260206

Epoch: 6| Step: 5
Training loss: 3.169740155758717
Validation loss: 2.983664349583574

Epoch: 6| Step: 6
Training loss: 3.5483834844162527
Validation loss: 2.9800467992068427

Epoch: 6| Step: 7
Training loss: 3.020829685252826
Validation loss: 2.9808783951433107

Epoch: 6| Step: 8
Training loss: 3.0098518096842852
Validation loss: 2.981150214565735

Epoch: 6| Step: 9
Training loss: 3.0077833298098504
Validation loss: 2.9778599175440763

Epoch: 6| Step: 10
Training loss: 3.520837065263986
Validation loss: 2.9761903763989315

Epoch: 6| Step: 11
Training loss: 3.6446435058576085
Validation loss: 2.9792995278400314

Epoch: 6| Step: 12
Training loss: 3.389450080626658
Validation loss: 2.9779232972140273

Epoch: 6| Step: 13
Training loss: 3.3899273835903365
Validation loss: 2.9809066667289974

Epoch: 43| Step: 0
Training loss: 3.699748757569982
Validation loss: 2.989603681746264

Epoch: 6| Step: 1
Training loss: 3.204038610656729
Validation loss: 2.998790100480904

Epoch: 6| Step: 2
Training loss: 2.781126298189407
Validation loss: 2.9909306184724946

Epoch: 6| Step: 3
Training loss: 3.304176092595385
Validation loss: 2.983182762055326

Epoch: 6| Step: 4
Training loss: 2.815508272077914
Validation loss: 2.978530968852323

Epoch: 6| Step: 5
Training loss: 3.5993301192206455
Validation loss: 2.9782515162244225

Epoch: 6| Step: 6
Training loss: 3.9799780426186477
Validation loss: 2.9683449434846514

Epoch: 6| Step: 7
Training loss: 2.9242072767378615
Validation loss: 2.9697571821084545

Epoch: 6| Step: 8
Training loss: 3.109579568392339
Validation loss: 2.9684782135866166

Epoch: 6| Step: 9
Training loss: 2.7678229439727766
Validation loss: 2.9698776719933355

Epoch: 6| Step: 10
Training loss: 3.240699665677169
Validation loss: 2.9678731386524704

Epoch: 6| Step: 11
Training loss: 3.204470319377447
Validation loss: 2.9715089146807325

Epoch: 6| Step: 12
Training loss: 3.397621775978748
Validation loss: 2.970713633420226

Epoch: 6| Step: 13
Training loss: 3.1968013214242244
Validation loss: 2.972163502036427

Epoch: 44| Step: 0
Training loss: 3.3226120828132264
Validation loss: 2.9710508177349646

Epoch: 6| Step: 1
Training loss: 2.6533005439546975
Validation loss: 2.9689335591983763

Epoch: 6| Step: 2
Training loss: 3.1743109608691373
Validation loss: 2.968751658000386

Epoch: 6| Step: 3
Training loss: 3.4470398739820616
Validation loss: 2.9656011084889777

Epoch: 6| Step: 4
Training loss: 3.2789574743400185
Validation loss: 2.964001478884465

Epoch: 6| Step: 5
Training loss: 2.699831240289604
Validation loss: 2.9646107891798215

Epoch: 6| Step: 6
Training loss: 3.4781834627432304
Validation loss: 2.9666260578832313

Epoch: 6| Step: 7
Training loss: 4.02316609180154
Validation loss: 2.9575796919302433

Epoch: 6| Step: 8
Training loss: 2.9761020574605466
Validation loss: 2.9599698479875762

Epoch: 6| Step: 9
Training loss: 3.1686724952383574
Validation loss: 2.9562732023287595

Epoch: 6| Step: 10
Training loss: 3.178407453590562
Validation loss: 2.956853276806121

Epoch: 6| Step: 11
Training loss: 2.621241376332372
Validation loss: 2.9597050864543846

Epoch: 6| Step: 12
Training loss: 3.498925725374783
Validation loss: 2.9552342801991416

Epoch: 6| Step: 13
Training loss: 3.863966214792466
Validation loss: 2.9557628761759154

Epoch: 45| Step: 0
Training loss: 3.252289185901289
Validation loss: 2.9554967289679013

Epoch: 6| Step: 1
Training loss: 4.0827530948187345
Validation loss: 2.9553081088765127

Epoch: 6| Step: 2
Training loss: 3.1263583473609167
Validation loss: 2.958080330035698

Epoch: 6| Step: 3
Training loss: 2.9150653984886548
Validation loss: 2.9526380949333397

Epoch: 6| Step: 4
Training loss: 2.7384891621540794
Validation loss: 2.9505952633220707

Epoch: 6| Step: 5
Training loss: 3.4144080225077142
Validation loss: 2.952956954950304

Epoch: 6| Step: 6
Training loss: 3.656870732230782
Validation loss: 2.954293425243286

Epoch: 6| Step: 7
Training loss: 2.9962283903702573
Validation loss: 2.9577714564684183

Epoch: 6| Step: 8
Training loss: 2.6957587273566204
Validation loss: 2.9536202861742216

Epoch: 6| Step: 9
Training loss: 3.5621618813126332
Validation loss: 2.9525655275202873

Epoch: 6| Step: 10
Training loss: 3.2664717895093105
Validation loss: 2.951494066816149

Epoch: 6| Step: 11
Training loss: 2.707981399753989
Validation loss: 2.9512769823536122

Epoch: 6| Step: 12
Training loss: 2.90129109285731
Validation loss: 2.9512841834923287

Epoch: 6| Step: 13
Training loss: 4.016073120287418
Validation loss: 2.951719030212457

Epoch: 46| Step: 0
Training loss: 2.6203863380324046
Validation loss: 2.9503347359540246

Epoch: 6| Step: 1
Training loss: 3.0552801547543305
Validation loss: 2.951503117518559

Epoch: 6| Step: 2
Training loss: 3.0884733573131253
Validation loss: 2.9506434644195343

Epoch: 6| Step: 3
Training loss: 3.107845064187268
Validation loss: 2.9529597278536923

Epoch: 6| Step: 4
Training loss: 3.6716659161715115
Validation loss: 2.9540897895743146

Epoch: 6| Step: 5
Training loss: 3.7869119420557915
Validation loss: 2.952991385995662

Epoch: 6| Step: 6
Training loss: 2.57658775044243
Validation loss: 2.9592760072643016

Epoch: 6| Step: 7
Training loss: 3.1551351561214545
Validation loss: 2.964734488770828

Epoch: 6| Step: 8
Training loss: 3.0367264190333603
Validation loss: 2.955736332094543

Epoch: 6| Step: 9
Training loss: 3.4811156214421595
Validation loss: 2.948601584920442

Epoch: 6| Step: 10
Training loss: 3.7883822430195813
Validation loss: 2.94319159463299

Epoch: 6| Step: 11
Training loss: 3.154411460283297
Validation loss: 2.9424991174293114

Epoch: 6| Step: 12
Training loss: 3.2720982399814718
Validation loss: 2.9384935034656

Epoch: 6| Step: 13
Training loss: 3.1336195517414285
Validation loss: 2.9400847039693496

Epoch: 47| Step: 0
Training loss: 3.7148214153015497
Validation loss: 2.939511045578165

Epoch: 6| Step: 1
Training loss: 3.1006131580990166
Validation loss: 2.9391148565627385

Epoch: 6| Step: 2
Training loss: 4.2485934903351446
Validation loss: 2.9382220087628146

Epoch: 6| Step: 3
Training loss: 2.4875901249033374
Validation loss: 2.9387305533224812

Epoch: 6| Step: 4
Training loss: 3.8883968238754023
Validation loss: 2.93635195236283

Epoch: 6| Step: 5
Training loss: 2.5166689205370107
Validation loss: 2.9352857805617583

Epoch: 6| Step: 6
Training loss: 3.3880985533556984
Validation loss: 2.934430133042558

Epoch: 6| Step: 7
Training loss: 3.0185913360157963
Validation loss: 2.9333517281896144

Epoch: 6| Step: 8
Training loss: 3.1504938495371926
Validation loss: 2.9312716336274867

Epoch: 6| Step: 9
Training loss: 3.4061979237346582
Validation loss: 2.9324516145372703

Epoch: 6| Step: 10
Training loss: 2.6592562549227377
Validation loss: 2.931884347989573

Epoch: 6| Step: 11
Training loss: 2.9403977406621395
Validation loss: 2.9320109820310836

Epoch: 6| Step: 12
Training loss: 3.2273735892717785
Validation loss: 2.9303849643711155

Epoch: 6| Step: 13
Training loss: 2.501435058702359
Validation loss: 2.931227406500997

Epoch: 48| Step: 0
Training loss: 3.2594843172227708
Validation loss: 2.9345822074135417

Epoch: 6| Step: 1
Training loss: 2.1637026491058236
Validation loss: 2.933881997463278

Epoch: 6| Step: 2
Training loss: 3.521224923713182
Validation loss: 2.9371819447241916

Epoch: 6| Step: 3
Training loss: 3.957926250740257
Validation loss: 2.944699794649087

Epoch: 6| Step: 4
Training loss: 3.179549530560132
Validation loss: 2.950536561129417

Epoch: 6| Step: 5
Training loss: 3.397478060283095
Validation loss: 2.959142312328909

Epoch: 6| Step: 6
Training loss: 3.134512195265877
Validation loss: 2.9630229862333444

Epoch: 6| Step: 7
Training loss: 2.225077887039812
Validation loss: 2.9676914367953815

Epoch: 6| Step: 8
Training loss: 3.3659186926647355
Validation loss: 2.9799792062774872

Epoch: 6| Step: 9
Training loss: 3.7921278676553665
Validation loss: 2.9777027104084253

Epoch: 6| Step: 10
Training loss: 3.9623798099424725
Validation loss: 2.934697125030924

Epoch: 6| Step: 11
Training loss: 3.005161930741914
Validation loss: 2.9238238628253166

Epoch: 6| Step: 12
Training loss: 2.5903572965750645
Validation loss: 2.9227763517406298

Epoch: 6| Step: 13
Training loss: 2.729441873977244
Validation loss: 2.9225080321048145

Epoch: 49| Step: 0
Training loss: 3.6714956534015912
Validation loss: 2.9349800564593083

Epoch: 6| Step: 1
Training loss: 2.8421582808206347
Validation loss: 2.935037822487721

Epoch: 6| Step: 2
Training loss: 3.8446748442752767
Validation loss: 2.9396419382877492

Epoch: 6| Step: 3
Training loss: 3.344086389466098
Validation loss: 2.9257030476883137

Epoch: 6| Step: 4
Training loss: 3.012190528264182
Validation loss: 2.9209759408051577

Epoch: 6| Step: 5
Training loss: 3.6362539090594184
Validation loss: 2.9167325383027207

Epoch: 6| Step: 6
Training loss: 3.1000542420594734
Validation loss: 2.91819940863317

Epoch: 6| Step: 7
Training loss: 3.1257719993692783
Validation loss: 2.9170928631969795

Epoch: 6| Step: 8
Training loss: 2.6995649764381886
Validation loss: 2.9186312415460844

Epoch: 6| Step: 9
Training loss: 3.6376797136829984
Validation loss: 2.918846536357275

Epoch: 6| Step: 10
Training loss: 3.339732385752976
Validation loss: 2.9188250880441986

Epoch: 6| Step: 11
Training loss: 2.174595727290118
Validation loss: 2.9195070602094213

Epoch: 6| Step: 12
Training loss: 3.218173966204719
Validation loss: 2.927589645682634

Epoch: 6| Step: 13
Training loss: 2.5882108439856295
Validation loss: 2.9447051157203337

Epoch: 50| Step: 0
Training loss: 3.395668462639794
Validation loss: 3.0032208749458285

Epoch: 6| Step: 1
Training loss: 3.961898295930854
Validation loss: 3.008243081966613

Epoch: 6| Step: 2
Training loss: 3.633343795154687
Validation loss: 2.932449948252168

Epoch: 6| Step: 3
Training loss: 3.131991690321382
Validation loss: 2.9162754734057037

Epoch: 6| Step: 4
Training loss: 3.6666875029463166
Validation loss: 2.9130994003653803

Epoch: 6| Step: 5
Training loss: 2.9488054604871494
Validation loss: 2.915427684584229

Epoch: 6| Step: 6
Training loss: 2.8699279494329684
Validation loss: 2.9211137600446864

Epoch: 6| Step: 7
Training loss: 3.4752504766195114
Validation loss: 2.932592774996835

Epoch: 6| Step: 8
Training loss: 3.04029268211064
Validation loss: 2.927142568342217

Epoch: 6| Step: 9
Training loss: 3.1501826520976763
Validation loss: 2.927515838681923

Epoch: 6| Step: 10
Training loss: 2.4459406134382236
Validation loss: 2.9175644004248684

Epoch: 6| Step: 11
Training loss: 2.9036078799836464
Validation loss: 2.9116330678901816

Epoch: 6| Step: 12
Training loss: 3.050771871984626
Validation loss: 2.914915042000004

Epoch: 6| Step: 13
Training loss: 3.01755663422768
Validation loss: 2.9132340361572995

Epoch: 51| Step: 0
Training loss: 2.971468353529176
Validation loss: 2.9088864099906724

Epoch: 6| Step: 1
Training loss: 3.5112146815652077
Validation loss: 2.9068321027025577

Epoch: 6| Step: 2
Training loss: 3.400522018076396
Validation loss: 2.90908392413044

Epoch: 6| Step: 3
Training loss: 2.4541665557015033
Validation loss: 2.9081298988158055

Epoch: 6| Step: 4
Training loss: 3.3065641949783307
Validation loss: 2.905221835503943

Epoch: 6| Step: 5
Training loss: 3.100940863051893
Validation loss: 2.9043663290181376

Epoch: 6| Step: 6
Training loss: 3.287358148219559
Validation loss: 2.905192472660737

Epoch: 6| Step: 7
Training loss: 2.943390155674322
Validation loss: 2.902517359216382

Epoch: 6| Step: 8
Training loss: 3.5902249504316783
Validation loss: 2.904271001002859

Epoch: 6| Step: 9
Training loss: 2.7616151523178822
Validation loss: 2.9029250640355104

Epoch: 6| Step: 10
Training loss: 3.51031527198282
Validation loss: 2.925164494824848

Epoch: 6| Step: 11
Training loss: 3.004818384709041
Validation loss: 2.968307809329311

Epoch: 6| Step: 12
Training loss: 2.5051250377826526
Validation loss: 2.9895510442212823

Epoch: 6| Step: 13
Training loss: 4.52090304038221
Validation loss: 2.955226870944903

Epoch: 52| Step: 0
Training loss: 3.093209267572766
Validation loss: 2.917468607360066

Epoch: 6| Step: 1
Training loss: 3.4166046385058038
Validation loss: 2.9049826390422213

Epoch: 6| Step: 2
Training loss: 3.5076231363750434
Validation loss: 2.9023054463200504

Epoch: 6| Step: 3
Training loss: 3.5751519657728035
Validation loss: 2.897132934849464

Epoch: 6| Step: 4
Training loss: 3.1943236968582345
Validation loss: 2.898013049659626

Epoch: 6| Step: 5
Training loss: 2.8521851578325954
Validation loss: 2.8950843140396714

Epoch: 6| Step: 6
Training loss: 3.278944095359536
Validation loss: 2.8978974752755753

Epoch: 6| Step: 7
Training loss: 2.8251623157693286
Validation loss: 2.89601736191471

Epoch: 6| Step: 8
Training loss: 3.275479428674663
Validation loss: 2.8956538292512786

Epoch: 6| Step: 9
Training loss: 3.4953686180606254
Validation loss: 2.896096356966994

Epoch: 6| Step: 10
Training loss: 2.191133369958636
Validation loss: 2.893089457570165

Epoch: 6| Step: 11
Training loss: 3.198245169368839
Validation loss: 2.892581945760236

Epoch: 6| Step: 12
Training loss: 2.9194306129380374
Validation loss: 2.8936168810752894

Epoch: 6| Step: 13
Training loss: 3.655625770948345
Validation loss: 2.8911450699489407

Epoch: 53| Step: 0
Training loss: 3.215059108635716
Validation loss: 2.8895363843913895

Epoch: 6| Step: 1
Training loss: 3.3099410051234237
Validation loss: 2.888866235616869

Epoch: 6| Step: 2
Training loss: 3.7519228773670124
Validation loss: 2.8924471348358898

Epoch: 6| Step: 3
Training loss: 2.8293646524525347
Validation loss: 2.8934330873044054

Epoch: 6| Step: 4
Training loss: 3.466431538848761
Validation loss: 2.905149271017829

Epoch: 6| Step: 5
Training loss: 3.324111309175518
Validation loss: 2.9290169501016416

Epoch: 6| Step: 6
Training loss: 2.40749614204264
Validation loss: 2.9460168486292

Epoch: 6| Step: 7
Training loss: 3.131376094144706
Validation loss: 2.9648097125471833

Epoch: 6| Step: 8
Training loss: 2.816002423968139
Validation loss: 2.9540006250181454

Epoch: 6| Step: 9
Training loss: 3.6336377590863145
Validation loss: 2.946305573951305

Epoch: 6| Step: 10
Training loss: 3.6936943914936258
Validation loss: 2.8922351577526855

Epoch: 6| Step: 11
Training loss: 3.1267356630153547
Validation loss: 2.888642621711928

Epoch: 6| Step: 12
Training loss: 2.554007996883434
Validation loss: 2.888627569847038

Epoch: 6| Step: 13
Training loss: 3.3374290258740458
Validation loss: 2.891762944211846

Epoch: 54| Step: 0
Training loss: 3.8601556521247136
Validation loss: 2.9079259529354164

Epoch: 6| Step: 1
Training loss: 3.197409540944352
Validation loss: 2.941290838830727

Epoch: 6| Step: 2
Training loss: 3.7925236889697187
Validation loss: 2.99416164168227

Epoch: 6| Step: 3
Training loss: 3.0759303600627983
Validation loss: 2.9374297654433263

Epoch: 6| Step: 4
Training loss: 3.1165079317792173
Validation loss: 2.9085357662439506

Epoch: 6| Step: 5
Training loss: 3.1586888021829003
Validation loss: 2.8854531095969596

Epoch: 6| Step: 6
Training loss: 3.0766943690691186
Validation loss: 2.880830467750677

Epoch: 6| Step: 7
Training loss: 2.827812219679388
Validation loss: 2.8811370492205755

Epoch: 6| Step: 8
Training loss: 3.1500797201089994
Validation loss: 2.8812956947157473

Epoch: 6| Step: 9
Training loss: 2.8514599925389614
Validation loss: 2.8794958906885673

Epoch: 6| Step: 10
Training loss: 2.920621062295889
Validation loss: 2.878419974030311

Epoch: 6| Step: 11
Training loss: 2.7781970809665246
Validation loss: 2.8839333995682837

Epoch: 6| Step: 12
Training loss: 3.0270104403207045
Validation loss: 2.881741285784314

Epoch: 6| Step: 13
Training loss: 3.906533192859631
Validation loss: 2.885187654316633

Epoch: 55| Step: 0
Training loss: 2.4369160857531975
Validation loss: 2.8810566046853117

Epoch: 6| Step: 1
Training loss: 3.355131512038497
Validation loss: 2.8780327433194106

Epoch: 6| Step: 2
Training loss: 3.31673578033769
Validation loss: 2.8755021479343963

Epoch: 6| Step: 3
Training loss: 2.856863784784716
Validation loss: 2.877448969022569

Epoch: 6| Step: 4
Training loss: 3.1327284804038786
Validation loss: 2.8744881982721306

Epoch: 6| Step: 5
Training loss: 3.725781116897539
Validation loss: 2.8733730554710335

Epoch: 6| Step: 6
Training loss: 3.2319238192578625
Validation loss: 2.8715858214705183

Epoch: 6| Step: 7
Training loss: 3.103339390105153
Validation loss: 2.8742345706788246

Epoch: 6| Step: 8
Training loss: 2.272803988462424
Validation loss: 2.873983489711602

Epoch: 6| Step: 9
Training loss: 3.2707820491455397
Validation loss: 2.8735522583769093

Epoch: 6| Step: 10
Training loss: 3.04194845348779
Validation loss: 2.8754288922841433

Epoch: 6| Step: 11
Training loss: 2.736866540645289
Validation loss: 2.8834577762490174

Epoch: 6| Step: 12
Training loss: 3.943211122383441
Validation loss: 2.88014349439532

Epoch: 6| Step: 13
Training loss: 3.850850439891505
Validation loss: 2.921852556131142

Epoch: 56| Step: 0
Training loss: 3.2379388754755576
Validation loss: 2.9266572616699422

Epoch: 6| Step: 1
Training loss: 3.241386149085059
Validation loss: 2.944182482635437

Epoch: 6| Step: 2
Training loss: 3.57260332132986
Validation loss: 2.950999686926959

Epoch: 6| Step: 3
Training loss: 3.5611489394293563
Validation loss: 2.9425841228040714

Epoch: 6| Step: 4
Training loss: 2.9164172111282767
Validation loss: 2.927364015498266

Epoch: 6| Step: 5
Training loss: 3.7925981208917716
Validation loss: 2.925144884230213

Epoch: 6| Step: 6
Training loss: 2.5549002742527844
Validation loss: 2.9159657217643415

Epoch: 6| Step: 7
Training loss: 3.087385933811462
Validation loss: 2.9126300959283995

Epoch: 6| Step: 8
Training loss: 2.9681379791637874
Validation loss: 2.9104203175881307

Epoch: 6| Step: 9
Training loss: 2.750608030204892
Validation loss: 2.9095118056097937

Epoch: 6| Step: 10
Training loss: 3.787082555950358
Validation loss: 2.908262851807292

Epoch: 6| Step: 11
Training loss: 3.0422732301455686
Validation loss: 2.9081316345728316

Epoch: 6| Step: 12
Training loss: 3.223548053689189
Validation loss: 2.9062711009462423

Epoch: 6| Step: 13
Training loss: 2.4805049863556423
Validation loss: 2.905764445376762

Epoch: 57| Step: 0
Training loss: 2.281302987097332
Validation loss: 2.9045887482984183

Epoch: 6| Step: 1
Training loss: 2.8494929080037505
Validation loss: 2.9042600006003165

Epoch: 6| Step: 2
Training loss: 3.3466984948953593
Validation loss: 2.9054321097929274

Epoch: 6| Step: 3
Training loss: 3.2940708185121106
Validation loss: 2.902954740357728

Epoch: 6| Step: 4
Training loss: 3.2688614718683975
Validation loss: 2.9036333590496652

Epoch: 6| Step: 5
Training loss: 2.7023804802451052
Validation loss: 2.900034816011029

Epoch: 6| Step: 6
Training loss: 2.8132752091910462
Validation loss: 2.900952244324851

Epoch: 6| Step: 7
Training loss: 3.4039437422177095
Validation loss: 2.906500483689932

Epoch: 6| Step: 8
Training loss: 3.077398224053354
Validation loss: 2.91037095791868

Epoch: 6| Step: 9
Training loss: 3.942786890790133
Validation loss: 2.9096046120378207

Epoch: 6| Step: 10
Training loss: 2.9815220802637197
Validation loss: 2.9066277967518146

Epoch: 6| Step: 11
Training loss: 3.109117660224854
Validation loss: 2.8998747061995642

Epoch: 6| Step: 12
Training loss: 3.487993081077223
Validation loss: 2.900811738553779

Epoch: 6| Step: 13
Training loss: 4.118144494151101
Validation loss: 2.9022491417134146

Epoch: 58| Step: 0
Training loss: 3.0593455670726524
Validation loss: 2.904245679359033

Epoch: 6| Step: 1
Training loss: 3.325805285463051
Validation loss: 2.9064195142220908

Epoch: 6| Step: 2
Training loss: 3.3175432213021008
Validation loss: 2.908890520433567

Epoch: 6| Step: 3
Training loss: 3.2328580533224978
Validation loss: 2.9095296976584124

Epoch: 6| Step: 4
Training loss: 3.491609324953264
Validation loss: 2.9003442775978243

Epoch: 6| Step: 5
Training loss: 3.0907640015111326
Validation loss: 2.8968909288781655

Epoch: 6| Step: 6
Training loss: 2.9309429276271013
Validation loss: 2.89266146269158

Epoch: 6| Step: 7
Training loss: 3.742564140590719
Validation loss: 2.8954188723896754

Epoch: 6| Step: 8
Training loss: 2.948458905892834
Validation loss: 2.892603183635663

Epoch: 6| Step: 9
Training loss: 2.713525246090302
Validation loss: 2.893449664697916

Epoch: 6| Step: 10
Training loss: 2.9758537029280303
Validation loss: 2.8928979258149226

Epoch: 6| Step: 11
Training loss: 3.006682423918965
Validation loss: 2.8935902719075814

Epoch: 6| Step: 12
Training loss: 2.7710378662187325
Validation loss: 2.8918488691711874

Epoch: 6| Step: 13
Training loss: 4.203175597613085
Validation loss: 2.8924070648097526

Epoch: 59| Step: 0
Training loss: 3.3773617428281124
Validation loss: 2.891979179033692

Epoch: 6| Step: 1
Training loss: 3.4173397858799763
Validation loss: 2.88596135361065

Epoch: 6| Step: 2
Training loss: 2.7581489509045696
Validation loss: 2.890683721573932

Epoch: 6| Step: 3
Training loss: 3.15803824650783
Validation loss: 2.88687259264633

Epoch: 6| Step: 4
Training loss: 2.8549418452497943
Validation loss: 2.886385479181861

Epoch: 6| Step: 5
Training loss: 3.234416869256475
Validation loss: 2.8841084263300045

Epoch: 6| Step: 6
Training loss: 2.9038916422487038
Validation loss: 2.88664755165262

Epoch: 6| Step: 7
Training loss: 3.0724195864950667
Validation loss: 2.8848773693240033

Epoch: 6| Step: 8
Training loss: 3.0817590939030266
Validation loss: 2.897679549918015

Epoch: 6| Step: 9
Training loss: 2.4368828212224107
Validation loss: 2.8937046805561213

Epoch: 6| Step: 10
Training loss: 3.377546974154774
Validation loss: 2.90238118225187

Epoch: 6| Step: 11
Training loss: 3.896421840232838
Validation loss: 2.9188484818045755

Epoch: 6| Step: 12
Training loss: 3.3124116130049006
Validation loss: 2.8891566277771354

Epoch: 6| Step: 13
Training loss: 3.46890519628358
Validation loss: 2.8855243249781006

Epoch: 60| Step: 0
Training loss: 3.1478446610549
Validation loss: 2.880103599449353

Epoch: 6| Step: 1
Training loss: 3.122677970316316
Validation loss: 2.87844650345006

Epoch: 6| Step: 2
Training loss: 3.148790666257779
Validation loss: 2.8797801949995554

Epoch: 6| Step: 3
Training loss: 2.9982860755553564
Validation loss: 2.8868151123058983

Epoch: 6| Step: 4
Training loss: 3.6168568668072427
Validation loss: 2.880758613060393

Epoch: 6| Step: 5
Training loss: 2.788864000453393
Validation loss: 2.865755031648273

Epoch: 6| Step: 6
Training loss: 3.0568548060444116
Validation loss: 2.8347988542882745

Epoch: 6| Step: 7
Training loss: 3.0345767927398306
Validation loss: 2.8320464886066894

Epoch: 6| Step: 8
Training loss: 3.0827091375656988
Validation loss: 2.829469950081372

Epoch: 6| Step: 9
Training loss: 2.8613602880551556
Validation loss: 2.8270529545824963

Epoch: 6| Step: 10
Training loss: 3.6153882950671963
Validation loss: 2.827580059250517

Epoch: 6| Step: 11
Training loss: 2.7133968751513846
Validation loss: 2.8268065936610056

Epoch: 6| Step: 12
Training loss: 3.336331703783498
Validation loss: 2.8259704483139796

Epoch: 6| Step: 13
Training loss: 3.7802502279867465
Validation loss: 2.8252587241599225

Epoch: 61| Step: 0
Training loss: 3.4634708406860057
Validation loss: 2.834088832508415

Epoch: 6| Step: 1
Training loss: 2.8813790579996423
Validation loss: 2.8320981212920384

Epoch: 6| Step: 2
Training loss: 2.966504341856574
Validation loss: 2.8298677432091592

Epoch: 6| Step: 3
Training loss: 3.614766771277226
Validation loss: 2.832503948090353

Epoch: 6| Step: 4
Training loss: 2.8728818969245427
Validation loss: 2.837979351762329

Epoch: 6| Step: 5
Training loss: 3.5873855625734663
Validation loss: 2.8390939046447596

Epoch: 6| Step: 6
Training loss: 3.5836214053257613
Validation loss: 2.8421495890883324

Epoch: 6| Step: 7
Training loss: 2.8355314105881684
Validation loss: 2.847545070253874

Epoch: 6| Step: 8
Training loss: 2.6454978990562688
Validation loss: 2.8593957923667994

Epoch: 6| Step: 9
Training loss: 2.710599762823488
Validation loss: 2.879121277780841

Epoch: 6| Step: 10
Training loss: 3.440959091666162
Validation loss: 2.8858736596707946

Epoch: 6| Step: 11
Training loss: 3.3153684180642062
Validation loss: 2.8511666511302662

Epoch: 6| Step: 12
Training loss: 3.03973396944214
Validation loss: 2.8311956199264823

Epoch: 6| Step: 13
Training loss: 2.2146770004124767
Validation loss: 2.8231023827183215

Epoch: 62| Step: 0
Training loss: 3.2844469753984615
Validation loss: 2.818245209716002

Epoch: 6| Step: 1
Training loss: 3.2769619488571746
Validation loss: 2.818849163686277

Epoch: 6| Step: 2
Training loss: 3.3301079085911507
Validation loss: 2.818752833477452

Epoch: 6| Step: 3
Training loss: 3.172552928918916
Validation loss: 2.819676404961457

Epoch: 6| Step: 4
Training loss: 3.3937950960257743
Validation loss: 2.8195947888244146

Epoch: 6| Step: 5
Training loss: 3.212669480896136
Validation loss: 2.8194355102647526

Epoch: 6| Step: 6
Training loss: 3.3175261171487205
Validation loss: 2.81811889898708

Epoch: 6| Step: 7
Training loss: 3.153971387763615
Validation loss: 2.819825754756977

Epoch: 6| Step: 8
Training loss: 2.464124668379654
Validation loss: 2.819174410931731

Epoch: 6| Step: 9
Training loss: 2.7189264349853794
Validation loss: 2.819196259097988

Epoch: 6| Step: 10
Training loss: 2.8759926450632674
Validation loss: 2.8197300797901708

Epoch: 6| Step: 11
Training loss: 3.0335421989829405
Validation loss: 2.818912008737629

Epoch: 6| Step: 12
Training loss: 2.77056426460375
Validation loss: 2.8163931660011663

Epoch: 6| Step: 13
Training loss: 3.893338034988421
Validation loss: 2.8135177384282066

Epoch: 63| Step: 0
Training loss: 3.1164435165674935
Validation loss: 2.8119761682165456

Epoch: 6| Step: 1
Training loss: 2.731199502369009
Validation loss: 2.813809912664333

Epoch: 6| Step: 2
Training loss: 2.6937875165340377
Validation loss: 2.81196558716343

Epoch: 6| Step: 3
Training loss: 3.405456870597183
Validation loss: 2.809364788180082

Epoch: 6| Step: 4
Training loss: 3.3630912629629273
Validation loss: 2.810445664650281

Epoch: 6| Step: 5
Training loss: 3.2891416562810134
Validation loss: 2.810064281532241

Epoch: 6| Step: 6
Training loss: 2.9869793617804987
Validation loss: 2.8096601233818816

Epoch: 6| Step: 7
Training loss: 3.2781691847333554
Validation loss: 2.8108905302591256

Epoch: 6| Step: 8
Training loss: 2.963763094084351
Validation loss: 2.813978531669781

Epoch: 6| Step: 9
Training loss: 3.14445209285074
Validation loss: 2.82988058644217

Epoch: 6| Step: 10
Training loss: 2.2994198357663445
Validation loss: 2.857662588102216

Epoch: 6| Step: 11
Training loss: 3.592940529589924
Validation loss: 2.8854780097702473

Epoch: 6| Step: 12
Training loss: 3.3365449374691445
Validation loss: 2.8809876974735236

Epoch: 6| Step: 13
Training loss: 3.35594264493179
Validation loss: 2.869495229509872

Epoch: 64| Step: 0
Training loss: 2.880077853475082
Validation loss: 2.8521387380782492

Epoch: 6| Step: 1
Training loss: 2.8979281160378454
Validation loss: 2.830648944549421

Epoch: 6| Step: 2
Training loss: 3.175486345663313
Validation loss: 2.8235006180598172

Epoch: 6| Step: 3
Training loss: 3.2940048090257497
Validation loss: 2.8134170140202244

Epoch: 6| Step: 4
Training loss: 3.28369775934562
Validation loss: 2.8148601478168547

Epoch: 6| Step: 5
Training loss: 2.5589632888551757
Validation loss: 2.802331110120517

Epoch: 6| Step: 6
Training loss: 2.9308261133762517
Validation loss: 2.7971556277477423

Epoch: 6| Step: 7
Training loss: 2.6642030024464405
Validation loss: 2.798711395102211

Epoch: 6| Step: 8
Training loss: 4.033757812189813
Validation loss: 2.798603538636545

Epoch: 6| Step: 9
Training loss: 3.145217195176509
Validation loss: 2.8004817634620593

Epoch: 6| Step: 10
Training loss: 3.2236637274627125
Validation loss: 2.799136403136983

Epoch: 6| Step: 11
Training loss: 2.7107658221936908
Validation loss: 2.8007208183099523

Epoch: 6| Step: 12
Training loss: 3.0051035386209293
Validation loss: 2.8001626232637578

Epoch: 6| Step: 13
Training loss: 3.673306449911766
Validation loss: 2.7980959691691933

Epoch: 65| Step: 0
Training loss: 3.2085639738601173
Validation loss: 2.7968806353061

Epoch: 6| Step: 1
Training loss: 3.338021621231809
Validation loss: 2.8004818650746137

Epoch: 6| Step: 2
Training loss: 3.377558409597338
Validation loss: 2.7975616721236656

Epoch: 6| Step: 3
Training loss: 2.5193071605772763
Validation loss: 2.79546033754834

Epoch: 6| Step: 4
Training loss: 3.2685348469109505
Validation loss: 2.7926360580638203

Epoch: 6| Step: 5
Training loss: 3.085434962048187
Validation loss: 2.790819941166111

Epoch: 6| Step: 6
Training loss: 3.5144692110543834
Validation loss: 2.791517758488393

Epoch: 6| Step: 7
Training loss: 3.0278614413711353
Validation loss: 2.7868816953831783

Epoch: 6| Step: 8
Training loss: 3.446380103820141
Validation loss: 2.789536541526716

Epoch: 6| Step: 9
Training loss: 3.50043457603043
Validation loss: 2.787632620105005

Epoch: 6| Step: 10
Training loss: 2.5923739540410313
Validation loss: 2.7899667375866253

Epoch: 6| Step: 11
Training loss: 2.689357736484687
Validation loss: 2.789040195174485

Epoch: 6| Step: 12
Training loss: 2.747484790874451
Validation loss: 2.7890102241056423

Epoch: 6| Step: 13
Training loss: 2.6635821404413593
Validation loss: 2.7925304116772454

Epoch: 66| Step: 0
Training loss: 2.8014855769458626
Validation loss: 2.792909925423487

Epoch: 6| Step: 1
Training loss: 3.829634512850301
Validation loss: 2.793024326823925

Epoch: 6| Step: 2
Training loss: 3.1961822445296484
Validation loss: 2.7901769755134764

Epoch: 6| Step: 3
Training loss: 3.4826006969125447
Validation loss: 2.795049114785998

Epoch: 6| Step: 4
Training loss: 2.9848001386995673
Validation loss: 2.787724076674127

Epoch: 6| Step: 5
Training loss: 3.222452793056712
Validation loss: 2.7805770607440543

Epoch: 6| Step: 6
Training loss: 3.12563378582814
Validation loss: 2.7811680268147354

Epoch: 6| Step: 7
Training loss: 3.254092647347265
Validation loss: 2.780924340272137

Epoch: 6| Step: 8
Training loss: 2.667222819348657
Validation loss: 2.7801021075049297

Epoch: 6| Step: 9
Training loss: 3.2961054622480934
Validation loss: 2.782437754733451

Epoch: 6| Step: 10
Training loss: 2.678497495085026
Validation loss: 2.780073270223906

Epoch: 6| Step: 11
Training loss: 2.8672267484966936
Validation loss: 2.7814023071927623

Epoch: 6| Step: 12
Training loss: 2.8329808820031612
Validation loss: 2.781103490012593

Epoch: 6| Step: 13
Training loss: 2.755051135438436
Validation loss: 2.7766896775398187

Epoch: 67| Step: 0
Training loss: 2.900127401513134
Validation loss: 2.7771265827010776

Epoch: 6| Step: 1
Training loss: 3.247033158856989
Validation loss: 2.777410842354895

Epoch: 6| Step: 2
Training loss: 2.9998553559083594
Validation loss: 2.775670645729499

Epoch: 6| Step: 3
Training loss: 2.610142943169369
Validation loss: 2.777260684897449

Epoch: 6| Step: 4
Training loss: 3.558033870868168
Validation loss: 2.776525379144922

Epoch: 6| Step: 5
Training loss: 2.212771244987064
Validation loss: 2.774984709425859

Epoch: 6| Step: 6
Training loss: 3.3777007140883035
Validation loss: 2.7777666841476853

Epoch: 6| Step: 7
Training loss: 3.4066741399316007
Validation loss: 2.777022965296827

Epoch: 6| Step: 8
Training loss: 3.602625625823659
Validation loss: 2.7776886631060114

Epoch: 6| Step: 9
Training loss: 3.4393668913983952
Validation loss: 2.772826898199979

Epoch: 6| Step: 10
Training loss: 3.1448866744008788
Validation loss: 2.7717531040655126

Epoch: 6| Step: 11
Training loss: 2.585755033480582
Validation loss: 2.7725192037816635

Epoch: 6| Step: 12
Training loss: 2.403897609453414
Validation loss: 2.771798589244022

Epoch: 6| Step: 13
Training loss: 3.491462922505894
Validation loss: 2.7733445850587577

Epoch: 68| Step: 0
Training loss: 2.9363683590473877
Validation loss: 2.7714832603671287

Epoch: 6| Step: 1
Training loss: 3.3139876857660004
Validation loss: 2.770335327022558

Epoch: 6| Step: 2
Training loss: 2.937891994861983
Validation loss: 2.769492561825332

Epoch: 6| Step: 3
Training loss: 3.297598086063102
Validation loss: 2.7705155131055075

Epoch: 6| Step: 4
Training loss: 3.038330617608053
Validation loss: 2.771855496923401

Epoch: 6| Step: 5
Training loss: 2.954882225103633
Validation loss: 2.771097560302559

Epoch: 6| Step: 6
Training loss: 3.0764539801201116
Validation loss: 2.7719163831192866

Epoch: 6| Step: 7
Training loss: 3.312010530980271
Validation loss: 2.7732837579505882

Epoch: 6| Step: 8
Training loss: 3.4747243758196187
Validation loss: 2.7719921680651076

Epoch: 6| Step: 9
Training loss: 3.026921908613555
Validation loss: 2.773615092476137

Epoch: 6| Step: 10
Training loss: 3.260233978580797
Validation loss: 2.7704312244548825

Epoch: 6| Step: 11
Training loss: 2.8057551570009807
Validation loss: 2.7681153226678115

Epoch: 6| Step: 12
Training loss: 2.701126241677761
Validation loss: 2.7683882996293865

Epoch: 6| Step: 13
Training loss: 2.9713877955458043
Validation loss: 2.7662549277965867

Epoch: 69| Step: 0
Training loss: 2.726042864668897
Validation loss: 2.7632131811231173

Epoch: 6| Step: 1
Training loss: 3.304586061765046
Validation loss: 2.7686530985308404

Epoch: 6| Step: 2
Training loss: 2.5205097043290072
Validation loss: 2.777450680154408

Epoch: 6| Step: 3
Training loss: 3.1419466947893864
Validation loss: 2.795721818539929

Epoch: 6| Step: 4
Training loss: 3.740937280964799
Validation loss: 2.8174428112816874

Epoch: 6| Step: 5
Training loss: 3.241424985635176
Validation loss: 2.7940441825974762

Epoch: 6| Step: 6
Training loss: 3.126715380025497
Validation loss: 2.7694654478455103

Epoch: 6| Step: 7
Training loss: 2.9184520887971575
Validation loss: 2.7608461856531434

Epoch: 6| Step: 8
Training loss: 2.798271895918105
Validation loss: 2.76078101408402

Epoch: 6| Step: 9
Training loss: 2.890069526707214
Validation loss: 2.7623455797529313

Epoch: 6| Step: 10
Training loss: 3.1376950085589645
Validation loss: 2.761042119171374

Epoch: 6| Step: 11
Training loss: 2.862412470516293
Validation loss: 2.7582256048752933

Epoch: 6| Step: 12
Training loss: 3.428072816491572
Validation loss: 2.762161801606198

Epoch: 6| Step: 13
Training loss: 3.1822803619899878
Validation loss: 2.7628907446598543

Epoch: 70| Step: 0
Training loss: 2.9670778082508797
Validation loss: 2.773257236610566

Epoch: 6| Step: 1
Training loss: 3.4620714934673007
Validation loss: 2.773497239953765

Epoch: 6| Step: 2
Training loss: 2.7731206148743537
Validation loss: 2.7614272072904336

Epoch: 6| Step: 3
Training loss: 3.6576140378016824
Validation loss: 2.7590495718735824

Epoch: 6| Step: 4
Training loss: 2.929313615465484
Validation loss: 2.7566390921573882

Epoch: 6| Step: 5
Training loss: 2.9530097091210328
Validation loss: 2.7578825290000153

Epoch: 6| Step: 6
Training loss: 3.324321310431318
Validation loss: 2.757795278323506

Epoch: 6| Step: 7
Training loss: 2.7037470989238184
Validation loss: 2.7566931601859723

Epoch: 6| Step: 8
Training loss: 3.0565311107577937
Validation loss: 2.7540332884451697

Epoch: 6| Step: 9
Training loss: 3.073656275477184
Validation loss: 2.7564846680131683

Epoch: 6| Step: 10
Training loss: 3.543576223159426
Validation loss: 2.758744230770948

Epoch: 6| Step: 11
Training loss: 2.6844239484700676
Validation loss: 2.759999147316645

Epoch: 6| Step: 12
Training loss: 2.263148881796232
Validation loss: 2.766897192700068

Epoch: 6| Step: 13
Training loss: 3.5597824975338783
Validation loss: 2.7745880407249124

Epoch: 71| Step: 0
Training loss: 3.527950129132704
Validation loss: 2.7894403037396693

Epoch: 6| Step: 1
Training loss: 3.4015607841743205
Validation loss: 2.761683866977892

Epoch: 6| Step: 2
Training loss: 2.5338446423206844
Validation loss: 2.7526825474297385

Epoch: 6| Step: 3
Training loss: 3.375951279690908
Validation loss: 2.752676604641832

Epoch: 6| Step: 4
Training loss: 2.813886258432762
Validation loss: 2.753207658178194

Epoch: 6| Step: 5
Training loss: 2.9460016147689383
Validation loss: 2.7501273456669795

Epoch: 6| Step: 6
Training loss: 3.5157378454111523
Validation loss: 2.749837657093005

Epoch: 6| Step: 7
Training loss: 3.0084662185301516
Validation loss: 2.751062499298874

Epoch: 6| Step: 8
Training loss: 2.749211631824225
Validation loss: 2.7508004161946613

Epoch: 6| Step: 9
Training loss: 2.6359526701051412
Validation loss: 2.754971002216532

Epoch: 6| Step: 10
Training loss: 3.068182830296616
Validation loss: 2.7565903994278007

Epoch: 6| Step: 11
Training loss: 3.1832745538314473
Validation loss: 2.755606039294121

Epoch: 6| Step: 12
Training loss: 3.5057924567081433
Validation loss: 2.757328950742607

Epoch: 6| Step: 13
Training loss: 2.0193388089071855
Validation loss: 2.755330197487852

Epoch: 72| Step: 0
Training loss: 2.04740887151497
Validation loss: 2.7568451306872768

Epoch: 6| Step: 1
Training loss: 3.651803206156397
Validation loss: 2.7534185641728626

Epoch: 6| Step: 2
Training loss: 2.593218461690274
Validation loss: 2.756144277515797

Epoch: 6| Step: 3
Training loss: 3.239682767431674
Validation loss: 2.7566187420899424

Epoch: 6| Step: 4
Training loss: 3.16051444344765
Validation loss: 2.754103212477454

Epoch: 6| Step: 5
Training loss: 2.5620027385283106
Validation loss: 2.7489534644580638

Epoch: 6| Step: 6
Training loss: 3.24276691452884
Validation loss: 2.7473423870055034

Epoch: 6| Step: 7
Training loss: 2.9607920749351067
Validation loss: 2.7464220649540807

Epoch: 6| Step: 8
Training loss: 3.7277268484104176
Validation loss: 2.7453225350113515

Epoch: 6| Step: 9
Training loss: 3.170146301936804
Validation loss: 2.7500424670784014

Epoch: 6| Step: 10
Training loss: 3.0411931196193893
Validation loss: 2.7435159909386932

Epoch: 6| Step: 11
Training loss: 2.458973709580226
Validation loss: 2.7455950254821873

Epoch: 6| Step: 12
Training loss: 3.5915859174981457
Validation loss: 2.7419191999392227

Epoch: 6| Step: 13
Training loss: 2.914845706527
Validation loss: 2.742335391695224

Epoch: 73| Step: 0
Training loss: 3.6179647908181884
Validation loss: 2.7433989792778677

Epoch: 6| Step: 1
Training loss: 2.980223959373265
Validation loss: 2.7446492046409157

Epoch: 6| Step: 2
Training loss: 2.740434656960429
Validation loss: 2.7518213576016253

Epoch: 6| Step: 3
Training loss: 3.118901978728649
Validation loss: 2.7568845105846225

Epoch: 6| Step: 4
Training loss: 3.070215898309343
Validation loss: 2.7550481642743594

Epoch: 6| Step: 5
Training loss: 2.7501709624814192
Validation loss: 2.7594976962276503

Epoch: 6| Step: 6
Training loss: 3.721042343255488
Validation loss: 2.7584750224931973

Epoch: 6| Step: 7
Training loss: 3.4124861161505
Validation loss: 2.7879967998975257

Epoch: 6| Step: 8
Training loss: 2.648464956675754
Validation loss: 2.785937544869318

Epoch: 6| Step: 9
Training loss: 2.9124790829410836
Validation loss: 2.7534575508223127

Epoch: 6| Step: 10
Training loss: 2.922993491792954
Validation loss: 2.7473779541391865

Epoch: 6| Step: 11
Training loss: 2.565936134049044
Validation loss: 2.7434127478134043

Epoch: 6| Step: 12
Training loss: 2.9933114194457247
Validation loss: 2.7478650607079462

Epoch: 6| Step: 13
Training loss: 3.324335510857037
Validation loss: 2.7483242565526935

Epoch: 74| Step: 0
Training loss: 3.120760827098676
Validation loss: 2.751001258724772

Epoch: 6| Step: 1
Training loss: 2.652721709568176
Validation loss: 2.757238731410916

Epoch: 6| Step: 2
Training loss: 2.761176459393874
Validation loss: 2.7469672626905517

Epoch: 6| Step: 3
Training loss: 3.2133862887038167
Validation loss: 2.7519362159968237

Epoch: 6| Step: 4
Training loss: 2.819513096675637
Validation loss: 2.754738187165086

Epoch: 6| Step: 5
Training loss: 3.4482984686801057
Validation loss: 2.7520789606415574

Epoch: 6| Step: 6
Training loss: 2.2796027101745935
Validation loss: 2.7480061622047574

Epoch: 6| Step: 7
Training loss: 3.7407446769620907
Validation loss: 2.742449731275127

Epoch: 6| Step: 8
Training loss: 2.9157737636740912
Validation loss: 2.7383851013249383

Epoch: 6| Step: 9
Training loss: 3.4071718420924784
Validation loss: 2.735712407920792

Epoch: 6| Step: 10
Training loss: 3.236560912154433
Validation loss: 2.732254326349

Epoch: 6| Step: 11
Training loss: 3.103664502653555
Validation loss: 2.7350858077969566

Epoch: 6| Step: 12
Training loss: 2.6438940455376687
Validation loss: 2.7337277932390927

Epoch: 6| Step: 13
Training loss: 3.107588825260634
Validation loss: 2.739471658481218

Epoch: 75| Step: 0
Training loss: 2.238759680407035
Validation loss: 2.7403244983611557

Epoch: 6| Step: 1
Training loss: 3.0171406944275407
Validation loss: 2.7404165440038226

Epoch: 6| Step: 2
Training loss: 3.3130213489161253
Validation loss: 2.7383359070627993

Epoch: 6| Step: 3
Training loss: 3.408698225813709
Validation loss: 2.731007204682336

Epoch: 6| Step: 4
Training loss: 3.3239454791375276
Validation loss: 2.7271002415990115

Epoch: 6| Step: 5
Training loss: 2.7068297296022505
Validation loss: 2.724356201067268

Epoch: 6| Step: 6
Training loss: 3.6168887713275444
Validation loss: 2.7227938861137493

Epoch: 6| Step: 7
Training loss: 2.621057274190822
Validation loss: 2.725403374512321

Epoch: 6| Step: 8
Training loss: 2.851804289299631
Validation loss: 2.7398859024857973

Epoch: 6| Step: 9
Training loss: 2.6509241903740572
Validation loss: 2.749797461202325

Epoch: 6| Step: 10
Training loss: 2.818863007506809
Validation loss: 2.7869992022291536

Epoch: 6| Step: 11
Training loss: 3.3345569907720924
Validation loss: 2.8306568836625843

Epoch: 6| Step: 12
Training loss: 3.4273388582798603
Validation loss: 2.819631884881722

Epoch: 6| Step: 13
Training loss: 3.416392912403576
Validation loss: 2.815036763578254

Epoch: 76| Step: 0
Training loss: 3.177338203254625
Validation loss: 2.7895451104585858

Epoch: 6| Step: 1
Training loss: 3.777271794735416
Validation loss: 2.775596714282368

Epoch: 6| Step: 2
Training loss: 3.2282349913951385
Validation loss: 2.7590150202747603

Epoch: 6| Step: 3
Training loss: 2.849911731892347
Validation loss: 2.7552683920813843

Epoch: 6| Step: 4
Training loss: 3.1716313010118475
Validation loss: 2.7457181030944438

Epoch: 6| Step: 5
Training loss: 3.0400072213137337
Validation loss: 2.746484472673722

Epoch: 6| Step: 6
Training loss: 2.6412316703250633
Validation loss: 2.7584935940075126

Epoch: 6| Step: 7
Training loss: 3.082522895771271
Validation loss: 2.773054352447628

Epoch: 6| Step: 8
Training loss: 2.65517089466166
Validation loss: 2.802636382259404

Epoch: 6| Step: 9
Training loss: 2.4856355935749375
Validation loss: 2.7760320876189297

Epoch: 6| Step: 10
Training loss: 2.804722692752306
Validation loss: 2.775008090782621

Epoch: 6| Step: 11
Training loss: 3.7495692959445797
Validation loss: 2.7829037402645533

Epoch: 6| Step: 12
Training loss: 3.072882821279228
Validation loss: 2.785188179849626

Epoch: 6| Step: 13
Training loss: 3.1970547354281007
Validation loss: 2.7984971693887646

Epoch: 77| Step: 0
Training loss: 3.2991734307600304
Validation loss: 2.8062872536785957

Epoch: 6| Step: 1
Training loss: 2.462729924500507
Validation loss: 2.790524688263825

Epoch: 6| Step: 2
Training loss: 2.8552920682129534
Validation loss: 2.7845607039670957

Epoch: 6| Step: 3
Training loss: 3.2363524358339317
Validation loss: 2.774853395460125

Epoch: 6| Step: 4
Training loss: 3.1866331230643326
Validation loss: 2.773241828418259

Epoch: 6| Step: 5
Training loss: 3.498754279654319
Validation loss: 2.7717492971059077

Epoch: 6| Step: 6
Training loss: 2.3441418129527483
Validation loss: 2.7690680227661306

Epoch: 6| Step: 7
Training loss: 3.463390023872347
Validation loss: 2.772557713799387

Epoch: 6| Step: 8
Training loss: 3.5664551847512214
Validation loss: 2.768834994954165

Epoch: 6| Step: 9
Training loss: 3.197501256016417
Validation loss: 2.765841307424401

Epoch: 6| Step: 10
Training loss: 3.3214243025979355
Validation loss: 2.746260943466614

Epoch: 6| Step: 11
Training loss: 3.242495749653874
Validation loss: 2.7320123912894387

Epoch: 6| Step: 12
Training loss: 2.2521997930414344
Validation loss: 2.722217627999929

Epoch: 6| Step: 13
Training loss: 2.434720435259431
Validation loss: 2.706997887810766

Epoch: 78| Step: 0
Training loss: 2.893246178815918
Validation loss: 2.713447929292055

Epoch: 6| Step: 1
Training loss: 3.3937553335467556
Validation loss: 2.7150794798531552

Epoch: 6| Step: 2
Training loss: 3.2312846139496374
Validation loss: 2.723191679838391

Epoch: 6| Step: 3
Training loss: 2.9902589324799895
Validation loss: 2.720737811672215

Epoch: 6| Step: 4
Training loss: 2.779827311249944
Validation loss: 2.7183840020501564

Epoch: 6| Step: 5
Training loss: 2.919637547559397
Validation loss: 2.7177779218831932

Epoch: 6| Step: 6
Training loss: 3.147333069753713
Validation loss: 2.711017367858022

Epoch: 6| Step: 7
Training loss: 2.9833397792412653
Validation loss: 2.7128657793436286

Epoch: 6| Step: 8
Training loss: 3.213888700883252
Validation loss: 2.7072015528912234

Epoch: 6| Step: 9
Training loss: 3.066352756300915
Validation loss: 2.7083413615395675

Epoch: 6| Step: 10
Training loss: 2.9449391419319038
Validation loss: 2.7059936874195114

Epoch: 6| Step: 11
Training loss: 3.143870029471166
Validation loss: 2.711971486615105

Epoch: 6| Step: 12
Training loss: 2.7640735132182375
Validation loss: 2.7263117219256916

Epoch: 6| Step: 13
Training loss: 2.7861589978067602
Validation loss: 2.746657194032034

Epoch: 79| Step: 0
Training loss: 3.6036804988535516
Validation loss: 2.7749950240753063

Epoch: 6| Step: 1
Training loss: 2.4030276433820728
Validation loss: 2.7434248174189118

Epoch: 6| Step: 2
Training loss: 3.4714790125282087
Validation loss: 2.720598717445367

Epoch: 6| Step: 3
Training loss: 3.185607946992749
Validation loss: 2.717744089793162

Epoch: 6| Step: 4
Training loss: 2.8982833451151353
Validation loss: 2.707377233935909

Epoch: 6| Step: 5
Training loss: 2.5787483155415627
Validation loss: 2.7118752093569896

Epoch: 6| Step: 6
Training loss: 2.6827560072268075
Validation loss: 2.709266471238559

Epoch: 6| Step: 7
Training loss: 2.9840209111767035
Validation loss: 2.7080385191234524

Epoch: 6| Step: 8
Training loss: 2.9810190555202762
Validation loss: 2.7154865671557746

Epoch: 6| Step: 9
Training loss: 2.2473107266952064
Validation loss: 2.711160079766087

Epoch: 6| Step: 10
Training loss: 3.4294023330069194
Validation loss: 2.6960315688581646

Epoch: 6| Step: 11
Training loss: 2.9839868742523734
Validation loss: 2.694609284596065

Epoch: 6| Step: 12
Training loss: 3.209273229543604
Validation loss: 2.7058387216288176

Epoch: 6| Step: 13
Training loss: 3.769070643612365
Validation loss: 2.6934922215967037

Epoch: 80| Step: 0
Training loss: 3.283025352117538
Validation loss: 2.689752246927856

Epoch: 6| Step: 1
Training loss: 3.3516189819413937
Validation loss: 2.6911874129654274

Epoch: 6| Step: 2
Training loss: 3.3893832556616794
Validation loss: 2.6903158900155426

Epoch: 6| Step: 3
Training loss: 2.848837859810428
Validation loss: 2.69048228372776

Epoch: 6| Step: 4
Training loss: 3.1933166687702457
Validation loss: 2.69334548384672

Epoch: 6| Step: 5
Training loss: 3.155552702068179
Validation loss: 2.6965760329535606

Epoch: 6| Step: 6
Training loss: 3.0404313248273196
Validation loss: 2.7088855347695358

Epoch: 6| Step: 7
Training loss: 2.864941957162084
Validation loss: 2.706827830664456

Epoch: 6| Step: 8
Training loss: 2.714723257780249
Validation loss: 2.7022728981468678

Epoch: 6| Step: 9
Training loss: 3.0596377952480505
Validation loss: 2.711982792441232

Epoch: 6| Step: 10
Training loss: 2.3997981781342297
Validation loss: 2.7052274303902655

Epoch: 6| Step: 11
Training loss: 2.3017785286244257
Validation loss: 2.7114513411797403

Epoch: 6| Step: 12
Training loss: 3.0752426051758057
Validation loss: 2.701972687839078

Epoch: 6| Step: 13
Training loss: 3.530283432731355
Validation loss: 2.697464690360482

Epoch: 81| Step: 0
Training loss: 2.925675312563904
Validation loss: 2.696716694224504

Epoch: 6| Step: 1
Training loss: 3.541710946797333
Validation loss: 2.708892269215806

Epoch: 6| Step: 2
Training loss: 3.2648323228667575
Validation loss: 2.698744876024963

Epoch: 6| Step: 3
Training loss: 3.068500789926299
Validation loss: 2.6926952112695774

Epoch: 6| Step: 4
Training loss: 3.364033153102951
Validation loss: 2.685943438920646

Epoch: 6| Step: 5
Training loss: 2.943045069689991
Validation loss: 2.6792880734964575

Epoch: 6| Step: 6
Training loss: 2.7391715568248927
Validation loss: 2.683620912900092

Epoch: 6| Step: 7
Training loss: 2.982501495437695
Validation loss: 2.6864806271671564

Epoch: 6| Step: 8
Training loss: 3.1326645509407327
Validation loss: 2.687305156248616

Epoch: 6| Step: 9
Training loss: 3.026601471499866
Validation loss: 2.6882787817611264

Epoch: 6| Step: 10
Training loss: 3.150440875490435
Validation loss: 2.691997432726471

Epoch: 6| Step: 11
Training loss: 2.638805778488533
Validation loss: 2.6976125383177068

Epoch: 6| Step: 12
Training loss: 2.4875930001974496
Validation loss: 2.692473559705689

Epoch: 6| Step: 13
Training loss: 2.944559097057149
Validation loss: 2.6930169501322667

Epoch: 82| Step: 0
Training loss: 2.6724809996711887
Validation loss: 2.6927137080675037

Epoch: 6| Step: 1
Training loss: 3.291189778867585
Validation loss: 2.693523675237719

Epoch: 6| Step: 2
Training loss: 2.720557127442686
Validation loss: 2.6891298305217655

Epoch: 6| Step: 3
Training loss: 3.3340789120036263
Validation loss: 2.685309755538651

Epoch: 6| Step: 4
Training loss: 2.9078056519851523
Validation loss: 2.684907082574822

Epoch: 6| Step: 5
Training loss: 3.274630163145649
Validation loss: 2.686177986693855

Epoch: 6| Step: 6
Training loss: 3.428033729805695
Validation loss: 2.6785970125475678

Epoch: 6| Step: 7
Training loss: 3.18267127403988
Validation loss: 2.6806096085985205

Epoch: 6| Step: 8
Training loss: 2.2203651244808236
Validation loss: 2.6787848603689812

Epoch: 6| Step: 9
Training loss: 2.96313330725805
Validation loss: 2.6782316315814887

Epoch: 6| Step: 10
Training loss: 2.8836513218988635
Validation loss: 2.6762755215692056

Epoch: 6| Step: 11
Training loss: 3.1034498645880713
Validation loss: 2.6782112237026685

Epoch: 6| Step: 12
Training loss: 2.5435794970006844
Validation loss: 2.6908088741592566

Epoch: 6| Step: 13
Training loss: 3.5523640511450507
Validation loss: 2.7069346833853385

Epoch: 83| Step: 0
Training loss: 2.5595600662113687
Validation loss: 2.7572714020208053

Epoch: 6| Step: 1
Training loss: 3.198985034198103
Validation loss: 2.8114101289898135

Epoch: 6| Step: 2
Training loss: 3.193181677490942
Validation loss: 2.830976116100057

Epoch: 6| Step: 3
Training loss: 3.267543831307265
Validation loss: 2.7403576484703884

Epoch: 6| Step: 4
Training loss: 2.9218010714556986
Validation loss: 2.680932419658607

Epoch: 6| Step: 5
Training loss: 2.7661761580590905
Validation loss: 2.671677125431517

Epoch: 6| Step: 6
Training loss: 2.7633478304947072
Validation loss: 2.674898724176517

Epoch: 6| Step: 7
Training loss: 2.434039667462961
Validation loss: 2.6786086793683483

Epoch: 6| Step: 8
Training loss: 3.348473465833588
Validation loss: 2.6783135247675514

Epoch: 6| Step: 9
Training loss: 2.7812718594152823
Validation loss: 2.681893095770819

Epoch: 6| Step: 10
Training loss: 3.2827915022122665
Validation loss: 2.6864483791668965

Epoch: 6| Step: 11
Training loss: 3.83273374318736
Validation loss: 2.6844995074713256

Epoch: 6| Step: 12
Training loss: 2.6681101190469705
Validation loss: 2.6861125171812934

Epoch: 6| Step: 13
Training loss: 3.2375113350806033
Validation loss: 2.6798789333479722

Epoch: 84| Step: 0
Training loss: 3.095042257436461
Validation loss: 2.676847007346351

Epoch: 6| Step: 1
Training loss: 3.2010562822327078
Validation loss: 2.6766268401330318

Epoch: 6| Step: 2
Training loss: 2.8578760773024734
Validation loss: 2.677651641676506

Epoch: 6| Step: 3
Training loss: 2.7916926102832416
Validation loss: 2.6778642209717924

Epoch: 6| Step: 4
Training loss: 3.2281893492024594
Validation loss: 2.6723611127154867

Epoch: 6| Step: 5
Training loss: 2.9040706215460323
Validation loss: 2.6728216337865778

Epoch: 6| Step: 6
Training loss: 2.725754932507213
Validation loss: 2.6680857663158104

Epoch: 6| Step: 7
Training loss: 3.442146490115088
Validation loss: 2.6658379663646414

Epoch: 6| Step: 8
Training loss: 2.697508782345084
Validation loss: 2.662979515471403

Epoch: 6| Step: 9
Training loss: 3.2102804509466876
Validation loss: 2.66452415276347

Epoch: 6| Step: 10
Training loss: 3.17499377633033
Validation loss: 2.6694273086092384

Epoch: 6| Step: 11
Training loss: 2.6728392528603098
Validation loss: 2.6813727464935386

Epoch: 6| Step: 12
Training loss: 2.9425575060155573
Validation loss: 2.705023032871615

Epoch: 6| Step: 13
Training loss: 3.12957870743769
Validation loss: 2.73631196358604

Epoch: 85| Step: 0
Training loss: 2.922958091683373
Validation loss: 2.725265934154669

Epoch: 6| Step: 1
Training loss: 3.1256858073152918
Validation loss: 2.7299474936046444

Epoch: 6| Step: 2
Training loss: 3.4011095087938736
Validation loss: 2.7386033571454766

Epoch: 6| Step: 3
Training loss: 3.291716530981505
Validation loss: 2.719388972277547

Epoch: 6| Step: 4
Training loss: 2.5523653354671976
Validation loss: 2.6965096246398788

Epoch: 6| Step: 5
Training loss: 3.145872978987988
Validation loss: 2.694132689117215

Epoch: 6| Step: 6
Training loss: 3.3568122492273083
Validation loss: 2.6723226687816535

Epoch: 6| Step: 7
Training loss: 2.4717712264817777
Validation loss: 2.6592440404543543

Epoch: 6| Step: 8
Training loss: 2.924148409520016
Validation loss: 2.6602104836450198

Epoch: 6| Step: 9
Training loss: 3.4650628365768177
Validation loss: 2.660960344451556

Epoch: 6| Step: 10
Training loss: 3.1468365482227494
Validation loss: 2.6657597146093543

Epoch: 6| Step: 11
Training loss: 2.8094661031681936
Validation loss: 2.665657411664459

Epoch: 6| Step: 12
Training loss: 3.080649488014722
Validation loss: 2.6651204241512354

Epoch: 6| Step: 13
Training loss: 1.2229032906749029
Validation loss: 2.6695172362371027

Epoch: 86| Step: 0
Training loss: 3.2386325696226343
Validation loss: 2.6647427435343967

Epoch: 6| Step: 1
Training loss: 3.2674635680662356
Validation loss: 2.6643903679281458

Epoch: 6| Step: 2
Training loss: 3.2516784735275777
Validation loss: 2.6670949294638855

Epoch: 6| Step: 3
Training loss: 2.604837366837346
Validation loss: 2.6674514485443033

Epoch: 6| Step: 4
Training loss: 2.779631154270344
Validation loss: 2.671803081326282

Epoch: 6| Step: 5
Training loss: 3.041653741957147
Validation loss: 2.66875350841255

Epoch: 6| Step: 6
Training loss: 2.418063406870969
Validation loss: 2.666818782354279

Epoch: 6| Step: 7
Training loss: 3.7836951554718325
Validation loss: 2.66702962688161

Epoch: 6| Step: 8
Training loss: 2.8626643371051372
Validation loss: 2.664651652275382

Epoch: 6| Step: 9
Training loss: 2.571328747794774
Validation loss: 2.663034542625716

Epoch: 6| Step: 10
Training loss: 3.2998614773431507
Validation loss: 2.6632103263569418

Epoch: 6| Step: 11
Training loss: 2.620519356248331
Validation loss: 2.6605233665570744

Epoch: 6| Step: 12
Training loss: 3.175268453227386
Validation loss: 2.6598690031405017

Epoch: 6| Step: 13
Training loss: 2.7362199063517405
Validation loss: 2.658326412452558

Epoch: 87| Step: 0
Training loss: 3.5927155705960936
Validation loss: 2.6589135768204017

Epoch: 6| Step: 1
Training loss: 2.500170129709223
Validation loss: 2.659558477182169

Epoch: 6| Step: 2
Training loss: 2.8435115504639805
Validation loss: 2.6584236965070533

Epoch: 6| Step: 3
Training loss: 2.666645755288467
Validation loss: 2.6586642253770023

Epoch: 6| Step: 4
Training loss: 3.2259315446471444
Validation loss: 2.660830583106155

Epoch: 6| Step: 5
Training loss: 2.834631416809783
Validation loss: 2.658158008761313

Epoch: 6| Step: 6
Training loss: 2.831258313164706
Validation loss: 2.661485584723873

Epoch: 6| Step: 7
Training loss: 3.1292399824944703
Validation loss: 2.662783906681949

Epoch: 6| Step: 8
Training loss: 2.8007497532987533
Validation loss: 2.6617014007189312

Epoch: 6| Step: 9
Training loss: 2.646633647917725
Validation loss: 2.667041412550604

Epoch: 6| Step: 10
Training loss: 2.8315132877631526
Validation loss: 2.667058929951456

Epoch: 6| Step: 11
Training loss: 3.4559302349378127
Validation loss: 2.6516529721571303

Epoch: 6| Step: 12
Training loss: 3.4142471368301006
Validation loss: 2.6577636257051087

Epoch: 6| Step: 13
Training loss: 2.5674725179863627
Validation loss: 2.683888908500101

Epoch: 88| Step: 0
Training loss: 3.260030965365452
Validation loss: 2.7817983562602584

Epoch: 6| Step: 1
Training loss: 3.002291598873355
Validation loss: 2.774868999804721

Epoch: 6| Step: 2
Training loss: 2.703204203421019
Validation loss: 2.7205925792472447

Epoch: 6| Step: 3
Training loss: 3.7717316683231896
Validation loss: 2.701079830257905

Epoch: 6| Step: 4
Training loss: 2.471216828389415
Validation loss: 2.6859254204584744

Epoch: 6| Step: 5
Training loss: 2.7859001289809378
Validation loss: 2.6828507781013196

Epoch: 6| Step: 6
Training loss: 3.0833800716122597
Validation loss: 2.69537782784586

Epoch: 6| Step: 7
Training loss: 2.922971468733701
Validation loss: 2.6714676534066597

Epoch: 6| Step: 8
Training loss: 3.194301902428739
Validation loss: 2.6659355494419104

Epoch: 6| Step: 9
Training loss: 3.2449121998809956
Validation loss: 2.6673190177132486

Epoch: 6| Step: 10
Training loss: 2.9832795214639267
Validation loss: 2.668468319208391

Epoch: 6| Step: 11
Training loss: 3.0993361469840526
Validation loss: 2.668122081542122

Epoch: 6| Step: 12
Training loss: 2.9229003412756476
Validation loss: 2.670402624421632

Epoch: 6| Step: 13
Training loss: 2.582391156896886
Validation loss: 2.673354720619632

Epoch: 89| Step: 0
Training loss: 2.453594187192496
Validation loss: 2.682923379102591

Epoch: 6| Step: 1
Training loss: 3.1359280056279886
Validation loss: 2.6932637259999828

Epoch: 6| Step: 2
Training loss: 3.0814714394749476
Validation loss: 2.7220116648199726

Epoch: 6| Step: 3
Training loss: 2.2372652580686396
Validation loss: 2.749518849258375

Epoch: 6| Step: 4
Training loss: 3.2244745107321484
Validation loss: 2.7664169587520395

Epoch: 6| Step: 5
Training loss: 3.131781582052865
Validation loss: 2.732588480833991

Epoch: 6| Step: 6
Training loss: 2.846780357085748
Validation loss: 2.723935752653808

Epoch: 6| Step: 7
Training loss: 2.798884516997753
Validation loss: 2.721881918710411

Epoch: 6| Step: 8
Training loss: 3.5890344614503933
Validation loss: 2.722601732021368

Epoch: 6| Step: 9
Training loss: 3.2725453037188923
Validation loss: 2.7339088701270686

Epoch: 6| Step: 10
Training loss: 3.5993196533314333
Validation loss: 2.7183166863924564

Epoch: 6| Step: 11
Training loss: 3.1909606697243293
Validation loss: 2.71528040780516

Epoch: 6| Step: 12
Training loss: 2.6182888162067304
Validation loss: 2.697948644875118

Epoch: 6| Step: 13
Training loss: 2.8159799028242998
Validation loss: 2.6940389603009316

Epoch: 90| Step: 0
Training loss: 2.812404037533888
Validation loss: 2.6904939571342275

Epoch: 6| Step: 1
Training loss: 2.7037226727321984
Validation loss: 2.6851746490651185

Epoch: 6| Step: 2
Training loss: 3.153774688297485
Validation loss: 2.684080867426855

Epoch: 6| Step: 3
Training loss: 2.7693917867521516
Validation loss: 2.6840217176119023

Epoch: 6| Step: 4
Training loss: 3.272986915914209
Validation loss: 2.682032580018523

Epoch: 6| Step: 5
Training loss: 3.3898455167696766
Validation loss: 2.680675289971004

Epoch: 6| Step: 6
Training loss: 3.1752917298383903
Validation loss: 2.67317887223193

Epoch: 6| Step: 7
Training loss: 3.4035203828387637
Validation loss: 2.6704722029039387

Epoch: 6| Step: 8
Training loss: 3.4861390989547076
Validation loss: 2.66451479595245

Epoch: 6| Step: 9
Training loss: 2.7526246463780084
Validation loss: 2.6623172000717106

Epoch: 6| Step: 10
Training loss: 2.823948933018079
Validation loss: 2.656797036405332

Epoch: 6| Step: 11
Training loss: 2.641039482858655
Validation loss: 2.6649590210893384

Epoch: 6| Step: 12
Training loss: 2.886116429571743
Validation loss: 2.689260075760317

Epoch: 6| Step: 13
Training loss: 2.6534641691598893
Validation loss: 2.7049956773568686

Epoch: 91| Step: 0
Training loss: 3.464050821534991
Validation loss: 2.7134374317011876

Epoch: 6| Step: 1
Training loss: 2.8650181850635135
Validation loss: 2.719739035082933

Epoch: 6| Step: 2
Training loss: 2.8139998781140485
Validation loss: 2.7215169325782727

Epoch: 6| Step: 3
Training loss: 3.3771232707732977
Validation loss: 2.7257022870529237

Epoch: 6| Step: 4
Training loss: 2.7647314837348205
Validation loss: 2.712001058907792

Epoch: 6| Step: 5
Training loss: 2.5135351942674373
Validation loss: 2.704846719336204

Epoch: 6| Step: 6
Training loss: 3.3423641577245586
Validation loss: 2.699875025855395

Epoch: 6| Step: 7
Training loss: 3.5101644876308304
Validation loss: 2.685045335162771

Epoch: 6| Step: 8
Training loss: 3.145438988497295
Validation loss: 2.670998539471382

Epoch: 6| Step: 9
Training loss: 3.3401211450501074
Validation loss: 2.664495379863414

Epoch: 6| Step: 10
Training loss: 2.6913114622391414
Validation loss: 2.6448515486016477

Epoch: 6| Step: 11
Training loss: 2.713032465413238
Validation loss: 2.6481393504758146

Epoch: 6| Step: 12
Training loss: 2.904064053693393
Validation loss: 2.650828415408466

Epoch: 6| Step: 13
Training loss: 2.4475301126219393
Validation loss: 2.6669498076659335

Epoch: 92| Step: 0
Training loss: 2.6897876672717724
Validation loss: 2.741635334553865

Epoch: 6| Step: 1
Training loss: 2.920272305999309
Validation loss: 2.7878502720465734

Epoch: 6| Step: 2
Training loss: 3.5239272358772284
Validation loss: 2.8109771461415365

Epoch: 6| Step: 3
Training loss: 2.7752425216685386
Validation loss: 2.7347864692832764

Epoch: 6| Step: 4
Training loss: 2.8106161802228558
Validation loss: 2.673799179921096

Epoch: 6| Step: 5
Training loss: 2.6323951820597244
Validation loss: 2.668173266963848

Epoch: 6| Step: 6
Training loss: 3.130777892196461
Validation loss: 2.6615345590808923

Epoch: 6| Step: 7
Training loss: 3.047798681854618
Validation loss: 2.6576195445359665

Epoch: 6| Step: 8
Training loss: 3.4161429275164563
Validation loss: 2.6617967440089596

Epoch: 6| Step: 9
Training loss: 2.6477532417134166
Validation loss: 2.6580323823309517

Epoch: 6| Step: 10
Training loss: 2.9622736912814296
Validation loss: 2.656156710314154

Epoch: 6| Step: 11
Training loss: 3.3828976380380413
Validation loss: 2.676009942181575

Epoch: 6| Step: 12
Training loss: 3.6445846308389735
Validation loss: 2.6855308366074726

Epoch: 6| Step: 13
Training loss: 2.0399233583003205
Validation loss: 2.645333332401574

Epoch: 93| Step: 0
Training loss: 2.9092329570378905
Validation loss: 2.631624112497232

Epoch: 6| Step: 1
Training loss: 2.622378902639508
Validation loss: 2.632881320177938

Epoch: 6| Step: 2
Training loss: 2.665843558435445
Validation loss: 2.634344824058067

Epoch: 6| Step: 3
Training loss: 2.3891269752479505
Validation loss: 2.6367651275603197

Epoch: 6| Step: 4
Training loss: 3.2177993703905683
Validation loss: 2.6363483798690486

Epoch: 6| Step: 5
Training loss: 2.9291565274044564
Validation loss: 2.6379655014416055

Epoch: 6| Step: 6
Training loss: 3.0839285576705433
Validation loss: 2.639190587138705

Epoch: 6| Step: 7
Training loss: 3.408368632935128
Validation loss: 2.6336197385872957

Epoch: 6| Step: 8
Training loss: 2.9983258344363177
Validation loss: 2.6337003854209153

Epoch: 6| Step: 9
Training loss: 3.3484176428664885
Validation loss: 2.6337179094601226

Epoch: 6| Step: 10
Training loss: 3.174340102936566
Validation loss: 2.6322825220255335

Epoch: 6| Step: 11
Training loss: 3.0412045654716175
Validation loss: 2.632134577982052

Epoch: 6| Step: 12
Training loss: 2.5946420261680645
Validation loss: 2.631295449036809

Epoch: 6| Step: 13
Training loss: 3.358235010517319
Validation loss: 2.630913893932149

Epoch: 94| Step: 0
Training loss: 3.243741097557479
Validation loss: 2.6324809289703506

Epoch: 6| Step: 1
Training loss: 2.9708702145748718
Validation loss: 2.6335858674364787

Epoch: 6| Step: 2
Training loss: 2.883296109291833
Validation loss: 2.634885930453475

Epoch: 6| Step: 3
Training loss: 2.892825387178273
Validation loss: 2.633433692785582

Epoch: 6| Step: 4
Training loss: 3.4348364480963136
Validation loss: 2.6347773350914756

Epoch: 6| Step: 5
Training loss: 2.710483040218074
Validation loss: 2.633892028979389

Epoch: 6| Step: 6
Training loss: 2.9622262047545873
Validation loss: 2.647389240682804

Epoch: 6| Step: 7
Training loss: 2.9770939870598787
Validation loss: 2.6495465387318884

Epoch: 6| Step: 8
Training loss: 2.6334947556703643
Validation loss: 2.650882708364803

Epoch: 6| Step: 9
Training loss: 2.622917620896299
Validation loss: 2.6586903759497016

Epoch: 6| Step: 10
Training loss: 3.1203953196652456
Validation loss: 2.661921889414686

Epoch: 6| Step: 11
Training loss: 3.006535087914871
Validation loss: 2.651592070256645

Epoch: 6| Step: 12
Training loss: 3.3277516043653925
Validation loss: 2.6464297360682623

Epoch: 6| Step: 13
Training loss: 2.4646525119887173
Validation loss: 2.6491597137960174

Epoch: 95| Step: 0
Training loss: 3.090289097073478
Validation loss: 2.637635083596416

Epoch: 6| Step: 1
Training loss: 2.6363280960605273
Validation loss: 2.6334588887226174

Epoch: 6| Step: 2
Training loss: 3.0010602984677037
Validation loss: 2.629075190516129

Epoch: 6| Step: 3
Training loss: 3.1069776024430107
Validation loss: 2.625119973686837

Epoch: 6| Step: 4
Training loss: 2.542685591114007
Validation loss: 2.631430196492502

Epoch: 6| Step: 5
Training loss: 3.1933946146755905
Validation loss: 2.629532462295725

Epoch: 6| Step: 6
Training loss: 2.5509415440338654
Validation loss: 2.6238560955334007

Epoch: 6| Step: 7
Training loss: 2.8761632473365606
Validation loss: 2.62744302545274

Epoch: 6| Step: 8
Training loss: 3.2460107528781066
Validation loss: 2.630911295126856

Epoch: 6| Step: 9
Training loss: 2.8602495367388054
Validation loss: 2.6260095706806497

Epoch: 6| Step: 10
Training loss: 3.121080916549022
Validation loss: 2.635473817277548

Epoch: 6| Step: 11
Training loss: 2.8452407785977973
Validation loss: 2.6380552615522244

Epoch: 6| Step: 12
Training loss: 2.9515392748846363
Validation loss: 2.6376300566834496

Epoch: 6| Step: 13
Training loss: 3.6448478602092935
Validation loss: 2.636191460477759

Epoch: 96| Step: 0
Training loss: 2.456282800353514
Validation loss: 2.630221405207997

Epoch: 6| Step: 1
Training loss: 2.895629839070766
Validation loss: 2.6259235646165022

Epoch: 6| Step: 2
Training loss: 3.3643829632472984
Validation loss: 2.6406036529483963

Epoch: 6| Step: 3
Training loss: 3.054455214154144
Validation loss: 2.62706001693414

Epoch: 6| Step: 4
Training loss: 2.6096433398759
Validation loss: 2.6164248676974085

Epoch: 6| Step: 5
Training loss: 3.211254688941083
Validation loss: 2.62971541445032

Epoch: 6| Step: 6
Training loss: 3.079197730568862
Validation loss: 2.617227923357028

Epoch: 6| Step: 7
Training loss: 2.628330207279389
Validation loss: 2.6144060944940053

Epoch: 6| Step: 8
Training loss: 3.0223886804771594
Validation loss: 2.6178478874047904

Epoch: 6| Step: 9
Training loss: 2.334623445620946
Validation loss: 2.617803555405536

Epoch: 6| Step: 10
Training loss: 2.88413644384821
Validation loss: 2.621276720953871

Epoch: 6| Step: 11
Training loss: 3.030688046936173
Validation loss: 2.6291080388815513

Epoch: 6| Step: 12
Training loss: 3.628610063010337
Validation loss: 2.627344106384292

Epoch: 6| Step: 13
Training loss: 3.114386272681786
Validation loss: 2.621174260436373

Epoch: 97| Step: 0
Training loss: 3.542998897335905
Validation loss: 2.613842497936201

Epoch: 6| Step: 1
Training loss: 2.4873928717926765
Validation loss: 2.612046267899641

Epoch: 6| Step: 2
Training loss: 3.0185314660118605
Validation loss: 2.6088962755625498

Epoch: 6| Step: 3
Training loss: 3.1009946827035613
Validation loss: 2.6110434387759596

Epoch: 6| Step: 4
Training loss: 3.1868234552201367
Validation loss: 2.606841708300121

Epoch: 6| Step: 5
Training loss: 3.3528953338496827
Validation loss: 2.609112668471832

Epoch: 6| Step: 6
Training loss: 2.9847260113950402
Validation loss: 2.6121667079694926

Epoch: 6| Step: 7
Training loss: 2.5415387564403344
Validation loss: 2.6138202142050404

Epoch: 6| Step: 8
Training loss: 2.790371029564975
Validation loss: 2.614273600724635

Epoch: 6| Step: 9
Training loss: 2.529641005033988
Validation loss: 2.6160925896231135

Epoch: 6| Step: 10
Training loss: 2.70579740690961
Validation loss: 2.615697775105826

Epoch: 6| Step: 11
Training loss: 3.2365547243580863
Validation loss: 2.6169961339284153

Epoch: 6| Step: 12
Training loss: 2.3259424821953267
Validation loss: 2.616296902255792

Epoch: 6| Step: 13
Training loss: 3.625126014360758
Validation loss: 2.6184290059996256

Epoch: 98| Step: 0
Training loss: 2.6260542796002406
Validation loss: 2.6170603173150497

Epoch: 6| Step: 1
Training loss: 3.507223984726457
Validation loss: 2.613571247285298

Epoch: 6| Step: 2
Training loss: 3.041075052355673
Validation loss: 2.6119538413936705

Epoch: 6| Step: 3
Training loss: 3.0536199006557223
Validation loss: 2.6102917614108962

Epoch: 6| Step: 4
Training loss: 2.7222776656008385
Validation loss: 2.613736986908712

Epoch: 6| Step: 5
Training loss: 2.540005646646786
Validation loss: 2.609352766539978

Epoch: 6| Step: 6
Training loss: 2.1243105499196675
Validation loss: 2.6098243160004464

Epoch: 6| Step: 7
Training loss: 3.4120737389470657
Validation loss: 2.604965978864825

Epoch: 6| Step: 8
Training loss: 3.1764482874492628
Validation loss: 2.604351232735779

Epoch: 6| Step: 9
Training loss: 2.476275984017823
Validation loss: 2.6074861328151417

Epoch: 6| Step: 10
Training loss: 3.6685921786153943
Validation loss: 2.6079057085500215

Epoch: 6| Step: 11
Training loss: 2.3973728264740575
Validation loss: 2.617650432904535

Epoch: 6| Step: 12
Training loss: 3.0681632481279553
Validation loss: 2.648713183467778

Epoch: 6| Step: 13
Training loss: 3.2202507890454966
Validation loss: 2.6778022273614908

Epoch: 99| Step: 0
Training loss: 2.372394035553626
Validation loss: 2.694817797806859

Epoch: 6| Step: 1
Training loss: 3.618556115947052
Validation loss: 2.7155408144810798

Epoch: 6| Step: 2
Training loss: 2.8424134519581346
Validation loss: 2.702820063560873

Epoch: 6| Step: 3
Training loss: 2.9063983182079554
Validation loss: 2.6835722938467144

Epoch: 6| Step: 4
Training loss: 2.595785330567872
Validation loss: 2.6631373660374478

Epoch: 6| Step: 5
Training loss: 2.978361772409637
Validation loss: 2.6313980152492373

Epoch: 6| Step: 6
Training loss: 3.1576840004123214
Validation loss: 2.627986802087115

Epoch: 6| Step: 7
Training loss: 3.4139226889189405
Validation loss: 2.613892300211648

Epoch: 6| Step: 8
Training loss: 3.306955844119491
Validation loss: 2.602104063880957

Epoch: 6| Step: 9
Training loss: 2.6907187415617053
Validation loss: 2.599902132793884

Epoch: 6| Step: 10
Training loss: 2.3393056820814913
Validation loss: 2.5991851341393364

Epoch: 6| Step: 11
Training loss: 2.997059175402898
Validation loss: 2.596207499363806

Epoch: 6| Step: 12
Training loss: 3.036304781887949
Validation loss: 2.596607319129701

Epoch: 6| Step: 13
Training loss: 2.469611102233883
Validation loss: 2.5968402492244085

Epoch: 100| Step: 0
Training loss: 2.8689707685638806
Validation loss: 2.597596467525522

Epoch: 6| Step: 1
Training loss: 3.2265129916847157
Validation loss: 2.595175890705988

Epoch: 6| Step: 2
Training loss: 3.246164259162025
Validation loss: 2.5965794967556293

Epoch: 6| Step: 3
Training loss: 2.885206928732573
Validation loss: 2.5937452685652373

Epoch: 6| Step: 4
Training loss: 3.1207391301101546
Validation loss: 2.5946494395098725

Epoch: 6| Step: 5
Training loss: 2.875582428691485
Validation loss: 2.5921979526257433

Epoch: 6| Step: 6
Training loss: 2.755309181795462
Validation loss: 2.5936755868848036

Epoch: 6| Step: 7
Training loss: 2.8823668592925245
Validation loss: 2.593328249668249

Epoch: 6| Step: 8
Training loss: 3.2021654133813513
Validation loss: 2.5896878348760017

Epoch: 6| Step: 9
Training loss: 3.4174388540137555
Validation loss: 2.594284748728736

Epoch: 6| Step: 10
Training loss: 2.766920055904066
Validation loss: 2.597399906472814

Epoch: 6| Step: 11
Training loss: 2.5989304249908023
Validation loss: 2.5976505205151526

Epoch: 6| Step: 12
Training loss: 2.480881159582702
Validation loss: 2.597873390677344

Epoch: 6| Step: 13
Training loss: 2.467053276986632
Validation loss: 2.599123606473004

Epoch: 101| Step: 0
Training loss: 3.023164958646402
Validation loss: 2.604577423843929

Epoch: 6| Step: 1
Training loss: 2.608279060879765
Validation loss: 2.6049366671951546

Epoch: 6| Step: 2
Training loss: 3.672432325556322
Validation loss: 2.6128703269054605

Epoch: 6| Step: 3
Training loss: 3.2002231758494815
Validation loss: 2.6106492030491357

Epoch: 6| Step: 4
Training loss: 2.9521986704397274
Validation loss: 2.6031284242977852

Epoch: 6| Step: 5
Training loss: 2.3855249194329016
Validation loss: 2.594838154935306

Epoch: 6| Step: 6
Training loss: 2.416441304013948
Validation loss: 2.5929777021317535

Epoch: 6| Step: 7
Training loss: 3.1364089223736
Validation loss: 2.593141889987454

Epoch: 6| Step: 8
Training loss: 2.8754736468706605
Validation loss: 2.592386200750496

Epoch: 6| Step: 9
Training loss: 2.906792046645478
Validation loss: 2.590086330098367

Epoch: 6| Step: 10
Training loss: 2.97898593879037
Validation loss: 2.591281880413122

Epoch: 6| Step: 11
Training loss: 2.728739571579819
Validation loss: 2.592133694613585

Epoch: 6| Step: 12
Training loss: 3.0368046156881325
Validation loss: 2.5901115785194215

Epoch: 6| Step: 13
Training loss: 3.176812599195186
Validation loss: 2.590281149996264

Epoch: 102| Step: 0
Training loss: 2.569543323389895
Validation loss: 2.5855557716033295

Epoch: 6| Step: 1
Training loss: 3.0011298912892204
Validation loss: 2.588316207009879

Epoch: 6| Step: 2
Training loss: 3.110825396845378
Validation loss: 2.5873961902775267

Epoch: 6| Step: 3
Training loss: 2.3724264958755876
Validation loss: 2.5893714350488515

Epoch: 6| Step: 4
Training loss: 2.5595677043576943
Validation loss: 2.5885353869877843

Epoch: 6| Step: 5
Training loss: 2.7100467152809613
Validation loss: 2.5936014078737477

Epoch: 6| Step: 6
Training loss: 3.043510104836149
Validation loss: 2.5981145935056214

Epoch: 6| Step: 7
Training loss: 2.980628253073506
Validation loss: 2.5989178145487983

Epoch: 6| Step: 8
Training loss: 3.1145409078270783
Validation loss: 2.596718635262827

Epoch: 6| Step: 9
Training loss: 3.1488809202325654
Validation loss: 2.592966366822504

Epoch: 6| Step: 10
Training loss: 3.22539626651514
Validation loss: 2.592889867761243

Epoch: 6| Step: 11
Training loss: 2.773759678139978
Validation loss: 2.5898517977310584

Epoch: 6| Step: 12
Training loss: 2.7544053944260387
Validation loss: 2.5901617143502587

Epoch: 6| Step: 13
Training loss: 3.949950258931708
Validation loss: 2.5888517444154155

Epoch: 103| Step: 0
Training loss: 3.1169528347016873
Validation loss: 2.588515423766955

Epoch: 6| Step: 1
Training loss: 2.989253824574684
Validation loss: 2.5885987667423893

Epoch: 6| Step: 2
Training loss: 3.0221665345309754
Validation loss: 2.5872524323560264

Epoch: 6| Step: 3
Training loss: 3.111804415639165
Validation loss: 2.5895292492388244

Epoch: 6| Step: 4
Training loss: 2.9864271208656987
Validation loss: 2.586384900761983

Epoch: 6| Step: 5
Training loss: 3.40689234845159
Validation loss: 2.5897843103469493

Epoch: 6| Step: 6
Training loss: 2.299613721171789
Validation loss: 2.585671290493997

Epoch: 6| Step: 7
Training loss: 2.876685436300999
Validation loss: 2.5869892339708462

Epoch: 6| Step: 8
Training loss: 3.338052619587908
Validation loss: 2.588744842471396

Epoch: 6| Step: 9
Training loss: 2.201897028678304
Validation loss: 2.58982320886975

Epoch: 6| Step: 10
Training loss: 2.662674080615673
Validation loss: 2.5890449422084427

Epoch: 6| Step: 11
Training loss: 2.90666261430627
Validation loss: 2.5969549009005566

Epoch: 6| Step: 12
Training loss: 3.1455634466614493
Validation loss: 2.623907157664228

Epoch: 6| Step: 13
Training loss: 2.6408794212793616
Validation loss: 2.6035138722615785

Epoch: 104| Step: 0
Training loss: 2.903563211175032
Validation loss: 2.584071021949905

Epoch: 6| Step: 1
Training loss: 3.051942963133441
Validation loss: 2.583795512757362

Epoch: 6| Step: 2
Training loss: 3.1656273257217826
Validation loss: 2.581373772194608

Epoch: 6| Step: 3
Training loss: 1.8785971151291805
Validation loss: 2.5842534476566

Epoch: 6| Step: 4
Training loss: 3.209961680245959
Validation loss: 2.588310049271985

Epoch: 6| Step: 5
Training loss: 3.101997710088774
Validation loss: 2.594690324653

Epoch: 6| Step: 6
Training loss: 2.963629553128027
Validation loss: 2.6090972548218487

Epoch: 6| Step: 7
Training loss: 2.7847746899345287
Validation loss: 2.6224743695198605

Epoch: 6| Step: 8
Training loss: 3.376224436996837
Validation loss: 2.6161813147757567

Epoch: 6| Step: 9
Training loss: 3.0432341904244824
Validation loss: 2.6146171484947334

Epoch: 6| Step: 10
Training loss: 2.7694263088644755
Validation loss: 2.622839197028335

Epoch: 6| Step: 11
Training loss: 2.8836281715721888
Validation loss: 2.6192489231765697

Epoch: 6| Step: 12
Training loss: 2.949444126839604
Validation loss: 2.633287293216122

Epoch: 6| Step: 13
Training loss: 2.553600208223186
Validation loss: 2.6428221912957617

Epoch: 105| Step: 0
Training loss: 2.9800484337167013
Validation loss: 2.6554628773096227

Epoch: 6| Step: 1
Training loss: 2.893729527444286
Validation loss: 2.665334432845298

Epoch: 6| Step: 2
Training loss: 3.1031296467818303
Validation loss: 2.6347742010538138

Epoch: 6| Step: 3
Training loss: 2.7733776677084823
Validation loss: 2.617821796945335

Epoch: 6| Step: 4
Training loss: 3.3584607676772618
Validation loss: 2.5986496644258015

Epoch: 6| Step: 5
Training loss: 3.644174572662517
Validation loss: 2.597221724665682

Epoch: 6| Step: 6
Training loss: 2.5350664355057795
Validation loss: 2.59227815249601

Epoch: 6| Step: 7
Training loss: 2.6800148989135186
Validation loss: 2.601828698519872

Epoch: 6| Step: 8
Training loss: 3.099584760850599
Validation loss: 2.607616225560871

Epoch: 6| Step: 9
Training loss: 2.464379606965819
Validation loss: 2.60899254236874

Epoch: 6| Step: 10
Training loss: 2.934732635121714
Validation loss: 2.596442627660547

Epoch: 6| Step: 11
Training loss: 3.095411682850623
Validation loss: 2.5932697504368667

Epoch: 6| Step: 12
Training loss: 2.5699585088208226
Validation loss: 2.595851748908515

Epoch: 6| Step: 13
Training loss: 2.771437834764935
Validation loss: 2.596419122305732

Epoch: 106| Step: 0
Training loss: 2.9069281986530084
Validation loss: 2.597244396586292

Epoch: 6| Step: 1
Training loss: 2.9052960870965854
Validation loss: 2.5929413291090464

Epoch: 6| Step: 2
Training loss: 3.3666455038431597
Validation loss: 2.593959415905504

Epoch: 6| Step: 3
Training loss: 2.9939601816448564
Validation loss: 2.5940671327343083

Epoch: 6| Step: 4
Training loss: 2.912615296533441
Validation loss: 2.5966448857728492

Epoch: 6| Step: 5
Training loss: 2.8449121133808912
Validation loss: 2.6080850772081554

Epoch: 6| Step: 6
Training loss: 3.0557013582834998
Validation loss: 2.6129258079013797

Epoch: 6| Step: 7
Training loss: 2.588448311077247
Validation loss: 2.6226767041001735

Epoch: 6| Step: 8
Training loss: 2.8882482706859043
Validation loss: 2.6236284621398047

Epoch: 6| Step: 9
Training loss: 2.66622845704952
Validation loss: 2.6172000204541983

Epoch: 6| Step: 10
Training loss: 2.8947697797297662
Validation loss: 2.610798741651574

Epoch: 6| Step: 11
Training loss: 2.7275825057238885
Validation loss: 2.590076941926547

Epoch: 6| Step: 12
Training loss: 2.79615288474987
Validation loss: 2.586494068912875

Epoch: 6| Step: 13
Training loss: 3.7732459230936137
Validation loss: 2.5799637895437186

Epoch: 107| Step: 0
Training loss: 2.546729148011724
Validation loss: 2.5757606889284657

Epoch: 6| Step: 1
Training loss: 2.9433473866502706
Validation loss: 2.575899416317292

Epoch: 6| Step: 2
Training loss: 2.7186249452089566
Validation loss: 2.573577603331604

Epoch: 6| Step: 3
Training loss: 3.1033029741495164
Validation loss: 2.574068889973536

Epoch: 6| Step: 4
Training loss: 3.079401980963799
Validation loss: 2.575181193099178

Epoch: 6| Step: 5
Training loss: 3.3285207020667475
Validation loss: 2.5728742830066107

Epoch: 6| Step: 6
Training loss: 2.2469134883210398
Validation loss: 2.573216962849282

Epoch: 6| Step: 7
Training loss: 3.434132539140957
Validation loss: 2.5690889632736225

Epoch: 6| Step: 8
Training loss: 3.129879613151641
Validation loss: 2.5697132864222256

Epoch: 6| Step: 9
Training loss: 2.691148189137346
Validation loss: 2.566859159401626

Epoch: 6| Step: 10
Training loss: 3.498369382030703
Validation loss: 2.5623257085281606

Epoch: 6| Step: 11
Training loss: 2.2037151439071794
Validation loss: 2.563747389527633

Epoch: 6| Step: 12
Training loss: 2.570054432630198
Validation loss: 2.5654901905636245

Epoch: 6| Step: 13
Training loss: 3.057209037604294
Validation loss: 2.5678864119265485

Epoch: 108| Step: 0
Training loss: 3.0061287266623578
Validation loss: 2.56440671628816

Epoch: 6| Step: 1
Training loss: 3.4726095636274006
Validation loss: 2.564206097388408

Epoch: 6| Step: 2
Training loss: 2.8002432036363767
Validation loss: 2.5630584936550487

Epoch: 6| Step: 3
Training loss: 3.1135073092723866
Validation loss: 2.5645693135436662

Epoch: 6| Step: 4
Training loss: 2.8008720776928326
Validation loss: 2.5640537184700203

Epoch: 6| Step: 5
Training loss: 2.5445107561972145
Validation loss: 2.568810997944736

Epoch: 6| Step: 6
Training loss: 3.1573147630156146
Validation loss: 2.5679603623868243

Epoch: 6| Step: 7
Training loss: 2.8035842298192875
Validation loss: 2.5730932071443133

Epoch: 6| Step: 8
Training loss: 3.4790318323988827
Validation loss: 2.5849074953897886

Epoch: 6| Step: 9
Training loss: 2.5447445249205347
Validation loss: 2.5864359434105273

Epoch: 6| Step: 10
Training loss: 2.7612525298217956
Validation loss: 2.597571668867786

Epoch: 6| Step: 11
Training loss: 2.798228527724564
Validation loss: 2.5878714800246643

Epoch: 6| Step: 12
Training loss: 2.514707220186731
Validation loss: 2.5919130182777215

Epoch: 6| Step: 13
Training loss: 2.816673488345341
Validation loss: 2.576946461752296

Epoch: 109| Step: 0
Training loss: 2.8927533536454253
Validation loss: 2.5729843282868

Epoch: 6| Step: 1
Training loss: 3.0085185225558315
Validation loss: 2.5665176394149634

Epoch: 6| Step: 2
Training loss: 2.5451683457910494
Validation loss: 2.5636560197041764

Epoch: 6| Step: 3
Training loss: 3.13503439633423
Validation loss: 2.56262362302269

Epoch: 6| Step: 4
Training loss: 3.046311233399717
Validation loss: 2.564768605603904

Epoch: 6| Step: 5
Training loss: 2.4215707895508967
Validation loss: 2.563888162800579

Epoch: 6| Step: 6
Training loss: 2.3334760168137407
Validation loss: 2.5614576333106758

Epoch: 6| Step: 7
Training loss: 3.24101703152276
Validation loss: 2.57023837583624

Epoch: 6| Step: 8
Training loss: 3.0058517604679382
Validation loss: 2.5721889169253527

Epoch: 6| Step: 9
Training loss: 3.249705081176448
Validation loss: 2.5741747830398016

Epoch: 6| Step: 10
Training loss: 3.2032376897574304
Validation loss: 2.5773525767641825

Epoch: 6| Step: 11
Training loss: 2.9042492614414157
Validation loss: 2.571677045623024

Epoch: 6| Step: 12
Training loss: 3.009318502337488
Validation loss: 2.5756840003399706

Epoch: 6| Step: 13
Training loss: 2.090957601459454
Validation loss: 2.574863629981761

Epoch: 110| Step: 0
Training loss: 2.556169645730006
Validation loss: 2.5715674867233567

Epoch: 6| Step: 1
Training loss: 3.0397617349612243
Validation loss: 2.566281035022

Epoch: 6| Step: 2
Training loss: 2.559046115634132
Validation loss: 2.560720578738099

Epoch: 6| Step: 3
Training loss: 2.650142694626062
Validation loss: 2.5587497162971666

Epoch: 6| Step: 4
Training loss: 2.934724836041916
Validation loss: 2.5589380426693547

Epoch: 6| Step: 5
Training loss: 3.337271573254101
Validation loss: 2.5533347036332903

Epoch: 6| Step: 6
Training loss: 2.755103663936376
Validation loss: 2.5501169789132767

Epoch: 6| Step: 7
Training loss: 2.685436432388125
Validation loss: 2.5544485955297977

Epoch: 6| Step: 8
Training loss: 2.855569276723126
Validation loss: 2.5542594578919413

Epoch: 6| Step: 9
Training loss: 3.321413822405014
Validation loss: 2.5572213168102365

Epoch: 6| Step: 10
Training loss: 2.6610713510677675
Validation loss: 2.5554066642029256

Epoch: 6| Step: 11
Training loss: 2.7482600342935113
Validation loss: 2.558090435748109

Epoch: 6| Step: 12
Training loss: 3.078075582814377
Validation loss: 2.559677367236848

Epoch: 6| Step: 13
Training loss: 3.622826812723765
Validation loss: 2.5568742322200575

Epoch: 111| Step: 0
Training loss: 3.1166584837562996
Validation loss: 2.5532491201559484

Epoch: 6| Step: 1
Training loss: 3.2485741642052437
Validation loss: 2.550925660303999

Epoch: 6| Step: 2
Training loss: 2.9178239615391854
Validation loss: 2.549070721223181

Epoch: 6| Step: 3
Training loss: 3.0753119147670063
Validation loss: 2.5502012566077

Epoch: 6| Step: 4
Training loss: 2.8631893210856503
Validation loss: 2.5491016819952863

Epoch: 6| Step: 5
Training loss: 2.8912316587850135
Validation loss: 2.5495050397917547

Epoch: 6| Step: 6
Training loss: 3.072708243505561
Validation loss: 2.5481112235629952

Epoch: 6| Step: 7
Training loss: 2.6422123398563486
Validation loss: 2.5478973812814614

Epoch: 6| Step: 8
Training loss: 2.2553558183917923
Validation loss: 2.54713761197287

Epoch: 6| Step: 9
Training loss: 3.5428476197250984
Validation loss: 2.5456177193635803

Epoch: 6| Step: 10
Training loss: 2.546612872342797
Validation loss: 2.5485503047230527

Epoch: 6| Step: 11
Training loss: 2.3404444463175853
Validation loss: 2.55032052658251

Epoch: 6| Step: 12
Training loss: 2.9091942752550506
Validation loss: 2.5600369559252782

Epoch: 6| Step: 13
Training loss: 3.1632987902101535
Validation loss: 2.56535474470388

Epoch: 112| Step: 0
Training loss: 2.535255935660492
Validation loss: 2.5578759764804655

Epoch: 6| Step: 1
Training loss: 3.334243379978605
Validation loss: 2.554568414345105

Epoch: 6| Step: 2
Training loss: 3.3149028196517847
Validation loss: 2.5497754304328977

Epoch: 6| Step: 3
Training loss: 2.9906298215821243
Validation loss: 2.54912477686721

Epoch: 6| Step: 4
Training loss: 2.9591242489629903
Validation loss: 2.5459691196961676

Epoch: 6| Step: 5
Training loss: 2.7314234034751026
Validation loss: 2.5469554186586905

Epoch: 6| Step: 6
Training loss: 2.046975985067036
Validation loss: 2.5461852433553083

Epoch: 6| Step: 7
Training loss: 2.576456443218571
Validation loss: 2.5475376851625247

Epoch: 6| Step: 8
Training loss: 3.184307968437413
Validation loss: 2.5485967517026644

Epoch: 6| Step: 9
Training loss: 3.041223066895085
Validation loss: 2.543359100871321

Epoch: 6| Step: 10
Training loss: 2.7127207406930194
Validation loss: 2.545701260312308

Epoch: 6| Step: 11
Training loss: 3.364897548935412
Validation loss: 2.5499234859014797

Epoch: 6| Step: 12
Training loss: 2.3571943095813204
Validation loss: 2.5478913331327946

Epoch: 6| Step: 13
Training loss: 3.2019892470055944
Validation loss: 2.5501052459932048

Epoch: 113| Step: 0
Training loss: 2.9905316026347926
Validation loss: 2.5530848440121967

Epoch: 6| Step: 1
Training loss: 3.3567261654663993
Validation loss: 2.5523040943876976

Epoch: 6| Step: 2
Training loss: 2.284784792191785
Validation loss: 2.563063366756983

Epoch: 6| Step: 3
Training loss: 3.183869332397492
Validation loss: 2.5716720911493454

Epoch: 6| Step: 4
Training loss: 2.5743571173335527
Validation loss: 2.567088733902985

Epoch: 6| Step: 5
Training loss: 2.868695519954332
Validation loss: 2.5762110462292656

Epoch: 6| Step: 6
Training loss: 3.4232113810964067
Validation loss: 2.578654447989905

Epoch: 6| Step: 7
Training loss: 2.689448337924661
Validation loss: 2.57642094542859

Epoch: 6| Step: 8
Training loss: 2.2739418754966465
Validation loss: 2.563792777235837

Epoch: 6| Step: 9
Training loss: 2.882858482759119
Validation loss: 2.563837132219842

Epoch: 6| Step: 10
Training loss: 2.921631338802109
Validation loss: 2.5522363303362368

Epoch: 6| Step: 11
Training loss: 3.0452585480766308
Validation loss: 2.552349970845099

Epoch: 6| Step: 12
Training loss: 3.2238427029992702
Validation loss: 2.5446459222426054

Epoch: 6| Step: 13
Training loss: 2.3164089260761314
Validation loss: 2.5381881473028964

Epoch: 114| Step: 0
Training loss: 3.08609201551455
Validation loss: 2.5423501381949776

Epoch: 6| Step: 1
Training loss: 2.8313175959654604
Validation loss: 2.5386226917443917

Epoch: 6| Step: 2
Training loss: 3.40805076105524
Validation loss: 2.539029155098908

Epoch: 6| Step: 3
Training loss: 2.594328482589229
Validation loss: 2.536842749816191

Epoch: 6| Step: 4
Training loss: 2.4317311220296154
Validation loss: 2.538196972910624

Epoch: 6| Step: 5
Training loss: 2.8840618786039767
Validation loss: 2.53853334224741

Epoch: 6| Step: 6
Training loss: 3.046999884760335
Validation loss: 2.541222439870255

Epoch: 6| Step: 7
Training loss: 2.4330548566912635
Validation loss: 2.5402930128581023

Epoch: 6| Step: 8
Training loss: 2.8055953997645804
Validation loss: 2.5423158865131392

Epoch: 6| Step: 9
Training loss: 3.4091901776281603
Validation loss: 2.542514464624914

Epoch: 6| Step: 10
Training loss: 2.881078513911121
Validation loss: 2.5396787924413555

Epoch: 6| Step: 11
Training loss: 2.7411411821481853
Validation loss: 2.5364070928513445

Epoch: 6| Step: 12
Training loss: 2.8278298408380462
Validation loss: 2.536143494091048

Epoch: 6| Step: 13
Training loss: 3.0562610524607634
Validation loss: 2.535327382728811

Epoch: 115| Step: 0
Training loss: 3.5829469930873157
Validation loss: 2.5394335777404304

Epoch: 6| Step: 1
Training loss: 2.790538749771637
Validation loss: 2.538223912135948

Epoch: 6| Step: 2
Training loss: 3.1006517586517477
Validation loss: 2.5332604995527293

Epoch: 6| Step: 3
Training loss: 2.9339932551914276
Validation loss: 2.538742740459741

Epoch: 6| Step: 4
Training loss: 2.5475511647964715
Validation loss: 2.53492180032992

Epoch: 6| Step: 5
Training loss: 2.5490958237653194
Validation loss: 2.5350273970884563

Epoch: 6| Step: 6
Training loss: 3.1247538660393137
Validation loss: 2.5372362913225515

Epoch: 6| Step: 7
Training loss: 2.09274882962084
Validation loss: 2.53386863000608

Epoch: 6| Step: 8
Training loss: 2.566190341826459
Validation loss: 2.5339257122769405

Epoch: 6| Step: 9
Training loss: 2.7514870697721423
Validation loss: 2.5341352302185576

Epoch: 6| Step: 10
Training loss: 2.839891268032212
Validation loss: 2.53393585077125

Epoch: 6| Step: 11
Training loss: 3.0740686013999885
Validation loss: 2.5385067981474623

Epoch: 6| Step: 12
Training loss: 2.9893908466395236
Validation loss: 2.5448222133702805

Epoch: 6| Step: 13
Training loss: 3.5921607442542203
Validation loss: 2.551869071787662

Epoch: 116| Step: 0
Training loss: 3.1841113459608414
Validation loss: 2.5474776644528974

Epoch: 6| Step: 1
Training loss: 3.0463666442904263
Validation loss: 2.5471540940204127

Epoch: 6| Step: 2
Training loss: 3.4738506584504747
Validation loss: 2.5408574501731027

Epoch: 6| Step: 3
Training loss: 2.986851648182332
Validation loss: 2.53670943277895

Epoch: 6| Step: 4
Training loss: 2.720253714901884
Validation loss: 2.5361577064912626

Epoch: 6| Step: 5
Training loss: 2.994137758376808
Validation loss: 2.5350970657255703

Epoch: 6| Step: 6
Training loss: 2.55921669867536
Validation loss: 2.538380398817097

Epoch: 6| Step: 7
Training loss: 2.1840538127124365
Validation loss: 2.5373419362408827

Epoch: 6| Step: 8
Training loss: 2.9173405186752364
Validation loss: 2.5350871604207903

Epoch: 6| Step: 9
Training loss: 3.4925337583511853
Validation loss: 2.534980481020781

Epoch: 6| Step: 10
Training loss: 2.436173004452535
Validation loss: 2.543344180791818

Epoch: 6| Step: 11
Training loss: 2.6777678528632993
Validation loss: 2.5449194442504086

Epoch: 6| Step: 12
Training loss: 2.3634010978133837
Validation loss: 2.541808811437843

Epoch: 6| Step: 13
Training loss: 3.147281103059402
Validation loss: 2.543432172919246

Epoch: 117| Step: 0
Training loss: 3.1053489805913546
Validation loss: 2.541486552846712

Epoch: 6| Step: 1
Training loss: 2.7861445360174395
Validation loss: 2.5379233637896257

Epoch: 6| Step: 2
Training loss: 3.4006957520337497
Validation loss: 2.535229060962228

Epoch: 6| Step: 3
Training loss: 2.640229867117767
Validation loss: 2.533987878081341

Epoch: 6| Step: 4
Training loss: 3.251411424946474
Validation loss: 2.535455394312965

Epoch: 6| Step: 5
Training loss: 3.1666321668920605
Validation loss: 2.5351129950329585

Epoch: 6| Step: 6
Training loss: 2.5226847467735647
Validation loss: 2.533739009422774

Epoch: 6| Step: 7
Training loss: 2.496168060868127
Validation loss: 2.5321018350941387

Epoch: 6| Step: 8
Training loss: 3.15308440440333
Validation loss: 2.532445048450195

Epoch: 6| Step: 9
Training loss: 2.6792497193874802
Validation loss: 2.5388285302082254

Epoch: 6| Step: 10
Training loss: 2.8514079848976173
Validation loss: 2.534488102200725

Epoch: 6| Step: 11
Training loss: 2.404963260774486
Validation loss: 2.543831835192288

Epoch: 6| Step: 12
Training loss: 2.5881821953967235
Validation loss: 2.5489447260599363

Epoch: 6| Step: 13
Training loss: 3.193127768980697
Validation loss: 2.558294922299589

Epoch: 118| Step: 0
Training loss: 2.586417807605818
Validation loss: 2.560540639467476

Epoch: 6| Step: 1
Training loss: 3.1996643724862173
Validation loss: 2.565474223033775

Epoch: 6| Step: 2
Training loss: 2.449002927187272
Validation loss: 2.5544875684726662

Epoch: 6| Step: 3
Training loss: 3.044881471729217
Validation loss: 2.569361550471095

Epoch: 6| Step: 4
Training loss: 2.6462425656365145
Validation loss: 2.5496433557172957

Epoch: 6| Step: 5
Training loss: 2.4070995862175604
Validation loss: 2.541387768786321

Epoch: 6| Step: 6
Training loss: 3.0732206205054338
Validation loss: 2.54184937959306

Epoch: 6| Step: 7
Training loss: 2.5699580449639163
Validation loss: 2.5397531584471316

Epoch: 6| Step: 8
Training loss: 3.3561415613937897
Validation loss: 2.5406728731848296

Epoch: 6| Step: 9
Training loss: 2.8667384323481544
Validation loss: 2.541721019301565

Epoch: 6| Step: 10
Training loss: 2.940834101216263
Validation loss: 2.54152535789261

Epoch: 6| Step: 11
Training loss: 3.1045574650556893
Validation loss: 2.5389109101964316

Epoch: 6| Step: 12
Training loss: 2.9182156582179894
Validation loss: 2.543369289959227

Epoch: 6| Step: 13
Training loss: 3.044986393840188
Validation loss: 2.547596580423773

Epoch: 119| Step: 0
Training loss: 2.780849985223911
Validation loss: 2.544445467179377

Epoch: 6| Step: 1
Training loss: 3.528282066072461
Validation loss: 2.5492065998600024

Epoch: 6| Step: 2
Training loss: 3.6179841649355806
Validation loss: 2.546589779857949

Epoch: 6| Step: 3
Training loss: 2.8794186678258553
Validation loss: 2.5485035913289003

Epoch: 6| Step: 4
Training loss: 2.645329545084999
Validation loss: 2.544896136940964

Epoch: 6| Step: 5
Training loss: 3.139102243994992
Validation loss: 2.5558054796081158

Epoch: 6| Step: 6
Training loss: 2.579890715775899
Validation loss: 2.5505840834178803

Epoch: 6| Step: 7
Training loss: 2.4439144342618477
Validation loss: 2.5504318304766875

Epoch: 6| Step: 8
Training loss: 2.7259688728553684
Validation loss: 2.539642002054888

Epoch: 6| Step: 9
Training loss: 2.658391919183058
Validation loss: 2.5333744473459223

Epoch: 6| Step: 10
Training loss: 2.897711896940567
Validation loss: 2.5351713032107046

Epoch: 6| Step: 11
Training loss: 2.8596681538376516
Validation loss: 2.538232985071775

Epoch: 6| Step: 12
Training loss: 2.021656091740503
Validation loss: 2.5443608693603825

Epoch: 6| Step: 13
Training loss: 3.5853604785359257
Validation loss: 2.554054937829876

Epoch: 120| Step: 0
Training loss: 3.469182580316829
Validation loss: 2.5632504280539252

Epoch: 6| Step: 1
Training loss: 3.2077656693716903
Validation loss: 2.583633179849651

Epoch: 6| Step: 2
Training loss: 3.3923245578455075
Validation loss: 2.6099850886589273

Epoch: 6| Step: 3
Training loss: 2.905009999873535
Validation loss: 2.6071231732551423

Epoch: 6| Step: 4
Training loss: 3.035774865066919
Validation loss: 2.55074021785175

Epoch: 6| Step: 5
Training loss: 2.4071486145151195
Validation loss: 2.536765650735646

Epoch: 6| Step: 6
Training loss: 2.848033989864214
Validation loss: 2.52686517551201

Epoch: 6| Step: 7
Training loss: 2.701845428495572
Validation loss: 2.521333189461589

Epoch: 6| Step: 8
Training loss: 2.7139354476223425
Validation loss: 2.526283645499599

Epoch: 6| Step: 9
Training loss: 3.494607858992875
Validation loss: 2.5298742751060366

Epoch: 6| Step: 10
Training loss: 2.7555262785385133
Validation loss: 2.5297637803706787

Epoch: 6| Step: 11
Training loss: 1.993380798786867
Validation loss: 2.5267415536744626

Epoch: 6| Step: 12
Training loss: 2.633739908033389
Validation loss: 2.539162254424838

Epoch: 6| Step: 13
Training loss: 2.139549374953181
Validation loss: 2.5450077828279563

Epoch: 121| Step: 0
Training loss: 2.622160602059291
Validation loss: 2.5558931289891946

Epoch: 6| Step: 1
Training loss: 3.578531300494062
Validation loss: 2.5644389664481437

Epoch: 6| Step: 2
Training loss: 2.9075088235814697
Validation loss: 2.5493661331143915

Epoch: 6| Step: 3
Training loss: 2.627050960945335
Validation loss: 2.5497830063955726

Epoch: 6| Step: 4
Training loss: 2.9637222279728035
Validation loss: 2.5471995680565227

Epoch: 6| Step: 5
Training loss: 2.5770635095778025
Validation loss: 2.5380313457411043

Epoch: 6| Step: 6
Training loss: 2.796986156790787
Validation loss: 2.5294626727448732

Epoch: 6| Step: 7
Training loss: 3.116171152499869
Validation loss: 2.527450882580578

Epoch: 6| Step: 8
Training loss: 2.6393613782707783
Validation loss: 2.526531984226354

Epoch: 6| Step: 9
Training loss: 2.754767879670049
Validation loss: 2.5246975444174233

Epoch: 6| Step: 10
Training loss: 2.891339682817982
Validation loss: 2.530024540890908

Epoch: 6| Step: 11
Training loss: 3.116096630767453
Validation loss: 2.5296984188268787

Epoch: 6| Step: 12
Training loss: 2.70088526376785
Validation loss: 2.539256162365011

Epoch: 6| Step: 13
Training loss: 2.761310897991425
Validation loss: 2.547398881540166

Epoch: 122| Step: 0
Training loss: 2.689068358801179
Validation loss: 2.5544213005170917

Epoch: 6| Step: 1
Training loss: 2.7812162247224985
Validation loss: 2.5702506701662897

Epoch: 6| Step: 2
Training loss: 3.11384391725726
Validation loss: 2.5604146720508463

Epoch: 6| Step: 3
Training loss: 3.208557583456688
Validation loss: 2.56447957548065

Epoch: 6| Step: 4
Training loss: 3.1016356798278
Validation loss: 2.570017267342096

Epoch: 6| Step: 5
Training loss: 3.1210243876249053
Validation loss: 2.5692924936453743

Epoch: 6| Step: 6
Training loss: 3.0158917402978473
Validation loss: 2.5667046826853612

Epoch: 6| Step: 7
Training loss: 2.8286887602808237
Validation loss: 2.5710135237415637

Epoch: 6| Step: 8
Training loss: 2.6866782063062042
Validation loss: 2.5414903657940293

Epoch: 6| Step: 9
Training loss: 2.803763489743901
Validation loss: 2.5301583388436866

Epoch: 6| Step: 10
Training loss: 3.2506237898583956
Validation loss: 2.527829444618964

Epoch: 6| Step: 11
Training loss: 2.4932961225367882
Validation loss: 2.515848956810502

Epoch: 6| Step: 12
Training loss: 2.569100601513261
Validation loss: 2.5134683285284263

Epoch: 6| Step: 13
Training loss: 1.9159332475442379
Validation loss: 2.5148585573637736

Epoch: 123| Step: 0
Training loss: 3.0748647086301855
Validation loss: 2.516115825924478

Epoch: 6| Step: 1
Training loss: 2.794021770733806
Validation loss: 2.5196105196693677

Epoch: 6| Step: 2
Training loss: 3.379154897372207
Validation loss: 2.517785222177654

Epoch: 6| Step: 3
Training loss: 2.704800654203465
Validation loss: 2.520560665192866

Epoch: 6| Step: 4
Training loss: 2.47474868731527
Validation loss: 2.5172996310000384

Epoch: 6| Step: 5
Training loss: 2.8834489156088376
Validation loss: 2.5166167389202942

Epoch: 6| Step: 6
Training loss: 2.877887933931082
Validation loss: 2.5146520118038853

Epoch: 6| Step: 7
Training loss: 3.0407459136978088
Validation loss: 2.5178879022425904

Epoch: 6| Step: 8
Training loss: 2.509112059996596
Validation loss: 2.524111753001626

Epoch: 6| Step: 9
Training loss: 2.4772806660618016
Validation loss: 2.5248088183133253

Epoch: 6| Step: 10
Training loss: 2.9161394096822018
Validation loss: 2.5190722555626683

Epoch: 6| Step: 11
Training loss: 3.092473392850105
Validation loss: 2.5196950002172396

Epoch: 6| Step: 12
Training loss: 3.1267704335490016
Validation loss: 2.5161048585883727

Epoch: 6| Step: 13
Training loss: 2.899617656627588
Validation loss: 2.515195558315585

Epoch: 124| Step: 0
Training loss: 2.971192329049261
Validation loss: 2.5130364795580085

Epoch: 6| Step: 1
Training loss: 2.314764718114096
Validation loss: 2.5122158404718156

Epoch: 6| Step: 2
Training loss: 3.002623682325365
Validation loss: 2.5143092541322827

Epoch: 6| Step: 3
Training loss: 3.094156411959868
Validation loss: 2.5115695366113995

Epoch: 6| Step: 4
Training loss: 3.153098468649993
Validation loss: 2.5127631445790457

Epoch: 6| Step: 5
Training loss: 2.3969747947796787
Validation loss: 2.5132451469890995

Epoch: 6| Step: 6
Training loss: 2.663092204395358
Validation loss: 2.511994965360325

Epoch: 6| Step: 7
Training loss: 2.920202092532376
Validation loss: 2.51915157529324

Epoch: 6| Step: 8
Training loss: 3.3121743671938964
Validation loss: 2.5200128531107864

Epoch: 6| Step: 9
Training loss: 2.5256466481301256
Validation loss: 2.5167120493927504

Epoch: 6| Step: 10
Training loss: 2.866948006005799
Validation loss: 2.517951659308173

Epoch: 6| Step: 11
Training loss: 3.041032559562675
Validation loss: 2.5202743804168484

Epoch: 6| Step: 12
Training loss: 2.927758153776851
Validation loss: 2.5221352686028498

Epoch: 6| Step: 13
Training loss: 2.5898010342442634
Validation loss: 2.524393463225266

Epoch: 125| Step: 0
Training loss: 3.0477697379175828
Validation loss: 2.5256352613490414

Epoch: 6| Step: 1
Training loss: 2.186060731698587
Validation loss: 2.5216165714167733

Epoch: 6| Step: 2
Training loss: 3.006100174626204
Validation loss: 2.5246285717575003

Epoch: 6| Step: 3
Training loss: 2.823071511914471
Validation loss: 2.526184251214059

Epoch: 6| Step: 4
Training loss: 2.872977831002467
Validation loss: 2.522256238248516

Epoch: 6| Step: 5
Training loss: 2.7691109450002567
Validation loss: 2.5179181967225484

Epoch: 6| Step: 6
Training loss: 2.913549628648641
Validation loss: 2.5180908730838714

Epoch: 6| Step: 7
Training loss: 3.031784954255512
Validation loss: 2.513636897503533

Epoch: 6| Step: 8
Training loss: 2.9075596637459027
Validation loss: 2.5136499220131387

Epoch: 6| Step: 9
Training loss: 3.559984490221506
Validation loss: 2.5142004440222507

Epoch: 6| Step: 10
Training loss: 2.854981763150147
Validation loss: 2.512624289121419

Epoch: 6| Step: 11
Training loss: 2.6041173904843173
Validation loss: 2.5085665581481726

Epoch: 6| Step: 12
Training loss: 2.5993254153233862
Validation loss: 2.509227432368131

Epoch: 6| Step: 13
Training loss: 2.5357118065436235
Validation loss: 2.508292685989427

Epoch: 126| Step: 0
Training loss: 3.026404371645556
Validation loss: 2.511468351402535

Epoch: 6| Step: 1
Training loss: 2.6208914438505877
Validation loss: 2.5128100051358504

Epoch: 6| Step: 2
Training loss: 3.14922676889794
Validation loss: 2.5153820654537924

Epoch: 6| Step: 3
Training loss: 2.7223719882206647
Validation loss: 2.52025081467308

Epoch: 6| Step: 4
Training loss: 2.7260619307918694
Validation loss: 2.5205534987565064

Epoch: 6| Step: 5
Training loss: 3.030952832314668
Validation loss: 2.522587672102287

Epoch: 6| Step: 6
Training loss: 2.9358327476406316
Validation loss: 2.5235639803509025

Epoch: 6| Step: 7
Training loss: 2.8171360377193517
Validation loss: 2.5215466563927067

Epoch: 6| Step: 8
Training loss: 2.544395690998758
Validation loss: 2.5236807572305406

Epoch: 6| Step: 9
Training loss: 3.1718980008498714
Validation loss: 2.5268323747751555

Epoch: 6| Step: 10
Training loss: 2.2167899917294016
Validation loss: 2.528107948884065

Epoch: 6| Step: 11
Training loss: 2.8993655464427754
Validation loss: 2.551084356482949

Epoch: 6| Step: 12
Training loss: 2.9560877555860188
Validation loss: 2.5442744822336425

Epoch: 6| Step: 13
Training loss: 3.2164228600588998
Validation loss: 2.5355751794593213

Epoch: 127| Step: 0
Training loss: 2.7959726252491417
Validation loss: 2.519186968253396

Epoch: 6| Step: 1
Training loss: 2.1724455379073
Validation loss: 2.5144927454347

Epoch: 6| Step: 2
Training loss: 2.958216561891773
Validation loss: 2.5055414767603015

Epoch: 6| Step: 3
Training loss: 3.3450823829895158
Validation loss: 2.5064343221188943

Epoch: 6| Step: 4
Training loss: 3.0152391572299813
Validation loss: 2.505358807974517

Epoch: 6| Step: 5
Training loss: 2.611998740845825
Validation loss: 2.5081053383859704

Epoch: 6| Step: 6
Training loss: 2.9920593712367842
Validation loss: 2.507353981894949

Epoch: 6| Step: 7
Training loss: 2.995330832777997
Validation loss: 2.5073427860574906

Epoch: 6| Step: 8
Training loss: 2.9321321180899353
Validation loss: 2.5090000317098373

Epoch: 6| Step: 9
Training loss: 3.248827502686456
Validation loss: 2.5085890809001183

Epoch: 6| Step: 10
Training loss: 3.066109690327089
Validation loss: 2.5092918998787215

Epoch: 6| Step: 11
Training loss: 2.748055984709714
Validation loss: 2.509076038568611

Epoch: 6| Step: 12
Training loss: 2.062699626162815
Validation loss: 2.505685643420332

Epoch: 6| Step: 13
Training loss: 3.000036875180271
Validation loss: 2.5100414659691195

Epoch: 128| Step: 0
Training loss: 2.7270321154659984
Validation loss: 2.510492821935099

Epoch: 6| Step: 1
Training loss: 2.864832271972166
Validation loss: 2.5178411626655177

Epoch: 6| Step: 2
Training loss: 3.0352805172336774
Validation loss: 2.5280218571865096

Epoch: 6| Step: 3
Training loss: 2.7983260839147617
Validation loss: 2.5476741295774175

Epoch: 6| Step: 4
Training loss: 3.0507701526786803
Validation loss: 2.592874422928766

Epoch: 6| Step: 5
Training loss: 3.102554278025721
Validation loss: 2.5695853911851967

Epoch: 6| Step: 6
Training loss: 3.08178926588852
Validation loss: 2.53174572334988

Epoch: 6| Step: 7
Training loss: 2.341585100411835
Validation loss: 2.520854584426277

Epoch: 6| Step: 8
Training loss: 2.863030103881624
Validation loss: 2.5038088639972043

Epoch: 6| Step: 9
Training loss: 2.6552381495620865
Validation loss: 2.500245228912117

Epoch: 6| Step: 10
Training loss: 3.1765547182332132
Validation loss: 2.5004964171558224

Epoch: 6| Step: 11
Training loss: 2.583920063536191
Validation loss: 2.5031739759875262

Epoch: 6| Step: 12
Training loss: 2.7390573574437873
Validation loss: 2.5055441365367837

Epoch: 6| Step: 13
Training loss: 3.0694246440112636
Validation loss: 2.5063928697966587

Epoch: 129| Step: 0
Training loss: 2.891273219654012
Validation loss: 2.510985474977157

Epoch: 6| Step: 1
Training loss: 3.0064069361973647
Validation loss: 2.5100330091445975

Epoch: 6| Step: 2
Training loss: 2.1872560637565828
Validation loss: 2.50655891327859

Epoch: 6| Step: 3
Training loss: 3.69143983533002
Validation loss: 2.507524204099914

Epoch: 6| Step: 4
Training loss: 2.806464012498376
Validation loss: 2.504210114212635

Epoch: 6| Step: 5
Training loss: 2.840753338792432
Validation loss: 2.5089019227704874

Epoch: 6| Step: 6
Training loss: 2.34128104821192
Validation loss: 2.5226879286034696

Epoch: 6| Step: 7
Training loss: 2.1327616367632993
Validation loss: 2.5184555948737817

Epoch: 6| Step: 8
Training loss: 2.845356581721953
Validation loss: 2.5106893609262873

Epoch: 6| Step: 9
Training loss: 3.3690433919393232
Validation loss: 2.512599250736282

Epoch: 6| Step: 10
Training loss: 3.3912776195893253
Validation loss: 2.510299778612083

Epoch: 6| Step: 11
Training loss: 2.9134602678639494
Validation loss: 2.512936710252681

Epoch: 6| Step: 12
Training loss: 2.684809646678458
Validation loss: 2.518925427786488

Epoch: 6| Step: 13
Training loss: 2.2925854546148168
Validation loss: 2.519566011868692

Epoch: 130| Step: 0
Training loss: 2.7324354868093765
Validation loss: 2.51724747773417

Epoch: 6| Step: 1
Training loss: 3.056006885680585
Validation loss: 2.510148825330835

Epoch: 6| Step: 2
Training loss: 2.4700328535914347
Validation loss: 2.5057067668607758

Epoch: 6| Step: 3
Training loss: 2.9553479098594377
Validation loss: 2.504619074134827

Epoch: 6| Step: 4
Training loss: 3.1597067156028085
Validation loss: 2.5011985233677767

Epoch: 6| Step: 5
Training loss: 2.763777983552696
Validation loss: 2.500529279363808

Epoch: 6| Step: 6
Training loss: 2.7826415449061606
Validation loss: 2.5013177208677666

Epoch: 6| Step: 7
Training loss: 2.2860855690801456
Validation loss: 2.5076936878878113

Epoch: 6| Step: 8
Training loss: 2.78067627893599
Validation loss: 2.5077464651146992

Epoch: 6| Step: 9
Training loss: 2.739125250942414
Validation loss: 2.5133354225162523

Epoch: 6| Step: 10
Training loss: 2.8185365109680003
Validation loss: 2.51434338976698

Epoch: 6| Step: 11
Training loss: 2.8771354374091103
Validation loss: 2.5269137721711488

Epoch: 6| Step: 12
Training loss: 2.989365803494864
Validation loss: 2.526675014598404

Epoch: 6| Step: 13
Training loss: 3.7219308024210034
Validation loss: 2.51971386858725

Epoch: 131| Step: 0
Training loss: 2.8121739516412476
Validation loss: 2.5247815805951683

Epoch: 6| Step: 1
Training loss: 2.5573778830689653
Validation loss: 2.5224370374831975

Epoch: 6| Step: 2
Training loss: 2.5761206031075816
Validation loss: 2.515762421142282

Epoch: 6| Step: 3
Training loss: 2.7042168854065443
Validation loss: 2.519774306448946

Epoch: 6| Step: 4
Training loss: 2.5944834212271353
Validation loss: 2.517772090255515

Epoch: 6| Step: 5
Training loss: 3.291173262174204
Validation loss: 2.513115425673797

Epoch: 6| Step: 6
Training loss: 2.3163285395177904
Validation loss: 2.5127489477932112

Epoch: 6| Step: 7
Training loss: 3.339237912202356
Validation loss: 2.5131578912498953

Epoch: 6| Step: 8
Training loss: 3.364306994606033
Validation loss: 2.5065399612243158

Epoch: 6| Step: 9
Training loss: 3.0694860069103838
Validation loss: 2.5018947619775362

Epoch: 6| Step: 10
Training loss: 2.6458299792010656
Validation loss: 2.4982554552867806

Epoch: 6| Step: 11
Training loss: 2.929181759733454
Validation loss: 2.49539177010261

Epoch: 6| Step: 12
Training loss: 2.303709902567063
Validation loss: 2.495771460035235

Epoch: 6| Step: 13
Training loss: 3.052138413766576
Validation loss: 2.4926864418262302

Epoch: 132| Step: 0
Training loss: 3.072199350892376
Validation loss: 2.4957049945840493

Epoch: 6| Step: 1
Training loss: 2.6462583325686873
Validation loss: 2.48940942755599

Epoch: 6| Step: 2
Training loss: 2.7770263662216434
Validation loss: 2.488264504709872

Epoch: 6| Step: 3
Training loss: 2.5979845341492998
Validation loss: 2.496163092089809

Epoch: 6| Step: 4
Training loss: 3.335197563210391
Validation loss: 2.493218225924569

Epoch: 6| Step: 5
Training loss: 2.8986586000575336
Validation loss: 2.4950278572386577

Epoch: 6| Step: 6
Training loss: 2.9570314112553624
Validation loss: 2.4934523258891947

Epoch: 6| Step: 7
Training loss: 2.841952248222471
Validation loss: 2.4982384515533136

Epoch: 6| Step: 8
Training loss: 2.6454796942719434
Validation loss: 2.499908989100843

Epoch: 6| Step: 9
Training loss: 2.8533070701507515
Validation loss: 2.5051387425602436

Epoch: 6| Step: 10
Training loss: 2.408309055544791
Validation loss: 2.523330649132835

Epoch: 6| Step: 11
Training loss: 3.5267215826401666
Validation loss: 2.520055286893512

Epoch: 6| Step: 12
Training loss: 2.6769842186378194
Validation loss: 2.5351778043984123

Epoch: 6| Step: 13
Training loss: 1.9312691943748694
Validation loss: 2.531675742748081

Epoch: 133| Step: 0
Training loss: 3.0402964462497897
Validation loss: 2.5274265611303184

Epoch: 6| Step: 1
Training loss: 3.4251553910917676
Validation loss: 2.5193542168984004

Epoch: 6| Step: 2
Training loss: 3.160852834083376
Validation loss: 2.5110903723403597

Epoch: 6| Step: 3
Training loss: 2.573620739766876
Validation loss: 2.5039535107690263

Epoch: 6| Step: 4
Training loss: 2.8800468928440157
Validation loss: 2.5021670383578747

Epoch: 6| Step: 5
Training loss: 2.8102144915622413
Validation loss: 2.502281767892782

Epoch: 6| Step: 6
Training loss: 2.387869250119039
Validation loss: 2.5016265095208983

Epoch: 6| Step: 7
Training loss: 2.642968035547587
Validation loss: 2.5121670727626477

Epoch: 6| Step: 8
Training loss: 3.013349712406081
Validation loss: 2.5028658652977893

Epoch: 6| Step: 9
Training loss: 2.18662876763104
Validation loss: 2.5080371278564493

Epoch: 6| Step: 10
Training loss: 2.9720142287764717
Validation loss: 2.507505797628102

Epoch: 6| Step: 11
Training loss: 3.2795719760650788
Validation loss: 2.5124446347109197

Epoch: 6| Step: 12
Training loss: 2.495273317950243
Validation loss: 2.509972106910325

Epoch: 6| Step: 13
Training loss: 2.57631661541365
Validation loss: 2.511026167445468

Epoch: 134| Step: 0
Training loss: 3.0816790980295825
Validation loss: 2.5051011524847997

Epoch: 6| Step: 1
Training loss: 3.7217377273009755
Validation loss: 2.5149620444731235

Epoch: 6| Step: 2
Training loss: 3.232700965104127
Validation loss: 2.5055153858353023

Epoch: 6| Step: 3
Training loss: 2.6677142310881052
Validation loss: 2.509078350780754

Epoch: 6| Step: 4
Training loss: 2.211876336253879
Validation loss: 2.5030836714520137

Epoch: 6| Step: 5
Training loss: 2.5186599526033966
Validation loss: 2.504992987303816

Epoch: 6| Step: 6
Training loss: 2.827142871594262
Validation loss: 2.508095509446062

Epoch: 6| Step: 7
Training loss: 2.6478530103793894
Validation loss: 2.499535808742782

Epoch: 6| Step: 8
Training loss: 2.6064218953846905
Validation loss: 2.508077821141343

Epoch: 6| Step: 9
Training loss: 2.35252933333916
Validation loss: 2.5083085279621713

Epoch: 6| Step: 10
Training loss: 3.100993606319682
Validation loss: 2.5120193586580024

Epoch: 6| Step: 11
Training loss: 3.2322815832943164
Validation loss: 2.5060319206571893

Epoch: 6| Step: 12
Training loss: 2.5242630402420003
Validation loss: 2.5078600020061628

Epoch: 6| Step: 13
Training loss: 2.4504494624566733
Validation loss: 2.50560493972028

Epoch: 135| Step: 0
Training loss: 2.616334417432908
Validation loss: 2.4996997047878335

Epoch: 6| Step: 1
Training loss: 2.662513797348163
Validation loss: 2.4980529648076577

Epoch: 6| Step: 2
Training loss: 3.3162472240840426
Validation loss: 2.5129278285746333

Epoch: 6| Step: 3
Training loss: 2.9297034504774127
Validation loss: 2.504245736770105

Epoch: 6| Step: 4
Training loss: 2.9062806814891724
Validation loss: 2.50461642412342

Epoch: 6| Step: 5
Training loss: 2.5110688265988457
Validation loss: 2.5084330863306072

Epoch: 6| Step: 6
Training loss: 2.0247602815377603
Validation loss: 2.5131919048131444

Epoch: 6| Step: 7
Training loss: 2.979287809741027
Validation loss: 2.520559320597645

Epoch: 6| Step: 8
Training loss: 2.749285518424088
Validation loss: 2.522323892486212

Epoch: 6| Step: 9
Training loss: 2.726467185554194
Validation loss: 2.519976017989716

Epoch: 6| Step: 10
Training loss: 2.7017863051297053
Validation loss: 2.52885657066067

Epoch: 6| Step: 11
Training loss: 3.025579438003396
Validation loss: 2.528315303483847

Epoch: 6| Step: 12
Training loss: 3.6826156337009452
Validation loss: 2.5415154342671253

Epoch: 6| Step: 13
Training loss: 2.1333835382315836
Validation loss: 2.5479437365288047

Epoch: 136| Step: 0
Training loss: 3.181159201414807
Validation loss: 2.5459554615121056

Epoch: 6| Step: 1
Training loss: 3.105814212801287
Validation loss: 2.539761185226447

Epoch: 6| Step: 2
Training loss: 2.404480122230817
Validation loss: 2.5362245239216494

Epoch: 6| Step: 3
Training loss: 3.0791201459358337
Validation loss: 2.531328838887445

Epoch: 6| Step: 4
Training loss: 2.4413849608446787
Validation loss: 2.514532220920477

Epoch: 6| Step: 5
Training loss: 2.422988537164984
Validation loss: 2.5205057660683137

Epoch: 6| Step: 6
Training loss: 2.81170261523638
Validation loss: 2.511392087226829

Epoch: 6| Step: 7
Training loss: 3.0944549065745397
Validation loss: 2.5177723575377025

Epoch: 6| Step: 8
Training loss: 2.221705442845218
Validation loss: 2.507390382846729

Epoch: 6| Step: 9
Training loss: 2.729707407100869
Validation loss: 2.4963817664888173

Epoch: 6| Step: 10
Training loss: 2.7865828917046964
Validation loss: 2.494981929629687

Epoch: 6| Step: 11
Training loss: 2.867036155427469
Validation loss: 2.4941292423935444

Epoch: 6| Step: 12
Training loss: 3.0967215706920053
Validation loss: 2.497316373174557

Epoch: 6| Step: 13
Training loss: 3.5605423216338137
Validation loss: 2.492648717446422

Epoch: 137| Step: 0
Training loss: 2.5791683975567246
Validation loss: 2.493451204178331

Epoch: 6| Step: 1
Training loss: 2.8590221083040763
Validation loss: 2.496810736932888

Epoch: 6| Step: 2
Training loss: 3.112389718059112
Validation loss: 2.494691461950203

Epoch: 6| Step: 3
Training loss: 2.2826734308576335
Validation loss: 2.4972688646350805

Epoch: 6| Step: 4
Training loss: 2.5657556832748756
Validation loss: 2.5047798055441266

Epoch: 6| Step: 5
Training loss: 2.919408726335072
Validation loss: 2.507186155650545

Epoch: 6| Step: 6
Training loss: 2.8615780874179593
Validation loss: 2.510841897998519

Epoch: 6| Step: 7
Training loss: 2.4454427568642063
Validation loss: 2.5265463125891015

Epoch: 6| Step: 8
Training loss: 2.8981395475751746
Validation loss: 2.530997798118694

Epoch: 6| Step: 9
Training loss: 2.9760796262896934
Validation loss: 2.529328154849044

Epoch: 6| Step: 10
Training loss: 3.2935366248374267
Validation loss: 2.5352693946433926

Epoch: 6| Step: 11
Training loss: 2.732954953528348
Validation loss: 2.542179597215498

Epoch: 6| Step: 12
Training loss: 2.8927531888069087
Validation loss: 2.5296689494878835

Epoch: 6| Step: 13
Training loss: 3.293759288449012
Validation loss: 2.537025808806796

Epoch: 138| Step: 0
Training loss: 3.0375301155512613
Validation loss: 2.5262312179977586

Epoch: 6| Step: 1
Training loss: 3.000272102731632
Validation loss: 2.517567558116518

Epoch: 6| Step: 2
Training loss: 2.5729515186579985
Validation loss: 2.5178195718544836

Epoch: 6| Step: 3
Training loss: 3.1239658933528758
Validation loss: 2.519454996872957

Epoch: 6| Step: 4
Training loss: 2.918919338239653
Validation loss: 2.5205645992994223

Epoch: 6| Step: 5
Training loss: 3.012490971341988
Validation loss: 2.5139296647024825

Epoch: 6| Step: 6
Training loss: 2.990146030189889
Validation loss: 2.5037000941544165

Epoch: 6| Step: 7
Training loss: 2.6949092839814033
Validation loss: 2.5001844548299292

Epoch: 6| Step: 8
Training loss: 2.2695249468770045
Validation loss: 2.4979246292850132

Epoch: 6| Step: 9
Training loss: 2.8241428560266453
Validation loss: 2.501893850012486

Epoch: 6| Step: 10
Training loss: 2.758954554632531
Validation loss: 2.502880739877845

Epoch: 6| Step: 11
Training loss: 2.7542890566719094
Validation loss: 2.49703976098355

Epoch: 6| Step: 12
Training loss: 2.881836930277701
Validation loss: 2.496533312934437

Epoch: 6| Step: 13
Training loss: 2.2640593281915216
Validation loss: 2.496131726833538

Epoch: 139| Step: 0
Training loss: 2.691035761476138
Validation loss: 2.4967979177251576

Epoch: 6| Step: 1
Training loss: 2.809890893195862
Validation loss: 2.4884194394164587

Epoch: 6| Step: 2
Training loss: 2.5403399731049934
Validation loss: 2.489881923311644

Epoch: 6| Step: 3
Training loss: 2.4251742624808754
Validation loss: 2.4895154508079558

Epoch: 6| Step: 4
Training loss: 3.1259815963232667
Validation loss: 2.489290284452731

Epoch: 6| Step: 5
Training loss: 3.138415114244973
Validation loss: 2.492478292399091

Epoch: 6| Step: 6
Training loss: 2.9780660521366333
Validation loss: 2.491917144464186

Epoch: 6| Step: 7
Training loss: 2.862150918922765
Validation loss: 2.5022563965219935

Epoch: 6| Step: 8
Training loss: 2.752850442417657
Validation loss: 2.51097570733895

Epoch: 6| Step: 9
Training loss: 2.6579851653960245
Validation loss: 2.535262644431411

Epoch: 6| Step: 10
Training loss: 2.7894880039677146
Validation loss: 2.5293671312234105

Epoch: 6| Step: 11
Training loss: 3.5412200346923437
Validation loss: 2.531702542259166

Epoch: 6| Step: 12
Training loss: 2.5424883926411717
Validation loss: 2.5135765206436154

Epoch: 6| Step: 13
Training loss: 2.2149186701945
Validation loss: 2.510468201399136

Epoch: 140| Step: 0
Training loss: 2.7374068536109215
Validation loss: 2.5055031340214855

Epoch: 6| Step: 1
Training loss: 2.4564835221421015
Validation loss: 2.493058873613675

Epoch: 6| Step: 2
Training loss: 2.785357924084226
Validation loss: 2.4937747408110202

Epoch: 6| Step: 3
Training loss: 2.6222408871426435
Validation loss: 2.4968457263096697

Epoch: 6| Step: 4
Training loss: 2.6893731619943644
Validation loss: 2.4969070200679355

Epoch: 6| Step: 5
Training loss: 3.2041823712093462
Validation loss: 2.5045997071849766

Epoch: 6| Step: 6
Training loss: 2.5391083229038207
Validation loss: 2.500873426430014

Epoch: 6| Step: 7
Training loss: 3.023002652383209
Validation loss: 2.5094088658690916

Epoch: 6| Step: 8
Training loss: 2.8157480769719423
Validation loss: 2.509520061716906

Epoch: 6| Step: 9
Training loss: 2.724287335358681
Validation loss: 2.5120885877143864

Epoch: 6| Step: 10
Training loss: 2.5261750385954174
Validation loss: 2.5144005727225944

Epoch: 6| Step: 11
Training loss: 3.3133562528814045
Validation loss: 2.511101808741582

Epoch: 6| Step: 12
Training loss: 2.8112351858411073
Validation loss: 2.521917912389448

Epoch: 6| Step: 13
Training loss: 3.072208663499685
Validation loss: 2.517849763301564

Epoch: 141| Step: 0
Training loss: 2.5868959984269266
Validation loss: 2.5215568985443824

Epoch: 6| Step: 1
Training loss: 2.3061730720901754
Validation loss: 2.5262560400890344

Epoch: 6| Step: 2
Training loss: 2.98429734693231
Validation loss: 2.5376891111719644

Epoch: 6| Step: 3
Training loss: 3.125598850091274
Validation loss: 2.5508096613557454

Epoch: 6| Step: 4
Training loss: 2.7058442831410185
Validation loss: 2.5533055984641986

Epoch: 6| Step: 5
Training loss: 3.17629621583958
Validation loss: 2.5453305937329644

Epoch: 6| Step: 6
Training loss: 2.8879319301413395
Validation loss: 2.535397985504838

Epoch: 6| Step: 7
Training loss: 2.506561632830369
Validation loss: 2.5179505770194917

Epoch: 6| Step: 8
Training loss: 2.6110081844018933
Validation loss: 2.510543020121419

Epoch: 6| Step: 9
Training loss: 3.2386125457228556
Validation loss: 2.5061415483051013

Epoch: 6| Step: 10
Training loss: 2.7520286706717316
Validation loss: 2.4938960334834004

Epoch: 6| Step: 11
Training loss: 3.0293677080089085
Validation loss: 2.4879870551271472

Epoch: 6| Step: 12
Training loss: 2.6906319045488862
Validation loss: 2.495360162453559

Epoch: 6| Step: 13
Training loss: 2.6195930016324405
Validation loss: 2.5276332890406703

Epoch: 142| Step: 0
Training loss: 2.5919001773579993
Validation loss: 2.5560046225061837

Epoch: 6| Step: 1
Training loss: 2.8691486023544646
Validation loss: 2.5803786306129437

Epoch: 6| Step: 2
Training loss: 2.637410843051876
Validation loss: 2.5926616681920795

Epoch: 6| Step: 3
Training loss: 2.8927332432770663
Validation loss: 2.5997708030281035

Epoch: 6| Step: 4
Training loss: 2.407448111160128
Validation loss: 2.572057668205363

Epoch: 6| Step: 5
Training loss: 3.088827976553209
Validation loss: 2.571075861703134

Epoch: 6| Step: 6
Training loss: 3.089951466299578
Validation loss: 2.578633179459593

Epoch: 6| Step: 7
Training loss: 2.7647991779374737
Validation loss: 2.650262613531815

Epoch: 6| Step: 8
Training loss: 3.189019831923803
Validation loss: 2.694771760066901

Epoch: 6| Step: 9
Training loss: 3.612566177131607
Validation loss: 2.7375537721128183

Epoch: 6| Step: 10
Training loss: 2.9084487309192406
Validation loss: 2.6722749781184114

Epoch: 6| Step: 11
Training loss: 2.8419160064161666
Validation loss: 2.620610982722024

Epoch: 6| Step: 12
Training loss: 3.0740485913736735
Validation loss: 2.5611831108497896

Epoch: 6| Step: 13
Training loss: 2.773999997975763
Validation loss: 2.565728303717277

Epoch: 143| Step: 0
Training loss: 2.4409836548316988
Validation loss: 2.565831411679149

Epoch: 6| Step: 1
Training loss: 3.0958839532163065
Validation loss: 2.5538492294133226

Epoch: 6| Step: 2
Training loss: 3.25940224626076
Validation loss: 2.539715821275138

Epoch: 6| Step: 3
Training loss: 2.485644322148289
Validation loss: 2.5261539300232916

Epoch: 6| Step: 4
Training loss: 2.9689469121578975
Validation loss: 2.4989037889361967

Epoch: 6| Step: 5
Training loss: 2.358441705089645
Validation loss: 2.5006915499842317

Epoch: 6| Step: 6
Training loss: 3.4403885236059275
Validation loss: 2.490763920090953

Epoch: 6| Step: 7
Training loss: 2.360211154737281
Validation loss: 2.48890124609744

Epoch: 6| Step: 8
Training loss: 2.990888428122577
Validation loss: 2.4968831927120827

Epoch: 6| Step: 9
Training loss: 3.324646470628582
Validation loss: 2.491928182246691

Epoch: 6| Step: 10
Training loss: 3.0366986257613995
Validation loss: 2.496943112324159

Epoch: 6| Step: 11
Training loss: 2.6477735919450627
Validation loss: 2.506004808259002

Epoch: 6| Step: 12
Training loss: 2.016521047688991
Validation loss: 2.516667788800785

Epoch: 6| Step: 13
Training loss: 2.718398411258505
Validation loss: 2.5364454884399805

Epoch: 144| Step: 0
Training loss: 3.018691643255493
Validation loss: 2.547581459749329

Epoch: 6| Step: 1
Training loss: 2.579828797507828
Validation loss: 2.5498445985891585

Epoch: 6| Step: 2
Training loss: 3.0968395181080224
Validation loss: 2.5578970703257715

Epoch: 6| Step: 3
Training loss: 3.0061420508530907
Validation loss: 2.5460016839591413

Epoch: 6| Step: 4
Training loss: 2.6985554963661156
Validation loss: 2.5386822038174457

Epoch: 6| Step: 5
Training loss: 2.4220392971300115
Validation loss: 2.527038322460224

Epoch: 6| Step: 6
Training loss: 2.3402272516739777
Validation loss: 2.5265135493150686

Epoch: 6| Step: 7
Training loss: 3.0501844381629653
Validation loss: 2.5210814537383692

Epoch: 6| Step: 8
Training loss: 2.416669111140977
Validation loss: 2.517533107752128

Epoch: 6| Step: 9
Training loss: 3.4349409808512217
Validation loss: 2.5164687705213438

Epoch: 6| Step: 10
Training loss: 3.3258269350096588
Validation loss: 2.512860995643961

Epoch: 6| Step: 11
Training loss: 3.237701916381559
Validation loss: 2.5099188147109976

Epoch: 6| Step: 12
Training loss: 2.2460778277288904
Validation loss: 2.508277653397869

Epoch: 6| Step: 13
Training loss: 1.402355225922534
Validation loss: 2.502447782967059

Epoch: 145| Step: 0
Training loss: 3.3910429384915433
Validation loss: 2.5085555465653284

Epoch: 6| Step: 1
Training loss: 2.6384244699776525
Validation loss: 2.5128175905240484

Epoch: 6| Step: 2
Training loss: 2.5285475633555654
Validation loss: 2.5074367620590716

Epoch: 6| Step: 3
Training loss: 2.7044300611342136
Validation loss: 2.5167589769939296

Epoch: 6| Step: 4
Training loss: 2.3014358599615785
Validation loss: 2.5167840585410315

Epoch: 6| Step: 5
Training loss: 2.6167469166236117
Validation loss: 2.5277292338277677

Epoch: 6| Step: 6
Training loss: 2.8815399090268476
Validation loss: 2.5305943467254606

Epoch: 6| Step: 7
Training loss: 2.811424219170191
Validation loss: 2.5384621843674275

Epoch: 6| Step: 8
Training loss: 3.5960187302081468
Validation loss: 2.541773550918694

Epoch: 6| Step: 9
Training loss: 2.71914897928926
Validation loss: 2.5365711342136685

Epoch: 6| Step: 10
Training loss: 2.7292807945868605
Validation loss: 2.53861117836225

Epoch: 6| Step: 11
Training loss: 3.0185895983806987
Validation loss: 2.536634512643578

Epoch: 6| Step: 12
Training loss: 3.0101258732530023
Validation loss: 2.5464129184463675

Epoch: 6| Step: 13
Training loss: 2.1888922484232793
Validation loss: 2.5467649318158796

Epoch: 146| Step: 0
Training loss: 2.7137155507632156
Validation loss: 2.5502033762184637

Epoch: 6| Step: 1
Training loss: 2.6192596886388184
Validation loss: 2.553050252347626

Epoch: 6| Step: 2
Training loss: 2.6193321436782795
Validation loss: 2.552465275069498

Epoch: 6| Step: 3
Training loss: 3.019724534968354
Validation loss: 2.5734747549209063

Epoch: 6| Step: 4
Training loss: 2.503715519774797
Validation loss: 2.558089838454919

Epoch: 6| Step: 5
Training loss: 3.068501411515984
Validation loss: 2.5451944124818366

Epoch: 6| Step: 6
Training loss: 2.8293351592807947
Validation loss: 2.531353687961547

Epoch: 6| Step: 7
Training loss: 2.9987391365366514
Validation loss: 2.518594778250039

Epoch: 6| Step: 8
Training loss: 2.455596747659411
Validation loss: 2.516714940310663

Epoch: 6| Step: 9
Training loss: 3.1828531538886224
Validation loss: 2.4999895054586676

Epoch: 6| Step: 10
Training loss: 2.615646956521401
Validation loss: 2.495520207116668

Epoch: 6| Step: 11
Training loss: 3.2244243788260976
Validation loss: 2.4925769881263227

Epoch: 6| Step: 12
Training loss: 2.6051214578616446
Validation loss: 2.484258797481236

Epoch: 6| Step: 13
Training loss: 3.088305528093209
Validation loss: 2.4893944204762573

Epoch: 147| Step: 0
Training loss: 2.512145485230671
Validation loss: 2.48515262301951

Epoch: 6| Step: 1
Training loss: 2.8520771555047646
Validation loss: 2.4882610006820953

Epoch: 6| Step: 2
Training loss: 2.5609974992018185
Validation loss: 2.4866128997234913

Epoch: 6| Step: 3
Training loss: 3.0247426136322977
Validation loss: 2.489101273825021

Epoch: 6| Step: 4
Training loss: 2.6067261185496466
Validation loss: 2.4858064537193867

Epoch: 6| Step: 5
Training loss: 2.757413927189194
Validation loss: 2.49427995544659

Epoch: 6| Step: 6
Training loss: 3.0124365202360943
Validation loss: 2.4934585328172734

Epoch: 6| Step: 7
Training loss: 3.0504773876363136
Validation loss: 2.4922644135613226

Epoch: 6| Step: 8
Training loss: 2.46975204798535
Validation loss: 2.4949822327476907

Epoch: 6| Step: 9
Training loss: 3.2263189413219537
Validation loss: 2.495039801895293

Epoch: 6| Step: 10
Training loss: 3.1507876122994745
Validation loss: 2.505947100727463

Epoch: 6| Step: 11
Training loss: 2.5355934271610954
Validation loss: 2.5046982783958853

Epoch: 6| Step: 12
Training loss: 2.535304460469273
Validation loss: 2.504593955721687

Epoch: 6| Step: 13
Training loss: 2.9235084578090174
Validation loss: 2.5129036052857905

Epoch: 148| Step: 0
Training loss: 3.114576120697822
Validation loss: 2.5016560791354086

Epoch: 6| Step: 1
Training loss: 2.6471251890801457
Validation loss: 2.489868737404945

Epoch: 6| Step: 2
Training loss: 2.801204037644591
Validation loss: 2.4904631432514583

Epoch: 6| Step: 3
Training loss: 3.107862248317419
Validation loss: 2.4763875661239676

Epoch: 6| Step: 4
Training loss: 2.4554844097496193
Validation loss: 2.478892098562466

Epoch: 6| Step: 5
Training loss: 2.8251779280812355
Validation loss: 2.478562327312567

Epoch: 6| Step: 6
Training loss: 2.7320220414776357
Validation loss: 2.4768378685418178

Epoch: 6| Step: 7
Training loss: 3.197420576718269
Validation loss: 2.476860720177595

Epoch: 6| Step: 8
Training loss: 3.134299061122474
Validation loss: 2.4768741487015213

Epoch: 6| Step: 9
Training loss: 2.554541907405211
Validation loss: 2.475844163932436

Epoch: 6| Step: 10
Training loss: 2.9865079118338675
Validation loss: 2.4790044331450005

Epoch: 6| Step: 11
Training loss: 2.4376200132902412
Validation loss: 2.477262487630408

Epoch: 6| Step: 12
Training loss: 2.1490392223771035
Validation loss: 2.47118949793211

Epoch: 6| Step: 13
Training loss: 3.5516631622750654
Validation loss: 2.4749960100811546

Epoch: 149| Step: 0
Training loss: 2.7261654802502373
Validation loss: 2.478425265028556

Epoch: 6| Step: 1
Training loss: 3.047719672080252
Validation loss: 2.4801762559653384

Epoch: 6| Step: 2
Training loss: 3.253409431328379
Validation loss: 2.4881994666362326

Epoch: 6| Step: 3
Training loss: 2.869729726207165
Validation loss: 2.5125126204880033

Epoch: 6| Step: 4
Training loss: 2.7417723947408525
Validation loss: 2.5193384576111857

Epoch: 6| Step: 5
Training loss: 3.3765880945622246
Validation loss: 2.528820912595872

Epoch: 6| Step: 6
Training loss: 2.5449814573560516
Validation loss: 2.5259220955528816

Epoch: 6| Step: 7
Training loss: 2.565366676698106
Validation loss: 2.5023015236564468

Epoch: 6| Step: 8
Training loss: 3.0275259836784465
Validation loss: 2.4872779821728295

Epoch: 6| Step: 9
Training loss: 2.8002487378672276
Validation loss: 2.4920229833554313

Epoch: 6| Step: 10
Training loss: 2.3905998677447324
Validation loss: 2.503326737506997

Epoch: 6| Step: 11
Training loss: 2.8327622305549047
Validation loss: 2.563316988320894

Epoch: 6| Step: 12
Training loss: 2.9173429704131535
Validation loss: 2.7332636361599016

Epoch: 6| Step: 13
Training loss: 2.0867119540864745
Validation loss: 2.7468128603906434

Epoch: 150| Step: 0
Training loss: 2.7919867222970294
Validation loss: 2.744875525057701

Epoch: 6| Step: 1
Training loss: 2.9282550208863625
Validation loss: 2.661175196342954

Epoch: 6| Step: 2
Training loss: 3.155629314163532
Validation loss: 2.5748080457135702

Epoch: 6| Step: 3
Training loss: 3.2022498447174863
Validation loss: 2.5521355997592847

Epoch: 6| Step: 4
Training loss: 3.314381622820011
Validation loss: 2.5392235913537826

Epoch: 6| Step: 5
Training loss: 2.662672737499888
Validation loss: 2.5409422261794297

Epoch: 6| Step: 6
Training loss: 3.091795486960759
Validation loss: 2.567832541577994

Epoch: 6| Step: 7
Training loss: 2.3599719372390138
Validation loss: 2.5891204359938653

Epoch: 6| Step: 8
Training loss: 3.1865481283042034
Validation loss: 2.5987257660538443

Epoch: 6| Step: 9
Training loss: 2.774305095096996
Validation loss: 2.584030974784443

Epoch: 6| Step: 10
Training loss: 2.9053727333346564
Validation loss: 2.565297282480459

Epoch: 6| Step: 11
Training loss: 2.687497338581985
Validation loss: 2.565476619318765

Epoch: 6| Step: 12
Training loss: 2.30464901649544
Validation loss: 2.552517380677488

Epoch: 6| Step: 13
Training loss: 2.471063230303745
Validation loss: 2.542245489977622

Epoch: 151| Step: 0
Training loss: 2.7759317706735103
Validation loss: 2.5495794650832346

Epoch: 6| Step: 1
Training loss: 2.7868227901560068
Validation loss: 2.5696683963630105

Epoch: 6| Step: 2
Training loss: 3.4499809485752566
Validation loss: 2.5587276691407514

Epoch: 6| Step: 3
Training loss: 2.61748637300604
Validation loss: 2.540286330996252

Epoch: 6| Step: 4
Training loss: 2.9231466698144093
Validation loss: 2.5463129033922374

Epoch: 6| Step: 5
Training loss: 2.957660079067665
Validation loss: 2.5541189975549625

Epoch: 6| Step: 6
Training loss: 3.472384087074606
Validation loss: 2.5619521587141625

Epoch: 6| Step: 7
Training loss: 2.545976164245504
Validation loss: 2.583726523212359

Epoch: 6| Step: 8
Training loss: 2.898834283614264
Validation loss: 2.6020053648066575

Epoch: 6| Step: 9
Training loss: 2.70454492925955
Validation loss: 2.6056970213831696

Epoch: 6| Step: 10
Training loss: 3.0834037325958525
Validation loss: 2.610241835438523

Epoch: 6| Step: 11
Training loss: 3.0643631853237276
Validation loss: 2.6053482551506773

Epoch: 6| Step: 12
Training loss: 2.1689453125
Validation loss: 2.590007753465508

Epoch: 6| Step: 13
Training loss: 2.5622250479217294
Validation loss: 2.609252625198697

Epoch: 152| Step: 0
Training loss: 2.8760961018768905
Validation loss: 2.5903255373531127

Epoch: 6| Step: 1
Training loss: 3.3023722589406987
Validation loss: 2.5881185449282285

Epoch: 6| Step: 2
Training loss: 2.9404528771192022
Validation loss: 2.563616487636607

Epoch: 6| Step: 3
Training loss: 2.809382512270311
Validation loss: 2.5546352871225513

Epoch: 6| Step: 4
Training loss: 2.6620609225861647
Validation loss: 2.551269474476031

Epoch: 6| Step: 5
Training loss: 3.191718208819776
Validation loss: 2.5479744800839828

Epoch: 6| Step: 6
Training loss: 3.08103224660013
Validation loss: 2.5510472364063417

Epoch: 6| Step: 7
Training loss: 2.6431549412620643
Validation loss: 2.5656786976334267

Epoch: 6| Step: 8
Training loss: 2.94258100296056
Validation loss: 2.581948564819632

Epoch: 6| Step: 9
Training loss: 3.1366035183729752
Validation loss: 2.585327946034046

Epoch: 6| Step: 10
Training loss: 2.691941693863446
Validation loss: 2.5840247046473466

Epoch: 6| Step: 11
Training loss: 2.4122403375695196
Validation loss: 2.5721857026411445

Epoch: 6| Step: 12
Training loss: 2.8217974106101025
Validation loss: 2.555629526812211

Epoch: 6| Step: 13
Training loss: 2.2967107804947324
Validation loss: 2.5409100243631197

Epoch: 153| Step: 0
Training loss: 1.845082722698653
Validation loss: 2.521322663735213

Epoch: 6| Step: 1
Training loss: 2.6855043498053557
Validation loss: 2.4966524220353827

Epoch: 6| Step: 2
Training loss: 2.423328677106929
Validation loss: 2.4977870878781845

Epoch: 6| Step: 3
Training loss: 2.277050280760093
Validation loss: 2.5004488982934157

Epoch: 6| Step: 4
Training loss: 3.1774936765402266
Validation loss: 2.508563834893703

Epoch: 6| Step: 5
Training loss: 3.262953400073658
Validation loss: 2.507474617706353

Epoch: 6| Step: 6
Training loss: 2.7818712547892392
Validation loss: 2.501642175941664

Epoch: 6| Step: 7
Training loss: 3.1137165066859875
Validation loss: 2.4905273326947106

Epoch: 6| Step: 8
Training loss: 2.8017222421169192
Validation loss: 2.4878128606942993

Epoch: 6| Step: 9
Training loss: 3.398870190666017
Validation loss: 2.506607213265447

Epoch: 6| Step: 10
Training loss: 3.216618841603052
Validation loss: 2.515149702366312

Epoch: 6| Step: 11
Training loss: 2.1347412778088946
Validation loss: 2.51583321530729

Epoch: 6| Step: 12
Training loss: 2.6233589855848045
Validation loss: 2.5134051054268784

Epoch: 6| Step: 13
Training loss: 2.989879544743841
Validation loss: 2.5153329494114405

Epoch: 154| Step: 0
Training loss: 2.8298007784433716
Validation loss: 2.524056758448439

Epoch: 6| Step: 1
Training loss: 2.4505025854184646
Validation loss: 2.516327956630297

Epoch: 6| Step: 2
Training loss: 3.015285650737255
Validation loss: 2.531411802203999

Epoch: 6| Step: 3
Training loss: 2.287352668728663
Validation loss: 2.5323842873605784

Epoch: 6| Step: 4
Training loss: 2.8482800965963637
Validation loss: 2.5264162118086215

Epoch: 6| Step: 5
Training loss: 3.3153970393734933
Validation loss: 2.5225907859643524

Epoch: 6| Step: 6
Training loss: 2.7940653748834
Validation loss: 2.5249439242209903

Epoch: 6| Step: 7
Training loss: 2.9105443913243496
Validation loss: 2.5182609650690075

Epoch: 6| Step: 8
Training loss: 3.0081921622702303
Validation loss: 2.504230780210138

Epoch: 6| Step: 9
Training loss: 3.0027731158369044
Validation loss: 2.500987734558666

Epoch: 6| Step: 10
Training loss: 2.9954857240354844
Validation loss: 2.499110647157706

Epoch: 6| Step: 11
Training loss: 2.3544276832658846
Validation loss: 2.49513256857397

Epoch: 6| Step: 12
Training loss: 2.7733454299473435
Validation loss: 2.5031008778343407

Epoch: 6| Step: 13
Training loss: 2.3782199314333496
Validation loss: 2.4967364292775094

Epoch: 155| Step: 0
Training loss: 2.8534053334691714
Validation loss: 2.4875748538411315

Epoch: 6| Step: 1
Training loss: 3.076062436049313
Validation loss: 2.477128411628217

Epoch: 6| Step: 2
Training loss: 2.6191044861123016
Validation loss: 2.463561290135644

Epoch: 6| Step: 3
Training loss: 2.392181886832082
Validation loss: 2.4690208032116274

Epoch: 6| Step: 4
Training loss: 2.825857359831744
Validation loss: 2.4730370639178654

Epoch: 6| Step: 5
Training loss: 2.7736816298803197
Validation loss: 2.469205364424231

Epoch: 6| Step: 6
Training loss: 2.6849982571729405
Validation loss: 2.467802527140435

Epoch: 6| Step: 7
Training loss: 2.968217018871458
Validation loss: 2.470047915512339

Epoch: 6| Step: 8
Training loss: 3.1964779246448267
Validation loss: 2.4733848880387352

Epoch: 6| Step: 9
Training loss: 2.8664549845526612
Validation loss: 2.484844914291371

Epoch: 6| Step: 10
Training loss: 2.674252350328919
Validation loss: 2.476813681473444

Epoch: 6| Step: 11
Training loss: 3.197583871894192
Validation loss: 2.4813528596129015

Epoch: 6| Step: 12
Training loss: 2.339655847917453
Validation loss: 2.477868297950182

Epoch: 6| Step: 13
Training loss: 2.479933312965365
Validation loss: 2.478715679966659

Epoch: 156| Step: 0
Training loss: 2.5501668987632655
Validation loss: 2.493146132527731

Epoch: 6| Step: 1
Training loss: 2.838066205909146
Validation loss: 2.4887610196548007

Epoch: 6| Step: 2
Training loss: 2.1652682143967983
Validation loss: 2.4889132072812723

Epoch: 6| Step: 3
Training loss: 3.0135228236998572
Validation loss: 2.4922886965263733

Epoch: 6| Step: 4
Training loss: 2.3928742641983294
Validation loss: 2.4878296760051186

Epoch: 6| Step: 5
Training loss: 3.1532829615606883
Validation loss: 2.4957873917581446

Epoch: 6| Step: 6
Training loss: 2.173519253101641
Validation loss: 2.496769415415825

Epoch: 6| Step: 7
Training loss: 3.2639634865607126
Validation loss: 2.4991321549449474

Epoch: 6| Step: 8
Training loss: 3.068735120313818
Validation loss: 2.500945737855825

Epoch: 6| Step: 9
Training loss: 2.521897262229176
Validation loss: 2.513458352266329

Epoch: 6| Step: 10
Training loss: 3.0855199603799877
Validation loss: 2.511635019830122

Epoch: 6| Step: 11
Training loss: 2.234279817274435
Validation loss: 2.499664407170866

Epoch: 6| Step: 12
Training loss: 3.0208920352537705
Validation loss: 2.4851128753015903

Epoch: 6| Step: 13
Training loss: 3.2449674522989427
Validation loss: 2.48929798167495

Epoch: 157| Step: 0
Training loss: 3.396984833430542
Validation loss: 2.4763506939196556

Epoch: 6| Step: 1
Training loss: 2.6162528575402266
Validation loss: 2.4748933192174145

Epoch: 6| Step: 2
Training loss: 2.928449771095385
Validation loss: 2.466051035779688

Epoch: 6| Step: 3
Training loss: 2.551833959319987
Validation loss: 2.463687439653967

Epoch: 6| Step: 4
Training loss: 1.950211144288987
Validation loss: 2.459823161302091

Epoch: 6| Step: 5
Training loss: 3.1290085069803455
Validation loss: 2.461463437880028

Epoch: 6| Step: 6
Training loss: 2.428912269091579
Validation loss: 2.4646404803925934

Epoch: 6| Step: 7
Training loss: 2.803347126506872
Validation loss: 2.4663485707172748

Epoch: 6| Step: 8
Training loss: 3.0519915535486217
Validation loss: 2.4650169977195575

Epoch: 6| Step: 9
Training loss: 2.646508698861928
Validation loss: 2.4684297243042472

Epoch: 6| Step: 10
Training loss: 3.0426606596481487
Validation loss: 2.4858490753932188

Epoch: 6| Step: 11
Training loss: 2.3681581225763133
Validation loss: 2.489952838126713

Epoch: 6| Step: 12
Training loss: 3.1148221403874023
Validation loss: 2.496599290142561

Epoch: 6| Step: 13
Training loss: 2.3409938628561537
Validation loss: 2.503860755547933

Epoch: 158| Step: 0
Training loss: 2.83419115507035
Validation loss: 2.5085931564143693

Epoch: 6| Step: 1
Training loss: 2.532305650399149
Validation loss: 2.5122103452354194

Epoch: 6| Step: 2
Training loss: 2.5492629575505745
Validation loss: 2.518006632445143

Epoch: 6| Step: 3
Training loss: 2.052107086302356
Validation loss: 2.4957777577516556

Epoch: 6| Step: 4
Training loss: 2.4167613526134186
Validation loss: 2.488832067353671

Epoch: 6| Step: 5
Training loss: 2.5014107538407067
Validation loss: 2.473047944431267

Epoch: 6| Step: 6
Training loss: 2.859429364130569
Validation loss: 2.465216918922819

Epoch: 6| Step: 7
Training loss: 2.7461026057267413
Validation loss: 2.466853054618518

Epoch: 6| Step: 8
Training loss: 3.0694240226085423
Validation loss: 2.459817958086831

Epoch: 6| Step: 9
Training loss: 2.9254740208665564
Validation loss: 2.4567560489514597

Epoch: 6| Step: 10
Training loss: 3.448816433661093
Validation loss: 2.4553384675070964

Epoch: 6| Step: 11
Training loss: 2.6992818159804135
Validation loss: 2.459683070856303

Epoch: 6| Step: 12
Training loss: 2.832349793507716
Validation loss: 2.4616111311302786

Epoch: 6| Step: 13
Training loss: 3.295321708800181
Validation loss: 2.4619115164710013

Epoch: 159| Step: 0
Training loss: 3.027494483394621
Validation loss: 2.4605262987062324

Epoch: 6| Step: 1
Training loss: 2.4988892948928094
Validation loss: 2.460330770756404

Epoch: 6| Step: 2
Training loss: 2.677094297473191
Validation loss: 2.4597961758543945

Epoch: 6| Step: 3
Training loss: 2.654736615063974
Validation loss: 2.466559804493442

Epoch: 6| Step: 4
Training loss: 2.811294042802865
Validation loss: 2.4689564305111

Epoch: 6| Step: 5
Training loss: 2.92065306219215
Validation loss: 2.4682193049144483

Epoch: 6| Step: 6
Training loss: 3.3652440102517316
Validation loss: 2.4915196899905148

Epoch: 6| Step: 7
Training loss: 2.540509841392358
Validation loss: 2.4947856319242407

Epoch: 6| Step: 8
Training loss: 2.6016024566422953
Validation loss: 2.5046915271649817

Epoch: 6| Step: 9
Training loss: 2.5561912846992043
Validation loss: 2.51223618855912

Epoch: 6| Step: 10
Training loss: 2.8987647023553986
Validation loss: 2.524853411382845

Epoch: 6| Step: 11
Training loss: 2.1753941847418803
Validation loss: 2.521097296699548

Epoch: 6| Step: 12
Training loss: 3.215669064826924
Validation loss: 2.5224785513706727

Epoch: 6| Step: 13
Training loss: 2.4924469337438855
Validation loss: 2.5117617280827655

Epoch: 160| Step: 0
Training loss: 3.053619588346268
Validation loss: 2.502746362528334

Epoch: 6| Step: 1
Training loss: 2.8375693426187705
Validation loss: 2.491178591433123

Epoch: 6| Step: 2
Training loss: 2.587636153467472
Validation loss: 2.479800633310655

Epoch: 6| Step: 3
Training loss: 2.6295128132489265
Validation loss: 2.4722995352684105

Epoch: 6| Step: 4
Training loss: 3.2575488818607776
Validation loss: 2.4746299302702273

Epoch: 6| Step: 5
Training loss: 2.7606401077143845
Validation loss: 2.4732351530845706

Epoch: 6| Step: 6
Training loss: 2.8557995397169185
Validation loss: 2.472635466295771

Epoch: 6| Step: 7
Training loss: 2.0250758309942016
Validation loss: 2.4748029854806126

Epoch: 6| Step: 8
Training loss: 3.07675093756175
Validation loss: 2.463703495605494

Epoch: 6| Step: 9
Training loss: 2.138423037749759
Validation loss: 2.472187144379471

Epoch: 6| Step: 10
Training loss: 3.306595055614825
Validation loss: 2.476812435265816

Epoch: 6| Step: 11
Training loss: 2.583330759436853
Validation loss: 2.478403851141899

Epoch: 6| Step: 12
Training loss: 2.5801550993024236
Validation loss: 2.4768879549367506

Epoch: 6| Step: 13
Training loss: 2.9258770793301636
Validation loss: 2.489442759992923

Epoch: 161| Step: 0
Training loss: 2.951332799839787
Validation loss: 2.4930366044044923

Epoch: 6| Step: 1
Training loss: 2.22393836936358
Validation loss: 2.4931727503205554

Epoch: 6| Step: 2
Training loss: 2.8252898278564555
Validation loss: 2.4886106012750107

Epoch: 6| Step: 3
Training loss: 2.444893603047914
Validation loss: 2.4939240546545123

Epoch: 6| Step: 4
Training loss: 2.1249590477082743
Validation loss: 2.492850645245552

Epoch: 6| Step: 5
Training loss: 2.440394419231702
Validation loss: 2.4840037803197084

Epoch: 6| Step: 6
Training loss: 2.2591624728503596
Validation loss: 2.5057664447845935

Epoch: 6| Step: 7
Training loss: 2.8242903366618877
Validation loss: 2.496155995285105

Epoch: 6| Step: 8
Training loss: 2.4549030250617387
Validation loss: 2.496741125327634

Epoch: 6| Step: 9
Training loss: 3.2774490866936654
Validation loss: 2.4945552447670445

Epoch: 6| Step: 10
Training loss: 3.310156803162569
Validation loss: 2.495957522041928

Epoch: 6| Step: 11
Training loss: 3.2650779740514224
Validation loss: 2.486856626715057

Epoch: 6| Step: 12
Training loss: 2.7690846845820665
Validation loss: 2.4809949576887385

Epoch: 6| Step: 13
Training loss: 3.4697444280781258
Validation loss: 2.476242136320591

Epoch: 162| Step: 0
Training loss: 3.1706104482613475
Validation loss: 2.468694366164671

Epoch: 6| Step: 1
Training loss: 2.979814330083749
Validation loss: 2.4670030314506026

Epoch: 6| Step: 2
Training loss: 2.4587214104328887
Validation loss: 2.4675481364809175

Epoch: 6| Step: 3
Training loss: 2.773015551639368
Validation loss: 2.4655843084787135

Epoch: 6| Step: 4
Training loss: 2.4306106040412527
Validation loss: 2.4674474993411097

Epoch: 6| Step: 5
Training loss: 2.845379037932703
Validation loss: 2.4743859220888558

Epoch: 6| Step: 6
Training loss: 2.9610825958533025
Validation loss: 2.461871386749155

Epoch: 6| Step: 7
Training loss: 2.692330477167488
Validation loss: 2.4662220188566812

Epoch: 6| Step: 8
Training loss: 3.119491299460094
Validation loss: 2.4659901394270456

Epoch: 6| Step: 9
Training loss: 2.410702240121609
Validation loss: 2.469186901240681

Epoch: 6| Step: 10
Training loss: 2.3805739597047832
Validation loss: 2.4691143688610793

Epoch: 6| Step: 11
Training loss: 2.5127681835770233
Validation loss: 2.4781440195051188

Epoch: 6| Step: 12
Training loss: 2.8118335358088618
Validation loss: 2.4752708372222223

Epoch: 6| Step: 13
Training loss: 3.0065266820908993
Validation loss: 2.480504245841594

Epoch: 163| Step: 0
Training loss: 2.64334363767805
Validation loss: 2.4809602144127116

Epoch: 6| Step: 1
Training loss: 2.8881876799553723
Validation loss: 2.4850900139249466

Epoch: 6| Step: 2
Training loss: 2.9309997061316384
Validation loss: 2.4765393371316615

Epoch: 6| Step: 3
Training loss: 2.6564287910876025
Validation loss: 2.4706461519715885

Epoch: 6| Step: 4
Training loss: 2.7541910660009683
Validation loss: 2.478516452475988

Epoch: 6| Step: 5
Training loss: 2.6952084728566366
Validation loss: 2.478286196625247

Epoch: 6| Step: 6
Training loss: 2.8413162716455163
Validation loss: 2.477255250785205

Epoch: 6| Step: 7
Training loss: 3.0991216707326745
Validation loss: 2.4768638490902073

Epoch: 6| Step: 8
Training loss: 2.1205867491582526
Validation loss: 2.4702076563107798

Epoch: 6| Step: 9
Training loss: 2.5717751651636633
Validation loss: 2.476029836912936

Epoch: 6| Step: 10
Training loss: 2.760112289825816
Validation loss: 2.4802581736483673

Epoch: 6| Step: 11
Training loss: 2.6793192173868436
Validation loss: 2.479544243652645

Epoch: 6| Step: 12
Training loss: 2.578488318534637
Validation loss: 2.473179284291237

Epoch: 6| Step: 13
Training loss: 3.3971782587561012
Validation loss: 2.4708559465565867

Epoch: 164| Step: 0
Training loss: 3.2645220924643015
Validation loss: 2.471954882306306

Epoch: 6| Step: 1
Training loss: 2.6736636950673676
Validation loss: 2.4643549251992027

Epoch: 6| Step: 2
Training loss: 2.837379950449945
Validation loss: 2.470032622140307

Epoch: 6| Step: 3
Training loss: 2.836691007528381
Validation loss: 2.4734480582357112

Epoch: 6| Step: 4
Training loss: 3.057629819470473
Validation loss: 2.468964876434651

Epoch: 6| Step: 5
Training loss: 3.241441755819788
Validation loss: 2.473287123259575

Epoch: 6| Step: 6
Training loss: 2.781443814157442
Validation loss: 2.474542218893034

Epoch: 6| Step: 7
Training loss: 2.8890133875731108
Validation loss: 2.4774396973290895

Epoch: 6| Step: 8
Training loss: 2.2803809195760913
Validation loss: 2.4636298059384334

Epoch: 6| Step: 9
Training loss: 2.597145707289088
Validation loss: 2.4653426572042516

Epoch: 6| Step: 10
Training loss: 2.2556677534618363
Validation loss: 2.4703952503937634

Epoch: 6| Step: 11
Training loss: 2.713906544897233
Validation loss: 2.474533761961442

Epoch: 6| Step: 12
Training loss: 2.3326693225826216
Validation loss: 2.4829210177620893

Epoch: 6| Step: 13
Training loss: 2.2907255725717626
Validation loss: 2.4780470823484553

Epoch: 165| Step: 0
Training loss: 2.513043328746196
Validation loss: 2.4730402194375416

Epoch: 6| Step: 1
Training loss: 2.5296985911078473
Validation loss: 2.462833070485463

Epoch: 6| Step: 2
Training loss: 2.442217931478517
Validation loss: 2.4623611668412058

Epoch: 6| Step: 3
Training loss: 3.1618964422207325
Validation loss: 2.4639336991824936

Epoch: 6| Step: 4
Training loss: 2.0262619983993253
Validation loss: 2.464152040781449

Epoch: 6| Step: 5
Training loss: 3.0351615915533756
Validation loss: 2.453535607176339

Epoch: 6| Step: 6
Training loss: 3.6621180989479423
Validation loss: 2.458844252925728

Epoch: 6| Step: 7
Training loss: 2.7875535660459403
Validation loss: 2.4562114994885422

Epoch: 6| Step: 8
Training loss: 3.1723498660757024
Validation loss: 2.4603631118367244

Epoch: 6| Step: 9
Training loss: 2.589285996159881
Validation loss: 2.452578046091929

Epoch: 6| Step: 10
Training loss: 2.57942398176371
Validation loss: 2.4591066132541806

Epoch: 6| Step: 11
Training loss: 2.136423707777854
Validation loss: 2.470338433194626

Epoch: 6| Step: 12
Training loss: 2.6622183673178323
Validation loss: 2.479661543825602

Epoch: 6| Step: 13
Training loss: 2.743947738438941
Validation loss: 2.493451198009434

Epoch: 166| Step: 0
Training loss: 2.6130793426473793
Validation loss: 2.502632677645441

Epoch: 6| Step: 1
Training loss: 2.7426023685680714
Validation loss: 2.5196281483790113

Epoch: 6| Step: 2
Training loss: 2.4217078366579177
Validation loss: 2.5247104575422683

Epoch: 6| Step: 3
Training loss: 3.012494137073684
Validation loss: 2.517956128962052

Epoch: 6| Step: 4
Training loss: 2.878171746850788
Validation loss: 2.5061728655177005

Epoch: 6| Step: 5
Training loss: 2.921587108769968
Validation loss: 2.5038486389809

Epoch: 6| Step: 6
Training loss: 2.474946273837096
Validation loss: 2.502409014284358

Epoch: 6| Step: 7
Training loss: 2.021501122741614
Validation loss: 2.482962192884647

Epoch: 6| Step: 8
Training loss: 2.81635461090619
Validation loss: 2.4807032449675215

Epoch: 6| Step: 9
Training loss: 3.008550221522786
Validation loss: 2.4713472925343383

Epoch: 6| Step: 10
Training loss: 2.7389928570612803
Validation loss: 2.4689258685696625

Epoch: 6| Step: 11
Training loss: 2.675623712287634
Validation loss: 2.4562869083825656

Epoch: 6| Step: 12
Training loss: 2.979448816414504
Validation loss: 2.4540860391732915

Epoch: 6| Step: 13
Training loss: 3.3528673170751397
Validation loss: 2.4577989958683473

Epoch: 167| Step: 0
Training loss: 2.4365239267597203
Validation loss: 2.461306649065499

Epoch: 6| Step: 1
Training loss: 2.630443741237944
Validation loss: 2.452196227428619

Epoch: 6| Step: 2
Training loss: 2.358901222609235
Validation loss: 2.4630473619037945

Epoch: 6| Step: 3
Training loss: 2.6524848731901263
Validation loss: 2.4579969916108215

Epoch: 6| Step: 4
Training loss: 2.6864746266808113
Validation loss: 2.462751164465734

Epoch: 6| Step: 5
Training loss: 3.0044460729291114
Validation loss: 2.455339012531858

Epoch: 6| Step: 6
Training loss: 2.424242990847724
Validation loss: 2.464095673693576

Epoch: 6| Step: 7
Training loss: 3.1418281641835275
Validation loss: 2.478968818100154

Epoch: 6| Step: 8
Training loss: 3.0785636782904238
Validation loss: 2.493023202267455

Epoch: 6| Step: 9
Training loss: 2.795204047055036
Validation loss: 2.52092442305139

Epoch: 6| Step: 10
Training loss: 2.775564662085971
Validation loss: 2.5193792166424687

Epoch: 6| Step: 11
Training loss: 3.30515453744881
Validation loss: 2.550980113800533

Epoch: 6| Step: 12
Training loss: 2.538356084122605
Validation loss: 2.569431595205254

Epoch: 6| Step: 13
Training loss: 2.780364249126111
Validation loss: 2.5619095472951017

Epoch: 168| Step: 0
Training loss: 3.2974393099506196
Validation loss: 2.529760505087839

Epoch: 6| Step: 1
Training loss: 2.9781196906411718
Validation loss: 2.526535723347335

Epoch: 6| Step: 2
Training loss: 2.9868139716277677
Validation loss: 2.5142147957574292

Epoch: 6| Step: 3
Training loss: 2.614018676901234
Validation loss: 2.494476609485108

Epoch: 6| Step: 4
Training loss: 1.953957464194424
Validation loss: 2.4835143943377123

Epoch: 6| Step: 5
Training loss: 2.742783962491155
Validation loss: 2.4800595982902998

Epoch: 6| Step: 6
Training loss: 2.396995085850064
Validation loss: 2.4604684273612123

Epoch: 6| Step: 7
Training loss: 2.331238169294922
Validation loss: 2.4605689029741566

Epoch: 6| Step: 8
Training loss: 2.915887256206207
Validation loss: 2.4662782094909548

Epoch: 6| Step: 9
Training loss: 2.3743847501815143
Validation loss: 2.4666701372377724

Epoch: 6| Step: 10
Training loss: 2.439913606208572
Validation loss: 2.457124346752221

Epoch: 6| Step: 11
Training loss: 2.7741767865087392
Validation loss: 2.450918741347198

Epoch: 6| Step: 12
Training loss: 3.3581056547646044
Validation loss: 2.4428805255516988

Epoch: 6| Step: 13
Training loss: 3.3103152573843304
Validation loss: 2.4546548485664124

Epoch: 169| Step: 0
Training loss: 2.290478889832711
Validation loss: 2.462118829585038

Epoch: 6| Step: 1
Training loss: 3.0444279160557524
Validation loss: 2.456071830883274

Epoch: 6| Step: 2
Training loss: 2.698933609780886
Validation loss: 2.4666016591171562

Epoch: 6| Step: 3
Training loss: 2.678405187988498
Validation loss: 2.4772008594164965

Epoch: 6| Step: 4
Training loss: 2.619792222818628
Validation loss: 2.4885807607593917

Epoch: 6| Step: 5
Training loss: 3.0444503135191443
Validation loss: 2.487522767869129

Epoch: 6| Step: 6
Training loss: 2.665093812418561
Validation loss: 2.486008546966576

Epoch: 6| Step: 7
Training loss: 1.6648011336830968
Validation loss: 2.4831724356589007

Epoch: 6| Step: 8
Training loss: 2.694421239361899
Validation loss: 2.4908976686785063

Epoch: 6| Step: 9
Training loss: 3.1349218406851214
Validation loss: 2.4744991714324676

Epoch: 6| Step: 10
Training loss: 2.9626918617926044
Validation loss: 2.4785162487100516

Epoch: 6| Step: 11
Training loss: 3.3815645025797485
Validation loss: 2.473045986232645

Epoch: 6| Step: 12
Training loss: 2.6161989081470365
Validation loss: 2.468264444664793

Epoch: 6| Step: 13
Training loss: 2.4186159909998457
Validation loss: 2.463837400038999

Epoch: 170| Step: 0
Training loss: 2.3445769821938773
Validation loss: 2.4725955178792045

Epoch: 6| Step: 1
Training loss: 2.175411062749096
Validation loss: 2.46999522796787

Epoch: 6| Step: 2
Training loss: 2.72442289418397
Validation loss: 2.472681322715695

Epoch: 6| Step: 3
Training loss: 2.4936500012991982
Validation loss: 2.4932884633629526

Epoch: 6| Step: 4
Training loss: 2.659342861317534
Validation loss: 2.490693991267755

Epoch: 6| Step: 5
Training loss: 3.292415260145545
Validation loss: 2.4879182487118388

Epoch: 6| Step: 6
Training loss: 2.1485897495769883
Validation loss: 2.4910273470041884

Epoch: 6| Step: 7
Training loss: 2.7579162405240107
Validation loss: 2.4943506820164694

Epoch: 6| Step: 8
Training loss: 2.6402143350927956
Validation loss: 2.4809389763730194

Epoch: 6| Step: 9
Training loss: 3.1177329444274977
Validation loss: 2.487350930017913

Epoch: 6| Step: 10
Training loss: 3.2871656588689984
Validation loss: 2.4906240172498806

Epoch: 6| Step: 11
Training loss: 2.827808172699215
Validation loss: 2.503005978042066

Epoch: 6| Step: 12
Training loss: 3.0122369105266538
Validation loss: 2.4972637194221305

Epoch: 6| Step: 13
Training loss: 2.245576112227253
Validation loss: 2.4813889353175864

Epoch: 171| Step: 0
Training loss: 3.034852394398471
Validation loss: 2.48414883519629

Epoch: 6| Step: 1
Training loss: 2.699457492013939
Validation loss: 2.4701944613820013

Epoch: 6| Step: 2
Training loss: 2.5643798631719132
Validation loss: 2.4594058076296803

Epoch: 6| Step: 3
Training loss: 2.8534527927716224
Validation loss: 2.4643322135111694

Epoch: 6| Step: 4
Training loss: 2.7582859573060454
Validation loss: 2.4770058704434676

Epoch: 6| Step: 5
Training loss: 2.8828335066032573
Validation loss: 2.4810107786707585

Epoch: 6| Step: 6
Training loss: 2.714376856772297
Validation loss: 2.4806266519305704

Epoch: 6| Step: 7
Training loss: 3.0007056360071114
Validation loss: 2.480532466350102

Epoch: 6| Step: 8
Training loss: 2.5230945082422047
Validation loss: 2.4775621094432987

Epoch: 6| Step: 9
Training loss: 2.8269273108146735
Validation loss: 2.4772632296309305

Epoch: 6| Step: 10
Training loss: 2.896502813073479
Validation loss: 2.479894020703615

Epoch: 6| Step: 11
Training loss: 2.0879681593341672
Validation loss: 2.4751007640865246

Epoch: 6| Step: 12
Training loss: 2.789445952227422
Validation loss: 2.471416360097665

Epoch: 6| Step: 13
Training loss: 2.216838281723697
Validation loss: 2.4695220244813108

Epoch: 172| Step: 0
Training loss: 3.0284673759034653
Validation loss: 2.4665892420770352

Epoch: 6| Step: 1
Training loss: 2.130867654730133
Validation loss: 2.4822450468032553

Epoch: 6| Step: 2
Training loss: 2.5585316890731877
Validation loss: 2.4882204510666814

Epoch: 6| Step: 3
Training loss: 2.3677546762769257
Validation loss: 2.482576313105519

Epoch: 6| Step: 4
Training loss: 3.093897343989694
Validation loss: 2.4973739983550467

Epoch: 6| Step: 5
Training loss: 3.5172817819195052
Validation loss: 2.5254405214794833

Epoch: 6| Step: 6
Training loss: 2.8023346193843883
Validation loss: 2.5272243588397583

Epoch: 6| Step: 7
Training loss: 2.8543027488028896
Validation loss: 2.518441575743497

Epoch: 6| Step: 8
Training loss: 2.4349210741227387
Validation loss: 2.523250866409594

Epoch: 6| Step: 9
Training loss: 2.450581100214651
Validation loss: 2.5271770199582844

Epoch: 6| Step: 10
Training loss: 3.1405135557224964
Validation loss: 2.5213609687492493

Epoch: 6| Step: 11
Training loss: 2.5216150464180247
Validation loss: 2.4944942287723233

Epoch: 6| Step: 12
Training loss: 2.3768636518955284
Validation loss: 2.4849898457901034

Epoch: 6| Step: 13
Training loss: 2.852862169040417
Validation loss: 2.464894642787236

Epoch: 173| Step: 0
Training loss: 2.5996916404679227
Validation loss: 2.4663277951862725

Epoch: 6| Step: 1
Training loss: 2.4060345838158823
Validation loss: 2.4698344442725557

Epoch: 6| Step: 2
Training loss: 2.0824665809688403
Validation loss: 2.4709967974397604

Epoch: 6| Step: 3
Training loss: 2.955066506917016
Validation loss: 2.505702585362702

Epoch: 6| Step: 4
Training loss: 2.569902938167662
Validation loss: 2.5585403122433537

Epoch: 6| Step: 5
Training loss: 3.020944597672561
Validation loss: 2.6710409376086175

Epoch: 6| Step: 6
Training loss: 3.1629736262960733
Validation loss: 2.6872217349554424

Epoch: 6| Step: 7
Training loss: 2.2029793332689387
Validation loss: 2.691628451393388

Epoch: 6| Step: 8
Training loss: 3.703183073079388
Validation loss: 2.6334197162475066

Epoch: 6| Step: 9
Training loss: 2.883602540636577
Validation loss: 2.516396507844916

Epoch: 6| Step: 10
Training loss: 3.5364479360675736
Validation loss: 2.4960173375433636

Epoch: 6| Step: 11
Training loss: 2.723732777891643
Validation loss: 2.4784066884769986

Epoch: 6| Step: 12
Training loss: 2.4728531359830317
Validation loss: 2.513922006186507

Epoch: 6| Step: 13
Training loss: 2.241834446561792
Validation loss: 2.5580873681049248

Epoch: 174| Step: 0
Training loss: 3.018322780540832
Validation loss: 2.597826073081056

Epoch: 6| Step: 1
Training loss: 2.8467900720986803
Validation loss: 2.665996867002733

Epoch: 6| Step: 2
Training loss: 2.2846429753755535
Validation loss: 2.6970639918241126

Epoch: 6| Step: 3
Training loss: 2.709143492983746
Validation loss: 2.7282359499398714

Epoch: 6| Step: 4
Training loss: 2.9251530664285132
Validation loss: 2.7465966402127906

Epoch: 6| Step: 5
Training loss: 2.634693141927143
Validation loss: 2.746634936859782

Epoch: 6| Step: 6
Training loss: 2.695829037913969
Validation loss: 2.7579887803473606

Epoch: 6| Step: 7
Training loss: 3.0650742280071066
Validation loss: 2.734060102340498

Epoch: 6| Step: 8
Training loss: 2.8177657952974795
Validation loss: 2.731286378684235

Epoch: 6| Step: 9
Training loss: 3.3817427355497283
Validation loss: 2.7631610517267653

Epoch: 6| Step: 10
Training loss: 3.1719438517196226
Validation loss: 2.677808876270035

Epoch: 6| Step: 11
Training loss: 2.4182477799295667
Validation loss: 2.5728935535261774

Epoch: 6| Step: 12
Training loss: 2.9921170617321105
Validation loss: 2.465462140793357

Epoch: 6| Step: 13
Training loss: 2.78470696761936
Validation loss: 2.4414231570735145

Epoch: 175| Step: 0
Training loss: 2.4649524694971063
Validation loss: 2.4404632256554994

Epoch: 6| Step: 1
Training loss: 3.326607371574568
Validation loss: 2.446146946133002

Epoch: 6| Step: 2
Training loss: 2.4144575172363383
Validation loss: 2.4485830361325327

Epoch: 6| Step: 3
Training loss: 3.091651590178575
Validation loss: 2.481898737079065

Epoch: 6| Step: 4
Training loss: 2.777666333400142
Validation loss: 2.4851090191805163

Epoch: 6| Step: 5
Training loss: 2.17762992847906
Validation loss: 2.533000336316529

Epoch: 6| Step: 6
Training loss: 2.9355930063324727
Validation loss: 2.559312226743196

Epoch: 6| Step: 7
Training loss: 2.52443521811735
Validation loss: 2.5946309619408012

Epoch: 6| Step: 8
Training loss: 2.849163561768433
Validation loss: 2.567356348992513

Epoch: 6| Step: 9
Training loss: 2.952845323024724
Validation loss: 2.5684636639204044

Epoch: 6| Step: 10
Training loss: 2.8771912889900007
Validation loss: 2.551236426787365

Epoch: 6| Step: 11
Training loss: 2.7125139297619896
Validation loss: 2.5015466274394247

Epoch: 6| Step: 12
Training loss: 2.942579382487618
Validation loss: 2.509400608170781

Epoch: 6| Step: 13
Training loss: 2.8964094691195124
Validation loss: 2.4784509444846194

Epoch: 176| Step: 0
Training loss: 2.7494218391925784
Validation loss: 2.4967039781848626

Epoch: 6| Step: 1
Training loss: 3.013847499237018
Validation loss: 2.444896943787762

Epoch: 6| Step: 2
Training loss: 2.5415571428892347
Validation loss: 2.44563143082463

Epoch: 6| Step: 3
Training loss: 2.8188136971121556
Validation loss: 2.4575029065206095

Epoch: 6| Step: 4
Training loss: 2.0454897087619686
Validation loss: 2.4579363822780094

Epoch: 6| Step: 5
Training loss: 2.557599569043698
Validation loss: 2.4613784283045197

Epoch: 6| Step: 6
Training loss: 3.121266690882923
Validation loss: 2.475418091926242

Epoch: 6| Step: 7
Training loss: 3.3079803150333946
Validation loss: 2.478615909974624

Epoch: 6| Step: 8
Training loss: 3.1506011570908194
Validation loss: 2.5035081654812084

Epoch: 6| Step: 9
Training loss: 3.1557226968058747
Validation loss: 2.553120441337055

Epoch: 6| Step: 10
Training loss: 3.3636722492487596
Validation loss: 2.6180392969732287

Epoch: 6| Step: 11
Training loss: 2.06721397146517
Validation loss: 2.6689736570559757

Epoch: 6| Step: 12
Training loss: 2.7137292564017477
Validation loss: 2.6655125337987586

Epoch: 6| Step: 13
Training loss: 3.559446933947174
Validation loss: 2.6647190329955346

Epoch: 177| Step: 0
Training loss: 3.0771690472076396
Validation loss: 2.6167330126100716

Epoch: 6| Step: 1
Training loss: 3.1677961008460827
Validation loss: 2.578046527164221

Epoch: 6| Step: 2
Training loss: 3.0071624449734977
Validation loss: 2.5670705133448988

Epoch: 6| Step: 3
Training loss: 2.6698457027527955
Validation loss: 2.5652794639330363

Epoch: 6| Step: 4
Training loss: 2.846692250454697
Validation loss: 2.5587985760463003

Epoch: 6| Step: 5
Training loss: 1.9708845888641147
Validation loss: 2.5605130139133605

Epoch: 6| Step: 6
Training loss: 2.525562442796816
Validation loss: 2.5783279682111586

Epoch: 6| Step: 7
Training loss: 2.236434840692073
Validation loss: 2.5465550848656764

Epoch: 6| Step: 8
Training loss: 2.8796814660243517
Validation loss: 2.540282023754436

Epoch: 6| Step: 9
Training loss: 2.7748601998520837
Validation loss: 2.532969784988997

Epoch: 6| Step: 10
Training loss: 3.050763588047066
Validation loss: 2.5035066519802514

Epoch: 6| Step: 11
Training loss: 2.7790225249452067
Validation loss: 2.4918520679803096

Epoch: 6| Step: 12
Training loss: 3.0074767086303598
Validation loss: 2.4907419556117265

Epoch: 6| Step: 13
Training loss: 2.9911181578412247
Validation loss: 2.4813684282892368

Epoch: 178| Step: 0
Training loss: 2.4610652829857886
Validation loss: 2.485924574231465

Epoch: 6| Step: 1
Training loss: 2.7619193731275407
Validation loss: 2.4748012700348223

Epoch: 6| Step: 2
Training loss: 2.306714837594795
Validation loss: 2.4698182620994826

Epoch: 6| Step: 3
Training loss: 2.8717858965876695
Validation loss: 2.4506321490180265

Epoch: 6| Step: 4
Training loss: 2.785115502528891
Validation loss: 2.4522245201914505

Epoch: 6| Step: 5
Training loss: 2.974385904996327
Validation loss: 2.435658798897936

Epoch: 6| Step: 6
Training loss: 2.8438928589202472
Validation loss: 2.446958182382078

Epoch: 6| Step: 7
Training loss: 2.8656896685809032
Validation loss: 2.4508825675496446

Epoch: 6| Step: 8
Training loss: 2.2530085265044404
Validation loss: 2.4456839592696964

Epoch: 6| Step: 9
Training loss: 2.7230261136868137
Validation loss: 2.4479578947227285

Epoch: 6| Step: 10
Training loss: 2.5200697212565166
Validation loss: 2.4503145072951775

Epoch: 6| Step: 11
Training loss: 2.868264310524624
Validation loss: 2.4600135038695354

Epoch: 6| Step: 12
Training loss: 3.1047485284129883
Validation loss: 2.46940923206654

Epoch: 6| Step: 13
Training loss: 2.985466083579925
Validation loss: 2.47633192684694

Epoch: 179| Step: 0
Training loss: 2.640793563609122
Validation loss: 2.487384212225321

Epoch: 6| Step: 1
Training loss: 2.130102874707214
Validation loss: 2.503182008430112

Epoch: 6| Step: 2
Training loss: 2.3250306322274334
Validation loss: 2.5213606149137555

Epoch: 6| Step: 3
Training loss: 2.746787188518395
Validation loss: 2.512593268627144

Epoch: 6| Step: 4
Training loss: 2.5792648107767704
Validation loss: 2.4928261127095177

Epoch: 6| Step: 5
Training loss: 2.780656815610728
Validation loss: 2.461756280785366

Epoch: 6| Step: 6
Training loss: 2.9825107683625283
Validation loss: 2.4454061403822833

Epoch: 6| Step: 7
Training loss: 3.1272245500172304
Validation loss: 2.4317000953981984

Epoch: 6| Step: 8
Training loss: 3.3542400059866364
Validation loss: 2.438217097569581

Epoch: 6| Step: 9
Training loss: 3.0629732972916814
Validation loss: 2.434337951402668

Epoch: 6| Step: 10
Training loss: 2.25529598450451
Validation loss: 2.4353144712820916

Epoch: 6| Step: 11
Training loss: 2.9412567789670008
Validation loss: 2.4406766866075094

Epoch: 6| Step: 12
Training loss: 2.8739944026204967
Validation loss: 2.440543902221261

Epoch: 6| Step: 13
Training loss: 2.4268178398951674
Validation loss: 2.4381884319738996

Epoch: 180| Step: 0
Training loss: 2.9209678179970444
Validation loss: 2.435408746615656

Epoch: 6| Step: 1
Training loss: 2.8996571239480025
Validation loss: 2.434199700706121

Epoch: 6| Step: 2
Training loss: 2.5505666365018436
Validation loss: 2.4390150588342547

Epoch: 6| Step: 3
Training loss: 2.338135670604692
Validation loss: 2.438908112657659

Epoch: 6| Step: 4
Training loss: 2.4741624821539396
Validation loss: 2.4405383012781514

Epoch: 6| Step: 5
Training loss: 2.8341347925924425
Validation loss: 2.4507852869561084

Epoch: 6| Step: 6
Training loss: 2.397879569802123
Validation loss: 2.4600480146263486

Epoch: 6| Step: 7
Training loss: 2.5595930404847467
Validation loss: 2.467609755391365

Epoch: 6| Step: 8
Training loss: 2.2334541610751772
Validation loss: 2.4769723628818014

Epoch: 6| Step: 9
Training loss: 2.4753960109590096
Validation loss: 2.4767032168084877

Epoch: 6| Step: 10
Training loss: 3.2125733007239563
Validation loss: 2.485783968965663

Epoch: 6| Step: 11
Training loss: 2.933624958222815
Validation loss: 2.5008466691758735

Epoch: 6| Step: 12
Training loss: 3.1927264878387973
Validation loss: 2.517583905861787

Epoch: 6| Step: 13
Training loss: 2.706164112446104
Validation loss: 2.5167971426505935

Epoch: 181| Step: 0
Training loss: 2.474754467739809
Validation loss: 2.51067502273489

Epoch: 6| Step: 1
Training loss: 2.0902816741445167
Validation loss: 2.503203609765849

Epoch: 6| Step: 2
Training loss: 2.7439254079027955
Validation loss: 2.5072405529684176

Epoch: 6| Step: 3
Training loss: 3.041282490197296
Validation loss: 2.5191081940949647

Epoch: 6| Step: 4
Training loss: 2.7192493725504407
Validation loss: 2.5072134812477467

Epoch: 6| Step: 5
Training loss: 2.788816467888294
Validation loss: 2.4946636487630234

Epoch: 6| Step: 6
Training loss: 3.1772025330909104
Validation loss: 2.4854863315677713

Epoch: 6| Step: 7
Training loss: 2.6141813863385055
Validation loss: 2.4631837176656703

Epoch: 6| Step: 8
Training loss: 3.0421382764880898
Validation loss: 2.458110127258541

Epoch: 6| Step: 9
Training loss: 2.56519984859155
Validation loss: 2.4611592000365587

Epoch: 6| Step: 10
Training loss: 2.2811010651765433
Validation loss: 2.446254216159389

Epoch: 6| Step: 11
Training loss: 2.9196507765036355
Validation loss: 2.4397947270797187

Epoch: 6| Step: 12
Training loss: 2.457550915707729
Validation loss: 2.4479372155019328

Epoch: 6| Step: 13
Training loss: 3.2817144156088953
Validation loss: 2.4482388696497894

Epoch: 182| Step: 0
Training loss: 2.7200529111596445
Validation loss: 2.4451806939328926

Epoch: 6| Step: 1
Training loss: 2.4347755660820036
Validation loss: 2.455008670885221

Epoch: 6| Step: 2
Training loss: 1.9974502761629407
Validation loss: 2.4536888091751305

Epoch: 6| Step: 3
Training loss: 3.012979087881094
Validation loss: 2.4498539206154586

Epoch: 6| Step: 4
Training loss: 2.596197421368455
Validation loss: 2.44256903803099

Epoch: 6| Step: 5
Training loss: 3.0510616393437866
Validation loss: 2.4596285926448282

Epoch: 6| Step: 6
Training loss: 2.8215871873249405
Validation loss: 2.4605657522986215

Epoch: 6| Step: 7
Training loss: 3.0446885308881875
Validation loss: 2.489252672355995

Epoch: 6| Step: 8
Training loss: 3.086857680252649
Validation loss: 2.486751289581715

Epoch: 6| Step: 9
Training loss: 2.511758617126257
Validation loss: 2.4962508566367383

Epoch: 6| Step: 10
Training loss: 2.649305893306508
Validation loss: 2.521441594159004

Epoch: 6| Step: 11
Training loss: 2.674006632383648
Validation loss: 2.5267814754673674

Epoch: 6| Step: 12
Training loss: 2.430505351199012
Validation loss: 2.5450060502346714

Epoch: 6| Step: 13
Training loss: 3.170090046274594
Validation loss: 2.527153549014873

Epoch: 183| Step: 0
Training loss: 2.530351926881091
Validation loss: 2.490245660108443

Epoch: 6| Step: 1
Training loss: 2.131914222108208
Validation loss: 2.4787146622529606

Epoch: 6| Step: 2
Training loss: 2.6793403066921044
Validation loss: 2.4513133491700865

Epoch: 6| Step: 3
Training loss: 3.15646633502103
Validation loss: 2.465067928529505

Epoch: 6| Step: 4
Training loss: 2.8779394630496515
Validation loss: 2.4883781835740373

Epoch: 6| Step: 5
Training loss: 3.030169107483325
Validation loss: 2.5149447653170456

Epoch: 6| Step: 6
Training loss: 2.5720897895422565
Validation loss: 2.5144208378770356

Epoch: 6| Step: 7
Training loss: 2.9187422497011326
Validation loss: 2.5302840769563195

Epoch: 6| Step: 8
Training loss: 3.0215834815274993
Validation loss: 2.52951525826558

Epoch: 6| Step: 9
Training loss: 2.691414931328978
Validation loss: 2.5226294833067513

Epoch: 6| Step: 10
Training loss: 2.962085672369478
Validation loss: 2.5052229589830515

Epoch: 6| Step: 11
Training loss: 2.9802524393163043
Validation loss: 2.49442886700426

Epoch: 6| Step: 12
Training loss: 2.5844055432287205
Validation loss: 2.475523196742852

Epoch: 6| Step: 13
Training loss: 2.5061850332463322
Validation loss: 2.4768967785080576

Epoch: 184| Step: 0
Training loss: 2.680802449752157
Validation loss: 2.4728445975945528

Epoch: 6| Step: 1
Training loss: 1.8821344698054412
Validation loss: 2.463796080109793

Epoch: 6| Step: 2
Training loss: 2.696611086064749
Validation loss: 2.45390360556596

Epoch: 6| Step: 3
Training loss: 3.1275575471823855
Validation loss: 2.456507013964559

Epoch: 6| Step: 4
Training loss: 2.9510069017733533
Validation loss: 2.4434382305429527

Epoch: 6| Step: 5
Training loss: 2.3585937419131957
Validation loss: 2.4432718258620216

Epoch: 6| Step: 6
Training loss: 3.17098099460398
Validation loss: 2.4396919930850727

Epoch: 6| Step: 7
Training loss: 3.0368462255370443
Validation loss: 2.444504982825437

Epoch: 6| Step: 8
Training loss: 2.680442058771674
Validation loss: 2.4529325557227364

Epoch: 6| Step: 9
Training loss: 2.7307825522134026
Validation loss: 2.4601633141010595

Epoch: 6| Step: 10
Training loss: 2.7477635913367315
Validation loss: 2.4944606868619092

Epoch: 6| Step: 11
Training loss: 2.9846274383991247
Validation loss: 2.497716468879206

Epoch: 6| Step: 12
Training loss: 2.5171356404205536
Validation loss: 2.504967530816909

Epoch: 6| Step: 13
Training loss: 2.3974479100015196
Validation loss: 2.491887170192718

Epoch: 185| Step: 0
Training loss: 2.5263996512941262
Validation loss: 2.471175522921015

Epoch: 6| Step: 1
Training loss: 2.3094790547509834
Validation loss: 2.461452740499852

Epoch: 6| Step: 2
Training loss: 2.5343195823320794
Validation loss: 2.4615686480061614

Epoch: 6| Step: 3
Training loss: 2.59389136974726
Validation loss: 2.45616911919579

Epoch: 6| Step: 4
Training loss: 2.8057982389111316
Validation loss: 2.457603390714815

Epoch: 6| Step: 5
Training loss: 2.564651981264449
Validation loss: 2.461496425429024

Epoch: 6| Step: 6
Training loss: 2.8304893768763493
Validation loss: 2.4662460338151764

Epoch: 6| Step: 7
Training loss: 2.9441041769793452
Validation loss: 2.477811800064356

Epoch: 6| Step: 8
Training loss: 3.2999390740983734
Validation loss: 2.470307216905996

Epoch: 6| Step: 9
Training loss: 2.4340966747459474
Validation loss: 2.4575851877391304

Epoch: 6| Step: 10
Training loss: 2.5883223033243428
Validation loss: 2.4576228734867467

Epoch: 6| Step: 11
Training loss: 2.386120610433471
Validation loss: 2.455213573249966

Epoch: 6| Step: 12
Training loss: 3.118724778556897
Validation loss: 2.470389737885493

Epoch: 6| Step: 13
Training loss: 2.777057015899325
Validation loss: 2.471487650711268

Epoch: 186| Step: 0
Training loss: 2.322820162514794
Validation loss: 2.467486549278692

Epoch: 6| Step: 1
Training loss: 2.806888917095548
Validation loss: 2.474252595785298

Epoch: 6| Step: 2
Training loss: 3.23129759998789
Validation loss: 2.486168992038704

Epoch: 6| Step: 3
Training loss: 2.31561070076135
Validation loss: 2.481438189099994

Epoch: 6| Step: 4
Training loss: 2.4397932171359957
Validation loss: 2.4932456192647354

Epoch: 6| Step: 5
Training loss: 2.3405094377946356
Validation loss: 2.5115216352201535

Epoch: 6| Step: 6
Training loss: 2.5338099215422334
Validation loss: 2.5269492907665403

Epoch: 6| Step: 7
Training loss: 2.528348319206846
Validation loss: 2.526195643639163

Epoch: 6| Step: 8
Training loss: 2.798709715143947
Validation loss: 2.528154569635177

Epoch: 6| Step: 9
Training loss: 2.7133033828425765
Validation loss: 2.507666316407273

Epoch: 6| Step: 10
Training loss: 3.105524947899528
Validation loss: 2.509865418216135

Epoch: 6| Step: 11
Training loss: 2.7339817309268004
Validation loss: 2.503070664167824

Epoch: 6| Step: 12
Training loss: 2.7914697852859356
Validation loss: 2.5090105008237544

Epoch: 6| Step: 13
Training loss: 2.959759399842503
Validation loss: 2.4983843905135696

Epoch: 187| Step: 0
Training loss: 2.698562741092885
Validation loss: 2.481871570733915

Epoch: 6| Step: 1
Training loss: 2.3616926923065766
Validation loss: 2.475634889409324

Epoch: 6| Step: 2
Training loss: 2.3582482078834177
Validation loss: 2.4735517802268068

Epoch: 6| Step: 3
Training loss: 2.673595922737962
Validation loss: 2.481787747773095

Epoch: 6| Step: 4
Training loss: 3.224603607893465
Validation loss: 2.4737492737360207

Epoch: 6| Step: 5
Training loss: 2.6811634147553027
Validation loss: 2.475175415208389

Epoch: 6| Step: 6
Training loss: 3.2569485257432027
Validation loss: 2.469919752362053

Epoch: 6| Step: 7
Training loss: 2.5872566108674446
Validation loss: 2.4559035431067984

Epoch: 6| Step: 8
Training loss: 2.3622844012344646
Validation loss: 2.454435480374949

Epoch: 6| Step: 9
Training loss: 2.364549835460746
Validation loss: 2.4460448017393017

Epoch: 6| Step: 10
Training loss: 3.4919036135398183
Validation loss: 2.452886187438636

Epoch: 6| Step: 11
Training loss: 2.503646670498016
Validation loss: 2.452386332464712

Epoch: 6| Step: 12
Training loss: 2.27958419806296
Validation loss: 2.454869754671979

Epoch: 6| Step: 13
Training loss: 2.3644653380497815
Validation loss: 2.47072674413589

Epoch: 188| Step: 0
Training loss: 3.069142514238314
Validation loss: 2.485465562319169

Epoch: 6| Step: 1
Training loss: 2.947250093149929
Validation loss: 2.480981804631716

Epoch: 6| Step: 2
Training loss: 2.9527687786352335
Validation loss: 2.490336752389018

Epoch: 6| Step: 3
Training loss: 2.3431851532897814
Validation loss: 2.4922308354688245

Epoch: 6| Step: 4
Training loss: 2.579677137681007
Validation loss: 2.5058286421353735

Epoch: 6| Step: 5
Training loss: 2.561878687271253
Validation loss: 2.5045573022437666

Epoch: 6| Step: 6
Training loss: 2.5021246464918634
Validation loss: 2.503718473824014

Epoch: 6| Step: 7
Training loss: 2.5162301609187674
Validation loss: 2.5043883058730843

Epoch: 6| Step: 8
Training loss: 2.5948706354666564
Validation loss: 2.4976014449518757

Epoch: 6| Step: 9
Training loss: 2.921978790561327
Validation loss: 2.5045248460312854

Epoch: 6| Step: 10
Training loss: 2.5162475952804
Validation loss: 2.5183319394220494

Epoch: 6| Step: 11
Training loss: 2.530538199856429
Validation loss: 2.529419495753959

Epoch: 6| Step: 12
Training loss: 2.43543674492262
Validation loss: 2.54765529218783

Epoch: 6| Step: 13
Training loss: 3.4048057083960415
Validation loss: 2.5208274768695893

Epoch: 189| Step: 0
Training loss: 2.4946095526902674
Validation loss: 2.4998407743877635

Epoch: 6| Step: 1
Training loss: 3.152432692169987
Validation loss: 2.4847393474286275

Epoch: 6| Step: 2
Training loss: 2.521837796264166
Validation loss: 2.4958760086983522

Epoch: 6| Step: 3
Training loss: 2.3019026143066856
Validation loss: 2.4942872970675936

Epoch: 6| Step: 4
Training loss: 2.0620640380639044
Validation loss: 2.4891613251493223

Epoch: 6| Step: 5
Training loss: 3.073538369257785
Validation loss: 2.4940885589669604

Epoch: 6| Step: 6
Training loss: 2.2180185321140287
Validation loss: 2.4988951210405412

Epoch: 6| Step: 7
Training loss: 2.6325039555446543
Validation loss: 2.5057633294541106

Epoch: 6| Step: 8
Training loss: 2.9692197729160243
Validation loss: 2.503914211495319

Epoch: 6| Step: 9
Training loss: 2.6677869787891195
Validation loss: 2.4919838631995215

Epoch: 6| Step: 10
Training loss: 3.007314031341833
Validation loss: 2.480953678617303

Epoch: 6| Step: 11
Training loss: 2.798640626215844
Validation loss: 2.4736332622918726

Epoch: 6| Step: 12
Training loss: 2.7690818432759876
Validation loss: 2.472858687578471

Epoch: 6| Step: 13
Training loss: 2.169085790489603
Validation loss: 2.462127149026742

Epoch: 190| Step: 0
Training loss: 2.186843882663958
Validation loss: 2.471053181401159

Epoch: 6| Step: 1
Training loss: 2.4218441868944587
Validation loss: 2.4682074838968093

Epoch: 6| Step: 2
Training loss: 2.629013807525303
Validation loss: 2.4694579648685826

Epoch: 6| Step: 3
Training loss: 2.5803419349361794
Validation loss: 2.471252639182104

Epoch: 6| Step: 4
Training loss: 2.386236013987955
Validation loss: 2.468091973340668

Epoch: 6| Step: 5
Training loss: 2.445734054742731
Validation loss: 2.482058559033812

Epoch: 6| Step: 6
Training loss: 2.690385201254261
Validation loss: 2.485019157898521

Epoch: 6| Step: 7
Training loss: 2.856880141850102
Validation loss: 2.492720305861595

Epoch: 6| Step: 8
Training loss: 2.382218083517234
Validation loss: 2.507372951312564

Epoch: 6| Step: 9
Training loss: 2.90448502301206
Validation loss: 2.5109516816664295

Epoch: 6| Step: 10
Training loss: 3.1470035288075464
Validation loss: 2.5254354158975065

Epoch: 6| Step: 11
Training loss: 3.121402042521849
Validation loss: 2.558053843265404

Epoch: 6| Step: 12
Training loss: 2.737577731627075
Validation loss: 2.5060613001894474

Epoch: 6| Step: 13
Training loss: 2.4134867453771283
Validation loss: 2.515578295830132

Epoch: 191| Step: 0
Training loss: 2.678613742312499
Validation loss: 2.5013292449970934

Epoch: 6| Step: 1
Training loss: 2.781042284120411
Validation loss: 2.5063224094018506

Epoch: 6| Step: 2
Training loss: 2.369626843655732
Validation loss: 2.482662524735101

Epoch: 6| Step: 3
Training loss: 2.6850887393317073
Validation loss: 2.4866055503932927

Epoch: 6| Step: 4
Training loss: 2.8543535343078856
Validation loss: 2.4950373112464477

Epoch: 6| Step: 5
Training loss: 2.713999489342143
Validation loss: 2.48639309963702

Epoch: 6| Step: 6
Training loss: 2.6472237205256515
Validation loss: 2.487038878901033

Epoch: 6| Step: 7
Training loss: 2.309926224558445
Validation loss: 2.4736474338031345

Epoch: 6| Step: 8
Training loss: 2.706176270500324
Validation loss: 2.478621452799855

Epoch: 6| Step: 9
Training loss: 2.778059340088329
Validation loss: 2.4748445991793044

Epoch: 6| Step: 10
Training loss: 2.259760455205571
Validation loss: 2.4831000092989477

Epoch: 6| Step: 11
Training loss: 2.9749405414185315
Validation loss: 2.480176357263291

Epoch: 6| Step: 12
Training loss: 2.2941822694505825
Validation loss: 2.478896236862574

Epoch: 6| Step: 13
Training loss: 2.769245514973074
Validation loss: 2.4804785416506476

Epoch: 192| Step: 0
Training loss: 2.431361366996652
Validation loss: 2.467622430660286

Epoch: 6| Step: 1
Training loss: 2.6062358316086702
Validation loss: 2.4805691058691632

Epoch: 6| Step: 2
Training loss: 2.6236523393154085
Validation loss: 2.4816504121921596

Epoch: 6| Step: 3
Training loss: 2.6183494607520603
Validation loss: 2.476974349026048

Epoch: 6| Step: 4
Training loss: 2.744422979524029
Validation loss: 2.4819327379750358

Epoch: 6| Step: 5
Training loss: 2.530100903063235
Validation loss: 2.4982759109223736

Epoch: 6| Step: 6
Training loss: 2.2677444541576532
Validation loss: 2.504220502002153

Epoch: 6| Step: 7
Training loss: 2.9156188899361553
Validation loss: 2.4970445432168296

Epoch: 6| Step: 8
Training loss: 2.674780620955531
Validation loss: 2.515890388856591

Epoch: 6| Step: 9
Training loss: 2.907253953358118
Validation loss: 2.514531486858884

Epoch: 6| Step: 10
Training loss: 2.9448419898345604
Validation loss: 2.5142795656741255

Epoch: 6| Step: 11
Training loss: 2.215694741683514
Validation loss: 2.501669941261017

Epoch: 6| Step: 12
Training loss: 2.753477845113389
Validation loss: 2.499429048949879

Epoch: 6| Step: 13
Training loss: 1.7750652757918914
Validation loss: 2.4777946601759857

Epoch: 193| Step: 0
Training loss: 2.587408563592378
Validation loss: 2.479088516706378

Epoch: 6| Step: 1
Training loss: 2.041026138205579
Validation loss: 2.4569231973364536

Epoch: 6| Step: 2
Training loss: 2.7531778873901804
Validation loss: 2.4472029930951806

Epoch: 6| Step: 3
Training loss: 1.8831728515217332
Validation loss: 2.4276821012808005

Epoch: 6| Step: 4
Training loss: 2.6661542360372468
Validation loss: 2.4276635556776562

Epoch: 6| Step: 5
Training loss: 2.7128797274124175
Validation loss: 2.42735577851199

Epoch: 6| Step: 6
Training loss: 2.2350393521388234
Validation loss: 2.426161157308429

Epoch: 6| Step: 7
Training loss: 2.5384592131846344
Validation loss: 2.4356165156907847

Epoch: 6| Step: 8
Training loss: 2.9732386335622194
Validation loss: 2.4383934566962706

Epoch: 6| Step: 9
Training loss: 2.7322032042035342
Validation loss: 2.436680326483123

Epoch: 6| Step: 10
Training loss: 2.8262402065534276
Validation loss: 2.4478517780767013

Epoch: 6| Step: 11
Training loss: 2.9405389852237303
Validation loss: 2.440137336153465

Epoch: 6| Step: 12
Training loss: 2.4356441768980788
Validation loss: 2.4474681788133976

Epoch: 6| Step: 13
Training loss: 3.2370852112630626
Validation loss: 2.439150464707858

Epoch: 194| Step: 0
Training loss: 2.167812582353907
Validation loss: 2.459436840191941

Epoch: 6| Step: 1
Training loss: 3.112991453537083
Validation loss: 2.4531814780839207

Epoch: 6| Step: 2
Training loss: 2.2751045538383496
Validation loss: 2.4534417951034735

Epoch: 6| Step: 3
Training loss: 2.9849587713362387
Validation loss: 2.4635493270948134

Epoch: 6| Step: 4
Training loss: 2.547500159176568
Validation loss: 2.488195153714723

Epoch: 6| Step: 5
Training loss: 2.4262319444066107
Validation loss: 2.4935387151305015

Epoch: 6| Step: 6
Training loss: 2.111337158861339
Validation loss: 2.4857116104473405

Epoch: 6| Step: 7
Training loss: 2.8419577851244022
Validation loss: 2.4980419120112933

Epoch: 6| Step: 8
Training loss: 2.3695651662268857
Validation loss: 2.4933205579099504

Epoch: 6| Step: 9
Training loss: 3.0763722962983735
Validation loss: 2.474045263208489

Epoch: 6| Step: 10
Training loss: 2.567248712739762
Validation loss: 2.4752418550297253

Epoch: 6| Step: 11
Training loss: 2.747786584821073
Validation loss: 2.4750887273481825

Epoch: 6| Step: 12
Training loss: 2.4117452122627028
Validation loss: 2.4705243518540168

Epoch: 6| Step: 13
Training loss: 2.286871476672415
Validation loss: 2.4758096434853973

Epoch: 195| Step: 0
Training loss: 3.0851521325585023
Validation loss: 2.4877528087653493

Epoch: 6| Step: 1
Training loss: 1.744526750940585
Validation loss: 2.478175810011486

Epoch: 6| Step: 2
Training loss: 2.1038729648386463
Validation loss: 2.48369578320519

Epoch: 6| Step: 3
Training loss: 2.5682638520437497
Validation loss: 2.481828357039475

Epoch: 6| Step: 4
Training loss: 2.2488714142741584
Validation loss: 2.4940581004401774

Epoch: 6| Step: 5
Training loss: 3.152087649090105
Validation loss: 2.4815329198662677

Epoch: 6| Step: 6
Training loss: 2.3974324956943276
Validation loss: 2.4740179422361455

Epoch: 6| Step: 7
Training loss: 2.789547832586946
Validation loss: 2.4907005478216355

Epoch: 6| Step: 8
Training loss: 2.498304745962496
Validation loss: 2.5061684597522107

Epoch: 6| Step: 9
Training loss: 2.1347718792794934
Validation loss: 2.5106082482843486

Epoch: 6| Step: 10
Training loss: 2.42169543185109
Validation loss: 2.505149758928436

Epoch: 6| Step: 11
Training loss: 3.1058739355852096
Validation loss: 2.534085598517877

Epoch: 6| Step: 12
Training loss: 2.957253129060131
Validation loss: 2.5238692036490296

Epoch: 6| Step: 13
Training loss: 2.8833845857978604
Validation loss: 2.530751001781536

Epoch: 196| Step: 0
Training loss: 3.3603619212551035
Validation loss: 2.511704899444741

Epoch: 6| Step: 1
Training loss: 1.774528067269292
Validation loss: 2.5041641420705836

Epoch: 6| Step: 2
Training loss: 2.601130177544178
Validation loss: 2.485035616599503

Epoch: 6| Step: 3
Training loss: 2.650359140207704
Validation loss: 2.4908140146413165

Epoch: 6| Step: 4
Training loss: 2.5713223499732436
Validation loss: 2.452340402845779

Epoch: 6| Step: 5
Training loss: 2.8075672549907664
Validation loss: 2.449300594106886

Epoch: 6| Step: 6
Training loss: 2.447292416023297
Validation loss: 2.4502122300747424

Epoch: 6| Step: 7
Training loss: 2.133683358723353
Validation loss: 2.4287324718044467

Epoch: 6| Step: 8
Training loss: 2.3456701932274084
Validation loss: 2.4263515281944392

Epoch: 6| Step: 9
Training loss: 2.3289365442065866
Validation loss: 2.4269592311170554

Epoch: 6| Step: 10
Training loss: 2.6159391699901713
Validation loss: 2.4331974954009734

Epoch: 6| Step: 11
Training loss: 2.7326773468848704
Validation loss: 2.4388798462135615

Epoch: 6| Step: 12
Training loss: 2.226918617011954
Validation loss: 2.4549436978896724

Epoch: 6| Step: 13
Training loss: 3.2250251709894644
Validation loss: 2.4496281498818404

Epoch: 197| Step: 0
Training loss: 2.5996325783442775
Validation loss: 2.4967214415950245

Epoch: 6| Step: 1
Training loss: 2.543015815076654
Validation loss: 2.511382477353787

Epoch: 6| Step: 2
Training loss: 3.024445121884027
Validation loss: 2.5355942612866116

Epoch: 6| Step: 3
Training loss: 1.9116200959847331
Validation loss: 2.5505014225959224

Epoch: 6| Step: 4
Training loss: 2.421599341671126
Validation loss: 2.5343986160438203

Epoch: 6| Step: 5
Training loss: 2.55087686683705
Validation loss: 2.5473400169320284

Epoch: 6| Step: 6
Training loss: 2.5822046541975845
Validation loss: 2.5748626980613123

Epoch: 6| Step: 7
Training loss: 2.432454584997416
Validation loss: 2.5689296039958602

Epoch: 6| Step: 8
Training loss: 2.3066944758809766
Validation loss: 2.565441344338703

Epoch: 6| Step: 9
Training loss: 2.5384335721971856
Validation loss: 2.570189199922856

Epoch: 6| Step: 10
Training loss: 2.2834740862193517
Validation loss: 2.574010307602755

Epoch: 6| Step: 11
Training loss: 2.957354710574177
Validation loss: 2.5761337072821253

Epoch: 6| Step: 12
Training loss: 3.1187461837714627
Validation loss: 2.55867990215499

Epoch: 6| Step: 13
Training loss: 2.0473685797875927
Validation loss: 2.5566848032478755

Epoch: 198| Step: 0
Training loss: 2.645426340915112
Validation loss: 2.537414412704658

Epoch: 6| Step: 1
Training loss: 2.508772621680024
Validation loss: 2.5484646018184205

Epoch: 6| Step: 2
Training loss: 2.162459127227313
Validation loss: 2.5484925199338204

Epoch: 6| Step: 3
Training loss: 2.4419520874196974
Validation loss: 2.5389426723882784

Epoch: 6| Step: 4
Training loss: 2.2375877064825103
Validation loss: 2.5257249635945485

Epoch: 6| Step: 5
Training loss: 3.005861119994214
Validation loss: 2.5167039511377878

Epoch: 6| Step: 6
Training loss: 2.1710742599529445
Validation loss: 2.507097660349146

Epoch: 6| Step: 7
Training loss: 2.877132785675046
Validation loss: 2.49225579869393

Epoch: 6| Step: 8
Training loss: 2.542140093210742
Validation loss: 2.477872367089106

Epoch: 6| Step: 9
Training loss: 2.5120391878606623
Validation loss: 2.5019001394905316

Epoch: 6| Step: 10
Training loss: 2.9867307941614007
Validation loss: 2.513977082736228

Epoch: 6| Step: 11
Training loss: 2.5229010705652195
Validation loss: 2.51910618418039

Epoch: 6| Step: 12
Training loss: 2.252711887025783
Validation loss: 2.5158484289703926

Epoch: 6| Step: 13
Training loss: 2.7595749537426024
Validation loss: 2.5086312572469947

Epoch: 199| Step: 0
Training loss: 2.7076483129173354
Validation loss: 2.507207767478137

Epoch: 6| Step: 1
Training loss: 2.878544157075482
Validation loss: 2.499130534673811

Epoch: 6| Step: 2
Training loss: 2.5955398083380423
Validation loss: 2.481625561291482

Epoch: 6| Step: 3
Training loss: 2.368420773779423
Validation loss: 2.499528855874182

Epoch: 6| Step: 4
Training loss: 2.898097097967148
Validation loss: 2.4896721698983537

Epoch: 6| Step: 5
Training loss: 2.5068544833690196
Validation loss: 2.4975895920957916

Epoch: 6| Step: 6
Training loss: 2.6799110786432476
Validation loss: 2.5082777607154383

Epoch: 6| Step: 7
Training loss: 2.1262064482250147
Validation loss: 2.516585287831878

Epoch: 6| Step: 8
Training loss: 2.878340728991766
Validation loss: 2.5334012354648965

Epoch: 6| Step: 9
Training loss: 2.736872290143651
Validation loss: 2.5539497112179497

Epoch: 6| Step: 10
Training loss: 2.312024041760322
Validation loss: 2.546020517472645

Epoch: 6| Step: 11
Training loss: 2.128193307192065
Validation loss: 2.5168439545827157

Epoch: 6| Step: 12
Training loss: 2.099722925708555
Validation loss: 2.504285018556829

Epoch: 6| Step: 13
Training loss: 1.820953649158268
Validation loss: 2.4850357713442

Epoch: 200| Step: 0
Training loss: 2.4778900920271876
Validation loss: 2.4657848657192183

Epoch: 6| Step: 1
Training loss: 2.425580838043949
Validation loss: 2.473608536054193

Epoch: 6| Step: 2
Training loss: 2.345157658334264
Validation loss: 2.457831574700487

Epoch: 6| Step: 3
Training loss: 2.5168167987362287
Validation loss: 2.455660551875531

Epoch: 6| Step: 4
Training loss: 2.119595330321061
Validation loss: 2.453648105097288

Epoch: 6| Step: 5
Training loss: 2.2522603443275315
Validation loss: 2.4696222968053396

Epoch: 6| Step: 6
Training loss: 2.409018966948512
Validation loss: 2.457324934075055

Epoch: 6| Step: 7
Training loss: 2.2273515340561327
Validation loss: 2.46144401050331

Epoch: 6| Step: 8
Training loss: 2.8403778203637895
Validation loss: 2.4832197255704247

Epoch: 6| Step: 9
Training loss: 2.094094091580436
Validation loss: 2.4784120104110334

Epoch: 6| Step: 10
Training loss: 2.984378035778479
Validation loss: 2.488769210378943

Epoch: 6| Step: 11
Training loss: 2.8242681348606244
Validation loss: 2.489935015789864

Epoch: 6| Step: 12
Training loss: 2.9019617417151484
Validation loss: 2.5039266072556066

Epoch: 6| Step: 13
Training loss: 2.532369389682232
Validation loss: 2.496417102304637

Epoch: 201| Step: 0
Training loss: 2.684320209907687
Validation loss: 2.484704587381369

Epoch: 6| Step: 1
Training loss: 2.4329619590209317
Validation loss: 2.483288073727775

Epoch: 6| Step: 2
Training loss: 2.392727992755226
Validation loss: 2.471478206200154

Epoch: 6| Step: 3
Training loss: 2.260975031880626
Validation loss: 2.48285101260115

Epoch: 6| Step: 4
Training loss: 1.815593972655026
Validation loss: 2.4985854823224742

Epoch: 6| Step: 5
Training loss: 2.6996172598369155
Validation loss: 2.512560016288927

Epoch: 6| Step: 6
Training loss: 2.4128910913848305
Validation loss: 2.5273896514776144

Epoch: 6| Step: 7
Training loss: 2.4122169130886664
Validation loss: 2.5327242719674374

Epoch: 6| Step: 8
Training loss: 2.6097467580249485
Validation loss: 2.5335665865294392

Epoch: 6| Step: 9
Training loss: 2.540877787834106
Validation loss: 2.521720151239764

Epoch: 6| Step: 10
Training loss: 2.5882873000820665
Validation loss: 2.523435677417526

Epoch: 6| Step: 11
Training loss: 2.972227930398215
Validation loss: 2.5026685367477177

Epoch: 6| Step: 12
Training loss: 2.2972988853388454
Validation loss: 2.5123088265189706

Epoch: 6| Step: 13
Training loss: 2.1949496257797567
Validation loss: 2.5090619169651247

Epoch: 202| Step: 0
Training loss: 2.410023591333685
Validation loss: 2.506097479521484

Epoch: 6| Step: 1
Training loss: 2.747538939209624
Validation loss: 2.5165552238341573

Epoch: 6| Step: 2
Training loss: 1.9844845719010469
Validation loss: 2.5206521641278643

Epoch: 6| Step: 3
Training loss: 2.9807659915878073
Validation loss: 2.520975666372095

Epoch: 6| Step: 4
Training loss: 2.7295688788979913
Validation loss: 2.518115483738206

Epoch: 6| Step: 5
Training loss: 2.469285448169619
Validation loss: 2.519371392547023

Epoch: 6| Step: 6
Training loss: 1.9861310262800504
Validation loss: 2.5095447150506276

Epoch: 6| Step: 7
Training loss: 1.9809937994377076
Validation loss: 2.508091175541853

Epoch: 6| Step: 8
Training loss: 2.7453462931898502
Validation loss: 2.5101479960268036

Epoch: 6| Step: 9
Training loss: 2.0404939851866173
Validation loss: 2.5036115339976903

Epoch: 6| Step: 10
Training loss: 2.2636314302901135
Validation loss: 2.512594269557535

Epoch: 6| Step: 11
Training loss: 2.620301355691958
Validation loss: 2.521819209113878

Epoch: 6| Step: 12
Training loss: 2.9057685699407765
Validation loss: 2.524180203529352

Epoch: 6| Step: 13
Training loss: 1.9762571196937555
Validation loss: 2.530392838793189

Epoch: 203| Step: 0
Training loss: 2.228614156351845
Validation loss: 2.5115210891177946

Epoch: 6| Step: 1
Training loss: 2.780170445465721
Validation loss: 2.514812621871548

Epoch: 6| Step: 2
Training loss: 2.4901351849118036
Validation loss: 2.5002030259416874

Epoch: 6| Step: 3
Training loss: 2.4332209465340586
Validation loss: 2.5083221059862786

Epoch: 6| Step: 4
Training loss: 1.8436508798626265
Validation loss: 2.50465377991571

Epoch: 6| Step: 5
Training loss: 2.2065528553696687
Validation loss: 2.480646908793846

Epoch: 6| Step: 6
Training loss: 2.965454038751035
Validation loss: 2.5005526670110427

Epoch: 6| Step: 7
Training loss: 2.466482932318795
Validation loss: 2.4997411060615877

Epoch: 6| Step: 8
Training loss: 1.9645469244141505
Validation loss: 2.5126072816163316

Epoch: 6| Step: 9
Training loss: 2.107004034073801
Validation loss: 2.529343169768946

Epoch: 6| Step: 10
Training loss: 2.481919520681747
Validation loss: 2.504169689771304

Epoch: 6| Step: 11
Training loss: 2.5204366786988652
Validation loss: 2.5254569822034214

Epoch: 6| Step: 12
Training loss: 2.753716818063708
Validation loss: 2.5343136312611603

Epoch: 6| Step: 13
Training loss: 2.952154252289179
Validation loss: 2.530384362854928

Epoch: 204| Step: 0
Training loss: 1.8628749444405193
Validation loss: 2.5060191041189923

Epoch: 6| Step: 1
Training loss: 2.1906131934529376
Validation loss: 2.5118725095086014

Epoch: 6| Step: 2
Training loss: 1.9693493611934643
Validation loss: 2.5259195237124086

Epoch: 6| Step: 3
Training loss: 2.501256055009596
Validation loss: 2.5269773654229937

Epoch: 6| Step: 4
Training loss: 2.817772987361985
Validation loss: 2.5245982613310294

Epoch: 6| Step: 5
Training loss: 2.745393883633812
Validation loss: 2.525953090388853

Epoch: 6| Step: 6
Training loss: 2.432179831657295
Validation loss: 2.5082428689765317

Epoch: 6| Step: 7
Training loss: 2.094939847460432
Validation loss: 2.5297302480433306

Epoch: 6| Step: 8
Training loss: 2.731888168816386
Validation loss: 2.5233672950818278

Epoch: 6| Step: 9
Training loss: 3.03294545373061
Validation loss: 2.5246406413981974

Epoch: 6| Step: 10
Training loss: 2.1434529134794325
Validation loss: 2.512185002702783

Epoch: 6| Step: 11
Training loss: 2.5320438976731134
Validation loss: 2.518161974907218

Epoch: 6| Step: 12
Training loss: 1.922577892258344
Validation loss: 2.525759268730312

Epoch: 6| Step: 13
Training loss: 2.1757699633978467
Validation loss: 2.556142883599825

Epoch: 205| Step: 0
Training loss: 2.5526972025913444
Validation loss: 2.573394869117994

Epoch: 6| Step: 1
Training loss: 1.748370024578215
Validation loss: 2.5717576058199962

Epoch: 6| Step: 2
Training loss: 2.988870320819847
Validation loss: 2.563438889812148

Epoch: 6| Step: 3
Training loss: 2.1023581888134677
Validation loss: 2.5745328865607955

Epoch: 6| Step: 4
Training loss: 2.334652039865323
Validation loss: 2.5711959795161374

Epoch: 6| Step: 5
Training loss: 2.4888944005148277
Validation loss: 2.573477824145531

Epoch: 6| Step: 6
Training loss: 2.5039626188077806
Validation loss: 2.592505039482287

Epoch: 6| Step: 7
Training loss: 2.292874231941158
Validation loss: 2.5724034107375537

Epoch: 6| Step: 8
Training loss: 2.690080158216367
Validation loss: 2.5805984827724284

Epoch: 6| Step: 9
Training loss: 2.780509078528392
Validation loss: 2.573903648808261

Epoch: 6| Step: 10
Training loss: 2.3322048410187284
Validation loss: 2.5799249197399736

Epoch: 6| Step: 11
Training loss: 1.5781940407333628
Validation loss: 2.573152203436289

Epoch: 6| Step: 12
Training loss: 1.6748088158203494
Validation loss: 2.5650553833852534

Epoch: 6| Step: 13
Training loss: 2.9255838773233616
Validation loss: 2.5803567255374724

Epoch: 206| Step: 0
Training loss: 2.4448101271095037
Validation loss: 2.59215839101157

Epoch: 6| Step: 1
Training loss: 1.909867715398864
Validation loss: 2.59868296742436

Epoch: 6| Step: 2
Training loss: 2.4241530994373517
Validation loss: 2.623522645997408

Epoch: 6| Step: 3
Training loss: 1.8370795411159972
Validation loss: 2.619959151142053

Epoch: 6| Step: 4
Training loss: 2.150399162143873
Validation loss: 2.652705238838195

Epoch: 6| Step: 5
Training loss: 2.2727632866520264
Validation loss: 2.62668054913026

Epoch: 6| Step: 6
Training loss: 2.589676197092241
Validation loss: 2.6148024433178527

Epoch: 6| Step: 7
Training loss: 3.1467324460422588
Validation loss: 2.6206936806387917

Epoch: 6| Step: 8
Training loss: 2.2032845080915426
Validation loss: 2.605651336435208

Epoch: 6| Step: 9
Training loss: 2.5164184266831766
Validation loss: 2.5929855522863523

Epoch: 6| Step: 10
Training loss: 2.584669188207551
Validation loss: 2.5850606007219494

Epoch: 6| Step: 11
Training loss: 2.369015632973937
Validation loss: 2.5681125624122725

Epoch: 6| Step: 12
Training loss: 2.6477925013121557
Validation loss: 2.563574411894997

Epoch: 6| Step: 13
Training loss: 1.7684597788241743
Validation loss: 2.5428890601835574

Epoch: 207| Step: 0
Training loss: 1.5921299498155324
Validation loss: 2.5609831783969423

Epoch: 6| Step: 1
Training loss: 2.20909489389753
Validation loss: 2.5664486968576075

Epoch: 6| Step: 2
Training loss: 2.722739788946602
Validation loss: 2.584070866191186

Epoch: 6| Step: 3
Training loss: 1.7530355012457477
Validation loss: 2.5987055348515025

Epoch: 6| Step: 4
Training loss: 2.731730986608495
Validation loss: 2.602155562704196

Epoch: 6| Step: 5
Training loss: 2.0999422882869285
Validation loss: 2.6189956749115977

Epoch: 6| Step: 6
Training loss: 2.294189959748567
Validation loss: 2.623112503379261

Epoch: 6| Step: 7
Training loss: 2.404511257006463
Validation loss: 2.6363541531264465

Epoch: 6| Step: 8
Training loss: 2.7606140258101117
Validation loss: 2.615149085057037

Epoch: 6| Step: 9
Training loss: 2.2986214155085904
Validation loss: 2.6029090706208984

Epoch: 6| Step: 10
Training loss: 2.284627634839123
Validation loss: 2.59764376265764

Epoch: 6| Step: 11
Training loss: 2.694811788296322
Validation loss: 2.575799661383232

Epoch: 6| Step: 12
Training loss: 2.2992387921739446
Validation loss: 2.57296737103476

Epoch: 6| Step: 13
Training loss: 2.4232235999188885
Validation loss: 2.530340664616573

Epoch: 208| Step: 0
Training loss: 2.26219854717611
Validation loss: 2.5046285385115037

Epoch: 6| Step: 1
Training loss: 2.058795723607121
Validation loss: 2.4908309476086616

Epoch: 6| Step: 2
Training loss: 2.39375290036337
Validation loss: 2.469589303089444

Epoch: 6| Step: 3
Training loss: 2.6067323380154828
Validation loss: 2.4818240061891066

Epoch: 6| Step: 4
Training loss: 2.721244369311765
Validation loss: 2.476070536471565

Epoch: 6| Step: 5
Training loss: 2.231807487361876
Validation loss: 2.508106304310287

Epoch: 6| Step: 6
Training loss: 2.0057633329611853
Validation loss: 2.5518730902361715

Epoch: 6| Step: 7
Training loss: 1.9351379393664965
Validation loss: 2.604644123894873

Epoch: 6| Step: 8
Training loss: 2.3451060123515695
Validation loss: 2.618747378198285

Epoch: 6| Step: 9
Training loss: 2.655003423455109
Validation loss: 2.634941462577015

Epoch: 6| Step: 10
Training loss: 2.7293418556264197
Validation loss: 2.612570982746554

Epoch: 6| Step: 11
Training loss: 1.9849387742216251
Validation loss: 2.5976145312055396

Epoch: 6| Step: 12
Training loss: 2.532644758841497
Validation loss: 2.5646432207054852

Epoch: 6| Step: 13
Training loss: 2.4985610635535136
Validation loss: 2.548177988124089

Epoch: 209| Step: 0
Training loss: 2.9298751567503802
Validation loss: 2.535791608682498

Epoch: 6| Step: 1
Training loss: 1.7840824027595883
Validation loss: 2.5248923492064077

Epoch: 6| Step: 2
Training loss: 1.667960602429969
Validation loss: 2.5074362799904133

Epoch: 6| Step: 3
Training loss: 2.8054935072866396
Validation loss: 2.503300532865414

Epoch: 6| Step: 4
Training loss: 2.235715024104447
Validation loss: 2.510844989670309

Epoch: 6| Step: 5
Training loss: 2.5149648996865293
Validation loss: 2.5265012998874794

Epoch: 6| Step: 6
Training loss: 2.581977231936605
Validation loss: 2.5227838841430783

Epoch: 6| Step: 7
Training loss: 2.4617637579316427
Validation loss: 2.5482963784640162

Epoch: 6| Step: 8
Training loss: 2.2318523544918865
Validation loss: 2.54453042287447

Epoch: 6| Step: 9
Training loss: 1.619432595574792
Validation loss: 2.5798411574310407

Epoch: 6| Step: 10
Training loss: 1.9910311465737012
Validation loss: 2.639206534134486

Epoch: 6| Step: 11
Training loss: 2.4345395621428443
Validation loss: 2.6659847728469575

Epoch: 6| Step: 12
Training loss: 2.2381464999182774
Validation loss: 2.6570810445168185

Epoch: 6| Step: 13
Training loss: 2.7029687031448706
Validation loss: 2.625367364994402

Epoch: 210| Step: 0
Training loss: 2.4393154132904495
Validation loss: 2.585781462364329

Epoch: 6| Step: 1
Training loss: 2.186599109970689
Validation loss: 2.570186959644445

Epoch: 6| Step: 2
Training loss: 1.5525703775422484
Validation loss: 2.5409557297037284

Epoch: 6| Step: 3
Training loss: 2.502376094803203
Validation loss: 2.543693913787833

Epoch: 6| Step: 4
Training loss: 2.3117047566321998
Validation loss: 2.5351642478509424

Epoch: 6| Step: 5
Training loss: 2.4531096439731357
Validation loss: 2.5489379200357942

Epoch: 6| Step: 6
Training loss: 2.468266210353851
Validation loss: 2.545138174212464

Epoch: 6| Step: 7
Training loss: 2.353220611696756
Validation loss: 2.5380815740003637

Epoch: 6| Step: 8
Training loss: 2.2716772861843553
Validation loss: 2.549992860160353

Epoch: 6| Step: 9
Training loss: 2.3806065087915993
Validation loss: 2.52675072922388

Epoch: 6| Step: 10
Training loss: 2.4996170704349527
Validation loss: 2.534742983927207

Epoch: 6| Step: 11
Training loss: 2.672891167043083
Validation loss: 2.5399765229813607

Epoch: 6| Step: 12
Training loss: 1.5507743316419198
Validation loss: 2.555447329991891

Epoch: 6| Step: 13
Training loss: 1.9476705453457466
Validation loss: 2.618718443990332

Epoch: 211| Step: 0
Training loss: 2.5537932811174566
Validation loss: 2.6742575288878165

Epoch: 6| Step: 1
Training loss: 1.766662697817585
Validation loss: 2.716371943888483

Epoch: 6| Step: 2
Training loss: 2.0772688399886152
Validation loss: 2.7230500475688624

Epoch: 6| Step: 3
Training loss: 2.9165390168367296
Validation loss: 2.749656916870225

Epoch: 6| Step: 4
Training loss: 2.7317291537809343
Validation loss: 2.6919124426169883

Epoch: 6| Step: 5
Training loss: 2.526135304606417
Validation loss: 2.610616464161443

Epoch: 6| Step: 6
Training loss: 1.8734416207593534
Validation loss: 2.5771475859864763

Epoch: 6| Step: 7
Training loss: 2.373020551873038
Validation loss: 2.5943416825462577

Epoch: 6| Step: 8
Training loss: 2.842547151816964
Validation loss: 2.6333444167008135

Epoch: 6| Step: 9
Training loss: 1.722419705228866
Validation loss: 2.6382877777749676

Epoch: 6| Step: 10
Training loss: 2.2886191710201453
Validation loss: 2.6124695722885702

Epoch: 6| Step: 11
Training loss: 1.8857868175470236
Validation loss: 2.5773107829627

Epoch: 6| Step: 12
Training loss: 2.4996916580785578
Validation loss: 2.5595549761043475

Epoch: 6| Step: 13
Training loss: 2.2469298291049027
Validation loss: 2.530423059547333

Epoch: 212| Step: 0
Training loss: 1.825950960066928
Validation loss: 2.4857704493449315

Epoch: 6| Step: 1
Training loss: 2.7979730762770556
Validation loss: 2.484417187041098

Epoch: 6| Step: 2
Training loss: 2.7110616781942887
Validation loss: 2.471289600936361

Epoch: 6| Step: 3
Training loss: 2.093411660257719
Validation loss: 2.5072860832296526

Epoch: 6| Step: 4
Training loss: 2.205044390519192
Validation loss: 2.5114152348856273

Epoch: 6| Step: 5
Training loss: 2.958105015786936
Validation loss: 2.5472615407489823

Epoch: 6| Step: 6
Training loss: 2.480317743465749
Validation loss: 2.576928494940813

Epoch: 6| Step: 7
Training loss: 2.2640000402497735
Validation loss: 2.6003147907286106

Epoch: 6| Step: 8
Training loss: 2.5122474125915133
Validation loss: 2.6223655827899877

Epoch: 6| Step: 9
Training loss: 2.026308945887411
Validation loss: 2.639175181104995

Epoch: 6| Step: 10
Training loss: 1.6553105983107468
Validation loss: 2.6572912984896577

Epoch: 6| Step: 11
Training loss: 1.8932120537979236
Validation loss: 2.6600831721827505

Epoch: 6| Step: 12
Training loss: 1.8844296803298424
Validation loss: 2.6727855325224716

Epoch: 6| Step: 13
Training loss: 1.9342276102589282
Validation loss: 2.676608895917729

Epoch: 213| Step: 0
Training loss: 2.6321334189482193
Validation loss: 2.6965969530732488

Epoch: 6| Step: 1
Training loss: 2.691340696203658
Validation loss: 2.709720342233154

Epoch: 6| Step: 2
Training loss: 2.471925648629731
Validation loss: 2.70319415446259

Epoch: 6| Step: 3
Training loss: 1.776316452769849
Validation loss: 2.7010302071208647

Epoch: 6| Step: 4
Training loss: 1.8481483368727332
Validation loss: 2.6972525599576858

Epoch: 6| Step: 5
Training loss: 1.8292471547184799
Validation loss: 2.6821941628412507

Epoch: 6| Step: 6
Training loss: 2.2477472471844653
Validation loss: 2.676162510287792

Epoch: 6| Step: 7
Training loss: 2.1125624698228
Validation loss: 2.6764222047700383

Epoch: 6| Step: 8
Training loss: 1.8576875610947057
Validation loss: 2.670153083334867

Epoch: 6| Step: 9
Training loss: 2.2364673554502486
Validation loss: 2.646832978227059

Epoch: 6| Step: 10
Training loss: 2.4264984299257497
Validation loss: 2.648238862581969

Epoch: 6| Step: 11
Training loss: 2.06572448213899
Validation loss: 2.6185739296934747

Epoch: 6| Step: 12
Training loss: 2.6092977912124784
Validation loss: 2.6229257225553977

Epoch: 6| Step: 13
Training loss: 2.148696939235994
Validation loss: 2.5961988966330054

Epoch: 214| Step: 0
Training loss: 2.2564597119539145
Validation loss: 2.5708165795772255

Epoch: 6| Step: 1
Training loss: 2.1384699756654313
Validation loss: 2.5802789554537893

Epoch: 6| Step: 2
Training loss: 2.3713117370451418
Validation loss: 2.55046208819686

Epoch: 6| Step: 3
Training loss: 2.2396861089736966
Validation loss: 2.528951120795044

Epoch: 6| Step: 4
Training loss: 2.126210485020551
Validation loss: 2.5343012485784104

Epoch: 6| Step: 5
Training loss: 1.916595464572518
Validation loss: 2.499828723454749

Epoch: 6| Step: 6
Training loss: 1.9141859365093112
Validation loss: 2.487083591527434

Epoch: 6| Step: 7
Training loss: 2.2843031635809097
Validation loss: 2.465113789486042

Epoch: 6| Step: 8
Training loss: 2.3694947332680667
Validation loss: 2.4474656533706507

Epoch: 6| Step: 9
Training loss: 2.0726841423956
Validation loss: 2.463164844027842

Epoch: 6| Step: 10
Training loss: 2.4647632712693603
Validation loss: 2.4687014629908965

Epoch: 6| Step: 11
Training loss: 2.5643346778029414
Validation loss: 2.5094633948052563

Epoch: 6| Step: 12
Training loss: 2.0681157963796677
Validation loss: 2.5751149056436833

Epoch: 6| Step: 13
Training loss: 2.0618413393638506
Validation loss: 2.6137703664191405

Epoch: 215| Step: 0
Training loss: 2.039892970250676
Validation loss: 2.688993266632766

Epoch: 6| Step: 1
Training loss: 2.332945677934625
Validation loss: 2.6919045266788784

Epoch: 6| Step: 2
Training loss: 2.6500181809287517
Validation loss: 2.6932279430136936

Epoch: 6| Step: 3
Training loss: 2.0081269133078146
Validation loss: 2.655167407656641

Epoch: 6| Step: 4
Training loss: 2.427627131455711
Validation loss: 2.6241954345906104

Epoch: 6| Step: 5
Training loss: 2.3566520084894655
Validation loss: 2.634533238732557

Epoch: 6| Step: 6
Training loss: 2.2026754150509387
Validation loss: 2.598057778877494

Epoch: 6| Step: 7
Training loss: 2.210679649171491
Validation loss: 2.609626882145321

Epoch: 6| Step: 8
Training loss: 1.879685714099318
Validation loss: 2.578109626811193

Epoch: 6| Step: 9
Training loss: 1.5326803883461957
Validation loss: 2.5908158260612266

Epoch: 6| Step: 10
Training loss: 2.1696762921124737
Validation loss: 2.5928591421336673

Epoch: 6| Step: 11
Training loss: 1.7259430615613336
Validation loss: 2.5930908399407673

Epoch: 6| Step: 12
Training loss: 2.544429892517338
Validation loss: 2.592070551625786

Epoch: 6| Step: 13
Training loss: 2.07293362506722
Validation loss: 2.6257847171174795

Epoch: 216| Step: 0
Training loss: 1.752236435861509
Validation loss: 2.6072319809323923

Epoch: 6| Step: 1
Training loss: 2.175993602532912
Validation loss: 2.592354634501889

Epoch: 6| Step: 2
Training loss: 1.6793479398784006
Validation loss: 2.6202045200908644

Epoch: 6| Step: 3
Training loss: 1.9602353484096713
Validation loss: 2.624807666191811

Epoch: 6| Step: 4
Training loss: 2.589869342292009
Validation loss: 2.6412653623813727

Epoch: 6| Step: 5
Training loss: 2.5049366846667906
Validation loss: 2.6356583159868365

Epoch: 6| Step: 6
Training loss: 1.943883409245584
Validation loss: 2.6496585518008904

Epoch: 6| Step: 7
Training loss: 2.682564039505824
Validation loss: 2.6265174134456153

Epoch: 6| Step: 8
Training loss: 2.437807014888504
Validation loss: 2.615308723641804

Epoch: 6| Step: 9
Training loss: 2.2846331657927035
Validation loss: 2.622540072833469

Epoch: 6| Step: 10
Training loss: 1.6147748854025237
Validation loss: 2.6486445297714414

Epoch: 6| Step: 11
Training loss: 1.7674207079851962
Validation loss: 2.633282912230999

Epoch: 6| Step: 12
Training loss: 1.7609295822006166
Validation loss: 2.6463677316618903

Epoch: 6| Step: 13
Training loss: 2.5331607718004348
Validation loss: 2.621969474777928

Epoch: 217| Step: 0
Training loss: 2.070460361022974
Validation loss: 2.5656935387919333

Epoch: 6| Step: 1
Training loss: 1.94845511054529
Validation loss: 2.532197321016989

Epoch: 6| Step: 2
Training loss: 2.392222450444542
Validation loss: 2.541485296993764

Epoch: 6| Step: 3
Training loss: 1.6459862440839235
Validation loss: 2.5150896268415877

Epoch: 6| Step: 4
Training loss: 2.246640982929128
Validation loss: 2.5196938851018156

Epoch: 6| Step: 5
Training loss: 2.379415723744249
Validation loss: 2.5387093317793332

Epoch: 6| Step: 6
Training loss: 2.8350731239105493
Validation loss: 2.5427793880889458

Epoch: 6| Step: 7
Training loss: 2.213193786810381
Validation loss: 2.532392664482201

Epoch: 6| Step: 8
Training loss: 1.8817273570371251
Validation loss: 2.5564504586985755

Epoch: 6| Step: 9
Training loss: 2.2254463476751387
Validation loss: 2.5688433794330927

Epoch: 6| Step: 10
Training loss: 1.61893667080009
Validation loss: 2.5833415396166717

Epoch: 6| Step: 11
Training loss: 2.147769338572899
Validation loss: 2.5852450807003207

Epoch: 6| Step: 12
Training loss: 1.9727607321688378
Validation loss: 2.588535019555781

Epoch: 6| Step: 13
Training loss: 2.3797808262539344
Validation loss: 2.5859487114655124

Epoch: 218| Step: 0
Training loss: 2.1006183985317275
Validation loss: 2.590539749175534

Epoch: 6| Step: 1
Training loss: 2.37858952761277
Validation loss: 2.576935661783623

Epoch: 6| Step: 2
Training loss: 1.600231082441506
Validation loss: 2.54851974666737

Epoch: 6| Step: 3
Training loss: 2.341010361692106
Validation loss: 2.5318234542414633

Epoch: 6| Step: 4
Training loss: 1.736921623073686
Validation loss: 2.504492684199836

Epoch: 6| Step: 5
Training loss: 2.504898993307875
Validation loss: 2.512501185406743

Epoch: 6| Step: 6
Training loss: 2.2525959933505684
Validation loss: 2.5039558553550103

Epoch: 6| Step: 7
Training loss: 2.1189081723747596
Validation loss: 2.5134117067743365

Epoch: 6| Step: 8
Training loss: 1.9582347101038085
Validation loss: 2.5064186227474794

Epoch: 6| Step: 9
Training loss: 2.30337538787976
Validation loss: 2.5331472661927914

Epoch: 6| Step: 10
Training loss: 1.663222768175616
Validation loss: 2.562146074097664

Epoch: 6| Step: 11
Training loss: 1.6934116095876053
Validation loss: 2.584344233093785

Epoch: 6| Step: 12
Training loss: 2.2301313743040505
Validation loss: 2.6480281115461346

Epoch: 6| Step: 13
Training loss: 2.2560354453068676
Validation loss: 2.6797665485361053

Epoch: 219| Step: 0
Training loss: 2.3711078272594883
Validation loss: 2.6705110632289966

Epoch: 6| Step: 1
Training loss: 1.627689263725929
Validation loss: 2.6719574938636503

Epoch: 6| Step: 2
Training loss: 2.158078399782583
Validation loss: 2.681614916203005

Epoch: 6| Step: 3
Training loss: 2.5380691228341155
Validation loss: 2.6786279223335

Epoch: 6| Step: 4
Training loss: 1.5243372680949174
Validation loss: 2.6656165349738137

Epoch: 6| Step: 5
Training loss: 2.2591745037007183
Validation loss: 2.6680322298815002

Epoch: 6| Step: 6
Training loss: 2.1380462706923202
Validation loss: 2.6555251385353573

Epoch: 6| Step: 7
Training loss: 2.1621261361703525
Validation loss: 2.6490145462502577

Epoch: 6| Step: 8
Training loss: 1.8789119601410764
Validation loss: 2.6220875310035536

Epoch: 6| Step: 9
Training loss: 1.9398856703506995
Validation loss: 2.600871551530737

Epoch: 6| Step: 10
Training loss: 1.6122061262036347
Validation loss: 2.554500168929607

Epoch: 6| Step: 11
Training loss: 2.1634823679125077
Validation loss: 2.5191762249412726

Epoch: 6| Step: 12
Training loss: 2.0369178923368683
Validation loss: 2.470913739582061

Epoch: 6| Step: 13
Training loss: 2.1806629691695645
Validation loss: 2.4445053184209673

Epoch: 220| Step: 0
Training loss: 2.183041634135086
Validation loss: 2.440653057120151

Epoch: 6| Step: 1
Training loss: 2.0580657918958694
Validation loss: 2.4078927994478865

Epoch: 6| Step: 2
Training loss: 2.061797744954891
Validation loss: 2.402451030537788

Epoch: 6| Step: 3
Training loss: 2.2441465744590414
Validation loss: 2.4158212603108984

Epoch: 6| Step: 4
Training loss: 1.8566977195380165
Validation loss: 2.445386852769629

Epoch: 6| Step: 5
Training loss: 2.0638899310134895
Validation loss: 2.4370178153808055

Epoch: 6| Step: 6
Training loss: 1.8314362232706431
Validation loss: 2.4611676112611383

Epoch: 6| Step: 7
Training loss: 2.462278745364352
Validation loss: 2.478872791747293

Epoch: 6| Step: 8
Training loss: 2.0521137086843804
Validation loss: 2.4545671278733945

Epoch: 6| Step: 9
Training loss: 1.3476755776608835
Validation loss: 2.4926666396834376

Epoch: 6| Step: 10
Training loss: 2.6379313979407613
Validation loss: 2.482667396619431

Epoch: 6| Step: 11
Training loss: 2.3658977557910092
Validation loss: 2.5038315298870386

Epoch: 6| Step: 12
Training loss: 1.7561059424347631
Validation loss: 2.5394846262554127

Epoch: 6| Step: 13
Training loss: 2.46712546678268
Validation loss: 2.603074130018314

Epoch: 221| Step: 0
Training loss: 2.007783050914868
Validation loss: 2.64640020941905

Epoch: 6| Step: 1
Training loss: 2.035805626065303
Validation loss: 2.6458086014737403

Epoch: 6| Step: 2
Training loss: 2.181588386586427
Validation loss: 2.6704082309340946

Epoch: 6| Step: 3
Training loss: 2.254718495325761
Validation loss: 2.643604440123664

Epoch: 6| Step: 4
Training loss: 1.9144490377199215
Validation loss: 2.631553767952224

Epoch: 6| Step: 5
Training loss: 2.3846368528398356
Validation loss: 2.6150963402584524

Epoch: 6| Step: 6
Training loss: 1.9006709394889731
Validation loss: 2.598739135055291

Epoch: 6| Step: 7
Training loss: 2.205780160818137
Validation loss: 2.5613337338132474

Epoch: 6| Step: 8
Training loss: 1.5803478939595492
Validation loss: 2.5221182479823354

Epoch: 6| Step: 9
Training loss: 2.068580910955251
Validation loss: 2.5024704140603355

Epoch: 6| Step: 10
Training loss: 2.078828735512037
Validation loss: 2.503987163046294

Epoch: 6| Step: 11
Training loss: 2.2544760157429713
Validation loss: 2.477973240903738

Epoch: 6| Step: 12
Training loss: 1.5994187312466204
Validation loss: 2.4816228319747027

Epoch: 6| Step: 13
Training loss: 1.330261397093736
Validation loss: 2.4599556350509193

Epoch: 222| Step: 0
Training loss: 2.2979445270452987
Validation loss: 2.4767840528208453

Epoch: 6| Step: 1
Training loss: 2.2031005425144006
Validation loss: 2.442077755433935

Epoch: 6| Step: 2
Training loss: 1.9341832350920145
Validation loss: 2.4715418120294603

Epoch: 6| Step: 3
Training loss: 1.7510559438486106
Validation loss: 2.4595390277529656

Epoch: 6| Step: 4
Training loss: 2.102039155473803
Validation loss: 2.465943866965687

Epoch: 6| Step: 5
Training loss: 1.7381453900339758
Validation loss: 2.4622354918299765

Epoch: 6| Step: 6
Training loss: 2.3887280686038928
Validation loss: 2.4956253621127433

Epoch: 6| Step: 7
Training loss: 2.3811121142257656
Validation loss: 2.524086202916471

Epoch: 6| Step: 8
Training loss: 1.778427363802335
Validation loss: 2.577433450923331

Epoch: 6| Step: 9
Training loss: 2.0531791691478265
Validation loss: 2.5923139953575975

Epoch: 6| Step: 10
Training loss: 1.897239338357153
Validation loss: 2.623538970631493

Epoch: 6| Step: 11
Training loss: 1.7056910231501712
Validation loss: 2.665186750802566

Epoch: 6| Step: 12
Training loss: 1.4958530959556744
Validation loss: 2.6697288250331916

Epoch: 6| Step: 13
Training loss: 2.0104846316957183
Validation loss: 2.658280829608928

Epoch: 223| Step: 0
Training loss: 1.5264559846261858
Validation loss: 2.625672801570057

Epoch: 6| Step: 1
Training loss: 2.333213417059901
Validation loss: 2.574703677226027

Epoch: 6| Step: 2
Training loss: 2.060782439882087
Validation loss: 2.5686416808329575

Epoch: 6| Step: 3
Training loss: 1.7606861276953338
Validation loss: 2.5437031304828968

Epoch: 6| Step: 4
Training loss: 1.3463647818623425
Validation loss: 2.535186635429765

Epoch: 6| Step: 5
Training loss: 2.1556220868036498
Validation loss: 2.493173973954821

Epoch: 6| Step: 6
Training loss: 2.015433605481219
Validation loss: 2.4677190158269444

Epoch: 6| Step: 7
Training loss: 2.001053532636875
Validation loss: 2.4537711942602414

Epoch: 6| Step: 8
Training loss: 1.9502507537617355
Validation loss: 2.4443290698914173

Epoch: 6| Step: 9
Training loss: 2.1159981064742905
Validation loss: 2.4532086131023374

Epoch: 6| Step: 10
Training loss: 2.5749256975138692
Validation loss: 2.42963068470682

Epoch: 6| Step: 11
Training loss: 1.5918320727991202
Validation loss: 2.4441690988656055

Epoch: 6| Step: 12
Training loss: 1.9447892186115905
Validation loss: 2.4968316151075776

Epoch: 6| Step: 13
Training loss: 0.9817441874293892
Validation loss: 2.4924288515270705

Epoch: 224| Step: 0
Training loss: 2.266387916235685
Validation loss: 2.5100702342795045

Epoch: 6| Step: 1
Training loss: 1.353350784810927
Validation loss: 2.5297265151642003

Epoch: 6| Step: 2
Training loss: 2.041580574659832
Validation loss: 2.5633639948242846

Epoch: 6| Step: 3
Training loss: 1.5503119616208625
Validation loss: 2.5843100657963403

Epoch: 6| Step: 4
Training loss: 2.097305581104243
Validation loss: 2.5607563892771696

Epoch: 6| Step: 5
Training loss: 1.7628252906112125
Validation loss: 2.547787454869294

Epoch: 6| Step: 6
Training loss: 1.5944097312814025
Validation loss: 2.517452419286072

Epoch: 6| Step: 7
Training loss: 2.3426612868503263
Validation loss: 2.5235432877864965

Epoch: 6| Step: 8
Training loss: 2.0477184858182693
Validation loss: 2.529318911111621

Epoch: 6| Step: 9
Training loss: 1.898892006803011
Validation loss: 2.4914490466623573

Epoch: 6| Step: 10
Training loss: 2.0835228134455233
Validation loss: 2.5053944663851286

Epoch: 6| Step: 11
Training loss: 1.9451769433034305
Validation loss: 2.4869028956043944

Epoch: 6| Step: 12
Training loss: 2.1331789030366957
Validation loss: 2.4782659649472922

Epoch: 6| Step: 13
Training loss: 1.920260363647799
Validation loss: 2.4978044426195565

Epoch: 225| Step: 0
Training loss: 1.8650272913513495
Validation loss: 2.4717966991828533

Epoch: 6| Step: 1
Training loss: 2.1013591909092435
Validation loss: 2.489495482361921

Epoch: 6| Step: 2
Training loss: 1.9496421583442594
Validation loss: 2.4934672689626844

Epoch: 6| Step: 3
Training loss: 1.805562389393451
Validation loss: 2.5060535409042606

Epoch: 6| Step: 4
Training loss: 2.408025903670179
Validation loss: 2.5093159680058523

Epoch: 6| Step: 5
Training loss: 1.896335018417156
Validation loss: 2.496712806168312

Epoch: 6| Step: 6
Training loss: 0.9478916891531118
Validation loss: 2.5063473243321837

Epoch: 6| Step: 7
Training loss: 1.7855258283624433
Validation loss: 2.4991060668619354

Epoch: 6| Step: 8
Training loss: 1.9086047777691926
Validation loss: 2.5010363204915382

Epoch: 6| Step: 9
Training loss: 2.1727060607884616
Validation loss: 2.5062873175738116

Epoch: 6| Step: 10
Training loss: 1.5563010272504012
Validation loss: 2.501945245384937

Epoch: 6| Step: 11
Training loss: 1.9608971337042966
Validation loss: 2.5102147500394887

Epoch: 6| Step: 12
Training loss: 1.703445684356987
Validation loss: 2.5148225244606657

Epoch: 6| Step: 13
Training loss: 2.2180360531916645
Validation loss: 2.4986418470179466

Epoch: 226| Step: 0
Training loss: 1.9991484259594416
Validation loss: 2.4926575212240794

Epoch: 6| Step: 1
Training loss: 1.6276162434447787
Validation loss: 2.528160799866843

Epoch: 6| Step: 2
Training loss: 1.9191594361094353
Validation loss: 2.5107371393305353

Epoch: 6| Step: 3
Training loss: 1.349451787335425
Validation loss: 2.518754994409759

Epoch: 6| Step: 4
Training loss: 1.9347911479521112
Validation loss: 2.520572995362037

Epoch: 6| Step: 5
Training loss: 1.760358534836894
Validation loss: 2.5170078439802115

Epoch: 6| Step: 6
Training loss: 1.4370858798396657
Validation loss: 2.5263066425054

Epoch: 6| Step: 7
Training loss: 1.8752005151979045
Validation loss: 2.5297482501011577

Epoch: 6| Step: 8
Training loss: 1.7642437418572223
Validation loss: 2.5255992938875087

Epoch: 6| Step: 9
Training loss: 2.123253048147989
Validation loss: 2.55556599950893

Epoch: 6| Step: 10
Training loss: 2.383927881558126
Validation loss: 2.520204161642344

Epoch: 6| Step: 11
Training loss: 1.5747058957117999
Validation loss: 2.525287268822525

Epoch: 6| Step: 12
Training loss: 1.8691227671887265
Validation loss: 2.5275741274095247

Epoch: 6| Step: 13
Training loss: 2.3069080065378986
Validation loss: 2.5027977526860163

Epoch: 227| Step: 0
Training loss: 1.7352342968477383
Validation loss: 2.518449939184083

Epoch: 6| Step: 1
Training loss: 1.9859863707429142
Validation loss: 2.497742085483682

Epoch: 6| Step: 2
Training loss: 2.245667737282876
Validation loss: 2.474362725376201

Epoch: 6| Step: 3
Training loss: 1.2649933922636525
Validation loss: 2.471669778015428

Epoch: 6| Step: 4
Training loss: 1.833239581861016
Validation loss: 2.504676913082815

Epoch: 6| Step: 5
Training loss: 1.7102691877984197
Validation loss: 2.506341608587974

Epoch: 6| Step: 6
Training loss: 1.3049238984437657
Validation loss: 2.522657181247489

Epoch: 6| Step: 7
Training loss: 1.7375118996192112
Validation loss: 2.52967351295591

Epoch: 6| Step: 8
Training loss: 2.1947926621931946
Validation loss: 2.512972885474381

Epoch: 6| Step: 9
Training loss: 1.9787739682026162
Validation loss: 2.514691775337093

Epoch: 6| Step: 10
Training loss: 1.9678392271492788
Validation loss: 2.5155471364748405

Epoch: 6| Step: 11
Training loss: 2.0199965747011057
Validation loss: 2.5117498302863575

Epoch: 6| Step: 12
Training loss: 1.6982705463237424
Validation loss: 2.56966735980002

Epoch: 6| Step: 13
Training loss: 1.8416553171881187
Validation loss: 2.5699986276375135

Epoch: 228| Step: 0
Training loss: 2.291457449870687
Validation loss: 2.535370634038268

Epoch: 6| Step: 1
Training loss: 1.567975178901634
Validation loss: 2.5385143814829854

Epoch: 6| Step: 2
Training loss: 1.944284435530861
Validation loss: 2.5260125366060406

Epoch: 6| Step: 3
Training loss: 2.025924744619557
Validation loss: 2.5097049369192326

Epoch: 6| Step: 4
Training loss: 2.0558950842572545
Validation loss: 2.518517916557194

Epoch: 6| Step: 5
Training loss: 1.7456039663455074
Validation loss: 2.536360333702696

Epoch: 6| Step: 6
Training loss: 1.7968871406476745
Validation loss: 2.5377272903725943

Epoch: 6| Step: 7
Training loss: 2.27084842875185
Validation loss: 2.55484126739839

Epoch: 6| Step: 8
Training loss: 1.8350060880180628
Validation loss: 2.522509370012795

Epoch: 6| Step: 9
Training loss: 2.0134786370666635
Validation loss: 2.534228531340298

Epoch: 6| Step: 10
Training loss: 1.4090354882665372
Validation loss: 2.5184103204976833

Epoch: 6| Step: 11
Training loss: 1.399785420458306
Validation loss: 2.516912028296076

Epoch: 6| Step: 12
Training loss: 1.4356099017573694
Validation loss: 2.505843194255141

Epoch: 6| Step: 13
Training loss: 1.4303842316456026
Validation loss: 2.495960853493998

Epoch: 229| Step: 0
Training loss: 1.5312443947202892
Validation loss: 2.525629570984398

Epoch: 6| Step: 1
Training loss: 1.6045201973028749
Validation loss: 2.554188061134274

Epoch: 6| Step: 2
Training loss: 2.426052502195326
Validation loss: 2.561617357343874

Epoch: 6| Step: 3
Training loss: 1.6895424527052902
Validation loss: 2.536743390279689

Epoch: 6| Step: 4
Training loss: 2.060110615473315
Validation loss: 2.5113407647295394

Epoch: 6| Step: 5
Training loss: 1.5238917529393332
Validation loss: 2.5061805006592417

Epoch: 6| Step: 6
Training loss: 2.372116748014511
Validation loss: 2.5343969019920136

Epoch: 6| Step: 7
Training loss: 1.5532684751130532
Validation loss: 2.5151734448422505

Epoch: 6| Step: 8
Training loss: 1.7889455565499826
Validation loss: 2.5254828858900407

Epoch: 6| Step: 9
Training loss: 1.1678126814558558
Validation loss: 2.543782847202658

Epoch: 6| Step: 10
Training loss: 1.6975870651142428
Validation loss: 2.56335991338061

Epoch: 6| Step: 11
Training loss: 1.6293106126080372
Validation loss: 2.5753892630021125

Epoch: 6| Step: 12
Training loss: 2.168258290244525
Validation loss: 2.57134281058325

Epoch: 6| Step: 13
Training loss: 1.5648374240269352
Validation loss: 2.569252589308781

Epoch: 230| Step: 0
Training loss: 1.6617137110767806
Validation loss: 2.5010288070004587

Epoch: 6| Step: 1
Training loss: 1.8716399285616556
Validation loss: 2.4943349785354587

Epoch: 6| Step: 2
Training loss: 1.894376768125831
Validation loss: 2.4852002883918227

Epoch: 6| Step: 3
Training loss: 1.5828314370531624
Validation loss: 2.460728100085943

Epoch: 6| Step: 4
Training loss: 1.8212525392199157
Validation loss: 2.4633505350191385

Epoch: 6| Step: 5
Training loss: 1.8855910949389936
Validation loss: 2.439657381423242

Epoch: 6| Step: 6
Training loss: 2.1174775660383705
Validation loss: 2.438871411731616

Epoch: 6| Step: 7
Training loss: 1.3885106504180884
Validation loss: 2.429854095385115

Epoch: 6| Step: 8
Training loss: 1.628223010607493
Validation loss: 2.414938957450764

Epoch: 6| Step: 9
Training loss: 2.138383791955789
Validation loss: 2.428639852145537

Epoch: 6| Step: 10
Training loss: 1.4124367151177593
Validation loss: 2.431286185672498

Epoch: 6| Step: 11
Training loss: 1.9668959106846549
Validation loss: 2.4388203080701736

Epoch: 6| Step: 12
Training loss: 1.3026345828152002
Validation loss: 2.474755462738047

Epoch: 6| Step: 13
Training loss: 1.5579032420032035
Validation loss: 2.4815292255426247

Epoch: 231| Step: 0
Training loss: 1.7065980828680707
Validation loss: 2.5109088775826702

Epoch: 6| Step: 1
Training loss: 1.7056936090466261
Validation loss: 2.539261428448791

Epoch: 6| Step: 2
Training loss: 1.6437411551001857
Validation loss: 2.5500004063219284

Epoch: 6| Step: 3
Training loss: 1.6442914411888467
Validation loss: 2.5766053654212557

Epoch: 6| Step: 4
Training loss: 1.2113910440971363
Validation loss: 2.590014941526021

Epoch: 6| Step: 5
Training loss: 1.275744215362908
Validation loss: 2.607622455684438

Epoch: 6| Step: 6
Training loss: 1.9530024375607329
Validation loss: 2.608132878065088

Epoch: 6| Step: 7
Training loss: 1.9699961033893911
Validation loss: 2.636658901323834

Epoch: 6| Step: 8
Training loss: 1.7177970325092138
Validation loss: 2.6397674074720845

Epoch: 6| Step: 9
Training loss: 2.087025333735157
Validation loss: 2.5781394841249363

Epoch: 6| Step: 10
Training loss: 1.7714604183709497
Validation loss: 2.552290283277106

Epoch: 6| Step: 11
Training loss: 1.9534897120419423
Validation loss: 2.5342248986607645

Epoch: 6| Step: 12
Training loss: 1.5836700616788246
Validation loss: 2.4873743817968013

Epoch: 6| Step: 13
Training loss: 1.9273052259661039
Validation loss: 2.4822317671395457

Epoch: 232| Step: 0
Training loss: 1.6182293323344463
Validation loss: 2.4602354591055353

Epoch: 6| Step: 1
Training loss: 1.7061284731110533
Validation loss: 2.432166132122933

Epoch: 6| Step: 2
Training loss: 1.5958682176779448
Validation loss: 2.46778770083701

Epoch: 6| Step: 3
Training loss: 2.19049738840149
Validation loss: 2.473676930060408

Epoch: 6| Step: 4
Training loss: 1.7830256930568416
Validation loss: 2.46784744078042

Epoch: 6| Step: 5
Training loss: 1.0491520614051828
Validation loss: 2.4852488931013985

Epoch: 6| Step: 6
Training loss: 1.9498209357575773
Validation loss: 2.497478332118414

Epoch: 6| Step: 7
Training loss: 2.0016801452606416
Validation loss: 2.500778196077286

Epoch: 6| Step: 8
Training loss: 1.4413141981055075
Validation loss: 2.497834060045949

Epoch: 6| Step: 9
Training loss: 1.521373974928974
Validation loss: 2.501371121497804

Epoch: 6| Step: 10
Training loss: 2.0704942155659105
Validation loss: 2.526804293434858

Epoch: 6| Step: 11
Training loss: 1.6979365981478685
Validation loss: 2.530843969807593

Epoch: 6| Step: 12
Training loss: 1.4192020317923226
Validation loss: 2.528878131107095

Epoch: 6| Step: 13
Training loss: 1.573387361881156
Validation loss: 2.6211647420322204

Epoch: 233| Step: 0
Training loss: 1.7587936714785528
Validation loss: 2.614005313470858

Epoch: 6| Step: 1
Training loss: 1.2920224509872034
Validation loss: 2.6419955732600946

Epoch: 6| Step: 2
Training loss: 1.6762139888709964
Validation loss: 2.6213187467796004

Epoch: 6| Step: 3
Training loss: 1.788345193115518
Validation loss: 2.6123171646238807

Epoch: 6| Step: 4
Training loss: 2.1377450545977252
Validation loss: 2.6216772636139587

Epoch: 6| Step: 5
Training loss: 1.6047343781188232
Validation loss: 2.5711076453253194

Epoch: 6| Step: 6
Training loss: 1.553307308803076
Validation loss: 2.554045173300771

Epoch: 6| Step: 7
Training loss: 1.5280713155790882
Validation loss: 2.5133245996203954

Epoch: 6| Step: 8
Training loss: 1.4507241052436235
Validation loss: 2.5154187089781703

Epoch: 6| Step: 9
Training loss: 1.2211513337306443
Validation loss: 2.5184860331785877

Epoch: 6| Step: 10
Training loss: 1.7593016695558363
Validation loss: 2.5269248610064596

Epoch: 6| Step: 11
Training loss: 1.9800860093441988
Validation loss: 2.4958580417147176

Epoch: 6| Step: 12
Training loss: 2.3865263466458657
Validation loss: 2.504166125075556

Epoch: 6| Step: 13
Training loss: 1.2730328437661667
Validation loss: 2.503303690176728

Epoch: 234| Step: 0
Training loss: 1.4554448632058012
Validation loss: 2.4861022915224162

Epoch: 6| Step: 1
Training loss: 1.9404675307708898
Validation loss: 2.4389058747736696

Epoch: 6| Step: 2
Training loss: 2.0601501950814036
Validation loss: 2.4534467866622225

Epoch: 6| Step: 3
Training loss: 1.5135750032006081
Validation loss: 2.465935074897143

Epoch: 6| Step: 4
Training loss: 1.808046196262984
Validation loss: 2.4666800491393475

Epoch: 6| Step: 5
Training loss: 2.1308641861984525
Validation loss: 2.4587135549274537

Epoch: 6| Step: 6
Training loss: 1.547072889212442
Validation loss: 2.4980381394764746

Epoch: 6| Step: 7
Training loss: 1.656549246763254
Validation loss: 2.514755802030934

Epoch: 6| Step: 8
Training loss: 1.8547327127706388
Validation loss: 2.5326653203595146

Epoch: 6| Step: 9
Training loss: 1.8611203505000449
Validation loss: 2.5531464057535413

Epoch: 6| Step: 10
Training loss: 1.5436219969280123
Validation loss: 2.562423718925543

Epoch: 6| Step: 11
Training loss: 1.9073125660652503
Validation loss: 2.557461883899537

Epoch: 6| Step: 12
Training loss: 0.9802217210320927
Validation loss: 2.5689874779446393

Epoch: 6| Step: 13
Training loss: 0.5935441714450753
Validation loss: 2.5218417853065667

Epoch: 235| Step: 0
Training loss: 1.715759727871773
Validation loss: 2.5739467090636645

Epoch: 6| Step: 1
Training loss: 1.6072813322567765
Validation loss: 2.5942020726523105

Epoch: 6| Step: 2
Training loss: 1.5676342343617404
Validation loss: 2.5944578754375183

Epoch: 6| Step: 3
Training loss: 1.4819413965764512
Validation loss: 2.570144646343384

Epoch: 6| Step: 4
Training loss: 1.9542161258818058
Validation loss: 2.57477271835876

Epoch: 6| Step: 5
Training loss: 1.8345811094463638
Validation loss: 2.5785786467945657

Epoch: 6| Step: 6
Training loss: 1.7443726525176437
Validation loss: 2.561349312784708

Epoch: 6| Step: 7
Training loss: 1.6686575760410227
Validation loss: 2.542096782610917

Epoch: 6| Step: 8
Training loss: 1.6822116781612866
Validation loss: 2.543884712218455

Epoch: 6| Step: 9
Training loss: 2.013874328677572
Validation loss: 2.5354542158564786

Epoch: 6| Step: 10
Training loss: 1.3252482055813108
Validation loss: 2.541515245639187

Epoch: 6| Step: 11
Training loss: 1.5296203349158368
Validation loss: 2.5441834408760453

Epoch: 6| Step: 12
Training loss: 1.5984617408562525
Validation loss: 2.5158049928524537

Epoch: 6| Step: 13
Training loss: 1.5575437139802764
Validation loss: 2.4987348195669323

Epoch: 236| Step: 0
Training loss: 1.7867917638487671
Validation loss: 2.5134165394555965

Epoch: 6| Step: 1
Training loss: 2.1107510069967033
Validation loss: 2.463497528205937

Epoch: 6| Step: 2
Training loss: 1.4035895294428353
Validation loss: 2.4653898554996383

Epoch: 6| Step: 3
Training loss: 1.4299204485446944
Validation loss: 2.4526698892978365

Epoch: 6| Step: 4
Training loss: 1.5485751124570963
Validation loss: 2.4280822017401724

Epoch: 6| Step: 5
Training loss: 1.096018482323898
Validation loss: 2.437448500516999

Epoch: 6| Step: 6
Training loss: 1.5306413180321388
Validation loss: 2.4696946642709197

Epoch: 6| Step: 7
Training loss: 1.0493496356600132
Validation loss: 2.4998113602050456

Epoch: 6| Step: 8
Training loss: 2.1117649808586902
Validation loss: 2.496877579538367

Epoch: 6| Step: 9
Training loss: 1.91486911515642
Validation loss: 2.5283806673225597

Epoch: 6| Step: 10
Training loss: 1.7735761008528383
Validation loss: 2.5611525794003134

Epoch: 6| Step: 11
Training loss: 1.3949697537031558
Validation loss: 2.6088947367269673

Epoch: 6| Step: 12
Training loss: 1.7917687882292213
Validation loss: 2.6286168356257997

Epoch: 6| Step: 13
Training loss: 1.6474502282735803
Validation loss: 2.6650810340751923

Epoch: 237| Step: 0
Training loss: 1.3978523436679127
Validation loss: 2.6864716789178997

Epoch: 6| Step: 1
Training loss: 1.0546027255426205
Validation loss: 2.6797885555825984

Epoch: 6| Step: 2
Training loss: 1.438857142803145
Validation loss: 2.6675767068361194

Epoch: 6| Step: 3
Training loss: 1.789678276068882
Validation loss: 2.6690613936947734

Epoch: 6| Step: 4
Training loss: 2.0641781308909812
Validation loss: 2.687375509589155

Epoch: 6| Step: 5
Training loss: 1.9241313559804432
Validation loss: 2.653045812202153

Epoch: 6| Step: 6
Training loss: 1.466963147772502
Validation loss: 2.669951302836797

Epoch: 6| Step: 7
Training loss: 1.5226745259894408
Validation loss: 2.614322974104474

Epoch: 6| Step: 8
Training loss: 1.698054333431975
Validation loss: 2.5894872074480184

Epoch: 6| Step: 9
Training loss: 1.7977446732042288
Validation loss: 2.5734961079219185

Epoch: 6| Step: 10
Training loss: 1.876869922266496
Validation loss: 2.559462674341933

Epoch: 6| Step: 11
Training loss: 1.5639537152273444
Validation loss: 2.5688827402506798

Epoch: 6| Step: 12
Training loss: 1.4603934677537964
Validation loss: 2.5418381198592317

Epoch: 6| Step: 13
Training loss: 1.1239884385162566
Validation loss: 2.5646930007542617

Epoch: 238| Step: 0
Training loss: 1.6463585349578815
Validation loss: 2.5872673291097703

Epoch: 6| Step: 1
Training loss: 1.6868305997881328
Validation loss: 2.593740684392721

Epoch: 6| Step: 2
Training loss: 1.0588671341812064
Validation loss: 2.5829687770980985

Epoch: 6| Step: 3
Training loss: 1.5091234743933202
Validation loss: 2.5873171346149064

Epoch: 6| Step: 4
Training loss: 1.5060719934912996
Validation loss: 2.550103058442544

Epoch: 6| Step: 5
Training loss: 1.7950564262425779
Validation loss: 2.5093138654509306

Epoch: 6| Step: 6
Training loss: 1.5157462002774065
Validation loss: 2.5228671939989464

Epoch: 6| Step: 7
Training loss: 1.4201796768578039
Validation loss: 2.563633577740621

Epoch: 6| Step: 8
Training loss: 1.519167976790362
Validation loss: 2.6152659807339633

Epoch: 6| Step: 9
Training loss: 2.2050126017861316
Validation loss: 2.630037113847852

Epoch: 6| Step: 10
Training loss: 1.532574450627541
Validation loss: 2.648248064895961

Epoch: 6| Step: 11
Training loss: 1.7257467560884774
Validation loss: 2.6429702936728345

Epoch: 6| Step: 12
Training loss: 1.6753372279930359
Validation loss: 2.6377868127427835

Epoch: 6| Step: 13
Training loss: 2.0118424757159112
Validation loss: 2.6270739716833593

Epoch: 239| Step: 0
Training loss: 1.2983226739121836
Validation loss: 2.602049291076326

Epoch: 6| Step: 1
Training loss: 1.9291246342319708
Validation loss: 2.56751567212052

Epoch: 6| Step: 2
Training loss: 2.1468320084311014
Validation loss: 2.579268556942925

Epoch: 6| Step: 3
Training loss: 1.5981716080285295
Validation loss: 2.5527565211185395

Epoch: 6| Step: 4
Training loss: 1.4739993014443966
Validation loss: 2.545544745302455

Epoch: 6| Step: 5
Training loss: 1.696061632440035
Validation loss: 2.522665990053694

Epoch: 6| Step: 6
Training loss: 1.2131322352858371
Validation loss: 2.5082031023502087

Epoch: 6| Step: 7
Training loss: 1.8459633941409956
Validation loss: 2.496814936402726

Epoch: 6| Step: 8
Training loss: 1.307899131321132
Validation loss: 2.499270455755739

Epoch: 6| Step: 9
Training loss: 1.5107591525742254
Validation loss: 2.521100891349861

Epoch: 6| Step: 10
Training loss: 1.3141175248354273
Validation loss: 2.5513100951743564

Epoch: 6| Step: 11
Training loss: 1.2883546214958346
Validation loss: 2.5946691263103703

Epoch: 6| Step: 12
Training loss: 1.8780049722055216
Validation loss: 2.610007444423038

Epoch: 6| Step: 13
Training loss: 1.9640635463860516
Validation loss: 2.6257461858474365

Epoch: 240| Step: 0
Training loss: 1.2024821756354425
Validation loss: 2.6223888335820034

Epoch: 6| Step: 1
Training loss: 1.4759949900430978
Validation loss: 2.5761891325857302

Epoch: 6| Step: 2
Training loss: 1.9607929313227204
Validation loss: 2.5990603294993244

Epoch: 6| Step: 3
Training loss: 1.6660563384578715
Validation loss: 2.598059941838603

Epoch: 6| Step: 4
Training loss: 1.843036578241287
Validation loss: 2.599221909983907

Epoch: 6| Step: 5
Training loss: 1.8809167332286343
Validation loss: 2.601837010688105

Epoch: 6| Step: 6
Training loss: 1.2154245245601818
Validation loss: 2.571803312695945

Epoch: 6| Step: 7
Training loss: 1.1895824042660124
Validation loss: 2.5834768204497256

Epoch: 6| Step: 8
Training loss: 1.3798780609934558
Validation loss: 2.5785546365865897

Epoch: 6| Step: 9
Training loss: 1.910036110561602
Validation loss: 2.5841254992260687

Epoch: 6| Step: 10
Training loss: 1.41224186488108
Validation loss: 2.588350748310022

Epoch: 6| Step: 11
Training loss: 1.5654819263254403
Validation loss: 2.5776545219921654

Epoch: 6| Step: 12
Training loss: 1.6101279117879814
Validation loss: 2.615127362414491

Epoch: 6| Step: 13
Training loss: 0.877522714761031
Validation loss: 2.6226529226345807

Epoch: 241| Step: 0
Training loss: 1.7544136248047764
Validation loss: 2.599275095263225

Epoch: 6| Step: 1
Training loss: 1.4945985179704393
Validation loss: 2.599587863720233

Epoch: 6| Step: 2
Training loss: 1.435377129101123
Validation loss: 2.650822212362588

Epoch: 6| Step: 3
Training loss: 1.4651331094413735
Validation loss: 2.616449379885068

Epoch: 6| Step: 4
Training loss: 1.3890489369471504
Validation loss: 2.620313565799211

Epoch: 6| Step: 5
Training loss: 1.0516236059337623
Validation loss: 2.668323239438709

Epoch: 6| Step: 6
Training loss: 1.8270805831534704
Validation loss: 2.6533719651006047

Epoch: 6| Step: 7
Training loss: 1.3630254991991089
Validation loss: 2.631420298210618

Epoch: 6| Step: 8
Training loss: 1.7260333324807475
Validation loss: 2.5970615981595198

Epoch: 6| Step: 9
Training loss: 1.7621565653275333
Validation loss: 2.636883750258775

Epoch: 6| Step: 10
Training loss: 1.916669728096991
Validation loss: 2.5946396103803724

Epoch: 6| Step: 11
Training loss: 1.487332740163464
Validation loss: 2.6151193454109776

Epoch: 6| Step: 12
Training loss: 1.1617574719951544
Validation loss: 2.5832369859520687

Epoch: 6| Step: 13
Training loss: 1.4962094414104992
Validation loss: 2.578504565387238

Epoch: 242| Step: 0
Training loss: 1.4439986572153711
Validation loss: 2.5947794190328595

Epoch: 6| Step: 1
Training loss: 1.4842275445880155
Validation loss: 2.584578326897572

Epoch: 6| Step: 2
Training loss: 1.5119925159894818
Validation loss: 2.584467435170921

Epoch: 6| Step: 3
Training loss: 1.652984422789169
Validation loss: 2.6208095112469882

Epoch: 6| Step: 4
Training loss: 1.4748053212114582
Validation loss: 2.625097492710456

Epoch: 6| Step: 5
Training loss: 1.8818060373208414
Validation loss: 2.6264301628993514

Epoch: 6| Step: 6
Training loss: 1.2807055921687294
Validation loss: 2.625920853481336

Epoch: 6| Step: 7
Training loss: 1.9215391532408972
Validation loss: 2.608868442740918

Epoch: 6| Step: 8
Training loss: 1.5158371924291263
Validation loss: 2.5568718970556246

Epoch: 6| Step: 9
Training loss: 1.1130037196046654
Validation loss: 2.557537100078202

Epoch: 6| Step: 10
Training loss: 1.1891345770466355
Validation loss: 2.5788067654267497

Epoch: 6| Step: 11
Training loss: 1.5906801765030196
Validation loss: 2.5545970264380213

Epoch: 6| Step: 12
Training loss: 1.7354694384381795
Validation loss: 2.5233467167249204

Epoch: 6| Step: 13
Training loss: 1.58637941714817
Validation loss: 2.5689180338397857

Epoch: 243| Step: 0
Training loss: 1.462433401042294
Validation loss: 2.5353700465599083

Epoch: 6| Step: 1
Training loss: 1.1821266372829062
Validation loss: 2.5387609674138245

Epoch: 6| Step: 2
Training loss: 1.3441056956215152
Validation loss: 2.544336130694786

Epoch: 6| Step: 3
Training loss: 1.7430283779475784
Validation loss: 2.5109360585258758

Epoch: 6| Step: 4
Training loss: 1.2855339075139807
Validation loss: 2.5411606235616535

Epoch: 6| Step: 5
Training loss: 1.6702692752451633
Validation loss: 2.548251990402162

Epoch: 6| Step: 6
Training loss: 1.302681894689385
Validation loss: 2.562005774466158

Epoch: 6| Step: 7
Training loss: 1.0280425737263315
Validation loss: 2.5918242798682667

Epoch: 6| Step: 8
Training loss: 1.5594897455414622
Validation loss: 2.6095959959910173

Epoch: 6| Step: 9
Training loss: 1.6614924539950873
Validation loss: 2.656048903070443

Epoch: 6| Step: 10
Training loss: 1.539179763586765
Validation loss: 2.6577661423078593

Epoch: 6| Step: 11
Training loss: 2.2841130932334903
Validation loss: 2.683317865816159

Epoch: 6| Step: 12
Training loss: 1.271133022721559
Validation loss: 2.689871068077841

Epoch: 6| Step: 13
Training loss: 1.2648058465623453
Validation loss: 2.6942325092235686

Epoch: 244| Step: 0
Training loss: 1.7574777241973238
Validation loss: 2.7010466043166708

Epoch: 6| Step: 1
Training loss: 1.4237132503599481
Validation loss: 2.6570642505729483

Epoch: 6| Step: 2
Training loss: 1.9461329924410558
Validation loss: 2.683439133849411

Epoch: 6| Step: 3
Training loss: 1.6055449307598715
Validation loss: 2.6634245713072375

Epoch: 6| Step: 4
Training loss: 1.1950708780856374
Validation loss: 2.652035857721885

Epoch: 6| Step: 5
Training loss: 1.150792827146556
Validation loss: 2.6447563902580664

Epoch: 6| Step: 6
Training loss: 1.4126217072302256
Validation loss: 2.626730548166575

Epoch: 6| Step: 7
Training loss: 1.6675691863066386
Validation loss: 2.647469773581934

Epoch: 6| Step: 8
Training loss: 1.538795021941718
Validation loss: 2.607582927524829

Epoch: 6| Step: 9
Training loss: 1.457945672235738
Validation loss: 2.605163585866038

Epoch: 6| Step: 10
Training loss: 1.4567681041696965
Validation loss: 2.57113453785551

Epoch: 6| Step: 11
Training loss: 1.4433894380115104
Validation loss: 2.5521866372961015

Epoch: 6| Step: 12
Training loss: 1.4342289071077177
Validation loss: 2.550811762872939

Epoch: 6| Step: 13
Training loss: 1.0224569734133997
Validation loss: 2.5778244554357985

Epoch: 245| Step: 0
Training loss: 1.189775645560584
Validation loss: 2.540643588151744

Epoch: 6| Step: 1
Training loss: 1.276528287730284
Validation loss: 2.540074191667991

Epoch: 6| Step: 2
Training loss: 1.7768839817846578
Validation loss: 2.574249211130072

Epoch: 6| Step: 3
Training loss: 1.4353636748004903
Validation loss: 2.5621128084885205

Epoch: 6| Step: 4
Training loss: 1.4832152001705923
Validation loss: 2.560681489916862

Epoch: 6| Step: 5
Training loss: 1.236274850670781
Validation loss: 2.588162909942544

Epoch: 6| Step: 6
Training loss: 1.4398675578193534
Validation loss: 2.576445366567547

Epoch: 6| Step: 7
Training loss: 1.400457489673205
Validation loss: 2.6251381370423044

Epoch: 6| Step: 8
Training loss: 1.6190754655305248
Validation loss: 2.604400050052304

Epoch: 6| Step: 9
Training loss: 1.910910241095569
Validation loss: 2.5967313343779383

Epoch: 6| Step: 10
Training loss: 1.3797861809179657
Validation loss: 2.5977754812104337

Epoch: 6| Step: 11
Training loss: 1.2578636775060186
Validation loss: 2.57890876995329

Epoch: 6| Step: 12
Training loss: 1.4557343712055704
Validation loss: 2.5964325722999897

Epoch: 6| Step: 13
Training loss: 1.4529329398603787
Validation loss: 2.615601637468569

Epoch: 246| Step: 0
Training loss: 1.1927793501099464
Validation loss: 2.5706653354666265

Epoch: 6| Step: 1
Training loss: 1.570799946451247
Validation loss: 2.6226394448435992

Epoch: 6| Step: 2
Training loss: 1.2889895331799008
Validation loss: 2.601831977671441

Epoch: 6| Step: 3
Training loss: 1.9516060377629216
Validation loss: 2.599560241883309

Epoch: 6| Step: 4
Training loss: 1.1998981949219192
Validation loss: 2.608656208202477

Epoch: 6| Step: 5
Training loss: 0.9925767930827687
Validation loss: 2.607655826949791

Epoch: 6| Step: 6
Training loss: 1.654095886343247
Validation loss: 2.6120271998637206

Epoch: 6| Step: 7
Training loss: 1.2382565083724508
Validation loss: 2.61468476704713

Epoch: 6| Step: 8
Training loss: 1.3984658861742358
Validation loss: 2.6258944048783146

Epoch: 6| Step: 9
Training loss: 1.3310938694337373
Validation loss: 2.6099682126804593

Epoch: 6| Step: 10
Training loss: 1.7731616103890862
Validation loss: 2.617144599701305

Epoch: 6| Step: 11
Training loss: 1.615348101559548
Validation loss: 2.638718938149356

Epoch: 6| Step: 12
Training loss: 1.4065137403910686
Validation loss: 2.6395281558352783

Epoch: 6| Step: 13
Training loss: 1.0938110879459881
Validation loss: 2.6633566269864772

Epoch: 247| Step: 0
Training loss: 1.3921164326451687
Validation loss: 2.629854405357717

Epoch: 6| Step: 1
Training loss: 1.206038971462633
Validation loss: 2.6262717879778883

Epoch: 6| Step: 2
Training loss: 1.8216898541081428
Validation loss: 2.6551227800570922

Epoch: 6| Step: 3
Training loss: 1.27310063873939
Validation loss: 2.6065046456379575

Epoch: 6| Step: 4
Training loss: 1.0119732275274984
Validation loss: 2.5873187447440555

Epoch: 6| Step: 5
Training loss: 1.3775548607620605
Validation loss: 2.554656556748531

Epoch: 6| Step: 6
Training loss: 1.3626842339223768
Validation loss: 2.576203518131064

Epoch: 6| Step: 7
Training loss: 1.2175771988004527
Validation loss: 2.5602087837032

Epoch: 6| Step: 8
Training loss: 1.4339723840605478
Validation loss: 2.5680806329101658

Epoch: 6| Step: 9
Training loss: 1.0373725629006356
Validation loss: 2.5276910324189465

Epoch: 6| Step: 10
Training loss: 1.561178105991927
Validation loss: 2.5569375325116317

Epoch: 6| Step: 11
Training loss: 1.7569754408898652
Validation loss: 2.555496904952392

Epoch: 6| Step: 12
Training loss: 1.5898558969994347
Validation loss: 2.5734203480482165

Epoch: 6| Step: 13
Training loss: 1.8400336489503144
Validation loss: 2.5543947117610304

Epoch: 248| Step: 0
Training loss: 1.7732192926139976
Validation loss: 2.594756638629572

Epoch: 6| Step: 1
Training loss: 1.4402706148923246
Validation loss: 2.612887684527602

Epoch: 6| Step: 2
Training loss: 1.0800655426341024
Validation loss: 2.6150440904497136

Epoch: 6| Step: 3
Training loss: 1.2361948143316277
Validation loss: 2.648393391583013

Epoch: 6| Step: 4
Training loss: 1.5803647907062792
Validation loss: 2.64238277656378

Epoch: 6| Step: 5
Training loss: 1.096115388337177
Validation loss: 2.669108951601028

Epoch: 6| Step: 6
Training loss: 1.3444949014949346
Validation loss: 2.6652124285743284

Epoch: 6| Step: 7
Training loss: 1.5427823883697174
Validation loss: 2.6272432320098873

Epoch: 6| Step: 8
Training loss: 1.210296067200907
Validation loss: 2.6478436750173113

Epoch: 6| Step: 9
Training loss: 1.2788273772454755
Validation loss: 2.6346054839116504

Epoch: 6| Step: 10
Training loss: 1.50718320057774
Validation loss: 2.614726808621108

Epoch: 6| Step: 11
Training loss: 1.5622575190267498
Validation loss: 2.600406787025157

Epoch: 6| Step: 12
Training loss: 1.3245743355690927
Validation loss: 2.595007646748448

Epoch: 6| Step: 13
Training loss: 1.8243027857634508
Validation loss: 2.5983642501500355

Epoch: 249| Step: 0
Training loss: 1.5163830306777832
Validation loss: 2.588577981016006

Epoch: 6| Step: 1
Training loss: 1.5168246997341224
Validation loss: 2.585534942574482

Epoch: 6| Step: 2
Training loss: 1.4929851377377261
Validation loss: 2.5279183854804503

Epoch: 6| Step: 3
Training loss: 1.1484400950292215
Validation loss: 2.522014739400557

Epoch: 6| Step: 4
Training loss: 1.3504325244462514
Validation loss: 2.537658375856641

Epoch: 6| Step: 5
Training loss: 1.8328478199188947
Validation loss: 2.538915375264062

Epoch: 6| Step: 6
Training loss: 1.663728492420106
Validation loss: 2.555319619151492

Epoch: 6| Step: 7
Training loss: 1.1440264529290947
Validation loss: 2.5264676156848025

Epoch: 6| Step: 8
Training loss: 1.2459619147418033
Validation loss: 2.5867370929693823

Epoch: 6| Step: 9
Training loss: 1.3131865567681489
Validation loss: 2.6092386370362592

Epoch: 6| Step: 10
Training loss: 0.9623547469184497
Validation loss: 2.6271021005242288

Epoch: 6| Step: 11
Training loss: 1.2874199777567525
Validation loss: 2.637775644722395

Epoch: 6| Step: 12
Training loss: 1.6862787136520365
Validation loss: 2.636751782184941

Epoch: 6| Step: 13
Training loss: 1.3401823366714407
Validation loss: 2.660219091385366

Epoch: 250| Step: 0
Training loss: 1.3040104554114071
Validation loss: 2.6578117918527324

Epoch: 6| Step: 1
Training loss: 1.4186715730340866
Validation loss: 2.6187845724199996

Epoch: 6| Step: 2
Training loss: 1.8912685969737477
Validation loss: 2.6252351705328936

Epoch: 6| Step: 3
Training loss: 1.2027930755513598
Validation loss: 2.6250174434412394

Epoch: 6| Step: 4
Training loss: 1.380958132739687
Validation loss: 2.625619638402872

Epoch: 6| Step: 5
Training loss: 1.3000135476066688
Validation loss: 2.614162595716318

Epoch: 6| Step: 6
Training loss: 1.5465287100306597
Validation loss: 2.566157831953498

Epoch: 6| Step: 7
Training loss: 1.4148170607696764
Validation loss: 2.5523634120067906

Epoch: 6| Step: 8
Training loss: 1.225769272424203
Validation loss: 2.534707889094003

Epoch: 6| Step: 9
Training loss: 1.1743808149728754
Validation loss: 2.545748959650255

Epoch: 6| Step: 10
Training loss: 1.5668453067359518
Validation loss: 2.5418330184693185

Epoch: 6| Step: 11
Training loss: 1.482349499530163
Validation loss: 2.537220532970186

Epoch: 6| Step: 12
Training loss: 1.0841566344160345
Validation loss: 2.5449153392701747

Epoch: 6| Step: 13
Training loss: 1.1126323214072453
Validation loss: 2.5690589658495675

Epoch: 251| Step: 0
Training loss: 1.8325553095694618
Validation loss: 2.577668694480493

Epoch: 6| Step: 1
Training loss: 1.08488869276305
Validation loss: 2.5941790470397237

Epoch: 6| Step: 2
Training loss: 1.190780325142031
Validation loss: 2.5902262677273833

Epoch: 6| Step: 3
Training loss: 1.253538416449934
Validation loss: 2.595394149619724

Epoch: 6| Step: 4
Training loss: 1.5195459987836608
Validation loss: 2.6257064442994205

Epoch: 6| Step: 5
Training loss: 1.5931905624769056
Validation loss: 2.640064034047409

Epoch: 6| Step: 6
Training loss: 1.2884621811787418
Validation loss: 2.611006756779213

Epoch: 6| Step: 7
Training loss: 1.4160945896624766
Validation loss: 2.62517187842037

Epoch: 6| Step: 8
Training loss: 1.5009685409420903
Validation loss: 2.600863800090652

Epoch: 6| Step: 9
Training loss: 1.4788666362666205
Validation loss: 2.6180608945958057

Epoch: 6| Step: 10
Training loss: 0.7460852417785285
Validation loss: 2.5888731008054973

Epoch: 6| Step: 11
Training loss: 1.5322296745506956
Validation loss: 2.560860529325653

Epoch: 6| Step: 12
Training loss: 1.1900626689373253
Validation loss: 2.563274754641216

Epoch: 6| Step: 13
Training loss: 1.4756891806514831
Validation loss: 2.594859601853228

Epoch: 252| Step: 0
Training loss: 1.4355295193200428
Validation loss: 2.583856317996512

Epoch: 6| Step: 1
Training loss: 0.7583164623675434
Validation loss: 2.591153795231417

Epoch: 6| Step: 2
Training loss: 1.3917593454958894
Validation loss: 2.5707985051061684

Epoch: 6| Step: 3
Training loss: 1.297519385867379
Validation loss: 2.578544050151408

Epoch: 6| Step: 4
Training loss: 1.7475875165687744
Validation loss: 2.5552531741244096

Epoch: 6| Step: 5
Training loss: 1.4047152303264734
Validation loss: 2.5673450713134556

Epoch: 6| Step: 6
Training loss: 1.1228923127335468
Validation loss: 2.56442164728292

Epoch: 6| Step: 7
Training loss: 1.4768811240373965
Validation loss: 2.549399464488771

Epoch: 6| Step: 8
Training loss: 1.0939170709801374
Validation loss: 2.520251982437316

Epoch: 6| Step: 9
Training loss: 1.9108177241095285
Validation loss: 2.568750403435916

Epoch: 6| Step: 10
Training loss: 1.662021441884825
Validation loss: 2.583468214027523

Epoch: 6| Step: 11
Training loss: 1.3747581789474415
Validation loss: 2.5912760641179804

Epoch: 6| Step: 12
Training loss: 0.9782960687284804
Validation loss: 2.560548337764824

Epoch: 6| Step: 13
Training loss: 1.0971216821010803
Validation loss: 2.5497224955933757

Epoch: 253| Step: 0
Training loss: 1.316116708670502
Validation loss: 2.584323314940478

Epoch: 6| Step: 1
Training loss: 1.4377175042173562
Validation loss: 2.567659994908945

Epoch: 6| Step: 2
Training loss: 1.4673842715587797
Validation loss: 2.569007065018145

Epoch: 6| Step: 3
Training loss: 1.4705451384007553
Validation loss: 2.607155107904814

Epoch: 6| Step: 4
Training loss: 1.4356003524265404
Validation loss: 2.6239909778344073

Epoch: 6| Step: 5
Training loss: 1.776955362999044
Validation loss: 2.620374469708056

Epoch: 6| Step: 6
Training loss: 1.2025013087338883
Validation loss: 2.6371074999737623

Epoch: 6| Step: 7
Training loss: 0.9657300515421634
Validation loss: 2.653012645648022

Epoch: 6| Step: 8
Training loss: 1.1173419978944625
Validation loss: 2.6679971625840353

Epoch: 6| Step: 9
Training loss: 1.7459824631150014
Validation loss: 2.6413213126472272

Epoch: 6| Step: 10
Training loss: 1.357941891526749
Validation loss: 2.6532934645380672

Epoch: 6| Step: 11
Training loss: 1.166909748820662
Validation loss: 2.6516883010380288

Epoch: 6| Step: 12
Training loss: 1.3052594421723234
Validation loss: 2.6170484074581912

Epoch: 6| Step: 13
Training loss: 1.0720648238808992
Validation loss: 2.6122338413510224

Epoch: 254| Step: 0
Training loss: 0.8055742063409457
Validation loss: 2.5585991736715195

Epoch: 6| Step: 1
Training loss: 1.8202991403245
Validation loss: 2.5430532832390633

Epoch: 6| Step: 2
Training loss: 1.1612448161063884
Validation loss: 2.541961743235194

Epoch: 6| Step: 3
Training loss: 1.7878527153251624
Validation loss: 2.5519779393673767

Epoch: 6| Step: 4
Training loss: 0.8873668436443182
Validation loss: 2.5310143842563377

Epoch: 6| Step: 5
Training loss: 1.8105439779676122
Validation loss: 2.5412577060185777

Epoch: 6| Step: 6
Training loss: 0.5012060758794776
Validation loss: 2.5671374319415645

Epoch: 6| Step: 7
Training loss: 1.3541967046291654
Validation loss: 2.5594412002557103

Epoch: 6| Step: 8
Training loss: 1.3110764367337147
Validation loss: 2.5488577741389027

Epoch: 6| Step: 9
Training loss: 1.5738487850148284
Validation loss: 2.600803831117745

Epoch: 6| Step: 10
Training loss: 1.2618831846246659
Validation loss: 2.577901502003531

Epoch: 6| Step: 11
Training loss: 1.358516290352889
Validation loss: 2.642321282611067

Epoch: 6| Step: 12
Training loss: 1.3666561729136826
Validation loss: 2.6334045860284334

Epoch: 6| Step: 13
Training loss: 1.5708932134950981
Validation loss: 2.6318210436475105

Epoch: 255| Step: 0
Training loss: 1.305435605772683
Validation loss: 2.593436463243478

Epoch: 6| Step: 1
Training loss: 1.0187242609996783
Validation loss: 2.619373635980261

Epoch: 6| Step: 2
Training loss: 1.4351547847567967
Validation loss: 2.599795094564997

Epoch: 6| Step: 3
Training loss: 1.8084422103638558
Validation loss: 2.617834251690757

Epoch: 6| Step: 4
Training loss: 1.4231310316652415
Validation loss: 2.5894353141103634

Epoch: 6| Step: 5
Training loss: 0.7027709493401678
Validation loss: 2.6412671987763314

Epoch: 6| Step: 6
Training loss: 1.0670303363044817
Validation loss: 2.634032590326186

Epoch: 6| Step: 7
Training loss: 1.2205553621506011
Validation loss: 2.6445033521109678

Epoch: 6| Step: 8
Training loss: 1.5804537973719577
Validation loss: 2.57290090099651

Epoch: 6| Step: 9
Training loss: 1.5365018504386407
Validation loss: 2.561385990303857

Epoch: 6| Step: 10
Training loss: 1.3664921327344235
Validation loss: 2.5677467374436733

Epoch: 6| Step: 11
Training loss: 1.2445152592993656
Validation loss: 2.556573519891508

Epoch: 6| Step: 12
Training loss: 1.5743674688397618
Validation loss: 2.536449564677543

Epoch: 6| Step: 13
Training loss: 1.1870574126398943
Validation loss: 2.5778972247929737

Epoch: 256| Step: 0
Training loss: 2.0863178492187497
Validation loss: 2.575691752908553

Epoch: 6| Step: 1
Training loss: 1.4959490434668603
Validation loss: 2.571707176991203

Epoch: 6| Step: 2
Training loss: 1.4546564707330247
Validation loss: 2.5872675253016446

Epoch: 6| Step: 3
Training loss: 1.57497007553495
Validation loss: 2.630505263362038

Epoch: 6| Step: 4
Training loss: 1.1387870298493161
Validation loss: 2.6556533027453053

Epoch: 6| Step: 5
Training loss: 0.9224715161772011
Validation loss: 2.6408209133704266

Epoch: 6| Step: 6
Training loss: 1.4394398744301928
Validation loss: 2.6454797824568175

Epoch: 6| Step: 7
Training loss: 1.4511237361106262
Validation loss: 2.6525376259735007

Epoch: 6| Step: 8
Training loss: 1.026894939133832
Validation loss: 2.6428002615327624

Epoch: 6| Step: 9
Training loss: 1.0822086670777524
Validation loss: 2.6083124031040423

Epoch: 6| Step: 10
Training loss: 0.8803605657150064
Validation loss: 2.6288697041306843

Epoch: 6| Step: 11
Training loss: 1.0424896168363251
Validation loss: 2.6215345553240548

Epoch: 6| Step: 12
Training loss: 1.0439659808890038
Validation loss: 2.631722280369334

Epoch: 6| Step: 13
Training loss: 1.3679190286241618
Validation loss: 2.6044834802352677

Epoch: 257| Step: 0
Training loss: 1.7043044879401437
Validation loss: 2.607542549312888

Epoch: 6| Step: 1
Training loss: 0.8302943049150422
Validation loss: 2.601720901993633

Epoch: 6| Step: 2
Training loss: 1.1094343142704142
Validation loss: 2.578280110943151

Epoch: 6| Step: 3
Training loss: 1.0821632277222906
Validation loss: 2.6111162474782543

Epoch: 6| Step: 4
Training loss: 1.6230414398506319
Validation loss: 2.606184906234064

Epoch: 6| Step: 5
Training loss: 1.4103235372715384
Validation loss: 2.593402922846219

Epoch: 6| Step: 6
Training loss: 1.2109309042474101
Validation loss: 2.6064730787413675

Epoch: 6| Step: 7
Training loss: 1.2988693804391271
Validation loss: 2.5876149954181957

Epoch: 6| Step: 8
Training loss: 1.4090995739365577
Validation loss: 2.603623928159775

Epoch: 6| Step: 9
Training loss: 0.8992898960951249
Validation loss: 2.5677593971357875

Epoch: 6| Step: 10
Training loss: 1.2747884500064697
Validation loss: 2.5749955012896155

Epoch: 6| Step: 11
Training loss: 1.519694106291387
Validation loss: 2.5789732292462304

Epoch: 6| Step: 12
Training loss: 1.519228083711236
Validation loss: 2.559307439656288

Epoch: 6| Step: 13
Training loss: 0.9276769359274716
Validation loss: 2.5657955950363025

Epoch: 258| Step: 0
Training loss: 1.1023842201941687
Validation loss: 2.5562741180557036

Epoch: 6| Step: 1
Training loss: 1.60458906813417
Validation loss: 2.5572425017695326

Epoch: 6| Step: 2
Training loss: 1.1135792115997865
Validation loss: 2.5557147015594532

Epoch: 6| Step: 3
Training loss: 1.2126480326787603
Validation loss: 2.5737179614450407

Epoch: 6| Step: 4
Training loss: 1.8484506330886141
Validation loss: 2.5513200862095413

Epoch: 6| Step: 5
Training loss: 1.152519186857303
Validation loss: 2.595615481624607

Epoch: 6| Step: 6
Training loss: 1.2937334916540455
Validation loss: 2.6057966707047457

Epoch: 6| Step: 7
Training loss: 1.5492692393791423
Validation loss: 2.6360835588154257

Epoch: 6| Step: 8
Training loss: 1.0350088338428869
Validation loss: 2.628276302907507

Epoch: 6| Step: 9
Training loss: 1.14072595436959
Validation loss: 2.610616782331318

Epoch: 6| Step: 10
Training loss: 1.13347064663674
Validation loss: 2.646592306920905

Epoch: 6| Step: 11
Training loss: 0.793241857843363
Validation loss: 2.6482083464111987

Epoch: 6| Step: 12
Training loss: 1.3759754795479016
Validation loss: 2.6360412723893485

Epoch: 6| Step: 13
Training loss: 1.480233286952185
Validation loss: 2.630747379090002

Epoch: 259| Step: 0
Training loss: 1.3174611740616542
Validation loss: 2.6220180657586187

Epoch: 6| Step: 1
Training loss: 1.3230311827268204
Validation loss: 2.623291173330528

Epoch: 6| Step: 2
Training loss: 2.0560533748407632
Validation loss: 2.647487119330212

Epoch: 6| Step: 3
Training loss: 1.0580393335281655
Validation loss: 2.6395605167019474

Epoch: 6| Step: 4
Training loss: 0.9910338896683561
Validation loss: 2.6186578535132004

Epoch: 6| Step: 5
Training loss: 1.221027642411264
Validation loss: 2.5871293851993844

Epoch: 6| Step: 6
Training loss: 1.2248953891384278
Validation loss: 2.6001107219125315

Epoch: 6| Step: 7
Training loss: 0.8293181047853189
Validation loss: 2.634349889354211

Epoch: 6| Step: 8
Training loss: 1.1363722545123585
Validation loss: 2.5724887396548866

Epoch: 6| Step: 9
Training loss: 1.445583998465206
Validation loss: 2.5534463108691883

Epoch: 6| Step: 10
Training loss: 1.5104069501191597
Validation loss: 2.5726294561266183

Epoch: 6| Step: 11
Training loss: 1.260673633369254
Validation loss: 2.559208921242465

Epoch: 6| Step: 12
Training loss: 1.1567001497514109
Validation loss: 2.582448300311888

Epoch: 6| Step: 13
Training loss: 0.7241221638193797
Validation loss: 2.5723722460720135

Epoch: 260| Step: 0
Training loss: 1.220936305853692
Validation loss: 2.5662842547038944

Epoch: 6| Step: 1
Training loss: 1.39166452365794
Validation loss: 2.5691581034025606

Epoch: 6| Step: 2
Training loss: 1.274753241876586
Validation loss: 2.5610193916796815

Epoch: 6| Step: 3
Training loss: 1.2819441798907762
Validation loss: 2.5986594685224924

Epoch: 6| Step: 4
Training loss: 1.5545427264565315
Validation loss: 2.5639535686510997

Epoch: 6| Step: 5
Training loss: 1.4645135532792612
Validation loss: 2.562092692421229

Epoch: 6| Step: 6
Training loss: 0.993227376204452
Validation loss: 2.5534219759859558

Epoch: 6| Step: 7
Training loss: 1.0050160252066835
Validation loss: 2.5791908305835625

Epoch: 6| Step: 8
Training loss: 1.1007651832117362
Validation loss: 2.5760886514511885

Epoch: 6| Step: 9
Training loss: 1.3018966337504307
Validation loss: 2.6031394908161785

Epoch: 6| Step: 10
Training loss: 0.7976687722713015
Validation loss: 2.6114794320019428

Epoch: 6| Step: 11
Training loss: 1.3400464140981296
Validation loss: 2.5944212939189017

Epoch: 6| Step: 12
Training loss: 1.4347162243911686
Validation loss: 2.667139052522652

Epoch: 6| Step: 13
Training loss: 1.6146957440366085
Validation loss: 2.6366299614338105

Epoch: 261| Step: 0
Training loss: 1.2879911652493017
Validation loss: 2.574710622246332

Epoch: 6| Step: 1
Training loss: 1.9449962067750948
Validation loss: 2.5968200684891793

Epoch: 6| Step: 2
Training loss: 1.1988895225277714
Validation loss: 2.6271465181074443

Epoch: 6| Step: 3
Training loss: 1.3061538952969756
Validation loss: 2.5740513851191804

Epoch: 6| Step: 4
Training loss: 1.0258859945539862
Validation loss: 2.5406057761819603

Epoch: 6| Step: 5
Training loss: 1.4630424308699173
Validation loss: 2.5258165768978955

Epoch: 6| Step: 6
Training loss: 0.6929530067762864
Validation loss: 2.5029143891663144

Epoch: 6| Step: 7
Training loss: 0.9159465836979399
Validation loss: 2.50359931792224

Epoch: 6| Step: 8
Training loss: 0.8729870325525886
Validation loss: 2.522126602280356

Epoch: 6| Step: 9
Training loss: 1.1741700650272686
Validation loss: 2.524296756909279

Epoch: 6| Step: 10
Training loss: 1.5350549873170387
Validation loss: 2.504221113167692

Epoch: 6| Step: 11
Training loss: 1.7697093612934602
Validation loss: 2.514428640672433

Epoch: 6| Step: 12
Training loss: 0.90450987974626
Validation loss: 2.5400650309410073

Epoch: 6| Step: 13
Training loss: 0.8156724762527147
Validation loss: 2.5754022494550295

Epoch: 262| Step: 0
Training loss: 0.7186646203455458
Validation loss: 2.57029795979958

Epoch: 6| Step: 1
Training loss: 1.0570470906020144
Validation loss: 2.586952972964928

Epoch: 6| Step: 2
Training loss: 1.2034889760544627
Validation loss: 2.6200405839189216

Epoch: 6| Step: 3
Training loss: 1.0701012507333052
Validation loss: 2.6066761272345707

Epoch: 6| Step: 4
Training loss: 1.2518625687864224
Validation loss: 2.640523577637538

Epoch: 6| Step: 5
Training loss: 1.1986710978487265
Validation loss: 2.656059431059886

Epoch: 6| Step: 6
Training loss: 1.5024668753680959
Validation loss: 2.656064440466752

Epoch: 6| Step: 7
Training loss: 1.5956553121661772
Validation loss: 2.657284923367122

Epoch: 6| Step: 8
Training loss: 1.3400263536765493
Validation loss: 2.648248581351411

Epoch: 6| Step: 9
Training loss: 1.1445857220599218
Validation loss: 2.641254229452255

Epoch: 6| Step: 10
Training loss: 1.3124982288893603
Validation loss: 2.591011834829284

Epoch: 6| Step: 11
Training loss: 1.4297310244079273
Validation loss: 2.573383327007854

Epoch: 6| Step: 12
Training loss: 1.1954090353685722
Validation loss: 2.570758574284924

Epoch: 6| Step: 13
Training loss: 1.3658675879620081
Validation loss: 2.543317189962158

Epoch: 263| Step: 0
Training loss: 1.3546280246161226
Validation loss: 2.54786230061191

Epoch: 6| Step: 1
Training loss: 1.1996431376389922
Validation loss: 2.5300545157653835

Epoch: 6| Step: 2
Training loss: 1.1553156402437903
Validation loss: 2.509046959483656

Epoch: 6| Step: 3
Training loss: 0.6927296317323068
Validation loss: 2.5320897787443735

Epoch: 6| Step: 4
Training loss: 1.2192237128997976
Validation loss: 2.538123381472865

Epoch: 6| Step: 5
Training loss: 1.3110153338818038
Validation loss: 2.5127778524257924

Epoch: 6| Step: 6
Training loss: 1.5178701544452395
Validation loss: 2.526827363823982

Epoch: 6| Step: 7
Training loss: 1.183658509953536
Validation loss: 2.54988791130737

Epoch: 6| Step: 8
Training loss: 1.0179786991971114
Validation loss: 2.5645002996150037

Epoch: 6| Step: 9
Training loss: 1.3725483451903047
Validation loss: 2.580634913533127

Epoch: 6| Step: 10
Training loss: 0.7474491530128113
Validation loss: 2.604405152916603

Epoch: 6| Step: 11
Training loss: 1.8806851980780885
Validation loss: 2.604358705064358

Epoch: 6| Step: 12
Training loss: 1.2542549195188382
Validation loss: 2.6357661562740438

Epoch: 6| Step: 13
Training loss: 1.2458132245706564
Validation loss: 2.621263891358321

Epoch: 264| Step: 0
Training loss: 1.2573508606097288
Validation loss: 2.6296228251569054

Epoch: 6| Step: 1
Training loss: 1.4414104678704802
Validation loss: 2.592329327823858

Epoch: 6| Step: 2
Training loss: 1.0291907239462563
Validation loss: 2.626426675316014

Epoch: 6| Step: 3
Training loss: 1.1483616187529635
Validation loss: 2.5757846057460214

Epoch: 6| Step: 4
Training loss: 1.1519472118806728
Validation loss: 2.5932140011495726

Epoch: 6| Step: 5
Training loss: 1.3500862659160113
Validation loss: 2.5946505886105387

Epoch: 6| Step: 6
Training loss: 1.3586353174994112
Validation loss: 2.5704592917724165

Epoch: 6| Step: 7
Training loss: 1.014651198470588
Validation loss: 2.5677393862073754

Epoch: 6| Step: 8
Training loss: 1.1354256842485526
Validation loss: 2.5511522149441435

Epoch: 6| Step: 9
Training loss: 1.0399206532873877
Validation loss: 2.5258562854519986

Epoch: 6| Step: 10
Training loss: 1.6480255335338976
Validation loss: 2.544172852491803

Epoch: 6| Step: 11
Training loss: 0.8911597002036671
Validation loss: 2.514286344180463

Epoch: 6| Step: 12
Training loss: 1.4268518895981648
Validation loss: 2.525942944211949

Epoch: 6| Step: 13
Training loss: 1.42788716345389
Validation loss: 2.527356438618321

Epoch: 265| Step: 0
Training loss: 1.1973638945384206
Validation loss: 2.533509702593322

Epoch: 6| Step: 1
Training loss: 0.9887908707188016
Validation loss: 2.573568734692137

Epoch: 6| Step: 2
Training loss: 1.3344834652130397
Validation loss: 2.599207266186242

Epoch: 6| Step: 3
Training loss: 1.2662079022141817
Validation loss: 2.5615354358808573

Epoch: 6| Step: 4
Training loss: 1.281291821425278
Validation loss: 2.587430353482173

Epoch: 6| Step: 5
Training loss: 0.6872419393156218
Validation loss: 2.5569480931024584

Epoch: 6| Step: 6
Training loss: 1.3332132146293147
Validation loss: 2.5305701866795687

Epoch: 6| Step: 7
Training loss: 1.2356802883716282
Validation loss: 2.5584882090553998

Epoch: 6| Step: 8
Training loss: 0.9293334671519369
Validation loss: 2.5726389737376207

Epoch: 6| Step: 9
Training loss: 1.8411365024990272
Validation loss: 2.556276292302391

Epoch: 6| Step: 10
Training loss: 1.2760364246909497
Validation loss: 2.5630306371781613

Epoch: 6| Step: 11
Training loss: 1.0252679660639643
Validation loss: 2.5238372294124156

Epoch: 6| Step: 12
Training loss: 1.4662359920265102
Validation loss: 2.5343016521975668

Epoch: 6| Step: 13
Training loss: 0.7682213648168235
Validation loss: 2.5409808624730545

Epoch: 266| Step: 0
Training loss: 1.6599927395351608
Validation loss: 2.548633399496271

Epoch: 6| Step: 1
Training loss: 1.1937433052873876
Validation loss: 2.5187361066426868

Epoch: 6| Step: 2
Training loss: 1.2729855536984411
Validation loss: 2.5402878468045444

Epoch: 6| Step: 3
Training loss: 1.7001723146060894
Validation loss: 2.5420549033314437

Epoch: 6| Step: 4
Training loss: 1.0824036215678583
Validation loss: 2.5973299902108837

Epoch: 6| Step: 5
Training loss: 0.8204526509042392
Validation loss: 2.5563999986780557

Epoch: 6| Step: 6
Training loss: 1.0924732931264078
Validation loss: 2.5640090212824913

Epoch: 6| Step: 7
Training loss: 0.8581045643706292
Validation loss: 2.5839172289572825

Epoch: 6| Step: 8
Training loss: 1.2899782107235536
Validation loss: 2.5766418884584055

Epoch: 6| Step: 9
Training loss: 1.0429531482001073
Validation loss: 2.5607969525923733

Epoch: 6| Step: 10
Training loss: 1.4394980103988122
Validation loss: 2.5352686433286493

Epoch: 6| Step: 11
Training loss: 0.926629044457438
Validation loss: 2.596546391888791

Epoch: 6| Step: 12
Training loss: 1.291024812558907
Validation loss: 2.5890126262387283

Epoch: 6| Step: 13
Training loss: 0.5533953377825437
Validation loss: 2.5722659538934654

Epoch: 267| Step: 0
Training loss: 0.948299009465126
Validation loss: 2.567267328472323

Epoch: 6| Step: 1
Training loss: 0.779128436478335
Validation loss: 2.595838843033162

Epoch: 6| Step: 2
Training loss: 1.2582105871463074
Validation loss: 2.5814476679799325

Epoch: 6| Step: 3
Training loss: 1.4303437274693582
Validation loss: 2.6018455819679596

Epoch: 6| Step: 4
Training loss: 1.6661965024906604
Validation loss: 2.600911445848179

Epoch: 6| Step: 5
Training loss: 1.1456649945609179
Validation loss: 2.611202265090094

Epoch: 6| Step: 6
Training loss: 1.1983334134295935
Validation loss: 2.6148607569078033

Epoch: 6| Step: 7
Training loss: 1.8316552400565216
Validation loss: 2.615621369455986

Epoch: 6| Step: 8
Training loss: 1.014185839471523
Validation loss: 2.5908185264352084

Epoch: 6| Step: 9
Training loss: 0.646014270252833
Validation loss: 2.6132242137766264

Epoch: 6| Step: 10
Training loss: 1.5620788006510298
Validation loss: 2.6532065167077903

Epoch: 6| Step: 11
Training loss: 0.9526685966503738
Validation loss: 2.619959473069865

Epoch: 6| Step: 12
Training loss: 0.7586855234720121
Validation loss: 2.6532012100992164

Epoch: 6| Step: 13
Training loss: 0.7050563354506744
Validation loss: 2.6340762520977967

Epoch: 268| Step: 0
Training loss: 0.8453111334770284
Validation loss: 2.6114535974570985

Epoch: 6| Step: 1
Training loss: 1.2713935221897237
Validation loss: 2.592183385848936

Epoch: 6| Step: 2
Training loss: 0.8801033175571166
Validation loss: 2.6079102461967776

Epoch: 6| Step: 3
Training loss: 1.304040165738952
Validation loss: 2.6377740721960152

Epoch: 6| Step: 4
Training loss: 1.1309097621411714
Validation loss: 2.593173223226769

Epoch: 6| Step: 5
Training loss: 1.3007003254963134
Validation loss: 2.6003187599439372

Epoch: 6| Step: 6
Training loss: 1.358398964043302
Validation loss: 2.6046072425192217

Epoch: 6| Step: 7
Training loss: 1.1003318567802494
Validation loss: 2.590331844692342

Epoch: 6| Step: 8
Training loss: 1.2872255588358916
Validation loss: 2.6176055755496335

Epoch: 6| Step: 9
Training loss: 1.827121426552418
Validation loss: 2.6064371468278513

Epoch: 6| Step: 10
Training loss: 0.614174453585918
Validation loss: 2.601322696996481

Epoch: 6| Step: 11
Training loss: 1.2527115974698833
Validation loss: 2.6346388062891024

Epoch: 6| Step: 12
Training loss: 1.0754204149758542
Validation loss: 2.6442110328215995

Epoch: 6| Step: 13
Training loss: 0.918683102825647
Validation loss: 2.6272856336953754

Epoch: 269| Step: 0
Training loss: 1.7644590731139018
Validation loss: 2.622598964134156

Epoch: 6| Step: 1
Training loss: 1.1159937956921246
Validation loss: 2.650276435469811

Epoch: 6| Step: 2
Training loss: 1.1028802443484167
Validation loss: 2.640356320190468

Epoch: 6| Step: 3
Training loss: 1.4208225924774822
Validation loss: 2.5814411532231167

Epoch: 6| Step: 4
Training loss: 0.9594962624322515
Validation loss: 2.609695397215498

Epoch: 6| Step: 5
Training loss: 0.8296132659749017
Validation loss: 2.5746459198196208

Epoch: 6| Step: 6
Training loss: 0.7544251864726236
Validation loss: 2.5904589937336984

Epoch: 6| Step: 7
Training loss: 1.1164819583622427
Validation loss: 2.5879146833147026

Epoch: 6| Step: 8
Training loss: 1.7146621642718571
Validation loss: 2.574897888776195

Epoch: 6| Step: 9
Training loss: 0.9506811485788085
Validation loss: 2.5737198520127764

Epoch: 6| Step: 10
Training loss: 1.0618038140606922
Validation loss: 2.5603993787608816

Epoch: 6| Step: 11
Training loss: 0.7248828299978191
Validation loss: 2.528878957310126

Epoch: 6| Step: 12
Training loss: 1.3677228043142453
Validation loss: 2.5390700160468263

Epoch: 6| Step: 13
Training loss: 1.0206472785232823
Validation loss: 2.554561451696202

Epoch: 270| Step: 0
Training loss: 1.0136304196386778
Validation loss: 2.529830769716379

Epoch: 6| Step: 1
Training loss: 1.0836960417658754
Validation loss: 2.545216735002402

Epoch: 6| Step: 2
Training loss: 1.9103283638828232
Validation loss: 2.5269814893976768

Epoch: 6| Step: 3
Training loss: 1.0491112126326538
Validation loss: 2.5372768770156537

Epoch: 6| Step: 4
Training loss: 0.6337107417495426
Validation loss: 2.5580371718802213

Epoch: 6| Step: 5
Training loss: 1.2495928101128846
Validation loss: 2.5680908621735834

Epoch: 6| Step: 6
Training loss: 1.1261950609226548
Validation loss: 2.5507516965878487

Epoch: 6| Step: 7
Training loss: 1.0632684957732943
Validation loss: 2.5601128815286898

Epoch: 6| Step: 8
Training loss: 1.3433955412597174
Validation loss: 2.559628190740631

Epoch: 6| Step: 9
Training loss: 1.0637024078301722
Validation loss: 2.5728045452375867

Epoch: 6| Step: 10
Training loss: 1.3281705063148348
Validation loss: 2.545092670395744

Epoch: 6| Step: 11
Training loss: 1.079024340598093
Validation loss: 2.583893218748701

Epoch: 6| Step: 12
Training loss: 0.7478280008688591
Validation loss: 2.6033456412992066

Epoch: 6| Step: 13
Training loss: 1.2641543568359876
Validation loss: 2.6334251941402873

Epoch: 271| Step: 0
Training loss: 1.0819745100548004
Validation loss: 2.598635626094556

Epoch: 6| Step: 1
Training loss: 1.1063611637448887
Validation loss: 2.623337316265987

Epoch: 6| Step: 2
Training loss: 0.8550236907264566
Validation loss: 2.6258741233025837

Epoch: 6| Step: 3
Training loss: 0.9067854779131068
Validation loss: 2.6094004852266677

Epoch: 6| Step: 4
Training loss: 1.4987469048424356
Validation loss: 2.6316483876458183

Epoch: 6| Step: 5
Training loss: 0.7058734159862213
Validation loss: 2.5974849373347753

Epoch: 6| Step: 6
Training loss: 0.9451700528852757
Validation loss: 2.6107377243374223

Epoch: 6| Step: 7
Training loss: 1.3557084720813666
Validation loss: 2.5994065546151606

Epoch: 6| Step: 8
Training loss: 1.6943341082032632
Validation loss: 2.6044728357959017

Epoch: 6| Step: 9
Training loss: 1.0215364811227787
Validation loss: 2.565208768151133

Epoch: 6| Step: 10
Training loss: 0.9159578089575823
Validation loss: 2.545002472224341

Epoch: 6| Step: 11
Training loss: 1.057738236450477
Validation loss: 2.5758527371023354

Epoch: 6| Step: 12
Training loss: 1.2112964713331882
Validation loss: 2.5991062092069606

Epoch: 6| Step: 13
Training loss: 1.6393885721800314
Validation loss: 2.616720243033117

Epoch: 272| Step: 0
Training loss: 1.0577949804210374
Validation loss: 2.6028158018144754

Epoch: 6| Step: 1
Training loss: 1.0858498956486238
Validation loss: 2.5856800977933103

Epoch: 6| Step: 2
Training loss: 0.8539779074600824
Validation loss: 2.5734395009127997

Epoch: 6| Step: 3
Training loss: 2.1009359453868774
Validation loss: 2.5612054912060738

Epoch: 6| Step: 4
Training loss: 0.9948708301355672
Validation loss: 2.5527884585120266

Epoch: 6| Step: 5
Training loss: 0.7931709971215183
Validation loss: 2.5729906372846525

Epoch: 6| Step: 6
Training loss: 0.8232243763364613
Validation loss: 2.602848828666177

Epoch: 6| Step: 7
Training loss: 1.4264538158450886
Validation loss: 2.6021247267830745

Epoch: 6| Step: 8
Training loss: 1.0533564893273755
Validation loss: 2.608152400182436

Epoch: 6| Step: 9
Training loss: 0.9397110931814223
Validation loss: 2.5919087429236844

Epoch: 6| Step: 10
Training loss: 1.0891214800808096
Validation loss: 2.625367310311054

Epoch: 6| Step: 11
Training loss: 0.9836753599262532
Validation loss: 2.6232998836449917

Epoch: 6| Step: 12
Training loss: 1.1919021824986136
Validation loss: 2.63555114586514

Epoch: 6| Step: 13
Training loss: 1.2269833079806136
Validation loss: 2.6500005828073565

Epoch: 273| Step: 0
Training loss: 0.7541816880291526
Validation loss: 2.648544479243707

Epoch: 6| Step: 1
Training loss: 1.666973165304107
Validation loss: 2.6807720489302262

Epoch: 6| Step: 2
Training loss: 1.2545016292410922
Validation loss: 2.7031294185866206

Epoch: 6| Step: 3
Training loss: 0.7920198071199358
Validation loss: 2.6982663621202123

Epoch: 6| Step: 4
Training loss: 0.9103709282868465
Validation loss: 2.6516680649616884

Epoch: 6| Step: 5
Training loss: 0.8015911937433581
Validation loss: 2.6648878460314323

Epoch: 6| Step: 6
Training loss: 1.557478579868326
Validation loss: 2.669182307678479

Epoch: 6| Step: 7
Training loss: 1.4349252613555417
Validation loss: 2.66352632717009

Epoch: 6| Step: 8
Training loss: 1.2811566295562271
Validation loss: 2.6642749434511397

Epoch: 6| Step: 9
Training loss: 1.1602284829615117
Validation loss: 2.6675809637473096

Epoch: 6| Step: 10
Training loss: 1.034173117122365
Validation loss: 2.628658377401128

Epoch: 6| Step: 11
Training loss: 1.130402467757769
Validation loss: 2.5687197403692

Epoch: 6| Step: 12
Training loss: 0.3718218436837717
Validation loss: 2.595261957555907

Epoch: 6| Step: 13
Training loss: 1.013864076360119
Validation loss: 2.590766324313417

Epoch: 274| Step: 0
Training loss: 1.1076634595983155
Validation loss: 2.557750848060244

Epoch: 6| Step: 1
Training loss: 0.9698013630241245
Validation loss: 2.5547138930379187

Epoch: 6| Step: 2
Training loss: 1.0236833582835727
Validation loss: 2.5821592009340786

Epoch: 6| Step: 3
Training loss: 0.8695568331153569
Validation loss: 2.5809384752613336

Epoch: 6| Step: 4
Training loss: 0.9589697997933725
Validation loss: 2.576861265522743

Epoch: 6| Step: 5
Training loss: 0.8326010745209965
Validation loss: 2.615208850557046

Epoch: 6| Step: 6
Training loss: 1.3283129390808623
Validation loss: 2.6118576110999583

Epoch: 6| Step: 7
Training loss: 1.292315730198292
Validation loss: 2.605584916998451

Epoch: 6| Step: 8
Training loss: 0.8767739433628315
Validation loss: 2.600738797536432

Epoch: 6| Step: 9
Training loss: 1.8599433350904309
Validation loss: 2.615518173298604

Epoch: 6| Step: 10
Training loss: 1.156121272576537
Validation loss: 2.633281511287774

Epoch: 6| Step: 11
Training loss: 0.9338499539662004
Validation loss: 2.608751024546458

Epoch: 6| Step: 12
Training loss: 1.3149507439384849
Validation loss: 2.682023598767541

Epoch: 6| Step: 13
Training loss: 0.849891878712555
Validation loss: 2.634764261819372

Epoch: 275| Step: 0
Training loss: 1.449321486129582
Validation loss: 2.6415244357818373

Epoch: 6| Step: 1
Training loss: 1.1485334083836394
Validation loss: 2.608092219378292

Epoch: 6| Step: 2
Training loss: 0.8722278414246258
Validation loss: 2.610679334364833

Epoch: 6| Step: 3
Training loss: 0.9774574146604396
Validation loss: 2.5758224372589384

Epoch: 6| Step: 4
Training loss: 1.3785102859268286
Validation loss: 2.6093335668172513

Epoch: 6| Step: 5
Training loss: 0.7669763122889557
Validation loss: 2.6084793623805065

Epoch: 6| Step: 6
Training loss: 1.7111076374899434
Validation loss: 2.6028992716966948

Epoch: 6| Step: 7
Training loss: 1.0371735691239528
Validation loss: 2.591948801898485

Epoch: 6| Step: 8
Training loss: 1.0501448962734858
Validation loss: 2.5971290292062466

Epoch: 6| Step: 9
Training loss: 1.1112445069081809
Validation loss: 2.5969891910737037

Epoch: 6| Step: 10
Training loss: 0.7816886814639517
Validation loss: 2.618365478870778

Epoch: 6| Step: 11
Training loss: 0.8653537504283622
Validation loss: 2.560063746444414

Epoch: 6| Step: 12
Training loss: 0.9760124183161798
Validation loss: 2.571916635369897

Epoch: 6| Step: 13
Training loss: 1.2761926159488306
Validation loss: 2.571824467252182

Epoch: 276| Step: 0
Training loss: 0.8878908854667527
Validation loss: 2.5909309412290056

Epoch: 6| Step: 1
Training loss: 1.3369211958812615
Validation loss: 2.5948769021192954

Epoch: 6| Step: 2
Training loss: 1.098059854936234
Validation loss: 2.5663229355245254

Epoch: 6| Step: 3
Training loss: 0.5232609977915119
Validation loss: 2.5734841548455845

Epoch: 6| Step: 4
Training loss: 1.0595361097590308
Validation loss: 2.6296230474359463

Epoch: 6| Step: 5
Training loss: 0.9766041861219996
Validation loss: 2.623023961854933

Epoch: 6| Step: 6
Training loss: 1.0428730781479856
Validation loss: 2.6351866009857425

Epoch: 6| Step: 7
Training loss: 1.1513472046545705
Validation loss: 2.6213022420582193

Epoch: 6| Step: 8
Training loss: 1.1359203982738402
Validation loss: 2.6380292980612743

Epoch: 6| Step: 9
Training loss: 1.1780655175530184
Validation loss: 2.633352851354007

Epoch: 6| Step: 10
Training loss: 0.7822656133574204
Validation loss: 2.6223121746463285

Epoch: 6| Step: 11
Training loss: 1.3219526137344295
Validation loss: 2.6057869544585

Epoch: 6| Step: 12
Training loss: 1.748552882092154
Validation loss: 2.610347178377351

Epoch: 6| Step: 13
Training loss: 0.7227145197290076
Validation loss: 2.622147855981049

Epoch: 277| Step: 0
Training loss: 1.1022998695642698
Validation loss: 2.5862011969747174

Epoch: 6| Step: 1
Training loss: 1.2866018217840332
Validation loss: 2.6098017386296735

Epoch: 6| Step: 2
Training loss: 1.127849149925012
Validation loss: 2.5894308124014236

Epoch: 6| Step: 3
Training loss: 0.87277999314779
Validation loss: 2.590959883966226

Epoch: 6| Step: 4
Training loss: 1.081369466190468
Validation loss: 2.5715018747578453

Epoch: 6| Step: 5
Training loss: 0.7128927570467904
Validation loss: 2.6073639485987443

Epoch: 6| Step: 6
Training loss: 0.9010728746129023
Validation loss: 2.5616236242822112

Epoch: 6| Step: 7
Training loss: 1.1685135505292121
Validation loss: 2.594337571771812

Epoch: 6| Step: 8
Training loss: 0.6848589496810096
Validation loss: 2.5663669620821326

Epoch: 6| Step: 9
Training loss: 1.2543203080232852
Validation loss: 2.56654098111386

Epoch: 6| Step: 10
Training loss: 1.7995494676061823
Validation loss: 2.5824233949047226

Epoch: 6| Step: 11
Training loss: 0.9011434523288231
Validation loss: 2.584798351477399

Epoch: 6| Step: 12
Training loss: 0.9744360393126394
Validation loss: 2.5481297547498314

Epoch: 6| Step: 13
Training loss: 0.9182060421985202
Validation loss: 2.5470475174206

Epoch: 278| Step: 0
Training loss: 0.8836928847443152
Validation loss: 2.5703949530902137

Epoch: 6| Step: 1
Training loss: 0.7206449407645673
Validation loss: 2.5809922717121676

Epoch: 6| Step: 2
Training loss: 1.649323573320808
Validation loss: 2.5299410634218784

Epoch: 6| Step: 3
Training loss: 0.9415396441532061
Validation loss: 2.576209248045746

Epoch: 6| Step: 4
Training loss: 1.0510352299281747
Validation loss: 2.5686166505388397

Epoch: 6| Step: 5
Training loss: 0.9089364321548368
Validation loss: 2.5794383929987905

Epoch: 6| Step: 6
Training loss: 1.2326662332191207
Validation loss: 2.585403443248026

Epoch: 6| Step: 7
Training loss: 0.778872228432311
Validation loss: 2.603865688199755

Epoch: 6| Step: 8
Training loss: 1.159997126394856
Validation loss: 2.6086526919428996

Epoch: 6| Step: 9
Training loss: 1.4571102826567297
Validation loss: 2.613253297108611

Epoch: 6| Step: 10
Training loss: 1.1688509769983741
Validation loss: 2.599634660116625

Epoch: 6| Step: 11
Training loss: 0.8853169927405623
Validation loss: 2.647450415503582

Epoch: 6| Step: 12
Training loss: 1.036625923652196
Validation loss: 2.6068735278961843

Epoch: 6| Step: 13
Training loss: 1.0833868355866527
Validation loss: 2.588945639323633

Epoch: 279| Step: 0
Training loss: 0.9002430561140041
Validation loss: 2.5930822110518945

Epoch: 6| Step: 1
Training loss: 0.9202907980673866
Validation loss: 2.564485830426116

Epoch: 6| Step: 2
Training loss: 0.9295533027283698
Validation loss: 2.5380172953472795

Epoch: 6| Step: 3
Training loss: 1.6042957336555472
Validation loss: 2.5486403712988634

Epoch: 6| Step: 4
Training loss: 0.8864242131756332
Validation loss: 2.5672621717621547

Epoch: 6| Step: 5
Training loss: 0.9156657122000752
Validation loss: 2.575234470709564

Epoch: 6| Step: 6
Training loss: 0.9934559620992386
Validation loss: 2.6041308765207987

Epoch: 6| Step: 7
Training loss: 1.1576146501153228
Validation loss: 2.5845596791292627

Epoch: 6| Step: 8
Training loss: 0.9549894077152998
Validation loss: 2.6394939909386412

Epoch: 6| Step: 9
Training loss: 0.9511604073399123
Validation loss: 2.6301626005108787

Epoch: 6| Step: 10
Training loss: 1.3634699387574571
Validation loss: 2.612485562674354

Epoch: 6| Step: 11
Training loss: 1.2749251586789492
Validation loss: 2.6350487202472475

Epoch: 6| Step: 12
Training loss: 1.3275688353254853
Validation loss: 2.6598991739757567

Epoch: 6| Step: 13
Training loss: 0.7059912857566091
Validation loss: 2.6709177091391827

Epoch: 280| Step: 0
Training loss: 1.211649088821695
Validation loss: 2.6336993107884874

Epoch: 6| Step: 1
Training loss: 1.062078672907409
Validation loss: 2.646352657065464

Epoch: 6| Step: 2
Training loss: 0.7622702142894575
Validation loss: 2.6497086232625517

Epoch: 6| Step: 3
Training loss: 0.5000434498981476
Validation loss: 2.6209241140566566

Epoch: 6| Step: 4
Training loss: 0.9189669761577032
Validation loss: 2.634672168626253

Epoch: 6| Step: 5
Training loss: 1.1247019902870121
Validation loss: 2.5815368320959418

Epoch: 6| Step: 6
Training loss: 1.1520067659748916
Validation loss: 2.585367958235575

Epoch: 6| Step: 7
Training loss: 0.8602203372984053
Validation loss: 2.5912697204928827

Epoch: 6| Step: 8
Training loss: 1.1487938983154833
Validation loss: 2.581255608827448

Epoch: 6| Step: 9
Training loss: 1.3332199207391344
Validation loss: 2.598911476752707

Epoch: 6| Step: 10
Training loss: 1.6430493562219004
Validation loss: 2.566714341123463

Epoch: 6| Step: 11
Training loss: 0.9092978493909534
Validation loss: 2.561391369028642

Epoch: 6| Step: 12
Training loss: 1.1483610997121207
Validation loss: 2.5855922445569104

Epoch: 6| Step: 13
Training loss: 0.7884791266678642
Validation loss: 2.621208248446814

Epoch: 281| Step: 0
Training loss: 1.0690083040997922
Validation loss: 2.648451667351121

Epoch: 6| Step: 1
Training loss: 0.8138770758090164
Validation loss: 2.6505479543680908

Epoch: 6| Step: 2
Training loss: 1.7830620633639933
Validation loss: 2.6652914072132807

Epoch: 6| Step: 3
Training loss: 1.18975906321165
Validation loss: 2.674376817024851

Epoch: 6| Step: 4
Training loss: 0.6144631047296286
Validation loss: 2.6813491313804234

Epoch: 6| Step: 5
Training loss: 0.9886238197997763
Validation loss: 2.6518280041590203

Epoch: 6| Step: 6
Training loss: 1.1037951090182299
Validation loss: 2.6681999642414227

Epoch: 6| Step: 7
Training loss: 1.0003794903714587
Validation loss: 2.648073725658512

Epoch: 6| Step: 8
Training loss: 1.055831853498723
Validation loss: 2.603819014611363

Epoch: 6| Step: 9
Training loss: 1.1797411571703993
Validation loss: 2.641472754350798

Epoch: 6| Step: 10
Training loss: 1.0065702130254004
Validation loss: 2.617237113246071

Epoch: 6| Step: 11
Training loss: 0.716576898482573
Validation loss: 2.6031113728842152

Epoch: 6| Step: 12
Training loss: 1.1301650055111452
Validation loss: 2.5880001585601935

Epoch: 6| Step: 13
Training loss: 0.767144116886228
Validation loss: 2.597615150991927

Epoch: 282| Step: 0
Training loss: 0.9675580351818733
Validation loss: 2.6174715816357126

Epoch: 6| Step: 1
Training loss: 1.0300853394829657
Validation loss: 2.594621313556226

Epoch: 6| Step: 2
Training loss: 0.6985475099362627
Validation loss: 2.588773657144517

Epoch: 6| Step: 3
Training loss: 1.1761448193507082
Validation loss: 2.6161380354020296

Epoch: 6| Step: 4
Training loss: 0.31442440683715805
Validation loss: 2.5663348370445114

Epoch: 6| Step: 5
Training loss: 0.9556510782519451
Validation loss: 2.5917660107930782

Epoch: 6| Step: 6
Training loss: 1.1377963696567222
Validation loss: 2.5688515278833863

Epoch: 6| Step: 7
Training loss: 1.7067979875844603
Validation loss: 2.633315296300838

Epoch: 6| Step: 8
Training loss: 0.9750392172335596
Validation loss: 2.596153250927549

Epoch: 6| Step: 9
Training loss: 1.4171604343172435
Validation loss: 2.5790545038715273

Epoch: 6| Step: 10
Training loss: 0.687894902819839
Validation loss: 2.5748898341324473

Epoch: 6| Step: 11
Training loss: 1.3390743615638863
Validation loss: 2.571599799607341

Epoch: 6| Step: 12
Training loss: 0.9207797252073404
Validation loss: 2.5936169027413998

Epoch: 6| Step: 13
Training loss: 0.42266434540108677
Validation loss: 2.582183681977349

Epoch: 283| Step: 0
Training loss: 1.288539248530782
Validation loss: 2.569570358001156

Epoch: 6| Step: 1
Training loss: 1.0178341241494815
Validation loss: 2.599280681607272

Epoch: 6| Step: 2
Training loss: 0.8929829420295254
Validation loss: 2.6185892670021236

Epoch: 6| Step: 3
Training loss: 1.702815036390253
Validation loss: 2.5785010497683056

Epoch: 6| Step: 4
Training loss: 0.6284472289012837
Validation loss: 2.567633154849165

Epoch: 6| Step: 5
Training loss: 0.8000885735593036
Validation loss: 2.5319132075934823

Epoch: 6| Step: 6
Training loss: 0.9679386679198384
Validation loss: 2.5290312943983575

Epoch: 6| Step: 7
Training loss: 1.1453772533061115
Validation loss: 2.5314541542837494

Epoch: 6| Step: 8
Training loss: 0.9000515247536978
Validation loss: 2.52750511457545

Epoch: 6| Step: 9
Training loss: 1.2094062722275778
Validation loss: 2.5489946306491404

Epoch: 6| Step: 10
Training loss: 0.9639284371468975
Validation loss: 2.560041251960565

Epoch: 6| Step: 11
Training loss: 0.9332681830408063
Validation loss: 2.5435873685857504

Epoch: 6| Step: 12
Training loss: 0.7899220383479535
Validation loss: 2.5604248238052314

Epoch: 6| Step: 13
Training loss: 1.3335592505669345
Validation loss: 2.580601597666285

Epoch: 284| Step: 0
Training loss: 0.6091033378912316
Validation loss: 2.6058335785335216

Epoch: 6| Step: 1
Training loss: 1.1491858710403338
Validation loss: 2.6385296651754633

Epoch: 6| Step: 2
Training loss: 1.857462500479912
Validation loss: 2.5950092471662938

Epoch: 6| Step: 3
Training loss: 0.9578072029701611
Validation loss: 2.618585161985065

Epoch: 6| Step: 4
Training loss: 0.9049082063520132
Validation loss: 2.607317220134526

Epoch: 6| Step: 5
Training loss: 1.0871172746706443
Validation loss: 2.6352010360908498

Epoch: 6| Step: 6
Training loss: 0.970063518823728
Validation loss: 2.6080387155360105

Epoch: 6| Step: 7
Training loss: 0.6268590933853476
Validation loss: 2.638270183031829

Epoch: 6| Step: 8
Training loss: 1.184071359487992
Validation loss: 2.63185866288229

Epoch: 6| Step: 9
Training loss: 1.288561359441093
Validation loss: 2.615806599023861

Epoch: 6| Step: 10
Training loss: 0.8041107555250281
Validation loss: 2.629429102559819

Epoch: 6| Step: 11
Training loss: 0.9415488234070132
Validation loss: 2.6639166076819527

Epoch: 6| Step: 12
Training loss: 0.8240277398958478
Validation loss: 2.6203799171493993

Epoch: 6| Step: 13
Training loss: 0.9548448148935903
Validation loss: 2.6135614741133377

Epoch: 285| Step: 0
Training loss: 0.7787783243162557
Validation loss: 2.6548939524358888

Epoch: 6| Step: 1
Training loss: 0.9551096093852758
Validation loss: 2.6201406857304272

Epoch: 6| Step: 2
Training loss: 0.9816444308855726
Validation loss: 2.6454424005282635

Epoch: 6| Step: 3
Training loss: 1.212083483464632
Validation loss: 2.6187399948954546

Epoch: 6| Step: 4
Training loss: 0.8607163797815488
Validation loss: 2.5864783559371785

Epoch: 6| Step: 5
Training loss: 0.9176361780165235
Validation loss: 2.610185041200469

Epoch: 6| Step: 6
Training loss: 1.0416290594305904
Validation loss: 2.605153429841712

Epoch: 6| Step: 7
Training loss: 1.2171960362733707
Validation loss: 2.6175054237995985

Epoch: 6| Step: 8
Training loss: 1.6533278111909098
Validation loss: 2.6026267170090986

Epoch: 6| Step: 9
Training loss: 0.9880542720645374
Validation loss: 2.5988118169458536

Epoch: 6| Step: 10
Training loss: 0.888878196827506
Validation loss: 2.5799524050058102

Epoch: 6| Step: 11
Training loss: 0.7730216247228299
Validation loss: 2.591538268212137

Epoch: 6| Step: 12
Training loss: 1.1432638083432578
Validation loss: 2.5895084234608263

Epoch: 6| Step: 13
Training loss: 0.839281044457149
Validation loss: 2.589980027478159

Epoch: 286| Step: 0
Training loss: 0.6227724433569889
Validation loss: 2.5730035989785436

Epoch: 6| Step: 1
Training loss: 0.918875518321261
Validation loss: 2.586354565215279

Epoch: 6| Step: 2
Training loss: 1.01982597680412
Validation loss: 2.6072793598777806

Epoch: 6| Step: 3
Training loss: 1.1681962317989987
Validation loss: 2.56911224868101

Epoch: 6| Step: 4
Training loss: 1.2591332556185875
Validation loss: 2.604427559530525

Epoch: 6| Step: 5
Training loss: 0.9233422322194451
Validation loss: 2.6314239418738308

Epoch: 6| Step: 6
Training loss: 0.5924060066127262
Validation loss: 2.599519190729359

Epoch: 6| Step: 7
Training loss: 1.0500070208360188
Validation loss: 2.635613546264988

Epoch: 6| Step: 8
Training loss: 0.9850300017498091
Validation loss: 2.659380916415695

Epoch: 6| Step: 9
Training loss: 1.1351512050319652
Validation loss: 2.6342083863258003

Epoch: 6| Step: 10
Training loss: 0.8129515126937887
Validation loss: 2.638480731167899

Epoch: 6| Step: 11
Training loss: 0.8968204043050202
Validation loss: 2.66402766048236

Epoch: 6| Step: 12
Training loss: 1.1048794311234331
Validation loss: 2.6379232685076093

Epoch: 6| Step: 13
Training loss: 2.039247000228735
Validation loss: 2.632413822083218

Epoch: 287| Step: 0
Training loss: 0.9994826170500807
Validation loss: 2.602005365299285

Epoch: 6| Step: 1
Training loss: 0.932268295137211
Validation loss: 2.6186330335440164

Epoch: 6| Step: 2
Training loss: 0.8306158141926361
Validation loss: 2.570221410940664

Epoch: 6| Step: 3
Training loss: 1.2081841946786007
Validation loss: 2.5909324016818687

Epoch: 6| Step: 4
Training loss: 0.6871487413745837
Validation loss: 2.546194495333758

Epoch: 6| Step: 5
Training loss: 0.6477328918903834
Validation loss: 2.580370576187588

Epoch: 6| Step: 6
Training loss: 1.0109389551261323
Validation loss: 2.5496773742300407

Epoch: 6| Step: 7
Training loss: 1.1621323014249796
Validation loss: 2.5433129473248353

Epoch: 6| Step: 8
Training loss: 0.7241846366674934
Validation loss: 2.5752018261338914

Epoch: 6| Step: 9
Training loss: 0.9424381536333125
Validation loss: 2.5645802675521776

Epoch: 6| Step: 10
Training loss: 1.3341556735105085
Validation loss: 2.5739062404319135

Epoch: 6| Step: 11
Training loss: 1.7754535391123332
Validation loss: 2.5771482514801303

Epoch: 6| Step: 12
Training loss: 0.6696817395865463
Validation loss: 2.595095393633916

Epoch: 6| Step: 13
Training loss: 0.9455377925035359
Validation loss: 2.571761062871986

Epoch: 288| Step: 0
Training loss: 0.8804500669242022
Validation loss: 2.5743110303213474

Epoch: 6| Step: 1
Training loss: 1.0056123596876398
Validation loss: 2.5661076407440944

Epoch: 6| Step: 2
Training loss: 1.0040097906843535
Validation loss: 2.5817682690401966

Epoch: 6| Step: 3
Training loss: 1.390016143897185
Validation loss: 2.5933187990909317

Epoch: 6| Step: 4
Training loss: 1.7124144567578425
Validation loss: 2.6176428427987366

Epoch: 6| Step: 5
Training loss: 0.9739509147048714
Validation loss: 2.594487515960724

Epoch: 6| Step: 6
Training loss: 1.2071883213594403
Validation loss: 2.6034700169835854

Epoch: 6| Step: 7
Training loss: 0.7971598920000578
Validation loss: 2.6084630172095973

Epoch: 6| Step: 8
Training loss: 0.7721470558014036
Validation loss: 2.6002796561061126

Epoch: 6| Step: 9
Training loss: 0.8374794971746271
Validation loss: 2.6162585879320637

Epoch: 6| Step: 10
Training loss: 0.5975294290262185
Validation loss: 2.5978701154104806

Epoch: 6| Step: 11
Training loss: 0.9550248893769884
Validation loss: 2.5899221019628733

Epoch: 6| Step: 12
Training loss: 0.5176153205605882
Validation loss: 2.624256132157479

Epoch: 6| Step: 13
Training loss: 1.1806054491208464
Validation loss: 2.6340009129225734

Epoch: 289| Step: 0
Training loss: 0.7272029228197874
Validation loss: 2.569038794403159

Epoch: 6| Step: 1
Training loss: 1.0231192290481812
Validation loss: 2.598590860772987

Epoch: 6| Step: 2
Training loss: 0.726629848845319
Validation loss: 2.584003312650555

Epoch: 6| Step: 3
Training loss: 0.928012396663868
Validation loss: 2.596495323866677

Epoch: 6| Step: 4
Training loss: 1.5308113248292037
Validation loss: 2.565268055200777

Epoch: 6| Step: 5
Training loss: 0.8524672924826237
Validation loss: 2.605372274273391

Epoch: 6| Step: 6
Training loss: 0.9090483967095878
Validation loss: 2.6057036447191457

Epoch: 6| Step: 7
Training loss: 0.5815994145619333
Validation loss: 2.608955986792007

Epoch: 6| Step: 8
Training loss: 1.2621803029991605
Validation loss: 2.5810989524392216

Epoch: 6| Step: 9
Training loss: 0.6904871807413867
Validation loss: 2.6203915134698477

Epoch: 6| Step: 10
Training loss: 1.03637744198126
Validation loss: 2.579960385217407

Epoch: 6| Step: 11
Training loss: 1.2561359486595758
Validation loss: 2.626839286855754

Epoch: 6| Step: 12
Training loss: 1.3294017265011333
Validation loss: 2.6394421939906723

Epoch: 6| Step: 13
Training loss: 0.8770185076632154
Validation loss: 2.607354036629844

Epoch: 290| Step: 0
Training loss: 1.5149120738383406
Validation loss: 2.60499542699803

Epoch: 6| Step: 1
Training loss: 1.094316935063634
Validation loss: 2.5951434930240476

Epoch: 6| Step: 2
Training loss: 0.8297514149101218
Validation loss: 2.620909088746892

Epoch: 6| Step: 3
Training loss: 1.0887631764364616
Validation loss: 2.598635546185356

Epoch: 6| Step: 4
Training loss: 0.9644684467048836
Validation loss: 2.572129596040396

Epoch: 6| Step: 5
Training loss: 1.1910108566814293
Validation loss: 2.5875552682719047

Epoch: 6| Step: 6
Training loss: 1.2522586443772719
Validation loss: 2.5218968169791993

Epoch: 6| Step: 7
Training loss: 0.8732791736664781
Validation loss: 2.5569898201940258

Epoch: 6| Step: 8
Training loss: 0.8565354337872958
Validation loss: 2.553205829314418

Epoch: 6| Step: 9
Training loss: 0.6234371672894731
Validation loss: 2.594512636575085

Epoch: 6| Step: 10
Training loss: 1.139772331609755
Validation loss: 2.5775662480133175

Epoch: 6| Step: 11
Training loss: 0.722624494525051
Validation loss: 2.5904008790156414

Epoch: 6| Step: 12
Training loss: 0.8042744808034439
Validation loss: 2.580642830042658

Epoch: 6| Step: 13
Training loss: 0.7744403849069212
Validation loss: 2.6311980680834473

Epoch: 291| Step: 0
Training loss: 0.877766493246588
Validation loss: 2.6104366585906202

Epoch: 6| Step: 1
Training loss: 0.7704998833039212
Validation loss: 2.564951340690096

Epoch: 6| Step: 2
Training loss: 1.0710896364629707
Validation loss: 2.565609651594359

Epoch: 6| Step: 3
Training loss: 0.9652196792725029
Validation loss: 2.5779847455896037

Epoch: 6| Step: 4
Training loss: 1.0521492827238403
Validation loss: 2.578551475971546

Epoch: 6| Step: 5
Training loss: 1.094876227242167
Validation loss: 2.5691120231623277

Epoch: 6| Step: 6
Training loss: 1.5120857049680423
Validation loss: 2.5526327968530387

Epoch: 6| Step: 7
Training loss: 0.9011318440965194
Validation loss: 2.5780215464170757

Epoch: 6| Step: 8
Training loss: 1.1364108058502964
Validation loss: 2.5671935897274683

Epoch: 6| Step: 9
Training loss: 1.0503643584451747
Validation loss: 2.6135194721580133

Epoch: 6| Step: 10
Training loss: 0.747412828701902
Validation loss: 2.5937039800802295

Epoch: 6| Step: 11
Training loss: 0.794064671176793
Validation loss: 2.5616980717747517

Epoch: 6| Step: 12
Training loss: 0.8349333819923074
Validation loss: 2.5729312462053398

Epoch: 6| Step: 13
Training loss: 0.9804216350770523
Validation loss: 2.566730357869972

Epoch: 292| Step: 0
Training loss: 0.9293189720807392
Validation loss: 2.5500146958114462

Epoch: 6| Step: 1
Training loss: 0.9333604656828404
Validation loss: 2.571109286544483

Epoch: 6| Step: 2
Training loss: 0.6687132049848332
Validation loss: 2.561925590077731

Epoch: 6| Step: 3
Training loss: 1.585840757830037
Validation loss: 2.5553702785803756

Epoch: 6| Step: 4
Training loss: 1.0311034127291496
Validation loss: 2.5414415293743065

Epoch: 6| Step: 5
Training loss: 0.9366986028367422
Validation loss: 2.5836465416131547

Epoch: 6| Step: 6
Training loss: 1.115435901077483
Validation loss: 2.579222331317013

Epoch: 6| Step: 7
Training loss: 1.232014245573269
Validation loss: 2.615388369213022

Epoch: 6| Step: 8
Training loss: 0.6774659958361167
Validation loss: 2.6600774600627237

Epoch: 6| Step: 9
Training loss: 0.5984401174941227
Validation loss: 2.632642721327284

Epoch: 6| Step: 10
Training loss: 0.8665519309818006
Validation loss: 2.63402339577201

Epoch: 6| Step: 11
Training loss: 0.8394876834222619
Validation loss: 2.6501167141253963

Epoch: 6| Step: 12
Training loss: 1.364160904278913
Validation loss: 2.6506296515355117

Epoch: 6| Step: 13
Training loss: 0.5844610303903263
Validation loss: 2.632459174053092

Epoch: 293| Step: 0
Training loss: 0.9282920687034927
Validation loss: 2.6131468136109977

Epoch: 6| Step: 1
Training loss: 1.050568739946561
Validation loss: 2.6412632309192383

Epoch: 6| Step: 2
Training loss: 0.8914751044652095
Validation loss: 2.608939657381461

Epoch: 6| Step: 3
Training loss: 1.1418277199931588
Validation loss: 2.6182649821575628

Epoch: 6| Step: 4
Training loss: 0.6692811220518675
Validation loss: 2.614717859437634

Epoch: 6| Step: 5
Training loss: 1.549488749327533
Validation loss: 2.629335088681889

Epoch: 6| Step: 6
Training loss: 0.9910519326745983
Validation loss: 2.631656575428853

Epoch: 6| Step: 7
Training loss: 1.0325988271490483
Validation loss: 2.564013221675469

Epoch: 6| Step: 8
Training loss: 0.8084780108045412
Validation loss: 2.5848437841194083

Epoch: 6| Step: 9
Training loss: 0.916341792682896
Validation loss: 2.555141824403407

Epoch: 6| Step: 10
Training loss: 1.149979678264687
Validation loss: 2.5453510296086854

Epoch: 6| Step: 11
Training loss: 0.8549028031275896
Validation loss: 2.5574002972268306

Epoch: 6| Step: 12
Training loss: 0.7563901708289055
Validation loss: 2.5334560109838624

Epoch: 6| Step: 13
Training loss: 0.20381344989132963
Validation loss: 2.5342317735352617

Epoch: 294| Step: 0
Training loss: 1.4793179752526222
Validation loss: 2.58453314947127

Epoch: 6| Step: 1
Training loss: 1.1368761510775014
Validation loss: 2.62879917763123

Epoch: 6| Step: 2
Training loss: 0.8420528721824903
Validation loss: 2.598591432972107

Epoch: 6| Step: 3
Training loss: 0.8346985878845277
Validation loss: 2.620421137027032

Epoch: 6| Step: 4
Training loss: 0.7333129751746377
Validation loss: 2.6067010389243364

Epoch: 6| Step: 5
Training loss: 0.9876891462040405
Validation loss: 2.635526469424302

Epoch: 6| Step: 6
Training loss: 0.9178627764628086
Validation loss: 2.6452721231580356

Epoch: 6| Step: 7
Training loss: 1.0163054314354567
Validation loss: 2.6316719426744606

Epoch: 6| Step: 8
Training loss: 0.6672411966268369
Validation loss: 2.647045648086147

Epoch: 6| Step: 9
Training loss: 1.0527168796196675
Validation loss: 2.6123284287246467

Epoch: 6| Step: 10
Training loss: 0.7653374423864868
Validation loss: 2.651395550765759

Epoch: 6| Step: 11
Training loss: 1.085341420314178
Validation loss: 2.6288654142777714

Epoch: 6| Step: 12
Training loss: 0.9393586807203994
Validation loss: 2.5987000814362875

Epoch: 6| Step: 13
Training loss: 0.8404174619402044
Validation loss: 2.5913440533093164

Epoch: 295| Step: 0
Training loss: 0.5326967454837715
Validation loss: 2.5752908998925954

Epoch: 6| Step: 1
Training loss: 0.7774787287240189
Validation loss: 2.594354064238587

Epoch: 6| Step: 2
Training loss: 0.9852508402706842
Validation loss: 2.5817072130432033

Epoch: 6| Step: 3
Training loss: 0.7794210769994587
Validation loss: 2.5920127925044394

Epoch: 6| Step: 4
Training loss: 1.01215179484025
Validation loss: 2.572840892055727

Epoch: 6| Step: 5
Training loss: 0.9044213755118391
Validation loss: 2.613357082508698

Epoch: 6| Step: 6
Training loss: 0.9050368706690105
Validation loss: 2.5622406014628814

Epoch: 6| Step: 7
Training loss: 1.2481513658698622
Validation loss: 2.6130449781221485

Epoch: 6| Step: 8
Training loss: 0.9530883219181098
Validation loss: 2.59712250245575

Epoch: 6| Step: 9
Training loss: 1.5038947563227596
Validation loss: 2.613972780401425

Epoch: 6| Step: 10
Training loss: 0.4674680664763371
Validation loss: 2.591172880337762

Epoch: 6| Step: 11
Training loss: 1.3384523869091143
Validation loss: 2.579450959530065

Epoch: 6| Step: 12
Training loss: 0.8269107842000839
Validation loss: 2.6150990175208095

Epoch: 6| Step: 13
Training loss: 0.6977785291658427
Validation loss: 2.589800293799942

Epoch: 296| Step: 0
Training loss: 1.393154158905309
Validation loss: 2.6136832955348392

Epoch: 6| Step: 1
Training loss: 1.1452594822872233
Validation loss: 2.5873527494467963

Epoch: 6| Step: 2
Training loss: 0.3610728006133364
Validation loss: 2.6258498933799563

Epoch: 6| Step: 3
Training loss: 0.909101341469467
Validation loss: 2.6175718610227405

Epoch: 6| Step: 4
Training loss: 0.9408739096476973
Validation loss: 2.5771543622755586

Epoch: 6| Step: 5
Training loss: 0.9683190279268893
Validation loss: 2.619432963525606

Epoch: 6| Step: 6
Training loss: 1.198513556781305
Validation loss: 2.606602069364427

Epoch: 6| Step: 7
Training loss: 0.9322481873388
Validation loss: 2.6034963024707296

Epoch: 6| Step: 8
Training loss: 0.9001918747137518
Validation loss: 2.5813301892944502

Epoch: 6| Step: 9
Training loss: 1.2075549720903465
Validation loss: 2.6150389063898474

Epoch: 6| Step: 10
Training loss: 0.6812273319217772
Validation loss: 2.580572863112115

Epoch: 6| Step: 11
Training loss: 0.8076876294783066
Validation loss: 2.574188698323332

Epoch: 6| Step: 12
Training loss: 0.8137480613579928
Validation loss: 2.572795312224999

Epoch: 6| Step: 13
Training loss: 0.41940648587504964
Validation loss: 2.6121171917626915

Epoch: 297| Step: 0
Training loss: 1.163013369508816
Validation loss: 2.59434684570926

Epoch: 6| Step: 1
Training loss: 0.7340559570748442
Validation loss: 2.627166972338604

Epoch: 6| Step: 2
Training loss: 0.6993654406237696
Validation loss: 2.616285087891411

Epoch: 6| Step: 3
Training loss: 1.0432162901905322
Validation loss: 2.6137088701861417

Epoch: 6| Step: 4
Training loss: 0.9325640758150581
Validation loss: 2.585188848962632

Epoch: 6| Step: 5
Training loss: 0.9875863689364902
Validation loss: 2.6197363901179163

Epoch: 6| Step: 6
Training loss: 0.7941710279117477
Validation loss: 2.5999328205463126

Epoch: 6| Step: 7
Training loss: 0.6020724624479573
Validation loss: 2.6311735880675244

Epoch: 6| Step: 8
Training loss: 0.8059800516693728
Validation loss: 2.6314855229158964

Epoch: 6| Step: 9
Training loss: 0.5446254785521171
Validation loss: 2.6602512843957657

Epoch: 6| Step: 10
Training loss: 1.7032591040774032
Validation loss: 2.615778984780573

Epoch: 6| Step: 11
Training loss: 0.9189167403381416
Validation loss: 2.6259067412795485

Epoch: 6| Step: 12
Training loss: 0.8481559511073622
Validation loss: 2.633880423965099

Epoch: 6| Step: 13
Training loss: 1.04887887274298
Validation loss: 2.5970640728963588

Epoch: 298| Step: 0
Training loss: 1.0480198080724346
Validation loss: 2.596000535151656

Epoch: 6| Step: 1
Training loss: 0.9306925301936237
Validation loss: 2.5539071379314056

Epoch: 6| Step: 2
Training loss: 0.668316087151453
Validation loss: 2.551216303340826

Epoch: 6| Step: 3
Training loss: 1.2345634992544556
Validation loss: 2.5605804297737698

Epoch: 6| Step: 4
Training loss: 0.6741068388000784
Validation loss: 2.572723360153771

Epoch: 6| Step: 5
Training loss: 0.7954273538152943
Validation loss: 2.5682611069926486

Epoch: 6| Step: 6
Training loss: 0.9325118879220121
Validation loss: 2.5750744344639918

Epoch: 6| Step: 7
Training loss: 1.139785614518223
Validation loss: 2.557422951771757

Epoch: 6| Step: 8
Training loss: 0.8988139151818082
Validation loss: 2.575945702568499

Epoch: 6| Step: 9
Training loss: 0.7917903167799287
Validation loss: 2.5566951412768266

Epoch: 6| Step: 10
Training loss: 1.5631674294736118
Validation loss: 2.576514732165649

Epoch: 6| Step: 11
Training loss: 0.702783544070277
Validation loss: 2.6097066299002747

Epoch: 6| Step: 12
Training loss: 0.7072713876175769
Validation loss: 2.6003145560852894

Epoch: 6| Step: 13
Training loss: 0.2748432536334858
Validation loss: 2.606671429097267

Epoch: 299| Step: 0
Training loss: 0.9828439947033809
Validation loss: 2.6655270374242774

Epoch: 6| Step: 1
Training loss: 0.7318962957996001
Validation loss: 2.647059310557416

Epoch: 6| Step: 2
Training loss: 0.8170450440156286
Validation loss: 2.6707864045457423

Epoch: 6| Step: 3
Training loss: 0.48247169515374366
Validation loss: 2.6333575233069095

Epoch: 6| Step: 4
Training loss: 0.6083998090749989
Validation loss: 2.6472509854546424

Epoch: 6| Step: 5
Training loss: 1.1759331690586614
Validation loss: 2.6367444356854497

Epoch: 6| Step: 6
Training loss: 0.9464688125445586
Validation loss: 2.6255681003767277

Epoch: 6| Step: 7
Training loss: 1.621750664033573
Validation loss: 2.6119228571219306

Epoch: 6| Step: 8
Training loss: 0.7560283067969434
Validation loss: 2.5909349693459838

Epoch: 6| Step: 9
Training loss: 0.7203988774406841
Validation loss: 2.61165078278551

Epoch: 6| Step: 10
Training loss: 1.1963635978055738
Validation loss: 2.5684505201144154

Epoch: 6| Step: 11
Training loss: 0.8052690497072279
Validation loss: 2.5735608830866834

Epoch: 6| Step: 12
Training loss: 0.8519978241735982
Validation loss: 2.565178177680262

Epoch: 6| Step: 13
Training loss: 0.7556127890206796
Validation loss: 2.5922217988827847

Epoch: 300| Step: 0
Training loss: 0.9711816479407
Validation loss: 2.544963260850194

Epoch: 6| Step: 1
Training loss: 0.9726974907523562
Validation loss: 2.5960529539523707

Epoch: 6| Step: 2
Training loss: 0.8553413749172103
Validation loss: 2.5827403411751804

Epoch: 6| Step: 3
Training loss: 1.016689915990512
Validation loss: 2.612116584250233

Epoch: 6| Step: 4
Training loss: 0.5658816045312911
Validation loss: 2.5758271747431793

Epoch: 6| Step: 5
Training loss: 0.6216589077788344
Validation loss: 2.5677525750870585

Epoch: 6| Step: 6
Training loss: 0.6693909879853402
Validation loss: 2.596752067674964

Epoch: 6| Step: 7
Training loss: 0.9601014384679009
Validation loss: 2.576850770623193

Epoch: 6| Step: 8
Training loss: 1.4811840895784896
Validation loss: 2.5982811839074595

Epoch: 6| Step: 9
Training loss: 0.762447106762498
Validation loss: 2.581521483197191

Epoch: 6| Step: 10
Training loss: 0.8684550120704382
Validation loss: 2.5940057544658184

Epoch: 6| Step: 11
Training loss: 0.6928297787285232
Validation loss: 2.602562144175067

Epoch: 6| Step: 12
Training loss: 1.1246413082930178
Validation loss: 2.616746594300572

Epoch: 6| Step: 13
Training loss: 1.2119266039055705
Validation loss: 2.609127187895513

Epoch: 301| Step: 0
Training loss: 0.7969702121476048
Validation loss: 2.603787088274607

Epoch: 6| Step: 1
Training loss: 0.9147886016928725
Validation loss: 2.606284301812227

Epoch: 6| Step: 2
Training loss: 0.8383838473459339
Validation loss: 2.636244183867885

Epoch: 6| Step: 3
Training loss: 1.4148847181180397
Validation loss: 2.562786428439106

Epoch: 6| Step: 4
Training loss: 1.0232613098839216
Validation loss: 2.604633734051487

Epoch: 6| Step: 5
Training loss: 0.945120263848498
Validation loss: 2.593876562429545

Epoch: 6| Step: 6
Training loss: 0.902785057054826
Validation loss: 2.5440898800728604

Epoch: 6| Step: 7
Training loss: 1.1714810535756517
Validation loss: 2.6098743737277412

Epoch: 6| Step: 8
Training loss: 0.45241301604134443
Validation loss: 2.5916438580055923

Epoch: 6| Step: 9
Training loss: 0.5599831062135836
Validation loss: 2.6288024143630824

Epoch: 6| Step: 10
Training loss: 0.9759644164649706
Validation loss: 2.6456144634938665

Epoch: 6| Step: 11
Training loss: 0.6586860673488691
Validation loss: 2.5974959242655515

Epoch: 6| Step: 12
Training loss: 0.9086942923785439
Validation loss: 2.605824225451474

Epoch: 6| Step: 13
Training loss: 0.9002878126250617
Validation loss: 2.6206333994692232

Epoch: 302| Step: 0
Training loss: 0.7707365250153497
Validation loss: 2.6098917375231863

Epoch: 6| Step: 1
Training loss: 1.014320357208875
Validation loss: 2.6129401491552415

Epoch: 6| Step: 2
Training loss: 0.851286327130286
Validation loss: 2.590836676952111

Epoch: 6| Step: 3
Training loss: 0.6155481174309755
Validation loss: 2.610957812610136

Epoch: 6| Step: 4
Training loss: 0.7101618129734757
Validation loss: 2.57592984463501

Epoch: 6| Step: 5
Training loss: 1.4124924178468548
Validation loss: 2.581112537886729

Epoch: 6| Step: 6
Training loss: 1.000828399857795
Validation loss: 2.609609114792183

Epoch: 6| Step: 7
Training loss: 0.7464528842194447
Validation loss: 2.5908712064183144

Epoch: 6| Step: 8
Training loss: 0.971282509759231
Validation loss: 2.624410755532531

Epoch: 6| Step: 9
Training loss: 0.8085606148974914
Validation loss: 2.6035100068783774

Epoch: 6| Step: 10
Training loss: 0.7682394813664116
Validation loss: 2.617561641980046

Epoch: 6| Step: 11
Training loss: 0.9783359141751701
Validation loss: 2.5924141828404728

Epoch: 6| Step: 12
Training loss: 0.9336882028723255
Validation loss: 2.609551612222262

Epoch: 6| Step: 13
Training loss: 1.0010531959041777
Validation loss: 2.5918676961987797

Epoch: 303| Step: 0
Training loss: 1.0736047828184037
Validation loss: 2.6031847899768805

Epoch: 6| Step: 1
Training loss: 0.948609333089413
Validation loss: 2.6221290227231173

Epoch: 6| Step: 2
Training loss: 0.9791150722032005
Validation loss: 2.574768522574657

Epoch: 6| Step: 3
Training loss: 0.9077251201866684
Validation loss: 2.5856777440274117

Epoch: 6| Step: 4
Training loss: 0.6602986424838434
Validation loss: 2.600341157404599

Epoch: 6| Step: 5
Training loss: 0.9019200044269605
Validation loss: 2.585097518993201

Epoch: 6| Step: 6
Training loss: 1.457885164696583
Validation loss: 2.59812906289111

Epoch: 6| Step: 7
Training loss: 0.7198193100857765
Validation loss: 2.5873971216469758

Epoch: 6| Step: 8
Training loss: 1.0203067563232644
Validation loss: 2.6073991116460347

Epoch: 6| Step: 9
Training loss: 0.5112810665475593
Validation loss: 2.59478307166425

Epoch: 6| Step: 10
Training loss: 0.705497469058725
Validation loss: 2.5819290928027345

Epoch: 6| Step: 11
Training loss: 0.8880141286885864
Validation loss: 2.616211363759049

Epoch: 6| Step: 12
Training loss: 0.7492202042773376
Validation loss: 2.5923313452468784

Epoch: 6| Step: 13
Training loss: 0.7582400187694776
Validation loss: 2.540150463669034

Epoch: 304| Step: 0
Training loss: 1.5666619375171031
Validation loss: 2.608091153853463

Epoch: 6| Step: 1
Training loss: 0.9166596188418786
Validation loss: 2.60068136647177

Epoch: 6| Step: 2
Training loss: 0.6360731069335066
Validation loss: 2.6037380074080954

Epoch: 6| Step: 3
Training loss: 0.9558006627142988
Validation loss: 2.6057033594005037

Epoch: 6| Step: 4
Training loss: 0.69323181268391
Validation loss: 2.5828587502659976

Epoch: 6| Step: 5
Training loss: 0.9760617612699283
Validation loss: 2.6097953447503643

Epoch: 6| Step: 6
Training loss: 0.7767706056826166
Validation loss: 2.5913537000458335

Epoch: 6| Step: 7
Training loss: 0.6542138801431722
Validation loss: 2.5569520343883996

Epoch: 6| Step: 8
Training loss: 1.0647327300850116
Validation loss: 2.588478326450668

Epoch: 6| Step: 9
Training loss: 0.914679164398862
Validation loss: 2.548194321587654

Epoch: 6| Step: 10
Training loss: 0.712348376420367
Validation loss: 2.532641049996767

Epoch: 6| Step: 11
Training loss: 0.8195730600519635
Validation loss: 2.531267725898785

Epoch: 6| Step: 12
Training loss: 0.6783460775282627
Validation loss: 2.527094300067933

Epoch: 6| Step: 13
Training loss: 0.8137927408317904
Validation loss: 2.5029624276274456

Epoch: 305| Step: 0
Training loss: 0.9560430290282842
Validation loss: 2.5214109851336093

Epoch: 6| Step: 1
Training loss: 0.9245570011237132
Validation loss: 2.5036824198501724

Epoch: 6| Step: 2
Training loss: 0.6473759614120095
Validation loss: 2.518964816504806

Epoch: 6| Step: 3
Training loss: 1.0263079509101147
Validation loss: 2.481320419132623

Epoch: 6| Step: 4
Training loss: 0.9548355761880268
Validation loss: 2.5205163999683293

Epoch: 6| Step: 5
Training loss: 0.7256150169244396
Validation loss: 2.5333557464966048

Epoch: 6| Step: 6
Training loss: 0.36432004913372257
Validation loss: 2.5075975398224086

Epoch: 6| Step: 7
Training loss: 1.1690990885433996
Validation loss: 2.520686708147376

Epoch: 6| Step: 8
Training loss: 0.8978020120573112
Validation loss: 2.532711847098952

Epoch: 6| Step: 9
Training loss: 0.9028105085911481
Validation loss: 2.5834468531467643

Epoch: 6| Step: 10
Training loss: 0.7817330964849926
Validation loss: 2.5662303986743904

Epoch: 6| Step: 11
Training loss: 0.6932653014072605
Validation loss: 2.5572911802954343

Epoch: 6| Step: 12
Training loss: 1.2918510561764849
Validation loss: 2.5672770946378676

Epoch: 6| Step: 13
Training loss: 0.4577900220280642
Validation loss: 2.5631540365702055

Epoch: 306| Step: 0
Training loss: 0.5754501995625598
Validation loss: 2.6056807010651553

Epoch: 6| Step: 1
Training loss: 1.302636001281289
Validation loss: 2.593202816151848

Epoch: 6| Step: 2
Training loss: 0.7997324332179815
Validation loss: 2.6104163251708883

Epoch: 6| Step: 3
Training loss: 0.7819190403086684
Validation loss: 2.5522417087563913

Epoch: 6| Step: 4
Training loss: 1.0519059412502958
Validation loss: 2.5647833750629805

Epoch: 6| Step: 5
Training loss: 0.7657643016285436
Validation loss: 2.587522632007879

Epoch: 6| Step: 6
Training loss: 0.561113396908518
Validation loss: 2.5588891505182243

Epoch: 6| Step: 7
Training loss: 1.1323392734620703
Validation loss: 2.5092898034335924

Epoch: 6| Step: 8
Training loss: 0.8883427607863305
Validation loss: 2.4393508295790314

Epoch: 6| Step: 9
Training loss: 0.751576435808501
Validation loss: 2.4163930467183388

Epoch: 6| Step: 10
Training loss: 1.0418407040485147
Validation loss: 2.4372942858464777

Epoch: 6| Step: 11
Training loss: 1.306151613609609
Validation loss: 2.4362440331080384

Epoch: 6| Step: 12
Training loss: 0.9138487215371605
Validation loss: 2.4508441913396837

Epoch: 6| Step: 13
Training loss: 0.7774408557757166
Validation loss: 2.4282891998896416

Epoch: 307| Step: 0
Training loss: 1.3811231736174456
Validation loss: 2.465129151332548

Epoch: 6| Step: 1
Training loss: 0.7118340173835775
Validation loss: 2.5040440716229573

Epoch: 6| Step: 2
Training loss: 1.0138760105749303
Validation loss: 2.522141412058089

Epoch: 6| Step: 3
Training loss: 0.539375021084711
Validation loss: 2.5549005205926325

Epoch: 6| Step: 4
Training loss: 0.6369982848855469
Validation loss: 2.54417524062571

Epoch: 6| Step: 5
Training loss: 1.1679609929978616
Validation loss: 2.584808964863199

Epoch: 6| Step: 6
Training loss: 0.9777790883867072
Validation loss: 2.631304633637535

Epoch: 6| Step: 7
Training loss: 0.6481360688547257
Validation loss: 2.6634501447895045

Epoch: 6| Step: 8
Training loss: 0.8264258605280476
Validation loss: 2.6451150101390484

Epoch: 6| Step: 9
Training loss: 0.9492289224715341
Validation loss: 2.623600191501812

Epoch: 6| Step: 10
Training loss: 0.9401696658718629
Validation loss: 2.6319486780150885

Epoch: 6| Step: 11
Training loss: 1.1824100227883543
Validation loss: 2.652564608677289

Epoch: 6| Step: 12
Training loss: 0.7182727556139202
Validation loss: 2.6028409540875

Epoch: 6| Step: 13
Training loss: 0.7586661574343004
Validation loss: 2.5754550128412412

Epoch: 308| Step: 0
Training loss: 0.7854763156760987
Validation loss: 2.5531809780416403

Epoch: 6| Step: 1
Training loss: 0.7461334138083647
Validation loss: 2.5508497848591545

Epoch: 6| Step: 2
Training loss: 0.8362939377718841
Validation loss: 2.529357856208258

Epoch: 6| Step: 3
Training loss: 0.7084377483002338
Validation loss: 2.5602960250055142

Epoch: 6| Step: 4
Training loss: 0.8147736794471134
Validation loss: 2.5609369060136244

Epoch: 6| Step: 5
Training loss: 0.5193337947231703
Validation loss: 2.559814213642566

Epoch: 6| Step: 6
Training loss: 1.0730436799259062
Validation loss: 2.5558447102069133

Epoch: 6| Step: 7
Training loss: 1.2392076462616277
Validation loss: 2.516568695222627

Epoch: 6| Step: 8
Training loss: 0.9549562653418573
Validation loss: 2.5929716256607547

Epoch: 6| Step: 9
Training loss: 0.7233262950874152
Validation loss: 2.5679590955211764

Epoch: 6| Step: 10
Training loss: 1.2424544041670185
Validation loss: 2.5517909528960385

Epoch: 6| Step: 11
Training loss: 1.013932916622999
Validation loss: 2.5927714500839083

Epoch: 6| Step: 12
Training loss: 0.37251885478413754
Validation loss: 2.580844028042188

Epoch: 6| Step: 13
Training loss: 0.5642846988070424
Validation loss: 2.572604833342543

Epoch: 309| Step: 0
Training loss: 0.7680002076079168
Validation loss: 2.552252271701524

Epoch: 6| Step: 1
Training loss: 0.7781592457294152
Validation loss: 2.5504718805161586

Epoch: 6| Step: 2
Training loss: 0.817408334568319
Validation loss: 2.5420327618052307

Epoch: 6| Step: 3
Training loss: 1.0024157194255243
Validation loss: 2.5001329581478022

Epoch: 6| Step: 4
Training loss: 0.7141995471683713
Validation loss: 2.4998649940133553

Epoch: 6| Step: 5
Training loss: 0.9261957842034639
Validation loss: 2.489255143045652

Epoch: 6| Step: 6
Training loss: 0.4594403700476197
Validation loss: 2.452466718726715

Epoch: 6| Step: 7
Training loss: 0.7689041835956368
Validation loss: 2.5033216948655337

Epoch: 6| Step: 8
Training loss: 0.7109491535950356
Validation loss: 2.441455727615242

Epoch: 6| Step: 9
Training loss: 0.9075818305519904
Validation loss: 2.430832134943166

Epoch: 6| Step: 10
Training loss: 1.0788792722120437
Validation loss: 2.4244648931547577

Epoch: 6| Step: 11
Training loss: 1.0036367804305903
Validation loss: 2.4120789983200974

Epoch: 6| Step: 12
Training loss: 0.7934423075556984
Validation loss: 2.429315140765081

Epoch: 6| Step: 13
Training loss: 0.9403420285640215
Validation loss: 2.4600258707313043

Epoch: 310| Step: 0
Training loss: 0.800739901335769
Validation loss: 2.4369996574643618

Epoch: 6| Step: 1
Training loss: 0.6112891236560613
Validation loss: 2.461983472796464

Epoch: 6| Step: 2
Training loss: 1.0375597994013064
Validation loss: 2.472012126958438

Epoch: 6| Step: 3
Training loss: 0.9371087847473651
Validation loss: 2.5146307514515334

Epoch: 6| Step: 4
Training loss: 0.935761874984496
Validation loss: 2.5219885134347595

Epoch: 6| Step: 5
Training loss: 0.7954003021397927
Validation loss: 2.508822631521938

Epoch: 6| Step: 6
Training loss: 0.5471776125029284
Validation loss: 2.5686345197924214

Epoch: 6| Step: 7
Training loss: 0.9012463324335951
Validation loss: 2.531582654886972

Epoch: 6| Step: 8
Training loss: 0.6693648533270229
Validation loss: 2.5539845637284615

Epoch: 6| Step: 9
Training loss: 0.7843823390784528
Validation loss: 2.565446611633529

Epoch: 6| Step: 10
Training loss: 0.8532146909747341
Validation loss: 2.559180176390664

Epoch: 6| Step: 11
Training loss: 0.6873821244190568
Validation loss: 2.5105920618958266

Epoch: 6| Step: 12
Training loss: 1.0544461574636554
Validation loss: 2.5345187960532467

Epoch: 6| Step: 13
Training loss: 0.8433106656163065
Validation loss: 2.557503155036853

Epoch: 311| Step: 0
Training loss: 0.7612177839806671
Validation loss: 2.536597685430681

Epoch: 6| Step: 1
Training loss: 0.6264934340008855
Validation loss: 2.5476343917800803

Epoch: 6| Step: 2
Training loss: 1.041939159356064
Validation loss: 2.51990731286489

Epoch: 6| Step: 3
Training loss: 0.8091395650607904
Validation loss: 2.5426461584908506

Epoch: 6| Step: 4
Training loss: 1.1310044164326833
Validation loss: 2.5199463342361836

Epoch: 6| Step: 5
Training loss: 0.29618499276008997
Validation loss: 2.483082259604144

Epoch: 6| Step: 6
Training loss: 0.6819727615848865
Validation loss: 2.5255792057246453

Epoch: 6| Step: 7
Training loss: 0.9648215719909634
Validation loss: 2.5022132859118766

Epoch: 6| Step: 8
Training loss: 0.6038646244444033
Validation loss: 2.5269614101935916

Epoch: 6| Step: 9
Training loss: 1.0916288243109598
Validation loss: 2.492300170857376

Epoch: 6| Step: 10
Training loss: 0.7071650257323814
Validation loss: 2.506941523890307

Epoch: 6| Step: 11
Training loss: 0.5151173664815032
Validation loss: 2.498255886279124

Epoch: 6| Step: 12
Training loss: 0.8399126601225965
Validation loss: 2.480505092807748

Epoch: 6| Step: 13
Training loss: 0.638103033466718
Validation loss: 2.48395234295494

Epoch: 312| Step: 0
Training loss: 0.7552616407500545
Validation loss: 2.485088632600429

Epoch: 6| Step: 1
Training loss: 0.6813735876059988
Validation loss: 2.4688459361885635

Epoch: 6| Step: 2
Training loss: 0.7313986993867295
Validation loss: 2.504740327837552

Epoch: 6| Step: 3
Training loss: 1.3517105815227466
Validation loss: 2.5325387479171244

Epoch: 6| Step: 4
Training loss: 0.7404495771911885
Validation loss: 2.5131906644033783

Epoch: 6| Step: 5
Training loss: 0.9516280879826553
Validation loss: 2.5071936343292225

Epoch: 6| Step: 6
Training loss: 0.6258614087527103
Validation loss: 2.5488206251555283

Epoch: 6| Step: 7
Training loss: 0.5593739642767668
Validation loss: 2.5029411867951827

Epoch: 6| Step: 8
Training loss: 0.8833084738730118
Validation loss: 2.4920326858861643

Epoch: 6| Step: 9
Training loss: 0.685871145388793
Validation loss: 2.5270743901621913

Epoch: 6| Step: 10
Training loss: 0.7226603739852767
Validation loss: 2.5202987464745314

Epoch: 6| Step: 11
Training loss: 0.7545704263109522
Validation loss: 2.5033204086011787

Epoch: 6| Step: 12
Training loss: 0.79737718503455
Validation loss: 2.5336987677385783

Epoch: 6| Step: 13
Training loss: 0.6365793695775444
Validation loss: 2.495333502241989

Epoch: 313| Step: 0
Training loss: 0.6467537678806772
Validation loss: 2.5203576862554766

Epoch: 6| Step: 1
Training loss: 0.5707508127287777
Validation loss: 2.5085020341833015

Epoch: 6| Step: 2
Training loss: 0.9018038831496501
Validation loss: 2.4422034516226026

Epoch: 6| Step: 3
Training loss: 0.7451647422084248
Validation loss: 2.459373657227864

Epoch: 6| Step: 4
Training loss: 0.9534758250467966
Validation loss: 2.456029764456411

Epoch: 6| Step: 5
Training loss: 0.6932190659090701
Validation loss: 2.489881766294074

Epoch: 6| Step: 6
Training loss: 0.7338582107580519
Validation loss: 2.469407720505856

Epoch: 6| Step: 7
Training loss: 0.8021589383909468
Validation loss: 2.4413522675483526

Epoch: 6| Step: 8
Training loss: 0.8872574837531049
Validation loss: 2.451370687331084

Epoch: 6| Step: 9
Training loss: 1.0386475616513133
Validation loss: 2.487869763132254

Epoch: 6| Step: 10
Training loss: 0.7996018074396877
Validation loss: 2.477906259766686

Epoch: 6| Step: 11
Training loss: 0.9481289734125332
Validation loss: 2.496394682311748

Epoch: 6| Step: 12
Training loss: 0.7443788002102926
Validation loss: 2.4917303650960383

Epoch: 6| Step: 13
Training loss: 0.543795196803319
Validation loss: 2.5108243495237974

Epoch: 314| Step: 0
Training loss: 0.9313693501330931
Validation loss: 2.4958168564464382

Epoch: 6| Step: 1
Training loss: 0.6933300173279742
Validation loss: 2.53807283182748

Epoch: 6| Step: 2
Training loss: 0.6867570764394367
Validation loss: 2.5149564002948512

Epoch: 6| Step: 3
Training loss: 0.6345599031871456
Validation loss: 2.509648673593904

Epoch: 6| Step: 4
Training loss: 0.839005020417571
Validation loss: 2.547244660847756

Epoch: 6| Step: 5
Training loss: 0.7799124903373638
Validation loss: 2.5192797504222555

Epoch: 6| Step: 6
Training loss: 0.9779099590611632
Validation loss: 2.5205931641056147

Epoch: 6| Step: 7
Training loss: 0.891105120895855
Validation loss: 2.4966156694220865

Epoch: 6| Step: 8
Training loss: 0.5475031378843364
Validation loss: 2.5110219131291585

Epoch: 6| Step: 9
Training loss: 0.775582008861005
Validation loss: 2.453847756322187

Epoch: 6| Step: 10
Training loss: 0.7503390340629449
Validation loss: 2.4868387275518864

Epoch: 6| Step: 11
Training loss: 0.8323850998615894
Validation loss: 2.432336139177962

Epoch: 6| Step: 12
Training loss: 0.7780107866289663
Validation loss: 2.4369481495117093

Epoch: 6| Step: 13
Training loss: 0.6208761541802447
Validation loss: 2.4567373972474447

Epoch: 315| Step: 0
Training loss: 0.5181983542427598
Validation loss: 2.4470506377620156

Epoch: 6| Step: 1
Training loss: 0.7851487723986084
Validation loss: 2.4659134600190398

Epoch: 6| Step: 2
Training loss: 1.0431444684423778
Validation loss: 2.5162404878787417

Epoch: 6| Step: 3
Training loss: 0.5130888672720705
Validation loss: 2.4553072870863843

Epoch: 6| Step: 4
Training loss: 0.6914788762973957
Validation loss: 2.4503017503402864

Epoch: 6| Step: 5
Training loss: 0.42186998434970574
Validation loss: 2.477024124240856

Epoch: 6| Step: 6
Training loss: 0.9058083082694461
Validation loss: 2.457828958730295

Epoch: 6| Step: 7
Training loss: 0.9515239212910002
Validation loss: 2.456731637041688

Epoch: 6| Step: 8
Training loss: 0.9992571992612418
Validation loss: 2.4846098124520224

Epoch: 6| Step: 9
Training loss: 0.726902010769227
Validation loss: 2.4734350516108847

Epoch: 6| Step: 10
Training loss: 0.9487254112686061
Validation loss: 2.477034956191971

Epoch: 6| Step: 11
Training loss: 0.7109721248704723
Validation loss: 2.50391751546749

Epoch: 6| Step: 12
Training loss: 0.5736635339528753
Validation loss: 2.462999413015547

Epoch: 6| Step: 13
Training loss: 0.6030045107329584
Validation loss: 2.4597777295919823

Epoch: 316| Step: 0
Training loss: 0.5525978647700258
Validation loss: 2.502972890243292

Epoch: 6| Step: 1
Training loss: 0.5313766552906731
Validation loss: 2.5004597487251115

Epoch: 6| Step: 2
Training loss: 0.6049042562120903
Validation loss: 2.516249628873855

Epoch: 6| Step: 3
Training loss: 0.6584920956318985
Validation loss: 2.497410068464763

Epoch: 6| Step: 4
Training loss: 0.7392043544131169
Validation loss: 2.507367129527369

Epoch: 6| Step: 5
Training loss: 0.7333256143105898
Validation loss: 2.4618713430129513

Epoch: 6| Step: 6
Training loss: 0.9353614256986591
Validation loss: 2.445956927380271

Epoch: 6| Step: 7
Training loss: 0.5592995299675786
Validation loss: 2.4338215622042667

Epoch: 6| Step: 8
Training loss: 0.7206144614329962
Validation loss: 2.4838436293938675

Epoch: 6| Step: 9
Training loss: 1.055506296570039
Validation loss: 2.439306424350915

Epoch: 6| Step: 10
Training loss: 0.8670382671996867
Validation loss: 2.443512197597647

Epoch: 6| Step: 11
Training loss: 0.9088908555168362
Validation loss: 2.46999643350375

Epoch: 6| Step: 12
Training loss: 0.9619505589721331
Validation loss: 2.48702782663474

Epoch: 6| Step: 13
Training loss: 0.333745982881723
Validation loss: 2.5026193607023557

Epoch: 317| Step: 0
Training loss: 0.7499746477292638
Validation loss: 2.4771768652798207

Epoch: 6| Step: 1
Training loss: 0.3395864565048448
Validation loss: 2.5421538258457588

Epoch: 6| Step: 2
Training loss: 0.5641235128358172
Validation loss: 2.5477943333958732

Epoch: 6| Step: 3
Training loss: 0.9672890691471052
Validation loss: 2.5137196293509443

Epoch: 6| Step: 4
Training loss: 0.7371146456111041
Validation loss: 2.527694256629611

Epoch: 6| Step: 5
Training loss: 0.5387826275958068
Validation loss: 2.5236519541098685

Epoch: 6| Step: 6
Training loss: 0.7167320118174686
Validation loss: 2.5676316352153363

Epoch: 6| Step: 7
Training loss: 0.7428903163259781
Validation loss: 2.5492436532132867

Epoch: 6| Step: 8
Training loss: 0.7554083372969478
Validation loss: 2.5238169281318044

Epoch: 6| Step: 9
Training loss: 0.8074925244578793
Validation loss: 2.506261256405467

Epoch: 6| Step: 10
Training loss: 0.8373812036097995
Validation loss: 2.5397455576128505

Epoch: 6| Step: 11
Training loss: 0.8402863511698142
Validation loss: 2.555191706283214

Epoch: 6| Step: 12
Training loss: 0.7764003530651864
Validation loss: 2.4847084874643195

Epoch: 6| Step: 13
Training loss: 0.8523210419340588
Validation loss: 2.5183823132121215

Epoch: 318| Step: 0
Training loss: 0.6794759486912347
Validation loss: 2.4630961570865453

Epoch: 6| Step: 1
Training loss: 0.6446317189835289
Validation loss: 2.4771976139863696

Epoch: 6| Step: 2
Training loss: 0.7320278074006481
Validation loss: 2.466638990929861

Epoch: 6| Step: 3
Training loss: 0.8936704133351362
Validation loss: 2.4752224922959214

Epoch: 6| Step: 4
Training loss: 0.6703439611774532
Validation loss: 2.498717730348048

Epoch: 6| Step: 5
Training loss: 0.7368272460787296
Validation loss: 2.452955112723457

Epoch: 6| Step: 6
Training loss: 0.8658650254833872
Validation loss: 2.48057234895521

Epoch: 6| Step: 7
Training loss: 0.5675478513012069
Validation loss: 2.488470423872573

Epoch: 6| Step: 8
Training loss: 0.9346874645951193
Validation loss: 2.5123464306920105

Epoch: 6| Step: 9
Training loss: 0.45012228946563554
Validation loss: 2.522314814668091

Epoch: 6| Step: 10
Training loss: 0.8164643627455793
Validation loss: 2.561725504414687

Epoch: 6| Step: 11
Training loss: 0.5003944569544465
Validation loss: 2.529911146483137

Epoch: 6| Step: 12
Training loss: 0.8111256934151381
Validation loss: 2.539303329569428

Epoch: 6| Step: 13
Training loss: 0.8691944919995368
Validation loss: 2.5155681383813087

Epoch: 319| Step: 0
Training loss: 0.5318331322961991
Validation loss: 2.506706054280303

Epoch: 6| Step: 1
Training loss: 0.892549476748095
Validation loss: 2.5043625729908334

Epoch: 6| Step: 2
Training loss: 0.44967782156617836
Validation loss: 2.506622136213473

Epoch: 6| Step: 3
Training loss: 0.5986142925739443
Validation loss: 2.4812316894268913

Epoch: 6| Step: 4
Training loss: 0.8205932863242081
Validation loss: 2.483938509931448

Epoch: 6| Step: 5
Training loss: 0.9458706996835597
Validation loss: 2.4814434859361465

Epoch: 6| Step: 6
Training loss: 0.6668092133196739
Validation loss: 2.4473343246616217

Epoch: 6| Step: 7
Training loss: 1.015392100700051
Validation loss: 2.461866385196861

Epoch: 6| Step: 8
Training loss: 0.8619715564464828
Validation loss: 2.459155914050395

Epoch: 6| Step: 9
Training loss: 0.525638847849046
Validation loss: 2.4968047806556077

Epoch: 6| Step: 10
Training loss: 0.5785825568302964
Validation loss: 2.474147873220092

Epoch: 6| Step: 11
Training loss: 0.8006031861858639
Validation loss: 2.485994379405779

Epoch: 6| Step: 12
Training loss: 0.574944329676644
Validation loss: 2.504282406068927

Epoch: 6| Step: 13
Training loss: 0.5598104604053811
Validation loss: 2.5004756423746084

Epoch: 320| Step: 0
Training loss: 0.5729381008184575
Validation loss: 2.5036794841895023

Epoch: 6| Step: 1
Training loss: 0.7914305552358882
Validation loss: 2.50355651818077

Epoch: 6| Step: 2
Training loss: 1.0060911633724416
Validation loss: 2.506430703365737

Epoch: 6| Step: 3
Training loss: 0.7950042007143373
Validation loss: 2.508184277195909

Epoch: 6| Step: 4
Training loss: 0.2463808579868587
Validation loss: 2.4782663663136106

Epoch: 6| Step: 5
Training loss: 0.7717026027636045
Validation loss: 2.4787564145452206

Epoch: 6| Step: 6
Training loss: 0.4710154783090808
Validation loss: 2.510739941147527

Epoch: 6| Step: 7
Training loss: 0.7988013377280154
Validation loss: 2.518036528433408

Epoch: 6| Step: 8
Training loss: 0.8032977129991634
Validation loss: 2.4998362467059323

Epoch: 6| Step: 9
Training loss: 0.6493329678719815
Validation loss: 2.470473572965717

Epoch: 6| Step: 10
Training loss: 0.5499163932543335
Validation loss: 2.5641585394371367

Epoch: 6| Step: 11
Training loss: 0.8312345460301298
Validation loss: 2.5284772138931246

Epoch: 6| Step: 12
Training loss: 0.9258619506686806
Validation loss: 2.5637969989818172

Epoch: 6| Step: 13
Training loss: 0.706950082914662
Validation loss: 2.532903364487835

Epoch: 321| Step: 0
Training loss: 0.7433573688233447
Validation loss: 2.5137821194401173

Epoch: 6| Step: 1
Training loss: 0.912867718900132
Validation loss: 2.518292758658465

Epoch: 6| Step: 2
Training loss: 0.8042150795813731
Validation loss: 2.5319435691662853

Epoch: 6| Step: 3
Training loss: 0.6341029537526175
Validation loss: 2.4837041397840465

Epoch: 6| Step: 4
Training loss: 0.46017561193381873
Validation loss: 2.5052030308021593

Epoch: 6| Step: 5
Training loss: 0.5870965302687257
Validation loss: 2.5126491803347326

Epoch: 6| Step: 6
Training loss: 0.7749774898828573
Validation loss: 2.4795339365219378

Epoch: 6| Step: 7
Training loss: 0.7101009603365211
Validation loss: 2.508403408042109

Epoch: 6| Step: 8
Training loss: 0.8006546292566081
Validation loss: 2.4953743102289554

Epoch: 6| Step: 9
Training loss: 0.797990653755315
Validation loss: 2.528294559561915

Epoch: 6| Step: 10
Training loss: 0.6764879665770624
Validation loss: 2.5126120821746025

Epoch: 6| Step: 11
Training loss: 0.8784968121839338
Validation loss: 2.516390686560596

Epoch: 6| Step: 12
Training loss: 0.551304940234461
Validation loss: 2.572398332091833

Epoch: 6| Step: 13
Training loss: 0.629904150786216
Validation loss: 2.5355522240522266

Epoch: 322| Step: 0
Training loss: 0.7450167487009128
Validation loss: 2.547361322311339

Epoch: 6| Step: 1
Training loss: 0.6515491694635
Validation loss: 2.5267269123973124

Epoch: 6| Step: 2
Training loss: 0.9467939323242953
Validation loss: 2.5553159015823814

Epoch: 6| Step: 3
Training loss: 0.8269080451134786
Validation loss: 2.5226137170416814

Epoch: 6| Step: 4
Training loss: 0.6403571243337799
Validation loss: 2.5313916356000212

Epoch: 6| Step: 5
Training loss: 0.7007697394711101
Validation loss: 2.512763916906381

Epoch: 6| Step: 6
Training loss: 0.6362982221289891
Validation loss: 2.4921298433605523

Epoch: 6| Step: 7
Training loss: 0.6937444772586429
Validation loss: 2.509906736581905

Epoch: 6| Step: 8
Training loss: 0.6124570374115575
Validation loss: 2.500017096348213

Epoch: 6| Step: 9
Training loss: 0.5169584199133539
Validation loss: 2.435724110548312

Epoch: 6| Step: 10
Training loss: 0.6301990750055719
Validation loss: 2.4604775129909315

Epoch: 6| Step: 11
Training loss: 0.8293395582616592
Validation loss: 2.446111052864698

Epoch: 6| Step: 12
Training loss: 0.7760649470649916
Validation loss: 2.454107733151788

Epoch: 6| Step: 13
Training loss: 0.3197575040932883
Validation loss: 2.43627551643546

Epoch: 323| Step: 0
Training loss: 0.602714822072521
Validation loss: 2.4722075834259902

Epoch: 6| Step: 1
Training loss: 0.38464973369684874
Validation loss: 2.465200094959213

Epoch: 6| Step: 2
Training loss: 0.6566132947690693
Validation loss: 2.4271418088096914

Epoch: 6| Step: 3
Training loss: 0.8147124099581329
Validation loss: 2.4996548014396893

Epoch: 6| Step: 4
Training loss: 0.4439713040424271
Validation loss: 2.487811937384322

Epoch: 6| Step: 5
Training loss: 0.6374406291392273
Validation loss: 2.5080203795429576

Epoch: 6| Step: 6
Training loss: 0.36131439182886216
Validation loss: 2.52988276694007

Epoch: 6| Step: 7
Training loss: 1.0316773887245554
Validation loss: 2.497415070433625

Epoch: 6| Step: 8
Training loss: 0.5581734416482536
Validation loss: 2.516607837631853

Epoch: 6| Step: 9
Training loss: 0.9069296820235712
Validation loss: 2.5124617086206897

Epoch: 6| Step: 10
Training loss: 0.6663201494485416
Validation loss: 2.4931827604538213

Epoch: 6| Step: 11
Training loss: 0.7438553791564225
Validation loss: 2.5076816440233634

Epoch: 6| Step: 12
Training loss: 0.8480833181934918
Validation loss: 2.5121076060827146

Epoch: 6| Step: 13
Training loss: 0.9320572215552192
Validation loss: 2.46712200858725

Epoch: 324| Step: 0
Training loss: 0.6945427909724651
Validation loss: 2.5230324266175406

Epoch: 6| Step: 1
Training loss: 0.7425441085994756
Validation loss: 2.54168953743228

Epoch: 6| Step: 2
Training loss: 0.7769478407920324
Validation loss: 2.500653881781083

Epoch: 6| Step: 3
Training loss: 0.6228003656992025
Validation loss: 2.5358266480787175

Epoch: 6| Step: 4
Training loss: 0.7639937246998615
Validation loss: 2.5081458527143

Epoch: 6| Step: 5
Training loss: 0.8649050944970075
Validation loss: 2.4759639204107047

Epoch: 6| Step: 6
Training loss: 0.5625328213335097
Validation loss: 2.478470279927823

Epoch: 6| Step: 7
Training loss: 0.5994573642755316
Validation loss: 2.447892835645502

Epoch: 6| Step: 8
Training loss: 0.8110372875169544
Validation loss: 2.4903609584137167

Epoch: 6| Step: 9
Training loss: 0.28908056769739277
Validation loss: 2.4848447151712327

Epoch: 6| Step: 10
Training loss: 0.7033120224497758
Validation loss: 2.44622804046828

Epoch: 6| Step: 11
Training loss: 0.6861570854030776
Validation loss: 2.4487984504972165

Epoch: 6| Step: 12
Training loss: 0.8362292556014389
Validation loss: 2.46532134961632

Epoch: 6| Step: 13
Training loss: 0.7676284035869828
Validation loss: 2.459760391083949

Epoch: 325| Step: 0
Training loss: 0.8450663506117065
Validation loss: 2.4731359601782095

Epoch: 6| Step: 1
Training loss: 0.663157575779713
Validation loss: 2.462363173099897

Epoch: 6| Step: 2
Training loss: 0.8022686054881293
Validation loss: 2.4814042537474523

Epoch: 6| Step: 3
Training loss: 0.8185010254841266
Validation loss: 2.5239120093646905

Epoch: 6| Step: 4
Training loss: 0.7181107124388039
Validation loss: 2.4507204938463727

Epoch: 6| Step: 5
Training loss: 0.5677877218984183
Validation loss: 2.477330809734055

Epoch: 6| Step: 6
Training loss: 0.5973394214853471
Validation loss: 2.438290230480514

Epoch: 6| Step: 7
Training loss: 0.4873907131793859
Validation loss: 2.437648553057837

Epoch: 6| Step: 8
Training loss: 0.5715434494305931
Validation loss: 2.4503713661176265

Epoch: 6| Step: 9
Training loss: 0.9370828336174699
Validation loss: 2.4325938717651927

Epoch: 6| Step: 10
Training loss: 0.7430424634625836
Validation loss: 2.4393940643102576

Epoch: 6| Step: 11
Training loss: 0.7115203229075265
Validation loss: 2.4553485400045583

Epoch: 6| Step: 12
Training loss: 0.5639318679482673
Validation loss: 2.462794050857361

Epoch: 6| Step: 13
Training loss: 0.613149373642316
Validation loss: 2.564921829608285

Epoch: 326| Step: 0
Training loss: 0.7811531006801871
Validation loss: 2.48471879737634

Epoch: 6| Step: 1
Training loss: 0.9436207916533801
Validation loss: 2.555915798397549

Epoch: 6| Step: 2
Training loss: 0.38055348950696904
Validation loss: 2.5474256177862413

Epoch: 6| Step: 3
Training loss: 0.4420778684550964
Validation loss: 2.5479273481320113

Epoch: 6| Step: 4
Training loss: 0.837897454080562
Validation loss: 2.479604510921759

Epoch: 6| Step: 5
Training loss: 0.8514469663307553
Validation loss: 2.489907887703789

Epoch: 6| Step: 6
Training loss: 0.7567515467693147
Validation loss: 2.4663750214040134

Epoch: 6| Step: 7
Training loss: 0.7632048366565315
Validation loss: 2.421793232045878

Epoch: 6| Step: 8
Training loss: 0.5347237335805741
Validation loss: 2.4589575872977485

Epoch: 6| Step: 9
Training loss: 0.7496725400677923
Validation loss: 2.4801298703711483

Epoch: 6| Step: 10
Training loss: 0.41128866906681205
Validation loss: 2.478906243629438

Epoch: 6| Step: 11
Training loss: 0.745973747149427
Validation loss: 2.478016697700958

Epoch: 6| Step: 12
Training loss: 0.7458760208473233
Validation loss: 2.501463681050878

Epoch: 6| Step: 13
Training loss: 0.50974668270302
Validation loss: 2.4885332672755243

Epoch: 327| Step: 0
Training loss: 0.5837276749354661
Validation loss: 2.4827551808021253

Epoch: 6| Step: 1
Training loss: 0.8749442082737949
Validation loss: 2.4280332857260007

Epoch: 6| Step: 2
Training loss: 0.4484667246795869
Validation loss: 2.4385869074740847

Epoch: 6| Step: 3
Training loss: 0.6206675332621961
Validation loss: 2.451493573981719

Epoch: 6| Step: 4
Training loss: 0.6637972133533158
Validation loss: 2.4343478232935354

Epoch: 6| Step: 5
Training loss: 0.7822825665374284
Validation loss: 2.466413616944685

Epoch: 6| Step: 6
Training loss: 0.8491592091565765
Validation loss: 2.4411518506148266

Epoch: 6| Step: 7
Training loss: 0.6449413035543351
Validation loss: 2.4263872478170954

Epoch: 6| Step: 8
Training loss: 0.6118504057355182
Validation loss: 2.4176156423002757

Epoch: 6| Step: 9
Training loss: 0.6186957942454074
Validation loss: 2.425607105490791

Epoch: 6| Step: 10
Training loss: 0.3094481940335268
Validation loss: 2.4919429245903513

Epoch: 6| Step: 11
Training loss: 0.6445238979960659
Validation loss: 2.4570821804443668

Epoch: 6| Step: 12
Training loss: 1.0109524568043857
Validation loss: 2.5184155752010358

Epoch: 6| Step: 13
Training loss: 0.635384266970559
Validation loss: 2.5136424880407064

Epoch: 328| Step: 0
Training loss: 0.770104054690442
Validation loss: 2.524286531460172

Epoch: 6| Step: 1
Training loss: 0.6724930737007566
Validation loss: 2.526071487181388

Epoch: 6| Step: 2
Training loss: 0.7442466680306711
Validation loss: 2.4873367335141316

Epoch: 6| Step: 3
Training loss: 0.7614256074676962
Validation loss: 2.501405339404827

Epoch: 6| Step: 4
Training loss: 0.8140107561239657
Validation loss: 2.5416388958147267

Epoch: 6| Step: 5
Training loss: 0.4741738444250421
Validation loss: 2.494187621642956

Epoch: 6| Step: 6
Training loss: 0.7677209153474975
Validation loss: 2.4853646109432854

Epoch: 6| Step: 7
Training loss: 0.5453987086229385
Validation loss: 2.48562023521318

Epoch: 6| Step: 8
Training loss: 0.6024225947806533
Validation loss: 2.491519823753565

Epoch: 6| Step: 9
Training loss: 0.4917286899072317
Validation loss: 2.462958701993644

Epoch: 6| Step: 10
Training loss: 0.919979020791724
Validation loss: 2.480238803562777

Epoch: 6| Step: 11
Training loss: 0.626317709386174
Validation loss: 2.47510840910954

Epoch: 6| Step: 12
Training loss: 0.5882222960417457
Validation loss: 2.4931376641519565

Epoch: 6| Step: 13
Training loss: 0.5139958045617553
Validation loss: 2.507412165703865

Epoch: 329| Step: 0
Training loss: 0.7097831828874926
Validation loss: 2.497149233638629

Epoch: 6| Step: 1
Training loss: 0.4230466397074347
Validation loss: 2.5030702606336743

Epoch: 6| Step: 2
Training loss: 0.6029532074241065
Validation loss: 2.513525791475991

Epoch: 6| Step: 3
Training loss: 0.6397015498583971
Validation loss: 2.536324623452831

Epoch: 6| Step: 4
Training loss: 0.7925427800734877
Validation loss: 2.5018880687611444

Epoch: 6| Step: 5
Training loss: 0.4102595244678796
Validation loss: 2.5187559654103926

Epoch: 6| Step: 6
Training loss: 0.5781379131215286
Validation loss: 2.483406994314846

Epoch: 6| Step: 7
Training loss: 0.6507702655941393
Validation loss: 2.4728356745531364

Epoch: 6| Step: 8
Training loss: 0.6856151449004648
Validation loss: 2.472135820991731

Epoch: 6| Step: 9
Training loss: 0.7529580671253556
Validation loss: 2.4890431697565476

Epoch: 6| Step: 10
Training loss: 0.6909035185795671
Validation loss: 2.497131709055551

Epoch: 6| Step: 11
Training loss: 0.6931978279288855
Validation loss: 2.5237714919210505

Epoch: 6| Step: 12
Training loss: 1.0008127962451578
Validation loss: 2.513381553815765

Epoch: 6| Step: 13
Training loss: 0.4809036767479137
Validation loss: 2.5202355736726356

Epoch: 330| Step: 0
Training loss: 0.5979446263925831
Validation loss: 2.5323004650137366

Epoch: 6| Step: 1
Training loss: 0.752034527224405
Validation loss: 2.5118441466139014

Epoch: 6| Step: 2
Training loss: 0.7784434834927582
Validation loss: 2.521068420336806

Epoch: 6| Step: 3
Training loss: 0.5914136697160113
Validation loss: 2.5394188435713816

Epoch: 6| Step: 4
Training loss: 0.48945618222827647
Validation loss: 2.4975473575950553

Epoch: 6| Step: 5
Training loss: 0.7343021519018096
Validation loss: 2.533621933203412

Epoch: 6| Step: 6
Training loss: 0.9129643160353097
Validation loss: 2.5288349451495584

Epoch: 6| Step: 7
Training loss: 0.7289189508278101
Validation loss: 2.4920885285835825

Epoch: 6| Step: 8
Training loss: 0.5128644972898921
Validation loss: 2.486471123461017

Epoch: 6| Step: 9
Training loss: 0.49819743554723656
Validation loss: 2.45454400079678

Epoch: 6| Step: 10
Training loss: 0.7173000305586335
Validation loss: 2.484864869556096

Epoch: 6| Step: 11
Training loss: 0.500930427077746
Validation loss: 2.4888695611715397

Epoch: 6| Step: 12
Training loss: 0.7188066791908712
Validation loss: 2.497469161425242

Epoch: 6| Step: 13
Training loss: 0.4787023530312556
Validation loss: 2.483214699911554

Epoch: 331| Step: 0
Training loss: 0.5837197358007545
Validation loss: 2.515164071618602

Epoch: 6| Step: 1
Training loss: 0.7171998930880482
Validation loss: 2.5252901707349675

Epoch: 6| Step: 2
Training loss: 0.2914068165791503
Validation loss: 2.5437393438595706

Epoch: 6| Step: 3
Training loss: 0.4827155327565321
Validation loss: 2.510598596608154

Epoch: 6| Step: 4
Training loss: 0.7860073961002169
Validation loss: 2.5136914902522745

Epoch: 6| Step: 5
Training loss: 0.5231138908637738
Validation loss: 2.5509579582899597

Epoch: 6| Step: 6
Training loss: 0.9362990952926286
Validation loss: 2.5341849347957126

Epoch: 6| Step: 7
Training loss: 0.7017133741697374
Validation loss: 2.5496561605989814

Epoch: 6| Step: 8
Training loss: 0.6849936837232317
Validation loss: 2.5070355445879406

Epoch: 6| Step: 9
Training loss: 0.8004371461990372
Validation loss: 2.5294574146394333

Epoch: 6| Step: 10
Training loss: 0.6745833877302702
Validation loss: 2.484036748221637

Epoch: 6| Step: 11
Training loss: 0.6348058130307003
Validation loss: 2.4411858950035814

Epoch: 6| Step: 12
Training loss: 0.6893446407394502
Validation loss: 2.4383756307438027

Epoch: 6| Step: 13
Training loss: 0.31256944361622696
Validation loss: 2.4461148279289713

Epoch: 332| Step: 0
Training loss: 0.6952617069508368
Validation loss: 2.4081020634919414

Epoch: 6| Step: 1
Training loss: 0.4506455360949965
Validation loss: 2.471767160782069

Epoch: 6| Step: 2
Training loss: 0.5751580580869742
Validation loss: 2.478610264740739

Epoch: 6| Step: 3
Training loss: 0.6003047377855508
Validation loss: 2.4440959593531675

Epoch: 6| Step: 4
Training loss: 1.0683214365693015
Validation loss: 2.4991858017906643

Epoch: 6| Step: 5
Training loss: 0.5770422100283379
Validation loss: 2.4757498523276014

Epoch: 6| Step: 6
Training loss: 0.39329296714475287
Validation loss: 2.48972941237058

Epoch: 6| Step: 7
Training loss: 0.6832037767044021
Validation loss: 2.5000867449159756

Epoch: 6| Step: 8
Training loss: 0.693895932906618
Validation loss: 2.4988696609108922

Epoch: 6| Step: 9
Training loss: 0.6207209493911834
Validation loss: 2.4984842586643214

Epoch: 6| Step: 10
Training loss: 0.7561158132122714
Validation loss: 2.5052893724872516

Epoch: 6| Step: 11
Training loss: 0.6915936189209841
Validation loss: 2.477449763788209

Epoch: 6| Step: 12
Training loss: 0.530366611900772
Validation loss: 2.5346266509692685

Epoch: 6| Step: 13
Training loss: 0.6715110635918293
Validation loss: 2.49241473280395

Epoch: 333| Step: 0
Training loss: 0.6786945807592323
Validation loss: 2.523796785150709

Epoch: 6| Step: 1
Training loss: 0.6995817126796263
Validation loss: 2.480468705558179

Epoch: 6| Step: 2
Training loss: 0.5380282777884846
Validation loss: 2.450414803962842

Epoch: 6| Step: 3
Training loss: 0.5927813056536734
Validation loss: 2.446231222186329

Epoch: 6| Step: 4
Training loss: 0.7080285641490105
Validation loss: 2.4739298335162503

Epoch: 6| Step: 5
Training loss: 0.661444518678437
Validation loss: 2.4894416601609253

Epoch: 6| Step: 6
Training loss: 0.5830655221156423
Validation loss: 2.4679564704739243

Epoch: 6| Step: 7
Training loss: 0.9377732196680012
Validation loss: 2.4593966742606006

Epoch: 6| Step: 8
Training loss: 0.5257750738951665
Validation loss: 2.4875577420603734

Epoch: 6| Step: 9
Training loss: 0.5986631799559525
Validation loss: 2.4504643057838797

Epoch: 6| Step: 10
Training loss: 0.6911059228392976
Validation loss: 2.4489830890115307

Epoch: 6| Step: 11
Training loss: 0.7630001928946675
Validation loss: 2.4981993009662156

Epoch: 6| Step: 12
Training loss: 0.5411940738249199
Validation loss: 2.4676951258439113

Epoch: 6| Step: 13
Training loss: 0.48617998800813833
Validation loss: 2.452594358217432

Epoch: 334| Step: 0
Training loss: 0.6987290612292558
Validation loss: 2.4340763475044795

Epoch: 6| Step: 1
Training loss: 0.5132276695771084
Validation loss: 2.4548360023986495

Epoch: 6| Step: 2
Training loss: 0.6877382905851434
Validation loss: 2.4529578279523867

Epoch: 6| Step: 3
Training loss: 0.5576560145554242
Validation loss: 2.482797744372478

Epoch: 6| Step: 4
Training loss: 0.8033022020831911
Validation loss: 2.4303923651020645

Epoch: 6| Step: 5
Training loss: 0.7147104941648474
Validation loss: 2.457416414177106

Epoch: 6| Step: 6
Training loss: 0.5122833049702469
Validation loss: 2.4536916646414606

Epoch: 6| Step: 7
Training loss: 0.6529776411507782
Validation loss: 2.4637093175529947

Epoch: 6| Step: 8
Training loss: 0.6317635779240668
Validation loss: 2.4673953843483263

Epoch: 6| Step: 9
Training loss: 0.5768481149329041
Validation loss: 2.498592095120855

Epoch: 6| Step: 10
Training loss: 0.7863815009036844
Validation loss: 2.499121825506115

Epoch: 6| Step: 11
Training loss: 0.5281113018990667
Validation loss: 2.5042068223994463

Epoch: 6| Step: 12
Training loss: 0.611197021856467
Validation loss: 2.510033128643403

Epoch: 6| Step: 13
Training loss: 0.8585183816029452
Validation loss: 2.5568049534314286

Epoch: 335| Step: 0
Training loss: 0.4437315802713662
Validation loss: 2.4911560182975374

Epoch: 6| Step: 1
Training loss: 0.6274786912104078
Validation loss: 2.537940192047792

Epoch: 6| Step: 2
Training loss: 0.5827238583079253
Validation loss: 2.518263925470129

Epoch: 6| Step: 3
Training loss: 0.8156806970630786
Validation loss: 2.535291399067021

Epoch: 6| Step: 4
Training loss: 0.6365932036585648
Validation loss: 2.5052865645745515

Epoch: 6| Step: 5
Training loss: 0.902529082318427
Validation loss: 2.521930541901038

Epoch: 6| Step: 6
Training loss: 0.5635256423599266
Validation loss: 2.5495541320100994

Epoch: 6| Step: 7
Training loss: 0.7430704586717185
Validation loss: 2.538121302781724

Epoch: 6| Step: 8
Training loss: 0.8595934850216873
Validation loss: 2.5552921092126506

Epoch: 6| Step: 9
Training loss: 0.4181329636321473
Validation loss: 2.59375800200581

Epoch: 6| Step: 10
Training loss: 0.4913401500111715
Validation loss: 2.549451742362336

Epoch: 6| Step: 11
Training loss: 0.6893671430622491
Validation loss: 2.563489985323921

Epoch: 6| Step: 12
Training loss: 0.3488384463159859
Validation loss: 2.5621270349274345

Epoch: 6| Step: 13
Training loss: 0.6010133788417554
Validation loss: 2.554372631532274

Epoch: 336| Step: 0
Training loss: 0.37211892919230316
Validation loss: 2.560280360521252

Epoch: 6| Step: 1
Training loss: 0.350337160724442
Validation loss: 2.5551234383853707

Epoch: 6| Step: 2
Training loss: 0.5503026628021195
Validation loss: 2.5145810375744673

Epoch: 6| Step: 3
Training loss: 0.6274883801877612
Validation loss: 2.544746355412088

Epoch: 6| Step: 4
Training loss: 0.6299848843456588
Validation loss: 2.5347631097083236

Epoch: 6| Step: 5
Training loss: 0.7342050233910693
Validation loss: 2.5525574421853867

Epoch: 6| Step: 6
Training loss: 0.6085692237936233
Validation loss: 2.509985516600377

Epoch: 6| Step: 7
Training loss: 0.5524754001785321
Validation loss: 2.5013526897334577

Epoch: 6| Step: 8
Training loss: 0.49661683867378653
Validation loss: 2.4950280041711252

Epoch: 6| Step: 9
Training loss: 0.6623752476536421
Validation loss: 2.4721532977349363

Epoch: 6| Step: 10
Training loss: 0.8350502367954319
Validation loss: 2.463275589022249

Epoch: 6| Step: 11
Training loss: 0.9168720268196104
Validation loss: 2.434863085896977

Epoch: 6| Step: 12
Training loss: 0.6540562429188044
Validation loss: 2.4414220912624502

Epoch: 6| Step: 13
Training loss: 0.716234573877195
Validation loss: 2.4553675301050704

Epoch: 337| Step: 0
Training loss: 1.0683500578925598
Validation loss: 2.466355503824463

Epoch: 6| Step: 1
Training loss: 0.47802188858488776
Validation loss: 2.5178581470352395

Epoch: 6| Step: 2
Training loss: 0.6504730080788877
Validation loss: 2.4850139089179293

Epoch: 6| Step: 3
Training loss: 0.6232079563764162
Validation loss: 2.462430640535241

Epoch: 6| Step: 4
Training loss: 0.540318615042047
Validation loss: 2.476806510595728

Epoch: 6| Step: 5
Training loss: 0.5858388944943421
Validation loss: 2.433968036781684

Epoch: 6| Step: 6
Training loss: 0.8397097458499518
Validation loss: 2.4679947717264588

Epoch: 6| Step: 7
Training loss: 0.6494390497204754
Validation loss: 2.488086264909268

Epoch: 6| Step: 8
Training loss: 0.5855807935218929
Validation loss: 2.463696346921917

Epoch: 6| Step: 9
Training loss: 0.35997094623231163
Validation loss: 2.450444256599728

Epoch: 6| Step: 10
Training loss: 0.22645564683644298
Validation loss: 2.477669896301589

Epoch: 6| Step: 11
Training loss: 0.5305661680858912
Validation loss: 2.435247693783084

Epoch: 6| Step: 12
Training loss: 0.6050846727483618
Validation loss: 2.4449547517053336

Epoch: 6| Step: 13
Training loss: 0.5168221188562487
Validation loss: 2.4388144298610808

Epoch: 338| Step: 0
Training loss: 0.29009017750805466
Validation loss: 2.4186948604138268

Epoch: 6| Step: 1
Training loss: 0.561708104824592
Validation loss: 2.4517504983230625

Epoch: 6| Step: 2
Training loss: 0.605423341094277
Validation loss: 2.438749663504838

Epoch: 6| Step: 3
Training loss: 0.8583488580231828
Validation loss: 2.434660636400731

Epoch: 6| Step: 4
Training loss: 0.5052309588317851
Validation loss: 2.4761104609196405

Epoch: 6| Step: 5
Training loss: 0.6242583404322997
Validation loss: 2.4267851890976924

Epoch: 6| Step: 6
Training loss: 0.6486009139086001
Validation loss: 2.4893181339898867

Epoch: 6| Step: 7
Training loss: 0.5943469760758481
Validation loss: 2.4470777978107763

Epoch: 6| Step: 8
Training loss: 0.6753133134956173
Validation loss: 2.4413175612881326

Epoch: 6| Step: 9
Training loss: 0.6233688766074712
Validation loss: 2.432398273836734

Epoch: 6| Step: 10
Training loss: 0.5441013571214148
Validation loss: 2.4493731004098724

Epoch: 6| Step: 11
Training loss: 0.7459521333995458
Validation loss: 2.4844496459024605

Epoch: 6| Step: 12
Training loss: 0.4514975260152448
Validation loss: 2.459603999222385

Epoch: 6| Step: 13
Training loss: 0.5387047119311985
Validation loss: 2.4313625099718728

Epoch: 339| Step: 0
Training loss: 0.631784947031426
Validation loss: 2.439151354937163

Epoch: 6| Step: 1
Training loss: 0.9107750356805442
Validation loss: 2.467776796092166

Epoch: 6| Step: 2
Training loss: 0.47309924087044225
Validation loss: 2.4817561600331866

Epoch: 6| Step: 3
Training loss: 0.4880496887448341
Validation loss: 2.4952157624096585

Epoch: 6| Step: 4
Training loss: 0.43590915478397524
Validation loss: 2.468753642833302

Epoch: 6| Step: 5
Training loss: 0.41560380996379526
Validation loss: 2.4746681370410344

Epoch: 6| Step: 6
Training loss: 0.5790738489940034
Validation loss: 2.4164837307232045

Epoch: 6| Step: 7
Training loss: 0.47883971780494455
Validation loss: 2.473646281347448

Epoch: 6| Step: 8
Training loss: 0.5720548013581498
Validation loss: 2.4636266061070082

Epoch: 6| Step: 9
Training loss: 0.6905364691835776
Validation loss: 2.4790656147691537

Epoch: 6| Step: 10
Training loss: 0.29469816299839346
Validation loss: 2.475952147758008

Epoch: 6| Step: 11
Training loss: 0.6914429304662579
Validation loss: 2.4859207606200466

Epoch: 6| Step: 12
Training loss: 0.7189901199616995
Validation loss: 2.447586657486704

Epoch: 6| Step: 13
Training loss: 0.5780324088517731
Validation loss: 2.447860401548106

Epoch: 340| Step: 0
Training loss: 0.6871622296206331
Validation loss: 2.4441199184748017

Epoch: 6| Step: 1
Training loss: 0.5518395287421247
Validation loss: 2.4567641778527882

Epoch: 6| Step: 2
Training loss: 0.6757932452421683
Validation loss: 2.438296218248217

Epoch: 6| Step: 3
Training loss: 0.751332133114772
Validation loss: 2.4504203750077296

Epoch: 6| Step: 4
Training loss: 0.5586542483560273
Validation loss: 2.4603790467323052

Epoch: 6| Step: 5
Training loss: 0.6005797843307763
Validation loss: 2.44955414458489

Epoch: 6| Step: 6
Training loss: 0.618260308316649
Validation loss: 2.405814321171103

Epoch: 6| Step: 7
Training loss: 0.3382127582379173
Validation loss: 2.407611400538353

Epoch: 6| Step: 8
Training loss: 0.5957902188029941
Validation loss: 2.4450374200735863

Epoch: 6| Step: 9
Training loss: 0.6265978891172143
Validation loss: 2.4164289581058407

Epoch: 6| Step: 10
Training loss: 0.4409570180302667
Validation loss: 2.448076495780685

Epoch: 6| Step: 11
Training loss: 0.6339320416806449
Validation loss: 2.46300507633507

Epoch: 6| Step: 12
Training loss: 0.5490689004037603
Validation loss: 2.4386178832786967

Epoch: 6| Step: 13
Training loss: 0.22287074014055466
Validation loss: 2.466377180313029

Epoch: 341| Step: 0
Training loss: 0.23849963514731948
Validation loss: 2.4476940178575055

Epoch: 6| Step: 1
Training loss: 0.5814531771045
Validation loss: 2.486356570172122

Epoch: 6| Step: 2
Training loss: 0.43322779703011655
Validation loss: 2.4461156223476404

Epoch: 6| Step: 3
Training loss: 0.3527252572065115
Validation loss: 2.470722726522597

Epoch: 6| Step: 4
Training loss: 0.40793107746036866
Validation loss: 2.488897075506242

Epoch: 6| Step: 5
Training loss: 0.44028463745222
Validation loss: 2.4591368562526403

Epoch: 6| Step: 6
Training loss: 0.6068275708916167
Validation loss: 2.4396629675756745

Epoch: 6| Step: 7
Training loss: 0.40680810299289155
Validation loss: 2.45407710538113

Epoch: 6| Step: 8
Training loss: 0.6174330404016112
Validation loss: 2.4597243441888814

Epoch: 6| Step: 9
Training loss: 0.9489404089721722
Validation loss: 2.4147736564872657

Epoch: 6| Step: 10
Training loss: 0.6606054188723492
Validation loss: 2.4949497454807994

Epoch: 6| Step: 11
Training loss: 0.4264737368722792
Validation loss: 2.509847505412551

Epoch: 6| Step: 12
Training loss: 0.5727770086053682
Validation loss: 2.484883847646206

Epoch: 6| Step: 13
Training loss: 1.1089542289417618
Validation loss: 2.4951004706206987

Epoch: 342| Step: 0
Training loss: 0.609723065080497
Validation loss: 2.498827543457711

Epoch: 6| Step: 1
Training loss: 0.5341587097400566
Validation loss: 2.514907379915808

Epoch: 6| Step: 2
Training loss: 0.4773097355487685
Validation loss: 2.497137481812582

Epoch: 6| Step: 3
Training loss: 0.5549062109649279
Validation loss: 2.543958888764519

Epoch: 6| Step: 4
Training loss: 0.8326436327842518
Validation loss: 2.5021563223767225

Epoch: 6| Step: 5
Training loss: 0.56010243943454
Validation loss: 2.5056133623785795

Epoch: 6| Step: 6
Training loss: 0.6917495737215803
Validation loss: 2.5150728984801964

Epoch: 6| Step: 7
Training loss: 0.617893225953419
Validation loss: 2.4731078714010826

Epoch: 6| Step: 8
Training loss: 0.5925151633080794
Validation loss: 2.489976698854575

Epoch: 6| Step: 9
Training loss: 0.6010686655663461
Validation loss: 2.4822275677848444

Epoch: 6| Step: 10
Training loss: 0.26512466318953515
Validation loss: 2.492870874764886

Epoch: 6| Step: 11
Training loss: 0.45822860503836166
Validation loss: 2.4652111722907257

Epoch: 6| Step: 12
Training loss: 0.54240486998552
Validation loss: 2.4698669816411423

Epoch: 6| Step: 13
Training loss: 0.35521240213399996
Validation loss: 2.480775313472316

Epoch: 343| Step: 0
Training loss: 0.9134559575192238
Validation loss: 2.477125262351265

Epoch: 6| Step: 1
Training loss: 0.21285460106075194
Validation loss: 2.46608262820772

Epoch: 6| Step: 2
Training loss: 0.3404791362170887
Validation loss: 2.436146008011335

Epoch: 6| Step: 3
Training loss: 0.543697225267726
Validation loss: 2.437046412694019

Epoch: 6| Step: 4
Training loss: 0.7600903442291455
Validation loss: 2.4569320800859438

Epoch: 6| Step: 5
Training loss: 0.5806084979353608
Validation loss: 2.4461657645258454

Epoch: 6| Step: 6
Training loss: 0.45408249681708074
Validation loss: 2.421993962176942

Epoch: 6| Step: 7
Training loss: 0.7549875046157085
Validation loss: 2.4329086817171386

Epoch: 6| Step: 8
Training loss: 0.6594552149500571
Validation loss: 2.437871613846963

Epoch: 6| Step: 9
Training loss: 0.6865644591923828
Validation loss: 2.4853480873733944

Epoch: 6| Step: 10
Training loss: 0.4920306788489963
Validation loss: 2.47652048867421

Epoch: 6| Step: 11
Training loss: 0.4491142814900943
Validation loss: 2.4705962643432278

Epoch: 6| Step: 12
Training loss: 0.5286342513095063
Validation loss: 2.476199980827633

Epoch: 6| Step: 13
Training loss: 0.3385183864316243
Validation loss: 2.506652050366243

Epoch: 344| Step: 0
Training loss: 0.6589046102118492
Validation loss: 2.425914173494715

Epoch: 6| Step: 1
Training loss: 0.42948676535673647
Validation loss: 2.450441909984953

Epoch: 6| Step: 2
Training loss: 0.5737998628245868
Validation loss: 2.434427084469534

Epoch: 6| Step: 3
Training loss: 0.27392725000650686
Validation loss: 2.479227969234736

Epoch: 6| Step: 4
Training loss: 0.6231689333565437
Validation loss: 2.4119795776746353

Epoch: 6| Step: 5
Training loss: 0.7588247244173617
Validation loss: 2.407055247950449

Epoch: 6| Step: 6
Training loss: 0.889945189041944
Validation loss: 2.4195536348575026

Epoch: 6| Step: 7
Training loss: 0.31980174910259074
Validation loss: 2.4374006075981622

Epoch: 6| Step: 8
Training loss: 0.5271255889610671
Validation loss: 2.3767533665584133

Epoch: 6| Step: 9
Training loss: 0.527494959874956
Validation loss: 2.4317090175720044

Epoch: 6| Step: 10
Training loss: 0.4520864258790779
Validation loss: 2.4119869306551696

Epoch: 6| Step: 11
Training loss: 0.3986048253583177
Validation loss: 2.4257611172873865

Epoch: 6| Step: 12
Training loss: 0.6272997506983861
Validation loss: 2.4653704788208453

Epoch: 6| Step: 13
Training loss: 0.5089974297044532
Validation loss: 2.438562088174942

Epoch: 345| Step: 0
Training loss: 0.6118723728797631
Validation loss: 2.4578315527964416

Epoch: 6| Step: 1
Training loss: 0.23629892184574144
Validation loss: 2.412374089537689

Epoch: 6| Step: 2
Training loss: 0.5636408944713432
Validation loss: 2.412884419021743

Epoch: 6| Step: 3
Training loss: 0.5577265269812981
Validation loss: 2.4153647630618105

Epoch: 6| Step: 4
Training loss: 0.7960298207438326
Validation loss: 2.399946146535147

Epoch: 6| Step: 5
Training loss: 0.3765688503885402
Validation loss: 2.426478387157565

Epoch: 6| Step: 6
Training loss: 0.7592011931768755
Validation loss: 2.4233568993478336

Epoch: 6| Step: 7
Training loss: 0.6918586716280152
Validation loss: 2.4001152218143367

Epoch: 6| Step: 8
Training loss: 0.5093806482949726
Validation loss: 2.445013435865878

Epoch: 6| Step: 9
Training loss: 0.6516817582944765
Validation loss: 2.410204841710423

Epoch: 6| Step: 10
Training loss: 0.5980835428090938
Validation loss: 2.478558216898953

Epoch: 6| Step: 11
Training loss: 0.26424994502793303
Validation loss: 2.4051539632751413

Epoch: 6| Step: 12
Training loss: 0.49573520409304334
Validation loss: 2.476188369771435

Epoch: 6| Step: 13
Training loss: 0.39058606907441457
Validation loss: 2.4841295408566038

Epoch: 346| Step: 0
Training loss: 0.3541991228303866
Validation loss: 2.4725992960545153

Epoch: 6| Step: 1
Training loss: 0.7991651649447729
Validation loss: 2.4998625379117843

Epoch: 6| Step: 2
Training loss: 0.6859041027723897
Validation loss: 2.4997307950353598

Epoch: 6| Step: 3
Training loss: 0.6794691941026894
Validation loss: 2.4737472052042975

Epoch: 6| Step: 4
Training loss: 0.6523238310371164
Validation loss: 2.4261009858057188

Epoch: 6| Step: 5
Training loss: 0.5123318210154252
Validation loss: 2.4940028317369425

Epoch: 6| Step: 6
Training loss: 0.5386754733623128
Validation loss: 2.429507755863492

Epoch: 6| Step: 7
Training loss: 0.414083912133846
Validation loss: 2.4253281199547443

Epoch: 6| Step: 8
Training loss: 0.5908065920411
Validation loss: 2.442315046327266

Epoch: 6| Step: 9
Training loss: 0.44520805204766684
Validation loss: 2.459945868009843

Epoch: 6| Step: 10
Training loss: 0.528849676760697
Validation loss: 2.459960692595469

Epoch: 6| Step: 11
Training loss: 0.4985788234674838
Validation loss: 2.4883619530321712

Epoch: 6| Step: 12
Training loss: 0.34274591840822116
Validation loss: 2.494372158388853

Epoch: 6| Step: 13
Training loss: 0.6061376752717949
Validation loss: 2.4617630628079286

Epoch: 347| Step: 0
Training loss: 0.7286285231094928
Validation loss: 2.4653498749447755

Epoch: 6| Step: 1
Training loss: 0.6844972144265963
Validation loss: 2.463816117412137

Epoch: 6| Step: 2
Training loss: 0.3882083525049469
Validation loss: 2.455015527415345

Epoch: 6| Step: 3
Training loss: 0.48474672881621644
Validation loss: 2.4922939013840963

Epoch: 6| Step: 4
Training loss: 0.5224983558446396
Validation loss: 2.4187935524679505

Epoch: 6| Step: 5
Training loss: 0.7930862264572058
Validation loss: 2.456013828090127

Epoch: 6| Step: 6
Training loss: 0.49848553656254496
Validation loss: 2.444132798949206

Epoch: 6| Step: 7
Training loss: 0.3063955846522522
Validation loss: 2.43897089660735

Epoch: 6| Step: 8
Training loss: 0.5267166647789168
Validation loss: 2.414291261084042

Epoch: 6| Step: 9
Training loss: 0.4930131889178862
Validation loss: 2.3915120012171984

Epoch: 6| Step: 10
Training loss: 0.4577875970310223
Validation loss: 2.461779776443505

Epoch: 6| Step: 11
Training loss: 0.5505961384391542
Validation loss: 2.46069525382407

Epoch: 6| Step: 12
Training loss: 0.5987934687291376
Validation loss: 2.447141326528158

Epoch: 6| Step: 13
Training loss: 0.385258141556003
Validation loss: 2.472361340613721

Epoch: 348| Step: 0
Training loss: 0.32040552788774634
Validation loss: 2.4268555407305823

Epoch: 6| Step: 1
Training loss: 0.5325145257392431
Validation loss: 2.4846360439719586

Epoch: 6| Step: 2
Training loss: 0.5775790084941499
Validation loss: 2.4715985538522465

Epoch: 6| Step: 3
Training loss: 0.5992805498823954
Validation loss: 2.442317036513041

Epoch: 6| Step: 4
Training loss: 0.3934020700174317
Validation loss: 2.4501021355741943

Epoch: 6| Step: 5
Training loss: 0.6981356452806473
Validation loss: 2.4810899518134506

Epoch: 6| Step: 6
Training loss: 0.5660648500929262
Validation loss: 2.465410126291694

Epoch: 6| Step: 7
Training loss: 0.38893247139714465
Validation loss: 2.485525884046496

Epoch: 6| Step: 8
Training loss: 0.5321190961779538
Validation loss: 2.4495477908235257

Epoch: 6| Step: 9
Training loss: 0.35649752299824594
Validation loss: 2.4438854337254416

Epoch: 6| Step: 10
Training loss: 0.6430355866968129
Validation loss: 2.431361980133334

Epoch: 6| Step: 11
Training loss: 0.5348472538486978
Validation loss: 2.446231376241742

Epoch: 6| Step: 12
Training loss: 0.6288547850218176
Validation loss: 2.43747287837175

Epoch: 6| Step: 13
Training loss: 0.6296314773059778
Validation loss: 2.4272345323684776

Epoch: 349| Step: 0
Training loss: 0.7236838380684876
Validation loss: 2.439588521271262

Epoch: 6| Step: 1
Training loss: 0.43628380532435485
Validation loss: 2.4067085408792477

Epoch: 6| Step: 2
Training loss: 0.62706415732161
Validation loss: 2.43591957297489

Epoch: 6| Step: 3
Training loss: 0.41977142477652546
Validation loss: 2.4228570593691434

Epoch: 6| Step: 4
Training loss: 0.5513062376197073
Validation loss: 2.4854964252609046

Epoch: 6| Step: 5
Training loss: 0.6425162288456712
Validation loss: 2.4796129412541426

Epoch: 6| Step: 6
Training loss: 0.5950469608768096
Validation loss: 2.4158214820991892

Epoch: 6| Step: 7
Training loss: 0.555972692395347
Validation loss: 2.428600815169264

Epoch: 6| Step: 8
Training loss: 0.2990929670370446
Validation loss: 2.444382338451167

Epoch: 6| Step: 9
Training loss: 0.44475758427183537
Validation loss: 2.441397241456834

Epoch: 6| Step: 10
Training loss: 0.4743418940575612
Validation loss: 2.515969627527671

Epoch: 6| Step: 11
Training loss: 0.4413791580663346
Validation loss: 2.4745729994764556

Epoch: 6| Step: 12
Training loss: 0.3399223477906727
Validation loss: 2.451987045516034

Epoch: 6| Step: 13
Training loss: 0.7387550085320745
Validation loss: 2.4689354931351617

Epoch: 350| Step: 0
Training loss: 0.5370889833220708
Validation loss: 2.5021288196251303

Epoch: 6| Step: 1
Training loss: 0.5917961447934723
Validation loss: 2.454258962024907

Epoch: 6| Step: 2
Training loss: 0.3723390064585668
Validation loss: 2.446353050788364

Epoch: 6| Step: 3
Training loss: 0.46659225703685236
Validation loss: 2.469120479151741

Epoch: 6| Step: 4
Training loss: 0.36511524317868427
Validation loss: 2.4580588635089047

Epoch: 6| Step: 5
Training loss: 0.46433173759783697
Validation loss: 2.4765441423887826

Epoch: 6| Step: 6
Training loss: 0.2820003223104529
Validation loss: 2.4624400416653143

Epoch: 6| Step: 7
Training loss: 0.4757911975490922
Validation loss: 2.4806398430417937

Epoch: 6| Step: 8
Training loss: 0.7547890825795067
Validation loss: 2.4639375905243788

Epoch: 6| Step: 9
Training loss: 0.631586747947422
Validation loss: 2.4725419965648965

Epoch: 6| Step: 10
Training loss: 0.4562552621616359
Validation loss: 2.465513452332849

Epoch: 6| Step: 11
Training loss: 0.5868442639883346
Validation loss: 2.4605259246614364

Epoch: 6| Step: 12
Training loss: 0.42580137292749004
Validation loss: 2.454951591564963

Epoch: 6| Step: 13
Training loss: 0.8189463547404977
Validation loss: 2.482274896352656

Epoch: 351| Step: 0
Training loss: 0.3879424107644689
Validation loss: 2.4981981234067145

Epoch: 6| Step: 1
Training loss: 0.5495156702387999
Validation loss: 2.497700232303305

Epoch: 6| Step: 2
Training loss: 0.6072872049376058
Validation loss: 2.5010930676333456

Epoch: 6| Step: 3
Training loss: 0.40492774283477645
Validation loss: 2.517452255332167

Epoch: 6| Step: 4
Training loss: 0.3529775645087163
Validation loss: 2.496487424317062

Epoch: 6| Step: 5
Training loss: 0.38598339410254257
Validation loss: 2.481435821171925

Epoch: 6| Step: 6
Training loss: 0.5794362842529367
Validation loss: 2.490645331217436

Epoch: 6| Step: 7
Training loss: 0.25669601748415805
Validation loss: 2.4766470497216604

Epoch: 6| Step: 8
Training loss: 0.5119286608952245
Validation loss: 2.4907416375679383

Epoch: 6| Step: 9
Training loss: 0.7019972976771126
Validation loss: 2.4967267799372173

Epoch: 6| Step: 10
Training loss: 0.5756827654521183
Validation loss: 2.477132818332393

Epoch: 6| Step: 11
Training loss: 0.545108858794576
Validation loss: 2.495343056801427

Epoch: 6| Step: 12
Training loss: 0.6635328536793297
Validation loss: 2.47921956241053

Epoch: 6| Step: 13
Training loss: 0.7355493125125571
Validation loss: 2.482390904640218

Epoch: 352| Step: 0
Training loss: 0.45156638331871934
Validation loss: 2.4968925565296707

Epoch: 6| Step: 1
Training loss: 0.4878668896144897
Validation loss: 2.480258898214802

Epoch: 6| Step: 2
Training loss: 0.2494682527967466
Validation loss: 2.4463507515984757

Epoch: 6| Step: 3
Training loss: 0.6132060691285557
Validation loss: 2.4293021922785294

Epoch: 6| Step: 4
Training loss: 0.5401752155429405
Validation loss: 2.4841433315362598

Epoch: 6| Step: 5
Training loss: 0.2380785627216507
Validation loss: 2.4458719029300844

Epoch: 6| Step: 6
Training loss: 0.6064720455057928
Validation loss: 2.455336790667703

Epoch: 6| Step: 7
Training loss: 0.5665482441728253
Validation loss: 2.488558702838898

Epoch: 6| Step: 8
Training loss: 0.583410536107731
Validation loss: 2.484840005407874

Epoch: 6| Step: 9
Training loss: 0.5456837076543171
Validation loss: 2.4790924856025334

Epoch: 6| Step: 10
Training loss: 0.468149117942239
Validation loss: 2.505144821268237

Epoch: 6| Step: 11
Training loss: 0.3722582164879818
Validation loss: 2.484765827262976

Epoch: 6| Step: 12
Training loss: 0.56804152577347
Validation loss: 2.493126750490898

Epoch: 6| Step: 13
Training loss: 0.7760562297982179
Validation loss: 2.4609134217787085

Epoch: 353| Step: 0
Training loss: 0.52621684289348
Validation loss: 2.5008099987049066

Epoch: 6| Step: 1
Training loss: 0.7883478459789264
Validation loss: 2.481873606670698

Epoch: 6| Step: 2
Training loss: 0.453313262240354
Validation loss: 2.4800773706517174

Epoch: 6| Step: 3
Training loss: 0.5350200173385495
Validation loss: 2.457884510991869

Epoch: 6| Step: 4
Training loss: 0.39647244214671784
Validation loss: 2.4768651553039627

Epoch: 6| Step: 5
Training loss: 0.4809452578270277
Validation loss: 2.482401543806347

Epoch: 6| Step: 6
Training loss: 0.4735716790141286
Validation loss: 2.4909885611285865

Epoch: 6| Step: 7
Training loss: 0.3098195273222053
Validation loss: 2.4868545154802586

Epoch: 6| Step: 8
Training loss: 0.4851823507957333
Validation loss: 2.5061179816271957

Epoch: 6| Step: 9
Training loss: 0.3953173897180721
Validation loss: 2.512956411326673

Epoch: 6| Step: 10
Training loss: 0.522170226600721
Validation loss: 2.491474576448731

Epoch: 6| Step: 11
Training loss: 0.5864826463862136
Validation loss: 2.4944535646590773

Epoch: 6| Step: 12
Training loss: 0.5391428238000656
Validation loss: 2.4898560091008117

Epoch: 6| Step: 13
Training loss: 0.42374760438585113
Validation loss: 2.487555371712875

Epoch: 354| Step: 0
Training loss: 0.6319885069701444
Validation loss: 2.484472850591466

Epoch: 6| Step: 1
Training loss: 0.4179891955642536
Validation loss: 2.48128892359641

Epoch: 6| Step: 2
Training loss: 0.7522970230628799
Validation loss: 2.443208222761543

Epoch: 6| Step: 3
Training loss: 0.374918889174721
Validation loss: 2.4384314558720255

Epoch: 6| Step: 4
Training loss: 0.5941275851632668
Validation loss: 2.454666296204152

Epoch: 6| Step: 5
Training loss: 0.32166470074094045
Validation loss: 2.500741883405479

Epoch: 6| Step: 6
Training loss: 0.43358555347840294
Validation loss: 2.5178090395850177

Epoch: 6| Step: 7
Training loss: 0.5389759160041678
Validation loss: 2.513375877528285

Epoch: 6| Step: 8
Training loss: 0.52267069661199
Validation loss: 2.5231668605334048

Epoch: 6| Step: 9
Training loss: 0.4264788730795431
Validation loss: 2.5182488282024424

Epoch: 6| Step: 10
Training loss: 0.2799179800424278
Validation loss: 2.530468930495491

Epoch: 6| Step: 11
Training loss: 0.31736385582284904
Validation loss: 2.5091562444174187

Epoch: 6| Step: 12
Training loss: 0.682237926337182
Validation loss: 2.5297442162690618

Epoch: 6| Step: 13
Training loss: 0.5465173369167978
Validation loss: 2.5083455058034048

Epoch: 355| Step: 0
Training loss: 0.2836453635167156
Validation loss: 2.520262810678353

Epoch: 6| Step: 1
Training loss: 0.3294052285143365
Validation loss: 2.469239381255888

Epoch: 6| Step: 2
Training loss: 0.7257515267813691
Validation loss: 2.4877574800381743

Epoch: 6| Step: 3
Training loss: 0.6308218174197799
Validation loss: 2.468023671265131

Epoch: 6| Step: 4
Training loss: 0.51501133554446
Validation loss: 2.4462325101731235

Epoch: 6| Step: 5
Training loss: 0.1887571193602925
Validation loss: 2.4416808932803136

Epoch: 6| Step: 6
Training loss: 0.6462432780552616
Validation loss: 2.4600490431887034

Epoch: 6| Step: 7
Training loss: 0.5985102069003508
Validation loss: 2.4439424578562736

Epoch: 6| Step: 8
Training loss: 0.4715084136169737
Validation loss: 2.459529221533626

Epoch: 6| Step: 9
Training loss: 0.46944044444237837
Validation loss: 2.4294048918248605

Epoch: 6| Step: 10
Training loss: 0.6730919838886636
Validation loss: 2.4255273584482517

Epoch: 6| Step: 11
Training loss: 0.3804880337067905
Validation loss: 2.4487289941536865

Epoch: 6| Step: 12
Training loss: 0.38030268748154067
Validation loss: 2.4554966501237705

Epoch: 6| Step: 13
Training loss: 0.22434774170802305
Validation loss: 2.4182351692008615

Epoch: 356| Step: 0
Training loss: 0.6840314934936742
Validation loss: 2.4940648311158693

Epoch: 6| Step: 1
Training loss: 0.5116571869836628
Validation loss: 2.45255883630965

Epoch: 6| Step: 2
Training loss: 0.5712094504156962
Validation loss: 2.5119743469096383

Epoch: 6| Step: 3
Training loss: 0.49183080251680955
Validation loss: 2.4520256788110304

Epoch: 6| Step: 4
Training loss: 0.28428771073136017
Validation loss: 2.478332393291407

Epoch: 6| Step: 5
Training loss: 0.4599525143121386
Validation loss: 2.5589943323058066

Epoch: 6| Step: 6
Training loss: 0.3175221064148064
Validation loss: 2.510349362815348

Epoch: 6| Step: 7
Training loss: 0.37791582816485525
Validation loss: 2.5464011468137313

Epoch: 6| Step: 8
Training loss: 0.4244525019533867
Validation loss: 2.5614263234583827

Epoch: 6| Step: 9
Training loss: 0.4124377420433087
Validation loss: 2.547736010226941

Epoch: 6| Step: 10
Training loss: 0.5850155507164558
Validation loss: 2.5332700082164488

Epoch: 6| Step: 11
Training loss: 0.4710201129962095
Validation loss: 2.5597654969664707

Epoch: 6| Step: 12
Training loss: 0.8159550419254562
Validation loss: 2.5822686400600507

Epoch: 6| Step: 13
Training loss: 0.3073977702092822
Validation loss: 2.542296292956105

Epoch: 357| Step: 0
Training loss: 0.38286617447722204
Validation loss: 2.541040211869681

Epoch: 6| Step: 1
Training loss: 0.3563518244801951
Validation loss: 2.548514675753041

Epoch: 6| Step: 2
Training loss: 0.6131202826673298
Validation loss: 2.5144781414175803

Epoch: 6| Step: 3
Training loss: 0.5981867312122586
Validation loss: 2.5424892174463922

Epoch: 6| Step: 4
Training loss: 0.41856274332259025
Validation loss: 2.5056687586590423

Epoch: 6| Step: 5
Training loss: 0.4476038557617774
Validation loss: 2.521414209749161

Epoch: 6| Step: 6
Training loss: 0.555895524179838
Validation loss: 2.454593172859751

Epoch: 6| Step: 7
Training loss: 0.5572951099847915
Validation loss: 2.433416102231251

Epoch: 6| Step: 8
Training loss: 0.2535627535846242
Validation loss: 2.4583925556733717

Epoch: 6| Step: 9
Training loss: 0.47976429787362024
Validation loss: 2.453991312368779

Epoch: 6| Step: 10
Training loss: 0.7507076898238141
Validation loss: 2.455181569477074

Epoch: 6| Step: 11
Training loss: 0.4893158290066179
Validation loss: 2.4590291348540276

Epoch: 6| Step: 12
Training loss: 0.4384852283190681
Validation loss: 2.4805281380308823

Epoch: 6| Step: 13
Training loss: 0.5104572383819155
Validation loss: 2.458421725030505

Epoch: 358| Step: 0
Training loss: 0.4706008926742232
Validation loss: 2.4939924825957376

Epoch: 6| Step: 1
Training loss: 0.3687287510390831
Validation loss: 2.49128930643394

Epoch: 6| Step: 2
Training loss: 0.4393822846005489
Validation loss: 2.501358528591654

Epoch: 6| Step: 3
Training loss: 0.6985934141086154
Validation loss: 2.51966591345019

Epoch: 6| Step: 4
Training loss: 0.6589867881816645
Validation loss: 2.5121972607077274

Epoch: 6| Step: 5
Training loss: 0.5624151695711226
Validation loss: 2.491072882356083

Epoch: 6| Step: 6
Training loss: 0.46044585306630464
Validation loss: 2.5043439805168903

Epoch: 6| Step: 7
Training loss: 0.3302921977882034
Validation loss: 2.4526036690052266

Epoch: 6| Step: 8
Training loss: 0.554882122873202
Validation loss: 2.446785238101015

Epoch: 6| Step: 9
Training loss: 0.49231639566946866
Validation loss: 2.4248875157924066

Epoch: 6| Step: 10
Training loss: 0.4776641120301051
Validation loss: 2.417291552666543

Epoch: 6| Step: 11
Training loss: 0.357024466953076
Validation loss: 2.428883782882454

Epoch: 6| Step: 12
Training loss: 0.45863263876732746
Validation loss: 2.434197071977476

Epoch: 6| Step: 13
Training loss: 0.5004889064877954
Validation loss: 2.425571373322625

Epoch: 359| Step: 0
Training loss: 0.5368683430233442
Validation loss: 2.4401139126184646

Epoch: 6| Step: 1
Training loss: 0.18885352431445984
Validation loss: 2.4813173170198284

Epoch: 6| Step: 2
Training loss: 0.4283886090964546
Validation loss: 2.4798005795525775

Epoch: 6| Step: 3
Training loss: 0.4937274547451559
Validation loss: 2.4904831255557554

Epoch: 6| Step: 4
Training loss: 0.5351211090801868
Validation loss: 2.4929291837312815

Epoch: 6| Step: 5
Training loss: 0.2881188713257677
Validation loss: 2.5052188401232898

Epoch: 6| Step: 6
Training loss: 0.4514699339450752
Validation loss: 2.4583245821783675

Epoch: 6| Step: 7
Training loss: 0.42322338926838143
Validation loss: 2.5067798910192987

Epoch: 6| Step: 8
Training loss: 0.7581076293112569
Validation loss: 2.478205959951418

Epoch: 6| Step: 9
Training loss: 0.5780765925580761
Validation loss: 2.4675079020655533

Epoch: 6| Step: 10
Training loss: 0.519721691821247
Validation loss: 2.449549474242221

Epoch: 6| Step: 11
Training loss: 0.4560963450322387
Validation loss: 2.4654145752579915

Epoch: 6| Step: 12
Training loss: 0.451795502049911
Validation loss: 2.4271513001503395

Epoch: 6| Step: 13
Training loss: 0.38437776331954976
Validation loss: 2.4561291680758766

Epoch: 360| Step: 0
Training loss: 0.406030669059329
Validation loss: 2.4767339539738327

Epoch: 6| Step: 1
Training loss: 0.4645195319182625
Validation loss: 2.484940642803015

Epoch: 6| Step: 2
Training loss: 0.5522093689003874
Validation loss: 2.4689727938127755

Epoch: 6| Step: 3
Training loss: 0.43671329474411374
Validation loss: 2.52629277856906

Epoch: 6| Step: 4
Training loss: 0.5031930178518719
Validation loss: 2.503648261735441

Epoch: 6| Step: 5
Training loss: 0.459967449166437
Validation loss: 2.4647206698147643

Epoch: 6| Step: 6
Training loss: 0.4481730023349202
Validation loss: 2.48021898679572

Epoch: 6| Step: 7
Training loss: 0.5718566161989463
Validation loss: 2.4865684595795314

Epoch: 6| Step: 8
Training loss: 0.3945078134657423
Validation loss: 2.459589663412202

Epoch: 6| Step: 9
Training loss: 0.4641465480229393
Validation loss: 2.4310873521784084

Epoch: 6| Step: 10
Training loss: 0.48179298212499233
Validation loss: 2.428732521415143

Epoch: 6| Step: 11
Training loss: 0.6397707756637306
Validation loss: 2.433796200814533

Epoch: 6| Step: 12
Training loss: 0.487289092095293
Validation loss: 2.4228792043774314

Epoch: 6| Step: 13
Training loss: 0.38648839312689903
Validation loss: 2.4402253696527603

Epoch: 361| Step: 0
Training loss: 0.4403073972104472
Validation loss: 2.4152678361710214

Epoch: 6| Step: 1
Training loss: 0.6570217045692752
Validation loss: 2.4316035276138885

Epoch: 6| Step: 2
Training loss: 0.3847450793052641
Validation loss: 2.463558728118392

Epoch: 6| Step: 3
Training loss: 0.6614358903176291
Validation loss: 2.4842677021957607

Epoch: 6| Step: 4
Training loss: 0.6740257084072329
Validation loss: 2.4342697748671362

Epoch: 6| Step: 5
Training loss: 0.32459859543218533
Validation loss: 2.4347404801997747

Epoch: 6| Step: 6
Training loss: 0.36285521023407813
Validation loss: 2.450459600036229

Epoch: 6| Step: 7
Training loss: 0.5464355883250197
Validation loss: 2.41891009344742

Epoch: 6| Step: 8
Training loss: 0.4592718968848118
Validation loss: 2.476656000177323

Epoch: 6| Step: 9
Training loss: 0.35580407559868005
Validation loss: 2.4696246127382593

Epoch: 6| Step: 10
Training loss: 0.16494219380580868
Validation loss: 2.454230970573747

Epoch: 6| Step: 11
Training loss: 0.502438796382313
Validation loss: 2.423477245157833

Epoch: 6| Step: 12
Training loss: 0.34647567548872465
Validation loss: 2.4295743956755573

Epoch: 6| Step: 13
Training loss: 0.39097905326184795
Validation loss: 2.4495261077430963

Epoch: 362| Step: 0
Training loss: 0.44427830248953265
Validation loss: 2.4552396447917095

Epoch: 6| Step: 1
Training loss: 0.6060894891284752
Validation loss: 2.4741568246864234

Epoch: 6| Step: 2
Training loss: 0.5924456222545644
Validation loss: 2.454901584979814

Epoch: 6| Step: 3
Training loss: 0.5452502502063036
Validation loss: 2.4844331657775953

Epoch: 6| Step: 4
Training loss: 0.47111633967807287
Validation loss: 2.4722027801096997

Epoch: 6| Step: 5
Training loss: 0.47545244352551425
Validation loss: 2.4165256453440906

Epoch: 6| Step: 6
Training loss: 0.45538146424188414
Validation loss: 2.44156016084919

Epoch: 6| Step: 7
Training loss: 0.3235213235603323
Validation loss: 2.4353311216842437

Epoch: 6| Step: 8
Training loss: 0.688400978646921
Validation loss: 2.466438414792286

Epoch: 6| Step: 9
Training loss: 0.28019463365005376
Validation loss: 2.423372817603567

Epoch: 6| Step: 10
Training loss: 0.29950329918309987
Validation loss: 2.4303031853260433

Epoch: 6| Step: 11
Training loss: 0.4214543435301837
Validation loss: 2.455252859529683

Epoch: 6| Step: 12
Training loss: 0.3852135234597963
Validation loss: 2.4717703293317794

Epoch: 6| Step: 13
Training loss: 0.46651431034745
Validation loss: 2.493599559682992

Epoch: 363| Step: 0
Training loss: 0.3651351589956176
Validation loss: 2.4221912231837517

Epoch: 6| Step: 1
Training loss: 0.3864314042483134
Validation loss: 2.4168332063393567

Epoch: 6| Step: 2
Training loss: 0.48963289483459094
Validation loss: 2.4362633825804902

Epoch: 6| Step: 3
Training loss: 0.4086315516824455
Validation loss: 2.4395028944409924

Epoch: 6| Step: 4
Training loss: 0.36396606052073494
Validation loss: 2.425712990444012

Epoch: 6| Step: 5
Training loss: 0.4224289506785624
Validation loss: 2.427017276679557

Epoch: 6| Step: 6
Training loss: 0.6258912407726113
Validation loss: 2.4282103887186293

Epoch: 6| Step: 7
Training loss: 0.3047965905936235
Validation loss: 2.4160455123635525

Epoch: 6| Step: 8
Training loss: 0.5392144306974871
Validation loss: 2.4116380783518188

Epoch: 6| Step: 9
Training loss: 0.6786494604576382
Validation loss: 2.4176933143227233

Epoch: 6| Step: 10
Training loss: 0.29808030647175054
Validation loss: 2.4457233210582316

Epoch: 6| Step: 11
Training loss: 0.5866849582251723
Validation loss: 2.444348742371072

Epoch: 6| Step: 12
Training loss: 0.5550253470535262
Validation loss: 2.46775396526283

Epoch: 6| Step: 13
Training loss: 0.56322395572988
Validation loss: 2.4733638119453882

Epoch: 364| Step: 0
Training loss: 0.7403255195165246
Validation loss: 2.5137198394419755

Epoch: 6| Step: 1
Training loss: 0.4082706888309584
Validation loss: 2.448833998685988

Epoch: 6| Step: 2
Training loss: 0.5102730925388801
Validation loss: 2.4943781379469914

Epoch: 6| Step: 3
Training loss: 0.4785340908925053
Validation loss: 2.480956273820972

Epoch: 6| Step: 4
Training loss: 0.4448444516786402
Validation loss: 2.468313817009275

Epoch: 6| Step: 5
Training loss: 0.30870126710303586
Validation loss: 2.4654658077212845

Epoch: 6| Step: 6
Training loss: 0.46918473747012324
Validation loss: 2.4466010917627723

Epoch: 6| Step: 7
Training loss: 0.5842370599742802
Validation loss: 2.439743655367732

Epoch: 6| Step: 8
Training loss: 0.334027181637171
Validation loss: 2.4553558403728704

Epoch: 6| Step: 9
Training loss: 0.6116451867157968
Validation loss: 2.4320930954481494

Epoch: 6| Step: 10
Training loss: 0.3382503050466545
Validation loss: 2.467296106288271

Epoch: 6| Step: 11
Training loss: 0.3477110015960277
Validation loss: 2.4705966321939163

Epoch: 6| Step: 12
Training loss: 0.749012137555327
Validation loss: 2.468864734206318

Epoch: 6| Step: 13
Training loss: 0.31796467190313504
Validation loss: 2.4438158262084015

Epoch: 365| Step: 0
Training loss: 0.6324004963117651
Validation loss: 2.4658484187920955

Epoch: 6| Step: 1
Training loss: 0.39816274706536114
Validation loss: 2.44257176795406

Epoch: 6| Step: 2
Training loss: 0.3167788819119827
Validation loss: 2.4301191287571875

Epoch: 6| Step: 3
Training loss: 0.2860204456488894
Validation loss: 2.4461498963417165

Epoch: 6| Step: 4
Training loss: 0.3756369506026608
Validation loss: 2.442974411314751

Epoch: 6| Step: 5
Training loss: 0.343695224385884
Validation loss: 2.424547595597422

Epoch: 6| Step: 6
Training loss: 0.5038426677008696
Validation loss: 2.420273836974282

Epoch: 6| Step: 7
Training loss: 0.6472349851420435
Validation loss: 2.4632642365545774

Epoch: 6| Step: 8
Training loss: 0.6333855048031795
Validation loss: 2.432343509669036

Epoch: 6| Step: 9
Training loss: 0.548670084180575
Validation loss: 2.408768633272043

Epoch: 6| Step: 10
Training loss: 0.31832075762416245
Validation loss: 2.3915017021969853

Epoch: 6| Step: 11
Training loss: 0.5201989379307319
Validation loss: 2.4015903815306796

Epoch: 6| Step: 12
Training loss: 0.42271195501158204
Validation loss: 2.3870792215051715

Epoch: 6| Step: 13
Training loss: 0.6581760706562586
Validation loss: 2.415943060404037

Epoch: 366| Step: 0
Training loss: 0.6451794457140275
Validation loss: 2.3692452409377025

Epoch: 6| Step: 1
Training loss: 0.5769860931667591
Validation loss: 2.442914125819747

Epoch: 6| Step: 2
Training loss: 0.4251086145342952
Validation loss: 2.4357094363143736

Epoch: 6| Step: 3
Training loss: 0.29903437160282215
Validation loss: 2.4668583619871987

Epoch: 6| Step: 4
Training loss: 0.40412167424875656
Validation loss: 2.419105640621245

Epoch: 6| Step: 5
Training loss: 0.4136888509550511
Validation loss: 2.470101104780415

Epoch: 6| Step: 6
Training loss: 0.3263488449338949
Validation loss: 2.4358550743287495

Epoch: 6| Step: 7
Training loss: 0.5805850655626752
Validation loss: 2.463875688326654

Epoch: 6| Step: 8
Training loss: 0.4760493971393824
Validation loss: 2.477712771755523

Epoch: 6| Step: 9
Training loss: 0.3405428306092644
Validation loss: 2.499250646285321

Epoch: 6| Step: 10
Training loss: 0.5663746792117363
Validation loss: 2.449433093753313

Epoch: 6| Step: 11
Training loss: 0.5689953264436712
Validation loss: 2.424722276123338

Epoch: 6| Step: 12
Training loss: 0.3344881485741176
Validation loss: 2.4649588365925754

Epoch: 6| Step: 13
Training loss: 0.3649763123781915
Validation loss: 2.4697249244942685

Epoch: 367| Step: 0
Training loss: 0.581828241979257
Validation loss: 2.456016152027661

Epoch: 6| Step: 1
Training loss: 0.4519173874239362
Validation loss: 2.4554402054543507

Epoch: 6| Step: 2
Training loss: 0.5244090046274653
Validation loss: 2.449578542205577

Epoch: 6| Step: 3
Training loss: 0.5524868630016861
Validation loss: 2.437013157305879

Epoch: 6| Step: 4
Training loss: 0.3604056051611186
Validation loss: 2.473674808613356

Epoch: 6| Step: 5
Training loss: 0.4123406326332222
Validation loss: 2.4568945757367606

Epoch: 6| Step: 6
Training loss: 0.34092701987602275
Validation loss: 2.432806614819747

Epoch: 6| Step: 7
Training loss: 0.4028183073538182
Validation loss: 2.4730457042685017

Epoch: 6| Step: 8
Training loss: 0.413612499064293
Validation loss: 2.461092996706166

Epoch: 6| Step: 9
Training loss: 0.506619886975355
Validation loss: 2.463840900302844

Epoch: 6| Step: 10
Training loss: 0.4588956706587865
Validation loss: 2.4280760768659513

Epoch: 6| Step: 11
Training loss: 0.4079076254092394
Validation loss: 2.477864561433942

Epoch: 6| Step: 12
Training loss: 0.40694236443819454
Validation loss: 2.50550909622365

Epoch: 6| Step: 13
Training loss: 0.5428525951381441
Validation loss: 2.4901533393776525

Epoch: 368| Step: 0
Training loss: 0.365594023835099
Validation loss: 2.5107709733079755

Epoch: 6| Step: 1
Training loss: 0.6382872330234595
Validation loss: 2.5084290238424214

Epoch: 6| Step: 2
Training loss: 0.2480289723100793
Validation loss: 2.4854352255573753

Epoch: 6| Step: 3
Training loss: 0.47308979170499166
Validation loss: 2.4928510113549303

Epoch: 6| Step: 4
Training loss: 0.521173277223874
Validation loss: 2.4923290277177457

Epoch: 6| Step: 5
Training loss: 0.6989394967563082
Validation loss: 2.5059667355241997

Epoch: 6| Step: 6
Training loss: 0.24956943269993384
Validation loss: 2.4992907717883392

Epoch: 6| Step: 7
Training loss: 0.36159198508879875
Validation loss: 2.4970636782183337

Epoch: 6| Step: 8
Training loss: 0.4832193678744817
Validation loss: 2.470293712210487

Epoch: 6| Step: 9
Training loss: 0.4886947102017837
Validation loss: 2.462493126664252

Epoch: 6| Step: 10
Training loss: 0.25921804033657103
Validation loss: 2.4604670608670967

Epoch: 6| Step: 11
Training loss: 0.40576359166563464
Validation loss: 2.452886153471173

Epoch: 6| Step: 12
Training loss: 0.4430520425090541
Validation loss: 2.479776344879059

Epoch: 6| Step: 13
Training loss: 0.47784867810242815
Validation loss: 2.4601072860027653

Epoch: 369| Step: 0
Training loss: 0.5491481947312686
Validation loss: 2.5295819704227904

Epoch: 6| Step: 1
Training loss: 0.5201378056518158
Validation loss: 2.4603533224476823

Epoch: 6| Step: 2
Training loss: 0.4162272242022733
Validation loss: 2.488474272724428

Epoch: 6| Step: 3
Training loss: 0.3877961150219218
Validation loss: 2.4857562190628277

Epoch: 6| Step: 4
Training loss: 0.22512146168109304
Validation loss: 2.443750074105605

Epoch: 6| Step: 5
Training loss: 0.5265590056351535
Validation loss: 2.4346266344964866

Epoch: 6| Step: 6
Training loss: 0.3492835140552506
Validation loss: 2.436049070284769

Epoch: 6| Step: 7
Training loss: 0.50146983588983
Validation loss: 2.4450126306039097

Epoch: 6| Step: 8
Training loss: 0.6098978538273399
Validation loss: 2.452630989417344

Epoch: 6| Step: 9
Training loss: 0.25762403708976245
Validation loss: 2.444664208291406

Epoch: 6| Step: 10
Training loss: 0.4951191136550305
Validation loss: 2.4614776565437433

Epoch: 6| Step: 11
Training loss: 0.45788803649181103
Validation loss: 2.47157538180427

Epoch: 6| Step: 12
Training loss: 0.5036408664441361
Validation loss: 2.513293600010137

Epoch: 6| Step: 13
Training loss: 0.25732156943996864
Validation loss: 2.447073747656381

Epoch: 370| Step: 0
Training loss: 0.4505362388608218
Validation loss: 2.446222311059764

Epoch: 6| Step: 1
Training loss: 0.6582017213710228
Validation loss: 2.493873653532529

Epoch: 6| Step: 2
Training loss: 0.2602738879121321
Validation loss: 2.481874744976583

Epoch: 6| Step: 3
Training loss: 0.4487086343693698
Validation loss: 2.5308610624164305

Epoch: 6| Step: 4
Training loss: 0.49020955604252664
Validation loss: 2.5106084811004554

Epoch: 6| Step: 5
Training loss: 0.4410410695469123
Validation loss: 2.5123589317877606

Epoch: 6| Step: 6
Training loss: 0.5426676622064505
Validation loss: 2.523570130486828

Epoch: 6| Step: 7
Training loss: 0.33123036452342985
Validation loss: 2.4806585444531244

Epoch: 6| Step: 8
Training loss: 0.38667218091680317
Validation loss: 2.525056538598142

Epoch: 6| Step: 9
Training loss: 0.13770899467939468
Validation loss: 2.51277775346235

Epoch: 6| Step: 10
Training loss: 0.423196647387432
Validation loss: 2.4272361016143793

Epoch: 6| Step: 11
Training loss: 0.45032022857387277
Validation loss: 2.461052475506098

Epoch: 6| Step: 12
Training loss: 0.32182618437651106
Validation loss: 2.4486437539630797

Epoch: 6| Step: 13
Training loss: 0.649372850989126
Validation loss: 2.4348982900401257

Epoch: 371| Step: 0
Training loss: 0.5113408098038964
Validation loss: 2.392163654630062

Epoch: 6| Step: 1
Training loss: 0.4418366114979115
Validation loss: 2.4339315557600263

Epoch: 6| Step: 2
Training loss: 0.48290815054049796
Validation loss: 2.4366507248367997

Epoch: 6| Step: 3
Training loss: 0.44409573948029135
Validation loss: 2.435837631316376

Epoch: 6| Step: 4
Training loss: 0.21988506110649908
Validation loss: 2.4122186879200522

Epoch: 6| Step: 5
Training loss: 0.5539814390901692
Validation loss: 2.4272609358585027

Epoch: 6| Step: 6
Training loss: 0.13144630499772583
Validation loss: 2.4072540781504066

Epoch: 6| Step: 7
Training loss: 0.2822705138939492
Validation loss: 2.4547248484540556

Epoch: 6| Step: 8
Training loss: 0.5209148883546142
Validation loss: 2.473539360764598

Epoch: 6| Step: 9
Training loss: 0.4714408253908109
Validation loss: 2.4822403692878776

Epoch: 6| Step: 10
Training loss: 0.37580552607615375
Validation loss: 2.399672565120075

Epoch: 6| Step: 11
Training loss: 0.5067245860885593
Validation loss: 2.495057905005132

Epoch: 6| Step: 12
Training loss: 0.15579093611246578
Validation loss: 2.4542230756252597

Epoch: 6| Step: 13
Training loss: 0.7431456153775701
Validation loss: 2.4471578393665223

Epoch: 372| Step: 0
Training loss: 0.6933886454676645
Validation loss: 2.4474961423398853

Epoch: 6| Step: 1
Training loss: 0.48096741021280576
Validation loss: 2.4111728616625134

Epoch: 6| Step: 2
Training loss: 0.44086862416817546
Validation loss: 2.4393225356851707

Epoch: 6| Step: 3
Training loss: 0.42453464387359124
Validation loss: 2.429412727077472

Epoch: 6| Step: 4
Training loss: 0.31985999919127367
Validation loss: 2.421278425898098

Epoch: 6| Step: 5
Training loss: 0.4785735114759898
Validation loss: 2.415131356675712

Epoch: 6| Step: 6
Training loss: 0.4251405462514287
Validation loss: 2.363062429403851

Epoch: 6| Step: 7
Training loss: 0.33495830167839913
Validation loss: 2.404532697780831

Epoch: 6| Step: 8
Training loss: 0.46720537961600367
Validation loss: 2.458029646041146

Epoch: 6| Step: 9
Training loss: 0.3693873877473233
Validation loss: 2.43721447942837

Epoch: 6| Step: 10
Training loss: 0.22916172665271123
Validation loss: 2.457909767768076

Epoch: 6| Step: 11
Training loss: 0.59386716489736
Validation loss: 2.472573388895093

Epoch: 6| Step: 12
Training loss: 0.21221187426276023
Validation loss: 2.498150373029616

Epoch: 6| Step: 13
Training loss: 0.4307352642963863
Validation loss: 2.481893103443943

Epoch: 373| Step: 0
Training loss: 0.256453922589135
Validation loss: 2.4772074858347666

Epoch: 6| Step: 1
Training loss: 0.23461617141416724
Validation loss: 2.459468452954765

Epoch: 6| Step: 2
Training loss: 0.4035246656943136
Validation loss: 2.4520774293886083

Epoch: 6| Step: 3
Training loss: 0.47424647895901473
Validation loss: 2.4436163446607106

Epoch: 6| Step: 4
Training loss: 0.3143127791638063
Validation loss: 2.4427478630620634

Epoch: 6| Step: 5
Training loss: 0.34822901146181884
Validation loss: 2.4174585537205417

Epoch: 6| Step: 6
Training loss: 0.26776216957652804
Validation loss: 2.4106049758063426

Epoch: 6| Step: 7
Training loss: 0.4859342703757949
Validation loss: 2.402256355926997

Epoch: 6| Step: 8
Training loss: 0.5444007487289807
Validation loss: 2.4104631209011536

Epoch: 6| Step: 9
Training loss: 0.34875971090134594
Validation loss: 2.4252700936880913

Epoch: 6| Step: 10
Training loss: 0.4925104928230174
Validation loss: 2.365471035821587

Epoch: 6| Step: 11
Training loss: 0.5018512607627418
Validation loss: 2.432866371788026

Epoch: 6| Step: 12
Training loss: 0.6424357711660365
Validation loss: 2.410135137940484

Epoch: 6| Step: 13
Training loss: 0.46844649025686025
Validation loss: 2.4179968251394826

Epoch: 374| Step: 0
Training loss: 0.3281180517278418
Validation loss: 2.40392242352295

Epoch: 6| Step: 1
Training loss: 0.6583769481029699
Validation loss: 2.4344002655945274

Epoch: 6| Step: 2
Training loss: 0.5720596724041983
Validation loss: 2.411915639385975

Epoch: 6| Step: 3
Training loss: 0.24501758998863554
Validation loss: 2.454170363292657

Epoch: 6| Step: 4
Training loss: 0.48456125370093167
Validation loss: 2.4394804484531765

Epoch: 6| Step: 5
Training loss: 0.24990331001885
Validation loss: 2.4263346745879755

Epoch: 6| Step: 6
Training loss: 0.5617560128915995
Validation loss: 2.4314933939515484

Epoch: 6| Step: 7
Training loss: 0.2144340162675237
Validation loss: 2.4378429725821347

Epoch: 6| Step: 8
Training loss: 0.11306288653898615
Validation loss: 2.4538411399548963

Epoch: 6| Step: 9
Training loss: 0.2846518196249488
Validation loss: 2.4508979804162117

Epoch: 6| Step: 10
Training loss: 0.4349871575717931
Validation loss: 2.43531510395103

Epoch: 6| Step: 11
Training loss: 0.4782781206170051
Validation loss: 2.4730217454919705

Epoch: 6| Step: 12
Training loss: 0.4367870925629371
Validation loss: 2.4174115946223664

Epoch: 6| Step: 13
Training loss: 0.44561352510377966
Validation loss: 2.4110790241319804

Epoch: 375| Step: 0
Training loss: 0.33961758816240795
Validation loss: 2.452942681733695

Epoch: 6| Step: 1
Training loss: 0.41094984753990293
Validation loss: 2.399383944998859

Epoch: 6| Step: 2
Training loss: 0.4979232335422396
Validation loss: 2.4253813460343956

Epoch: 6| Step: 3
Training loss: 0.1963610445954679
Validation loss: 2.439831666295665

Epoch: 6| Step: 4
Training loss: 0.5263464645807667
Validation loss: 2.44789311474685

Epoch: 6| Step: 5
Training loss: 0.4215493534829285
Validation loss: 2.4331238469639658

Epoch: 6| Step: 6
Training loss: 0.5841329379237266
Validation loss: 2.450467492463351

Epoch: 6| Step: 7
Training loss: 0.38015760666886983
Validation loss: 2.441518805159154

Epoch: 6| Step: 8
Training loss: 0.3373412699429342
Validation loss: 2.4337531489422726

Epoch: 6| Step: 9
Training loss: 0.5542018806292764
Validation loss: 2.4109353516954384

Epoch: 6| Step: 10
Training loss: 0.2506298237857215
Validation loss: 2.4843738638716037

Epoch: 6| Step: 11
Training loss: 0.2889015419773955
Validation loss: 2.4843516344501597

Epoch: 6| Step: 12
Training loss: 0.3742471130708234
Validation loss: 2.4175576769373794

Epoch: 6| Step: 13
Training loss: 0.5598283741846706
Validation loss: 2.4132747839110307

Epoch: 376| Step: 0
Training loss: 0.2792744927674634
Validation loss: 2.4497033375934407

Epoch: 6| Step: 1
Training loss: 0.4413657549622064
Validation loss: 2.4178462132552583

Epoch: 6| Step: 2
Training loss: 0.48013613593255405
Validation loss: 2.3968117669288573

Epoch: 6| Step: 3
Training loss: 0.4391867275228529
Validation loss: 2.4062246085037673

Epoch: 6| Step: 4
Training loss: 0.6076927439726143
Validation loss: 2.3905715437752963

Epoch: 6| Step: 5
Training loss: 0.4209882635929417
Validation loss: 2.423139690093836

Epoch: 6| Step: 6
Training loss: 0.21588635189435154
Validation loss: 2.424428712724699

Epoch: 6| Step: 7
Training loss: 0.3688262125235152
Validation loss: 2.4331960382582354

Epoch: 6| Step: 8
Training loss: 0.3909162198746361
Validation loss: 2.429071831704595

Epoch: 6| Step: 9
Training loss: 0.3625232417778541
Validation loss: 2.4669428397919324

Epoch: 6| Step: 10
Training loss: 0.3692192115086639
Validation loss: 2.4387504734628305

Epoch: 6| Step: 11
Training loss: 0.39225060764506375
Validation loss: 2.469774984904916

Epoch: 6| Step: 12
Training loss: 0.5977490670927993
Validation loss: 2.447153221021018

Epoch: 6| Step: 13
Training loss: 0.3962902665061202
Validation loss: 2.461416745468655

Epoch: 377| Step: 0
Training loss: 0.42468610840513993
Validation loss: 2.446649441655767

Epoch: 6| Step: 1
Training loss: 0.6267395130979774
Validation loss: 2.4510465446016303

Epoch: 6| Step: 2
Training loss: 0.4159953152709136
Validation loss: 2.4361938195736093

Epoch: 6| Step: 3
Training loss: 0.49092428895013285
Validation loss: 2.4122983382451175

Epoch: 6| Step: 4
Training loss: 0.7229287123615566
Validation loss: 2.4327546935182784

Epoch: 6| Step: 5
Training loss: 0.3002446949932435
Validation loss: 2.488690564304801

Epoch: 6| Step: 6
Training loss: 0.3103876845486725
Validation loss: 2.4693825439562467

Epoch: 6| Step: 7
Training loss: 0.18576660196357211
Validation loss: 2.427998767609672

Epoch: 6| Step: 8
Training loss: 0.3727242037957103
Validation loss: 2.4477042757751977

Epoch: 6| Step: 9
Training loss: 0.3049737856887269
Validation loss: 2.4351138185100174

Epoch: 6| Step: 10
Training loss: 0.41710236141397905
Validation loss: 2.4808921699973894

Epoch: 6| Step: 11
Training loss: 0.24066035952178133
Validation loss: 2.4423085026353877

Epoch: 6| Step: 12
Training loss: 0.3596686117480846
Validation loss: 2.4256991539847705

Epoch: 6| Step: 13
Training loss: 0.20295631300107883
Validation loss: 2.4935636683466496

Epoch: 378| Step: 0
Training loss: 0.39409182409920457
Validation loss: 2.444757053477956

Epoch: 6| Step: 1
Training loss: 0.4312392910719588
Validation loss: 2.4589696373168364

Epoch: 6| Step: 2
Training loss: 0.5046817519389101
Validation loss: 2.4385503646648434

Epoch: 6| Step: 3
Training loss: 0.24730684620793736
Validation loss: 2.4112437400429774

Epoch: 6| Step: 4
Training loss: 0.6431838777688661
Validation loss: 2.4358316974957788

Epoch: 6| Step: 5
Training loss: 0.390529372908025
Validation loss: 2.4455338108340694

Epoch: 6| Step: 6
Training loss: 0.4774404474640097
Validation loss: 2.434535124674811

Epoch: 6| Step: 7
Training loss: 0.38397111530247585
Validation loss: 2.468468198922301

Epoch: 6| Step: 8
Training loss: 0.41844369517633945
Validation loss: 2.4886854312301456

Epoch: 6| Step: 9
Training loss: 0.30670506717440665
Validation loss: 2.4909550090631405

Epoch: 6| Step: 10
Training loss: 0.17098353310926537
Validation loss: 2.504752686757141

Epoch: 6| Step: 11
Training loss: 0.3061031685354237
Validation loss: 2.4830634762995203

Epoch: 6| Step: 12
Training loss: 0.5083563899715728
Validation loss: 2.5175321220234346

Epoch: 6| Step: 13
Training loss: 0.289712522983546
Validation loss: 2.5090373610637844

Epoch: 379| Step: 0
Training loss: 0.4372092541128385
Validation loss: 2.5208715586627317

Epoch: 6| Step: 1
Training loss: 0.36966234506910745
Validation loss: 2.4927107345641963

Epoch: 6| Step: 2
Training loss: 0.5250854172928856
Validation loss: 2.4815124765301046

Epoch: 6| Step: 3
Training loss: 0.41905943554377195
Validation loss: 2.443028501686333

Epoch: 6| Step: 4
Training loss: 0.36498298765407355
Validation loss: 2.4462857592923526

Epoch: 6| Step: 5
Training loss: 0.5238808988631816
Validation loss: 2.4447894537703916

Epoch: 6| Step: 6
Training loss: 0.4577973783163411
Validation loss: 2.4178978588220432

Epoch: 6| Step: 7
Training loss: 0.3538448213060591
Validation loss: 2.3984110162268264

Epoch: 6| Step: 8
Training loss: 0.3844162569932114
Validation loss: 2.427894330742352

Epoch: 6| Step: 9
Training loss: 0.25643859703411326
Validation loss: 2.410128934482764

Epoch: 6| Step: 10
Training loss: 0.5430268181137419
Validation loss: 2.405123824916335

Epoch: 6| Step: 11
Training loss: 0.3273790144759781
Validation loss: 2.4312441880971525

Epoch: 6| Step: 12
Training loss: 0.4643637158035562
Validation loss: 2.372324503550119

Epoch: 6| Step: 13
Training loss: 0.16426410662989716
Validation loss: 2.3856277325871926

Epoch: 380| Step: 0
Training loss: 0.2998090737484831
Validation loss: 2.389142997901415

Epoch: 6| Step: 1
Training loss: 0.33770639987127726
Validation loss: 2.4353715760973893

Epoch: 6| Step: 2
Training loss: 0.5158060218480964
Validation loss: 2.368325312691361

Epoch: 6| Step: 3
Training loss: 0.42118255867743365
Validation loss: 2.4059109501542637

Epoch: 6| Step: 4
Training loss: 0.5076985157907162
Validation loss: 2.454332262452557

Epoch: 6| Step: 5
Training loss: 0.2168837107055133
Validation loss: 2.433411789136563

Epoch: 6| Step: 6
Training loss: 0.39826241554572334
Validation loss: 2.4282933832534965

Epoch: 6| Step: 7
Training loss: 0.4440694995250627
Validation loss: 2.4482739908845064

Epoch: 6| Step: 8
Training loss: 0.3902038974716892
Validation loss: 2.40943821809383

Epoch: 6| Step: 9
Training loss: 0.28077527884203796
Validation loss: 2.442484794631758

Epoch: 6| Step: 10
Training loss: 0.4066842582518328
Validation loss: 2.396442858688747

Epoch: 6| Step: 11
Training loss: 0.3153682920624787
Validation loss: 2.3953055964660344

Epoch: 6| Step: 12
Training loss: 0.5470374274865253
Validation loss: 2.414131545603911

Epoch: 6| Step: 13
Training loss: 0.5433152554533317
Validation loss: 2.400375820202935

Epoch: 381| Step: 0
Training loss: 0.6863079573958006
Validation loss: 2.4091236591443614

Epoch: 6| Step: 1
Training loss: 0.32316171157186524
Validation loss: 2.4425179393115943

Epoch: 6| Step: 2
Training loss: 0.20727982083855503
Validation loss: 2.3747883477322427

Epoch: 6| Step: 3
Training loss: 0.19529031627557927
Validation loss: 2.4135001494247814

Epoch: 6| Step: 4
Training loss: 0.27031271058002715
Validation loss: 2.424780871622024

Epoch: 6| Step: 5
Training loss: 0.34823241335106264
Validation loss: 2.427871772152265

Epoch: 6| Step: 6
Training loss: 0.48988191312977014
Validation loss: 2.4504492574030317

Epoch: 6| Step: 7
Training loss: 0.3309170709811811
Validation loss: 2.4481441265579447

Epoch: 6| Step: 8
Training loss: 0.41418976897134396
Validation loss: 2.4318304414870777

Epoch: 6| Step: 9
Training loss: 0.40969617562379396
Validation loss: 2.3738990216857254

Epoch: 6| Step: 10
Training loss: 0.4364746715094538
Validation loss: 2.406520207733691

Epoch: 6| Step: 11
Training loss: 0.5597401838783608
Validation loss: 2.398992197134721

Epoch: 6| Step: 12
Training loss: 0.2993052793242401
Validation loss: 2.403560447373928

Epoch: 6| Step: 13
Training loss: 0.40061964602768557
Validation loss: 2.3961470899186366

Epoch: 382| Step: 0
Training loss: 0.46749312059165304
Validation loss: 2.4237192299078374

Epoch: 6| Step: 1
Training loss: 0.28234037328663125
Validation loss: 2.387688288420496

Epoch: 6| Step: 2
Training loss: 0.5197011340033685
Validation loss: 2.4046357622262935

Epoch: 6| Step: 3
Training loss: 0.39316060140027187
Validation loss: 2.409242886500206

Epoch: 6| Step: 4
Training loss: 0.5784392404968027
Validation loss: 2.4270865793183116

Epoch: 6| Step: 5
Training loss: 0.2841557889242615
Validation loss: 2.420843813480626

Epoch: 6| Step: 6
Training loss: 0.3596659187716279
Validation loss: 2.42473353837671

Epoch: 6| Step: 7
Training loss: 0.36629464782186155
Validation loss: 2.4358600308852445

Epoch: 6| Step: 8
Training loss: 0.23253024804333008
Validation loss: 2.45823118464458

Epoch: 6| Step: 9
Training loss: 0.3082769191957841
Validation loss: 2.421108174996881

Epoch: 6| Step: 10
Training loss: 0.44415168714880315
Validation loss: 2.4480711257019228

Epoch: 6| Step: 11
Training loss: 0.41869391165352665
Validation loss: 2.429871759126982

Epoch: 6| Step: 12
Training loss: 0.39317858499083647
Validation loss: 2.442206072783107

Epoch: 6| Step: 13
Training loss: 0.669238462048702
Validation loss: 2.464950048290854

Epoch: 383| Step: 0
Training loss: 0.5126181408158839
Validation loss: 2.416709397404609

Epoch: 6| Step: 1
Training loss: 0.5438418058744123
Validation loss: 2.391741287246737

Epoch: 6| Step: 2
Training loss: 0.08713927717980836
Validation loss: 2.41933267075627

Epoch: 6| Step: 3
Training loss: 0.5652948986411048
Validation loss: 2.3954464889461473

Epoch: 6| Step: 4
Training loss: 0.3931477717185934
Validation loss: 2.39764161175674

Epoch: 6| Step: 5
Training loss: 0.33727848412849887
Validation loss: 2.401546247388088

Epoch: 6| Step: 6
Training loss: 0.29361808026386665
Validation loss: 2.3672283792744597

Epoch: 6| Step: 7
Training loss: 0.38463714313399405
Validation loss: 2.420807655179507

Epoch: 6| Step: 8
Training loss: 0.39210766743472286
Validation loss: 2.3791314671157076

Epoch: 6| Step: 9
Training loss: 0.32111655476840534
Validation loss: 2.443372375422743

Epoch: 6| Step: 10
Training loss: 0.44637811886571915
Validation loss: 2.453809254100806

Epoch: 6| Step: 11
Training loss: 0.44276438713499744
Validation loss: 2.430130306922643

Epoch: 6| Step: 12
Training loss: 0.26031781068676235
Validation loss: 2.4091359850261833

Epoch: 6| Step: 13
Training loss: 0.15492975238042522
Validation loss: 2.4100373465278557

Epoch: 384| Step: 0
Training loss: 0.37716309229047246
Validation loss: 2.415274391561211

Epoch: 6| Step: 1
Training loss: 0.20418607066517971
Validation loss: 2.4215012567957084

Epoch: 6| Step: 2
Training loss: 0.2586165807044068
Validation loss: 2.3960068570751636

Epoch: 6| Step: 3
Training loss: 0.5257198620990617
Validation loss: 2.40739558543663

Epoch: 6| Step: 4
Training loss: 0.18024072277926842
Validation loss: 2.3920743332918617

Epoch: 6| Step: 5
Training loss: 0.35020891919485114
Validation loss: 2.4042163677889397

Epoch: 6| Step: 6
Training loss: 0.14508004643816885
Validation loss: 2.390601368009236

Epoch: 6| Step: 7
Training loss: 0.3535947131633915
Validation loss: 2.382735197231159

Epoch: 6| Step: 8
Training loss: 0.47600799882503203
Validation loss: 2.397960102668665

Epoch: 6| Step: 9
Training loss: 0.34130695653694637
Validation loss: 2.4016499929331863

Epoch: 6| Step: 10
Training loss: 0.5419544378657646
Validation loss: 2.4084140415196384

Epoch: 6| Step: 11
Training loss: 0.4130892922556042
Validation loss: 2.4267513398940235

Epoch: 6| Step: 12
Training loss: 0.4366522477344043
Validation loss: 2.392269158135239

Epoch: 6| Step: 13
Training loss: 0.5512095470247376
Validation loss: 2.3800753328329574

Epoch: 385| Step: 0
Training loss: 0.29308348634211673
Validation loss: 2.3844903706764473

Epoch: 6| Step: 1
Training loss: 0.2467238141337994
Validation loss: 2.389553531554193

Epoch: 6| Step: 2
Training loss: 0.28178741185369205
Validation loss: 2.378042146607085

Epoch: 6| Step: 3
Training loss: 0.33685470279277624
Validation loss: 2.381014868594545

Epoch: 6| Step: 4
Training loss: 0.40718720609547454
Validation loss: 2.401965582924703

Epoch: 6| Step: 5
Training loss: 0.27364038025372345
Validation loss: 2.363985018384268

Epoch: 6| Step: 6
Training loss: 0.34463614339734094
Validation loss: 2.3498634101010527

Epoch: 6| Step: 7
Training loss: 0.23918968320597278
Validation loss: 2.4188930311364794

Epoch: 6| Step: 8
Training loss: 0.3667277643747985
Validation loss: 2.3764871519098847

Epoch: 6| Step: 9
Training loss: 0.2498314408448424
Validation loss: 2.411664451951139

Epoch: 6| Step: 10
Training loss: 0.6157806877360165
Validation loss: 2.416858153842047

Epoch: 6| Step: 11
Training loss: 0.6535804584126552
Validation loss: 2.4665332955048282

Epoch: 6| Step: 12
Training loss: 0.35688274141322923
Validation loss: 2.4204267158823836

Epoch: 6| Step: 13
Training loss: 0.38401632399184393
Validation loss: 2.4179298895673997

Epoch: 386| Step: 0
Training loss: 0.23603621495632476
Validation loss: 2.425177255116198

Epoch: 6| Step: 1
Training loss: 0.24533479461680682
Validation loss: 2.4371050295625447

Epoch: 6| Step: 2
Training loss: 0.295919386119015
Validation loss: 2.437078306428754

Epoch: 6| Step: 3
Training loss: 0.22910797747568395
Validation loss: 2.440935835476215

Epoch: 6| Step: 4
Training loss: 0.29993720341131413
Validation loss: 2.4228164129277623

Epoch: 6| Step: 5
Training loss: 0.4091137853461273
Validation loss: 2.46133176448591

Epoch: 6| Step: 6
Training loss: 0.5427516530686923
Validation loss: 2.427421012568239

Epoch: 6| Step: 7
Training loss: 0.39645678795362815
Validation loss: 2.442223294482963

Epoch: 6| Step: 8
Training loss: 0.5398406065919726
Validation loss: 2.432868874450502

Epoch: 6| Step: 9
Training loss: 0.22217667111969874
Validation loss: 2.451774134829821

Epoch: 6| Step: 10
Training loss: 0.5098476709278791
Validation loss: 2.4281841430986986

Epoch: 6| Step: 11
Training loss: 0.4752989104545974
Validation loss: 2.462404124574215

Epoch: 6| Step: 12
Training loss: 0.16893720883024346
Validation loss: 2.4161455121477693

Epoch: 6| Step: 13
Training loss: 0.4832007880682471
Validation loss: 2.394159116365346

Epoch: 387| Step: 0
Training loss: 0.23765614860076045
Validation loss: 2.4362341931036426

Epoch: 6| Step: 1
Training loss: 0.15996452811919065
Validation loss: 2.4091284892630376

Epoch: 6| Step: 2
Training loss: 0.6605981104204419
Validation loss: 2.432934636121491

Epoch: 6| Step: 3
Training loss: 0.2752551157984397
Validation loss: 2.3773407683662935

Epoch: 6| Step: 4
Training loss: 0.44862482365232476
Validation loss: 2.4071108329403885

Epoch: 6| Step: 5
Training loss: 0.4534701972703313
Validation loss: 2.3936572537548515

Epoch: 6| Step: 6
Training loss: 0.279815791984281
Validation loss: 2.3623010715154997

Epoch: 6| Step: 7
Training loss: 0.5073815791550981
Validation loss: 2.400609714001589

Epoch: 6| Step: 8
Training loss: 0.43488151465807967
Validation loss: 2.392163810827825

Epoch: 6| Step: 9
Training loss: 0.25402527000286
Validation loss: 2.4173297022034266

Epoch: 6| Step: 10
Training loss: 0.2535858920954733
Validation loss: 2.416664577210244

Epoch: 6| Step: 11
Training loss: 0.14657444410111325
Validation loss: 2.4041639228782823

Epoch: 6| Step: 12
Training loss: 0.43204382797060165
Validation loss: 2.425304184486168

Epoch: 6| Step: 13
Training loss: 0.28759528581714255
Validation loss: 2.396511164080061

Epoch: 388| Step: 0
Training loss: 0.18184619468990043
Validation loss: 2.464340601422163

Epoch: 6| Step: 1
Training loss: 0.36136890902906554
Validation loss: 2.4413453978471393

Epoch: 6| Step: 2
Training loss: 0.5525482187763128
Validation loss: 2.452055371384747

Epoch: 6| Step: 3
Training loss: 0.4356643791953473
Validation loss: 2.423613156302924

Epoch: 6| Step: 4
Training loss: 0.20219304795001375
Validation loss: 2.438367120921423

Epoch: 6| Step: 5
Training loss: 0.5163813447934154
Validation loss: 2.4301090226322843

Epoch: 6| Step: 6
Training loss: 0.2924935110301611
Validation loss: 2.4596146514861505

Epoch: 6| Step: 7
Training loss: 0.4402412298933059
Validation loss: 2.423521256010576

Epoch: 6| Step: 8
Training loss: 0.2410490751625381
Validation loss: 2.4289580380007885

Epoch: 6| Step: 9
Training loss: 0.532002757201543
Validation loss: 2.4449470234055957

Epoch: 6| Step: 10
Training loss: 0.21982067212057316
Validation loss: 2.4674311976145464

Epoch: 6| Step: 11
Training loss: 0.4846669363287176
Validation loss: 2.4526226333217265

Epoch: 6| Step: 12
Training loss: 0.18261488234753132
Validation loss: 2.444179630649259

Epoch: 6| Step: 13
Training loss: 0.1510994481409745
Validation loss: 2.4418200227953197

Epoch: 389| Step: 0
Training loss: 0.4598447324876468
Validation loss: 2.4372526263639296

Epoch: 6| Step: 1
Training loss: 0.374332449728692
Validation loss: 2.4432823447252017

Epoch: 6| Step: 2
Training loss: 0.2564889863384294
Validation loss: 2.4264851367727718

Epoch: 6| Step: 3
Training loss: 0.3990042152946971
Validation loss: 2.4094002787712316

Epoch: 6| Step: 4
Training loss: 0.4188458162259763
Validation loss: 2.4755393923676

Epoch: 6| Step: 5
Training loss: 0.25626632126724685
Validation loss: 2.4816254750318945

Epoch: 6| Step: 6
Training loss: 0.36488746038150943
Validation loss: 2.419303438604567

Epoch: 6| Step: 7
Training loss: 0.5513154003160864
Validation loss: 2.474301135800424

Epoch: 6| Step: 8
Training loss: 0.21233863313529439
Validation loss: 2.504854571059669

Epoch: 6| Step: 9
Training loss: 0.22187956650829915
Validation loss: 2.413557087383411

Epoch: 6| Step: 10
Training loss: 0.42453887340115826
Validation loss: 2.4545013055290203

Epoch: 6| Step: 11
Training loss: 0.4208688039592658
Validation loss: 2.4184938220134606

Epoch: 6| Step: 12
Training loss: 0.524225183211533
Validation loss: 2.426864518743939

Epoch: 6| Step: 13
Training loss: 0.3027306956406009
Validation loss: 2.37173631660322

Epoch: 390| Step: 0
Training loss: 0.2565987075179947
Validation loss: 2.401895732907511

Epoch: 6| Step: 1
Training loss: 0.16680041673460136
Validation loss: 2.4130302994450963

Epoch: 6| Step: 2
Training loss: 0.5191828771522912
Validation loss: 2.4255708385198487

Epoch: 6| Step: 3
Training loss: 0.5109664978757869
Validation loss: 2.3718016223062244

Epoch: 6| Step: 4
Training loss: 0.27047558533985716
Validation loss: 2.394362669094646

Epoch: 6| Step: 5
Training loss: 0.4891170824688645
Validation loss: 2.36768010310958

Epoch: 6| Step: 6
Training loss: 0.3901018836137542
Validation loss: 2.370272709811051

Epoch: 6| Step: 7
Training loss: 0.3150108438282912
Validation loss: 2.3877093541549264

Epoch: 6| Step: 8
Training loss: 0.43495704501825144
Validation loss: 2.4093974750872342

Epoch: 6| Step: 9
Training loss: 0.19409554915729768
Validation loss: 2.376696178994767

Epoch: 6| Step: 10
Training loss: 0.3806832126206282
Validation loss: 2.4220283091935912

Epoch: 6| Step: 11
Training loss: 0.35705063514754476
Validation loss: 2.4155499958667255

Epoch: 6| Step: 12
Training loss: 0.32355701753799077
Validation loss: 2.4173624139019183

Epoch: 6| Step: 13
Training loss: 0.3791179458875022
Validation loss: 2.398903287414082

Epoch: 391| Step: 0
Training loss: 0.34996206725149276
Validation loss: 2.4510137050929615

Epoch: 6| Step: 1
Training loss: 0.4143584111720794
Validation loss: 2.445601317473528

Epoch: 6| Step: 2
Training loss: 0.31475726518207264
Validation loss: 2.388152494618927

Epoch: 6| Step: 3
Training loss: 0.24348366657078865
Validation loss: 2.4254334304621774

Epoch: 6| Step: 4
Training loss: 0.4182897208791381
Validation loss: 2.389567308025015

Epoch: 6| Step: 5
Training loss: 0.3461032642236472
Validation loss: 2.4085269782709706

Epoch: 6| Step: 6
Training loss: 0.2315237982579628
Validation loss: 2.38245694288027

Epoch: 6| Step: 7
Training loss: 0.4278753388024877
Validation loss: 2.4181332086384404

Epoch: 6| Step: 8
Training loss: 0.3481227659294176
Validation loss: 2.447023877616641

Epoch: 6| Step: 9
Training loss: 0.2668350789990727
Validation loss: 2.416726419971095

Epoch: 6| Step: 10
Training loss: 0.4164706683117199
Validation loss: 2.4276286241499045

Epoch: 6| Step: 11
Training loss: 0.5723863025273295
Validation loss: 2.413299957287761

Epoch: 6| Step: 12
Training loss: 0.5090841949317391
Validation loss: 2.4260791364942405

Epoch: 6| Step: 13
Training loss: 0.20429853580886573
Validation loss: 2.42658386485186

Epoch: 392| Step: 0
Training loss: 0.32712849798216326
Validation loss: 2.4604293754422866

Epoch: 6| Step: 1
Training loss: 0.34823258451442324
Validation loss: 2.459758677654183

Epoch: 6| Step: 2
Training loss: 0.4074168686819769
Validation loss: 2.468664360715758

Epoch: 6| Step: 3
Training loss: 0.3925252660588752
Validation loss: 2.4918706883306503

Epoch: 6| Step: 4
Training loss: 0.33760853938270624
Validation loss: 2.4411638162980775

Epoch: 6| Step: 5
Training loss: 0.29007088843004925
Validation loss: 2.489680840557343

Epoch: 6| Step: 6
Training loss: 0.1383657165142444
Validation loss: 2.493960301097293

Epoch: 6| Step: 7
Training loss: 0.5025288882895402
Validation loss: 2.4363600697643437

Epoch: 6| Step: 8
Training loss: 0.4107283099664855
Validation loss: 2.421460649530858

Epoch: 6| Step: 9
Training loss: 0.3901839245631319
Validation loss: 2.395942655176267

Epoch: 6| Step: 10
Training loss: 0.14841732716261677
Validation loss: 2.375123677598291

Epoch: 6| Step: 11
Training loss: 0.33687262902283593
Validation loss: 2.3903502370002108

Epoch: 6| Step: 12
Training loss: 0.49183333233753923
Validation loss: 2.3814194497718564

Epoch: 6| Step: 13
Training loss: 0.4654517325024125
Validation loss: 2.3788040365212164

Epoch: 393| Step: 0
Training loss: 0.20945913987023101
Validation loss: 2.3738707581750655

Epoch: 6| Step: 1
Training loss: 0.356063450105433
Validation loss: 2.3731601358731695

Epoch: 6| Step: 2
Training loss: 0.4736378463005698
Validation loss: 2.36624567223739

Epoch: 6| Step: 3
Training loss: 0.3488059268565162
Validation loss: 2.3816652448755233

Epoch: 6| Step: 4
Training loss: 0.20819452350304768
Validation loss: 2.375103534283285

Epoch: 6| Step: 5
Training loss: 0.17061246651249412
Validation loss: 2.3710251291911515

Epoch: 6| Step: 6
Training loss: 0.357767198851631
Validation loss: 2.3992228503362543

Epoch: 6| Step: 7
Training loss: 0.3390166642810915
Validation loss: 2.3783113525262163

Epoch: 6| Step: 8
Training loss: 0.2867610531192403
Validation loss: 2.372173953036154

Epoch: 6| Step: 9
Training loss: 0.29876030046270935
Validation loss: 2.4146074136087505

Epoch: 6| Step: 10
Training loss: 0.774370343776987
Validation loss: 2.4363066605266765

Epoch: 6| Step: 11
Training loss: 0.22471539856055114
Validation loss: 2.421477462951136

Epoch: 6| Step: 12
Training loss: 0.2053690708439884
Validation loss: 2.448378737455358

Epoch: 6| Step: 13
Training loss: 0.5981392996422997
Validation loss: 2.466429605777208

Epoch: 394| Step: 0
Training loss: 0.3060076430922949
Validation loss: 2.4626592766681177

Epoch: 6| Step: 1
Training loss: 0.28952439237770805
Validation loss: 2.488325789883268

Epoch: 6| Step: 2
Training loss: 0.41074494394056776
Validation loss: 2.4836054568674504

Epoch: 6| Step: 3
Training loss: 0.2727993193563377
Validation loss: 2.4326366996600917

Epoch: 6| Step: 4
Training loss: 0.544858675884378
Validation loss: 2.4532144129306244

Epoch: 6| Step: 5
Training loss: 0.16560033016193518
Validation loss: 2.441358949264571

Epoch: 6| Step: 6
Training loss: 0.1972257743845391
Validation loss: 2.42404432681798

Epoch: 6| Step: 7
Training loss: 0.4752282397381973
Validation loss: 2.461318232417143

Epoch: 6| Step: 8
Training loss: 0.45948994165189655
Validation loss: 2.439294428536912

Epoch: 6| Step: 9
Training loss: 0.3887922206103818
Validation loss: 2.4353217569655246

Epoch: 6| Step: 10
Training loss: 0.32033766670914887
Validation loss: 2.4401903726355556

Epoch: 6| Step: 11
Training loss: 0.47928507696303874
Validation loss: 2.431935709716931

Epoch: 6| Step: 12
Training loss: 0.3407959806397207
Validation loss: 2.417990916452354

Epoch: 6| Step: 13
Training loss: 0.4289607404271095
Validation loss: 2.4285696271500354

Epoch: 395| Step: 0
Training loss: 0.28318882610134316
Validation loss: 2.425620105409552

Epoch: 6| Step: 1
Training loss: 0.6001888792448553
Validation loss: 2.4459233267248077

Epoch: 6| Step: 2
Training loss: 0.2643937014555268
Validation loss: 2.43424680881151

Epoch: 6| Step: 3
Training loss: 0.2399901567616148
Validation loss: 2.4637901917735747

Epoch: 6| Step: 4
Training loss: 0.3406860065074062
Validation loss: 2.4486691908561604

Epoch: 6| Step: 5
Training loss: 0.3277133334728834
Validation loss: 2.438075556928903

Epoch: 6| Step: 6
Training loss: 0.3120819991689735
Validation loss: 2.4251610498090743

Epoch: 6| Step: 7
Training loss: 0.38343777486329617
Validation loss: 2.41331146777645

Epoch: 6| Step: 8
Training loss: 0.4768390790976934
Validation loss: 2.4571955241002126

Epoch: 6| Step: 9
Training loss: 0.40173197038663877
Validation loss: 2.499340503623205

Epoch: 6| Step: 10
Training loss: 0.3580592574779936
Validation loss: 2.464477396387495

Epoch: 6| Step: 11
Training loss: 0.5105613256976347
Validation loss: 2.5008495323039033

Epoch: 6| Step: 12
Training loss: 0.430722775425326
Validation loss: 2.5008408824284056

Epoch: 6| Step: 13
Training loss: 0.4440548185668015
Validation loss: 2.4409294855381223

Epoch: 396| Step: 0
Training loss: 0.4989705365652431
Validation loss: 2.4308463935664744

Epoch: 6| Step: 1
Training loss: 0.5853511674107672
Validation loss: 2.3729410492009873

Epoch: 6| Step: 2
Training loss: 0.41596963117779984
Validation loss: 2.407342670934219

Epoch: 6| Step: 3
Training loss: 0.38351722000483557
Validation loss: 2.4384991396814377

Epoch: 6| Step: 4
Training loss: 0.18676846572565334
Validation loss: 2.4021941982740085

Epoch: 6| Step: 5
Training loss: 0.2966523967192491
Validation loss: 2.3888102246457215

Epoch: 6| Step: 6
Training loss: 0.4871827854126573
Validation loss: 2.4231310162045614

Epoch: 6| Step: 7
Training loss: 0.30059150804658574
Validation loss: 2.395920148848631

Epoch: 6| Step: 8
Training loss: 0.4755885693988392
Validation loss: 2.4109575727115495

Epoch: 6| Step: 9
Training loss: 0.3019559142069037
Validation loss: 2.392931335106798

Epoch: 6| Step: 10
Training loss: 0.3109819735058795
Validation loss: 2.4063147355166548

Epoch: 6| Step: 11
Training loss: 0.37514044198092067
Validation loss: 2.416696911779214

Epoch: 6| Step: 12
Training loss: 0.20854349959809998
Validation loss: 2.4245469870816834

Epoch: 6| Step: 13
Training loss: 0.36341457586569764
Validation loss: 2.477138845714044

Epoch: 397| Step: 0
Training loss: 0.3133085876295147
Validation loss: 2.4372224368362674

Epoch: 6| Step: 1
Training loss: 0.323994340561665
Validation loss: 2.4340943113178883

Epoch: 6| Step: 2
Training loss: 0.5769933243618236
Validation loss: 2.3804905577058015

Epoch: 6| Step: 3
Training loss: 0.1711464199881116
Validation loss: 2.400603380739354

Epoch: 6| Step: 4
Training loss: 0.40587697876687845
Validation loss: 2.426288240188688

Epoch: 6| Step: 5
Training loss: 0.49767190618156515
Validation loss: 2.3914263269193703

Epoch: 6| Step: 6
Training loss: 0.3199857347631722
Validation loss: 2.400945995253141

Epoch: 6| Step: 7
Training loss: 0.4050005810050564
Validation loss: 2.3831555056933755

Epoch: 6| Step: 8
Training loss: 0.38402974975352494
Validation loss: 2.3680409686911212

Epoch: 6| Step: 9
Training loss: 0.5174714464335874
Validation loss: 2.3936798707879587

Epoch: 6| Step: 10
Training loss: 0.2713109841769041
Validation loss: 2.366865739100369

Epoch: 6| Step: 11
Training loss: 0.5013944136237989
Validation loss: 2.4196424077151244

Epoch: 6| Step: 12
Training loss: 0.3570029508364562
Validation loss: 2.4028568088460034

Epoch: 6| Step: 13
Training loss: 0.17947404041227705
Validation loss: 2.3672048849055445

Epoch: 398| Step: 0
Training loss: 0.502973180575379
Validation loss: 2.374788545285097

Epoch: 6| Step: 1
Training loss: 0.5503459319357951
Validation loss: 2.3919429664759475

Epoch: 6| Step: 2
Training loss: 0.33955865718647826
Validation loss: 2.4330475441998507

Epoch: 6| Step: 3
Training loss: 0.373973215580938
Validation loss: 2.425736486456443

Epoch: 6| Step: 4
Training loss: 0.3152935454698813
Validation loss: 2.436076993354867

Epoch: 6| Step: 5
Training loss: 0.26884674836991695
Validation loss: 2.4262872311258423

Epoch: 6| Step: 6
Training loss: 0.44549782560761914
Validation loss: 2.457551703300107

Epoch: 6| Step: 7
Training loss: 0.2994458041750501
Validation loss: 2.448758693723753

Epoch: 6| Step: 8
Training loss: 0.37717709780605435
Validation loss: 2.4726922224197336

Epoch: 6| Step: 9
Training loss: 0.40368890429989435
Validation loss: 2.455777588777316

Epoch: 6| Step: 10
Training loss: 0.31103230569392604
Validation loss: 2.4460036769909705

Epoch: 6| Step: 11
Training loss: 0.5290549312980747
Validation loss: 2.466302757668735

Epoch: 6| Step: 12
Training loss: 0.1577308811974124
Validation loss: 2.435444322873581

Epoch: 6| Step: 13
Training loss: 0.3418719508960889
Validation loss: 2.468206410955669

Epoch: 399| Step: 0
Training loss: 0.3720039448657114
Validation loss: 2.4514629674072306

Epoch: 6| Step: 1
Training loss: 0.39916844732263007
Validation loss: 2.4852528862004215

Epoch: 6| Step: 2
Training loss: 0.27340140785710804
Validation loss: 2.42101731371038

Epoch: 6| Step: 3
Training loss: 0.4607355515930778
Validation loss: 2.4099536780772235

Epoch: 6| Step: 4
Training loss: 0.38534544810854515
Validation loss: 2.434363796842266

Epoch: 6| Step: 5
Training loss: 0.5432182946097072
Validation loss: 2.380198318037806

Epoch: 6| Step: 6
Training loss: 0.21975348413632564
Validation loss: 2.3779177200458594

Epoch: 6| Step: 7
Training loss: 0.1851309682591059
Validation loss: 2.445406768867809

Epoch: 6| Step: 8
Training loss: 0.41854398128970177
Validation loss: 2.4410513855001015

Epoch: 6| Step: 9
Training loss: 0.32895097768208914
Validation loss: 2.4465512120885036

Epoch: 6| Step: 10
Training loss: 0.4225839556564887
Validation loss: 2.4080985375682986

Epoch: 6| Step: 11
Training loss: 0.37864109475355345
Validation loss: 2.3936938280709548

Epoch: 6| Step: 12
Training loss: 0.36066528558084715
Validation loss: 2.3868032898688067

Epoch: 6| Step: 13
Training loss: 0.2838577334445295
Validation loss: 2.380590730212933

Epoch: 400| Step: 0
Training loss: 0.26179820605389015
Validation loss: 2.4004050548366087

Epoch: 6| Step: 1
Training loss: 0.35351762718350277
Validation loss: 2.3828844543384085

Epoch: 6| Step: 2
Training loss: 0.3059676980924013
Validation loss: 2.384975290596769

Epoch: 6| Step: 3
Training loss: 0.24300160017291228
Validation loss: 2.407469615228083

Epoch: 6| Step: 4
Training loss: 0.2661547287327225
Validation loss: 2.435927389377641

Epoch: 6| Step: 5
Training loss: 0.3243324585950516
Validation loss: 2.4122426342000374

Epoch: 6| Step: 6
Training loss: 0.3943752320254168
Validation loss: 2.428823003305237

Epoch: 6| Step: 7
Training loss: 0.3676751125375206
Validation loss: 2.4691751606481755

Epoch: 6| Step: 8
Training loss: 0.47546369481603906
Validation loss: 2.3830544701068073

Epoch: 6| Step: 9
Training loss: 0.3897311283030325
Validation loss: 2.377997981855284

Epoch: 6| Step: 10
Training loss: 0.4773364114899633
Validation loss: 2.4049147331841327

Epoch: 6| Step: 11
Training loss: 0.5056244588219537
Validation loss: 2.403849021957239

Epoch: 6| Step: 12
Training loss: 0.42829057596345316
Validation loss: 2.3850808662021463

Epoch: 6| Step: 13
Training loss: 0.2935577321354685
Validation loss: 2.404250372183391

Testing loss: 2.4662023347842688
