Epoch: 1| Step: 0
Training loss: 5.394709446730976
Validation loss: 5.853497801509841

Epoch: 6| Step: 1
Training loss: 6.1771282775513265
Validation loss: 5.827255022657942

Epoch: 6| Step: 2
Training loss: 7.01544828128626
Validation loss: 5.802123586162622

Epoch: 6| Step: 3
Training loss: 5.096303101057821
Validation loss: 5.775155608643883

Epoch: 6| Step: 4
Training loss: 5.773029152930542
Validation loss: 5.746632642633592

Epoch: 6| Step: 5
Training loss: 6.600535873853083
Validation loss: 5.713065156068265

Epoch: 6| Step: 6
Training loss: 6.501272810514744
Validation loss: 5.675506961193362

Epoch: 6| Step: 7
Training loss: 6.4765147907998495
Validation loss: 5.631763274456442

Epoch: 6| Step: 8
Training loss: 5.282365128203109
Validation loss: 5.580316698697165

Epoch: 6| Step: 9
Training loss: 5.108199331362819
Validation loss: 5.523457535899426

Epoch: 6| Step: 10
Training loss: 6.038125660071708
Validation loss: 5.458597968527266

Epoch: 6| Step: 11
Training loss: 3.4691134425660657
Validation loss: 5.389152020530186

Epoch: 6| Step: 12
Training loss: 5.032238596585892
Validation loss: 5.3125375243278645

Epoch: 6| Step: 13
Training loss: 3.1766764562668786
Validation loss: 5.230933876153401

Epoch: 2| Step: 0
Training loss: 5.559330240705235
Validation loss: 5.147431597889253

Epoch: 6| Step: 1
Training loss: 4.9677529924203325
Validation loss: 5.061577063983934

Epoch: 6| Step: 2
Training loss: 5.48949069886584
Validation loss: 4.9731468744406495

Epoch: 6| Step: 3
Training loss: 4.693700732748469
Validation loss: 4.886079701191422

Epoch: 6| Step: 4
Training loss: 5.617000401634567
Validation loss: 4.802310381508867

Epoch: 6| Step: 5
Training loss: 4.779632095160452
Validation loss: 4.721447438848036

Epoch: 6| Step: 6
Training loss: 4.782895671391753
Validation loss: 4.645062457364059

Epoch: 6| Step: 7
Training loss: 4.641307639317093
Validation loss: 4.571351160957477

Epoch: 6| Step: 8
Training loss: 4.270093875540984
Validation loss: 4.502624237618014

Epoch: 6| Step: 9
Training loss: 4.545216890537926
Validation loss: 4.437411545283935

Epoch: 6| Step: 10
Training loss: 4.006822251796942
Validation loss: 4.379247581134279

Epoch: 6| Step: 11
Training loss: 3.8444195916236774
Validation loss: 4.332030915048433

Epoch: 6| Step: 12
Training loss: 4.970517977580817
Validation loss: 4.2871582829764385

Epoch: 6| Step: 13
Training loss: 3.696255650237031
Validation loss: 4.246623042170991

Epoch: 3| Step: 0
Training loss: 4.419139002143254
Validation loss: 4.2031760977552155

Epoch: 6| Step: 1
Training loss: 4.418799958762732
Validation loss: 4.160004613588234

Epoch: 6| Step: 2
Training loss: 4.854762006715232
Validation loss: 4.119626577295619

Epoch: 6| Step: 3
Training loss: 4.133855388856335
Validation loss: 4.082753415057711

Epoch: 6| Step: 4
Training loss: 3.3310811699603264
Validation loss: 4.045413647706105

Epoch: 6| Step: 5
Training loss: 5.023503565613392
Validation loss: 4.009418791164437

Epoch: 6| Step: 6
Training loss: 3.9501240916014644
Validation loss: 3.9739093622942603

Epoch: 6| Step: 7
Training loss: 4.644547471257943
Validation loss: 3.9449803515812283

Epoch: 6| Step: 8
Training loss: 4.601259904895869
Validation loss: 3.915076571642839

Epoch: 6| Step: 9
Training loss: 4.20142020782203
Validation loss: 3.8844681077644396

Epoch: 6| Step: 10
Training loss: 3.811529567595314
Validation loss: 3.8559155984497933

Epoch: 6| Step: 11
Training loss: 3.1765449609755443
Validation loss: 3.832007476233484

Epoch: 6| Step: 12
Training loss: 3.127878770464445
Validation loss: 3.8113590969598854

Epoch: 6| Step: 13
Training loss: 3.4960847481553103
Validation loss: 3.794283451505812

Epoch: 4| Step: 0
Training loss: 3.901989497848604
Validation loss: 3.7764301136174616

Epoch: 6| Step: 1
Training loss: 4.343396947770079
Validation loss: 3.7565167384480906

Epoch: 6| Step: 2
Training loss: 3.549219104683699
Validation loss: 3.727015296086989

Epoch: 6| Step: 3
Training loss: 2.9148174054650746
Validation loss: 3.7072089770827876

Epoch: 6| Step: 4
Training loss: 4.255448383235639
Validation loss: 3.6938907812797597

Epoch: 6| Step: 5
Training loss: 2.8158054848594305
Validation loss: 3.675854698175211

Epoch: 6| Step: 6
Training loss: 4.340872930115572
Validation loss: 3.6563447937002214

Epoch: 6| Step: 7
Training loss: 3.965734222086378
Validation loss: 3.633324152966955

Epoch: 6| Step: 8
Training loss: 3.5935753821367946
Validation loss: 3.6137983015722432

Epoch: 6| Step: 9
Training loss: 4.315202833516029
Validation loss: 3.597014694086286

Epoch: 6| Step: 10
Training loss: 3.891260547127355
Validation loss: 3.57530581308438

Epoch: 6| Step: 11
Training loss: 3.8781835952746264
Validation loss: 3.5548193040689617

Epoch: 6| Step: 12
Training loss: 4.374016133443053
Validation loss: 3.5369400758782454

Epoch: 6| Step: 13
Training loss: 2.3829054517282513
Validation loss: 3.5168642080049906

Epoch: 5| Step: 0
Training loss: 3.2738986544015063
Validation loss: 3.50224234273624

Epoch: 6| Step: 1
Training loss: 3.0008519870213948
Validation loss: 3.484550899474891

Epoch: 6| Step: 2
Training loss: 4.660421666071732
Validation loss: 3.4641338741726773

Epoch: 6| Step: 3
Training loss: 3.348468624082484
Validation loss: 3.43725714398979

Epoch: 6| Step: 4
Training loss: 3.2478683523548972
Validation loss: 3.4208579363810085

Epoch: 6| Step: 5
Training loss: 3.512183102468274
Validation loss: 3.4097668872397318

Epoch: 6| Step: 6
Training loss: 3.3521668216099187
Validation loss: 3.399914519485904

Epoch: 6| Step: 7
Training loss: 3.05265346231942
Validation loss: 3.386947850988369

Epoch: 6| Step: 8
Training loss: 2.6065539797973045
Validation loss: 3.3707369303258203

Epoch: 6| Step: 9
Training loss: 3.6520734880789436
Validation loss: 3.3564672960141837

Epoch: 6| Step: 10
Training loss: 3.8813495911921994
Validation loss: 3.3459984686516107

Epoch: 6| Step: 11
Training loss: 4.371515684924958
Validation loss: 3.333900076359962

Epoch: 6| Step: 12
Training loss: 4.290820485862177
Validation loss: 3.3215432888295946

Epoch: 6| Step: 13
Training loss: 3.91718330763481
Validation loss: 3.306198565536641

Epoch: 6| Step: 0
Training loss: 3.120005316362987
Validation loss: 3.287620497432732

Epoch: 6| Step: 1
Training loss: 3.5289217945404263
Validation loss: 3.281002126336693

Epoch: 6| Step: 2
Training loss: 3.8735545754291527
Validation loss: 3.276466333626987

Epoch: 6| Step: 3
Training loss: 3.349380173918523
Validation loss: 3.2595333908105335

Epoch: 6| Step: 4
Training loss: 3.984883354518811
Validation loss: 3.25900943699844

Epoch: 6| Step: 5
Training loss: 3.0307080285768175
Validation loss: 3.2395340788771794

Epoch: 6| Step: 6
Training loss: 3.8749596378316276
Validation loss: 3.2354892030025715

Epoch: 6| Step: 7
Training loss: 3.5697464442034703
Validation loss: 3.2226199222430094

Epoch: 6| Step: 8
Training loss: 3.725625742128449
Validation loss: 3.2119675950482596

Epoch: 6| Step: 9
Training loss: 3.0610996080733597
Validation loss: 3.2017903634570297

Epoch: 6| Step: 10
Training loss: 3.111117694106025
Validation loss: 3.1971602613359544

Epoch: 6| Step: 11
Training loss: 3.29094940933943
Validation loss: 3.189916622365662

Epoch: 6| Step: 12
Training loss: 3.6523079773482094
Validation loss: 3.1824835451960887

Epoch: 6| Step: 13
Training loss: 3.4453368586157054
Validation loss: 3.1759789193223686

Epoch: 7| Step: 0
Training loss: 3.267221453000886
Validation loss: 3.1931464996939454

Epoch: 6| Step: 1
Training loss: 3.6992713416932066
Validation loss: 3.1660828551466413

Epoch: 6| Step: 2
Training loss: 3.577492204040521
Validation loss: 3.1715397431545043

Epoch: 6| Step: 3
Training loss: 3.809287546983108
Validation loss: 3.16704650850331

Epoch: 6| Step: 4
Training loss: 3.1589830104447096
Validation loss: 3.157049564537719

Epoch: 6| Step: 5
Training loss: 3.424435985375129
Validation loss: 3.1560052553243314

Epoch: 6| Step: 6
Training loss: 3.1003775459005025
Validation loss: 3.1499311415201756

Epoch: 6| Step: 7
Training loss: 3.751899365383009
Validation loss: 3.1456782539041246

Epoch: 6| Step: 8
Training loss: 2.869196299823591
Validation loss: 3.143088372838543

Epoch: 6| Step: 9
Training loss: 2.370668476811345
Validation loss: 3.1400554672997423

Epoch: 6| Step: 10
Training loss: 3.5434491926350704
Validation loss: 3.1369754845209536

Epoch: 6| Step: 11
Training loss: 3.6772166255894185
Validation loss: 3.1256345108836694

Epoch: 6| Step: 12
Training loss: 3.7176776269421494
Validation loss: 3.1154522530340016

Epoch: 6| Step: 13
Training loss: 3.753456303110555
Validation loss: 3.1139796705668097

Epoch: 8| Step: 0
Training loss: 3.381442243995171
Validation loss: 3.1089762325157126

Epoch: 6| Step: 1
Training loss: 3.539381404428348
Validation loss: 3.1105939899968753

Epoch: 6| Step: 2
Training loss: 3.147125652373316
Validation loss: 3.105771134820386

Epoch: 6| Step: 3
Training loss: 3.8453271622980822
Validation loss: 3.098116364248357

Epoch: 6| Step: 4
Training loss: 3.006399640266921
Validation loss: 3.0837169520542305

Epoch: 6| Step: 5
Training loss: 3.598176966125099
Validation loss: 3.0783256022731225

Epoch: 6| Step: 6
Training loss: 2.5730349144166085
Validation loss: 3.06579227710938

Epoch: 6| Step: 7
Training loss: 3.060624930452078
Validation loss: 3.0590781557201816

Epoch: 6| Step: 8
Training loss: 4.030767367547904
Validation loss: 3.051937997032845

Epoch: 6| Step: 9
Training loss: 3.116763896411488
Validation loss: 3.047662414999963

Epoch: 6| Step: 10
Training loss: 3.487641039768547
Validation loss: 3.0471294085461156

Epoch: 6| Step: 11
Training loss: 2.1388047547189983
Validation loss: 3.0460815322052297

Epoch: 6| Step: 12
Training loss: 3.7250244037417635
Validation loss: 3.0486186626955387

Epoch: 6| Step: 13
Training loss: 4.177217983951666
Validation loss: 3.047230497687203

Epoch: 9| Step: 0
Training loss: 3.5102735692109075
Validation loss: 3.0414453820144725

Epoch: 6| Step: 1
Training loss: 3.5141959443628035
Validation loss: 3.0386943316280632

Epoch: 6| Step: 2
Training loss: 3.271031189459898
Validation loss: 3.0332401797047406

Epoch: 6| Step: 3
Training loss: 3.592091716801856
Validation loss: 3.0288334576243754

Epoch: 6| Step: 4
Training loss: 2.7965015183323096
Validation loss: 3.0217221580115785

Epoch: 6| Step: 5
Training loss: 3.5663397992765367
Validation loss: 3.0176359053292563

Epoch: 6| Step: 6
Training loss: 2.752559251277475
Validation loss: 3.015276252447663

Epoch: 6| Step: 7
Training loss: 3.900292698562564
Validation loss: 3.010739030144149

Epoch: 6| Step: 8
Training loss: 3.3932508856819226
Validation loss: 3.005154556717701

Epoch: 6| Step: 9
Training loss: 3.2237015941900995
Validation loss: 3.0032430334019953

Epoch: 6| Step: 10
Training loss: 3.120227067949768
Validation loss: 2.9999634114977303

Epoch: 6| Step: 11
Training loss: 3.155451305291127
Validation loss: 2.997872474116251

Epoch: 6| Step: 12
Training loss: 3.4311153420184484
Validation loss: 3.001217200371935

Epoch: 6| Step: 13
Training loss: 2.7256679871092424
Validation loss: 2.9897402487474727

Epoch: 10| Step: 0
Training loss: 3.0495887604177083
Validation loss: 2.990438297819215

Epoch: 6| Step: 1
Training loss: 3.314511965677251
Validation loss: 2.9931707757279917

Epoch: 6| Step: 2
Training loss: 3.089719053662712
Validation loss: 2.9928527484917185

Epoch: 6| Step: 3
Training loss: 3.4681877161632846
Validation loss: 2.9944349033458066

Epoch: 6| Step: 4
Training loss: 3.599374632029739
Validation loss: 2.9940470439183415

Epoch: 6| Step: 5
Training loss: 3.7101469141412338
Validation loss: 2.989480693905035

Epoch: 6| Step: 6
Training loss: 3.3256999032070538
Validation loss: 2.9820607661783898

Epoch: 6| Step: 7
Training loss: 3.165920136110123
Validation loss: 2.977851498787685

Epoch: 6| Step: 8
Training loss: 3.1772088364790543
Validation loss: 2.975123247327255

Epoch: 6| Step: 9
Training loss: 3.51769022998589
Validation loss: 2.9732069495797546

Epoch: 6| Step: 10
Training loss: 2.488799755263922
Validation loss: 2.9702311967366173

Epoch: 6| Step: 11
Training loss: 2.84695857204876
Validation loss: 2.9678805033786286

Epoch: 6| Step: 12
Training loss: 3.2642877934679695
Validation loss: 2.9715210327069532

Epoch: 6| Step: 13
Training loss: 4.083183804842841
Validation loss: 2.967485771140594

Epoch: 11| Step: 0
Training loss: 2.8207688741677135
Validation loss: 2.9663272334646282

Epoch: 6| Step: 1
Training loss: 3.468884439698366
Validation loss: 2.9643422970451025

Epoch: 6| Step: 2
Training loss: 3.9726470076942024
Validation loss: 2.9630550715512896

Epoch: 6| Step: 3
Training loss: 3.103145627724428
Validation loss: 2.9613950092732435

Epoch: 6| Step: 4
Training loss: 3.1784380583237084
Validation loss: 2.9594240856954257

Epoch: 6| Step: 5
Training loss: 3.3424031049426364
Validation loss: 2.958391133260391

Epoch: 6| Step: 6
Training loss: 2.746631379765005
Validation loss: 2.954203924922459

Epoch: 6| Step: 7
Training loss: 3.7290424915858407
Validation loss: 2.951575629841018

Epoch: 6| Step: 8
Training loss: 3.115778324865578
Validation loss: 2.948200459293966

Epoch: 6| Step: 9
Training loss: 3.1957013702667534
Validation loss: 2.9504351967003672

Epoch: 6| Step: 10
Training loss: 3.175339634068616
Validation loss: 2.9527272151138515

Epoch: 6| Step: 11
Training loss: 3.6284103136799377
Validation loss: 2.9461733431348165

Epoch: 6| Step: 12
Training loss: 2.827534144943313
Validation loss: 2.94388771798324

Epoch: 6| Step: 13
Training loss: 3.0964363842254494
Validation loss: 2.9425791803640484

Epoch: 12| Step: 0
Training loss: 2.863278585435322
Validation loss: 2.949192940660774

Epoch: 6| Step: 1
Training loss: 3.1810161991804193
Validation loss: 2.9456626901727287

Epoch: 6| Step: 2
Training loss: 3.7007304630414533
Validation loss: 2.9788859847768996

Epoch: 6| Step: 3
Training loss: 3.045482610782824
Validation loss: 2.9459990946391397

Epoch: 6| Step: 4
Training loss: 3.473689780466582
Validation loss: 2.9364132901241913

Epoch: 6| Step: 5
Training loss: 2.913101324129663
Validation loss: 2.941485768332117

Epoch: 6| Step: 6
Training loss: 4.025423792924974
Validation loss: 2.943245786822745

Epoch: 6| Step: 7
Training loss: 2.2396770605538845
Validation loss: 2.9469949854128497

Epoch: 6| Step: 8
Training loss: 2.7756320061838964
Validation loss: 2.9523076731355284

Epoch: 6| Step: 9
Training loss: 3.6422539860807475
Validation loss: 2.9438205828013406

Epoch: 6| Step: 10
Training loss: 3.5021781955437796
Validation loss: 2.931769049044009

Epoch: 6| Step: 11
Training loss: 3.4079865395007016
Validation loss: 2.928546675632162

Epoch: 6| Step: 12
Training loss: 3.590619390498229
Validation loss: 2.9166912698953236

Epoch: 6| Step: 13
Training loss: 2.2789528136781234
Validation loss: 2.913543944470655

Epoch: 13| Step: 0
Training loss: 3.216559396117983
Validation loss: 2.9246886185867087

Epoch: 6| Step: 1
Training loss: 2.9737315895950607
Validation loss: 2.9443000843652314

Epoch: 6| Step: 2
Training loss: 3.269715152431409
Validation loss: 2.938650242461196

Epoch: 6| Step: 3
Training loss: 3.2102445054147974
Validation loss: 2.9222887014024903

Epoch: 6| Step: 4
Training loss: 2.825622884896813
Validation loss: 2.909023831709113

Epoch: 6| Step: 5
Training loss: 2.736762350673237
Validation loss: 2.909114041697038

Epoch: 6| Step: 6
Training loss: 2.949114947987011
Validation loss: 2.9132102250693683

Epoch: 6| Step: 7
Training loss: 3.6590015458622136
Validation loss: 2.9175724351738834

Epoch: 6| Step: 8
Training loss: 3.598191941065815
Validation loss: 2.9045792539672837

Epoch: 6| Step: 9
Training loss: 4.033472439177258
Validation loss: 2.899125003741767

Epoch: 6| Step: 10
Training loss: 2.8700764832623173
Validation loss: 2.892322484201719

Epoch: 6| Step: 11
Training loss: 2.2520875783122163
Validation loss: 2.8866148497350848

Epoch: 6| Step: 12
Training loss: 3.7568184217813667
Validation loss: 2.8929998742016605

Epoch: 6| Step: 13
Training loss: 3.5690496369018105
Validation loss: 2.889188638982869

Epoch: 14| Step: 0
Training loss: 3.1868521836147283
Validation loss: 2.88879518604107

Epoch: 6| Step: 1
Training loss: 3.094803139583893
Validation loss: 2.8872990518449733

Epoch: 6| Step: 2
Training loss: 2.471516857413085
Validation loss: 2.8969783937386038

Epoch: 6| Step: 3
Training loss: 3.1911513414683537
Validation loss: 2.9028947029823104

Epoch: 6| Step: 4
Training loss: 3.698016413386609
Validation loss: 2.906471338398982

Epoch: 6| Step: 5
Training loss: 3.422798206386919
Validation loss: 2.8823798643923735

Epoch: 6| Step: 6
Training loss: 2.5092442308606433
Validation loss: 2.8883298693781363

Epoch: 6| Step: 7
Training loss: 3.2786346184879847
Validation loss: 2.89239420317889

Epoch: 6| Step: 8
Training loss: 3.6507152170176407
Validation loss: 2.893008932443862

Epoch: 6| Step: 9
Training loss: 2.9049417155684223
Validation loss: 2.896271563947102

Epoch: 6| Step: 10
Training loss: 3.3999154921856376
Validation loss: 2.891631351487106

Epoch: 6| Step: 11
Training loss: 3.7018613309026613
Validation loss: 2.8852190200485617

Epoch: 6| Step: 12
Training loss: 3.2351424186759092
Validation loss: 2.879031186764136

Epoch: 6| Step: 13
Training loss: 2.5701407053387677
Validation loss: 2.876153355223265

Epoch: 15| Step: 0
Training loss: 3.225951795072403
Validation loss: 2.872887956032499

Epoch: 6| Step: 1
Training loss: 3.244849158074191
Validation loss: 2.8699922789485925

Epoch: 6| Step: 2
Training loss: 1.944146477106234
Validation loss: 2.8694334279828264

Epoch: 6| Step: 3
Training loss: 3.1886304458941925
Validation loss: 2.8720954786552624

Epoch: 6| Step: 4
Training loss: 3.8899497553073763
Validation loss: 2.8737062733005785

Epoch: 6| Step: 5
Training loss: 3.06740473144628
Validation loss: 2.868612161641622

Epoch: 6| Step: 6
Training loss: 3.6126422048912517
Validation loss: 2.8659662399296413

Epoch: 6| Step: 7
Training loss: 2.9078279538899525
Validation loss: 2.8612533685564947

Epoch: 6| Step: 8
Training loss: 3.100400923367834
Validation loss: 2.8624899981210645

Epoch: 6| Step: 9
Training loss: 3.192292892202552
Validation loss: 2.860009708270459

Epoch: 6| Step: 10
Training loss: 3.69563817853302
Validation loss: 2.85568649238173

Epoch: 6| Step: 11
Training loss: 2.9806976830388785
Validation loss: 2.856469192902889

Epoch: 6| Step: 12
Training loss: 3.527500288521953
Validation loss: 2.852623726282139

Epoch: 6| Step: 13
Training loss: 2.052288787419493
Validation loss: 2.8508622187725647

Epoch: 16| Step: 0
Training loss: 2.7946091322994606
Validation loss: 2.8672202804357756

Epoch: 6| Step: 1
Training loss: 3.017739932959518
Validation loss: 2.8881344518732672

Epoch: 6| Step: 2
Training loss: 3.6096122630688834
Validation loss: 2.8862733056137184

Epoch: 6| Step: 3
Training loss: 3.1908728014807317
Validation loss: 2.8534316534263

Epoch: 6| Step: 4
Training loss: 2.7757857576307337
Validation loss: 2.849634003611686

Epoch: 6| Step: 5
Training loss: 3.077009434588538
Validation loss: 2.8516609465961817

Epoch: 6| Step: 6
Training loss: 3.7188671959113027
Validation loss: 2.8734050774575866

Epoch: 6| Step: 7
Training loss: 3.1600026398659797
Validation loss: 2.8574193969695183

Epoch: 6| Step: 8
Training loss: 3.1068000291133058
Validation loss: 2.879046206878415

Epoch: 6| Step: 9
Training loss: 2.684575463515884
Validation loss: 2.863452238955401

Epoch: 6| Step: 10
Training loss: 3.277557911655843
Validation loss: 2.8871567113175844

Epoch: 6| Step: 11
Training loss: 3.660548886274258
Validation loss: 2.902391075068968

Epoch: 6| Step: 12
Training loss: 3.183244444985839
Validation loss: 2.854271010996107

Epoch: 6| Step: 13
Training loss: 3.3339290245570155
Validation loss: 2.8523676835800704

Epoch: 17| Step: 0
Training loss: 3.2778033365090087
Validation loss: 2.8792426490104015

Epoch: 6| Step: 1
Training loss: 3.279896629611967
Validation loss: 2.917341965112981

Epoch: 6| Step: 2
Training loss: 2.9018679160747047
Validation loss: 2.941752254160487

Epoch: 6| Step: 3
Training loss: 2.5377437981807933
Validation loss: 2.948167657525102

Epoch: 6| Step: 4
Training loss: 3.23298371840158
Validation loss: 3.0207798857976567

Epoch: 6| Step: 5
Training loss: 3.5056058404146935
Validation loss: 2.9253288440734213

Epoch: 6| Step: 6
Training loss: 3.5950941142999064
Validation loss: 2.8656862449517924

Epoch: 6| Step: 7
Training loss: 2.59905417551641
Validation loss: 2.8359703614168845

Epoch: 6| Step: 8
Training loss: 2.797492955312305
Validation loss: 2.8527600614505904

Epoch: 6| Step: 9
Training loss: 2.950466513519498
Validation loss: 2.921327050963276

Epoch: 6| Step: 10
Training loss: 3.957441664535087
Validation loss: 3.003114165835589

Epoch: 6| Step: 11
Training loss: 3.3578869739934287
Validation loss: 2.9451633090375418

Epoch: 6| Step: 12
Training loss: 2.875594036264745
Validation loss: 2.9179297921763716

Epoch: 6| Step: 13
Training loss: 4.667284288861848
Validation loss: 2.8972891365279914

Epoch: 18| Step: 0
Training loss: 3.1652998400455807
Validation loss: 2.856203773368416

Epoch: 6| Step: 1
Training loss: 2.909465856393411
Validation loss: 2.8491931862050968

Epoch: 6| Step: 2
Training loss: 3.175829597283432
Validation loss: 2.8582458274857356

Epoch: 6| Step: 3
Training loss: 3.076893826492366
Validation loss: 2.8623396160832275

Epoch: 6| Step: 4
Training loss: 3.866058863081691
Validation loss: 2.890434190105763

Epoch: 6| Step: 5
Training loss: 3.5417112160667044
Validation loss: 2.8552762551322526

Epoch: 6| Step: 6
Training loss: 3.0674041096343596
Validation loss: 2.8407364177861556

Epoch: 6| Step: 7
Training loss: 3.07851535239023
Validation loss: 2.836191059645293

Epoch: 6| Step: 8
Training loss: 2.904451859936648
Validation loss: 2.832120140414741

Epoch: 6| Step: 9
Training loss: 2.9042765161946154
Validation loss: 2.831589214154123

Epoch: 6| Step: 10
Training loss: 3.4465952451033957
Validation loss: 2.8284383693217445

Epoch: 6| Step: 11
Training loss: 3.300135442092828
Validation loss: 2.8308311708397325

Epoch: 6| Step: 12
Training loss: 3.2961856067025423
Validation loss: 2.828666367331683

Epoch: 6| Step: 13
Training loss: 2.0397824006806373
Validation loss: 2.8265964839850994

Epoch: 19| Step: 0
Training loss: 2.740910681142221
Validation loss: 2.8267388000018268

Epoch: 6| Step: 1
Training loss: 3.5687271037260806
Validation loss: 2.82894007154609

Epoch: 6| Step: 2
Training loss: 3.8141037116350036
Validation loss: 2.8303601416796753

Epoch: 6| Step: 3
Training loss: 2.9452517880119515
Validation loss: 2.8223275419513585

Epoch: 6| Step: 4
Training loss: 2.8070103793983465
Validation loss: 2.8186283290949685

Epoch: 6| Step: 5
Training loss: 3.0418269668213447
Validation loss: 2.8230508751909116

Epoch: 6| Step: 6
Training loss: 3.0878547989699068
Validation loss: 2.814782746459966

Epoch: 6| Step: 7
Training loss: 3.743499462169936
Validation loss: 2.8140591755747653

Epoch: 6| Step: 8
Training loss: 2.8245685619285568
Validation loss: 2.812663460268962

Epoch: 6| Step: 9
Training loss: 2.7193477455830233
Validation loss: 2.8106422113123384

Epoch: 6| Step: 10
Training loss: 2.6200713254232557
Validation loss: 2.8106121860131883

Epoch: 6| Step: 11
Training loss: 3.2978615392116635
Validation loss: 2.8066235668366097

Epoch: 6| Step: 12
Training loss: 3.7288600149111555
Validation loss: 2.8056852757510047

Epoch: 6| Step: 13
Training loss: 2.6628765251879813
Validation loss: 2.8038873842020977

Epoch: 20| Step: 0
Training loss: 3.6450850381860653
Validation loss: 2.802454310462024

Epoch: 6| Step: 1
Training loss: 3.2550877581835733
Validation loss: 2.8097448757311954

Epoch: 6| Step: 2
Training loss: 2.47077482217488
Validation loss: 2.8216603398709283

Epoch: 6| Step: 3
Training loss: 3.1191525491905763
Validation loss: 2.8368319265362785

Epoch: 6| Step: 4
Training loss: 3.0258898978767
Validation loss: 2.8170901270064057

Epoch: 6| Step: 5
Training loss: 2.5070461159821398
Validation loss: 2.813914977870553

Epoch: 6| Step: 6
Training loss: 3.107960441524168
Validation loss: 2.809957812404255

Epoch: 6| Step: 7
Training loss: 3.237312199510515
Validation loss: 2.834161252613328

Epoch: 6| Step: 8
Training loss: 3.195275490693374
Validation loss: 2.874206965047916

Epoch: 6| Step: 9
Training loss: 2.7893605647310826
Validation loss: 2.8543905450765727

Epoch: 6| Step: 10
Training loss: 3.6912929618446126
Validation loss: 2.8178027316534204

Epoch: 6| Step: 11
Training loss: 3.156128531658622
Validation loss: 2.807314035906909

Epoch: 6| Step: 12
Training loss: 3.5446879496250845
Validation loss: 2.794246766641084

Epoch: 6| Step: 13
Training loss: 2.864473893358077
Validation loss: 2.7933747733979595

Epoch: 21| Step: 0
Training loss: 3.8151928506206287
Validation loss: 2.7976916984871703

Epoch: 6| Step: 1
Training loss: 3.2309112430283733
Validation loss: 2.8083579058110875

Epoch: 6| Step: 2
Training loss: 2.5871891553725814
Validation loss: 2.8140323652858017

Epoch: 6| Step: 3
Training loss: 3.7704740462017576
Validation loss: 2.818839385116967

Epoch: 6| Step: 4
Training loss: 3.4192744436872045
Validation loss: 2.8131664129220195

Epoch: 6| Step: 5
Training loss: 3.1678079924147298
Validation loss: 2.80087789442379

Epoch: 6| Step: 6
Training loss: 3.284665900068566
Validation loss: 2.7999475801632654

Epoch: 6| Step: 7
Training loss: 3.215615681596754
Validation loss: 2.7955330577242012

Epoch: 6| Step: 8
Training loss: 2.8912237423612783
Validation loss: 2.790834415471725

Epoch: 6| Step: 9
Training loss: 3.188369482792305
Validation loss: 2.79043137854353

Epoch: 6| Step: 10
Training loss: 3.0972302830643006
Validation loss: 2.791379946618356

Epoch: 6| Step: 11
Training loss: 1.982969191592264
Validation loss: 2.7899267008413497

Epoch: 6| Step: 12
Training loss: 2.7072507210590606
Validation loss: 2.813573980880301

Epoch: 6| Step: 13
Training loss: 3.0590501934321868
Validation loss: 2.858136504225994

Epoch: 22| Step: 0
Training loss: 3.605387677472508
Validation loss: 2.891081810541548

Epoch: 6| Step: 1
Training loss: 2.5818236667218235
Validation loss: 2.8509471733435587

Epoch: 6| Step: 2
Training loss: 3.4861433391592707
Validation loss: 2.8089655554283777

Epoch: 6| Step: 3
Training loss: 3.428513449791736
Validation loss: 2.778869483972513

Epoch: 6| Step: 4
Training loss: 3.230933085677569
Validation loss: 2.7852065290613925

Epoch: 6| Step: 5
Training loss: 2.6788364315641213
Validation loss: 2.794355423382452

Epoch: 6| Step: 6
Training loss: 2.6280645011987316
Validation loss: 2.7946657562032846

Epoch: 6| Step: 7
Training loss: 3.7820287485790116
Validation loss: 2.793565268579091

Epoch: 6| Step: 8
Training loss: 2.4807324847489443
Validation loss: 2.78670783334219

Epoch: 6| Step: 9
Training loss: 3.586762377042175
Validation loss: 2.7851111284087313

Epoch: 6| Step: 10
Training loss: 2.2785415247702945
Validation loss: 2.779263872955472

Epoch: 6| Step: 11
Training loss: 3.659889301022607
Validation loss: 2.778098091676105

Epoch: 6| Step: 12
Training loss: 3.0134071535447493
Validation loss: 2.7745559805720568

Epoch: 6| Step: 13
Training loss: 2.7835070420688846
Validation loss: 2.774328235457863

Epoch: 23| Step: 0
Training loss: 3.272967684951356
Validation loss: 2.775982344254288

Epoch: 6| Step: 1
Training loss: 2.8419539260726805
Validation loss: 2.7764873599752327

Epoch: 6| Step: 2
Training loss: 3.3873891551896262
Validation loss: 2.7752981745015943

Epoch: 6| Step: 3
Training loss: 3.2260227444645726
Validation loss: 2.773901693461399

Epoch: 6| Step: 4
Training loss: 3.1038239735803588
Validation loss: 2.775674392817812

Epoch: 6| Step: 5
Training loss: 3.0825584743921524
Validation loss: 2.7731181669017113

Epoch: 6| Step: 6
Training loss: 3.0852975688840796
Validation loss: 2.773821876531168

Epoch: 6| Step: 7
Training loss: 3.485076970436688
Validation loss: 2.775088374297399

Epoch: 6| Step: 8
Training loss: 2.904460068653944
Validation loss: 2.774707599153989

Epoch: 6| Step: 9
Training loss: 2.8428017848444935
Validation loss: 2.7700887754957466

Epoch: 6| Step: 10
Training loss: 3.2882777929344504
Validation loss: 2.7701419267152145

Epoch: 6| Step: 11
Training loss: 2.9250021127546457
Validation loss: 2.7741140379008162

Epoch: 6| Step: 12
Training loss: 2.7725991284851497
Validation loss: 2.7826370673968186

Epoch: 6| Step: 13
Training loss: 3.41176487756307
Validation loss: 2.802149761373361

Epoch: 24| Step: 0
Training loss: 3.701729427001982
Validation loss: 2.8035862333027444

Epoch: 6| Step: 1
Training loss: 2.5495645562673457
Validation loss: 2.784904573197164

Epoch: 6| Step: 2
Training loss: 2.963109812364678
Validation loss: 2.7699873122502243

Epoch: 6| Step: 3
Training loss: 2.9735771687630486
Validation loss: 2.7735548739544718

Epoch: 6| Step: 4
Training loss: 2.6557588908648073
Validation loss: 2.7800619849466037

Epoch: 6| Step: 5
Training loss: 3.0798048673471277
Validation loss: 2.798291510650225

Epoch: 6| Step: 6
Training loss: 2.942638205083674
Validation loss: 2.7903242778932955

Epoch: 6| Step: 7
Training loss: 3.497665989435988
Validation loss: 2.7818301274366295

Epoch: 6| Step: 8
Training loss: 3.4642553679270565
Validation loss: 2.7756712580836904

Epoch: 6| Step: 9
Training loss: 3.55284631016971
Validation loss: 2.7658177632995913

Epoch: 6| Step: 10
Training loss: 3.0056077679580167
Validation loss: 2.7633019909760503

Epoch: 6| Step: 11
Training loss: 3.0448050485726466
Validation loss: 2.756512300289173

Epoch: 6| Step: 12
Training loss: 3.075481848452156
Validation loss: 2.7538453724256824

Epoch: 6| Step: 13
Training loss: 2.918248664881142
Validation loss: 2.752798358917603

Epoch: 25| Step: 0
Training loss: 3.6623824116965715
Validation loss: 2.752170040288112

Epoch: 6| Step: 1
Training loss: 3.122001124555934
Validation loss: 2.7519120852505723

Epoch: 6| Step: 2
Training loss: 2.550515223792894
Validation loss: 2.7545693471861257

Epoch: 6| Step: 3
Training loss: 2.7449790895426447
Validation loss: 2.7563054165312644

Epoch: 6| Step: 4
Training loss: 3.3095730499859584
Validation loss: 2.7565475668218213

Epoch: 6| Step: 5
Training loss: 3.284432892874417
Validation loss: 2.7617153617860266

Epoch: 6| Step: 6
Training loss: 3.1323409260685566
Validation loss: 2.7467987878365654

Epoch: 6| Step: 7
Training loss: 2.7344546061235757
Validation loss: 2.7398207385503994

Epoch: 6| Step: 8
Training loss: 2.9450045558719338
Validation loss: 2.739532583150217

Epoch: 6| Step: 9
Training loss: 3.544426833547159
Validation loss: 2.740327012114265

Epoch: 6| Step: 10
Training loss: 3.244778179469278
Validation loss: 2.73719831134003

Epoch: 6| Step: 11
Training loss: 3.0726845001621337
Validation loss: 2.7345385749514444

Epoch: 6| Step: 12
Training loss: 2.79027917647866
Validation loss: 2.73500166455158

Epoch: 6| Step: 13
Training loss: 2.7946882170247895
Validation loss: 2.7324086196520314

Epoch: 26| Step: 0
Training loss: 2.725098487404124
Validation loss: 2.730021150334197

Epoch: 6| Step: 1
Training loss: 3.2004436900580555
Validation loss: 2.7268722710332978

Epoch: 6| Step: 2
Training loss: 2.74903800784327
Validation loss: 2.7263517469022096

Epoch: 6| Step: 3
Training loss: 3.019927597188506
Validation loss: 2.727351242321481

Epoch: 6| Step: 4
Training loss: 2.8694495650872818
Validation loss: 2.7263195069307398

Epoch: 6| Step: 5
Training loss: 2.9347501829754794
Validation loss: 2.727927170160633

Epoch: 6| Step: 6
Training loss: 2.8169605910605378
Validation loss: 2.7235559699528005

Epoch: 6| Step: 7
Training loss: 2.8626613388237
Validation loss: 2.7273221095360363

Epoch: 6| Step: 8
Training loss: 3.6327010599086766
Validation loss: 2.7284152823558743

Epoch: 6| Step: 9
Training loss: 3.479832446569974
Validation loss: 2.7257773611144165

Epoch: 6| Step: 10
Training loss: 3.4958708793312225
Validation loss: 2.7233161493193196

Epoch: 6| Step: 11
Training loss: 2.2819630801718898
Validation loss: 2.7223033162225714

Epoch: 6| Step: 12
Training loss: 3.2652005006411486
Validation loss: 2.7233279898108553

Epoch: 6| Step: 13
Training loss: 3.615875995071036
Validation loss: 2.72198221399969

Epoch: 27| Step: 0
Training loss: 3.325119308969872
Validation loss: 2.7186466622200234

Epoch: 6| Step: 1
Training loss: 3.3837377679192957
Validation loss: 2.722073741245658

Epoch: 6| Step: 2
Training loss: 2.119284854322846
Validation loss: 2.7263792934112385

Epoch: 6| Step: 3
Training loss: 3.269633046597036
Validation loss: 2.7229376783239028

Epoch: 6| Step: 4
Training loss: 3.612315115767929
Validation loss: 2.722158857635947

Epoch: 6| Step: 5
Training loss: 2.827373510174051
Validation loss: 2.7159860385195405

Epoch: 6| Step: 6
Training loss: 2.6169797900319267
Validation loss: 2.715344582082692

Epoch: 6| Step: 7
Training loss: 3.126364448218719
Validation loss: 2.717720395005236

Epoch: 6| Step: 8
Training loss: 2.738336973398784
Validation loss: 2.71301193944709

Epoch: 6| Step: 9
Training loss: 3.1931992983578716
Validation loss: 2.712774018919066

Epoch: 6| Step: 10
Training loss: 3.162856939022635
Validation loss: 2.7149628100902445

Epoch: 6| Step: 11
Training loss: 3.6178419538638233
Validation loss: 2.7108003712211692

Epoch: 6| Step: 12
Training loss: 2.711613551555331
Validation loss: 2.7149685257119742

Epoch: 6| Step: 13
Training loss: 2.4660803931529003
Validation loss: 2.7087404959453556

Epoch: 28| Step: 0
Training loss: 3.059522777569215
Validation loss: 2.704879091086261

Epoch: 6| Step: 1
Training loss: 2.942677257452526
Validation loss: 2.706096159342022

Epoch: 6| Step: 2
Training loss: 3.0826065822221422
Validation loss: 2.7070579296063335

Epoch: 6| Step: 3
Training loss: 1.937356574379666
Validation loss: 2.712811145881997

Epoch: 6| Step: 4
Training loss: 3.0800854012180223
Validation loss: 2.7287818551606096

Epoch: 6| Step: 5
Training loss: 3.1190828378922206
Validation loss: 2.729495889970583

Epoch: 6| Step: 6
Training loss: 2.7049932473428036
Validation loss: 2.723250324360178

Epoch: 6| Step: 7
Training loss: 3.7075884353060595
Validation loss: 2.7235842629311073

Epoch: 6| Step: 8
Training loss: 3.2266245690534157
Validation loss: 2.728815513764145

Epoch: 6| Step: 9
Training loss: 3.134379235337991
Validation loss: 2.717876255736024

Epoch: 6| Step: 10
Training loss: 3.102248723676857
Validation loss: 2.7149572021027604

Epoch: 6| Step: 11
Training loss: 3.308051378997374
Validation loss: 2.6979363946307813

Epoch: 6| Step: 12
Training loss: 3.083470848384877
Validation loss: 2.7007984831060847

Epoch: 6| Step: 13
Training loss: 2.9731825013100344
Validation loss: 2.699855466200139

Epoch: 29| Step: 0
Training loss: 2.7704716687808033
Validation loss: 2.7070130243403896

Epoch: 6| Step: 1
Training loss: 3.0393359691287416
Validation loss: 2.7048128382903376

Epoch: 6| Step: 2
Training loss: 2.5067374043257113
Validation loss: 2.7051590756303265

Epoch: 6| Step: 3
Training loss: 3.329466643363838
Validation loss: 2.7029271112337394

Epoch: 6| Step: 4
Training loss: 2.349376384697151
Validation loss: 2.7003659819535453

Epoch: 6| Step: 5
Training loss: 3.1788769937904786
Validation loss: 2.6972397923486477

Epoch: 6| Step: 6
Training loss: 3.055242853829139
Validation loss: 2.6983510589924413

Epoch: 6| Step: 7
Training loss: 3.826753580876354
Validation loss: 2.697721565411686

Epoch: 6| Step: 8
Training loss: 3.4631588525912655
Validation loss: 2.698328511676535

Epoch: 6| Step: 9
Training loss: 3.386397719429919
Validation loss: 2.700929922567805

Epoch: 6| Step: 10
Training loss: 2.8404186144428496
Validation loss: 2.7042482029308363

Epoch: 6| Step: 11
Training loss: 3.2290537824691192
Validation loss: 2.7035940847889317

Epoch: 6| Step: 12
Training loss: 2.102468869481175
Validation loss: 2.7005410605948015

Epoch: 6| Step: 13
Training loss: 3.3364553295308164
Validation loss: 2.703886742413091

Epoch: 30| Step: 0
Training loss: 3.1353563744376114
Validation loss: 2.7049684267660057

Epoch: 6| Step: 1
Training loss: 3.165749935836689
Validation loss: 2.7073601601607895

Epoch: 6| Step: 2
Training loss: 2.631639802379686
Validation loss: 2.711597764720249

Epoch: 6| Step: 3
Training loss: 3.085121529780573
Validation loss: 2.698360273771217

Epoch: 6| Step: 4
Training loss: 2.9957434338772493
Validation loss: 2.6992028469816716

Epoch: 6| Step: 5
Training loss: 3.160220377758256
Validation loss: 2.6889017279067082

Epoch: 6| Step: 6
Training loss: 3.067124592412388
Validation loss: 2.6863544690826657

Epoch: 6| Step: 7
Training loss: 2.8056372094520725
Validation loss: 2.6836846874125087

Epoch: 6| Step: 8
Training loss: 2.3809619158599307
Validation loss: 2.686430929986923

Epoch: 6| Step: 9
Training loss: 2.750467780815777
Validation loss: 2.6833867320415745

Epoch: 6| Step: 10
Training loss: 3.23491041386654
Validation loss: 2.68878921394076

Epoch: 6| Step: 11
Training loss: 3.4491841885832164
Validation loss: 2.6873096552237654

Epoch: 6| Step: 12
Training loss: 2.825435729730141
Validation loss: 2.6881042053112782

Epoch: 6| Step: 13
Training loss: 3.9240412713543154
Validation loss: 2.6846410736443946

Epoch: 31| Step: 0
Training loss: 3.4815626897727094
Validation loss: 2.685992507549306

Epoch: 6| Step: 1
Training loss: 2.361160916071167
Validation loss: 2.684122929976716

Epoch: 6| Step: 2
Training loss: 3.449025339858046
Validation loss: 2.6844619278299504

Epoch: 6| Step: 3
Training loss: 3.197601617625545
Validation loss: 2.6808871150370686

Epoch: 6| Step: 4
Training loss: 1.9171214048002825
Validation loss: 2.6774146464460014

Epoch: 6| Step: 5
Training loss: 2.689582904684642
Validation loss: 2.6809596716783144

Epoch: 6| Step: 6
Training loss: 2.1610571308907205
Validation loss: 2.686302425715239

Epoch: 6| Step: 7
Training loss: 3.7124837444733028
Validation loss: 2.6994704808565935

Epoch: 6| Step: 8
Training loss: 3.0700775134213676
Validation loss: 2.6896026200644743

Epoch: 6| Step: 9
Training loss: 3.5237796050658625
Validation loss: 2.6759394567258816

Epoch: 6| Step: 10
Training loss: 2.63341427046898
Validation loss: 2.6766999576157295

Epoch: 6| Step: 11
Training loss: 3.257167541917082
Validation loss: 2.691042978814416

Epoch: 6| Step: 12
Training loss: 2.912398530559591
Validation loss: 2.6989005606927465

Epoch: 6| Step: 13
Training loss: 3.85084276264365
Validation loss: 2.724654254653231

Epoch: 32| Step: 0
Training loss: 2.89833681492069
Validation loss: 2.737400994725547

Epoch: 6| Step: 1
Training loss: 2.80649272659096
Validation loss: 2.7444105626077993

Epoch: 6| Step: 2
Training loss: 3.6636967913675864
Validation loss: 2.7493172000198287

Epoch: 6| Step: 3
Training loss: 2.7719639261769125
Validation loss: 2.7486330104555314

Epoch: 6| Step: 4
Training loss: 2.7648634212211265
Validation loss: 2.7349163010683024

Epoch: 6| Step: 5
Training loss: 3.230668602588476
Validation loss: 2.7297061345344895

Epoch: 6| Step: 6
Training loss: 2.8081179071163187
Validation loss: 2.727357586202041

Epoch: 6| Step: 7
Training loss: 3.2200208210716226
Validation loss: 2.725442978256287

Epoch: 6| Step: 8
Training loss: 3.1440315560366128
Validation loss: 2.720570508381146

Epoch: 6| Step: 9
Training loss: 3.4772727669383254
Validation loss: 2.7222182589704325

Epoch: 6| Step: 10
Training loss: 2.8283729233796726
Validation loss: 2.7047283902086785

Epoch: 6| Step: 11
Training loss: 2.8439049311762092
Validation loss: 2.673568455182213

Epoch: 6| Step: 12
Training loss: 3.238495786253329
Validation loss: 2.681619916111062

Epoch: 6| Step: 13
Training loss: 3.1536869935747243
Validation loss: 2.684374129171425

Epoch: 33| Step: 0
Training loss: 3.4541298625413326
Validation loss: 2.7083101812718815

Epoch: 6| Step: 1
Training loss: 2.7455800689765235
Validation loss: 2.728592618193521

Epoch: 6| Step: 2
Training loss: 2.845960491536164
Validation loss: 2.7542461752455027

Epoch: 6| Step: 3
Training loss: 2.9942938260911824
Validation loss: 2.7858620546239217

Epoch: 6| Step: 4
Training loss: 2.6530872140087514
Validation loss: 2.774993294653551

Epoch: 6| Step: 5
Training loss: 3.671494614397827
Validation loss: 2.7884996902868786

Epoch: 6| Step: 6
Training loss: 3.291016784124425
Validation loss: 2.6838876581479116

Epoch: 6| Step: 7
Training loss: 2.789007448139278
Validation loss: 2.660869128524522

Epoch: 6| Step: 8
Training loss: 3.1960200713175517
Validation loss: 2.6697699758077835

Epoch: 6| Step: 9
Training loss: 2.586973783639635
Validation loss: 2.676205585301602

Epoch: 6| Step: 10
Training loss: 3.0167996189332658
Validation loss: 2.707078694855574

Epoch: 6| Step: 11
Training loss: 2.8945045624402295
Validation loss: 2.725447109041414

Epoch: 6| Step: 12
Training loss: 3.0845146665479506
Validation loss: 2.752077546580573

Epoch: 6| Step: 13
Training loss: 3.6467835559510626
Validation loss: 2.698811124846293

Epoch: 34| Step: 0
Training loss: 2.641763656071181
Validation loss: 2.6849812014977656

Epoch: 6| Step: 1
Training loss: 3.1486604294525
Validation loss: 2.675448268875303

Epoch: 6| Step: 2
Training loss: 3.4694971877901826
Validation loss: 2.669659822554704

Epoch: 6| Step: 3
Training loss: 2.5556244138295767
Validation loss: 2.6719725468144278

Epoch: 6| Step: 4
Training loss: 3.3027670039229453
Validation loss: 2.6680701591201346

Epoch: 6| Step: 5
Training loss: 2.6965168349329214
Validation loss: 2.6643389645390356

Epoch: 6| Step: 6
Training loss: 3.271436712572578
Validation loss: 2.6607997103350853

Epoch: 6| Step: 7
Training loss: 3.161560727283252
Validation loss: 2.6619423046815713

Epoch: 6| Step: 8
Training loss: 2.8371870162363457
Validation loss: 2.6737102257026297

Epoch: 6| Step: 9
Training loss: 2.3409911130388563
Validation loss: 2.673683945888469

Epoch: 6| Step: 10
Training loss: 2.667264652756497
Validation loss: 2.69443110315507

Epoch: 6| Step: 11
Training loss: 2.885063636382068
Validation loss: 2.7130765377909984

Epoch: 6| Step: 12
Training loss: 3.807642860061888
Validation loss: 2.7033753495799955

Epoch: 6| Step: 13
Training loss: 3.5408402918705866
Validation loss: 2.656308450845951

Epoch: 35| Step: 0
Training loss: 3.158026016166843
Validation loss: 2.64791122639539

Epoch: 6| Step: 1
Training loss: 2.8850228124605826
Validation loss: 2.6478737945608812

Epoch: 6| Step: 2
Training loss: 2.9815430311225675
Validation loss: 2.6541257081403673

Epoch: 6| Step: 3
Training loss: 3.0031041933543663
Validation loss: 2.6568131643063118

Epoch: 6| Step: 4
Training loss: 3.5256059491028786
Validation loss: 2.6546674527337655

Epoch: 6| Step: 5
Training loss: 2.968652824016068
Validation loss: 2.656921754425274

Epoch: 6| Step: 6
Training loss: 2.6206220722614275
Validation loss: 2.6568691277687115

Epoch: 6| Step: 7
Training loss: 3.3021946516236613
Validation loss: 2.650698255751051

Epoch: 6| Step: 8
Training loss: 2.751399291102989
Validation loss: 2.649388031310627

Epoch: 6| Step: 9
Training loss: 3.039715145217147
Validation loss: 2.6485186572969153

Epoch: 6| Step: 10
Training loss: 3.1693678093740068
Validation loss: 2.6466480990489774

Epoch: 6| Step: 11
Training loss: 2.9340335602612417
Validation loss: 2.648222371715221

Epoch: 6| Step: 12
Training loss: 2.3898286178623573
Validation loss: 2.6449990934360352

Epoch: 6| Step: 13
Training loss: 3.436240780548461
Validation loss: 2.6465580966342435

Epoch: 36| Step: 0
Training loss: 3.0015636183951586
Validation loss: 2.6454734244167626

Epoch: 6| Step: 1
Training loss: 3.4794698495546648
Validation loss: 2.646855001459631

Epoch: 6| Step: 2
Training loss: 3.721815368533368
Validation loss: 2.649922344194467

Epoch: 6| Step: 3
Training loss: 3.1564562135315444
Validation loss: 2.655996304002037

Epoch: 6| Step: 4
Training loss: 2.1651966414448984
Validation loss: 2.6761412646991993

Epoch: 6| Step: 5
Training loss: 3.594953650545825
Validation loss: 2.7001220783389432

Epoch: 6| Step: 6
Training loss: 3.113591541253702
Validation loss: 2.666677008372937

Epoch: 6| Step: 7
Training loss: 2.606239673767856
Validation loss: 2.6458340632642985

Epoch: 6| Step: 8
Training loss: 2.8329776839896565
Validation loss: 2.6420031482280977

Epoch: 6| Step: 9
Training loss: 3.2286783813142215
Validation loss: 2.64404626632741

Epoch: 6| Step: 10
Training loss: 1.9767639901816878
Validation loss: 2.643352269308111

Epoch: 6| Step: 11
Training loss: 3.077575944448432
Validation loss: 2.64051295420948

Epoch: 6| Step: 12
Training loss: 2.7320903716045892
Validation loss: 2.6439635110165716

Epoch: 6| Step: 13
Training loss: 2.9213577873509964
Validation loss: 2.6426077612926333

Epoch: 37| Step: 0
Training loss: 3.0905851880354946
Validation loss: 2.64543909596944

Epoch: 6| Step: 1
Training loss: 2.926457203499825
Validation loss: 2.6561607591958434

Epoch: 6| Step: 2
Training loss: 2.6974953478330246
Validation loss: 2.644792269749578

Epoch: 6| Step: 3
Training loss: 2.822161377562137
Validation loss: 2.646311890028648

Epoch: 6| Step: 4
Training loss: 3.498583643298424
Validation loss: 2.6444900991049085

Epoch: 6| Step: 5
Training loss: 2.1575340096808873
Validation loss: 2.6442041889039087

Epoch: 6| Step: 6
Training loss: 3.3132575266536777
Validation loss: 2.646144691332815

Epoch: 6| Step: 7
Training loss: 3.3038455981922543
Validation loss: 2.6683399759716577

Epoch: 6| Step: 8
Training loss: 3.626387232038169
Validation loss: 2.6855826572335153

Epoch: 6| Step: 9
Training loss: 1.9646165841593384
Validation loss: 2.6827044339749038

Epoch: 6| Step: 10
Training loss: 3.2317603411057183
Validation loss: 2.6978107427956455

Epoch: 6| Step: 11
Training loss: 2.7555529277371966
Validation loss: 2.7206590809955586

Epoch: 6| Step: 12
Training loss: 3.407567880448353
Validation loss: 2.6955394590465236

Epoch: 6| Step: 13
Training loss: 2.648191097353861
Validation loss: 2.6607043370986156

Epoch: 38| Step: 0
Training loss: 2.695242972099158
Validation loss: 2.642635858662997

Epoch: 6| Step: 1
Training loss: 3.4253597543939067
Validation loss: 2.638832856428777

Epoch: 6| Step: 2
Training loss: 2.5802728202645255
Validation loss: 2.6362093112404548

Epoch: 6| Step: 3
Training loss: 2.888358222280409
Validation loss: 2.641480682635838

Epoch: 6| Step: 4
Training loss: 2.881673944690957
Validation loss: 2.6414141702931615

Epoch: 6| Step: 5
Training loss: 2.5266359449479903
Validation loss: 2.6514518886674674

Epoch: 6| Step: 6
Training loss: 3.2079972590674966
Validation loss: 2.6556497994800288

Epoch: 6| Step: 7
Training loss: 3.2145177182225333
Validation loss: 2.6390062061764947

Epoch: 6| Step: 8
Training loss: 3.303651327102249
Validation loss: 2.638149832697549

Epoch: 6| Step: 9
Training loss: 3.6813743272391983
Validation loss: 2.6372930275522513

Epoch: 6| Step: 10
Training loss: 2.932960086253086
Validation loss: 2.6393575522741317

Epoch: 6| Step: 11
Training loss: 2.225569332876024
Validation loss: 2.6366512307865557

Epoch: 6| Step: 12
Training loss: 2.801577317921502
Validation loss: 2.6322088349497306

Epoch: 6| Step: 13
Training loss: 3.4303988542344896
Validation loss: 2.6336990557579014

Epoch: 39| Step: 0
Training loss: 3.092417420354016
Validation loss: 2.63031932621393

Epoch: 6| Step: 1
Training loss: 2.771718612783579
Validation loss: 2.628179074432072

Epoch: 6| Step: 2
Training loss: 2.8020312128336635
Validation loss: 2.6306012578459277

Epoch: 6| Step: 3
Training loss: 3.558321727820119
Validation loss: 2.6291462868618494

Epoch: 6| Step: 4
Training loss: 2.260628287492534
Validation loss: 2.6268178980417565

Epoch: 6| Step: 5
Training loss: 2.7506229388665484
Validation loss: 2.623112851307916

Epoch: 6| Step: 6
Training loss: 3.001497054093984
Validation loss: 2.6260774230520756

Epoch: 6| Step: 7
Training loss: 3.249589160480762
Validation loss: 2.6239835545737082

Epoch: 6| Step: 8
Training loss: 3.111804109169273
Validation loss: 2.6230914799978273

Epoch: 6| Step: 9
Training loss: 3.2909365137932065
Validation loss: 2.6233942752910386

Epoch: 6| Step: 10
Training loss: 2.9185363952761936
Validation loss: 2.6223214601219027

Epoch: 6| Step: 11
Training loss: 2.735269106051456
Validation loss: 2.619697802181193

Epoch: 6| Step: 12
Training loss: 2.680429606094885
Validation loss: 2.6248200028171524

Epoch: 6| Step: 13
Training loss: 3.5918191781526145
Validation loss: 2.627292042580249

Epoch: 40| Step: 0
Training loss: 3.399173209696953
Validation loss: 2.629267900528338

Epoch: 6| Step: 1
Training loss: 2.46008014579413
Validation loss: 2.6345456154481632

Epoch: 6| Step: 2
Training loss: 3.15630091257862
Validation loss: 2.630481319745327

Epoch: 6| Step: 3
Training loss: 2.8157518025930752
Validation loss: 2.6322621815639407

Epoch: 6| Step: 4
Training loss: 3.315732997677836
Validation loss: 2.6302745728308254

Epoch: 6| Step: 5
Training loss: 3.0338815494114755
Validation loss: 2.6264899381670106

Epoch: 6| Step: 6
Training loss: 2.428622782188305
Validation loss: 2.6178252313585637

Epoch: 6| Step: 7
Training loss: 3.1742436627014308
Validation loss: 2.6184998333476925

Epoch: 6| Step: 8
Training loss: 3.0598283909068034
Validation loss: 2.617564877671759

Epoch: 6| Step: 9
Training loss: 2.6699932231174146
Validation loss: 2.6143989479996153

Epoch: 6| Step: 10
Training loss: 3.0025404663916415
Validation loss: 2.616129396296274

Epoch: 6| Step: 11
Training loss: 2.8724715683130095
Validation loss: 2.6137711628456

Epoch: 6| Step: 12
Training loss: 3.281928001474187
Validation loss: 2.614380766908189

Epoch: 6| Step: 13
Training loss: 2.8466215621745903
Validation loss: 2.615107628660241

Epoch: 41| Step: 0
Training loss: 2.8170241525932904
Validation loss: 2.6165096859243437

Epoch: 6| Step: 1
Training loss: 2.801970374419754
Validation loss: 2.6216466602415585

Epoch: 6| Step: 2
Training loss: 3.1940981322460913
Validation loss: 2.624110686981497

Epoch: 6| Step: 3
Training loss: 3.0445886102901003
Validation loss: 2.6240752574335997

Epoch: 6| Step: 4
Training loss: 3.0895884875003543
Validation loss: 2.6218716653070304

Epoch: 6| Step: 5
Training loss: 2.8667306146216602
Validation loss: 2.6178959751557236

Epoch: 6| Step: 6
Training loss: 3.2008088460546866
Validation loss: 2.6296437066309437

Epoch: 6| Step: 7
Training loss: 2.890007159214326
Validation loss: 2.6333273350823987

Epoch: 6| Step: 8
Training loss: 2.8761753499316915
Validation loss: 2.6429241898999405

Epoch: 6| Step: 9
Training loss: 3.4635877257226872
Validation loss: 2.6527745576642228

Epoch: 6| Step: 10
Training loss: 2.6807750574698432
Validation loss: 2.6292689233448048

Epoch: 6| Step: 11
Training loss: 2.153617246746366
Validation loss: 2.618539465945668

Epoch: 6| Step: 12
Training loss: 2.8782559078238426
Validation loss: 2.6200236836677813

Epoch: 6| Step: 13
Training loss: 3.810605813669959
Validation loss: 2.6189425044360135

Epoch: 42| Step: 0
Training loss: 2.9458489776872168
Validation loss: 2.618066857020166

Epoch: 6| Step: 1
Training loss: 2.9495309424477214
Validation loss: 2.623128232444878

Epoch: 6| Step: 2
Training loss: 3.41106347669656
Validation loss: 2.626692029795049

Epoch: 6| Step: 3
Training loss: 2.8085861099839584
Validation loss: 2.621487468244869

Epoch: 6| Step: 4
Training loss: 3.188729441780983
Validation loss: 2.621687289621942

Epoch: 6| Step: 5
Training loss: 3.2650303641480263
Validation loss: 2.628382609454643

Epoch: 6| Step: 6
Training loss: 3.158812738300486
Validation loss: 2.6361611967599226

Epoch: 6| Step: 7
Training loss: 2.5505093346346235
Validation loss: 2.6389724794485616

Epoch: 6| Step: 8
Training loss: 3.1922845273949525
Validation loss: 2.627599037957557

Epoch: 6| Step: 9
Training loss: 2.622033031916071
Validation loss: 2.622050970268973

Epoch: 6| Step: 10
Training loss: 3.1461027590004798
Validation loss: 2.618925454180855

Epoch: 6| Step: 11
Training loss: 2.3741622250284315
Validation loss: 2.617048901172696

Epoch: 6| Step: 12
Training loss: 3.146242498268396
Validation loss: 2.616053630430148

Epoch: 6| Step: 13
Training loss: 3.1268036786976547
Validation loss: 2.611721916651165

Epoch: 43| Step: 0
Training loss: 3.1547282865777504
Validation loss: 2.6066258526935946

Epoch: 6| Step: 1
Training loss: 2.5655024546862593
Validation loss: 2.60520485805362

Epoch: 6| Step: 2
Training loss: 3.492571850135217
Validation loss: 2.6024691188098683

Epoch: 6| Step: 3
Training loss: 3.3079697922477074
Validation loss: 2.604460452992204

Epoch: 6| Step: 4
Training loss: 3.658682641548707
Validation loss: 2.6026743285238503

Epoch: 6| Step: 5
Training loss: 2.409102693401324
Validation loss: 2.608501280925873

Epoch: 6| Step: 6
Training loss: 2.9087005456278483
Validation loss: 2.620423837709845

Epoch: 6| Step: 7
Training loss: 2.565286842205797
Validation loss: 2.6165538840608735

Epoch: 6| Step: 8
Training loss: 3.165141809308813
Validation loss: 2.620040938126354

Epoch: 6| Step: 9
Training loss: 2.8818190602267575
Validation loss: 2.618677545339534

Epoch: 6| Step: 10
Training loss: 2.6495501226351537
Validation loss: 2.6274452422806633

Epoch: 6| Step: 11
Training loss: 2.7717915553592922
Validation loss: 2.638236597512102

Epoch: 6| Step: 12
Training loss: 2.935107616420683
Validation loss: 2.640326700377682

Epoch: 6| Step: 13
Training loss: 2.7558811762736175
Validation loss: 2.6210762775120524

Epoch: 44| Step: 0
Training loss: 2.7911619517767403
Validation loss: 2.6166750150690667

Epoch: 6| Step: 1
Training loss: 3.2967760694946477
Validation loss: 2.6171307276771607

Epoch: 6| Step: 2
Training loss: 2.466650830896769
Validation loss: 2.6105918402486674

Epoch: 6| Step: 3
Training loss: 3.324460730167126
Validation loss: 2.6129441649276894

Epoch: 6| Step: 4
Training loss: 3.276123983847978
Validation loss: 2.6276281748762242

Epoch: 6| Step: 5
Training loss: 2.897212918848657
Validation loss: 2.626270641975111

Epoch: 6| Step: 6
Training loss: 2.6735327859169873
Validation loss: 2.60849426370917

Epoch: 6| Step: 7
Training loss: 2.9406296311442346
Validation loss: 2.599294938368391

Epoch: 6| Step: 8
Training loss: 2.979562764189919
Validation loss: 2.5966310133288393

Epoch: 6| Step: 9
Training loss: 2.421587723952482
Validation loss: 2.5938320203776253

Epoch: 6| Step: 10
Training loss: 3.677316732086522
Validation loss: 2.593650197217856

Epoch: 6| Step: 11
Training loss: 2.7871203245229905
Validation loss: 2.5929451089057185

Epoch: 6| Step: 12
Training loss: 2.9387462488407676
Validation loss: 2.591117726074244

Epoch: 6| Step: 13
Training loss: 2.549698089977835
Validation loss: 2.5905169151607628

Epoch: 45| Step: 0
Training loss: 3.0277208056519247
Validation loss: 2.592896356718852

Epoch: 6| Step: 1
Training loss: 3.0979921175694525
Validation loss: 2.5922232922334874

Epoch: 6| Step: 2
Training loss: 3.4511340171063076
Validation loss: 2.5933772151676235

Epoch: 6| Step: 3
Training loss: 3.37847142591442
Validation loss: 2.590526172097677

Epoch: 6| Step: 4
Training loss: 2.9356105490432984
Validation loss: 2.5916634617940537

Epoch: 6| Step: 5
Training loss: 1.7429809816103126
Validation loss: 2.5910238989955205

Epoch: 6| Step: 6
Training loss: 3.1031702136292587
Validation loss: 2.592393561208655

Epoch: 6| Step: 7
Training loss: 2.93363714884468
Validation loss: 2.5932157015339006

Epoch: 6| Step: 8
Training loss: 2.8066238052405716
Validation loss: 2.5916267973066707

Epoch: 6| Step: 9
Training loss: 2.559487409533508
Validation loss: 2.5932756769348897

Epoch: 6| Step: 10
Training loss: 2.6125395082835645
Validation loss: 2.5967151936665536

Epoch: 6| Step: 11
Training loss: 3.594071348998839
Validation loss: 2.600605759759551

Epoch: 6| Step: 12
Training loss: 2.9530160066382005
Validation loss: 2.6080868563632946

Epoch: 6| Step: 13
Training loss: 2.6198162484706313
Validation loss: 2.6128478317815116

Epoch: 46| Step: 0
Training loss: 3.1774897747940747
Validation loss: 2.6104824277243077

Epoch: 6| Step: 1
Training loss: 3.0630195332700456
Validation loss: 2.617385073657841

Epoch: 6| Step: 2
Training loss: 2.5424506015536137
Validation loss: 2.6362486085547836

Epoch: 6| Step: 3
Training loss: 2.6662436586886726
Validation loss: 2.673415633074215

Epoch: 6| Step: 4
Training loss: 3.2964360094008662
Validation loss: 2.6576221326582923

Epoch: 6| Step: 5
Training loss: 2.9556591322523804
Validation loss: 2.636119054537581

Epoch: 6| Step: 6
Training loss: 2.480092321953971
Validation loss: 2.6029561500518184

Epoch: 6| Step: 7
Training loss: 2.730162421903793
Validation loss: 2.5905603375682342

Epoch: 6| Step: 8
Training loss: 3.336961932867417
Validation loss: 2.5845128334571164

Epoch: 6| Step: 9
Training loss: 2.756586510147513
Validation loss: 2.5837987512945255

Epoch: 6| Step: 10
Training loss: 2.8830873932071706
Validation loss: 2.586276821349352

Epoch: 6| Step: 11
Training loss: 2.6331143078880075
Validation loss: 2.586365995417874

Epoch: 6| Step: 12
Training loss: 3.55597101870421
Validation loss: 2.5896029954608544

Epoch: 6| Step: 13
Training loss: 3.311509326127409
Validation loss: 2.5879425532741482

Epoch: 47| Step: 0
Training loss: 2.8460898362414757
Validation loss: 2.589233955222815

Epoch: 6| Step: 1
Training loss: 2.687552872958277
Validation loss: 2.588800615710572

Epoch: 6| Step: 2
Training loss: 2.426905962530142
Validation loss: 2.5878303653003334

Epoch: 6| Step: 3
Training loss: 2.98722280070221
Validation loss: 2.590457993200129

Epoch: 6| Step: 4
Training loss: 3.7434113159843454
Validation loss: 2.5875948279387866

Epoch: 6| Step: 5
Training loss: 2.899564703795482
Validation loss: 2.5936098689765132

Epoch: 6| Step: 6
Training loss: 3.076506058236711
Validation loss: 2.595891248310127

Epoch: 6| Step: 7
Training loss: 2.9513100188444357
Validation loss: 2.606290462330599

Epoch: 6| Step: 8
Training loss: 2.7649431842947387
Validation loss: 2.621132810331041

Epoch: 6| Step: 9
Training loss: 3.2871749427135617
Validation loss: 2.6209453631661233

Epoch: 6| Step: 10
Training loss: 2.890721664874433
Validation loss: 2.626643522351228

Epoch: 6| Step: 11
Training loss: 2.5864995708601644
Validation loss: 2.632614572808771

Epoch: 6| Step: 12
Training loss: 3.1428216492518866
Validation loss: 2.638044810881837

Epoch: 6| Step: 13
Training loss: 3.099853506010893
Validation loss: 2.6638619692637158

Epoch: 48| Step: 0
Training loss: 2.779806469692027
Validation loss: 2.6650314226633474

Epoch: 6| Step: 1
Training loss: 3.3871833456200307
Validation loss: 2.63592879833952

Epoch: 6| Step: 2
Training loss: 2.7574210172739138
Validation loss: 2.62381488125386

Epoch: 6| Step: 3
Training loss: 2.72166181708342
Validation loss: 2.618869007823123

Epoch: 6| Step: 4
Training loss: 2.8268907920435096
Validation loss: 2.60832908929079

Epoch: 6| Step: 5
Training loss: 3.0669231003510338
Validation loss: 2.6119497936719975

Epoch: 6| Step: 6
Training loss: 3.3861718533702097
Validation loss: 2.600723097186396

Epoch: 6| Step: 7
Training loss: 2.931822626918356
Validation loss: 2.593369937572706

Epoch: 6| Step: 8
Training loss: 2.9894812873322305
Validation loss: 2.580685360624893

Epoch: 6| Step: 9
Training loss: 2.1102051408309004
Validation loss: 2.5859729157325635

Epoch: 6| Step: 10
Training loss: 3.5417203712131498
Validation loss: 2.583597323226669

Epoch: 6| Step: 11
Training loss: 2.9961281268399396
Validation loss: 2.5862768748767206

Epoch: 6| Step: 12
Training loss: 2.909465200826739
Validation loss: 2.58808038598978

Epoch: 6| Step: 13
Training loss: 2.948069124806308
Validation loss: 2.585282395963628

Epoch: 49| Step: 0
Training loss: 3.248229791808995
Validation loss: 2.580810512480357

Epoch: 6| Step: 1
Training loss: 2.9222247072538856
Validation loss: 2.580781313870558

Epoch: 6| Step: 2
Training loss: 2.9375701246616543
Validation loss: 2.5831397741911664

Epoch: 6| Step: 3
Training loss: 3.11268248118865
Validation loss: 2.5848262937179216

Epoch: 6| Step: 4
Training loss: 3.4470888432894027
Validation loss: 2.594050648326049

Epoch: 6| Step: 5
Training loss: 2.946145989544888
Validation loss: 2.6421362264860337

Epoch: 6| Step: 6
Training loss: 2.8537672742604028
Validation loss: 2.637169072729128

Epoch: 6| Step: 7
Training loss: 2.5205960648112855
Validation loss: 2.5812400308178285

Epoch: 6| Step: 8
Training loss: 3.490534653685464
Validation loss: 2.577046689589797

Epoch: 6| Step: 9
Training loss: 2.9377592256485725
Validation loss: 2.572513915639318

Epoch: 6| Step: 10
Training loss: 2.83576733627744
Validation loss: 2.5754131792872346

Epoch: 6| Step: 11
Training loss: 2.4090684510193516
Validation loss: 2.579418565106258

Epoch: 6| Step: 12
Training loss: 2.6050117240539428
Validation loss: 2.582704577374171

Epoch: 6| Step: 13
Training loss: 2.8729597398730027
Validation loss: 2.583423745567545

Epoch: 50| Step: 0
Training loss: 2.895413118972248
Validation loss: 2.5835889503914213

Epoch: 6| Step: 1
Training loss: 3.394629579092253
Validation loss: 2.581012891070062

Epoch: 6| Step: 2
Training loss: 2.4933320768458556
Validation loss: 2.5802719270592367

Epoch: 6| Step: 3
Training loss: 3.2978392723064593
Validation loss: 2.577819648029165

Epoch: 6| Step: 4
Training loss: 2.7152645525944927
Validation loss: 2.5750998798516638

Epoch: 6| Step: 5
Training loss: 2.916582996439853
Validation loss: 2.573466441298462

Epoch: 6| Step: 6
Training loss: 3.3649552241119527
Validation loss: 2.57222273892514

Epoch: 6| Step: 7
Training loss: 3.1458141671580018
Validation loss: 2.569608777847837

Epoch: 6| Step: 8
Training loss: 2.8046906452639484
Validation loss: 2.5689212711735085

Epoch: 6| Step: 9
Training loss: 2.7908555365979923
Validation loss: 2.5720953302753213

Epoch: 6| Step: 10
Training loss: 2.683161760456473
Validation loss: 2.5684389373198075

Epoch: 6| Step: 11
Training loss: 2.4739178035160077
Validation loss: 2.5691451502476195

Epoch: 6| Step: 12
Training loss: 3.449005707914961
Validation loss: 2.567802984737122

Epoch: 6| Step: 13
Training loss: 2.559659919203631
Validation loss: 2.564353805553218

Epoch: 51| Step: 0
Training loss: 3.009772279052508
Validation loss: 2.5633888418851036

Epoch: 6| Step: 1
Training loss: 2.7172642298301346
Validation loss: 2.565316849761236

Epoch: 6| Step: 2
Training loss: 3.038360593097693
Validation loss: 2.5648995626396287

Epoch: 6| Step: 3
Training loss: 2.5886881509905
Validation loss: 2.5643927384269927

Epoch: 6| Step: 4
Training loss: 2.8986924874150897
Validation loss: 2.566148175416905

Epoch: 6| Step: 5
Training loss: 2.8168104413448702
Validation loss: 2.563589019230716

Epoch: 6| Step: 6
Training loss: 3.2871585509077823
Validation loss: 2.5636199666670167

Epoch: 6| Step: 7
Training loss: 3.339600028799251
Validation loss: 2.5626113931418475

Epoch: 6| Step: 8
Training loss: 2.2402201139067657
Validation loss: 2.5602853911101273

Epoch: 6| Step: 9
Training loss: 3.0727760584499646
Validation loss: 2.5614448614032725

Epoch: 6| Step: 10
Training loss: 3.491644832084565
Validation loss: 2.55971715443725

Epoch: 6| Step: 11
Training loss: 2.8090533011877103
Validation loss: 2.5594029573256853

Epoch: 6| Step: 12
Training loss: 2.6111104527826585
Validation loss: 2.5656972428231564

Epoch: 6| Step: 13
Training loss: 2.986027764234093
Validation loss: 2.5731547738981244

Epoch: 52| Step: 0
Training loss: 3.125848120994509
Validation loss: 2.6207209398484217

Epoch: 6| Step: 1
Training loss: 2.346595969038287
Validation loss: 2.682442141281651

Epoch: 6| Step: 2
Training loss: 2.6677862638336514
Validation loss: 2.6881576767404254

Epoch: 6| Step: 3
Training loss: 3.112817440161161
Validation loss: 2.6288648827997125

Epoch: 6| Step: 4
Training loss: 3.0027165828856095
Validation loss: 2.5696528538602106

Epoch: 6| Step: 5
Training loss: 2.788066098331342
Validation loss: 2.5609662497929433

Epoch: 6| Step: 6
Training loss: 2.833046524640711
Validation loss: 2.557769464763239

Epoch: 6| Step: 7
Training loss: 2.1615994204392632
Validation loss: 2.5581936621517283

Epoch: 6| Step: 8
Training loss: 2.801052873068159
Validation loss: 2.557730920199908

Epoch: 6| Step: 9
Training loss: 3.1310150241058823
Validation loss: 2.5611055343106077

Epoch: 6| Step: 10
Training loss: 3.333401361407064
Validation loss: 2.5667564742612394

Epoch: 6| Step: 11
Training loss: 3.2024997007800162
Validation loss: 2.572015131510405

Epoch: 6| Step: 12
Training loss: 3.388396202988986
Validation loss: 2.587491231828873

Epoch: 6| Step: 13
Training loss: 2.9115311415046996
Validation loss: 2.5755643506332757

Epoch: 53| Step: 0
Training loss: 2.499072665839861
Validation loss: 2.5713742429554665

Epoch: 6| Step: 1
Training loss: 2.690151237575738
Validation loss: 2.5696308344054

Epoch: 6| Step: 2
Training loss: 3.251403652199107
Validation loss: 2.5653369565357464

Epoch: 6| Step: 3
Training loss: 3.1112214553277617
Validation loss: 2.5720627505139158

Epoch: 6| Step: 4
Training loss: 3.0744838188317565
Validation loss: 2.570191830202719

Epoch: 6| Step: 5
Training loss: 3.4269474702164677
Validation loss: 2.5657356187499367

Epoch: 6| Step: 6
Training loss: 2.8495631903813896
Validation loss: 2.567481755162882

Epoch: 6| Step: 7
Training loss: 2.625624718578662
Validation loss: 2.5664236871298023

Epoch: 6| Step: 8
Training loss: 2.8658770235115814
Validation loss: 2.5658087709269792

Epoch: 6| Step: 9
Training loss: 3.4000394706678936
Validation loss: 2.563707329882792

Epoch: 6| Step: 10
Training loss: 2.5861631911520067
Validation loss: 2.5597842186974358

Epoch: 6| Step: 11
Training loss: 2.841147269234905
Validation loss: 2.5620532623098407

Epoch: 6| Step: 12
Training loss: 3.0082005634403455
Validation loss: 2.5605666968440537

Epoch: 6| Step: 13
Training loss: 2.705772382423518
Validation loss: 2.5599118560215133

Epoch: 54| Step: 0
Training loss: 2.688957972160164
Validation loss: 2.5591180084713856

Epoch: 6| Step: 1
Training loss: 2.963322386090283
Validation loss: 2.559926552355001

Epoch: 6| Step: 2
Training loss: 3.609526131508535
Validation loss: 2.5561284453322863

Epoch: 6| Step: 3
Training loss: 2.617089841927987
Validation loss: 2.555291487186941

Epoch: 6| Step: 4
Training loss: 3.0073362295409813
Validation loss: 2.5529317731731407

Epoch: 6| Step: 5
Training loss: 2.946618395218664
Validation loss: 2.5528704342136836

Epoch: 6| Step: 6
Training loss: 2.759492357119375
Validation loss: 2.553188044864548

Epoch: 6| Step: 7
Training loss: 1.8949736717629626
Validation loss: 2.556009901223841

Epoch: 6| Step: 8
Training loss: 2.8436960068492056
Validation loss: 2.567481116120284

Epoch: 6| Step: 9
Training loss: 2.7867035279581454
Validation loss: 2.585505226189639

Epoch: 6| Step: 10
Training loss: 3.8673825609738692
Validation loss: 2.6213780410605323

Epoch: 6| Step: 11
Training loss: 3.006374262979652
Validation loss: 2.6160622031487164

Epoch: 6| Step: 12
Training loss: 2.7496381001327537
Validation loss: 2.5979324720720474

Epoch: 6| Step: 13
Training loss: 3.1168186667464943
Validation loss: 2.569037964151254

Epoch: 55| Step: 0
Training loss: 3.2139026474133874
Validation loss: 2.5660915601680863

Epoch: 6| Step: 1
Training loss: 3.4917680117178818
Validation loss: 2.5629833094800425

Epoch: 6| Step: 2
Training loss: 3.0211518393792245
Validation loss: 2.5624590614584246

Epoch: 6| Step: 3
Training loss: 2.328989367711787
Validation loss: 2.5600212327752145

Epoch: 6| Step: 4
Training loss: 3.0538074367148083
Validation loss: 2.5557555023774916

Epoch: 6| Step: 5
Training loss: 3.26301463076567
Validation loss: 2.5561360486007327

Epoch: 6| Step: 6
Training loss: 2.791023056842581
Validation loss: 2.5543541441304614

Epoch: 6| Step: 7
Training loss: 2.7739977633378543
Validation loss: 2.556691544529886

Epoch: 6| Step: 8
Training loss: 3.0302742242888923
Validation loss: 2.5579223302936076

Epoch: 6| Step: 9
Training loss: 2.448007189652849
Validation loss: 2.5614903579676516

Epoch: 6| Step: 10
Training loss: 2.1246508143136538
Validation loss: 2.5662148443400317

Epoch: 6| Step: 11
Training loss: 3.268957892201851
Validation loss: 2.5674460524079463

Epoch: 6| Step: 12
Training loss: 2.79472498596774
Validation loss: 2.5659066782547106

Epoch: 6| Step: 13
Training loss: 3.1719345312686227
Validation loss: 2.5674841665487524

Epoch: 56| Step: 0
Training loss: 3.099869657668085
Validation loss: 2.577411582485911

Epoch: 6| Step: 1
Training loss: 3.0820897318001896
Validation loss: 2.5823914249364255

Epoch: 6| Step: 2
Training loss: 2.9140850812839894
Validation loss: 2.5951290346524916

Epoch: 6| Step: 3
Training loss: 3.089093335412139
Validation loss: 2.6143507008066837

Epoch: 6| Step: 4
Training loss: 3.3348609920510497
Validation loss: 2.583735915606612

Epoch: 6| Step: 5
Training loss: 2.957762613898516
Validation loss: 2.577716400989988

Epoch: 6| Step: 6
Training loss: 2.3354291586041307
Validation loss: 2.5765109969205904

Epoch: 6| Step: 7
Training loss: 2.7240851660255143
Validation loss: 2.552180099075884

Epoch: 6| Step: 8
Training loss: 3.412819922126249
Validation loss: 2.5495437620088075

Epoch: 6| Step: 9
Training loss: 2.869818953276489
Validation loss: 2.550420107046524

Epoch: 6| Step: 10
Training loss: 2.9627927740104463
Validation loss: 2.55127059789699

Epoch: 6| Step: 11
Training loss: 2.733811674673844
Validation loss: 2.5587236564476776

Epoch: 6| Step: 12
Training loss: 2.724518630181272
Validation loss: 2.5686100453509706

Epoch: 6| Step: 13
Training loss: 2.1239819051255546
Validation loss: 2.5832367398333766

Epoch: 57| Step: 0
Training loss: 2.9880720476709985
Validation loss: 2.605865978089993

Epoch: 6| Step: 1
Training loss: 3.188125997669189
Validation loss: 2.6411746883070473

Epoch: 6| Step: 2
Training loss: 3.7230180882729953
Validation loss: 2.7032217909051113

Epoch: 6| Step: 3
Training loss: 3.2786421812409334
Validation loss: 2.7008122467003437

Epoch: 6| Step: 4
Training loss: 3.0990593559831567
Validation loss: 2.675249882395856

Epoch: 6| Step: 5
Training loss: 3.006432947631381
Validation loss: 2.6456368757515567

Epoch: 6| Step: 6
Training loss: 2.559334730639635
Validation loss: 2.616249678774363

Epoch: 6| Step: 7
Training loss: 3.0747476241588525
Validation loss: 2.5947044860967012

Epoch: 6| Step: 8
Training loss: 2.431474819428708
Validation loss: 2.568518423315628

Epoch: 6| Step: 9
Training loss: 3.028497134117419
Validation loss: 2.560466949301038

Epoch: 6| Step: 10
Training loss: 2.550413704018528
Validation loss: 2.561443486225055

Epoch: 6| Step: 11
Training loss: 2.7694537712849043
Validation loss: 2.5663702925381657

Epoch: 6| Step: 12
Training loss: 2.924270871569537
Validation loss: 2.56877283263263

Epoch: 6| Step: 13
Training loss: 2.728889936632638
Validation loss: 2.5695916456742047

Epoch: 58| Step: 0
Training loss: 2.9836965059264218
Validation loss: 2.5819661799627016

Epoch: 6| Step: 1
Training loss: 3.3584687185961792
Validation loss: 2.586352246260238

Epoch: 6| Step: 2
Training loss: 2.121312700917345
Validation loss: 2.581198914749959

Epoch: 6| Step: 3
Training loss: 2.9981362593556495
Validation loss: 2.5837147087503554

Epoch: 6| Step: 4
Training loss: 1.675253049040745
Validation loss: 2.5815775872693254

Epoch: 6| Step: 5
Training loss: 3.01448092722779
Validation loss: 2.5754082937176976

Epoch: 6| Step: 6
Training loss: 2.764943442982045
Validation loss: 2.578063122854177

Epoch: 6| Step: 7
Training loss: 3.1551924340615853
Validation loss: 2.5822951532718346

Epoch: 6| Step: 8
Training loss: 2.662725297592114
Validation loss: 2.579098607320535

Epoch: 6| Step: 9
Training loss: 3.4968862306688933
Validation loss: 2.564797438755532

Epoch: 6| Step: 10
Training loss: 3.2821129526975663
Validation loss: 2.5531394201485402

Epoch: 6| Step: 11
Training loss: 2.7644919105559076
Validation loss: 2.5461761061251824

Epoch: 6| Step: 12
Training loss: 3.2567807400213815
Validation loss: 2.540834974330794

Epoch: 6| Step: 13
Training loss: 2.7150091107182237
Validation loss: 2.5417216345620863

Epoch: 59| Step: 0
Training loss: 3.2506358184957147
Validation loss: 2.5372654120879288

Epoch: 6| Step: 1
Training loss: 2.8363974962680985
Validation loss: 2.5360441556807656

Epoch: 6| Step: 2
Training loss: 2.6703193106433316
Validation loss: 2.5376822133364603

Epoch: 6| Step: 3
Training loss: 3.213002230204459
Validation loss: 2.535618038298207

Epoch: 6| Step: 4
Training loss: 2.5250344906708
Validation loss: 2.536921392668296

Epoch: 6| Step: 5
Training loss: 2.296388224188189
Validation loss: 2.5420238032818654

Epoch: 6| Step: 6
Training loss: 3.6560851491949777
Validation loss: 2.5584936429707694

Epoch: 6| Step: 7
Training loss: 2.8527067214187536
Validation loss: 2.5472589824024348

Epoch: 6| Step: 8
Training loss: 2.7915098421448388
Validation loss: 2.5622024893661264

Epoch: 6| Step: 9
Training loss: 3.212204583385445
Validation loss: 2.557875337042532

Epoch: 6| Step: 10
Training loss: 3.1597719088456646
Validation loss: 2.5605672605198686

Epoch: 6| Step: 11
Training loss: 2.5468805231139786
Validation loss: 2.552292371521823

Epoch: 6| Step: 12
Training loss: 2.6162281612499947
Validation loss: 2.57348110156733

Epoch: 6| Step: 13
Training loss: 2.6158894066837934
Validation loss: 2.5807306014358176

Epoch: 60| Step: 0
Training loss: 2.9371681837608934
Validation loss: 2.5851434908110384

Epoch: 6| Step: 1
Training loss: 2.695935075147924
Validation loss: 2.588497518438316

Epoch: 6| Step: 2
Training loss: 3.261160687429529
Validation loss: 2.590222603721476

Epoch: 6| Step: 3
Training loss: 2.6483061541280364
Validation loss: 2.584417901102957

Epoch: 6| Step: 4
Training loss: 3.222717358558882
Validation loss: 2.5775600775237897

Epoch: 6| Step: 5
Training loss: 2.3690826585035536
Validation loss: 2.571394390099411

Epoch: 6| Step: 6
Training loss: 3.3860915856184826
Validation loss: 2.5774761001088202

Epoch: 6| Step: 7
Training loss: 2.630503017926293
Validation loss: 2.570079761137417

Epoch: 6| Step: 8
Training loss: 3.66681572582243
Validation loss: 2.5689365157271618

Epoch: 6| Step: 9
Training loss: 2.762658030965311
Validation loss: 2.5613862525344673

Epoch: 6| Step: 10
Training loss: 2.685796508284113
Validation loss: 2.5451074331619963

Epoch: 6| Step: 11
Training loss: 3.122668197414285
Validation loss: 2.5453921325168474

Epoch: 6| Step: 12
Training loss: 2.556636894812023
Validation loss: 2.5362223557336745

Epoch: 6| Step: 13
Training loss: 2.5014946284429938
Validation loss: 2.5343108555061513

Epoch: 61| Step: 0
Training loss: 2.5152970568220403
Validation loss: 2.5422093440630893

Epoch: 6| Step: 1
Training loss: 2.875746920214137
Validation loss: 2.537967463801492

Epoch: 6| Step: 2
Training loss: 3.0591764516179496
Validation loss: 2.534635781791018

Epoch: 6| Step: 3
Training loss: 2.8225550308471656
Validation loss: 2.5386999788049662

Epoch: 6| Step: 4
Training loss: 2.7878184388970517
Validation loss: 2.5422488137140764

Epoch: 6| Step: 5
Training loss: 2.9587690722000293
Validation loss: 2.55411793962548

Epoch: 6| Step: 6
Training loss: 3.156676008726943
Validation loss: 2.565775185111348

Epoch: 6| Step: 7
Training loss: 2.656039599893264
Validation loss: 2.5641352230414585

Epoch: 6| Step: 8
Training loss: 2.754519823048367
Validation loss: 2.559807976826073

Epoch: 6| Step: 9
Training loss: 2.958089379652876
Validation loss: 2.5724823726220447

Epoch: 6| Step: 10
Training loss: 3.0027869313120434
Validation loss: 2.5567596191514332

Epoch: 6| Step: 11
Training loss: 3.220444612786924
Validation loss: 2.5481952904248586

Epoch: 6| Step: 12
Training loss: 2.8223894666276244
Validation loss: 2.540793605487627

Epoch: 6| Step: 13
Training loss: 3.28133806382941
Validation loss: 2.529606365400657

Epoch: 62| Step: 0
Training loss: 2.8996464349351
Validation loss: 2.524754639080533

Epoch: 6| Step: 1
Training loss: 2.4356278296677636
Validation loss: 2.526888437094191

Epoch: 6| Step: 2
Training loss: 2.798948914928843
Validation loss: 2.524870550638081

Epoch: 6| Step: 3
Training loss: 3.0311825145012734
Validation loss: 2.5339400463821646

Epoch: 6| Step: 4
Training loss: 2.93116011166564
Validation loss: 2.5357971306622447

Epoch: 6| Step: 5
Training loss: 2.9145227636370077
Validation loss: 2.5366746905745425

Epoch: 6| Step: 6
Training loss: 2.5231512043111675
Validation loss: 2.5346572288518767

Epoch: 6| Step: 7
Training loss: 2.775159961798259
Validation loss: 2.532326412081934

Epoch: 6| Step: 8
Training loss: 2.471185955168978
Validation loss: 2.5352381698958992

Epoch: 6| Step: 9
Training loss: 2.9167620143745934
Validation loss: 2.53203168714997

Epoch: 6| Step: 10
Training loss: 3.0585959326101726
Validation loss: 2.5227220352103163

Epoch: 6| Step: 11
Training loss: 2.7575294414203984
Validation loss: 2.527778569444907

Epoch: 6| Step: 12
Training loss: 3.6826385521705247
Validation loss: 2.536915322394394

Epoch: 6| Step: 13
Training loss: 3.362702039583502
Validation loss: 2.5555209642669685

Epoch: 63| Step: 0
Training loss: 3.851745972509501
Validation loss: 2.5682011952719943

Epoch: 6| Step: 1
Training loss: 1.8679577503654274
Validation loss: 2.577862896465427

Epoch: 6| Step: 2
Training loss: 2.7781019074689235
Validation loss: 2.584401260910947

Epoch: 6| Step: 3
Training loss: 3.2959639750428513
Validation loss: 2.579067450994364

Epoch: 6| Step: 4
Training loss: 2.2722784804343994
Validation loss: 2.5599870462820506

Epoch: 6| Step: 5
Training loss: 2.9465528552773104
Validation loss: 2.5538553829082047

Epoch: 6| Step: 6
Training loss: 3.0828570092493
Validation loss: 2.555994393016404

Epoch: 6| Step: 7
Training loss: 2.7417109148654126
Validation loss: 2.5399655567321133

Epoch: 6| Step: 8
Training loss: 3.0153447945029983
Validation loss: 2.5288645336925475

Epoch: 6| Step: 9
Training loss: 2.587321484438428
Validation loss: 2.5263523081216097

Epoch: 6| Step: 10
Training loss: 2.6937538837307504
Validation loss: 2.525994917945802

Epoch: 6| Step: 11
Training loss: 3.2382803664994273
Validation loss: 2.523166788394503

Epoch: 6| Step: 12
Training loss: 2.2617115817837616
Validation loss: 2.5194460109808285

Epoch: 6| Step: 13
Training loss: 3.247889493706656
Validation loss: 2.5171468945481577

Epoch: 64| Step: 0
Training loss: 3.3930138114380517
Validation loss: 2.517836910700584

Epoch: 6| Step: 1
Training loss: 3.3665807757106863
Validation loss: 2.514549492716196

Epoch: 6| Step: 2
Training loss: 2.906537605739286
Validation loss: 2.5122294912605163

Epoch: 6| Step: 3
Training loss: 2.52412051001137
Validation loss: 2.5121515857631445

Epoch: 6| Step: 4
Training loss: 1.2901858434693747
Validation loss: 2.5118251099207227

Epoch: 6| Step: 5
Training loss: 2.78449839651425
Validation loss: 2.512381350134422

Epoch: 6| Step: 6
Training loss: 2.5471513282323874
Validation loss: 2.5140458285778804

Epoch: 6| Step: 7
Training loss: 3.159037954461689
Validation loss: 2.5104201380677122

Epoch: 6| Step: 8
Training loss: 2.9342183389170295
Validation loss: 2.511852337083276

Epoch: 6| Step: 9
Training loss: 3.1196762513648877
Validation loss: 2.5116715332761896

Epoch: 6| Step: 10
Training loss: 3.1123581574380057
Validation loss: 2.51784989159306

Epoch: 6| Step: 11
Training loss: 2.3897372323996193
Validation loss: 2.5293676035377732

Epoch: 6| Step: 12
Training loss: 3.2395105547973686
Validation loss: 2.54896757393212

Epoch: 6| Step: 13
Training loss: 2.67517671090534
Validation loss: 2.573535474282515

Epoch: 65| Step: 0
Training loss: 2.7975089777170896
Validation loss: 2.594031439114555

Epoch: 6| Step: 1
Training loss: 2.8648792090924933
Validation loss: 2.625562526513266

Epoch: 6| Step: 2
Training loss: 3.0151654619707893
Validation loss: 2.62454189360076

Epoch: 6| Step: 3
Training loss: 3.078720577345658
Validation loss: 2.585223448905638

Epoch: 6| Step: 4
Training loss: 2.7448449802227635
Validation loss: 2.5575364395054203

Epoch: 6| Step: 5
Training loss: 2.4745621650365486
Validation loss: 2.5450937089091887

Epoch: 6| Step: 6
Training loss: 2.8203879898408526
Validation loss: 2.530998526391691

Epoch: 6| Step: 7
Training loss: 2.922803435485416
Validation loss: 2.5256098515284546

Epoch: 6| Step: 8
Training loss: 2.6209307419505694
Validation loss: 2.5193292708384494

Epoch: 6| Step: 9
Training loss: 2.9632958353228256
Validation loss: 2.5130360184561966

Epoch: 6| Step: 10
Training loss: 2.9473345465972183
Validation loss: 2.511836444996777

Epoch: 6| Step: 11
Training loss: 2.6571400665819365
Validation loss: 2.511298642054597

Epoch: 6| Step: 12
Training loss: 3.266142005697149
Validation loss: 2.5094637584909756

Epoch: 6| Step: 13
Training loss: 2.8888869550486556
Validation loss: 2.5141827007797755

Epoch: 66| Step: 0
Training loss: 2.8463382889193376
Validation loss: 2.51431420642297

Epoch: 6| Step: 1
Training loss: 3.0473256878214134
Validation loss: 2.515755831058272

Epoch: 6| Step: 2
Training loss: 2.879440195990387
Validation loss: 2.515514762948116

Epoch: 6| Step: 3
Training loss: 2.5131192255606027
Validation loss: 2.5135504738560086

Epoch: 6| Step: 4
Training loss: 3.22840071587326
Validation loss: 2.5163007218606186

Epoch: 6| Step: 5
Training loss: 2.8061536606731945
Validation loss: 2.5212128588360754

Epoch: 6| Step: 6
Training loss: 3.253759850257387
Validation loss: 2.5273939015722626

Epoch: 6| Step: 7
Training loss: 2.3712313013541055
Validation loss: 2.536286446385648

Epoch: 6| Step: 8
Training loss: 3.1228331110394447
Validation loss: 2.536043397519375

Epoch: 6| Step: 9
Training loss: 2.426601007257949
Validation loss: 2.537989814531899

Epoch: 6| Step: 10
Training loss: 2.972184934609968
Validation loss: 2.5336501150410164

Epoch: 6| Step: 11
Training loss: 2.596724952742221
Validation loss: 2.5342011763564383

Epoch: 6| Step: 12
Training loss: 2.76085134478665
Validation loss: 2.536570342857612

Epoch: 6| Step: 13
Training loss: 3.2929090899473983
Validation loss: 2.531964085752976

Epoch: 67| Step: 0
Training loss: 2.8694337782077377
Validation loss: 2.530519508439555

Epoch: 6| Step: 1
Training loss: 3.0952955296535993
Validation loss: 2.5324099632771984

Epoch: 6| Step: 2
Training loss: 3.076145213178109
Validation loss: 2.5407962071723844

Epoch: 6| Step: 3
Training loss: 2.7304872613151123
Validation loss: 2.547317418140567

Epoch: 6| Step: 4
Training loss: 2.849230839855588
Validation loss: 2.5607553971607886

Epoch: 6| Step: 5
Training loss: 2.488696675977113
Validation loss: 2.5478227649787013

Epoch: 6| Step: 6
Training loss: 2.990767896660377
Validation loss: 2.5441054900698026

Epoch: 6| Step: 7
Training loss: 2.3890537259306877
Validation loss: 2.5315089030695757

Epoch: 6| Step: 8
Training loss: 2.884253330495624
Validation loss: 2.524961465943394

Epoch: 6| Step: 9
Training loss: 2.8514451094201574
Validation loss: 2.5174485821508785

Epoch: 6| Step: 10
Training loss: 2.5789743584922
Validation loss: 2.5126010913823826

Epoch: 6| Step: 11
Training loss: 2.663427372283998
Validation loss: 2.5101671424627017

Epoch: 6| Step: 12
Training loss: 2.8943987982094264
Validation loss: 2.5076587164593698

Epoch: 6| Step: 13
Training loss: 3.8943625272974467
Validation loss: 2.5027467630417153

Epoch: 68| Step: 0
Training loss: 3.1355476901199575
Validation loss: 2.5065297395334

Epoch: 6| Step: 1
Training loss: 2.8866558145520242
Validation loss: 2.507322588435782

Epoch: 6| Step: 2
Training loss: 2.45657232756445
Validation loss: 2.5070033934913036

Epoch: 6| Step: 3
Training loss: 3.1120302757418328
Validation loss: 2.5046706971078856

Epoch: 6| Step: 4
Training loss: 3.3440510266713837
Validation loss: 2.5035593321298286

Epoch: 6| Step: 5
Training loss: 2.6991779418157065
Validation loss: 2.5040443004422746

Epoch: 6| Step: 6
Training loss: 2.7857935792865276
Validation loss: 2.5005050620714173

Epoch: 6| Step: 7
Training loss: 2.5758722809292993
Validation loss: 2.5046002691264904

Epoch: 6| Step: 8
Training loss: 1.7918977218799936
Validation loss: 2.508905764802462

Epoch: 6| Step: 9
Training loss: 3.167687117808602
Validation loss: 2.5284134500015076

Epoch: 6| Step: 10
Training loss: 3.272513247726122
Validation loss: 2.541602169356948

Epoch: 6| Step: 11
Training loss: 2.632122911650155
Validation loss: 2.528956984127128

Epoch: 6| Step: 12
Training loss: 3.0031819952439807
Validation loss: 2.527689108438494

Epoch: 6| Step: 13
Training loss: 3.0205859554331767
Validation loss: 2.522527363640928

Epoch: 69| Step: 0
Training loss: 2.7459105515994606
Validation loss: 2.5205014077328687

Epoch: 6| Step: 1
Training loss: 3.1413570329045233
Validation loss: 2.5086442009542154

Epoch: 6| Step: 2
Training loss: 2.636463746349536
Validation loss: 2.5044751577726974

Epoch: 6| Step: 3
Training loss: 2.4268405339900254
Validation loss: 2.502629098467855

Epoch: 6| Step: 4
Training loss: 2.723276951446284
Validation loss: 2.504051559685881

Epoch: 6| Step: 5
Training loss: 2.5180695781351217
Validation loss: 2.504292561179021

Epoch: 6| Step: 6
Training loss: 3.7288317538847604
Validation loss: 2.500425851094382

Epoch: 6| Step: 7
Training loss: 3.108410249496486
Validation loss: 2.5058734594062506

Epoch: 6| Step: 8
Training loss: 2.8648029774931323
Validation loss: 2.501999260724066

Epoch: 6| Step: 9
Training loss: 2.6878707984799584
Validation loss: 2.50620465901857

Epoch: 6| Step: 10
Training loss: 2.977061632814506
Validation loss: 2.5081423907717597

Epoch: 6| Step: 11
Training loss: 2.7370710759772336
Validation loss: 2.5074550540168214

Epoch: 6| Step: 12
Training loss: 2.356660810118884
Validation loss: 2.511687734652853

Epoch: 6| Step: 13
Training loss: 3.07747011915462
Validation loss: 2.5120028277393582

Epoch: 70| Step: 0
Training loss: 2.8844345202354447
Validation loss: 2.5206706215654178

Epoch: 6| Step: 1
Training loss: 3.0929629162730725
Validation loss: 2.530174963920744

Epoch: 6| Step: 2
Training loss: 2.8680144320647583
Validation loss: 2.5290009444927017

Epoch: 6| Step: 3
Training loss: 2.264799191160607
Validation loss: 2.5350458307636337

Epoch: 6| Step: 4
Training loss: 2.9062383507936054
Validation loss: 2.5400704018268123

Epoch: 6| Step: 5
Training loss: 2.1547218104252495
Validation loss: 2.5283597191181904

Epoch: 6| Step: 6
Training loss: 2.373997526917941
Validation loss: 2.52529509387738

Epoch: 6| Step: 7
Training loss: 2.831870280985709
Validation loss: 2.5233385920122

Epoch: 6| Step: 8
Training loss: 2.73356625177072
Validation loss: 2.522396160164832

Epoch: 6| Step: 9
Training loss: 2.936259555663064
Validation loss: 2.5200776388087784

Epoch: 6| Step: 10
Training loss: 3.159018029818717
Validation loss: 2.51766245685533

Epoch: 6| Step: 11
Training loss: 3.2296857519195803
Validation loss: 2.5118007167778806

Epoch: 6| Step: 12
Training loss: 3.365911609343606
Validation loss: 2.503756299681014

Epoch: 6| Step: 13
Training loss: 2.863580997696956
Validation loss: 2.509012384973524

Epoch: 71| Step: 0
Training loss: 2.206587323128977
Validation loss: 2.505520305370877

Epoch: 6| Step: 1
Training loss: 2.2502663772575286
Validation loss: 2.509079876246989

Epoch: 6| Step: 2
Training loss: 3.1093431020662847
Validation loss: 2.5109565548167048

Epoch: 6| Step: 3
Training loss: 3.158270613987851
Validation loss: 2.5111073135503106

Epoch: 6| Step: 4
Training loss: 2.7521061201593686
Validation loss: 2.5053611461290757

Epoch: 6| Step: 5
Training loss: 3.3593363914932572
Validation loss: 2.5038711140707073

Epoch: 6| Step: 6
Training loss: 2.6245660877362686
Validation loss: 2.5079957050920565

Epoch: 6| Step: 7
Training loss: 2.8711427437890307
Validation loss: 2.5121590996639287

Epoch: 6| Step: 8
Training loss: 2.828415576486123
Validation loss: 2.509641997481891

Epoch: 6| Step: 9
Training loss: 2.9839429292922874
Validation loss: 2.505203707220881

Epoch: 6| Step: 10
Training loss: 3.0841417713357866
Validation loss: 2.5008760906585956

Epoch: 6| Step: 11
Training loss: 2.701947964758066
Validation loss: 2.4932699800724887

Epoch: 6| Step: 12
Training loss: 2.540596929678976
Validation loss: 2.497433716287144

Epoch: 6| Step: 13
Training loss: 3.17120233929237
Validation loss: 2.495740940897626

Epoch: 72| Step: 0
Training loss: 2.3625026965252056
Validation loss: 2.4958153803955523

Epoch: 6| Step: 1
Training loss: 3.0285086279524647
Validation loss: 2.499196905946349

Epoch: 6| Step: 2
Training loss: 3.317815582282582
Validation loss: 2.4957366030019594

Epoch: 6| Step: 3
Training loss: 3.016056484523205
Validation loss: 2.4957301644538323

Epoch: 6| Step: 4
Training loss: 2.8921659743931536
Validation loss: 2.496211323124387

Epoch: 6| Step: 5
Training loss: 2.6289710026966864
Validation loss: 2.4995346533515153

Epoch: 6| Step: 6
Training loss: 2.5473340328761025
Validation loss: 2.5013530971318523

Epoch: 6| Step: 7
Training loss: 3.3103227477597916
Validation loss: 2.511954428405009

Epoch: 6| Step: 8
Training loss: 2.6806337337480586
Validation loss: 2.516779056104835

Epoch: 6| Step: 9
Training loss: 2.794244221575113
Validation loss: 2.519956257344936

Epoch: 6| Step: 10
Training loss: 2.962720027430452
Validation loss: 2.5209271555802157

Epoch: 6| Step: 11
Training loss: 3.1957841818825017
Validation loss: 2.5156201858285914

Epoch: 6| Step: 12
Training loss: 2.536656762937979
Validation loss: 2.5082553169345068

Epoch: 6| Step: 13
Training loss: 1.7842704862594676
Validation loss: 2.497608823512424

Epoch: 73| Step: 0
Training loss: 2.6990074593948683
Validation loss: 2.489437038389692

Epoch: 6| Step: 1
Training loss: 2.7673298381813063
Validation loss: 2.493334633974547

Epoch: 6| Step: 2
Training loss: 3.0605764771023747
Validation loss: 2.492698761777415

Epoch: 6| Step: 3
Training loss: 3.2665436105192027
Validation loss: 2.492232874258165

Epoch: 6| Step: 4
Training loss: 2.323766738150049
Validation loss: 2.4905689451151702

Epoch: 6| Step: 5
Training loss: 2.4967036449849926
Validation loss: 2.4946098373554224

Epoch: 6| Step: 6
Training loss: 2.893082517426131
Validation loss: 2.497982819258262

Epoch: 6| Step: 7
Training loss: 2.531618256331032
Validation loss: 2.5065628489057836

Epoch: 6| Step: 8
Training loss: 2.440757726364621
Validation loss: 2.4962200989321564

Epoch: 6| Step: 9
Training loss: 2.8486748274776956
Validation loss: 2.502123454898641

Epoch: 6| Step: 10
Training loss: 2.9636583534335506
Validation loss: 2.5051279748194073

Epoch: 6| Step: 11
Training loss: 3.202427783541929
Validation loss: 2.5035946915672915

Epoch: 6| Step: 12
Training loss: 3.363132096903228
Validation loss: 2.497416454435655

Epoch: 6| Step: 13
Training loss: 2.239920609974661
Validation loss: 2.495298714090189

Epoch: 74| Step: 0
Training loss: 2.975639460463823
Validation loss: 2.498034028269094

Epoch: 6| Step: 1
Training loss: 2.2619024804947516
Validation loss: 2.4937321219825153

Epoch: 6| Step: 2
Training loss: 3.1687907741112813
Validation loss: 2.5040993633859023

Epoch: 6| Step: 3
Training loss: 2.7240422796925774
Validation loss: 2.5036164224591304

Epoch: 6| Step: 4
Training loss: 3.3038842778479895
Validation loss: 2.5098837976799735

Epoch: 6| Step: 5
Training loss: 3.0593921695963884
Validation loss: 2.5039191720592706

Epoch: 6| Step: 6
Training loss: 3.086238798087932
Validation loss: 2.5042137597204963

Epoch: 6| Step: 7
Training loss: 2.469212935296676
Validation loss: 2.503982400727249

Epoch: 6| Step: 8
Training loss: 2.272035461384101
Validation loss: 2.4997934389405034

Epoch: 6| Step: 9
Training loss: 2.5698987633622195
Validation loss: 2.496955807581699

Epoch: 6| Step: 10
Training loss: 2.7111239410402543
Validation loss: 2.4976942925168544

Epoch: 6| Step: 11
Training loss: 2.937198379939652
Validation loss: 2.4955318720478106

Epoch: 6| Step: 12
Training loss: 2.9553806631628317
Validation loss: 2.493772028903019

Epoch: 6| Step: 13
Training loss: 2.78356014705721
Validation loss: 2.4900850241985024

Epoch: 75| Step: 0
Training loss: 3.052303232510387
Validation loss: 2.492214462345816

Epoch: 6| Step: 1
Training loss: 3.044881315126349
Validation loss: 2.4886265201222644

Epoch: 6| Step: 2
Training loss: 3.0687528342177592
Validation loss: 2.491829958769906

Epoch: 6| Step: 3
Training loss: 1.9283677503217473
Validation loss: 2.4859918250391364

Epoch: 6| Step: 4
Training loss: 2.878116411326762
Validation loss: 2.4896988294655484

Epoch: 6| Step: 5
Training loss: 3.2680077142145816
Validation loss: 2.497410519106871

Epoch: 6| Step: 6
Training loss: 3.0589817624354345
Validation loss: 2.4975998863006637

Epoch: 6| Step: 7
Training loss: 2.8589410504684616
Validation loss: 2.501248060454671

Epoch: 6| Step: 8
Training loss: 3.00372544080558
Validation loss: 2.5073411347950416

Epoch: 6| Step: 9
Training loss: 2.4843920821076453
Validation loss: 2.5094985903486515

Epoch: 6| Step: 10
Training loss: 3.1294083591250312
Validation loss: 2.5096003463344503

Epoch: 6| Step: 11
Training loss: 2.5366408786975048
Validation loss: 2.500575971396712

Epoch: 6| Step: 12
Training loss: 2.403128246210929
Validation loss: 2.4943352252039004

Epoch: 6| Step: 13
Training loss: 2.0599870111000405
Validation loss: 2.4967730748681047

Epoch: 76| Step: 0
Training loss: 2.7052965206852173
Validation loss: 2.500446499155417

Epoch: 6| Step: 1
Training loss: 3.2402691048847028
Validation loss: 2.4929167230037894

Epoch: 6| Step: 2
Training loss: 3.0608336917396817
Validation loss: 2.4973762598095854

Epoch: 6| Step: 3
Training loss: 2.8609833076680773
Validation loss: 2.506025481450817

Epoch: 6| Step: 4
Training loss: 2.7716223566118994
Validation loss: 2.507505214867602

Epoch: 6| Step: 5
Training loss: 2.145733494581013
Validation loss: 2.5064595448264755

Epoch: 6| Step: 6
Training loss: 2.48265294305933
Validation loss: 2.51753857100385

Epoch: 6| Step: 7
Training loss: 2.9600867506150883
Validation loss: 2.5416263612092846

Epoch: 6| Step: 8
Training loss: 3.279621701173417
Validation loss: 2.5071394282301567

Epoch: 6| Step: 9
Training loss: 3.432567317160848
Validation loss: 2.4864307663319285

Epoch: 6| Step: 10
Training loss: 2.282945290423352
Validation loss: 2.483291408755877

Epoch: 6| Step: 11
Training loss: 2.6285378366598495
Validation loss: 2.483346793002068

Epoch: 6| Step: 12
Training loss: 2.5083985401519775
Validation loss: 2.4895407790236495

Epoch: 6| Step: 13
Training loss: 3.0094474807519562
Validation loss: 2.491903795976091

Epoch: 77| Step: 0
Training loss: 2.723001510205027
Validation loss: 2.4895956051397405

Epoch: 6| Step: 1
Training loss: 3.3699042386448785
Validation loss: 2.483862021818593

Epoch: 6| Step: 2
Training loss: 3.283878399938258
Validation loss: 2.4803364504064263

Epoch: 6| Step: 3
Training loss: 2.5284134783916183
Validation loss: 2.4842735409633203

Epoch: 6| Step: 4
Training loss: 2.451525999226611
Validation loss: 2.473458003090775

Epoch: 6| Step: 5
Training loss: 3.352710731704762
Validation loss: 2.4753494291139524

Epoch: 6| Step: 6
Training loss: 2.689664013807604
Validation loss: 2.481664962498004

Epoch: 6| Step: 7
Training loss: 2.393015146630793
Validation loss: 2.4947424353748677

Epoch: 6| Step: 8
Training loss: 2.8707736920351885
Validation loss: 2.5211200095156596

Epoch: 6| Step: 9
Training loss: 3.257186866166559
Validation loss: 2.509289619534813

Epoch: 6| Step: 10
Training loss: 2.9032628284336153
Validation loss: 2.497921607831721

Epoch: 6| Step: 11
Training loss: 2.0386672532101757
Validation loss: 2.495369458016426

Epoch: 6| Step: 12
Training loss: 2.8083565602535305
Validation loss: 2.495103319793109

Epoch: 6| Step: 13
Training loss: 2.210006463917389
Validation loss: 2.4935034829766005

Epoch: 78| Step: 0
Training loss: 3.406375147769087
Validation loss: 2.5011389711745364

Epoch: 6| Step: 1
Training loss: 3.11560416104647
Validation loss: 2.508989558465108

Epoch: 6| Step: 2
Training loss: 2.6551371318798043
Validation loss: 2.4972588205782413

Epoch: 6| Step: 3
Training loss: 2.932372467571986
Validation loss: 2.4963081562160716

Epoch: 6| Step: 4
Training loss: 2.5405860438064063
Validation loss: 2.4836141244490078

Epoch: 6| Step: 5
Training loss: 2.949651380726588
Validation loss: 2.4792373831895334

Epoch: 6| Step: 6
Training loss: 3.180976924904886
Validation loss: 2.479775954095334

Epoch: 6| Step: 7
Training loss: 2.772875489794498
Validation loss: 2.472684032872029

Epoch: 6| Step: 8
Training loss: 3.0326204643003325
Validation loss: 2.474189416081053

Epoch: 6| Step: 9
Training loss: 2.1491254225352017
Validation loss: 2.4749240322475914

Epoch: 6| Step: 10
Training loss: 2.9003541269799533
Validation loss: 2.4778119790568907

Epoch: 6| Step: 11
Training loss: 2.173658777377155
Validation loss: 2.4720401846297655

Epoch: 6| Step: 12
Training loss: 2.6846069022606507
Validation loss: 2.4767824888321646

Epoch: 6| Step: 13
Training loss: 2.579863915513917
Validation loss: 2.4808384639254806

Epoch: 79| Step: 0
Training loss: 2.4233449105358327
Validation loss: 2.486062306858323

Epoch: 6| Step: 1
Training loss: 2.3775791418980714
Validation loss: 2.5021570108893685

Epoch: 6| Step: 2
Training loss: 2.5183819182392693
Validation loss: 2.526215623389094

Epoch: 6| Step: 3
Training loss: 3.0465007845616046
Validation loss: 2.5088690843970403

Epoch: 6| Step: 4
Training loss: 2.856847093805129
Validation loss: 2.5118975678953244

Epoch: 6| Step: 5
Training loss: 2.8734903103578935
Validation loss: 2.4942071239156904

Epoch: 6| Step: 6
Training loss: 2.720227333414044
Validation loss: 2.491794974581756

Epoch: 6| Step: 7
Training loss: 2.827593084231516
Validation loss: 2.488637385014421

Epoch: 6| Step: 8
Training loss: 3.089077590496461
Validation loss: 2.4899283264604333

Epoch: 6| Step: 9
Training loss: 2.7826423160320424
Validation loss: 2.490975994980511

Epoch: 6| Step: 10
Training loss: 2.945659262888699
Validation loss: 2.489085775144918

Epoch: 6| Step: 11
Training loss: 2.209416273883505
Validation loss: 2.4992366137982627

Epoch: 6| Step: 12
Training loss: 3.4401800631925505
Validation loss: 2.5163167161597415

Epoch: 6| Step: 13
Training loss: 3.3382560302295956
Validation loss: 2.567119099880884

Epoch: 80| Step: 0
Training loss: 2.763205984361593
Validation loss: 2.5190117733785313

Epoch: 6| Step: 1
Training loss: 3.0059989713361226
Validation loss: 2.4949817981072875

Epoch: 6| Step: 2
Training loss: 2.826341604159575
Validation loss: 2.477108127026921

Epoch: 6| Step: 3
Training loss: 2.779798321715376
Validation loss: 2.470088551726527

Epoch: 6| Step: 4
Training loss: 2.8061334394618367
Validation loss: 2.4729789773793143

Epoch: 6| Step: 5
Training loss: 2.1640054302746794
Validation loss: 2.4832870238201523

Epoch: 6| Step: 6
Training loss: 2.604723319005878
Validation loss: 2.494508754518996

Epoch: 6| Step: 7
Training loss: 3.0162329184550027
Validation loss: 2.528469281579611

Epoch: 6| Step: 8
Training loss: 2.72617308888133
Validation loss: 2.552905756363479

Epoch: 6| Step: 9
Training loss: 2.860925139604136
Validation loss: 2.540429928118525

Epoch: 6| Step: 10
Training loss: 3.446089399633816
Validation loss: 2.5623895474771983

Epoch: 6| Step: 11
Training loss: 2.9241749896016844
Validation loss: 2.55297086215799

Epoch: 6| Step: 12
Training loss: 2.850036714551585
Validation loss: 2.525516274637535

Epoch: 6| Step: 13
Training loss: 2.727995749926123
Validation loss: 2.51359396117205

Epoch: 81| Step: 0
Training loss: 2.2443323808754236
Validation loss: 2.5097184951306946

Epoch: 6| Step: 1
Training loss: 3.336853044648078
Validation loss: 2.5093746973333118

Epoch: 6| Step: 2
Training loss: 2.745819381963996
Validation loss: 2.507547996285017

Epoch: 6| Step: 3
Training loss: 2.980225239376546
Validation loss: 2.513283821961549

Epoch: 6| Step: 4
Training loss: 2.9251902330925885
Validation loss: 2.52020127777862

Epoch: 6| Step: 5
Training loss: 3.0511685368572508
Validation loss: 2.5219652524012983

Epoch: 6| Step: 6
Training loss: 2.7141734221900147
Validation loss: 2.5041995139546964

Epoch: 6| Step: 7
Training loss: 2.396181120024306
Validation loss: 2.4907061208788637

Epoch: 6| Step: 8
Training loss: 2.622099591026014
Validation loss: 2.4839772056677885

Epoch: 6| Step: 9
Training loss: 2.8957327589687463
Validation loss: 2.479437298237788

Epoch: 6| Step: 10
Training loss: 2.6676286114735763
Validation loss: 2.480270840610257

Epoch: 6| Step: 11
Training loss: 2.8437100921178122
Validation loss: 2.4801104507005265

Epoch: 6| Step: 12
Training loss: 2.90536682491714
Validation loss: 2.475455351882018

Epoch: 6| Step: 13
Training loss: 2.882326162609987
Validation loss: 2.488422687724811

Epoch: 82| Step: 0
Training loss: 3.00363019014539
Validation loss: 2.4746132982452154

Epoch: 6| Step: 1
Training loss: 2.235804174088287
Validation loss: 2.4685887732819234

Epoch: 6| Step: 2
Training loss: 3.3578831398528752
Validation loss: 2.465948751088128

Epoch: 6| Step: 3
Training loss: 2.7095713402380377
Validation loss: 2.4649093793666217

Epoch: 6| Step: 4
Training loss: 2.848161566212664
Validation loss: 2.467833155973416

Epoch: 6| Step: 5
Training loss: 3.350012503073974
Validation loss: 2.467187110796783

Epoch: 6| Step: 6
Training loss: 2.9121332813614638
Validation loss: 2.466874310005386

Epoch: 6| Step: 7
Training loss: 2.831027233126193
Validation loss: 2.4708412869460004

Epoch: 6| Step: 8
Training loss: 2.9646451177389346
Validation loss: 2.4707774431149807

Epoch: 6| Step: 9
Training loss: 2.819120794635898
Validation loss: 2.4689718811091037

Epoch: 6| Step: 10
Training loss: 2.414770818699373
Validation loss: 2.467744376604735

Epoch: 6| Step: 11
Training loss: 2.1690672145012404
Validation loss: 2.48120499209466

Epoch: 6| Step: 12
Training loss: 2.329751694509277
Validation loss: 2.467848082768932

Epoch: 6| Step: 13
Training loss: 3.1586119623671083
Validation loss: 2.472222464106985

Epoch: 83| Step: 0
Training loss: 2.6883884114793686
Validation loss: 2.4729700641527526

Epoch: 6| Step: 1
Training loss: 2.8758659717170882
Validation loss: 2.474456862956941

Epoch: 6| Step: 2
Training loss: 3.131596736022285
Validation loss: 2.4715544344593456

Epoch: 6| Step: 3
Training loss: 3.2348977371396113
Validation loss: 2.4666432069498736

Epoch: 6| Step: 4
Training loss: 3.1307877920895053
Validation loss: 2.464321130148057

Epoch: 6| Step: 5
Training loss: 2.8066004442963663
Validation loss: 2.46201521842312

Epoch: 6| Step: 6
Training loss: 2.187464686517417
Validation loss: 2.461470537848583

Epoch: 6| Step: 7
Training loss: 3.06699026584231
Validation loss: 2.45820158752626

Epoch: 6| Step: 8
Training loss: 2.465347456208553
Validation loss: 2.459580681860515

Epoch: 6| Step: 9
Training loss: 2.630351107407942
Validation loss: 2.4613048929658863

Epoch: 6| Step: 10
Training loss: 2.9353569817053575
Validation loss: 2.4636954634805415

Epoch: 6| Step: 11
Training loss: 2.5873239724549264
Validation loss: 2.4723622178477878

Epoch: 6| Step: 12
Training loss: 2.5624358006320547
Validation loss: 2.467448306632227

Epoch: 6| Step: 13
Training loss: 2.4773438962841925
Validation loss: 2.47044756983586

Epoch: 84| Step: 0
Training loss: 2.838971829265532
Validation loss: 2.476540750139086

Epoch: 6| Step: 1
Training loss: 2.906669176287253
Validation loss: 2.487831925526069

Epoch: 6| Step: 2
Training loss: 1.8677784132340198
Validation loss: 2.477000726609398

Epoch: 6| Step: 3
Training loss: 3.164427785627161
Validation loss: 2.4670299141658787

Epoch: 6| Step: 4
Training loss: 2.4049768423761844
Validation loss: 2.4649833032675343

Epoch: 6| Step: 5
Training loss: 2.8918569877794016
Validation loss: 2.4616733089720686

Epoch: 6| Step: 6
Training loss: 2.990243942873328
Validation loss: 2.4667240696818133

Epoch: 6| Step: 7
Training loss: 2.8148278669236872
Validation loss: 2.4575460941764375

Epoch: 6| Step: 8
Training loss: 2.6510333727473916
Validation loss: 2.461199429908483

Epoch: 6| Step: 9
Training loss: 3.292202209816375
Validation loss: 2.460247975945281

Epoch: 6| Step: 10
Training loss: 2.4289726358680737
Validation loss: 2.4652705420708

Epoch: 6| Step: 11
Training loss: 3.1477631634780927
Validation loss: 2.4649281387622293

Epoch: 6| Step: 12
Training loss: 3.038807993138928
Validation loss: 2.4694449766773303

Epoch: 6| Step: 13
Training loss: 1.997695847269151
Validation loss: 2.4743955502822033

Epoch: 85| Step: 0
Training loss: 2.2900793531570263
Validation loss: 2.469898100736326

Epoch: 6| Step: 1
Training loss: 3.1613666116815033
Validation loss: 2.481880976727225

Epoch: 6| Step: 2
Training loss: 2.962768310758103
Validation loss: 2.4875101491723424

Epoch: 6| Step: 3
Training loss: 2.1773498469371044
Validation loss: 2.496775237782594

Epoch: 6| Step: 4
Training loss: 3.278424308793224
Validation loss: 2.498580383940448

Epoch: 6| Step: 5
Training loss: 3.1006602168760087
Validation loss: 2.492018466159439

Epoch: 6| Step: 6
Training loss: 2.005871736512543
Validation loss: 2.4800630270748805

Epoch: 6| Step: 7
Training loss: 3.288689598999038
Validation loss: 2.4780627824888253

Epoch: 6| Step: 8
Training loss: 2.1578294801699975
Validation loss: 2.4785181291483624

Epoch: 6| Step: 9
Training loss: 2.5561519240239625
Validation loss: 2.4724251881311874

Epoch: 6| Step: 10
Training loss: 2.8462305673263386
Validation loss: 2.476614806127282

Epoch: 6| Step: 11
Training loss: 2.363627662175841
Validation loss: 2.4654543733142313

Epoch: 6| Step: 12
Training loss: 3.471195767741053
Validation loss: 2.4684692447472276

Epoch: 6| Step: 13
Training loss: 2.7600470721335655
Validation loss: 2.4773618092025527

Epoch: 86| Step: 0
Training loss: 2.401031582384316
Validation loss: 2.484091244822347

Epoch: 6| Step: 1
Training loss: 2.199596528422406
Validation loss: 2.48552081973056

Epoch: 6| Step: 2
Training loss: 2.9600068494356657
Validation loss: 2.479331051333343

Epoch: 6| Step: 3
Training loss: 2.9716442255216506
Validation loss: 2.4798518290799207

Epoch: 6| Step: 4
Training loss: 2.9978703251151564
Validation loss: 2.4801654253297474

Epoch: 6| Step: 5
Training loss: 2.7991809396322154
Validation loss: 2.4794511915283066

Epoch: 6| Step: 6
Training loss: 3.365168202746466
Validation loss: 2.488637955710963

Epoch: 6| Step: 7
Training loss: 2.9875717218321003
Validation loss: 2.495732318513662

Epoch: 6| Step: 8
Training loss: 2.5783252985047618
Validation loss: 2.5029719448711854

Epoch: 6| Step: 9
Training loss: 2.3287497072736687
Validation loss: 2.4936700279745616

Epoch: 6| Step: 10
Training loss: 3.215825057409952
Validation loss: 2.487114587975411

Epoch: 6| Step: 11
Training loss: 2.598372052458625
Validation loss: 2.48622286033968

Epoch: 6| Step: 12
Training loss: 2.3675005110968708
Validation loss: 2.4960444136084456

Epoch: 6| Step: 13
Training loss: 2.7158577102670516
Validation loss: 2.4940197163282503

Epoch: 87| Step: 0
Training loss: 3.1799050896354366
Validation loss: 2.4995824372834465

Epoch: 6| Step: 1
Training loss: 3.007727366642186
Validation loss: 2.495101973808712

Epoch: 6| Step: 2
Training loss: 2.7090211630635648
Validation loss: 2.5205843409358333

Epoch: 6| Step: 3
Training loss: 2.583209301421856
Validation loss: 2.545987356338907

Epoch: 6| Step: 4
Training loss: 3.288955360534166
Validation loss: 2.5219078536660646

Epoch: 6| Step: 5
Training loss: 3.346741381060703
Validation loss: 2.506054410436426

Epoch: 6| Step: 6
Training loss: 2.6118567080837365
Validation loss: 2.488496014092712

Epoch: 6| Step: 7
Training loss: 3.0139716957854144
Validation loss: 2.468538710624689

Epoch: 6| Step: 8
Training loss: 2.7997373287426153
Validation loss: 2.4648040434939773

Epoch: 6| Step: 9
Training loss: 2.611945616385246
Validation loss: 2.465749591019125

Epoch: 6| Step: 10
Training loss: 2.6596257917443604
Validation loss: 2.46924111717735

Epoch: 6| Step: 11
Training loss: 2.554131403602343
Validation loss: 2.4673189964233773

Epoch: 6| Step: 12
Training loss: 2.127436755413639
Validation loss: 2.4662529323877638

Epoch: 6| Step: 13
Training loss: 1.8279663408340006
Validation loss: 2.473611272140941

Epoch: 88| Step: 0
Training loss: 2.755485265956492
Validation loss: 2.482359692232096

Epoch: 6| Step: 1
Training loss: 2.9250689506555
Validation loss: 2.491031731179059

Epoch: 6| Step: 2
Training loss: 2.5785033902006735
Validation loss: 2.484185020967152

Epoch: 6| Step: 3
Training loss: 2.354275073590881
Validation loss: 2.483419914646793

Epoch: 6| Step: 4
Training loss: 2.9118201907260888
Validation loss: 2.497906997247182

Epoch: 6| Step: 5
Training loss: 2.318014117582182
Validation loss: 2.5198308900232638

Epoch: 6| Step: 6
Training loss: 2.9779272279987548
Validation loss: 2.5377413817700725

Epoch: 6| Step: 7
Training loss: 3.2915163287505718
Validation loss: 2.5501232379230165

Epoch: 6| Step: 8
Training loss: 3.085271449581469
Validation loss: 2.560101171387949

Epoch: 6| Step: 9
Training loss: 2.4174958045394455
Validation loss: 2.533628139619327

Epoch: 6| Step: 10
Training loss: 2.3450256944887617
Validation loss: 2.506254058798598

Epoch: 6| Step: 11
Training loss: 2.7774405804586557
Validation loss: 2.4964903802443095

Epoch: 6| Step: 12
Training loss: 3.021149629717807
Validation loss: 2.4801184358658737

Epoch: 6| Step: 13
Training loss: 3.2911408080790947
Validation loss: 2.467927916582357

Epoch: 89| Step: 0
Training loss: 2.8015038743190606
Validation loss: 2.4736616549791997

Epoch: 6| Step: 1
Training loss: 2.817929092944634
Validation loss: 2.4778423703532635

Epoch: 6| Step: 2
Training loss: 2.963168871091548
Validation loss: 2.4853930212417747

Epoch: 6| Step: 3
Training loss: 2.4881206562432645
Validation loss: 2.485419739602162

Epoch: 6| Step: 4
Training loss: 2.6004668440213283
Validation loss: 2.490730315594331

Epoch: 6| Step: 5
Training loss: 2.732989586948136
Validation loss: 2.497126831512044

Epoch: 6| Step: 6
Training loss: 3.072396616922966
Validation loss: 2.486773415079661

Epoch: 6| Step: 7
Training loss: 2.625395427166509
Validation loss: 2.494765794035724

Epoch: 6| Step: 8
Training loss: 2.750271003547931
Validation loss: 2.493404202908615

Epoch: 6| Step: 9
Training loss: 2.524634298903642
Validation loss: 2.4876514905844758

Epoch: 6| Step: 10
Training loss: 3.149597560061323
Validation loss: 2.4857574803818894

Epoch: 6| Step: 11
Training loss: 2.0946159280224363
Validation loss: 2.47796422459621

Epoch: 6| Step: 12
Training loss: 3.273421185072708
Validation loss: 2.4764481866152694

Epoch: 6| Step: 13
Training loss: 3.04950369877426
Validation loss: 2.4778220843543224

Epoch: 90| Step: 0
Training loss: 3.330115640826068
Validation loss: 2.498489743047147

Epoch: 6| Step: 1
Training loss: 2.1434041937133963
Validation loss: 2.521107744050926

Epoch: 6| Step: 2
Training loss: 3.0835149213226667
Validation loss: 2.5264743209022904

Epoch: 6| Step: 3
Training loss: 3.0294530202342864
Validation loss: 2.5258823728091295

Epoch: 6| Step: 4
Training loss: 2.838142315598157
Validation loss: 2.522753588136484

Epoch: 6| Step: 5
Training loss: 2.875732328604533
Validation loss: 2.516742284684974

Epoch: 6| Step: 6
Training loss: 2.243970846289359
Validation loss: 2.5074965409216254

Epoch: 6| Step: 7
Training loss: 3.3747215156101937
Validation loss: 2.512706494690974

Epoch: 6| Step: 8
Training loss: 2.508181345782254
Validation loss: 2.485036615218444

Epoch: 6| Step: 9
Training loss: 2.6152369276266483
Validation loss: 2.476507203158375

Epoch: 6| Step: 10
Training loss: 2.9965035408211698
Validation loss: 2.460277761537169

Epoch: 6| Step: 11
Training loss: 2.6411051116213313
Validation loss: 2.4655847514207005

Epoch: 6| Step: 12
Training loss: 2.438357275816817
Validation loss: 2.4747016644066813

Epoch: 6| Step: 13
Training loss: 2.604736957412316
Validation loss: 2.466712419218049

Epoch: 91| Step: 0
Training loss: 2.3771966513242826
Validation loss: 2.4846125044380076

Epoch: 6| Step: 1
Training loss: 2.931420711272029
Validation loss: 2.5341167970010425

Epoch: 6| Step: 2
Training loss: 2.8601063277746785
Validation loss: 2.5761521612860987

Epoch: 6| Step: 3
Training loss: 2.744129330214745
Validation loss: 2.5956741077436942

Epoch: 6| Step: 4
Training loss: 2.9463575214225055
Validation loss: 2.533371682705249

Epoch: 6| Step: 5
Training loss: 2.2951775331332986
Validation loss: 2.490284640797967

Epoch: 6| Step: 6
Training loss: 3.3783386106470257
Validation loss: 2.459292159293407

Epoch: 6| Step: 7
Training loss: 2.528536154152284
Validation loss: 2.4632597467578203

Epoch: 6| Step: 8
Training loss: 3.0160854166011903
Validation loss: 2.475654650707406

Epoch: 6| Step: 9
Training loss: 3.0819603896123726
Validation loss: 2.47113744525718

Epoch: 6| Step: 10
Training loss: 2.3799465266399427
Validation loss: 2.470785510322109

Epoch: 6| Step: 11
Training loss: 2.9413015238038183
Validation loss: 2.4672156233859766

Epoch: 6| Step: 12
Training loss: 3.2186080753184103
Validation loss: 2.461949936757919

Epoch: 6| Step: 13
Training loss: 2.341867428337992
Validation loss: 2.4672048324903737

Epoch: 92| Step: 0
Training loss: 2.9950942619150314
Validation loss: 2.470376086280151

Epoch: 6| Step: 1
Training loss: 2.8679943144886906
Validation loss: 2.4814052713911936

Epoch: 6| Step: 2
Training loss: 2.3263262257906283
Validation loss: 2.5136552733581996

Epoch: 6| Step: 3
Training loss: 2.8360551962061202
Validation loss: 2.527817266474995

Epoch: 6| Step: 4
Training loss: 2.670607059631867
Validation loss: 2.551040459105175

Epoch: 6| Step: 5
Training loss: 2.7442407121427306
Validation loss: 2.589032524233849

Epoch: 6| Step: 6
Training loss: 2.706416248738909
Validation loss: 2.6066031000913212

Epoch: 6| Step: 7
Training loss: 2.986525474798615
Validation loss: 2.6084003972839938

Epoch: 6| Step: 8
Training loss: 2.880791842428796
Validation loss: 2.603473325085921

Epoch: 6| Step: 9
Training loss: 3.3107758839485575
Validation loss: 2.5845556222299337

Epoch: 6| Step: 10
Training loss: 2.79103595574077
Validation loss: 2.5570182322455532

Epoch: 6| Step: 11
Training loss: 2.7397353464941365
Validation loss: 2.500487900367364

Epoch: 6| Step: 12
Training loss: 2.7938887354733426
Validation loss: 2.463797209078815

Epoch: 6| Step: 13
Training loss: 2.262660434999054
Validation loss: 2.458616642576379

Epoch: 93| Step: 0
Training loss: 2.834517025990474
Validation loss: 2.4594290536834404

Epoch: 6| Step: 1
Training loss: 3.1083559446219793
Validation loss: 2.4694132269010365

Epoch: 6| Step: 2
Training loss: 2.7476481871694056
Validation loss: 2.4722743923155903

Epoch: 6| Step: 3
Training loss: 2.4217068521517606
Validation loss: 2.4718594183673854

Epoch: 6| Step: 4
Training loss: 2.6020386406201337
Validation loss: 2.4775943373465306

Epoch: 6| Step: 5
Training loss: 3.700439380641473
Validation loss: 2.477724848514748

Epoch: 6| Step: 6
Training loss: 2.7868556419738826
Validation loss: 2.476642307548202

Epoch: 6| Step: 7
Training loss: 2.648328030554726
Validation loss: 2.4649176717089594

Epoch: 6| Step: 8
Training loss: 3.2659351256375326
Validation loss: 2.4682494809186384

Epoch: 6| Step: 9
Training loss: 2.7486046805833158
Validation loss: 2.4611681987437377

Epoch: 6| Step: 10
Training loss: 2.5013096240180017
Validation loss: 2.4584289474483594

Epoch: 6| Step: 11
Training loss: 2.0084679865775033
Validation loss: 2.4632040482439983

Epoch: 6| Step: 12
Training loss: 3.0775136582592872
Validation loss: 2.46808597372377

Epoch: 6| Step: 13
Training loss: 1.813421475544924
Validation loss: 2.47051173661355

Epoch: 94| Step: 0
Training loss: 2.933352525243687
Validation loss: 2.4715259605145734

Epoch: 6| Step: 1
Training loss: 2.7828589082646835
Validation loss: 2.4751202883160355

Epoch: 6| Step: 2
Training loss: 3.0620241379337725
Validation loss: 2.468899714150376

Epoch: 6| Step: 3
Training loss: 2.724563434172498
Validation loss: 2.470239039907278

Epoch: 6| Step: 4
Training loss: 3.032268235170565
Validation loss: 2.4609028871247114

Epoch: 6| Step: 5
Training loss: 2.0703346107309866
Validation loss: 2.4665200320689897

Epoch: 6| Step: 6
Training loss: 2.5998944041009793
Validation loss: 2.4580607011919553

Epoch: 6| Step: 7
Training loss: 2.992277696808793
Validation loss: 2.451908628019373

Epoch: 6| Step: 8
Training loss: 2.7487235141118234
Validation loss: 2.4543677795840915

Epoch: 6| Step: 9
Training loss: 2.8541685972184014
Validation loss: 2.4573490093791857

Epoch: 6| Step: 10
Training loss: 2.9853280827400996
Validation loss: 2.4572008690215115

Epoch: 6| Step: 11
Training loss: 2.3581431627825267
Validation loss: 2.454971721940684

Epoch: 6| Step: 12
Training loss: 2.640106150198125
Validation loss: 2.467104368389941

Epoch: 6| Step: 13
Training loss: 2.4825031258216685
Validation loss: 2.466275351965732

Epoch: 95| Step: 0
Training loss: 2.833091295413364
Validation loss: 2.4725153059794485

Epoch: 6| Step: 1
Training loss: 2.8772613919621173
Validation loss: 2.4860579252631276

Epoch: 6| Step: 2
Training loss: 2.830580514738106
Validation loss: 2.4900099006640826

Epoch: 6| Step: 3
Training loss: 2.632314753811703
Validation loss: 2.493377541318544

Epoch: 6| Step: 4
Training loss: 2.71448779070967
Validation loss: 2.482308630806819

Epoch: 6| Step: 5
Training loss: 2.892769672612076
Validation loss: 2.4809395013070534

Epoch: 6| Step: 6
Training loss: 2.6975813452305273
Validation loss: 2.4770752076632943

Epoch: 6| Step: 7
Training loss: 2.6672597364712227
Validation loss: 2.4804563176278984

Epoch: 6| Step: 8
Training loss: 2.387590863960363
Validation loss: 2.4630688000122083

Epoch: 6| Step: 9
Training loss: 2.584132091541457
Validation loss: 2.4718366138381724

Epoch: 6| Step: 10
Training loss: 2.922610756347426
Validation loss: 2.456984701866192

Epoch: 6| Step: 11
Training loss: 3.0508895639883185
Validation loss: 2.459912671556601

Epoch: 6| Step: 12
Training loss: 2.5964546349975657
Validation loss: 2.4652140164905134

Epoch: 6| Step: 13
Training loss: 2.8015205546109625
Validation loss: 2.4585713663576003

Epoch: 96| Step: 0
Training loss: 2.8329803770539006
Validation loss: 2.4578574463705825

Epoch: 6| Step: 1
Training loss: 2.7047546413645196
Validation loss: 2.459152121475971

Epoch: 6| Step: 2
Training loss: 2.1353219608302183
Validation loss: 2.4569579805309636

Epoch: 6| Step: 3
Training loss: 2.300898550569896
Validation loss: 2.4686170837917087

Epoch: 6| Step: 4
Training loss: 3.301490915066717
Validation loss: 2.465911457688484

Epoch: 6| Step: 5
Training loss: 2.801890048672259
Validation loss: 2.472577903252963

Epoch: 6| Step: 6
Training loss: 2.7930069927451733
Validation loss: 2.4789006611078044

Epoch: 6| Step: 7
Training loss: 2.928173925424619
Validation loss: 2.4627040186568427

Epoch: 6| Step: 8
Training loss: 3.0226571902157526
Validation loss: 2.457691637247016

Epoch: 6| Step: 9
Training loss: 2.2890856224168137
Validation loss: 2.461362667569051

Epoch: 6| Step: 10
Training loss: 2.9835485142796903
Validation loss: 2.4561780620787563

Epoch: 6| Step: 11
Training loss: 2.7886117950349782
Validation loss: 2.451335335937796

Epoch: 6| Step: 12
Training loss: 2.6910784650496
Validation loss: 2.4591248299879727

Epoch: 6| Step: 13
Training loss: 2.5803354670641396
Validation loss: 2.4651215164397224

Epoch: 97| Step: 0
Training loss: 2.7235628695584126
Validation loss: 2.4622875109243574

Epoch: 6| Step: 1
Training loss: 2.514374036909654
Validation loss: 2.472631575163816

Epoch: 6| Step: 2
Training loss: 2.934832883947851
Validation loss: 2.456005773295959

Epoch: 6| Step: 3
Training loss: 2.4968264464048753
Validation loss: 2.4585920635354346

Epoch: 6| Step: 4
Training loss: 2.9328973301613503
Validation loss: 2.467667663920869

Epoch: 6| Step: 5
Training loss: 2.4176603006513764
Validation loss: 2.4756476421594344

Epoch: 6| Step: 6
Training loss: 2.5568156579515735
Validation loss: 2.474419713328798

Epoch: 6| Step: 7
Training loss: 3.2164256768222526
Validation loss: 2.4726378799764643

Epoch: 6| Step: 8
Training loss: 3.2553400038474343
Validation loss: 2.4708426720852676

Epoch: 6| Step: 9
Training loss: 2.725184051177639
Validation loss: 2.4624621034676024

Epoch: 6| Step: 10
Training loss: 2.5273270525373364
Validation loss: 2.454002532228175

Epoch: 6| Step: 11
Training loss: 2.6520548285315666
Validation loss: 2.456813402523701

Epoch: 6| Step: 12
Training loss: 2.6081279584409423
Validation loss: 2.4630665195484096

Epoch: 6| Step: 13
Training loss: 2.691986862915769
Validation loss: 2.462577336759886

Epoch: 98| Step: 0
Training loss: 3.0259199966070978
Validation loss: 2.468419039458055

Epoch: 6| Step: 1
Training loss: 3.2188541432541538
Validation loss: 2.4680854502108005

Epoch: 6| Step: 2
Training loss: 2.9161245296349856
Validation loss: 2.4645451908226716

Epoch: 6| Step: 3
Training loss: 2.796202850558186
Validation loss: 2.4681921251102117

Epoch: 6| Step: 4
Training loss: 2.4535067315950903
Validation loss: 2.4584144619221373

Epoch: 6| Step: 5
Training loss: 2.443362595078064
Validation loss: 2.459134728517135

Epoch: 6| Step: 6
Training loss: 2.7217485400669266
Validation loss: 2.463050260644224

Epoch: 6| Step: 7
Training loss: 2.3505483068822604
Validation loss: 2.4788881650250203

Epoch: 6| Step: 8
Training loss: 2.7901410921031884
Validation loss: 2.507401669467861

Epoch: 6| Step: 9
Training loss: 2.4032419401966414
Validation loss: 2.5004731950749477

Epoch: 6| Step: 10
Training loss: 2.8664193852545523
Validation loss: 2.4930145982487715

Epoch: 6| Step: 11
Training loss: 2.5479233345283436
Validation loss: 2.4975411290081477

Epoch: 6| Step: 12
Training loss: 2.9510484287136465
Validation loss: 2.478445365074955

Epoch: 6| Step: 13
Training loss: 3.1719328776373588
Validation loss: 2.4787155941229386

Epoch: 99| Step: 0
Training loss: 3.1569270550309096
Validation loss: 2.468894826520333

Epoch: 6| Step: 1
Training loss: 3.222057235995545
Validation loss: 2.4661733426952637

Epoch: 6| Step: 2
Training loss: 2.637343495141417
Validation loss: 2.451848045934274

Epoch: 6| Step: 3
Training loss: 2.2594492962072303
Validation loss: 2.4465329750830023

Epoch: 6| Step: 4
Training loss: 2.3695109330339834
Validation loss: 2.448464051003403

Epoch: 6| Step: 5
Training loss: 2.3005464236461464
Validation loss: 2.446035767308259

Epoch: 6| Step: 6
Training loss: 2.9072746193437373
Validation loss: 2.448306758242186

Epoch: 6| Step: 7
Training loss: 2.999130917868076
Validation loss: 2.4360296991147155

Epoch: 6| Step: 8
Training loss: 2.6513581951965373
Validation loss: 2.4521540861524995

Epoch: 6| Step: 9
Training loss: 2.8876482508529837
Validation loss: 2.450516925219444

Epoch: 6| Step: 10
Training loss: 2.6144106581205704
Validation loss: 2.4529699387983253

Epoch: 6| Step: 11
Training loss: 2.943113766088005
Validation loss: 2.4562314128801304

Epoch: 6| Step: 12
Training loss: 2.5445266850084742
Validation loss: 2.478311652016499

Epoch: 6| Step: 13
Training loss: 2.427734669618596
Validation loss: 2.4928068762762736

Epoch: 100| Step: 0
Training loss: 2.6114110255866776
Validation loss: 2.510348211379806

Epoch: 6| Step: 1
Training loss: 2.897386715166217
Validation loss: 2.489761747404138

Epoch: 6| Step: 2
Training loss: 2.769316198180585
Validation loss: 2.469288735145151

Epoch: 6| Step: 3
Training loss: 2.761829336237346
Validation loss: 2.470303338711207

Epoch: 6| Step: 4
Training loss: 2.9604066559105315
Validation loss: 2.452389140838145

Epoch: 6| Step: 5
Training loss: 2.9504175440235625
Validation loss: 2.448844634985674

Epoch: 6| Step: 6
Training loss: 3.528517619638883
Validation loss: 2.45622338658888

Epoch: 6| Step: 7
Training loss: 2.1784946910556195
Validation loss: 2.4503609697542874

Epoch: 6| Step: 8
Training loss: 2.7687176153558064
Validation loss: 2.446278570189226

Epoch: 6| Step: 9
Training loss: 2.3413857297154053
Validation loss: 2.4460056945701893

Epoch: 6| Step: 10
Training loss: 2.3245772397835016
Validation loss: 2.4513397105735515

Epoch: 6| Step: 11
Training loss: 2.447800805346262
Validation loss: 2.454814815090979

Epoch: 6| Step: 12
Training loss: 2.6594370851542624
Validation loss: 2.4688396414217997

Epoch: 6| Step: 13
Training loss: 2.7198742701418457
Validation loss: 2.452196293814488

Epoch: 101| Step: 0
Training loss: 2.3257741644164827
Validation loss: 2.434356572531389

Epoch: 6| Step: 1
Training loss: 3.130537848284773
Validation loss: 2.444016796711708

Epoch: 6| Step: 2
Training loss: 3.0149829556566967
Validation loss: 2.4410186184206606

Epoch: 6| Step: 3
Training loss: 2.0839786547338317
Validation loss: 2.439822823210715

Epoch: 6| Step: 4
Training loss: 2.554414693749396
Validation loss: 2.443612835360201

Epoch: 6| Step: 5
Training loss: 3.0287320405472484
Validation loss: 2.4497297199848975

Epoch: 6| Step: 6
Training loss: 3.0037176621149286
Validation loss: 2.4513863156992177

Epoch: 6| Step: 7
Training loss: 2.0278058710576317
Validation loss: 2.4541381850441386

Epoch: 6| Step: 8
Training loss: 2.4737879858430407
Validation loss: 2.4549313639059496

Epoch: 6| Step: 9
Training loss: 2.8295793534776426
Validation loss: 2.4578633457908494

Epoch: 6| Step: 10
Training loss: 3.1672943563930183
Validation loss: 2.4605589570779305

Epoch: 6| Step: 11
Training loss: 2.7413640973254947
Validation loss: 2.462312347722926

Epoch: 6| Step: 12
Training loss: 2.816404641583495
Validation loss: 2.45213439892694

Epoch: 6| Step: 13
Training loss: 2.4795468036275086
Validation loss: 2.45498919190705

Epoch: 102| Step: 0
Training loss: 2.5421865171349705
Validation loss: 2.4535778226796756

Epoch: 6| Step: 1
Training loss: 3.251289991978334
Validation loss: 2.454415110588276

Epoch: 6| Step: 2
Training loss: 2.4656205441974945
Validation loss: 2.463767712122044

Epoch: 6| Step: 3
Training loss: 2.900420053249275
Validation loss: 2.459514351611552

Epoch: 6| Step: 4
Training loss: 2.653210235772186
Validation loss: 2.471790502163493

Epoch: 6| Step: 5
Training loss: 2.784090713048019
Validation loss: 2.4680489993085404

Epoch: 6| Step: 6
Training loss: 2.574807083903108
Validation loss: 2.46003089686794

Epoch: 6| Step: 7
Training loss: 2.879060448666828
Validation loss: 2.4556595924651585

Epoch: 6| Step: 8
Training loss: 2.732680662278296
Validation loss: 2.4525015165190847

Epoch: 6| Step: 9
Training loss: 2.7150413386392516
Validation loss: 2.446239547452709

Epoch: 6| Step: 10
Training loss: 2.84699541961548
Validation loss: 2.4495632895348423

Epoch: 6| Step: 11
Training loss: 2.4657378350995978
Validation loss: 2.437005440114273

Epoch: 6| Step: 12
Training loss: 2.6763313117897622
Validation loss: 2.449028595879573

Epoch: 6| Step: 13
Training loss: 2.351995181202007
Validation loss: 2.442242955582721

Epoch: 103| Step: 0
Training loss: 2.8345865021414602
Validation loss: 2.441951245453897

Epoch: 6| Step: 1
Training loss: 2.7192886520490687
Validation loss: 2.4446627244260193

Epoch: 6| Step: 2
Training loss: 3.370043894994101
Validation loss: 2.4419955112548077

Epoch: 6| Step: 3
Training loss: 2.852731125584381
Validation loss: 2.4580267121768524

Epoch: 6| Step: 4
Training loss: 2.7987829765091057
Validation loss: 2.445931540889865

Epoch: 6| Step: 5
Training loss: 2.6313000418283226
Validation loss: 2.4491541530582523

Epoch: 6| Step: 6
Training loss: 3.013964576376333
Validation loss: 2.4489353557195144

Epoch: 6| Step: 7
Training loss: 2.209317210087777
Validation loss: 2.461304446128952

Epoch: 6| Step: 8
Training loss: 2.3191029899464395
Validation loss: 2.456709152283189

Epoch: 6| Step: 9
Training loss: 2.2177695673678253
Validation loss: 2.445582833329839

Epoch: 6| Step: 10
Training loss: 2.046222378888655
Validation loss: 2.447168106341108

Epoch: 6| Step: 11
Training loss: 2.4449588410203242
Validation loss: 2.444127221963857

Epoch: 6| Step: 12
Training loss: 3.4945789315995834
Validation loss: 2.44513959449278

Epoch: 6| Step: 13
Training loss: 2.5170500137034177
Validation loss: 2.4521801891772093

Epoch: 104| Step: 0
Training loss: 2.642014628777732
Validation loss: 2.466707635340854

Epoch: 6| Step: 1
Training loss: 3.0702587637433387
Validation loss: 2.466882219543994

Epoch: 6| Step: 2
Training loss: 2.842705838845457
Validation loss: 2.46612222160818

Epoch: 6| Step: 3
Training loss: 2.9024991677978793
Validation loss: 2.464549158174356

Epoch: 6| Step: 4
Training loss: 2.8803756876791007
Validation loss: 2.463892033346557

Epoch: 6| Step: 5
Training loss: 3.0694240226085423
Validation loss: 2.476755854294885

Epoch: 6| Step: 6
Training loss: 2.583104267014082
Validation loss: 2.4969779299275996

Epoch: 6| Step: 7
Training loss: 2.160821905237066
Validation loss: 2.488189696096449

Epoch: 6| Step: 8
Training loss: 2.5944450090704048
Validation loss: 2.5087568878911983

Epoch: 6| Step: 9
Training loss: 2.8647114303153627
Validation loss: 2.501633612839387

Epoch: 6| Step: 10
Training loss: 3.017129315329378
Validation loss: 2.4862379437909907

Epoch: 6| Step: 11
Training loss: 2.3657884145756323
Validation loss: 2.482272732680341

Epoch: 6| Step: 12
Training loss: 2.5231101942820957
Validation loss: 2.474871561420417

Epoch: 6| Step: 13
Training loss: 2.2554385895094957
Validation loss: 2.46676998298982

Epoch: 105| Step: 0
Training loss: 2.946515472583808
Validation loss: 2.4595660498972074

Epoch: 6| Step: 1
Training loss: 2.64262107030422
Validation loss: 2.456934752312885

Epoch: 6| Step: 2
Training loss: 2.27948703315864
Validation loss: 2.4512389298684094

Epoch: 6| Step: 3
Training loss: 2.806503855346663
Validation loss: 2.4487030867597226

Epoch: 6| Step: 4
Training loss: 3.1031611475995233
Validation loss: 2.439325543542831

Epoch: 6| Step: 5
Training loss: 2.609895848355623
Validation loss: 2.446935959841116

Epoch: 6| Step: 6
Training loss: 2.4754580372532393
Validation loss: 2.4409964835894873

Epoch: 6| Step: 7
Training loss: 3.3761080583029166
Validation loss: 2.446271566557219

Epoch: 6| Step: 8
Training loss: 2.2949378739468917
Validation loss: 2.4513325561628005

Epoch: 6| Step: 9
Training loss: 3.1656982714654713
Validation loss: 2.4543006232256444

Epoch: 6| Step: 10
Training loss: 1.5309169173467918
Validation loss: 2.477818269653356

Epoch: 6| Step: 11
Training loss: 2.363947397721518
Validation loss: 2.4856775446972863

Epoch: 6| Step: 12
Training loss: 3.014624711398374
Validation loss: 2.4910199607841452

Epoch: 6| Step: 13
Training loss: 2.804435442380904
Validation loss: 2.488998633440678

Epoch: 106| Step: 0
Training loss: 2.4264540177049763
Validation loss: 2.493812920009477

Epoch: 6| Step: 1
Training loss: 2.546164758797606
Validation loss: 2.494373038159736

Epoch: 6| Step: 2
Training loss: 2.855150113677188
Validation loss: 2.492188228298856

Epoch: 6| Step: 3
Training loss: 3.1962878690228447
Validation loss: 2.480380463201787

Epoch: 6| Step: 4
Training loss: 2.4614462674738875
Validation loss: 2.4412842406928914

Epoch: 6| Step: 5
Training loss: 2.7832370474906396
Validation loss: 2.443876628387039

Epoch: 6| Step: 6
Training loss: 2.313852275646746
Validation loss: 2.4475158579711684

Epoch: 6| Step: 7
Training loss: 2.953298412257187
Validation loss: 2.4416033543586817

Epoch: 6| Step: 8
Training loss: 2.7635060614458493
Validation loss: 2.443330847378208

Epoch: 6| Step: 9
Training loss: 2.818417068070708
Validation loss: 2.441101021011428

Epoch: 6| Step: 10
Training loss: 2.6552253093054587
Validation loss: 2.4530868030900463

Epoch: 6| Step: 11
Training loss: 2.947179875222913
Validation loss: 2.456870402068353

Epoch: 6| Step: 12
Training loss: 2.465198521541491
Validation loss: 2.4537360446179886

Epoch: 6| Step: 13
Training loss: 2.5001629776283325
Validation loss: 2.446785310396368

Epoch: 107| Step: 0
Training loss: 1.831477945872415
Validation loss: 2.4452735027343695

Epoch: 6| Step: 1
Training loss: 2.959626000463922
Validation loss: 2.459925766875404

Epoch: 6| Step: 2
Training loss: 2.335500312643453
Validation loss: 2.446208671303581

Epoch: 6| Step: 3
Training loss: 2.9749155369156663
Validation loss: 2.4544192687458266

Epoch: 6| Step: 4
Training loss: 3.068779249498621
Validation loss: 2.453603976383115

Epoch: 6| Step: 5
Training loss: 2.537343731658257
Validation loss: 2.447962584334341

Epoch: 6| Step: 6
Training loss: 3.265059280675198
Validation loss: 2.448481639909159

Epoch: 6| Step: 7
Training loss: 3.205270634738812
Validation loss: 2.446145955742423

Epoch: 6| Step: 8
Training loss: 1.5718420370297326
Validation loss: 2.4476659827512486

Epoch: 6| Step: 9
Training loss: 2.639214313808916
Validation loss: 2.446475026315805

Epoch: 6| Step: 10
Training loss: 2.8560463129450495
Validation loss: 2.4452486616645714

Epoch: 6| Step: 11
Training loss: 2.588882106650241
Validation loss: 2.4599369065175334

Epoch: 6| Step: 12
Training loss: 2.5618167059232233
Validation loss: 2.4539589515623836

Epoch: 6| Step: 13
Training loss: 2.908242967690054
Validation loss: 2.457735039592414

Epoch: 108| Step: 0
Training loss: 2.9365635454631267
Validation loss: 2.4523518801042545

Epoch: 6| Step: 1
Training loss: 2.947073897994704
Validation loss: 2.4476298865684725

Epoch: 6| Step: 2
Training loss: 2.6141815687425054
Validation loss: 2.457212282888309

Epoch: 6| Step: 3
Training loss: 3.2808330452624728
Validation loss: 2.4553269770622626

Epoch: 6| Step: 4
Training loss: 2.4032621783526635
Validation loss: 2.447120713740069

Epoch: 6| Step: 5
Training loss: 3.182358728046637
Validation loss: 2.451973432600015

Epoch: 6| Step: 6
Training loss: 2.957701028939016
Validation loss: 2.4597094702351345

Epoch: 6| Step: 7
Training loss: 2.735106277772037
Validation loss: 2.455825740780578

Epoch: 6| Step: 8
Training loss: 2.1989078064761687
Validation loss: 2.458417243074711

Epoch: 6| Step: 9
Training loss: 2.9968330833837054
Validation loss: 2.4679380644289415

Epoch: 6| Step: 10
Training loss: 2.324964387682465
Validation loss: 2.461877252600057

Epoch: 6| Step: 11
Training loss: 2.0904975795261955
Validation loss: 2.4635312169634362

Epoch: 6| Step: 12
Training loss: 2.1152884774936913
Validation loss: 2.455918005863904

Epoch: 6| Step: 13
Training loss: 2.820079846705918
Validation loss: 2.4559974550391197

Epoch: 109| Step: 0
Training loss: 2.4303011104066203
Validation loss: 2.4472867744814586

Epoch: 6| Step: 1
Training loss: 1.8495487900089402
Validation loss: 2.445031733485299

Epoch: 6| Step: 2
Training loss: 2.1774572632337077
Validation loss: 2.4381023458909845

Epoch: 6| Step: 3
Training loss: 3.1483737380620878
Validation loss: 2.4424929174998846

Epoch: 6| Step: 4
Training loss: 2.989799961300714
Validation loss: 2.4284525352324846

Epoch: 6| Step: 5
Training loss: 2.679248295594001
Validation loss: 2.4329926007660463

Epoch: 6| Step: 6
Training loss: 2.9668452527017655
Validation loss: 2.4383578393565557

Epoch: 6| Step: 7
Training loss: 2.6083192802595003
Validation loss: 2.4328537498998926

Epoch: 6| Step: 8
Training loss: 2.5223902368624573
Validation loss: 2.435327406750113

Epoch: 6| Step: 9
Training loss: 2.3525517306178743
Validation loss: 2.450783449047945

Epoch: 6| Step: 10
Training loss: 2.6743368663774807
Validation loss: 2.4774952423982803

Epoch: 6| Step: 11
Training loss: 3.104162553276733
Validation loss: 2.4563131073432083

Epoch: 6| Step: 12
Training loss: 2.8396880934924447
Validation loss: 2.4529140421678135

Epoch: 6| Step: 13
Training loss: 3.6369156830238456
Validation loss: 2.449304453223076

Epoch: 110| Step: 0
Training loss: 2.3383680476002056
Validation loss: 2.4446172726161453

Epoch: 6| Step: 1
Training loss: 2.4839206496017674
Validation loss: 2.4381397124106017

Epoch: 6| Step: 2
Training loss: 2.468465281618848
Validation loss: 2.4399832945779156

Epoch: 6| Step: 3
Training loss: 2.9147236664594547
Validation loss: 2.430964934118104

Epoch: 6| Step: 4
Training loss: 2.8233547551116684
Validation loss: 2.427873378735438

Epoch: 6| Step: 5
Training loss: 3.010919724685628
Validation loss: 2.4276128782127864

Epoch: 6| Step: 6
Training loss: 2.393012655853587
Validation loss: 2.4301721095987387

Epoch: 6| Step: 7
Training loss: 2.9288875861093455
Validation loss: 2.438297251780645

Epoch: 6| Step: 8
Training loss: 2.9744869014100828
Validation loss: 2.4487034113105217

Epoch: 6| Step: 9
Training loss: 2.445022517063545
Validation loss: 2.463786982785693

Epoch: 6| Step: 10
Training loss: 3.013040650790804
Validation loss: 2.4800643781201406

Epoch: 6| Step: 11
Training loss: 2.8522914843027145
Validation loss: 2.4976867966853145

Epoch: 6| Step: 12
Training loss: 2.453062894970471
Validation loss: 2.5276307392262507

Epoch: 6| Step: 13
Training loss: 2.9293718905520922
Validation loss: 2.533377748314839

Epoch: 111| Step: 0
Training loss: 3.0300490369700075
Validation loss: 2.5138886255940114

Epoch: 6| Step: 1
Training loss: 2.4229705301618836
Validation loss: 2.492992723526141

Epoch: 6| Step: 2
Training loss: 3.1550739476746674
Validation loss: 2.4654530756125217

Epoch: 6| Step: 3
Training loss: 2.807444542925609
Validation loss: 2.4293227462538987

Epoch: 6| Step: 4
Training loss: 2.711011990010234
Validation loss: 2.4216650060356053

Epoch: 6| Step: 5
Training loss: 2.465988546241217
Validation loss: 2.4206851096380606

Epoch: 6| Step: 6
Training loss: 3.0577530174337166
Validation loss: 2.4243156538603405

Epoch: 6| Step: 7
Training loss: 2.4991665404513603
Validation loss: 2.4215199644617624

Epoch: 6| Step: 8
Training loss: 2.5431864421150703
Validation loss: 2.4342356063697164

Epoch: 6| Step: 9
Training loss: 2.5285713245062387
Validation loss: 2.427670313085847

Epoch: 6| Step: 10
Training loss: 2.3548283505096013
Validation loss: 2.4448456829563954

Epoch: 6| Step: 11
Training loss: 3.0640460413170274
Validation loss: 2.4359135972565027

Epoch: 6| Step: 12
Training loss: 2.972511237839486
Validation loss: 2.45712166325461

Epoch: 6| Step: 13
Training loss: 1.7810412502106128
Validation loss: 2.4538758587072698

Epoch: 112| Step: 0
Training loss: 2.5535860166028193
Validation loss: 2.467342990834078

Epoch: 6| Step: 1
Training loss: 2.7863200405896142
Validation loss: 2.480657751795592

Epoch: 6| Step: 2
Training loss: 3.1861635286039323
Validation loss: 2.5026022524240163

Epoch: 6| Step: 3
Training loss: 2.6487599404451383
Validation loss: 2.519492741136513

Epoch: 6| Step: 4
Training loss: 3.0200501226850975
Validation loss: 2.502933833684669

Epoch: 6| Step: 5
Training loss: 2.8778269593771055
Validation loss: 2.455555926957841

Epoch: 6| Step: 6
Training loss: 2.5316770216943736
Validation loss: 2.439953492920168

Epoch: 6| Step: 7
Training loss: 2.7121241717873756
Validation loss: 2.432877123207796

Epoch: 6| Step: 8
Training loss: 1.6919650592938786
Validation loss: 2.4311192898181773

Epoch: 6| Step: 9
Training loss: 3.1406954477484463
Validation loss: 2.433451559077515

Epoch: 6| Step: 10
Training loss: 2.5549917244077314
Validation loss: 2.4330082649974094

Epoch: 6| Step: 11
Training loss: 2.742373468336807
Validation loss: 2.4273107852448814

Epoch: 6| Step: 12
Training loss: 2.8299413085890306
Validation loss: 2.438641993199732

Epoch: 6| Step: 13
Training loss: 1.8020817163125724
Validation loss: 2.417338848161049

Epoch: 113| Step: 0
Training loss: 2.830891473229436
Validation loss: 2.4335673485884564

Epoch: 6| Step: 1
Training loss: 2.519685867651574
Validation loss: 2.4160424325491827

Epoch: 6| Step: 2
Training loss: 2.166116118787167
Validation loss: 2.412612939131736

Epoch: 6| Step: 3
Training loss: 2.2162235543727404
Validation loss: 2.4206119584887538

Epoch: 6| Step: 4
Training loss: 3.163715258723713
Validation loss: 2.4147259837560626

Epoch: 6| Step: 5
Training loss: 3.0334403392935263
Validation loss: 2.413395750118137

Epoch: 6| Step: 6
Training loss: 2.0633886330280644
Validation loss: 2.419936107860576

Epoch: 6| Step: 7
Training loss: 3.0118146947873976
Validation loss: 2.4335685200241683

Epoch: 6| Step: 8
Training loss: 2.795569941189371
Validation loss: 2.454039647241114

Epoch: 6| Step: 9
Training loss: 2.6385709459497773
Validation loss: 2.4753877506112776

Epoch: 6| Step: 10
Training loss: 2.6389176305800697
Validation loss: 2.491782292126394

Epoch: 6| Step: 11
Training loss: 2.561309351757017
Validation loss: 2.526700687654524

Epoch: 6| Step: 12
Training loss: 3.28926169184165
Validation loss: 2.606233098026016

Epoch: 6| Step: 13
Training loss: 3.20603639363308
Validation loss: 2.531274785029722

Epoch: 114| Step: 0
Training loss: 2.2937648762316685
Validation loss: 2.4867538143025247

Epoch: 6| Step: 1
Training loss: 2.512486555528492
Validation loss: 2.449359278287897

Epoch: 6| Step: 2
Training loss: 2.511689228934456
Validation loss: 2.4413051106822854

Epoch: 6| Step: 3
Training loss: 3.0627238911901595
Validation loss: 2.43368533419437

Epoch: 6| Step: 4
Training loss: 2.838809574095035
Validation loss: 2.437640409840238

Epoch: 6| Step: 5
Training loss: 2.5924883612111236
Validation loss: 2.436341338730723

Epoch: 6| Step: 6
Training loss: 2.4927174354532635
Validation loss: 2.4395077810582793

Epoch: 6| Step: 7
Training loss: 2.721449640719566
Validation loss: 2.4527418209501892

Epoch: 6| Step: 8
Training loss: 2.2122710287288996
Validation loss: 2.4492313315145307

Epoch: 6| Step: 9
Training loss: 3.130924255117677
Validation loss: 2.4588968108472447

Epoch: 6| Step: 10
Training loss: 2.2797605276666846
Validation loss: 2.461471669967244

Epoch: 6| Step: 11
Training loss: 2.937984832360968
Validation loss: 2.4565879692799015

Epoch: 6| Step: 12
Training loss: 3.4245656204430808
Validation loss: 2.47021180760304

Epoch: 6| Step: 13
Training loss: 1.923693285249208
Validation loss: 2.4725451454584895

Epoch: 115| Step: 0
Training loss: 2.8213610615163947
Validation loss: 2.461900156671907

Epoch: 6| Step: 1
Training loss: 2.6111356540184816
Validation loss: 2.4370717549875067

Epoch: 6| Step: 2
Training loss: 2.767921830225656
Validation loss: 2.437783733016434

Epoch: 6| Step: 3
Training loss: 2.326659285233966
Validation loss: 2.434302211537188

Epoch: 6| Step: 4
Training loss: 1.7651293573714064
Validation loss: 2.42823640073141

Epoch: 6| Step: 5
Training loss: 2.394978367940732
Validation loss: 2.4259309993763103

Epoch: 6| Step: 6
Training loss: 2.488367483420394
Validation loss: 2.4320842758761807

Epoch: 6| Step: 7
Training loss: 3.0785667760786657
Validation loss: 2.4269039723825996

Epoch: 6| Step: 8
Training loss: 3.2611965103997274
Validation loss: 2.438619623126406

Epoch: 6| Step: 9
Training loss: 2.4379893080779684
Validation loss: 2.4344758172539347

Epoch: 6| Step: 10
Training loss: 2.008057100707584
Validation loss: 2.436114700857033

Epoch: 6| Step: 11
Training loss: 2.9988286592662674
Validation loss: 2.4560552428038664

Epoch: 6| Step: 12
Training loss: 2.8819180059688447
Validation loss: 2.4385808541892686

Epoch: 6| Step: 13
Training loss: 3.5866122805597502
Validation loss: 2.4584302811844783

Epoch: 116| Step: 0
Training loss: 2.191671046070128
Validation loss: 2.4232436669627355

Epoch: 6| Step: 1
Training loss: 2.3766074513053472
Validation loss: 2.4266990640149477

Epoch: 6| Step: 2
Training loss: 3.004602398711154
Validation loss: 2.425755140851558

Epoch: 6| Step: 3
Training loss: 2.926132608867502
Validation loss: 2.4340012426676934

Epoch: 6| Step: 4
Training loss: 2.42014827084893
Validation loss: 2.4209289184844

Epoch: 6| Step: 5
Training loss: 2.4510890019606033
Validation loss: 2.416479486070091

Epoch: 6| Step: 6
Training loss: 2.3868583975486963
Validation loss: 2.421268981416694

Epoch: 6| Step: 7
Training loss: 2.7497903570547817
Validation loss: 2.4320593143219242

Epoch: 6| Step: 8
Training loss: 3.2312750219560527
Validation loss: 2.4406778945454626

Epoch: 6| Step: 9
Training loss: 3.048124555971396
Validation loss: 2.446218640961507

Epoch: 6| Step: 10
Training loss: 2.8096950531158904
Validation loss: 2.45195756436127

Epoch: 6| Step: 11
Training loss: 2.8602832123107085
Validation loss: 2.451953836977915

Epoch: 6| Step: 12
Training loss: 2.2759830865952253
Validation loss: 2.4551708415937434

Epoch: 6| Step: 13
Training loss: 2.4819929110958356
Validation loss: 2.4497354171209027

Epoch: 117| Step: 0
Training loss: 2.708637152038831
Validation loss: 2.458695221493996

Epoch: 6| Step: 1
Training loss: 2.8605437678146104
Validation loss: 2.4562274326153095

Epoch: 6| Step: 2
Training loss: 3.0495696842996414
Validation loss: 2.4312469085927617

Epoch: 6| Step: 3
Training loss: 2.7174769961902157
Validation loss: 2.4179934053547125

Epoch: 6| Step: 4
Training loss: 3.164474498157207
Validation loss: 2.4176778912449666

Epoch: 6| Step: 5
Training loss: 2.4380206994671463
Validation loss: 2.4209778859160567

Epoch: 6| Step: 6
Training loss: 2.578016059192153
Validation loss: 2.427836583332046

Epoch: 6| Step: 7
Training loss: 2.1445754972524345
Validation loss: 2.4216677277648095

Epoch: 6| Step: 8
Training loss: 2.626988339099481
Validation loss: 2.432743716042899

Epoch: 6| Step: 9
Training loss: 2.8464584029023023
Validation loss: 2.4290602792767255

Epoch: 6| Step: 10
Training loss: 2.5157189203583097
Validation loss: 2.436642922327725

Epoch: 6| Step: 11
Training loss: 2.0820468236401597
Validation loss: 2.4293398577252203

Epoch: 6| Step: 12
Training loss: 2.766667401263894
Validation loss: 2.429680460150184

Epoch: 6| Step: 13
Training loss: 2.8845097370852892
Validation loss: 2.428425000077147

Epoch: 118| Step: 0
Training loss: 2.7726388560437694
Validation loss: 2.4252439251264395

Epoch: 6| Step: 1
Training loss: 2.1908487028867216
Validation loss: 2.4318798451100987

Epoch: 6| Step: 2
Training loss: 2.7221294752743614
Validation loss: 2.430067206475088

Epoch: 6| Step: 3
Training loss: 3.213251843771201
Validation loss: 2.4350303757939984

Epoch: 6| Step: 4
Training loss: 2.8763169299332954
Validation loss: 2.449186696153889

Epoch: 6| Step: 5
Training loss: 2.1075967710819588
Validation loss: 2.4590594601226217

Epoch: 6| Step: 6
Training loss: 2.5339395809904115
Validation loss: 2.4652889929891884

Epoch: 6| Step: 7
Training loss: 2.6982566786165343
Validation loss: 2.4526894828574055

Epoch: 6| Step: 8
Training loss: 2.8358117277981587
Validation loss: 2.4608363357171203

Epoch: 6| Step: 9
Training loss: 2.7620495459154597
Validation loss: 2.4625007535696866

Epoch: 6| Step: 10
Training loss: 2.575353253771969
Validation loss: 2.4547753735033266

Epoch: 6| Step: 11
Training loss: 3.038590029197679
Validation loss: 2.467417846534555

Epoch: 6| Step: 12
Training loss: 2.4102350899091047
Validation loss: 2.448842482604348

Epoch: 6| Step: 13
Training loss: 1.8471861033465817
Validation loss: 2.4504182533042402

Epoch: 119| Step: 0
Training loss: 2.159686018411037
Validation loss: 2.473996651854116

Epoch: 6| Step: 1
Training loss: 1.8946360136344835
Validation loss: 2.5021236946517513

Epoch: 6| Step: 2
Training loss: 2.5340567204330346
Validation loss: 2.513582536109726

Epoch: 6| Step: 3
Training loss: 3.1574611039835383
Validation loss: 2.5099805486193634

Epoch: 6| Step: 4
Training loss: 2.8766468141415182
Validation loss: 2.482683292650311

Epoch: 6| Step: 5
Training loss: 3.1831533677391084
Validation loss: 2.4614653313458463

Epoch: 6| Step: 6
Training loss: 3.2793436961554745
Validation loss: 2.460659207080007

Epoch: 6| Step: 7
Training loss: 2.407906098622859
Validation loss: 2.4831554938284675

Epoch: 6| Step: 8
Training loss: 2.586726964201885
Validation loss: 2.493492358607318

Epoch: 6| Step: 9
Training loss: 2.3493493904246288
Validation loss: 2.4836040365248944

Epoch: 6| Step: 10
Training loss: 2.9485690380162786
Validation loss: 2.509750778967037

Epoch: 6| Step: 11
Training loss: 2.7220016852940505
Validation loss: 2.5156138980421527

Epoch: 6| Step: 12
Training loss: 3.203158345863013
Validation loss: 2.5316561939280207

Epoch: 6| Step: 13
Training loss: 2.56680466623594
Validation loss: 2.549737791590517

Epoch: 120| Step: 0
Training loss: 2.703531929212775
Validation loss: 2.6341524630804463

Epoch: 6| Step: 1
Training loss: 3.168571668794646
Validation loss: 2.708068464751426

Epoch: 6| Step: 2
Training loss: 3.1947514943890205
Validation loss: 2.7364500792310507

Epoch: 6| Step: 3
Training loss: 2.5552343314074584
Validation loss: 2.6491557867917845

Epoch: 6| Step: 4
Training loss: 2.2576671936373978
Validation loss: 2.5903225692463785

Epoch: 6| Step: 5
Training loss: 2.9715110387467107
Validation loss: 2.5382449758818835

Epoch: 6| Step: 6
Training loss: 2.4539344569798174
Validation loss: 2.4698469882381953

Epoch: 6| Step: 7
Training loss: 2.945203379423396
Validation loss: 2.4403932804866386

Epoch: 6| Step: 8
Training loss: 3.1003792376968184
Validation loss: 2.4483606480892997

Epoch: 6| Step: 9
Training loss: 3.087390412768047
Validation loss: 2.4713829530983373

Epoch: 6| Step: 10
Training loss: 2.06370208850978
Validation loss: 2.519752811560859

Epoch: 6| Step: 11
Training loss: 2.660718861152614
Validation loss: 2.5684048998010187

Epoch: 6| Step: 12
Training loss: 2.1210861065412465
Validation loss: 2.605018626653048

Epoch: 6| Step: 13
Training loss: 3.059956019465713
Validation loss: 2.544371438825875

Epoch: 121| Step: 0
Training loss: 2.7240314267175987
Validation loss: 2.4883880728817496

Epoch: 6| Step: 1
Training loss: 2.2923986710812962
Validation loss: 2.4832822378049535

Epoch: 6| Step: 2
Training loss: 2.7150872649610656
Validation loss: 2.492106575207654

Epoch: 6| Step: 3
Training loss: 3.1117512426612146
Validation loss: 2.460834957967759

Epoch: 6| Step: 4
Training loss: 2.921506970732999
Validation loss: 2.4547068747830387

Epoch: 6| Step: 5
Training loss: 2.5672472268306055
Validation loss: 2.435283855593587

Epoch: 6| Step: 6
Training loss: 2.7791796918923146
Validation loss: 2.437698275208845

Epoch: 6| Step: 7
Training loss: 2.1521408068456473
Validation loss: 2.450161976092274

Epoch: 6| Step: 8
Training loss: 2.667240875729104
Validation loss: 2.4518226901187

Epoch: 6| Step: 9
Training loss: 2.592824747903306
Validation loss: 2.459547972975496

Epoch: 6| Step: 10
Training loss: 3.333299223407427
Validation loss: 2.46538694807166

Epoch: 6| Step: 11
Training loss: 2.921246629353098
Validation loss: 2.463975900145024

Epoch: 6| Step: 12
Training loss: 1.9408059372148325
Validation loss: 2.44120854479229

Epoch: 6| Step: 13
Training loss: 1.8168491274812608
Validation loss: 2.4406745406780015

Epoch: 122| Step: 0
Training loss: 2.747003830458863
Validation loss: 2.438404402428871

Epoch: 6| Step: 1
Training loss: 2.3555648050286577
Validation loss: 2.4342470805256373

Epoch: 6| Step: 2
Training loss: 2.571076160835555
Validation loss: 2.4376412259510936

Epoch: 6| Step: 3
Training loss: 2.5307844699349964
Validation loss: 2.446061869595975

Epoch: 6| Step: 4
Training loss: 2.9229469984732512
Validation loss: 2.4498259238304687

Epoch: 6| Step: 5
Training loss: 2.9723854693525147
Validation loss: 2.439894345574976

Epoch: 6| Step: 6
Training loss: 1.7851546473255935
Validation loss: 2.438675238728096

Epoch: 6| Step: 7
Training loss: 1.7490671941500988
Validation loss: 2.4462158228840365

Epoch: 6| Step: 8
Training loss: 2.756443797108189
Validation loss: 2.449097860541774

Epoch: 6| Step: 9
Training loss: 3.1352958444696464
Validation loss: 2.4533563571023906

Epoch: 6| Step: 10
Training loss: 3.000999919826528
Validation loss: 2.4723904011596103

Epoch: 6| Step: 11
Training loss: 2.605314281637345
Validation loss: 2.4629621977814367

Epoch: 6| Step: 12
Training loss: 3.0555398439716255
Validation loss: 2.4553279809774193

Epoch: 6| Step: 13
Training loss: 2.245024796584722
Validation loss: 2.443433050666877

Epoch: 123| Step: 0
Training loss: 2.4049621702775927
Validation loss: 2.4300965644460484

Epoch: 6| Step: 1
Training loss: 2.6297179013521848
Validation loss: 2.4222513859723493

Epoch: 6| Step: 2
Training loss: 2.343245388386652
Validation loss: 2.423424771709993

Epoch: 6| Step: 3
Training loss: 2.4247998695771207
Validation loss: 2.4132996747168165

Epoch: 6| Step: 4
Training loss: 3.015651248165398
Validation loss: 2.420483657190354

Epoch: 6| Step: 5
Training loss: 2.1275590185996043
Validation loss: 2.4268372941022096

Epoch: 6| Step: 6
Training loss: 2.6086853395133804
Validation loss: 2.4388431490668343

Epoch: 6| Step: 7
Training loss: 2.2833635128653444
Validation loss: 2.471290098873706

Epoch: 6| Step: 8
Training loss: 2.9441367314452
Validation loss: 2.490630581193164

Epoch: 6| Step: 9
Training loss: 3.1911824216758724
Validation loss: 2.518845109612848

Epoch: 6| Step: 10
Training loss: 3.20709429178294
Validation loss: 2.526498032551664

Epoch: 6| Step: 11
Training loss: 2.1015130359827117
Validation loss: 2.5024502974861713

Epoch: 6| Step: 12
Training loss: 2.4341501545914657
Validation loss: 2.482294675018703

Epoch: 6| Step: 13
Training loss: 3.320261948144585
Validation loss: 2.4577135560018517

Epoch: 124| Step: 0
Training loss: 2.803529378074067
Validation loss: 2.437193904701396

Epoch: 6| Step: 1
Training loss: 2.9218217977484273
Validation loss: 2.4148044547115095

Epoch: 6| Step: 2
Training loss: 2.2618800288595353
Validation loss: 2.418392603267268

Epoch: 6| Step: 3
Training loss: 2.7138432916589212
Validation loss: 2.4107738985255645

Epoch: 6| Step: 4
Training loss: 2.589572713947286
Validation loss: 2.40202467592174

Epoch: 6| Step: 5
Training loss: 2.673335518332688
Validation loss: 2.4104654500677896

Epoch: 6| Step: 6
Training loss: 2.2013650993829375
Validation loss: 2.4159339988286126

Epoch: 6| Step: 7
Training loss: 2.648886673458433
Validation loss: 2.4129351986406435

Epoch: 6| Step: 8
Training loss: 2.7806947132373807
Validation loss: 2.426679455515984

Epoch: 6| Step: 9
Training loss: 2.4305061359528177
Validation loss: 2.4445375060131855

Epoch: 6| Step: 10
Training loss: 2.7637629733218945
Validation loss: 2.4409481025939925

Epoch: 6| Step: 11
Training loss: 3.0565635598312175
Validation loss: 2.458546228994663

Epoch: 6| Step: 12
Training loss: 2.35532643155511
Validation loss: 2.470858138902226

Epoch: 6| Step: 13
Training loss: 2.2628227003752945
Validation loss: 2.494169724211208

Epoch: 125| Step: 0
Training loss: 2.7671856113903424
Validation loss: 2.5219058734295894

Epoch: 6| Step: 1
Training loss: 1.9780622981591252
Validation loss: 2.493399442482103

Epoch: 6| Step: 2
Training loss: 2.822701665331865
Validation loss: 2.474499335124261

Epoch: 6| Step: 3
Training loss: 2.6913524782874565
Validation loss: 2.4481802392434413

Epoch: 6| Step: 4
Training loss: 2.918282161360589
Validation loss: 2.4087510574387627

Epoch: 6| Step: 5
Training loss: 2.6602291147612984
Validation loss: 2.401461992733221

Epoch: 6| Step: 6
Training loss: 2.5746601287835174
Validation loss: 2.4019181026595864

Epoch: 6| Step: 7
Training loss: 2.590389970855902
Validation loss: 2.39794377009027

Epoch: 6| Step: 8
Training loss: 3.0429635788527145
Validation loss: 2.396894399938759

Epoch: 6| Step: 9
Training loss: 2.635770500062136
Validation loss: 2.4050071947028835

Epoch: 6| Step: 10
Training loss: 2.372520658445308
Validation loss: 2.4268372919894676

Epoch: 6| Step: 11
Training loss: 3.2762040349187607
Validation loss: 2.44366761606803

Epoch: 6| Step: 12
Training loss: 2.486903697095388
Validation loss: 2.4608133253785405

Epoch: 6| Step: 13
Training loss: 1.381728614979838
Validation loss: 2.476780690916756

Epoch: 126| Step: 0
Training loss: 2.4033006700614417
Validation loss: 2.4441540033347846

Epoch: 6| Step: 1
Training loss: 2.409075675608661
Validation loss: 2.433762988444187

Epoch: 6| Step: 2
Training loss: 2.547005211245564
Validation loss: 2.438530304784648

Epoch: 6| Step: 3
Training loss: 2.2161067207611493
Validation loss: 2.4212359058535893

Epoch: 6| Step: 4
Training loss: 3.1761909774226478
Validation loss: 2.4083001254529015

Epoch: 6| Step: 5
Training loss: 2.4270941825482324
Validation loss: 2.407857943895476

Epoch: 6| Step: 6
Training loss: 2.578383924024498
Validation loss: 2.412137899354281

Epoch: 6| Step: 7
Training loss: 2.8939218227053365
Validation loss: 2.4172713269742614

Epoch: 6| Step: 8
Training loss: 2.337420448948707
Validation loss: 2.4433716414916766

Epoch: 6| Step: 9
Training loss: 2.995385913217862
Validation loss: 2.4581354150900596

Epoch: 6| Step: 10
Training loss: 2.792070919393148
Validation loss: 2.47670136293998

Epoch: 6| Step: 11
Training loss: 2.734496021317381
Validation loss: 2.519701584068411

Epoch: 6| Step: 12
Training loss: 2.487061589391439
Validation loss: 2.534472849711108

Epoch: 6| Step: 13
Training loss: 2.4848659198287475
Validation loss: 2.4788172692723243

Epoch: 127| Step: 0
Training loss: 2.7643502956237804
Validation loss: 2.45018833157297

Epoch: 6| Step: 1
Training loss: 2.9172058333733633
Validation loss: 2.4262819205955104

Epoch: 6| Step: 2
Training loss: 2.78267607400008
Validation loss: 2.4145149581910945

Epoch: 6| Step: 3
Training loss: 2.5220868065435833
Validation loss: 2.40387549114389

Epoch: 6| Step: 4
Training loss: 2.717695185048435
Validation loss: 2.398836923037171

Epoch: 6| Step: 5
Training loss: 2.970196502041942
Validation loss: 2.3972815361089044

Epoch: 6| Step: 6
Training loss: 2.346383306651882
Validation loss: 2.3983264729182787

Epoch: 6| Step: 7
Training loss: 2.5267329472862494
Validation loss: 2.407263002538114

Epoch: 6| Step: 8
Training loss: 2.084457729819625
Validation loss: 2.4222886054195576

Epoch: 6| Step: 9
Training loss: 2.0305789719446303
Validation loss: 2.4420363917125814

Epoch: 6| Step: 10
Training loss: 3.0465453923279475
Validation loss: 2.467309860136632

Epoch: 6| Step: 11
Training loss: 2.829248700382871
Validation loss: 2.4888330654793824

Epoch: 6| Step: 12
Training loss: 1.793388500405032
Validation loss: 2.4846285097770218

Epoch: 6| Step: 13
Training loss: 2.7523776093175263
Validation loss: 2.454483680119348

Epoch: 128| Step: 0
Training loss: 2.679194724814552
Validation loss: 2.431058816056697

Epoch: 6| Step: 1
Training loss: 2.276753632135113
Validation loss: 2.4067300371750893

Epoch: 6| Step: 2
Training loss: 1.710955127642675
Validation loss: 2.400241658647174

Epoch: 6| Step: 3
Training loss: 2.3181339401767986
Validation loss: 2.403694020539555

Epoch: 6| Step: 4
Training loss: 3.264240610276728
Validation loss: 2.398799965985661

Epoch: 6| Step: 5
Training loss: 2.474412050637058
Validation loss: 2.38515797041738

Epoch: 6| Step: 6
Training loss: 2.785087252881775
Validation loss: 2.39685400309895

Epoch: 6| Step: 7
Training loss: 2.4828509568440404
Validation loss: 2.400840900008561

Epoch: 6| Step: 8
Training loss: 2.1032619482744135
Validation loss: 2.4132013475798346

Epoch: 6| Step: 9
Training loss: 2.28706496641077
Validation loss: 2.418863718952044

Epoch: 6| Step: 10
Training loss: 2.7793914928937706
Validation loss: 2.430169248650138

Epoch: 6| Step: 11
Training loss: 2.491530280915035
Validation loss: 2.44647208173863

Epoch: 6| Step: 12
Training loss: 3.072130436720917
Validation loss: 2.4605086310184894

Epoch: 6| Step: 13
Training loss: 3.4385848674277226
Validation loss: 2.4731386667265527

Epoch: 129| Step: 0
Training loss: 2.559868554674617
Validation loss: 2.4756720601529474

Epoch: 6| Step: 1
Training loss: 2.2646586494824197
Validation loss: 2.4704614555703137

Epoch: 6| Step: 2
Training loss: 2.7201784261916724
Validation loss: 2.4441990809229592

Epoch: 6| Step: 3
Training loss: 2.9312928544350383
Validation loss: 2.432207631556235

Epoch: 6| Step: 4
Training loss: 2.6275671259093776
Validation loss: 2.4352618033851523

Epoch: 6| Step: 5
Training loss: 2.5550969813505016
Validation loss: 2.446820497024327

Epoch: 6| Step: 6
Training loss: 2.757984793578918
Validation loss: 2.4590041783620222

Epoch: 6| Step: 7
Training loss: 2.3979714403655006
Validation loss: 2.460036283566113

Epoch: 6| Step: 8
Training loss: 2.0784421979856527
Validation loss: 2.431373444126489

Epoch: 6| Step: 9
Training loss: 2.5780145794890506
Validation loss: 2.4195199928176905

Epoch: 6| Step: 10
Training loss: 2.9273439519844975
Validation loss: 2.4099817274474287

Epoch: 6| Step: 11
Training loss: 2.6907631336867364
Validation loss: 2.412410757344074

Epoch: 6| Step: 12
Training loss: 2.2486266077188453
Validation loss: 2.4151509273093184

Epoch: 6| Step: 13
Training loss: 2.733172604634558
Validation loss: 2.431731667074274

Epoch: 130| Step: 0
Training loss: 2.551278268899511
Validation loss: 2.4251385144211697

Epoch: 6| Step: 1
Training loss: 2.4340306558802105
Validation loss: 2.4311145350260213

Epoch: 6| Step: 2
Training loss: 3.063986281361757
Validation loss: 2.4423452873191316

Epoch: 6| Step: 3
Training loss: 3.242505161395998
Validation loss: 2.4238487856822593

Epoch: 6| Step: 4
Training loss: 2.4613137578189237
Validation loss: 2.401010505406972

Epoch: 6| Step: 5
Training loss: 2.3396914118880185
Validation loss: 2.399924049491677

Epoch: 6| Step: 6
Training loss: 2.8247871723857183
Validation loss: 2.393778933391967

Epoch: 6| Step: 7
Training loss: 1.61327415631007
Validation loss: 2.3839203603025427

Epoch: 6| Step: 8
Training loss: 2.6685020170756326
Validation loss: 2.3720244953644403

Epoch: 6| Step: 9
Training loss: 2.4621697141409467
Validation loss: 2.361242781883931

Epoch: 6| Step: 10
Training loss: 2.944423551505316
Validation loss: 2.365703791267738

Epoch: 6| Step: 11
Training loss: 2.286120923519385
Validation loss: 2.365452141196091

Epoch: 6| Step: 12
Training loss: 2.552794708963265
Validation loss: 2.3652641404460315

Epoch: 6| Step: 13
Training loss: 1.952340235407407
Validation loss: 2.377945603403756

Epoch: 131| Step: 0
Training loss: 2.0631248221271647
Validation loss: 2.4182887321429956

Epoch: 6| Step: 1
Training loss: 1.967531705259143
Validation loss: 2.4617240579823543

Epoch: 6| Step: 2
Training loss: 2.9568519285951265
Validation loss: 2.467053524304534

Epoch: 6| Step: 3
Training loss: 2.4058515540836813
Validation loss: 2.476581513762193

Epoch: 6| Step: 4
Training loss: 2.0813431452622315
Validation loss: 2.475612386314759

Epoch: 6| Step: 5
Training loss: 2.8953004708119985
Validation loss: 2.477690000406472

Epoch: 6| Step: 6
Training loss: 3.154359912537678
Validation loss: 2.4348577740660207

Epoch: 6| Step: 7
Training loss: 2.0412034527808665
Validation loss: 2.398105236106519

Epoch: 6| Step: 8
Training loss: 2.7807698210346183
Validation loss: 2.3917898897191265

Epoch: 6| Step: 9
Training loss: 2.988554419703822
Validation loss: 2.3932511791276654

Epoch: 6| Step: 10
Training loss: 2.6224972737809984
Validation loss: 2.3933600379972937

Epoch: 6| Step: 11
Training loss: 2.7611113531861773
Validation loss: 2.3927526815901348

Epoch: 6| Step: 12
Training loss: 2.7095215367307586
Validation loss: 2.3941492436650593

Epoch: 6| Step: 13
Training loss: 2.2355510044409703
Validation loss: 2.4096611996902517

Epoch: 132| Step: 0
Training loss: 2.806940815268017
Validation loss: 2.4012683076944197

Epoch: 6| Step: 1
Training loss: 2.227854357275503
Validation loss: 2.3950282603860304

Epoch: 6| Step: 2
Training loss: 2.5467074286442517
Validation loss: 2.4139235415675

Epoch: 6| Step: 3
Training loss: 2.5378473279047773
Validation loss: 2.423001493998581

Epoch: 6| Step: 4
Training loss: 2.5389759225022965
Validation loss: 2.4548372848264273

Epoch: 6| Step: 5
Training loss: 1.8635101497651114
Validation loss: 2.4645183616213164

Epoch: 6| Step: 6
Training loss: 2.4451445988059324
Validation loss: 2.4875003707719743

Epoch: 6| Step: 7
Training loss: 2.8681758663465824
Validation loss: 2.4967544541144773

Epoch: 6| Step: 8
Training loss: 2.351790306234961
Validation loss: 2.5120569646128876

Epoch: 6| Step: 9
Training loss: 2.264391754197911
Validation loss: 2.5326333265936127

Epoch: 6| Step: 10
Training loss: 2.812824484862431
Validation loss: 2.5374601552459635

Epoch: 6| Step: 11
Training loss: 2.7304865627771977
Validation loss: 2.5241724999415234

Epoch: 6| Step: 12
Training loss: 3.3530366941060286
Validation loss: 2.4685092537089326

Epoch: 6| Step: 13
Training loss: 2.7923987173702898
Validation loss: 2.426489994666877

Epoch: 133| Step: 0
Training loss: 2.606545107300624
Validation loss: 2.4120885000412913

Epoch: 6| Step: 1
Training loss: 2.403266345010689
Validation loss: 2.398605710078994

Epoch: 6| Step: 2
Training loss: 2.4629088241546078
Validation loss: 2.3893952750725935

Epoch: 6| Step: 3
Training loss: 1.937931997068641
Validation loss: 2.3812057330805363

Epoch: 6| Step: 4
Training loss: 3.101426282529042
Validation loss: 2.387356278849917

Epoch: 6| Step: 5
Training loss: 3.0109042044571876
Validation loss: 2.3943750281361

Epoch: 6| Step: 6
Training loss: 2.179593757609814
Validation loss: 2.38218227950521

Epoch: 6| Step: 7
Training loss: 2.936162116374505
Validation loss: 2.397005594956992

Epoch: 6| Step: 8
Training loss: 2.120618229458066
Validation loss: 2.4120729571615653

Epoch: 6| Step: 9
Training loss: 2.7817750928015643
Validation loss: 2.428348043980549

Epoch: 6| Step: 10
Training loss: 2.5242506671612595
Validation loss: 2.4572142453586023

Epoch: 6| Step: 11
Training loss: 2.520673436750098
Validation loss: 2.515137625403669

Epoch: 6| Step: 12
Training loss: 2.526475429980889
Validation loss: 2.5248555741033383

Epoch: 6| Step: 13
Training loss: 2.567280288106025
Validation loss: 2.542220347021011

Epoch: 134| Step: 0
Training loss: 2.7174077721801666
Validation loss: 2.5111781715714705

Epoch: 6| Step: 1
Training loss: 2.846138087683055
Validation loss: 2.497671652019335

Epoch: 6| Step: 2
Training loss: 2.3276654500370415
Validation loss: 2.4680738549932864

Epoch: 6| Step: 3
Training loss: 2.611030373328337
Validation loss: 2.4471028769802023

Epoch: 6| Step: 4
Training loss: 2.462401327102333
Validation loss: 2.4410702069426975

Epoch: 6| Step: 5
Training loss: 2.5446845622457386
Validation loss: 2.425595843065821

Epoch: 6| Step: 6
Training loss: 2.0786159767167454
Validation loss: 2.4180209315427517

Epoch: 6| Step: 7
Training loss: 2.412441660121291
Validation loss: 2.4197915098614664

Epoch: 6| Step: 8
Training loss: 2.87275873810071
Validation loss: 2.420264729647946

Epoch: 6| Step: 9
Training loss: 3.406209682960941
Validation loss: 2.4317980962446857

Epoch: 6| Step: 10
Training loss: 2.098280829675939
Validation loss: 2.4338053812741833

Epoch: 6| Step: 11
Training loss: 2.2425827050241183
Validation loss: 2.4458399750245388

Epoch: 6| Step: 12
Training loss: 2.8016112732351646
Validation loss: 2.4434103396607063

Epoch: 6| Step: 13
Training loss: 1.6937395524832377
Validation loss: 2.437467178868396

Epoch: 135| Step: 0
Training loss: 2.5779135877452037
Validation loss: 2.4299382022173854

Epoch: 6| Step: 1
Training loss: 2.660269893061729
Validation loss: 2.428784715528292

Epoch: 6| Step: 2
Training loss: 2.880254504826482
Validation loss: 2.4274715884291216

Epoch: 6| Step: 3
Training loss: 2.314231430574266
Validation loss: 2.4215404066339583

Epoch: 6| Step: 4
Training loss: 2.3206977909670856
Validation loss: 2.428012203463619

Epoch: 6| Step: 5
Training loss: 2.271482485690852
Validation loss: 2.425989206917103

Epoch: 6| Step: 6
Training loss: 2.405226452609001
Validation loss: 2.4293465608724967

Epoch: 6| Step: 7
Training loss: 1.7594552057390371
Validation loss: 2.436241831711725

Epoch: 6| Step: 8
Training loss: 2.8209543950648412
Validation loss: 2.4532573103339

Epoch: 6| Step: 9
Training loss: 2.9702989251851495
Validation loss: 2.503257357283338

Epoch: 6| Step: 10
Training loss: 3.0145834275364063
Validation loss: 2.5800447726309663

Epoch: 6| Step: 11
Training loss: 2.4198561590968573
Validation loss: 2.6053874216554416

Epoch: 6| Step: 12
Training loss: 2.943083792620962
Validation loss: 2.582066987384067

Epoch: 6| Step: 13
Training loss: 2.351785034599996
Validation loss: 2.55249362549724

Epoch: 136| Step: 0
Training loss: 2.516454903322637
Validation loss: 2.478593043491608

Epoch: 6| Step: 1
Training loss: 2.615506671521446
Validation loss: 2.425945759177739

Epoch: 6| Step: 2
Training loss: 2.9970327644071855
Validation loss: 2.412515004811803

Epoch: 6| Step: 3
Training loss: 2.664443718715071
Validation loss: 2.4080859109506583

Epoch: 6| Step: 4
Training loss: 2.1166234690345775
Validation loss: 2.4082827612314066

Epoch: 6| Step: 5
Training loss: 1.7322881705072402
Validation loss: 2.4199348630845208

Epoch: 6| Step: 6
Training loss: 3.096768534626969
Validation loss: 2.422527754268949

Epoch: 6| Step: 7
Training loss: 2.4738839764044993
Validation loss: 2.4386146006925538

Epoch: 6| Step: 8
Training loss: 2.5198340418830787
Validation loss: 2.464434585060877

Epoch: 6| Step: 9
Training loss: 2.3304313142578637
Validation loss: 2.4788911414212222

Epoch: 6| Step: 10
Training loss: 2.7829589736661386
Validation loss: 2.48184352711004

Epoch: 6| Step: 11
Training loss: 2.729139536560172
Validation loss: 2.484743938731252

Epoch: 6| Step: 12
Training loss: 2.43014100187653
Validation loss: 2.495817067017301

Epoch: 6| Step: 13
Training loss: 2.8266601984231947
Validation loss: 2.5054805548787797

Epoch: 137| Step: 0
Training loss: 3.0699019994843466
Validation loss: 2.516500400325441

Epoch: 6| Step: 1
Training loss: 2.54775218250749
Validation loss: 2.5157930367321915

Epoch: 6| Step: 2
Training loss: 2.9635314047333496
Validation loss: 2.473101285828803

Epoch: 6| Step: 3
Training loss: 2.5615036120503754
Validation loss: 2.4776449418415614

Epoch: 6| Step: 4
Training loss: 1.872996786042494
Validation loss: 2.478265006012552

Epoch: 6| Step: 5
Training loss: 2.4211911128046295
Validation loss: 2.47395389645

Epoch: 6| Step: 6
Training loss: 2.107161200861485
Validation loss: 2.4780134212681286

Epoch: 6| Step: 7
Training loss: 2.48196101919298
Validation loss: 2.477833791217962

Epoch: 6| Step: 8
Training loss: 1.9404365681496025
Validation loss: 2.482706556185153

Epoch: 6| Step: 9
Training loss: 2.3729474082163398
Validation loss: 2.4578918768395965

Epoch: 6| Step: 10
Training loss: 2.2238024285468656
Validation loss: 2.4587273182068756

Epoch: 6| Step: 11
Training loss: 2.6259342529247744
Validation loss: 2.4423094756878885

Epoch: 6| Step: 12
Training loss: 2.705329921860641
Validation loss: 2.4419402321575494

Epoch: 6| Step: 13
Training loss: 3.407649181568008
Validation loss: 2.423583705515342

Epoch: 138| Step: 0
Training loss: 2.570396074136395
Validation loss: 2.425942661286002

Epoch: 6| Step: 1
Training loss: 2.4763680270401407
Validation loss: 2.4235059842664657

Epoch: 6| Step: 2
Training loss: 2.12653553403957
Validation loss: 2.4252917811611208

Epoch: 6| Step: 3
Training loss: 2.4771830746969803
Validation loss: 2.4458654400286446

Epoch: 6| Step: 4
Training loss: 2.876870583400945
Validation loss: 2.476853913769853

Epoch: 6| Step: 5
Training loss: 3.031313236796091
Validation loss: 2.5034941097530785

Epoch: 6| Step: 6
Training loss: 2.287322440838689
Validation loss: 2.5192156295821713

Epoch: 6| Step: 7
Training loss: 2.286339816857545
Validation loss: 2.5236067079429687

Epoch: 6| Step: 8
Training loss: 2.0599083078218072
Validation loss: 2.5141993427844795

Epoch: 6| Step: 9
Training loss: 2.696086916034696
Validation loss: 2.4881107813280163

Epoch: 6| Step: 10
Training loss: 2.5055777316393737
Validation loss: 2.472928397139623

Epoch: 6| Step: 11
Training loss: 2.164407089837101
Validation loss: 2.466857004748517

Epoch: 6| Step: 12
Training loss: 2.5663101898284784
Validation loss: 2.4354155004287614

Epoch: 6| Step: 13
Training loss: 3.4769515944922063
Validation loss: 2.437508483400772

Epoch: 139| Step: 0
Training loss: 1.8204169509455566
Validation loss: 2.418174093882046

Epoch: 6| Step: 1
Training loss: 2.561891250875227
Validation loss: 2.4292685364436295

Epoch: 6| Step: 2
Training loss: 2.3896626049973366
Validation loss: 2.4301885325600585

Epoch: 6| Step: 3
Training loss: 2.0859431005967064
Validation loss: 2.4261824500801805

Epoch: 6| Step: 4
Training loss: 2.5270702561944
Validation loss: 2.4551751049775574

Epoch: 6| Step: 5
Training loss: 2.8369307026727983
Validation loss: 2.453497245035291

Epoch: 6| Step: 6
Training loss: 2.4698668259460743
Validation loss: 2.4734702856312034

Epoch: 6| Step: 7
Training loss: 2.6175763652632216
Validation loss: 2.465881780172801

Epoch: 6| Step: 8
Training loss: 2.651748073470368
Validation loss: 2.4949041092858892

Epoch: 6| Step: 9
Training loss: 2.140572428927909
Validation loss: 2.4799669634927204

Epoch: 6| Step: 10
Training loss: 2.841808620572806
Validation loss: 2.470603078132782

Epoch: 6| Step: 11
Training loss: 3.0265340399007137
Validation loss: 2.4540637714895843

Epoch: 6| Step: 12
Training loss: 2.0748464780338973
Validation loss: 2.4464682977945733

Epoch: 6| Step: 13
Training loss: 2.2277282875294917
Validation loss: 2.4696149742492244

Epoch: 140| Step: 0
Training loss: 2.3246063678550852
Validation loss: 2.4778846313692564

Epoch: 6| Step: 1
Training loss: 2.321192616219209
Validation loss: 2.4823763668513337

Epoch: 6| Step: 2
Training loss: 2.5876406682058244
Validation loss: 2.4925681717220565

Epoch: 6| Step: 3
Training loss: 2.9059546535915644
Validation loss: 2.493653454575692

Epoch: 6| Step: 4
Training loss: 2.3375014361208826
Validation loss: 2.4666569181890954

Epoch: 6| Step: 5
Training loss: 2.498635014783726
Validation loss: 2.4740500194267288

Epoch: 6| Step: 6
Training loss: 2.4679679114668467
Validation loss: 2.472421327775136

Epoch: 6| Step: 7
Training loss: 2.4782988902171805
Validation loss: 2.473472659630233

Epoch: 6| Step: 8
Training loss: 1.7843632178243278
Validation loss: 2.457432311846321

Epoch: 6| Step: 9
Training loss: 2.7198431513946675
Validation loss: 2.455309650977713

Epoch: 6| Step: 10
Training loss: 2.345389644566307
Validation loss: 2.4390778232139456

Epoch: 6| Step: 11
Training loss: 2.179554268651634
Validation loss: 2.4226704096120173

Epoch: 6| Step: 12
Training loss: 2.8207797775556314
Validation loss: 2.4472910762172124

Epoch: 6| Step: 13
Training loss: 2.9148246034490772
Validation loss: 2.4339141995525724

Epoch: 141| Step: 0
Training loss: 1.982543941554409
Validation loss: 2.435903174970772

Epoch: 6| Step: 1
Training loss: 2.8612547985484964
Validation loss: 2.4641413238617234

Epoch: 6| Step: 2
Training loss: 2.7589327776449575
Validation loss: 2.4692846970234594

Epoch: 6| Step: 3
Training loss: 2.5374827943415874
Validation loss: 2.4665164472600836

Epoch: 6| Step: 4
Training loss: 1.9036048923026372
Validation loss: 2.4528668734631727

Epoch: 6| Step: 5
Training loss: 2.364308737608559
Validation loss: 2.4500693383407395

Epoch: 6| Step: 6
Training loss: 2.580542892883061
Validation loss: 2.4507889094198987

Epoch: 6| Step: 7
Training loss: 2.316309188687658
Validation loss: 2.4394599180594057

Epoch: 6| Step: 8
Training loss: 2.4203326821024467
Validation loss: 2.4398287221067303

Epoch: 6| Step: 9
Training loss: 2.6558965111184203
Validation loss: 2.4493115041800366

Epoch: 6| Step: 10
Training loss: 2.8472205143951834
Validation loss: 2.462494032399549

Epoch: 6| Step: 11
Training loss: 2.7406280517561132
Validation loss: 2.450735188036158

Epoch: 6| Step: 12
Training loss: 2.150443843006329
Validation loss: 2.453901878644229

Epoch: 6| Step: 13
Training loss: 2.287329007621165
Validation loss: 2.470120405949318

Epoch: 142| Step: 0
Training loss: 2.6580325260396767
Validation loss: 2.497063995456902

Epoch: 6| Step: 1
Training loss: 2.362963442280312
Validation loss: 2.5265157633785624

Epoch: 6| Step: 2
Training loss: 3.004968661178197
Validation loss: 2.5458276838586302

Epoch: 6| Step: 3
Training loss: 2.888591484101538
Validation loss: 2.5571487500771557

Epoch: 6| Step: 4
Training loss: 3.262868931982614
Validation loss: 2.53934060415577

Epoch: 6| Step: 5
Training loss: 2.387211775233704
Validation loss: 2.529271514128146

Epoch: 6| Step: 6
Training loss: 2.051167188387333
Validation loss: 2.4776943750711946

Epoch: 6| Step: 7
Training loss: 2.175876361952784
Validation loss: 2.451314097456549

Epoch: 6| Step: 8
Training loss: 2.110023455376449
Validation loss: 2.448957965240309

Epoch: 6| Step: 9
Training loss: 2.4524023850483667
Validation loss: 2.4397943729733065

Epoch: 6| Step: 10
Training loss: 2.1811051766048224
Validation loss: 2.432309195010524

Epoch: 6| Step: 11
Training loss: 1.7676927055188096
Validation loss: 2.4293841865865398

Epoch: 6| Step: 12
Training loss: 2.3938233167610545
Validation loss: 2.4294166230616874

Epoch: 6| Step: 13
Training loss: 2.5818201576083704
Validation loss: 2.447237594414239

Epoch: 143| Step: 0
Training loss: 2.127194561667088
Validation loss: 2.4479375647650126

Epoch: 6| Step: 1
Training loss: 2.657478138357335
Validation loss: 2.455741925005734

Epoch: 6| Step: 2
Training loss: 2.382967584284659
Validation loss: 2.4652571252141424

Epoch: 6| Step: 3
Training loss: 2.630207346295968
Validation loss: 2.472021006304724

Epoch: 6| Step: 4
Training loss: 2.458486056567768
Validation loss: 2.4887848150682297

Epoch: 6| Step: 5
Training loss: 2.0795728186120717
Validation loss: 2.4948588442363526

Epoch: 6| Step: 6
Training loss: 2.3906251994612866
Validation loss: 2.5116971157461925

Epoch: 6| Step: 7
Training loss: 2.344758490710875
Validation loss: 2.549069964924806

Epoch: 6| Step: 8
Training loss: 2.2460989512507714
Validation loss: 2.5653685324480002

Epoch: 6| Step: 9
Training loss: 2.6279140827760403
Validation loss: 2.5324267851486844

Epoch: 6| Step: 10
Training loss: 2.9128078183424115
Validation loss: 2.520473027003873

Epoch: 6| Step: 11
Training loss: 2.3892447282989036
Validation loss: 2.529450844019295

Epoch: 6| Step: 12
Training loss: 2.0995955213932493
Validation loss: 2.509692844481388

Epoch: 6| Step: 13
Training loss: 2.819978984862678
Validation loss: 2.503301645042348

Epoch: 144| Step: 0
Training loss: 2.5748432889491517
Validation loss: 2.5032846295004902

Epoch: 6| Step: 1
Training loss: 2.656417482369292
Validation loss: 2.4884062668799465

Epoch: 6| Step: 2
Training loss: 2.892757639443561
Validation loss: 2.470467707809242

Epoch: 6| Step: 3
Training loss: 2.3632846800724074
Validation loss: 2.4404900782228838

Epoch: 6| Step: 4
Training loss: 2.84795479589656
Validation loss: 2.4128168709313793

Epoch: 6| Step: 5
Training loss: 2.863691896392805
Validation loss: 2.408884126742404

Epoch: 6| Step: 6
Training loss: 2.5667489344140524
Validation loss: 2.4252324453726275

Epoch: 6| Step: 7
Training loss: 2.0169221710939884
Validation loss: 2.439294368631262

Epoch: 6| Step: 8
Training loss: 2.64201977252131
Validation loss: 2.480508821729123

Epoch: 6| Step: 9
Training loss: 2.133429469485582
Validation loss: 2.5093596385314556

Epoch: 6| Step: 10
Training loss: 2.3125780453270672
Validation loss: 2.530526125926075

Epoch: 6| Step: 11
Training loss: 2.629248949588059
Validation loss: 2.5808188590658587

Epoch: 6| Step: 12
Training loss: 2.122493612147268
Validation loss: 2.5902284807765223

Epoch: 6| Step: 13
Training loss: 2.30419616634347
Validation loss: 2.6129057043077224

Epoch: 145| Step: 0
Training loss: 3.2219046531222855
Validation loss: 2.543142486031423

Epoch: 6| Step: 1
Training loss: 2.1014243154935555
Validation loss: 2.5023655538800744

Epoch: 6| Step: 2
Training loss: 2.8701957699666707
Validation loss: 2.4948596704020227

Epoch: 6| Step: 3
Training loss: 2.859441704310749
Validation loss: 2.4803876123778847

Epoch: 6| Step: 4
Training loss: 2.530385752886434
Validation loss: 2.4736612259199897

Epoch: 6| Step: 5
Training loss: 1.868242165447864
Validation loss: 2.454159595472281

Epoch: 6| Step: 6
Training loss: 2.4863887279043877
Validation loss: 2.464387978591243

Epoch: 6| Step: 7
Training loss: 2.5239716428079637
Validation loss: 2.477448225054765

Epoch: 6| Step: 8
Training loss: 2.3431379409151845
Validation loss: 2.4860078194353954

Epoch: 6| Step: 9
Training loss: 2.0511732326278596
Validation loss: 2.4978754532415284

Epoch: 6| Step: 10
Training loss: 2.4447055831293047
Validation loss: 2.5095570288572797

Epoch: 6| Step: 11
Training loss: 2.268051321515364
Validation loss: 2.5305018988710746

Epoch: 6| Step: 12
Training loss: 2.5338831263132366
Validation loss: 2.5738498665504346

Epoch: 6| Step: 13
Training loss: 2.708679930199195
Validation loss: 2.5807996531870248

Epoch: 146| Step: 0
Training loss: 2.7686044624604045
Validation loss: 2.56358904923132

Epoch: 6| Step: 1
Training loss: 3.0777730208022365
Validation loss: 2.5258506737373096

Epoch: 6| Step: 2
Training loss: 2.861412614740215
Validation loss: 2.4932011950347612

Epoch: 6| Step: 3
Training loss: 2.3826876248016258
Validation loss: 2.4881292967619575

Epoch: 6| Step: 4
Training loss: 2.5240415434766126
Validation loss: 2.47880345723523

Epoch: 6| Step: 5
Training loss: 2.228071805471474
Validation loss: 2.490793666521349

Epoch: 6| Step: 6
Training loss: 2.430293458400716
Validation loss: 2.489643888234345

Epoch: 6| Step: 7
Training loss: 2.2298041053227107
Validation loss: 2.4834968623168234

Epoch: 6| Step: 8
Training loss: 2.1889170825044038
Validation loss: 2.496952493371076

Epoch: 6| Step: 9
Training loss: 2.243231447276407
Validation loss: 2.4787762114607133

Epoch: 6| Step: 10
Training loss: 2.5083124250721323
Validation loss: 2.48715746141198

Epoch: 6| Step: 11
Training loss: 2.650581504790524
Validation loss: 2.487198494249585

Epoch: 6| Step: 12
Training loss: 2.5267059606283055
Validation loss: 2.4994972738738483

Epoch: 6| Step: 13
Training loss: 2.2069849060054065
Validation loss: 2.4863465897816854

Epoch: 147| Step: 0
Training loss: 2.080332107440082
Validation loss: 2.5231553375876614

Epoch: 6| Step: 1
Training loss: 2.0153175533525305
Validation loss: 2.533825063692709

Epoch: 6| Step: 2
Training loss: 2.2514840635870432
Validation loss: 2.555370890554544

Epoch: 6| Step: 3
Training loss: 2.568460371113114
Validation loss: 2.559734091302045

Epoch: 6| Step: 4
Training loss: 2.6552813390605126
Validation loss: 2.576135938408483

Epoch: 6| Step: 5
Training loss: 2.834034515084534
Validation loss: 2.600847865407156

Epoch: 6| Step: 6
Training loss: 2.7796392169638047
Validation loss: 2.596164847827065

Epoch: 6| Step: 7
Training loss: 2.2867150883047427
Validation loss: 2.5640960383016655

Epoch: 6| Step: 8
Training loss: 2.194305840741254
Validation loss: 2.531815495453092

Epoch: 6| Step: 9
Training loss: 2.6487591303424534
Validation loss: 2.521966222674189

Epoch: 6| Step: 10
Training loss: 2.7622532522897236
Validation loss: 2.5049567439184184

Epoch: 6| Step: 11
Training loss: 2.7329387271403855
Validation loss: 2.51632807583016

Epoch: 6| Step: 12
Training loss: 2.167394723590491
Validation loss: 2.5117472449552096

Epoch: 6| Step: 13
Training loss: 1.693982987373613
Validation loss: 2.497392370175896

Epoch: 148| Step: 0
Training loss: 2.44262098686256
Validation loss: 2.50917876085455

Epoch: 6| Step: 1
Training loss: 2.8447617627842776
Validation loss: 2.510343289561351

Epoch: 6| Step: 2
Training loss: 1.877541409174259
Validation loss: 2.5141848441285135

Epoch: 6| Step: 3
Training loss: 2.968108097750424
Validation loss: 2.517582183926011

Epoch: 6| Step: 4
Training loss: 2.6781261110247843
Validation loss: 2.540483693334624

Epoch: 6| Step: 5
Training loss: 2.6812430001547614
Validation loss: 2.5642305418801494

Epoch: 6| Step: 6
Training loss: 2.480563520888863
Validation loss: 2.5566709927391287

Epoch: 6| Step: 7
Training loss: 1.7468230838601724
Validation loss: 2.5579305866965565

Epoch: 6| Step: 8
Training loss: 2.537345141115576
Validation loss: 2.517710120241771

Epoch: 6| Step: 9
Training loss: 2.342223216898492
Validation loss: 2.525022157920906

Epoch: 6| Step: 10
Training loss: 2.336317356826568
Validation loss: 2.519434033472472

Epoch: 6| Step: 11
Training loss: 2.1188339081749965
Validation loss: 2.514169441955319

Epoch: 6| Step: 12
Training loss: 1.8653354797123705
Validation loss: 2.5050241274997354

Epoch: 6| Step: 13
Training loss: 2.382658206134128
Validation loss: 2.5022581269551907

Epoch: 149| Step: 0
Training loss: 2.5317398350857094
Validation loss: 2.5076598757749453

Epoch: 6| Step: 1
Training loss: 2.239347673186057
Validation loss: 2.4815931625993897

Epoch: 6| Step: 2
Training loss: 2.0250374496199526
Validation loss: 2.5041503664387488

Epoch: 6| Step: 3
Training loss: 2.500543725967629
Validation loss: 2.503964995124043

Epoch: 6| Step: 4
Training loss: 1.9921077936720408
Validation loss: 2.509888364435958

Epoch: 6| Step: 5
Training loss: 2.402957397489683
Validation loss: 2.508559126484757

Epoch: 6| Step: 6
Training loss: 2.4469466431556457
Validation loss: 2.5171419060731894

Epoch: 6| Step: 7
Training loss: 2.6253313127971345
Validation loss: 2.510114195526513

Epoch: 6| Step: 8
Training loss: 2.447911840122957
Validation loss: 2.5108969114216872

Epoch: 6| Step: 9
Training loss: 2.4610717736806293
Validation loss: 2.51092632387774

Epoch: 6| Step: 10
Training loss: 2.251052610225693
Validation loss: 2.532344260027963

Epoch: 6| Step: 11
Training loss: 2.5816649207381603
Validation loss: 2.5283491415271735

Epoch: 6| Step: 12
Training loss: 2.512514169377849
Validation loss: 2.5160117586107824

Epoch: 6| Step: 13
Training loss: 2.357862480346724
Validation loss: 2.494694929713429

Epoch: 150| Step: 0
Training loss: 2.1435860529453525
Validation loss: 2.5066068614383097

Epoch: 6| Step: 1
Training loss: 2.738835125030722
Validation loss: 2.4995745040416826

Epoch: 6| Step: 2
Training loss: 2.261802553195644
Validation loss: 2.5021645373857884

Epoch: 6| Step: 3
Training loss: 2.3836357320553625
Validation loss: 2.4966213827885246

Epoch: 6| Step: 4
Training loss: 2.499812405223603
Validation loss: 2.494875353111904

Epoch: 6| Step: 5
Training loss: 2.413297958044501
Validation loss: 2.5164685586223206

Epoch: 6| Step: 6
Training loss: 2.07515556028102
Validation loss: 2.518931432514359

Epoch: 6| Step: 7
Training loss: 2.794578333866745
Validation loss: 2.520855827675262

Epoch: 6| Step: 8
Training loss: 3.0388519292610545
Validation loss: 2.4985277363044625

Epoch: 6| Step: 9
Training loss: 2.4162434722606974
Validation loss: 2.50237814479194

Epoch: 6| Step: 10
Training loss: 2.271098083554947
Validation loss: 2.498676463452613

Epoch: 6| Step: 11
Training loss: 2.578064518999386
Validation loss: 2.491260119552636

Epoch: 6| Step: 12
Training loss: 1.6358188531474076
Validation loss: 2.493390398674865

Epoch: 6| Step: 13
Training loss: 1.6150316251841166
Validation loss: 2.4867039864170573

Epoch: 151| Step: 0
Training loss: 2.1136646874805605
Validation loss: 2.4757910814790547

Epoch: 6| Step: 1
Training loss: 2.851800777983471
Validation loss: 2.4730353094098647

Epoch: 6| Step: 2
Training loss: 2.142199528922623
Validation loss: 2.478742958468284

Epoch: 6| Step: 3
Training loss: 2.332768053882102
Validation loss: 2.4742964297981223

Epoch: 6| Step: 4
Training loss: 2.6061421543559242
Validation loss: 2.4753196555460857

Epoch: 6| Step: 5
Training loss: 2.1742349879665603
Validation loss: 2.4795335260555182

Epoch: 6| Step: 6
Training loss: 2.552182150244638
Validation loss: 2.477154107632872

Epoch: 6| Step: 7
Training loss: 1.8017641641148208
Validation loss: 2.4766736799946907

Epoch: 6| Step: 8
Training loss: 2.283019646679109
Validation loss: 2.473978798505832

Epoch: 6| Step: 9
Training loss: 2.3682343336867935
Validation loss: 2.5037216889724063

Epoch: 6| Step: 10
Training loss: 2.759800440304769
Validation loss: 2.4901322446047787

Epoch: 6| Step: 11
Training loss: 2.822021051389171
Validation loss: 2.4709332460571614

Epoch: 6| Step: 12
Training loss: 1.599621596889359
Validation loss: 2.489714358309196

Epoch: 6| Step: 13
Training loss: 2.2944807172386055
Validation loss: 2.5065123899739996

Epoch: 152| Step: 0
Training loss: 2.536630539789318
Validation loss: 2.5300508649334286

Epoch: 6| Step: 1
Training loss: 2.0750030931196943
Validation loss: 2.5281458397811556

Epoch: 6| Step: 2
Training loss: 1.8799103970175863
Validation loss: 2.5140690802874497

Epoch: 6| Step: 3
Training loss: 2.6799104558874176
Validation loss: 2.535750339034939

Epoch: 6| Step: 4
Training loss: 2.0285727830955236
Validation loss: 2.5153690697873943

Epoch: 6| Step: 5
Training loss: 2.152120201284958
Validation loss: 2.5182069167763657

Epoch: 6| Step: 6
Training loss: 2.486101618156092
Validation loss: 2.5254723322863297

Epoch: 6| Step: 7
Training loss: 2.619706220099205
Validation loss: 2.5426240634522648

Epoch: 6| Step: 8
Training loss: 1.989932949911027
Validation loss: 2.5301858074488326

Epoch: 6| Step: 9
Training loss: 2.477146212263942
Validation loss: 2.5439109583419373

Epoch: 6| Step: 10
Training loss: 2.32361591118454
Validation loss: 2.5373599873517785

Epoch: 6| Step: 11
Training loss: 2.314801076495057
Validation loss: 2.527418224351138

Epoch: 6| Step: 12
Training loss: 2.7790904715719726
Validation loss: 2.494899758632141

Epoch: 6| Step: 13
Training loss: 2.5105140846524403
Validation loss: 2.4759857229671716

Epoch: 153| Step: 0
Training loss: 2.76542964611731
Validation loss: 2.4757567881013864

Epoch: 6| Step: 1
Training loss: 1.889850300102978
Validation loss: 2.4645370007281433

Epoch: 6| Step: 2
Training loss: 2.1326564410339044
Validation loss: 2.4697636031456414

Epoch: 6| Step: 3
Training loss: 2.107286337523448
Validation loss: 2.4850597484027546

Epoch: 6| Step: 4
Training loss: 2.4495389932805827
Validation loss: 2.4892318943665774

Epoch: 6| Step: 5
Training loss: 2.906537605739286
Validation loss: 2.507232577495646

Epoch: 6| Step: 6
Training loss: 1.7358455437889886
Validation loss: 2.5045868541458387

Epoch: 6| Step: 7
Training loss: 2.410048224255545
Validation loss: 2.523691306644241

Epoch: 6| Step: 8
Training loss: 2.9289777786177753
Validation loss: 2.534519368556571

Epoch: 6| Step: 9
Training loss: 1.9730649619141043
Validation loss: 2.5591860586183595

Epoch: 6| Step: 10
Training loss: 2.2926443153142984
Validation loss: 2.5378858148407395

Epoch: 6| Step: 11
Training loss: 2.247448852432312
Validation loss: 2.544093078462322

Epoch: 6| Step: 12
Training loss: 2.6657285430940467
Validation loss: 2.5090963058580362

Epoch: 6| Step: 13
Training loss: 0.7116943355187483
Validation loss: 2.5001940067446586

Epoch: 154| Step: 0
Training loss: 2.2686157481087754
Validation loss: 2.478293507008396

Epoch: 6| Step: 1
Training loss: 2.4074020600327444
Validation loss: 2.475848352369556

Epoch: 6| Step: 2
Training loss: 2.136658495065632
Validation loss: 2.4626785247754603

Epoch: 6| Step: 3
Training loss: 1.9344910052246416
Validation loss: 2.4579956367799918

Epoch: 6| Step: 4
Training loss: 1.9995846913195248
Validation loss: 2.4647665985993936

Epoch: 6| Step: 5
Training loss: 1.6926746854127661
Validation loss: 2.449707355144537

Epoch: 6| Step: 6
Training loss: 2.160539093031151
Validation loss: 2.4728620620715698

Epoch: 6| Step: 7
Training loss: 2.6343533226560303
Validation loss: 2.4865183392951873

Epoch: 6| Step: 8
Training loss: 2.510167047481543
Validation loss: 2.4920931629254977

Epoch: 6| Step: 9
Training loss: 1.9786537777415787
Validation loss: 2.5254789137650455

Epoch: 6| Step: 10
Training loss: 2.2966566955209693
Validation loss: 2.5460938665577793

Epoch: 6| Step: 11
Training loss: 2.8442365628347814
Validation loss: 2.5733215809200436

Epoch: 6| Step: 12
Training loss: 2.7089970484562955
Validation loss: 2.630067078606683

Epoch: 6| Step: 13
Training loss: 3.190606492126169
Validation loss: 2.654680524560962

Epoch: 155| Step: 0
Training loss: 2.5294033897094264
Validation loss: 2.658971704937909

Epoch: 6| Step: 1
Training loss: 2.5543881862179627
Validation loss: 2.611240775344068

Epoch: 6| Step: 2
Training loss: 1.7258376589355096
Validation loss: 2.5720997397294796

Epoch: 6| Step: 3
Training loss: 2.1076393050630324
Validation loss: 2.5343337513477993

Epoch: 6| Step: 4
Training loss: 2.7321234452157284
Validation loss: 2.539627728649616

Epoch: 6| Step: 5
Training loss: 2.6027612072464543
Validation loss: 2.5233363690651096

Epoch: 6| Step: 6
Training loss: 2.344368001204854
Validation loss: 2.515988789778943

Epoch: 6| Step: 7
Training loss: 2.297780487738183
Validation loss: 2.4986591281060533

Epoch: 6| Step: 8
Training loss: 2.484094855870082
Validation loss: 2.4820412274362558

Epoch: 6| Step: 9
Training loss: 2.1041991983549044
Validation loss: 2.479679360394346

Epoch: 6| Step: 10
Training loss: 2.290242590735786
Validation loss: 2.4821500173571116

Epoch: 6| Step: 11
Training loss: 2.115603033540584
Validation loss: 2.488037574465806

Epoch: 6| Step: 12
Training loss: 2.418539593044232
Validation loss: 2.50749794721936

Epoch: 6| Step: 13
Training loss: 2.258169918083395
Validation loss: 2.5253535820443664

Epoch: 156| Step: 0
Training loss: 1.480611909975131
Validation loss: 2.5611612768265575

Epoch: 6| Step: 1
Training loss: 2.764467331139756
Validation loss: 2.5733869721524942

Epoch: 6| Step: 2
Training loss: 2.4207967018949605
Validation loss: 2.5804690248359217

Epoch: 6| Step: 3
Training loss: 2.4799447534929477
Validation loss: 2.609738516237185

Epoch: 6| Step: 4
Training loss: 2.1902738150904333
Validation loss: 2.634775108864548

Epoch: 6| Step: 5
Training loss: 2.495344022529055
Validation loss: 2.613682781567509

Epoch: 6| Step: 6
Training loss: 3.317016976672739
Validation loss: 2.6210854597767335

Epoch: 6| Step: 7
Training loss: 1.4749813595903225
Validation loss: 2.593723490214219

Epoch: 6| Step: 8
Training loss: 2.259882522500435
Validation loss: 2.5875669344190215

Epoch: 6| Step: 9
Training loss: 2.1723752989279017
Validation loss: 2.561734793337015

Epoch: 6| Step: 10
Training loss: 1.7345961696062138
Validation loss: 2.539265223535756

Epoch: 6| Step: 11
Training loss: 2.4927847693637872
Validation loss: 2.540225742328428

Epoch: 6| Step: 12
Training loss: 2.2728145834017526
Validation loss: 2.524995832217446

Epoch: 6| Step: 13
Training loss: 2.4700944354271113
Validation loss: 2.5098451591802484

Epoch: 157| Step: 0
Training loss: 2.945936384831091
Validation loss: 2.5273610803097717

Epoch: 6| Step: 1
Training loss: 2.331256578042412
Validation loss: 2.529578266208619

Epoch: 6| Step: 2
Training loss: 2.3626856534157668
Validation loss: 2.552023885979231

Epoch: 6| Step: 3
Training loss: 2.365446048151145
Validation loss: 2.5623186388922985

Epoch: 6| Step: 4
Training loss: 2.061593521206275
Validation loss: 2.563115090882188

Epoch: 6| Step: 5
Training loss: 1.8886762932584695
Validation loss: 2.581656792870185

Epoch: 6| Step: 6
Training loss: 2.3520107919224826
Validation loss: 2.578550928157724

Epoch: 6| Step: 7
Training loss: 2.060784522359195
Validation loss: 2.589894142440769

Epoch: 6| Step: 8
Training loss: 2.8706034338980073
Validation loss: 2.6145225507705128

Epoch: 6| Step: 9
Training loss: 1.6398902337627002
Validation loss: 2.598945306101713

Epoch: 6| Step: 10
Training loss: 1.8825241437886053
Validation loss: 2.5936593273260318

Epoch: 6| Step: 11
Training loss: 2.4287344973977905
Validation loss: 2.5906957560199713

Epoch: 6| Step: 12
Training loss: 2.219528276655655
Validation loss: 2.54676901267575

Epoch: 6| Step: 13
Training loss: 2.417869060476522
Validation loss: 2.5268078363395645

Epoch: 158| Step: 0
Training loss: 2.027455468306112
Validation loss: 2.4918258784725933

Epoch: 6| Step: 1
Training loss: 2.025602147562838
Validation loss: 2.5099077314338047

Epoch: 6| Step: 2
Training loss: 2.533890841859987
Validation loss: 2.4884209693053165

Epoch: 6| Step: 3
Training loss: 1.7850908062915296
Validation loss: 2.4948452432905426

Epoch: 6| Step: 4
Training loss: 2.566644062421602
Validation loss: 2.4934641619129456

Epoch: 6| Step: 5
Training loss: 1.7732320658133034
Validation loss: 2.4951124786325454

Epoch: 6| Step: 6
Training loss: 2.3308781467894595
Validation loss: 2.487560501966484

Epoch: 6| Step: 7
Training loss: 3.0385685301072614
Validation loss: 2.4741205197049054

Epoch: 6| Step: 8
Training loss: 2.170967845690932
Validation loss: 2.50123325918624

Epoch: 6| Step: 9
Training loss: 2.7640296947026894
Validation loss: 2.500274316545395

Epoch: 6| Step: 10
Training loss: 1.8624005745585366
Validation loss: 2.5220413798233388

Epoch: 6| Step: 11
Training loss: 2.0666187660244626
Validation loss: 2.5475500125647788

Epoch: 6| Step: 12
Training loss: 2.3033134890565004
Validation loss: 2.5679463120231434

Epoch: 6| Step: 13
Training loss: 2.445126657462291
Validation loss: 2.599155443622043

Epoch: 159| Step: 0
Training loss: 1.86172477922892
Validation loss: 2.6123957738444235

Epoch: 6| Step: 1
Training loss: 2.3401528792692265
Validation loss: 2.644445883160614

Epoch: 6| Step: 2
Training loss: 1.984068539000859
Validation loss: 2.6387174361365826

Epoch: 6| Step: 3
Training loss: 2.308615230970282
Validation loss: 2.630830958913219

Epoch: 6| Step: 4
Training loss: 2.4492439621596573
Validation loss: 2.574966390063644

Epoch: 6| Step: 5
Training loss: 2.3948990257814557
Validation loss: 2.533908019136317

Epoch: 6| Step: 6
Training loss: 2.0411775223618864
Validation loss: 2.5096569228146595

Epoch: 6| Step: 7
Training loss: 2.024599897629998
Validation loss: 2.496299447471338

Epoch: 6| Step: 8
Training loss: 2.5305513901390673
Validation loss: 2.48617197312352

Epoch: 6| Step: 9
Training loss: 2.2600017348426302
Validation loss: 2.494684104048715

Epoch: 6| Step: 10
Training loss: 2.229912843925499
Validation loss: 2.5132572906783324

Epoch: 6| Step: 11
Training loss: 2.7680100324040997
Validation loss: 2.508191349166143

Epoch: 6| Step: 12
Training loss: 2.6306270958440527
Validation loss: 2.503619513837758

Epoch: 6| Step: 13
Training loss: 2.7089445940437087
Validation loss: 2.502381859559856

Epoch: 160| Step: 0
Training loss: 2.4001882916339357
Validation loss: 2.4888648590245332

Epoch: 6| Step: 1
Training loss: 2.117930151834984
Validation loss: 2.4901390775188097

Epoch: 6| Step: 2
Training loss: 2.4620513817192333
Validation loss: 2.474411532606744

Epoch: 6| Step: 3
Training loss: 1.7863331594256495
Validation loss: 2.4704044748929848

Epoch: 6| Step: 4
Training loss: 2.2040141590722855
Validation loss: 2.4779156704660807

Epoch: 6| Step: 5
Training loss: 2.56168063950642
Validation loss: 2.4760778761742355

Epoch: 6| Step: 6
Training loss: 2.366798494813462
Validation loss: 2.4768676331750723

Epoch: 6| Step: 7
Training loss: 2.383207894961216
Validation loss: 2.4810431405363773

Epoch: 6| Step: 8
Training loss: 2.3444561720982127
Validation loss: 2.4975943527474107

Epoch: 6| Step: 9
Training loss: 2.3549325310504248
Validation loss: 2.528994188193264

Epoch: 6| Step: 10
Training loss: 1.698043381656891
Validation loss: 2.5495650328842427

Epoch: 6| Step: 11
Training loss: 2.1864580125037607
Validation loss: 2.575578970592887

Epoch: 6| Step: 12
Training loss: 1.6662840721956536
Validation loss: 2.5875671761628305

Epoch: 6| Step: 13
Training loss: 2.7080925076347055
Validation loss: 2.602813893721464

Epoch: 161| Step: 0
Training loss: 2.1233053743127597
Validation loss: 2.686241649917296

Epoch: 6| Step: 1
Training loss: 3.087991615106139
Validation loss: 2.70528947688595

Epoch: 6| Step: 2
Training loss: 2.4561092423737247
Validation loss: 2.640646275036998

Epoch: 6| Step: 3
Training loss: 1.7152310501028183
Validation loss: 2.598249328152407

Epoch: 6| Step: 4
Training loss: 1.5571827249685342
Validation loss: 2.5760672940651697

Epoch: 6| Step: 5
Training loss: 2.1843906647607576
Validation loss: 2.5360940674737056

Epoch: 6| Step: 6
Training loss: 2.4884976902223443
Validation loss: 2.5531706358245185

Epoch: 6| Step: 7
Training loss: 1.9095713962373548
Validation loss: 2.5421155684107464

Epoch: 6| Step: 8
Training loss: 2.3438547746763128
Validation loss: 2.5202138375659398

Epoch: 6| Step: 9
Training loss: 2.747860856799354
Validation loss: 2.4847051744577393

Epoch: 6| Step: 10
Training loss: 1.878666027677241
Validation loss: 2.4599351223439845

Epoch: 6| Step: 11
Training loss: 3.044105562282032
Validation loss: 2.4729587727756535

Epoch: 6| Step: 12
Training loss: 2.2493964551372514
Validation loss: 2.4670492362450442

Epoch: 6| Step: 13
Training loss: 2.9856446446440668
Validation loss: 2.4943326619064874

Epoch: 162| Step: 0
Training loss: 2.7989392042245775
Validation loss: 2.506761318519816

Epoch: 6| Step: 1
Training loss: 2.219104792207071
Validation loss: 2.5199503690009255

Epoch: 6| Step: 2
Training loss: 1.9717249721033216
Validation loss: 2.5410669191755892

Epoch: 6| Step: 3
Training loss: 2.060502443241336
Validation loss: 2.565159569772814

Epoch: 6| Step: 4
Training loss: 2.0735144847385105
Validation loss: 2.6129043630815

Epoch: 6| Step: 5
Training loss: 2.5624832524938626
Validation loss: 2.609448841630226

Epoch: 6| Step: 6
Training loss: 2.1182884366219628
Validation loss: 2.6024494939693894

Epoch: 6| Step: 7
Training loss: 1.6936762776113699
Validation loss: 2.586528816918203

Epoch: 6| Step: 8
Training loss: 2.489071515408824
Validation loss: 2.572301833924724

Epoch: 6| Step: 9
Training loss: 2.564619350929321
Validation loss: 2.5667781698007635

Epoch: 6| Step: 10
Training loss: 2.3579246661161806
Validation loss: 2.5572574590551227

Epoch: 6| Step: 11
Training loss: 2.340737199322364
Validation loss: 2.5158421733433656

Epoch: 6| Step: 12
Training loss: 1.6691054462106545
Validation loss: 2.497377695929675

Epoch: 6| Step: 13
Training loss: 1.977392452127044
Validation loss: 2.486144719420192

Epoch: 163| Step: 0
Training loss: 2.6093244719038897
Validation loss: 2.4895821031287735

Epoch: 6| Step: 1
Training loss: 1.9450945751271234
Validation loss: 2.4752475721599265

Epoch: 6| Step: 2
Training loss: 2.253015616588422
Validation loss: 2.476190623656152

Epoch: 6| Step: 3
Training loss: 1.9198834404731584
Validation loss: 2.4700149965024054

Epoch: 6| Step: 4
Training loss: 2.5207514683905408
Validation loss: 2.4619516694887325

Epoch: 6| Step: 5
Training loss: 2.1690202791946454
Validation loss: 2.467499866740138

Epoch: 6| Step: 6
Training loss: 1.7672643562151462
Validation loss: 2.4662548928615875

Epoch: 6| Step: 7
Training loss: 2.045745421448187
Validation loss: 2.4874147792709835

Epoch: 6| Step: 8
Training loss: 2.62923797736412
Validation loss: 2.496228841331396

Epoch: 6| Step: 9
Training loss: 2.1043521560140537
Validation loss: 2.4978611164183038

Epoch: 6| Step: 10
Training loss: 2.182656293343743
Validation loss: 2.505884265888733

Epoch: 6| Step: 11
Training loss: 1.8817521904610426
Validation loss: 2.518592370441179

Epoch: 6| Step: 12
Training loss: 2.238059254234317
Validation loss: 2.5633640158265507

Epoch: 6| Step: 13
Training loss: 1.8342012027375905
Validation loss: 2.6180660295864917

Epoch: 164| Step: 0
Training loss: 2.6990953519358207
Validation loss: 2.63632329614897

Epoch: 6| Step: 1
Training loss: 1.833344856861774
Validation loss: 2.6464481910254403

Epoch: 6| Step: 2
Training loss: 2.818102533450138
Validation loss: 2.625971604061579

Epoch: 6| Step: 3
Training loss: 1.8104605546145056
Validation loss: 2.584189469272966

Epoch: 6| Step: 4
Training loss: 1.8895575922930439
Validation loss: 2.572352528154263

Epoch: 6| Step: 5
Training loss: 1.7945679823188818
Validation loss: 2.53384383898375

Epoch: 6| Step: 6
Training loss: 2.2612080631616425
Validation loss: 2.5180916829735462

Epoch: 6| Step: 7
Training loss: 1.9100452851124814
Validation loss: 2.515042797036735

Epoch: 6| Step: 8
Training loss: 2.924239400453901
Validation loss: 2.5032395052390983

Epoch: 6| Step: 9
Training loss: 2.195908869313365
Validation loss: 2.488284374854622

Epoch: 6| Step: 10
Training loss: 1.6096441543836497
Validation loss: 2.4968458356587253

Epoch: 6| Step: 11
Training loss: 3.2194792282541083
Validation loss: 2.4783599108228582

Epoch: 6| Step: 12
Training loss: 1.6878228055416522
Validation loss: 2.475710165410755

Epoch: 6| Step: 13
Training loss: 2.0127855749865717
Validation loss: 2.4851775547027115

Epoch: 165| Step: 0
Training loss: 2.0443675283577116
Validation loss: 2.466698039497517

Epoch: 6| Step: 1
Training loss: 2.4080987739075446
Validation loss: 2.492246927663838

Epoch: 6| Step: 2
Training loss: 2.83546767533439
Validation loss: 2.5092555540968218

Epoch: 6| Step: 3
Training loss: 2.6850739995608457
Validation loss: 2.5156118751447947

Epoch: 6| Step: 4
Training loss: 1.4566248922810374
Validation loss: 2.547987410568289

Epoch: 6| Step: 5
Training loss: 1.813573782291558
Validation loss: 2.559012153542802

Epoch: 6| Step: 6
Training loss: 2.0791757551566676
Validation loss: 2.6030279745584437

Epoch: 6| Step: 7
Training loss: 1.6802452403408226
Validation loss: 2.631611396668287

Epoch: 6| Step: 8
Training loss: 2.2163827652169386
Validation loss: 2.663549955927193

Epoch: 6| Step: 9
Training loss: 2.80950072689288
Validation loss: 2.696809560923652

Epoch: 6| Step: 10
Training loss: 1.672107216938296
Validation loss: 2.715861790026629

Epoch: 6| Step: 11
Training loss: 2.670917361678845
Validation loss: 2.6912444277215295

Epoch: 6| Step: 12
Training loss: 2.2169618519971084
Validation loss: 2.6638758524843413

Epoch: 6| Step: 13
Training loss: 2.16096180800794
Validation loss: 2.663670157649105

Epoch: 166| Step: 0
Training loss: 2.042821466742238
Validation loss: 2.6391996267279687

Epoch: 6| Step: 1
Training loss: 1.9353119585383574
Validation loss: 2.60896320813612

Epoch: 6| Step: 2
Training loss: 2.3187063290167145
Validation loss: 2.562454046141975

Epoch: 6| Step: 3
Training loss: 2.004272189570991
Validation loss: 2.561233055240344

Epoch: 6| Step: 4
Training loss: 2.0424116553037144
Validation loss: 2.561610204688873

Epoch: 6| Step: 5
Training loss: 1.6101621906257921
Validation loss: 2.565340745026162

Epoch: 6| Step: 6
Training loss: 2.4825459591086956
Validation loss: 2.553128166024561

Epoch: 6| Step: 7
Training loss: 2.47998234342627
Validation loss: 2.582468376944853

Epoch: 6| Step: 8
Training loss: 2.2761296328750382
Validation loss: 2.570268304637306

Epoch: 6| Step: 9
Training loss: 2.556141104395658
Validation loss: 2.5585942329507105

Epoch: 6| Step: 10
Training loss: 1.9705210394618144
Validation loss: 2.5615727377408644

Epoch: 6| Step: 11
Training loss: 2.033599902747127
Validation loss: 2.5499652409783358

Epoch: 6| Step: 12
Training loss: 2.1539163538737673
Validation loss: 2.5320784735862865

Epoch: 6| Step: 13
Training loss: 1.6226445513079957
Validation loss: 2.5487496564138934

Epoch: 167| Step: 0
Training loss: 1.9855073116247597
Validation loss: 2.5353795877578693

Epoch: 6| Step: 1
Training loss: 2.2290082382043064
Validation loss: 2.5621349215716616

Epoch: 6| Step: 2
Training loss: 2.2787702486495585
Validation loss: 2.5459620157176563

Epoch: 6| Step: 3
Training loss: 2.2618559958762945
Validation loss: 2.549545446269619

Epoch: 6| Step: 4
Training loss: 2.070435718252447
Validation loss: 2.542662338946742

Epoch: 6| Step: 5
Training loss: 1.545751144129888
Validation loss: 2.5202149015897533

Epoch: 6| Step: 6
Training loss: 2.2279142860621994
Validation loss: 2.497031239591975

Epoch: 6| Step: 7
Training loss: 2.21220388640009
Validation loss: 2.521861380724958

Epoch: 6| Step: 8
Training loss: 2.8663794602821078
Validation loss: 2.5095960865364555

Epoch: 6| Step: 9
Training loss: 2.30458735878836
Validation loss: 2.506310134938341

Epoch: 6| Step: 10
Training loss: 2.0654271479742072
Validation loss: 2.5129734496241656

Epoch: 6| Step: 11
Training loss: 1.779368829371449
Validation loss: 2.5137911133406408

Epoch: 6| Step: 12
Training loss: 1.8914966938212756
Validation loss: 2.53218001874446

Epoch: 6| Step: 13
Training loss: 1.346164574423159
Validation loss: 2.5422689980591255

Epoch: 168| Step: 0
Training loss: 1.8684120791285501
Validation loss: 2.5462946590129536

Epoch: 6| Step: 1
Training loss: 1.9185583758267764
Validation loss: 2.5483134073309928

Epoch: 6| Step: 2
Training loss: 1.7711959318040202
Validation loss: 2.552812759264652

Epoch: 6| Step: 3
Training loss: 1.7616774729695304
Validation loss: 2.550384519275689

Epoch: 6| Step: 4
Training loss: 2.691511664243223
Validation loss: 2.5657076164801986

Epoch: 6| Step: 5
Training loss: 2.057247525156062
Validation loss: 2.57064969726957

Epoch: 6| Step: 6
Training loss: 1.8950458260382608
Validation loss: 2.55637869843006

Epoch: 6| Step: 7
Training loss: 2.4277133587812183
Validation loss: 2.5661491424708314

Epoch: 6| Step: 8
Training loss: 2.0232484942795566
Validation loss: 2.557766286482468

Epoch: 6| Step: 9
Training loss: 2.1549444254283148
Validation loss: 2.5307735692057483

Epoch: 6| Step: 10
Training loss: 1.8407932431282263
Validation loss: 2.5102243899149195

Epoch: 6| Step: 11
Training loss: 2.2925469759555397
Validation loss: 2.5028815367644346

Epoch: 6| Step: 12
Training loss: 2.3361949970103946
Validation loss: 2.505062662291063

Epoch: 6| Step: 13
Training loss: 2.2100755069313562
Validation loss: 2.5263901066247563

Epoch: 169| Step: 0
Training loss: 2.3991505311628947
Validation loss: 2.5523265927779297

Epoch: 6| Step: 1
Training loss: 2.0847669881980977
Validation loss: 2.5915749557148566

Epoch: 6| Step: 2
Training loss: 1.7036258066186514
Validation loss: 2.578985710567697

Epoch: 6| Step: 3
Training loss: 2.2015894956537756
Validation loss: 2.5820005728828046

Epoch: 6| Step: 4
Training loss: 2.3600293193224364
Validation loss: 2.57771706633679

Epoch: 6| Step: 5
Training loss: 1.395668143371306
Validation loss: 2.5664812260206973

Epoch: 6| Step: 6
Training loss: 1.8224078385607343
Validation loss: 2.5710487820980283

Epoch: 6| Step: 7
Training loss: 2.694585906790861
Validation loss: 2.559798267291872

Epoch: 6| Step: 8
Training loss: 2.0496218355794995
Validation loss: 2.574881021785685

Epoch: 6| Step: 9
Training loss: 2.252284903126395
Validation loss: 2.5731289690348107

Epoch: 6| Step: 10
Training loss: 2.0115146570470563
Validation loss: 2.563933023076686

Epoch: 6| Step: 11
Training loss: 1.7698508136184306
Validation loss: 2.553912537426241

Epoch: 6| Step: 12
Training loss: 2.114302242243908
Validation loss: 2.562610332715892

Epoch: 6| Step: 13
Training loss: 2.5592545216654474
Validation loss: 2.5976997070230325

Epoch: 170| Step: 0
Training loss: 1.9811763063798888
Validation loss: 2.6039837608503342

Epoch: 6| Step: 1
Training loss: 1.2856486110716694
Validation loss: 2.582796349290181

Epoch: 6| Step: 2
Training loss: 2.0146479641298525
Validation loss: 2.5909194673444027

Epoch: 6| Step: 3
Training loss: 2.356048158454592
Validation loss: 2.5794540315824555

Epoch: 6| Step: 4
Training loss: 1.756039891283003
Validation loss: 2.557556382914408

Epoch: 6| Step: 5
Training loss: 2.1155196373536818
Validation loss: 2.539866757926861

Epoch: 6| Step: 6
Training loss: 1.7503396113427248
Validation loss: 2.5166968979948763

Epoch: 6| Step: 7
Training loss: 2.388656503872763
Validation loss: 2.5232932152595158

Epoch: 6| Step: 8
Training loss: 2.664783458536527
Validation loss: 2.529684293774394

Epoch: 6| Step: 9
Training loss: 1.5622136425830597
Validation loss: 2.537351264920686

Epoch: 6| Step: 10
Training loss: 1.8770281948355927
Validation loss: 2.550804251272671

Epoch: 6| Step: 11
Training loss: 2.5860448163862895
Validation loss: 2.5431064163748496

Epoch: 6| Step: 12
Training loss: 2.1330692569883056
Validation loss: 2.5536289636818705

Epoch: 6| Step: 13
Training loss: 1.5174682263185455
Validation loss: 2.5518531506324655

Epoch: 171| Step: 0
Training loss: 2.5475740000091185
Validation loss: 2.550579041735773

Epoch: 6| Step: 1
Training loss: 1.1395877668351448
Validation loss: 2.5476219611384887

Epoch: 6| Step: 2
Training loss: 2.1051575496185126
Validation loss: 2.5641542527995345

Epoch: 6| Step: 3
Training loss: 2.1968630273527996
Validation loss: 2.5551253647847343

Epoch: 6| Step: 4
Training loss: 1.5071412801250041
Validation loss: 2.579814279143232

Epoch: 6| Step: 5
Training loss: 2.1502280801845104
Validation loss: 2.5897349581591276

Epoch: 6| Step: 6
Training loss: 1.597511639380998
Validation loss: 2.5906968920309437

Epoch: 6| Step: 7
Training loss: 1.8842003483596932
Validation loss: 2.6057678937462487

Epoch: 6| Step: 8
Training loss: 2.325978153339367
Validation loss: 2.60044819287366

Epoch: 6| Step: 9
Training loss: 1.8450539713876595
Validation loss: 2.607183998363979

Epoch: 6| Step: 10
Training loss: 1.770301768985018
Validation loss: 2.595626280908474

Epoch: 6| Step: 11
Training loss: 2.472337843897487
Validation loss: 2.5882460225887387

Epoch: 6| Step: 12
Training loss: 1.9264098219073007
Validation loss: 2.571384356426711

Epoch: 6| Step: 13
Training loss: 1.7875945219644402
Validation loss: 2.5481268884058923

Epoch: 172| Step: 0
Training loss: 2.054566818580432
Validation loss: 2.54526779242405

Epoch: 6| Step: 1
Training loss: 2.1104284975925927
Validation loss: 2.5613944337156807

Epoch: 6| Step: 2
Training loss: 2.045409748280426
Validation loss: 2.556464058806373

Epoch: 6| Step: 3
Training loss: 1.3130844722196615
Validation loss: 2.5689748602296536

Epoch: 6| Step: 4
Training loss: 2.099722357970287
Validation loss: 2.57435551801848

Epoch: 6| Step: 5
Training loss: 1.486044657440506
Validation loss: 2.5792346792371568

Epoch: 6| Step: 6
Training loss: 2.9039967323474
Validation loss: 2.5625215304891067

Epoch: 6| Step: 7
Training loss: 2.3398806357302355
Validation loss: 2.58388117833883

Epoch: 6| Step: 8
Training loss: 2.1758463385826525
Validation loss: 2.5901624764659936

Epoch: 6| Step: 9
Training loss: 1.743217266563765
Validation loss: 2.6004664181390114

Epoch: 6| Step: 10
Training loss: 1.856996377209081
Validation loss: 2.5928450783834616

Epoch: 6| Step: 11
Training loss: 1.7199279909807084
Validation loss: 2.584606451048556

Epoch: 6| Step: 12
Training loss: 2.1609434931762292
Validation loss: 2.580781532409383

Epoch: 6| Step: 13
Training loss: 0.6896412190308292
Validation loss: 2.580825994741802

Epoch: 173| Step: 0
Training loss: 2.3864815901632235
Validation loss: 2.578246680129303

Epoch: 6| Step: 1
Training loss: 1.8055313581491765
Validation loss: 2.5941866880081546

Epoch: 6| Step: 2
Training loss: 1.6534637911661416
Validation loss: 2.6192448984738013

Epoch: 6| Step: 3
Training loss: 1.8265113555822539
Validation loss: 2.6027925635644276

Epoch: 6| Step: 4
Training loss: 2.2194159139752383
Validation loss: 2.6053314376970302

Epoch: 6| Step: 5
Training loss: 1.6739221321690654
Validation loss: 2.5822613837756188

Epoch: 6| Step: 6
Training loss: 1.91198013071486
Validation loss: 2.5868394477868315

Epoch: 6| Step: 7
Training loss: 1.7739714100285362
Validation loss: 2.5847828721812367

Epoch: 6| Step: 8
Training loss: 2.0249051107144407
Validation loss: 2.5776549426924147

Epoch: 6| Step: 9
Training loss: 2.0594832581471447
Validation loss: 2.569685906133361

Epoch: 6| Step: 10
Training loss: 2.744295185121279
Validation loss: 2.582126790844847

Epoch: 6| Step: 11
Training loss: 1.5763418869353298
Validation loss: 2.5418747067518694

Epoch: 6| Step: 12
Training loss: 1.8683868131830057
Validation loss: 2.554896310736687

Epoch: 6| Step: 13
Training loss: 1.6972154756957534
Validation loss: 2.5456777657990455

Epoch: 174| Step: 0
Training loss: 1.8704272140213476
Validation loss: 2.5159285126653423

Epoch: 6| Step: 1
Training loss: 2.121904699373338
Validation loss: 2.5080647569628627

Epoch: 6| Step: 2
Training loss: 2.030634977692489
Validation loss: 2.5050850313150668

Epoch: 6| Step: 3
Training loss: 1.8333492133868874
Validation loss: 2.5081375274856823

Epoch: 6| Step: 4
Training loss: 2.153496684422364
Validation loss: 2.5178901345816858

Epoch: 6| Step: 5
Training loss: 1.613618090473606
Validation loss: 2.472322345897031

Epoch: 6| Step: 6
Training loss: 1.7475452918212313
Validation loss: 2.491360801168761

Epoch: 6| Step: 7
Training loss: 2.2081679396202296
Validation loss: 2.5033630044914297

Epoch: 6| Step: 8
Training loss: 1.4528977411231971
Validation loss: 2.5031128054749603

Epoch: 6| Step: 9
Training loss: 2.0644542798749135
Validation loss: 2.5068021976769153

Epoch: 6| Step: 10
Training loss: 2.3619011498422147
Validation loss: 2.5449432872549855

Epoch: 6| Step: 11
Training loss: 2.1221336780116076
Validation loss: 2.6119854966378937

Epoch: 6| Step: 12
Training loss: 1.897419974709027
Validation loss: 2.672387594521693

Epoch: 6| Step: 13
Training loss: 1.9943451809185582
Validation loss: 2.7035449202900925

Epoch: 175| Step: 0
Training loss: 2.1556919868570525
Validation loss: 2.6689584565580327

Epoch: 6| Step: 1
Training loss: 2.2961237710428946
Validation loss: 2.6536071214836316

Epoch: 6| Step: 2
Training loss: 2.3856839248219894
Validation loss: 2.5922063955629198

Epoch: 6| Step: 3
Training loss: 1.7653107490064919
Validation loss: 2.5521933844325115

Epoch: 6| Step: 4
Training loss: 2.0021760546608838
Validation loss: 2.4996769347692918

Epoch: 6| Step: 5
Training loss: 2.311711151017736
Validation loss: 2.490245870120923

Epoch: 6| Step: 6
Training loss: 2.1452245373345598
Validation loss: 2.4953030044599274

Epoch: 6| Step: 7
Training loss: 2.2269596214179606
Validation loss: 2.484362998908134

Epoch: 6| Step: 8
Training loss: 1.9821891460144243
Validation loss: 2.471175563380296

Epoch: 6| Step: 9
Training loss: 2.2948943440835334
Validation loss: 2.49016444366019

Epoch: 6| Step: 10
Training loss: 1.6351743708962918
Validation loss: 2.4932930039634105

Epoch: 6| Step: 11
Training loss: 1.6215475527283427
Validation loss: 2.537631405371409

Epoch: 6| Step: 12
Training loss: 1.9959330932702326
Validation loss: 2.5439126035025

Epoch: 6| Step: 13
Training loss: 1.08260421180829
Validation loss: 2.564385713478298

Epoch: 176| Step: 0
Training loss: 2.40948081173829
Validation loss: 2.591598604915855

Epoch: 6| Step: 1
Training loss: 2.0169997147809093
Validation loss: 2.6096421954122295

Epoch: 6| Step: 2
Training loss: 1.609739762237075
Validation loss: 2.607612040348785

Epoch: 6| Step: 3
Training loss: 2.427938635313031
Validation loss: 2.6327620331929995

Epoch: 6| Step: 4
Training loss: 1.7100532371755592
Validation loss: 2.6033089079526475

Epoch: 6| Step: 5
Training loss: 2.142454827098398
Validation loss: 2.575425655962492

Epoch: 6| Step: 6
Training loss: 1.7680384252610186
Validation loss: 2.560917876874023

Epoch: 6| Step: 7
Training loss: 1.6189495567535828
Validation loss: 2.5456578531984713

Epoch: 6| Step: 8
Training loss: 1.3885740951257945
Validation loss: 2.535251518752561

Epoch: 6| Step: 9
Training loss: 2.383402966991517
Validation loss: 2.5453646336268054

Epoch: 6| Step: 10
Training loss: 1.4508481800620476
Validation loss: 2.5419025832787594

Epoch: 6| Step: 11
Training loss: 1.4026623632249582
Validation loss: 2.5362567129558617

Epoch: 6| Step: 12
Training loss: 2.6531643167015604
Validation loss: 2.5368163598242313

Epoch: 6| Step: 13
Training loss: 1.8467199683272115
Validation loss: 2.5363034674447973

Epoch: 177| Step: 0
Training loss: 1.5593380787975508
Validation loss: 2.56322184754442

Epoch: 6| Step: 1
Training loss: 1.8852395524212375
Validation loss: 2.5817942551593216

Epoch: 6| Step: 2
Training loss: 1.6697885203515306
Validation loss: 2.6047630775614166

Epoch: 6| Step: 3
Training loss: 1.6819712881978395
Validation loss: 2.6146610942814936

Epoch: 6| Step: 4
Training loss: 2.066250483333395
Validation loss: 2.594012547990706

Epoch: 6| Step: 5
Training loss: 2.0621631231599977
Validation loss: 2.5676237524748338

Epoch: 6| Step: 6
Training loss: 1.995841769981737
Validation loss: 2.537592374085201

Epoch: 6| Step: 7
Training loss: 2.063634849214743
Validation loss: 2.5203821044002934

Epoch: 6| Step: 8
Training loss: 2.3809320753230754
Validation loss: 2.5057381994914656

Epoch: 6| Step: 9
Training loss: 1.4818874999266864
Validation loss: 2.5105962398453596

Epoch: 6| Step: 10
Training loss: 1.9554966069979434
Validation loss: 2.4968770938909532

Epoch: 6| Step: 11
Training loss: 1.6194463609161
Validation loss: 2.514019668363021

Epoch: 6| Step: 12
Training loss: 2.1100590479755783
Validation loss: 2.5104710892953235

Epoch: 6| Step: 13
Training loss: 1.4514189518801774
Validation loss: 2.5151559276084074

Epoch: 178| Step: 0
Training loss: 1.844283463195055
Validation loss: 2.504623979565693

Epoch: 6| Step: 1
Training loss: 2.0534677112048034
Validation loss: 2.5367810167738116

Epoch: 6| Step: 2
Training loss: 1.91982165799765
Validation loss: 2.5428030989227075

Epoch: 6| Step: 3
Training loss: 1.7314732652054834
Validation loss: 2.5726529087879406

Epoch: 6| Step: 4
Training loss: 2.049696048440161
Validation loss: 2.5465633252711535

Epoch: 6| Step: 5
Training loss: 1.4161043547092544
Validation loss: 2.521766586119348

Epoch: 6| Step: 6
Training loss: 1.5079612856178102
Validation loss: 2.488737459906049

Epoch: 6| Step: 7
Training loss: 2.1562106363877533
Validation loss: 2.487409081861054

Epoch: 6| Step: 8
Training loss: 1.9357072473135617
Validation loss: 2.4840174550754353

Epoch: 6| Step: 9
Training loss: 1.845524467419755
Validation loss: 2.479658005412726

Epoch: 6| Step: 10
Training loss: 1.6643721601323744
Validation loss: 2.470405812541098

Epoch: 6| Step: 11
Training loss: 2.171203070239354
Validation loss: 2.480407479475551

Epoch: 6| Step: 12
Training loss: 2.047224873932574
Validation loss: 2.483046920897283

Epoch: 6| Step: 13
Training loss: 1.578025210407618
Validation loss: 2.500125352731677

Epoch: 179| Step: 0
Training loss: 2.1440727146685425
Validation loss: 2.520056243151001

Epoch: 6| Step: 1
Training loss: 1.9499702304621782
Validation loss: 2.5430309951574244

Epoch: 6| Step: 2
Training loss: 2.455276226345266
Validation loss: 2.6071481765462585

Epoch: 6| Step: 3
Training loss: 1.1896414271041496
Validation loss: 2.630457053318444

Epoch: 6| Step: 4
Training loss: 2.149579885378598
Validation loss: 2.6343612032734995

Epoch: 6| Step: 5
Training loss: 2.2887827210767115
Validation loss: 2.624274526177698

Epoch: 6| Step: 6
Training loss: 1.2566682337608652
Validation loss: 2.574073218363066

Epoch: 6| Step: 7
Training loss: 1.9953053927612385
Validation loss: 2.5481465915628765

Epoch: 6| Step: 8
Training loss: 1.4539228320521347
Validation loss: 2.5298448068021746

Epoch: 6| Step: 9
Training loss: 1.7645804767367839
Validation loss: 2.4875531652265

Epoch: 6| Step: 10
Training loss: 2.0307739873810395
Validation loss: 2.4763901179744927

Epoch: 6| Step: 11
Training loss: 1.9254336401262722
Validation loss: 2.474957694430307

Epoch: 6| Step: 12
Training loss: 2.0542934025272515
Validation loss: 2.499794348595195

Epoch: 6| Step: 13
Training loss: 1.5794176907009807
Validation loss: 2.5088561060857635

Epoch: 180| Step: 0
Training loss: 1.429962882113736
Validation loss: 2.528620456131293

Epoch: 6| Step: 1
Training loss: 1.3581684063129345
Validation loss: 2.5471760189237327

Epoch: 6| Step: 2
Training loss: 2.199094182716326
Validation loss: 2.5788121445986976

Epoch: 6| Step: 3
Training loss: 1.6252527040448217
Validation loss: 2.5695530958704933

Epoch: 6| Step: 4
Training loss: 2.1415788516237657
Validation loss: 2.5850820335547873

Epoch: 6| Step: 5
Training loss: 1.7992472372644714
Validation loss: 2.578728453512687

Epoch: 6| Step: 6
Training loss: 1.4940069001637228
Validation loss: 2.5702312601391974

Epoch: 6| Step: 7
Training loss: 1.805329972219414
Validation loss: 2.5859098949420605

Epoch: 6| Step: 8
Training loss: 1.6920366411953687
Validation loss: 2.5605504973688578

Epoch: 6| Step: 9
Training loss: 2.207372372351835
Validation loss: 2.5745816240245465

Epoch: 6| Step: 10
Training loss: 1.784920908567466
Validation loss: 2.6022065147188385

Epoch: 6| Step: 11
Training loss: 1.565421006243474
Validation loss: 2.607414711329438

Epoch: 6| Step: 12
Training loss: 2.2692352994900955
Validation loss: 2.601754764772945

Epoch: 6| Step: 13
Training loss: 2.4100152813755398
Validation loss: 2.565403459669085

Epoch: 181| Step: 0
Training loss: 1.9250674520787838
Validation loss: 2.5078020059507016

Epoch: 6| Step: 1
Training loss: 2.029314850625691
Validation loss: 2.4782025648040955

Epoch: 6| Step: 2
Training loss: 1.0655370950099696
Validation loss: 2.4810310323977562

Epoch: 6| Step: 3
Training loss: 1.4669559153802365
Validation loss: 2.463936326359173

Epoch: 6| Step: 4
Training loss: 1.5601104775458812
Validation loss: 2.48538633825447

Epoch: 6| Step: 5
Training loss: 2.188266837723927
Validation loss: 2.4573848876859024

Epoch: 6| Step: 6
Training loss: 1.6338771287858842
Validation loss: 2.4565988584681815

Epoch: 6| Step: 7
Training loss: 1.612582076002106
Validation loss: 2.4330251240063347

Epoch: 6| Step: 8
Training loss: 1.8402192528333505
Validation loss: 2.416458514127939

Epoch: 6| Step: 9
Training loss: 1.8287550011838267
Validation loss: 2.4242006840729564

Epoch: 6| Step: 10
Training loss: 1.8556429811289363
Validation loss: 2.4219171865059246

Epoch: 6| Step: 11
Training loss: 2.5223253946960362
Validation loss: 2.4279294089124495

Epoch: 6| Step: 12
Training loss: 1.663437846970437
Validation loss: 2.4525108407257545

Epoch: 6| Step: 13
Training loss: 1.9849111478507193
Validation loss: 2.4700819674452243

Epoch: 182| Step: 0
Training loss: 1.9437345056437558
Validation loss: 2.5187277584019627

Epoch: 6| Step: 1
Training loss: 2.056205855710252
Validation loss: 2.587928724327734

Epoch: 6| Step: 2
Training loss: 2.1919724655997643
Validation loss: 2.606909838305166

Epoch: 6| Step: 3
Training loss: 1.635128003863849
Validation loss: 2.6092829583356747

Epoch: 6| Step: 4
Training loss: 1.6113446968844793
Validation loss: 2.5614326939529017

Epoch: 6| Step: 5
Training loss: 1.5740123831226713
Validation loss: 2.5249441222095075

Epoch: 6| Step: 6
Training loss: 1.4673545376691142
Validation loss: 2.5199515674245085

Epoch: 6| Step: 7
Training loss: 1.7251111312672491
Validation loss: 2.5010992801996808

Epoch: 6| Step: 8
Training loss: 1.6058649098740057
Validation loss: 2.466160453632377

Epoch: 6| Step: 9
Training loss: 1.7787077312580908
Validation loss: 2.428349297640409

Epoch: 6| Step: 10
Training loss: 2.0199763916071265
Validation loss: 2.4433506590489364

Epoch: 6| Step: 11
Training loss: 1.7771219974558732
Validation loss: 2.4522642056174364

Epoch: 6| Step: 12
Training loss: 1.7281237141775139
Validation loss: 2.4665609540240054

Epoch: 6| Step: 13
Training loss: 2.5754153722161055
Validation loss: 2.463104102696378

Epoch: 183| Step: 0
Training loss: 2.44706151648466
Validation loss: 2.4784720942017584

Epoch: 6| Step: 1
Training loss: 2.0390974604507144
Validation loss: 2.489770295735335

Epoch: 6| Step: 2
Training loss: 1.4899647720063949
Validation loss: 2.5497778012541614

Epoch: 6| Step: 3
Training loss: 2.258304740283692
Validation loss: 2.554980837656166

Epoch: 6| Step: 4
Training loss: 1.5698401656460632
Validation loss: 2.546799638041988

Epoch: 6| Step: 5
Training loss: 1.683910225067728
Validation loss: 2.5596952428093243

Epoch: 6| Step: 6
Training loss: 1.5328160277159806
Validation loss: 2.541533173300409

Epoch: 6| Step: 7
Training loss: 2.045110276660203
Validation loss: 2.5400219165927775

Epoch: 6| Step: 8
Training loss: 1.982827852518874
Validation loss: 2.552181078956168

Epoch: 6| Step: 9
Training loss: 1.424818994503863
Validation loss: 2.5500191831580987

Epoch: 6| Step: 10
Training loss: 1.3941838021297959
Validation loss: 2.5448550909979164

Epoch: 6| Step: 11
Training loss: 1.61590407302091
Validation loss: 2.553157243093144

Epoch: 6| Step: 12
Training loss: 1.5475403096706535
Validation loss: 2.555087022140841

Epoch: 6| Step: 13
Training loss: 1.708082141861971
Validation loss: 2.5371650000634287

Epoch: 184| Step: 0
Training loss: 1.6388170725861695
Validation loss: 2.559580842196501

Epoch: 6| Step: 1
Training loss: 2.4547374309898276
Validation loss: 2.580615014366728

Epoch: 6| Step: 2
Training loss: 1.4704458307991823
Validation loss: 2.606668917257353

Epoch: 6| Step: 3
Training loss: 2.203429938241018
Validation loss: 2.6339998024010973

Epoch: 6| Step: 4
Training loss: 1.712750454151036
Validation loss: 2.6085327200854005

Epoch: 6| Step: 5
Training loss: 1.75369050667984
Validation loss: 2.5654815228023837

Epoch: 6| Step: 6
Training loss: 1.2368437789978288
Validation loss: 2.5108862092147235

Epoch: 6| Step: 7
Training loss: 1.7030211950742693
Validation loss: 2.4605964607942243

Epoch: 6| Step: 8
Training loss: 1.7903813993646829
Validation loss: 2.460597177605993

Epoch: 6| Step: 9
Training loss: 1.7011617841979714
Validation loss: 2.4560661922849087

Epoch: 6| Step: 10
Training loss: 2.094626627496692
Validation loss: 2.4530840273899077

Epoch: 6| Step: 11
Training loss: 2.1622765398058426
Validation loss: 2.4552765907484666

Epoch: 6| Step: 12
Training loss: 1.4239281722555537
Validation loss: 2.471571428842792

Epoch: 6| Step: 13
Training loss: 1.6314583597811214
Validation loss: 2.4610648355845104

Epoch: 185| Step: 0
Training loss: 1.559621677496342
Validation loss: 2.484544734428388

Epoch: 6| Step: 1
Training loss: 1.5261088889183403
Validation loss: 2.5159309377985455

Epoch: 6| Step: 2
Training loss: 0.7975132573978004
Validation loss: 2.540513881844702

Epoch: 6| Step: 3
Training loss: 1.4592035785118778
Validation loss: 2.5666769137242547

Epoch: 6| Step: 4
Training loss: 2.0345733452131927
Validation loss: 2.569939369915579

Epoch: 6| Step: 5
Training loss: 1.1874780150938276
Validation loss: 2.5703504928422554

Epoch: 6| Step: 6
Training loss: 1.8397005515448017
Validation loss: 2.5599930538367177

Epoch: 6| Step: 7
Training loss: 1.0254867653962227
Validation loss: 2.5494806421500984

Epoch: 6| Step: 8
Training loss: 1.8457041583991816
Validation loss: 2.53633965861082

Epoch: 6| Step: 9
Training loss: 1.8217492716151613
Validation loss: 2.5368012860577838

Epoch: 6| Step: 10
Training loss: 2.7732714106298
Validation loss: 2.522490245099749

Epoch: 6| Step: 11
Training loss: 2.054626696016907
Validation loss: 2.5307533580091293

Epoch: 6| Step: 12
Training loss: 2.270086696498427
Validation loss: 2.5396291630851726

Epoch: 6| Step: 13
Training loss: 1.5842377522329076
Validation loss: 2.529126282991732

Epoch: 186| Step: 0
Training loss: 1.3904507988678585
Validation loss: 2.533131218259508

Epoch: 6| Step: 1
Training loss: 1.7886215399486654
Validation loss: 2.5342264039321134

Epoch: 6| Step: 2
Training loss: 1.5256649850046098
Validation loss: 2.5444840245866427

Epoch: 6| Step: 3
Training loss: 1.7192149833784243
Validation loss: 2.5243362628984563

Epoch: 6| Step: 4
Training loss: 1.68398384832216
Validation loss: 2.5091196902812136

Epoch: 6| Step: 5
Training loss: 1.5175869228348586
Validation loss: 2.5024961366908722

Epoch: 6| Step: 6
Training loss: 1.841780305466294
Validation loss: 2.479282717333779

Epoch: 6| Step: 7
Training loss: 1.8464518002484844
Validation loss: 2.4921480666196394

Epoch: 6| Step: 8
Training loss: 1.999810686688311
Validation loss: 2.4918050931327262

Epoch: 6| Step: 9
Training loss: 1.5773337618477101
Validation loss: 2.5172953913597422

Epoch: 6| Step: 10
Training loss: 1.4393073620228054
Validation loss: 2.504216781771853

Epoch: 6| Step: 11
Training loss: 2.014488195351113
Validation loss: 2.5117761866312467

Epoch: 6| Step: 12
Training loss: 2.1009121140151077
Validation loss: 2.509159423479226

Epoch: 6| Step: 13
Training loss: 1.3998143754243029
Validation loss: 2.5035037540022524

Epoch: 187| Step: 0
Training loss: 1.732545867576976
Validation loss: 2.505822374794539

Epoch: 6| Step: 1
Training loss: 1.6206445278369683
Validation loss: 2.5061815133571366

Epoch: 6| Step: 2
Training loss: 1.766800615642804
Validation loss: 2.4917751879889747

Epoch: 6| Step: 3
Training loss: 1.098031356631298
Validation loss: 2.4993118420866534

Epoch: 6| Step: 4
Training loss: 1.8179295213087334
Validation loss: 2.490420341134943

Epoch: 6| Step: 5
Training loss: 1.748396002146615
Validation loss: 2.5160363697330648

Epoch: 6| Step: 6
Training loss: 1.6532914710641489
Validation loss: 2.487259893299338

Epoch: 6| Step: 7
Training loss: 1.5574379366392597
Validation loss: 2.4988301113777065

Epoch: 6| Step: 8
Training loss: 1.51519029813317
Validation loss: 2.48459416296864

Epoch: 6| Step: 9
Training loss: 2.0321682541716224
Validation loss: 2.4846311057854167

Epoch: 6| Step: 10
Training loss: 2.060453150638015
Validation loss: 2.4977807500677742

Epoch: 6| Step: 11
Training loss: 1.6868215539301918
Validation loss: 2.5216398631163814

Epoch: 6| Step: 12
Training loss: 1.4268269088066365
Validation loss: 2.532318652286244

Epoch: 6| Step: 13
Training loss: 1.7779696190494418
Validation loss: 2.5837472884346617

Epoch: 188| Step: 0
Training loss: 1.9586782016509707
Validation loss: 2.574881921839206

Epoch: 6| Step: 1
Training loss: 1.3589571606618658
Validation loss: 2.557176247561333

Epoch: 6| Step: 2
Training loss: 1.2857830524976637
Validation loss: 2.5643582313182103

Epoch: 6| Step: 3
Training loss: 1.388814712239052
Validation loss: 2.575682136097056

Epoch: 6| Step: 4
Training loss: 1.536010970165894
Validation loss: 2.540097275766231

Epoch: 6| Step: 5
Training loss: 1.8931945489781978
Validation loss: 2.5203122120940806

Epoch: 6| Step: 6
Training loss: 2.3038460957463593
Validation loss: 2.5228241144784382

Epoch: 6| Step: 7
Training loss: 1.1484987411259622
Validation loss: 2.533320086994524

Epoch: 6| Step: 8
Training loss: 1.2447369402529587
Validation loss: 2.5324685979028683

Epoch: 6| Step: 9
Training loss: 1.5403025322543427
Validation loss: 2.5344923029664446

Epoch: 6| Step: 10
Training loss: 1.7417801864108564
Validation loss: 2.5350536459218658

Epoch: 6| Step: 11
Training loss: 2.1236822867193523
Validation loss: 2.5604095876478334

Epoch: 6| Step: 12
Training loss: 1.3874376609475998
Validation loss: 2.5309838980919643

Epoch: 6| Step: 13
Training loss: 1.7112332441179772
Validation loss: 2.531427525825441

Epoch: 189| Step: 0
Training loss: 1.4082827816680499
Validation loss: 2.510271490882201

Epoch: 6| Step: 1
Training loss: 1.0686720367906717
Validation loss: 2.4907142964576594

Epoch: 6| Step: 2
Training loss: 1.1516984587576669
Validation loss: 2.493909087077044

Epoch: 6| Step: 3
Training loss: 2.159627287462342
Validation loss: 2.487116220197599

Epoch: 6| Step: 4
Training loss: 1.6909983365520505
Validation loss: 2.514350576962287

Epoch: 6| Step: 5
Training loss: 1.6617988628092029
Validation loss: 2.4979715013689803

Epoch: 6| Step: 6
Training loss: 1.4573794196945484
Validation loss: 2.516459082235258

Epoch: 6| Step: 7
Training loss: 1.483186587386405
Validation loss: 2.520107620094358

Epoch: 6| Step: 8
Training loss: 1.9046069709458786
Validation loss: 2.5354443751420424

Epoch: 6| Step: 9
Training loss: 1.951677258845817
Validation loss: 2.5503339553200854

Epoch: 6| Step: 10
Training loss: 2.191348804394118
Validation loss: 2.5367159269928417

Epoch: 6| Step: 11
Training loss: 1.4573714035648109
Validation loss: 2.5574286816622496

Epoch: 6| Step: 12
Training loss: 1.3827819820851182
Validation loss: 2.570446081873479

Epoch: 6| Step: 13
Training loss: 1.5790224450649974
Validation loss: 2.5535605244958304

Epoch: 190| Step: 0
Training loss: 1.5896693328485243
Validation loss: 2.5294633051762485

Epoch: 6| Step: 1
Training loss: 1.4680442737846398
Validation loss: 2.504765955511914

Epoch: 6| Step: 2
Training loss: 1.0251821542172697
Validation loss: 2.477951907429102

Epoch: 6| Step: 3
Training loss: 1.8226015163661877
Validation loss: 2.4813626488079423

Epoch: 6| Step: 4
Training loss: 1.484342233396573
Validation loss: 2.4728359575779493

Epoch: 6| Step: 5
Training loss: 1.0476802177446916
Validation loss: 2.480021375859403

Epoch: 6| Step: 6
Training loss: 1.7916306632512733
Validation loss: 2.515022921691272

Epoch: 6| Step: 7
Training loss: 2.225243857232643
Validation loss: 2.4993989268025563

Epoch: 6| Step: 8
Training loss: 1.7009823120875025
Validation loss: 2.516091034215521

Epoch: 6| Step: 9
Training loss: 1.5964703997249294
Validation loss: 2.495607790874644

Epoch: 6| Step: 10
Training loss: 1.9846646555560532
Validation loss: 2.5277116301758973

Epoch: 6| Step: 11
Training loss: 1.494607770110476
Validation loss: 2.5087162556940616

Epoch: 6| Step: 12
Training loss: 1.5760963922930198
Validation loss: 2.4997532835605645

Epoch: 6| Step: 13
Training loss: 1.291722691254113
Validation loss: 2.515345019830669

Epoch: 191| Step: 0
Training loss: 1.6561020119247991
Validation loss: 2.5117431868066755

Epoch: 6| Step: 1
Training loss: 1.30358794700175
Validation loss: 2.5127000322885005

Epoch: 6| Step: 2
Training loss: 1.2325344608588393
Validation loss: 2.468307395731423

Epoch: 6| Step: 3
Training loss: 1.4837437944033396
Validation loss: 2.4769390070123753

Epoch: 6| Step: 4
Training loss: 1.236306381637023
Validation loss: 2.4787475329531166

Epoch: 6| Step: 5
Training loss: 1.8871088039402857
Validation loss: 2.4832890007844806

Epoch: 6| Step: 6
Training loss: 1.6196426699228639
Validation loss: 2.4923140582759924

Epoch: 6| Step: 7
Training loss: 1.5301654633951949
Validation loss: 2.498239514674863

Epoch: 6| Step: 8
Training loss: 1.381861214019042
Validation loss: 2.493864329778699

Epoch: 6| Step: 9
Training loss: 1.8021748543433407
Validation loss: 2.516961813265237

Epoch: 6| Step: 10
Training loss: 1.8580565065346721
Validation loss: 2.5254027326194155

Epoch: 6| Step: 11
Training loss: 1.6130367952845635
Validation loss: 2.5360201167999326

Epoch: 6| Step: 12
Training loss: 1.2932749037145037
Validation loss: 2.5674637231169983

Epoch: 6| Step: 13
Training loss: 2.390925270122082
Validation loss: 2.5561628338697577

Epoch: 192| Step: 0
Training loss: 1.6609345889133267
Validation loss: 2.6186390685799625

Epoch: 6| Step: 1
Training loss: 1.5606223459339603
Validation loss: 2.649900154899778

Epoch: 6| Step: 2
Training loss: 2.1332413797627954
Validation loss: 2.659929652884863

Epoch: 6| Step: 3
Training loss: 1.6734215544182236
Validation loss: 2.6325060171655266

Epoch: 6| Step: 4
Training loss: 1.2551028047682427
Validation loss: 2.5521652074609404

Epoch: 6| Step: 5
Training loss: 1.9065084438542166
Validation loss: 2.526976691789097

Epoch: 6| Step: 6
Training loss: 1.7281433739125147
Validation loss: 2.4986472217846587

Epoch: 6| Step: 7
Training loss: 1.7344866879904384
Validation loss: 2.5011290113338633

Epoch: 6| Step: 8
Training loss: 1.339140549013169
Validation loss: 2.4840679890950805

Epoch: 6| Step: 9
Training loss: 1.1480938663321147
Validation loss: 2.482761802721837

Epoch: 6| Step: 10
Training loss: 1.5414930795767248
Validation loss: 2.4729481914686633

Epoch: 6| Step: 11
Training loss: 1.9721550333043225
Validation loss: 2.4796037634184978

Epoch: 6| Step: 12
Training loss: 1.6975517426864786
Validation loss: 2.5404450499843803

Epoch: 6| Step: 13
Training loss: 1.5432711148061984
Validation loss: 2.590779782874071

Epoch: 193| Step: 0
Training loss: 1.9282908462595976
Validation loss: 2.597229096096821

Epoch: 6| Step: 1
Training loss: 1.4875531355399334
Validation loss: 2.5952750376851905

Epoch: 6| Step: 2
Training loss: 2.1116577229941433
Validation loss: 2.583861286809936

Epoch: 6| Step: 3
Training loss: 1.351030763313965
Validation loss: 2.508536244753563

Epoch: 6| Step: 4
Training loss: 1.8845966164509267
Validation loss: 2.4857555033181207

Epoch: 6| Step: 5
Training loss: 1.6499583383560164
Validation loss: 2.4505122248036653

Epoch: 6| Step: 6
Training loss: 1.3216594168539149
Validation loss: 2.44267433885026

Epoch: 6| Step: 7
Training loss: 1.3268002803569885
Validation loss: 2.433576389276432

Epoch: 6| Step: 8
Training loss: 1.5991172918609386
Validation loss: 2.4464062344086113

Epoch: 6| Step: 9
Training loss: 1.1953604694788924
Validation loss: 2.443145162602311

Epoch: 6| Step: 10
Training loss: 1.491849451569451
Validation loss: 2.465828246212817

Epoch: 6| Step: 11
Training loss: 1.7525650027595852
Validation loss: 2.4771529692275793

Epoch: 6| Step: 12
Training loss: 1.1296135293847374
Validation loss: 2.5147327473078134

Epoch: 6| Step: 13
Training loss: 2.188575044498779
Validation loss: 2.5687393334763113

Epoch: 194| Step: 0
Training loss: 1.144456255542172
Validation loss: 2.606106805151789

Epoch: 6| Step: 1
Training loss: 2.0738365266579084
Validation loss: 2.6034184230411976

Epoch: 6| Step: 2
Training loss: 1.6917697436619643
Validation loss: 2.5992928809810576

Epoch: 6| Step: 3
Training loss: 1.711175283691511
Validation loss: 2.5871028695060145

Epoch: 6| Step: 4
Training loss: 1.5145407662407047
Validation loss: 2.5546081948117303

Epoch: 6| Step: 5
Training loss: 1.3878425450241294
Validation loss: 2.5526362220580006

Epoch: 6| Step: 6
Training loss: 1.5956666678439342
Validation loss: 2.509931961164983

Epoch: 6| Step: 7
Training loss: 1.7514809745171254
Validation loss: 2.5182813376076716

Epoch: 6| Step: 8
Training loss: 1.5289385730287581
Validation loss: 2.492575358965774

Epoch: 6| Step: 9
Training loss: 1.8897078630433077
Validation loss: 2.4895325882635984

Epoch: 6| Step: 10
Training loss: 1.6951203830696346
Validation loss: 2.5137780926220894

Epoch: 6| Step: 11
Training loss: 1.513258984765782
Validation loss: 2.5335216752825507

Epoch: 6| Step: 12
Training loss: 1.3068636260593545
Validation loss: 2.5614465838780043

Epoch: 6| Step: 13
Training loss: 1.5088924039245124
Validation loss: 2.5780314906151554

Epoch: 195| Step: 0
Training loss: 1.7456449405502334
Validation loss: 2.6651284379197056

Epoch: 6| Step: 1
Training loss: 1.8672644308035398
Validation loss: 2.692037972646303

Epoch: 6| Step: 2
Training loss: 2.0576843917003327
Validation loss: 2.6960948814996635

Epoch: 6| Step: 3
Training loss: 1.4138318289930483
Validation loss: 2.6061132789072134

Epoch: 6| Step: 4
Training loss: 1.4860377585746831
Validation loss: 2.4856109434149696

Epoch: 6| Step: 5
Training loss: 1.7231630025442755
Validation loss: 2.4594177939524497

Epoch: 6| Step: 6
Training loss: 1.5644333132133499
Validation loss: 2.453444496209898

Epoch: 6| Step: 7
Training loss: 1.4549593268933048
Validation loss: 2.433513044760782

Epoch: 6| Step: 8
Training loss: 2.055513977225961
Validation loss: 2.4500405932494247

Epoch: 6| Step: 9
Training loss: 1.7454132187621751
Validation loss: 2.446555557555797

Epoch: 6| Step: 10
Training loss: 2.053715813341216
Validation loss: 2.418444487334709

Epoch: 6| Step: 11
Training loss: 1.0322830343543126
Validation loss: 2.4766244712014984

Epoch: 6| Step: 12
Training loss: 1.7277806330402055
Validation loss: 2.5179739983350005

Epoch: 6| Step: 13
Training loss: 1.4708871916220854
Validation loss: 2.562078466291927

Epoch: 196| Step: 0
Training loss: 1.7677264915287487
Validation loss: 2.566709003517489

Epoch: 6| Step: 1
Training loss: 1.2375669615382743
Validation loss: 2.5903873165498768

Epoch: 6| Step: 2
Training loss: 2.056426034366555
Validation loss: 2.5856811507409674

Epoch: 6| Step: 3
Training loss: 1.9382699236525431
Validation loss: 2.593037187717272

Epoch: 6| Step: 4
Training loss: 1.562023776915008
Validation loss: 2.551839381284751

Epoch: 6| Step: 5
Training loss: 1.1067418831423563
Validation loss: 2.53083705331555

Epoch: 6| Step: 6
Training loss: 1.7294414562364684
Validation loss: 2.495684845562364

Epoch: 6| Step: 7
Training loss: 2.020391225792973
Validation loss: 2.463755639786094

Epoch: 6| Step: 8
Training loss: 1.5052080341413612
Validation loss: 2.468774247378176

Epoch: 6| Step: 9
Training loss: 1.4202204709091402
Validation loss: 2.487874255916902

Epoch: 6| Step: 10
Training loss: 1.5136847907715094
Validation loss: 2.490968921477137

Epoch: 6| Step: 11
Training loss: 1.151639458040014
Validation loss: 2.4867279252256846

Epoch: 6| Step: 12
Training loss: 1.0539353125589714
Validation loss: 2.484414380303766

Epoch: 6| Step: 13
Training loss: 1.0107581685594995
Validation loss: 2.498810101435083

Epoch: 197| Step: 0
Training loss: 1.8969476450249485
Validation loss: 2.477627653351883

Epoch: 6| Step: 1
Training loss: 1.1287954731480743
Validation loss: 2.4686311729809467

Epoch: 6| Step: 2
Training loss: 1.2001236971043612
Validation loss: 2.4595372281770587

Epoch: 6| Step: 3
Training loss: 1.5442724973038129
Validation loss: 2.4734447757510627

Epoch: 6| Step: 4
Training loss: 1.4797450891262776
Validation loss: 2.4979599104342975

Epoch: 6| Step: 5
Training loss: 1.4916762030241615
Validation loss: 2.5147861485138496

Epoch: 6| Step: 6
Training loss: 1.4877685304493145
Validation loss: 2.5112352009898786

Epoch: 6| Step: 7
Training loss: 1.660581359289849
Validation loss: 2.4776664559276136

Epoch: 6| Step: 8
Training loss: 1.0525133682996735
Validation loss: 2.5115530629556617

Epoch: 6| Step: 9
Training loss: 1.457037877126559
Validation loss: 2.517030387957516

Epoch: 6| Step: 10
Training loss: 1.2986762165923431
Validation loss: 2.5049255056580284

Epoch: 6| Step: 11
Training loss: 1.663215457444612
Validation loss: 2.508231467578111

Epoch: 6| Step: 12
Training loss: 1.9456232887405138
Validation loss: 2.527632983752763

Epoch: 6| Step: 13
Training loss: 1.4691188430287103
Validation loss: 2.531176923666486

Epoch: 198| Step: 0
Training loss: 1.4176500030484211
Validation loss: 2.4824508848991758

Epoch: 6| Step: 1
Training loss: 1.4095544349819582
Validation loss: 2.4683081850847164

Epoch: 6| Step: 2
Training loss: 1.3273000511264266
Validation loss: 2.461210149222005

Epoch: 6| Step: 3
Training loss: 1.6352999052251231
Validation loss: 2.438428874810714

Epoch: 6| Step: 4
Training loss: 1.4853490745428293
Validation loss: 2.4580209643792426

Epoch: 6| Step: 5
Training loss: 1.8443853285838645
Validation loss: 2.474442512700956

Epoch: 6| Step: 6
Training loss: 1.0331205107861952
Validation loss: 2.460950918009675

Epoch: 6| Step: 7
Training loss: 1.605635808341836
Validation loss: 2.4613159310623014

Epoch: 6| Step: 8
Training loss: 1.6172390989466032
Validation loss: 2.4806883118154976

Epoch: 6| Step: 9
Training loss: 1.652689363303503
Validation loss: 2.4708723035040245

Epoch: 6| Step: 10
Training loss: 1.086763027010411
Validation loss: 2.4887225687813332

Epoch: 6| Step: 11
Training loss: 1.2744249599180877
Validation loss: 2.532123853882386

Epoch: 6| Step: 12
Training loss: 1.465454381190428
Validation loss: 2.5315269076694094

Epoch: 6| Step: 13
Training loss: 1.2012435767630212
Validation loss: 2.5189559855959183

Epoch: 199| Step: 0
Training loss: 1.3198744368798982
Validation loss: 2.548217204357602

Epoch: 6| Step: 1
Training loss: 1.2488486709789868
Validation loss: 2.560722163042175

Epoch: 6| Step: 2
Training loss: 1.7919991724361484
Validation loss: 2.523998411884728

Epoch: 6| Step: 3
Training loss: 1.2767901139464588
Validation loss: 2.5302170297007853

Epoch: 6| Step: 4
Training loss: 1.4581165515901808
Validation loss: 2.527986559523909

Epoch: 6| Step: 5
Training loss: 1.2257751075683119
Validation loss: 2.508908339778046

Epoch: 6| Step: 6
Training loss: 1.2596267505363679
Validation loss: 2.5141179564092897

Epoch: 6| Step: 7
Training loss: 1.461772007178431
Validation loss: 2.5240585059298186

Epoch: 6| Step: 8
Training loss: 1.2394424914106181
Validation loss: 2.526433269430956

Epoch: 6| Step: 9
Training loss: 1.632967416815505
Validation loss: 2.51155306499714

Epoch: 6| Step: 10
Training loss: 1.2926429268855755
Validation loss: 2.4991016342765575

Epoch: 6| Step: 11
Training loss: 1.4563640467963865
Validation loss: 2.4639863951291736

Epoch: 6| Step: 12
Training loss: 1.467520666025662
Validation loss: 2.4877342328206393

Epoch: 6| Step: 13
Training loss: 1.9117587803623664
Validation loss: 2.453677840726546

Epoch: 200| Step: 0
Training loss: 1.1005567463859762
Validation loss: 2.4885302081500362

Epoch: 6| Step: 1
Training loss: 0.9042815172114823
Validation loss: 2.476319983054988

Epoch: 6| Step: 2
Training loss: 1.4774843597875233
Validation loss: 2.4727149444105714

Epoch: 6| Step: 3
Training loss: 1.5008275610208928
Validation loss: 2.5240700587775855

Epoch: 6| Step: 4
Training loss: 1.5139643429647869
Validation loss: 2.5278506385873794

Epoch: 6| Step: 5
Training loss: 1.9270285383802528
Validation loss: 2.5609032122572724

Epoch: 6| Step: 6
Training loss: 1.2186217607374314
Validation loss: 2.5486455822838594

Epoch: 6| Step: 7
Training loss: 1.2862455163697744
Validation loss: 2.570918002675297

Epoch: 6| Step: 8
Training loss: 1.2237254577295456
Validation loss: 2.520571211391775

Epoch: 6| Step: 9
Training loss: 1.3705026161951022
Validation loss: 2.5229395020023926

Epoch: 6| Step: 10
Training loss: 1.4918985935961662
Validation loss: 2.4925040502646243

Epoch: 6| Step: 11
Training loss: 1.798355554060993
Validation loss: 2.4511746068466227

Epoch: 6| Step: 12
Training loss: 1.6991408757748017
Validation loss: 2.4688753719539216

Epoch: 6| Step: 13
Training loss: 0.9949839075023574
Validation loss: 2.4801177743126988

Epoch: 201| Step: 0
Training loss: 1.696886869778927
Validation loss: 2.479282333710426

Epoch: 6| Step: 1
Training loss: 1.3046878654799263
Validation loss: 2.5116212494493335

Epoch: 6| Step: 2
Training loss: 1.360718863057239
Validation loss: 2.567495289848046

Epoch: 6| Step: 3
Training loss: 1.6256282765591228
Validation loss: 2.5873078909679292

Epoch: 6| Step: 4
Training loss: 1.709243911654208
Validation loss: 2.5355646997108545

Epoch: 6| Step: 5
Training loss: 1.3834627853092296
Validation loss: 2.5001775550343535

Epoch: 6| Step: 6
Training loss: 0.9324747186460346
Validation loss: 2.486575053817345

Epoch: 6| Step: 7
Training loss: 0.9850396531251482
Validation loss: 2.476931419389817

Epoch: 6| Step: 8
Training loss: 1.3008853538484557
Validation loss: 2.4257540892932443

Epoch: 6| Step: 9
Training loss: 1.3695270684064709
Validation loss: 2.4195184808168224

Epoch: 6| Step: 10
Training loss: 1.1686435140966476
Validation loss: 2.432190634598007

Epoch: 6| Step: 11
Training loss: 1.3540471782297274
Validation loss: 2.4066899087545046

Epoch: 6| Step: 12
Training loss: 2.1743378431495746
Validation loss: 2.418004957114846

Epoch: 6| Step: 13
Training loss: 1.2394684115866883
Validation loss: 2.419119567779978

Epoch: 202| Step: 0
Training loss: 1.2254774311560235
Validation loss: 2.438909604754368

Epoch: 6| Step: 1
Training loss: 1.3517205471176355
Validation loss: 2.4531882132730463

Epoch: 6| Step: 2
Training loss: 1.29704637429266
Validation loss: 2.4867173834359626

Epoch: 6| Step: 3
Training loss: 1.5157318077600073
Validation loss: 2.514272581183226

Epoch: 6| Step: 4
Training loss: 1.3642982253012423
Validation loss: 2.5352600471800533

Epoch: 6| Step: 5
Training loss: 1.5429146672681517
Validation loss: 2.528409451048464

Epoch: 6| Step: 6
Training loss: 1.4749978469574296
Validation loss: 2.5264641047738743

Epoch: 6| Step: 7
Training loss: 1.2096452278037713
Validation loss: 2.4983207672236993

Epoch: 6| Step: 8
Training loss: 1.3583097120388155
Validation loss: 2.466466687620357

Epoch: 6| Step: 9
Training loss: 1.1563737132929484
Validation loss: 2.4633513342865028

Epoch: 6| Step: 10
Training loss: 1.2403481258582234
Validation loss: 2.4415238641444703

Epoch: 6| Step: 11
Training loss: 1.5198025105825743
Validation loss: 2.453899405268127

Epoch: 6| Step: 12
Training loss: 1.5105698431107142
Validation loss: 2.4622665678580176

Epoch: 6| Step: 13
Training loss: 1.4191881721526238
Validation loss: 2.452777360589311

Epoch: 203| Step: 0
Training loss: 1.6371481976175903
Validation loss: 2.524838275841311

Epoch: 6| Step: 1
Training loss: 1.180508460557826
Validation loss: 2.508130691476194

Epoch: 6| Step: 2
Training loss: 1.3557934990400213
Validation loss: 2.5285068933103076

Epoch: 6| Step: 3
Training loss: 2.0024534912042364
Validation loss: 2.530305478328848

Epoch: 6| Step: 4
Training loss: 1.2016640251931316
Validation loss: 2.5146410523563127

Epoch: 6| Step: 5
Training loss: 1.2649953241224154
Validation loss: 2.498643549174008

Epoch: 6| Step: 6
Training loss: 1.1222841542112136
Validation loss: 2.4925506499002386

Epoch: 6| Step: 7
Training loss: 1.2513625348348323
Validation loss: 2.4823252190174037

Epoch: 6| Step: 8
Training loss: 0.954055300853168
Validation loss: 2.468040983922666

Epoch: 6| Step: 9
Training loss: 1.3906995774748832
Validation loss: 2.468674475419496

Epoch: 6| Step: 10
Training loss: 1.016024994944449
Validation loss: 2.439901537728324

Epoch: 6| Step: 11
Training loss: 1.4814805571676832
Validation loss: 2.4479138760276986

Epoch: 6| Step: 12
Training loss: 1.0827725621904607
Validation loss: 2.4215379568431494

Epoch: 6| Step: 13
Training loss: 1.179309102184874
Validation loss: 2.432531529215189

Epoch: 204| Step: 0
Training loss: 1.5986479500419153
Validation loss: 2.4656838738053355

Epoch: 6| Step: 1
Training loss: 0.9226365580706314
Validation loss: 2.509273362829483

Epoch: 6| Step: 2
Training loss: 1.2094404257097844
Validation loss: 2.526431940137934

Epoch: 6| Step: 3
Training loss: 1.1779066880222564
Validation loss: 2.5256800347127313

Epoch: 6| Step: 4
Training loss: 0.7600875995997084
Validation loss: 2.524163160134953

Epoch: 6| Step: 5
Training loss: 1.2933241249195806
Validation loss: 2.498301535130544

Epoch: 6| Step: 6
Training loss: 1.308211905722482
Validation loss: 2.4921614544322983

Epoch: 6| Step: 7
Training loss: 1.4063542221442666
Validation loss: 2.4826343454776945

Epoch: 6| Step: 8
Training loss: 1.450356830888491
Validation loss: 2.471262635923281

Epoch: 6| Step: 9
Training loss: 1.3644780368316343
Validation loss: 2.483770501128308

Epoch: 6| Step: 10
Training loss: 1.7808243092278682
Validation loss: 2.486690524891927

Epoch: 6| Step: 11
Training loss: 0.9784523949209726
Validation loss: 2.4751069973559496

Epoch: 6| Step: 12
Training loss: 1.2489517585044714
Validation loss: 2.4615502379386562

Epoch: 6| Step: 13
Training loss: 1.1496241660273212
Validation loss: 2.462162498531261

Epoch: 205| Step: 0
Training loss: 1.2741359363357134
Validation loss: 2.421250648217864

Epoch: 6| Step: 1
Training loss: 0.865084460771073
Validation loss: 2.4102190511144137

Epoch: 6| Step: 2
Training loss: 1.2980032000568367
Validation loss: 2.4094141721211164

Epoch: 6| Step: 3
Training loss: 1.4930066960740982
Validation loss: 2.4117257032836266

Epoch: 6| Step: 4
Training loss: 1.35578606928573
Validation loss: 2.4338335260060604

Epoch: 6| Step: 5
Training loss: 1.042862847484282
Validation loss: 2.468779800876926

Epoch: 6| Step: 6
Training loss: 0.9775111054377438
Validation loss: 2.4884378299575203

Epoch: 6| Step: 7
Training loss: 1.4548230658113626
Validation loss: 2.537432233955355

Epoch: 6| Step: 8
Training loss: 1.2918606069027867
Validation loss: 2.5449247499905105

Epoch: 6| Step: 9
Training loss: 1.6495367064425965
Validation loss: 2.5323807765538136

Epoch: 6| Step: 10
Training loss: 1.4695122546723045
Validation loss: 2.4938018813169394

Epoch: 6| Step: 11
Training loss: 1.3715430933530446
Validation loss: 2.487083413202167

Epoch: 6| Step: 12
Training loss: 1.4188766725429651
Validation loss: 2.46026789522028

Epoch: 6| Step: 13
Training loss: 0.7051313174146823
Validation loss: 2.4415478842065133

Epoch: 206| Step: 0
Training loss: 1.4903771568282094
Validation loss: 2.4165487087374227

Epoch: 6| Step: 1
Training loss: 1.963782507362084
Validation loss: 2.4434686863554465

Epoch: 6| Step: 2
Training loss: 0.9367267280601564
Validation loss: 2.4225778801551754

Epoch: 6| Step: 3
Training loss: 0.9229225091053219
Validation loss: 2.4387403886519587

Epoch: 6| Step: 4
Training loss: 1.4098760268313064
Validation loss: 2.422394488322401

Epoch: 6| Step: 5
Training loss: 1.4216102940576845
Validation loss: 2.4655677084945293

Epoch: 6| Step: 6
Training loss: 1.0061116022693548
Validation loss: 2.4931944712818797

Epoch: 6| Step: 7
Training loss: 1.4718050735612196
Validation loss: 2.466990305197079

Epoch: 6| Step: 8
Training loss: 1.188526212083045
Validation loss: 2.4938456317951037

Epoch: 6| Step: 9
Training loss: 1.173171788188516
Validation loss: 2.466521325051845

Epoch: 6| Step: 10
Training loss: 0.9808071509966353
Validation loss: 2.435889716337707

Epoch: 6| Step: 11
Training loss: 1.058690478420634
Validation loss: 2.43580169243381

Epoch: 6| Step: 12
Training loss: 1.2794726069068267
Validation loss: 2.414624506202884

Epoch: 6| Step: 13
Training loss: 1.0369670648154468
Validation loss: 2.4177589225400773

Epoch: 207| Step: 0
Training loss: 1.1952885145386347
Validation loss: 2.4291865034054543

Epoch: 6| Step: 1
Training loss: 1.2172838831534156
Validation loss: 2.4161050679330147

Epoch: 6| Step: 2
Training loss: 1.7712359101698163
Validation loss: 2.3973907915568464

Epoch: 6| Step: 3
Training loss: 1.2604730083809301
Validation loss: 2.4069959562701975

Epoch: 6| Step: 4
Training loss: 0.8352352294118242
Validation loss: 2.420290509287969

Epoch: 6| Step: 5
Training loss: 0.9926198783178413
Validation loss: 2.410735899934734

Epoch: 6| Step: 6
Training loss: 1.0458110128100442
Validation loss: 2.4235846723344654

Epoch: 6| Step: 7
Training loss: 1.3192762111469372
Validation loss: 2.46211655136506

Epoch: 6| Step: 8
Training loss: 1.1686162780312197
Validation loss: 2.4526142617799276

Epoch: 6| Step: 9
Training loss: 1.4464954380948456
Validation loss: 2.4784155552575475

Epoch: 6| Step: 10
Training loss: 1.5256816278721013
Validation loss: 2.4281024814991676

Epoch: 6| Step: 11
Training loss: 0.9171380687696001
Validation loss: 2.404621546482764

Epoch: 6| Step: 12
Training loss: 1.5004392616514917
Validation loss: 2.3869579097279976

Epoch: 6| Step: 13
Training loss: 1.3715768598742177
Validation loss: 2.3868701520851445

Epoch: 208| Step: 0
Training loss: 1.3184165207522176
Validation loss: 2.3925609520535907

Epoch: 6| Step: 1
Training loss: 1.1115196880839722
Validation loss: 2.4301162107791465

Epoch: 6| Step: 2
Training loss: 1.2359864544728065
Validation loss: 2.433640684433265

Epoch: 6| Step: 3
Training loss: 1.4775048533713315
Validation loss: 2.54246929398971

Epoch: 6| Step: 4
Training loss: 1.0800560505768648
Validation loss: 2.5976314805335114

Epoch: 6| Step: 5
Training loss: 1.4844119418717254
Validation loss: 2.6215806617030606

Epoch: 6| Step: 6
Training loss: 1.2592316198016749
Validation loss: 2.542705449357181

Epoch: 6| Step: 7
Training loss: 1.6638247897722858
Validation loss: 2.48490697296754

Epoch: 6| Step: 8
Training loss: 1.1813834422795424
Validation loss: 2.4268215361642507

Epoch: 6| Step: 9
Training loss: 1.4709343595453002
Validation loss: 2.422607659312083

Epoch: 6| Step: 10
Training loss: 0.9461109792965986
Validation loss: 2.425719274529365

Epoch: 6| Step: 11
Training loss: 1.3461362808779287
Validation loss: 2.4119972118232393

Epoch: 6| Step: 12
Training loss: 1.358603861652144
Validation loss: 2.404600480715773

Epoch: 6| Step: 13
Training loss: 1.1556150394090896
Validation loss: 2.4019164264163293

Epoch: 209| Step: 0
Training loss: 1.3464446882835077
Validation loss: 2.430085199925096

Epoch: 6| Step: 1
Training loss: 1.3036747730968388
Validation loss: 2.4704216800641783

Epoch: 6| Step: 2
Training loss: 0.7690359545191038
Validation loss: 2.512146281219355

Epoch: 6| Step: 3
Training loss: 1.3722658717119671
Validation loss: 2.564371197655976

Epoch: 6| Step: 4
Training loss: 0.8715202074536895
Validation loss: 2.558736325715615

Epoch: 6| Step: 5
Training loss: 1.02643327291557
Validation loss: 2.5379935612675846

Epoch: 6| Step: 6
Training loss: 1.3811753921727252
Validation loss: 2.523197398472795

Epoch: 6| Step: 7
Training loss: 1.6353440076233665
Validation loss: 2.472356156008863

Epoch: 6| Step: 8
Training loss: 0.9085695245453796
Validation loss: 2.449339064105217

Epoch: 6| Step: 9
Training loss: 1.2591146043726837
Validation loss: 2.4297108626168162

Epoch: 6| Step: 10
Training loss: 1.2999686604170142
Validation loss: 2.4367088430637565

Epoch: 6| Step: 11
Training loss: 1.3170440668135721
Validation loss: 2.432191628563114

Epoch: 6| Step: 12
Training loss: 1.3629607340305718
Validation loss: 2.4448209843437345

Epoch: 6| Step: 13
Training loss: 1.4187053522151132
Validation loss: 2.4261160013474914

Epoch: 210| Step: 0
Training loss: 1.39967828187592
Validation loss: 2.41556445719553

Epoch: 6| Step: 1
Training loss: 1.7669602468063466
Validation loss: 2.4053550987701353

Epoch: 6| Step: 2
Training loss: 1.332870666379519
Validation loss: 2.408459109986709

Epoch: 6| Step: 3
Training loss: 1.0956257131501317
Validation loss: 2.4445610234943342

Epoch: 6| Step: 4
Training loss: 1.2201766931279656
Validation loss: 2.468609686597658

Epoch: 6| Step: 5
Training loss: 0.7721028613238705
Validation loss: 2.4726489011775232

Epoch: 6| Step: 6
Training loss: 1.12963811784924
Validation loss: 2.4837653104062904

Epoch: 6| Step: 7
Training loss: 1.2576952577528078
Validation loss: 2.489796742142182

Epoch: 6| Step: 8
Training loss: 1.0778725922938206
Validation loss: 2.489912928682175

Epoch: 6| Step: 9
Training loss: 0.7922174812978758
Validation loss: 2.4847096512974103

Epoch: 6| Step: 10
Training loss: 1.3655121920365054
Validation loss: 2.5261065071460482

Epoch: 6| Step: 11
Training loss: 1.0961484497081622
Validation loss: 2.4894677465414774

Epoch: 6| Step: 12
Training loss: 1.2910426334666596
Validation loss: 2.47299668970418

Epoch: 6| Step: 13
Training loss: 1.2340487761324852
Validation loss: 2.4419552799582065

Epoch: 211| Step: 0
Training loss: 1.15272448440802
Validation loss: 2.4224219809041534

Epoch: 6| Step: 1
Training loss: 1.2562314634711067
Validation loss: 2.4094001314050004

Epoch: 6| Step: 2
Training loss: 0.9704256639818297
Validation loss: 2.3908850533577977

Epoch: 6| Step: 3
Training loss: 1.194812944528184
Validation loss: 2.373260660997455

Epoch: 6| Step: 4
Training loss: 0.925933310337997
Validation loss: 2.401579762253711

Epoch: 6| Step: 5
Training loss: 1.2841250563920152
Validation loss: 2.4025730208068232

Epoch: 6| Step: 6
Training loss: 1.3282567575958804
Validation loss: 2.4130388168146077

Epoch: 6| Step: 7
Training loss: 1.3838560832504114
Validation loss: 2.4215103652942744

Epoch: 6| Step: 8
Training loss: 1.038622253770603
Validation loss: 2.4482520724365746

Epoch: 6| Step: 9
Training loss: 0.8188633789300027
Validation loss: 2.447686983712256

Epoch: 6| Step: 10
Training loss: 1.2243112691014004
Validation loss: 2.4688700611333423

Epoch: 6| Step: 11
Training loss: 1.107294199747159
Validation loss: 2.448360999909687

Epoch: 6| Step: 12
Training loss: 1.778023122540576
Validation loss: 2.4905136422149

Epoch: 6| Step: 13
Training loss: 0.7437494406177116
Validation loss: 2.482343121550446

Epoch: 212| Step: 0
Training loss: 0.9522925947562161
Validation loss: 2.498417174812579

Epoch: 6| Step: 1
Training loss: 1.2665099358633891
Validation loss: 2.5111000394820597

Epoch: 6| Step: 2
Training loss: 1.1382360131275522
Validation loss: 2.4802576609735576

Epoch: 6| Step: 3
Training loss: 1.6660667134330542
Validation loss: 2.485400731565197

Epoch: 6| Step: 4
Training loss: 1.3076746203663372
Validation loss: 2.469413723140421

Epoch: 6| Step: 5
Training loss: 1.287958076615161
Validation loss: 2.464284787935493

Epoch: 6| Step: 6
Training loss: 0.856755860419109
Validation loss: 2.4382842395438717

Epoch: 6| Step: 7
Training loss: 0.9069162090463584
Validation loss: 2.4389313512113624

Epoch: 6| Step: 8
Training loss: 1.3811343079873981
Validation loss: 2.449392912400673

Epoch: 6| Step: 9
Training loss: 1.1395501075564145
Validation loss: 2.410551554269166

Epoch: 6| Step: 10
Training loss: 1.0739978910031203
Validation loss: 2.4189933450730052

Epoch: 6| Step: 11
Training loss: 0.7282306840026207
Validation loss: 2.4442415554864843

Epoch: 6| Step: 12
Training loss: 1.0097632048410008
Validation loss: 2.452620756808989

Epoch: 6| Step: 13
Training loss: 1.567039685110139
Validation loss: 2.4681456672370845

Epoch: 213| Step: 0
Training loss: 1.3864512440734034
Validation loss: 2.4380522944454297

Epoch: 6| Step: 1
Training loss: 0.7471667258686443
Validation loss: 2.4548582870967572

Epoch: 6| Step: 2
Training loss: 1.0640560424429488
Validation loss: 2.454937512630668

Epoch: 6| Step: 3
Training loss: 1.0521946586906918
Validation loss: 2.4041103656795073

Epoch: 6| Step: 4
Training loss: 1.2960558222946201
Validation loss: 2.4069963631303075

Epoch: 6| Step: 5
Training loss: 1.2401681957460162
Validation loss: 2.416215643062923

Epoch: 6| Step: 6
Training loss: 0.7543349554247012
Validation loss: 2.4305495912993385

Epoch: 6| Step: 7
Training loss: 1.2518204783900035
Validation loss: 2.4048656412217744

Epoch: 6| Step: 8
Training loss: 1.0830268548610509
Validation loss: 2.4099555566973976

Epoch: 6| Step: 9
Training loss: 1.0988687355193596
Validation loss: 2.413364630107968

Epoch: 6| Step: 10
Training loss: 1.7876067923276164
Validation loss: 2.4282697858198095

Epoch: 6| Step: 11
Training loss: 1.2611600506921847
Validation loss: 2.47211483380366

Epoch: 6| Step: 12
Training loss: 0.8665650341768625
Validation loss: 2.4341486811678448

Epoch: 6| Step: 13
Training loss: 0.6078447053903853
Validation loss: 2.405659456505427

Epoch: 214| Step: 0
Training loss: 1.2265887409488998
Validation loss: 2.4243073833747792

Epoch: 6| Step: 1
Training loss: 1.3411759851516813
Validation loss: 2.4379245755344296

Epoch: 6| Step: 2
Training loss: 1.04830095337156
Validation loss: 2.4296100663335376

Epoch: 6| Step: 3
Training loss: 0.907083358384989
Validation loss: 2.435728655311772

Epoch: 6| Step: 4
Training loss: 0.6729708318100209
Validation loss: 2.4117658632481227

Epoch: 6| Step: 5
Training loss: 1.1251441015565864
Validation loss: 2.4150687554834938

Epoch: 6| Step: 6
Training loss: 1.1929976044508488
Validation loss: 2.4163867956698257

Epoch: 6| Step: 7
Training loss: 1.6358985029088626
Validation loss: 2.4389348830148694

Epoch: 6| Step: 8
Training loss: 1.369038663759816
Validation loss: 2.4881459698077766

Epoch: 6| Step: 9
Training loss: 0.938895680721504
Validation loss: 2.4789821162773116

Epoch: 6| Step: 10
Training loss: 1.2947540404585782
Validation loss: 2.4523437836195456

Epoch: 6| Step: 11
Training loss: 0.6511670996314078
Validation loss: 2.459443656233163

Epoch: 6| Step: 12
Training loss: 1.2229800054642181
Validation loss: 2.4603992129329515

Epoch: 6| Step: 13
Training loss: 0.5156452290583822
Validation loss: 2.40774614698473

Epoch: 215| Step: 0
Training loss: 1.731184903790482
Validation loss: 2.4060323281418343

Epoch: 6| Step: 1
Training loss: 0.6973237085592963
Validation loss: 2.365701645601497

Epoch: 6| Step: 2
Training loss: 1.2374402388197454
Validation loss: 2.396226213690099

Epoch: 6| Step: 3
Training loss: 0.8692009036988547
Validation loss: 2.4069741508108518

Epoch: 6| Step: 4
Training loss: 1.4640563476172674
Validation loss: 2.459638572008194

Epoch: 6| Step: 5
Training loss: 1.1765094922449233
Validation loss: 2.4181819952082946

Epoch: 6| Step: 6
Training loss: 0.9857434645573261
Validation loss: 2.46093151731817

Epoch: 6| Step: 7
Training loss: 1.2871004836566944
Validation loss: 2.469697282205172

Epoch: 6| Step: 8
Training loss: 1.2178910970249541
Validation loss: 2.4176168278276515

Epoch: 6| Step: 9
Training loss: 0.8753674961559951
Validation loss: 2.464091867914122

Epoch: 6| Step: 10
Training loss: 1.1128299802389034
Validation loss: 2.432884234946073

Epoch: 6| Step: 11
Training loss: 0.8301586874967891
Validation loss: 2.4133787614211983

Epoch: 6| Step: 12
Training loss: 1.0045955087838168
Validation loss: 2.3870001795605367

Epoch: 6| Step: 13
Training loss: 0.714527998432408
Validation loss: 2.388793803751428

Epoch: 216| Step: 0
Training loss: 0.9427256222539329
Validation loss: 2.3891249069529144

Epoch: 6| Step: 1
Training loss: 1.0918710099984226
Validation loss: 2.4247185343623543

Epoch: 6| Step: 2
Training loss: 1.3080416297499848
Validation loss: 2.4042394468979316

Epoch: 6| Step: 3
Training loss: 1.025237095556041
Validation loss: 2.4212836536991795

Epoch: 6| Step: 4
Training loss: 0.8419344052862539
Validation loss: 2.4023070453888167

Epoch: 6| Step: 5
Training loss: 1.1892839383472487
Validation loss: 2.4456541421700133

Epoch: 6| Step: 6
Training loss: 0.8385971043112553
Validation loss: 2.4349916928956867

Epoch: 6| Step: 7
Training loss: 1.1493581079234307
Validation loss: 2.432623415284224

Epoch: 6| Step: 8
Training loss: 1.108472483846195
Validation loss: 2.4665281007282513

Epoch: 6| Step: 9
Training loss: 0.9288247216254003
Validation loss: 2.4562357041693024

Epoch: 6| Step: 10
Training loss: 1.1385307420844581
Validation loss: 2.390530515676664

Epoch: 6| Step: 11
Training loss: 1.6093604818633693
Validation loss: 2.399894562771449

Epoch: 6| Step: 12
Training loss: 1.0217392204206994
Validation loss: 2.4225916780910097

Epoch: 6| Step: 13
Training loss: 1.2224743009959183
Validation loss: 2.4105994478084183

Epoch: 217| Step: 0
Training loss: 0.4770116721670508
Validation loss: 2.4299861061184793

Epoch: 6| Step: 1
Training loss: 0.9958180962411718
Validation loss: 2.4242051230089676

Epoch: 6| Step: 2
Training loss: 1.2038954212610213
Validation loss: 2.4625807576137824

Epoch: 6| Step: 3
Training loss: 0.6080843388684737
Validation loss: 2.451194519322735

Epoch: 6| Step: 4
Training loss: 0.7251031637785365
Validation loss: 2.436031236648428

Epoch: 6| Step: 5
Training loss: 1.1300594155549195
Validation loss: 2.4599951822083805

Epoch: 6| Step: 6
Training loss: 1.1477616585663062
Validation loss: 2.4576106489181804

Epoch: 6| Step: 7
Training loss: 1.132366171417872
Validation loss: 2.4403660365879247

Epoch: 6| Step: 8
Training loss: 1.5479355076310228
Validation loss: 2.4192016062526873

Epoch: 6| Step: 9
Training loss: 1.4082623811865234
Validation loss: 2.416142395854746

Epoch: 6| Step: 10
Training loss: 0.8991338270505305
Validation loss: 2.401974715874554

Epoch: 6| Step: 11
Training loss: 1.555907571033186
Validation loss: 2.4074850893275004

Epoch: 6| Step: 12
Training loss: 1.099777832136934
Validation loss: 2.3963682710834573

Epoch: 6| Step: 13
Training loss: 0.877382440979216
Validation loss: 2.3882204086163186

Epoch: 218| Step: 0
Training loss: 1.0575674790300742
Validation loss: 2.398230925868379

Epoch: 6| Step: 1
Training loss: 0.9175854471108583
Validation loss: 2.404823079900946

Epoch: 6| Step: 2
Training loss: 0.8271841066274297
Validation loss: 2.4223964229095345

Epoch: 6| Step: 3
Training loss: 0.9628695162612397
Validation loss: 2.445849330915676

Epoch: 6| Step: 4
Training loss: 1.5819051810060316
Validation loss: 2.4925487162800475

Epoch: 6| Step: 5
Training loss: 1.012432950943392
Validation loss: 2.5118639771997238

Epoch: 6| Step: 6
Training loss: 0.9072338551535136
Validation loss: 2.5343388658099206

Epoch: 6| Step: 7
Training loss: 1.1731116318588835
Validation loss: 2.550489339639683

Epoch: 6| Step: 8
Training loss: 1.291042679634495
Validation loss: 2.5090532545312962

Epoch: 6| Step: 9
Training loss: 1.0438404226824223
Validation loss: 2.4519280535763235

Epoch: 6| Step: 10
Training loss: 1.6567782153537043
Validation loss: 2.4046855374558334

Epoch: 6| Step: 11
Training loss: 0.7816763668095569
Validation loss: 2.4141528202317497

Epoch: 6| Step: 12
Training loss: 0.8468600986197286
Validation loss: 2.388796532883763

Epoch: 6| Step: 13
Training loss: 0.5231694916066274
Validation loss: 2.386065021563687

Epoch: 219| Step: 0
Training loss: 0.8099226788715249
Validation loss: 2.3711604637924886

Epoch: 6| Step: 1
Training loss: 0.870599683570147
Validation loss: 2.3995375383794193

Epoch: 6| Step: 2
Training loss: 0.7916576652684363
Validation loss: 2.3972188013753493

Epoch: 6| Step: 3
Training loss: 1.7660741994181166
Validation loss: 2.3973975455376757

Epoch: 6| Step: 4
Training loss: 1.0153411468569233
Validation loss: 2.403026856055675

Epoch: 6| Step: 5
Training loss: 1.094159621782326
Validation loss: 2.4370228276930175

Epoch: 6| Step: 6
Training loss: 1.203285900107477
Validation loss: 2.438505484383741

Epoch: 6| Step: 7
Training loss: 1.1001826633164369
Validation loss: 2.478001226940906

Epoch: 6| Step: 8
Training loss: 1.0708106336649168
Validation loss: 2.496027439491001

Epoch: 6| Step: 9
Training loss: 1.102777663059266
Validation loss: 2.5142857079315477

Epoch: 6| Step: 10
Training loss: 1.1175954647379052
Validation loss: 2.5423709474268246

Epoch: 6| Step: 11
Training loss: 1.1162160638005645
Validation loss: 2.500100886452498

Epoch: 6| Step: 12
Training loss: 0.8562522331264362
Validation loss: 2.44581063150622

Epoch: 6| Step: 13
Training loss: 1.2604238283989
Validation loss: 2.3937407148209986

Epoch: 220| Step: 0
Training loss: 0.894346792867893
Validation loss: 2.383352136856873

Epoch: 6| Step: 1
Training loss: 1.0799641609426645
Validation loss: 2.389751200372704

Epoch: 6| Step: 2
Training loss: 0.8947909115724112
Validation loss: 2.3945273871884902

Epoch: 6| Step: 3
Training loss: 1.010388298554066
Validation loss: 2.3626381503755343

Epoch: 6| Step: 4
Training loss: 1.053724173956773
Validation loss: 2.373794852220226

Epoch: 6| Step: 5
Training loss: 1.2392060589937126
Validation loss: 2.3794708888518397

Epoch: 6| Step: 6
Training loss: 1.6401531449199778
Validation loss: 2.400276256585385

Epoch: 6| Step: 7
Training loss: 1.037798866060659
Validation loss: 2.429182621827083

Epoch: 6| Step: 8
Training loss: 1.0922119770936407
Validation loss: 2.4060506132119306

Epoch: 6| Step: 9
Training loss: 1.0374832197923531
Validation loss: 2.4115450264602067

Epoch: 6| Step: 10
Training loss: 1.0676063799058957
Validation loss: 2.4119352164485566

Epoch: 6| Step: 11
Training loss: 1.0315032416850718
Validation loss: 2.441705116535646

Epoch: 6| Step: 12
Training loss: 0.8813937441962003
Validation loss: 2.4250986081520347

Epoch: 6| Step: 13
Training loss: 1.0776584555642201
Validation loss: 2.409092065736688

Epoch: 221| Step: 0
Training loss: 1.1411697967859278
Validation loss: 2.4620530456554053

Epoch: 6| Step: 1
Training loss: 1.1276571894183638
Validation loss: 2.486465004256273

Epoch: 6| Step: 2
Training loss: 0.9836332160237174
Validation loss: 2.5130462789716383

Epoch: 6| Step: 3
Training loss: 0.9354405989838664
Validation loss: 2.4898972878190895

Epoch: 6| Step: 4
Training loss: 1.1535795148239607
Validation loss: 2.45478612295746

Epoch: 6| Step: 5
Training loss: 1.6069293652377137
Validation loss: 2.413930322570372

Epoch: 6| Step: 6
Training loss: 0.9186049833485225
Validation loss: 2.402931685543711

Epoch: 6| Step: 7
Training loss: 1.0023616084517106
Validation loss: 2.416540495478796

Epoch: 6| Step: 8
Training loss: 0.8612610667587621
Validation loss: 2.3795531948209145

Epoch: 6| Step: 9
Training loss: 0.9338511347610663
Validation loss: 2.4278395790213136

Epoch: 6| Step: 10
Training loss: 1.0185804354667456
Validation loss: 2.4228679345626327

Epoch: 6| Step: 11
Training loss: 1.1074499163702038
Validation loss: 2.458448300628906

Epoch: 6| Step: 12
Training loss: 1.1900265068019176
Validation loss: 2.4789297246243724

Epoch: 6| Step: 13
Training loss: 0.31342027580727666
Validation loss: 2.5179269935994393

Epoch: 222| Step: 0
Training loss: 0.9347108358609484
Validation loss: 2.495258898367417

Epoch: 6| Step: 1
Training loss: 1.020429836378761
Validation loss: 2.485712570634741

Epoch: 6| Step: 2
Training loss: 1.2529332554113024
Validation loss: 2.4753122783819212

Epoch: 6| Step: 3
Training loss: 1.0392702511632876
Validation loss: 2.4730047211640094

Epoch: 6| Step: 4
Training loss: 0.9500008645806645
Validation loss: 2.4578170379337476

Epoch: 6| Step: 5
Training loss: 1.0974328842148573
Validation loss: 2.4616491280768793

Epoch: 6| Step: 6
Training loss: 1.1217738092631975
Validation loss: 2.419521853414519

Epoch: 6| Step: 7
Training loss: 1.565651728540868
Validation loss: 2.3763175919122648

Epoch: 6| Step: 8
Training loss: 1.070511068594243
Validation loss: 2.359684175855633

Epoch: 6| Step: 9
Training loss: 0.7076258819660836
Validation loss: 2.3566073329959307

Epoch: 6| Step: 10
Training loss: 0.923666587078165
Validation loss: 2.4123004042065213

Epoch: 6| Step: 11
Training loss: 1.2117287296595003
Validation loss: 2.381015622284992

Epoch: 6| Step: 12
Training loss: 0.7153601110369725
Validation loss: 2.401136225662705

Epoch: 6| Step: 13
Training loss: 0.36681288012928326
Validation loss: 2.424431588906769

Epoch: 223| Step: 0
Training loss: 0.8648313526619269
Validation loss: 2.404474546033307

Epoch: 6| Step: 1
Training loss: 0.8130982470674472
Validation loss: 2.4328432913230054

Epoch: 6| Step: 2
Training loss: 1.1063577157720794
Validation loss: 2.4398908761020404

Epoch: 6| Step: 3
Training loss: 1.5309093641415976
Validation loss: 2.4495320795576396

Epoch: 6| Step: 4
Training loss: 0.866048253554114
Validation loss: 2.4711852393538485

Epoch: 6| Step: 5
Training loss: 0.975472841781254
Validation loss: 2.4153699012385803

Epoch: 6| Step: 6
Training loss: 1.1015056838946504
Validation loss: 2.4320761393262416

Epoch: 6| Step: 7
Training loss: 1.0477135559384736
Validation loss: 2.403714135704203

Epoch: 6| Step: 8
Training loss: 0.9759336964841241
Validation loss: 2.393666665272629

Epoch: 6| Step: 9
Training loss: 0.7728552890752334
Validation loss: 2.416688569605789

Epoch: 6| Step: 10
Training loss: 1.0540316202462248
Validation loss: 2.3862949947973537

Epoch: 6| Step: 11
Training loss: 0.9814369618833955
Validation loss: 2.4269828756232004

Epoch: 6| Step: 12
Training loss: 1.0510469689186626
Validation loss: 2.4040563562083648

Epoch: 6| Step: 13
Training loss: 0.6817065756298925
Validation loss: 2.4132418617053206

Epoch: 224| Step: 0
Training loss: 0.9923363521386067
Validation loss: 2.400309420707733

Epoch: 6| Step: 1
Training loss: 0.568966413552526
Validation loss: 2.397323387582178

Epoch: 6| Step: 2
Training loss: 1.1120078852188686
Validation loss: 2.4070081806823733

Epoch: 6| Step: 3
Training loss: 0.4552107850917315
Validation loss: 2.39516672078057

Epoch: 6| Step: 4
Training loss: 0.8026300070083208
Validation loss: 2.4017504912225247

Epoch: 6| Step: 5
Training loss: 0.8811951058788209
Validation loss: 2.3906470661081936

Epoch: 6| Step: 6
Training loss: 0.9835108339540105
Validation loss: 2.3626062538250685

Epoch: 6| Step: 7
Training loss: 0.8458923410087181
Validation loss: 2.3667072678253143

Epoch: 6| Step: 8
Training loss: 1.194014848418697
Validation loss: 2.3323797985542183

Epoch: 6| Step: 9
Training loss: 1.2669754829322868
Validation loss: 2.364821119352059

Epoch: 6| Step: 10
Training loss: 1.8028014264599
Validation loss: 2.3681851178776596

Epoch: 6| Step: 11
Training loss: 0.8005580684132096
Validation loss: 2.369251607708424

Epoch: 6| Step: 12
Training loss: 0.8911635126039409
Validation loss: 2.3946238935131476

Epoch: 6| Step: 13
Training loss: 0.915130838618094
Validation loss: 2.4298509006628635

Epoch: 225| Step: 0
Training loss: 0.9550138736635836
Validation loss: 2.456722704000232

Epoch: 6| Step: 1
Training loss: 0.7925927534487803
Validation loss: 2.4404389811443252

Epoch: 6| Step: 2
Training loss: 0.902390978349236
Validation loss: 2.4298239795802528

Epoch: 6| Step: 3
Training loss: 0.8963655546810761
Validation loss: 2.417383309069663

Epoch: 6| Step: 4
Training loss: 0.8751001641299608
Validation loss: 2.435995357977953

Epoch: 6| Step: 5
Training loss: 0.931402979836869
Validation loss: 2.381995026624895

Epoch: 6| Step: 6
Training loss: 0.7293509023521544
Validation loss: 2.3619217074943974

Epoch: 6| Step: 7
Training loss: 0.8946033432073996
Validation loss: 2.3866411913518526

Epoch: 6| Step: 8
Training loss: 1.616821026397027
Validation loss: 2.3771059751845556

Epoch: 6| Step: 9
Training loss: 1.1118115277156089
Validation loss: 2.409131515664253

Epoch: 6| Step: 10
Training loss: 0.9064511371894742
Validation loss: 2.424142075607729

Epoch: 6| Step: 11
Training loss: 1.1438372594347357
Validation loss: 2.437630640677615

Epoch: 6| Step: 12
Training loss: 0.7067692729695655
Validation loss: 2.46232048522086

Epoch: 6| Step: 13
Training loss: 1.2696560842320561
Validation loss: 2.4610971883726918

Epoch: 226| Step: 0
Training loss: 1.1655289290776556
Validation loss: 2.452500787933281

Epoch: 6| Step: 1
Training loss: 0.8933192208643858
Validation loss: 2.4258109763580413

Epoch: 6| Step: 2
Training loss: 1.635298009888791
Validation loss: 2.3834141534339315

Epoch: 6| Step: 3
Training loss: 0.9213429224777633
Validation loss: 2.3695595197662573

Epoch: 6| Step: 4
Training loss: 1.001264606993158
Validation loss: 2.3649651986707148

Epoch: 6| Step: 5
Training loss: 0.9537245631294377
Validation loss: 2.380406951390213

Epoch: 6| Step: 6
Training loss: 0.7690805577371239
Validation loss: 2.3717563080050437

Epoch: 6| Step: 7
Training loss: 0.9189545228599938
Validation loss: 2.345303206344655

Epoch: 6| Step: 8
Training loss: 0.9798266067185311
Validation loss: 2.361855658616891

Epoch: 6| Step: 9
Training loss: 0.7805788208837947
Validation loss: 2.357798785936296

Epoch: 6| Step: 10
Training loss: 0.7096829926294316
Validation loss: 2.344898126970575

Epoch: 6| Step: 11
Training loss: 0.8037766421635247
Validation loss: 2.3761070404494444

Epoch: 6| Step: 12
Training loss: 0.8823692762040892
Validation loss: 2.380068382129781

Epoch: 6| Step: 13
Training loss: 1.0730065181601747
Validation loss: 2.396198769333718

Epoch: 227| Step: 0
Training loss: 1.0433632322502173
Validation loss: 2.3954588793179776

Epoch: 6| Step: 1
Training loss: 1.0008210745279593
Validation loss: 2.4598146720045024

Epoch: 6| Step: 2
Training loss: 0.7480256000411721
Validation loss: 2.4028138513192783

Epoch: 6| Step: 3
Training loss: 0.5463859824004338
Validation loss: 2.3799100292073025

Epoch: 6| Step: 4
Training loss: 1.0693887775900297
Validation loss: 2.3524238040125236

Epoch: 6| Step: 5
Training loss: 0.9881732565034442
Validation loss: 2.371182649410266

Epoch: 6| Step: 6
Training loss: 0.943789618967872
Validation loss: 2.389069391742855

Epoch: 6| Step: 7
Training loss: 0.9527266873921086
Validation loss: 2.384452306418097

Epoch: 6| Step: 8
Training loss: 1.0330789127212707
Validation loss: 2.4227191587822414

Epoch: 6| Step: 9
Training loss: 1.0503656068704428
Validation loss: 2.3991658884840845

Epoch: 6| Step: 10
Training loss: 1.6173988241069468
Validation loss: 2.4359592577718407

Epoch: 6| Step: 11
Training loss: 0.6864372188425483
Validation loss: 2.457854936817993

Epoch: 6| Step: 12
Training loss: 0.9005909860238225
Validation loss: 2.478221443398703

Epoch: 6| Step: 13
Training loss: 1.0983725820271437
Validation loss: 2.468773619130055

Epoch: 228| Step: 0
Training loss: 0.9030029399186074
Validation loss: 2.4604037558798004

Epoch: 6| Step: 1
Training loss: 0.9858735198286361
Validation loss: 2.4476321887463866

Epoch: 6| Step: 2
Training loss: 0.9292136194713864
Validation loss: 2.451480294011927

Epoch: 6| Step: 3
Training loss: 0.8775164317904744
Validation loss: 2.4172315729364335

Epoch: 6| Step: 4
Training loss: 0.761489990313862
Validation loss: 2.4242483375694874

Epoch: 6| Step: 5
Training loss: 0.815074948568196
Validation loss: 2.4165474993469207

Epoch: 6| Step: 6
Training loss: 0.9765842282739007
Validation loss: 2.40836810732577

Epoch: 6| Step: 7
Training loss: 0.9157410232412224
Validation loss: 2.373120479032218

Epoch: 6| Step: 8
Training loss: 0.8807806415430566
Validation loss: 2.3949983130549333

Epoch: 6| Step: 9
Training loss: 0.9797124491409247
Validation loss: 2.36996071604798

Epoch: 6| Step: 10
Training loss: 1.1679134802355777
Validation loss: 2.417687517292937

Epoch: 6| Step: 11
Training loss: 0.550129823101443
Validation loss: 2.3797811429680995

Epoch: 6| Step: 12
Training loss: 0.8859417910194425
Validation loss: 2.3886334373370426

Epoch: 6| Step: 13
Training loss: 1.9057866768518494
Validation loss: 2.410789513053077

Epoch: 229| Step: 0
Training loss: 0.7035397895589889
Validation loss: 2.405219720612146

Epoch: 6| Step: 1
Training loss: 0.996940043847631
Validation loss: 2.426281449346137

Epoch: 6| Step: 2
Training loss: 0.6375306458680469
Validation loss: 2.4173173109876442

Epoch: 6| Step: 3
Training loss: 0.9662350033364908
Validation loss: 2.4234775794338765

Epoch: 6| Step: 4
Training loss: 1.0615604959176466
Validation loss: 2.4278172047128135

Epoch: 6| Step: 5
Training loss: 0.9908604194739675
Validation loss: 2.4086121629755533

Epoch: 6| Step: 6
Training loss: 0.9605416824057746
Validation loss: 2.402464785871232

Epoch: 6| Step: 7
Training loss: 0.8485014959826794
Validation loss: 2.410605605388988

Epoch: 6| Step: 8
Training loss: 0.5594532096787085
Validation loss: 2.3999126793587053

Epoch: 6| Step: 9
Training loss: 0.6986251101177222
Validation loss: 2.3732013670502368

Epoch: 6| Step: 10
Training loss: 0.8920112662951
Validation loss: 2.386652105892768

Epoch: 6| Step: 11
Training loss: 1.0120669910739044
Validation loss: 2.3687282608120843

Epoch: 6| Step: 12
Training loss: 0.8506946165815599
Validation loss: 2.404829985173319

Epoch: 6| Step: 13
Training loss: 1.9044452316008555
Validation loss: 2.4137473105879668

Epoch: 230| Step: 0
Training loss: 0.9777718037334883
Validation loss: 2.4336522814831874

Epoch: 6| Step: 1
Training loss: 1.0645508887516
Validation loss: 2.4507739074894745

Epoch: 6| Step: 2
Training loss: 0.586930996718768
Validation loss: 2.406826479740076

Epoch: 6| Step: 3
Training loss: 0.859761515308144
Validation loss: 2.378236596731977

Epoch: 6| Step: 4
Training loss: 1.0193831529881836
Validation loss: 2.362645330308825

Epoch: 6| Step: 5
Training loss: 0.5089497669366718
Validation loss: 2.3472440023670402

Epoch: 6| Step: 6
Training loss: 1.0454338744536178
Validation loss: 2.3342430264905523

Epoch: 6| Step: 7
Training loss: 0.8901325671443914
Validation loss: 2.316914030440136

Epoch: 6| Step: 8
Training loss: 1.1166690076737038
Validation loss: 2.335573379913967

Epoch: 6| Step: 9
Training loss: 1.512017272335882
Validation loss: 2.3554769302356995

Epoch: 6| Step: 10
Training loss: 0.7911622464903179
Validation loss: 2.375955417556956

Epoch: 6| Step: 11
Training loss: 1.1100189059597745
Validation loss: 2.4039373365829957

Epoch: 6| Step: 12
Training loss: 0.6503887921098422
Validation loss: 2.4152286191541226

Epoch: 6| Step: 13
Training loss: 0.7552418317709813
Validation loss: 2.456535286299382

Epoch: 231| Step: 0
Training loss: 1.2166422689073166
Validation loss: 2.4642216533282437

Epoch: 6| Step: 1
Training loss: 1.4544586296610529
Validation loss: 2.4391128530111676

Epoch: 6| Step: 2
Training loss: 0.800251594856482
Validation loss: 2.4132568871451

Epoch: 6| Step: 3
Training loss: 1.0185607734417892
Validation loss: 2.3995645738226186

Epoch: 6| Step: 4
Training loss: 0.8847285719769582
Validation loss: 2.38076782831218

Epoch: 6| Step: 5
Training loss: 0.9285069511371127
Validation loss: 2.3821522196468

Epoch: 6| Step: 6
Training loss: 0.6117048717498103
Validation loss: 2.365496857726599

Epoch: 6| Step: 7
Training loss: 1.0144606738714848
Validation loss: 2.3376112932874067

Epoch: 6| Step: 8
Training loss: 0.8544697262672913
Validation loss: 2.366298849200752

Epoch: 6| Step: 9
Training loss: 0.805411152301928
Validation loss: 2.344071165113776

Epoch: 6| Step: 10
Training loss: 1.0440614384152251
Validation loss: 2.384436733914459

Epoch: 6| Step: 11
Training loss: 0.6540919652025745
Validation loss: 2.406069142140103

Epoch: 6| Step: 12
Training loss: 0.738788934769249
Validation loss: 2.3873056628260683

Epoch: 6| Step: 13
Training loss: 0.46181417598980395
Validation loss: 2.3872640937414222

Epoch: 232| Step: 0
Training loss: 0.97266268440784
Validation loss: 2.40604628782141

Epoch: 6| Step: 1
Training loss: 1.1084731828803605
Validation loss: 2.390668384582726

Epoch: 6| Step: 2
Training loss: 0.86942319241416
Validation loss: 2.3800541090508323

Epoch: 6| Step: 3
Training loss: 0.8592694304386161
Validation loss: 2.3599578761128113

Epoch: 6| Step: 4
Training loss: 0.48795681665531354
Validation loss: 2.3481129302157795

Epoch: 6| Step: 5
Training loss: 1.2483195453250744
Validation loss: 2.396678228435839

Epoch: 6| Step: 6
Training loss: 1.1098211224223116
Validation loss: 2.345974756237543

Epoch: 6| Step: 7
Training loss: 0.8225541141066024
Validation loss: 2.3865089206785055

Epoch: 6| Step: 8
Training loss: 0.8974081030102978
Validation loss: 2.436819176556571

Epoch: 6| Step: 9
Training loss: 0.60908995588492
Validation loss: 2.412840807555941

Epoch: 6| Step: 10
Training loss: 0.761309313162477
Validation loss: 2.4318169234166245

Epoch: 6| Step: 11
Training loss: 1.0721925804398065
Validation loss: 2.4291753979378274

Epoch: 6| Step: 12
Training loss: 0.7858775227832181
Validation loss: 2.426132283753597

Epoch: 6| Step: 13
Training loss: 0.6387468113231759
Validation loss: 2.4314748816357254

Epoch: 233| Step: 0
Training loss: 0.858255454730849
Validation loss: 2.3902011715208227

Epoch: 6| Step: 1
Training loss: 0.7995001989988231
Validation loss: 2.4077323792334853

Epoch: 6| Step: 2
Training loss: 1.0015641139548594
Validation loss: 2.3874254396402965

Epoch: 6| Step: 3
Training loss: 0.851074008646166
Validation loss: 2.375843242736632

Epoch: 6| Step: 4
Training loss: 0.7970402116239919
Validation loss: 2.4045848169366146

Epoch: 6| Step: 5
Training loss: 0.9095848156061704
Validation loss: 2.3770406663777273

Epoch: 6| Step: 6
Training loss: 0.8652963379314578
Validation loss: 2.396769471185189

Epoch: 6| Step: 7
Training loss: 0.8830805008807332
Validation loss: 2.4092891918677832

Epoch: 6| Step: 8
Training loss: 0.8579651104473504
Validation loss: 2.392307151599741

Epoch: 6| Step: 9
Training loss: 0.4831756386614167
Validation loss: 2.4214952566124492

Epoch: 6| Step: 10
Training loss: 0.7482215139649226
Validation loss: 2.406050934459371

Epoch: 6| Step: 11
Training loss: 1.3877005956174724
Validation loss: 2.4058484713427295

Epoch: 6| Step: 12
Training loss: 0.9917071523870246
Validation loss: 2.4045322819744936

Epoch: 6| Step: 13
Training loss: 0.6542447880751248
Validation loss: 2.372868826833333

Epoch: 234| Step: 0
Training loss: 1.2908652906277105
Validation loss: 2.40150320877254

Epoch: 6| Step: 1
Training loss: 1.1228856244629772
Validation loss: 2.3865259491865563

Epoch: 6| Step: 2
Training loss: 0.6567634889664443
Validation loss: 2.4095007261792967

Epoch: 6| Step: 3
Training loss: 0.926016282776773
Validation loss: 2.3983539763028587

Epoch: 6| Step: 4
Training loss: 0.7236314946006892
Validation loss: 2.3647012920121053

Epoch: 6| Step: 5
Training loss: 1.128974094134199
Validation loss: 2.356165302602131

Epoch: 6| Step: 6
Training loss: 0.9024888949886588
Validation loss: 2.3552762831464444

Epoch: 6| Step: 7
Training loss: 0.8719355873194665
Validation loss: 2.372763026587134

Epoch: 6| Step: 8
Training loss: 0.5076707495406028
Validation loss: 2.35881839220669

Epoch: 6| Step: 9
Training loss: 0.9979808509323549
Validation loss: 2.378182827548273

Epoch: 6| Step: 10
Training loss: 0.7505144103545522
Validation loss: 2.36854662196224

Epoch: 6| Step: 11
Training loss: 0.799902941359291
Validation loss: 2.379591260954614

Epoch: 6| Step: 12
Training loss: 0.5868679542646692
Validation loss: 2.3963006425676165

Epoch: 6| Step: 13
Training loss: 0.5448210428121074
Validation loss: 2.3575249622456096

Epoch: 235| Step: 0
Training loss: 1.455135472338877
Validation loss: 2.3969742953083015

Epoch: 6| Step: 1
Training loss: 0.3988709056002146
Validation loss: 2.387789885391499

Epoch: 6| Step: 2
Training loss: 0.603312189572953
Validation loss: 2.3745753033222368

Epoch: 6| Step: 3
Training loss: 0.9562891983275837
Validation loss: 2.372587575233333

Epoch: 6| Step: 4
Training loss: 0.7630928361442709
Validation loss: 2.4118521096950305

Epoch: 6| Step: 5
Training loss: 0.6589848435269665
Validation loss: 2.3939174665810508

Epoch: 6| Step: 6
Training loss: 0.6067314517184638
Validation loss: 2.3999440549838185

Epoch: 6| Step: 7
Training loss: 0.8512030726646235
Validation loss: 2.444450139604325

Epoch: 6| Step: 8
Training loss: 0.8517575871695379
Validation loss: 2.4326415969084327

Epoch: 6| Step: 9
Training loss: 1.0247376897165072
Validation loss: 2.402457498184695

Epoch: 6| Step: 10
Training loss: 0.9578041225645725
Validation loss: 2.4002655439130898

Epoch: 6| Step: 11
Training loss: 1.203472235967557
Validation loss: 2.3707184672384907

Epoch: 6| Step: 12
Training loss: 0.5428966776265742
Validation loss: 2.3436246459690646

Epoch: 6| Step: 13
Training loss: 0.2810826863544285
Validation loss: 2.339463146378797

Epoch: 236| Step: 0
Training loss: 0.7069834698291818
Validation loss: 2.353601039445727

Epoch: 6| Step: 1
Training loss: 0.9281344544927785
Validation loss: 2.3426781383518134

Epoch: 6| Step: 2
Training loss: 1.0392262035854503
Validation loss: 2.3597335852609294

Epoch: 6| Step: 3
Training loss: 0.8475154285095564
Validation loss: 2.390636909739912

Epoch: 6| Step: 4
Training loss: 0.8330875193127039
Validation loss: 2.3951139985063725

Epoch: 6| Step: 5
Training loss: 0.795662087761987
Validation loss: 2.402594190779883

Epoch: 6| Step: 6
Training loss: 1.3831206587194547
Validation loss: 2.4085333529653736

Epoch: 6| Step: 7
Training loss: 0.7266037631879524
Validation loss: 2.4158547288887515

Epoch: 6| Step: 8
Training loss: 0.7990011759929573
Validation loss: 2.411078618226622

Epoch: 6| Step: 9
Training loss: 0.6134287176995024
Validation loss: 2.405658911947672

Epoch: 6| Step: 10
Training loss: 0.8471875982731248
Validation loss: 2.358185483822377

Epoch: 6| Step: 11
Training loss: 0.4411396808337854
Validation loss: 2.379986491990079

Epoch: 6| Step: 12
Training loss: 1.0458760406062222
Validation loss: 2.36794750275964

Epoch: 6| Step: 13
Training loss: 0.8988870574053368
Validation loss: 2.3461293547620463

Epoch: 237| Step: 0
Training loss: 0.581845349827622
Validation loss: 2.332718984383704

Epoch: 6| Step: 1
Training loss: 0.6603512673432335
Validation loss: 2.341069759166938

Epoch: 6| Step: 2
Training loss: 0.7898662363958614
Validation loss: 2.3424099794713826

Epoch: 6| Step: 3
Training loss: 1.3497082995582728
Validation loss: 2.3574781903798

Epoch: 6| Step: 4
Training loss: 0.9164874522988585
Validation loss: 2.3740497883820573

Epoch: 6| Step: 5
Training loss: 0.71332960852723
Validation loss: 2.3510013742523705

Epoch: 6| Step: 6
Training loss: 0.8941231675483211
Validation loss: 2.3939302937589684

Epoch: 6| Step: 7
Training loss: 0.9841827931537748
Validation loss: 2.37373710737989

Epoch: 6| Step: 8
Training loss: 0.9941136444567557
Validation loss: 2.382062562994526

Epoch: 6| Step: 9
Training loss: 0.9924897461945235
Validation loss: 2.3916971803770766

Epoch: 6| Step: 10
Training loss: 0.5216564508916589
Validation loss: 2.344977394219114

Epoch: 6| Step: 11
Training loss: 0.8113821482774719
Validation loss: 2.33347878482537

Epoch: 6| Step: 12
Training loss: 0.8035265130402736
Validation loss: 2.2992587672294458

Epoch: 6| Step: 13
Training loss: 0.44185020266587927
Validation loss: 2.3030206586063047

Epoch: 238| Step: 0
Training loss: 0.6821465131580354
Validation loss: 2.3116107540184103

Epoch: 6| Step: 1
Training loss: 0.9408964620843376
Validation loss: 2.328249949799193

Epoch: 6| Step: 2
Training loss: 0.8519498311660808
Validation loss: 2.3563086583705237

Epoch: 6| Step: 3
Training loss: 0.8732956226836298
Validation loss: 2.3651378899785147

Epoch: 6| Step: 4
Training loss: 0.6190760004149568
Validation loss: 2.383371584975629

Epoch: 6| Step: 5
Training loss: 1.2507489821532625
Validation loss: 2.421926929077257

Epoch: 6| Step: 6
Training loss: 0.9986140362238822
Validation loss: 2.4614467590703426

Epoch: 6| Step: 7
Training loss: 0.6623415919523186
Validation loss: 2.485219172112139

Epoch: 6| Step: 8
Training loss: 1.1293905202857872
Validation loss: 2.428113410801582

Epoch: 6| Step: 9
Training loss: 0.7576721690702988
Validation loss: 2.4049633780321873

Epoch: 6| Step: 10
Training loss: 0.4551697012645218
Validation loss: 2.373231064979939

Epoch: 6| Step: 11
Training loss: 0.8254534616666599
Validation loss: 2.3691539039196057

Epoch: 6| Step: 12
Training loss: 0.6991052375590714
Validation loss: 2.3517381987221064

Epoch: 6| Step: 13
Training loss: 0.8550224707812796
Validation loss: 2.324012602848855

Epoch: 239| Step: 0
Training loss: 0.6866564343748686
Validation loss: 2.3274022794953644

Epoch: 6| Step: 1
Training loss: 0.8380505958204972
Validation loss: 2.322940637755532

Epoch: 6| Step: 2
Training loss: 0.752302212623183
Validation loss: 2.32167967661241

Epoch: 6| Step: 3
Training loss: 0.7613081387773147
Validation loss: 2.345292896244213

Epoch: 6| Step: 4
Training loss: 0.7959205296732575
Validation loss: 2.364629731927632

Epoch: 6| Step: 5
Training loss: 0.8315574478976498
Validation loss: 2.3807536057297627

Epoch: 6| Step: 6
Training loss: 0.8450115098112937
Validation loss: 2.3810841002575875

Epoch: 6| Step: 7
Training loss: 0.6275169238053826
Validation loss: 2.3987911121752807

Epoch: 6| Step: 8
Training loss: 0.40494143203825794
Validation loss: 2.4134983649136594

Epoch: 6| Step: 9
Training loss: 0.9765616149898334
Validation loss: 2.3761866357089683

Epoch: 6| Step: 10
Training loss: 0.9773273372110588
Validation loss: 2.3794212336864162

Epoch: 6| Step: 11
Training loss: 1.292477563408734
Validation loss: 2.359958809794176

Epoch: 6| Step: 12
Training loss: 0.7643325562440583
Validation loss: 2.3990068987990347

Epoch: 6| Step: 13
Training loss: 0.9522091577193299
Validation loss: 2.3409395952553056

Epoch: 240| Step: 0
Training loss: 0.6168078449957616
Validation loss: 2.346246181202609

Epoch: 6| Step: 1
Training loss: 0.9999977350209335
Validation loss: 2.3542321742602272

Epoch: 6| Step: 2
Training loss: 0.9320751272586931
Validation loss: 2.3530319545406773

Epoch: 6| Step: 3
Training loss: 0.6208906261412316
Validation loss: 2.3636574923240525

Epoch: 6| Step: 4
Training loss: 0.8202366748461104
Validation loss: 2.360440505904361

Epoch: 6| Step: 5
Training loss: 1.2337442549056739
Validation loss: 2.365273398851922

Epoch: 6| Step: 6
Training loss: 0.6207749610273149
Validation loss: 2.3646633493700104

Epoch: 6| Step: 7
Training loss: 0.8583957641698808
Validation loss: 2.3354559904991032

Epoch: 6| Step: 8
Training loss: 0.5795236885603952
Validation loss: 2.3633896561046934

Epoch: 6| Step: 9
Training loss: 0.7919962514827144
Validation loss: 2.3589294486644814

Epoch: 6| Step: 10
Training loss: 0.7504015483388808
Validation loss: 2.3838426837228166

Epoch: 6| Step: 11
Training loss: 0.7553194863087441
Validation loss: 2.3639284084970256

Epoch: 6| Step: 12
Training loss: 0.74240077116696
Validation loss: 2.378500609715887

Epoch: 6| Step: 13
Training loss: 0.8521493062328148
Validation loss: 2.3988746981319236

Epoch: 241| Step: 0
Training loss: 0.9133026355494451
Validation loss: 2.439245015334659

Epoch: 6| Step: 1
Training loss: 0.5597947820508854
Validation loss: 2.416522153989698

Epoch: 6| Step: 2
Training loss: 0.7872646737062189
Validation loss: 2.390281013363962

Epoch: 6| Step: 3
Training loss: 0.7979881888689079
Validation loss: 2.355015224890648

Epoch: 6| Step: 4
Training loss: 0.5471685439159033
Validation loss: 2.3545134040645346

Epoch: 6| Step: 5
Training loss: 0.7053203219621021
Validation loss: 2.3817650213891133

Epoch: 6| Step: 6
Training loss: 0.7026729826221082
Validation loss: 2.3776967077887443

Epoch: 6| Step: 7
Training loss: 0.6676120140085485
Validation loss: 2.3738899227327486

Epoch: 6| Step: 8
Training loss: 0.9607307707931614
Validation loss: 2.401215879536083

Epoch: 6| Step: 9
Training loss: 0.670099929858638
Validation loss: 2.380359991552032

Epoch: 6| Step: 10
Training loss: 0.6114247888551831
Validation loss: 2.356225008938225

Epoch: 6| Step: 11
Training loss: 1.3345401438381095
Validation loss: 2.352473167571627

Epoch: 6| Step: 12
Training loss: 0.911975303451457
Validation loss: 2.3706889995296687

Epoch: 6| Step: 13
Training loss: 0.4509666438476155
Validation loss: 2.380738215783361

Epoch: 242| Step: 0
Training loss: 0.6254239551781114
Validation loss: 2.4068033546050187

Epoch: 6| Step: 1
Training loss: 0.8110113444728424
Validation loss: 2.431189065771673

Epoch: 6| Step: 2
Training loss: 0.7655139764746954
Validation loss: 2.4094030069069117

Epoch: 6| Step: 3
Training loss: 0.4425171738594739
Validation loss: 2.3956664538659616

Epoch: 6| Step: 4
Training loss: 1.2845516927911609
Validation loss: 2.37843175636621

Epoch: 6| Step: 5
Training loss: 0.8998425650650916
Validation loss: 2.3397335352692905

Epoch: 6| Step: 6
Training loss: 0.6694621296371746
Validation loss: 2.3584751411617737

Epoch: 6| Step: 7
Training loss: 0.6800526482172017
Validation loss: 2.348734748672629

Epoch: 6| Step: 8
Training loss: 0.7264123987178474
Validation loss: 2.3187720967245946

Epoch: 6| Step: 9
Training loss: 0.9065536779469517
Validation loss: 2.3540820833373544

Epoch: 6| Step: 10
Training loss: 0.7394783769377548
Validation loss: 2.3343225468318387

Epoch: 6| Step: 11
Training loss: 0.4656104168752396
Validation loss: 2.3682831804269107

Epoch: 6| Step: 12
Training loss: 0.9244420791851967
Validation loss: 2.345141842392144

Epoch: 6| Step: 13
Training loss: 0.8125940415171675
Validation loss: 2.35872772363134

Epoch: 243| Step: 0
Training loss: 0.5878709808818939
Validation loss: 2.356761292786302

Epoch: 6| Step: 1
Training loss: 0.49095307818973727
Validation loss: 2.392097562771062

Epoch: 6| Step: 2
Training loss: 1.356288738840131
Validation loss: 2.3803031103513987

Epoch: 6| Step: 3
Training loss: 0.7717226071057626
Validation loss: 2.3593135109402383

Epoch: 6| Step: 4
Training loss: 0.7694498396667873
Validation loss: 2.381693188231805

Epoch: 6| Step: 5
Training loss: 1.062800869697212
Validation loss: 2.3671040714702047

Epoch: 6| Step: 6
Training loss: 0.5781391760660345
Validation loss: 2.375489256312204

Epoch: 6| Step: 7
Training loss: 0.35566971935149705
Validation loss: 2.3391280773822145

Epoch: 6| Step: 8
Training loss: 0.6101625683954324
Validation loss: 2.3239882730875037

Epoch: 6| Step: 9
Training loss: 0.9481568853037269
Validation loss: 2.34554092947439

Epoch: 6| Step: 10
Training loss: 0.7738075527054271
Validation loss: 2.355049093332301

Epoch: 6| Step: 11
Training loss: 0.7086171021235852
Validation loss: 2.328587426311686

Epoch: 6| Step: 12
Training loss: 0.8341732124036222
Validation loss: 2.3294394031746095

Epoch: 6| Step: 13
Training loss: 0.7864209517801155
Validation loss: 2.3586116436824915

Epoch: 244| Step: 0
Training loss: 1.076839675988161
Validation loss: 2.3464812631665173

Epoch: 6| Step: 1
Training loss: 0.5658027327535256
Validation loss: 2.3602740595773657

Epoch: 6| Step: 2
Training loss: 0.6303662950730524
Validation loss: 2.3701290347984583

Epoch: 6| Step: 3
Training loss: 0.8181804743669051
Validation loss: 2.3937003863165174

Epoch: 6| Step: 4
Training loss: 0.937637255475773
Validation loss: 2.4115130921641748

Epoch: 6| Step: 5
Training loss: 0.7338445655153173
Validation loss: 2.4277558852314893

Epoch: 6| Step: 6
Training loss: 0.7471578309898684
Validation loss: 2.3910731979168234

Epoch: 6| Step: 7
Training loss: 0.6402403444264401
Validation loss: 2.3690418913043607

Epoch: 6| Step: 8
Training loss: 0.6291460089629023
Validation loss: 2.3445324779064887

Epoch: 6| Step: 9
Training loss: 0.6167828645860443
Validation loss: 2.3404022645315403

Epoch: 6| Step: 10
Training loss: 0.8577859579124779
Validation loss: 2.330729932584973

Epoch: 6| Step: 11
Training loss: 0.9495998920326525
Validation loss: 2.3437165573085883

Epoch: 6| Step: 12
Training loss: 0.7209249015669669
Validation loss: 2.305153698259834

Epoch: 6| Step: 13
Training loss: 0.7092061182054027
Validation loss: 2.312725919149268

Epoch: 245| Step: 0
Training loss: 0.6540730563285604
Validation loss: 2.32342715792723

Epoch: 6| Step: 1
Training loss: 0.27417576444791814
Validation loss: 2.3438710805592824

Epoch: 6| Step: 2
Training loss: 0.7867458819926142
Validation loss: 2.376698774242765

Epoch: 6| Step: 3
Training loss: 0.7367603035430598
Validation loss: 2.3936272442875572

Epoch: 6| Step: 4
Training loss: 0.807046524892975
Validation loss: 2.4098812937053835

Epoch: 6| Step: 5
Training loss: 1.2303596569322703
Validation loss: 2.3964528374745853

Epoch: 6| Step: 6
Training loss: 0.7378900288649615
Validation loss: 2.364359800408786

Epoch: 6| Step: 7
Training loss: 0.7479528861099745
Validation loss: 2.3808895814688436

Epoch: 6| Step: 8
Training loss: 0.5761619954959399
Validation loss: 2.371923506054579

Epoch: 6| Step: 9
Training loss: 0.9051524125631396
Validation loss: 2.3708992265857107

Epoch: 6| Step: 10
Training loss: 0.8728666866321232
Validation loss: 2.3401320164485435

Epoch: 6| Step: 11
Training loss: 0.7368368723601048
Validation loss: 2.3426987180521315

Epoch: 6| Step: 12
Training loss: 0.6551905208606431
Validation loss: 2.3527552273628536

Epoch: 6| Step: 13
Training loss: 0.663461525437558
Validation loss: 2.3270673676389255

Epoch: 246| Step: 0
Training loss: 1.2032189270610683
Validation loss: 2.3653366546236203

Epoch: 6| Step: 1
Training loss: 0.5606305528448677
Validation loss: 2.3754882558886647

Epoch: 6| Step: 2
Training loss: 0.5690514981056298
Validation loss: 2.3817342297110655

Epoch: 6| Step: 3
Training loss: 0.8132350970830923
Validation loss: 2.3812528420355092

Epoch: 6| Step: 4
Training loss: 0.7774694523222639
Validation loss: 2.4000933677276133

Epoch: 6| Step: 5
Training loss: 0.7186441758245405
Validation loss: 2.3886184137030644

Epoch: 6| Step: 6
Training loss: 0.7581902968172942
Validation loss: 2.3635857151639237

Epoch: 6| Step: 7
Training loss: 0.6608102031073614
Validation loss: 2.3688933528664746

Epoch: 6| Step: 8
Training loss: 0.5658531382226376
Validation loss: 2.340003356086281

Epoch: 6| Step: 9
Training loss: 0.9780402942091446
Validation loss: 2.365459729843785

Epoch: 6| Step: 10
Training loss: 0.9907600768022278
Validation loss: 2.361807474583338

Epoch: 6| Step: 11
Training loss: 0.4051612055159516
Validation loss: 2.37230015108984

Epoch: 6| Step: 12
Training loss: 0.7328922643135881
Validation loss: 2.375412602359403

Epoch: 6| Step: 13
Training loss: 0.4720562523613152
Validation loss: 2.3876622123377564

Epoch: 247| Step: 0
Training loss: 0.7513650551535898
Validation loss: 2.3708281985204818

Epoch: 6| Step: 1
Training loss: 0.8358189151112381
Validation loss: 2.351516685575103

Epoch: 6| Step: 2
Training loss: 0.6754106376334933
Validation loss: 2.3706639597996912

Epoch: 6| Step: 3
Training loss: 0.754065462210157
Validation loss: 2.3381864037295537

Epoch: 6| Step: 4
Training loss: 0.5925397585152368
Validation loss: 2.3890372154978383

Epoch: 6| Step: 5
Training loss: 0.7895938859165633
Validation loss: 2.357221742574368

Epoch: 6| Step: 6
Training loss: 0.8650260312788506
Validation loss: 2.3756807158078717

Epoch: 6| Step: 7
Training loss: 0.611601137861699
Validation loss: 2.405652150256473

Epoch: 6| Step: 8
Training loss: 1.158256542395647
Validation loss: 2.3722583660729817

Epoch: 6| Step: 9
Training loss: 0.8694702209278138
Validation loss: 2.3943820010142547

Epoch: 6| Step: 10
Training loss: 0.396052947943058
Validation loss: 2.35826606824866

Epoch: 6| Step: 11
Training loss: 0.8151291710346583
Validation loss: 2.3577301696230597

Epoch: 6| Step: 12
Training loss: 0.5027638578624821
Validation loss: 2.376743438814954

Epoch: 6| Step: 13
Training loss: 0.769570790160904
Validation loss: 2.3810932521999444

Epoch: 248| Step: 0
Training loss: 0.7616105222842668
Validation loss: 2.3735136185416184

Epoch: 6| Step: 1
Training loss: 0.6840860610396675
Validation loss: 2.377797535996716

Epoch: 6| Step: 2
Training loss: 0.5741187287496206
Validation loss: 2.3736591332005372

Epoch: 6| Step: 3
Training loss: 0.8568255668866434
Validation loss: 2.3596103439191274

Epoch: 6| Step: 4
Training loss: 0.6828615463414694
Validation loss: 2.351420494618429

Epoch: 6| Step: 5
Training loss: 0.9399601446488515
Validation loss: 2.334371464015497

Epoch: 6| Step: 6
Training loss: 0.8904877272439702
Validation loss: 2.337545741964416

Epoch: 6| Step: 7
Training loss: 0.803986586698456
Validation loss: 2.3189303959347467

Epoch: 6| Step: 8
Training loss: 0.7847411923286415
Validation loss: 2.3020979782868842

Epoch: 6| Step: 9
Training loss: 0.7103824335018448
Validation loss: 2.310373272863675

Epoch: 6| Step: 10
Training loss: 0.31650984210339406
Validation loss: 2.3282420879177645

Epoch: 6| Step: 11
Training loss: 0.5783086433508795
Validation loss: 2.3524011134501293

Epoch: 6| Step: 12
Training loss: 1.1023672965148577
Validation loss: 2.3075597197125415

Epoch: 6| Step: 13
Training loss: 0.460187851965398
Validation loss: 2.3498393572671232

Epoch: 249| Step: 0
Training loss: 0.40577475553242803
Validation loss: 2.373511800726541

Epoch: 6| Step: 1
Training loss: 0.8145334766737291
Validation loss: 2.4216620259979815

Epoch: 6| Step: 2
Training loss: 0.9305565562804299
Validation loss: 2.4551400182466767

Epoch: 6| Step: 3
Training loss: 1.208059521048729
Validation loss: 2.4313383597612437

Epoch: 6| Step: 4
Training loss: 0.7582526747457969
Validation loss: 2.454771277565641

Epoch: 6| Step: 5
Training loss: 0.8578561017849258
Validation loss: 2.4539179375068216

Epoch: 6| Step: 6
Training loss: 0.8408565712796701
Validation loss: 2.44703970137027

Epoch: 6| Step: 7
Training loss: 0.5694757096952219
Validation loss: 2.3685836408458893

Epoch: 6| Step: 8
Training loss: 0.5335888148871284
Validation loss: 2.3747097522382687

Epoch: 6| Step: 9
Training loss: 0.8258781903117093
Validation loss: 2.314167608737368

Epoch: 6| Step: 10
Training loss: 0.6767474857659874
Validation loss: 2.3078239577101844

Epoch: 6| Step: 11
Training loss: 0.6541519915601094
Validation loss: 2.3068914338310478

Epoch: 6| Step: 12
Training loss: 0.5977222181825771
Validation loss: 2.3259605636231684

Epoch: 6| Step: 13
Training loss: 0.5025394740660813
Validation loss: 2.306361804636132

Epoch: 250| Step: 0
Training loss: 0.5620970872459823
Validation loss: 2.3202498298966163

Epoch: 6| Step: 1
Training loss: 0.5297443708199029
Validation loss: 2.307842206641914

Epoch: 6| Step: 2
Training loss: 0.5322382094482504
Validation loss: 2.3344252989686862

Epoch: 6| Step: 3
Training loss: 0.6209281844662774
Validation loss: 2.3676052287408687

Epoch: 6| Step: 4
Training loss: 0.5069597273167549
Validation loss: 2.3759996688294667

Epoch: 6| Step: 5
Training loss: 0.7970432029176334
Validation loss: 2.372323092227317

Epoch: 6| Step: 6
Training loss: 0.967045083599592
Validation loss: 2.394681670507239

Epoch: 6| Step: 7
Training loss: 1.0161628472751363
Validation loss: 2.3510570599568275

Epoch: 6| Step: 8
Training loss: 0.6548099157557823
Validation loss: 2.351891948590081

Epoch: 6| Step: 9
Training loss: 1.1439011437445792
Validation loss: 2.3647024997312145

Epoch: 6| Step: 10
Training loss: 0.530131902475716
Validation loss: 2.348778205194948

Epoch: 6| Step: 11
Training loss: 0.6368799532097799
Validation loss: 2.3522204486167

Epoch: 6| Step: 12
Training loss: 0.8998435586490947
Validation loss: 2.325048493055912

Epoch: 6| Step: 13
Training loss: 0.5407587536417675
Validation loss: 2.3284102845469623

Epoch: 251| Step: 0
Training loss: 0.776833870214072
Validation loss: 2.3170478708422793

Epoch: 6| Step: 1
Training loss: 0.8495647199449207
Validation loss: 2.3179061298280144

Epoch: 6| Step: 2
Training loss: 0.5265013005493273
Validation loss: 2.3292463164801394

Epoch: 6| Step: 3
Training loss: 0.46396672837202413
Validation loss: 2.3430221335269974

Epoch: 6| Step: 4
Training loss: 1.0352284532233256
Validation loss: 2.3440702844357313

Epoch: 6| Step: 5
Training loss: 0.6603933506729665
Validation loss: 2.354603488290948

Epoch: 6| Step: 6
Training loss: 0.4849376794259415
Validation loss: 2.390482213619857

Epoch: 6| Step: 7
Training loss: 0.8187916781468004
Validation loss: 2.3894208083924697

Epoch: 6| Step: 8
Training loss: 0.6841000235326836
Validation loss: 2.364421994197055

Epoch: 6| Step: 9
Training loss: 0.6231864366309012
Validation loss: 2.3687009226596287

Epoch: 6| Step: 10
Training loss: 0.8063289973273935
Validation loss: 2.3550301384950814

Epoch: 6| Step: 11
Training loss: 0.6816087950349483
Validation loss: 2.3267061521546486

Epoch: 6| Step: 12
Training loss: 0.40365869029908785
Validation loss: 2.3327714969505933

Epoch: 6| Step: 13
Training loss: 0.9266365060311904
Validation loss: 2.314579887236568

Epoch: 252| Step: 0
Training loss: 0.510898456773277
Validation loss: 2.3245021747563612

Epoch: 6| Step: 1
Training loss: 0.7017796679437018
Validation loss: 2.3388911920446396

Epoch: 6| Step: 2
Training loss: 0.33477138349639135
Validation loss: 2.3353825611440464

Epoch: 6| Step: 3
Training loss: 0.6719275609238387
Validation loss: 2.339269056880519

Epoch: 6| Step: 4
Training loss: 0.4951173981735714
Validation loss: 2.3636909598206377

Epoch: 6| Step: 5
Training loss: 0.49882020936568855
Validation loss: 2.349066368918056

Epoch: 6| Step: 6
Training loss: 0.88459435967431
Validation loss: 2.3294884713226702

Epoch: 6| Step: 7
Training loss: 0.6013944316762269
Validation loss: 2.3798707606107627

Epoch: 6| Step: 8
Training loss: 0.39390917164476763
Validation loss: 2.348370297400988

Epoch: 6| Step: 9
Training loss: 0.5884259596881689
Validation loss: 2.377774240129965

Epoch: 6| Step: 10
Training loss: 0.946314257275536
Validation loss: 2.361945053888796

Epoch: 6| Step: 11
Training loss: 0.8821861948671865
Validation loss: 2.361306598904182

Epoch: 6| Step: 12
Training loss: 0.7411502617287961
Validation loss: 2.364884492915666

Epoch: 6| Step: 13
Training loss: 1.0366626646714887
Validation loss: 2.343147746270175

Epoch: 253| Step: 0
Training loss: 0.6528038640818348
Validation loss: 2.3292513793771046

Epoch: 6| Step: 1
Training loss: 0.46439994334287077
Validation loss: 2.3215183353614766

Epoch: 6| Step: 2
Training loss: 0.6462061764598729
Validation loss: 2.2944941092478532

Epoch: 6| Step: 3
Training loss: 1.146584345603474
Validation loss: 2.3315017326310734

Epoch: 6| Step: 4
Training loss: 0.6208588497840788
Validation loss: 2.3546799454006218

Epoch: 6| Step: 5
Training loss: 0.6166281519495507
Validation loss: 2.331371818556914

Epoch: 6| Step: 6
Training loss: 0.40819082287224556
Validation loss: 2.368227897606591

Epoch: 6| Step: 7
Training loss: 0.754402748235994
Validation loss: 2.3962503866525022

Epoch: 6| Step: 8
Training loss: 0.7604026967337446
Validation loss: 2.4250308304740225

Epoch: 6| Step: 9
Training loss: 0.9857677416345267
Validation loss: 2.3843574516936448

Epoch: 6| Step: 10
Training loss: 0.45635558173923774
Validation loss: 2.342559584880015

Epoch: 6| Step: 11
Training loss: 0.5124300025031346
Validation loss: 2.3573097861435

Epoch: 6| Step: 12
Training loss: 0.43614060514110625
Validation loss: 2.3107654204418386

Epoch: 6| Step: 13
Training loss: 0.5376625680150378
Validation loss: 2.3491558601898443

Epoch: 254| Step: 0
Training loss: 1.043056127195601
Validation loss: 2.3393757724816853

Epoch: 6| Step: 1
Training loss: 0.5170348573145565
Validation loss: 2.322545421468833

Epoch: 6| Step: 2
Training loss: 0.7189749075579108
Validation loss: 2.3435915077792036

Epoch: 6| Step: 3
Training loss: 0.47093739358335024
Validation loss: 2.3502815106332444

Epoch: 6| Step: 4
Training loss: 0.8609823627171841
Validation loss: 2.3626685105913374

Epoch: 6| Step: 5
Training loss: 0.8961876604646847
Validation loss: 2.3493052286187797

Epoch: 6| Step: 6
Training loss: 0.7093393997468371
Validation loss: 2.3546890244086147

Epoch: 6| Step: 7
Training loss: 0.6579483625867472
Validation loss: 2.3667680749249715

Epoch: 6| Step: 8
Training loss: 0.5797931472050301
Validation loss: 2.348263999284971

Epoch: 6| Step: 9
Training loss: 0.42268403503134905
Validation loss: 2.3160608586073286

Epoch: 6| Step: 10
Training loss: 0.46467542405589635
Validation loss: 2.3318665049943177

Epoch: 6| Step: 11
Training loss: 0.9422553574148387
Validation loss: 2.3449358887110776

Epoch: 6| Step: 12
Training loss: 0.41447929781464043
Validation loss: 2.3208346044127075

Epoch: 6| Step: 13
Training loss: 0.3272675482428657
Validation loss: 2.31825143760984

Epoch: 255| Step: 0
Training loss: 0.5152473511699498
Validation loss: 2.3515906484353666

Epoch: 6| Step: 1
Training loss: 1.0653288152759632
Validation loss: 2.3339067143183074

Epoch: 6| Step: 2
Training loss: 0.6469717349639666
Validation loss: 2.341154876494047

Epoch: 6| Step: 3
Training loss: 0.5005093007209604
Validation loss: 2.3424991477412913

Epoch: 6| Step: 4
Training loss: 0.6900756446174502
Validation loss: 2.3813610802566623

Epoch: 6| Step: 5
Training loss: 0.5990138871234166
Validation loss: 2.3581757496917137

Epoch: 6| Step: 6
Training loss: 0.4507808724968716
Validation loss: 2.3820492155868083

Epoch: 6| Step: 7
Training loss: 0.6062315289151267
Validation loss: 2.37979072570617

Epoch: 6| Step: 8
Training loss: 0.6112241321387022
Validation loss: 2.3802443741902697

Epoch: 6| Step: 9
Training loss: 0.8061260586478909
Validation loss: 2.3592450875504225

Epoch: 6| Step: 10
Training loss: 0.642866469970282
Validation loss: 2.351300893125061

Epoch: 6| Step: 11
Training loss: 0.6822980099060431
Validation loss: 2.346405174787436

Epoch: 6| Step: 12
Training loss: 0.36358685098814997
Validation loss: 2.330906542263091

Epoch: 6| Step: 13
Training loss: 0.7250083791314353
Validation loss: 2.305744769715335

Epoch: 256| Step: 0
Training loss: 0.6132835825493063
Validation loss: 2.3227754292720335

Epoch: 6| Step: 1
Training loss: 0.5866707346605377
Validation loss: 2.2801878694707267

Epoch: 6| Step: 2
Training loss: 0.6872644671211059
Validation loss: 2.31119058171376

Epoch: 6| Step: 3
Training loss: 0.6127129612704328
Validation loss: 2.3146249220244135

Epoch: 6| Step: 4
Training loss: 0.5970269923394024
Validation loss: 2.2982398582004286

Epoch: 6| Step: 5
Training loss: 0.8420307516045935
Validation loss: 2.310806395896508

Epoch: 6| Step: 6
Training loss: 0.7365050166620244
Validation loss: 2.3626539376279334

Epoch: 6| Step: 7
Training loss: 0.5726547220373651
Validation loss: 2.364223230727799

Epoch: 6| Step: 8
Training loss: 0.513378973589525
Validation loss: 2.3556132321169394

Epoch: 6| Step: 9
Training loss: 0.5270955950048326
Validation loss: 2.359568792679123

Epoch: 6| Step: 10
Training loss: 0.6182927243332316
Validation loss: 2.323012794533732

Epoch: 6| Step: 11
Training loss: 0.584292429430071
Validation loss: 2.3325303665687036

Epoch: 6| Step: 12
Training loss: 0.9974024235413891
Validation loss: 2.321732161160033

Epoch: 6| Step: 13
Training loss: 0.2038009108377979
Validation loss: 2.258964100400096

Epoch: 257| Step: 0
Training loss: 0.5437848660921158
Validation loss: 2.2946385214481566

Epoch: 6| Step: 1
Training loss: 0.40235450878387846
Validation loss: 2.3080541405078008

Epoch: 6| Step: 2
Training loss: 0.6672324198982801
Validation loss: 2.2784749209856185

Epoch: 6| Step: 3
Training loss: 0.5538334248477945
Validation loss: 2.2699754546521036

Epoch: 6| Step: 4
Training loss: 0.541134211905274
Validation loss: 2.3107522713982394

Epoch: 6| Step: 5
Training loss: 0.8751299625338301
Validation loss: 2.304763587459033

Epoch: 6| Step: 6
Training loss: 0.5632208867208468
Validation loss: 2.293094315235069

Epoch: 6| Step: 7
Training loss: 1.0416100041555072
Validation loss: 2.2917859923618744

Epoch: 6| Step: 8
Training loss: 0.6104185998341368
Validation loss: 2.3055710411696606

Epoch: 6| Step: 9
Training loss: 0.5928885082690145
Validation loss: 2.3198244171156652

Epoch: 6| Step: 10
Training loss: 0.5981291103321458
Validation loss: 2.305959451143789

Epoch: 6| Step: 11
Training loss: 0.38587244466214177
Validation loss: 2.3355282924334837

Epoch: 6| Step: 12
Training loss: 0.7035727029253599
Validation loss: 2.349677116123942

Epoch: 6| Step: 13
Training loss: 0.421502354956957
Validation loss: 2.3504734397603335

Epoch: 258| Step: 0
Training loss: 0.5413737299676767
Validation loss: 2.351284813217345

Epoch: 6| Step: 1
Training loss: 0.8090850885272465
Validation loss: 2.3103027958221847

Epoch: 6| Step: 2
Training loss: 0.5722436477555215
Validation loss: 2.267319104934949

Epoch: 6| Step: 3
Training loss: 0.5038822671077104
Validation loss: 2.252041923598566

Epoch: 6| Step: 4
Training loss: 0.5226302398459112
Validation loss: 2.340859511176151

Epoch: 6| Step: 5
Training loss: 0.8505957829532991
Validation loss: 2.314837651371398

Epoch: 6| Step: 6
Training loss: 0.5973599266518067
Validation loss: 2.301380109270096

Epoch: 6| Step: 7
Training loss: 0.45169293258923876
Validation loss: 2.3199547004626537

Epoch: 6| Step: 8
Training loss: 0.5547050419572271
Validation loss: 2.314766876663183

Epoch: 6| Step: 9
Training loss: 0.38911558348293523
Validation loss: 2.338612268149832

Epoch: 6| Step: 10
Training loss: 0.6470642715941276
Validation loss: 2.372629659155118

Epoch: 6| Step: 11
Training loss: 0.8542331847985525
Validation loss: 2.3533811406629366

Epoch: 6| Step: 12
Training loss: 0.3906489174196405
Validation loss: 2.3153524081730534

Epoch: 6| Step: 13
Training loss: 0.8595786113550762
Validation loss: 2.347066239237108

Epoch: 259| Step: 0
Training loss: 0.5662102721974576
Validation loss: 2.326266318516454

Epoch: 6| Step: 1
Training loss: 0.6035203161952333
Validation loss: 2.3240303744282746

Epoch: 6| Step: 2
Training loss: 0.5625964717789617
Validation loss: 2.2890322549304294

Epoch: 6| Step: 3
Training loss: 0.5239600235271558
Validation loss: 2.3143647426561036

Epoch: 6| Step: 4
Training loss: 0.6062459080351544
Validation loss: 2.3196226588655837

Epoch: 6| Step: 5
Training loss: 0.37618592613335894
Validation loss: 2.3133028483116123

Epoch: 6| Step: 6
Training loss: 0.4186260011330107
Validation loss: 2.294588829839606

Epoch: 6| Step: 7
Training loss: 0.5236740147317717
Validation loss: 2.314024890573178

Epoch: 6| Step: 8
Training loss: 0.3469293689218204
Validation loss: 2.282307650331339

Epoch: 6| Step: 9
Training loss: 1.0664078708957747
Validation loss: 2.2993969499442835

Epoch: 6| Step: 10
Training loss: 0.638123419682174
Validation loss: 2.2708127216631597

Epoch: 6| Step: 11
Training loss: 0.3835102262289855
Validation loss: 2.2912765211845763

Epoch: 6| Step: 12
Training loss: 0.7961954697601521
Validation loss: 2.286946936120151

Epoch: 6| Step: 13
Training loss: 0.7141430031036052
Validation loss: 2.3079341567123595

Epoch: 260| Step: 0
Training loss: 0.4933065076517458
Validation loss: 2.3269304623346554

Epoch: 6| Step: 1
Training loss: 0.4764614779851321
Validation loss: 2.295600137174656

Epoch: 6| Step: 2
Training loss: 0.9120403647608614
Validation loss: 2.309938068704128

Epoch: 6| Step: 3
Training loss: 0.6956398011421172
Validation loss: 2.2999621960884595

Epoch: 6| Step: 4
Training loss: 0.47845212554005034
Validation loss: 2.3211902554566395

Epoch: 6| Step: 5
Training loss: 0.8338417806823347
Validation loss: 2.2881322354492397

Epoch: 6| Step: 6
Training loss: 0.5190834180370798
Validation loss: 2.3027333062290607

Epoch: 6| Step: 7
Training loss: 0.41829688124578124
Validation loss: 2.292920553957946

Epoch: 6| Step: 8
Training loss: 0.27569673988599536
Validation loss: 2.292638356405361

Epoch: 6| Step: 9
Training loss: 0.8732126236503311
Validation loss: 2.275319365782884

Epoch: 6| Step: 10
Training loss: 0.36313462118248774
Validation loss: 2.3065972081802277

Epoch: 6| Step: 11
Training loss: 0.6779665150883595
Validation loss: 2.319406696580858

Epoch: 6| Step: 12
Training loss: 0.47267106718688073
Validation loss: 2.3041681287405904

Epoch: 6| Step: 13
Training loss: 0.24178110912487022
Validation loss: 2.320341999254107

Epoch: 261| Step: 0
Training loss: 0.7015026236897656
Validation loss: 2.342778984925375

Epoch: 6| Step: 1
Training loss: 0.36483007891443503
Validation loss: 2.321074888829014

Epoch: 6| Step: 2
Training loss: 0.47595682897660896
Validation loss: 2.343344533979845

Epoch: 6| Step: 3
Training loss: 0.5962877750226643
Validation loss: 2.3285424832072183

Epoch: 6| Step: 4
Training loss: 0.3569630455463626
Validation loss: 2.321862297711782

Epoch: 6| Step: 5
Training loss: 0.9631195415265408
Validation loss: 2.308837129334479

Epoch: 6| Step: 6
Training loss: 0.6646776379569685
Validation loss: 2.3165612724937064

Epoch: 6| Step: 7
Training loss: 0.44882370537423644
Validation loss: 2.28688706391468

Epoch: 6| Step: 8
Training loss: 0.5021051851901729
Validation loss: 2.2780060369463495

Epoch: 6| Step: 9
Training loss: 0.26773887873151725
Validation loss: 2.2643843674457833

Epoch: 6| Step: 10
Training loss: 0.5594461779355532
Validation loss: 2.2801231155373105

Epoch: 6| Step: 11
Training loss: 0.6869839118367533
Validation loss: 2.2697610015695946

Epoch: 6| Step: 12
Training loss: 0.792599070400566
Validation loss: 2.2562233041649677

Epoch: 6| Step: 13
Training loss: 0.4089474804403828
Validation loss: 2.2575608456813936

Epoch: 262| Step: 0
Training loss: 0.5318991677769898
Validation loss: 2.2558725263715367

Epoch: 6| Step: 1
Training loss: 0.7057162327068017
Validation loss: 2.2358086883669115

Epoch: 6| Step: 2
Training loss: 0.5330807891348878
Validation loss: 2.280891598765904

Epoch: 6| Step: 3
Training loss: 0.6604042715921083
Validation loss: 2.28189399789187

Epoch: 6| Step: 4
Training loss: 0.438372168401009
Validation loss: 2.286002584309502

Epoch: 6| Step: 5
Training loss: 0.3627700901133782
Validation loss: 2.33744770272532

Epoch: 6| Step: 6
Training loss: 0.750879804829211
Validation loss: 2.308469184416135

Epoch: 6| Step: 7
Training loss: 0.5343978129642671
Validation loss: 2.3000994256546896

Epoch: 6| Step: 8
Training loss: 0.6630305181386795
Validation loss: 2.307338586808553

Epoch: 6| Step: 9
Training loss: 0.7302022029457934
Validation loss: 2.304857956089126

Epoch: 6| Step: 10
Training loss: 0.6609807255094587
Validation loss: 2.3142382876723997

Epoch: 6| Step: 11
Training loss: 0.5391644644016687
Validation loss: 2.2972872711960237

Epoch: 6| Step: 12
Training loss: 0.2997833020662848
Validation loss: 2.29065101207089

Epoch: 6| Step: 13
Training loss: 0.536062739783713
Validation loss: 2.2870345463994117

Epoch: 263| Step: 0
Training loss: 0.440247610141998
Validation loss: 2.3067579954762434

Epoch: 6| Step: 1
Training loss: 0.6644934209751949
Validation loss: 2.3176164052793555

Epoch: 6| Step: 2
Training loss: 0.48242598311802526
Validation loss: 2.269228490550849

Epoch: 6| Step: 3
Training loss: 0.5556591013601434
Validation loss: 2.2737120187151945

Epoch: 6| Step: 4
Training loss: 0.6910317047646213
Validation loss: 2.2853381164221354

Epoch: 6| Step: 5
Training loss: 0.6083429840924901
Validation loss: 2.327996695782662

Epoch: 6| Step: 6
Training loss: 0.8013266218211679
Validation loss: 2.312340568760359

Epoch: 6| Step: 7
Training loss: 0.7908450849388186
Validation loss: 2.311548339308134

Epoch: 6| Step: 8
Training loss: 0.38000176535999414
Validation loss: 2.2898319234577005

Epoch: 6| Step: 9
Training loss: 0.373678581278106
Validation loss: 2.350208757737396

Epoch: 6| Step: 10
Training loss: 0.5006062289563317
Validation loss: 2.34669933138723

Epoch: 6| Step: 11
Training loss: 0.4661150465731436
Validation loss: 2.337958157403782

Epoch: 6| Step: 12
Training loss: 0.3138421324608755
Validation loss: 2.356190597600538

Epoch: 6| Step: 13
Training loss: 0.7459931230841698
Validation loss: 2.3612348688961977

Epoch: 264| Step: 0
Training loss: 0.849629158578932
Validation loss: 2.336303643830364

Epoch: 6| Step: 1
Training loss: 0.4812559176985305
Validation loss: 2.2968965202497014

Epoch: 6| Step: 2
Training loss: 0.555419063357853
Validation loss: 2.285034231401304

Epoch: 6| Step: 3
Training loss: 0.534370764776925
Validation loss: 2.316608426149956

Epoch: 6| Step: 4
Training loss: 0.5000435690970646
Validation loss: 2.308072538678578

Epoch: 6| Step: 5
Training loss: 0.5278934016090482
Validation loss: 2.3261546644913507

Epoch: 6| Step: 6
Training loss: 0.4650734726480726
Validation loss: 2.286408042723715

Epoch: 6| Step: 7
Training loss: 0.5642157454768524
Validation loss: 2.3041993895333333

Epoch: 6| Step: 8
Training loss: 0.5595458659479093
Validation loss: 2.292182169310102

Epoch: 6| Step: 9
Training loss: 0.7384767223116852
Validation loss: 2.296739707223015

Epoch: 6| Step: 10
Training loss: 0.31426612553765026
Validation loss: 2.3352676640088044

Epoch: 6| Step: 11
Training loss: 0.5969091495511194
Validation loss: 2.3336775471079676

Epoch: 6| Step: 12
Training loss: 0.5151045224220994
Validation loss: 2.326259696343239

Epoch: 6| Step: 13
Training loss: 0.8532418307280191
Validation loss: 2.3399271600494798

Epoch: 265| Step: 0
Training loss: 0.41479792153192707
Validation loss: 2.310732067300944

Epoch: 6| Step: 1
Training loss: 0.895797033831282
Validation loss: 2.2980832930161994

Epoch: 6| Step: 2
Training loss: 0.5741332892316381
Validation loss: 2.2803566858479885

Epoch: 6| Step: 3
Training loss: 0.5991898351902141
Validation loss: 2.2602878817595022

Epoch: 6| Step: 4
Training loss: 0.7527813202452818
Validation loss: 2.2428770208130584

Epoch: 6| Step: 5
Training loss: 0.5008919627718594
Validation loss: 2.2842958675903193

Epoch: 6| Step: 6
Training loss: 0.4870040210630327
Validation loss: 2.289871631111847

Epoch: 6| Step: 7
Training loss: 0.4635009283387765
Validation loss: 2.2986606674181838

Epoch: 6| Step: 8
Training loss: 0.4030766894350478
Validation loss: 2.2879482223974206

Epoch: 6| Step: 9
Training loss: 0.7302953340849626
Validation loss: 2.320274640812992

Epoch: 6| Step: 10
Training loss: 0.44348957653870713
Validation loss: 2.333306012088893

Epoch: 6| Step: 11
Training loss: 0.3276423583135164
Validation loss: 2.3057056812111254

Epoch: 6| Step: 12
Training loss: 0.3987165670519761
Validation loss: 2.280892662597827

Epoch: 6| Step: 13
Training loss: 0.6684570981256244
Validation loss: 2.3068321253910518

Epoch: 266| Step: 0
Training loss: 0.566040236502048
Validation loss: 2.2835544359519586

Epoch: 6| Step: 1
Training loss: 0.37380827848075443
Validation loss: 2.2966612459053253

Epoch: 6| Step: 2
Training loss: 0.6413589320693226
Validation loss: 2.298457380453244

Epoch: 6| Step: 3
Training loss: 0.3585571852182578
Validation loss: 2.29179416499455

Epoch: 6| Step: 4
Training loss: 0.7219244886336597
Validation loss: 2.284483111628474

Epoch: 6| Step: 5
Training loss: 0.40208278451727275
Validation loss: 2.342540110928018

Epoch: 6| Step: 6
Training loss: 0.5327942227000244
Validation loss: 2.3381933528462606

Epoch: 6| Step: 7
Training loss: 0.20759718395771248
Validation loss: 2.3158223676002527

Epoch: 6| Step: 8
Training loss: 0.7143510465035283
Validation loss: 2.326018354362822

Epoch: 6| Step: 9
Training loss: 0.5843439940524437
Validation loss: 2.2933199393924495

Epoch: 6| Step: 10
Training loss: 0.6813813511621207
Validation loss: 2.303174408751828

Epoch: 6| Step: 11
Training loss: 0.5689394897204881
Validation loss: 2.3268642256029812

Epoch: 6| Step: 12
Training loss: 0.2904571191881547
Validation loss: 2.314131061490783

Epoch: 6| Step: 13
Training loss: 1.0371389151351518
Validation loss: 2.2918624600385136

Epoch: 267| Step: 0
Training loss: 0.5699370729277691
Validation loss: 2.2805855373753126

Epoch: 6| Step: 1
Training loss: 0.2682650304478108
Validation loss: 2.325179349747828

Epoch: 6| Step: 2
Training loss: 0.6861227719435304
Validation loss: 2.3552004135939213

Epoch: 6| Step: 3
Training loss: 0.7999129262863834
Validation loss: 2.3251624563221593

Epoch: 6| Step: 4
Training loss: 0.7554888149622607
Validation loss: 2.3355252793258683

Epoch: 6| Step: 5
Training loss: 0.29441332391456704
Validation loss: 2.281308329453599

Epoch: 6| Step: 6
Training loss: 0.4831695785534503
Validation loss: 2.246291708620319

Epoch: 6| Step: 7
Training loss: 0.5929499807892885
Validation loss: 2.255480895165705

Epoch: 6| Step: 8
Training loss: 0.6381838038939617
Validation loss: 2.2462370738937305

Epoch: 6| Step: 9
Training loss: 0.4771646853665758
Validation loss: 2.2401404162753207

Epoch: 6| Step: 10
Training loss: 0.723599740738556
Validation loss: 2.232525815912434

Epoch: 6| Step: 11
Training loss: 0.37074208914020246
Validation loss: 2.258968866300311

Epoch: 6| Step: 12
Training loss: 0.5735270687489816
Validation loss: 2.290395274572836

Epoch: 6| Step: 13
Training loss: 0.4293729844802572
Validation loss: 2.3339626354321155

Epoch: 268| Step: 0
Training loss: 0.273454760960321
Validation loss: 2.3461275561595545

Epoch: 6| Step: 1
Training loss: 0.5060973031324716
Validation loss: 2.3208630658806038

Epoch: 6| Step: 2
Training loss: 0.5655640226763723
Validation loss: 2.3478054102781

Epoch: 6| Step: 3
Training loss: 0.47857363602245045
Validation loss: 2.3104269157990203

Epoch: 6| Step: 4
Training loss: 0.6012276051686731
Validation loss: 2.2958038077901235

Epoch: 6| Step: 5
Training loss: 0.283754929277062
Validation loss: 2.2572843275414582

Epoch: 6| Step: 6
Training loss: 0.4142835135178295
Validation loss: 2.3032643641543737

Epoch: 6| Step: 7
Training loss: 0.6957946134595056
Validation loss: 2.274478989676714

Epoch: 6| Step: 8
Training loss: 0.7629592966169427
Validation loss: 2.298997349546948

Epoch: 6| Step: 9
Training loss: 0.8399159245195531
Validation loss: 2.306243785937933

Epoch: 6| Step: 10
Training loss: 0.5712115373747213
Validation loss: 2.295879680480698

Epoch: 6| Step: 11
Training loss: 0.628103371622638
Validation loss: 2.3093822495730274

Epoch: 6| Step: 12
Training loss: 0.4445643917125546
Validation loss: 2.3459269126301594

Epoch: 6| Step: 13
Training loss: 0.3794481983300883
Validation loss: 2.3248852766879815

Epoch: 269| Step: 0
Training loss: 0.5779045818892469
Validation loss: 2.307786256624271

Epoch: 6| Step: 1
Training loss: 0.6986460978007599
Validation loss: 2.334549874226812

Epoch: 6| Step: 2
Training loss: 0.353404011678729
Validation loss: 2.2943383454931476

Epoch: 6| Step: 3
Training loss: 0.5968905761443919
Validation loss: 2.288162369732314

Epoch: 6| Step: 4
Training loss: 0.5681919493638969
Validation loss: 2.318066578400498

Epoch: 6| Step: 5
Training loss: 0.37214295486635096
Validation loss: 2.264903035053117

Epoch: 6| Step: 6
Training loss: 0.35190792068641774
Validation loss: 2.3036927715773343

Epoch: 6| Step: 7
Training loss: 0.5197366007480912
Validation loss: 2.3239261091725902

Epoch: 6| Step: 8
Training loss: 0.658088198626389
Validation loss: 2.3248694209746827

Epoch: 6| Step: 9
Training loss: 0.5165756017150757
Validation loss: 2.348836016818944

Epoch: 6| Step: 10
Training loss: 0.41392414012593143
Validation loss: 2.3353862319805465

Epoch: 6| Step: 11
Training loss: 0.8020307515401237
Validation loss: 2.346870135001091

Epoch: 6| Step: 12
Training loss: 0.5292237291082122
Validation loss: 2.342970851884161

Epoch: 6| Step: 13
Training loss: 0.2418203031316663
Validation loss: 2.3578938381839722

Epoch: 270| Step: 0
Training loss: 0.36627054365172046
Validation loss: 2.3423917349897594

Epoch: 6| Step: 1
Training loss: 0.41800037157462
Validation loss: 2.345581419840623

Epoch: 6| Step: 2
Training loss: 0.6011062229291304
Validation loss: 2.3076224394964657

Epoch: 6| Step: 3
Training loss: 0.5127465504065748
Validation loss: 2.3136353115678245

Epoch: 6| Step: 4
Training loss: 0.40915927517398326
Validation loss: 2.3318790391545154

Epoch: 6| Step: 5
Training loss: 0.6259749913902621
Validation loss: 2.3019906654873914

Epoch: 6| Step: 6
Training loss: 0.5217638445590682
Validation loss: 2.307487270799313

Epoch: 6| Step: 7
Training loss: 0.23971836372566158
Validation loss: 2.2797789157746027

Epoch: 6| Step: 8
Training loss: 0.5962590859478608
Validation loss: 2.2662694877868663

Epoch: 6| Step: 9
Training loss: 0.387797114077036
Validation loss: 2.2651039788938054

Epoch: 6| Step: 10
Training loss: 0.493427093159359
Validation loss: 2.3087404154989826

Epoch: 6| Step: 11
Training loss: 0.7478466512977572
Validation loss: 2.2954616142154434

Epoch: 6| Step: 12
Training loss: 0.39466521377647773
Validation loss: 2.2715517457890613

Epoch: 6| Step: 13
Training loss: 0.5401387734823229
Validation loss: 2.2796641124939323

Epoch: 271| Step: 0
Training loss: 0.519101646458354
Validation loss: 2.2644039361443373

Epoch: 6| Step: 1
Training loss: 0.4811682532598916
Validation loss: 2.258633591703632

Epoch: 6| Step: 2
Training loss: 0.4681854981570719
Validation loss: 2.2443456083596094

Epoch: 6| Step: 3
Training loss: 0.5729134183849381
Validation loss: 2.291879289632015

Epoch: 6| Step: 4
Training loss: 0.6159106216488422
Validation loss: 2.2823660313816925

Epoch: 6| Step: 5
Training loss: 0.3824098766342287
Validation loss: 2.2731777085436695

Epoch: 6| Step: 6
Training loss: 0.460513259139724
Validation loss: 2.2968871547636036

Epoch: 6| Step: 7
Training loss: 0.5813142341068669
Validation loss: 2.298511703566169

Epoch: 6| Step: 8
Training loss: 0.7507572325041482
Validation loss: 2.2726831216709367

Epoch: 6| Step: 9
Training loss: 0.5706288492380028
Validation loss: 2.2877327293436815

Epoch: 6| Step: 10
Training loss: 0.1479000601602655
Validation loss: 2.296785808408332

Epoch: 6| Step: 11
Training loss: 0.28756430000167976
Validation loss: 2.315705573896705

Epoch: 6| Step: 12
Training loss: 0.509401154578001
Validation loss: 2.273666775664729

Epoch: 6| Step: 13
Training loss: 0.27522072387070645
Validation loss: 2.278406123384149

Epoch: 272| Step: 0
Training loss: 0.40315671840351036
Validation loss: 2.3171136646014587

Epoch: 6| Step: 1
Training loss: 0.5836951008207953
Validation loss: 2.275922919770887

Epoch: 6| Step: 2
Training loss: 0.5866799546176448
Validation loss: 2.281815493477177

Epoch: 6| Step: 3
Training loss: 0.6030495828705378
Validation loss: 2.2841733731709524

Epoch: 6| Step: 4
Training loss: 0.43334054856834703
Validation loss: 2.289746334758929

Epoch: 6| Step: 5
Training loss: 0.5233000959281462
Validation loss: 2.305626580444535

Epoch: 6| Step: 6
Training loss: 0.3015031696915271
Validation loss: 2.255819356174761

Epoch: 6| Step: 7
Training loss: 0.5748606616656404
Validation loss: 2.2872517551077802

Epoch: 6| Step: 8
Training loss: 0.28566143279323836
Validation loss: 2.297823822350654

Epoch: 6| Step: 9
Training loss: 0.26658334075921364
Validation loss: 2.3204412423575036

Epoch: 6| Step: 10
Training loss: 0.4614273313466027
Validation loss: 2.306329934002469

Epoch: 6| Step: 11
Training loss: 0.7141979614917737
Validation loss: 2.3372469107580733

Epoch: 6| Step: 12
Training loss: 0.28299512130471444
Validation loss: 2.3039173539265194

Epoch: 6| Step: 13
Training loss: 0.3825143898956103
Validation loss: 2.3200235002814034

Epoch: 273| Step: 0
Training loss: 0.5696148982321119
Validation loss: 2.3088680543218136

Epoch: 6| Step: 1
Training loss: 0.40198645421118107
Validation loss: 2.2801151934022403

Epoch: 6| Step: 2
Training loss: 0.4699578617868201
Validation loss: 2.3186253553886202

Epoch: 6| Step: 3
Training loss: 0.3254879273631006
Validation loss: 2.2757683046315904

Epoch: 6| Step: 4
Training loss: 0.2315558559864838
Validation loss: 2.277833382381088

Epoch: 6| Step: 5
Training loss: 0.5626933507279344
Validation loss: 2.2898267745223495

Epoch: 6| Step: 6
Training loss: 0.5416695674182787
Validation loss: 2.286693686369275

Epoch: 6| Step: 7
Training loss: 0.6012307280150265
Validation loss: 2.2913541258146743

Epoch: 6| Step: 8
Training loss: 0.26044281192504504
Validation loss: 2.2854352479407174

Epoch: 6| Step: 9
Training loss: 0.5319298153164066
Validation loss: 2.295829055416184

Epoch: 6| Step: 10
Training loss: 0.6202989687272545
Validation loss: 2.319209902799055

Epoch: 6| Step: 11
Training loss: 0.5266314464222528
Validation loss: 2.3250953069941307

Epoch: 6| Step: 12
Training loss: 0.3667009254547916
Validation loss: 2.3565746852353247

Epoch: 6| Step: 13
Training loss: 0.36595509047868297
Validation loss: 2.303765961877824

Epoch: 274| Step: 0
Training loss: 0.6738792510608825
Validation loss: 2.3388098874367875

Epoch: 6| Step: 1
Training loss: 0.31542862457946635
Validation loss: 2.3217733527182736

Epoch: 6| Step: 2
Training loss: 0.4626410249976783
Validation loss: 2.319878944375872

Epoch: 6| Step: 3
Training loss: 0.3540805076066803
Validation loss: 2.299458813720358

Epoch: 6| Step: 4
Training loss: 0.5430604047740337
Validation loss: 2.326044466001663

Epoch: 6| Step: 5
Training loss: 0.4794040606715851
Validation loss: 2.3102196200829335

Epoch: 6| Step: 6
Training loss: 0.2786127260926629
Validation loss: 2.308340222749091

Epoch: 6| Step: 7
Training loss: 0.502682286122711
Validation loss: 2.288949041548189

Epoch: 6| Step: 8
Training loss: 0.3009514512881568
Validation loss: 2.3272909826215367

Epoch: 6| Step: 9
Training loss: 0.5707853264588683
Validation loss: 2.286250197445566

Epoch: 6| Step: 10
Training loss: 0.7210732520135799
Validation loss: 2.27191936211905

Epoch: 6| Step: 11
Training loss: 0.4163277757857582
Validation loss: 2.264511746910164

Epoch: 6| Step: 12
Training loss: 0.5147408795079086
Validation loss: 2.288946873772188

Epoch: 6| Step: 13
Training loss: 0.21997934000585445
Validation loss: 2.264244851293097

Epoch: 275| Step: 0
Training loss: 0.6279680824703362
Validation loss: 2.2527059931907587

Epoch: 6| Step: 1
Training loss: 0.5334112857931991
Validation loss: 2.279355766183093

Epoch: 6| Step: 2
Training loss: 0.5141372892940761
Validation loss: 2.2677559494183663

Epoch: 6| Step: 3
Training loss: 0.15307353746012053
Validation loss: 2.265739910420981

Epoch: 6| Step: 4
Training loss: 0.5608188620575999
Validation loss: 2.2997037851983126

Epoch: 6| Step: 5
Training loss: 0.517707722111526
Validation loss: 2.319055236444827

Epoch: 6| Step: 6
Training loss: 0.4710145924933805
Validation loss: 2.2841782374281117

Epoch: 6| Step: 7
Training loss: 0.44417401392098266
Validation loss: 2.2898716109598305

Epoch: 6| Step: 8
Training loss: 0.37140861003352194
Validation loss: 2.27637918035307

Epoch: 6| Step: 9
Training loss: 0.29827015963559544
Validation loss: 2.282882103220314

Epoch: 6| Step: 10
Training loss: 0.7016335033008172
Validation loss: 2.264313357389282

Epoch: 6| Step: 11
Training loss: 0.7163133367525744
Validation loss: 2.309599466666013

Epoch: 6| Step: 12
Training loss: 0.5164093929316322
Validation loss: 2.2816326917743224

Epoch: 6| Step: 13
Training loss: 0.3528461545328982
Validation loss: 2.3110699820332843

Epoch: 276| Step: 0
Training loss: 0.5827535205687262
Validation loss: 2.3042163965971802

Epoch: 6| Step: 1
Training loss: 0.37523947460323814
Validation loss: 2.3192642488567126

Epoch: 6| Step: 2
Training loss: 0.5549921085896369
Validation loss: 2.3485170632066876

Epoch: 6| Step: 3
Training loss: 0.5039640290010866
Validation loss: 2.322457462985654

Epoch: 6| Step: 4
Training loss: 0.5660459227314778
Validation loss: 2.3723360361656276

Epoch: 6| Step: 5
Training loss: 0.49591818278525424
Validation loss: 2.3163363057028867

Epoch: 6| Step: 6
Training loss: 0.43767133831802796
Validation loss: 2.3169672475394134

Epoch: 6| Step: 7
Training loss: 0.27779976870326006
Validation loss: 2.293080842381444

Epoch: 6| Step: 8
Training loss: 0.529040482136694
Validation loss: 2.2819881697415094

Epoch: 6| Step: 9
Training loss: 0.43277396639941285
Validation loss: 2.3096449326665067

Epoch: 6| Step: 10
Training loss: 0.32599347198128686
Validation loss: 2.314396081722265

Epoch: 6| Step: 11
Training loss: 0.7477954810597465
Validation loss: 2.2951701086327447

Epoch: 6| Step: 12
Training loss: 0.5622095046685566
Validation loss: 2.2831085608519985

Epoch: 6| Step: 13
Training loss: 0.5680072388338824
Validation loss: 2.262419675163616

Epoch: 277| Step: 0
Training loss: 0.7586461623655234
Validation loss: 2.281554649734558

Epoch: 6| Step: 1
Training loss: 0.34997132813997445
Validation loss: 2.251723929111157

Epoch: 6| Step: 2
Training loss: 0.48539911724123475
Validation loss: 2.2962848931301156

Epoch: 6| Step: 3
Training loss: 0.402464876182497
Validation loss: 2.273158455029915

Epoch: 6| Step: 4
Training loss: 0.43485591804238094
Validation loss: 2.301885593489018

Epoch: 6| Step: 5
Training loss: 0.3175508729097108
Validation loss: 2.2855182847180413

Epoch: 6| Step: 6
Training loss: 0.4455008861198989
Validation loss: 2.301642629675473

Epoch: 6| Step: 7
Training loss: 0.6010737477230207
Validation loss: 2.2600966878689004

Epoch: 6| Step: 8
Training loss: 0.4295469574399696
Validation loss: 2.294387746428181

Epoch: 6| Step: 9
Training loss: 0.40638066904648323
Validation loss: 2.2575243115104295

Epoch: 6| Step: 10
Training loss: 0.6502938184204142
Validation loss: 2.255323236071353

Epoch: 6| Step: 11
Training loss: 0.35436050869815744
Validation loss: 2.2776009929305796

Epoch: 6| Step: 12
Training loss: 0.5006918293212564
Validation loss: 2.2733548197998266

Epoch: 6| Step: 13
Training loss: 0.2684456066199811
Validation loss: 2.289149476077156

Epoch: 278| Step: 0
Training loss: 0.593998631069584
Validation loss: 2.2117934556323378

Epoch: 6| Step: 1
Training loss: 0.5517642670650537
Validation loss: 2.2489995213285328

Epoch: 6| Step: 2
Training loss: 0.5399374012514808
Validation loss: 2.2511859682771704

Epoch: 6| Step: 3
Training loss: 0.3444748951328239
Validation loss: 2.2919586349898964

Epoch: 6| Step: 4
Training loss: 0.2827151336404899
Validation loss: 2.3058599066153613

Epoch: 6| Step: 5
Training loss: 0.5250616355319467
Validation loss: 2.2851916334008733

Epoch: 6| Step: 6
Training loss: 0.4682341280099027
Validation loss: 2.308898381537133

Epoch: 6| Step: 7
Training loss: 0.36003773160400615
Validation loss: 2.312710657920685

Epoch: 6| Step: 8
Training loss: 0.47853644189513594
Validation loss: 2.33710755449376

Epoch: 6| Step: 9
Training loss: 0.3514151052272634
Validation loss: 2.293987147171453

Epoch: 6| Step: 10
Training loss: 0.6650449329626867
Validation loss: 2.2956548009418216

Epoch: 6| Step: 11
Training loss: 0.22814205804827647
Validation loss: 2.320102653296535

Epoch: 6| Step: 12
Training loss: 0.4066306678219825
Validation loss: 2.296215758297151

Epoch: 6| Step: 13
Training loss: 0.6945474251578916
Validation loss: 2.2610234496688513

Epoch: 279| Step: 0
Training loss: 0.3643086374941608
Validation loss: 2.296517464917306

Epoch: 6| Step: 1
Training loss: 0.24400134882300076
Validation loss: 2.293271684216243

Epoch: 6| Step: 2
Training loss: 0.2876254652791278
Validation loss: 2.290819865937145

Epoch: 6| Step: 3
Training loss: 0.3155127495684864
Validation loss: 2.3265954902736494

Epoch: 6| Step: 4
Training loss: 0.6370338643113723
Validation loss: 2.295987534040505

Epoch: 6| Step: 5
Training loss: 0.7413866239468428
Validation loss: 2.303322408804667

Epoch: 6| Step: 6
Training loss: 0.46852755036665206
Validation loss: 2.312915808962852

Epoch: 6| Step: 7
Training loss: 0.5186499096930564
Validation loss: 2.295362894362838

Epoch: 6| Step: 8
Training loss: 0.5236361681707214
Validation loss: 2.2823063136433386

Epoch: 6| Step: 9
Training loss: 0.3631124617074709
Validation loss: 2.309469983947527

Epoch: 6| Step: 10
Training loss: 0.2519670526957601
Validation loss: 2.346521303026928

Epoch: 6| Step: 11
Training loss: 0.5427457502454394
Validation loss: 2.2988518428356985

Epoch: 6| Step: 12
Training loss: 0.5933594423034108
Validation loss: 2.3407021791489973

Epoch: 6| Step: 13
Training loss: 0.19904724854652023
Validation loss: 2.331405273384866

Epoch: 280| Step: 0
Training loss: 0.4141088675682357
Validation loss: 2.3172488177498045

Epoch: 6| Step: 1
Training loss: 0.6278189506598114
Validation loss: 2.3150943492114324

Epoch: 6| Step: 2
Training loss: 0.20645357907579542
Validation loss: 2.2761618283828122

Epoch: 6| Step: 3
Training loss: 0.5834765315268129
Validation loss: 2.275270155892947

Epoch: 6| Step: 4
Training loss: 0.47014857505550756
Validation loss: 2.277945088493623

Epoch: 6| Step: 5
Training loss: 0.5373106700657061
Validation loss: 2.2679214804771863

Epoch: 6| Step: 6
Training loss: 0.49656053044556936
Validation loss: 2.2596368911032805

Epoch: 6| Step: 7
Training loss: 0.4164582883800783
Validation loss: 2.252586908017679

Epoch: 6| Step: 8
Training loss: 0.5274008260851377
Validation loss: 2.3008699424219383

Epoch: 6| Step: 9
Training loss: 0.3637553781918004
Validation loss: 2.2570082151008557

Epoch: 6| Step: 10
Training loss: 0.3232895853840335
Validation loss: 2.247453009242502

Epoch: 6| Step: 11
Training loss: 0.36621862784893966
Validation loss: 2.259593218398677

Epoch: 6| Step: 12
Training loss: 0.3859959986595435
Validation loss: 2.2982171856783844

Epoch: 6| Step: 13
Training loss: 0.4087325682699854
Validation loss: 2.283476953575768

Epoch: 281| Step: 0
Training loss: 0.258918298085302
Validation loss: 2.2754995367271813

Epoch: 6| Step: 1
Training loss: 0.4943054738449144
Validation loss: 2.291062588841493

Epoch: 6| Step: 2
Training loss: 0.4564783387157991
Validation loss: 2.333616731356398

Epoch: 6| Step: 3
Training loss: 0.6980781842741959
Validation loss: 2.3230610096349493

Epoch: 6| Step: 4
Training loss: 0.6005983925124946
Validation loss: 2.3445616379816663

Epoch: 6| Step: 5
Training loss: 0.42264934400180154
Validation loss: 2.3499193742352924

Epoch: 6| Step: 6
Training loss: 0.3267822835620806
Validation loss: 2.308570610871415

Epoch: 6| Step: 7
Training loss: 0.397195019444465
Validation loss: 2.3130663904558557

Epoch: 6| Step: 8
Training loss: 0.5040749260162464
Validation loss: 2.3202494940074376

Epoch: 6| Step: 9
Training loss: 0.3515182997150792
Validation loss: 2.2828104371713334

Epoch: 6| Step: 10
Training loss: 0.28707885579980746
Validation loss: 2.2692907135767175

Epoch: 6| Step: 11
Training loss: 0.5600660701076423
Validation loss: 2.260536860553846

Epoch: 6| Step: 12
Training loss: 0.34600995343147223
Validation loss: 2.268013194120139

Epoch: 6| Step: 13
Training loss: 0.34327992896970505
Validation loss: 2.27456264818625

Epoch: 282| Step: 0
Training loss: 0.39329954069189804
Validation loss: 2.327401183499603

Epoch: 6| Step: 1
Training loss: 0.5352144975357987
Validation loss: 2.2932533260446766

Epoch: 6| Step: 2
Training loss: 0.34043184455892916
Validation loss: 2.32948394269263

Epoch: 6| Step: 3
Training loss: 0.29758639179183144
Validation loss: 2.290139711692567

Epoch: 6| Step: 4
Training loss: 0.5858042247516985
Validation loss: 2.2950010978518627

Epoch: 6| Step: 5
Training loss: 0.3954310213115671
Validation loss: 2.2954627544986974

Epoch: 6| Step: 6
Training loss: 0.47288046003653755
Validation loss: 2.2956188423154984

Epoch: 6| Step: 7
Training loss: 0.6112954127910427
Validation loss: 2.3022390578435643

Epoch: 6| Step: 8
Training loss: 0.2646171016370307
Validation loss: 2.2693719247231243

Epoch: 6| Step: 9
Training loss: 0.2866388474640897
Validation loss: 2.273347782436363

Epoch: 6| Step: 10
Training loss: 0.40674205471454516
Validation loss: 2.2807381449454027

Epoch: 6| Step: 11
Training loss: 0.4415844920324897
Validation loss: 2.275519168973802

Epoch: 6| Step: 12
Training loss: 0.34791379668523487
Validation loss: 2.2634003101085014

Epoch: 6| Step: 13
Training loss: 0.4453614024030592
Validation loss: 2.249195719663369

Epoch: 283| Step: 0
Training loss: 0.3524169076219807
Validation loss: 2.270102481429661

Epoch: 6| Step: 1
Training loss: 0.508845789230975
Validation loss: 2.242969259031998

Epoch: 6| Step: 2
Training loss: 0.5847555828570037
Validation loss: 2.2638028762098834

Epoch: 6| Step: 3
Training loss: 0.5111862498691476
Validation loss: 2.2643801410964226

Epoch: 6| Step: 4
Training loss: 0.5307436661865677
Validation loss: 2.2620877305652622

Epoch: 6| Step: 5
Training loss: 0.3262680962538711
Validation loss: 2.255335164638067

Epoch: 6| Step: 6
Training loss: 0.38804224667785175
Validation loss: 2.251442273796177

Epoch: 6| Step: 7
Training loss: 0.4560659435770064
Validation loss: 2.259699679454312

Epoch: 6| Step: 8
Training loss: 0.3926880146541134
Validation loss: 2.2639868698476397

Epoch: 6| Step: 9
Training loss: 0.5485294112871919
Validation loss: 2.2291961999944983

Epoch: 6| Step: 10
Training loss: 0.287279039971764
Validation loss: 2.2361598729138925

Epoch: 6| Step: 11
Training loss: 0.32619310641144045
Validation loss: 2.2035701665300174

Epoch: 6| Step: 12
Training loss: 0.4240694369856997
Validation loss: 2.238520114371788

Epoch: 6| Step: 13
Training loss: 0.1388243521981124
Validation loss: 2.21716066568101

Epoch: 284| Step: 0
Training loss: 0.4151305333486357
Validation loss: 2.2155213552299777

Epoch: 6| Step: 1
Training loss: 0.4314905656642955
Validation loss: 2.251653357763909

Epoch: 6| Step: 2
Training loss: 0.41468771031136487
Validation loss: 2.243739995226579

Epoch: 6| Step: 3
Training loss: 0.5862880421152487
Validation loss: 2.2737321345917336

Epoch: 6| Step: 4
Training loss: 0.4334274522954803
Validation loss: 2.242869340886446

Epoch: 6| Step: 5
Training loss: 0.44769746014844025
Validation loss: 2.2635388708851703

Epoch: 6| Step: 6
Training loss: 0.4273162261077333
Validation loss: 2.2795620094217384

Epoch: 6| Step: 7
Training loss: 0.3525600162946766
Validation loss: 2.2322213472550665

Epoch: 6| Step: 8
Training loss: 0.26435159737465297
Validation loss: 2.241069313504165

Epoch: 6| Step: 9
Training loss: 0.30081099821342355
Validation loss: 2.271781017108979

Epoch: 6| Step: 10
Training loss: 0.42537074467326635
Validation loss: 2.2550881006163768

Epoch: 6| Step: 11
Training loss: 0.5487039771799171
Validation loss: 2.2724115038190167

Epoch: 6| Step: 12
Training loss: 0.26413276798327234
Validation loss: 2.2748173727038066

Epoch: 6| Step: 13
Training loss: 0.4962992355222808
Validation loss: 2.2837508834642373

Epoch: 285| Step: 0
Training loss: 0.48411346881390005
Validation loss: 2.276417712695454

Epoch: 6| Step: 1
Training loss: 0.3263175091011035
Validation loss: 2.2745329274298034

Epoch: 6| Step: 2
Training loss: 0.4891489025732225
Validation loss: 2.26518079698017

Epoch: 6| Step: 3
Training loss: 0.3376339174305467
Validation loss: 2.268873320740754

Epoch: 6| Step: 4
Training loss: 0.1398910335968128
Validation loss: 2.2613412497136256

Epoch: 6| Step: 5
Training loss: 0.6802104385210985
Validation loss: 2.262856589449844

Epoch: 6| Step: 6
Training loss: 0.31766790643518805
Validation loss: 2.245038041114692

Epoch: 6| Step: 7
Training loss: 0.3364483807728478
Validation loss: 2.286925339058619

Epoch: 6| Step: 8
Training loss: 0.4760790702377001
Validation loss: 2.236680086479288

Epoch: 6| Step: 9
Training loss: 0.5519787371417139
Validation loss: 2.266551941078598

Epoch: 6| Step: 10
Training loss: 0.4038805084584872
Validation loss: 2.2385902402683686

Epoch: 6| Step: 11
Training loss: 0.3718395769253936
Validation loss: 2.2919299801287885

Epoch: 6| Step: 12
Training loss: 0.39179786081085477
Validation loss: 2.280073731605973

Epoch: 6| Step: 13
Training loss: 0.137308639697392
Validation loss: 2.2913764083671904

Epoch: 286| Step: 0
Training loss: 0.49800932499569633
Validation loss: 2.2929179410320124

Epoch: 6| Step: 1
Training loss: 0.4438488984379104
Validation loss: 2.284941670022946

Epoch: 6| Step: 2
Training loss: 0.4326723636204134
Validation loss: 2.2676021770416246

Epoch: 6| Step: 3
Training loss: 0.5183426015593585
Validation loss: 2.2846601571926803

Epoch: 6| Step: 4
Training loss: 0.418757505491947
Validation loss: 2.2898357087406884

Epoch: 6| Step: 5
Training loss: 0.2654435295217776
Validation loss: 2.286159383060428

Epoch: 6| Step: 6
Training loss: 0.4146787268509027
Validation loss: 2.299023581303269

Epoch: 6| Step: 7
Training loss: 0.40629533368040444
Validation loss: 2.298774338536803

Epoch: 6| Step: 8
Training loss: 0.3321939967104211
Validation loss: 2.2561918768908047

Epoch: 6| Step: 9
Training loss: 0.27729377833669827
Validation loss: 2.267269144737796

Epoch: 6| Step: 10
Training loss: 0.5689340681332725
Validation loss: 2.238458382273026

Epoch: 6| Step: 11
Training loss: 0.26618179699157407
Validation loss: 2.246073871683308

Epoch: 6| Step: 12
Training loss: 0.34553301661604635
Validation loss: 2.296330110320296

Epoch: 6| Step: 13
Training loss: 0.1505985123644611
Validation loss: 2.294723148997016

Epoch: 287| Step: 0
Training loss: 0.33339261729831404
Validation loss: 2.2468589337500324

Epoch: 6| Step: 1
Training loss: 0.21945592531486519
Validation loss: 2.259513100131606

Epoch: 6| Step: 2
Training loss: 0.3490731373107844
Validation loss: 2.240610544641463

Epoch: 6| Step: 3
Training loss: 0.5720137214215292
Validation loss: 2.280177054134013

Epoch: 6| Step: 4
Training loss: 0.402233645734373
Validation loss: 2.2807264942422676

Epoch: 6| Step: 5
Training loss: 0.45128739104336585
Validation loss: 2.290836749072525

Epoch: 6| Step: 6
Training loss: 0.5543954107060193
Validation loss: 2.3122452981150947

Epoch: 6| Step: 7
Training loss: 0.20479784386387387
Validation loss: 2.3004128780167705

Epoch: 6| Step: 8
Training loss: 0.2783739941676879
Validation loss: 2.2873134850350665

Epoch: 6| Step: 9
Training loss: 0.1646855648441011
Validation loss: 2.2917940162184425

Epoch: 6| Step: 10
Training loss: 0.583903431465792
Validation loss: 2.245730166619122

Epoch: 6| Step: 11
Training loss: 0.4189640565604894
Validation loss: 2.2814245119321788

Epoch: 6| Step: 12
Training loss: 0.3252973883176015
Validation loss: 2.2736344095198686

Epoch: 6| Step: 13
Training loss: 0.4206226091189403
Validation loss: 2.235881680361329

Epoch: 288| Step: 0
Training loss: 0.3004262736861478
Validation loss: 2.2276495682837236

Epoch: 6| Step: 1
Training loss: 0.6179616635925397
Validation loss: 2.2407799315469163

Epoch: 6| Step: 2
Training loss: 0.48941084853468925
Validation loss: 2.252484272963438

Epoch: 6| Step: 3
Training loss: 0.4619820929789049
Validation loss: 2.2440719440476364

Epoch: 6| Step: 4
Training loss: 0.27803977078319697
Validation loss: 2.256109115228401

Epoch: 6| Step: 5
Training loss: 0.1981983982074384
Validation loss: 2.2816618377510522

Epoch: 6| Step: 6
Training loss: 0.4368361136248408
Validation loss: 2.2825269980903284

Epoch: 6| Step: 7
Training loss: 0.34533958932939984
Validation loss: 2.297141172372312

Epoch: 6| Step: 8
Training loss: 0.33854789972680593
Validation loss: 2.2992675008958106

Epoch: 6| Step: 9
Training loss: 0.2606783585163116
Validation loss: 2.3364912910289903

Epoch: 6| Step: 10
Training loss: 0.5632322102229229
Validation loss: 2.273309504233092

Epoch: 6| Step: 11
Training loss: 0.31052312220297495
Validation loss: 2.2889689462391405

Epoch: 6| Step: 12
Training loss: 0.36264505361673083
Validation loss: 2.2916037941490264

Epoch: 6| Step: 13
Training loss: 0.35926952058031153
Validation loss: 2.304377170899713

Epoch: 289| Step: 0
Training loss: 0.46872256516598326
Validation loss: 2.276837471950202

Epoch: 6| Step: 1
Training loss: 0.4115075874625653
Validation loss: 2.272446673327889

Epoch: 6| Step: 2
Training loss: 0.29872123202671447
Validation loss: 2.279621432434331

Epoch: 6| Step: 3
Training loss: 0.4081095355493728
Validation loss: 2.2623344505856533

Epoch: 6| Step: 4
Training loss: 0.34765299249044446
Validation loss: 2.269934792474917

Epoch: 6| Step: 5
Training loss: 0.30955008311315996
Validation loss: 2.2892588309646222

Epoch: 6| Step: 6
Training loss: 0.39267951453160166
Validation loss: 2.281863472993687

Epoch: 6| Step: 7
Training loss: 0.3512797384128604
Validation loss: 2.3128069053428923

Epoch: 6| Step: 8
Training loss: 0.4800129721299307
Validation loss: 2.291729350272179

Epoch: 6| Step: 9
Training loss: 0.556251818407494
Validation loss: 2.294943033477356

Epoch: 6| Step: 10
Training loss: 0.2713070022440762
Validation loss: 2.276785490029623

Epoch: 6| Step: 11
Training loss: 0.31757832300759464
Validation loss: 2.293574575067835

Epoch: 6| Step: 12
Training loss: 0.33275085334969345
Validation loss: 2.28229887535346

Epoch: 6| Step: 13
Training loss: 0.27649303037920187
Validation loss: 2.2678358573075696

Epoch: 290| Step: 0
Training loss: 0.246247758056388
Validation loss: 2.2991328400840447

Epoch: 6| Step: 1
Training loss: 0.3520415750641052
Validation loss: 2.274678703264622

Epoch: 6| Step: 2
Training loss: 0.3073646235201867
Validation loss: 2.254458584553218

Epoch: 6| Step: 3
Training loss: 0.361948460253062
Validation loss: 2.2992176386629968

Epoch: 6| Step: 4
Training loss: 0.39643551379768766
Validation loss: 2.2936687367797894

Epoch: 6| Step: 5
Training loss: 0.6704638543680324
Validation loss: 2.2813594166487388

Epoch: 6| Step: 6
Training loss: 0.27431871923148504
Validation loss: 2.2914553812424105

Epoch: 6| Step: 7
Training loss: 0.3900181061258603
Validation loss: 2.2848373449993655

Epoch: 6| Step: 8
Training loss: 0.39783986467216087
Validation loss: 2.3032053029169264

Epoch: 6| Step: 9
Training loss: 0.35208876744803763
Validation loss: 2.280900567421075

Epoch: 6| Step: 10
Training loss: 0.3572744680478513
Validation loss: 2.2971516193512387

Epoch: 6| Step: 11
Training loss: 0.3205020971445336
Validation loss: 2.2682850724869756

Epoch: 6| Step: 12
Training loss: 0.36788389438346203
Validation loss: 2.2762992705411063

Epoch: 6| Step: 13
Training loss: 0.5319866794732678
Validation loss: 2.2430692515879005

Epoch: 291| Step: 0
Training loss: 0.375606443863986
Validation loss: 2.3035492742263477

Epoch: 6| Step: 1
Training loss: 0.4233733343232971
Validation loss: 2.2794542188104447

Epoch: 6| Step: 2
Training loss: 0.3181688756795292
Validation loss: 2.293623351996789

Epoch: 6| Step: 3
Training loss: 0.2790401719570546
Validation loss: 2.315277253889937

Epoch: 6| Step: 4
Training loss: 0.42244431264107596
Validation loss: 2.315522382530326

Epoch: 6| Step: 5
Training loss: 0.6147173692265856
Validation loss: 2.3076526197749665

Epoch: 6| Step: 6
Training loss: 0.5299664868249622
Validation loss: 2.2693140871582815

Epoch: 6| Step: 7
Training loss: 0.45848081845643945
Validation loss: 2.2729589056275152

Epoch: 6| Step: 8
Training loss: 0.21690366881186313
Validation loss: 2.2695531834325497

Epoch: 6| Step: 9
Training loss: 0.4085286316485358
Validation loss: 2.1935394569380473

Epoch: 6| Step: 10
Training loss: 0.44387075366194256
Validation loss: 2.2367349277112853

Epoch: 6| Step: 11
Training loss: 0.2663348614083291
Validation loss: 2.2354373627896265

Epoch: 6| Step: 12
Training loss: 0.4146522424768565
Validation loss: 2.230400156661327

Epoch: 6| Step: 13
Training loss: 0.38362787953374655
Validation loss: 2.276429432749847

Epoch: 292| Step: 0
Training loss: 0.3065077013701954
Validation loss: 2.279843276357822

Epoch: 6| Step: 1
Training loss: 0.4082345904766815
Validation loss: 2.281256724173648

Epoch: 6| Step: 2
Training loss: 0.44967059755138894
Validation loss: 2.2752531780931378

Epoch: 6| Step: 3
Training loss: 0.5554963245871131
Validation loss: 2.3080140842149053

Epoch: 6| Step: 4
Training loss: 0.462392353727387
Validation loss: 2.3067626215113397

Epoch: 6| Step: 5
Training loss: 0.2502734804399006
Validation loss: 2.2666106730927744

Epoch: 6| Step: 6
Training loss: 0.2797771672411435
Validation loss: 2.2761796162477865

Epoch: 6| Step: 7
Training loss: 0.1729751296103144
Validation loss: 2.242404263685356

Epoch: 6| Step: 8
Training loss: 0.35864829103660184
Validation loss: 2.2498461649089703

Epoch: 6| Step: 9
Training loss: 0.6396256304453206
Validation loss: 2.231806517872716

Epoch: 6| Step: 10
Training loss: 0.30132455184277807
Validation loss: 2.218553389660374

Epoch: 6| Step: 11
Training loss: 0.49939516857511906
Validation loss: 2.2558848361449275

Epoch: 6| Step: 12
Training loss: 0.27625652564441006
Validation loss: 2.2124815938990547

Epoch: 6| Step: 13
Training loss: 0.2392749157456144
Validation loss: 2.263321458164151

Epoch: 293| Step: 0
Training loss: 0.3932891783068597
Validation loss: 2.3034877940889467

Epoch: 6| Step: 1
Training loss: 0.4820341490375511
Validation loss: 2.2635228329181207

Epoch: 6| Step: 2
Training loss: 0.6703736141773063
Validation loss: 2.301518309425803

Epoch: 6| Step: 3
Training loss: 0.4499255714854181
Validation loss: 2.2980639770826596

Epoch: 6| Step: 4
Training loss: 0.3516892946264273
Validation loss: 2.30567097065096

Epoch: 6| Step: 5
Training loss: 0.25376588903206343
Validation loss: 2.2808317539088034

Epoch: 6| Step: 6
Training loss: 0.347201961350065
Validation loss: 2.273296838994297

Epoch: 6| Step: 7
Training loss: 0.40588835978981863
Validation loss: 2.2329533031932947

Epoch: 6| Step: 8
Training loss: 0.3205469250568571
Validation loss: 2.252871885838839

Epoch: 6| Step: 9
Training loss: 0.4084529203672186
Validation loss: 2.2491403729851336

Epoch: 6| Step: 10
Training loss: 0.45377833850631405
Validation loss: 2.25940499298086

Epoch: 6| Step: 11
Training loss: 0.36182703164750013
Validation loss: 2.2649002109642824

Epoch: 6| Step: 12
Training loss: 0.1985877271889956
Validation loss: 2.2668269668121006

Epoch: 6| Step: 13
Training loss: 0.5623595274259168
Validation loss: 2.2829128430225882

Epoch: 294| Step: 0
Training loss: 0.5166425201967333
Validation loss: 2.2533263476705763

Epoch: 6| Step: 1
Training loss: 0.4006305440974361
Validation loss: 2.307096125585838

Epoch: 6| Step: 2
Training loss: 0.4477746390864285
Validation loss: 2.320513662732898

Epoch: 6| Step: 3
Training loss: 0.1885237955788156
Validation loss: 2.3005339862225047

Epoch: 6| Step: 4
Training loss: 0.35599719581008565
Validation loss: 2.310798213954831

Epoch: 6| Step: 5
Training loss: 0.2081294174412869
Validation loss: 2.3237424135371407

Epoch: 6| Step: 6
Training loss: 0.2998616664557011
Validation loss: 2.2913362378566293

Epoch: 6| Step: 7
Training loss: 0.26409897298436236
Validation loss: 2.3096417725747633

Epoch: 6| Step: 8
Training loss: 0.353251985909481
Validation loss: 2.2871851807943426

Epoch: 6| Step: 9
Training loss: 0.5708828517105741
Validation loss: 2.3114974463051503

Epoch: 6| Step: 10
Training loss: 0.42664644721794037
Validation loss: 2.28189107405797

Epoch: 6| Step: 11
Training loss: 0.4128776367800874
Validation loss: 2.2592608312864186

Epoch: 6| Step: 12
Training loss: 0.2807457695452891
Validation loss: 2.3021909523124955

Epoch: 6| Step: 13
Training loss: 0.4453654508731324
Validation loss: 2.2816032319370727

Epoch: 295| Step: 0
Training loss: 0.5230587115383619
Validation loss: 2.253041732847184

Epoch: 6| Step: 1
Training loss: 0.28659677483556834
Validation loss: 2.2673988648401577

Epoch: 6| Step: 2
Training loss: 0.24446682309777745
Validation loss: 2.2845759031112824

Epoch: 6| Step: 3
Training loss: 0.3722111192730867
Validation loss: 2.242717878993322

Epoch: 6| Step: 4
Training loss: 0.2718192854609082
Validation loss: 2.2565451896499056

Epoch: 6| Step: 5
Training loss: 0.43735866307232724
Validation loss: 2.295640231397797

Epoch: 6| Step: 6
Training loss: 0.49709417439502174
Validation loss: 2.271421478444384

Epoch: 6| Step: 7
Training loss: 0.18093136781964536
Validation loss: 2.273388821105695

Epoch: 6| Step: 8
Training loss: 0.3807704136949747
Validation loss: 2.2243490907288983

Epoch: 6| Step: 9
Training loss: 0.4448886493873052
Validation loss: 2.2721375280830514

Epoch: 6| Step: 10
Training loss: 0.3617780822143366
Validation loss: 2.2830680054120593

Epoch: 6| Step: 11
Training loss: 0.24922034762357728
Validation loss: 2.3123646812679315

Epoch: 6| Step: 12
Training loss: 0.33379691144309753
Validation loss: 2.2766952963406464

Epoch: 6| Step: 13
Training loss: 0.2632394282010579
Validation loss: 2.279520797355597

Epoch: 296| Step: 0
Training loss: 0.4744015148226305
Validation loss: 2.2420108490188237

Epoch: 6| Step: 1
Training loss: 0.3151742237282119
Validation loss: 2.3112890847351095

Epoch: 6| Step: 2
Training loss: 0.3707275792568714
Validation loss: 2.28424145050457

Epoch: 6| Step: 3
Training loss: 0.3458917178810377
Validation loss: 2.2981945581104988

Epoch: 6| Step: 4
Training loss: 0.2269368039432778
Validation loss: 2.3114707061790307

Epoch: 6| Step: 5
Training loss: 0.4954183892502713
Validation loss: 2.294077957320523

Epoch: 6| Step: 6
Training loss: 0.34623446822189935
Validation loss: 2.27598638888162

Epoch: 6| Step: 7
Training loss: 0.3344793722773209
Validation loss: 2.2892121375253267

Epoch: 6| Step: 8
Training loss: 0.2426843699234498
Validation loss: 2.2282015800907136

Epoch: 6| Step: 9
Training loss: 0.47222439291710694
Validation loss: 2.228079532376322

Epoch: 6| Step: 10
Training loss: 0.44508046245178784
Validation loss: 2.2461057127446304

Epoch: 6| Step: 11
Training loss: 0.2908849230665062
Validation loss: 2.243413833844771

Epoch: 6| Step: 12
Training loss: 0.4842359281670533
Validation loss: 2.2224589730180133

Epoch: 6| Step: 13
Training loss: 0.22430458951124632
Validation loss: 2.256434364661642

Epoch: 297| Step: 0
Training loss: 0.25790656425635344
Validation loss: 2.2476472300615606

Epoch: 6| Step: 1
Training loss: 0.37924672589809333
Validation loss: 2.2841287368988246

Epoch: 6| Step: 2
Training loss: 0.35686649886927324
Validation loss: 2.2855487551956144

Epoch: 6| Step: 3
Training loss: 0.3855269592150278
Validation loss: 2.2925722639213695

Epoch: 6| Step: 4
Training loss: 0.32370274627879936
Validation loss: 2.3090604785700077

Epoch: 6| Step: 5
Training loss: 0.32353279211929004
Validation loss: 2.262995549712615

Epoch: 6| Step: 6
Training loss: 0.23573592366490972
Validation loss: 2.284681125971148

Epoch: 6| Step: 7
Training loss: 0.46680737727014465
Validation loss: 2.2936388749119327

Epoch: 6| Step: 8
Training loss: 0.43487054975951345
Validation loss: 2.2948603731919683

Epoch: 6| Step: 9
Training loss: 0.20542823334008956
Validation loss: 2.2756197326088907

Epoch: 6| Step: 10
Training loss: 0.374901202220724
Validation loss: 2.291649245776712

Epoch: 6| Step: 11
Training loss: 0.23839581971447812
Validation loss: 2.2909367550238566

Epoch: 6| Step: 12
Training loss: 0.5465856604142961
Validation loss: 2.26301981075615

Epoch: 6| Step: 13
Training loss: 0.2685395670015352
Validation loss: 2.272411895854105

Epoch: 298| Step: 0
Training loss: 0.5284791379797174
Validation loss: 2.2478901178105124

Epoch: 6| Step: 1
Training loss: 0.32610153536237724
Validation loss: 2.2774569288523576

Epoch: 6| Step: 2
Training loss: 0.18287701405780485
Validation loss: 2.280460302456302

Epoch: 6| Step: 3
Training loss: 0.21193375913434073
Validation loss: 2.248002511275568

Epoch: 6| Step: 4
Training loss: 0.30113244299520175
Validation loss: 2.2847538352094374

Epoch: 6| Step: 5
Training loss: 0.4172063987537485
Validation loss: 2.289265784700973

Epoch: 6| Step: 6
Training loss: 0.09693747167383956
Validation loss: 2.2967806516222753

Epoch: 6| Step: 7
Training loss: 0.4637179646647631
Validation loss: 2.274837269192214

Epoch: 6| Step: 8
Training loss: 0.295586966574173
Validation loss: 2.2880389248853272

Epoch: 6| Step: 9
Training loss: 0.4722105715130956
Validation loss: 2.269342760983507

Epoch: 6| Step: 10
Training loss: 0.33419690425005133
Validation loss: 2.2758280553721364

Epoch: 6| Step: 11
Training loss: 0.27223607837490255
Validation loss: 2.288573631209655

Epoch: 6| Step: 12
Training loss: 0.2656343963307462
Validation loss: 2.25104042777471

Epoch: 6| Step: 13
Training loss: 0.33022970748140557
Validation loss: 2.287242702074442

Epoch: 299| Step: 0
Training loss: 0.17878581911945268
Validation loss: 2.2637562389438086

Epoch: 6| Step: 1
Training loss: 0.18477348972219979
Validation loss: 2.2792670371383403

Epoch: 6| Step: 2
Training loss: 0.22929506154943546
Validation loss: 2.225237280045172

Epoch: 6| Step: 3
Training loss: 0.3301933584016665
Validation loss: 2.2928473159933085

Epoch: 6| Step: 4
Training loss: 0.35297210809968593
Validation loss: 2.2831496351716805

Epoch: 6| Step: 5
Training loss: 0.30396262776141175
Validation loss: 2.2822091028754947

Epoch: 6| Step: 6
Training loss: 0.5829181442441975
Validation loss: 2.2671144103948553

Epoch: 6| Step: 7
Training loss: 0.22057482273099438
Validation loss: 2.2540388773657454

Epoch: 6| Step: 8
Training loss: 0.28184988366700336
Validation loss: 2.285532199227275

Epoch: 6| Step: 9
Training loss: 0.3854161296875108
Validation loss: 2.246512949641972

Epoch: 6| Step: 10
Training loss: 0.4800557633384075
Validation loss: 2.2905805891044255

Epoch: 6| Step: 11
Training loss: 0.36675021328754115
Validation loss: 2.265504477820361

Epoch: 6| Step: 12
Training loss: 0.18330982248956632
Validation loss: 2.3014468432945443

Epoch: 6| Step: 13
Training loss: 0.42280102575370776
Validation loss: 2.2680609711001596

Epoch: 300| Step: 0
Training loss: 0.20188743216436864
Validation loss: 2.265814721548263

Epoch: 6| Step: 1
Training loss: 0.4704629118933102
Validation loss: 2.2358184025774315

Epoch: 6| Step: 2
Training loss: 0.414086611063736
Validation loss: 2.252762727683066

Epoch: 6| Step: 3
Training loss: 0.35687434882857844
Validation loss: 2.2606732292947638

Epoch: 6| Step: 4
Training loss: 0.2618001555052573
Validation loss: 2.286066714725641

Epoch: 6| Step: 5
Training loss: 0.32682607910125755
Validation loss: 2.2714823011614698

Epoch: 6| Step: 6
Training loss: 0.2670381625035789
Validation loss: 2.288865523287586

Epoch: 6| Step: 7
Training loss: 0.3938661767231015
Validation loss: 2.328943331589937

Epoch: 6| Step: 8
Training loss: 0.3073236669699701
Validation loss: 2.350388414482716

Epoch: 6| Step: 9
Training loss: 0.2777417376437
Validation loss: 2.305183137102494

Epoch: 6| Step: 10
Training loss: 0.3379443792902631
Validation loss: 2.2967013104420912

Epoch: 6| Step: 11
Training loss: 0.4951121764521982
Validation loss: 2.2516191802345915

Epoch: 6| Step: 12
Training loss: 0.4371540200186604
Validation loss: 2.224036594585521

Epoch: 6| Step: 13
Training loss: 0.17748264679569845
Validation loss: 2.2489702507164235

Epoch: 301| Step: 0
Training loss: 0.2146011543435303
Validation loss: 2.209318700011203

Epoch: 6| Step: 1
Training loss: 0.36624700750098366
Validation loss: 2.2056737228553662

Epoch: 6| Step: 2
Training loss: 0.31965287838652334
Validation loss: 2.2304950026749832

Epoch: 6| Step: 3
Training loss: 0.5494028252334914
Validation loss: 2.2371714370621834

Epoch: 6| Step: 4
Training loss: 0.31168538251990957
Validation loss: 2.25983474334607

Epoch: 6| Step: 5
Training loss: 0.4368937242503807
Validation loss: 2.228974009037512

Epoch: 6| Step: 6
Training loss: 0.3783004873710758
Validation loss: 2.2637493059393914

Epoch: 6| Step: 7
Training loss: 0.28769195254267954
Validation loss: 2.2650817830903023

Epoch: 6| Step: 8
Training loss: 0.2779897098240555
Validation loss: 2.278055516342755

Epoch: 6| Step: 9
Training loss: 0.21146443566472944
Validation loss: 2.307944555947315

Epoch: 6| Step: 10
Training loss: 0.4462129624006987
Validation loss: 2.3041051402427275

Epoch: 6| Step: 11
Training loss: 0.27522562373095233
Validation loss: 2.2908929930256923

Epoch: 6| Step: 12
Training loss: 0.29284333405644775
Validation loss: 2.2783090820868384

Epoch: 6| Step: 13
Training loss: 0.4519924776423984
Validation loss: 2.271555911959057

Epoch: 302| Step: 0
Training loss: 0.2633952915411667
Validation loss: 2.278655913206152

Epoch: 6| Step: 1
Training loss: 0.26366266305160924
Validation loss: 2.2650473367781307

Epoch: 6| Step: 2
Training loss: 0.4550972635722514
Validation loss: 2.2439398712049132

Epoch: 6| Step: 3
Training loss: 0.48277766895268576
Validation loss: 2.2482245594653283

Epoch: 6| Step: 4
Training loss: 0.4110274372386582
Validation loss: 2.285104505557678

Epoch: 6| Step: 5
Training loss: 0.18426343848199916
Validation loss: 2.3110694284988433

Epoch: 6| Step: 6
Training loss: 0.41588389858796054
Validation loss: 2.3521617114655733

Epoch: 6| Step: 7
Training loss: 0.4670363095450709
Validation loss: 2.3180737736295933

Epoch: 6| Step: 8
Training loss: 0.20894260523838126
Validation loss: 2.326421290060636

Epoch: 6| Step: 9
Training loss: 0.5488665421367878
Validation loss: 2.320408761345274

Epoch: 6| Step: 10
Training loss: 0.44399773438837903
Validation loss: 2.2762626615187926

Epoch: 6| Step: 11
Training loss: 0.43816821974871706
Validation loss: 2.2860291760087446

Epoch: 6| Step: 12
Training loss: 0.27773491045206766
Validation loss: 2.2704033227633182

Epoch: 6| Step: 13
Training loss: 0.3672670927426162
Validation loss: 2.2747689656408223

Epoch: 303| Step: 0
Training loss: 0.4443794313040836
Validation loss: 2.2596956145191602

Epoch: 6| Step: 1
Training loss: 0.39949143087103384
Validation loss: 2.2847842917578483

Epoch: 6| Step: 2
Training loss: 0.44986625114258544
Validation loss: 2.271549074425328

Epoch: 6| Step: 3
Training loss: 0.31790664872467256
Validation loss: 2.2785971771998947

Epoch: 6| Step: 4
Training loss: 0.17069003340846514
Validation loss: 2.261286047822507

Epoch: 6| Step: 5
Training loss: 0.5346931068398438
Validation loss: 2.297896596018236

Epoch: 6| Step: 6
Training loss: 0.3832140587540788
Validation loss: 2.3169751028666123

Epoch: 6| Step: 7
Training loss: 0.45399580513595833
Validation loss: 2.3356516794188766

Epoch: 6| Step: 8
Training loss: 0.3869663755819513
Validation loss: 2.348137990975153

Epoch: 6| Step: 9
Training loss: 0.4519023019343713
Validation loss: 2.3364204787886385

Epoch: 6| Step: 10
Training loss: 0.35521242310900064
Validation loss: 2.313559985710339

Epoch: 6| Step: 11
Training loss: 0.27371770942665274
Validation loss: 2.307873686487577

Epoch: 6| Step: 12
Training loss: 0.20278642019452175
Validation loss: 2.287737081762401

Epoch: 6| Step: 13
Training loss: 0.3999513030212061
Validation loss: 2.285692522361749

Epoch: 304| Step: 0
Training loss: 0.42966769779699127
Validation loss: 2.262435155517286

Epoch: 6| Step: 1
Training loss: 0.34214982474218214
Validation loss: 2.231548680835321

Epoch: 6| Step: 2
Training loss: 0.450830239422254
Validation loss: 2.268045516146221

Epoch: 6| Step: 3
Training loss: 0.23680525291370083
Validation loss: 2.279907555288272

Epoch: 6| Step: 4
Training loss: 0.27132106232505876
Validation loss: 2.2703358761154964

Epoch: 6| Step: 5
Training loss: 0.50572084864629
Validation loss: 2.334178910515159

Epoch: 6| Step: 6
Training loss: 0.3319402794474681
Validation loss: 2.287244780116958

Epoch: 6| Step: 7
Training loss: 0.46940020924008047
Validation loss: 2.3411375103095033

Epoch: 6| Step: 8
Training loss: 0.38445333209901383
Validation loss: 2.330459931337292

Epoch: 6| Step: 9
Training loss: 0.24789392456494036
Validation loss: 2.2910545467575822

Epoch: 6| Step: 10
Training loss: 0.2181624457727154
Validation loss: 2.241997741259138

Epoch: 6| Step: 11
Training loss: 0.39099119188187786
Validation loss: 2.2466561714811

Epoch: 6| Step: 12
Training loss: 0.4905191939153661
Validation loss: 2.245503144230822

Epoch: 6| Step: 13
Training loss: 0.4574825634265307
Validation loss: 2.2387341418733278

Epoch: 305| Step: 0
Training loss: 0.2277277708322857
Validation loss: 2.2293291647006788

Epoch: 6| Step: 1
Training loss: 0.5308607302122803
Validation loss: 2.25603821912984

Epoch: 6| Step: 2
Training loss: 0.26090515415931526
Validation loss: 2.254403276675786

Epoch: 6| Step: 3
Training loss: 0.336631966402288
Validation loss: 2.273393096112426

Epoch: 6| Step: 4
Training loss: 0.3317065502552156
Validation loss: 2.2781627542125023

Epoch: 6| Step: 5
Training loss: 0.4064464277612361
Validation loss: 2.296009557246047

Epoch: 6| Step: 6
Training loss: 0.45922909969310943
Validation loss: 2.260092989462024

Epoch: 6| Step: 7
Training loss: 0.3469478590801224
Validation loss: 2.266531000821597

Epoch: 6| Step: 8
Training loss: 0.2665399892498898
Validation loss: 2.2174640541461805

Epoch: 6| Step: 9
Training loss: 0.1707645545784212
Validation loss: 2.238192938613873

Epoch: 6| Step: 10
Training loss: 0.4611427529025834
Validation loss: 2.1924223346620715

Epoch: 6| Step: 11
Training loss: 0.475209049601714
Validation loss: 2.2453072038269024

Epoch: 6| Step: 12
Training loss: 0.500207828006174
Validation loss: 2.226567863165731

Epoch: 6| Step: 13
Training loss: 0.25709656810131754
Validation loss: 2.254469501094637

Epoch: 306| Step: 0
Training loss: 0.46708743577097595
Validation loss: 2.266758178164173

Epoch: 6| Step: 1
Training loss: 0.4333948933756023
Validation loss: 2.2736590609813807

Epoch: 6| Step: 2
Training loss: 0.49318383809843835
Validation loss: 2.2717530393015424

Epoch: 6| Step: 3
Training loss: 0.3328372596879394
Validation loss: 2.24496173654562

Epoch: 6| Step: 4
Training loss: 0.4500887366065113
Validation loss: 2.291292343071077

Epoch: 6| Step: 5
Training loss: 0.253707764145385
Validation loss: 2.235096407755467

Epoch: 6| Step: 6
Training loss: 0.20363367102094604
Validation loss: 2.263081129452216

Epoch: 6| Step: 7
Training loss: 0.2675256051081915
Validation loss: 2.22498502925617

Epoch: 6| Step: 8
Training loss: 0.38076585452858563
Validation loss: 2.244788971832632

Epoch: 6| Step: 9
Training loss: 0.21329856425001983
Validation loss: 2.2526365258029313

Epoch: 6| Step: 10
Training loss: 0.3547928431019717
Validation loss: 2.2177042780985667

Epoch: 6| Step: 11
Training loss: 0.4681394415386195
Validation loss: 2.197156601401238

Epoch: 6| Step: 12
Training loss: 0.10928946795120091
Validation loss: 2.23797629511567

Epoch: 6| Step: 13
Training loss: 0.22523465404301354
Validation loss: 2.237428414171304

Epoch: 307| Step: 0
Training loss: 0.34304249085882904
Validation loss: 2.2230193643513925

Epoch: 6| Step: 1
Training loss: 0.3913606963612622
Validation loss: 2.2406813528064475

Epoch: 6| Step: 2
Training loss: 0.5324512252498346
Validation loss: 2.223258493370457

Epoch: 6| Step: 3
Training loss: 0.33370730412731303
Validation loss: 2.2376347502436427

Epoch: 6| Step: 4
Training loss: 0.2213296858021876
Validation loss: 2.225725450612743

Epoch: 6| Step: 5
Training loss: 0.4693444773912651
Validation loss: 2.2631367837166985

Epoch: 6| Step: 6
Training loss: 0.1246919972402238
Validation loss: 2.2660174919864993

Epoch: 6| Step: 7
Training loss: 0.2830244750494225
Validation loss: 2.2878939067489963

Epoch: 6| Step: 8
Training loss: 0.22753231709841346
Validation loss: 2.30640827926056

Epoch: 6| Step: 9
Training loss: 0.4448939079356734
Validation loss: 2.279925298468211

Epoch: 6| Step: 10
Training loss: 0.2978013793694323
Validation loss: 2.2920889766424475

Epoch: 6| Step: 11
Training loss: 0.4591315987027358
Validation loss: 2.3023495185923677

Epoch: 6| Step: 12
Training loss: 0.20014451475679607
Validation loss: 2.2721171374504947

Epoch: 6| Step: 13
Training loss: 0.3012933582547166
Validation loss: 2.298613419945878

Epoch: 308| Step: 0
Training loss: 0.3476246272931781
Validation loss: 2.301511667562389

Epoch: 6| Step: 1
Training loss: 0.30479406058404973
Validation loss: 2.285906380825875

Epoch: 6| Step: 2
Training loss: 0.39743728004925793
Validation loss: 2.3056292401227823

Epoch: 6| Step: 3
Training loss: 0.32014378314415665
Validation loss: 2.2653096195580096

Epoch: 6| Step: 4
Training loss: 0.18417508836588495
Validation loss: 2.3072068960343652

Epoch: 6| Step: 5
Training loss: 0.25663322890959556
Validation loss: 2.316297190073549

Epoch: 6| Step: 6
Training loss: 0.359136274077818
Validation loss: 2.312180028860534

Epoch: 6| Step: 7
Training loss: 0.3750675458474901
Validation loss: 2.333264758784123

Epoch: 6| Step: 8
Training loss: 0.4962616733888416
Validation loss: 2.3402162257773416

Epoch: 6| Step: 9
Training loss: 0.4551667385025601
Validation loss: 2.324264997168854

Epoch: 6| Step: 10
Training loss: 0.15670988235601457
Validation loss: 2.2930081361262498

Epoch: 6| Step: 11
Training loss: 0.11864458066559794
Validation loss: 2.2895963021849326

Epoch: 6| Step: 12
Training loss: 0.34847122208815934
Validation loss: 2.280253392820694

Epoch: 6| Step: 13
Training loss: 0.3115509045010904
Validation loss: 2.286829278651178

Epoch: 309| Step: 0
Training loss: 0.4020822100878955
Validation loss: 2.2728335020077473

Epoch: 6| Step: 1
Training loss: 0.2216369823039487
Validation loss: 2.2568444854670577

Epoch: 6| Step: 2
Training loss: 0.17806701134523137
Validation loss: 2.261174255670493

Epoch: 6| Step: 3
Training loss: 0.24836843778257076
Validation loss: 2.271997532867107

Epoch: 6| Step: 4
Training loss: 0.368084785162478
Validation loss: 2.254956481992437

Epoch: 6| Step: 5
Training loss: 0.23984993047548217
Validation loss: 2.2888801432353305

Epoch: 6| Step: 6
Training loss: 0.24895361127059507
Validation loss: 2.2623503377660388

Epoch: 6| Step: 7
Training loss: 0.38053718045501983
Validation loss: 2.2546678067877317

Epoch: 6| Step: 8
Training loss: 0.4020135135348325
Validation loss: 2.270793910407342

Epoch: 6| Step: 9
Training loss: 0.4082010807551983
Validation loss: 2.25432634010077

Epoch: 6| Step: 10
Training loss: 0.3212688636807636
Validation loss: 2.2591414658016578

Epoch: 6| Step: 11
Training loss: 0.3612759526708015
Validation loss: 2.2714087720632588

Epoch: 6| Step: 12
Training loss: 0.3030348732271332
Validation loss: 2.2932314770354454

Epoch: 6| Step: 13
Training loss: 0.3008557016945353
Validation loss: 2.2393274270268138

Epoch: 310| Step: 0
Training loss: 0.1857348543919727
Validation loss: 2.300983375715621

Epoch: 6| Step: 1
Training loss: 0.31672061797288903
Validation loss: 2.255453579010294

Epoch: 6| Step: 2
Training loss: 0.1419735855657789
Validation loss: 2.2771429923469904

Epoch: 6| Step: 3
Training loss: 0.633317910391423
Validation loss: 2.244130016920033

Epoch: 6| Step: 4
Training loss: 0.4450103336913158
Validation loss: 2.2852229047361616

Epoch: 6| Step: 5
Training loss: 0.29337906396779195
Validation loss: 2.2411058230791054

Epoch: 6| Step: 6
Training loss: 0.23597540424620256
Validation loss: 2.2308238291559124

Epoch: 6| Step: 7
Training loss: 0.31770200670957566
Validation loss: 2.2400158837648143

Epoch: 6| Step: 8
Training loss: 0.2373023719831612
Validation loss: 2.2612081005753337

Epoch: 6| Step: 9
Training loss: 0.2701869810991954
Validation loss: 2.2470576994507185

Epoch: 6| Step: 10
Training loss: 0.20928964867955296
Validation loss: 2.2530006569516217

Epoch: 6| Step: 11
Training loss: 0.18313928927567566
Validation loss: 2.3097679963961126

Epoch: 6| Step: 12
Training loss: 0.2846844702725874
Validation loss: 2.25875386704205

Epoch: 6| Step: 13
Training loss: 0.28330135614967333
Validation loss: 2.230330593381248

Epoch: 311| Step: 0
Training loss: 0.2692472094583372
Validation loss: 2.2828893509491275

Epoch: 6| Step: 1
Training loss: 0.4609946845838397
Validation loss: 2.26402205302839

Epoch: 6| Step: 2
Training loss: 0.1928814559277577
Validation loss: 2.2592620199109557

Epoch: 6| Step: 3
Training loss: 0.36905986164774685
Validation loss: 2.2311986341728467

Epoch: 6| Step: 4
Training loss: 0.23423480768362892
Validation loss: 2.255739341397305

Epoch: 6| Step: 5
Training loss: 0.4348431363034621
Validation loss: 2.3028708852567856

Epoch: 6| Step: 6
Training loss: 0.1730248719256395
Validation loss: 2.2925173002043326

Epoch: 6| Step: 7
Training loss: 0.41406987741483864
Validation loss: 2.2978791126530997

Epoch: 6| Step: 8
Training loss: 0.28445632159567225
Validation loss: 2.3176773524567116

Epoch: 6| Step: 9
Training loss: 0.3527637304719893
Validation loss: 2.3332851457307813

Epoch: 6| Step: 10
Training loss: 0.25064528157274896
Validation loss: 2.3234718540725154

Epoch: 6| Step: 11
Training loss: 0.34178759971022593
Validation loss: 2.3309213500065313

Epoch: 6| Step: 12
Training loss: 0.2725302768650971
Validation loss: 2.2815795482847108

Epoch: 6| Step: 13
Training loss: 0.2768314088731171
Validation loss: 2.301516542793927

Epoch: 312| Step: 0
Training loss: 0.30184680897913924
Validation loss: 2.2812874353079007

Epoch: 6| Step: 1
Training loss: 0.2942185256965256
Validation loss: 2.272809080085338

Epoch: 6| Step: 2
Training loss: 0.4029852928147324
Validation loss: 2.29620070274012

Epoch: 6| Step: 3
Training loss: 0.36587541595946227
Validation loss: 2.286228852271193

Epoch: 6| Step: 4
Training loss: 0.2802487671524685
Validation loss: 2.2714448052699363

Epoch: 6| Step: 5
Training loss: 0.2863258517852933
Validation loss: 2.260344178695365

Epoch: 6| Step: 6
Training loss: 0.23685491189854246
Validation loss: 2.2640517976819683

Epoch: 6| Step: 7
Training loss: 0.44231729253824803
Validation loss: 2.270767370889579

Epoch: 6| Step: 8
Training loss: 0.3735484401360378
Validation loss: 2.242615694218742

Epoch: 6| Step: 9
Training loss: 0.23737013271528398
Validation loss: 2.27468949346422

Epoch: 6| Step: 10
Training loss: 0.26081004313507666
Validation loss: 2.249536180487529

Epoch: 6| Step: 11
Training loss: 0.189518592770349
Validation loss: 2.2828358167094405

Epoch: 6| Step: 12
Training loss: 0.35718004978183004
Validation loss: 2.27048130210019

Epoch: 6| Step: 13
Training loss: 0.17146357147269686
Validation loss: 2.269383353562407

Epoch: 313| Step: 0
Training loss: 0.39636685363208096
Validation loss: 2.2701770635335317

Epoch: 6| Step: 1
Training loss: 0.2644239930823934
Validation loss: 2.2529285131722614

Epoch: 6| Step: 2
Training loss: 0.35408118095171703
Validation loss: 2.252645078324646

Epoch: 6| Step: 3
Training loss: 0.4160266570298543
Validation loss: 2.218102083375206

Epoch: 6| Step: 4
Training loss: 0.35675125578837724
Validation loss: 2.2583220112386653

Epoch: 6| Step: 5
Training loss: 0.24599018642575873
Validation loss: 2.256366043713058

Epoch: 6| Step: 6
Training loss: 0.3518239850249918
Validation loss: 2.2387975135911966

Epoch: 6| Step: 7
Training loss: 0.24964481693149945
Validation loss: 2.231960278874138

Epoch: 6| Step: 8
Training loss: 0.18126503249016399
Validation loss: 2.255748854424053

Epoch: 6| Step: 9
Training loss: 0.34281474459599215
Validation loss: 2.2437950569414182

Epoch: 6| Step: 10
Training loss: 0.2570200503149971
Validation loss: 2.2460633620479906

Epoch: 6| Step: 11
Training loss: 0.23065491608938288
Validation loss: 2.254539769379117

Epoch: 6| Step: 12
Training loss: 0.18200109461242975
Validation loss: 2.2612521060170185

Epoch: 6| Step: 13
Training loss: 0.1945270288920985
Validation loss: 2.3131552723726285

Epoch: 314| Step: 0
Training loss: 0.3599449696468719
Validation loss: 2.250159714839942

Epoch: 6| Step: 1
Training loss: 0.14127563587839473
Validation loss: 2.2539103674607968

Epoch: 6| Step: 2
Training loss: 0.32608298272496583
Validation loss: 2.2974604684377975

Epoch: 6| Step: 3
Training loss: 0.20011726346629732
Validation loss: 2.294676455027684

Epoch: 6| Step: 4
Training loss: 0.2198408550134198
Validation loss: 2.24285410554417

Epoch: 6| Step: 5
Training loss: 0.3623369721785882
Validation loss: 2.2706888391276423

Epoch: 6| Step: 6
Training loss: 0.3386270953254747
Validation loss: 2.2193911849436216

Epoch: 6| Step: 7
Training loss: 0.2353455000607039
Validation loss: 2.2230901285467266

Epoch: 6| Step: 8
Training loss: 0.17819418483786909
Validation loss: 2.2175434499912243

Epoch: 6| Step: 9
Training loss: 0.2935371987621222
Validation loss: 2.2350905566481667

Epoch: 6| Step: 10
Training loss: 0.49856398421582243
Validation loss: 2.265698978742432

Epoch: 6| Step: 11
Training loss: 0.3257112734354763
Validation loss: 2.275749406480235

Epoch: 6| Step: 12
Training loss: 0.266248630085855
Validation loss: 2.2754486613165064

Epoch: 6| Step: 13
Training loss: 0.2083678733485718
Validation loss: 2.2503890290285193

Epoch: 315| Step: 0
Training loss: 0.30689427035596245
Validation loss: 2.241122996077894

Epoch: 6| Step: 1
Training loss: 0.20611445748774243
Validation loss: 2.235482202364827

Epoch: 6| Step: 2
Training loss: 0.31570504042344794
Validation loss: 2.2724061377261857

Epoch: 6| Step: 3
Training loss: 0.441903956191574
Validation loss: 2.282467225034473

Epoch: 6| Step: 4
Training loss: 0.4444918851401329
Validation loss: 2.257565925124406

Epoch: 6| Step: 5
Training loss: 0.22977270472779587
Validation loss: 2.2559289755398937

Epoch: 6| Step: 6
Training loss: 0.20077558947350643
Validation loss: 2.2802440151916206

Epoch: 6| Step: 7
Training loss: 0.1012679928522046
Validation loss: 2.265410557754982

Epoch: 6| Step: 8
Training loss: 0.19601723367358578
Validation loss: 2.247185822057583

Epoch: 6| Step: 9
Training loss: 0.2714284386401461
Validation loss: 2.2616047132725416

Epoch: 6| Step: 10
Training loss: 0.33557068958971326
Validation loss: 2.236687184768113

Epoch: 6| Step: 11
Training loss: 0.30564205102610775
Validation loss: 2.263671049396968

Epoch: 6| Step: 12
Training loss: 0.2830963459630678
Validation loss: 2.2287981106058004

Epoch: 6| Step: 13
Training loss: 0.15780482958102596
Validation loss: 2.2216131122417444

Epoch: 316| Step: 0
Training loss: 0.3635046487377165
Validation loss: 2.2162233577233876

Epoch: 6| Step: 1
Training loss: 0.31535706998074065
Validation loss: 2.2318951525973376

Epoch: 6| Step: 2
Training loss: 0.30638604013340237
Validation loss: 2.251028173508647

Epoch: 6| Step: 3
Training loss: 0.311868148032775
Validation loss: 2.189708421170335

Epoch: 6| Step: 4
Training loss: 0.1879707229142885
Validation loss: 2.2477857981710763

Epoch: 6| Step: 5
Training loss: 0.17170861708931487
Validation loss: 2.223376864064505

Epoch: 6| Step: 6
Training loss: 0.22766585357925984
Validation loss: 2.2487971133759608

Epoch: 6| Step: 7
Training loss: 0.34154736812539727
Validation loss: 2.259655167845867

Epoch: 6| Step: 8
Training loss: 0.39086439426454384
Validation loss: 2.2382994703327843

Epoch: 6| Step: 9
Training loss: 0.2919674738501173
Validation loss: 2.241227124261817

Epoch: 6| Step: 10
Training loss: 0.2923839199577768
Validation loss: 2.2470430007751303

Epoch: 6| Step: 11
Training loss: 0.40946671790691785
Validation loss: 2.2504657584602192

Epoch: 6| Step: 12
Training loss: 0.2152028117774806
Validation loss: 2.23750361047388

Epoch: 6| Step: 13
Training loss: 0.2560266428472054
Validation loss: 2.2622436818795992

Epoch: 317| Step: 0
Training loss: 0.1636879482889464
Validation loss: 2.211107327005962

Epoch: 6| Step: 1
Training loss: 0.24854468156889067
Validation loss: 2.2104231971335824

Epoch: 6| Step: 2
Training loss: 0.2912638073214703
Validation loss: 2.230808292626398

Epoch: 6| Step: 3
Training loss: 0.3535506721110936
Validation loss: 2.2471201068561517

Epoch: 6| Step: 4
Training loss: 0.3635057965410696
Validation loss: 2.2645170111421185

Epoch: 6| Step: 5
Training loss: 0.27984941952839254
Validation loss: 2.2690465164242455

Epoch: 6| Step: 6
Training loss: 0.4465912311406312
Validation loss: 2.258820821929317

Epoch: 6| Step: 7
Training loss: 0.29454994749425867
Validation loss: 2.2507181240751226

Epoch: 6| Step: 8
Training loss: 0.2854847518202699
Validation loss: 2.27424692338605

Epoch: 6| Step: 9
Training loss: 0.3566067264821065
Validation loss: 2.258769006490546

Epoch: 6| Step: 10
Training loss: 0.2816550993143022
Validation loss: 2.2462531188667088

Epoch: 6| Step: 11
Training loss: 0.2700598964216944
Validation loss: 2.243148570869499

Epoch: 6| Step: 12
Training loss: 0.375299056334088
Validation loss: 2.252563276648258

Epoch: 6| Step: 13
Training loss: 0.47963156296328663
Validation loss: 2.269683994846797

Epoch: 318| Step: 0
Training loss: 0.3459058587405237
Validation loss: 2.278284645718276

Epoch: 6| Step: 1
Training loss: 0.3176114945751243
Validation loss: 2.2583371047690886

Epoch: 6| Step: 2
Training loss: 0.38609552738856606
Validation loss: 2.288077275997773

Epoch: 6| Step: 3
Training loss: 0.3321587710369671
Validation loss: 2.2398944640527336

Epoch: 6| Step: 4
Training loss: 0.4617270802942115
Validation loss: 2.228371309710933

Epoch: 6| Step: 5
Training loss: 0.39373773146998287
Validation loss: 2.2308902639949384

Epoch: 6| Step: 6
Training loss: 0.36760671506441395
Validation loss: 2.2603148922370715

Epoch: 6| Step: 7
Training loss: 0.28316481758697953
Validation loss: 2.2360940314456554

Epoch: 6| Step: 8
Training loss: 0.3435445952112324
Validation loss: 2.2954058390423895

Epoch: 6| Step: 9
Training loss: 0.309109895965765
Validation loss: 2.274702206313883

Epoch: 6| Step: 10
Training loss: 0.3188229561508021
Validation loss: 2.2910318794992537

Epoch: 6| Step: 11
Training loss: 0.30121655361602806
Validation loss: 2.2897710154795585

Epoch: 6| Step: 12
Training loss: 0.20463874614826183
Validation loss: 2.272631150764513

Epoch: 6| Step: 13
Training loss: 0.26654514652038147
Validation loss: 2.3093191338107633

Epoch: 319| Step: 0
Training loss: 0.15206142086958474
Validation loss: 2.3087812708833764

Epoch: 6| Step: 1
Training loss: 0.3613103295145398
Validation loss: 2.282419347785794

Epoch: 6| Step: 2
Training loss: 0.44579576738092996
Validation loss: 2.271718476909564

Epoch: 6| Step: 3
Training loss: 0.1640343641950991
Validation loss: 2.2797805018993946

Epoch: 6| Step: 4
Training loss: 0.2907716124924282
Validation loss: 2.253118666636735

Epoch: 6| Step: 5
Training loss: 0.33829925612526573
Validation loss: 2.232778520257448

Epoch: 6| Step: 6
Training loss: 0.2529702025260481
Validation loss: 2.251782040878384

Epoch: 6| Step: 7
Training loss: 0.36522776551819525
Validation loss: 2.245488450792066

Epoch: 6| Step: 8
Training loss: 0.3632216455927884
Validation loss: 2.2483875246100973

Epoch: 6| Step: 9
Training loss: 0.20862443176818407
Validation loss: 2.2567200448865155

Epoch: 6| Step: 10
Training loss: 0.2304954836582917
Validation loss: 2.256377250976391

Epoch: 6| Step: 11
Training loss: 0.3781026203058668
Validation loss: 2.3025827131144934

Epoch: 6| Step: 12
Training loss: 0.3585498708170173
Validation loss: 2.252370911447099

Epoch: 6| Step: 13
Training loss: 0.44106830049203133
Validation loss: 2.2839921783850095

Epoch: 320| Step: 0
Training loss: 0.39424101852438115
Validation loss: 2.282346091570666

Epoch: 6| Step: 1
Training loss: 0.32485531740937457
Validation loss: 2.2056211726073514

Epoch: 6| Step: 2
Training loss: 0.2670424731436785
Validation loss: 2.2172902984747034

Epoch: 6| Step: 3
Training loss: 0.3330118397220286
Validation loss: 2.2248933394389176

Epoch: 6| Step: 4
Training loss: 0.41083256502189264
Validation loss: 2.2223913529169828

Epoch: 6| Step: 5
Training loss: 0.30718262267873336
Validation loss: 2.21167460234263

Epoch: 6| Step: 6
Training loss: 0.34502737088748414
Validation loss: 2.228281908370171

Epoch: 6| Step: 7
Training loss: 0.1922422951219634
Validation loss: 2.2328202793200496

Epoch: 6| Step: 8
Training loss: 0.2198442949018524
Validation loss: 2.2437273983047397

Epoch: 6| Step: 9
Training loss: 0.2461869048358108
Validation loss: 2.2546692826612267

Epoch: 6| Step: 10
Training loss: 0.14656635533530676
Validation loss: 2.252409379883114

Epoch: 6| Step: 11
Training loss: 0.29311494358600537
Validation loss: 2.2602860483086387

Epoch: 6| Step: 12
Training loss: 0.2905640394613536
Validation loss: 2.2609625525271153

Epoch: 6| Step: 13
Training loss: 0.3018463770207754
Validation loss: 2.257491608315432

Epoch: 321| Step: 0
Training loss: 0.3326957896481011
Validation loss: 2.263559081132797

Epoch: 6| Step: 1
Training loss: 0.3468362803800641
Validation loss: 2.2670308764965865

Epoch: 6| Step: 2
Training loss: 0.158465280081858
Validation loss: 2.2826397672025567

Epoch: 6| Step: 3
Training loss: 0.2603835021199875
Validation loss: 2.2705697972338905

Epoch: 6| Step: 4
Training loss: 0.3918626633060498
Validation loss: 2.2620025167144298

Epoch: 6| Step: 5
Training loss: 0.4685996768242067
Validation loss: 2.2513794356393055

Epoch: 6| Step: 6
Training loss: 0.3429229388565301
Validation loss: 2.242161978213742

Epoch: 6| Step: 7
Training loss: 0.24909799992892773
Validation loss: 2.27854231798223

Epoch: 6| Step: 8
Training loss: 0.20204992243426165
Validation loss: 2.306120486618688

Epoch: 6| Step: 9
Training loss: 0.2476969977229624
Validation loss: 2.2990136189804606

Epoch: 6| Step: 10
Training loss: 0.21768588713936407
Validation loss: 2.294485262441229

Epoch: 6| Step: 11
Training loss: 0.24929799670496355
Validation loss: 2.3065445198426517

Epoch: 6| Step: 12
Training loss: 0.36751971535770056
Validation loss: 2.3051782429345113

Epoch: 6| Step: 13
Training loss: 0.2623725666943776
Validation loss: 2.2616046577286206

Epoch: 322| Step: 0
Training loss: 0.22999588900499504
Validation loss: 2.24647386442076

Epoch: 6| Step: 1
Training loss: 0.09636136835695375
Validation loss: 2.270925308499366

Epoch: 6| Step: 2
Training loss: 0.31087069153110486
Validation loss: 2.2455688236970626

Epoch: 6| Step: 3
Training loss: 0.2077890418730673
Validation loss: 2.2661476567752956

Epoch: 6| Step: 4
Training loss: 0.2819424687604998
Validation loss: 2.2658398111620817

Epoch: 6| Step: 5
Training loss: 0.3407386966252307
Validation loss: 2.2142344825365385

Epoch: 6| Step: 6
Training loss: 0.3337492086994063
Validation loss: 2.2153942654311813

Epoch: 6| Step: 7
Training loss: 0.35125659773525275
Validation loss: 2.2186039112923304

Epoch: 6| Step: 8
Training loss: 0.25698614623342525
Validation loss: 2.20292931621989

Epoch: 6| Step: 9
Training loss: 0.28631963261894633
Validation loss: 2.2175730926438595

Epoch: 6| Step: 10
Training loss: 0.32486061536816263
Validation loss: 2.2205526298931892

Epoch: 6| Step: 11
Training loss: 0.3898060033103019
Validation loss: 2.2312976525409405

Epoch: 6| Step: 12
Training loss: 0.33505354510300306
Validation loss: 2.220533974157455

Epoch: 6| Step: 13
Training loss: 0.18530925794534797
Validation loss: 2.237613716095621

Epoch: 323| Step: 0
Training loss: 0.25971066459965253
Validation loss: 2.2265252510874096

Epoch: 6| Step: 1
Training loss: 0.2901897103403944
Validation loss: 2.1747505249061128

Epoch: 6| Step: 2
Training loss: 0.20221338749028356
Validation loss: 2.233049373358498

Epoch: 6| Step: 3
Training loss: 0.2358233602066842
Validation loss: 2.2276926859246187

Epoch: 6| Step: 4
Training loss: 0.18078862612883345
Validation loss: 2.2817652333026013

Epoch: 6| Step: 5
Training loss: 0.220049311641114
Validation loss: 2.2686603404241397

Epoch: 6| Step: 6
Training loss: 0.45682098572960483
Validation loss: 2.282961110532702

Epoch: 6| Step: 7
Training loss: 0.2927237312615517
Validation loss: 2.2577625122509177

Epoch: 6| Step: 8
Training loss: 0.34554614797296185
Validation loss: 2.317379216028097

Epoch: 6| Step: 9
Training loss: 0.2004097325248317
Validation loss: 2.2654623944265593

Epoch: 6| Step: 10
Training loss: 0.49762994106822617
Validation loss: 2.2570973111726773

Epoch: 6| Step: 11
Training loss: 0.30210646453078926
Validation loss: 2.2598131991461994

Epoch: 6| Step: 12
Training loss: 0.3156994826180584
Validation loss: 2.2762451685378524

Epoch: 6| Step: 13
Training loss: 0.20203073733117952
Validation loss: 2.2795415806110193

Epoch: 324| Step: 0
Training loss: 0.2592883350176253
Validation loss: 2.2534673674426893

Epoch: 6| Step: 1
Training loss: 0.2833270229426929
Validation loss: 2.2838053801519926

Epoch: 6| Step: 2
Training loss: 0.154986560367699
Validation loss: 2.2546166531885596

Epoch: 6| Step: 3
Training loss: 0.2664291606907152
Validation loss: 2.233892928483055

Epoch: 6| Step: 4
Training loss: 0.1152275738083014
Validation loss: 2.265232109540893

Epoch: 6| Step: 5
Training loss: 0.5075711190138122
Validation loss: 2.2378614669443135

Epoch: 6| Step: 6
Training loss: 0.17514179267055036
Validation loss: 2.264738651373443

Epoch: 6| Step: 7
Training loss: 0.24922640887363592
Validation loss: 2.2238223468561373

Epoch: 6| Step: 8
Training loss: 0.2632473247415688
Validation loss: 2.220670790406279

Epoch: 6| Step: 9
Training loss: 0.18537422982182572
Validation loss: 2.2599839759033165

Epoch: 6| Step: 10
Training loss: 0.202857896444043
Validation loss: 2.2547955435869107

Epoch: 6| Step: 11
Training loss: 0.2665037038431206
Validation loss: 2.2908330756736515

Epoch: 6| Step: 12
Training loss: 0.32023884926709045
Validation loss: 2.2293920264089278

Epoch: 6| Step: 13
Training loss: 0.4015880264896688
Validation loss: 2.2712972439390953

Epoch: 325| Step: 0
Training loss: 0.1844337604121617
Validation loss: 2.2640927178101973

Epoch: 6| Step: 1
Training loss: 0.2650998337522106
Validation loss: 2.275028410865665

Epoch: 6| Step: 2
Training loss: 0.34392805256554726
Validation loss: 2.2839068198357757

Epoch: 6| Step: 3
Training loss: 0.28235691848386296
Validation loss: 2.2406607085221357

Epoch: 6| Step: 4
Training loss: 0.2805501654996844
Validation loss: 2.2660273731054987

Epoch: 6| Step: 5
Training loss: 0.2118348355891546
Validation loss: 2.2634452430254552

Epoch: 6| Step: 6
Training loss: 0.3549412596823024
Validation loss: 2.237226662158568

Epoch: 6| Step: 7
Training loss: 0.31304550242950163
Validation loss: 2.219122199002781

Epoch: 6| Step: 8
Training loss: 0.2626649633411263
Validation loss: 2.256640336399635

Epoch: 6| Step: 9
Training loss: 0.2102895870310615
Validation loss: 2.285718129546842

Epoch: 6| Step: 10
Training loss: 0.20761967654813107
Validation loss: 2.2616900078548285

Epoch: 6| Step: 11
Training loss: 0.380958270413423
Validation loss: 2.244900106783884

Epoch: 6| Step: 12
Training loss: 0.23223546510769214
Validation loss: 2.2460562668535538

Epoch: 6| Step: 13
Training loss: 0.2660262219171071
Validation loss: 2.2605087917792273

Epoch: 326| Step: 0
Training loss: 0.26932864936555817
Validation loss: 2.2685090093427553

Epoch: 6| Step: 1
Training loss: 0.2372992872086794
Validation loss: 2.2679286629775257

Epoch: 6| Step: 2
Training loss: 0.20773962578767247
Validation loss: 2.2856415920245374

Epoch: 6| Step: 3
Training loss: 0.18563952893255528
Validation loss: 2.2629730647403723

Epoch: 6| Step: 4
Training loss: 0.36525899630700626
Validation loss: 2.239290507223398

Epoch: 6| Step: 5
Training loss: 0.2600115135743036
Validation loss: 2.266467397853364

Epoch: 6| Step: 6
Training loss: 0.39181965298679194
Validation loss: 2.266526791765304

Epoch: 6| Step: 7
Training loss: 0.26501231497813954
Validation loss: 2.2863928766126826

Epoch: 6| Step: 8
Training loss: 0.31732673736528827
Validation loss: 2.270814080639821

Epoch: 6| Step: 9
Training loss: 0.3443320288736525
Validation loss: 2.251746574799195

Epoch: 6| Step: 10
Training loss: 0.23155459306836557
Validation loss: 2.202553605095941

Epoch: 6| Step: 11
Training loss: 0.16498264499627588
Validation loss: 2.234091975653925

Epoch: 6| Step: 12
Training loss: 0.2551313628039215
Validation loss: 2.24196703335989

Epoch: 6| Step: 13
Training loss: 0.18573332002253026
Validation loss: 2.236231705888313

Epoch: 327| Step: 0
Training loss: 0.2064933266288786
Validation loss: 2.1903144017871394

Epoch: 6| Step: 1
Training loss: 0.2196188259907018
Validation loss: 2.2060323275559193

Epoch: 6| Step: 2
Training loss: 0.21031962075159907
Validation loss: 2.2207507076806694

Epoch: 6| Step: 3
Training loss: 0.3024977097345776
Validation loss: 2.279045060913027

Epoch: 6| Step: 4
Training loss: 0.22106967296184968
Validation loss: 2.215083607688039

Epoch: 6| Step: 5
Training loss: 0.343266960527273
Validation loss: 2.263410097317038

Epoch: 6| Step: 6
Training loss: 0.3342466384287828
Validation loss: 2.2377450673700063

Epoch: 6| Step: 7
Training loss: 0.27190410633599055
Validation loss: 2.2501612232924493

Epoch: 6| Step: 8
Training loss: 0.19489557589546733
Validation loss: 2.2363140846059233

Epoch: 6| Step: 9
Training loss: 0.3019796007005657
Validation loss: 2.2622262306489667

Epoch: 6| Step: 10
Training loss: 0.17039291272733026
Validation loss: 2.256483566665698

Epoch: 6| Step: 11
Training loss: 0.1756285640076629
Validation loss: 2.2323895068801525

Epoch: 6| Step: 12
Training loss: 0.4506106333089207
Validation loss: 2.2857993413789988

Epoch: 6| Step: 13
Training loss: 0.3307775952583699
Validation loss: 2.2593245344392634

Epoch: 328| Step: 0
Training loss: 0.31620287540329994
Validation loss: 2.259568302222639

Epoch: 6| Step: 1
Training loss: 0.13351062703920272
Validation loss: 2.254272372055368

Epoch: 6| Step: 2
Training loss: 0.3639449343137382
Validation loss: 2.233814091363927

Epoch: 6| Step: 3
Training loss: 0.24378438517541415
Validation loss: 2.259785477036836

Epoch: 6| Step: 4
Training loss: 0.2207618314595438
Validation loss: 2.280329122142512

Epoch: 6| Step: 5
Training loss: 0.31490680593229725
Validation loss: 2.255716657942805

Epoch: 6| Step: 6
Training loss: 0.20399812879183363
Validation loss: 2.2398017847350387

Epoch: 6| Step: 7
Training loss: 0.34721500813089556
Validation loss: 2.2815652793216774

Epoch: 6| Step: 8
Training loss: 0.19814122264462986
Validation loss: 2.2858018715967514

Epoch: 6| Step: 9
Training loss: 0.3851988623764693
Validation loss: 2.288756850231977

Epoch: 6| Step: 10
Training loss: 0.3768428384206938
Validation loss: 2.29494786960155

Epoch: 6| Step: 11
Training loss: 0.14882227317939906
Validation loss: 2.2663143991680825

Epoch: 6| Step: 12
Training loss: 0.2444866322527594
Validation loss: 2.287232272603849

Epoch: 6| Step: 13
Training loss: 0.14227207204842074
Validation loss: 2.224696387591983

Epoch: 329| Step: 0
Training loss: 0.2371974828501499
Validation loss: 2.2582641540412833

Epoch: 6| Step: 1
Training loss: 0.12996554787028206
Validation loss: 2.2223205105219193

Epoch: 6| Step: 2
Training loss: 0.2550780034904716
Validation loss: 2.226698796163466

Epoch: 6| Step: 3
Training loss: 0.2730090053639815
Validation loss: 2.240253012013246

Epoch: 6| Step: 4
Training loss: 0.392193867149189
Validation loss: 2.2328384259554817

Epoch: 6| Step: 5
Training loss: 0.1382879665058277
Validation loss: 2.198664385871136

Epoch: 6| Step: 6
Training loss: 0.3224199445743879
Validation loss: 2.2518476314161773

Epoch: 6| Step: 7
Training loss: 0.3273138396771272
Validation loss: 2.2345129421251806

Epoch: 6| Step: 8
Training loss: 0.1937457953273698
Validation loss: 2.2489632367928634

Epoch: 6| Step: 9
Training loss: 0.2365207990125917
Validation loss: 2.2403570187141737

Epoch: 6| Step: 10
Training loss: 0.218917254811869
Validation loss: 2.2494055738709022

Epoch: 6| Step: 11
Training loss: 0.37541644496819443
Validation loss: 2.2857044203002577

Epoch: 6| Step: 12
Training loss: 0.3068377110498602
Validation loss: 2.2622013270411325

Epoch: 6| Step: 13
Training loss: 0.2502131000899037
Validation loss: 2.2657082988969095

Epoch: 330| Step: 0
Training loss: 0.3126023482566722
Validation loss: 2.256380910594829

Epoch: 6| Step: 1
Training loss: 0.3478188081085326
Validation loss: 2.2803166719770798

Epoch: 6| Step: 2
Training loss: 0.31704732917105266
Validation loss: 2.2719380802730904

Epoch: 6| Step: 3
Training loss: 0.23344692221422594
Validation loss: 2.290631011197089

Epoch: 6| Step: 4
Training loss: 0.3150855156078769
Validation loss: 2.2775343458824735

Epoch: 6| Step: 5
Training loss: 0.22090863474979142
Validation loss: 2.274295167122458

Epoch: 6| Step: 6
Training loss: 0.24334947189338804
Validation loss: 2.2884483422067787

Epoch: 6| Step: 7
Training loss: 0.2615522595250186
Validation loss: 2.3261405849249117

Epoch: 6| Step: 8
Training loss: 0.18492336918848087
Validation loss: 2.306392964557494

Epoch: 6| Step: 9
Training loss: 0.36834445247581543
Validation loss: 2.334747042935401

Epoch: 6| Step: 10
Training loss: 0.31771232519091314
Validation loss: 2.2750596787879345

Epoch: 6| Step: 11
Training loss: 0.25469307396060825
Validation loss: 2.2729891546486907

Epoch: 6| Step: 12
Training loss: 0.1348832971192422
Validation loss: 2.233255073701825

Epoch: 6| Step: 13
Training loss: 0.26629865996435104
Validation loss: 2.2551783627186777

Epoch: 331| Step: 0
Training loss: 0.26560821199658996
Validation loss: 2.233717338209877

Epoch: 6| Step: 1
Training loss: 0.17156116052531994
Validation loss: 2.223718516761747

Epoch: 6| Step: 2
Training loss: 0.3598153691895526
Validation loss: 2.2239325871718063

Epoch: 6| Step: 3
Training loss: 0.17306707707748525
Validation loss: 2.2026998021877464

Epoch: 6| Step: 4
Training loss: 0.35732910119552674
Validation loss: 2.206072848614122

Epoch: 6| Step: 5
Training loss: 0.39714754013150744
Validation loss: 2.2134391893170227

Epoch: 6| Step: 6
Training loss: 0.28053053916423804
Validation loss: 2.220879128960203

Epoch: 6| Step: 7
Training loss: 0.2752509879112705
Validation loss: 2.2530966372204744

Epoch: 6| Step: 8
Training loss: 0.20200215450993292
Validation loss: 2.2200643045730586

Epoch: 6| Step: 9
Training loss: 0.3546169471310459
Validation loss: 2.269083372929031

Epoch: 6| Step: 10
Training loss: 0.28410243921290185
Validation loss: 2.267146311863751

Epoch: 6| Step: 11
Training loss: 0.1982389553163618
Validation loss: 2.269284256144607

Epoch: 6| Step: 12
Training loss: 0.24700867407979366
Validation loss: 2.2234960044108565

Epoch: 6| Step: 13
Training loss: 0.10564061132018214
Validation loss: 2.2541795011420414

Epoch: 332| Step: 0
Training loss: 0.25649194925251906
Validation loss: 2.2505456281090956

Epoch: 6| Step: 1
Training loss: 0.34293752801893984
Validation loss: 2.2728487631086227

Epoch: 6| Step: 2
Training loss: 0.11761775901272972
Validation loss: 2.2598052755800317

Epoch: 6| Step: 3
Training loss: 0.3185712659160008
Validation loss: 2.245087321590469

Epoch: 6| Step: 4
Training loss: 0.24719945073325203
Validation loss: 2.288473953842825

Epoch: 6| Step: 5
Training loss: 0.38628575137950183
Validation loss: 2.308818258687391

Epoch: 6| Step: 6
Training loss: 0.2577608230124109
Validation loss: 2.2737525524585163

Epoch: 6| Step: 7
Training loss: 0.19239188429458196
Validation loss: 2.2703388221703724

Epoch: 6| Step: 8
Training loss: 0.20455236706227808
Validation loss: 2.2458387403997437

Epoch: 6| Step: 9
Training loss: 0.19010057620137286
Validation loss: 2.2493986615983776

Epoch: 6| Step: 10
Training loss: 0.2649401362747593
Validation loss: 2.2329773791719743

Epoch: 6| Step: 11
Training loss: 0.23427974036621954
Validation loss: 2.240090051911385

Epoch: 6| Step: 12
Training loss: 0.1943562942654491
Validation loss: 2.2626654055544853

Epoch: 6| Step: 13
Training loss: 0.34794343380932946
Validation loss: 2.2664588296231134

Epoch: 333| Step: 0
Training loss: 0.2949162413204288
Validation loss: 2.236942027126277

Epoch: 6| Step: 1
Training loss: 0.12914669846447366
Validation loss: 2.2673273035712143

Epoch: 6| Step: 2
Training loss: 0.25033525994465733
Validation loss: 2.2677860599762694

Epoch: 6| Step: 3
Training loss: 0.150608981752837
Validation loss: 2.2748875387459364

Epoch: 6| Step: 4
Training loss: 0.45568880356563074
Validation loss: 2.2690635852921366

Epoch: 6| Step: 5
Training loss: 0.2914657823434651
Validation loss: 2.2607718363953486

Epoch: 6| Step: 6
Training loss: 0.31122493493600917
Validation loss: 2.257231728943759

Epoch: 6| Step: 7
Training loss: 0.13899845298585442
Validation loss: 2.2782929978738213

Epoch: 6| Step: 8
Training loss: 0.13932763445225488
Validation loss: 2.2325362437274565

Epoch: 6| Step: 9
Training loss: 0.12705526644554826
Validation loss: 2.2416767174420387

Epoch: 6| Step: 10
Training loss: 0.3556959662669069
Validation loss: 2.2267503101850057

Epoch: 6| Step: 11
Training loss: 0.279114323425077
Validation loss: 2.237160035035095

Epoch: 6| Step: 12
Training loss: 0.25647129528613527
Validation loss: 2.2243099174411367

Epoch: 6| Step: 13
Training loss: 0.20761327982084324
Validation loss: 2.2473479333928847

Epoch: 334| Step: 0
Training loss: 0.2437927667073248
Validation loss: 2.239353049807086

Epoch: 6| Step: 1
Training loss: 0.16664586210538732
Validation loss: 2.2938117636671853

Epoch: 6| Step: 2
Training loss: 0.19963025620264113
Validation loss: 2.299497498917766

Epoch: 6| Step: 3
Training loss: 0.12931531244531808
Validation loss: 2.296724269447955

Epoch: 6| Step: 4
Training loss: 0.42401512696614746
Validation loss: 2.28347231713499

Epoch: 6| Step: 5
Training loss: 0.21055028838326104
Validation loss: 2.3039200089015432

Epoch: 6| Step: 6
Training loss: 0.27753185555471793
Validation loss: 2.339239860420118

Epoch: 6| Step: 7
Training loss: 0.32277595110009966
Validation loss: 2.3037922495034833

Epoch: 6| Step: 8
Training loss: 0.36967260387137096
Validation loss: 2.3351013353011583

Epoch: 6| Step: 9
Training loss: 0.17294972536517944
Validation loss: 2.298505914902299

Epoch: 6| Step: 10
Training loss: 0.23803426105066697
Validation loss: 2.278107388259509

Epoch: 6| Step: 11
Training loss: 0.3890902696986483
Validation loss: 2.2794244631424285

Epoch: 6| Step: 12
Training loss: 0.22091878633682582
Validation loss: 2.2709011640876753

Epoch: 6| Step: 13
Training loss: 0.16947070328256636
Validation loss: 2.2388180966177154

Epoch: 335| Step: 0
Training loss: 0.23916680298335039
Validation loss: 2.2730552829320145

Epoch: 6| Step: 1
Training loss: 0.18329650069102527
Validation loss: 2.284842578109835

Epoch: 6| Step: 2
Training loss: 0.2059509685233575
Validation loss: 2.3015727880781633

Epoch: 6| Step: 3
Training loss: 0.2578024862252037
Validation loss: 2.27251029959881

Epoch: 6| Step: 4
Training loss: 0.35309534750139066
Validation loss: 2.2693123355601394

Epoch: 6| Step: 5
Training loss: 0.27133046734362015
Validation loss: 2.2826318931105716

Epoch: 6| Step: 6
Training loss: 0.2785482577431197
Validation loss: 2.295856713587102

Epoch: 6| Step: 7
Training loss: 0.3802900313649454
Validation loss: 2.2732300673067427

Epoch: 6| Step: 8
Training loss: 0.2370460890850657
Validation loss: 2.2233919953461716

Epoch: 6| Step: 9
Training loss: 0.21584963707180937
Validation loss: 2.2386746046508734

Epoch: 6| Step: 10
Training loss: 0.3099972401388432
Validation loss: 2.190818835552878

Epoch: 6| Step: 11
Training loss: 0.35234863548528855
Validation loss: 2.196980685956456

Epoch: 6| Step: 12
Training loss: 0.1988816120024411
Validation loss: 2.2011116129426

Epoch: 6| Step: 13
Training loss: 0.33087689061736186
Validation loss: 2.1880955367409802

Epoch: 336| Step: 0
Training loss: 0.32973381006495867
Validation loss: 2.1791788543389843

Epoch: 6| Step: 1
Training loss: 0.2514700435360074
Validation loss: 2.1684048984870508

Epoch: 6| Step: 2
Training loss: 0.3000114299663062
Validation loss: 2.1588334807028033

Epoch: 6| Step: 3
Training loss: 0.3316450228809501
Validation loss: 2.2314357446899065

Epoch: 6| Step: 4
Training loss: 0.25245662030945626
Validation loss: 2.2063570956567964

Epoch: 6| Step: 5
Training loss: 0.3215021626776457
Validation loss: 2.219563429685596

Epoch: 6| Step: 6
Training loss: 0.2060542264815683
Validation loss: 2.2254848103671643

Epoch: 6| Step: 7
Training loss: 0.2063195302834966
Validation loss: 2.207991974935792

Epoch: 6| Step: 8
Training loss: 0.23442496720783973
Validation loss: 2.239265504526724

Epoch: 6| Step: 9
Training loss: 0.26825922578445527
Validation loss: 2.202207007653685

Epoch: 6| Step: 10
Training loss: 0.26981783571814943
Validation loss: 2.260291003669783

Epoch: 6| Step: 11
Training loss: 0.300014285899797
Validation loss: 2.24419545584199

Epoch: 6| Step: 12
Training loss: 0.14392730465674305
Validation loss: 2.229529594967926

Epoch: 6| Step: 13
Training loss: 0.27035144734803895
Validation loss: 2.2329579242674864

Epoch: 337| Step: 0
Training loss: 0.1637311382022911
Validation loss: 2.2266461273015086

Epoch: 6| Step: 1
Training loss: 0.2358709279301694
Validation loss: 2.212370679860435

Epoch: 6| Step: 2
Training loss: 0.12331010274156819
Validation loss: 2.2310745034202215

Epoch: 6| Step: 3
Training loss: 0.326243090136202
Validation loss: 2.2204029791223494

Epoch: 6| Step: 4
Training loss: 0.185858986009509
Validation loss: 2.2238364545899305

Epoch: 6| Step: 5
Training loss: 0.30647008247509805
Validation loss: 2.2300357552410937

Epoch: 6| Step: 6
Training loss: 0.3328919418871136
Validation loss: 2.2702009022774523

Epoch: 6| Step: 7
Training loss: 0.2815918434424814
Validation loss: 2.253639945778167

Epoch: 6| Step: 8
Training loss: 0.2167881456971815
Validation loss: 2.2224145114759697

Epoch: 6| Step: 9
Training loss: 0.18139699779247875
Validation loss: 2.2291512874532393

Epoch: 6| Step: 10
Training loss: 0.3446553402559326
Validation loss: 2.2409978666770227

Epoch: 6| Step: 11
Training loss: 0.3628776933975472
Validation loss: 2.238494282783491

Epoch: 6| Step: 12
Training loss: 0.1311734969974314
Validation loss: 2.273623545532047

Epoch: 6| Step: 13
Training loss: 0.2487956257890406
Validation loss: 2.292807058322954

Epoch: 338| Step: 0
Training loss: 0.14754337886226007
Validation loss: 2.270478426800135

Epoch: 6| Step: 1
Training loss: 0.16891973775990587
Validation loss: 2.2420111901974655

Epoch: 6| Step: 2
Training loss: 0.33212393420747965
Validation loss: 2.2765196955304874

Epoch: 6| Step: 3
Training loss: 0.32940442556432037
Validation loss: 2.260868461925652

Epoch: 6| Step: 4
Training loss: 0.2608734686175493
Validation loss: 2.294851278119415

Epoch: 6| Step: 5
Training loss: 0.23111966719646415
Validation loss: 2.307412343647226

Epoch: 6| Step: 6
Training loss: 0.346795849748107
Validation loss: 2.2801633441776596

Epoch: 6| Step: 7
Training loss: 0.1602769141269891
Validation loss: 2.2562225371940214

Epoch: 6| Step: 8
Training loss: 0.23729004049427724
Validation loss: 2.2541493839739206

Epoch: 6| Step: 9
Training loss: 0.17224502829600546
Validation loss: 2.249122781329692

Epoch: 6| Step: 10
Training loss: 0.296886443871229
Validation loss: 2.2687782768336677

Epoch: 6| Step: 11
Training loss: 0.21150789142094703
Validation loss: 2.235932091363108

Epoch: 6| Step: 12
Training loss: 0.3257225962652124
Validation loss: 2.2566201545040934

Epoch: 6| Step: 13
Training loss: 0.1830630240519151
Validation loss: 2.2189085165867604

Epoch: 339| Step: 0
Training loss: 0.18449759690857098
Validation loss: 2.259597608001153

Epoch: 6| Step: 1
Training loss: 0.17626127820758486
Validation loss: 2.3004471151670947

Epoch: 6| Step: 2
Training loss: 0.29628851330378714
Validation loss: 2.3084720951319957

Epoch: 6| Step: 3
Training loss: 0.37997376596092425
Validation loss: 2.268998941538071

Epoch: 6| Step: 4
Training loss: 0.3047122333953751
Validation loss: 2.281834396440696

Epoch: 6| Step: 5
Training loss: 0.19120655541858664
Validation loss: 2.288417346282602

Epoch: 6| Step: 6
Training loss: 0.3464626223714809
Validation loss: 2.2591996364192735

Epoch: 6| Step: 7
Training loss: 0.3953890775308437
Validation loss: 2.2919808143536176

Epoch: 6| Step: 8
Training loss: 0.17812713780709727
Validation loss: 2.235105681177172

Epoch: 6| Step: 9
Training loss: 0.25466073252428234
Validation loss: 2.2660826224062434

Epoch: 6| Step: 10
Training loss: 0.23465537149729965
Validation loss: 2.2648956595896554

Epoch: 6| Step: 11
Training loss: 0.13967129046843457
Validation loss: 2.2391641700091056

Epoch: 6| Step: 12
Training loss: 0.202835665556848
Validation loss: 2.2711260479835813

Epoch: 6| Step: 13
Training loss: 0.11826153746511486
Validation loss: 2.2685332102919866

Epoch: 340| Step: 0
Training loss: 0.3587306714915381
Validation loss: 2.263748884658465

Epoch: 6| Step: 1
Training loss: 0.14694666078131383
Validation loss: 2.3027370135261327

Epoch: 6| Step: 2
Training loss: 0.3155137767844351
Validation loss: 2.304232767140489

Epoch: 6| Step: 3
Training loss: 0.17124504907092247
Validation loss: 2.2980687210195816

Epoch: 6| Step: 4
Training loss: 0.27170396061507235
Validation loss: 2.2553372538926397

Epoch: 6| Step: 5
Training loss: 0.3882901411362556
Validation loss: 2.288556011090267

Epoch: 6| Step: 6
Training loss: 0.3794822640527767
Validation loss: 2.248537435955006

Epoch: 6| Step: 7
Training loss: 0.26153284558787077
Validation loss: 2.2235478082348106

Epoch: 6| Step: 8
Training loss: 0.19823411633828011
Validation loss: 2.233259996058908

Epoch: 6| Step: 9
Training loss: 0.1099535168842305
Validation loss: 2.235079880380954

Epoch: 6| Step: 10
Training loss: 0.17949811657897718
Validation loss: 2.270113024042506

Epoch: 6| Step: 11
Training loss: 0.24606282176083202
Validation loss: 2.251376691376122

Epoch: 6| Step: 12
Training loss: 0.277614622414213
Validation loss: 2.270403736034554

Epoch: 6| Step: 13
Training loss: 0.1395586632223819
Validation loss: 2.2562678153033153

Epoch: 341| Step: 0
Training loss: 0.3334655412611267
Validation loss: 2.2493838579807015

Epoch: 6| Step: 1
Training loss: 0.17717497688859563
Validation loss: 2.299561899592825

Epoch: 6| Step: 2
Training loss: 0.21801193930584054
Validation loss: 2.2634192354802543

Epoch: 6| Step: 3
Training loss: 0.1374111422153032
Validation loss: 2.2811854936753924

Epoch: 6| Step: 4
Training loss: 0.25795399510997474
Validation loss: 2.2972504531661193

Epoch: 6| Step: 5
Training loss: 0.24699551501816164
Validation loss: 2.2738748235579935

Epoch: 6| Step: 6
Training loss: 0.2934983235535516
Validation loss: 2.295933679914648

Epoch: 6| Step: 7
Training loss: 0.22520736205526468
Validation loss: 2.2902781283822184

Epoch: 6| Step: 8
Training loss: 0.3000177254010011
Validation loss: 2.2700747946272224

Epoch: 6| Step: 9
Training loss: 0.2911680321712351
Validation loss: 2.2778211287576617

Epoch: 6| Step: 10
Training loss: 0.20150785259831655
Validation loss: 2.234640975904641

Epoch: 6| Step: 11
Training loss: 0.29739309577995804
Validation loss: 2.239930305207933

Epoch: 6| Step: 12
Training loss: 0.19738254292686924
Validation loss: 2.2456430981261293

Epoch: 6| Step: 13
Training loss: 0.36467706519907417
Validation loss: 2.2446606096268167

Epoch: 342| Step: 0
Training loss: 0.3634891120429135
Validation loss: 2.2488438246081324

Epoch: 6| Step: 1
Training loss: 0.17901418836399566
Validation loss: 2.2689657777809296

Epoch: 6| Step: 2
Training loss: 0.2398042938383295
Validation loss: 2.278443761535132

Epoch: 6| Step: 3
Training loss: 0.20010840227455548
Validation loss: 2.2485352189575956

Epoch: 6| Step: 4
Training loss: 0.22922556383995732
Validation loss: 2.275486019127146

Epoch: 6| Step: 5
Training loss: 0.13024835130541346
Validation loss: 2.2699434797227176

Epoch: 6| Step: 6
Training loss: 0.20258788474067538
Validation loss: 2.28518350334453

Epoch: 6| Step: 7
Training loss: 0.12311236969677253
Validation loss: 2.2777546901801697

Epoch: 6| Step: 8
Training loss: 0.20872345795614067
Validation loss: 2.2300438989657216

Epoch: 6| Step: 9
Training loss: 0.15913900779984838
Validation loss: 2.2787311885100188

Epoch: 6| Step: 10
Training loss: 0.23526821005896356
Validation loss: 2.2606590911839386

Epoch: 6| Step: 11
Training loss: 0.24072362346338794
Validation loss: 2.258560065987433

Epoch: 6| Step: 12
Training loss: 0.4453873487779275
Validation loss: 2.2876612998594865

Epoch: 6| Step: 13
Training loss: 0.3847663801931338
Validation loss: 2.274566827156586

Epoch: 343| Step: 0
Training loss: 0.45347644068203463
Validation loss: 2.2968044944055803

Epoch: 6| Step: 1
Training loss: 0.23326783935673295
Validation loss: 2.2575299094350143

Epoch: 6| Step: 2
Training loss: 0.1650261958597442
Validation loss: 2.2760742169027974

Epoch: 6| Step: 3
Training loss: 0.2397320698600733
Validation loss: 2.2408805303175994

Epoch: 6| Step: 4
Training loss: 0.33705280045824465
Validation loss: 2.2695688187350376

Epoch: 6| Step: 5
Training loss: 0.1368666666141712
Validation loss: 2.2549873301927255

Epoch: 6| Step: 6
Training loss: 0.19241958111887603
Validation loss: 2.2787329204928337

Epoch: 6| Step: 7
Training loss: 0.17316113245554912
Validation loss: 2.253206620584031

Epoch: 6| Step: 8
Training loss: 0.1598693091503351
Validation loss: 2.2343876565324785

Epoch: 6| Step: 9
Training loss: 0.27595381268402147
Validation loss: 2.1990949614513413

Epoch: 6| Step: 10
Training loss: 0.24955284839713537
Validation loss: 2.2140203764442514

Epoch: 6| Step: 11
Training loss: 0.22154830198435757
Validation loss: 2.2385310748552247

Epoch: 6| Step: 12
Training loss: 0.1668109970457418
Validation loss: 2.252816568594341

Epoch: 6| Step: 13
Training loss: 0.1749898899087113
Validation loss: 2.245371096200641

Epoch: 344| Step: 0
Training loss: 0.19018492006876814
Validation loss: 2.2224145668458157

Epoch: 6| Step: 1
Training loss: 0.32776140322077835
Validation loss: 2.26776746101261

Epoch: 6| Step: 2
Training loss: 0.1962244582259492
Validation loss: 2.264838468371323

Epoch: 6| Step: 3
Training loss: 0.3565910146078644
Validation loss: 2.2187633759532885

Epoch: 6| Step: 4
Training loss: 0.2706021168617191
Validation loss: 2.2929857464464196

Epoch: 6| Step: 5
Training loss: 0.17418974861675576
Validation loss: 2.2868681718876327

Epoch: 6| Step: 6
Training loss: 0.25299199636619585
Validation loss: 2.297178907827959

Epoch: 6| Step: 7
Training loss: 0.29948665637173677
Validation loss: 2.2821569855006825

Epoch: 6| Step: 8
Training loss: 0.29359465813610525
Validation loss: 2.2812816478890006

Epoch: 6| Step: 9
Training loss: 0.3274135597099713
Validation loss: 2.248977274877335

Epoch: 6| Step: 10
Training loss: 0.36880425361189034
Validation loss: 2.2975701915248736

Epoch: 6| Step: 11
Training loss: 0.13157275031971735
Validation loss: 2.2763966768089303

Epoch: 6| Step: 12
Training loss: 0.24975354742656258
Validation loss: 2.2861023262576254

Epoch: 6| Step: 13
Training loss: 0.17096719720965395
Validation loss: 2.2968345818790725

Epoch: 345| Step: 0
Training loss: 0.17915800072722665
Validation loss: 2.2783305723491325

Epoch: 6| Step: 1
Training loss: 0.2989331353874052
Validation loss: 2.280845281414464

Epoch: 6| Step: 2
Training loss: 0.22506473656358492
Validation loss: 2.313317409123797

Epoch: 6| Step: 3
Training loss: 0.247516357611032
Validation loss: 2.332831808619847

Epoch: 6| Step: 4
Training loss: 0.3250139435197889
Validation loss: 2.297360426203654

Epoch: 6| Step: 5
Training loss: 0.3178469975445954
Validation loss: 2.263756970520625

Epoch: 6| Step: 6
Training loss: 0.19446116874122918
Validation loss: 2.3098214203120575

Epoch: 6| Step: 7
Training loss: 0.19679909484144364
Validation loss: 2.286230331879291

Epoch: 6| Step: 8
Training loss: 0.14138017645869655
Validation loss: 2.2643492000842094

Epoch: 6| Step: 9
Training loss: 0.2716429679403125
Validation loss: 2.2893453891711038

Epoch: 6| Step: 10
Training loss: 0.27984898023973315
Validation loss: 2.2701211129279724

Epoch: 6| Step: 11
Training loss: 0.3064456611470852
Validation loss: 2.2823591532224183

Epoch: 6| Step: 12
Training loss: 0.20660809691754403
Validation loss: 2.2715141658342284

Epoch: 6| Step: 13
Training loss: 0.2910848957543678
Validation loss: 2.28365948135699

Epoch: 346| Step: 0
Training loss: 0.21530677145547342
Validation loss: 2.2503838775653398

Epoch: 6| Step: 1
Training loss: 0.09551262385101086
Validation loss: 2.288260074861265

Epoch: 6| Step: 2
Training loss: 0.27871365776418633
Validation loss: 2.262826390355398

Epoch: 6| Step: 3
Training loss: 0.3074925488057683
Validation loss: 2.2443289848947567

Epoch: 6| Step: 4
Training loss: 0.19731603110630447
Validation loss: 2.2346382975580203

Epoch: 6| Step: 5
Training loss: 0.1988546559857489
Validation loss: 2.250746587742734

Epoch: 6| Step: 6
Training loss: 0.2975472944196892
Validation loss: 2.2573764960686384

Epoch: 6| Step: 7
Training loss: 0.1837343935275091
Validation loss: 2.2437955887968433

Epoch: 6| Step: 8
Training loss: 0.24135968027634538
Validation loss: 2.2525606191848797

Epoch: 6| Step: 9
Training loss: 0.15401135355879764
Validation loss: 2.2742232907876234

Epoch: 6| Step: 10
Training loss: 0.38815549352891715
Validation loss: 2.2912037778135628

Epoch: 6| Step: 11
Training loss: 0.1753899351246611
Validation loss: 2.2471601265902055

Epoch: 6| Step: 12
Training loss: 0.22777779788424887
Validation loss: 2.250920644018459

Epoch: 6| Step: 13
Training loss: 0.2341595692777965
Validation loss: 2.2421708342373123

Epoch: 347| Step: 0
Training loss: 0.3035707426163593
Validation loss: 2.2382553034082795

Epoch: 6| Step: 1
Training loss: 0.20163764550876173
Validation loss: 2.2181603189568673

Epoch: 6| Step: 2
Training loss: 0.34328739509760103
Validation loss: 2.2360724167238146

Epoch: 6| Step: 3
Training loss: 0.19418951489680408
Validation loss: 2.25739254647244

Epoch: 6| Step: 4
Training loss: 0.1318216104140033
Validation loss: 2.2276755693556587

Epoch: 6| Step: 5
Training loss: 0.1529700293015006
Validation loss: 2.2552867781883426

Epoch: 6| Step: 6
Training loss: 0.18757482863409103
Validation loss: 2.249868515575462

Epoch: 6| Step: 7
Training loss: 0.31612393064005045
Validation loss: 2.2573822764928146

Epoch: 6| Step: 8
Training loss: 0.310765447411397
Validation loss: 2.2616531538532625

Epoch: 6| Step: 9
Training loss: 0.14259662900020953
Validation loss: 2.25054260773145

Epoch: 6| Step: 10
Training loss: 0.25232974447587786
Validation loss: 2.2518771953457706

Epoch: 6| Step: 11
Training loss: 0.20471079489959898
Validation loss: 2.2520854644144532

Epoch: 6| Step: 12
Training loss: 0.12588041909835065
Validation loss: 2.2542998031680863

Epoch: 6| Step: 13
Training loss: 0.16969453467756365
Validation loss: 2.2458728757655533

Epoch: 348| Step: 0
Training loss: 0.13925809927077548
Validation loss: 2.2677506209197973

Epoch: 6| Step: 1
Training loss: 0.22312917176522
Validation loss: 2.2522243445326695

Epoch: 6| Step: 2
Training loss: 0.3540717119195282
Validation loss: 2.278704156694665

Epoch: 6| Step: 3
Training loss: 0.29007276345662864
Validation loss: 2.27100435305201

Epoch: 6| Step: 4
Training loss: 0.24858185005358222
Validation loss: 2.264716065980211

Epoch: 6| Step: 5
Training loss: 0.14189122269009596
Validation loss: 2.279910391710067

Epoch: 6| Step: 6
Training loss: 0.22053930228377497
Validation loss: 2.3178643309047424

Epoch: 6| Step: 7
Training loss: 0.13394893366562585
Validation loss: 2.2841985922229546

Epoch: 6| Step: 8
Training loss: 0.1220844031784498
Validation loss: 2.324952643242198

Epoch: 6| Step: 9
Training loss: 0.3624098591704966
Validation loss: 2.311156377261633

Epoch: 6| Step: 10
Training loss: 0.1971986109146886
Validation loss: 2.272477117987512

Epoch: 6| Step: 11
Training loss: 0.1825012614258845
Validation loss: 2.291805483695902

Epoch: 6| Step: 12
Training loss: 0.2298133469654958
Validation loss: 2.2524715411333593

Epoch: 6| Step: 13
Training loss: 0.11834612920186206
Validation loss: 2.2417812030032453

Epoch: 349| Step: 0
Training loss: 0.1990312928511025
Validation loss: 2.246600293238919

Epoch: 6| Step: 1
Training loss: 0.2039487166048479
Validation loss: 2.264122971631498

Epoch: 6| Step: 2
Training loss: 0.1191382095217127
Validation loss: 2.2751207929932056

Epoch: 6| Step: 3
Training loss: 0.25999712846160616
Validation loss: 2.246350443663456

Epoch: 6| Step: 4
Training loss: 0.3174491578229883
Validation loss: 2.2785250877816665

Epoch: 6| Step: 5
Training loss: 0.21136434953229927
Validation loss: 2.2641324771743623

Epoch: 6| Step: 6
Training loss: 0.17652737892715925
Validation loss: 2.267044656824927

Epoch: 6| Step: 7
Training loss: 0.13152110336493927
Validation loss: 2.2535715955694227

Epoch: 6| Step: 8
Training loss: 0.2065599944039188
Validation loss: 2.2697524271361496

Epoch: 6| Step: 9
Training loss: 0.3056474870081416
Validation loss: 2.2662999817753535

Epoch: 6| Step: 10
Training loss: 0.3011936358000803
Validation loss: 2.2461061784240792

Epoch: 6| Step: 11
Training loss: 0.20267615796249272
Validation loss: 2.2184671698043457

Epoch: 6| Step: 12
Training loss: 0.2823389614904581
Validation loss: 2.265673780923912

Epoch: 6| Step: 13
Training loss: 0.1464598380837209
Validation loss: 2.2513471630065

Epoch: 350| Step: 0
Training loss: 0.2921098835510414
Validation loss: 2.2502499393707147

Epoch: 6| Step: 1
Training loss: 0.18269503561002584
Validation loss: 2.298207983695655

Epoch: 6| Step: 2
Training loss: 0.2153221785525147
Validation loss: 2.2502393469896234

Epoch: 6| Step: 3
Training loss: 0.2249596973589685
Validation loss: 2.2653599885000313

Epoch: 6| Step: 4
Training loss: 0.2234403790108392
Validation loss: 2.313112771380399

Epoch: 6| Step: 5
Training loss: 0.13153467725692003
Validation loss: 2.2931666777838497

Epoch: 6| Step: 6
Training loss: 0.39590795549752067
Validation loss: 2.2734862015321458

Epoch: 6| Step: 7
Training loss: 0.20612070192259346
Validation loss: 2.3202035198222086

Epoch: 6| Step: 8
Training loss: 0.14262220929179625
Validation loss: 2.2726324796065405

Epoch: 6| Step: 9
Training loss: 0.2488919153893106
Validation loss: 2.248051448512423

Epoch: 6| Step: 10
Training loss: 0.21494946046580937
Validation loss: 2.271123395873103

Epoch: 6| Step: 11
Training loss: 0.35203429459949687
Validation loss: 2.2538470248400984

Epoch: 6| Step: 12
Training loss: 0.2790938352952681
Validation loss: 2.281361327557227

Epoch: 6| Step: 13
Training loss: 0.15686633028147362
Validation loss: 2.278059726323893

Testing loss: 2.577769399452113
