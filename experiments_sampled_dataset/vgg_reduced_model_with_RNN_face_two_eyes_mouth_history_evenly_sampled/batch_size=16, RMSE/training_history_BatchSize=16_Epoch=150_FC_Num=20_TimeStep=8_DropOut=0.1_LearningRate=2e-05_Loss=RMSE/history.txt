Epoch: 1| Step: 0
Training loss: 5.200184217271027
Validation loss: 5.71238747166805

Epoch: 6| Step: 1
Training loss: 5.5701974479703145
Validation loss: 5.693640141278094

Epoch: 6| Step: 2
Training loss: 5.515888153801176
Validation loss: 5.6766328950370335

Epoch: 6| Step: 3
Training loss: 6.11527648151026
Validation loss: 5.659108854180002

Epoch: 6| Step: 4
Training loss: 5.807057447514229
Validation loss: 5.638978859446535

Epoch: 6| Step: 5
Training loss: 5.800935788135084
Validation loss: 5.616561148916873

Epoch: 6| Step: 6
Training loss: 7.1969515810895155
Validation loss: 5.5907345740846175

Epoch: 6| Step: 7
Training loss: 6.501774178973401
Validation loss: 5.562324689844999

Epoch: 6| Step: 8
Training loss: 3.3702939036090163
Validation loss: 5.529486647930019

Epoch: 6| Step: 9
Training loss: 4.033217548778688
Validation loss: 5.494028020656526

Epoch: 6| Step: 10
Training loss: 5.944371152685447
Validation loss: 5.4550274279108

Epoch: 6| Step: 11
Training loss: 5.725163766442659
Validation loss: 5.411293239582633

Epoch: 6| Step: 12
Training loss: 5.435737762772848
Validation loss: 5.3613113870173965

Epoch: 6| Step: 13
Training loss: 4.7681373852643825
Validation loss: 5.3093387914857715

Epoch: 2| Step: 0
Training loss: 4.46746551619906
Validation loss: 5.25321533451843

Epoch: 6| Step: 1
Training loss: 4.492197265614386
Validation loss: 5.193641475652646

Epoch: 6| Step: 2
Training loss: 5.032609838735805
Validation loss: 5.1332167679446625

Epoch: 6| Step: 3
Training loss: 4.201900488160368
Validation loss: 5.070004581498616

Epoch: 6| Step: 4
Training loss: 4.933621198830016
Validation loss: 5.007112483401777

Epoch: 6| Step: 5
Training loss: 4.555671493998494
Validation loss: 4.941515476534374

Epoch: 6| Step: 6
Training loss: 5.41242090744481
Validation loss: 4.875874110995423

Epoch: 6| Step: 7
Training loss: 4.698992665877934
Validation loss: 4.807198410437074

Epoch: 6| Step: 8
Training loss: 5.432605689223631
Validation loss: 4.738402361108595

Epoch: 6| Step: 9
Training loss: 5.860595575994909
Validation loss: 4.670274945103583

Epoch: 6| Step: 10
Training loss: 4.8727971504149235
Validation loss: 4.606261863197328

Epoch: 6| Step: 11
Training loss: 4.311291953900545
Validation loss: 4.5473984067248825

Epoch: 6| Step: 12
Training loss: 5.0269757234659895
Validation loss: 4.494619676087055

Epoch: 6| Step: 13
Training loss: 5.333230355381208
Validation loss: 4.450190241896095

Epoch: 3| Step: 0
Training loss: 4.422128191597336
Validation loss: 4.409115175922604

Epoch: 6| Step: 1
Training loss: 4.654159588695985
Validation loss: 4.376241973524575

Epoch: 6| Step: 2
Training loss: 4.716235570898158
Validation loss: 4.34545605486114

Epoch: 6| Step: 3
Training loss: 4.659140080363773
Validation loss: 4.314312549657048

Epoch: 6| Step: 4
Training loss: 4.689739455283978
Validation loss: 4.283717641391974

Epoch: 6| Step: 5
Training loss: 3.4649521940822487
Validation loss: 4.250539500517556

Epoch: 6| Step: 6
Training loss: 3.846728775629287
Validation loss: 4.217598077007732

Epoch: 6| Step: 7
Training loss: 4.218218734633481
Validation loss: 4.187404885556416

Epoch: 6| Step: 8
Training loss: 4.465165414512107
Validation loss: 4.160491842626054

Epoch: 6| Step: 9
Training loss: 4.091794078161335
Validation loss: 4.13130023571981

Epoch: 6| Step: 10
Training loss: 4.562145898742829
Validation loss: 4.104579935753999

Epoch: 6| Step: 11
Training loss: 3.812840180776087
Validation loss: 4.077276736087816

Epoch: 6| Step: 12
Training loss: 4.817519505554841
Validation loss: 4.045630456188827

Epoch: 6| Step: 13
Training loss: 4.147502441773434
Validation loss: 4.013744719876989

Epoch: 4| Step: 0
Training loss: 3.867896552539882
Validation loss: 3.9902034292504363

Epoch: 6| Step: 1
Training loss: 4.466135393877498
Validation loss: 3.9629198135521033

Epoch: 6| Step: 2
Training loss: 4.286115791041902
Validation loss: 3.943482728662302

Epoch: 6| Step: 3
Training loss: 4.325718179511315
Validation loss: 3.931340661051692

Epoch: 6| Step: 4
Training loss: 3.3272222449712676
Validation loss: 3.9196073444942052

Epoch: 6| Step: 5
Training loss: 3.8825342090128805
Validation loss: 3.909008967188064

Epoch: 6| Step: 6
Training loss: 4.580136426867731
Validation loss: 3.8934605437678567

Epoch: 6| Step: 7
Training loss: 4.400885596884477
Validation loss: 3.8645956595742548

Epoch: 6| Step: 8
Training loss: 4.087609731152056
Validation loss: 3.8408916405827362

Epoch: 6| Step: 9
Training loss: 2.563574867906736
Validation loss: 3.827266221932154

Epoch: 6| Step: 10
Training loss: 4.679205715235042
Validation loss: 3.8138485814166936

Epoch: 6| Step: 11
Training loss: 4.45873584296971
Validation loss: 3.79166645932166

Epoch: 6| Step: 12
Training loss: 3.256629051946571
Validation loss: 3.77063671889627

Epoch: 6| Step: 13
Training loss: 3.541942645521324
Validation loss: 3.7573293029413444

Epoch: 5| Step: 0
Training loss: 4.173641216714653
Validation loss: 3.7457354973511805

Epoch: 6| Step: 1
Training loss: 3.9322011503534275
Validation loss: 3.7335987565474453

Epoch: 6| Step: 2
Training loss: 5.046127405687811
Validation loss: 3.720986447700499

Epoch: 6| Step: 3
Training loss: 3.948590840908469
Validation loss: 3.702537275718021

Epoch: 6| Step: 4
Training loss: 3.606867460019221
Validation loss: 3.694877001700235

Epoch: 6| Step: 5
Training loss: 3.228470577564962
Validation loss: 3.676848092069994

Epoch: 6| Step: 6
Training loss: 4.25786804722941
Validation loss: 3.6663877855632823

Epoch: 6| Step: 7
Training loss: 3.126169062332781
Validation loss: 3.655527669482725

Epoch: 6| Step: 8
Training loss: 2.823181046121068
Validation loss: 3.6482003361875615

Epoch: 6| Step: 9
Training loss: 4.3509277757468725
Validation loss: 3.6349205757303356

Epoch: 6| Step: 10
Training loss: 3.19401900918424
Validation loss: 3.6246133738877355

Epoch: 6| Step: 11
Training loss: 4.6708568879803165
Validation loss: 3.613691073664477

Epoch: 6| Step: 12
Training loss: 2.8170121344107626
Validation loss: 3.604503948461096

Epoch: 6| Step: 13
Training loss: 4.265637296442327
Validation loss: 3.597532178030852

Epoch: 6| Step: 0
Training loss: 3.1542305103796493
Validation loss: 3.5947011964839053

Epoch: 6| Step: 1
Training loss: 4.1805211456899185
Validation loss: 3.586131449774326

Epoch: 6| Step: 2
Training loss: 3.920106770365375
Validation loss: 3.5780118079004777

Epoch: 6| Step: 3
Training loss: 3.9177508916405337
Validation loss: 3.576102960449807

Epoch: 6| Step: 4
Training loss: 4.672733087741835
Validation loss: 3.575581623715553

Epoch: 6| Step: 5
Training loss: 3.8058532558181715
Validation loss: 3.570612992979196

Epoch: 6| Step: 6
Training loss: 3.7963670932471025
Validation loss: 3.5623266569752645

Epoch: 6| Step: 7
Training loss: 4.220915965971945
Validation loss: 3.5566651466660772

Epoch: 6| Step: 8
Training loss: 3.271978886365972
Validation loss: 3.544601339788513

Epoch: 6| Step: 9
Training loss: 3.590523507034236
Validation loss: 3.5363475390689216

Epoch: 6| Step: 10
Training loss: 3.881896004841864
Validation loss: 3.5309089948283607

Epoch: 6| Step: 11
Training loss: 3.052633624327125
Validation loss: 3.527367750000869

Epoch: 6| Step: 12
Training loss: 3.2187236303341855
Validation loss: 3.5237794610157476

Epoch: 6| Step: 13
Training loss: 3.5264878021293216
Validation loss: 3.5197127694227475

Epoch: 7| Step: 0
Training loss: 3.2176209478757722
Validation loss: 3.5127964584680087

Epoch: 6| Step: 1
Training loss: 3.643540160743957
Validation loss: 3.5019406389583345

Epoch: 6| Step: 2
Training loss: 3.801347272858294
Validation loss: 3.492657721383283

Epoch: 6| Step: 3
Training loss: 3.5427482898092393
Validation loss: 3.482963177026831

Epoch: 6| Step: 4
Training loss: 2.792293269497468
Validation loss: 3.4771444348205844

Epoch: 6| Step: 5
Training loss: 4.244752673884684
Validation loss: 3.4724443534978495

Epoch: 6| Step: 6
Training loss: 4.262826078141748
Validation loss: 3.46835994254951

Epoch: 6| Step: 7
Training loss: 3.960959530379748
Validation loss: 3.464117462731473

Epoch: 6| Step: 8
Training loss: 4.268951125314876
Validation loss: 3.4587951413099263

Epoch: 6| Step: 9
Training loss: 3.4500725835269037
Validation loss: 3.454985579539265

Epoch: 6| Step: 10
Training loss: 3.0656584976030485
Validation loss: 3.4530547597082717

Epoch: 6| Step: 11
Training loss: 3.7824899201091786
Validation loss: 3.445127954973132

Epoch: 6| Step: 12
Training loss: 2.9923807983112796
Validation loss: 3.4442002269633547

Epoch: 6| Step: 13
Training loss: 4.4819352694070975
Validation loss: 3.4451152525635567

Epoch: 8| Step: 0
Training loss: 3.3716920253260767
Validation loss: 3.4407787806221464

Epoch: 6| Step: 1
Training loss: 2.8318615250865684
Validation loss: 3.434901733487908

Epoch: 6| Step: 2
Training loss: 4.553320442356462
Validation loss: 3.429833984535702

Epoch: 6| Step: 3
Training loss: 4.05045422491115
Validation loss: 3.4247938903847803

Epoch: 6| Step: 4
Training loss: 3.8530236001142155
Validation loss: 3.4205653929088857

Epoch: 6| Step: 5
Training loss: 4.554836997037334
Validation loss: 3.418611267734009

Epoch: 6| Step: 6
Training loss: 3.8211896080608136
Validation loss: 3.4140891503072734

Epoch: 6| Step: 7
Training loss: 3.0896630312688713
Validation loss: 3.414071227020488

Epoch: 6| Step: 8
Training loss: 3.3980329601626953
Validation loss: 3.414522265417034

Epoch: 6| Step: 9
Training loss: 3.7518461133717693
Validation loss: 3.4216177313556813

Epoch: 6| Step: 10
Training loss: 3.2320995342961156
Validation loss: 3.415420934406713

Epoch: 6| Step: 11
Training loss: 3.3261849206566687
Validation loss: 3.4151217381517136

Epoch: 6| Step: 12
Training loss: 3.3849751032895554
Validation loss: 3.4091857018440934

Epoch: 6| Step: 13
Training loss: 3.1259099017123075
Validation loss: 3.4018116567612426

Epoch: 9| Step: 0
Training loss: 3.5194059258607675
Validation loss: 3.395230483167317

Epoch: 6| Step: 1
Training loss: 2.8907803880321064
Validation loss: 3.3907763203201737

Epoch: 6| Step: 2
Training loss: 3.95528404170749
Validation loss: 3.3868936083208

Epoch: 6| Step: 3
Training loss: 3.6980373022612976
Validation loss: 3.3846816337296683

Epoch: 6| Step: 4
Training loss: 3.838146808800221
Validation loss: 3.3818465003166147

Epoch: 6| Step: 5
Training loss: 3.5522833774353524
Validation loss: 3.379521138899465

Epoch: 6| Step: 6
Training loss: 3.4316706387418265
Validation loss: 3.3771075250768092

Epoch: 6| Step: 7
Training loss: 3.90180081093029
Validation loss: 3.37442343924614

Epoch: 6| Step: 8
Training loss: 3.5099025693233394
Validation loss: 3.3709610729796275

Epoch: 6| Step: 9
Training loss: 3.5135067131745954
Validation loss: 3.366019880468685

Epoch: 6| Step: 10
Training loss: 3.347631465504082
Validation loss: 3.3622394869355197

Epoch: 6| Step: 11
Training loss: 3.258526401377113
Validation loss: 3.358980841477427

Epoch: 6| Step: 12
Training loss: 3.835669358587333
Validation loss: 3.354953933090723

Epoch: 6| Step: 13
Training loss: 4.388456956450429
Validation loss: 3.351957299874195

Epoch: 10| Step: 0
Training loss: 4.057630231815676
Validation loss: 3.3463872231910066

Epoch: 6| Step: 1
Training loss: 2.9484936763908443
Validation loss: 3.3421358021382983

Epoch: 6| Step: 2
Training loss: 3.459051096017993
Validation loss: 3.3397951686866096

Epoch: 6| Step: 3
Training loss: 2.6194039595724963
Validation loss: 3.3374901330530182

Epoch: 6| Step: 4
Training loss: 3.3224171867986065
Validation loss: 3.33312732972627

Epoch: 6| Step: 5
Training loss: 4.222400583437308
Validation loss: 3.330481184762761

Epoch: 6| Step: 6
Training loss: 3.2300994182202682
Validation loss: 3.325044935158584

Epoch: 6| Step: 7
Training loss: 3.8165268190796713
Validation loss: 3.3221962525519735

Epoch: 6| Step: 8
Training loss: 3.971440041869517
Validation loss: 3.3182813236189217

Epoch: 6| Step: 9
Training loss: 2.781434470927628
Validation loss: 3.3185432583661827

Epoch: 6| Step: 10
Training loss: 3.4367812358901606
Validation loss: 3.317480414455365

Epoch: 6| Step: 11
Training loss: 4.065056099404853
Validation loss: 3.3239912703288543

Epoch: 6| Step: 12
Training loss: 4.2594141196387705
Validation loss: 3.3247554671554216

Epoch: 6| Step: 13
Training loss: 2.9206298786288296
Validation loss: 3.3139567485373282

Epoch: 11| Step: 0
Training loss: 2.98911248906595
Validation loss: 3.3094966923339495

Epoch: 6| Step: 1
Training loss: 3.7466500896435573
Validation loss: 3.3075663284510215

Epoch: 6| Step: 2
Training loss: 3.3278934595220573
Validation loss: 3.305046241853394

Epoch: 6| Step: 3
Training loss: 4.053557427720029
Validation loss: 3.3045356773989276

Epoch: 6| Step: 4
Training loss: 3.817317233104199
Validation loss: 3.302332201476331

Epoch: 6| Step: 5
Training loss: 3.101881957237532
Validation loss: 3.30107443251911

Epoch: 6| Step: 6
Training loss: 3.8085819811516886
Validation loss: 3.297147793903177

Epoch: 6| Step: 7
Training loss: 2.866281641749307
Validation loss: 3.2937164487373507

Epoch: 6| Step: 8
Training loss: 3.5501940821932867
Validation loss: 3.29259468123805

Epoch: 6| Step: 9
Training loss: 4.335498024603159
Validation loss: 3.291459125431451

Epoch: 6| Step: 10
Training loss: 3.2694195326082265
Validation loss: 3.2910652831447456

Epoch: 6| Step: 11
Training loss: 3.7366665628542672
Validation loss: 3.2883291982287517

Epoch: 6| Step: 12
Training loss: 3.1342362286625027
Validation loss: 3.2860633552033534

Epoch: 6| Step: 13
Training loss: 3.5049981804814423
Validation loss: 3.2854490430729375

Epoch: 12| Step: 0
Training loss: 3.364175321013329
Validation loss: 3.2843160404078073

Epoch: 6| Step: 1
Training loss: 3.891920617018333
Validation loss: 3.2821614645611685

Epoch: 6| Step: 2
Training loss: 2.5059849625095953
Validation loss: 3.2793799177535163

Epoch: 6| Step: 3
Training loss: 2.4592097923696876
Validation loss: 3.2765775775933674

Epoch: 6| Step: 4
Training loss: 4.1137479424971355
Validation loss: 3.2750859974210935

Epoch: 6| Step: 5
Training loss: 3.862870459706947
Validation loss: 3.2735792528706904

Epoch: 6| Step: 6
Training loss: 3.653701807174739
Validation loss: 3.271707287269493

Epoch: 6| Step: 7
Training loss: 3.4749431138905558
Validation loss: 3.269841960095808

Epoch: 6| Step: 8
Training loss: 3.7175225548229935
Validation loss: 3.26849917966682

Epoch: 6| Step: 9
Training loss: 3.063509871910082
Validation loss: 3.2661597980795802

Epoch: 6| Step: 10
Training loss: 3.3232598361730163
Validation loss: 3.264147629638922

Epoch: 6| Step: 11
Training loss: 4.144193903418476
Validation loss: 3.261796534215436

Epoch: 6| Step: 12
Training loss: 3.851403285328005
Validation loss: 3.260744827605005

Epoch: 6| Step: 13
Training loss: 3.1992896960616384
Validation loss: 3.258148932218757

Epoch: 13| Step: 0
Training loss: 3.7699672624699563
Validation loss: 3.256075622923188

Epoch: 6| Step: 1
Training loss: 3.6623157493933256
Validation loss: 3.251988957951758

Epoch: 6| Step: 2
Training loss: 3.539795115517121
Validation loss: 3.2502578620433895

Epoch: 6| Step: 3
Training loss: 2.3172534853490996
Validation loss: 3.247702931365749

Epoch: 6| Step: 4
Training loss: 2.9824102035523916
Validation loss: 3.2460871444261183

Epoch: 6| Step: 5
Training loss: 3.5901001017861223
Validation loss: 3.243274425973738

Epoch: 6| Step: 6
Training loss: 2.542288740565334
Validation loss: 3.240719559602392

Epoch: 6| Step: 7
Training loss: 4.315112663203891
Validation loss: 3.240906224932403

Epoch: 6| Step: 8
Training loss: 3.2236100328640767
Validation loss: 3.239026301922098

Epoch: 6| Step: 9
Training loss: 4.005260108378306
Validation loss: 3.2370983894436045

Epoch: 6| Step: 10
Training loss: 3.4323017002512834
Validation loss: 3.2373985618302332

Epoch: 6| Step: 11
Training loss: 4.144966584405698
Validation loss: 3.2329773207593666

Epoch: 6| Step: 12
Training loss: 3.814579130983286
Validation loss: 3.2265251658268355

Epoch: 6| Step: 13
Training loss: 2.460169693591206
Validation loss: 3.219641383947414

Epoch: 14| Step: 0
Training loss: 3.2464523025597356
Validation loss: 3.2156710818282517

Epoch: 6| Step: 1
Training loss: 3.2527499668906206
Validation loss: 3.2109286057140682

Epoch: 6| Step: 2
Training loss: 3.243931312859264
Validation loss: 3.2007559438442015

Epoch: 6| Step: 3
Training loss: 3.421981740183803
Validation loss: 3.19877912515372

Epoch: 6| Step: 4
Training loss: 2.801132371672062
Validation loss: 3.193725806557764

Epoch: 6| Step: 5
Training loss: 2.699326685556768
Validation loss: 3.1894632719896667

Epoch: 6| Step: 6
Training loss: 3.907428045019121
Validation loss: 3.1908111392946004

Epoch: 6| Step: 7
Training loss: 3.4616147448619556
Validation loss: 3.187339035496418

Epoch: 6| Step: 8
Training loss: 2.935456559447328
Validation loss: 3.182817768502927

Epoch: 6| Step: 9
Training loss: 3.7063747906060365
Validation loss: 3.180160137015912

Epoch: 6| Step: 10
Training loss: 3.324503329475745
Validation loss: 3.1779173683052973

Epoch: 6| Step: 11
Training loss: 4.26650175928276
Validation loss: 3.174546070058944

Epoch: 6| Step: 12
Training loss: 4.40808500132498
Validation loss: 3.1702250763008553

Epoch: 6| Step: 13
Training loss: 2.882354120961803
Validation loss: 3.168424900794502

Epoch: 15| Step: 0
Training loss: 3.3811140840469758
Validation loss: 3.166681780776357

Epoch: 6| Step: 1
Training loss: 3.4488910938476556
Validation loss: 3.1647602737406055

Epoch: 6| Step: 2
Training loss: 3.7871944895992313
Validation loss: 3.165999252071428

Epoch: 6| Step: 3
Training loss: 3.1800638861806583
Validation loss: 3.163768713855698

Epoch: 6| Step: 4
Training loss: 3.6778246138690274
Validation loss: 3.1623184127001207

Epoch: 6| Step: 5
Training loss: 3.0695658545170983
Validation loss: 3.1593278798302764

Epoch: 6| Step: 6
Training loss: 3.705838653741347
Validation loss: 3.1570834457821277

Epoch: 6| Step: 7
Training loss: 3.2748975024309117
Validation loss: 3.1584116363321133

Epoch: 6| Step: 8
Training loss: 3.231963802276578
Validation loss: 3.155841763222147

Epoch: 6| Step: 9
Training loss: 3.8186058803902476
Validation loss: 3.1524292148131408

Epoch: 6| Step: 10
Training loss: 3.630979933027426
Validation loss: 3.155157771988661

Epoch: 6| Step: 11
Training loss: 2.8039019236261553
Validation loss: 3.151073625213182

Epoch: 6| Step: 12
Training loss: 3.5062513382037053
Validation loss: 3.1523913621207242

Epoch: 6| Step: 13
Training loss: 3.190700943329792
Validation loss: 3.1570878550919126

Epoch: 16| Step: 0
Training loss: 3.897674669385471
Validation loss: 3.1610231479955053

Epoch: 6| Step: 1
Training loss: 3.2255744067686725
Validation loss: 3.1487239283027537

Epoch: 6| Step: 2
Training loss: 4.188097555312257
Validation loss: 3.1462517579390434

Epoch: 6| Step: 3
Training loss: 3.0871930236180054
Validation loss: 3.1415199453988576

Epoch: 6| Step: 4
Training loss: 3.27989561193946
Validation loss: 3.1377934348927425

Epoch: 6| Step: 5
Training loss: 2.8456166607059883
Validation loss: 3.1373599283409317

Epoch: 6| Step: 6
Training loss: 3.3149310134452823
Validation loss: 3.1383048723714015

Epoch: 6| Step: 7
Training loss: 3.1600980057789236
Validation loss: 3.138792647557521

Epoch: 6| Step: 8
Training loss: 4.0523105482451545
Validation loss: 3.1370259834080194

Epoch: 6| Step: 9
Training loss: 2.7921113945782836
Validation loss: 3.1360504166195184

Epoch: 6| Step: 10
Training loss: 3.54455867199278
Validation loss: 3.1539818082191653

Epoch: 6| Step: 11
Training loss: 3.9240167248726245
Validation loss: 3.126940691090816

Epoch: 6| Step: 12
Training loss: 3.180445025511797
Validation loss: 3.1299369453716013

Epoch: 6| Step: 13
Training loss: 2.4260193835346593
Validation loss: 3.1411229098438564

Epoch: 17| Step: 0
Training loss: 2.938609948368429
Validation loss: 3.21181486649269

Epoch: 6| Step: 1
Training loss: 2.8523182324762444
Validation loss: 3.186347410416437

Epoch: 6| Step: 2
Training loss: 3.614080095392614
Validation loss: 3.1782651777182855

Epoch: 6| Step: 3
Training loss: 3.56451439373713
Validation loss: 3.139754747247484

Epoch: 6| Step: 4
Training loss: 3.193986911534273
Validation loss: 3.1224703782381815

Epoch: 6| Step: 5
Training loss: 3.288237914608499
Validation loss: 3.1238232815169487

Epoch: 6| Step: 6
Training loss: 3.4142259082926025
Validation loss: 3.129296227015009

Epoch: 6| Step: 7
Training loss: 3.3462896951879544
Validation loss: 3.141364696827977

Epoch: 6| Step: 8
Training loss: 4.435986542842119
Validation loss: 3.14686042291923

Epoch: 6| Step: 9
Training loss: 3.5953763515964696
Validation loss: 3.144052170890155

Epoch: 6| Step: 10
Training loss: 3.0186128194216395
Validation loss: 3.142490407433227

Epoch: 6| Step: 11
Training loss: 3.343635628428768
Validation loss: 3.137762788315191

Epoch: 6| Step: 12
Training loss: 3.7158237773062033
Validation loss: 3.1248369301528682

Epoch: 6| Step: 13
Training loss: 3.016737974669411
Validation loss: 3.11524805876107

Epoch: 18| Step: 0
Training loss: 4.339823752837029
Validation loss: 3.1131866371119883

Epoch: 6| Step: 1
Training loss: 3.288922014656725
Validation loss: 3.107649782705967

Epoch: 6| Step: 2
Training loss: 2.7080642468707135
Validation loss: 3.106403987904802

Epoch: 6| Step: 3
Training loss: 3.545786955396029
Validation loss: 3.1045228090791386

Epoch: 6| Step: 4
Training loss: 3.1783441428640975
Validation loss: 3.10354576885331

Epoch: 6| Step: 5
Training loss: 3.1961001891950382
Validation loss: 3.102453609914743

Epoch: 6| Step: 6
Training loss: 3.461938717516226
Validation loss: 3.1005745702949703

Epoch: 6| Step: 7
Training loss: 3.4103268365480863
Validation loss: 3.102128651441641

Epoch: 6| Step: 8
Training loss: 3.3744903462212963
Validation loss: 3.09775929192385

Epoch: 6| Step: 9
Training loss: 3.7390591281440475
Validation loss: 3.0989670074057467

Epoch: 6| Step: 10
Training loss: 3.31739344916605
Validation loss: 3.098216378100284

Epoch: 6| Step: 11
Training loss: 3.2430877538730414
Validation loss: 3.0965185703483815

Epoch: 6| Step: 12
Training loss: 2.4754172965550154
Validation loss: 3.093983622845491

Epoch: 6| Step: 13
Training loss: 3.8957952133734466
Validation loss: 3.09078654925428

Epoch: 19| Step: 0
Training loss: 3.6099258596991177
Validation loss: 3.092072886741525

Epoch: 6| Step: 1
Training loss: 3.4935327452122324
Validation loss: 3.0910554240557526

Epoch: 6| Step: 2
Training loss: 2.2907392070032664
Validation loss: 3.0884518883787413

Epoch: 6| Step: 3
Training loss: 2.957321334175875
Validation loss: 3.0900830375759414

Epoch: 6| Step: 4
Training loss: 4.137826110342675
Validation loss: 3.0901080509659975

Epoch: 6| Step: 5
Training loss: 2.6711290891038453
Validation loss: 3.0886925271379884

Epoch: 6| Step: 6
Training loss: 3.133951869407567
Validation loss: 3.0875380004680566

Epoch: 6| Step: 7
Training loss: 3.4491136822191137
Validation loss: 3.0856739526156183

Epoch: 6| Step: 8
Training loss: 3.4434216905343984
Validation loss: 3.085077428273723

Epoch: 6| Step: 9
Training loss: 4.168475534076966
Validation loss: 3.083916103250527

Epoch: 6| Step: 10
Training loss: 3.6139331126522816
Validation loss: 3.0813758731700953

Epoch: 6| Step: 11
Training loss: 2.8003167654421537
Validation loss: 3.080788190219032

Epoch: 6| Step: 12
Training loss: 3.5045221270160525
Validation loss: 3.0802561635098136

Epoch: 6| Step: 13
Training loss: 3.309996468579578
Validation loss: 3.079326761708418

Epoch: 20| Step: 0
Training loss: 4.037845627485202
Validation loss: 3.0771590406278038

Epoch: 6| Step: 1
Training loss: 3.445444394309649
Validation loss: 3.0772459629039792

Epoch: 6| Step: 2
Training loss: 3.246285296319111
Validation loss: 3.0742161865407147

Epoch: 6| Step: 3
Training loss: 2.9225841620394957
Validation loss: 3.0737504112046774

Epoch: 6| Step: 4
Training loss: 3.7099137670977957
Validation loss: 3.0727962502978654

Epoch: 6| Step: 5
Training loss: 3.986540321933709
Validation loss: 3.070839991550961

Epoch: 6| Step: 6
Training loss: 2.9755899437432007
Validation loss: 3.069897690423352

Epoch: 6| Step: 7
Training loss: 3.4840477759833424
Validation loss: 3.0697592519395545

Epoch: 6| Step: 8
Training loss: 2.5430167526191334
Validation loss: 3.0672397512975436

Epoch: 6| Step: 9
Training loss: 2.9136049458561772
Validation loss: 3.067472660296448

Epoch: 6| Step: 10
Training loss: 3.272351797316479
Validation loss: 3.0653046369654

Epoch: 6| Step: 11
Training loss: 3.38318277847731
Validation loss: 3.066511280838931

Epoch: 6| Step: 12
Training loss: 3.5941896915973386
Validation loss: 3.0630921927017

Epoch: 6| Step: 13
Training loss: 2.9159139115926136
Validation loss: 3.0619842952288208

Epoch: 21| Step: 0
Training loss: 3.027646941722754
Validation loss: 3.0593364097198203

Epoch: 6| Step: 1
Training loss: 3.2339164666857085
Validation loss: 3.0608449770409174

Epoch: 6| Step: 2
Training loss: 3.3927153019906235
Validation loss: 3.0627316790557964

Epoch: 6| Step: 3
Training loss: 3.3619539519452077
Validation loss: 3.0632333252113524

Epoch: 6| Step: 4
Training loss: 3.013987991258458
Validation loss: 3.062575378896639

Epoch: 6| Step: 5
Training loss: 3.913841865701684
Validation loss: 3.0609076911993975

Epoch: 6| Step: 6
Training loss: 3.0636395261185827
Validation loss: 3.057240615778791

Epoch: 6| Step: 7
Training loss: 3.108510572955758
Validation loss: 3.057383723930131

Epoch: 6| Step: 8
Training loss: 3.6758336581346267
Validation loss: 3.0533663267658384

Epoch: 6| Step: 9
Training loss: 3.487721294642329
Validation loss: 3.052358193630815

Epoch: 6| Step: 10
Training loss: 3.8692845679307375
Validation loss: 3.050152793659962

Epoch: 6| Step: 11
Training loss: 3.3324103190094587
Validation loss: 3.0499663592681663

Epoch: 6| Step: 12
Training loss: 2.5448047672475314
Validation loss: 3.0490404888190556

Epoch: 6| Step: 13
Training loss: 3.6297602475019892
Validation loss: 3.048831630547452

Epoch: 22| Step: 0
Training loss: 3.039573959813733
Validation loss: 3.0480359444846172

Epoch: 6| Step: 1
Training loss: 3.258041410385557
Validation loss: 3.0457887726882147

Epoch: 6| Step: 2
Training loss: 3.2004831724172944
Validation loss: 3.0448818943885296

Epoch: 6| Step: 3
Training loss: 3.517584360679509
Validation loss: 3.0478477622704365

Epoch: 6| Step: 4
Training loss: 2.5099208442395438
Validation loss: 3.0474890322372086

Epoch: 6| Step: 5
Training loss: 3.6794631792442973
Validation loss: 3.045130907983531

Epoch: 6| Step: 6
Training loss: 4.078561342946043
Validation loss: 3.0445814311179276

Epoch: 6| Step: 7
Training loss: 3.4500096970573924
Validation loss: 3.0447973773559736

Epoch: 6| Step: 8
Training loss: 3.42936381765593
Validation loss: 3.041836038667624

Epoch: 6| Step: 9
Training loss: 2.6819983658412245
Validation loss: 3.041172981794694

Epoch: 6| Step: 10
Training loss: 4.313313725312448
Validation loss: 3.0410654336565592

Epoch: 6| Step: 11
Training loss: 2.579839887456132
Validation loss: 3.04007521084016

Epoch: 6| Step: 12
Training loss: 3.242191912176968
Validation loss: 3.0419308270552397

Epoch: 6| Step: 13
Training loss: 2.9195545794805615
Validation loss: 3.0435236006215347

Epoch: 23| Step: 0
Training loss: 3.1459417934962506
Validation loss: 3.04424631519838

Epoch: 6| Step: 1
Training loss: 3.2059748183871957
Validation loss: 3.042884414887751

Epoch: 6| Step: 2
Training loss: 3.306506654985054
Validation loss: 3.035766614519972

Epoch: 6| Step: 3
Training loss: 3.0197087441768624
Validation loss: 3.032870810054061

Epoch: 6| Step: 4
Training loss: 3.6353683832818824
Validation loss: 3.0347119795943183

Epoch: 6| Step: 5
Training loss: 3.414308168140188
Validation loss: 3.037619678295711

Epoch: 6| Step: 6
Training loss: 3.4762252129662436
Validation loss: 3.037879275490056

Epoch: 6| Step: 7
Training loss: 2.979570765976685
Validation loss: 3.0351043534984905

Epoch: 6| Step: 8
Training loss: 3.553634990772694
Validation loss: 3.0304967927419484

Epoch: 6| Step: 9
Training loss: 3.3912518884222593
Validation loss: 3.0303735272512595

Epoch: 6| Step: 10
Training loss: 3.2883149155959592
Validation loss: 3.0272561578850703

Epoch: 6| Step: 11
Training loss: 4.031861488036986
Validation loss: 3.027278168358599

Epoch: 6| Step: 12
Training loss: 2.9255582879831192
Validation loss: 3.0258009504221044

Epoch: 6| Step: 13
Training loss: 2.644060777655283
Validation loss: 3.0237176863939164

Epoch: 24| Step: 0
Training loss: 2.443293118512384
Validation loss: 3.023043653358451

Epoch: 6| Step: 1
Training loss: 3.327095553081687
Validation loss: 3.026320398325818

Epoch: 6| Step: 2
Training loss: 3.235262099530907
Validation loss: 3.027363437002411

Epoch: 6| Step: 3
Training loss: 2.675612841130525
Validation loss: 3.035573036911007

Epoch: 6| Step: 4
Training loss: 3.7598812888052997
Validation loss: 3.051734365669337

Epoch: 6| Step: 5
Training loss: 3.1703216808293324
Validation loss: 3.065718114579707

Epoch: 6| Step: 6
Training loss: 3.3475988465487543
Validation loss: 3.0406786086013855

Epoch: 6| Step: 7
Training loss: 3.709349218084501
Validation loss: 3.0279342688321185

Epoch: 6| Step: 8
Training loss: 3.7451483813482516
Validation loss: 3.020011345892895

Epoch: 6| Step: 9
Training loss: 2.8018794972377052
Validation loss: 3.0189193472569458

Epoch: 6| Step: 10
Training loss: 3.6102468255111426
Validation loss: 3.0153149540998663

Epoch: 6| Step: 11
Training loss: 3.145082565218442
Validation loss: 3.024828449558941

Epoch: 6| Step: 12
Training loss: 3.5745610641234626
Validation loss: 3.0349260373470948

Epoch: 6| Step: 13
Training loss: 3.7525889043168914
Validation loss: 3.0229599394744584

Epoch: 25| Step: 0
Training loss: 3.033407642865596
Validation loss: 3.020771012955801

Epoch: 6| Step: 1
Training loss: 3.1124919048648336
Validation loss: 3.0185249501704967

Epoch: 6| Step: 2
Training loss: 3.6881384862521656
Validation loss: 3.0166349059437256

Epoch: 6| Step: 3
Training loss: 2.9927538144118633
Validation loss: 3.0179744007996696

Epoch: 6| Step: 4
Training loss: 2.851222689513275
Validation loss: 3.0152386428420224

Epoch: 6| Step: 5
Training loss: 4.079572048182686
Validation loss: 3.0123716769985385

Epoch: 6| Step: 6
Training loss: 3.1681219738877897
Validation loss: 3.0144445944335514

Epoch: 6| Step: 7
Training loss: 4.045554162767657
Validation loss: 3.010622709756669

Epoch: 6| Step: 8
Training loss: 3.1650242980217183
Validation loss: 3.010507592393131

Epoch: 6| Step: 9
Training loss: 3.6257549683584758
Validation loss: 3.0077269259764794

Epoch: 6| Step: 10
Training loss: 2.46282499076155
Validation loss: 3.0100024974843844

Epoch: 6| Step: 11
Training loss: 3.201613204353475
Validation loss: 3.0158899577550824

Epoch: 6| Step: 12
Training loss: 3.333629229445966
Validation loss: 3.0208528500366016

Epoch: 6| Step: 13
Training loss: 3.0354534774429838
Validation loss: 3.0050288935342

Epoch: 26| Step: 0
Training loss: 2.9470122514721835
Validation loss: 3.0033908347782

Epoch: 6| Step: 1
Training loss: 3.689359034665767
Validation loss: 3.003663203888278

Epoch: 6| Step: 2
Training loss: 3.6179852193063393
Validation loss: 3.007632967243107

Epoch: 6| Step: 3
Training loss: 3.424138961931194
Validation loss: 3.0066202925496874

Epoch: 6| Step: 4
Training loss: 3.3383491607407625
Validation loss: 3.0019570422536788

Epoch: 6| Step: 5
Training loss: 3.7544994064251336
Validation loss: 3.0009933881310418

Epoch: 6| Step: 6
Training loss: 3.585848672136471
Validation loss: 2.9973342196533443

Epoch: 6| Step: 7
Training loss: 3.4717299574419527
Validation loss: 2.997571119183385

Epoch: 6| Step: 8
Training loss: 2.3174506112013833
Validation loss: 2.997490084164067

Epoch: 6| Step: 9
Training loss: 3.517533119333131
Validation loss: 2.994585404678572

Epoch: 6| Step: 10
Training loss: 2.951566577623821
Validation loss: 2.992690163743851

Epoch: 6| Step: 11
Training loss: 2.4751162954423687
Validation loss: 2.9909971556500627

Epoch: 6| Step: 12
Training loss: 3.6757472621469316
Validation loss: 2.9911417507097564

Epoch: 6| Step: 13
Training loss: 2.403583981815822
Validation loss: 2.994331942776211

Epoch: 27| Step: 0
Training loss: 3.265587619403283
Validation loss: 3.0103418598034426

Epoch: 6| Step: 1
Training loss: 2.5542011322965257
Validation loss: 3.0060835890775786

Epoch: 6| Step: 2
Training loss: 2.9167942200880175
Validation loss: 2.9991768746878638

Epoch: 6| Step: 3
Training loss: 3.35971110237268
Validation loss: 2.9944479045842476

Epoch: 6| Step: 4
Training loss: 3.3968191919594086
Validation loss: 2.989124842767439

Epoch: 6| Step: 5
Training loss: 3.763297473634131
Validation loss: 2.985430309631813

Epoch: 6| Step: 6
Training loss: 2.913391690604492
Validation loss: 2.9853497926364496

Epoch: 6| Step: 7
Training loss: 3.0182384175950676
Validation loss: 2.983661209112544

Epoch: 6| Step: 8
Training loss: 2.9773603356289056
Validation loss: 2.983144001038099

Epoch: 6| Step: 9
Training loss: 4.087613930703874
Validation loss: 2.9798546743927603

Epoch: 6| Step: 10
Training loss: 2.1723642141314867
Validation loss: 2.9802555347775863

Epoch: 6| Step: 11
Training loss: 3.9033316735433234
Validation loss: 2.9818044616605577

Epoch: 6| Step: 12
Training loss: 3.4285814591669768
Validation loss: 2.9809926219517173

Epoch: 6| Step: 13
Training loss: 3.7639759299210973
Validation loss: 2.9814782778242055

Epoch: 28| Step: 0
Training loss: 3.26646317672119
Validation loss: 2.9796557487885393

Epoch: 6| Step: 1
Training loss: 3.4240573560420713
Validation loss: 2.983294826205662

Epoch: 6| Step: 2
Training loss: 2.4145840078445646
Validation loss: 2.986468342422002

Epoch: 6| Step: 3
Training loss: 3.0753294357362213
Validation loss: 2.9883886440366942

Epoch: 6| Step: 4
Training loss: 4.298349356432235
Validation loss: 2.9808801814221515

Epoch: 6| Step: 5
Training loss: 3.5884396003784103
Validation loss: 2.974483729702531

Epoch: 6| Step: 6
Training loss: 3.2835323570333608
Validation loss: 2.974269138593963

Epoch: 6| Step: 7
Training loss: 3.239296527363233
Validation loss: 2.973867682911931

Epoch: 6| Step: 8
Training loss: 2.2432503656667406
Validation loss: 2.975279170761874

Epoch: 6| Step: 9
Training loss: 3.2288039137015994
Validation loss: 2.9752810026230208

Epoch: 6| Step: 10
Training loss: 2.9669733453317675
Validation loss: 2.973562095064289

Epoch: 6| Step: 11
Training loss: 3.8257461318775676
Validation loss: 2.972604901822169

Epoch: 6| Step: 12
Training loss: 3.09176649222082
Validation loss: 2.972654294921867

Epoch: 6| Step: 13
Training loss: 3.3477439913384908
Validation loss: 2.9745784468092618

Epoch: 29| Step: 0
Training loss: 2.672818647466998
Validation loss: 2.972630277626416

Epoch: 6| Step: 1
Training loss: 3.8932669987536155
Validation loss: 2.971171495028115

Epoch: 6| Step: 2
Training loss: 3.057522524035653
Validation loss: 2.968359522028751

Epoch: 6| Step: 3
Training loss: 3.5592751881685554
Validation loss: 2.967725257199136

Epoch: 6| Step: 4
Training loss: 3.161246395810427
Validation loss: 2.9682904063126574

Epoch: 6| Step: 5
Training loss: 2.557949398527509
Validation loss: 2.9684862970697856

Epoch: 6| Step: 6
Training loss: 3.0397273809766525
Validation loss: 2.9662486999911826

Epoch: 6| Step: 7
Training loss: 2.8654670230829695
Validation loss: 2.9718601258740063

Epoch: 6| Step: 8
Training loss: 3.07555549380254
Validation loss: 2.9780888660509977

Epoch: 6| Step: 9
Training loss: 3.329238060737543
Validation loss: 2.983527161619442

Epoch: 6| Step: 10
Training loss: 3.913751342344343
Validation loss: 2.975502584017347

Epoch: 6| Step: 11
Training loss: 2.8528934246899516
Validation loss: 2.9687170712296873

Epoch: 6| Step: 12
Training loss: 3.4457268498184197
Validation loss: 2.9710966411348485

Epoch: 6| Step: 13
Training loss: 4.263063660882089
Validation loss: 2.9714727294047303

Epoch: 30| Step: 0
Training loss: 3.1059909213609527
Validation loss: 2.9668755374017612

Epoch: 6| Step: 1
Training loss: 3.421096504177214
Validation loss: 2.963185901021145

Epoch: 6| Step: 2
Training loss: 3.7570264473969877
Validation loss: 2.9592503228917666

Epoch: 6| Step: 3
Training loss: 3.2101981618210393
Validation loss: 2.959900157004524

Epoch: 6| Step: 4
Training loss: 2.9550171295547365
Validation loss: 2.956595211949935

Epoch: 6| Step: 5
Training loss: 3.5565190218520426
Validation loss: 2.958354815263989

Epoch: 6| Step: 6
Training loss: 3.0799140184959914
Validation loss: 2.95660609480406

Epoch: 6| Step: 7
Training loss: 2.093085340076875
Validation loss: 2.9544136954089337

Epoch: 6| Step: 8
Training loss: 2.673213155174508
Validation loss: 2.9559651823988777

Epoch: 6| Step: 9
Training loss: 3.2068931187422853
Validation loss: 2.957680918119273

Epoch: 6| Step: 10
Training loss: 3.4455260472279794
Validation loss: 2.956237252020678

Epoch: 6| Step: 11
Training loss: 3.4382521760071456
Validation loss: 2.9581583281255406

Epoch: 6| Step: 12
Training loss: 3.3662756727438747
Validation loss: 2.9532360154351127

Epoch: 6| Step: 13
Training loss: 4.135970814408235
Validation loss: 2.946351817008104

Epoch: 31| Step: 0
Training loss: 4.463395759159259
Validation loss: 2.948615473368198

Epoch: 6| Step: 1
Training loss: 2.603533390611273
Validation loss: 2.946715781068369

Epoch: 6| Step: 2
Training loss: 3.8474948907313835
Validation loss: 2.9475408964132668

Epoch: 6| Step: 3
Training loss: 2.632755901509362
Validation loss: 2.945400008362306

Epoch: 6| Step: 4
Training loss: 2.548991254358265
Validation loss: 2.946188824101278

Epoch: 6| Step: 5
Training loss: 3.1313649778899713
Validation loss: 2.946032964794566

Epoch: 6| Step: 6
Training loss: 2.626279791436494
Validation loss: 2.94483627726111

Epoch: 6| Step: 7
Training loss: 3.432071352628213
Validation loss: 2.943973015041589

Epoch: 6| Step: 8
Training loss: 3.72968984730858
Validation loss: 2.9422186726245307

Epoch: 6| Step: 9
Training loss: 2.6997808155526934
Validation loss: 2.9420307279137226

Epoch: 6| Step: 10
Training loss: 3.591208181008283
Validation loss: 2.9394700533602545

Epoch: 6| Step: 11
Training loss: 3.19290540542286
Validation loss: 2.9397074919022157

Epoch: 6| Step: 12
Training loss: 2.9453712680124227
Validation loss: 2.9378822111167953

Epoch: 6| Step: 13
Training loss: 3.3292326181027745
Validation loss: 2.9374627551927324

Epoch: 32| Step: 0
Training loss: 3.2889078063105757
Validation loss: 2.936385315668142

Epoch: 6| Step: 1
Training loss: 2.441493162515485
Validation loss: 2.9366084037140188

Epoch: 6| Step: 2
Training loss: 3.084396093232633
Validation loss: 2.943768451222579

Epoch: 6| Step: 3
Training loss: 3.656657530414732
Validation loss: 2.9565464974419386

Epoch: 6| Step: 4
Training loss: 3.3343522104129817
Validation loss: 2.973265249881431

Epoch: 6| Step: 5
Training loss: 3.6180715448697787
Validation loss: 2.974803631951659

Epoch: 6| Step: 6
Training loss: 3.978551580746951
Validation loss: 2.9417623744918124

Epoch: 6| Step: 7
Training loss: 3.473847226830634
Validation loss: 2.9386370100634966

Epoch: 6| Step: 8
Training loss: 3.5343554859651394
Validation loss: 2.9377291059201207

Epoch: 6| Step: 9
Training loss: 2.725276523523657
Validation loss: 2.93990889296546

Epoch: 6| Step: 10
Training loss: 3.035402580094144
Validation loss: 2.9415733382439972

Epoch: 6| Step: 11
Training loss: 2.455502955082859
Validation loss: 2.9435826695573013

Epoch: 6| Step: 12
Training loss: 3.188777144139708
Validation loss: 2.940718300575822

Epoch: 6| Step: 13
Training loss: 2.8512293790868473
Validation loss: 2.9365862837163417

Epoch: 33| Step: 0
Training loss: 3.4171449900190805
Validation loss: 2.930007135271322

Epoch: 6| Step: 1
Training loss: 3.2435993843171174
Validation loss: 2.9237965421468086

Epoch: 6| Step: 2
Training loss: 3.7408161876135693
Validation loss: 2.9236202181552464

Epoch: 6| Step: 3
Training loss: 3.388669342128016
Validation loss: 2.930604704759473

Epoch: 6| Step: 4
Training loss: 2.9433545148641027
Validation loss: 2.9515187635726

Epoch: 6| Step: 5
Training loss: 3.8340218105422115
Validation loss: 2.9434493174213348

Epoch: 6| Step: 6
Training loss: 2.984988484064888
Validation loss: 2.931874638632254

Epoch: 6| Step: 7
Training loss: 2.9740899497245765
Validation loss: 2.921745344356962

Epoch: 6| Step: 8
Training loss: 2.931808151754867
Validation loss: 2.916453578448657

Epoch: 6| Step: 9
Training loss: 3.3847412531129915
Validation loss: 2.916830385831272

Epoch: 6| Step: 10
Training loss: 2.943671864891999
Validation loss: 2.915617480452582

Epoch: 6| Step: 11
Training loss: 2.4546035878525347
Validation loss: 2.9147221026219206

Epoch: 6| Step: 12
Training loss: 3.4441934788107393
Validation loss: 2.9161204364218682

Epoch: 6| Step: 13
Training loss: 3.0621245796379912
Validation loss: 2.918165161833921

Epoch: 34| Step: 0
Training loss: 3.0239517602554526
Validation loss: 2.922090148813489

Epoch: 6| Step: 1
Training loss: 3.623952122209926
Validation loss: 2.9158787525960865

Epoch: 6| Step: 2
Training loss: 3.439194417708579
Validation loss: 2.913098974426547

Epoch: 6| Step: 3
Training loss: 3.0980313664443657
Validation loss: 2.91423436162023

Epoch: 6| Step: 4
Training loss: 3.0030109872124755
Validation loss: 2.916123945895322

Epoch: 6| Step: 5
Training loss: 1.8700233535532311
Validation loss: 2.910864354896971

Epoch: 6| Step: 6
Training loss: 3.963317396892808
Validation loss: 2.907961333272387

Epoch: 6| Step: 7
Training loss: 3.7639459055906213
Validation loss: 2.9068585068723496

Epoch: 6| Step: 8
Training loss: 2.943925849861858
Validation loss: 2.9081838460830447

Epoch: 6| Step: 9
Training loss: 2.9656731974440618
Validation loss: 2.9081128135868655

Epoch: 6| Step: 10
Training loss: 3.0913363202264126
Validation loss: 2.908998244751473

Epoch: 6| Step: 11
Training loss: 2.6238546143240056
Validation loss: 2.9072208342137396

Epoch: 6| Step: 12
Training loss: 3.798669838243122
Validation loss: 2.9095734942082334

Epoch: 6| Step: 13
Training loss: 2.9135617396063616
Validation loss: 2.9111364724098943

Epoch: 35| Step: 0
Training loss: 3.0260027271770285
Validation loss: 2.9073439017030194

Epoch: 6| Step: 1
Training loss: 3.533824690956122
Validation loss: 2.9080501339767966

Epoch: 6| Step: 2
Training loss: 3.633972376582498
Validation loss: 2.9076996635826755

Epoch: 6| Step: 3
Training loss: 3.139351657823942
Validation loss: 2.907517599436776

Epoch: 6| Step: 4
Training loss: 3.5950750147350563
Validation loss: 2.9071140493431282

Epoch: 6| Step: 5
Training loss: 3.452546636555094
Validation loss: 2.905386110173407

Epoch: 6| Step: 6
Training loss: 3.140802330969996
Validation loss: 2.9118131297053256

Epoch: 6| Step: 7
Training loss: 2.865910799340732
Validation loss: 2.9613770366945857

Epoch: 6| Step: 8
Training loss: 3.784927723445205
Validation loss: 2.978622253112449

Epoch: 6| Step: 9
Training loss: 3.228769798912223
Validation loss: 2.996589946097573

Epoch: 6| Step: 10
Training loss: 2.6663577576370776
Validation loss: 2.958800739232589

Epoch: 6| Step: 11
Training loss: 3.217952147920499
Validation loss: 2.9229717669363287

Epoch: 6| Step: 12
Training loss: 2.696145191658033
Validation loss: 2.9082111045125028

Epoch: 6| Step: 13
Training loss: 2.399955641813431
Validation loss: 2.9274715145312675

Epoch: 36| Step: 0
Training loss: 3.472687831602034
Validation loss: 2.9458075149527243

Epoch: 6| Step: 1
Training loss: 3.7043839901885356
Validation loss: 2.922466931221033

Epoch: 6| Step: 2
Training loss: 3.6975614708464923
Validation loss: 2.906442274846843

Epoch: 6| Step: 3
Training loss: 2.9607986779998243
Validation loss: 2.8972587739298645

Epoch: 6| Step: 4
Training loss: 2.7679814359119574
Validation loss: 2.893526697385616

Epoch: 6| Step: 5
Training loss: 4.089708036340707
Validation loss: 2.895237542159802

Epoch: 6| Step: 6
Training loss: 3.0626678420803466
Validation loss: 2.898013251353005

Epoch: 6| Step: 7
Training loss: 2.274010759682141
Validation loss: 2.900119161084819

Epoch: 6| Step: 8
Training loss: 3.027519053644126
Validation loss: 2.9117822106848323

Epoch: 6| Step: 9
Training loss: 1.646212047350869
Validation loss: 2.9051151006991183

Epoch: 6| Step: 10
Training loss: 3.538093080442348
Validation loss: 2.905504021342832

Epoch: 6| Step: 11
Training loss: 3.0793847928627964
Validation loss: 2.90196490964468

Epoch: 6| Step: 12
Training loss: 3.2122019113662152
Validation loss: 2.8969833688448414

Epoch: 6| Step: 13
Training loss: 3.7244670102577158
Validation loss: 2.896163580468441

Epoch: 37| Step: 0
Training loss: 3.186608732194332
Validation loss: 2.893402264263828

Epoch: 6| Step: 1
Training loss: 3.687137779937135
Validation loss: 2.886022147421922

Epoch: 6| Step: 2
Training loss: 2.760326417611275
Validation loss: 2.886411869664533

Epoch: 6| Step: 3
Training loss: 3.7688524020376186
Validation loss: 2.8878534343714146

Epoch: 6| Step: 4
Training loss: 3.492144624929056
Validation loss: 2.8871506466367647

Epoch: 6| Step: 5
Training loss: 3.013642128620207
Validation loss: 2.8880161031743854

Epoch: 6| Step: 6
Training loss: 3.2695599808792153
Validation loss: 2.8842085965934037

Epoch: 6| Step: 7
Training loss: 3.502572068229239
Validation loss: 2.885234374027584

Epoch: 6| Step: 8
Training loss: 3.2726078120016635
Validation loss: 2.886546414476214

Epoch: 6| Step: 9
Training loss: 2.85665029980286
Validation loss: 2.884302022534687

Epoch: 6| Step: 10
Training loss: 2.82367588170532
Validation loss: 2.8846386028183106

Epoch: 6| Step: 11
Training loss: 2.5008585409359845
Validation loss: 2.883844468747773

Epoch: 6| Step: 12
Training loss: 2.9160941152363407
Validation loss: 2.8821077901370122

Epoch: 6| Step: 13
Training loss: 3.3642151496297092
Validation loss: 2.881526606541208

Epoch: 38| Step: 0
Training loss: 3.230111375665945
Validation loss: 2.8803768999090975

Epoch: 6| Step: 1
Training loss: 2.749005571378444
Validation loss: 2.8813797929140192

Epoch: 6| Step: 2
Training loss: 3.06767785014544
Validation loss: 2.8786263781697863

Epoch: 6| Step: 3
Training loss: 3.523789754036392
Validation loss: 2.8817686377611564

Epoch: 6| Step: 4
Training loss: 2.2856411411298563
Validation loss: 2.8829376196218814

Epoch: 6| Step: 5
Training loss: 3.3912721359143534
Validation loss: 2.89165472853446

Epoch: 6| Step: 6
Training loss: 3.2693149581701872
Validation loss: 2.893455041033684

Epoch: 6| Step: 7
Training loss: 3.2338468700950624
Validation loss: 2.8898753721012187

Epoch: 6| Step: 8
Training loss: 3.2851729420930718
Validation loss: 2.876734265347022

Epoch: 6| Step: 9
Training loss: 3.5611777277716503
Validation loss: 2.8742808815394922

Epoch: 6| Step: 10
Training loss: 3.1382315706058197
Validation loss: 2.8708849995873003

Epoch: 6| Step: 11
Training loss: 3.5952930620671855
Validation loss: 2.8710717681518747

Epoch: 6| Step: 12
Training loss: 2.4963151478372634
Validation loss: 2.873785371374883

Epoch: 6| Step: 13
Training loss: 3.3786210309082616
Validation loss: 2.873809441322011

Epoch: 39| Step: 0
Training loss: 3.289857165821761
Validation loss: 2.87538128928683

Epoch: 6| Step: 1
Training loss: 3.242402218981816
Validation loss: 2.8749728386564777

Epoch: 6| Step: 2
Training loss: 2.848170272001909
Validation loss: 2.877840140886676

Epoch: 6| Step: 3
Training loss: 3.7005039387406096
Validation loss: 2.8735197286069454

Epoch: 6| Step: 4
Training loss: 2.915082737581107
Validation loss: 2.874346073322783

Epoch: 6| Step: 5
Training loss: 3.397943430096826
Validation loss: 2.869949611318524

Epoch: 6| Step: 6
Training loss: 2.8518049581212668
Validation loss: 2.866607944529063

Epoch: 6| Step: 7
Training loss: 3.0381912512384015
Validation loss: 2.86862011901727

Epoch: 6| Step: 8
Training loss: 3.235093336453965
Validation loss: 2.870153205400869

Epoch: 6| Step: 9
Training loss: 3.056150744490015
Validation loss: 2.8668618819934197

Epoch: 6| Step: 10
Training loss: 2.591356758976834
Validation loss: 2.8753306558511516

Epoch: 6| Step: 11
Training loss: 2.882686787994107
Validation loss: 2.8827886012677677

Epoch: 6| Step: 12
Training loss: 3.5550689827923323
Validation loss: 2.89815886234792

Epoch: 6| Step: 13
Training loss: 3.934789420943694
Validation loss: 2.8957444778824892

Epoch: 40| Step: 0
Training loss: 2.749174427608541
Validation loss: 2.8764807769739456

Epoch: 6| Step: 1
Training loss: 3.655873597161539
Validation loss: 2.870039681918531

Epoch: 6| Step: 2
Training loss: 3.2217570952071446
Validation loss: 2.8639288429612635

Epoch: 6| Step: 3
Training loss: 3.0706678189755707
Validation loss: 2.8626212880021167

Epoch: 6| Step: 4
Training loss: 2.2321219655830373
Validation loss: 2.8634313605496917

Epoch: 6| Step: 5
Training loss: 3.2638660421090386
Validation loss: 2.859406876606285

Epoch: 6| Step: 6
Training loss: 2.8259520217807554
Validation loss: 2.862945829326081

Epoch: 6| Step: 7
Training loss: 4.114239384564415
Validation loss: 2.8621305577021774

Epoch: 6| Step: 8
Training loss: 3.430022968404401
Validation loss: 2.8633039936060594

Epoch: 6| Step: 9
Training loss: 2.652945044427502
Validation loss: 2.8579953628293224

Epoch: 6| Step: 10
Training loss: 3.336279679556216
Validation loss: 2.8566299756574747

Epoch: 6| Step: 11
Training loss: 2.919230360736859
Validation loss: 2.8553512389927453

Epoch: 6| Step: 12
Training loss: 3.367209733150569
Validation loss: 2.856280938148313

Epoch: 6| Step: 13
Training loss: 2.824300382286478
Validation loss: 2.8545949066888467

Epoch: 41| Step: 0
Training loss: 2.984222248422278
Validation loss: 2.854529027628949

Epoch: 6| Step: 1
Training loss: 3.537049788547659
Validation loss: 2.852267480839088

Epoch: 6| Step: 2
Training loss: 3.020958803574704
Validation loss: 2.8512953703495634

Epoch: 6| Step: 3
Training loss: 3.2591402197863477
Validation loss: 2.851925016255243

Epoch: 6| Step: 4
Training loss: 2.4891901916202777
Validation loss: 2.852599322096407

Epoch: 6| Step: 5
Training loss: 3.5845186505720443
Validation loss: 2.85057355538569

Epoch: 6| Step: 6
Training loss: 3.3629185639411783
Validation loss: 2.8506847982280177

Epoch: 6| Step: 7
Training loss: 2.652769703433901
Validation loss: 2.85004661095929

Epoch: 6| Step: 8
Training loss: 2.823974345541858
Validation loss: 2.8492759807511705

Epoch: 6| Step: 9
Training loss: 2.386990745516905
Validation loss: 2.848228327918499

Epoch: 6| Step: 10
Training loss: 3.174839382163933
Validation loss: 2.8479703111672707

Epoch: 6| Step: 11
Training loss: 3.8730316084860488
Validation loss: 2.847581018497042

Epoch: 6| Step: 12
Training loss: 3.2204967314666995
Validation loss: 2.846883793074562

Epoch: 6| Step: 13
Training loss: 3.5031412197421536
Validation loss: 2.8500873170180547

Epoch: 42| Step: 0
Training loss: 2.9269555947519774
Validation loss: 2.8536874039243343

Epoch: 6| Step: 1
Training loss: 3.6560405442975945
Validation loss: 2.849605677451157

Epoch: 6| Step: 2
Training loss: 3.311649717208525
Validation loss: 2.851493726061985

Epoch: 6| Step: 3
Training loss: 3.6395846341586977
Validation loss: 2.8451984714305962

Epoch: 6| Step: 4
Training loss: 2.9100159886501
Validation loss: 2.841621152908888

Epoch: 6| Step: 5
Training loss: 2.882315905631858
Validation loss: 2.8402007504099718

Epoch: 6| Step: 6
Training loss: 3.013794971258692
Validation loss: 2.840274539172802

Epoch: 6| Step: 7
Training loss: 3.0050911618843363
Validation loss: 2.8398978434729627

Epoch: 6| Step: 8
Training loss: 3.3559649525791317
Validation loss: 2.8379715975405566

Epoch: 6| Step: 9
Training loss: 2.31578016906676
Validation loss: 2.838387193603834

Epoch: 6| Step: 10
Training loss: 3.1453204378955504
Validation loss: 2.8395354403214914

Epoch: 6| Step: 11
Training loss: 2.39255849402023
Validation loss: 2.841000117733262

Epoch: 6| Step: 12
Training loss: 3.650187103492495
Validation loss: 2.8523868777833696

Epoch: 6| Step: 13
Training loss: 3.7695445322385814
Validation loss: 2.842380199633163

Epoch: 43| Step: 0
Training loss: 3.2002651939177427
Validation loss: 2.8344813620263594

Epoch: 6| Step: 1
Training loss: 3.5860864280076443
Validation loss: 2.835078619991955

Epoch: 6| Step: 2
Training loss: 3.206871261044339
Validation loss: 2.8328224683086582

Epoch: 6| Step: 3
Training loss: 3.0785082273535975
Validation loss: 2.832125962667612

Epoch: 6| Step: 4
Training loss: 3.064663025843967
Validation loss: 2.8331220995671895

Epoch: 6| Step: 5
Training loss: 2.5063174535944444
Validation loss: 2.8338005729038276

Epoch: 6| Step: 6
Training loss: 2.9728894737477405
Validation loss: 2.831152498900314

Epoch: 6| Step: 7
Training loss: 2.581942419696917
Validation loss: 2.832337291844721

Epoch: 6| Step: 8
Training loss: 3.661142320231386
Validation loss: 2.8315824392498645

Epoch: 6| Step: 9
Training loss: 2.5048110445981
Validation loss: 2.830626117890103

Epoch: 6| Step: 10
Training loss: 3.525645712291386
Validation loss: 2.8279164881628756

Epoch: 6| Step: 11
Training loss: 3.7730392972556293
Validation loss: 2.827491784999442

Epoch: 6| Step: 12
Training loss: 2.9626971730476557
Validation loss: 2.8274445971606346

Epoch: 6| Step: 13
Training loss: 2.81048885070837
Validation loss: 2.826238611897213

Epoch: 44| Step: 0
Training loss: 2.7300815553325672
Validation loss: 2.823590715836708

Epoch: 6| Step: 1
Training loss: 3.16707680371851
Validation loss: 2.8241682096171674

Epoch: 6| Step: 2
Training loss: 2.8088286279080483
Validation loss: 2.8258486306620965

Epoch: 6| Step: 3
Training loss: 3.452969232558566
Validation loss: 2.8270412460948444

Epoch: 6| Step: 4
Training loss: 3.2305242494476856
Validation loss: 2.8291608161895376

Epoch: 6| Step: 5
Training loss: 2.923147648561901
Validation loss: 2.8283283960698125

Epoch: 6| Step: 6
Training loss: 2.7783891344178153
Validation loss: 2.8313034581008565

Epoch: 6| Step: 7
Training loss: 3.30222555309531
Validation loss: 2.827883507772343

Epoch: 6| Step: 8
Training loss: 3.250446582335901
Validation loss: 2.8206592335653133

Epoch: 6| Step: 9
Training loss: 3.0298161212282486
Validation loss: 2.820601839030025

Epoch: 6| Step: 10
Training loss: 3.4063223734875097
Validation loss: 2.818136761784848

Epoch: 6| Step: 11
Training loss: 2.9681143632329903
Validation loss: 2.8202497534233872

Epoch: 6| Step: 12
Training loss: 3.2950383715790355
Validation loss: 2.8197242373969895

Epoch: 6| Step: 13
Training loss: 3.445695436263882
Validation loss: 2.8201184972292697

Epoch: 45| Step: 0
Training loss: 3.283174658747803
Validation loss: 2.824498597925951

Epoch: 6| Step: 1
Training loss: 2.9898629583893523
Validation loss: 2.8235809727549754

Epoch: 6| Step: 2
Training loss: 3.3263246923387237
Validation loss: 2.836730368893184

Epoch: 6| Step: 3
Training loss: 3.6740749829842643
Validation loss: 2.840343827558087

Epoch: 6| Step: 4
Training loss: 2.464049971699236
Validation loss: 2.8394571144291616

Epoch: 6| Step: 5
Training loss: 2.44986114108447
Validation loss: 2.8385907032977618

Epoch: 6| Step: 6
Training loss: 3.0236724841056604
Validation loss: 2.8397600810158776

Epoch: 6| Step: 7
Training loss: 2.79237856731531
Validation loss: 2.8352697021167064

Epoch: 6| Step: 8
Training loss: 3.5598710381798497
Validation loss: 2.8360856246717727

Epoch: 6| Step: 9
Training loss: 3.754791250712319
Validation loss: 2.8244152894539933

Epoch: 6| Step: 10
Training loss: 3.098352265063295
Validation loss: 2.8236770883160713

Epoch: 6| Step: 11
Training loss: 2.5151480465461513
Validation loss: 2.819636390019172

Epoch: 6| Step: 12
Training loss: 3.464589966572467
Validation loss: 2.8210841265727558

Epoch: 6| Step: 13
Training loss: 2.9417588224015314
Validation loss: 2.8198174742193753

Epoch: 46| Step: 0
Training loss: 3.4700760239949626
Validation loss: 2.837370917003483

Epoch: 6| Step: 1
Training loss: 2.8561413099447734
Validation loss: 2.8490889063539613

Epoch: 6| Step: 2
Training loss: 2.8127715933319015
Validation loss: 2.848378236323649

Epoch: 6| Step: 3
Training loss: 3.290098049940557
Validation loss: 2.8380746256066387

Epoch: 6| Step: 4
Training loss: 3.578013189309611
Validation loss: 2.832252068713782

Epoch: 6| Step: 5
Training loss: 2.4500483761118037
Validation loss: 2.811349361314353

Epoch: 6| Step: 6
Training loss: 3.2179768939377102
Validation loss: 2.806078165671459

Epoch: 6| Step: 7
Training loss: 3.272027415284302
Validation loss: 2.8025641875998213

Epoch: 6| Step: 8
Training loss: 2.9849833722186587
Validation loss: 2.8018403563020513

Epoch: 6| Step: 9
Training loss: 2.8795817810622575
Validation loss: 2.8019083406592378

Epoch: 6| Step: 10
Training loss: 2.5936902510413935
Validation loss: 2.801965027493068

Epoch: 6| Step: 11
Training loss: 2.9524079920736153
Validation loss: 2.8022326055960654

Epoch: 6| Step: 12
Training loss: 3.7075202707776986
Validation loss: 2.8016176804735187

Epoch: 6| Step: 13
Training loss: 3.520031418226652
Validation loss: 2.802528337472568

Epoch: 47| Step: 0
Training loss: 2.5245305106422893
Validation loss: 2.800666113695842

Epoch: 6| Step: 1
Training loss: 3.0527493701647073
Validation loss: 2.799980256015411

Epoch: 6| Step: 2
Training loss: 2.991689934458521
Validation loss: 2.797794258114825

Epoch: 6| Step: 3
Training loss: 3.551402424780844
Validation loss: 2.799956774634324

Epoch: 6| Step: 4
Training loss: 2.9484364261433194
Validation loss: 2.7981500808641475

Epoch: 6| Step: 5
Training loss: 3.0674930274591894
Validation loss: 2.796810370989986

Epoch: 6| Step: 6
Training loss: 3.4650654512199033
Validation loss: 2.7959599499288768

Epoch: 6| Step: 7
Training loss: 3.0009018813925934
Validation loss: 2.797011741878946

Epoch: 6| Step: 8
Training loss: 2.3139206929773266
Validation loss: 2.8033671172472077

Epoch: 6| Step: 9
Training loss: 2.753002694884844
Validation loss: 2.8172041589204135

Epoch: 6| Step: 10
Training loss: 3.4519398584442222
Validation loss: 2.8393604342182206

Epoch: 6| Step: 11
Training loss: 3.2490464792446403
Validation loss: 2.8550325258015423

Epoch: 6| Step: 12
Training loss: 3.3894105485433816
Validation loss: 2.8785084748371466

Epoch: 6| Step: 13
Training loss: 3.7784894213738487
Validation loss: 2.858992879828695

Epoch: 48| Step: 0
Training loss: 3.4020337249322163
Validation loss: 2.81670673378513

Epoch: 6| Step: 1
Training loss: 2.459308775576074
Validation loss: 2.804042468114816

Epoch: 6| Step: 2
Training loss: 2.9878556490733796
Validation loss: 2.8017268483395332

Epoch: 6| Step: 3
Training loss: 3.986604194109102
Validation loss: 2.8007635254831906

Epoch: 6| Step: 4
Training loss: 3.1062664806765388
Validation loss: 2.7986293690923545

Epoch: 6| Step: 5
Training loss: 2.78791764214044
Validation loss: 2.800124952499119

Epoch: 6| Step: 6
Training loss: 3.530315579364653
Validation loss: 2.7977874361951125

Epoch: 6| Step: 7
Training loss: 2.5604271296966874
Validation loss: 2.798074543540319

Epoch: 6| Step: 8
Training loss: 3.0248931613687304
Validation loss: 2.7986249336505162

Epoch: 6| Step: 9
Training loss: 2.7550652412125203
Validation loss: 2.7914794071764497

Epoch: 6| Step: 10
Training loss: 3.1821873091564927
Validation loss: 2.7913630257193276

Epoch: 6| Step: 11
Training loss: 2.6657534962995824
Validation loss: 2.787702636622684

Epoch: 6| Step: 12
Training loss: 3.373325921705143
Validation loss: 2.7883095818108012

Epoch: 6| Step: 13
Training loss: 3.45583696156509
Validation loss: 2.78740400464216

Epoch: 49| Step: 0
Training loss: 2.8731618893213335
Validation loss: 2.7883125184516717

Epoch: 6| Step: 1
Training loss: 3.1227643980873605
Validation loss: 2.7883595888705344

Epoch: 6| Step: 2
Training loss: 3.0671348532279668
Validation loss: 2.7857620327644774

Epoch: 6| Step: 3
Training loss: 2.4848538303176775
Validation loss: 2.7888492042965614

Epoch: 6| Step: 4
Training loss: 3.4338020547948993
Validation loss: 2.784294711864844

Epoch: 6| Step: 5
Training loss: 2.9386263372119736
Validation loss: 2.7833177282647386

Epoch: 6| Step: 6
Training loss: 3.2905722299603055
Validation loss: 2.783472291185496

Epoch: 6| Step: 7
Training loss: 2.9495598804159204
Validation loss: 2.7860465845640943

Epoch: 6| Step: 8
Training loss: 3.2186011122554485
Validation loss: 2.7922535892915614

Epoch: 6| Step: 9
Training loss: 3.0548823067678277
Validation loss: 2.7982971137871284

Epoch: 6| Step: 10
Training loss: 3.1885013877287776
Validation loss: 2.805308250634369

Epoch: 6| Step: 11
Training loss: 3.1138327384133757
Validation loss: 2.8273288728240025

Epoch: 6| Step: 12
Training loss: 3.4821774519435005
Validation loss: 2.81066208996719

Epoch: 6| Step: 13
Training loss: 3.1478846516591688
Validation loss: 2.8042820028846394

Epoch: 50| Step: 0
Training loss: 2.3108619868467737
Validation loss: 2.8045651125820403

Epoch: 6| Step: 1
Training loss: 2.697492342735644
Validation loss: 2.7970730061876132

Epoch: 6| Step: 2
Training loss: 2.945107531308777
Validation loss: 2.784789034558402

Epoch: 6| Step: 3
Training loss: 3.1335396624328915
Validation loss: 2.776628896013212

Epoch: 6| Step: 4
Training loss: 3.7985743106885828
Validation loss: 2.7726383475020686

Epoch: 6| Step: 5
Training loss: 3.406701574227588
Validation loss: 2.772234322330272

Epoch: 6| Step: 6
Training loss: 3.606192106049996
Validation loss: 2.7723505173502585

Epoch: 6| Step: 7
Training loss: 2.852039872017849
Validation loss: 2.773962733443642

Epoch: 6| Step: 8
Training loss: 3.0100276568083184
Validation loss: 2.7727319592112187

Epoch: 6| Step: 9
Training loss: 2.6011957133401404
Validation loss: 2.7722026252085428

Epoch: 6| Step: 10
Training loss: 2.7422901797293604
Validation loss: 2.770977145754488

Epoch: 6| Step: 11
Training loss: 3.3241435848214747
Validation loss: 2.772519525563705

Epoch: 6| Step: 12
Training loss: 3.2270104048885986
Validation loss: 2.771164967628244

Epoch: 6| Step: 13
Training loss: 3.4445762626145013
Validation loss: 2.7730873045114097

Epoch: 51| Step: 0
Training loss: 2.9989601558367505
Validation loss: 2.773784455258106

Epoch: 6| Step: 1
Training loss: 2.788094146769876
Validation loss: 2.77300006999308

Epoch: 6| Step: 2
Training loss: 3.3065595802789596
Validation loss: 2.773449139452897

Epoch: 6| Step: 3
Training loss: 3.8870271646636336
Validation loss: 2.7714793688611326

Epoch: 6| Step: 4
Training loss: 3.0493876733690515
Validation loss: 2.770740950366861

Epoch: 6| Step: 5
Training loss: 2.368508854571447
Validation loss: 2.7688766662368685

Epoch: 6| Step: 6
Training loss: 3.1937495282017907
Validation loss: 2.767671792077348

Epoch: 6| Step: 7
Training loss: 3.129420396564293
Validation loss: 2.769337397329274

Epoch: 6| Step: 8
Training loss: 3.2549676343301956
Validation loss: 2.770668475156344

Epoch: 6| Step: 9
Training loss: 3.026212616303135
Validation loss: 2.7705191783345207

Epoch: 6| Step: 10
Training loss: 2.811197615118866
Validation loss: 2.772148194756566

Epoch: 6| Step: 11
Training loss: 3.0166361798454804
Validation loss: 2.7723583247278873

Epoch: 6| Step: 12
Training loss: 3.015624051266852
Validation loss: 2.770194406898512

Epoch: 6| Step: 13
Training loss: 3.372274075032127
Validation loss: 2.7696779176596027

Epoch: 52| Step: 0
Training loss: 2.9476810716139514
Validation loss: 2.7672874821495475

Epoch: 6| Step: 1
Training loss: 2.9317609849959685
Validation loss: 2.7680790958450094

Epoch: 6| Step: 2
Training loss: 3.107008603833345
Validation loss: 2.7661689152529023

Epoch: 6| Step: 3
Training loss: 3.2935583417168988
Validation loss: 2.762621147956363

Epoch: 6| Step: 4
Training loss: 3.271873519299599
Validation loss: 2.7587605609269112

Epoch: 6| Step: 5
Training loss: 2.75055827629571
Validation loss: 2.759042862290787

Epoch: 6| Step: 6
Training loss: 2.371758708691383
Validation loss: 2.754742864505007

Epoch: 6| Step: 7
Training loss: 4.093961288008225
Validation loss: 2.75791480063968

Epoch: 6| Step: 8
Training loss: 2.864252485185124
Validation loss: 2.759012916594799

Epoch: 6| Step: 9
Training loss: 3.1070320848785653
Validation loss: 2.7586786285317735

Epoch: 6| Step: 10
Training loss: 3.1092360575701448
Validation loss: 2.7598840169804584

Epoch: 6| Step: 11
Training loss: 3.1631910089352475
Validation loss: 2.7672597342014997

Epoch: 6| Step: 12
Training loss: 2.3938800866060674
Validation loss: 2.773526181194508

Epoch: 6| Step: 13
Training loss: 3.425834698841884
Validation loss: 2.784841921780433

Epoch: 53| Step: 0
Training loss: 3.3580947210642598
Validation loss: 2.7748203063834356

Epoch: 6| Step: 1
Training loss: 2.7614576763975864
Validation loss: 2.7643370959998625

Epoch: 6| Step: 2
Training loss: 2.970741647925767
Validation loss: 2.7586308462889404

Epoch: 6| Step: 3
Training loss: 2.5755526569947347
Validation loss: 2.755502301110161

Epoch: 6| Step: 4
Training loss: 2.990362900875187
Validation loss: 2.751997079910652

Epoch: 6| Step: 5
Training loss: 2.699329246986457
Validation loss: 2.7497692169796077

Epoch: 6| Step: 6
Training loss: 2.958172556488617
Validation loss: 2.7493439765394667

Epoch: 6| Step: 7
Training loss: 3.122464486524145
Validation loss: 2.751075606992095

Epoch: 6| Step: 8
Training loss: 3.186728739459781
Validation loss: 2.745563536237861

Epoch: 6| Step: 9
Training loss: 3.120253964382722
Validation loss: 2.7484687893919366

Epoch: 6| Step: 10
Training loss: 3.185431014619743
Validation loss: 2.746749986930847

Epoch: 6| Step: 11
Training loss: 3.7735747318310615
Validation loss: 2.750910157155771

Epoch: 6| Step: 12
Training loss: 3.369649531311407
Validation loss: 2.750803752615528

Epoch: 6| Step: 13
Training loss: 2.328652955683327
Validation loss: 2.7531021572188434

Epoch: 54| Step: 0
Training loss: 2.8466731547416466
Validation loss: 2.7532385460082054

Epoch: 6| Step: 1
Training loss: 2.867605901224282
Validation loss: 2.7540490824321635

Epoch: 6| Step: 2
Training loss: 2.394112032213724
Validation loss: 2.7522928667244746

Epoch: 6| Step: 3
Training loss: 2.881200158604548
Validation loss: 2.7497487293646876

Epoch: 6| Step: 4
Training loss: 3.379607693404061
Validation loss: 2.7473735777904067

Epoch: 6| Step: 5
Training loss: 3.4913917676070887
Validation loss: 2.7470620720917873

Epoch: 6| Step: 6
Training loss: 3.2546717005587475
Validation loss: 2.74679622960686

Epoch: 6| Step: 7
Training loss: 2.278645321800538
Validation loss: 2.7479608177718147

Epoch: 6| Step: 8
Training loss: 2.554516707844507
Validation loss: 2.74624003480472

Epoch: 6| Step: 9
Training loss: 3.5250056598157964
Validation loss: 2.754057072012232

Epoch: 6| Step: 10
Training loss: 3.469135572294274
Validation loss: 2.74859239121891

Epoch: 6| Step: 11
Training loss: 3.2061996961666654
Validation loss: 2.743215868192199

Epoch: 6| Step: 12
Training loss: 3.6811735550046305
Validation loss: 2.7369559702990798

Epoch: 6| Step: 13
Training loss: 2.3903617963322
Validation loss: 2.741257580362659

Epoch: 55| Step: 0
Training loss: 2.9526662318812957
Validation loss: 2.736736275394661

Epoch: 6| Step: 1
Training loss: 2.6039435227476466
Validation loss: 2.7450049856569385

Epoch: 6| Step: 2
Training loss: 3.389104827574325
Validation loss: 2.7583001915281797

Epoch: 6| Step: 3
Training loss: 3.332685328121582
Validation loss: 2.7510464337628786

Epoch: 6| Step: 4
Training loss: 2.521218850998244
Validation loss: 2.7506337279301367

Epoch: 6| Step: 5
Training loss: 3.1081976266917564
Validation loss: 2.740783926790069

Epoch: 6| Step: 6
Training loss: 3.5055517035085475
Validation loss: 2.7388176773161006

Epoch: 6| Step: 7
Training loss: 3.4118994663002087
Validation loss: 2.7339525215756604

Epoch: 6| Step: 8
Training loss: 2.4150562401456424
Validation loss: 2.7295009655968787

Epoch: 6| Step: 9
Training loss: 3.232894779889521
Validation loss: 2.7291986704207596

Epoch: 6| Step: 10
Training loss: 3.1591901021370066
Validation loss: 2.7298287555538967

Epoch: 6| Step: 11
Training loss: 2.894741447116529
Validation loss: 2.730761703409999

Epoch: 6| Step: 12
Training loss: 3.106144592830054
Validation loss: 2.728786293268585

Epoch: 6| Step: 13
Training loss: 2.9250190669033334
Validation loss: 2.730933264763208

Epoch: 56| Step: 0
Training loss: 3.093494134976623
Validation loss: 2.729314012142163

Epoch: 6| Step: 1
Training loss: 2.9972033180612496
Validation loss: 2.729421478928253

Epoch: 6| Step: 2
Training loss: 2.8077765749595103
Validation loss: 2.728722608922033

Epoch: 6| Step: 3
Training loss: 2.949180107621429
Validation loss: 2.727552245642691

Epoch: 6| Step: 4
Training loss: 3.3371036822862012
Validation loss: 2.7270419515524322

Epoch: 6| Step: 5
Training loss: 3.2902319634474124
Validation loss: 2.7278323888096447

Epoch: 6| Step: 6
Training loss: 3.1784083537339782
Validation loss: 2.727442603493284

Epoch: 6| Step: 7
Training loss: 3.030788897808393
Validation loss: 2.7261294971841403

Epoch: 6| Step: 8
Training loss: 3.011092183881381
Validation loss: 2.7248682306151486

Epoch: 6| Step: 9
Training loss: 2.9160022160400008
Validation loss: 2.725430396324995

Epoch: 6| Step: 10
Training loss: 3.0984141323422287
Validation loss: 2.7252355166524644

Epoch: 6| Step: 11
Training loss: 2.619137894119102
Validation loss: 2.724197123746962

Epoch: 6| Step: 12
Training loss: 3.1058856036556794
Validation loss: 2.723644666674966

Epoch: 6| Step: 13
Training loss: 3.405727101358566
Validation loss: 2.726616471490952

Epoch: 57| Step: 0
Training loss: 3.2630093699398763
Validation loss: 2.7239111790349706

Epoch: 6| Step: 1
Training loss: 3.0794956621702188
Validation loss: 2.7230798860146184

Epoch: 6| Step: 2
Training loss: 2.9067544806919883
Validation loss: 2.7250821380338315

Epoch: 6| Step: 3
Training loss: 2.825931942238363
Validation loss: 2.7243463195256674

Epoch: 6| Step: 4
Training loss: 2.7901187040173263
Validation loss: 2.724113459154076

Epoch: 6| Step: 5
Training loss: 3.177085467895458
Validation loss: 2.7284410538004638

Epoch: 6| Step: 6
Training loss: 3.436993093395425
Validation loss: 2.7220546650824247

Epoch: 6| Step: 7
Training loss: 2.5171130973859195
Validation loss: 2.7212150270069655

Epoch: 6| Step: 8
Training loss: 3.675248045562521
Validation loss: 2.720988946119363

Epoch: 6| Step: 9
Training loss: 2.882350646861836
Validation loss: 2.7282213591797086

Epoch: 6| Step: 10
Training loss: 2.3428100735724438
Validation loss: 2.7333519991120556

Epoch: 6| Step: 11
Training loss: 3.314368530704487
Validation loss: 2.744498926765323

Epoch: 6| Step: 12
Training loss: 2.85850453285764
Validation loss: 2.748137960476745

Epoch: 6| Step: 13
Training loss: 3.6944039580788606
Validation loss: 2.7327193622098735

Epoch: 58| Step: 0
Training loss: 3.5212390071546995
Validation loss: 2.7234217385540958

Epoch: 6| Step: 1
Training loss: 2.865785510644085
Validation loss: 2.7210559375197074

Epoch: 6| Step: 2
Training loss: 3.1644880597303224
Validation loss: 2.7221702077937233

Epoch: 6| Step: 3
Training loss: 2.4096265609569136
Validation loss: 2.7204556591523015

Epoch: 6| Step: 4
Training loss: 3.3267337953856977
Validation loss: 2.7162307120199753

Epoch: 6| Step: 5
Training loss: 2.5833539244128545
Validation loss: 2.7140077489014005

Epoch: 6| Step: 6
Training loss: 2.7806256911554934
Validation loss: 2.711771106659161

Epoch: 6| Step: 7
Training loss: 2.5129784351521107
Validation loss: 2.719761583052663

Epoch: 6| Step: 8
Training loss: 2.896829575529193
Validation loss: 2.7205538566413106

Epoch: 6| Step: 9
Training loss: 3.1233693255206814
Validation loss: 2.7151381551281

Epoch: 6| Step: 10
Training loss: 3.7032762971383564
Validation loss: 2.713964163951271

Epoch: 6| Step: 11
Training loss: 3.0688291271442414
Validation loss: 2.7118185413807665

Epoch: 6| Step: 12
Training loss: 3.1885966490115822
Validation loss: 2.7113587490514464

Epoch: 6| Step: 13
Training loss: 3.2390821913595853
Validation loss: 2.7216698188472863

Epoch: 59| Step: 0
Training loss: 2.56906589319905
Validation loss: 2.7258436394999475

Epoch: 6| Step: 1
Training loss: 3.306897445772685
Validation loss: 2.7157722708397096

Epoch: 6| Step: 2
Training loss: 2.9037518993671987
Validation loss: 2.7096143468046385

Epoch: 6| Step: 3
Training loss: 2.850279469758202
Validation loss: 2.7149240392930722

Epoch: 6| Step: 4
Training loss: 2.956686788474004
Validation loss: 2.714458465090435

Epoch: 6| Step: 5
Training loss: 2.7420446461911085
Validation loss: 2.711958021655003

Epoch: 6| Step: 6
Training loss: 3.14526009968421
Validation loss: 2.711404747204736

Epoch: 6| Step: 7
Training loss: 3.780664572045931
Validation loss: 2.7166300556436975

Epoch: 6| Step: 8
Training loss: 3.033892865677718
Validation loss: 2.702920475741489

Epoch: 6| Step: 9
Training loss: 2.729871256101675
Validation loss: 2.6979023830922433

Epoch: 6| Step: 10
Training loss: 3.1324831059297904
Validation loss: 2.700361697453058

Epoch: 6| Step: 11
Training loss: 2.781247342569175
Validation loss: 2.7015819072705396

Epoch: 6| Step: 12
Training loss: 3.324250594276822
Validation loss: 2.704516748966188

Epoch: 6| Step: 13
Training loss: 2.984836562648799
Validation loss: 2.702861053404516

Epoch: 60| Step: 0
Training loss: 2.719431473836683
Validation loss: 2.704866770816336

Epoch: 6| Step: 1
Training loss: 3.1662309915760414
Validation loss: 2.7038421220206965

Epoch: 6| Step: 2
Training loss: 2.788781159900971
Validation loss: 2.7066353093421234

Epoch: 6| Step: 3
Training loss: 3.247631383621275
Validation loss: 2.703289904458448

Epoch: 6| Step: 4
Training loss: 2.7879808396073713
Validation loss: 2.7015974527699917

Epoch: 6| Step: 5
Training loss: 3.1828931540755856
Validation loss: 2.7013905959786446

Epoch: 6| Step: 6
Training loss: 2.937794447406074
Validation loss: 2.70059464650504

Epoch: 6| Step: 7
Training loss: 3.49568455182098
Validation loss: 2.7001697803654925

Epoch: 6| Step: 8
Training loss: 3.097453049372404
Validation loss: 2.697996525958981

Epoch: 6| Step: 9
Training loss: 2.9794566584656494
Validation loss: 2.6959196691164538

Epoch: 6| Step: 10
Training loss: 3.320769873139963
Validation loss: 2.6994696508337146

Epoch: 6| Step: 11
Training loss: 2.9177388173401297
Validation loss: 2.7112426935917453

Epoch: 6| Step: 12
Training loss: 2.965079839702558
Validation loss: 2.719119393752974

Epoch: 6| Step: 13
Training loss: 2.5255278913656682
Validation loss: 2.713703685335106

Epoch: 61| Step: 0
Training loss: 3.0154377775431507
Validation loss: 2.7155191424925933

Epoch: 6| Step: 1
Training loss: 2.727981504181838
Validation loss: 2.709988895631597

Epoch: 6| Step: 2
Training loss: 2.904306233435242
Validation loss: 2.7119037962491683

Epoch: 6| Step: 3
Training loss: 2.754275552864302
Validation loss: 2.713089702386314

Epoch: 6| Step: 4
Training loss: 3.804164341357977
Validation loss: 2.7135629126199428

Epoch: 6| Step: 5
Training loss: 2.360174990809718
Validation loss: 2.700914246985998

Epoch: 6| Step: 6
Training loss: 2.4634272499747114
Validation loss: 2.6971268192340654

Epoch: 6| Step: 7
Training loss: 3.778677072884448
Validation loss: 2.689338956364876

Epoch: 6| Step: 8
Training loss: 2.8956912621059954
Validation loss: 2.6910052838225784

Epoch: 6| Step: 9
Training loss: 3.3689472883838922
Validation loss: 2.6889513260313884

Epoch: 6| Step: 10
Training loss: 2.7014699290153623
Validation loss: 2.686707621409606

Epoch: 6| Step: 11
Training loss: 3.245030050976151
Validation loss: 2.692192287308806

Epoch: 6| Step: 12
Training loss: 2.6186796119716993
Validation loss: 2.686489446559942

Epoch: 6| Step: 13
Training loss: 3.5499018051106335
Validation loss: 2.69365157042791

Epoch: 62| Step: 0
Training loss: 3.2649436130298866
Validation loss: 2.689965630213504

Epoch: 6| Step: 1
Training loss: 3.1859492101075255
Validation loss: 2.695651149177506

Epoch: 6| Step: 2
Training loss: 2.5330786986958422
Validation loss: 2.6900265715659404

Epoch: 6| Step: 3
Training loss: 2.9067338110083423
Validation loss: 2.686179044149198

Epoch: 6| Step: 4
Training loss: 3.2139278697078084
Validation loss: 2.684584518355221

Epoch: 6| Step: 5
Training loss: 2.9368528911361573
Validation loss: 2.6835906242522802

Epoch: 6| Step: 6
Training loss: 2.886036628379675
Validation loss: 2.6862588903690123

Epoch: 6| Step: 7
Training loss: 2.9266970414632545
Validation loss: 2.6876209496050665

Epoch: 6| Step: 8
Training loss: 2.6340620658241463
Validation loss: 2.689600291476326

Epoch: 6| Step: 9
Training loss: 3.2118266190304996
Validation loss: 2.687999485281584

Epoch: 6| Step: 10
Training loss: 3.3302339131448058
Validation loss: 2.6881560173377346

Epoch: 6| Step: 11
Training loss: 3.026678984472722
Validation loss: 2.687777784127948

Epoch: 6| Step: 12
Training loss: 3.0253896793292583
Validation loss: 2.683015480112333

Epoch: 6| Step: 13
Training loss: 3.2929851128837977
Validation loss: 2.6812105266138837

Epoch: 63| Step: 0
Training loss: 3.054412126934103
Validation loss: 2.683360932970688

Epoch: 6| Step: 1
Training loss: 3.0994592256480935
Validation loss: 2.6797950283214846

Epoch: 6| Step: 2
Training loss: 3.333469165577574
Validation loss: 2.688024708607016

Epoch: 6| Step: 3
Training loss: 3.2280748716083063
Validation loss: 2.686789113123212

Epoch: 6| Step: 4
Training loss: 2.9452982530325187
Validation loss: 2.6889835583155155

Epoch: 6| Step: 5
Training loss: 2.799078898831679
Validation loss: 2.6860623999250652

Epoch: 6| Step: 6
Training loss: 3.0729861666476332
Validation loss: 2.6840114335030134

Epoch: 6| Step: 7
Training loss: 2.7802890446194364
Validation loss: 2.688738231242924

Epoch: 6| Step: 8
Training loss: 3.002215838679258
Validation loss: 2.6928259561900876

Epoch: 6| Step: 9
Training loss: 2.947313190781676
Validation loss: 2.710365851003812

Epoch: 6| Step: 10
Training loss: 2.8690711546005847
Validation loss: 2.719029481162794

Epoch: 6| Step: 11
Training loss: 3.324076164226845
Validation loss: 2.692806967962262

Epoch: 6| Step: 12
Training loss: 2.898016474906685
Validation loss: 2.6886210792163867

Epoch: 6| Step: 13
Training loss: 2.7405560196619807
Validation loss: 2.680524046057376

Epoch: 64| Step: 0
Training loss: 2.9752062814185147
Validation loss: 2.6760607372334038

Epoch: 6| Step: 1
Training loss: 2.7119079084261286
Validation loss: 2.67440952308162

Epoch: 6| Step: 2
Training loss: 3.1945880544327485
Validation loss: 2.6711627793175006

Epoch: 6| Step: 3
Training loss: 2.828985093984644
Validation loss: 2.673518019832437

Epoch: 6| Step: 4
Training loss: 2.979849854853547
Validation loss: 2.6757571903228223

Epoch: 6| Step: 5
Training loss: 3.0633349156366965
Validation loss: 2.6746167901787667

Epoch: 6| Step: 6
Training loss: 3.375687564467119
Validation loss: 2.67227521219922

Epoch: 6| Step: 7
Training loss: 3.163658888705752
Validation loss: 2.6700634910888272

Epoch: 6| Step: 8
Training loss: 2.841956610630955
Validation loss: 2.6712980200910605

Epoch: 6| Step: 9
Training loss: 2.781639757599526
Validation loss: 2.670794290687225

Epoch: 6| Step: 10
Training loss: 2.877092843635046
Validation loss: 2.6706157461761113

Epoch: 6| Step: 11
Training loss: 3.2700346601323353
Validation loss: 2.669212004910946

Epoch: 6| Step: 12
Training loss: 2.9087639876924
Validation loss: 2.674632463649821

Epoch: 6| Step: 13
Training loss: 3.1698302645322864
Validation loss: 2.670047211828193

Epoch: 65| Step: 0
Training loss: 3.292923425835397
Validation loss: 2.668785891937917

Epoch: 6| Step: 1
Training loss: 2.4817955973865033
Validation loss: 2.6753006190507294

Epoch: 6| Step: 2
Training loss: 2.9124437187552643
Validation loss: 2.6717801238224905

Epoch: 6| Step: 3
Training loss: 2.8910028983873204
Validation loss: 2.6654371973512343

Epoch: 6| Step: 4
Training loss: 2.6129100860997863
Validation loss: 2.6684711504374117

Epoch: 6| Step: 5
Training loss: 2.3812162461979858
Validation loss: 2.668008087833415

Epoch: 6| Step: 6
Training loss: 3.580609121448895
Validation loss: 2.6724193944065537

Epoch: 6| Step: 7
Training loss: 3.446267892973023
Validation loss: 2.671227913677381

Epoch: 6| Step: 8
Training loss: 3.482077076049553
Validation loss: 2.675489456246466

Epoch: 6| Step: 9
Training loss: 2.6504643879059415
Validation loss: 2.6889381366920397

Epoch: 6| Step: 10
Training loss: 3.221223047785419
Validation loss: 2.694831712764224

Epoch: 6| Step: 11
Training loss: 2.8725852777025334
Validation loss: 2.69656872869904

Epoch: 6| Step: 12
Training loss: 3.0725862659483356
Validation loss: 2.694889879495226

Epoch: 6| Step: 13
Training loss: 2.7289529284775043
Validation loss: 2.701133065702718

Epoch: 66| Step: 0
Training loss: 2.7309948764949916
Validation loss: 2.723914282043037

Epoch: 6| Step: 1
Training loss: 3.2360739553462334
Validation loss: 2.7154624136672223

Epoch: 6| Step: 2
Training loss: 2.784855937416348
Validation loss: 2.7143303375730325

Epoch: 6| Step: 3
Training loss: 2.356089647740964
Validation loss: 2.697877259718329

Epoch: 6| Step: 4
Training loss: 3.2095760234214845
Validation loss: 2.6852478498067165

Epoch: 6| Step: 5
Training loss: 2.715743671804923
Validation loss: 2.675791449812181

Epoch: 6| Step: 6
Training loss: 3.235345667158076
Validation loss: 2.6698831069210125

Epoch: 6| Step: 7
Training loss: 2.9103153466893055
Validation loss: 2.668854997700096

Epoch: 6| Step: 8
Training loss: 2.9895428556211905
Validation loss: 2.680409010273449

Epoch: 6| Step: 9
Training loss: 3.3578158286722974
Validation loss: 2.6850711085015955

Epoch: 6| Step: 10
Training loss: 2.8621042702672166
Validation loss: 2.6956198278282177

Epoch: 6| Step: 11
Training loss: 3.5112203853304838
Validation loss: 2.6862341324158296

Epoch: 6| Step: 12
Training loss: 2.3536768941116364
Validation loss: 2.685599561127864

Epoch: 6| Step: 13
Training loss: 3.9683640660347312
Validation loss: 2.6853912295286286

Epoch: 67| Step: 0
Training loss: 2.5399491390632845
Validation loss: 2.661151472803151

Epoch: 6| Step: 1
Training loss: 3.1247631746199485
Validation loss: 2.65665666433827

Epoch: 6| Step: 2
Training loss: 2.627434101530568
Validation loss: 2.658006015024151

Epoch: 6| Step: 3
Training loss: 3.2983539753236313
Validation loss: 2.6637696159998963

Epoch: 6| Step: 4
Training loss: 3.4285128934722655
Validation loss: 2.674569657067138

Epoch: 6| Step: 5
Training loss: 3.4789823532775364
Validation loss: 2.673964993615073

Epoch: 6| Step: 6
Training loss: 3.0899155098434634
Validation loss: 2.667966258395377

Epoch: 6| Step: 7
Training loss: 3.1042195428701422
Validation loss: 2.6651996940849147

Epoch: 6| Step: 8
Training loss: 2.4973780233936824
Validation loss: 2.6784914116302483

Epoch: 6| Step: 9
Training loss: 3.251702816239387
Validation loss: 2.6795598357273995

Epoch: 6| Step: 10
Training loss: 2.9259799130963393
Validation loss: 2.657239133561473

Epoch: 6| Step: 11
Training loss: 2.2412377449377154
Validation loss: 2.6601335427780226

Epoch: 6| Step: 12
Training loss: 3.5676880921766525
Validation loss: 2.657905969654956

Epoch: 6| Step: 13
Training loss: 2.131365833882249
Validation loss: 2.664243988388279

Epoch: 68| Step: 0
Training loss: 2.667823262527525
Validation loss: 2.6625133111014287

Epoch: 6| Step: 1
Training loss: 3.3575059526267155
Validation loss: 2.6613217600870165

Epoch: 6| Step: 2
Training loss: 3.3054039721812405
Validation loss: 2.668350932483215

Epoch: 6| Step: 3
Training loss: 2.659588499722091
Validation loss: 2.6643678045574855

Epoch: 6| Step: 4
Training loss: 3.0762757298936987
Validation loss: 2.662717209195722

Epoch: 6| Step: 5
Training loss: 3.1739848218529696
Validation loss: 2.6644754075068615

Epoch: 6| Step: 6
Training loss: 2.4271664803033
Validation loss: 2.6587090765370576

Epoch: 6| Step: 7
Training loss: 3.1655437251933263
Validation loss: 2.6545914318684916

Epoch: 6| Step: 8
Training loss: 2.6996381022608773
Validation loss: 2.651290382577084

Epoch: 6| Step: 9
Training loss: 3.1624629746030015
Validation loss: 2.6485142831153072

Epoch: 6| Step: 10
Training loss: 3.0440497969415294
Validation loss: 2.6479544366474936

Epoch: 6| Step: 11
Training loss: 3.0077460739925628
Validation loss: 2.666432779640567

Epoch: 6| Step: 12
Training loss: 3.489112814691233
Validation loss: 2.6473638383948614

Epoch: 6| Step: 13
Training loss: 2.0267564808662026
Validation loss: 2.642443258160021

Epoch: 69| Step: 0
Training loss: 3.615575443544757
Validation loss: 2.644400724162084

Epoch: 6| Step: 1
Training loss: 2.24249276133446
Validation loss: 2.644266536834166

Epoch: 6| Step: 2
Training loss: 2.9546650095405935
Validation loss: 2.6443852350548487

Epoch: 6| Step: 3
Training loss: 2.7422822680494967
Validation loss: 2.6447163469494366

Epoch: 6| Step: 4
Training loss: 2.936114369942661
Validation loss: 2.643487408834218

Epoch: 6| Step: 5
Training loss: 3.0915707706135267
Validation loss: 2.640565053452696

Epoch: 6| Step: 6
Training loss: 3.0056667848674232
Validation loss: 2.64322492468919

Epoch: 6| Step: 7
Training loss: 3.16955752344222
Validation loss: 2.6409194994682004

Epoch: 6| Step: 8
Training loss: 3.575435777260508
Validation loss: 2.6402129514214723

Epoch: 6| Step: 9
Training loss: 2.7173766251872435
Validation loss: 2.6413042554396142

Epoch: 6| Step: 10
Training loss: 3.068167288903151
Validation loss: 2.644910509172847

Epoch: 6| Step: 11
Training loss: 2.2265959084664666
Validation loss: 2.643749817463932

Epoch: 6| Step: 12
Training loss: 3.0487935603722156
Validation loss: 2.6452828379549045

Epoch: 6| Step: 13
Training loss: 3.171732481211656
Validation loss: 2.6433419918460626

Epoch: 70| Step: 0
Training loss: 2.486044748463616
Validation loss: 2.6472641423239054

Epoch: 6| Step: 1
Training loss: 2.9115964871533806
Validation loss: 2.6512426616891287

Epoch: 6| Step: 2
Training loss: 2.6640666167375633
Validation loss: 2.647142040752697

Epoch: 6| Step: 3
Training loss: 3.1188426583081608
Validation loss: 2.656330336647345

Epoch: 6| Step: 4
Training loss: 3.557416802919273
Validation loss: 2.648360802747485

Epoch: 6| Step: 5
Training loss: 2.435477273370208
Validation loss: 2.6529621833364048

Epoch: 6| Step: 6
Training loss: 2.7481112496346745
Validation loss: 2.6468926443168153

Epoch: 6| Step: 7
Training loss: 2.831198692277928
Validation loss: 2.6454581392809575

Epoch: 6| Step: 8
Training loss: 3.170622028490054
Validation loss: 2.641464380565217

Epoch: 6| Step: 9
Training loss: 3.5561356832838653
Validation loss: 2.6446688835507213

Epoch: 6| Step: 10
Training loss: 2.59546062637003
Validation loss: 2.6421822595943674

Epoch: 6| Step: 11
Training loss: 2.3571160219985163
Validation loss: 2.636230890313342

Epoch: 6| Step: 12
Training loss: 3.854725372784028
Validation loss: 2.6373445420435067

Epoch: 6| Step: 13
Training loss: 2.986018023161206
Validation loss: 2.6354553234088347

Epoch: 71| Step: 0
Training loss: 3.1160525595819384
Validation loss: 2.6418978958063306

Epoch: 6| Step: 1
Training loss: 2.6274152271304274
Validation loss: 2.638602618039551

Epoch: 6| Step: 2
Training loss: 3.186748341214658
Validation loss: 2.6398501646784194

Epoch: 6| Step: 3
Training loss: 2.815896759297293
Validation loss: 2.63478867052721

Epoch: 6| Step: 4
Training loss: 2.7718158117810963
Validation loss: 2.639541470662306

Epoch: 6| Step: 5
Training loss: 2.602339253440323
Validation loss: 2.63819485187293

Epoch: 6| Step: 6
Training loss: 3.6326016928923135
Validation loss: 2.6371531882662866

Epoch: 6| Step: 7
Training loss: 3.2868835045225206
Validation loss: 2.6352522256944377

Epoch: 6| Step: 8
Training loss: 3.254137193560179
Validation loss: 2.635158345386014

Epoch: 6| Step: 9
Training loss: 2.064036981510084
Validation loss: 2.63579177635025

Epoch: 6| Step: 10
Training loss: 2.6554793193502424
Validation loss: 2.637192363611532

Epoch: 6| Step: 11
Training loss: 3.3973600236072836
Validation loss: 2.6376105952863944

Epoch: 6| Step: 12
Training loss: 3.436822581733452
Validation loss: 2.6513186896155942

Epoch: 6| Step: 13
Training loss: 2.0311048015637456
Validation loss: 2.6550285498788115

Epoch: 72| Step: 0
Training loss: 3.318197712319812
Validation loss: 2.65727579383314

Epoch: 6| Step: 1
Training loss: 2.7859188710358476
Validation loss: 2.6594317157876266

Epoch: 6| Step: 2
Training loss: 2.5187331244042976
Validation loss: 2.657373031453832

Epoch: 6| Step: 3
Training loss: 2.404140687358083
Validation loss: 2.6395629817020314

Epoch: 6| Step: 4
Training loss: 2.4828943602773106
Validation loss: 2.6337767026699606

Epoch: 6| Step: 5
Training loss: 2.936087735541276
Validation loss: 2.630158782820389

Epoch: 6| Step: 6
Training loss: 3.487437591541248
Validation loss: 2.6314660131533554

Epoch: 6| Step: 7
Training loss: 3.1808381119384794
Validation loss: 2.6319143952480215

Epoch: 6| Step: 8
Training loss: 2.6497951392395875
Validation loss: 2.6287269693886284

Epoch: 6| Step: 9
Training loss: 3.3579379534461826
Validation loss: 2.629380709228785

Epoch: 6| Step: 10
Training loss: 3.375690248335881
Validation loss: 2.631730349078935

Epoch: 6| Step: 11
Training loss: 2.668319388676204
Validation loss: 2.633589168373067

Epoch: 6| Step: 12
Training loss: 3.3977444347622026
Validation loss: 2.6370736011950724

Epoch: 6| Step: 13
Training loss: 2.7852744656549633
Validation loss: 2.643340702917409

Epoch: 73| Step: 0
Training loss: 2.929760090246532
Validation loss: 2.6358855154420544

Epoch: 6| Step: 1
Training loss: 3.0310733389746076
Validation loss: 2.6304630617139995

Epoch: 6| Step: 2
Training loss: 2.6639303135449293
Validation loss: 2.6260203777408204

Epoch: 6| Step: 3
Training loss: 3.608529656570475
Validation loss: 2.632633073000241

Epoch: 6| Step: 4
Training loss: 3.205687451601219
Validation loss: 2.63009865815511

Epoch: 6| Step: 5
Training loss: 2.738458429065248
Validation loss: 2.627147769605337

Epoch: 6| Step: 6
Training loss: 3.374424072858408
Validation loss: 2.631786040327116

Epoch: 6| Step: 7
Training loss: 2.449637101992358
Validation loss: 2.6309241829152286

Epoch: 6| Step: 8
Training loss: 3.125356577556782
Validation loss: 2.628695081273552

Epoch: 6| Step: 9
Training loss: 2.6691065494255337
Validation loss: 2.6348301957523996

Epoch: 6| Step: 10
Training loss: 3.1423702420171686
Validation loss: 2.6346843135933664

Epoch: 6| Step: 11
Training loss: 2.506119010717593
Validation loss: 2.645106613961949

Epoch: 6| Step: 12
Training loss: 2.9210380130581095
Validation loss: 2.6506604512595238

Epoch: 6| Step: 13
Training loss: 3.0208205299544586
Validation loss: 2.666059508216616

Epoch: 74| Step: 0
Training loss: 2.795639532415193
Validation loss: 2.663053459150742

Epoch: 6| Step: 1
Training loss: 3.1228709788646034
Validation loss: 2.6576874426037502

Epoch: 6| Step: 2
Training loss: 3.260263815192464
Validation loss: 2.643214869807833

Epoch: 6| Step: 3
Training loss: 3.1199840726201344
Validation loss: 2.638615013559127

Epoch: 6| Step: 4
Training loss: 2.8024692104257847
Validation loss: 2.6303623508100418

Epoch: 6| Step: 5
Training loss: 2.2953272165303193
Validation loss: 2.6243523942989393

Epoch: 6| Step: 6
Training loss: 2.783553123552375
Validation loss: 2.62301425469012

Epoch: 6| Step: 7
Training loss: 2.3763600520897437
Validation loss: 2.6156272884351095

Epoch: 6| Step: 8
Training loss: 2.6897646211789965
Validation loss: 2.620447571900958

Epoch: 6| Step: 9
Training loss: 3.0307239193938362
Validation loss: 2.6177578222184326

Epoch: 6| Step: 10
Training loss: 4.048723306877047
Validation loss: 2.6159282448410655

Epoch: 6| Step: 11
Training loss: 2.638348020929198
Validation loss: 2.618069948388397

Epoch: 6| Step: 12
Training loss: 3.020608056098052
Validation loss: 2.6179304934000935

Epoch: 6| Step: 13
Training loss: 3.397063580483685
Validation loss: 2.6178827118186563

Epoch: 75| Step: 0
Training loss: 3.015732204923296
Validation loss: 2.617410177260308

Epoch: 6| Step: 1
Training loss: 1.8496361864477016
Validation loss: 2.617292667211138

Epoch: 6| Step: 2
Training loss: 3.182683859141717
Validation loss: 2.6183300009558277

Epoch: 6| Step: 3
Training loss: 3.0241318331748346
Validation loss: 2.6171469966746184

Epoch: 6| Step: 4
Training loss: 3.2356768213447245
Validation loss: 2.6170118419585826

Epoch: 6| Step: 5
Training loss: 3.2735691817935177
Validation loss: 2.6168630385077916

Epoch: 6| Step: 6
Training loss: 2.912907184739455
Validation loss: 2.6166238671624753

Epoch: 6| Step: 7
Training loss: 2.8861996980284323
Validation loss: 2.6156035075639665

Epoch: 6| Step: 8
Training loss: 3.2827917927193773
Validation loss: 2.615694113456453

Epoch: 6| Step: 9
Training loss: 2.682933209680215
Validation loss: 2.608901828530657

Epoch: 6| Step: 10
Training loss: 2.7048484291581363
Validation loss: 2.6130592176699223

Epoch: 6| Step: 11
Training loss: 3.1279408159632665
Validation loss: 2.615658105331071

Epoch: 6| Step: 12
Training loss: 2.9127228549291235
Validation loss: 2.624986143607872

Epoch: 6| Step: 13
Training loss: 3.3227340664015514
Validation loss: 2.6623864987730284

Epoch: 76| Step: 0
Training loss: 2.6845008616311956
Validation loss: 2.668685074870669

Epoch: 6| Step: 1
Training loss: 2.9588235439996025
Validation loss: 2.675877574686583

Epoch: 6| Step: 2
Training loss: 3.522958524166938
Validation loss: 2.6768468119736957

Epoch: 6| Step: 3
Training loss: 3.026805962817546
Validation loss: 2.655373974028212

Epoch: 6| Step: 4
Training loss: 3.081850537319258
Validation loss: 2.6495622618135966

Epoch: 6| Step: 5
Training loss: 3.4426982069612007
Validation loss: 2.6078334324850774

Epoch: 6| Step: 6
Training loss: 3.0891627973174347
Validation loss: 2.605114352814556

Epoch: 6| Step: 7
Training loss: 3.036215578891576
Validation loss: 2.6064167728626715

Epoch: 6| Step: 8
Training loss: 3.1150846726373578
Validation loss: 2.607001268513009

Epoch: 6| Step: 9
Training loss: 2.2731283180814645
Validation loss: 2.611760170904237

Epoch: 6| Step: 10
Training loss: 2.6081520915412666
Validation loss: 2.607150641708804

Epoch: 6| Step: 11
Training loss: 3.0507940665743907
Validation loss: 2.600485028736865

Epoch: 6| Step: 12
Training loss: 3.1106691973801692
Validation loss: 2.6011156262939026

Epoch: 6| Step: 13
Training loss: 1.9873114058547372
Validation loss: 2.6047735534992422

Epoch: 77| Step: 0
Training loss: 3.0758987353935283
Validation loss: 2.601208651770874

Epoch: 6| Step: 1
Training loss: 3.260336942987875
Validation loss: 2.602939097509709

Epoch: 6| Step: 2
Training loss: 2.2355914239279033
Validation loss: 2.607004696530282

Epoch: 6| Step: 3
Training loss: 2.929716471210921
Validation loss: 2.6048258321691344

Epoch: 6| Step: 4
Training loss: 2.6975832896415306
Validation loss: 2.6087892073883583

Epoch: 6| Step: 5
Training loss: 2.4638967977189243
Validation loss: 2.6165695075463193

Epoch: 6| Step: 6
Training loss: 3.314390542693276
Validation loss: 2.617154749844616

Epoch: 6| Step: 7
Training loss: 3.185354969598935
Validation loss: 2.602128887323742

Epoch: 6| Step: 8
Training loss: 2.9688311114022277
Validation loss: 2.6129208786597373

Epoch: 6| Step: 9
Training loss: 3.053500596119629
Validation loss: 2.607030172477265

Epoch: 6| Step: 10
Training loss: 3.043647817662856
Validation loss: 2.603788803415041

Epoch: 6| Step: 11
Training loss: 2.7591832890341577
Validation loss: 2.6011560549932518

Epoch: 6| Step: 12
Training loss: 2.8392566771963232
Validation loss: 2.602150182527782

Epoch: 6| Step: 13
Training loss: 3.5248473871620605
Validation loss: 2.60156337308501

Epoch: 78| Step: 0
Training loss: 2.753384674677341
Validation loss: 2.604242482384073

Epoch: 6| Step: 1
Training loss: 3.5687166817040072
Validation loss: 2.5994502565473225

Epoch: 6| Step: 2
Training loss: 2.86669634944127
Validation loss: 2.6006216505806146

Epoch: 6| Step: 3
Training loss: 2.7623435342934153
Validation loss: 2.599632973792398

Epoch: 6| Step: 4
Training loss: 3.744473008280499
Validation loss: 2.6007508831188098

Epoch: 6| Step: 5
Training loss: 2.7225600106567343
Validation loss: 2.5987137652645544

Epoch: 6| Step: 6
Training loss: 2.423895405366582
Validation loss: 2.5997028172706056

Epoch: 6| Step: 7
Training loss: 2.8526027506477183
Validation loss: 2.5972022190946515

Epoch: 6| Step: 8
Training loss: 2.4813068565945753
Validation loss: 2.5978114154940157

Epoch: 6| Step: 9
Training loss: 3.10164244426252
Validation loss: 2.601164628516971

Epoch: 6| Step: 10
Training loss: 2.860369066554072
Validation loss: 2.6202493486074703

Epoch: 6| Step: 11
Training loss: 3.191343346562989
Validation loss: 2.629477101603018

Epoch: 6| Step: 12
Training loss: 2.775556931153849
Validation loss: 2.6422369019477676

Epoch: 6| Step: 13
Training loss: 2.9850900801927627
Validation loss: 2.649784391411895

Epoch: 79| Step: 0
Training loss: 3.047256211128261
Validation loss: 2.639746277825442

Epoch: 6| Step: 1
Training loss: 2.9778221849037236
Validation loss: 2.6401797984397284

Epoch: 6| Step: 2
Training loss: 2.4094721041060194
Validation loss: 2.6398346488709876

Epoch: 6| Step: 3
Training loss: 2.727445005986583
Validation loss: 2.634464643680492

Epoch: 6| Step: 4
Training loss: 3.0228275600544445
Validation loss: 2.6230724345902203

Epoch: 6| Step: 5
Training loss: 2.973413919745242
Validation loss: 2.624321034759127

Epoch: 6| Step: 6
Training loss: 3.2197569225801703
Validation loss: 2.6053221940044606

Epoch: 6| Step: 7
Training loss: 2.736375175251275
Validation loss: 2.599788895974854

Epoch: 6| Step: 8
Training loss: 3.463114516609488
Validation loss: 2.600002558354333

Epoch: 6| Step: 9
Training loss: 3.241502363132014
Validation loss: 2.6001361194835098

Epoch: 6| Step: 10
Training loss: 2.1298640065366454
Validation loss: 2.600057593166063

Epoch: 6| Step: 11
Training loss: 2.958308439194793
Validation loss: 2.5968691112928908

Epoch: 6| Step: 12
Training loss: 3.2007952893959244
Validation loss: 2.594556692662126

Epoch: 6| Step: 13
Training loss: 2.930267195252216
Validation loss: 2.5976710545237265

Epoch: 80| Step: 0
Training loss: 2.70462629490297
Validation loss: 2.59899566411173

Epoch: 6| Step: 1
Training loss: 2.468612184178642
Validation loss: 2.5988714077136845

Epoch: 6| Step: 2
Training loss: 3.3716179184933845
Validation loss: 2.599433866436401

Epoch: 6| Step: 3
Training loss: 3.147788158312407
Validation loss: 2.5966255358107886

Epoch: 6| Step: 4
Training loss: 2.4734618214069948
Validation loss: 2.595876202541821

Epoch: 6| Step: 5
Training loss: 3.22059978182821
Validation loss: 2.5971480990295213

Epoch: 6| Step: 6
Training loss: 3.5082656805503127
Validation loss: 2.605600384878442

Epoch: 6| Step: 7
Training loss: 2.889787212312749
Validation loss: 2.6097545852433894

Epoch: 6| Step: 8
Training loss: 2.7483782754820343
Validation loss: 2.616241692647031

Epoch: 6| Step: 9
Training loss: 2.980378675787093
Validation loss: 2.614327829117847

Epoch: 6| Step: 10
Training loss: 2.936958100676929
Validation loss: 2.604499741122085

Epoch: 6| Step: 11
Training loss: 2.8036111875705156
Validation loss: 2.5975784165500424

Epoch: 6| Step: 12
Training loss: 3.029212188028851
Validation loss: 2.5878232256578766

Epoch: 6| Step: 13
Training loss: 2.712792720909331
Validation loss: 2.585916804908796

Epoch: 81| Step: 0
Training loss: 3.089441092353528
Validation loss: 2.592978194497312

Epoch: 6| Step: 1
Training loss: 3.439515234036043
Validation loss: 2.5983576278383747

Epoch: 6| Step: 2
Training loss: 2.554074275060703
Validation loss: 2.6012305044450152

Epoch: 6| Step: 3
Training loss: 2.333909190734657
Validation loss: 2.600715745516046

Epoch: 6| Step: 4
Training loss: 2.9989192923446724
Validation loss: 2.601647481528399

Epoch: 6| Step: 5
Training loss: 2.7291458264979647
Validation loss: 2.6001079079422373

Epoch: 6| Step: 6
Training loss: 3.2158400334860686
Validation loss: 2.593714840696762

Epoch: 6| Step: 7
Training loss: 3.0542984736694883
Validation loss: 2.5904682434552644

Epoch: 6| Step: 8
Training loss: 2.891875125579139
Validation loss: 2.5882857985175645

Epoch: 6| Step: 9
Training loss: 2.871318782369487
Validation loss: 2.584996466777549

Epoch: 6| Step: 10
Training loss: 3.0170586691346406
Validation loss: 2.585356555847539

Epoch: 6| Step: 11
Training loss: 2.6784595756791556
Validation loss: 2.5862173259853902

Epoch: 6| Step: 12
Training loss: 2.9594059105681767
Validation loss: 2.587427161104372

Epoch: 6| Step: 13
Training loss: 3.529293227075107
Validation loss: 2.59202089284409

Epoch: 82| Step: 0
Training loss: 2.643652901095094
Validation loss: 2.6168828520917664

Epoch: 6| Step: 1
Training loss: 2.5335503945300824
Validation loss: 2.631166544601049

Epoch: 6| Step: 2
Training loss: 3.2381516673409734
Validation loss: 2.6401638369312828

Epoch: 6| Step: 3
Training loss: 3.492654449171627
Validation loss: 2.6321773352600224

Epoch: 6| Step: 4
Training loss: 2.702403418749854
Validation loss: 2.6363227652019767

Epoch: 6| Step: 5
Training loss: 3.6202976376323517
Validation loss: 2.610593177752906

Epoch: 6| Step: 6
Training loss: 2.7699060442031924
Validation loss: 2.583398898189457

Epoch: 6| Step: 7
Training loss: 2.8891683671533865
Validation loss: 2.575580858799212

Epoch: 6| Step: 8
Training loss: 3.122304745899979
Validation loss: 2.576332353547777

Epoch: 6| Step: 9
Training loss: 2.7283318579904168
Validation loss: 2.581854009332441

Epoch: 6| Step: 10
Training loss: 2.8730352571357556
Validation loss: 2.5800208336988275

Epoch: 6| Step: 11
Training loss: 3.0412766890289604
Validation loss: 2.5875989147491154

Epoch: 6| Step: 12
Training loss: 2.4425007312347975
Validation loss: 2.587391065757924

Epoch: 6| Step: 13
Training loss: 2.8707197088410625
Validation loss: 2.58547132311552

Epoch: 83| Step: 0
Training loss: 3.067741424088471
Validation loss: 2.5912276792387297

Epoch: 6| Step: 1
Training loss: 3.4531382564790793
Validation loss: 2.5875011475596024

Epoch: 6| Step: 2
Training loss: 2.6424081413594043
Validation loss: 2.5889262922206537

Epoch: 6| Step: 3
Training loss: 3.008713307428341
Validation loss: 2.5863844616576186

Epoch: 6| Step: 4
Training loss: 2.3117992267220897
Validation loss: 2.5859643622292188

Epoch: 6| Step: 5
Training loss: 2.9671462696459088
Validation loss: 2.5842506818930784

Epoch: 6| Step: 6
Training loss: 2.865148500119038
Validation loss: 2.5790786972946105

Epoch: 6| Step: 7
Training loss: 2.9580008808003133
Validation loss: 2.577071676304921

Epoch: 6| Step: 8
Training loss: 3.3274109840093917
Validation loss: 2.573017986392262

Epoch: 6| Step: 9
Training loss: 2.971708409787665
Validation loss: 2.57036046671807

Epoch: 6| Step: 10
Training loss: 2.860353896380065
Validation loss: 2.571282639654027

Epoch: 6| Step: 11
Training loss: 2.220051128726579
Validation loss: 2.5779197215879757

Epoch: 6| Step: 12
Training loss: 3.2002362879299997
Validation loss: 2.59028881829831

Epoch: 6| Step: 13
Training loss: 3.200487940065451
Validation loss: 2.5902440987529163

Epoch: 84| Step: 0
Training loss: 3.016179167275048
Validation loss: 2.583300693185352

Epoch: 6| Step: 1
Training loss: 3.185014840515152
Validation loss: 2.5765840968912994

Epoch: 6| Step: 2
Training loss: 2.292798739471675
Validation loss: 2.577789226603829

Epoch: 6| Step: 3
Training loss: 2.9823416128893885
Validation loss: 2.5662968037326563

Epoch: 6| Step: 4
Training loss: 2.540785829678232
Validation loss: 2.5698306557157515

Epoch: 6| Step: 5
Training loss: 2.8583812550196748
Validation loss: 2.567666944004508

Epoch: 6| Step: 6
Training loss: 2.9151489850505934
Validation loss: 2.5658155182117515

Epoch: 6| Step: 7
Training loss: 2.9733895438772686
Validation loss: 2.565154873550982

Epoch: 6| Step: 8
Training loss: 3.0574504717903728
Validation loss: 2.5669068051420054

Epoch: 6| Step: 9
Training loss: 2.7890151417876177
Validation loss: 2.567395999217276

Epoch: 6| Step: 10
Training loss: 2.843814388007329
Validation loss: 2.5645236896649295

Epoch: 6| Step: 11
Training loss: 2.98789921730772
Validation loss: 2.56991207682802

Epoch: 6| Step: 12
Training loss: 3.553672964339232
Validation loss: 2.5676349500527524

Epoch: 6| Step: 13
Training loss: 2.8730606504067273
Validation loss: 2.5709182918543925

Epoch: 85| Step: 0
Training loss: 3.384730405453666
Validation loss: 2.5732069621866573

Epoch: 6| Step: 1
Training loss: 3.0511182142253577
Validation loss: 2.5729161518626658

Epoch: 6| Step: 2
Training loss: 3.2324879619377187
Validation loss: 2.5775919721515743

Epoch: 6| Step: 3
Training loss: 3.5328117225507767
Validation loss: 2.5781397267527266

Epoch: 6| Step: 4
Training loss: 2.4602224128478123
Validation loss: 2.57898330695378

Epoch: 6| Step: 5
Training loss: 2.8248173882531837
Validation loss: 2.584631043807538

Epoch: 6| Step: 6
Training loss: 3.307714208008357
Validation loss: 2.5924370787611615

Epoch: 6| Step: 7
Training loss: 1.8878917009763772
Validation loss: 2.5877891766133216

Epoch: 6| Step: 8
Training loss: 2.8187633708628272
Validation loss: 2.586490682102175

Epoch: 6| Step: 9
Training loss: 2.916576456763891
Validation loss: 2.5904006177428913

Epoch: 6| Step: 10
Training loss: 3.111884250018026
Validation loss: 2.582442197079831

Epoch: 6| Step: 11
Training loss: 2.988436347078035
Validation loss: 2.5873613389844166

Epoch: 6| Step: 12
Training loss: 2.707270976319362
Validation loss: 2.587247626613659

Epoch: 6| Step: 13
Training loss: 2.0538012547752063
Validation loss: 2.5764308500328355

Epoch: 86| Step: 0
Training loss: 2.9557644790130873
Validation loss: 2.572856268826279

Epoch: 6| Step: 1
Training loss: 2.5349791572210543
Validation loss: 2.566617009972099

Epoch: 6| Step: 2
Training loss: 2.8718591201891117
Validation loss: 2.563547467057361

Epoch: 6| Step: 3
Training loss: 2.69392584914895
Validation loss: 2.5661505450979853

Epoch: 6| Step: 4
Training loss: 3.1566565223485195
Validation loss: 2.568185204668429

Epoch: 6| Step: 5
Training loss: 2.71778931580544
Validation loss: 2.570935001365022

Epoch: 6| Step: 6
Training loss: 2.8578093364483244
Validation loss: 2.572296567711091

Epoch: 6| Step: 7
Training loss: 3.7068722593342063
Validation loss: 2.571471332232598

Epoch: 6| Step: 8
Training loss: 2.4174158206710152
Validation loss: 2.568318478948714

Epoch: 6| Step: 9
Training loss: 3.594822466502877
Validation loss: 2.57314669138108

Epoch: 6| Step: 10
Training loss: 3.058543861342814
Validation loss: 2.5711302354285333

Epoch: 6| Step: 11
Training loss: 2.9071038745316438
Validation loss: 2.571837071983496

Epoch: 6| Step: 12
Training loss: 2.5492654827112013
Validation loss: 2.5671012959762103

Epoch: 6| Step: 13
Training loss: 2.537031282628266
Validation loss: 2.57289717644745

Epoch: 87| Step: 0
Training loss: 2.8308409405878323
Validation loss: 2.5682646760576078

Epoch: 6| Step: 1
Training loss: 2.7458040999003
Validation loss: 2.5665249132417105

Epoch: 6| Step: 2
Training loss: 3.452302998882594
Validation loss: 2.575391151347526

Epoch: 6| Step: 3
Training loss: 2.970081552740874
Validation loss: 2.580749653359421

Epoch: 6| Step: 4
Training loss: 2.8847692614863676
Validation loss: 2.5922710335097863

Epoch: 6| Step: 5
Training loss: 3.3034068121823053
Validation loss: 2.588265953220449

Epoch: 6| Step: 6
Training loss: 3.280544532142212
Validation loss: 2.6032462664649993

Epoch: 6| Step: 7
Training loss: 2.7971856141896434
Validation loss: 2.596746729614648

Epoch: 6| Step: 8
Training loss: 2.6747847211969296
Validation loss: 2.5857806979659252

Epoch: 6| Step: 9
Training loss: 1.8573015978325327
Validation loss: 2.5827871688705226

Epoch: 6| Step: 10
Training loss: 3.0388870777013923
Validation loss: 2.567636797174155

Epoch: 6| Step: 11
Training loss: 2.8760302812258134
Validation loss: 2.5643789644309085

Epoch: 6| Step: 12
Training loss: 3.042019305406817
Validation loss: 2.5634068050864656

Epoch: 6| Step: 13
Training loss: 2.824425569720179
Validation loss: 2.5634781145988645

Epoch: 88| Step: 0
Training loss: 3.3605699410024394
Validation loss: 2.5594897292905805

Epoch: 6| Step: 1
Training loss: 2.6122625215638995
Validation loss: 2.5587892113416717

Epoch: 6| Step: 2
Training loss: 2.181366741914787
Validation loss: 2.559773767454604

Epoch: 6| Step: 3
Training loss: 2.8725250205866764
Validation loss: 2.5576803852083527

Epoch: 6| Step: 4
Training loss: 2.976533023558118
Validation loss: 2.5575905347389787

Epoch: 6| Step: 5
Training loss: 2.6745326338007427
Validation loss: 2.5609665911490227

Epoch: 6| Step: 6
Training loss: 2.9854823749247505
Validation loss: 2.5584819634954132

Epoch: 6| Step: 7
Training loss: 2.360702545370964
Validation loss: 2.5600596357056586

Epoch: 6| Step: 8
Training loss: 2.988609944136799
Validation loss: 2.5682128864474505

Epoch: 6| Step: 9
Training loss: 3.4451152719111406
Validation loss: 2.5616590358986544

Epoch: 6| Step: 10
Training loss: 2.7656116377513094
Validation loss: 2.548602866578514

Epoch: 6| Step: 11
Training loss: 3.548237543086766
Validation loss: 2.5542862091437186

Epoch: 6| Step: 12
Training loss: 2.9227368720711513
Validation loss: 2.559286246747357

Epoch: 6| Step: 13
Training loss: 2.8104977580239527
Validation loss: 2.5631564350243288

Epoch: 89| Step: 0
Training loss: 2.764016324741719
Validation loss: 2.56723005692814

Epoch: 6| Step: 1
Training loss: 3.535255523467991
Validation loss: 2.565324668637009

Epoch: 6| Step: 2
Training loss: 2.824915714188097
Validation loss: 2.5639838367777097

Epoch: 6| Step: 3
Training loss: 3.3545528845036325
Validation loss: 2.5666955755539713

Epoch: 6| Step: 4
Training loss: 2.7866885556573577
Validation loss: 2.56766218547357

Epoch: 6| Step: 5
Training loss: 3.1200283939341125
Validation loss: 2.562372414058627

Epoch: 6| Step: 6
Training loss: 2.924117100156847
Validation loss: 2.5642271016694504

Epoch: 6| Step: 7
Training loss: 2.817561194526199
Validation loss: 2.560338784434285

Epoch: 6| Step: 8
Training loss: 3.031399280765612
Validation loss: 2.560622725412972

Epoch: 6| Step: 9
Training loss: 2.646415185903686
Validation loss: 2.5606234607785368

Epoch: 6| Step: 10
Training loss: 2.6761820026652074
Validation loss: 2.5704383793091528

Epoch: 6| Step: 11
Training loss: 2.829330440344786
Validation loss: 2.5698238331799783

Epoch: 6| Step: 12
Training loss: 2.9293194755824867
Validation loss: 2.590166853183445

Epoch: 6| Step: 13
Training loss: 2.1666209387233057
Validation loss: 2.5922672280063193

Epoch: 90| Step: 0
Training loss: 3.10780087598772
Validation loss: 2.608427113690947

Epoch: 6| Step: 1
Training loss: 3.3087257620136623
Validation loss: 2.6028590522862514

Epoch: 6| Step: 2
Training loss: 2.7579416563572563
Validation loss: 2.599779894877778

Epoch: 6| Step: 3
Training loss: 2.941357616007299
Validation loss: 2.5849090370999606

Epoch: 6| Step: 4
Training loss: 2.7205520445534623
Validation loss: 2.5666719785645196

Epoch: 6| Step: 5
Training loss: 2.3310123434963246
Validation loss: 2.5541832654472834

Epoch: 6| Step: 6
Training loss: 2.5702920002685077
Validation loss: 2.553009136167232

Epoch: 6| Step: 7
Training loss: 3.105297846859847
Validation loss: 2.5528241935333025

Epoch: 6| Step: 8
Training loss: 3.0671954846193192
Validation loss: 2.553559877953576

Epoch: 6| Step: 9
Training loss: 2.724086566384186
Validation loss: 2.5551751767539503

Epoch: 6| Step: 10
Training loss: 2.9874944710780102
Validation loss: 2.5589267679628978

Epoch: 6| Step: 11
Training loss: 3.3303669286881448
Validation loss: 2.5582420234489405

Epoch: 6| Step: 12
Training loss: 3.09231703738944
Validation loss: 2.560910838389017

Epoch: 6| Step: 13
Training loss: 2.7823601553735284
Validation loss: 2.556973155406648

Epoch: 91| Step: 0
Training loss: 2.7752306661878245
Validation loss: 2.5579748058053164

Epoch: 6| Step: 1
Training loss: 2.963048016687265
Validation loss: 2.5663423081819983

Epoch: 6| Step: 2
Training loss: 2.857839370025573
Validation loss: 2.5712075374275885

Epoch: 6| Step: 3
Training loss: 2.917457219114997
Validation loss: 2.5691103088205467

Epoch: 6| Step: 4
Training loss: 2.3332525534497828
Validation loss: 2.5707961596537676

Epoch: 6| Step: 5
Training loss: 2.8615590910408533
Validation loss: 2.576015184126509

Epoch: 6| Step: 6
Training loss: 3.639383521852076
Validation loss: 2.572783289130881

Epoch: 6| Step: 7
Training loss: 3.4159391295394523
Validation loss: 2.5610769919270804

Epoch: 6| Step: 8
Training loss: 2.671976723324017
Validation loss: 2.548500748542058

Epoch: 6| Step: 9
Training loss: 2.751895251454093
Validation loss: 2.5506802614458466

Epoch: 6| Step: 10
Training loss: 2.7250944628660068
Validation loss: 2.5511720133127067

Epoch: 6| Step: 11
Training loss: 2.6639909035467233
Validation loss: 2.5499396955826006

Epoch: 6| Step: 12
Training loss: 2.727977746089656
Validation loss: 2.551538564882229

Epoch: 6| Step: 13
Training loss: 3.6038870436551274
Validation loss: 2.5494133073492833

Epoch: 92| Step: 0
Training loss: 2.569309583910836
Validation loss: 2.5461914848449494

Epoch: 6| Step: 1
Training loss: 3.1808733404247187
Validation loss: 2.5512455669960903

Epoch: 6| Step: 2
Training loss: 2.678340829278141
Validation loss: 2.544906622587122

Epoch: 6| Step: 3
Training loss: 2.4062177977946186
Validation loss: 2.5450234758386396

Epoch: 6| Step: 4
Training loss: 3.1015163773727408
Validation loss: 2.543614547540444

Epoch: 6| Step: 5
Training loss: 2.6723314754211103
Validation loss: 2.5477798317174982

Epoch: 6| Step: 6
Training loss: 3.449704508635401
Validation loss: 2.541770555365777

Epoch: 6| Step: 7
Training loss: 2.77106488247492
Validation loss: 2.5440911820012553

Epoch: 6| Step: 8
Training loss: 3.063077911033688
Validation loss: 2.5421952391109826

Epoch: 6| Step: 9
Training loss: 2.6617494984992915
Validation loss: 2.5401206351825194

Epoch: 6| Step: 10
Training loss: 2.8845280863928098
Validation loss: 2.5409856301092995

Epoch: 6| Step: 11
Training loss: 3.4222379866425476
Validation loss: 2.541711105517654

Epoch: 6| Step: 12
Training loss: 2.8128994128282394
Validation loss: 2.5375029782060987

Epoch: 6| Step: 13
Training loss: 2.7252906084400723
Validation loss: 2.5427181923875652

Epoch: 93| Step: 0
Training loss: 2.4609980500053483
Validation loss: 2.540144060994499

Epoch: 6| Step: 1
Training loss: 3.0493420125651247
Validation loss: 2.5400192106617148

Epoch: 6| Step: 2
Training loss: 3.5001287436648676
Validation loss: 2.5458295840611083

Epoch: 6| Step: 3
Training loss: 2.66174063084339
Validation loss: 2.554887540808328

Epoch: 6| Step: 4
Training loss: 2.722528309600458
Validation loss: 2.574479942957887

Epoch: 6| Step: 5
Training loss: 2.2880029927881047
Validation loss: 2.5853779882100882

Epoch: 6| Step: 6
Training loss: 3.260038717543148
Validation loss: 2.600983790070117

Epoch: 6| Step: 7
Training loss: 2.843206332710697
Validation loss: 2.6048413911647743

Epoch: 6| Step: 8
Training loss: 2.7096037208259025
Validation loss: 2.589884527882666

Epoch: 6| Step: 9
Training loss: 3.173988577674932
Validation loss: 2.58974586363326

Epoch: 6| Step: 10
Training loss: 3.057801047699875
Validation loss: 2.5549049692554164

Epoch: 6| Step: 11
Training loss: 2.9706093837938345
Validation loss: 2.5452812780359135

Epoch: 6| Step: 12
Training loss: 2.6170513971723777
Validation loss: 2.5336139264364443

Epoch: 6| Step: 13
Training loss: 3.3045771154270556
Validation loss: 2.536422871923799

Epoch: 94| Step: 0
Training loss: 2.7417636989440153
Validation loss: 2.5408333740948996

Epoch: 6| Step: 1
Training loss: 3.441369393158906
Validation loss: 2.546998134313695

Epoch: 6| Step: 2
Training loss: 2.96115345029003
Validation loss: 2.547594456128396

Epoch: 6| Step: 3
Training loss: 2.892397115686071
Validation loss: 2.5464522051528053

Epoch: 6| Step: 4
Training loss: 3.093942347240309
Validation loss: 2.548532774977967

Epoch: 6| Step: 5
Training loss: 2.4683500521254844
Validation loss: 2.542499696886003

Epoch: 6| Step: 6
Training loss: 2.875942241677642
Validation loss: 2.541903893891593

Epoch: 6| Step: 7
Training loss: 2.7742800010508955
Validation loss: 2.5433814576432625

Epoch: 6| Step: 8
Training loss: 2.9296064441912124
Validation loss: 2.5475956244407576

Epoch: 6| Step: 9
Training loss: 2.855592320556403
Validation loss: 2.553448939319883

Epoch: 6| Step: 10
Training loss: 2.4554287729094866
Validation loss: 2.5764196857082617

Epoch: 6| Step: 11
Training loss: 3.31498783184137
Validation loss: 2.594296498255516

Epoch: 6| Step: 12
Training loss: 3.050198507884364
Validation loss: 2.6041274722851697

Epoch: 6| Step: 13
Training loss: 2.65088030031104
Validation loss: 2.5826523849601335

Epoch: 95| Step: 0
Training loss: 2.3956318203863582
Validation loss: 2.545290707547449

Epoch: 6| Step: 1
Training loss: 2.966414325854822
Validation loss: 2.536225735882325

Epoch: 6| Step: 2
Training loss: 3.3800632502489645
Validation loss: 2.53739084247117

Epoch: 6| Step: 3
Training loss: 3.0396881636246964
Validation loss: 2.546161387816015

Epoch: 6| Step: 4
Training loss: 3.030857021381513
Validation loss: 2.5885077670480174

Epoch: 6| Step: 5
Training loss: 2.919760198805764
Validation loss: 2.6097212997560315

Epoch: 6| Step: 6
Training loss: 3.4023465529910957
Validation loss: 2.554881728958212

Epoch: 6| Step: 7
Training loss: 3.3658420503381774
Validation loss: 2.5406458615441214

Epoch: 6| Step: 8
Training loss: 2.313839704772637
Validation loss: 2.5432365725946138

Epoch: 6| Step: 9
Training loss: 2.9885751617104064
Validation loss: 2.5384179374201574

Epoch: 6| Step: 10
Training loss: 2.4029949019080736
Validation loss: 2.5488109265711656

Epoch: 6| Step: 11
Training loss: 2.4672964138466456
Validation loss: 2.572427489321514

Epoch: 6| Step: 12
Training loss: 2.7496439096347114
Validation loss: 2.588539036545418

Epoch: 6| Step: 13
Training loss: 3.1992045904086073
Validation loss: 2.565244137272497

Epoch: 96| Step: 0
Training loss: 2.548769380908297
Validation loss: 2.562215023366785

Epoch: 6| Step: 1
Training loss: 2.3376746209346195
Validation loss: 2.586838722351316

Epoch: 6| Step: 2
Training loss: 3.5035328065346905
Validation loss: 2.639190276299065

Epoch: 6| Step: 3
Training loss: 3.1036423788719887
Validation loss: 2.6012506470215215

Epoch: 6| Step: 4
Training loss: 3.6740494153931147
Validation loss: 2.581329464296953

Epoch: 6| Step: 5
Training loss: 2.6153572629128314
Validation loss: 2.5607707594041313

Epoch: 6| Step: 6
Training loss: 2.9483406831323746
Validation loss: 2.560161177532546

Epoch: 6| Step: 7
Training loss: 3.030439917478125
Validation loss: 2.566166675754661

Epoch: 6| Step: 8
Training loss: 2.8462084529023954
Validation loss: 2.5732531972417934

Epoch: 6| Step: 9
Training loss: 3.275345785508522
Validation loss: 2.583742503954908

Epoch: 6| Step: 10
Training loss: 3.2792666299230615
Validation loss: 2.5958149322308963

Epoch: 6| Step: 11
Training loss: 2.680707464926415
Validation loss: 2.6067578825160185

Epoch: 6| Step: 12
Training loss: 2.26384502074548
Validation loss: 2.6481651828977557

Epoch: 6| Step: 13
Training loss: 2.3241355560543924
Validation loss: 2.6645593629426387

Epoch: 97| Step: 0
Training loss: 3.7262731795692132
Validation loss: 2.6390936267086462

Epoch: 6| Step: 1
Training loss: 2.6079644142367613
Validation loss: 2.5727331235444546

Epoch: 6| Step: 2
Training loss: 2.8961439080496003
Validation loss: 2.5482229116878146

Epoch: 6| Step: 3
Training loss: 2.8280230761966445
Validation loss: 2.537825804260682

Epoch: 6| Step: 4
Training loss: 2.5418935163811653
Validation loss: 2.537539934730824

Epoch: 6| Step: 5
Training loss: 2.9661349373679555
Validation loss: 2.551829737874927

Epoch: 6| Step: 6
Training loss: 2.9030471709200514
Validation loss: 2.549498432350631

Epoch: 6| Step: 7
Training loss: 3.2610283583525446
Validation loss: 2.5400040156092323

Epoch: 6| Step: 8
Training loss: 3.0287534520235435
Validation loss: 2.531197367467458

Epoch: 6| Step: 9
Training loss: 2.9283310661965722
Validation loss: 2.52957633656932

Epoch: 6| Step: 10
Training loss: 2.4459126378924796
Validation loss: 2.5277345898491608

Epoch: 6| Step: 11
Training loss: 2.8413558775092307
Validation loss: 2.529551116332112

Epoch: 6| Step: 12
Training loss: 2.730215167275125
Validation loss: 2.5256016731924262

Epoch: 6| Step: 13
Training loss: 3.1890430081644183
Validation loss: 2.527540445332888

Epoch: 98| Step: 0
Training loss: 3.212226553237067
Validation loss: 2.534547006354755

Epoch: 6| Step: 1
Training loss: 3.0712038255759615
Validation loss: 2.532865354477601

Epoch: 6| Step: 2
Training loss: 3.066563304596635
Validation loss: 2.5501854763341703

Epoch: 6| Step: 3
Training loss: 2.9056971854837226
Validation loss: 2.5597193047272238

Epoch: 6| Step: 4
Training loss: 2.745753043298008
Validation loss: 2.5701268843444223

Epoch: 6| Step: 5
Training loss: 2.7473096692402863
Validation loss: 2.568644735871493

Epoch: 6| Step: 6
Training loss: 2.645320892771314
Validation loss: 2.5369867146467215

Epoch: 6| Step: 7
Training loss: 3.1278197727429435
Validation loss: 2.515916242270672

Epoch: 6| Step: 8
Training loss: 3.4070450441133278
Validation loss: 2.52284085597028

Epoch: 6| Step: 9
Training loss: 2.8716474141962416
Validation loss: 2.523385242970148

Epoch: 6| Step: 10
Training loss: 2.584305631543801
Validation loss: 2.525524356816329

Epoch: 6| Step: 11
Training loss: 2.4214903495260724
Validation loss: 2.527845397411996

Epoch: 6| Step: 12
Training loss: 2.718630470191447
Validation loss: 2.5326507745680016

Epoch: 6| Step: 13
Training loss: 3.0516579671166624
Validation loss: 2.5354443994089424

Epoch: 99| Step: 0
Training loss: 2.9881922091513804
Validation loss: 2.5381699935029935

Epoch: 6| Step: 1
Training loss: 2.9992870437307126
Validation loss: 2.5380837507007725

Epoch: 6| Step: 2
Training loss: 2.602000156739778
Validation loss: 2.5369988811113946

Epoch: 6| Step: 3
Training loss: 3.017249583904969
Validation loss: 2.536555359095539

Epoch: 6| Step: 4
Training loss: 2.836151199065805
Validation loss: 2.5249765200291305

Epoch: 6| Step: 5
Training loss: 2.700572578329265
Validation loss: 2.522455940224005

Epoch: 6| Step: 6
Training loss: 2.6032590174436843
Validation loss: 2.5151494929043574

Epoch: 6| Step: 7
Training loss: 2.8558765125451813
Validation loss: 2.5152874618682715

Epoch: 6| Step: 8
Training loss: 3.4408352017615074
Validation loss: 2.5161226188427004

Epoch: 6| Step: 9
Training loss: 2.934735884732179
Validation loss: 2.5148318286181435

Epoch: 6| Step: 10
Training loss: 2.608944337677289
Validation loss: 2.5196815068804903

Epoch: 6| Step: 11
Training loss: 3.0548451570768393
Validation loss: 2.5188397662403785

Epoch: 6| Step: 12
Training loss: 2.825255482016763
Validation loss: 2.5162260865668418

Epoch: 6| Step: 13
Training loss: 3.1449035045090556
Validation loss: 2.5142033826932746

Epoch: 100| Step: 0
Training loss: 2.393610866078789
Validation loss: 2.519407909872337

Epoch: 6| Step: 1
Training loss: 2.7894411658102936
Validation loss: 2.5280554131881656

Epoch: 6| Step: 2
Training loss: 3.3957753244761775
Validation loss: 2.526785430325939

Epoch: 6| Step: 3
Training loss: 2.676574589423086
Validation loss: 2.50580230405692

Epoch: 6| Step: 4
Training loss: 2.541393911599698
Validation loss: 2.4998746225235466

Epoch: 6| Step: 5
Training loss: 3.1262390731992733
Validation loss: 2.4985773478895377

Epoch: 6| Step: 6
Training loss: 2.648328570711124
Validation loss: 2.4989714762779225

Epoch: 6| Step: 7
Training loss: 2.9483562092372506
Validation loss: 2.501096835560257

Epoch: 6| Step: 8
Training loss: 2.9170203039948928
Validation loss: 2.5038693786090223

Epoch: 6| Step: 9
Training loss: 2.896498697442253
Validation loss: 2.503426854981708

Epoch: 6| Step: 10
Training loss: 2.9811887658826146
Validation loss: 2.500122655915495

Epoch: 6| Step: 11
Training loss: 2.620477413476834
Validation loss: 2.499733458430633

Epoch: 6| Step: 12
Training loss: 3.1377927240850836
Validation loss: 2.498782383337115

Epoch: 6| Step: 13
Training loss: 3.4656528702243867
Validation loss: 2.496390158649159

Epoch: 101| Step: 0
Training loss: 2.9166990732481675
Validation loss: 2.495545130246803

Epoch: 6| Step: 1
Training loss: 2.8566654896446244
Validation loss: 2.5068893657980813

Epoch: 6| Step: 2
Training loss: 2.5902191396376515
Validation loss: 2.5249282851097132

Epoch: 6| Step: 3
Training loss: 2.9147401896094967
Validation loss: 2.5385977583037764

Epoch: 6| Step: 4
Training loss: 3.2931611897450552
Validation loss: 2.524410240008753

Epoch: 6| Step: 5
Training loss: 3.22253965224677
Validation loss: 2.5275912614013625

Epoch: 6| Step: 6
Training loss: 2.5287636684589505
Validation loss: 2.5376765509955583

Epoch: 6| Step: 7
Training loss: 2.707610537596429
Validation loss: 2.540081660313149

Epoch: 6| Step: 8
Training loss: 2.629529949869973
Validation loss: 2.533894362715371

Epoch: 6| Step: 9
Training loss: 2.5943543063381274
Validation loss: 2.533050684577993

Epoch: 6| Step: 10
Training loss: 2.714031904945259
Validation loss: 2.5580002930071664

Epoch: 6| Step: 11
Training loss: 3.4268314226473358
Validation loss: 2.5889155640124866

Epoch: 6| Step: 12
Training loss: 2.813596469345893
Validation loss: 2.5933439517856267

Epoch: 6| Step: 13
Training loss: 3.071252111264203
Validation loss: 2.584920009547179

Epoch: 102| Step: 0
Training loss: 2.579459197710836
Validation loss: 2.579672650744496

Epoch: 6| Step: 1
Training loss: 2.9611951569953137
Validation loss: 2.5863245950763885

Epoch: 6| Step: 2
Training loss: 2.79180978057086
Validation loss: 2.5467804489134775

Epoch: 6| Step: 3
Training loss: 2.735580440208007
Validation loss: 2.5199256170519355

Epoch: 6| Step: 4
Training loss: 2.2788424394348836
Validation loss: 2.512218133976858

Epoch: 6| Step: 5
Training loss: 3.4837714386695415
Validation loss: 2.5054725533392173

Epoch: 6| Step: 6
Training loss: 3.0173804357271043
Validation loss: 2.5116581907674442

Epoch: 6| Step: 7
Training loss: 3.1069820531566794
Validation loss: 2.517729701996216

Epoch: 6| Step: 8
Training loss: 2.8073634396202958
Validation loss: 2.4987554887833014

Epoch: 6| Step: 9
Training loss: 2.450919940053381
Validation loss: 2.4963167868807608

Epoch: 6| Step: 10
Training loss: 2.927265926290718
Validation loss: 2.4985460339744807

Epoch: 6| Step: 11
Training loss: 3.443387624848666
Validation loss: 2.494170185717307

Epoch: 6| Step: 12
Training loss: 2.5150445303946736
Validation loss: 2.497477351818703

Epoch: 6| Step: 13
Training loss: 2.8670459681199723
Validation loss: 2.4978549368516108

Epoch: 103| Step: 0
Training loss: 2.828434205407877
Validation loss: 2.5010137122979033

Epoch: 6| Step: 1
Training loss: 3.009807608656322
Validation loss: 2.5020342784679213

Epoch: 6| Step: 2
Training loss: 3.0409481994170973
Validation loss: 2.499335581155255

Epoch: 6| Step: 3
Training loss: 2.9045497063369448
Validation loss: 2.501681744553967

Epoch: 6| Step: 4
Training loss: 2.6012504321734515
Validation loss: 2.4989706206952653

Epoch: 6| Step: 5
Training loss: 2.6910064356006456
Validation loss: 2.501302266111162

Epoch: 6| Step: 6
Training loss: 3.03893697523544
Validation loss: 2.4990605691433734

Epoch: 6| Step: 7
Training loss: 3.0920272808771396
Validation loss: 2.501314581547988

Epoch: 6| Step: 8
Training loss: 3.019533145010725
Validation loss: 2.496581725759082

Epoch: 6| Step: 9
Training loss: 2.1105758074765344
Validation loss: 2.495775587295973

Epoch: 6| Step: 10
Training loss: 3.0017301021172824
Validation loss: 2.5010318877395377

Epoch: 6| Step: 11
Training loss: 2.8121508911476494
Validation loss: 2.511953830347348

Epoch: 6| Step: 12
Training loss: 2.8361848245179093
Validation loss: 2.5135691853863826

Epoch: 6| Step: 13
Training loss: 3.3379946224290467
Validation loss: 2.5093253068837535

Epoch: 104| Step: 0
Training loss: 2.981804344732993
Validation loss: 2.5017964948068148

Epoch: 6| Step: 1
Training loss: 2.462464068000556
Validation loss: 2.513006615900042

Epoch: 6| Step: 2
Training loss: 3.0126560598131684
Validation loss: 2.5326780724050213

Epoch: 6| Step: 3
Training loss: 3.5742941259555474
Validation loss: 2.547665626606308

Epoch: 6| Step: 4
Training loss: 2.8372347468276145
Validation loss: 2.5507229107025533

Epoch: 6| Step: 5
Training loss: 2.7551055677511025
Validation loss: 2.5366528457037196

Epoch: 6| Step: 6
Training loss: 3.0149231721569274
Validation loss: 2.531671076563255

Epoch: 6| Step: 7
Training loss: 2.4773251294916245
Validation loss: 2.5220719507035154

Epoch: 6| Step: 8
Training loss: 2.80392437171979
Validation loss: 2.514195557785796

Epoch: 6| Step: 9
Training loss: 2.899255518884415
Validation loss: 2.5090764707675075

Epoch: 6| Step: 10
Training loss: 3.0741691149106147
Validation loss: 2.5198907085570847

Epoch: 6| Step: 11
Training loss: 2.8690440640128827
Validation loss: 2.511650713134014

Epoch: 6| Step: 12
Training loss: 2.538828395908406
Validation loss: 2.4992013896519505

Epoch: 6| Step: 13
Training loss: 2.480784478706536
Validation loss: 2.496204961799854

Epoch: 105| Step: 0
Training loss: 3.3048537192240066
Validation loss: 2.4993284184803644

Epoch: 6| Step: 1
Training loss: 2.9816644152623377
Validation loss: 2.501523178371689

Epoch: 6| Step: 2
Training loss: 2.9967646637176952
Validation loss: 2.500541541194564

Epoch: 6| Step: 3
Training loss: 2.989115360508479
Validation loss: 2.498627543320744

Epoch: 6| Step: 4
Training loss: 2.9422371186029452
Validation loss: 2.5075552315836553

Epoch: 6| Step: 5
Training loss: 2.29863189144928
Validation loss: 2.5061881122502645

Epoch: 6| Step: 6
Training loss: 2.918988275706317
Validation loss: 2.5090402199540196

Epoch: 6| Step: 7
Training loss: 2.5141816352227533
Validation loss: 2.5163962409259786

Epoch: 6| Step: 8
Training loss: 2.2350448991332046
Validation loss: 2.5174200030491294

Epoch: 6| Step: 9
Training loss: 2.945009251371143
Validation loss: 2.5167227288629754

Epoch: 6| Step: 10
Training loss: 2.918927506270965
Validation loss: 2.5101229390686575

Epoch: 6| Step: 11
Training loss: 2.9556831703584265
Validation loss: 2.5052324451262358

Epoch: 6| Step: 12
Training loss: 2.6474404948088006
Validation loss: 2.511854780440557

Epoch: 6| Step: 13
Training loss: 3.4724885880768177
Validation loss: 2.5108949133122875

Epoch: 106| Step: 0
Training loss: 3.087231791966567
Validation loss: 2.5163957325573896

Epoch: 6| Step: 1
Training loss: 2.73736321791241
Validation loss: 2.5233510091879423

Epoch: 6| Step: 2
Training loss: 2.854997796961374
Validation loss: 2.5112846595345766

Epoch: 6| Step: 3
Training loss: 2.9488156478967555
Validation loss: 2.5113983243352886

Epoch: 6| Step: 4
Training loss: 3.0174649806862663
Validation loss: 2.5166920206799848

Epoch: 6| Step: 5
Training loss: 2.129277132258042
Validation loss: 2.5192122271190582

Epoch: 6| Step: 6
Training loss: 2.8074405515088556
Validation loss: 2.523157731389732

Epoch: 6| Step: 7
Training loss: 3.127722660374824
Validation loss: 2.5273873144296837

Epoch: 6| Step: 8
Training loss: 2.7125366946783975
Validation loss: 2.5207899844670445

Epoch: 6| Step: 9
Training loss: 3.0141348047517416
Validation loss: 2.5167975775980267

Epoch: 6| Step: 10
Training loss: 2.9663644943935386
Validation loss: 2.5186315765710696

Epoch: 6| Step: 11
Training loss: 2.877587356633357
Validation loss: 2.5044642909577695

Epoch: 6| Step: 12
Training loss: 2.5627044037962263
Validation loss: 2.50792868041628

Epoch: 6| Step: 13
Training loss: 2.841605415318029
Validation loss: 2.500972823093494

Epoch: 107| Step: 0
Training loss: 2.6995673610071282
Validation loss: 2.4959736158877797

Epoch: 6| Step: 1
Training loss: 3.4716454870414566
Validation loss: 2.4928192233993247

Epoch: 6| Step: 2
Training loss: 3.2786349093634204
Validation loss: 2.4953934385183874

Epoch: 6| Step: 3
Training loss: 3.280024999197617
Validation loss: 2.4959132477669366

Epoch: 6| Step: 4
Training loss: 2.2568039274896186
Validation loss: 2.4960275591467878

Epoch: 6| Step: 5
Training loss: 3.070635208370695
Validation loss: 2.505639502929199

Epoch: 6| Step: 6
Training loss: 2.979489786902917
Validation loss: 2.4976284776701463

Epoch: 6| Step: 7
Training loss: 2.6306454940436255
Validation loss: 2.4929645499744484

Epoch: 6| Step: 8
Training loss: 2.450977138367531
Validation loss: 2.492663116132039

Epoch: 6| Step: 9
Training loss: 2.001434169589141
Validation loss: 2.4956229357380892

Epoch: 6| Step: 10
Training loss: 3.2091503506700283
Validation loss: 2.5067601143016276

Epoch: 6| Step: 11
Training loss: 2.956111628901117
Validation loss: 2.514278705104324

Epoch: 6| Step: 12
Training loss: 2.708589884026571
Validation loss: 2.5070250774526097

Epoch: 6| Step: 13
Training loss: 2.331066449586737
Validation loss: 2.5081607665077947

Epoch: 108| Step: 0
Training loss: 2.7460541593429877
Validation loss: 2.5087453610936272

Epoch: 6| Step: 1
Training loss: 3.3439661829575478
Validation loss: 2.5197879681777144

Epoch: 6| Step: 2
Training loss: 2.659390287433798
Validation loss: 2.5224236889061276

Epoch: 6| Step: 3
Training loss: 3.507309501624507
Validation loss: 2.523364021656076

Epoch: 6| Step: 4
Training loss: 2.443937750040745
Validation loss: 2.5487808705319535

Epoch: 6| Step: 5
Training loss: 2.6030261988396703
Validation loss: 2.5689389207578044

Epoch: 6| Step: 6
Training loss: 2.7879184973254674
Validation loss: 2.603532857900715

Epoch: 6| Step: 7
Training loss: 2.6213969070969307
Validation loss: 2.652864110483504

Epoch: 6| Step: 8
Training loss: 2.5380416930842054
Validation loss: 2.6331171011891037

Epoch: 6| Step: 9
Training loss: 3.1172563358823466
Validation loss: 2.672929629655533

Epoch: 6| Step: 10
Training loss: 2.6757718051270354
Validation loss: 2.590275144397447

Epoch: 6| Step: 11
Training loss: 3.4708104243138775
Validation loss: 2.5413183043815573

Epoch: 6| Step: 12
Training loss: 2.5530076409661495
Validation loss: 2.503314585584054

Epoch: 6| Step: 13
Training loss: 2.811868215172445
Validation loss: 2.4918279165644464

Epoch: 109| Step: 0
Training loss: 3.1766546908696913
Validation loss: 2.496551581066413

Epoch: 6| Step: 1
Training loss: 2.712029229020679
Validation loss: 2.5129911197922836

Epoch: 6| Step: 2
Training loss: 2.3343396287559295
Validation loss: 2.5482725728689433

Epoch: 6| Step: 3
Training loss: 2.7517189375658706
Validation loss: 2.557928350715335

Epoch: 6| Step: 4
Training loss: 3.1787617903478376
Validation loss: 2.5531378246123895

Epoch: 6| Step: 5
Training loss: 3.3506190966280363
Validation loss: 2.52993355217401

Epoch: 6| Step: 6
Training loss: 3.302073930953606
Validation loss: 2.521330315023479

Epoch: 6| Step: 7
Training loss: 2.6446736915802154
Validation loss: 2.517515274964279

Epoch: 6| Step: 8
Training loss: 3.1791790829903923
Validation loss: 2.526973567099398

Epoch: 6| Step: 9
Training loss: 2.8052254588589696
Validation loss: 2.5259093225940368

Epoch: 6| Step: 10
Training loss: 2.7294517445852176
Validation loss: 2.5282199629797075

Epoch: 6| Step: 11
Training loss: 2.71168265971239
Validation loss: 2.520535888724011

Epoch: 6| Step: 12
Training loss: 2.4092291682697393
Validation loss: 2.531899221464022

Epoch: 6| Step: 13
Training loss: 2.8433854424850904
Validation loss: 2.5321418915699234

Epoch: 110| Step: 0
Training loss: 3.0133148990618626
Validation loss: 2.540359847665765

Epoch: 6| Step: 1
Training loss: 2.8144689661410105
Validation loss: 2.529599744494567

Epoch: 6| Step: 2
Training loss: 3.0251251951430147
Validation loss: 2.516265121215731

Epoch: 6| Step: 3
Training loss: 2.9901396514022043
Validation loss: 2.5259860517348143

Epoch: 6| Step: 4
Training loss: 2.691488455747465
Validation loss: 2.5417216678466676

Epoch: 6| Step: 5
Training loss: 2.7247226048940476
Validation loss: 2.5563400727253667

Epoch: 6| Step: 6
Training loss: 2.7869736999978993
Validation loss: 2.595138400596412

Epoch: 6| Step: 7
Training loss: 2.635204643395507
Validation loss: 2.605287410307463

Epoch: 6| Step: 8
Training loss: 3.0457292016246136
Validation loss: 2.5979437965680177

Epoch: 6| Step: 9
Training loss: 2.4228194825440705
Validation loss: 2.5926510909076796

Epoch: 6| Step: 10
Training loss: 3.5245995476699967
Validation loss: 2.5660304009088275

Epoch: 6| Step: 11
Training loss: 2.9546248245248887
Validation loss: 2.5346967624972647

Epoch: 6| Step: 12
Training loss: 2.875755045055576
Validation loss: 2.5252067834571412

Epoch: 6| Step: 13
Training loss: 2.4255175362705796
Validation loss: 2.516338458422187

Epoch: 111| Step: 0
Training loss: 2.4221591905778475
Validation loss: 2.5163462583277285

Epoch: 6| Step: 1
Training loss: 2.5965101883260644
Validation loss: 2.5174495281966967

Epoch: 6| Step: 2
Training loss: 2.886187307041191
Validation loss: 2.518060179040385

Epoch: 6| Step: 3
Training loss: 2.845872694630413
Validation loss: 2.519953372688839

Epoch: 6| Step: 4
Training loss: 3.4531332853053884
Validation loss: 2.5149647844994747

Epoch: 6| Step: 5
Training loss: 3.45020940946738
Validation loss: 2.5072417871194372

Epoch: 6| Step: 6
Training loss: 2.971075171373184
Validation loss: 2.5034207106589137

Epoch: 6| Step: 7
Training loss: 2.776171902481708
Validation loss: 2.5009349264352423

Epoch: 6| Step: 8
Training loss: 3.0220483550691206
Validation loss: 2.5008196891843864

Epoch: 6| Step: 9
Training loss: 2.9986518373757356
Validation loss: 2.5071995649035093

Epoch: 6| Step: 10
Training loss: 2.5655338656818962
Validation loss: 2.5111536904722014

Epoch: 6| Step: 11
Training loss: 2.4644273989681977
Validation loss: 2.5184499147534307

Epoch: 6| Step: 12
Training loss: 2.9374441587943685
Validation loss: 2.522062846058181

Epoch: 6| Step: 13
Training loss: 2.556447207578181
Validation loss: 2.5193988240913403

Epoch: 112| Step: 0
Training loss: 2.8881951094048746
Validation loss: 2.5424824606906085

Epoch: 6| Step: 1
Training loss: 3.1336155953664653
Validation loss: 2.5582427990821808

Epoch: 6| Step: 2
Training loss: 3.2372264731784615
Validation loss: 2.6668436167315686

Epoch: 6| Step: 3
Training loss: 3.343779234000783
Validation loss: 2.7114001463844675

Epoch: 6| Step: 4
Training loss: 2.76584783830907
Validation loss: 2.631555106492739

Epoch: 6| Step: 5
Training loss: 2.950953093623584
Validation loss: 2.561650762490265

Epoch: 6| Step: 6
Training loss: 2.6669195969158075
Validation loss: 2.496249116904236

Epoch: 6| Step: 7
Training loss: 3.489117461274317
Validation loss: 2.4973701385822435

Epoch: 6| Step: 8
Training loss: 3.4231987052032453
Validation loss: 2.49951656343415

Epoch: 6| Step: 9
Training loss: 2.464160467799464
Validation loss: 2.4979193612392505

Epoch: 6| Step: 10
Training loss: 2.29227833532127
Validation loss: 2.4970416079656728

Epoch: 6| Step: 11
Training loss: 2.652689353663062
Validation loss: 2.5006320605568795

Epoch: 6| Step: 12
Training loss: 2.141500920315335
Validation loss: 2.504299980935038

Epoch: 6| Step: 13
Training loss: 3.251199940930764
Validation loss: 2.507826676684997

Epoch: 113| Step: 0
Training loss: 3.6937031699373164
Validation loss: 2.4935385388090423

Epoch: 6| Step: 1
Training loss: 3.193289342456458
Validation loss: 2.4790247921993336

Epoch: 6| Step: 2
Training loss: 2.5685256265999628
Validation loss: 2.4774133140715064

Epoch: 6| Step: 3
Training loss: 2.6890967305391396
Validation loss: 2.477975856299255

Epoch: 6| Step: 4
Training loss: 2.9122498629970552
Validation loss: 2.479742465355468

Epoch: 6| Step: 5
Training loss: 2.8176375196282084
Validation loss: 2.5019407399553937

Epoch: 6| Step: 6
Training loss: 2.595169414363079
Validation loss: 2.509394423307558

Epoch: 6| Step: 7
Training loss: 2.5289720245660288
Validation loss: 2.532940436704383

Epoch: 6| Step: 8
Training loss: 2.6041992388913497
Validation loss: 2.5621364669788664

Epoch: 6| Step: 9
Training loss: 2.8498432986363
Validation loss: 2.5612417043483515

Epoch: 6| Step: 10
Training loss: 2.795141951175589
Validation loss: 2.5621411412171278

Epoch: 6| Step: 11
Training loss: 2.2673356536895235
Validation loss: 2.5407134357657712

Epoch: 6| Step: 12
Training loss: 2.9144070909906534
Validation loss: 2.5521695438679997

Epoch: 6| Step: 13
Training loss: 2.8097158426801214
Validation loss: 2.55847635821008

Epoch: 114| Step: 0
Training loss: 2.716803369027555
Validation loss: 2.5261580106893775

Epoch: 6| Step: 1
Training loss: 2.879561413112206
Validation loss: 2.4990349475888043

Epoch: 6| Step: 2
Training loss: 3.1261902640460963
Validation loss: 2.49670748319837

Epoch: 6| Step: 3
Training loss: 2.5020112530449916
Validation loss: 2.4868561772531117

Epoch: 6| Step: 4
Training loss: 2.6720002797520657
Validation loss: 2.4832897956991977

Epoch: 6| Step: 5
Training loss: 2.3960032084957796
Validation loss: 2.479671711371332

Epoch: 6| Step: 6
Training loss: 2.550789381776615
Validation loss: 2.4809285345026693

Epoch: 6| Step: 7
Training loss: 2.9249003857987543
Validation loss: 2.474004894567561

Epoch: 6| Step: 8
Training loss: 3.2144865669590463
Validation loss: 2.477792285661999

Epoch: 6| Step: 9
Training loss: 3.3515636381845386
Validation loss: 2.4765094619288353

Epoch: 6| Step: 10
Training loss: 2.9145741358719377
Validation loss: 2.4895950459898857

Epoch: 6| Step: 11
Training loss: 2.1120932689720777
Validation loss: 2.4897404866237007

Epoch: 6| Step: 12
Training loss: 2.9570077066227554
Validation loss: 2.505370410725293

Epoch: 6| Step: 13
Training loss: 3.0069734269982877
Validation loss: 2.526592217392741

Epoch: 115| Step: 0
Training loss: 3.191131019630539
Validation loss: 2.5110477176367927

Epoch: 6| Step: 1
Training loss: 2.4722724604651516
Validation loss: 2.4862951843880587

Epoch: 6| Step: 2
Training loss: 2.334483226631711
Validation loss: 2.4866758251222225

Epoch: 6| Step: 3
Training loss: 2.800277430550287
Validation loss: 2.4728171783448754

Epoch: 6| Step: 4
Training loss: 2.4521317141504615
Validation loss: 2.4706709732271723

Epoch: 6| Step: 5
Training loss: 3.1047866168084863
Validation loss: 2.468179537419095

Epoch: 6| Step: 6
Training loss: 3.20244222667794
Validation loss: 2.4761789323186827

Epoch: 6| Step: 7
Training loss: 3.017850538876967
Validation loss: 2.4759115197690287

Epoch: 6| Step: 8
Training loss: 2.494563390260132
Validation loss: 2.4788773018724912

Epoch: 6| Step: 9
Training loss: 2.7609944344712822
Validation loss: 2.4779624171924635

Epoch: 6| Step: 10
Training loss: 2.783924231556002
Validation loss: 2.4871234350500675

Epoch: 6| Step: 11
Training loss: 2.962950975561618
Validation loss: 2.4871259016703053

Epoch: 6| Step: 12
Training loss: 2.8774600906322148
Validation loss: 2.495650389998817

Epoch: 6| Step: 13
Training loss: 2.8533503532199154
Validation loss: 2.513432039060364

Epoch: 116| Step: 0
Training loss: 1.8184415837602768
Validation loss: 2.535165001724705

Epoch: 6| Step: 1
Training loss: 2.359543345931701
Validation loss: 2.554038266439745

Epoch: 6| Step: 2
Training loss: 2.9200051592428538
Validation loss: 2.5748164480983844

Epoch: 6| Step: 3
Training loss: 2.510534407728788
Validation loss: 2.5961860813551287

Epoch: 6| Step: 4
Training loss: 2.448168467023057
Validation loss: 2.5832755101851577

Epoch: 6| Step: 5
Training loss: 2.9232781452927283
Validation loss: 2.5505954774219135

Epoch: 6| Step: 6
Training loss: 3.4282469624303027
Validation loss: 2.510531454551546

Epoch: 6| Step: 7
Training loss: 2.8973126555101536
Validation loss: 2.5037077009989397

Epoch: 6| Step: 8
Training loss: 2.973179133341203
Validation loss: 2.4969195994894733

Epoch: 6| Step: 9
Training loss: 2.382124104102255
Validation loss: 2.4908193728490007

Epoch: 6| Step: 10
Training loss: 3.4422492771085587
Validation loss: 2.4958965855222686

Epoch: 6| Step: 11
Training loss: 3.170275656089814
Validation loss: 2.47600771066698

Epoch: 6| Step: 12
Training loss: 2.760091299399001
Validation loss: 2.472125234088266

Epoch: 6| Step: 13
Training loss: 2.9398375605128506
Validation loss: 2.466423629141394

Epoch: 117| Step: 0
Training loss: 3.4019134634809123
Validation loss: 2.4657143948327422

Epoch: 6| Step: 1
Training loss: 2.4538236947247207
Validation loss: 2.4683181833648113

Epoch: 6| Step: 2
Training loss: 2.9696172150310205
Validation loss: 2.4706917869459795

Epoch: 6| Step: 3
Training loss: 2.0390373608438948
Validation loss: 2.4733640575957843

Epoch: 6| Step: 4
Training loss: 2.4113970117757213
Validation loss: 2.477142723556402

Epoch: 6| Step: 5
Training loss: 3.2179450352575887
Validation loss: 2.487039831360407

Epoch: 6| Step: 6
Training loss: 3.232176249872785
Validation loss: 2.4872621185986206

Epoch: 6| Step: 7
Training loss: 3.0009992842554234
Validation loss: 2.496088834994568

Epoch: 6| Step: 8
Training loss: 2.4654476435588495
Validation loss: 2.502500730246039

Epoch: 6| Step: 9
Training loss: 2.7958205808830976
Validation loss: 2.499276310761776

Epoch: 6| Step: 10
Training loss: 2.8838305652808467
Validation loss: 2.4994811339965577

Epoch: 6| Step: 11
Training loss: 2.836865654169603
Validation loss: 2.493236786716552

Epoch: 6| Step: 12
Training loss: 2.7874499021398926
Validation loss: 2.493894669371983

Epoch: 6| Step: 13
Training loss: 2.128740048701647
Validation loss: 2.487779084432083

Epoch: 118| Step: 0
Training loss: 2.944401040946902
Validation loss: 2.4657981154349318

Epoch: 6| Step: 1
Training loss: 3.0449647833129716
Validation loss: 2.4621955168007528

Epoch: 6| Step: 2
Training loss: 2.8858003510424384
Validation loss: 2.469675099743789

Epoch: 6| Step: 3
Training loss: 3.384079764073148
Validation loss: 2.483534200293678

Epoch: 6| Step: 4
Training loss: 2.618861514245902
Validation loss: 2.490044682399963

Epoch: 6| Step: 5
Training loss: 2.828837268138946
Validation loss: 2.49149481405409

Epoch: 6| Step: 6
Training loss: 2.757571461115592
Validation loss: 2.497883550959852

Epoch: 6| Step: 7
Training loss: 2.1164169880146453
Validation loss: 2.494576143874285

Epoch: 6| Step: 8
Training loss: 2.3784784643334174
Validation loss: 2.4952577240436074

Epoch: 6| Step: 9
Training loss: 3.305934084706517
Validation loss: 2.496909036557991

Epoch: 6| Step: 10
Training loss: 3.191018649485193
Validation loss: 2.498699407772596

Epoch: 6| Step: 11
Training loss: 2.414768547829668
Validation loss: 2.500843602047617

Epoch: 6| Step: 12
Training loss: 2.4586438343921495
Validation loss: 2.507547959479714

Epoch: 6| Step: 13
Training loss: 3.4531178193859167
Validation loss: 2.5029589165214996

Epoch: 119| Step: 0
Training loss: 2.928999919314398
Validation loss: 2.5136429561705014

Epoch: 6| Step: 1
Training loss: 2.810007813738076
Validation loss: 2.523744644251754

Epoch: 6| Step: 2
Training loss: 1.8934729068088008
Validation loss: 2.5421934874574315

Epoch: 6| Step: 3
Training loss: 2.912304222501388
Validation loss: 2.5555948592452915

Epoch: 6| Step: 4
Training loss: 3.096066465024155
Validation loss: 2.546844157108867

Epoch: 6| Step: 5
Training loss: 2.558968692708778
Validation loss: 2.5554753925251714

Epoch: 6| Step: 6
Training loss: 2.815628515785385
Validation loss: 2.5497036502115398

Epoch: 6| Step: 7
Training loss: 2.618466284047702
Validation loss: 2.5424990858470267

Epoch: 6| Step: 8
Training loss: 2.7130180532190136
Validation loss: 2.5231120049069284

Epoch: 6| Step: 9
Training loss: 2.763297615725409
Validation loss: 2.5014178982544424

Epoch: 6| Step: 10
Training loss: 2.9651742381577306
Validation loss: 2.493289602626707

Epoch: 6| Step: 11
Training loss: 2.9677229861621544
Validation loss: 2.475334483859179

Epoch: 6| Step: 12
Training loss: 3.0093977280627007
Validation loss: 2.4642700445000147

Epoch: 6| Step: 13
Training loss: 2.6020062958731343
Validation loss: 2.46718348747149

Epoch: 120| Step: 0
Training loss: 2.8084237971766903
Validation loss: 2.4678350996095686

Epoch: 6| Step: 1
Training loss: 2.91050752913447
Validation loss: 2.4667429836404637

Epoch: 6| Step: 2
Training loss: 2.5403076874608432
Validation loss: 2.466756559219223

Epoch: 6| Step: 3
Training loss: 2.9110591025555936
Validation loss: 2.4696478414979732

Epoch: 6| Step: 4
Training loss: 2.744228375209537
Validation loss: 2.4641710712360023

Epoch: 6| Step: 5
Training loss: 2.836229041380632
Validation loss: 2.458704729705322

Epoch: 6| Step: 6
Training loss: 2.3920744447510316
Validation loss: 2.4686396906341495

Epoch: 6| Step: 7
Training loss: 2.617311935882759
Validation loss: 2.4851058738274614

Epoch: 6| Step: 8
Training loss: 2.510276558370734
Validation loss: 2.510823310109508

Epoch: 6| Step: 9
Training loss: 3.12162201460638
Validation loss: 2.545693894760416

Epoch: 6| Step: 10
Training loss: 3.7841229834461267
Validation loss: 2.5810092944397462

Epoch: 6| Step: 11
Training loss: 2.7096992765005092
Validation loss: 2.5641423276609627

Epoch: 6| Step: 12
Training loss: 2.4935214977695432
Validation loss: 2.560660872535835

Epoch: 6| Step: 13
Training loss: 3.3305443222058666
Validation loss: 2.5410540841265443

Epoch: 121| Step: 0
Training loss: 2.852141689895206
Validation loss: 2.5105011383320117

Epoch: 6| Step: 1
Training loss: 2.775787990829224
Validation loss: 2.49647098360868

Epoch: 6| Step: 2
Training loss: 3.2532207962281365
Validation loss: 2.4858314783655375

Epoch: 6| Step: 3
Training loss: 2.1593351545397828
Validation loss: 2.474569868703226

Epoch: 6| Step: 4
Training loss: 3.5950470283838434
Validation loss: 2.480657023211847

Epoch: 6| Step: 5
Training loss: 2.4449774661907755
Validation loss: 2.4857734133751763

Epoch: 6| Step: 6
Training loss: 2.4472046377950507
Validation loss: 2.4953934816670564

Epoch: 6| Step: 7
Training loss: 2.5857583528450334
Validation loss: 2.5209074267979577

Epoch: 6| Step: 8
Training loss: 2.502474704427853
Validation loss: 2.527986700484325

Epoch: 6| Step: 9
Training loss: 2.419265424040026
Validation loss: 2.5464534947991675

Epoch: 6| Step: 10
Training loss: 2.6602704307933833
Validation loss: 2.548151154133928

Epoch: 6| Step: 11
Training loss: 2.7692002285593706
Validation loss: 2.5364671673182593

Epoch: 6| Step: 12
Training loss: 3.100688205744519
Validation loss: 2.504143833838929

Epoch: 6| Step: 13
Training loss: 3.4505680335313373
Validation loss: 2.496446869689256

Epoch: 122| Step: 0
Training loss: 2.3950977246569165
Validation loss: 2.4859357809351113

Epoch: 6| Step: 1
Training loss: 2.4954422412410424
Validation loss: 2.4789018695520957

Epoch: 6| Step: 2
Training loss: 3.201584757350037
Validation loss: 2.477594169720301

Epoch: 6| Step: 3
Training loss: 2.614100488909978
Validation loss: 2.472045129301135

Epoch: 6| Step: 4
Training loss: 2.9357174273683926
Validation loss: 2.4736713222645665

Epoch: 6| Step: 5
Training loss: 3.000026543817711
Validation loss: 2.4827097871857355

Epoch: 6| Step: 6
Training loss: 3.0003334495878655
Validation loss: 2.4929719479149317

Epoch: 6| Step: 7
Training loss: 2.061587507516346
Validation loss: 2.493636447219846

Epoch: 6| Step: 8
Training loss: 3.381116622578777
Validation loss: 2.492099100631335

Epoch: 6| Step: 9
Training loss: 2.9670970933107013
Validation loss: 2.4956796672940125

Epoch: 6| Step: 10
Training loss: 2.3083212961188315
Validation loss: 2.5012535459520326

Epoch: 6| Step: 11
Training loss: 2.885050248843942
Validation loss: 2.50324437240832

Epoch: 6| Step: 12
Training loss: 2.853013262696832
Validation loss: 2.50910345801829

Epoch: 6| Step: 13
Training loss: 1.203309131750549
Validation loss: 2.5053809349130316

Epoch: 123| Step: 0
Training loss: 2.789261498284187
Validation loss: 2.5008939764874953

Epoch: 6| Step: 1
Training loss: 2.426927575173837
Validation loss: 2.4951219199901726

Epoch: 6| Step: 2
Training loss: 2.9307047387630343
Validation loss: 2.481180754606848

Epoch: 6| Step: 3
Training loss: 2.3763985782348716
Validation loss: 2.4854733508077334

Epoch: 6| Step: 4
Training loss: 2.6513546881899206
Validation loss: 2.4778078891259834

Epoch: 6| Step: 5
Training loss: 2.848265699101083
Validation loss: 2.48434153094623

Epoch: 6| Step: 6
Training loss: 2.105273292542207
Validation loss: 2.4910796746122417

Epoch: 6| Step: 7
Training loss: 2.6947218980421868
Validation loss: 2.495748518586459

Epoch: 6| Step: 8
Training loss: 3.1309836512296862
Validation loss: 2.5020946464485343

Epoch: 6| Step: 9
Training loss: 2.9928895609752018
Validation loss: 2.5036713591393194

Epoch: 6| Step: 10
Training loss: 3.071090327930315
Validation loss: 2.498734748774624

Epoch: 6| Step: 11
Training loss: 2.9750812679699004
Validation loss: 2.5179072993450506

Epoch: 6| Step: 12
Training loss: 2.7431534590062956
Validation loss: 2.495162465329454

Epoch: 6| Step: 13
Training loss: 2.4232787955267567
Validation loss: 2.4945406134379358

Epoch: 124| Step: 0
Training loss: 2.7750718150425944
Validation loss: 2.488749544973034

Epoch: 6| Step: 1
Training loss: 2.386892658896498
Validation loss: 2.4847154910899745

Epoch: 6| Step: 2
Training loss: 2.6162695342390383
Validation loss: 2.48875573993774

Epoch: 6| Step: 3
Training loss: 2.9684618358295207
Validation loss: 2.4958880951506486

Epoch: 6| Step: 4
Training loss: 2.8607611292961184
Validation loss: 2.509943070891426

Epoch: 6| Step: 5
Training loss: 3.0376293264730028
Validation loss: 2.5322997796349798

Epoch: 6| Step: 6
Training loss: 2.670339756754542
Validation loss: 2.527479929457621

Epoch: 6| Step: 7
Training loss: 2.4832094925418793
Validation loss: 2.5323150563493764

Epoch: 6| Step: 8
Training loss: 2.732496564606429
Validation loss: 2.552274067431217

Epoch: 6| Step: 9
Training loss: 2.783671492937128
Validation loss: 2.5284621771013005

Epoch: 6| Step: 10
Training loss: 3.4865135848780313
Validation loss: 2.501803936823966

Epoch: 6| Step: 11
Training loss: 2.0933081317202618
Validation loss: 2.4759385930891695

Epoch: 6| Step: 12
Training loss: 2.819061931935236
Validation loss: 2.4680987223728894

Epoch: 6| Step: 13
Training loss: 2.399301578305584
Validation loss: 2.4788242419689688

Epoch: 125| Step: 0
Training loss: 3.03929674672623
Validation loss: 2.4798506991495675

Epoch: 6| Step: 1
Training loss: 2.5741898530718754
Validation loss: 2.4799264374589094

Epoch: 6| Step: 2
Training loss: 3.0990604330388516
Validation loss: 2.4752037342765414

Epoch: 6| Step: 3
Training loss: 2.567566491801008
Validation loss: 2.47175488689192

Epoch: 6| Step: 4
Training loss: 2.1803170118904425
Validation loss: 2.476277866157348

Epoch: 6| Step: 5
Training loss: 2.310019322434237
Validation loss: 2.4764014672072654

Epoch: 6| Step: 6
Training loss: 2.3182308222441175
Validation loss: 2.478347564072609

Epoch: 6| Step: 7
Training loss: 2.6858192333482966
Validation loss: 2.473694197970643

Epoch: 6| Step: 8
Training loss: 2.988968115760637
Validation loss: 2.4774916155226965

Epoch: 6| Step: 9
Training loss: 2.763634520369239
Validation loss: 2.4864090636133285

Epoch: 6| Step: 10
Training loss: 2.825694604736517
Validation loss: 2.5004265790442175

Epoch: 6| Step: 11
Training loss: 3.1438612324809565
Validation loss: 2.512656305036946

Epoch: 6| Step: 12
Training loss: 3.215454191930028
Validation loss: 2.5268438043533696

Epoch: 6| Step: 13
Training loss: 2.4898471665875133
Validation loss: 2.513508164844523

Epoch: 126| Step: 0
Training loss: 2.730088017760013
Validation loss: 2.492667939673122

Epoch: 6| Step: 1
Training loss: 2.9434646759738863
Validation loss: 2.485090752556711

Epoch: 6| Step: 2
Training loss: 2.6703601134258985
Validation loss: 2.4802757326966223

Epoch: 6| Step: 3
Training loss: 3.0182496345271446
Validation loss: 2.4694552875066367

Epoch: 6| Step: 4
Training loss: 2.748565039351118
Validation loss: 2.4681826762981585

Epoch: 6| Step: 5
Training loss: 2.138072921979545
Validation loss: 2.4737906896053685

Epoch: 6| Step: 6
Training loss: 2.7888074058324954
Validation loss: 2.4686402046832376

Epoch: 6| Step: 7
Training loss: 2.6875521632610266
Validation loss: 2.4656014095168586

Epoch: 6| Step: 8
Training loss: 2.5685455834946254
Validation loss: 2.4727412285045434

Epoch: 6| Step: 9
Training loss: 2.7608514311435544
Validation loss: 2.4692756536625726

Epoch: 6| Step: 10
Training loss: 2.7243863140938056
Validation loss: 2.4718100380198464

Epoch: 6| Step: 11
Training loss: 3.1117719296626363
Validation loss: 2.473953935568527

Epoch: 6| Step: 12
Training loss: 2.2629110984988943
Validation loss: 2.4776464447554094

Epoch: 6| Step: 13
Training loss: 2.972211085107522
Validation loss: 2.486474245435327

Epoch: 127| Step: 0
Training loss: 2.492216773743139
Validation loss: 2.4935385418933826

Epoch: 6| Step: 1
Training loss: 3.3065125676621014
Validation loss: 2.5040473232100453

Epoch: 6| Step: 2
Training loss: 2.9451580462444453
Validation loss: 2.5144160723789515

Epoch: 6| Step: 3
Training loss: 3.044588297054229
Validation loss: 2.5269494814962963

Epoch: 6| Step: 4
Training loss: 2.852686997351514
Validation loss: 2.5271106703849964

Epoch: 6| Step: 5
Training loss: 3.030003871600507
Validation loss: 2.5312008140825877

Epoch: 6| Step: 6
Training loss: 2.033288842115751
Validation loss: 2.5173376214432306

Epoch: 6| Step: 7
Training loss: 2.203772591720127
Validation loss: 2.510454753439933

Epoch: 6| Step: 8
Training loss: 2.2413305047081855
Validation loss: 2.4851119128192822

Epoch: 6| Step: 9
Training loss: 2.9034753495646877
Validation loss: 2.480521533918953

Epoch: 6| Step: 10
Training loss: 3.0225551214626796
Validation loss: 2.479993603858877

Epoch: 6| Step: 11
Training loss: 2.3885657722819453
Validation loss: 2.478003790578946

Epoch: 6| Step: 12
Training loss: 2.478044613933046
Validation loss: 2.4671308868292265

Epoch: 6| Step: 13
Training loss: 2.8587097061046363
Validation loss: 2.4659647200633388

Epoch: 128| Step: 0
Training loss: 2.48953555605279
Validation loss: 2.4672069553443405

Epoch: 6| Step: 1
Training loss: 1.9565497318052878
Validation loss: 2.4634004210860243

Epoch: 6| Step: 2
Training loss: 2.9795454802571646
Validation loss: 2.4673876499694254

Epoch: 6| Step: 3
Training loss: 3.1357359528219706
Validation loss: 2.4641409378811217

Epoch: 6| Step: 4
Training loss: 2.8669057598505496
Validation loss: 2.464292065991783

Epoch: 6| Step: 5
Training loss: 2.540578911657708
Validation loss: 2.4619473199572095

Epoch: 6| Step: 6
Training loss: 2.8239721504491597
Validation loss: 2.473332959305461

Epoch: 6| Step: 7
Training loss: 2.920524407419163
Validation loss: 2.474875333531425

Epoch: 6| Step: 8
Training loss: 3.2948078346076857
Validation loss: 2.4757290759549435

Epoch: 6| Step: 9
Training loss: 2.059993955362581
Validation loss: 2.4803722184201336

Epoch: 6| Step: 10
Training loss: 2.90913461251376
Validation loss: 2.497732157258788

Epoch: 6| Step: 11
Training loss: 2.323051300480798
Validation loss: 2.5036759822807473

Epoch: 6| Step: 12
Training loss: 2.789931901763821
Validation loss: 2.5247840936867814

Epoch: 6| Step: 13
Training loss: 2.886533904190544
Validation loss: 2.5228146772073354

Epoch: 129| Step: 0
Training loss: 3.023421728600661
Validation loss: 2.5227525886963975

Epoch: 6| Step: 1
Training loss: 2.9621012874081862
Validation loss: 2.518663335964354

Epoch: 6| Step: 2
Training loss: 2.742096989107891
Validation loss: 2.509235515928742

Epoch: 6| Step: 3
Training loss: 3.183401577069898
Validation loss: 2.5119901707666394

Epoch: 6| Step: 4
Training loss: 2.183307663084745
Validation loss: 2.5157692068625175

Epoch: 6| Step: 5
Training loss: 2.817562548426287
Validation loss: 2.530550849156477

Epoch: 6| Step: 6
Training loss: 2.857659831278683
Validation loss: 2.515733732190681

Epoch: 6| Step: 7
Training loss: 2.5873154026102476
Validation loss: 2.513161546220301

Epoch: 6| Step: 8
Training loss: 2.6691720240222887
Validation loss: 2.4960692950433807

Epoch: 6| Step: 9
Training loss: 2.5657010437711367
Validation loss: 2.4838577694855863

Epoch: 6| Step: 10
Training loss: 2.0948683755172275
Validation loss: 2.473741199612665

Epoch: 6| Step: 11
Training loss: 2.663977568494734
Validation loss: 2.4726900358473647

Epoch: 6| Step: 12
Training loss: 2.7674928381464503
Validation loss: 2.4793452409429757

Epoch: 6| Step: 13
Training loss: 2.8334028198098906
Validation loss: 2.4724405558761684

Epoch: 130| Step: 0
Training loss: 2.5814607252509543
Validation loss: 2.4806633959870936

Epoch: 6| Step: 1
Training loss: 2.69952823614681
Validation loss: 2.473253166246267

Epoch: 6| Step: 2
Training loss: 2.7499533562605905
Validation loss: 2.4898982510256293

Epoch: 6| Step: 3
Training loss: 3.30516622335974
Validation loss: 2.4767892799101965

Epoch: 6| Step: 4
Training loss: 2.873531795943766
Validation loss: 2.470984983484465

Epoch: 6| Step: 5
Training loss: 2.5764126726568204
Validation loss: 2.468246048186957

Epoch: 6| Step: 6
Training loss: 2.454320142660875
Validation loss: 2.4730005854449066

Epoch: 6| Step: 7
Training loss: 2.7905446450005003
Validation loss: 2.4723265371897574

Epoch: 6| Step: 8
Training loss: 3.081857190456853
Validation loss: 2.47899890875652

Epoch: 6| Step: 9
Training loss: 2.7899730061691614
Validation loss: 2.4797802666694575

Epoch: 6| Step: 10
Training loss: 2.418077506483624
Validation loss: 2.4865803737337933

Epoch: 6| Step: 11
Training loss: 2.3845074738065217
Validation loss: 2.4982560874088593

Epoch: 6| Step: 12
Training loss: 2.5918371661690203
Validation loss: 2.5121842904059517

Epoch: 6| Step: 13
Training loss: 2.2305797008169823
Validation loss: 2.5065919741959264

Epoch: 131| Step: 0
Training loss: 2.355065964505893
Validation loss: 2.5030332652887255

Epoch: 6| Step: 1
Training loss: 2.234550629228929
Validation loss: 2.48884928213345

Epoch: 6| Step: 2
Training loss: 2.633820021195969
Validation loss: 2.4857268042607568

Epoch: 6| Step: 3
Training loss: 3.2364395113224687
Validation loss: 2.472838409421582

Epoch: 6| Step: 4
Training loss: 2.964084372190898
Validation loss: 2.462831225954073

Epoch: 6| Step: 5
Training loss: 2.637263669820303
Validation loss: 2.469632911566559

Epoch: 6| Step: 6
Training loss: 1.957381653015613
Validation loss: 2.456118781471525

Epoch: 6| Step: 7
Training loss: 3.1815276199045988
Validation loss: 2.457410627395807

Epoch: 6| Step: 8
Training loss: 3.0896259911118067
Validation loss: 2.4652132240666242

Epoch: 6| Step: 9
Training loss: 2.9844476980572074
Validation loss: 2.4610394617051092

Epoch: 6| Step: 10
Training loss: 2.6031084479164077
Validation loss: 2.4631557526987207

Epoch: 6| Step: 11
Training loss: 1.7676734856441574
Validation loss: 2.468894360289556

Epoch: 6| Step: 12
Training loss: 3.2278255179707114
Validation loss: 2.4710284194899605

Epoch: 6| Step: 13
Training loss: 2.184519890385358
Validation loss: 2.4798697414569197

Epoch: 132| Step: 0
Training loss: 2.9916354235307847
Validation loss: 2.48925765389824

Epoch: 6| Step: 1
Training loss: 2.404087730006564
Validation loss: 2.51948816126343

Epoch: 6| Step: 2
Training loss: 2.724360847760185
Validation loss: 2.532393215194724

Epoch: 6| Step: 3
Training loss: 2.6025973258018604
Validation loss: 2.5507293169746035

Epoch: 6| Step: 4
Training loss: 3.31402610316382
Validation loss: 2.5412835333850303

Epoch: 6| Step: 5
Training loss: 2.6639772105058412
Validation loss: 2.5307767246581756

Epoch: 6| Step: 6
Training loss: 2.4777904077767765
Validation loss: 2.525104205567149

Epoch: 6| Step: 7
Training loss: 2.1614948560700724
Validation loss: 2.5245982153812476

Epoch: 6| Step: 8
Training loss: 2.702958294794057
Validation loss: 2.5183709414303044

Epoch: 6| Step: 9
Training loss: 2.6491006116700686
Validation loss: 2.535437335709012

Epoch: 6| Step: 10
Training loss: 3.2295209792808643
Validation loss: 2.525799011679775

Epoch: 6| Step: 11
Training loss: 2.2914530799052435
Validation loss: 2.5171798703800303

Epoch: 6| Step: 12
Training loss: 2.8071810123148238
Validation loss: 2.5010497206904763

Epoch: 6| Step: 13
Training loss: 2.707664250598609
Validation loss: 2.495288915868996

Epoch: 133| Step: 0
Training loss: 2.864841259990907
Validation loss: 2.483316654375875

Epoch: 6| Step: 1
Training loss: 3.0679201701693977
Validation loss: 2.469085780598505

Epoch: 6| Step: 2
Training loss: 2.873912107882391
Validation loss: 2.4680454042556446

Epoch: 6| Step: 3
Training loss: 2.7407318337995505
Validation loss: 2.4657259845103883

Epoch: 6| Step: 4
Training loss: 2.9232044153557033
Validation loss: 2.4577663748812633

Epoch: 6| Step: 5
Training loss: 2.596418088523375
Validation loss: 2.45833106081694

Epoch: 6| Step: 6
Training loss: 2.4314974700581975
Validation loss: 2.4561370141029206

Epoch: 6| Step: 7
Training loss: 2.9135620669288445
Validation loss: 2.451589813704559

Epoch: 6| Step: 8
Training loss: 2.239650127982106
Validation loss: 2.4594880522884113

Epoch: 6| Step: 9
Training loss: 2.2942585477525297
Validation loss: 2.472251710865255

Epoch: 6| Step: 10
Training loss: 2.13836617571178
Validation loss: 2.482645552576746

Epoch: 6| Step: 11
Training loss: 2.3881204487952656
Validation loss: 2.50327963695573

Epoch: 6| Step: 12
Training loss: 2.9746930516997976
Validation loss: 2.5219741002190577

Epoch: 6| Step: 13
Training loss: 3.2099818828701343
Validation loss: 2.5455266636059815

Epoch: 134| Step: 0
Training loss: 2.2144916126663428
Validation loss: 2.555894709765928

Epoch: 6| Step: 1
Training loss: 2.8390544649807183
Validation loss: 2.5835084316628794

Epoch: 6| Step: 2
Training loss: 2.16351498725272
Validation loss: 2.562960985658944

Epoch: 6| Step: 3
Training loss: 2.8744818178996274
Validation loss: 2.545809135914801

Epoch: 6| Step: 4
Training loss: 2.704103325884221
Validation loss: 2.5107832453637795

Epoch: 6| Step: 5
Training loss: 2.884014757666216
Validation loss: 2.4782984061012656

Epoch: 6| Step: 6
Training loss: 2.911272528672995
Validation loss: 2.465421528149043

Epoch: 6| Step: 7
Training loss: 2.937285070469851
Validation loss: 2.4621037160342265

Epoch: 6| Step: 8
Training loss: 2.6933570734557786
Validation loss: 2.45778883014961

Epoch: 6| Step: 9
Training loss: 2.107456606489463
Validation loss: 2.4612715841227373

Epoch: 6| Step: 10
Training loss: 2.8096671354590845
Validation loss: 2.4548755850377835

Epoch: 6| Step: 11
Training loss: 3.4296460681402623
Validation loss: 2.4555204374522193

Epoch: 6| Step: 12
Training loss: 2.7188734706158635
Validation loss: 2.451578341766947

Epoch: 6| Step: 13
Training loss: 2.4689730772804004
Validation loss: 2.456612674294407

Epoch: 135| Step: 0
Training loss: 2.0073567032650343
Validation loss: 2.4578463025189796

Epoch: 6| Step: 1
Training loss: 2.875784393781391
Validation loss: 2.4565823407366616

Epoch: 6| Step: 2
Training loss: 3.6302726809227437
Validation loss: 2.4601040346957537

Epoch: 6| Step: 3
Training loss: 2.704731810948904
Validation loss: 2.473010483376976

Epoch: 6| Step: 4
Training loss: 2.2842961706083895
Validation loss: 2.4812058930658556

Epoch: 6| Step: 5
Training loss: 2.532465513395609
Validation loss: 2.4892499771490155

Epoch: 6| Step: 6
Training loss: 2.2756916420054383
Validation loss: 2.4958386653303792

Epoch: 6| Step: 7
Training loss: 3.1150392094527835
Validation loss: 2.501197429730014

Epoch: 6| Step: 8
Training loss: 2.6683306469527506
Validation loss: 2.5035805482618305

Epoch: 6| Step: 9
Training loss: 2.8298036430364015
Validation loss: 2.501771693900685

Epoch: 6| Step: 10
Training loss: 2.2103050594455387
Validation loss: 2.501755758272909

Epoch: 6| Step: 11
Training loss: 2.6647185918873677
Validation loss: 2.492501650679163

Epoch: 6| Step: 12
Training loss: 2.8036012378944064
Validation loss: 2.48973848698071

Epoch: 6| Step: 13
Training loss: 2.6922391757001836
Validation loss: 2.495922328653721

Epoch: 136| Step: 0
Training loss: 2.7093282974952295
Validation loss: 2.4997790813254266

Epoch: 6| Step: 1
Training loss: 2.4361118374162163
Validation loss: 2.5175762370778445

Epoch: 6| Step: 2
Training loss: 3.0871054455166056
Validation loss: 2.5175789859694233

Epoch: 6| Step: 3
Training loss: 2.857449242649186
Validation loss: 2.505855048482034

Epoch: 6| Step: 4
Training loss: 2.46833691581485
Validation loss: 2.4922052733115807

Epoch: 6| Step: 5
Training loss: 2.0717627861739607
Validation loss: 2.4752877708766676

Epoch: 6| Step: 6
Training loss: 2.766188569487867
Validation loss: 2.4720330932402654

Epoch: 6| Step: 7
Training loss: 2.7035000050345257
Validation loss: 2.4661407846615977

Epoch: 6| Step: 8
Training loss: 1.9861257444374676
Validation loss: 2.462786070936773

Epoch: 6| Step: 9
Training loss: 2.295798536015029
Validation loss: 2.462065605317565

Epoch: 6| Step: 10
Training loss: 2.7948617348908305
Validation loss: 2.4668982650942715

Epoch: 6| Step: 11
Training loss: 3.1343588496787618
Validation loss: 2.46314318818726

Epoch: 6| Step: 12
Training loss: 3.4509687639191835
Validation loss: 2.4687940781296667

Epoch: 6| Step: 13
Training loss: 2.1828541057447133
Validation loss: 2.4680451933928014

Epoch: 137| Step: 0
Training loss: 2.470240372455924
Validation loss: 2.4676044122377183

Epoch: 6| Step: 1
Training loss: 3.07607855761236
Validation loss: 2.4703945063303947

Epoch: 6| Step: 2
Training loss: 2.3404301846234765
Validation loss: 2.4680918767403033

Epoch: 6| Step: 3
Training loss: 2.938733268115766
Validation loss: 2.474505796797352

Epoch: 6| Step: 4
Training loss: 2.993981682527069
Validation loss: 2.4865227427613856

Epoch: 6| Step: 5
Training loss: 2.3051140859178054
Validation loss: 2.485185585481061

Epoch: 6| Step: 6
Training loss: 3.1449406517263343
Validation loss: 2.474704702814695

Epoch: 6| Step: 7
Training loss: 2.157856218584317
Validation loss: 2.4704146919533647

Epoch: 6| Step: 8
Training loss: 2.8995074741815157
Validation loss: 2.469796305969993

Epoch: 6| Step: 9
Training loss: 2.7435551463390375
Validation loss: 2.4791151158415947

Epoch: 6| Step: 10
Training loss: 2.5236862579654784
Validation loss: 2.476375350332496

Epoch: 6| Step: 11
Training loss: 2.2906557338677223
Validation loss: 2.483252337389442

Epoch: 6| Step: 12
Training loss: 2.6135368735334206
Validation loss: 2.485349673822415

Epoch: 6| Step: 13
Training loss: 2.533477368359301
Validation loss: 2.4763928986086228

Epoch: 138| Step: 0
Training loss: 2.185853938263627
Validation loss: 2.4741271642169127

Epoch: 6| Step: 1
Training loss: 2.374847005634447
Validation loss: 2.476776494740656

Epoch: 6| Step: 2
Training loss: 2.4939738122992243
Validation loss: 2.492762034910732

Epoch: 6| Step: 3
Training loss: 2.8974926994699133
Validation loss: 2.4843603412208353

Epoch: 6| Step: 4
Training loss: 2.0565241158460545
Validation loss: 2.4875155093436705

Epoch: 6| Step: 5
Training loss: 3.064306543757692
Validation loss: 2.4870329249908787

Epoch: 6| Step: 6
Training loss: 2.9255701862392254
Validation loss: 2.4899371501526995

Epoch: 6| Step: 7
Training loss: 3.08101166273446
Validation loss: 2.486172517575844

Epoch: 6| Step: 8
Training loss: 3.0121870456081394
Validation loss: 2.483874566158548

Epoch: 6| Step: 9
Training loss: 2.497224029476241
Validation loss: 2.4714596002520803

Epoch: 6| Step: 10
Training loss: 2.347344452373443
Validation loss: 2.466302617340669

Epoch: 6| Step: 11
Training loss: 3.172994181303357
Validation loss: 2.459200536303731

Epoch: 6| Step: 12
Training loss: 2.274660391139638
Validation loss: 2.4568956024889395

Epoch: 6| Step: 13
Training loss: 2.671548209924661
Validation loss: 2.470189481871133

Epoch: 139| Step: 0
Training loss: 2.7236779812048804
Validation loss: 2.4812021352285565

Epoch: 6| Step: 1
Training loss: 2.114727773258931
Validation loss: 2.504581752626633

Epoch: 6| Step: 2
Training loss: 2.959304399463922
Validation loss: 2.521992955603965

Epoch: 6| Step: 3
Training loss: 2.918190167668189
Validation loss: 2.546111755938746

Epoch: 6| Step: 4
Training loss: 3.0452726405565507
Validation loss: 2.556549712150835

Epoch: 6| Step: 5
Training loss: 2.893255572995401
Validation loss: 2.547561045790789

Epoch: 6| Step: 6
Training loss: 2.5383356080908133
Validation loss: 2.50885508016175

Epoch: 6| Step: 7
Training loss: 3.1344957657403745
Validation loss: 2.4743008954235965

Epoch: 6| Step: 8
Training loss: 2.5011374746897386
Validation loss: 2.4638875748678926

Epoch: 6| Step: 9
Training loss: 1.732544422653542
Validation loss: 2.4674616149492667

Epoch: 6| Step: 10
Training loss: 2.4139353894592213
Validation loss: 2.4598576002126977

Epoch: 6| Step: 11
Training loss: 3.0046514373059297
Validation loss: 2.4625698631249366

Epoch: 6| Step: 12
Training loss: 3.0140490589465077
Validation loss: 2.4691514539915698

Epoch: 6| Step: 13
Training loss: 2.0339172457699406
Validation loss: 2.463314901793037

Epoch: 140| Step: 0
Training loss: 2.888867312945792
Validation loss: 2.4596988579878034

Epoch: 6| Step: 1
Training loss: 3.0098987032552147
Validation loss: 2.46493284288944

Epoch: 6| Step: 2
Training loss: 2.770245931979889
Validation loss: 2.4808949693526565

Epoch: 6| Step: 3
Training loss: 1.885948197556491
Validation loss: 2.4788344191543694

Epoch: 6| Step: 4
Training loss: 2.9969983979438215
Validation loss: 2.4920499238204736

Epoch: 6| Step: 5
Training loss: 2.907972912102094
Validation loss: 2.5106831639214087

Epoch: 6| Step: 6
Training loss: 3.0660423500236704
Validation loss: 2.526747969511078

Epoch: 6| Step: 7
Training loss: 2.308250027288327
Validation loss: 2.5348060894835927

Epoch: 6| Step: 8
Training loss: 2.860055644421026
Validation loss: 2.5433668511739844

Epoch: 6| Step: 9
Training loss: 2.4850254766743256
Validation loss: 2.5559439029288953

Epoch: 6| Step: 10
Training loss: 2.9421910914451326
Validation loss: 2.544210097049105

Epoch: 6| Step: 11
Training loss: 2.180792634336665
Validation loss: 2.5403865520328637

Epoch: 6| Step: 12
Training loss: 2.6512050515860555
Validation loss: 2.5444091903008674

Epoch: 6| Step: 13
Training loss: 1.9468453737212126
Validation loss: 2.54532587804825

Epoch: 141| Step: 0
Training loss: 2.4806415647846047
Validation loss: 2.5341166300786973

Epoch: 6| Step: 1
Training loss: 2.5403184806724233
Validation loss: 2.5185869344135985

Epoch: 6| Step: 2
Training loss: 2.77421795246926
Validation loss: 2.4960957188752317

Epoch: 6| Step: 3
Training loss: 2.637533872847877
Validation loss: 2.4838241200636397

Epoch: 6| Step: 4
Training loss: 2.418878880105636
Validation loss: 2.4856579590001906

Epoch: 6| Step: 5
Training loss: 3.029056660063976
Validation loss: 2.4716954654250576

Epoch: 6| Step: 6
Training loss: 2.836455494887078
Validation loss: 2.4796019675487453

Epoch: 6| Step: 7
Training loss: 2.955851270307377
Validation loss: 2.50196701519468

Epoch: 6| Step: 8
Training loss: 2.441336913077902
Validation loss: 2.504709444089413

Epoch: 6| Step: 9
Training loss: 2.6384624225831415
Validation loss: 2.5185393263013705

Epoch: 6| Step: 10
Training loss: 2.8126168120815898
Validation loss: 2.5348425533515977

Epoch: 6| Step: 11
Training loss: 1.7650691144773443
Validation loss: 2.5551509988013454

Epoch: 6| Step: 12
Training loss: 2.5223293646724967
Validation loss: 2.533716476505766

Epoch: 6| Step: 13
Training loss: 3.3546611982077628
Validation loss: 2.5461489207837937

Epoch: 142| Step: 0
Training loss: 2.8296422102709333
Validation loss: 2.53554988694475

Epoch: 6| Step: 1
Training loss: 2.376135504471054
Validation loss: 2.5336815344051002

Epoch: 6| Step: 2
Training loss: 2.87383412480684
Validation loss: 2.511435877321476

Epoch: 6| Step: 3
Training loss: 2.389735835651459
Validation loss: 2.4897980070774546

Epoch: 6| Step: 4
Training loss: 2.9868198785766356
Validation loss: 2.49007916611244

Epoch: 6| Step: 5
Training loss: 2.8932410696879547
Validation loss: 2.485644017891551

Epoch: 6| Step: 6
Training loss: 2.128666799535527
Validation loss: 2.482766236599886

Epoch: 6| Step: 7
Training loss: 2.3708087680752987
Validation loss: 2.4876614229721965

Epoch: 6| Step: 8
Training loss: 2.865643077531243
Validation loss: 2.4852047560871084

Epoch: 6| Step: 9
Training loss: 1.7671959563979673
Validation loss: 2.4958622592220356

Epoch: 6| Step: 10
Training loss: 2.389395503605493
Validation loss: 2.499634991938372

Epoch: 6| Step: 11
Training loss: 2.578398996300758
Validation loss: 2.5169079153238196

Epoch: 6| Step: 12
Training loss: 2.9049044539846376
Validation loss: 2.524905486740725

Epoch: 6| Step: 13
Training loss: 3.6891169478176336
Validation loss: 2.5323680918509797

Epoch: 143| Step: 0
Training loss: 2.5690235744061387
Validation loss: 2.5364205083287983

Epoch: 6| Step: 1
Training loss: 2.4658840299626528
Validation loss: 2.526538630421289

Epoch: 6| Step: 2
Training loss: 2.7292446290351453
Validation loss: 2.532066486985697

Epoch: 6| Step: 3
Training loss: 2.31279123895174
Validation loss: 2.5266872307158135

Epoch: 6| Step: 4
Training loss: 2.360407925281236
Validation loss: 2.52543579251003

Epoch: 6| Step: 5
Training loss: 2.6656573491520583
Validation loss: 2.507910203824206

Epoch: 6| Step: 6
Training loss: 2.8263611746597466
Validation loss: 2.5149477887447005

Epoch: 6| Step: 7
Training loss: 3.191655610333475
Validation loss: 2.5199312043195383

Epoch: 6| Step: 8
Training loss: 2.6193592682905096
Validation loss: 2.509360286756504

Epoch: 6| Step: 9
Training loss: 2.329312834364348
Validation loss: 2.4849943159270342

Epoch: 6| Step: 10
Training loss: 2.59859684715341
Validation loss: 2.4687772588132297

Epoch: 6| Step: 11
Training loss: 2.8866330186969296
Validation loss: 2.454674580329468

Epoch: 6| Step: 12
Training loss: 2.975931576321647
Validation loss: 2.450005394270657

Epoch: 6| Step: 13
Training loss: 2.20240923570026
Validation loss: 2.455924908916716

Epoch: 144| Step: 0
Training loss: 3.1278505675581165
Validation loss: 2.459089083403827

Epoch: 6| Step: 1
Training loss: 2.4050275992160097
Validation loss: 2.4545922224320162

Epoch: 6| Step: 2
Training loss: 2.0457439063805527
Validation loss: 2.472883474185597

Epoch: 6| Step: 3
Training loss: 2.6033729462615725
Validation loss: 2.486386191471082

Epoch: 6| Step: 4
Training loss: 2.4932736508303304
Validation loss: 2.482621375621482

Epoch: 6| Step: 5
Training loss: 2.852018972989142
Validation loss: 2.4622357802379766

Epoch: 6| Step: 6
Training loss: 2.4323394139005483
Validation loss: 2.4565002461302607

Epoch: 6| Step: 7
Training loss: 2.4828536455743415
Validation loss: 2.4527645521637687

Epoch: 6| Step: 8
Training loss: 2.111425688657004
Validation loss: 2.446245057790932

Epoch: 6| Step: 9
Training loss: 2.230187393320609
Validation loss: 2.450163697279447

Epoch: 6| Step: 10
Training loss: 3.298461243197497
Validation loss: 2.44865783453471

Epoch: 6| Step: 11
Training loss: 3.1554576521298405
Validation loss: 2.455440991635617

Epoch: 6| Step: 12
Training loss: 2.5857508842690256
Validation loss: 2.464362231136067

Epoch: 6| Step: 13
Training loss: 3.017193006118341
Validation loss: 2.4834216349783462

Epoch: 145| Step: 0
Training loss: 2.563790345379004
Validation loss: 2.4982682639370384

Epoch: 6| Step: 1
Training loss: 2.3273220853895245
Validation loss: 2.521552746889046

Epoch: 6| Step: 2
Training loss: 2.444829338530065
Validation loss: 2.541740424143221

Epoch: 6| Step: 3
Training loss: 2.628677154126661
Validation loss: 2.550523145337641

Epoch: 6| Step: 4
Training loss: 3.0110730222363022
Validation loss: 2.555859866251017

Epoch: 6| Step: 5
Training loss: 2.2491245685984675
Validation loss: 2.545906827551333

Epoch: 6| Step: 6
Training loss: 2.6145030360157726
Validation loss: 2.5400851170772913

Epoch: 6| Step: 7
Training loss: 3.0715205410086206
Validation loss: 2.5412750140753304

Epoch: 6| Step: 8
Training loss: 2.918267782431144
Validation loss: 2.5405509186887247

Epoch: 6| Step: 9
Training loss: 2.2380128070372813
Validation loss: 2.541856794610886

Epoch: 6| Step: 10
Training loss: 2.37351140000776
Validation loss: 2.5296013569041826

Epoch: 6| Step: 11
Training loss: 2.9732663785412283
Validation loss: 2.513501522952482

Epoch: 6| Step: 12
Training loss: 2.592563771536751
Validation loss: 2.5152542059073832

Epoch: 6| Step: 13
Training loss: 2.270602946595654
Validation loss: 2.517714020109333

Epoch: 146| Step: 0
Training loss: 3.0526558053808635
Validation loss: 2.5018203230173626

Epoch: 6| Step: 1
Training loss: 2.723376054448164
Validation loss: 2.5042948000067247

Epoch: 6| Step: 2
Training loss: 2.4284192666702156
Validation loss: 2.4911609672190336

Epoch: 6| Step: 3
Training loss: 2.314048866989087
Validation loss: 2.49134065611566

Epoch: 6| Step: 4
Training loss: 3.3647316032942407
Validation loss: 2.492681060891807

Epoch: 6| Step: 5
Training loss: 1.9070136619922644
Validation loss: 2.5202309717532976

Epoch: 6| Step: 6
Training loss: 2.8109774388968876
Validation loss: 2.53499566168771

Epoch: 6| Step: 7
Training loss: 2.1922785201042987
Validation loss: 2.529236329184231

Epoch: 6| Step: 8
Training loss: 2.837575056116874
Validation loss: 2.5344566543980025

Epoch: 6| Step: 9
Training loss: 2.7611463242180188
Validation loss: 2.5508473718185614

Epoch: 6| Step: 10
Training loss: 1.656481240882206
Validation loss: 2.546347900701329

Epoch: 6| Step: 11
Training loss: 3.1973773281972258
Validation loss: 2.5317760383270667

Epoch: 6| Step: 12
Training loss: 2.713517689858282
Validation loss: 2.504984617824042

Epoch: 6| Step: 13
Training loss: 1.674336626582116
Validation loss: 2.4765545789362213

Epoch: 147| Step: 0
Training loss: 2.9889827927023602
Validation loss: 2.4600622529340685

Epoch: 6| Step: 1
Training loss: 2.8221933956209266
Validation loss: 2.4572439086208644

Epoch: 6| Step: 2
Training loss: 2.1144319176293074
Validation loss: 2.46051451835166

Epoch: 6| Step: 3
Training loss: 2.4044492845237815
Validation loss: 2.451880069170433

Epoch: 6| Step: 4
Training loss: 2.911669364655731
Validation loss: 2.45597131742934

Epoch: 6| Step: 5
Training loss: 2.0844227294947575
Validation loss: 2.451817876143725

Epoch: 6| Step: 6
Training loss: 2.7341828196973808
Validation loss: 2.4547207785413545

Epoch: 6| Step: 7
Training loss: 2.632915189194983
Validation loss: 2.4702113125618044

Epoch: 6| Step: 8
Training loss: 3.1634817838522693
Validation loss: 2.482420646065812

Epoch: 6| Step: 9
Training loss: 2.2706858969139363
Validation loss: 2.510257043071049

Epoch: 6| Step: 10
Training loss: 2.633677083125403
Validation loss: 2.5485883725184784

Epoch: 6| Step: 11
Training loss: 2.8934464165640503
Validation loss: 2.5589825113544413

Epoch: 6| Step: 12
Training loss: 2.2935145701645605
Validation loss: 2.581783731656617

Epoch: 6| Step: 13
Training loss: 2.049019192785852
Validation loss: 2.5847382001999812

Epoch: 148| Step: 0
Training loss: 2.615582147427258
Validation loss: 2.587393716201948

Epoch: 6| Step: 1
Training loss: 2.8210977322411144
Validation loss: 2.6258750429769253

Epoch: 6| Step: 2
Training loss: 2.9722750967042537
Validation loss: 2.6274489802463994

Epoch: 6| Step: 3
Training loss: 2.4107987646408295
Validation loss: 2.5530159474046017

Epoch: 6| Step: 4
Training loss: 3.3405583916528077
Validation loss: 2.5008114359285023

Epoch: 6| Step: 5
Training loss: 2.22114455265282
Validation loss: 2.4730002817058954

Epoch: 6| Step: 6
Training loss: 1.7761803476850095
Validation loss: 2.4538224316175414

Epoch: 6| Step: 7
Training loss: 2.334810629441712
Validation loss: 2.450658948220317

Epoch: 6| Step: 8
Training loss: 2.6612726633263484
Validation loss: 2.4450326965416993

Epoch: 6| Step: 9
Training loss: 2.652949897370658
Validation loss: 2.4615320058268435

Epoch: 6| Step: 10
Training loss: 2.6816235546616185
Validation loss: 2.4613013328502524

Epoch: 6| Step: 11
Training loss: 2.617972003020631
Validation loss: 2.4619792399458955

Epoch: 6| Step: 12
Training loss: 2.74261306112358
Validation loss: 2.457733732599382

Epoch: 6| Step: 13
Training loss: 2.4159835529588616
Validation loss: 2.455354357748339

Epoch: 149| Step: 0
Training loss: 2.738167710065851
Validation loss: 2.4666663302338474

Epoch: 6| Step: 1
Training loss: 2.4719570913078344
Validation loss: 2.477101534495735

Epoch: 6| Step: 2
Training loss: 2.6295815403988145
Validation loss: 2.4764499728671865

Epoch: 6| Step: 3
Training loss: 2.302660655361532
Validation loss: 2.4808768561558145

Epoch: 6| Step: 4
Training loss: 2.5236350534306764
Validation loss: 2.4803529980605377

Epoch: 6| Step: 5
Training loss: 3.3471394410368
Validation loss: 2.4858714564296087

Epoch: 6| Step: 6
Training loss: 2.820223397408706
Validation loss: 2.4781767544979285

Epoch: 6| Step: 7
Training loss: 2.595135238445726
Validation loss: 2.4760996114646185

Epoch: 6| Step: 8
Training loss: 2.130670498904592
Validation loss: 2.4742136391647866

Epoch: 6| Step: 9
Training loss: 2.3763506211153054
Validation loss: 2.4857060885890725

Epoch: 6| Step: 10
Training loss: 2.381240376130128
Validation loss: 2.5061526472150257

Epoch: 6| Step: 11
Training loss: 3.004738244765368
Validation loss: 2.548228614981052

Epoch: 6| Step: 12
Training loss: 2.4872570475107403
Validation loss: 2.5937681804108284

Epoch: 6| Step: 13
Training loss: 1.3094485096110156
Validation loss: 2.626118721897013

Epoch: 150| Step: 0
Training loss: 2.4984279458231273
Validation loss: 2.6497871158631146

Epoch: 6| Step: 1
Training loss: 2.4819772533754603
Validation loss: 2.647155420422978

Epoch: 6| Step: 2
Training loss: 2.843924883820248
Validation loss: 2.648154761476191

Epoch: 6| Step: 3
Training loss: 2.61877994201586
Validation loss: 2.6144333417955172

Epoch: 6| Step: 4
Training loss: 2.5654353565375603
Validation loss: 2.586991587782207

Epoch: 6| Step: 5
Training loss: 2.6192553194266357
Validation loss: 2.547217816018893

Epoch: 6| Step: 6
Training loss: 2.2570550301349805
Validation loss: 2.4901428609910914

Epoch: 6| Step: 7
Training loss: 2.2379891569473185
Validation loss: 2.4636339974511645

Epoch: 6| Step: 8
Training loss: 2.2679042532354097
Validation loss: 2.454545944511511

Epoch: 6| Step: 9
Training loss: 2.5970036884468217
Validation loss: 2.4459585938802717

Epoch: 6| Step: 10
Training loss: 2.9100264757138325
Validation loss: 2.4377829043337513

Epoch: 6| Step: 11
Training loss: 2.7880688347767912
Validation loss: 2.43891335049647

Epoch: 6| Step: 12
Training loss: 2.321960172464417
Validation loss: 2.4416618975274593

Epoch: 6| Step: 13
Training loss: 3.3229787376290663
Validation loss: 2.466224281849656

Testing loss: 2.655472358116818
