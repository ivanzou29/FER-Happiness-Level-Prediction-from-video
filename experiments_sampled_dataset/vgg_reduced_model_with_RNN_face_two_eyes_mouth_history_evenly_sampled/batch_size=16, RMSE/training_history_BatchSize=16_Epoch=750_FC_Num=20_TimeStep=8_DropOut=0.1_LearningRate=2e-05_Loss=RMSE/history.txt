Epoch: 1| Step: 0
Training loss: 6.715142279485986
Validation loss: 5.789076957891058

Epoch: 6| Step: 1
Training loss: 4.534325128408547
Validation loss: 5.769813744576502

Epoch: 6| Step: 2
Training loss: 6.171714915843197
Validation loss: 5.75355340804632

Epoch: 6| Step: 3
Training loss: 6.2924122484383425
Validation loss: 5.737129323596834

Epoch: 6| Step: 4
Training loss: 5.561712316398688
Validation loss: 5.718061978105936

Epoch: 6| Step: 5
Training loss: 5.3843557861127005
Validation loss: 5.696530058896737

Epoch: 6| Step: 6
Training loss: 4.884851136921453
Validation loss: 5.671588386605659

Epoch: 6| Step: 7
Training loss: 5.388921407664829
Validation loss: 5.643085865441852

Epoch: 6| Step: 8
Training loss: 5.9048030635026265
Validation loss: 5.6096389090981384

Epoch: 6| Step: 9
Training loss: 4.790240443173805
Validation loss: 5.572339725464275

Epoch: 6| Step: 10
Training loss: 5.388554714542768
Validation loss: 5.530082900700913

Epoch: 6| Step: 11
Training loss: 6.067062705950029
Validation loss: 5.482077111422233

Epoch: 6| Step: 12
Training loss: 6.040691989896263
Validation loss: 5.430458915978033

Epoch: 6| Step: 13
Training loss: 5.942997686065681
Validation loss: 5.37290425329244

Epoch: 2| Step: 0
Training loss: 4.591990854181094
Validation loss: 5.313116002425889

Epoch: 6| Step: 1
Training loss: 5.243363500089173
Validation loss: 5.2514891224095

Epoch: 6| Step: 2
Training loss: 4.11406089588544
Validation loss: 5.1885862906944045

Epoch: 6| Step: 3
Training loss: 5.201434803131773
Validation loss: 5.127139597543361

Epoch: 6| Step: 4
Training loss: 4.491078752437515
Validation loss: 5.067610465963006

Epoch: 6| Step: 5
Training loss: 5.534315046678195
Validation loss: 5.008756220409373

Epoch: 6| Step: 6
Training loss: 6.088033802354688
Validation loss: 4.952116787325532

Epoch: 6| Step: 7
Training loss: 4.580962151491588
Validation loss: 4.899195675258866

Epoch: 6| Step: 8
Training loss: 5.495558419146942
Validation loss: 4.84802630206608

Epoch: 6| Step: 9
Training loss: 4.152499004917382
Validation loss: 4.798331400836804

Epoch: 6| Step: 10
Training loss: 5.234634438533232
Validation loss: 4.7513783823764255

Epoch: 6| Step: 11
Training loss: 5.446296329366902
Validation loss: 4.7070418203741795

Epoch: 6| Step: 12
Training loss: 4.137841091329478
Validation loss: 4.669849823408806

Epoch: 6| Step: 13
Training loss: 5.72136157496486
Validation loss: 4.6364933471978045

Epoch: 3| Step: 0
Training loss: 3.475891185624452
Validation loss: 4.599028104894065

Epoch: 6| Step: 1
Training loss: 4.37757601512395
Validation loss: 4.5620545931083

Epoch: 6| Step: 2
Training loss: 4.9575987627018945
Validation loss: 4.525460936355557

Epoch: 6| Step: 3
Training loss: 4.840890347895887
Validation loss: 4.491514295985505

Epoch: 6| Step: 4
Training loss: 4.928194959648282
Validation loss: 4.461759363936079

Epoch: 6| Step: 5
Training loss: 5.6469094727672
Validation loss: 4.436225300158886

Epoch: 6| Step: 6
Training loss: 4.616494063766995
Validation loss: 4.4079252671580775

Epoch: 6| Step: 7
Training loss: 4.553728215272551
Validation loss: 4.37887388607852

Epoch: 6| Step: 8
Training loss: 3.914078581085977
Validation loss: 4.350458792656475

Epoch: 6| Step: 9
Training loss: 4.413887925198253
Validation loss: 4.322974670629863

Epoch: 6| Step: 10
Training loss: 4.011364290648512
Validation loss: 4.293296452335652

Epoch: 6| Step: 11
Training loss: 4.119778651985738
Validation loss: 4.263250576651143

Epoch: 6| Step: 12
Training loss: 4.82506575465487
Validation loss: 4.23565315251498

Epoch: 6| Step: 13
Training loss: 3.7935808122041035
Validation loss: 4.213954113429775

Epoch: 4| Step: 0
Training loss: 3.9892904441367345
Validation loss: 4.202625793193413

Epoch: 6| Step: 1
Training loss: 4.4773904990007285
Validation loss: 4.186590041652765

Epoch: 6| Step: 2
Training loss: 3.6623749903673652
Validation loss: 4.171392630674566

Epoch: 6| Step: 3
Training loss: 4.297512381703913
Validation loss: 4.151236164167671

Epoch: 6| Step: 4
Training loss: 4.297483089074221
Validation loss: 4.129779206142166

Epoch: 6| Step: 5
Training loss: 3.8234784010682024
Validation loss: 4.112724756514385

Epoch: 6| Step: 6
Training loss: 4.468858410780707
Validation loss: 4.09533423284793

Epoch: 6| Step: 7
Training loss: 4.573368452806635
Validation loss: 4.0798211118258365

Epoch: 6| Step: 8
Training loss: 5.456092704611823
Validation loss: 4.067625229614624

Epoch: 6| Step: 9
Training loss: 3.0762658095777025
Validation loss: 4.049450157190082

Epoch: 6| Step: 10
Training loss: 2.8774388790847762
Validation loss: 4.027263873824284

Epoch: 6| Step: 11
Training loss: 5.750075961730752
Validation loss: 4.007767738844409

Epoch: 6| Step: 12
Training loss: 3.8198299298200467
Validation loss: 3.9901135280644353

Epoch: 6| Step: 13
Training loss: 3.3335529890802484
Validation loss: 3.981288668598828

Epoch: 5| Step: 0
Training loss: 4.111352944922112
Validation loss: 3.9667187861465996

Epoch: 6| Step: 1
Training loss: 4.108018078163432
Validation loss: 3.9565983379280687

Epoch: 6| Step: 2
Training loss: 3.94689559145862
Validation loss: 3.936141045720643

Epoch: 6| Step: 3
Training loss: 3.821184117401572
Validation loss: 3.9188412163044055

Epoch: 6| Step: 4
Training loss: 4.569162181625006
Validation loss: 3.9045605017817557

Epoch: 6| Step: 5
Training loss: 4.79376796037674
Validation loss: 3.8958473769040043

Epoch: 6| Step: 6
Training loss: 4.0685841703827705
Validation loss: 3.878603541512155

Epoch: 6| Step: 7
Training loss: 5.092937381259816
Validation loss: 3.870812417660441

Epoch: 6| Step: 8
Training loss: 4.027195984195106
Validation loss: 3.8446331982029265

Epoch: 6| Step: 9
Training loss: 4.182414596606864
Validation loss: 3.8370969913919875

Epoch: 6| Step: 10
Training loss: 4.1078082096604165
Validation loss: 3.8290772335894605

Epoch: 6| Step: 11
Training loss: 2.9689539789093793
Validation loss: 3.81668602434784

Epoch: 6| Step: 12
Training loss: 2.0176958195645067
Validation loss: 3.792226311726018

Epoch: 6| Step: 13
Training loss: 3.9224071369642277
Validation loss: 3.7849632369833794

Epoch: 6| Step: 0
Training loss: 3.2437053758201455
Validation loss: 3.7735020062944673

Epoch: 6| Step: 1
Training loss: 4.087979041909917
Validation loss: 3.7590688749430767

Epoch: 6| Step: 2
Training loss: 3.809683838389523
Validation loss: 3.747489976531656

Epoch: 6| Step: 3
Training loss: 3.761690355552233
Validation loss: 3.7404820044529825

Epoch: 6| Step: 4
Training loss: 4.3441109267204885
Validation loss: 3.7320656621285146

Epoch: 6| Step: 5
Training loss: 3.6495012125414887
Validation loss: 3.7191452791075754

Epoch: 6| Step: 6
Training loss: 3.588244525066189
Validation loss: 3.710874219094717

Epoch: 6| Step: 7
Training loss: 3.3086733037218585
Validation loss: 3.697772285153588

Epoch: 6| Step: 8
Training loss: 3.8348471651620444
Validation loss: 3.6897793429444903

Epoch: 6| Step: 9
Training loss: 3.8602227272249694
Validation loss: 3.679514127535076

Epoch: 6| Step: 10
Training loss: 3.90085809510854
Validation loss: 3.665239581239126

Epoch: 6| Step: 11
Training loss: 4.2625779667768615
Validation loss: 3.656555433674015

Epoch: 6| Step: 12
Training loss: 4.033917158343843
Validation loss: 3.6485576584819484

Epoch: 6| Step: 13
Training loss: 4.938181962830295
Validation loss: 3.6371736891022337

Epoch: 7| Step: 0
Training loss: 3.1450866587818465
Validation loss: 3.6265006977760055

Epoch: 6| Step: 1
Training loss: 4.297969498388981
Validation loss: 3.614438596298611

Epoch: 6| Step: 2
Training loss: 4.504098721020254
Validation loss: 3.609316154134877

Epoch: 6| Step: 3
Training loss: 3.4806372604935065
Validation loss: 3.6022298728980537

Epoch: 6| Step: 4
Training loss: 3.1283775387707684
Validation loss: 3.590655463586114

Epoch: 6| Step: 5
Training loss: 4.468003430726348
Validation loss: 3.584096395677637

Epoch: 6| Step: 6
Training loss: 3.8828107806994434
Validation loss: 3.5707257806363786

Epoch: 6| Step: 7
Training loss: 2.8448071872693337
Validation loss: 3.5703989643473095

Epoch: 6| Step: 8
Training loss: 4.24795236065835
Validation loss: 3.573489590437751

Epoch: 6| Step: 9
Training loss: 3.4561151185024652
Validation loss: 3.553630297252669

Epoch: 6| Step: 10
Training loss: 3.6370631791365353
Validation loss: 3.5642119883290873

Epoch: 6| Step: 11
Training loss: 4.028448506482957
Validation loss: 3.5486036421963028

Epoch: 6| Step: 12
Training loss: 3.610298864193094
Validation loss: 3.5392837634531777

Epoch: 6| Step: 13
Training loss: 3.749078637422485
Validation loss: 3.541655560837379

Epoch: 8| Step: 0
Training loss: 3.586220191999221
Validation loss: 3.5416536469675646

Epoch: 6| Step: 1
Training loss: 2.6569349415616874
Validation loss: 3.534406038065346

Epoch: 6| Step: 2
Training loss: 4.230608965099017
Validation loss: 3.524505283907509

Epoch: 6| Step: 3
Training loss: 3.8786284163778806
Validation loss: 3.5099652314314143

Epoch: 6| Step: 4
Training loss: 3.3997655619409506
Validation loss: 3.505713465271916

Epoch: 6| Step: 5
Training loss: 3.7333066042442784
Validation loss: 3.4961198666577222

Epoch: 6| Step: 6
Training loss: 4.087094086723533
Validation loss: 3.492145526423877

Epoch: 6| Step: 7
Training loss: 3.797961672155102
Validation loss: 3.4852305113926714

Epoch: 6| Step: 8
Training loss: 4.248647137906537
Validation loss: 3.4808187341806045

Epoch: 6| Step: 9
Training loss: 3.2139318755834125
Validation loss: 3.4725153385166356

Epoch: 6| Step: 10
Training loss: 4.036125842110785
Validation loss: 3.466002794227212

Epoch: 6| Step: 11
Training loss: 3.6774911339171252
Validation loss: 3.4571645169775094

Epoch: 6| Step: 12
Training loss: 3.6841659991362894
Validation loss: 3.4540503813643273

Epoch: 6| Step: 13
Training loss: 2.962620400344203
Validation loss: 3.449281372918471

Epoch: 9| Step: 0
Training loss: 3.609574877996815
Validation loss: 3.4427761243532724

Epoch: 6| Step: 1
Training loss: 3.611053208759081
Validation loss: 3.4415205248545533

Epoch: 6| Step: 2
Training loss: 3.373743741798886
Validation loss: 3.4457109563306467

Epoch: 6| Step: 3
Training loss: 3.642365002981086
Validation loss: 3.46768816099948

Epoch: 6| Step: 4
Training loss: 3.0625966893716985
Validation loss: 3.4262462982285715

Epoch: 6| Step: 5
Training loss: 4.350009935740381
Validation loss: 3.4240314085016936

Epoch: 6| Step: 6
Training loss: 3.6042090764426287
Validation loss: 3.4303641719596003

Epoch: 6| Step: 7
Training loss: 4.199779895282995
Validation loss: 3.4154691410838387

Epoch: 6| Step: 8
Training loss: 3.9438877668061356
Validation loss: 3.4083741282161264

Epoch: 6| Step: 9
Training loss: 2.5236952328230577
Validation loss: 3.403970329404552

Epoch: 6| Step: 10
Training loss: 3.7418115861067687
Validation loss: 3.4008831981048853

Epoch: 6| Step: 11
Training loss: 2.550354155088217
Validation loss: 3.4002314058126277

Epoch: 6| Step: 12
Training loss: 4.339767936092406
Validation loss: 3.3973009410987554

Epoch: 6| Step: 13
Training loss: 3.986752268362306
Validation loss: 3.38927956581918

Epoch: 10| Step: 0
Training loss: 4.1396637574542545
Validation loss: 3.3813150513165655

Epoch: 6| Step: 1
Training loss: 3.8008728329954082
Validation loss: 3.3748529129457436

Epoch: 6| Step: 2
Training loss: 4.05470255295857
Validation loss: 3.3707595370733334

Epoch: 6| Step: 3
Training loss: 3.8172585229750404
Validation loss: 3.3625772120505992

Epoch: 6| Step: 4
Training loss: 3.6229463218863085
Validation loss: 3.358889110365361

Epoch: 6| Step: 5
Training loss: 3.8118080386716278
Validation loss: 3.3534308999576

Epoch: 6| Step: 6
Training loss: 3.496119118710333
Validation loss: 3.3452009591842025

Epoch: 6| Step: 7
Training loss: 3.59597709312399
Validation loss: 3.340627201677834

Epoch: 6| Step: 8
Training loss: 3.0258807578888356
Validation loss: 3.3361434832583647

Epoch: 6| Step: 9
Training loss: 3.4108642682100885
Validation loss: 3.332882392796228

Epoch: 6| Step: 10
Training loss: 2.9176373274385714
Validation loss: 3.3291994215342315

Epoch: 6| Step: 11
Training loss: 2.866468791638077
Validation loss: 3.325139393252768

Epoch: 6| Step: 12
Training loss: 4.1133120862596515
Validation loss: 3.3273135901407676

Epoch: 6| Step: 13
Training loss: 2.9285915919018484
Validation loss: 3.322107634280349

Epoch: 11| Step: 0
Training loss: 4.031144251656238
Validation loss: 3.319822917942122

Epoch: 6| Step: 1
Training loss: 2.590515601927884
Validation loss: 3.3168570432679654

Epoch: 6| Step: 2
Training loss: 3.8307855819327257
Validation loss: 3.3182001197415554

Epoch: 6| Step: 3
Training loss: 3.0263530069851705
Validation loss: 3.3094810695274686

Epoch: 6| Step: 4
Training loss: 3.2751623448326597
Validation loss: 3.3062474761282696

Epoch: 6| Step: 5
Training loss: 3.1721873763784023
Validation loss: 3.2993704876866734

Epoch: 6| Step: 6
Training loss: 3.17790588403752
Validation loss: 3.2975611549806825

Epoch: 6| Step: 7
Training loss: 3.646689149228192
Validation loss: 3.2962603547932012

Epoch: 6| Step: 8
Training loss: 4.293621815374175
Validation loss: 3.2879645140255205

Epoch: 6| Step: 9
Training loss: 3.7982135187266515
Validation loss: 3.2851615167195907

Epoch: 6| Step: 10
Training loss: 3.679878764436033
Validation loss: 3.2807331574697383

Epoch: 6| Step: 11
Training loss: 3.4112721787930695
Validation loss: 3.2728676166390147

Epoch: 6| Step: 12
Training loss: 3.5658335565393253
Validation loss: 3.2690990566792615

Epoch: 6| Step: 13
Training loss: 3.8457006451553712
Validation loss: 3.2629553399195803

Epoch: 12| Step: 0
Training loss: 2.714090498020527
Validation loss: 3.257159224080041

Epoch: 6| Step: 1
Training loss: 3.037454606333182
Validation loss: 3.2531867735759707

Epoch: 6| Step: 2
Training loss: 3.4996956284192984
Validation loss: 3.2503514963529208

Epoch: 6| Step: 3
Training loss: 3.138842176316724
Validation loss: 3.2470539740448148

Epoch: 6| Step: 4
Training loss: 3.268778031704912
Validation loss: 3.241192059805703

Epoch: 6| Step: 5
Training loss: 3.4990423799811707
Validation loss: 3.2422516388620775

Epoch: 6| Step: 6
Training loss: 3.888736986796359
Validation loss: 3.241603795117867

Epoch: 6| Step: 7
Training loss: 4.315066693299995
Validation loss: 3.2364172527419117

Epoch: 6| Step: 8
Training loss: 3.733936491562552
Validation loss: 3.2382961871398646

Epoch: 6| Step: 9
Training loss: 3.074737698912585
Validation loss: 3.2288252306965037

Epoch: 6| Step: 10
Training loss: 4.158196703259485
Validation loss: 3.2266660581968862

Epoch: 6| Step: 11
Training loss: 3.763238554291225
Validation loss: 3.223247564166654

Epoch: 6| Step: 12
Training loss: 3.3091311327998083
Validation loss: 3.2248966185526267

Epoch: 6| Step: 13
Training loss: 2.785389423641335
Validation loss: 3.2239278246229417

Epoch: 13| Step: 0
Training loss: 3.3362836814486543
Validation loss: 3.2246868300414846

Epoch: 6| Step: 1
Training loss: 3.466138251697819
Validation loss: 3.2244543527970717

Epoch: 6| Step: 2
Training loss: 3.14395193130205
Validation loss: 3.2235243763659303

Epoch: 6| Step: 3
Training loss: 3.382251155521766
Validation loss: 3.2181953504248697

Epoch: 6| Step: 4
Training loss: 2.5825946325964355
Validation loss: 3.215550965200375

Epoch: 6| Step: 5
Training loss: 3.800659428650551
Validation loss: 3.2111049746449183

Epoch: 6| Step: 6
Training loss: 2.9098295092371216
Validation loss: 3.2075393188574144

Epoch: 6| Step: 7
Training loss: 3.7417989700364083
Validation loss: 3.2038566115995772

Epoch: 6| Step: 8
Training loss: 3.5182520566582047
Validation loss: 3.204224844610987

Epoch: 6| Step: 9
Training loss: 4.364867766344793
Validation loss: 3.202224949945703

Epoch: 6| Step: 10
Training loss: 3.592752998378937
Validation loss: 3.1980556933334547

Epoch: 6| Step: 11
Training loss: 3.010855742820826
Validation loss: 3.1986376071428864

Epoch: 6| Step: 12
Training loss: 3.8506560274498476
Validation loss: 3.1917469766912476

Epoch: 6| Step: 13
Training loss: 3.4337022089401077
Validation loss: 3.189454261554472

Epoch: 14| Step: 0
Training loss: 3.63243852556775
Validation loss: 3.1911982958586265

Epoch: 6| Step: 1
Training loss: 3.1566548607137856
Validation loss: 3.190679722745606

Epoch: 6| Step: 2
Training loss: 2.942550213822061
Validation loss: 3.1904559085378037

Epoch: 6| Step: 3
Training loss: 3.0855000246178097
Validation loss: 3.1880347446562634

Epoch: 6| Step: 4
Training loss: 3.8730711289347113
Validation loss: 3.1808910504296364

Epoch: 6| Step: 5
Training loss: 3.9173484912195593
Validation loss: 3.1792993577970745

Epoch: 6| Step: 6
Training loss: 2.744604974196831
Validation loss: 3.1749465273836464

Epoch: 6| Step: 7
Training loss: 4.917576247740725
Validation loss: 3.1739044235814466

Epoch: 6| Step: 8
Training loss: 2.9145383062876973
Validation loss: 3.1705411851264556

Epoch: 6| Step: 9
Training loss: 3.3228949343808756
Validation loss: 3.170592101897055

Epoch: 6| Step: 10
Training loss: 3.0097245913511244
Validation loss: 3.1685645003023097

Epoch: 6| Step: 11
Training loss: 2.8494319952075537
Validation loss: 3.1643534508463937

Epoch: 6| Step: 12
Training loss: 2.5492630510750867
Validation loss: 3.1609734201527675

Epoch: 6| Step: 13
Training loss: 4.970564025251659
Validation loss: 3.163985218647303

Epoch: 15| Step: 0
Training loss: 3.2303378206633298
Validation loss: 3.1606024954322085

Epoch: 6| Step: 1
Training loss: 3.5849187729490577
Validation loss: 3.162752081828307

Epoch: 6| Step: 2
Training loss: 2.525388170375354
Validation loss: 3.1671489603046643

Epoch: 6| Step: 3
Training loss: 3.718516879428245
Validation loss: 3.1914067359934286

Epoch: 6| Step: 4
Training loss: 2.8936359292404443
Validation loss: 3.153553927539279

Epoch: 6| Step: 5
Training loss: 3.164436977502083
Validation loss: 3.1550031758068435

Epoch: 6| Step: 6
Training loss: 3.3024352133876973
Validation loss: 3.187177052586378

Epoch: 6| Step: 7
Training loss: 4.075953815441882
Validation loss: 3.1471657156517265

Epoch: 6| Step: 8
Training loss: 3.723547909756887
Validation loss: 3.1421859299572428

Epoch: 6| Step: 9
Training loss: 3.491179386876667
Validation loss: 3.1498204871724917

Epoch: 6| Step: 10
Training loss: 3.6022487822279157
Validation loss: 3.153661780484154

Epoch: 6| Step: 11
Training loss: 3.1639515798459015
Validation loss: 3.167078147431598

Epoch: 6| Step: 12
Training loss: 3.7172919227842165
Validation loss: 3.1594696404333495

Epoch: 6| Step: 13
Training loss: 3.5242192316784338
Validation loss: 3.1454804702090358

Epoch: 16| Step: 0
Training loss: 2.9047145273840083
Validation loss: 3.1543928002689547

Epoch: 6| Step: 1
Training loss: 3.3884326509579803
Validation loss: 3.140032830018056

Epoch: 6| Step: 2
Training loss: 3.139510986736604
Validation loss: 3.126295958846446

Epoch: 6| Step: 3
Training loss: 4.09083581531289
Validation loss: 3.1298399543934647

Epoch: 6| Step: 4
Training loss: 3.0374329422193016
Validation loss: 3.116190408305916

Epoch: 6| Step: 5
Training loss: 3.6104662017740634
Validation loss: 3.1128456409107033

Epoch: 6| Step: 6
Training loss: 3.557068817322346
Validation loss: 3.109414063969548

Epoch: 6| Step: 7
Training loss: 3.671176535547067
Validation loss: 3.107433274082299

Epoch: 6| Step: 8
Training loss: 3.807561709128723
Validation loss: 3.106263024265757

Epoch: 6| Step: 9
Training loss: 2.988983909423237
Validation loss: 3.103196482990678

Epoch: 6| Step: 10
Training loss: 3.1835560053360656
Validation loss: 3.0962512844243872

Epoch: 6| Step: 11
Training loss: 3.4123786597285193
Validation loss: 3.09740025574727

Epoch: 6| Step: 12
Training loss: 3.2361956645814183
Validation loss: 3.09922154460821

Epoch: 6| Step: 13
Training loss: 2.95797170300261
Validation loss: 3.099854036957644

Epoch: 17| Step: 0
Training loss: 3.970988806088919
Validation loss: 3.1035955305170826

Epoch: 6| Step: 1
Training loss: 3.0158229624547164
Validation loss: 3.1027566009022176

Epoch: 6| Step: 2
Training loss: 2.6738517542840587
Validation loss: 3.10584846311721

Epoch: 6| Step: 3
Training loss: 3.765238761879512
Validation loss: 3.095621410805461

Epoch: 6| Step: 4
Training loss: 3.0006860902173567
Validation loss: 3.0778217465080586

Epoch: 6| Step: 5
Training loss: 3.1099760921822717
Validation loss: 3.0736956716278576

Epoch: 6| Step: 6
Training loss: 3.394122732358754
Validation loss: 3.078898979121994

Epoch: 6| Step: 7
Training loss: 3.4890783751178254
Validation loss: 3.0801884899466865

Epoch: 6| Step: 8
Training loss: 3.646441744946982
Validation loss: 3.0772686696788694

Epoch: 6| Step: 9
Training loss: 3.849258073931464
Validation loss: 3.069734511185102

Epoch: 6| Step: 10
Training loss: 3.129606590044069
Validation loss: 3.068821874360402

Epoch: 6| Step: 11
Training loss: 3.1492888480438066
Validation loss: 3.0677847703429078

Epoch: 6| Step: 12
Training loss: 3.4182855600942883
Validation loss: 3.0668406377197712

Epoch: 6| Step: 13
Training loss: 2.990531443185827
Validation loss: 3.0673443265098954

Epoch: 18| Step: 0
Training loss: 3.7613953701944722
Validation loss: 3.0665247146884638

Epoch: 6| Step: 1
Training loss: 3.093708847234581
Validation loss: 3.063055604582141

Epoch: 6| Step: 2
Training loss: 2.9893712268688293
Validation loss: 3.059573318915

Epoch: 6| Step: 3
Training loss: 2.7030002807775104
Validation loss: 3.0594060444653275

Epoch: 6| Step: 4
Training loss: 3.3112422066607987
Validation loss: 3.0584167639644355

Epoch: 6| Step: 5
Training loss: 2.8631543473540613
Validation loss: 3.058832027520661

Epoch: 6| Step: 6
Training loss: 3.5196556213284595
Validation loss: 3.0598973014721547

Epoch: 6| Step: 7
Training loss: 3.7406432085223464
Validation loss: 3.056804849589412

Epoch: 6| Step: 8
Training loss: 3.153791017390352
Validation loss: 3.0511501713605633

Epoch: 6| Step: 9
Training loss: 4.4126108128624955
Validation loss: 3.0486637625170574

Epoch: 6| Step: 10
Training loss: 2.8617590465827556
Validation loss: 3.0510003327399198

Epoch: 6| Step: 11
Training loss: 3.561448460703121
Validation loss: 3.0493829065583595

Epoch: 6| Step: 12
Training loss: 3.030705511212021
Validation loss: 3.046400470660954

Epoch: 6| Step: 13
Training loss: 3.213553817618885
Validation loss: 3.0437314072716344

Epoch: 19| Step: 0
Training loss: 3.46541152998364
Validation loss: 3.0405631536637965

Epoch: 6| Step: 1
Training loss: 3.742763658102798
Validation loss: 3.041825286284978

Epoch: 6| Step: 2
Training loss: 3.0938421678781887
Validation loss: 3.043284677119393

Epoch: 6| Step: 3
Training loss: 3.088616939011257
Validation loss: 3.0385553295464995

Epoch: 6| Step: 4
Training loss: 3.637683383998899
Validation loss: 3.038702813826061

Epoch: 6| Step: 5
Training loss: 2.9643134445758044
Validation loss: 3.0344651490526617

Epoch: 6| Step: 6
Training loss: 2.7136730277005614
Validation loss: 3.0345807633439468

Epoch: 6| Step: 7
Training loss: 3.9898685655481336
Validation loss: 3.0354275305771172

Epoch: 6| Step: 8
Training loss: 3.0218132446669386
Validation loss: 3.034432751761076

Epoch: 6| Step: 9
Training loss: 3.9551449164884978
Validation loss: 3.030730681382366

Epoch: 6| Step: 10
Training loss: 3.519181957122829
Validation loss: 3.028009956193077

Epoch: 6| Step: 11
Training loss: 2.646202652354018
Validation loss: 3.028184616802571

Epoch: 6| Step: 12
Training loss: 3.30873541770751
Validation loss: 3.0252809370859444

Epoch: 6| Step: 13
Training loss: 2.485449504608717
Validation loss: 3.0251666673391573

Epoch: 20| Step: 0
Training loss: 3.381965513553218
Validation loss: 3.0225677820700407

Epoch: 6| Step: 1
Training loss: 3.741991392344897
Validation loss: 3.020101431561433

Epoch: 6| Step: 2
Training loss: 2.864005087086086
Validation loss: 3.0210871153167376

Epoch: 6| Step: 3
Training loss: 3.768956147434483
Validation loss: 3.017901027176846

Epoch: 6| Step: 4
Training loss: 3.6694557823784395
Validation loss: 3.016128658651974

Epoch: 6| Step: 5
Training loss: 3.089613798629631
Validation loss: 3.0146052686118012

Epoch: 6| Step: 6
Training loss: 3.3873535406116435
Validation loss: 3.0101410602340173

Epoch: 6| Step: 7
Training loss: 3.6747529134922425
Validation loss: 3.017280097642079

Epoch: 6| Step: 8
Training loss: 3.7048243233116414
Validation loss: 3.0221887559679557

Epoch: 6| Step: 9
Training loss: 3.106799415186177
Validation loss: 3.0160575504199496

Epoch: 6| Step: 10
Training loss: 2.9096977538357414
Validation loss: 3.01064811254279

Epoch: 6| Step: 11
Training loss: 2.9318021339692386
Validation loss: 3.0023833638176787

Epoch: 6| Step: 12
Training loss: 2.397242444059801
Validation loss: 3.008324997379372

Epoch: 6| Step: 13
Training loss: 3.099558300421988
Validation loss: 3.0099703615505247

Epoch: 21| Step: 0
Training loss: 3.3415361722991554
Validation loss: 2.9993310784185594

Epoch: 6| Step: 1
Training loss: 3.368753516030821
Validation loss: 3.002803564096746

Epoch: 6| Step: 2
Training loss: 3.4685095626393485
Validation loss: 3.0177081699626083

Epoch: 6| Step: 3
Training loss: 3.0243073229973745
Validation loss: 3.001412491541259

Epoch: 6| Step: 4
Training loss: 3.289614524637062
Validation loss: 2.99707135264459

Epoch: 6| Step: 5
Training loss: 2.7276523455932593
Validation loss: 2.999961722892029

Epoch: 6| Step: 6
Training loss: 2.803650900883246
Validation loss: 2.994623536486064

Epoch: 6| Step: 7
Training loss: 3.210190586362287
Validation loss: 2.9943337595566755

Epoch: 6| Step: 8
Training loss: 2.9724584606402717
Validation loss: 2.9889512258668427

Epoch: 6| Step: 9
Training loss: 3.919486119978249
Validation loss: 2.99040091678212

Epoch: 6| Step: 10
Training loss: 3.65035457195278
Validation loss: 2.9894588673651326

Epoch: 6| Step: 11
Training loss: 3.5701693249465163
Validation loss: 2.9883652516219925

Epoch: 6| Step: 12
Training loss: 3.1333069827277145
Validation loss: 2.987606531386431

Epoch: 6| Step: 13
Training loss: 3.219955514873029
Validation loss: 2.9824579454843096

Epoch: 22| Step: 0
Training loss: 3.263292565667477
Validation loss: 2.9833301342289182

Epoch: 6| Step: 1
Training loss: 3.2674654652201376
Validation loss: 2.9827154306674775

Epoch: 6| Step: 2
Training loss: 3.208969515524026
Validation loss: 2.982837016341925

Epoch: 6| Step: 3
Training loss: 3.0010418672218417
Validation loss: 2.982453257368913

Epoch: 6| Step: 4
Training loss: 2.1319103079460704
Validation loss: 2.981491039772921

Epoch: 6| Step: 5
Training loss: 3.657363070090915
Validation loss: 2.9790916585454172

Epoch: 6| Step: 6
Training loss: 2.5989495979931845
Validation loss: 2.9848560018001042

Epoch: 6| Step: 7
Training loss: 3.5126593394130357
Validation loss: 2.9793531028352995

Epoch: 6| Step: 8
Training loss: 3.148162148222201
Validation loss: 2.9789558735926684

Epoch: 6| Step: 9
Training loss: 3.7808999143851527
Validation loss: 2.978068025182995

Epoch: 6| Step: 10
Training loss: 3.2998533852114704
Validation loss: 2.979177415723546

Epoch: 6| Step: 11
Training loss: 3.809276030634099
Validation loss: 2.9803708989547686

Epoch: 6| Step: 12
Training loss: 3.5568414554948
Validation loss: 2.96904967716357

Epoch: 6| Step: 13
Training loss: 3.0003250263891497
Validation loss: 2.9711939908637572

Epoch: 23| Step: 0
Training loss: 3.17533167510864
Validation loss: 2.9714106193216208

Epoch: 6| Step: 1
Training loss: 3.166795995647929
Validation loss: 2.9712530606038916

Epoch: 6| Step: 2
Training loss: 3.661903640054305
Validation loss: 2.9695577233995043

Epoch: 6| Step: 3
Training loss: 2.934424555708415
Validation loss: 2.970060997497434

Epoch: 6| Step: 4
Training loss: 3.3059855768220276
Validation loss: 2.9682104184903553

Epoch: 6| Step: 5
Training loss: 2.7680458637362855
Validation loss: 2.965550887316826

Epoch: 6| Step: 6
Training loss: 3.1731313838597734
Validation loss: 2.9647063595653913

Epoch: 6| Step: 7
Training loss: 3.3230001185988556
Validation loss: 2.9624331268977575

Epoch: 6| Step: 8
Training loss: 3.3903424545203897
Validation loss: 2.96092464426806

Epoch: 6| Step: 9
Training loss: 3.010746938854506
Validation loss: 2.961397204654211

Epoch: 6| Step: 10
Training loss: 3.134388363202134
Validation loss: 2.965990112876238

Epoch: 6| Step: 11
Training loss: 3.6857210167689236
Validation loss: 2.9684659000503997

Epoch: 6| Step: 12
Training loss: 3.163711490705709
Validation loss: 2.9568572763506187

Epoch: 6| Step: 13
Training loss: 3.7676458357624054
Validation loss: 2.9543861690719093

Epoch: 24| Step: 0
Training loss: 3.1196722773070014
Validation loss: 2.9529002678652696

Epoch: 6| Step: 1
Training loss: 3.604499463425669
Validation loss: 2.9574399486249336

Epoch: 6| Step: 2
Training loss: 2.0836142414173873
Validation loss: 2.950555215767076

Epoch: 6| Step: 3
Training loss: 3.4058790092370463
Validation loss: 2.9513088548599313

Epoch: 6| Step: 4
Training loss: 2.9511733291794067
Validation loss: 2.950389490334948

Epoch: 6| Step: 5
Training loss: 2.4051426903473723
Validation loss: 2.9561306680959554

Epoch: 6| Step: 6
Training loss: 3.00778459808487
Validation loss: 2.9590932351627317

Epoch: 6| Step: 7
Training loss: 4.162721342783003
Validation loss: 2.9671276104521196

Epoch: 6| Step: 8
Training loss: 3.318240104628924
Validation loss: 2.9608397593643416

Epoch: 6| Step: 9
Training loss: 3.411281684009858
Validation loss: 2.9528192007080456

Epoch: 6| Step: 10
Training loss: 3.841168288687894
Validation loss: 2.951586737052512

Epoch: 6| Step: 11
Training loss: 3.4613564541235045
Validation loss: 2.942653958167356

Epoch: 6| Step: 12
Training loss: 2.8634667642195604
Validation loss: 2.942838185100973

Epoch: 6| Step: 13
Training loss: 3.2524904832400194
Validation loss: 2.945147422267769

Epoch: 25| Step: 0
Training loss: 3.462041743281927
Validation loss: 2.94604058078329

Epoch: 6| Step: 1
Training loss: 2.7245239681954505
Validation loss: 2.9481138914696055

Epoch: 6| Step: 2
Training loss: 3.5802225020328695
Validation loss: 2.9435349111098223

Epoch: 6| Step: 3
Training loss: 2.860432747066129
Validation loss: 2.9409431790591642

Epoch: 6| Step: 4
Training loss: 2.876110525848576
Validation loss: 2.9388522350130137

Epoch: 6| Step: 5
Training loss: 3.723261300679119
Validation loss: 2.937780180559543

Epoch: 6| Step: 6
Training loss: 3.1467812396328063
Validation loss: 2.9390224612397735

Epoch: 6| Step: 7
Training loss: 3.3069699749225214
Validation loss: 2.940086051149541

Epoch: 6| Step: 8
Training loss: 2.9952383399343523
Validation loss: 2.9466241687191004

Epoch: 6| Step: 9
Training loss: 3.4630699046760305
Validation loss: 2.956009447018602

Epoch: 6| Step: 10
Training loss: 2.2361919778084776
Validation loss: 2.9380992259890975

Epoch: 6| Step: 11
Training loss: 3.568527075757935
Validation loss: 2.9374980189051216

Epoch: 6| Step: 12
Training loss: 3.4229311075368374
Validation loss: 2.9359994955730517

Epoch: 6| Step: 13
Training loss: 3.793427083131318
Validation loss: 2.9316979251592334

Epoch: 26| Step: 0
Training loss: 2.786634996939975
Validation loss: 2.932527594733265

Epoch: 6| Step: 1
Training loss: 3.230449856353456
Validation loss: 2.931027990012755

Epoch: 6| Step: 2
Training loss: 3.616728059332575
Validation loss: 2.929758100417807

Epoch: 6| Step: 3
Training loss: 3.8629605706928385
Validation loss: 2.9295747731168973

Epoch: 6| Step: 4
Training loss: 3.1534367478116208
Validation loss: 2.9303043775391844

Epoch: 6| Step: 5
Training loss: 3.1209171326357414
Validation loss: 2.9295825850320085

Epoch: 6| Step: 6
Training loss: 3.0570173427500396
Validation loss: 2.928789073502478

Epoch: 6| Step: 7
Training loss: 2.4321396403754543
Validation loss: 2.929353774885244

Epoch: 6| Step: 8
Training loss: 2.485480872127253
Validation loss: 2.9270092659900526

Epoch: 6| Step: 9
Training loss: 3.0509648969913337
Validation loss: 2.923491207273197

Epoch: 6| Step: 10
Training loss: 3.7800646728957448
Validation loss: 2.925369246610823

Epoch: 6| Step: 11
Training loss: 3.3877340200746997
Validation loss: 2.9229198458921517

Epoch: 6| Step: 12
Training loss: 3.252937749774233
Validation loss: 2.921360776288392

Epoch: 6| Step: 13
Training loss: 3.8420329406851224
Validation loss: 2.9207224888941083

Epoch: 27| Step: 0
Training loss: 3.496123892371806
Validation loss: 2.921599664635551

Epoch: 6| Step: 1
Training loss: 3.511566668008339
Validation loss: 2.9253828141945823

Epoch: 6| Step: 2
Training loss: 3.777505328757203
Validation loss: 2.9393529744424907

Epoch: 6| Step: 3
Training loss: 3.1082433433562686
Validation loss: 2.924045009845077

Epoch: 6| Step: 4
Training loss: 3.1243184681627656
Validation loss: 2.912947721721432

Epoch: 6| Step: 5
Training loss: 4.085171396121998
Validation loss: 2.916450530421898

Epoch: 6| Step: 6
Training loss: 2.8630928924765446
Validation loss: 2.914602460406074

Epoch: 6| Step: 7
Training loss: 2.6919988193027575
Validation loss: 2.915412275058738

Epoch: 6| Step: 8
Training loss: 3.171039339676254
Validation loss: 2.9192900322994517

Epoch: 6| Step: 9
Training loss: 2.810435575888674
Validation loss: 2.9171113107449145

Epoch: 6| Step: 10
Training loss: 2.8632749216548414
Validation loss: 2.9145144390049524

Epoch: 6| Step: 11
Training loss: 3.3056000155353824
Validation loss: 2.912166805926207

Epoch: 6| Step: 12
Training loss: 3.271900626503928
Validation loss: 2.90865083947544

Epoch: 6| Step: 13
Training loss: 2.249659936425798
Validation loss: 2.9089524707320216

Epoch: 28| Step: 0
Training loss: 3.3132668813057924
Validation loss: 2.906816333639442

Epoch: 6| Step: 1
Training loss: 2.7823257937397923
Validation loss: 2.9059516717453806

Epoch: 6| Step: 2
Training loss: 3.1756563244186724
Validation loss: 2.906106010025342

Epoch: 6| Step: 3
Training loss: 3.545074678180553
Validation loss: 2.906746188494007

Epoch: 6| Step: 4
Training loss: 2.53772932998827
Validation loss: 2.902652524703746

Epoch: 6| Step: 5
Training loss: 2.5928368856996626
Validation loss: 2.9078354248487512

Epoch: 6| Step: 6
Training loss: 3.0509045682202527
Validation loss: 2.911385668339541

Epoch: 6| Step: 7
Training loss: 3.3381826095595226
Validation loss: 2.9070138420362044

Epoch: 6| Step: 8
Training loss: 3.8913671559344225
Validation loss: 2.905090831251328

Epoch: 6| Step: 9
Training loss: 3.6170482897078005
Validation loss: 2.9054681910841005

Epoch: 6| Step: 10
Training loss: 3.3217363962018496
Validation loss: 2.9032375103590393

Epoch: 6| Step: 11
Training loss: 2.854140195700601
Validation loss: 2.899745614022861

Epoch: 6| Step: 12
Training loss: 3.3013544250866285
Validation loss: 2.8990577339507837

Epoch: 6| Step: 13
Training loss: 3.294568452722276
Validation loss: 2.898455165876311

Epoch: 29| Step: 0
Training loss: 2.698893415660926
Validation loss: 2.8986674610790653

Epoch: 6| Step: 1
Training loss: 3.820849421864912
Validation loss: 2.896924084703757

Epoch: 6| Step: 2
Training loss: 2.8412790147782627
Validation loss: 2.8973328411570067

Epoch: 6| Step: 3
Training loss: 3.8099291529038286
Validation loss: 2.896449711245725

Epoch: 6| Step: 4
Training loss: 3.0734455925001494
Validation loss: 2.897080031286447

Epoch: 6| Step: 5
Training loss: 3.2310794866496013
Validation loss: 2.893803932170899

Epoch: 6| Step: 6
Training loss: 2.9097998484046768
Validation loss: 2.8927673781783714

Epoch: 6| Step: 7
Training loss: 2.975420234555884
Validation loss: 2.8921157057276634

Epoch: 6| Step: 8
Training loss: 2.869354842507151
Validation loss: 2.8925947817405606

Epoch: 6| Step: 9
Training loss: 3.008033803749877
Validation loss: 2.8913784225886587

Epoch: 6| Step: 10
Training loss: 3.28135375812513
Validation loss: 2.8898734098107113

Epoch: 6| Step: 11
Training loss: 3.516529017883709
Validation loss: 2.889776280087991

Epoch: 6| Step: 12
Training loss: 3.5131338830417183
Validation loss: 2.8887690294320656

Epoch: 6| Step: 13
Training loss: 2.7470366377246345
Validation loss: 2.8911436139517908

Epoch: 30| Step: 0
Training loss: 2.937071911075321
Validation loss: 2.8883120297356477

Epoch: 6| Step: 1
Training loss: 3.4648888895734946
Validation loss: 2.885551548697931

Epoch: 6| Step: 2
Training loss: 3.0331426001587776
Validation loss: 2.886689356138976

Epoch: 6| Step: 3
Training loss: 3.511165520156594
Validation loss: 2.8845189135311573

Epoch: 6| Step: 4
Training loss: 2.734520521378847
Validation loss: 2.8864185318621276

Epoch: 6| Step: 5
Training loss: 3.488631723190172
Validation loss: 2.886256052810792

Epoch: 6| Step: 6
Training loss: 3.5538634969572036
Validation loss: 2.883369651410167

Epoch: 6| Step: 7
Training loss: 2.680466786058374
Validation loss: 2.8828752899201575

Epoch: 6| Step: 8
Training loss: 3.7647493856034253
Validation loss: 2.8825105934271074

Epoch: 6| Step: 9
Training loss: 1.9811970050836112
Validation loss: 2.877697487500532

Epoch: 6| Step: 10
Training loss: 3.243463839512113
Validation loss: 2.8810305201919815

Epoch: 6| Step: 11
Training loss: 3.6088173175342986
Validation loss: 2.878026437612159

Epoch: 6| Step: 12
Training loss: 2.999945481122861
Validation loss: 2.8785474638832618

Epoch: 6| Step: 13
Training loss: 3.133317331178534
Validation loss: 2.8776625279548047

Epoch: 31| Step: 0
Training loss: 3.4593567004318526
Validation loss: 2.8759208335207727

Epoch: 6| Step: 1
Training loss: 2.730628711560836
Validation loss: 2.8771468337786947

Epoch: 6| Step: 2
Training loss: 2.357211706468846
Validation loss: 2.8796192421163957

Epoch: 6| Step: 3
Training loss: 3.2993022065353195
Validation loss: 2.88085834273036

Epoch: 6| Step: 4
Training loss: 3.568608584833939
Validation loss: 2.8794871531843915

Epoch: 6| Step: 5
Training loss: 3.5396640426358266
Validation loss: 2.8732688421378056

Epoch: 6| Step: 6
Training loss: 3.1803067890665844
Validation loss: 2.8762456327541757

Epoch: 6| Step: 7
Training loss: 2.875834965741794
Validation loss: 2.880491495171835

Epoch: 6| Step: 8
Training loss: 3.4705023935604045
Validation loss: 2.957199276785956

Epoch: 6| Step: 9
Training loss: 3.529729465135522
Validation loss: 2.874933909922334

Epoch: 6| Step: 10
Training loss: 3.2206351676142293
Validation loss: 2.8767421958002597

Epoch: 6| Step: 11
Training loss: 3.1624126135773594
Validation loss: 2.9575173706973645

Epoch: 6| Step: 12
Training loss: 3.127956060369229
Validation loss: 3.013116685042478

Epoch: 6| Step: 13
Training loss: 2.7997408201971696
Validation loss: 2.912554492710889

Epoch: 32| Step: 0
Training loss: 3.137119747387441
Validation loss: 2.9086116158246464

Epoch: 6| Step: 1
Training loss: 2.313803228243128
Validation loss: 2.9134007892790246

Epoch: 6| Step: 2
Training loss: 3.5846645780357087
Validation loss: 2.9109561468059786

Epoch: 6| Step: 3
Training loss: 3.0842676207799795
Validation loss: 2.910956837264343

Epoch: 6| Step: 4
Training loss: 2.993082813946206
Validation loss: 2.9111746193873738

Epoch: 6| Step: 5
Training loss: 3.050572113410239
Validation loss: 2.898872541186522

Epoch: 6| Step: 6
Training loss: 2.503419063977842
Validation loss: 2.894592705203859

Epoch: 6| Step: 7
Training loss: 3.301724740341982
Validation loss: 2.906376684530341

Epoch: 6| Step: 8
Training loss: 2.6732598892866637
Validation loss: 2.906433845921332

Epoch: 6| Step: 9
Training loss: 3.345287504285413
Validation loss: 2.935503247632183

Epoch: 6| Step: 10
Training loss: 3.885893614321387
Validation loss: 2.9257286226188417

Epoch: 6| Step: 11
Training loss: 3.732954577124925
Validation loss: 2.8819382416217376

Epoch: 6| Step: 12
Training loss: 3.784100553608069
Validation loss: 2.886276954411999

Epoch: 6| Step: 13
Training loss: 2.748209630596992
Validation loss: 2.9021939154631258

Epoch: 33| Step: 0
Training loss: 3.8637561718321582
Validation loss: 2.9371240689911735

Epoch: 6| Step: 1
Training loss: 2.7630168448565304
Validation loss: 2.9255390226602644

Epoch: 6| Step: 2
Training loss: 3.2771336484725753
Validation loss: 2.9043120469132186

Epoch: 6| Step: 3
Training loss: 3.2283041181474905
Validation loss: 2.868151992243476

Epoch: 6| Step: 4
Training loss: 3.227037445654943
Validation loss: 2.863916244618343

Epoch: 6| Step: 5
Training loss: 3.045333080897457
Validation loss: 2.8647056742894823

Epoch: 6| Step: 6
Training loss: 3.5798807292655157
Validation loss: 2.861522429217423

Epoch: 6| Step: 7
Training loss: 2.552028567187142
Validation loss: 2.8626390844562146

Epoch: 6| Step: 8
Training loss: 2.86995187486447
Validation loss: 2.864533741690458

Epoch: 6| Step: 9
Training loss: 2.8312027344116215
Validation loss: 2.869110453279677

Epoch: 6| Step: 10
Training loss: 3.641568434122911
Validation loss: 2.871007614623921

Epoch: 6| Step: 11
Training loss: 2.9551494461196657
Validation loss: 2.8715698838519086

Epoch: 6| Step: 12
Training loss: 3.2285788380457063
Validation loss: 2.8780781219132536

Epoch: 6| Step: 13
Training loss: 3.3261735953093026
Validation loss: 2.8681779444835573

Epoch: 34| Step: 0
Training loss: 3.1275244625119787
Validation loss: 2.8627305080546277

Epoch: 6| Step: 1
Training loss: 2.458618718624455
Validation loss: 2.858049802536955

Epoch: 6| Step: 2
Training loss: 3.641033362541952
Validation loss: 2.85979253081956

Epoch: 6| Step: 3
Training loss: 2.9719359318436522
Validation loss: 2.8565303630873853

Epoch: 6| Step: 4
Training loss: 2.7397156793418533
Validation loss: 2.85571330211899

Epoch: 6| Step: 5
Training loss: 2.7972062410236713
Validation loss: 2.852261178390907

Epoch: 6| Step: 6
Training loss: 3.1841630110777497
Validation loss: 2.8498239451680103

Epoch: 6| Step: 7
Training loss: 3.1227230168912143
Validation loss: 2.8496461577027308

Epoch: 6| Step: 8
Training loss: 3.521829242290578
Validation loss: 2.8494853974392678

Epoch: 6| Step: 9
Training loss: 3.2570261200562265
Validation loss: 2.851146625080673

Epoch: 6| Step: 10
Training loss: 3.6191445776253377
Validation loss: 2.8506272995593394

Epoch: 6| Step: 11
Training loss: 3.1999513860824536
Validation loss: 2.8489796276496144

Epoch: 6| Step: 12
Training loss: 3.1319403825739656
Validation loss: 2.84988480191011

Epoch: 6| Step: 13
Training loss: 3.4101365341193377
Validation loss: 2.8454672428870564

Epoch: 35| Step: 0
Training loss: 2.736227487024478
Validation loss: 2.8447496112555943

Epoch: 6| Step: 1
Training loss: 3.374086892266911
Validation loss: 2.8475040582095335

Epoch: 6| Step: 2
Training loss: 3.1961074996648757
Validation loss: 2.8434226401960596

Epoch: 6| Step: 3
Training loss: 3.2929198056675504
Validation loss: 2.8392056072033984

Epoch: 6| Step: 4
Training loss: 3.098281162336413
Validation loss: 2.839365900782838

Epoch: 6| Step: 5
Training loss: 2.9621973905248327
Validation loss: 2.8395850237542053

Epoch: 6| Step: 6
Training loss: 3.024684441871646
Validation loss: 2.8400832657174435

Epoch: 6| Step: 7
Training loss: 2.6514658310666968
Validation loss: 2.837321446673435

Epoch: 6| Step: 8
Training loss: 2.9681858530592016
Validation loss: 2.840702590813167

Epoch: 6| Step: 9
Training loss: 3.7988266187336346
Validation loss: 2.838243739620271

Epoch: 6| Step: 10
Training loss: 2.761148137518702
Validation loss: 2.8395629966106966

Epoch: 6| Step: 11
Training loss: 3.525227500121418
Validation loss: 2.834579460362786

Epoch: 6| Step: 12
Training loss: 3.4681240582391806
Validation loss: 2.837847048321833

Epoch: 6| Step: 13
Training loss: 2.957429201466952
Validation loss: 2.8481599964314572

Epoch: 36| Step: 0
Training loss: 3.0642396306686193
Validation loss: 2.8446981766590973

Epoch: 6| Step: 1
Training loss: 2.5697055088336733
Validation loss: 2.850219583858548

Epoch: 6| Step: 2
Training loss: 2.516975751006025
Validation loss: 2.8420556109669066

Epoch: 6| Step: 3
Training loss: 3.029030842908345
Validation loss: 2.836091481268761

Epoch: 6| Step: 4
Training loss: 3.3509614845733084
Validation loss: 2.8322376467664236

Epoch: 6| Step: 5
Training loss: 3.133448814401337
Validation loss: 2.831034551783037

Epoch: 6| Step: 6
Training loss: 3.2077496150375326
Validation loss: 2.833897883349811

Epoch: 6| Step: 7
Training loss: 2.9369118284265294
Validation loss: 2.8351463019412844

Epoch: 6| Step: 8
Training loss: 3.0127306078260685
Validation loss: 2.8406002040752663

Epoch: 6| Step: 9
Training loss: 3.675084176688952
Validation loss: 2.84629836778938

Epoch: 6| Step: 10
Training loss: 3.3729668603892597
Validation loss: 2.8289285534728945

Epoch: 6| Step: 11
Training loss: 3.539059535818985
Validation loss: 2.830472318429277

Epoch: 6| Step: 12
Training loss: 3.239712204572658
Validation loss: 2.8284557790197287

Epoch: 6| Step: 13
Training loss: 3.1504868872847456
Validation loss: 2.829087554924035

Epoch: 37| Step: 0
Training loss: 2.255588161794489
Validation loss: 2.8283405583265484

Epoch: 6| Step: 1
Training loss: 3.7701134741019375
Validation loss: 2.836630011426383

Epoch: 6| Step: 2
Training loss: 2.864586588539817
Validation loss: 2.8314862932545166

Epoch: 6| Step: 3
Training loss: 3.3305700928751953
Validation loss: 2.830207992650854

Epoch: 6| Step: 4
Training loss: 2.850163197445928
Validation loss: 2.8318553057745186

Epoch: 6| Step: 5
Training loss: 3.043067000128809
Validation loss: 2.83769545972189

Epoch: 6| Step: 6
Training loss: 3.9079891148145216
Validation loss: 2.838902985101996

Epoch: 6| Step: 7
Training loss: 3.3162670667937437
Validation loss: 2.830232664185889

Epoch: 6| Step: 8
Training loss: 3.2873873034984977
Validation loss: 2.8207261854125596

Epoch: 6| Step: 9
Training loss: 3.4211288405049816
Validation loss: 2.824203676121603

Epoch: 6| Step: 10
Training loss: 3.050080945551128
Validation loss: 2.820873412083851

Epoch: 6| Step: 11
Training loss: 2.2358281671969342
Validation loss: 2.8227351512899235

Epoch: 6| Step: 12
Training loss: 3.390908506292506
Validation loss: 2.817218165522826

Epoch: 6| Step: 13
Training loss: 2.568627080273555
Validation loss: 2.8208592227828566

Epoch: 38| Step: 0
Training loss: 2.9331945155270507
Validation loss: 2.81802486817525

Epoch: 6| Step: 1
Training loss: 2.584308214720031
Validation loss: 2.820176961536694

Epoch: 6| Step: 2
Training loss: 3.0654245542426755
Validation loss: 2.831155396535054

Epoch: 6| Step: 3
Training loss: 3.0469923730397332
Validation loss: 2.834002200214669

Epoch: 6| Step: 4
Training loss: 3.368346118956216
Validation loss: 2.853328531174198

Epoch: 6| Step: 5
Training loss: 3.446858377148551
Validation loss: 2.855359031311397

Epoch: 6| Step: 6
Training loss: 3.3459555223955264
Validation loss: 2.826473795828123

Epoch: 6| Step: 7
Training loss: 3.719362096339441
Validation loss: 2.818929138050113

Epoch: 6| Step: 8
Training loss: 2.457046387448402
Validation loss: 2.8163978802164613

Epoch: 6| Step: 9
Training loss: 3.4154449387508317
Validation loss: 2.815645778885673

Epoch: 6| Step: 10
Training loss: 2.429083353471089
Validation loss: 2.815005396326677

Epoch: 6| Step: 11
Training loss: 2.9648841181684453
Validation loss: 2.8170109003736705

Epoch: 6| Step: 12
Training loss: 3.5479924126493403
Validation loss: 2.8160534486502757

Epoch: 6| Step: 13
Training loss: 3.2469879277612574
Validation loss: 2.8157436712273936

Epoch: 39| Step: 0
Training loss: 3.146829577878649
Validation loss: 2.8150286483611002

Epoch: 6| Step: 1
Training loss: 3.3438090381579797
Validation loss: 2.8152395653752698

Epoch: 6| Step: 2
Training loss: 3.996596795988686
Validation loss: 2.8131849423389546

Epoch: 6| Step: 3
Training loss: 2.5525965168159916
Validation loss: 2.8110979603104957

Epoch: 6| Step: 4
Training loss: 2.464876830639245
Validation loss: 2.807272797294966

Epoch: 6| Step: 5
Training loss: 3.6010218812404298
Validation loss: 2.80633711578372

Epoch: 6| Step: 6
Training loss: 2.774102101818438
Validation loss: 2.805624270774548

Epoch: 6| Step: 7
Training loss: 2.7399653372695205
Validation loss: 2.806146783248546

Epoch: 6| Step: 8
Training loss: 3.724494664266602
Validation loss: 2.8061387967175273

Epoch: 6| Step: 9
Training loss: 2.512669408600201
Validation loss: 2.804410209319823

Epoch: 6| Step: 10
Training loss: 2.612694096998063
Validation loss: 2.8056943618738925

Epoch: 6| Step: 11
Training loss: 2.9056423741586554
Validation loss: 2.8008939395686734

Epoch: 6| Step: 12
Training loss: 3.4392946586950957
Validation loss: 2.8014573798146367

Epoch: 6| Step: 13
Training loss: 3.638381987412554
Validation loss: 2.8025069173721073

Epoch: 40| Step: 0
Training loss: 2.798592492970605
Validation loss: 2.8034021290484996

Epoch: 6| Step: 1
Training loss: 2.938403051641569
Validation loss: 2.8024797093273786

Epoch: 6| Step: 2
Training loss: 3.0681556328063904
Validation loss: 2.8043094155886

Epoch: 6| Step: 3
Training loss: 3.355888793375886
Validation loss: 2.8067729023999743

Epoch: 6| Step: 4
Training loss: 3.2026378726390092
Validation loss: 2.8043956615611694

Epoch: 6| Step: 5
Training loss: 3.1208572393570435
Validation loss: 2.802169218133618

Epoch: 6| Step: 6
Training loss: 3.891429281788836
Validation loss: 2.8018841132664694

Epoch: 6| Step: 7
Training loss: 3.088969534988317
Validation loss: 2.797440700411113

Epoch: 6| Step: 8
Training loss: 2.637673619056479
Validation loss: 2.7978493524100374

Epoch: 6| Step: 9
Training loss: 3.2360637881448477
Validation loss: 2.7955898444861775

Epoch: 6| Step: 10
Training loss: 3.405006531696525
Validation loss: 2.797406177605222

Epoch: 6| Step: 11
Training loss: 2.935916879854578
Validation loss: 2.7956416030320743

Epoch: 6| Step: 12
Training loss: 2.1832480387249156
Validation loss: 2.7951888625644115

Epoch: 6| Step: 13
Training loss: 3.599472001880523
Validation loss: 2.7953217506570884

Epoch: 41| Step: 0
Training loss: 2.1929691066001
Validation loss: 2.7941191774455083

Epoch: 6| Step: 1
Training loss: 2.8327174545814193
Validation loss: 2.7933367807325573

Epoch: 6| Step: 2
Training loss: 3.010159614614571
Validation loss: 2.790394463906291

Epoch: 6| Step: 3
Training loss: 3.674095878193132
Validation loss: 2.7883337313147774

Epoch: 6| Step: 4
Training loss: 3.540177933698544
Validation loss: 2.7902834653202175

Epoch: 6| Step: 5
Training loss: 2.701588982562056
Validation loss: 2.7898286818551425

Epoch: 6| Step: 6
Training loss: 3.3155650227808966
Validation loss: 2.791578762254264

Epoch: 6| Step: 7
Training loss: 2.5556096736964298
Validation loss: 2.790721285709312

Epoch: 6| Step: 8
Training loss: 2.720263005331703
Validation loss: 2.7891624273994706

Epoch: 6| Step: 9
Training loss: 3.180654917520243
Validation loss: 2.7851379197868877

Epoch: 6| Step: 10
Training loss: 3.323495573281625
Validation loss: 2.7898679609866

Epoch: 6| Step: 11
Training loss: 3.4155878984647243
Validation loss: 2.7897984683881187

Epoch: 6| Step: 12
Training loss: 3.7054005001505725
Validation loss: 2.790567044368029

Epoch: 6| Step: 13
Training loss: 2.707211178831598
Validation loss: 2.7986633917753663

Epoch: 42| Step: 0
Training loss: 2.398009321033984
Validation loss: 2.8088668308711204

Epoch: 6| Step: 1
Training loss: 3.2789692536146022
Validation loss: 2.8373628313307218

Epoch: 6| Step: 2
Training loss: 2.9494072658085884
Validation loss: 2.815010185722339

Epoch: 6| Step: 3
Training loss: 3.047573068320182
Validation loss: 2.8264714303444642

Epoch: 6| Step: 4
Training loss: 3.4621720361833384
Validation loss: 2.8266510028379956

Epoch: 6| Step: 5
Training loss: 2.9953736555197317
Validation loss: 2.8254484769696773

Epoch: 6| Step: 6
Training loss: 2.6765752129550684
Validation loss: 2.807370320456686

Epoch: 6| Step: 7
Training loss: 3.2106807262655663
Validation loss: 2.787982554536056

Epoch: 6| Step: 8
Training loss: 3.6367142920051894
Validation loss: 2.779914373948731

Epoch: 6| Step: 9
Training loss: 3.211981313667716
Validation loss: 2.7804560130008418

Epoch: 6| Step: 10
Training loss: 2.898277586769546
Validation loss: 2.7807731620619887

Epoch: 6| Step: 11
Training loss: 3.5807920952093504
Validation loss: 2.775723187629011

Epoch: 6| Step: 12
Training loss: 2.93745487259635
Validation loss: 2.777772446357232

Epoch: 6| Step: 13
Training loss: 2.6497043516673924
Validation loss: 2.776356773606102

Epoch: 43| Step: 0
Training loss: 2.6857428905737755
Validation loss: 2.774817749042864

Epoch: 6| Step: 1
Training loss: 3.0225158390611435
Validation loss: 2.7764309045734894

Epoch: 6| Step: 2
Training loss: 2.7190114914993946
Validation loss: 2.7779109074537525

Epoch: 6| Step: 3
Training loss: 3.097985960838074
Validation loss: 2.7897312310157507

Epoch: 6| Step: 4
Training loss: 3.1519465048457245
Validation loss: 2.781110495736889

Epoch: 6| Step: 5
Training loss: 2.3899962153065615
Validation loss: 2.781057867566865

Epoch: 6| Step: 6
Training loss: 3.3690281061374137
Validation loss: 2.773572125331203

Epoch: 6| Step: 7
Training loss: 3.198345805811918
Validation loss: 2.7728850292053635

Epoch: 6| Step: 8
Training loss: 2.6602758081039464
Validation loss: 2.772326668787116

Epoch: 6| Step: 9
Training loss: 3.720957894000654
Validation loss: 2.770573118914893

Epoch: 6| Step: 10
Training loss: 2.6659986334737837
Validation loss: 2.7741895604325535

Epoch: 6| Step: 11
Training loss: 3.7099214789211836
Validation loss: 2.7768231721176844

Epoch: 6| Step: 12
Training loss: 3.2410130591242705
Validation loss: 2.7761623171113956

Epoch: 6| Step: 13
Training loss: 3.652371950091667
Validation loss: 2.772565496552776

Epoch: 44| Step: 0
Training loss: 3.772744946474959
Validation loss: 2.7645895963895657

Epoch: 6| Step: 1
Training loss: 3.2490228504470466
Validation loss: 2.7634873909582236

Epoch: 6| Step: 2
Training loss: 3.7804353955715646
Validation loss: 2.7637762498946814

Epoch: 6| Step: 3
Training loss: 2.880672994500611
Validation loss: 2.7688842760136727

Epoch: 6| Step: 4
Training loss: 2.347986893053531
Validation loss: 2.7668603569347887

Epoch: 6| Step: 5
Training loss: 3.100573480536
Validation loss: 2.7678793980415546

Epoch: 6| Step: 6
Training loss: 3.28470916064414
Validation loss: 2.7627631874312573

Epoch: 6| Step: 7
Training loss: 2.5832504648843
Validation loss: 2.76345662324822

Epoch: 6| Step: 8
Training loss: 3.121915439347615
Validation loss: 2.7624741761624554

Epoch: 6| Step: 9
Training loss: 2.967434882949565
Validation loss: 2.760106112253617

Epoch: 6| Step: 10
Training loss: 2.558304119461048
Validation loss: 2.76453709048596

Epoch: 6| Step: 11
Training loss: 2.5367516903490515
Validation loss: 2.7644401419056592

Epoch: 6| Step: 12
Training loss: 3.1216993066724568
Validation loss: 2.780096711142142

Epoch: 6| Step: 13
Training loss: 3.8183426410279098
Validation loss: 2.789053776082438

Epoch: 45| Step: 0
Training loss: 3.000782705563384
Validation loss: 2.770507331327112

Epoch: 6| Step: 1
Training loss: 3.2356337894278315
Validation loss: 2.766238159040465

Epoch: 6| Step: 2
Training loss: 2.6348243520199435
Validation loss: 2.7831821530524707

Epoch: 6| Step: 3
Training loss: 2.9777076901147557
Validation loss: 2.7816228548672517

Epoch: 6| Step: 4
Training loss: 2.6057460928979777
Validation loss: 2.793604717251774

Epoch: 6| Step: 5
Training loss: 2.620519356248331
Validation loss: 2.7846899362055195

Epoch: 6| Step: 6
Training loss: 3.5901144463193506
Validation loss: 2.7930414937433086

Epoch: 6| Step: 7
Training loss: 3.1692530125556044
Validation loss: 2.785770062989486

Epoch: 6| Step: 8
Training loss: 3.2290245435058984
Validation loss: 2.7768504275180903

Epoch: 6| Step: 9
Training loss: 3.3220138678677524
Validation loss: 2.7771461243085844

Epoch: 6| Step: 10
Training loss: 3.379021403384603
Validation loss: 2.7766729754938715

Epoch: 6| Step: 11
Training loss: 3.432229179928795
Validation loss: 2.7684490639105728

Epoch: 6| Step: 12
Training loss: 3.194713433776212
Validation loss: 2.759792170095647

Epoch: 6| Step: 13
Training loss: 2.173327063490984
Validation loss: 2.755880580917694

Epoch: 46| Step: 0
Training loss: 2.86279226085453
Validation loss: 2.7572526009865683

Epoch: 6| Step: 1
Training loss: 3.2804110953271852
Validation loss: 2.756695306554806

Epoch: 6| Step: 2
Training loss: 3.3462446657465303
Validation loss: 2.7543973863106985

Epoch: 6| Step: 3
Training loss: 2.6058503976654968
Validation loss: 2.7526802731344246

Epoch: 6| Step: 4
Training loss: 2.7588464457527673
Validation loss: 2.751349809604394

Epoch: 6| Step: 5
Training loss: 3.0116220104943845
Validation loss: 2.7552876374506794

Epoch: 6| Step: 6
Training loss: 2.459968981818675
Validation loss: 2.7578818197391834

Epoch: 6| Step: 7
Training loss: 3.2828474243572283
Validation loss: 2.7590625496340797

Epoch: 6| Step: 8
Training loss: 3.1844893055953527
Validation loss: 2.755218783740139

Epoch: 6| Step: 9
Training loss: 2.90670739953201
Validation loss: 2.756023079410364

Epoch: 6| Step: 10
Training loss: 2.984571200806834
Validation loss: 2.754469545998312

Epoch: 6| Step: 11
Training loss: 3.2222795115964864
Validation loss: 2.753333188810044

Epoch: 6| Step: 12
Training loss: 3.679627241868274
Validation loss: 2.752033994450592

Epoch: 6| Step: 13
Training loss: 3.4279282909001627
Validation loss: 2.7474487343139913

Epoch: 47| Step: 0
Training loss: 2.6611906888775105
Validation loss: 2.7462843892078146

Epoch: 6| Step: 1
Training loss: 3.3652219058097486
Validation loss: 2.7436931104048576

Epoch: 6| Step: 2
Training loss: 3.891434795870003
Validation loss: 2.743091556812484

Epoch: 6| Step: 3
Training loss: 1.8787508006040248
Validation loss: 2.7421091421028088

Epoch: 6| Step: 4
Training loss: 3.2435216158103533
Validation loss: 2.740413867556895

Epoch: 6| Step: 5
Training loss: 2.979792726976114
Validation loss: 2.7423019121205523

Epoch: 6| Step: 6
Training loss: 3.033163351668966
Validation loss: 2.742620511956524

Epoch: 6| Step: 7
Training loss: 3.5026986753436136
Validation loss: 2.7460755614090555

Epoch: 6| Step: 8
Training loss: 2.733764841940333
Validation loss: 2.744121362178223

Epoch: 6| Step: 9
Training loss: 2.715071458666472
Validation loss: 2.743919352718772

Epoch: 6| Step: 10
Training loss: 3.028439349381675
Validation loss: 2.755439217483139

Epoch: 6| Step: 11
Training loss: 2.7916979052565605
Validation loss: 2.7572053983986957

Epoch: 6| Step: 12
Training loss: 3.2694551192413392
Validation loss: 2.764854666382454

Epoch: 6| Step: 13
Training loss: 3.636114904176505
Validation loss: 2.767577905464064

Epoch: 48| Step: 0
Training loss: 3.146219764536911
Validation loss: 2.7453823913697963

Epoch: 6| Step: 1
Training loss: 2.8781626347867686
Validation loss: 2.7380559968260574

Epoch: 6| Step: 2
Training loss: 3.0773929558117827
Validation loss: 2.7367043694672155

Epoch: 6| Step: 3
Training loss: 2.66986999238064
Validation loss: 2.7343331938798396

Epoch: 6| Step: 4
Training loss: 3.626267836276046
Validation loss: 2.733673179084965

Epoch: 6| Step: 5
Training loss: 2.7549968751311535
Validation loss: 2.7350591569514457

Epoch: 6| Step: 6
Training loss: 3.2670155170260164
Validation loss: 2.7339499541384793

Epoch: 6| Step: 7
Training loss: 3.2291022181488627
Validation loss: 2.733207345975759

Epoch: 6| Step: 8
Training loss: 3.3359192036968985
Validation loss: 2.732078721100518

Epoch: 6| Step: 9
Training loss: 2.9582388061321967
Validation loss: 2.7311737072043063

Epoch: 6| Step: 10
Training loss: 2.606799287796333
Validation loss: 2.731819506117289

Epoch: 6| Step: 11
Training loss: 2.1483462782480407
Validation loss: 2.730747015835629

Epoch: 6| Step: 12
Training loss: 3.5569197468212788
Validation loss: 2.7285441700294015

Epoch: 6| Step: 13
Training loss: 3.4416912536728086
Validation loss: 2.7534624807929995

Epoch: 49| Step: 0
Training loss: 3.650897028185347
Validation loss: 2.729811776185962

Epoch: 6| Step: 1
Training loss: 2.9388758906858405
Validation loss: 2.7301335228825696

Epoch: 6| Step: 2
Training loss: 2.715231976091634
Validation loss: 2.729740596925185

Epoch: 6| Step: 3
Training loss: 2.947586598244467
Validation loss: 2.7304651709059313

Epoch: 6| Step: 4
Training loss: 2.470124839685803
Validation loss: 2.7401567237501996

Epoch: 6| Step: 5
Training loss: 2.959745866846253
Validation loss: 2.739267500803454

Epoch: 6| Step: 6
Training loss: 2.689773041889635
Validation loss: 2.7352258627060855

Epoch: 6| Step: 7
Training loss: 3.3223149981634017
Validation loss: 2.728958549038404

Epoch: 6| Step: 8
Training loss: 2.6799807374176567
Validation loss: 2.7387139931023494

Epoch: 6| Step: 9
Training loss: 3.3771430381911323
Validation loss: 2.7514185234701656

Epoch: 6| Step: 10
Training loss: 2.8846479326025833
Validation loss: 2.7411418312086577

Epoch: 6| Step: 11
Training loss: 3.4058582885614452
Validation loss: 2.7302183072508526

Epoch: 6| Step: 12
Training loss: 3.613184384259032
Validation loss: 2.7356602464709816

Epoch: 6| Step: 13
Training loss: 2.8409671791380227
Validation loss: 2.7382892397115266

Epoch: 50| Step: 0
Training loss: 2.9354516862269855
Validation loss: 2.739728083382021

Epoch: 6| Step: 1
Training loss: 2.9363478978232096
Validation loss: 2.730485276490517

Epoch: 6| Step: 2
Training loss: 2.944821911334799
Validation loss: 2.7238560358179753

Epoch: 6| Step: 3
Training loss: 2.4061433842806985
Validation loss: 2.72136585491952

Epoch: 6| Step: 4
Training loss: 3.2285252251917913
Validation loss: 2.7223461480220434

Epoch: 6| Step: 5
Training loss: 3.5135600489431367
Validation loss: 2.721304731729092

Epoch: 6| Step: 6
Training loss: 2.5748082876596237
Validation loss: 2.7193823844952756

Epoch: 6| Step: 7
Training loss: 3.3419439839680107
Validation loss: 2.722672946318665

Epoch: 6| Step: 8
Training loss: 2.8291007197638542
Validation loss: 2.7208607313387287

Epoch: 6| Step: 9
Training loss: 3.189218992573695
Validation loss: 2.71992090942209

Epoch: 6| Step: 10
Training loss: 2.9216693663017943
Validation loss: 2.7259260556579044

Epoch: 6| Step: 11
Training loss: 3.2994620491593434
Validation loss: 2.720561925741708

Epoch: 6| Step: 12
Training loss: 3.1788493933459905
Validation loss: 2.72425322651158

Epoch: 6| Step: 13
Training loss: 3.3832349271196818
Validation loss: 2.722978073941503

Epoch: 51| Step: 0
Training loss: 3.4495311694934196
Validation loss: 2.723006332440953

Epoch: 6| Step: 1
Training loss: 3.048121740117695
Validation loss: 2.716730693915962

Epoch: 6| Step: 2
Training loss: 3.0394206877907846
Validation loss: 2.7145019089401257

Epoch: 6| Step: 3
Training loss: 2.9507494863386707
Validation loss: 2.715361895499341

Epoch: 6| Step: 4
Training loss: 1.886007676482127
Validation loss: 2.7142532193871585

Epoch: 6| Step: 5
Training loss: 3.467959202157954
Validation loss: 2.7108320448742593

Epoch: 6| Step: 6
Training loss: 3.1130461370699085
Validation loss: 2.710282511434812

Epoch: 6| Step: 7
Training loss: 3.230897074744532
Validation loss: 2.710511176452343

Epoch: 6| Step: 8
Training loss: 2.935735294185989
Validation loss: 2.7160581700583135

Epoch: 6| Step: 9
Training loss: 3.171121141268895
Validation loss: 2.7164423626568137

Epoch: 6| Step: 10
Training loss: 2.99985980659979
Validation loss: 2.718197009262349

Epoch: 6| Step: 11
Training loss: 2.947094122950818
Validation loss: 2.7346503606341033

Epoch: 6| Step: 12
Training loss: 2.9759722747741804
Validation loss: 2.7190030811966404

Epoch: 6| Step: 13
Training loss: 3.255368127588363
Validation loss: 2.7137285554395594

Epoch: 52| Step: 0
Training loss: 3.808452897034845
Validation loss: 2.7081582333840597

Epoch: 6| Step: 1
Training loss: 3.152695571193645
Validation loss: 2.7059439128058123

Epoch: 6| Step: 2
Training loss: 2.7065629209952604
Validation loss: 2.706928749075239

Epoch: 6| Step: 3
Training loss: 3.146575301293294
Validation loss: 2.705992656655266

Epoch: 6| Step: 4
Training loss: 2.3417490237630956
Validation loss: 2.705487154010153

Epoch: 6| Step: 5
Training loss: 3.2997935606223323
Validation loss: 2.7095198222884713

Epoch: 6| Step: 6
Training loss: 2.871290052281562
Validation loss: 2.709162734815599

Epoch: 6| Step: 7
Training loss: 3.0219967585810728
Validation loss: 2.710497735449879

Epoch: 6| Step: 8
Training loss: 3.090420250817056
Validation loss: 2.7041207529883775

Epoch: 6| Step: 9
Training loss: 3.315597237804218
Validation loss: 2.7019369224615186

Epoch: 6| Step: 10
Training loss: 2.5425705370875504
Validation loss: 2.699905921826845

Epoch: 6| Step: 11
Training loss: 2.5394669900165643
Validation loss: 2.70178810703089

Epoch: 6| Step: 12
Training loss: 3.0721731202300533
Validation loss: 2.7031955940948276

Epoch: 6| Step: 13
Training loss: 3.613681750396935
Validation loss: 2.7071186954721

Epoch: 53| Step: 0
Training loss: 3.6017986890422846
Validation loss: 2.7032436420922186

Epoch: 6| Step: 1
Training loss: 3.1612074792792044
Validation loss: 2.7041826182062945

Epoch: 6| Step: 2
Training loss: 2.891880072232051
Validation loss: 2.702695252011369

Epoch: 6| Step: 3
Training loss: 2.4389372280875268
Validation loss: 2.6975593959072537

Epoch: 6| Step: 4
Training loss: 3.247121563270349
Validation loss: 2.6963557301041137

Epoch: 6| Step: 5
Training loss: 2.63851266376405
Validation loss: 2.696376374307475

Epoch: 6| Step: 6
Training loss: 2.8819224733385846
Validation loss: 2.6950342901196978

Epoch: 6| Step: 7
Training loss: 2.9421533291899284
Validation loss: 2.6983209736939937

Epoch: 6| Step: 8
Training loss: 2.9071053507545512
Validation loss: 2.6966467737727418

Epoch: 6| Step: 9
Training loss: 2.9458938146386853
Validation loss: 2.694982130893326

Epoch: 6| Step: 10
Training loss: 3.209271149408352
Validation loss: 2.693879108120107

Epoch: 6| Step: 11
Training loss: 3.6779519298870085
Validation loss: 2.693228720702824

Epoch: 6| Step: 12
Training loss: 2.838443542091014
Validation loss: 2.696592522831955

Epoch: 6| Step: 13
Training loss: 2.720275538597128
Validation loss: 2.6957161559358003

Epoch: 54| Step: 0
Training loss: 3.2033491847042694
Validation loss: 2.699419425427438

Epoch: 6| Step: 1
Training loss: 2.7614294437454716
Validation loss: 2.6999887698633867

Epoch: 6| Step: 2
Training loss: 2.9256537986467457
Validation loss: 2.6982441998430233

Epoch: 6| Step: 3
Training loss: 3.1983250824180938
Validation loss: 2.6958083124903625

Epoch: 6| Step: 4
Training loss: 2.9187054910472274
Validation loss: 2.6944363485432525

Epoch: 6| Step: 5
Training loss: 3.369898861688982
Validation loss: 2.693896641335024

Epoch: 6| Step: 6
Training loss: 2.9037477940104757
Validation loss: 2.6933268681231515

Epoch: 6| Step: 7
Training loss: 3.0872095504237382
Validation loss: 2.690159255875921

Epoch: 6| Step: 8
Training loss: 2.4767334695520264
Validation loss: 2.688284492130127

Epoch: 6| Step: 9
Training loss: 2.8569459029841857
Validation loss: 2.687381013915315

Epoch: 6| Step: 10
Training loss: 2.5863973433429304
Validation loss: 2.690081122650029

Epoch: 6| Step: 11
Training loss: 3.5568745686462604
Validation loss: 2.686302524966395

Epoch: 6| Step: 12
Training loss: 3.3033581668550314
Validation loss: 2.6888177430823315

Epoch: 6| Step: 13
Training loss: 3.061279053493715
Validation loss: 2.686600781031375

Epoch: 55| Step: 0
Training loss: 2.8654417289276504
Validation loss: 2.6859086894664963

Epoch: 6| Step: 1
Training loss: 2.9014718760038347
Validation loss: 2.698646101551479

Epoch: 6| Step: 2
Training loss: 2.863438787979391
Validation loss: 2.6942764952002314

Epoch: 6| Step: 3
Training loss: 2.8199068660101507
Validation loss: 2.7062056413450124

Epoch: 6| Step: 4
Training loss: 2.9467156505684726
Validation loss: 2.726966426270068

Epoch: 6| Step: 5
Training loss: 3.029819898383101
Validation loss: 2.730081774127586

Epoch: 6| Step: 6
Training loss: 3.0016895940463844
Validation loss: 2.7220271332012094

Epoch: 6| Step: 7
Training loss: 3.290780893891534
Validation loss: 2.719974839275403

Epoch: 6| Step: 8
Training loss: 3.4053211870666416
Validation loss: 2.6978055666861

Epoch: 6| Step: 9
Training loss: 2.643226290295669
Validation loss: 2.6871606078766597

Epoch: 6| Step: 10
Training loss: 2.5025880768755235
Validation loss: 2.6817194238144517

Epoch: 6| Step: 11
Training loss: 3.4374987515533952
Validation loss: 2.682459431957256

Epoch: 6| Step: 12
Training loss: 3.394625365046717
Validation loss: 2.6869520586043794

Epoch: 6| Step: 13
Training loss: 3.1324511388574128
Validation loss: 2.689520000180641

Epoch: 56| Step: 0
Training loss: 3.2893428728294927
Validation loss: 2.6890753716820015

Epoch: 6| Step: 1
Training loss: 3.4899148052933278
Validation loss: 2.6910759376830113

Epoch: 6| Step: 2
Training loss: 3.662780537455659
Validation loss: 2.688061739647924

Epoch: 6| Step: 3
Training loss: 2.8903991610996984
Validation loss: 2.693343218460673

Epoch: 6| Step: 4
Training loss: 3.073284545257429
Validation loss: 2.6903351683568193

Epoch: 6| Step: 5
Training loss: 3.2425006025868184
Validation loss: 2.6923670290714568

Epoch: 6| Step: 6
Training loss: 3.0583185727406828
Validation loss: 2.6888950272940946

Epoch: 6| Step: 7
Training loss: 2.9090395429801346
Validation loss: 2.6886901757493873

Epoch: 6| Step: 8
Training loss: 2.960289071376037
Validation loss: 2.697478735171826

Epoch: 6| Step: 9
Training loss: 2.562602157417282
Validation loss: 2.693814252124182

Epoch: 6| Step: 10
Training loss: 3.2212425876660933
Validation loss: 2.6978519888213217

Epoch: 6| Step: 11
Training loss: 2.732705614847123
Validation loss: 2.6888649210486966

Epoch: 6| Step: 12
Training loss: 2.4467493290497337
Validation loss: 2.691731802580437

Epoch: 6| Step: 13
Training loss: 2.003903513529138
Validation loss: 2.7007284177302378

Epoch: 57| Step: 0
Training loss: 3.5333537359068474
Validation loss: 2.7082979324589243

Epoch: 6| Step: 1
Training loss: 3.126278272498654
Validation loss: 2.6918598990946534

Epoch: 6| Step: 2
Training loss: 2.4679585407428717
Validation loss: 2.6739457755769434

Epoch: 6| Step: 3
Training loss: 3.3389623003051243
Validation loss: 2.671239988893204

Epoch: 6| Step: 4
Training loss: 3.2338710521311023
Validation loss: 2.6715534935243834

Epoch: 6| Step: 5
Training loss: 2.9736049105833824
Validation loss: 2.6720300953372313

Epoch: 6| Step: 6
Training loss: 2.4277540161614977
Validation loss: 2.6723892349364853

Epoch: 6| Step: 7
Training loss: 2.8742056039362827
Validation loss: 2.6799971830487617

Epoch: 6| Step: 8
Training loss: 3.110194879295319
Validation loss: 2.677969979686986

Epoch: 6| Step: 9
Training loss: 3.230743433426646
Validation loss: 2.6746558107402736

Epoch: 6| Step: 10
Training loss: 2.605155228220107
Validation loss: 2.6764858490920824

Epoch: 6| Step: 11
Training loss: 3.1051389123185653
Validation loss: 2.6718397576546233

Epoch: 6| Step: 12
Training loss: 3.4239650248497053
Validation loss: 2.671864647069549

Epoch: 6| Step: 13
Training loss: 2.275674145761644
Validation loss: 2.66883040777707

Epoch: 58| Step: 0
Training loss: 3.1271272666804917
Validation loss: 2.667903446705181

Epoch: 6| Step: 1
Training loss: 2.5446491461272194
Validation loss: 2.6684260483232833

Epoch: 6| Step: 2
Training loss: 3.361272515519083
Validation loss: 2.686312079781669

Epoch: 6| Step: 3
Training loss: 3.3441641007454828
Validation loss: 2.6965603292097002

Epoch: 6| Step: 4
Training loss: 3.2280733944515294
Validation loss: 2.6927158597353564

Epoch: 6| Step: 5
Training loss: 2.9665866398107954
Validation loss: 2.67725728241005

Epoch: 6| Step: 6
Training loss: 3.504456815980651
Validation loss: 2.670923922144726

Epoch: 6| Step: 7
Training loss: 2.7103670163094415
Validation loss: 2.667252226023007

Epoch: 6| Step: 8
Training loss: 3.105689390009767
Validation loss: 2.663416320440364

Epoch: 6| Step: 9
Training loss: 3.212412845601944
Validation loss: 2.6671405327624917

Epoch: 6| Step: 10
Training loss: 2.797365795526558
Validation loss: 2.669730790689928

Epoch: 6| Step: 11
Training loss: 3.384383543783941
Validation loss: 2.6736674844372237

Epoch: 6| Step: 12
Training loss: 2.39846930964248
Validation loss: 2.6688469470924043

Epoch: 6| Step: 13
Training loss: 1.5164472571463423
Validation loss: 2.6716720963607923

Epoch: 59| Step: 0
Training loss: 2.4159800990213447
Validation loss: 2.673535422880449

Epoch: 6| Step: 1
Training loss: 2.597437340253225
Validation loss: 2.673144245514933

Epoch: 6| Step: 2
Training loss: 2.905162648885513
Validation loss: 2.661354191657857

Epoch: 6| Step: 3
Training loss: 3.0024582010451764
Validation loss: 2.6631135314635475

Epoch: 6| Step: 4
Training loss: 2.7992662830879116
Validation loss: 2.6624819985504806

Epoch: 6| Step: 5
Training loss: 3.2900290620673927
Validation loss: 2.6619837308776524

Epoch: 6| Step: 6
Training loss: 3.1099488002082913
Validation loss: 2.6638356057659456

Epoch: 6| Step: 7
Training loss: 3.545389948436506
Validation loss: 2.6639164363822783

Epoch: 6| Step: 8
Training loss: 2.773230660475903
Validation loss: 2.665740389332203

Epoch: 6| Step: 9
Training loss: 2.849556496896299
Validation loss: 2.6753321064175375

Epoch: 6| Step: 10
Training loss: 2.7768707087155433
Validation loss: 2.6763789416673096

Epoch: 6| Step: 11
Training loss: 3.6562955152498855
Validation loss: 2.6794395421746775

Epoch: 6| Step: 12
Training loss: 2.802302289347123
Validation loss: 2.662417590017363

Epoch: 6| Step: 13
Training loss: 3.6618381409971983
Validation loss: 2.6578950260298373

Epoch: 60| Step: 0
Training loss: 2.517500373817575
Validation loss: 2.659615599337554

Epoch: 6| Step: 1
Training loss: 3.156545946202247
Validation loss: 2.6562537852579418

Epoch: 6| Step: 2
Training loss: 2.7155085566130737
Validation loss: 2.6565401096188537

Epoch: 6| Step: 3
Training loss: 2.525189243438884
Validation loss: 2.658892230044784

Epoch: 6| Step: 4
Training loss: 2.8288448534615775
Validation loss: 2.6564430924264677

Epoch: 6| Step: 5
Training loss: 2.5347868146170875
Validation loss: 2.66174940314831

Epoch: 6| Step: 6
Training loss: 3.441891587291708
Validation loss: 2.6625151058810133

Epoch: 6| Step: 7
Training loss: 3.189082631669523
Validation loss: 2.6538977537773496

Epoch: 6| Step: 8
Training loss: 3.3556210857445974
Validation loss: 2.653998653455262

Epoch: 6| Step: 9
Training loss: 3.0144938981384692
Validation loss: 2.655576862165576

Epoch: 6| Step: 10
Training loss: 3.3420816698122913
Validation loss: 2.657494890133646

Epoch: 6| Step: 11
Training loss: 3.3832364774724217
Validation loss: 2.660626469127049

Epoch: 6| Step: 12
Training loss: 2.8214077077856445
Validation loss: 2.658100463710428

Epoch: 6| Step: 13
Training loss: 2.8019247660151727
Validation loss: 2.664943213766402

Epoch: 61| Step: 0
Training loss: 2.340923283189678
Validation loss: 2.6968530571336395

Epoch: 6| Step: 1
Training loss: 2.3588568516370154
Validation loss: 2.7148895427423967

Epoch: 6| Step: 2
Training loss: 2.6605900930238997
Validation loss: 2.748704038113916

Epoch: 6| Step: 3
Training loss: 3.0230261549958617
Validation loss: 2.7396548569986434

Epoch: 6| Step: 4
Training loss: 3.0094891519574403
Validation loss: 2.7056048643800756

Epoch: 6| Step: 5
Training loss: 3.3153994843985095
Validation loss: 2.660503986863253

Epoch: 6| Step: 6
Training loss: 2.9180328076134776
Validation loss: 2.65188533826641

Epoch: 6| Step: 7
Training loss: 3.2222744802278616
Validation loss: 2.6491370226374764

Epoch: 6| Step: 8
Training loss: 3.190820946126827
Validation loss: 2.651819054021599

Epoch: 6| Step: 9
Training loss: 3.7614758691385126
Validation loss: 2.6533701728321075

Epoch: 6| Step: 10
Training loss: 3.077797499531137
Validation loss: 2.6542363525006136

Epoch: 6| Step: 11
Training loss: 3.0012638290957327
Validation loss: 2.654903416541625

Epoch: 6| Step: 12
Training loss: 2.483723681021992
Validation loss: 2.6563196451803535

Epoch: 6| Step: 13
Training loss: 3.727092073507422
Validation loss: 2.6581572883226454

Epoch: 62| Step: 0
Training loss: 3.211180740387642
Validation loss: 2.6536552529424102

Epoch: 6| Step: 1
Training loss: 3.186966795361434
Validation loss: 2.6523222034304146

Epoch: 6| Step: 2
Training loss: 3.021056348965217
Validation loss: 2.6498637457111855

Epoch: 6| Step: 3
Training loss: 3.070197571600582
Validation loss: 2.648896031275726

Epoch: 6| Step: 4
Training loss: 2.9180350953593797
Validation loss: 2.6480088679173193

Epoch: 6| Step: 5
Training loss: 2.750743592038899
Validation loss: 2.6464838945264018

Epoch: 6| Step: 6
Training loss: 2.703847446810748
Validation loss: 2.6470102262489665

Epoch: 6| Step: 7
Training loss: 3.100712349785262
Validation loss: 2.645646317738855

Epoch: 6| Step: 8
Training loss: 3.132758009286861
Validation loss: 2.644168653377434

Epoch: 6| Step: 9
Training loss: 3.1002585026418563
Validation loss: 2.6476603933701517

Epoch: 6| Step: 10
Training loss: 3.2592313681799463
Validation loss: 2.6531355143336217

Epoch: 6| Step: 11
Training loss: 2.942574845158633
Validation loss: 2.661069527376199

Epoch: 6| Step: 12
Training loss: 2.6104239907939566
Validation loss: 2.6645487622222714

Epoch: 6| Step: 13
Training loss: 2.5074037593122362
Validation loss: 2.6721768350548456

Epoch: 63| Step: 0
Training loss: 3.1513936668491658
Validation loss: 2.6854136048005173

Epoch: 6| Step: 1
Training loss: 2.390245095777712
Validation loss: 2.671850867727043

Epoch: 6| Step: 2
Training loss: 2.697562254575336
Validation loss: 2.653108045117341

Epoch: 6| Step: 3
Training loss: 2.6589870936499067
Validation loss: 2.656277166489449

Epoch: 6| Step: 4
Training loss: 2.839077138994231
Validation loss: 2.6450336689316885

Epoch: 6| Step: 5
Training loss: 3.7583006226553333
Validation loss: 2.640876373114354

Epoch: 6| Step: 6
Training loss: 2.980558181560869
Validation loss: 2.6411003776610924

Epoch: 6| Step: 7
Training loss: 2.3147355691979286
Validation loss: 2.6394134973310157

Epoch: 6| Step: 8
Training loss: 2.936090658841037
Validation loss: 2.637254324192476

Epoch: 6| Step: 9
Training loss: 3.2248864797085237
Validation loss: 2.6383835036762924

Epoch: 6| Step: 10
Training loss: 3.1429189019513633
Validation loss: 2.6380358275869793

Epoch: 6| Step: 11
Training loss: 3.1822343603656837
Validation loss: 2.6369421588618476

Epoch: 6| Step: 12
Training loss: 2.848245274622461
Validation loss: 2.639279155517247

Epoch: 6| Step: 13
Training loss: 3.4632450445215857
Validation loss: 2.6445911667453177

Epoch: 64| Step: 0
Training loss: 2.8198727082546258
Validation loss: 2.6387858837197466

Epoch: 6| Step: 1
Training loss: 3.2300453877286475
Validation loss: 2.6409296096840236

Epoch: 6| Step: 2
Training loss: 3.4736457161694543
Validation loss: 2.6494978265810714

Epoch: 6| Step: 3
Training loss: 3.1952626567208164
Validation loss: 2.6418348883859095

Epoch: 6| Step: 4
Training loss: 2.751274333813315
Validation loss: 2.640881731669603

Epoch: 6| Step: 5
Training loss: 3.200286798738083
Validation loss: 2.638125312238559

Epoch: 6| Step: 6
Training loss: 2.35752179456327
Validation loss: 2.637899419434236

Epoch: 6| Step: 7
Training loss: 2.4547521940820394
Validation loss: 2.6384096648155553

Epoch: 6| Step: 8
Training loss: 3.1221627134336343
Validation loss: 2.6468298265013313

Epoch: 6| Step: 9
Training loss: 2.96335843038784
Validation loss: 2.633816781870118

Epoch: 6| Step: 10
Training loss: 2.719070240321452
Validation loss: 2.6321241305884877

Epoch: 6| Step: 11
Training loss: 2.6305055557363426
Validation loss: 2.626617206932148

Epoch: 6| Step: 12
Training loss: 3.6206928841963277
Validation loss: 2.625823124805942

Epoch: 6| Step: 13
Training loss: 2.679479474147987
Validation loss: 2.626744157218498

Epoch: 65| Step: 0
Training loss: 3.0623486539851164
Validation loss: 2.630977729996179

Epoch: 6| Step: 1
Training loss: 3.0282590602177706
Validation loss: 2.632304493637956

Epoch: 6| Step: 2
Training loss: 2.613145947339327
Validation loss: 2.6319333873872988

Epoch: 6| Step: 3
Training loss: 2.9547907253976544
Validation loss: 2.6339224423811416

Epoch: 6| Step: 4
Training loss: 3.117162259795605
Validation loss: 2.6333402022846815

Epoch: 6| Step: 5
Training loss: 3.260788543910903
Validation loss: 2.6347586232453275

Epoch: 6| Step: 6
Training loss: 2.8047702957726037
Validation loss: 2.6332485202710343

Epoch: 6| Step: 7
Training loss: 3.289885284371808
Validation loss: 2.643057766411731

Epoch: 6| Step: 8
Training loss: 2.8063954542903993
Validation loss: 2.6358362250014116

Epoch: 6| Step: 9
Training loss: 3.230772509241362
Validation loss: 2.6304520506973676

Epoch: 6| Step: 10
Training loss: 2.6699767033850037
Validation loss: 2.6299216877047873

Epoch: 6| Step: 11
Training loss: 2.3176048227119765
Validation loss: 2.627338699727683

Epoch: 6| Step: 12
Training loss: 3.151774037060474
Validation loss: 2.625698393204015

Epoch: 6| Step: 13
Training loss: 3.4614659717501173
Validation loss: 2.6261150269434865

Epoch: 66| Step: 0
Training loss: 3.219210101084854
Validation loss: 2.624688481110649

Epoch: 6| Step: 1
Training loss: 2.780277553671874
Validation loss: 2.6258773265405915

Epoch: 6| Step: 2
Training loss: 2.998596498886565
Validation loss: 2.623021127507261

Epoch: 6| Step: 3
Training loss: 3.24014489968385
Validation loss: 2.6221621546187035

Epoch: 6| Step: 4
Training loss: 3.083539663748491
Validation loss: 2.628561642906817

Epoch: 6| Step: 5
Training loss: 2.8061566343684574
Validation loss: 2.6379007780791706

Epoch: 6| Step: 6
Training loss: 3.1673226597254893
Validation loss: 2.658100316147522

Epoch: 6| Step: 7
Training loss: 2.5484878956052803
Validation loss: 2.6643506601167926

Epoch: 6| Step: 8
Training loss: 3.3829609263500853
Validation loss: 2.650024157549629

Epoch: 6| Step: 9
Training loss: 2.977898245441754
Validation loss: 2.620765641169053

Epoch: 6| Step: 10
Training loss: 2.2298850449838827
Validation loss: 2.621989370036909

Epoch: 6| Step: 11
Training loss: 2.805616474644282
Validation loss: 2.6272898070833572

Epoch: 6| Step: 12
Training loss: 3.0668957362106575
Validation loss: 2.6309240065441366

Epoch: 6| Step: 13
Training loss: 3.5151979992422837
Validation loss: 2.637721255952463

Epoch: 67| Step: 0
Training loss: 3.2274255960576967
Validation loss: 2.6565621218596682

Epoch: 6| Step: 1
Training loss: 3.248650784300301
Validation loss: 2.6727566691925824

Epoch: 6| Step: 2
Training loss: 2.948448393801086
Validation loss: 2.6838699210417705

Epoch: 6| Step: 3
Training loss: 3.159941978404788
Validation loss: 2.6776201394591483

Epoch: 6| Step: 4
Training loss: 3.2216537858442713
Validation loss: 2.6660750916042297

Epoch: 6| Step: 5
Training loss: 2.9488562354808314
Validation loss: 2.659668276714432

Epoch: 6| Step: 6
Training loss: 2.6570027799351297
Validation loss: 2.6605418066209507

Epoch: 6| Step: 7
Training loss: 3.391084841999629
Validation loss: 2.6533512152915733

Epoch: 6| Step: 8
Training loss: 3.1956433262514956
Validation loss: 2.6290957155514314

Epoch: 6| Step: 9
Training loss: 3.0604561973045974
Validation loss: 2.6309840051637017

Epoch: 6| Step: 10
Training loss: 2.833688227548554
Validation loss: 2.6561304961894447

Epoch: 6| Step: 11
Training loss: 2.9113675252893736
Validation loss: 2.685320856660833

Epoch: 6| Step: 12
Training loss: 2.0918170489879766
Validation loss: 2.693396028111643

Epoch: 6| Step: 13
Training loss: 3.04914685183378
Validation loss: 2.6936128773913803

Epoch: 68| Step: 0
Training loss: 2.9225171041518405
Validation loss: 2.7238893797624906

Epoch: 6| Step: 1
Training loss: 2.9052363443010205
Validation loss: 2.74411660040353

Epoch: 6| Step: 2
Training loss: 2.88564750399871
Validation loss: 2.707022152811586

Epoch: 6| Step: 3
Training loss: 3.118899073888969
Validation loss: 2.695396310039161

Epoch: 6| Step: 4
Training loss: 3.045229423411467
Validation loss: 2.6733792602971613

Epoch: 6| Step: 5
Training loss: 3.2180735053089276
Validation loss: 2.6488236696823564

Epoch: 6| Step: 6
Training loss: 2.708066711995824
Validation loss: 2.6504789390555548

Epoch: 6| Step: 7
Training loss: 2.82704217740722
Validation loss: 2.6412385267981806

Epoch: 6| Step: 8
Training loss: 3.141398016846025
Validation loss: 2.6397012268379307

Epoch: 6| Step: 9
Training loss: 3.2057338604039223
Validation loss: 2.6368621094446656

Epoch: 6| Step: 10
Training loss: 3.4527232769277316
Validation loss: 2.6415458258587465

Epoch: 6| Step: 11
Training loss: 2.699295771558485
Validation loss: 2.6415978901736943

Epoch: 6| Step: 12
Training loss: 2.7781136648764293
Validation loss: 2.642267273630766

Epoch: 6| Step: 13
Training loss: 2.5079927468810994
Validation loss: 2.6442175907110945

Epoch: 69| Step: 0
Training loss: 2.8616897302437625
Validation loss: 2.636213731123531

Epoch: 6| Step: 1
Training loss: 3.4262778467036936
Validation loss: 2.638288159655483

Epoch: 6| Step: 2
Training loss: 2.116404821565075
Validation loss: 2.6383159065765813

Epoch: 6| Step: 3
Training loss: 3.4309835917681712
Validation loss: 2.6319679533524805

Epoch: 6| Step: 4
Training loss: 2.4767307741776836
Validation loss: 2.6360547944720056

Epoch: 6| Step: 5
Training loss: 3.4164346445588554
Validation loss: 2.6320209990067447

Epoch: 6| Step: 6
Training loss: 2.50351506121756
Validation loss: 2.639971594062589

Epoch: 6| Step: 7
Training loss: 3.2338763603587126
Validation loss: 2.6332295794807687

Epoch: 6| Step: 8
Training loss: 2.659199233023559
Validation loss: 2.6392964861303985

Epoch: 6| Step: 9
Training loss: 3.5337211941819135
Validation loss: 2.643601703482165

Epoch: 6| Step: 10
Training loss: 2.9162765968702495
Validation loss: 2.641499228460251

Epoch: 6| Step: 11
Training loss: 2.895382487011647
Validation loss: 2.633798994707591

Epoch: 6| Step: 12
Training loss: 2.6965107341363845
Validation loss: 2.631765040449287

Epoch: 6| Step: 13
Training loss: 3.179377960209699
Validation loss: 2.632895710473893

Epoch: 70| Step: 0
Training loss: 3.2314991720258432
Validation loss: 2.64430982700293

Epoch: 6| Step: 1
Training loss: 2.289754821445734
Validation loss: 2.6311896898540814

Epoch: 6| Step: 2
Training loss: 3.2386932295045896
Validation loss: 2.6279883312064864

Epoch: 6| Step: 3
Training loss: 2.833702699109149
Validation loss: 2.626213092762404

Epoch: 6| Step: 4
Training loss: 3.1431542076563646
Validation loss: 2.630326875841713

Epoch: 6| Step: 5
Training loss: 2.9950350366749707
Validation loss: 2.6236240093293333

Epoch: 6| Step: 6
Training loss: 2.997983572723396
Validation loss: 2.622709103788439

Epoch: 6| Step: 7
Training loss: 2.997109928409973
Validation loss: 2.6252217216237574

Epoch: 6| Step: 8
Training loss: 2.700738106610044
Validation loss: 2.62252253031148

Epoch: 6| Step: 9
Training loss: 3.049923823921849
Validation loss: 2.623071028193731

Epoch: 6| Step: 10
Training loss: 3.141424428436119
Validation loss: 2.6317152763625526

Epoch: 6| Step: 11
Training loss: 3.0427258532911132
Validation loss: 2.644693224110149

Epoch: 6| Step: 12
Training loss: 2.2821280474899694
Validation loss: 2.652757865955447

Epoch: 6| Step: 13
Training loss: 3.788155673339804
Validation loss: 2.6583333665979767

Epoch: 71| Step: 0
Training loss: 2.60780186545259
Validation loss: 2.631368429045995

Epoch: 6| Step: 1
Training loss: 2.903799685292477
Validation loss: 2.6206124432647857

Epoch: 6| Step: 2
Training loss: 2.7829293313794636
Validation loss: 2.6114481043990265

Epoch: 6| Step: 3
Training loss: 2.7678934912338478
Validation loss: 2.6116067137030394

Epoch: 6| Step: 4
Training loss: 3.117392473484889
Validation loss: 2.6304892757982827

Epoch: 6| Step: 5
Training loss: 2.845226533314862
Validation loss: 2.619264715572851

Epoch: 6| Step: 6
Training loss: 2.942780314327516
Validation loss: 2.6235841994803715

Epoch: 6| Step: 7
Training loss: 2.764985091322703
Validation loss: 2.6187451823971917

Epoch: 6| Step: 8
Training loss: 2.6209060897391363
Validation loss: 2.6133121043710217

Epoch: 6| Step: 9
Training loss: 2.9324464548203064
Validation loss: 2.609122268181049

Epoch: 6| Step: 10
Training loss: 3.6768594877209884
Validation loss: 2.6083079211979148

Epoch: 6| Step: 11
Training loss: 3.2810395672850157
Validation loss: 2.606272026963008

Epoch: 6| Step: 12
Training loss: 3.3195696549540568
Validation loss: 2.6132693150721416

Epoch: 6| Step: 13
Training loss: 2.6283362849123613
Validation loss: 2.612771153419545

Epoch: 72| Step: 0
Training loss: 3.0573980690909157
Validation loss: 2.6093292831631842

Epoch: 6| Step: 1
Training loss: 2.9956891558832934
Validation loss: 2.620114082892086

Epoch: 6| Step: 2
Training loss: 3.0064167698147313
Validation loss: 2.6227293316416356

Epoch: 6| Step: 3
Training loss: 3.328267555586513
Validation loss: 2.624081292165245

Epoch: 6| Step: 4
Training loss: 2.716773092685492
Validation loss: 2.633420500890392

Epoch: 6| Step: 5
Training loss: 3.168112491681558
Validation loss: 2.6239404937762085

Epoch: 6| Step: 6
Training loss: 3.1807079880199174
Validation loss: 2.6175561984675646

Epoch: 6| Step: 7
Training loss: 2.5952557708584942
Validation loss: 2.6016732227763932

Epoch: 6| Step: 8
Training loss: 2.766249763912806
Validation loss: 2.599173383039665

Epoch: 6| Step: 9
Training loss: 3.021062978149303
Validation loss: 2.5987461460588865

Epoch: 6| Step: 10
Training loss: 3.2541058354343684
Validation loss: 2.6043045496380364

Epoch: 6| Step: 11
Training loss: 2.5469842430978296
Validation loss: 2.601828115208823

Epoch: 6| Step: 12
Training loss: 2.7181401061942805
Validation loss: 2.6018408159890725

Epoch: 6| Step: 13
Training loss: 2.6787001678773206
Validation loss: 2.5977008320759722

Epoch: 73| Step: 0
Training loss: 3.0146849753313
Validation loss: 2.607144589420849

Epoch: 6| Step: 1
Training loss: 2.6167620412692174
Validation loss: 2.6025891756375534

Epoch: 6| Step: 2
Training loss: 2.3843720882293002
Validation loss: 2.609239517377976

Epoch: 6| Step: 3
Training loss: 2.7674689745865395
Validation loss: 2.6197940889440816

Epoch: 6| Step: 4
Training loss: 2.9886965793380846
Validation loss: 2.62497644662911

Epoch: 6| Step: 5
Training loss: 2.8256989078690125
Validation loss: 2.646577976567816

Epoch: 6| Step: 6
Training loss: 3.180976775002142
Validation loss: 2.6466402831074323

Epoch: 6| Step: 7
Training loss: 3.212087309338353
Validation loss: 2.622362515060197

Epoch: 6| Step: 8
Training loss: 3.320168884761714
Validation loss: 2.602654064974208

Epoch: 6| Step: 9
Training loss: 3.1849884909716817
Validation loss: 2.6030051649006767

Epoch: 6| Step: 10
Training loss: 2.4638100948968895
Validation loss: 2.5890667430807692

Epoch: 6| Step: 11
Training loss: 3.359846782823993
Validation loss: 2.5921907973212734

Epoch: 6| Step: 12
Training loss: 2.9833281113847034
Validation loss: 2.59098127987303

Epoch: 6| Step: 13
Training loss: 2.4288587720763806
Validation loss: 2.5920309747149837

Epoch: 74| Step: 0
Training loss: 2.9808135026999625
Validation loss: 2.5906944676166805

Epoch: 6| Step: 1
Training loss: 2.6364748693636146
Validation loss: 2.5933194110069704

Epoch: 6| Step: 2
Training loss: 2.9712483384156223
Validation loss: 2.5944478746365323

Epoch: 6| Step: 3
Training loss: 2.0968611647125304
Validation loss: 2.6087957462238314

Epoch: 6| Step: 4
Training loss: 3.2239092616145424
Validation loss: 2.601631492028323

Epoch: 6| Step: 5
Training loss: 3.27292645455169
Validation loss: 2.5996561867875037

Epoch: 6| Step: 6
Training loss: 2.9222320501680383
Validation loss: 2.597490324213397

Epoch: 6| Step: 7
Training loss: 3.048676569493461
Validation loss: 2.601112309772272

Epoch: 6| Step: 8
Training loss: 2.4457118284164734
Validation loss: 2.602135791658814

Epoch: 6| Step: 9
Training loss: 3.297598664468479
Validation loss: 2.608334092079117

Epoch: 6| Step: 10
Training loss: 3.058048360438447
Validation loss: 2.5985997140604433

Epoch: 6| Step: 11
Training loss: 2.6070769464033416
Validation loss: 2.589269516956509

Epoch: 6| Step: 12
Training loss: 3.6960858751534427
Validation loss: 2.5887671855812546

Epoch: 6| Step: 13
Training loss: 2.1972829860425245
Validation loss: 2.5841940168181337

Epoch: 75| Step: 0
Training loss: 2.7102589926182095
Validation loss: 2.582761409127577

Epoch: 6| Step: 1
Training loss: 2.640731719078255
Validation loss: 2.5846941364454117

Epoch: 6| Step: 2
Training loss: 3.301800127048803
Validation loss: 2.589517538471836

Epoch: 6| Step: 3
Training loss: 3.213634982163342
Validation loss: 2.5851287137131997

Epoch: 6| Step: 4
Training loss: 2.9580439215565937
Validation loss: 2.58653422562358

Epoch: 6| Step: 5
Training loss: 3.074972174293723
Validation loss: 2.5987591174014857

Epoch: 6| Step: 6
Training loss: 3.016681703421138
Validation loss: 2.5910797300340858

Epoch: 6| Step: 7
Training loss: 3.235987754147892
Validation loss: 2.5872954547476175

Epoch: 6| Step: 8
Training loss: 2.6965091426219745
Validation loss: 2.618444094494258

Epoch: 6| Step: 9
Training loss: 3.0545726081334807
Validation loss: 2.6757100887969387

Epoch: 6| Step: 10
Training loss: 2.7561882790642005
Validation loss: 2.6182616403601773

Epoch: 6| Step: 11
Training loss: 2.940901552142147
Validation loss: 2.600142610076488

Epoch: 6| Step: 12
Training loss: 2.7080448779524757
Validation loss: 2.5820025953974333

Epoch: 6| Step: 13
Training loss: 2.758429785095676
Validation loss: 2.5847290405631496

Epoch: 76| Step: 0
Training loss: 2.7840293113108188
Validation loss: 2.583920646921314

Epoch: 6| Step: 1
Training loss: 2.5992867995476163
Validation loss: 2.5920119429069093

Epoch: 6| Step: 2
Training loss: 3.2681116009523445
Validation loss: 2.60355616610121

Epoch: 6| Step: 3
Training loss: 2.5827546138011415
Validation loss: 2.6049424707036155

Epoch: 6| Step: 4
Training loss: 3.2994886406710044
Validation loss: 2.5958300060071213

Epoch: 6| Step: 5
Training loss: 3.5184221457134415
Validation loss: 2.5852113943622546

Epoch: 6| Step: 6
Training loss: 2.980163478591545
Validation loss: 2.580584631358677

Epoch: 6| Step: 7
Training loss: 3.071208483392476
Validation loss: 2.5825781494100837

Epoch: 6| Step: 8
Training loss: 3.1127892539806266
Validation loss: 2.5821575607812663

Epoch: 6| Step: 9
Training loss: 3.4786110318190735
Validation loss: 2.615240778127877

Epoch: 6| Step: 10
Training loss: 2.7490569144831074
Validation loss: 2.634049308234542

Epoch: 6| Step: 11
Training loss: 1.7925733076185881
Validation loss: 2.6864758071210573

Epoch: 6| Step: 12
Training loss: 2.585962024583952
Validation loss: 2.7185778527408426

Epoch: 6| Step: 13
Training loss: 3.304199759921727
Validation loss: 2.6916246863572018

Epoch: 77| Step: 0
Training loss: 2.868322495996578
Validation loss: 2.6069081911061116

Epoch: 6| Step: 1
Training loss: 3.343607961899968
Validation loss: 2.5823817655680608

Epoch: 6| Step: 2
Training loss: 2.9789872193256004
Validation loss: 2.583901257232633

Epoch: 6| Step: 3
Training loss: 2.8286705544677506
Validation loss: 2.6311541393241638

Epoch: 6| Step: 4
Training loss: 3.2802834676740815
Validation loss: 2.589105381574226

Epoch: 6| Step: 5
Training loss: 2.9520526533522506
Validation loss: 2.5830368737900224

Epoch: 6| Step: 6
Training loss: 2.420467435287169
Validation loss: 2.5879309482571258

Epoch: 6| Step: 7
Training loss: 2.911736344841359
Validation loss: 2.5919299618641976

Epoch: 6| Step: 8
Training loss: 2.5449671239921603
Validation loss: 2.5907544984150817

Epoch: 6| Step: 9
Training loss: 2.9718768868906666
Validation loss: 2.587088271068185

Epoch: 6| Step: 10
Training loss: 3.0609659517844032
Validation loss: 2.5899334218903007

Epoch: 6| Step: 11
Training loss: 2.705004352982098
Validation loss: 2.591914433173554

Epoch: 6| Step: 12
Training loss: 2.901852962846491
Validation loss: 2.5995490457300736

Epoch: 6| Step: 13
Training loss: 3.7047881564427745
Validation loss: 2.6183337303941423

Epoch: 78| Step: 0
Training loss: 3.6740889996592343
Validation loss: 2.59898089277981

Epoch: 6| Step: 1
Training loss: 2.905241432334216
Validation loss: 2.5865744610015327

Epoch: 6| Step: 2
Training loss: 3.0184202531431836
Validation loss: 2.575925290462099

Epoch: 6| Step: 3
Training loss: 3.486802286339304
Validation loss: 2.573629844307262

Epoch: 6| Step: 4
Training loss: 2.8197548439112117
Validation loss: 2.5702915843475806

Epoch: 6| Step: 5
Training loss: 2.8200473819296237
Validation loss: 2.5796076841969375

Epoch: 6| Step: 6
Training loss: 3.0175013263892265
Validation loss: 2.5713299850839637

Epoch: 6| Step: 7
Training loss: 2.6028256027765746
Validation loss: 2.5743471141292407

Epoch: 6| Step: 8
Training loss: 2.9203679895410333
Validation loss: 2.571185162372683

Epoch: 6| Step: 9
Training loss: 2.677864188422053
Validation loss: 2.5767496039270137

Epoch: 6| Step: 10
Training loss: 2.7739586568830537
Validation loss: 2.574752571762056

Epoch: 6| Step: 11
Training loss: 2.857984194178618
Validation loss: 2.5705514499976463

Epoch: 6| Step: 12
Training loss: 2.5537761030762964
Validation loss: 2.5710142945247183

Epoch: 6| Step: 13
Training loss: 2.455260689562503
Validation loss: 2.5757962814117845

Epoch: 79| Step: 0
Training loss: 3.29773502070507
Validation loss: 2.5788568426877676

Epoch: 6| Step: 1
Training loss: 2.6499863318324732
Validation loss: 2.575341763243503

Epoch: 6| Step: 2
Training loss: 2.6136331136027398
Validation loss: 2.5780493144998027

Epoch: 6| Step: 3
Training loss: 2.772275783460543
Validation loss: 2.580823945478217

Epoch: 6| Step: 4
Training loss: 2.978701646342716
Validation loss: 2.5787055472209635

Epoch: 6| Step: 5
Training loss: 2.91113903680985
Validation loss: 2.5723560511797197

Epoch: 6| Step: 6
Training loss: 2.7855246622571785
Validation loss: 2.571961658629487

Epoch: 6| Step: 7
Training loss: 2.7806447259876776
Validation loss: 2.570436827423659

Epoch: 6| Step: 8
Training loss: 2.9839397332699447
Validation loss: 2.566251063715492

Epoch: 6| Step: 9
Training loss: 2.833610820271852
Validation loss: 2.5668232042893537

Epoch: 6| Step: 10
Training loss: 2.66632583546084
Validation loss: 2.563605806513747

Epoch: 6| Step: 11
Training loss: 3.4441090252994915
Validation loss: 2.565337508170679

Epoch: 6| Step: 12
Training loss: 2.7454841989963223
Validation loss: 2.561973988999179

Epoch: 6| Step: 13
Training loss: 3.618083538029378
Validation loss: 2.5671796839617804

Epoch: 80| Step: 0
Training loss: 2.73751415440632
Validation loss: 2.5691672357316944

Epoch: 6| Step: 1
Training loss: 2.9033109508867736
Validation loss: 2.5684027717548914

Epoch: 6| Step: 2
Training loss: 2.6547844826965994
Validation loss: 2.570972607089064

Epoch: 6| Step: 3
Training loss: 2.9354419397620295
Validation loss: 2.5639019034370554

Epoch: 6| Step: 4
Training loss: 2.3657926472328312
Validation loss: 2.5672061323139928

Epoch: 6| Step: 5
Training loss: 3.006203912393606
Validation loss: 2.5703715037639365

Epoch: 6| Step: 6
Training loss: 2.6898841927994983
Validation loss: 2.5785848983598596

Epoch: 6| Step: 7
Training loss: 3.4863586253480254
Validation loss: 2.594113554360244

Epoch: 6| Step: 8
Training loss: 3.224374541910948
Validation loss: 2.612613486162381

Epoch: 6| Step: 9
Training loss: 2.859176545473972
Validation loss: 2.6355784123899633

Epoch: 6| Step: 10
Training loss: 2.633141652708095
Validation loss: 2.699951737191662

Epoch: 6| Step: 11
Training loss: 2.918081176716345
Validation loss: 2.673585447022999

Epoch: 6| Step: 12
Training loss: 3.5350699229791145
Validation loss: 2.6271869790007427

Epoch: 6| Step: 13
Training loss: 2.876017017436183
Validation loss: 2.5728450860012884

Epoch: 81| Step: 0
Training loss: 2.9596598342087415
Validation loss: 2.5600907404653825

Epoch: 6| Step: 1
Training loss: 3.2782163129076562
Validation loss: 2.5581324213016807

Epoch: 6| Step: 2
Training loss: 3.3388547626542
Validation loss: 2.568198294430772

Epoch: 6| Step: 3
Training loss: 3.0377690325616316
Validation loss: 2.5685822371041853

Epoch: 6| Step: 4
Training loss: 2.9733433574741324
Validation loss: 2.564373796913946

Epoch: 6| Step: 5
Training loss: 3.225841968248564
Validation loss: 2.564458141405253

Epoch: 6| Step: 6
Training loss: 2.5474128389281616
Validation loss: 2.56486644568847

Epoch: 6| Step: 7
Training loss: 2.738887703383548
Validation loss: 2.556834809866663

Epoch: 6| Step: 8
Training loss: 2.47797986215286
Validation loss: 2.556193166165623

Epoch: 6| Step: 9
Training loss: 3.0636213157146357
Validation loss: 2.5547965545372997

Epoch: 6| Step: 10
Training loss: 2.5114996593550294
Validation loss: 2.5547209586309787

Epoch: 6| Step: 11
Training loss: 3.088009836210882
Validation loss: 2.561975647076574

Epoch: 6| Step: 12
Training loss: 2.8160349353769005
Validation loss: 2.5728539959955175

Epoch: 6| Step: 13
Training loss: 2.584855697559028
Validation loss: 2.5894355695402815

Epoch: 82| Step: 0
Training loss: 3.2617153875824734
Validation loss: 2.5895097065141695

Epoch: 6| Step: 1
Training loss: 2.8518230162461364
Validation loss: 2.595809001654178

Epoch: 6| Step: 2
Training loss: 3.0007042058316906
Validation loss: 2.583843501033109

Epoch: 6| Step: 3
Training loss: 3.4285006544210725
Validation loss: 2.582091749286522

Epoch: 6| Step: 4
Training loss: 2.8371271837976275
Validation loss: 2.581748710266671

Epoch: 6| Step: 5
Training loss: 3.0647829849555492
Validation loss: 2.5823437372863527

Epoch: 6| Step: 6
Training loss: 2.4507727552612684
Validation loss: 2.5691890156867667

Epoch: 6| Step: 7
Training loss: 2.9680889799141785
Validation loss: 2.5580544566019388

Epoch: 6| Step: 8
Training loss: 2.7216785487024437
Validation loss: 2.5545502690683155

Epoch: 6| Step: 9
Training loss: 3.3362945437039326
Validation loss: 2.553016939516092

Epoch: 6| Step: 10
Training loss: 2.654996508867228
Validation loss: 2.550178173997767

Epoch: 6| Step: 11
Training loss: 2.9798616963493654
Validation loss: 2.548557584563967

Epoch: 6| Step: 12
Training loss: 2.303402196385644
Validation loss: 2.5457768652518737

Epoch: 6| Step: 13
Training loss: 2.4987695526991556
Validation loss: 2.5487356329196755

Epoch: 83| Step: 0
Training loss: 2.8837700470821597
Validation loss: 2.547317969652093

Epoch: 6| Step: 1
Training loss: 3.174961035782227
Validation loss: 2.5559182337346216

Epoch: 6| Step: 2
Training loss: 2.6576290365563184
Validation loss: 2.557344859682994

Epoch: 6| Step: 3
Training loss: 2.758986182808368
Validation loss: 2.5660743925234364

Epoch: 6| Step: 4
Training loss: 2.6004209104369984
Validation loss: 2.554761021709438

Epoch: 6| Step: 5
Training loss: 3.363042204865128
Validation loss: 2.557897190094097

Epoch: 6| Step: 6
Training loss: 3.524245615649373
Validation loss: 2.5589814789784104

Epoch: 6| Step: 7
Training loss: 2.6173345268286954
Validation loss: 2.5546409158886436

Epoch: 6| Step: 8
Training loss: 2.851699616780439
Validation loss: 2.5554736810735954

Epoch: 6| Step: 9
Training loss: 2.67194344059251
Validation loss: 2.5623109173989156

Epoch: 6| Step: 10
Training loss: 3.0456870868882433
Validation loss: 2.5714723551079985

Epoch: 6| Step: 11
Training loss: 3.453907045210268
Validation loss: 2.6002255715015647

Epoch: 6| Step: 12
Training loss: 2.4699341070984473
Validation loss: 2.5690457287923056

Epoch: 6| Step: 13
Training loss: 1.9563014331430382
Validation loss: 2.55219685593121

Epoch: 84| Step: 0
Training loss: 3.2399423937915763
Validation loss: 2.544267627442283

Epoch: 6| Step: 1
Training loss: 2.824683693251148
Validation loss: 2.540027195219117

Epoch: 6| Step: 2
Training loss: 2.773448073675927
Validation loss: 2.5468490199647476

Epoch: 6| Step: 3
Training loss: 2.5024356421427516
Validation loss: 2.541375267744527

Epoch: 6| Step: 4
Training loss: 3.3645516188379685
Validation loss: 2.5466962417286934

Epoch: 6| Step: 5
Training loss: 2.941848458210283
Validation loss: 2.547380707334421

Epoch: 6| Step: 6
Training loss: 2.905188582006594
Validation loss: 2.5445031111384075

Epoch: 6| Step: 7
Training loss: 2.207500468650414
Validation loss: 2.549055865752184

Epoch: 6| Step: 8
Training loss: 3.5806795687852895
Validation loss: 2.555681680255772

Epoch: 6| Step: 9
Training loss: 2.8804356150199557
Validation loss: 2.5819690703002167

Epoch: 6| Step: 10
Training loss: 3.12681069368386
Validation loss: 2.579108425103496

Epoch: 6| Step: 11
Training loss: 2.7085520338130937
Validation loss: 2.5912643602560768

Epoch: 6| Step: 12
Training loss: 2.187934723300508
Validation loss: 2.5733072599595572

Epoch: 6| Step: 13
Training loss: 3.430100261902217
Validation loss: 2.5567646486460656

Epoch: 85| Step: 0
Training loss: 2.5049197426614875
Validation loss: 2.5585515736229594

Epoch: 6| Step: 1
Training loss: 3.0748273351310544
Validation loss: 2.55042564861806

Epoch: 6| Step: 2
Training loss: 2.9356189954963074
Validation loss: 2.557168135092375

Epoch: 6| Step: 3
Training loss: 3.1824747002757943
Validation loss: 2.55042206313319

Epoch: 6| Step: 4
Training loss: 2.375552464526673
Validation loss: 2.5480018436540286

Epoch: 6| Step: 5
Training loss: 2.738172586110694
Validation loss: 2.542843808491069

Epoch: 6| Step: 6
Training loss: 3.7326658798937324
Validation loss: 2.540163375949388

Epoch: 6| Step: 7
Training loss: 2.3393906805851588
Validation loss: 2.536934124330937

Epoch: 6| Step: 8
Training loss: 2.9788348317682964
Validation loss: 2.541780622225061

Epoch: 6| Step: 9
Training loss: 2.903860771309532
Validation loss: 2.540118545005436

Epoch: 6| Step: 10
Training loss: 2.967358072127908
Validation loss: 2.538100429921348

Epoch: 6| Step: 11
Training loss: 2.7179734447380586
Validation loss: 2.540549733009498

Epoch: 6| Step: 12
Training loss: 3.035590770356446
Validation loss: 2.5477475497915227

Epoch: 6| Step: 13
Training loss: 2.9810013001550133
Validation loss: 2.548161178682513

Epoch: 86| Step: 0
Training loss: 2.8644660694511828
Validation loss: 2.5443875594432446

Epoch: 6| Step: 1
Training loss: 3.082395737517494
Validation loss: 2.554364142328279

Epoch: 6| Step: 2
Training loss: 2.49132750211174
Validation loss: 2.5729507614081415

Epoch: 6| Step: 3
Training loss: 2.876292725883564
Validation loss: 2.572848284515404

Epoch: 6| Step: 4
Training loss: 3.178498966866758
Validation loss: 2.5733688978030496

Epoch: 6| Step: 5
Training loss: 2.7924145982433672
Validation loss: 2.5793833515860713

Epoch: 6| Step: 6
Training loss: 2.9211575040264566
Validation loss: 2.566781082234701

Epoch: 6| Step: 7
Training loss: 3.2465263289631396
Validation loss: 2.5755060431633074

Epoch: 6| Step: 8
Training loss: 3.0470449546950595
Validation loss: 2.58397768210267

Epoch: 6| Step: 9
Training loss: 2.7831016120467638
Validation loss: 2.560298094704877

Epoch: 6| Step: 10
Training loss: 2.91675302286826
Validation loss: 2.5677347625954403

Epoch: 6| Step: 11
Training loss: 2.4019064404437196
Validation loss: 2.5597830534443116

Epoch: 6| Step: 12
Training loss: 3.2608025823154274
Validation loss: 2.5640617561622956

Epoch: 6| Step: 13
Training loss: 2.0967259679553947
Validation loss: 2.552628128804981

Epoch: 87| Step: 0
Training loss: 2.3840186896519633
Validation loss: 2.537621945378281

Epoch: 6| Step: 1
Training loss: 3.0438046366274216
Validation loss: 2.534239623575155

Epoch: 6| Step: 2
Training loss: 3.1726793293511544
Validation loss: 2.5301580105560824

Epoch: 6| Step: 3
Training loss: 3.2823687871316847
Validation loss: 2.535487692199738

Epoch: 6| Step: 4
Training loss: 2.6194146089100867
Validation loss: 2.532257948907364

Epoch: 6| Step: 5
Training loss: 2.6610579117899524
Validation loss: 2.5309647501053125

Epoch: 6| Step: 6
Training loss: 2.5371187722352913
Validation loss: 2.5323415732266605

Epoch: 6| Step: 7
Training loss: 3.414274510275727
Validation loss: 2.530357949071776

Epoch: 6| Step: 8
Training loss: 3.133742501212218
Validation loss: 2.530691442994029

Epoch: 6| Step: 9
Training loss: 2.6294563250776237
Validation loss: 2.5375717827814257

Epoch: 6| Step: 10
Training loss: 3.580585150394566
Validation loss: 2.5430824069520237

Epoch: 6| Step: 11
Training loss: 2.679724512317276
Validation loss: 2.543739071747174

Epoch: 6| Step: 12
Training loss: 2.5589894694878974
Validation loss: 2.557426252775667

Epoch: 6| Step: 13
Training loss: 2.1108437405086344
Validation loss: 2.591870437019407

Epoch: 88| Step: 0
Training loss: 3.0191073693827666
Validation loss: 2.616227437104173

Epoch: 6| Step: 1
Training loss: 3.6599600463520847
Validation loss: 2.666438556984743

Epoch: 6| Step: 2
Training loss: 2.552361225387116
Validation loss: 2.6752223048484445

Epoch: 6| Step: 3
Training loss: 2.7001384487683384
Validation loss: 2.6807797930917965

Epoch: 6| Step: 4
Training loss: 2.814508187405945
Validation loss: 2.6244154482882576

Epoch: 6| Step: 5
Training loss: 2.7263974027737707
Validation loss: 2.5659594460693356

Epoch: 6| Step: 6
Training loss: 2.3921512892540746
Validation loss: 2.5303510505012046

Epoch: 6| Step: 7
Training loss: 2.9026506346419145
Validation loss: 2.526653000072251

Epoch: 6| Step: 8
Training loss: 3.1036826317458868
Validation loss: 2.5330951801229498

Epoch: 6| Step: 9
Training loss: 2.1245662022037313
Validation loss: 2.536207250133939

Epoch: 6| Step: 10
Training loss: 2.513692741633476
Validation loss: 2.5484015960678086

Epoch: 6| Step: 11
Training loss: 3.316910165126283
Validation loss: 2.5382303529844137

Epoch: 6| Step: 12
Training loss: 3.3998696302214944
Validation loss: 2.538574680767409

Epoch: 6| Step: 13
Training loss: 3.2604855336156597
Validation loss: 2.532963395539016

Epoch: 89| Step: 0
Training loss: 2.8795827746171114
Validation loss: 2.534915358154229

Epoch: 6| Step: 1
Training loss: 3.221504292218956
Validation loss: 2.541776912590541

Epoch: 6| Step: 2
Training loss: 2.8205555311828348
Validation loss: 2.533742403002342

Epoch: 6| Step: 3
Training loss: 2.9862725581406506
Validation loss: 2.5367920094217418

Epoch: 6| Step: 4
Training loss: 2.5929912698336164
Validation loss: 2.5369660881116767

Epoch: 6| Step: 5
Training loss: 2.8200701242209707
Validation loss: 2.5482062604935276

Epoch: 6| Step: 6
Training loss: 3.2757094335564654
Validation loss: 2.5623659888720645

Epoch: 6| Step: 7
Training loss: 2.8093196265138674
Validation loss: 2.5899176060493225

Epoch: 6| Step: 8
Training loss: 3.400122073730879
Validation loss: 2.6372641996057857

Epoch: 6| Step: 9
Training loss: 2.0235467240594924
Validation loss: 2.5768672526403376

Epoch: 6| Step: 10
Training loss: 2.447278095040057
Validation loss: 2.5413233704885525

Epoch: 6| Step: 11
Training loss: 2.968091068423289
Validation loss: 2.5335887372840795

Epoch: 6| Step: 12
Training loss: 3.0574604531551053
Validation loss: 2.532011858592908

Epoch: 6| Step: 13
Training loss: 2.9096944762621435
Validation loss: 2.5323065716594058

Epoch: 90| Step: 0
Training loss: 3.0837937260478387
Validation loss: 2.527944144278977

Epoch: 6| Step: 1
Training loss: 2.6785071973819674
Validation loss: 2.5352519657019275

Epoch: 6| Step: 2
Training loss: 3.159921908560508
Validation loss: 2.5418226865600806

Epoch: 6| Step: 3
Training loss: 2.753324752991294
Validation loss: 2.5324960201916347

Epoch: 6| Step: 4
Training loss: 3.144211121369656
Validation loss: 2.5355189199409276

Epoch: 6| Step: 5
Training loss: 3.1658341333987905
Validation loss: 2.541086220053644

Epoch: 6| Step: 6
Training loss: 3.20724207827492
Validation loss: 2.544407338408011

Epoch: 6| Step: 7
Training loss: 2.8488125853884245
Validation loss: 2.556144816251426

Epoch: 6| Step: 8
Training loss: 2.408419337161467
Validation loss: 2.5644102162398963

Epoch: 6| Step: 9
Training loss: 3.023866135132017
Validation loss: 2.6512587460218056

Epoch: 6| Step: 10
Training loss: 3.4172422497989565
Validation loss: 2.666872754580638

Epoch: 6| Step: 11
Training loss: 2.307906459995374
Validation loss: 2.57498246300557

Epoch: 6| Step: 12
Training loss: 2.85124627019027
Validation loss: 2.539746817354288

Epoch: 6| Step: 13
Training loss: 1.604243049619604
Validation loss: 2.532983570883435

Epoch: 91| Step: 0
Training loss: 2.815449587896847
Validation loss: 2.528136026898455

Epoch: 6| Step: 1
Training loss: 2.7951578164628033
Validation loss: 2.5311104166164613

Epoch: 6| Step: 2
Training loss: 2.7809139434437458
Validation loss: 2.537654809711612

Epoch: 6| Step: 3
Training loss: 2.878790305713075
Validation loss: 2.5466436566279347

Epoch: 6| Step: 4
Training loss: 2.9103292733799364
Validation loss: 2.5502626607715073

Epoch: 6| Step: 5
Training loss: 3.038112148563001
Validation loss: 2.554018889789362

Epoch: 6| Step: 6
Training loss: 3.131741081302441
Validation loss: 2.5525822563424603

Epoch: 6| Step: 7
Training loss: 2.967609869217392
Validation loss: 2.547466146811816

Epoch: 6| Step: 8
Training loss: 2.5293328831293045
Validation loss: 2.535298218468215

Epoch: 6| Step: 9
Training loss: 2.9124316031484034
Validation loss: 2.555866652839648

Epoch: 6| Step: 10
Training loss: 2.8822073779495527
Validation loss: 2.594499710699127

Epoch: 6| Step: 11
Training loss: 3.007385382113149
Validation loss: 2.6566018100190276

Epoch: 6| Step: 12
Training loss: 2.7426447038891566
Validation loss: 2.66736812956832

Epoch: 6| Step: 13
Training loss: 2.7124350860844437
Validation loss: 2.722500948710152

Epoch: 92| Step: 0
Training loss: 2.821464493507327
Validation loss: 2.7645030581602206

Epoch: 6| Step: 1
Training loss: 3.021019730352922
Validation loss: 2.755322105530174

Epoch: 6| Step: 2
Training loss: 3.2361632485253207
Validation loss: 2.757628336083885

Epoch: 6| Step: 3
Training loss: 2.592463346569842
Validation loss: 2.6694203583950964

Epoch: 6| Step: 4
Training loss: 3.255406797335426
Validation loss: 2.601578564323117

Epoch: 6| Step: 5
Training loss: 2.749737900468107
Validation loss: 2.5780654597064863

Epoch: 6| Step: 6
Training loss: 2.822944744200388
Validation loss: 2.547908945269547

Epoch: 6| Step: 7
Training loss: 3.08449178704541
Validation loss: 2.536792222654892

Epoch: 6| Step: 8
Training loss: 3.2454422022577756
Validation loss: 2.530538379171792

Epoch: 6| Step: 9
Training loss: 2.40432811131085
Validation loss: 2.526186831918457

Epoch: 6| Step: 10
Training loss: 2.578100585821902
Validation loss: 2.5216339136376646

Epoch: 6| Step: 11
Training loss: 2.659202729684643
Validation loss: 2.5232524015957596

Epoch: 6| Step: 12
Training loss: 2.7781654998607803
Validation loss: 2.5191321480825395

Epoch: 6| Step: 13
Training loss: 3.455303626844756
Validation loss: 2.5213377283624943

Epoch: 93| Step: 0
Training loss: 3.202090063607153
Validation loss: 2.5229525135445487

Epoch: 6| Step: 1
Training loss: 2.675038032617882
Validation loss: 2.5199674235932354

Epoch: 6| Step: 2
Training loss: 3.1330248220892916
Validation loss: 2.523086137843665

Epoch: 6| Step: 3
Training loss: 2.7997627055570224
Validation loss: 2.52103183961059

Epoch: 6| Step: 4
Training loss: 2.9390551731762575
Validation loss: 2.5193186013998443

Epoch: 6| Step: 5
Training loss: 2.6039987331920535
Validation loss: 2.5221286850058973

Epoch: 6| Step: 6
Training loss: 3.2106479040824856
Validation loss: 2.51901580760475

Epoch: 6| Step: 7
Training loss: 2.0443628634655564
Validation loss: 2.5235054832146377

Epoch: 6| Step: 8
Training loss: 3.13589090370643
Validation loss: 2.53353514347842

Epoch: 6| Step: 9
Training loss: 3.2360593676125426
Validation loss: 2.5494191356879425

Epoch: 6| Step: 10
Training loss: 2.5751157827179494
Validation loss: 2.5645983478615806

Epoch: 6| Step: 11
Training loss: 3.2177612860165095
Validation loss: 2.538791159242268

Epoch: 6| Step: 12
Training loss: 2.627490723917491
Validation loss: 2.532082997275519

Epoch: 6| Step: 13
Training loss: 2.4609201582040265
Validation loss: 2.517836424004906

Epoch: 94| Step: 0
Training loss: 2.864446426356718
Validation loss: 2.5216741079290825

Epoch: 6| Step: 1
Training loss: 2.451488750994473
Validation loss: 2.515480651362378

Epoch: 6| Step: 2
Training loss: 3.0229321434488874
Validation loss: 2.5146119203832122

Epoch: 6| Step: 3
Training loss: 2.760854280919881
Validation loss: 2.523609538137857

Epoch: 6| Step: 4
Training loss: 3.133260566461677
Validation loss: 2.5194414544262935

Epoch: 6| Step: 5
Training loss: 2.832474204313788
Validation loss: 2.5285797081769172

Epoch: 6| Step: 6
Training loss: 2.4619990889844288
Validation loss: 2.5302126090626613

Epoch: 6| Step: 7
Training loss: 2.867532735303489
Validation loss: 2.535861073846835

Epoch: 6| Step: 8
Training loss: 2.8877369242647792
Validation loss: 2.530645934694671

Epoch: 6| Step: 9
Training loss: 2.991626178888978
Validation loss: 2.554552535102403

Epoch: 6| Step: 10
Training loss: 2.637456584410378
Validation loss: 2.538624022732838

Epoch: 6| Step: 11
Training loss: 2.73671670097429
Validation loss: 2.539609497821713

Epoch: 6| Step: 12
Training loss: 3.665809588975804
Validation loss: 2.537080389867383

Epoch: 6| Step: 13
Training loss: 2.496613784131514
Validation loss: 2.520629289451231

Epoch: 95| Step: 0
Training loss: 2.8975950595116373
Validation loss: 2.51896339269204

Epoch: 6| Step: 1
Training loss: 2.412915793842344
Validation loss: 2.5256403304929043

Epoch: 6| Step: 2
Training loss: 2.9282118679583866
Validation loss: 2.5157042816780595

Epoch: 6| Step: 3
Training loss: 3.2038680540578603
Validation loss: 2.5176739805028294

Epoch: 6| Step: 4
Training loss: 3.0440128283437136
Validation loss: 2.5205218659077047

Epoch: 6| Step: 5
Training loss: 3.3188594017028628
Validation loss: 2.5132289658527847

Epoch: 6| Step: 6
Training loss: 2.5350264646815313
Validation loss: 2.5108752272041186

Epoch: 6| Step: 7
Training loss: 2.8845904070433033
Validation loss: 2.508270593935866

Epoch: 6| Step: 8
Training loss: 3.0857415632021175
Validation loss: 2.511878002422259

Epoch: 6| Step: 9
Training loss: 3.0171150913963234
Validation loss: 2.515399092926365

Epoch: 6| Step: 10
Training loss: 2.324840507369181
Validation loss: 2.515199478899806

Epoch: 6| Step: 11
Training loss: 2.776853193480363
Validation loss: 2.528962254423879

Epoch: 6| Step: 12
Training loss: 2.6450175031288374
Validation loss: 2.528302126884859

Epoch: 6| Step: 13
Training loss: 2.974451472899874
Validation loss: 2.5354409251954038

Epoch: 96| Step: 0
Training loss: 2.007306224359111
Validation loss: 2.5408172425307396

Epoch: 6| Step: 1
Training loss: 2.7238232862986744
Validation loss: 2.552265593847374

Epoch: 6| Step: 2
Training loss: 2.6413671590490004
Validation loss: 2.551690288126073

Epoch: 6| Step: 3
Training loss: 2.027661249072737
Validation loss: 2.5847736968335244

Epoch: 6| Step: 4
Training loss: 3.1708104644498767
Validation loss: 2.578113622258084

Epoch: 6| Step: 5
Training loss: 2.424724453087583
Validation loss: 2.5548193300072444

Epoch: 6| Step: 6
Training loss: 2.957174763793673
Validation loss: 2.5581335878077596

Epoch: 6| Step: 7
Training loss: 2.8317365821917213
Validation loss: 2.5361714394252903

Epoch: 6| Step: 8
Training loss: 3.2838892903316315
Validation loss: 2.544182114811304

Epoch: 6| Step: 9
Training loss: 2.9686203777725875
Validation loss: 2.5316289944380026

Epoch: 6| Step: 10
Training loss: 3.7720042284783037
Validation loss: 2.523528220071349

Epoch: 6| Step: 11
Training loss: 2.4729185040624317
Validation loss: 2.516771900291525

Epoch: 6| Step: 12
Training loss: 2.9083311771359326
Validation loss: 2.512875825342214

Epoch: 6| Step: 13
Training loss: 3.4228653541537413
Validation loss: 2.5129655504954895

Epoch: 97| Step: 0
Training loss: 2.1646553632141305
Validation loss: 2.505194191292305

Epoch: 6| Step: 1
Training loss: 2.7503667066737116
Validation loss: 2.5098499486786867

Epoch: 6| Step: 2
Training loss: 2.557408461587275
Validation loss: 2.503347532663197

Epoch: 6| Step: 3
Training loss: 3.115067375274962
Validation loss: 2.508232578590707

Epoch: 6| Step: 4
Training loss: 2.462920440565959
Validation loss: 2.516808083541994

Epoch: 6| Step: 5
Training loss: 2.828883791130902
Validation loss: 2.506080794967793

Epoch: 6| Step: 6
Training loss: 3.0555292321044205
Validation loss: 2.5142206995735537

Epoch: 6| Step: 7
Training loss: 2.9149554727860245
Validation loss: 2.5350462271852834

Epoch: 6| Step: 8
Training loss: 3.159155839361301
Validation loss: 2.5436086943107807

Epoch: 6| Step: 9
Training loss: 2.8182590437681134
Validation loss: 2.544057017244765

Epoch: 6| Step: 10
Training loss: 2.816464321685895
Validation loss: 2.523905478142305

Epoch: 6| Step: 11
Training loss: 3.5754464464259237
Validation loss: 2.53957770460024

Epoch: 6| Step: 12
Training loss: 2.356592520752879
Validation loss: 2.5439230322337

Epoch: 6| Step: 13
Training loss: 3.1035609497063983
Validation loss: 2.5495388620604293

Epoch: 98| Step: 0
Training loss: 3.405562025115558
Validation loss: 2.539072467793855

Epoch: 6| Step: 1
Training loss: 2.746653341088176
Validation loss: 2.532236370667541

Epoch: 6| Step: 2
Training loss: 2.408702046857832
Validation loss: 2.5174597859989767

Epoch: 6| Step: 3
Training loss: 3.246998501320585
Validation loss: 2.506560806430592

Epoch: 6| Step: 4
Training loss: 2.384449480925818
Validation loss: 2.5013076746206373

Epoch: 6| Step: 5
Training loss: 3.0430126260476076
Validation loss: 2.5024952946064727

Epoch: 6| Step: 6
Training loss: 2.048069263359892
Validation loss: 2.502221785557654

Epoch: 6| Step: 7
Training loss: 2.648242144286083
Validation loss: 2.500689139802121

Epoch: 6| Step: 8
Training loss: 3.0183197789034426
Validation loss: 2.5006874749195447

Epoch: 6| Step: 9
Training loss: 3.153048562974969
Validation loss: 2.505108709023538

Epoch: 6| Step: 10
Training loss: 2.511095221740204
Validation loss: 2.5250634800612994

Epoch: 6| Step: 11
Training loss: 3.1313269082254505
Validation loss: 2.520953319368349

Epoch: 6| Step: 12
Training loss: 3.0957936944558844
Validation loss: 2.5401406598194014

Epoch: 6| Step: 13
Training loss: 2.599974001240956
Validation loss: 2.5529449401405

Epoch: 99| Step: 0
Training loss: 3.007631132924761
Validation loss: 2.607160731446328

Epoch: 6| Step: 1
Training loss: 2.948729296357297
Validation loss: 2.669830580196959

Epoch: 6| Step: 2
Training loss: 3.1293059628328126
Validation loss: 2.735691536713032

Epoch: 6| Step: 3
Training loss: 3.227606431312786
Validation loss: 2.6862997411609455

Epoch: 6| Step: 4
Training loss: 2.718379203679118
Validation loss: 2.6289533065931003

Epoch: 6| Step: 5
Training loss: 2.615937802879016
Validation loss: 2.5468282186335087

Epoch: 6| Step: 6
Training loss: 3.1185220333102044
Validation loss: 2.512360701181154

Epoch: 6| Step: 7
Training loss: 1.8596859840177915
Validation loss: 2.499746428725083

Epoch: 6| Step: 8
Training loss: 2.495757986299549
Validation loss: 2.5007719575973715

Epoch: 6| Step: 9
Training loss: 3.3905701522961595
Validation loss: 2.510371611203647

Epoch: 6| Step: 10
Training loss: 2.834970524818012
Validation loss: 2.5191979740712487

Epoch: 6| Step: 11
Training loss: 2.8181309597538653
Validation loss: 2.5183812514679484

Epoch: 6| Step: 12
Training loss: 2.5217852305869632
Validation loss: 2.5049153439029412

Epoch: 6| Step: 13
Training loss: 3.2817906978708056
Validation loss: 2.5019612013235224

Epoch: 100| Step: 0
Training loss: 3.14753759505625
Validation loss: 2.515382544470877

Epoch: 6| Step: 1
Training loss: 3.4413968279879534
Validation loss: 2.542007186110633

Epoch: 6| Step: 2
Training loss: 2.849599167594381
Validation loss: 2.566478518019813

Epoch: 6| Step: 3
Training loss: 3.1276941511479346
Validation loss: 2.611591412936874

Epoch: 6| Step: 4
Training loss: 3.3191292124046172
Validation loss: 2.660424718668685

Epoch: 6| Step: 5
Training loss: 2.9945524346816197
Validation loss: 2.5836743970858125

Epoch: 6| Step: 6
Training loss: 2.5799845145004756
Validation loss: 2.5528922839141206

Epoch: 6| Step: 7
Training loss: 2.2935320342649907
Validation loss: 2.5247752374392727

Epoch: 6| Step: 8
Training loss: 2.697441520728756
Validation loss: 2.5108161659114376

Epoch: 6| Step: 9
Training loss: 2.3650605872621737
Validation loss: 2.511811510007332

Epoch: 6| Step: 10
Training loss: 2.462520029983774
Validation loss: 2.509983689356859

Epoch: 6| Step: 11
Training loss: 2.7927212692202086
Validation loss: 2.5140157158565875

Epoch: 6| Step: 12
Training loss: 3.0463732183970174
Validation loss: 2.5245299876638354

Epoch: 6| Step: 13
Training loss: 2.4477133375633966
Validation loss: 2.5162411664245488

Epoch: 101| Step: 0
Training loss: 3.0850971091642534
Validation loss: 2.5095473353405784

Epoch: 6| Step: 1
Training loss: 2.9338373928763257
Validation loss: 2.5085594422695823

Epoch: 6| Step: 2
Training loss: 2.840423650708276
Validation loss: 2.5106428488096975

Epoch: 6| Step: 3
Training loss: 3.2446503258910178
Validation loss: 2.5100266052259115

Epoch: 6| Step: 4
Training loss: 2.220021702772027
Validation loss: 2.528229480460807

Epoch: 6| Step: 5
Training loss: 2.817630496451313
Validation loss: 2.568107326540202

Epoch: 6| Step: 6
Training loss: 3.3981045263872356
Validation loss: 2.592330558056514

Epoch: 6| Step: 7
Training loss: 2.8989313326990174
Validation loss: 2.593336631589752

Epoch: 6| Step: 8
Training loss: 3.1432465956024833
Validation loss: 2.642929167943352

Epoch: 6| Step: 9
Training loss: 2.6121334640147476
Validation loss: 2.568129763349841

Epoch: 6| Step: 10
Training loss: 2.122130532250701
Validation loss: 2.5351956019338475

Epoch: 6| Step: 11
Training loss: 3.3573241605181394
Validation loss: 2.5074494645092638

Epoch: 6| Step: 12
Training loss: 2.770146956556491
Validation loss: 2.496546477503932

Epoch: 6| Step: 13
Training loss: 2.4483842660147537
Validation loss: 2.500397299914458

Epoch: 102| Step: 0
Training loss: 3.121938197323925
Validation loss: 2.503772594255818

Epoch: 6| Step: 1
Training loss: 2.6841152078772095
Validation loss: 2.509418758112513

Epoch: 6| Step: 2
Training loss: 3.2566767846701596
Validation loss: 2.521482817386276

Epoch: 6| Step: 3
Training loss: 2.6533557157994156
Validation loss: 2.535931335740556

Epoch: 6| Step: 4
Training loss: 3.266955966854723
Validation loss: 2.515762568901815

Epoch: 6| Step: 5
Training loss: 3.3267274886427662
Validation loss: 2.506783943907892

Epoch: 6| Step: 6
Training loss: 2.4057393708845063
Validation loss: 2.502319178003525

Epoch: 6| Step: 7
Training loss: 2.6231101362903875
Validation loss: 2.493088770043281

Epoch: 6| Step: 8
Training loss: 2.641686942647463
Validation loss: 2.498564165291127

Epoch: 6| Step: 9
Training loss: 2.7474502533981324
Validation loss: 2.498236343780101

Epoch: 6| Step: 10
Training loss: 2.3629682853853153
Validation loss: 2.503267268715289

Epoch: 6| Step: 11
Training loss: 3.0023508397896386
Validation loss: 2.512894800005299

Epoch: 6| Step: 12
Training loss: 2.8833940121066934
Validation loss: 2.5217279873635725

Epoch: 6| Step: 13
Training loss: 3.0275540186554006
Validation loss: 2.5626392091584296

Epoch: 103| Step: 0
Training loss: 2.996760526664552
Validation loss: 2.656304696067044

Epoch: 6| Step: 1
Training loss: 3.0684423599336768
Validation loss: 2.7751677280160494

Epoch: 6| Step: 2
Training loss: 2.081481517481524
Validation loss: 2.7478822233359543

Epoch: 6| Step: 3
Training loss: 2.698077831585021
Validation loss: 2.7336660864890296

Epoch: 6| Step: 4
Training loss: 3.4523688821941776
Validation loss: 2.6755042928968007

Epoch: 6| Step: 5
Training loss: 2.6041324053735817
Validation loss: 2.5981039397474066

Epoch: 6| Step: 6
Training loss: 3.0392976880698184
Validation loss: 2.5446584560785777

Epoch: 6| Step: 7
Training loss: 3.216632035090418
Validation loss: 2.5112989411614612

Epoch: 6| Step: 8
Training loss: 2.357591068292843
Validation loss: 2.49600108169776

Epoch: 6| Step: 9
Training loss: 3.004392904438959
Validation loss: 2.4920876099438622

Epoch: 6| Step: 10
Training loss: 2.7413360925906702
Validation loss: 2.5107477482347935

Epoch: 6| Step: 11
Training loss: 3.556874970828391
Validation loss: 2.512755115217393

Epoch: 6| Step: 12
Training loss: 2.4590923840084535
Validation loss: 2.511304996791743

Epoch: 6| Step: 13
Training loss: 3.2064015075699084
Validation loss: 2.501891459432862

Epoch: 104| Step: 0
Training loss: 3.1392603704085733
Validation loss: 2.5103060541781126

Epoch: 6| Step: 1
Training loss: 3.0848457819695225
Validation loss: 2.497814220709511

Epoch: 6| Step: 2
Training loss: 3.20091834004001
Validation loss: 2.496763412834618

Epoch: 6| Step: 3
Training loss: 3.1805210380032314
Validation loss: 2.495300831536521

Epoch: 6| Step: 4
Training loss: 3.143289678708035
Validation loss: 2.4967466001911447

Epoch: 6| Step: 5
Training loss: 2.7961227001941484
Validation loss: 2.4897866396263018

Epoch: 6| Step: 6
Training loss: 2.2448583771484047
Validation loss: 2.4939302933030096

Epoch: 6| Step: 7
Training loss: 2.2854903017721666
Validation loss: 2.4984399214249047

Epoch: 6| Step: 8
Training loss: 2.496632596926437
Validation loss: 2.5183987605188998

Epoch: 6| Step: 9
Training loss: 2.670570367334204
Validation loss: 2.5223635269459557

Epoch: 6| Step: 10
Training loss: 2.539042968674879
Validation loss: 2.535708649144321

Epoch: 6| Step: 11
Training loss: 2.807897489404597
Validation loss: 2.562055889935486

Epoch: 6| Step: 12
Training loss: 2.8197731072884062
Validation loss: 2.5492163406851494

Epoch: 6| Step: 13
Training loss: 2.9636808786171227
Validation loss: 2.557024117441452

Epoch: 105| Step: 0
Training loss: 2.78363440668873
Validation loss: 2.5737914953386114

Epoch: 6| Step: 1
Training loss: 3.4551446454344026
Validation loss: 2.5581304661000073

Epoch: 6| Step: 2
Training loss: 2.9824538513348027
Validation loss: 2.5347008405356632

Epoch: 6| Step: 3
Training loss: 2.8616607368539624
Validation loss: 2.5034386172215775

Epoch: 6| Step: 4
Training loss: 3.1286430486306087
Validation loss: 2.5061196715448024

Epoch: 6| Step: 5
Training loss: 2.188581145007809
Validation loss: 2.488985900686963

Epoch: 6| Step: 6
Training loss: 2.6041845905958687
Validation loss: 2.493796539797588

Epoch: 6| Step: 7
Training loss: 3.1234505436039552
Validation loss: 2.492771722737938

Epoch: 6| Step: 8
Training loss: 3.0380647487508456
Validation loss: 2.4980796801484084

Epoch: 6| Step: 9
Training loss: 2.6265461319249437
Validation loss: 2.491749912322363

Epoch: 6| Step: 10
Training loss: 2.660355032553166
Validation loss: 2.491809826769154

Epoch: 6| Step: 11
Training loss: 2.7970589518657634
Validation loss: 2.489505076833549

Epoch: 6| Step: 12
Training loss: 2.9090860946572086
Validation loss: 2.4852848225094193

Epoch: 6| Step: 13
Training loss: 2.704122546697652
Validation loss: 2.4904499537310536

Epoch: 106| Step: 0
Training loss: 3.0710364500147724
Validation loss: 2.4916737638015687

Epoch: 6| Step: 1
Training loss: 3.3079964595162243
Validation loss: 2.5007002844401343

Epoch: 6| Step: 2
Training loss: 2.4816843493437744
Validation loss: 2.501555113978056

Epoch: 6| Step: 3
Training loss: 2.934884713035351
Validation loss: 2.5023936472011243

Epoch: 6| Step: 4
Training loss: 3.1501334570815116
Validation loss: 2.50219895037832

Epoch: 6| Step: 5
Training loss: 2.2504394949725324
Validation loss: 2.4952329439357577

Epoch: 6| Step: 6
Training loss: 2.8389295027237904
Validation loss: 2.501300825582362

Epoch: 6| Step: 7
Training loss: 2.1767101667691007
Validation loss: 2.500879815858403

Epoch: 6| Step: 8
Training loss: 2.7932226105674176
Validation loss: 2.492440535040407

Epoch: 6| Step: 9
Training loss: 2.9765431160683637
Validation loss: 2.4988581398015066

Epoch: 6| Step: 10
Training loss: 2.7226376854415504
Validation loss: 2.5043929256437045

Epoch: 6| Step: 11
Training loss: 2.5754204638254166
Validation loss: 2.512723729043333

Epoch: 6| Step: 12
Training loss: 2.9937585436354635
Validation loss: 2.526072756786641

Epoch: 6| Step: 13
Training loss: 3.073235205396025
Validation loss: 2.552332416472863

Epoch: 107| Step: 0
Training loss: 2.9861703635160213
Validation loss: 2.577200355419188

Epoch: 6| Step: 1
Training loss: 2.6369469663967204
Validation loss: 2.570158163015666

Epoch: 6| Step: 2
Training loss: 2.2710910499223393
Validation loss: 2.553311510290263

Epoch: 6| Step: 3
Training loss: 2.878196432115651
Validation loss: 2.5420382298876194

Epoch: 6| Step: 4
Training loss: 2.715972533995865
Validation loss: 2.5340576744419345

Epoch: 6| Step: 5
Training loss: 2.4165932435907087
Validation loss: 2.507513942969895

Epoch: 6| Step: 6
Training loss: 3.6417597365252776
Validation loss: 2.4937900253078666

Epoch: 6| Step: 7
Training loss: 2.730824896161391
Validation loss: 2.4952352638385458

Epoch: 6| Step: 8
Training loss: 3.12466047349884
Validation loss: 2.4936345144416063

Epoch: 6| Step: 9
Training loss: 2.797583974987513
Validation loss: 2.4914544950829627

Epoch: 6| Step: 10
Training loss: 2.989927230000463
Validation loss: 2.489684867221498

Epoch: 6| Step: 11
Training loss: 2.8696614332239627
Validation loss: 2.4892430521942024

Epoch: 6| Step: 12
Training loss: 2.9315750755184284
Validation loss: 2.488748511790689

Epoch: 6| Step: 13
Training loss: 2.7102163273521436
Validation loss: 2.487394916608752

Epoch: 108| Step: 0
Training loss: 2.7513018041063857
Validation loss: 2.4989506600944305

Epoch: 6| Step: 1
Training loss: 2.8906203811196205
Validation loss: 2.5001797334605005

Epoch: 6| Step: 2
Training loss: 3.161180629610156
Validation loss: 2.5151190427604724

Epoch: 6| Step: 3
Training loss: 2.9587165333604153
Validation loss: 2.527640009422279

Epoch: 6| Step: 4
Training loss: 2.8715995913874965
Validation loss: 2.5307234663745346

Epoch: 6| Step: 5
Training loss: 2.6072782212592847
Validation loss: 2.5266283279902333

Epoch: 6| Step: 6
Training loss: 2.5088966379232756
Validation loss: 2.524878521164419

Epoch: 6| Step: 7
Training loss: 2.8697468407390296
Validation loss: 2.5079134003099277

Epoch: 6| Step: 8
Training loss: 3.0759911281224603
Validation loss: 2.5173104413885112

Epoch: 6| Step: 9
Training loss: 2.2707417554209046
Validation loss: 2.5068072599065334

Epoch: 6| Step: 10
Training loss: 2.8101475520101435
Validation loss: 2.497765206712105

Epoch: 6| Step: 11
Training loss: 2.563138370548806
Validation loss: 2.5124817639136365

Epoch: 6| Step: 12
Training loss: 3.0220903258744833
Validation loss: 2.523735096651934

Epoch: 6| Step: 13
Training loss: 2.9498298466636306
Validation loss: 2.522911309250727

Epoch: 109| Step: 0
Training loss: 2.8182744405297995
Validation loss: 2.5451829560233157

Epoch: 6| Step: 1
Training loss: 2.6834188123873917
Validation loss: 2.5544157947112636

Epoch: 6| Step: 2
Training loss: 2.549899499446084
Validation loss: 2.57985737290861

Epoch: 6| Step: 3
Training loss: 3.169271669202249
Validation loss: 2.617277145013667

Epoch: 6| Step: 4
Training loss: 2.7000649832923402
Validation loss: 2.5968747975840594

Epoch: 6| Step: 5
Training loss: 2.9407149233228824
Validation loss: 2.5922425939611413

Epoch: 6| Step: 6
Training loss: 2.603104967495886
Validation loss: 2.581374295574249

Epoch: 6| Step: 7
Training loss: 3.09354839246037
Validation loss: 2.6119531857495577

Epoch: 6| Step: 8
Training loss: 2.9388166682746655
Validation loss: 2.612673835605501

Epoch: 6| Step: 9
Training loss: 3.1651232789725188
Validation loss: 2.5421554741603565

Epoch: 6| Step: 10
Training loss: 2.8454986896796757
Validation loss: 2.519995804929847

Epoch: 6| Step: 11
Training loss: 2.7143541072890764
Validation loss: 2.498082123635466

Epoch: 6| Step: 12
Training loss: 2.437890339432516
Validation loss: 2.488764171204305

Epoch: 6| Step: 13
Training loss: 2.8325876675916466
Validation loss: 2.481542939761682

Epoch: 110| Step: 0
Training loss: 2.8801594753616726
Validation loss: 2.4919394360226983

Epoch: 6| Step: 1
Training loss: 2.7160220436471327
Validation loss: 2.502002971955976

Epoch: 6| Step: 2
Training loss: 3.116035114565476
Validation loss: 2.5064673437672065

Epoch: 6| Step: 3
Training loss: 2.667601798920705
Validation loss: 2.5089350948441513

Epoch: 6| Step: 4
Training loss: 2.584592532835885
Validation loss: 2.518081027634886

Epoch: 6| Step: 5
Training loss: 3.1875749467004724
Validation loss: 2.5627504682049205

Epoch: 6| Step: 6
Training loss: 3.7031641447034436
Validation loss: 2.502170238082139

Epoch: 6| Step: 7
Training loss: 2.323591080228549
Validation loss: 2.4952403639184033

Epoch: 6| Step: 8
Training loss: 2.4816231511871534
Validation loss: 2.496200008500249

Epoch: 6| Step: 9
Training loss: 2.69123757862249
Validation loss: 2.516903361304349

Epoch: 6| Step: 10
Training loss: 2.371930397402004
Validation loss: 2.542412738311505

Epoch: 6| Step: 11
Training loss: 2.6190739906931966
Validation loss: 2.5742977030077014

Epoch: 6| Step: 12
Training loss: 3.3542958742137787
Validation loss: 2.587973065849957

Epoch: 6| Step: 13
Training loss: 3.0282590602177706
Validation loss: 2.576598881204748

Epoch: 111| Step: 0
Training loss: 2.648024985446203
Validation loss: 2.525381800318875

Epoch: 6| Step: 1
Training loss: 3.259333486466363
Validation loss: 2.510295564936

Epoch: 6| Step: 2
Training loss: 2.576744125932442
Validation loss: 2.5132327533272396

Epoch: 6| Step: 3
Training loss: 2.1698586963757682
Validation loss: 2.508022741792789

Epoch: 6| Step: 4
Training loss: 3.0882434583069838
Validation loss: 2.5153873896726022

Epoch: 6| Step: 5
Training loss: 2.6631787755693965
Validation loss: 2.5046762068391164

Epoch: 6| Step: 6
Training loss: 2.8872629770206455
Validation loss: 2.49230735373084

Epoch: 6| Step: 7
Training loss: 2.6591282229113715
Validation loss: 2.5058989414736073

Epoch: 6| Step: 8
Training loss: 2.9491185051257927
Validation loss: 2.4879541622400363

Epoch: 6| Step: 9
Training loss: 2.944844904444115
Validation loss: 2.507595914286466

Epoch: 6| Step: 10
Training loss: 2.26376045060339
Validation loss: 2.5204080785531118

Epoch: 6| Step: 11
Training loss: 2.5293081865094553
Validation loss: 2.5220626620742754

Epoch: 6| Step: 12
Training loss: 3.64029217291511
Validation loss: 2.501434305424298

Epoch: 6| Step: 13
Training loss: 2.382734753950663
Validation loss: 2.5022140604709566

Epoch: 112| Step: 0
Training loss: 2.6569794494730052
Validation loss: 2.5063682703571244

Epoch: 6| Step: 1
Training loss: 2.6376707265838624
Validation loss: 2.5065739551551234

Epoch: 6| Step: 2
Training loss: 2.456672775730248
Validation loss: 2.5149234411804073

Epoch: 6| Step: 3
Training loss: 2.228830567688556
Validation loss: 2.5004930881581773

Epoch: 6| Step: 4
Training loss: 2.7973455960205276
Validation loss: 2.5059868294970222

Epoch: 6| Step: 5
Training loss: 2.367543410937451
Validation loss: 2.5013711184231218

Epoch: 6| Step: 6
Training loss: 2.374818292994993
Validation loss: 2.48626174633865

Epoch: 6| Step: 7
Training loss: 3.3413098424596708
Validation loss: 2.475925762109774

Epoch: 6| Step: 8
Training loss: 2.7465121084849495
Validation loss: 2.4771256188831487

Epoch: 6| Step: 9
Training loss: 2.8940308996843203
Validation loss: 2.4834506388766324

Epoch: 6| Step: 10
Training loss: 3.265680486034302
Validation loss: 2.4806809671519696

Epoch: 6| Step: 11
Training loss: 3.2881321984513012
Validation loss: 2.499242357074968

Epoch: 6| Step: 12
Training loss: 3.337417310054683
Validation loss: 2.4983561638622818

Epoch: 6| Step: 13
Training loss: 2.0730216097186136
Validation loss: 2.513521880010463

Epoch: 113| Step: 0
Training loss: 2.7757630819750916
Validation loss: 2.5258405992115427

Epoch: 6| Step: 1
Training loss: 2.7718266496881854
Validation loss: 2.527541134030771

Epoch: 6| Step: 2
Training loss: 2.7560643174648836
Validation loss: 2.517729625628586

Epoch: 6| Step: 3
Training loss: 2.4016932157186934
Validation loss: 2.510010141870966

Epoch: 6| Step: 4
Training loss: 2.2712327681681876
Validation loss: 2.492295944236351

Epoch: 6| Step: 5
Training loss: 2.819711637024769
Validation loss: 2.4989589584794287

Epoch: 6| Step: 6
Training loss: 2.270445647670492
Validation loss: 2.4810929343511217

Epoch: 6| Step: 7
Training loss: 3.0753077283259587
Validation loss: 2.4799011382014995

Epoch: 6| Step: 8
Training loss: 3.17468633228712
Validation loss: 2.4749851712780857

Epoch: 6| Step: 9
Training loss: 2.507643269090452
Validation loss: 2.474895101930193

Epoch: 6| Step: 10
Training loss: 3.331397511721397
Validation loss: 2.4694528613719586

Epoch: 6| Step: 11
Training loss: 3.202247462205896
Validation loss: 2.472568385143827

Epoch: 6| Step: 12
Training loss: 2.753870580996842
Validation loss: 2.471993063530975

Epoch: 6| Step: 13
Training loss: 2.585055474547507
Validation loss: 2.478366123482404

Epoch: 114| Step: 0
Training loss: 3.1345204099963353
Validation loss: 2.4874931297015674

Epoch: 6| Step: 1
Training loss: 2.72119092436464
Validation loss: 2.5010852591095043

Epoch: 6| Step: 2
Training loss: 3.0921651460630857
Validation loss: 2.499051997195117

Epoch: 6| Step: 3
Training loss: 2.814563926405864
Validation loss: 2.486646873791016

Epoch: 6| Step: 4
Training loss: 3.054110655503027
Validation loss: 2.495849105423837

Epoch: 6| Step: 5
Training loss: 2.73197421809887
Validation loss: 2.4837859307925245

Epoch: 6| Step: 6
Training loss: 2.7196855360460384
Validation loss: 2.47976195614035

Epoch: 6| Step: 7
Training loss: 3.0449557005818426
Validation loss: 2.5094294154977077

Epoch: 6| Step: 8
Training loss: 2.8402757486607135
Validation loss: 2.5191835815251076

Epoch: 6| Step: 9
Training loss: 2.7539869364288037
Validation loss: 2.5037874603774344

Epoch: 6| Step: 10
Training loss: 2.546288171106598
Validation loss: 2.532461173618122

Epoch: 6| Step: 11
Training loss: 2.4184651643280115
Validation loss: 2.5633636927916745

Epoch: 6| Step: 12
Training loss: 2.4556316034078227
Validation loss: 2.572738950870002

Epoch: 6| Step: 13
Training loss: 2.005351298466488
Validation loss: 2.5595105068482638

Epoch: 115| Step: 0
Training loss: 2.237082488249957
Validation loss: 2.564395868506801

Epoch: 6| Step: 1
Training loss: 2.7625514478768984
Validation loss: 2.5753219824519067

Epoch: 6| Step: 2
Training loss: 2.6640568618491014
Validation loss: 2.5538477999533353

Epoch: 6| Step: 3
Training loss: 2.5935303009010506
Validation loss: 2.527779654624964

Epoch: 6| Step: 4
Training loss: 2.740561587427592
Validation loss: 2.513836783991263

Epoch: 6| Step: 5
Training loss: 3.0376914886271984
Validation loss: 2.514144165056271

Epoch: 6| Step: 6
Training loss: 2.87344235227423
Validation loss: 2.528237691870536

Epoch: 6| Step: 7
Training loss: 2.9896243598772383
Validation loss: 2.5240517033908705

Epoch: 6| Step: 8
Training loss: 2.741083950122406
Validation loss: 2.5130091519886313

Epoch: 6| Step: 9
Training loss: 3.3563444440400594
Validation loss: 2.5237770056635638

Epoch: 6| Step: 10
Training loss: 2.639511866958167
Validation loss: 2.495103610566743

Epoch: 6| Step: 11
Training loss: 2.690490301041347
Validation loss: 2.4938888623814197

Epoch: 6| Step: 12
Training loss: 3.0931263304649907
Validation loss: 2.498005177788714

Epoch: 6| Step: 13
Training loss: 2.2402329914650805
Validation loss: 2.492177596966046

Epoch: 116| Step: 0
Training loss: 2.2489586645647033
Validation loss: 2.4839145354669143

Epoch: 6| Step: 1
Training loss: 3.319748056342947
Validation loss: 2.4845357904650465

Epoch: 6| Step: 2
Training loss: 2.8459660206399526
Validation loss: 2.4915194451012193

Epoch: 6| Step: 3
Training loss: 3.114294406583762
Validation loss: 2.4833998951233363

Epoch: 6| Step: 4
Training loss: 3.1816514157275577
Validation loss: 2.4926817437939137

Epoch: 6| Step: 5
Training loss: 2.4596104510393135
Validation loss: 2.50223897327772

Epoch: 6| Step: 6
Training loss: 2.92634314322407
Validation loss: 2.531324957969922

Epoch: 6| Step: 7
Training loss: 2.3247537461995305
Validation loss: 2.5492163849341156

Epoch: 6| Step: 8
Training loss: 3.018293869909263
Validation loss: 2.5649778110200296

Epoch: 6| Step: 9
Training loss: 2.580237430618403
Validation loss: 2.5417742478633274

Epoch: 6| Step: 10
Training loss: 2.614998063912778
Validation loss: 2.5090659855808353

Epoch: 6| Step: 11
Training loss: 2.3420941416308865
Validation loss: 2.4984560095412394

Epoch: 6| Step: 12
Training loss: 3.264429338949854
Validation loss: 2.4862770099994025

Epoch: 6| Step: 13
Training loss: 2.277723748514806
Validation loss: 2.4706668159618146

Epoch: 117| Step: 0
Training loss: 3.3026764795247145
Validation loss: 2.476298958342018

Epoch: 6| Step: 1
Training loss: 3.358708515145289
Validation loss: 2.4807149682039507

Epoch: 6| Step: 2
Training loss: 3.32277597031846
Validation loss: 2.4869689247106432

Epoch: 6| Step: 3
Training loss: 2.703214258032297
Validation loss: 2.484445542133546

Epoch: 6| Step: 4
Training loss: 2.7359621509811793
Validation loss: 2.476296337551955

Epoch: 6| Step: 5
Training loss: 2.588787156763507
Validation loss: 2.47155073040677

Epoch: 6| Step: 6
Training loss: 2.4687359000660445
Validation loss: 2.4780131119362294

Epoch: 6| Step: 7
Training loss: 2.742706771330504
Validation loss: 2.4848034546582984

Epoch: 6| Step: 8
Training loss: 2.337050463038993
Validation loss: 2.4963025895036752

Epoch: 6| Step: 9
Training loss: 2.22918204424061
Validation loss: 2.499670014086577

Epoch: 6| Step: 10
Training loss: 3.1376665899420657
Validation loss: 2.529242701189238

Epoch: 6| Step: 11
Training loss: 2.836048470840207
Validation loss: 2.5399713835356987

Epoch: 6| Step: 12
Training loss: 2.5128232150210508
Validation loss: 2.536369087842607

Epoch: 6| Step: 13
Training loss: 2.3738004767267418
Validation loss: 2.50549673489598

Epoch: 118| Step: 0
Training loss: 2.5803479408028425
Validation loss: 2.5142662441429433

Epoch: 6| Step: 1
Training loss: 3.1921445629875134
Validation loss: 2.4886443538901286

Epoch: 6| Step: 2
Training loss: 3.48007360884767
Validation loss: 2.4887798861436745

Epoch: 6| Step: 3
Training loss: 2.1982310162213365
Validation loss: 2.4860551657513406

Epoch: 6| Step: 4
Training loss: 3.3339620633040776
Validation loss: 2.484599285923053

Epoch: 6| Step: 5
Training loss: 2.8674929921231698
Validation loss: 2.4847149989383746

Epoch: 6| Step: 6
Training loss: 2.5511822932901937
Validation loss: 2.4881114830005626

Epoch: 6| Step: 7
Training loss: 2.6399071976216217
Validation loss: 2.481192723562128

Epoch: 6| Step: 8
Training loss: 2.8493300805020483
Validation loss: 2.500280978707513

Epoch: 6| Step: 9
Training loss: 2.5604360688863146
Validation loss: 2.504794777248648

Epoch: 6| Step: 10
Training loss: 2.0504203551497677
Validation loss: 2.506113265809929

Epoch: 6| Step: 11
Training loss: 2.487501180830632
Validation loss: 2.5359314065054224

Epoch: 6| Step: 12
Training loss: 2.7326714140655435
Validation loss: 2.5297499840237423

Epoch: 6| Step: 13
Training loss: 2.835601198207082
Validation loss: 2.540136473440951

Epoch: 119| Step: 0
Training loss: 2.82084021029815
Validation loss: 2.5248872612999183

Epoch: 6| Step: 1
Training loss: 2.5885085494585716
Validation loss: 2.5108856527640584

Epoch: 6| Step: 2
Training loss: 2.708158624344785
Validation loss: 2.4989427227952214

Epoch: 6| Step: 3
Training loss: 2.441159167184477
Validation loss: 2.480368292914612

Epoch: 6| Step: 4
Training loss: 2.7574805040958585
Validation loss: 2.4855285482232223

Epoch: 6| Step: 5
Training loss: 2.854158239050533
Validation loss: 2.4914692114184027

Epoch: 6| Step: 6
Training loss: 2.6717993296119458
Validation loss: 2.486386152290385

Epoch: 6| Step: 7
Training loss: 3.403811640690879
Validation loss: 2.486114695660564

Epoch: 6| Step: 8
Training loss: 2.4218297154284456
Validation loss: 2.4750568479901807

Epoch: 6| Step: 9
Training loss: 3.019475188728041
Validation loss: 2.4817879337097444

Epoch: 6| Step: 10
Training loss: 2.6039763927883866
Validation loss: 2.4896810037658237

Epoch: 6| Step: 11
Training loss: 2.7450653364400024
Validation loss: 2.5118002166649425

Epoch: 6| Step: 12
Training loss: 2.6677866213114094
Validation loss: 2.5240383928081003

Epoch: 6| Step: 13
Training loss: 3.2793327906665586
Validation loss: 2.5264105607481984

Epoch: 120| Step: 0
Training loss: 2.4910514897155505
Validation loss: 2.54369647269646

Epoch: 6| Step: 1
Training loss: 2.889248246885149
Validation loss: 2.5668872350003675

Epoch: 6| Step: 2
Training loss: 3.1332958733233536
Validation loss: 2.521262959503265

Epoch: 6| Step: 3
Training loss: 2.7295383074144732
Validation loss: 2.4983075760883557

Epoch: 6| Step: 4
Training loss: 2.73396263282874
Validation loss: 2.48415251117619

Epoch: 6| Step: 5
Training loss: 2.9414928165174947
Validation loss: 2.4694662357081882

Epoch: 6| Step: 6
Training loss: 3.4764210875821755
Validation loss: 2.482222286048259

Epoch: 6| Step: 7
Training loss: 2.9091116649797564
Validation loss: 2.481539339463677

Epoch: 6| Step: 8
Training loss: 2.9202705098618935
Validation loss: 2.4896796533054233

Epoch: 6| Step: 9
Training loss: 2.5777404498360945
Validation loss: 2.4707535629899127

Epoch: 6| Step: 10
Training loss: 2.118103955103248
Validation loss: 2.467735307341287

Epoch: 6| Step: 11
Training loss: 2.479568726664269
Validation loss: 2.4689080917355155

Epoch: 6| Step: 12
Training loss: 2.797132085993463
Validation loss: 2.46056871335028

Epoch: 6| Step: 13
Training loss: 1.9168387073206792
Validation loss: 2.497003901128821

Epoch: 121| Step: 0
Training loss: 2.4922783814125866
Validation loss: 2.545439844697634

Epoch: 6| Step: 1
Training loss: 2.609146016746963
Validation loss: 2.6217996041063154

Epoch: 6| Step: 2
Training loss: 3.0449383180381075
Validation loss: 2.712646397782966

Epoch: 6| Step: 3
Training loss: 2.6010412662023548
Validation loss: 2.705454902298062

Epoch: 6| Step: 4
Training loss: 2.6948894666323002
Validation loss: 2.606550273829634

Epoch: 6| Step: 5
Training loss: 3.031618705427458
Validation loss: 2.5524091176543746

Epoch: 6| Step: 6
Training loss: 2.3676801615788774
Validation loss: 2.4948605654145237

Epoch: 6| Step: 7
Training loss: 2.8230981991289372
Validation loss: 2.4901397003765466

Epoch: 6| Step: 8
Training loss: 2.3578720863856963
Validation loss: 2.4770455976632704

Epoch: 6| Step: 9
Training loss: 3.1904541986164348
Validation loss: 2.465901373236776

Epoch: 6| Step: 10
Training loss: 2.2484816620434995
Validation loss: 2.479246157037673

Epoch: 6| Step: 11
Training loss: 2.836695041835829
Validation loss: 2.4764282856838196

Epoch: 6| Step: 12
Training loss: 3.405859688611065
Validation loss: 2.48477088176854

Epoch: 6| Step: 13
Training loss: 2.6272716683610318
Validation loss: 2.481870071928043

Epoch: 122| Step: 0
Training loss: 3.326021201125223
Validation loss: 2.4797166989912567

Epoch: 6| Step: 1
Training loss: 3.0600516984349673
Validation loss: 2.4792153341704597

Epoch: 6| Step: 2
Training loss: 2.944622090416883
Validation loss: 2.4829242144108115

Epoch: 6| Step: 3
Training loss: 2.710024897190041
Validation loss: 2.479083076268051

Epoch: 6| Step: 4
Training loss: 2.514331366539454
Validation loss: 2.474070880361342

Epoch: 6| Step: 5
Training loss: 2.5495498746133345
Validation loss: 2.4659603594169495

Epoch: 6| Step: 6
Training loss: 1.9623802318594377
Validation loss: 2.4752443521329646

Epoch: 6| Step: 7
Training loss: 3.3226980458314253
Validation loss: 2.4804251728617683

Epoch: 6| Step: 8
Training loss: 2.759449157063986
Validation loss: 2.479081981147013

Epoch: 6| Step: 9
Training loss: 3.1134579942184373
Validation loss: 2.4952758941512263

Epoch: 6| Step: 10
Training loss: 2.7707754334636263
Validation loss: 2.5131029691455122

Epoch: 6| Step: 11
Training loss: 2.3044272065670053
Validation loss: 2.507001761434563

Epoch: 6| Step: 12
Training loss: 2.440362569886627
Validation loss: 2.5146012401044326

Epoch: 6| Step: 13
Training loss: 2.8202636376372348
Validation loss: 2.516548121376177

Epoch: 123| Step: 0
Training loss: 2.4160832216000983
Validation loss: 2.4948350147878866

Epoch: 6| Step: 1
Training loss: 2.5103362982035144
Validation loss: 2.4850976431758434

Epoch: 6| Step: 2
Training loss: 2.303532508191796
Validation loss: 2.4719386880869307

Epoch: 6| Step: 3
Training loss: 1.857254229339619
Validation loss: 2.4693053796742266

Epoch: 6| Step: 4
Training loss: 3.579486038353424
Validation loss: 2.4707752610735945

Epoch: 6| Step: 5
Training loss: 2.534749567125319
Validation loss: 2.4724594717271873

Epoch: 6| Step: 6
Training loss: 3.0053134593503947
Validation loss: 2.4644937030891536

Epoch: 6| Step: 7
Training loss: 3.1636493931225975
Validation loss: 2.4754688563803624

Epoch: 6| Step: 8
Training loss: 3.2268918956880968
Validation loss: 2.4737433479476363

Epoch: 6| Step: 9
Training loss: 3.0553549113046103
Validation loss: 2.47309509518828

Epoch: 6| Step: 10
Training loss: 1.9827813184374077
Validation loss: 2.473673556678922

Epoch: 6| Step: 11
Training loss: 2.622338535222054
Validation loss: 2.4660699871268132

Epoch: 6| Step: 12
Training loss: 3.133338636704955
Validation loss: 2.4730545819770526

Epoch: 6| Step: 13
Training loss: 1.7779440065327143
Validation loss: 2.4854795508438894

Epoch: 124| Step: 0
Training loss: 2.969172397479161
Validation loss: 2.4905203690878803

Epoch: 6| Step: 1
Training loss: 3.0663986303149757
Validation loss: 2.5023283160667655

Epoch: 6| Step: 2
Training loss: 2.844187943827632
Validation loss: 2.508504075077906

Epoch: 6| Step: 3
Training loss: 2.2030306315671253
Validation loss: 2.5274363027218616

Epoch: 6| Step: 4
Training loss: 3.3817461196291707
Validation loss: 2.6100080367106697

Epoch: 6| Step: 5
Training loss: 3.3760846125950943
Validation loss: 2.6310775764646257

Epoch: 6| Step: 6
Training loss: 3.0034115784585937
Validation loss: 2.6381177334241857

Epoch: 6| Step: 7
Training loss: 2.5590117367903495
Validation loss: 2.625181766082494

Epoch: 6| Step: 8
Training loss: 2.296328005890802
Validation loss: 2.642162803589353

Epoch: 6| Step: 9
Training loss: 2.873957237546702
Validation loss: 2.595742384693167

Epoch: 6| Step: 10
Training loss: 2.07024432375954
Validation loss: 2.5624292615505415

Epoch: 6| Step: 11
Training loss: 2.95835421559302
Validation loss: 2.5434474956583237

Epoch: 6| Step: 12
Training loss: 2.0977060322741496
Validation loss: 2.5012423474070737

Epoch: 6| Step: 13
Training loss: 2.6289758998945887
Validation loss: 2.484219096864272

Epoch: 125| Step: 0
Training loss: 2.8691685456435887
Validation loss: 2.468405065379166

Epoch: 6| Step: 1
Training loss: 2.7211967945986713
Validation loss: 2.4565813472481315

Epoch: 6| Step: 2
Training loss: 2.5856247450598135
Validation loss: 2.467089764422395

Epoch: 6| Step: 3
Training loss: 3.2691957946563597
Validation loss: 2.4805135107777843

Epoch: 6| Step: 4
Training loss: 2.392458243967321
Validation loss: 2.4729356611605184

Epoch: 6| Step: 5
Training loss: 3.181175839622075
Validation loss: 2.4662263899551617

Epoch: 6| Step: 6
Training loss: 2.891539557866963
Validation loss: 2.4619764097111236

Epoch: 6| Step: 7
Training loss: 3.2532206496542644
Validation loss: 2.4577450605446236

Epoch: 6| Step: 8
Training loss: 2.8112435819383825
Validation loss: 2.453362559932049

Epoch: 6| Step: 9
Training loss: 2.3594252221023293
Validation loss: 2.452165248031398

Epoch: 6| Step: 10
Training loss: 2.64597955935448
Validation loss: 2.4406352592257785

Epoch: 6| Step: 11
Training loss: 2.738385991638666
Validation loss: 2.445185918335192

Epoch: 6| Step: 12
Training loss: 2.5941849309431695
Validation loss: 2.4386258350559245

Epoch: 6| Step: 13
Training loss: 2.771137842258284
Validation loss: 2.4517300351247715

Epoch: 126| Step: 0
Training loss: 2.350424050563698
Validation loss: 2.4935175364180076

Epoch: 6| Step: 1
Training loss: 2.7574783425332274
Validation loss: 2.557332434639525

Epoch: 6| Step: 2
Training loss: 3.3358648859558917
Validation loss: 2.5784436249939393

Epoch: 6| Step: 3
Training loss: 3.1799238337386173
Validation loss: 2.581974323736038

Epoch: 6| Step: 4
Training loss: 3.0686168696161267
Validation loss: 2.5535785382617986

Epoch: 6| Step: 5
Training loss: 2.7909412200598824
Validation loss: 2.5233072257225104

Epoch: 6| Step: 6
Training loss: 2.600983334703159
Validation loss: 2.4902490563375075

Epoch: 6| Step: 7
Training loss: 1.8196814102052608
Validation loss: 2.4499186257231167

Epoch: 6| Step: 8
Training loss: 2.45762852624689
Validation loss: 2.4462227501716653

Epoch: 6| Step: 9
Training loss: 2.7338663554536096
Validation loss: 2.43775537676514

Epoch: 6| Step: 10
Training loss: 3.083269651288014
Validation loss: 2.443919604725735

Epoch: 6| Step: 11
Training loss: 3.0306361255217333
Validation loss: 2.4383663534168325

Epoch: 6| Step: 12
Training loss: 2.82534316012642
Validation loss: 2.4430412074243444

Epoch: 6| Step: 13
Training loss: 2.2980504563903654
Validation loss: 2.4412452389362813

Epoch: 127| Step: 0
Training loss: 2.719359757019682
Validation loss: 2.4454589792539227

Epoch: 6| Step: 1
Training loss: 2.408193917732551
Validation loss: 2.4416175532298654

Epoch: 6| Step: 2
Training loss: 2.9797295169838427
Validation loss: 2.443106282895081

Epoch: 6| Step: 3
Training loss: 2.6150912415904846
Validation loss: 2.4405924929095426

Epoch: 6| Step: 4
Training loss: 3.064430718130319
Validation loss: 2.455946540722611

Epoch: 6| Step: 5
Training loss: 2.5354022595872086
Validation loss: 2.4663210272752463

Epoch: 6| Step: 6
Training loss: 2.71401705882278
Validation loss: 2.4930894698006374

Epoch: 6| Step: 7
Training loss: 2.9040597845812117
Validation loss: 2.512782838341815

Epoch: 6| Step: 8
Training loss: 2.6872951518211967
Validation loss: 2.543386079160652

Epoch: 6| Step: 9
Training loss: 3.0812665524918295
Validation loss: 2.5746437561071667

Epoch: 6| Step: 10
Training loss: 3.219822084712469
Validation loss: 2.535826236614541

Epoch: 6| Step: 11
Training loss: 2.4294854475685814
Validation loss: 2.520957596584941

Epoch: 6| Step: 12
Training loss: 2.5283056960819783
Validation loss: 2.5054111933692957

Epoch: 6| Step: 13
Training loss: 2.301780289486404
Validation loss: 2.4841859920644525

Epoch: 128| Step: 0
Training loss: 2.8656221113117595
Validation loss: 2.481632961009949

Epoch: 6| Step: 1
Training loss: 2.450525449342397
Validation loss: 2.475513552223351

Epoch: 6| Step: 2
Training loss: 2.0140342645315834
Validation loss: 2.491875091597753

Epoch: 6| Step: 3
Training loss: 3.65182331477563
Validation loss: 2.4857870330177803

Epoch: 6| Step: 4
Training loss: 2.341485111714646
Validation loss: 2.4765396321552564

Epoch: 6| Step: 5
Training loss: 2.8367370655305857
Validation loss: 2.4754174280812644

Epoch: 6| Step: 6
Training loss: 2.2698646602532713
Validation loss: 2.4783671113414196

Epoch: 6| Step: 7
Training loss: 2.4988293768071745
Validation loss: 2.483744142800009

Epoch: 6| Step: 8
Training loss: 2.9695549124698517
Validation loss: 2.479209616883533

Epoch: 6| Step: 9
Training loss: 3.294800019512429
Validation loss: 2.4769245459007294

Epoch: 6| Step: 10
Training loss: 2.4605305653134644
Validation loss: 2.4890341163008087

Epoch: 6| Step: 11
Training loss: 2.8158980293288978
Validation loss: 2.485920038735128

Epoch: 6| Step: 12
Training loss: 2.3155795032392072
Validation loss: 2.498835593975529

Epoch: 6| Step: 13
Training loss: 2.727225236768212
Validation loss: 2.527453088215579

Epoch: 129| Step: 0
Training loss: 2.8742041108157026
Validation loss: 2.5657132259513253

Epoch: 6| Step: 1
Training loss: 2.330038832967117
Validation loss: 2.5816715987779157

Epoch: 6| Step: 2
Training loss: 3.218116920210637
Validation loss: 2.6329363376357695

Epoch: 6| Step: 3
Training loss: 3.1752992383861867
Validation loss: 2.6260861387683034

Epoch: 6| Step: 4
Training loss: 2.72764124475733
Validation loss: 2.553128875935525

Epoch: 6| Step: 5
Training loss: 2.5741765159187167
Validation loss: 2.532735484156927

Epoch: 6| Step: 6
Training loss: 2.6538227435369097
Validation loss: 2.500557485585567

Epoch: 6| Step: 7
Training loss: 2.5183006889235373
Validation loss: 2.4820820752773227

Epoch: 6| Step: 8
Training loss: 2.3861720681191194
Validation loss: 2.4632803972573605

Epoch: 6| Step: 9
Training loss: 2.5515847685777153
Validation loss: 2.4560268449042044

Epoch: 6| Step: 10
Training loss: 3.254860837572084
Validation loss: 2.449265229058789

Epoch: 6| Step: 11
Training loss: 2.1341585376271386
Validation loss: 2.458310871915018

Epoch: 6| Step: 12
Training loss: 2.7983857235785896
Validation loss: 2.4542786102723304

Epoch: 6| Step: 13
Training loss: 3.0781821618363905
Validation loss: 2.463613797374331

Epoch: 130| Step: 0
Training loss: 3.0032343912991593
Validation loss: 2.452057511536292

Epoch: 6| Step: 1
Training loss: 3.0167891869156214
Validation loss: 2.468112993697759

Epoch: 6| Step: 2
Training loss: 2.8448242841201163
Validation loss: 2.488923779941394

Epoch: 6| Step: 3
Training loss: 2.8707512683701166
Validation loss: 2.498706612264074

Epoch: 6| Step: 4
Training loss: 2.9649978215690447
Validation loss: 2.5275026772187927

Epoch: 6| Step: 5
Training loss: 2.49030694594011
Validation loss: 2.5544784453839107

Epoch: 6| Step: 6
Training loss: 2.570938729753869
Validation loss: 2.522393977041279

Epoch: 6| Step: 7
Training loss: 2.4588557081669524
Validation loss: 2.5014004373983503

Epoch: 6| Step: 8
Training loss: 2.978922871749129
Validation loss: 2.4974523956194044

Epoch: 6| Step: 9
Training loss: 2.6468704673971484
Validation loss: 2.4818022714493844

Epoch: 6| Step: 10
Training loss: 2.5680845860606127
Validation loss: 2.486161637787197

Epoch: 6| Step: 11
Training loss: 2.593083031628034
Validation loss: 2.4806051340640507

Epoch: 6| Step: 12
Training loss: 2.6364794813312993
Validation loss: 2.4719134501982887

Epoch: 6| Step: 13
Training loss: 1.754010169809887
Validation loss: 2.4693389497450475

Epoch: 131| Step: 0
Training loss: 2.2912601688407013
Validation loss: 2.458860434337664

Epoch: 6| Step: 1
Training loss: 2.705653689191161
Validation loss: 2.47226744262435

Epoch: 6| Step: 2
Training loss: 2.1645694510706512
Validation loss: 2.4637928461569554

Epoch: 6| Step: 3
Training loss: 3.27424877374164
Validation loss: 2.4785837936145283

Epoch: 6| Step: 4
Training loss: 2.7790344500415647
Validation loss: 2.477446360361038

Epoch: 6| Step: 5
Training loss: 2.941689121783808
Validation loss: 2.4797739210885346

Epoch: 6| Step: 6
Training loss: 2.6075189808111707
Validation loss: 2.493646810175496

Epoch: 6| Step: 7
Training loss: 2.3124967008000112
Validation loss: 2.4921162120904734

Epoch: 6| Step: 8
Training loss: 2.6401827289458812
Validation loss: 2.5265345371790264

Epoch: 6| Step: 9
Training loss: 2.882655359136028
Validation loss: 2.490386925017417

Epoch: 6| Step: 10
Training loss: 2.5291371887935954
Validation loss: 2.4834690672448496

Epoch: 6| Step: 11
Training loss: 2.6708698724477977
Validation loss: 2.4904531376277648

Epoch: 6| Step: 12
Training loss: 2.856243816343997
Validation loss: 2.4794409832708566

Epoch: 6| Step: 13
Training loss: 3.207058161856101
Validation loss: 2.467735638738785

Epoch: 132| Step: 0
Training loss: 2.4941618462169837
Validation loss: 2.4691910843583567

Epoch: 6| Step: 1
Training loss: 2.4758688740558443
Validation loss: 2.4728523480805213

Epoch: 6| Step: 2
Training loss: 2.554412453686958
Validation loss: 2.466231744410305

Epoch: 6| Step: 3
Training loss: 2.4538869464142947
Validation loss: 2.467711347911429

Epoch: 6| Step: 4
Training loss: 2.4556481087428157
Validation loss: 2.4616845198539097

Epoch: 6| Step: 5
Training loss: 2.7241266513459395
Validation loss: 2.4630609885562396

Epoch: 6| Step: 6
Training loss: 2.899307655034222
Validation loss: 2.468365800442429

Epoch: 6| Step: 7
Training loss: 2.471209303077483
Validation loss: 2.4531968169408067

Epoch: 6| Step: 8
Training loss: 2.668954781530495
Validation loss: 2.457966802903387

Epoch: 6| Step: 9
Training loss: 3.0750106315118866
Validation loss: 2.4582040132936203

Epoch: 6| Step: 10
Training loss: 2.7976386876368613
Validation loss: 2.4540154015735665

Epoch: 6| Step: 11
Training loss: 2.931616227101175
Validation loss: 2.450248789905559

Epoch: 6| Step: 12
Training loss: 2.6161084128322454
Validation loss: 2.47160315919311

Epoch: 6| Step: 13
Training loss: 3.1054193072911556
Validation loss: 2.474986417369959

Epoch: 133| Step: 0
Training loss: 2.818153548308623
Validation loss: 2.46609652396589

Epoch: 6| Step: 1
Training loss: 2.567432308771885
Validation loss: 2.4526761325375377

Epoch: 6| Step: 2
Training loss: 2.799277696087334
Validation loss: 2.451244233393676

Epoch: 6| Step: 3
Training loss: 2.6326369954370183
Validation loss: 2.458527963135228

Epoch: 6| Step: 4
Training loss: 2.516094282460898
Validation loss: 2.4618156557823627

Epoch: 6| Step: 5
Training loss: 3.25762075321879
Validation loss: 2.4648951742583183

Epoch: 6| Step: 6
Training loss: 2.673746267978655
Validation loss: 2.454245622853944

Epoch: 6| Step: 7
Training loss: 2.7274286594029493
Validation loss: 2.4709184603270877

Epoch: 6| Step: 8
Training loss: 2.347406815211951
Validation loss: 2.45274188575347

Epoch: 6| Step: 9
Training loss: 2.807883733950715
Validation loss: 2.4455927007120803

Epoch: 6| Step: 10
Training loss: 2.5409270497629004
Validation loss: 2.4434794761078313

Epoch: 6| Step: 11
Training loss: 2.602504525304372
Validation loss: 2.445091188531544

Epoch: 6| Step: 12
Training loss: 2.8382874727902814
Validation loss: 2.4469292210626827

Epoch: 6| Step: 13
Training loss: 1.56769027784053
Validation loss: 2.44306830448803

Epoch: 134| Step: 0
Training loss: 3.2248493662112994
Validation loss: 2.4363209839180278

Epoch: 6| Step: 1
Training loss: 2.9603525353898417
Validation loss: 2.444804302100626

Epoch: 6| Step: 2
Training loss: 2.351801153600504
Validation loss: 2.4310063797104835

Epoch: 6| Step: 3
Training loss: 2.7291824301538634
Validation loss: 2.4289061858906775

Epoch: 6| Step: 4
Training loss: 3.4437668981674086
Validation loss: 2.435254930188477

Epoch: 6| Step: 5
Training loss: 2.5654140743481877
Validation loss: 2.4303522223188883

Epoch: 6| Step: 6
Training loss: 1.9520870044501386
Validation loss: 2.4419009106991423

Epoch: 6| Step: 7
Training loss: 2.592500316652961
Validation loss: 2.4447503579791747

Epoch: 6| Step: 8
Training loss: 2.61211502670149
Validation loss: 2.437567519837487

Epoch: 6| Step: 9
Training loss: 2.770251612201239
Validation loss: 2.449454359010347

Epoch: 6| Step: 10
Training loss: 3.035144624233687
Validation loss: 2.470679062572088

Epoch: 6| Step: 11
Training loss: 2.2827848731738087
Validation loss: 2.4748891643832884

Epoch: 6| Step: 12
Training loss: 2.085175793049867
Validation loss: 2.4987117462980173

Epoch: 6| Step: 13
Training loss: 2.2987536577918535
Validation loss: 2.5070451752137144

Epoch: 135| Step: 0
Training loss: 2.519287192182653
Validation loss: 2.465668846570333

Epoch: 6| Step: 1
Training loss: 2.8865666123538793
Validation loss: 2.455538962676913

Epoch: 6| Step: 2
Training loss: 2.499722751502875
Validation loss: 2.4632510647956773

Epoch: 6| Step: 3
Training loss: 2.5282124319153074
Validation loss: 2.447773021776376

Epoch: 6| Step: 4
Training loss: 2.7865364325205593
Validation loss: 2.437800132041936

Epoch: 6| Step: 5
Training loss: 2.5678715115605053
Validation loss: 2.442737767467497

Epoch: 6| Step: 6
Training loss: 2.473026097315378
Validation loss: 2.4311879817658264

Epoch: 6| Step: 7
Training loss: 2.7082466600683257
Validation loss: 2.4362662184838415

Epoch: 6| Step: 8
Training loss: 2.3613748727214543
Validation loss: 2.45248280109862

Epoch: 6| Step: 9
Training loss: 3.0266977322310336
Validation loss: 2.453319977859501

Epoch: 6| Step: 10
Training loss: 3.128068104473294
Validation loss: 2.4669196541493292

Epoch: 6| Step: 11
Training loss: 2.7825723997501077
Validation loss: 2.454466221699898

Epoch: 6| Step: 12
Training loss: 2.25253471017528
Validation loss: 2.4602103262410813

Epoch: 6| Step: 13
Training loss: 2.505436327123485
Validation loss: 2.4236411798092834

Epoch: 136| Step: 0
Training loss: 2.6705588506696754
Validation loss: 2.437654633898181

Epoch: 6| Step: 1
Training loss: 2.6472157048503986
Validation loss: 2.4321018749329286

Epoch: 6| Step: 2
Training loss: 2.336293375215729
Validation loss: 2.428507451538101

Epoch: 6| Step: 3
Training loss: 2.7278725174065457
Validation loss: 2.4206568191795914

Epoch: 6| Step: 4
Training loss: 2.372188711215069
Validation loss: 2.420929570796992

Epoch: 6| Step: 5
Training loss: 2.126140064265752
Validation loss: 2.4275455614771126

Epoch: 6| Step: 6
Training loss: 2.801132712132323
Validation loss: 2.433023842725758

Epoch: 6| Step: 7
Training loss: 2.9922837523275363
Validation loss: 2.423897607399461

Epoch: 6| Step: 8
Training loss: 2.677595740137282
Validation loss: 2.4250414601739716

Epoch: 6| Step: 9
Training loss: 2.777286748931593
Validation loss: 2.4582373788237386

Epoch: 6| Step: 10
Training loss: 2.2224129541984894
Validation loss: 2.465345733143512

Epoch: 6| Step: 11
Training loss: 3.1694758319405705
Validation loss: 2.4654532908563622

Epoch: 6| Step: 12
Training loss: 2.8671226390185773
Validation loss: 2.461324003761913

Epoch: 6| Step: 13
Training loss: 2.7011854677554776
Validation loss: 2.464724893796746

Epoch: 137| Step: 0
Training loss: 2.8987997399356473
Validation loss: 2.449899555714716

Epoch: 6| Step: 1
Training loss: 2.842668935675846
Validation loss: 2.4286013968069757

Epoch: 6| Step: 2
Training loss: 2.811064120500098
Validation loss: 2.42689232829662

Epoch: 6| Step: 3
Training loss: 2.6105355976733913
Validation loss: 2.4200462081533005

Epoch: 6| Step: 4
Training loss: 2.6786885971600767
Validation loss: 2.4202114376495745

Epoch: 6| Step: 5
Training loss: 2.3585097387362266
Validation loss: 2.4221916401922496

Epoch: 6| Step: 6
Training loss: 2.5562164677516814
Validation loss: 2.4390135652254123

Epoch: 6| Step: 7
Training loss: 2.4771422661224176
Validation loss: 2.4079529013396064

Epoch: 6| Step: 8
Training loss: 2.5863398213043562
Validation loss: 2.427735089898826

Epoch: 6| Step: 9
Training loss: 2.9289989425224876
Validation loss: 2.4134024603708504

Epoch: 6| Step: 10
Training loss: 2.1635300845511285
Validation loss: 2.4198916588944854

Epoch: 6| Step: 11
Training loss: 2.752898942411015
Validation loss: 2.423055577397284

Epoch: 6| Step: 12
Training loss: 2.5253572985462958
Validation loss: 2.4192421332806915

Epoch: 6| Step: 13
Training loss: 3.029764027487266
Validation loss: 2.4276793873504583

Epoch: 138| Step: 0
Training loss: 2.5017587197598674
Validation loss: 2.437356568631901

Epoch: 6| Step: 1
Training loss: 3.056135141909669
Validation loss: 2.4526788982468815

Epoch: 6| Step: 2
Training loss: 2.42765050545245
Validation loss: 2.495440329380703

Epoch: 6| Step: 3
Training loss: 3.0627844542141838
Validation loss: 2.5232067570945644

Epoch: 6| Step: 4
Training loss: 2.589238943419828
Validation loss: 2.521118485233412

Epoch: 6| Step: 5
Training loss: 1.8193245363722879
Validation loss: 2.500213888719474

Epoch: 6| Step: 6
Training loss: 2.680443304036171
Validation loss: 2.506754575401857

Epoch: 6| Step: 7
Training loss: 2.403772837767916
Validation loss: 2.55211936083124

Epoch: 6| Step: 8
Training loss: 2.620457124216299
Validation loss: 2.547906046479586

Epoch: 6| Step: 9
Training loss: 2.5781616208336606
Validation loss: 2.5262245659200033

Epoch: 6| Step: 10
Training loss: 2.9557886775855557
Validation loss: 2.4697643380569896

Epoch: 6| Step: 11
Training loss: 2.8292972390368054
Validation loss: 2.4476307187253887

Epoch: 6| Step: 12
Training loss: 2.7739621807839994
Validation loss: 2.4342283279670536

Epoch: 6| Step: 13
Training loss: 2.654856956062477
Validation loss: 2.4264245358922736

Epoch: 139| Step: 0
Training loss: 2.656691929574634
Validation loss: 2.4186889258737727

Epoch: 6| Step: 1
Training loss: 2.449075454340819
Validation loss: 2.4129686296907042

Epoch: 6| Step: 2
Training loss: 2.8756971757864513
Validation loss: 2.420660948218175

Epoch: 6| Step: 3
Training loss: 2.7517581001523643
Validation loss: 2.45547724966624

Epoch: 6| Step: 4
Training loss: 2.3094509747181178
Validation loss: 2.5180803455124923

Epoch: 6| Step: 5
Training loss: 2.933941247831582
Validation loss: 2.532940955922084

Epoch: 6| Step: 6
Training loss: 2.4881976965465604
Validation loss: 2.551212816439667

Epoch: 6| Step: 7
Training loss: 2.874224516729826
Validation loss: 2.5898696016386107

Epoch: 6| Step: 8
Training loss: 2.5205244605465307
Validation loss: 2.5851682410954697

Epoch: 6| Step: 9
Training loss: 2.238822938038688
Validation loss: 2.5421743432273343

Epoch: 6| Step: 10
Training loss: 3.1535291369283485
Validation loss: 2.5104583857950398

Epoch: 6| Step: 11
Training loss: 2.7937906829807524
Validation loss: 2.463389312716631

Epoch: 6| Step: 12
Training loss: 2.2284131306540944
Validation loss: 2.4322374548674954

Epoch: 6| Step: 13
Training loss: 2.6916641975446622
Validation loss: 2.423616826784018

Epoch: 140| Step: 0
Training loss: 2.710408007886242
Validation loss: 2.4141096718542654

Epoch: 6| Step: 1
Training loss: 2.728644944814785
Validation loss: 2.412454708668226

Epoch: 6| Step: 2
Training loss: 2.3906864332894964
Validation loss: 2.4108571519744793

Epoch: 6| Step: 3
Training loss: 2.3203488742019496
Validation loss: 2.4094460757160254

Epoch: 6| Step: 4
Training loss: 2.9168285506599996
Validation loss: 2.4123390455418163

Epoch: 6| Step: 5
Training loss: 2.76814706751799
Validation loss: 2.40623870450626

Epoch: 6| Step: 6
Training loss: 2.0374101396649307
Validation loss: 2.4151652684271263

Epoch: 6| Step: 7
Training loss: 2.7989849464581384
Validation loss: 2.4577020130318323

Epoch: 6| Step: 8
Training loss: 2.965592964409344
Validation loss: 2.4971742862897752

Epoch: 6| Step: 9
Training loss: 2.633469768402069
Validation loss: 2.4923384899055936

Epoch: 6| Step: 10
Training loss: 2.602844197490959
Validation loss: 2.484595780853471

Epoch: 6| Step: 11
Training loss: 2.929507481448427
Validation loss: 2.4770428208667163

Epoch: 6| Step: 12
Training loss: 2.5529353581458136
Validation loss: 2.452484236328894

Epoch: 6| Step: 13
Training loss: 2.695880951576316
Validation loss: 2.4282020438690664

Epoch: 141| Step: 0
Training loss: 2.638729972962133
Validation loss: 2.440269322178084

Epoch: 6| Step: 1
Training loss: 2.729109659157683
Validation loss: 2.4284579750857276

Epoch: 6| Step: 2
Training loss: 2.6088808242756967
Validation loss: 2.4056060178580054

Epoch: 6| Step: 3
Training loss: 2.128859997168138
Validation loss: 2.411704020313342

Epoch: 6| Step: 4
Training loss: 3.0913202782342157
Validation loss: 2.4192922061756845

Epoch: 6| Step: 5
Training loss: 2.910030080633262
Validation loss: 2.430539631202984

Epoch: 6| Step: 6
Training loss: 2.6517768445034045
Validation loss: 2.442767807497788

Epoch: 6| Step: 7
Training loss: 2.1741917829523727
Validation loss: 2.4407559407754054

Epoch: 6| Step: 8
Training loss: 2.2918750552595353
Validation loss: 2.4541547933935766

Epoch: 6| Step: 9
Training loss: 2.7583191490000716
Validation loss: 2.4770013331062843

Epoch: 6| Step: 10
Training loss: 2.756268120184954
Validation loss: 2.4484827204467905

Epoch: 6| Step: 11
Training loss: 3.0366703611561494
Validation loss: 2.4606455994244536

Epoch: 6| Step: 12
Training loss: 2.451871709731454
Validation loss: 2.406550004760973

Epoch: 6| Step: 13
Training loss: 2.338284541368956
Validation loss: 2.439843539683937

Epoch: 142| Step: 0
Training loss: 2.865370671125601
Validation loss: 2.4227872413265654

Epoch: 6| Step: 1
Training loss: 2.2449969723687433
Validation loss: 2.449601063112047

Epoch: 6| Step: 2
Training loss: 2.871679627722658
Validation loss: 2.4515140454282176

Epoch: 6| Step: 3
Training loss: 2.167927949538653
Validation loss: 2.4704297754140496

Epoch: 6| Step: 4
Training loss: 2.7669353936762455
Validation loss: 2.504376403756935

Epoch: 6| Step: 5
Training loss: 2.9265231934864553
Validation loss: 2.511418669859151

Epoch: 6| Step: 6
Training loss: 2.783659673355022
Validation loss: 2.5421163156849675

Epoch: 6| Step: 7
Training loss: 2.1674774438020963
Validation loss: 2.6113986413227743

Epoch: 6| Step: 8
Training loss: 2.896585124469982
Validation loss: 2.619963181107876

Epoch: 6| Step: 9
Training loss: 3.274744469377982
Validation loss: 2.6093228753537665

Epoch: 6| Step: 10
Training loss: 2.810424886870092
Validation loss: 2.523216519041939

Epoch: 6| Step: 11
Training loss: 2.6042148026150187
Validation loss: 2.49707372819339

Epoch: 6| Step: 12
Training loss: 2.4123537009356584
Validation loss: 2.476004333213259

Epoch: 6| Step: 13
Training loss: 1.8656261092650728
Validation loss: 2.447997346664284

Epoch: 143| Step: 0
Training loss: 2.213739351907169
Validation loss: 2.463486970781106

Epoch: 6| Step: 1
Training loss: 2.2356926294111017
Validation loss: 2.457432195005765

Epoch: 6| Step: 2
Training loss: 2.2858208627206498
Validation loss: 2.473763273587871

Epoch: 6| Step: 3
Training loss: 2.7478880141593462
Validation loss: 2.473111170918582

Epoch: 6| Step: 4
Training loss: 3.2169528128946228
Validation loss: 2.484942612261742

Epoch: 6| Step: 5
Training loss: 2.823862731358488
Validation loss: 2.455739951963413

Epoch: 6| Step: 6
Training loss: 2.7904164850437043
Validation loss: 2.4547033343407514

Epoch: 6| Step: 7
Training loss: 1.4698853669915717
Validation loss: 2.453974900359145

Epoch: 6| Step: 8
Training loss: 2.9867823612704343
Validation loss: 2.457148862224378

Epoch: 6| Step: 9
Training loss: 2.9564537381378915
Validation loss: 2.451342198559183

Epoch: 6| Step: 10
Training loss: 2.825078345368621
Validation loss: 2.4582654002630218

Epoch: 6| Step: 11
Training loss: 2.4838738085870755
Validation loss: 2.462448400624468

Epoch: 6| Step: 12
Training loss: 2.597366661049212
Validation loss: 2.494035013714507

Epoch: 6| Step: 13
Training loss: 2.9347813789008814
Validation loss: 2.516039032170507

Epoch: 144| Step: 0
Training loss: 2.4938435090012554
Validation loss: 2.521642111958748

Epoch: 6| Step: 1
Training loss: 2.784954903749425
Validation loss: 2.523143251189426

Epoch: 6| Step: 2
Training loss: 2.667180448946267
Validation loss: 2.4944099738680787

Epoch: 6| Step: 3
Training loss: 2.1670545695378176
Validation loss: 2.4842146500997337

Epoch: 6| Step: 4
Training loss: 2.3695905215795654
Validation loss: 2.4845136703205166

Epoch: 6| Step: 5
Training loss: 2.285543294880015
Validation loss: 2.48420125299958

Epoch: 6| Step: 6
Training loss: 2.4822464947759797
Validation loss: 2.4858265652424385

Epoch: 6| Step: 7
Training loss: 2.44764417930863
Validation loss: 2.483427448379155

Epoch: 6| Step: 8
Training loss: 2.7472048339019177
Validation loss: 2.4596321546604734

Epoch: 6| Step: 9
Training loss: 2.9716480766167055
Validation loss: 2.43182972990059

Epoch: 6| Step: 10
Training loss: 2.523598491623386
Validation loss: 2.4099257060367894

Epoch: 6| Step: 11
Training loss: 2.821413876528007
Validation loss: 2.41888874301829

Epoch: 6| Step: 12
Training loss: 2.3754300179937404
Validation loss: 2.4163619706147146

Epoch: 6| Step: 13
Training loss: 3.427890037197328
Validation loss: 2.4148112555349686

Epoch: 145| Step: 0
Training loss: 2.9475031226791133
Validation loss: 2.412570297179361

Epoch: 6| Step: 1
Training loss: 2.047979741048449
Validation loss: 2.4202229316860233

Epoch: 6| Step: 2
Training loss: 2.624187161981477
Validation loss: 2.4529280752336926

Epoch: 6| Step: 3
Training loss: 2.8545416332742795
Validation loss: 2.49095317403484

Epoch: 6| Step: 4
Training loss: 1.9717675350546606
Validation loss: 2.536442681664114

Epoch: 6| Step: 5
Training loss: 2.6810907632275454
Validation loss: 2.6028610329848805

Epoch: 6| Step: 6
Training loss: 2.7301076669386855
Validation loss: 2.6343081064520857

Epoch: 6| Step: 7
Training loss: 2.1973199863067054
Validation loss: 2.5704799028690926

Epoch: 6| Step: 8
Training loss: 2.3256429460054027
Validation loss: 2.4878924701597986

Epoch: 6| Step: 9
Training loss: 2.920954268523585
Validation loss: 2.4539320118436487

Epoch: 6| Step: 10
Training loss: 2.7524378981067983
Validation loss: 2.449347693330259

Epoch: 6| Step: 11
Training loss: 2.5902530122402005
Validation loss: 2.456572178331872

Epoch: 6| Step: 12
Training loss: 2.409016987564536
Validation loss: 2.4618731382793273

Epoch: 6| Step: 13
Training loss: 2.7469925474462245
Validation loss: 2.4737664002002644

Epoch: 146| Step: 0
Training loss: 1.730474467730925
Validation loss: 2.494307901386756

Epoch: 6| Step: 1
Training loss: 2.5963872348180694
Validation loss: 2.4601396300210236

Epoch: 6| Step: 2
Training loss: 3.01162501880733
Validation loss: 2.481137129011934

Epoch: 6| Step: 3
Training loss: 2.5666449913331695
Validation loss: 2.48800330408588

Epoch: 6| Step: 4
Training loss: 2.4396716494147337
Validation loss: 2.5250551882747314

Epoch: 6| Step: 5
Training loss: 2.9208235047121063
Validation loss: 2.5163301908626847

Epoch: 6| Step: 6
Training loss: 2.0973502562839093
Validation loss: 2.476854926037882

Epoch: 6| Step: 7
Training loss: 2.6537061290735307
Validation loss: 2.473209665138418

Epoch: 6| Step: 8
Training loss: 2.5726342194207894
Validation loss: 2.5152632368423156

Epoch: 6| Step: 9
Training loss: 2.674893999227725
Validation loss: 2.5260809437461966

Epoch: 6| Step: 10
Training loss: 3.073167866067883
Validation loss: 2.522409935752838

Epoch: 6| Step: 11
Training loss: 2.164542354995019
Validation loss: 2.5467442505939673

Epoch: 6| Step: 12
Training loss: 2.3462063950646344
Validation loss: 2.517337994175277

Epoch: 6| Step: 13
Training loss: 2.64642383463965
Validation loss: 2.508373455497617

Epoch: 147| Step: 0
Training loss: 2.3639202672676545
Validation loss: 2.488501897539693

Epoch: 6| Step: 1
Training loss: 3.0368702490770008
Validation loss: 2.490528826290624

Epoch: 6| Step: 2
Training loss: 3.049809221648487
Validation loss: 2.464127206920016

Epoch: 6| Step: 3
Training loss: 1.7665694419930933
Validation loss: 2.465549847140246

Epoch: 6| Step: 4
Training loss: 2.809097520748078
Validation loss: 2.457394471907205

Epoch: 6| Step: 5
Training loss: 1.9128051364796212
Validation loss: 2.4531929629026696

Epoch: 6| Step: 6
Training loss: 2.0491141382377602
Validation loss: 2.4539064169041813

Epoch: 6| Step: 7
Training loss: 2.347474457720654
Validation loss: 2.4447600730003423

Epoch: 6| Step: 8
Training loss: 2.430358205382434
Validation loss: 2.4502511361821475

Epoch: 6| Step: 9
Training loss: 2.6029701434140353
Validation loss: 2.472829760052846

Epoch: 6| Step: 10
Training loss: 2.2652845455743993
Validation loss: 2.5139705165253736

Epoch: 6| Step: 11
Training loss: 2.1370376265287674
Validation loss: 2.5887241807164036

Epoch: 6| Step: 12
Training loss: 3.3524052198468848
Validation loss: 2.631674906034101

Epoch: 6| Step: 13
Training loss: 2.6102207663405874
Validation loss: 2.5793787886022246

Epoch: 148| Step: 0
Training loss: 2.315034456923517
Validation loss: 2.5712782567154635

Epoch: 6| Step: 1
Training loss: 2.509146362377945
Validation loss: 2.4698122158145353

Epoch: 6| Step: 2
Training loss: 2.479887934890748
Validation loss: 2.4528883420199925

Epoch: 6| Step: 3
Training loss: 2.7132594473742957
Validation loss: 2.443257428848794

Epoch: 6| Step: 4
Training loss: 2.0704048567990583
Validation loss: 2.435687691088458

Epoch: 6| Step: 5
Training loss: 2.5787656045978724
Validation loss: 2.438969477600723

Epoch: 6| Step: 6
Training loss: 2.154999301140267
Validation loss: 2.4359117060301405

Epoch: 6| Step: 7
Training loss: 2.952689971367905
Validation loss: 2.4652945325013356

Epoch: 6| Step: 8
Training loss: 1.9410479884713268
Validation loss: 2.4959079485134463

Epoch: 6| Step: 9
Training loss: 3.0350146954100534
Validation loss: 2.551491799693228

Epoch: 6| Step: 10
Training loss: 2.512711063458697
Validation loss: 2.551760788291471

Epoch: 6| Step: 11
Training loss: 1.7623383305849574
Validation loss: 2.549888404955512

Epoch: 6| Step: 12
Training loss: 3.130964309542572
Validation loss: 2.5199070259707264

Epoch: 6| Step: 13
Training loss: 2.9387296984063385
Validation loss: 2.5349409224717947

Epoch: 149| Step: 0
Training loss: 2.495003475576667
Validation loss: 2.5402878690067894

Epoch: 6| Step: 1
Training loss: 2.556945735947877
Validation loss: 2.5361480812883856

Epoch: 6| Step: 2
Training loss: 2.040607086617094
Validation loss: 2.5133063973027125

Epoch: 6| Step: 3
Training loss: 2.7249763487743146
Validation loss: 2.498984992188109

Epoch: 6| Step: 4
Training loss: 2.5692938087457375
Validation loss: 2.4629060064379704

Epoch: 6| Step: 5
Training loss: 2.0168766600723456
Validation loss: 2.4534446623513566

Epoch: 6| Step: 6
Training loss: 2.718774554262324
Validation loss: 2.4410708060884323

Epoch: 6| Step: 7
Training loss: 2.4742120124187945
Validation loss: 2.459447239885125

Epoch: 6| Step: 8
Training loss: 2.6724424596146448
Validation loss: 2.460469028555867

Epoch: 6| Step: 9
Training loss: 2.448679011252084
Validation loss: 2.4746370033405114

Epoch: 6| Step: 10
Training loss: 2.644798637181627
Validation loss: 2.5063588621583768

Epoch: 6| Step: 11
Training loss: 2.7226019570671687
Validation loss: 2.517090271008152

Epoch: 6| Step: 12
Training loss: 2.4022285247709863
Validation loss: 2.5437575672612867

Epoch: 6| Step: 13
Training loss: 2.2510986824587955
Validation loss: 2.531229124156571

Epoch: 150| Step: 0
Training loss: 2.5777205641287377
Validation loss: 2.576856013601389

Epoch: 6| Step: 1
Training loss: 2.494111469429973
Validation loss: 2.6142425772631466

Epoch: 6| Step: 2
Training loss: 2.6607376785200914
Validation loss: 2.604671043199669

Epoch: 6| Step: 3
Training loss: 3.012414201329813
Validation loss: 2.5648307235202212

Epoch: 6| Step: 4
Training loss: 2.2750026912463692
Validation loss: 2.481416953084937

Epoch: 6| Step: 5
Training loss: 3.1953686100666414
Validation loss: 2.447426899910157

Epoch: 6| Step: 6
Training loss: 2.6471756261100605
Validation loss: 2.4378865537357997

Epoch: 6| Step: 7
Training loss: 2.5368996196491067
Validation loss: 2.4152810477690227

Epoch: 6| Step: 8
Training loss: 2.1748381236554652
Validation loss: 2.4452694836647475

Epoch: 6| Step: 9
Training loss: 2.6769148381466485
Validation loss: 2.444638395197245

Epoch: 6| Step: 10
Training loss: 2.256897632080794
Validation loss: 2.469839554246555

Epoch: 6| Step: 11
Training loss: 2.0738407803578824
Validation loss: 2.4929410695433702

Epoch: 6| Step: 12
Training loss: 1.864524954054188
Validation loss: 2.5360432438653056

Epoch: 6| Step: 13
Training loss: 1.7052932376343404
Validation loss: 2.5618832133779765

Epoch: 151| Step: 0
Training loss: 2.8691632274467103
Validation loss: 2.6287910375109433

Epoch: 6| Step: 1
Training loss: 2.382350389040132
Validation loss: 2.6018481674364176

Epoch: 6| Step: 2
Training loss: 1.9869147440681274
Validation loss: 2.496582373707841

Epoch: 6| Step: 3
Training loss: 2.049555995588492
Validation loss: 2.4477872592196097

Epoch: 6| Step: 4
Training loss: 2.798350451130982
Validation loss: 2.4352435544737348

Epoch: 6| Step: 5
Training loss: 2.359722187695108
Validation loss: 2.4193923382604554

Epoch: 6| Step: 6
Training loss: 2.878603128652861
Validation loss: 2.4399049945775393

Epoch: 6| Step: 7
Training loss: 2.6059260617567914
Validation loss: 2.4478375431033474

Epoch: 6| Step: 8
Training loss: 3.0833676997838437
Validation loss: 2.461567165999261

Epoch: 6| Step: 9
Training loss: 2.309123486771689
Validation loss: 2.4864223859231585

Epoch: 6| Step: 10
Training loss: 2.279273757882717
Validation loss: 2.527445853583574

Epoch: 6| Step: 11
Training loss: 2.0714877265789404
Validation loss: 2.5649613205682873

Epoch: 6| Step: 12
Training loss: 2.5489832103800363
Validation loss: 2.5768907363729188

Epoch: 6| Step: 13
Training loss: 2.0262551738618835
Validation loss: 2.62131887000716

Epoch: 152| Step: 0
Training loss: 2.7808844508280854
Validation loss: 2.648109424184767

Epoch: 6| Step: 1
Training loss: 2.606168135493922
Validation loss: 2.625636836559682

Epoch: 6| Step: 2
Training loss: 2.4346280907830025
Validation loss: 2.569810528235404

Epoch: 6| Step: 3
Training loss: 2.2420032172949895
Validation loss: 2.5397695188376876

Epoch: 6| Step: 4
Training loss: 1.7654851672409146
Validation loss: 2.491599922865246

Epoch: 6| Step: 5
Training loss: 2.654880933803729
Validation loss: 2.469994788411593

Epoch: 6| Step: 6
Training loss: 3.098528321936209
Validation loss: 2.4591743555947225

Epoch: 6| Step: 7
Training loss: 1.9402481401176763
Validation loss: 2.4541979626677377

Epoch: 6| Step: 8
Training loss: 2.62218051444396
Validation loss: 2.4502961361291358

Epoch: 6| Step: 9
Training loss: 2.724240426408599
Validation loss: 2.441678936174423

Epoch: 6| Step: 10
Training loss: 2.34460667530474
Validation loss: 2.4557493891462046

Epoch: 6| Step: 11
Training loss: 2.6094279026904728
Validation loss: 2.4947757011822587

Epoch: 6| Step: 12
Training loss: 2.324701852037525
Validation loss: 2.486372318372406

Epoch: 6| Step: 13
Training loss: 1.638847114368229
Validation loss: 2.540045802541798

Epoch: 153| Step: 0
Training loss: 2.622445907544021
Validation loss: 2.5904366978747135

Epoch: 6| Step: 1
Training loss: 2.583047502353385
Validation loss: 2.5917244197457925

Epoch: 6| Step: 2
Training loss: 2.246516391961792
Validation loss: 2.645938600541078

Epoch: 6| Step: 3
Training loss: 1.9072485637811896
Validation loss: 2.690569359964388

Epoch: 6| Step: 4
Training loss: 2.469915766650382
Validation loss: 2.663717383529096

Epoch: 6| Step: 5
Training loss: 2.4048801833223363
Validation loss: 2.649109664862333

Epoch: 6| Step: 6
Training loss: 2.29797440770758
Validation loss: 2.6028067863150803

Epoch: 6| Step: 7
Training loss: 2.8634974045499426
Validation loss: 2.5634918874349912

Epoch: 6| Step: 8
Training loss: 2.3028616186549447
Validation loss: 2.4743048927214195

Epoch: 6| Step: 9
Training loss: 2.472971915635117
Validation loss: 2.445729241361914

Epoch: 6| Step: 10
Training loss: 2.7927321113694425
Validation loss: 2.4391621417157743

Epoch: 6| Step: 11
Training loss: 2.6791484501893237
Validation loss: 2.4356122485952985

Epoch: 6| Step: 12
Training loss: 2.2081450496036514
Validation loss: 2.445307302077943

Epoch: 6| Step: 13
Training loss: 2.4094381638298636
Validation loss: 2.4612678343889094

Epoch: 154| Step: 0
Training loss: 2.4489201754625145
Validation loss: 2.4893058251137283

Epoch: 6| Step: 1
Training loss: 2.7727026597194095
Validation loss: 2.520459537832308

Epoch: 6| Step: 2
Training loss: 2.3373283404797274
Validation loss: 2.5666801728621844

Epoch: 6| Step: 3
Training loss: 2.134277511313909
Validation loss: 2.625956419212789

Epoch: 6| Step: 4
Training loss: 2.0572964310087896
Validation loss: 2.657063605095221

Epoch: 6| Step: 5
Training loss: 2.16825444169119
Validation loss: 2.710442883059684

Epoch: 6| Step: 6
Training loss: 3.046848394815733
Validation loss: 2.6914315995164224

Epoch: 6| Step: 7
Training loss: 2.190411836752943
Validation loss: 2.6194311950130094

Epoch: 6| Step: 8
Training loss: 2.0705960061633815
Validation loss: 2.574369944680828

Epoch: 6| Step: 9
Training loss: 2.9233367038070868
Validation loss: 2.5097695494698877

Epoch: 6| Step: 10
Training loss: 2.491424730817902
Validation loss: 2.4793292619870924

Epoch: 6| Step: 11
Training loss: 1.9560248248391334
Validation loss: 2.4629154911070685

Epoch: 6| Step: 12
Training loss: 2.7755287560189825
Validation loss: 2.4557079404351754

Epoch: 6| Step: 13
Training loss: 2.6919144149314396
Validation loss: 2.448565146681741

Epoch: 155| Step: 0
Training loss: 2.7296757890507948
Validation loss: 2.462396444272565

Epoch: 6| Step: 1
Training loss: 2.6003405934775934
Validation loss: 2.468855317043465

Epoch: 6| Step: 2
Training loss: 2.4402825539004893
Validation loss: 2.503668583202457

Epoch: 6| Step: 3
Training loss: 2.4999988555905586
Validation loss: 2.5171158187749914

Epoch: 6| Step: 4
Training loss: 2.5407438843936996
Validation loss: 2.5480269245304004

Epoch: 6| Step: 5
Training loss: 2.682167973798966
Validation loss: 2.5848124600009883

Epoch: 6| Step: 6
Training loss: 2.249982409938295
Validation loss: 2.579318049757596

Epoch: 6| Step: 7
Training loss: 2.46570805360183
Validation loss: 2.5902249988852977

Epoch: 6| Step: 8
Training loss: 2.5574232845789036
Validation loss: 2.610331766124301

Epoch: 6| Step: 9
Training loss: 1.175081165026495
Validation loss: 2.604791091053952

Epoch: 6| Step: 10
Training loss: 2.4546516673230534
Validation loss: 2.5898052472496356

Epoch: 6| Step: 11
Training loss: 2.1467061782936367
Validation loss: 2.5897353249259214

Epoch: 6| Step: 12
Training loss: 2.4155726971213523
Validation loss: 2.5414547094696576

Epoch: 6| Step: 13
Training loss: 2.62923108569592
Validation loss: 2.5148557795039337

Epoch: 156| Step: 0
Training loss: 2.5470000628324216
Validation loss: 2.467596735654703

Epoch: 6| Step: 1
Training loss: 2.156379253549324
Validation loss: 2.436295107680014

Epoch: 6| Step: 2
Training loss: 2.0602508766219665
Validation loss: 2.480052340663406

Epoch: 6| Step: 3
Training loss: 2.961366164447842
Validation loss: 2.426935662436186

Epoch: 6| Step: 4
Training loss: 2.0611536660246954
Validation loss: 2.446239867090393

Epoch: 6| Step: 5
Training loss: 1.70084992087445
Validation loss: 2.4823051545185306

Epoch: 6| Step: 6
Training loss: 2.6850599700652276
Validation loss: 2.507289681321224

Epoch: 6| Step: 7
Training loss: 2.3072719759707248
Validation loss: 2.5401420243269905

Epoch: 6| Step: 8
Training loss: 2.269667183092992
Validation loss: 2.5905498298834373

Epoch: 6| Step: 9
Training loss: 3.0365791274963323
Validation loss: 2.620294947319631

Epoch: 6| Step: 10
Training loss: 2.159312188522642
Validation loss: 2.672220665060406

Epoch: 6| Step: 11
Training loss: 2.260640626937182
Validation loss: 2.690530276721673

Epoch: 6| Step: 12
Training loss: 2.577974627184248
Validation loss: 2.6573665214652107

Epoch: 6| Step: 13
Training loss: 2.656877869842494
Validation loss: 2.6460177688581785

Epoch: 157| Step: 0
Training loss: 2.2252523214878597
Validation loss: 2.5560516070228547

Epoch: 6| Step: 1
Training loss: 1.9235882449789803
Validation loss: 2.514128865622902

Epoch: 6| Step: 2
Training loss: 1.9945628049022635
Validation loss: 2.4625235508592698

Epoch: 6| Step: 3
Training loss: 2.4255131129482654
Validation loss: 2.442749156033997

Epoch: 6| Step: 4
Training loss: 2.6117967343476542
Validation loss: 2.4396652625601

Epoch: 6| Step: 5
Training loss: 2.359814533446047
Validation loss: 2.4367234965499582

Epoch: 6| Step: 6
Training loss: 2.6645177189371494
Validation loss: 2.4382498581381022

Epoch: 6| Step: 7
Training loss: 2.9544603668978726
Validation loss: 2.4553116974542335

Epoch: 6| Step: 8
Training loss: 2.1721167121145593
Validation loss: 2.4716145833056737

Epoch: 6| Step: 9
Training loss: 2.4307615598540835
Validation loss: 2.476460584243278

Epoch: 6| Step: 10
Training loss: 2.1306505808996894
Validation loss: 2.5093029399015134

Epoch: 6| Step: 11
Training loss: 2.6791212189786124
Validation loss: 2.554879278585123

Epoch: 6| Step: 12
Training loss: 2.67515193472078
Validation loss: 2.601489549066273

Epoch: 6| Step: 13
Training loss: 1.9862825731663856
Validation loss: 2.616565627647691

Epoch: 158| Step: 0
Training loss: 2.767612239005523
Validation loss: 2.644303337206879

Epoch: 6| Step: 1
Training loss: 2.1720807094717896
Validation loss: 2.598730239823422

Epoch: 6| Step: 2
Training loss: 2.3002247161553613
Validation loss: 2.5418843022015998

Epoch: 6| Step: 3
Training loss: 1.8603109360311358
Validation loss: 2.4873282324761297

Epoch: 6| Step: 4
Training loss: 2.7574983153074344
Validation loss: 2.4443837721449335

Epoch: 6| Step: 5
Training loss: 2.046315939463597
Validation loss: 2.4363060617877226

Epoch: 6| Step: 6
Training loss: 2.7221786101950074
Validation loss: 2.4284555871679507

Epoch: 6| Step: 7
Training loss: 2.9872061995962467
Validation loss: 2.4257592815561444

Epoch: 6| Step: 8
Training loss: 2.8794415207952544
Validation loss: 2.43878060885989

Epoch: 6| Step: 9
Training loss: 2.1041469636000927
Validation loss: 2.468476164628303

Epoch: 6| Step: 10
Training loss: 1.650600153697395
Validation loss: 2.51155142160651

Epoch: 6| Step: 11
Training loss: 2.6272847359818727
Validation loss: 2.5489983237450304

Epoch: 6| Step: 12
Training loss: 1.9512679159452613
Validation loss: 2.559873913553946

Epoch: 6| Step: 13
Training loss: 1.7569082010959614
Validation loss: 2.6149169907696095

Epoch: 159| Step: 0
Training loss: 2.3523249103117316
Validation loss: 2.647562094107263

Epoch: 6| Step: 1
Training loss: 2.697832339428275
Validation loss: 2.6612383238583965

Epoch: 6| Step: 2
Training loss: 2.001513980989134
Validation loss: 2.682437349340222

Epoch: 6| Step: 3
Training loss: 2.834057397512877
Validation loss: 2.6302910319733073

Epoch: 6| Step: 4
Training loss: 2.7570845640134687
Validation loss: 2.592500322586169

Epoch: 6| Step: 5
Training loss: 1.964855156139234
Validation loss: 2.554872509442337

Epoch: 6| Step: 6
Training loss: 2.5017381347911614
Validation loss: 2.5626180197937303

Epoch: 6| Step: 7
Training loss: 2.366397839263951
Validation loss: 2.5675478173303268

Epoch: 6| Step: 8
Training loss: 2.350842235683104
Validation loss: 2.5656705920644383

Epoch: 6| Step: 9
Training loss: 2.565524293732842
Validation loss: 2.544604082902096

Epoch: 6| Step: 10
Training loss: 1.9314333782353892
Validation loss: 2.548284087871196

Epoch: 6| Step: 11
Training loss: 2.1446099605603277
Validation loss: 2.5462857718657808

Epoch: 6| Step: 12
Training loss: 1.9969554616271883
Validation loss: 2.5451695142098143

Epoch: 6| Step: 13
Training loss: 2.1746108572975236
Validation loss: 2.5267804730548225

Epoch: 160| Step: 0
Training loss: 2.4113914749621266
Validation loss: 2.5059798730436555

Epoch: 6| Step: 1
Training loss: 1.9585267099989463
Validation loss: 2.507361507105549

Epoch: 6| Step: 2
Training loss: 2.2819168997234875
Validation loss: 2.4892260641397246

Epoch: 6| Step: 3
Training loss: 2.82126903427795
Validation loss: 2.540909420004481

Epoch: 6| Step: 4
Training loss: 2.6733585276887046
Validation loss: 2.5722013484431794

Epoch: 6| Step: 5
Training loss: 2.331310371660374
Validation loss: 2.574217780002229

Epoch: 6| Step: 6
Training loss: 2.743710000131088
Validation loss: 2.576605325622524

Epoch: 6| Step: 7
Training loss: 2.2565852330933764
Validation loss: 2.554867405982479

Epoch: 6| Step: 8
Training loss: 1.6746980594245873
Validation loss: 2.5686784398614115

Epoch: 6| Step: 9
Training loss: 2.2657958919924632
Validation loss: 2.5820484535304806

Epoch: 6| Step: 10
Training loss: 2.5620615514289558
Validation loss: 2.5701022126473902

Epoch: 6| Step: 11
Training loss: 1.9775593170259034
Validation loss: 2.5705342787287853

Epoch: 6| Step: 12
Training loss: 1.9729476260287524
Validation loss: 2.545807801633812

Epoch: 6| Step: 13
Training loss: 2.0098517485646785
Validation loss: 2.557593589947341

Epoch: 161| Step: 0
Training loss: 2.5397837392100073
Validation loss: 2.5677262332026687

Epoch: 6| Step: 1
Training loss: 1.8391544808435039
Validation loss: 2.5553941605127384

Epoch: 6| Step: 2
Training loss: 2.1266290366970213
Validation loss: 2.563851672064167

Epoch: 6| Step: 3
Training loss: 1.9517402928334384
Validation loss: 2.603785735459254

Epoch: 6| Step: 4
Training loss: 2.3871499528964506
Validation loss: 2.636072611149346

Epoch: 6| Step: 5
Training loss: 2.515234685910545
Validation loss: 2.6082586688668936

Epoch: 6| Step: 6
Training loss: 1.9632263807408312
Validation loss: 2.607283283093144

Epoch: 6| Step: 7
Training loss: 2.7261418671219757
Validation loss: 2.589430583702124

Epoch: 6| Step: 8
Training loss: 2.436326159974456
Validation loss: 2.5773308478915946

Epoch: 6| Step: 9
Training loss: 2.3209542051807888
Validation loss: 2.519831150474063

Epoch: 6| Step: 10
Training loss: 2.2236726980941937
Validation loss: 2.4964359977084265

Epoch: 6| Step: 11
Training loss: 2.769161570939702
Validation loss: 2.487312573298434

Epoch: 6| Step: 12
Training loss: 2.4059871183194823
Validation loss: 2.4691506254536657

Epoch: 6| Step: 13
Training loss: 1.5846398969183104
Validation loss: 2.4654963735603763

Epoch: 162| Step: 0
Training loss: 2.6381520988339604
Validation loss: 2.4581199526971536

Epoch: 6| Step: 1
Training loss: 2.129188224947108
Validation loss: 2.4529268910956126

Epoch: 6| Step: 2
Training loss: 1.5222306386261713
Validation loss: 2.4803167088383034

Epoch: 6| Step: 3
Training loss: 2.3019062394138667
Validation loss: 2.5043051669711005

Epoch: 6| Step: 4
Training loss: 1.8604689513488544
Validation loss: 2.523268461558107

Epoch: 6| Step: 5
Training loss: 2.2725153884954192
Validation loss: 2.53990814186609

Epoch: 6| Step: 6
Training loss: 2.4144748965104
Validation loss: 2.5718559605237314

Epoch: 6| Step: 7
Training loss: 2.8377483040814058
Validation loss: 2.5930999087454794

Epoch: 6| Step: 8
Training loss: 1.8261334909903228
Validation loss: 2.5886847937891364

Epoch: 6| Step: 9
Training loss: 2.8545606763507867
Validation loss: 2.589828808672604

Epoch: 6| Step: 10
Training loss: 2.30099450047651
Validation loss: 2.611114093368923

Epoch: 6| Step: 11
Training loss: 1.6472746738676496
Validation loss: 2.5857374149008905

Epoch: 6| Step: 12
Training loss: 2.222714709969609
Validation loss: 2.551439126539318

Epoch: 6| Step: 13
Training loss: 2.753095618447344
Validation loss: 2.5397748847967327

Epoch: 163| Step: 0
Training loss: 2.099812739969503
Validation loss: 2.494467305456412

Epoch: 6| Step: 1
Training loss: 2.686174997566933
Validation loss: 2.5014004630204036

Epoch: 6| Step: 2
Training loss: 2.4989200166661645
Validation loss: 2.481634071533991

Epoch: 6| Step: 3
Training loss: 1.9063886998480786
Validation loss: 2.486819178834107

Epoch: 6| Step: 4
Training loss: 2.51893379165607
Validation loss: 2.484652098169392

Epoch: 6| Step: 5
Training loss: 1.6176869823506714
Validation loss: 2.513540149103145

Epoch: 6| Step: 6
Training loss: 1.8735803315833228
Validation loss: 2.5409013923122

Epoch: 6| Step: 7
Training loss: 2.1532513319804396
Validation loss: 2.6024400509028576

Epoch: 6| Step: 8
Training loss: 2.3632875048341813
Validation loss: 2.581555546387391

Epoch: 6| Step: 9
Training loss: 2.602979302879818
Validation loss: 2.5411984378682697

Epoch: 6| Step: 10
Training loss: 2.209297893209225
Validation loss: 2.5230493679126114

Epoch: 6| Step: 11
Training loss: 2.745379120263183
Validation loss: 2.5003658775528033

Epoch: 6| Step: 12
Training loss: 2.0684153951779796
Validation loss: 2.4779120597248263

Epoch: 6| Step: 13
Training loss: 1.7273044286675217
Validation loss: 2.482862897097217

Epoch: 164| Step: 0
Training loss: 2.278887112876828
Validation loss: 2.4929563550381015

Epoch: 6| Step: 1
Training loss: 1.6512775272728737
Validation loss: 2.5105715927528576

Epoch: 6| Step: 2
Training loss: 1.9751813081018355
Validation loss: 2.506043843042722

Epoch: 6| Step: 3
Training loss: 1.7769406039605438
Validation loss: 2.504611875391239

Epoch: 6| Step: 4
Training loss: 2.623441415116988
Validation loss: 2.489240152028938

Epoch: 6| Step: 5
Training loss: 2.5100418591903395
Validation loss: 2.458684047030856

Epoch: 6| Step: 6
Training loss: 2.0408569858354357
Validation loss: 2.4475169022745833

Epoch: 6| Step: 7
Training loss: 2.122723650432613
Validation loss: 2.4610710215900804

Epoch: 6| Step: 8
Training loss: 1.6740679752672618
Validation loss: 2.4856638986705004

Epoch: 6| Step: 9
Training loss: 2.903945994008946
Validation loss: 2.509349857924054

Epoch: 6| Step: 10
Training loss: 2.7828847816842655
Validation loss: 2.56577943556879

Epoch: 6| Step: 11
Training loss: 1.8423544564598053
Validation loss: 2.631425167468505

Epoch: 6| Step: 12
Training loss: 2.59970026122468
Validation loss: 2.6992662419487705

Epoch: 6| Step: 13
Training loss: 2.2486208821708074
Validation loss: 2.7768887574534222

Epoch: 165| Step: 0
Training loss: 1.962314562935487
Validation loss: 2.8417779042637936

Epoch: 6| Step: 1
Training loss: 2.312384112779315
Validation loss: 2.867453994027881

Epoch: 6| Step: 2
Training loss: 2.650166445129371
Validation loss: 2.778233026368657

Epoch: 6| Step: 3
Training loss: 1.8789321992791317
Validation loss: 2.6241176722074777

Epoch: 6| Step: 4
Training loss: 2.0803283254380482
Validation loss: 2.4785905952718825

Epoch: 6| Step: 5
Training loss: 2.636856821471757
Validation loss: 2.466419405989825

Epoch: 6| Step: 6
Training loss: 2.788560068732157
Validation loss: 2.440392881295439

Epoch: 6| Step: 7
Training loss: 2.8550338727074047
Validation loss: 2.435234537871411

Epoch: 6| Step: 8
Training loss: 2.3595564816636903
Validation loss: 2.4443277043383578

Epoch: 6| Step: 9
Training loss: 1.5816913004016413
Validation loss: 2.464863552049521

Epoch: 6| Step: 10
Training loss: 2.3353654550137715
Validation loss: 2.4917084780702496

Epoch: 6| Step: 11
Training loss: 2.2975691181200757
Validation loss: 2.553682207057964

Epoch: 6| Step: 12
Training loss: 2.1220567178795444
Validation loss: 2.634574182192146

Epoch: 6| Step: 13
Training loss: 2.032264221517062
Validation loss: 2.71803642454002

Epoch: 166| Step: 0
Training loss: 1.9288340546147817
Validation loss: 2.699163559172394

Epoch: 6| Step: 1
Training loss: 2.822158167288185
Validation loss: 2.6664139245864877

Epoch: 6| Step: 2
Training loss: 2.3268490565531796
Validation loss: 2.6282026693330343

Epoch: 6| Step: 3
Training loss: 2.3183334593380915
Validation loss: 2.6073760944209745

Epoch: 6| Step: 4
Training loss: 2.754170117012975
Validation loss: 2.5323479520972954

Epoch: 6| Step: 5
Training loss: 1.8419956330611065
Validation loss: 2.467824452703073

Epoch: 6| Step: 6
Training loss: 1.9920098319021664
Validation loss: 2.423654732902824

Epoch: 6| Step: 7
Training loss: 2.6301081773680344
Validation loss: 2.431841800487632

Epoch: 6| Step: 8
Training loss: 2.359599829060428
Validation loss: 2.4145956953599814

Epoch: 6| Step: 9
Training loss: 2.4545872697575772
Validation loss: 2.4190600424450563

Epoch: 6| Step: 10
Training loss: 2.5455490124190665
Validation loss: 2.433250901240132

Epoch: 6| Step: 11
Training loss: 1.757455950709978
Validation loss: 2.4266045453864686

Epoch: 6| Step: 12
Training loss: 2.2568522064401706
Validation loss: 2.4785177712652735

Epoch: 6| Step: 13
Training loss: 1.18818263460423
Validation loss: 2.5198178735533356

Epoch: 167| Step: 0
Training loss: 2.1791360355750506
Validation loss: 2.5757909934793592

Epoch: 6| Step: 1
Training loss: 2.453768311722259
Validation loss: 2.6111606183969993

Epoch: 6| Step: 2
Training loss: 2.341256811943674
Validation loss: 2.6332456891402396

Epoch: 6| Step: 3
Training loss: 2.104970444859136
Validation loss: 2.6993226206948746

Epoch: 6| Step: 4
Training loss: 2.2814669571221997
Validation loss: 2.771111809202388

Epoch: 6| Step: 5
Training loss: 2.359050602116701
Validation loss: 2.8017242203962125

Epoch: 6| Step: 6
Training loss: 2.1093960231157225
Validation loss: 2.810852549067485

Epoch: 6| Step: 7
Training loss: 2.205166351202242
Validation loss: 2.7534262017748024

Epoch: 6| Step: 8
Training loss: 2.5868866898502274
Validation loss: 2.6724128136294314

Epoch: 6| Step: 9
Training loss: 2.595370050994486
Validation loss: 2.5927748247353044

Epoch: 6| Step: 10
Training loss: 1.8130992030478568
Validation loss: 2.512614380929651

Epoch: 6| Step: 11
Training loss: 2.6023730599027717
Validation loss: 2.4983830565580227

Epoch: 6| Step: 12
Training loss: 2.230725916586168
Validation loss: 2.4736456802462476

Epoch: 6| Step: 13
Training loss: 1.6788838437849836
Validation loss: 2.4667906674987106

Epoch: 168| Step: 0
Training loss: 2.0324323294284743
Validation loss: 2.461304415923189

Epoch: 6| Step: 1
Training loss: 2.8860422459270896
Validation loss: 2.4853602188346096

Epoch: 6| Step: 2
Training loss: 1.8692585460492481
Validation loss: 2.5150865047118405

Epoch: 6| Step: 3
Training loss: 2.3335231181573612
Validation loss: 2.577601691241846

Epoch: 6| Step: 4
Training loss: 2.423171059616175
Validation loss: 2.6505701401741217

Epoch: 6| Step: 5
Training loss: 1.9960950638679018
Validation loss: 2.6791221452538734

Epoch: 6| Step: 6
Training loss: 1.8316823143098313
Validation loss: 2.641053153103975

Epoch: 6| Step: 7
Training loss: 2.566396774204824
Validation loss: 2.5849581000954664

Epoch: 6| Step: 8
Training loss: 2.0603552561969214
Validation loss: 2.532940865843387

Epoch: 6| Step: 9
Training loss: 2.455324292644367
Validation loss: 2.523937073662486

Epoch: 6| Step: 10
Training loss: 1.806531484245585
Validation loss: 2.4721025834172905

Epoch: 6| Step: 11
Training loss: 2.4221485598715136
Validation loss: 2.4516962166226968

Epoch: 6| Step: 12
Training loss: 2.294867851757754
Validation loss: 2.4362960294684974

Epoch: 6| Step: 13
Training loss: 1.8397934698211862
Validation loss: 2.4455704374596476

Epoch: 169| Step: 0
Training loss: 2.278386029645865
Validation loss: 2.442841716143529

Epoch: 6| Step: 1
Training loss: 2.1275186758869022
Validation loss: 2.5059157888776946

Epoch: 6| Step: 2
Training loss: 1.687172752014921
Validation loss: 2.5708705648972905

Epoch: 6| Step: 3
Training loss: 2.196739737414969
Validation loss: 2.657735518495437

Epoch: 6| Step: 4
Training loss: 1.834527435987566
Validation loss: 2.7329851706744988

Epoch: 6| Step: 5
Training loss: 1.980823071327102
Validation loss: 2.7123810611388057

Epoch: 6| Step: 6
Training loss: 2.2705193632098664
Validation loss: 2.672082808124682

Epoch: 6| Step: 7
Training loss: 1.6874359966432309
Validation loss: 2.5997648765449832

Epoch: 6| Step: 8
Training loss: 2.814883260796373
Validation loss: 2.5434696792971785

Epoch: 6| Step: 9
Training loss: 2.307485763158719
Validation loss: 2.5248032032551175

Epoch: 6| Step: 10
Training loss: 2.0010642557955887
Validation loss: 2.4942258027440736

Epoch: 6| Step: 11
Training loss: 2.7311376098973037
Validation loss: 2.4733890847863487

Epoch: 6| Step: 12
Training loss: 2.256586712257099
Validation loss: 2.4673113719434956

Epoch: 6| Step: 13
Training loss: 2.2067267013673413
Validation loss: 2.4424209516633355

Epoch: 170| Step: 0
Training loss: 1.8419766060278644
Validation loss: 2.4251329254687954

Epoch: 6| Step: 1
Training loss: 2.4260497505137386
Validation loss: 2.4458356785978297

Epoch: 6| Step: 2
Training loss: 2.5606519035953945
Validation loss: 2.4450072611354883

Epoch: 6| Step: 3
Training loss: 1.4662190809185072
Validation loss: 2.4661700702788703

Epoch: 6| Step: 4
Training loss: 2.1118435578998773
Validation loss: 2.5048683151851927

Epoch: 6| Step: 5
Training loss: 1.033633281387183
Validation loss: 2.518534954383898

Epoch: 6| Step: 6
Training loss: 2.3091790349714674
Validation loss: 2.5889639930928383

Epoch: 6| Step: 7
Training loss: 2.87392919750776
Validation loss: 2.6180363749743365

Epoch: 6| Step: 8
Training loss: 2.547887308404382
Validation loss: 2.6486655671387815

Epoch: 6| Step: 9
Training loss: 1.8499853442874539
Validation loss: 2.692125973692886

Epoch: 6| Step: 10
Training loss: 2.2084552323388014
Validation loss: 2.6417394204985687

Epoch: 6| Step: 11
Training loss: 1.9558184552964328
Validation loss: 2.564855905706518

Epoch: 6| Step: 12
Training loss: 2.540295674093157
Validation loss: 2.5172784938322077

Epoch: 6| Step: 13
Training loss: 1.7161493219350765
Validation loss: 2.4800674476881013

Epoch: 171| Step: 0
Training loss: 1.5918949775655393
Validation loss: 2.4542344025390017

Epoch: 6| Step: 1
Training loss: 2.096939618043102
Validation loss: 2.418772543355653

Epoch: 6| Step: 2
Training loss: 2.662708285069349
Validation loss: 2.4312340863852673

Epoch: 6| Step: 3
Training loss: 2.0476757550756917
Validation loss: 2.428035357304183

Epoch: 6| Step: 4
Training loss: 1.8795083839775482
Validation loss: 2.4502814717405585

Epoch: 6| Step: 5
Training loss: 2.2089604141190535
Validation loss: 2.470756362418646

Epoch: 6| Step: 6
Training loss: 2.415539632179552
Validation loss: 2.4939760346916797

Epoch: 6| Step: 7
Training loss: 2.6552641890527147
Validation loss: 2.5610686245460346

Epoch: 6| Step: 8
Training loss: 1.8598952647428801
Validation loss: 2.6252466077153813

Epoch: 6| Step: 9
Training loss: 1.9672255896409874
Validation loss: 2.7076412960661154

Epoch: 6| Step: 10
Training loss: 1.7432297125242677
Validation loss: 2.7283008093995798

Epoch: 6| Step: 11
Training loss: 1.976393379545289
Validation loss: 2.721628811324955

Epoch: 6| Step: 12
Training loss: 2.3495681771767467
Validation loss: 2.6565076043178757

Epoch: 6| Step: 13
Training loss: 2.778455466149182
Validation loss: 2.5899837591355968

Epoch: 172| Step: 0
Training loss: 2.414707332276381
Validation loss: 2.530367948875592

Epoch: 6| Step: 1
Training loss: 2.327938200349923
Validation loss: 2.497620148177336

Epoch: 6| Step: 2
Training loss: 2.1371497464014313
Validation loss: 2.466515289393757

Epoch: 6| Step: 3
Training loss: 1.9257537035103587
Validation loss: 2.441250641882394

Epoch: 6| Step: 4
Training loss: 1.884124045797514
Validation loss: 2.452983585898425

Epoch: 6| Step: 5
Training loss: 2.498790639190947
Validation loss: 2.449841920986046

Epoch: 6| Step: 6
Training loss: 1.9240392268974182
Validation loss: 2.4534832131350672

Epoch: 6| Step: 7
Training loss: 2.1170377220861796
Validation loss: 2.5171873417729227

Epoch: 6| Step: 8
Training loss: 2.1543944847702106
Validation loss: 2.583323270941544

Epoch: 6| Step: 9
Training loss: 1.5082833143058298
Validation loss: 2.6401886287886938

Epoch: 6| Step: 10
Training loss: 2.1240704691272847
Validation loss: 2.6626402569989565

Epoch: 6| Step: 11
Training loss: 1.3919122717140373
Validation loss: 2.6351213608736805

Epoch: 6| Step: 12
Training loss: 2.0684407536074323
Validation loss: 2.607440355330738

Epoch: 6| Step: 13
Training loss: 3.0360959045581555
Validation loss: 2.600039608577169

Epoch: 173| Step: 0
Training loss: 2.2913770203623365
Validation loss: 2.5902944141254602

Epoch: 6| Step: 1
Training loss: 1.2799258484074654
Validation loss: 2.534102859453174

Epoch: 6| Step: 2
Training loss: 2.2017302731439905
Validation loss: 2.511422150763635

Epoch: 6| Step: 3
Training loss: 1.7310322345705156
Validation loss: 2.4783719296051943

Epoch: 6| Step: 4
Training loss: 2.949550342234306
Validation loss: 2.45195310613827

Epoch: 6| Step: 5
Training loss: 1.7270547156576261
Validation loss: 2.4558334233630323

Epoch: 6| Step: 6
Training loss: 1.7758617888017145
Validation loss: 2.470844000158143

Epoch: 6| Step: 7
Training loss: 1.8522487607980878
Validation loss: 2.477122634673479

Epoch: 6| Step: 8
Training loss: 2.460829765746978
Validation loss: 2.536734512116261

Epoch: 6| Step: 9
Training loss: 2.517092827426093
Validation loss: 2.602511624670648

Epoch: 6| Step: 10
Training loss: 1.7138706652831524
Validation loss: 2.645775866463743

Epoch: 6| Step: 11
Training loss: 1.5854798206210887
Validation loss: 2.6428968143736196

Epoch: 6| Step: 12
Training loss: 2.2343027596699816
Validation loss: 2.6534657217602007

Epoch: 6| Step: 13
Training loss: 2.465422887217806
Validation loss: 2.6160264891825302

Epoch: 174| Step: 0
Training loss: 2.0142105225710245
Validation loss: 2.5606617600672745

Epoch: 6| Step: 1
Training loss: 2.183797045475526
Validation loss: 2.5472262470144393

Epoch: 6| Step: 2
Training loss: 1.961330480826763
Validation loss: 2.562791743204481

Epoch: 6| Step: 3
Training loss: 2.0424855464951523
Validation loss: 2.561143713780752

Epoch: 6| Step: 4
Training loss: 1.5175598221979867
Validation loss: 2.5712110271249404

Epoch: 6| Step: 5
Training loss: 1.9198219684673214
Validation loss: 2.574834387830006

Epoch: 6| Step: 6
Training loss: 2.1181056435365533
Validation loss: 2.5530638123279568

Epoch: 6| Step: 7
Training loss: 2.173702870450869
Validation loss: 2.56354891210947

Epoch: 6| Step: 8
Training loss: 1.8740382589019486
Validation loss: 2.544004343328253

Epoch: 6| Step: 9
Training loss: 2.2629297470064054
Validation loss: 2.523403412206967

Epoch: 6| Step: 10
Training loss: 2.459388269488007
Validation loss: 2.501305928156093

Epoch: 6| Step: 11
Training loss: 1.6658831026022338
Validation loss: 2.4832897936344844

Epoch: 6| Step: 12
Training loss: 1.9275178642780995
Validation loss: 2.451511099583374

Epoch: 6| Step: 13
Training loss: 2.2810815200253094
Validation loss: 2.467023431353074

Epoch: 175| Step: 0
Training loss: 2.230839633336634
Validation loss: 2.4796049306814445

Epoch: 6| Step: 1
Training loss: 1.8835828795845209
Validation loss: 2.496495951672446

Epoch: 6| Step: 2
Training loss: 1.5189181073874467
Validation loss: 2.5369576482817933

Epoch: 6| Step: 3
Training loss: 2.210122972752308
Validation loss: 2.5648710584787047

Epoch: 6| Step: 4
Training loss: 1.8596148937207397
Validation loss: 2.6060563573132955

Epoch: 6| Step: 5
Training loss: 1.8153020312164514
Validation loss: 2.6202296299467984

Epoch: 6| Step: 6
Training loss: 2.6990097561207986
Validation loss: 2.655130128810235

Epoch: 6| Step: 7
Training loss: 1.9522732517783916
Validation loss: 2.654658259152443

Epoch: 6| Step: 8
Training loss: 2.226916047520121
Validation loss: 2.6958215937450993

Epoch: 6| Step: 9
Training loss: 2.099738822317729
Validation loss: 2.6601577572546278

Epoch: 6| Step: 10
Training loss: 1.286914121784412
Validation loss: 2.5777795524765503

Epoch: 6| Step: 11
Training loss: 2.1249656674472623
Validation loss: 2.5406892337072207

Epoch: 6| Step: 12
Training loss: 1.7853755357144985
Validation loss: 2.4991536974244117

Epoch: 6| Step: 13
Training loss: 1.814613622623563
Validation loss: 2.520411479910445

Epoch: 176| Step: 0
Training loss: 1.6839078180993035
Validation loss: 2.529819627749416

Epoch: 6| Step: 1
Training loss: 2.385908073438686
Validation loss: 2.5399351386422864

Epoch: 6| Step: 2
Training loss: 0.9112246549872811
Validation loss: 2.5868542141212783

Epoch: 6| Step: 3
Training loss: 2.037663824130089
Validation loss: 2.6492636747130365

Epoch: 6| Step: 4
Training loss: 1.5557522602067946
Validation loss: 2.6327738184104916

Epoch: 6| Step: 5
Training loss: 2.203223692935713
Validation loss: 2.6567740109889786

Epoch: 6| Step: 6
Training loss: 2.099068675836426
Validation loss: 2.6062926405911946

Epoch: 6| Step: 7
Training loss: 2.0039983360146563
Validation loss: 2.6064989070800855

Epoch: 6| Step: 8
Training loss: 2.308832921065849
Validation loss: 2.5852713729937187

Epoch: 6| Step: 9
Training loss: 2.653190825851041
Validation loss: 2.578358508063632

Epoch: 6| Step: 10
Training loss: 1.81728750201364
Validation loss: 2.542040332605215

Epoch: 6| Step: 11
Training loss: 1.8563129632720057
Validation loss: 2.587074690245481

Epoch: 6| Step: 12
Training loss: 1.5102884786295068
Validation loss: 2.538946564885412

Epoch: 6| Step: 13
Training loss: 2.361492495183834
Validation loss: 2.533607706072723

Epoch: 177| Step: 0
Training loss: 2.0307874886596773
Validation loss: 2.5262964064180444

Epoch: 6| Step: 1
Training loss: 1.6432939890445446
Validation loss: 2.50376880680567

Epoch: 6| Step: 2
Training loss: 1.7776750528273788
Validation loss: 2.4658813320859454

Epoch: 6| Step: 3
Training loss: 1.6759582995095512
Validation loss: 2.490250177431808

Epoch: 6| Step: 4
Training loss: 2.2769184533328026
Validation loss: 2.476310669818135

Epoch: 6| Step: 5
Training loss: 2.1448352924768486
Validation loss: 2.5131308455278014

Epoch: 6| Step: 6
Training loss: 1.8728321258621599
Validation loss: 2.53731032173356

Epoch: 6| Step: 7
Training loss: 2.277385626223048
Validation loss: 2.5687153909825495

Epoch: 6| Step: 8
Training loss: 2.1474789232278875
Validation loss: 2.6052338085172266

Epoch: 6| Step: 9
Training loss: 1.5968767796933883
Validation loss: 2.574016822243402

Epoch: 6| Step: 10
Training loss: 2.1973470037013483
Validation loss: 2.598076639600932

Epoch: 6| Step: 11
Training loss: 1.5254151639051345
Validation loss: 2.5966865855912102

Epoch: 6| Step: 12
Training loss: 1.8508164073588658
Validation loss: 2.5777205263362997

Epoch: 6| Step: 13
Training loss: 2.3079638969334724
Validation loss: 2.584533747844727

Epoch: 178| Step: 0
Training loss: 1.8118236200496112
Validation loss: 2.6149979345051975

Epoch: 6| Step: 1
Training loss: 1.7644187385091574
Validation loss: 2.6386976174545977

Epoch: 6| Step: 2
Training loss: 1.9934744474076012
Validation loss: 2.65137165269914

Epoch: 6| Step: 3
Training loss: 1.791408150526753
Validation loss: 2.6172988223878257

Epoch: 6| Step: 4
Training loss: 1.445744960110551
Validation loss: 2.6241002906838107

Epoch: 6| Step: 5
Training loss: 1.93688413614763
Validation loss: 2.616213746888819

Epoch: 6| Step: 6
Training loss: 1.8895061744938324
Validation loss: 2.6377410100491807

Epoch: 6| Step: 7
Training loss: 1.889050166718489
Validation loss: 2.60230296200915

Epoch: 6| Step: 8
Training loss: 1.880985624170201
Validation loss: 2.567527461273677

Epoch: 6| Step: 9
Training loss: 2.1808605250800186
Validation loss: 2.5447642764290834

Epoch: 6| Step: 10
Training loss: 2.15488888447436
Validation loss: 2.5059902719112888

Epoch: 6| Step: 11
Training loss: 2.054209374324938
Validation loss: 2.522429099895631

Epoch: 6| Step: 12
Training loss: 1.7609016909000481
Validation loss: 2.5073182542180406

Epoch: 6| Step: 13
Training loss: 2.524048911272153
Validation loss: 2.533701289186418

Epoch: 179| Step: 0
Training loss: 2.222052252415181
Validation loss: 2.57522197717999

Epoch: 6| Step: 1
Training loss: 1.5679765473966871
Validation loss: 2.606566996868638

Epoch: 6| Step: 2
Training loss: 1.7647990092313655
Validation loss: 2.626429887641053

Epoch: 6| Step: 3
Training loss: 1.906165136730855
Validation loss: 2.6721498589916237

Epoch: 6| Step: 4
Training loss: 2.33656287354133
Validation loss: 2.655102638711127

Epoch: 6| Step: 5
Training loss: 1.5089712483553281
Validation loss: 2.58404337611839

Epoch: 6| Step: 6
Training loss: 1.7502739555638558
Validation loss: 2.5809626192392154

Epoch: 6| Step: 7
Training loss: 1.7952407703064126
Validation loss: 2.547306179557607

Epoch: 6| Step: 8
Training loss: 2.1993941513229354
Validation loss: 2.552556262083269

Epoch: 6| Step: 9
Training loss: 2.169282422410676
Validation loss: 2.5403202326096874

Epoch: 6| Step: 10
Training loss: 1.7212735463556241
Validation loss: 2.5419026246293863

Epoch: 6| Step: 11
Training loss: 1.3875417496869522
Validation loss: 2.532547916128757

Epoch: 6| Step: 12
Training loss: 2.4223366574233594
Validation loss: 2.5392182954078

Epoch: 6| Step: 13
Training loss: 1.1102065609854388
Validation loss: 2.576395016558561

Epoch: 180| Step: 0
Training loss: 1.8902780513995245
Validation loss: 2.6053442001183953

Epoch: 6| Step: 1
Training loss: 1.8270204255580982
Validation loss: 2.5752164775190134

Epoch: 6| Step: 2
Training loss: 1.700421418520884
Validation loss: 2.596891344028208

Epoch: 6| Step: 3
Training loss: 2.3194111829899433
Validation loss: 2.580725145798858

Epoch: 6| Step: 4
Training loss: 1.7331529040451246
Validation loss: 2.591580609107292

Epoch: 6| Step: 5
Training loss: 1.716489380258877
Validation loss: 2.685175459638305

Epoch: 6| Step: 6
Training loss: 1.9487961672244098
Validation loss: 2.696819935017859

Epoch: 6| Step: 7
Training loss: 2.2500362393321813
Validation loss: 2.7150838761521308

Epoch: 6| Step: 8
Training loss: 1.8175259984188916
Validation loss: 2.681499085895466

Epoch: 6| Step: 9
Training loss: 1.8162190002400278
Validation loss: 2.5994455108323513

Epoch: 6| Step: 10
Training loss: 2.263883144732822
Validation loss: 2.5672441471613086

Epoch: 6| Step: 11
Training loss: 1.3980273279239546
Validation loss: 2.492854453397493

Epoch: 6| Step: 12
Training loss: 1.7351475962320435
Validation loss: 2.4729310759247514

Epoch: 6| Step: 13
Training loss: 1.7597429991695437
Validation loss: 2.4820002467126323

Epoch: 181| Step: 0
Training loss: 1.54721759123521
Validation loss: 2.5066623001948605

Epoch: 6| Step: 1
Training loss: 1.809808113295966
Validation loss: 2.5163622727131836

Epoch: 6| Step: 2
Training loss: 2.169250878970786
Validation loss: 2.570433575043631

Epoch: 6| Step: 3
Training loss: 2.070447809368094
Validation loss: 2.631179554879263

Epoch: 6| Step: 4
Training loss: 2.1983155043859672
Validation loss: 2.7025024846712036

Epoch: 6| Step: 5
Training loss: 1.9406819825091688
Validation loss: 2.6994314619078272

Epoch: 6| Step: 6
Training loss: 1.4009748062384433
Validation loss: 2.656326331453973

Epoch: 6| Step: 7
Training loss: 1.663176107958133
Validation loss: 2.6863088235899495

Epoch: 6| Step: 8
Training loss: 2.610475410922829
Validation loss: 2.638574203729053

Epoch: 6| Step: 9
Training loss: 1.9285732867216816
Validation loss: 2.631109369935587

Epoch: 6| Step: 10
Training loss: 1.408423672361273
Validation loss: 2.5679314918709952

Epoch: 6| Step: 11
Training loss: 1.9080097018461062
Validation loss: 2.5434848153442826

Epoch: 6| Step: 12
Training loss: 1.72978689568044
Validation loss: 2.529363762180205

Epoch: 6| Step: 13
Training loss: 1.2092769928088907
Validation loss: 2.497815432832827

Epoch: 182| Step: 0
Training loss: 1.5806106782734237
Validation loss: 2.5150919528919844

Epoch: 6| Step: 1
Training loss: 1.6966635949957023
Validation loss: 2.5120308438982164

Epoch: 6| Step: 2
Training loss: 1.8305708996302215
Validation loss: 2.531317814919064

Epoch: 6| Step: 3
Training loss: 1.3492364437177842
Validation loss: 2.551744803166964

Epoch: 6| Step: 4
Training loss: 2.657127325244049
Validation loss: 2.546646848790034

Epoch: 6| Step: 5
Training loss: 1.7911277078648935
Validation loss: 2.528121440850519

Epoch: 6| Step: 6
Training loss: 1.8175836500308917
Validation loss: 2.5489030598725306

Epoch: 6| Step: 7
Training loss: 1.190860260475919
Validation loss: 2.5568838606149

Epoch: 6| Step: 8
Training loss: 2.1108703964037723
Validation loss: 2.569961307921151

Epoch: 6| Step: 9
Training loss: 1.7283103001947178
Validation loss: 2.593541675261356

Epoch: 6| Step: 10
Training loss: 1.6709625035661257
Validation loss: 2.652926077084632

Epoch: 6| Step: 11
Training loss: 1.879348036760069
Validation loss: 2.6399831188913865

Epoch: 6| Step: 12
Training loss: 1.9719577874700982
Validation loss: 2.641466694325964

Epoch: 6| Step: 13
Training loss: 2.1211307304629083
Validation loss: 2.6545371877250425

Epoch: 183| Step: 0
Training loss: 2.1394396096318586
Validation loss: 2.6392633974015878

Epoch: 6| Step: 1
Training loss: 1.9979341089192015
Validation loss: 2.6274942266753363

Epoch: 6| Step: 2
Training loss: 1.3944638447005147
Validation loss: 2.6303998252212155

Epoch: 6| Step: 3
Training loss: 2.07588821152784
Validation loss: 2.5755556152474313

Epoch: 6| Step: 4
Training loss: 2.226531018486322
Validation loss: 2.564290641346509

Epoch: 6| Step: 5
Training loss: 1.7480586046219593
Validation loss: 2.53422635132856

Epoch: 6| Step: 6
Training loss: 1.9410167894457793
Validation loss: 2.5372616423008694

Epoch: 6| Step: 7
Training loss: 1.3728405294112025
Validation loss: 2.5294943822943674

Epoch: 6| Step: 8
Training loss: 1.8684181403525513
Validation loss: 2.582390740939176

Epoch: 6| Step: 9
Training loss: 1.7394841864498387
Validation loss: 2.5658498268761796

Epoch: 6| Step: 10
Training loss: 1.5366041038890346
Validation loss: 2.5871102578775824

Epoch: 6| Step: 11
Training loss: 1.8132817785680577
Validation loss: 2.5812896248748785

Epoch: 6| Step: 12
Training loss: 1.638216703395847
Validation loss: 2.5868544618778486

Epoch: 6| Step: 13
Training loss: 1.72575366376775
Validation loss: 2.587292996429443

Epoch: 184| Step: 0
Training loss: 1.4349385536143788
Validation loss: 2.574993579301755

Epoch: 6| Step: 1
Training loss: 1.4509234414702288
Validation loss: 2.572234782579232

Epoch: 6| Step: 2
Training loss: 2.0873621957944635
Validation loss: 2.5761622460488467

Epoch: 6| Step: 3
Training loss: 1.7465511124124147
Validation loss: 2.5884118625212253

Epoch: 6| Step: 4
Training loss: 2.349784711350652
Validation loss: 2.608512782633935

Epoch: 6| Step: 5
Training loss: 1.4968503627461796
Validation loss: 2.63770144242055

Epoch: 6| Step: 6
Training loss: 1.5913194560604644
Validation loss: 2.700418701734136

Epoch: 6| Step: 7
Training loss: 1.87077930969989
Validation loss: 2.6775736355997037

Epoch: 6| Step: 8
Training loss: 1.691775380792733
Validation loss: 2.6359925654749943

Epoch: 6| Step: 9
Training loss: 1.8518667494209955
Validation loss: 2.628593909590174

Epoch: 6| Step: 10
Training loss: 1.6367846637281427
Validation loss: 2.607165310705217

Epoch: 6| Step: 11
Training loss: 1.7072414382270769
Validation loss: 2.5853236830931703

Epoch: 6| Step: 12
Training loss: 2.0794488805792124
Validation loss: 2.551128902273698

Epoch: 6| Step: 13
Training loss: 1.838630940662621
Validation loss: 2.526463372149649

Epoch: 185| Step: 0
Training loss: 1.3404841102247407
Validation loss: 2.520589873855134

Epoch: 6| Step: 1
Training loss: 1.5192433062354627
Validation loss: 2.501079514939622

Epoch: 6| Step: 2
Training loss: 1.9324274418127823
Validation loss: 2.517099062630596

Epoch: 6| Step: 3
Training loss: 1.6754777540131995
Validation loss: 2.5338856597185364

Epoch: 6| Step: 4
Training loss: 1.6535436723846015
Validation loss: 2.610226312562377

Epoch: 6| Step: 5
Training loss: 1.3902453643716055
Validation loss: 2.655558446513961

Epoch: 6| Step: 6
Training loss: 1.871278120605535
Validation loss: 2.710771108794644

Epoch: 6| Step: 7
Training loss: 1.9802763655479387
Validation loss: 2.7099102878391803

Epoch: 6| Step: 8
Training loss: 2.018714724961798
Validation loss: 2.747345582990143

Epoch: 6| Step: 9
Training loss: 2.111438109632415
Validation loss: 2.700271905556222

Epoch: 6| Step: 10
Training loss: 1.9637017694932977
Validation loss: 2.679679712500489

Epoch: 6| Step: 11
Training loss: 1.88355636148199
Validation loss: 2.5893496515929293

Epoch: 6| Step: 12
Training loss: 1.393695612988106
Validation loss: 2.5337335917264734

Epoch: 6| Step: 13
Training loss: 2.135683914457077
Validation loss: 2.4708108935786033

Epoch: 186| Step: 0
Training loss: 2.3283640079575716
Validation loss: 2.453219071593577

Epoch: 6| Step: 1
Training loss: 1.3514293538920545
Validation loss: 2.470834182777571

Epoch: 6| Step: 2
Training loss: 1.4038201850744274
Validation loss: 2.5113881224185706

Epoch: 6| Step: 3
Training loss: 1.956839972797516
Validation loss: 2.560826730950658

Epoch: 6| Step: 4
Training loss: 1.6460947320081536
Validation loss: 2.6155709149814346

Epoch: 6| Step: 5
Training loss: 2.0744258683815735
Validation loss: 2.6696998047806453

Epoch: 6| Step: 6
Training loss: 1.8864864735546834
Validation loss: 2.70521824279373

Epoch: 6| Step: 7
Training loss: 1.6314605518544052
Validation loss: 2.6706177380584486

Epoch: 6| Step: 8
Training loss: 1.7101283141285923
Validation loss: 2.673361417029951

Epoch: 6| Step: 9
Training loss: 1.769059343549146
Validation loss: 2.6430969541443763

Epoch: 6| Step: 10
Training loss: 2.102572967496891
Validation loss: 2.6143548105114207

Epoch: 6| Step: 11
Training loss: 1.6092847780289399
Validation loss: 2.555711324115282

Epoch: 6| Step: 12
Training loss: 1.6834219647985356
Validation loss: 2.5617134989180412

Epoch: 6| Step: 13
Training loss: 1.6739600184142727
Validation loss: 2.599664225837534

Epoch: 187| Step: 0
Training loss: 1.5849302503960878
Validation loss: 2.59670759173091

Epoch: 6| Step: 1
Training loss: 1.3524370836724193
Validation loss: 2.600352902241169

Epoch: 6| Step: 2
Training loss: 2.102573194284327
Validation loss: 2.6065188151843226

Epoch: 6| Step: 3
Training loss: 1.206433589582534
Validation loss: 2.6474425999939926

Epoch: 6| Step: 4
Training loss: 1.6043454438040485
Validation loss: 2.714226108967201

Epoch: 6| Step: 5
Training loss: 1.8441367309503343
Validation loss: 2.7248330574193744

Epoch: 6| Step: 6
Training loss: 1.363991888257067
Validation loss: 2.6852329314222354

Epoch: 6| Step: 7
Training loss: 2.5655742905097316
Validation loss: 2.5943696731896613

Epoch: 6| Step: 8
Training loss: 1.821404387476462
Validation loss: 2.5492171200702325

Epoch: 6| Step: 9
Training loss: 1.7427652538585805
Validation loss: 2.5512697447804036

Epoch: 6| Step: 10
Training loss: 1.657337191771857
Validation loss: 2.526736604941409

Epoch: 6| Step: 11
Training loss: 1.4413683713158945
Validation loss: 2.521663211533069

Epoch: 6| Step: 12
Training loss: 1.7365257056365937
Validation loss: 2.553108758368028

Epoch: 6| Step: 13
Training loss: 2.019453921580767
Validation loss: 2.573128104235389

Epoch: 188| Step: 0
Training loss: 1.608253236202552
Validation loss: 2.5985169671036776

Epoch: 6| Step: 1
Training loss: 1.595838562016433
Validation loss: 2.5865769442853606

Epoch: 6| Step: 2
Training loss: 1.703856634775798
Validation loss: 2.5905459842461953

Epoch: 6| Step: 3
Training loss: 1.7428913832814212
Validation loss: 2.5950888094110187

Epoch: 6| Step: 4
Training loss: 1.6599557553565127
Validation loss: 2.600754759010012

Epoch: 6| Step: 5
Training loss: 1.7960035118077189
Validation loss: 2.5859243840404607

Epoch: 6| Step: 6
Training loss: 1.796192935363686
Validation loss: 2.6025786495355137

Epoch: 6| Step: 7
Training loss: 2.027081011319636
Validation loss: 2.6054070440458044

Epoch: 6| Step: 8
Training loss: 1.7632391008943193
Validation loss: 2.6247019542402863

Epoch: 6| Step: 9
Training loss: 1.731271802854447
Validation loss: 2.6360203978298147

Epoch: 6| Step: 10
Training loss: 2.0881848747942744
Validation loss: 2.5577419175274065

Epoch: 6| Step: 11
Training loss: 1.1501957415804887
Validation loss: 2.557717407013639

Epoch: 6| Step: 12
Training loss: 1.4548422398199339
Validation loss: 2.570580455642944

Epoch: 6| Step: 13
Training loss: 1.704759286125995
Validation loss: 2.5960907024175204

Epoch: 189| Step: 0
Training loss: 1.7782461705010393
Validation loss: 2.6069662299058405

Epoch: 6| Step: 1
Training loss: 1.3857694573437749
Validation loss: 2.6422089419934505

Epoch: 6| Step: 2
Training loss: 1.8347019664497501
Validation loss: 2.678465683134498

Epoch: 6| Step: 3
Training loss: 1.724720796850146
Validation loss: 2.640168335643362

Epoch: 6| Step: 4
Training loss: 1.7344052423813199
Validation loss: 2.656858346803012

Epoch: 6| Step: 5
Training loss: 1.5842876402717785
Validation loss: 2.606969352138131

Epoch: 6| Step: 6
Training loss: 1.6577597161176425
Validation loss: 2.553141666348467

Epoch: 6| Step: 7
Training loss: 1.8404618377128255
Validation loss: 2.496659091295205

Epoch: 6| Step: 8
Training loss: 1.3268257068708267
Validation loss: 2.4776815293863854

Epoch: 6| Step: 9
Training loss: 1.1400032439102064
Validation loss: 2.4749178016249007

Epoch: 6| Step: 10
Training loss: 1.5984764325573537
Validation loss: 2.507495641217826

Epoch: 6| Step: 11
Training loss: 2.014465590004398
Validation loss: 2.568098861275454

Epoch: 6| Step: 12
Training loss: 2.4068962319308573
Validation loss: 2.6402839964234373

Epoch: 6| Step: 13
Training loss: 1.3348418980107482
Validation loss: 2.720339943723805

Epoch: 190| Step: 0
Training loss: 1.8743068685484223
Validation loss: 2.791443941846109

Epoch: 6| Step: 1
Training loss: 1.7935661035569248
Validation loss: 2.866473399351225

Epoch: 6| Step: 2
Training loss: 1.4737935417803047
Validation loss: 2.865156212106357

Epoch: 6| Step: 3
Training loss: 1.755545141427958
Validation loss: 2.8794126491704226

Epoch: 6| Step: 4
Training loss: 2.1945278082141932
Validation loss: 2.7906963356036636

Epoch: 6| Step: 5
Training loss: 1.7044975979184642
Validation loss: 2.617696532285973

Epoch: 6| Step: 6
Training loss: 1.1863018818032354
Validation loss: 2.511813700287289

Epoch: 6| Step: 7
Training loss: 1.9660532207445267
Validation loss: 2.4686843138502916

Epoch: 6| Step: 8
Training loss: 1.7423158606896296
Validation loss: 2.4536450792730706

Epoch: 6| Step: 9
Training loss: 2.0157028301500937
Validation loss: 2.4393109771536126

Epoch: 6| Step: 10
Training loss: 1.994841479550176
Validation loss: 2.4616475409337144

Epoch: 6| Step: 11
Training loss: 1.8198466871474859
Validation loss: 2.453134135818478

Epoch: 6| Step: 12
Training loss: 1.8790214646003145
Validation loss: 2.4620580603648765

Epoch: 6| Step: 13
Training loss: 1.444003197732486
Validation loss: 2.5010014076800844

Epoch: 191| Step: 0
Training loss: 1.2520655255736
Validation loss: 2.5586929483666654

Epoch: 6| Step: 1
Training loss: 1.7074610258600142
Validation loss: 2.6499737747358987

Epoch: 6| Step: 2
Training loss: 1.8439105982260877
Validation loss: 2.769203740925975

Epoch: 6| Step: 3
Training loss: 1.878296941671505
Validation loss: 2.799511393623651

Epoch: 6| Step: 4
Training loss: 1.6473800377013628
Validation loss: 2.701109981636714

Epoch: 6| Step: 5
Training loss: 1.6443448719960458
Validation loss: 2.6275859036033453

Epoch: 6| Step: 6
Training loss: 1.5881363231701144
Validation loss: 2.5419280531203965

Epoch: 6| Step: 7
Training loss: 2.002032677535246
Validation loss: 2.4961672074056676

Epoch: 6| Step: 8
Training loss: 1.4939709934855565
Validation loss: 2.4524753061096907

Epoch: 6| Step: 9
Training loss: 1.7276369091937533
Validation loss: 2.4371081632315703

Epoch: 6| Step: 10
Training loss: 1.8461119183951114
Validation loss: 2.429562444666647

Epoch: 6| Step: 11
Training loss: 1.9254471371035227
Validation loss: 2.4447657098865547

Epoch: 6| Step: 12
Training loss: 1.8908649639085973
Validation loss: 2.466959970901927

Epoch: 6| Step: 13
Training loss: 1.239635797667264
Validation loss: 2.5535283317132365

Epoch: 192| Step: 0
Training loss: 1.9321614210406977
Validation loss: 2.610795171325154

Epoch: 6| Step: 1
Training loss: 1.5871216811299915
Validation loss: 2.663831756215347

Epoch: 6| Step: 2
Training loss: 1.4810281064227513
Validation loss: 2.6786643769700405

Epoch: 6| Step: 3
Training loss: 1.9816067828644843
Validation loss: 2.682209288330385

Epoch: 6| Step: 4
Training loss: 1.3275115447610988
Validation loss: 2.6957778098621867

Epoch: 6| Step: 5
Training loss: 1.350290526811838
Validation loss: 2.7172745003584513

Epoch: 6| Step: 6
Training loss: 1.3081096607808902
Validation loss: 2.6816133923286007

Epoch: 6| Step: 7
Training loss: 1.4652023486850418
Validation loss: 2.6689876870627622

Epoch: 6| Step: 8
Training loss: 1.7345407080317297
Validation loss: 2.629825719106388

Epoch: 6| Step: 9
Training loss: 1.8121561184590187
Validation loss: 2.5144381461227296

Epoch: 6| Step: 10
Training loss: 1.807399149253673
Validation loss: 2.490919992002711

Epoch: 6| Step: 11
Training loss: 1.6669954770306588
Validation loss: 2.5082357460470988

Epoch: 6| Step: 12
Training loss: 1.77332194619837
Validation loss: 2.4906281478939554

Epoch: 6| Step: 13
Training loss: 2.2160296889702225
Validation loss: 2.521189571326343

Epoch: 193| Step: 0
Training loss: 1.9525363492818062
Validation loss: 2.5404036490582977

Epoch: 6| Step: 1
Training loss: 1.4697437576859567
Validation loss: 2.5528180194764576

Epoch: 6| Step: 2
Training loss: 1.7790860198754677
Validation loss: 2.6145244696841137

Epoch: 6| Step: 3
Training loss: 2.035925077457544
Validation loss: 2.660373104709923

Epoch: 6| Step: 4
Training loss: 1.820412367017259
Validation loss: 2.6686425211442257

Epoch: 6| Step: 5
Training loss: 1.9734522658133198
Validation loss: 2.634156589579551

Epoch: 6| Step: 6
Training loss: 1.6207959004895407
Validation loss: 2.590061661453509

Epoch: 6| Step: 7
Training loss: 1.2001635281084242
Validation loss: 2.591513107884295

Epoch: 6| Step: 8
Training loss: 1.8978050654149643
Validation loss: 2.5963497700989664

Epoch: 6| Step: 9
Training loss: 1.3914040944052206
Validation loss: 2.5721304781194236

Epoch: 6| Step: 10
Training loss: 0.8847843530285421
Validation loss: 2.5888867132893747

Epoch: 6| Step: 11
Training loss: 1.1662839136783945
Validation loss: 2.5870444123348864

Epoch: 6| Step: 12
Training loss: 1.7355379896432326
Validation loss: 2.585232246822517

Epoch: 6| Step: 13
Training loss: 0.5862426217678349
Validation loss: 2.620719227963532

Epoch: 194| Step: 0
Training loss: 1.9755045958445971
Validation loss: 2.6537990643971625

Epoch: 6| Step: 1
Training loss: 1.4736104044591465
Validation loss: 2.654003639705165

Epoch: 6| Step: 2
Training loss: 1.4357008248127183
Validation loss: 2.621528384666714

Epoch: 6| Step: 3
Training loss: 1.7212756933041318
Validation loss: 2.6493181032755713

Epoch: 6| Step: 4
Training loss: 1.8768562029882727
Validation loss: 2.639725635540531

Epoch: 6| Step: 5
Training loss: 1.834610219818065
Validation loss: 2.610292277028047

Epoch: 6| Step: 6
Training loss: 1.49022669558965
Validation loss: 2.6305989082156622

Epoch: 6| Step: 7
Training loss: 1.4382133372537573
Validation loss: 2.596303531632154

Epoch: 6| Step: 8
Training loss: 1.6359326789733912
Validation loss: 2.6252294987968665

Epoch: 6| Step: 9
Training loss: 1.9524968472307567
Validation loss: 2.6301690318703463

Epoch: 6| Step: 10
Training loss: 0.7500995728833654
Validation loss: 2.6094998202166027

Epoch: 6| Step: 11
Training loss: 1.5685004411963686
Validation loss: 2.621974419763143

Epoch: 6| Step: 12
Training loss: 1.0236731105151549
Validation loss: 2.626934080264151

Epoch: 6| Step: 13
Training loss: 0.7553109241827427
Validation loss: 2.6287617662219818

Epoch: 195| Step: 0
Training loss: 0.9026359976592584
Validation loss: 2.665633325047207

Epoch: 6| Step: 1
Training loss: 1.52724579401853
Validation loss: 2.6994397916830555

Epoch: 6| Step: 2
Training loss: 1.1024648879638368
Validation loss: 2.6877349422675914

Epoch: 6| Step: 3
Training loss: 1.6247239978856163
Validation loss: 2.71202535334928

Epoch: 6| Step: 4
Training loss: 1.7121915358460844
Validation loss: 2.6583487397177357

Epoch: 6| Step: 5
Training loss: 1.5646135912262342
Validation loss: 2.6044982744966285

Epoch: 6| Step: 6
Training loss: 1.9550578814667492
Validation loss: 2.5906442510549956

Epoch: 6| Step: 7
Training loss: 1.368318798128926
Validation loss: 2.5748044772555563

Epoch: 6| Step: 8
Training loss: 1.8094737340576084
Validation loss: 2.5216506681146282

Epoch: 6| Step: 9
Training loss: 1.5192684152204876
Validation loss: 2.536249529211524

Epoch: 6| Step: 10
Training loss: 1.5807235776330053
Validation loss: 2.5488426166908713

Epoch: 6| Step: 11
Training loss: 1.8057668521522
Validation loss: 2.566650349048811

Epoch: 6| Step: 12
Training loss: 1.677469892160579
Validation loss: 2.6176807245527507

Epoch: 6| Step: 13
Training loss: 1.4511593886155276
Validation loss: 2.612170277402712

Epoch: 196| Step: 0
Training loss: 1.7606966221182314
Validation loss: 2.665766083889958

Epoch: 6| Step: 1
Training loss: 1.0632641232447462
Validation loss: 2.68413674851566

Epoch: 6| Step: 2
Training loss: 1.1090634405498112
Validation loss: 2.723979802028326

Epoch: 6| Step: 3
Training loss: 1.166699181966445
Validation loss: 2.7356625630294706

Epoch: 6| Step: 4
Training loss: 1.3727035418783977
Validation loss: 2.7308095330024162

Epoch: 6| Step: 5
Training loss: 1.781097606363948
Validation loss: 2.7126765680287424

Epoch: 6| Step: 6
Training loss: 1.940539160655952
Validation loss: 2.657890503307514

Epoch: 6| Step: 7
Training loss: 1.2003080409770872
Validation loss: 2.6401505786491115

Epoch: 6| Step: 8
Training loss: 1.9558494182110004
Validation loss: 2.5576876240277833

Epoch: 6| Step: 9
Training loss: 1.7522922217471342
Validation loss: 2.5552606034200664

Epoch: 6| Step: 10
Training loss: 1.5168636019498147
Validation loss: 2.541729090297414

Epoch: 6| Step: 11
Training loss: 1.22917436608096
Validation loss: 2.5712680760256514

Epoch: 6| Step: 12
Training loss: 1.6141495480841674
Validation loss: 2.5751963319051994

Epoch: 6| Step: 13
Training loss: 1.912606070575217
Validation loss: 2.598009263739236

Epoch: 197| Step: 0
Training loss: 1.7619500864733686
Validation loss: 2.6083617812086874

Epoch: 6| Step: 1
Training loss: 1.35590076432816
Validation loss: 2.618339000945979

Epoch: 6| Step: 2
Training loss: 1.6954518625664454
Validation loss: 2.6876420815550044

Epoch: 6| Step: 3
Training loss: 1.2947477796159508
Validation loss: 2.7106185696639105

Epoch: 6| Step: 4
Training loss: 1.397752903282495
Validation loss: 2.688438661786878

Epoch: 6| Step: 5
Training loss: 1.734684203482691
Validation loss: 2.618053459416958

Epoch: 6| Step: 6
Training loss: 1.7534108301207023
Validation loss: 2.598764649611564

Epoch: 6| Step: 7
Training loss: 1.2129597175809257
Validation loss: 2.5690034964856157

Epoch: 6| Step: 8
Training loss: 1.822516224792849
Validation loss: 2.5816675621656153

Epoch: 6| Step: 9
Training loss: 1.4567638489336763
Validation loss: 2.61596639054355

Epoch: 6| Step: 10
Training loss: 1.6417187632445185
Validation loss: 2.660826077898707

Epoch: 6| Step: 11
Training loss: 1.552926758178205
Validation loss: 2.689691507143504

Epoch: 6| Step: 12
Training loss: 1.2622580778030073
Validation loss: 2.698632976219129

Epoch: 6| Step: 13
Training loss: 1.3519020315599022
Validation loss: 2.705086095263699

Epoch: 198| Step: 0
Training loss: 1.510937392699308
Validation loss: 2.7205506141057283

Epoch: 6| Step: 1
Training loss: 1.3439292788120825
Validation loss: 2.7297500598017304

Epoch: 6| Step: 2
Training loss: 1.517051733131911
Validation loss: 2.6962345695085443

Epoch: 6| Step: 3
Training loss: 1.9796474341332748
Validation loss: 2.6887089194010008

Epoch: 6| Step: 4
Training loss: 1.7814774618979512
Validation loss: 2.6147732654458564

Epoch: 6| Step: 5
Training loss: 1.5304254141139624
Validation loss: 2.5749659071968267

Epoch: 6| Step: 6
Training loss: 1.265983907413501
Validation loss: 2.55422281504221

Epoch: 6| Step: 7
Training loss: 1.6749656844538339
Validation loss: 2.5539281616670277

Epoch: 6| Step: 8
Training loss: 1.2198073373380298
Validation loss: 2.572453778082249

Epoch: 6| Step: 9
Training loss: 1.1167285750199614
Validation loss: 2.5866861444704483

Epoch: 6| Step: 10
Training loss: 1.5451195514435683
Validation loss: 2.5865707952916326

Epoch: 6| Step: 11
Training loss: 1.139571866402593
Validation loss: 2.607510196151181

Epoch: 6| Step: 12
Training loss: 1.9505743843608119
Validation loss: 2.647833908772036

Epoch: 6| Step: 13
Training loss: 1.2594754616776442
Validation loss: 2.7197844437752403

Epoch: 199| Step: 0
Training loss: 1.502146456693207
Validation loss: 2.7354876470372855

Epoch: 6| Step: 1
Training loss: 1.124788635319535
Validation loss: 2.7646159226881237

Epoch: 6| Step: 2
Training loss: 1.1027423140820751
Validation loss: 2.7359805576638974

Epoch: 6| Step: 3
Training loss: 1.4518980363191596
Validation loss: 2.7227106002279395

Epoch: 6| Step: 4
Training loss: 1.550126252108581
Validation loss: 2.6798501234583076

Epoch: 6| Step: 5
Training loss: 1.4235880666382152
Validation loss: 2.615828977558991

Epoch: 6| Step: 6
Training loss: 1.9217997590510176
Validation loss: 2.5898103412549665

Epoch: 6| Step: 7
Training loss: 1.805027785153398
Validation loss: 2.5725296850098287

Epoch: 6| Step: 8
Training loss: 1.5562240445220787
Validation loss: 2.57036446124448

Epoch: 6| Step: 9
Training loss: 1.6330040632245262
Validation loss: 2.5558768477343707

Epoch: 6| Step: 10
Training loss: 1.273969667789238
Validation loss: 2.6082755873587855

Epoch: 6| Step: 11
Training loss: 1.6805271622682383
Validation loss: 2.6249339519733073

Epoch: 6| Step: 12
Training loss: 1.5857039406462297
Validation loss: 2.686321363532874

Epoch: 6| Step: 13
Training loss: 0.9649963875935197
Validation loss: 2.6950208680049674

Epoch: 200| Step: 0
Training loss: 0.8254659897229013
Validation loss: 2.7110856401598675

Epoch: 6| Step: 1
Training loss: 1.4872707029932155
Validation loss: 2.702854481299177

Epoch: 6| Step: 2
Training loss: 1.2002457684929184
Validation loss: 2.6866758017095997

Epoch: 6| Step: 3
Training loss: 1.2667825844494165
Validation loss: 2.6621589888648596

Epoch: 6| Step: 4
Training loss: 1.8337922894490792
Validation loss: 2.674679401082184

Epoch: 6| Step: 5
Training loss: 1.1225254606490214
Validation loss: 2.6775814062458325

Epoch: 6| Step: 6
Training loss: 1.509487822365706
Validation loss: 2.677182192673083

Epoch: 6| Step: 7
Training loss: 1.5573275592797071
Validation loss: 2.6784307218082324

Epoch: 6| Step: 8
Training loss: 1.570915599797071
Validation loss: 2.668820918132921

Epoch: 6| Step: 9
Training loss: 1.5983735878137824
Validation loss: 2.670979651380767

Epoch: 6| Step: 10
Training loss: 1.8639429864677644
Validation loss: 2.6419254718755933

Epoch: 6| Step: 11
Training loss: 1.9074722499003791
Validation loss: 2.6314152867040956

Epoch: 6| Step: 12
Training loss: 0.9902573080623841
Validation loss: 2.6128693354443353

Epoch: 6| Step: 13
Training loss: 1.2154025053172037
Validation loss: 2.6088041369191917

Epoch: 201| Step: 0
Training loss: 1.406516028778382
Validation loss: 2.598436950419519

Epoch: 6| Step: 1
Training loss: 1.3208723517750827
Validation loss: 2.6162597814354873

Epoch: 6| Step: 2
Training loss: 1.4031359206966223
Validation loss: 2.6354870621229156

Epoch: 6| Step: 3
Training loss: 1.9145840926751703
Validation loss: 2.656914505187189

Epoch: 6| Step: 4
Training loss: 1.7407529937968218
Validation loss: 2.6564987143387877

Epoch: 6| Step: 5
Training loss: 1.0838048287924156
Validation loss: 2.6571118707663017

Epoch: 6| Step: 6
Training loss: 1.666666563351946
Validation loss: 2.6627125329148695

Epoch: 6| Step: 7
Training loss: 1.1060570543207613
Validation loss: 2.675031615453686

Epoch: 6| Step: 8
Training loss: 1.1636787140316507
Validation loss: 2.708372720348369

Epoch: 6| Step: 9
Training loss: 1.3453933071275654
Validation loss: 2.6724049233906

Epoch: 6| Step: 10
Training loss: 1.8972045285411547
Validation loss: 2.696429003808237

Epoch: 6| Step: 11
Training loss: 1.0230560756763392
Validation loss: 2.695264719616402

Epoch: 6| Step: 12
Training loss: 1.399245257954539
Validation loss: 2.729419264148631

Epoch: 6| Step: 13
Training loss: 1.2742183608119424
Validation loss: 2.7313075407338476

Epoch: 202| Step: 0
Training loss: 1.0868214364697646
Validation loss: 2.757400135592685

Epoch: 6| Step: 1
Training loss: 1.8083517683059291
Validation loss: 2.736505838044259

Epoch: 6| Step: 2
Training loss: 1.8907376090317967
Validation loss: 2.7236575448777214

Epoch: 6| Step: 3
Training loss: 1.3215735017251353
Validation loss: 2.65105849811776

Epoch: 6| Step: 4
Training loss: 1.1835807572964163
Validation loss: 2.6126498649653365

Epoch: 6| Step: 5
Training loss: 1.156022023588481
Validation loss: 2.5776774157435285

Epoch: 6| Step: 6
Training loss: 1.0154266163668935
Validation loss: 2.5772101237335825

Epoch: 6| Step: 7
Training loss: 1.6194297983253554
Validation loss: 2.6068820009930116

Epoch: 6| Step: 8
Training loss: 1.4748584259108066
Validation loss: 2.6187437178761344

Epoch: 6| Step: 9
Training loss: 1.4512497481839588
Validation loss: 2.6452190142041188

Epoch: 6| Step: 10
Training loss: 1.5654243569095923
Validation loss: 2.668967775698224

Epoch: 6| Step: 11
Training loss: 1.7609268743267206
Validation loss: 2.6790229401193617

Epoch: 6| Step: 12
Training loss: 1.0666065517016161
Validation loss: 2.7241393503465847

Epoch: 6| Step: 13
Training loss: 1.6208623881869828
Validation loss: 2.715451234675719

Epoch: 203| Step: 0
Training loss: 1.5242410741253436
Validation loss: 2.718598976037746

Epoch: 6| Step: 1
Training loss: 1.1963329073597924
Validation loss: 2.7215050427596212

Epoch: 6| Step: 2
Training loss: 1.5958632875557854
Validation loss: 2.719540993081328

Epoch: 6| Step: 3
Training loss: 0.949643295228345
Validation loss: 2.700973855475658

Epoch: 6| Step: 4
Training loss: 0.9790253368134456
Validation loss: 2.657681386754598

Epoch: 6| Step: 5
Training loss: 1.5788097595599395
Validation loss: 2.6242378229993846

Epoch: 6| Step: 6
Training loss: 1.5250200708037813
Validation loss: 2.633237205465292

Epoch: 6| Step: 7
Training loss: 1.724543223510994
Validation loss: 2.63992816671949

Epoch: 6| Step: 8
Training loss: 1.1698262935052872
Validation loss: 2.6157589148761047

Epoch: 6| Step: 9
Training loss: 1.634001522535084
Validation loss: 2.6226553223935523

Epoch: 6| Step: 10
Training loss: 1.37143079304799
Validation loss: 2.6206624690531717

Epoch: 6| Step: 11
Training loss: 1.122618220248604
Validation loss: 2.6876955411935017

Epoch: 6| Step: 12
Training loss: 1.6057235626937905
Validation loss: 2.678032668232176

Epoch: 6| Step: 13
Training loss: 1.8236509170442483
Validation loss: 2.683816398572857

Epoch: 204| Step: 0
Training loss: 1.0563051040089848
Validation loss: 2.70634108755313

Epoch: 6| Step: 1
Training loss: 1.547991109147279
Validation loss: 2.720938079641377

Epoch: 6| Step: 2
Training loss: 1.1948604851048725
Validation loss: 2.7032065942634036

Epoch: 6| Step: 3
Training loss: 1.8484664334300416
Validation loss: 2.720431839088253

Epoch: 6| Step: 4
Training loss: 1.1238951025645603
Validation loss: 2.7044417075145293

Epoch: 6| Step: 5
Training loss: 0.9347268733764932
Validation loss: 2.716684088571524

Epoch: 6| Step: 6
Training loss: 1.5395573628893173
Validation loss: 2.682368462563625

Epoch: 6| Step: 7
Training loss: 1.7989155999700013
Validation loss: 2.7236533356077994

Epoch: 6| Step: 8
Training loss: 1.2984594295040774
Validation loss: 2.7072835280654366

Epoch: 6| Step: 9
Training loss: 1.30349100951038
Validation loss: 2.685232120866398

Epoch: 6| Step: 10
Training loss: 1.1893863753207299
Validation loss: 2.655026038405838

Epoch: 6| Step: 11
Training loss: 1.50187121342798
Validation loss: 2.6325374252777975

Epoch: 6| Step: 12
Training loss: 1.7836600613391846
Validation loss: 2.6538723954334764

Epoch: 6| Step: 13
Training loss: 0.958627420718571
Validation loss: 2.6391603432416093

Epoch: 205| Step: 0
Training loss: 1.1162461803409374
Validation loss: 2.60986779437404

Epoch: 6| Step: 1
Training loss: 1.3597032874069093
Validation loss: 2.601861791354487

Epoch: 6| Step: 2
Training loss: 1.4013132543519702
Validation loss: 2.5866543708978837

Epoch: 6| Step: 3
Training loss: 1.2264718186211814
Validation loss: 2.6484731950749283

Epoch: 6| Step: 4
Training loss: 1.218324733778579
Validation loss: 2.624752509603785

Epoch: 6| Step: 5
Training loss: 1.6291782508821995
Validation loss: 2.6725476376631434

Epoch: 6| Step: 6
Training loss: 1.58954889435998
Validation loss: 2.6925328932761263

Epoch: 6| Step: 7
Training loss: 1.78225492271956
Validation loss: 2.694679707914386

Epoch: 6| Step: 8
Training loss: 1.2767439901144375
Validation loss: 2.656735859687006

Epoch: 6| Step: 9
Training loss: 1.0824276855489003
Validation loss: 2.7242978532492494

Epoch: 6| Step: 10
Training loss: 1.827298099621173
Validation loss: 2.7133287299771895

Epoch: 6| Step: 11
Training loss: 1.1218791695944996
Validation loss: 2.7285927769769365

Epoch: 6| Step: 12
Training loss: 0.9887097903441636
Validation loss: 2.7371046850979264

Epoch: 6| Step: 13
Training loss: 1.7449487947531368
Validation loss: 2.709251008539848

Epoch: 206| Step: 0
Training loss: 1.6559825897269083
Validation loss: 2.648497333214337

Epoch: 6| Step: 1
Training loss: 2.115750997332825
Validation loss: 2.64995228242082

Epoch: 6| Step: 2
Training loss: 1.5173092951342617
Validation loss: 2.5891675473255757

Epoch: 6| Step: 3
Training loss: 1.4458537969689302
Validation loss: 2.5704340836957926

Epoch: 6| Step: 4
Training loss: 1.0678084659918863
Validation loss: 2.569308638002338

Epoch: 6| Step: 5
Training loss: 0.9296179993881234
Validation loss: 2.6107055006223883

Epoch: 6| Step: 6
Training loss: 1.2503451824421716
Validation loss: 2.621155069060407

Epoch: 6| Step: 7
Training loss: 1.296685768017803
Validation loss: 2.658846553732816

Epoch: 6| Step: 8
Training loss: 1.3690761491120813
Validation loss: 2.681220301322055

Epoch: 6| Step: 9
Training loss: 1.2152871061905588
Validation loss: 2.708541234242843

Epoch: 6| Step: 10
Training loss: 1.6744971702007303
Validation loss: 2.745753590431432

Epoch: 6| Step: 11
Training loss: 0.7917452237822588
Validation loss: 2.7546068759348166

Epoch: 6| Step: 12
Training loss: 1.1629024075752756
Validation loss: 2.7161127400951526

Epoch: 6| Step: 13
Training loss: 1.3531114379344125
Validation loss: 2.690266185543547

Epoch: 207| Step: 0
Training loss: 0.9475591460415755
Validation loss: 2.6632650782536955

Epoch: 6| Step: 1
Training loss: 0.9377340978170575
Validation loss: 2.6357381568573346

Epoch: 6| Step: 2
Training loss: 1.4819623916065172
Validation loss: 2.6209209370437145

Epoch: 6| Step: 3
Training loss: 1.4839867335032424
Validation loss: 2.619047933003684

Epoch: 6| Step: 4
Training loss: 1.3702980623604715
Validation loss: 2.6217874126536547

Epoch: 6| Step: 5
Training loss: 1.5981147686418584
Validation loss: 2.646732219940058

Epoch: 6| Step: 6
Training loss: 1.7759651622534272
Validation loss: 2.694501183856861

Epoch: 6| Step: 7
Training loss: 1.6491189425005954
Validation loss: 2.7207811552569567

Epoch: 6| Step: 8
Training loss: 0.9670237265420701
Validation loss: 2.713422240308644

Epoch: 6| Step: 9
Training loss: 1.312422523028322
Validation loss: 2.7063264417439608

Epoch: 6| Step: 10
Training loss: 1.634697660904278
Validation loss: 2.7120196598834223

Epoch: 6| Step: 11
Training loss: 1.6693388339359305
Validation loss: 2.677049093568954

Epoch: 6| Step: 12
Training loss: 0.8224741836600848
Validation loss: 2.647100056398763

Epoch: 6| Step: 13
Training loss: 0.5976336855150499
Validation loss: 2.627040560181746

Epoch: 208| Step: 0
Training loss: 1.7493365937678456
Validation loss: 2.621503132738218

Epoch: 6| Step: 1
Training loss: 1.2584526375977207
Validation loss: 2.59085034195235

Epoch: 6| Step: 2
Training loss: 1.0728568026437089
Validation loss: 2.5896976174639144

Epoch: 6| Step: 3
Training loss: 1.2528466236532276
Validation loss: 2.618761063000074

Epoch: 6| Step: 4
Training loss: 1.489339457290704
Validation loss: 2.6038333710711106

Epoch: 6| Step: 5
Training loss: 1.188832088006852
Validation loss: 2.6560826672924702

Epoch: 6| Step: 6
Training loss: 0.8285342231040763
Validation loss: 2.6688361424682316

Epoch: 6| Step: 7
Training loss: 1.2332932283135627
Validation loss: 2.7203691117019124

Epoch: 6| Step: 8
Training loss: 1.1999087755973594
Validation loss: 2.69825198886953

Epoch: 6| Step: 9
Training loss: 1.7730974720057424
Validation loss: 2.7159308033002114

Epoch: 6| Step: 10
Training loss: 1.034113866568344
Validation loss: 2.677362955942177

Epoch: 6| Step: 11
Training loss: 1.4992015620961392
Validation loss: 2.6632742267229754

Epoch: 6| Step: 12
Training loss: 1.7205013715433133
Validation loss: 2.6853970720529685

Epoch: 6| Step: 13
Training loss: 1.488738062480018
Validation loss: 2.697525570639231

Epoch: 209| Step: 0
Training loss: 0.9996064723078154
Validation loss: 2.653619378322017

Epoch: 6| Step: 1
Training loss: 1.39686504590885
Validation loss: 2.678351834852616

Epoch: 6| Step: 2
Training loss: 1.463132382471622
Validation loss: 2.70382239858841

Epoch: 6| Step: 3
Training loss: 1.2715571275748971
Validation loss: 2.689000677269099

Epoch: 6| Step: 4
Training loss: 1.2785645696710253
Validation loss: 2.7082645073057994

Epoch: 6| Step: 5
Training loss: 1.6676756268482391
Validation loss: 2.666624764592635

Epoch: 6| Step: 6
Training loss: 1.5685949849293812
Validation loss: 2.675693554538118

Epoch: 6| Step: 7
Training loss: 1.3285957848386267
Validation loss: 2.669749449472786

Epoch: 6| Step: 8
Training loss: 1.1334023354131502
Validation loss: 2.678707650056453

Epoch: 6| Step: 9
Training loss: 1.4548457632213745
Validation loss: 2.6875816117238975

Epoch: 6| Step: 10
Training loss: 0.8792191012205375
Validation loss: 2.7021236429732363

Epoch: 6| Step: 11
Training loss: 1.1408440888991302
Validation loss: 2.730802402927685

Epoch: 6| Step: 12
Training loss: 1.7021569817000846
Validation loss: 2.7082165171480894

Epoch: 6| Step: 13
Training loss: 1.0878781877830637
Validation loss: 2.661364506967495

Epoch: 210| Step: 0
Training loss: 1.327759007906933
Validation loss: 2.6504359856579023

Epoch: 6| Step: 1
Training loss: 1.4975264340266319
Validation loss: 2.6239950656015356

Epoch: 6| Step: 2
Training loss: 1.0755193431680745
Validation loss: 2.6524383761465704

Epoch: 6| Step: 3
Training loss: 1.0858517619804149
Validation loss: 2.6586266228711115

Epoch: 6| Step: 4
Training loss: 1.1689144630791188
Validation loss: 2.6353660856528625

Epoch: 6| Step: 5
Training loss: 2.0283201949551604
Validation loss: 2.6559192405693977

Epoch: 6| Step: 6
Training loss: 1.3493364557765999
Validation loss: 2.67446191769796

Epoch: 6| Step: 7
Training loss: 1.168294293508231
Validation loss: 2.65957915639235

Epoch: 6| Step: 8
Training loss: 1.384390496367443
Validation loss: 2.62815676886707

Epoch: 6| Step: 9
Training loss: 1.291884921718196
Validation loss: 2.632552168516905

Epoch: 6| Step: 10
Training loss: 1.1289233566096846
Validation loss: 2.626173964005021

Epoch: 6| Step: 11
Training loss: 1.3979348925763482
Validation loss: 2.6465335262132674

Epoch: 6| Step: 12
Training loss: 1.059815212373389
Validation loss: 2.690608003393598

Epoch: 6| Step: 13
Training loss: 1.324381725443622
Validation loss: 2.6888944171065727

Epoch: 211| Step: 0
Training loss: 1.3176585503423193
Validation loss: 2.731716276091479

Epoch: 6| Step: 1
Training loss: 1.0982960638419441
Validation loss: 2.752079659288021

Epoch: 6| Step: 2
Training loss: 1.6938505417377772
Validation loss: 2.7653146361869982

Epoch: 6| Step: 3
Training loss: 1.1642341231233622
Validation loss: 2.8000076833669367

Epoch: 6| Step: 4
Training loss: 1.2418839185650774
Validation loss: 2.702373359592739

Epoch: 6| Step: 5
Training loss: 1.3026552648129923
Validation loss: 2.635485979464361

Epoch: 6| Step: 6
Training loss: 1.6892328901566207
Validation loss: 2.582268850530714

Epoch: 6| Step: 7
Training loss: 1.1173298885065508
Validation loss: 2.5673518764710366

Epoch: 6| Step: 8
Training loss: 0.687825862645529
Validation loss: 2.54343059850812

Epoch: 6| Step: 9
Training loss: 1.6604450288820793
Validation loss: 2.5587146140887813

Epoch: 6| Step: 10
Training loss: 1.2540320217479353
Validation loss: 2.5612741855369126

Epoch: 6| Step: 11
Training loss: 1.1139750677739648
Validation loss: 2.6130218634643367

Epoch: 6| Step: 12
Training loss: 1.629752691616335
Validation loss: 2.6034643864547493

Epoch: 6| Step: 13
Training loss: 1.0182956501491456
Validation loss: 2.6824703881401812

Epoch: 212| Step: 0
Training loss: 1.1056253167341177
Validation loss: 2.694815778148568

Epoch: 6| Step: 1
Training loss: 1.4474977211942508
Validation loss: 2.7472847839938686

Epoch: 6| Step: 2
Training loss: 1.0696180555005184
Validation loss: 2.7715002462134453

Epoch: 6| Step: 3
Training loss: 0.9118160454123335
Validation loss: 2.7510717285527604

Epoch: 6| Step: 4
Training loss: 1.6085764561187148
Validation loss: 2.7384459963379935

Epoch: 6| Step: 5
Training loss: 1.210577732910288
Validation loss: 2.7145110037276003

Epoch: 6| Step: 6
Training loss: 1.1224214885756407
Validation loss: 2.6410006169638622

Epoch: 6| Step: 7
Training loss: 1.3557636918507845
Validation loss: 2.6192835860646766

Epoch: 6| Step: 8
Training loss: 1.225288507002392
Validation loss: 2.616390641177904

Epoch: 6| Step: 9
Training loss: 1.5599535218675469
Validation loss: 2.580058011881909

Epoch: 6| Step: 10
Training loss: 1.6353785597457695
Validation loss: 2.62946044334704

Epoch: 6| Step: 11
Training loss: 1.343824606310297
Validation loss: 2.6627966642777112

Epoch: 6| Step: 12
Training loss: 1.3357069028412827
Validation loss: 2.6867694228982706

Epoch: 6| Step: 13
Training loss: 1.1822698761980723
Validation loss: 2.670190659855038

Epoch: 213| Step: 0
Training loss: 0.7800265459898676
Validation loss: 2.683189755145379

Epoch: 6| Step: 1
Training loss: 1.5788542318481478
Validation loss: 2.713206413009414

Epoch: 6| Step: 2
Training loss: 1.3999006406403138
Validation loss: 2.72081993021961

Epoch: 6| Step: 3
Training loss: 1.3228363202944733
Validation loss: 2.7464378112337435

Epoch: 6| Step: 4
Training loss: 1.2147148039359374
Validation loss: 2.7279111718360407

Epoch: 6| Step: 5
Training loss: 0.9971055819469082
Validation loss: 2.695746162842346

Epoch: 6| Step: 6
Training loss: 1.3935450210717213
Validation loss: 2.6800016129825117

Epoch: 6| Step: 7
Training loss: 1.0666734968403848
Validation loss: 2.662024985007675

Epoch: 6| Step: 8
Training loss: 1.2212930703352847
Validation loss: 2.6125004254514614

Epoch: 6| Step: 9
Training loss: 1.1398106110679478
Validation loss: 2.5834381434217084

Epoch: 6| Step: 10
Training loss: 1.3724136303128358
Validation loss: 2.583610447030686

Epoch: 6| Step: 11
Training loss: 1.8413398636838634
Validation loss: 2.6004205920054813

Epoch: 6| Step: 12
Training loss: 0.9848884878114956
Validation loss: 2.614368815426645

Epoch: 6| Step: 13
Training loss: 1.4656114524751997
Validation loss: 2.664859510928013

Epoch: 214| Step: 0
Training loss: 0.7023275727815962
Validation loss: 2.679300264522629

Epoch: 6| Step: 1
Training loss: 1.820034349662337
Validation loss: 2.7006546692841806

Epoch: 6| Step: 2
Training loss: 1.3245904451467112
Validation loss: 2.751797566822573

Epoch: 6| Step: 3
Training loss: 1.0930587764198667
Validation loss: 2.7466429750743075

Epoch: 6| Step: 4
Training loss: 1.6110987644526331
Validation loss: 2.7322748044013743

Epoch: 6| Step: 5
Training loss: 1.183251813086421
Validation loss: 2.7484993051473814

Epoch: 6| Step: 6
Training loss: 1.1816463754056876
Validation loss: 2.74019416173394

Epoch: 6| Step: 7
Training loss: 1.0660309183457197
Validation loss: 2.681116123262462

Epoch: 6| Step: 8
Training loss: 0.9155883117720512
Validation loss: 2.67108596869584

Epoch: 6| Step: 9
Training loss: 1.307079384071935
Validation loss: 2.6296818298337596

Epoch: 6| Step: 10
Training loss: 1.4025975159795379
Validation loss: 2.66172958355397

Epoch: 6| Step: 11
Training loss: 1.2984055828482144
Validation loss: 2.6091953063677513

Epoch: 6| Step: 12
Training loss: 1.2929634946964101
Validation loss: 2.6342563476747616

Epoch: 6| Step: 13
Training loss: 1.17398263228598
Validation loss: 2.634891634916276

Epoch: 215| Step: 0
Training loss: 0.8746421967958807
Validation loss: 2.637945327250767

Epoch: 6| Step: 1
Training loss: 1.3773981335701115
Validation loss: 2.67827829822583

Epoch: 6| Step: 2
Training loss: 1.568106853065382
Validation loss: 2.654667992565965

Epoch: 6| Step: 3
Training loss: 1.4325030176686828
Validation loss: 2.6602474335131614

Epoch: 6| Step: 4
Training loss: 0.8773816257633692
Validation loss: 2.6765063800376767

Epoch: 6| Step: 5
Training loss: 1.4313011027045963
Validation loss: 2.6992094783161598

Epoch: 6| Step: 6
Training loss: 1.4906474849516569
Validation loss: 2.6856362132317653

Epoch: 6| Step: 7
Training loss: 1.1266397076735213
Validation loss: 2.725730030113252

Epoch: 6| Step: 8
Training loss: 1.1482878087897588
Validation loss: 2.741310482587238

Epoch: 6| Step: 9
Training loss: 1.039700649168005
Validation loss: 2.7216291410077407

Epoch: 6| Step: 10
Training loss: 1.1920887977468633
Validation loss: 2.7105895407757283

Epoch: 6| Step: 11
Training loss: 1.2057586182965119
Validation loss: 2.7174927526443904

Epoch: 6| Step: 12
Training loss: 1.114097108878519
Validation loss: 2.7504125632413565

Epoch: 6| Step: 13
Training loss: 1.440670332122993
Validation loss: 2.6666090488618295

Epoch: 216| Step: 0
Training loss: 1.542226182941392
Validation loss: 2.655729852137125

Epoch: 6| Step: 1
Training loss: 1.1322489421870705
Validation loss: 2.6103665307270627

Epoch: 6| Step: 2
Training loss: 1.197286434521695
Validation loss: 2.6186860551348907

Epoch: 6| Step: 3
Training loss: 0.8869390004072548
Validation loss: 2.6302967619958397

Epoch: 6| Step: 4
Training loss: 1.0597364726066008
Validation loss: 2.679532346548175

Epoch: 6| Step: 5
Training loss: 0.7664183962731482
Validation loss: 2.7160456097806316

Epoch: 6| Step: 6
Training loss: 1.8509000083917158
Validation loss: 2.7423770328241033

Epoch: 6| Step: 7
Training loss: 1.3408023085639171
Validation loss: 2.7725194885772653

Epoch: 6| Step: 8
Training loss: 1.1658226888705572
Validation loss: 2.754455053714886

Epoch: 6| Step: 9
Training loss: 1.4072621411836492
Validation loss: 2.7412627015461286

Epoch: 6| Step: 10
Training loss: 1.0291882915515789
Validation loss: 2.731646068060651

Epoch: 6| Step: 11
Training loss: 1.221969948125945
Validation loss: 2.7482846728414403

Epoch: 6| Step: 12
Training loss: 1.282110901937958
Validation loss: 2.7129705619837026

Epoch: 6| Step: 13
Training loss: 1.0528378692315068
Validation loss: 2.6837139987246954

Epoch: 217| Step: 0
Training loss: 1.5512434801430366
Validation loss: 2.6137064318068464

Epoch: 6| Step: 1
Training loss: 1.6112466687507612
Validation loss: 2.5542925874093334

Epoch: 6| Step: 2
Training loss: 1.2175651072300973
Validation loss: 2.5154291157069926

Epoch: 6| Step: 3
Training loss: 1.0342678648447947
Validation loss: 2.556153837613079

Epoch: 6| Step: 4
Training loss: 1.2753491241572912
Validation loss: 2.6092951738254935

Epoch: 6| Step: 5
Training loss: 1.3913768493184935
Validation loss: 2.6862578711192566

Epoch: 6| Step: 6
Training loss: 1.1448818880488927
Validation loss: 2.7628448660089333

Epoch: 6| Step: 7
Training loss: 1.325385285987073
Validation loss: 2.767951134940637

Epoch: 6| Step: 8
Training loss: 1.4567288245957801
Validation loss: 2.764312402990992

Epoch: 6| Step: 9
Training loss: 1.196284478626422
Validation loss: 2.7439055082438117

Epoch: 6| Step: 10
Training loss: 1.2353289334482505
Validation loss: 2.702303166183991

Epoch: 6| Step: 11
Training loss: 1.0361201566881415
Validation loss: 2.655762071571785

Epoch: 6| Step: 12
Training loss: 0.9066329344325073
Validation loss: 2.6182939125644884

Epoch: 6| Step: 13
Training loss: 1.1302788649435798
Validation loss: 2.616063601063638

Epoch: 218| Step: 0
Training loss: 1.3159525737564948
Validation loss: 2.6140989619642263

Epoch: 6| Step: 1
Training loss: 0.6610283142177579
Validation loss: 2.6501761166850395

Epoch: 6| Step: 2
Training loss: 1.296211532566426
Validation loss: 2.711310599970734

Epoch: 6| Step: 3
Training loss: 0.8418589699627258
Validation loss: 2.7231825490848

Epoch: 6| Step: 4
Training loss: 1.4181547016716953
Validation loss: 2.7375418966940623

Epoch: 6| Step: 5
Training loss: 1.1115992639364172
Validation loss: 2.7659841167243733

Epoch: 6| Step: 6
Training loss: 1.8912310929245222
Validation loss: 2.7435941142986624

Epoch: 6| Step: 7
Training loss: 1.561750232098695
Validation loss: 2.7226700481042148

Epoch: 6| Step: 8
Training loss: 0.9914660196045794
Validation loss: 2.699225407888951

Epoch: 6| Step: 9
Training loss: 1.0523686667298309
Validation loss: 2.6698345132796

Epoch: 6| Step: 10
Training loss: 0.7347952269412095
Validation loss: 2.651898652919696

Epoch: 6| Step: 11
Training loss: 1.348767427856868
Validation loss: 2.6008186443386783

Epoch: 6| Step: 12
Training loss: 0.7149101601692269
Validation loss: 2.572138393893048

Epoch: 6| Step: 13
Training loss: 1.6135933414834382
Validation loss: 2.583173142672191

Epoch: 219| Step: 0
Training loss: 0.9863304213695422
Validation loss: 2.6605163343038267

Epoch: 6| Step: 1
Training loss: 0.9698627910216763
Validation loss: 2.678100256490202

Epoch: 6| Step: 2
Training loss: 0.8491240068663191
Validation loss: 2.738398338977652

Epoch: 6| Step: 3
Training loss: 1.6426090414469332
Validation loss: 2.764438940042419

Epoch: 6| Step: 4
Training loss: 1.4882111620481984
Validation loss: 2.7671797284689825

Epoch: 6| Step: 5
Training loss: 1.1079290933953405
Validation loss: 2.7718328936278773

Epoch: 6| Step: 6
Training loss: 1.2074979108393507
Validation loss: 2.71952365442284

Epoch: 6| Step: 7
Training loss: 1.3907514364648972
Validation loss: 2.7109112623779086

Epoch: 6| Step: 8
Training loss: 1.1884933131972288
Validation loss: 2.6824859335336857

Epoch: 6| Step: 9
Training loss: 1.31642590063806
Validation loss: 2.6529956626425117

Epoch: 6| Step: 10
Training loss: 1.4700225836128462
Validation loss: 2.6533992963205595

Epoch: 6| Step: 11
Training loss: 0.9748559918791334
Validation loss: 2.6578928625703218

Epoch: 6| Step: 12
Training loss: 1.3370560096301813
Validation loss: 2.6654903367511626

Epoch: 6| Step: 13
Training loss: 0.6226017237664221
Validation loss: 2.6550476895229087

Epoch: 220| Step: 0
Training loss: 1.1935846144267548
Validation loss: 2.663549107010733

Epoch: 6| Step: 1
Training loss: 1.013477284711844
Validation loss: 2.678522427916904

Epoch: 6| Step: 2
Training loss: 1.1357929877665076
Validation loss: 2.691267542111379

Epoch: 6| Step: 3
Training loss: 1.0043856296321023
Validation loss: 2.6910124698045643

Epoch: 6| Step: 4
Training loss: 0.9745383074273851
Validation loss: 2.6814762152284053

Epoch: 6| Step: 5
Training loss: 0.9662573648051178
Validation loss: 2.7029821218343426

Epoch: 6| Step: 6
Training loss: 1.136966848663459
Validation loss: 2.6986142810719618

Epoch: 6| Step: 7
Training loss: 1.2188380771991336
Validation loss: 2.6856200216852972

Epoch: 6| Step: 8
Training loss: 1.6459193951603432
Validation loss: 2.6896026419873165

Epoch: 6| Step: 9
Training loss: 1.2573812468104602
Validation loss: 2.679602412208679

Epoch: 6| Step: 10
Training loss: 0.8205513379403193
Validation loss: 2.6647136449288316

Epoch: 6| Step: 11
Training loss: 1.1223483094010327
Validation loss: 2.6400350732204396

Epoch: 6| Step: 12
Training loss: 1.6151917162500926
Validation loss: 2.636977141377027

Epoch: 6| Step: 13
Training loss: 1.3803894883756251
Validation loss: 2.621338329130954

Epoch: 221| Step: 0
Training loss: 0.8386822853099671
Validation loss: 2.6235840773363646

Epoch: 6| Step: 1
Training loss: 0.9320483964748165
Validation loss: 2.6509701376096446

Epoch: 6| Step: 2
Training loss: 1.007315165506306
Validation loss: 2.6465565951957837

Epoch: 6| Step: 3
Training loss: 1.248558787158434
Validation loss: 2.6758155063070785

Epoch: 6| Step: 4
Training loss: 1.1343030397063856
Validation loss: 2.735486168168967

Epoch: 6| Step: 5
Training loss: 1.1367740683187837
Validation loss: 2.7033793286901076

Epoch: 6| Step: 6
Training loss: 1.0210450724853883
Validation loss: 2.6929245757215714

Epoch: 6| Step: 7
Training loss: 1.0091311086306516
Validation loss: 2.65334155820787

Epoch: 6| Step: 8
Training loss: 1.9813581346912286
Validation loss: 2.68265966385383

Epoch: 6| Step: 9
Training loss: 1.2371327943936963
Validation loss: 2.6546195887852453

Epoch: 6| Step: 10
Training loss: 1.0823314814851797
Validation loss: 2.658467183340645

Epoch: 6| Step: 11
Training loss: 1.308673002206006
Validation loss: 2.6256023190596935

Epoch: 6| Step: 12
Training loss: 1.0547584792377476
Validation loss: 2.6365993459046972

Epoch: 6| Step: 13
Training loss: 1.0971716629054409
Validation loss: 2.6439829266217374

Epoch: 222| Step: 0
Training loss: 1.008875618809782
Validation loss: 2.645389892441497

Epoch: 6| Step: 1
Training loss: 0.6008244482812859
Validation loss: 2.703308968890229

Epoch: 6| Step: 2
Training loss: 1.161590357690914
Validation loss: 2.7219952319231537

Epoch: 6| Step: 3
Training loss: 0.9715131607361848
Validation loss: 2.72565551155926

Epoch: 6| Step: 4
Training loss: 0.9447599955966516
Validation loss: 2.7434063859250237

Epoch: 6| Step: 5
Training loss: 1.2126664155628126
Validation loss: 2.715843754837653

Epoch: 6| Step: 6
Training loss: 1.1117577551984499
Validation loss: 2.6788232871667623

Epoch: 6| Step: 7
Training loss: 1.1289602088572401
Validation loss: 2.6502396832139463

Epoch: 6| Step: 8
Training loss: 1.483330369082
Validation loss: 2.629536624318202

Epoch: 6| Step: 9
Training loss: 1.1149814405735579
Validation loss: 2.588149790402755

Epoch: 6| Step: 10
Training loss: 1.2236463054330142
Validation loss: 2.6091947271599323

Epoch: 6| Step: 11
Training loss: 1.6809509493532135
Validation loss: 2.652911469780317

Epoch: 6| Step: 12
Training loss: 1.269612565004011
Validation loss: 2.6505866115980266

Epoch: 6| Step: 13
Training loss: 1.035911773776467
Validation loss: 2.6323555993275813

Epoch: 223| Step: 0
Training loss: 1.0389936610772892
Validation loss: 2.6443458628229988

Epoch: 6| Step: 1
Training loss: 0.7253989881157686
Validation loss: 2.6864574181506478

Epoch: 6| Step: 2
Training loss: 1.199752142263393
Validation loss: 2.6757470095421017

Epoch: 6| Step: 3
Training loss: 1.7442936504424933
Validation loss: 2.6711409670569144

Epoch: 6| Step: 4
Training loss: 1.017435777779073
Validation loss: 2.695395953369792

Epoch: 6| Step: 5
Training loss: 1.1661810829431323
Validation loss: 2.689115347422819

Epoch: 6| Step: 6
Training loss: 1.048833410153845
Validation loss: 2.693675794812534

Epoch: 6| Step: 7
Training loss: 1.068049746876368
Validation loss: 2.708231198173258

Epoch: 6| Step: 8
Training loss: 1.3395175814868447
Validation loss: 2.707073481540086

Epoch: 6| Step: 9
Training loss: 0.7793286156942585
Validation loss: 2.6594583109159853

Epoch: 6| Step: 10
Training loss: 1.7050433772545794
Validation loss: 2.688156940499818

Epoch: 6| Step: 11
Training loss: 0.7072577350850151
Validation loss: 2.690893143625348

Epoch: 6| Step: 12
Training loss: 0.7853400930892007
Validation loss: 2.6628238227051146

Epoch: 6| Step: 13
Training loss: 1.4214083566070308
Validation loss: 2.6789728567430293

Epoch: 224| Step: 0
Training loss: 1.3383063123040924
Validation loss: 2.719988412524737

Epoch: 6| Step: 1
Training loss: 0.6545618232513021
Validation loss: 2.6816315224582534

Epoch: 6| Step: 2
Training loss: 1.3399564289724104
Validation loss: 2.6990272037652603

Epoch: 6| Step: 3
Training loss: 1.1175527975765145
Validation loss: 2.7357518933513347

Epoch: 6| Step: 4
Training loss: 1.292736251533683
Validation loss: 2.7060375172740985

Epoch: 6| Step: 5
Training loss: 1.0575145555400824
Validation loss: 2.6898461384595995

Epoch: 6| Step: 6
Training loss: 1.2754322179581283
Validation loss: 2.693114452250449

Epoch: 6| Step: 7
Training loss: 0.854101647639363
Validation loss: 2.674070305436518

Epoch: 6| Step: 8
Training loss: 1.6336435639691727
Validation loss: 2.648707667505051

Epoch: 6| Step: 9
Training loss: 0.9887987372712063
Validation loss: 2.637933607898294

Epoch: 6| Step: 10
Training loss: 1.2820392596769283
Validation loss: 2.6088734734835053

Epoch: 6| Step: 11
Training loss: 0.8287682823822794
Validation loss: 2.6635318966630126

Epoch: 6| Step: 12
Training loss: 1.1935470608277339
Validation loss: 2.6451336118941766

Epoch: 6| Step: 13
Training loss: 0.5634160265477642
Validation loss: 2.6163026727258942

Epoch: 225| Step: 0
Training loss: 1.7198299829599686
Validation loss: 2.659652167090508

Epoch: 6| Step: 1
Training loss: 1.0505268682414632
Validation loss: 2.6881781063831816

Epoch: 6| Step: 2
Training loss: 1.3149423128246038
Validation loss: 2.7378504282851557

Epoch: 6| Step: 3
Training loss: 0.841093118785357
Validation loss: 2.782446518743097

Epoch: 6| Step: 4
Training loss: 0.9560676550448453
Validation loss: 2.8290759305225284

Epoch: 6| Step: 5
Training loss: 1.0791975021866438
Validation loss: 2.8181042018477487

Epoch: 6| Step: 6
Training loss: 1.0712966292747812
Validation loss: 2.775779719304231

Epoch: 6| Step: 7
Training loss: 1.1122638537486664
Validation loss: 2.726698555904164

Epoch: 6| Step: 8
Training loss: 1.099558095600217
Validation loss: 2.670648795871645

Epoch: 6| Step: 9
Training loss: 1.125436062542685
Validation loss: 2.6398934592907914

Epoch: 6| Step: 10
Training loss: 1.0221297666875426
Validation loss: 2.6042044519123793

Epoch: 6| Step: 11
Training loss: 1.0205158142068176
Validation loss: 2.5789489443739053

Epoch: 6| Step: 12
Training loss: 1.2229563189462398
Validation loss: 2.5752481030224046

Epoch: 6| Step: 13
Training loss: 1.2256468252430108
Validation loss: 2.5870863486503315

Epoch: 226| Step: 0
Training loss: 1.1906105260895374
Validation loss: 2.599281876002367

Epoch: 6| Step: 1
Training loss: 0.8814373277183765
Validation loss: 2.6214493442048092

Epoch: 6| Step: 2
Training loss: 0.8640345053250851
Validation loss: 2.6264677041518096

Epoch: 6| Step: 3
Training loss: 1.4011933009495787
Validation loss: 2.687380596082979

Epoch: 6| Step: 4
Training loss: 1.237331856758234
Validation loss: 2.693841546077686

Epoch: 6| Step: 5
Training loss: 1.183553462082479
Validation loss: 2.733015069495584

Epoch: 6| Step: 6
Training loss: 0.6743737927656708
Validation loss: 2.7132308927178643

Epoch: 6| Step: 7
Training loss: 1.3896174692119898
Validation loss: 2.685426824815517

Epoch: 6| Step: 8
Training loss: 1.0564668128149055
Validation loss: 2.6331280436182194

Epoch: 6| Step: 9
Training loss: 1.784763418168298
Validation loss: 2.6379950865420114

Epoch: 6| Step: 10
Training loss: 1.0424387867655047
Validation loss: 2.668512452702727

Epoch: 6| Step: 11
Training loss: 0.9242207376389401
Validation loss: 2.630875552767377

Epoch: 6| Step: 12
Training loss: 0.8226541430382044
Validation loss: 2.5824257402204687

Epoch: 6| Step: 13
Training loss: 0.9129473086295248
Validation loss: 2.61495717668089

Epoch: 227| Step: 0
Training loss: 1.0446201922853928
Validation loss: 2.6271127342698533

Epoch: 6| Step: 1
Training loss: 0.6684020572234615
Validation loss: 2.6648701767911587

Epoch: 6| Step: 2
Training loss: 0.7951930377925984
Validation loss: 2.7103874289398653

Epoch: 6| Step: 3
Training loss: 0.628221340287768
Validation loss: 2.7037665403496187

Epoch: 6| Step: 4
Training loss: 1.2056665205146406
Validation loss: 2.743063020174638

Epoch: 6| Step: 5
Training loss: 0.7665582146507315
Validation loss: 2.737259872902216

Epoch: 6| Step: 6
Training loss: 1.0652946295656296
Validation loss: 2.7184174800718273

Epoch: 6| Step: 7
Training loss: 1.1399904341045382
Validation loss: 2.67065330754717

Epoch: 6| Step: 8
Training loss: 1.1886897902779288
Validation loss: 2.657743574787715

Epoch: 6| Step: 9
Training loss: 1.0196907240278579
Validation loss: 2.613021455325927

Epoch: 6| Step: 10
Training loss: 1.12158628271125
Validation loss: 2.624521527336166

Epoch: 6| Step: 11
Training loss: 1.4373532095887185
Validation loss: 2.602351499553782

Epoch: 6| Step: 12
Training loss: 1.296740605388122
Validation loss: 2.6013416138740877

Epoch: 6| Step: 13
Training loss: 2.098161292059101
Validation loss: 2.653098289554054

Epoch: 228| Step: 0
Training loss: 1.3171783808961564
Validation loss: 2.7241342082654167

Epoch: 6| Step: 1
Training loss: 0.9280017347072962
Validation loss: 2.6737933719792983

Epoch: 6| Step: 2
Training loss: 1.1298545365681862
Validation loss: 2.710419312667252

Epoch: 6| Step: 3
Training loss: 0.8220901120720515
Validation loss: 2.7491429541852805

Epoch: 6| Step: 4
Training loss: 1.1632577559415271
Validation loss: 2.7552843045985353

Epoch: 6| Step: 5
Training loss: 1.4991160013155722
Validation loss: 2.7447530373215336

Epoch: 6| Step: 6
Training loss: 0.9043849300743603
Validation loss: 2.7124002147875284

Epoch: 6| Step: 7
Training loss: 1.2245250228717661
Validation loss: 2.6882493805117598

Epoch: 6| Step: 8
Training loss: 1.1189631509449305
Validation loss: 2.652259845751553

Epoch: 6| Step: 9
Training loss: 0.8554642211236784
Validation loss: 2.6715034572431877

Epoch: 6| Step: 10
Training loss: 1.1028823520830842
Validation loss: 2.6638213874231367

Epoch: 6| Step: 11
Training loss: 0.8313473321821508
Validation loss: 2.6654873792467892

Epoch: 6| Step: 12
Training loss: 1.6735003405258064
Validation loss: 2.6617565809487647

Epoch: 6| Step: 13
Training loss: 0.43617429147386094
Validation loss: 2.6443124814742274

Epoch: 229| Step: 0
Training loss: 1.0581427595312174
Validation loss: 2.64458799102127

Epoch: 6| Step: 1
Training loss: 0.7505312468639971
Validation loss: 2.6923105751341296

Epoch: 6| Step: 2
Training loss: 1.2904073462407821
Validation loss: 2.6866632405199704

Epoch: 6| Step: 3
Training loss: 1.0643945520366944
Validation loss: 2.7065840509204566

Epoch: 6| Step: 4
Training loss: 1.1617296127293761
Validation loss: 2.6692265571065503

Epoch: 6| Step: 5
Training loss: 1.0782766926515324
Validation loss: 2.6189752028694646

Epoch: 6| Step: 6
Training loss: 1.2739288224768461
Validation loss: 2.571370403534781

Epoch: 6| Step: 7
Training loss: 0.9739849712516567
Validation loss: 2.5573620994623916

Epoch: 6| Step: 8
Training loss: 1.6446923111358325
Validation loss: 2.5828089431569365

Epoch: 6| Step: 9
Training loss: 1.2611572149833425
Validation loss: 2.5807510877860595

Epoch: 6| Step: 10
Training loss: 1.0451316551614362
Validation loss: 2.6430859957601607

Epoch: 6| Step: 11
Training loss: 1.0226989877045465
Validation loss: 2.686729586391545

Epoch: 6| Step: 12
Training loss: 1.1319951232663574
Validation loss: 2.7680244648329597

Epoch: 6| Step: 13
Training loss: 0.4179457185763482
Validation loss: 2.796845032226692

Epoch: 230| Step: 0
Training loss: 0.738272853581553
Validation loss: 2.8372158964844534

Epoch: 6| Step: 1
Training loss: 1.1228385931179372
Validation loss: 2.828744545214915

Epoch: 6| Step: 2
Training loss: 1.1409130516556876
Validation loss: 2.7959936828047818

Epoch: 6| Step: 3
Training loss: 0.9237564736579492
Validation loss: 2.6960206249952297

Epoch: 6| Step: 4
Training loss: 1.3551065362243009
Validation loss: 2.637624438815009

Epoch: 6| Step: 5
Training loss: 0.8792022206739196
Validation loss: 2.6009101191358908

Epoch: 6| Step: 6
Training loss: 1.2498056260618253
Validation loss: 2.628906536701097

Epoch: 6| Step: 7
Training loss: 1.0390523465456394
Validation loss: 2.6379956861511995

Epoch: 6| Step: 8
Training loss: 1.335191395644662
Validation loss: 2.7368089934774087

Epoch: 6| Step: 9
Training loss: 0.8258604359983074
Validation loss: 2.7420876193261337

Epoch: 6| Step: 10
Training loss: 1.0339700488174217
Validation loss: 2.763040810424726

Epoch: 6| Step: 11
Training loss: 1.0557470580160968
Validation loss: 2.7854629801259585

Epoch: 6| Step: 12
Training loss: 1.5304709807881585
Validation loss: 2.756969173878383

Epoch: 6| Step: 13
Training loss: 1.3473913402307969
Validation loss: 2.7485813749546133

Epoch: 231| Step: 0
Training loss: 1.050343248484147
Validation loss: 2.7234525820228885

Epoch: 6| Step: 1
Training loss: 1.0220522059041934
Validation loss: 2.6799699528092917

Epoch: 6| Step: 2
Training loss: 0.9905248212250982
Validation loss: 2.634370699298647

Epoch: 6| Step: 3
Training loss: 1.1342871702887685
Validation loss: 2.588946084925182

Epoch: 6| Step: 4
Training loss: 1.1312724200814275
Validation loss: 2.5564886455157505

Epoch: 6| Step: 5
Training loss: 1.0702220572245835
Validation loss: 2.595928533984997

Epoch: 6| Step: 6
Training loss: 1.0228404859052724
Validation loss: 2.6480301959334156

Epoch: 6| Step: 7
Training loss: 1.2316392931823594
Validation loss: 2.697302131886649

Epoch: 6| Step: 8
Training loss: 1.7094396714942928
Validation loss: 2.706250439700449

Epoch: 6| Step: 9
Training loss: 0.9119927864793296
Validation loss: 2.7095901192095497

Epoch: 6| Step: 10
Training loss: 0.8307022082380153
Validation loss: 2.6758707734382106

Epoch: 6| Step: 11
Training loss: 1.0336962498410376
Validation loss: 2.688409283741786

Epoch: 6| Step: 12
Training loss: 1.0070136400907066
Validation loss: 2.7051578265802547

Epoch: 6| Step: 13
Training loss: 0.9024714590087649
Validation loss: 2.656645094112216

Epoch: 232| Step: 0
Training loss: 0.885870204031412
Validation loss: 2.6933277147927535

Epoch: 6| Step: 1
Training loss: 1.0705068926849897
Validation loss: 2.6490347135626338

Epoch: 6| Step: 2
Training loss: 0.3970217703716321
Validation loss: 2.6454958276941993

Epoch: 6| Step: 3
Training loss: 0.9963623283172924
Validation loss: 2.654447987847889

Epoch: 6| Step: 4
Training loss: 0.9901209057084076
Validation loss: 2.6398970135699904

Epoch: 6| Step: 5
Training loss: 1.7387536939174486
Validation loss: 2.6636749977893173

Epoch: 6| Step: 6
Training loss: 0.728196961608348
Validation loss: 2.6762523945619923

Epoch: 6| Step: 7
Training loss: 0.9601947425966918
Validation loss: 2.684469154247423

Epoch: 6| Step: 8
Training loss: 0.9658249410396865
Validation loss: 2.7233737227317776

Epoch: 6| Step: 9
Training loss: 1.3624914991481065
Validation loss: 2.6853251871171047

Epoch: 6| Step: 10
Training loss: 0.8956835458897267
Validation loss: 2.6493232309039088

Epoch: 6| Step: 11
Training loss: 1.377395017884695
Validation loss: 2.677430323167379

Epoch: 6| Step: 12
Training loss: 1.0257732149900403
Validation loss: 2.7007224185239846

Epoch: 6| Step: 13
Training loss: 0.9275941762898475
Validation loss: 2.649860328635656

Epoch: 233| Step: 0
Training loss: 0.5941415048124984
Validation loss: 2.6906812087648544

Epoch: 6| Step: 1
Training loss: 1.1799183297585505
Validation loss: 2.6972758576231697

Epoch: 6| Step: 2
Training loss: 1.2785179970332028
Validation loss: 2.651787311629414

Epoch: 6| Step: 3
Training loss: 1.2827096393713415
Validation loss: 2.630915853509545

Epoch: 6| Step: 4
Training loss: 1.2733498291541572
Validation loss: 2.6082313462487425

Epoch: 6| Step: 5
Training loss: 1.5033075899822586
Validation loss: 2.615333176693843

Epoch: 6| Step: 6
Training loss: 1.0367843779637937
Validation loss: 2.538211735887957

Epoch: 6| Step: 7
Training loss: 1.0313643189846793
Validation loss: 2.556864430330479

Epoch: 6| Step: 8
Training loss: 0.8358091451910888
Validation loss: 2.604926411378962

Epoch: 6| Step: 9
Training loss: 0.694687744806395
Validation loss: 2.5935933628813945

Epoch: 6| Step: 10
Training loss: 1.2889700654151894
Validation loss: 2.610565169564032

Epoch: 6| Step: 11
Training loss: 1.1734940597780419
Validation loss: 2.6418509785647912

Epoch: 6| Step: 12
Training loss: 1.0750259972910816
Validation loss: 2.6655764438939613

Epoch: 6| Step: 13
Training loss: 0.24213515762022036
Validation loss: 2.686298472844102

Epoch: 234| Step: 0
Training loss: 1.0085971350579814
Validation loss: 2.665358727034901

Epoch: 6| Step: 1
Training loss: 0.9563333886382427
Validation loss: 2.6650417559652677

Epoch: 6| Step: 2
Training loss: 1.075780780157736
Validation loss: 2.6731369769738413

Epoch: 6| Step: 3
Training loss: 1.0817975504549306
Validation loss: 2.6581461595939775

Epoch: 6| Step: 4
Training loss: 1.040348719673654
Validation loss: 2.651770714733371

Epoch: 6| Step: 5
Training loss: 1.1773680564836815
Validation loss: 2.6586866095888246

Epoch: 6| Step: 6
Training loss: 0.9853634186136317
Validation loss: 2.6060904942859735

Epoch: 6| Step: 7
Training loss: 1.5056072969136178
Validation loss: 2.590183561249157

Epoch: 6| Step: 8
Training loss: 1.1030264251151276
Validation loss: 2.6046394486673297

Epoch: 6| Step: 9
Training loss: 0.885170143065548
Validation loss: 2.6157442793710928

Epoch: 6| Step: 10
Training loss: 0.7962257882214425
Validation loss: 2.6330298327401507

Epoch: 6| Step: 11
Training loss: 1.1195000143012812
Validation loss: 2.635146824750519

Epoch: 6| Step: 12
Training loss: 0.9076401801385104
Validation loss: 2.632217449526209

Epoch: 6| Step: 13
Training loss: 0.5885058507458323
Validation loss: 2.6358893309169202

Epoch: 235| Step: 0
Training loss: 1.0995232936305097
Validation loss: 2.662414534735414

Epoch: 6| Step: 1
Training loss: 1.0772573324375785
Validation loss: 2.676641524895888

Epoch: 6| Step: 2
Training loss: 0.7510712840412654
Validation loss: 2.6520698059503656

Epoch: 6| Step: 3
Training loss: 1.0522017963051122
Validation loss: 2.6414498588556943

Epoch: 6| Step: 4
Training loss: 0.9421965894371369
Validation loss: 2.6733236328688355

Epoch: 6| Step: 5
Training loss: 0.9605621597296387
Validation loss: 2.6930583709601836

Epoch: 6| Step: 6
Training loss: 1.1684927897037014
Validation loss: 2.6472452698562923

Epoch: 6| Step: 7
Training loss: 0.8413022882952551
Validation loss: 2.6464788243621857

Epoch: 6| Step: 8
Training loss: 1.2953756006422217
Validation loss: 2.6272251798120094

Epoch: 6| Step: 9
Training loss: 0.8570743282205435
Validation loss: 2.6196835703384957

Epoch: 6| Step: 10
Training loss: 1.0525885712784684
Validation loss: 2.582337912772616

Epoch: 6| Step: 11
Training loss: 1.0918367272816654
Validation loss: 2.556701972775832

Epoch: 6| Step: 12
Training loss: 0.9556761821365799
Validation loss: 2.585903888113794

Epoch: 6| Step: 13
Training loss: 1.084936545138156
Validation loss: 2.641411734196227

Epoch: 236| Step: 0
Training loss: 1.1833725524277448
Validation loss: 2.6906539427789977

Epoch: 6| Step: 1
Training loss: 0.5641070298135386
Validation loss: 2.7177005336350537

Epoch: 6| Step: 2
Training loss: 0.9552388124307496
Validation loss: 2.7396387750979754

Epoch: 6| Step: 3
Training loss: 1.0824916149457775
Validation loss: 2.768317673297534

Epoch: 6| Step: 4
Training loss: 1.217712645554338
Validation loss: 2.670346411763402

Epoch: 6| Step: 5
Training loss: 1.7561393404270647
Validation loss: 2.6946309173526637

Epoch: 6| Step: 6
Training loss: 0.5286855792308225
Validation loss: 2.6504654605771694

Epoch: 6| Step: 7
Training loss: 0.9599636073963063
Validation loss: 2.6471306909080816

Epoch: 6| Step: 8
Training loss: 0.8967531420501377
Validation loss: 2.6314592676090762

Epoch: 6| Step: 9
Training loss: 0.5631200763516782
Validation loss: 2.6289397167784205

Epoch: 6| Step: 10
Training loss: 0.8216247235542458
Validation loss: 2.6461440267215024

Epoch: 6| Step: 11
Training loss: 1.138433781590804
Validation loss: 2.653537050543169

Epoch: 6| Step: 12
Training loss: 0.8727616904685132
Validation loss: 2.682085254889765

Epoch: 6| Step: 13
Training loss: 1.0321556507247336
Validation loss: 2.6823545546327185

Epoch: 237| Step: 0
Training loss: 0.945951450775581
Validation loss: 2.6987736846445824

Epoch: 6| Step: 1
Training loss: 0.6157132177514337
Validation loss: 2.65955754409324

Epoch: 6| Step: 2
Training loss: 0.7440539532346405
Validation loss: 2.662017335076227

Epoch: 6| Step: 3
Training loss: 0.823385821173922
Validation loss: 2.63663419878872

Epoch: 6| Step: 4
Training loss: 0.6823467761392579
Validation loss: 2.6261470591379177

Epoch: 6| Step: 5
Training loss: 0.4622372228714397
Validation loss: 2.6312461232756075

Epoch: 6| Step: 6
Training loss: 0.901599990356127
Validation loss: 2.6675449760798617

Epoch: 6| Step: 7
Training loss: 1.2189931382446935
Validation loss: 2.6749092551276883

Epoch: 6| Step: 8
Training loss: 1.6975412090170403
Validation loss: 2.6402131320270334

Epoch: 6| Step: 9
Training loss: 1.3555683901879259
Validation loss: 2.687257907968807

Epoch: 6| Step: 10
Training loss: 0.9405605902433478
Validation loss: 2.723343143832803

Epoch: 6| Step: 11
Training loss: 0.7663294606912247
Validation loss: 2.7224852716195613

Epoch: 6| Step: 12
Training loss: 1.173937343397355
Validation loss: 2.7492853846138896

Epoch: 6| Step: 13
Training loss: 0.8935778005143435
Validation loss: 2.7112491375704453

Epoch: 238| Step: 0
Training loss: 0.9331245999293866
Validation loss: 2.642865867911544

Epoch: 6| Step: 1
Training loss: 0.7806629263931876
Validation loss: 2.61681898078849

Epoch: 6| Step: 2
Training loss: 1.1017095589379484
Validation loss: 2.5731805316769067

Epoch: 6| Step: 3
Training loss: 0.8954846161778139
Validation loss: 2.5492536453077657

Epoch: 6| Step: 4
Training loss: 1.7217204694413053
Validation loss: 2.5376137885810106

Epoch: 6| Step: 5
Training loss: 0.9596746256395472
Validation loss: 2.5594979726244813

Epoch: 6| Step: 6
Training loss: 1.028340483464918
Validation loss: 2.564654608226777

Epoch: 6| Step: 7
Training loss: 1.2241158837175974
Validation loss: 2.5874302147693773

Epoch: 6| Step: 8
Training loss: 0.7319430400908106
Validation loss: 2.592749281886723

Epoch: 6| Step: 9
Training loss: 0.9119962176884472
Validation loss: 2.6406406927106656

Epoch: 6| Step: 10
Training loss: 0.7874723596112069
Validation loss: 2.7091099240157024

Epoch: 6| Step: 11
Training loss: 0.9988710468067455
Validation loss: 2.7027005638841892

Epoch: 6| Step: 12
Training loss: 0.7464350374167286
Validation loss: 2.738527620858429

Epoch: 6| Step: 13
Training loss: 1.0040718862247409
Validation loss: 2.7297479279338352

Epoch: 239| Step: 0
Training loss: 1.3385767604319225
Validation loss: 2.6672366254838313

Epoch: 6| Step: 1
Training loss: 0.7725860455809344
Validation loss: 2.683704503438309

Epoch: 6| Step: 2
Training loss: 0.789238862827567
Validation loss: 2.6445376805874545

Epoch: 6| Step: 3
Training loss: 1.1506034511721948
Validation loss: 2.6449461355353465

Epoch: 6| Step: 4
Training loss: 0.7898929493840693
Validation loss: 2.609934157859306

Epoch: 6| Step: 5
Training loss: 0.724841345495046
Validation loss: 2.576761465247673

Epoch: 6| Step: 6
Training loss: 1.191899031990427
Validation loss: 2.5656246700154006

Epoch: 6| Step: 7
Training loss: 0.8767020156995563
Validation loss: 2.546560573438755

Epoch: 6| Step: 8
Training loss: 1.2038024382295773
Validation loss: 2.5774622602623936

Epoch: 6| Step: 9
Training loss: 0.5190601363980876
Validation loss: 2.573078993512946

Epoch: 6| Step: 10
Training loss: 1.1817310141048452
Validation loss: 2.5631825908310053

Epoch: 6| Step: 11
Training loss: 0.8821087623237966
Validation loss: 2.6099084204885243

Epoch: 6| Step: 12
Training loss: 1.1077525134719919
Validation loss: 2.6337480396718784

Epoch: 6| Step: 13
Training loss: 0.5483134289677881
Validation loss: 2.6471958025898257

Epoch: 240| Step: 0
Training loss: 1.100770922924411
Validation loss: 2.644605395415705

Epoch: 6| Step: 1
Training loss: 1.0942990695966495
Validation loss: 2.6434598141458028

Epoch: 6| Step: 2
Training loss: 0.9802079784839945
Validation loss: 2.6784667924482743

Epoch: 6| Step: 3
Training loss: 0.914931251256985
Validation loss: 2.65990246008804

Epoch: 6| Step: 4
Training loss: 0.7080449798299341
Validation loss: 2.64073669445905

Epoch: 6| Step: 5
Training loss: 0.9232963983490928
Validation loss: 2.661693138731506

Epoch: 6| Step: 6
Training loss: 0.9168545393165763
Validation loss: 2.6109326931181416

Epoch: 6| Step: 7
Training loss: 0.678327537210369
Validation loss: 2.65007767082678

Epoch: 6| Step: 8
Training loss: 1.043133669040649
Validation loss: 2.6436337381080817

Epoch: 6| Step: 9
Training loss: 1.535023535507641
Validation loss: 2.627788354838394

Epoch: 6| Step: 10
Training loss: 0.9079662383226464
Validation loss: 2.6768487848537794

Epoch: 6| Step: 11
Training loss: 0.9397105540373922
Validation loss: 2.6842819563516085

Epoch: 6| Step: 12
Training loss: 0.8992018723747505
Validation loss: 2.6805422548059044

Epoch: 6| Step: 13
Training loss: 0.5812929065824103
Validation loss: 2.678361827698947

Epoch: 241| Step: 0
Training loss: 0.7604155910606267
Validation loss: 2.68522221564426

Epoch: 6| Step: 1
Training loss: 1.3401926548378404
Validation loss: 2.6179078762603205

Epoch: 6| Step: 2
Training loss: 0.8388697099037128
Validation loss: 2.649783950236291

Epoch: 6| Step: 3
Training loss: 0.9918647902118881
Validation loss: 2.603132397101561

Epoch: 6| Step: 4
Training loss: 0.9107068078885431
Validation loss: 2.583469084296585

Epoch: 6| Step: 5
Training loss: 0.9432353062520283
Validation loss: 2.622929158104813

Epoch: 6| Step: 6
Training loss: 0.4627844934277072
Validation loss: 2.6485670206091747

Epoch: 6| Step: 7
Training loss: 1.2472109196317622
Validation loss: 2.668608155467209

Epoch: 6| Step: 8
Training loss: 1.3154889541562407
Validation loss: 2.709928606589325

Epoch: 6| Step: 9
Training loss: 0.9425165743597351
Validation loss: 2.6834783413878784

Epoch: 6| Step: 10
Training loss: 0.7552505525210045
Validation loss: 2.6876711369994863

Epoch: 6| Step: 11
Training loss: 0.799998053905981
Validation loss: 2.66683633390184

Epoch: 6| Step: 12
Training loss: 0.7007488366565445
Validation loss: 2.651284141934323

Epoch: 6| Step: 13
Training loss: 0.9629559291646563
Validation loss: 2.656022959590534

Epoch: 242| Step: 0
Training loss: 0.9405058991319685
Validation loss: 2.5916112351448612

Epoch: 6| Step: 1
Training loss: 0.8692580583082025
Validation loss: 2.6254395704322038

Epoch: 6| Step: 2
Training loss: 1.0511978628177487
Validation loss: 2.6335189619821224

Epoch: 6| Step: 3
Training loss: 1.041336325081481
Validation loss: 2.6388002233572294

Epoch: 6| Step: 4
Training loss: 0.9134102801176898
Validation loss: 2.5899023701697583

Epoch: 6| Step: 5
Training loss: 0.9726716312280007
Validation loss: 2.5939774505560873

Epoch: 6| Step: 6
Training loss: 0.9580883182837133
Validation loss: 2.6142892633337667

Epoch: 6| Step: 7
Training loss: 0.5578270832794764
Validation loss: 2.598880118984447

Epoch: 6| Step: 8
Training loss: 1.01931456386117
Validation loss: 2.635001420311402

Epoch: 6| Step: 9
Training loss: 0.8917078830129697
Validation loss: 2.6830385602897167

Epoch: 6| Step: 10
Training loss: 1.3540300544885449
Validation loss: 2.7013053092030517

Epoch: 6| Step: 11
Training loss: 0.8085549755290352
Validation loss: 2.673700351625866

Epoch: 6| Step: 12
Training loss: 0.7142729434506577
Validation loss: 2.692811070268597

Epoch: 6| Step: 13
Training loss: 0.8322109332851862
Validation loss: 2.6800743820381165

Epoch: 243| Step: 0
Training loss: 1.0449506238743769
Validation loss: 2.6350129036389833

Epoch: 6| Step: 1
Training loss: 1.466449721865166
Validation loss: 2.672984580491179

Epoch: 6| Step: 2
Training loss: 0.7585395392898221
Validation loss: 2.696967890563482

Epoch: 6| Step: 3
Training loss: 0.7630956480737725
Validation loss: 2.713675472615224

Epoch: 6| Step: 4
Training loss: 0.8763010706147024
Validation loss: 2.737032176250894

Epoch: 6| Step: 5
Training loss: 1.3124919164499491
Validation loss: 2.721773476063137

Epoch: 6| Step: 6
Training loss: 0.5881713501100692
Validation loss: 2.710481488120007

Epoch: 6| Step: 7
Training loss: 0.8072301451508704
Validation loss: 2.6280498610611676

Epoch: 6| Step: 8
Training loss: 0.8198150579725676
Validation loss: 2.578912133916511

Epoch: 6| Step: 9
Training loss: 0.9810461038999619
Validation loss: 2.529498192035144

Epoch: 6| Step: 10
Training loss: 0.986187673709776
Validation loss: 2.5006151703782824

Epoch: 6| Step: 11
Training loss: 0.8428824874678876
Validation loss: 2.516846302948699

Epoch: 6| Step: 12
Training loss: 0.8446808378159395
Validation loss: 2.537365014885604

Epoch: 6| Step: 13
Training loss: 1.3827038307379105
Validation loss: 2.6165946170138015

Epoch: 244| Step: 0
Training loss: 0.6807912217925214
Validation loss: 2.6487160183913367

Epoch: 6| Step: 1
Training loss: 0.9922485933493296
Validation loss: 2.7082668160599215

Epoch: 6| Step: 2
Training loss: 0.8991519906511191
Validation loss: 2.7744481109327

Epoch: 6| Step: 3
Training loss: 1.0244274447633421
Validation loss: 2.78333658073648

Epoch: 6| Step: 4
Training loss: 0.9889984544022598
Validation loss: 2.75245815614011

Epoch: 6| Step: 5
Training loss: 0.7606605809210952
Validation loss: 2.7141016920623398

Epoch: 6| Step: 6
Training loss: 0.6850469347613547
Validation loss: 2.686277742602351

Epoch: 6| Step: 7
Training loss: 0.9476652266037132
Validation loss: 2.6072460014928187

Epoch: 6| Step: 8
Training loss: 1.100006086159255
Validation loss: 2.5590103653136502

Epoch: 6| Step: 9
Training loss: 1.375983666644631
Validation loss: 2.565196135846963

Epoch: 6| Step: 10
Training loss: 1.0388445518051517
Validation loss: 2.5473113001789707

Epoch: 6| Step: 11
Training loss: 0.7177293828821972
Validation loss: 2.5318317603141485

Epoch: 6| Step: 12
Training loss: 1.1306196891023097
Validation loss: 2.596191101617922

Epoch: 6| Step: 13
Training loss: 0.7745792554269542
Validation loss: 2.655309478041238

Epoch: 245| Step: 0
Training loss: 0.6943676132509696
Validation loss: 2.710193884424269

Epoch: 6| Step: 1
Training loss: 0.829558553212219
Validation loss: 2.784603227202229

Epoch: 6| Step: 2
Training loss: 0.817057299772265
Validation loss: 2.8552701487743914

Epoch: 6| Step: 3
Training loss: 0.9657249596470217
Validation loss: 2.883583863604591

Epoch: 6| Step: 4
Training loss: 0.6912319157530205
Validation loss: 2.7787430541885305

Epoch: 6| Step: 5
Training loss: 0.8638103123984856
Validation loss: 2.7171962901472595

Epoch: 6| Step: 6
Training loss: 1.279800525559897
Validation loss: 2.6744590928108702

Epoch: 6| Step: 7
Training loss: 0.9501993271369454
Validation loss: 2.63605602180375

Epoch: 6| Step: 8
Training loss: 0.9742205499725722
Validation loss: 2.582490135057844

Epoch: 6| Step: 9
Training loss: 1.4669963025525596
Validation loss: 2.5381989353870917

Epoch: 6| Step: 10
Training loss: 0.5497073261790824
Validation loss: 2.5360971030898996

Epoch: 6| Step: 11
Training loss: 1.2041506173319376
Validation loss: 2.570872112532214

Epoch: 6| Step: 12
Training loss: 0.928333354130396
Validation loss: 2.596691324501131

Epoch: 6| Step: 13
Training loss: 0.7829685002442469
Validation loss: 2.6470329022259325

Epoch: 246| Step: 0
Training loss: 0.8051899202584767
Validation loss: 2.6948902305237934

Epoch: 6| Step: 1
Training loss: 0.9403689039003089
Validation loss: 2.75235406831418

Epoch: 6| Step: 2
Training loss: 1.0885925767787383
Validation loss: 2.7594516199498393

Epoch: 6| Step: 3
Training loss: 1.1826746932144052
Validation loss: 2.7255515495573523

Epoch: 6| Step: 4
Training loss: 0.9359360365306895
Validation loss: 2.728628790507992

Epoch: 6| Step: 5
Training loss: 0.6351374549477863
Validation loss: 2.687705831236332

Epoch: 6| Step: 6
Training loss: 1.0863318516277436
Validation loss: 2.650879539210861

Epoch: 6| Step: 7
Training loss: 1.0842414619825604
Validation loss: 2.5964220449355744

Epoch: 6| Step: 8
Training loss: 0.5375230340679602
Validation loss: 2.5566187963039

Epoch: 6| Step: 9
Training loss: 0.6728057181321729
Validation loss: 2.5772725694445318

Epoch: 6| Step: 10
Training loss: 1.005914719920049
Validation loss: 2.581832143584306

Epoch: 6| Step: 11
Training loss: 0.8122128933044512
Validation loss: 2.6173372468578977

Epoch: 6| Step: 12
Training loss: 1.0377794532832694
Validation loss: 2.6371168879238365

Epoch: 6| Step: 13
Training loss: 0.7064302324199476
Validation loss: 2.6806265916705976

Epoch: 247| Step: 0
Training loss: 1.1300528224481952
Validation loss: 2.676668685556595

Epoch: 6| Step: 1
Training loss: 1.172621883165759
Validation loss: 2.6441454210368267

Epoch: 6| Step: 2
Training loss: 0.6002052651401614
Validation loss: 2.60925048723618

Epoch: 6| Step: 3
Training loss: 1.2189758287181685
Validation loss: 2.5745367252483238

Epoch: 6| Step: 4
Training loss: 0.6633700182209955
Validation loss: 2.5236465056163198

Epoch: 6| Step: 5
Training loss: 0.8815621492803688
Validation loss: 2.5197197340830297

Epoch: 6| Step: 6
Training loss: 0.7543443582880716
Validation loss: 2.511745285286716

Epoch: 6| Step: 7
Training loss: 0.8968034562873765
Validation loss: 2.5413756127408162

Epoch: 6| Step: 8
Training loss: 0.8376216856961075
Validation loss: 2.5714705585955726

Epoch: 6| Step: 9
Training loss: 0.9139285519259767
Validation loss: 2.566944748519996

Epoch: 6| Step: 10
Training loss: 0.7935861148005026
Validation loss: 2.577352399711166

Epoch: 6| Step: 11
Training loss: 0.7173916794093663
Validation loss: 2.642728076434732

Epoch: 6| Step: 12
Training loss: 1.0011102354532981
Validation loss: 2.7050026129310276

Epoch: 6| Step: 13
Training loss: 0.8452926238538412
Validation loss: 2.6828048427011755

Epoch: 248| Step: 0
Training loss: 0.6911262117507365
Validation loss: 2.6768069173448263

Epoch: 6| Step: 1
Training loss: 0.6922389474181374
Validation loss: 2.6723384353318704

Epoch: 6| Step: 2
Training loss: 0.7689036022032939
Validation loss: 2.6265180644780752

Epoch: 6| Step: 3
Training loss: 0.8591048076004462
Validation loss: 2.610302185696708

Epoch: 6| Step: 4
Training loss: 0.9860592617289535
Validation loss: 2.59743659803781

Epoch: 6| Step: 5
Training loss: 0.6683839767806369
Validation loss: 2.5776945299802976

Epoch: 6| Step: 6
Training loss: 1.1797493924711084
Validation loss: 2.5310186657412115

Epoch: 6| Step: 7
Training loss: 0.8779184852029668
Validation loss: 2.5182217592772917

Epoch: 6| Step: 8
Training loss: 0.7086766944126739
Validation loss: 2.614520551451267

Epoch: 6| Step: 9
Training loss: 1.0107870635606855
Validation loss: 2.600393747003928

Epoch: 6| Step: 10
Training loss: 1.0742427199030247
Validation loss: 2.6356187997701133

Epoch: 6| Step: 11
Training loss: 0.844834513739868
Validation loss: 2.6911369148602184

Epoch: 6| Step: 12
Training loss: 0.9643861558111948
Validation loss: 2.7257557968495436

Epoch: 6| Step: 13
Training loss: 0.96830471633957
Validation loss: 2.7315927121290238

Epoch: 249| Step: 0
Training loss: 0.7747069450790952
Validation loss: 2.7261317531926483

Epoch: 6| Step: 1
Training loss: 0.8819986153200313
Validation loss: 2.7067917865835773

Epoch: 6| Step: 2
Training loss: 1.0313781889802711
Validation loss: 2.7006596140081385

Epoch: 6| Step: 3
Training loss: 0.9175074290668622
Validation loss: 2.6473692211011515

Epoch: 6| Step: 4
Training loss: 0.9267643726305621
Validation loss: 2.6676351867545343

Epoch: 6| Step: 5
Training loss: 0.8912208304105886
Validation loss: 2.6808791034303074

Epoch: 6| Step: 6
Training loss: 0.5465831795428715
Validation loss: 2.6204677898185227

Epoch: 6| Step: 7
Training loss: 0.7129262418863814
Validation loss: 2.6081436982567334

Epoch: 6| Step: 8
Training loss: 0.5996786816829742
Validation loss: 2.619843537359347

Epoch: 6| Step: 9
Training loss: 0.7639182393379068
Validation loss: 2.618747786423252

Epoch: 6| Step: 10
Training loss: 1.0961912975013866
Validation loss: 2.6249164493778743

Epoch: 6| Step: 11
Training loss: 1.0636338186863445
Validation loss: 2.635357015403932

Epoch: 6| Step: 12
Training loss: 0.7554154780638557
Validation loss: 2.6056242058834074

Epoch: 6| Step: 13
Training loss: 0.870592597528242
Validation loss: 2.666739082763161

Epoch: 250| Step: 0
Training loss: 0.6347483940720198
Validation loss: 2.6311267884634755

Epoch: 6| Step: 1
Training loss: 0.6809977694445475
Validation loss: 2.638899394001656

Epoch: 6| Step: 2
Training loss: 0.9999019455520071
Validation loss: 2.6635646839109732

Epoch: 6| Step: 3
Training loss: 0.5603307912280217
Validation loss: 2.6233918117112642

Epoch: 6| Step: 4
Training loss: 0.9030763698803513
Validation loss: 2.6201511530205566

Epoch: 6| Step: 5
Training loss: 1.2117486021593773
Validation loss: 2.6447117755179104

Epoch: 6| Step: 6
Training loss: 1.1672254768127293
Validation loss: 2.652387445735589

Epoch: 6| Step: 7
Training loss: 0.6262339094230642
Validation loss: 2.6481414425202625

Epoch: 6| Step: 8
Training loss: 0.807459233438922
Validation loss: 2.610699804685514

Epoch: 6| Step: 9
Training loss: 0.7480230501927664
Validation loss: 2.638727570820034

Epoch: 6| Step: 10
Training loss: 0.8236943606166118
Validation loss: 2.610158281891821

Epoch: 6| Step: 11
Training loss: 0.6374907698617569
Validation loss: 2.647350709135701

Epoch: 6| Step: 12
Training loss: 0.9776186610539344
Validation loss: 2.6427039505951493

Epoch: 6| Step: 13
Training loss: 0.6137113338729222
Validation loss: 2.642558788325857

Epoch: 251| Step: 0
Training loss: 0.3717390172435293
Validation loss: 2.660274796245262

Epoch: 6| Step: 1
Training loss: 0.6419828028351284
Validation loss: 2.578317867061672

Epoch: 6| Step: 2
Training loss: 0.7805041758580151
Validation loss: 2.614657353721755

Epoch: 6| Step: 3
Training loss: 0.7473865114133563
Validation loss: 2.5904925880816236

Epoch: 6| Step: 4
Training loss: 0.742897376835046
Validation loss: 2.5891985860758577

Epoch: 6| Step: 5
Training loss: 0.8632191769476952
Validation loss: 2.626734791731065

Epoch: 6| Step: 6
Training loss: 1.1783808867927723
Validation loss: 2.6231358066785715

Epoch: 6| Step: 7
Training loss: 0.7481145205676029
Validation loss: 2.6157149355886133

Epoch: 6| Step: 8
Training loss: 0.9083882789150426
Validation loss: 2.5815529962069728

Epoch: 6| Step: 9
Training loss: 0.9758324908202128
Validation loss: 2.5787962675094276

Epoch: 6| Step: 10
Training loss: 0.8025101768585161
Validation loss: 2.580222797311445

Epoch: 6| Step: 11
Training loss: 0.8131652456142016
Validation loss: 2.584043585452396

Epoch: 6| Step: 12
Training loss: 1.0543089575850755
Validation loss: 2.5527889054037303

Epoch: 6| Step: 13
Training loss: 0.7163532349783496
Validation loss: 2.5782396287937703

Epoch: 252| Step: 0
Training loss: 0.947068184008245
Validation loss: 2.6146519188701127

Epoch: 6| Step: 1
Training loss: 0.9979832996641471
Validation loss: 2.6312320659414925

Epoch: 6| Step: 2
Training loss: 0.5328767217598896
Validation loss: 2.6142889201145625

Epoch: 6| Step: 3
Training loss: 0.2305813207330565
Validation loss: 2.5906427864813817

Epoch: 6| Step: 4
Training loss: 1.0157061030943741
Validation loss: 2.6776334917799773

Epoch: 6| Step: 5
Training loss: 1.1841282912194198
Validation loss: 2.6587199319584385

Epoch: 6| Step: 6
Training loss: 0.9683916290439013
Validation loss: 2.6113173823073876

Epoch: 6| Step: 7
Training loss: 0.6201237715724535
Validation loss: 2.65236791574065

Epoch: 6| Step: 8
Training loss: 1.0496943074238738
Validation loss: 2.6069261587954964

Epoch: 6| Step: 9
Training loss: 0.508833401847524
Validation loss: 2.605953637761917

Epoch: 6| Step: 10
Training loss: 0.5954556060357348
Validation loss: 2.61303788971423

Epoch: 6| Step: 11
Training loss: 0.7035707967878442
Validation loss: 2.555360827072195

Epoch: 6| Step: 12
Training loss: 0.8056714606667901
Validation loss: 2.5727143709857425

Epoch: 6| Step: 13
Training loss: 0.9145453718181251
Validation loss: 2.5874526901085275

Epoch: 253| Step: 0
Training loss: 0.9857082118465242
Validation loss: 2.6258462888450036

Epoch: 6| Step: 1
Training loss: 0.8062086819256264
Validation loss: 2.629808716015958

Epoch: 6| Step: 2
Training loss: 0.4411859215631011
Validation loss: 2.643378510260248

Epoch: 6| Step: 3
Training loss: 0.6230148498531864
Validation loss: 2.6823266697403816

Epoch: 6| Step: 4
Training loss: 0.8769685535730422
Validation loss: 2.6472646013508445

Epoch: 6| Step: 5
Training loss: 1.1833458064769589
Validation loss: 2.6586540813540456

Epoch: 6| Step: 6
Training loss: 0.4945995627131768
Validation loss: 2.7069772753636268

Epoch: 6| Step: 7
Training loss: 0.9249460823222331
Validation loss: 2.6252689575370303

Epoch: 6| Step: 8
Training loss: 0.8307452942688812
Validation loss: 2.62044072266202

Epoch: 6| Step: 9
Training loss: 0.7369797552710745
Validation loss: 2.6360317804371878

Epoch: 6| Step: 10
Training loss: 0.9695817391699808
Validation loss: 2.642672732188499

Epoch: 6| Step: 11
Training loss: 0.6776784604447811
Validation loss: 2.6014289835245177

Epoch: 6| Step: 12
Training loss: 0.6281083299313142
Validation loss: 2.6294843065633993

Epoch: 6| Step: 13
Training loss: 1.078471418370749
Validation loss: 2.6685284276593606

Epoch: 254| Step: 0
Training loss: 1.0024189897753917
Validation loss: 2.6716260589572287

Epoch: 6| Step: 1
Training loss: 0.9215494647936167
Validation loss: 2.698697704535452

Epoch: 6| Step: 2
Training loss: 0.8748458658428874
Validation loss: 2.7008249452149617

Epoch: 6| Step: 3
Training loss: 0.7576490402901356
Validation loss: 2.657324306483922

Epoch: 6| Step: 4
Training loss: 0.7482074933633049
Validation loss: 2.6654735736691433

Epoch: 6| Step: 5
Training loss: 0.7472585802399244
Validation loss: 2.6690786106498754

Epoch: 6| Step: 6
Training loss: 0.944840620820163
Validation loss: 2.683837002633654

Epoch: 6| Step: 7
Training loss: 0.8340579141181315
Validation loss: 2.6568033760310725

Epoch: 6| Step: 8
Training loss: 0.6369770204929515
Validation loss: 2.688975972208398

Epoch: 6| Step: 9
Training loss: 0.9255870502736505
Validation loss: 2.64387663936944

Epoch: 6| Step: 10
Training loss: 0.6279740384636854
Validation loss: 2.604646344378952

Epoch: 6| Step: 11
Training loss: 0.46528178501143225
Validation loss: 2.5743770648716278

Epoch: 6| Step: 12
Training loss: 0.7407447846840922
Validation loss: 2.5652051863395604

Epoch: 6| Step: 13
Training loss: 1.112431626951256
Validation loss: 2.5337427824273244

Epoch: 255| Step: 0
Training loss: 0.9836654527872788
Validation loss: 2.5508148804720134

Epoch: 6| Step: 1
Training loss: 0.8356425754407878
Validation loss: 2.5837928040512868

Epoch: 6| Step: 2
Training loss: 0.6293059080246348
Validation loss: 2.578223614936798

Epoch: 6| Step: 3
Training loss: 0.8422767351254755
Validation loss: 2.577548926047154

Epoch: 6| Step: 4
Training loss: 0.8539126801663129
Validation loss: 2.590830259027776

Epoch: 6| Step: 5
Training loss: 0.7078003467585913
Validation loss: 2.632822201224297

Epoch: 6| Step: 6
Training loss: 0.783645276764934
Validation loss: 2.6950477207287533

Epoch: 6| Step: 7
Training loss: 0.5042720915645963
Validation loss: 2.690827997484023

Epoch: 6| Step: 8
Training loss: 0.7841840960044979
Validation loss: 2.6979058324422334

Epoch: 6| Step: 9
Training loss: 0.8359658067135292
Validation loss: 2.671234294872388

Epoch: 6| Step: 10
Training loss: 0.6473445413719531
Validation loss: 2.6674421981101797

Epoch: 6| Step: 11
Training loss: 0.5498891870533349
Validation loss: 2.6381468299666304

Epoch: 6| Step: 12
Training loss: 0.8782567315716421
Validation loss: 2.6160620404750774

Epoch: 6| Step: 13
Training loss: 1.4572286599940087
Validation loss: 2.6030326359375695

Epoch: 256| Step: 0
Training loss: 0.39763734918729227
Validation loss: 2.569438389847959

Epoch: 6| Step: 1
Training loss: 0.7010080470223229
Validation loss: 2.537251878819362

Epoch: 6| Step: 2
Training loss: 0.9106641670135031
Validation loss: 2.5323879530506828

Epoch: 6| Step: 3
Training loss: 0.7601918493483762
Validation loss: 2.5995947738179104

Epoch: 6| Step: 4
Training loss: 0.6788566597582574
Validation loss: 2.6141303676362178

Epoch: 6| Step: 5
Training loss: 0.3768871822887095
Validation loss: 2.64111250617255

Epoch: 6| Step: 6
Training loss: 1.0000218746653822
Validation loss: 2.6318890228296503

Epoch: 6| Step: 7
Training loss: 0.8203556594393941
Validation loss: 2.666438253167321

Epoch: 6| Step: 8
Training loss: 0.8248996182262671
Validation loss: 2.6495054918569334

Epoch: 6| Step: 9
Training loss: 1.0752258573623104
Validation loss: 2.6134793151483766

Epoch: 6| Step: 10
Training loss: 1.1483045228537685
Validation loss: 2.631998553598169

Epoch: 6| Step: 11
Training loss: 0.7955337906044018
Validation loss: 2.598285010202753

Epoch: 6| Step: 12
Training loss: 0.8695203316029607
Validation loss: 2.581054407402603

Epoch: 6| Step: 13
Training loss: 0.7046374901663897
Validation loss: 2.5218386501881462

Epoch: 257| Step: 0
Training loss: 0.9119860547363147
Validation loss: 2.5357133018331797

Epoch: 6| Step: 1
Training loss: 0.7332254299699599
Validation loss: 2.53060062920123

Epoch: 6| Step: 2
Training loss: 0.7917517733420052
Validation loss: 2.5706852119255585

Epoch: 6| Step: 3
Training loss: 0.7804389940303904
Validation loss: 2.584714006191206

Epoch: 6| Step: 4
Training loss: 0.9008201187098512
Validation loss: 2.615179124334439

Epoch: 6| Step: 5
Training loss: 0.6807291664720889
Validation loss: 2.6030180854735896

Epoch: 6| Step: 6
Training loss: 0.9224625347768963
Validation loss: 2.6288328047305365

Epoch: 6| Step: 7
Training loss: 1.0611587361160788
Validation loss: 2.60379425503359

Epoch: 6| Step: 8
Training loss: 0.5490117427702672
Validation loss: 2.631974460902046

Epoch: 6| Step: 9
Training loss: 0.7916962885752409
Validation loss: 2.5656899311782873

Epoch: 6| Step: 10
Training loss: 0.7928610667508407
Validation loss: 2.5754342355080837

Epoch: 6| Step: 11
Training loss: 0.878957348503748
Validation loss: 2.579507567794134

Epoch: 6| Step: 12
Training loss: 0.5081480824763243
Validation loss: 2.607115879456672

Epoch: 6| Step: 13
Training loss: 0.7454784312566065
Validation loss: 2.5924066454270998

Epoch: 258| Step: 0
Training loss: 0.5895203468008079
Validation loss: 2.609833019198596

Epoch: 6| Step: 1
Training loss: 0.9189573767556247
Validation loss: 2.658101985633252

Epoch: 6| Step: 2
Training loss: 1.0962860134564205
Validation loss: 2.659930937148271

Epoch: 6| Step: 3
Training loss: 0.6669777104829875
Validation loss: 2.6782699911765686

Epoch: 6| Step: 4
Training loss: 0.6554807059433196
Validation loss: 2.656373804670842

Epoch: 6| Step: 5
Training loss: 0.4143369952418781
Validation loss: 2.644239401102982

Epoch: 6| Step: 6
Training loss: 0.4903904335905233
Validation loss: 2.635030512348514

Epoch: 6| Step: 7
Training loss: 1.1656672533983021
Validation loss: 2.6262923417553914

Epoch: 6| Step: 8
Training loss: 0.6220676296302037
Validation loss: 2.627970289004491

Epoch: 6| Step: 9
Training loss: 0.6363707217295785
Validation loss: 2.6326669997426895

Epoch: 6| Step: 10
Training loss: 0.83709857202093
Validation loss: 2.5957790675897625

Epoch: 6| Step: 11
Training loss: 0.8652202527549171
Validation loss: 2.6258326009396824

Epoch: 6| Step: 12
Training loss: 0.8862502419023494
Validation loss: 2.582979803939351

Epoch: 6| Step: 13
Training loss: 0.35088966410469197
Validation loss: 2.6154203416420945

Epoch: 259| Step: 0
Training loss: 0.6971209293114616
Validation loss: 2.62276439914001

Epoch: 6| Step: 1
Training loss: 0.8530726210615422
Validation loss: 2.6339131510837683

Epoch: 6| Step: 2
Training loss: 0.643302578668631
Validation loss: 2.6525564458065136

Epoch: 6| Step: 3
Training loss: 0.9316008937208999
Validation loss: 2.6667753519192985

Epoch: 6| Step: 4
Training loss: 0.37515470174766263
Validation loss: 2.5974492936427502

Epoch: 6| Step: 5
Training loss: 0.7613019927987509
Validation loss: 2.5500292164485843

Epoch: 6| Step: 6
Training loss: 0.8335397504425206
Validation loss: 2.5569709882694727

Epoch: 6| Step: 7
Training loss: 0.7573267372822403
Validation loss: 2.5405063882334398

Epoch: 6| Step: 8
Training loss: 0.5882400285481213
Validation loss: 2.5697024191411795

Epoch: 6| Step: 9
Training loss: 0.8690292458480096
Validation loss: 2.6036238168950896

Epoch: 6| Step: 10
Training loss: 0.9576183153364063
Validation loss: 2.6275049515249167

Epoch: 6| Step: 11
Training loss: 0.6814797985024257
Validation loss: 2.6349376408648966

Epoch: 6| Step: 12
Training loss: 0.9645948822670334
Validation loss: 2.623169358804832

Epoch: 6| Step: 13
Training loss: 0.6471838264600529
Validation loss: 2.6606939753892394

Epoch: 260| Step: 0
Training loss: 0.9014752985468186
Validation loss: 2.666247530717888

Epoch: 6| Step: 1
Training loss: 0.4892535485483482
Validation loss: 2.651872136653522

Epoch: 6| Step: 2
Training loss: 0.8942119578267362
Validation loss: 2.6625105669350257

Epoch: 6| Step: 3
Training loss: 0.8614912851682113
Validation loss: 2.653743699865971

Epoch: 6| Step: 4
Training loss: 0.9615141836182513
Validation loss: 2.6133579653869687

Epoch: 6| Step: 5
Training loss: 0.748369909113397
Validation loss: 2.629994377337027

Epoch: 6| Step: 6
Training loss: 0.3132353118739377
Validation loss: 2.629004120526734

Epoch: 6| Step: 7
Training loss: 0.6719957731062922
Validation loss: 2.6400716490297014

Epoch: 6| Step: 8
Training loss: 0.5743502771164525
Validation loss: 2.637044185606917

Epoch: 6| Step: 9
Training loss: 0.8257024346654719
Validation loss: 2.6652793002377053

Epoch: 6| Step: 10
Training loss: 0.5271979236307195
Validation loss: 2.663210281114135

Epoch: 6| Step: 11
Training loss: 0.7974122424257245
Validation loss: 2.6934998758860056

Epoch: 6| Step: 12
Training loss: 0.9917026446465013
Validation loss: 2.697747333581524

Epoch: 6| Step: 13
Training loss: 0.407057326757357
Validation loss: 2.6910983742897607

Epoch: 261| Step: 0
Training loss: 0.6596299053875042
Validation loss: 2.6995610201953104

Epoch: 6| Step: 1
Training loss: 0.5748774584514209
Validation loss: 2.6607076901445237

Epoch: 6| Step: 2
Training loss: 0.27568002469451386
Validation loss: 2.6399920693409227

Epoch: 6| Step: 3
Training loss: 0.8335752175871094
Validation loss: 2.6658653962491243

Epoch: 6| Step: 4
Training loss: 0.8968456595802029
Validation loss: 2.6377977707883637

Epoch: 6| Step: 5
Training loss: 0.8972483519110924
Validation loss: 2.6303059676276073

Epoch: 6| Step: 6
Training loss: 1.0300685588463359
Validation loss: 2.6375480278123984

Epoch: 6| Step: 7
Training loss: 0.7155615532747434
Validation loss: 2.596774511694578

Epoch: 6| Step: 8
Training loss: 0.8539014769034207
Validation loss: 2.6192273382865703

Epoch: 6| Step: 9
Training loss: 0.6718708304342369
Validation loss: 2.6718287108635246

Epoch: 6| Step: 10
Training loss: 0.8557774235095023
Validation loss: 2.6229795619355425

Epoch: 6| Step: 11
Training loss: 0.40348014712507135
Validation loss: 2.6271267472891133

Epoch: 6| Step: 12
Training loss: 0.7416757124088443
Validation loss: 2.5933379908444305

Epoch: 6| Step: 13
Training loss: 0.34262030460364945
Validation loss: 2.647644849743776

Epoch: 262| Step: 0
Training loss: 0.4748975091084493
Validation loss: 2.676722485033296

Epoch: 6| Step: 1
Training loss: 0.6840255899173798
Validation loss: 2.6340906660366112

Epoch: 6| Step: 2
Training loss: 0.8985698436620849
Validation loss: 2.622426587634938

Epoch: 6| Step: 3
Training loss: 0.565428896888615
Validation loss: 2.6341700356931046

Epoch: 6| Step: 4
Training loss: 0.8185930305444301
Validation loss: 2.615364224467117

Epoch: 6| Step: 5
Training loss: 1.0307602152775037
Validation loss: 2.5880191475578216

Epoch: 6| Step: 6
Training loss: 0.7247887566721775
Validation loss: 2.6062695334273935

Epoch: 6| Step: 7
Training loss: 0.5784575047426481
Validation loss: 2.549920539886686

Epoch: 6| Step: 8
Training loss: 0.5695951470426837
Validation loss: 2.5793271779199554

Epoch: 6| Step: 9
Training loss: 0.6370311508945877
Validation loss: 2.60449370236029

Epoch: 6| Step: 10
Training loss: 0.8646205679600802
Validation loss: 2.649578102845008

Epoch: 6| Step: 11
Training loss: 0.9754567409193494
Validation loss: 2.654267899477488

Epoch: 6| Step: 12
Training loss: 0.5206781505825497
Validation loss: 2.7030298682311726

Epoch: 6| Step: 13
Training loss: 0.4349926385859536
Validation loss: 2.700119033439522

Epoch: 263| Step: 0
Training loss: 0.6979925176101935
Validation loss: 2.696523424386139

Epoch: 6| Step: 1
Training loss: 0.4620101860954683
Validation loss: 2.6902371924323614

Epoch: 6| Step: 2
Training loss: 0.5825446252142251
Validation loss: 2.667503445478507

Epoch: 6| Step: 3
Training loss: 0.9116297242829278
Validation loss: 2.624862284937284

Epoch: 6| Step: 4
Training loss: 0.594854031136526
Validation loss: 2.6205316631688613

Epoch: 6| Step: 5
Training loss: 0.5949945456791768
Validation loss: 2.5812099372336825

Epoch: 6| Step: 6
Training loss: 0.8780789699233036
Validation loss: 2.6256597151866186

Epoch: 6| Step: 7
Training loss: 0.7830915490485669
Validation loss: 2.588674620154995

Epoch: 6| Step: 8
Training loss: 0.7726791208737482
Validation loss: 2.5783885673170954

Epoch: 6| Step: 9
Training loss: 0.5405680323227363
Validation loss: 2.6150018103574912

Epoch: 6| Step: 10
Training loss: 0.669637102374826
Validation loss: 2.632441743403348

Epoch: 6| Step: 11
Training loss: 0.9749898530970055
Validation loss: 2.641410974249991

Epoch: 6| Step: 12
Training loss: 0.7000018162363196
Validation loss: 2.674684153247612

Epoch: 6| Step: 13
Training loss: 0.874783216597489
Validation loss: 2.6928053754488763

Epoch: 264| Step: 0
Training loss: 0.7970096250022276
Validation loss: 2.7055995013573484

Epoch: 6| Step: 1
Training loss: 0.9147552734122912
Validation loss: 2.69316367484553

Epoch: 6| Step: 2
Training loss: 0.6853785294548519
Validation loss: 2.6963456651300763

Epoch: 6| Step: 3
Training loss: 0.774752606621709
Validation loss: 2.6856337924289964

Epoch: 6| Step: 4
Training loss: 0.5515127532397451
Validation loss: 2.636448879612893

Epoch: 6| Step: 5
Training loss: 0.6712465452037822
Validation loss: 2.5711037267358376

Epoch: 6| Step: 6
Training loss: 0.691188282203249
Validation loss: 2.5570227569297366

Epoch: 6| Step: 7
Training loss: 0.6804779980597119
Validation loss: 2.6023074857820303

Epoch: 6| Step: 8
Training loss: 0.8918026616915061
Validation loss: 2.635538142090032

Epoch: 6| Step: 9
Training loss: 0.8131319302872713
Validation loss: 2.6702439754001177

Epoch: 6| Step: 10
Training loss: 0.8386084409549582
Validation loss: 2.7139982556958424

Epoch: 6| Step: 11
Training loss: 0.784432300435203
Validation loss: 2.748807514313471

Epoch: 6| Step: 12
Training loss: 0.6420535697408803
Validation loss: 2.731749062370404

Epoch: 6| Step: 13
Training loss: 0.5490497128208578
Validation loss: 2.6516008471312755

Epoch: 265| Step: 0
Training loss: 0.7824315863248029
Validation loss: 2.5819570680805213

Epoch: 6| Step: 1
Training loss: 0.7828466503133288
Validation loss: 2.57415495045632

Epoch: 6| Step: 2
Training loss: 1.1059341259872826
Validation loss: 2.5201608819776635

Epoch: 6| Step: 3
Training loss: 0.7863742244451649
Validation loss: 2.5645607946154914

Epoch: 6| Step: 4
Training loss: 0.46250870799553057
Validation loss: 2.5868221274628267

Epoch: 6| Step: 5
Training loss: 0.8905007794401943
Validation loss: 2.6597989949980296

Epoch: 6| Step: 6
Training loss: 0.7621658186978377
Validation loss: 2.721294037408335

Epoch: 6| Step: 7
Training loss: 0.7519249452537337
Validation loss: 2.7522688015133094

Epoch: 6| Step: 8
Training loss: 0.7229770669980202
Validation loss: 2.8227227114890647

Epoch: 6| Step: 9
Training loss: 0.35212953191988633
Validation loss: 2.7848105513556685

Epoch: 6| Step: 10
Training loss: 0.5975555634300973
Validation loss: 2.7550096477226984

Epoch: 6| Step: 11
Training loss: 0.822985227762816
Validation loss: 2.7145774485837255

Epoch: 6| Step: 12
Training loss: 0.7768289212642624
Validation loss: 2.673662003656619

Epoch: 6| Step: 13
Training loss: 0.4144877643113723
Validation loss: 2.6028952433816435

Epoch: 266| Step: 0
Training loss: 0.903781422639931
Validation loss: 2.5564365115434105

Epoch: 6| Step: 1
Training loss: 0.8131979365553902
Validation loss: 2.6355252223914567

Epoch: 6| Step: 2
Training loss: 0.8445647509173743
Validation loss: 2.687778939673611

Epoch: 6| Step: 3
Training loss: 0.564760856824644
Validation loss: 2.731765022734232

Epoch: 6| Step: 4
Training loss: 0.6689427062491998
Validation loss: 2.7227524454543848

Epoch: 6| Step: 5
Training loss: 0.7703770670419742
Validation loss: 2.76980502779183

Epoch: 6| Step: 6
Training loss: 0.7194251745442578
Validation loss: 2.7475142076647057

Epoch: 6| Step: 7
Training loss: 0.41552994365304624
Validation loss: 2.6914640545120188

Epoch: 6| Step: 8
Training loss: 0.6111569149620143
Validation loss: 2.6736231296799926

Epoch: 6| Step: 9
Training loss: 0.7880696007832754
Validation loss: 2.5959406187542906

Epoch: 6| Step: 10
Training loss: 0.8544579722502509
Validation loss: 2.5066741924799096

Epoch: 6| Step: 11
Training loss: 0.7482656452800517
Validation loss: 2.4923875818215184

Epoch: 6| Step: 12
Training loss: 0.8924213831066241
Validation loss: 2.4675926298313833

Epoch: 6| Step: 13
Training loss: 0.8109181484493346
Validation loss: 2.5197142348631885

Epoch: 267| Step: 0
Training loss: 0.5532607951742168
Validation loss: 2.541587216772697

Epoch: 6| Step: 1
Training loss: 0.5004579711667988
Validation loss: 2.5702778319889528

Epoch: 6| Step: 2
Training loss: 0.8872682658400807
Validation loss: 2.60096445661708

Epoch: 6| Step: 3
Training loss: 0.7815518749663373
Validation loss: 2.641902385258153

Epoch: 6| Step: 4
Training loss: 0.5184629254950046
Validation loss: 2.6762481500069244

Epoch: 6| Step: 5
Training loss: 0.5106784058637546
Validation loss: 2.694358356474749

Epoch: 6| Step: 6
Training loss: 0.7366265215946202
Validation loss: 2.6359883980850896

Epoch: 6| Step: 7
Training loss: 0.582254405413251
Validation loss: 2.6142171147242643

Epoch: 6| Step: 8
Training loss: 0.8595885965023131
Validation loss: 2.599490197332572

Epoch: 6| Step: 9
Training loss: 1.105035326207467
Validation loss: 2.5027689663380066

Epoch: 6| Step: 10
Training loss: 0.691094603049614
Validation loss: 2.4723801025709204

Epoch: 6| Step: 11
Training loss: 0.9190229814808548
Validation loss: 2.4364376082508206

Epoch: 6| Step: 12
Training loss: 0.8901973500739624
Validation loss: 2.427395328194595

Epoch: 6| Step: 13
Training loss: 0.9364406958854364
Validation loss: 2.4245930810556557

Epoch: 268| Step: 0
Training loss: 0.669134917850062
Validation loss: 2.4830073072485455

Epoch: 6| Step: 1
Training loss: 0.5540748490249916
Validation loss: 2.551787533086684

Epoch: 6| Step: 2
Training loss: 0.5961994042512259
Validation loss: 2.576523637429706

Epoch: 6| Step: 3
Training loss: 0.8332316018633414
Validation loss: 2.5784088764039628

Epoch: 6| Step: 4
Training loss: 1.029286509394705
Validation loss: 2.5911634327824706

Epoch: 6| Step: 5
Training loss: 0.813538364659315
Validation loss: 2.5586501784663107

Epoch: 6| Step: 6
Training loss: 0.8294490809295767
Validation loss: 2.553857531106842

Epoch: 6| Step: 7
Training loss: 0.6038026590069513
Validation loss: 2.6107231353134135

Epoch: 6| Step: 8
Training loss: 1.115724793146203
Validation loss: 2.5391904565517662

Epoch: 6| Step: 9
Training loss: 0.7252010181879596
Validation loss: 2.5673510197111775

Epoch: 6| Step: 10
Training loss: 0.6775305933572844
Validation loss: 2.5527772691216692

Epoch: 6| Step: 11
Training loss: 0.5195529904513421
Validation loss: 2.529163857583966

Epoch: 6| Step: 12
Training loss: 0.9320320890411667
Validation loss: 2.5303289666410347

Epoch: 6| Step: 13
Training loss: 0.40888553142716877
Validation loss: 2.5136324318981367

Epoch: 269| Step: 0
Training loss: 0.8106978310342969
Validation loss: 2.5206566025498103

Epoch: 6| Step: 1
Training loss: 0.6753304582120706
Validation loss: 2.544122515750306

Epoch: 6| Step: 2
Training loss: 0.7770833485034876
Validation loss: 2.6252214013177917

Epoch: 6| Step: 3
Training loss: 0.530205176018668
Validation loss: 2.6234326945231436

Epoch: 6| Step: 4
Training loss: 0.9151472843949587
Validation loss: 2.59032133608066

Epoch: 6| Step: 5
Training loss: 1.0066391376074333
Validation loss: 2.64730067054792

Epoch: 6| Step: 6
Training loss: 0.5067781330875373
Validation loss: 2.590523712886853

Epoch: 6| Step: 7
Training loss: 0.7819991525318598
Validation loss: 2.571902041440794

Epoch: 6| Step: 8
Training loss: 0.8269082253168236
Validation loss: 2.5205062207180418

Epoch: 6| Step: 9
Training loss: 0.5966141784968529
Validation loss: 2.4866051297534093

Epoch: 6| Step: 10
Training loss: 0.7427117353435427
Validation loss: 2.4591521944502457

Epoch: 6| Step: 11
Training loss: 0.8716267550237556
Validation loss: 2.5010685493195854

Epoch: 6| Step: 12
Training loss: 0.9273231639039354
Validation loss: 2.5445149827321223

Epoch: 6| Step: 13
Training loss: 0.8002849250282158
Validation loss: 2.586295912707242

Epoch: 270| Step: 0
Training loss: 0.7249533358716523
Validation loss: 2.6790403035797072

Epoch: 6| Step: 1
Training loss: 0.5516509096002422
Validation loss: 2.7440893548029517

Epoch: 6| Step: 2
Training loss: 0.8034123066380036
Validation loss: 2.6890203611662065

Epoch: 6| Step: 3
Training loss: 0.5497973426341797
Validation loss: 2.6592864312638547

Epoch: 6| Step: 4
Training loss: 0.5813963326456928
Validation loss: 2.5641079291618074

Epoch: 6| Step: 5
Training loss: 0.9525030326794983
Validation loss: 2.4699267522526083

Epoch: 6| Step: 6
Training loss: 0.7440833522753764
Validation loss: 2.377766507494871

Epoch: 6| Step: 7
Training loss: 0.9016003539602572
Validation loss: 2.334824244700608

Epoch: 6| Step: 8
Training loss: 0.6035326612716069
Validation loss: 2.3605604240948495

Epoch: 6| Step: 9
Training loss: 0.8216186297639974
Validation loss: 2.4049109328888623

Epoch: 6| Step: 10
Training loss: 0.617293819492829
Validation loss: 2.468408422073339

Epoch: 6| Step: 11
Training loss: 0.6794303977790913
Validation loss: 2.549310656617735

Epoch: 6| Step: 12
Training loss: 0.9052669191588749
Validation loss: 2.6754133888545732

Epoch: 6| Step: 13
Training loss: 1.1830616374915754
Validation loss: 2.725410260975278

Epoch: 271| Step: 0
Training loss: 0.9564906247642163
Validation loss: 2.68830654197487

Epoch: 6| Step: 1
Training loss: 0.5517751235271808
Validation loss: 2.635835032581298

Epoch: 6| Step: 2
Training loss: 0.6527022787041189
Validation loss: 2.5672474964512824

Epoch: 6| Step: 3
Training loss: 0.7139502606150258
Validation loss: 2.4973223302847676

Epoch: 6| Step: 4
Training loss: 0.5891095575210389
Validation loss: 2.459188908575602

Epoch: 6| Step: 5
Training loss: 0.7010900083050522
Validation loss: 2.4313024313450735

Epoch: 6| Step: 6
Training loss: 0.7071440380191163
Validation loss: 2.4459149673659493

Epoch: 6| Step: 7
Training loss: 0.8498620019416139
Validation loss: 2.4592421210880677

Epoch: 6| Step: 8
Training loss: 0.692243317189856
Validation loss: 2.4825600549586433

Epoch: 6| Step: 9
Training loss: 0.7486404971895974
Validation loss: 2.4843380791728817

Epoch: 6| Step: 10
Training loss: 0.601808571957474
Validation loss: 2.484739452667569

Epoch: 6| Step: 11
Training loss: 0.8265369591615833
Validation loss: 2.611424918668008

Epoch: 6| Step: 12
Training loss: 0.8737249621295263
Validation loss: 2.606901853067803

Epoch: 6| Step: 13
Training loss: 0.6973539451419695
Validation loss: 2.5972231282793836

Epoch: 272| Step: 0
Training loss: 0.6794098911958979
Validation loss: 2.5770104866503196

Epoch: 6| Step: 1
Training loss: 0.726725242190416
Validation loss: 2.551300258844933

Epoch: 6| Step: 2
Training loss: 0.9969804594407319
Validation loss: 2.5035303763609207

Epoch: 6| Step: 3
Training loss: 0.7795497703837196
Validation loss: 2.4788141355858957

Epoch: 6| Step: 4
Training loss: 0.4241373893879979
Validation loss: 2.4352614128272454

Epoch: 6| Step: 5
Training loss: 0.3320591297786373
Validation loss: 2.439622941607275

Epoch: 6| Step: 6
Training loss: 0.8528501941350365
Validation loss: 2.4840778264160632

Epoch: 6| Step: 7
Training loss: 0.5510912895093631
Validation loss: 2.475302448688191

Epoch: 6| Step: 8
Training loss: 0.7814070353039703
Validation loss: 2.466008862012355

Epoch: 6| Step: 9
Training loss: 0.8673716856413092
Validation loss: 2.461861671044892

Epoch: 6| Step: 10
Training loss: 0.6592291015188401
Validation loss: 2.5074903891904565

Epoch: 6| Step: 11
Training loss: 0.6386349168635814
Validation loss: 2.463289360115593

Epoch: 6| Step: 12
Training loss: 0.47582730663856637
Validation loss: 2.5017506550795443

Epoch: 6| Step: 13
Training loss: 0.7044867574314877
Validation loss: 2.634590473378444

Epoch: 273| Step: 0
Training loss: 0.729978672395365
Validation loss: 2.612920808017672

Epoch: 6| Step: 1
Training loss: 0.6193590711437317
Validation loss: 2.6263554809464518

Epoch: 6| Step: 2
Training loss: 0.7046529909468199
Validation loss: 2.6448986084108257

Epoch: 6| Step: 3
Training loss: 0.5778013560663104
Validation loss: 2.581812304286533

Epoch: 6| Step: 4
Training loss: 0.4353023578259203
Validation loss: 2.5595342229461577

Epoch: 6| Step: 5
Training loss: 0.6398395282014546
Validation loss: 2.512478826290044

Epoch: 6| Step: 6
Training loss: 0.8531946412331772
Validation loss: 2.534925145299302

Epoch: 6| Step: 7
Training loss: 0.7825629455184917
Validation loss: 2.5118068589731504

Epoch: 6| Step: 8
Training loss: 0.734482087788778
Validation loss: 2.4799347354102688

Epoch: 6| Step: 9
Training loss: 0.5765080392645886
Validation loss: 2.527153642343169

Epoch: 6| Step: 10
Training loss: 0.35895202457746
Validation loss: 2.4523898135301314

Epoch: 6| Step: 11
Training loss: 0.7812710186991907
Validation loss: 2.4885020288894717

Epoch: 6| Step: 12
Training loss: 0.7605828839492961
Validation loss: 2.5490953520892226

Epoch: 6| Step: 13
Training loss: 0.7690485878390948
Validation loss: 2.5377289279244875

Epoch: 274| Step: 0
Training loss: 0.5593695954642458
Validation loss: 2.6009274353393335

Epoch: 6| Step: 1
Training loss: 0.4923734162405148
Validation loss: 2.624427672467253

Epoch: 6| Step: 2
Training loss: 0.5455118629204124
Validation loss: 2.614005771473015

Epoch: 6| Step: 3
Training loss: 0.8260473423522716
Validation loss: 2.626095972224789

Epoch: 6| Step: 4
Training loss: 0.8101994148902033
Validation loss: 2.6104972420011037

Epoch: 6| Step: 5
Training loss: 0.6533994070850832
Validation loss: 2.577658503226055

Epoch: 6| Step: 6
Training loss: 0.6884155246380511
Validation loss: 2.580532012594457

Epoch: 6| Step: 7
Training loss: 0.49716928991780235
Validation loss: 2.582686145373373

Epoch: 6| Step: 8
Training loss: 0.5546627576440759
Validation loss: 2.502285140614189

Epoch: 6| Step: 9
Training loss: 0.8093385813410425
Validation loss: 2.491945403414797

Epoch: 6| Step: 10
Training loss: 0.7662480991209264
Validation loss: 2.4948443148763446

Epoch: 6| Step: 11
Training loss: 0.6904977120175806
Validation loss: 2.524314509291447

Epoch: 6| Step: 12
Training loss: 0.6705614156878698
Validation loss: 2.5505551931175803

Epoch: 6| Step: 13
Training loss: 0.3045582252521838
Validation loss: 2.597910734743313

Epoch: 275| Step: 0
Training loss: 0.5233705961827039
Validation loss: 2.61822072674052

Epoch: 6| Step: 1
Training loss: 0.3527595908106827
Validation loss: 2.6142433254942183

Epoch: 6| Step: 2
Training loss: 0.824378843262385
Validation loss: 2.665586657268121

Epoch: 6| Step: 3
Training loss: 0.5527908781577037
Validation loss: 2.6933200638215835

Epoch: 6| Step: 4
Training loss: 0.5275213437033535
Validation loss: 2.688668818430058

Epoch: 6| Step: 5
Training loss: 0.5226864622133839
Validation loss: 2.6188729596853224

Epoch: 6| Step: 6
Training loss: 0.8031867022134507
Validation loss: 2.581992865568429

Epoch: 6| Step: 7
Training loss: 0.6196768571533169
Validation loss: 2.5631978355094396

Epoch: 6| Step: 8
Training loss: 0.71525407698375
Validation loss: 2.5227466702957417

Epoch: 6| Step: 9
Training loss: 0.8029436641470461
Validation loss: 2.5269442242485

Epoch: 6| Step: 10
Training loss: 0.7606546647893885
Validation loss: 2.493004133430915

Epoch: 6| Step: 11
Training loss: 0.5478661955104878
Validation loss: 2.571117887472981

Epoch: 6| Step: 12
Training loss: 0.8036416303154309
Validation loss: 2.5652841359421585

Epoch: 6| Step: 13
Training loss: 0.27377336855219303
Validation loss: 2.609589321625798

Epoch: 276| Step: 0
Training loss: 0.7970325089911916
Validation loss: 2.629128708949027

Epoch: 6| Step: 1
Training loss: 0.6929305993967708
Validation loss: 2.6526500882563826

Epoch: 6| Step: 2
Training loss: 0.7921064602483797
Validation loss: 2.657455087972039

Epoch: 6| Step: 3
Training loss: 0.40393865075376134
Validation loss: 2.66520012116599

Epoch: 6| Step: 4
Training loss: 0.8682797401007333
Validation loss: 2.6460907768618576

Epoch: 6| Step: 5
Training loss: 0.5991075882636939
Validation loss: 2.6254137136046154

Epoch: 6| Step: 6
Training loss: 0.7278120309673418
Validation loss: 2.6361806270402837

Epoch: 6| Step: 7
Training loss: 0.49399268909982763
Validation loss: 2.617563707534446

Epoch: 6| Step: 8
Training loss: 0.7100657053887607
Validation loss: 2.5603589042687536

Epoch: 6| Step: 9
Training loss: 0.478638925042454
Validation loss: 2.5616568351966484

Epoch: 6| Step: 10
Training loss: 0.284230519366152
Validation loss: 2.5766755107258827

Epoch: 6| Step: 11
Training loss: 0.5103808669426446
Validation loss: 2.5268126048460746

Epoch: 6| Step: 12
Training loss: 0.44729657461704175
Validation loss: 2.5307235707142555

Epoch: 6| Step: 13
Training loss: 0.8280886876044266
Validation loss: 2.5529043153289477

Epoch: 277| Step: 0
Training loss: 0.7268872509462704
Validation loss: 2.592079374764945

Epoch: 6| Step: 1
Training loss: 0.3465928734625623
Validation loss: 2.598524207592252

Epoch: 6| Step: 2
Training loss: 0.5953086672682046
Validation loss: 2.6294229175235335

Epoch: 6| Step: 3
Training loss: 0.5713235958780017
Validation loss: 2.6623947769040543

Epoch: 6| Step: 4
Training loss: 0.6007160324990127
Validation loss: 2.6691235739933075

Epoch: 6| Step: 5
Training loss: 0.6519534376725349
Validation loss: 2.666200593883362

Epoch: 6| Step: 6
Training loss: 0.5542999310506674
Validation loss: 2.6299995572617596

Epoch: 6| Step: 7
Training loss: 0.7468061391457557
Validation loss: 2.6210981068558814

Epoch: 6| Step: 8
Training loss: 0.6882659806496533
Validation loss: 2.5919049240300556

Epoch: 6| Step: 9
Training loss: 0.8482412964958695
Validation loss: 2.543556381007959

Epoch: 6| Step: 10
Training loss: 0.7056693348501533
Validation loss: 2.5266121798015013

Epoch: 6| Step: 11
Training loss: 0.4910267964429823
Validation loss: 2.4797200806932085

Epoch: 6| Step: 12
Training loss: 0.6391607624048167
Validation loss: 2.472924645384211

Epoch: 6| Step: 13
Training loss: 0.39195866842989896
Validation loss: 2.4927672099840468

Epoch: 278| Step: 0
Training loss: 0.49571957331694066
Validation loss: 2.5610231915621284

Epoch: 6| Step: 1
Training loss: 0.4901136272407825
Validation loss: 2.5932799989696114

Epoch: 6| Step: 2
Training loss: 0.877910677456866
Validation loss: 2.585145228733409

Epoch: 6| Step: 3
Training loss: 0.71243631178657
Validation loss: 2.598816894530265

Epoch: 6| Step: 4
Training loss: 0.6956279553387458
Validation loss: 2.6390161041772604

Epoch: 6| Step: 5
Training loss: 0.4539112307460735
Validation loss: 2.578880831194391

Epoch: 6| Step: 6
Training loss: 0.8774449386058558
Validation loss: 2.587650905348335

Epoch: 6| Step: 7
Training loss: 0.4242876787195239
Validation loss: 2.58320690670002

Epoch: 6| Step: 8
Training loss: 0.6041788450745627
Validation loss: 2.583001655009735

Epoch: 6| Step: 9
Training loss: 0.666843179839182
Validation loss: 2.520112405347973

Epoch: 6| Step: 10
Training loss: 0.4668645450590862
Validation loss: 2.529358395925677

Epoch: 6| Step: 11
Training loss: 0.5551146085213632
Validation loss: 2.519768780895518

Epoch: 6| Step: 12
Training loss: 0.5920531973617887
Validation loss: 2.5093255510569903

Epoch: 6| Step: 13
Training loss: 0.5086912621278022
Validation loss: 2.523366706840828

Epoch: 279| Step: 0
Training loss: 0.20377471525270413
Validation loss: 2.521724676228084

Epoch: 6| Step: 1
Training loss: 0.6616508674256709
Validation loss: 2.525007855429421

Epoch: 6| Step: 2
Training loss: 0.6941047852408243
Validation loss: 2.5716965773213425

Epoch: 6| Step: 3
Training loss: 0.5675690652185917
Validation loss: 2.600297034676286

Epoch: 6| Step: 4
Training loss: 0.7545963350759561
Validation loss: 2.625587291717653

Epoch: 6| Step: 5
Training loss: 0.4225831798914773
Validation loss: 2.657496801170349

Epoch: 6| Step: 6
Training loss: 0.3519802472569403
Validation loss: 2.668000588139777

Epoch: 6| Step: 7
Training loss: 0.4386500501765935
Validation loss: 2.676187095106842

Epoch: 6| Step: 8
Training loss: 0.8197538744412297
Validation loss: 2.6683048829346174

Epoch: 6| Step: 9
Training loss: 0.8378541311572982
Validation loss: 2.687946625877117

Epoch: 6| Step: 10
Training loss: 0.549835800455985
Validation loss: 2.666719059916547

Epoch: 6| Step: 11
Training loss: 0.5486566133045467
Validation loss: 2.6410380433193663

Epoch: 6| Step: 12
Training loss: 0.6495504365151534
Validation loss: 2.6285054005573607

Epoch: 6| Step: 13
Training loss: 0.8204363048315478
Validation loss: 2.5690601263964545

Epoch: 280| Step: 0
Training loss: 0.6413986837519292
Validation loss: 2.546968165589213

Epoch: 6| Step: 1
Training loss: 0.7574626862428686
Validation loss: 2.5006774568958123

Epoch: 6| Step: 2
Training loss: 0.4623113460085438
Validation loss: 2.54842944445562

Epoch: 6| Step: 3
Training loss: 0.699385234256756
Validation loss: 2.529022928443691

Epoch: 6| Step: 4
Training loss: 0.5299376378167746
Validation loss: 2.546883366702709

Epoch: 6| Step: 5
Training loss: 0.4897603634764492
Validation loss: 2.5587449852669315

Epoch: 6| Step: 6
Training loss: 0.7826618026685694
Validation loss: 2.590955632270583

Epoch: 6| Step: 7
Training loss: 0.3781940806945877
Validation loss: 2.6436419081653284

Epoch: 6| Step: 8
Training loss: 0.6475246392352557
Validation loss: 2.651943636870264

Epoch: 6| Step: 9
Training loss: 0.3747364150976619
Validation loss: 2.652180881161234

Epoch: 6| Step: 10
Training loss: 0.6198824941509433
Validation loss: 2.597252786597734

Epoch: 6| Step: 11
Training loss: 0.5882774930431267
Validation loss: 2.595452819260243

Epoch: 6| Step: 12
Training loss: 0.7801483779775946
Validation loss: 2.5734662714494463

Epoch: 6| Step: 13
Training loss: 0.517285908674543
Validation loss: 2.6152351650989907

Epoch: 281| Step: 0
Training loss: 0.5538412811959532
Validation loss: 2.6208953916851447

Epoch: 6| Step: 1
Training loss: 0.7349410614724121
Validation loss: 2.5942977591771794

Epoch: 6| Step: 2
Training loss: 0.7019414477260668
Validation loss: 2.589016133525208

Epoch: 6| Step: 3
Training loss: 0.8610173570874937
Validation loss: 2.605658469534294

Epoch: 6| Step: 4
Training loss: 0.7614172314267442
Validation loss: 2.590361191976663

Epoch: 6| Step: 5
Training loss: 0.46943963501076136
Validation loss: 2.602626307240544

Epoch: 6| Step: 6
Training loss: 0.5112968044728023
Validation loss: 2.601887763998417

Epoch: 6| Step: 7
Training loss: 0.7242760727139345
Validation loss: 2.578005142384096

Epoch: 6| Step: 8
Training loss: 0.6307801943948043
Validation loss: 2.586920787440342

Epoch: 6| Step: 9
Training loss: 0.09066675391716009
Validation loss: 2.610865704988098

Epoch: 6| Step: 10
Training loss: 0.3268163903282607
Validation loss: 2.6145816618799596

Epoch: 6| Step: 11
Training loss: 0.5291254251533817
Validation loss: 2.62863189880109

Epoch: 6| Step: 12
Training loss: 0.42869750329868506
Validation loss: 2.636642760013921

Epoch: 6| Step: 13
Training loss: 0.1781581918844459
Validation loss: 2.613057442881409

Epoch: 282| Step: 0
Training loss: 0.38102915965279405
Validation loss: 2.5999869349051234

Epoch: 6| Step: 1
Training loss: 0.32299189947366563
Validation loss: 2.595969376269493

Epoch: 6| Step: 2
Training loss: 0.6817603238439339
Validation loss: 2.5891305009394916

Epoch: 6| Step: 3
Training loss: 0.7377127017394846
Validation loss: 2.5638660448407236

Epoch: 6| Step: 4
Training loss: 0.3447920221094487
Validation loss: 2.5689405683521858

Epoch: 6| Step: 5
Training loss: 0.6432081108405064
Validation loss: 2.5175044450888566

Epoch: 6| Step: 6
Training loss: 0.9260837044773635
Validation loss: 2.564490723308335

Epoch: 6| Step: 7
Training loss: 0.6574132690954385
Validation loss: 2.539847075829716

Epoch: 6| Step: 8
Training loss: 0.5126757808779621
Validation loss: 2.583339583647038

Epoch: 6| Step: 9
Training loss: 0.4801681632771462
Validation loss: 2.583599478448417

Epoch: 6| Step: 10
Training loss: 0.7232234893697603
Validation loss: 2.615514597162392

Epoch: 6| Step: 11
Training loss: 0.5585999121692861
Validation loss: 2.5757340596845086

Epoch: 6| Step: 12
Training loss: 0.44363920480768665
Validation loss: 2.565161786458489

Epoch: 6| Step: 13
Training loss: 0.32311884898191573
Validation loss: 2.5677884977174408

Epoch: 283| Step: 0
Training loss: 0.471936710692958
Validation loss: 2.5753268423031637

Epoch: 6| Step: 1
Training loss: 0.48591794100340097
Validation loss: 2.5769441592019753

Epoch: 6| Step: 2
Training loss: 0.7179333567067637
Validation loss: 2.650070759832139

Epoch: 6| Step: 3
Training loss: 0.5395695333544942
Validation loss: 2.624988123236458

Epoch: 6| Step: 4
Training loss: 0.6010605836091812
Validation loss: 2.5849217768769353

Epoch: 6| Step: 5
Training loss: 0.6167558536816146
Validation loss: 2.5912248912385643

Epoch: 6| Step: 6
Training loss: 0.6697515821747925
Validation loss: 2.605557258377949

Epoch: 6| Step: 7
Training loss: 0.46721665409432717
Validation loss: 2.57901651201574

Epoch: 6| Step: 8
Training loss: 0.6651131788901326
Validation loss: 2.5761467596424503

Epoch: 6| Step: 9
Training loss: 0.7025168862129053
Validation loss: 2.566106761090439

Epoch: 6| Step: 10
Training loss: 0.5658273040055112
Validation loss: 2.593177410981318

Epoch: 6| Step: 11
Training loss: 0.47576928961492365
Validation loss: 2.6334700322162146

Epoch: 6| Step: 12
Training loss: 0.6173885838770745
Validation loss: 2.6162064652054715

Epoch: 6| Step: 13
Training loss: 0.4047328422802182
Validation loss: 2.618116505499657

Epoch: 284| Step: 0
Training loss: 0.4841805344574581
Validation loss: 2.637378939885016

Epoch: 6| Step: 1
Training loss: 0.5863362290789975
Validation loss: 2.578987867655202

Epoch: 6| Step: 2
Training loss: 0.32481311413264835
Validation loss: 2.6026877796827863

Epoch: 6| Step: 3
Training loss: 0.6906306339914425
Validation loss: 2.5743720583339282

Epoch: 6| Step: 4
Training loss: 0.6777508208728239
Validation loss: 2.520135454599174

Epoch: 6| Step: 5
Training loss: 0.49484322095288014
Validation loss: 2.5727618574725364

Epoch: 6| Step: 6
Training loss: 0.414434445865373
Validation loss: 2.551765960252996

Epoch: 6| Step: 7
Training loss: 0.7694730785089949
Validation loss: 2.582064985770031

Epoch: 6| Step: 8
Training loss: 0.5430774991473915
Validation loss: 2.5841574239317695

Epoch: 6| Step: 9
Training loss: 0.36264575214961803
Validation loss: 2.611392841363528

Epoch: 6| Step: 10
Training loss: 0.666441012478698
Validation loss: 2.6115188766420854

Epoch: 6| Step: 11
Training loss: 0.5613379395966825
Validation loss: 2.602102984081437

Epoch: 6| Step: 12
Training loss: 0.5506785953171084
Validation loss: 2.5763682774489896

Epoch: 6| Step: 13
Training loss: 0.8815881797190229
Validation loss: 2.608572483968963

Epoch: 285| Step: 0
Training loss: 0.4705158035024116
Validation loss: 2.5714845508220474

Epoch: 6| Step: 1
Training loss: 0.8503110596947071
Validation loss: 2.5678006405421057

Epoch: 6| Step: 2
Training loss: 0.34225740197775817
Validation loss: 2.6086511883424723

Epoch: 6| Step: 3
Training loss: 0.6020774371332536
Validation loss: 2.580007432291134

Epoch: 6| Step: 4
Training loss: 0.7546990529947188
Validation loss: 2.5816384983707366

Epoch: 6| Step: 5
Training loss: 0.3792407731937348
Validation loss: 2.5444439830667065

Epoch: 6| Step: 6
Training loss: 0.5083728339789503
Validation loss: 2.574847522446028

Epoch: 6| Step: 7
Training loss: 0.7617348693707082
Validation loss: 2.582642937007965

Epoch: 6| Step: 8
Training loss: 0.6064954113499715
Validation loss: 2.591939898199221

Epoch: 6| Step: 9
Training loss: 0.6130667147215905
Validation loss: 2.602664283449303

Epoch: 6| Step: 10
Training loss: 0.26961148491395587
Validation loss: 2.604685259629948

Epoch: 6| Step: 11
Training loss: 0.653358013621938
Validation loss: 2.6027175490882537

Epoch: 6| Step: 12
Training loss: 0.21969001466063434
Validation loss: 2.592261360518222

Epoch: 6| Step: 13
Training loss: 0.4258393764191476
Validation loss: 2.639648930872262

Epoch: 286| Step: 0
Training loss: 0.5754111747930793
Validation loss: 2.621307440137345

Epoch: 6| Step: 1
Training loss: 0.3585380469380906
Validation loss: 2.644190318742415

Epoch: 6| Step: 2
Training loss: 0.40896526171774356
Validation loss: 2.6250223299474276

Epoch: 6| Step: 3
Training loss: 0.6747991890138119
Validation loss: 2.5995008700644915

Epoch: 6| Step: 4
Training loss: 0.3535370477750446
Validation loss: 2.568577741765333

Epoch: 6| Step: 5
Training loss: 0.5533100271295753
Validation loss: 2.5402362709696655

Epoch: 6| Step: 6
Training loss: 0.7350124271146716
Validation loss: 2.5514527402971154

Epoch: 6| Step: 7
Training loss: 0.4564152013520562
Validation loss: 2.533514496937636

Epoch: 6| Step: 8
Training loss: 0.3890545365464579
Validation loss: 2.5449704371228026

Epoch: 6| Step: 9
Training loss: 0.8117262016593194
Validation loss: 2.5955478640883367

Epoch: 6| Step: 10
Training loss: 0.6664842092656699
Validation loss: 2.569634346197347

Epoch: 6| Step: 11
Training loss: 0.4009598198473686
Validation loss: 2.590958321614833

Epoch: 6| Step: 12
Training loss: 0.6707714243768353
Validation loss: 2.549920773386319

Epoch: 6| Step: 13
Training loss: 0.7332215686362336
Validation loss: 2.607577031578008

Epoch: 287| Step: 0
Training loss: 0.7331659631756825
Validation loss: 2.573232711472862

Epoch: 6| Step: 1
Training loss: 0.537897038750512
Validation loss: 2.609173477169256

Epoch: 6| Step: 2
Training loss: 0.32166389005002877
Validation loss: 2.61922794317096

Epoch: 6| Step: 3
Training loss: 0.25203662050677683
Validation loss: 2.6043164734769486

Epoch: 6| Step: 4
Training loss: 0.4829459490495486
Validation loss: 2.562543126825582

Epoch: 6| Step: 5
Training loss: 0.5830855325751241
Validation loss: 2.625356736873733

Epoch: 6| Step: 6
Training loss: 0.6045686491644946
Validation loss: 2.5899366131585575

Epoch: 6| Step: 7
Training loss: 0.5114609454749297
Validation loss: 2.5939057618809485

Epoch: 6| Step: 8
Training loss: 0.8160994468868453
Validation loss: 2.5615826777394495

Epoch: 6| Step: 9
Training loss: 0.26509131785784296
Validation loss: 2.5773759735170625

Epoch: 6| Step: 10
Training loss: 0.5626512694939523
Validation loss: 2.5495688598934816

Epoch: 6| Step: 11
Training loss: 0.8235497313134414
Validation loss: 2.5619385417095044

Epoch: 6| Step: 12
Training loss: 0.4983695387472875
Validation loss: 2.5899469214032895

Epoch: 6| Step: 13
Training loss: 0.4669911606736264
Validation loss: 2.592296457452506

Epoch: 288| Step: 0
Training loss: 0.667953401801922
Validation loss: 2.594610517993995

Epoch: 6| Step: 1
Training loss: 0.6990975642544223
Validation loss: 2.5957078736065653

Epoch: 6| Step: 2
Training loss: 0.5357828578885911
Validation loss: 2.6215956372028164

Epoch: 6| Step: 3
Training loss: 0.7344318124425749
Validation loss: 2.634467356727497

Epoch: 6| Step: 4
Training loss: 0.33143469007258747
Validation loss: 2.6343329018403647

Epoch: 6| Step: 5
Training loss: 0.6062555430837271
Validation loss: 2.668531260745995

Epoch: 6| Step: 6
Training loss: 0.6216144418469893
Validation loss: 2.658016626406447

Epoch: 6| Step: 7
Training loss: 0.37531029261464793
Validation loss: 2.6396836648247177

Epoch: 6| Step: 8
Training loss: 0.47716221830475497
Validation loss: 2.6027661020482222

Epoch: 6| Step: 9
Training loss: 0.5542547660247616
Validation loss: 2.59673958881882

Epoch: 6| Step: 10
Training loss: 0.627332554737497
Validation loss: 2.5420017421657675

Epoch: 6| Step: 11
Training loss: 0.45744368699058463
Validation loss: 2.556584209336513

Epoch: 6| Step: 12
Training loss: 0.556442118267667
Validation loss: 2.6110461329579753

Epoch: 6| Step: 13
Training loss: 0.3924966034772633
Validation loss: 2.5861460427498724

Epoch: 289| Step: 0
Training loss: 0.6989800242788203
Validation loss: 2.6115729727784633

Epoch: 6| Step: 1
Training loss: 0.40829200324618126
Validation loss: 2.5987771069059784

Epoch: 6| Step: 2
Training loss: 0.2949740382667277
Validation loss: 2.6064256408782893

Epoch: 6| Step: 3
Training loss: 0.5451141619760655
Validation loss: 2.6096154010657

Epoch: 6| Step: 4
Training loss: 0.46533896410041564
Validation loss: 2.59608265822671

Epoch: 6| Step: 5
Training loss: 0.8223890633251062
Validation loss: 2.613725040330132

Epoch: 6| Step: 6
Training loss: 0.5918926249682505
Validation loss: 2.574930906080638

Epoch: 6| Step: 7
Training loss: 0.37530076363514053
Validation loss: 2.533740094073625

Epoch: 6| Step: 8
Training loss: 0.4472971742655455
Validation loss: 2.580488471111865

Epoch: 6| Step: 9
Training loss: 0.6932035889028018
Validation loss: 2.532839534389757

Epoch: 6| Step: 10
Training loss: 0.6652825535762311
Validation loss: 2.5442582344437397

Epoch: 6| Step: 11
Training loss: 0.3853669864837223
Validation loss: 2.534909662326858

Epoch: 6| Step: 12
Training loss: 0.5950336133454099
Validation loss: 2.5354020523039855

Epoch: 6| Step: 13
Training loss: 0.42404127254782004
Validation loss: 2.556083733925356

Epoch: 290| Step: 0
Training loss: 0.4139275600870502
Validation loss: 2.5686872665010068

Epoch: 6| Step: 1
Training loss: 0.7429731527332418
Validation loss: 2.6024546637037966

Epoch: 6| Step: 2
Training loss: 0.6247166945184306
Validation loss: 2.6129083043419654

Epoch: 6| Step: 3
Training loss: 0.3352354165147486
Validation loss: 2.6431441567340994

Epoch: 6| Step: 4
Training loss: 0.5077003061627616
Validation loss: 2.6405113590410756

Epoch: 6| Step: 5
Training loss: 0.602212579399921
Validation loss: 2.598676486010432

Epoch: 6| Step: 6
Training loss: 0.4002507407368007
Validation loss: 2.5966624180033695

Epoch: 6| Step: 7
Training loss: 0.5585938833810074
Validation loss: 2.5643734110242757

Epoch: 6| Step: 8
Training loss: 0.6440575448354112
Validation loss: 2.5779369938260674

Epoch: 6| Step: 9
Training loss: 0.555467433364531
Validation loss: 2.5527375404645904

Epoch: 6| Step: 10
Training loss: 0.4195942865108175
Validation loss: 2.558990048538393

Epoch: 6| Step: 11
Training loss: 0.7096356219836764
Validation loss: 2.5929233248227463

Epoch: 6| Step: 12
Training loss: 0.6011772904080882
Validation loss: 2.615173208262155

Epoch: 6| Step: 13
Training loss: 0.438340095744651
Validation loss: 2.6066437947910788

Epoch: 291| Step: 0
Training loss: 0.43677786425296083
Validation loss: 2.628632925766129

Epoch: 6| Step: 1
Training loss: 0.6359986521868549
Validation loss: 2.655688234748597

Epoch: 6| Step: 2
Training loss: 0.5246856668064248
Validation loss: 2.711213327198763

Epoch: 6| Step: 3
Training loss: 0.45177488777159674
Validation loss: 2.674356303042056

Epoch: 6| Step: 4
Training loss: 0.5168107011463646
Validation loss: 2.629589412893668

Epoch: 6| Step: 5
Training loss: 0.44313426751909246
Validation loss: 2.65126660298075

Epoch: 6| Step: 6
Training loss: 0.6831216762493277
Validation loss: 2.6054693698859257

Epoch: 6| Step: 7
Training loss: 0.5362782654504444
Validation loss: 2.5962508937418978

Epoch: 6| Step: 8
Training loss: 0.8720487483008014
Validation loss: 2.589604286387132

Epoch: 6| Step: 9
Training loss: 0.3408790144332498
Validation loss: 2.5944510583756006

Epoch: 6| Step: 10
Training loss: 0.5269911540952071
Validation loss: 2.588187321321465

Epoch: 6| Step: 11
Training loss: 0.5079198870453774
Validation loss: 2.5953671815076627

Epoch: 6| Step: 12
Training loss: 0.6409352179476892
Validation loss: 2.579235601626307

Epoch: 6| Step: 13
Training loss: 0.22298408098718006
Validation loss: 2.5590351118897643

Epoch: 292| Step: 0
Training loss: 0.8287089466266152
Validation loss: 2.5610640179202293

Epoch: 6| Step: 1
Training loss: 0.4778377480382238
Validation loss: 2.558990768844968

Epoch: 6| Step: 2
Training loss: 0.5464578945242017
Validation loss: 2.520390523448367

Epoch: 6| Step: 3
Training loss: 0.5661488178201414
Validation loss: 2.578181401465799

Epoch: 6| Step: 4
Training loss: 0.5041218082186003
Validation loss: 2.5737324833203754

Epoch: 6| Step: 5
Training loss: 0.45757650796149596
Validation loss: 2.5784580894324844

Epoch: 6| Step: 6
Training loss: 0.3816466777091177
Validation loss: 2.590181317479285

Epoch: 6| Step: 7
Training loss: 0.6185221907737082
Validation loss: 2.618306956453607

Epoch: 6| Step: 8
Training loss: 0.6819173693758384
Validation loss: 2.6367559823977937

Epoch: 6| Step: 9
Training loss: 0.4690219408222514
Validation loss: 2.5739150869923035

Epoch: 6| Step: 10
Training loss: 0.32914309140577674
Validation loss: 2.577243264105601

Epoch: 6| Step: 11
Training loss: 0.5474960070947815
Validation loss: 2.634575588286442

Epoch: 6| Step: 12
Training loss: 0.23717806228135657
Validation loss: 2.5990618859940566

Epoch: 6| Step: 13
Training loss: 0.6861910062631367
Validation loss: 2.5462270295296996

Epoch: 293| Step: 0
Training loss: 0.6583541108325303
Validation loss: 2.573715357678773

Epoch: 6| Step: 1
Training loss: 0.5734220414325805
Validation loss: 2.5323597885497997

Epoch: 6| Step: 2
Training loss: 0.12286714642996352
Validation loss: 2.5420223681805694

Epoch: 6| Step: 3
Training loss: 0.5479553450746902
Validation loss: 2.5679278669356154

Epoch: 6| Step: 4
Training loss: 0.37394805228180944
Validation loss: 2.569627158741316

Epoch: 6| Step: 5
Training loss: 0.6801384493187392
Validation loss: 2.553063182730346

Epoch: 6| Step: 6
Training loss: 0.22378906055569628
Validation loss: 2.5789832085427404

Epoch: 6| Step: 7
Training loss: 0.5187470102798529
Validation loss: 2.588354750728862

Epoch: 6| Step: 8
Training loss: 0.54377615197092
Validation loss: 2.6173161011765393

Epoch: 6| Step: 9
Training loss: 0.5247559525150831
Validation loss: 2.551329017114844

Epoch: 6| Step: 10
Training loss: 0.6632047161973408
Validation loss: 2.568086649482937

Epoch: 6| Step: 11
Training loss: 0.6166864848389025
Validation loss: 2.578545022498601

Epoch: 6| Step: 12
Training loss: 0.6165555785187479
Validation loss: 2.575362320333138

Epoch: 6| Step: 13
Training loss: 0.41469766375829015
Validation loss: 2.6127066909899472

Epoch: 294| Step: 0
Training loss: 0.4377045493830089
Validation loss: 2.6037537166548907

Epoch: 6| Step: 1
Training loss: 0.5145753812239828
Validation loss: 2.6027531885966817

Epoch: 6| Step: 2
Training loss: 0.6632272291706875
Validation loss: 2.619145467657243

Epoch: 6| Step: 3
Training loss: 0.4116573476154866
Validation loss: 2.5655588591026017

Epoch: 6| Step: 4
Training loss: 0.42572042048186115
Validation loss: 2.608018093591557

Epoch: 6| Step: 5
Training loss: 0.5745275017701924
Validation loss: 2.5716367516185854

Epoch: 6| Step: 6
Training loss: 0.4163908721202784
Validation loss: 2.5898355319836335

Epoch: 6| Step: 7
Training loss: 0.4961954748433218
Validation loss: 2.574865705893086

Epoch: 6| Step: 8
Training loss: 0.3315167536083672
Validation loss: 2.5722613324380954

Epoch: 6| Step: 9
Training loss: 0.6198377565402343
Validation loss: 2.5291478244138883

Epoch: 6| Step: 10
Training loss: 0.4985119163185124
Validation loss: 2.5642113082337565

Epoch: 6| Step: 11
Training loss: 0.5123362128287071
Validation loss: 2.6293155005615176

Epoch: 6| Step: 12
Training loss: 0.6524965940949278
Validation loss: 2.617544666959149

Epoch: 6| Step: 13
Training loss: 0.7282703385582253
Validation loss: 2.608175307349455

Epoch: 295| Step: 0
Training loss: 0.42487659065058814
Validation loss: 2.5914064809387973

Epoch: 6| Step: 1
Training loss: 0.5072791306228088
Validation loss: 2.61124287240622

Epoch: 6| Step: 2
Training loss: 0.31974048246307063
Validation loss: 2.61153776874584

Epoch: 6| Step: 3
Training loss: 0.7598727035575613
Validation loss: 2.6249262076190574

Epoch: 6| Step: 4
Training loss: 0.5355176053719425
Validation loss: 2.5965333769102577

Epoch: 6| Step: 5
Training loss: 0.4788515896742015
Validation loss: 2.624475464807272

Epoch: 6| Step: 6
Training loss: 0.3619108913260053
Validation loss: 2.5763299111381577

Epoch: 6| Step: 7
Training loss: 0.4761197738370652
Validation loss: 2.5470657151404286

Epoch: 6| Step: 8
Training loss: 0.16957228423270393
Validation loss: 2.550843527632144

Epoch: 6| Step: 9
Training loss: 0.49531411312093304
Validation loss: 2.5781690209074477

Epoch: 6| Step: 10
Training loss: 0.23338046463594433
Validation loss: 2.555155389337086

Epoch: 6| Step: 11
Training loss: 0.9065560777680629
Validation loss: 2.5578391203400024

Epoch: 6| Step: 12
Training loss: 0.550483569060238
Validation loss: 2.607468833621852

Epoch: 6| Step: 13
Training loss: 0.5910270140181493
Validation loss: 2.585820888557696

Epoch: 296| Step: 0
Training loss: 0.5240598366657747
Validation loss: 2.5833836655438907

Epoch: 6| Step: 1
Training loss: 0.5896737314708157
Validation loss: 2.641177785630563

Epoch: 6| Step: 2
Training loss: 0.3899255976253703
Validation loss: 2.5837594996330577

Epoch: 6| Step: 3
Training loss: 0.3222435914801455
Validation loss: 2.613270554086175

Epoch: 6| Step: 4
Training loss: 0.3467448535975956
Validation loss: 2.619413671308166

Epoch: 6| Step: 5
Training loss: 0.2147645804448153
Validation loss: 2.628455130976221

Epoch: 6| Step: 6
Training loss: 0.734800256199966
Validation loss: 2.6009864769306774

Epoch: 6| Step: 7
Training loss: 1.0020723922565749
Validation loss: 2.560454749168725

Epoch: 6| Step: 8
Training loss: 0.3897395015609243
Validation loss: 2.5699265663413358

Epoch: 6| Step: 9
Training loss: 0.3631932962244255
Validation loss: 2.532755809097187

Epoch: 6| Step: 10
Training loss: 0.3456534549354229
Validation loss: 2.5137570324167893

Epoch: 6| Step: 11
Training loss: 0.35601157357926533
Validation loss: 2.523084045747728

Epoch: 6| Step: 12
Training loss: 0.6287901397997291
Validation loss: 2.5691939290482755

Epoch: 6| Step: 13
Training loss: 0.16689572141344622
Validation loss: 2.545935704140523

Epoch: 297| Step: 0
Training loss: 0.6431881637992395
Validation loss: 2.5792968642257983

Epoch: 6| Step: 1
Training loss: 0.5201468011989653
Validation loss: 2.5502162119645777

Epoch: 6| Step: 2
Training loss: 0.6245981354981516
Validation loss: 2.586109123585942

Epoch: 6| Step: 3
Training loss: 0.4459260428225957
Validation loss: 2.533891593077387

Epoch: 6| Step: 4
Training loss: 0.2640474823061492
Validation loss: 2.5764498282785557

Epoch: 6| Step: 5
Training loss: 0.21183186356392017
Validation loss: 2.5982060796349016

Epoch: 6| Step: 6
Training loss: 0.46290567429942664
Validation loss: 2.584894770914979

Epoch: 6| Step: 7
Training loss: 0.5597290293303544
Validation loss: 2.554512171696466

Epoch: 6| Step: 8
Training loss: 0.6370088817270682
Validation loss: 2.6042821508253162

Epoch: 6| Step: 9
Training loss: 0.5937830514241583
Validation loss: 2.601134638308067

Epoch: 6| Step: 10
Training loss: 0.6515529430612456
Validation loss: 2.626390822144177

Epoch: 6| Step: 11
Training loss: 0.15234197102021516
Validation loss: 2.607330942313892

Epoch: 6| Step: 12
Training loss: 0.623760639665637
Validation loss: 2.627604861659642

Epoch: 6| Step: 13
Training loss: 0.27727647422100765
Validation loss: 2.608759394257504

Epoch: 298| Step: 0
Training loss: 0.5949457575812762
Validation loss: 2.602589774538579

Epoch: 6| Step: 1
Training loss: 0.47393905334942504
Validation loss: 2.6249646371470337

Epoch: 6| Step: 2
Training loss: 0.6801459640682125
Validation loss: 2.609519533503527

Epoch: 6| Step: 3
Training loss: 0.5199570309326936
Validation loss: 2.6178667955296167

Epoch: 6| Step: 4
Training loss: 0.5902550633741238
Validation loss: 2.5609311519386635

Epoch: 6| Step: 5
Training loss: 0.223015946416811
Validation loss: 2.5707335915277287

Epoch: 6| Step: 6
Training loss: 0.46370530365503665
Validation loss: 2.567322729499806

Epoch: 6| Step: 7
Training loss: 0.46582782987210924
Validation loss: 2.5521670235896954

Epoch: 6| Step: 8
Training loss: 0.6636656529054638
Validation loss: 2.5481928879493707

Epoch: 6| Step: 9
Training loss: 0.35383039760554647
Validation loss: 2.6256138874328303

Epoch: 6| Step: 10
Training loss: 0.5746958819841689
Validation loss: 2.5798406327466474

Epoch: 6| Step: 11
Training loss: 0.36064795320211146
Validation loss: 2.6122115856068198

Epoch: 6| Step: 12
Training loss: 0.5800577025238243
Validation loss: 2.6101178639626377

Epoch: 6| Step: 13
Training loss: 0.4717966096703279
Validation loss: 2.5783604926692343

Epoch: 299| Step: 0
Training loss: 0.5775578784425417
Validation loss: 2.57564839037965

Epoch: 6| Step: 1
Training loss: 0.6255162729377107
Validation loss: 2.5523829528909006

Epoch: 6| Step: 2
Training loss: 0.42384932504536965
Validation loss: 2.5431888614165015

Epoch: 6| Step: 3
Training loss: 0.4059176185678718
Validation loss: 2.529310876533022

Epoch: 6| Step: 4
Training loss: 0.7654852447632523
Validation loss: 2.5211327426766554

Epoch: 6| Step: 5
Training loss: 0.4264182653862468
Validation loss: 2.522755095679577

Epoch: 6| Step: 6
Training loss: 0.39749001061585254
Validation loss: 2.574547504411624

Epoch: 6| Step: 7
Training loss: 0.36354889803291685
Validation loss: 2.5232903247663536

Epoch: 6| Step: 8
Training loss: 0.5768902712750333
Validation loss: 2.5708413840265374

Epoch: 6| Step: 9
Training loss: 0.41207704824058816
Validation loss: 2.5521345088633596

Epoch: 6| Step: 10
Training loss: 0.5116789125267291
Validation loss: 2.5817009789686107

Epoch: 6| Step: 11
Training loss: 0.5803752870133804
Validation loss: 2.61618081893769

Epoch: 6| Step: 12
Training loss: 0.49254324333479205
Validation loss: 2.6113610326579164

Epoch: 6| Step: 13
Training loss: 0.20366513440472225
Validation loss: 2.571570112602717

Epoch: 300| Step: 0
Training loss: 0.33863811830673496
Validation loss: 2.597795007148433

Epoch: 6| Step: 1
Training loss: 0.5296959305263946
Validation loss: 2.6004776340026

Epoch: 6| Step: 2
Training loss: 0.5897104226303133
Validation loss: 2.5902093372450627

Epoch: 6| Step: 3
Training loss: 0.41128156784320113
Validation loss: 2.630467737824839

Epoch: 6| Step: 4
Training loss: 0.4118897996596601
Validation loss: 2.61571023114397

Epoch: 6| Step: 5
Training loss: 0.40881227371799755
Validation loss: 2.614879550356217

Epoch: 6| Step: 6
Training loss: 0.4016950618565723
Validation loss: 2.605042236474162

Epoch: 6| Step: 7
Training loss: 0.6530028799411188
Validation loss: 2.6322602960336607

Epoch: 6| Step: 8
Training loss: 0.6175316925255727
Validation loss: 2.6338839795452365

Epoch: 6| Step: 9
Training loss: 0.4879837045078961
Validation loss: 2.6416285671401813

Epoch: 6| Step: 10
Training loss: 0.42193733743769857
Validation loss: 2.581186415327566

Epoch: 6| Step: 11
Training loss: 0.5305812778140506
Validation loss: 2.6041756598204513

Epoch: 6| Step: 12
Training loss: 0.4674837015493228
Validation loss: 2.602891817831568

Epoch: 6| Step: 13
Training loss: 0.6818560940143371
Validation loss: 2.6117174023139387

Epoch: 301| Step: 0
Training loss: 0.5143036239160346
Validation loss: 2.602137605423023

Epoch: 6| Step: 1
Training loss: 0.6859838066024864
Validation loss: 2.5726431296470755

Epoch: 6| Step: 2
Training loss: 0.4866695813958313
Validation loss: 2.5725283715636746

Epoch: 6| Step: 3
Training loss: 0.4946580673011839
Validation loss: 2.606204946581061

Epoch: 6| Step: 4
Training loss: 0.4835302308108265
Validation loss: 2.618461954142767

Epoch: 6| Step: 5
Training loss: 0.5513342658013496
Validation loss: 2.624285496685499

Epoch: 6| Step: 6
Training loss: 0.3480647826377641
Validation loss: 2.5978810355821547

Epoch: 6| Step: 7
Training loss: 0.6945076903047187
Validation loss: 2.5883611054598434

Epoch: 6| Step: 8
Training loss: 0.3843246876733149
Validation loss: 2.6357746036027976

Epoch: 6| Step: 9
Training loss: 0.43170938764009625
Validation loss: 2.6079420802799316

Epoch: 6| Step: 10
Training loss: 0.6160547992681283
Validation loss: 2.563211945907799

Epoch: 6| Step: 11
Training loss: 0.404130044323359
Validation loss: 2.6241566142573

Epoch: 6| Step: 12
Training loss: 0.486163682214214
Validation loss: 2.563413563694011

Epoch: 6| Step: 13
Training loss: 0.15409695675231902
Validation loss: 2.631003646146431

Epoch: 302| Step: 0
Training loss: 0.48975963326599947
Validation loss: 2.6124127636766836

Epoch: 6| Step: 1
Training loss: 0.3967342998376414
Validation loss: 2.6506936240334635

Epoch: 6| Step: 2
Training loss: 0.4080672882250208
Validation loss: 2.622639633501871

Epoch: 6| Step: 3
Training loss: 0.4523430193432324
Validation loss: 2.6119290318235038

Epoch: 6| Step: 4
Training loss: 0.3300128736838683
Validation loss: 2.57975020259229

Epoch: 6| Step: 5
Training loss: 0.5560077214613947
Validation loss: 2.52463061180094

Epoch: 6| Step: 6
Training loss: 0.43412507640817083
Validation loss: 2.5070274048499024

Epoch: 6| Step: 7
Training loss: 0.36616167881603695
Validation loss: 2.5102138216927137

Epoch: 6| Step: 8
Training loss: 0.5596336874765764
Validation loss: 2.513684486789504

Epoch: 6| Step: 9
Training loss: 0.5766409823131398
Validation loss: 2.532918687156174

Epoch: 6| Step: 10
Training loss: 0.5316855384303493
Validation loss: 2.5745283846841613

Epoch: 6| Step: 11
Training loss: 0.35680091573299405
Validation loss: 2.5917993043178646

Epoch: 6| Step: 12
Training loss: 0.528986090039138
Validation loss: 2.61392579248797

Epoch: 6| Step: 13
Training loss: 1.0517924948581778
Validation loss: 2.6076523388349244

Epoch: 303| Step: 0
Training loss: 0.5991447462715391
Validation loss: 2.635573463261628

Epoch: 6| Step: 1
Training loss: 0.45611499983869236
Validation loss: 2.6406265271405647

Epoch: 6| Step: 2
Training loss: 0.7096506566268989
Validation loss: 2.618058906791597

Epoch: 6| Step: 3
Training loss: 0.464567454954831
Validation loss: 2.620053108351522

Epoch: 6| Step: 4
Training loss: 0.4103551110064734
Validation loss: 2.623633031221649

Epoch: 6| Step: 5
Training loss: 0.5233961629914219
Validation loss: 2.5711468448507944

Epoch: 6| Step: 6
Training loss: 0.5078148768442723
Validation loss: 2.5801120929798858

Epoch: 6| Step: 7
Training loss: 0.45891284791114806
Validation loss: 2.5436948339470806

Epoch: 6| Step: 8
Training loss: 0.6411448672111993
Validation loss: 2.5722805308082806

Epoch: 6| Step: 9
Training loss: 0.4370904606467447
Validation loss: 2.578952198937809

Epoch: 6| Step: 10
Training loss: 0.33404908473570766
Validation loss: 2.5705782695597774

Epoch: 6| Step: 11
Training loss: 0.23985267181453074
Validation loss: 2.57234598039682

Epoch: 6| Step: 12
Training loss: 0.5178516744691363
Validation loss: 2.5913711285833574

Epoch: 6| Step: 13
Training loss: 0.33684533565398234
Validation loss: 2.599408547806925

Epoch: 304| Step: 0
Training loss: 0.5057599769057003
Validation loss: 2.6091157635712925

Epoch: 6| Step: 1
Training loss: 0.6678553256278963
Validation loss: 2.584607997897738

Epoch: 6| Step: 2
Training loss: 0.6537479660265119
Validation loss: 2.6127303657641647

Epoch: 6| Step: 3
Training loss: 0.36211661832575054
Validation loss: 2.555561258572134

Epoch: 6| Step: 4
Training loss: 0.4563436307592823
Validation loss: 2.5655020050127906

Epoch: 6| Step: 5
Training loss: 0.3185920099395185
Validation loss: 2.5340570391104906

Epoch: 6| Step: 6
Training loss: 0.5298750981220317
Validation loss: 2.522034525593097

Epoch: 6| Step: 7
Training loss: 0.44030829403928085
Validation loss: 2.545487939197609

Epoch: 6| Step: 8
Training loss: 0.4805926031496729
Validation loss: 2.5216098166819783

Epoch: 6| Step: 9
Training loss: 0.3069301865983613
Validation loss: 2.5195099799442895

Epoch: 6| Step: 10
Training loss: 0.5709108062249956
Validation loss: 2.546280464934398

Epoch: 6| Step: 11
Training loss: 0.20501182937800796
Validation loss: 2.5322772571961645

Epoch: 6| Step: 12
Training loss: 0.37311888793591064
Validation loss: 2.546417583793349

Epoch: 6| Step: 13
Training loss: 0.6537757506322729
Validation loss: 2.570614657828877

Epoch: 305| Step: 0
Training loss: 0.5270652318065138
Validation loss: 2.5396287098399646

Epoch: 6| Step: 1
Training loss: 0.4789334088787587
Validation loss: 2.548914388974998

Epoch: 6| Step: 2
Training loss: 0.35192545063309444
Validation loss: 2.6213818013694308

Epoch: 6| Step: 3
Training loss: 0.5340843882799059
Validation loss: 2.6206005867253452

Epoch: 6| Step: 4
Training loss: 0.5703616447699312
Validation loss: 2.6117394178549773

Epoch: 6| Step: 5
Training loss: 0.37994384275382775
Validation loss: 2.6642176286707415

Epoch: 6| Step: 6
Training loss: 0.38995618785008856
Validation loss: 2.6312409545736726

Epoch: 6| Step: 7
Training loss: 0.40405350883847607
Validation loss: 2.6155862395148612

Epoch: 6| Step: 8
Training loss: 0.6686432316480817
Validation loss: 2.5807265196429734

Epoch: 6| Step: 9
Training loss: 0.3739154350979437
Validation loss: 2.544573238679898

Epoch: 6| Step: 10
Training loss: 0.30890076491059587
Validation loss: 2.557068811402817

Epoch: 6| Step: 11
Training loss: 0.5170936476267666
Validation loss: 2.5391695662296345

Epoch: 6| Step: 12
Training loss: 0.5618027233020428
Validation loss: 2.5683042319055303

Epoch: 6| Step: 13
Training loss: 0.2743148352801058
Validation loss: 2.4962614264612775

Epoch: 306| Step: 0
Training loss: 0.35551167323266264
Validation loss: 2.514637156898372

Epoch: 6| Step: 1
Training loss: 0.4748266217380149
Validation loss: 2.5034659181852206

Epoch: 6| Step: 2
Training loss: 0.5383853806096515
Validation loss: 2.529388391870439

Epoch: 6| Step: 3
Training loss: 0.5282414178236872
Validation loss: 2.564040320593829

Epoch: 6| Step: 4
Training loss: 0.23013324886769773
Validation loss: 2.564524867259033

Epoch: 6| Step: 5
Training loss: 0.4741001615608099
Validation loss: 2.6016362362192753

Epoch: 6| Step: 6
Training loss: 0.4683036745625346
Validation loss: 2.6211255687210735

Epoch: 6| Step: 7
Training loss: 0.5394725069601217
Validation loss: 2.66646388715978

Epoch: 6| Step: 8
Training loss: 0.5660542150470061
Validation loss: 2.6754529612243685

Epoch: 6| Step: 9
Training loss: 0.6781534443879824
Validation loss: 2.6523543869352095

Epoch: 6| Step: 10
Training loss: 0.3287059885560253
Validation loss: 2.68508895415482

Epoch: 6| Step: 11
Training loss: 0.2993799238656155
Validation loss: 2.627768895674055

Epoch: 6| Step: 12
Training loss: 0.5273462931253783
Validation loss: 2.60688016201078

Epoch: 6| Step: 13
Training loss: 0.3856855326707285
Validation loss: 2.57182289626671

Epoch: 307| Step: 0
Training loss: 0.5415111159454387
Validation loss: 2.5618634977867702

Epoch: 6| Step: 1
Training loss: 0.5320336788530966
Validation loss: 2.525967832060705

Epoch: 6| Step: 2
Training loss: 0.3005639071258079
Validation loss: 2.516710097664755

Epoch: 6| Step: 3
Training loss: 0.5941326514517251
Validation loss: 2.5725057792879684

Epoch: 6| Step: 4
Training loss: 0.41050055448515566
Validation loss: 2.557992409650637

Epoch: 6| Step: 5
Training loss: 0.37154036299561743
Validation loss: 2.560722506933641

Epoch: 6| Step: 6
Training loss: 0.4786753796523401
Validation loss: 2.608112699192055

Epoch: 6| Step: 7
Training loss: 0.43897832015994803
Validation loss: 2.6137151515035026

Epoch: 6| Step: 8
Training loss: 0.46875085830609897
Validation loss: 2.618281901593659

Epoch: 6| Step: 9
Training loss: 0.5510252824545752
Validation loss: 2.66107489151138

Epoch: 6| Step: 10
Training loss: 0.34646182669604336
Validation loss: 2.6301026360323236

Epoch: 6| Step: 11
Training loss: 0.6226412609789883
Validation loss: 2.6266399960105753

Epoch: 6| Step: 12
Training loss: 0.29458902536061154
Validation loss: 2.5954400916652123

Epoch: 6| Step: 13
Training loss: 0.5771050606320136
Validation loss: 2.6298110283335334

Epoch: 308| Step: 0
Training loss: 0.17263367492360923
Validation loss: 2.5717170399382896

Epoch: 6| Step: 1
Training loss: 0.644823135405108
Validation loss: 2.581944811619906

Epoch: 6| Step: 2
Training loss: 0.5149716949091641
Validation loss: 2.6094176497893655

Epoch: 6| Step: 3
Training loss: 0.5540057277262852
Validation loss: 2.606452924394181

Epoch: 6| Step: 4
Training loss: 0.2841186457878792
Validation loss: 2.5790241934336042

Epoch: 6| Step: 5
Training loss: 0.46697897132542127
Validation loss: 2.5903326176446733

Epoch: 6| Step: 6
Training loss: 0.5554172390045095
Validation loss: 2.5836866364114695

Epoch: 6| Step: 7
Training loss: 0.3606354543668025
Validation loss: 2.639209580342613

Epoch: 6| Step: 8
Training loss: 0.4696138686931481
Validation loss: 2.650525561391341

Epoch: 6| Step: 9
Training loss: 0.5635194811681772
Validation loss: 2.6583481948467464

Epoch: 6| Step: 10
Training loss: 0.44081939237445333
Validation loss: 2.657173188854037

Epoch: 6| Step: 11
Training loss: 0.3954388593683803
Validation loss: 2.5612447602060544

Epoch: 6| Step: 12
Training loss: 0.342653835112433
Validation loss: 2.6089180510696592

Epoch: 6| Step: 13
Training loss: 0.6309039215327591
Validation loss: 2.6118306068538315

Epoch: 309| Step: 0
Training loss: 0.4448431117780453
Validation loss: 2.5877563317889485

Epoch: 6| Step: 1
Training loss: 0.3543036724140888
Validation loss: 2.5900634683310892

Epoch: 6| Step: 2
Training loss: 0.22896756207093016
Validation loss: 2.5844603903924264

Epoch: 6| Step: 3
Training loss: 0.4203816757568185
Validation loss: 2.5601918589908403

Epoch: 6| Step: 4
Training loss: 0.57124221479257
Validation loss: 2.530994806018535

Epoch: 6| Step: 5
Training loss: 0.5448706271229539
Validation loss: 2.5523556905290796

Epoch: 6| Step: 6
Training loss: 0.24630080701035229
Validation loss: 2.6141305637733785

Epoch: 6| Step: 7
Training loss: 0.6975429207916801
Validation loss: 2.6517374708406014

Epoch: 6| Step: 8
Training loss: 0.5075032099260564
Validation loss: 2.7022802714169214

Epoch: 6| Step: 9
Training loss: 0.5852810042950715
Validation loss: 2.6702106153856664

Epoch: 6| Step: 10
Training loss: 0.5696373692823445
Validation loss: 2.664811331710025

Epoch: 6| Step: 11
Training loss: 0.3066080890086758
Validation loss: 2.611136368776493

Epoch: 6| Step: 12
Training loss: 0.477315994929223
Validation loss: 2.575479617334902

Epoch: 6| Step: 13
Training loss: 0.602938996920621
Validation loss: 2.510842587703041

Epoch: 310| Step: 0
Training loss: 0.4810076691745737
Validation loss: 2.531048535657723

Epoch: 6| Step: 1
Training loss: 0.4275399380148214
Validation loss: 2.5150193061218897

Epoch: 6| Step: 2
Training loss: 0.35735933350751325
Validation loss: 2.5588257592442707

Epoch: 6| Step: 3
Training loss: 0.4310557688192642
Validation loss: 2.554889080063378

Epoch: 6| Step: 4
Training loss: 0.30290758653662886
Validation loss: 2.5869332056418783

Epoch: 6| Step: 5
Training loss: 0.4772351161630174
Validation loss: 2.5931337358092006

Epoch: 6| Step: 6
Training loss: 0.40740022684080673
Validation loss: 2.600031560827749

Epoch: 6| Step: 7
Training loss: 0.6476939890947896
Validation loss: 2.625340986982201

Epoch: 6| Step: 8
Training loss: 0.4139822216305481
Validation loss: 2.6179239910903482

Epoch: 6| Step: 9
Training loss: 0.5518412569126769
Validation loss: 2.6330230873076257

Epoch: 6| Step: 10
Training loss: 0.33170656148589595
Validation loss: 2.5863299942965763

Epoch: 6| Step: 11
Training loss: 0.48390738157313096
Validation loss: 2.5670554254864464

Epoch: 6| Step: 12
Training loss: 0.3739937553878909
Validation loss: 2.542611815011019

Epoch: 6| Step: 13
Training loss: 0.8557142140681635
Validation loss: 2.526291688691173

Epoch: 311| Step: 0
Training loss: 0.38925043492424594
Validation loss: 2.5329210535128346

Epoch: 6| Step: 1
Training loss: 0.7527916926528617
Validation loss: 2.539210970113439

Epoch: 6| Step: 2
Training loss: 0.6455265798451961
Validation loss: 2.529051566999845

Epoch: 6| Step: 3
Training loss: 0.4494276804810814
Validation loss: 2.571325938218883

Epoch: 6| Step: 4
Training loss: 0.4761405390003695
Validation loss: 2.6010926835652923

Epoch: 6| Step: 5
Training loss: 0.3929722453999012
Validation loss: 2.644074770663334

Epoch: 6| Step: 6
Training loss: 0.5553518802759705
Validation loss: 2.622167784594228

Epoch: 6| Step: 7
Training loss: 0.31943036937573205
Validation loss: 2.6554621802752947

Epoch: 6| Step: 8
Training loss: 0.31965940465740056
Validation loss: 2.62555816974252

Epoch: 6| Step: 9
Training loss: 0.38738478516698305
Validation loss: 2.577599915909324

Epoch: 6| Step: 10
Training loss: 0.4192718442663796
Validation loss: 2.53745500161069

Epoch: 6| Step: 11
Training loss: 0.532120104300569
Validation loss: 2.5341464857356377

Epoch: 6| Step: 12
Training loss: 0.5286828170642925
Validation loss: 2.540482778571557

Epoch: 6| Step: 13
Training loss: 0.16976445678224727
Validation loss: 2.5485413580447034

Epoch: 312| Step: 0
Training loss: 0.31640234108853293
Validation loss: 2.586651881246213

Epoch: 6| Step: 1
Training loss: 0.48680379501123583
Validation loss: 2.6330770463894555

Epoch: 6| Step: 2
Training loss: 0.39514697533489707
Validation loss: 2.6514752247410116

Epoch: 6| Step: 3
Training loss: 0.38368505179914614
Validation loss: 2.625291607935516

Epoch: 6| Step: 4
Training loss: 0.36199446401130314
Validation loss: 2.6220791344184784

Epoch: 6| Step: 5
Training loss: 0.6662135571216087
Validation loss: 2.614331572110287

Epoch: 6| Step: 6
Training loss: 0.24031977182406045
Validation loss: 2.601125706423955

Epoch: 6| Step: 7
Training loss: 0.48851634660134036
Validation loss: 2.5661729810341063

Epoch: 6| Step: 8
Training loss: 0.5087584854280626
Validation loss: 2.527216376121054

Epoch: 6| Step: 9
Training loss: 0.5625472843641341
Validation loss: 2.539695588374609

Epoch: 6| Step: 10
Training loss: 0.4849565153193025
Validation loss: 2.5028559297419664

Epoch: 6| Step: 11
Training loss: 0.5594350175253764
Validation loss: 2.5342248197553867

Epoch: 6| Step: 12
Training loss: 0.38983969906095484
Validation loss: 2.5350405033360603

Epoch: 6| Step: 13
Training loss: 0.23393972031245178
Validation loss: 2.5359189912848716

Epoch: 313| Step: 0
Training loss: 0.34249716816726905
Validation loss: 2.5528101803710554

Epoch: 6| Step: 1
Training loss: 0.5255594088785227
Validation loss: 2.546534935499726

Epoch: 6| Step: 2
Training loss: 0.30802060271843507
Validation loss: 2.5721788360196114

Epoch: 6| Step: 3
Training loss: 0.34464098594900167
Validation loss: 2.6060095709716404

Epoch: 6| Step: 4
Training loss: 0.63470050184267
Validation loss: 2.646636965514658

Epoch: 6| Step: 5
Training loss: 0.34743160319106287
Validation loss: 2.637304584499627

Epoch: 6| Step: 6
Training loss: 0.5838359529329569
Validation loss: 2.605750899942158

Epoch: 6| Step: 7
Training loss: 0.6364510330264336
Validation loss: 2.5870505834902557

Epoch: 6| Step: 8
Training loss: 0.25263286538976876
Validation loss: 2.597266632031468

Epoch: 6| Step: 9
Training loss: 0.5241141998138991
Validation loss: 2.5601388971961176

Epoch: 6| Step: 10
Training loss: 0.2881917726758006
Validation loss: 2.5542490332235643

Epoch: 6| Step: 11
Training loss: 0.6602263103078776
Validation loss: 2.5223091224025986

Epoch: 6| Step: 12
Training loss: 0.34440829360143776
Validation loss: 2.5278867342508877

Epoch: 6| Step: 13
Training loss: 0.2133301388947166
Validation loss: 2.5298298840356708

Epoch: 314| Step: 0
Training loss: 0.4200696463400568
Validation loss: 2.5382592401453037

Epoch: 6| Step: 1
Training loss: 0.493997575763592
Validation loss: 2.5724040076970183

Epoch: 6| Step: 2
Training loss: 0.6019020856029264
Validation loss: 2.5750156220916884

Epoch: 6| Step: 3
Training loss: 0.2649191847416842
Validation loss: 2.583132368508348

Epoch: 6| Step: 4
Training loss: 0.5205567929123013
Validation loss: 2.605401362600672

Epoch: 6| Step: 5
Training loss: 0.32977549657662086
Validation loss: 2.600922051636792

Epoch: 6| Step: 6
Training loss: 0.4418357346340088
Validation loss: 2.6118675472024013

Epoch: 6| Step: 7
Training loss: 0.47093592225173087
Validation loss: 2.6641338443365945

Epoch: 6| Step: 8
Training loss: 0.37655897732428456
Validation loss: 2.6240916802340153

Epoch: 6| Step: 9
Training loss: 0.4239083491047379
Validation loss: 2.6339987103716345

Epoch: 6| Step: 10
Training loss: 0.546593920817105
Validation loss: 2.5928919964733375

Epoch: 6| Step: 11
Training loss: 0.2561632492181425
Validation loss: 2.5855701506445885

Epoch: 6| Step: 12
Training loss: 0.4590467856971999
Validation loss: 2.5653636387416934

Epoch: 6| Step: 13
Training loss: 0.4581878243287666
Validation loss: 2.5236678520428257

Epoch: 315| Step: 0
Training loss: 0.45780187015105633
Validation loss: 2.4847925296693156

Epoch: 6| Step: 1
Training loss: 0.5068440225356915
Validation loss: 2.520300721870571

Epoch: 6| Step: 2
Training loss: 0.4181446168913614
Validation loss: 2.5637976594414487

Epoch: 6| Step: 3
Training loss: 0.28241900050809604
Validation loss: 2.6098191422006134

Epoch: 6| Step: 4
Training loss: 0.5201332218736889
Validation loss: 2.6843349079758303

Epoch: 6| Step: 5
Training loss: 0.17910852657910195
Validation loss: 2.6837224680332805

Epoch: 6| Step: 6
Training loss: 0.7185798111816403
Validation loss: 2.684041345135541

Epoch: 6| Step: 7
Training loss: 0.32960222009098034
Validation loss: 2.685293978748771

Epoch: 6| Step: 8
Training loss: 0.30139958620985924
Validation loss: 2.667870264985128

Epoch: 6| Step: 9
Training loss: 0.5735517507549492
Validation loss: 2.6100377452143495

Epoch: 6| Step: 10
Training loss: 0.3157133120502988
Validation loss: 2.6046119227259226

Epoch: 6| Step: 11
Training loss: 0.40136492280715624
Validation loss: 2.5447635279176044

Epoch: 6| Step: 12
Training loss: 0.5385016135613965
Validation loss: 2.5196407618963783

Epoch: 6| Step: 13
Training loss: 0.5347630525113322
Validation loss: 2.524147570523285

Epoch: 316| Step: 0
Training loss: 0.16177785825204283
Validation loss: 2.5667857525093845

Epoch: 6| Step: 1
Training loss: 0.3546004957460272
Validation loss: 2.601981596389422

Epoch: 6| Step: 2
Training loss: 0.6009652281427824
Validation loss: 2.6561356676119985

Epoch: 6| Step: 3
Training loss: 0.42048823288454756
Validation loss: 2.669187656470262

Epoch: 6| Step: 4
Training loss: 0.3098349177438185
Validation loss: 2.6996417848995224

Epoch: 6| Step: 5
Training loss: 0.44800857406845507
Validation loss: 2.7070216944473384

Epoch: 6| Step: 6
Training loss: 0.5208746099010569
Validation loss: 2.692617597213704

Epoch: 6| Step: 7
Training loss: 0.37796245107649495
Validation loss: 2.6560405400093443

Epoch: 6| Step: 8
Training loss: 0.5652515084517749
Validation loss: 2.677137570082933

Epoch: 6| Step: 9
Training loss: 0.4039578513676544
Validation loss: 2.658346448365708

Epoch: 6| Step: 10
Training loss: 0.42971168796777615
Validation loss: 2.594602300254653

Epoch: 6| Step: 11
Training loss: 0.6060096293697822
Validation loss: 2.547161158441332

Epoch: 6| Step: 12
Training loss: 0.2676002883085628
Validation loss: 2.5292508540684406

Epoch: 6| Step: 13
Training loss: 0.5128011830328895
Validation loss: 2.5238877503083836

Epoch: 317| Step: 0
Training loss: 0.4923094189731357
Validation loss: 2.501190952965742

Epoch: 6| Step: 1
Training loss: 0.49057879260716636
Validation loss: 2.5510279686849033

Epoch: 6| Step: 2
Training loss: 0.4822295882916918
Validation loss: 2.5895510024741273

Epoch: 6| Step: 3
Training loss: 0.47909985124832133
Validation loss: 2.6402575606197654

Epoch: 6| Step: 4
Training loss: 0.35236526601188106
Validation loss: 2.634641990113417

Epoch: 6| Step: 5
Training loss: 0.5875067233654595
Validation loss: 2.6472733446367416

Epoch: 6| Step: 6
Training loss: 0.2966230728948457
Validation loss: 2.6435077220803707

Epoch: 6| Step: 7
Training loss: 0.2865509519257357
Validation loss: 2.6716240160092712

Epoch: 6| Step: 8
Training loss: 0.6103959456519122
Validation loss: 2.635828696989365

Epoch: 6| Step: 9
Training loss: 0.39003522218696157
Validation loss: 2.6130656859740755

Epoch: 6| Step: 10
Training loss: 0.3376212507129431
Validation loss: 2.597609156427574

Epoch: 6| Step: 11
Training loss: 0.43738516935446164
Validation loss: 2.596839388372454

Epoch: 6| Step: 12
Training loss: 0.5160840332058946
Validation loss: 2.6071810956646018

Epoch: 6| Step: 13
Training loss: 0.2785577530853364
Validation loss: 2.609170957912556

Epoch: 318| Step: 0
Training loss: 0.4671826863120628
Validation loss: 2.6376240830810684

Epoch: 6| Step: 1
Training loss: 0.3256994583864133
Validation loss: 2.5973085400029565

Epoch: 6| Step: 2
Training loss: 0.40623083436213014
Validation loss: 2.6390576648837256

Epoch: 6| Step: 3
Training loss: 0.3941094060051709
Validation loss: 2.6208386385462736

Epoch: 6| Step: 4
Training loss: 0.5726967967668344
Validation loss: 2.6030260806553494

Epoch: 6| Step: 5
Training loss: 0.25782161754322824
Validation loss: 2.5796494676179638

Epoch: 6| Step: 6
Training loss: 0.20296956497510374
Validation loss: 2.5775708470274967

Epoch: 6| Step: 7
Training loss: 0.4200863183534815
Validation loss: 2.604215213118046

Epoch: 6| Step: 8
Training loss: 0.5527640830100232
Validation loss: 2.599498397647497

Epoch: 6| Step: 9
Training loss: 0.38824318482385745
Validation loss: 2.5642393318424666

Epoch: 6| Step: 10
Training loss: 0.29954695418157173
Validation loss: 2.6105334587975237

Epoch: 6| Step: 11
Training loss: 0.6156907099786417
Validation loss: 2.6547154094915517

Epoch: 6| Step: 12
Training loss: 0.3537745291694299
Validation loss: 2.6641677606140646

Epoch: 6| Step: 13
Training loss: 0.3668034757075063
Validation loss: 2.6742271476101522

Epoch: 319| Step: 0
Training loss: 0.30246592278493806
Validation loss: 2.668432742691131

Epoch: 6| Step: 1
Training loss: 0.1529657126583966
Validation loss: 2.6650640962308345

Epoch: 6| Step: 2
Training loss: 0.5121438684784138
Validation loss: 2.6684270378764197

Epoch: 6| Step: 3
Training loss: 0.2901245145436194
Validation loss: 2.6242084217918777

Epoch: 6| Step: 4
Training loss: 0.5039837208419715
Validation loss: 2.6101872834894118

Epoch: 6| Step: 5
Training loss: 0.21214405008217327
Validation loss: 2.607509388963815

Epoch: 6| Step: 6
Training loss: 0.31734015544919764
Validation loss: 2.598849508568646

Epoch: 6| Step: 7
Training loss: 0.5456142060915253
Validation loss: 2.602673087420446

Epoch: 6| Step: 8
Training loss: 0.34801542822918285
Validation loss: 2.618762779591345

Epoch: 6| Step: 9
Training loss: 0.4742482070949288
Validation loss: 2.618024986589621

Epoch: 6| Step: 10
Training loss: 0.4576882099259145
Validation loss: 2.628071074016481

Epoch: 6| Step: 11
Training loss: 0.45171726175100674
Validation loss: 2.639293025262087

Epoch: 6| Step: 12
Training loss: 0.4968921064635022
Validation loss: 2.657811163918785

Epoch: 6| Step: 13
Training loss: 0.43862396005728443
Validation loss: 2.6748519679010934

Epoch: 320| Step: 0
Training loss: 0.3989424404368477
Validation loss: 2.6510091600279218

Epoch: 6| Step: 1
Training loss: 0.3216785169162077
Validation loss: 2.665610660635157

Epoch: 6| Step: 2
Training loss: 0.38510670527036867
Validation loss: 2.6134386650871604

Epoch: 6| Step: 3
Training loss: 0.4876726401134418
Validation loss: 2.5886101469262037

Epoch: 6| Step: 4
Training loss: 0.2419605422245672
Validation loss: 2.6283429462979817

Epoch: 6| Step: 5
Training loss: 0.547997657485466
Validation loss: 2.5510370181909297

Epoch: 6| Step: 6
Training loss: 0.3527709008418064
Validation loss: 2.6125869126544767

Epoch: 6| Step: 7
Training loss: 0.335494703293674
Validation loss: 2.5916974668634825

Epoch: 6| Step: 8
Training loss: 0.5609430116260465
Validation loss: 2.603892523989726

Epoch: 6| Step: 9
Training loss: 0.40312121559555003
Validation loss: 2.6127523085009816

Epoch: 6| Step: 10
Training loss: 0.3493799703650506
Validation loss: 2.617876360689389

Epoch: 6| Step: 11
Training loss: 0.5182558624701511
Validation loss: 2.5860341991505034

Epoch: 6| Step: 12
Training loss: 0.3213591455705552
Validation loss: 2.6264141978703672

Epoch: 6| Step: 13
Training loss: 0.2700833319398487
Validation loss: 2.631434335054441

Epoch: 321| Step: 0
Training loss: 0.6353892388182701
Validation loss: 2.627386786478601

Epoch: 6| Step: 1
Training loss: 0.3827169844131193
Validation loss: 2.637622514352134

Epoch: 6| Step: 2
Training loss: 0.34945321458098577
Validation loss: 2.6067742614897296

Epoch: 6| Step: 3
Training loss: 0.36188007160118174
Validation loss: 2.583426987547772

Epoch: 6| Step: 4
Training loss: 0.4181798241543253
Validation loss: 2.602532902952159

Epoch: 6| Step: 5
Training loss: 0.382403992652699
Validation loss: 2.5843405200768927

Epoch: 6| Step: 6
Training loss: 0.24268521419129485
Validation loss: 2.6093724848677597

Epoch: 6| Step: 7
Training loss: 0.47314585399147535
Validation loss: 2.599114326893497

Epoch: 6| Step: 8
Training loss: 0.1827588781145471
Validation loss: 2.5859227532154443

Epoch: 6| Step: 9
Training loss: 0.6201456378808266
Validation loss: 2.5793228126268297

Epoch: 6| Step: 10
Training loss: 0.2645050448637839
Validation loss: 2.6096692105151784

Epoch: 6| Step: 11
Training loss: 0.30453739381232536
Validation loss: 2.5844582368805527

Epoch: 6| Step: 12
Training loss: 0.40302247140840225
Validation loss: 2.5947124169851867

Epoch: 6| Step: 13
Training loss: 0.3946250766189786
Validation loss: 2.5534647290429495

Epoch: 322| Step: 0
Training loss: 0.5988990229114097
Validation loss: 2.562938525606146

Epoch: 6| Step: 1
Training loss: 0.45945397560989215
Validation loss: 2.544861824832474

Epoch: 6| Step: 2
Training loss: 0.1776410371277513
Validation loss: 2.5249737005042903

Epoch: 6| Step: 3
Training loss: 0.2182033725386109
Validation loss: 2.5828973069392216

Epoch: 6| Step: 4
Training loss: 0.40476450390007945
Validation loss: 2.5791978768336596

Epoch: 6| Step: 5
Training loss: 0.27402816735751395
Validation loss: 2.5869704351142775

Epoch: 6| Step: 6
Training loss: 0.2658087571636493
Validation loss: 2.5976996566917054

Epoch: 6| Step: 7
Training loss: 0.39907389661128234
Validation loss: 2.609025178317027

Epoch: 6| Step: 8
Training loss: 0.3650342423563184
Validation loss: 2.6211492124449567

Epoch: 6| Step: 9
Training loss: 0.34595473879735855
Validation loss: 2.6427570310317585

Epoch: 6| Step: 10
Training loss: 0.15328877726085494
Validation loss: 2.615070413511915

Epoch: 6| Step: 11
Training loss: 0.5329635976398627
Validation loss: 2.6424276052598525

Epoch: 6| Step: 12
Training loss: 0.6498909253522426
Validation loss: 2.6206425373079725

Epoch: 6| Step: 13
Training loss: 0.29819523729701525
Validation loss: 2.6445091579750066

Epoch: 323| Step: 0
Training loss: 0.4397936709472918
Validation loss: 2.680077740503349

Epoch: 6| Step: 1
Training loss: 0.3432595048076052
Validation loss: 2.624442192146875

Epoch: 6| Step: 2
Training loss: 0.47832363714742643
Validation loss: 2.6086684890310856

Epoch: 6| Step: 3
Training loss: 0.27497995476925646
Validation loss: 2.567496852497991

Epoch: 6| Step: 4
Training loss: 0.2836022557015558
Validation loss: 2.5319746816548943

Epoch: 6| Step: 5
Training loss: 0.44243838737992647
Validation loss: 2.5164469000030336

Epoch: 6| Step: 6
Training loss: 0.5334372093946295
Validation loss: 2.589819071125374

Epoch: 6| Step: 7
Training loss: 0.4953759925893946
Validation loss: 2.5683032676594384

Epoch: 6| Step: 8
Training loss: 0.3120625772351949
Validation loss: 2.632374039984086

Epoch: 6| Step: 9
Training loss: 0.45153493434097997
Validation loss: 2.614160934454458

Epoch: 6| Step: 10
Training loss: 0.6282192292394966
Validation loss: 2.7133231082191567

Epoch: 6| Step: 11
Training loss: 0.20909301215836812
Validation loss: 2.6981943654081357

Epoch: 6| Step: 12
Training loss: 0.4809178835045299
Validation loss: 2.665711505499294

Epoch: 6| Step: 13
Training loss: 0.3874558639001894
Validation loss: 2.6510185877162495

Epoch: 324| Step: 0
Training loss: 0.4672741704305133
Validation loss: 2.61300573409982

Epoch: 6| Step: 1
Training loss: 0.30650070059433315
Validation loss: 2.5998534588026474

Epoch: 6| Step: 2
Training loss: 0.27079943145184443
Validation loss: 2.5610022941409594

Epoch: 6| Step: 3
Training loss: 0.556762976333758
Validation loss: 2.522410526249654

Epoch: 6| Step: 4
Training loss: 0.47506944311885124
Validation loss: 2.546732804127299

Epoch: 6| Step: 5
Training loss: 0.6398430913938083
Validation loss: 2.5329381452628077

Epoch: 6| Step: 6
Training loss: 0.32792480356056847
Validation loss: 2.5672446085127807

Epoch: 6| Step: 7
Training loss: 0.5192062967869318
Validation loss: 2.5771078042741276

Epoch: 6| Step: 8
Training loss: 0.2776665488046699
Validation loss: 2.5938234463377126

Epoch: 6| Step: 9
Training loss: 0.41088031254842455
Validation loss: 2.639119887662566

Epoch: 6| Step: 10
Training loss: 0.3086742223767676
Validation loss: 2.584719638883748

Epoch: 6| Step: 11
Training loss: 0.4002413215458813
Validation loss: 2.617500326886051

Epoch: 6| Step: 12
Training loss: 0.23351418246822012
Validation loss: 2.6386662029987717

Epoch: 6| Step: 13
Training loss: 0.32524531212037205
Validation loss: 2.6635903571079362

Epoch: 325| Step: 0
Training loss: 0.5370644013042571
Validation loss: 2.6017443141234233

Epoch: 6| Step: 1
Training loss: 0.31029421046545164
Validation loss: 2.5687831689193987

Epoch: 6| Step: 2
Training loss: 0.27962188217358674
Validation loss: 2.5704894613512037

Epoch: 6| Step: 3
Training loss: 0.3673474998071797
Validation loss: 2.5619571750131125

Epoch: 6| Step: 4
Training loss: 0.3913260844172308
Validation loss: 2.5650102269072077

Epoch: 6| Step: 5
Training loss: 0.481559229251119
Validation loss: 2.5257938997175535

Epoch: 6| Step: 6
Training loss: 0.5827444686250737
Validation loss: 2.535810906240738

Epoch: 6| Step: 7
Training loss: 0.45579261519758846
Validation loss: 2.5368483746062807

Epoch: 6| Step: 8
Training loss: 0.33074924703398423
Validation loss: 2.5282981054482048

Epoch: 6| Step: 9
Training loss: 0.24641541999149563
Validation loss: 2.574829263200809

Epoch: 6| Step: 10
Training loss: 0.4097075960364811
Validation loss: 2.5349839128849205

Epoch: 6| Step: 11
Training loss: 0.3485867766431317
Validation loss: 2.5566702858171575

Epoch: 6| Step: 12
Training loss: 0.3310634758156944
Validation loss: 2.589458045294385

Epoch: 6| Step: 13
Training loss: 0.39325678225256766
Validation loss: 2.617679761845884

Epoch: 326| Step: 0
Training loss: 0.4033856465991822
Validation loss: 2.626651691575018

Epoch: 6| Step: 1
Training loss: 0.4301878703363929
Validation loss: 2.609165749901671

Epoch: 6| Step: 2
Training loss: 0.4737344534444321
Validation loss: 2.6263019216193344

Epoch: 6| Step: 3
Training loss: 0.37396044487033847
Validation loss: 2.649568329446824

Epoch: 6| Step: 4
Training loss: 0.27110238954700383
Validation loss: 2.6302358529425858

Epoch: 6| Step: 5
Training loss: 0.24775717931982946
Validation loss: 2.621837922525052

Epoch: 6| Step: 6
Training loss: 0.5000210697979918
Validation loss: 2.5818930566237603

Epoch: 6| Step: 7
Training loss: 0.3604400030015796
Validation loss: 2.5563635655189167

Epoch: 6| Step: 8
Training loss: 0.5723649287074002
Validation loss: 2.5761961293285562

Epoch: 6| Step: 9
Training loss: 0.5594547012492277
Validation loss: 2.5190336755668605

Epoch: 6| Step: 10
Training loss: 0.35171605041769394
Validation loss: 2.5024787868266007

Epoch: 6| Step: 11
Training loss: 0.25175731650008415
Validation loss: 2.4577381699056997

Epoch: 6| Step: 12
Training loss: 0.39939055805019935
Validation loss: 2.518307470858273

Epoch: 6| Step: 13
Training loss: 0.5108780397586538
Validation loss: 2.5495243863935118

Epoch: 327| Step: 0
Training loss: 0.34351746323323357
Validation loss: 2.6005101564802415

Epoch: 6| Step: 1
Training loss: 0.329082058291808
Validation loss: 2.6187250980249805

Epoch: 6| Step: 2
Training loss: 0.3262633235447034
Validation loss: 2.64315094132176

Epoch: 6| Step: 3
Training loss: 0.39476263229712394
Validation loss: 2.6218293070898424

Epoch: 6| Step: 4
Training loss: 0.2551695573633888
Validation loss: 2.653133872643341

Epoch: 6| Step: 5
Training loss: 0.30213862220095233
Validation loss: 2.6267103335582687

Epoch: 6| Step: 6
Training loss: 0.258338089035211
Validation loss: 2.6042298740386647

Epoch: 6| Step: 7
Training loss: 0.588756342082276
Validation loss: 2.598501890169278

Epoch: 6| Step: 8
Training loss: 0.4550519288999943
Validation loss: 2.555807863894008

Epoch: 6| Step: 9
Training loss: 0.5691253377292166
Validation loss: 2.492519010337061

Epoch: 6| Step: 10
Training loss: 0.36678649432653476
Validation loss: 2.4762223113808877

Epoch: 6| Step: 11
Training loss: 0.44831566634283837
Validation loss: 2.4621531088360853

Epoch: 6| Step: 12
Training loss: 0.4269994230724341
Validation loss: 2.492311074251603

Epoch: 6| Step: 13
Training loss: 0.2688237316434432
Validation loss: 2.5012703344510436

Epoch: 328| Step: 0
Training loss: 0.4515926991168621
Validation loss: 2.505527809485781

Epoch: 6| Step: 1
Training loss: 0.526202202526849
Validation loss: 2.518474585520061

Epoch: 6| Step: 2
Training loss: 0.3659040054902729
Validation loss: 2.5432104258589283

Epoch: 6| Step: 3
Training loss: 0.2655499997562573
Validation loss: 2.563047711183931

Epoch: 6| Step: 4
Training loss: 0.4099581830575996
Validation loss: 2.6096627111981396

Epoch: 6| Step: 5
Training loss: 0.3358975985583438
Validation loss: 2.618257225421199

Epoch: 6| Step: 6
Training loss: 0.4472725213864304
Validation loss: 2.6660930355612686

Epoch: 6| Step: 7
Training loss: 0.5272510023148236
Validation loss: 2.606392605989941

Epoch: 6| Step: 8
Training loss: 0.3145931358683814
Validation loss: 2.595612665743954

Epoch: 6| Step: 9
Training loss: 0.30940341963425566
Validation loss: 2.603298719581289

Epoch: 6| Step: 10
Training loss: 0.3886027442372874
Validation loss: 2.5417255535663843

Epoch: 6| Step: 11
Training loss: 0.2538714164901701
Validation loss: 2.516964141659634

Epoch: 6| Step: 12
Training loss: 0.4394960170582733
Validation loss: 2.5200484272613357

Epoch: 6| Step: 13
Training loss: 0.3957473782857975
Validation loss: 2.4855846242002664

Epoch: 329| Step: 0
Training loss: 0.38721222651533205
Validation loss: 2.509868221006247

Epoch: 6| Step: 1
Training loss: 0.48310730769738724
Validation loss: 2.5084759980681697

Epoch: 6| Step: 2
Training loss: 0.28598050956154186
Validation loss: 2.5774137568053344

Epoch: 6| Step: 3
Training loss: 0.27397825721021435
Validation loss: 2.616908406250378

Epoch: 6| Step: 4
Training loss: 0.3178311629052878
Validation loss: 2.6592191736671302

Epoch: 6| Step: 5
Training loss: 0.42958254832884546
Validation loss: 2.6611146934805374

Epoch: 6| Step: 6
Training loss: 0.5318157325294013
Validation loss: 2.6739517782925364

Epoch: 6| Step: 7
Training loss: 0.5110508585944399
Validation loss: 2.679614686952823

Epoch: 6| Step: 8
Training loss: 0.5763732041161579
Validation loss: 2.6443475691073868

Epoch: 6| Step: 9
Training loss: 0.46094260778668233
Validation loss: 2.636719740757667

Epoch: 6| Step: 10
Training loss: 0.3120928257456499
Validation loss: 2.5958724734294765

Epoch: 6| Step: 11
Training loss: 0.32098905708252934
Validation loss: 2.5406524027072477

Epoch: 6| Step: 12
Training loss: 0.3059817847482321
Validation loss: 2.476883171047178

Epoch: 6| Step: 13
Training loss: 0.48520507751077885
Validation loss: 2.4865565242326766

Epoch: 330| Step: 0
Training loss: 0.5030606293815898
Validation loss: 2.5904314962387422

Epoch: 6| Step: 1
Training loss: 0.2767720710780318
Validation loss: 2.607892402268258

Epoch: 6| Step: 2
Training loss: 0.6549549494239996
Validation loss: 2.6592436818282312

Epoch: 6| Step: 3
Training loss: 0.4666204877410922
Validation loss: 2.702873589587113

Epoch: 6| Step: 4
Training loss: 0.587796986368585
Validation loss: 2.6933838751875503

Epoch: 6| Step: 5
Training loss: 0.3718314217430391
Validation loss: 2.6547719531236877

Epoch: 6| Step: 6
Training loss: 0.4337991451378116
Validation loss: 2.5764552949585413

Epoch: 6| Step: 7
Training loss: 0.41808506425668157
Validation loss: 2.4822958038365694

Epoch: 6| Step: 8
Training loss: 0.5132630320295996
Validation loss: 2.4380305091276546

Epoch: 6| Step: 9
Training loss: 0.38122259573079814
Validation loss: 2.4345743308043972

Epoch: 6| Step: 10
Training loss: 0.2578858213488663
Validation loss: 2.4215524544023035

Epoch: 6| Step: 11
Training loss: 0.43031668980261756
Validation loss: 2.4143066388994874

Epoch: 6| Step: 12
Training loss: 0.47507328547261835
Validation loss: 2.4124937168035054

Epoch: 6| Step: 13
Training loss: 0.29534796698593674
Validation loss: 2.5049583159019626

Epoch: 331| Step: 0
Training loss: 0.2389952951600646
Validation loss: 2.4699976146481055

Epoch: 6| Step: 1
Training loss: 0.350388112479125
Validation loss: 2.482574745537307

Epoch: 6| Step: 2
Training loss: 0.3227789749359309
Validation loss: 2.570098504989746

Epoch: 6| Step: 3
Training loss: 0.3659485143735324
Validation loss: 2.553049618730078

Epoch: 6| Step: 4
Training loss: 0.4100049966123873
Validation loss: 2.549770100601474

Epoch: 6| Step: 5
Training loss: 0.47607072877827367
Validation loss: 2.5546915802464096

Epoch: 6| Step: 6
Training loss: 0.39348501341223824
Validation loss: 2.5704520550102177

Epoch: 6| Step: 7
Training loss: 0.32999131229192186
Validation loss: 2.524534523863637

Epoch: 6| Step: 8
Training loss: 0.37164616877150114
Validation loss: 2.518936496829653

Epoch: 6| Step: 9
Training loss: 0.517960087170088
Validation loss: 2.5128794184906584

Epoch: 6| Step: 10
Training loss: 0.42127520698042886
Validation loss: 2.5264260770341056

Epoch: 6| Step: 11
Training loss: 0.5575487191676194
Validation loss: 2.526425891845852

Epoch: 6| Step: 12
Training loss: 0.1912232127160597
Validation loss: 2.528122806775014

Epoch: 6| Step: 13
Training loss: 0.20233278576223238
Validation loss: 2.5493684359356017

Epoch: 332| Step: 0
Training loss: 0.492058176882909
Validation loss: 2.5313083009476274

Epoch: 6| Step: 1
Training loss: 0.280873496983186
Validation loss: 2.5062039486022565

Epoch: 6| Step: 2
Training loss: 0.2542328860966263
Validation loss: 2.5589994175171222

Epoch: 6| Step: 3
Training loss: 0.30377439467660433
Validation loss: 2.5468701361871395

Epoch: 6| Step: 4
Training loss: 0.4228591213475755
Validation loss: 2.546930999613305

Epoch: 6| Step: 5
Training loss: 0.3556376883685239
Validation loss: 2.606892608059856

Epoch: 6| Step: 6
Training loss: 0.3025913269724418
Validation loss: 2.586168225914762

Epoch: 6| Step: 7
Training loss: 0.4701968592673519
Validation loss: 2.572973957563964

Epoch: 6| Step: 8
Training loss: 0.2556175516018043
Validation loss: 2.6169692473612503

Epoch: 6| Step: 9
Training loss: 0.45566084395022854
Validation loss: 2.597523654906346

Epoch: 6| Step: 10
Training loss: 0.4333532542760446
Validation loss: 2.555133197790519

Epoch: 6| Step: 11
Training loss: 0.3281842359933742
Validation loss: 2.5466806194254135

Epoch: 6| Step: 12
Training loss: 0.5029958440730294
Validation loss: 2.5319504259347725

Epoch: 6| Step: 13
Training loss: 0.26440952398006506
Validation loss: 2.5210403368237997

Epoch: 333| Step: 0
Training loss: 0.46196935213910717
Validation loss: 2.5204246052008537

Epoch: 6| Step: 1
Training loss: 0.24405372598973313
Validation loss: 2.5113481258912698

Epoch: 6| Step: 2
Training loss: 0.4044717603947371
Validation loss: 2.4753461408653004

Epoch: 6| Step: 3
Training loss: 0.3362691484196419
Validation loss: 2.5336182156706255

Epoch: 6| Step: 4
Training loss: 0.22838738910746892
Validation loss: 2.5333270857603867

Epoch: 6| Step: 5
Training loss: 0.2682105894352885
Validation loss: 2.5501110616920624

Epoch: 6| Step: 6
Training loss: 0.19863424385027703
Validation loss: 2.5834140017402247

Epoch: 6| Step: 7
Training loss: 0.4056363790118018
Validation loss: 2.5548200414551876

Epoch: 6| Step: 8
Training loss: 0.33752714021488905
Validation loss: 2.6209149967625702

Epoch: 6| Step: 9
Training loss: 0.4991342977569683
Validation loss: 2.6168317900502376

Epoch: 6| Step: 10
Training loss: 0.40984165297279707
Validation loss: 2.5527581023312003

Epoch: 6| Step: 11
Training loss: 0.5453270393772401
Validation loss: 2.5352846686317245

Epoch: 6| Step: 12
Training loss: 0.3075028222039824
Validation loss: 2.524112753934862

Epoch: 6| Step: 13
Training loss: 0.15056535552956302
Validation loss: 2.492304578508805

Epoch: 334| Step: 0
Training loss: 0.3748632817588118
Validation loss: 2.486237706630515

Epoch: 6| Step: 1
Training loss: 0.4571728935176899
Validation loss: 2.4594856100675657

Epoch: 6| Step: 2
Training loss: 0.4049219284631663
Validation loss: 2.4988849988824136

Epoch: 6| Step: 3
Training loss: 0.39361515006675724
Validation loss: 2.483086143651276

Epoch: 6| Step: 4
Training loss: 0.4379589024177352
Validation loss: 2.5307930412727617

Epoch: 6| Step: 5
Training loss: 0.32865744488128856
Validation loss: 2.523085602372942

Epoch: 6| Step: 6
Training loss: 0.2846262199449425
Validation loss: 2.5639265953017265

Epoch: 6| Step: 7
Training loss: 0.3507612740960811
Validation loss: 2.604533306933054

Epoch: 6| Step: 8
Training loss: 0.32606118431213404
Validation loss: 2.583253955183884

Epoch: 6| Step: 9
Training loss: 0.4868310373263668
Validation loss: 2.6112140896884086

Epoch: 6| Step: 10
Training loss: 0.3314799050760899
Validation loss: 2.570505780203071

Epoch: 6| Step: 11
Training loss: 0.31625027992025057
Validation loss: 2.543570572649841

Epoch: 6| Step: 12
Training loss: 0.22167334358447863
Validation loss: 2.521610060682346

Epoch: 6| Step: 13
Training loss: 0.13472832979153038
Validation loss: 2.5145584216813592

Epoch: 335| Step: 0
Training loss: 0.3657942372085581
Validation loss: 2.5291854255471056

Epoch: 6| Step: 1
Training loss: 0.5415714864981288
Validation loss: 2.5377352387021914

Epoch: 6| Step: 2
Training loss: 0.41882717360872507
Validation loss: 2.554022126184016

Epoch: 6| Step: 3
Training loss: 0.27650910363119396
Validation loss: 2.6032352919860076

Epoch: 6| Step: 4
Training loss: 0.22268773575737374
Validation loss: 2.5883255500640248

Epoch: 6| Step: 5
Training loss: 0.1759844929541391
Validation loss: 2.6162935579445734

Epoch: 6| Step: 6
Training loss: 0.18287528255985774
Validation loss: 2.6035774397846305

Epoch: 6| Step: 7
Training loss: 0.3132262968919924
Validation loss: 2.6245657077663056

Epoch: 6| Step: 8
Training loss: 0.2508159078732003
Validation loss: 2.6288592676543163

Epoch: 6| Step: 9
Training loss: 0.47503998926883345
Validation loss: 2.5957696955626774

Epoch: 6| Step: 10
Training loss: 0.37548044342869247
Validation loss: 2.5722233578531273

Epoch: 6| Step: 11
Training loss: 0.4781415294457782
Validation loss: 2.6497218811277503

Epoch: 6| Step: 12
Training loss: 0.34849419496071676
Validation loss: 2.571921836573982

Epoch: 6| Step: 13
Training loss: 0.32341962018556913
Validation loss: 2.5699586305209006

Epoch: 336| Step: 0
Training loss: 0.1739546818740213
Validation loss: 2.575260306738252

Epoch: 6| Step: 1
Training loss: 0.25105872089712594
Validation loss: 2.5708091588380433

Epoch: 6| Step: 2
Training loss: 0.3356789436712966
Validation loss: 2.5833630085437185

Epoch: 6| Step: 3
Training loss: 0.22958052537992898
Validation loss: 2.5468585996932087

Epoch: 6| Step: 4
Training loss: 0.48693306002565256
Validation loss: 2.55581673899502

Epoch: 6| Step: 5
Training loss: 0.29034423186595076
Validation loss: 2.5978042815721727

Epoch: 6| Step: 6
Training loss: 0.4042800125807276
Validation loss: 2.6013830615088387

Epoch: 6| Step: 7
Training loss: 0.5221943112562062
Validation loss: 2.5524188834203883

Epoch: 6| Step: 8
Training loss: 0.17944016226690576
Validation loss: 2.565397454791158

Epoch: 6| Step: 9
Training loss: 0.4769198531809182
Validation loss: 2.544172982982722

Epoch: 6| Step: 10
Training loss: 0.4539261674040191
Validation loss: 2.558094055582379

Epoch: 6| Step: 11
Training loss: 0.31692386015373875
Validation loss: 2.5574386086972134

Epoch: 6| Step: 12
Training loss: 0.22476756288967917
Validation loss: 2.56816786135428

Epoch: 6| Step: 13
Training loss: 0.23197310261764933
Validation loss: 2.562516089108008

Epoch: 337| Step: 0
Training loss: 0.3690982370411481
Validation loss: 2.5128566924033606

Epoch: 6| Step: 1
Training loss: 0.49739148269534794
Validation loss: 2.5635469780395423

Epoch: 6| Step: 2
Training loss: 0.38537042787198644
Validation loss: 2.5458195654365197

Epoch: 6| Step: 3
Training loss: 0.2878018158121398
Validation loss: 2.5368687545129176

Epoch: 6| Step: 4
Training loss: 0.3831305447748157
Validation loss: 2.559030163996208

Epoch: 6| Step: 5
Training loss: 0.4693646216229284
Validation loss: 2.62460704700357

Epoch: 6| Step: 6
Training loss: 0.25857186469735277
Validation loss: 2.6379789854780302

Epoch: 6| Step: 7
Training loss: 0.3231629680816515
Validation loss: 2.640629143568151

Epoch: 6| Step: 8
Training loss: 0.33670858115575886
Validation loss: 2.6445453064383284

Epoch: 6| Step: 9
Training loss: 0.46714796645370965
Validation loss: 2.6430948872053177

Epoch: 6| Step: 10
Training loss: 0.1708211996743285
Validation loss: 2.5711301815858323

Epoch: 6| Step: 11
Training loss: 0.272330139923127
Validation loss: 2.581418325623842

Epoch: 6| Step: 12
Training loss: 0.2378948236354887
Validation loss: 2.5893946647908677

Epoch: 6| Step: 13
Training loss: 0.26215022375674596
Validation loss: 2.5997527099554354

Epoch: 338| Step: 0
Training loss: 0.24884754775820167
Validation loss: 2.551732847160698

Epoch: 6| Step: 1
Training loss: 0.4503739472185546
Validation loss: 2.5654141353060185

Epoch: 6| Step: 2
Training loss: 0.2704101551478845
Validation loss: 2.5247909597449323

Epoch: 6| Step: 3
Training loss: 0.6272089070998966
Validation loss: 2.557026098553753

Epoch: 6| Step: 4
Training loss: 0.350894271722242
Validation loss: 2.528399152498538

Epoch: 6| Step: 5
Training loss: 0.37965468590621676
Validation loss: 2.5536839699051144

Epoch: 6| Step: 6
Training loss: 0.25900300017942646
Validation loss: 2.558182547512334

Epoch: 6| Step: 7
Training loss: 0.2939837864634969
Validation loss: 2.613139118204582

Epoch: 6| Step: 8
Training loss: 0.19990400193444022
Validation loss: 2.5721160119851687

Epoch: 6| Step: 9
Training loss: 0.22872326864070308
Validation loss: 2.587806691073791

Epoch: 6| Step: 10
Training loss: 0.40987495585700495
Validation loss: 2.5658826373920887

Epoch: 6| Step: 11
Training loss: 0.2952589672755337
Validation loss: 2.574235162227202

Epoch: 6| Step: 12
Training loss: 0.25193861986146554
Validation loss: 2.5780899627184106

Epoch: 6| Step: 13
Training loss: 0.20026017045566882
Validation loss: 2.5803261904580754

Epoch: 339| Step: 0
Training loss: 0.5141320143892869
Validation loss: 2.5324337590506047

Epoch: 6| Step: 1
Training loss: 0.40197236781496637
Validation loss: 2.552724259948512

Epoch: 6| Step: 2
Training loss: 0.31775617499845543
Validation loss: 2.5978644046535897

Epoch: 6| Step: 3
Training loss: 0.24723472703485427
Validation loss: 2.523016757367877

Epoch: 6| Step: 4
Training loss: 0.29156125525303905
Validation loss: 2.5445049307209078

Epoch: 6| Step: 5
Training loss: 0.5600205984755007
Validation loss: 2.548461145354795

Epoch: 6| Step: 6
Training loss: 0.29618977220174464
Validation loss: 2.527078178189562

Epoch: 6| Step: 7
Training loss: 0.26743226356844724
Validation loss: 2.527112982327407

Epoch: 6| Step: 8
Training loss: 0.20348701861753596
Validation loss: 2.555611026935282

Epoch: 6| Step: 9
Training loss: 0.40772306696656757
Validation loss: 2.5048895857313473

Epoch: 6| Step: 10
Training loss: 0.22774370347771075
Validation loss: 2.5315631109177743

Epoch: 6| Step: 11
Training loss: 0.39712275708975714
Validation loss: 2.603504602422011

Epoch: 6| Step: 12
Training loss: 0.2574815649081456
Validation loss: 2.567641976096104

Epoch: 6| Step: 13
Training loss: 0.22228460917997533
Validation loss: 2.6019045130632694

Epoch: 340| Step: 0
Training loss: 0.19543178730304944
Validation loss: 2.59816613637677

Epoch: 6| Step: 1
Training loss: 0.4364053792702374
Validation loss: 2.618410438739153

Epoch: 6| Step: 2
Training loss: 0.4416193827323941
Validation loss: 2.6205215036046847

Epoch: 6| Step: 3
Training loss: 0.40248392496528496
Validation loss: 2.60623061428974

Epoch: 6| Step: 4
Training loss: 0.33295041929328295
Validation loss: 2.6056989831989377

Epoch: 6| Step: 5
Training loss: 0.38470996899530624
Validation loss: 2.615276127385561

Epoch: 6| Step: 6
Training loss: 0.21533064722840364
Validation loss: 2.5958051433154137

Epoch: 6| Step: 7
Training loss: 0.31115863929927673
Validation loss: 2.5599892794637116

Epoch: 6| Step: 8
Training loss: 0.38680231751997224
Validation loss: 2.5490615008042816

Epoch: 6| Step: 9
Training loss: 0.24980996777260595
Validation loss: 2.585178424561836

Epoch: 6| Step: 10
Training loss: 0.2499215405251166
Validation loss: 2.60140209571285

Epoch: 6| Step: 11
Training loss: 0.4642749479900477
Validation loss: 2.551353492538695

Epoch: 6| Step: 12
Training loss: 0.2189815691993761
Validation loss: 2.592478832417501

Epoch: 6| Step: 13
Training loss: 0.19164212931910718
Validation loss: 2.636057103255653

Epoch: 341| Step: 0
Training loss: 0.2274967530825802
Validation loss: 2.651964157952272

Epoch: 6| Step: 1
Training loss: 0.3682730030403689
Validation loss: 2.6178691213331353

Epoch: 6| Step: 2
Training loss: 0.45592818864461526
Validation loss: 2.6210387871691863

Epoch: 6| Step: 3
Training loss: 0.4616196321061189
Validation loss: 2.593500186826285

Epoch: 6| Step: 4
Training loss: 0.35855647872010266
Validation loss: 2.573428808758548

Epoch: 6| Step: 5
Training loss: 0.2271136781267125
Validation loss: 2.5387044381846477

Epoch: 6| Step: 6
Training loss: 0.19723543559298984
Validation loss: 2.5198824465480776

Epoch: 6| Step: 7
Training loss: 0.33020712233520894
Validation loss: 2.500084418235383

Epoch: 6| Step: 8
Training loss: 0.30746453751404845
Validation loss: 2.4680266830966517

Epoch: 6| Step: 9
Training loss: 0.4419989868126558
Validation loss: 2.503774245823932

Epoch: 6| Step: 10
Training loss: 0.41890287740133053
Validation loss: 2.4622163719700967

Epoch: 6| Step: 11
Training loss: 0.2593683345351868
Validation loss: 2.56617503850093

Epoch: 6| Step: 12
Training loss: 0.3912330853520071
Validation loss: 2.574504009091111

Epoch: 6| Step: 13
Training loss: 0.24958594873429335
Validation loss: 2.6133153632274233

Epoch: 342| Step: 0
Training loss: 0.3514342073960989
Validation loss: 2.5986161992077736

Epoch: 6| Step: 1
Training loss: 0.2766249704658296
Validation loss: 2.601325213013192

Epoch: 6| Step: 2
Training loss: 0.38928408306799983
Validation loss: 2.641821780169431

Epoch: 6| Step: 3
Training loss: 0.3102419213611829
Validation loss: 2.5984278380851125

Epoch: 6| Step: 4
Training loss: 0.48332344783616005
Validation loss: 2.6088591683432796

Epoch: 6| Step: 5
Training loss: 0.3046807752992001
Validation loss: 2.634164071762384

Epoch: 6| Step: 6
Training loss: 0.24563251141718098
Validation loss: 2.5856845296887445

Epoch: 6| Step: 7
Training loss: 0.46792017281776443
Validation loss: 2.5499125870624146

Epoch: 6| Step: 8
Training loss: 0.22288362705330975
Validation loss: 2.546517899773517

Epoch: 6| Step: 9
Training loss: 0.339378531790634
Validation loss: 2.5376466408970577

Epoch: 6| Step: 10
Training loss: 0.18634585969924727
Validation loss: 2.516180337020495

Epoch: 6| Step: 11
Training loss: 0.2020996329691639
Validation loss: 2.5350788508565456

Epoch: 6| Step: 12
Training loss: 0.39117134034775664
Validation loss: 2.5140040051431485

Epoch: 6| Step: 13
Training loss: 0.4137861121112192
Validation loss: 2.5588805545719744

Epoch: 343| Step: 0
Training loss: 0.4442786882010976
Validation loss: 2.5401629924372386

Epoch: 6| Step: 1
Training loss: 0.3222842124433657
Validation loss: 2.5650411851812307

Epoch: 6| Step: 2
Training loss: 0.28542310169140345
Validation loss: 2.5880135265041293

Epoch: 6| Step: 3
Training loss: 0.4891353309197407
Validation loss: 2.5581475387382904

Epoch: 6| Step: 4
Training loss: 0.4264898266210644
Validation loss: 2.5922368218527505

Epoch: 6| Step: 5
Training loss: 0.2615625570153615
Validation loss: 2.590768643770368

Epoch: 6| Step: 6
Training loss: 0.3437683577403994
Validation loss: 2.5916227732325976

Epoch: 6| Step: 7
Training loss: 0.3708113750464489
Validation loss: 2.606772840891114

Epoch: 6| Step: 8
Training loss: 0.1804271278439288
Validation loss: 2.58116392018757

Epoch: 6| Step: 9
Training loss: 0.28160598531280023
Validation loss: 2.5918127881775823

Epoch: 6| Step: 10
Training loss: 0.2800240420552691
Validation loss: 2.600330101652503

Epoch: 6| Step: 11
Training loss: 0.24128992123456414
Validation loss: 2.5906643067240145

Epoch: 6| Step: 12
Training loss: 0.2205012081431034
Validation loss: 2.600743410281751

Epoch: 6| Step: 13
Training loss: 0.13132049676819918
Validation loss: 2.6031262251700342

Epoch: 344| Step: 0
Training loss: 0.38579236440612297
Validation loss: 2.597246276938272

Epoch: 6| Step: 1
Training loss: 0.3131070677824881
Validation loss: 2.616702182410659

Epoch: 6| Step: 2
Training loss: 0.17704466205843697
Validation loss: 2.5953916495841995

Epoch: 6| Step: 3
Training loss: 0.328046539553575
Validation loss: 2.661273799554712

Epoch: 6| Step: 4
Training loss: 0.23767131380222195
Validation loss: 2.6219347960654487

Epoch: 6| Step: 5
Training loss: 0.35720368276066694
Validation loss: 2.6531681488771075

Epoch: 6| Step: 6
Training loss: 0.523846622968229
Validation loss: 2.615016591678974

Epoch: 6| Step: 7
Training loss: 0.3148485386865273
Validation loss: 2.6004268137362065

Epoch: 6| Step: 8
Training loss: 0.23440780410078513
Validation loss: 2.586966022268529

Epoch: 6| Step: 9
Training loss: 0.22417323019269905
Validation loss: 2.5966033422663872

Epoch: 6| Step: 10
Training loss: 0.17182168892391617
Validation loss: 2.5190748435530574

Epoch: 6| Step: 11
Training loss: 0.38537827721562434
Validation loss: 2.582476360301516

Epoch: 6| Step: 12
Training loss: 0.42656560274889077
Validation loss: 2.5477461511201898

Epoch: 6| Step: 13
Training loss: 0.49875700943306867
Validation loss: 2.5494858991813554

Epoch: 345| Step: 0
Training loss: 0.27830770363605706
Validation loss: 2.5618657143223333

Epoch: 6| Step: 1
Training loss: 0.24856847453544642
Validation loss: 2.542720966022317

Epoch: 6| Step: 2
Training loss: 0.3057941367192577
Validation loss: 2.5286876881614844

Epoch: 6| Step: 3
Training loss: 0.5129362866078337
Validation loss: 2.5330727679872074

Epoch: 6| Step: 4
Training loss: 0.460188483386768
Validation loss: 2.527970788133281

Epoch: 6| Step: 5
Training loss: 0.2024167441008969
Validation loss: 2.5164304755955857

Epoch: 6| Step: 6
Training loss: 0.3048457688304349
Validation loss: 2.5127693374745106

Epoch: 6| Step: 7
Training loss: 0.2998914313559165
Validation loss: 2.5384093893042015

Epoch: 6| Step: 8
Training loss: 0.31491150233514575
Validation loss: 2.5567088654219683

Epoch: 6| Step: 9
Training loss: 0.36460318057215685
Validation loss: 2.5640096516918263

Epoch: 6| Step: 10
Training loss: 0.4030759130947269
Validation loss: 2.5515871276705835

Epoch: 6| Step: 11
Training loss: 0.28778005622138136
Validation loss: 2.5716409385559116

Epoch: 6| Step: 12
Training loss: 0.25747334684927786
Validation loss: 2.523154081755106

Epoch: 6| Step: 13
Training loss: 0.4231107767438925
Validation loss: 2.5463998858338206

Epoch: 346| Step: 0
Training loss: 0.28270232546800855
Validation loss: 2.524426093560469

Epoch: 6| Step: 1
Training loss: 0.4617111373247971
Validation loss: 2.542642863000906

Epoch: 6| Step: 2
Training loss: 0.1934278155107261
Validation loss: 2.4916583222785103

Epoch: 6| Step: 3
Training loss: 0.40685134177270904
Validation loss: 2.504149464508962

Epoch: 6| Step: 4
Training loss: 0.4666118334872871
Validation loss: 2.482206100461081

Epoch: 6| Step: 5
Training loss: 0.4074892253562924
Validation loss: 2.526205910579362

Epoch: 6| Step: 6
Training loss: 0.3927716968863913
Validation loss: 2.5204866966422794

Epoch: 6| Step: 7
Training loss: 0.3598530119591393
Validation loss: 2.543730160554019

Epoch: 6| Step: 8
Training loss: 0.14360442564986275
Validation loss: 2.569858896371929

Epoch: 6| Step: 9
Training loss: 0.20344089739609825
Validation loss: 2.5684866695362554

Epoch: 6| Step: 10
Training loss: 0.22720508049601557
Validation loss: 2.552652248802618

Epoch: 6| Step: 11
Training loss: 0.15318204026587845
Validation loss: 2.570530135366959

Epoch: 6| Step: 12
Training loss: 0.3738969633843766
Validation loss: 2.551651471388946

Epoch: 6| Step: 13
Training loss: 0.20892815413014165
Validation loss: 2.57080956819336

Epoch: 347| Step: 0
Training loss: 0.4599214929728463
Validation loss: 2.551997957356481

Epoch: 6| Step: 1
Training loss: 0.3966996684223748
Validation loss: 2.5592103166543057

Epoch: 6| Step: 2
Training loss: 0.19782614624718667
Validation loss: 2.5624849172448916

Epoch: 6| Step: 3
Training loss: 0.3519237146145293
Validation loss: 2.554163756403431

Epoch: 6| Step: 4
Training loss: 0.2702409412504947
Validation loss: 2.5027573013349698

Epoch: 6| Step: 5
Training loss: 0.41636224195665955
Validation loss: 2.4817889739217396

Epoch: 6| Step: 6
Training loss: 0.3650246492319255
Validation loss: 2.4831321291924953

Epoch: 6| Step: 7
Training loss: 0.4364545797704045
Validation loss: 2.481733698497627

Epoch: 6| Step: 8
Training loss: 0.469094340687876
Validation loss: 2.529195460395356

Epoch: 6| Step: 9
Training loss: 0.2305199517740136
Validation loss: 2.526132104792049

Epoch: 6| Step: 10
Training loss: 0.3754711172003067
Validation loss: 2.518882538346975

Epoch: 6| Step: 11
Training loss: 0.21436633036907943
Validation loss: 2.5144823542019576

Epoch: 6| Step: 12
Training loss: 0.17120267218400823
Validation loss: 2.5659060588021796

Epoch: 6| Step: 13
Training loss: 0.3284818434611144
Validation loss: 2.5479624792197946

Epoch: 348| Step: 0
Training loss: 0.35643389957916577
Validation loss: 2.5494888625413665

Epoch: 6| Step: 1
Training loss: 0.48000924692585156
Validation loss: 2.563000411307966

Epoch: 6| Step: 2
Training loss: 0.33661130487536617
Validation loss: 2.5167199622285295

Epoch: 6| Step: 3
Training loss: 0.18801283242557856
Validation loss: 2.515113066644572

Epoch: 6| Step: 4
Training loss: 0.20567154177898309
Validation loss: 2.500565218865655

Epoch: 6| Step: 5
Training loss: 0.2014637283686329
Validation loss: 2.5120343525296374

Epoch: 6| Step: 6
Training loss: 0.38505196929658886
Validation loss: 2.519379682688745

Epoch: 6| Step: 7
Training loss: 0.4028337698234263
Validation loss: 2.5029375394338294

Epoch: 6| Step: 8
Training loss: 0.22624672061429782
Validation loss: 2.5080229022744147

Epoch: 6| Step: 9
Training loss: 0.25452163654717
Validation loss: 2.5125348344156433

Epoch: 6| Step: 10
Training loss: 0.34140784876468727
Validation loss: 2.5272302687831423

Epoch: 6| Step: 11
Training loss: 0.3219635212105368
Validation loss: 2.557918324355068

Epoch: 6| Step: 12
Training loss: 0.24314472780381358
Validation loss: 2.546576004198587

Epoch: 6| Step: 13
Training loss: 0.45880865426290685
Validation loss: 2.5371038841692046

Epoch: 349| Step: 0
Training loss: 0.2731704770511562
Validation loss: 2.553804181966187

Epoch: 6| Step: 1
Training loss: 0.4199444254653144
Validation loss: 2.541160162518827

Epoch: 6| Step: 2
Training loss: 0.15742937477175029
Validation loss: 2.55711213710098

Epoch: 6| Step: 3
Training loss: 0.3209096529318925
Validation loss: 2.5242432857361004

Epoch: 6| Step: 4
Training loss: 0.20436033244389593
Validation loss: 2.555858922386169

Epoch: 6| Step: 5
Training loss: 0.30438070256650496
Validation loss: 2.5786227315392636

Epoch: 6| Step: 6
Training loss: 0.2991231446876169
Validation loss: 2.544716309796925

Epoch: 6| Step: 7
Training loss: 0.31663210778554574
Validation loss: 2.5771627858584614

Epoch: 6| Step: 8
Training loss: 0.24362231358103428
Validation loss: 2.547912883432923

Epoch: 6| Step: 9
Training loss: 0.3446965731363019
Validation loss: 2.5716326105314873

Epoch: 6| Step: 10
Training loss: 0.39948438104693745
Validation loss: 2.5593166041301676

Epoch: 6| Step: 11
Training loss: 0.31334047542499555
Validation loss: 2.588289422674728

Epoch: 6| Step: 12
Training loss: 0.44838961501771624
Validation loss: 2.5483026389273644

Epoch: 6| Step: 13
Training loss: 0.1958721820279258
Validation loss: 2.524022533774121

Epoch: 350| Step: 0
Training loss: 0.27590410235639873
Validation loss: 2.5264068873999346

Epoch: 6| Step: 1
Training loss: 0.22783147662210138
Validation loss: 2.527219188388769

Epoch: 6| Step: 2
Training loss: 0.3600525895092209
Validation loss: 2.5399869007541187

Epoch: 6| Step: 3
Training loss: 0.30524762337967737
Validation loss: 2.5440809308086436

Epoch: 6| Step: 4
Training loss: 0.22737028550434554
Validation loss: 2.558432691875377

Epoch: 6| Step: 5
Training loss: 0.5046411227243793
Validation loss: 2.5723435720736227

Epoch: 6| Step: 6
Training loss: 0.39521349092991453
Validation loss: 2.547981180017864

Epoch: 6| Step: 7
Training loss: 0.18141808772665857
Validation loss: 2.5467149583680784

Epoch: 6| Step: 8
Training loss: 0.3365608686019759
Validation loss: 2.5443792414612676

Epoch: 6| Step: 9
Training loss: 0.29898088577263954
Validation loss: 2.5647699600076255

Epoch: 6| Step: 10
Training loss: 0.2358067333285741
Validation loss: 2.5670631401987793

Epoch: 6| Step: 11
Training loss: 0.3134296655483985
Validation loss: 2.5217463291658473

Epoch: 6| Step: 12
Training loss: 0.4067440330217752
Validation loss: 2.534136328356997

Epoch: 6| Step: 13
Training loss: 0.2177842740497453
Validation loss: 2.502335618194888

Epoch: 351| Step: 0
Training loss: 0.44423184695209966
Validation loss: 2.5114140507629075

Epoch: 6| Step: 1
Training loss: 0.19109080069847847
Validation loss: 2.4825896195821877

Epoch: 6| Step: 2
Training loss: 0.34976396392843645
Validation loss: 2.4643360522089415

Epoch: 6| Step: 3
Training loss: 0.19047438268179695
Validation loss: 2.45449994354632

Epoch: 6| Step: 4
Training loss: 0.16621225157060265
Validation loss: 2.5135879661315395

Epoch: 6| Step: 5
Training loss: 0.17956478655587793
Validation loss: 2.528495013474041

Epoch: 6| Step: 6
Training loss: 0.24771743584172765
Validation loss: 2.5517596992446236

Epoch: 6| Step: 7
Training loss: 0.37005445607995335
Validation loss: 2.50966924577506

Epoch: 6| Step: 8
Training loss: 0.43487670041634796
Validation loss: 2.514258285858146

Epoch: 6| Step: 9
Training loss: 0.5447161980234847
Validation loss: 2.5532969706676614

Epoch: 6| Step: 10
Training loss: 0.19064560411446624
Validation loss: 2.5473838412091516

Epoch: 6| Step: 11
Training loss: 0.15710612831953258
Validation loss: 2.5398881810038882

Epoch: 6| Step: 12
Training loss: 0.341681466373267
Validation loss: 2.5393201183951346

Epoch: 6| Step: 13
Training loss: 0.1755362498722601
Validation loss: 2.5119151583711563

Epoch: 352| Step: 0
Training loss: 0.12187952772924508
Validation loss: 2.57775849950087

Epoch: 6| Step: 1
Training loss: 0.1858841591145211
Validation loss: 2.5791077859597062

Epoch: 6| Step: 2
Training loss: 0.4382962066219913
Validation loss: 2.5227181562955203

Epoch: 6| Step: 3
Training loss: 0.26299110408249643
Validation loss: 2.5754552666714674

Epoch: 6| Step: 4
Training loss: 0.23583303564129252
Validation loss: 2.5184165341170477

Epoch: 6| Step: 5
Training loss: 0.22452404225672593
Validation loss: 2.5600937035667015

Epoch: 6| Step: 6
Training loss: 0.1939248572681094
Validation loss: 2.5709988080209247

Epoch: 6| Step: 7
Training loss: 0.23145070451982347
Validation loss: 2.6392217389131787

Epoch: 6| Step: 8
Training loss: 0.46453571531713933
Validation loss: 2.6065566805867735

Epoch: 6| Step: 9
Training loss: 0.49082309587010486
Validation loss: 2.5849158401516528

Epoch: 6| Step: 10
Training loss: 0.25645833850326555
Validation loss: 2.5791125641272523

Epoch: 6| Step: 11
Training loss: 0.3601738302776751
Validation loss: 2.5893587186495237

Epoch: 6| Step: 12
Training loss: 0.24469044381535163
Validation loss: 2.535066953276775

Epoch: 6| Step: 13
Training loss: 0.3644995411450045
Validation loss: 2.561476149510802

Epoch: 353| Step: 0
Training loss: 0.1402796637635978
Validation loss: 2.4884149965520708

Epoch: 6| Step: 1
Training loss: 0.3415657024634778
Validation loss: 2.475453357269653

Epoch: 6| Step: 2
Training loss: 0.23374440078098038
Validation loss: 2.4869612537819794

Epoch: 6| Step: 3
Training loss: 0.20856427366607386
Validation loss: 2.5052617690543397

Epoch: 6| Step: 4
Training loss: 0.5271378291710298
Validation loss: 2.4999941477143075

Epoch: 6| Step: 5
Training loss: 0.17140779610165188
Validation loss: 2.5347137289953348

Epoch: 6| Step: 6
Training loss: 0.3069234867598362
Validation loss: 2.5290690974638617

Epoch: 6| Step: 7
Training loss: 0.21651705304924895
Validation loss: 2.5405757653525827

Epoch: 6| Step: 8
Training loss: 0.38280557120144554
Validation loss: 2.5682986191097927

Epoch: 6| Step: 9
Training loss: 0.3283695830728606
Validation loss: 2.525889268360122

Epoch: 6| Step: 10
Training loss: 0.4661131763917688
Validation loss: 2.5416958015610467

Epoch: 6| Step: 11
Training loss: 0.21850994255470446
Validation loss: 2.529817343614793

Epoch: 6| Step: 12
Training loss: 0.17560026600457487
Validation loss: 2.517923611285364

Epoch: 6| Step: 13
Training loss: 0.41426536700650346
Validation loss: 2.4991971993210638

Epoch: 354| Step: 0
Training loss: 0.3347366850194145
Validation loss: 2.463489959541154

Epoch: 6| Step: 1
Training loss: 0.263013767235644
Validation loss: 2.4813587481153805

Epoch: 6| Step: 2
Training loss: 0.45177835103609104
Validation loss: 2.501798921854703

Epoch: 6| Step: 3
Training loss: 0.18594810872307274
Validation loss: 2.5102464402631175

Epoch: 6| Step: 4
Training loss: 0.26714834796420417
Validation loss: 2.515259469242739

Epoch: 6| Step: 5
Training loss: 0.28988394137266665
Validation loss: 2.49714097441137

Epoch: 6| Step: 6
Training loss: 0.26026159278726535
Validation loss: 2.538515091441191

Epoch: 6| Step: 7
Training loss: 0.4111235882591906
Validation loss: 2.5317150627096248

Epoch: 6| Step: 8
Training loss: 0.3472104375216903
Validation loss: 2.521530218435157

Epoch: 6| Step: 9
Training loss: 0.21514176593527579
Validation loss: 2.55085526921656

Epoch: 6| Step: 10
Training loss: 0.3732633112624477
Validation loss: 2.533715803651773

Epoch: 6| Step: 11
Training loss: 0.19853711856711012
Validation loss: 2.5438201619687666

Epoch: 6| Step: 12
Training loss: 0.2871837389910372
Validation loss: 2.501663060934155

Epoch: 6| Step: 13
Training loss: 0.11709436848530295
Validation loss: 2.5064976392254357

Epoch: 355| Step: 0
Training loss: 0.168969995977691
Validation loss: 2.5065272337092726

Epoch: 6| Step: 1
Training loss: 0.24826508783319196
Validation loss: 2.503642695471921

Epoch: 6| Step: 2
Training loss: 0.5706315128167835
Validation loss: 2.539154566002028

Epoch: 6| Step: 3
Training loss: 0.5287192595904594
Validation loss: 2.5192358926380365

Epoch: 6| Step: 4
Training loss: 0.13805746246220638
Validation loss: 2.5689937528497397

Epoch: 6| Step: 5
Training loss: 0.4138061701687016
Validation loss: 2.5581391928420056

Epoch: 6| Step: 6
Training loss: 0.23199294284608307
Validation loss: 2.6030333253442954

Epoch: 6| Step: 7
Training loss: 0.27662000112244384
Validation loss: 2.6202732585319364

Epoch: 6| Step: 8
Training loss: 0.32421937046221455
Validation loss: 2.586373173651464

Epoch: 6| Step: 9
Training loss: 0.22672943016466204
Validation loss: 2.5535561763956234

Epoch: 6| Step: 10
Training loss: 0.4156785951921546
Validation loss: 2.5601398274666276

Epoch: 6| Step: 11
Training loss: 0.30270324054712466
Validation loss: 2.5435828572936274

Epoch: 6| Step: 12
Training loss: 0.3674966038657286
Validation loss: 2.4816125882290856

Epoch: 6| Step: 13
Training loss: 0.17867006553664394
Validation loss: 2.542260213814746

Epoch: 356| Step: 0
Training loss: 0.2502966551224581
Validation loss: 2.6165996902178263

Epoch: 6| Step: 1
Training loss: 0.20924339998198246
Validation loss: 2.630643016789439

Epoch: 6| Step: 2
Training loss: 0.32702924920065574
Validation loss: 2.64804422895789

Epoch: 6| Step: 3
Training loss: 0.39819625956346316
Validation loss: 2.6474128958116756

Epoch: 6| Step: 4
Training loss: 0.43375756202174254
Validation loss: 2.673947654722708

Epoch: 6| Step: 5
Training loss: 0.2624192755190813
Validation loss: 2.599029758688558

Epoch: 6| Step: 6
Training loss: 0.2968603933656108
Validation loss: 2.6088668488597118

Epoch: 6| Step: 7
Training loss: 0.4231231381193637
Validation loss: 2.58269568870735

Epoch: 6| Step: 8
Training loss: 0.24673555335043165
Validation loss: 2.5928691619159148

Epoch: 6| Step: 9
Training loss: 0.38320968420109897
Validation loss: 2.5016766473582344

Epoch: 6| Step: 10
Training loss: 0.42421839803607314
Validation loss: 2.51206544626026

Epoch: 6| Step: 11
Training loss: 0.41762252086302043
Validation loss: 2.528968709736805

Epoch: 6| Step: 12
Training loss: 0.4187635903501716
Validation loss: 2.5522157110287305

Epoch: 6| Step: 13
Training loss: 0.305818549168281
Validation loss: 2.575068228136607

Epoch: 357| Step: 0
Training loss: 0.3114506388301731
Validation loss: 2.6142980301176015

Epoch: 6| Step: 1
Training loss: 0.25760205667641706
Validation loss: 2.569196048456391

Epoch: 6| Step: 2
Training loss: 0.3640841972860044
Validation loss: 2.58188851197638

Epoch: 6| Step: 3
Training loss: 0.4340026061918085
Validation loss: 2.58504641322338

Epoch: 6| Step: 4
Training loss: 0.22164394914018812
Validation loss: 2.5265436277395534

Epoch: 6| Step: 5
Training loss: 0.36175052593881035
Validation loss: 2.5347075492586653

Epoch: 6| Step: 6
Training loss: 0.41068440900262615
Validation loss: 2.527401444711907

Epoch: 6| Step: 7
Training loss: 0.36559304562341116
Validation loss: 2.529697711461368

Epoch: 6| Step: 8
Training loss: 0.39486995170798156
Validation loss: 2.5452813686850906

Epoch: 6| Step: 9
Training loss: 0.22419130144014954
Validation loss: 2.4909163548274305

Epoch: 6| Step: 10
Training loss: 0.3556908133940134
Validation loss: 2.4775446460201516

Epoch: 6| Step: 11
Training loss: 0.3592264448870758
Validation loss: 2.455165125744998

Epoch: 6| Step: 12
Training loss: 0.31961120034281476
Validation loss: 2.478731187637731

Epoch: 6| Step: 13
Training loss: 0.21798093173807745
Validation loss: 2.509311300086344

Epoch: 358| Step: 0
Training loss: 0.2445568351645209
Validation loss: 2.4629878802459517

Epoch: 6| Step: 1
Training loss: 0.2529841773057285
Validation loss: 2.5335672887672898

Epoch: 6| Step: 2
Training loss: 0.20072240523778906
Validation loss: 2.5508836842703952

Epoch: 6| Step: 3
Training loss: 0.43178153866456404
Validation loss: 2.5491721345788627

Epoch: 6| Step: 4
Training loss: 0.33187437278343457
Validation loss: 2.575796725306992

Epoch: 6| Step: 5
Training loss: 0.5828774975897617
Validation loss: 2.613009530984734

Epoch: 6| Step: 6
Training loss: 0.41221483517371804
Validation loss: 2.620718865043792

Epoch: 6| Step: 7
Training loss: 0.3236756659563585
Validation loss: 2.6108514495492665

Epoch: 6| Step: 8
Training loss: 0.361342888607802
Validation loss: 2.5915645955815396

Epoch: 6| Step: 9
Training loss: 0.35299839729466664
Validation loss: 2.6055143771458376

Epoch: 6| Step: 10
Training loss: 0.4073734338770654
Validation loss: 2.561507234067091

Epoch: 6| Step: 11
Training loss: 0.3558898778712365
Validation loss: 2.5517690344908925

Epoch: 6| Step: 12
Training loss: 0.39480943597882134
Validation loss: 2.5283518193896657

Epoch: 6| Step: 13
Training loss: 0.3285787601108355
Validation loss: 2.578666398971817

Epoch: 359| Step: 0
Training loss: 0.3633505027145471
Validation loss: 2.5954957304171162

Epoch: 6| Step: 1
Training loss: 0.38257116378798217
Validation loss: 2.632813439646394

Epoch: 6| Step: 2
Training loss: 0.2685963130249446
Validation loss: 2.5620753649002

Epoch: 6| Step: 3
Training loss: 0.2373774067795379
Validation loss: 2.6074065958874852

Epoch: 6| Step: 4
Training loss: 0.4241577483940259
Validation loss: 2.555766853264923

Epoch: 6| Step: 5
Training loss: 0.38185320568794556
Validation loss: 2.589619610147676

Epoch: 6| Step: 6
Training loss: 0.26825721217571913
Validation loss: 2.5709958096251797

Epoch: 6| Step: 7
Training loss: 0.42874558988699746
Validation loss: 2.520558728650051

Epoch: 6| Step: 8
Training loss: 0.35799462127108006
Validation loss: 2.523132024823906

Epoch: 6| Step: 9
Training loss: 0.26641155640359787
Validation loss: 2.5653222697117193

Epoch: 6| Step: 10
Training loss: 0.2456156006196389
Validation loss: 2.513821907441336

Epoch: 6| Step: 11
Training loss: 0.4003802972717664
Validation loss: 2.4835692260077646

Epoch: 6| Step: 12
Training loss: 0.2718670843879427
Validation loss: 2.5256321634211107

Epoch: 6| Step: 13
Training loss: 0.3310478457303713
Validation loss: 2.4952845360917486

Epoch: 360| Step: 0
Training loss: 0.3871571339113653
Validation loss: 2.517637509306627

Epoch: 6| Step: 1
Training loss: 0.3951827420562574
Validation loss: 2.5331031956139856

Epoch: 6| Step: 2
Training loss: 0.46123209122520414
Validation loss: 2.4855608914928506

Epoch: 6| Step: 3
Training loss: 0.30081909734235074
Validation loss: 2.5578931991498894

Epoch: 6| Step: 4
Training loss: 0.31132022364221035
Validation loss: 2.497348744451468

Epoch: 6| Step: 5
Training loss: 0.38930322178385224
Validation loss: 2.5142881264922723

Epoch: 6| Step: 6
Training loss: 0.2782690436006338
Validation loss: 2.4668257454436207

Epoch: 6| Step: 7
Training loss: 0.37922931937761056
Validation loss: 2.4944154815974184

Epoch: 6| Step: 8
Training loss: 0.23047919168902886
Validation loss: 2.4915207035026787

Epoch: 6| Step: 9
Training loss: 0.1617480295277191
Validation loss: 2.4530446823387053

Epoch: 6| Step: 10
Training loss: 0.1949047123113015
Validation loss: 2.5222448493746428

Epoch: 6| Step: 11
Training loss: 0.3230488824378378
Validation loss: 2.4727288858390093

Epoch: 6| Step: 12
Training loss: 0.2192353331233826
Validation loss: 2.474569412865629

Epoch: 6| Step: 13
Training loss: 0.2230770418039684
Validation loss: 2.4591673365653506

Epoch: 361| Step: 0
Training loss: 0.3408477466111459
Validation loss: 2.4740971552312034

Epoch: 6| Step: 1
Training loss: 0.3264743179375216
Validation loss: 2.4928543999209194

Epoch: 6| Step: 2
Training loss: 0.3897022028568334
Validation loss: 2.493145315048718

Epoch: 6| Step: 3
Training loss: 0.2510905174090017
Validation loss: 2.4915463477956012

Epoch: 6| Step: 4
Training loss: 0.17361992250705258
Validation loss: 2.4860185730567306

Epoch: 6| Step: 5
Training loss: 0.3560996273638718
Validation loss: 2.553814490498352

Epoch: 6| Step: 6
Training loss: 0.2219809027573642
Validation loss: 2.5461228256036232

Epoch: 6| Step: 7
Training loss: 0.300027224179652
Validation loss: 2.5889165740542874

Epoch: 6| Step: 8
Training loss: 0.4999576193014411
Validation loss: 2.5784449523292876

Epoch: 6| Step: 9
Training loss: 0.3709380375280559
Validation loss: 2.5355138321253645

Epoch: 6| Step: 10
Training loss: 0.310042902031264
Validation loss: 2.481627757552539

Epoch: 6| Step: 11
Training loss: 0.31664202582752765
Validation loss: 2.5001789213574

Epoch: 6| Step: 12
Training loss: 0.28607378927003135
Validation loss: 2.5143634606390397

Epoch: 6| Step: 13
Training loss: 0.2558687514123111
Validation loss: 2.5336307625748797

Epoch: 362| Step: 0
Training loss: 0.3164133141753372
Validation loss: 2.5314201541874355

Epoch: 6| Step: 1
Training loss: 0.3173987634025082
Validation loss: 2.525608411160657

Epoch: 6| Step: 2
Training loss: 0.41119637983283386
Validation loss: 2.516153681410569

Epoch: 6| Step: 3
Training loss: 0.4168658813440086
Validation loss: 2.5582360007590563

Epoch: 6| Step: 4
Training loss: 0.3233624951842709
Validation loss: 2.5918400385748868

Epoch: 6| Step: 5
Training loss: 0.2765834891980766
Validation loss: 2.5650235417593454

Epoch: 6| Step: 6
Training loss: 0.33194850563790884
Validation loss: 2.56012607264668

Epoch: 6| Step: 7
Training loss: 0.3707865598019483
Validation loss: 2.527923005857488

Epoch: 6| Step: 8
Training loss: 0.23980607255609315
Validation loss: 2.516648741736166

Epoch: 6| Step: 9
Training loss: 0.3180453852499375
Validation loss: 2.4458850456476258

Epoch: 6| Step: 10
Training loss: 0.3691274852533382
Validation loss: 2.4552784179843306

Epoch: 6| Step: 11
Training loss: 0.2690451841730474
Validation loss: 2.420968572628691

Epoch: 6| Step: 12
Training loss: 0.2365696043764386
Validation loss: 2.39619706127269

Epoch: 6| Step: 13
Training loss: 0.43134770875930034
Validation loss: 2.4205066066127916

Epoch: 363| Step: 0
Training loss: 0.38152230106456736
Validation loss: 2.453426149526022

Epoch: 6| Step: 1
Training loss: 0.2985680888600953
Validation loss: 2.529943905277061

Epoch: 6| Step: 2
Training loss: 0.3783676803153077
Validation loss: 2.5813863273179485

Epoch: 6| Step: 3
Training loss: 0.33039921599426725
Validation loss: 2.610626991733913

Epoch: 6| Step: 4
Training loss: 0.25609054023448846
Validation loss: 2.6113661101390884

Epoch: 6| Step: 5
Training loss: 0.4559218970982862
Validation loss: 2.605053621584655

Epoch: 6| Step: 6
Training loss: 0.2226389577073509
Validation loss: 2.5428141482086364

Epoch: 6| Step: 7
Training loss: 0.41494523726930505
Validation loss: 2.477622929869466

Epoch: 6| Step: 8
Training loss: 0.2954843727391398
Validation loss: 2.4640343705898964

Epoch: 6| Step: 9
Training loss: 0.3750723133300372
Validation loss: 2.4933740012926844

Epoch: 6| Step: 10
Training loss: 0.3531052752699534
Validation loss: 2.423622204504781

Epoch: 6| Step: 11
Training loss: 0.28906505171190827
Validation loss: 2.4413826165480774

Epoch: 6| Step: 12
Training loss: 0.21301748713046897
Validation loss: 2.4186421740352833

Epoch: 6| Step: 13
Training loss: 0.21135766075038642
Validation loss: 2.412784677743926

Epoch: 364| Step: 0
Training loss: 0.3846507021846136
Validation loss: 2.4421144060744284

Epoch: 6| Step: 1
Training loss: 0.3291451060299967
Validation loss: 2.463581072315616

Epoch: 6| Step: 2
Training loss: 0.33963047657925566
Validation loss: 2.4613354026748984

Epoch: 6| Step: 3
Training loss: 0.45933887508324683
Validation loss: 2.4693312525995035

Epoch: 6| Step: 4
Training loss: 0.3875592086534121
Validation loss: 2.5174273169023107

Epoch: 6| Step: 5
Training loss: 0.4222234417280075
Validation loss: 2.5053684256037387

Epoch: 6| Step: 6
Training loss: 0.3129809493278807
Validation loss: 2.515416708345611

Epoch: 6| Step: 7
Training loss: 0.2765951126611563
Validation loss: 2.4890903841790206

Epoch: 6| Step: 8
Training loss: 0.3539353508174204
Validation loss: 2.48813022407556

Epoch: 6| Step: 9
Training loss: 0.273877661519283
Validation loss: 2.4610338646974173

Epoch: 6| Step: 10
Training loss: 0.3128445156759834
Validation loss: 2.4719730147280585

Epoch: 6| Step: 11
Training loss: 0.21392918040976763
Validation loss: 2.4514827379333375

Epoch: 6| Step: 12
Training loss: 0.18256507986897608
Validation loss: 2.4555317328028177

Epoch: 6| Step: 13
Training loss: 0.2940005127032993
Validation loss: 2.4248446979867375

Epoch: 365| Step: 0
Training loss: 0.4601630801356194
Validation loss: 2.473446508721082

Epoch: 6| Step: 1
Training loss: 0.2400315366578647
Validation loss: 2.5557440451121365

Epoch: 6| Step: 2
Training loss: 0.16662733475687014
Validation loss: 2.5517263675555584

Epoch: 6| Step: 3
Training loss: 0.43120127969385613
Validation loss: 2.511385963412471

Epoch: 6| Step: 4
Training loss: 0.3123805771566811
Validation loss: 2.5518185171556196

Epoch: 6| Step: 5
Training loss: 0.5822214417486727
Validation loss: 2.5404615608197374

Epoch: 6| Step: 6
Training loss: 0.2193421115838509
Validation loss: 2.5510630555661615

Epoch: 6| Step: 7
Training loss: 0.18494171034586193
Validation loss: 2.518239270455205

Epoch: 6| Step: 8
Training loss: 0.33246911292634923
Validation loss: 2.510914605392106

Epoch: 6| Step: 9
Training loss: 0.20767064595032786
Validation loss: 2.5180140779681244

Epoch: 6| Step: 10
Training loss: 0.1937387578532922
Validation loss: 2.5206912888939215

Epoch: 6| Step: 11
Training loss: 0.2913042467785975
Validation loss: 2.5076011037295998

Epoch: 6| Step: 12
Training loss: 0.28925663640660876
Validation loss: 2.5288019672069666

Epoch: 6| Step: 13
Training loss: 0.329132067344782
Validation loss: 2.5305875161679134

Epoch: 366| Step: 0
Training loss: 0.3324587145966242
Validation loss: 2.5342127168552953

Epoch: 6| Step: 1
Training loss: 0.29477379725633635
Validation loss: 2.5193097788542493

Epoch: 6| Step: 2
Training loss: 0.3651738448141905
Validation loss: 2.5063423527196913

Epoch: 6| Step: 3
Training loss: 0.4024435493617674
Validation loss: 2.5196299503139294

Epoch: 6| Step: 4
Training loss: 0.28195120238179505
Validation loss: 2.5408885312031524

Epoch: 6| Step: 5
Training loss: 0.3242195543026427
Validation loss: 2.4692745500390867

Epoch: 6| Step: 6
Training loss: 0.3903529173278659
Validation loss: 2.45319262640556

Epoch: 6| Step: 7
Training loss: 0.30405095438193447
Validation loss: 2.4818235134641182

Epoch: 6| Step: 8
Training loss: 0.16468181543293325
Validation loss: 2.4733087711304806

Epoch: 6| Step: 9
Training loss: 0.2760563642559676
Validation loss: 2.484929157185748

Epoch: 6| Step: 10
Training loss: 0.17376429210858596
Validation loss: 2.5388498009884777

Epoch: 6| Step: 11
Training loss: 0.24619289701888833
Validation loss: 2.5276326744078355

Epoch: 6| Step: 12
Training loss: 0.130171097358521
Validation loss: 2.51711467196244

Epoch: 6| Step: 13
Training loss: 0.22314870484036303
Validation loss: 2.531396601057571

Epoch: 367| Step: 0
Training loss: 0.36836629721487496
Validation loss: 2.579893689922033

Epoch: 6| Step: 1
Training loss: 0.18514660274949116
Validation loss: 2.568553959455431

Epoch: 6| Step: 2
Training loss: 0.29200518780094203
Validation loss: 2.564687498007214

Epoch: 6| Step: 3
Training loss: 0.39670945341824676
Validation loss: 2.5436299231017876

Epoch: 6| Step: 4
Training loss: 0.3135301894667407
Validation loss: 2.545023494977627

Epoch: 6| Step: 5
Training loss: 0.20775465267700363
Validation loss: 2.560630659740961

Epoch: 6| Step: 6
Training loss: 0.2564488964890813
Validation loss: 2.545980555499172

Epoch: 6| Step: 7
Training loss: 0.3553547728864093
Validation loss: 2.608419576356154

Epoch: 6| Step: 8
Training loss: 0.2110025870607521
Validation loss: 2.596060341539853

Epoch: 6| Step: 9
Training loss: 0.298524153447067
Validation loss: 2.576459887000566

Epoch: 6| Step: 10
Training loss: 0.24210599327618368
Validation loss: 2.5821167353344032

Epoch: 6| Step: 11
Training loss: 0.38212087005190337
Validation loss: 2.6094455072088962

Epoch: 6| Step: 12
Training loss: 0.21854019321518292
Validation loss: 2.547093928394697

Epoch: 6| Step: 13
Training loss: 0.3080838856339158
Validation loss: 2.534911753764958

Epoch: 368| Step: 0
Training loss: 0.20566164288813743
Validation loss: 2.547519190928311

Epoch: 6| Step: 1
Training loss: 0.2978554647221327
Validation loss: 2.5085463289902084

Epoch: 6| Step: 2
Training loss: 0.27985876423288464
Validation loss: 2.5104603626793764

Epoch: 6| Step: 3
Training loss: 0.40367170271473896
Validation loss: 2.516173248277854

Epoch: 6| Step: 4
Training loss: 0.2199179345789178
Validation loss: 2.500136735212185

Epoch: 6| Step: 5
Training loss: 0.23566955831889205
Validation loss: 2.509757934369558

Epoch: 6| Step: 6
Training loss: 0.34116306940852426
Validation loss: 2.547684123802563

Epoch: 6| Step: 7
Training loss: 0.31075948958358307
Validation loss: 2.53639947087176

Epoch: 6| Step: 8
Training loss: 0.24107333748934598
Validation loss: 2.537809427804037

Epoch: 6| Step: 9
Training loss: 0.32819160285016763
Validation loss: 2.537284240731458

Epoch: 6| Step: 10
Training loss: 0.3191694939955405
Validation loss: 2.544880744349177

Epoch: 6| Step: 11
Training loss: 0.21148922080782834
Validation loss: 2.5241840690254738

Epoch: 6| Step: 12
Training loss: 0.28880912398391995
Validation loss: 2.5684897327440623

Epoch: 6| Step: 13
Training loss: 0.2427219830441705
Validation loss: 2.5543697907608203

Epoch: 369| Step: 0
Training loss: 0.2953024423491138
Validation loss: 2.5674636232659016

Epoch: 6| Step: 1
Training loss: 0.41049024516188215
Validation loss: 2.5930122258267834

Epoch: 6| Step: 2
Training loss: 0.32259834915366636
Validation loss: 2.5869895005430013

Epoch: 6| Step: 3
Training loss: 0.23098366807562237
Validation loss: 2.5745716694887335

Epoch: 6| Step: 4
Training loss: 0.35565050948755567
Validation loss: 2.5320086955673005

Epoch: 6| Step: 5
Training loss: 0.2908208182223543
Validation loss: 2.535449461074745

Epoch: 6| Step: 6
Training loss: 0.17214169185432832
Validation loss: 2.517169606344749

Epoch: 6| Step: 7
Training loss: 0.32666019046252975
Validation loss: 2.5297318938121003

Epoch: 6| Step: 8
Training loss: 0.1875967531117946
Validation loss: 2.5302224812701244

Epoch: 6| Step: 9
Training loss: 0.16563588637436188
Validation loss: 2.5384324683432755

Epoch: 6| Step: 10
Training loss: 0.27228032897474713
Validation loss: 2.556710378512734

Epoch: 6| Step: 11
Training loss: 0.36154982492687704
Validation loss: 2.537362179826557

Epoch: 6| Step: 12
Training loss: 0.30026939733771457
Validation loss: 2.5731118503359607

Epoch: 6| Step: 13
Training loss: 0.11973320832095416
Validation loss: 2.567137111378791

Epoch: 370| Step: 0
Training loss: 0.31654253720663467
Validation loss: 2.562351731743751

Epoch: 6| Step: 1
Training loss: 0.17418030626863365
Validation loss: 2.5354405955695416

Epoch: 6| Step: 2
Training loss: 0.3304637484701813
Validation loss: 2.542289035521934

Epoch: 6| Step: 3
Training loss: 0.3808551494657421
Validation loss: 2.531613711558347

Epoch: 6| Step: 4
Training loss: 0.19410114385782729
Validation loss: 2.475569099086973

Epoch: 6| Step: 5
Training loss: 0.2180373299292131
Validation loss: 2.5042952524810334

Epoch: 6| Step: 6
Training loss: 0.37550681357418025
Validation loss: 2.452981125705411

Epoch: 6| Step: 7
Training loss: 0.3045390085139212
Validation loss: 2.4987733785055815

Epoch: 6| Step: 8
Training loss: 0.4644166603243531
Validation loss: 2.5046404020696946

Epoch: 6| Step: 9
Training loss: 0.13388520287922293
Validation loss: 2.558546054661374

Epoch: 6| Step: 10
Training loss: 0.220438993272085
Validation loss: 2.561893158176027

Epoch: 6| Step: 11
Training loss: 0.3643315013158574
Validation loss: 2.6095007407496613

Epoch: 6| Step: 12
Training loss: 0.18736248139061856
Validation loss: 2.632459545092849

Epoch: 6| Step: 13
Training loss: 0.4298627669337271
Validation loss: 2.64749102363303

Epoch: 371| Step: 0
Training loss: 0.372780829824722
Validation loss: 2.6614778518482796

Epoch: 6| Step: 1
Training loss: 0.3331662693189879
Validation loss: 2.6537352073348766

Epoch: 6| Step: 2
Training loss: 0.4751784441204313
Validation loss: 2.6071067468153912

Epoch: 6| Step: 3
Training loss: 0.25630783498370197
Validation loss: 2.5364353256123744

Epoch: 6| Step: 4
Training loss: 0.35070485300516624
Validation loss: 2.541834990745735

Epoch: 6| Step: 5
Training loss: 0.2734252109490849
Validation loss: 2.5249721440277595

Epoch: 6| Step: 6
Training loss: 0.4431684309709216
Validation loss: 2.482100360944457

Epoch: 6| Step: 7
Training loss: 0.18850407374910316
Validation loss: 2.4924202824853365

Epoch: 6| Step: 8
Training loss: 0.19108607313404832
Validation loss: 2.5056493404801685

Epoch: 6| Step: 9
Training loss: 0.21169915266939568
Validation loss: 2.4904251566671243

Epoch: 6| Step: 10
Training loss: 0.28378022686198684
Validation loss: 2.5110349343567786

Epoch: 6| Step: 11
Training loss: 0.3697518228727109
Validation loss: 2.5229365511521036

Epoch: 6| Step: 12
Training loss: 0.2546204426020035
Validation loss: 2.5920908632957045

Epoch: 6| Step: 13
Training loss: 0.4604321959050099
Validation loss: 2.578001588295783

Epoch: 372| Step: 0
Training loss: 0.26087845231291107
Validation loss: 2.5493875985453127

Epoch: 6| Step: 1
Training loss: 0.2743292572281446
Validation loss: 2.531686990972503

Epoch: 6| Step: 2
Training loss: 0.42958650269003684
Validation loss: 2.465060614284275

Epoch: 6| Step: 3
Training loss: 0.39339383153384716
Validation loss: 2.4338806622650933

Epoch: 6| Step: 4
Training loss: 0.36752774322007037
Validation loss: 2.452911372876663

Epoch: 6| Step: 5
Training loss: 0.20926243118791774
Validation loss: 2.4801463889104527

Epoch: 6| Step: 6
Training loss: 0.18897620864324705
Validation loss: 2.487506006136407

Epoch: 6| Step: 7
Training loss: 0.4056994118347023
Validation loss: 2.4693218943165864

Epoch: 6| Step: 8
Training loss: 0.37942280903304476
Validation loss: 2.4720568075219993

Epoch: 6| Step: 9
Training loss: 0.3145797664027487
Validation loss: 2.5507748388331604

Epoch: 6| Step: 10
Training loss: 0.21580638236404395
Validation loss: 2.605655498231944

Epoch: 6| Step: 11
Training loss: 0.2586999415843265
Validation loss: 2.6087616608653676

Epoch: 6| Step: 12
Training loss: 0.4494089138725817
Validation loss: 2.634861338755334

Epoch: 6| Step: 13
Training loss: 0.2275383093825553
Validation loss: 2.6073605102382427

Epoch: 373| Step: 0
Training loss: 0.19549470032462465
Validation loss: 2.596924923281585

Epoch: 6| Step: 1
Training loss: 0.33719563535363434
Validation loss: 2.5678544556517995

Epoch: 6| Step: 2
Training loss: 0.17458268138627964
Validation loss: 2.5323271976776676

Epoch: 6| Step: 3
Training loss: 0.25605985925777835
Validation loss: 2.52682771587939

Epoch: 6| Step: 4
Training loss: 0.3909321912226662
Validation loss: 2.506076124602715

Epoch: 6| Step: 5
Training loss: 0.30808838375257475
Validation loss: 2.4687457475979975

Epoch: 6| Step: 6
Training loss: 0.2426152988643467
Validation loss: 2.493539863018879

Epoch: 6| Step: 7
Training loss: 0.3261906281522444
Validation loss: 2.5277560604742724

Epoch: 6| Step: 8
Training loss: 0.20016408537180444
Validation loss: 2.521533597944829

Epoch: 6| Step: 9
Training loss: 0.18779270848550284
Validation loss: 2.5339557689852916

Epoch: 6| Step: 10
Training loss: 0.3111489056521846
Validation loss: 2.5480275855562566

Epoch: 6| Step: 11
Training loss: 0.3619456607305025
Validation loss: 2.5369608495998817

Epoch: 6| Step: 12
Training loss: 0.3451349470818304
Validation loss: 2.5448989263345765

Epoch: 6| Step: 13
Training loss: 0.23251027742097458
Validation loss: 2.5721736099198003

Epoch: 374| Step: 0
Training loss: 0.38527840849457995
Validation loss: 2.548165543031066

Epoch: 6| Step: 1
Training loss: 0.3695493584807047
Validation loss: 2.5919762837913365

Epoch: 6| Step: 2
Training loss: 0.20988528640853846
Validation loss: 2.5834486522466173

Epoch: 6| Step: 3
Training loss: 0.1977008889796251
Validation loss: 2.5641971033564435

Epoch: 6| Step: 4
Training loss: 0.3669935485262399
Validation loss: 2.5538340373446875

Epoch: 6| Step: 5
Training loss: 0.24445162991206437
Validation loss: 2.581074221735299

Epoch: 6| Step: 6
Training loss: 0.36543713005964495
Validation loss: 2.5780209636858786

Epoch: 6| Step: 7
Training loss: 0.21104883858361836
Validation loss: 2.5761194019545903

Epoch: 6| Step: 8
Training loss: 0.22804962637464432
Validation loss: 2.5203939339838195

Epoch: 6| Step: 9
Training loss: 0.30105642636733554
Validation loss: 2.489511652995063

Epoch: 6| Step: 10
Training loss: 0.37699417523227763
Validation loss: 2.423339255031009

Epoch: 6| Step: 11
Training loss: 0.12932841213111948
Validation loss: 2.450038815471933

Epoch: 6| Step: 12
Training loss: 0.32911168204576857
Validation loss: 2.466760895594091

Epoch: 6| Step: 13
Training loss: 0.23053763055316281
Validation loss: 2.499085400545097

Epoch: 375| Step: 0
Training loss: 0.1452226276274033
Validation loss: 2.47644495055085

Epoch: 6| Step: 1
Training loss: 0.43344082584218996
Validation loss: 2.531617899878567

Epoch: 6| Step: 2
Training loss: 0.3306401225491321
Validation loss: 2.4681371211325995

Epoch: 6| Step: 3
Training loss: 0.21438727870565197
Validation loss: 2.4775027982857973

Epoch: 6| Step: 4
Training loss: 0.17892609865118597
Validation loss: 2.4743678974880123

Epoch: 6| Step: 5
Training loss: 0.26977916041713507
Validation loss: 2.5118159630302337

Epoch: 6| Step: 6
Training loss: 0.26572560761203073
Validation loss: 2.5270760782393644

Epoch: 6| Step: 7
Training loss: 0.2598282301185281
Validation loss: 2.5217134648963944

Epoch: 6| Step: 8
Training loss: 0.2808812160780268
Validation loss: 2.527450179657637

Epoch: 6| Step: 9
Training loss: 0.29027742808430934
Validation loss: 2.5235943539933694

Epoch: 6| Step: 10
Training loss: 0.1990661691270611
Validation loss: 2.467514298930552

Epoch: 6| Step: 11
Training loss: 0.3608903862395436
Validation loss: 2.5062728079254466

Epoch: 6| Step: 12
Training loss: 0.38046355586648173
Validation loss: 2.4945192176494717

Epoch: 6| Step: 13
Training loss: 0.25370611960026396
Validation loss: 2.536566149575995

Epoch: 376| Step: 0
Training loss: 0.33307362910063515
Validation loss: 2.5037515835111974

Epoch: 6| Step: 1
Training loss: 0.2926329404771228
Validation loss: 2.513356070091557

Epoch: 6| Step: 2
Training loss: 0.2903296046150797
Validation loss: 2.5230179086103997

Epoch: 6| Step: 3
Training loss: 0.19311438559093655
Validation loss: 2.5203327328356706

Epoch: 6| Step: 4
Training loss: 0.28372318267132685
Validation loss: 2.5723008901131945

Epoch: 6| Step: 5
Training loss: 0.2673004547412827
Validation loss: 2.5357922395354247

Epoch: 6| Step: 6
Training loss: 0.3062437611547759
Validation loss: 2.5430669116459526

Epoch: 6| Step: 7
Training loss: 0.17997048733749174
Validation loss: 2.5055209336137017

Epoch: 6| Step: 8
Training loss: 0.24374054743704918
Validation loss: 2.5327248803036286

Epoch: 6| Step: 9
Training loss: 0.23827191631609912
Validation loss: 2.514920387651993

Epoch: 6| Step: 10
Training loss: 0.38732992870051336
Validation loss: 2.5235681393641847

Epoch: 6| Step: 11
Training loss: 0.4458224739404015
Validation loss: 2.4693271382400823

Epoch: 6| Step: 12
Training loss: 0.2103701484991145
Validation loss: 2.544888466848291

Epoch: 6| Step: 13
Training loss: 0.2172827731226844
Validation loss: 2.5393097828237243

Epoch: 377| Step: 0
Training loss: 0.23446670963193228
Validation loss: 2.5896477933942883

Epoch: 6| Step: 1
Training loss: 0.2213445726821262
Validation loss: 2.5789505487929096

Epoch: 6| Step: 2
Training loss: 0.354178276526204
Validation loss: 2.579545458997175

Epoch: 6| Step: 3
Training loss: 0.3502147909556581
Validation loss: 2.569374800867812

Epoch: 6| Step: 4
Training loss: 0.26729957672678595
Validation loss: 2.542049812461506

Epoch: 6| Step: 5
Training loss: 0.49609721925979217
Validation loss: 2.55477643605335

Epoch: 6| Step: 6
Training loss: 0.27568314620173223
Validation loss: 2.506954149086103

Epoch: 6| Step: 7
Training loss: 0.22328332803932438
Validation loss: 2.5065892822916016

Epoch: 6| Step: 8
Training loss: 0.28735408604645485
Validation loss: 2.486563119017641

Epoch: 6| Step: 9
Training loss: 0.3304176390241929
Validation loss: 2.478448153746984

Epoch: 6| Step: 10
Training loss: 0.20559076087913655
Validation loss: 2.490866483616797

Epoch: 6| Step: 11
Training loss: 0.4410837565150424
Validation loss: 2.469841558582444

Epoch: 6| Step: 12
Training loss: 0.25706263063642176
Validation loss: 2.499058828289339

Epoch: 6| Step: 13
Training loss: 0.17063363950291513
Validation loss: 2.5481416969764696

Epoch: 378| Step: 0
Training loss: 0.20911930755054764
Validation loss: 2.558706202912955

Epoch: 6| Step: 1
Training loss: 0.45356203247567667
Validation loss: 2.508612244203673

Epoch: 6| Step: 2
Training loss: 0.17221867273973046
Validation loss: 2.5611135282030455

Epoch: 6| Step: 3
Training loss: 0.24005153334947682
Validation loss: 2.5921872646605606

Epoch: 6| Step: 4
Training loss: 0.23037780971852476
Validation loss: 2.5573841433546582

Epoch: 6| Step: 5
Training loss: 0.287984435740422
Validation loss: 2.540104775630752

Epoch: 6| Step: 6
Training loss: 0.2153373337004151
Validation loss: 2.567620409666361

Epoch: 6| Step: 7
Training loss: 0.1963767999072423
Validation loss: 2.5477631977520505

Epoch: 6| Step: 8
Training loss: 0.20766504907730665
Validation loss: 2.5590601477438746

Epoch: 6| Step: 9
Training loss: 0.21985005617078107
Validation loss: 2.5255815520587306

Epoch: 6| Step: 10
Training loss: 0.32694638973394885
Validation loss: 2.509592384490311

Epoch: 6| Step: 11
Training loss: 0.15686061280225086
Validation loss: 2.5445442287507967

Epoch: 6| Step: 12
Training loss: 0.38557022704236216
Validation loss: 2.501235575573619

Epoch: 6| Step: 13
Training loss: 0.3055409802165935
Validation loss: 2.5117474026472175

Epoch: 379| Step: 0
Training loss: 0.16423962318869292
Validation loss: 2.5370888464668693

Epoch: 6| Step: 1
Training loss: 0.2966515051167824
Validation loss: 2.5310855145109237

Epoch: 6| Step: 2
Training loss: 0.29411418790921845
Validation loss: 2.4857308584726288

Epoch: 6| Step: 3
Training loss: 0.20363328684494178
Validation loss: 2.482392915365558

Epoch: 6| Step: 4
Training loss: 0.33773009395246556
Validation loss: 2.5037165119671063

Epoch: 6| Step: 5
Training loss: 0.22675242356000908
Validation loss: 2.491766125940405

Epoch: 6| Step: 6
Training loss: 0.24064796016192389
Validation loss: 2.4927086699400762

Epoch: 6| Step: 7
Training loss: 0.20149453222225358
Validation loss: 2.5305950816994454

Epoch: 6| Step: 8
Training loss: 0.35310506426821126
Validation loss: 2.519190417053456

Epoch: 6| Step: 9
Training loss: 0.16670609109721013
Validation loss: 2.593283434250534

Epoch: 6| Step: 10
Training loss: 0.214525463848615
Validation loss: 2.5707455883075525

Epoch: 6| Step: 11
Training loss: 0.24389321570358793
Validation loss: 2.570344953334911

Epoch: 6| Step: 12
Training loss: 0.4379651457971347
Validation loss: 2.61373336174581

Epoch: 6| Step: 13
Training loss: 0.43347609702211887
Validation loss: 2.5917474909055147

Epoch: 380| Step: 0
Training loss: 0.24789904897799003
Validation loss: 2.544761972463706

Epoch: 6| Step: 1
Training loss: 0.14453030921011245
Validation loss: 2.571045170531819

Epoch: 6| Step: 2
Training loss: 0.14785506774698
Validation loss: 2.4993703674817187

Epoch: 6| Step: 3
Training loss: 0.1755228156158016
Validation loss: 2.5058408954268807

Epoch: 6| Step: 4
Training loss: 0.20607307315898826
Validation loss: 2.503163090209779

Epoch: 6| Step: 5
Training loss: 0.3992871966725652
Validation loss: 2.470104723825939

Epoch: 6| Step: 6
Training loss: 0.44024529160078146
Validation loss: 2.4761316699708256

Epoch: 6| Step: 7
Training loss: 0.27301520026075743
Validation loss: 2.4459278043233694

Epoch: 6| Step: 8
Training loss: 0.1348717865689263
Validation loss: 2.437152641121179

Epoch: 6| Step: 9
Training loss: 0.30250434750199295
Validation loss: 2.4179380016229577

Epoch: 6| Step: 10
Training loss: 0.2328733179161681
Validation loss: 2.446867545500542

Epoch: 6| Step: 11
Training loss: 0.3264235821619449
Validation loss: 2.4811172780894104

Epoch: 6| Step: 12
Training loss: 0.2220365366081526
Validation loss: 2.4949256774832986

Epoch: 6| Step: 13
Training loss: 0.22939009323146825
Validation loss: 2.5547446971143972

Epoch: 381| Step: 0
Training loss: 0.20930296242217214
Validation loss: 2.5587668869979643

Epoch: 6| Step: 1
Training loss: 0.30250982755271294
Validation loss: 2.5876794260733473

Epoch: 6| Step: 2
Training loss: 0.2169567412259439
Validation loss: 2.571815198822752

Epoch: 6| Step: 3
Training loss: 0.4626745532536969
Validation loss: 2.6018943251044355

Epoch: 6| Step: 4
Training loss: 0.25637018013956575
Validation loss: 2.560963187596636

Epoch: 6| Step: 5
Training loss: 0.320307045401674
Validation loss: 2.553420912747672

Epoch: 6| Step: 6
Training loss: 0.25165629089726516
Validation loss: 2.550079453686448

Epoch: 6| Step: 7
Training loss: 0.27909374186061225
Validation loss: 2.544646049183139

Epoch: 6| Step: 8
Training loss: 0.3932373433389288
Validation loss: 2.507500684666887

Epoch: 6| Step: 9
Training loss: 0.2856497739653091
Validation loss: 2.4987965640599157

Epoch: 6| Step: 10
Training loss: 0.24913136256582352
Validation loss: 2.515187393512425

Epoch: 6| Step: 11
Training loss: 0.29934946098578574
Validation loss: 2.542047815643652

Epoch: 6| Step: 12
Training loss: 0.14395726774095505
Validation loss: 2.5452556241890836

Epoch: 6| Step: 13
Training loss: 0.22725680448555155
Validation loss: 2.536371619775604

Epoch: 382| Step: 0
Training loss: 0.3063644818010543
Validation loss: 2.578859043623411

Epoch: 6| Step: 1
Training loss: 0.365848616336564
Validation loss: 2.5828619621860986

Epoch: 6| Step: 2
Training loss: 0.25381796842657023
Validation loss: 2.6267121313295623

Epoch: 6| Step: 3
Training loss: 0.3109246601156555
Validation loss: 2.5787270617035367

Epoch: 6| Step: 4
Training loss: 0.2736998525612141
Validation loss: 2.598719970365155

Epoch: 6| Step: 5
Training loss: 0.17448588021490746
Validation loss: 2.5257462889023885

Epoch: 6| Step: 6
Training loss: 0.18520391792237692
Validation loss: 2.569600447227942

Epoch: 6| Step: 7
Training loss: 0.21271238827708894
Validation loss: 2.550291114595623

Epoch: 6| Step: 8
Training loss: 0.2507437431357318
Validation loss: 2.5245829592457807

Epoch: 6| Step: 9
Training loss: 0.35383566179795606
Validation loss: 2.4837918759716984

Epoch: 6| Step: 10
Training loss: 0.32888682799635094
Validation loss: 2.4813393881709596

Epoch: 6| Step: 11
Training loss: 0.32099829505604294
Validation loss: 2.495117780346091

Epoch: 6| Step: 12
Training loss: 0.20881578294079522
Validation loss: 2.4668788420670706

Epoch: 6| Step: 13
Training loss: 0.19060797537152113
Validation loss: 2.519535656310128

Epoch: 383| Step: 0
Training loss: 0.2183893756354461
Validation loss: 2.5486027126757484

Epoch: 6| Step: 1
Training loss: 0.36143757992327497
Validation loss: 2.56294190352904

Epoch: 6| Step: 2
Training loss: 0.23172450227600633
Validation loss: 2.5888119841140314

Epoch: 6| Step: 3
Training loss: 0.2557429565679157
Validation loss: 2.5579452202483983

Epoch: 6| Step: 4
Training loss: 0.24117946805576687
Validation loss: 2.523834466513817

Epoch: 6| Step: 5
Training loss: 0.17871497102781964
Validation loss: 2.4968258847672864

Epoch: 6| Step: 6
Training loss: 0.38879087917011146
Validation loss: 2.4540539245877264

Epoch: 6| Step: 7
Training loss: 0.19841133380696893
Validation loss: 2.465882059837178

Epoch: 6| Step: 8
Training loss: 0.3508560075515471
Validation loss: 2.4269236994895773

Epoch: 6| Step: 9
Training loss: 0.34571620679339043
Validation loss: 2.4760937327153387

Epoch: 6| Step: 10
Training loss: 0.3386761569376126
Validation loss: 2.4770287329489498

Epoch: 6| Step: 11
Training loss: 0.16082426643097544
Validation loss: 2.5226318633802323

Epoch: 6| Step: 12
Training loss: 0.16760356149826977
Validation loss: 2.5400011133489153

Epoch: 6| Step: 13
Training loss: 0.2201620575766281
Validation loss: 2.5501286775992162

Epoch: 384| Step: 0
Training loss: 0.30489300864140306
Validation loss: 2.6131533538056857

Epoch: 6| Step: 1
Training loss: 0.28726207798398595
Validation loss: 2.604393198968773

Epoch: 6| Step: 2
Training loss: 0.25420803328834396
Validation loss: 2.5651098727361688

Epoch: 6| Step: 3
Training loss: 0.19616860636514047
Validation loss: 2.5486099450897783

Epoch: 6| Step: 4
Training loss: 0.3313895138656217
Validation loss: 2.5421822403405625

Epoch: 6| Step: 5
Training loss: 0.3178202036071172
Validation loss: 2.516219314304871

Epoch: 6| Step: 6
Training loss: 0.22093065736849726
Validation loss: 2.4982223179099483

Epoch: 6| Step: 7
Training loss: 0.25310037811055874
Validation loss: 2.5252294846913346

Epoch: 6| Step: 8
Training loss: 0.20020364883557962
Validation loss: 2.5215624618636516

Epoch: 6| Step: 9
Training loss: 0.1778524132600775
Validation loss: 2.5231104437257175

Epoch: 6| Step: 10
Training loss: 0.37115148797850184
Validation loss: 2.511032840387848

Epoch: 6| Step: 11
Training loss: 0.2534799224447412
Validation loss: 2.573532715927406

Epoch: 6| Step: 12
Training loss: 0.18692931110042701
Validation loss: 2.571753211728753

Epoch: 6| Step: 13
Training loss: 0.17210515283331224
Validation loss: 2.5997137706681177

Epoch: 385| Step: 0
Training loss: 0.21185087325425062
Validation loss: 2.5992791449693406

Epoch: 6| Step: 1
Training loss: 0.28661202151547943
Validation loss: 2.580057819116359

Epoch: 6| Step: 2
Training loss: 0.28532437371890734
Validation loss: 2.542834158187482

Epoch: 6| Step: 3
Training loss: 0.18267985405975723
Validation loss: 2.517773496923165

Epoch: 6| Step: 4
Training loss: 0.19556338409341026
Validation loss: 2.5353755724912506

Epoch: 6| Step: 5
Training loss: 0.3149252480790198
Validation loss: 2.4765688683015923

Epoch: 6| Step: 6
Training loss: 0.2338719851127737
Validation loss: 2.449673252320493

Epoch: 6| Step: 7
Training loss: 0.34063315513017745
Validation loss: 2.460286905181486

Epoch: 6| Step: 8
Training loss: 0.23777977752129356
Validation loss: 2.4171788111788657

Epoch: 6| Step: 9
Training loss: 0.2978140510326557
Validation loss: 2.4790263289200696

Epoch: 6| Step: 10
Training loss: 0.30995294167602183
Validation loss: 2.454253984652835

Epoch: 6| Step: 11
Training loss: 0.2747704984196391
Validation loss: 2.4482640180778548

Epoch: 6| Step: 12
Training loss: 0.19179397355505218
Validation loss: 2.4617892154657905

Epoch: 6| Step: 13
Training loss: 0.3128856544242689
Validation loss: 2.5116634126451287

Epoch: 386| Step: 0
Training loss: 0.2618781785612739
Validation loss: 2.554276230212338

Epoch: 6| Step: 1
Training loss: 0.36610140370384053
Validation loss: 2.570229868217182

Epoch: 6| Step: 2
Training loss: 0.28756633387204733
Validation loss: 2.591955606749108

Epoch: 6| Step: 3
Training loss: 0.23423895861304203
Validation loss: 2.5745671109218238

Epoch: 6| Step: 4
Training loss: 0.19597329889552645
Validation loss: 2.571660721742577

Epoch: 6| Step: 5
Training loss: 0.22852372701252993
Validation loss: 2.527897564269231

Epoch: 6| Step: 6
Training loss: 0.22256322222353855
Validation loss: 2.4917804757120123

Epoch: 6| Step: 7
Training loss: 0.39403149140198024
Validation loss: 2.4843802183414656

Epoch: 6| Step: 8
Training loss: 0.19090708045447893
Validation loss: 2.4916285583905062

Epoch: 6| Step: 9
Training loss: 0.328010879834802
Validation loss: 2.501756987956501

Epoch: 6| Step: 10
Training loss: 0.18501521787364267
Validation loss: 2.499604695353647

Epoch: 6| Step: 11
Training loss: 0.23478091375803395
Validation loss: 2.504394248208863

Epoch: 6| Step: 12
Training loss: 0.18989365278956621
Validation loss: 2.483253300592501

Epoch: 6| Step: 13
Training loss: 0.24648153693353206
Validation loss: 2.5157257489958194

Epoch: 387| Step: 0
Training loss: 0.287338036028672
Validation loss: 2.4903675673155248

Epoch: 6| Step: 1
Training loss: 0.25254158673717614
Validation loss: 2.4963233055597094

Epoch: 6| Step: 2
Training loss: 0.32519825656234086
Validation loss: 2.4878332950227104

Epoch: 6| Step: 3
Training loss: 0.29204964471138073
Validation loss: 2.5221102341729527

Epoch: 6| Step: 4
Training loss: 0.33141214208117764
Validation loss: 2.527232931093493

Epoch: 6| Step: 5
Training loss: 0.17556132758337456
Validation loss: 2.5303462450971965

Epoch: 6| Step: 6
Training loss: 0.3301248009539188
Validation loss: 2.580092852528086

Epoch: 6| Step: 7
Training loss: 0.24696080792938258
Validation loss: 2.5330936509020185

Epoch: 6| Step: 8
Training loss: 0.10844355151305755
Validation loss: 2.58696447831578

Epoch: 6| Step: 9
Training loss: 0.23381040439059173
Validation loss: 2.5339477152165713

Epoch: 6| Step: 10
Training loss: 0.11839907502846286
Validation loss: 2.54950443747056

Epoch: 6| Step: 11
Training loss: 0.2324962737312941
Validation loss: 2.554975982250348

Epoch: 6| Step: 12
Training loss: 0.24594431078833975
Validation loss: 2.545688228084646

Epoch: 6| Step: 13
Training loss: 0.24564135310162974
Validation loss: 2.5325623481243635

Epoch: 388| Step: 0
Training loss: 0.18576647161508547
Validation loss: 2.519621318108075

Epoch: 6| Step: 1
Training loss: 0.32543129134478366
Validation loss: 2.516670388431754

Epoch: 6| Step: 2
Training loss: 0.10006281083390506
Validation loss: 2.5444500673690063

Epoch: 6| Step: 3
Training loss: 0.12427029859641502
Validation loss: 2.5604923426111936

Epoch: 6| Step: 4
Training loss: 0.33092689860998786
Validation loss: 2.565328761944883

Epoch: 6| Step: 5
Training loss: 0.21356596265759373
Validation loss: 2.5588195473198807

Epoch: 6| Step: 6
Training loss: 0.33315434965345425
Validation loss: 2.548312575859744

Epoch: 6| Step: 7
Training loss: 0.18760269055023196
Validation loss: 2.50737494916127

Epoch: 6| Step: 8
Training loss: 0.18599934871621088
Validation loss: 2.543431178769952

Epoch: 6| Step: 9
Training loss: 0.2509660978399186
Validation loss: 2.5378322946076524

Epoch: 6| Step: 10
Training loss: 0.25238138219407125
Validation loss: 2.5274168489168654

Epoch: 6| Step: 11
Training loss: 0.2002997242398823
Validation loss: 2.5276639312393403

Epoch: 6| Step: 12
Training loss: 0.23172881070480392
Validation loss: 2.5380866566686646

Epoch: 6| Step: 13
Training loss: 0.3312372924958359
Validation loss: 2.510910272780236

Epoch: 389| Step: 0
Training loss: 0.3215147113044593
Validation loss: 2.4741551455765873

Epoch: 6| Step: 1
Training loss: 0.32253367518032605
Validation loss: 2.499676867080431

Epoch: 6| Step: 2
Training loss: 0.24525043012083564
Validation loss: 2.5042678561403267

Epoch: 6| Step: 3
Training loss: 0.29866149096008165
Validation loss: 2.4917116047999897

Epoch: 6| Step: 4
Training loss: 0.35376315645076317
Validation loss: 2.507336831283028

Epoch: 6| Step: 5
Training loss: 0.17919843917801842
Validation loss: 2.554281957626903

Epoch: 6| Step: 6
Training loss: 0.12347774905702978
Validation loss: 2.588999313458872

Epoch: 6| Step: 7
Training loss: 0.17199159048974472
Validation loss: 2.633104163769633

Epoch: 6| Step: 8
Training loss: 0.2620850462218218
Validation loss: 2.6063357613169913

Epoch: 6| Step: 9
Training loss: 0.3081972858953999
Validation loss: 2.640498728729649

Epoch: 6| Step: 10
Training loss: 0.2665626022320783
Validation loss: 2.6197211681489843

Epoch: 6| Step: 11
Training loss: 0.3605905996076413
Validation loss: 2.601510158708119

Epoch: 6| Step: 12
Training loss: 0.2565638910829698
Validation loss: 2.5300449352334424

Epoch: 6| Step: 13
Training loss: 0.22662204749135081
Validation loss: 2.4873049915535987

Epoch: 390| Step: 0
Training loss: 0.33427970499803383
Validation loss: 2.426324983526345

Epoch: 6| Step: 1
Training loss: 0.3002241598550955
Validation loss: 2.4172835561622144

Epoch: 6| Step: 2
Training loss: 0.2820840627617658
Validation loss: 2.4628121461111045

Epoch: 6| Step: 3
Training loss: 0.27627482404119025
Validation loss: 2.4340802070603518

Epoch: 6| Step: 4
Training loss: 0.23930145955465593
Validation loss: 2.447487706127503

Epoch: 6| Step: 5
Training loss: 0.1647801145329629
Validation loss: 2.479927877481611

Epoch: 6| Step: 6
Training loss: 0.23552896611848853
Validation loss: 2.5148329938016496

Epoch: 6| Step: 7
Training loss: 0.34665477824382285
Validation loss: 2.573308022085723

Epoch: 6| Step: 8
Training loss: 0.1679245535790497
Validation loss: 2.5696047387476595

Epoch: 6| Step: 9
Training loss: 0.34160179020398046
Validation loss: 2.5811351318035296

Epoch: 6| Step: 10
Training loss: 0.31668864705111593
Validation loss: 2.545890272982792

Epoch: 6| Step: 11
Training loss: 0.14173126857273144
Validation loss: 2.5772048198020916

Epoch: 6| Step: 12
Training loss: 0.23659574315404655
Validation loss: 2.485846538409279

Epoch: 6| Step: 13
Training loss: 0.19821949532958247
Validation loss: 2.513412541121406

Epoch: 391| Step: 0
Training loss: 0.1813518936574242
Validation loss: 2.52440281131965

Epoch: 6| Step: 1
Training loss: 0.37736802664748903
Validation loss: 2.5435161192704587

Epoch: 6| Step: 2
Training loss: 0.22370147483906086
Validation loss: 2.5422527051827584

Epoch: 6| Step: 3
Training loss: 0.24052578224359833
Validation loss: 2.581442885196655

Epoch: 6| Step: 4
Training loss: 0.1950210112781553
Validation loss: 2.5697084528672036

Epoch: 6| Step: 5
Training loss: 0.3559167993569549
Validation loss: 2.617599420114877

Epoch: 6| Step: 6
Training loss: 0.2879729097700292
Validation loss: 2.5824839038659166

Epoch: 6| Step: 7
Training loss: 0.2762410445509417
Validation loss: 2.5928080538911598

Epoch: 6| Step: 8
Training loss: 0.2420817344202913
Validation loss: 2.5601046672120393

Epoch: 6| Step: 9
Training loss: 0.27411525381707996
Validation loss: 2.5394770165412743

Epoch: 6| Step: 10
Training loss: 0.16044834296927232
Validation loss: 2.5468846450583777

Epoch: 6| Step: 11
Training loss: 0.17720571431053542
Validation loss: 2.5018498859862053

Epoch: 6| Step: 12
Training loss: 0.3900222705937996
Validation loss: 2.4995436144147485

Epoch: 6| Step: 13
Training loss: 0.180347030430679
Validation loss: 2.496674478785828

Epoch: 392| Step: 0
Training loss: 0.33779796807283297
Validation loss: 2.5171541664192345

Epoch: 6| Step: 1
Training loss: 0.22106020238198393
Validation loss: 2.498239149355154

Epoch: 6| Step: 2
Training loss: 0.29170125801591956
Validation loss: 2.5317280372515776

Epoch: 6| Step: 3
Training loss: 0.1386840438876298
Validation loss: 2.5203377444933333

Epoch: 6| Step: 4
Training loss: 0.13897911475671482
Validation loss: 2.551248765458494

Epoch: 6| Step: 5
Training loss: 0.3700478118857564
Validation loss: 2.548106406378073

Epoch: 6| Step: 6
Training loss: 0.3085314530857144
Validation loss: 2.5622979081182082

Epoch: 6| Step: 7
Training loss: 0.12434141816917332
Validation loss: 2.569627895271292

Epoch: 6| Step: 8
Training loss: 0.19127672055519765
Validation loss: 2.5710753945579343

Epoch: 6| Step: 9
Training loss: 0.3232984925986846
Validation loss: 2.553863519953875

Epoch: 6| Step: 10
Training loss: 0.39934054120072626
Validation loss: 2.4964883033425185

Epoch: 6| Step: 11
Training loss: 0.22173633775856447
Validation loss: 2.4946422005915463

Epoch: 6| Step: 12
Training loss: 0.22898069154242456
Validation loss: 2.5006632940154394

Epoch: 6| Step: 13
Training loss: 0.26683179813882957
Validation loss: 2.472165360172629

Epoch: 393| Step: 0
Training loss: 0.2614215615366232
Validation loss: 2.499890415292002

Epoch: 6| Step: 1
Training loss: 0.19163543254039883
Validation loss: 2.4989993420551

Epoch: 6| Step: 2
Training loss: 0.23403612115522368
Validation loss: 2.460885948244102

Epoch: 6| Step: 3
Training loss: 0.20608475994489656
Validation loss: 2.4592164709139426

Epoch: 6| Step: 4
Training loss: 0.2232692628663277
Validation loss: 2.5153077504537515

Epoch: 6| Step: 5
Training loss: 0.16171928949312164
Validation loss: 2.5256606942598534

Epoch: 6| Step: 6
Training loss: 0.20671449577584686
Validation loss: 2.472809608140034

Epoch: 6| Step: 7
Training loss: 0.2587939135978473
Validation loss: 2.4871931519483113

Epoch: 6| Step: 8
Training loss: 0.4714174667202357
Validation loss: 2.502458370668468

Epoch: 6| Step: 9
Training loss: 0.1981459698876298
Validation loss: 2.507299353403392

Epoch: 6| Step: 10
Training loss: 0.3235538052412506
Validation loss: 2.4929928849752954

Epoch: 6| Step: 11
Training loss: 0.14508157424031057
Validation loss: 2.487391287419791

Epoch: 6| Step: 12
Training loss: 0.25154352531190854
Validation loss: 2.4665013273955188

Epoch: 6| Step: 13
Training loss: 0.14621031236935322
Validation loss: 2.4746752353829002

Epoch: 394| Step: 0
Training loss: 0.279415118923294
Validation loss: 2.455388503825911

Epoch: 6| Step: 1
Training loss: 0.17571424690757328
Validation loss: 2.4727075045263596

Epoch: 6| Step: 2
Training loss: 0.21973963380716424
Validation loss: 2.4906499054570435

Epoch: 6| Step: 3
Training loss: 0.3582105845898697
Validation loss: 2.4970017430324956

Epoch: 6| Step: 4
Training loss: 0.15323552137817179
Validation loss: 2.5248686991370555

Epoch: 6| Step: 5
Training loss: 0.3283253466817585
Validation loss: 2.4986291008178916

Epoch: 6| Step: 6
Training loss: 0.30201946876941943
Validation loss: 2.5125349446123972

Epoch: 6| Step: 7
Training loss: 0.25207875690299425
Validation loss: 2.499466902796891

Epoch: 6| Step: 8
Training loss: 0.11254013921665504
Validation loss: 2.4559793027909116

Epoch: 6| Step: 9
Training loss: 0.30165551436123234
Validation loss: 2.476104446564961

Epoch: 6| Step: 10
Training loss: 0.20156263159222707
Validation loss: 2.5160096596134727

Epoch: 6| Step: 11
Training loss: 0.23773844444359685
Validation loss: 2.475820503530347

Epoch: 6| Step: 12
Training loss: 0.2075324200386251
Validation loss: 2.477382155885461

Epoch: 6| Step: 13
Training loss: 0.19923783192220715
Validation loss: 2.5196117966001306

Epoch: 395| Step: 0
Training loss: 0.2783286244004528
Validation loss: 2.4805288149771996

Epoch: 6| Step: 1
Training loss: 0.28527638765658997
Validation loss: 2.50473085160105

Epoch: 6| Step: 2
Training loss: 0.13900381307208867
Validation loss: 2.4970817253328126

Epoch: 6| Step: 3
Training loss: 0.18841043606902377
Validation loss: 2.4869281045630096

Epoch: 6| Step: 4
Training loss: 0.21655072165051648
Validation loss: 2.504043240297117

Epoch: 6| Step: 5
Training loss: 0.2138212058746152
Validation loss: 2.516522991635

Epoch: 6| Step: 6
Training loss: 0.17547967790966731
Validation loss: 2.518569910171173

Epoch: 6| Step: 7
Training loss: 0.21155268536485985
Validation loss: 2.5263033312823144

Epoch: 6| Step: 8
Training loss: 0.1972788626884266
Validation loss: 2.5041103474708213

Epoch: 6| Step: 9
Training loss: 0.3169766100841915
Validation loss: 2.5017221553977294

Epoch: 6| Step: 10
Training loss: 0.15634301516466764
Validation loss: 2.5377085135067907

Epoch: 6| Step: 11
Training loss: 0.35992064724003364
Validation loss: 2.5401343812583925

Epoch: 6| Step: 12
Training loss: 0.16459223963586078
Validation loss: 2.5355407381820854

Epoch: 6| Step: 13
Training loss: 0.3664414151038029
Validation loss: 2.529366550459063

Epoch: 396| Step: 0
Training loss: 0.1785539030943711
Validation loss: 2.524150030924763

Epoch: 6| Step: 1
Training loss: 0.3058938207997692
Validation loss: 2.5137793954618557

Epoch: 6| Step: 2
Training loss: 0.13603761483166305
Validation loss: 2.5389649751548062

Epoch: 6| Step: 3
Training loss: 0.1714006130313955
Validation loss: 2.5337759915052547

Epoch: 6| Step: 4
Training loss: 0.30910377365704034
Validation loss: 2.549520900194985

Epoch: 6| Step: 5
Training loss: 0.11693889155444258
Validation loss: 2.515746256196931

Epoch: 6| Step: 6
Training loss: 0.19617933556131412
Validation loss: 2.534745687399633

Epoch: 6| Step: 7
Training loss: 0.2439132547197467
Validation loss: 2.5573198556562944

Epoch: 6| Step: 8
Training loss: 0.30902830744756293
Validation loss: 2.5660691454992572

Epoch: 6| Step: 9
Training loss: 0.3286940771483211
Validation loss: 2.5329539535359826

Epoch: 6| Step: 10
Training loss: 0.21249161521413523
Validation loss: 2.509412990110813

Epoch: 6| Step: 11
Training loss: 0.23851723007876588
Validation loss: 2.525692932664146

Epoch: 6| Step: 12
Training loss: 0.12473125924413679
Validation loss: 2.5213465966842774

Epoch: 6| Step: 13
Training loss: 0.25529986640928176
Validation loss: 2.5583132805144775

Epoch: 397| Step: 0
Training loss: 0.15018705734762364
Validation loss: 2.5707399778504074

Epoch: 6| Step: 1
Training loss: 0.19206265371994882
Validation loss: 2.533104534562857

Epoch: 6| Step: 2
Training loss: 0.23125205039069033
Validation loss: 2.5446840806849362

Epoch: 6| Step: 3
Training loss: 0.2890020513478242
Validation loss: 2.5610010838951633

Epoch: 6| Step: 4
Training loss: 0.1940324512658923
Validation loss: 2.551093099288828

Epoch: 6| Step: 5
Training loss: 0.3409862169167841
Validation loss: 2.5323594534611167

Epoch: 6| Step: 6
Training loss: 0.28175881507660255
Validation loss: 2.484681056751018

Epoch: 6| Step: 7
Training loss: 0.16483536965641066
Validation loss: 2.4760650221031217

Epoch: 6| Step: 8
Training loss: 0.20199115365611622
Validation loss: 2.465764139502764

Epoch: 6| Step: 9
Training loss: 0.37254703448800597
Validation loss: 2.4662199138659453

Epoch: 6| Step: 10
Training loss: 0.24178879744390613
Validation loss: 2.466179771088902

Epoch: 6| Step: 11
Training loss: 0.28017847931428025
Validation loss: 2.474481498871238

Epoch: 6| Step: 12
Training loss: 0.17901109804814191
Validation loss: 2.487246550738262

Epoch: 6| Step: 13
Training loss: 0.2289413659563169
Validation loss: 2.515603597044603

Epoch: 398| Step: 0
Training loss: 0.11498668689479695
Validation loss: 2.5719504689244297

Epoch: 6| Step: 1
Training loss: 0.23439994520316526
Validation loss: 2.5354969286139477

Epoch: 6| Step: 2
Training loss: 0.2942172595293781
Validation loss: 2.582729561463818

Epoch: 6| Step: 3
Training loss: 0.28707044687863614
Validation loss: 2.6035115474196378

Epoch: 6| Step: 4
Training loss: 0.31432757033111275
Validation loss: 2.601149148057625

Epoch: 6| Step: 5
Training loss: 0.24606677316216177
Validation loss: 2.531910358329619

Epoch: 6| Step: 6
Training loss: 0.16078543932825798
Validation loss: 2.5101820212678922

Epoch: 6| Step: 7
Training loss: 0.23254448998254781
Validation loss: 2.5238827863300513

Epoch: 6| Step: 8
Training loss: 0.2916319803775168
Validation loss: 2.4810451833527103

Epoch: 6| Step: 9
Training loss: 0.21649335974031472
Validation loss: 2.504278155651751

Epoch: 6| Step: 10
Training loss: 0.3897448733508283
Validation loss: 2.445744209771184

Epoch: 6| Step: 11
Training loss: 0.24206218245997876
Validation loss: 2.4186298727501345

Epoch: 6| Step: 12
Training loss: 0.17342102943432175
Validation loss: 2.422921876514931

Epoch: 6| Step: 13
Training loss: 0.2781510223044851
Validation loss: 2.41949458641556

Epoch: 399| Step: 0
Training loss: 0.24340038994863286
Validation loss: 2.3945140717896334

Epoch: 6| Step: 1
Training loss: 0.2250357188906896
Validation loss: 2.462066504962603

Epoch: 6| Step: 2
Training loss: 0.20280383469183966
Validation loss: 2.492574388051405

Epoch: 6| Step: 3
Training loss: 0.3889838073996015
Validation loss: 2.5097462048103822

Epoch: 6| Step: 4
Training loss: 0.23443691707366743
Validation loss: 2.5067327766034126

Epoch: 6| Step: 5
Training loss: 0.27087858934581277
Validation loss: 2.510144241686407

Epoch: 6| Step: 6
Training loss: 0.340181577420336
Validation loss: 2.5284205961878503

Epoch: 6| Step: 7
Training loss: 0.19214700877074717
Validation loss: 2.49991928606074

Epoch: 6| Step: 8
Training loss: 0.22768790979895623
Validation loss: 2.491684889087996

Epoch: 6| Step: 9
Training loss: 0.3232324028262921
Validation loss: 2.5028936436734424

Epoch: 6| Step: 10
Training loss: 0.2512442797393972
Validation loss: 2.4992302181173867

Epoch: 6| Step: 11
Training loss: 0.23679318658315315
Validation loss: 2.500189482778644

Epoch: 6| Step: 12
Training loss: 0.18847808441970745
Validation loss: 2.5032950334197204

Epoch: 6| Step: 13
Training loss: 0.2382396520982273
Validation loss: 2.5111110753838672

Epoch: 400| Step: 0
Training loss: 0.2110848089056878
Validation loss: 2.5042639578548

Epoch: 6| Step: 1
Training loss: 0.16249174959072468
Validation loss: 2.5078331138221857

Epoch: 6| Step: 2
Training loss: 0.23200943359410844
Validation loss: 2.527239307135325

Epoch: 6| Step: 3
Training loss: 0.19638091637885444
Validation loss: 2.5573504408832024

Epoch: 6| Step: 4
Training loss: 0.17772889390815025
Validation loss: 2.5265766584963454

Epoch: 6| Step: 5
Training loss: 0.267710993836439
Validation loss: 2.549523102322673

Epoch: 6| Step: 6
Training loss: 0.15298972358155208
Validation loss: 2.5694807227612197

Epoch: 6| Step: 7
Training loss: 0.2994066012274638
Validation loss: 2.5288120735271757

Epoch: 6| Step: 8
Training loss: 0.3265215889159291
Validation loss: 2.513064265886682

Epoch: 6| Step: 9
Training loss: 0.2518103734823967
Validation loss: 2.5184704557588775

Epoch: 6| Step: 10
Training loss: 0.24731427236928857
Validation loss: 2.494736292270726

Epoch: 6| Step: 11
Training loss: 0.3543596256291717
Validation loss: 2.4484581344330456

Epoch: 6| Step: 12
Training loss: 0.20168670036244876
Validation loss: 2.482903750005778

Epoch: 6| Step: 13
Training loss: 0.21865363212229727
Validation loss: 2.481248385058272

Epoch: 401| Step: 0
Training loss: 0.224352880891208
Validation loss: 2.481474553352034

Epoch: 6| Step: 1
Training loss: 0.22581879458719842
Validation loss: 2.5135401919402987

Epoch: 6| Step: 2
Training loss: 0.14677117563816472
Validation loss: 2.497612337520486

Epoch: 6| Step: 3
Training loss: 0.180675269114393
Validation loss: 2.5306096671659026

Epoch: 6| Step: 4
Training loss: 0.30108753314724207
Validation loss: 2.5344563580241233

Epoch: 6| Step: 5
Training loss: 0.2697853052034894
Validation loss: 2.5336369965418637

Epoch: 6| Step: 6
Training loss: 0.22761948437216792
Validation loss: 2.5507936099685984

Epoch: 6| Step: 7
Training loss: 0.24814353771528752
Validation loss: 2.519025248421961

Epoch: 6| Step: 8
Training loss: 0.18878580330123698
Validation loss: 2.544722215384086

Epoch: 6| Step: 9
Training loss: 0.111597221137857
Validation loss: 2.5249147902952496

Epoch: 6| Step: 10
Training loss: 0.21487064193269478
Validation loss: 2.5126514004932816

Epoch: 6| Step: 11
Training loss: 0.3150891807502547
Validation loss: 2.553030588039076

Epoch: 6| Step: 12
Training loss: 0.2300852963895642
Validation loss: 2.565245119657848

Epoch: 6| Step: 13
Training loss: 0.2107925358430937
Validation loss: 2.6089698811552093

Epoch: 402| Step: 0
Training loss: 0.14643754210453186
Validation loss: 2.564005727753644

Epoch: 6| Step: 1
Training loss: 0.3346551327766437
Validation loss: 2.557230997031092

Epoch: 6| Step: 2
Training loss: 0.14740778742011318
Validation loss: 2.5644996278401817

Epoch: 6| Step: 3
Training loss: 0.12342070377734406
Validation loss: 2.570327074216732

Epoch: 6| Step: 4
Training loss: 0.18899194882794
Validation loss: 2.545276879532524

Epoch: 6| Step: 5
Training loss: 0.23593943923506921
Validation loss: 2.554735973327656

Epoch: 6| Step: 6
Training loss: 0.17402678292737614
Validation loss: 2.559038375751141

Epoch: 6| Step: 7
Training loss: 0.21337028154274768
Validation loss: 2.5149665204595655

Epoch: 6| Step: 8
Training loss: 0.2549269627008753
Validation loss: 2.5164913539649643

Epoch: 6| Step: 9
Training loss: 0.19506872222446503
Validation loss: 2.495039583038873

Epoch: 6| Step: 10
Training loss: 0.32120850315444965
Validation loss: 2.4987784262219113

Epoch: 6| Step: 11
Training loss: 0.25245244428161917
Validation loss: 2.5249833053545427

Epoch: 6| Step: 12
Training loss: 0.29726430814955146
Validation loss: 2.5385534526216693

Epoch: 6| Step: 13
Training loss: 0.1487674747248274
Validation loss: 2.524558426871836

Epoch: 403| Step: 0
Training loss: 0.22839229874951145
Validation loss: 2.519393332311533

Epoch: 6| Step: 1
Training loss: 0.19090388994917126
Validation loss: 2.539423567196792

Epoch: 6| Step: 2
Training loss: 0.12186215391070784
Validation loss: 2.502975663879004

Epoch: 6| Step: 3
Training loss: 0.29539232436657076
Validation loss: 2.5181092042187565

Epoch: 6| Step: 4
Training loss: 0.17001490950944395
Validation loss: 2.543383464501682

Epoch: 6| Step: 5
Training loss: 0.16675448091082623
Validation loss: 2.5447007488818736

Epoch: 6| Step: 6
Training loss: 0.23381804411697626
Validation loss: 2.5417860333597786

Epoch: 6| Step: 7
Training loss: 0.2726537917499067
Validation loss: 2.5568786137808854

Epoch: 6| Step: 8
Training loss: 0.4082781344038306
Validation loss: 2.5253691657338146

Epoch: 6| Step: 9
Training loss: 0.27240837437855014
Validation loss: 2.5163673946665357

Epoch: 6| Step: 10
Training loss: 0.20344435822372314
Validation loss: 2.4998253412660185

Epoch: 6| Step: 11
Training loss: 0.11781686026627135
Validation loss: 2.5140258336895984

Epoch: 6| Step: 12
Training loss: 0.21487633718093396
Validation loss: 2.500326286065761

Epoch: 6| Step: 13
Training loss: 0.1917960712703483
Validation loss: 2.537060782654576

Epoch: 404| Step: 0
Training loss: 0.11451471822871248
Validation loss: 2.531939071553481

Epoch: 6| Step: 1
Training loss: 0.28041681749265185
Validation loss: 2.5184688158641553

Epoch: 6| Step: 2
Training loss: 0.26008150785474315
Validation loss: 2.533353837949783

Epoch: 6| Step: 3
Training loss: 0.11392687285116289
Validation loss: 2.542165368059288

Epoch: 6| Step: 4
Training loss: 0.2610787922828234
Validation loss: 2.571473101826723

Epoch: 6| Step: 5
Training loss: 0.31841784215340924
Validation loss: 2.5361151746858623

Epoch: 6| Step: 6
Training loss: 0.13289692943942435
Validation loss: 2.5867304765695875

Epoch: 6| Step: 7
Training loss: 0.17360748260732853
Validation loss: 2.53498124152268

Epoch: 6| Step: 8
Training loss: 0.24020841504768597
Validation loss: 2.5336289999409525

Epoch: 6| Step: 9
Training loss: 0.162277605480463
Validation loss: 2.5316402843883767

Epoch: 6| Step: 10
Training loss: 0.2856836536710195
Validation loss: 2.554472478050324

Epoch: 6| Step: 11
Training loss: 0.20871164226466538
Validation loss: 2.5262269842136074

Epoch: 6| Step: 12
Training loss: 0.20377269514624546
Validation loss: 2.5318679025006667

Epoch: 6| Step: 13
Training loss: 0.15388198796851377
Validation loss: 2.5163250907378782

Epoch: 405| Step: 0
Training loss: 0.24958017981441674
Validation loss: 2.479087609795135

Epoch: 6| Step: 1
Training loss: 0.18999558879725822
Validation loss: 2.512646300043398

Epoch: 6| Step: 2
Training loss: 0.20187036305230738
Validation loss: 2.5578700150685716

Epoch: 6| Step: 3
Training loss: 0.30309517802200875
Validation loss: 2.5254168795890717

Epoch: 6| Step: 4
Training loss: 0.20083811767275633
Validation loss: 2.507351570959928

Epoch: 6| Step: 5
Training loss: 0.3127958089775169
Validation loss: 2.5358963079002503

Epoch: 6| Step: 6
Training loss: 0.29813199209015057
Validation loss: 2.588718955833141

Epoch: 6| Step: 7
Training loss: 0.2874902806505045
Validation loss: 2.5285944933394995

Epoch: 6| Step: 8
Training loss: 0.19178418391362517
Validation loss: 2.524176943345415

Epoch: 6| Step: 9
Training loss: 0.15801897634292286
Validation loss: 2.553412785335592

Epoch: 6| Step: 10
Training loss: 0.23927927504829585
Validation loss: 2.5330685274208133

Epoch: 6| Step: 11
Training loss: 0.1867214270523525
Validation loss: 2.518075929020044

Epoch: 6| Step: 12
Training loss: 0.1450590150559156
Validation loss: 2.455907342263692

Epoch: 6| Step: 13
Training loss: 0.11014798468159785
Validation loss: 2.507001893348963

Epoch: 406| Step: 0
Training loss: 0.13010971069613309
Validation loss: 2.507684063841872

Epoch: 6| Step: 1
Training loss: 0.11776243477916622
Validation loss: 2.4669397429816757

Epoch: 6| Step: 2
Training loss: 0.16963909450190903
Validation loss: 2.5047277938349555

Epoch: 6| Step: 3
Training loss: 0.28191176020424924
Validation loss: 2.4520706597834443

Epoch: 6| Step: 4
Training loss: 0.13519236131834617
Validation loss: 2.5230965647670454

Epoch: 6| Step: 5
Training loss: 0.1838615574490401
Validation loss: 2.4976768133277103

Epoch: 6| Step: 6
Training loss: 0.2865579200802959
Validation loss: 2.537806769517803

Epoch: 6| Step: 7
Training loss: 0.30758428246243064
Validation loss: 2.567094597010397

Epoch: 6| Step: 8
Training loss: 0.28366380251926365
Validation loss: 2.5113394151978956

Epoch: 6| Step: 9
Training loss: 0.14155887091744868
Validation loss: 2.535929276482081

Epoch: 6| Step: 10
Training loss: 0.15182521187457987
Validation loss: 2.5440584189520057

Epoch: 6| Step: 11
Training loss: 0.2853612554785127
Validation loss: 2.512934267947374

Epoch: 6| Step: 12
Training loss: 0.278671016921724
Validation loss: 2.4643162438400776

Epoch: 6| Step: 13
Training loss: 0.180044772685982
Validation loss: 2.476476907278087

Epoch: 407| Step: 0
Training loss: 0.13206006531337391
Validation loss: 2.491314564134947

Epoch: 6| Step: 1
Training loss: 0.2581955491655613
Validation loss: 2.495516324957962

Epoch: 6| Step: 2
Training loss: 0.29474505751350993
Validation loss: 2.482945626482091

Epoch: 6| Step: 3
Training loss: 0.19104613273091414
Validation loss: 2.497759021776245

Epoch: 6| Step: 4
Training loss: 0.17133391346613686
Validation loss: 2.480969193999195

Epoch: 6| Step: 5
Training loss: 0.19308334453801154
Validation loss: 2.4677520984381673

Epoch: 6| Step: 6
Training loss: 0.17182275129655056
Validation loss: 2.5205196984515847

Epoch: 6| Step: 7
Training loss: 0.22976424952578148
Validation loss: 2.531584815403024

Epoch: 6| Step: 8
Training loss: 0.2318037774035766
Validation loss: 2.502475164402348

Epoch: 6| Step: 9
Training loss: 0.21474468374721845
Validation loss: 2.5426803371631452

Epoch: 6| Step: 10
Training loss: 0.27199392732071737
Validation loss: 2.5187278276145086

Epoch: 6| Step: 11
Training loss: 0.3222509901018225
Validation loss: 2.5170665573071482

Epoch: 6| Step: 12
Training loss: 0.2520878453809822
Validation loss: 2.5143223307280107

Epoch: 6| Step: 13
Training loss: 0.17073198113867064
Validation loss: 2.530196994411307

Epoch: 408| Step: 0
Training loss: 0.15083112237778132
Validation loss: 2.5660642481338027

Epoch: 6| Step: 1
Training loss: 0.2836303119893317
Validation loss: 2.5750902996563796

Epoch: 6| Step: 2
Training loss: 0.13940385594607232
Validation loss: 2.5130798166298387

Epoch: 6| Step: 3
Training loss: 0.2027556196926201
Validation loss: 2.5520134406264163

Epoch: 6| Step: 4
Training loss: 0.13402763035485565
Validation loss: 2.5510193874523672

Epoch: 6| Step: 5
Training loss: 0.23842600818503673
Validation loss: 2.570325516092628

Epoch: 6| Step: 6
Training loss: 0.2799864173259892
Validation loss: 2.542801961678819

Epoch: 6| Step: 7
Training loss: 0.2895862371084138
Validation loss: 2.523476277314436

Epoch: 6| Step: 8
Training loss: 0.3270410162082139
Validation loss: 2.497540959641279

Epoch: 6| Step: 9
Training loss: 0.1368736343446301
Validation loss: 2.5070912090529576

Epoch: 6| Step: 10
Training loss: 0.15089277555551361
Validation loss: 2.51237247975836

Epoch: 6| Step: 11
Training loss: 0.13007903514005242
Validation loss: 2.4863863033422806

Epoch: 6| Step: 12
Training loss: 0.14899986800645576
Validation loss: 2.5074092057820287

Epoch: 6| Step: 13
Training loss: 0.2211356692794207
Validation loss: 2.459166851289373

Epoch: 409| Step: 0
Training loss: 0.23627475261949749
Validation loss: 2.4825540329941527

Epoch: 6| Step: 1
Training loss: 0.18638969539730624
Validation loss: 2.5062721389554947

Epoch: 6| Step: 2
Training loss: 0.34459383303149255
Validation loss: 2.522464889985635

Epoch: 6| Step: 3
Training loss: 0.21111532062975158
Validation loss: 2.5425611509272144

Epoch: 6| Step: 4
Training loss: 0.24926931173261627
Validation loss: 2.5064044319612546

Epoch: 6| Step: 5
Training loss: 0.1251544668544467
Validation loss: 2.5320093000254444

Epoch: 6| Step: 6
Training loss: 0.1751371557188363
Validation loss: 2.491664625246509

Epoch: 6| Step: 7
Training loss: 0.16352171553465594
Validation loss: 2.503830258219021

Epoch: 6| Step: 8
Training loss: 0.2170842988974489
Validation loss: 2.5412828751445353

Epoch: 6| Step: 9
Training loss: 0.20513499243513914
Validation loss: 2.5089556524403775

Epoch: 6| Step: 10
Training loss: 0.3226972752460505
Validation loss: 2.5168540447486887

Epoch: 6| Step: 11
Training loss: 0.13665749676351793
Validation loss: 2.4736105010622547

Epoch: 6| Step: 12
Training loss: 0.1452535160906313
Validation loss: 2.511516007808285

Epoch: 6| Step: 13
Training loss: 0.15568588467636318
Validation loss: 2.478472603108462

Epoch: 410| Step: 0
Training loss: 0.2149869528265936
Validation loss: 2.525460527886465

Epoch: 6| Step: 1
Training loss: 0.3478759221624337
Validation loss: 2.5228614597928094

Epoch: 6| Step: 2
Training loss: 0.2576394078040117
Validation loss: 2.525810073944813

Epoch: 6| Step: 3
Training loss: 0.19879100730395927
Validation loss: 2.4893275293536457

Epoch: 6| Step: 4
Training loss: 0.18143009988435432
Validation loss: 2.496375727032426

Epoch: 6| Step: 5
Training loss: 0.1818284427561044
Validation loss: 2.480769750657764

Epoch: 6| Step: 6
Training loss: 0.2847267077190873
Validation loss: 2.4947999263070684

Epoch: 6| Step: 7
Training loss: 0.2294016720442711
Validation loss: 2.5023852813213407

Epoch: 6| Step: 8
Training loss: 0.17018860676574024
Validation loss: 2.50283540808505

Epoch: 6| Step: 9
Training loss: 0.17587580257136404
Validation loss: 2.495112773514971

Epoch: 6| Step: 10
Training loss: 0.2893452163924458
Validation loss: 2.5238769335564797

Epoch: 6| Step: 11
Training loss: 0.16004943193022328
Validation loss: 2.4787198232154735

Epoch: 6| Step: 12
Training loss: 0.15547566470387306
Validation loss: 2.500744411429124

Epoch: 6| Step: 13
Training loss: 0.2188922300484807
Validation loss: 2.474359341014734

Epoch: 411| Step: 0
Training loss: 0.24473431689861985
Validation loss: 2.5121705852857574

Epoch: 6| Step: 1
Training loss: 0.09755726566117143
Validation loss: 2.5148504398880345

Epoch: 6| Step: 2
Training loss: 0.1961015688336648
Validation loss: 2.526982643399227

Epoch: 6| Step: 3
Training loss: 0.15233022678704447
Validation loss: 2.513514371203518

Epoch: 6| Step: 4
Training loss: 0.31552443838006805
Validation loss: 2.5207048876819305

Epoch: 6| Step: 5
Training loss: 0.15316961864540019
Validation loss: 2.5069394530903373

Epoch: 6| Step: 6
Training loss: 0.2952498197894148
Validation loss: 2.536127155797431

Epoch: 6| Step: 7
Training loss: 0.29590045185473596
Validation loss: 2.523500889290201

Epoch: 6| Step: 8
Training loss: 0.20861786049362605
Validation loss: 2.508276089116016

Epoch: 6| Step: 9
Training loss: 0.24644021214437417
Validation loss: 2.4951893611095795

Epoch: 6| Step: 10
Training loss: 0.17291468744600644
Validation loss: 2.5329687799649054

Epoch: 6| Step: 11
Training loss: 0.17236825217192375
Validation loss: 2.525036476322173

Epoch: 6| Step: 12
Training loss: 0.1752856367272645
Validation loss: 2.5227089828466216

Epoch: 6| Step: 13
Training loss: 0.11994377271799
Validation loss: 2.48906705053425

Epoch: 412| Step: 0
Training loss: 0.1693424342404047
Validation loss: 2.5311156874935783

Epoch: 6| Step: 1
Training loss: 0.13521117351288986
Validation loss: 2.5356125776027185

Epoch: 6| Step: 2
Training loss: 0.17456102171079704
Validation loss: 2.5185403798356454

Epoch: 6| Step: 3
Training loss: 0.35267372412566733
Validation loss: 2.5049707402684422

Epoch: 6| Step: 4
Training loss: 0.17274358038180918
Validation loss: 2.516625917258675

Epoch: 6| Step: 5
Training loss: 0.2239057216651364
Validation loss: 2.5053473862883653

Epoch: 6| Step: 6
Training loss: 0.12486495233041389
Validation loss: 2.512150406069496

Epoch: 6| Step: 7
Training loss: 0.31007249455567354
Validation loss: 2.4876348595688262

Epoch: 6| Step: 8
Training loss: 0.18371042642881216
Validation loss: 2.512693584153269

Epoch: 6| Step: 9
Training loss: 0.10679953371602059
Validation loss: 2.5434935777207435

Epoch: 6| Step: 10
Training loss: 0.22612031998016685
Validation loss: 2.4911283668281583

Epoch: 6| Step: 11
Training loss: 0.23129543650650825
Validation loss: 2.543602824437666

Epoch: 6| Step: 12
Training loss: 0.20731716386576363
Validation loss: 2.5081867343475324

Epoch: 6| Step: 13
Training loss: 0.21319104791908144
Validation loss: 2.544956474398596

Epoch: 413| Step: 0
Training loss: 0.2897057721528487
Validation loss: 2.5260167707496217

Epoch: 6| Step: 1
Training loss: 0.1246951005645991
Validation loss: 2.5306939988417896

Epoch: 6| Step: 2
Training loss: 0.08308457303507286
Validation loss: 2.4938809028041433

Epoch: 6| Step: 3
Training loss: 0.13937846677685262
Validation loss: 2.5385003221488334

Epoch: 6| Step: 4
Training loss: 0.11543143121012278
Validation loss: 2.5207173808871763

Epoch: 6| Step: 5
Training loss: 0.17727323592261388
Validation loss: 2.4929424280064314

Epoch: 6| Step: 6
Training loss: 0.27135983361729155
Validation loss: 2.486147051412587

Epoch: 6| Step: 7
Training loss: 0.29422434999522334
Validation loss: 2.5069948599497978

Epoch: 6| Step: 8
Training loss: 0.22532113952844704
Validation loss: 2.4930190910166243

Epoch: 6| Step: 9
Training loss: 0.23064880288318065
Validation loss: 2.506689288891555

Epoch: 6| Step: 10
Training loss: 0.15298219317786668
Validation loss: 2.5091462226579697

Epoch: 6| Step: 11
Training loss: 0.17762923012541335
Validation loss: 2.5108824825244302

Epoch: 6| Step: 12
Training loss: 0.1348182050437784
Validation loss: 2.5552870697967798

Epoch: 6| Step: 13
Training loss: 0.20619590042533997
Validation loss: 2.536842553261587

Epoch: 414| Step: 0
Training loss: 0.10101110450472013
Validation loss: 2.5087186459016335

Epoch: 6| Step: 1
Training loss: 0.21372393160519612
Validation loss: 2.5053459245502703

Epoch: 6| Step: 2
Training loss: 0.10098240778253946
Validation loss: 2.5161203151417255

Epoch: 6| Step: 3
Training loss: 0.1875495745766426
Validation loss: 2.534668662085552

Epoch: 6| Step: 4
Training loss: 0.14882219808396155
Validation loss: 2.5009695019053955

Epoch: 6| Step: 5
Training loss: 0.1808801132407376
Validation loss: 2.489292168080759

Epoch: 6| Step: 6
Training loss: 0.19485599574172702
Validation loss: 2.483008709347923

Epoch: 6| Step: 7
Training loss: 0.2879460269823791
Validation loss: 2.5036647464451143

Epoch: 6| Step: 8
Training loss: 0.1359927040673657
Validation loss: 2.454516501402848

Epoch: 6| Step: 9
Training loss: 0.33182955955227256
Validation loss: 2.5248357734650053

Epoch: 6| Step: 10
Training loss: 0.2568962838527792
Validation loss: 2.536561529782414

Epoch: 6| Step: 11
Training loss: 0.3080192965324146
Validation loss: 2.5568098775563683

Epoch: 6| Step: 12
Training loss: 0.2976295644457388
Validation loss: 2.585624342511771

Epoch: 6| Step: 13
Training loss: 0.2546585528767788
Validation loss: 2.5911420819127633

Epoch: 415| Step: 0
Training loss: 0.19351857307477
Validation loss: 2.5723090276109346

Epoch: 6| Step: 1
Training loss: 0.20895446135437976
Validation loss: 2.555159476862893

Epoch: 6| Step: 2
Training loss: 0.3618330443310971
Validation loss: 2.544717457770801

Epoch: 6| Step: 3
Training loss: 0.17952507390221425
Validation loss: 2.5395825107069774

Epoch: 6| Step: 4
Training loss: 0.2823338552154513
Validation loss: 2.53485372077401

Epoch: 6| Step: 5
Training loss: 0.1764814260319998
Validation loss: 2.508237248517754

Epoch: 6| Step: 6
Training loss: 0.20697270771258877
Validation loss: 2.472115244464845

Epoch: 6| Step: 7
Training loss: 0.3119193165622644
Validation loss: 2.463062274507823

Epoch: 6| Step: 8
Training loss: 0.1854371298434964
Validation loss: 2.5015175100202853

Epoch: 6| Step: 9
Training loss: 0.1832957893549498
Validation loss: 2.4948134231997408

Epoch: 6| Step: 10
Training loss: 0.18587009987468092
Validation loss: 2.5316165854596697

Epoch: 6| Step: 11
Training loss: 0.13914418714484034
Validation loss: 2.539700655699689

Epoch: 6| Step: 12
Training loss: 0.1579538017259962
Validation loss: 2.4844060797723064

Epoch: 6| Step: 13
Training loss: 0.10967501297540459
Validation loss: 2.51617683213263

Epoch: 416| Step: 0
Training loss: 0.27645546409787236
Validation loss: 2.53089576793801

Epoch: 6| Step: 1
Training loss: 0.25047272453557634
Validation loss: 2.517049763149943

Epoch: 6| Step: 2
Training loss: 0.20126285162460783
Validation loss: 2.51986736915114

Epoch: 6| Step: 3
Training loss: 0.2408312307019058
Validation loss: 2.496041901366229

Epoch: 6| Step: 4
Training loss: 0.2642194642565439
Validation loss: 2.4673520324468643

Epoch: 6| Step: 5
Training loss: 0.25513679448909027
Validation loss: 2.4931439093954992

Epoch: 6| Step: 6
Training loss: 0.3771157383386827
Validation loss: 2.541618899120619

Epoch: 6| Step: 7
Training loss: 0.1957688912085623
Validation loss: 2.491822169058837

Epoch: 6| Step: 8
Training loss: 0.185484032278489
Validation loss: 2.516098215399814

Epoch: 6| Step: 9
Training loss: 0.18829386261288875
Validation loss: 2.5172337935607496

Epoch: 6| Step: 10
Training loss: 0.16902074067177386
Validation loss: 2.465180831182299

Epoch: 6| Step: 11
Training loss: 0.20642924503391172
Validation loss: 2.4742509001624073

Epoch: 6| Step: 12
Training loss: 0.17510360328970223
Validation loss: 2.53003118297759

Epoch: 6| Step: 13
Training loss: 0.1972605544090109
Validation loss: 2.552775497614337

Epoch: 417| Step: 0
Training loss: 0.14978053459014137
Validation loss: 2.5404561665418717

Epoch: 6| Step: 1
Training loss: 0.3561437506929557
Validation loss: 2.526165148033535

Epoch: 6| Step: 2
Training loss: 0.2939698978927616
Validation loss: 2.566088281300695

Epoch: 6| Step: 3
Training loss: 0.2340770735233556
Validation loss: 2.5854964877029123

Epoch: 6| Step: 4
Training loss: 0.25029951273817
Validation loss: 2.5503980431695963

Epoch: 6| Step: 5
Training loss: 0.28214373577646784
Validation loss: 2.556769016357061

Epoch: 6| Step: 6
Training loss: 0.19315802561831455
Validation loss: 2.5152886380521657

Epoch: 6| Step: 7
Training loss: 0.2012725133920191
Validation loss: 2.517821071660734

Epoch: 6| Step: 8
Training loss: 0.19204240299424966
Validation loss: 2.5180646332301433

Epoch: 6| Step: 9
Training loss: 0.13951018632594303
Validation loss: 2.519029853052844

Epoch: 6| Step: 10
Training loss: 0.18452404592794813
Validation loss: 2.4996530845882683

Epoch: 6| Step: 11
Training loss: 0.14665216373088813
Validation loss: 2.528345020797223

Epoch: 6| Step: 12
Training loss: 0.2676941696581234
Validation loss: 2.5178666559771012

Epoch: 6| Step: 13
Training loss: 0.19648837887455606
Validation loss: 2.5035839898887673

Epoch: 418| Step: 0
Training loss: 0.18087455240917913
Validation loss: 2.5387843704290276

Epoch: 6| Step: 1
Training loss: 0.2416126288776053
Validation loss: 2.5632157905478135

Epoch: 6| Step: 2
Training loss: 0.11707921588378795
Validation loss: 2.56261888013677

Epoch: 6| Step: 3
Training loss: 0.34366435371176207
Validation loss: 2.600216707974936

Epoch: 6| Step: 4
Training loss: 0.24499750445029145
Validation loss: 2.580885655114428

Epoch: 6| Step: 5
Training loss: 0.19871339091936135
Validation loss: 2.529694149295368

Epoch: 6| Step: 6
Training loss: 0.18013868492763283
Validation loss: 2.5016858333705394

Epoch: 6| Step: 7
Training loss: 0.2635646743431436
Validation loss: 2.4640539616969996

Epoch: 6| Step: 8
Training loss: 0.16676062428973834
Validation loss: 2.4587164201983382

Epoch: 6| Step: 9
Training loss: 0.3333338710164661
Validation loss: 2.4158691799040968

Epoch: 6| Step: 10
Training loss: 0.13566898869720914
Validation loss: 2.4634340908783017

Epoch: 6| Step: 11
Training loss: 0.1922602577808878
Validation loss: 2.506109636363613

Epoch: 6| Step: 12
Training loss: 0.1739374095835641
Validation loss: 2.4911779307588895

Epoch: 6| Step: 13
Training loss: 0.31727497322834464
Validation loss: 2.526691131946846

Epoch: 419| Step: 0
Training loss: 0.24068219229740492
Validation loss: 2.5498865620689863

Epoch: 6| Step: 1
Training loss: 0.30545657248261143
Validation loss: 2.549775801439424

Epoch: 6| Step: 2
Training loss: 0.14964893679534297
Validation loss: 2.5633743819241066

Epoch: 6| Step: 3
Training loss: 0.22216941078472596
Validation loss: 2.578296572885623

Epoch: 6| Step: 4
Training loss: 0.4203479822774
Validation loss: 2.515877971542221

Epoch: 6| Step: 5
Training loss: 0.2096173513617349
Validation loss: 2.517171804183966

Epoch: 6| Step: 6
Training loss: 0.2678818475593023
Validation loss: 2.4620905640978794

Epoch: 6| Step: 7
Training loss: 0.261021881964783
Validation loss: 2.410230914025227

Epoch: 6| Step: 8
Training loss: 0.2487761447695573
Validation loss: 2.407372227228007

Epoch: 6| Step: 9
Training loss: 0.23833785400960536
Validation loss: 2.4205745469815927

Epoch: 6| Step: 10
Training loss: 0.23200843005238345
Validation loss: 2.469131980162495

Epoch: 6| Step: 11
Training loss: 0.1778585922122108
Validation loss: 2.519388438847844

Epoch: 6| Step: 12
Training loss: 0.19398047175572855
Validation loss: 2.497536357990399

Epoch: 6| Step: 13
Training loss: 0.16625265142649728
Validation loss: 2.55934228832242

Epoch: 420| Step: 0
Training loss: 0.258624474351145
Validation loss: 2.557485027574737

Epoch: 6| Step: 1
Training loss: 0.22860768900813977
Validation loss: 2.5501207628715314

Epoch: 6| Step: 2
Training loss: 0.28173010961360734
Validation loss: 2.530560345714206

Epoch: 6| Step: 3
Training loss: 0.23787537386509536
Validation loss: 2.575530582967232

Epoch: 6| Step: 4
Training loss: 0.29514288042523334
Validation loss: 2.56492225539546

Epoch: 6| Step: 5
Training loss: 0.17463569890720107
Validation loss: 2.5502967619968397

Epoch: 6| Step: 6
Training loss: 0.2586869524193973
Validation loss: 2.481295056599246

Epoch: 6| Step: 7
Training loss: 0.2114979046093286
Validation loss: 2.48617453864782

Epoch: 6| Step: 8
Training loss: 0.3274928543170301
Validation loss: 2.4851672895043144

Epoch: 6| Step: 9
Training loss: 0.20911894235941011
Validation loss: 2.5005754669883937

Epoch: 6| Step: 10
Training loss: 0.22217046715306227
Validation loss: 2.480136215041353

Epoch: 6| Step: 11
Training loss: 0.23202384397458972
Validation loss: 2.5179406531334774

Epoch: 6| Step: 12
Training loss: 0.3031055021405824
Validation loss: 2.531510882883068

Epoch: 6| Step: 13
Training loss: 0.06829033498753517
Validation loss: 2.5132179328755457

Epoch: 421| Step: 0
Training loss: 0.25436844939155506
Validation loss: 2.5361865050580237

Epoch: 6| Step: 1
Training loss: 0.2994334006238905
Validation loss: 2.547689889683852

Epoch: 6| Step: 2
Training loss: 0.2334065934675506
Validation loss: 2.5649111389287227

Epoch: 6| Step: 3
Training loss: 0.29071377454574165
Validation loss: 2.550035513876476

Epoch: 6| Step: 4
Training loss: 0.2687591745230021
Validation loss: 2.5178873310485517

Epoch: 6| Step: 5
Training loss: 0.21995493570904734
Validation loss: 2.4717735404012537

Epoch: 6| Step: 6
Training loss: 0.16715761545956823
Validation loss: 2.491119543753361

Epoch: 6| Step: 7
Training loss: 0.10969441469519385
Validation loss: 2.4730727063358726

Epoch: 6| Step: 8
Training loss: 0.1763634471137601
Validation loss: 2.4353104673576342

Epoch: 6| Step: 9
Training loss: 0.19925584634701887
Validation loss: 2.4940265725128357

Epoch: 6| Step: 10
Training loss: 0.21942134427427007
Validation loss: 2.487988213304959

Epoch: 6| Step: 11
Training loss: 0.2690559564076094
Validation loss: 2.4980157812410466

Epoch: 6| Step: 12
Training loss: 0.15936047871201184
Validation loss: 2.496444327044538

Epoch: 6| Step: 13
Training loss: 0.19578592144141557
Validation loss: 2.511930438628821

Epoch: 422| Step: 0
Training loss: 0.23771385741160445
Validation loss: 2.542979597445296

Epoch: 6| Step: 1
Training loss: 0.15342275877916656
Validation loss: 2.5847427011552706

Epoch: 6| Step: 2
Training loss: 0.3408361830199728
Validation loss: 2.566842454319603

Epoch: 6| Step: 3
Training loss: 0.18613973566651545
Validation loss: 2.542097613594046

Epoch: 6| Step: 4
Training loss: 0.20752990696717605
Validation loss: 2.5312195288270987

Epoch: 6| Step: 5
Training loss: 0.16096318882478353
Validation loss: 2.524855795452092

Epoch: 6| Step: 6
Training loss: 0.2149728733792452
Validation loss: 2.4994304618381458

Epoch: 6| Step: 7
Training loss: 0.20817168143272777
Validation loss: 2.4360165879433615

Epoch: 6| Step: 8
Training loss: 0.2872847196796235
Validation loss: 2.4845704889007183

Epoch: 6| Step: 9
Training loss: 0.36608774783480713
Validation loss: 2.4582011542042803

Epoch: 6| Step: 10
Training loss: 0.17155980339085056
Validation loss: 2.5002750265958382

Epoch: 6| Step: 11
Training loss: 0.18927341471668102
Validation loss: 2.47736478122362

Epoch: 6| Step: 12
Training loss: 0.240191355009011
Validation loss: 2.521061733281809

Epoch: 6| Step: 13
Training loss: 0.1865524648878005
Validation loss: 2.5015915291107795

Epoch: 423| Step: 0
Training loss: 0.2877450769170665
Validation loss: 2.5236700259376956

Epoch: 6| Step: 1
Training loss: 0.30207769481833713
Validation loss: 2.534905446071401

Epoch: 6| Step: 2
Training loss: 0.2281057725276079
Validation loss: 2.502431330194604

Epoch: 6| Step: 3
Training loss: 0.2494389377457932
Validation loss: 2.490256858690404

Epoch: 6| Step: 4
Training loss: 0.3191103473807842
Validation loss: 2.4571314707355505

Epoch: 6| Step: 5
Training loss: 0.19877442194883754
Validation loss: 2.488731254594846

Epoch: 6| Step: 6
Training loss: 0.2178780172043903
Validation loss: 2.4731390803275133

Epoch: 6| Step: 7
Training loss: 0.24691591979977162
Validation loss: 2.454789789645757

Epoch: 6| Step: 8
Training loss: 0.20795465067611132
Validation loss: 2.485597210385088

Epoch: 6| Step: 9
Training loss: 0.2672863782883326
Validation loss: 2.4637077109257826

Epoch: 6| Step: 10
Training loss: 0.2030240596709302
Validation loss: 2.489373193632639

Epoch: 6| Step: 11
Training loss: 0.21034359327998178
Validation loss: 2.534279196611538

Epoch: 6| Step: 12
Training loss: 0.22546162833943997
Validation loss: 2.537027121433697

Epoch: 6| Step: 13
Training loss: 0.3263367561658282
Validation loss: 2.576369302360433

Epoch: 424| Step: 0
Training loss: 0.19759439699283335
Validation loss: 2.5907939488712133

Epoch: 6| Step: 1
Training loss: 0.25679572773332743
Validation loss: 2.5382035910862597

Epoch: 6| Step: 2
Training loss: 0.18316160231695516
Validation loss: 2.575588116983753

Epoch: 6| Step: 3
Training loss: 0.12706432607523527
Validation loss: 2.558367982604154

Epoch: 6| Step: 4
Training loss: 0.19550830562807556
Validation loss: 2.564251285523011

Epoch: 6| Step: 5
Training loss: 0.2889054877197376
Validation loss: 2.543861576324269

Epoch: 6| Step: 6
Training loss: 0.22572488345184258
Validation loss: 2.5034492898242795

Epoch: 6| Step: 7
Training loss: 0.19041474112518603
Validation loss: 2.5309005662210264

Epoch: 6| Step: 8
Training loss: 0.2765917994178621
Validation loss: 2.4930218058003244

Epoch: 6| Step: 9
Training loss: 0.382947197396761
Validation loss: 2.4999188379218484

Epoch: 6| Step: 10
Training loss: 0.17459779888754656
Validation loss: 2.4701315131084387

Epoch: 6| Step: 11
Training loss: 0.13126530955353585
Validation loss: 2.4585987620053644

Epoch: 6| Step: 12
Training loss: 0.14636818410281133
Validation loss: 2.4759016375762046

Epoch: 6| Step: 13
Training loss: 0.141523945023345
Validation loss: 2.492593135682766

Epoch: 425| Step: 0
Training loss: 0.17659533921085108
Validation loss: 2.4725542541057233

Epoch: 6| Step: 1
Training loss: 0.25334032519368804
Validation loss: 2.5036235452191242

Epoch: 6| Step: 2
Training loss: 0.2429294756826927
Validation loss: 2.5067476855088993

Epoch: 6| Step: 3
Training loss: 0.2618432531710622
Validation loss: 2.447197864138678

Epoch: 6| Step: 4
Training loss: 0.2888751840677504
Validation loss: 2.4445171376466805

Epoch: 6| Step: 5
Training loss: 0.26334649248280645
Validation loss: 2.4137181345289944

Epoch: 6| Step: 6
Training loss: 0.17950264087742612
Validation loss: 2.4781792879543074

Epoch: 6| Step: 7
Training loss: 0.21908660943742717
Validation loss: 2.467563104480151

Epoch: 6| Step: 8
Training loss: 0.22253001968253677
Validation loss: 2.5102795251241856

Epoch: 6| Step: 9
Training loss: 0.3140439635353031
Validation loss: 2.524784664335922

Epoch: 6| Step: 10
Training loss: 0.23357697366033534
Validation loss: 2.5111509922280173

Epoch: 6| Step: 11
Training loss: 0.1921591838662947
Validation loss: 2.5254114668801333

Epoch: 6| Step: 12
Training loss: 0.10906648550703224
Validation loss: 2.5432318358907247

Epoch: 6| Step: 13
Training loss: 0.12383429304338686
Validation loss: 2.4962177891877317

Epoch: 426| Step: 0
Training loss: 0.1553202504540258
Validation loss: 2.5302300028055273

Epoch: 6| Step: 1
Training loss: 0.17301524758054457
Validation loss: 2.5364947257777395

Epoch: 6| Step: 2
Training loss: 0.10928686030644721
Validation loss: 2.5414646807423598

Epoch: 6| Step: 3
Training loss: 0.33075193892449095
Validation loss: 2.5266520818238027

Epoch: 6| Step: 4
Training loss: 0.23493279996535865
Validation loss: 2.536975681916768

Epoch: 6| Step: 5
Training loss: 0.17297661562698655
Validation loss: 2.5695057426427272

Epoch: 6| Step: 6
Training loss: 0.32157157373555195
Validation loss: 2.5628360194832362

Epoch: 6| Step: 7
Training loss: 0.3068639585835522
Validation loss: 2.518991058685335

Epoch: 6| Step: 8
Training loss: 0.18600154182541062
Validation loss: 2.521853091625384

Epoch: 6| Step: 9
Training loss: 0.26373158944312836
Validation loss: 2.527768354530925

Epoch: 6| Step: 10
Training loss: 0.15778522869570538
Validation loss: 2.5442388719807485

Epoch: 6| Step: 11
Training loss: 0.18759160982760667
Validation loss: 2.5226347231239643

Epoch: 6| Step: 12
Training loss: 0.2191123345757397
Validation loss: 2.551001364659678

Epoch: 6| Step: 13
Training loss: 0.24584053272815395
Validation loss: 2.6071383965046735

Epoch: 427| Step: 0
Training loss: 0.20572017798927023
Validation loss: 2.596430658775473

Epoch: 6| Step: 1
Training loss: 0.20107000049170076
Validation loss: 2.574994916878022

Epoch: 6| Step: 2
Training loss: 0.2917531288374724
Validation loss: 2.5500030946240275

Epoch: 6| Step: 3
Training loss: 0.21112054371012667
Validation loss: 2.5800321076399984

Epoch: 6| Step: 4
Training loss: 0.18631285118983612
Validation loss: 2.5804623138795626

Epoch: 6| Step: 5
Training loss: 0.23971016608822351
Validation loss: 2.5154323179255327

Epoch: 6| Step: 6
Training loss: 0.358244798039525
Validation loss: 2.4856524504306154

Epoch: 6| Step: 7
Training loss: 0.16654194819568388
Validation loss: 2.4872115092967086

Epoch: 6| Step: 8
Training loss: 0.18102985158242213
Validation loss: 2.5014122235152034

Epoch: 6| Step: 9
Training loss: 0.2073790130583343
Validation loss: 2.5060838945591297

Epoch: 6| Step: 10
Training loss: 0.15837712197398912
Validation loss: 2.5136572906909644

Epoch: 6| Step: 11
Training loss: 0.12679425349084564
Validation loss: 2.5184650942865723

Epoch: 6| Step: 12
Training loss: 0.17658331988809267
Validation loss: 2.5480953201779273

Epoch: 6| Step: 13
Training loss: 0.133433593708457
Validation loss: 2.526204781086056

Epoch: 428| Step: 0
Training loss: 0.11420627393437846
Validation loss: 2.5519171440722372

Epoch: 6| Step: 1
Training loss: 0.2542174852617593
Validation loss: 2.545613398986811

Epoch: 6| Step: 2
Training loss: 0.21129581253742616
Validation loss: 2.5716747049593853

Epoch: 6| Step: 3
Training loss: 0.2137449516151959
Validation loss: 2.541276957025208

Epoch: 6| Step: 4
Training loss: 0.14107679271501977
Validation loss: 2.488078811484728

Epoch: 6| Step: 5
Training loss: 0.11527774285679152
Validation loss: 2.5075072136333136

Epoch: 6| Step: 6
Training loss: 0.1883301734676817
Validation loss: 2.4869044496204586

Epoch: 6| Step: 7
Training loss: 0.23441734726124794
Validation loss: 2.469445966028808

Epoch: 6| Step: 8
Training loss: 0.2405054222584186
Validation loss: 2.4678576523254665

Epoch: 6| Step: 9
Training loss: 0.15925129058148757
Validation loss: 2.439931751895792

Epoch: 6| Step: 10
Training loss: 0.16694797800687
Validation loss: 2.4912017128627535

Epoch: 6| Step: 11
Training loss: 0.12604036859232726
Validation loss: 2.47945259977444

Epoch: 6| Step: 12
Training loss: 0.38946949762730043
Validation loss: 2.505713316871381

Epoch: 6| Step: 13
Training loss: 0.13442782206617487
Validation loss: 2.4620095163818525

Epoch: 429| Step: 0
Training loss: 0.2682003666252259
Validation loss: 2.4785752853106664

Epoch: 6| Step: 1
Training loss: 0.15531762412078656
Validation loss: 2.457267990978583

Epoch: 6| Step: 2
Training loss: 0.15307079348325278
Validation loss: 2.471950715273635

Epoch: 6| Step: 3
Training loss: 0.20415959605475228
Validation loss: 2.497311243457894

Epoch: 6| Step: 4
Training loss: 0.17690651260744625
Validation loss: 2.494619008283331

Epoch: 6| Step: 5
Training loss: 0.0805187488977411
Validation loss: 2.465638897879766

Epoch: 6| Step: 6
Training loss: 0.24477083881863135
Validation loss: 2.4633883636012404

Epoch: 6| Step: 7
Training loss: 0.20462278041789297
Validation loss: 2.509704421066299

Epoch: 6| Step: 8
Training loss: 0.1477375972039348
Validation loss: 2.4769142133785347

Epoch: 6| Step: 9
Training loss: 0.20685418672536254
Validation loss: 2.4889530318152273

Epoch: 6| Step: 10
Training loss: 0.20748750327293164
Validation loss: 2.469805565402994

Epoch: 6| Step: 11
Training loss: 0.26323842342712345
Validation loss: 2.4924317675248315

Epoch: 6| Step: 12
Training loss: 0.13303108319851628
Validation loss: 2.5127222631791333

Epoch: 6| Step: 13
Training loss: 0.20268140552896738
Validation loss: 2.5031119943234583

Epoch: 430| Step: 0
Training loss: 0.17536716962783566
Validation loss: 2.5284080568886513

Epoch: 6| Step: 1
Training loss: 0.31075854255415397
Validation loss: 2.5053984488643577

Epoch: 6| Step: 2
Training loss: 0.14379727374080314
Validation loss: 2.5579908973182124

Epoch: 6| Step: 3
Training loss: 0.21822006886408868
Validation loss: 2.487655201579797

Epoch: 6| Step: 4
Training loss: 0.1617031580554229
Validation loss: 2.5688680482506236

Epoch: 6| Step: 5
Training loss: 0.23860337418467048
Validation loss: 2.5072258003688455

Epoch: 6| Step: 6
Training loss: 0.20496784151320566
Validation loss: 2.5200691505570045

Epoch: 6| Step: 7
Training loss: 0.1982378277980433
Validation loss: 2.569436036169796

Epoch: 6| Step: 8
Training loss: 0.15154323799590214
Validation loss: 2.5144882737026393

Epoch: 6| Step: 9
Training loss: 0.10996724613719153
Validation loss: 2.476338754359238

Epoch: 6| Step: 10
Training loss: 0.10241640111232056
Validation loss: 2.4825261777976335

Epoch: 6| Step: 11
Training loss: 0.2449408881246825
Validation loss: 2.4661757003292877

Epoch: 6| Step: 12
Training loss: 0.25000196694553983
Validation loss: 2.437421797451565

Epoch: 6| Step: 13
Training loss: 0.26413572977624694
Validation loss: 2.4775150374915644

Epoch: 431| Step: 0
Training loss: 0.22147739944372533
Validation loss: 2.475135051017138

Epoch: 6| Step: 1
Training loss: 0.1251641923667901
Validation loss: 2.485694528125493

Epoch: 6| Step: 2
Training loss: 0.12128330591764652
Validation loss: 2.484681546845784

Epoch: 6| Step: 3
Training loss: 0.2557468895037826
Validation loss: 2.4438822080422535

Epoch: 6| Step: 4
Training loss: 0.1153309869678582
Validation loss: 2.4588802908281266

Epoch: 6| Step: 5
Training loss: 0.1163691997770262
Validation loss: 2.4461893334259344

Epoch: 6| Step: 6
Training loss: 0.22681781753577937
Validation loss: 2.4990250619439993

Epoch: 6| Step: 7
Training loss: 0.163941690833495
Validation loss: 2.4623942194064083

Epoch: 6| Step: 8
Training loss: 0.1826915283659479
Validation loss: 2.4306269407166106

Epoch: 6| Step: 9
Training loss: 0.2563937191222913
Validation loss: 2.4417775486306437

Epoch: 6| Step: 10
Training loss: 0.2534028859142759
Validation loss: 2.4600105786239905

Epoch: 6| Step: 11
Training loss: 0.13447664901800646
Validation loss: 2.436947995921431

Epoch: 6| Step: 12
Training loss: 0.1411361807751982
Validation loss: 2.4545494956252623

Epoch: 6| Step: 13
Training loss: 0.30633297448185676
Validation loss: 2.4497340033031194

Epoch: 432| Step: 0
Training loss: 0.1448552263727612
Validation loss: 2.4545588235410576

Epoch: 6| Step: 1
Training loss: 0.13199140071493284
Validation loss: 2.455874412736404

Epoch: 6| Step: 2
Training loss: 0.16044302595821527
Validation loss: 2.4724973092162554

Epoch: 6| Step: 3
Training loss: 0.30138322116329574
Validation loss: 2.4606097728298697

Epoch: 6| Step: 4
Training loss: 0.15369464346816125
Validation loss: 2.4963537256652395

Epoch: 6| Step: 5
Training loss: 0.13992859009050498
Validation loss: 2.4863469042633217

Epoch: 6| Step: 6
Training loss: 0.15863502087590567
Validation loss: 2.514931734771169

Epoch: 6| Step: 7
Training loss: 0.14317136956649934
Validation loss: 2.528082781940538

Epoch: 6| Step: 8
Training loss: 0.24689706752027532
Validation loss: 2.528066699323199

Epoch: 6| Step: 9
Training loss: 0.12739157159070644
Validation loss: 2.5472183766100085

Epoch: 6| Step: 10
Training loss: 0.15097286175415262
Validation loss: 2.5301096869667004

Epoch: 6| Step: 11
Training loss: 0.1650972151019878
Validation loss: 2.5401188215427246

Epoch: 6| Step: 12
Training loss: 0.27711301258626003
Validation loss: 2.535470279925518

Epoch: 6| Step: 13
Training loss: 0.24442768767990897
Validation loss: 2.5352477459709424

Epoch: 433| Step: 0
Training loss: 0.3001158277110146
Validation loss: 2.5586064670036603

Epoch: 6| Step: 1
Training loss: 0.2591261485728062
Validation loss: 2.5362835969807547

Epoch: 6| Step: 2
Training loss: 0.12190248778502127
Validation loss: 2.5264197045209174

Epoch: 6| Step: 3
Training loss: 0.1538060445422894
Validation loss: 2.5467079742479832

Epoch: 6| Step: 4
Training loss: 0.15688029952805582
Validation loss: 2.512225709416788

Epoch: 6| Step: 5
Training loss: 0.15635760893348014
Validation loss: 2.5056335563845997

Epoch: 6| Step: 6
Training loss: 0.16141337042960613
Validation loss: 2.5215879399197108

Epoch: 6| Step: 7
Training loss: 0.14438059403782516
Validation loss: 2.5074087722733216

Epoch: 6| Step: 8
Training loss: 0.13603200094119594
Validation loss: 2.5314171828410843

Epoch: 6| Step: 9
Training loss: 0.22368821036819425
Validation loss: 2.514418560145445

Epoch: 6| Step: 10
Training loss: 0.14886161797784558
Validation loss: 2.52293158885872

Epoch: 6| Step: 11
Training loss: 0.13821103527834783
Validation loss: 2.451714498873755

Epoch: 6| Step: 12
Training loss: 0.1457043159374829
Validation loss: 2.4922683589034866

Epoch: 6| Step: 13
Training loss: 0.2918976340411343
Validation loss: 2.4874096136748336

Epoch: 434| Step: 0
Training loss: 0.10326088745001916
Validation loss: 2.487339763702516

Epoch: 6| Step: 1
Training loss: 0.15851483425208243
Validation loss: 2.4709340843725167

Epoch: 6| Step: 2
Training loss: 0.1151435663971159
Validation loss: 2.48587365409585

Epoch: 6| Step: 3
Training loss: 0.11982227190172481
Validation loss: 2.4775310907511265

Epoch: 6| Step: 4
Training loss: 0.19822549984604676
Validation loss: 2.5487640721073257

Epoch: 6| Step: 5
Training loss: 0.10995935689626944
Validation loss: 2.545763134537761

Epoch: 6| Step: 6
Training loss: 0.16982866339545985
Validation loss: 2.493842227100173

Epoch: 6| Step: 7
Training loss: 0.37175244547841896
Validation loss: 2.5303038856182516

Epoch: 6| Step: 8
Training loss: 0.2605484231791332
Validation loss: 2.5092482297067216

Epoch: 6| Step: 9
Training loss: 0.19859085052378503
Validation loss: 2.5012047131230064

Epoch: 6| Step: 10
Training loss: 0.18953303981731554
Validation loss: 2.4461505188719816

Epoch: 6| Step: 11
Training loss: 0.150577787878869
Validation loss: 2.509986257609038

Epoch: 6| Step: 12
Training loss: 0.17172725786578805
Validation loss: 2.5406877151112988

Epoch: 6| Step: 13
Training loss: 0.17640519667244223
Validation loss: 2.5043625084996277

Epoch: 435| Step: 0
Training loss: 0.09770699613062149
Validation loss: 2.49664044607422

Epoch: 6| Step: 1
Training loss: 0.1492738127849212
Validation loss: 2.4727251768067315

Epoch: 6| Step: 2
Training loss: 0.09152499986813714
Validation loss: 2.495405078358506

Epoch: 6| Step: 3
Training loss: 0.24688499647737577
Validation loss: 2.4482834819765027

Epoch: 6| Step: 4
Training loss: 0.23193311189300275
Validation loss: 2.4707825443944214

Epoch: 6| Step: 5
Training loss: 0.3824139875742229
Validation loss: 2.441884595905865

Epoch: 6| Step: 6
Training loss: 0.2956298641627283
Validation loss: 2.4214933488316133

Epoch: 6| Step: 7
Training loss: 0.11007393456734431
Validation loss: 2.496302690660722

Epoch: 6| Step: 8
Training loss: 0.1544233479833403
Validation loss: 2.4930310000514946

Epoch: 6| Step: 9
Training loss: 0.14205274064710885
Validation loss: 2.4675472866258046

Epoch: 6| Step: 10
Training loss: 0.11411487572198852
Validation loss: 2.483419729864635

Epoch: 6| Step: 11
Training loss: 0.15020250965430063
Validation loss: 2.460554426920377

Epoch: 6| Step: 12
Training loss: 0.13992036340473146
Validation loss: 2.518905798841852

Epoch: 6| Step: 13
Training loss: 0.10850591743830924
Validation loss: 2.4925438112548655

Epoch: 436| Step: 0
Training loss: 0.18839419250008563
Validation loss: 2.4675459609343586

Epoch: 6| Step: 1
Training loss: 0.358198978312711
Validation loss: 2.4942674459653067

Epoch: 6| Step: 2
Training loss: 0.12926761232672332
Validation loss: 2.4508952524452594

Epoch: 6| Step: 3
Training loss: 0.220481541895809
Validation loss: 2.4490371858969358

Epoch: 6| Step: 4
Training loss: 0.19929044966618872
Validation loss: 2.4388448130695988

Epoch: 6| Step: 5
Training loss: 0.18056310977680978
Validation loss: 2.4301976923636657

Epoch: 6| Step: 6
Training loss: 0.16734842594855076
Validation loss: 2.424112586828588

Epoch: 6| Step: 7
Training loss: 0.08799048155341987
Validation loss: 2.4684757876339307

Epoch: 6| Step: 8
Training loss: 0.16436121630804512
Validation loss: 2.4407941247908966

Epoch: 6| Step: 9
Training loss: 0.2388477314396708
Validation loss: 2.4254493802753143

Epoch: 6| Step: 10
Training loss: 0.09098971882285803
Validation loss: 2.4517173388634586

Epoch: 6| Step: 11
Training loss: 0.08668685532751659
Validation loss: 2.441692844821571

Epoch: 6| Step: 12
Training loss: 0.17570728229236696
Validation loss: 2.491438610768509

Epoch: 6| Step: 13
Training loss: 0.11368414330887881
Validation loss: 2.448644865838064

Epoch: 437| Step: 0
Training loss: 0.13735642903015075
Validation loss: 2.4672214422412453

Epoch: 6| Step: 1
Training loss: 0.10189984763814217
Validation loss: 2.468734089021409

Epoch: 6| Step: 2
Training loss: 0.218879218763981
Validation loss: 2.4831908433789818

Epoch: 6| Step: 3
Training loss: 0.21873336967195267
Validation loss: 2.489399395555912

Epoch: 6| Step: 4
Training loss: 0.17731804346314464
Validation loss: 2.486524747052479

Epoch: 6| Step: 5
Training loss: 0.1408286408330599
Validation loss: 2.4901083966922144

Epoch: 6| Step: 6
Training loss: 0.1584952447836768
Validation loss: 2.5013156843587803

Epoch: 6| Step: 7
Training loss: 0.17198006171550623
Validation loss: 2.551111447024713

Epoch: 6| Step: 8
Training loss: 0.2331371281079533
Validation loss: 2.538780511006357

Epoch: 6| Step: 9
Training loss: 0.26609008407979523
Validation loss: 2.507032226829817

Epoch: 6| Step: 10
Training loss: 0.1562629038727621
Validation loss: 2.532057975138493

Epoch: 6| Step: 11
Training loss: 0.23056867017527183
Validation loss: 2.503768207816679

Epoch: 6| Step: 12
Training loss: 0.15019070354081884
Validation loss: 2.5029051882019275

Epoch: 6| Step: 13
Training loss: 0.15067331571996842
Validation loss: 2.463988477057367

Epoch: 438| Step: 0
Training loss: 0.13096597229932172
Validation loss: 2.4551033051816953

Epoch: 6| Step: 1
Training loss: 0.23498784844199017
Validation loss: 2.4773842182776713

Epoch: 6| Step: 2
Training loss: 0.22820538058369336
Validation loss: 2.4507016026815944

Epoch: 6| Step: 3
Training loss: 0.18137747663717005
Validation loss: 2.4245375177958057

Epoch: 6| Step: 4
Training loss: 0.1364293577890017
Validation loss: 2.4230955448214124

Epoch: 6| Step: 5
Training loss: 0.15758735416942998
Validation loss: 2.4186036106139674

Epoch: 6| Step: 6
Training loss: 0.12596366875482845
Validation loss: 2.4806100001710853

Epoch: 6| Step: 7
Training loss: 0.18375527601387776
Validation loss: 2.505096243383159

Epoch: 6| Step: 8
Training loss: 0.11496447620914417
Validation loss: 2.5018537662584404

Epoch: 6| Step: 9
Training loss: 0.22947282100693978
Validation loss: 2.5277789943893025

Epoch: 6| Step: 10
Training loss: 0.18301501265033943
Validation loss: 2.5400190650702283

Epoch: 6| Step: 11
Training loss: 0.13007256980008214
Validation loss: 2.5623204538275663

Epoch: 6| Step: 12
Training loss: 0.2436752996543442
Validation loss: 2.5676160015057627

Epoch: 6| Step: 13
Training loss: 0.31557180315169514
Validation loss: 2.523520512461404

Epoch: 439| Step: 0
Training loss: 0.1926539297033768
Validation loss: 2.559497298535112

Epoch: 6| Step: 1
Training loss: 0.3270150211497616
Validation loss: 2.511159085930972

Epoch: 6| Step: 2
Training loss: 0.1523955208281283
Validation loss: 2.5191436782366643

Epoch: 6| Step: 3
Training loss: 0.16426627809751573
Validation loss: 2.500849191968054

Epoch: 6| Step: 4
Training loss: 0.15202520151642485
Validation loss: 2.528445895634154

Epoch: 6| Step: 5
Training loss: 0.2015864535448086
Validation loss: 2.506438169979013

Epoch: 6| Step: 6
Training loss: 0.19139282023746507
Validation loss: 2.5090518271375255

Epoch: 6| Step: 7
Training loss: 0.11811567923819641
Validation loss: 2.523413720986081

Epoch: 6| Step: 8
Training loss: 0.15734844932811803
Validation loss: 2.525720284385827

Epoch: 6| Step: 9
Training loss: 0.22699104261528086
Validation loss: 2.51096731083564

Epoch: 6| Step: 10
Training loss: 0.09956643169947066
Validation loss: 2.47742519102183

Epoch: 6| Step: 11
Training loss: 0.28059363599835024
Validation loss: 2.501962358796261

Epoch: 6| Step: 12
Training loss: 0.13403163276683525
Validation loss: 2.514544319651994

Epoch: 6| Step: 13
Training loss: 0.283157608057598
Validation loss: 2.492293806750417

Epoch: 440| Step: 0
Training loss: 0.15341647588730775
Validation loss: 2.496437131941566

Epoch: 6| Step: 1
Training loss: 0.12966208237590224
Validation loss: 2.468747482828124

Epoch: 6| Step: 2
Training loss: 0.2017669579647927
Validation loss: 2.455814343957458

Epoch: 6| Step: 3
Training loss: 0.200002940722542
Validation loss: 2.4459532956640713

Epoch: 6| Step: 4
Training loss: 0.25478551183977677
Validation loss: 2.4465867688285847

Epoch: 6| Step: 5
Training loss: 0.12194672240874889
Validation loss: 2.4229667169218936

Epoch: 6| Step: 6
Training loss: 0.16242203951447023
Validation loss: 2.466275935632939

Epoch: 6| Step: 7
Training loss: 0.17472388888248802
Validation loss: 2.4604383966156447

Epoch: 6| Step: 8
Training loss: 0.15410811310009465
Validation loss: 2.5089842998579877

Epoch: 6| Step: 9
Training loss: 0.2585009716742458
Validation loss: 2.501438020568998

Epoch: 6| Step: 10
Training loss: 0.17540753162010286
Validation loss: 2.515583141673929

Epoch: 6| Step: 11
Training loss: 0.24298958091121506
Validation loss: 2.5112118372872305

Epoch: 6| Step: 12
Training loss: 0.14858808533734622
Validation loss: 2.544317932092654

Epoch: 6| Step: 13
Training loss: 0.1116397828670317
Validation loss: 2.495089912317648

Epoch: 441| Step: 0
Training loss: 0.24789801208184528
Validation loss: 2.5430243890409683

Epoch: 6| Step: 1
Training loss: 0.16820629090316547
Validation loss: 2.519893510370021

Epoch: 6| Step: 2
Training loss: 0.2624152580351428
Validation loss: 2.5404576176647957

Epoch: 6| Step: 3
Training loss: 0.22495464655960462
Validation loss: 2.514624432645238

Epoch: 6| Step: 4
Training loss: 0.14752694730376878
Validation loss: 2.5127698134188106

Epoch: 6| Step: 5
Training loss: 0.10430809096417439
Validation loss: 2.461612800571277

Epoch: 6| Step: 6
Training loss: 0.1626510417921579
Validation loss: 2.516601751976613

Epoch: 6| Step: 7
Training loss: 0.16054940233306458
Validation loss: 2.486296167034471

Epoch: 6| Step: 8
Training loss: 0.09763344498434279
Validation loss: 2.4799410640396964

Epoch: 6| Step: 9
Training loss: 0.10122657203129609
Validation loss: 2.46325179436476

Epoch: 6| Step: 10
Training loss: 0.15610863728215787
Validation loss: 2.4950503912351114

Epoch: 6| Step: 11
Training loss: 0.10711731652410712
Validation loss: 2.4900408349459298

Epoch: 6| Step: 12
Training loss: 0.12743030514361903
Validation loss: 2.51277920220514

Epoch: 6| Step: 13
Training loss: 0.3363782519690458
Validation loss: 2.50435450492336

Epoch: 442| Step: 0
Training loss: 0.15038375095659431
Validation loss: 2.496235443427229

Epoch: 6| Step: 1
Training loss: 0.2429987180572023
Validation loss: 2.536141000342342

Epoch: 6| Step: 2
Training loss: 0.08468157231077166
Validation loss: 2.5359111717169136

Epoch: 6| Step: 3
Training loss: 0.14436517659327894
Validation loss: 2.5425088130457656

Epoch: 6| Step: 4
Training loss: 0.2022906738247719
Validation loss: 2.534229798882224

Epoch: 6| Step: 5
Training loss: 0.17193306678969422
Validation loss: 2.5300426239436784

Epoch: 6| Step: 6
Training loss: 0.20408835664946576
Validation loss: 2.536438731756049

Epoch: 6| Step: 7
Training loss: 0.19648935527822323
Validation loss: 2.5197608440593107

Epoch: 6| Step: 8
Training loss: 0.3286588844069684
Validation loss: 2.5464363860416728

Epoch: 6| Step: 9
Training loss: 0.11039665026868488
Validation loss: 2.569005892472349

Epoch: 6| Step: 10
Training loss: 0.19528773150749867
Validation loss: 2.5828756257051557

Epoch: 6| Step: 11
Training loss: 0.1135638346234103
Validation loss: 2.543807510121339

Epoch: 6| Step: 12
Training loss: 0.13526689212307363
Validation loss: 2.5479433773294398

Epoch: 6| Step: 13
Training loss: 0.14540418352576673
Validation loss: 2.534028734326039

Epoch: 443| Step: 0
Training loss: 0.1339936606300775
Validation loss: 2.5299632697321197

Epoch: 6| Step: 1
Training loss: 0.28351365526807515
Validation loss: 2.520802319616494

Epoch: 6| Step: 2
Training loss: 0.088942815228747
Validation loss: 2.4856960509249344

Epoch: 6| Step: 3
Training loss: 0.28269394449786184
Validation loss: 2.4723282398355892

Epoch: 6| Step: 4
Training loss: 0.25074301514353015
Validation loss: 2.4992230289832666

Epoch: 6| Step: 5
Training loss: 0.19761617126022574
Validation loss: 2.4726242210839557

Epoch: 6| Step: 6
Training loss: 0.178100533645549
Validation loss: 2.4665082122618194

Epoch: 6| Step: 7
Training loss: 0.18221778848505932
Validation loss: 2.4961093561436716

Epoch: 6| Step: 8
Training loss: 0.12891564912919473
Validation loss: 2.5096920987893623

Epoch: 6| Step: 9
Training loss: 0.3222701794851578
Validation loss: 2.5843897084380307

Epoch: 6| Step: 10
Training loss: 0.22308610113582444
Validation loss: 2.541180988557019

Epoch: 6| Step: 11
Training loss: 0.23070623801999218
Validation loss: 2.564489705645584

Epoch: 6| Step: 12
Training loss: 0.21901620266801378
Validation loss: 2.557908937385194

Epoch: 6| Step: 13
Training loss: 0.1752778952660606
Validation loss: 2.5426760309519922

Epoch: 444| Step: 0
Training loss: 0.24346243695111727
Validation loss: 2.529910512137049

Epoch: 6| Step: 1
Training loss: 0.19409804424092109
Validation loss: 2.5398915461804656

Epoch: 6| Step: 2
Training loss: 0.20077035703685356
Validation loss: 2.5140004452141365

Epoch: 6| Step: 3
Training loss: 0.28568073271533256
Validation loss: 2.489553999104787

Epoch: 6| Step: 4
Training loss: 0.11356786938120617
Validation loss: 2.4739758307070825

Epoch: 6| Step: 5
Training loss: 0.2580039440618721
Validation loss: 2.4915901718335407

Epoch: 6| Step: 6
Training loss: 0.38876983711558355
Validation loss: 2.450250215458492

Epoch: 6| Step: 7
Training loss: 0.4189517503079261
Validation loss: 2.4561638983239917

Epoch: 6| Step: 8
Training loss: 0.26641668819438935
Validation loss: 2.48038847540411

Epoch: 6| Step: 9
Training loss: 0.15270054435208266
Validation loss: 2.4887410734832

Epoch: 6| Step: 10
Training loss: 0.1416585412979376
Validation loss: 2.5356192818913508

Epoch: 6| Step: 11
Training loss: 0.28290719981125223
Validation loss: 2.567133252638712

Epoch: 6| Step: 12
Training loss: 0.2994160820680753
Validation loss: 2.5120683200738823

Epoch: 6| Step: 13
Training loss: 0.31428448674694526
Validation loss: 2.546212902532725

Epoch: 445| Step: 0
Training loss: 0.2554194913265076
Validation loss: 2.487231727991468

Epoch: 6| Step: 1
Training loss: 0.20821607488613858
Validation loss: 2.4854384741557785

Epoch: 6| Step: 2
Training loss: 0.2618807959996308
Validation loss: 2.4698960601179016

Epoch: 6| Step: 3
Training loss: 0.17813121592400646
Validation loss: 2.4721013006128025

Epoch: 6| Step: 4
Training loss: 0.28429908472739696
Validation loss: 2.475817768849603

Epoch: 6| Step: 5
Training loss: 0.23914163844115982
Validation loss: 2.441851607984714

Epoch: 6| Step: 6
Training loss: 0.14102811784433814
Validation loss: 2.4261168305809835

Epoch: 6| Step: 7
Training loss: 0.19553944753820565
Validation loss: 2.437233163780707

Epoch: 6| Step: 8
Training loss: 0.28733443178186713
Validation loss: 2.3952516175044916

Epoch: 6| Step: 9
Training loss: 0.15263761396871642
Validation loss: 2.4585975070863677

Epoch: 6| Step: 10
Training loss: 0.2203619860811087
Validation loss: 2.4549098693554363

Epoch: 6| Step: 11
Training loss: 0.206346747797615
Validation loss: 2.477973296770601

Epoch: 6| Step: 12
Training loss: 0.3070271964933997
Validation loss: 2.4561076881830366

Epoch: 6| Step: 13
Training loss: 0.18957003692663518
Validation loss: 2.5024022169228464

Epoch: 446| Step: 0
Training loss: 0.17994704368221295
Validation loss: 2.5219981682813293

Epoch: 6| Step: 1
Training loss: 0.3051982047425974
Validation loss: 2.479656719796746

Epoch: 6| Step: 2
Training loss: 0.2518807092734227
Validation loss: 2.5208732651310823

Epoch: 6| Step: 3
Training loss: 0.12658283076234683
Validation loss: 2.512595728609276

Epoch: 6| Step: 4
Training loss: 0.2870051655470635
Validation loss: 2.520487767162191

Epoch: 6| Step: 5
Training loss: 0.21205974440803801
Validation loss: 2.4786380263835923

Epoch: 6| Step: 6
Training loss: 0.15200296212317005
Validation loss: 2.487160982455721

Epoch: 6| Step: 7
Training loss: 0.2057253479100168
Validation loss: 2.480636407820273

Epoch: 6| Step: 8
Training loss: 0.2614137095990522
Validation loss: 2.4638626093192713

Epoch: 6| Step: 9
Training loss: 0.22535088087889021
Validation loss: 2.4357054746139117

Epoch: 6| Step: 10
Training loss: 0.2581513663165818
Validation loss: 2.4536001135808934

Epoch: 6| Step: 11
Training loss: 0.25805256965768053
Validation loss: 2.4506088519481857

Epoch: 6| Step: 12
Training loss: 0.3275829788456133
Validation loss: 2.4853738799381415

Epoch: 6| Step: 13
Training loss: 0.176655328662507
Validation loss: 2.4814998629123264

Epoch: 447| Step: 0
Training loss: 0.23058709645937275
Validation loss: 2.5281565155701866

Epoch: 6| Step: 1
Training loss: 0.23974251210320668
Validation loss: 2.5553572986740742

Epoch: 6| Step: 2
Training loss: 0.3134397681202695
Validation loss: 2.5307928320925543

Epoch: 6| Step: 3
Training loss: 0.34290290626266023
Validation loss: 2.543891227417593

Epoch: 6| Step: 4
Training loss: 0.19127960296978744
Validation loss: 2.5240658142586243

Epoch: 6| Step: 5
Training loss: 0.3039550168447165
Validation loss: 2.5182746146474115

Epoch: 6| Step: 6
Training loss: 0.1632686322643783
Validation loss: 2.490993074017236

Epoch: 6| Step: 7
Training loss: 0.21489561495274442
Validation loss: 2.479577210881237

Epoch: 6| Step: 8
Training loss: 0.2954291975962274
Validation loss: 2.4620440382077695

Epoch: 6| Step: 9
Training loss: 0.20262215803296005
Validation loss: 2.4687748070900035

Epoch: 6| Step: 10
Training loss: 0.20080610002742852
Validation loss: 2.479670894102559

Epoch: 6| Step: 11
Training loss: 0.19836704663003532
Validation loss: 2.4912343910172474

Epoch: 6| Step: 12
Training loss: 0.22074228125067133
Validation loss: 2.4818840652237335

Epoch: 6| Step: 13
Training loss: 0.08284182501642572
Validation loss: 2.4683134836121625

Epoch: 448| Step: 0
Training loss: 0.34708056845294527
Validation loss: 2.4624355774343796

Epoch: 6| Step: 1
Training loss: 0.2457058286290695
Validation loss: 2.492769501842872

Epoch: 6| Step: 2
Training loss: 0.29024452099323234
Validation loss: 2.476916781246685

Epoch: 6| Step: 3
Training loss: 0.21281717065623568
Validation loss: 2.4625312255591965

Epoch: 6| Step: 4
Training loss: 0.12865316225969733
Validation loss: 2.463669459569534

Epoch: 6| Step: 5
Training loss: 0.19374472818585783
Validation loss: 2.4622524360029803

Epoch: 6| Step: 6
Training loss: 0.23285036099205025
Validation loss: 2.452171610169864

Epoch: 6| Step: 7
Training loss: 0.31768818176439534
Validation loss: 2.5012825096296205

Epoch: 6| Step: 8
Training loss: 0.20877041068772015
Validation loss: 2.4998739395353353

Epoch: 6| Step: 9
Training loss: 0.18971692232581502
Validation loss: 2.468424107703461

Epoch: 6| Step: 10
Training loss: 0.19128057674868443
Validation loss: 2.494675987723829

Epoch: 6| Step: 11
Training loss: 0.2720024325440829
Validation loss: 2.4801312668615356

Epoch: 6| Step: 12
Training loss: 0.2781535401863193
Validation loss: 2.4617248629848

Epoch: 6| Step: 13
Training loss: 0.23094480453935526
Validation loss: 2.4885001905070427

Epoch: 449| Step: 0
Training loss: 0.2002369348940599
Validation loss: 2.461924936981948

Epoch: 6| Step: 1
Training loss: 0.16602031476745666
Validation loss: 2.4549015077020075

Epoch: 6| Step: 2
Training loss: 0.19092899300437124
Validation loss: 2.4679923867450113

Epoch: 6| Step: 3
Training loss: 0.29882533252882343
Validation loss: 2.4601126694074273

Epoch: 6| Step: 4
Training loss: 0.22831240200570063
Validation loss: 2.493582912821002

Epoch: 6| Step: 5
Training loss: 0.22128625650806924
Validation loss: 2.4816203764134763

Epoch: 6| Step: 6
Training loss: 0.13284916932514285
Validation loss: 2.5116699767218678

Epoch: 6| Step: 7
Training loss: 0.24300949515523737
Validation loss: 2.4779507184372176

Epoch: 6| Step: 8
Training loss: 0.23370564565225668
Validation loss: 2.4659859597161273

Epoch: 6| Step: 9
Training loss: 0.11267131586297142
Validation loss: 2.491657157575528

Epoch: 6| Step: 10
Training loss: 0.24076083888306787
Validation loss: 2.4622420377461993

Epoch: 6| Step: 11
Training loss: 0.36101937376881493
Validation loss: 2.4829481808850558

Epoch: 6| Step: 12
Training loss: 0.20911380289453893
Validation loss: 2.536249199690753

Epoch: 6| Step: 13
Training loss: 0.23883656377985701
Validation loss: 2.5328292751081265

Epoch: 450| Step: 0
Training loss: 0.21064136168492087
Validation loss: 2.509702200343747

Epoch: 6| Step: 1
Training loss: 0.21098576099590557
Validation loss: 2.5104521249064207

Epoch: 6| Step: 2
Training loss: 0.25534500951646577
Validation loss: 2.5207482892014057

Epoch: 6| Step: 3
Training loss: 0.34463659738944963
Validation loss: 2.513906293408521

Epoch: 6| Step: 4
Training loss: 0.2970591149862617
Validation loss: 2.5492266144698963

Epoch: 6| Step: 5
Training loss: 0.14065652070170917
Validation loss: 2.540594909519645

Epoch: 6| Step: 6
Training loss: 0.1390271672356536
Validation loss: 2.500966978209515

Epoch: 6| Step: 7
Training loss: 0.1313422389845481
Validation loss: 2.5055174926009918

Epoch: 6| Step: 8
Training loss: 0.15645628663242703
Validation loss: 2.5174114803771994

Epoch: 6| Step: 9
Training loss: 0.26405273058273465
Validation loss: 2.5284660380790025

Epoch: 6| Step: 10
Training loss: 0.33744807285392164
Validation loss: 2.561783465058149

Epoch: 6| Step: 11
Training loss: 0.3277115487662215
Validation loss: 2.5527346300851725

Epoch: 6| Step: 12
Training loss: 0.23128515246990036
Validation loss: 2.482399456666208

Epoch: 6| Step: 13
Training loss: 0.29020729708754706
Validation loss: 2.4377928379911173

Epoch: 451| Step: 0
Training loss: 0.1910140827327321
Validation loss: 2.4211855539172227

Epoch: 6| Step: 1
Training loss: 0.1454064957341787
Validation loss: 2.4470685115699666

Epoch: 6| Step: 2
Training loss: 0.26323482885234983
Validation loss: 2.4126866292624944

Epoch: 6| Step: 3
Training loss: 0.25549348483951734
Validation loss: 2.4409195814501996

Epoch: 6| Step: 4
Training loss: 0.32435611894080324
Validation loss: 2.437705679967048

Epoch: 6| Step: 5
Training loss: 0.16751091683098424
Validation loss: 2.4907899972549137

Epoch: 6| Step: 6
Training loss: 0.300813697947295
Validation loss: 2.485891758212848

Epoch: 6| Step: 7
Training loss: 0.2915967221634442
Validation loss: 2.543525826453228

Epoch: 6| Step: 8
Training loss: 0.1395180366812651
Validation loss: 2.527770672971139

Epoch: 6| Step: 9
Training loss: 0.403345398203573
Validation loss: 2.5747571180524202

Epoch: 6| Step: 10
Training loss: 0.21680421215391668
Validation loss: 2.5338289751809917

Epoch: 6| Step: 11
Training loss: 0.20487693727286066
Validation loss: 2.4920256981955418

Epoch: 6| Step: 12
Training loss: 0.18679522141474958
Validation loss: 2.440090129541952

Epoch: 6| Step: 13
Training loss: 0.21042416947903275
Validation loss: 2.4183391905073437

Epoch: 452| Step: 0
Training loss: 0.2983255211221959
Validation loss: 2.425396623939084

Epoch: 6| Step: 1
Training loss: 0.2692990339307175
Validation loss: 2.4457898198780734

Epoch: 6| Step: 2
Training loss: 0.36880494047898016
Validation loss: 2.4761632808004155

Epoch: 6| Step: 3
Training loss: 0.3021636628628303
Validation loss: 2.5245509625691094

Epoch: 6| Step: 4
Training loss: 0.2599243596895254
Validation loss: 2.50424071952473

Epoch: 6| Step: 5
Training loss: 0.2009222092454009
Validation loss: 2.5081294771830858

Epoch: 6| Step: 6
Training loss: 0.1499641117237958
Validation loss: 2.512840996428943

Epoch: 6| Step: 7
Training loss: 0.21892657135953505
Validation loss: 2.4759976751016186

Epoch: 6| Step: 8
Training loss: 0.18075404632624267
Validation loss: 2.515862528784858

Epoch: 6| Step: 9
Training loss: 0.19461099529778664
Validation loss: 2.489689811344528

Epoch: 6| Step: 10
Training loss: 0.36237920524312534
Validation loss: 2.5356823797936627

Epoch: 6| Step: 11
Training loss: 0.25773577559947114
Validation loss: 2.516119318670681

Epoch: 6| Step: 12
Training loss: 0.17557846664472873
Validation loss: 2.4970771880283396

Epoch: 6| Step: 13
Training loss: 0.2252245646631643
Validation loss: 2.4834584832340427

Epoch: 453| Step: 0
Training loss: 0.26417650041768714
Validation loss: 2.4904998301944192

Epoch: 6| Step: 1
Training loss: 0.2511257959935213
Validation loss: 2.5049628271617603

Epoch: 6| Step: 2
Training loss: 0.2851574257604319
Validation loss: 2.508536413378071

Epoch: 6| Step: 3
Training loss: 0.22847524106782785
Validation loss: 2.471730029847748

Epoch: 6| Step: 4
Training loss: 0.2991192963658556
Validation loss: 2.4880494939497146

Epoch: 6| Step: 5
Training loss: 0.17534614330270362
Validation loss: 2.5051136027503054

Epoch: 6| Step: 6
Training loss: 0.22269119022008746
Validation loss: 2.512117245327907

Epoch: 6| Step: 7
Training loss: 0.09655497917497306
Validation loss: 2.4945632659095036

Epoch: 6| Step: 8
Training loss: 0.21749125789195783
Validation loss: 2.542321971118583

Epoch: 6| Step: 9
Training loss: 0.2757198043754658
Validation loss: 2.474186206074661

Epoch: 6| Step: 10
Training loss: 0.235405563554025
Validation loss: 2.4254436599170197

Epoch: 6| Step: 11
Training loss: 0.21476642777787947
Validation loss: 2.408824617736203

Epoch: 6| Step: 12
Training loss: 0.2576249336194467
Validation loss: 2.404956372940498

Epoch: 6| Step: 13
Training loss: 0.2470360532386547
Validation loss: 2.4247951214238768

Epoch: 454| Step: 0
Training loss: 0.21910908721989802
Validation loss: 2.4310111357687365

Epoch: 6| Step: 1
Training loss: 0.22010467209391613
Validation loss: 2.4839497730713016

Epoch: 6| Step: 2
Training loss: 0.2125116001497156
Validation loss: 2.5035999814624876

Epoch: 6| Step: 3
Training loss: 0.17237066733985107
Validation loss: 2.485273335388171

Epoch: 6| Step: 4
Training loss: 0.15301722436491894
Validation loss: 2.505321553766354

Epoch: 6| Step: 5
Training loss: 0.20300964601271176
Validation loss: 2.5011582296239916

Epoch: 6| Step: 6
Training loss: 0.24716895475156994
Validation loss: 2.5236026221355603

Epoch: 6| Step: 7
Training loss: 0.24199839869572362
Validation loss: 2.5337020085878095

Epoch: 6| Step: 8
Training loss: 0.16887232686820622
Validation loss: 2.5448455918737523

Epoch: 6| Step: 9
Training loss: 0.15870632394952597
Validation loss: 2.5541381777204175

Epoch: 6| Step: 10
Training loss: 0.25021114969269853
Validation loss: 2.539012788928042

Epoch: 6| Step: 11
Training loss: 0.25535158918012085
Validation loss: 2.5319251959322506

Epoch: 6| Step: 12
Training loss: 0.18176436567595794
Validation loss: 2.545588933330287

Epoch: 6| Step: 13
Training loss: 0.28999219059705855
Validation loss: 2.501052595886355

Epoch: 455| Step: 0
Training loss: 0.15334191139818337
Validation loss: 2.4657829651734926

Epoch: 6| Step: 1
Training loss: 0.22047812884608942
Validation loss: 2.44858818626828

Epoch: 6| Step: 2
Training loss: 0.26480171297605515
Validation loss: 2.4781008551230506

Epoch: 6| Step: 3
Training loss: 0.22818979035635722
Validation loss: 2.4410397710910794

Epoch: 6| Step: 4
Training loss: 0.2243319747232058
Validation loss: 2.4213982215005982

Epoch: 6| Step: 5
Training loss: 0.28524454918349923
Validation loss: 2.4454729046657624

Epoch: 6| Step: 6
Training loss: 0.19983383667123933
Validation loss: 2.419357650235638

Epoch: 6| Step: 7
Training loss: 0.29002721999937964
Validation loss: 2.454217456804827

Epoch: 6| Step: 8
Training loss: 0.19502490804611639
Validation loss: 2.448813420036827

Epoch: 6| Step: 9
Training loss: 0.32016094623209945
Validation loss: 2.496423313157488

Epoch: 6| Step: 10
Training loss: 0.27283441248019874
Validation loss: 2.4893956542063145

Epoch: 6| Step: 11
Training loss: 0.243624974244431
Validation loss: 2.49332493805252

Epoch: 6| Step: 12
Training loss: 0.1847959683041961
Validation loss: 2.539020410130487

Epoch: 6| Step: 13
Training loss: 0.14787099677775373
Validation loss: 2.5135439595671065

Epoch: 456| Step: 0
Training loss: 0.3243965213082293
Validation loss: 2.510872033467958

Epoch: 6| Step: 1
Training loss: 0.2186409303685792
Validation loss: 2.4573246834306715

Epoch: 6| Step: 2
Training loss: 0.19340322941233304
Validation loss: 2.439426614652493

Epoch: 6| Step: 3
Training loss: 0.277864585001742
Validation loss: 2.415120275743856

Epoch: 6| Step: 4
Training loss: 0.1973901582185602
Validation loss: 2.44917976573544

Epoch: 6| Step: 5
Training loss: 0.1966138970234663
Validation loss: 2.4243110284829403

Epoch: 6| Step: 6
Training loss: 0.2072144992923378
Validation loss: 2.4206497872213646

Epoch: 6| Step: 7
Training loss: 0.19258342488019983
Validation loss: 2.3873250309512564

Epoch: 6| Step: 8
Training loss: 0.1612155470710156
Validation loss: 2.4325219503154565

Epoch: 6| Step: 9
Training loss: 0.32535109354242536
Validation loss: 2.505897407932719

Epoch: 6| Step: 10
Training loss: 0.173333879824917
Validation loss: 2.566223445688796

Epoch: 6| Step: 11
Training loss: 0.22565764571422425
Validation loss: 2.5667531542941644

Epoch: 6| Step: 12
Training loss: 0.37646876232913173
Validation loss: 2.5441708069576023

Epoch: 6| Step: 13
Training loss: 0.26974141869316787
Validation loss: 2.4976615264425353

Epoch: 457| Step: 0
Training loss: 0.20598346148113778
Validation loss: 2.497793317904485

Epoch: 6| Step: 1
Training loss: 0.2890671652340094
Validation loss: 2.467596070744507

Epoch: 6| Step: 2
Training loss: 0.18794146859051403
Validation loss: 2.4035464588575124

Epoch: 6| Step: 3
Training loss: 0.27352334446107485
Validation loss: 2.400367307029468

Epoch: 6| Step: 4
Training loss: 0.20888071073833053
Validation loss: 2.4088413543936915

Epoch: 6| Step: 5
Training loss: 0.3292519539888775
Validation loss: 2.4136903489703143

Epoch: 6| Step: 6
Training loss: 0.34537753705291624
Validation loss: 2.3774051631274

Epoch: 6| Step: 7
Training loss: 0.20855636082999846
Validation loss: 2.442146635676458

Epoch: 6| Step: 8
Training loss: 0.18573768241224362
Validation loss: 2.483883163649672

Epoch: 6| Step: 9
Training loss: 0.2170989535295523
Validation loss: 2.4803343191515066

Epoch: 6| Step: 10
Training loss: 0.12205817352973634
Validation loss: 2.4840587162594723

Epoch: 6| Step: 11
Training loss: 0.29133804433297705
Validation loss: 2.4804943380214093

Epoch: 6| Step: 12
Training loss: 0.32805079801884207
Validation loss: 2.478771253843475

Epoch: 6| Step: 13
Training loss: 0.17489447498778582
Validation loss: 2.4524944710748366

Epoch: 458| Step: 0
Training loss: 0.15342794273002483
Validation loss: 2.4419866056679362

Epoch: 6| Step: 1
Training loss: 0.3315935615961073
Validation loss: 2.4686934024734963

Epoch: 6| Step: 2
Training loss: 0.25168231338109226
Validation loss: 2.414244998562416

Epoch: 6| Step: 3
Training loss: 0.36206824306711927
Validation loss: 2.4187036747529262

Epoch: 6| Step: 4
Training loss: 0.17955395670323282
Validation loss: 2.3967815204621488

Epoch: 6| Step: 5
Training loss: 0.19508245271611355
Validation loss: 2.3991791417347788

Epoch: 6| Step: 6
Training loss: 0.29332568994953184
Validation loss: 2.4074108113588313

Epoch: 6| Step: 7
Training loss: 0.2466411104339472
Validation loss: 2.4414210454020773

Epoch: 6| Step: 8
Training loss: 0.2755094637024213
Validation loss: 2.459813993526444

Epoch: 6| Step: 9
Training loss: 0.18058940272685725
Validation loss: 2.47433818152756

Epoch: 6| Step: 10
Training loss: 0.21860852094129943
Validation loss: 2.526338161316332

Epoch: 6| Step: 11
Training loss: 0.17779157577450044
Validation loss: 2.4852212259375936

Epoch: 6| Step: 12
Training loss: 0.22148644010734905
Validation loss: 2.5328672694653998

Epoch: 6| Step: 13
Training loss: 0.2716660886277639
Validation loss: 2.55668159052891

Epoch: 459| Step: 0
Training loss: 0.3071701798353685
Validation loss: 2.5586031094082204

Epoch: 6| Step: 1
Training loss: 0.29396063425680713
Validation loss: 2.56040264388696

Epoch: 6| Step: 2
Training loss: 0.20575350404191337
Validation loss: 2.559044315407159

Epoch: 6| Step: 3
Training loss: 0.2265351295381059
Validation loss: 2.493244175109259

Epoch: 6| Step: 4
Training loss: 0.3448097841779202
Validation loss: 2.4333034978237973

Epoch: 6| Step: 5
Training loss: 0.23214127728689665
Validation loss: 2.408680704928128

Epoch: 6| Step: 6
Training loss: 0.2860894023787844
Validation loss: 2.4183914902042845

Epoch: 6| Step: 7
Training loss: 0.31884398757669985
Validation loss: 2.4429806793320505

Epoch: 6| Step: 8
Training loss: 0.31264660495825436
Validation loss: 2.4617372087525915

Epoch: 6| Step: 9
Training loss: 0.3044713794383675
Validation loss: 2.504104165921642

Epoch: 6| Step: 10
Training loss: 0.18217999352879669
Validation loss: 2.513798373502884

Epoch: 6| Step: 11
Training loss: 0.22034575637447093
Validation loss: 2.5757265759763714

Epoch: 6| Step: 12
Training loss: 0.24180120763147792
Validation loss: 2.5403506026941844

Epoch: 6| Step: 13
Training loss: 0.3267793309707232
Validation loss: 2.593411655451186

Epoch: 460| Step: 0
Training loss: 0.2962243831198305
Validation loss: 2.5590838559940665

Epoch: 6| Step: 1
Training loss: 0.17611241405045525
Validation loss: 2.5056959319884013

Epoch: 6| Step: 2
Training loss: 0.29882810006733707
Validation loss: 2.504725710969554

Epoch: 6| Step: 3
Training loss: 0.2624895786305736
Validation loss: 2.464777913984173

Epoch: 6| Step: 4
Training loss: 0.14707828287359112
Validation loss: 2.439727398653087

Epoch: 6| Step: 5
Training loss: 0.275598799028915
Validation loss: 2.445379993354243

Epoch: 6| Step: 6
Training loss: 0.1949214167006615
Validation loss: 2.4449806117890747

Epoch: 6| Step: 7
Training loss: 0.26168451512312857
Validation loss: 2.488854991182217

Epoch: 6| Step: 8
Training loss: 0.1410516254406442
Validation loss: 2.503116963646463

Epoch: 6| Step: 9
Training loss: 0.2826632780442326
Validation loss: 2.539564161445245

Epoch: 6| Step: 10
Training loss: 0.25454799540814455
Validation loss: 2.5326837479455073

Epoch: 6| Step: 11
Training loss: 0.22235166898821168
Validation loss: 2.5383695660561196

Epoch: 6| Step: 12
Training loss: 0.1939391969790331
Validation loss: 2.536041278709807

Epoch: 6| Step: 13
Training loss: 0.17393950847791606
Validation loss: 2.5604642359405685

Epoch: 461| Step: 0
Training loss: 0.19936634654814692
Validation loss: 2.5497642006732217

Epoch: 6| Step: 1
Training loss: 0.15546732020080067
Validation loss: 2.528217321481957

Epoch: 6| Step: 2
Training loss: 0.28869743750184496
Validation loss: 2.514245878836801

Epoch: 6| Step: 3
Training loss: 0.2414356991480757
Validation loss: 2.5441344566336754

Epoch: 6| Step: 4
Training loss: 0.2314585187017372
Validation loss: 2.5041711230191694

Epoch: 6| Step: 5
Training loss: 0.3271921840285076
Validation loss: 2.5500374672421526

Epoch: 6| Step: 6
Training loss: 0.338448444393791
Validation loss: 2.518508712540486

Epoch: 6| Step: 7
Training loss: 0.20913765535750697
Validation loss: 2.567587571433841

Epoch: 6| Step: 8
Training loss: 0.19353327011958654
Validation loss: 2.5621698638563313

Epoch: 6| Step: 9
Training loss: 0.1901026240159939
Validation loss: 2.5519956287802814

Epoch: 6| Step: 10
Training loss: 0.23586446819132173
Validation loss: 2.575857711402046

Epoch: 6| Step: 11
Training loss: 0.2183643586164981
Validation loss: 2.583892050477695

Epoch: 6| Step: 12
Training loss: 0.2952678999953725
Validation loss: 2.5643548832531904

Epoch: 6| Step: 13
Training loss: 0.2754406443953725
Validation loss: 2.5443032564371184

Epoch: 462| Step: 0
Training loss: 0.25525751742839003
Validation loss: 2.539531637792509

Epoch: 6| Step: 1
Training loss: 0.28490341421684473
Validation loss: 2.5254221623493245

Epoch: 6| Step: 2
Training loss: 0.18162185818106927
Validation loss: 2.494358530122687

Epoch: 6| Step: 3
Training loss: 0.1950614173618329
Validation loss: 2.5322434270981886

Epoch: 6| Step: 4
Training loss: 0.3382715712785919
Validation loss: 2.5135394519793617

Epoch: 6| Step: 5
Training loss: 0.1886076496030495
Validation loss: 2.496695698488623

Epoch: 6| Step: 6
Training loss: 0.1784843926685628
Validation loss: 2.5045162108964742

Epoch: 6| Step: 7
Training loss: 0.24571285592415457
Validation loss: 2.501601358497616

Epoch: 6| Step: 8
Training loss: 0.2837814739601538
Validation loss: 2.5328726702899953

Epoch: 6| Step: 9
Training loss: 0.2253949731840399
Validation loss: 2.5318678194716373

Epoch: 6| Step: 10
Training loss: 0.31976324766959
Validation loss: 2.546810462124402

Epoch: 6| Step: 11
Training loss: 0.17104095511011605
Validation loss: 2.5449097454054694

Epoch: 6| Step: 12
Training loss: 0.21869980713064396
Validation loss: 2.5674811400843844

Epoch: 6| Step: 13
Training loss: 0.40017333298473756
Validation loss: 2.5336834892489626

Epoch: 463| Step: 0
Training loss: 0.2113255798553243
Validation loss: 2.6074124971357624

Epoch: 6| Step: 1
Training loss: 0.39089411048785316
Validation loss: 2.551183684048385

Epoch: 6| Step: 2
Training loss: 0.20753069679291064
Validation loss: 2.5601272302333853

Epoch: 6| Step: 3
Training loss: 0.22403648957042366
Validation loss: 2.5742927695115236

Epoch: 6| Step: 4
Training loss: 0.21930576296938728
Validation loss: 2.547197474630165

Epoch: 6| Step: 5
Training loss: 0.2285645913374462
Validation loss: 2.527784856383458

Epoch: 6| Step: 6
Training loss: 0.24353948207644457
Validation loss: 2.546123676417242

Epoch: 6| Step: 7
Training loss: 0.22081823638528486
Validation loss: 2.6087327716632585

Epoch: 6| Step: 8
Training loss: 0.22954876790672615
Validation loss: 2.5418185886816747

Epoch: 6| Step: 9
Training loss: 0.3179554278045546
Validation loss: 2.548040897594492

Epoch: 6| Step: 10
Training loss: 0.21451105888242283
Validation loss: 2.5393420175525727

Epoch: 6| Step: 11
Training loss: 0.2538126846459343
Validation loss: 2.525086699355479

Epoch: 6| Step: 12
Training loss: 0.21436238549267406
Validation loss: 2.548683521413824

Epoch: 6| Step: 13
Training loss: 0.20947426570816446
Validation loss: 2.5824646115953502

Epoch: 464| Step: 0
Training loss: 0.2873380878880083
Validation loss: 2.5765486615544386

Epoch: 6| Step: 1
Training loss: 0.2852020226935183
Validation loss: 2.583400257711112

Epoch: 6| Step: 2
Training loss: 0.21013683669037944
Validation loss: 2.5568542626852344

Epoch: 6| Step: 3
Training loss: 0.19529456056224043
Validation loss: 2.535428221424112

Epoch: 6| Step: 4
Training loss: 0.185262441966351
Validation loss: 2.5568186569337725

Epoch: 6| Step: 5
Training loss: 0.1395113078323202
Validation loss: 2.536327445520876

Epoch: 6| Step: 6
Training loss: 0.1922929912344491
Validation loss: 2.473664415880161

Epoch: 6| Step: 7
Training loss: 0.28416685357232163
Validation loss: 2.505755722711354

Epoch: 6| Step: 8
Training loss: 0.1780761116264122
Validation loss: 2.4972414438230786

Epoch: 6| Step: 9
Training loss: 0.2810974369581239
Validation loss: 2.452328199509984

Epoch: 6| Step: 10
Training loss: 0.24929181017582766
Validation loss: 2.4775200685036576

Epoch: 6| Step: 11
Training loss: 0.23341696757415567
Validation loss: 2.5246670535634994

Epoch: 6| Step: 12
Training loss: 0.24628320092555234
Validation loss: 2.5097320430541137

Epoch: 6| Step: 13
Training loss: 0.1721027285279083
Validation loss: 2.543649120879776

Epoch: 465| Step: 0
Training loss: 0.1762248798994731
Validation loss: 2.5430892326794954

Epoch: 6| Step: 1
Training loss: 0.2566572227510685
Validation loss: 2.5026628023580018

Epoch: 6| Step: 2
Training loss: 0.285068563801196
Validation loss: 2.548606088475449

Epoch: 6| Step: 3
Training loss: 0.23766113323885452
Validation loss: 2.4844607230522495

Epoch: 6| Step: 4
Training loss: 0.2961820244364497
Validation loss: 2.4911162032540646

Epoch: 6| Step: 5
Training loss: 0.2538294896223841
Validation loss: 2.4611752318578692

Epoch: 6| Step: 6
Training loss: 0.1775204555383745
Validation loss: 2.4693873781934386

Epoch: 6| Step: 7
Training loss: 0.19584013241436263
Validation loss: 2.4486201956005513

Epoch: 6| Step: 8
Training loss: 0.2856426793225891
Validation loss: 2.436042444513725

Epoch: 6| Step: 9
Training loss: 0.16273492168384135
Validation loss: 2.490408237411188

Epoch: 6| Step: 10
Training loss: 0.21584697921124563
Validation loss: 2.481232732971719

Epoch: 6| Step: 11
Training loss: 0.20476944717164194
Validation loss: 2.4997341773520128

Epoch: 6| Step: 12
Training loss: 0.15729936845083342
Validation loss: 2.511587612698077

Epoch: 6| Step: 13
Training loss: 0.11647490966328304
Validation loss: 2.5295728958485357

Epoch: 466| Step: 0
Training loss: 0.2247880805250689
Validation loss: 2.5295939079888177

Epoch: 6| Step: 1
Training loss: 0.20904123121108145
Validation loss: 2.4791909748587426

Epoch: 6| Step: 2
Training loss: 0.1735936201079644
Validation loss: 2.5229599724151246

Epoch: 6| Step: 3
Training loss: 0.22988718817864326
Validation loss: 2.5011416730448217

Epoch: 6| Step: 4
Training loss: 0.1121751535815664
Validation loss: 2.4737602428323773

Epoch: 6| Step: 5
Training loss: 0.14126970273986728
Validation loss: 2.5293540523374394

Epoch: 6| Step: 6
Training loss: 0.16897640603649217
Validation loss: 2.4830257967251717

Epoch: 6| Step: 7
Training loss: 0.2701205018254616
Validation loss: 2.504778789209013

Epoch: 6| Step: 8
Training loss: 0.1601747874254817
Validation loss: 2.49187614817494

Epoch: 6| Step: 9
Training loss: 0.07901838426937548
Validation loss: 2.513427034032606

Epoch: 6| Step: 10
Training loss: 0.27939111946846856
Validation loss: 2.5233522006626257

Epoch: 6| Step: 11
Training loss: 0.1646525241077671
Validation loss: 2.5027575497341346

Epoch: 6| Step: 12
Training loss: 0.16301511608758432
Validation loss: 2.5100056233408647

Epoch: 6| Step: 13
Training loss: 0.1573766560603718
Validation loss: 2.4800782182804997

Epoch: 467| Step: 0
Training loss: 0.18095216204149286
Validation loss: 2.4694127047076013

Epoch: 6| Step: 1
Training loss: 0.2568855092759889
Validation loss: 2.48772226442242

Epoch: 6| Step: 2
Training loss: 0.21900979010590244
Validation loss: 2.457355966834203

Epoch: 6| Step: 3
Training loss: 0.12237883679762615
Validation loss: 2.4478783553212122

Epoch: 6| Step: 4
Training loss: 0.11044037882188973
Validation loss: 2.493808312507507

Epoch: 6| Step: 5
Training loss: 0.18809774605352772
Validation loss: 2.482225115403856

Epoch: 6| Step: 6
Training loss: 0.12985645829910322
Validation loss: 2.453283307571749

Epoch: 6| Step: 7
Training loss: 0.19863574420637153
Validation loss: 2.443483642383171

Epoch: 6| Step: 8
Training loss: 0.1378824571994732
Validation loss: 2.4871257181942497

Epoch: 6| Step: 9
Training loss: 0.2190416809670038
Validation loss: 2.5077878899514072

Epoch: 6| Step: 10
Training loss: 0.24816468212183032
Validation loss: 2.5069412068790644

Epoch: 6| Step: 11
Training loss: 0.157011115505646
Validation loss: 2.5066442284772146

Epoch: 6| Step: 12
Training loss: 0.21109317403922295
Validation loss: 2.516072068372874

Epoch: 6| Step: 13
Training loss: 0.06183444802411555
Validation loss: 2.5294697916427635

Epoch: 468| Step: 0
Training loss: 0.18833795698645553
Validation loss: 2.5059303844816623

Epoch: 6| Step: 1
Training loss: 0.13669284166356327
Validation loss: 2.530681114729195

Epoch: 6| Step: 2
Training loss: 0.20778723111367317
Validation loss: 2.498385308890244

Epoch: 6| Step: 3
Training loss: 0.13204701797862195
Validation loss: 2.500476119121017

Epoch: 6| Step: 4
Training loss: 0.1494992829675607
Validation loss: 2.5138408530374012

Epoch: 6| Step: 5
Training loss: 0.18177182576219186
Validation loss: 2.4800758418180955

Epoch: 6| Step: 6
Training loss: 0.250501636052452
Validation loss: 2.495515166164778

Epoch: 6| Step: 7
Training loss: 0.1669168804420947
Validation loss: 2.4684130598498113

Epoch: 6| Step: 8
Training loss: 0.11304991219110971
Validation loss: 2.4857107245168533

Epoch: 6| Step: 9
Training loss: 0.12420117415838343
Validation loss: 2.522132250741875

Epoch: 6| Step: 10
Training loss: 0.14826797542503967
Validation loss: 2.5011559510893266

Epoch: 6| Step: 11
Training loss: 0.1471752785105765
Validation loss: 2.5176419286047

Epoch: 6| Step: 12
Training loss: 0.20424284904444925
Validation loss: 2.5145949676114303

Epoch: 6| Step: 13
Training loss: 0.1539446153603183
Validation loss: 2.5041605794144433

Epoch: 469| Step: 0
Training loss: 0.22435671652148606
Validation loss: 2.4932421196668786

Epoch: 6| Step: 1
Training loss: 0.14779763592589584
Validation loss: 2.492740315323506

Epoch: 6| Step: 2
Training loss: 0.30283592735817794
Validation loss: 2.5242229491278327

Epoch: 6| Step: 3
Training loss: 0.14922626386568338
Validation loss: 2.503246076555391

Epoch: 6| Step: 4
Training loss: 0.12952938609973688
Validation loss: 2.502475405658425

Epoch: 6| Step: 5
Training loss: 0.22504262189362795
Validation loss: 2.4996831775204433

Epoch: 6| Step: 6
Training loss: 0.12644696201289132
Validation loss: 2.5233401718477215

Epoch: 6| Step: 7
Training loss: 0.09237112854509145
Validation loss: 2.492259915704198

Epoch: 6| Step: 8
Training loss: 0.1457614991402227
Validation loss: 2.484515235117622

Epoch: 6| Step: 9
Training loss: 0.1321421422764136
Validation loss: 2.4655750337127276

Epoch: 6| Step: 10
Training loss: 0.1477817052897496
Validation loss: 2.4556969966644515

Epoch: 6| Step: 11
Training loss: 0.14272366241861326
Validation loss: 2.4853371524004215

Epoch: 6| Step: 12
Training loss: 0.12915432785176642
Validation loss: 2.4913342977898076

Epoch: 6| Step: 13
Training loss: 0.09874547057689115
Validation loss: 2.4920885563587984

Epoch: 470| Step: 0
Training loss: 0.13115132204340943
Validation loss: 2.5125754171043937

Epoch: 6| Step: 1
Training loss: 0.21861231251310015
Validation loss: 2.5160754888376022

Epoch: 6| Step: 2
Training loss: 0.14423692220927029
Validation loss: 2.541131691701153

Epoch: 6| Step: 3
Training loss: 0.27035494730197024
Validation loss: 2.508466739831937

Epoch: 6| Step: 4
Training loss: 0.17182711996395256
Validation loss: 2.5284034313143717

Epoch: 6| Step: 5
Training loss: 0.09234544510423195
Validation loss: 2.520395467858683

Epoch: 6| Step: 6
Training loss: 0.2221039480672782
Validation loss: 2.4760102665328665

Epoch: 6| Step: 7
Training loss: 0.13619647405187385
Validation loss: 2.499329773471704

Epoch: 6| Step: 8
Training loss: 0.15005270657801092
Validation loss: 2.4648426667539285

Epoch: 6| Step: 9
Training loss: 0.17401296988708034
Validation loss: 2.4885747281250508

Epoch: 6| Step: 10
Training loss: 0.17378611539201183
Validation loss: 2.5022794965283253

Epoch: 6| Step: 11
Training loss: 0.13952819609423742
Validation loss: 2.4779084081116647

Epoch: 6| Step: 12
Training loss: 0.09891283773416165
Validation loss: 2.5207403971470663

Epoch: 6| Step: 13
Training loss: 0.21895929099659023
Validation loss: 2.5143127035052295

Epoch: 471| Step: 0
Training loss: 0.1864685656938366
Validation loss: 2.5773066698916045

Epoch: 6| Step: 1
Training loss: 0.18035507585401295
Validation loss: 2.567241882343787

Epoch: 6| Step: 2
Training loss: 0.10424612164115525
Validation loss: 2.591698144447818

Epoch: 6| Step: 3
Training loss: 0.14251356100087784
Validation loss: 2.5890934589741703

Epoch: 6| Step: 4
Training loss: 0.2164816153635036
Validation loss: 2.5467511752233065

Epoch: 6| Step: 5
Training loss: 0.22255328792659956
Validation loss: 2.546335663376696

Epoch: 6| Step: 6
Training loss: 0.1951389686256991
Validation loss: 2.523081092018263

Epoch: 6| Step: 7
Training loss: 0.21377203405317088
Validation loss: 2.4706546886189975

Epoch: 6| Step: 8
Training loss: 0.1761230272039789
Validation loss: 2.5049904318419984

Epoch: 6| Step: 9
Training loss: 0.15914533981732443
Validation loss: 2.4682593584346066

Epoch: 6| Step: 10
Training loss: 0.1954101032521997
Validation loss: 2.4412190599440797

Epoch: 6| Step: 11
Training loss: 0.17454789656037178
Validation loss: 2.46586595985043

Epoch: 6| Step: 12
Training loss: 0.17441232430509299
Validation loss: 2.4427633188595155

Epoch: 6| Step: 13
Training loss: 0.09623014086510102
Validation loss: 2.470508029441102

Epoch: 472| Step: 0
Training loss: 0.12528663048355412
Validation loss: 2.4645428649155683

Epoch: 6| Step: 1
Training loss: 0.13474386841229863
Validation loss: 2.4618999983903502

Epoch: 6| Step: 2
Training loss: 0.11598748675040124
Validation loss: 2.4769312894964717

Epoch: 6| Step: 3
Training loss: 0.1801075276266589
Validation loss: 2.5162140203741394

Epoch: 6| Step: 4
Training loss: 0.237458685368361
Validation loss: 2.538584977422106

Epoch: 6| Step: 5
Training loss: 0.09133445659060434
Validation loss: 2.5225083557395087

Epoch: 6| Step: 6
Training loss: 0.26146976527010896
Validation loss: 2.5349048842743

Epoch: 6| Step: 7
Training loss: 0.16330432546269152
Validation loss: 2.5763903049947556

Epoch: 6| Step: 8
Training loss: 0.18891021766944777
Validation loss: 2.492459017281863

Epoch: 6| Step: 9
Training loss: 0.23406350576136287
Validation loss: 2.4879602746909004

Epoch: 6| Step: 10
Training loss: 0.17499754299414463
Validation loss: 2.470183894179624

Epoch: 6| Step: 11
Training loss: 0.13484946697399916
Validation loss: 2.427441750921429

Epoch: 6| Step: 12
Training loss: 0.1951539826853171
Validation loss: 2.438147620534099

Epoch: 6| Step: 13
Training loss: 0.2966315501012727
Validation loss: 2.4299899009583523

Epoch: 473| Step: 0
Training loss: 0.1514614734483747
Validation loss: 2.4552659551646108

Epoch: 6| Step: 1
Training loss: 0.1768916555926746
Validation loss: 2.4818991982846015

Epoch: 6| Step: 2
Training loss: 0.11242352707784226
Validation loss: 2.470582464973944

Epoch: 6| Step: 3
Training loss: 0.1380005085273198
Validation loss: 2.5628127440724313

Epoch: 6| Step: 4
Training loss: 0.2940504196677402
Validation loss: 2.5100486103294686

Epoch: 6| Step: 5
Training loss: 0.16423911284191842
Validation loss: 2.5353552645079724

Epoch: 6| Step: 6
Training loss: 0.2024377328453833
Validation loss: 2.572229605927804

Epoch: 6| Step: 7
Training loss: 0.10189805626324448
Validation loss: 2.5412501207812914

Epoch: 6| Step: 8
Training loss: 0.13741165731460203
Validation loss: 2.5254266766439586

Epoch: 6| Step: 9
Training loss: 0.11910145928793464
Validation loss: 2.51985372209613

Epoch: 6| Step: 10
Training loss: 0.1641080827060126
Validation loss: 2.4990609056194404

Epoch: 6| Step: 11
Training loss: 0.2802437424297158
Validation loss: 2.5164605563648945

Epoch: 6| Step: 12
Training loss: 0.1631343221558495
Validation loss: 2.4736856997943777

Epoch: 6| Step: 13
Training loss: 0.17073440854328922
Validation loss: 2.4795220732912773

Epoch: 474| Step: 0
Training loss: 0.1621611409092064
Validation loss: 2.454934567761036

Epoch: 6| Step: 1
Training loss: 0.2568595788322423
Validation loss: 2.454656298192682

Epoch: 6| Step: 2
Training loss: 0.1620723498242343
Validation loss: 2.4490805877394153

Epoch: 6| Step: 3
Training loss: 0.11884595435623652
Validation loss: 2.4630939848934905

Epoch: 6| Step: 4
Training loss: 0.15641581558488163
Validation loss: 2.4951442794977736

Epoch: 6| Step: 5
Training loss: 0.14266026103720214
Validation loss: 2.472718053686653

Epoch: 6| Step: 6
Training loss: 0.1805717748047102
Validation loss: 2.467497507254431

Epoch: 6| Step: 7
Training loss: 0.22063736231212136
Validation loss: 2.4945655699920377

Epoch: 6| Step: 8
Training loss: 0.16767111179113053
Validation loss: 2.4961960729667876

Epoch: 6| Step: 9
Training loss: 0.18189443268144007
Validation loss: 2.480440473472054

Epoch: 6| Step: 10
Training loss: 0.2006721493318817
Validation loss: 2.508855568599729

Epoch: 6| Step: 11
Training loss: 0.15212182239451708
Validation loss: 2.493615712954693

Epoch: 6| Step: 12
Training loss: 0.0839760077544505
Validation loss: 2.489244394137427

Epoch: 6| Step: 13
Training loss: 0.19480709488266412
Validation loss: 2.4998683833270086

Epoch: 475| Step: 0
Training loss: 0.25042860722015015
Validation loss: 2.518402865966543

Epoch: 6| Step: 1
Training loss: 0.1428684388211928
Validation loss: 2.4997836778223133

Epoch: 6| Step: 2
Training loss: 0.11602899589938112
Validation loss: 2.5242390227196494

Epoch: 6| Step: 3
Training loss: 0.13538606157222877
Validation loss: 2.4814885876195567

Epoch: 6| Step: 4
Training loss: 0.1555992223559152
Validation loss: 2.47598629761523

Epoch: 6| Step: 5
Training loss: 0.21655261395611258
Validation loss: 2.4836304118233423

Epoch: 6| Step: 6
Training loss: 0.12862604203928144
Validation loss: 2.4938853014939895

Epoch: 6| Step: 7
Training loss: 0.16980120879743862
Validation loss: 2.4950456935440104

Epoch: 6| Step: 8
Training loss: 0.14124042234821704
Validation loss: 2.4867419257213923

Epoch: 6| Step: 9
Training loss: 0.22065981718528685
Validation loss: 2.495613752063295

Epoch: 6| Step: 10
Training loss: 0.19941023431553853
Validation loss: 2.4852457448307375

Epoch: 6| Step: 11
Training loss: 0.2337337782274777
Validation loss: 2.5087648687368564

Epoch: 6| Step: 12
Training loss: 0.1614792769189756
Validation loss: 2.488205735607835

Epoch: 6| Step: 13
Training loss: 0.14151431717362542
Validation loss: 2.485672239350448

Epoch: 476| Step: 0
Training loss: 0.1747422239916082
Validation loss: 2.4671689177430967

Epoch: 6| Step: 1
Training loss: 0.11021312537198127
Validation loss: 2.4638242771268293

Epoch: 6| Step: 2
Training loss: 0.17905120557679036
Validation loss: 2.4749377250605313

Epoch: 6| Step: 3
Training loss: 0.21774905970684647
Validation loss: 2.4914703700354432

Epoch: 6| Step: 4
Training loss: 0.14674706746401125
Validation loss: 2.474068693971221

Epoch: 6| Step: 5
Training loss: 0.15599828352465261
Validation loss: 2.495501745492456

Epoch: 6| Step: 6
Training loss: 0.11279016136209638
Validation loss: 2.5060616398174655

Epoch: 6| Step: 7
Training loss: 0.12124080342878625
Validation loss: 2.4636117057640834

Epoch: 6| Step: 8
Training loss: 0.14812320764479306
Validation loss: 2.505529674767468

Epoch: 6| Step: 9
Training loss: 0.19028513385908127
Validation loss: 2.4407199325145648

Epoch: 6| Step: 10
Training loss: 0.13756878768627837
Validation loss: 2.4926768873685385

Epoch: 6| Step: 11
Training loss: 0.26930866172500506
Validation loss: 2.5045937617541507

Epoch: 6| Step: 12
Training loss: 0.12024928404546333
Validation loss: 2.5061460114026226

Epoch: 6| Step: 13
Training loss: 0.12537684855139503
Validation loss: 2.550906732356543

Epoch: 477| Step: 0
Training loss: 0.13077397905097787
Validation loss: 2.5031803185775714

Epoch: 6| Step: 1
Training loss: 0.14827952009102421
Validation loss: 2.497129979689763

Epoch: 6| Step: 2
Training loss: 0.2748297668378493
Validation loss: 2.5020550843660456

Epoch: 6| Step: 3
Training loss: 0.22341085021607685
Validation loss: 2.4885618283752957

Epoch: 6| Step: 4
Training loss: 0.10869276623419162
Validation loss: 2.457769624065312

Epoch: 6| Step: 5
Training loss: 0.10409819219977255
Validation loss: 2.481608185347615

Epoch: 6| Step: 6
Training loss: 0.19368598788084448
Validation loss: 2.4882034230602836

Epoch: 6| Step: 7
Training loss: 0.22378193576762537
Validation loss: 2.483875065701464

Epoch: 6| Step: 8
Training loss: 0.20417480432258814
Validation loss: 2.4679251752334914

Epoch: 6| Step: 9
Training loss: 0.0735810831734566
Validation loss: 2.525697128772646

Epoch: 6| Step: 10
Training loss: 0.07168219871175897
Validation loss: 2.4440057722687154

Epoch: 6| Step: 11
Training loss: 0.30435734981613344
Validation loss: 2.4834666702846833

Epoch: 6| Step: 12
Training loss: 0.1294070975481553
Validation loss: 2.4692070141953137

Epoch: 6| Step: 13
Training loss: 0.11984343075492146
Validation loss: 2.419550454083109

Epoch: 478| Step: 0
Training loss: 0.15543689161748359
Validation loss: 2.482647412332783

Epoch: 6| Step: 1
Training loss: 0.08793978375971612
Validation loss: 2.466907885099858

Epoch: 6| Step: 2
Training loss: 0.27955845940814933
Validation loss: 2.480019865598183

Epoch: 6| Step: 3
Training loss: 0.10911510874440404
Validation loss: 2.4659270853882544

Epoch: 6| Step: 4
Training loss: 0.13592723884440122
Validation loss: 2.4648292435378654

Epoch: 6| Step: 5
Training loss: 0.22998638104980826
Validation loss: 2.469250071896366

Epoch: 6| Step: 6
Training loss: 0.12309038059177717
Validation loss: 2.470722833396176

Epoch: 6| Step: 7
Training loss: 0.17379676878930264
Validation loss: 2.4711110652587074

Epoch: 6| Step: 8
Training loss: 0.13392810140254785
Validation loss: 2.5012844662211053

Epoch: 6| Step: 9
Training loss: 0.13500325357966955
Validation loss: 2.4785007262475665

Epoch: 6| Step: 10
Training loss: 0.1008182962105875
Validation loss: 2.508215453406284

Epoch: 6| Step: 11
Training loss: 0.1338695228490948
Validation loss: 2.488598136436454

Epoch: 6| Step: 12
Training loss: 0.18038631430754276
Validation loss: 2.5291877487700605

Epoch: 6| Step: 13
Training loss: 0.15537999653320417
Validation loss: 2.482800753254012

Epoch: 479| Step: 0
Training loss: 0.08696653089663195
Validation loss: 2.491356551344789

Epoch: 6| Step: 1
Training loss: 0.22182038333434756
Validation loss: 2.482296045504737

Epoch: 6| Step: 2
Training loss: 0.20226047009809234
Validation loss: 2.501615105124705

Epoch: 6| Step: 3
Training loss: 0.15100544188179682
Validation loss: 2.5390605881701926

Epoch: 6| Step: 4
Training loss: 0.15277873197592312
Validation loss: 2.497970807084386

Epoch: 6| Step: 5
Training loss: 0.1282948531118214
Validation loss: 2.5249780561967228

Epoch: 6| Step: 6
Training loss: 0.17489679137106307
Validation loss: 2.5030353966762564

Epoch: 6| Step: 7
Training loss: 0.12884653037450894
Validation loss: 2.492353550746215

Epoch: 6| Step: 8
Training loss: 0.18422173579338658
Validation loss: 2.4828217420115135

Epoch: 6| Step: 9
Training loss: 0.14307510297465947
Validation loss: 2.4835578099181808

Epoch: 6| Step: 10
Training loss: 0.22845348100038976
Validation loss: 2.5074196590447677

Epoch: 6| Step: 11
Training loss: 0.15376512427878877
Validation loss: 2.500029210976201

Epoch: 6| Step: 12
Training loss: 0.14901669338259713
Validation loss: 2.4909206609789103

Epoch: 6| Step: 13
Training loss: 0.12565511901116902
Validation loss: 2.5001581921313853

Epoch: 480| Step: 0
Training loss: 0.10453931244946499
Validation loss: 2.5006160787088474

Epoch: 6| Step: 1
Training loss: 0.1924955260543365
Validation loss: 2.4781247968639613

Epoch: 6| Step: 2
Training loss: 0.218868206647481
Validation loss: 2.472426559940388

Epoch: 6| Step: 3
Training loss: 0.11279101184286854
Validation loss: 2.5117172363431832

Epoch: 6| Step: 4
Training loss: 0.17570945545155137
Validation loss: 2.451566073986288

Epoch: 6| Step: 5
Training loss: 0.15555257119095647
Validation loss: 2.4525143477472278

Epoch: 6| Step: 6
Training loss: 0.15232883282523496
Validation loss: 2.4394067122606296

Epoch: 6| Step: 7
Training loss: 0.24492710844103682
Validation loss: 2.426531041265106

Epoch: 6| Step: 8
Training loss: 0.157108932230822
Validation loss: 2.448813860777882

Epoch: 6| Step: 9
Training loss: 0.13400704661922
Validation loss: 2.4279494930247236

Epoch: 6| Step: 10
Training loss: 0.17864028910012497
Validation loss: 2.4507152422761824

Epoch: 6| Step: 11
Training loss: 0.1282309559259019
Validation loss: 2.4475846584930685

Epoch: 6| Step: 12
Training loss: 0.21941745632508605
Validation loss: 2.4548669997853794

Epoch: 6| Step: 13
Training loss: 0.10251533142865286
Validation loss: 2.4492487550260136

Epoch: 481| Step: 0
Training loss: 0.1936265756119367
Validation loss: 2.454878298142566

Epoch: 6| Step: 1
Training loss: 0.13944677984938283
Validation loss: 2.4458476465225014

Epoch: 6| Step: 2
Training loss: 0.11638663337859306
Validation loss: 2.458416216958042

Epoch: 6| Step: 3
Training loss: 0.19416174437937575
Validation loss: 2.4855833700133165

Epoch: 6| Step: 4
Training loss: 0.22741040697868134
Validation loss: 2.491447310779673

Epoch: 6| Step: 5
Training loss: 0.17628938029535524
Validation loss: 2.4491450746193095

Epoch: 6| Step: 6
Training loss: 0.15789864521146013
Validation loss: 2.4466731258704515

Epoch: 6| Step: 7
Training loss: 0.11347199691806253
Validation loss: 2.4397570244404903

Epoch: 6| Step: 8
Training loss: 0.14544982522771702
Validation loss: 2.4265855446566498

Epoch: 6| Step: 9
Training loss: 0.1247160263820317
Validation loss: 2.43014882051421

Epoch: 6| Step: 10
Training loss: 0.18000935670918694
Validation loss: 2.419029493401095

Epoch: 6| Step: 11
Training loss: 0.09273612125201965
Validation loss: 2.4643968432767447

Epoch: 6| Step: 12
Training loss: 0.16458672829840584
Validation loss: 2.4483532043538365

Epoch: 6| Step: 13
Training loss: 0.08162810113205594
Validation loss: 2.4322752424471124

Epoch: 482| Step: 0
Training loss: 0.14084798300276966
Validation loss: 2.436412186758117

Epoch: 6| Step: 1
Training loss: 0.12775330359522793
Validation loss: 2.4546250015320945

Epoch: 6| Step: 2
Training loss: 0.15160737209103756
Validation loss: 2.432225311407804

Epoch: 6| Step: 3
Training loss: 0.08181649150010706
Validation loss: 2.446764631219081

Epoch: 6| Step: 4
Training loss: 0.13946835036736563
Validation loss: 2.4584977282880294

Epoch: 6| Step: 5
Training loss: 0.13862748846051243
Validation loss: 2.4854510383885993

Epoch: 6| Step: 6
Training loss: 0.14727267190277807
Validation loss: 2.459932167824778

Epoch: 6| Step: 7
Training loss: 0.10469498963395546
Validation loss: 2.5014863845878925

Epoch: 6| Step: 8
Training loss: 0.15517335941448596
Validation loss: 2.4945891728416223

Epoch: 6| Step: 9
Training loss: 0.22412039563438044
Validation loss: 2.4736980252495164

Epoch: 6| Step: 10
Training loss: 0.27240268535760803
Validation loss: 2.4528584912581497

Epoch: 6| Step: 11
Training loss: 0.0963266844692014
Validation loss: 2.4192687842743883

Epoch: 6| Step: 12
Training loss: 0.0890266747951042
Validation loss: 2.428176285933281

Epoch: 6| Step: 13
Training loss: 0.12090486361506636
Validation loss: 2.3987781790021394

Epoch: 483| Step: 0
Training loss: 0.0994625645867661
Validation loss: 2.390447695925996

Epoch: 6| Step: 1
Training loss: 0.15746028776988213
Validation loss: 2.3760665944540387

Epoch: 6| Step: 2
Training loss: 0.16451906073938383
Validation loss: 2.4100805103727225

Epoch: 6| Step: 3
Training loss: 0.16936052709237404
Validation loss: 2.3786760226169896

Epoch: 6| Step: 4
Training loss: 0.2014439234039364
Validation loss: 2.4442963855576094

Epoch: 6| Step: 5
Training loss: 0.1019026625922137
Validation loss: 2.435255766047709

Epoch: 6| Step: 6
Training loss: 0.12427672107090305
Validation loss: 2.458783242206402

Epoch: 6| Step: 7
Training loss: 0.10564827651248766
Validation loss: 2.4857554981614576

Epoch: 6| Step: 8
Training loss: 0.20242976455595732
Validation loss: 2.4978886517904906

Epoch: 6| Step: 9
Training loss: 0.177467502150974
Validation loss: 2.4819117411830383

Epoch: 6| Step: 10
Training loss: 0.16428420436539917
Validation loss: 2.5262302701665447

Epoch: 6| Step: 11
Training loss: 0.13801885699410651
Validation loss: 2.456135899356958

Epoch: 6| Step: 12
Training loss: 0.2314349385443519
Validation loss: 2.4974605593788763

Epoch: 6| Step: 13
Training loss: 0.20218820226862785
Validation loss: 2.4637562526651156

Epoch: 484| Step: 0
Training loss: 0.21679958135616784
Validation loss: 2.4622523953970763

Epoch: 6| Step: 1
Training loss: 0.19448119634098018
Validation loss: 2.449658876184936

Epoch: 6| Step: 2
Training loss: 0.11777643592142739
Validation loss: 2.4582948088994856

Epoch: 6| Step: 3
Training loss: 0.13333756774148914
Validation loss: 2.4658209778890297

Epoch: 6| Step: 4
Training loss: 0.22207305893084597
Validation loss: 2.4658839311965055

Epoch: 6| Step: 5
Training loss: 0.162135903359465
Validation loss: 2.447923291017833

Epoch: 6| Step: 6
Training loss: 0.1549364187211334
Validation loss: 2.4283091870661155

Epoch: 6| Step: 7
Training loss: 0.22452145389856829
Validation loss: 2.4045723397871352

Epoch: 6| Step: 8
Training loss: 0.189628284141753
Validation loss: 2.436752942657607

Epoch: 6| Step: 9
Training loss: 0.14969568576609923
Validation loss: 2.429962306735291

Epoch: 6| Step: 10
Training loss: 0.14938762530636873
Validation loss: 2.4091600140892386

Epoch: 6| Step: 11
Training loss: 0.14131563191526372
Validation loss: 2.4183725129316174

Epoch: 6| Step: 12
Training loss: 0.13142959704835616
Validation loss: 2.419247453965752

Epoch: 6| Step: 13
Training loss: 0.09966456529867704
Validation loss: 2.416655493410934

Epoch: 485| Step: 0
Training loss: 0.11888337111957588
Validation loss: 2.4335311201858376

Epoch: 6| Step: 1
Training loss: 0.105670435884235
Validation loss: 2.4471457568511297

Epoch: 6| Step: 2
Training loss: 0.2665758784292087
Validation loss: 2.4495051722631938

Epoch: 6| Step: 3
Training loss: 0.14070552268942732
Validation loss: 2.493798713003724

Epoch: 6| Step: 4
Training loss: 0.134212492107481
Validation loss: 2.4713916438370402

Epoch: 6| Step: 5
Training loss: 0.08325336544595233
Validation loss: 2.5070809364364313

Epoch: 6| Step: 6
Training loss: 0.16591661530156523
Validation loss: 2.484146091107805

Epoch: 6| Step: 7
Training loss: 0.15807614116323154
Validation loss: 2.4678146191549137

Epoch: 6| Step: 8
Training loss: 0.2080935986345448
Validation loss: 2.4604689295723547

Epoch: 6| Step: 9
Training loss: 0.12679538463861292
Validation loss: 2.4509388462710047

Epoch: 6| Step: 10
Training loss: 0.1752218989651769
Validation loss: 2.4518282077756113

Epoch: 6| Step: 11
Training loss: 0.11642591643137604
Validation loss: 2.4973740168326684

Epoch: 6| Step: 12
Training loss: 0.10206806456305516
Validation loss: 2.446201842488896

Epoch: 6| Step: 13
Training loss: 0.19594668424640324
Validation loss: 2.4830844690309553

Epoch: 486| Step: 0
Training loss: 0.09342081669751749
Validation loss: 2.4746418040038676

Epoch: 6| Step: 1
Training loss: 0.18582606141726304
Validation loss: 2.493260678738645

Epoch: 6| Step: 2
Training loss: 0.1342417305622939
Validation loss: 2.496870868765741

Epoch: 6| Step: 3
Training loss: 0.11907219093912967
Validation loss: 2.473976897001107

Epoch: 6| Step: 4
Training loss: 0.1771579344536975
Validation loss: 2.4767864334767693

Epoch: 6| Step: 5
Training loss: 0.08671579624420862
Validation loss: 2.487789976211241

Epoch: 6| Step: 6
Training loss: 0.10141744709060718
Validation loss: 2.4269812045438854

Epoch: 6| Step: 7
Training loss: 0.09200232423627125
Validation loss: 2.4265293413489886

Epoch: 6| Step: 8
Training loss: 0.22484184342530994
Validation loss: 2.463163795950741

Epoch: 6| Step: 9
Training loss: 0.1718286213289651
Validation loss: 2.4682453772197825

Epoch: 6| Step: 10
Training loss: 0.08899226137804017
Validation loss: 2.4847231158161436

Epoch: 6| Step: 11
Training loss: 0.08150389014746011
Validation loss: 2.451712620881702

Epoch: 6| Step: 12
Training loss: 0.15731402742419553
Validation loss: 2.4501415090438052

Epoch: 6| Step: 13
Training loss: 0.11101664084305973
Validation loss: 2.450921103195295

Epoch: 487| Step: 0
Training loss: 0.09906973236289549
Validation loss: 2.479598914463792

Epoch: 6| Step: 1
Training loss: 0.08316423039847179
Validation loss: 2.4995210455406887

Epoch: 6| Step: 2
Training loss: 0.17761274514684433
Validation loss: 2.486838597660581

Epoch: 6| Step: 3
Training loss: 0.10773640016612264
Validation loss: 2.476369500189325

Epoch: 6| Step: 4
Training loss: 0.15072512273783456
Validation loss: 2.49624962013277

Epoch: 6| Step: 5
Training loss: 0.23184808861528902
Validation loss: 2.5086740572722532

Epoch: 6| Step: 6
Training loss: 0.07770076844749489
Validation loss: 2.508955526759477

Epoch: 6| Step: 7
Training loss: 0.24587301921289031
Validation loss: 2.489327112263274

Epoch: 6| Step: 8
Training loss: 0.15499855998354764
Validation loss: 2.482218591717808

Epoch: 6| Step: 9
Training loss: 0.13923574703509306
Validation loss: 2.5004729618277874

Epoch: 6| Step: 10
Training loss: 0.22790379413927628
Validation loss: 2.460078970309123

Epoch: 6| Step: 11
Training loss: 0.17066283197847748
Validation loss: 2.4612807126175404

Epoch: 6| Step: 12
Training loss: 0.10915583553011642
Validation loss: 2.456435241619348

Epoch: 6| Step: 13
Training loss: 0.1053699100912253
Validation loss: 2.438359811744615

Epoch: 488| Step: 0
Training loss: 0.18658166745379096
Validation loss: 2.465542609709271

Epoch: 6| Step: 1
Training loss: 0.0634396372280055
Validation loss: 2.4534113507638873

Epoch: 6| Step: 2
Training loss: 0.20138444132844846
Validation loss: 2.4451012969513823

Epoch: 6| Step: 3
Training loss: 0.1152542145671124
Validation loss: 2.394380194224359

Epoch: 6| Step: 4
Training loss: 0.14898287819889114
Validation loss: 2.421646144399925

Epoch: 6| Step: 5
Training loss: 0.13269510410080235
Validation loss: 2.4368212006881036

Epoch: 6| Step: 6
Training loss: 0.17039834011614308
Validation loss: 2.450775223947457

Epoch: 6| Step: 7
Training loss: 0.09463457183096882
Validation loss: 2.471201306760067

Epoch: 6| Step: 8
Training loss: 0.15046951776033335
Validation loss: 2.472665549007747

Epoch: 6| Step: 9
Training loss: 0.12731953343845165
Validation loss: 2.4802982198387147

Epoch: 6| Step: 10
Training loss: 0.20119469707624338
Validation loss: 2.488753689029117

Epoch: 6| Step: 11
Training loss: 0.13518193805652987
Validation loss: 2.4788139928634494

Epoch: 6| Step: 12
Training loss: 0.12126598875819186
Validation loss: 2.498746583374001

Epoch: 6| Step: 13
Training loss: 0.11111919138588083
Validation loss: 2.490925604707454

Epoch: 489| Step: 0
Training loss: 0.08356461585464672
Validation loss: 2.483132721286533

Epoch: 6| Step: 1
Training loss: 0.1382385454670911
Validation loss: 2.476284014676882

Epoch: 6| Step: 2
Training loss: 0.16567870902177567
Validation loss: 2.4775883400454863

Epoch: 6| Step: 3
Training loss: 0.18124370892886432
Validation loss: 2.461470114996401

Epoch: 6| Step: 4
Training loss: 0.1884241179400683
Validation loss: 2.4554826254729933

Epoch: 6| Step: 5
Training loss: 0.112910271621273
Validation loss: 2.4584351760628302

Epoch: 6| Step: 6
Training loss: 0.17157195207653048
Validation loss: 2.485913770187062

Epoch: 6| Step: 7
Training loss: 0.19410038575176347
Validation loss: 2.466395469117394

Epoch: 6| Step: 8
Training loss: 0.1208793179764965
Validation loss: 2.504213565211646

Epoch: 6| Step: 9
Training loss: 0.21489552827598626
Validation loss: 2.48120476685181

Epoch: 6| Step: 10
Training loss: 0.1973478410316412
Validation loss: 2.480813656560675

Epoch: 6| Step: 11
Training loss: 0.12184457888324941
Validation loss: 2.488942710602282

Epoch: 6| Step: 12
Training loss: 0.1384973166103385
Validation loss: 2.4655276466003935

Epoch: 6| Step: 13
Training loss: 0.1379421807753682
Validation loss: 2.507183675022912

Epoch: 490| Step: 0
Training loss: 0.23274736293267861
Validation loss: 2.4565253689469744

Epoch: 6| Step: 1
Training loss: 0.160733398391888
Validation loss: 2.4550114840907287

Epoch: 6| Step: 2
Training loss: 0.1920537021538598
Validation loss: 2.473559824912353

Epoch: 6| Step: 3
Training loss: 0.05196862204748701
Validation loss: 2.432022632847548

Epoch: 6| Step: 4
Training loss: 0.12690471312985582
Validation loss: 2.4344827347723954

Epoch: 6| Step: 5
Training loss: 0.1566912500284974
Validation loss: 2.4201491087477547

Epoch: 6| Step: 6
Training loss: 0.11323754108630124
Validation loss: 2.419635782576307

Epoch: 6| Step: 7
Training loss: 0.13978352715104067
Validation loss: 2.410783696763727

Epoch: 6| Step: 8
Training loss: 0.10331237831010477
Validation loss: 2.4247335077153704

Epoch: 6| Step: 9
Training loss: 0.1447214473175631
Validation loss: 2.457939994202656

Epoch: 6| Step: 10
Training loss: 0.12282269355460979
Validation loss: 2.430206303581386

Epoch: 6| Step: 11
Training loss: 0.1600833296499876
Validation loss: 2.441038310227871

Epoch: 6| Step: 12
Training loss: 0.13960704990451028
Validation loss: 2.446486180048595

Epoch: 6| Step: 13
Training loss: 0.21046796392167977
Validation loss: 2.4664863976465954

Epoch: 491| Step: 0
Training loss: 0.08579295095954095
Validation loss: 2.479482034210261

Epoch: 6| Step: 1
Training loss: 0.24630452772285297
Validation loss: 2.4709113200670476

Epoch: 6| Step: 2
Training loss: 0.141744206370259
Validation loss: 2.4569283592059477

Epoch: 6| Step: 3
Training loss: 0.07817965026561818
Validation loss: 2.499855277271736

Epoch: 6| Step: 4
Training loss: 0.0844337423359898
Validation loss: 2.427228924741944

Epoch: 6| Step: 5
Training loss: 0.1917651859217189
Validation loss: 2.425472542726402

Epoch: 6| Step: 6
Training loss: 0.13255081622699091
Validation loss: 2.425988153875135

Epoch: 6| Step: 7
Training loss: 0.21891100952507095
Validation loss: 2.409393390321294

Epoch: 6| Step: 8
Training loss: 0.1244211727847325
Validation loss: 2.42224690270862

Epoch: 6| Step: 9
Training loss: 0.11850563445382294
Validation loss: 2.405860895521212

Epoch: 6| Step: 10
Training loss: 0.10581669545319831
Validation loss: 2.4143678518703093

Epoch: 6| Step: 11
Training loss: 0.14586069852231565
Validation loss: 2.4375178565461666

Epoch: 6| Step: 12
Training loss: 0.175238034877237
Validation loss: 2.4114786538483157

Epoch: 6| Step: 13
Training loss: 0.0732672203518326
Validation loss: 2.4565599881911435

Epoch: 492| Step: 0
Training loss: 0.13114870880157065
Validation loss: 2.4341569540244405

Epoch: 6| Step: 1
Training loss: 0.21254240657711507
Validation loss: 2.476777032977751

Epoch: 6| Step: 2
Training loss: 0.11354761623913855
Validation loss: 2.464278213635036

Epoch: 6| Step: 3
Training loss: 0.10572036998622787
Validation loss: 2.4771014579104973

Epoch: 6| Step: 4
Training loss: 0.10030513752749382
Validation loss: 2.490638243908581

Epoch: 6| Step: 5
Training loss: 0.14804553053957534
Validation loss: 2.4687655557329538

Epoch: 6| Step: 6
Training loss: 0.145661637584484
Validation loss: 2.460939781394952

Epoch: 6| Step: 7
Training loss: 0.2112793360181807
Validation loss: 2.485884057662649

Epoch: 6| Step: 8
Training loss: 0.19954134496604628
Validation loss: 2.4787797082115834

Epoch: 6| Step: 9
Training loss: 0.08796908796933232
Validation loss: 2.4500124970988586

Epoch: 6| Step: 10
Training loss: 0.11306656027431017
Validation loss: 2.4591569117112493

Epoch: 6| Step: 11
Training loss: 0.15482421285976466
Validation loss: 2.465342673842202

Epoch: 6| Step: 12
Training loss: 0.1266109991749743
Validation loss: 2.449785784501187

Epoch: 6| Step: 13
Training loss: 0.09465775989809268
Validation loss: 2.458718459147256

Epoch: 493| Step: 0
Training loss: 0.10538801882825048
Validation loss: 2.4441675979175423

Epoch: 6| Step: 1
Training loss: 0.11208563463544113
Validation loss: 2.453341198975918

Epoch: 6| Step: 2
Training loss: 0.12528692039109052
Validation loss: 2.4702677902112313

Epoch: 6| Step: 3
Training loss: 0.1049280789970381
Validation loss: 2.455783926420548

Epoch: 6| Step: 4
Training loss: 0.12427312767362855
Validation loss: 2.4559715298507325

Epoch: 6| Step: 5
Training loss: 0.1179421682282952
Validation loss: 2.464072261502279

Epoch: 6| Step: 6
Training loss: 0.18744820634424358
Validation loss: 2.4688696520091398

Epoch: 6| Step: 7
Training loss: 0.17511737816668546
Validation loss: 2.445112428641797

Epoch: 6| Step: 8
Training loss: 0.13794885788986058
Validation loss: 2.489410647376063

Epoch: 6| Step: 9
Training loss: 0.14341299369169777
Validation loss: 2.505736357384951

Epoch: 6| Step: 10
Training loss: 0.23020830632694367
Validation loss: 2.4469122682172695

Epoch: 6| Step: 11
Training loss: 0.11156507422979423
Validation loss: 2.478818057347298

Epoch: 6| Step: 12
Training loss: 0.1301642788429081
Validation loss: 2.490659589148099

Epoch: 6| Step: 13
Training loss: 0.24295982148180242
Validation loss: 2.4923948055864833

Epoch: 494| Step: 0
Training loss: 0.21484882175354628
Validation loss: 2.490189026611292

Epoch: 6| Step: 1
Training loss: 0.10071362566450837
Validation loss: 2.481613975620666

Epoch: 6| Step: 2
Training loss: 0.16406070617421725
Validation loss: 2.4851369908807865

Epoch: 6| Step: 3
Training loss: 0.11885530671295355
Validation loss: 2.4800390890564175

Epoch: 6| Step: 4
Training loss: 0.0974699150032948
Validation loss: 2.482776007831361

Epoch: 6| Step: 5
Training loss: 0.19131189083512087
Validation loss: 2.5055370110511412

Epoch: 6| Step: 6
Training loss: 0.10926460757791731
Validation loss: 2.495312692182181

Epoch: 6| Step: 7
Training loss: 0.17692953798846386
Validation loss: 2.5119677004517444

Epoch: 6| Step: 8
Training loss: 0.2076739645377746
Validation loss: 2.517791962226933

Epoch: 6| Step: 9
Training loss: 0.14968982505585393
Validation loss: 2.5188570329259754

Epoch: 6| Step: 10
Training loss: 0.11937609838060291
Validation loss: 2.495602751640562

Epoch: 6| Step: 11
Training loss: 0.16951285934899613
Validation loss: 2.4875312218654777

Epoch: 6| Step: 12
Training loss: 0.2381532825735095
Validation loss: 2.4756985582704494

Epoch: 6| Step: 13
Training loss: 0.13572384003614146
Validation loss: 2.483430945807019

Epoch: 495| Step: 0
Training loss: 0.1355434169932827
Validation loss: 2.5078614403006996

Epoch: 6| Step: 1
Training loss: 0.13985469231870665
Validation loss: 2.495463356875705

Epoch: 6| Step: 2
Training loss: 0.2356202424072464
Validation loss: 2.5451650157946273

Epoch: 6| Step: 3
Training loss: 0.0678513347213427
Validation loss: 2.51391702966828

Epoch: 6| Step: 4
Training loss: 0.20603362423237437
Validation loss: 2.5289599411309083

Epoch: 6| Step: 5
Training loss: 0.10429233083933873
Validation loss: 2.5202609329049888

Epoch: 6| Step: 6
Training loss: 0.1937954061123881
Validation loss: 2.4900114964977824

Epoch: 6| Step: 7
Training loss: 0.1306495835246526
Validation loss: 2.4631080463488533

Epoch: 6| Step: 8
Training loss: 0.07628071784748455
Validation loss: 2.4950267341811188

Epoch: 6| Step: 9
Training loss: 0.10975803844529929
Validation loss: 2.4436952527583653

Epoch: 6| Step: 10
Training loss: 0.21158915103922418
Validation loss: 2.4476751305661986

Epoch: 6| Step: 11
Training loss: 0.091352931390905
Validation loss: 2.429850151569521

Epoch: 6| Step: 12
Training loss: 0.12465812079445211
Validation loss: 2.4336650014103567

Epoch: 6| Step: 13
Training loss: 0.1355432658305887
Validation loss: 2.393231303006873

Epoch: 496| Step: 0
Training loss: 0.10641703973868795
Validation loss: 2.395114973606574

Epoch: 6| Step: 1
Training loss: 0.13819319081762874
Validation loss: 2.411932897735891

Epoch: 6| Step: 2
Training loss: 0.10050432820364806
Validation loss: 2.422582850384162

Epoch: 6| Step: 3
Training loss: 0.11606205290614277
Validation loss: 2.395579426184118

Epoch: 6| Step: 4
Training loss: 0.21426112329781719
Validation loss: 2.388751782983466

Epoch: 6| Step: 5
Training loss: 0.20969848197570382
Validation loss: 2.459314713211713

Epoch: 6| Step: 6
Training loss: 0.0628838967935864
Validation loss: 2.4378352853591254

Epoch: 6| Step: 7
Training loss: 0.13815847916736418
Validation loss: 2.422815580183888

Epoch: 6| Step: 8
Training loss: 0.11430156310291124
Validation loss: 2.459561345928696

Epoch: 6| Step: 9
Training loss: 0.11151774887969024
Validation loss: 2.4671300492998056

Epoch: 6| Step: 10
Training loss: 0.1867438008251049
Validation loss: 2.4672166676636915

Epoch: 6| Step: 11
Training loss: 0.11514673699043988
Validation loss: 2.43025792383204

Epoch: 6| Step: 12
Training loss: 0.14956816661029607
Validation loss: 2.4195754551537854

Epoch: 6| Step: 13
Training loss: 0.15032278115964692
Validation loss: 2.4500854401112764

Epoch: 497| Step: 0
Training loss: 0.08887179331319495
Validation loss: 2.429161354034085

Epoch: 6| Step: 1
Training loss: 0.19542614491568847
Validation loss: 2.474413942482844

Epoch: 6| Step: 2
Training loss: 0.11607437765388838
Validation loss: 2.4118489522462543

Epoch: 6| Step: 3
Training loss: 0.17274927356259462
Validation loss: 2.422297106639116

Epoch: 6| Step: 4
Training loss: 0.13442831395677313
Validation loss: 2.4328898208441654

Epoch: 6| Step: 5
Training loss: 0.09125954029428943
Validation loss: 2.4494612980713977

Epoch: 6| Step: 6
Training loss: 0.07327984159860867
Validation loss: 2.4588969557683478

Epoch: 6| Step: 7
Training loss: 0.1546471458837844
Validation loss: 2.429506051698906

Epoch: 6| Step: 8
Training loss: 0.08402857061159635
Validation loss: 2.443711562806808

Epoch: 6| Step: 9
Training loss: 0.10142801165171432
Validation loss: 2.4664732061965378

Epoch: 6| Step: 10
Training loss: 0.1823585024425402
Validation loss: 2.4526354320358177

Epoch: 6| Step: 11
Training loss: 0.14412602761639237
Validation loss: 2.4594065216613274

Epoch: 6| Step: 12
Training loss: 0.1160707630116119
Validation loss: 2.444130706401183

Epoch: 6| Step: 13
Training loss: 0.23486648525661805
Validation loss: 2.427450192905991

Epoch: 498| Step: 0
Training loss: 0.21804822170288632
Validation loss: 2.4174973082613067

Epoch: 6| Step: 1
Training loss: 0.19818095497095672
Validation loss: 2.4530297438457023

Epoch: 6| Step: 2
Training loss: 0.15330406880434913
Validation loss: 2.4259986768770885

Epoch: 6| Step: 3
Training loss: 0.26091710484913727
Validation loss: 2.4710331519468878

Epoch: 6| Step: 4
Training loss: 0.20940790309290516
Validation loss: 2.463195181867745

Epoch: 6| Step: 5
Training loss: 0.13951194201348352
Validation loss: 2.4890585039077093

Epoch: 6| Step: 6
Training loss: 0.3121570851475879
Validation loss: 2.4879165330352357

Epoch: 6| Step: 7
Training loss: 0.1346237015807674
Validation loss: 2.482964128807929

Epoch: 6| Step: 8
Training loss: 0.10249501144958366
Validation loss: 2.490973682431858

Epoch: 6| Step: 9
Training loss: 0.22293002881053559
Validation loss: 2.472168571766003

Epoch: 6| Step: 10
Training loss: 0.16366691240421222
Validation loss: 2.449191233730333

Epoch: 6| Step: 11
Training loss: 0.12846447642777806
Validation loss: 2.4313645998015607

Epoch: 6| Step: 12
Training loss: 0.13140615415626325
Validation loss: 2.434510599988884

Epoch: 6| Step: 13
Training loss: 0.23391851635089378
Validation loss: 2.4230598121175984

Epoch: 499| Step: 0
Training loss: 0.21746927240240163
Validation loss: 2.435576592688965

Epoch: 6| Step: 1
Training loss: 0.27127132701094003
Validation loss: 2.4577308745276016

Epoch: 6| Step: 2
Training loss: 0.21453292209782115
Validation loss: 2.4364993068782406

Epoch: 6| Step: 3
Training loss: 0.17038423838445785
Validation loss: 2.4992115695109876

Epoch: 6| Step: 4
Training loss: 0.1199079955950492
Validation loss: 2.4618286165364647

Epoch: 6| Step: 5
Training loss: 0.2222038826891636
Validation loss: 2.4702947956606947

Epoch: 6| Step: 6
Training loss: 0.19993505541042433
Validation loss: 2.477923002634209

Epoch: 6| Step: 7
Training loss: 0.21047698189624353
Validation loss: 2.451897370347788

Epoch: 6| Step: 8
Training loss: 0.09581756561422664
Validation loss: 2.4315703865084464

Epoch: 6| Step: 9
Training loss: 0.21856151703091795
Validation loss: 2.443449391842818

Epoch: 6| Step: 10
Training loss: 0.20122164508735177
Validation loss: 2.432542204126781

Epoch: 6| Step: 11
Training loss: 0.1992928797113166
Validation loss: 2.444052524586231

Epoch: 6| Step: 12
Training loss: 0.18315752433876353
Validation loss: 2.4304982303904628

Epoch: 6| Step: 13
Training loss: 0.1258091294447818
Validation loss: 2.4463376407255084

Epoch: 500| Step: 0
Training loss: 0.24218831523634998
Validation loss: 2.437348897229759

Epoch: 6| Step: 1
Training loss: 0.19472619748248723
Validation loss: 2.440138373633836

Epoch: 6| Step: 2
Training loss: 0.14857715386652898
Validation loss: 2.434612082113396

Epoch: 6| Step: 3
Training loss: 0.13917789680770085
Validation loss: 2.426018937595746

Epoch: 6| Step: 4
Training loss: 0.24571356849733064
Validation loss: 2.4314119737131574

Epoch: 6| Step: 5
Training loss: 0.189924401157013
Validation loss: 2.395726557238655

Epoch: 6| Step: 6
Training loss: 0.13515647932264685
Validation loss: 2.469018660112403

Epoch: 6| Step: 7
Training loss: 0.18673402572138253
Validation loss: 2.4620278896943533

Epoch: 6| Step: 8
Training loss: 0.20865490156329022
Validation loss: 2.4512398251201764

Epoch: 6| Step: 9
Training loss: 0.1780001989481382
Validation loss: 2.434735564008374

Epoch: 6| Step: 10
Training loss: 0.13586811701116816
Validation loss: 2.4423383185933956

Epoch: 6| Step: 11
Training loss: 0.16339266366262245
Validation loss: 2.4717447267116315

Epoch: 6| Step: 12
Training loss: 0.11120612587282686
Validation loss: 2.4792463007692813

Epoch: 6| Step: 13
Training loss: 0.14088772365234847
Validation loss: 2.525520920218597

Epoch: 501| Step: 0
Training loss: 0.14595872024300088
Validation loss: 2.5035741042865034

Epoch: 6| Step: 1
Training loss: 0.16205671902992197
Validation loss: 2.518630990277627

Epoch: 6| Step: 2
Training loss: 0.2244179033925155
Validation loss: 2.4747075464628656

Epoch: 6| Step: 3
Training loss: 0.11268302381080907
Validation loss: 2.4497011974782237

Epoch: 6| Step: 4
Training loss: 0.12588314910438358
Validation loss: 2.4610407310042643

Epoch: 6| Step: 5
Training loss: 0.29476805964237146
Validation loss: 2.453447355095315

Epoch: 6| Step: 6
Training loss: 0.2891206940504704
Validation loss: 2.431234776002424

Epoch: 6| Step: 7
Training loss: 0.2731276800517354
Validation loss: 2.4254024950302426

Epoch: 6| Step: 8
Training loss: 0.2176333605580725
Validation loss: 2.423484560080338

Epoch: 6| Step: 9
Training loss: 0.13396879639434545
Validation loss: 2.435434128055622

Epoch: 6| Step: 10
Training loss: 0.15849590289750187
Validation loss: 2.447923469054005

Epoch: 6| Step: 11
Training loss: 0.23134111722864867
Validation loss: 2.4070288946752734

Epoch: 6| Step: 12
Training loss: 0.1946714562407669
Validation loss: 2.426730225366362

Epoch: 6| Step: 13
Training loss: 0.138900749292869
Validation loss: 2.4575048776259236

Epoch: 502| Step: 0
Training loss: 0.16100588336406915
Validation loss: 2.4437581529038868

Epoch: 6| Step: 1
Training loss: 0.16471747945267645
Validation loss: 2.4690647705998336

Epoch: 6| Step: 2
Training loss: 0.2538797071228078
Validation loss: 2.495586476144461

Epoch: 6| Step: 3
Training loss: 0.26001925025798106
Validation loss: 2.499621035453016

Epoch: 6| Step: 4
Training loss: 0.18567374058336517
Validation loss: 2.4288805995497325

Epoch: 6| Step: 5
Training loss: 0.23722200562352821
Validation loss: 2.4336502294340505

Epoch: 6| Step: 6
Training loss: 0.2503933643066248
Validation loss: 2.4072159718141135

Epoch: 6| Step: 7
Training loss: 0.11647001206712414
Validation loss: 2.4395231617536597

Epoch: 6| Step: 8
Training loss: 0.24578347400937092
Validation loss: 2.4407727074066856

Epoch: 6| Step: 9
Training loss: 0.1665525393343689
Validation loss: 2.376502972836322

Epoch: 6| Step: 10
Training loss: 0.22594751552157927
Validation loss: 2.3599332521024152

Epoch: 6| Step: 11
Training loss: 0.135405899194421
Validation loss: 2.3727088135449494

Epoch: 6| Step: 12
Training loss: 0.15969699047575553
Validation loss: 2.37419500239027

Epoch: 6| Step: 13
Training loss: 0.22022679501602124
Validation loss: 2.4047816846293717

Epoch: 503| Step: 0
Training loss: 0.2536631373952791
Validation loss: 2.368081858131849

Epoch: 6| Step: 1
Training loss: 0.2339993168003754
Validation loss: 2.3653672229797698

Epoch: 6| Step: 2
Training loss: 0.19565658777436568
Validation loss: 2.3224286280823354

Epoch: 6| Step: 3
Training loss: 0.1752091209898158
Validation loss: 2.3339733251034716

Epoch: 6| Step: 4
Training loss: 0.22068272555439006
Validation loss: 2.4152010744101924

Epoch: 6| Step: 5
Training loss: 0.18015304670108007
Validation loss: 2.4412060065729926

Epoch: 6| Step: 6
Training loss: 0.20727467171731925
Validation loss: 2.469284743223886

Epoch: 6| Step: 7
Training loss: 0.20736891722423909
Validation loss: 2.5090841818780976

Epoch: 6| Step: 8
Training loss: 0.24964849526660282
Validation loss: 2.4905547978348723

Epoch: 6| Step: 9
Training loss: 0.25832153410011977
Validation loss: 2.5140848654672454

Epoch: 6| Step: 10
Training loss: 0.24726225442381916
Validation loss: 2.4704582137392856

Epoch: 6| Step: 11
Training loss: 0.152513244681068
Validation loss: 2.4519615928564598

Epoch: 6| Step: 12
Training loss: 0.1921567702342963
Validation loss: 2.4388268800425346

Epoch: 6| Step: 13
Training loss: 0.2616114182799411
Validation loss: 2.443157699843319

Epoch: 504| Step: 0
Training loss: 0.16815616442910886
Validation loss: 2.4101146647143064

Epoch: 6| Step: 1
Training loss: 0.21552746093912745
Validation loss: 2.392976296639058

Epoch: 6| Step: 2
Training loss: 0.2773505465252314
Validation loss: 2.418919576284209

Epoch: 6| Step: 3
Training loss: 0.20410298616195688
Validation loss: 2.448996271560556

Epoch: 6| Step: 4
Training loss: 0.275843390145072
Validation loss: 2.4180548223834766

Epoch: 6| Step: 5
Training loss: 0.323116289497304
Validation loss: 2.510407932657591

Epoch: 6| Step: 6
Training loss: 0.15298178529578324
Validation loss: 2.519564963850743

Epoch: 6| Step: 7
Training loss: 0.24595740492222937
Validation loss: 2.492226283675303

Epoch: 6| Step: 8
Training loss: 0.1631112278956291
Validation loss: 2.4678160080706526

Epoch: 6| Step: 9
Training loss: 0.250053593732238
Validation loss: 2.464887668908762

Epoch: 6| Step: 10
Training loss: 0.20721109244427804
Validation loss: 2.4290187118231645

Epoch: 6| Step: 11
Training loss: 0.17188904444794265
Validation loss: 2.3976137484183764

Epoch: 6| Step: 12
Training loss: 0.24038710817548395
Validation loss: 2.387176462801127

Epoch: 6| Step: 13
Training loss: 0.31451659420943745
Validation loss: 2.3338939708106734

Epoch: 505| Step: 0
Training loss: 0.28941807914394335
Validation loss: 2.309259637658251

Epoch: 6| Step: 1
Training loss: 0.13972633696663997
Validation loss: 2.330500365811234

Epoch: 6| Step: 2
Training loss: 0.2928155752934494
Validation loss: 2.3380489565265172

Epoch: 6| Step: 3
Training loss: 0.42048826832230635
Validation loss: 2.3708013706448585

Epoch: 6| Step: 4
Training loss: 0.24508937358730545
Validation loss: 2.420560817775093

Epoch: 6| Step: 5
Training loss: 0.18418870056364275
Validation loss: 2.4962006318996823

Epoch: 6| Step: 6
Training loss: 0.32480327355862143
Validation loss: 2.537297951654685

Epoch: 6| Step: 7
Training loss: 0.36390847234510076
Validation loss: 2.575959472438335

Epoch: 6| Step: 8
Training loss: 0.34664838407789933
Validation loss: 2.5832693652417973

Epoch: 6| Step: 9
Training loss: 0.3174489113862765
Validation loss: 2.490473433972906

Epoch: 6| Step: 10
Training loss: 0.22272271285339104
Validation loss: 2.40442194042382

Epoch: 6| Step: 11
Training loss: 0.2732186940627361
Validation loss: 2.3695452039429674

Epoch: 6| Step: 12
Training loss: 0.418521373168824
Validation loss: 2.3492717651586674

Epoch: 6| Step: 13
Training loss: 0.24278508570402166
Validation loss: 2.370456068461363

Epoch: 506| Step: 0
Training loss: 0.23214280981938434
Validation loss: 2.389619014410049

Epoch: 6| Step: 1
Training loss: 0.2953702284887215
Validation loss: 2.4412845242251895

Epoch: 6| Step: 2
Training loss: 0.2683696178497139
Validation loss: 2.525444530716908

Epoch: 6| Step: 3
Training loss: 0.3597709506258854
Validation loss: 2.578722114313

Epoch: 6| Step: 4
Training loss: 0.43294597041304156
Validation loss: 2.6213722455777897

Epoch: 6| Step: 5
Training loss: 0.6849794348880547
Validation loss: 2.623501406525099

Epoch: 6| Step: 6
Training loss: 0.35000858211213465
Validation loss: 2.525005721267786

Epoch: 6| Step: 7
Training loss: 0.22945133413746585
Validation loss: 2.4825208207946483

Epoch: 6| Step: 8
Training loss: 0.17374537673637924
Validation loss: 2.3893986762407113

Epoch: 6| Step: 9
Training loss: 0.4327142059865568
Validation loss: 2.3861042763211833

Epoch: 6| Step: 10
Training loss: 0.5944831237162181
Validation loss: 2.3348860344691196

Epoch: 6| Step: 11
Training loss: 0.25725868737035135
Validation loss: 2.364600490825667

Epoch: 6| Step: 12
Training loss: 0.20608535646839476
Validation loss: 2.419048516388866

Epoch: 6| Step: 13
Training loss: 0.2962517470296218
Validation loss: 2.5107952924739543

Epoch: 507| Step: 0
Training loss: 0.38740697944008096
Validation loss: 2.6402553438685987

Epoch: 6| Step: 1
Training loss: 0.6299292258971915
Validation loss: 2.6619293628959646

Epoch: 6| Step: 2
Training loss: 0.22981816130567367
Validation loss: 2.5880377332528903

Epoch: 6| Step: 3
Training loss: 0.1646572753235768
Validation loss: 2.5126361888988984

Epoch: 6| Step: 4
Training loss: 0.2475763122718537
Validation loss: 2.430879037272796

Epoch: 6| Step: 5
Training loss: 0.3500623592103315
Validation loss: 2.397674772759808

Epoch: 6| Step: 6
Training loss: 0.4736183085629603
Validation loss: 2.3751982340094955

Epoch: 6| Step: 7
Training loss: 0.45618987275120754
Validation loss: 2.411241467977931

Epoch: 6| Step: 8
Training loss: 0.38073941811442524
Validation loss: 2.4325554952694763

Epoch: 6| Step: 9
Training loss: 0.2152363917261479
Validation loss: 2.3944944995070783

Epoch: 6| Step: 10
Training loss: 0.20528274500513422
Validation loss: 2.4832569778980664

Epoch: 6| Step: 11
Training loss: 0.38961891311037267
Validation loss: 2.497398037624895

Epoch: 6| Step: 12
Training loss: 0.3956596553985255
Validation loss: 2.5161222479683825

Epoch: 6| Step: 13
Training loss: 0.3296777791583383
Validation loss: 2.5427847960900527

Epoch: 508| Step: 0
Training loss: 0.333705629621122
Validation loss: 2.560296975245052

Epoch: 6| Step: 1
Training loss: 0.2865388612554851
Validation loss: 2.5648716441975212

Epoch: 6| Step: 2
Training loss: 0.17161577356492078
Validation loss: 2.5116078086846394

Epoch: 6| Step: 3
Training loss: 0.2120682467495106
Validation loss: 2.4821152174333903

Epoch: 6| Step: 4
Training loss: 0.23720958358126487
Validation loss: 2.4405192315041178

Epoch: 6| Step: 5
Training loss: 0.27788645072249185
Validation loss: 2.456726715811724

Epoch: 6| Step: 6
Training loss: 0.2742141321124898
Validation loss: 2.474013928931284

Epoch: 6| Step: 7
Training loss: 0.34301009526354936
Validation loss: 2.498013650701973

Epoch: 6| Step: 8
Training loss: 0.34500417796659705
Validation loss: 2.488763732902758

Epoch: 6| Step: 9
Training loss: 0.2809006587685872
Validation loss: 2.4619551464010305

Epoch: 6| Step: 10
Training loss: 0.4121027941426945
Validation loss: 2.516120175554292

Epoch: 6| Step: 11
Training loss: 0.23728149991503972
Validation loss: 2.5111612471739293

Epoch: 6| Step: 12
Training loss: 0.21316155858427843
Validation loss: 2.4621436701676203

Epoch: 6| Step: 13
Training loss: 0.1941246244871508
Validation loss: 2.497921434385412

Epoch: 509| Step: 0
Training loss: 0.17065091873339933
Validation loss: 2.469835197846473

Epoch: 6| Step: 1
Training loss: 0.2362067013123013
Validation loss: 2.471521292793523

Epoch: 6| Step: 2
Training loss: 0.31186433752864795
Validation loss: 2.4493272911744737

Epoch: 6| Step: 3
Training loss: 0.23119653135192444
Validation loss: 2.4391283864967384

Epoch: 6| Step: 4
Training loss: 0.3057903967158433
Validation loss: 2.45695687398314

Epoch: 6| Step: 5
Training loss: 0.3057845490618293
Validation loss: 2.4186429896669455

Epoch: 6| Step: 6
Training loss: 0.2714837712342938
Validation loss: 2.4111172719656553

Epoch: 6| Step: 7
Training loss: 0.16262826831862842
Validation loss: 2.370272685475491

Epoch: 6| Step: 8
Training loss: 0.2953085227981058
Validation loss: 2.425788352950229

Epoch: 6| Step: 9
Training loss: 0.2702723555991876
Validation loss: 2.385954125748267

Epoch: 6| Step: 10
Training loss: 0.2610061538060344
Validation loss: 2.42120062217843

Epoch: 6| Step: 11
Training loss: 0.27296496842313706
Validation loss: 2.417799093095435

Epoch: 6| Step: 12
Training loss: 0.15703541527153583
Validation loss: 2.4815945944234894

Epoch: 6| Step: 13
Training loss: 0.20432721673072668
Validation loss: 2.488249782814616

Epoch: 510| Step: 0
Training loss: 0.1931962182229188
Validation loss: 2.4234404470074162

Epoch: 6| Step: 1
Training loss: 0.29522017998751326
Validation loss: 2.4479873653999076

Epoch: 6| Step: 2
Training loss: 0.15778319823297002
Validation loss: 2.403728358680617

Epoch: 6| Step: 3
Training loss: 0.16897136288939
Validation loss: 2.4281481553411353

Epoch: 6| Step: 4
Training loss: 0.31441304443058055
Validation loss: 2.387741293834444

Epoch: 6| Step: 5
Training loss: 0.2156836823761459
Validation loss: 2.417589014438761

Epoch: 6| Step: 6
Training loss: 0.17036628704993745
Validation loss: 2.384369424995054

Epoch: 6| Step: 7
Training loss: 0.26417778365292294
Validation loss: 2.449797736267934

Epoch: 6| Step: 8
Training loss: 0.303789588581467
Validation loss: 2.482115137904313

Epoch: 6| Step: 9
Training loss: 0.453440441303454
Validation loss: 2.477333420116193

Epoch: 6| Step: 10
Training loss: 0.12864608230515248
Validation loss: 2.4983622057141317

Epoch: 6| Step: 11
Training loss: 0.20481541473274975
Validation loss: 2.5077937240493178

Epoch: 6| Step: 12
Training loss: 0.3166388492642675
Validation loss: 2.4820632213988145

Epoch: 6| Step: 13
Training loss: 0.38274063681443904
Validation loss: 2.487433033981335

Epoch: 511| Step: 0
Training loss: 0.32433933865026054
Validation loss: 2.463013348026475

Epoch: 6| Step: 1
Training loss: 0.20522978488187607
Validation loss: 2.48153482901123

Epoch: 6| Step: 2
Training loss: 0.27619160172989876
Validation loss: 2.4834503023501515

Epoch: 6| Step: 3
Training loss: 0.2870870828083791
Validation loss: 2.4721693552199375

Epoch: 6| Step: 4
Training loss: 0.321733277795527
Validation loss: 2.459595404938184

Epoch: 6| Step: 5
Training loss: 0.2865575170759733
Validation loss: 2.489837840111302

Epoch: 6| Step: 6
Training loss: 0.2702791369802475
Validation loss: 2.4267155854864453

Epoch: 6| Step: 7
Training loss: 0.22410750503733315
Validation loss: 2.3638535660424247

Epoch: 6| Step: 8
Training loss: 0.23908048013626954
Validation loss: 2.406755444110116

Epoch: 6| Step: 9
Training loss: 0.2808550206935818
Validation loss: 2.372512769295288

Epoch: 6| Step: 10
Training loss: 0.3168356771730245
Validation loss: 2.326144237283007

Epoch: 6| Step: 11
Training loss: 0.2360435695829618
Validation loss: 2.3531826353720673

Epoch: 6| Step: 12
Training loss: 0.24736153548897574
Validation loss: 2.3489758101351743

Epoch: 6| Step: 13
Training loss: 0.22869983812302655
Validation loss: 2.3736108517976717

Epoch: 512| Step: 0
Training loss: 0.18888079328949126
Validation loss: 2.4397505731863967

Epoch: 6| Step: 1
Training loss: 0.2094028596704647
Validation loss: 2.446891081448114

Epoch: 6| Step: 2
Training loss: 0.1837223900922481
Validation loss: 2.4672959426381063

Epoch: 6| Step: 3
Training loss: 0.23676455215153636
Validation loss: 2.5473238470667767

Epoch: 6| Step: 4
Training loss: 0.34404168974665467
Validation loss: 2.5681112946234466

Epoch: 6| Step: 5
Training loss: 0.2628554100948918
Validation loss: 2.5356219803852706

Epoch: 6| Step: 6
Training loss: 0.26708143315157545
Validation loss: 2.4997611126539763

Epoch: 6| Step: 7
Training loss: 0.1587357561787527
Validation loss: 2.4901178076057304

Epoch: 6| Step: 8
Training loss: 0.1983445377818033
Validation loss: 2.4633473202549476

Epoch: 6| Step: 9
Training loss: 0.21025236441919087
Validation loss: 2.446158774195215

Epoch: 6| Step: 10
Training loss: 0.15573943286619132
Validation loss: 2.4139588726668704

Epoch: 6| Step: 11
Training loss: 0.21521739546580954
Validation loss: 2.399630841154514

Epoch: 6| Step: 12
Training loss: 0.3290167679484899
Validation loss: 2.4165003787939456

Epoch: 6| Step: 13
Training loss: 0.34338282352098853
Validation loss: 2.4036930878483926

Epoch: 513| Step: 0
Training loss: 0.32524074202753267
Validation loss: 2.4287126770558234

Epoch: 6| Step: 1
Training loss: 0.3179516902536719
Validation loss: 2.4353615104537494

Epoch: 6| Step: 2
Training loss: 0.1695836087426926
Validation loss: 2.4457598279717105

Epoch: 6| Step: 3
Training loss: 0.23429712750254958
Validation loss: 2.4762613099062674

Epoch: 6| Step: 4
Training loss: 0.25828755566606953
Validation loss: 2.4559973986723693

Epoch: 6| Step: 5
Training loss: 0.2253210651288184
Validation loss: 2.464970078292855

Epoch: 6| Step: 6
Training loss: 0.1781711869842485
Validation loss: 2.4886045944668025

Epoch: 6| Step: 7
Training loss: 0.2931882671654365
Validation loss: 2.468622078416936

Epoch: 6| Step: 8
Training loss: 0.2943700971822795
Validation loss: 2.456819563233879

Epoch: 6| Step: 9
Training loss: 0.3121246229130518
Validation loss: 2.4713920167559746

Epoch: 6| Step: 10
Training loss: 0.28429021357368517
Validation loss: 2.4147774157813924

Epoch: 6| Step: 11
Training loss: 0.26450107314463583
Validation loss: 2.392016174474632

Epoch: 6| Step: 12
Training loss: 0.22635147527319688
Validation loss: 2.3867067326294413

Epoch: 6| Step: 13
Training loss: 0.1556042679608318
Validation loss: 2.389036406927954

Epoch: 514| Step: 0
Training loss: 0.16536439059589197
Validation loss: 2.343517289179324

Epoch: 6| Step: 1
Training loss: 0.16144864889039112
Validation loss: 2.4127189555147375

Epoch: 6| Step: 2
Training loss: 0.22908591162515532
Validation loss: 2.4172281297970404

Epoch: 6| Step: 3
Training loss: 0.14942237731137523
Validation loss: 2.4254909719056714

Epoch: 6| Step: 4
Training loss: 0.293325410545346
Validation loss: 2.4566777711595806

Epoch: 6| Step: 5
Training loss: 0.2674204507979845
Validation loss: 2.44688932967064

Epoch: 6| Step: 6
Training loss: 0.20045035329120567
Validation loss: 2.423228363846755

Epoch: 6| Step: 7
Training loss: 0.20280339383693927
Validation loss: 2.4355974829031077

Epoch: 6| Step: 8
Training loss: 0.21054048616981885
Validation loss: 2.402149387930588

Epoch: 6| Step: 9
Training loss: 0.13206596792725403
Validation loss: 2.394747927902251

Epoch: 6| Step: 10
Training loss: 0.17196871630061583
Validation loss: 2.432594293313638

Epoch: 6| Step: 11
Training loss: 0.197792934757869
Validation loss: 2.4753027614658976

Epoch: 6| Step: 12
Training loss: 0.13989433567081486
Validation loss: 2.405564980284488

Epoch: 6| Step: 13
Training loss: 0.25968058348533
Validation loss: 2.4105440884321054

Epoch: 515| Step: 0
Training loss: 0.17896945161850117
Validation loss: 2.424425853457966

Epoch: 6| Step: 1
Training loss: 0.22119019362767772
Validation loss: 2.4136181058704933

Epoch: 6| Step: 2
Training loss: 0.2667131015959419
Validation loss: 2.4086298292282917

Epoch: 6| Step: 3
Training loss: 0.23651986973888597
Validation loss: 2.4389397812815052

Epoch: 6| Step: 4
Training loss: 0.20439922948869818
Validation loss: 2.425370557158572

Epoch: 6| Step: 5
Training loss: 0.1430420513058547
Validation loss: 2.4137320694071254

Epoch: 6| Step: 6
Training loss: 0.23708344966676625
Validation loss: 2.4221265140256514

Epoch: 6| Step: 7
Training loss: 0.15591974523335783
Validation loss: 2.416515312363258

Epoch: 6| Step: 8
Training loss: 0.1430747514705909
Validation loss: 2.409481218178813

Epoch: 6| Step: 9
Training loss: 0.16673329010171584
Validation loss: 2.4415823031700907

Epoch: 6| Step: 10
Training loss: 0.2562558254882351
Validation loss: 2.4311430994924703

Epoch: 6| Step: 11
Training loss: 0.20885360940460926
Validation loss: 2.4216050689932302

Epoch: 6| Step: 12
Training loss: 0.14344275905384357
Validation loss: 2.4673932606174693

Epoch: 6| Step: 13
Training loss: 0.2120076513405413
Validation loss: 2.429331334190865

Epoch: 516| Step: 0
Training loss: 0.1470654723648865
Validation loss: 2.462418155612445

Epoch: 6| Step: 1
Training loss: 0.15043150977707762
Validation loss: 2.4819864748540756

Epoch: 6| Step: 2
Training loss: 0.2379702508394399
Validation loss: 2.5039528790614227

Epoch: 6| Step: 3
Training loss: 0.1213864319568539
Validation loss: 2.478954769050216

Epoch: 6| Step: 4
Training loss: 0.31274838113403924
Validation loss: 2.4785101279665627

Epoch: 6| Step: 5
Training loss: 0.1633005272286507
Validation loss: 2.489556993642157

Epoch: 6| Step: 6
Training loss: 0.12015033667688271
Validation loss: 2.4525952670856728

Epoch: 6| Step: 7
Training loss: 0.23597440967736544
Validation loss: 2.4487448529533693

Epoch: 6| Step: 8
Training loss: 0.19285032909015115
Validation loss: 2.414767156005244

Epoch: 6| Step: 9
Training loss: 0.17010498594373702
Validation loss: 2.4151916868349366

Epoch: 6| Step: 10
Training loss: 0.2057559663885518
Validation loss: 2.4332887663224754

Epoch: 6| Step: 11
Training loss: 0.1940047830792084
Validation loss: 2.455350334819661

Epoch: 6| Step: 12
Training loss: 0.17399908081584706
Validation loss: 2.41277075864476

Epoch: 6| Step: 13
Training loss: 0.1968861319407154
Validation loss: 2.4322118050183423

Epoch: 517| Step: 0
Training loss: 0.1936498444627235
Validation loss: 2.4529010364007564

Epoch: 6| Step: 1
Training loss: 0.23225779311355088
Validation loss: 2.441038654701805

Epoch: 6| Step: 2
Training loss: 0.19077064117565548
Validation loss: 2.436636644319881

Epoch: 6| Step: 3
Training loss: 0.22013994114547758
Validation loss: 2.449046262118836

Epoch: 6| Step: 4
Training loss: 0.19905530545274894
Validation loss: 2.4412991933012806

Epoch: 6| Step: 5
Training loss: 0.22445932434847088
Validation loss: 2.4410252527395326

Epoch: 6| Step: 6
Training loss: 0.22088799287504543
Validation loss: 2.4256029634695193

Epoch: 6| Step: 7
Training loss: 0.13797157386231454
Validation loss: 2.441015898313204

Epoch: 6| Step: 8
Training loss: 0.14755679797854004
Validation loss: 2.4813473848789633

Epoch: 6| Step: 9
Training loss: 0.2065242641627963
Validation loss: 2.4745517376980377

Epoch: 6| Step: 10
Training loss: 0.1641108237352142
Validation loss: 2.472502492488268

Epoch: 6| Step: 11
Training loss: 0.14832183447301336
Validation loss: 2.4244929565137623

Epoch: 6| Step: 12
Training loss: 0.23542875393216714
Validation loss: 2.4502998890518057

Epoch: 6| Step: 13
Training loss: 0.14228223772793205
Validation loss: 2.4574129472739377

Epoch: 518| Step: 0
Training loss: 0.15537470987788493
Validation loss: 2.472955229437177

Epoch: 6| Step: 1
Training loss: 0.18062259094981306
Validation loss: 2.450562160898825

Epoch: 6| Step: 2
Training loss: 0.2892795469578639
Validation loss: 2.504129737656919

Epoch: 6| Step: 3
Training loss: 0.08975453715823405
Validation loss: 2.4879732934811094

Epoch: 6| Step: 4
Training loss: 0.24308683708768644
Validation loss: 2.5171700279878246

Epoch: 6| Step: 5
Training loss: 0.31052756099500184
Validation loss: 2.572609659462665

Epoch: 6| Step: 6
Training loss: 0.18748700573716998
Validation loss: 2.5308492908745026

Epoch: 6| Step: 7
Training loss: 0.20471267836535542
Validation loss: 2.545899096057598

Epoch: 6| Step: 8
Training loss: 0.17778393819395596
Validation loss: 2.5149612830143777

Epoch: 6| Step: 9
Training loss: 0.17715099505310042
Validation loss: 2.4537185359527265

Epoch: 6| Step: 10
Training loss: 0.20863706481919747
Validation loss: 2.424474160496414

Epoch: 6| Step: 11
Training loss: 0.15901151209929865
Validation loss: 2.4082191314456742

Epoch: 6| Step: 12
Training loss: 0.17615124651462147
Validation loss: 2.4331178591110754

Epoch: 6| Step: 13
Training loss: 0.12128881156514573
Validation loss: 2.424459661110529

Epoch: 519| Step: 0
Training loss: 0.15714905291386316
Validation loss: 2.4250544398677225

Epoch: 6| Step: 1
Training loss: 0.11406762441463643
Validation loss: 2.4104350861730057

Epoch: 6| Step: 2
Training loss: 0.16880502554253685
Validation loss: 2.4171904612241866

Epoch: 6| Step: 3
Training loss: 0.21720627628096079
Validation loss: 2.4060827920832595

Epoch: 6| Step: 4
Training loss: 0.25620459061194284
Validation loss: 2.4293232992259326

Epoch: 6| Step: 5
Training loss: 0.1436958073487371
Validation loss: 2.474032074240014

Epoch: 6| Step: 6
Training loss: 0.16956108529505715
Validation loss: 2.4264454956552988

Epoch: 6| Step: 7
Training loss: 0.13037979439837696
Validation loss: 2.4220856298761193

Epoch: 6| Step: 8
Training loss: 0.1307709523274843
Validation loss: 2.436800230751195

Epoch: 6| Step: 9
Training loss: 0.15136028397106924
Validation loss: 2.420180058895769

Epoch: 6| Step: 10
Training loss: 0.18184441240435528
Validation loss: 2.433106138344237

Epoch: 6| Step: 11
Training loss: 0.16840451845654625
Validation loss: 2.4532067634244865

Epoch: 6| Step: 12
Training loss: 0.1973922719525136
Validation loss: 2.447082267011132

Epoch: 6| Step: 13
Training loss: 0.31832339077588234
Validation loss: 2.4512163847901527

Epoch: 520| Step: 0
Training loss: 0.1030312035727982
Validation loss: 2.4704411733020786

Epoch: 6| Step: 1
Training loss: 0.15651675342123716
Validation loss: 2.447007425162601

Epoch: 6| Step: 2
Training loss: 0.1847619570474897
Validation loss: 2.417930149331723

Epoch: 6| Step: 3
Training loss: 0.12996214401423475
Validation loss: 2.401394773490961

Epoch: 6| Step: 4
Training loss: 0.23675768409301318
Validation loss: 2.381249106254148

Epoch: 6| Step: 5
Training loss: 0.1493704925539376
Validation loss: 2.380688178387191

Epoch: 6| Step: 6
Training loss: 0.1645323972308817
Validation loss: 2.437991517360231

Epoch: 6| Step: 7
Training loss: 0.1399669882051751
Validation loss: 2.4688400427629835

Epoch: 6| Step: 8
Training loss: 0.1630892953127263
Validation loss: 2.436263903460945

Epoch: 6| Step: 9
Training loss: 0.2137050449491209
Validation loss: 2.4659129921849434

Epoch: 6| Step: 10
Training loss: 0.15793976231967363
Validation loss: 2.4665935501640783

Epoch: 6| Step: 11
Training loss: 0.1817817857297335
Validation loss: 2.439252392801094

Epoch: 6| Step: 12
Training loss: 0.0954636526307809
Validation loss: 2.4653208145975283

Epoch: 6| Step: 13
Training loss: 0.22591729206977526
Validation loss: 2.45950391050852

Epoch: 521| Step: 0
Training loss: 0.22976468729076208
Validation loss: 2.4453060198941796

Epoch: 6| Step: 1
Training loss: 0.17036117024522346
Validation loss: 2.3710890553991817

Epoch: 6| Step: 2
Training loss: 0.18498994666246685
Validation loss: 2.3693018465991966

Epoch: 6| Step: 3
Training loss: 0.17481895473798686
Validation loss: 2.3446285807855642

Epoch: 6| Step: 4
Training loss: 0.14136307462942638
Validation loss: 2.3163215657557847

Epoch: 6| Step: 5
Training loss: 0.20996599413083308
Validation loss: 2.3056475331109545

Epoch: 6| Step: 6
Training loss: 0.23026083603563124
Validation loss: 2.347889206814857

Epoch: 6| Step: 7
Training loss: 0.14118115070060377
Validation loss: 2.367892461657218

Epoch: 6| Step: 8
Training loss: 0.13993390123749733
Validation loss: 2.422660292255897

Epoch: 6| Step: 9
Training loss: 0.17505222248100993
Validation loss: 2.4223864949052425

Epoch: 6| Step: 10
Training loss: 0.14282967963904677
Validation loss: 2.430312819384731

Epoch: 6| Step: 11
Training loss: 0.18832623708030777
Validation loss: 2.4640923527403715

Epoch: 6| Step: 12
Training loss: 0.190995271452571
Validation loss: 2.4647649188131453

Epoch: 6| Step: 13
Training loss: 0.14231644092099008
Validation loss: 2.464576945060251

Epoch: 522| Step: 0
Training loss: 0.10877732910491497
Validation loss: 2.440548014683497

Epoch: 6| Step: 1
Training loss: 0.23116643014202196
Validation loss: 2.4551263904427456

Epoch: 6| Step: 2
Training loss: 0.14010845125186747
Validation loss: 2.445678971783666

Epoch: 6| Step: 3
Training loss: 0.18736501643016498
Validation loss: 2.456624684681009

Epoch: 6| Step: 4
Training loss: 0.1679398545095531
Validation loss: 2.4123652632298858

Epoch: 6| Step: 5
Training loss: 0.252171414463817
Validation loss: 2.4364872446343027

Epoch: 6| Step: 6
Training loss: 0.15564331050379238
Validation loss: 2.465611604370076

Epoch: 6| Step: 7
Training loss: 0.17540896517352722
Validation loss: 2.4621461680603463

Epoch: 6| Step: 8
Training loss: 0.14474717326772502
Validation loss: 2.4455077411732553

Epoch: 6| Step: 9
Training loss: 0.21482704271031003
Validation loss: 2.4635343066114266

Epoch: 6| Step: 10
Training loss: 0.2567792764685116
Validation loss: 2.428613957402995

Epoch: 6| Step: 11
Training loss: 0.153320676961089
Validation loss: 2.4426468926443374

Epoch: 6| Step: 12
Training loss: 0.08869956000271617
Validation loss: 2.424921808080585

Epoch: 6| Step: 13
Training loss: 0.1729706391780137
Validation loss: 2.456177097651768

Epoch: 523| Step: 0
Training loss: 0.14457565347225998
Validation loss: 2.466113443689607

Epoch: 6| Step: 1
Training loss: 0.14363435882906223
Validation loss: 2.450139366172343

Epoch: 6| Step: 2
Training loss: 0.22954312023114154
Validation loss: 2.431006127670773

Epoch: 6| Step: 3
Training loss: 0.21933603125389317
Validation loss: 2.453870127305292

Epoch: 6| Step: 4
Training loss: 0.250514157391988
Validation loss: 2.4255576502038005

Epoch: 6| Step: 5
Training loss: 0.15009722638239265
Validation loss: 2.4351141101302316

Epoch: 6| Step: 6
Training loss: 0.18765509667784586
Validation loss: 2.4375006604989133

Epoch: 6| Step: 7
Training loss: 0.08791039562383444
Validation loss: 2.3909831305945213

Epoch: 6| Step: 8
Training loss: 0.10595738283441813
Validation loss: 2.405167604555621

Epoch: 6| Step: 9
Training loss: 0.12206534566311401
Validation loss: 2.399073541117676

Epoch: 6| Step: 10
Training loss: 0.1503639816859697
Validation loss: 2.381112474905778

Epoch: 6| Step: 11
Training loss: 0.2371914990028937
Validation loss: 2.371907277371095

Epoch: 6| Step: 12
Training loss: 0.14006851610117632
Validation loss: 2.423804129237926

Epoch: 6| Step: 13
Training loss: 0.15806887075241524
Validation loss: 2.3916573056690997

Epoch: 524| Step: 0
Training loss: 0.18370862167297125
Validation loss: 2.4234045136339275

Epoch: 6| Step: 1
Training loss: 0.12130060524925113
Validation loss: 2.4489608709746555

Epoch: 6| Step: 2
Training loss: 0.21719991319160237
Validation loss: 2.445810643036159

Epoch: 6| Step: 3
Training loss: 0.20527730079739426
Validation loss: 2.463378319814975

Epoch: 6| Step: 4
Training loss: 0.17875164381351769
Validation loss: 2.427317054368038

Epoch: 6| Step: 5
Training loss: 0.1325175642909096
Validation loss: 2.405632420822388

Epoch: 6| Step: 6
Training loss: 0.18614426864801786
Validation loss: 2.399545418807199

Epoch: 6| Step: 7
Training loss: 0.1294237067960975
Validation loss: 2.430569723374131

Epoch: 6| Step: 8
Training loss: 0.11433556348441686
Validation loss: 2.3721500064634973

Epoch: 6| Step: 9
Training loss: 0.14192149095862353
Validation loss: 2.394343116988613

Epoch: 6| Step: 10
Training loss: 0.16844826274662733
Validation loss: 2.402396815157693

Epoch: 6| Step: 11
Training loss: 0.15287797742994683
Validation loss: 2.3824795430322037

Epoch: 6| Step: 12
Training loss: 0.11656685828685055
Validation loss: 2.3749302010245383

Epoch: 6| Step: 13
Training loss: 0.1650182722190156
Validation loss: 2.4033483838197545

Epoch: 525| Step: 0
Training loss: 0.15802728040272188
Validation loss: 2.4302565957324953

Epoch: 6| Step: 1
Training loss: 0.12496449294045055
Validation loss: 2.4053744318708685

Epoch: 6| Step: 2
Training loss: 0.11044655989761246
Validation loss: 2.420258192011307

Epoch: 6| Step: 3
Training loss: 0.12898165491425698
Validation loss: 2.3898430889450153

Epoch: 6| Step: 4
Training loss: 0.1425093001334075
Validation loss: 2.426201171841821

Epoch: 6| Step: 5
Training loss: 0.14735202683131463
Validation loss: 2.3972270754858958

Epoch: 6| Step: 6
Training loss: 0.18508732756331442
Validation loss: 2.3979125692856536

Epoch: 6| Step: 7
Training loss: 0.2405500508910573
Validation loss: 2.405838429230743

Epoch: 6| Step: 8
Training loss: 0.13175717579574395
Validation loss: 2.394848078895911

Epoch: 6| Step: 9
Training loss: 0.1544017435376274
Validation loss: 2.3835321908651506

Epoch: 6| Step: 10
Training loss: 0.11464307908983459
Validation loss: 2.3807489247931164

Epoch: 6| Step: 11
Training loss: 0.10917384092751009
Validation loss: 2.3826116123846415

Epoch: 6| Step: 12
Training loss: 0.10386206576605153
Validation loss: 2.3795807697463336

Epoch: 6| Step: 13
Training loss: 0.15610480715181876
Validation loss: 2.40025315752641

Epoch: 526| Step: 0
Training loss: 0.1252323613567132
Validation loss: 2.3930434245372196

Epoch: 6| Step: 1
Training loss: 0.08756597481853728
Validation loss: 2.4065579581005334

Epoch: 6| Step: 2
Training loss: 0.19356116929734665
Validation loss: 2.411106595233031

Epoch: 6| Step: 3
Training loss: 0.1109344398049596
Validation loss: 2.394314212000078

Epoch: 6| Step: 4
Training loss: 0.11051023098351137
Validation loss: 2.3834263293865767

Epoch: 6| Step: 5
Training loss: 0.1319550929422475
Validation loss: 2.4280881254639364

Epoch: 6| Step: 6
Training loss: 0.12352975826004463
Validation loss: 2.3823800622362326

Epoch: 6| Step: 7
Training loss: 0.12123117032776864
Validation loss: 2.3991035278740958

Epoch: 6| Step: 8
Training loss: 0.09509159817048926
Validation loss: 2.397836900516565

Epoch: 6| Step: 9
Training loss: 0.24037504342168534
Validation loss: 2.3939863467990934

Epoch: 6| Step: 10
Training loss: 0.09626595759632303
Validation loss: 2.470761842981207

Epoch: 6| Step: 11
Training loss: 0.11481557730821731
Validation loss: 2.4200006118091584

Epoch: 6| Step: 12
Training loss: 0.18098961649466744
Validation loss: 2.391220049815398

Epoch: 6| Step: 13
Training loss: 0.06408314285081557
Validation loss: 2.4230785003445723

Epoch: 527| Step: 0
Training loss: 0.09026033804123865
Validation loss: 2.406085498408899

Epoch: 6| Step: 1
Training loss: 0.08778372197152216
Validation loss: 2.4028498824328555

Epoch: 6| Step: 2
Training loss: 0.1152364116424068
Validation loss: 2.4196652782372525

Epoch: 6| Step: 3
Training loss: 0.12655251457712766
Validation loss: 2.3960173897757997

Epoch: 6| Step: 4
Training loss: 0.10297681826064914
Validation loss: 2.4060808518376886

Epoch: 6| Step: 5
Training loss: 0.10567216330904496
Validation loss: 2.3656329973423516

Epoch: 6| Step: 6
Training loss: 0.13414656078866916
Validation loss: 2.3966423730273463

Epoch: 6| Step: 7
Training loss: 0.12963104225595593
Validation loss: 2.3963785186991666

Epoch: 6| Step: 8
Training loss: 0.22034269626459066
Validation loss: 2.381231204566916

Epoch: 6| Step: 9
Training loss: 0.09360828715835093
Validation loss: 2.4075362314689026

Epoch: 6| Step: 10
Training loss: 0.0753534715894136
Validation loss: 2.424441293352525

Epoch: 6| Step: 11
Training loss: 0.11594548079688768
Validation loss: 2.4303773896936667

Epoch: 6| Step: 12
Training loss: 0.19101231773025268
Validation loss: 2.4249565248743807

Epoch: 6| Step: 13
Training loss: 0.16481851479516915
Validation loss: 2.432749429773906

Epoch: 528| Step: 0
Training loss: 0.17844053563142984
Validation loss: 2.436658521534267

Epoch: 6| Step: 1
Training loss: 0.16172209980393187
Validation loss: 2.458236444926693

Epoch: 6| Step: 2
Training loss: 0.08917760605122868
Validation loss: 2.4637932155436753

Epoch: 6| Step: 3
Training loss: 0.11304653449755296
Validation loss: 2.43625326485017

Epoch: 6| Step: 4
Training loss: 0.14624713760411415
Validation loss: 2.416417493764491

Epoch: 6| Step: 5
Training loss: 0.0967889515125372
Validation loss: 2.388097321259416

Epoch: 6| Step: 6
Training loss: 0.11817602617214897
Validation loss: 2.408157532234445

Epoch: 6| Step: 7
Training loss: 0.1279206891571618
Validation loss: 2.403444345021122

Epoch: 6| Step: 8
Training loss: 0.13152221510307477
Validation loss: 2.384823703716245

Epoch: 6| Step: 9
Training loss: 0.15762352440254532
Validation loss: 2.40849189000752

Epoch: 6| Step: 10
Training loss: 0.11450357171645081
Validation loss: 2.4086511694800876

Epoch: 6| Step: 11
Training loss: 0.1590034585882496
Validation loss: 2.438513400782852

Epoch: 6| Step: 12
Training loss: 0.07680037303750299
Validation loss: 2.429697002498743

Epoch: 6| Step: 13
Training loss: 0.21964815224213982
Validation loss: 2.436659820367687

Epoch: 529| Step: 0
Training loss: 0.09569164129373857
Validation loss: 2.4507617329655194

Epoch: 6| Step: 1
Training loss: 0.1182576549723281
Validation loss: 2.4589127906932347

Epoch: 6| Step: 2
Training loss: 0.1163433746810339
Validation loss: 2.4429007826823663

Epoch: 6| Step: 3
Training loss: 0.13845156913505632
Validation loss: 2.4378681751462774

Epoch: 6| Step: 4
Training loss: 0.10780701519656247
Validation loss: 2.477364803989784

Epoch: 6| Step: 5
Training loss: 0.1696952975397686
Validation loss: 2.4301155862512145

Epoch: 6| Step: 6
Training loss: 0.19893521345995513
Validation loss: 2.438006111611946

Epoch: 6| Step: 7
Training loss: 0.13061449995458319
Validation loss: 2.39742005403591

Epoch: 6| Step: 8
Training loss: 0.14348630509090426
Validation loss: 2.4367515186771316

Epoch: 6| Step: 9
Training loss: 0.11707927156622844
Validation loss: 2.4204318560234634

Epoch: 6| Step: 10
Training loss: 0.2232510335509585
Validation loss: 2.379479282317479

Epoch: 6| Step: 11
Training loss: 0.12867097625001633
Validation loss: 2.3974505041720917

Epoch: 6| Step: 12
Training loss: 0.15974148099195207
Validation loss: 2.417986685047406

Epoch: 6| Step: 13
Training loss: 0.15980161387439631
Validation loss: 2.4034087900204164

Epoch: 530| Step: 0
Training loss: 0.11635550154407193
Validation loss: 2.4397946924046123

Epoch: 6| Step: 1
Training loss: 0.08732568586461285
Validation loss: 2.4182897095598594

Epoch: 6| Step: 2
Training loss: 0.07911065426134396
Validation loss: 2.457970984777761

Epoch: 6| Step: 3
Training loss: 0.11346318991782166
Validation loss: 2.4087115193273814

Epoch: 6| Step: 4
Training loss: 0.10729751324078415
Validation loss: 2.4331202772234217

Epoch: 6| Step: 5
Training loss: 0.2560062569239162
Validation loss: 2.4409283160596313

Epoch: 6| Step: 6
Training loss: 0.16357855150548137
Validation loss: 2.4067661950018224

Epoch: 6| Step: 7
Training loss: 0.11152292658994462
Validation loss: 2.4047082298679694

Epoch: 6| Step: 8
Training loss: 0.16233959281709417
Validation loss: 2.3882049111355133

Epoch: 6| Step: 9
Training loss: 0.1662481754873303
Validation loss: 2.3609564195065724

Epoch: 6| Step: 10
Training loss: 0.10751196378154598
Validation loss: 2.3620982115627838

Epoch: 6| Step: 11
Training loss: 0.19066920744978952
Validation loss: 2.355914102696983

Epoch: 6| Step: 12
Training loss: 0.1724009486204964
Validation loss: 2.319120325468993

Epoch: 6| Step: 13
Training loss: 0.1775853926467475
Validation loss: 2.3687111557665688

Epoch: 531| Step: 0
Training loss: 0.12011221355901708
Validation loss: 2.3546912018846413

Epoch: 6| Step: 1
Training loss: 0.12908381456969223
Validation loss: 2.369933289888411

Epoch: 6| Step: 2
Training loss: 0.17949957972466724
Validation loss: 2.3643869377461724

Epoch: 6| Step: 3
Training loss: 0.08972165892724036
Validation loss: 2.3908974164365087

Epoch: 6| Step: 4
Training loss: 0.08810667927171924
Validation loss: 2.4187805402368285

Epoch: 6| Step: 5
Training loss: 0.1054576762001959
Validation loss: 2.4109025309943033

Epoch: 6| Step: 6
Training loss: 0.21075554346676764
Validation loss: 2.4369863237595952

Epoch: 6| Step: 7
Training loss: 0.09477429809412279
Validation loss: 2.423524600823862

Epoch: 6| Step: 8
Training loss: 0.14152724848182308
Validation loss: 2.4349194121764164

Epoch: 6| Step: 9
Training loss: 0.1319730116706862
Validation loss: 2.430405148502638

Epoch: 6| Step: 10
Training loss: 0.15410306081297284
Validation loss: 2.4291802404260814

Epoch: 6| Step: 11
Training loss: 0.18100718314317327
Validation loss: 2.422247469996463

Epoch: 6| Step: 12
Training loss: 0.16609911221867527
Validation loss: 2.438773359789583

Epoch: 6| Step: 13
Training loss: 0.08332757507735027
Validation loss: 2.4356119749283374

Epoch: 532| Step: 0
Training loss: 0.0730617780833315
Validation loss: 2.4205187792082543

Epoch: 6| Step: 1
Training loss: 0.1300345660068517
Validation loss: 2.42559723924578

Epoch: 6| Step: 2
Training loss: 0.10911811310408391
Validation loss: 2.432203305251108

Epoch: 6| Step: 3
Training loss: 0.10208801338681632
Validation loss: 2.4280184404198266

Epoch: 6| Step: 4
Training loss: 0.12834490303838686
Validation loss: 2.4081111305852834

Epoch: 6| Step: 5
Training loss: 0.14063020537596926
Validation loss: 2.434571681419958

Epoch: 6| Step: 6
Training loss: 0.1383618125506951
Validation loss: 2.391589774405365

Epoch: 6| Step: 7
Training loss: 0.13160742275905551
Validation loss: 2.4071192711430984

Epoch: 6| Step: 8
Training loss: 0.11326264360145312
Validation loss: 2.3833399809625524

Epoch: 6| Step: 9
Training loss: 0.09646283982754511
Validation loss: 2.415786140037332

Epoch: 6| Step: 10
Training loss: 0.18195954903989278
Validation loss: 2.4032991318556625

Epoch: 6| Step: 11
Training loss: 0.1585261496804946
Validation loss: 2.417567656054171

Epoch: 6| Step: 12
Training loss: 0.17519498652807422
Validation loss: 2.4081910328027982

Epoch: 6| Step: 13
Training loss: 0.11542862748048228
Validation loss: 2.407644778801111

Epoch: 533| Step: 0
Training loss: 0.1142806413455409
Validation loss: 2.4360428049536074

Epoch: 6| Step: 1
Training loss: 0.1444655410790618
Validation loss: 2.43313228661898

Epoch: 6| Step: 2
Training loss: 0.14083791879331134
Validation loss: 2.4187898497602904

Epoch: 6| Step: 3
Training loss: 0.1416620322712961
Validation loss: 2.4035281371376653

Epoch: 6| Step: 4
Training loss: 0.09041367527064564
Validation loss: 2.4471127403284774

Epoch: 6| Step: 5
Training loss: 0.1553110820793807
Validation loss: 2.442312784798265

Epoch: 6| Step: 6
Training loss: 0.16081621683245736
Validation loss: 2.4192146437712094

Epoch: 6| Step: 7
Training loss: 0.15074462841199818
Validation loss: 2.404194964713671

Epoch: 6| Step: 8
Training loss: 0.1245788056895531
Validation loss: 2.4191738089646564

Epoch: 6| Step: 9
Training loss: 0.10676538833442316
Validation loss: 2.425073943106544

Epoch: 6| Step: 10
Training loss: 0.10736055357842289
Validation loss: 2.4230094589358835

Epoch: 6| Step: 11
Training loss: 0.13971713850422604
Validation loss: 2.4426160351042463

Epoch: 6| Step: 12
Training loss: 0.19276690988977432
Validation loss: 2.4259067792426596

Epoch: 6| Step: 13
Training loss: 0.14361612471472754
Validation loss: 2.453107534001133

Epoch: 534| Step: 0
Training loss: 0.11087490989118008
Validation loss: 2.419963722655421

Epoch: 6| Step: 1
Training loss: 0.1276326480207582
Validation loss: 2.4328542109192495

Epoch: 6| Step: 2
Training loss: 0.10906703200392512
Validation loss: 2.4473686905294048

Epoch: 6| Step: 3
Training loss: 0.14242049871000478
Validation loss: 2.413712297150649

Epoch: 6| Step: 4
Training loss: 0.1621442780205868
Validation loss: 2.397196025768072

Epoch: 6| Step: 5
Training loss: 0.1316644613040051
Validation loss: 2.421643197156832

Epoch: 6| Step: 6
Training loss: 0.17402763383046618
Validation loss: 2.416627987208037

Epoch: 6| Step: 7
Training loss: 0.07422822339683316
Validation loss: 2.3634937423735365

Epoch: 6| Step: 8
Training loss: 0.14898866670265162
Validation loss: 2.4100184545234615

Epoch: 6| Step: 9
Training loss: 0.13322771606098013
Validation loss: 2.3816584107590235

Epoch: 6| Step: 10
Training loss: 0.126698679128256
Validation loss: 2.3973719175228383

Epoch: 6| Step: 11
Training loss: 0.11677031565902236
Validation loss: 2.3963050534835193

Epoch: 6| Step: 12
Training loss: 0.16827303471431365
Validation loss: 2.388779770617483

Epoch: 6| Step: 13
Training loss: 0.12919440718245562
Validation loss: 2.4053852992445064

Epoch: 535| Step: 0
Training loss: 0.14624394076176894
Validation loss: 2.4154730344787563

Epoch: 6| Step: 1
Training loss: 0.0937871462027613
Validation loss: 2.431998333180938

Epoch: 6| Step: 2
Training loss: 0.10076829435184807
Validation loss: 2.425199842998332

Epoch: 6| Step: 3
Training loss: 0.09160402005931223
Validation loss: 2.3971760550922796

Epoch: 6| Step: 4
Training loss: 0.14589767583523117
Validation loss: 2.403659787497111

Epoch: 6| Step: 5
Training loss: 0.19744514568205435
Validation loss: 2.3980357322712416

Epoch: 6| Step: 6
Training loss: 0.11048232407919348
Validation loss: 2.3742767251645143

Epoch: 6| Step: 7
Training loss: 0.08745236270845619
Validation loss: 2.3863943521410147

Epoch: 6| Step: 8
Training loss: 0.10508814324337172
Validation loss: 2.4294800849367113

Epoch: 6| Step: 9
Training loss: 0.15460667714313897
Validation loss: 2.422691802903356

Epoch: 6| Step: 10
Training loss: 0.11028694691675527
Validation loss: 2.382191844513068

Epoch: 6| Step: 11
Training loss: 0.12078585243339056
Validation loss: 2.4008937527918617

Epoch: 6| Step: 12
Training loss: 0.1686735337579113
Validation loss: 2.460341202098523

Epoch: 6| Step: 13
Training loss: 0.22443504202231598
Validation loss: 2.4264193820322975

Epoch: 536| Step: 0
Training loss: 0.17044395505091228
Validation loss: 2.4453046286768583

Epoch: 6| Step: 1
Training loss: 0.10554336628139614
Validation loss: 2.481224274046694

Epoch: 6| Step: 2
Training loss: 0.1294107678860762
Validation loss: 2.434762167550615

Epoch: 6| Step: 3
Training loss: 0.09382968734533105
Validation loss: 2.476794466621023

Epoch: 6| Step: 4
Training loss: 0.11206660534806014
Validation loss: 2.419671657491465

Epoch: 6| Step: 5
Training loss: 0.1707252496832886
Validation loss: 2.4425137782113655

Epoch: 6| Step: 6
Training loss: 0.10529226531068145
Validation loss: 2.4379789724800496

Epoch: 6| Step: 7
Training loss: 0.17532549160573332
Validation loss: 2.463981380182475

Epoch: 6| Step: 8
Training loss: 0.0901696575812941
Validation loss: 2.405727413894658

Epoch: 6| Step: 9
Training loss: 0.08864700371895654
Validation loss: 2.4339510573832737

Epoch: 6| Step: 10
Training loss: 0.10542034875271811
Validation loss: 2.4437500856452656

Epoch: 6| Step: 11
Training loss: 0.14693092311311795
Validation loss: 2.4509598756712023

Epoch: 6| Step: 12
Training loss: 0.08720922178996604
Validation loss: 2.4206040555625608

Epoch: 6| Step: 13
Training loss: 0.13551802616769665
Validation loss: 2.3796497002753316

Epoch: 537| Step: 0
Training loss: 0.08629722247087436
Validation loss: 2.398672123069515

Epoch: 6| Step: 1
Training loss: 0.15448236181020578
Validation loss: 2.4104684524559827

Epoch: 6| Step: 2
Training loss: 0.1086101269208212
Validation loss: 2.403626256838209

Epoch: 6| Step: 3
Training loss: 0.10621251451276267
Validation loss: 2.425425446003403

Epoch: 6| Step: 4
Training loss: 0.09874508859848742
Validation loss: 2.417380837037464

Epoch: 6| Step: 5
Training loss: 0.1852840368917319
Validation loss: 2.423476332245492

Epoch: 6| Step: 6
Training loss: 0.1013799594998909
Validation loss: 2.4050193892504015

Epoch: 6| Step: 7
Training loss: 0.1845694950630615
Validation loss: 2.3917786459833814

Epoch: 6| Step: 8
Training loss: 0.12937093555589696
Validation loss: 2.3997721249403514

Epoch: 6| Step: 9
Training loss: 0.14896731188419843
Validation loss: 2.4150987883144555

Epoch: 6| Step: 10
Training loss: 0.12705219511378674
Validation loss: 2.428846745772483

Epoch: 6| Step: 11
Training loss: 0.10367170299351904
Validation loss: 2.4409216389411252

Epoch: 6| Step: 12
Training loss: 0.09481248203483618
Validation loss: 2.4523734963852863

Epoch: 6| Step: 13
Training loss: 0.1965173940045885
Validation loss: 2.434409814988691

Epoch: 538| Step: 0
Training loss: 0.14278947502686506
Validation loss: 2.4644361069536123

Epoch: 6| Step: 1
Training loss: 0.1819626711728045
Validation loss: 2.4118824796662137

Epoch: 6| Step: 2
Training loss: 0.12826133284170185
Validation loss: 2.4521220999501456

Epoch: 6| Step: 3
Training loss: 0.1706501219406581
Validation loss: 2.4227154276837326

Epoch: 6| Step: 4
Training loss: 0.09387144527549654
Validation loss: 2.433262695587162

Epoch: 6| Step: 5
Training loss: 0.13173494355969584
Validation loss: 2.4018654672091

Epoch: 6| Step: 6
Training loss: 0.10828105912047237
Validation loss: 2.4286775252252855

Epoch: 6| Step: 7
Training loss: 0.10170040030293982
Validation loss: 2.40151981070803

Epoch: 6| Step: 8
Training loss: 0.11445004439520777
Validation loss: 2.371067460602245

Epoch: 6| Step: 9
Training loss: 0.11213715953317038
Validation loss: 2.396237108644387

Epoch: 6| Step: 10
Training loss: 0.14441945288547312
Validation loss: 2.3940135536233043

Epoch: 6| Step: 11
Training loss: 0.18543189652362463
Validation loss: 2.41161791899016

Epoch: 6| Step: 12
Training loss: 0.1413601758092395
Validation loss: 2.429518343816554

Epoch: 6| Step: 13
Training loss: 0.16069778904565973
Validation loss: 2.4475861248757744

Epoch: 539| Step: 0
Training loss: 0.13873847517271784
Validation loss: 2.4486383003241334

Epoch: 6| Step: 1
Training loss: 0.10865300160671215
Validation loss: 2.430868389860011

Epoch: 6| Step: 2
Training loss: 0.07526490471447538
Validation loss: 2.473470460273864

Epoch: 6| Step: 3
Training loss: 0.15010527378625235
Validation loss: 2.4791172853720314

Epoch: 6| Step: 4
Training loss: 0.08892535307789723
Validation loss: 2.452814464353337

Epoch: 6| Step: 5
Training loss: 0.2106338982867329
Validation loss: 2.4740966039767924

Epoch: 6| Step: 6
Training loss: 0.12741685682012907
Validation loss: 2.4523178767796336

Epoch: 6| Step: 7
Training loss: 0.18805047529805088
Validation loss: 2.444505925639014

Epoch: 6| Step: 8
Training loss: 0.10187448669667025
Validation loss: 2.414237464505723

Epoch: 6| Step: 9
Training loss: 0.10692447902207132
Validation loss: 2.417223352452895

Epoch: 6| Step: 10
Training loss: 0.11065586298045639
Validation loss: 2.409159674634235

Epoch: 6| Step: 11
Training loss: 0.18542853145106405
Validation loss: 2.429450216696715

Epoch: 6| Step: 12
Training loss: 0.11282031235629837
Validation loss: 2.418061130611786

Epoch: 6| Step: 13
Training loss: 0.0892377192211758
Validation loss: 2.3836288100182133

Epoch: 540| Step: 0
Training loss: 0.12773267849836745
Validation loss: 2.391977977039871

Epoch: 6| Step: 1
Training loss: 0.07638881125982029
Validation loss: 2.394488857229734

Epoch: 6| Step: 2
Training loss: 0.13726712332978686
Validation loss: 2.392555865614718

Epoch: 6| Step: 3
Training loss: 0.06430315140025057
Validation loss: 2.368469239997875

Epoch: 6| Step: 4
Training loss: 0.21163310046389208
Validation loss: 2.414073460741837

Epoch: 6| Step: 5
Training loss: 0.18223164910089173
Validation loss: 2.3965487281934914

Epoch: 6| Step: 6
Training loss: 0.11409477273759008
Validation loss: 2.4071286348189656

Epoch: 6| Step: 7
Training loss: 0.1436627947586303
Validation loss: 2.4055215291954397

Epoch: 6| Step: 8
Training loss: 0.09994349820599885
Validation loss: 2.41303707233399

Epoch: 6| Step: 9
Training loss: 0.07469272164821983
Validation loss: 2.426805184435665

Epoch: 6| Step: 10
Training loss: 0.0911332961951352
Validation loss: 2.3999664434613104

Epoch: 6| Step: 11
Training loss: 0.1446281121416977
Validation loss: 2.4095327727944356

Epoch: 6| Step: 12
Training loss: 0.15530749013561368
Validation loss: 2.3864667850187047

Epoch: 6| Step: 13
Training loss: 0.11495512732166698
Validation loss: 2.4118666867336844

Epoch: 541| Step: 0
Training loss: 0.12101024778891795
Validation loss: 2.43047726918688

Epoch: 6| Step: 1
Training loss: 0.10425214737057312
Validation loss: 2.403591421275352

Epoch: 6| Step: 2
Training loss: 0.07114434904409145
Validation loss: 2.3900360211904035

Epoch: 6| Step: 3
Training loss: 0.1451095789561559
Validation loss: 2.397799903461043

Epoch: 6| Step: 4
Training loss: 0.09014863134915897
Validation loss: 2.408724579566725

Epoch: 6| Step: 5
Training loss: 0.1102747438808114
Validation loss: 2.447656001182994

Epoch: 6| Step: 6
Training loss: 0.0842902247728586
Validation loss: 2.42905041808674

Epoch: 6| Step: 7
Training loss: 0.17907950952971743
Validation loss: 2.439925166088145

Epoch: 6| Step: 8
Training loss: 0.09275916140287276
Validation loss: 2.4508442122601535

Epoch: 6| Step: 9
Training loss: 0.0913728090394095
Validation loss: 2.4438496194867465

Epoch: 6| Step: 10
Training loss: 0.13922489734953433
Validation loss: 2.445637600834369

Epoch: 6| Step: 11
Training loss: 0.18909575981593896
Validation loss: 2.460601622251046

Epoch: 6| Step: 12
Training loss: 0.11086416607827544
Validation loss: 2.443513689505841

Epoch: 6| Step: 13
Training loss: 0.0601905327185879
Validation loss: 2.4569710008207526

Epoch: 542| Step: 0
Training loss: 0.15951002983020282
Validation loss: 2.4272460277379286

Epoch: 6| Step: 1
Training loss: 0.09532418453011314
Validation loss: 2.443202297398289

Epoch: 6| Step: 2
Training loss: 0.10023556025481455
Validation loss: 2.4185669725682164

Epoch: 6| Step: 3
Training loss: 0.09237346763204482
Validation loss: 2.43628471122868

Epoch: 6| Step: 4
Training loss: 0.13597227397184303
Validation loss: 2.4395077138016776

Epoch: 6| Step: 5
Training loss: 0.1773245666648392
Validation loss: 2.4345310894571806

Epoch: 6| Step: 6
Training loss: 0.12721270652374525
Validation loss: 2.444748478831977

Epoch: 6| Step: 7
Training loss: 0.13678515047974873
Validation loss: 2.4173755244397634

Epoch: 6| Step: 8
Training loss: 0.15743020889902373
Validation loss: 2.420549610245082

Epoch: 6| Step: 9
Training loss: 0.10976567913203415
Validation loss: 2.3975064513861892

Epoch: 6| Step: 10
Training loss: 0.1315440443373038
Validation loss: 2.443931962813909

Epoch: 6| Step: 11
Training loss: 0.09090620511795777
Validation loss: 2.450490946757086

Epoch: 6| Step: 12
Training loss: 0.11850970528817632
Validation loss: 2.4358960599433743

Epoch: 6| Step: 13
Training loss: 0.15586299653016641
Validation loss: 2.444155288745102

Epoch: 543| Step: 0
Training loss: 0.11049593705587524
Validation loss: 2.419669483397748

Epoch: 6| Step: 1
Training loss: 0.11639386693644102
Validation loss: 2.420338032166359

Epoch: 6| Step: 2
Training loss: 0.11935670987162618
Validation loss: 2.390061624894135

Epoch: 6| Step: 3
Training loss: 0.17980964282540013
Validation loss: 2.4001408525805856

Epoch: 6| Step: 4
Training loss: 0.14519574797213247
Validation loss: 2.400317093537215

Epoch: 6| Step: 5
Training loss: 0.1954028302162935
Validation loss: 2.40493354002682

Epoch: 6| Step: 6
Training loss: 0.10305975002086523
Validation loss: 2.4141855855953844

Epoch: 6| Step: 7
Training loss: 0.1341976692333436
Validation loss: 2.4052598458487386

Epoch: 6| Step: 8
Training loss: 0.15119631567236716
Validation loss: 2.3922539419339075

Epoch: 6| Step: 9
Training loss: 0.10484757550731998
Validation loss: 2.400722934063268

Epoch: 6| Step: 10
Training loss: 0.09482836905765601
Validation loss: 2.4058213903646144

Epoch: 6| Step: 11
Training loss: 0.1464070942792294
Validation loss: 2.403023175461368

Epoch: 6| Step: 12
Training loss: 0.10889084128200834
Validation loss: 2.3950040868631417

Epoch: 6| Step: 13
Training loss: 0.08598476161537132
Validation loss: 2.4173337793916154

Epoch: 544| Step: 0
Training loss: 0.08452612777639916
Validation loss: 2.419085957854842

Epoch: 6| Step: 1
Training loss: 0.11414800975782861
Validation loss: 2.434921140453167

Epoch: 6| Step: 2
Training loss: 0.11794025727572996
Validation loss: 2.4227958534876715

Epoch: 6| Step: 3
Training loss: 0.10035780618858796
Validation loss: 2.4062315907258216

Epoch: 6| Step: 4
Training loss: 0.18013856084684754
Validation loss: 2.42544080396073

Epoch: 6| Step: 5
Training loss: 0.1255787771743674
Validation loss: 2.43083774454023

Epoch: 6| Step: 6
Training loss: 0.09393954983046444
Validation loss: 2.43696485081874

Epoch: 6| Step: 7
Training loss: 0.13119062090955697
Validation loss: 2.4341862821540787

Epoch: 6| Step: 8
Training loss: 0.1788301122645812
Validation loss: 2.4396183778275597

Epoch: 6| Step: 9
Training loss: 0.12144949019649177
Validation loss: 2.4405746882709556

Epoch: 6| Step: 10
Training loss: 0.10186512499907528
Validation loss: 2.432667439293858

Epoch: 6| Step: 11
Training loss: 0.14240250810993793
Validation loss: 2.426294961804464

Epoch: 6| Step: 12
Training loss: 0.0996669761687529
Validation loss: 2.433800143502554

Epoch: 6| Step: 13
Training loss: 0.10859214383590994
Validation loss: 2.442868775016651

Epoch: 545| Step: 0
Training loss: 0.15754722687563635
Validation loss: 2.411282441370565

Epoch: 6| Step: 1
Training loss: 0.13320040154679375
Validation loss: 2.4261222917857515

Epoch: 6| Step: 2
Training loss: 0.11832972806768732
Validation loss: 2.4324629110424256

Epoch: 6| Step: 3
Training loss: 0.07693745034713599
Validation loss: 2.4312417480841595

Epoch: 6| Step: 4
Training loss: 0.0735480312459537
Validation loss: 2.446643942706492

Epoch: 6| Step: 5
Training loss: 0.08917787758072075
Validation loss: 2.4256950575660214

Epoch: 6| Step: 6
Training loss: 0.08681291952951839
Validation loss: 2.433973621772394

Epoch: 6| Step: 7
Training loss: 0.09098221591370688
Validation loss: 2.44131798605571

Epoch: 6| Step: 8
Training loss: 0.09570967398832292
Validation loss: 2.4121072621108133

Epoch: 6| Step: 9
Training loss: 0.13259534754297564
Validation loss: 2.4172379448259993

Epoch: 6| Step: 10
Training loss: 0.13172303062714505
Validation loss: 2.3712702908419363

Epoch: 6| Step: 11
Training loss: 0.14499555575819434
Validation loss: 2.408095045706462

Epoch: 6| Step: 12
Training loss: 0.1907662962380616
Validation loss: 2.4356199007321084

Epoch: 6| Step: 13
Training loss: 0.09451005221161053
Validation loss: 2.435598691518099

Epoch: 546| Step: 0
Training loss: 0.09938774041462337
Validation loss: 2.464685381964144

Epoch: 6| Step: 1
Training loss: 0.14815855167357522
Validation loss: 2.4329922519918203

Epoch: 6| Step: 2
Training loss: 0.1363217926194264
Validation loss: 2.4377157359313086

Epoch: 6| Step: 3
Training loss: 0.14733549175804883
Validation loss: 2.408396959136745

Epoch: 6| Step: 4
Training loss: 0.09581456702510369
Validation loss: 2.447431923638494

Epoch: 6| Step: 5
Training loss: 0.1952563300425427
Validation loss: 2.426704350390979

Epoch: 6| Step: 6
Training loss: 0.07984700228045062
Validation loss: 2.4140357798471404

Epoch: 6| Step: 7
Training loss: 0.095957772453764
Validation loss: 2.444453999036734

Epoch: 6| Step: 8
Training loss: 0.12137120133126597
Validation loss: 2.4345569707551813

Epoch: 6| Step: 9
Training loss: 0.09503650102091576
Validation loss: 2.4382790849924474

Epoch: 6| Step: 10
Training loss: 0.07643493442526411
Validation loss: 2.4625549272385325

Epoch: 6| Step: 11
Training loss: 0.07374445675166032
Validation loss: 2.471774287679582

Epoch: 6| Step: 12
Training loss: 0.0782746877746529
Validation loss: 2.4620549563692093

Epoch: 6| Step: 13
Training loss: 0.13013841818281416
Validation loss: 2.4718050342790354

Epoch: 547| Step: 0
Training loss: 0.11742872999870765
Validation loss: 2.4837996851906365

Epoch: 6| Step: 1
Training loss: 0.10130538397742496
Validation loss: 2.5176291912807165

Epoch: 6| Step: 2
Training loss: 0.10913976850562687
Validation loss: 2.478587297359908

Epoch: 6| Step: 3
Training loss: 0.08461239452733069
Validation loss: 2.488228748661625

Epoch: 6| Step: 4
Training loss: 0.08073640285896098
Validation loss: 2.446258964580207

Epoch: 6| Step: 5
Training loss: 0.19506229586958784
Validation loss: 2.463073739795561

Epoch: 6| Step: 6
Training loss: 0.10525713106029806
Validation loss: 2.4654242431663076

Epoch: 6| Step: 7
Training loss: 0.07460894721842254
Validation loss: 2.450024730280477

Epoch: 6| Step: 8
Training loss: 0.15289719627421933
Validation loss: 2.446490024742335

Epoch: 6| Step: 9
Training loss: 0.12782468199094432
Validation loss: 2.4082051199565346

Epoch: 6| Step: 10
Training loss: 0.06487236081159248
Validation loss: 2.433794234208209

Epoch: 6| Step: 11
Training loss: 0.08342768002347214
Validation loss: 2.4463561862343552

Epoch: 6| Step: 12
Training loss: 0.08116348846516021
Validation loss: 2.4270380810673626

Epoch: 6| Step: 13
Training loss: 0.129905447744297
Validation loss: 2.4162992262437077

Epoch: 548| Step: 0
Training loss: 0.09542398225685303
Validation loss: 2.4413598229372555

Epoch: 6| Step: 1
Training loss: 0.10043557511457163
Validation loss: 2.4291414659502597

Epoch: 6| Step: 2
Training loss: 0.14894255246642274
Validation loss: 2.4253424003660156

Epoch: 6| Step: 3
Training loss: 0.0804855692516956
Validation loss: 2.427909768641882

Epoch: 6| Step: 4
Training loss: 0.06650495906450216
Validation loss: 2.451884111908277

Epoch: 6| Step: 5
Training loss: 0.09536288563383721
Validation loss: 2.4321741988043115

Epoch: 6| Step: 6
Training loss: 0.11637040024644506
Validation loss: 2.431807201491848

Epoch: 6| Step: 7
Training loss: 0.08713210273408448
Validation loss: 2.4734620686023447

Epoch: 6| Step: 8
Training loss: 0.08500609074975173
Validation loss: 2.421041218496727

Epoch: 6| Step: 9
Training loss: 0.10672717442360473
Validation loss: 2.426292178171297

Epoch: 6| Step: 10
Training loss: 0.11950112739309504
Validation loss: 2.4489632454409533

Epoch: 6| Step: 11
Training loss: 0.0832776284548693
Validation loss: 2.4436338192236295

Epoch: 6| Step: 12
Training loss: 0.21760221344555272
Validation loss: 2.458450380990288

Epoch: 6| Step: 13
Training loss: 0.058338671022115145
Validation loss: 2.427529923248356

Epoch: 549| Step: 0
Training loss: 0.10315671364501793
Validation loss: 2.420805378323704

Epoch: 6| Step: 1
Training loss: 0.09858878257679442
Validation loss: 2.408958582235028

Epoch: 6| Step: 2
Training loss: 0.09874595158463098
Validation loss: 2.4089820527659787

Epoch: 6| Step: 3
Training loss: 0.15767571758191956
Validation loss: 2.430042567069127

Epoch: 6| Step: 4
Training loss: 0.08756767650876997
Validation loss: 2.393874078233335

Epoch: 6| Step: 5
Training loss: 0.10499774879358333
Validation loss: 2.407972037916353

Epoch: 6| Step: 6
Training loss: 0.09334542976358365
Validation loss: 2.4348360880932085

Epoch: 6| Step: 7
Training loss: 0.10809184869912121
Validation loss: 2.4680097328619435

Epoch: 6| Step: 8
Training loss: 0.14284161819673205
Validation loss: 2.423370784354975

Epoch: 6| Step: 9
Training loss: 0.10175737153907753
Validation loss: 2.445447491135688

Epoch: 6| Step: 10
Training loss: 0.1559410796490401
Validation loss: 2.4547210782759814

Epoch: 6| Step: 11
Training loss: 0.11452933189508521
Validation loss: 2.433046275575184

Epoch: 6| Step: 12
Training loss: 0.1611835110985437
Validation loss: 2.4290871106717593

Epoch: 6| Step: 13
Training loss: 0.06115022493588717
Validation loss: 2.452262406975463

Epoch: 550| Step: 0
Training loss: 0.12749213455052297
Validation loss: 2.4594690262502605

Epoch: 6| Step: 1
Training loss: 0.16024577150962677
Validation loss: 2.459281019336897

Epoch: 6| Step: 2
Training loss: 0.15182818078674756
Validation loss: 2.419837706073243

Epoch: 6| Step: 3
Training loss: 0.10676084351520192
Validation loss: 2.4663237963935982

Epoch: 6| Step: 4
Training loss: 0.07807298359137464
Validation loss: 2.474244001094504

Epoch: 6| Step: 5
Training loss: 0.11500364172782522
Validation loss: 2.4336085549755215

Epoch: 6| Step: 6
Training loss: 0.13715265764628218
Validation loss: 2.4222625517607246

Epoch: 6| Step: 7
Training loss: 0.13503101036864482
Validation loss: 2.395762169535882

Epoch: 6| Step: 8
Training loss: 0.09446184786959777
Validation loss: 2.422425318768926

Epoch: 6| Step: 9
Training loss: 0.07486794476373418
Validation loss: 2.4244083699836647

Epoch: 6| Step: 10
Training loss: 0.10252838079128827
Validation loss: 2.41222345378754

Epoch: 6| Step: 11
Training loss: 0.06782745769886915
Validation loss: 2.3768077569993165

Epoch: 6| Step: 12
Training loss: 0.06706803507373617
Validation loss: 2.414935863486258

Epoch: 6| Step: 13
Training loss: 0.11590320248864404
Validation loss: 2.4028307066627277

Epoch: 551| Step: 0
Training loss: 0.11187112710285532
Validation loss: 2.409688339116544

Epoch: 6| Step: 1
Training loss: 0.0918275548515775
Validation loss: 2.389727837053337

Epoch: 6| Step: 2
Training loss: 0.08391650640236947
Validation loss: 2.4335380424965973

Epoch: 6| Step: 3
Training loss: 0.10878253879539808
Validation loss: 2.408666207591843

Epoch: 6| Step: 4
Training loss: 0.15595516163106035
Validation loss: 2.417702941369649

Epoch: 6| Step: 5
Training loss: 0.07884752429935053
Validation loss: 2.4228042148414835

Epoch: 6| Step: 6
Training loss: 0.08848835822288854
Validation loss: 2.425740408425198

Epoch: 6| Step: 7
Training loss: 0.09627232319023604
Validation loss: 2.395893189983064

Epoch: 6| Step: 8
Training loss: 0.06933635053377302
Validation loss: 2.3892730873108863

Epoch: 6| Step: 9
Training loss: 0.1545988821253883
Validation loss: 2.3744555476955203

Epoch: 6| Step: 10
Training loss: 0.15693782570431788
Validation loss: 2.377939955280762

Epoch: 6| Step: 11
Training loss: 0.16877428118538976
Validation loss: 2.4007364809215423

Epoch: 6| Step: 12
Training loss: 0.08930548327714395
Validation loss: 2.442325423406799

Epoch: 6| Step: 13
Training loss: 0.07621325078256255
Validation loss: 2.4129196123415957

Epoch: 552| Step: 0
Training loss: 0.078543984927971
Validation loss: 2.4288820466156213

Epoch: 6| Step: 1
Training loss: 0.06781738887141121
Validation loss: 2.4304619646780137

Epoch: 6| Step: 2
Training loss: 0.09462390331353401
Validation loss: 2.440240822516738

Epoch: 6| Step: 3
Training loss: 0.11428663509726503
Validation loss: 2.423644121449465

Epoch: 6| Step: 4
Training loss: 0.1019795776265715
Validation loss: 2.4402550188103254

Epoch: 6| Step: 5
Training loss: 0.1342931980830258
Validation loss: 2.4411510167744366

Epoch: 6| Step: 6
Training loss: 0.16977329993421245
Validation loss: 2.44554848429799

Epoch: 6| Step: 7
Training loss: 0.08014890113311243
Validation loss: 2.4429409522341325

Epoch: 6| Step: 8
Training loss: 0.08676673425061211
Validation loss: 2.4219246146379314

Epoch: 6| Step: 9
Training loss: 0.0877378672722541
Validation loss: 2.4197367898693587

Epoch: 6| Step: 10
Training loss: 0.1422379236626176
Validation loss: 2.423435664455089

Epoch: 6| Step: 11
Training loss: 0.09740672180268346
Validation loss: 2.4261424753916048

Epoch: 6| Step: 12
Training loss: 0.126058684794879
Validation loss: 2.4099870121981666

Epoch: 6| Step: 13
Training loss: 0.056407731243481946
Validation loss: 2.4232098571564427

Epoch: 553| Step: 0
Training loss: 0.07756717734292891
Validation loss: 2.4412919816378693

Epoch: 6| Step: 1
Training loss: 0.0643663400084232
Validation loss: 2.411822666231737

Epoch: 6| Step: 2
Training loss: 0.058934441171306876
Validation loss: 2.434616569984954

Epoch: 6| Step: 3
Training loss: 0.16296682747998884
Validation loss: 2.4467889618327687

Epoch: 6| Step: 4
Training loss: 0.08923789664018839
Validation loss: 2.438091599637826

Epoch: 6| Step: 5
Training loss: 0.09278126231874749
Validation loss: 2.463173460724264

Epoch: 6| Step: 6
Training loss: 0.14413906706508212
Validation loss: 2.4570341391438584

Epoch: 6| Step: 7
Training loss: 0.18332597806293266
Validation loss: 2.463098011827733

Epoch: 6| Step: 8
Training loss: 0.11937298940917672
Validation loss: 2.4420469620881007

Epoch: 6| Step: 9
Training loss: 0.12367800794975135
Validation loss: 2.4607107753067

Epoch: 6| Step: 10
Training loss: 0.07969705697326683
Validation loss: 2.4701710530271477

Epoch: 6| Step: 11
Training loss: 0.09489321060024847
Validation loss: 2.448372678014272

Epoch: 6| Step: 12
Training loss: 0.11689405257940483
Validation loss: 2.433241999470348

Epoch: 6| Step: 13
Training loss: 0.07187262847346539
Validation loss: 2.427152719728924

Epoch: 554| Step: 0
Training loss: 0.14455751876272613
Validation loss: 2.4568667958754786

Epoch: 6| Step: 1
Training loss: 0.1282327062615133
Validation loss: 2.4437145956853974

Epoch: 6| Step: 2
Training loss: 0.09113081797033074
Validation loss: 2.4633125913759337

Epoch: 6| Step: 3
Training loss: 0.11896661652199382
Validation loss: 2.4281641744251234

Epoch: 6| Step: 4
Training loss: 0.1316152420814955
Validation loss: 2.4077244750255007

Epoch: 6| Step: 5
Training loss: 0.1109226480468624
Validation loss: 2.4019753445173646

Epoch: 6| Step: 6
Training loss: 0.14225184326201154
Validation loss: 2.4222701889186573

Epoch: 6| Step: 7
Training loss: 0.1247969707079332
Validation loss: 2.401290132404871

Epoch: 6| Step: 8
Training loss: 0.1308713736655661
Validation loss: 2.4294003742758092

Epoch: 6| Step: 9
Training loss: 0.07300098757737182
Validation loss: 2.446438749087456

Epoch: 6| Step: 10
Training loss: 0.10226348448510168
Validation loss: 2.4651402201432147

Epoch: 6| Step: 11
Training loss: 0.0961826581898224
Validation loss: 2.4586379858518987

Epoch: 6| Step: 12
Training loss: 0.17802020554034714
Validation loss: 2.425173106018197

Epoch: 6| Step: 13
Training loss: 0.10314076404304998
Validation loss: 2.4654877722610373

Epoch: 555| Step: 0
Training loss: 0.13894183115100697
Validation loss: 2.449722803660725

Epoch: 6| Step: 1
Training loss: 0.15796330606718725
Validation loss: 2.4093578794854866

Epoch: 6| Step: 2
Training loss: 0.09336565627032348
Validation loss: 2.4013325230752174

Epoch: 6| Step: 3
Training loss: 0.101704956062819
Validation loss: 2.4222925620755342

Epoch: 6| Step: 4
Training loss: 0.16870423022974546
Validation loss: 2.375283360915693

Epoch: 6| Step: 5
Training loss: 0.11463397615588651
Validation loss: 2.355943264447876

Epoch: 6| Step: 6
Training loss: 0.14274912860749703
Validation loss: 2.3696196223978996

Epoch: 6| Step: 7
Training loss: 0.09110339970785253
Validation loss: 2.3585566227539854

Epoch: 6| Step: 8
Training loss: 0.12178739186598973
Validation loss: 2.4106253318740984

Epoch: 6| Step: 9
Training loss: 0.13697395348026395
Validation loss: 2.398754444580427

Epoch: 6| Step: 10
Training loss: 0.11044983159577382
Validation loss: 2.38260481649006

Epoch: 6| Step: 11
Training loss: 0.09768664363911617
Validation loss: 2.4235139094642415

Epoch: 6| Step: 12
Training loss: 0.16106073327921844
Validation loss: 2.4234824507614934

Epoch: 6| Step: 13
Training loss: 0.074620608288006
Validation loss: 2.447512124870865

Epoch: 556| Step: 0
Training loss: 0.05974125567872212
Validation loss: 2.421566113407763

Epoch: 6| Step: 1
Training loss: 0.14354884207106375
Validation loss: 2.4717129784720258

Epoch: 6| Step: 2
Training loss: 0.19262408120222743
Validation loss: 2.449105184776135

Epoch: 6| Step: 3
Training loss: 0.11680824581663762
Validation loss: 2.4371141149825934

Epoch: 6| Step: 4
Training loss: 0.06851311493650522
Validation loss: 2.4394425034504215

Epoch: 6| Step: 5
Training loss: 0.1649887696782848
Validation loss: 2.4505898490327827

Epoch: 6| Step: 6
Training loss: 0.09684650401962958
Validation loss: 2.4136311815150955

Epoch: 6| Step: 7
Training loss: 0.06474958859155552
Validation loss: 2.4305361568147537

Epoch: 6| Step: 8
Training loss: 0.1067814245049533
Validation loss: 2.4390927294379487

Epoch: 6| Step: 9
Training loss: 0.10475732019436637
Validation loss: 2.4243630238155562

Epoch: 6| Step: 10
Training loss: 0.1281469117013137
Validation loss: 2.419601121351236

Epoch: 6| Step: 11
Training loss: 0.09886946002212833
Validation loss: 2.4002466081064977

Epoch: 6| Step: 12
Training loss: 0.09974063378055617
Validation loss: 2.3861158014280095

Epoch: 6| Step: 13
Training loss: 0.09712163500989233
Validation loss: 2.411066029278578

Epoch: 557| Step: 0
Training loss: 0.11157885559119557
Validation loss: 2.389956780440743

Epoch: 6| Step: 1
Training loss: 0.10718085386563511
Validation loss: 2.4389087811843706

Epoch: 6| Step: 2
Training loss: 0.1334532609717129
Validation loss: 2.4003363214290756

Epoch: 6| Step: 3
Training loss: 0.11869806421339643
Validation loss: 2.403984183441365

Epoch: 6| Step: 4
Training loss: 0.18711521482015114
Validation loss: 2.3962096569236757

Epoch: 6| Step: 5
Training loss: 0.09262257406272811
Validation loss: 2.42672914359445

Epoch: 6| Step: 6
Training loss: 0.07413492990855414
Validation loss: 2.4470756176845274

Epoch: 6| Step: 7
Training loss: 0.14630543269606586
Validation loss: 2.4582554148037885

Epoch: 6| Step: 8
Training loss: 0.0805430002603294
Validation loss: 2.422909044638494

Epoch: 6| Step: 9
Training loss: 0.11279087972977124
Validation loss: 2.472874351200449

Epoch: 6| Step: 10
Training loss: 0.11200073407828788
Validation loss: 2.4477389354675156

Epoch: 6| Step: 11
Training loss: 0.15990712980714578
Validation loss: 2.471049077171087

Epoch: 6| Step: 12
Training loss: 0.07994183129915951
Validation loss: 2.4287239725272496

Epoch: 6| Step: 13
Training loss: 0.08254287039805208
Validation loss: 2.4704191402088442

Epoch: 558| Step: 0
Training loss: 0.09255444630275637
Validation loss: 2.434240905340689

Epoch: 6| Step: 1
Training loss: 0.15825753394870373
Validation loss: 2.418384262702847

Epoch: 6| Step: 2
Training loss: 0.07219488960689631
Validation loss: 2.42094603527805

Epoch: 6| Step: 3
Training loss: 0.06380153513043577
Validation loss: 2.4273093478039245

Epoch: 6| Step: 4
Training loss: 0.08022577351092916
Validation loss: 2.4016177445266216

Epoch: 6| Step: 5
Training loss: 0.0790061434038848
Validation loss: 2.4431411269149605

Epoch: 6| Step: 6
Training loss: 0.12731213060071686
Validation loss: 2.3999700053666775

Epoch: 6| Step: 7
Training loss: 0.1366300772166786
Validation loss: 2.3947568566102

Epoch: 6| Step: 8
Training loss: 0.13894404311266526
Validation loss: 2.4411826773051257

Epoch: 6| Step: 9
Training loss: 0.09853985154275983
Validation loss: 2.39254192955258

Epoch: 6| Step: 10
Training loss: 0.1083296222310939
Validation loss: 2.410165648678815

Epoch: 6| Step: 11
Training loss: 0.09026720968872395
Validation loss: 2.3847494073835906

Epoch: 6| Step: 12
Training loss: 0.15290769099724602
Validation loss: 2.428083522582424

Epoch: 6| Step: 13
Training loss: 0.16024403957233804
Validation loss: 2.4283436690984606

Epoch: 559| Step: 0
Training loss: 0.08928887434033475
Validation loss: 2.395289407400492

Epoch: 6| Step: 1
Training loss: 0.12787445710692474
Validation loss: 2.4386396896306914

Epoch: 6| Step: 2
Training loss: 0.11275325835752331
Validation loss: 2.4222268374616625

Epoch: 6| Step: 3
Training loss: 0.09076895338349703
Validation loss: 2.4089649068337193

Epoch: 6| Step: 4
Training loss: 0.1055083686096495
Validation loss: 2.4082887980589986

Epoch: 6| Step: 5
Training loss: 0.17533622144324176
Validation loss: 2.421545714329095

Epoch: 6| Step: 6
Training loss: 0.21290332861278613
Validation loss: 2.4248119275820375

Epoch: 6| Step: 7
Training loss: 0.07674340265728086
Validation loss: 2.4208322556756445

Epoch: 6| Step: 8
Training loss: 0.08585225287914965
Validation loss: 2.4266696813157393

Epoch: 6| Step: 9
Training loss: 0.09614106618332686
Validation loss: 2.4110043746746523

Epoch: 6| Step: 10
Training loss: 0.06991403978018967
Validation loss: 2.4057764131456687

Epoch: 6| Step: 11
Training loss: 0.1364005199902445
Validation loss: 2.4098518357370975

Epoch: 6| Step: 12
Training loss: 0.15609693778852515
Validation loss: 2.423800229520736

Epoch: 6| Step: 13
Training loss: 0.08371455630207289
Validation loss: 2.4355080939915594

Epoch: 560| Step: 0
Training loss: 0.06461926202415304
Validation loss: 2.4234028321531094

Epoch: 6| Step: 1
Training loss: 0.08812026646934823
Validation loss: 2.4120555595182744

Epoch: 6| Step: 2
Training loss: 0.07695802900499074
Validation loss: 2.4154676815993463

Epoch: 6| Step: 3
Training loss: 0.06336148541318887
Validation loss: 2.4128011993979084

Epoch: 6| Step: 4
Training loss: 0.07576391203641805
Validation loss: 2.389706966121682

Epoch: 6| Step: 5
Training loss: 0.09307978394819655
Validation loss: 2.3923508078680618

Epoch: 6| Step: 6
Training loss: 0.12192846449048401
Validation loss: 2.4069056518606042

Epoch: 6| Step: 7
Training loss: 0.13249471455954465
Validation loss: 2.421267826265151

Epoch: 6| Step: 8
Training loss: 0.10421202437018999
Validation loss: 2.4304935925188986

Epoch: 6| Step: 9
Training loss: 0.08391029672702822
Validation loss: 2.430555439923152

Epoch: 6| Step: 10
Training loss: 0.1417647112473528
Validation loss: 2.425265052065407

Epoch: 6| Step: 11
Training loss: 0.06311824609015355
Validation loss: 2.3981967463284044

Epoch: 6| Step: 12
Training loss: 0.14508668391546323
Validation loss: 2.424492984534663

Epoch: 6| Step: 13
Training loss: 0.04596638975739133
Validation loss: 2.456208658432775

Epoch: 561| Step: 0
Training loss: 0.10378700347626792
Validation loss: 2.4221519901951334

Epoch: 6| Step: 1
Training loss: 0.1543599917089316
Validation loss: 2.428085391398771

Epoch: 6| Step: 2
Training loss: 0.08306898499644948
Validation loss: 2.435251576747831

Epoch: 6| Step: 3
Training loss: 0.08564275894158131
Validation loss: 2.4441800501995057

Epoch: 6| Step: 4
Training loss: 0.07253584729835669
Validation loss: 2.4243785164536513

Epoch: 6| Step: 5
Training loss: 0.12661122720392914
Validation loss: 2.432030473370104

Epoch: 6| Step: 6
Training loss: 0.08626595498139197
Validation loss: 2.4331623888704224

Epoch: 6| Step: 7
Training loss: 0.09127392850308051
Validation loss: 2.411051135855979

Epoch: 6| Step: 8
Training loss: 0.08831500277445306
Validation loss: 2.4245228054625185

Epoch: 6| Step: 9
Training loss: 0.1477036468184299
Validation loss: 2.401392598863783

Epoch: 6| Step: 10
Training loss: 0.14536362102572267
Validation loss: 2.4180340560037052

Epoch: 6| Step: 11
Training loss: 0.14607077382199454
Validation loss: 2.4314434932488203

Epoch: 6| Step: 12
Training loss: 0.06913981773961247
Validation loss: 2.3999934302773336

Epoch: 6| Step: 13
Training loss: 0.0875986069422477
Validation loss: 2.4236020284703614

Epoch: 562| Step: 0
Training loss: 0.11216682596901516
Validation loss: 2.400220178874102

Epoch: 6| Step: 1
Training loss: 0.08540064384723896
Validation loss: 2.4019540708970726

Epoch: 6| Step: 2
Training loss: 0.12001754147623822
Validation loss: 2.4000232859049278

Epoch: 6| Step: 3
Training loss: 0.09941634941843186
Validation loss: 2.401331352995358

Epoch: 6| Step: 4
Training loss: 0.08717245097670054
Validation loss: 2.441661556291326

Epoch: 6| Step: 5
Training loss: 0.1242715014304913
Validation loss: 2.418342799027706

Epoch: 6| Step: 6
Training loss: 0.10739855513174638
Validation loss: 2.4631316696213124

Epoch: 6| Step: 7
Training loss: 0.0962811259776861
Validation loss: 2.437534330981873

Epoch: 6| Step: 8
Training loss: 0.14102777444591813
Validation loss: 2.431219134087502

Epoch: 6| Step: 9
Training loss: 0.08545077731209759
Validation loss: 2.4600046999850003

Epoch: 6| Step: 10
Training loss: 0.17689725739184367
Validation loss: 2.438372720543494

Epoch: 6| Step: 11
Training loss: 0.16357471409053673
Validation loss: 2.4456249332193947

Epoch: 6| Step: 12
Training loss: 0.08196331514930116
Validation loss: 2.416590849783652

Epoch: 6| Step: 13
Training loss: 0.0880141767358637
Validation loss: 2.4002873376891225

Epoch: 563| Step: 0
Training loss: 0.11763422378612608
Validation loss: 2.4225042366591794

Epoch: 6| Step: 1
Training loss: 0.08458815930349015
Validation loss: 2.4341162187545984

Epoch: 6| Step: 2
Training loss: 0.10798266292203369
Validation loss: 2.403257144431297

Epoch: 6| Step: 3
Training loss: 0.16360969728057947
Validation loss: 2.4083082316230495

Epoch: 6| Step: 4
Training loss: 0.1681273066883604
Validation loss: 2.43040554195057

Epoch: 6| Step: 5
Training loss: 0.08944787526447165
Validation loss: 2.4299017793861832

Epoch: 6| Step: 6
Training loss: 0.11296765725278693
Validation loss: 2.463151773215135

Epoch: 6| Step: 7
Training loss: 0.17626658302441064
Validation loss: 2.4743789482820295

Epoch: 6| Step: 8
Training loss: 0.09040532618188105
Validation loss: 2.445743621728263

Epoch: 6| Step: 9
Training loss: 0.0777702682382021
Validation loss: 2.4125360939198814

Epoch: 6| Step: 10
Training loss: 0.11929184275357761
Validation loss: 2.415003462708941

Epoch: 6| Step: 11
Training loss: 0.10683470556186982
Validation loss: 2.456754963704574

Epoch: 6| Step: 12
Training loss: 0.10473296686927787
Validation loss: 2.4508429800441633

Epoch: 6| Step: 13
Training loss: 0.050051516949138064
Validation loss: 2.437371916622775

Epoch: 564| Step: 0
Training loss: 0.06891294521991143
Validation loss: 2.4361375209183316

Epoch: 6| Step: 1
Training loss: 0.11397764710957421
Validation loss: 2.370061332525519

Epoch: 6| Step: 2
Training loss: 0.1424633112532614
Validation loss: 2.39013840432715

Epoch: 6| Step: 3
Training loss: 0.07683352892794575
Validation loss: 2.380319534891886

Epoch: 6| Step: 4
Training loss: 0.07129591425537425
Validation loss: 2.3910097931399075

Epoch: 6| Step: 5
Training loss: 0.09166677874139234
Validation loss: 2.4190861920608864

Epoch: 6| Step: 6
Training loss: 0.11101789080235741
Validation loss: 2.363331934725139

Epoch: 6| Step: 7
Training loss: 0.14912215246837737
Validation loss: 2.3717598544480776

Epoch: 6| Step: 8
Training loss: 0.14763512334101625
Validation loss: 2.397779781181046

Epoch: 6| Step: 9
Training loss: 0.10001448455604924
Validation loss: 2.401079744825337

Epoch: 6| Step: 10
Training loss: 0.0694489967655475
Validation loss: 2.3748408881160725

Epoch: 6| Step: 11
Training loss: 0.08752071633501744
Validation loss: 2.3969769819710995

Epoch: 6| Step: 12
Training loss: 0.15538156091712585
Validation loss: 2.380676412710756

Epoch: 6| Step: 13
Training loss: 0.09400931396876759
Validation loss: 2.406808494016527

Epoch: 565| Step: 0
Training loss: 0.115438240560584
Validation loss: 2.403927149983345

Epoch: 6| Step: 1
Training loss: 0.13756094118515028
Validation loss: 2.4073818439006

Epoch: 6| Step: 2
Training loss: 0.15314097759033815
Validation loss: 2.4119026687039646

Epoch: 6| Step: 3
Training loss: 0.09713341946973322
Validation loss: 2.39888236860394

Epoch: 6| Step: 4
Training loss: 0.08681140687877714
Validation loss: 2.4304307267049747

Epoch: 6| Step: 5
Training loss: 0.14854634836580435
Validation loss: 2.4272474124067576

Epoch: 6| Step: 6
Training loss: 0.09689220998544502
Validation loss: 2.3975753888854507

Epoch: 6| Step: 7
Training loss: 0.08453270260890137
Validation loss: 2.402483945888123

Epoch: 6| Step: 8
Training loss: 0.11519499283594566
Validation loss: 2.4113976682615132

Epoch: 6| Step: 9
Training loss: 0.07533490241515635
Validation loss: 2.4313347958345433

Epoch: 6| Step: 10
Training loss: 0.09433045104758896
Validation loss: 2.4051164211082323

Epoch: 6| Step: 11
Training loss: 0.06672694801332646
Validation loss: 2.438144492932679

Epoch: 6| Step: 12
Training loss: 0.06356305685076047
Validation loss: 2.416379333008588

Epoch: 6| Step: 13
Training loss: 0.10011001138498259
Validation loss: 2.416111141452229

Epoch: 566| Step: 0
Training loss: 0.13880097732914431
Validation loss: 2.432404689258146

Epoch: 6| Step: 1
Training loss: 0.1089120672853285
Validation loss: 2.412584098953837

Epoch: 6| Step: 2
Training loss: 0.09569686752414976
Validation loss: 2.4186621190389115

Epoch: 6| Step: 3
Training loss: 0.16521144644733307
Validation loss: 2.446904789692167

Epoch: 6| Step: 4
Training loss: 0.11920613692120313
Validation loss: 2.432502103145158

Epoch: 6| Step: 5
Training loss: 0.10391995350385205
Validation loss: 2.467327202739665

Epoch: 6| Step: 6
Training loss: 0.14992027920961526
Validation loss: 2.4455382414484745

Epoch: 6| Step: 7
Training loss: 0.06671388626796358
Validation loss: 2.4540462714304776

Epoch: 6| Step: 8
Training loss: 0.10733581910688042
Validation loss: 2.4315165494360294

Epoch: 6| Step: 9
Training loss: 0.06284827559834161
Validation loss: 2.4536473590898686

Epoch: 6| Step: 10
Training loss: 0.10570881155130409
Validation loss: 2.450867503431696

Epoch: 6| Step: 11
Training loss: 0.10094016394923372
Validation loss: 2.4496857090580892

Epoch: 6| Step: 12
Training loss: 0.0841811254117436
Validation loss: 2.449573190071605

Epoch: 6| Step: 13
Training loss: 0.10292653942179994
Validation loss: 2.42769301399576

Epoch: 567| Step: 0
Training loss: 0.1200012213240004
Validation loss: 2.3985686099838204

Epoch: 6| Step: 1
Training loss: 0.09561795707397305
Validation loss: 2.432794574310563

Epoch: 6| Step: 2
Training loss: 0.08058526945368852
Validation loss: 2.3716292216481483

Epoch: 6| Step: 3
Training loss: 0.09964877172284693
Validation loss: 2.4153818560014386

Epoch: 6| Step: 4
Training loss: 0.10932783404130697
Validation loss: 2.4050034553135125

Epoch: 6| Step: 5
Training loss: 0.17047603175540116
Validation loss: 2.4076862765778326

Epoch: 6| Step: 6
Training loss: 0.14135414739054372
Validation loss: 2.4105741366902618

Epoch: 6| Step: 7
Training loss: 0.09593533546105888
Validation loss: 2.4212709730194812

Epoch: 6| Step: 8
Training loss: 0.08023136874308472
Validation loss: 2.385618832576911

Epoch: 6| Step: 9
Training loss: 0.070775714909422
Validation loss: 2.4204156538974018

Epoch: 6| Step: 10
Training loss: 0.16034814921566792
Validation loss: 2.385439737798306

Epoch: 6| Step: 11
Training loss: 0.0698696135631106
Validation loss: 2.4114537399936786

Epoch: 6| Step: 12
Training loss: 0.1482177538330588
Validation loss: 2.4109152401568346

Epoch: 6| Step: 13
Training loss: 0.11679374984081442
Validation loss: 2.4264471935170753

Epoch: 568| Step: 0
Training loss: 0.10916228983185182
Validation loss: 2.418881120620379

Epoch: 6| Step: 1
Training loss: 0.08823164901014914
Validation loss: 2.4246620890017625

Epoch: 6| Step: 2
Training loss: 0.08455636997570369
Validation loss: 2.4138719808961198

Epoch: 6| Step: 3
Training loss: 0.08014299219387211
Validation loss: 2.4200655923246184

Epoch: 6| Step: 4
Training loss: 0.1456702433037181
Validation loss: 2.4286131984277373

Epoch: 6| Step: 5
Training loss: 0.10941050157673299
Validation loss: 2.4373654227683654

Epoch: 6| Step: 6
Training loss: 0.1509559952913447
Validation loss: 2.4173542219669693

Epoch: 6| Step: 7
Training loss: 0.07318732113962934
Validation loss: 2.414510402165335

Epoch: 6| Step: 8
Training loss: 0.087275167462577
Validation loss: 2.441230107473121

Epoch: 6| Step: 9
Training loss: 0.1296768922374105
Validation loss: 2.4714381758018553

Epoch: 6| Step: 10
Training loss: 0.11726951510707327
Validation loss: 2.4237209413144365

Epoch: 6| Step: 11
Training loss: 0.13750791987455085
Validation loss: 2.414892317200579

Epoch: 6| Step: 12
Training loss: 0.09839013905531666
Validation loss: 2.4236041382140248

Epoch: 6| Step: 13
Training loss: 0.07859103557419204
Validation loss: 2.4470058578573366

Epoch: 569| Step: 0
Training loss: 0.06875615092418541
Validation loss: 2.4436280401944526

Epoch: 6| Step: 1
Training loss: 0.10155300866306495
Validation loss: 2.4027490908333475

Epoch: 6| Step: 2
Training loss: 0.18716801618392137
Validation loss: 2.3783137341997267

Epoch: 6| Step: 3
Training loss: 0.07392109297949719
Validation loss: 2.395485396264196

Epoch: 6| Step: 4
Training loss: 0.0747911378725338
Validation loss: 2.4113082245453596

Epoch: 6| Step: 5
Training loss: 0.09025987888098196
Validation loss: 2.4021121152436975

Epoch: 6| Step: 6
Training loss: 0.05601063760330829
Validation loss: 2.4063294153488672

Epoch: 6| Step: 7
Training loss: 0.07204539015411948
Validation loss: 2.3994142879417684

Epoch: 6| Step: 8
Training loss: 0.07570479926550058
Validation loss: 2.416870644468461

Epoch: 6| Step: 9
Training loss: 0.08410600792227127
Validation loss: 2.398013228482886

Epoch: 6| Step: 10
Training loss: 0.11082977719744651
Validation loss: 2.400459344036885

Epoch: 6| Step: 11
Training loss: 0.1463637936526705
Validation loss: 2.3997888841373753

Epoch: 6| Step: 12
Training loss: 0.0950257649195077
Validation loss: 2.4246426004246486

Epoch: 6| Step: 13
Training loss: 0.04942076094840404
Validation loss: 2.4206241146681964

Epoch: 570| Step: 0
Training loss: 0.06533245434360327
Validation loss: 2.4130616978665866

Epoch: 6| Step: 1
Training loss: 0.06591771090421757
Validation loss: 2.389299701341952

Epoch: 6| Step: 2
Training loss: 0.08674715925658155
Validation loss: 2.4210694941392936

Epoch: 6| Step: 3
Training loss: 0.08536230299039153
Validation loss: 2.43721558494687

Epoch: 6| Step: 4
Training loss: 0.09132284165462666
Validation loss: 2.4057006411258377

Epoch: 6| Step: 5
Training loss: 0.0888499515712431
Validation loss: 2.417539716438175

Epoch: 6| Step: 6
Training loss: 0.1328403149256919
Validation loss: 2.40572224286843

Epoch: 6| Step: 7
Training loss: 0.13359045336933448
Validation loss: 2.391322591310274

Epoch: 6| Step: 8
Training loss: 0.15002505346523565
Validation loss: 2.370419736379674

Epoch: 6| Step: 9
Training loss: 0.1486434887574388
Validation loss: 2.380106709301778

Epoch: 6| Step: 10
Training loss: 0.10121226903554083
Validation loss: 2.4147738836800166

Epoch: 6| Step: 11
Training loss: 0.13026295152180886
Validation loss: 2.429055929951759

Epoch: 6| Step: 12
Training loss: 0.12070394657682539
Validation loss: 2.433730109541826

Epoch: 6| Step: 13
Training loss: 0.05928140686036523
Validation loss: 2.4650231680870918

Epoch: 571| Step: 0
Training loss: 0.09499659834907777
Validation loss: 2.4520714794555505

Epoch: 6| Step: 1
Training loss: 0.15435842300516883
Validation loss: 2.4597278503057245

Epoch: 6| Step: 2
Training loss: 0.06462949766370917
Validation loss: 2.4714510554932505

Epoch: 6| Step: 3
Training loss: 0.09594370808691477
Validation loss: 2.4668730733257918

Epoch: 6| Step: 4
Training loss: 0.07992253073929516
Validation loss: 2.4562372629757587

Epoch: 6| Step: 5
Training loss: 0.12815561074267454
Validation loss: 2.477745811723116

Epoch: 6| Step: 6
Training loss: 0.10900244956041992
Validation loss: 2.4927249544556793

Epoch: 6| Step: 7
Training loss: 0.17343442243990112
Validation loss: 2.4693669682319226

Epoch: 6| Step: 8
Training loss: 0.09076154509778749
Validation loss: 2.4439568733869734

Epoch: 6| Step: 9
Training loss: 0.10373249368732812
Validation loss: 2.419482259266204

Epoch: 6| Step: 10
Training loss: 0.14675302031112358
Validation loss: 2.4335094376660673

Epoch: 6| Step: 11
Training loss: 0.09082199423268644
Validation loss: 2.4306019992658925

Epoch: 6| Step: 12
Training loss: 0.11812512489216373
Validation loss: 2.4135849004994157

Epoch: 6| Step: 13
Training loss: 0.1034114781577172
Validation loss: 2.439370560072104

Epoch: 572| Step: 0
Training loss: 0.09593894670060442
Validation loss: 2.4239039659961437

Epoch: 6| Step: 1
Training loss: 0.07913376305817339
Validation loss: 2.4583582677840226

Epoch: 6| Step: 2
Training loss: 0.12326743400838143
Validation loss: 2.448320207778927

Epoch: 6| Step: 3
Training loss: 0.10692088604672761
Validation loss: 2.392986529854918

Epoch: 6| Step: 4
Training loss: 0.15092258993789678
Validation loss: 2.4437932582820237

Epoch: 6| Step: 5
Training loss: 0.16316354926395954
Validation loss: 2.4485794329156483

Epoch: 6| Step: 6
Training loss: 0.11897471867762742
Validation loss: 2.4262240957120595

Epoch: 6| Step: 7
Training loss: 0.12720486550498653
Validation loss: 2.443582271185452

Epoch: 6| Step: 8
Training loss: 0.13760104909575932
Validation loss: 2.4471691706972147

Epoch: 6| Step: 9
Training loss: 0.13131653938271956
Validation loss: 2.3959185877144225

Epoch: 6| Step: 10
Training loss: 0.11530559569522676
Validation loss: 2.42279182887485

Epoch: 6| Step: 11
Training loss: 0.18916690481551832
Validation loss: 2.3884121452591147

Epoch: 6| Step: 12
Training loss: 0.1503699523787332
Validation loss: 2.416972896946004

Epoch: 6| Step: 13
Training loss: 0.10747086101626108
Validation loss: 2.406922908854721

Epoch: 573| Step: 0
Training loss: 0.17075828800116885
Validation loss: 2.4284242484325973

Epoch: 6| Step: 1
Training loss: 0.1138497916751207
Validation loss: 2.400621943702071

Epoch: 6| Step: 2
Training loss: 0.14768044762919516
Validation loss: 2.4027868844443234

Epoch: 6| Step: 3
Training loss: 0.09645316530397069
Validation loss: 2.4214777138652197

Epoch: 6| Step: 4
Training loss: 0.09601956232935675
Validation loss: 2.4181009950534778

Epoch: 6| Step: 5
Training loss: 0.09098481078242515
Validation loss: 2.3900681260674093

Epoch: 6| Step: 6
Training loss: 0.11842712565759717
Validation loss: 2.407287836229971

Epoch: 6| Step: 7
Training loss: 0.05585504486733624
Validation loss: 2.3988743091306692

Epoch: 6| Step: 8
Training loss: 0.14874909347570497
Validation loss: 2.3855686106215233

Epoch: 6| Step: 9
Training loss: 0.1170858578166562
Validation loss: 2.350927642572905

Epoch: 6| Step: 10
Training loss: 0.11252746048203291
Validation loss: 2.3612405396065266

Epoch: 6| Step: 11
Training loss: 0.0979929983057898
Validation loss: 2.3599176639145876

Epoch: 6| Step: 12
Training loss: 0.10809520459057995
Validation loss: 2.3704216073970645

Epoch: 6| Step: 13
Training loss: 0.18952559038912367
Validation loss: 2.346479358856642

Epoch: 574| Step: 0
Training loss: 0.09357087088917779
Validation loss: 2.3628517790510712

Epoch: 6| Step: 1
Training loss: 0.15279069164695128
Validation loss: 2.3761863638290293

Epoch: 6| Step: 2
Training loss: 0.11996006186788973
Validation loss: 2.379330090664284

Epoch: 6| Step: 3
Training loss: 0.2134398628651423
Validation loss: 2.4150077078332437

Epoch: 6| Step: 4
Training loss: 0.10961495202437008
Validation loss: 2.4590532205790407

Epoch: 6| Step: 5
Training loss: 0.15128412736545144
Validation loss: 2.5033232351047836

Epoch: 6| Step: 6
Training loss: 0.09499767185326094
Validation loss: 2.5072542502724535

Epoch: 6| Step: 7
Training loss: 0.19634029801530964
Validation loss: 2.498348063571268

Epoch: 6| Step: 8
Training loss: 0.09262547992023405
Validation loss: 2.476298848085648

Epoch: 6| Step: 9
Training loss: 0.12945205561415463
Validation loss: 2.4542911063087294

Epoch: 6| Step: 10
Training loss: 0.09271387898899666
Validation loss: 2.481021207795361

Epoch: 6| Step: 11
Training loss: 0.11539637767577043
Validation loss: 2.4464167701843484

Epoch: 6| Step: 12
Training loss: 0.07844692600556157
Validation loss: 2.424287970199889

Epoch: 6| Step: 13
Training loss: 0.10910271488623204
Validation loss: 2.401905471302654

Epoch: 575| Step: 0
Training loss: 0.11439111872215942
Validation loss: 2.405117449179407

Epoch: 6| Step: 1
Training loss: 0.13388613499709623
Validation loss: 2.430692397063098

Epoch: 6| Step: 2
Training loss: 0.10219446133749854
Validation loss: 2.388541625122495

Epoch: 6| Step: 3
Training loss: 0.10606238405741715
Validation loss: 2.4132548336880135

Epoch: 6| Step: 4
Training loss: 0.14794733027395454
Validation loss: 2.3768430304106176

Epoch: 6| Step: 5
Training loss: 0.05059600936010619
Validation loss: 2.378257065461114

Epoch: 6| Step: 6
Training loss: 0.07391705178003147
Validation loss: 2.413059604934505

Epoch: 6| Step: 7
Training loss: 0.08785080537516411
Validation loss: 2.424621238091262

Epoch: 6| Step: 8
Training loss: 0.14811384528245589
Validation loss: 2.4663801666101555

Epoch: 6| Step: 9
Training loss: 0.14265210048494242
Validation loss: 2.4719206560125424

Epoch: 6| Step: 10
Training loss: 0.08841108821609774
Validation loss: 2.47472927203423

Epoch: 6| Step: 11
Training loss: 0.12222770462404679
Validation loss: 2.3936286591144844

Epoch: 6| Step: 12
Training loss: 0.09220213410233404
Validation loss: 2.4018676032502775

Epoch: 6| Step: 13
Training loss: 0.17112222460689788
Validation loss: 2.4020228151127214

Epoch: 576| Step: 0
Training loss: 0.04971150488666794
Validation loss: 2.3934394600937976

Epoch: 6| Step: 1
Training loss: 0.11698765005569177
Validation loss: 2.3857927174194686

Epoch: 6| Step: 2
Training loss: 0.11194684611972544
Validation loss: 2.3633195771421667

Epoch: 6| Step: 3
Training loss: 0.12667391958876997
Validation loss: 2.399047623782112

Epoch: 6| Step: 4
Training loss: 0.10232437001257381
Validation loss: 2.390809054939845

Epoch: 6| Step: 5
Training loss: 0.11968367354473981
Validation loss: 2.390100484721251

Epoch: 6| Step: 6
Training loss: 0.06723541572189977
Validation loss: 2.377400817430939

Epoch: 6| Step: 7
Training loss: 0.14727484727309906
Validation loss: 2.3972333556418586

Epoch: 6| Step: 8
Training loss: 0.11744991961235277
Validation loss: 2.4148103940205368

Epoch: 6| Step: 9
Training loss: 0.0851129563983816
Validation loss: 2.3945113863782983

Epoch: 6| Step: 10
Training loss: 0.1389903052588896
Validation loss: 2.4507692122738205

Epoch: 6| Step: 11
Training loss: 0.12838839056144216
Validation loss: 2.436521780329249

Epoch: 6| Step: 12
Training loss: 0.10805422456559562
Validation loss: 2.430159435739638

Epoch: 6| Step: 13
Training loss: 0.12221669384917346
Validation loss: 2.421149195302339

Epoch: 577| Step: 0
Training loss: 0.08252231886630178
Validation loss: 2.4130664924802945

Epoch: 6| Step: 1
Training loss: 0.05628137276544478
Validation loss: 2.409928841006477

Epoch: 6| Step: 2
Training loss: 0.14166036897456882
Validation loss: 2.4018357999223556

Epoch: 6| Step: 3
Training loss: 0.05173073366151053
Validation loss: 2.4002914464959844

Epoch: 6| Step: 4
Training loss: 0.14039453854463585
Validation loss: 2.388255737816343

Epoch: 6| Step: 5
Training loss: 0.1543778255431866
Validation loss: 2.375121146470944

Epoch: 6| Step: 6
Training loss: 0.10775378708645274
Validation loss: 2.3859988593542902

Epoch: 6| Step: 7
Training loss: 0.17020725533164663
Validation loss: 2.420493866257414

Epoch: 6| Step: 8
Training loss: 0.1631246109753205
Validation loss: 2.4076935170270053

Epoch: 6| Step: 9
Training loss: 0.06616065949262516
Validation loss: 2.38382736211382

Epoch: 6| Step: 10
Training loss: 0.12695758518306954
Validation loss: 2.4067845027235815

Epoch: 6| Step: 11
Training loss: 0.08179971398543158
Validation loss: 2.401620323518413

Epoch: 6| Step: 12
Training loss: 0.11672885470587209
Validation loss: 2.450275220306789

Epoch: 6| Step: 13
Training loss: 0.11727663067935486
Validation loss: 2.449731209153064

Epoch: 578| Step: 0
Training loss: 0.1662880737583551
Validation loss: 2.4418663565938306

Epoch: 6| Step: 1
Training loss: 0.15793511565582052
Validation loss: 2.453148138364176

Epoch: 6| Step: 2
Training loss: 0.09131768125303283
Validation loss: 2.3921022898218878

Epoch: 6| Step: 3
Training loss: 0.1009806508577666
Validation loss: 2.4151152920147543

Epoch: 6| Step: 4
Training loss: 0.1373732635698096
Validation loss: 2.437007143242494

Epoch: 6| Step: 5
Training loss: 0.07611675591254935
Validation loss: 2.4266890426877703

Epoch: 6| Step: 6
Training loss: 0.08364450916793618
Validation loss: 2.4610787643617034

Epoch: 6| Step: 7
Training loss: 0.1035251658019507
Validation loss: 2.4315064404209314

Epoch: 6| Step: 8
Training loss: 0.08524017922615298
Validation loss: 2.4474234877284933

Epoch: 6| Step: 9
Training loss: 0.07336903078925792
Validation loss: 2.426275567438327

Epoch: 6| Step: 10
Training loss: 0.1158360436806231
Validation loss: 2.4087720028279493

Epoch: 6| Step: 11
Training loss: 0.10491974871079378
Validation loss: 2.4309058570299094

Epoch: 6| Step: 12
Training loss: 0.1147607712793713
Validation loss: 2.405980958508662

Epoch: 6| Step: 13
Training loss: 0.15370501709215834
Validation loss: 2.4214409001504817

Epoch: 579| Step: 0
Training loss: 0.15535920851137536
Validation loss: 2.3871148199728527

Epoch: 6| Step: 1
Training loss: 0.07545255034988815
Validation loss: 2.405818968257088

Epoch: 6| Step: 2
Training loss: 0.08504694936694052
Validation loss: 2.4051410819043357

Epoch: 6| Step: 3
Training loss: 0.14500729030747142
Validation loss: 2.3836086041369304

Epoch: 6| Step: 4
Training loss: 0.0828311386366127
Validation loss: 2.376110541557598

Epoch: 6| Step: 5
Training loss: 0.10570194813255747
Validation loss: 2.4181937045595014

Epoch: 6| Step: 6
Training loss: 0.145298660296068
Validation loss: 2.4069817736376145

Epoch: 6| Step: 7
Training loss: 0.10578657758079155
Validation loss: 2.3932657880515347

Epoch: 6| Step: 8
Training loss: 0.0916777507445757
Validation loss: 2.408550835656474

Epoch: 6| Step: 9
Training loss: 0.14932960416997837
Validation loss: 2.452601486474027

Epoch: 6| Step: 10
Training loss: 0.08011307186415734
Validation loss: 2.446749188647997

Epoch: 6| Step: 11
Training loss: 0.1690080559266377
Validation loss: 2.43895471042276

Epoch: 6| Step: 12
Training loss: 0.0826664637887504
Validation loss: 2.4492078431772013

Epoch: 6| Step: 13
Training loss: 0.08519606556268788
Validation loss: 2.45242694249646

Epoch: 580| Step: 0
Training loss: 0.10213067609661808
Validation loss: 2.4510058813657754

Epoch: 6| Step: 1
Training loss: 0.06463033705113513
Validation loss: 2.4272849819412206

Epoch: 6| Step: 2
Training loss: 0.11996266264747929
Validation loss: 2.4374798715253085

Epoch: 6| Step: 3
Training loss: 0.06912013170446449
Validation loss: 2.3765730190301175

Epoch: 6| Step: 4
Training loss: 0.09577965109643397
Validation loss: 2.407328277357918

Epoch: 6| Step: 5
Training loss: 0.08261878347997134
Validation loss: 2.3941432836182592

Epoch: 6| Step: 6
Training loss: 0.17284697187114462
Validation loss: 2.3706974743721103

Epoch: 6| Step: 7
Training loss: 0.15176391294729819
Validation loss: 2.3738238153704696

Epoch: 6| Step: 8
Training loss: 0.08013755349308592
Validation loss: 2.434114685803915

Epoch: 6| Step: 9
Training loss: 0.12892613113140866
Validation loss: 2.454286079907689

Epoch: 6| Step: 10
Training loss: 0.08645082908210612
Validation loss: 2.446207227151297

Epoch: 6| Step: 11
Training loss: 0.16257472635517733
Validation loss: 2.4465587650443075

Epoch: 6| Step: 12
Training loss: 0.10829593348338075
Validation loss: 2.432521038162789

Epoch: 6| Step: 13
Training loss: 0.08036016306471248
Validation loss: 2.4292835814783778

Epoch: 581| Step: 0
Training loss: 0.0834166946796144
Validation loss: 2.413613949647759

Epoch: 6| Step: 1
Training loss: 0.1333441890703066
Validation loss: 2.391731914779172

Epoch: 6| Step: 2
Training loss: 0.08549076977429
Validation loss: 2.4082129177296965

Epoch: 6| Step: 3
Training loss: 0.1349174156070493
Validation loss: 2.3494029307268214

Epoch: 6| Step: 4
Training loss: 0.11369877772180666
Validation loss: 2.3630669321965776

Epoch: 6| Step: 5
Training loss: 0.1846096461129024
Validation loss: 2.3507484392713516

Epoch: 6| Step: 6
Training loss: 0.15395749468590045
Validation loss: 2.3726231869152166

Epoch: 6| Step: 7
Training loss: 0.11331388398075916
Validation loss: 2.36241998805567

Epoch: 6| Step: 8
Training loss: 0.1288901954825925
Validation loss: 2.377800678824228

Epoch: 6| Step: 9
Training loss: 0.10413854239199322
Validation loss: 2.4047287989624913

Epoch: 6| Step: 10
Training loss: 0.16120552965304286
Validation loss: 2.3853261864153184

Epoch: 6| Step: 11
Training loss: 0.11836754405595082
Validation loss: 2.4091990979162063

Epoch: 6| Step: 12
Training loss: 0.09001012614358951
Validation loss: 2.4386393237927155

Epoch: 6| Step: 13
Training loss: 0.06312639781376833
Validation loss: 2.425246527619241

Epoch: 582| Step: 0
Training loss: 0.08610752203689763
Validation loss: 2.431368735170655

Epoch: 6| Step: 1
Training loss: 0.06640043653959019
Validation loss: 2.4130979616106925

Epoch: 6| Step: 2
Training loss: 0.09922755213614083
Validation loss: 2.438977797172251

Epoch: 6| Step: 3
Training loss: 0.13952663418267872
Validation loss: 2.4629782345207416

Epoch: 6| Step: 4
Training loss: 0.10826768808082471
Validation loss: 2.4527933233402845

Epoch: 6| Step: 5
Training loss: 0.08879619948992588
Validation loss: 2.497714983686972

Epoch: 6| Step: 6
Training loss: 0.10169749733039597
Validation loss: 2.4801610219465333

Epoch: 6| Step: 7
Training loss: 0.10552471936379942
Validation loss: 2.4554431016905993

Epoch: 6| Step: 8
Training loss: 0.1705098666562228
Validation loss: 2.481164413955292

Epoch: 6| Step: 9
Training loss: 0.18419973318938027
Validation loss: 2.469298607465761

Epoch: 6| Step: 10
Training loss: 0.0951731957535137
Validation loss: 2.438633467223853

Epoch: 6| Step: 11
Training loss: 0.1534063255898901
Validation loss: 2.459655140090495

Epoch: 6| Step: 12
Training loss: 0.11866250799151525
Validation loss: 2.419628232459962

Epoch: 6| Step: 13
Training loss: 0.1363111550991941
Validation loss: 2.423062197417763

Epoch: 583| Step: 0
Training loss: 0.08911750458515214
Validation loss: 2.4189068810915964

Epoch: 6| Step: 1
Training loss: 0.2069962129995143
Validation loss: 2.3936995161330947

Epoch: 6| Step: 2
Training loss: 0.09691847587047796
Validation loss: 2.3672605151496997

Epoch: 6| Step: 3
Training loss: 0.13047579871912823
Validation loss: 2.391360541923337

Epoch: 6| Step: 4
Training loss: 0.07477252557653001
Validation loss: 2.4104443465659795

Epoch: 6| Step: 5
Training loss: 0.08914152704930903
Validation loss: 2.3874080470809584

Epoch: 6| Step: 6
Training loss: 0.11616540064725006
Validation loss: 2.3666239710421024

Epoch: 6| Step: 7
Training loss: 0.08654469321531641
Validation loss: 2.4125385613526076

Epoch: 6| Step: 8
Training loss: 0.18007675799266762
Validation loss: 2.3864043020430685

Epoch: 6| Step: 9
Training loss: 0.09561137258129533
Validation loss: 2.4040335675329243

Epoch: 6| Step: 10
Training loss: 0.08574453276813501
Validation loss: 2.4196913280771106

Epoch: 6| Step: 11
Training loss: 0.13301053429506088
Validation loss: 2.4453373823564584

Epoch: 6| Step: 12
Training loss: 0.07479532173230156
Validation loss: 2.4237632363666055

Epoch: 6| Step: 13
Training loss: 0.0981700873433027
Validation loss: 2.4243365863850364

Epoch: 584| Step: 0
Training loss: 0.1033217035210758
Validation loss: 2.413687875811203

Epoch: 6| Step: 1
Training loss: 0.16377118905399274
Validation loss: 2.4232353473270174

Epoch: 6| Step: 2
Training loss: 0.14432486412921447
Validation loss: 2.388385188590694

Epoch: 6| Step: 3
Training loss: 0.133479177132871
Validation loss: 2.3810259855044467

Epoch: 6| Step: 4
Training loss: 0.13207673581560594
Validation loss: 2.3937793232212456

Epoch: 6| Step: 5
Training loss: 0.08740040974102226
Validation loss: 2.4032565939955175

Epoch: 6| Step: 6
Training loss: 0.10140529717348928
Validation loss: 2.3888775007328316

Epoch: 6| Step: 7
Training loss: 0.09369943168896791
Validation loss: 2.4171674766050306

Epoch: 6| Step: 8
Training loss: 0.1364091842593579
Validation loss: 2.4130190686253963

Epoch: 6| Step: 9
Training loss: 0.11525486909341
Validation loss: 2.4159147099061062

Epoch: 6| Step: 10
Training loss: 0.17298327562459861
Validation loss: 2.4122452432801804

Epoch: 6| Step: 11
Training loss: 0.11333608944196975
Validation loss: 2.4039053209531174

Epoch: 6| Step: 12
Training loss: 0.11166950220747245
Validation loss: 2.39935839803542

Epoch: 6| Step: 13
Training loss: 0.1350481485781012
Validation loss: 2.379924081248325

Epoch: 585| Step: 0
Training loss: 0.17892781631549964
Validation loss: 2.3931924554529007

Epoch: 6| Step: 1
Training loss: 0.10514527624950266
Validation loss: 2.388784018342928

Epoch: 6| Step: 2
Training loss: 0.07539987606154129
Validation loss: 2.3845880583461008

Epoch: 6| Step: 3
Training loss: 0.11453712590121214
Validation loss: 2.368928654301355

Epoch: 6| Step: 4
Training loss: 0.08682368969911647
Validation loss: 2.3507518303763604

Epoch: 6| Step: 5
Training loss: 0.1323388573689083
Validation loss: 2.3603701232446217

Epoch: 6| Step: 6
Training loss: 0.08183663420278196
Validation loss: 2.4076218260377136

Epoch: 6| Step: 7
Training loss: 0.08924455481635928
Validation loss: 2.433299462670852

Epoch: 6| Step: 8
Training loss: 0.07938176142718763
Validation loss: 2.414880086519175

Epoch: 6| Step: 9
Training loss: 0.14581552393909297
Validation loss: 2.4425955940389223

Epoch: 6| Step: 10
Training loss: 0.08457241342062569
Validation loss: 2.4195512646406048

Epoch: 6| Step: 11
Training loss: 0.07139512885320964
Validation loss: 2.421902712829794

Epoch: 6| Step: 12
Training loss: 0.08978279782828846
Validation loss: 2.437910225811136

Epoch: 6| Step: 13
Training loss: 0.10157328786776605
Validation loss: 2.4468857066723406

Epoch: 586| Step: 0
Training loss: 0.09876156891585619
Validation loss: 2.4310446419881777

Epoch: 6| Step: 1
Training loss: 0.09206899930901968
Validation loss: 2.4412348761676905

Epoch: 6| Step: 2
Training loss: 0.18544504483363508
Validation loss: 2.415054469522633

Epoch: 6| Step: 3
Training loss: 0.11654603153383314
Validation loss: 2.411666108131266

Epoch: 6| Step: 4
Training loss: 0.12608235375052607
Validation loss: 2.4550343801638523

Epoch: 6| Step: 5
Training loss: 0.07320074816481702
Validation loss: 2.4216216299823285

Epoch: 6| Step: 6
Training loss: 0.07484120120226077
Validation loss: 2.437762317578098

Epoch: 6| Step: 7
Training loss: 0.08096412402144292
Validation loss: 2.422554945856877

Epoch: 6| Step: 8
Training loss: 0.14754991183942426
Validation loss: 2.4203349445739977

Epoch: 6| Step: 9
Training loss: 0.0623330161736484
Validation loss: 2.4340145832456415

Epoch: 6| Step: 10
Training loss: 0.11743844502298721
Validation loss: 2.4281703587293224

Epoch: 6| Step: 11
Training loss: 0.08042388795060713
Validation loss: 2.377458456032364

Epoch: 6| Step: 12
Training loss: 0.11341146680070543
Validation loss: 2.4224004899823717

Epoch: 6| Step: 13
Training loss: 0.18507881356043202
Validation loss: 2.4138016302765615

Epoch: 587| Step: 0
Training loss: 0.0974386795635042
Validation loss: 2.414930727570737

Epoch: 6| Step: 1
Training loss: 0.0990802934608134
Validation loss: 2.4290916520220036

Epoch: 6| Step: 2
Training loss: 0.1463883975634462
Validation loss: 2.4229203005070516

Epoch: 6| Step: 3
Training loss: 0.10140121932401708
Validation loss: 2.4132327448381545

Epoch: 6| Step: 4
Training loss: 0.09684020501966825
Validation loss: 2.4376678682447266

Epoch: 6| Step: 5
Training loss: 0.14849348016516326
Validation loss: 2.4222829347482047

Epoch: 6| Step: 6
Training loss: 0.12047911600620542
Validation loss: 2.3864851609157207

Epoch: 6| Step: 7
Training loss: 0.07902887324722213
Validation loss: 2.395053211303282

Epoch: 6| Step: 8
Training loss: 0.10071606228148289
Validation loss: 2.4177993698389284

Epoch: 6| Step: 9
Training loss: 0.10913974290571869
Validation loss: 2.4341137052626425

Epoch: 6| Step: 10
Training loss: 0.13933743344790706
Validation loss: 2.4294961936373047

Epoch: 6| Step: 11
Training loss: 0.11090870537274254
Validation loss: 2.4364630820881628

Epoch: 6| Step: 12
Training loss: 0.15155329184727984
Validation loss: 2.448871166908266

Epoch: 6| Step: 13
Training loss: 0.06519628643476373
Validation loss: 2.458281382127724

Epoch: 588| Step: 0
Training loss: 0.1256528806469473
Validation loss: 2.4451235005186973

Epoch: 6| Step: 1
Training loss: 0.20838086162267908
Validation loss: 2.468955431618305

Epoch: 6| Step: 2
Training loss: 0.16582824005120086
Validation loss: 2.4552209972303314

Epoch: 6| Step: 3
Training loss: 0.08940988978377426
Validation loss: 2.4325747660590844

Epoch: 6| Step: 4
Training loss: 0.12348359430378382
Validation loss: 2.4052466692706562

Epoch: 6| Step: 5
Training loss: 0.1004508138637887
Validation loss: 2.3984337150947637

Epoch: 6| Step: 6
Training loss: 0.08984723291694988
Validation loss: 2.406343182071461

Epoch: 6| Step: 7
Training loss: 0.09179139120888442
Validation loss: 2.392833433075979

Epoch: 6| Step: 8
Training loss: 0.09549504645280404
Validation loss: 2.4095420015447306

Epoch: 6| Step: 9
Training loss: 0.11670907030859717
Validation loss: 2.41806821489159

Epoch: 6| Step: 10
Training loss: 0.10968809359273028
Validation loss: 2.399669929550117

Epoch: 6| Step: 11
Training loss: 0.1705239525373569
Validation loss: 2.4165502279007747

Epoch: 6| Step: 12
Training loss: 0.09276242441763637
Validation loss: 2.44503446799829

Epoch: 6| Step: 13
Training loss: 0.07515310366145384
Validation loss: 2.440084202910713

Epoch: 589| Step: 0
Training loss: 0.12368594078181834
Validation loss: 2.454507965550874

Epoch: 6| Step: 1
Training loss: 0.10200631847691322
Validation loss: 2.455015343628007

Epoch: 6| Step: 2
Training loss: 0.1292893612110353
Validation loss: 2.4679910155873865

Epoch: 6| Step: 3
Training loss: 0.15602592852575495
Validation loss: 2.4965105617864296

Epoch: 6| Step: 4
Training loss: 0.09402498011795499
Validation loss: 2.4888527147746258

Epoch: 6| Step: 5
Training loss: 0.127907641891858
Validation loss: 2.459256232713522

Epoch: 6| Step: 6
Training loss: 0.09929863293409995
Validation loss: 2.4059605237214603

Epoch: 6| Step: 7
Training loss: 0.14634765602599537
Validation loss: 2.4100839206430544

Epoch: 6| Step: 8
Training loss: 0.16567963090533094
Validation loss: 2.416247436163205

Epoch: 6| Step: 9
Training loss: 0.1209120425394298
Validation loss: 2.379530057278085

Epoch: 6| Step: 10
Training loss: 0.1538969240412885
Validation loss: 2.3698298813043035

Epoch: 6| Step: 11
Training loss: 0.16595189049206555
Validation loss: 2.3920592508891536

Epoch: 6| Step: 12
Training loss: 0.11738466524766088
Validation loss: 2.398088859617115

Epoch: 6| Step: 13
Training loss: 0.1453578547484642
Validation loss: 2.4111877256260996

Epoch: 590| Step: 0
Training loss: 0.10617410599902767
Validation loss: 2.424242836716873

Epoch: 6| Step: 1
Training loss: 0.14440540686070022
Validation loss: 2.4704093712108

Epoch: 6| Step: 2
Training loss: 0.10386017372922657
Validation loss: 2.4776319484537073

Epoch: 6| Step: 3
Training loss: 0.11833988460421073
Validation loss: 2.4919860184401266

Epoch: 6| Step: 4
Training loss: 0.13718628641690986
Validation loss: 2.486881341584927

Epoch: 6| Step: 5
Training loss: 0.16090448559393586
Validation loss: 2.4333795470893547

Epoch: 6| Step: 6
Training loss: 0.15136228368875854
Validation loss: 2.405653935259542

Epoch: 6| Step: 7
Training loss: 0.13197452184225944
Validation loss: 2.410125637027888

Epoch: 6| Step: 8
Training loss: 0.15412729336160816
Validation loss: 2.3564709994059574

Epoch: 6| Step: 9
Training loss: 0.13122215089072412
Validation loss: 2.3437518868387484

Epoch: 6| Step: 10
Training loss: 0.2723933994167456
Validation loss: 2.2991990924206296

Epoch: 6| Step: 11
Training loss: 0.17842746619558858
Validation loss: 2.3318145712302543

Epoch: 6| Step: 12
Training loss: 0.13660041592612832
Validation loss: 2.340463087710451

Epoch: 6| Step: 13
Training loss: 0.13358591486168062
Validation loss: 2.3976654480783663

Epoch: 591| Step: 0
Training loss: 0.1376034991916906
Validation loss: 2.4409355498028744

Epoch: 6| Step: 1
Training loss: 0.17753798775090568
Validation loss: 2.4335924816600687

Epoch: 6| Step: 2
Training loss: 0.18796661053880384
Validation loss: 2.4848169000977394

Epoch: 6| Step: 3
Training loss: 0.1763144195547481
Validation loss: 2.482754974286335

Epoch: 6| Step: 4
Training loss: 0.17056665093559345
Validation loss: 2.4648503742759877

Epoch: 6| Step: 5
Training loss: 0.21988914408795332
Validation loss: 2.4696775858668554

Epoch: 6| Step: 6
Training loss: 0.15116851443121224
Validation loss: 2.4746256356557694

Epoch: 6| Step: 7
Training loss: 0.12917781891926247
Validation loss: 2.487714029030414

Epoch: 6| Step: 8
Training loss: 0.12359677161563273
Validation loss: 2.419518817758934

Epoch: 6| Step: 9
Training loss: 0.1969736223097843
Validation loss: 2.3903409802708717

Epoch: 6| Step: 10
Training loss: 0.1823539468550457
Validation loss: 2.4013145437103622

Epoch: 6| Step: 11
Training loss: 0.20320473536491646
Validation loss: 2.4120717380870995

Epoch: 6| Step: 12
Training loss: 0.12836741768778784
Validation loss: 2.418031785017982

Epoch: 6| Step: 13
Training loss: 0.14585655458948701
Validation loss: 2.4148761500971236

Epoch: 592| Step: 0
Training loss: 0.09118000706850449
Validation loss: 2.416041299303837

Epoch: 6| Step: 1
Training loss: 0.07928513782999246
Validation loss: 2.4533650009334904

Epoch: 6| Step: 2
Training loss: 0.15585958461699576
Validation loss: 2.4502721882248837

Epoch: 6| Step: 3
Training loss: 0.22440370182194355
Validation loss: 2.4638293298516833

Epoch: 6| Step: 4
Training loss: 0.23272101601800702
Validation loss: 2.4203496802452036

Epoch: 6| Step: 5
Training loss: 0.15732638229123236
Validation loss: 2.426171830662514

Epoch: 6| Step: 6
Training loss: 0.13537674018775203
Validation loss: 2.377075089722047

Epoch: 6| Step: 7
Training loss: 0.11382909369858318
Validation loss: 2.3808920095556942

Epoch: 6| Step: 8
Training loss: 0.11168385440862309
Validation loss: 2.3781955681951055

Epoch: 6| Step: 9
Training loss: 0.17246342848364504
Validation loss: 2.4038337606768456

Epoch: 6| Step: 10
Training loss: 0.16766556834787177
Validation loss: 2.3783054611212777

Epoch: 6| Step: 11
Training loss: 0.26082554031395816
Validation loss: 2.3969526639266414

Epoch: 6| Step: 12
Training loss: 0.15769392648408606
Validation loss: 2.4073876178258673

Epoch: 6| Step: 13
Training loss: 0.12091701053688904
Validation loss: 2.437211930738232

Epoch: 593| Step: 0
Training loss: 0.13399807412316844
Validation loss: 2.4919926394922065

Epoch: 6| Step: 1
Training loss: 0.15428407833295454
Validation loss: 2.4823109101173833

Epoch: 6| Step: 2
Training loss: 0.13246115324227242
Validation loss: 2.5069462964385867

Epoch: 6| Step: 3
Training loss: 0.09167816724845489
Validation loss: 2.4833475873821196

Epoch: 6| Step: 4
Training loss: 0.16821690459092214
Validation loss: 2.517019292198492

Epoch: 6| Step: 5
Training loss: 0.2068245863929144
Validation loss: 2.480189149714356

Epoch: 6| Step: 6
Training loss: 0.2824822162204074
Validation loss: 2.5063137374996134

Epoch: 6| Step: 7
Training loss: 0.12454114080132787
Validation loss: 2.4662667565015886

Epoch: 6| Step: 8
Training loss: 0.1298600800777017
Validation loss: 2.4614696379857244

Epoch: 6| Step: 9
Training loss: 0.12288645095793592
Validation loss: 2.4464002423886027

Epoch: 6| Step: 10
Training loss: 0.22490510959556084
Validation loss: 2.4296461875443933

Epoch: 6| Step: 11
Training loss: 0.17433309608723535
Validation loss: 2.394378880486495

Epoch: 6| Step: 12
Training loss: 0.14894125185797938
Validation loss: 2.3878265425994374

Epoch: 6| Step: 13
Training loss: 0.1617123095754903
Validation loss: 2.4274325305530855

Epoch: 594| Step: 0
Training loss: 0.18677914652183256
Validation loss: 2.404867157638156

Epoch: 6| Step: 1
Training loss: 0.19363290532402136
Validation loss: 2.431969266710193

Epoch: 6| Step: 2
Training loss: 0.1173973072959968
Validation loss: 2.3881607357321912

Epoch: 6| Step: 3
Training loss: 0.2591371031261075
Validation loss: 2.3773882828019075

Epoch: 6| Step: 4
Training loss: 0.1212296338772439
Validation loss: 2.3849672878570223

Epoch: 6| Step: 5
Training loss: 0.13888750638538627
Validation loss: 2.430441454090634

Epoch: 6| Step: 6
Training loss: 0.16488462479206997
Validation loss: 2.376861294115685

Epoch: 6| Step: 7
Training loss: 0.12636332321744118
Validation loss: 2.3652990354076637

Epoch: 6| Step: 8
Training loss: 0.1954159462684361
Validation loss: 2.33981214806667

Epoch: 6| Step: 9
Training loss: 0.11965381596526217
Validation loss: 2.3488235218487343

Epoch: 6| Step: 10
Training loss: 0.1350698492582913
Validation loss: 2.35764939344403

Epoch: 6| Step: 11
Training loss: 0.11137272961814519
Validation loss: 2.344640744941678

Epoch: 6| Step: 12
Training loss: 0.15209445362935473
Validation loss: 2.361439744114876

Epoch: 6| Step: 13
Training loss: 0.0896108916452798
Validation loss: 2.359177302223196

Epoch: 595| Step: 0
Training loss: 0.2077162135930484
Validation loss: 2.3626275318033962

Epoch: 6| Step: 1
Training loss: 0.2051546226605432
Validation loss: 2.3711642900695487

Epoch: 6| Step: 2
Training loss: 0.18245850262725158
Validation loss: 2.388504314501288

Epoch: 6| Step: 3
Training loss: 0.18227151804789699
Validation loss: 2.394381715675378

Epoch: 6| Step: 4
Training loss: 0.12622223784880549
Validation loss: 2.400858638927755

Epoch: 6| Step: 5
Training loss: 0.12348477086193566
Validation loss: 2.394250613586619

Epoch: 6| Step: 6
Training loss: 0.20803544483307695
Validation loss: 2.437646078439636

Epoch: 6| Step: 7
Training loss: 0.16018730537032122
Validation loss: 2.37618934048111

Epoch: 6| Step: 8
Training loss: 0.09076368453325001
Validation loss: 2.3745641367791497

Epoch: 6| Step: 9
Training loss: 0.17982684827406534
Validation loss: 2.3523164782609296

Epoch: 6| Step: 10
Training loss: 0.12335627877503297
Validation loss: 2.356783689007086

Epoch: 6| Step: 11
Training loss: 0.17425011194313098
Validation loss: 2.341245655116905

Epoch: 6| Step: 12
Training loss: 0.1633041543729681
Validation loss: 2.346008416981659

Epoch: 6| Step: 13
Training loss: 0.15445808849357331
Validation loss: 2.3075283544595893

Epoch: 596| Step: 0
Training loss: 0.1514254181128214
Validation loss: 2.359703922793675

Epoch: 6| Step: 1
Training loss: 0.10563503508327579
Validation loss: 2.3557279308117667

Epoch: 6| Step: 2
Training loss: 0.08966123659939493
Validation loss: 2.377495155000441

Epoch: 6| Step: 3
Training loss: 0.18171129595162192
Validation loss: 2.3774714086740185

Epoch: 6| Step: 4
Training loss: 0.17528000467544594
Validation loss: 2.4018414526921363

Epoch: 6| Step: 5
Training loss: 0.14867309645984406
Validation loss: 2.4106342974864234

Epoch: 6| Step: 6
Training loss: 0.09961080550120281
Validation loss: 2.4124245722521422

Epoch: 6| Step: 7
Training loss: 0.22233759514338067
Validation loss: 2.4224231153977054

Epoch: 6| Step: 8
Training loss: 0.27758016047119277
Validation loss: 2.448172432640356

Epoch: 6| Step: 9
Training loss: 0.11156605091774986
Validation loss: 2.4207424737755057

Epoch: 6| Step: 10
Training loss: 0.1574512854144321
Validation loss: 2.418273862000619

Epoch: 6| Step: 11
Training loss: 0.0606331690988031
Validation loss: 2.3883282892070157

Epoch: 6| Step: 12
Training loss: 0.1048492809590596
Validation loss: 2.3467708816395003

Epoch: 6| Step: 13
Training loss: 0.2768581060590049
Validation loss: 2.3244968776307506

Epoch: 597| Step: 0
Training loss: 0.1615783773253717
Validation loss: 2.3704756997098566

Epoch: 6| Step: 1
Training loss: 0.18027094780389902
Validation loss: 2.3551028752535226

Epoch: 6| Step: 2
Training loss: 0.1756340470138921
Validation loss: 2.3873847676770166

Epoch: 6| Step: 3
Training loss: 0.08495216214692211
Validation loss: 2.3961135461415726

Epoch: 6| Step: 4
Training loss: 0.15760206908712507
Validation loss: 2.4128668848560793

Epoch: 6| Step: 5
Training loss: 0.15825427370568051
Validation loss: 2.3935978872433874

Epoch: 6| Step: 6
Training loss: 0.09631975199437075
Validation loss: 2.3842760572399153

Epoch: 6| Step: 7
Training loss: 0.157524726531314
Validation loss: 2.376212413993529

Epoch: 6| Step: 8
Training loss: 0.18568377213024634
Validation loss: 2.360863274683468

Epoch: 6| Step: 9
Training loss: 0.1446967144353378
Validation loss: 2.356144622368227

Epoch: 6| Step: 10
Training loss: 0.19947390018180974
Validation loss: 2.3791972357414584

Epoch: 6| Step: 11
Training loss: 0.224075262831466
Validation loss: 2.3469531435014006

Epoch: 6| Step: 12
Training loss: 0.18089856573836316
Validation loss: 2.387163192850601

Epoch: 6| Step: 13
Training loss: 0.08930900282783424
Validation loss: 2.3028096174539967

Epoch: 598| Step: 0
Training loss: 0.16606322335447124
Validation loss: 2.3608723662899678

Epoch: 6| Step: 1
Training loss: 0.2734342438640181
Validation loss: 2.381997993865695

Epoch: 6| Step: 2
Training loss: 0.16411532959263447
Validation loss: 2.3572651764062225

Epoch: 6| Step: 3
Training loss: 0.18962079916332486
Validation loss: 2.392876473350991

Epoch: 6| Step: 4
Training loss: 0.1475491733434634
Validation loss: 2.39949466459541

Epoch: 6| Step: 5
Training loss: 0.13491318405778138
Validation loss: 2.403132526181042

Epoch: 6| Step: 6
Training loss: 0.16680004822618258
Validation loss: 2.4029898866301824

Epoch: 6| Step: 7
Training loss: 0.11308629014482346
Validation loss: 2.401399508128987

Epoch: 6| Step: 8
Training loss: 0.20711376237341228
Validation loss: 2.415455512205486

Epoch: 6| Step: 9
Training loss: 0.15773617154402453
Validation loss: 2.4108601671670096

Epoch: 6| Step: 10
Training loss: 0.2262650131676732
Validation loss: 2.3784280064529413

Epoch: 6| Step: 11
Training loss: 0.1949587288305102
Validation loss: 2.3632325971085786

Epoch: 6| Step: 12
Training loss: 0.14460958471545773
Validation loss: 2.343760642297572

Epoch: 6| Step: 13
Training loss: 0.05187805172549863
Validation loss: 2.3058631002407

Epoch: 599| Step: 0
Training loss: 0.11251029391347252
Validation loss: 2.3045996619842604

Epoch: 6| Step: 1
Training loss: 0.11415672313399992
Validation loss: 2.320895282612782

Epoch: 6| Step: 2
Training loss: 0.13839170871864606
Validation loss: 2.321403078355964

Epoch: 6| Step: 3
Training loss: 0.18583902147344708
Validation loss: 2.3785548373317256

Epoch: 6| Step: 4
Training loss: 0.1240743397460901
Validation loss: 2.3850738612947686

Epoch: 6| Step: 5
Training loss: 0.1398116538440404
Validation loss: 2.416820556937444

Epoch: 6| Step: 6
Training loss: 0.145418344424697
Validation loss: 2.438439519699743

Epoch: 6| Step: 7
Training loss: 0.11505952598027054
Validation loss: 2.4851141482947674

Epoch: 6| Step: 8
Training loss: 0.2110656596199464
Validation loss: 2.4636025047391104

Epoch: 6| Step: 9
Training loss: 0.15123546775843213
Validation loss: 2.469474288512352

Epoch: 6| Step: 10
Training loss: 0.15687670789412056
Validation loss: 2.482326231119803

Epoch: 6| Step: 11
Training loss: 0.13576189076524292
Validation loss: 2.4438177490830246

Epoch: 6| Step: 12
Training loss: 0.16932456496437823
Validation loss: 2.4385434523773992

Epoch: 6| Step: 13
Training loss: 0.13095622962063413
Validation loss: 2.452022578843785

Epoch: 600| Step: 0
Training loss: 0.1313229931220696
Validation loss: 2.4359866256762968

Epoch: 6| Step: 1
Training loss: 0.11544222190821002
Validation loss: 2.424384947809794

Epoch: 6| Step: 2
Training loss: 0.11789865084732405
Validation loss: 2.4080549208697266

Epoch: 6| Step: 3
Training loss: 0.13813333304974718
Validation loss: 2.417540948661844

Epoch: 6| Step: 4
Training loss: 0.1410434840677824
Validation loss: 2.4285757528907506

Epoch: 6| Step: 5
Training loss: 0.18437980225338207
Validation loss: 2.4392474147609797

Epoch: 6| Step: 6
Training loss: 0.17714461266742615
Validation loss: 2.427646135649435

Epoch: 6| Step: 7
Training loss: 0.162817454198632
Validation loss: 2.4575171939991654

Epoch: 6| Step: 8
Training loss: 0.0963939721992928
Validation loss: 2.441939031667976

Epoch: 6| Step: 9
Training loss: 0.11723577379304558
Validation loss: 2.4416525030168037

Epoch: 6| Step: 10
Training loss: 0.1481912100571652
Validation loss: 2.4471665066632924

Epoch: 6| Step: 11
Training loss: 0.15420609833903112
Validation loss: 2.3915204542596644

Epoch: 6| Step: 12
Training loss: 0.1581095430486536
Validation loss: 2.3783304430356247

Epoch: 6| Step: 13
Training loss: 0.08662279486464172
Validation loss: 2.385304656092219

Epoch: 601| Step: 0
Training loss: 0.08671121822332015
Validation loss: 2.4282554835613994

Epoch: 6| Step: 1
Training loss: 0.13522928750635083
Validation loss: 2.36491383457308

Epoch: 6| Step: 2
Training loss: 0.0909581471547356
Validation loss: 2.392864641718365

Epoch: 6| Step: 3
Training loss: 0.11226328625695166
Validation loss: 2.37115093645471

Epoch: 6| Step: 4
Training loss: 0.11952723250151262
Validation loss: 2.3851808515689275

Epoch: 6| Step: 5
Training loss: 0.09762404864601086
Validation loss: 2.3812250044022227

Epoch: 6| Step: 6
Training loss: 0.13366523637010327
Validation loss: 2.358722581623238

Epoch: 6| Step: 7
Training loss: 0.14191054472381445
Validation loss: 2.3617501888914183

Epoch: 6| Step: 8
Training loss: 0.14104689122017466
Validation loss: 2.365958429018655

Epoch: 6| Step: 9
Training loss: 0.17976074177302792
Validation loss: 2.3717100037919114

Epoch: 6| Step: 10
Training loss: 0.14908931071209408
Validation loss: 2.343506057787263

Epoch: 6| Step: 11
Training loss: 0.09629346303575806
Validation loss: 2.341563147846741

Epoch: 6| Step: 12
Training loss: 0.10871787301658567
Validation loss: 2.340612202008092

Epoch: 6| Step: 13
Training loss: 0.17666677902232353
Validation loss: 2.332195861902282

Epoch: 602| Step: 0
Training loss: 0.11459927601515887
Validation loss: 2.349218087640422

Epoch: 6| Step: 1
Training loss: 0.12595993494113827
Validation loss: 2.3679462306543453

Epoch: 6| Step: 2
Training loss: 0.11677030768334291
Validation loss: 2.348491215073999

Epoch: 6| Step: 3
Training loss: 0.14959793993323875
Validation loss: 2.3999841573322205

Epoch: 6| Step: 4
Training loss: 0.07201661238921472
Validation loss: 2.3861532729506965

Epoch: 6| Step: 5
Training loss: 0.09928103166747708
Validation loss: 2.4049294881866747

Epoch: 6| Step: 6
Training loss: 0.13754222015769105
Validation loss: 2.415149057507031

Epoch: 6| Step: 7
Training loss: 0.1617259523842656
Validation loss: 2.4203814524069767

Epoch: 6| Step: 8
Training loss: 0.07911794398659865
Validation loss: 2.4257333296421706

Epoch: 6| Step: 9
Training loss: 0.12343301432945676
Validation loss: 2.4157453470315153

Epoch: 6| Step: 10
Training loss: 0.1266028707778597
Validation loss: 2.4119399537793993

Epoch: 6| Step: 11
Training loss: 0.14026015690202123
Validation loss: 2.4348122787331383

Epoch: 6| Step: 12
Training loss: 0.0887986065257584
Validation loss: 2.4129368194187224

Epoch: 6| Step: 13
Training loss: 0.06761140679100497
Validation loss: 2.434568511842576

Epoch: 603| Step: 0
Training loss: 0.09932327790620535
Validation loss: 2.4394594304394346

Epoch: 6| Step: 1
Training loss: 0.10362866815044079
Validation loss: 2.4164834601944234

Epoch: 6| Step: 2
Training loss: 0.08203525192853134
Validation loss: 2.4091592460589237

Epoch: 6| Step: 3
Training loss: 0.14444537446813344
Validation loss: 2.4180534563053127

Epoch: 6| Step: 4
Training loss: 0.15731622378436025
Validation loss: 2.391028740982752

Epoch: 6| Step: 5
Training loss: 0.09286890639046709
Validation loss: 2.4261895328360943

Epoch: 6| Step: 6
Training loss: 0.14722744980663868
Validation loss: 2.40562804885551

Epoch: 6| Step: 7
Training loss: 0.17409274501096195
Validation loss: 2.411737339808582

Epoch: 6| Step: 8
Training loss: 0.13470273001475425
Validation loss: 2.405878874476305

Epoch: 6| Step: 9
Training loss: 0.11217835826074303
Validation loss: 2.4230087458169

Epoch: 6| Step: 10
Training loss: 0.13328999346443807
Validation loss: 2.3967058726751436

Epoch: 6| Step: 11
Training loss: 0.07113214428067767
Validation loss: 2.4247076442085205

Epoch: 6| Step: 12
Training loss: 0.12031161072637693
Validation loss: 2.4233327933943047

Epoch: 6| Step: 13
Training loss: 0.03589746147007777
Validation loss: 2.4272654257038675

Epoch: 604| Step: 0
Training loss: 0.14321657183208336
Validation loss: 2.41477648047041

Epoch: 6| Step: 1
Training loss: 0.14185769823211317
Validation loss: 2.447459257525973

Epoch: 6| Step: 2
Training loss: 0.13245904395218927
Validation loss: 2.4196301840920693

Epoch: 6| Step: 3
Training loss: 0.09004816352707376
Validation loss: 2.4220417665245257

Epoch: 6| Step: 4
Training loss: 0.07389352465106964
Validation loss: 2.4102129840208097

Epoch: 6| Step: 5
Training loss: 0.06994880551909383
Validation loss: 2.41852686882701

Epoch: 6| Step: 6
Training loss: 0.165466916467668
Validation loss: 2.401220131953243

Epoch: 6| Step: 7
Training loss: 0.16300050702191698
Validation loss: 2.361174967861603

Epoch: 6| Step: 8
Training loss: 0.07387697115215276
Validation loss: 2.401883793606804

Epoch: 6| Step: 9
Training loss: 0.13450533152005617
Validation loss: 2.3859736778331118

Epoch: 6| Step: 10
Training loss: 0.12246930338682699
Validation loss: 2.3927704188655925

Epoch: 6| Step: 11
Training loss: 0.10014419404251435
Validation loss: 2.3986639271549457

Epoch: 6| Step: 12
Training loss: 0.1383947639290025
Validation loss: 2.4472661204925554

Epoch: 6| Step: 13
Training loss: 0.052974111839826886
Validation loss: 2.4381069272293248

Epoch: 605| Step: 0
Training loss: 0.08860275729878758
Validation loss: 2.4405515336431263

Epoch: 6| Step: 1
Training loss: 0.18308140914522525
Validation loss: 2.4439550062173336

Epoch: 6| Step: 2
Training loss: 0.1495825496956781
Validation loss: 2.4608441755911463

Epoch: 6| Step: 3
Training loss: 0.09723421455209456
Validation loss: 2.448913828431088

Epoch: 6| Step: 4
Training loss: 0.05185404414574614
Validation loss: 2.3795388410811973

Epoch: 6| Step: 5
Training loss: 0.12567362475336136
Validation loss: 2.3943032424463144

Epoch: 6| Step: 6
Training loss: 0.08829788055583143
Validation loss: 2.41354633593757

Epoch: 6| Step: 7
Training loss: 0.10952584474398265
Validation loss: 2.402198552478311

Epoch: 6| Step: 8
Training loss: 0.1301847118568096
Validation loss: 2.366586672895376

Epoch: 6| Step: 9
Training loss: 0.1610330908870168
Validation loss: 2.380664085932462

Epoch: 6| Step: 10
Training loss: 0.07248201385039467
Validation loss: 2.3740097673652705

Epoch: 6| Step: 11
Training loss: 0.10939536160584866
Validation loss: 2.3842702574524433

Epoch: 6| Step: 12
Training loss: 0.10085679132209072
Validation loss: 2.3696398528994425

Epoch: 6| Step: 13
Training loss: 0.03512030823931961
Validation loss: 2.3826476574165807

Epoch: 606| Step: 0
Training loss: 0.0321726745829865
Validation loss: 2.4067687908455206

Epoch: 6| Step: 1
Training loss: 0.07833035421328749
Validation loss: 2.391197603033088

Epoch: 6| Step: 2
Training loss: 0.06268199113637221
Validation loss: 2.399562510784912

Epoch: 6| Step: 3
Training loss: 0.09039023302829063
Validation loss: 2.3902084359769886

Epoch: 6| Step: 4
Training loss: 0.10075579809787095
Validation loss: 2.4208110715181976

Epoch: 6| Step: 5
Training loss: 0.14803421298510985
Validation loss: 2.389204812660652

Epoch: 6| Step: 6
Training loss: 0.13122507494449928
Validation loss: 2.413447866950783

Epoch: 6| Step: 7
Training loss: 0.1194361476671921
Validation loss: 2.3922261969525818

Epoch: 6| Step: 8
Training loss: 0.08656114279805414
Validation loss: 2.3934509702307727

Epoch: 6| Step: 9
Training loss: 0.08839826213837819
Validation loss: 2.383300083679132

Epoch: 6| Step: 10
Training loss: 0.11062300894448718
Validation loss: 2.356281466075539

Epoch: 6| Step: 11
Training loss: 0.09615769255377071
Validation loss: 2.391343149039162

Epoch: 6| Step: 12
Training loss: 0.10524343335502577
Validation loss: 2.360235194198955

Epoch: 6| Step: 13
Training loss: 0.08258747655542127
Validation loss: 2.36726224679683

Epoch: 607| Step: 0
Training loss: 0.13361605017516537
Validation loss: 2.3940611264055445

Epoch: 6| Step: 1
Training loss: 0.08349436484883671
Validation loss: 2.3940916417507005

Epoch: 6| Step: 2
Training loss: 0.06878765007271635
Validation loss: 2.3903451158271882

Epoch: 6| Step: 3
Training loss: 0.07839326101109689
Validation loss: 2.4339000242064777

Epoch: 6| Step: 4
Training loss: 0.11701468202101728
Validation loss: 2.4373737825246162

Epoch: 6| Step: 5
Training loss: 0.12820311438812082
Validation loss: 2.432898465209566

Epoch: 6| Step: 6
Training loss: 0.11247800224528971
Validation loss: 2.425218270021536

Epoch: 6| Step: 7
Training loss: 0.09563710407244429
Validation loss: 2.4505719010021703

Epoch: 6| Step: 8
Training loss: 0.08298379887312825
Validation loss: 2.416688933462631

Epoch: 6| Step: 9
Training loss: 0.12447773338700438
Validation loss: 2.3924547335642012

Epoch: 6| Step: 10
Training loss: 0.13042708776761544
Validation loss: 2.386462868332545

Epoch: 6| Step: 11
Training loss: 0.06006482720009715
Validation loss: 2.3934049464887828

Epoch: 6| Step: 12
Training loss: 0.09116625784050622
Validation loss: 2.417145007752618

Epoch: 6| Step: 13
Training loss: 0.07670889356038371
Validation loss: 2.404298474411335

Epoch: 608| Step: 0
Training loss: 0.09465988014441293
Validation loss: 2.379809521032529

Epoch: 6| Step: 1
Training loss: 0.12550684869457315
Validation loss: 2.3815852557439

Epoch: 6| Step: 2
Training loss: 0.09288175182778102
Validation loss: 2.4196240770252255

Epoch: 6| Step: 3
Training loss: 0.14536351851612403
Validation loss: 2.3820604815701203

Epoch: 6| Step: 4
Training loss: 0.07308886055781753
Validation loss: 2.4170117504910476

Epoch: 6| Step: 5
Training loss: 0.10902146268947002
Validation loss: 2.461325408839109

Epoch: 6| Step: 6
Training loss: 0.07840115793352108
Validation loss: 2.455044311893103

Epoch: 6| Step: 7
Training loss: 0.12232008367130755
Validation loss: 2.4240404433510605

Epoch: 6| Step: 8
Training loss: 0.12998493023559018
Validation loss: 2.4602079337132157

Epoch: 6| Step: 9
Training loss: 0.08415205982292982
Validation loss: 2.460499774204833

Epoch: 6| Step: 10
Training loss: 0.15031994979621932
Validation loss: 2.422179426258788

Epoch: 6| Step: 11
Training loss: 0.13140675658038783
Validation loss: 2.4197853634724176

Epoch: 6| Step: 12
Training loss: 0.12106144381856566
Validation loss: 2.424142517661724

Epoch: 6| Step: 13
Training loss: 0.12546597738991103
Validation loss: 2.3888381520338413

Epoch: 609| Step: 0
Training loss: 0.1714952782573148
Validation loss: 2.4064677768107123

Epoch: 6| Step: 1
Training loss: 0.12002606928921553
Validation loss: 2.3929749837374366

Epoch: 6| Step: 2
Training loss: 0.09532647069568863
Validation loss: 2.4158530246437637

Epoch: 6| Step: 3
Training loss: 0.08639782383344934
Validation loss: 2.3914361808445808

Epoch: 6| Step: 4
Training loss: 0.05985148120658501
Validation loss: 2.400574483316371

Epoch: 6| Step: 5
Training loss: 0.0729805022624845
Validation loss: 2.397546836163465

Epoch: 6| Step: 6
Training loss: 0.11089207767041942
Validation loss: 2.4350833655873867

Epoch: 6| Step: 7
Training loss: 0.08744097500580356
Validation loss: 2.42805005680054

Epoch: 6| Step: 8
Training loss: 0.1699686314939579
Validation loss: 2.412708083452733

Epoch: 6| Step: 9
Training loss: 0.07860277532190273
Validation loss: 2.423134764648903

Epoch: 6| Step: 10
Training loss: 0.08974256726497842
Validation loss: 2.3885463347929905

Epoch: 6| Step: 11
Training loss: 0.14022728522185302
Validation loss: 2.4232321536647605

Epoch: 6| Step: 12
Training loss: 0.12730615388506192
Validation loss: 2.4042273486271575

Epoch: 6| Step: 13
Training loss: 0.12916936176190433
Validation loss: 2.3873382318128034

Epoch: 610| Step: 0
Training loss: 0.07620476660584244
Validation loss: 2.3918430914873574

Epoch: 6| Step: 1
Training loss: 0.15325736922364167
Validation loss: 2.3852162964584593

Epoch: 6| Step: 2
Training loss: 0.07769557832966817
Validation loss: 2.3849461377066343

Epoch: 6| Step: 3
Training loss: 0.11216346319848498
Validation loss: 2.394820473159109

Epoch: 6| Step: 4
Training loss: 0.08100281342337987
Validation loss: 2.3552415553490853

Epoch: 6| Step: 5
Training loss: 0.07899194056238695
Validation loss: 2.399285674780148

Epoch: 6| Step: 6
Training loss: 0.07703153589864915
Validation loss: 2.3991432820286196

Epoch: 6| Step: 7
Training loss: 0.0710705746877228
Validation loss: 2.4115447638819574

Epoch: 6| Step: 8
Training loss: 0.08232185851364368
Validation loss: 2.4111520998054887

Epoch: 6| Step: 9
Training loss: 0.09848588915960163
Validation loss: 2.4108668222700267

Epoch: 6| Step: 10
Training loss: 0.16282992341135874
Validation loss: 2.4445561794885133

Epoch: 6| Step: 11
Training loss: 0.11996440940808861
Validation loss: 2.4679315606291095

Epoch: 6| Step: 12
Training loss: 0.15827429901141649
Validation loss: 2.4286459850982154

Epoch: 6| Step: 13
Training loss: 0.16225716162453735
Validation loss: 2.42726844163744

Epoch: 611| Step: 0
Training loss: 0.11822805169569872
Validation loss: 2.3893870274880347

Epoch: 6| Step: 1
Training loss: 0.07084543530020726
Validation loss: 2.397515638747551

Epoch: 6| Step: 2
Training loss: 0.1772263045600223
Validation loss: 2.404603765490714

Epoch: 6| Step: 3
Training loss: 0.08568618613974138
Validation loss: 2.4191230336610383

Epoch: 6| Step: 4
Training loss: 0.10454635463944849
Validation loss: 2.400042616024017

Epoch: 6| Step: 5
Training loss: 0.11296763252032724
Validation loss: 2.400116665928796

Epoch: 6| Step: 6
Training loss: 0.0707412502336262
Validation loss: 2.43445296055484

Epoch: 6| Step: 7
Training loss: 0.1164052964817908
Validation loss: 2.415280661410149

Epoch: 6| Step: 8
Training loss: 0.10655068947346558
Validation loss: 2.409990523657577

Epoch: 6| Step: 9
Training loss: 0.09900982253397887
Validation loss: 2.449196417652534

Epoch: 6| Step: 10
Training loss: 0.09094682721024445
Validation loss: 2.411671744237658

Epoch: 6| Step: 11
Training loss: 0.10928248852711651
Validation loss: 2.4088984226905104

Epoch: 6| Step: 12
Training loss: 0.08540303208206741
Validation loss: 2.4369104869920357

Epoch: 6| Step: 13
Training loss: 0.09486636434237354
Validation loss: 2.409956647062342

Epoch: 612| Step: 0
Training loss: 0.08443400981834977
Validation loss: 2.3992020310151743

Epoch: 6| Step: 1
Training loss: 0.07873687742662089
Validation loss: 2.393679510930599

Epoch: 6| Step: 2
Training loss: 0.06393112138167818
Validation loss: 2.4045478549389174

Epoch: 6| Step: 3
Training loss: 0.08573405068615836
Validation loss: 2.3999938276426867

Epoch: 6| Step: 4
Training loss: 0.12980570691443394
Validation loss: 2.4121119735960845

Epoch: 6| Step: 5
Training loss: 0.14971572990054702
Validation loss: 2.4375128860069912

Epoch: 6| Step: 6
Training loss: 0.07840253290865633
Validation loss: 2.415733330791829

Epoch: 6| Step: 7
Training loss: 0.07698115791890735
Validation loss: 2.4317883900579456

Epoch: 6| Step: 8
Training loss: 0.12648667695682175
Validation loss: 2.408682441920499

Epoch: 6| Step: 9
Training loss: 0.060604975111657036
Validation loss: 2.431109440670857

Epoch: 6| Step: 10
Training loss: 0.0913039731575244
Validation loss: 2.4697547696602036

Epoch: 6| Step: 11
Training loss: 0.07821756779744712
Validation loss: 2.4729380144208823

Epoch: 6| Step: 12
Training loss: 0.049624204859561004
Validation loss: 2.4745004996149342

Epoch: 6| Step: 13
Training loss: 0.10086955205305509
Validation loss: 2.4484709580570314

Epoch: 613| Step: 0
Training loss: 0.11347130748510946
Validation loss: 2.4762818147116366

Epoch: 6| Step: 1
Training loss: 0.07530268521085294
Validation loss: 2.438877630377909

Epoch: 6| Step: 2
Training loss: 0.07674249248644033
Validation loss: 2.445620782646847

Epoch: 6| Step: 3
Training loss: 0.07219145164366536
Validation loss: 2.4352951805903698

Epoch: 6| Step: 4
Training loss: 0.05836818710564374
Validation loss: 2.4378690711017854

Epoch: 6| Step: 5
Training loss: 0.09260433244565207
Validation loss: 2.4361523904120763

Epoch: 6| Step: 6
Training loss: 0.057446483525807494
Validation loss: 2.439174492376816

Epoch: 6| Step: 7
Training loss: 0.12814526920952082
Validation loss: 2.445494200166122

Epoch: 6| Step: 8
Training loss: 0.08532859462663986
Validation loss: 2.4318374666793883

Epoch: 6| Step: 9
Training loss: 0.1128241425738391
Validation loss: 2.4228422236134555

Epoch: 6| Step: 10
Training loss: 0.11340784529906518
Validation loss: 2.4266919964798417

Epoch: 6| Step: 11
Training loss: 0.09874318811606987
Validation loss: 2.4291240343576987

Epoch: 6| Step: 12
Training loss: 0.07940264492641194
Validation loss: 2.432157440357114

Epoch: 6| Step: 13
Training loss: 0.15876136998137164
Validation loss: 2.4498241061317527

Epoch: 614| Step: 0
Training loss: 0.10363630242192383
Validation loss: 2.4721421156615926

Epoch: 6| Step: 1
Training loss: 0.0809748440186128
Validation loss: 2.4557091597705325

Epoch: 6| Step: 2
Training loss: 0.0889814082949785
Validation loss: 2.44027005126414

Epoch: 6| Step: 3
Training loss: 0.08721925429817197
Validation loss: 2.448760334761459

Epoch: 6| Step: 4
Training loss: 0.07286754156783085
Validation loss: 2.4162795131896324

Epoch: 6| Step: 5
Training loss: 0.08418713811044005
Validation loss: 2.4440969988243553

Epoch: 6| Step: 6
Training loss: 0.09120637098067913
Validation loss: 2.4039667678498104

Epoch: 6| Step: 7
Training loss: 0.06915777782992547
Validation loss: 2.3718738587952655

Epoch: 6| Step: 8
Training loss: 0.08325329273298335
Validation loss: 2.405296753739162

Epoch: 6| Step: 9
Training loss: 0.07765610770667258
Validation loss: 2.3762696649843598

Epoch: 6| Step: 10
Training loss: 0.10157434687844567
Validation loss: 2.4057986216051024

Epoch: 6| Step: 11
Training loss: 0.06288944296584931
Validation loss: 2.378767022036992

Epoch: 6| Step: 12
Training loss: 0.15493637063313823
Validation loss: 2.385820809073062

Epoch: 6| Step: 13
Training loss: 0.15814258453162208
Validation loss: 2.386100872606012

Epoch: 615| Step: 0
Training loss: 0.11017928558981739
Validation loss: 2.393264818625048

Epoch: 6| Step: 1
Training loss: 0.09190646184321596
Validation loss: 2.408288344046658

Epoch: 6| Step: 2
Training loss: 0.08359358488940039
Validation loss: 2.376963010883298

Epoch: 6| Step: 3
Training loss: 0.07948426692221155
Validation loss: 2.4056706481523804

Epoch: 6| Step: 4
Training loss: 0.09498924525457648
Validation loss: 2.4135566019654795

Epoch: 6| Step: 5
Training loss: 0.09334876706497276
Validation loss: 2.403760064179251

Epoch: 6| Step: 6
Training loss: 0.11133518949480506
Validation loss: 2.4102074391689254

Epoch: 6| Step: 7
Training loss: 0.0738025716932817
Validation loss: 2.444669752591774

Epoch: 6| Step: 8
Training loss: 0.07763760944071457
Validation loss: 2.4332963167219037

Epoch: 6| Step: 9
Training loss: 0.07533149648827188
Validation loss: 2.4124537660807115

Epoch: 6| Step: 10
Training loss: 0.18151722069296933
Validation loss: 2.4359105788711597

Epoch: 6| Step: 11
Training loss: 0.10292774285464626
Validation loss: 2.4128772393047075

Epoch: 6| Step: 12
Training loss: 0.13461259086429414
Validation loss: 2.3876426399897372

Epoch: 6| Step: 13
Training loss: 0.1123568828199218
Validation loss: 2.393769775598529

Epoch: 616| Step: 0
Training loss: 0.1017781316052859
Validation loss: 2.3725718578618897

Epoch: 6| Step: 1
Training loss: 0.07371636123089854
Validation loss: 2.370527979877583

Epoch: 6| Step: 2
Training loss: 0.08891286828694035
Validation loss: 2.3762480614365726

Epoch: 6| Step: 3
Training loss: 0.08928419094829769
Validation loss: 2.3701560033252242

Epoch: 6| Step: 4
Training loss: 0.11544174592858772
Validation loss: 2.4270117686350154

Epoch: 6| Step: 5
Training loss: 0.14057578444220475
Validation loss: 2.366854526436177

Epoch: 6| Step: 6
Training loss: 0.0939444323793928
Validation loss: 2.387009121676307

Epoch: 6| Step: 7
Training loss: 0.11085577358769978
Validation loss: 2.3713843798055536

Epoch: 6| Step: 8
Training loss: 0.05909857636501392
Validation loss: 2.425434409227754

Epoch: 6| Step: 9
Training loss: 0.10939555315637946
Validation loss: 2.396575766331465

Epoch: 6| Step: 10
Training loss: 0.07271355591708657
Validation loss: 2.413087356322682

Epoch: 6| Step: 11
Training loss: 0.08314521300896827
Validation loss: 2.387432062889443

Epoch: 6| Step: 12
Training loss: 0.11006406873676801
Validation loss: 2.4264806243530708

Epoch: 6| Step: 13
Training loss: 0.1472577786062824
Validation loss: 2.4617937391856195

Epoch: 617| Step: 0
Training loss: 0.09718021718179937
Validation loss: 2.427608308751333

Epoch: 6| Step: 1
Training loss: 0.07846739364615479
Validation loss: 2.413588765737718

Epoch: 6| Step: 2
Training loss: 0.11777303167371275
Validation loss: 2.4139305100167743

Epoch: 6| Step: 3
Training loss: 0.10111500198288331
Validation loss: 2.4205560210602752

Epoch: 6| Step: 4
Training loss: 0.09181358307095093
Validation loss: 2.4185847622027556

Epoch: 6| Step: 5
Training loss: 0.13399236783134563
Validation loss: 2.3704988163996417

Epoch: 6| Step: 6
Training loss: 0.13633282552228537
Validation loss: 2.4098882073557095

Epoch: 6| Step: 7
Training loss: 0.05690980327498571
Validation loss: 2.4078948992664664

Epoch: 6| Step: 8
Training loss: 0.09641959142878481
Validation loss: 2.3723373631908773

Epoch: 6| Step: 9
Training loss: 0.043332450417881474
Validation loss: 2.3948934973908216

Epoch: 6| Step: 10
Training loss: 0.10790825751519938
Validation loss: 2.410604582317106

Epoch: 6| Step: 11
Training loss: 0.11551254045410199
Validation loss: 2.395384112844975

Epoch: 6| Step: 12
Training loss: 0.11813149121528638
Validation loss: 2.4409122862182717

Epoch: 6| Step: 13
Training loss: 0.09213296259024632
Validation loss: 2.424701617597511

Epoch: 618| Step: 0
Training loss: 0.09098318324028337
Validation loss: 2.4182721181160933

Epoch: 6| Step: 1
Training loss: 0.09027854263713217
Validation loss: 2.4051763352329734

Epoch: 6| Step: 2
Training loss: 0.12535057230338684
Validation loss: 2.4451181501662616

Epoch: 6| Step: 3
Training loss: 0.07159224472457393
Validation loss: 2.4657978638323934

Epoch: 6| Step: 4
Training loss: 0.0876667403082499
Validation loss: 2.435213812718588

Epoch: 6| Step: 5
Training loss: 0.06081264945849374
Validation loss: 2.440696786617259

Epoch: 6| Step: 6
Training loss: 0.08750916990697417
Validation loss: 2.4550698516343696

Epoch: 6| Step: 7
Training loss: 0.12414984381351334
Validation loss: 2.459760355648066

Epoch: 6| Step: 8
Training loss: 0.08460538832728784
Validation loss: 2.422478217067609

Epoch: 6| Step: 9
Training loss: 0.05951182824560746
Validation loss: 2.4106480922662414

Epoch: 6| Step: 10
Training loss: 0.08944003996451301
Validation loss: 2.439784612960768

Epoch: 6| Step: 11
Training loss: 0.09960132454147955
Validation loss: 2.4002565166071514

Epoch: 6| Step: 12
Training loss: 0.13166352760470215
Validation loss: 2.393504824854325

Epoch: 6| Step: 13
Training loss: 0.09317559864587793
Validation loss: 2.401116956664336

Epoch: 619| Step: 0
Training loss: 0.050394910899950573
Validation loss: 2.3876091871832545

Epoch: 6| Step: 1
Training loss: 0.12272916376036938
Validation loss: 2.3875189430117993

Epoch: 6| Step: 2
Training loss: 0.06981644553819062
Validation loss: 2.413396625415734

Epoch: 6| Step: 3
Training loss: 0.08352489142133254
Validation loss: 2.3944352945464886

Epoch: 6| Step: 4
Training loss: 0.07290932037892175
Validation loss: 2.3988876387997915

Epoch: 6| Step: 5
Training loss: 0.06922390442852971
Validation loss: 2.4009125665728317

Epoch: 6| Step: 6
Training loss: 0.08907831704079362
Validation loss: 2.384226981173509

Epoch: 6| Step: 7
Training loss: 0.10433732348556596
Validation loss: 2.402994461564747

Epoch: 6| Step: 8
Training loss: 0.07982907003040077
Validation loss: 2.416599559347247

Epoch: 6| Step: 9
Training loss: 0.06708102438983032
Validation loss: 2.392961998774853

Epoch: 6| Step: 10
Training loss: 0.1433685484297681
Validation loss: 2.4118905419088335

Epoch: 6| Step: 11
Training loss: 0.12918445159644815
Validation loss: 2.398517808915445

Epoch: 6| Step: 12
Training loss: 0.08911642817704399
Validation loss: 2.3964767444567108

Epoch: 6| Step: 13
Training loss: 0.13029190401566595
Validation loss: 2.3937236241131146

Epoch: 620| Step: 0
Training loss: 0.12373090396193367
Validation loss: 2.4210355586694146

Epoch: 6| Step: 1
Training loss: 0.06053694712861262
Validation loss: 2.4188126207662046

Epoch: 6| Step: 2
Training loss: 0.09855205232239868
Validation loss: 2.4142317982849453

Epoch: 6| Step: 3
Training loss: 0.1222756109029277
Validation loss: 2.3895918621531096

Epoch: 6| Step: 4
Training loss: 0.13483420990252082
Validation loss: 2.401715800307424

Epoch: 6| Step: 5
Training loss: 0.10523938033300749
Validation loss: 2.3677324563736097

Epoch: 6| Step: 6
Training loss: 0.13138048123450113
Validation loss: 2.391299536554789

Epoch: 6| Step: 7
Training loss: 0.1239757220776848
Validation loss: 2.4228487394639933

Epoch: 6| Step: 8
Training loss: 0.08919543125237904
Validation loss: 2.404973599683809

Epoch: 6| Step: 9
Training loss: 0.10420825297009877
Validation loss: 2.446473276336203

Epoch: 6| Step: 10
Training loss: 0.13750343616483593
Validation loss: 2.386174943141545

Epoch: 6| Step: 11
Training loss: 0.06587263243676035
Validation loss: 2.454813952472942

Epoch: 6| Step: 12
Training loss: 0.07091522832401571
Validation loss: 2.450124432984805

Epoch: 6| Step: 13
Training loss: 0.15826147675216196
Validation loss: 2.4525823725186653

Epoch: 621| Step: 0
Training loss: 0.1265863696300898
Validation loss: 2.4214508944962674

Epoch: 6| Step: 1
Training loss: 0.11678601472815135
Validation loss: 2.421175425062135

Epoch: 6| Step: 2
Training loss: 0.08363470763117636
Validation loss: 2.3936123794505417

Epoch: 6| Step: 3
Training loss: 0.09171689891896836
Validation loss: 2.40832098108851

Epoch: 6| Step: 4
Training loss: 0.0752648180969237
Validation loss: 2.402768676964716

Epoch: 6| Step: 5
Training loss: 0.06333028371243721
Validation loss: 2.383409599805271

Epoch: 6| Step: 6
Training loss: 0.10627154506997036
Validation loss: 2.355477819437363

Epoch: 6| Step: 7
Training loss: 0.15662765163816578
Validation loss: 2.3456009412243026

Epoch: 6| Step: 8
Training loss: 0.14102331019036493
Validation loss: 2.3139105953660284

Epoch: 6| Step: 9
Training loss: 0.140320182623951
Validation loss: 2.341113579169811

Epoch: 6| Step: 10
Training loss: 0.17990155531400173
Validation loss: 2.366234070935149

Epoch: 6| Step: 11
Training loss: 0.06724476840939898
Validation loss: 2.359277423442793

Epoch: 6| Step: 12
Training loss: 0.08833147325146767
Validation loss: 2.394686729413889

Epoch: 6| Step: 13
Training loss: 0.1641031169568022
Validation loss: 2.420368560457625

Epoch: 622| Step: 0
Training loss: 0.11936405993057593
Validation loss: 2.4278528552549905

Epoch: 6| Step: 1
Training loss: 0.0985559692934485
Validation loss: 2.4630795486600237

Epoch: 6| Step: 2
Training loss: 0.11207708847527052
Validation loss: 2.4308952350451793

Epoch: 6| Step: 3
Training loss: 0.08383030954342663
Validation loss: 2.4172348119116904

Epoch: 6| Step: 4
Training loss: 0.0851875440159416
Validation loss: 2.4052638145293153

Epoch: 6| Step: 5
Training loss: 0.10626297829406707
Validation loss: 2.439106540369437

Epoch: 6| Step: 6
Training loss: 0.14677559831892362
Validation loss: 2.4168426660333

Epoch: 6| Step: 7
Training loss: 0.08201729281080185
Validation loss: 2.35950363081269

Epoch: 6| Step: 8
Training loss: 0.11261179852567287
Validation loss: 2.3667841953265554

Epoch: 6| Step: 9
Training loss: 0.08393741836369906
Validation loss: 2.393375445327416

Epoch: 6| Step: 10
Training loss: 0.11236360497165293
Validation loss: 2.3542878624939294

Epoch: 6| Step: 11
Training loss: 0.08937264365978081
Validation loss: 2.3696557901331397

Epoch: 6| Step: 12
Training loss: 0.10082303038713299
Validation loss: 2.3556833444444556

Epoch: 6| Step: 13
Training loss: 0.11142557463430361
Validation loss: 2.351697129762694

Epoch: 623| Step: 0
Training loss: 0.08923097181869326
Validation loss: 2.4070358884100864

Epoch: 6| Step: 1
Training loss: 0.12417558288870377
Validation loss: 2.4114038051989968

Epoch: 6| Step: 2
Training loss: 0.14439439738208207
Validation loss: 2.410622064343849

Epoch: 6| Step: 3
Training loss: 0.08300476349111449
Validation loss: 2.4203595106844222

Epoch: 6| Step: 4
Training loss: 0.13015202894384265
Validation loss: 2.402883027038052

Epoch: 6| Step: 5
Training loss: 0.054865286275418056
Validation loss: 2.428761489138676

Epoch: 6| Step: 6
Training loss: 0.06722309699870821
Validation loss: 2.4494353827235504

Epoch: 6| Step: 7
Training loss: 0.06600351081391498
Validation loss: 2.474514575508002

Epoch: 6| Step: 8
Training loss: 0.13792748863522325
Validation loss: 2.469251314653065

Epoch: 6| Step: 9
Training loss: 0.09069515135723898
Validation loss: 2.4499781976147874

Epoch: 6| Step: 10
Training loss: 0.08654502412080993
Validation loss: 2.467486046417919

Epoch: 6| Step: 11
Training loss: 0.1522839930295337
Validation loss: 2.427547155603431

Epoch: 6| Step: 12
Training loss: 0.1275990194787683
Validation loss: 2.4232007026772067

Epoch: 6| Step: 13
Training loss: 0.06429081767763556
Validation loss: 2.415214777826882

Epoch: 624| Step: 0
Training loss: 0.10771147099295925
Validation loss: 2.392270871947752

Epoch: 6| Step: 1
Training loss: 0.12973424115151666
Validation loss: 2.3893673155705035

Epoch: 6| Step: 2
Training loss: 0.12270776250098742
Validation loss: 2.4038756543124924

Epoch: 6| Step: 3
Training loss: 0.12381959669185574
Validation loss: 2.4242222224865104

Epoch: 6| Step: 4
Training loss: 0.15030215497413638
Validation loss: 2.3929569506849035

Epoch: 6| Step: 5
Training loss: 0.18062579806524404
Validation loss: 2.398686593704059

Epoch: 6| Step: 6
Training loss: 0.11768753341303598
Validation loss: 2.415295205019424

Epoch: 6| Step: 7
Training loss: 0.09120477292060658
Validation loss: 2.4149384993807845

Epoch: 6| Step: 8
Training loss: 0.10361310130111787
Validation loss: 2.406994021021035

Epoch: 6| Step: 9
Training loss: 0.08019550954290042
Validation loss: 2.4517765031732797

Epoch: 6| Step: 10
Training loss: 0.07894023880847291
Validation loss: 2.4388371931259685

Epoch: 6| Step: 11
Training loss: 0.18769575867217797
Validation loss: 2.467532468139295

Epoch: 6| Step: 12
Training loss: 0.14702326514750216
Validation loss: 2.4419783708844185

Epoch: 6| Step: 13
Training loss: 0.14848646811842786
Validation loss: 2.4360547015445624

Epoch: 625| Step: 0
Training loss: 0.14499968575986158
Validation loss: 2.410065524698425

Epoch: 6| Step: 1
Training loss: 0.11015977904571474
Validation loss: 2.3801137255966442

Epoch: 6| Step: 2
Training loss: 0.07894246266585153
Validation loss: 2.3954143726755848

Epoch: 6| Step: 3
Training loss: 0.11468792516385301
Validation loss: 2.4156098295037705

Epoch: 6| Step: 4
Training loss: 0.13836632229181953
Validation loss: 2.3869558314983106

Epoch: 6| Step: 5
Training loss: 0.11470560211637192
Validation loss: 2.3971682738200206

Epoch: 6| Step: 6
Training loss: 0.14471136932316855
Validation loss: 2.4290436513252494

Epoch: 6| Step: 7
Training loss: 0.13258736827146456
Validation loss: 2.4396984870515595

Epoch: 6| Step: 8
Training loss: 0.11679441168748668
Validation loss: 2.416217016015726

Epoch: 6| Step: 9
Training loss: 0.10005930654408506
Validation loss: 2.398930769758664

Epoch: 6| Step: 10
Training loss: 0.14373984689723146
Validation loss: 2.4246684751984686

Epoch: 6| Step: 11
Training loss: 0.12281932680797157
Validation loss: 2.411288146417448

Epoch: 6| Step: 12
Training loss: 0.08437000498291482
Validation loss: 2.4143902478185706

Epoch: 6| Step: 13
Training loss: 0.1436500621746724
Validation loss: 2.405713438511339

Epoch: 626| Step: 0
Training loss: 0.11796436301657368
Validation loss: 2.4045071580758406

Epoch: 6| Step: 1
Training loss: 0.09608322682951004
Validation loss: 2.4299033550861067

Epoch: 6| Step: 2
Training loss: 0.1289139225150293
Validation loss: 2.4247658530987293

Epoch: 6| Step: 3
Training loss: 0.09117402651126938
Validation loss: 2.43687186655126

Epoch: 6| Step: 4
Training loss: 0.12100516432290918
Validation loss: 2.4322458733556984

Epoch: 6| Step: 5
Training loss: 0.13566323598340269
Validation loss: 2.469660097832405

Epoch: 6| Step: 6
Training loss: 0.11733326588258693
Validation loss: 2.426386530408013

Epoch: 6| Step: 7
Training loss: 0.16890526445720583
Validation loss: 2.447292642816045

Epoch: 6| Step: 8
Training loss: 0.0814080035108663
Validation loss: 2.4030517297909535

Epoch: 6| Step: 9
Training loss: 0.14117330046938412
Validation loss: 2.4367876308174528

Epoch: 6| Step: 10
Training loss: 0.14806323803983018
Validation loss: 2.399314979326676

Epoch: 6| Step: 11
Training loss: 0.14604301081522708
Validation loss: 2.393605397368639

Epoch: 6| Step: 12
Training loss: 0.1492374972605048
Validation loss: 2.3805608290241134

Epoch: 6| Step: 13
Training loss: 0.09384014841905286
Validation loss: 2.3763350926139357

Epoch: 627| Step: 0
Training loss: 0.08896739780180953
Validation loss: 2.380155028039383

Epoch: 6| Step: 1
Training loss: 0.06853460604647112
Validation loss: 2.3716522665611874

Epoch: 6| Step: 2
Training loss: 0.08922817982078875
Validation loss: 2.3961275459537985

Epoch: 6| Step: 3
Training loss: 0.13127023336582883
Validation loss: 2.400381182173059

Epoch: 6| Step: 4
Training loss: 0.09532871772808184
Validation loss: 2.41878797959135

Epoch: 6| Step: 5
Training loss: 0.11181911315306761
Validation loss: 2.4176355469945654

Epoch: 6| Step: 6
Training loss: 0.19975340847991238
Validation loss: 2.4112982264346776

Epoch: 6| Step: 7
Training loss: 0.17528215656566357
Validation loss: 2.438683548791024

Epoch: 6| Step: 8
Training loss: 0.14637293073118335
Validation loss: 2.3920121811350037

Epoch: 6| Step: 9
Training loss: 0.11535546034942427
Validation loss: 2.4076873807477384

Epoch: 6| Step: 10
Training loss: 0.1790592780164537
Validation loss: 2.395957494856085

Epoch: 6| Step: 11
Training loss: 0.08407364580827398
Validation loss: 2.3604384792676094

Epoch: 6| Step: 12
Training loss: 0.15036862076136565
Validation loss: 2.340072416598371

Epoch: 6| Step: 13
Training loss: 0.183935861204976
Validation loss: 2.365276070581372

Epoch: 628| Step: 0
Training loss: 0.133554524524519
Validation loss: 2.4047170123192987

Epoch: 6| Step: 1
Training loss: 0.13452730668166918
Validation loss: 2.3857687409857586

Epoch: 6| Step: 2
Training loss: 0.11755014574580566
Validation loss: 2.413690242226759

Epoch: 6| Step: 3
Training loss: 0.17137571446230182
Validation loss: 2.4247134910641837

Epoch: 6| Step: 4
Training loss: 0.15094140372549392
Validation loss: 2.4154202072433835

Epoch: 6| Step: 5
Training loss: 0.08422490264220171
Validation loss: 2.3846131701059514

Epoch: 6| Step: 6
Training loss: 0.18587875800704537
Validation loss: 2.437576187579636

Epoch: 6| Step: 7
Training loss: 0.15451443701252768
Validation loss: 2.3891848674676797

Epoch: 6| Step: 8
Training loss: 0.11980174677012989
Validation loss: 2.377948615586788

Epoch: 6| Step: 9
Training loss: 0.15438102889933336
Validation loss: 2.3726866184268864

Epoch: 6| Step: 10
Training loss: 0.11670337653634148
Validation loss: 2.3642687501325788

Epoch: 6| Step: 11
Training loss: 0.19528930526335572
Validation loss: 2.3397694629207826

Epoch: 6| Step: 12
Training loss: 0.12752650697137805
Validation loss: 2.3233621123197477

Epoch: 6| Step: 13
Training loss: 0.17953855104598898
Validation loss: 2.3664941277524916

Epoch: 629| Step: 0
Training loss: 0.17252569138593324
Validation loss: 2.3620236953337024

Epoch: 6| Step: 1
Training loss: 0.0881585752075059
Validation loss: 2.377127691184003

Epoch: 6| Step: 2
Training loss: 0.11976779349143757
Validation loss: 2.3841782965713025

Epoch: 6| Step: 3
Training loss: 0.11021882065732079
Validation loss: 2.421269610344067

Epoch: 6| Step: 4
Training loss: 0.13449434259279602
Validation loss: 2.4504862708766186

Epoch: 6| Step: 5
Training loss: 0.1267085139682983
Validation loss: 2.4275785674404182

Epoch: 6| Step: 6
Training loss: 0.1796883396460777
Validation loss: 2.439501075355799

Epoch: 6| Step: 7
Training loss: 0.11998186009112782
Validation loss: 2.403106482466311

Epoch: 6| Step: 8
Training loss: 0.15295542893743294
Validation loss: 2.3815170782544137

Epoch: 6| Step: 9
Training loss: 0.14626568045878452
Validation loss: 2.3969709658529728

Epoch: 6| Step: 10
Training loss: 0.13746071845013053
Validation loss: 2.3712182432703854

Epoch: 6| Step: 11
Training loss: 0.1489864976028601
Validation loss: 2.3469731177106454

Epoch: 6| Step: 12
Training loss: 0.13032401588610984
Validation loss: 2.392780041188767

Epoch: 6| Step: 13
Training loss: 0.12985088558306324
Validation loss: 2.3554147135835803

Epoch: 630| Step: 0
Training loss: 0.13270288740563735
Validation loss: 2.355650693672626

Epoch: 6| Step: 1
Training loss: 0.17585455107883208
Validation loss: 2.371499224860003

Epoch: 6| Step: 2
Training loss: 0.16659301319971911
Validation loss: 2.377310317305654

Epoch: 6| Step: 3
Training loss: 0.11605136397927217
Validation loss: 2.3913279065764743

Epoch: 6| Step: 4
Training loss: 0.11247259110772888
Validation loss: 2.4113633101597505

Epoch: 6| Step: 5
Training loss: 0.20157104074880264
Validation loss: 2.396533589441486

Epoch: 6| Step: 6
Training loss: 0.15756925116287526
Validation loss: 2.407360697925854

Epoch: 6| Step: 7
Training loss: 0.09003756701867965
Validation loss: 2.4044364740126642

Epoch: 6| Step: 8
Training loss: 0.07415493932482825
Validation loss: 2.377811844184018

Epoch: 6| Step: 9
Training loss: 0.08348019487584973
Validation loss: 2.3832106649129323

Epoch: 6| Step: 10
Training loss: 0.13370895075568803
Validation loss: 2.3385070371408196

Epoch: 6| Step: 11
Training loss: 0.14787351604025026
Validation loss: 2.3735355629052854

Epoch: 6| Step: 12
Training loss: 0.1325317388434233
Validation loss: 2.3362673731873898

Epoch: 6| Step: 13
Training loss: 0.19282144800873993
Validation loss: 2.383474348500154

Epoch: 631| Step: 0
Training loss: 0.1749790749641787
Validation loss: 2.40011275015488

Epoch: 6| Step: 1
Training loss: 0.10379289883438989
Validation loss: 2.4454557624604574

Epoch: 6| Step: 2
Training loss: 0.13515435697078768
Validation loss: 2.4306715630437945

Epoch: 6| Step: 3
Training loss: 0.17321427323593439
Validation loss: 2.4502673806201067

Epoch: 6| Step: 4
Training loss: 0.15395903722897245
Validation loss: 2.420169818845091

Epoch: 6| Step: 5
Training loss: 0.0842228873763534
Validation loss: 2.424377442620657

Epoch: 6| Step: 6
Training loss: 0.0736578969447626
Validation loss: 2.430259843720488

Epoch: 6| Step: 7
Training loss: 0.15249096042388144
Validation loss: 2.4087031633339886

Epoch: 6| Step: 8
Training loss: 0.1169633390365965
Validation loss: 2.392095540448896

Epoch: 6| Step: 9
Training loss: 0.14774743725922976
Validation loss: 2.369846560169119

Epoch: 6| Step: 10
Training loss: 0.12255529574026074
Validation loss: 2.3601700029379358

Epoch: 6| Step: 11
Training loss: 0.22663603608707075
Validation loss: 2.3691256411515265

Epoch: 6| Step: 12
Training loss: 0.15080717535930618
Validation loss: 2.3982310659036483

Epoch: 6| Step: 13
Training loss: 0.14547353379141179
Validation loss: 2.4155608392181893

Epoch: 632| Step: 0
Training loss: 0.1269333603952625
Validation loss: 2.4072105084524797

Epoch: 6| Step: 1
Training loss: 0.14314515221828414
Validation loss: 2.4344210366373553

Epoch: 6| Step: 2
Training loss: 0.1489101902039139
Validation loss: 2.4390613728676254

Epoch: 6| Step: 3
Training loss: 0.12170088753239493
Validation loss: 2.428127364423821

Epoch: 6| Step: 4
Training loss: 0.2047760145978414
Validation loss: 2.4328701184045136

Epoch: 6| Step: 5
Training loss: 0.17298601061806027
Validation loss: 2.354748395293286

Epoch: 6| Step: 6
Training loss: 0.09544326574762141
Validation loss: 2.376268787339001

Epoch: 6| Step: 7
Training loss: 0.08674676202150834
Validation loss: 2.3645313194516784

Epoch: 6| Step: 8
Training loss: 0.14469097950996712
Validation loss: 2.33069799698784

Epoch: 6| Step: 9
Training loss: 0.138164471762377
Validation loss: 2.3821697713807564

Epoch: 6| Step: 10
Training loss: 0.16879993313666858
Validation loss: 2.3544381733136515

Epoch: 6| Step: 11
Training loss: 0.1693980154890671
Validation loss: 2.362887435477302

Epoch: 6| Step: 12
Training loss: 0.16737563742145187
Validation loss: 2.3619031773947445

Epoch: 6| Step: 13
Training loss: 0.14250820222053381
Validation loss: 2.3965568302533926

Epoch: 633| Step: 0
Training loss: 0.16180050391341533
Validation loss: 2.4190844137899914

Epoch: 6| Step: 1
Training loss: 0.15927982106203062
Validation loss: 2.4421164783051377

Epoch: 6| Step: 2
Training loss: 0.1703976186605232
Validation loss: 2.4193591130639334

Epoch: 6| Step: 3
Training loss: 0.14904477102984345
Validation loss: 2.4594662535835337

Epoch: 6| Step: 4
Training loss: 0.07584879902622521
Validation loss: 2.4229461587571777

Epoch: 6| Step: 5
Training loss: 0.06350395271927022
Validation loss: 2.441366747202257

Epoch: 6| Step: 6
Training loss: 0.14802929942501017
Validation loss: 2.383242953168932

Epoch: 6| Step: 7
Training loss: 0.061534895662496855
Validation loss: 2.3969692342776856

Epoch: 6| Step: 8
Training loss: 0.08840886024661529
Validation loss: 2.36608380141231

Epoch: 6| Step: 9
Training loss: 0.11509924578900148
Validation loss: 2.341689074231037

Epoch: 6| Step: 10
Training loss: 0.1302365097713052
Validation loss: 2.336845642577178

Epoch: 6| Step: 11
Training loss: 0.13008845692060222
Validation loss: 2.3579936757767643

Epoch: 6| Step: 12
Training loss: 0.15207435557460752
Validation loss: 2.348376710941554

Epoch: 6| Step: 13
Training loss: 0.12425197360948549
Validation loss: 2.401849584929555

Epoch: 634| Step: 0
Training loss: 0.14943136476552762
Validation loss: 2.405788851016447

Epoch: 6| Step: 1
Training loss: 0.21178019817834676
Validation loss: 2.408250148421781

Epoch: 6| Step: 2
Training loss: 0.14510319926023169
Validation loss: 2.4201788417863974

Epoch: 6| Step: 3
Training loss: 0.09239192619291295
Validation loss: 2.425956458313233

Epoch: 6| Step: 4
Training loss: 0.10107414503601629
Validation loss: 2.3759717847541557

Epoch: 6| Step: 5
Training loss: 0.13320434491446315
Validation loss: 2.3643612273278434

Epoch: 6| Step: 6
Training loss: 0.08545728372933335
Validation loss: 2.344345244700531

Epoch: 6| Step: 7
Training loss: 0.1606626471418406
Validation loss: 2.325924238603089

Epoch: 6| Step: 8
Training loss: 0.13079142585598344
Validation loss: 2.351669957183859

Epoch: 6| Step: 9
Training loss: 0.09207181642847244
Validation loss: 2.4011715313835476

Epoch: 6| Step: 10
Training loss: 0.08471021983975417
Validation loss: 2.374447607751236

Epoch: 6| Step: 11
Training loss: 0.06907896657373704
Validation loss: 2.4247523812826026

Epoch: 6| Step: 12
Training loss: 0.14233738680873814
Validation loss: 2.407801029811269

Epoch: 6| Step: 13
Training loss: 0.1400159920558965
Validation loss: 2.413625174512962

Epoch: 635| Step: 0
Training loss: 0.10908416841576844
Validation loss: 2.4238427178017785

Epoch: 6| Step: 1
Training loss: 0.11927187053640333
Validation loss: 2.426300632080177

Epoch: 6| Step: 2
Training loss: 0.11160571642372838
Validation loss: 2.438631501890332

Epoch: 6| Step: 3
Training loss: 0.08172407995387601
Validation loss: 2.4501371835386445

Epoch: 6| Step: 4
Training loss: 0.10414376503802865
Validation loss: 2.4222466931507642

Epoch: 6| Step: 5
Training loss: 0.06159014907248802
Validation loss: 2.3959916512361685

Epoch: 6| Step: 6
Training loss: 0.1228711485601111
Validation loss: 2.423732892568242

Epoch: 6| Step: 7
Training loss: 0.14905179430146487
Validation loss: 2.422763947388373

Epoch: 6| Step: 8
Training loss: 0.08060701676091503
Validation loss: 2.409903047860948

Epoch: 6| Step: 9
Training loss: 0.10084570516529746
Validation loss: 2.3922771868151833

Epoch: 6| Step: 10
Training loss: 0.10594737980214339
Validation loss: 2.392391424338622

Epoch: 6| Step: 11
Training loss: 0.10166386442722862
Validation loss: 2.3910084711169755

Epoch: 6| Step: 12
Training loss: 0.06379878715187998
Validation loss: 2.396420553898208

Epoch: 6| Step: 13
Training loss: 0.09492268365743156
Validation loss: 2.411485553351198

Epoch: 636| Step: 0
Training loss: 0.09367385891586386
Validation loss: 2.407176317431376

Epoch: 6| Step: 1
Training loss: 0.12166401576952085
Validation loss: 2.3956741554773298

Epoch: 6| Step: 2
Training loss: 0.11315909738547944
Validation loss: 2.367582885077537

Epoch: 6| Step: 3
Training loss: 0.1402030415714874
Validation loss: 2.384043053600673

Epoch: 6| Step: 4
Training loss: 0.1397127523574741
Validation loss: 2.380809964690527

Epoch: 6| Step: 5
Training loss: 0.08212688525204638
Validation loss: 2.4172210690392046

Epoch: 6| Step: 6
Training loss: 0.07189509406331947
Validation loss: 2.392783006840753

Epoch: 6| Step: 7
Training loss: 0.11092423070879842
Validation loss: 2.4035282688646897

Epoch: 6| Step: 8
Training loss: 0.10144916042393623
Validation loss: 2.3942421128979188

Epoch: 6| Step: 9
Training loss: 0.1616549787698137
Validation loss: 2.4332514206582894

Epoch: 6| Step: 10
Training loss: 0.14071096335970987
Validation loss: 2.394450593245142

Epoch: 6| Step: 11
Training loss: 0.06553961643180892
Validation loss: 2.3964252208050096

Epoch: 6| Step: 12
Training loss: 0.06089316445596418
Validation loss: 2.4013659982206637

Epoch: 6| Step: 13
Training loss: 0.06309779944374388
Validation loss: 2.433447741191387

Epoch: 637| Step: 0
Training loss: 0.08799618633633027
Validation loss: 2.404670364107846

Epoch: 6| Step: 1
Training loss: 0.09831357982137064
Validation loss: 2.4216718966307598

Epoch: 6| Step: 2
Training loss: 0.11390582912665582
Validation loss: 2.397825310932786

Epoch: 6| Step: 3
Training loss: 0.10814756282052285
Validation loss: 2.3945912903299136

Epoch: 6| Step: 4
Training loss: 0.09578499406307925
Validation loss: 2.4313750926806366

Epoch: 6| Step: 5
Training loss: 0.06722857611354158
Validation loss: 2.413165804604326

Epoch: 6| Step: 6
Training loss: 0.11626459133317732
Validation loss: 2.3718798607495364

Epoch: 6| Step: 7
Training loss: 0.11728638609432736
Validation loss: 2.385293742371692

Epoch: 6| Step: 8
Training loss: 0.08986352619949449
Validation loss: 2.391269253600081

Epoch: 6| Step: 9
Training loss: 0.10333681858085407
Validation loss: 2.3493071590100993

Epoch: 6| Step: 10
Training loss: 0.08951512649245509
Validation loss: 2.3730227946329836

Epoch: 6| Step: 11
Training loss: 0.08764458497520936
Validation loss: 2.3686499469503706

Epoch: 6| Step: 12
Training loss: 0.10612322698388121
Validation loss: 2.3376149332067846

Epoch: 6| Step: 13
Training loss: 0.1573001144574277
Validation loss: 2.393989259555173

Epoch: 638| Step: 0
Training loss: 0.11672278290028057
Validation loss: 2.390535884179817

Epoch: 6| Step: 1
Training loss: 0.06928287745879844
Validation loss: 2.4490176076060317

Epoch: 6| Step: 2
Training loss: 0.08847860645518488
Validation loss: 2.4059905018933394

Epoch: 6| Step: 3
Training loss: 0.11606131065136212
Validation loss: 2.430895623140752

Epoch: 6| Step: 4
Training loss: 0.11137932720940281
Validation loss: 2.461273654806636

Epoch: 6| Step: 5
Training loss: 0.13299519931403822
Validation loss: 2.4461206561053217

Epoch: 6| Step: 6
Training loss: 0.10891885668061528
Validation loss: 2.468386934789677

Epoch: 6| Step: 7
Training loss: 0.11590073962829307
Validation loss: 2.4744780183211605

Epoch: 6| Step: 8
Training loss: 0.12782373481563056
Validation loss: 2.4169183923703317

Epoch: 6| Step: 9
Training loss: 0.08800709213219376
Validation loss: 2.438060250170352

Epoch: 6| Step: 10
Training loss: 0.11450235167476697
Validation loss: 2.4195138144816255

Epoch: 6| Step: 11
Training loss: 0.07895659478877076
Validation loss: 2.428345453257407

Epoch: 6| Step: 12
Training loss: 0.09363061535500948
Validation loss: 2.389282046671491

Epoch: 6| Step: 13
Training loss: 0.060958077398219415
Validation loss: 2.3901054508906183

Epoch: 639| Step: 0
Training loss: 0.08958247797949472
Validation loss: 2.3843376928193485

Epoch: 6| Step: 1
Training loss: 0.1298192162523404
Validation loss: 2.393297356862342

Epoch: 6| Step: 2
Training loss: 0.11990763831360149
Validation loss: 2.4031581525026535

Epoch: 6| Step: 3
Training loss: 0.08209511280507817
Validation loss: 2.4089216900080537

Epoch: 6| Step: 4
Training loss: 0.06605147511291895
Validation loss: 2.4091585541131484

Epoch: 6| Step: 5
Training loss: 0.07840236957593907
Validation loss: 2.3814962344018493

Epoch: 6| Step: 6
Training loss: 0.08796964642811604
Validation loss: 2.4237655152035273

Epoch: 6| Step: 7
Training loss: 0.10906930335229487
Validation loss: 2.4092784618110414

Epoch: 6| Step: 8
Training loss: 0.10235683051813114
Validation loss: 2.3916042219684415

Epoch: 6| Step: 9
Training loss: 0.10108560691476953
Validation loss: 2.3745230847339975

Epoch: 6| Step: 10
Training loss: 0.1034763054576315
Validation loss: 2.3897915869390016

Epoch: 6| Step: 11
Training loss: 0.1052324995724794
Validation loss: 2.3908803922568005

Epoch: 6| Step: 12
Training loss: 0.05770145937188786
Validation loss: 2.4001608455845393

Epoch: 6| Step: 13
Training loss: 0.08674810939255351
Validation loss: 2.4154791164858653

Epoch: 640| Step: 0
Training loss: 0.10999613041194536
Validation loss: 2.419519822227591

Epoch: 6| Step: 1
Training loss: 0.08019475178120726
Validation loss: 2.3951016893039356

Epoch: 6| Step: 2
Training loss: 0.1202958065998275
Validation loss: 2.3979659890835383

Epoch: 6| Step: 3
Training loss: 0.10130833955419953
Validation loss: 2.390284412735488

Epoch: 6| Step: 4
Training loss: 0.08690200679190914
Validation loss: 2.3845204935196826

Epoch: 6| Step: 5
Training loss: 0.091054593695384
Validation loss: 2.413290631366813

Epoch: 6| Step: 6
Training loss: 0.12811465396047403
Validation loss: 2.4222889917190082

Epoch: 6| Step: 7
Training loss: 0.06742226440852085
Validation loss: 2.398747269061061

Epoch: 6| Step: 8
Training loss: 0.06558969845306149
Validation loss: 2.3709018195288496

Epoch: 6| Step: 9
Training loss: 0.0815051327943782
Validation loss: 2.4214366779504823

Epoch: 6| Step: 10
Training loss: 0.10274236597233186
Validation loss: 2.3949635885606995

Epoch: 6| Step: 11
Training loss: 0.1022508476194211
Validation loss: 2.417606943820006

Epoch: 6| Step: 12
Training loss: 0.09442970618971085
Validation loss: 2.4126715928332954

Epoch: 6| Step: 13
Training loss: 0.050837579534599504
Validation loss: 2.412227350566355

Epoch: 641| Step: 0
Training loss: 0.13376450139159649
Validation loss: 2.4158324775730646

Epoch: 6| Step: 1
Training loss: 0.07485339220090322
Validation loss: 2.4052339498740114

Epoch: 6| Step: 2
Training loss: 0.12096296446477398
Validation loss: 2.4161993256607177

Epoch: 6| Step: 3
Training loss: 0.08279392792167935
Validation loss: 2.4071277029261045

Epoch: 6| Step: 4
Training loss: 0.10412163853972392
Validation loss: 2.38732635447703

Epoch: 6| Step: 5
Training loss: 0.06143262382324276
Validation loss: 2.39234719014724

Epoch: 6| Step: 6
Training loss: 0.06673173516745506
Validation loss: 2.3870740616325397

Epoch: 6| Step: 7
Training loss: 0.08484836497760953
Validation loss: 2.4003145580030147

Epoch: 6| Step: 8
Training loss: 0.0744495630062676
Validation loss: 2.4211829417651516

Epoch: 6| Step: 9
Training loss: 0.0981926728788457
Validation loss: 2.384451424796056

Epoch: 6| Step: 10
Training loss: 0.08294060735372111
Validation loss: 2.401007951919669

Epoch: 6| Step: 11
Training loss: 0.13310976980065498
Validation loss: 2.37121384190803

Epoch: 6| Step: 12
Training loss: 0.07044753049620718
Validation loss: 2.3962038175483116

Epoch: 6| Step: 13
Training loss: 0.06501684253183346
Validation loss: 2.38016291878597

Epoch: 642| Step: 0
Training loss: 0.12938108554293576
Validation loss: 2.3940909564259565

Epoch: 6| Step: 1
Training loss: 0.0974467079844394
Validation loss: 2.395354314982433

Epoch: 6| Step: 2
Training loss: 0.07594643144908494
Validation loss: 2.402541896126149

Epoch: 6| Step: 3
Training loss: 0.0892442834897355
Validation loss: 2.404601021248667

Epoch: 6| Step: 4
Training loss: 0.0864285829596416
Validation loss: 2.4135872537388057

Epoch: 6| Step: 5
Training loss: 0.06056938791116727
Validation loss: 2.437157579786237

Epoch: 6| Step: 6
Training loss: 0.1107155485255599
Validation loss: 2.437417073360279

Epoch: 6| Step: 7
Training loss: 0.09755329426986203
Validation loss: 2.476809736872235

Epoch: 6| Step: 8
Training loss: 0.09255913024508593
Validation loss: 2.4369155544921215

Epoch: 6| Step: 9
Training loss: 0.10565677853931325
Validation loss: 2.442160058778182

Epoch: 6| Step: 10
Training loss: 0.08078405862349106
Validation loss: 2.4478031754394234

Epoch: 6| Step: 11
Training loss: 0.11287332950086743
Validation loss: 2.448479746873089

Epoch: 6| Step: 12
Training loss: 0.08779223020622717
Validation loss: 2.390526859811344

Epoch: 6| Step: 13
Training loss: 0.06180543455651996
Validation loss: 2.417481388698623

Epoch: 643| Step: 0
Training loss: 0.07222639771891932
Validation loss: 2.4348260270797284

Epoch: 6| Step: 1
Training loss: 0.15341240856407573
Validation loss: 2.430699930214922

Epoch: 6| Step: 2
Training loss: 0.05723547369737889
Validation loss: 2.4297443588067082

Epoch: 6| Step: 3
Training loss: 0.07871978960831043
Validation loss: 2.425197912233122

Epoch: 6| Step: 4
Training loss: 0.13437154759917838
Validation loss: 2.445979721647875

Epoch: 6| Step: 5
Training loss: 0.09042719390594914
Validation loss: 2.451910286291882

Epoch: 6| Step: 6
Training loss: 0.05605391500186622
Validation loss: 2.4314275806474446

Epoch: 6| Step: 7
Training loss: 0.11031251402144303
Validation loss: 2.4300308409640783

Epoch: 6| Step: 8
Training loss: 0.10397812698446116
Validation loss: 2.4288657319796587

Epoch: 6| Step: 9
Training loss: 0.14635791406098822
Validation loss: 2.4357035705956425

Epoch: 6| Step: 10
Training loss: 0.07931084087077878
Validation loss: 2.4088361951073907

Epoch: 6| Step: 11
Training loss: 0.09961425077435432
Validation loss: 2.3781769848732894

Epoch: 6| Step: 12
Training loss: 0.07816991111191618
Validation loss: 2.3855858672169727

Epoch: 6| Step: 13
Training loss: 0.08072751438336845
Validation loss: 2.3759070641257525

Epoch: 644| Step: 0
Training loss: 0.07821721952215907
Validation loss: 2.372141399557946

Epoch: 6| Step: 1
Training loss: 0.1081815216036801
Validation loss: 2.39438639244487

Epoch: 6| Step: 2
Training loss: 0.11665092250978956
Validation loss: 2.3626657306621417

Epoch: 6| Step: 3
Training loss: 0.20454623866111565
Validation loss: 2.3642180150083614

Epoch: 6| Step: 4
Training loss: 0.05054873180811355
Validation loss: 2.374050332631272

Epoch: 6| Step: 5
Training loss: 0.08844855498917438
Validation loss: 2.3684151603106347

Epoch: 6| Step: 6
Training loss: 0.07528560345121584
Validation loss: 2.4227380998913777

Epoch: 6| Step: 7
Training loss: 0.14934787655621246
Validation loss: 2.4446753251934705

Epoch: 6| Step: 8
Training loss: 0.08031754639278593
Validation loss: 2.446693902218536

Epoch: 6| Step: 9
Training loss: 0.12432016335538769
Validation loss: 2.4476871701445977

Epoch: 6| Step: 10
Training loss: 0.09150224946760269
Validation loss: 2.4490172537863635

Epoch: 6| Step: 11
Training loss: 0.1146751509158362
Validation loss: 2.430638417141657

Epoch: 6| Step: 12
Training loss: 0.0688739854775548
Validation loss: 2.4258218805813643

Epoch: 6| Step: 13
Training loss: 0.058159800780695596
Validation loss: 2.386882461849684

Epoch: 645| Step: 0
Training loss: 0.09938726251296968
Validation loss: 2.421570201989826

Epoch: 6| Step: 1
Training loss: 0.15052893087743976
Validation loss: 2.4051151201632077

Epoch: 6| Step: 2
Training loss: 0.11755083502463153
Validation loss: 2.417445863050845

Epoch: 6| Step: 3
Training loss: 0.13993585792504912
Validation loss: 2.393839230873407

Epoch: 6| Step: 4
Training loss: 0.11262202003423304
Validation loss: 2.3928521843446537

Epoch: 6| Step: 5
Training loss: 0.15242779687496216
Validation loss: 2.420793530166939

Epoch: 6| Step: 6
Training loss: 0.1231140679865254
Validation loss: 2.3772057187480238

Epoch: 6| Step: 7
Training loss: 0.11969389415324144
Validation loss: 2.3854948425880993

Epoch: 6| Step: 8
Training loss: 0.08976811874484815
Validation loss: 2.428302499002718

Epoch: 6| Step: 9
Training loss: 0.07887720739680928
Validation loss: 2.4157022854673715

Epoch: 6| Step: 10
Training loss: 0.1014877603698921
Validation loss: 2.384901749298907

Epoch: 6| Step: 11
Training loss: 0.15474597543319268
Validation loss: 2.365076981077538

Epoch: 6| Step: 12
Training loss: 0.09006835498249366
Validation loss: 2.4115234247855715

Epoch: 6| Step: 13
Training loss: 0.12008685217410923
Validation loss: 2.4197001483217195

Epoch: 646| Step: 0
Training loss: 0.11759779946103552
Validation loss: 2.3751390596707016

Epoch: 6| Step: 1
Training loss: 0.12301319660506631
Validation loss: 2.3867688446402764

Epoch: 6| Step: 2
Training loss: 0.07723011148100097
Validation loss: 2.3630070260708247

Epoch: 6| Step: 3
Training loss: 0.09360125782233034
Validation loss: 2.3298497704033476

Epoch: 6| Step: 4
Training loss: 0.10661541619866152
Validation loss: 2.3648184162124744

Epoch: 6| Step: 5
Training loss: 0.06432699375255893
Validation loss: 2.334667755569701

Epoch: 6| Step: 6
Training loss: 0.07453072694179044
Validation loss: 2.334503326203222

Epoch: 6| Step: 7
Training loss: 0.15399279388026565
Validation loss: 2.3553075578626435

Epoch: 6| Step: 8
Training loss: 0.14153968511399104
Validation loss: 2.349684507503825

Epoch: 6| Step: 9
Training loss: 0.14879339618936427
Validation loss: 2.3581732536428017

Epoch: 6| Step: 10
Training loss: 0.09017702154273687
Validation loss: 2.3858292624007693

Epoch: 6| Step: 11
Training loss: 0.0750063714658893
Validation loss: 2.3594948272928615

Epoch: 6| Step: 12
Training loss: 0.07421346068357208
Validation loss: 2.3915707516832674

Epoch: 6| Step: 13
Training loss: 0.06656788690578035
Validation loss: 2.410071778314183

Epoch: 647| Step: 0
Training loss: 0.08184776903446095
Validation loss: 2.3792980240656285

Epoch: 6| Step: 1
Training loss: 0.10003114677192679
Validation loss: 2.407025714923593

Epoch: 6| Step: 2
Training loss: 0.12853337313185137
Validation loss: 2.4066646385417254

Epoch: 6| Step: 3
Training loss: 0.0880142005442499
Validation loss: 2.374692349674259

Epoch: 6| Step: 4
Training loss: 0.1426618604507323
Validation loss: 2.4006414702995422

Epoch: 6| Step: 5
Training loss: 0.09438546698990999
Validation loss: 2.397584239165811

Epoch: 6| Step: 6
Training loss: 0.11327450419762408
Validation loss: 2.414076795016977

Epoch: 6| Step: 7
Training loss: 0.04985530702471608
Validation loss: 2.399055051128063

Epoch: 6| Step: 8
Training loss: 0.07408344018543245
Validation loss: 2.3911967024556797

Epoch: 6| Step: 9
Training loss: 0.08766152935483404
Validation loss: 2.371975348469644

Epoch: 6| Step: 10
Training loss: 0.14171282902033602
Validation loss: 2.389486946125798

Epoch: 6| Step: 11
Training loss: 0.0832883861393701
Validation loss: 2.385577324906181

Epoch: 6| Step: 12
Training loss: 0.09462673294988809
Validation loss: 2.421960904982537

Epoch: 6| Step: 13
Training loss: 0.07042566438166202
Validation loss: 2.443414926784758

Epoch: 648| Step: 0
Training loss: 0.10050866019539745
Validation loss: 2.4176189549889093

Epoch: 6| Step: 1
Training loss: 0.09857718154690358
Validation loss: 2.4334608572486407

Epoch: 6| Step: 2
Training loss: 0.08618379649634798
Validation loss: 2.44586632362127

Epoch: 6| Step: 3
Training loss: 0.13139747185479564
Validation loss: 2.454927254652839

Epoch: 6| Step: 4
Training loss: 0.11969834472787302
Validation loss: 2.446410998253151

Epoch: 6| Step: 5
Training loss: 0.07621794310123488
Validation loss: 2.4274532962665516

Epoch: 6| Step: 6
Training loss: 0.13214488387509743
Validation loss: 2.425167797540868

Epoch: 6| Step: 7
Training loss: 0.11086038575575265
Validation loss: 2.3915612081068955

Epoch: 6| Step: 8
Training loss: 0.09937596087471041
Validation loss: 2.403437550433194

Epoch: 6| Step: 9
Training loss: 0.11809099318432728
Validation loss: 2.3603607163572993

Epoch: 6| Step: 10
Training loss: 0.1396777849104616
Validation loss: 2.35241438551042

Epoch: 6| Step: 11
Training loss: 0.19046798712160642
Validation loss: 2.3740547406133667

Epoch: 6| Step: 12
Training loss: 0.08956760489742192
Validation loss: 2.405273398063858

Epoch: 6| Step: 13
Training loss: 0.0781924135701909
Validation loss: 2.3748171713836017

Epoch: 649| Step: 0
Training loss: 0.10512288214583432
Validation loss: 2.388859744210955

Epoch: 6| Step: 1
Training loss: 0.10765310024033187
Validation loss: 2.413649313956809

Epoch: 6| Step: 2
Training loss: 0.13169024859376627
Validation loss: 2.438685311719139

Epoch: 6| Step: 3
Training loss: 0.12618489006398573
Validation loss: 2.4557988492039193

Epoch: 6| Step: 4
Training loss: 0.07136099269625341
Validation loss: 2.4353445665614197

Epoch: 6| Step: 5
Training loss: 0.1209199180686208
Validation loss: 2.4370931407285457

Epoch: 6| Step: 6
Training loss: 0.10479609689186196
Validation loss: 2.463163893264771

Epoch: 6| Step: 7
Training loss: 0.11425465799525376
Validation loss: 2.4731621402856656

Epoch: 6| Step: 8
Training loss: 0.1021957736355226
Validation loss: 2.4805325541979544

Epoch: 6| Step: 9
Training loss: 0.08467643336890418
Validation loss: 2.431100670256301

Epoch: 6| Step: 10
Training loss: 0.09002864512588213
Validation loss: 2.436220165951348

Epoch: 6| Step: 11
Training loss: 0.1006836601649305
Validation loss: 2.43144612811757

Epoch: 6| Step: 12
Training loss: 0.0825235546417835
Validation loss: 2.405229888947187

Epoch: 6| Step: 13
Training loss: 0.0664873224326784
Validation loss: 2.4172856624058414

Epoch: 650| Step: 0
Training loss: 0.0563372800783694
Validation loss: 2.37541718372939

Epoch: 6| Step: 1
Training loss: 0.07206886155650234
Validation loss: 2.3894110727601205

Epoch: 6| Step: 2
Training loss: 0.16552132339557035
Validation loss: 2.3640717901789294

Epoch: 6| Step: 3
Training loss: 0.07429810096780189
Validation loss: 2.4141386329196446

Epoch: 6| Step: 4
Training loss: 0.08836745878236477
Validation loss: 2.423389872704865

Epoch: 6| Step: 5
Training loss: 0.11849803073520346
Validation loss: 2.452185302485493

Epoch: 6| Step: 6
Training loss: 0.0877746399532676
Validation loss: 2.4669013681918868

Epoch: 6| Step: 7
Training loss: 0.11091883193357105
Validation loss: 2.4376310613550336

Epoch: 6| Step: 8
Training loss: 0.1275898007331292
Validation loss: 2.469242936155945

Epoch: 6| Step: 9
Training loss: 0.09312844365268531
Validation loss: 2.444803313263357

Epoch: 6| Step: 10
Training loss: 0.06176995661080126
Validation loss: 2.4460789981211093

Epoch: 6| Step: 11
Training loss: 0.12875153186497884
Validation loss: 2.3968954791322434

Epoch: 6| Step: 12
Training loss: 0.09086286409358632
Validation loss: 2.376567167003919

Epoch: 6| Step: 13
Training loss: 0.14039761650580285
Validation loss: 2.360443423128699

Epoch: 651| Step: 0
Training loss: 0.07964525751030382
Validation loss: 2.371491492303665

Epoch: 6| Step: 1
Training loss: 0.09170208764996632
Validation loss: 2.3509067445126615

Epoch: 6| Step: 2
Training loss: 0.09146276503812961
Validation loss: 2.3337687948143397

Epoch: 6| Step: 3
Training loss: 0.09168836592373918
Validation loss: 2.3762958803768788

Epoch: 6| Step: 4
Training loss: 0.08857129164699028
Validation loss: 2.3787497714772514

Epoch: 6| Step: 5
Training loss: 0.12150524962798154
Validation loss: 2.3749970310324313

Epoch: 6| Step: 6
Training loss: 0.07847807197296347
Validation loss: 2.409500996428099

Epoch: 6| Step: 7
Training loss: 0.1243785782100427
Validation loss: 2.4353239512983604

Epoch: 6| Step: 8
Training loss: 0.12392598175441433
Validation loss: 2.4144478039854156

Epoch: 6| Step: 9
Training loss: 0.0928774100481268
Validation loss: 2.4013434658565234

Epoch: 6| Step: 10
Training loss: 0.06365097366899869
Validation loss: 2.4213165094426645

Epoch: 6| Step: 11
Training loss: 0.0812557209274946
Validation loss: 2.4653089807216775

Epoch: 6| Step: 12
Training loss: 0.13946157237521664
Validation loss: 2.389346465094515

Epoch: 6| Step: 13
Training loss: 0.11632615476519219
Validation loss: 2.376714315469071

Epoch: 652| Step: 0
Training loss: 0.07356662102404964
Validation loss: 2.350254154796347

Epoch: 6| Step: 1
Training loss: 0.11690432189630125
Validation loss: 2.379194337740576

Epoch: 6| Step: 2
Training loss: 0.1176051327429467
Validation loss: 2.366679605462794

Epoch: 6| Step: 3
Training loss: 0.1030024864619435
Validation loss: 2.4307464380114587

Epoch: 6| Step: 4
Training loss: 0.10078443921388064
Validation loss: 2.401773470208804

Epoch: 6| Step: 5
Training loss: 0.07959325174629522
Validation loss: 2.411668299007081

Epoch: 6| Step: 6
Training loss: 0.08130468456264273
Validation loss: 2.379868060022636

Epoch: 6| Step: 7
Training loss: 0.1312428733616562
Validation loss: 2.424998413565797

Epoch: 6| Step: 8
Training loss: 0.08058584730075775
Validation loss: 2.4108744902104755

Epoch: 6| Step: 9
Training loss: 0.056097022046818774
Validation loss: 2.406795629489665

Epoch: 6| Step: 10
Training loss: 0.0676660940880306
Validation loss: 2.423083851222885

Epoch: 6| Step: 11
Training loss: 0.06143272425859175
Validation loss: 2.4019104119967984

Epoch: 6| Step: 12
Training loss: 0.1274092622755945
Validation loss: 2.4018597525891607

Epoch: 6| Step: 13
Training loss: 0.09281103476578324
Validation loss: 2.4173815380301202

Epoch: 653| Step: 0
Training loss: 0.06901465783792043
Validation loss: 2.4257729327263835

Epoch: 6| Step: 1
Training loss: 0.09721674246142258
Validation loss: 2.426764815402871

Epoch: 6| Step: 2
Training loss: 0.1429694240846012
Validation loss: 2.393443742393919

Epoch: 6| Step: 3
Training loss: 0.10233171479607651
Validation loss: 2.452778337327655

Epoch: 6| Step: 4
Training loss: 0.055107111946030754
Validation loss: 2.409570758972158

Epoch: 6| Step: 5
Training loss: 0.06248483995515988
Validation loss: 2.437012708118869

Epoch: 6| Step: 6
Training loss: 0.06910468880981593
Validation loss: 2.420622725151559

Epoch: 6| Step: 7
Training loss: 0.08901997939888401
Validation loss: 2.4243187786816414

Epoch: 6| Step: 8
Training loss: 0.09438815577023715
Validation loss: 2.4362568605163974

Epoch: 6| Step: 9
Training loss: 0.06957562080963711
Validation loss: 2.425649962682776

Epoch: 6| Step: 10
Training loss: 0.07817358056243068
Validation loss: 2.4265858193415992

Epoch: 6| Step: 11
Training loss: 0.0680788551450759
Validation loss: 2.438560194271801

Epoch: 6| Step: 12
Training loss: 0.04660717127830571
Validation loss: 2.457108899907229

Epoch: 6| Step: 13
Training loss: 0.06009428003030795
Validation loss: 2.4111591682347115

Epoch: 654| Step: 0
Training loss: 0.04922186410225806
Validation loss: 2.413165654546568

Epoch: 6| Step: 1
Training loss: 0.13771220705534945
Validation loss: 2.4399020714913795

Epoch: 6| Step: 2
Training loss: 0.07165806129660084
Validation loss: 2.4196122018934543

Epoch: 6| Step: 3
Training loss: 0.08294208954061764
Validation loss: 2.4370876622939246

Epoch: 6| Step: 4
Training loss: 0.07981192724482428
Validation loss: 2.44392378808352

Epoch: 6| Step: 5
Training loss: 0.08257254190076377
Validation loss: 2.4612392956025078

Epoch: 6| Step: 6
Training loss: 0.05914812686399233
Validation loss: 2.403085442356709

Epoch: 6| Step: 7
Training loss: 0.05673893461983814
Validation loss: 2.4509501773798363

Epoch: 6| Step: 8
Training loss: 0.12130633659639775
Validation loss: 2.4205510125130645

Epoch: 6| Step: 9
Training loss: 0.07413607623091542
Validation loss: 2.4351599656584515

Epoch: 6| Step: 10
Training loss: 0.08123985362430844
Validation loss: 2.4223231181218727

Epoch: 6| Step: 11
Training loss: 0.1112104304067281
Validation loss: 2.458430287441253

Epoch: 6| Step: 12
Training loss: 0.08873081223162958
Validation loss: 2.4384418957377654

Epoch: 6| Step: 13
Training loss: 0.03429028974356764
Validation loss: 2.4237112450906206

Epoch: 655| Step: 0
Training loss: 0.1306548299221847
Validation loss: 2.4461018494180413

Epoch: 6| Step: 1
Training loss: 0.08766914648495461
Validation loss: 2.397630216899794

Epoch: 6| Step: 2
Training loss: 0.10173980659751862
Validation loss: 2.419610709021676

Epoch: 6| Step: 3
Training loss: 0.04857627529534978
Validation loss: 2.3736044977999073

Epoch: 6| Step: 4
Training loss: 0.05477190741476394
Validation loss: 2.383955621494293

Epoch: 6| Step: 5
Training loss: 0.07853414568550905
Validation loss: 2.410745627609757

Epoch: 6| Step: 6
Training loss: 0.09330028715076702
Validation loss: 2.392024313321716

Epoch: 6| Step: 7
Training loss: 0.12743521635143146
Validation loss: 2.4209688320669707

Epoch: 6| Step: 8
Training loss: 0.0838810901063541
Validation loss: 2.429811581390829

Epoch: 6| Step: 9
Training loss: 0.06580491437695117
Validation loss: 2.402484369518526

Epoch: 6| Step: 10
Training loss: 0.07858372956210095
Validation loss: 2.4297293778217144

Epoch: 6| Step: 11
Training loss: 0.09198024372551701
Validation loss: 2.4330496294211836

Epoch: 6| Step: 12
Training loss: 0.10370134391881759
Validation loss: 2.4153748653374225

Epoch: 6| Step: 13
Training loss: 0.048429127323328075
Validation loss: 2.440262041285861

Epoch: 656| Step: 0
Training loss: 0.09176108494522221
Validation loss: 2.4240682641507276

Epoch: 6| Step: 1
Training loss: 0.08676654641177228
Validation loss: 2.4273646406118496

Epoch: 6| Step: 2
Training loss: 0.08693135550263073
Validation loss: 2.4070116661328895

Epoch: 6| Step: 3
Training loss: 0.11574221095723157
Validation loss: 2.4325632249974944

Epoch: 6| Step: 4
Training loss: 0.10528625488104337
Validation loss: 2.4157143931276943

Epoch: 6| Step: 5
Training loss: 0.10892739840424213
Validation loss: 2.404823357604679

Epoch: 6| Step: 6
Training loss: 0.09311664242172443
Validation loss: 2.418371960635841

Epoch: 6| Step: 7
Training loss: 0.08363813175780374
Validation loss: 2.3807497485611027

Epoch: 6| Step: 8
Training loss: 0.1401876828766037
Validation loss: 2.40188211360389

Epoch: 6| Step: 9
Training loss: 0.08169862031090502
Validation loss: 2.4217284190966013

Epoch: 6| Step: 10
Training loss: 0.06496570964174474
Validation loss: 2.3642789308576346

Epoch: 6| Step: 11
Training loss: 0.11697285385739356
Validation loss: 2.367162978811073

Epoch: 6| Step: 12
Training loss: 0.07751601210468492
Validation loss: 2.3784487888096093

Epoch: 6| Step: 13
Training loss: 0.0710961625716862
Validation loss: 2.3982712236193926

Epoch: 657| Step: 0
Training loss: 0.09994098218179669
Validation loss: 2.340147487205376

Epoch: 6| Step: 1
Training loss: 0.07802383309918433
Validation loss: 2.381195015359003

Epoch: 6| Step: 2
Training loss: 0.07856257799754675
Validation loss: 2.361461991203072

Epoch: 6| Step: 3
Training loss: 0.08627513374599706
Validation loss: 2.343080044501364

Epoch: 6| Step: 4
Training loss: 0.06265523378161679
Validation loss: 2.330057157668956

Epoch: 6| Step: 5
Training loss: 0.09488856826229133
Validation loss: 2.3694176462686167

Epoch: 6| Step: 6
Training loss: 0.06638308780299265
Validation loss: 2.3557566339955094

Epoch: 6| Step: 7
Training loss: 0.05767813183005312
Validation loss: 2.4008460270902297

Epoch: 6| Step: 8
Training loss: 0.1059365582353935
Validation loss: 2.361084907160328

Epoch: 6| Step: 9
Training loss: 0.11356088227078706
Validation loss: 2.376830059244237

Epoch: 6| Step: 10
Training loss: 0.08373907772410925
Validation loss: 2.3998245451142255

Epoch: 6| Step: 11
Training loss: 0.07325364341153696
Validation loss: 2.381237231651979

Epoch: 6| Step: 12
Training loss: 0.08380363666611369
Validation loss: 2.415099746322975

Epoch: 6| Step: 13
Training loss: 0.12197871777245298
Validation loss: 2.4129870863727545

Epoch: 658| Step: 0
Training loss: 0.07490371543692627
Validation loss: 2.416320069069185

Epoch: 6| Step: 1
Training loss: 0.07770519116115271
Validation loss: 2.3784836544401546

Epoch: 6| Step: 2
Training loss: 0.10124240004161511
Validation loss: 2.380894443023845

Epoch: 6| Step: 3
Training loss: 0.08116021238663738
Validation loss: 2.3916523137804746

Epoch: 6| Step: 4
Training loss: 0.1069476584325531
Validation loss: 2.3816046122621937

Epoch: 6| Step: 5
Training loss: 0.10846575803045438
Validation loss: 2.3906905307162174

Epoch: 6| Step: 6
Training loss: 0.07136588986474547
Validation loss: 2.4286206910548764

Epoch: 6| Step: 7
Training loss: 0.0638226136275929
Validation loss: 2.400833082028839

Epoch: 6| Step: 8
Training loss: 0.0871938904860872
Validation loss: 2.3614980599723907

Epoch: 6| Step: 9
Training loss: 0.0865000604949034
Validation loss: 2.3704319282485318

Epoch: 6| Step: 10
Training loss: 0.11837824019606745
Validation loss: 2.4143827726152436

Epoch: 6| Step: 11
Training loss: 0.09533265479192031
Validation loss: 2.4183411564307526

Epoch: 6| Step: 12
Training loss: 0.09038607037740048
Validation loss: 2.40506248965828

Epoch: 6| Step: 13
Training loss: 0.07050327407939849
Validation loss: 2.3968427873976323

Epoch: 659| Step: 0
Training loss: 0.07799937758021645
Validation loss: 2.3965570559639375

Epoch: 6| Step: 1
Training loss: 0.06595249684578493
Validation loss: 2.412105690196581

Epoch: 6| Step: 2
Training loss: 0.07716583104166927
Validation loss: 2.3720865962672524

Epoch: 6| Step: 3
Training loss: 0.07045268283721318
Validation loss: 2.408080609784891

Epoch: 6| Step: 4
Training loss: 0.07767933449640511
Validation loss: 2.4106138409954783

Epoch: 6| Step: 5
Training loss: 0.07124327796254588
Validation loss: 2.3886865709587055

Epoch: 6| Step: 6
Training loss: 0.09338779316215215
Validation loss: 2.4180713096191004

Epoch: 6| Step: 7
Training loss: 0.08202212430511542
Validation loss: 2.411417053914026

Epoch: 6| Step: 8
Training loss: 0.12286390597340133
Validation loss: 2.3693607955964175

Epoch: 6| Step: 9
Training loss: 0.10021970333047986
Validation loss: 2.354386344357125

Epoch: 6| Step: 10
Training loss: 0.07139536365604628
Validation loss: 2.376338628987142

Epoch: 6| Step: 11
Training loss: 0.10029277857211764
Validation loss: 2.390727692479559

Epoch: 6| Step: 12
Training loss: 0.10775113795563529
Validation loss: 2.3940683341743654

Epoch: 6| Step: 13
Training loss: 0.1015698219374321
Validation loss: 2.336653852505602

Epoch: 660| Step: 0
Training loss: 0.07223873024587818
Validation loss: 2.376782578411785

Epoch: 6| Step: 1
Training loss: 0.07263572105467209
Validation loss: 2.3910262588581963

Epoch: 6| Step: 2
Training loss: 0.08895506548611849
Validation loss: 2.348698045654711

Epoch: 6| Step: 3
Training loss: 0.07117428423261518
Validation loss: 2.375633788804169

Epoch: 6| Step: 4
Training loss: 0.050439389977503316
Validation loss: 2.3989821327342695

Epoch: 6| Step: 5
Training loss: 0.07054382260584903
Validation loss: 2.376225415503241

Epoch: 6| Step: 6
Training loss: 0.12468151034522504
Validation loss: 2.40483136356032

Epoch: 6| Step: 7
Training loss: 0.132551237795618
Validation loss: 2.399502029124301

Epoch: 6| Step: 8
Training loss: 0.09879223526203508
Validation loss: 2.3804811689421865

Epoch: 6| Step: 9
Training loss: 0.14231655871342008
Validation loss: 2.3771562055343765

Epoch: 6| Step: 10
Training loss: 0.09072358610335728
Validation loss: 2.4359183500481567

Epoch: 6| Step: 11
Training loss: 0.11552963980088429
Validation loss: 2.3740162622818977

Epoch: 6| Step: 12
Training loss: 0.07644050863743777
Validation loss: 2.3747565398890527

Epoch: 6| Step: 13
Training loss: 0.06527908985586872
Validation loss: 2.3914806023327517

Epoch: 661| Step: 0
Training loss: 0.08107917484692503
Validation loss: 2.3689819712407454

Epoch: 6| Step: 1
Training loss: 0.07136356693264721
Validation loss: 2.3799356578272244

Epoch: 6| Step: 2
Training loss: 0.08986899808969735
Validation loss: 2.3791040496950697

Epoch: 6| Step: 3
Training loss: 0.13003771729946637
Validation loss: 2.410041034493644

Epoch: 6| Step: 4
Training loss: 0.0756921424959848
Validation loss: 2.417297845387789

Epoch: 6| Step: 5
Training loss: 0.09354953393300151
Validation loss: 2.420890100009225

Epoch: 6| Step: 6
Training loss: 0.09027817641479968
Validation loss: 2.423785397422699

Epoch: 6| Step: 7
Training loss: 0.12605029173835788
Validation loss: 2.3864180762829723

Epoch: 6| Step: 8
Training loss: 0.13031431812051775
Validation loss: 2.411079653590842

Epoch: 6| Step: 9
Training loss: 0.06517748479242942
Validation loss: 2.4125172979929235

Epoch: 6| Step: 10
Training loss: 0.05066898205150998
Validation loss: 2.4202327986546934

Epoch: 6| Step: 11
Training loss: 0.10246429896685215
Validation loss: 2.379229443774658

Epoch: 6| Step: 12
Training loss: 0.09964767355571842
Validation loss: 2.4035441421849457

Epoch: 6| Step: 13
Training loss: 0.10342351846329995
Validation loss: 2.416325865135763

Epoch: 662| Step: 0
Training loss: 0.09440516978040134
Validation loss: 2.427252143088582

Epoch: 6| Step: 1
Training loss: 0.11247509177289629
Validation loss: 2.4084275994039155

Epoch: 6| Step: 2
Training loss: 0.11746553181783567
Validation loss: 2.3980865945983934

Epoch: 6| Step: 3
Training loss: 0.07480319696440381
Validation loss: 2.384859118708764

Epoch: 6| Step: 4
Training loss: 0.07154488712230905
Validation loss: 2.37968501936145

Epoch: 6| Step: 5
Training loss: 0.10766701903275698
Validation loss: 2.4041548206379226

Epoch: 6| Step: 6
Training loss: 0.0787686063341869
Validation loss: 2.3578037472926177

Epoch: 6| Step: 7
Training loss: 0.06074145414762202
Validation loss: 2.3795165717662434

Epoch: 6| Step: 8
Training loss: 0.09886849920607682
Validation loss: 2.3595194754358446

Epoch: 6| Step: 9
Training loss: 0.0976501939803129
Validation loss: 2.3351693309674078

Epoch: 6| Step: 10
Training loss: 0.0629659879400509
Validation loss: 2.343152916986488

Epoch: 6| Step: 11
Training loss: 0.06241054204955378
Validation loss: 2.358733231360623

Epoch: 6| Step: 12
Training loss: 0.14551570410098066
Validation loss: 2.3431780362646344

Epoch: 6| Step: 13
Training loss: 0.09678903811229153
Validation loss: 2.334456426933831

Epoch: 663| Step: 0
Training loss: 0.06577064510792695
Validation loss: 2.341719068621053

Epoch: 6| Step: 1
Training loss: 0.07720609514289939
Validation loss: 2.338281803714791

Epoch: 6| Step: 2
Training loss: 0.08628514264115407
Validation loss: 2.3658480839401905

Epoch: 6| Step: 3
Training loss: 0.09598244563241899
Validation loss: 2.347620458335019

Epoch: 6| Step: 4
Training loss: 0.09380487981493633
Validation loss: 2.4205651050493584

Epoch: 6| Step: 5
Training loss: 0.07223085262788038
Validation loss: 2.3774290271137404

Epoch: 6| Step: 6
Training loss: 0.12192786106563352
Validation loss: 2.399978767236151

Epoch: 6| Step: 7
Training loss: 0.09211079712045726
Validation loss: 2.379814133257435

Epoch: 6| Step: 8
Training loss: 0.14093574654996094
Validation loss: 2.407247389097785

Epoch: 6| Step: 9
Training loss: 0.07345390872054398
Validation loss: 2.382693256290659

Epoch: 6| Step: 10
Training loss: 0.054194042027322024
Validation loss: 2.3962342735110527

Epoch: 6| Step: 11
Training loss: 0.05634916888608227
Validation loss: 2.3938312256383245

Epoch: 6| Step: 12
Training loss: 0.11309485062703704
Validation loss: 2.346763467427651

Epoch: 6| Step: 13
Training loss: 0.0679707378885999
Validation loss: 2.372382442705422

Epoch: 664| Step: 0
Training loss: 0.10419436374640517
Validation loss: 2.3516596286654092

Epoch: 6| Step: 1
Training loss: 0.08937675451844025
Validation loss: 2.366563917720294

Epoch: 6| Step: 2
Training loss: 0.0677202490109042
Validation loss: 2.3511795524153962

Epoch: 6| Step: 3
Training loss: 0.10088494680659912
Validation loss: 2.356835471770305

Epoch: 6| Step: 4
Training loss: 0.09588748826647336
Validation loss: 2.3647181067891014

Epoch: 6| Step: 5
Training loss: 0.0779579910708184
Validation loss: 2.37849431405016

Epoch: 6| Step: 6
Training loss: 0.08037419944686346
Validation loss: 2.35078714959749

Epoch: 6| Step: 7
Training loss: 0.10520416645337384
Validation loss: 2.3603870818311976

Epoch: 6| Step: 8
Training loss: 0.08884008224784715
Validation loss: 2.3603489481918074

Epoch: 6| Step: 9
Training loss: 0.07422661112261891
Validation loss: 2.3847655852247267

Epoch: 6| Step: 10
Training loss: 0.1067125221295092
Validation loss: 2.380864825609212

Epoch: 6| Step: 11
Training loss: 0.08611958082036979
Validation loss: 2.3590739839884196

Epoch: 6| Step: 12
Training loss: 0.11389663865050267
Validation loss: 2.3464523454591726

Epoch: 6| Step: 13
Training loss: 0.06478211578902976
Validation loss: 2.36914794645891

Epoch: 665| Step: 0
Training loss: 0.0890580788987378
Validation loss: 2.3835424990450926

Epoch: 6| Step: 1
Training loss: 0.12136552676319105
Validation loss: 2.3781424556646344

Epoch: 6| Step: 2
Training loss: 0.13010630345352378
Validation loss: 2.3983716657402137

Epoch: 6| Step: 3
Training loss: 0.059265117075609434
Validation loss: 2.392736495608871

Epoch: 6| Step: 4
Training loss: 0.1007796246745028
Validation loss: 2.4042474921183263

Epoch: 6| Step: 5
Training loss: 0.07442273167051638
Validation loss: 2.426591864515575

Epoch: 6| Step: 6
Training loss: 0.06850371109305535
Validation loss: 2.3916129941199844

Epoch: 6| Step: 7
Training loss: 0.09816492637408994
Validation loss: 2.4043961356503063

Epoch: 6| Step: 8
Training loss: 0.11467656403043203
Validation loss: 2.41114440191375

Epoch: 6| Step: 9
Training loss: 0.15202645736306944
Validation loss: 2.385890827769683

Epoch: 6| Step: 10
Training loss: 0.06670253935293424
Validation loss: 2.4065121892864956

Epoch: 6| Step: 11
Training loss: 0.08751655287932651
Validation loss: 2.360294661813428

Epoch: 6| Step: 12
Training loss: 0.10145032171133282
Validation loss: 2.34745204530806

Epoch: 6| Step: 13
Training loss: 0.0692793890890693
Validation loss: 2.329625986712368

Epoch: 666| Step: 0
Training loss: 0.09555722812945652
Validation loss: 2.339448757887138

Epoch: 6| Step: 1
Training loss: 0.14014517861593231
Validation loss: 2.3685356302123917

Epoch: 6| Step: 2
Training loss: 0.10983848291903481
Validation loss: 2.335517702083964

Epoch: 6| Step: 3
Training loss: 0.09641047767538284
Validation loss: 2.345906038869186

Epoch: 6| Step: 4
Training loss: 0.07805346253519843
Validation loss: 2.3988794778193867

Epoch: 6| Step: 5
Training loss: 0.09261677212986019
Validation loss: 2.4232205614949804

Epoch: 6| Step: 6
Training loss: 0.11418734113403443
Validation loss: 2.4177802087232148

Epoch: 6| Step: 7
Training loss: 0.04211208780198922
Validation loss: 2.386244458324401

Epoch: 6| Step: 8
Training loss: 0.06135681841764662
Validation loss: 2.426828656404939

Epoch: 6| Step: 9
Training loss: 0.14020074318873846
Validation loss: 2.413708059838147

Epoch: 6| Step: 10
Training loss: 0.08217256159150112
Validation loss: 2.3835500811863484

Epoch: 6| Step: 11
Training loss: 0.11242399512592167
Validation loss: 2.407382915197998

Epoch: 6| Step: 12
Training loss: 0.09362691010836387
Validation loss: 2.386250051337917

Epoch: 6| Step: 13
Training loss: 0.06004087450349589
Validation loss: 2.4170701097158704

Epoch: 667| Step: 0
Training loss: 0.08715029287906634
Validation loss: 2.4247665392691213

Epoch: 6| Step: 1
Training loss: 0.10504649104459976
Validation loss: 2.3955968321874406

Epoch: 6| Step: 2
Training loss: 0.10550531442277228
Validation loss: 2.4125713794555557

Epoch: 6| Step: 3
Training loss: 0.07844009039883484
Validation loss: 2.355017882131754

Epoch: 6| Step: 4
Training loss: 0.11887484359405008
Validation loss: 2.414329177702659

Epoch: 6| Step: 5
Training loss: 0.1394949850198728
Validation loss: 2.4182135504286215

Epoch: 6| Step: 6
Training loss: 0.1119373200834182
Validation loss: 2.435335825083792

Epoch: 6| Step: 7
Training loss: 0.14227610436880447
Validation loss: 2.428062433365371

Epoch: 6| Step: 8
Training loss: 0.10458121562456339
Validation loss: 2.4072452740710695

Epoch: 6| Step: 9
Training loss: 0.08713870538345167
Validation loss: 2.4183112603352086

Epoch: 6| Step: 10
Training loss: 0.10014517981815493
Validation loss: 2.365182400004307

Epoch: 6| Step: 11
Training loss: 0.069412457861356
Validation loss: 2.3741902458945736

Epoch: 6| Step: 12
Training loss: 0.1299666514171061
Validation loss: 2.3816027360366587

Epoch: 6| Step: 13
Training loss: 0.08825339314563976
Validation loss: 2.3744511706884524

Epoch: 668| Step: 0
Training loss: 0.10572185874763615
Validation loss: 2.3603377561612477

Epoch: 6| Step: 1
Training loss: 0.06756173097616561
Validation loss: 2.33522411689656

Epoch: 6| Step: 2
Training loss: 0.06511687472611011
Validation loss: 2.3553756020382792

Epoch: 6| Step: 3
Training loss: 0.07223677059139667
Validation loss: 2.3638641378956864

Epoch: 6| Step: 4
Training loss: 0.11739103602643704
Validation loss: 2.335461318201994

Epoch: 6| Step: 5
Training loss: 0.12332725370034801
Validation loss: 2.346942694276634

Epoch: 6| Step: 6
Training loss: 0.11195524000737554
Validation loss: 2.3305510401939205

Epoch: 6| Step: 7
Training loss: 0.10267181431633993
Validation loss: 2.333212695174734

Epoch: 6| Step: 8
Training loss: 0.09896715547320853
Validation loss: 2.3442613302321185

Epoch: 6| Step: 9
Training loss: 0.0911780765813763
Validation loss: 2.344381532526583

Epoch: 6| Step: 10
Training loss: 0.0665081308510276
Validation loss: 2.3398177446957478

Epoch: 6| Step: 11
Training loss: 0.11722888215873764
Validation loss: 2.372052289664242

Epoch: 6| Step: 12
Training loss: 0.051648514883594766
Validation loss: 2.3483127243098467

Epoch: 6| Step: 13
Training loss: 0.05729470077882912
Validation loss: 2.3991617702696932

Epoch: 669| Step: 0
Training loss: 0.08252818158196999
Validation loss: 2.4090252711692184

Epoch: 6| Step: 1
Training loss: 0.10306385261215972
Validation loss: 2.3908920299807157

Epoch: 6| Step: 2
Training loss: 0.06578638577743523
Validation loss: 2.4132252957945766

Epoch: 6| Step: 3
Training loss: 0.08579561593537478
Validation loss: 2.3823367763713823

Epoch: 6| Step: 4
Training loss: 0.11447655695068662
Validation loss: 2.411362744563943

Epoch: 6| Step: 5
Training loss: 0.09379441977234006
Validation loss: 2.4271313203386753

Epoch: 6| Step: 6
Training loss: 0.08495717204727418
Validation loss: 2.4086738399644037

Epoch: 6| Step: 7
Training loss: 0.08017406879970576
Validation loss: 2.4093145718157665

Epoch: 6| Step: 8
Training loss: 0.11799282087342837
Validation loss: 2.401756540199402

Epoch: 6| Step: 9
Training loss: 0.07905830566302494
Validation loss: 2.4207922932448347

Epoch: 6| Step: 10
Training loss: 0.1163993558186226
Validation loss: 2.430530199503642

Epoch: 6| Step: 11
Training loss: 0.08003282719588135
Validation loss: 2.405626715683773

Epoch: 6| Step: 12
Training loss: 0.09372480868598305
Validation loss: 2.4295278121552712

Epoch: 6| Step: 13
Training loss: 0.07154232917351881
Validation loss: 2.3907210290334624

Epoch: 670| Step: 0
Training loss: 0.13425459235521958
Validation loss: 2.3857496471348094

Epoch: 6| Step: 1
Training loss: 0.08025784793586732
Validation loss: 2.4022456296739514

Epoch: 6| Step: 2
Training loss: 0.11248907211661015
Validation loss: 2.3599726140046404

Epoch: 6| Step: 3
Training loss: 0.06763851328624637
Validation loss: 2.330358049456835

Epoch: 6| Step: 4
Training loss: 0.22732279900563807
Validation loss: 2.337536300255359

Epoch: 6| Step: 5
Training loss: 0.1013796655328609
Validation loss: 2.3010246300921153

Epoch: 6| Step: 6
Training loss: 0.18620919924789556
Validation loss: 2.267893241975116

Epoch: 6| Step: 7
Training loss: 0.31493504244267007
Validation loss: 2.221670429580513

Epoch: 6| Step: 8
Training loss: 0.13531608391788333
Validation loss: 2.3599811984827634

Epoch: 6| Step: 9
Training loss: 0.14669660452904384
Validation loss: 2.4744278235721406

Epoch: 6| Step: 10
Training loss: 0.47891082014731595
Validation loss: 2.527219961370343

Epoch: 6| Step: 11
Training loss: 0.10678497420462664
Validation loss: 2.4247586361392037

Epoch: 6| Step: 12
Training loss: 0.23185017742076566
Validation loss: 2.279652726199734

Epoch: 6| Step: 13
Training loss: 0.2746473793440189
Validation loss: 2.2824365213507565

Epoch: 671| Step: 0
Training loss: 0.28372207974772945
Validation loss: 2.2828545012236865

Epoch: 6| Step: 1
Training loss: 0.2936642973242628
Validation loss: 2.3506868401615444

Epoch: 6| Step: 2
Training loss: 0.23347830902105018
Validation loss: 2.4879310600901756

Epoch: 6| Step: 3
Training loss: 0.48715362041971794
Validation loss: 2.536665878872511

Epoch: 6| Step: 4
Training loss: 0.35782773264482026
Validation loss: 2.5326327961781674

Epoch: 6| Step: 5
Training loss: 0.4794516148076446
Validation loss: 2.462757042794653

Epoch: 6| Step: 6
Training loss: 0.40559921958592443
Validation loss: 2.392082316541781

Epoch: 6| Step: 7
Training loss: 0.4938003212600565
Validation loss: 2.2893100598918825

Epoch: 6| Step: 8
Training loss: 0.2819350033478073
Validation loss: 2.3279870986151776

Epoch: 6| Step: 9
Training loss: 0.4231889889338369
Validation loss: 2.3977260166954593

Epoch: 6| Step: 10
Training loss: 0.5713890575047472
Validation loss: 2.530788468174165

Epoch: 6| Step: 11
Training loss: 0.8879423060147151
Validation loss: 2.581923897857089

Epoch: 6| Step: 12
Training loss: 0.7127729762992511
Validation loss: 2.5924614657153784

Epoch: 6| Step: 13
Training loss: 0.8570782574651836
Validation loss: 2.587734602104009

Epoch: 672| Step: 0
Training loss: 1.2603308067817725
Validation loss: 2.5524597379261365

Epoch: 6| Step: 1
Training loss: 0.421963311594895
Validation loss: 2.4081132043973033

Epoch: 6| Step: 2
Training loss: 0.45992828058830226
Validation loss: 2.4218128483498584

Epoch: 6| Step: 3
Training loss: 0.7927677294367523
Validation loss: 2.614158470999272

Epoch: 6| Step: 4
Training loss: 0.8244648787384417
Validation loss: 2.5802484522416433

Epoch: 6| Step: 5
Training loss: 0.5309341557640473
Validation loss: 2.6438715603266636

Epoch: 6| Step: 6
Training loss: 1.0416544087006627
Validation loss: 2.5534138003850124

Epoch: 6| Step: 7
Training loss: 0.7219272545071082
Validation loss: 2.2913576098553037

Epoch: 6| Step: 8
Training loss: 1.0231287250206307
Validation loss: 2.217214329924243

Epoch: 6| Step: 9
Training loss: 0.8501626153675025
Validation loss: 2.1849965761354557

Epoch: 6| Step: 10
Training loss: 0.9251069780297062
Validation loss: 2.185747060698732

Epoch: 6| Step: 11
Training loss: 0.9612368295806538
Validation loss: 2.193914758561354

Epoch: 6| Step: 12
Training loss: 0.48152235857725945
Validation loss: 2.3730650480070716

Epoch: 6| Step: 13
Training loss: 0.8124065712251207
Validation loss: 2.5854220115539808

Epoch: 673| Step: 0
Training loss: 1.1445627566222574
Validation loss: 2.7661935777875923

Epoch: 6| Step: 1
Training loss: 1.1797820804904138
Validation loss: 2.78074882796974

Epoch: 6| Step: 2
Training loss: 0.9487951455916009
Validation loss: 2.6214690478231613

Epoch: 6| Step: 3
Training loss: 0.6704180689912224
Validation loss: 2.528425432627703

Epoch: 6| Step: 4
Training loss: 0.5011812502072588
Validation loss: 2.456368395396769

Epoch: 6| Step: 5
Training loss: 0.9330642667144622
Validation loss: 2.4163627376818626

Epoch: 6| Step: 6
Training loss: 0.9264402981177807
Validation loss: 2.4349930542089204

Epoch: 6| Step: 7
Training loss: 1.1477568808855991
Validation loss: 2.4393493014943433

Epoch: 6| Step: 8
Training loss: 1.2168420872011376
Validation loss: 2.451955223899761

Epoch: 6| Step: 9
Training loss: 1.0801370614994914
Validation loss: 2.522258245652904

Epoch: 6| Step: 10
Training loss: 0.6795787724315183
Validation loss: 2.5304174660654297

Epoch: 6| Step: 11
Training loss: 0.7445144315182974
Validation loss: 2.532719179550096

Epoch: 6| Step: 12
Training loss: 0.6929399538131762
Validation loss: 2.5554503095126035

Epoch: 6| Step: 13
Training loss: 1.242017194481475
Validation loss: 2.5834451374017218

Epoch: 674| Step: 0
Training loss: 0.633260309459983
Validation loss: 2.63638542009871

Epoch: 6| Step: 1
Training loss: 0.664061310710964
Validation loss: 2.604323544278779

Epoch: 6| Step: 2
Training loss: 0.780464311344634
Validation loss: 2.5956458644961176

Epoch: 6| Step: 3
Training loss: 1.2158671297305141
Validation loss: 2.6541105433451055

Epoch: 6| Step: 4
Training loss: 0.7978293743806972
Validation loss: 2.4923244987330695

Epoch: 6| Step: 5
Training loss: 0.5303521141852382
Validation loss: 2.37831447365524

Epoch: 6| Step: 6
Training loss: 0.8173766141631398
Validation loss: 2.3405456322942566

Epoch: 6| Step: 7
Training loss: 0.8338965698046296
Validation loss: 2.355262900406004

Epoch: 6| Step: 8
Training loss: 0.4078790939153656
Validation loss: 2.3837407174060803

Epoch: 6| Step: 9
Training loss: 1.023220301286832
Validation loss: 2.3778121460663284

Epoch: 6| Step: 10
Training loss: 0.9318886352810506
Validation loss: 2.3802003321581937

Epoch: 6| Step: 11
Training loss: 1.0097068312036164
Validation loss: 2.3862727756406343

Epoch: 6| Step: 12
Training loss: 0.8982207327028738
Validation loss: 2.4252340219921273

Epoch: 6| Step: 13
Training loss: 1.057553839789708
Validation loss: 2.4275259170448966

Epoch: 675| Step: 0
Training loss: 0.8663370584664929
Validation loss: 2.513345686399453

Epoch: 6| Step: 1
Training loss: 0.7193354005627748
Validation loss: 2.5499376034004366

Epoch: 6| Step: 2
Training loss: 0.6997417859259408
Validation loss: 2.562065441822306

Epoch: 6| Step: 3
Training loss: 0.6503079565165383
Validation loss: 2.5263533624567693

Epoch: 6| Step: 4
Training loss: 0.7716803965641318
Validation loss: 2.509323491419236

Epoch: 6| Step: 5
Training loss: 0.658437760637736
Validation loss: 2.4279733153054646

Epoch: 6| Step: 6
Training loss: 0.8183619970311515
Validation loss: 2.337516891385998

Epoch: 6| Step: 7
Training loss: 1.134341346094388
Validation loss: 2.3736885499968827

Epoch: 6| Step: 8
Training loss: 0.6833476032147222
Validation loss: 2.411681141793911

Epoch: 6| Step: 9
Training loss: 1.1061571761159013
Validation loss: 2.4516394878663976

Epoch: 6| Step: 10
Training loss: 0.7474967985818238
Validation loss: 2.473453707996214

Epoch: 6| Step: 11
Training loss: 1.018750589756707
Validation loss: 2.629287137016589

Epoch: 6| Step: 12
Training loss: 1.187042800829044
Validation loss: 2.7043716938697586

Epoch: 6| Step: 13
Training loss: 1.265474286936893
Validation loss: 2.7067157417252123

Epoch: 676| Step: 0
Training loss: 0.6686757679320198
Validation loss: 2.539930456341668

Epoch: 6| Step: 1
Training loss: 0.6875866271842288
Validation loss: 2.4078594030631297

Epoch: 6| Step: 2
Training loss: 0.9667289941250186
Validation loss: 2.2989563130414457

Epoch: 6| Step: 3
Training loss: 0.6097563259630241
Validation loss: 2.250592075231491

Epoch: 6| Step: 4
Training loss: 1.1902980966415129
Validation loss: 2.247918343008557

Epoch: 6| Step: 5
Training loss: 0.7736623417959279
Validation loss: 2.3070564965906706

Epoch: 6| Step: 6
Training loss: 0.528760631355199
Validation loss: 2.388122801899988

Epoch: 6| Step: 7
Training loss: 0.5917219611867234
Validation loss: 2.5457444552097583

Epoch: 6| Step: 8
Training loss: 0.42671695749359617
Validation loss: 2.686973988671704

Epoch: 6| Step: 9
Training loss: 1.1968069271320663
Validation loss: 2.7935984549831017

Epoch: 6| Step: 10
Training loss: 0.6001101213965498
Validation loss: 2.701563655286242

Epoch: 6| Step: 11
Training loss: 0.47483360425297105
Validation loss: 2.5676164897486116

Epoch: 6| Step: 12
Training loss: 0.5390043089045058
Validation loss: 2.4915806419817845

Epoch: 6| Step: 13
Training loss: 0.4517366746574299
Validation loss: 2.3841165246091602

Epoch: 677| Step: 0
Training loss: 0.5389392269548796
Validation loss: 2.3693309918090124

Epoch: 6| Step: 1
Training loss: 0.6469619231863247
Validation loss: 2.306958395147891

Epoch: 6| Step: 2
Training loss: 0.48870812639146477
Validation loss: 2.2817920221263503

Epoch: 6| Step: 3
Training loss: 0.7307368719701169
Validation loss: 2.2713298742065704

Epoch: 6| Step: 4
Training loss: 0.8936706467726836
Validation loss: 2.2408962498439746

Epoch: 6| Step: 5
Training loss: 0.6321318462650568
Validation loss: 2.2141846740001645

Epoch: 6| Step: 6
Training loss: 0.7419248015633216
Validation loss: 2.297949536188806

Epoch: 6| Step: 7
Training loss: 0.4649935248652181
Validation loss: 2.4079192026235097

Epoch: 6| Step: 8
Training loss: 0.43249933777466276
Validation loss: 2.4622986773634303

Epoch: 6| Step: 9
Training loss: 0.6726757866373835
Validation loss: 2.5417136502844735

Epoch: 6| Step: 10
Training loss: 0.7451160275911475
Validation loss: 2.5571535361925273

Epoch: 6| Step: 11
Training loss: 0.6432553001582785
Validation loss: 2.5229187829771624

Epoch: 6| Step: 12
Training loss: 0.7430361262917641
Validation loss: 2.5331231299897325

Epoch: 6| Step: 13
Training loss: 0.21717552248085137
Validation loss: 2.4986952665528537

Epoch: 678| Step: 0
Training loss: 0.43931075439019485
Validation loss: 2.461092288372151

Epoch: 6| Step: 1
Training loss: 0.3995488692461324
Validation loss: 2.4331240545313624

Epoch: 6| Step: 2
Training loss: 0.3647249718695024
Validation loss: 2.426184325115815

Epoch: 6| Step: 3
Training loss: 0.44895406471695504
Validation loss: 2.420193766958269

Epoch: 6| Step: 4
Training loss: 0.44075172982658084
Validation loss: 2.4332881663141483

Epoch: 6| Step: 5
Training loss: 0.4922226635921017
Validation loss: 2.3940022330562107

Epoch: 6| Step: 6
Training loss: 0.41197741235230106
Validation loss: 2.455631362247457

Epoch: 6| Step: 7
Training loss: 0.43889299086807976
Validation loss: 2.492015230253701

Epoch: 6| Step: 8
Training loss: 0.35076862346464116
Validation loss: 2.5042276220202417

Epoch: 6| Step: 9
Training loss: 0.7521008631247462
Validation loss: 2.5312585662166143

Epoch: 6| Step: 10
Training loss: 0.3064682834590964
Validation loss: 2.488866002373254

Epoch: 6| Step: 11
Training loss: 0.5036360733469886
Validation loss: 2.5043608829112247

Epoch: 6| Step: 12
Training loss: 0.291556169946119
Validation loss: 2.482824185026514

Epoch: 6| Step: 13
Training loss: 0.42901723777155815
Validation loss: 2.4538985334481636

Epoch: 679| Step: 0
Training loss: 0.5828331409307127
Validation loss: 2.4790786285638293

Epoch: 6| Step: 1
Training loss: 0.44944299822730366
Validation loss: 2.478169211010188

Epoch: 6| Step: 2
Training loss: 0.3719461789651403
Validation loss: 2.469865340614633

Epoch: 6| Step: 3
Training loss: 0.5339339840154882
Validation loss: 2.4538226311655347

Epoch: 6| Step: 4
Training loss: 0.2778713151616229
Validation loss: 2.4482169896318258

Epoch: 6| Step: 5
Training loss: 0.4506895781974187
Validation loss: 2.4224397702733764

Epoch: 6| Step: 6
Training loss: 0.5489300941958856
Validation loss: 2.421254213223276

Epoch: 6| Step: 7
Training loss: 0.42415683498242457
Validation loss: 2.407542191370436

Epoch: 6| Step: 8
Training loss: 0.6120105870615185
Validation loss: 2.3992022826560655

Epoch: 6| Step: 9
Training loss: 0.3760265564810662
Validation loss: 2.3357439050428144

Epoch: 6| Step: 10
Training loss: 0.3052468911293046
Validation loss: 2.337905215800564

Epoch: 6| Step: 11
Training loss: 0.3619209787085692
Validation loss: 2.3409809317875547

Epoch: 6| Step: 12
Training loss: 0.44029162626151075
Validation loss: 2.3111048316957357

Epoch: 6| Step: 13
Training loss: 0.34422989422476297
Validation loss: 2.3365174277161884

Epoch: 680| Step: 0
Training loss: 0.3274235152520009
Validation loss: 2.3190807328114746

Epoch: 6| Step: 1
Training loss: 0.3553722585987646
Validation loss: 2.313877641548205

Epoch: 6| Step: 2
Training loss: 0.27801960544784304
Validation loss: 2.2926724636533677

Epoch: 6| Step: 3
Training loss: 0.3297750560150261
Validation loss: 2.335775502749604

Epoch: 6| Step: 4
Training loss: 0.2902211346693126
Validation loss: 2.3062020735562

Epoch: 6| Step: 5
Training loss: 0.36924199322133894
Validation loss: 2.324688568983766

Epoch: 6| Step: 6
Training loss: 0.3897284327639266
Validation loss: 2.3569551056718554

Epoch: 6| Step: 7
Training loss: 0.25598036839045346
Validation loss: 2.3351654039929732

Epoch: 6| Step: 8
Training loss: 0.340014480587492
Validation loss: 2.362934439858687

Epoch: 6| Step: 9
Training loss: 0.39436744839893856
Validation loss: 2.3734035491108307

Epoch: 6| Step: 10
Training loss: 0.29516734082703056
Validation loss: 2.4085836421027267

Epoch: 6| Step: 11
Training loss: 0.3177285057709495
Validation loss: 2.427864490510567

Epoch: 6| Step: 12
Training loss: 0.26642156819802487
Validation loss: 2.4137978872525276

Epoch: 6| Step: 13
Training loss: 0.4837510951470884
Validation loss: 2.388504353140976

Epoch: 681| Step: 0
Training loss: 0.22509912089038905
Validation loss: 2.4431605099057534

Epoch: 6| Step: 1
Training loss: 0.29128772380777535
Validation loss: 2.414582687580705

Epoch: 6| Step: 2
Training loss: 0.39402682095214525
Validation loss: 2.4213368855712063

Epoch: 6| Step: 3
Training loss: 0.23832068351512892
Validation loss: 2.4038608677794753

Epoch: 6| Step: 4
Training loss: 0.29731934321468756
Validation loss: 2.378511315866231

Epoch: 6| Step: 5
Training loss: 0.14951841288305623
Validation loss: 2.406433328613347

Epoch: 6| Step: 6
Training loss: 0.25915314596689165
Validation loss: 2.4245464726716484

Epoch: 6| Step: 7
Training loss: 0.35224152792860536
Validation loss: 2.383662027224266

Epoch: 6| Step: 8
Training loss: 0.22597178369215254
Validation loss: 2.412537167179043

Epoch: 6| Step: 9
Training loss: 0.26153036710918526
Validation loss: 2.4374189834025204

Epoch: 6| Step: 10
Training loss: 0.28004258647270636
Validation loss: 2.420087137349322

Epoch: 6| Step: 11
Training loss: 0.30772991234322267
Validation loss: 2.4245747084929334

Epoch: 6| Step: 12
Training loss: 0.32358782633429994
Validation loss: 2.446232282234094

Epoch: 6| Step: 13
Training loss: 0.3050689876619165
Validation loss: 2.4034499865411494

Epoch: 682| Step: 0
Training loss: 0.22139372004749
Validation loss: 2.4463718885544905

Epoch: 6| Step: 1
Training loss: 0.2719126006685673
Validation loss: 2.387963071065869

Epoch: 6| Step: 2
Training loss: 0.2298197660633213
Validation loss: 2.408938288706716

Epoch: 6| Step: 3
Training loss: 0.2431171862295375
Validation loss: 2.399037398788055

Epoch: 6| Step: 4
Training loss: 0.22114984488176706
Validation loss: 2.385793230514451

Epoch: 6| Step: 5
Training loss: 0.2339048438326169
Validation loss: 2.4087519972180034

Epoch: 6| Step: 6
Training loss: 0.27743794628054996
Validation loss: 2.402934734952581

Epoch: 6| Step: 7
Training loss: 0.32989509293152225
Validation loss: 2.4178755547396156

Epoch: 6| Step: 8
Training loss: 0.18359234991960127
Validation loss: 2.4181367459045817

Epoch: 6| Step: 9
Training loss: 0.22149879368266265
Validation loss: 2.4019868489719367

Epoch: 6| Step: 10
Training loss: 0.23942263628470112
Validation loss: 2.411044321768138

Epoch: 6| Step: 11
Training loss: 0.22357322698649598
Validation loss: 2.429083627873582

Epoch: 6| Step: 12
Training loss: 0.26523216033145774
Validation loss: 2.3980053654704707

Epoch: 6| Step: 13
Training loss: 0.10513147538411952
Validation loss: 2.4091446225766844

Epoch: 683| Step: 0
Training loss: 0.24346851148900905
Validation loss: 2.4303678360585113

Epoch: 6| Step: 1
Training loss: 0.2212733439075687
Validation loss: 2.429575858155923

Epoch: 6| Step: 2
Training loss: 0.16715589942153677
Validation loss: 2.3908567434895804

Epoch: 6| Step: 3
Training loss: 0.18444477837956347
Validation loss: 2.3954973075241766

Epoch: 6| Step: 4
Training loss: 0.31982114368154313
Validation loss: 2.3822155497042603

Epoch: 6| Step: 5
Training loss: 0.1892933614312655
Validation loss: 2.3940561571979564

Epoch: 6| Step: 6
Training loss: 0.22077489209317722
Validation loss: 2.3926785661058068

Epoch: 6| Step: 7
Training loss: 0.17343937340145593
Validation loss: 2.3776963757020795

Epoch: 6| Step: 8
Training loss: 0.19995265303402016
Validation loss: 2.376356219075249

Epoch: 6| Step: 9
Training loss: 0.3481262758666514
Validation loss: 2.3581558312347872

Epoch: 6| Step: 10
Training loss: 0.24350865777249084
Validation loss: 2.3905447540873968

Epoch: 6| Step: 11
Training loss: 0.24821709626871705
Validation loss: 2.3752740551826506

Epoch: 6| Step: 12
Training loss: 0.198646977762554
Validation loss: 2.403143983491236

Epoch: 6| Step: 13
Training loss: 0.15376432478085306
Validation loss: 2.380665981204352

Epoch: 684| Step: 0
Training loss: 0.1902200474131586
Validation loss: 2.4072887201381206

Epoch: 6| Step: 1
Training loss: 0.22633221860586764
Validation loss: 2.409823421025431

Epoch: 6| Step: 2
Training loss: 0.183808302809688
Validation loss: 2.3932975518162096

Epoch: 6| Step: 3
Training loss: 0.22789829368099
Validation loss: 2.4025386063980894

Epoch: 6| Step: 4
Training loss: 0.21297603608707907
Validation loss: 2.4314308618655804

Epoch: 6| Step: 5
Training loss: 0.1809495474538549
Validation loss: 2.4158804892648638

Epoch: 6| Step: 6
Training loss: 0.22084891306303286
Validation loss: 2.4054877569853836

Epoch: 6| Step: 7
Training loss: 0.20752563467587007
Validation loss: 2.428925558988115

Epoch: 6| Step: 8
Training loss: 0.17503868722737084
Validation loss: 2.362795752869507

Epoch: 6| Step: 9
Training loss: 0.2236604964932615
Validation loss: 2.375629292024956

Epoch: 6| Step: 10
Training loss: 0.16011080446011883
Validation loss: 2.3900759057850935

Epoch: 6| Step: 11
Training loss: 0.11865883483713541
Validation loss: 2.372195895743457

Epoch: 6| Step: 12
Training loss: 0.232031502386399
Validation loss: 2.3927789729960205

Epoch: 6| Step: 13
Training loss: 0.225053389824363
Validation loss: 2.3856145512754234

Epoch: 685| Step: 0
Training loss: 0.15594147979076403
Validation loss: 2.3882022811589203

Epoch: 6| Step: 1
Training loss: 0.17352423732841676
Validation loss: 2.400204367550197

Epoch: 6| Step: 2
Training loss: 0.16497722573320214
Validation loss: 2.403018962507516

Epoch: 6| Step: 3
Training loss: 0.15596257237555539
Validation loss: 2.3837228559403263

Epoch: 6| Step: 4
Training loss: 0.2016149844362143
Validation loss: 2.3833891355282506

Epoch: 6| Step: 5
Training loss: 0.1736255708606802
Validation loss: 2.401882136018168

Epoch: 6| Step: 6
Training loss: 0.22634833177529418
Validation loss: 2.3889697325047163

Epoch: 6| Step: 7
Training loss: 0.14122437852387473
Validation loss: 2.3822184612483066

Epoch: 6| Step: 8
Training loss: 0.1779222648068938
Validation loss: 2.3689034065782364

Epoch: 6| Step: 9
Training loss: 0.177245189990217
Validation loss: 2.358745071168873

Epoch: 6| Step: 10
Training loss: 0.20826587876407385
Validation loss: 2.395751481621986

Epoch: 6| Step: 11
Training loss: 0.1496518679797945
Validation loss: 2.4067796588468204

Epoch: 6| Step: 12
Training loss: 0.2452052288836613
Validation loss: 2.3790525975373793

Epoch: 6| Step: 13
Training loss: 0.1444519121625623
Validation loss: 2.3888726511313814

Epoch: 686| Step: 0
Training loss: 0.1708180265624795
Validation loss: 2.4079393359915686

Epoch: 6| Step: 1
Training loss: 0.15036632911317013
Validation loss: 2.349706883893197

Epoch: 6| Step: 2
Training loss: 0.17949999479928713
Validation loss: 2.368289983860885

Epoch: 6| Step: 3
Training loss: 0.21573210765050244
Validation loss: 2.3650250291803943

Epoch: 6| Step: 4
Training loss: 0.17511854286528772
Validation loss: 2.3807156526735924

Epoch: 6| Step: 5
Training loss: 0.07627162148985278
Validation loss: 2.3519170393886735

Epoch: 6| Step: 6
Training loss: 0.16374271880771243
Validation loss: 2.379605356894231

Epoch: 6| Step: 7
Training loss: 0.1488747493672123
Validation loss: 2.3731195813172516

Epoch: 6| Step: 8
Training loss: 0.16924718667189717
Validation loss: 2.3633947038922756

Epoch: 6| Step: 9
Training loss: 0.11592153368564269
Validation loss: 2.3701348378222473

Epoch: 6| Step: 10
Training loss: 0.1616730332831255
Validation loss: 2.3350402434559725

Epoch: 6| Step: 11
Training loss: 0.1251328328783936
Validation loss: 2.3442866454117346

Epoch: 6| Step: 12
Training loss: 0.13327306941463643
Validation loss: 2.346543139832208

Epoch: 6| Step: 13
Training loss: 0.09354327177987168
Validation loss: 2.3799966894991758

Epoch: 687| Step: 0
Training loss: 0.09462265332548586
Validation loss: 2.351338748291373

Epoch: 6| Step: 1
Training loss: 0.11696342662425063
Validation loss: 2.366852849731054

Epoch: 6| Step: 2
Training loss: 0.15237853068907584
Validation loss: 2.4366968134199745

Epoch: 6| Step: 3
Training loss: 0.1886449269385832
Validation loss: 2.394499782037043

Epoch: 6| Step: 4
Training loss: 0.12398252037502462
Validation loss: 2.4157620516596627

Epoch: 6| Step: 5
Training loss: 0.19895259992883269
Validation loss: 2.409017853811272

Epoch: 6| Step: 6
Training loss: 0.09758739905346643
Validation loss: 2.4140059467194206

Epoch: 6| Step: 7
Training loss: 0.12920293478260347
Validation loss: 2.4206760260993145

Epoch: 6| Step: 8
Training loss: 0.19915272983832122
Validation loss: 2.4371252821029454

Epoch: 6| Step: 9
Training loss: 0.13021516940927413
Validation loss: 2.3942357451245635

Epoch: 6| Step: 10
Training loss: 0.2382991033650865
Validation loss: 2.361151076945131

Epoch: 6| Step: 11
Training loss: 0.16910642317749544
Validation loss: 2.359322217885887

Epoch: 6| Step: 12
Training loss: 0.17758202573265594
Validation loss: 2.361058291601065

Epoch: 6| Step: 13
Training loss: 0.08601423110837286
Validation loss: 2.3893827132399936

Epoch: 688| Step: 0
Training loss: 0.20421825157869394
Validation loss: 2.3739251525659686

Epoch: 6| Step: 1
Training loss: 0.1533933939151993
Validation loss: 2.3491893214814805

Epoch: 6| Step: 2
Training loss: 0.2567909984653174
Validation loss: 2.322510437163466

Epoch: 6| Step: 3
Training loss: 0.15630104899951347
Validation loss: 2.355006945077955

Epoch: 6| Step: 4
Training loss: 0.15536142651245907
Validation loss: 2.374886422067217

Epoch: 6| Step: 5
Training loss: 0.12435596672666578
Validation loss: 2.387877383775593

Epoch: 6| Step: 6
Training loss: 0.19287687848264776
Validation loss: 2.377195967599444

Epoch: 6| Step: 7
Training loss: 0.08732137179271854
Validation loss: 2.3667867879036533

Epoch: 6| Step: 8
Training loss: 0.1886405034175049
Validation loss: 2.4276021562805186

Epoch: 6| Step: 9
Training loss: 0.11728012874604987
Validation loss: 2.4019764908028134

Epoch: 6| Step: 10
Training loss: 0.13447943997915532
Validation loss: 2.4068686866262583

Epoch: 6| Step: 11
Training loss: 0.14178997527430937
Validation loss: 2.3831268689529677

Epoch: 6| Step: 12
Training loss: 0.12260482493650325
Validation loss: 2.4058734698817323

Epoch: 6| Step: 13
Training loss: 0.2262370633278377
Validation loss: 2.37306215710169

Epoch: 689| Step: 0
Training loss: 0.16555426387130515
Validation loss: 2.395250957128572

Epoch: 6| Step: 1
Training loss: 0.17512654131674632
Validation loss: 2.3608486726594524

Epoch: 6| Step: 2
Training loss: 0.27817528945086367
Validation loss: 2.3615036073782867

Epoch: 6| Step: 3
Training loss: 0.1408639176324375
Validation loss: 2.382129813333462

Epoch: 6| Step: 4
Training loss: 0.14683969636466102
Validation loss: 2.364161950177382

Epoch: 6| Step: 5
Training loss: 0.28936783670494565
Validation loss: 2.323217143990492

Epoch: 6| Step: 6
Training loss: 0.16309605641295666
Validation loss: 2.3038309687614116

Epoch: 6| Step: 7
Training loss: 0.22779216523851764
Validation loss: 2.2956053747858016

Epoch: 6| Step: 8
Training loss: 0.1867443194897825
Validation loss: 2.2914599839098106

Epoch: 6| Step: 9
Training loss: 0.22668327203809194
Validation loss: 2.3517102177506977

Epoch: 6| Step: 10
Training loss: 0.16476235527097044
Validation loss: 2.375504824877088

Epoch: 6| Step: 11
Training loss: 0.16936285867494688
Validation loss: 2.3445753409485826

Epoch: 6| Step: 12
Training loss: 0.18837862978806685
Validation loss: 2.358308950183858

Epoch: 6| Step: 13
Training loss: 0.1786839511695054
Validation loss: 2.3728248866758177

Epoch: 690| Step: 0
Training loss: 0.1621097139561798
Validation loss: 2.373249075623215

Epoch: 6| Step: 1
Training loss: 0.2303095930736429
Validation loss: 2.3657797693551914

Epoch: 6| Step: 2
Training loss: 0.12114998065637
Validation loss: 2.4060524141682107

Epoch: 6| Step: 3
Training loss: 0.15299280990507488
Validation loss: 2.392174856636187

Epoch: 6| Step: 4
Training loss: 0.21032408425904744
Validation loss: 2.4163177338753346

Epoch: 6| Step: 5
Training loss: 0.13746228351026157
Validation loss: 2.359251116199226

Epoch: 6| Step: 6
Training loss: 0.18995949823272382
Validation loss: 2.384017713239243

Epoch: 6| Step: 7
Training loss: 0.24265828059931802
Validation loss: 2.380803240105778

Epoch: 6| Step: 8
Training loss: 0.184113294946748
Validation loss: 2.3618044385579453

Epoch: 6| Step: 9
Training loss: 0.09662734165506397
Validation loss: 2.3545745647239413

Epoch: 6| Step: 10
Training loss: 0.11885819807607016
Validation loss: 2.3462136984917215

Epoch: 6| Step: 11
Training loss: 0.12897651375763813
Validation loss: 2.3308709974107495

Epoch: 6| Step: 12
Training loss: 0.17407395628205763
Validation loss: 2.3278995549838646

Epoch: 6| Step: 13
Training loss: 0.13312189444425354
Validation loss: 2.3348423627538577

Epoch: 691| Step: 0
Training loss: 0.1284083808829809
Validation loss: 2.335047264515786

Epoch: 6| Step: 1
Training loss: 0.11287911333307415
Validation loss: 2.3179534574168636

Epoch: 6| Step: 2
Training loss: 0.15790291547245924
Validation loss: 2.3604648536475965

Epoch: 6| Step: 3
Training loss: 0.18539931804596887
Validation loss: 2.3998483992793127

Epoch: 6| Step: 4
Training loss: 0.1766350462081896
Validation loss: 2.3947005266696726

Epoch: 6| Step: 5
Training loss: 0.15751497104805318
Validation loss: 2.3921804657911023

Epoch: 6| Step: 6
Training loss: 0.15180548921763762
Validation loss: 2.4100234062427632

Epoch: 6| Step: 7
Training loss: 0.19169181813331895
Validation loss: 2.421760783444645

Epoch: 6| Step: 8
Training loss: 0.16673120103585026
Validation loss: 2.4226080836564052

Epoch: 6| Step: 9
Training loss: 0.20078738978754027
Validation loss: 2.450635833428816

Epoch: 6| Step: 10
Training loss: 0.2490307077580725
Validation loss: 2.4204628322123107

Epoch: 6| Step: 11
Training loss: 0.1608329989210747
Validation loss: 2.415234462420683

Epoch: 6| Step: 12
Training loss: 0.12878010820217256
Validation loss: 2.3590350466754524

Epoch: 6| Step: 13
Training loss: 0.1146774411272849
Validation loss: 2.3675990091350942

Epoch: 692| Step: 0
Training loss: 0.1501450205165556
Validation loss: 2.354557651921336

Epoch: 6| Step: 1
Training loss: 0.1709918557017125
Validation loss: 2.343758940320755

Epoch: 6| Step: 2
Training loss: 0.13521882576584374
Validation loss: 2.3540873803208835

Epoch: 6| Step: 3
Training loss: 0.1727260629697693
Validation loss: 2.318793532050203

Epoch: 6| Step: 4
Training loss: 0.19786291061648917
Validation loss: 2.34400186149362

Epoch: 6| Step: 5
Training loss: 0.19079891502646193
Validation loss: 2.3600824484302425

Epoch: 6| Step: 6
Training loss: 0.14615874655081704
Validation loss: 2.331895639859421

Epoch: 6| Step: 7
Training loss: 0.1586301538657462
Validation loss: 2.349254971321036

Epoch: 6| Step: 8
Training loss: 0.1879748847448658
Validation loss: 2.3460840057372514

Epoch: 6| Step: 9
Training loss: 0.11393553365908568
Validation loss: 2.3347763460877533

Epoch: 6| Step: 10
Training loss: 0.14758158163260315
Validation loss: 2.325852298906223

Epoch: 6| Step: 11
Training loss: 0.241564055902916
Validation loss: 2.36656467384645

Epoch: 6| Step: 12
Training loss: 0.18473947432709897
Validation loss: 2.3843421731748466

Epoch: 6| Step: 13
Training loss: 0.12674409089666416
Validation loss: 2.3801704734565927

Epoch: 693| Step: 0
Training loss: 0.18662763351567596
Validation loss: 2.345589489194385

Epoch: 6| Step: 1
Training loss: 0.10879467379550951
Validation loss: 2.414999330101395

Epoch: 6| Step: 2
Training loss: 0.19202297464454082
Validation loss: 2.390275880781071

Epoch: 6| Step: 3
Training loss: 0.13951464559557547
Validation loss: 2.3926995155825965

Epoch: 6| Step: 4
Training loss: 0.163034316704782
Validation loss: 2.353529079219919

Epoch: 6| Step: 5
Training loss: 0.13184711267650115
Validation loss: 2.3707389451879863

Epoch: 6| Step: 6
Training loss: 0.13690364460620016
Validation loss: 2.3758313365295467

Epoch: 6| Step: 7
Training loss: 0.12666911120732854
Validation loss: 2.360596948104288

Epoch: 6| Step: 8
Training loss: 0.1255110337823199
Validation loss: 2.3533239717621806

Epoch: 6| Step: 9
Training loss: 0.18079596163698908
Validation loss: 2.3586104051279038

Epoch: 6| Step: 10
Training loss: 0.2110513891837494
Validation loss: 2.3348676175549077

Epoch: 6| Step: 11
Training loss: 0.14065106468245228
Validation loss: 2.3847528904286297

Epoch: 6| Step: 12
Training loss: 0.14811959858393764
Validation loss: 2.349073408625133

Epoch: 6| Step: 13
Training loss: 0.11836320474301826
Validation loss: 2.339228293957603

Epoch: 694| Step: 0
Training loss: 0.18921501888373438
Validation loss: 2.3713604490434506

Epoch: 6| Step: 1
Training loss: 0.13038722306391165
Validation loss: 2.368102917488122

Epoch: 6| Step: 2
Training loss: 0.1438259299989846
Validation loss: 2.3477215474161803

Epoch: 6| Step: 3
Training loss: 0.15440165306039316
Validation loss: 2.353025748165914

Epoch: 6| Step: 4
Training loss: 0.14826656211527126
Validation loss: 2.376602195885072

Epoch: 6| Step: 5
Training loss: 0.1887802188095575
Validation loss: 2.329031236654471

Epoch: 6| Step: 6
Training loss: 0.15468106545445734
Validation loss: 2.378669223022706

Epoch: 6| Step: 7
Training loss: 0.12504525408539732
Validation loss: 2.3653582868379472

Epoch: 6| Step: 8
Training loss: 0.16091642010232154
Validation loss: 2.334366559384301

Epoch: 6| Step: 9
Training loss: 0.11907000090032237
Validation loss: 2.3712249842258784

Epoch: 6| Step: 10
Training loss: 0.1673157663393438
Validation loss: 2.3788181662233825

Epoch: 6| Step: 11
Training loss: 0.14463534344057843
Validation loss: 2.3732925499205697

Epoch: 6| Step: 12
Training loss: 0.12595998669772807
Validation loss: 2.377114907606539

Epoch: 6| Step: 13
Training loss: 0.13563024584341926
Validation loss: 2.380435886322662

Epoch: 695| Step: 0
Training loss: 0.13656879102851105
Validation loss: 2.381992720203395

Epoch: 6| Step: 1
Training loss: 0.13738000901056843
Validation loss: 2.38515649574942

Epoch: 6| Step: 2
Training loss: 0.17614913167709698
Validation loss: 2.3837250800270517

Epoch: 6| Step: 3
Training loss: 0.09750703856542574
Validation loss: 2.3817882233287997

Epoch: 6| Step: 4
Training loss: 0.12557643362009555
Validation loss: 2.363043532335198

Epoch: 6| Step: 5
Training loss: 0.14883523909018617
Validation loss: 2.369926701029187

Epoch: 6| Step: 6
Training loss: 0.08894934890929865
Validation loss: 2.373789115382648

Epoch: 6| Step: 7
Training loss: 0.16138118905699012
Validation loss: 2.3652040639786023

Epoch: 6| Step: 8
Training loss: 0.14528418644534305
Validation loss: 2.3623268396251644

Epoch: 6| Step: 9
Training loss: 0.16249967607135765
Validation loss: 2.3299441220531962

Epoch: 6| Step: 10
Training loss: 0.10506125601894935
Validation loss: 2.353906980503202

Epoch: 6| Step: 11
Training loss: 0.16761863614525135
Validation loss: 2.33191914119832

Epoch: 6| Step: 12
Training loss: 0.08896421019813239
Validation loss: 2.315235795610983

Epoch: 6| Step: 13
Training loss: 0.1459375857489781
Validation loss: 2.3231952815970507

Epoch: 696| Step: 0
Training loss: 0.1643427997495631
Validation loss: 2.3321254529329676

Epoch: 6| Step: 1
Training loss: 0.1645679974251656
Validation loss: 2.3101632829227046

Epoch: 6| Step: 2
Training loss: 0.11060604358694144
Validation loss: 2.3051203306510955

Epoch: 6| Step: 3
Training loss: 0.13526274724496543
Validation loss: 2.3285762230948484

Epoch: 6| Step: 4
Training loss: 0.11200164876037215
Validation loss: 2.340254206568272

Epoch: 6| Step: 5
Training loss: 0.11175327101129598
Validation loss: 2.341173313483352

Epoch: 6| Step: 6
Training loss: 0.12214236993727859
Validation loss: 2.306940270355044

Epoch: 6| Step: 7
Training loss: 0.13438332969885794
Validation loss: 2.34689104825085

Epoch: 6| Step: 8
Training loss: 0.18133146370867373
Validation loss: 2.35887755971611

Epoch: 6| Step: 9
Training loss: 0.1564233414441474
Validation loss: 2.3976453690431048

Epoch: 6| Step: 10
Training loss: 0.1682282649794547
Validation loss: 2.3576712027522957

Epoch: 6| Step: 11
Training loss: 0.15960845071279442
Validation loss: 2.3310949093019886

Epoch: 6| Step: 12
Training loss: 0.16978905408600595
Validation loss: 2.3503544816078774

Epoch: 6| Step: 13
Training loss: 0.13787578362409086
Validation loss: 2.328653145040084

Epoch: 697| Step: 0
Training loss: 0.13984285173180921
Validation loss: 2.366923131685337

Epoch: 6| Step: 1
Training loss: 0.11282954097863541
Validation loss: 2.314118011888487

Epoch: 6| Step: 2
Training loss: 0.1698927361069399
Validation loss: 2.3411894179438515

Epoch: 6| Step: 3
Training loss: 0.230451550892606
Validation loss: 2.323271568450599

Epoch: 6| Step: 4
Training loss: 0.14616614424799002
Validation loss: 2.3192491561120416

Epoch: 6| Step: 5
Training loss: 0.15265747314829906
Validation loss: 2.3624134563744303

Epoch: 6| Step: 6
Training loss: 0.10817420380160261
Validation loss: 2.38800890983054

Epoch: 6| Step: 7
Training loss: 0.15872334672363042
Validation loss: 2.3711712560619183

Epoch: 6| Step: 8
Training loss: 0.17623621025993402
Validation loss: 2.405628589157514

Epoch: 6| Step: 9
Training loss: 0.16314719528713942
Validation loss: 2.377493539714299

Epoch: 6| Step: 10
Training loss: 0.1408524924874965
Validation loss: 2.400774797955393

Epoch: 6| Step: 11
Training loss: 0.14802529170144965
Validation loss: 2.398533225332924

Epoch: 6| Step: 12
Training loss: 0.20799110238021776
Validation loss: 2.4589313101695236

Epoch: 6| Step: 13
Training loss: 0.2198848069765164
Validation loss: 2.4455813342977137

Epoch: 698| Step: 0
Training loss: 0.11316826546250792
Validation loss: 2.4153017051416836

Epoch: 6| Step: 1
Training loss: 0.10408805523356995
Validation loss: 2.392707594783286

Epoch: 6| Step: 2
Training loss: 0.18680954006756162
Validation loss: 2.4111788232074125

Epoch: 6| Step: 3
Training loss: 0.08929812566460427
Validation loss: 2.3873490003457114

Epoch: 6| Step: 4
Training loss: 0.16895748381238446
Validation loss: 2.386048561362624

Epoch: 6| Step: 5
Training loss: 0.16561686365367712
Validation loss: 2.3681473728679028

Epoch: 6| Step: 6
Training loss: 0.12014746865774181
Validation loss: 2.3615531860613066

Epoch: 6| Step: 7
Training loss: 0.1584665671702059
Validation loss: 2.339223623080748

Epoch: 6| Step: 8
Training loss: 0.15136663375260984
Validation loss: 2.3521010164125338

Epoch: 6| Step: 9
Training loss: 0.10156925344021393
Validation loss: 2.3167452359843437

Epoch: 6| Step: 10
Training loss: 0.1661339786738858
Validation loss: 2.359491624770095

Epoch: 6| Step: 11
Training loss: 0.14671559205480525
Validation loss: 2.3639297771144228

Epoch: 6| Step: 12
Training loss: 0.1097865705767179
Validation loss: 2.344717822128408

Epoch: 6| Step: 13
Training loss: 0.15215636001351032
Validation loss: 2.3490612128553603

Epoch: 699| Step: 0
Training loss: 0.10969060254939415
Validation loss: 2.337118927972571

Epoch: 6| Step: 1
Training loss: 0.15495026744266754
Validation loss: 2.3394391104444634

Epoch: 6| Step: 2
Training loss: 0.11859527439901812
Validation loss: 2.335110289521953

Epoch: 6| Step: 3
Training loss: 0.10777464077517346
Validation loss: 2.393513512387035

Epoch: 6| Step: 4
Training loss: 0.11541610063346348
Validation loss: 2.3615456271977506

Epoch: 6| Step: 5
Training loss: 0.09339467402828643
Validation loss: 2.3700014533800013

Epoch: 6| Step: 6
Training loss: 0.17319578712725628
Validation loss: 2.398519763829765

Epoch: 6| Step: 7
Training loss: 0.08206492822588873
Validation loss: 2.4058779506239527

Epoch: 6| Step: 8
Training loss: 0.1541458549714317
Validation loss: 2.394182470172191

Epoch: 6| Step: 9
Training loss: 0.14972757968611805
Validation loss: 2.436428588701898

Epoch: 6| Step: 10
Training loss: 0.1478912441363627
Validation loss: 2.4009383276367777

Epoch: 6| Step: 11
Training loss: 0.22686299587838527
Validation loss: 2.411688325071789

Epoch: 6| Step: 12
Training loss: 0.09767343369935048
Validation loss: 2.4083194354442927

Epoch: 6| Step: 13
Training loss: 0.2413912265386623
Validation loss: 2.394447603962697

Epoch: 700| Step: 0
Training loss: 0.1314851757099978
Validation loss: 2.4062376369610985

Epoch: 6| Step: 1
Training loss: 0.16361818434440703
Validation loss: 2.3723367774843847

Epoch: 6| Step: 2
Training loss: 0.1290971685980522
Validation loss: 2.3725125834390886

Epoch: 6| Step: 3
Training loss: 0.1539498906300569
Validation loss: 2.340635961660839

Epoch: 6| Step: 4
Training loss: 0.14127858917002117
Validation loss: 2.38016126438099

Epoch: 6| Step: 5
Training loss: 0.09915121682494521
Validation loss: 2.3463544172376287

Epoch: 6| Step: 6
Training loss: 0.14518048124225186
Validation loss: 2.350186367582406

Epoch: 6| Step: 7
Training loss: 0.13147754699059178
Validation loss: 2.368768795851323

Epoch: 6| Step: 8
Training loss: 0.15438366513315782
Validation loss: 2.3561261616256948

Epoch: 6| Step: 9
Training loss: 0.13309629356907707
Validation loss: 2.3629704205144755

Epoch: 6| Step: 10
Training loss: 0.16428810457192242
Validation loss: 2.408924909293999

Epoch: 6| Step: 11
Training loss: 0.09005389308636963
Validation loss: 2.4032826147490396

Epoch: 6| Step: 12
Training loss: 0.18897402048622922
Validation loss: 2.4204999573609483

Epoch: 6| Step: 13
Training loss: 0.16185716174494508
Validation loss: 2.4191369156809612

Epoch: 701| Step: 0
Training loss: 0.1718604341750563
Validation loss: 2.398658192082208

Epoch: 6| Step: 1
Training loss: 0.09047967340806307
Validation loss: 2.392133933734353

Epoch: 6| Step: 2
Training loss: 0.11293445729488306
Validation loss: 2.3929534238721084

Epoch: 6| Step: 3
Training loss: 0.1803153513149085
Validation loss: 2.358015455807896

Epoch: 6| Step: 4
Training loss: 0.11516949071552282
Validation loss: 2.3843902534073624

Epoch: 6| Step: 5
Training loss: 0.159913408113986
Validation loss: 2.3853183297436824

Epoch: 6| Step: 6
Training loss: 0.16560529600652482
Validation loss: 2.3884746873363225

Epoch: 6| Step: 7
Training loss: 0.1067488568259276
Validation loss: 2.3552309056063323

Epoch: 6| Step: 8
Training loss: 0.11200233060942977
Validation loss: 2.348681588815848

Epoch: 6| Step: 9
Training loss: 0.09861657509428146
Validation loss: 2.367959890322874

Epoch: 6| Step: 10
Training loss: 0.13748495117111856
Validation loss: 2.3663416538217423

Epoch: 6| Step: 11
Training loss: 0.07531825456161137
Validation loss: 2.3453182451058203

Epoch: 6| Step: 12
Training loss: 0.14274522056361585
Validation loss: 2.3718142891431557

Epoch: 6| Step: 13
Training loss: 0.13544305596224193
Validation loss: 2.38627105671456

Epoch: 702| Step: 0
Training loss: 0.1445045704316811
Validation loss: 2.359609608380319

Epoch: 6| Step: 1
Training loss: 0.1217540573395286
Validation loss: 2.350712310803419

Epoch: 6| Step: 2
Training loss: 0.08562357960518314
Validation loss: 2.3562633322644877

Epoch: 6| Step: 3
Training loss: 0.12279811949050157
Validation loss: 2.367517386123125

Epoch: 6| Step: 4
Training loss: 0.09720472857733531
Validation loss: 2.353745533827609

Epoch: 6| Step: 5
Training loss: 0.1695790944069521
Validation loss: 2.31780982040165

Epoch: 6| Step: 6
Training loss: 0.1327340090445177
Validation loss: 2.3072447390890414

Epoch: 6| Step: 7
Training loss: 0.13148310034548266
Validation loss: 2.3705273380286216

Epoch: 6| Step: 8
Training loss: 0.16371397055217177
Validation loss: 2.3406194462209133

Epoch: 6| Step: 9
Training loss: 0.11289409133842847
Validation loss: 2.338545772507685

Epoch: 6| Step: 10
Training loss: 0.09590718351831476
Validation loss: 2.336529913885619

Epoch: 6| Step: 11
Training loss: 0.16738543024319638
Validation loss: 2.3268837552784563

Epoch: 6| Step: 12
Training loss: 0.08803866422595101
Validation loss: 2.338706242173741

Epoch: 6| Step: 13
Training loss: 0.1449303593683989
Validation loss: 2.3720332123931187

Epoch: 703| Step: 0
Training loss: 0.12621295543628908
Validation loss: 2.3463292953624197

Epoch: 6| Step: 1
Training loss: 0.16988644285307464
Validation loss: 2.328233638017284

Epoch: 6| Step: 2
Training loss: 0.15194000638607275
Validation loss: 2.3300602196570184

Epoch: 6| Step: 3
Training loss: 0.14331236648054263
Validation loss: 2.311391233718687

Epoch: 6| Step: 4
Training loss: 0.14388360081351234
Validation loss: 2.3373240222749074

Epoch: 6| Step: 5
Training loss: 0.11117122703572511
Validation loss: 2.3490996028510085

Epoch: 6| Step: 6
Training loss: 0.1554451359014835
Validation loss: 2.34170269219317

Epoch: 6| Step: 7
Training loss: 0.14527616046467626
Validation loss: 2.349646727156004

Epoch: 6| Step: 8
Training loss: 0.06881546390635507
Validation loss: 2.326806571008714

Epoch: 6| Step: 9
Training loss: 0.12423852607164397
Validation loss: 2.3722775112364594

Epoch: 6| Step: 10
Training loss: 0.10073787824208505
Validation loss: 2.3550714318135353

Epoch: 6| Step: 11
Training loss: 0.16788447284032787
Validation loss: 2.3706568663329697

Epoch: 6| Step: 12
Training loss: 0.12630855078377207
Validation loss: 2.4039126015843313

Epoch: 6| Step: 13
Training loss: 0.09150490592320909
Validation loss: 2.3778023337934777

Epoch: 704| Step: 0
Training loss: 0.1473206617079423
Validation loss: 2.378279340640946

Epoch: 6| Step: 1
Training loss: 0.11812980013257779
Validation loss: 2.3561201086598538

Epoch: 6| Step: 2
Training loss: 0.13140367355723884
Validation loss: 2.3602372525094566

Epoch: 6| Step: 3
Training loss: 0.11505335798315856
Validation loss: 2.349899994549107

Epoch: 6| Step: 4
Training loss: 0.164601847255163
Validation loss: 2.346944068429903

Epoch: 6| Step: 5
Training loss: 0.1207413699228232
Validation loss: 2.3479232615767622

Epoch: 6| Step: 6
Training loss: 0.11203064862492892
Validation loss: 2.3568945117606734

Epoch: 6| Step: 7
Training loss: 0.16995649971556975
Validation loss: 2.306582536869258

Epoch: 6| Step: 8
Training loss: 0.1076776580397884
Validation loss: 2.3403275696103174

Epoch: 6| Step: 9
Training loss: 0.08930705275317957
Validation loss: 2.3411640616084894

Epoch: 6| Step: 10
Training loss: 0.06482932091081314
Validation loss: 2.3487202742654016

Epoch: 6| Step: 11
Training loss: 0.10546980963280633
Validation loss: 2.3131750031274674

Epoch: 6| Step: 12
Training loss: 0.1392123944130136
Validation loss: 2.3432746716946804

Epoch: 6| Step: 13
Training loss: 0.1396165224432708
Validation loss: 2.345421486691297

Epoch: 705| Step: 0
Training loss: 0.10629725001665853
Validation loss: 2.3544913730553665

Epoch: 6| Step: 1
Training loss: 0.12560988445584387
Validation loss: 2.3546776808146865

Epoch: 6| Step: 2
Training loss: 0.08675429307410895
Validation loss: 2.385132368891287

Epoch: 6| Step: 3
Training loss: 0.08837345801995154
Validation loss: 2.3700064605836677

Epoch: 6| Step: 4
Training loss: 0.13143424544429497
Validation loss: 2.3160084829734573

Epoch: 6| Step: 5
Training loss: 0.14103948253952986
Validation loss: 2.354187390229615

Epoch: 6| Step: 6
Training loss: 0.16304362770433073
Validation loss: 2.3217745827672394

Epoch: 6| Step: 7
Training loss: 0.095244359063397
Validation loss: 2.3629814899565265

Epoch: 6| Step: 8
Training loss: 0.15130906988964943
Validation loss: 2.322447010622934

Epoch: 6| Step: 9
Training loss: 0.0483101479032107
Validation loss: 2.3595879375875124

Epoch: 6| Step: 10
Training loss: 0.13440098012346133
Validation loss: 2.3486286307837414

Epoch: 6| Step: 11
Training loss: 0.12986205229089495
Validation loss: 2.3320875986385228

Epoch: 6| Step: 12
Training loss: 0.1793615037712171
Validation loss: 2.3314318068654356

Epoch: 6| Step: 13
Training loss: 0.10577455532549193
Validation loss: 2.331465926080497

Epoch: 706| Step: 0
Training loss: 0.0910969540685206
Validation loss: 2.3260823188984983

Epoch: 6| Step: 1
Training loss: 0.10214738972930662
Validation loss: 2.3286034471704147

Epoch: 6| Step: 2
Training loss: 0.09317562363424568
Validation loss: 2.330825315494941

Epoch: 6| Step: 3
Training loss: 0.16279540194573477
Validation loss: 2.291066898008275

Epoch: 6| Step: 4
Training loss: 0.1279332255099909
Validation loss: 2.353706570994811

Epoch: 6| Step: 5
Training loss: 0.10205942327238418
Validation loss: 2.3410218722607534

Epoch: 6| Step: 6
Training loss: 0.13151536041510517
Validation loss: 2.3372742554031274

Epoch: 6| Step: 7
Training loss: 0.11584268453585012
Validation loss: 2.348390175498924

Epoch: 6| Step: 8
Training loss: 0.1439960467968154
Validation loss: 2.339124702853352

Epoch: 6| Step: 9
Training loss: 0.16411830316377646
Validation loss: 2.3937150326609196

Epoch: 6| Step: 10
Training loss: 0.1160465086985999
Validation loss: 2.3407960867941666

Epoch: 6| Step: 11
Training loss: 0.08758850092339784
Validation loss: 2.3569812204623743

Epoch: 6| Step: 12
Training loss: 0.07536514721395626
Validation loss: 2.348325646664861

Epoch: 6| Step: 13
Training loss: 0.18659009291719894
Validation loss: 2.339136749318191

Epoch: 707| Step: 0
Training loss: 0.08424998300064747
Validation loss: 2.3459330839650203

Epoch: 6| Step: 1
Training loss: 0.12992034455875792
Validation loss: 2.3276768812162167

Epoch: 6| Step: 2
Training loss: 0.12030459724827665
Validation loss: 2.3287119940621803

Epoch: 6| Step: 3
Training loss: 0.12293005499286348
Validation loss: 2.3659702592174185

Epoch: 6| Step: 4
Training loss: 0.10839345851838766
Validation loss: 2.3561484213472785

Epoch: 6| Step: 5
Training loss: 0.13071395138298372
Validation loss: 2.3274956553376

Epoch: 6| Step: 6
Training loss: 0.13502078157980257
Validation loss: 2.3624554296264013

Epoch: 6| Step: 7
Training loss: 0.1604094248743034
Validation loss: 2.3443188442542424

Epoch: 6| Step: 8
Training loss: 0.12799757692159522
Validation loss: 2.3369007572593574

Epoch: 6| Step: 9
Training loss: 0.10593371859978161
Validation loss: 2.3665767707488192

Epoch: 6| Step: 10
Training loss: 0.19732508377026053
Validation loss: 2.3713249589413072

Epoch: 6| Step: 11
Training loss: 0.11065186091603285
Validation loss: 2.361621071452952

Epoch: 6| Step: 12
Training loss: 0.16286373419601802
Validation loss: 2.378492086150079

Epoch: 6| Step: 13
Training loss: 0.16148772600237712
Validation loss: 2.3796191133906848

Epoch: 708| Step: 0
Training loss: 0.17866270529665088
Validation loss: 2.3831821401725213

Epoch: 6| Step: 1
Training loss: 0.10865073869895592
Validation loss: 2.3785258234691544

Epoch: 6| Step: 2
Training loss: 0.10844852819484986
Validation loss: 2.334008541798137

Epoch: 6| Step: 3
Training loss: 0.09014634301082886
Validation loss: 2.364219747799588

Epoch: 6| Step: 4
Training loss: 0.1683644690041686
Validation loss: 2.3419878760992616

Epoch: 6| Step: 5
Training loss: 0.12378585015580078
Validation loss: 2.3282005505368915

Epoch: 6| Step: 6
Training loss: 0.15096428069856757
Validation loss: 2.333881421109027

Epoch: 6| Step: 7
Training loss: 0.1533057697955638
Validation loss: 2.3418001570050797

Epoch: 6| Step: 8
Training loss: 0.16574702693429003
Validation loss: 2.344563634604716

Epoch: 6| Step: 9
Training loss: 0.11968446336783442
Validation loss: 2.3236167298314636

Epoch: 6| Step: 10
Training loss: 0.1788005708303983
Validation loss: 2.3093986900660095

Epoch: 6| Step: 11
Training loss: 0.13535246029951017
Validation loss: 2.326249842946603

Epoch: 6| Step: 12
Training loss: 0.12148566429337176
Validation loss: 2.3374368830721695

Epoch: 6| Step: 13
Training loss: 0.13083007826167647
Validation loss: 2.354193317488622

Epoch: 709| Step: 0
Training loss: 0.10375522379191045
Validation loss: 2.358436027649695

Epoch: 6| Step: 1
Training loss: 0.11128421385925526
Validation loss: 2.3469906886698446

Epoch: 6| Step: 2
Training loss: 0.15927833589564083
Validation loss: 2.343457468023131

Epoch: 6| Step: 3
Training loss: 0.1246786755950364
Validation loss: 2.373749946408003

Epoch: 6| Step: 4
Training loss: 0.12037650857952605
Validation loss: 2.3789441508306504

Epoch: 6| Step: 5
Training loss: 0.15182651844845108
Validation loss: 2.36086734134248

Epoch: 6| Step: 6
Training loss: 0.10455572121970058
Validation loss: 2.3816751434917722

Epoch: 6| Step: 7
Training loss: 0.1871121886167242
Validation loss: 2.3718275482300575

Epoch: 6| Step: 8
Training loss: 0.17344171458785435
Validation loss: 2.340556156628978

Epoch: 6| Step: 9
Training loss: 0.10955246934765007
Validation loss: 2.340154644668984

Epoch: 6| Step: 10
Training loss: 0.16601386349809394
Validation loss: 2.3527781171799633

Epoch: 6| Step: 11
Training loss: 0.13882552620511357
Validation loss: 2.302046460415176

Epoch: 6| Step: 12
Training loss: 0.12351326126452393
Validation loss: 2.339736956034985

Epoch: 6| Step: 13
Training loss: 0.18067099068219133
Validation loss: 2.309779441786635

Epoch: 710| Step: 0
Training loss: 0.11476163961737014
Validation loss: 2.3539850562593596

Epoch: 6| Step: 1
Training loss: 0.11502391378662562
Validation loss: 2.3348846501998914

Epoch: 6| Step: 2
Training loss: 0.1170145745741541
Validation loss: 2.35068970623599

Epoch: 6| Step: 3
Training loss: 0.15525540661035872
Validation loss: 2.358607622046092

Epoch: 6| Step: 4
Training loss: 0.17790888508731934
Validation loss: 2.3773617133538107

Epoch: 6| Step: 5
Training loss: 0.11212868374681349
Validation loss: 2.3791763791075926

Epoch: 6| Step: 6
Training loss: 0.1712346067610637
Validation loss: 2.369206161315551

Epoch: 6| Step: 7
Training loss: 0.1189820375419547
Validation loss: 2.379852725751535

Epoch: 6| Step: 8
Training loss: 0.16571710337842807
Validation loss: 2.35608119652072

Epoch: 6| Step: 9
Training loss: 0.12178847775192583
Validation loss: 2.3658404661971897

Epoch: 6| Step: 10
Training loss: 0.14623559807511402
Validation loss: 2.3597723165833164

Epoch: 6| Step: 11
Training loss: 0.13816766680803946
Validation loss: 2.395236427741964

Epoch: 6| Step: 12
Training loss: 0.19201241092753077
Validation loss: 2.3727274807512977

Epoch: 6| Step: 13
Training loss: 0.13742803104398377
Validation loss: 2.358601391756919

Epoch: 711| Step: 0
Training loss: 0.15895346498054602
Validation loss: 2.357105743990731

Epoch: 6| Step: 1
Training loss: 0.09280334793589677
Validation loss: 2.3143055432073627

Epoch: 6| Step: 2
Training loss: 0.12084100480706444
Validation loss: 2.3550065510077847

Epoch: 6| Step: 3
Training loss: 0.08713439808656996
Validation loss: 2.3438992453470577

Epoch: 6| Step: 4
Training loss: 0.12302891282266336
Validation loss: 2.306434634583836

Epoch: 6| Step: 5
Training loss: 0.1580781619716781
Validation loss: 2.3021554908214306

Epoch: 6| Step: 6
Training loss: 0.1296037529938414
Validation loss: 2.3248584099071548

Epoch: 6| Step: 7
Training loss: 0.16358791123202457
Validation loss: 2.367058525361012

Epoch: 6| Step: 8
Training loss: 0.1471510783161819
Validation loss: 2.330283866485206

Epoch: 6| Step: 9
Training loss: 0.1361743031874551
Validation loss: 2.3163174275303153

Epoch: 6| Step: 10
Training loss: 0.10860593370658399
Validation loss: 2.353744585156051

Epoch: 6| Step: 11
Training loss: 0.1007410214960514
Validation loss: 2.3656153930836585

Epoch: 6| Step: 12
Training loss: 0.12106166691461447
Validation loss: 2.375286186518441

Epoch: 6| Step: 13
Training loss: 0.11812035879473347
Validation loss: 2.3733388221777956

Epoch: 712| Step: 0
Training loss: 0.13822274613818838
Validation loss: 2.3727578101915414

Epoch: 6| Step: 1
Training loss: 0.07916632697174743
Validation loss: 2.3821324220332323

Epoch: 6| Step: 2
Training loss: 0.13116549513287387
Validation loss: 2.3649006337449934

Epoch: 6| Step: 3
Training loss: 0.14523044494679602
Validation loss: 2.3554768453425

Epoch: 6| Step: 4
Training loss: 0.11142926891863161
Validation loss: 2.369689569952554

Epoch: 6| Step: 5
Training loss: 0.10964354687293396
Validation loss: 2.3593463772370855

Epoch: 6| Step: 6
Training loss: 0.13768114192904204
Validation loss: 2.3613579098294366

Epoch: 6| Step: 7
Training loss: 0.13324370227624807
Validation loss: 2.385322241860629

Epoch: 6| Step: 8
Training loss: 0.1510072489417162
Validation loss: 2.384184060560948

Epoch: 6| Step: 9
Training loss: 0.09803802727677015
Validation loss: 2.377248171689869

Epoch: 6| Step: 10
Training loss: 0.0948873806509826
Validation loss: 2.3820214507588924

Epoch: 6| Step: 11
Training loss: 0.09045940903550881
Validation loss: 2.390257501850348

Epoch: 6| Step: 12
Training loss: 0.1171854972668222
Validation loss: 2.35341596998747

Epoch: 6| Step: 13
Training loss: 0.1270666568463622
Validation loss: 2.400718390840371

Epoch: 713| Step: 0
Training loss: 0.11282208714998945
Validation loss: 2.338439624189006

Epoch: 6| Step: 1
Training loss: 0.08889892032524693
Validation loss: 2.3464836995446543

Epoch: 6| Step: 2
Training loss: 0.10515323882588394
Validation loss: 2.3671222413658115

Epoch: 6| Step: 3
Training loss: 0.1053935330232211
Validation loss: 2.3938630793542073

Epoch: 6| Step: 4
Training loss: 0.11900564270405499
Validation loss: 2.3470846975115367

Epoch: 6| Step: 5
Training loss: 0.1283559758345152
Validation loss: 2.340686257528981

Epoch: 6| Step: 6
Training loss: 0.14860798431634584
Validation loss: 2.3561818453529084

Epoch: 6| Step: 7
Training loss: 0.1101619390952988
Validation loss: 2.375668699794744

Epoch: 6| Step: 8
Training loss: 0.13207899223628686
Validation loss: 2.368223376481177

Epoch: 6| Step: 9
Training loss: 0.13394980971784556
Validation loss: 2.3137735985339125

Epoch: 6| Step: 10
Training loss: 0.1180434912317158
Validation loss: 2.368478921540878

Epoch: 6| Step: 11
Training loss: 0.16794874382639507
Validation loss: 2.328320733064165

Epoch: 6| Step: 12
Training loss: 0.142068192710302
Validation loss: 2.345356977287424

Epoch: 6| Step: 13
Training loss: 0.10445161727068186
Validation loss: 2.3772635842301435

Epoch: 714| Step: 0
Training loss: 0.11895293945765033
Validation loss: 2.35092225341234

Epoch: 6| Step: 1
Training loss: 0.1271691758079935
Validation loss: 2.350804457583349

Epoch: 6| Step: 2
Training loss: 0.10787057366384781
Validation loss: 2.3284956675602024

Epoch: 6| Step: 3
Training loss: 0.12027689930343516
Validation loss: 2.3826096497976965

Epoch: 6| Step: 4
Training loss: 0.07225812731329992
Validation loss: 2.347227100092092

Epoch: 6| Step: 5
Training loss: 0.10409450167101397
Validation loss: 2.359678089645661

Epoch: 6| Step: 6
Training loss: 0.10520609186006838
Validation loss: 2.3834640324963083

Epoch: 6| Step: 7
Training loss: 0.1059570839877371
Validation loss: 2.358176738978661

Epoch: 6| Step: 8
Training loss: 0.13003982289333452
Validation loss: 2.3957551562665635

Epoch: 6| Step: 9
Training loss: 0.07600936304197471
Validation loss: 2.368800975763949

Epoch: 6| Step: 10
Training loss: 0.12173718965904858
Validation loss: 2.3613459050722305

Epoch: 6| Step: 11
Training loss: 0.12596513267533876
Validation loss: 2.386552938671742

Epoch: 6| Step: 12
Training loss: 0.14518811480785687
Validation loss: 2.419775546592511

Epoch: 6| Step: 13
Training loss: 0.17072065643092396
Validation loss: 2.355591239962513

Epoch: 715| Step: 0
Training loss: 0.11533326011862227
Validation loss: 2.3740748928270734

Epoch: 6| Step: 1
Training loss: 0.11363406978264373
Validation loss: 2.386703950623162

Epoch: 6| Step: 2
Training loss: 0.11066028149545294
Validation loss: 2.3690771916080076

Epoch: 6| Step: 3
Training loss: 0.13386233613457207
Validation loss: 2.3369065775229747

Epoch: 6| Step: 4
Training loss: 0.07535450977061094
Validation loss: 2.3404982083988384

Epoch: 6| Step: 5
Training loss: 0.169474819345838
Validation loss: 2.3411209729478797

Epoch: 6| Step: 6
Training loss: 0.12072175323538646
Validation loss: 2.345807432671632

Epoch: 6| Step: 7
Training loss: 0.12697229974165908
Validation loss: 2.364537891903397

Epoch: 6| Step: 8
Training loss: 0.13130158818338322
Validation loss: 2.3320868379297015

Epoch: 6| Step: 9
Training loss: 0.14174663084389214
Validation loss: 2.354903594106582

Epoch: 6| Step: 10
Training loss: 0.1389326745957231
Validation loss: 2.3534883252729184

Epoch: 6| Step: 11
Training loss: 0.18282422655756517
Validation loss: 2.3730315690327886

Epoch: 6| Step: 12
Training loss: 0.13671936307497168
Validation loss: 2.3820951283322063

Epoch: 6| Step: 13
Training loss: 0.11770642146805617
Validation loss: 2.3614803103571678

Epoch: 716| Step: 0
Training loss: 0.19332945235717086
Validation loss: 2.3655768284134595

Epoch: 6| Step: 1
Training loss: 0.08877227766364842
Validation loss: 2.391796723826675

Epoch: 6| Step: 2
Training loss: 0.1331113300446346
Validation loss: 2.3548431558864835

Epoch: 6| Step: 3
Training loss: 0.16854342028464345
Validation loss: 2.3835620053036712

Epoch: 6| Step: 4
Training loss: 0.1477137035026761
Validation loss: 2.3607898390635955

Epoch: 6| Step: 5
Training loss: 0.0987046235287664
Validation loss: 2.386142449599729

Epoch: 6| Step: 6
Training loss: 0.09271954928909576
Validation loss: 2.3555130748700175

Epoch: 6| Step: 7
Training loss: 0.10809204255961476
Validation loss: 2.3638784588422688

Epoch: 6| Step: 8
Training loss: 0.1474348828369268
Validation loss: 2.3446948350361385

Epoch: 6| Step: 9
Training loss: 0.08423742993493116
Validation loss: 2.310403356180255

Epoch: 6| Step: 10
Training loss: 0.16255942459379955
Validation loss: 2.3523825448637115

Epoch: 6| Step: 11
Training loss: 0.11447139079968426
Validation loss: 2.349130920511967

Epoch: 6| Step: 12
Training loss: 0.15511478259860031
Validation loss: 2.3417863436517727

Epoch: 6| Step: 13
Training loss: 0.11274010794371639
Validation loss: 2.372516086609888

Epoch: 717| Step: 0
Training loss: 0.0892759813811063
Validation loss: 2.326223331911801

Epoch: 6| Step: 1
Training loss: 0.1595745221520055
Validation loss: 2.3541394706837306

Epoch: 6| Step: 2
Training loss: 0.12439449252204214
Validation loss: 2.3637987961880387

Epoch: 6| Step: 3
Training loss: 0.10027168311771445
Validation loss: 2.3458830437492852

Epoch: 6| Step: 4
Training loss: 0.12799989797496827
Validation loss: 2.3440707429570646

Epoch: 6| Step: 5
Training loss: 0.1170414093482024
Validation loss: 2.3670300529116473

Epoch: 6| Step: 6
Training loss: 0.13406787139073317
Validation loss: 2.375265295542592

Epoch: 6| Step: 7
Training loss: 0.10822814159883885
Validation loss: 2.353312648822717

Epoch: 6| Step: 8
Training loss: 0.09244524477289924
Validation loss: 2.364027942438265

Epoch: 6| Step: 9
Training loss: 0.1421312422597759
Validation loss: 2.3669476878520364

Epoch: 6| Step: 10
Training loss: 0.13793810278307522
Validation loss: 2.3291382837430894

Epoch: 6| Step: 11
Training loss: 0.15190985830997245
Validation loss: 2.352323976324912

Epoch: 6| Step: 12
Training loss: 0.07345998171353223
Validation loss: 2.3574197326705337

Epoch: 6| Step: 13
Training loss: 0.10910761455490672
Validation loss: 2.379586853532329

Epoch: 718| Step: 0
Training loss: 0.13208256012282102
Validation loss: 2.3520242836347154

Epoch: 6| Step: 1
Training loss: 0.1046173825236877
Validation loss: 2.327020969598673

Epoch: 6| Step: 2
Training loss: 0.10662743535759997
Validation loss: 2.337586844594966

Epoch: 6| Step: 3
Training loss: 0.06479461830832714
Validation loss: 2.3589576809026

Epoch: 6| Step: 4
Training loss: 0.10640574078431028
Validation loss: 2.3425838913887156

Epoch: 6| Step: 5
Training loss: 0.10259963471752434
Validation loss: 2.3524744229794523

Epoch: 6| Step: 6
Training loss: 0.11676026985898186
Validation loss: 2.3604226060583744

Epoch: 6| Step: 7
Training loss: 0.12066434280397528
Validation loss: 2.352149693560705

Epoch: 6| Step: 8
Training loss: 0.13179389848496775
Validation loss: 2.3607315372038897

Epoch: 6| Step: 9
Training loss: 0.09046896787890615
Validation loss: 2.353998922182744

Epoch: 6| Step: 10
Training loss: 0.1111762114595228
Validation loss: 2.367036391524337

Epoch: 6| Step: 11
Training loss: 0.09995343122365323
Validation loss: 2.3732197840881706

Epoch: 6| Step: 12
Training loss: 0.12185713655431336
Validation loss: 2.3831719915238905

Epoch: 6| Step: 13
Training loss: 0.09429126198946991
Validation loss: 2.3477209375510615

Epoch: 719| Step: 0
Training loss: 0.13606295660991038
Validation loss: 2.353103924521686

Epoch: 6| Step: 1
Training loss: 0.08181827577634616
Validation loss: 2.374367725295189

Epoch: 6| Step: 2
Training loss: 0.12671217427437176
Validation loss: 2.3315231487847194

Epoch: 6| Step: 3
Training loss: 0.09180572142484233
Validation loss: 2.329945033102526

Epoch: 6| Step: 4
Training loss: 0.09855332334695456
Validation loss: 2.355998562946129

Epoch: 6| Step: 5
Training loss: 0.12775001575942044
Validation loss: 2.363677449017741

Epoch: 6| Step: 6
Training loss: 0.12123678588879094
Validation loss: 2.361708602570579

Epoch: 6| Step: 7
Training loss: 0.11685811481798612
Validation loss: 2.3490230754289074

Epoch: 6| Step: 8
Training loss: 0.13352278503272838
Validation loss: 2.3430463953008496

Epoch: 6| Step: 9
Training loss: 0.135129830363621
Validation loss: 2.3655257891749106

Epoch: 6| Step: 10
Training loss: 0.1417776722686783
Validation loss: 2.324304417415055

Epoch: 6| Step: 11
Training loss: 0.20389498975509182
Validation loss: 2.32854953486873

Epoch: 6| Step: 12
Training loss: 0.10699774938320968
Validation loss: 2.336987020846659

Epoch: 6| Step: 13
Training loss: 0.18108496222514625
Validation loss: 2.357146303250449

Epoch: 720| Step: 0
Training loss: 0.1030307651692913
Validation loss: 2.390635241135949

Epoch: 6| Step: 1
Training loss: 0.11685041983203161
Validation loss: 2.4084088746651116

Epoch: 6| Step: 2
Training loss: 0.14253481768964862
Validation loss: 2.393578747134937

Epoch: 6| Step: 3
Training loss: 0.14213480025181427
Validation loss: 2.3937144147006286

Epoch: 6| Step: 4
Training loss: 0.1744657992940726
Validation loss: 2.436005715146983

Epoch: 6| Step: 5
Training loss: 0.1329478107510652
Validation loss: 2.389812099910136

Epoch: 6| Step: 6
Training loss: 0.13109985005459623
Validation loss: 2.3816704277685665

Epoch: 6| Step: 7
Training loss: 0.10616200481202961
Validation loss: 2.3409825448896964

Epoch: 6| Step: 8
Training loss: 0.11885225072425873
Validation loss: 2.4086955629841658

Epoch: 6| Step: 9
Training loss: 0.17726534484061054
Validation loss: 2.349731842551706

Epoch: 6| Step: 10
Training loss: 0.13385471765674437
Validation loss: 2.3462165820498067

Epoch: 6| Step: 11
Training loss: 0.123230018256731
Validation loss: 2.3352676129614265

Epoch: 6| Step: 12
Training loss: 0.10858964809382396
Validation loss: 2.3242735309854403

Epoch: 6| Step: 13
Training loss: 0.10975650260730697
Validation loss: 2.3265622219243456

Epoch: 721| Step: 0
Training loss: 0.147994018922751
Validation loss: 2.320403611207814

Epoch: 6| Step: 1
Training loss: 0.0851103958862129
Validation loss: 2.3113238517886456

Epoch: 6| Step: 2
Training loss: 0.12737543583637204
Validation loss: 2.3238879481198498

Epoch: 6| Step: 3
Training loss: 0.06989879893342392
Validation loss: 2.3335217388473626

Epoch: 6| Step: 4
Training loss: 0.116301637404675
Validation loss: 2.3249388588037565

Epoch: 6| Step: 5
Training loss: 0.11011538085592155
Validation loss: 2.323222548865047

Epoch: 6| Step: 6
Training loss: 0.09606704806132543
Validation loss: 2.3549767386462004

Epoch: 6| Step: 7
Training loss: 0.10860202332411154
Validation loss: 2.3576259430747517

Epoch: 6| Step: 8
Training loss: 0.17106064863809414
Validation loss: 2.3529442689807145

Epoch: 6| Step: 9
Training loss: 0.09947627187764473
Validation loss: 2.346144607861041

Epoch: 6| Step: 10
Training loss: 0.14734704627823006
Validation loss: 2.3456257982104223

Epoch: 6| Step: 11
Training loss: 0.07945148752338733
Validation loss: 2.3457476945085713

Epoch: 6| Step: 12
Training loss: 0.11303251599068746
Validation loss: 2.3847242502947217

Epoch: 6| Step: 13
Training loss: 0.15577743116191858
Validation loss: 2.364211185759985

Epoch: 722| Step: 0
Training loss: 0.09998324764270107
Validation loss: 2.344692371651437

Epoch: 6| Step: 1
Training loss: 0.11382577185466498
Validation loss: 2.3243793220097007

Epoch: 6| Step: 2
Training loss: 0.09477183646328567
Validation loss: 2.331173818913271

Epoch: 6| Step: 3
Training loss: 0.12640800819070147
Validation loss: 2.309464206099669

Epoch: 6| Step: 4
Training loss: 0.07790837056104373
Validation loss: 2.3111294645819647

Epoch: 6| Step: 5
Training loss: 0.10902701094213273
Validation loss: 2.332567023391551

Epoch: 6| Step: 6
Training loss: 0.09893086223602215
Validation loss: 2.3607651450006233

Epoch: 6| Step: 7
Training loss: 0.10747837834766331
Validation loss: 2.3422295980172674

Epoch: 6| Step: 8
Training loss: 0.132139153939537
Validation loss: 2.3728484796272227

Epoch: 6| Step: 9
Training loss: 0.11659588488457227
Validation loss: 2.367127163415658

Epoch: 6| Step: 10
Training loss: 0.10988979443534962
Validation loss: 2.3564351077220227

Epoch: 6| Step: 11
Training loss: 0.10102521934144447
Validation loss: 2.3589544944955354

Epoch: 6| Step: 12
Training loss: 0.08323977820455522
Validation loss: 2.32708044983302

Epoch: 6| Step: 13
Training loss: 0.15165913023297634
Validation loss: 2.335068608627559

Epoch: 723| Step: 0
Training loss: 0.10525427309454738
Validation loss: 2.3087810032801017

Epoch: 6| Step: 1
Training loss: 0.09261706374347967
Validation loss: 2.331695281245779

Epoch: 6| Step: 2
Training loss: 0.10154738680558976
Validation loss: 2.352298267020546

Epoch: 6| Step: 3
Training loss: 0.16205188007402882
Validation loss: 2.3618212902405937

Epoch: 6| Step: 4
Training loss: 0.12149834721180872
Validation loss: 2.374537089840314

Epoch: 6| Step: 5
Training loss: 0.07696139925317794
Validation loss: 2.3190813438519418

Epoch: 6| Step: 6
Training loss: 0.07806303129614753
Validation loss: 2.3336209553530765

Epoch: 6| Step: 7
Training loss: 0.09688822575240613
Validation loss: 2.3524266243793197

Epoch: 6| Step: 8
Training loss: 0.150852343001755
Validation loss: 2.3603290926057867

Epoch: 6| Step: 9
Training loss: 0.08174021500974187
Validation loss: 2.355901598475082

Epoch: 6| Step: 10
Training loss: 0.13131187972757946
Validation loss: 2.3164209993687592

Epoch: 6| Step: 11
Training loss: 0.16770247489656048
Validation loss: 2.325905232137183

Epoch: 6| Step: 12
Training loss: 0.1403689968238596
Validation loss: 2.3001018139158487

Epoch: 6| Step: 13
Training loss: 0.07082284057552972
Validation loss: 2.317033465138687

Epoch: 724| Step: 0
Training loss: 0.12466538614391663
Validation loss: 2.317992616432398

Epoch: 6| Step: 1
Training loss: 0.12472554340537596
Validation loss: 2.325350556071162

Epoch: 6| Step: 2
Training loss: 0.09751337567152486
Validation loss: 2.342225065564022

Epoch: 6| Step: 3
Training loss: 0.07757004387957224
Validation loss: 2.3418956714096364

Epoch: 6| Step: 4
Training loss: 0.10435400944495674
Validation loss: 2.349785288495325

Epoch: 6| Step: 5
Training loss: 0.10922163616372704
Validation loss: 2.33331779908431

Epoch: 6| Step: 6
Training loss: 0.09870063697048746
Validation loss: 2.393401431047421

Epoch: 6| Step: 7
Training loss: 0.13467663439006253
Validation loss: 2.3819014985273683

Epoch: 6| Step: 8
Training loss: 0.09584340693907135
Validation loss: 2.3779520536106475

Epoch: 6| Step: 9
Training loss: 0.10966649551285246
Validation loss: 2.376560156419368

Epoch: 6| Step: 10
Training loss: 0.08970821045960745
Validation loss: 2.37462955904035

Epoch: 6| Step: 11
Training loss: 0.1270392199335213
Validation loss: 2.384365537119292

Epoch: 6| Step: 12
Training loss: 0.11875282161899055
Validation loss: 2.3974601397909727

Epoch: 6| Step: 13
Training loss: 0.105248990520135
Validation loss: 2.3755492194404155

Epoch: 725| Step: 0
Training loss: 0.08643429924320159
Validation loss: 2.3478180700876665

Epoch: 6| Step: 1
Training loss: 0.11044041676952185
Validation loss: 2.366662857700225

Epoch: 6| Step: 2
Training loss: 0.15014370551290274
Validation loss: 2.3428383293538415

Epoch: 6| Step: 3
Training loss: 0.11410545722507172
Validation loss: 2.3574588826186234

Epoch: 6| Step: 4
Training loss: 0.11588502912420844
Validation loss: 2.350762084363273

Epoch: 6| Step: 5
Training loss: 0.09330305212114938
Validation loss: 2.3487951503357065

Epoch: 6| Step: 6
Training loss: 0.08439777064799311
Validation loss: 2.3183813979982206

Epoch: 6| Step: 7
Training loss: 0.11052891733681036
Validation loss: 2.2879271311727023

Epoch: 6| Step: 8
Training loss: 0.1553208740517411
Validation loss: 2.30163331580281

Epoch: 6| Step: 9
Training loss: 0.05960566222276143
Validation loss: 2.296871077870635

Epoch: 6| Step: 10
Training loss: 0.12801096423695224
Validation loss: 2.3306136461453373

Epoch: 6| Step: 11
Training loss: 0.10696442912839514
Validation loss: 2.2995917324833495

Epoch: 6| Step: 12
Training loss: 0.12254364560828522
Validation loss: 2.313557695280071

Epoch: 6| Step: 13
Training loss: 0.10903506587035042
Validation loss: 2.3263456938624154

Epoch: 726| Step: 0
Training loss: 0.09169732438183306
Validation loss: 2.340150125177215

Epoch: 6| Step: 1
Training loss: 0.14510964313678237
Validation loss: 2.3319200050276954

Epoch: 6| Step: 2
Training loss: 0.07832078243885178
Validation loss: 2.3453533269754896

Epoch: 6| Step: 3
Training loss: 0.11360008489687863
Validation loss: 2.38031880682941

Epoch: 6| Step: 4
Training loss: 0.13050539621344523
Validation loss: 2.3691657273598055

Epoch: 6| Step: 5
Training loss: 0.13466343253105015
Validation loss: 2.384194252482045

Epoch: 6| Step: 6
Training loss: 0.10458166088645218
Validation loss: 2.3893993489632956

Epoch: 6| Step: 7
Training loss: 0.12330101274806708
Validation loss: 2.409111809935804

Epoch: 6| Step: 8
Training loss: 0.17545591553705872
Validation loss: 2.375957140709074

Epoch: 6| Step: 9
Training loss: 0.10229243637379361
Validation loss: 2.404020286658191

Epoch: 6| Step: 10
Training loss: 0.1549003064448839
Validation loss: 2.3743256635420207

Epoch: 6| Step: 11
Training loss: 0.1479918918821134
Validation loss: 2.362028530597364

Epoch: 6| Step: 12
Training loss: 0.07227321533343817
Validation loss: 2.3744467828765243

Epoch: 6| Step: 13
Training loss: 0.09621359961230612
Validation loss: 2.3283011868139676

Epoch: 727| Step: 0
Training loss: 0.0926423702973126
Validation loss: 2.3775583745833644

Epoch: 6| Step: 1
Training loss: 0.18946814723283087
Validation loss: 2.3362872192923914

Epoch: 6| Step: 2
Training loss: 0.13702561137430666
Validation loss: 2.359934365036101

Epoch: 6| Step: 3
Training loss: 0.10076567877012224
Validation loss: 2.3742055854240323

Epoch: 6| Step: 4
Training loss: 0.11179963031841603
Validation loss: 2.3700458082475615

Epoch: 6| Step: 5
Training loss: 0.08262908592848393
Validation loss: 2.3855819308156363

Epoch: 6| Step: 6
Training loss: 0.12628933426001512
Validation loss: 2.3647476543232417

Epoch: 6| Step: 7
Training loss: 0.12651647154619164
Validation loss: 2.399800467443102

Epoch: 6| Step: 8
Training loss: 0.12669985523302169
Validation loss: 2.355802669034446

Epoch: 6| Step: 9
Training loss: 0.10232483419665397
Validation loss: 2.370320122579248

Epoch: 6| Step: 10
Training loss: 0.11503826442240901
Validation loss: 2.3676714068682467

Epoch: 6| Step: 11
Training loss: 0.10739620075323313
Validation loss: 2.349008558052102

Epoch: 6| Step: 12
Training loss: 0.10318703952735085
Validation loss: 2.313988749329302

Epoch: 6| Step: 13
Training loss: 0.13625890510225572
Validation loss: 2.341016250585382

Epoch: 728| Step: 0
Training loss: 0.08845520940796714
Validation loss: 2.3037126724026655

Epoch: 6| Step: 1
Training loss: 0.12134919603206805
Validation loss: 2.341063304254392

Epoch: 6| Step: 2
Training loss: 0.12667909537949512
Validation loss: 2.3443282936404217

Epoch: 6| Step: 3
Training loss: 0.10920561293288071
Validation loss: 2.3135372497374886

Epoch: 6| Step: 4
Training loss: 0.12082621415379859
Validation loss: 2.3044502882896003

Epoch: 6| Step: 5
Training loss: 0.12078712851886576
Validation loss: 2.3283039290464926

Epoch: 6| Step: 6
Training loss: 0.0802683402854014
Validation loss: 2.3178282738613434

Epoch: 6| Step: 7
Training loss: 0.13082046784431298
Validation loss: 2.2983838883712013

Epoch: 6| Step: 8
Training loss: 0.12343209381578064
Validation loss: 2.32366807176719

Epoch: 6| Step: 9
Training loss: 0.11173023418274793
Validation loss: 2.327643992882593

Epoch: 6| Step: 10
Training loss: 0.11529586250697062
Validation loss: 2.357101123766916

Epoch: 6| Step: 11
Training loss: 0.14977626903997898
Validation loss: 2.351099862385308

Epoch: 6| Step: 12
Training loss: 0.19154866428412384
Validation loss: 2.3708868943882218

Epoch: 6| Step: 13
Training loss: 0.062301658165091714
Validation loss: 2.360723068393675

Epoch: 729| Step: 0
Training loss: 0.06610664633022323
Validation loss: 2.363772141775062

Epoch: 6| Step: 1
Training loss: 0.09752260600185307
Validation loss: 2.340878953659982

Epoch: 6| Step: 2
Training loss: 0.11002417756557463
Validation loss: 2.344093212306413

Epoch: 6| Step: 3
Training loss: 0.11212569775863947
Validation loss: 2.347924792113193

Epoch: 6| Step: 4
Training loss: 0.10780536949378228
Validation loss: 2.387322711423588

Epoch: 6| Step: 5
Training loss: 0.09403169055308128
Validation loss: 2.320224859055379

Epoch: 6| Step: 6
Training loss: 0.1302526128501357
Validation loss: 2.331250284554471

Epoch: 6| Step: 7
Training loss: 0.12522337743264284
Validation loss: 2.349227572974941

Epoch: 6| Step: 8
Training loss: 0.1059726404743154
Validation loss: 2.3449330877597756

Epoch: 6| Step: 9
Training loss: 0.11083655415497402
Validation loss: 2.371250307775674

Epoch: 6| Step: 10
Training loss: 0.12901420119023024
Validation loss: 2.327412037690146

Epoch: 6| Step: 11
Training loss: 0.10356865730007554
Validation loss: 2.326741200083121

Epoch: 6| Step: 12
Training loss: 0.1251182146176123
Validation loss: 2.3584682681093194

Epoch: 6| Step: 13
Training loss: 0.10374096868456763
Validation loss: 2.3145395157838626

Epoch: 730| Step: 0
Training loss: 0.08921295015219642
Validation loss: 2.345487786857333

Epoch: 6| Step: 1
Training loss: 0.07798852026291583
Validation loss: 2.3211189987811736

Epoch: 6| Step: 2
Training loss: 0.11844650121117134
Validation loss: 2.2944463161984707

Epoch: 6| Step: 3
Training loss: 0.0728033972747731
Validation loss: 2.3242379864456497

Epoch: 6| Step: 4
Training loss: 0.1217958186986507
Validation loss: 2.3434581222090536

Epoch: 6| Step: 5
Training loss: 0.08224631681572807
Validation loss: 2.3173520503713085

Epoch: 6| Step: 6
Training loss: 0.16285995427921368
Validation loss: 2.335447951446094

Epoch: 6| Step: 7
Training loss: 0.09758748494467333
Validation loss: 2.3374275692464965

Epoch: 6| Step: 8
Training loss: 0.07072260914832325
Validation loss: 2.33335628219898

Epoch: 6| Step: 9
Training loss: 0.1249154445646413
Validation loss: 2.345783069949082

Epoch: 6| Step: 10
Training loss: 0.13096362558896824
Validation loss: 2.3536670645452746

Epoch: 6| Step: 11
Training loss: 0.11240496512238896
Validation loss: 2.328673762816234

Epoch: 6| Step: 12
Training loss: 0.109647810825124
Validation loss: 2.355422183282093

Epoch: 6| Step: 13
Training loss: 0.09163991210738262
Validation loss: 2.331454359536703

Epoch: 731| Step: 0
Training loss: 0.12345472740723769
Validation loss: 2.3428186613000874

Epoch: 6| Step: 1
Training loss: 0.10453450602719111
Validation loss: 2.33571428255907

Epoch: 6| Step: 2
Training loss: 0.09366633735304149
Validation loss: 2.3483079219398

Epoch: 6| Step: 3
Training loss: 0.12150796679585874
Validation loss: 2.3664483283217344

Epoch: 6| Step: 4
Training loss: 0.08448047271021551
Validation loss: 2.3501570659474025

Epoch: 6| Step: 5
Training loss: 0.09647314570019694
Validation loss: 2.332473365314994

Epoch: 6| Step: 6
Training loss: 0.12990147592784929
Validation loss: 2.332446002855503

Epoch: 6| Step: 7
Training loss: 0.12116765643338771
Validation loss: 2.312421801263988

Epoch: 6| Step: 8
Training loss: 0.11172145660162847
Validation loss: 2.3046242592799007

Epoch: 6| Step: 9
Training loss: 0.09087503486879249
Validation loss: 2.326704842075346

Epoch: 6| Step: 10
Training loss: 0.16454977380461144
Validation loss: 2.3382966464325143

Epoch: 6| Step: 11
Training loss: 0.13173509202268158
Validation loss: 2.3161425771516293

Epoch: 6| Step: 12
Training loss: 0.11091177450685681
Validation loss: 2.2973046948990894

Epoch: 6| Step: 13
Training loss: 0.09528518914743811
Validation loss: 2.319316103303704

Epoch: 732| Step: 0
Training loss: 0.09535763621569383
Validation loss: 2.3084632252664528

Epoch: 6| Step: 1
Training loss: 0.11353371702443864
Validation loss: 2.303484214875412

Epoch: 6| Step: 2
Training loss: 0.07609059202898581
Validation loss: 2.340925897289347

Epoch: 6| Step: 3
Training loss: 0.08399803028429835
Validation loss: 2.321862721698129

Epoch: 6| Step: 4
Training loss: 0.09793664256300541
Validation loss: 2.336965033864912

Epoch: 6| Step: 5
Training loss: 0.10289487412874451
Validation loss: 2.326242488963946

Epoch: 6| Step: 6
Training loss: 0.12331833489529756
Validation loss: 2.3250834438585457

Epoch: 6| Step: 7
Training loss: 0.06320896965700677
Validation loss: 2.357688680934488

Epoch: 6| Step: 8
Training loss: 0.08572524854921452
Validation loss: 2.3633406670020936

Epoch: 6| Step: 9
Training loss: 0.13596706151165944
Validation loss: 2.365906135104054

Epoch: 6| Step: 10
Training loss: 0.10966218982393078
Validation loss: 2.362504163630859

Epoch: 6| Step: 11
Training loss: 0.07834807971543775
Validation loss: 2.382959779477544

Epoch: 6| Step: 12
Training loss: 0.0979137268876372
Validation loss: 2.3777849075024693

Epoch: 6| Step: 13
Training loss: 0.09029171017993559
Validation loss: 2.356415158232571

Epoch: 733| Step: 0
Training loss: 0.092992063211869
Validation loss: 2.374035393808936

Epoch: 6| Step: 1
Training loss: 0.1071185163468779
Validation loss: 2.3776829299268885

Epoch: 6| Step: 2
Training loss: 0.10085756236722021
Validation loss: 2.385194624006909

Epoch: 6| Step: 3
Training loss: 0.12770341562144466
Validation loss: 2.3771650487959426

Epoch: 6| Step: 4
Training loss: 0.14550425377916681
Validation loss: 2.3816966822046814

Epoch: 6| Step: 5
Training loss: 0.08878903568131477
Validation loss: 2.3409640319296567

Epoch: 6| Step: 6
Training loss: 0.07975960687787385
Validation loss: 2.336726686226639

Epoch: 6| Step: 7
Training loss: 0.09311789762371957
Validation loss: 2.3565850112494973

Epoch: 6| Step: 8
Training loss: 0.10808030260271176
Validation loss: 2.35823943935611

Epoch: 6| Step: 9
Training loss: 0.10114204047851041
Validation loss: 2.3467221453575826

Epoch: 6| Step: 10
Training loss: 0.10588943505093504
Validation loss: 2.30138082888681

Epoch: 6| Step: 11
Training loss: 0.08845753623058522
Validation loss: 2.3215997182534784

Epoch: 6| Step: 12
Training loss: 0.12140219383386372
Validation loss: 2.314913298619758

Epoch: 6| Step: 13
Training loss: 0.07348430351940866
Validation loss: 2.3533665238053953

Epoch: 734| Step: 0
Training loss: 0.1082961054790975
Validation loss: 2.3760471162145813

Epoch: 6| Step: 1
Training loss: 0.10573536235370314
Validation loss: 2.366440893427378

Epoch: 6| Step: 2
Training loss: 0.10934601978836343
Validation loss: 2.3642638511377454

Epoch: 6| Step: 3
Training loss: 0.1361974040277679
Validation loss: 2.3791168430580223

Epoch: 6| Step: 4
Training loss: 0.09986963118731335
Validation loss: 2.3616567432038966

Epoch: 6| Step: 5
Training loss: 0.120553715988288
Validation loss: 2.370076945398715

Epoch: 6| Step: 6
Training loss: 0.11882599340905828
Validation loss: 2.357923598441835

Epoch: 6| Step: 7
Training loss: 0.09178394368582628
Validation loss: 2.3599883968192477

Epoch: 6| Step: 8
Training loss: 0.08949688628110831
Validation loss: 2.3653069621662217

Epoch: 6| Step: 9
Training loss: 0.10505332193162983
Validation loss: 2.3415253744136124

Epoch: 6| Step: 10
Training loss: 0.08948756183939711
Validation loss: 2.3506188183991363

Epoch: 6| Step: 11
Training loss: 0.08006788106850611
Validation loss: 2.37304585086016

Epoch: 6| Step: 12
Training loss: 0.07623054005929601
Validation loss: 2.354718556255688

Epoch: 6| Step: 13
Training loss: 0.11462103339084687
Validation loss: 2.361044275219343

Epoch: 735| Step: 0
Training loss: 0.10894464226561347
Validation loss: 2.3299695916893635

Epoch: 6| Step: 1
Training loss: 0.11092233319099906
Validation loss: 2.350091904654208

Epoch: 6| Step: 2
Training loss: 0.08624416061170649
Validation loss: 2.3215935101174203

Epoch: 6| Step: 3
Training loss: 0.10894709995618468
Validation loss: 2.3123754452833136

Epoch: 6| Step: 4
Training loss: 0.13777510042541644
Validation loss: 2.3303151218291895

Epoch: 6| Step: 5
Training loss: 0.08286872037284587
Validation loss: 2.348391323923627

Epoch: 6| Step: 6
Training loss: 0.13703838858284592
Validation loss: 2.337832360676684

Epoch: 6| Step: 7
Training loss: 0.1347717062642302
Validation loss: 2.3558850815051815

Epoch: 6| Step: 8
Training loss: 0.0954007803020315
Validation loss: 2.354829982431512

Epoch: 6| Step: 9
Training loss: 0.09680560610651429
Validation loss: 2.3686391783686656

Epoch: 6| Step: 10
Training loss: 0.1150549850066299
Validation loss: 2.3602022088494325

Epoch: 6| Step: 11
Training loss: 0.0653700912986828
Validation loss: 2.364309015191581

Epoch: 6| Step: 12
Training loss: 0.0817643831476941
Validation loss: 2.3905995878525372

Epoch: 6| Step: 13
Training loss: 0.10395934265047461
Validation loss: 2.3748881395180974

Epoch: 736| Step: 0
Training loss: 0.10505560913782358
Validation loss: 2.3699701562243995

Epoch: 6| Step: 1
Training loss: 0.09102786865888433
Validation loss: 2.36142775008719

Epoch: 6| Step: 2
Training loss: 0.11367405007762256
Validation loss: 2.3813696710644736

Epoch: 6| Step: 3
Training loss: 0.0641806289664165
Validation loss: 2.3462577939248654

Epoch: 6| Step: 4
Training loss: 0.07643538525097487
Validation loss: 2.3642948421511836

Epoch: 6| Step: 5
Training loss: 0.07504406493837212
Validation loss: 2.3707537047304417

Epoch: 6| Step: 6
Training loss: 0.10356524915447717
Validation loss: 2.3777101232964983

Epoch: 6| Step: 7
Training loss: 0.08640956187670007
Validation loss: 2.370317753964248

Epoch: 6| Step: 8
Training loss: 0.130924109204372
Validation loss: 2.373327922024468

Epoch: 6| Step: 9
Training loss: 0.09112165050767405
Validation loss: 2.383703241298397

Epoch: 6| Step: 10
Training loss: 0.08537373887561144
Validation loss: 2.3634258250787905

Epoch: 6| Step: 11
Training loss: 0.12517462394323406
Validation loss: 2.3699537091779286

Epoch: 6| Step: 12
Training loss: 0.09474366318811772
Validation loss: 2.3739874710219735

Epoch: 6| Step: 13
Training loss: 0.07423079543495248
Validation loss: 2.405087570981479

Epoch: 737| Step: 0
Training loss: 0.0866560051718884
Validation loss: 2.3624332987826393

Epoch: 6| Step: 1
Training loss: 0.09987731500742777
Validation loss: 2.36758247036156

Epoch: 6| Step: 2
Training loss: 0.13206706097494797
Validation loss: 2.3854096717013644

Epoch: 6| Step: 3
Training loss: 0.11072448154976429
Validation loss: 2.398227770262281

Epoch: 6| Step: 4
Training loss: 0.08974096389405242
Validation loss: 2.3437782674199124

Epoch: 6| Step: 5
Training loss: 0.11597516079907126
Validation loss: 2.3693219732356523

Epoch: 6| Step: 6
Training loss: 0.08251756744756694
Validation loss: 2.3081128233183477

Epoch: 6| Step: 7
Training loss: 0.10630082464555436
Validation loss: 2.3375126481077317

Epoch: 6| Step: 8
Training loss: 0.10561545641377988
Validation loss: 2.3442445924986326

Epoch: 6| Step: 9
Training loss: 0.1036253159029854
Validation loss: 2.3486760438710315

Epoch: 6| Step: 10
Training loss: 0.09004841174658329
Validation loss: 2.3189362342165585

Epoch: 6| Step: 11
Training loss: 0.0692443107917293
Validation loss: 2.326647925083537

Epoch: 6| Step: 12
Training loss: 0.09763879620027793
Validation loss: 2.3408404474629974

Epoch: 6| Step: 13
Training loss: 0.10685815719572102
Validation loss: 2.3490726883398185

Epoch: 738| Step: 0
Training loss: 0.08254414817606863
Validation loss: 2.3075767125646123

Epoch: 6| Step: 1
Training loss: 0.11602487816178497
Validation loss: 2.311112918818871

Epoch: 6| Step: 2
Training loss: 0.10675659947381394
Validation loss: 2.31905243297707

Epoch: 6| Step: 3
Training loss: 0.1030764711232
Validation loss: 2.3785659684338123

Epoch: 6| Step: 4
Training loss: 0.1486992285337106
Validation loss: 2.3453046716388606

Epoch: 6| Step: 5
Training loss: 0.10982413548197227
Validation loss: 2.3785018104281908

Epoch: 6| Step: 6
Training loss: 0.06218936211107998
Validation loss: 2.3535987629292614

Epoch: 6| Step: 7
Training loss: 0.08709976096192996
Validation loss: 2.3420464924037505

Epoch: 6| Step: 8
Training loss: 0.13137038647547855
Validation loss: 2.3438380453875025

Epoch: 6| Step: 9
Training loss: 0.09819909851511165
Validation loss: 2.3897567567508045

Epoch: 6| Step: 10
Training loss: 0.06622280700878848
Validation loss: 2.361472510254704

Epoch: 6| Step: 11
Training loss: 0.08257791891315913
Validation loss: 2.3027218692356493

Epoch: 6| Step: 12
Training loss: 0.12564886335023132
Validation loss: 2.3518383946423707

Epoch: 6| Step: 13
Training loss: 0.13618004798983696
Validation loss: 2.3209232794138974

Epoch: 739| Step: 0
Training loss: 0.09345197992814402
Validation loss: 2.3217842288018864

Epoch: 6| Step: 1
Training loss: 0.12742523295353356
Validation loss: 2.3429410953680905

Epoch: 6| Step: 2
Training loss: 0.05943343978922067
Validation loss: 2.3504832614138356

Epoch: 6| Step: 3
Training loss: 0.1341937828156667
Validation loss: 2.3054250975618134

Epoch: 6| Step: 4
Training loss: 0.11967660381229815
Validation loss: 2.349891483975525

Epoch: 6| Step: 5
Training loss: 0.075706949014404
Validation loss: 2.3602694705373044

Epoch: 6| Step: 6
Training loss: 0.09967133521020413
Validation loss: 2.3665516474272583

Epoch: 6| Step: 7
Training loss: 0.09490393225703898
Validation loss: 2.330814790668193

Epoch: 6| Step: 8
Training loss: 0.1158602978418166
Validation loss: 2.351899360805111

Epoch: 6| Step: 9
Training loss: 0.08177751513331757
Validation loss: 2.3438383943029506

Epoch: 6| Step: 10
Training loss: 0.0767116798689745
Validation loss: 2.3444417631291454

Epoch: 6| Step: 11
Training loss: 0.1087043500872085
Validation loss: 2.4015067272993167

Epoch: 6| Step: 12
Training loss: 0.09852578238595479
Validation loss: 2.3751668455868913

Epoch: 6| Step: 13
Training loss: 0.072257531202546
Validation loss: 2.3595148164779456

Epoch: 740| Step: 0
Training loss: 0.07928893773047208
Validation loss: 2.351232470437194

Epoch: 6| Step: 1
Training loss: 0.11538094558099149
Validation loss: 2.367641314367609

Epoch: 6| Step: 2
Training loss: 0.09780979007251515
Validation loss: 2.364698400638984

Epoch: 6| Step: 3
Training loss: 0.10604682317136434
Validation loss: 2.3343906771994467

Epoch: 6| Step: 4
Training loss: 0.090579374724567
Validation loss: 2.3388129681092695

Epoch: 6| Step: 5
Training loss: 0.08963346231584612
Validation loss: 2.3419883610260603

Epoch: 6| Step: 6
Training loss: 0.08344534675887445
Validation loss: 2.3747090127398494

Epoch: 6| Step: 7
Training loss: 0.0774271012571822
Validation loss: 2.30803812696002

Epoch: 6| Step: 8
Training loss: 0.10356531210277395
Validation loss: 2.3698005247891474

Epoch: 6| Step: 9
Training loss: 0.08807875578588287
Validation loss: 2.3140863278413737

Epoch: 6| Step: 10
Training loss: 0.06024016868247109
Validation loss: 2.3235291296649567

Epoch: 6| Step: 11
Training loss: 0.0785826688599246
Validation loss: 2.3475655620160283

Epoch: 6| Step: 12
Training loss: 0.09194286384793385
Validation loss: 2.3390965835995

Epoch: 6| Step: 13
Training loss: 0.1325563386697476
Validation loss: 2.3492613442525343

Epoch: 741| Step: 0
Training loss: 0.05958826935700378
Validation loss: 2.3594580020931275

Epoch: 6| Step: 1
Training loss: 0.07939177715972284
Validation loss: 2.3478878015498745

Epoch: 6| Step: 2
Training loss: 0.07849832090268426
Validation loss: 2.34944150500241

Epoch: 6| Step: 3
Training loss: 0.083177634037124
Validation loss: 2.344203424380735

Epoch: 6| Step: 4
Training loss: 0.059956599678167875
Validation loss: 2.3626121626757715

Epoch: 6| Step: 5
Training loss: 0.1430439589665201
Validation loss: 2.31653354999624

Epoch: 6| Step: 6
Training loss: 0.10389950934752952
Validation loss: 2.332191833737506

Epoch: 6| Step: 7
Training loss: 0.06945501096458381
Validation loss: 2.344949733801394

Epoch: 6| Step: 8
Training loss: 0.06796997743353288
Validation loss: 2.3441026210432363

Epoch: 6| Step: 9
Training loss: 0.10782399340885433
Validation loss: 2.3230954504297356

Epoch: 6| Step: 10
Training loss: 0.07616347486688159
Validation loss: 2.3588138970629324

Epoch: 6| Step: 11
Training loss: 0.11657947318270628
Validation loss: 2.3542103249257433

Epoch: 6| Step: 12
Training loss: 0.10391417738424383
Validation loss: 2.3075745750639

Epoch: 6| Step: 13
Training loss: 0.12369429097801551
Validation loss: 2.338541413796906

Epoch: 742| Step: 0
Training loss: 0.11900440621032324
Validation loss: 2.3446706143743152

Epoch: 6| Step: 1
Training loss: 0.08945438246696888
Validation loss: 2.3400870825332363

Epoch: 6| Step: 2
Training loss: 0.087670038825091
Validation loss: 2.326947907004499

Epoch: 6| Step: 3
Training loss: 0.12705658584928262
Validation loss: 2.3166968573480355

Epoch: 6| Step: 4
Training loss: 0.07404614128051941
Validation loss: 2.3336363143777255

Epoch: 6| Step: 5
Training loss: 0.05382459492589677
Validation loss: 2.296960038466564

Epoch: 6| Step: 6
Training loss: 0.07643459935037811
Validation loss: 2.3275819067773265

Epoch: 6| Step: 7
Training loss: 0.14420160513004682
Validation loss: 2.343755823490469

Epoch: 6| Step: 8
Training loss: 0.08427968336904607
Validation loss: 2.364392340671763

Epoch: 6| Step: 9
Training loss: 0.09892253060757052
Validation loss: 2.350921505886159

Epoch: 6| Step: 10
Training loss: 0.1011804124183067
Validation loss: 2.35435025919204

Epoch: 6| Step: 11
Training loss: 0.057228474373501675
Validation loss: 2.371002265238513

Epoch: 6| Step: 12
Training loss: 0.11664871495649305
Validation loss: 2.332419468821903

Epoch: 6| Step: 13
Training loss: 0.08642636045703662
Validation loss: 2.3475004087828655

Epoch: 743| Step: 0
Training loss: 0.10622729276190206
Validation loss: 2.3272113811933703

Epoch: 6| Step: 1
Training loss: 0.07829724635696728
Validation loss: 2.3860823068014247

Epoch: 6| Step: 2
Training loss: 0.0978555648046117
Validation loss: 2.3383771669179483

Epoch: 6| Step: 3
Training loss: 0.1040641941256275
Validation loss: 2.359461966866737

Epoch: 6| Step: 4
Training loss: 0.07426301991094987
Validation loss: 2.3307298742886626

Epoch: 6| Step: 5
Training loss: 0.1124319682120232
Validation loss: 2.3453271122237758

Epoch: 6| Step: 6
Training loss: 0.09126283141446831
Validation loss: 2.3734821095498675

Epoch: 6| Step: 7
Training loss: 0.07265982208905199
Validation loss: 2.390734424535786

Epoch: 6| Step: 8
Training loss: 0.08239653410213685
Validation loss: 2.339353649049237

Epoch: 6| Step: 9
Training loss: 0.11760603551277939
Validation loss: 2.337770403688649

Epoch: 6| Step: 10
Training loss: 0.13880119875136368
Validation loss: 2.380465474611719

Epoch: 6| Step: 11
Training loss: 0.10517243421607368
Validation loss: 2.3509612204071537

Epoch: 6| Step: 12
Training loss: 0.07308639168916763
Validation loss: 2.3420232590723207

Epoch: 6| Step: 13
Training loss: 0.07282578035118878
Validation loss: 2.3470001644371434

Epoch: 744| Step: 0
Training loss: 0.07467916380276325
Validation loss: 2.347154510834304

Epoch: 6| Step: 1
Training loss: 0.08827421932581533
Validation loss: 2.3426133438352013

Epoch: 6| Step: 2
Training loss: 0.11739769204988845
Validation loss: 2.360306536692025

Epoch: 6| Step: 3
Training loss: 0.10990933618559218
Validation loss: 2.3571256865478096

Epoch: 6| Step: 4
Training loss: 0.059431404611873025
Validation loss: 2.3594966390659025

Epoch: 6| Step: 5
Training loss: 0.07610842923504968
Validation loss: 2.367256235842432

Epoch: 6| Step: 6
Training loss: 0.09240971590869147
Validation loss: 2.3364445337071955

Epoch: 6| Step: 7
Training loss: 0.1536266522369121
Validation loss: 2.345910423237719

Epoch: 6| Step: 8
Training loss: 0.09741596223865011
Validation loss: 2.3373927122645677

Epoch: 6| Step: 9
Training loss: 0.06882141844304372
Validation loss: 2.3067524797855166

Epoch: 6| Step: 10
Training loss: 0.1574516935481237
Validation loss: 2.3520280086111094

Epoch: 6| Step: 11
Training loss: 0.12890006541819427
Validation loss: 2.367983227527804

Epoch: 6| Step: 12
Training loss: 0.11683865520743458
Validation loss: 2.327766712702006

Epoch: 6| Step: 13
Training loss: 0.06441199189461697
Validation loss: 2.3671751863704973

Epoch: 745| Step: 0
Training loss: 0.08591429982434863
Validation loss: 2.371590349942607

Epoch: 6| Step: 1
Training loss: 0.08765956653518833
Validation loss: 2.3516163818282667

Epoch: 6| Step: 2
Training loss: 0.08892170313367924
Validation loss: 2.348188659751302

Epoch: 6| Step: 3
Training loss: 0.159197004815541
Validation loss: 2.3505037727768494

Epoch: 6| Step: 4
Training loss: 0.12172991785863005
Validation loss: 2.3607646476417323

Epoch: 6| Step: 5
Training loss: 0.08443868097161326
Validation loss: 2.370514063558177

Epoch: 6| Step: 6
Training loss: 0.06668164145897967
Validation loss: 2.3496797755831795

Epoch: 6| Step: 7
Training loss: 0.14117101788326586
Validation loss: 2.331221161418496

Epoch: 6| Step: 8
Training loss: 0.07500042679287751
Validation loss: 2.3664816902673795

Epoch: 6| Step: 9
Training loss: 0.08593406453635075
Validation loss: 2.351466963420399

Epoch: 6| Step: 10
Training loss: 0.15414268902161873
Validation loss: 2.3318530406740234

Epoch: 6| Step: 11
Training loss: 0.11451780457568836
Validation loss: 2.3031802930951306

Epoch: 6| Step: 12
Training loss: 0.09435463674593417
Validation loss: 2.3250942926056486

Epoch: 6| Step: 13
Training loss: 0.038982273209509734
Validation loss: 2.343227256533776

Epoch: 746| Step: 0
Training loss: 0.09450243459478169
Validation loss: 2.364543154622104

Epoch: 6| Step: 1
Training loss: 0.09363017272251822
Validation loss: 2.366491715225649

Epoch: 6| Step: 2
Training loss: 0.08240419713495048
Validation loss: 2.352514641445425

Epoch: 6| Step: 3
Training loss: 0.09363455419468195
Validation loss: 2.3653242722893575

Epoch: 6| Step: 4
Training loss: 0.047694224916159926
Validation loss: 2.3687142814280713

Epoch: 6| Step: 5
Training loss: 0.09156626283510638
Validation loss: 2.3335526827653017

Epoch: 6| Step: 6
Training loss: 0.10543616550920473
Validation loss: 2.3795159986006693

Epoch: 6| Step: 7
Training loss: 0.1340067755766289
Validation loss: 2.3247128224924434

Epoch: 6| Step: 8
Training loss: 0.10001121603382708
Validation loss: 2.3260024584291825

Epoch: 6| Step: 9
Training loss: 0.06519200082325276
Validation loss: 2.323799173880817

Epoch: 6| Step: 10
Training loss: 0.09426851726377555
Validation loss: 2.3559394743873723

Epoch: 6| Step: 11
Training loss: 0.0796674133911752
Validation loss: 2.286599892182708

Epoch: 6| Step: 12
Training loss: 0.10765490831444302
Validation loss: 2.309090912616511

Epoch: 6| Step: 13
Training loss: 0.11234604032699348
Validation loss: 2.330214804940719

Epoch: 747| Step: 0
Training loss: 0.12992952697021007
Validation loss: 2.322824691996275

Epoch: 6| Step: 1
Training loss: 0.11933165228808895
Validation loss: 2.291309603694864

Epoch: 6| Step: 2
Training loss: 0.1134782221438038
Validation loss: 2.3262377071545677

Epoch: 6| Step: 3
Training loss: 0.06498281693064016
Validation loss: 2.325240493672213

Epoch: 6| Step: 4
Training loss: 0.10200095899799594
Validation loss: 2.332056965071834

Epoch: 6| Step: 5
Training loss: 0.1454379983126239
Validation loss: 2.323814529422944

Epoch: 6| Step: 6
Training loss: 0.11734206814328924
Validation loss: 2.336333754817662

Epoch: 6| Step: 7
Training loss: 0.0869167681069314
Validation loss: 2.3321653473777726

Epoch: 6| Step: 8
Training loss: 0.16724180783392503
Validation loss: 2.368365645714029

Epoch: 6| Step: 9
Training loss: 0.11662424144927493
Validation loss: 2.3969942922640954

Epoch: 6| Step: 10
Training loss: 0.11878486579473886
Validation loss: 2.3985618256325703

Epoch: 6| Step: 11
Training loss: 0.08836003887203693
Validation loss: 2.373136489845837

Epoch: 6| Step: 12
Training loss: 0.10256073132395738
Validation loss: 2.4359015873653207

Epoch: 6| Step: 13
Training loss: 0.15794041095476932
Validation loss: 2.413370236753308

Epoch: 748| Step: 0
Training loss: 0.09491297479983261
Validation loss: 2.3969620673181202

Epoch: 6| Step: 1
Training loss: 0.10666776301319114
Validation loss: 2.4083639574777473

Epoch: 6| Step: 2
Training loss: 0.1446716297006263
Validation loss: 2.4010214838232233

Epoch: 6| Step: 3
Training loss: 0.08155841452681514
Validation loss: 2.371891501449535

Epoch: 6| Step: 4
Training loss: 0.13113168594926425
Validation loss: 2.393024389801993

Epoch: 6| Step: 5
Training loss: 0.16706266087332708
Validation loss: 2.3942093273038294

Epoch: 6| Step: 6
Training loss: 0.14359056582360505
Validation loss: 2.3860473687457335

Epoch: 6| Step: 7
Training loss: 0.1271853963106217
Validation loss: 2.374435383596912

Epoch: 6| Step: 8
Training loss: 0.10344645150281201
Validation loss: 2.363523909374638

Epoch: 6| Step: 9
Training loss: 0.10281695901193073
Validation loss: 2.363440399248629

Epoch: 6| Step: 10
Training loss: 0.11184985064623176
Validation loss: 2.3629819884761947

Epoch: 6| Step: 11
Training loss: 0.11539678927765563
Validation loss: 2.3577990816825714

Epoch: 6| Step: 12
Training loss: 0.08723323594910433
Validation loss: 2.3545946147329784

Epoch: 6| Step: 13
Training loss: 0.1592653781084699
Validation loss: 2.3662571759753233

Epoch: 749| Step: 0
Training loss: 0.1097275722290166
Validation loss: 2.3480355692375694

Epoch: 6| Step: 1
Training loss: 0.14127001918021256
Validation loss: 2.357975038159655

Epoch: 6| Step: 2
Training loss: 0.12031566302984362
Validation loss: 2.3725808543571456

Epoch: 6| Step: 3
Training loss: 0.10988808245994308
Validation loss: 2.3808167129456717

Epoch: 6| Step: 4
Training loss: 0.15590398145360623
Validation loss: 2.3480092026415447

Epoch: 6| Step: 5
Training loss: 0.09543344882980473
Validation loss: 2.3506651034687294

Epoch: 6| Step: 6
Training loss: 0.08771145359844626
Validation loss: 2.391645005473804

Epoch: 6| Step: 7
Training loss: 0.11544671941538703
Validation loss: 2.382959963174149

Epoch: 6| Step: 8
Training loss: 0.1508599365061934
Validation loss: 2.38483343872608

Epoch: 6| Step: 9
Training loss: 0.11509455263830005
Validation loss: 2.3646318818190086

Epoch: 6| Step: 10
Training loss: 0.10917915965107912
Validation loss: 2.37012513113476

Epoch: 6| Step: 11
Training loss: 0.12058396089723798
Validation loss: 2.374234640203683

Epoch: 6| Step: 12
Training loss: 0.13541927625513644
Validation loss: 2.346175257996531

Epoch: 6| Step: 13
Training loss: 0.08990942586302242
Validation loss: 2.371903030766192

Epoch: 750| Step: 0
Training loss: 0.17448687299154853
Validation loss: 2.3262269984667507

Epoch: 6| Step: 1
Training loss: 0.06571854696138138
Validation loss: 2.3515432178002618

Epoch: 6| Step: 2
Training loss: 0.12583441440036838
Validation loss: 2.351455249411295

Epoch: 6| Step: 3
Training loss: 0.11284866444163323
Validation loss: 2.3477207426344235

Epoch: 6| Step: 4
Training loss: 0.079541952550345
Validation loss: 2.3404452525059933

Epoch: 6| Step: 5
Training loss: 0.07039860909809048
Validation loss: 2.3354131637127935

Epoch: 6| Step: 6
Training loss: 0.10426710075261279
Validation loss: 2.3385818587251643

Epoch: 6| Step: 7
Training loss: 0.10697660495643271
Validation loss: 2.339967194283319

Epoch: 6| Step: 8
Training loss: 0.16005691494855537
Validation loss: 2.366724193731176

Epoch: 6| Step: 9
Training loss: 0.10664782814179861
Validation loss: 2.3825046479632044

Epoch: 6| Step: 10
Training loss: 0.15664542350173422
Validation loss: 2.374753898257366

Epoch: 6| Step: 11
Training loss: 0.13169220047044983
Validation loss: 2.4086251082707397

Epoch: 6| Step: 12
Training loss: 0.08797699075758404
Validation loss: 2.4075910370898175

Epoch: 6| Step: 13
Training loss: 0.1234432225168429
Validation loss: 2.390592217346268

Testing loss: 2.432739099032136
