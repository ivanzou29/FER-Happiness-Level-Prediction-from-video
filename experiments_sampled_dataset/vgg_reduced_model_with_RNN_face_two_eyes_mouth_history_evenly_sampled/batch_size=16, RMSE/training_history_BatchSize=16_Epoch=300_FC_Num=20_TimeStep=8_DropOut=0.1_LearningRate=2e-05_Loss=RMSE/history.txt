Epoch: 1| Step: 0
Training loss: 5.02579425209388
Validation loss: 5.86199012332167

Epoch: 6| Step: 1
Training loss: 5.567155240179828
Validation loss: 5.846651722180841

Epoch: 6| Step: 2
Training loss: 7.162672334365325
Validation loss: 5.830542440248115

Epoch: 6| Step: 3
Training loss: 5.610875346116522
Validation loss: 5.812285134495233

Epoch: 6| Step: 4
Training loss: 6.318203907959808
Validation loss: 5.7921760614228095

Epoch: 6| Step: 5
Training loss: 6.595806072449472
Validation loss: 5.76887450116015

Epoch: 6| Step: 6
Training loss: 5.1327534153990895
Validation loss: 5.743886319943541

Epoch: 6| Step: 7
Training loss: 6.279698118498425
Validation loss: 5.715060667660971

Epoch: 6| Step: 8
Training loss: 5.779554953683413
Validation loss: 5.683589896143799

Epoch: 6| Step: 9
Training loss: 5.155511791675628
Validation loss: 5.648901507527036

Epoch: 6| Step: 10
Training loss: 4.844430002041286
Validation loss: 5.609690938116457

Epoch: 6| Step: 11
Training loss: 4.631891014226887
Validation loss: 5.567319554847116

Epoch: 6| Step: 12
Training loss: 5.814342575893146
Validation loss: 5.520906254322971

Epoch: 6| Step: 13
Training loss: 6.149538050724192
Validation loss: 5.469361033722369

Epoch: 2| Step: 0
Training loss: 5.082380841345864
Validation loss: 5.41423556702244

Epoch: 6| Step: 1
Training loss: 4.498420014103954
Validation loss: 5.356483513942679

Epoch: 6| Step: 2
Training loss: 4.351553733720973
Validation loss: 5.291642300478054

Epoch: 6| Step: 3
Training loss: 5.623125230111421
Validation loss: 5.227256753931069

Epoch: 6| Step: 4
Training loss: 5.9987798085856205
Validation loss: 5.160646532974373

Epoch: 6| Step: 5
Training loss: 4.752444792561788
Validation loss: 5.092754722509467

Epoch: 6| Step: 6
Training loss: 5.0785625562691905
Validation loss: 5.028094186078307

Epoch: 6| Step: 7
Training loss: 5.214124994357837
Validation loss: 4.961305613445992

Epoch: 6| Step: 8
Training loss: 4.83904741954332
Validation loss: 4.8982273941288765

Epoch: 6| Step: 9
Training loss: 4.8570731743053495
Validation loss: 4.830836062891418

Epoch: 6| Step: 10
Training loss: 5.722220946541225
Validation loss: 4.763228699331969

Epoch: 6| Step: 11
Training loss: 4.727334607326207
Validation loss: 4.692887238327954

Epoch: 6| Step: 12
Training loss: 5.334182651763804
Validation loss: 4.627464311940695

Epoch: 6| Step: 13
Training loss: 4.151926416219132
Validation loss: 4.567447011635452

Epoch: 3| Step: 0
Training loss: 5.361140280179186
Validation loss: 4.510083217080021

Epoch: 6| Step: 1
Training loss: 5.113743585560612
Validation loss: 4.463381436645885

Epoch: 6| Step: 2
Training loss: 4.67101205874638
Validation loss: 4.423729257633999

Epoch: 6| Step: 3
Training loss: 4.342719305690569
Validation loss: 4.391033342945015

Epoch: 6| Step: 4
Training loss: 4.694003260620701
Validation loss: 4.360731304591232

Epoch: 6| Step: 5
Training loss: 4.444754459906903
Validation loss: 4.331703505851789

Epoch: 6| Step: 6
Training loss: 4.76199773107328
Validation loss: 4.30358528024445

Epoch: 6| Step: 7
Training loss: 3.662336321092915
Validation loss: 4.278260519851001

Epoch: 6| Step: 8
Training loss: 3.801446870110697
Validation loss: 4.254334464704106

Epoch: 6| Step: 9
Training loss: 4.35628035984926
Validation loss: 4.230790329342803

Epoch: 6| Step: 10
Training loss: 3.3841426075676084
Validation loss: 4.208277733743249

Epoch: 6| Step: 11
Training loss: 4.9096615344080785
Validation loss: 4.186666360057848

Epoch: 6| Step: 12
Training loss: 4.011038807093708
Validation loss: 4.165653264672544

Epoch: 6| Step: 13
Training loss: 3.9594499853390452
Validation loss: 4.1468014134347015

Epoch: 4| Step: 0
Training loss: 5.5641542182353865
Validation loss: 4.1232008405296865

Epoch: 6| Step: 1
Training loss: 3.6444208224495034
Validation loss: 4.100472222822817

Epoch: 6| Step: 2
Training loss: 4.854319208501574
Validation loss: 4.080622314061019

Epoch: 6| Step: 3
Training loss: 3.8113455353370793
Validation loss: 4.054692799649298

Epoch: 6| Step: 4
Training loss: 3.4583945824281757
Validation loss: 4.0280233718249905

Epoch: 6| Step: 5
Training loss: 4.524223404310333
Validation loss: 4.0034431410191775

Epoch: 6| Step: 6
Training loss: 4.823827516081729
Validation loss: 3.976728828507583

Epoch: 6| Step: 7
Training loss: 4.4364068202604585
Validation loss: 3.960888877137056

Epoch: 6| Step: 8
Training loss: 3.5523530441910935
Validation loss: 3.9512918289532095

Epoch: 6| Step: 9
Training loss: 3.4189624671538352
Validation loss: 3.937999289363189

Epoch: 6| Step: 10
Training loss: 3.982056665068125
Validation loss: 3.9228841100044125

Epoch: 6| Step: 11
Training loss: 3.4968001861341818
Validation loss: 3.924759942467863

Epoch: 6| Step: 12
Training loss: 4.408865943467855
Validation loss: 3.9157261427193064

Epoch: 6| Step: 13
Training loss: 2.950880055165846
Validation loss: 3.8882062311840127

Epoch: 5| Step: 0
Training loss: 3.5350154279617696
Validation loss: 3.8901577447501547

Epoch: 6| Step: 1
Training loss: 4.62557979764218
Validation loss: 3.9004077523104237

Epoch: 6| Step: 2
Training loss: 3.9838519781566064
Validation loss: 3.868445309104572

Epoch: 6| Step: 3
Training loss: 4.014393183360997
Validation loss: 3.8517294647876144

Epoch: 6| Step: 4
Training loss: 4.588556792645271
Validation loss: 3.8477453007982554

Epoch: 6| Step: 5
Training loss: 4.231220492058644
Validation loss: 3.849662329508914

Epoch: 6| Step: 6
Training loss: 4.226877253688475
Validation loss: 3.8412515847686666

Epoch: 6| Step: 7
Training loss: 4.593737959035027
Validation loss: 3.8227311058819375

Epoch: 6| Step: 8
Training loss: 3.7233713109724307
Validation loss: 3.8079790475945714

Epoch: 6| Step: 9
Training loss: 3.0666037331909872
Validation loss: 3.802840224292044

Epoch: 6| Step: 10
Training loss: 3.8015353012523088
Validation loss: 3.804071481678371

Epoch: 6| Step: 11
Training loss: 3.783810339838165
Validation loss: 3.7947335391792216

Epoch: 6| Step: 12
Training loss: 3.529858475352527
Validation loss: 3.779564526838747

Epoch: 6| Step: 13
Training loss: 4.057060003298118
Validation loss: 3.768818339295196

Epoch: 6| Step: 0
Training loss: 3.699814229889571
Validation loss: 3.7632148704855055

Epoch: 6| Step: 1
Training loss: 3.5890724590530363
Validation loss: 3.76264089148104

Epoch: 6| Step: 2
Training loss: 4.735721207892913
Validation loss: 3.748775879880903

Epoch: 6| Step: 3
Training loss: 3.792392297974438
Validation loss: 3.738436138561684

Epoch: 6| Step: 4
Training loss: 3.5565607186589423
Validation loss: 3.733346995388763

Epoch: 6| Step: 5
Training loss: 3.372300375197417
Validation loss: 3.7325714104211256

Epoch: 6| Step: 6
Training loss: 4.111150669789653
Validation loss: 3.729314991667471

Epoch: 6| Step: 7
Training loss: 3.842413196861451
Validation loss: 3.7184465794167507

Epoch: 6| Step: 8
Training loss: 3.3953958865378806
Validation loss: 3.704906110920852

Epoch: 6| Step: 9
Training loss: 4.099363714947923
Validation loss: 3.6994866626723946

Epoch: 6| Step: 10
Training loss: 4.005896513723502
Validation loss: 3.698062941093153

Epoch: 6| Step: 11
Training loss: 3.9549980701774587
Validation loss: 3.7010834023173316

Epoch: 6| Step: 12
Training loss: 4.278177983002583
Validation loss: 3.692248491158915

Epoch: 6| Step: 13
Training loss: 4.151063134853063
Validation loss: 3.6795307013934653

Epoch: 7| Step: 0
Training loss: 3.97642507859002
Validation loss: 3.6748358782424013

Epoch: 6| Step: 1
Training loss: 4.430680313400051
Validation loss: 3.6750577901861834

Epoch: 6| Step: 2
Training loss: 3.2429836536598935
Validation loss: 3.6665800346327715

Epoch: 6| Step: 3
Training loss: 3.5876672101014346
Validation loss: 3.6593128631355643

Epoch: 6| Step: 4
Training loss: 3.932223826785295
Validation loss: 3.653582286594188

Epoch: 6| Step: 5
Training loss: 4.534604008555135
Validation loss: 3.646375274928721

Epoch: 6| Step: 6
Training loss: 3.6554338897458187
Validation loss: 3.640255711392606

Epoch: 6| Step: 7
Training loss: 4.486348957151241
Validation loss: 3.6369623509473716

Epoch: 6| Step: 8
Training loss: 3.1820491484005893
Validation loss: 3.6279114858183723

Epoch: 6| Step: 9
Training loss: 3.8776228857090285
Validation loss: 3.6209920098588033

Epoch: 6| Step: 10
Training loss: 4.2958441590186
Validation loss: 3.6168138350936365

Epoch: 6| Step: 11
Training loss: 3.8441288458976377
Validation loss: 3.613099819374261

Epoch: 6| Step: 12
Training loss: 3.2821194904526823
Validation loss: 3.609100160867482

Epoch: 6| Step: 13
Training loss: 1.9594701619135944
Validation loss: 3.604555371632136

Epoch: 8| Step: 0
Training loss: 4.004617172022566
Validation loss: 3.600075922442291

Epoch: 6| Step: 1
Training loss: 3.193598429746758
Validation loss: 3.590687847948454

Epoch: 6| Step: 2
Training loss: 4.024532428380947
Validation loss: 3.5863858838354488

Epoch: 6| Step: 3
Training loss: 4.066517647894774
Validation loss: 3.5844599037254175

Epoch: 6| Step: 4
Training loss: 3.008298047000563
Validation loss: 3.5798347380163817

Epoch: 6| Step: 5
Training loss: 4.068801218580632
Validation loss: 3.576619200885855

Epoch: 6| Step: 6
Training loss: 3.471923888211645
Validation loss: 3.5718260911544295

Epoch: 6| Step: 7
Training loss: 4.231663585379762
Validation loss: 3.565153951508596

Epoch: 6| Step: 8
Training loss: 3.603076939125815
Validation loss: 3.558396887211081

Epoch: 6| Step: 9
Training loss: 2.7860421889014213
Validation loss: 3.5523760092251404

Epoch: 6| Step: 10
Training loss: 3.4755617908861964
Validation loss: 3.547535948783494

Epoch: 6| Step: 11
Training loss: 3.838202217790047
Validation loss: 3.5417064372561633

Epoch: 6| Step: 12
Training loss: 4.60381351457171
Validation loss: 3.5389200962580993

Epoch: 6| Step: 13
Training loss: 4.152671937362781
Validation loss: 3.534295430923443

Epoch: 9| Step: 0
Training loss: 3.8080449574565494
Validation loss: 3.5260738471244295

Epoch: 6| Step: 1
Training loss: 2.9303980258186226
Validation loss: 3.5197848580238627

Epoch: 6| Step: 2
Training loss: 3.4418893706626266
Validation loss: 3.5136580997723184

Epoch: 6| Step: 3
Training loss: 3.782744057314665
Validation loss: 3.511470467199476

Epoch: 6| Step: 4
Training loss: 3.957994921757629
Validation loss: 3.5045680956574645

Epoch: 6| Step: 5
Training loss: 3.589401931887497
Validation loss: 3.49849011188739

Epoch: 6| Step: 6
Training loss: 4.303561691698277
Validation loss: 3.4945270271919777

Epoch: 6| Step: 7
Training loss: 3.6775929185239415
Validation loss: 3.487266615372236

Epoch: 6| Step: 8
Training loss: 3.9402717643772287
Validation loss: 3.4923874445729237

Epoch: 6| Step: 9
Training loss: 3.9162852054186073
Validation loss: 3.486070296024598

Epoch: 6| Step: 10
Training loss: 4.7602414600453375
Validation loss: 3.473153565610208

Epoch: 6| Step: 11
Training loss: 3.077767443343102
Validation loss: 3.4714459488499547

Epoch: 6| Step: 12
Training loss: 2.8263753463166568
Validation loss: 3.5055159160008675

Epoch: 6| Step: 13
Training loss: 3.2723369341527344
Validation loss: 3.4589858632372192

Epoch: 10| Step: 0
Training loss: 4.456049016028881
Validation loss: 3.472728397076667

Epoch: 6| Step: 1
Training loss: 3.024929890726566
Validation loss: 3.483555596662453

Epoch: 6| Step: 2
Training loss: 3.729026891266156
Validation loss: 3.470951455236988

Epoch: 6| Step: 3
Training loss: 4.779285700589716
Validation loss: 3.455292286959177

Epoch: 6| Step: 4
Training loss: 4.053863500464157
Validation loss: 3.4406441249276574

Epoch: 6| Step: 5
Training loss: 3.2998863316235214
Validation loss: 3.4431586874907345

Epoch: 6| Step: 6
Training loss: 2.3502169082855335
Validation loss: 3.466701684361583

Epoch: 6| Step: 7
Training loss: 3.8507725522637113
Validation loss: 3.4656665211389144

Epoch: 6| Step: 8
Training loss: 3.3087214385595227
Validation loss: 3.4253932135242495

Epoch: 6| Step: 9
Training loss: 4.200099834890461
Validation loss: 3.4242104047945476

Epoch: 6| Step: 10
Training loss: 2.984956694629092
Validation loss: 3.439461086956909

Epoch: 6| Step: 11
Training loss: 3.352241785174078
Validation loss: 3.4453109999036675

Epoch: 6| Step: 12
Training loss: 3.4759991478693966
Validation loss: 3.4366958169713473

Epoch: 6| Step: 13
Training loss: 3.9221382204761754
Validation loss: 3.417128977097741

Epoch: 11| Step: 0
Training loss: 3.560252769154662
Validation loss: 3.401991712128463

Epoch: 6| Step: 1
Training loss: 3.837404300850834
Validation loss: 3.3974884959930267

Epoch: 6| Step: 2
Training loss: 3.8961911504643907
Validation loss: 3.3998273448549305

Epoch: 6| Step: 3
Training loss: 4.140228828335043
Validation loss: 3.3989450941500228

Epoch: 6| Step: 4
Training loss: 3.588201601758642
Validation loss: 3.38894033356536

Epoch: 6| Step: 5
Training loss: 3.628948429055534
Validation loss: 3.3762324402385575

Epoch: 6| Step: 6
Training loss: 3.598562849133331
Validation loss: 3.3695612282749443

Epoch: 6| Step: 7
Training loss: 4.1453572420019915
Validation loss: 3.3684079119153303

Epoch: 6| Step: 8
Training loss: 2.8043108929013933
Validation loss: 3.3636644219047116

Epoch: 6| Step: 9
Training loss: 3.7079841506520514
Validation loss: 3.35622002779258

Epoch: 6| Step: 10
Training loss: 3.015685560181662
Validation loss: 3.340835418116914

Epoch: 6| Step: 11
Training loss: 3.650065612203248
Validation loss: 3.3390852758652425

Epoch: 6| Step: 12
Training loss: 3.817644494300547
Validation loss: 3.336360245916755

Epoch: 6| Step: 13
Training loss: 1.907153993975114
Validation loss: 3.373797970964227

Epoch: 12| Step: 0
Training loss: 3.6353319189182116
Validation loss: 3.432493827032806

Epoch: 6| Step: 1
Training loss: 3.147046863518502
Validation loss: 3.4374379082494713

Epoch: 6| Step: 2
Training loss: 3.6862008343946346
Validation loss: 3.4332966033646626

Epoch: 6| Step: 3
Training loss: 3.913867328825974
Validation loss: 3.395421778078197

Epoch: 6| Step: 4
Training loss: 4.077389939516709
Validation loss: 3.343281316394163

Epoch: 6| Step: 5
Training loss: 4.459459798283294
Validation loss: 3.3851155086377083

Epoch: 6| Step: 6
Training loss: 3.0735439543912815
Validation loss: 3.3842009077359916

Epoch: 6| Step: 7
Training loss: 3.0760664664479958
Validation loss: 3.3666638022107738

Epoch: 6| Step: 8
Training loss: 3.096988100821645
Validation loss: 3.3451784716981208

Epoch: 6| Step: 9
Training loss: 3.2045113889456416
Validation loss: 3.3297625232782604

Epoch: 6| Step: 10
Training loss: 3.4506984832904495
Validation loss: 3.3195854681425363

Epoch: 6| Step: 11
Training loss: 3.920899653642402
Validation loss: 3.3116498178451583

Epoch: 6| Step: 12
Training loss: 3.9942296845969474
Validation loss: 3.307783567967508

Epoch: 6| Step: 13
Training loss: 3.0760063199497973
Validation loss: 3.3153866205464904

Epoch: 13| Step: 0
Training loss: 3.0894364620255694
Validation loss: 3.3226633828201124

Epoch: 6| Step: 1
Training loss: 4.100247417521008
Validation loss: 3.310157156324107

Epoch: 6| Step: 2
Training loss: 3.074127700019606
Validation loss: 3.2906556690741833

Epoch: 6| Step: 3
Training loss: 3.7064243217758754
Validation loss: 3.2834935375694383

Epoch: 6| Step: 4
Training loss: 3.371730350930692
Validation loss: 3.2779347866068616

Epoch: 6| Step: 5
Training loss: 2.888197420785266
Validation loss: 3.2753880467928354

Epoch: 6| Step: 6
Training loss: 3.593456223131635
Validation loss: 3.2739315440857855

Epoch: 6| Step: 7
Training loss: 3.6440951463607507
Validation loss: 3.271074296487914

Epoch: 6| Step: 8
Training loss: 3.8300457553769838
Validation loss: 3.2709342243933714

Epoch: 6| Step: 9
Training loss: 3.1042306027239173
Validation loss: 3.2669538708710597

Epoch: 6| Step: 10
Training loss: 3.97656393894252
Validation loss: 3.263518083033127

Epoch: 6| Step: 11
Training loss: 3.5015378025993416
Validation loss: 3.2587630341345006

Epoch: 6| Step: 12
Training loss: 3.85779863666378
Validation loss: 3.253385671891908

Epoch: 6| Step: 13
Training loss: 3.2151799819900218
Validation loss: 3.2499595604866163

Epoch: 14| Step: 0
Training loss: 2.676076162751205
Validation loss: 3.2489826354891145

Epoch: 6| Step: 1
Training loss: 3.2571871589573362
Validation loss: 3.246040026803102

Epoch: 6| Step: 2
Training loss: 3.582482229482869
Validation loss: 3.2424884567999612

Epoch: 6| Step: 3
Training loss: 4.005481302246521
Validation loss: 3.237410359280522

Epoch: 6| Step: 4
Training loss: 3.3419210119952028
Validation loss: 3.2339832206741956

Epoch: 6| Step: 5
Training loss: 3.7391499274394717
Validation loss: 3.2290625537888866

Epoch: 6| Step: 6
Training loss: 3.668134496679474
Validation loss: 3.2250689676663553

Epoch: 6| Step: 7
Training loss: 2.37138995813787
Validation loss: 3.2224149625707743

Epoch: 6| Step: 8
Training loss: 3.270032910289283
Validation loss: 3.2215783682675716

Epoch: 6| Step: 9
Training loss: 3.7333180994903743
Validation loss: 3.2155890749554894

Epoch: 6| Step: 10
Training loss: 3.9997073304872224
Validation loss: 3.209199204177219

Epoch: 6| Step: 11
Training loss: 3.3373071507661214
Validation loss: 3.20452357147229

Epoch: 6| Step: 12
Training loss: 4.075552761290006
Validation loss: 3.2036224803280495

Epoch: 6| Step: 13
Training loss: 3.0144379013683555
Validation loss: 3.1994834627215316

Epoch: 15| Step: 0
Training loss: 2.9175037999197855
Validation loss: 3.1960285835664077

Epoch: 6| Step: 1
Training loss: 4.00523510722656
Validation loss: 3.191227105370588

Epoch: 6| Step: 2
Training loss: 2.536923490532177
Validation loss: 3.1863662887990887

Epoch: 6| Step: 3
Training loss: 2.8545817238138635
Validation loss: 3.191162212505881

Epoch: 6| Step: 4
Training loss: 3.5530489655933954
Validation loss: 3.206043782199293

Epoch: 6| Step: 5
Training loss: 3.7015501125993127
Validation loss: 3.2078213122664456

Epoch: 6| Step: 6
Training loss: 2.9127783515433725
Validation loss: 3.1885045700653483

Epoch: 6| Step: 7
Training loss: 4.0381802862693075
Validation loss: 3.1866866651882253

Epoch: 6| Step: 8
Training loss: 3.5706810959212714
Validation loss: 3.1792410159398687

Epoch: 6| Step: 9
Training loss: 3.851941815436952
Validation loss: 3.1752646908455224

Epoch: 6| Step: 10
Training loss: 3.8343510037070034
Validation loss: 3.1756772280320846

Epoch: 6| Step: 11
Training loss: 2.9563387383657362
Validation loss: 3.1748705752226436

Epoch: 6| Step: 12
Training loss: 3.700976557346364
Validation loss: 3.1732808005506263

Epoch: 6| Step: 13
Training loss: 3.420995311797408
Validation loss: 3.169425993250604

Epoch: 16| Step: 0
Training loss: 2.7071445986314013
Validation loss: 3.166748315139594

Epoch: 6| Step: 1
Training loss: 2.9313206710917896
Validation loss: 3.167027246210219

Epoch: 6| Step: 2
Training loss: 3.5820525490097417
Validation loss: 3.163603008758373

Epoch: 6| Step: 3
Training loss: 3.8636979205281756
Validation loss: 3.161005977927221

Epoch: 6| Step: 4
Training loss: 3.5514647242542154
Validation loss: 3.1558914102705162

Epoch: 6| Step: 5
Training loss: 3.7745987584176866
Validation loss: 3.155621208814987

Epoch: 6| Step: 6
Training loss: 3.353172360216417
Validation loss: 3.1502549970800104

Epoch: 6| Step: 7
Training loss: 3.3073757050818147
Validation loss: 3.146157693279947

Epoch: 6| Step: 8
Training loss: 3.4089816278223863
Validation loss: 3.1422873484933707

Epoch: 6| Step: 9
Training loss: 3.4085279774445834
Validation loss: 3.1389212266516604

Epoch: 6| Step: 10
Training loss: 4.3480515073306565
Validation loss: 3.1338144632903995

Epoch: 6| Step: 11
Training loss: 3.235903171594833
Validation loss: 3.1294105275714696

Epoch: 6| Step: 12
Training loss: 3.1637411825659303
Validation loss: 3.12828479036768

Epoch: 6| Step: 13
Training loss: 2.3477480548293674
Validation loss: 3.1258036279516905

Epoch: 17| Step: 0
Training loss: 3.104733170056805
Validation loss: 3.123915307264255

Epoch: 6| Step: 1
Training loss: 3.7756620369736282
Validation loss: 3.1211801493587963

Epoch: 6| Step: 2
Training loss: 2.8529549321339793
Validation loss: 3.119988588591501

Epoch: 6| Step: 3
Training loss: 2.582835754548311
Validation loss: 3.1168601904877096

Epoch: 6| Step: 4
Training loss: 3.1873308024659357
Validation loss: 3.1143422480857517

Epoch: 6| Step: 5
Training loss: 2.8356486191752786
Validation loss: 3.115393554044133

Epoch: 6| Step: 6
Training loss: 3.6205162731869636
Validation loss: 3.11473821494374

Epoch: 6| Step: 7
Training loss: 3.2957246771326236
Validation loss: 3.1134211778624663

Epoch: 6| Step: 8
Training loss: 3.193682191729863
Validation loss: 3.1094729640544583

Epoch: 6| Step: 9
Training loss: 3.5446209572262752
Validation loss: 3.1090262140056897

Epoch: 6| Step: 10
Training loss: 3.8502430232247193
Validation loss: 3.1072184384450203

Epoch: 6| Step: 11
Training loss: 3.779079602523862
Validation loss: 3.105034644000483

Epoch: 6| Step: 12
Training loss: 4.03354289768872
Validation loss: 3.1039888113939953

Epoch: 6| Step: 13
Training loss: 3.490263884878045
Validation loss: 3.10201893651347

Epoch: 18| Step: 0
Training loss: 3.455293276715132
Validation loss: 3.1000040001368707

Epoch: 6| Step: 1
Training loss: 3.5455849607974983
Validation loss: 3.099137293480069

Epoch: 6| Step: 2
Training loss: 2.5246474255954383
Validation loss: 3.097349028864979

Epoch: 6| Step: 3
Training loss: 3.0457202777328174
Validation loss: 3.0954027945237637

Epoch: 6| Step: 4
Training loss: 3.511808774004265
Validation loss: 3.094407352447038

Epoch: 6| Step: 5
Training loss: 3.450906999199843
Validation loss: 3.09319967506862

Epoch: 6| Step: 6
Training loss: 2.658841473396234
Validation loss: 3.090227885110635

Epoch: 6| Step: 7
Training loss: 3.74536800415009
Validation loss: 3.09021209868838

Epoch: 6| Step: 8
Training loss: 3.3922624281906417
Validation loss: 3.0886097841557634

Epoch: 6| Step: 9
Training loss: 3.60677147967428
Validation loss: 3.0874183940593993

Epoch: 6| Step: 10
Training loss: 3.370209579063522
Validation loss: 3.0867792715887497

Epoch: 6| Step: 11
Training loss: 2.970570056550841
Validation loss: 3.0849350945697243

Epoch: 6| Step: 12
Training loss: 4.030162102631397
Validation loss: 3.088894069833818

Epoch: 6| Step: 13
Training loss: 3.746500925921045
Validation loss: 3.0966835668849235

Epoch: 19| Step: 0
Training loss: 3.17225682257737
Validation loss: 3.0975629309889845

Epoch: 6| Step: 1
Training loss: 3.337887196458157
Validation loss: 3.080541486401704

Epoch: 6| Step: 2
Training loss: 3.3888438244378665
Validation loss: 3.087107523264459

Epoch: 6| Step: 3
Training loss: 3.6628165983774847
Validation loss: 3.093021783177554

Epoch: 6| Step: 4
Training loss: 3.662661677102198
Validation loss: 3.0814058858416136

Epoch: 6| Step: 5
Training loss: 3.633815175808147
Validation loss: 3.0805278082573855

Epoch: 6| Step: 6
Training loss: 3.098396126321331
Validation loss: 3.0807931464284177

Epoch: 6| Step: 7
Training loss: 2.185926252749277
Validation loss: 3.0812163553329457

Epoch: 6| Step: 8
Training loss: 3.444794700274397
Validation loss: 3.0890529638002304

Epoch: 6| Step: 9
Training loss: 3.284344186102925
Validation loss: 3.089076221153069

Epoch: 6| Step: 10
Training loss: 3.890177137955655
Validation loss: 3.0760974076661367

Epoch: 6| Step: 11
Training loss: 3.3361629079382835
Validation loss: 3.074329607145136

Epoch: 6| Step: 12
Training loss: 3.6858229622180008
Validation loss: 3.07420509042327

Epoch: 6| Step: 13
Training loss: 2.750993982489441
Validation loss: 3.073624051896336

Epoch: 20| Step: 0
Training loss: 3.787126246980854
Validation loss: 3.0746754311019004

Epoch: 6| Step: 1
Training loss: 3.1427057310267874
Validation loss: 3.076621110950589

Epoch: 6| Step: 2
Training loss: 3.407156727349313
Validation loss: 3.072103806583874

Epoch: 6| Step: 3
Training loss: 3.3081277746595763
Validation loss: 3.068874578200986

Epoch: 6| Step: 4
Training loss: 3.2446119688351187
Validation loss: 3.068792920695582

Epoch: 6| Step: 5
Training loss: 2.9756335313206375
Validation loss: 3.065348638234126

Epoch: 6| Step: 6
Training loss: 3.4111624475344526
Validation loss: 3.063953733516811

Epoch: 6| Step: 7
Training loss: 3.916846589088423
Validation loss: 3.06118849044541

Epoch: 6| Step: 8
Training loss: 3.4088106941887983
Validation loss: 3.060704084517955

Epoch: 6| Step: 9
Training loss: 3.673925598246736
Validation loss: 3.059800804126992

Epoch: 6| Step: 10
Training loss: 2.7462901320583226
Validation loss: 3.0604328732387525

Epoch: 6| Step: 11
Training loss: 3.427619884350398
Validation loss: 3.057118032810758

Epoch: 6| Step: 12
Training loss: 3.3003198064104273
Validation loss: 3.056856902676341

Epoch: 6| Step: 13
Training loss: 2.688578189767803
Validation loss: 3.058258992584995

Epoch: 21| Step: 0
Training loss: 3.4475201304776784
Validation loss: 3.0646648385742954

Epoch: 6| Step: 1
Training loss: 3.3444974545163886
Validation loss: 3.0573293126634558

Epoch: 6| Step: 2
Training loss: 3.498065141196725
Validation loss: 3.0541559344380977

Epoch: 6| Step: 3
Training loss: 3.0444835178469756
Validation loss: 3.051399113664174

Epoch: 6| Step: 4
Training loss: 3.5307019914068114
Validation loss: 3.048026640448671

Epoch: 6| Step: 5
Training loss: 3.6041377659927045
Validation loss: 3.0480224804537857

Epoch: 6| Step: 6
Training loss: 3.3824513443001094
Validation loss: 3.0484236541247083

Epoch: 6| Step: 7
Training loss: 2.939701635051591
Validation loss: 3.048176204726143

Epoch: 6| Step: 8
Training loss: 2.99665248390833
Validation loss: 3.046285281393959

Epoch: 6| Step: 9
Training loss: 3.7570906677433977
Validation loss: 3.0469595452235585

Epoch: 6| Step: 10
Training loss: 3.1643330022777625
Validation loss: 3.0439071711048946

Epoch: 6| Step: 11
Training loss: 3.4493572686830514
Validation loss: 3.0438558508160067

Epoch: 6| Step: 12
Training loss: 3.6231146546473263
Validation loss: 3.043978702567413

Epoch: 6| Step: 13
Training loss: 2.3499891524368883
Validation loss: 3.0403559095859705

Epoch: 22| Step: 0
Training loss: 3.7024762192914817
Validation loss: 3.0441248259143707

Epoch: 6| Step: 1
Training loss: 3.76624530415918
Validation loss: 3.039613349008004

Epoch: 6| Step: 2
Training loss: 3.955946567463836
Validation loss: 3.0384549963231726

Epoch: 6| Step: 3
Training loss: 2.7205138349442457
Validation loss: 3.0381984488855895

Epoch: 6| Step: 4
Training loss: 4.095072525369619
Validation loss: 3.0372404896047596

Epoch: 6| Step: 5
Training loss: 3.274000023918175
Validation loss: 3.03552615991806

Epoch: 6| Step: 6
Training loss: 2.7111693181458207
Validation loss: 3.034344315794312

Epoch: 6| Step: 7
Training loss: 2.641047697827456
Validation loss: 3.03437350184923

Epoch: 6| Step: 8
Training loss: 2.4878568422093505
Validation loss: 3.0330467324580326

Epoch: 6| Step: 9
Training loss: 3.230402031316775
Validation loss: 3.039006235515162

Epoch: 6| Step: 10
Training loss: 3.2781069279582584
Validation loss: 3.042538967177101

Epoch: 6| Step: 11
Training loss: 3.0323627435200713
Validation loss: 3.0303984159315145

Epoch: 6| Step: 12
Training loss: 3.6322435815441874
Validation loss: 3.028634529909867

Epoch: 6| Step: 13
Training loss: 3.7760508710376324
Validation loss: 3.0263129216818343

Epoch: 23| Step: 0
Training loss: 3.3515185373263985
Validation loss: 3.0279969864553378

Epoch: 6| Step: 1
Training loss: 2.8711968851055043
Validation loss: 3.029893548577101

Epoch: 6| Step: 2
Training loss: 3.323092098248982
Validation loss: 3.030335435838536

Epoch: 6| Step: 3
Training loss: 2.751203967016521
Validation loss: 3.029007215921758

Epoch: 6| Step: 4
Training loss: 4.008672610785753
Validation loss: 3.0269196413371735

Epoch: 6| Step: 5
Training loss: 4.195142461928904
Validation loss: 3.025298439354865

Epoch: 6| Step: 6
Training loss: 3.7889739036033885
Validation loss: 3.0242432208613503

Epoch: 6| Step: 7
Training loss: 2.6968763154734985
Validation loss: 3.021497600930637

Epoch: 6| Step: 8
Training loss: 3.121912537311864
Validation loss: 3.0210071574530124

Epoch: 6| Step: 9
Training loss: 2.623656337714636
Validation loss: 3.019408486090119

Epoch: 6| Step: 10
Training loss: 3.5027050736461924
Validation loss: 3.0196472849510805

Epoch: 6| Step: 11
Training loss: 3.7703779307385865
Validation loss: 3.026553286622057

Epoch: 6| Step: 12
Training loss: 2.885705173726244
Validation loss: 3.0307301704695733

Epoch: 6| Step: 13
Training loss: 2.859425695418083
Validation loss: 3.032955931609263

Epoch: 24| Step: 0
Training loss: 3.6449004514729153
Validation loss: 3.0436195266229547

Epoch: 6| Step: 1
Training loss: 3.3495045993088315
Validation loss: 3.023943004388655

Epoch: 6| Step: 2
Training loss: 3.4882968334093407
Validation loss: 3.0151697404194144

Epoch: 6| Step: 3
Training loss: 3.329224310906236
Validation loss: 3.013108459237079

Epoch: 6| Step: 4
Training loss: 2.4461721061113595
Validation loss: 3.013406835366156

Epoch: 6| Step: 5
Training loss: 2.7047749153172242
Validation loss: 3.0139103211634377

Epoch: 6| Step: 6
Training loss: 2.7317117854968185
Validation loss: 3.016289058686865

Epoch: 6| Step: 7
Training loss: 3.8876711498008856
Validation loss: 3.016541851022137

Epoch: 6| Step: 8
Training loss: 2.96547381675943
Validation loss: 3.0172160356860434

Epoch: 6| Step: 9
Training loss: 3.5056820115302525
Validation loss: 3.0153192374376085

Epoch: 6| Step: 10
Training loss: 3.3604430873815248
Validation loss: 3.0132234415034898

Epoch: 6| Step: 11
Training loss: 4.00717497099502
Validation loss: 3.009846123397341

Epoch: 6| Step: 12
Training loss: 2.901486831196034
Validation loss: 3.0086049167936673

Epoch: 6| Step: 13
Training loss: 3.8016701391043406
Validation loss: 3.0081302734386592

Epoch: 25| Step: 0
Training loss: 2.5679873817169487
Validation loss: 3.006211325630105

Epoch: 6| Step: 1
Training loss: 3.248971336137331
Validation loss: 3.009897832780369

Epoch: 6| Step: 2
Training loss: 3.5696466605518484
Validation loss: 3.0470711055190494

Epoch: 6| Step: 3
Training loss: 3.6836807386335324
Validation loss: 3.041356931641577

Epoch: 6| Step: 4
Training loss: 3.677253582320834
Validation loss: 3.0035529700276107

Epoch: 6| Step: 5
Training loss: 3.691711606913932
Validation loss: 3.0012712152418897

Epoch: 6| Step: 6
Training loss: 3.025007288900374
Validation loss: 3.000972557685211

Epoch: 6| Step: 7
Training loss: 3.220780260077302
Validation loss: 3.0130150614183204

Epoch: 6| Step: 8
Training loss: 3.2767216998032387
Validation loss: 3.076562484367651

Epoch: 6| Step: 9
Training loss: 3.779456603940484
Validation loss: 3.0112279133924105

Epoch: 6| Step: 10
Training loss: 3.6060527357496883
Validation loss: 2.997364835207422

Epoch: 6| Step: 11
Training loss: 2.7437265972972877
Validation loss: 3.0037493673650317

Epoch: 6| Step: 12
Training loss: 3.1139462094717367
Validation loss: 3.0533887728497673

Epoch: 6| Step: 13
Training loss: 2.381504187446291
Validation loss: 3.090194563378788

Epoch: 26| Step: 0
Training loss: 3.528405588377525
Validation loss: 3.1025775349786757

Epoch: 6| Step: 1
Training loss: 3.20310118131388
Validation loss: 3.0114993634264375

Epoch: 6| Step: 2
Training loss: 2.7197646078465554
Validation loss: 2.9922140385830724

Epoch: 6| Step: 3
Training loss: 3.6630938780822357
Validation loss: 2.995037549782716

Epoch: 6| Step: 4
Training loss: 3.3386002573633755
Validation loss: 2.9990159338355173

Epoch: 6| Step: 5
Training loss: 4.111817073063196
Validation loss: 3.0049073714137307

Epoch: 6| Step: 6
Training loss: 2.660513115919188
Validation loss: 3.0074237505675616

Epoch: 6| Step: 7
Training loss: 3.3295595900815185
Validation loss: 3.0119607707218217

Epoch: 6| Step: 8
Training loss: 2.814858613198642
Validation loss: 3.013656450609792

Epoch: 6| Step: 9
Training loss: 3.7526525652709664
Validation loss: 3.0080324699555296

Epoch: 6| Step: 10
Training loss: 3.2807397354827
Validation loss: 3.002114183362281

Epoch: 6| Step: 11
Training loss: 3.69023057088033
Validation loss: 2.9944668781064383

Epoch: 6| Step: 12
Training loss: 2.3985436630362207
Validation loss: 2.9912146142756595

Epoch: 6| Step: 13
Training loss: 3.426942182762794
Validation loss: 2.987420372011815

Epoch: 27| Step: 0
Training loss: 3.48705541039724
Validation loss: 2.984588563864232

Epoch: 6| Step: 1
Training loss: 3.2988313050421323
Validation loss: 2.989520683088036

Epoch: 6| Step: 2
Training loss: 1.991429442745424
Validation loss: 3.001266427531552

Epoch: 6| Step: 3
Training loss: 3.512504583063903
Validation loss: 3.013129384457565

Epoch: 6| Step: 4
Training loss: 3.7492082395761983
Validation loss: 3.0042791116633207

Epoch: 6| Step: 5
Training loss: 3.7608429868745956
Validation loss: 2.9819686698634187

Epoch: 6| Step: 6
Training loss: 2.9887978898778162
Validation loss: 2.979377330098656

Epoch: 6| Step: 7
Training loss: 2.748555410869254
Validation loss: 2.9797123183341303

Epoch: 6| Step: 8
Training loss: 2.9730383167537116
Validation loss: 2.980272358254509

Epoch: 6| Step: 9
Training loss: 3.3693100331050165
Validation loss: 2.9820122862816993

Epoch: 6| Step: 10
Training loss: 3.388745608888016
Validation loss: 2.982155211680881

Epoch: 6| Step: 11
Training loss: 3.4834166436218226
Validation loss: 2.97766476484156

Epoch: 6| Step: 12
Training loss: 3.883787220855422
Validation loss: 2.9765005633050854

Epoch: 6| Step: 13
Training loss: 2.661416538057166
Validation loss: 2.974022447256188

Epoch: 28| Step: 0
Training loss: 2.894696641487711
Validation loss: 2.971520692788623

Epoch: 6| Step: 1
Training loss: 2.286042913586442
Validation loss: 2.971972168411917

Epoch: 6| Step: 2
Training loss: 3.6970917690568794
Validation loss: 2.972154857544361

Epoch: 6| Step: 3
Training loss: 3.1716828687383978
Validation loss: 2.9701008165708864

Epoch: 6| Step: 4
Training loss: 4.091441894282747
Validation loss: 2.967720595049449

Epoch: 6| Step: 5
Training loss: 3.817854326413574
Validation loss: 2.968132052310074

Epoch: 6| Step: 6
Training loss: 3.023343028088398
Validation loss: 2.966563870523771

Epoch: 6| Step: 7
Training loss: 3.718653060547165
Validation loss: 2.965941359923825

Epoch: 6| Step: 8
Training loss: 3.189185201928114
Validation loss: 2.9652248435256356

Epoch: 6| Step: 9
Training loss: 2.658221960176198
Validation loss: 2.9634773481990306

Epoch: 6| Step: 10
Training loss: 3.1875312654046435
Validation loss: 2.9618306670174093

Epoch: 6| Step: 11
Training loss: 3.3650780816959722
Validation loss: 2.960695912348166

Epoch: 6| Step: 12
Training loss: 2.8278172783964592
Validation loss: 2.9609029899220523

Epoch: 6| Step: 13
Training loss: 3.2313015843300734
Validation loss: 2.976059475993904

Epoch: 29| Step: 0
Training loss: 3.4803483216486306
Validation loss: 3.017275371869224

Epoch: 6| Step: 1
Training loss: 2.976193062190794
Validation loss: 3.0132828690687026

Epoch: 6| Step: 2
Training loss: 3.1948273157486327
Validation loss: 3.0596437140989554

Epoch: 6| Step: 3
Training loss: 3.205920083842449
Validation loss: 3.0591988399873955

Epoch: 6| Step: 4
Training loss: 2.871296529031684
Validation loss: 3.0227037816551476

Epoch: 6| Step: 5
Training loss: 3.784388855106308
Validation loss: 2.987353296050741

Epoch: 6| Step: 6
Training loss: 2.8080937095612115
Validation loss: 2.9537719323529834

Epoch: 6| Step: 7
Training loss: 3.591950073625871
Validation loss: 2.955792084451104

Epoch: 6| Step: 8
Training loss: 3.5593905347262376
Validation loss: 2.959243359449873

Epoch: 6| Step: 9
Training loss: 2.6809667975686544
Validation loss: 2.970204078513324

Epoch: 6| Step: 10
Training loss: 3.2853112654791152
Validation loss: 2.975698491065175

Epoch: 6| Step: 11
Training loss: 3.874810121867881
Validation loss: 2.9570579991966506

Epoch: 6| Step: 12
Training loss: 3.385783170766161
Validation loss: 2.95492081547109

Epoch: 6| Step: 13
Training loss: 2.786755716492007
Validation loss: 2.9538130940866645

Epoch: 30| Step: 0
Training loss: 3.379637463781682
Validation loss: 2.9581037314118963

Epoch: 6| Step: 1
Training loss: 3.1717625489995824
Validation loss: 2.9702922828232565

Epoch: 6| Step: 2
Training loss: 3.242611629826299
Validation loss: 2.9710907495204957

Epoch: 6| Step: 3
Training loss: 3.707068552647539
Validation loss: 2.9651981680024857

Epoch: 6| Step: 4
Training loss: 3.507323097123672
Validation loss: 2.9548505733383656

Epoch: 6| Step: 5
Training loss: 3.1430335986155744
Validation loss: 2.958133609886829

Epoch: 6| Step: 6
Training loss: 3.1282923330696857
Validation loss: 2.9537113091861333

Epoch: 6| Step: 7
Training loss: 3.5379232631920314
Validation loss: 2.944504315228144

Epoch: 6| Step: 8
Training loss: 3.5689408820790787
Validation loss: 2.9396065755831846

Epoch: 6| Step: 9
Training loss: 2.3356516991759024
Validation loss: 2.938642663152083

Epoch: 6| Step: 10
Training loss: 2.4575736170440385
Validation loss: 2.9383032509335143

Epoch: 6| Step: 11
Training loss: 3.1491789216967927
Validation loss: 2.9372040157223136

Epoch: 6| Step: 12
Training loss: 3.6678715084620794
Validation loss: 2.936664761900495

Epoch: 6| Step: 13
Training loss: 3.0461816243296
Validation loss: 2.9361111061413188

Epoch: 31| Step: 0
Training loss: 3.7384404354822127
Validation loss: 2.935509526813264

Epoch: 6| Step: 1
Training loss: 4.1139721122690345
Validation loss: 2.934579027520695

Epoch: 6| Step: 2
Training loss: 3.0035582738957305
Validation loss: 2.9329520569467133

Epoch: 6| Step: 3
Training loss: 2.8323800970491506
Validation loss: 2.9392023575572934

Epoch: 6| Step: 4
Training loss: 3.6461178187231216
Validation loss: 2.940820049617055

Epoch: 6| Step: 5
Training loss: 3.2496943696906215
Validation loss: 2.932152194304913

Epoch: 6| Step: 6
Training loss: 2.6794132726279214
Validation loss: 2.929761961069316

Epoch: 6| Step: 7
Training loss: 2.9654680280877
Validation loss: 2.929881837367434

Epoch: 6| Step: 8
Training loss: 2.5043596401747945
Validation loss: 2.944200318980847

Epoch: 6| Step: 9
Training loss: 4.012175150523287
Validation loss: 2.9318384118828846

Epoch: 6| Step: 10
Training loss: 2.953688471892264
Validation loss: 2.93138581172595

Epoch: 6| Step: 11
Training loss: 3.1265849862345756
Validation loss: 2.9305014996452625

Epoch: 6| Step: 12
Training loss: 2.785865383102668
Validation loss: 2.93651221394681

Epoch: 6| Step: 13
Training loss: 2.996263879673034
Validation loss: 2.9315527986099417

Epoch: 32| Step: 0
Training loss: 3.34537673311246
Validation loss: 2.9258594169258623

Epoch: 6| Step: 1
Training loss: 3.3163931658770904
Validation loss: 2.925129404948844

Epoch: 6| Step: 2
Training loss: 2.6136072978940392
Validation loss: 2.918404259932789

Epoch: 6| Step: 3
Training loss: 3.0552561199007386
Validation loss: 2.9169960914131234

Epoch: 6| Step: 4
Training loss: 3.3996516722474297
Validation loss: 2.9185376390894873

Epoch: 6| Step: 5
Training loss: 2.9692636145960276
Validation loss: 2.9178774510619885

Epoch: 6| Step: 6
Training loss: 3.466632918658191
Validation loss: 2.9183207209283113

Epoch: 6| Step: 7
Training loss: 2.867713152438788
Validation loss: 2.917338045845013

Epoch: 6| Step: 8
Training loss: 2.8966758289199572
Validation loss: 2.915932275164024

Epoch: 6| Step: 9
Training loss: 3.181958786223373
Validation loss: 2.9164986018499444

Epoch: 6| Step: 10
Training loss: 3.693826195048776
Validation loss: 2.9138667565353265

Epoch: 6| Step: 11
Training loss: 3.571425650459185
Validation loss: 2.914089539808857

Epoch: 6| Step: 12
Training loss: 3.1760905397899726
Validation loss: 2.9125138481508404

Epoch: 6| Step: 13
Training loss: 3.4596653100577788
Validation loss: 2.911465977540167

Epoch: 33| Step: 0
Training loss: 3.6684668774512645
Validation loss: 2.912615034238265

Epoch: 6| Step: 1
Training loss: 3.169669601358303
Validation loss: 2.9073511534609833

Epoch: 6| Step: 2
Training loss: 3.47650791082493
Validation loss: 2.9059332653939824

Epoch: 6| Step: 3
Training loss: 2.9709013522272203
Validation loss: 2.9035140722195933

Epoch: 6| Step: 4
Training loss: 3.000130014781163
Validation loss: 2.9069248720975005

Epoch: 6| Step: 5
Training loss: 3.334626201401916
Validation loss: 2.9069842644747057

Epoch: 6| Step: 6
Training loss: 3.485725722640346
Validation loss: 2.900221639691757

Epoch: 6| Step: 7
Training loss: 2.86055560310571
Validation loss: 2.8976460771552937

Epoch: 6| Step: 8
Training loss: 3.036953309394529
Validation loss: 2.896492570893927

Epoch: 6| Step: 9
Training loss: 2.995462801271087
Validation loss: 2.8959032748022424

Epoch: 6| Step: 10
Training loss: 3.60355585174024
Validation loss: 2.9135658839286322

Epoch: 6| Step: 11
Training loss: 3.447047343921367
Validation loss: 2.929189423036685

Epoch: 6| Step: 12
Training loss: 2.7310633196200205
Validation loss: 2.944280367001201

Epoch: 6| Step: 13
Training loss: 2.793313257271205
Validation loss: 2.91596992069534

Epoch: 34| Step: 0
Training loss: 2.9783601714043773
Validation loss: 2.8960356524734046

Epoch: 6| Step: 1
Training loss: 2.5270472357033276
Validation loss: 2.894894602170743

Epoch: 6| Step: 2
Training loss: 2.970635708677837
Validation loss: 2.8969363660505523

Epoch: 6| Step: 3
Training loss: 3.191409238255945
Validation loss: 2.8957158635351243

Epoch: 6| Step: 4
Training loss: 3.2459965036012597
Validation loss: 2.89529961369733

Epoch: 6| Step: 5
Training loss: 3.329738029050041
Validation loss: 2.8944347530963777

Epoch: 6| Step: 6
Training loss: 2.5400343692887244
Validation loss: 2.889862071613291

Epoch: 6| Step: 7
Training loss: 3.3371131129814895
Validation loss: 2.8883764051277945

Epoch: 6| Step: 8
Training loss: 3.883305662217557
Validation loss: 2.8883424819451005

Epoch: 6| Step: 9
Training loss: 3.0516732800792434
Validation loss: 2.8863238216966143

Epoch: 6| Step: 10
Training loss: 3.5251947660275076
Validation loss: 2.8822259358182305

Epoch: 6| Step: 11
Training loss: 2.9066676998428234
Validation loss: 2.882443889327973

Epoch: 6| Step: 12
Training loss: 3.305615594640988
Validation loss: 2.881864612269458

Epoch: 6| Step: 13
Training loss: 3.933592295338609
Validation loss: 2.8842054660475656

Epoch: 35| Step: 0
Training loss: 3.270993287534716
Validation loss: 2.8871540101831323

Epoch: 6| Step: 1
Training loss: 3.8817493357085073
Validation loss: 2.8851532120399583

Epoch: 6| Step: 2
Training loss: 3.5540141715055396
Validation loss: 2.8781460281317726

Epoch: 6| Step: 3
Training loss: 2.774845421412143
Validation loss: 2.876232382436109

Epoch: 6| Step: 4
Training loss: 3.0375046843818367
Validation loss: 2.875582318142943

Epoch: 6| Step: 5
Training loss: 3.3442110118180253
Validation loss: 2.8755131246200802

Epoch: 6| Step: 6
Training loss: 3.226391951738833
Validation loss: 2.8761516081894487

Epoch: 6| Step: 7
Training loss: 3.5134531051613553
Validation loss: 2.8753054493581374

Epoch: 6| Step: 8
Training loss: 2.7370859712667457
Validation loss: 2.8839061739075333

Epoch: 6| Step: 9
Training loss: 3.082108451930342
Validation loss: 2.8886664950867815

Epoch: 6| Step: 10
Training loss: 3.0844757094556083
Validation loss: 2.8989308993724356

Epoch: 6| Step: 11
Training loss: 3.1478295129660685
Validation loss: 2.8854469533766927

Epoch: 6| Step: 12
Training loss: 2.689243726813282
Validation loss: 2.875033996794775

Epoch: 6| Step: 13
Training loss: 2.9773456013938255
Validation loss: 2.8713680437388445

Epoch: 36| Step: 0
Training loss: 2.6647293285452425
Validation loss: 2.8715651004064338

Epoch: 6| Step: 1
Training loss: 3.7044657280039797
Validation loss: 2.870513609619602

Epoch: 6| Step: 2
Training loss: 2.7918695594353715
Validation loss: 2.869253790919773

Epoch: 6| Step: 3
Training loss: 2.2754637612307334
Validation loss: 2.870240566851398

Epoch: 6| Step: 4
Training loss: 3.3490353462219744
Validation loss: 2.884857246707483

Epoch: 6| Step: 5
Training loss: 3.716927474469184
Validation loss: 2.900929609418022

Epoch: 6| Step: 6
Training loss: 3.8606234241721378
Validation loss: 2.887857560547979

Epoch: 6| Step: 7
Training loss: 3.6420890254745864
Validation loss: 2.871845638959661

Epoch: 6| Step: 8
Training loss: 2.7262879154134643
Validation loss: 2.863778298357778

Epoch: 6| Step: 9
Training loss: 3.354925855564902
Validation loss: 2.862320021091253

Epoch: 6| Step: 10
Training loss: 2.859121509426289
Validation loss: 2.868391267736101

Epoch: 6| Step: 11
Training loss: 2.8708550801627704
Validation loss: 2.886063892569458

Epoch: 6| Step: 12
Training loss: 3.129557223948581
Validation loss: 2.8670523659344767

Epoch: 6| Step: 13
Training loss: 3.185125027153351
Validation loss: 2.8629953986279686

Epoch: 37| Step: 0
Training loss: 3.3422913979694275
Validation loss: 2.8590504667055043

Epoch: 6| Step: 1
Training loss: 3.095147327866829
Validation loss: 2.858810386095089

Epoch: 6| Step: 2
Training loss: 3.2102554970664428
Validation loss: 2.859162905814529

Epoch: 6| Step: 3
Training loss: 2.5628559516616
Validation loss: 2.861283593561163

Epoch: 6| Step: 4
Training loss: 3.346120689153611
Validation loss: 2.8546294482447547

Epoch: 6| Step: 5
Training loss: 2.3123198774141565
Validation loss: 2.857035179350499

Epoch: 6| Step: 6
Training loss: 3.3609138690112412
Validation loss: 2.8576605785727964

Epoch: 6| Step: 7
Training loss: 3.6101686340000754
Validation loss: 2.856325867999405

Epoch: 6| Step: 8
Training loss: 3.6011703178385015
Validation loss: 2.8549652820655234

Epoch: 6| Step: 9
Training loss: 2.728573120647354
Validation loss: 2.8525542841199822

Epoch: 6| Step: 10
Training loss: 2.734214211232411
Validation loss: 2.853450108247862

Epoch: 6| Step: 11
Training loss: 3.7207600266318237
Validation loss: 2.855813282516268

Epoch: 6| Step: 12
Training loss: 3.3132147827533416
Validation loss: 2.8601594688585936

Epoch: 6| Step: 13
Training loss: 3.0502404040037234
Validation loss: 2.859386787231114

Epoch: 38| Step: 0
Training loss: 2.8816827147084587
Validation loss: 2.8618922833941185

Epoch: 6| Step: 1
Training loss: 3.408392835873355
Validation loss: 2.8654893950547855

Epoch: 6| Step: 2
Training loss: 3.010027339975892
Validation loss: 2.854837605660574

Epoch: 6| Step: 3
Training loss: 3.0411330673874053
Validation loss: 2.8461192008288174

Epoch: 6| Step: 4
Training loss: 3.592142558304123
Validation loss: 2.8475128380336967

Epoch: 6| Step: 5
Training loss: 3.086377230834031
Validation loss: 2.845672002985583

Epoch: 6| Step: 6
Training loss: 3.9116239889379654
Validation loss: 2.8470368050235564

Epoch: 6| Step: 7
Training loss: 2.3816379341259197
Validation loss: 2.8458620035885165

Epoch: 6| Step: 8
Training loss: 3.3040324975602284
Validation loss: 2.843532730199125

Epoch: 6| Step: 9
Training loss: 3.2109826449076984
Validation loss: 2.8439320502955265

Epoch: 6| Step: 10
Training loss: 3.3527943585890156
Validation loss: 2.8418862772536917

Epoch: 6| Step: 11
Training loss: 3.448964369866609
Validation loss: 2.8429565404537085

Epoch: 6| Step: 12
Training loss: 2.2000286447220763
Validation loss: 2.841554088910848

Epoch: 6| Step: 13
Training loss: 2.8990887426956946
Validation loss: 2.845320318405617

Epoch: 39| Step: 0
Training loss: 3.14577839447621
Validation loss: 2.8575164835558

Epoch: 6| Step: 1
Training loss: 3.414618614872557
Validation loss: 2.8624230728742517

Epoch: 6| Step: 2
Training loss: 3.149500210788815
Validation loss: 2.848109825984412

Epoch: 6| Step: 3
Training loss: 2.8999371620473506
Validation loss: 2.8408847993947632

Epoch: 6| Step: 4
Training loss: 3.554987029147193
Validation loss: 2.8420855837097077

Epoch: 6| Step: 5
Training loss: 3.277959427047732
Validation loss: 2.839876665516263

Epoch: 6| Step: 6
Training loss: 2.955365657999929
Validation loss: 2.8375262091313767

Epoch: 6| Step: 7
Training loss: 2.948626123974
Validation loss: 2.8384756356979475

Epoch: 6| Step: 8
Training loss: 3.2282868365981714
Validation loss: 2.837899723640681

Epoch: 6| Step: 9
Training loss: 3.6232332330777846
Validation loss: 2.8392623674346256

Epoch: 6| Step: 10
Training loss: 3.0046598483760785
Validation loss: 2.842176771860498

Epoch: 6| Step: 11
Training loss: 3.14433835782603
Validation loss: 2.846971668657895

Epoch: 6| Step: 12
Training loss: 2.4530832080561336
Validation loss: 2.846116608470385

Epoch: 6| Step: 13
Training loss: 3.3341192431622044
Validation loss: 2.8402524975193026

Epoch: 40| Step: 0
Training loss: 3.3673540326422975
Validation loss: 2.8371482476418404

Epoch: 6| Step: 1
Training loss: 2.931293505120083
Validation loss: 2.8423348445953134

Epoch: 6| Step: 2
Training loss: 3.64732144457995
Validation loss: 2.8483188216812523

Epoch: 6| Step: 3
Training loss: 3.2374998468229634
Validation loss: 2.846751719757949

Epoch: 6| Step: 4
Training loss: 3.7167129707588176
Validation loss: 2.840601391764532

Epoch: 6| Step: 5
Training loss: 3.4140560752406652
Validation loss: 2.837340594482398

Epoch: 6| Step: 6
Training loss: 2.86532174505722
Validation loss: 2.830451615201912

Epoch: 6| Step: 7
Training loss: 2.125732968646744
Validation loss: 2.827808604232323

Epoch: 6| Step: 8
Training loss: 3.527790366590037
Validation loss: 2.8268339647813376

Epoch: 6| Step: 9
Training loss: 2.7072556527885694
Validation loss: 2.8242476276082162

Epoch: 6| Step: 10
Training loss: 3.503620999397891
Validation loss: 2.8245558461153766

Epoch: 6| Step: 11
Training loss: 3.1690826903485183
Validation loss: 2.8247550040295977

Epoch: 6| Step: 12
Training loss: 2.6530651072289575
Validation loss: 2.8218322282611537

Epoch: 6| Step: 13
Training loss: 2.4770988581507516
Validation loss: 2.822443704784402

Epoch: 41| Step: 0
Training loss: 2.819560534546331
Validation loss: 2.8234922584107625

Epoch: 6| Step: 1
Training loss: 3.673624344345004
Validation loss: 2.8223565215682562

Epoch: 6| Step: 2
Training loss: 2.667063792778447
Validation loss: 2.8343886383228156

Epoch: 6| Step: 3
Training loss: 3.1386603288135477
Validation loss: 2.833801231499984

Epoch: 6| Step: 4
Training loss: 3.165110624046365
Validation loss: 2.856427601311579

Epoch: 6| Step: 5
Training loss: 3.395388583837483
Validation loss: 2.8656030397556345

Epoch: 6| Step: 6
Training loss: 3.700462961874115
Validation loss: 2.8763903091353824

Epoch: 6| Step: 7
Training loss: 2.344445595833896
Validation loss: 2.8746538841132803

Epoch: 6| Step: 8
Training loss: 3.8222542725064548
Validation loss: 2.8845627707622947

Epoch: 6| Step: 9
Training loss: 2.9900535364365695
Validation loss: 2.8858960902003727

Epoch: 6| Step: 10
Training loss: 3.280426212624605
Validation loss: 2.8435319034603364

Epoch: 6| Step: 11
Training loss: 2.6962812811142696
Validation loss: 2.8171476695278677

Epoch: 6| Step: 12
Training loss: 2.4978799413717963
Validation loss: 2.8193599303605454

Epoch: 6| Step: 13
Training loss: 3.7409370260355455
Validation loss: 2.8730900213021244

Epoch: 42| Step: 0
Training loss: 3.0874183674881706
Validation loss: 2.8401332863969415

Epoch: 6| Step: 1
Training loss: 2.92999640298564
Validation loss: 2.8183080445842448

Epoch: 6| Step: 2
Training loss: 3.5090386981107615
Validation loss: 2.8147208010720397

Epoch: 6| Step: 3
Training loss: 2.5488989341517203
Validation loss: 2.812015438837162

Epoch: 6| Step: 4
Training loss: 3.0807843024682793
Validation loss: 2.813932423216601

Epoch: 6| Step: 5
Training loss: 2.7093494172081916
Validation loss: 2.8227807286098314

Epoch: 6| Step: 6
Training loss: 3.0335942278440906
Validation loss: 2.8469148352050473

Epoch: 6| Step: 7
Training loss: 3.2081901881664163
Validation loss: 2.8784044714804855

Epoch: 6| Step: 8
Training loss: 4.038618111282533
Validation loss: 2.8802408813163716

Epoch: 6| Step: 9
Training loss: 3.6880687986150518
Validation loss: 2.816486813469894

Epoch: 6| Step: 10
Training loss: 3.3673931156405947
Validation loss: 2.8024729930353613

Epoch: 6| Step: 11
Training loss: 2.8526408625600017
Validation loss: 2.799640296063119

Epoch: 6| Step: 12
Training loss: 3.027073293110491
Validation loss: 2.8635972250774744

Epoch: 6| Step: 13
Training loss: 2.1477579047664035
Validation loss: 2.8252907370614078

Epoch: 43| Step: 0
Training loss: 3.2685593558563912
Validation loss: 2.806211454858193

Epoch: 6| Step: 1
Training loss: 2.7463318896509965
Validation loss: 2.7986960354462598

Epoch: 6| Step: 2
Training loss: 3.6011892526647777
Validation loss: 2.797320821389788

Epoch: 6| Step: 3
Training loss: 3.3821669881100527
Validation loss: 2.8015535040267285

Epoch: 6| Step: 4
Training loss: 2.928477289102322
Validation loss: 2.7997495263806447

Epoch: 6| Step: 5
Training loss: 3.072690242033246
Validation loss: 2.7983089805637396

Epoch: 6| Step: 6
Training loss: 3.007693122377347
Validation loss: 2.7968742722124054

Epoch: 6| Step: 7
Training loss: 3.488147147784504
Validation loss: 2.799387506509253

Epoch: 6| Step: 8
Training loss: 2.8599961236780747
Validation loss: 2.7988840938284314

Epoch: 6| Step: 9
Training loss: 3.476075830578447
Validation loss: 2.7959512282775676

Epoch: 6| Step: 10
Training loss: 2.759647612535618
Validation loss: 2.80070915489217

Epoch: 6| Step: 11
Training loss: 2.970638597980167
Validation loss: 2.8019890227074127

Epoch: 6| Step: 12
Training loss: 2.6926956520790353
Validation loss: 2.7983986380093424

Epoch: 6| Step: 13
Training loss: 3.226930758910506
Validation loss: 2.793550360585454

Epoch: 44| Step: 0
Training loss: 1.8953595110793662
Validation loss: 2.7927231942073596

Epoch: 6| Step: 1
Training loss: 3.256368413079088
Validation loss: 2.7882521355652385

Epoch: 6| Step: 2
Training loss: 3.1365971333833165
Validation loss: 2.7906936586902713

Epoch: 6| Step: 3
Training loss: 3.586531047691444
Validation loss: 2.7868602681690327

Epoch: 6| Step: 4
Training loss: 2.61228305700741
Validation loss: 2.785088887668774

Epoch: 6| Step: 5
Training loss: 3.4459308233773287
Validation loss: 2.7835038958934923

Epoch: 6| Step: 6
Training loss: 2.777107153578352
Validation loss: 2.782792899831117

Epoch: 6| Step: 7
Training loss: 2.8068590178764112
Validation loss: 2.7810491120866687

Epoch: 6| Step: 8
Training loss: 2.823101323881221
Validation loss: 2.781795985042319

Epoch: 6| Step: 9
Training loss: 2.671946028272826
Validation loss: 2.7793326585952953

Epoch: 6| Step: 10
Training loss: 3.476168698070312
Validation loss: 2.7797293659128526

Epoch: 6| Step: 11
Training loss: 3.6806507186263158
Validation loss: 2.7787401674028294

Epoch: 6| Step: 12
Training loss: 3.3632877717525327
Validation loss: 2.7813210224237856

Epoch: 6| Step: 13
Training loss: 3.7147600583698224
Validation loss: 2.7864884508399235

Epoch: 45| Step: 0
Training loss: 2.2296374052711743
Validation loss: 2.786278239147807

Epoch: 6| Step: 1
Training loss: 3.867257535666324
Validation loss: 2.7892026782430723

Epoch: 6| Step: 2
Training loss: 3.2521381680649073
Validation loss: 2.7925131020738148

Epoch: 6| Step: 3
Training loss: 3.955464511411725
Validation loss: 2.792743597888028

Epoch: 6| Step: 4
Training loss: 2.8670418102035202
Validation loss: 2.795486369455597

Epoch: 6| Step: 5
Training loss: 2.7079710987132164
Validation loss: 2.781414986178507

Epoch: 6| Step: 6
Training loss: 3.5770360630639386
Validation loss: 2.775971243671421

Epoch: 6| Step: 7
Training loss: 3.551325354523525
Validation loss: 2.7756634387815566

Epoch: 6| Step: 8
Training loss: 2.6325911703380003
Validation loss: 2.7744457768616666

Epoch: 6| Step: 9
Training loss: 3.2928841830036752
Validation loss: 2.7732077217269815

Epoch: 6| Step: 10
Training loss: 2.7320604392050405
Validation loss: 2.772910081328248

Epoch: 6| Step: 11
Training loss: 2.942165160334898
Validation loss: 2.7773748438518266

Epoch: 6| Step: 12
Training loss: 2.3391424029099444
Validation loss: 2.776673965247543

Epoch: 6| Step: 13
Training loss: 2.5766549282949853
Validation loss: 2.7719596321121243

Epoch: 46| Step: 0
Training loss: 3.865371801893075
Validation loss: 2.767782828660927

Epoch: 6| Step: 1
Training loss: 2.543331372354867
Validation loss: 2.766052963360471

Epoch: 6| Step: 2
Training loss: 2.4597157185365193
Validation loss: 2.765050790562025

Epoch: 6| Step: 3
Training loss: 3.501688958420413
Validation loss: 2.7652507779311453

Epoch: 6| Step: 4
Training loss: 3.253624875289338
Validation loss: 2.7670744748703524

Epoch: 6| Step: 5
Training loss: 2.635782621002157
Validation loss: 2.7644147681989626

Epoch: 6| Step: 6
Training loss: 3.1397172365615225
Validation loss: 2.764075941376607

Epoch: 6| Step: 7
Training loss: 3.813226849418607
Validation loss: 2.7641357106849735

Epoch: 6| Step: 8
Training loss: 2.090058673965905
Validation loss: 2.762944574366764

Epoch: 6| Step: 9
Training loss: 3.0869151437933096
Validation loss: 2.762226630609657

Epoch: 6| Step: 10
Training loss: 3.1353580473598295
Validation loss: 2.7613178536629013

Epoch: 6| Step: 11
Training loss: 3.055227246612334
Validation loss: 2.7601858465487004

Epoch: 6| Step: 12
Training loss: 2.979556842853877
Validation loss: 2.7642056323555644

Epoch: 6| Step: 13
Training loss: 3.1846972840564707
Validation loss: 2.768664770134666

Epoch: 47| Step: 0
Training loss: 2.1672501756424016
Validation loss: 2.781868934318872

Epoch: 6| Step: 1
Training loss: 2.8272906173768946
Validation loss: 2.792412816262975

Epoch: 6| Step: 2
Training loss: 3.3021937852230927
Validation loss: 2.795521374496255

Epoch: 6| Step: 3
Training loss: 3.4157563989603497
Validation loss: 2.802730213145186

Epoch: 6| Step: 4
Training loss: 2.7013154781230964
Validation loss: 2.82511627868348

Epoch: 6| Step: 5
Training loss: 3.581021398468127
Validation loss: 2.845330671806166

Epoch: 6| Step: 6
Training loss: 3.750949739351829
Validation loss: 2.813369874414625

Epoch: 6| Step: 7
Training loss: 3.0358653375567104
Validation loss: 2.7954678437791194

Epoch: 6| Step: 8
Training loss: 2.8494276442437125
Validation loss: 2.756337986592924

Epoch: 6| Step: 9
Training loss: 2.75364824533883
Validation loss: 2.757022030802181

Epoch: 6| Step: 10
Training loss: 3.639569960542133
Validation loss: 2.7744497963414414

Epoch: 6| Step: 11
Training loss: 2.693472502326425
Validation loss: 2.779061867329419

Epoch: 6| Step: 12
Training loss: 3.1370616834642213
Validation loss: 2.7880361563302083

Epoch: 6| Step: 13
Training loss: 3.3195611799313367
Validation loss: 2.7806197426284673

Epoch: 48| Step: 0
Training loss: 3.5554437189262535
Validation loss: 2.773369780930833

Epoch: 6| Step: 1
Training loss: 2.5386004687795776
Validation loss: 2.7607127496171553

Epoch: 6| Step: 2
Training loss: 2.992149571907953
Validation loss: 2.7638828265635045

Epoch: 6| Step: 3
Training loss: 3.1108433309238226
Validation loss: 2.765275359654388

Epoch: 6| Step: 4
Training loss: 2.4726458363969104
Validation loss: 2.765629942578858

Epoch: 6| Step: 5
Training loss: 2.885589337375402
Validation loss: 2.7678711566028733

Epoch: 6| Step: 6
Training loss: 3.2495992853645657
Validation loss: 2.7789960878932822

Epoch: 6| Step: 7
Training loss: 3.115408865606944
Validation loss: 2.777298359329592

Epoch: 6| Step: 8
Training loss: 3.391090747821553
Validation loss: 2.7755507741021814

Epoch: 6| Step: 9
Training loss: 3.3272016077073054
Validation loss: 2.7692652001401803

Epoch: 6| Step: 10
Training loss: 3.0192785712518004
Validation loss: 2.751142480788673

Epoch: 6| Step: 11
Training loss: 3.1460315229288023
Validation loss: 2.747597055667805

Epoch: 6| Step: 12
Training loss: 2.8160972478612347
Validation loss: 2.744857585238647

Epoch: 6| Step: 13
Training loss: 3.659432615482999
Validation loss: 2.745395523380895

Epoch: 49| Step: 0
Training loss: 2.913933226962534
Validation loss: 2.7468331132435058

Epoch: 6| Step: 1
Training loss: 3.209600388320945
Validation loss: 2.7475983442071414

Epoch: 6| Step: 2
Training loss: 3.170949415637721
Validation loss: 2.749475575482719

Epoch: 6| Step: 3
Training loss: 3.1478919226235442
Validation loss: 2.748959849879742

Epoch: 6| Step: 4
Training loss: 2.160506759820139
Validation loss: 2.75050592476446

Epoch: 6| Step: 5
Training loss: 2.593396266118087
Validation loss: 2.7512680161941483

Epoch: 6| Step: 6
Training loss: 2.808736699356755
Validation loss: 2.754140827629334

Epoch: 6| Step: 7
Training loss: 3.2176969713031247
Validation loss: 2.7502816485786794

Epoch: 6| Step: 8
Training loss: 2.96507951806725
Validation loss: 2.7468917010127645

Epoch: 6| Step: 9
Training loss: 3.513580541605824
Validation loss: 2.7431160137477812

Epoch: 6| Step: 10
Training loss: 3.5886386513119346
Validation loss: 2.7402920064680143

Epoch: 6| Step: 11
Training loss: 3.4290893311121353
Validation loss: 2.7403756055866055

Epoch: 6| Step: 12
Training loss: 2.6060634774991347
Validation loss: 2.7399337281210467

Epoch: 6| Step: 13
Training loss: 3.829684068482946
Validation loss: 2.7383977735233564

Epoch: 50| Step: 0
Training loss: 3.295925781136575
Validation loss: 2.738004680574983

Epoch: 6| Step: 1
Training loss: 2.6110416046883618
Validation loss: 2.738016869055861

Epoch: 6| Step: 2
Training loss: 3.758581388172095
Validation loss: 2.736678162488259

Epoch: 6| Step: 3
Training loss: 2.9242772309766387
Validation loss: 2.7335983556316923

Epoch: 6| Step: 4
Training loss: 2.737613264553813
Validation loss: 2.732981420400841

Epoch: 6| Step: 5
Training loss: 3.228303822737168
Validation loss: 2.7317681947128776

Epoch: 6| Step: 6
Training loss: 2.221160224298192
Validation loss: 2.730497593364779

Epoch: 6| Step: 7
Training loss: 3.093304072137532
Validation loss: 2.729937180602396

Epoch: 6| Step: 8
Training loss: 2.8960928674845228
Validation loss: 2.7292546591013815

Epoch: 6| Step: 9
Training loss: 3.256837548022465
Validation loss: 2.7289569163244303

Epoch: 6| Step: 10
Training loss: 3.3171628845997763
Validation loss: 2.728004576066669

Epoch: 6| Step: 11
Training loss: 2.9443211999527517
Validation loss: 2.7289882054549515

Epoch: 6| Step: 12
Training loss: 3.1058681015335368
Validation loss: 2.730451982110351

Epoch: 6| Step: 13
Training loss: 3.4426210578016905
Validation loss: 2.731335448370194

Epoch: 51| Step: 0
Training loss: 3.2319974407431413
Validation loss: 2.7361579466114665

Epoch: 6| Step: 1
Training loss: 3.432850971101851
Validation loss: 2.7306995925969355

Epoch: 6| Step: 2
Training loss: 2.6896144621860203
Validation loss: 2.72978708829709

Epoch: 6| Step: 3
Training loss: 2.313057084899318
Validation loss: 2.7306608011384776

Epoch: 6| Step: 4
Training loss: 3.218023570039017
Validation loss: 2.728003811110559

Epoch: 6| Step: 5
Training loss: 2.975738811916396
Validation loss: 2.730604848800413

Epoch: 6| Step: 6
Training loss: 3.521153828557167
Validation loss: 2.7283980818388907

Epoch: 6| Step: 7
Training loss: 2.8981319790859565
Validation loss: 2.7272558576805426

Epoch: 6| Step: 8
Training loss: 3.279057814953648
Validation loss: 2.7281005199729376

Epoch: 6| Step: 9
Training loss: 2.7847860767107395
Validation loss: 2.727892827238173

Epoch: 6| Step: 10
Training loss: 3.7139725972337128
Validation loss: 2.7418571913397414

Epoch: 6| Step: 11
Training loss: 2.9761988300024593
Validation loss: 2.7493527854315123

Epoch: 6| Step: 12
Training loss: 2.3592832433782407
Validation loss: 2.7411203223476495

Epoch: 6| Step: 13
Training loss: 3.0756970429660107
Validation loss: 2.734640224737274

Epoch: 52| Step: 0
Training loss: 3.2307494847599014
Validation loss: 2.7255692721940115

Epoch: 6| Step: 1
Training loss: 3.1602129842713182
Validation loss: 2.7221549022097378

Epoch: 6| Step: 2
Training loss: 3.3141596253374392
Validation loss: 2.723312375375398

Epoch: 6| Step: 3
Training loss: 3.1053176555224136
Validation loss: 2.7234708021536456

Epoch: 6| Step: 4
Training loss: 2.757674864881716
Validation loss: 2.7229372226387865

Epoch: 6| Step: 5
Training loss: 2.5482343544791757
Validation loss: 2.7227479636148813

Epoch: 6| Step: 6
Training loss: 2.8863913385240134
Validation loss: 2.726236636249176

Epoch: 6| Step: 7
Training loss: 2.435054628358637
Validation loss: 2.7247565535627998

Epoch: 6| Step: 8
Training loss: 3.5123128929396588
Validation loss: 2.726503884407982

Epoch: 6| Step: 9
Training loss: 3.421973936836698
Validation loss: 2.7244984739787848

Epoch: 6| Step: 10
Training loss: 2.9039944335421763
Validation loss: 2.7213487709362063

Epoch: 6| Step: 11
Training loss: 1.9792932034916362
Validation loss: 2.721020852599995

Epoch: 6| Step: 12
Training loss: 3.8465821291814484
Validation loss: 2.7208838136674816

Epoch: 6| Step: 13
Training loss: 3.2802843398616828
Validation loss: 2.718892693561484

Epoch: 53| Step: 0
Training loss: 3.2284695436820248
Validation loss: 2.7187719668343813

Epoch: 6| Step: 1
Training loss: 3.299895001677285
Validation loss: 2.7175956730047557

Epoch: 6| Step: 2
Training loss: 2.444319745938682
Validation loss: 2.715432179019891

Epoch: 6| Step: 3
Training loss: 2.938421226682778
Validation loss: 2.7135068391932293

Epoch: 6| Step: 4
Training loss: 2.583857780463756
Validation loss: 2.7136295290128842

Epoch: 6| Step: 5
Training loss: 2.2745040017505995
Validation loss: 2.7112222382311058

Epoch: 6| Step: 6
Training loss: 3.0939745580691196
Validation loss: 2.7112575880003

Epoch: 6| Step: 7
Training loss: 3.507813859357337
Validation loss: 2.708170530160459

Epoch: 6| Step: 8
Training loss: 3.233870019974722
Validation loss: 2.7076216429156514

Epoch: 6| Step: 9
Training loss: 3.527444054412038
Validation loss: 2.7052994536219233

Epoch: 6| Step: 10
Training loss: 3.3663343158507324
Validation loss: 2.7062255501326495

Epoch: 6| Step: 11
Training loss: 3.030789999125447
Validation loss: 2.7026875279605314

Epoch: 6| Step: 12
Training loss: 3.089283194253462
Validation loss: 2.7011307480038242

Epoch: 6| Step: 13
Training loss: 2.400460449395096
Validation loss: 2.7021367907230025

Epoch: 54| Step: 0
Training loss: 3.0094059674183873
Validation loss: 2.713411227700491

Epoch: 6| Step: 1
Training loss: 2.791280254741586
Validation loss: 2.734696290437902

Epoch: 6| Step: 2
Training loss: 2.705650076323665
Validation loss: 2.7612524379068315

Epoch: 6| Step: 3
Training loss: 2.1526589829130645
Validation loss: 2.7873858924707715

Epoch: 6| Step: 4
Training loss: 3.4908911840022916
Validation loss: 2.8073519681738115

Epoch: 6| Step: 5
Training loss: 3.323324547172214
Validation loss: 2.773916982463982

Epoch: 6| Step: 6
Training loss: 3.0287742336057826
Validation loss: 2.71766630061215

Epoch: 6| Step: 7
Training loss: 2.727251725404966
Validation loss: 2.6993757236442715

Epoch: 6| Step: 8
Training loss: 3.394236245632014
Validation loss: 2.694981404127205

Epoch: 6| Step: 9
Training loss: 2.9403974163269804
Validation loss: 2.6992626499743353

Epoch: 6| Step: 10
Training loss: 3.102771744304343
Validation loss: 2.70094811144404

Epoch: 6| Step: 11
Training loss: 3.8803372696654836
Validation loss: 2.7041257871271407

Epoch: 6| Step: 12
Training loss: 3.0043456074987236
Validation loss: 2.7092505552839614

Epoch: 6| Step: 13
Training loss: 2.708152109587519
Validation loss: 2.703568493246494

Epoch: 55| Step: 0
Training loss: 3.426898213095195
Validation loss: 2.7004766598369914

Epoch: 6| Step: 1
Training loss: 3.165686070718296
Validation loss: 2.7003073027881728

Epoch: 6| Step: 2
Training loss: 3.1045511677513122
Validation loss: 2.701947194322617

Epoch: 6| Step: 3
Training loss: 3.097391316844794
Validation loss: 2.699696342061281

Epoch: 6| Step: 4
Training loss: 3.4821556789735038
Validation loss: 2.699897686543918

Epoch: 6| Step: 5
Training loss: 3.13258418062175
Validation loss: 2.700722429914895

Epoch: 6| Step: 6
Training loss: 2.675227064674081
Validation loss: 2.7160916248348257

Epoch: 6| Step: 7
Training loss: 2.374719201604372
Validation loss: 2.7340400436733154

Epoch: 6| Step: 8
Training loss: 2.8671342808412374
Validation loss: 2.7528864291592647

Epoch: 6| Step: 9
Training loss: 3.309058074616782
Validation loss: 2.7473430999203554

Epoch: 6| Step: 10
Training loss: 3.0294892221130962
Validation loss: 2.726119084161941

Epoch: 6| Step: 11
Training loss: 2.816717080411873
Validation loss: 2.710476709808861

Epoch: 6| Step: 12
Training loss: 3.0612764055040826
Validation loss: 2.706007667120823

Epoch: 6| Step: 13
Training loss: 2.523811241793669
Validation loss: 2.7019977845189347

Epoch: 56| Step: 0
Training loss: 2.7839510371188636
Validation loss: 2.699876660963611

Epoch: 6| Step: 1
Training loss: 2.7910911384334964
Validation loss: 2.6964659374955615

Epoch: 6| Step: 2
Training loss: 2.991803575391945
Validation loss: 2.6971335355152752

Epoch: 6| Step: 3
Training loss: 2.878766122458958
Validation loss: 2.697708329622336

Epoch: 6| Step: 4
Training loss: 2.9141986395813
Validation loss: 2.698650417274866

Epoch: 6| Step: 5
Training loss: 2.6795934543844573
Validation loss: 2.696094209233206

Epoch: 6| Step: 6
Training loss: 3.2830931799984366
Validation loss: 2.695101722155029

Epoch: 6| Step: 7
Training loss: 3.4533721697279267
Validation loss: 2.6966068431328645

Epoch: 6| Step: 8
Training loss: 3.3413462332222554
Validation loss: 2.6910854688815844

Epoch: 6| Step: 9
Training loss: 2.8743315209809883
Validation loss: 2.6924855396393825

Epoch: 6| Step: 10
Training loss: 2.984691343467777
Validation loss: 2.6917683997574993

Epoch: 6| Step: 11
Training loss: 3.110638998934054
Validation loss: 2.689552569749367

Epoch: 6| Step: 12
Training loss: 3.0783483743704605
Validation loss: 2.686596410644921

Epoch: 6| Step: 13
Training loss: 3.1873593766851234
Validation loss: 2.69010741572308

Epoch: 57| Step: 0
Training loss: 3.3079264034216513
Validation loss: 2.6860958503458487

Epoch: 6| Step: 1
Training loss: 2.650252089116101
Validation loss: 2.6849567373042826

Epoch: 6| Step: 2
Training loss: 3.3340463034761747
Validation loss: 2.6829743175014813

Epoch: 6| Step: 3
Training loss: 2.939449880604522
Validation loss: 2.682561731566589

Epoch: 6| Step: 4
Training loss: 2.9562269601065214
Validation loss: 2.6854975987124505

Epoch: 6| Step: 5
Training loss: 3.1819497948215867
Validation loss: 2.6866535295083684

Epoch: 6| Step: 6
Training loss: 2.7790788040875367
Validation loss: 2.7077479888709104

Epoch: 6| Step: 7
Training loss: 3.7795159012759885
Validation loss: 2.7206964838633447

Epoch: 6| Step: 8
Training loss: 2.342514628035918
Validation loss: 2.6883502673062756

Epoch: 6| Step: 9
Training loss: 3.038752758255542
Validation loss: 2.6824677666500314

Epoch: 6| Step: 10
Training loss: 2.860016630964675
Validation loss: 2.6807685354566093

Epoch: 6| Step: 11
Training loss: 3.133677679443918
Validation loss: 2.6805981082872963

Epoch: 6| Step: 12
Training loss: 2.6820156115846325
Validation loss: 2.6818663665634586

Epoch: 6| Step: 13
Training loss: 3.1169171897307697
Validation loss: 2.682800290303567

Epoch: 58| Step: 0
Training loss: 3.3808785564158352
Validation loss: 2.6816798645694906

Epoch: 6| Step: 1
Training loss: 2.408888126168281
Validation loss: 2.684162589794867

Epoch: 6| Step: 2
Training loss: 2.960124123007074
Validation loss: 2.689085243644064

Epoch: 6| Step: 3
Training loss: 3.726260510890178
Validation loss: 2.687451657172599

Epoch: 6| Step: 4
Training loss: 3.4180001393647945
Validation loss: 2.6856028964556424

Epoch: 6| Step: 5
Training loss: 2.6755732768743816
Validation loss: 2.6799709457526957

Epoch: 6| Step: 6
Training loss: 3.422922052590855
Validation loss: 2.6771697387183515

Epoch: 6| Step: 7
Training loss: 2.93872661547198
Validation loss: 2.67334928331007

Epoch: 6| Step: 8
Training loss: 2.0027539842485247
Validation loss: 2.672998095035609

Epoch: 6| Step: 9
Training loss: 2.9438683488061317
Validation loss: 2.67125603823124

Epoch: 6| Step: 10
Training loss: 3.1218169213621305
Validation loss: 2.670381024838332

Epoch: 6| Step: 11
Training loss: 2.9823136325621937
Validation loss: 2.670872333508005

Epoch: 6| Step: 12
Training loss: 2.9840346536746276
Validation loss: 2.6693563304847756

Epoch: 6| Step: 13
Training loss: 2.881672289967681
Validation loss: 2.6721319461135042

Epoch: 59| Step: 0
Training loss: 2.9417983727153105
Validation loss: 2.6767238325922924

Epoch: 6| Step: 1
Training loss: 3.2725611858898938
Validation loss: 2.6788885510725855

Epoch: 6| Step: 2
Training loss: 3.3968985043495983
Validation loss: 2.6860484824879296

Epoch: 6| Step: 3
Training loss: 3.347040998970808
Validation loss: 2.6972758167535833

Epoch: 6| Step: 4
Training loss: 2.9183079778970247
Validation loss: 2.714060918740092

Epoch: 6| Step: 5
Training loss: 2.843037610374493
Validation loss: 2.6992592346499475

Epoch: 6| Step: 6
Training loss: 3.0859989981016165
Validation loss: 2.6842998024759916

Epoch: 6| Step: 7
Training loss: 3.216978011274621
Validation loss: 2.6795681670016824

Epoch: 6| Step: 8
Training loss: 2.9817822762926354
Validation loss: 2.6716578986126174

Epoch: 6| Step: 9
Training loss: 3.011707983727514
Validation loss: 2.668663397983266

Epoch: 6| Step: 10
Training loss: 2.9387225589744754
Validation loss: 2.6720592495459146

Epoch: 6| Step: 11
Training loss: 2.300996572784564
Validation loss: 2.6699730777677466

Epoch: 6| Step: 12
Training loss: 2.85421554263699
Validation loss: 2.6744302561697637

Epoch: 6| Step: 13
Training loss: 2.9675070318895562
Validation loss: 2.6731716152933007

Epoch: 60| Step: 0
Training loss: 3.5422727328067816
Validation loss: 2.6698081933950384

Epoch: 6| Step: 1
Training loss: 2.9957523474713947
Validation loss: 2.6743693677832194

Epoch: 6| Step: 2
Training loss: 2.831063445894524
Validation loss: 2.6813675611203194

Epoch: 6| Step: 3
Training loss: 2.6254958638100705
Validation loss: 2.6803680754411277

Epoch: 6| Step: 4
Training loss: 3.2726081034127734
Validation loss: 2.683873482036241

Epoch: 6| Step: 5
Training loss: 3.318520311356368
Validation loss: 2.680314338617828

Epoch: 6| Step: 6
Training loss: 3.5709042382220564
Validation loss: 2.6787783067137

Epoch: 6| Step: 7
Training loss: 2.0582324874616633
Validation loss: 2.679488326152344

Epoch: 6| Step: 8
Training loss: 3.0977673889465147
Validation loss: 2.6775913770739117

Epoch: 6| Step: 9
Training loss: 3.708522163183963
Validation loss: 2.6764603101278444

Epoch: 6| Step: 10
Training loss: 2.7296892398682386
Validation loss: 2.67157373251266

Epoch: 6| Step: 11
Training loss: 2.950509987407434
Validation loss: 2.671638497972068

Epoch: 6| Step: 12
Training loss: 2.8828009214918224
Validation loss: 2.6703994073917854

Epoch: 6| Step: 13
Training loss: 1.4701258931130907
Validation loss: 2.669591204338147

Epoch: 61| Step: 0
Training loss: 3.4790097656200656
Validation loss: 2.66236448846765

Epoch: 6| Step: 1
Training loss: 3.2147283521778163
Validation loss: 2.6603036273212943

Epoch: 6| Step: 2
Training loss: 3.308258219778267
Validation loss: 2.6614810372794495

Epoch: 6| Step: 3
Training loss: 3.3142990409179123
Validation loss: 2.6582926338138715

Epoch: 6| Step: 4
Training loss: 3.3607680160515163
Validation loss: 2.6609308778782794

Epoch: 6| Step: 5
Training loss: 2.460624650718271
Validation loss: 2.657641777418148

Epoch: 6| Step: 6
Training loss: 3.0953010755286705
Validation loss: 2.6604879772140655

Epoch: 6| Step: 7
Training loss: 2.9570156081880716
Validation loss: 2.6568011103644324

Epoch: 6| Step: 8
Training loss: 2.3808399478160434
Validation loss: 2.6563645378574607

Epoch: 6| Step: 9
Training loss: 2.4822107640981628
Validation loss: 2.657680867791413

Epoch: 6| Step: 10
Training loss: 2.874216719365109
Validation loss: 2.663456034481014

Epoch: 6| Step: 11
Training loss: 2.6992742198759494
Validation loss: 2.670605378764534

Epoch: 6| Step: 12
Training loss: 3.19314315017198
Validation loss: 2.6671020770183316

Epoch: 6| Step: 13
Training loss: 3.0349564063069496
Validation loss: 2.6673902912869694

Epoch: 62| Step: 0
Training loss: 2.6895621616309326
Validation loss: 2.660651499089094

Epoch: 6| Step: 1
Training loss: 2.5819830493208085
Validation loss: 2.667918066095479

Epoch: 6| Step: 2
Training loss: 3.6238884372591667
Validation loss: 2.661690351340362

Epoch: 6| Step: 3
Training loss: 2.9507060159793648
Validation loss: 2.655843216441336

Epoch: 6| Step: 4
Training loss: 2.3784904930978463
Validation loss: 2.651920849660216

Epoch: 6| Step: 5
Training loss: 3.296155516594324
Validation loss: 2.6505325775940243

Epoch: 6| Step: 6
Training loss: 3.5880057161215473
Validation loss: 2.6499098593530115

Epoch: 6| Step: 7
Training loss: 3.4877374274263966
Validation loss: 2.647495212618192

Epoch: 6| Step: 8
Training loss: 2.9066727853704792
Validation loss: 2.6476270024922988

Epoch: 6| Step: 9
Training loss: 2.782937555860594
Validation loss: 2.648191028620722

Epoch: 6| Step: 10
Training loss: 2.652921858021006
Validation loss: 2.645489462424749

Epoch: 6| Step: 11
Training loss: 3.28024131166354
Validation loss: 2.6443761201231526

Epoch: 6| Step: 12
Training loss: 2.696014931962859
Validation loss: 2.642575684155297

Epoch: 6| Step: 13
Training loss: 2.5837550793188595
Validation loss: 2.6498543497103406

Epoch: 63| Step: 0
Training loss: 2.842788701489852
Validation loss: 2.649717586333612

Epoch: 6| Step: 1
Training loss: 2.307553129400778
Validation loss: 2.6642459532804854

Epoch: 6| Step: 2
Training loss: 3.128274803880917
Validation loss: 2.6608533913244017

Epoch: 6| Step: 3
Training loss: 3.0985360165014444
Validation loss: 2.664487916465875

Epoch: 6| Step: 4
Training loss: 2.772821062380682
Validation loss: 2.6451328724010676

Epoch: 6| Step: 5
Training loss: 3.082744559357702
Validation loss: 2.645680147373997

Epoch: 6| Step: 6
Training loss: 3.442690450570912
Validation loss: 2.6464390861051683

Epoch: 6| Step: 7
Training loss: 2.5258353447305675
Validation loss: 2.646588251150193

Epoch: 6| Step: 8
Training loss: 3.423993573975995
Validation loss: 2.654035048420814

Epoch: 6| Step: 9
Training loss: 2.759230813636721
Validation loss: 2.6554339589201437

Epoch: 6| Step: 10
Training loss: 2.9972286139054645
Validation loss: 2.6615553144428064

Epoch: 6| Step: 11
Training loss: 3.3872841403779885
Validation loss: 2.6553564297455665

Epoch: 6| Step: 12
Training loss: 2.6504842675574554
Validation loss: 2.6505372956752113

Epoch: 6| Step: 13
Training loss: 3.522434675532819
Validation loss: 2.6517000234090125

Epoch: 64| Step: 0
Training loss: 3.1197291364225124
Validation loss: 2.6501270175521032

Epoch: 6| Step: 1
Training loss: 3.135086870221923
Validation loss: 2.6505053967175667

Epoch: 6| Step: 2
Training loss: 2.2411217898255895
Validation loss: 2.644988305765623

Epoch: 6| Step: 3
Training loss: 2.6576826831975016
Validation loss: 2.6444315508703964

Epoch: 6| Step: 4
Training loss: 2.45557121235424
Validation loss: 2.648902835972454

Epoch: 6| Step: 5
Training loss: 3.132016202034582
Validation loss: 2.6502194950837246

Epoch: 6| Step: 6
Training loss: 3.624260136309828
Validation loss: 2.6597388483057234

Epoch: 6| Step: 7
Training loss: 3.5479745378924585
Validation loss: 2.645473756806676

Epoch: 6| Step: 8
Training loss: 2.811936470372228
Validation loss: 2.638651512866968

Epoch: 6| Step: 9
Training loss: 2.7368494663062313
Validation loss: 2.6402352978673798

Epoch: 6| Step: 10
Training loss: 2.9923277341485655
Validation loss: 2.639307003723112

Epoch: 6| Step: 11
Training loss: 3.662056510035096
Validation loss: 2.637839676267287

Epoch: 6| Step: 12
Training loss: 2.6308309189603416
Validation loss: 2.6357048133629166

Epoch: 6| Step: 13
Training loss: 2.4518967973730588
Validation loss: 2.6346169631266125

Epoch: 65| Step: 0
Training loss: 2.892179164122239
Validation loss: 2.6336542235279414

Epoch: 6| Step: 1
Training loss: 3.1885625526785186
Validation loss: 2.6323996969699004

Epoch: 6| Step: 2
Training loss: 2.7281719365402775
Validation loss: 2.6297903070879967

Epoch: 6| Step: 3
Training loss: 2.9141325341366464
Validation loss: 2.638399824782949

Epoch: 6| Step: 4
Training loss: 3.377045470740688
Validation loss: 2.6363474142547783

Epoch: 6| Step: 5
Training loss: 3.0604585343923323
Validation loss: 2.6472481692989493

Epoch: 6| Step: 6
Training loss: 3.144655744090334
Validation loss: 2.6557715277573464

Epoch: 6| Step: 7
Training loss: 3.2816369691366822
Validation loss: 2.6491316778775067

Epoch: 6| Step: 8
Training loss: 3.0687295264281715
Validation loss: 2.627565547273478

Epoch: 6| Step: 9
Training loss: 3.225097027878913
Validation loss: 2.62967407752694

Epoch: 6| Step: 10
Training loss: 2.729060561663089
Validation loss: 2.630215265652149

Epoch: 6| Step: 11
Training loss: 2.5481056095496144
Validation loss: 2.6300414368807155

Epoch: 6| Step: 12
Training loss: 2.7586296102979726
Validation loss: 2.6324267025155454

Epoch: 6| Step: 13
Training loss: 2.622025121089846
Validation loss: 2.6332268554227283

Epoch: 66| Step: 0
Training loss: 2.68992815552815
Validation loss: 2.6337573305783497

Epoch: 6| Step: 1
Training loss: 2.965248854230803
Validation loss: 2.6372237431303414

Epoch: 6| Step: 2
Training loss: 2.9796850291473436
Validation loss: 2.6328869092189313

Epoch: 6| Step: 3
Training loss: 2.634652148744736
Validation loss: 2.634641416013351

Epoch: 6| Step: 4
Training loss: 2.960652762941788
Validation loss: 2.6318711719866985

Epoch: 6| Step: 5
Training loss: 2.8757208874043076
Validation loss: 2.634820604084813

Epoch: 6| Step: 6
Training loss: 3.007604497678032
Validation loss: 2.6329101328229974

Epoch: 6| Step: 7
Training loss: 3.228922943433892
Validation loss: 2.6341418840308064

Epoch: 6| Step: 8
Training loss: 3.0037984642662403
Validation loss: 2.636040231777409

Epoch: 6| Step: 9
Training loss: 3.1112539470520364
Validation loss: 2.6343326916367116

Epoch: 6| Step: 10
Training loss: 2.4760333437546365
Validation loss: 2.640363241077002

Epoch: 6| Step: 11
Training loss: 2.9526429766889404
Validation loss: 2.6413951609129858

Epoch: 6| Step: 12
Training loss: 3.094219441873471
Validation loss: 2.6392445794286874

Epoch: 6| Step: 13
Training loss: 4.102511515952806
Validation loss: 2.635841941024105

Epoch: 67| Step: 0
Training loss: 3.1778185551330878
Validation loss: 2.629142185651895

Epoch: 6| Step: 1
Training loss: 3.63177606708181
Validation loss: 2.625873895824698

Epoch: 6| Step: 2
Training loss: 3.005547797975931
Validation loss: 2.6255893133666417

Epoch: 6| Step: 3
Training loss: 2.365250704745962
Validation loss: 2.62438145492478

Epoch: 6| Step: 4
Training loss: 3.103326329579493
Validation loss: 2.6235328066429617

Epoch: 6| Step: 5
Training loss: 2.648133116928672
Validation loss: 2.621078558409946

Epoch: 6| Step: 6
Training loss: 3.417955078097656
Validation loss: 2.6213238196426873

Epoch: 6| Step: 7
Training loss: 3.257055839652545
Validation loss: 2.6184772886805923

Epoch: 6| Step: 8
Training loss: 2.972953631129601
Validation loss: 2.6209347797147964

Epoch: 6| Step: 9
Training loss: 2.960927837426516
Validation loss: 2.618036299574188

Epoch: 6| Step: 10
Training loss: 2.9855607957426833
Validation loss: 2.6162952394095234

Epoch: 6| Step: 11
Training loss: 2.54237989413916
Validation loss: 2.6157637966264895

Epoch: 6| Step: 12
Training loss: 2.5644040360876703
Validation loss: 2.6142460320687833

Epoch: 6| Step: 13
Training loss: 2.4539011316692383
Validation loss: 2.6159260182532322

Epoch: 68| Step: 0
Training loss: 1.9229139915549647
Validation loss: 2.6161398992343985

Epoch: 6| Step: 1
Training loss: 2.7584217468413463
Validation loss: 2.6148722659379158

Epoch: 6| Step: 2
Training loss: 3.2520141229264197
Validation loss: 2.6155005983823516

Epoch: 6| Step: 3
Training loss: 3.0002962601926133
Validation loss: 2.618804589768475

Epoch: 6| Step: 4
Training loss: 2.734350411440784
Validation loss: 2.6197632169714904

Epoch: 6| Step: 5
Training loss: 2.999306598637731
Validation loss: 2.62187416551559

Epoch: 6| Step: 6
Training loss: 2.7266676043607534
Validation loss: 2.633689387938995

Epoch: 6| Step: 7
Training loss: 3.3238893876934434
Validation loss: 2.6305791823484856

Epoch: 6| Step: 8
Training loss: 2.9237244000889997
Validation loss: 2.6233852017618746

Epoch: 6| Step: 9
Training loss: 3.889272554333534
Validation loss: 2.6160373570830315

Epoch: 6| Step: 10
Training loss: 2.9929963057087674
Validation loss: 2.6130086185555292

Epoch: 6| Step: 11
Training loss: 2.7778757607874773
Validation loss: 2.612937165529449

Epoch: 6| Step: 12
Training loss: 2.779592041297813
Validation loss: 2.6133456423412866

Epoch: 6| Step: 13
Training loss: 3.0943005004618094
Validation loss: 2.6124470776390956

Epoch: 69| Step: 0
Training loss: 3.513596284232407
Validation loss: 2.6106324649157

Epoch: 6| Step: 1
Training loss: 2.4393168793893363
Validation loss: 2.612223015529076

Epoch: 6| Step: 2
Training loss: 2.90910215809121
Validation loss: 2.6139364131445024

Epoch: 6| Step: 3
Training loss: 2.8612624645836586
Validation loss: 2.610155669296428

Epoch: 6| Step: 4
Training loss: 3.0566063047194647
Validation loss: 2.6085248199136695

Epoch: 6| Step: 5
Training loss: 3.0990710497106684
Validation loss: 2.6087424504046206

Epoch: 6| Step: 6
Training loss: 3.301495825712161
Validation loss: 2.6091004295282874

Epoch: 6| Step: 7
Training loss: 2.7186293301166145
Validation loss: 2.6077726102355365

Epoch: 6| Step: 8
Training loss: 2.6813757557933022
Validation loss: 2.6060181432838854

Epoch: 6| Step: 9
Training loss: 3.1548745963781304
Validation loss: 2.6091632694483455

Epoch: 6| Step: 10
Training loss: 2.8060021679707403
Validation loss: 2.607587085255534

Epoch: 6| Step: 11
Training loss: 3.2543426257699606
Validation loss: 2.6081230722276354

Epoch: 6| Step: 12
Training loss: 2.479421896311898
Validation loss: 2.6084541944504656

Epoch: 6| Step: 13
Training loss: 3.07237737201413
Validation loss: 2.60585047145064

Epoch: 70| Step: 0
Training loss: 3.824152414995411
Validation loss: 2.6061219059655008

Epoch: 6| Step: 1
Training loss: 2.9462419657219354
Validation loss: 2.6083077265886585

Epoch: 6| Step: 2
Training loss: 2.415861477941777
Validation loss: 2.6058031895025455

Epoch: 6| Step: 3
Training loss: 2.8627769369567524
Validation loss: 2.6053378415474233

Epoch: 6| Step: 4
Training loss: 2.6735888778840993
Validation loss: 2.604271540017

Epoch: 6| Step: 5
Training loss: 2.363264704874936
Validation loss: 2.6057979949291017

Epoch: 6| Step: 6
Training loss: 2.9356914390759576
Validation loss: 2.60485812419053

Epoch: 6| Step: 7
Training loss: 3.4139479698681403
Validation loss: 2.603747788406862

Epoch: 6| Step: 8
Training loss: 2.8356265903844275
Validation loss: 2.6049749275975334

Epoch: 6| Step: 9
Training loss: 2.9075245677274126
Validation loss: 2.6046163440617307

Epoch: 6| Step: 10
Training loss: 3.016725803729954
Validation loss: 2.602928429026417

Epoch: 6| Step: 11
Training loss: 2.9741249015557014
Validation loss: 2.6018303499200366

Epoch: 6| Step: 12
Training loss: 2.7099295289565006
Validation loss: 2.602219759438962

Epoch: 6| Step: 13
Training loss: 3.3981647250442637
Validation loss: 2.6024823011188722

Epoch: 71| Step: 0
Training loss: 2.735682670712231
Validation loss: 2.6034077240262055

Epoch: 6| Step: 1
Training loss: 3.154013266081357
Validation loss: 2.600621335131017

Epoch: 6| Step: 2
Training loss: 2.8267305424358713
Validation loss: 2.6024268910370507

Epoch: 6| Step: 3
Training loss: 2.6769006768241406
Validation loss: 2.6055917895459952

Epoch: 6| Step: 4
Training loss: 2.799652595766557
Validation loss: 2.6048453200203787

Epoch: 6| Step: 5
Training loss: 3.047908353413952
Validation loss: 2.606236219169275

Epoch: 6| Step: 6
Training loss: 2.5923459032808642
Validation loss: 2.6101099140768524

Epoch: 6| Step: 7
Training loss: 2.64520309231005
Validation loss: 2.600982231768572

Epoch: 6| Step: 8
Training loss: 3.0247517570593287
Validation loss: 2.600829274162552

Epoch: 6| Step: 9
Training loss: 3.610367015241139
Validation loss: 2.595038821129793

Epoch: 6| Step: 10
Training loss: 3.120306228379244
Validation loss: 2.595142164350875

Epoch: 6| Step: 11
Training loss: 2.82030015768378
Validation loss: 2.5895821197868334

Epoch: 6| Step: 12
Training loss: 3.086704902357179
Validation loss: 2.591976000423357

Epoch: 6| Step: 13
Training loss: 3.1316163783343973
Validation loss: 2.5911831777281518

Epoch: 72| Step: 0
Training loss: 3.229285322080762
Validation loss: 2.5915579618298152

Epoch: 6| Step: 1
Training loss: 2.717619562264939
Validation loss: 2.5904678035585924

Epoch: 6| Step: 2
Training loss: 2.9436691111083393
Validation loss: 2.5869615212175696

Epoch: 6| Step: 3
Training loss: 2.8589003538984192
Validation loss: 2.5876113891404335

Epoch: 6| Step: 4
Training loss: 2.7566941022449427
Validation loss: 2.5882687582746735

Epoch: 6| Step: 5
Training loss: 2.7773937966603324
Validation loss: 2.5857056956027065

Epoch: 6| Step: 6
Training loss: 3.2138622913305914
Validation loss: 2.5853405602917516

Epoch: 6| Step: 7
Training loss: 2.779885117880903
Validation loss: 2.5894941890501433

Epoch: 6| Step: 8
Training loss: 2.3628898864028542
Validation loss: 2.5949204817597735

Epoch: 6| Step: 9
Training loss: 2.9955239282530073
Validation loss: 2.6134642391895424

Epoch: 6| Step: 10
Training loss: 3.194741494193494
Validation loss: 2.610153100896528

Epoch: 6| Step: 11
Training loss: 2.711938942399151
Validation loss: 2.622340659581197

Epoch: 6| Step: 12
Training loss: 3.3217069682043276
Validation loss: 2.614776835242636

Epoch: 6| Step: 13
Training loss: 3.491473575129859
Validation loss: 2.6229345973082703

Epoch: 73| Step: 0
Training loss: 2.8902661899878384
Validation loss: 2.602710962477798

Epoch: 6| Step: 1
Training loss: 3.6074571674894487
Validation loss: 2.5905594360346966

Epoch: 6| Step: 2
Training loss: 2.117929026119661
Validation loss: 2.588890180641433

Epoch: 6| Step: 3
Training loss: 3.2596395295601166
Validation loss: 2.588150272790937

Epoch: 6| Step: 4
Training loss: 2.9812506653726984
Validation loss: 2.5893745369141117

Epoch: 6| Step: 5
Training loss: 2.2330642803829597
Validation loss: 2.589294319880093

Epoch: 6| Step: 6
Training loss: 2.677655397637514
Validation loss: 2.5927938563817783

Epoch: 6| Step: 7
Training loss: 2.999598476242572
Validation loss: 2.592793714989658

Epoch: 6| Step: 8
Training loss: 2.5378356786730305
Validation loss: 2.5933467740838516

Epoch: 6| Step: 9
Training loss: 2.911433693514829
Validation loss: 2.599106597830685

Epoch: 6| Step: 10
Training loss: 3.078789189128374
Validation loss: 2.599259211990612

Epoch: 6| Step: 11
Training loss: 3.2474416787165
Validation loss: 2.5950190511859272

Epoch: 6| Step: 12
Training loss: 3.1522614611316646
Validation loss: 2.5924538809729634

Epoch: 6| Step: 13
Training loss: 3.504144530768828
Validation loss: 2.591065004600686

Epoch: 74| Step: 0
Training loss: 3.0363792204106526
Validation loss: 2.595100790412109

Epoch: 6| Step: 1
Training loss: 2.617649504464388
Validation loss: 2.604449154862872

Epoch: 6| Step: 2
Training loss: 2.9876547162842213
Validation loss: 2.6132577823052583

Epoch: 6| Step: 3
Training loss: 3.322873696235723
Validation loss: 2.6132910894564945

Epoch: 6| Step: 4
Training loss: 2.863218798613356
Validation loss: 2.612973390695772

Epoch: 6| Step: 5
Training loss: 3.042536380396724
Validation loss: 2.607977671001137

Epoch: 6| Step: 6
Training loss: 3.1247044232773638
Validation loss: 2.6008047162859653

Epoch: 6| Step: 7
Training loss: 2.384101694024643
Validation loss: 2.596445174077666

Epoch: 6| Step: 8
Training loss: 2.4033199156846483
Validation loss: 2.59455062384149

Epoch: 6| Step: 9
Training loss: 3.0381592337369376
Validation loss: 2.588801936745384

Epoch: 6| Step: 10
Training loss: 3.230167324113793
Validation loss: 2.593588992934679

Epoch: 6| Step: 11
Training loss: 2.6658680633956937
Validation loss: 2.5942916373770046

Epoch: 6| Step: 12
Training loss: 3.4920995645737944
Validation loss: 2.591799527367905

Epoch: 6| Step: 13
Training loss: 2.6495325755895336
Validation loss: 2.586205261205435

Epoch: 75| Step: 0
Training loss: 2.860201690071129
Validation loss: 2.5850939131702932

Epoch: 6| Step: 1
Training loss: 2.8463418069741566
Validation loss: 2.583677022567445

Epoch: 6| Step: 2
Training loss: 3.1096823075605453
Validation loss: 2.585127388817945

Epoch: 6| Step: 3
Training loss: 2.60447204833796
Validation loss: 2.5879278456522097

Epoch: 6| Step: 4
Training loss: 2.526964869687887
Validation loss: 2.5880791656235096

Epoch: 6| Step: 5
Training loss: 2.878776060807156
Validation loss: 2.5856273497226017

Epoch: 6| Step: 6
Training loss: 3.803690252872192
Validation loss: 2.5874657993118197

Epoch: 6| Step: 7
Training loss: 2.720233468666606
Validation loss: 2.584879122601231

Epoch: 6| Step: 8
Training loss: 2.78490011313453
Validation loss: 2.5840528804604412

Epoch: 6| Step: 9
Training loss: 3.069267891188128
Validation loss: 2.5816533023973416

Epoch: 6| Step: 10
Training loss: 2.897556386930528
Validation loss: 2.5815734114825335

Epoch: 6| Step: 11
Training loss: 3.263481495279503
Validation loss: 2.579566124703861

Epoch: 6| Step: 12
Training loss: 2.816885686481282
Validation loss: 2.5794204514957775

Epoch: 6| Step: 13
Training loss: 2.72767952933929
Validation loss: 2.577471249283183

Epoch: 76| Step: 0
Training loss: 3.0021961438922284
Validation loss: 2.5775917225101117

Epoch: 6| Step: 1
Training loss: 2.663156304935293
Validation loss: 2.578156157771741

Epoch: 6| Step: 2
Training loss: 3.3172458264420013
Validation loss: 2.578387871320879

Epoch: 6| Step: 3
Training loss: 2.65343892067896
Validation loss: 2.576936867530344

Epoch: 6| Step: 4
Training loss: 2.9450024509905477
Validation loss: 2.574875989843501

Epoch: 6| Step: 5
Training loss: 3.073783329879549
Validation loss: 2.5745468810635486

Epoch: 6| Step: 6
Training loss: 2.5914126976008878
Validation loss: 2.5752252693055766

Epoch: 6| Step: 7
Training loss: 3.0534871662595404
Validation loss: 2.577271601590826

Epoch: 6| Step: 8
Training loss: 3.0402864085350334
Validation loss: 2.583925425118314

Epoch: 6| Step: 9
Training loss: 2.9169488679512687
Validation loss: 2.5929511449023193

Epoch: 6| Step: 10
Training loss: 3.1727731119110185
Validation loss: 2.594218271493002

Epoch: 6| Step: 11
Training loss: 2.624423644961156
Validation loss: 2.585329396761101

Epoch: 6| Step: 12
Training loss: 2.5134204184456723
Validation loss: 2.5774934325106633

Epoch: 6| Step: 13
Training loss: 3.5327902616453017
Validation loss: 2.5758403242021

Epoch: 77| Step: 0
Training loss: 2.6592172542276202
Validation loss: 2.5741095477653153

Epoch: 6| Step: 1
Training loss: 3.0321348806087274
Validation loss: 2.573199017819071

Epoch: 6| Step: 2
Training loss: 3.331846779907911
Validation loss: 2.5747993117445147

Epoch: 6| Step: 3
Training loss: 2.621413187269163
Validation loss: 2.5753741362800806

Epoch: 6| Step: 4
Training loss: 3.333704037716003
Validation loss: 2.576400948041947

Epoch: 6| Step: 5
Training loss: 3.2574461220935467
Validation loss: 2.5760761600739

Epoch: 6| Step: 6
Training loss: 2.809664929188665
Validation loss: 2.578988126107962

Epoch: 6| Step: 7
Training loss: 2.833217020078294
Validation loss: 2.5820025219236844

Epoch: 6| Step: 8
Training loss: 2.5149916331339726
Validation loss: 2.583163506572014

Epoch: 6| Step: 9
Training loss: 3.064324283261855
Validation loss: 2.580833613657099

Epoch: 6| Step: 10
Training loss: 3.0026459151996976
Validation loss: 2.579055349785338

Epoch: 6| Step: 11
Training loss: 3.0594139899320574
Validation loss: 2.578302043604531

Epoch: 6| Step: 12
Training loss: 3.006810088137914
Validation loss: 2.577250437036133

Epoch: 6| Step: 13
Training loss: 2.1673358715179014
Validation loss: 2.577419372628258

Epoch: 78| Step: 0
Training loss: 3.126518033391549
Validation loss: 2.577355273339804

Epoch: 6| Step: 1
Training loss: 2.9357560845277657
Validation loss: 2.5767915441261446

Epoch: 6| Step: 2
Training loss: 3.1560584283987514
Validation loss: 2.5783663719052208

Epoch: 6| Step: 3
Training loss: 2.6162475720069436
Validation loss: 2.5838812343962427

Epoch: 6| Step: 4
Training loss: 2.835122235604721
Validation loss: 2.5896971046758686

Epoch: 6| Step: 5
Training loss: 2.6522795679251283
Validation loss: 2.5946529421410105

Epoch: 6| Step: 6
Training loss: 3.6307519462825564
Validation loss: 2.593519912993347

Epoch: 6| Step: 7
Training loss: 2.8465659483602797
Validation loss: 2.5792029112776094

Epoch: 6| Step: 8
Training loss: 2.511616991037441
Validation loss: 2.572365760154466

Epoch: 6| Step: 9
Training loss: 3.2464094134743724
Validation loss: 2.566950754771885

Epoch: 6| Step: 10
Training loss: 3.131615312475661
Validation loss: 2.5644647023046865

Epoch: 6| Step: 11
Training loss: 2.3773904114505533
Validation loss: 2.56053769390396

Epoch: 6| Step: 12
Training loss: 2.790495688591781
Validation loss: 2.5592835752083087

Epoch: 6| Step: 13
Training loss: 3.0230493419581452
Validation loss: 2.5588656328223496

Epoch: 79| Step: 0
Training loss: 2.6901884604311124
Validation loss: 2.557701903145453

Epoch: 6| Step: 1
Training loss: 2.9539905066934886
Validation loss: 2.568395552155621

Epoch: 6| Step: 2
Training loss: 2.8752648604751703
Validation loss: 2.5753329375112664

Epoch: 6| Step: 3
Training loss: 3.049469141803859
Validation loss: 2.5934265257227205

Epoch: 6| Step: 4
Training loss: 3.461797809666562
Validation loss: 2.589881380104421

Epoch: 6| Step: 5
Training loss: 2.7398355945632202
Validation loss: 2.6341478081091925

Epoch: 6| Step: 6
Training loss: 2.904268963698262
Validation loss: 2.665433029830961

Epoch: 6| Step: 7
Training loss: 3.3350337142040902
Validation loss: 2.674946480193503

Epoch: 6| Step: 8
Training loss: 2.971482314551261
Validation loss: 2.59235854470279

Epoch: 6| Step: 9
Training loss: 2.9494895558098766
Validation loss: 2.5874853297317006

Epoch: 6| Step: 10
Training loss: 2.347330131031652
Validation loss: 2.584252485393444

Epoch: 6| Step: 11
Training loss: 3.1625875166894932
Validation loss: 2.585100308643171

Epoch: 6| Step: 12
Training loss: 3.2927440055275325
Validation loss: 2.586644759164149

Epoch: 6| Step: 13
Training loss: 2.3104887799451
Validation loss: 2.5972471603577607

Epoch: 80| Step: 0
Training loss: 3.005780690571828
Validation loss: 2.597645336778631

Epoch: 6| Step: 1
Training loss: 3.1699685065693637
Validation loss: 2.6001650268016356

Epoch: 6| Step: 2
Training loss: 2.6356434077451616
Validation loss: 2.5983913538960124

Epoch: 6| Step: 3
Training loss: 3.4194653531497585
Validation loss: 2.582148961875897

Epoch: 6| Step: 4
Training loss: 2.658246983846709
Validation loss: 2.577525515945004

Epoch: 6| Step: 5
Training loss: 2.2362722598098643
Validation loss: 2.5742066090672653

Epoch: 6| Step: 6
Training loss: 3.1566412654876532
Validation loss: 2.5955517744171623

Epoch: 6| Step: 7
Training loss: 3.4278878115142035
Validation loss: 2.6247947620450534

Epoch: 6| Step: 8
Training loss: 3.5149363203507122
Validation loss: 2.6616345711194334

Epoch: 6| Step: 9
Training loss: 2.753799414760603
Validation loss: 2.668665081034407

Epoch: 6| Step: 10
Training loss: 3.347848109975759
Validation loss: 2.6631766279536917

Epoch: 6| Step: 11
Training loss: 2.471204479147525
Validation loss: 2.6632003430797666

Epoch: 6| Step: 12
Training loss: 2.4436091623918483
Validation loss: 2.6377437333329774

Epoch: 6| Step: 13
Training loss: 2.733219970895456
Validation loss: 2.6258208983098412

Epoch: 81| Step: 0
Training loss: 2.9477140718719173
Validation loss: 2.5874162562608594

Epoch: 6| Step: 1
Training loss: 2.797560112437736
Validation loss: 2.5759704476764944

Epoch: 6| Step: 2
Training loss: 3.172729377119872
Validation loss: 2.5684506843063546

Epoch: 6| Step: 3
Training loss: 2.743635789584002
Validation loss: 2.555935422454223

Epoch: 6| Step: 4
Training loss: 3.0811388781088476
Validation loss: 2.551664102428357

Epoch: 6| Step: 5
Training loss: 3.00564156003988
Validation loss: 2.5525601217684244

Epoch: 6| Step: 6
Training loss: 3.0087572075662785
Validation loss: 2.551668247790852

Epoch: 6| Step: 7
Training loss: 3.3321568956197676
Validation loss: 2.5502398511413955

Epoch: 6| Step: 8
Training loss: 2.2524935362592924
Validation loss: 2.5506497057909643

Epoch: 6| Step: 9
Training loss: 3.050702786382955
Validation loss: 2.5472860572677423

Epoch: 6| Step: 10
Training loss: 3.036425390222955
Validation loss: 2.550469776708583

Epoch: 6| Step: 11
Training loss: 2.544627315311247
Validation loss: 2.548320979592057

Epoch: 6| Step: 12
Training loss: 2.925035042838129
Validation loss: 2.5479837401546384

Epoch: 6| Step: 13
Training loss: 2.6736836697419397
Validation loss: 2.547812695831473

Epoch: 82| Step: 0
Training loss: 2.7409091154087295
Validation loss: 2.5459272185233868

Epoch: 6| Step: 1
Training loss: 2.568997960061243
Validation loss: 2.54674308793085

Epoch: 6| Step: 2
Training loss: 3.452657124164086
Validation loss: 2.5511392125719135

Epoch: 6| Step: 3
Training loss: 2.4823506102698563
Validation loss: 2.5467689472451425

Epoch: 6| Step: 4
Training loss: 2.588254507141404
Validation loss: 2.550223803204628

Epoch: 6| Step: 5
Training loss: 3.10926228227894
Validation loss: 2.5553107558678922

Epoch: 6| Step: 6
Training loss: 2.763782986944847
Validation loss: 2.56231823668486

Epoch: 6| Step: 7
Training loss: 3.1519059606359425
Validation loss: 2.58112956578049

Epoch: 6| Step: 8
Training loss: 2.766029543842301
Validation loss: 2.591176560808665

Epoch: 6| Step: 9
Training loss: 2.6062030815457
Validation loss: 2.5830948614059364

Epoch: 6| Step: 10
Training loss: 3.4185274375985006
Validation loss: 2.579662955357357

Epoch: 6| Step: 11
Training loss: 2.882016782861324
Validation loss: 2.569930654314551

Epoch: 6| Step: 12
Training loss: 3.1761310755396712
Validation loss: 2.5697858884174405

Epoch: 6| Step: 13
Training loss: 3.023448224504558
Validation loss: 2.5458276184038295

Epoch: 83| Step: 0
Training loss: 2.8174361251996607
Validation loss: 2.5444781254993716

Epoch: 6| Step: 1
Training loss: 3.0739175147243465
Validation loss: 2.5444975959617957

Epoch: 6| Step: 2
Training loss: 2.7082946383328497
Validation loss: 2.547377406396046

Epoch: 6| Step: 3
Training loss: 2.4461009549059494
Validation loss: 2.55030944598624

Epoch: 6| Step: 4
Training loss: 3.2428571997535083
Validation loss: 2.553621899083073

Epoch: 6| Step: 5
Training loss: 3.5017137419053865
Validation loss: 2.554607748238285

Epoch: 6| Step: 6
Training loss: 2.81647177102834
Validation loss: 2.5596558949517787

Epoch: 6| Step: 7
Training loss: 2.7814652434650786
Validation loss: 2.5569615993257115

Epoch: 6| Step: 8
Training loss: 3.4299914110259686
Validation loss: 2.556547603317021

Epoch: 6| Step: 9
Training loss: 3.117777603625529
Validation loss: 2.5516462780966496

Epoch: 6| Step: 10
Training loss: 2.6795556394648337
Validation loss: 2.554365077712782

Epoch: 6| Step: 11
Training loss: 2.995971518041195
Validation loss: 2.552501403304258

Epoch: 6| Step: 12
Training loss: 2.3979752185167813
Validation loss: 2.5558163648531607

Epoch: 6| Step: 13
Training loss: 2.351668751492873
Validation loss: 2.5640890845274966

Epoch: 84| Step: 0
Training loss: 3.2153109353545797
Validation loss: 2.576587896703764

Epoch: 6| Step: 1
Training loss: 3.254773961904393
Validation loss: 2.5898276208066497

Epoch: 6| Step: 2
Training loss: 2.4321514037462038
Validation loss: 2.5949040679773385

Epoch: 6| Step: 3
Training loss: 2.1501104326497074
Validation loss: 2.5935700728881637

Epoch: 6| Step: 4
Training loss: 3.386264088524976
Validation loss: 2.5932723657096823

Epoch: 6| Step: 5
Training loss: 2.9935137247331967
Validation loss: 2.5697524992365612

Epoch: 6| Step: 6
Training loss: 3.049541069898799
Validation loss: 2.5580660919289397

Epoch: 6| Step: 7
Training loss: 2.8593686630095423
Validation loss: 2.5491014537005676

Epoch: 6| Step: 8
Training loss: 2.609076203010881
Validation loss: 2.546775372522768

Epoch: 6| Step: 9
Training loss: 3.3632160317791087
Validation loss: 2.54516935204138

Epoch: 6| Step: 10
Training loss: 2.6781125792812905
Validation loss: 2.5444855731577554

Epoch: 6| Step: 11
Training loss: 3.112690293956157
Validation loss: 2.5451528581481946

Epoch: 6| Step: 12
Training loss: 2.5936987079006926
Validation loss: 2.537719508703473

Epoch: 6| Step: 13
Training loss: 2.7871024459827587
Validation loss: 2.539005751310874

Epoch: 85| Step: 0
Training loss: 2.753652747640821
Validation loss: 2.5386053433873066

Epoch: 6| Step: 1
Training loss: 2.9644844329986304
Validation loss: 2.53816757598297

Epoch: 6| Step: 2
Training loss: 2.616064029796596
Validation loss: 2.5376170607994633

Epoch: 6| Step: 3
Training loss: 2.4774725652844394
Validation loss: 2.5350102061598783

Epoch: 6| Step: 4
Training loss: 3.20177256247365
Validation loss: 2.5386569346841963

Epoch: 6| Step: 5
Training loss: 2.8568868181764073
Validation loss: 2.5359633910119252

Epoch: 6| Step: 6
Training loss: 3.1412592764556933
Validation loss: 2.5365496856483776

Epoch: 6| Step: 7
Training loss: 2.146210004714911
Validation loss: 2.5340633994994635

Epoch: 6| Step: 8
Training loss: 3.097062928380473
Validation loss: 2.5453185839283714

Epoch: 6| Step: 9
Training loss: 3.152816566829911
Validation loss: 2.5399079642215683

Epoch: 6| Step: 10
Training loss: 2.5935685427514166
Validation loss: 2.5388006976810105

Epoch: 6| Step: 11
Training loss: 3.36432286879225
Validation loss: 2.5347276884694216

Epoch: 6| Step: 12
Training loss: 2.9209736948575564
Validation loss: 2.5398795671812615

Epoch: 6| Step: 13
Training loss: 3.366969125840086
Validation loss: 2.5527297704069682

Epoch: 86| Step: 0
Training loss: 3.290302106442531
Validation loss: 2.559134280125261

Epoch: 6| Step: 1
Training loss: 3.0400839219305067
Validation loss: 2.5593966649166595

Epoch: 6| Step: 2
Training loss: 2.6957682790871456
Validation loss: 2.554964931878223

Epoch: 6| Step: 3
Training loss: 3.084930487395226
Validation loss: 2.548738097246081

Epoch: 6| Step: 4
Training loss: 2.817825023517106
Validation loss: 2.534780930383177

Epoch: 6| Step: 5
Training loss: 2.7349603516879686
Validation loss: 2.534954360878255

Epoch: 6| Step: 6
Training loss: 3.2514441289440943
Validation loss: 2.533718949875037

Epoch: 6| Step: 7
Training loss: 2.2746941413263615
Validation loss: 2.5361081335767626

Epoch: 6| Step: 8
Training loss: 2.9883994883164497
Validation loss: 2.5361834634838796

Epoch: 6| Step: 9
Training loss: 3.232658778610985
Validation loss: 2.5388538683169997

Epoch: 6| Step: 10
Training loss: 2.8308463307792473
Validation loss: 2.5385098642051442

Epoch: 6| Step: 11
Training loss: 2.723072956000252
Validation loss: 2.538716072826891

Epoch: 6| Step: 12
Training loss: 2.9350309343673637
Validation loss: 2.538979272732577

Epoch: 6| Step: 13
Training loss: 2.599092244359546
Validation loss: 2.5392461097280568

Epoch: 87| Step: 0
Training loss: 2.279815327209197
Validation loss: 2.5359965720217095

Epoch: 6| Step: 1
Training loss: 3.38180858348741
Validation loss: 2.5376478137893126

Epoch: 6| Step: 2
Training loss: 2.7625888171525363
Validation loss: 2.542697212076719

Epoch: 6| Step: 3
Training loss: 2.94594609657588
Validation loss: 2.5438417820304604

Epoch: 6| Step: 4
Training loss: 3.037286783906062
Validation loss: 2.5469879602460543

Epoch: 6| Step: 5
Training loss: 2.3580132400878684
Validation loss: 2.5533973195870963

Epoch: 6| Step: 6
Training loss: 3.5061725954701766
Validation loss: 2.5538840200544177

Epoch: 6| Step: 7
Training loss: 3.1340661335036955
Validation loss: 2.5528172863815333

Epoch: 6| Step: 8
Training loss: 2.3436751290124582
Validation loss: 2.5399112960636296

Epoch: 6| Step: 9
Training loss: 3.0576472858128154
Validation loss: 2.538871170546621

Epoch: 6| Step: 10
Training loss: 2.8812183634909863
Validation loss: 2.536878044510742

Epoch: 6| Step: 11
Training loss: 3.0086511805066993
Validation loss: 2.5363312955362938

Epoch: 6| Step: 12
Training loss: 2.1318603178719266
Validation loss: 2.5342838443378484

Epoch: 6| Step: 13
Training loss: 3.712088380336952
Validation loss: 2.5328814223139466

Epoch: 88| Step: 0
Training loss: 2.9432485619070587
Validation loss: 2.533760752941211

Epoch: 6| Step: 1
Training loss: 2.4499745153541923
Validation loss: 2.532978778570515

Epoch: 6| Step: 2
Training loss: 2.963992352175917
Validation loss: 2.5334631515478083

Epoch: 6| Step: 3
Training loss: 2.9106782381063923
Validation loss: 2.5331282276672735

Epoch: 6| Step: 4
Training loss: 3.2994549676880376
Validation loss: 2.5376687727066676

Epoch: 6| Step: 5
Training loss: 3.3381780385694677
Validation loss: 2.533122012689175

Epoch: 6| Step: 6
Training loss: 3.221536855777808
Validation loss: 2.5295557291662383

Epoch: 6| Step: 7
Training loss: 2.787655943199198
Validation loss: 2.528800697958159

Epoch: 6| Step: 8
Training loss: 2.6599811154605844
Validation loss: 2.5245764256972865

Epoch: 6| Step: 9
Training loss: 2.9398557266855097
Validation loss: 2.526753421970158

Epoch: 6| Step: 10
Training loss: 2.7060323966907154
Validation loss: 2.5248275621604326

Epoch: 6| Step: 11
Training loss: 2.967063987214235
Validation loss: 2.526058271476349

Epoch: 6| Step: 12
Training loss: 2.4969811332212917
Validation loss: 2.525342409156953

Epoch: 6| Step: 13
Training loss: 2.501516645060091
Validation loss: 2.5275688035047885

Epoch: 89| Step: 0
Training loss: 2.8136351096152845
Validation loss: 2.5342199640351115

Epoch: 6| Step: 1
Training loss: 3.301110173376529
Validation loss: 2.530769911307176

Epoch: 6| Step: 2
Training loss: 2.864424951972203
Validation loss: 2.524228225246247

Epoch: 6| Step: 3
Training loss: 2.618748441345188
Validation loss: 2.524058481045611

Epoch: 6| Step: 4
Training loss: 2.9579941102872636
Validation loss: 2.5227082613265717

Epoch: 6| Step: 5
Training loss: 3.095806940786848
Validation loss: 2.520885641568398

Epoch: 6| Step: 6
Training loss: 2.8177942249982686
Validation loss: 2.5217049038704342

Epoch: 6| Step: 7
Training loss: 3.084907301834706
Validation loss: 2.5219224116093772

Epoch: 6| Step: 8
Training loss: 2.7900513677756296
Validation loss: 2.5226186743709182

Epoch: 6| Step: 9
Training loss: 3.1123742442023454
Validation loss: 2.526330867171877

Epoch: 6| Step: 10
Training loss: 2.856256838066213
Validation loss: 2.5263119944393906

Epoch: 6| Step: 11
Training loss: 2.4440052572340543
Validation loss: 2.533518410929181

Epoch: 6| Step: 12
Training loss: 2.967445167092755
Validation loss: 2.523744501022786

Epoch: 6| Step: 13
Training loss: 2.564815591500118
Validation loss: 2.520520923049265

Epoch: 90| Step: 0
Training loss: 3.6642972631014867
Validation loss: 2.517970169121606

Epoch: 6| Step: 1
Training loss: 2.7914755077295426
Validation loss: 2.5211938410242807

Epoch: 6| Step: 2
Training loss: 2.450505796110019
Validation loss: 2.5247682474600053

Epoch: 6| Step: 3
Training loss: 2.764656198936032
Validation loss: 2.5252697395152506

Epoch: 6| Step: 4
Training loss: 3.2938571514384214
Validation loss: 2.524728752292006

Epoch: 6| Step: 5
Training loss: 2.791660925636272
Validation loss: 2.526006556830293

Epoch: 6| Step: 6
Training loss: 3.1617779054379245
Validation loss: 2.525250567489218

Epoch: 6| Step: 7
Training loss: 2.852055086414423
Validation loss: 2.5275343880291365

Epoch: 6| Step: 8
Training loss: 2.7403506134024163
Validation loss: 2.5270016840951017

Epoch: 6| Step: 9
Training loss: 2.6014632472445034
Validation loss: 2.525884176372047

Epoch: 6| Step: 10
Training loss: 3.069757853100528
Validation loss: 2.5267552675244462

Epoch: 6| Step: 11
Training loss: 2.807550950305624
Validation loss: 2.5258967962017014

Epoch: 6| Step: 12
Training loss: 2.664140269467193
Validation loss: 2.5290282269862283

Epoch: 6| Step: 13
Training loss: 2.4139643281894196
Validation loss: 2.537409925799377

Epoch: 91| Step: 0
Training loss: 3.0272857857354043
Validation loss: 2.537495622197187

Epoch: 6| Step: 1
Training loss: 2.784067334303543
Validation loss: 2.537877367967935

Epoch: 6| Step: 2
Training loss: 2.837356590646539
Validation loss: 2.5499337699069904

Epoch: 6| Step: 3
Training loss: 3.409730305676138
Validation loss: 2.541716583369664

Epoch: 6| Step: 4
Training loss: 2.1351055631961646
Validation loss: 2.5384232799780126

Epoch: 6| Step: 5
Training loss: 2.5205185959063208
Validation loss: 2.527230898729948

Epoch: 6| Step: 6
Training loss: 3.2809023718384482
Validation loss: 2.5215517754403614

Epoch: 6| Step: 7
Training loss: 3.213785583702674
Validation loss: 2.513526574788304

Epoch: 6| Step: 8
Training loss: 2.505969930396856
Validation loss: 2.5154467074753306

Epoch: 6| Step: 9
Training loss: 3.052255584404238
Validation loss: 2.5138150843402647

Epoch: 6| Step: 10
Training loss: 2.633433645084213
Validation loss: 2.513078729182679

Epoch: 6| Step: 11
Training loss: 2.575820725392742
Validation loss: 2.5183266020866943

Epoch: 6| Step: 12
Training loss: 2.8339328879497696
Validation loss: 2.513587046169991

Epoch: 6| Step: 13
Training loss: 3.8189842239697307
Validation loss: 2.511993818251047

Epoch: 92| Step: 0
Training loss: 3.3587117804626745
Validation loss: 2.5096022218691165

Epoch: 6| Step: 1
Training loss: 2.4200199036528454
Validation loss: 2.5143555668968394

Epoch: 6| Step: 2
Training loss: 2.268633298788625
Validation loss: 2.5214310088974847

Epoch: 6| Step: 3
Training loss: 3.3258700903079452
Validation loss: 2.540454602395928

Epoch: 6| Step: 4
Training loss: 3.052014989163649
Validation loss: 2.5352421944809467

Epoch: 6| Step: 5
Training loss: 3.0837822836433504
Validation loss: 2.532683562708699

Epoch: 6| Step: 6
Training loss: 3.4718086572827143
Validation loss: 2.5264118180062254

Epoch: 6| Step: 7
Training loss: 2.411155357579895
Validation loss: 2.5239409882859727

Epoch: 6| Step: 8
Training loss: 3.0852473392597197
Validation loss: 2.5223407643448765

Epoch: 6| Step: 9
Training loss: 2.8018087845823008
Validation loss: 2.5223385303546513

Epoch: 6| Step: 10
Training loss: 2.5341111014020807
Validation loss: 2.535498917446628

Epoch: 6| Step: 11
Training loss: 2.5367157875281054
Validation loss: 2.532278481169871

Epoch: 6| Step: 12
Training loss: 2.966341185842039
Validation loss: 2.528728556539517

Epoch: 6| Step: 13
Training loss: 2.606730417299676
Validation loss: 2.5306752528591905

Epoch: 93| Step: 0
Training loss: 2.355730994257083
Validation loss: 2.5168533572008074

Epoch: 6| Step: 1
Training loss: 2.8384595013313545
Validation loss: 2.5155652991392574

Epoch: 6| Step: 2
Training loss: 3.112082984288599
Validation loss: 2.5158612479131635

Epoch: 6| Step: 3
Training loss: 3.37837671970636
Validation loss: 2.5302714318951613

Epoch: 6| Step: 4
Training loss: 2.6045059186575608
Validation loss: 2.5298034229147897

Epoch: 6| Step: 5
Training loss: 2.997633636524524
Validation loss: 2.520920492557207

Epoch: 6| Step: 6
Training loss: 3.230189614650236
Validation loss: 2.525240656301769

Epoch: 6| Step: 7
Training loss: 2.768246200571318
Validation loss: 2.5266284558359904

Epoch: 6| Step: 8
Training loss: 2.9267104014240477
Validation loss: 2.5261027227359043

Epoch: 6| Step: 9
Training loss: 2.169666182512042
Validation loss: 2.5453013406344978

Epoch: 6| Step: 10
Training loss: 3.080266681867156
Validation loss: 2.563928231618682

Epoch: 6| Step: 11
Training loss: 2.5663384322636746
Validation loss: 2.5703318296218645

Epoch: 6| Step: 12
Training loss: 3.0767484578688014
Validation loss: 2.586713185248336

Epoch: 6| Step: 13
Training loss: 3.1672537075475393
Validation loss: 2.5738458814174026

Epoch: 94| Step: 0
Training loss: 3.4200873735209
Validation loss: 2.5466303453393175

Epoch: 6| Step: 1
Training loss: 2.7860646097450923
Validation loss: 2.542783490468169

Epoch: 6| Step: 2
Training loss: 3.0327409046965306
Validation loss: 2.5446025354105863

Epoch: 6| Step: 3
Training loss: 2.8147795022688404
Validation loss: 2.5470367748671077

Epoch: 6| Step: 4
Training loss: 2.7889998399550486
Validation loss: 2.5530533913127496

Epoch: 6| Step: 5
Training loss: 2.191745996912993
Validation loss: 2.5578429038993997

Epoch: 6| Step: 6
Training loss: 3.2806740391547713
Validation loss: 2.5597684233883102

Epoch: 6| Step: 7
Training loss: 2.7574730683132964
Validation loss: 2.5546294185010177

Epoch: 6| Step: 8
Training loss: 2.9020851399967644
Validation loss: 2.561906611310909

Epoch: 6| Step: 9
Training loss: 2.6043686953697858
Validation loss: 2.549754057751706

Epoch: 6| Step: 10
Training loss: 2.9872949505909476
Validation loss: 2.5328315099670182

Epoch: 6| Step: 11
Training loss: 3.023200604919066
Validation loss: 2.5363414668668423

Epoch: 6| Step: 12
Training loss: 2.7462996816677383
Validation loss: 2.523183507291997

Epoch: 6| Step: 13
Training loss: 2.836095379935124
Validation loss: 2.5137101527993795

Epoch: 95| Step: 0
Training loss: 2.9112518910671725
Validation loss: 2.5112017121999304

Epoch: 6| Step: 1
Training loss: 2.542199271842463
Validation loss: 2.5101837028323595

Epoch: 6| Step: 2
Training loss: 2.5080102385048817
Validation loss: 2.5060943768780617

Epoch: 6| Step: 3
Training loss: 2.068941403665004
Validation loss: 2.503377416308952

Epoch: 6| Step: 4
Training loss: 3.118781349162175
Validation loss: 2.503405456288327

Epoch: 6| Step: 5
Training loss: 3.0894000365369316
Validation loss: 2.503680784604664

Epoch: 6| Step: 6
Training loss: 2.4010247307853825
Validation loss: 2.5113024375445163

Epoch: 6| Step: 7
Training loss: 2.825939619727301
Validation loss: 2.5134488206712886

Epoch: 6| Step: 8
Training loss: 3.25112851430332
Validation loss: 2.53512138740776

Epoch: 6| Step: 9
Training loss: 2.923673188634535
Validation loss: 2.534319546927143

Epoch: 6| Step: 10
Training loss: 3.209957669415738
Validation loss: 2.5164740639161547

Epoch: 6| Step: 11
Training loss: 3.512908292777071
Validation loss: 2.517707523720853

Epoch: 6| Step: 12
Training loss: 2.7094924989277245
Validation loss: 2.507882224433576

Epoch: 6| Step: 13
Training loss: 3.139063204835971
Validation loss: 2.5005164915225797

Epoch: 96| Step: 0
Training loss: 3.12236934562607
Validation loss: 2.500525230690933

Epoch: 6| Step: 1
Training loss: 2.8915534100811713
Validation loss: 2.503937394496525

Epoch: 6| Step: 2
Training loss: 2.000034928016847
Validation loss: 2.506254531888578

Epoch: 6| Step: 3
Training loss: 2.8873050904649484
Validation loss: 2.5074225852143823

Epoch: 6| Step: 4
Training loss: 2.617966994168596
Validation loss: 2.5101177390086873

Epoch: 6| Step: 5
Training loss: 2.8737491706226375
Validation loss: 2.5058564756506443

Epoch: 6| Step: 6
Training loss: 3.228123174262477
Validation loss: 2.5059471907534543

Epoch: 6| Step: 7
Training loss: 2.7726036000136833
Validation loss: 2.5017169286531473

Epoch: 6| Step: 8
Training loss: 3.0155239582428814
Validation loss: 2.5002667459083794

Epoch: 6| Step: 9
Training loss: 2.9303550671722616
Validation loss: 2.499737997579842

Epoch: 6| Step: 10
Training loss: 3.4311628709302893
Validation loss: 2.503994495658705

Epoch: 6| Step: 11
Training loss: 1.7025647423039307
Validation loss: 2.510857584007299

Epoch: 6| Step: 12
Training loss: 3.212091317509364
Validation loss: 2.524812773215725

Epoch: 6| Step: 13
Training loss: 3.2124913671949
Validation loss: 2.5508344573392705

Epoch: 97| Step: 0
Training loss: 3.471727897212735
Validation loss: 2.5530700902210004

Epoch: 6| Step: 1
Training loss: 3.302599235851435
Validation loss: 2.5576430320933574

Epoch: 6| Step: 2
Training loss: 3.1811463104916884
Validation loss: 2.5292765465902685

Epoch: 6| Step: 3
Training loss: 2.6914071358511786
Validation loss: 2.5098702311686565

Epoch: 6| Step: 4
Training loss: 2.8873382853351983
Validation loss: 2.501818333029493

Epoch: 6| Step: 5
Training loss: 2.2191976176314436
Validation loss: 2.5034578590044942

Epoch: 6| Step: 6
Training loss: 2.7804109829429575
Validation loss: 2.5010248206383867

Epoch: 6| Step: 7
Training loss: 2.31076912927515
Validation loss: 2.50125176460163

Epoch: 6| Step: 8
Training loss: 2.526874669688522
Validation loss: 2.4987877234320903

Epoch: 6| Step: 9
Training loss: 3.4862370326860006
Validation loss: 2.501486852942895

Epoch: 6| Step: 10
Training loss: 2.6187009164949075
Validation loss: 2.500500350021983

Epoch: 6| Step: 11
Training loss: 2.3434658641245747
Validation loss: 2.5008699728720796

Epoch: 6| Step: 12
Training loss: 2.837524474454351
Validation loss: 2.507497208542531

Epoch: 6| Step: 13
Training loss: 3.41372923457431
Validation loss: 2.5121674074832487

Epoch: 98| Step: 0
Training loss: 2.923784417467235
Validation loss: 2.5217081075234105

Epoch: 6| Step: 1
Training loss: 2.6801156016227217
Validation loss: 2.5099819142022954

Epoch: 6| Step: 2
Training loss: 2.690512986460028
Validation loss: 2.5049474143395303

Epoch: 6| Step: 3
Training loss: 3.002810592150551
Validation loss: 2.5031615683068886

Epoch: 6| Step: 4
Training loss: 2.909783952696005
Validation loss: 2.5010136876969287

Epoch: 6| Step: 5
Training loss: 2.771020314114964
Validation loss: 2.4993684258032576

Epoch: 6| Step: 6
Training loss: 3.715637443143063
Validation loss: 2.52725615327966

Epoch: 6| Step: 7
Training loss: 3.0267984009809217
Validation loss: 2.560939658915479

Epoch: 6| Step: 8
Training loss: 2.4060758057002025
Validation loss: 2.5850541644904617

Epoch: 6| Step: 9
Training loss: 1.7454169068829968
Validation loss: 2.6051132555652523

Epoch: 6| Step: 10
Training loss: 2.936013028004193
Validation loss: 2.6327231200808763

Epoch: 6| Step: 11
Training loss: 2.667086945634456
Validation loss: 2.6374005677100496

Epoch: 6| Step: 12
Training loss: 3.541289515141866
Validation loss: 2.607775206539954

Epoch: 6| Step: 13
Training loss: 3.171054677635611
Validation loss: 2.593599047458379

Epoch: 99| Step: 0
Training loss: 2.4624197235190004
Validation loss: 2.571837066002618

Epoch: 6| Step: 1
Training loss: 3.039528779099584
Validation loss: 2.557332312338583

Epoch: 6| Step: 2
Training loss: 2.4430840914256513
Validation loss: 2.550926142696492

Epoch: 6| Step: 3
Training loss: 2.3652276213066767
Validation loss: 2.5434775582776012

Epoch: 6| Step: 4
Training loss: 2.356170903909599
Validation loss: 2.5468053636480885

Epoch: 6| Step: 5
Training loss: 2.8645231668338162
Validation loss: 2.5490838427631233

Epoch: 6| Step: 6
Training loss: 3.308344988157817
Validation loss: 2.5498856873760616

Epoch: 6| Step: 7
Training loss: 2.818758295897056
Validation loss: 2.5534660954663555

Epoch: 6| Step: 8
Training loss: 3.344967201653726
Validation loss: 2.585731820613609

Epoch: 6| Step: 9
Training loss: 2.938995792132802
Validation loss: 2.7545805833418964

Epoch: 6| Step: 10
Training loss: 3.5299049448934046
Validation loss: 2.9635395709144863

Epoch: 6| Step: 11
Training loss: 3.678390241861695
Validation loss: 2.981196754705686

Epoch: 6| Step: 12
Training loss: 2.9920236726936142
Validation loss: 2.727313907218552

Epoch: 6| Step: 13
Training loss: 3.476505167627684
Validation loss: 2.5542211619689272

Epoch: 100| Step: 0
Training loss: 2.665645721820102
Validation loss: 2.5361610270868047

Epoch: 6| Step: 1
Training loss: 2.847253171757733
Validation loss: 2.557162007614826

Epoch: 6| Step: 2
Training loss: 3.088862556311735
Validation loss: 2.6352803956526625

Epoch: 6| Step: 3
Training loss: 3.7241460294927773
Validation loss: 2.6825311538123815

Epoch: 6| Step: 4
Training loss: 2.4424587575032852
Validation loss: 2.5688858404096337

Epoch: 6| Step: 5
Training loss: 2.79047142366597
Validation loss: 2.5359993914221124

Epoch: 6| Step: 6
Training loss: 3.1424332153215837
Validation loss: 2.5697772411310975

Epoch: 6| Step: 7
Training loss: 3.280664882261239
Validation loss: 2.6302312943560886

Epoch: 6| Step: 8
Training loss: 2.54087525433766
Validation loss: 2.6636976825209495

Epoch: 6| Step: 9
Training loss: 2.911361301468017
Validation loss: 2.663688754942365

Epoch: 6| Step: 10
Training loss: 2.612030688025228
Validation loss: 2.6420730442708455

Epoch: 6| Step: 11
Training loss: 2.380069341851511
Validation loss: 2.6414055895927446

Epoch: 6| Step: 12
Training loss: 3.2062887802901887
Validation loss: 2.6552102618244118

Epoch: 6| Step: 13
Training loss: 3.2402724895569492
Validation loss: 2.6161218909519968

Epoch: 101| Step: 0
Training loss: 1.650699166795032
Validation loss: 2.5925487509557765

Epoch: 6| Step: 1
Training loss: 3.4096280767146725
Validation loss: 2.5559379139413627

Epoch: 6| Step: 2
Training loss: 2.6377818133319657
Validation loss: 2.5265844957925108

Epoch: 6| Step: 3
Training loss: 2.8528467918037386
Validation loss: 2.508713744900671

Epoch: 6| Step: 4
Training loss: 3.4428217528219642
Validation loss: 2.4939025898427114

Epoch: 6| Step: 5
Training loss: 2.8026270191220575
Validation loss: 2.4968136714286917

Epoch: 6| Step: 6
Training loss: 2.7392431030966473
Validation loss: 2.502973722948871

Epoch: 6| Step: 7
Training loss: 3.0217428657811727
Validation loss: 2.50188668851359

Epoch: 6| Step: 8
Training loss: 3.069104915691301
Validation loss: 2.503621745075542

Epoch: 6| Step: 9
Training loss: 2.649456986987563
Validation loss: 2.5085054741679396

Epoch: 6| Step: 10
Training loss: 3.2059034253172594
Validation loss: 2.5056402615935007

Epoch: 6| Step: 11
Training loss: 2.753057167698434
Validation loss: 2.504255823440091

Epoch: 6| Step: 12
Training loss: 3.0221461808542864
Validation loss: 2.503381552535438

Epoch: 6| Step: 13
Training loss: 2.9352016791695767
Validation loss: 2.50239325943717

Epoch: 102| Step: 0
Training loss: 2.663428267440898
Validation loss: 2.4999878544666223

Epoch: 6| Step: 1
Training loss: 2.9414333225742006
Validation loss: 2.5001706024123433

Epoch: 6| Step: 2
Training loss: 3.2727096586042403
Validation loss: 2.503403102994363

Epoch: 6| Step: 3
Training loss: 2.7627414822218004
Validation loss: 2.5214023996953334

Epoch: 6| Step: 4
Training loss: 2.717606402632903
Validation loss: 2.51591521311178

Epoch: 6| Step: 5
Training loss: 2.782230590089003
Validation loss: 2.521568165473186

Epoch: 6| Step: 6
Training loss: 2.948081902679643
Validation loss: 2.5226531254058644

Epoch: 6| Step: 7
Training loss: 2.4855410160785203
Validation loss: 2.5225118060963667

Epoch: 6| Step: 8
Training loss: 2.8493612075475196
Validation loss: 2.535016999012639

Epoch: 6| Step: 9
Training loss: 3.2598624606460165
Validation loss: 2.536743027473164

Epoch: 6| Step: 10
Training loss: 2.9698636827107534
Validation loss: 2.5384813454841475

Epoch: 6| Step: 11
Training loss: 2.3675591205437763
Validation loss: 2.5614113324662737

Epoch: 6| Step: 12
Training loss: 3.109256301224475
Validation loss: 2.556663962617045

Epoch: 6| Step: 13
Training loss: 2.8310971317747926
Validation loss: 2.5560539850613506

Epoch: 103| Step: 0
Training loss: 2.5959616733948727
Validation loss: 2.543560171702483

Epoch: 6| Step: 1
Training loss: 2.7259480568295347
Validation loss: 2.5624572603776796

Epoch: 6| Step: 2
Training loss: 2.8890247761319894
Validation loss: 2.5740065826670446

Epoch: 6| Step: 3
Training loss: 3.2578025470096765
Validation loss: 2.591828420346158

Epoch: 6| Step: 4
Training loss: 2.832080246074012
Validation loss: 2.586107491886112

Epoch: 6| Step: 5
Training loss: 3.3238208142584718
Validation loss: 2.578505991120473

Epoch: 6| Step: 6
Training loss: 2.3683220187334584
Validation loss: 2.563620595672011

Epoch: 6| Step: 7
Training loss: 2.758052134706447
Validation loss: 2.55146138638722

Epoch: 6| Step: 8
Training loss: 2.7427387607237432
Validation loss: 2.5612914193872394

Epoch: 6| Step: 9
Training loss: 3.081613490579613
Validation loss: 2.583656509804905

Epoch: 6| Step: 10
Training loss: 3.008608863731189
Validation loss: 2.5627394293481562

Epoch: 6| Step: 11
Training loss: 2.4232829277676706
Validation loss: 2.5512775011973896

Epoch: 6| Step: 12
Training loss: 2.8704559240500562
Validation loss: 2.545231976491825

Epoch: 6| Step: 13
Training loss: 3.4899557949206876
Validation loss: 2.5394547899479583

Epoch: 104| Step: 0
Training loss: 2.921431727112862
Validation loss: 2.5278735584604197

Epoch: 6| Step: 1
Training loss: 2.7331262843479895
Validation loss: 2.513907484515588

Epoch: 6| Step: 2
Training loss: 2.894439654632074
Validation loss: 2.5022866538294544

Epoch: 6| Step: 3
Training loss: 3.1814606242725034
Validation loss: 2.488764150602589

Epoch: 6| Step: 4
Training loss: 2.1562595090794625
Validation loss: 2.484223512661793

Epoch: 6| Step: 5
Training loss: 3.09302165387748
Validation loss: 2.486632799045875

Epoch: 6| Step: 6
Training loss: 3.2694902679536533
Validation loss: 2.4868407511750767

Epoch: 6| Step: 7
Training loss: 3.148063997211936
Validation loss: 2.4921937368235634

Epoch: 6| Step: 8
Training loss: 2.8166517343821282
Validation loss: 2.4936845317928293

Epoch: 6| Step: 9
Training loss: 3.1933166687702457
Validation loss: 2.490374332671608

Epoch: 6| Step: 10
Training loss: 2.3542123863259277
Validation loss: 2.4895224645952236

Epoch: 6| Step: 11
Training loss: 2.666402108261598
Validation loss: 2.492534823997688

Epoch: 6| Step: 12
Training loss: 2.4614956661777443
Validation loss: 2.4966149475490127

Epoch: 6| Step: 13
Training loss: 3.3572112456199843
Validation loss: 2.496469430926565

Epoch: 105| Step: 0
Training loss: 3.236660799230043
Validation loss: 2.493742474260287

Epoch: 6| Step: 1
Training loss: 2.5798829529700353
Validation loss: 2.5005738327867624

Epoch: 6| Step: 2
Training loss: 2.82663160485289
Validation loss: 2.5117505743468227

Epoch: 6| Step: 3
Training loss: 3.0217662203913527
Validation loss: 2.5243524718542916

Epoch: 6| Step: 4
Training loss: 2.799816353769948
Validation loss: 2.5262514389888127

Epoch: 6| Step: 5
Training loss: 2.9619377278666352
Validation loss: 2.5032323347883363

Epoch: 6| Step: 6
Training loss: 2.8056404386296587
Validation loss: 2.497166001479876

Epoch: 6| Step: 7
Training loss: 2.7151456596403745
Validation loss: 2.4880436187063975

Epoch: 6| Step: 8
Training loss: 2.6649351061279236
Validation loss: 2.491481383044231

Epoch: 6| Step: 9
Training loss: 3.4809272712401755
Validation loss: 2.4933057651039796

Epoch: 6| Step: 10
Training loss: 2.256945169562851
Validation loss: 2.5030261295826146

Epoch: 6| Step: 11
Training loss: 3.1700864362514887
Validation loss: 2.5096207973502764

Epoch: 6| Step: 12
Training loss: 2.4139007217864434
Validation loss: 2.5102068504000186

Epoch: 6| Step: 13
Training loss: 2.758230809806314
Validation loss: 2.528033152091073

Epoch: 106| Step: 0
Training loss: 2.9045626756627283
Validation loss: 2.5418628631696354

Epoch: 6| Step: 1
Training loss: 2.973537560050775
Validation loss: 2.543949894698923

Epoch: 6| Step: 2
Training loss: 2.555426907641432
Validation loss: 2.5400325762778695

Epoch: 6| Step: 3
Training loss: 3.05523848381647
Validation loss: 2.5267554978381632

Epoch: 6| Step: 4
Training loss: 2.782848798717501
Validation loss: 2.5080987476035643

Epoch: 6| Step: 5
Training loss: 3.0254810928008635
Validation loss: 2.49718036282618

Epoch: 6| Step: 6
Training loss: 2.836481888068876
Validation loss: 2.4872527762449597

Epoch: 6| Step: 7
Training loss: 2.775908752656717
Validation loss: 2.4859006849223175

Epoch: 6| Step: 8
Training loss: 3.022595823171518
Validation loss: 2.4881650248748586

Epoch: 6| Step: 9
Training loss: 3.3035875297949353
Validation loss: 2.4811057489412627

Epoch: 6| Step: 10
Training loss: 2.251137869593122
Validation loss: 2.479367876112959

Epoch: 6| Step: 11
Training loss: 2.8426035152432085
Validation loss: 2.4796674420307294

Epoch: 6| Step: 12
Training loss: 2.6007663551057596
Validation loss: 2.4831332369812253

Epoch: 6| Step: 13
Training loss: 3.042970787116215
Validation loss: 2.4930058851970793

Epoch: 107| Step: 0
Training loss: 2.9761110298815496
Validation loss: 2.492778859001858

Epoch: 6| Step: 1
Training loss: 2.6853107140480867
Validation loss: 2.5024455404380026

Epoch: 6| Step: 2
Training loss: 3.1820203766425137
Validation loss: 2.5114880338823107

Epoch: 6| Step: 3
Training loss: 2.488919881313608
Validation loss: 2.5130186005793416

Epoch: 6| Step: 4
Training loss: 2.678368157439505
Validation loss: 2.5551633677318994

Epoch: 6| Step: 5
Training loss: 2.810920610954943
Validation loss: 2.5922793941259035

Epoch: 6| Step: 6
Training loss: 3.29206301721303
Validation loss: 2.5631400278729712

Epoch: 6| Step: 7
Training loss: 3.040262255148086
Validation loss: 2.5306834310074477

Epoch: 6| Step: 8
Training loss: 3.1958150678275965
Validation loss: 2.5294871306969067

Epoch: 6| Step: 9
Training loss: 2.3627727371298786
Validation loss: 2.5102896763986307

Epoch: 6| Step: 10
Training loss: 2.6579910855226307
Validation loss: 2.5079935912084252

Epoch: 6| Step: 11
Training loss: 2.9939619335743703
Validation loss: 2.482798659221539

Epoch: 6| Step: 12
Training loss: 2.790223550488462
Validation loss: 2.4715236474005766

Epoch: 6| Step: 13
Training loss: 2.47237892463859
Validation loss: 2.4785425943689168

Epoch: 108| Step: 0
Training loss: 3.026948688940484
Validation loss: 2.4805133981249665

Epoch: 6| Step: 1
Training loss: 2.8475301581201573
Validation loss: 2.484021974436645

Epoch: 6| Step: 2
Training loss: 3.0084186686267897
Validation loss: 2.487066850543

Epoch: 6| Step: 3
Training loss: 2.6245701755844486
Validation loss: 2.487933362071377

Epoch: 6| Step: 4
Training loss: 2.760441550856417
Validation loss: 2.485642238762421

Epoch: 6| Step: 5
Training loss: 2.8398435820903494
Validation loss: 2.486800361901233

Epoch: 6| Step: 6
Training loss: 3.117819050459582
Validation loss: 2.4866276163607153

Epoch: 6| Step: 7
Training loss: 2.6838926012862845
Validation loss: 2.4823248751090454

Epoch: 6| Step: 8
Training loss: 3.4779199586051943
Validation loss: 2.4788128583231295

Epoch: 6| Step: 9
Training loss: 1.708294224485252
Validation loss: 2.4904289407341906

Epoch: 6| Step: 10
Training loss: 3.443471542149968
Validation loss: 2.5072006037750785

Epoch: 6| Step: 11
Training loss: 2.8332277914099278
Validation loss: 2.510844933513821

Epoch: 6| Step: 12
Training loss: 2.7713233304161724
Validation loss: 2.5401382880773946

Epoch: 6| Step: 13
Training loss: 2.579280155213774
Validation loss: 2.558708118599506

Epoch: 109| Step: 0
Training loss: 2.8290450986231988
Validation loss: 2.557455819275727

Epoch: 6| Step: 1
Training loss: 2.6285672245525125
Validation loss: 2.5833167956481495

Epoch: 6| Step: 2
Training loss: 2.7632655192092703
Validation loss: 2.572040059956896

Epoch: 6| Step: 3
Training loss: 2.89274560622499
Validation loss: 2.558059929521602

Epoch: 6| Step: 4
Training loss: 3.0409500810815495
Validation loss: 2.536140264448457

Epoch: 6| Step: 5
Training loss: 2.917695182017974
Validation loss: 2.5112614810673213

Epoch: 6| Step: 6
Training loss: 2.522825751542116
Validation loss: 2.4780314069377476

Epoch: 6| Step: 7
Training loss: 3.1539588392785474
Validation loss: 2.4755830461890076

Epoch: 6| Step: 8
Training loss: 2.8920088471188956
Validation loss: 2.478869322016865

Epoch: 6| Step: 9
Training loss: 3.1575947531212685
Validation loss: 2.485655581684169

Epoch: 6| Step: 10
Training loss: 2.9755328943315384
Validation loss: 2.487672568263557

Epoch: 6| Step: 11
Training loss: 2.9159214339275144
Validation loss: 2.4902098321318507

Epoch: 6| Step: 12
Training loss: 2.801897621854823
Validation loss: 2.491224299991258

Epoch: 6| Step: 13
Training loss: 2.5856895673664777
Validation loss: 2.482169924571798

Epoch: 110| Step: 0
Training loss: 2.3426785881174825
Validation loss: 2.48436312376932

Epoch: 6| Step: 1
Training loss: 3.0110939258430687
Validation loss: 2.4815675445852934

Epoch: 6| Step: 2
Training loss: 2.787593679179704
Validation loss: 2.4813742160222985

Epoch: 6| Step: 3
Training loss: 3.1091774729187573
Validation loss: 2.4783851865058715

Epoch: 6| Step: 4
Training loss: 2.8447619304036373
Validation loss: 2.4786454081294447

Epoch: 6| Step: 5
Training loss: 3.1362061040063423
Validation loss: 2.478682595783349

Epoch: 6| Step: 6
Training loss: 3.1719485119348523
Validation loss: 2.4768697166963554

Epoch: 6| Step: 7
Training loss: 2.5947303298159046
Validation loss: 2.4751588267251026

Epoch: 6| Step: 8
Training loss: 3.036121347527806
Validation loss: 2.485407021521024

Epoch: 6| Step: 9
Training loss: 2.5727512651373092
Validation loss: 2.4831081944342155

Epoch: 6| Step: 10
Training loss: 3.3286980507235295
Validation loss: 2.4822224533619486

Epoch: 6| Step: 11
Training loss: 2.5714830324672744
Validation loss: 2.491003222583715

Epoch: 6| Step: 12
Training loss: 2.440000767316854
Validation loss: 2.4957487733328168

Epoch: 6| Step: 13
Training loss: 2.667471307315976
Validation loss: 2.496755128714924

Epoch: 111| Step: 0
Training loss: 2.1281854651735657
Validation loss: 2.51013953751856

Epoch: 6| Step: 1
Training loss: 2.749930814392928
Validation loss: 2.5175676589282783

Epoch: 6| Step: 2
Training loss: 2.959076873038576
Validation loss: 2.526301597023686

Epoch: 6| Step: 3
Training loss: 3.0242354254335533
Validation loss: 2.5391549486568454

Epoch: 6| Step: 4
Training loss: 2.4596484486665635
Validation loss: 2.552342046934742

Epoch: 6| Step: 5
Training loss: 2.3044009272971637
Validation loss: 2.5628586344813584

Epoch: 6| Step: 6
Training loss: 3.2921444188047975
Validation loss: 2.549971196741632

Epoch: 6| Step: 7
Training loss: 2.752905870911743
Validation loss: 2.534851612094955

Epoch: 6| Step: 8
Training loss: 3.2526546786895882
Validation loss: 2.5164690394700786

Epoch: 6| Step: 9
Training loss: 2.6575180617227363
Validation loss: 2.514012984993249

Epoch: 6| Step: 10
Training loss: 3.6985865599582644
Validation loss: 2.501967778558853

Epoch: 6| Step: 11
Training loss: 2.994631414134059
Validation loss: 2.492991848409843

Epoch: 6| Step: 12
Training loss: 2.614783888542791
Validation loss: 2.48194687655846

Epoch: 6| Step: 13
Training loss: 2.5737767397217297
Validation loss: 2.479038207966726

Epoch: 112| Step: 0
Training loss: 2.4748408834769666
Validation loss: 2.4894643734467254

Epoch: 6| Step: 1
Training loss: 3.4321117826721967
Validation loss: 2.4918793436237645

Epoch: 6| Step: 2
Training loss: 3.2700254734458665
Validation loss: 2.511244027402464

Epoch: 6| Step: 3
Training loss: 2.6732243036533285
Validation loss: 2.4911219997275733

Epoch: 6| Step: 4
Training loss: 2.3696985806358635
Validation loss: 2.4916102027181695

Epoch: 6| Step: 5
Training loss: 2.508257769928217
Validation loss: 2.4883311379949546

Epoch: 6| Step: 6
Training loss: 2.7519938436816354
Validation loss: 2.4960203756810686

Epoch: 6| Step: 7
Training loss: 2.880678622507529
Validation loss: 2.495972690461074

Epoch: 6| Step: 8
Training loss: 3.030075632290776
Validation loss: 2.504745085133239

Epoch: 6| Step: 9
Training loss: 2.5565349653192984
Validation loss: 2.5095215766989827

Epoch: 6| Step: 10
Training loss: 2.305326315068067
Validation loss: 2.5357171123405773

Epoch: 6| Step: 11
Training loss: 3.2913178528696014
Validation loss: 2.540497125631149

Epoch: 6| Step: 12
Training loss: 3.4891089880887525
Validation loss: 2.542782929907525

Epoch: 6| Step: 13
Training loss: 1.9759820379799902
Validation loss: 2.5242622023721584

Epoch: 113| Step: 0
Training loss: 3.0355912416028925
Validation loss: 2.507171857753622

Epoch: 6| Step: 1
Training loss: 2.380636253260232
Validation loss: 2.492306341567194

Epoch: 6| Step: 2
Training loss: 2.882912073250713
Validation loss: 2.483231804454213

Epoch: 6| Step: 3
Training loss: 3.1547291934775776
Validation loss: 2.473803515077787

Epoch: 6| Step: 4
Training loss: 2.443762437247313
Validation loss: 2.466441976847621

Epoch: 6| Step: 5
Training loss: 2.937617198148262
Validation loss: 2.459908234525167

Epoch: 6| Step: 6
Training loss: 2.6984233208633337
Validation loss: 2.458647477601312

Epoch: 6| Step: 7
Training loss: 2.919651919742916
Validation loss: 2.4631584400304103

Epoch: 6| Step: 8
Training loss: 3.088120704683406
Validation loss: 2.463045687710505

Epoch: 6| Step: 9
Training loss: 2.8510380510877087
Validation loss: 2.459174559920838

Epoch: 6| Step: 10
Training loss: 2.4542573878602667
Validation loss: 2.465323806333772

Epoch: 6| Step: 11
Training loss: 2.4380570777676893
Validation loss: 2.4684855749292223

Epoch: 6| Step: 12
Training loss: 3.263507941630142
Validation loss: 2.476478570838569

Epoch: 6| Step: 13
Training loss: 2.712853010560871
Validation loss: 2.487964693122093

Epoch: 114| Step: 0
Training loss: 3.0450974194206344
Validation loss: 2.5006231782337807

Epoch: 6| Step: 1
Training loss: 3.0593345008172323
Validation loss: 2.5042576835269323

Epoch: 6| Step: 2
Training loss: 2.6397564605162733
Validation loss: 2.5279682842942757

Epoch: 6| Step: 3
Training loss: 2.8148204132306973
Validation loss: 2.5512165344609072

Epoch: 6| Step: 4
Training loss: 2.7791533550380216
Validation loss: 2.541700630895735

Epoch: 6| Step: 5
Training loss: 2.157368798184069
Validation loss: 2.5459506905956872

Epoch: 6| Step: 6
Training loss: 2.8143152101228304
Validation loss: 2.5721277292212976

Epoch: 6| Step: 7
Training loss: 2.9218293048733024
Validation loss: 2.5833736744673916

Epoch: 6| Step: 8
Training loss: 3.064457170667342
Validation loss: 2.6082682628732394

Epoch: 6| Step: 9
Training loss: 2.6368601669252376
Validation loss: 2.563800270780173

Epoch: 6| Step: 10
Training loss: 3.065458775795805
Validation loss: 2.5377971303657234

Epoch: 6| Step: 11
Training loss: 2.8112315390435705
Validation loss: 2.5035633973999936

Epoch: 6| Step: 12
Training loss: 2.793531155815514
Validation loss: 2.4824452948581124

Epoch: 6| Step: 13
Training loss: 2.7668927406722887
Validation loss: 2.47086702654569

Epoch: 115| Step: 0
Training loss: 2.432547404032195
Validation loss: 2.4648158943554104

Epoch: 6| Step: 1
Training loss: 2.48918674348087
Validation loss: 2.466521826030551

Epoch: 6| Step: 2
Training loss: 2.547519532073579
Validation loss: 2.465616924808606

Epoch: 6| Step: 3
Training loss: 2.779725417703545
Validation loss: 2.462422902014419

Epoch: 6| Step: 4
Training loss: 2.7820000655052897
Validation loss: 2.4650777033557

Epoch: 6| Step: 5
Training loss: 3.3940578257861596
Validation loss: 2.4631900133561926

Epoch: 6| Step: 6
Training loss: 2.575100413466398
Validation loss: 2.477915593388708

Epoch: 6| Step: 7
Training loss: 2.393091462787743
Validation loss: 2.480251671146107

Epoch: 6| Step: 8
Training loss: 2.819291117423874
Validation loss: 2.4887634738361197

Epoch: 6| Step: 9
Training loss: 2.437292236863683
Validation loss: 2.4935250468390757

Epoch: 6| Step: 10
Training loss: 3.0317294341376186
Validation loss: 2.5070481140912984

Epoch: 6| Step: 11
Training loss: 3.5254475681429582
Validation loss: 2.5236364075615145

Epoch: 6| Step: 12
Training loss: 3.30503955165264
Validation loss: 2.525205508340398

Epoch: 6| Step: 13
Training loss: 2.5089413012757134
Validation loss: 2.5303163587849147

Epoch: 116| Step: 0
Training loss: 2.922183586593649
Validation loss: 2.521909648889369

Epoch: 6| Step: 1
Training loss: 3.1546596637346065
Validation loss: 2.5346113072711582

Epoch: 6| Step: 2
Training loss: 2.6670384048597473
Validation loss: 2.5105533000159412

Epoch: 6| Step: 3
Training loss: 2.3467410520482765
Validation loss: 2.512338762247666

Epoch: 6| Step: 4
Training loss: 1.796300182451208
Validation loss: 2.504847822296959

Epoch: 6| Step: 5
Training loss: 3.093471938458987
Validation loss: 2.4889121283307727

Epoch: 6| Step: 6
Training loss: 2.9486728592469147
Validation loss: 2.4866949409400045

Epoch: 6| Step: 7
Training loss: 2.9977406895257275
Validation loss: 2.472475089145285

Epoch: 6| Step: 8
Training loss: 3.0177423031288244
Validation loss: 2.4637748751660244

Epoch: 6| Step: 9
Training loss: 3.0389918929579043
Validation loss: 2.4590681412457247

Epoch: 6| Step: 10
Training loss: 2.947969002590491
Validation loss: 2.45574058145804

Epoch: 6| Step: 11
Training loss: 2.9716076398697107
Validation loss: 2.455769341778435

Epoch: 6| Step: 12
Training loss: 2.592333027420461
Validation loss: 2.458436648487049

Epoch: 6| Step: 13
Training loss: 2.3912247048937987
Validation loss: 2.453616645642119

Epoch: 117| Step: 0
Training loss: 2.7288929071545227
Validation loss: 2.456859778601313

Epoch: 6| Step: 1
Training loss: 3.008895560128376
Validation loss: 2.4578615152615

Epoch: 6| Step: 2
Training loss: 2.95395660801387
Validation loss: 2.4557785272631554

Epoch: 6| Step: 3
Training loss: 2.8633751743206854
Validation loss: 2.4588849179043115

Epoch: 6| Step: 4
Training loss: 2.8206139400780113
Validation loss: 2.4614388487298724

Epoch: 6| Step: 5
Training loss: 2.9302147962976037
Validation loss: 2.471453566280989

Epoch: 6| Step: 6
Training loss: 2.4877264101897474
Validation loss: 2.4833942452796736

Epoch: 6| Step: 7
Training loss: 2.817549855587422
Validation loss: 2.5030365376489416

Epoch: 6| Step: 8
Training loss: 2.777480067088023
Validation loss: 2.514307134340885

Epoch: 6| Step: 9
Training loss: 2.8669701267757755
Validation loss: 2.5296008674047035

Epoch: 6| Step: 10
Training loss: 2.655360802310676
Validation loss: 2.521867501466428

Epoch: 6| Step: 11
Training loss: 3.00802651176538
Validation loss: 2.525421330954852

Epoch: 6| Step: 12
Training loss: 2.501545523705621
Validation loss: 2.54324492505842

Epoch: 6| Step: 13
Training loss: 2.8207386994558554
Validation loss: 2.547628221246559

Epoch: 118| Step: 0
Training loss: 2.488837307251676
Validation loss: 2.5793108219475847

Epoch: 6| Step: 1
Training loss: 2.1391803851082165
Validation loss: 2.599595862548622

Epoch: 6| Step: 2
Training loss: 3.137600633443548
Validation loss: 2.602507831186235

Epoch: 6| Step: 3
Training loss: 2.771076755778081
Validation loss: 2.537657697986399

Epoch: 6| Step: 4
Training loss: 2.6486142980028182
Validation loss: 2.5017483089392623

Epoch: 6| Step: 5
Training loss: 3.18023841827853
Validation loss: 2.477324437182083

Epoch: 6| Step: 6
Training loss: 2.7583771470692025
Validation loss: 2.4560722838911704

Epoch: 6| Step: 7
Training loss: 2.962085511389269
Validation loss: 2.4516129587151325

Epoch: 6| Step: 8
Training loss: 2.750674251782007
Validation loss: 2.4434279631092783

Epoch: 6| Step: 9
Training loss: 3.25093534654896
Validation loss: 2.4519720629399178

Epoch: 6| Step: 10
Training loss: 2.641854265292734
Validation loss: 2.456461232358915

Epoch: 6| Step: 11
Training loss: 2.7034361555470734
Validation loss: 2.461325898376565

Epoch: 6| Step: 12
Training loss: 2.8890947570155343
Validation loss: 2.45851165336093

Epoch: 6| Step: 13
Training loss: 3.288365958571253
Validation loss: 2.460062702080838

Epoch: 119| Step: 0
Training loss: 2.823514183029077
Validation loss: 2.4606792136663924

Epoch: 6| Step: 1
Training loss: 2.401382775118431
Validation loss: 2.4795939197203634

Epoch: 6| Step: 2
Training loss: 2.606385214246022
Validation loss: 2.473427294659034

Epoch: 6| Step: 3
Training loss: 2.733601139098955
Validation loss: 2.5029159521899658

Epoch: 6| Step: 4
Training loss: 2.8235904316526175
Validation loss: 2.532845023331284

Epoch: 6| Step: 5
Training loss: 2.8734788602307257
Validation loss: 2.550486037196254

Epoch: 6| Step: 6
Training loss: 3.090712780761755
Validation loss: 2.563439224838491

Epoch: 6| Step: 7
Training loss: 2.9933531559866235
Validation loss: 2.56548173365097

Epoch: 6| Step: 8
Training loss: 2.991550945569292
Validation loss: 2.5719959600649687

Epoch: 6| Step: 9
Training loss: 2.688171657644265
Validation loss: 2.565219332667242

Epoch: 6| Step: 10
Training loss: 3.26821884011794
Validation loss: 2.5591204417629037

Epoch: 6| Step: 11
Training loss: 2.695307634874459
Validation loss: 2.5297664536955464

Epoch: 6| Step: 12
Training loss: 2.5032308682307125
Validation loss: 2.522560068929149

Epoch: 6| Step: 13
Training loss: 2.9302027541694096
Validation loss: 2.510445896680247

Epoch: 120| Step: 0
Training loss: 2.7450595172481895
Validation loss: 2.5010500005225196

Epoch: 6| Step: 1
Training loss: 2.645589191456677
Validation loss: 2.4875999802434867

Epoch: 6| Step: 2
Training loss: 2.9150801203662136
Validation loss: 2.4729270577459705

Epoch: 6| Step: 3
Training loss: 3.1488106556161606
Validation loss: 2.4683410733691753

Epoch: 6| Step: 4
Training loss: 2.5234252173535245
Validation loss: 2.462491596283166

Epoch: 6| Step: 5
Training loss: 2.5480101694296367
Validation loss: 2.461118658051709

Epoch: 6| Step: 6
Training loss: 2.625616001330753
Validation loss: 2.458221310113551

Epoch: 6| Step: 7
Training loss: 2.4790409814941032
Validation loss: 2.4652400644242674

Epoch: 6| Step: 8
Training loss: 3.2012899957710683
Validation loss: 2.468166921619367

Epoch: 6| Step: 9
Training loss: 2.756491628422749
Validation loss: 2.4728038283528644

Epoch: 6| Step: 10
Training loss: 2.605136924557118
Validation loss: 2.476416507992119

Epoch: 6| Step: 11
Training loss: 3.0154918581967
Validation loss: 2.476224696718081

Epoch: 6| Step: 12
Training loss: 2.6558869057614385
Validation loss: 2.4771146822830774

Epoch: 6| Step: 13
Training loss: 3.3679579276041762
Validation loss: 2.465523574764074

Epoch: 121| Step: 0
Training loss: 3.2205380408437922
Validation loss: 2.458966133246601

Epoch: 6| Step: 1
Training loss: 2.646127058731252
Validation loss: 2.458036349172626

Epoch: 6| Step: 2
Training loss: 2.521970529176862
Validation loss: 2.454605329946893

Epoch: 6| Step: 3
Training loss: 3.1319111504844463
Validation loss: 2.4574359485058537

Epoch: 6| Step: 4
Training loss: 3.2358212393483017
Validation loss: 2.456117144828425

Epoch: 6| Step: 5
Training loss: 2.6852157111156205
Validation loss: 2.4463570602182503

Epoch: 6| Step: 6
Training loss: 2.4970628651018196
Validation loss: 2.460951054996858

Epoch: 6| Step: 7
Training loss: 2.3276153621089937
Validation loss: 2.4621410108826245

Epoch: 6| Step: 8
Training loss: 2.6557600579289025
Validation loss: 2.483460453868166

Epoch: 6| Step: 9
Training loss: 2.809458126073105
Validation loss: 2.4857139392363354

Epoch: 6| Step: 10
Training loss: 3.092748152229288
Validation loss: 2.491039689568797

Epoch: 6| Step: 11
Training loss: 3.037324148354557
Validation loss: 2.519408024856252

Epoch: 6| Step: 12
Training loss: 2.0083667272215853
Validation loss: 2.5263077161403937

Epoch: 6| Step: 13
Training loss: 2.8904075746987616
Validation loss: 2.526731222453962

Epoch: 122| Step: 0
Training loss: 2.600585570784803
Validation loss: 2.520075400777769

Epoch: 6| Step: 1
Training loss: 2.986778370039913
Validation loss: 2.5151973547623827

Epoch: 6| Step: 2
Training loss: 1.9949945756652057
Validation loss: 2.503982330595212

Epoch: 6| Step: 3
Training loss: 2.8659166227193187
Validation loss: 2.4995357174602244

Epoch: 6| Step: 4
Training loss: 2.3362583718269776
Validation loss: 2.4952211841119176

Epoch: 6| Step: 5
Training loss: 2.61338616632397
Validation loss: 2.501208048348237

Epoch: 6| Step: 6
Training loss: 2.570775694693008
Validation loss: 2.499135756056617

Epoch: 6| Step: 7
Training loss: 3.09143411287829
Validation loss: 2.4821707942080855

Epoch: 6| Step: 8
Training loss: 3.3814497178301894
Validation loss: 2.4742877813817383

Epoch: 6| Step: 9
Training loss: 2.6283673078348504
Validation loss: 2.4625253378422016

Epoch: 6| Step: 10
Training loss: 2.7927959682132815
Validation loss: 2.4619044989974856

Epoch: 6| Step: 11
Training loss: 3.3570960543074544
Validation loss: 2.4507780488118014

Epoch: 6| Step: 12
Training loss: 2.491744238199879
Validation loss: 2.460862107561776

Epoch: 6| Step: 13
Training loss: 2.9226073301004756
Validation loss: 2.449683678811974

Epoch: 123| Step: 0
Training loss: 2.11658528339194
Validation loss: 2.462993576899632

Epoch: 6| Step: 1
Training loss: 3.1640985180723864
Validation loss: 2.4959843245185755

Epoch: 6| Step: 2
Training loss: 3.143132816956563
Validation loss: 2.515110035261234

Epoch: 6| Step: 3
Training loss: 2.7402778779734622
Validation loss: 2.546524785756231

Epoch: 6| Step: 4
Training loss: 3.478245839832839
Validation loss: 2.535552293816596

Epoch: 6| Step: 5
Training loss: 3.149828733602097
Validation loss: 2.5787380231744073

Epoch: 6| Step: 6
Training loss: 2.7345771060911255
Validation loss: 2.547885241703871

Epoch: 6| Step: 7
Training loss: 2.2038306871379207
Validation loss: 2.5117525176806597

Epoch: 6| Step: 8
Training loss: 3.138677648077298
Validation loss: 2.4833213267669616

Epoch: 6| Step: 9
Training loss: 2.4656906486638683
Validation loss: 2.4773616850233218

Epoch: 6| Step: 10
Training loss: 2.410520059340294
Validation loss: 2.4608404074958847

Epoch: 6| Step: 11
Training loss: 2.89961897221359
Validation loss: 2.463342243645651

Epoch: 6| Step: 12
Training loss: 1.5874754866261835
Validation loss: 2.4645662882393524

Epoch: 6| Step: 13
Training loss: 3.428683679309906
Validation loss: 2.4739376562492548

Epoch: 124| Step: 0
Training loss: 2.6343372129578833
Validation loss: 2.4872823966625552

Epoch: 6| Step: 1
Training loss: 3.146126099830577
Validation loss: 2.4950326494931434

Epoch: 6| Step: 2
Training loss: 2.8589603978149842
Validation loss: 2.4988533671945965

Epoch: 6| Step: 3
Training loss: 2.6425547574089245
Validation loss: 2.51227110443161

Epoch: 6| Step: 4
Training loss: 2.3636635715412533
Validation loss: 2.5110180937332145

Epoch: 6| Step: 5
Training loss: 2.0956110867414734
Validation loss: 2.5197734233379245

Epoch: 6| Step: 6
Training loss: 2.943587468351822
Validation loss: 2.5179803056812466

Epoch: 6| Step: 7
Training loss: 2.737051738112024
Validation loss: 2.522076194512121

Epoch: 6| Step: 8
Training loss: 3.0728448029644237
Validation loss: 2.509336407036381

Epoch: 6| Step: 9
Training loss: 2.9924902700522558
Validation loss: 2.506851966620316

Epoch: 6| Step: 10
Training loss: 2.9635157972300616
Validation loss: 2.5080102650815896

Epoch: 6| Step: 11
Training loss: 2.49014016365906
Validation loss: 2.496568833494851

Epoch: 6| Step: 12
Training loss: 2.5457078564611453
Validation loss: 2.477106773334351

Epoch: 6| Step: 13
Training loss: 3.1452394813365956
Validation loss: 2.4741476421539157

Epoch: 125| Step: 0
Training loss: 2.9381893241964137
Validation loss: 2.4485692137386423

Epoch: 6| Step: 1
Training loss: 2.541181601426195
Validation loss: 2.4461749672080195

Epoch: 6| Step: 2
Training loss: 2.6155990107075766
Validation loss: 2.4421447755207777

Epoch: 6| Step: 3
Training loss: 3.012627727918995
Validation loss: 2.4441937558175755

Epoch: 6| Step: 4
Training loss: 2.8100342007928023
Validation loss: 2.442752346481294

Epoch: 6| Step: 5
Training loss: 2.602348964826798
Validation loss: 2.439723283756808

Epoch: 6| Step: 6
Training loss: 2.826557209606713
Validation loss: 2.444253604635622

Epoch: 6| Step: 7
Training loss: 3.0073432060840157
Validation loss: 2.4450649500618162

Epoch: 6| Step: 8
Training loss: 3.0830713796602374
Validation loss: 2.448094438544219

Epoch: 6| Step: 9
Training loss: 2.431494724538588
Validation loss: 2.457238519974522

Epoch: 6| Step: 10
Training loss: 2.7377259566186862
Validation loss: 2.4540708928664032

Epoch: 6| Step: 11
Training loss: 2.6401798392221427
Validation loss: 2.46817256581108

Epoch: 6| Step: 12
Training loss: 2.70490034600268
Validation loss: 2.4891831336404406

Epoch: 6| Step: 13
Training loss: 2.256618302736554
Validation loss: 2.510008597564125

Epoch: 126| Step: 0
Training loss: 2.917247351107538
Validation loss: 2.5892940218622624

Epoch: 6| Step: 1
Training loss: 2.679173723352927
Validation loss: 2.6456774167555412

Epoch: 6| Step: 2
Training loss: 3.3037471650855106
Validation loss: 2.658101195738055

Epoch: 6| Step: 3
Training loss: 2.736899817877546
Validation loss: 2.6049260610212226

Epoch: 6| Step: 4
Training loss: 2.8752119566696934
Validation loss: 2.5527441545857386

Epoch: 6| Step: 5
Training loss: 2.417445112234506
Validation loss: 2.504273541811646

Epoch: 6| Step: 6
Training loss: 2.79489969581958
Validation loss: 2.463225565127688

Epoch: 6| Step: 7
Training loss: 2.9517935521578313
Validation loss: 2.44365061174488

Epoch: 6| Step: 8
Training loss: 2.3513336577228223
Validation loss: 2.4246044105218023

Epoch: 6| Step: 9
Training loss: 2.6711851422902324
Validation loss: 2.4221041271629695

Epoch: 6| Step: 10
Training loss: 3.375848734065697
Validation loss: 2.4300803629325443

Epoch: 6| Step: 11
Training loss: 2.78745298132137
Validation loss: 2.4297132999467013

Epoch: 6| Step: 12
Training loss: 2.4185007523840523
Validation loss: 2.429150718352791

Epoch: 6| Step: 13
Training loss: 2.9226970638146974
Validation loss: 2.4316157416536504

Epoch: 127| Step: 0
Training loss: 2.9292338515960834
Validation loss: 2.4315093266818755

Epoch: 6| Step: 1
Training loss: 2.5302764527432826
Validation loss: 2.4315260068307505

Epoch: 6| Step: 2
Training loss: 2.4664798390886675
Validation loss: 2.450187917236747

Epoch: 6| Step: 3
Training loss: 2.5089054756284517
Validation loss: 2.4750682261238475

Epoch: 6| Step: 4
Training loss: 3.455979768146352
Validation loss: 2.5338826507935885

Epoch: 6| Step: 5
Training loss: 2.556218426423142
Validation loss: 2.5860634375841967

Epoch: 6| Step: 6
Training loss: 3.3196673316202863
Validation loss: 2.6305668746812074

Epoch: 6| Step: 7
Training loss: 2.673913100280707
Validation loss: 2.681019623425398

Epoch: 6| Step: 8
Training loss: 2.239804799566501
Validation loss: 2.6774447607984033

Epoch: 6| Step: 9
Training loss: 3.2837421943679237
Validation loss: 2.6565375812393133

Epoch: 6| Step: 10
Training loss: 2.841187884435932
Validation loss: 2.6363456249988007

Epoch: 6| Step: 11
Training loss: 2.3283931910530775
Validation loss: 2.5744086284900893

Epoch: 6| Step: 12
Training loss: 2.902056221562627
Validation loss: 2.54088982468235

Epoch: 6| Step: 13
Training loss: 2.8320785623741926
Validation loss: 2.510187561285773

Epoch: 128| Step: 0
Training loss: 2.337914896164217
Validation loss: 2.488648143240295

Epoch: 6| Step: 1
Training loss: 2.2725396234899913
Validation loss: 2.4526378899624444

Epoch: 6| Step: 2
Training loss: 2.9708517565341017
Validation loss: 2.436146713601555

Epoch: 6| Step: 3
Training loss: 2.9528398325649543
Validation loss: 2.429045823361172

Epoch: 6| Step: 4
Training loss: 2.7589514436448304
Validation loss: 2.433713578806159

Epoch: 6| Step: 5
Training loss: 2.248702840941397
Validation loss: 2.4349205824352214

Epoch: 6| Step: 6
Training loss: 2.6256931842903057
Validation loss: 2.4336535224032323

Epoch: 6| Step: 7
Training loss: 3.310486811540309
Validation loss: 2.427468207866635

Epoch: 6| Step: 8
Training loss: 2.577724356298723
Validation loss: 2.4322725768562257

Epoch: 6| Step: 9
Training loss: 2.831574080826338
Validation loss: 2.426537143626642

Epoch: 6| Step: 10
Training loss: 2.832919782489182
Validation loss: 2.4280497579968388

Epoch: 6| Step: 11
Training loss: 2.8379702678303147
Validation loss: 2.4350290239769854

Epoch: 6| Step: 12
Training loss: 2.9707822569691564
Validation loss: 2.435722589661008

Epoch: 6| Step: 13
Training loss: 3.247975379033095
Validation loss: 2.444749581992226

Epoch: 129| Step: 0
Training loss: 2.033543626927435
Validation loss: 2.4513469057499733

Epoch: 6| Step: 1
Training loss: 2.993310622941194
Validation loss: 2.473139817345595

Epoch: 6| Step: 2
Training loss: 2.246298500348348
Validation loss: 2.4797710610230066

Epoch: 6| Step: 3
Training loss: 2.6836251114035856
Validation loss: 2.490852391545983

Epoch: 6| Step: 4
Training loss: 2.6524681545291013
Validation loss: 2.4861573491719935

Epoch: 6| Step: 5
Training loss: 2.4275251867714305
Validation loss: 2.4813622830698456

Epoch: 6| Step: 6
Training loss: 3.4022967995558626
Validation loss: 2.4704662446310937

Epoch: 6| Step: 7
Training loss: 3.312753343790762
Validation loss: 2.4497799503937108

Epoch: 6| Step: 8
Training loss: 2.790810259130101
Validation loss: 2.442049406001959

Epoch: 6| Step: 9
Training loss: 2.776114447941595
Validation loss: 2.431732553694048

Epoch: 6| Step: 10
Training loss: 2.7876674037325557
Validation loss: 2.4307147501793804

Epoch: 6| Step: 11
Training loss: 2.34187384217241
Validation loss: 2.4283552048769597

Epoch: 6| Step: 12
Training loss: 2.635856973608592
Validation loss: 2.429116030368468

Epoch: 6| Step: 13
Training loss: 3.1461197341668146
Validation loss: 2.426958678662697

Epoch: 130| Step: 0
Training loss: 2.5344218408510475
Validation loss: 2.4218406582189433

Epoch: 6| Step: 1
Training loss: 2.9771010344726307
Validation loss: 2.431310630586645

Epoch: 6| Step: 2
Training loss: 2.389135158274725
Validation loss: 2.4372735161495345

Epoch: 6| Step: 3
Training loss: 3.1072908250375124
Validation loss: 2.453223455410327

Epoch: 6| Step: 4
Training loss: 3.2642877934679695
Validation loss: 2.468258559717907

Epoch: 6| Step: 5
Training loss: 2.990438482991523
Validation loss: 2.4701380028130355

Epoch: 6| Step: 6
Training loss: 2.6686111950121254
Validation loss: 2.4748912008847563

Epoch: 6| Step: 7
Training loss: 2.9440823118375126
Validation loss: 2.4840598256990556

Epoch: 6| Step: 8
Training loss: 2.8480070340251853
Validation loss: 2.4727957843180666

Epoch: 6| Step: 9
Training loss: 2.31721551920644
Validation loss: 2.468947980405243

Epoch: 6| Step: 10
Training loss: 2.8564623396928406
Validation loss: 2.4571486525131156

Epoch: 6| Step: 11
Training loss: 2.2799394579428562
Validation loss: 2.4381656111303505

Epoch: 6| Step: 12
Training loss: 2.4888131667531628
Validation loss: 2.4407646565390975

Epoch: 6| Step: 13
Training loss: 2.171295527813753
Validation loss: 2.435564317463246

Epoch: 131| Step: 0
Training loss: 2.98430405777101
Validation loss: 2.4375367710062954

Epoch: 6| Step: 1
Training loss: 2.9170078804608
Validation loss: 2.4463382055707363

Epoch: 6| Step: 2
Training loss: 2.5452553683543657
Validation loss: 2.4571949961803594

Epoch: 6| Step: 3
Training loss: 3.047903347094921
Validation loss: 2.4808124908998406

Epoch: 6| Step: 4
Training loss: 2.464583442109708
Validation loss: 2.5001478438602565

Epoch: 6| Step: 5
Training loss: 2.7935526630933287
Validation loss: 2.515001141553137

Epoch: 6| Step: 6
Training loss: 2.5874782248055292
Validation loss: 2.5189696660111545

Epoch: 6| Step: 7
Training loss: 2.3948046479959464
Validation loss: 2.519200275975477

Epoch: 6| Step: 8
Training loss: 2.8859452590879386
Validation loss: 2.508014914979001

Epoch: 6| Step: 9
Training loss: 2.8150413052118486
Validation loss: 2.4948794243116525

Epoch: 6| Step: 10
Training loss: 2.4034226886717955
Validation loss: 2.464750086718945

Epoch: 6| Step: 11
Training loss: 3.0200463333112424
Validation loss: 2.448584166357396

Epoch: 6| Step: 12
Training loss: 2.6955774149419396
Validation loss: 2.4405254102364693

Epoch: 6| Step: 13
Training loss: 2.473903829409205
Validation loss: 2.4411089389701925

Epoch: 132| Step: 0
Training loss: 2.802026618090476
Validation loss: 2.4429115759924653

Epoch: 6| Step: 1
Training loss: 2.963547816658455
Validation loss: 2.4386254681646053

Epoch: 6| Step: 2
Training loss: 2.4510024297134887
Validation loss: 2.436321720499203

Epoch: 6| Step: 3
Training loss: 2.2963836559589135
Validation loss: 2.434407729879355

Epoch: 6| Step: 4
Training loss: 2.864426783127549
Validation loss: 2.4362921855240356

Epoch: 6| Step: 5
Training loss: 3.037473601552276
Validation loss: 2.443195770772938

Epoch: 6| Step: 6
Training loss: 3.1568602925594096
Validation loss: 2.4441306738853847

Epoch: 6| Step: 7
Training loss: 2.8260811011467433
Validation loss: 2.4605817671488377

Epoch: 6| Step: 8
Training loss: 2.475099919932014
Validation loss: 2.463342453870352

Epoch: 6| Step: 9
Training loss: 2.4453844541255685
Validation loss: 2.4731028407427753

Epoch: 6| Step: 10
Training loss: 2.411685897163465
Validation loss: 2.4906248098235335

Epoch: 6| Step: 11
Training loss: 2.1618625737781834
Validation loss: 2.505198611051131

Epoch: 6| Step: 12
Training loss: 3.2013818975681656
Validation loss: 2.51081479874016

Epoch: 6| Step: 13
Training loss: 2.8538839009869514
Validation loss: 2.488811561910561

Epoch: 133| Step: 0
Training loss: 2.4541008824424546
Validation loss: 2.481499474466222

Epoch: 6| Step: 1
Training loss: 2.7230548320605306
Validation loss: 2.468123587424543

Epoch: 6| Step: 2
Training loss: 2.9353548699058982
Validation loss: 2.4509447801260014

Epoch: 6| Step: 3
Training loss: 2.7517568005179487
Validation loss: 2.4356508248035116

Epoch: 6| Step: 4
Training loss: 2.476540935434505
Validation loss: 2.429056452377761

Epoch: 6| Step: 5
Training loss: 3.045198106256415
Validation loss: 2.4249974388529365

Epoch: 6| Step: 6
Training loss: 2.5042071228652363
Validation loss: 2.423400473634954

Epoch: 6| Step: 7
Training loss: 2.851893241200326
Validation loss: 2.4241348990930858

Epoch: 6| Step: 8
Training loss: 2.3954350568917304
Validation loss: 2.419377552253996

Epoch: 6| Step: 9
Training loss: 2.0962918921909766
Validation loss: 2.431294224167592

Epoch: 6| Step: 10
Training loss: 1.9413416523615434
Validation loss: 2.43279330766155

Epoch: 6| Step: 11
Training loss: 3.072882666103389
Validation loss: 2.436745506072155

Epoch: 6| Step: 12
Training loss: 3.2344484182677222
Validation loss: 2.432618791476072

Epoch: 6| Step: 13
Training loss: 3.288913315676573
Validation loss: 2.4458039179280733

Epoch: 134| Step: 0
Training loss: 3.091224795808324
Validation loss: 2.4483990726499343

Epoch: 6| Step: 1
Training loss: 2.8776054186695994
Validation loss: 2.4672126375805394

Epoch: 6| Step: 2
Training loss: 2.935559707380053
Validation loss: 2.483228093042755

Epoch: 6| Step: 3
Training loss: 2.7647443328255714
Validation loss: 2.4808038838003634

Epoch: 6| Step: 4
Training loss: 2.202988857093921
Validation loss: 2.4852237666545296

Epoch: 6| Step: 5
Training loss: 2.953299865389505
Validation loss: 2.4813630775686364

Epoch: 6| Step: 6
Training loss: 3.072408722529665
Validation loss: 2.477028822990994

Epoch: 6| Step: 7
Training loss: 3.1259550542547316
Validation loss: 2.481168818657482

Epoch: 6| Step: 8
Training loss: 3.2120055118670265
Validation loss: 2.4754805795507844

Epoch: 6| Step: 9
Training loss: 2.577958072691339
Validation loss: 2.489318034093797

Epoch: 6| Step: 10
Training loss: 2.579460769014857
Validation loss: 2.4936598069881657

Epoch: 6| Step: 11
Training loss: 1.9235687235887613
Validation loss: 2.529065231324788

Epoch: 6| Step: 12
Training loss: 2.5263220772330355
Validation loss: 2.5599349024386147

Epoch: 6| Step: 13
Training loss: 1.7822269638270096
Validation loss: 2.5709198065540195

Epoch: 135| Step: 0
Training loss: 3.0344576823385294
Validation loss: 2.570040675012526

Epoch: 6| Step: 1
Training loss: 2.5363708313895525
Validation loss: 2.5452348330018912

Epoch: 6| Step: 2
Training loss: 2.7602644008650885
Validation loss: 2.515178384219432

Epoch: 6| Step: 3
Training loss: 3.057918313232123
Validation loss: 2.4957750983525484

Epoch: 6| Step: 4
Training loss: 2.1707511573901765
Validation loss: 2.484244616329819

Epoch: 6| Step: 5
Training loss: 2.16191010560523
Validation loss: 2.470797134317134

Epoch: 6| Step: 6
Training loss: 2.2123893580816487
Validation loss: 2.463292099338402

Epoch: 6| Step: 7
Training loss: 2.951295639260388
Validation loss: 2.4687739493497483

Epoch: 6| Step: 8
Training loss: 2.8063527213754225
Validation loss: 2.4749704211487287

Epoch: 6| Step: 9
Training loss: 2.8800422569989506
Validation loss: 2.4855122444070936

Epoch: 6| Step: 10
Training loss: 2.700468842101883
Validation loss: 2.4853699396396336

Epoch: 6| Step: 11
Training loss: 2.8817460897019873
Validation loss: 2.4934548818664184

Epoch: 6| Step: 12
Training loss: 2.9307432993391105
Validation loss: 2.495483724448597

Epoch: 6| Step: 13
Training loss: 3.3291472535090536
Validation loss: 2.5083846917040757

Epoch: 136| Step: 0
Training loss: 2.519915600226163
Validation loss: 2.514166331938689

Epoch: 6| Step: 1
Training loss: 2.8589295420709266
Validation loss: 2.5176298661428484

Epoch: 6| Step: 2
Training loss: 2.9346127219793297
Validation loss: 2.5261364787840317

Epoch: 6| Step: 3
Training loss: 2.544785654750806
Validation loss: 2.5202224392599293

Epoch: 6| Step: 4
Training loss: 3.130746669251802
Validation loss: 2.5152612044898297

Epoch: 6| Step: 5
Training loss: 2.7979135982433165
Validation loss: 2.4905374049282347

Epoch: 6| Step: 6
Training loss: 3.1416955138753178
Validation loss: 2.4889525245364132

Epoch: 6| Step: 7
Training loss: 2.4911540887403283
Validation loss: 2.4865727330517786

Epoch: 6| Step: 8
Training loss: 1.8560806068682751
Validation loss: 2.4811814902694387

Epoch: 6| Step: 9
Training loss: 2.9991499968207953
Validation loss: 2.473320633067584

Epoch: 6| Step: 10
Training loss: 2.6531542521415408
Validation loss: 2.4702762710874318

Epoch: 6| Step: 11
Training loss: 2.9346041101423137
Validation loss: 2.467732791212119

Epoch: 6| Step: 12
Training loss: 2.4431966091619617
Validation loss: 2.462858553398804

Epoch: 6| Step: 13
Training loss: 2.267089580837401
Validation loss: 2.482276826615292

Epoch: 137| Step: 0
Training loss: 2.7964141295501554
Validation loss: 2.5090607102749676

Epoch: 6| Step: 1
Training loss: 2.9433300520582333
Validation loss: 2.516710221939756

Epoch: 6| Step: 2
Training loss: 2.7542725231547838
Validation loss: 2.530070234649459

Epoch: 6| Step: 3
Training loss: 2.7638347456424928
Validation loss: 2.5358435059209268

Epoch: 6| Step: 4
Training loss: 2.7927153785860486
Validation loss: 2.5219863939988687

Epoch: 6| Step: 5
Training loss: 2.856025777150146
Validation loss: 2.5248202880209054

Epoch: 6| Step: 6
Training loss: 2.712644012425326
Validation loss: 2.5174349993785095

Epoch: 6| Step: 7
Training loss: 2.183750863470858
Validation loss: 2.530875609377505

Epoch: 6| Step: 8
Training loss: 2.5372365166432433
Validation loss: 2.5026388413173395

Epoch: 6| Step: 9
Training loss: 2.872183373699061
Validation loss: 2.479317995952188

Epoch: 6| Step: 10
Training loss: 2.4455443446027423
Validation loss: 2.4585784496523906

Epoch: 6| Step: 11
Training loss: 2.254272431191661
Validation loss: 2.465728405994424

Epoch: 6| Step: 12
Training loss: 2.7751054073625125
Validation loss: 2.46933607395973

Epoch: 6| Step: 13
Training loss: 3.3940269174581785
Validation loss: 2.4889809999705106

Epoch: 138| Step: 0
Training loss: 2.2295069449659417
Validation loss: 2.4802546448724323

Epoch: 6| Step: 1
Training loss: 2.552870357893049
Validation loss: 2.4790551396721954

Epoch: 6| Step: 2
Training loss: 2.694326469180763
Validation loss: 2.4804750565963927

Epoch: 6| Step: 3
Training loss: 2.7499514488789445
Validation loss: 2.4739080532558173

Epoch: 6| Step: 4
Training loss: 2.904672666350723
Validation loss: 2.479343759221887

Epoch: 6| Step: 5
Training loss: 2.8620756142875425
Validation loss: 2.460812613838665

Epoch: 6| Step: 6
Training loss: 2.647330984136493
Validation loss: 2.4550028460567392

Epoch: 6| Step: 7
Training loss: 3.126200636054909
Validation loss: 2.4551722815177355

Epoch: 6| Step: 8
Training loss: 2.7645913471564763
Validation loss: 2.4552043898282863

Epoch: 6| Step: 9
Training loss: 2.0531754532512547
Validation loss: 2.452353614389756

Epoch: 6| Step: 10
Training loss: 2.228561949185762
Validation loss: 2.455634894043868

Epoch: 6| Step: 11
Training loss: 2.5630292578495895
Validation loss: 2.4638077974303867

Epoch: 6| Step: 12
Training loss: 3.272028872598045
Validation loss: 2.488244036831865

Epoch: 6| Step: 13
Training loss: 2.853578790047813
Validation loss: 2.500667346565515

Epoch: 139| Step: 0
Training loss: 2.8101077608236675
Validation loss: 2.5243879345804228

Epoch: 6| Step: 1
Training loss: 2.762286914184849
Validation loss: 2.537832881516031

Epoch: 6| Step: 2
Training loss: 2.793201442175237
Validation loss: 2.5416202572869415

Epoch: 6| Step: 3
Training loss: 2.1762672853961096
Validation loss: 2.5479031295751473

Epoch: 6| Step: 4
Training loss: 2.4741371384637385
Validation loss: 2.583216065779542

Epoch: 6| Step: 5
Training loss: 2.887716613835452
Validation loss: 2.584501081609306

Epoch: 6| Step: 6
Training loss: 3.014065512205273
Validation loss: 2.592922730609958

Epoch: 6| Step: 7
Training loss: 2.769981530606499
Validation loss: 2.5896691179758395

Epoch: 6| Step: 8
Training loss: 2.622816721916096
Validation loss: 2.530299419538917

Epoch: 6| Step: 9
Training loss: 2.938543256191043
Validation loss: 2.456469785948847

Epoch: 6| Step: 10
Training loss: 2.4765586491985045
Validation loss: 2.4235443596693913

Epoch: 6| Step: 11
Training loss: 2.446499764815677
Validation loss: 2.4059644235847495

Epoch: 6| Step: 12
Training loss: 2.7835444726257212
Validation loss: 2.406090007524228

Epoch: 6| Step: 13
Training loss: 2.830278114429232
Validation loss: 2.4007259801375027

Epoch: 140| Step: 0
Training loss: 2.9127105767742756
Validation loss: 2.407276244223778

Epoch: 6| Step: 1
Training loss: 2.936240555255587
Validation loss: 2.407287467224846

Epoch: 6| Step: 2
Training loss: 2.951751874156585
Validation loss: 2.399763368191987

Epoch: 6| Step: 3
Training loss: 3.191315555100906
Validation loss: 2.3998272691800007

Epoch: 6| Step: 4
Training loss: 2.5944554851695503
Validation loss: 2.3956450696455582

Epoch: 6| Step: 5
Training loss: 2.414072376218673
Validation loss: 2.4000387220266957

Epoch: 6| Step: 6
Training loss: 3.153118279471669
Validation loss: 2.421881711105697

Epoch: 6| Step: 7
Training loss: 2.9518087370197765
Validation loss: 2.4327661599057815

Epoch: 6| Step: 8
Training loss: 1.9524560622035019
Validation loss: 2.4754474573087175

Epoch: 6| Step: 9
Training loss: 2.9689241057088314
Validation loss: 2.4762232276239615

Epoch: 6| Step: 10
Training loss: 2.9863555886981104
Validation loss: 2.491850175999249

Epoch: 6| Step: 11
Training loss: 1.7716394123171313
Validation loss: 2.47809154651008

Epoch: 6| Step: 12
Training loss: 2.485539193555925
Validation loss: 2.4594327332547867

Epoch: 6| Step: 13
Training loss: 2.117615378523074
Validation loss: 2.4762251408626437

Epoch: 141| Step: 0
Training loss: 2.3237679693503
Validation loss: 2.4655324982740106

Epoch: 6| Step: 1
Training loss: 1.8429075353012272
Validation loss: 2.466656568978263

Epoch: 6| Step: 2
Training loss: 2.7579281704340897
Validation loss: 2.4463982848664685

Epoch: 6| Step: 3
Training loss: 3.5909726232740224
Validation loss: 2.4314717586306323

Epoch: 6| Step: 4
Training loss: 2.8348255341953887
Validation loss: 2.412258386412064

Epoch: 6| Step: 5
Training loss: 2.7114661852771405
Validation loss: 2.4008141763262705

Epoch: 6| Step: 6
Training loss: 2.661026642807563
Validation loss: 2.4034265926530427

Epoch: 6| Step: 7
Training loss: 3.011139216493239
Validation loss: 2.413963777009095

Epoch: 6| Step: 8
Training loss: 3.032526907428012
Validation loss: 2.4377279246046

Epoch: 6| Step: 9
Training loss: 2.935631015406767
Validation loss: 2.514902730529576

Epoch: 6| Step: 10
Training loss: 2.434243202804097
Validation loss: 2.5923612939047485

Epoch: 6| Step: 11
Training loss: 2.736899033863639
Validation loss: 2.6534278117736445

Epoch: 6| Step: 12
Training loss: 2.319526513551917
Validation loss: 2.631370364902644

Epoch: 6| Step: 13
Training loss: 2.5771314151341955
Validation loss: 2.5832774637223097

Epoch: 142| Step: 0
Training loss: 2.4508371557754787
Validation loss: 2.494986211296514

Epoch: 6| Step: 1
Training loss: 3.2746565194588837
Validation loss: 2.4758104615110375

Epoch: 6| Step: 2
Training loss: 2.520874233281862
Validation loss: 2.4816980802669137

Epoch: 6| Step: 3
Training loss: 2.819303379590975
Validation loss: 2.494418467729225

Epoch: 6| Step: 4
Training loss: 2.8807549305749247
Validation loss: 2.518275308933357

Epoch: 6| Step: 5
Training loss: 2.7575730173883026
Validation loss: 2.507501112025372

Epoch: 6| Step: 6
Training loss: 2.00247027904919
Validation loss: 2.489777942049599

Epoch: 6| Step: 7
Training loss: 2.601253548454273
Validation loss: 2.4729476244080217

Epoch: 6| Step: 8
Training loss: 2.3458622887169893
Validation loss: 2.4683877885100594

Epoch: 6| Step: 9
Training loss: 2.7414033208675397
Validation loss: 2.467612145937209

Epoch: 6| Step: 10
Training loss: 2.6200473931081034
Validation loss: 2.45374293813744

Epoch: 6| Step: 11
Training loss: 2.5649963872634998
Validation loss: 2.4477041417124297

Epoch: 6| Step: 12
Training loss: 3.1276099940533415
Validation loss: 2.4396033718326886

Epoch: 6| Step: 13
Training loss: 2.1341531752766043
Validation loss: 2.426862922584679

Epoch: 143| Step: 0
Training loss: 3.0508431441784842
Validation loss: 2.424287084029899

Epoch: 6| Step: 1
Training loss: 2.7840017357524856
Validation loss: 2.425970758802646

Epoch: 6| Step: 2
Training loss: 2.4250428186156094
Validation loss: 2.436923015280626

Epoch: 6| Step: 3
Training loss: 2.368344165992884
Validation loss: 2.4235026235601174

Epoch: 6| Step: 4
Training loss: 2.317159957876396
Validation loss: 2.433791873646511

Epoch: 6| Step: 5
Training loss: 2.690483743501873
Validation loss: 2.4351690583353776

Epoch: 6| Step: 6
Training loss: 2.576221202409905
Validation loss: 2.433835504167305

Epoch: 6| Step: 7
Training loss: 2.0131702704848062
Validation loss: 2.44111999434893

Epoch: 6| Step: 8
Training loss: 2.8282847491085112
Validation loss: 2.4240312126890347

Epoch: 6| Step: 9
Training loss: 2.607061948472615
Validation loss: 2.4331364584950634

Epoch: 6| Step: 10
Training loss: 2.815750024456331
Validation loss: 2.4417522782755348

Epoch: 6| Step: 11
Training loss: 2.2500001059638106
Validation loss: 2.452595767773151

Epoch: 6| Step: 12
Training loss: 3.200539340821099
Validation loss: 2.4381664281168716

Epoch: 6| Step: 13
Training loss: 3.099489994550452
Validation loss: 2.446725127443319

Epoch: 144| Step: 0
Training loss: 2.7416200403888604
Validation loss: 2.4837070629285107

Epoch: 6| Step: 1
Training loss: 2.721569309521762
Validation loss: 2.492336499547289

Epoch: 6| Step: 2
Training loss: 2.6975869133128425
Validation loss: 2.511961043770531

Epoch: 6| Step: 3
Training loss: 2.26156694762586
Validation loss: 2.4902109743483

Epoch: 6| Step: 4
Training loss: 3.145827202864646
Validation loss: 2.4908437131290806

Epoch: 6| Step: 5
Training loss: 2.8041869330465024
Validation loss: 2.4688706031708865

Epoch: 6| Step: 6
Training loss: 2.379078224618211
Validation loss: 2.472863451262475

Epoch: 6| Step: 7
Training loss: 2.473687172468234
Validation loss: 2.452089141022782

Epoch: 6| Step: 8
Training loss: 1.8662421095643593
Validation loss: 2.443679410495431

Epoch: 6| Step: 9
Training loss: 2.5011056362510007
Validation loss: 2.4542829117655844

Epoch: 6| Step: 10
Training loss: 2.9594611762610414
Validation loss: 2.4559167260881822

Epoch: 6| Step: 11
Training loss: 3.0844195918267707
Validation loss: 2.485809194943685

Epoch: 6| Step: 12
Training loss: 2.2980300179057283
Validation loss: 2.486112068203431

Epoch: 6| Step: 13
Training loss: 3.0372126816232488
Validation loss: 2.501919059063288

Epoch: 145| Step: 0
Training loss: 2.6194872416989985
Validation loss: 2.469884607297351

Epoch: 6| Step: 1
Training loss: 2.512704990811617
Validation loss: 2.4427606332288847

Epoch: 6| Step: 2
Training loss: 3.4502106533146777
Validation loss: 2.419441732022047

Epoch: 6| Step: 3
Training loss: 2.591811777286189
Validation loss: 2.4179710899608224

Epoch: 6| Step: 4
Training loss: 2.328857716205329
Validation loss: 2.429664493796503

Epoch: 6| Step: 5
Training loss: 3.164020001161343
Validation loss: 2.433984346182556

Epoch: 6| Step: 6
Training loss: 2.9426007726585977
Validation loss: 2.4306672297858176

Epoch: 6| Step: 7
Training loss: 2.6476459952094213
Validation loss: 2.436299969163289

Epoch: 6| Step: 8
Training loss: 2.5207438072091444
Validation loss: 2.4599515737923903

Epoch: 6| Step: 9
Training loss: 2.3597497705572037
Validation loss: 2.478446899051834

Epoch: 6| Step: 10
Training loss: 2.5987627239934152
Validation loss: 2.4721213431902234

Epoch: 6| Step: 11
Training loss: 1.7986945849293388
Validation loss: 2.4932511110580227

Epoch: 6| Step: 12
Training loss: 2.736653887834656
Validation loss: 2.4926513133298887

Epoch: 6| Step: 13
Training loss: 2.831982084702545
Validation loss: 2.502445515851104

Epoch: 146| Step: 0
Training loss: 1.8991189997160256
Validation loss: 2.4920020638649274

Epoch: 6| Step: 1
Training loss: 2.689007979199937
Validation loss: 2.484084989719807

Epoch: 6| Step: 2
Training loss: 2.399355138133565
Validation loss: 2.4873847976385846

Epoch: 6| Step: 3
Training loss: 2.1731972820119645
Validation loss: 2.4954997853943466

Epoch: 6| Step: 4
Training loss: 3.242851759184107
Validation loss: 2.501529904846516

Epoch: 6| Step: 5
Training loss: 2.3748731077327125
Validation loss: 2.5112937705889844

Epoch: 6| Step: 6
Training loss: 2.7582853522454163
Validation loss: 2.5080539067229974

Epoch: 6| Step: 7
Training loss: 2.5527489449421616
Validation loss: 2.55127082750488

Epoch: 6| Step: 8
Training loss: 2.9020867830809616
Validation loss: 2.532745730659896

Epoch: 6| Step: 9
Training loss: 2.4311048292737127
Validation loss: 2.523834657478964

Epoch: 6| Step: 10
Training loss: 3.0935191058685936
Validation loss: 2.477158014428875

Epoch: 6| Step: 11
Training loss: 2.911954797624476
Validation loss: 2.4343283469643424

Epoch: 6| Step: 12
Training loss: 2.1003523394781105
Validation loss: 2.419582795646244

Epoch: 6| Step: 13
Training loss: 3.074310727906532
Validation loss: 2.414141785780865

Epoch: 147| Step: 0
Training loss: 2.4239274710829943
Validation loss: 2.4059102948352438

Epoch: 6| Step: 1
Training loss: 3.1428739931224587
Validation loss: 2.4095215671672445

Epoch: 6| Step: 2
Training loss: 2.999658883092708
Validation loss: 2.419451977273459

Epoch: 6| Step: 3
Training loss: 3.0633414533284036
Validation loss: 2.416289700763278

Epoch: 6| Step: 4
Training loss: 2.3388482270238775
Validation loss: 2.426956145610319

Epoch: 6| Step: 5
Training loss: 2.550957152302504
Validation loss: 2.4355042372247726

Epoch: 6| Step: 6
Training loss: 2.3462383031375698
Validation loss: 2.416297341415324

Epoch: 6| Step: 7
Training loss: 2.502194966905014
Validation loss: 2.412817428748756

Epoch: 6| Step: 8
Training loss: 2.8006720315448557
Validation loss: 2.416720095529345

Epoch: 6| Step: 9
Training loss: 2.982520041258531
Validation loss: 2.4189340582715158

Epoch: 6| Step: 10
Training loss: 2.5050647929753023
Validation loss: 2.4302345000159544

Epoch: 6| Step: 11
Training loss: 2.7678315578983397
Validation loss: 2.4413118870372723

Epoch: 6| Step: 12
Training loss: 2.2272950155385063
Validation loss: 2.462852183996342

Epoch: 6| Step: 13
Training loss: 2.3167401180927207
Validation loss: 2.473532348295986

Epoch: 148| Step: 0
Training loss: 2.9675317774471583
Validation loss: 2.477016248122064

Epoch: 6| Step: 1
Training loss: 2.5000913603301695
Validation loss: 2.4616819288065166

Epoch: 6| Step: 2
Training loss: 2.5821688293646265
Validation loss: 2.4692630154310846

Epoch: 6| Step: 3
Training loss: 2.7540174096581516
Validation loss: 2.463101742122279

Epoch: 6| Step: 4
Training loss: 2.1117619325524912
Validation loss: 2.4541868439832824

Epoch: 6| Step: 5
Training loss: 2.9500850794533338
Validation loss: 2.426716174970977

Epoch: 6| Step: 6
Training loss: 2.758746715659506
Validation loss: 2.3911231016204377

Epoch: 6| Step: 7
Training loss: 2.3806709045967804
Validation loss: 2.381021647493189

Epoch: 6| Step: 8
Training loss: 2.9214030001870595
Validation loss: 2.377615940357901

Epoch: 6| Step: 9
Training loss: 2.3038690697899615
Validation loss: 2.3800454090119634

Epoch: 6| Step: 10
Training loss: 2.725776799625559
Validation loss: 2.3793425708879066

Epoch: 6| Step: 11
Training loss: 2.7433907241040414
Validation loss: 2.3805577006096454

Epoch: 6| Step: 12
Training loss: 2.5479001281484326
Validation loss: 2.393029494528318

Epoch: 6| Step: 13
Training loss: 2.9890759576952175
Validation loss: 2.4119727146600036

Epoch: 149| Step: 0
Training loss: 2.9657201464296117
Validation loss: 2.427757536770103

Epoch: 6| Step: 1
Training loss: 2.612753958884056
Validation loss: 2.4696366937551826

Epoch: 6| Step: 2
Training loss: 2.760803675363195
Validation loss: 2.494974776034112

Epoch: 6| Step: 3
Training loss: 2.8005045776765662
Validation loss: 2.539602102488432

Epoch: 6| Step: 4
Training loss: 2.5941038694622622
Validation loss: 2.56064116805726

Epoch: 6| Step: 5
Training loss: 2.533306087380844
Validation loss: 2.5753734608712633

Epoch: 6| Step: 6
Training loss: 2.161679825675322
Validation loss: 2.5447988588297323

Epoch: 6| Step: 7
Training loss: 2.3396581916914645
Validation loss: 2.5043979088035235

Epoch: 6| Step: 8
Training loss: 2.830132714923813
Validation loss: 2.472900518527101

Epoch: 6| Step: 9
Training loss: 2.2469837316273016
Validation loss: 2.438939412335155

Epoch: 6| Step: 10
Training loss: 3.280822435405661
Validation loss: 2.4120919276664283

Epoch: 6| Step: 11
Training loss: 2.3162331218897125
Validation loss: 2.4139614628999624

Epoch: 6| Step: 12
Training loss: 2.4928181487104677
Validation loss: 2.386046153565207

Epoch: 6| Step: 13
Training loss: 2.336344501672038
Validation loss: 2.3876457967010305

Epoch: 150| Step: 0
Training loss: 1.9326377894540483
Validation loss: 2.377912828147687

Epoch: 6| Step: 1
Training loss: 2.7620523081362633
Validation loss: 2.3854676874506735

Epoch: 6| Step: 2
Training loss: 2.8709622099969323
Validation loss: 2.3945443929339554

Epoch: 6| Step: 3
Training loss: 3.1077569940289003
Validation loss: 2.3848310501264183

Epoch: 6| Step: 4
Training loss: 2.897585843964684
Validation loss: 2.395291464486024

Epoch: 6| Step: 5
Training loss: 2.170481612206047
Validation loss: 2.404379032185079

Epoch: 6| Step: 6
Training loss: 2.2085780841823692
Validation loss: 2.418428784955674

Epoch: 6| Step: 7
Training loss: 2.2857170786159346
Validation loss: 2.4335311159719764

Epoch: 6| Step: 8
Training loss: 3.0716661570468036
Validation loss: 2.4413740967304753

Epoch: 6| Step: 9
Training loss: 2.9204336272908398
Validation loss: 2.435753456645964

Epoch: 6| Step: 10
Training loss: 2.1969268402017237
Validation loss: 2.449662597641529

Epoch: 6| Step: 11
Training loss: 2.679645326688452
Validation loss: 2.464459910981309

Epoch: 6| Step: 12
Training loss: 2.4022238600673655
Validation loss: 2.500951169687779

Epoch: 6| Step: 13
Training loss: 2.657222435165391
Validation loss: 2.5156543271136074

Epoch: 151| Step: 0
Training loss: 2.180899771743784
Validation loss: 2.507252633716354

Epoch: 6| Step: 1
Training loss: 2.8171587188824643
Validation loss: 2.4893667880582115

Epoch: 6| Step: 2
Training loss: 2.238838698921295
Validation loss: 2.4688739877876875

Epoch: 6| Step: 3
Training loss: 2.0205209103837793
Validation loss: 2.476364199746843

Epoch: 6| Step: 4
Training loss: 1.7940095029258163
Validation loss: 2.476681594466887

Epoch: 6| Step: 5
Training loss: 2.712833148520459
Validation loss: 2.4856362103414953

Epoch: 6| Step: 6
Training loss: 2.111606350192627
Validation loss: 2.4682342698821995

Epoch: 6| Step: 7
Training loss: 2.7753243918304245
Validation loss: 2.4788404077524997

Epoch: 6| Step: 8
Training loss: 3.3383912971582426
Validation loss: 2.4880491425895346

Epoch: 6| Step: 9
Training loss: 3.589790219311506
Validation loss: 2.475949509516463

Epoch: 6| Step: 10
Training loss: 2.149586762037782
Validation loss: 2.4826467184095384

Epoch: 6| Step: 11
Training loss: 2.8871770967208765
Validation loss: 2.470347809938593

Epoch: 6| Step: 12
Training loss: 2.5556218016602803
Validation loss: 2.467418198754636

Epoch: 6| Step: 13
Training loss: 2.4183011173211795
Validation loss: 2.4611591187886765

Epoch: 152| Step: 0
Training loss: 2.326357586651648
Validation loss: 2.4553920599856256

Epoch: 6| Step: 1
Training loss: 2.4006582907047074
Validation loss: 2.4388681836214485

Epoch: 6| Step: 2
Training loss: 1.6107001913310124
Validation loss: 2.445608128048047

Epoch: 6| Step: 3
Training loss: 2.597031321680779
Validation loss: 2.4503595709446633

Epoch: 6| Step: 4
Training loss: 1.7191494564218741
Validation loss: 2.445862770382083

Epoch: 6| Step: 5
Training loss: 2.7824376174500696
Validation loss: 2.4478593521547394

Epoch: 6| Step: 6
Training loss: 3.0072242855235096
Validation loss: 2.4501506225045278

Epoch: 6| Step: 7
Training loss: 2.053059560351236
Validation loss: 2.451865165405302

Epoch: 6| Step: 8
Training loss: 2.5618396001093107
Validation loss: 2.4535169558064314

Epoch: 6| Step: 9
Training loss: 2.8900058392528427
Validation loss: 2.4461339735566896

Epoch: 6| Step: 10
Training loss: 2.913601999995861
Validation loss: 2.4365486926427646

Epoch: 6| Step: 11
Training loss: 3.3901681899937226
Validation loss: 2.42348646153344

Epoch: 6| Step: 12
Training loss: 2.4799590781127354
Validation loss: 2.4079276997440897

Epoch: 6| Step: 13
Training loss: 2.735533637756019
Validation loss: 2.3983298646274878

Epoch: 153| Step: 0
Training loss: 2.5655235502789937
Validation loss: 2.398907152797383

Epoch: 6| Step: 1
Training loss: 2.442379883982151
Validation loss: 2.4061506304381064

Epoch: 6| Step: 2
Training loss: 2.5685273902387604
Validation loss: 2.419655168446337

Epoch: 6| Step: 3
Training loss: 2.480965824333094
Validation loss: 2.4099989613513038

Epoch: 6| Step: 4
Training loss: 2.262399943125669
Validation loss: 2.4500162169719415

Epoch: 6| Step: 5
Training loss: 2.244178127576382
Validation loss: 2.4363357849478926

Epoch: 6| Step: 6
Training loss: 3.3270304854624175
Validation loss: 2.4263623422925313

Epoch: 6| Step: 7
Training loss: 2.4440965645750934
Validation loss: 2.426930582548446

Epoch: 6| Step: 8
Training loss: 1.7847941425772815
Validation loss: 2.429594976892947

Epoch: 6| Step: 9
Training loss: 2.917132113420796
Validation loss: 2.4399527921082247

Epoch: 6| Step: 10
Training loss: 2.2610054011189713
Validation loss: 2.4190898694107354

Epoch: 6| Step: 11
Training loss: 3.0705423438937514
Validation loss: 2.4300712274783636

Epoch: 6| Step: 12
Training loss: 2.6767998531676693
Validation loss: 2.425256098257216

Epoch: 6| Step: 13
Training loss: 2.4546954722429817
Validation loss: 2.4270414661900195

Epoch: 154| Step: 0
Training loss: 2.5092355843814316
Validation loss: 2.424704039874017

Epoch: 6| Step: 1
Training loss: 1.9781448001684179
Validation loss: 2.4336677065589654

Epoch: 6| Step: 2
Training loss: 2.376831954337571
Validation loss: 2.452287279970422

Epoch: 6| Step: 3
Training loss: 2.6202102741279663
Validation loss: 2.4827702254312447

Epoch: 6| Step: 4
Training loss: 2.322870251201831
Validation loss: 2.491941721955814

Epoch: 6| Step: 5
Training loss: 3.204408565231607
Validation loss: 2.524119859990814

Epoch: 6| Step: 6
Training loss: 2.7864653305013394
Validation loss: 2.5090084961031947

Epoch: 6| Step: 7
Training loss: 2.7378598050769254
Validation loss: 2.5076083664783178

Epoch: 6| Step: 8
Training loss: 2.0752891752669615
Validation loss: 2.5199043747415573

Epoch: 6| Step: 9
Training loss: 2.2209670045094385
Validation loss: 2.530230969402515

Epoch: 6| Step: 10
Training loss: 2.7166125785576307
Validation loss: 2.516801311827462

Epoch: 6| Step: 11
Training loss: 2.1533887372206784
Validation loss: 2.5033697920755977

Epoch: 6| Step: 12
Training loss: 3.1509910053983137
Validation loss: 2.4845047133472002

Epoch: 6| Step: 13
Training loss: 2.8757809117448354
Validation loss: 2.4239647250787892

Epoch: 155| Step: 0
Training loss: 2.484596674404208
Validation loss: 2.4028945484848054

Epoch: 6| Step: 1
Training loss: 2.6904079761771427
Validation loss: 2.4007985038611577

Epoch: 6| Step: 2
Training loss: 2.0475264815596375
Validation loss: 2.4057174517335396

Epoch: 6| Step: 3
Training loss: 2.6422611562432183
Validation loss: 2.4179411283248586

Epoch: 6| Step: 4
Training loss: 2.6172739498606914
Validation loss: 2.4273880287536316

Epoch: 6| Step: 5
Training loss: 2.499100904914961
Validation loss: 2.4601031395434854

Epoch: 6| Step: 6
Training loss: 2.5999366789222997
Validation loss: 2.4674802884469673

Epoch: 6| Step: 7
Training loss: 2.3894005924803015
Validation loss: 2.415333618535191

Epoch: 6| Step: 8
Training loss: 2.835154527761946
Validation loss: 2.3889750551520543

Epoch: 6| Step: 9
Training loss: 2.7395013330368974
Validation loss: 2.3775954235184678

Epoch: 6| Step: 10
Training loss: 2.7053431412093056
Validation loss: 2.3672720848893314

Epoch: 6| Step: 11
Training loss: 2.653543237581517
Validation loss: 2.3783639013154994

Epoch: 6| Step: 12
Training loss: 2.59095291620816
Validation loss: 2.3686696050732188

Epoch: 6| Step: 13
Training loss: 2.525648536109904
Validation loss: 2.373864233161876

Epoch: 156| Step: 0
Training loss: 2.26408997197198
Validation loss: 2.3722400053313444

Epoch: 6| Step: 1
Training loss: 2.2068083794066014
Validation loss: 2.385524695902528

Epoch: 6| Step: 2
Training loss: 3.0082206944506242
Validation loss: 2.3885546035265635

Epoch: 6| Step: 3
Training loss: 2.836261320936357
Validation loss: 2.396562732951558

Epoch: 6| Step: 4
Training loss: 1.5645415129915932
Validation loss: 2.3953706106341026

Epoch: 6| Step: 5
Training loss: 2.2265194537368527
Validation loss: 2.418023320223273

Epoch: 6| Step: 6
Training loss: 2.011939531081214
Validation loss: 2.429110006251584

Epoch: 6| Step: 7
Training loss: 2.8426806776454145
Validation loss: 2.4704468226750786

Epoch: 6| Step: 8
Training loss: 2.962297031837622
Validation loss: 2.5218106545464214

Epoch: 6| Step: 9
Training loss: 2.471879834195702
Validation loss: 2.514046115121176

Epoch: 6| Step: 10
Training loss: 3.2858020995826984
Validation loss: 2.5104639195865457

Epoch: 6| Step: 11
Training loss: 2.4839026043974277
Validation loss: 2.4955221117247377

Epoch: 6| Step: 12
Training loss: 2.775312622606369
Validation loss: 2.4921862645660022

Epoch: 6| Step: 13
Training loss: 2.5907319676089076
Validation loss: 2.4703298622456193

Epoch: 157| Step: 0
Training loss: 2.6856058232166746
Validation loss: 2.461912936832698

Epoch: 6| Step: 1
Training loss: 2.118842910034811
Validation loss: 2.4665520945178225

Epoch: 6| Step: 2
Training loss: 3.0171274188088453
Validation loss: 2.4600333531370744

Epoch: 6| Step: 3
Training loss: 2.627925151252588
Validation loss: 2.4488112602998213

Epoch: 6| Step: 4
Training loss: 2.7098780603881147
Validation loss: 2.4410893842591905

Epoch: 6| Step: 5
Training loss: 1.9894785695346646
Validation loss: 2.434076070505146

Epoch: 6| Step: 6
Training loss: 2.596102647195012
Validation loss: 2.413780004985957

Epoch: 6| Step: 7
Training loss: 2.8078814413685165
Validation loss: 2.411166923494078

Epoch: 6| Step: 8
Training loss: 2.282202534840889
Validation loss: 2.3958297329983047

Epoch: 6| Step: 9
Training loss: 3.0469174113133994
Validation loss: 2.3802768674700623

Epoch: 6| Step: 10
Training loss: 1.983104990254996
Validation loss: 2.3829252784220416

Epoch: 6| Step: 11
Training loss: 1.9135192723037584
Validation loss: 2.3852990716096243

Epoch: 6| Step: 12
Training loss: 2.717373027905909
Validation loss: 2.3791767034449496

Epoch: 6| Step: 13
Training loss: 2.603409395103971
Validation loss: 2.4051681833330396

Epoch: 158| Step: 0
Training loss: 2.2742169803781547
Validation loss: 2.427021644445947

Epoch: 6| Step: 1
Training loss: 2.920338762307089
Validation loss: 2.4543376627024363

Epoch: 6| Step: 2
Training loss: 2.667879563903265
Validation loss: 2.4566379368415134

Epoch: 6| Step: 3
Training loss: 2.6258901267617247
Validation loss: 2.470688459294551

Epoch: 6| Step: 4
Training loss: 2.451889893435272
Validation loss: 2.4561106389525644

Epoch: 6| Step: 5
Training loss: 2.004490460459465
Validation loss: 2.4687633563368743

Epoch: 6| Step: 6
Training loss: 2.482898201252561
Validation loss: 2.4457443103988354

Epoch: 6| Step: 7
Training loss: 2.37275650068861
Validation loss: 2.4335116341598346

Epoch: 6| Step: 8
Training loss: 2.6611742040932325
Validation loss: 2.4363570834994346

Epoch: 6| Step: 9
Training loss: 2.2898906993185153
Validation loss: 2.4188259359475377

Epoch: 6| Step: 10
Training loss: 2.4770985694033825
Validation loss: 2.444289030132574

Epoch: 6| Step: 11
Training loss: 2.656026673746028
Validation loss: 2.4460138046978126

Epoch: 6| Step: 12
Training loss: 2.072837585269822
Validation loss: 2.4667051223206142

Epoch: 6| Step: 13
Training loss: 2.676526577024239
Validation loss: 2.481895061892806

Epoch: 159| Step: 0
Training loss: 2.440896235791052
Validation loss: 2.4549608918462114

Epoch: 6| Step: 1
Training loss: 2.6332782820085776
Validation loss: 2.454685646674131

Epoch: 6| Step: 2
Training loss: 2.6304515361081027
Validation loss: 2.4572374975388382

Epoch: 6| Step: 3
Training loss: 3.150249253357005
Validation loss: 2.4647243352454935

Epoch: 6| Step: 4
Training loss: 1.8034318130712852
Validation loss: 2.4398826121801

Epoch: 6| Step: 5
Training loss: 2.3733014507866783
Validation loss: 2.4563743985854374

Epoch: 6| Step: 6
Training loss: 2.0963624057647356
Validation loss: 2.454245948238656

Epoch: 6| Step: 7
Training loss: 2.5286984240127355
Validation loss: 2.472303292120213

Epoch: 6| Step: 8
Training loss: 2.9544858673062397
Validation loss: 2.4726874895093474

Epoch: 6| Step: 9
Training loss: 2.2939056094238683
Validation loss: 2.4801253961181535

Epoch: 6| Step: 10
Training loss: 2.2703908319999218
Validation loss: 2.45812521165291

Epoch: 6| Step: 11
Training loss: 2.4850805468332946
Validation loss: 2.4616899039750204

Epoch: 6| Step: 12
Training loss: 2.427803707590532
Validation loss: 2.4432921364083136

Epoch: 6| Step: 13
Training loss: 1.2630855845210047
Validation loss: 2.419279534661708

Epoch: 160| Step: 0
Training loss: 2.0626214887500014
Validation loss: 2.4055191419551663

Epoch: 6| Step: 1
Training loss: 2.3677672629876496
Validation loss: 2.3979045936858796

Epoch: 6| Step: 2
Training loss: 2.062361625884663
Validation loss: 2.401711713150924

Epoch: 6| Step: 3
Training loss: 2.7100050144219545
Validation loss: 2.3969086465371006

Epoch: 6| Step: 4
Training loss: 2.1716545596874584
Validation loss: 2.39199172561443

Epoch: 6| Step: 5
Training loss: 2.410176232253571
Validation loss: 2.388450009021617

Epoch: 6| Step: 6
Training loss: 2.259412152629896
Validation loss: 2.4005352916418325

Epoch: 6| Step: 7
Training loss: 2.7074093245013264
Validation loss: 2.4077392080181297

Epoch: 6| Step: 8
Training loss: 2.51908570127849
Validation loss: 2.4199768588265558

Epoch: 6| Step: 9
Training loss: 2.3026647969768264
Validation loss: 2.429383485363795

Epoch: 6| Step: 10
Training loss: 2.6845243081612056
Validation loss: 2.4439899739768935

Epoch: 6| Step: 11
Training loss: 2.598797035690714
Validation loss: 2.4425387809169288

Epoch: 6| Step: 12
Training loss: 2.6055666606298598
Validation loss: 2.452868928248711

Epoch: 6| Step: 13
Training loss: 2.693836371858162
Validation loss: 2.4630263180909178

Epoch: 161| Step: 0
Training loss: 2.7868766874662
Validation loss: 2.4863144278955573

Epoch: 6| Step: 1
Training loss: 2.3540763725136347
Validation loss: 2.493450442319427

Epoch: 6| Step: 2
Training loss: 2.329200854474212
Validation loss: 2.485732559156332

Epoch: 6| Step: 3
Training loss: 2.877153170817843
Validation loss: 2.4746304026721826

Epoch: 6| Step: 4
Training loss: 2.99958830233759
Validation loss: 2.456046675766429

Epoch: 6| Step: 5
Training loss: 1.853933498280384
Validation loss: 2.4335522231115894

Epoch: 6| Step: 6
Training loss: 2.2014049552173423
Validation loss: 2.4063019093674356

Epoch: 6| Step: 7
Training loss: 1.9731328709481315
Validation loss: 2.3843602117083806

Epoch: 6| Step: 8
Training loss: 2.1150556015028847
Validation loss: 2.420505408732039

Epoch: 6| Step: 9
Training loss: 2.8263873246855367
Validation loss: 2.406025703885134

Epoch: 6| Step: 10
Training loss: 2.263429406570444
Validation loss: 2.4176075143174156

Epoch: 6| Step: 11
Training loss: 2.247551963807976
Validation loss: 2.3875245641788974

Epoch: 6| Step: 12
Training loss: 2.5391930179795614
Validation loss: 2.379912783069176

Epoch: 6| Step: 13
Training loss: 2.7273123073595733
Validation loss: 2.353540621695268

Epoch: 162| Step: 0
Training loss: 2.4775007618615206
Validation loss: 2.3320630563099223

Epoch: 6| Step: 1
Training loss: 2.3104623632380807
Validation loss: 2.3273972048654272

Epoch: 6| Step: 2
Training loss: 2.495994410679746
Validation loss: 2.3323637217475977

Epoch: 6| Step: 3
Training loss: 1.8718549418449406
Validation loss: 2.3429887056124046

Epoch: 6| Step: 4
Training loss: 2.25860085633043
Validation loss: 2.3601325968222477

Epoch: 6| Step: 5
Training loss: 2.74386189087058
Validation loss: 2.378577878736192

Epoch: 6| Step: 6
Training loss: 2.291377332513363
Validation loss: 2.3869338461876515

Epoch: 6| Step: 7
Training loss: 2.3236544909864385
Validation loss: 2.416434201172571

Epoch: 6| Step: 8
Training loss: 2.5157519954115095
Validation loss: 2.4326070588198405

Epoch: 6| Step: 9
Training loss: 2.595927416064459
Validation loss: 2.4674577530615514

Epoch: 6| Step: 10
Training loss: 2.768660695032884
Validation loss: 2.4615365820933537

Epoch: 6| Step: 11
Training loss: 2.4110613194709045
Validation loss: 2.483240810927272

Epoch: 6| Step: 12
Training loss: 2.5002913305289667
Validation loss: 2.484566162456936

Epoch: 6| Step: 13
Training loss: 2.444833726904444
Validation loss: 2.495026705411111

Epoch: 163| Step: 0
Training loss: 2.3092869268200693
Validation loss: 2.4829788108009687

Epoch: 6| Step: 1
Training loss: 2.467331200945157
Validation loss: 2.475952919142858

Epoch: 6| Step: 2
Training loss: 2.3478846383357213
Validation loss: 2.490074063697955

Epoch: 6| Step: 3
Training loss: 1.8446047466521005
Validation loss: 2.497205693374651

Epoch: 6| Step: 4
Training loss: 2.423641225293139
Validation loss: 2.5027909789151646

Epoch: 6| Step: 5
Training loss: 2.6628478740826695
Validation loss: 2.491406676167878

Epoch: 6| Step: 6
Training loss: 2.3352178275143665
Validation loss: 2.4840652108601526

Epoch: 6| Step: 7
Training loss: 2.7080548265505104
Validation loss: 2.4872160774827354

Epoch: 6| Step: 8
Training loss: 2.391619107862346
Validation loss: 2.47686782879637

Epoch: 6| Step: 9
Training loss: 2.391631469290347
Validation loss: 2.4600338825320525

Epoch: 6| Step: 10
Training loss: 2.4149796308523266
Validation loss: 2.465364004642749

Epoch: 6| Step: 11
Training loss: 2.1793851471805015
Validation loss: 2.4463797265776077

Epoch: 6| Step: 12
Training loss: 2.635760459539759
Validation loss: 2.433405879952656

Epoch: 6| Step: 13
Training loss: 2.3078999517629466
Validation loss: 2.430106820689371

Epoch: 164| Step: 0
Training loss: 2.2896733949793515
Validation loss: 2.4154047240122076

Epoch: 6| Step: 1
Training loss: 2.3723069030195605
Validation loss: 2.4104151927461235

Epoch: 6| Step: 2
Training loss: 2.130571914150275
Validation loss: 2.412849276188336

Epoch: 6| Step: 3
Training loss: 2.6483423446620398
Validation loss: 2.4154085046129103

Epoch: 6| Step: 4
Training loss: 1.9259101251962023
Validation loss: 2.422324014535403

Epoch: 6| Step: 5
Training loss: 2.286143867110714
Validation loss: 2.435657017991044

Epoch: 6| Step: 6
Training loss: 2.5478738335673814
Validation loss: 2.434006063442376

Epoch: 6| Step: 7
Training loss: 1.87197307399801
Validation loss: 2.4249908198868018

Epoch: 6| Step: 8
Training loss: 2.2307594764556926
Validation loss: 2.417544104508927

Epoch: 6| Step: 9
Training loss: 2.581613296177128
Validation loss: 2.421006358197639

Epoch: 6| Step: 10
Training loss: 2.497912966290921
Validation loss: 2.4262728020095494

Epoch: 6| Step: 11
Training loss: 3.0085201075121115
Validation loss: 2.427963277592148

Epoch: 6| Step: 12
Training loss: 2.0736468257612004
Validation loss: 2.4704547135117

Epoch: 6| Step: 13
Training loss: 2.6361048909274607
Validation loss: 2.471912929570135

Epoch: 165| Step: 0
Training loss: 1.975273284836665
Validation loss: 2.4570984569294474

Epoch: 6| Step: 1
Training loss: 2.5738614055724165
Validation loss: 2.449883320348592

Epoch: 6| Step: 2
Training loss: 2.4103219394209674
Validation loss: 2.4706410945103103

Epoch: 6| Step: 3
Training loss: 2.443633847025044
Validation loss: 2.453944285556424

Epoch: 6| Step: 4
Training loss: 2.138928931826121
Validation loss: 2.4298912637918004

Epoch: 6| Step: 5
Training loss: 2.3815220074226437
Validation loss: 2.3977377468232626

Epoch: 6| Step: 6
Training loss: 2.326694740446664
Validation loss: 2.3645516645023736

Epoch: 6| Step: 7
Training loss: 2.4148897895385777
Validation loss: 2.346749725893655

Epoch: 6| Step: 8
Training loss: 2.9317300822252403
Validation loss: 2.350234597888386

Epoch: 6| Step: 9
Training loss: 2.588461666802619
Validation loss: 2.341968492080793

Epoch: 6| Step: 10
Training loss: 2.1350586629844073
Validation loss: 2.3509264806656978

Epoch: 6| Step: 11
Training loss: 2.1268374408966944
Validation loss: 2.3885298530522556

Epoch: 6| Step: 12
Training loss: 2.4726854657078805
Validation loss: 2.3961767399070157

Epoch: 6| Step: 13
Training loss: 2.03775122562241
Validation loss: 2.4001878195337776

Epoch: 166| Step: 0
Training loss: 2.265864287269375
Validation loss: 2.4005206324444646

Epoch: 6| Step: 1
Training loss: 2.7657477572508817
Validation loss: 2.423498602765568

Epoch: 6| Step: 2
Training loss: 2.4046893322437586
Validation loss: 2.438501818440944

Epoch: 6| Step: 3
Training loss: 2.0648217282688717
Validation loss: 2.4572179272032124

Epoch: 6| Step: 4
Training loss: 2.1397981926426652
Validation loss: 2.4496292984622636

Epoch: 6| Step: 5
Training loss: 2.963942640874407
Validation loss: 2.437287737089468

Epoch: 6| Step: 6
Training loss: 2.2501449538268465
Validation loss: 2.4176638921585787

Epoch: 6| Step: 7
Training loss: 1.619046971243507
Validation loss: 2.401621499328528

Epoch: 6| Step: 8
Training loss: 1.8863859337223214
Validation loss: 2.364084309744913

Epoch: 6| Step: 9
Training loss: 3.1649456534156646
Validation loss: 2.359863456152559

Epoch: 6| Step: 10
Training loss: 2.167024313923642
Validation loss: 2.3440111437281397

Epoch: 6| Step: 11
Training loss: 2.2564169190604093
Validation loss: 2.3496956297164893

Epoch: 6| Step: 12
Training loss: 2.189140358737627
Validation loss: 2.354526925261252

Epoch: 6| Step: 13
Training loss: 2.386272382436404
Validation loss: 2.337516849710002

Epoch: 167| Step: 0
Training loss: 2.8096492306760426
Validation loss: 2.3488836036230696

Epoch: 6| Step: 1
Training loss: 2.24397658370205
Validation loss: 2.3722598725336446

Epoch: 6| Step: 2
Training loss: 2.5589130697388343
Validation loss: 2.37732459068231

Epoch: 6| Step: 3
Training loss: 2.6695068751230715
Validation loss: 2.393547498534619

Epoch: 6| Step: 4
Training loss: 3.0726275464270802
Validation loss: 2.4053422877542

Epoch: 6| Step: 5
Training loss: 1.8128545348593021
Validation loss: 2.433766301274709

Epoch: 6| Step: 6
Training loss: 1.955052820550685
Validation loss: 2.454831353070179

Epoch: 6| Step: 7
Training loss: 2.101704078641826
Validation loss: 2.484812336786478

Epoch: 6| Step: 8
Training loss: 2.329713522690899
Validation loss: 2.43010243947902

Epoch: 6| Step: 9
Training loss: 2.2660337934339414
Validation loss: 2.3835638262094956

Epoch: 6| Step: 10
Training loss: 2.0371483481785444
Validation loss: 2.3843419742631538

Epoch: 6| Step: 11
Training loss: 2.2682249738535503
Validation loss: 2.392573758645141

Epoch: 6| Step: 12
Training loss: 2.020660497870993
Validation loss: 2.3930878590418243

Epoch: 6| Step: 13
Training loss: 2.7754953406254783
Validation loss: 2.4157124139236306

Epoch: 168| Step: 0
Training loss: 2.573591650843336
Validation loss: 2.4521291035997974

Epoch: 6| Step: 1
Training loss: 2.9343746684991325
Validation loss: 2.518148562945633

Epoch: 6| Step: 2
Training loss: 2.191091259844296
Validation loss: 2.532710633456799

Epoch: 6| Step: 3
Training loss: 1.8832955275035288
Validation loss: 2.541859794096446

Epoch: 6| Step: 4
Training loss: 2.1604926345794992
Validation loss: 2.5677735773146035

Epoch: 6| Step: 5
Training loss: 2.723574687327963
Validation loss: 2.559289226807309

Epoch: 6| Step: 6
Training loss: 2.3120384786763135
Validation loss: 2.5394016864096574

Epoch: 6| Step: 7
Training loss: 1.7979018221434258
Validation loss: 2.515541743293934

Epoch: 6| Step: 8
Training loss: 2.097860486194769
Validation loss: 2.494207046827846

Epoch: 6| Step: 9
Training loss: 2.6214428369320295
Validation loss: 2.471741255272555

Epoch: 6| Step: 10
Training loss: 2.3660366168892946
Validation loss: 2.4507470656095487

Epoch: 6| Step: 11
Training loss: 2.380991055083666
Validation loss: 2.427289785425838

Epoch: 6| Step: 12
Training loss: 2.0221861280054334
Validation loss: 2.4025853664236636

Epoch: 6| Step: 13
Training loss: 2.2888431378867087
Validation loss: 2.3722149960219214

Epoch: 169| Step: 0
Training loss: 2.0173358605607046
Validation loss: 2.3574441355366478

Epoch: 6| Step: 1
Training loss: 2.055765195701094
Validation loss: 2.3386819792222218

Epoch: 6| Step: 2
Training loss: 2.383089443434752
Validation loss: 2.342135229020474

Epoch: 6| Step: 3
Training loss: 2.235164582851308
Validation loss: 2.3475034725902595

Epoch: 6| Step: 4
Training loss: 2.866757727071239
Validation loss: 2.3443314769628443

Epoch: 6| Step: 5
Training loss: 2.1687187478399927
Validation loss: 2.3392059269265584

Epoch: 6| Step: 6
Training loss: 2.8472987239660217
Validation loss: 2.344593310389793

Epoch: 6| Step: 7
Training loss: 2.047183879813573
Validation loss: 2.3374980002936443

Epoch: 6| Step: 8
Training loss: 2.5656194540467996
Validation loss: 2.350064300071102

Epoch: 6| Step: 9
Training loss: 2.019567611042346
Validation loss: 2.3965142968076725

Epoch: 6| Step: 10
Training loss: 2.79550017765804
Validation loss: 2.432477098979035

Epoch: 6| Step: 11
Training loss: 1.6083698281741385
Validation loss: 2.425946789517795

Epoch: 6| Step: 12
Training loss: 2.319753457485434
Validation loss: 2.442914555294458

Epoch: 6| Step: 13
Training loss: 1.7311372520558046
Validation loss: 2.4470170123135255

Epoch: 170| Step: 0
Training loss: 1.8508778525535503
Validation loss: 2.4388394951944945

Epoch: 6| Step: 1
Training loss: 2.9980087029328866
Validation loss: 2.452733845952706

Epoch: 6| Step: 2
Training loss: 2.20176319212008
Validation loss: 2.442580117238477

Epoch: 6| Step: 3
Training loss: 2.1689774099943775
Validation loss: 2.4391161259928067

Epoch: 6| Step: 4
Training loss: 2.6478872262041886
Validation loss: 2.42029524562348

Epoch: 6| Step: 5
Training loss: 1.7181448131097443
Validation loss: 2.4657879639798983

Epoch: 6| Step: 6
Training loss: 2.0023608578692684
Validation loss: 2.4726011478145105

Epoch: 6| Step: 7
Training loss: 2.7444749295922084
Validation loss: 2.489535133848437

Epoch: 6| Step: 8
Training loss: 2.562710544031263
Validation loss: 2.4509794133441956

Epoch: 6| Step: 9
Training loss: 1.8576495715950219
Validation loss: 2.4302672416061335

Epoch: 6| Step: 10
Training loss: 2.363407352330384
Validation loss: 2.402125342100404

Epoch: 6| Step: 11
Training loss: 2.1316799188857622
Validation loss: 2.3961830244206306

Epoch: 6| Step: 12
Training loss: 2.658291738856379
Validation loss: 2.4243381186450894

Epoch: 6| Step: 13
Training loss: 1.4341210167443068
Validation loss: 2.430916693051693

Epoch: 171| Step: 0
Training loss: 2.365381540245171
Validation loss: 2.4752601674068826

Epoch: 6| Step: 1
Training loss: 2.6083622411846465
Validation loss: 2.4588387812489394

Epoch: 6| Step: 2
Training loss: 2.8199704456809758
Validation loss: 2.4408738120689053

Epoch: 6| Step: 3
Training loss: 2.402892507510256
Validation loss: 2.401744426219296

Epoch: 6| Step: 4
Training loss: 1.945195389864881
Validation loss: 2.371273928285688

Epoch: 6| Step: 5
Training loss: 2.1641198987268875
Validation loss: 2.3703722909948572

Epoch: 6| Step: 6
Training loss: 1.9194284389041376
Validation loss: 2.346167037680414

Epoch: 6| Step: 7
Training loss: 2.414778421160671
Validation loss: 2.339841933418092

Epoch: 6| Step: 8
Training loss: 2.427979583509852
Validation loss: 2.3423206556732303

Epoch: 6| Step: 9
Training loss: 1.8653618094965838
Validation loss: 2.373218029782076

Epoch: 6| Step: 10
Training loss: 1.9915570626632806
Validation loss: 2.4050482098157073

Epoch: 6| Step: 11
Training loss: 2.7879608286564577
Validation loss: 2.4615210931569864

Epoch: 6| Step: 12
Training loss: 2.770567018335485
Validation loss: 2.473671423828899

Epoch: 6| Step: 13
Training loss: 1.9889778161132725
Validation loss: 2.4940421885078834

Epoch: 172| Step: 0
Training loss: 2.0533079440334823
Validation loss: 2.518167109997935

Epoch: 6| Step: 1
Training loss: 2.128446812881664
Validation loss: 2.5392573981187807

Epoch: 6| Step: 2
Training loss: 3.0377481555432384
Validation loss: 2.5192512948734276

Epoch: 6| Step: 3
Training loss: 2.0471027043774055
Validation loss: 2.4550063714475896

Epoch: 6| Step: 4
Training loss: 2.251550775797893
Validation loss: 2.417867016237934

Epoch: 6| Step: 5
Training loss: 2.1435980651220325
Validation loss: 2.3938096526013006

Epoch: 6| Step: 6
Training loss: 2.386664806699117
Validation loss: 2.366109329506934

Epoch: 6| Step: 7
Training loss: 2.4539600093166634
Validation loss: 2.366015478463871

Epoch: 6| Step: 8
Training loss: 2.6425654938953484
Validation loss: 2.3686589453537796

Epoch: 6| Step: 9
Training loss: 1.957818092039849
Validation loss: 2.368374355642954

Epoch: 6| Step: 10
Training loss: 1.8294838965521205
Validation loss: 2.3793885089248756

Epoch: 6| Step: 11
Training loss: 2.291773105808221
Validation loss: 2.4078627478063708

Epoch: 6| Step: 12
Training loss: 2.6917458639707452
Validation loss: 2.432331988589861

Epoch: 6| Step: 13
Training loss: 2.533945414568686
Validation loss: 2.442692266720519

Epoch: 173| Step: 0
Training loss: 2.3614883557803297
Validation loss: 2.444375687024025

Epoch: 6| Step: 1
Training loss: 2.209141193628196
Validation loss: 2.4458743451183658

Epoch: 6| Step: 2
Training loss: 2.2084264075860416
Validation loss: 2.4539857462965897

Epoch: 6| Step: 3
Training loss: 1.7667108758157306
Validation loss: 2.465083028066503

Epoch: 6| Step: 4
Training loss: 2.172321959685811
Validation loss: 2.487565548732361

Epoch: 6| Step: 5
Training loss: 2.2620743914985066
Validation loss: 2.535564782618827

Epoch: 6| Step: 6
Training loss: 2.830760423381845
Validation loss: 2.5513109784224306

Epoch: 6| Step: 7
Training loss: 2.6980002450455087
Validation loss: 2.5583324001746526

Epoch: 6| Step: 8
Training loss: 2.8555322058185224
Validation loss: 2.5475471274548385

Epoch: 6| Step: 9
Training loss: 1.766676733000285
Validation loss: 2.5260145004295094

Epoch: 6| Step: 10
Training loss: 1.6454140656251781
Validation loss: 2.493883093412279

Epoch: 6| Step: 11
Training loss: 2.405992865757183
Validation loss: 2.4499860853143685

Epoch: 6| Step: 12
Training loss: 2.5921362947139825
Validation loss: 2.428445618483188

Epoch: 6| Step: 13
Training loss: 2.2506683204759304
Validation loss: 2.413881801606133

Epoch: 174| Step: 0
Training loss: 1.6261101378598066
Validation loss: 2.373213864380144

Epoch: 6| Step: 1
Training loss: 2.3745210064175497
Validation loss: 2.3689221957581053

Epoch: 6| Step: 2
Training loss: 2.4101568435346716
Validation loss: 2.3637244127438652

Epoch: 6| Step: 3
Training loss: 2.4192963685384314
Validation loss: 2.3413019862010054

Epoch: 6| Step: 4
Training loss: 2.6919989964340174
Validation loss: 2.3614937425400373

Epoch: 6| Step: 5
Training loss: 2.023403800772106
Validation loss: 2.363800899115322

Epoch: 6| Step: 6
Training loss: 1.6943151115434785
Validation loss: 2.3536250794341265

Epoch: 6| Step: 7
Training loss: 2.0577110410340795
Validation loss: 2.341806834853116

Epoch: 6| Step: 8
Training loss: 2.2184664048029896
Validation loss: 2.3433366034932503

Epoch: 6| Step: 9
Training loss: 2.5953954050692905
Validation loss: 2.343013221578455

Epoch: 6| Step: 10
Training loss: 2.886209941204387
Validation loss: 2.347541500381143

Epoch: 6| Step: 11
Training loss: 2.4618985676079226
Validation loss: 2.3656334676688675

Epoch: 6| Step: 12
Training loss: 1.7622947005156244
Validation loss: 2.4187169078604422

Epoch: 6| Step: 13
Training loss: 2.391105753111873
Validation loss: 2.4484937592840534

Epoch: 175| Step: 0
Training loss: 1.9752619992079878
Validation loss: 2.496155289711668

Epoch: 6| Step: 1
Training loss: 2.6368403653955514
Validation loss: 2.5528011562314443

Epoch: 6| Step: 2
Training loss: 2.1649859830125058
Validation loss: 2.562596777232234

Epoch: 6| Step: 3
Training loss: 2.7505232573252156
Validation loss: 2.537048419442857

Epoch: 6| Step: 4
Training loss: 2.0161403026881066
Validation loss: 2.5104344144008386

Epoch: 6| Step: 5
Training loss: 2.493131739716542
Validation loss: 2.4965881487619352

Epoch: 6| Step: 6
Training loss: 2.1826870968949397
Validation loss: 2.479989959962431

Epoch: 6| Step: 7
Training loss: 1.8431185918148763
Validation loss: 2.4813809965999294

Epoch: 6| Step: 8
Training loss: 2.5558123897179046
Validation loss: 2.4691023019011005

Epoch: 6| Step: 9
Training loss: 2.36294184998306
Validation loss: 2.469652643555113

Epoch: 6| Step: 10
Training loss: 2.7913218517767344
Validation loss: 2.448612460024087

Epoch: 6| Step: 11
Training loss: 2.497410195753203
Validation loss: 2.443567884394412

Epoch: 6| Step: 12
Training loss: 1.9069750298164005
Validation loss: 2.426372903821439

Epoch: 6| Step: 13
Training loss: 1.8942748220669363
Validation loss: 2.4135338822789305

Epoch: 176| Step: 0
Training loss: 2.6898057494524763
Validation loss: 2.4167598378258823

Epoch: 6| Step: 1
Training loss: 2.4274448458439295
Validation loss: 2.424465262188979

Epoch: 6| Step: 2
Training loss: 1.765734036209941
Validation loss: 2.4161616527199703

Epoch: 6| Step: 3
Training loss: 1.1300413239780263
Validation loss: 2.418586952111184

Epoch: 6| Step: 4
Training loss: 2.420876967999294
Validation loss: 2.4372648173532157

Epoch: 6| Step: 5
Training loss: 2.217893515745578
Validation loss: 2.42185765900955

Epoch: 6| Step: 6
Training loss: 1.4175744046929517
Validation loss: 2.4084852480338887

Epoch: 6| Step: 7
Training loss: 1.6380522400999262
Validation loss: 2.3972151728207702

Epoch: 6| Step: 8
Training loss: 2.5984107735842707
Validation loss: 2.3900285213019963

Epoch: 6| Step: 9
Training loss: 2.460438705031243
Validation loss: 2.3925644087257014

Epoch: 6| Step: 10
Training loss: 2.4927656405968914
Validation loss: 2.4220110772653527

Epoch: 6| Step: 11
Training loss: 2.483308383210399
Validation loss: 2.4559701859067244

Epoch: 6| Step: 12
Training loss: 2.8258674842558027
Validation loss: 2.479976751955885

Epoch: 6| Step: 13
Training loss: 1.942172660985775
Validation loss: 2.4794999885482407

Epoch: 177| Step: 0
Training loss: 2.5651662957788917
Validation loss: 2.4779071588335086

Epoch: 6| Step: 1
Training loss: 2.098048906852663
Validation loss: 2.4673560368462617

Epoch: 6| Step: 2
Training loss: 2.2828252918634373
Validation loss: 2.4826536421439402

Epoch: 6| Step: 3
Training loss: 1.8365115952264623
Validation loss: 2.5147777137615734

Epoch: 6| Step: 4
Training loss: 2.342296302105673
Validation loss: 2.515308364021405

Epoch: 6| Step: 5
Training loss: 1.5051129936814642
Validation loss: 2.504996184441802

Epoch: 6| Step: 6
Training loss: 2.5370830625560123
Validation loss: 2.4850525920353044

Epoch: 6| Step: 7
Training loss: 1.9623766477657987
Validation loss: 2.457348939481127

Epoch: 6| Step: 8
Training loss: 2.3658953372381326
Validation loss: 2.436121256450596

Epoch: 6| Step: 9
Training loss: 1.9165075139297254
Validation loss: 2.408678975384847

Epoch: 6| Step: 10
Training loss: 2.501563346333691
Validation loss: 2.369257188898189

Epoch: 6| Step: 11
Training loss: 2.128131578522092
Validation loss: 2.3646241701723394

Epoch: 6| Step: 12
Training loss: 2.269142839874274
Validation loss: 2.3483351508876846

Epoch: 6| Step: 13
Training loss: 2.4213421635375707
Validation loss: 2.359039882631218

Epoch: 178| Step: 0
Training loss: 2.248197787445177
Validation loss: 2.380039988840433

Epoch: 6| Step: 1
Training loss: 2.311177881001771
Validation loss: 2.3949048458586484

Epoch: 6| Step: 2
Training loss: 1.7867045626725484
Validation loss: 2.414243413173722

Epoch: 6| Step: 3
Training loss: 1.8710415062350165
Validation loss: 2.4231223946547713

Epoch: 6| Step: 4
Training loss: 2.5356117626932555
Validation loss: 2.4486006333446815

Epoch: 6| Step: 5
Training loss: 1.7462313126347129
Validation loss: 2.447040106810706

Epoch: 6| Step: 6
Training loss: 1.3978305970181812
Validation loss: 2.4381062900273998

Epoch: 6| Step: 7
Training loss: 2.081014818071863
Validation loss: 2.4688403278034485

Epoch: 6| Step: 8
Training loss: 2.058774647012192
Validation loss: 2.4818199166720367

Epoch: 6| Step: 9
Training loss: 2.372990812416472
Validation loss: 2.5293911735341323

Epoch: 6| Step: 10
Training loss: 2.3793948819547506
Validation loss: 2.5417472988621244

Epoch: 6| Step: 11
Training loss: 2.808278200040377
Validation loss: 2.5323112974155424

Epoch: 6| Step: 12
Training loss: 2.1991552204828233
Validation loss: 2.531114285708729

Epoch: 6| Step: 13
Training loss: 2.392611407612894
Validation loss: 2.5222624789840093

Epoch: 179| Step: 0
Training loss: 1.8848168558856622
Validation loss: 2.475868411209252

Epoch: 6| Step: 1
Training loss: 2.5140960027289134
Validation loss: 2.435954175653368

Epoch: 6| Step: 2
Training loss: 2.0455812048951545
Validation loss: 2.377641093407808

Epoch: 6| Step: 3
Training loss: 2.4079068907419203
Validation loss: 2.352308561674414

Epoch: 6| Step: 4
Training loss: 1.9434396085039163
Validation loss: 2.3349497297294572

Epoch: 6| Step: 5
Training loss: 2.464592535453723
Validation loss: 2.331506737851307

Epoch: 6| Step: 6
Training loss: 1.6426906116265847
Validation loss: 2.323174185935859

Epoch: 6| Step: 7
Training loss: 2.150714347511041
Validation loss: 2.338503923725236

Epoch: 6| Step: 8
Training loss: 2.1559945660099773
Validation loss: 2.3451097925909816

Epoch: 6| Step: 9
Training loss: 2.0063214535927396
Validation loss: 2.352882497458131

Epoch: 6| Step: 10
Training loss: 2.2256462487371667
Validation loss: 2.3702302152156376

Epoch: 6| Step: 11
Training loss: 2.075968031686713
Validation loss: 2.3636115272960243

Epoch: 6| Step: 12
Training loss: 2.124077316126994
Validation loss: 2.4013413861981188

Epoch: 6| Step: 13
Training loss: 2.1291370511716994
Validation loss: 2.4104498041933446

Epoch: 180| Step: 0
Training loss: 2.267823303794069
Validation loss: 2.420682304197588

Epoch: 6| Step: 1
Training loss: 2.032851541482917
Validation loss: 2.4360099605053778

Epoch: 6| Step: 2
Training loss: 2.116685983865054
Validation loss: 2.4178281859794386

Epoch: 6| Step: 3
Training loss: 2.082821007358493
Validation loss: 2.473053852189976

Epoch: 6| Step: 4
Training loss: 2.1854770570841087
Validation loss: 2.4571124379267024

Epoch: 6| Step: 5
Training loss: 2.1968879883817687
Validation loss: 2.4524900870003514

Epoch: 6| Step: 6
Training loss: 1.976233413501217
Validation loss: 2.4538420833603234

Epoch: 6| Step: 7
Training loss: 2.62180751854644
Validation loss: 2.453091345993098

Epoch: 6| Step: 8
Training loss: 1.6381109684907558
Validation loss: 2.4420810160436677

Epoch: 6| Step: 9
Training loss: 1.5371787068921452
Validation loss: 2.4692093429766597

Epoch: 6| Step: 10
Training loss: 1.7020737789762137
Validation loss: 2.5121730079237623

Epoch: 6| Step: 11
Training loss: 2.6979470466071764
Validation loss: 2.562297936132881

Epoch: 6| Step: 12
Training loss: 2.4154862338103977
Validation loss: 2.566622788257026

Epoch: 6| Step: 13
Training loss: 2.186257254586853
Validation loss: 2.5381763501505694

Epoch: 181| Step: 0
Training loss: 2.3526596602157825
Validation loss: 2.462978640460084

Epoch: 6| Step: 1
Training loss: 2.078988032289585
Validation loss: 2.409900270824859

Epoch: 6| Step: 2
Training loss: 1.7356510451343825
Validation loss: 2.40780126724444

Epoch: 6| Step: 3
Training loss: 2.0726816117582323
Validation loss: 2.4145289235084966

Epoch: 6| Step: 4
Training loss: 2.3567083585829094
Validation loss: 2.423331783100826

Epoch: 6| Step: 5
Training loss: 2.431674941713173
Validation loss: 2.442493283285467

Epoch: 6| Step: 6
Training loss: 2.1385060982054194
Validation loss: 2.4331380521192836

Epoch: 6| Step: 7
Training loss: 1.7191570840267407
Validation loss: 2.4083285251380238

Epoch: 6| Step: 8
Training loss: 1.8243733571310772
Validation loss: 2.4008046961896055

Epoch: 6| Step: 9
Training loss: 1.5823764754021103
Validation loss: 2.4118406331647386

Epoch: 6| Step: 10
Training loss: 1.7966796105342615
Validation loss: 2.435368267555863

Epoch: 6| Step: 11
Training loss: 2.6202751507312265
Validation loss: 2.471892693436317

Epoch: 6| Step: 12
Training loss: 2.53715589097442
Validation loss: 2.522564661518094

Epoch: 6| Step: 13
Training loss: 2.113779851791766
Validation loss: 2.550649101729889

Epoch: 182| Step: 0
Training loss: 2.0560611441014323
Validation loss: 2.5698476715737626

Epoch: 6| Step: 1
Training loss: 2.025308693798499
Validation loss: 2.557001051807432

Epoch: 6| Step: 2
Training loss: 2.3381792111856194
Validation loss: 2.542728402695836

Epoch: 6| Step: 3
Training loss: 1.7496735404551746
Validation loss: 2.464801996577964

Epoch: 6| Step: 4
Training loss: 2.0907432260427514
Validation loss: 2.4619488277679062

Epoch: 6| Step: 5
Training loss: 1.9947716203152093
Validation loss: 2.408713016825618

Epoch: 6| Step: 6
Training loss: 2.0335361233671416
Validation loss: 2.4006534018961565

Epoch: 6| Step: 7
Training loss: 2.448046341295368
Validation loss: 2.3872976517902273

Epoch: 6| Step: 8
Training loss: 2.201409937145907
Validation loss: 2.373560354164841

Epoch: 6| Step: 9
Training loss: 1.8376670320329327
Validation loss: 2.3748500983918417

Epoch: 6| Step: 10
Training loss: 2.138880109012083
Validation loss: 2.367136388813274

Epoch: 6| Step: 11
Training loss: 1.8593919897505373
Validation loss: 2.380435241221923

Epoch: 6| Step: 12
Training loss: 2.214624895320071
Validation loss: 2.4085692729725827

Epoch: 6| Step: 13
Training loss: 1.9143332153701988
Validation loss: 2.4158235705161633

Epoch: 183| Step: 0
Training loss: 2.1478553676892385
Validation loss: 2.435089206480306

Epoch: 6| Step: 1
Training loss: 1.3492634353350457
Validation loss: 2.4269821024058604

Epoch: 6| Step: 2
Training loss: 2.5111572207471977
Validation loss: 2.440178557667057

Epoch: 6| Step: 3
Training loss: 2.035025272071871
Validation loss: 2.447631842058222

Epoch: 6| Step: 4
Training loss: 1.5991134154157263
Validation loss: 2.4878697280967454

Epoch: 6| Step: 5
Training loss: 1.9830427728984812
Validation loss: 2.498801900020794

Epoch: 6| Step: 6
Training loss: 2.0807892206252334
Validation loss: 2.538188035189806

Epoch: 6| Step: 7
Training loss: 2.294370778245401
Validation loss: 2.522461677892805

Epoch: 6| Step: 8
Training loss: 2.0887407190560707
Validation loss: 2.5151928312814125

Epoch: 6| Step: 9
Training loss: 2.342277369387854
Validation loss: 2.5223049897721963

Epoch: 6| Step: 10
Training loss: 2.1908221494849434
Validation loss: 2.5151128006087227

Epoch: 6| Step: 11
Training loss: 1.6464798136474852
Validation loss: 2.5074461907512915

Epoch: 6| Step: 12
Training loss: 1.9929909077201042
Validation loss: 2.446763320985382

Epoch: 6| Step: 13
Training loss: 2.4403474266473086
Validation loss: 2.4032791244236824

Epoch: 184| Step: 0
Training loss: 1.9399417134996926
Validation loss: 2.385892350336256

Epoch: 6| Step: 1
Training loss: 1.955311886039102
Validation loss: 2.3838069697135866

Epoch: 6| Step: 2
Training loss: 1.806242433947916
Validation loss: 2.4084157504963795

Epoch: 6| Step: 3
Training loss: 1.9269989682537776
Validation loss: 2.4045446878987993

Epoch: 6| Step: 4
Training loss: 2.4301122557845165
Validation loss: 2.424748229343018

Epoch: 6| Step: 5
Training loss: 2.0697502092402122
Validation loss: 2.4106888279609944

Epoch: 6| Step: 6
Training loss: 1.5266501956922955
Validation loss: 2.3997331535860322

Epoch: 6| Step: 7
Training loss: 2.392454756066802
Validation loss: 2.4114559672081435

Epoch: 6| Step: 8
Training loss: 1.8823827989222774
Validation loss: 2.4200376995563517

Epoch: 6| Step: 9
Training loss: 2.2028311675524472
Validation loss: 2.4465691000236034

Epoch: 6| Step: 10
Training loss: 2.3096025202563983
Validation loss: 2.46666494898527

Epoch: 6| Step: 11
Training loss: 1.6737457931727788
Validation loss: 2.4901273543805735

Epoch: 6| Step: 12
Training loss: 2.4546064046555656
Validation loss: 2.487243496729859

Epoch: 6| Step: 13
Training loss: 1.798814473219437
Validation loss: 2.473905345476667

Epoch: 185| Step: 0
Training loss: 1.7467620048760126
Validation loss: 2.4282035113990914

Epoch: 6| Step: 1
Training loss: 2.368628639192225
Validation loss: 2.3993599644108095

Epoch: 6| Step: 2
Training loss: 2.126131990399605
Validation loss: 2.3868144388930097

Epoch: 6| Step: 3
Training loss: 1.4100104174668755
Validation loss: 2.3578280428918283

Epoch: 6| Step: 4
Training loss: 2.496510740978652
Validation loss: 2.3601712053722763

Epoch: 6| Step: 5
Training loss: 1.9763648495969903
Validation loss: 2.3546362613714753

Epoch: 6| Step: 6
Training loss: 2.2374690048372563
Validation loss: 2.334998293418829

Epoch: 6| Step: 7
Training loss: 1.4784788583192763
Validation loss: 2.358731864618937

Epoch: 6| Step: 8
Training loss: 2.021566225320589
Validation loss: 2.3654817592184867

Epoch: 6| Step: 9
Training loss: 2.2556972428884836
Validation loss: 2.370078285587208

Epoch: 6| Step: 10
Training loss: 1.6573410758903842
Validation loss: 2.3903556552429484

Epoch: 6| Step: 11
Training loss: 2.097404820097951
Validation loss: 2.3952873909840307

Epoch: 6| Step: 12
Training loss: 1.8546729378903895
Validation loss: 2.4302178168045954

Epoch: 6| Step: 13
Training loss: 1.858351546000142
Validation loss: 2.4070491435932904

Epoch: 186| Step: 0
Training loss: 1.6159911222308452
Validation loss: 2.410296153141128

Epoch: 6| Step: 1
Training loss: 1.3402857815904854
Validation loss: 2.386575022020279

Epoch: 6| Step: 2
Training loss: 2.257410772678833
Validation loss: 2.376593536066212

Epoch: 6| Step: 3
Training loss: 2.1048587630272206
Validation loss: 2.3598506409751416

Epoch: 6| Step: 4
Training loss: 1.97277015885928
Validation loss: 2.371848668904212

Epoch: 6| Step: 5
Training loss: 1.9004226164364684
Validation loss: 2.3656626656593107

Epoch: 6| Step: 6
Training loss: 2.1529830287861564
Validation loss: 2.3928444050823012

Epoch: 6| Step: 7
Training loss: 2.013408536369649
Validation loss: 2.436432959588735

Epoch: 6| Step: 8
Training loss: 1.8089038426499446
Validation loss: 2.440688592648111

Epoch: 6| Step: 9
Training loss: 2.066938421881468
Validation loss: 2.451258297981729

Epoch: 6| Step: 10
Training loss: 2.3223847149342323
Validation loss: 2.455229430886557

Epoch: 6| Step: 11
Training loss: 1.8100894815234483
Validation loss: 2.448400720734614

Epoch: 6| Step: 12
Training loss: 2.023696706068945
Validation loss: 2.4641631415510097

Epoch: 6| Step: 13
Training loss: 1.9289448038592107
Validation loss: 2.4369489690103596

Epoch: 187| Step: 0
Training loss: 2.112736037571453
Validation loss: 2.45329599781884

Epoch: 6| Step: 1
Training loss: 2.003072286260377
Validation loss: 2.434351347003367

Epoch: 6| Step: 2
Training loss: 2.666791396402934
Validation loss: 2.4486354379178756

Epoch: 6| Step: 3
Training loss: 1.8510017028627646
Validation loss: 2.4492169161498896

Epoch: 6| Step: 4
Training loss: 2.0209901362144915
Validation loss: 2.4386943334338853

Epoch: 6| Step: 5
Training loss: 1.7660753469108237
Validation loss: 2.4445939276625936

Epoch: 6| Step: 6
Training loss: 1.6187817367918536
Validation loss: 2.4460739506528757

Epoch: 6| Step: 7
Training loss: 2.037934206700762
Validation loss: 2.441591913723266

Epoch: 6| Step: 8
Training loss: 2.1014696972858875
Validation loss: 2.4252052890904396

Epoch: 6| Step: 9
Training loss: 1.5858730058757482
Validation loss: 2.4274707271834868

Epoch: 6| Step: 10
Training loss: 2.118744337586345
Validation loss: 2.439755817097386

Epoch: 6| Step: 11
Training loss: 1.5559463388560075
Validation loss: 2.4422832902585774

Epoch: 6| Step: 12
Training loss: 1.5221530292189256
Validation loss: 2.443782191917795

Epoch: 6| Step: 13
Training loss: 1.164016364290625
Validation loss: 2.4513550379472027

Epoch: 188| Step: 0
Training loss: 1.955822904721795
Validation loss: 2.4403914767721995

Epoch: 6| Step: 1
Training loss: 1.5886213772479028
Validation loss: 2.453794858839214

Epoch: 6| Step: 2
Training loss: 2.0083540249255893
Validation loss: 2.4553036973919315

Epoch: 6| Step: 3
Training loss: 2.4069597262732434
Validation loss: 2.4413476329698716

Epoch: 6| Step: 4
Training loss: 1.8182887669016432
Validation loss: 2.431088867002062

Epoch: 6| Step: 5
Training loss: 1.908005953141688
Validation loss: 2.454040324181645

Epoch: 6| Step: 6
Training loss: 2.070868305957406
Validation loss: 2.4545903200088013

Epoch: 6| Step: 7
Training loss: 1.7219851477643742
Validation loss: 2.4335210237532854

Epoch: 6| Step: 8
Training loss: 1.8567499174747473
Validation loss: 2.426269900538046

Epoch: 6| Step: 9
Training loss: 1.6407547672358826
Validation loss: 2.440533780177413

Epoch: 6| Step: 10
Training loss: 1.7780809152297108
Validation loss: 2.4474610706962157

Epoch: 6| Step: 11
Training loss: 2.016120435757922
Validation loss: 2.4305247505763377

Epoch: 6| Step: 12
Training loss: 2.0461714605639996
Validation loss: 2.4487732829553277

Epoch: 6| Step: 13
Training loss: 1.0128424453898788
Validation loss: 2.41896208723363

Epoch: 189| Step: 0
Training loss: 1.8990387141182052
Validation loss: 2.4227624035512676

Epoch: 6| Step: 1
Training loss: 1.5164425404847752
Validation loss: 2.401729497407983

Epoch: 6| Step: 2
Training loss: 1.738698022149143
Validation loss: 2.4183958555283653

Epoch: 6| Step: 3
Training loss: 1.8023877043008782
Validation loss: 2.4113945123439695

Epoch: 6| Step: 4
Training loss: 1.5515635172522706
Validation loss: 2.407001309350859

Epoch: 6| Step: 5
Training loss: 2.429131447311543
Validation loss: 2.401337742521223

Epoch: 6| Step: 6
Training loss: 1.7918475599419914
Validation loss: 2.3926100136140915

Epoch: 6| Step: 7
Training loss: 2.0352748023591714
Validation loss: 2.3760784196408884

Epoch: 6| Step: 8
Training loss: 1.938802465913187
Validation loss: 2.3760924662895615

Epoch: 6| Step: 9
Training loss: 1.8414201401715455
Validation loss: 2.4098901573015072

Epoch: 6| Step: 10
Training loss: 1.6165689953404918
Validation loss: 2.419598197045916

Epoch: 6| Step: 11
Training loss: 2.382273328471746
Validation loss: 2.4199906549075836

Epoch: 6| Step: 12
Training loss: 1.996697082712424
Validation loss: 2.3995238437241317

Epoch: 6| Step: 13
Training loss: 1.8743175536202723
Validation loss: 2.4129267829016308

Epoch: 190| Step: 0
Training loss: 1.7070947980072884
Validation loss: 2.4069017481967685

Epoch: 6| Step: 1
Training loss: 1.7534238835922584
Validation loss: 2.4761840618124387

Epoch: 6| Step: 2
Training loss: 2.172887662094785
Validation loss: 2.476410448830848

Epoch: 6| Step: 3
Training loss: 2.0156794104514173
Validation loss: 2.4901310081511023

Epoch: 6| Step: 4
Training loss: 1.387190230904624
Validation loss: 2.450662287377461

Epoch: 6| Step: 5
Training loss: 1.9648337392381348
Validation loss: 2.4164322458983074

Epoch: 6| Step: 6
Training loss: 1.4639209332820429
Validation loss: 2.390265885860726

Epoch: 6| Step: 7
Training loss: 1.956689861924796
Validation loss: 2.3657173154222826

Epoch: 6| Step: 8
Training loss: 2.058246735309712
Validation loss: 2.375513991569285

Epoch: 6| Step: 9
Training loss: 2.178210561377119
Validation loss: 2.401018077764809

Epoch: 6| Step: 10
Training loss: 1.622175255767639
Validation loss: 2.402501237844252

Epoch: 6| Step: 11
Training loss: 1.7121689079599494
Validation loss: 2.386284911223489

Epoch: 6| Step: 12
Training loss: 1.8768151080686872
Validation loss: 2.392170694236075

Epoch: 6| Step: 13
Training loss: 2.0833486429287738
Validation loss: 2.4046795368918943

Epoch: 191| Step: 0
Training loss: 1.3929405650284297
Validation loss: 2.3883659041997922

Epoch: 6| Step: 1
Training loss: 1.9093133669831295
Validation loss: 2.385337816106539

Epoch: 6| Step: 2
Training loss: 2.1583202209467114
Validation loss: 2.4053749972760623

Epoch: 6| Step: 3
Training loss: 1.543433088136814
Validation loss: 2.4260994250716603

Epoch: 6| Step: 4
Training loss: 1.8064125040733183
Validation loss: 2.456098930837672

Epoch: 6| Step: 5
Training loss: 1.9867486649217507
Validation loss: 2.459631003976247

Epoch: 6| Step: 6
Training loss: 1.8127662200096855
Validation loss: 2.446834146990509

Epoch: 6| Step: 7
Training loss: 1.8053269347514624
Validation loss: 2.4529048146020056

Epoch: 6| Step: 8
Training loss: 1.6266869078742197
Validation loss: 2.4329925596718045

Epoch: 6| Step: 9
Training loss: 1.5529580776846947
Validation loss: 2.3847023465388353

Epoch: 6| Step: 10
Training loss: 2.4198219703575505
Validation loss: 2.3747398674410376

Epoch: 6| Step: 11
Training loss: 1.7225291233341318
Validation loss: 2.3619254304291677

Epoch: 6| Step: 12
Training loss: 1.5228025237942047
Validation loss: 2.3689617821957984

Epoch: 6| Step: 13
Training loss: 2.2264138690797504
Validation loss: 2.3617520754608217

Epoch: 192| Step: 0
Training loss: 1.5678780126998144
Validation loss: 2.3713910451543936

Epoch: 6| Step: 1
Training loss: 2.1005514329162853
Validation loss: 2.384793650277603

Epoch: 6| Step: 2
Training loss: 1.620892100833725
Validation loss: 2.3964121143959876

Epoch: 6| Step: 3
Training loss: 1.4568433052323666
Validation loss: 2.4044642625529327

Epoch: 6| Step: 4
Training loss: 1.6348494823828912
Validation loss: 2.4150467453238

Epoch: 6| Step: 5
Training loss: 1.98522582549607
Validation loss: 2.436740533957515

Epoch: 6| Step: 6
Training loss: 1.930419968189776
Validation loss: 2.465478181028226

Epoch: 6| Step: 7
Training loss: 1.6548568336359322
Validation loss: 2.502868043944809

Epoch: 6| Step: 8
Training loss: 2.2575839761891245
Validation loss: 2.5190568435821414

Epoch: 6| Step: 9
Training loss: 1.623521352149962
Validation loss: 2.488059604034289

Epoch: 6| Step: 10
Training loss: 1.9757986892286536
Validation loss: 2.451118140045713

Epoch: 6| Step: 11
Training loss: 1.539823469844216
Validation loss: 2.4097675640234635

Epoch: 6| Step: 12
Training loss: 2.008055201011072
Validation loss: 2.3971115540416066

Epoch: 6| Step: 13
Training loss: 2.241539625611931
Validation loss: 2.4034244465308032

Epoch: 193| Step: 0
Training loss: 1.91640805144445
Validation loss: 2.3921846635394335

Epoch: 6| Step: 1
Training loss: 2.059956919025188
Validation loss: 2.4055656884503307

Epoch: 6| Step: 2
Training loss: 1.9394044437810327
Validation loss: 2.4056052782660435

Epoch: 6| Step: 3
Training loss: 1.922426594298864
Validation loss: 2.4332364607388275

Epoch: 6| Step: 4
Training loss: 1.7851061657446978
Validation loss: 2.4351711922723513

Epoch: 6| Step: 5
Training loss: 1.5882062047068806
Validation loss: 2.437976796835837

Epoch: 6| Step: 6
Training loss: 1.6619667861686156
Validation loss: 2.485411961260349

Epoch: 6| Step: 7
Training loss: 1.949016675240674
Validation loss: 2.491380912101843

Epoch: 6| Step: 8
Training loss: 2.246830827599796
Validation loss: 2.5063693515101213

Epoch: 6| Step: 9
Training loss: 1.5273527257318982
Validation loss: 2.5036518251206017

Epoch: 6| Step: 10
Training loss: 1.82516154527937
Validation loss: 2.5670685919148473

Epoch: 6| Step: 11
Training loss: 0.9914095975490175
Validation loss: 2.559519711661064

Epoch: 6| Step: 12
Training loss: 1.900184926018259
Validation loss: 2.5203183864400693

Epoch: 6| Step: 13
Training loss: 1.2749135175059703
Validation loss: 2.476414544175371

Epoch: 194| Step: 0
Training loss: 1.5621885370723048
Validation loss: 2.4493367677182962

Epoch: 6| Step: 1
Training loss: 1.2997020563409747
Validation loss: 2.4410218594404913

Epoch: 6| Step: 2
Training loss: 1.811218005648742
Validation loss: 2.4157002669874643

Epoch: 6| Step: 3
Training loss: 2.0090686712913413
Validation loss: 2.416589954426005

Epoch: 6| Step: 4
Training loss: 2.2359581520518335
Validation loss: 2.407198983700719

Epoch: 6| Step: 5
Training loss: 1.530630102994114
Validation loss: 2.408576080757817

Epoch: 6| Step: 6
Training loss: 1.5493608018133016
Validation loss: 2.441296416800263

Epoch: 6| Step: 7
Training loss: 1.6888369456398478
Validation loss: 2.5150042648081925

Epoch: 6| Step: 8
Training loss: 2.2526422456966326
Validation loss: 2.5869952234144282

Epoch: 6| Step: 9
Training loss: 1.9125024783049838
Validation loss: 2.547858474057918

Epoch: 6| Step: 10
Training loss: 2.2321960922432584
Validation loss: 2.532652659857104

Epoch: 6| Step: 11
Training loss: 1.7716695568866188
Validation loss: 2.494808388012871

Epoch: 6| Step: 12
Training loss: 1.7046686578787964
Validation loss: 2.4576950878496633

Epoch: 6| Step: 13
Training loss: 1.6068703132718323
Validation loss: 2.4564815945712186

Epoch: 195| Step: 0
Training loss: 1.9805580134091934
Validation loss: 2.4588218135518414

Epoch: 6| Step: 1
Training loss: 1.534344562920093
Validation loss: 2.465890765804562

Epoch: 6| Step: 2
Training loss: 1.5515516082903837
Validation loss: 2.4846141429470223

Epoch: 6| Step: 3
Training loss: 2.1193314286221736
Validation loss: 2.4872920326531878

Epoch: 6| Step: 4
Training loss: 1.4250059763465173
Validation loss: 2.4735566550274655

Epoch: 6| Step: 5
Training loss: 2.017414333788983
Validation loss: 2.4274471006305722

Epoch: 6| Step: 6
Training loss: 1.6606046901231886
Validation loss: 2.400020644311066

Epoch: 6| Step: 7
Training loss: 2.157788377498561
Validation loss: 2.3714723429566344

Epoch: 6| Step: 8
Training loss: 1.6300129961303103
Validation loss: 2.355809492188065

Epoch: 6| Step: 9
Training loss: 1.8442651061434419
Validation loss: 2.3445884643182002

Epoch: 6| Step: 10
Training loss: 2.2928816146800926
Validation loss: 2.329804762520393

Epoch: 6| Step: 11
Training loss: 1.5731677766484755
Validation loss: 2.350319417122536

Epoch: 6| Step: 12
Training loss: 1.2672848589993004
Validation loss: 2.3793583194941803

Epoch: 6| Step: 13
Training loss: 1.416762750770511
Validation loss: 2.3884267601672513

Epoch: 196| Step: 0
Training loss: 1.2718405041714733
Validation loss: 2.4217994574952684

Epoch: 6| Step: 1
Training loss: 1.943297602759607
Validation loss: 2.4405636587836685

Epoch: 6| Step: 2
Training loss: 1.549957748575549
Validation loss: 2.4585035464003813

Epoch: 6| Step: 3
Training loss: 1.8159261089408165
Validation loss: 2.4905117759805075

Epoch: 6| Step: 4
Training loss: 1.1824509545573008
Validation loss: 2.52849698449452

Epoch: 6| Step: 5
Training loss: 1.7332271867431224
Validation loss: 2.5592783042445726

Epoch: 6| Step: 6
Training loss: 1.694242289041098
Validation loss: 2.534324231501677

Epoch: 6| Step: 7
Training loss: 1.6504131609038297
Validation loss: 2.5170239030453625

Epoch: 6| Step: 8
Training loss: 1.9716727949591637
Validation loss: 2.5001200103667562

Epoch: 6| Step: 9
Training loss: 2.0764029115042484
Validation loss: 2.455112256123768

Epoch: 6| Step: 10
Training loss: 1.5898271789436993
Validation loss: 2.403527016657703

Epoch: 6| Step: 11
Training loss: 2.0125804055778778
Validation loss: 2.4068107457676664

Epoch: 6| Step: 12
Training loss: 1.9456557618284835
Validation loss: 2.410489545643164

Epoch: 6| Step: 13
Training loss: 1.8153386085485907
Validation loss: 2.403448284166677

Epoch: 197| Step: 0
Training loss: 1.599947976220267
Validation loss: 2.4128161691438104

Epoch: 6| Step: 1
Training loss: 1.9581130154094075
Validation loss: 2.3976059086886106

Epoch: 6| Step: 2
Training loss: 1.7645029874642848
Validation loss: 2.408708511556255

Epoch: 6| Step: 3
Training loss: 1.493747075927937
Validation loss: 2.449731598450566

Epoch: 6| Step: 4
Training loss: 1.6478915643849845
Validation loss: 2.4541673067741354

Epoch: 6| Step: 5
Training loss: 1.672630567144131
Validation loss: 2.4633516007089

Epoch: 6| Step: 6
Training loss: 1.9197883753576714
Validation loss: 2.487241135359333

Epoch: 6| Step: 7
Training loss: 1.396081954487825
Validation loss: 2.4661564670427087

Epoch: 6| Step: 8
Training loss: 1.5129652773647764
Validation loss: 2.44012500822636

Epoch: 6| Step: 9
Training loss: 1.0353014574230588
Validation loss: 2.4571986926602696

Epoch: 6| Step: 10
Training loss: 2.241931754490036
Validation loss: 2.4508948591485833

Epoch: 6| Step: 11
Training loss: 1.7122945759769386
Validation loss: 2.4579508268157504

Epoch: 6| Step: 12
Training loss: 1.8879126015695644
Validation loss: 2.4359169766228232

Epoch: 6| Step: 13
Training loss: 1.540045255020841
Validation loss: 2.417823409290781

Epoch: 198| Step: 0
Training loss: 1.6959251316477804
Validation loss: 2.3843562958626054

Epoch: 6| Step: 1
Training loss: 2.1684127765306553
Validation loss: 2.3950224015390122

Epoch: 6| Step: 2
Training loss: 1.3747648558257068
Validation loss: 2.3865342399592016

Epoch: 6| Step: 3
Training loss: 1.7245562881127252
Validation loss: 2.380509775586053

Epoch: 6| Step: 4
Training loss: 1.7937948613421872
Validation loss: 2.379461270348777

Epoch: 6| Step: 5
Training loss: 1.5486884998244563
Validation loss: 2.3882571601191462

Epoch: 6| Step: 6
Training loss: 1.0756965598330552
Validation loss: 2.409880495852477

Epoch: 6| Step: 7
Training loss: 1.6362192488797653
Validation loss: 2.4505186126801095

Epoch: 6| Step: 8
Training loss: 1.7023166523037638
Validation loss: 2.4692474410292435

Epoch: 6| Step: 9
Training loss: 1.9752090102069415
Validation loss: 2.5278480656665336

Epoch: 6| Step: 10
Training loss: 1.4493302870446143
Validation loss: 2.53778429797304

Epoch: 6| Step: 11
Training loss: 1.6683367785489043
Validation loss: 2.497798367601386

Epoch: 6| Step: 12
Training loss: 1.745668431993842
Validation loss: 2.4944133695660526

Epoch: 6| Step: 13
Training loss: 1.7820553213966357
Validation loss: 2.4771288452615026

Epoch: 199| Step: 0
Training loss: 1.7977115176647862
Validation loss: 2.4651611003180087

Epoch: 6| Step: 1
Training loss: 1.705529851164051
Validation loss: 2.454999536821207

Epoch: 6| Step: 2
Training loss: 1.6275114312773962
Validation loss: 2.4537780343975313

Epoch: 6| Step: 3
Training loss: 1.393696682171028
Validation loss: 2.4536402636494157

Epoch: 6| Step: 4
Training loss: 2.097578732782674
Validation loss: 2.4559239214253967

Epoch: 6| Step: 5
Training loss: 1.8783377503098029
Validation loss: 2.4685001483103233

Epoch: 6| Step: 6
Training loss: 1.6494695677827778
Validation loss: 2.4985423381288676

Epoch: 6| Step: 7
Training loss: 1.6881817041199945
Validation loss: 2.493731398246693

Epoch: 6| Step: 8
Training loss: 1.8887231261628175
Validation loss: 2.475981478850627

Epoch: 6| Step: 9
Training loss: 1.42911363768367
Validation loss: 2.4559798257529004

Epoch: 6| Step: 10
Training loss: 1.4442235194904103
Validation loss: 2.4604213232512957

Epoch: 6| Step: 11
Training loss: 1.5442682516023907
Validation loss: 2.4566726588535674

Epoch: 6| Step: 12
Training loss: 1.7638186777046625
Validation loss: 2.433207145393653

Epoch: 6| Step: 13
Training loss: 1.533742782961305
Validation loss: 2.427728316831187

Epoch: 200| Step: 0
Training loss: 1.7206896154628937
Validation loss: 2.4477617272796435

Epoch: 6| Step: 1
Training loss: 1.0571407467220848
Validation loss: 2.473725542515916

Epoch: 6| Step: 2
Training loss: 1.894062039190053
Validation loss: 2.516641015094085

Epoch: 6| Step: 3
Training loss: 2.3175701543072
Validation loss: 2.547699010416018

Epoch: 6| Step: 4
Training loss: 1.518481443546124
Validation loss: 2.5534616337548965

Epoch: 6| Step: 5
Training loss: 1.829156177232887
Validation loss: 2.4973043234051726

Epoch: 6| Step: 6
Training loss: 1.483758898919663
Validation loss: 2.417923150528912

Epoch: 6| Step: 7
Training loss: 1.6099325158802391
Validation loss: 2.378899280793763

Epoch: 6| Step: 8
Training loss: 1.2012663021033392
Validation loss: 2.3684754962848693

Epoch: 6| Step: 9
Training loss: 1.8783888391904027
Validation loss: 2.351239788236504

Epoch: 6| Step: 10
Training loss: 2.131327241185876
Validation loss: 2.347348293444458

Epoch: 6| Step: 11
Training loss: 1.2606124515693782
Validation loss: 2.3489848315191786

Epoch: 6| Step: 12
Training loss: 1.5728455415859395
Validation loss: 2.3541616315803258

Epoch: 6| Step: 13
Training loss: 1.8279330813097903
Validation loss: 2.3781499790237386

Epoch: 201| Step: 0
Training loss: 1.533853924874857
Validation loss: 2.4165555248085386

Epoch: 6| Step: 1
Training loss: 1.4919592398171462
Validation loss: 2.4663360983513933

Epoch: 6| Step: 2
Training loss: 1.6876076557999347
Validation loss: 2.498511644545714

Epoch: 6| Step: 3
Training loss: 1.9849915034883394
Validation loss: 2.5405841689452617

Epoch: 6| Step: 4
Training loss: 1.6524632187528576
Validation loss: 2.501668406152493

Epoch: 6| Step: 5
Training loss: 1.4888756233465756
Validation loss: 2.4891660782322655

Epoch: 6| Step: 6
Training loss: 1.7561485722803647
Validation loss: 2.4586047013557164

Epoch: 6| Step: 7
Training loss: 1.6032322808670565
Validation loss: 2.4348105208975865

Epoch: 6| Step: 8
Training loss: 1.9133089411683777
Validation loss: 2.454509805370239

Epoch: 6| Step: 9
Training loss: 1.8049259441115046
Validation loss: 2.4510230171784766

Epoch: 6| Step: 10
Training loss: 1.653732257496988
Validation loss: 2.4486754442962004

Epoch: 6| Step: 11
Training loss: 1.3220516240144116
Validation loss: 2.444342213562808

Epoch: 6| Step: 12
Training loss: 1.5886142484832524
Validation loss: 2.470871716253615

Epoch: 6| Step: 13
Training loss: 0.919375214670702
Validation loss: 2.466869829896784

Epoch: 202| Step: 0
Training loss: 1.413954251187316
Validation loss: 2.468998250217878

Epoch: 6| Step: 1
Training loss: 1.9029618342065875
Validation loss: 2.47733034095156

Epoch: 6| Step: 2
Training loss: 1.9709363634896437
Validation loss: 2.4847043294391593

Epoch: 6| Step: 3
Training loss: 1.2199647180739848
Validation loss: 2.483997820166769

Epoch: 6| Step: 4
Training loss: 1.489239802017119
Validation loss: 2.517062810230659

Epoch: 6| Step: 5
Training loss: 1.691583919223926
Validation loss: 2.5327741904764087

Epoch: 6| Step: 6
Training loss: 1.4077805560993766
Validation loss: 2.541284600692628

Epoch: 6| Step: 7
Training loss: 1.6789350376705388
Validation loss: 2.5332056398570812

Epoch: 6| Step: 8
Training loss: 1.567032458165774
Validation loss: 2.5460913473136433

Epoch: 6| Step: 9
Training loss: 1.597232529242979
Validation loss: 2.5410159982944247

Epoch: 6| Step: 10
Training loss: 1.3342217029003218
Validation loss: 2.4640157677375405

Epoch: 6| Step: 11
Training loss: 1.811281057424547
Validation loss: 2.464341471628583

Epoch: 6| Step: 12
Training loss: 0.895894340537371
Validation loss: 2.4366181710801333

Epoch: 6| Step: 13
Training loss: 2.230961359411839
Validation loss: 2.4267309342225

Epoch: 203| Step: 0
Training loss: 1.5181424970627557
Validation loss: 2.4529745456698286

Epoch: 6| Step: 1
Training loss: 1.9463877329910557
Validation loss: 2.447152071802239

Epoch: 6| Step: 2
Training loss: 1.4361932039111491
Validation loss: 2.4412096548029614

Epoch: 6| Step: 3
Training loss: 1.3667619315338844
Validation loss: 2.4422243268783377

Epoch: 6| Step: 4
Training loss: 1.428566665300875
Validation loss: 2.455157292274847

Epoch: 6| Step: 5
Training loss: 1.3677788899514698
Validation loss: 2.463141766453381

Epoch: 6| Step: 6
Training loss: 1.5335530458821116
Validation loss: 2.4975993345881973

Epoch: 6| Step: 7
Training loss: 1.6268849810815456
Validation loss: 2.5087235203238696

Epoch: 6| Step: 8
Training loss: 0.9249424091659668
Validation loss: 2.523021354714071

Epoch: 6| Step: 9
Training loss: 1.8798616958026644
Validation loss: 2.524618039461212

Epoch: 6| Step: 10
Training loss: 1.7440907299256672
Validation loss: 2.4684846963174993

Epoch: 6| Step: 11
Training loss: 1.5172344982281167
Validation loss: 2.463011588980295

Epoch: 6| Step: 12
Training loss: 1.5266794774852013
Validation loss: 2.415824478892089

Epoch: 6| Step: 13
Training loss: 2.179110542970202
Validation loss: 2.408997310696675

Epoch: 204| Step: 0
Training loss: 1.8208416345728613
Validation loss: 2.4017169018851083

Epoch: 6| Step: 1
Training loss: 0.7681551019343337
Validation loss: 2.4247599651355616

Epoch: 6| Step: 2
Training loss: 1.4991688014819793
Validation loss: 2.4328882771101705

Epoch: 6| Step: 3
Training loss: 2.120320497074662
Validation loss: 2.440542114374726

Epoch: 6| Step: 4
Training loss: 1.6255071288849854
Validation loss: 2.469641181301236

Epoch: 6| Step: 5
Training loss: 1.0590799489051395
Validation loss: 2.503183373625301

Epoch: 6| Step: 6
Training loss: 1.8716674434878786
Validation loss: 2.524355857233482

Epoch: 6| Step: 7
Training loss: 1.4406363232347588
Validation loss: 2.5048208229703555

Epoch: 6| Step: 8
Training loss: 1.6612246676911013
Validation loss: 2.5430808655911505

Epoch: 6| Step: 9
Training loss: 1.447643318262617
Validation loss: 2.5421937758702464

Epoch: 6| Step: 10
Training loss: 1.682277935275165
Validation loss: 2.5496755402402784

Epoch: 6| Step: 11
Training loss: 0.8884217968873627
Validation loss: 2.5378814004895283

Epoch: 6| Step: 12
Training loss: 1.4189713561679969
Validation loss: 2.5383474792403455

Epoch: 6| Step: 13
Training loss: 1.6713002723317019
Validation loss: 2.5118498345277414

Epoch: 205| Step: 0
Training loss: 1.524968009363045
Validation loss: 2.463323457862728

Epoch: 6| Step: 1
Training loss: 1.1733191175213749
Validation loss: 2.432406123687989

Epoch: 6| Step: 2
Training loss: 1.362154300825089
Validation loss: 2.427324241805531

Epoch: 6| Step: 3
Training loss: 1.3771505877086196
Validation loss: 2.4235652327434885

Epoch: 6| Step: 4
Training loss: 1.8468702390451273
Validation loss: 2.4261882035661593

Epoch: 6| Step: 5
Training loss: 1.4112202442367139
Validation loss: 2.447116975846502

Epoch: 6| Step: 6
Training loss: 1.5272356468246826
Validation loss: 2.4437614298922647

Epoch: 6| Step: 7
Training loss: 1.643898885387918
Validation loss: 2.4589995619357916

Epoch: 6| Step: 8
Training loss: 1.8191153719711535
Validation loss: 2.4739672371272863

Epoch: 6| Step: 9
Training loss: 1.2678598522871145
Validation loss: 2.5116608200801607

Epoch: 6| Step: 10
Training loss: 1.4540599973334447
Validation loss: 2.526180239598725

Epoch: 6| Step: 11
Training loss: 1.6244691568571563
Validation loss: 2.5327038961633477

Epoch: 6| Step: 12
Training loss: 1.6242372483323486
Validation loss: 2.5221678844461946

Epoch: 6| Step: 13
Training loss: 1.3086998739908688
Validation loss: 2.496792509714459

Epoch: 206| Step: 0
Training loss: 1.1143907873861434
Validation loss: 2.504733746624019

Epoch: 6| Step: 1
Training loss: 1.5707497059276743
Validation loss: 2.4810928630554425

Epoch: 6| Step: 2
Training loss: 1.7651556961073558
Validation loss: 2.478522243765828

Epoch: 6| Step: 3
Training loss: 1.7254716698247816
Validation loss: 2.5013060080999194

Epoch: 6| Step: 4
Training loss: 1.4431605634441695
Validation loss: 2.5039130023243708

Epoch: 6| Step: 5
Training loss: 1.1565206056400992
Validation loss: 2.5129891712953416

Epoch: 6| Step: 6
Training loss: 1.5073918363569008
Validation loss: 2.492746757480393

Epoch: 6| Step: 7
Training loss: 1.2139861093885926
Validation loss: 2.5146310012265447

Epoch: 6| Step: 8
Training loss: 1.7019298454690532
Validation loss: 2.486722527789569

Epoch: 6| Step: 9
Training loss: 0.8088385906959127
Validation loss: 2.469565794012887

Epoch: 6| Step: 10
Training loss: 1.8959038550147307
Validation loss: 2.458728799840166

Epoch: 6| Step: 11
Training loss: 1.4186471204385152
Validation loss: 2.4706049168617774

Epoch: 6| Step: 12
Training loss: 1.3797486409413728
Validation loss: 2.444949769023055

Epoch: 6| Step: 13
Training loss: 1.5685801653478475
Validation loss: 2.4573641662567662

Epoch: 207| Step: 0
Training loss: 1.5613962471163536
Validation loss: 2.4716024186050904

Epoch: 6| Step: 1
Training loss: 1.249886126099715
Validation loss: 2.4720560121063446

Epoch: 6| Step: 2
Training loss: 1.7833190412334883
Validation loss: 2.4696672240630906

Epoch: 6| Step: 3
Training loss: 1.6611300137074085
Validation loss: 2.488765175537759

Epoch: 6| Step: 4
Training loss: 0.9916638171264569
Validation loss: 2.490123078772468

Epoch: 6| Step: 5
Training loss: 1.3081626979245866
Validation loss: 2.507074468736207

Epoch: 6| Step: 6
Training loss: 0.9783973241627519
Validation loss: 2.4922335655122954

Epoch: 6| Step: 7
Training loss: 1.4818859714856478
Validation loss: 2.4810717336122994

Epoch: 6| Step: 8
Training loss: 1.0855189003759562
Validation loss: 2.4793028326600552

Epoch: 6| Step: 9
Training loss: 2.3197571574743163
Validation loss: 2.500003227108749

Epoch: 6| Step: 10
Training loss: 1.2261553045917117
Validation loss: 2.478580767201987

Epoch: 6| Step: 11
Training loss: 1.5634783924099223
Validation loss: 2.46503156248696

Epoch: 6| Step: 12
Training loss: 1.0658005332125093
Validation loss: 2.463857337117425

Epoch: 6| Step: 13
Training loss: 1.2730623406415689
Validation loss: 2.4907720501927932

Epoch: 208| Step: 0
Training loss: 1.3327854739598526
Validation loss: 2.4672226808243813

Epoch: 6| Step: 1
Training loss: 1.2857103631550126
Validation loss: 2.491121255165775

Epoch: 6| Step: 2
Training loss: 1.529309970609639
Validation loss: 2.515557167128722

Epoch: 6| Step: 3
Training loss: 1.5266269260270342
Validation loss: 2.512954117475266

Epoch: 6| Step: 4
Training loss: 1.6230678809467238
Validation loss: 2.506025884509101

Epoch: 6| Step: 5
Training loss: 1.4508262417769866
Validation loss: 2.486678398374293

Epoch: 6| Step: 6
Training loss: 0.8048845438763872
Validation loss: 2.4687498992716366

Epoch: 6| Step: 7
Training loss: 1.4874869402143838
Validation loss: 2.46460911288095

Epoch: 6| Step: 8
Training loss: 1.3079344497756655
Validation loss: 2.475514262644517

Epoch: 6| Step: 9
Training loss: 1.4045799935587004
Validation loss: 2.489511840414382

Epoch: 6| Step: 10
Training loss: 1.255917228920502
Validation loss: 2.4778309056338195

Epoch: 6| Step: 11
Training loss: 1.9733669096220943
Validation loss: 2.4985346242391504

Epoch: 6| Step: 12
Training loss: 1.5683001629398852
Validation loss: 2.487129919586374

Epoch: 6| Step: 13
Training loss: 0.9940756006465871
Validation loss: 2.4972072461122834

Epoch: 209| Step: 0
Training loss: 1.4874412589135282
Validation loss: 2.4681578892238822

Epoch: 6| Step: 1
Training loss: 1.2158069288137612
Validation loss: 2.4572916015382393

Epoch: 6| Step: 2
Training loss: 1.505006224407112
Validation loss: 2.467293102396857

Epoch: 6| Step: 3
Training loss: 0.9873609517381847
Validation loss: 2.464129746498147

Epoch: 6| Step: 4
Training loss: 1.390677676114008
Validation loss: 2.45789036341106

Epoch: 6| Step: 5
Training loss: 1.5097970502773288
Validation loss: 2.4855806336969923

Epoch: 6| Step: 6
Training loss: 0.7881625113458036
Validation loss: 2.475533462579569

Epoch: 6| Step: 7
Training loss: 1.4885279333372268
Validation loss: 2.5473384157505974

Epoch: 6| Step: 8
Training loss: 1.1214350802151982
Validation loss: 2.5588480119413752

Epoch: 6| Step: 9
Training loss: 1.339738046463595
Validation loss: 2.5630407175568903

Epoch: 6| Step: 10
Training loss: 0.9888968981431611
Validation loss: 2.536505393210995

Epoch: 6| Step: 11
Training loss: 1.6394516881936907
Validation loss: 2.523911756445196

Epoch: 6| Step: 12
Training loss: 2.172881188351403
Validation loss: 2.4945910987141264

Epoch: 6| Step: 13
Training loss: 1.6678916323699546
Validation loss: 2.477875723373594

Epoch: 210| Step: 0
Training loss: 1.6366615740637915
Validation loss: 2.474246589866175

Epoch: 6| Step: 1
Training loss: 1.4417843206536527
Validation loss: 2.460951078956593

Epoch: 6| Step: 2
Training loss: 0.8655788863806543
Validation loss: 2.4729437949311066

Epoch: 6| Step: 3
Training loss: 1.4689249786685987
Validation loss: 2.47998542601742

Epoch: 6| Step: 4
Training loss: 1.1915013009599313
Validation loss: 2.4502848281523097

Epoch: 6| Step: 5
Training loss: 1.31861058985298
Validation loss: 2.448323600386592

Epoch: 6| Step: 6
Training loss: 1.5223246887197692
Validation loss: 2.4571631121148947

Epoch: 6| Step: 7
Training loss: 1.2499657626231617
Validation loss: 2.4510166442139676

Epoch: 6| Step: 8
Training loss: 1.4488494484762644
Validation loss: 2.4390325006702294

Epoch: 6| Step: 9
Training loss: 1.3228486211302748
Validation loss: 2.449876318650241

Epoch: 6| Step: 10
Training loss: 1.423037881375128
Validation loss: 2.4870881831409637

Epoch: 6| Step: 11
Training loss: 1.9143101123320532
Validation loss: 2.502507248183119

Epoch: 6| Step: 12
Training loss: 1.0865211290674066
Validation loss: 2.5430947982901233

Epoch: 6| Step: 13
Training loss: 1.1834066513791366
Validation loss: 2.5978425552430093

Epoch: 211| Step: 0
Training loss: 1.3471298295332963
Validation loss: 2.6486122527919473

Epoch: 6| Step: 1
Training loss: 1.712291373471643
Validation loss: 2.6521387798645497

Epoch: 6| Step: 2
Training loss: 1.1192910724062672
Validation loss: 2.5878060040499022

Epoch: 6| Step: 3
Training loss: 0.7426983330166169
Validation loss: 2.539318134069645

Epoch: 6| Step: 4
Training loss: 1.5124436643843635
Validation loss: 2.466800639192906

Epoch: 6| Step: 5
Training loss: 1.7164304860921185
Validation loss: 2.4411140019554978

Epoch: 6| Step: 6
Training loss: 1.084661378889397
Validation loss: 2.408557389637193

Epoch: 6| Step: 7
Training loss: 1.0652326896494677
Validation loss: 2.395808936623959

Epoch: 6| Step: 8
Training loss: 1.698154510814457
Validation loss: 2.378757686823181

Epoch: 6| Step: 9
Training loss: 1.047828354094102
Validation loss: 2.392570688798242

Epoch: 6| Step: 10
Training loss: 1.3859493216404999
Validation loss: 2.391331620180218

Epoch: 6| Step: 11
Training loss: 1.4875190765696316
Validation loss: 2.4160421232411657

Epoch: 6| Step: 12
Training loss: 1.944085649660043
Validation loss: 2.43000266115627

Epoch: 6| Step: 13
Training loss: 1.1704897004089476
Validation loss: 2.4752486275490035

Epoch: 212| Step: 0
Training loss: 1.3588105268429413
Validation loss: 2.4958676332979945

Epoch: 6| Step: 1
Training loss: 1.2972643623931723
Validation loss: 2.4986883075619994

Epoch: 6| Step: 2
Training loss: 1.603293251295298
Validation loss: 2.502938094578753

Epoch: 6| Step: 3
Training loss: 1.2575188999007065
Validation loss: 2.4878874848535726

Epoch: 6| Step: 4
Training loss: 1.048560706913853
Validation loss: 2.4391447911963446

Epoch: 6| Step: 5
Training loss: 1.2509649843488648
Validation loss: 2.433989539847218

Epoch: 6| Step: 6
Training loss: 1.8837259063496168
Validation loss: 2.4281966572872276

Epoch: 6| Step: 7
Training loss: 1.3338245837908023
Validation loss: 2.439609392106004

Epoch: 6| Step: 8
Training loss: 1.6062375940222284
Validation loss: 2.4280426278749894

Epoch: 6| Step: 9
Training loss: 1.2994141138748487
Validation loss: 2.444106823955509

Epoch: 6| Step: 10
Training loss: 1.063142694306955
Validation loss: 2.4371632326783237

Epoch: 6| Step: 11
Training loss: 1.6484075606822792
Validation loss: 2.456068242306249

Epoch: 6| Step: 12
Training loss: 0.8717053921803086
Validation loss: 2.4802214618329934

Epoch: 6| Step: 13
Training loss: 1.1514600048233654
Validation loss: 2.4930820526711543

Epoch: 213| Step: 0
Training loss: 0.760435539603636
Validation loss: 2.4916868552737457

Epoch: 6| Step: 1
Training loss: 1.425487080365965
Validation loss: 2.500625438800305

Epoch: 6| Step: 2
Training loss: 1.3570107695110716
Validation loss: 2.472179835642368

Epoch: 6| Step: 3
Training loss: 0.9385977358199195
Validation loss: 2.4681073836471477

Epoch: 6| Step: 4
Training loss: 1.295754511644832
Validation loss: 2.4783746842245216

Epoch: 6| Step: 5
Training loss: 1.5257382747694028
Validation loss: 2.474137243117476

Epoch: 6| Step: 6
Training loss: 1.9749345068393866
Validation loss: 2.4531525055870564

Epoch: 6| Step: 7
Training loss: 1.2242866346359291
Validation loss: 2.4532510236383467

Epoch: 6| Step: 8
Training loss: 1.581485908611956
Validation loss: 2.4955184946118387

Epoch: 6| Step: 9
Training loss: 1.4486224240602636
Validation loss: 2.508301253953948

Epoch: 6| Step: 10
Training loss: 1.1849987893561122
Validation loss: 2.514215362687524

Epoch: 6| Step: 11
Training loss: 1.3621024908051003
Validation loss: 2.5444535164352584

Epoch: 6| Step: 12
Training loss: 1.0709582420457622
Validation loss: 2.546568064335344

Epoch: 6| Step: 13
Training loss: 0.9159929805470002
Validation loss: 2.531110798461694

Epoch: 214| Step: 0
Training loss: 1.694070809587943
Validation loss: 2.55069556878574

Epoch: 6| Step: 1
Training loss: 0.673712524228172
Validation loss: 2.5274215736724686

Epoch: 6| Step: 2
Training loss: 0.8467724671177763
Validation loss: 2.51436447717831

Epoch: 6| Step: 3
Training loss: 1.427429083083095
Validation loss: 2.495772006502206

Epoch: 6| Step: 4
Training loss: 1.005755669145681
Validation loss: 2.446070245745873

Epoch: 6| Step: 5
Training loss: 1.7886699928928593
Validation loss: 2.432682511257331

Epoch: 6| Step: 6
Training loss: 1.5427438306448669
Validation loss: 2.4254424761013493

Epoch: 6| Step: 7
Training loss: 1.631941713732155
Validation loss: 2.432440492310847

Epoch: 6| Step: 8
Training loss: 1.3738700385231002
Validation loss: 2.443999249886926

Epoch: 6| Step: 9
Training loss: 1.237173794610023
Validation loss: 2.4538224326622955

Epoch: 6| Step: 10
Training loss: 1.1730992343940738
Validation loss: 2.4590156870707096

Epoch: 6| Step: 11
Training loss: 1.0823026241057438
Validation loss: 2.454689250849415

Epoch: 6| Step: 12
Training loss: 1.2911372740619438
Validation loss: 2.474515246329303

Epoch: 6| Step: 13
Training loss: 0.8585601758423518
Validation loss: 2.4875532394287827

Epoch: 215| Step: 0
Training loss: 1.3689539369868502
Validation loss: 2.4724190590484345

Epoch: 6| Step: 1
Training loss: 1.175462445099318
Validation loss: 2.485962727555076

Epoch: 6| Step: 2
Training loss: 1.3662670851997718
Validation loss: 2.5010257031942813

Epoch: 6| Step: 3
Training loss: 1.3820539646212022
Validation loss: 2.4855011678178744

Epoch: 6| Step: 4
Training loss: 1.0882835568898568
Validation loss: 2.468355011459241

Epoch: 6| Step: 5
Training loss: 1.8611415517351422
Validation loss: 2.49089665285443

Epoch: 6| Step: 6
Training loss: 1.3806582982963826
Validation loss: 2.4657465145439628

Epoch: 6| Step: 7
Training loss: 1.0638665219062025
Validation loss: 2.468276629970853

Epoch: 6| Step: 8
Training loss: 1.5591264545767556
Validation loss: 2.442803553639736

Epoch: 6| Step: 9
Training loss: 0.9716303980608797
Validation loss: 2.4410861181240944

Epoch: 6| Step: 10
Training loss: 1.3943176533368131
Validation loss: 2.447255891117451

Epoch: 6| Step: 11
Training loss: 1.4641173329054473
Validation loss: 2.443902677158999

Epoch: 6| Step: 12
Training loss: 1.025750843535859
Validation loss: 2.460825642382462

Epoch: 6| Step: 13
Training loss: 0.5983352543907177
Validation loss: 2.4757009741423914

Epoch: 216| Step: 0
Training loss: 1.0773339617577065
Validation loss: 2.465293866970217

Epoch: 6| Step: 1
Training loss: 1.5377082094465426
Validation loss: 2.5126091018503454

Epoch: 6| Step: 2
Training loss: 1.7413845521269076
Validation loss: 2.496659773109216

Epoch: 6| Step: 3
Training loss: 1.4139002079855139
Validation loss: 2.535847275794265

Epoch: 6| Step: 4
Training loss: 1.21792388696365
Validation loss: 2.519417923628846

Epoch: 6| Step: 5
Training loss: 1.3763275673442845
Validation loss: 2.511409632755281

Epoch: 6| Step: 6
Training loss: 1.0012830609257923
Validation loss: 2.5265190611322312

Epoch: 6| Step: 7
Training loss: 1.3242274371287002
Validation loss: 2.4827484349549493

Epoch: 6| Step: 8
Training loss: 1.4745552103566324
Validation loss: 2.4582241639650317

Epoch: 6| Step: 9
Training loss: 1.1958546624402628
Validation loss: 2.4532563238588017

Epoch: 6| Step: 10
Training loss: 0.8510043213462263
Validation loss: 2.4240343971021905

Epoch: 6| Step: 11
Training loss: 1.1465974456294212
Validation loss: 2.4316035149622834

Epoch: 6| Step: 12
Training loss: 1.3297347691311479
Validation loss: 2.424600208633581

Epoch: 6| Step: 13
Training loss: 1.0523306049299068
Validation loss: 2.458542963110252

Epoch: 217| Step: 0
Training loss: 1.0326268801190057
Validation loss: 2.4920739691843132

Epoch: 6| Step: 1
Training loss: 1.6772966268997787
Validation loss: 2.4993135273746088

Epoch: 6| Step: 2
Training loss: 1.0757240429795585
Validation loss: 2.5190272182015465

Epoch: 6| Step: 3
Training loss: 1.0302197483048765
Validation loss: 2.504094269575672

Epoch: 6| Step: 4
Training loss: 1.6107687979274328
Validation loss: 2.4661684486223776

Epoch: 6| Step: 5
Training loss: 1.2768264329573857
Validation loss: 2.488830007237418

Epoch: 6| Step: 6
Training loss: 1.5441711376445924
Validation loss: 2.4789708419427448

Epoch: 6| Step: 7
Training loss: 1.135553870820921
Validation loss: 2.4605889259230014

Epoch: 6| Step: 8
Training loss: 1.1187129776438982
Validation loss: 2.4900652857909424

Epoch: 6| Step: 9
Training loss: 1.475099999868835
Validation loss: 2.4756123257346054

Epoch: 6| Step: 10
Training loss: 1.1292931444811751
Validation loss: 2.467179057281471

Epoch: 6| Step: 11
Training loss: 1.022428816297172
Validation loss: 2.4535131534705727

Epoch: 6| Step: 12
Training loss: 0.988176423193917
Validation loss: 2.422994125773437

Epoch: 6| Step: 13
Training loss: 1.5107630979130207
Validation loss: 2.4532835050736272

Epoch: 218| Step: 0
Training loss: 1.119837039944971
Validation loss: 2.467922066151688

Epoch: 6| Step: 1
Training loss: 1.1926723569194424
Validation loss: 2.4701165430291607

Epoch: 6| Step: 2
Training loss: 0.7600496050682871
Validation loss: 2.459112196925739

Epoch: 6| Step: 3
Training loss: 0.8791101515866722
Validation loss: 2.487662929624766

Epoch: 6| Step: 4
Training loss: 1.6595624512509466
Validation loss: 2.477037388354877

Epoch: 6| Step: 5
Training loss: 0.7300928546038075
Validation loss: 2.494129499361032

Epoch: 6| Step: 6
Training loss: 1.476753424355544
Validation loss: 2.5035429839427286

Epoch: 6| Step: 7
Training loss: 1.7942964047260128
Validation loss: 2.494008245796782

Epoch: 6| Step: 8
Training loss: 1.4249139525551286
Validation loss: 2.4802055970544865

Epoch: 6| Step: 9
Training loss: 1.5117797839241625
Validation loss: 2.5020405532482872

Epoch: 6| Step: 10
Training loss: 1.1382409355025513
Validation loss: 2.4708026376158867

Epoch: 6| Step: 11
Training loss: 1.178772122771185
Validation loss: 2.4699569769378025

Epoch: 6| Step: 12
Training loss: 0.8530887260690128
Validation loss: 2.4639328033406174

Epoch: 6| Step: 13
Training loss: 1.443684831609943
Validation loss: 2.4781960444944113

Epoch: 219| Step: 0
Training loss: 1.2533995177839468
Validation loss: 2.4831416450093076

Epoch: 6| Step: 1
Training loss: 1.270471594350697
Validation loss: 2.4829127772865696

Epoch: 6| Step: 2
Training loss: 1.1838742166217915
Validation loss: 2.508093340450599

Epoch: 6| Step: 3
Training loss: 1.2847512021390386
Validation loss: 2.509001462198407

Epoch: 6| Step: 4
Training loss: 1.0175336070216339
Validation loss: 2.517584064715649

Epoch: 6| Step: 5
Training loss: 1.0503464263548694
Validation loss: 2.508305768399922

Epoch: 6| Step: 6
Training loss: 0.6659492168711469
Validation loss: 2.46771891817311

Epoch: 6| Step: 7
Training loss: 1.3037463236946216
Validation loss: 2.4741733628989646

Epoch: 6| Step: 8
Training loss: 1.2212721330087613
Validation loss: 2.497252094404756

Epoch: 6| Step: 9
Training loss: 1.784590550112006
Validation loss: 2.474410215773197

Epoch: 6| Step: 10
Training loss: 1.3242158692815273
Validation loss: 2.4953895695180246

Epoch: 6| Step: 11
Training loss: 1.2828810939500979
Validation loss: 2.5057800130523504

Epoch: 6| Step: 12
Training loss: 1.1833460583248891
Validation loss: 2.50651136513628

Epoch: 6| Step: 13
Training loss: 1.1404855721316594
Validation loss: 2.5109051693040674

Epoch: 220| Step: 0
Training loss: 1.1820307820502627
Validation loss: 2.5160594919861143

Epoch: 6| Step: 1
Training loss: 1.4016909554259849
Validation loss: 2.516019173355706

Epoch: 6| Step: 2
Training loss: 0.9056820569647789
Validation loss: 2.5165527381798865

Epoch: 6| Step: 3
Training loss: 1.2947365468518235
Validation loss: 2.5064501860655666

Epoch: 6| Step: 4
Training loss: 0.9581116475209428
Validation loss: 2.471783589486746

Epoch: 6| Step: 5
Training loss: 1.22501873858386
Validation loss: 2.463465968187435

Epoch: 6| Step: 6
Training loss: 1.000839060201361
Validation loss: 2.452215866067632

Epoch: 6| Step: 7
Training loss: 0.8357168245044102
Validation loss: 2.461136049489818

Epoch: 6| Step: 8
Training loss: 1.319920363119117
Validation loss: 2.468245480046033

Epoch: 6| Step: 9
Training loss: 1.8527343518367527
Validation loss: 2.4987309895975605

Epoch: 6| Step: 10
Training loss: 1.3355615990477843
Validation loss: 2.5178388371185365

Epoch: 6| Step: 11
Training loss: 1.083150842163536
Validation loss: 2.4694103719653997

Epoch: 6| Step: 12
Training loss: 1.26998583357712
Validation loss: 2.472907479397824

Epoch: 6| Step: 13
Training loss: 1.2665313489477596
Validation loss: 2.4616001032099244

Epoch: 221| Step: 0
Training loss: 1.2996628911081833
Validation loss: 2.4724221863238203

Epoch: 6| Step: 1
Training loss: 1.3480070680297151
Validation loss: 2.4780524785070233

Epoch: 6| Step: 2
Training loss: 1.3744948933250838
Validation loss: 2.5170355385975287

Epoch: 6| Step: 3
Training loss: 1.3678211596578478
Validation loss: 2.529516930524973

Epoch: 6| Step: 4
Training loss: 1.1757506306358818
Validation loss: 2.565013674063292

Epoch: 6| Step: 5
Training loss: 1.4524944947445355
Validation loss: 2.56909258657072

Epoch: 6| Step: 6
Training loss: 0.8766017966208302
Validation loss: 2.5587519766083973

Epoch: 6| Step: 7
Training loss: 0.8831159694612172
Validation loss: 2.54528963587646

Epoch: 6| Step: 8
Training loss: 1.6603186673768353
Validation loss: 2.571631390335076

Epoch: 6| Step: 9
Training loss: 1.4363925648608646
Validation loss: 2.5450166452256244

Epoch: 6| Step: 10
Training loss: 0.7811825150906748
Validation loss: 2.5139299461601485

Epoch: 6| Step: 11
Training loss: 0.5963196862482142
Validation loss: 2.5186658348035396

Epoch: 6| Step: 12
Training loss: 1.0039107623165857
Validation loss: 2.5215398496191033

Epoch: 6| Step: 13
Training loss: 1.3748496580295018
Validation loss: 2.4965684330172375

Epoch: 222| Step: 0
Training loss: 1.4090053691098408
Validation loss: 2.4772643995490156

Epoch: 6| Step: 1
Training loss: 1.3149686485440433
Validation loss: 2.4610355168212426

Epoch: 6| Step: 2
Training loss: 1.1457757010560279
Validation loss: 2.424534625878783

Epoch: 6| Step: 3
Training loss: 1.1664611885229805
Validation loss: 2.4370380034251222

Epoch: 6| Step: 4
Training loss: 0.8208354554576519
Validation loss: 2.430234976828152

Epoch: 6| Step: 5
Training loss: 1.0183372082509075
Validation loss: 2.4689917663433074

Epoch: 6| Step: 6
Training loss: 1.546815736194092
Validation loss: 2.4656113548280225

Epoch: 6| Step: 7
Training loss: 1.1549448431146863
Validation loss: 2.486399710836956

Epoch: 6| Step: 8
Training loss: 0.8352574942788376
Validation loss: 2.5033215212813302

Epoch: 6| Step: 9
Training loss: 1.3915847723767811
Validation loss: 2.519528192389667

Epoch: 6| Step: 10
Training loss: 1.2050583403460993
Validation loss: 2.5220290060081183

Epoch: 6| Step: 11
Training loss: 1.3602910079677923
Validation loss: 2.494366131538851

Epoch: 6| Step: 12
Training loss: 1.1986892972817629
Validation loss: 2.4901923246008217

Epoch: 6| Step: 13
Training loss: 0.9595235641213912
Validation loss: 2.4673751506465234

Epoch: 223| Step: 0
Training loss: 1.1347675159326973
Validation loss: 2.459740507825371

Epoch: 6| Step: 1
Training loss: 1.1885159814295319
Validation loss: 2.440851237947006

Epoch: 6| Step: 2
Training loss: 1.650614164664235
Validation loss: 2.476522020737839

Epoch: 6| Step: 3
Training loss: 1.2631157855755268
Validation loss: 2.4427528239985405

Epoch: 6| Step: 4
Training loss: 1.1571128821569345
Validation loss: 2.4403926318009064

Epoch: 6| Step: 5
Training loss: 1.1336165107108855
Validation loss: 2.478180853130433

Epoch: 6| Step: 6
Training loss: 1.551395630866898
Validation loss: 2.4971686460516733

Epoch: 6| Step: 7
Training loss: 0.6240689495366577
Validation loss: 2.4864695856707106

Epoch: 6| Step: 8
Training loss: 0.6624701763133943
Validation loss: 2.4994398361136088

Epoch: 6| Step: 9
Training loss: 1.2362409563958427
Validation loss: 2.50037142957971

Epoch: 6| Step: 10
Training loss: 1.1934830871489583
Validation loss: 2.4916036773675416

Epoch: 6| Step: 11
Training loss: 1.1066879181564058
Validation loss: 2.514218880506298

Epoch: 6| Step: 12
Training loss: 1.3098699922332138
Validation loss: 2.5071045380322676

Epoch: 6| Step: 13
Training loss: 1.0548215992765573
Validation loss: 2.4639043079076317

Epoch: 224| Step: 0
Training loss: 0.7264095678682428
Validation loss: 2.466240246442064

Epoch: 6| Step: 1
Training loss: 1.222415595700104
Validation loss: 2.461762454639605

Epoch: 6| Step: 2
Training loss: 1.1278400071727728
Validation loss: 2.4833576717025054

Epoch: 6| Step: 3
Training loss: 1.567093315603238
Validation loss: 2.473316229936438

Epoch: 6| Step: 4
Training loss: 0.7985612568060023
Validation loss: 2.461293914710963

Epoch: 6| Step: 5
Training loss: 1.2504716460206229
Validation loss: 2.4661390174507924

Epoch: 6| Step: 6
Training loss: 1.7727447366632307
Validation loss: 2.4723668964242194

Epoch: 6| Step: 7
Training loss: 1.1561540099843344
Validation loss: 2.4695870307229715

Epoch: 6| Step: 8
Training loss: 1.2301477407100332
Validation loss: 2.446909493894569

Epoch: 6| Step: 9
Training loss: 1.079268968119889
Validation loss: 2.4433887941217924

Epoch: 6| Step: 10
Training loss: 1.062636422767537
Validation loss: 2.407819422827253

Epoch: 6| Step: 11
Training loss: 0.9674003182053215
Validation loss: 2.4084429295034937

Epoch: 6| Step: 12
Training loss: 1.0161663080078946
Validation loss: 2.409810958233575

Epoch: 6| Step: 13
Training loss: 1.257115425624917
Validation loss: 2.443894175043228

Epoch: 225| Step: 0
Training loss: 1.3404592985172825
Validation loss: 2.4410378901376424

Epoch: 6| Step: 1
Training loss: 1.4567116394491368
Validation loss: 2.4708447918137435

Epoch: 6| Step: 2
Training loss: 1.2881559016016093
Validation loss: 2.4856498936498386

Epoch: 6| Step: 3
Training loss: 0.9131166830343384
Validation loss: 2.477843548792225

Epoch: 6| Step: 4
Training loss: 0.7116677861647842
Validation loss: 2.519062160542892

Epoch: 6| Step: 5
Training loss: 0.9047855185741146
Validation loss: 2.535227465783142

Epoch: 6| Step: 6
Training loss: 1.230806770520189
Validation loss: 2.5409934027849945

Epoch: 6| Step: 7
Training loss: 1.0690052374630297
Validation loss: 2.517448696205937

Epoch: 6| Step: 8
Training loss: 1.280407046774219
Validation loss: 2.500367056654655

Epoch: 6| Step: 9
Training loss: 0.6227332494742536
Validation loss: 2.5005477940899583

Epoch: 6| Step: 10
Training loss: 1.1845746901164733
Validation loss: 2.457824369302179

Epoch: 6| Step: 11
Training loss: 1.9518471161349713
Validation loss: 2.4439900893621718

Epoch: 6| Step: 12
Training loss: 0.7860008745067284
Validation loss: 2.461055191176534

Epoch: 6| Step: 13
Training loss: 0.7097999778584175
Validation loss: 2.4344451557406432

Epoch: 226| Step: 0
Training loss: 1.3182898382992496
Validation loss: 2.4656388573296324

Epoch: 6| Step: 1
Training loss: 1.043066241676211
Validation loss: 2.4561589665626493

Epoch: 6| Step: 2
Training loss: 1.202005336000655
Validation loss: 2.506661330645914

Epoch: 6| Step: 3
Training loss: 1.0912628232501824
Validation loss: 2.5063594052940985

Epoch: 6| Step: 4
Training loss: 1.2363503018720903
Validation loss: 2.4963259125130395

Epoch: 6| Step: 5
Training loss: 0.9153672386047719
Validation loss: 2.516709627049532

Epoch: 6| Step: 6
Training loss: 1.2618892306488518
Validation loss: 2.4874655132651715

Epoch: 6| Step: 7
Training loss: 0.9585445661914805
Validation loss: 2.482294891900492

Epoch: 6| Step: 8
Training loss: 1.536776243607263
Validation loss: 2.4897014855729513

Epoch: 6| Step: 9
Training loss: 0.8045704580574405
Validation loss: 2.4472832144005037

Epoch: 6| Step: 10
Training loss: 1.3311418265508708
Validation loss: 2.474289987264385

Epoch: 6| Step: 11
Training loss: 1.1470053949470322
Validation loss: 2.4389092132038934

Epoch: 6| Step: 12
Training loss: 0.969055435268086
Validation loss: 2.4493385601353457

Epoch: 6| Step: 13
Training loss: 1.0410638908949017
Validation loss: 2.4222166351694714

Epoch: 227| Step: 0
Training loss: 0.720851438401544
Validation loss: 2.412088608449975

Epoch: 6| Step: 1
Training loss: 0.9598040214810438
Validation loss: 2.4480251894746767

Epoch: 6| Step: 2
Training loss: 1.1318291440929376
Validation loss: 2.4461409209887695

Epoch: 6| Step: 3
Training loss: 1.1142429414336847
Validation loss: 2.4926200854129354

Epoch: 6| Step: 4
Training loss: 1.4054773963378124
Validation loss: 2.4943895389451582

Epoch: 6| Step: 5
Training loss: 0.9196557309946645
Validation loss: 2.4888443085292766

Epoch: 6| Step: 6
Training loss: 0.8740706958461513
Validation loss: 2.4767501458216925

Epoch: 6| Step: 7
Training loss: 0.7631049820432522
Validation loss: 2.485021387267623

Epoch: 6| Step: 8
Training loss: 0.9886004268010179
Validation loss: 2.4825736085850396

Epoch: 6| Step: 9
Training loss: 1.783860953287919
Validation loss: 2.4579639743064368

Epoch: 6| Step: 10
Training loss: 1.4609069005036177
Validation loss: 2.454366507878478

Epoch: 6| Step: 11
Training loss: 1.2399478611444226
Validation loss: 2.4553759830957547

Epoch: 6| Step: 12
Training loss: 0.9751192337880812
Validation loss: 2.4495078510224357

Epoch: 6| Step: 13
Training loss: 1.250540997735709
Validation loss: 2.4695021788130123

Epoch: 228| Step: 0
Training loss: 1.3721028062767133
Validation loss: 2.491393983503893

Epoch: 6| Step: 1
Training loss: 1.1507433624142447
Validation loss: 2.5050560809009714

Epoch: 6| Step: 2
Training loss: 1.2027242414165906
Validation loss: 2.4995679061499425

Epoch: 6| Step: 3
Training loss: 1.0056629766924003
Validation loss: 2.5249220601011833

Epoch: 6| Step: 4
Training loss: 0.8678699935093981
Validation loss: 2.541085111298793

Epoch: 6| Step: 5
Training loss: 1.2457140400821924
Validation loss: 2.5243935627488865

Epoch: 6| Step: 6
Training loss: 1.1905094961775364
Validation loss: 2.558789329565395

Epoch: 6| Step: 7
Training loss: 0.8609359436574947
Validation loss: 2.5227492936407403

Epoch: 6| Step: 8
Training loss: 1.054540722841601
Validation loss: 2.4976051427030006

Epoch: 6| Step: 9
Training loss: 1.239317355217278
Validation loss: 2.4707947852431946

Epoch: 6| Step: 10
Training loss: 1.356667376165806
Validation loss: 2.448021215241017

Epoch: 6| Step: 11
Training loss: 1.47681065648864
Validation loss: 2.482847430720588

Epoch: 6| Step: 12
Training loss: 0.7338793278954603
Validation loss: 2.4602449259353367

Epoch: 6| Step: 13
Training loss: 0.44842324516687593
Validation loss: 2.4992185345458298

Epoch: 229| Step: 0
Training loss: 1.2278043935133862
Validation loss: 2.500634892149555

Epoch: 6| Step: 1
Training loss: 0.9537419995513574
Validation loss: 2.510565026825445

Epoch: 6| Step: 2
Training loss: 0.5669434203523296
Validation loss: 2.519331434230791

Epoch: 6| Step: 3
Training loss: 1.07186626508618
Validation loss: 2.543047883873698

Epoch: 6| Step: 4
Training loss: 0.8324166421712358
Validation loss: 2.5170533157107053

Epoch: 6| Step: 5
Training loss: 1.1338701769507855
Validation loss: 2.5211411724372064

Epoch: 6| Step: 6
Training loss: 1.1007339391565503
Validation loss: 2.5115022102352063

Epoch: 6| Step: 7
Training loss: 1.0209550525474687
Validation loss: 2.4950457418361554

Epoch: 6| Step: 8
Training loss: 1.16493883365293
Validation loss: 2.4638055322178833

Epoch: 6| Step: 9
Training loss: 1.6171152587087694
Validation loss: 2.4444894190077173

Epoch: 6| Step: 10
Training loss: 1.0521398220697364
Validation loss: 2.4548572177199235

Epoch: 6| Step: 11
Training loss: 1.0438790795464978
Validation loss: 2.450096790862046

Epoch: 6| Step: 12
Training loss: 1.0716667239860016
Validation loss: 2.432658907922565

Epoch: 6| Step: 13
Training loss: 1.2078779392848176
Validation loss: 2.445591655587003

Epoch: 230| Step: 0
Training loss: 0.9930640426278999
Validation loss: 2.442621259744244

Epoch: 6| Step: 1
Training loss: 0.5935517030159523
Validation loss: 2.4169549660433627

Epoch: 6| Step: 2
Training loss: 0.9583419232743668
Validation loss: 2.431424218237762

Epoch: 6| Step: 3
Training loss: 1.2883055342865923
Validation loss: 2.451339909277835

Epoch: 6| Step: 4
Training loss: 0.8573267716690119
Validation loss: 2.4786690539774767

Epoch: 6| Step: 5
Training loss: 0.9987151116685916
Validation loss: 2.4972576913379263

Epoch: 6| Step: 6
Training loss: 1.2795982413550238
Validation loss: 2.503441380100831

Epoch: 6| Step: 7
Training loss: 0.9145866260744459
Validation loss: 2.476568108495338

Epoch: 6| Step: 8
Training loss: 1.3153743151683162
Validation loss: 2.4955160804608636

Epoch: 6| Step: 9
Training loss: 1.0783366120026716
Validation loss: 2.482323686404413

Epoch: 6| Step: 10
Training loss: 0.9432622571280752
Validation loss: 2.475176214800305

Epoch: 6| Step: 11
Training loss: 0.9270995206526956
Validation loss: 2.473074943364317

Epoch: 6| Step: 12
Training loss: 1.106088686889838
Validation loss: 2.493408768488398

Epoch: 6| Step: 13
Training loss: 1.8472239208293297
Validation loss: 2.482458857372688

Epoch: 231| Step: 0
Training loss: 0.9538902587549999
Validation loss: 2.462109326228435

Epoch: 6| Step: 1
Training loss: 0.9236091854359016
Validation loss: 2.441096844893513

Epoch: 6| Step: 2
Training loss: 0.9160708998410625
Validation loss: 2.4474374302446344

Epoch: 6| Step: 3
Training loss: 0.7682889408628902
Validation loss: 2.4529790741491966

Epoch: 6| Step: 4
Training loss: 0.9257851773593186
Validation loss: 2.5026059361276216

Epoch: 6| Step: 5
Training loss: 1.0338724488660542
Validation loss: 2.52987312597022

Epoch: 6| Step: 6
Training loss: 1.5741352977356784
Validation loss: 2.5235155883967004

Epoch: 6| Step: 7
Training loss: 1.2826975112284207
Validation loss: 2.5517058360552123

Epoch: 6| Step: 8
Training loss: 1.1590178584812147
Validation loss: 2.497417274622664

Epoch: 6| Step: 9
Training loss: 1.45451255918282
Validation loss: 2.470825164282835

Epoch: 6| Step: 10
Training loss: 0.8630173914274202
Validation loss: 2.446419261080733

Epoch: 6| Step: 11
Training loss: 0.7989980801307425
Validation loss: 2.4520441107275905

Epoch: 6| Step: 12
Training loss: 1.082175730620057
Validation loss: 2.411546007673412

Epoch: 6| Step: 13
Training loss: 0.8639861461160065
Validation loss: 2.389684836620184

Epoch: 232| Step: 0
Training loss: 1.0215384066060682
Validation loss: 2.380178676504926

Epoch: 6| Step: 1
Training loss: 1.4532350888132843
Validation loss: 2.3948224460784977

Epoch: 6| Step: 2
Training loss: 1.1524511254926042
Validation loss: 2.3919448351265653

Epoch: 6| Step: 3
Training loss: 1.0748506109543017
Validation loss: 2.4054357479842494

Epoch: 6| Step: 4
Training loss: 1.2141514611759354
Validation loss: 2.4506123721527815

Epoch: 6| Step: 5
Training loss: 0.8838853646599809
Validation loss: 2.47876391849614

Epoch: 6| Step: 6
Training loss: 0.9489034435143403
Validation loss: 2.4964533792997736

Epoch: 6| Step: 7
Training loss: 0.9185861013152115
Validation loss: 2.4990503948243132

Epoch: 6| Step: 8
Training loss: 0.7063796692361254
Validation loss: 2.5010136395200186

Epoch: 6| Step: 9
Training loss: 0.6985768616507124
Validation loss: 2.503647110801909

Epoch: 6| Step: 10
Training loss: 1.1317853282708896
Validation loss: 2.4976044339464085

Epoch: 6| Step: 11
Training loss: 0.9071490005171431
Validation loss: 2.5144544734314405

Epoch: 6| Step: 12
Training loss: 1.3545404162962
Validation loss: 2.515425565948195

Epoch: 6| Step: 13
Training loss: 1.073746511522517
Validation loss: 2.520260346990587

Epoch: 233| Step: 0
Training loss: 0.9206228966569149
Validation loss: 2.5081421674369495

Epoch: 6| Step: 1
Training loss: 1.2638463838763607
Validation loss: 2.4878533891305454

Epoch: 6| Step: 2
Training loss: 1.2816897312233617
Validation loss: 2.468939343366199

Epoch: 6| Step: 3
Training loss: 0.6913014779746502
Validation loss: 2.4743744258132265

Epoch: 6| Step: 4
Training loss: 0.9276786064652512
Validation loss: 2.472215345241852

Epoch: 6| Step: 5
Training loss: 0.992454132538409
Validation loss: 2.4564413782305854

Epoch: 6| Step: 6
Training loss: 0.8802951265840879
Validation loss: 2.452972874530281

Epoch: 6| Step: 7
Training loss: 1.1561309134527706
Validation loss: 2.452274462189962

Epoch: 6| Step: 8
Training loss: 0.8268180466556052
Validation loss: 2.421290435794729

Epoch: 6| Step: 9
Training loss: 1.035845947823063
Validation loss: 2.459245066011789

Epoch: 6| Step: 10
Training loss: 1.3594668565605448
Validation loss: 2.4646768319225325

Epoch: 6| Step: 11
Training loss: 0.9240550433913612
Validation loss: 2.464727742718206

Epoch: 6| Step: 12
Training loss: 0.9399043405333785
Validation loss: 2.462790443969768

Epoch: 6| Step: 13
Training loss: 1.03280637799871
Validation loss: 2.492288145181124

Epoch: 234| Step: 0
Training loss: 1.0295115759088966
Validation loss: 2.439560528578868

Epoch: 6| Step: 1
Training loss: 1.1353030483315472
Validation loss: 2.4401785040866852

Epoch: 6| Step: 2
Training loss: 1.1453899508279715
Validation loss: 2.4024245739351584

Epoch: 6| Step: 3
Training loss: 1.5361443753786446
Validation loss: 2.3775961734407476

Epoch: 6| Step: 4
Training loss: 1.266526548683405
Validation loss: 2.3818516690821787

Epoch: 6| Step: 5
Training loss: 1.2236924335784178
Validation loss: 2.374686943194165

Epoch: 6| Step: 6
Training loss: 0.8224786043138056
Validation loss: 2.370187856412772

Epoch: 6| Step: 7
Training loss: 0.775532053773836
Validation loss: 2.3810552596061054

Epoch: 6| Step: 8
Training loss: 0.6052119787328539
Validation loss: 2.416640742639909

Epoch: 6| Step: 9
Training loss: 0.8048399993684677
Validation loss: 2.446141007451633

Epoch: 6| Step: 10
Training loss: 0.6504587819354843
Validation loss: 2.4691704978275104

Epoch: 6| Step: 11
Training loss: 0.9252957708874952
Validation loss: 2.5388075601646345

Epoch: 6| Step: 12
Training loss: 1.1731186434817964
Validation loss: 2.5286060503024284

Epoch: 6| Step: 13
Training loss: 0.7851486964835083
Validation loss: 2.5668923814776927

Epoch: 235| Step: 0
Training loss: 0.5075265519473332
Validation loss: 2.5449267626834065

Epoch: 6| Step: 1
Training loss: 0.9562390220859659
Validation loss: 2.543260611810467

Epoch: 6| Step: 2
Training loss: 1.0327916615009918
Validation loss: 2.5377021541720066

Epoch: 6| Step: 3
Training loss: 1.1791107081332979
Validation loss: 2.4890510881559127

Epoch: 6| Step: 4
Training loss: 0.7271412830887127
Validation loss: 2.4542940018118875

Epoch: 6| Step: 5
Training loss: 1.067820299682175
Validation loss: 2.448340760731454

Epoch: 6| Step: 6
Training loss: 1.1309393819860234
Validation loss: 2.421933186467543

Epoch: 6| Step: 7
Training loss: 0.7631209940262357
Validation loss: 2.407512543456414

Epoch: 6| Step: 8
Training loss: 1.5916237204518167
Validation loss: 2.415648443901612

Epoch: 6| Step: 9
Training loss: 1.0866243125310409
Validation loss: 2.4091421080385675

Epoch: 6| Step: 10
Training loss: 1.1979535415060183
Validation loss: 2.401982727055685

Epoch: 6| Step: 11
Training loss: 0.9035997113303795
Validation loss: 2.425746891126558

Epoch: 6| Step: 12
Training loss: 1.0019892933286825
Validation loss: 2.455544479291435

Epoch: 6| Step: 13
Training loss: 0.7593144741976233
Validation loss: 2.4718999610193277

Epoch: 236| Step: 0
Training loss: 1.6552387245161766
Validation loss: 2.514897939440713

Epoch: 6| Step: 1
Training loss: 1.1774711757622676
Validation loss: 2.501980127607052

Epoch: 6| Step: 2
Training loss: 0.44366896319218907
Validation loss: 2.5455919364749677

Epoch: 6| Step: 3
Training loss: 0.7789401813183314
Validation loss: 2.53260635118331

Epoch: 6| Step: 4
Training loss: 0.9677476927627026
Validation loss: 2.536612176248303

Epoch: 6| Step: 5
Training loss: 0.7496003834720392
Validation loss: 2.5198746331714528

Epoch: 6| Step: 6
Training loss: 0.807426900714206
Validation loss: 2.5131663232779893

Epoch: 6| Step: 7
Training loss: 1.3624559762824409
Validation loss: 2.4935794224353387

Epoch: 6| Step: 8
Training loss: 1.2346028467739698
Validation loss: 2.4516677755517273

Epoch: 6| Step: 9
Training loss: 0.8262894639186581
Validation loss: 2.4270278010290687

Epoch: 6| Step: 10
Training loss: 0.8282431752078868
Validation loss: 2.3938295185653335

Epoch: 6| Step: 11
Training loss: 1.0933081688155912
Validation loss: 2.4070679204463676

Epoch: 6| Step: 12
Training loss: 0.6871608417747382
Validation loss: 2.3999427603147687

Epoch: 6| Step: 13
Training loss: 0.7659920571615096
Validation loss: 2.4189350131713607

Epoch: 237| Step: 0
Training loss: 1.0633303819414115
Validation loss: 2.4649344632787376

Epoch: 6| Step: 1
Training loss: 1.1050568477110005
Validation loss: 2.454002163457075

Epoch: 6| Step: 2
Training loss: 0.6809901546867313
Validation loss: 2.4693604245919762

Epoch: 6| Step: 3
Training loss: 0.8730808396527879
Validation loss: 2.4795111498462847

Epoch: 6| Step: 4
Training loss: 1.0599258880977895
Validation loss: 2.4851520437857153

Epoch: 6| Step: 5
Training loss: 1.1623523618407554
Validation loss: 2.476167535476277

Epoch: 6| Step: 6
Training loss: 0.6511725917141729
Validation loss: 2.500613134322341

Epoch: 6| Step: 7
Training loss: 1.2418280507290511
Validation loss: 2.4803082917507338

Epoch: 6| Step: 8
Training loss: 0.9911995722678172
Validation loss: 2.4950382339376054

Epoch: 6| Step: 9
Training loss: 1.4552902169515225
Validation loss: 2.4579772646161495

Epoch: 6| Step: 10
Training loss: 0.8983413644855117
Validation loss: 2.492055129176893

Epoch: 6| Step: 11
Training loss: 0.6383823590172851
Validation loss: 2.472071274294006

Epoch: 6| Step: 12
Training loss: 0.9489454339019907
Validation loss: 2.47624560455578

Epoch: 6| Step: 13
Training loss: 0.41514121201012205
Validation loss: 2.507191230397615

Epoch: 238| Step: 0
Training loss: 1.019745435176582
Validation loss: 2.4986036728625622

Epoch: 6| Step: 1
Training loss: 0.47886847118327297
Validation loss: 2.506162641306605

Epoch: 6| Step: 2
Training loss: 1.2445407864671603
Validation loss: 2.535270449314992

Epoch: 6| Step: 3
Training loss: 0.8948229851235971
Validation loss: 2.5113353849735103

Epoch: 6| Step: 4
Training loss: 0.9009194631157055
Validation loss: 2.4863530443804183

Epoch: 6| Step: 5
Training loss: 1.0337541405296202
Validation loss: 2.503433069948873

Epoch: 6| Step: 6
Training loss: 0.8745417416699596
Validation loss: 2.4805045181730248

Epoch: 6| Step: 7
Training loss: 0.3834262326737265
Validation loss: 2.484925602029287

Epoch: 6| Step: 8
Training loss: 1.1520382233675996
Validation loss: 2.4559879065975077

Epoch: 6| Step: 9
Training loss: 0.8961560348242842
Validation loss: 2.4581771931006955

Epoch: 6| Step: 10
Training loss: 1.127810200228821
Validation loss: 2.4718597087638905

Epoch: 6| Step: 11
Training loss: 1.4135942895811722
Validation loss: 2.429735036917193

Epoch: 6| Step: 12
Training loss: 0.9938740251028034
Validation loss: 2.453178288659748

Epoch: 6| Step: 13
Training loss: 0.4143253248022058
Validation loss: 2.4366923104420093

Epoch: 239| Step: 0
Training loss: 0.8292846477539707
Validation loss: 2.4752974794529683

Epoch: 6| Step: 1
Training loss: 0.9225599039988512
Validation loss: 2.483437357401213

Epoch: 6| Step: 2
Training loss: 0.7422403015628629
Validation loss: 2.4699823264136995

Epoch: 6| Step: 3
Training loss: 0.6947132056761762
Validation loss: 2.471107882376867

Epoch: 6| Step: 4
Training loss: 0.6925068947211267
Validation loss: 2.450779830760288

Epoch: 6| Step: 5
Training loss: 0.8716323624298179
Validation loss: 2.4621251389314187

Epoch: 6| Step: 6
Training loss: 1.40442377824876
Validation loss: 2.483341374280682

Epoch: 6| Step: 7
Training loss: 0.8184572584659182
Validation loss: 2.4652624703355284

Epoch: 6| Step: 8
Training loss: 0.6051892773839396
Validation loss: 2.508231880502813

Epoch: 6| Step: 9
Training loss: 1.109816342530578
Validation loss: 2.520863538856193

Epoch: 6| Step: 10
Training loss: 0.8586195659834807
Validation loss: 2.5052999717153575

Epoch: 6| Step: 11
Training loss: 1.382065005237926
Validation loss: 2.4907890338785945

Epoch: 6| Step: 12
Training loss: 1.0953364719265413
Validation loss: 2.4960040459041997

Epoch: 6| Step: 13
Training loss: 1.2955245834868445
Validation loss: 2.484391518690962

Epoch: 240| Step: 0
Training loss: 0.7122934426836617
Validation loss: 2.4702005918331373

Epoch: 6| Step: 1
Training loss: 0.9070670292489619
Validation loss: 2.470403032432222

Epoch: 6| Step: 2
Training loss: 1.5488310497588242
Validation loss: 2.466456014018812

Epoch: 6| Step: 3
Training loss: 0.7654152407673565
Validation loss: 2.4594085668135994

Epoch: 6| Step: 4
Training loss: 0.841421658827324
Validation loss: 2.47743961247595

Epoch: 6| Step: 5
Training loss: 0.7875401380694412
Validation loss: 2.4601127673631904

Epoch: 6| Step: 6
Training loss: 0.9879181085385907
Validation loss: 2.4597433849279815

Epoch: 6| Step: 7
Training loss: 1.0114197749532001
Validation loss: 2.448352709604827

Epoch: 6| Step: 8
Training loss: 0.9580935440822238
Validation loss: 2.4511263022872147

Epoch: 6| Step: 9
Training loss: 0.9681429345259489
Validation loss: 2.4386005777711994

Epoch: 6| Step: 10
Training loss: 0.9659184327923261
Validation loss: 2.4349982215069814

Epoch: 6| Step: 11
Training loss: 0.6165165694888128
Validation loss: 2.4267666799527254

Epoch: 6| Step: 12
Training loss: 1.0739363420506072
Validation loss: 2.4264922693581856

Epoch: 6| Step: 13
Training loss: 0.8807792204190092
Validation loss: 2.4055696885976436

Epoch: 241| Step: 0
Training loss: 0.7910215024376553
Validation loss: 2.4352422417258874

Epoch: 6| Step: 1
Training loss: 1.3635147026005123
Validation loss: 2.422659376919324

Epoch: 6| Step: 2
Training loss: 0.37267058802758274
Validation loss: 2.445836627187445

Epoch: 6| Step: 3
Training loss: 0.7258189919372834
Validation loss: 2.4668987815846677

Epoch: 6| Step: 4
Training loss: 0.7313171600409798
Validation loss: 2.468018066724577

Epoch: 6| Step: 5
Training loss: 1.0437045698500973
Validation loss: 2.468063361809421

Epoch: 6| Step: 6
Training loss: 0.8677578330756607
Validation loss: 2.4866256389578014

Epoch: 6| Step: 7
Training loss: 0.6082660169675875
Validation loss: 2.4832412063276217

Epoch: 6| Step: 8
Training loss: 1.130355063668734
Validation loss: 2.499307509875912

Epoch: 6| Step: 9
Training loss: 1.1124444326174774
Validation loss: 2.5115813464585823

Epoch: 6| Step: 10
Training loss: 1.0073477094669196
Validation loss: 2.525963543029631

Epoch: 6| Step: 11
Training loss: 1.3455542051523959
Validation loss: 2.5139507249912327

Epoch: 6| Step: 12
Training loss: 0.7800443883638887
Validation loss: 2.4934720631883556

Epoch: 6| Step: 13
Training loss: 0.7107985643721183
Validation loss: 2.4837255306811725

Epoch: 242| Step: 0
Training loss: 0.7894089570824898
Validation loss: 2.4931271592334814

Epoch: 6| Step: 1
Training loss: 0.8106792663551362
Validation loss: 2.486620111912433

Epoch: 6| Step: 2
Training loss: 0.6073239115622088
Validation loss: 2.503475279909979

Epoch: 6| Step: 3
Training loss: 1.1269688332452954
Validation loss: 2.4901529183075555

Epoch: 6| Step: 4
Training loss: 0.8019872376646549
Validation loss: 2.5066706374821384

Epoch: 6| Step: 5
Training loss: 0.8044253172175337
Validation loss: 2.485351549090497

Epoch: 6| Step: 6
Training loss: 1.4497987147088338
Validation loss: 2.4798260111283144

Epoch: 6| Step: 7
Training loss: 0.705545117542155
Validation loss: 2.4557420586297067

Epoch: 6| Step: 8
Training loss: 0.7301844487295058
Validation loss: 2.4611727183968477

Epoch: 6| Step: 9
Training loss: 0.525810385997807
Validation loss: 2.4535212952058876

Epoch: 6| Step: 10
Training loss: 1.4490130913500432
Validation loss: 2.45219237495423

Epoch: 6| Step: 11
Training loss: 0.9257710130342838
Validation loss: 2.4639422642883804

Epoch: 6| Step: 12
Training loss: 0.5400888375216306
Validation loss: 2.470631325092827

Epoch: 6| Step: 13
Training loss: 1.4394567688853133
Validation loss: 2.43655147876255

Epoch: 243| Step: 0
Training loss: 0.9433881545958593
Validation loss: 2.4599901528723707

Epoch: 6| Step: 1
Training loss: 0.9959482124070884
Validation loss: 2.4458689261822726

Epoch: 6| Step: 2
Training loss: 0.669615962078776
Validation loss: 2.4686379280680537

Epoch: 6| Step: 3
Training loss: 0.7397998349651844
Validation loss: 2.4546955965244788

Epoch: 6| Step: 4
Training loss: 0.5281743043536091
Validation loss: 2.460228888051786

Epoch: 6| Step: 5
Training loss: 0.9314228819059843
Validation loss: 2.5102250854061428

Epoch: 6| Step: 6
Training loss: 0.9111030794548218
Validation loss: 2.4753648429154693

Epoch: 6| Step: 7
Training loss: 1.0394002609257007
Validation loss: 2.4684128152645717

Epoch: 6| Step: 8
Training loss: 0.810567391377207
Validation loss: 2.4527196758964855

Epoch: 6| Step: 9
Training loss: 1.196434491718342
Validation loss: 2.454245810354931

Epoch: 6| Step: 10
Training loss: 1.0009712033012024
Validation loss: 2.4713965394957373

Epoch: 6| Step: 11
Training loss: 1.291021303750157
Validation loss: 2.474325355718253

Epoch: 6| Step: 12
Training loss: 0.5205819826798097
Validation loss: 2.471274334958589

Epoch: 6| Step: 13
Training loss: 1.1126610885748474
Validation loss: 2.4862990644471297

Epoch: 244| Step: 0
Training loss: 1.117211828433751
Validation loss: 2.4898096874913156

Epoch: 6| Step: 1
Training loss: 0.9052554625667933
Validation loss: 2.473398014123162

Epoch: 6| Step: 2
Training loss: 0.8340703843945755
Validation loss: 2.474900221136622

Epoch: 6| Step: 3
Training loss: 0.49745511072922755
Validation loss: 2.4611641217782694

Epoch: 6| Step: 4
Training loss: 0.6824426168555112
Validation loss: 2.4657287043909615

Epoch: 6| Step: 5
Training loss: 0.9804813338608235
Validation loss: 2.453439364627607

Epoch: 6| Step: 6
Training loss: 0.896827781577355
Validation loss: 2.4453249653227203

Epoch: 6| Step: 7
Training loss: 0.8699668814395384
Validation loss: 2.453066926875835

Epoch: 6| Step: 8
Training loss: 1.0278337709679457
Validation loss: 2.4527580013355914

Epoch: 6| Step: 9
Training loss: 0.9216211907088038
Validation loss: 2.468735590610117

Epoch: 6| Step: 10
Training loss: 0.8718152671779347
Validation loss: 2.4565058096358103

Epoch: 6| Step: 11
Training loss: 1.1967014396064
Validation loss: 2.4376365806360423

Epoch: 6| Step: 12
Training loss: 1.081119855865191
Validation loss: 2.4685967136748257

Epoch: 6| Step: 13
Training loss: 0.5686594901535802
Validation loss: 2.4665054038540033

Epoch: 245| Step: 0
Training loss: 0.5664578644485282
Validation loss: 2.4765235745392404

Epoch: 6| Step: 1
Training loss: 0.6654545050746922
Validation loss: 2.4887931277778113

Epoch: 6| Step: 2
Training loss: 0.6686851719602611
Validation loss: 2.4891790381903167

Epoch: 6| Step: 3
Training loss: 0.5884203884333185
Validation loss: 2.494943051101012

Epoch: 6| Step: 4
Training loss: 0.6734536277450675
Validation loss: 2.473225920485021

Epoch: 6| Step: 5
Training loss: 0.9058642059500029
Validation loss: 2.4703546015826716

Epoch: 6| Step: 6
Training loss: 0.7924764072504519
Validation loss: 2.449265131715887

Epoch: 6| Step: 7
Training loss: 1.3903199622103384
Validation loss: 2.4345773666416073

Epoch: 6| Step: 8
Training loss: 0.9668712548822664
Validation loss: 2.436417829805251

Epoch: 6| Step: 9
Training loss: 0.9983232268605727
Validation loss: 2.434971671080194

Epoch: 6| Step: 10
Training loss: 1.019109646087653
Validation loss: 2.4128533423538197

Epoch: 6| Step: 11
Training loss: 0.9981056091584392
Validation loss: 2.4094838430168712

Epoch: 6| Step: 12
Training loss: 1.0558159901479922
Validation loss: 2.4430171810573533

Epoch: 6| Step: 13
Training loss: 1.0516152174546902
Validation loss: 2.45467334951408

Epoch: 246| Step: 0
Training loss: 0.8807244377227342
Validation loss: 2.4401984516625332

Epoch: 6| Step: 1
Training loss: 0.2748817178634742
Validation loss: 2.4541721537463728

Epoch: 6| Step: 2
Training loss: 0.5295768926135286
Validation loss: 2.4758672478796835

Epoch: 6| Step: 3
Training loss: 1.0404001101784537
Validation loss: 2.4985724382826757

Epoch: 6| Step: 4
Training loss: 0.6622507175155099
Validation loss: 2.4893314520594254

Epoch: 6| Step: 5
Training loss: 1.19461328338309
Validation loss: 2.507499037597977

Epoch: 6| Step: 6
Training loss: 0.8292336150957981
Validation loss: 2.473706211440258

Epoch: 6| Step: 7
Training loss: 0.8410649137675625
Validation loss: 2.476178003117698

Epoch: 6| Step: 8
Training loss: 1.1269525960990419
Validation loss: 2.4723765666984185

Epoch: 6| Step: 9
Training loss: 0.7856676324704363
Validation loss: 2.464898091626895

Epoch: 6| Step: 10
Training loss: 0.8257234406965489
Validation loss: 2.4855154944519806

Epoch: 6| Step: 11
Training loss: 1.3758730717462928
Validation loss: 2.472279512800755

Epoch: 6| Step: 12
Training loss: 0.8159459107578021
Validation loss: 2.4669988508578413

Epoch: 6| Step: 13
Training loss: 0.8674370690091897
Validation loss: 2.4824850889017793

Epoch: 247| Step: 0
Training loss: 0.5273412633766604
Validation loss: 2.4851553696071265

Epoch: 6| Step: 1
Training loss: 0.4652673410159237
Validation loss: 2.4657488601096924

Epoch: 6| Step: 2
Training loss: 0.7135006319670094
Validation loss: 2.466743107314973

Epoch: 6| Step: 3
Training loss: 1.5143709008401076
Validation loss: 2.479931714781382

Epoch: 6| Step: 4
Training loss: 0.8667570196945207
Validation loss: 2.4288004280082065

Epoch: 6| Step: 5
Training loss: 1.072956911585294
Validation loss: 2.4644717853425933

Epoch: 6| Step: 6
Training loss: 1.0735384364751634
Validation loss: 2.474644816586302

Epoch: 6| Step: 7
Training loss: 0.734161386467272
Validation loss: 2.457650052305814

Epoch: 6| Step: 8
Training loss: 0.8195895687913967
Validation loss: 2.4881923450570875

Epoch: 6| Step: 9
Training loss: 0.8088623190569489
Validation loss: 2.518538894199504

Epoch: 6| Step: 10
Training loss: 0.329043589842903
Validation loss: 2.502505966110078

Epoch: 6| Step: 11
Training loss: 1.1143246763530024
Validation loss: 2.5056820686036767

Epoch: 6| Step: 12
Training loss: 0.8780347445115299
Validation loss: 2.490309905600348

Epoch: 6| Step: 13
Training loss: 0.6878492162004693
Validation loss: 2.477445378343633

Epoch: 248| Step: 0
Training loss: 1.4310416390620826
Validation loss: 2.4374442040236683

Epoch: 6| Step: 1
Training loss: 1.2070697173374545
Validation loss: 2.4171921647913592

Epoch: 6| Step: 2
Training loss: 1.0065105219450678
Validation loss: 2.4406482169124337

Epoch: 6| Step: 3
Training loss: 0.77553885554032
Validation loss: 2.4021050527436847

Epoch: 6| Step: 4
Training loss: 0.7913506445974331
Validation loss: 2.412895191479046

Epoch: 6| Step: 5
Training loss: 0.6986424719249633
Validation loss: 2.422075412700085

Epoch: 6| Step: 6
Training loss: 0.8095477461114324
Validation loss: 2.398207921490243

Epoch: 6| Step: 7
Training loss: 0.7730732840508218
Validation loss: 2.412529050777614

Epoch: 6| Step: 8
Training loss: 0.7086512095445406
Validation loss: 2.428107899436567

Epoch: 6| Step: 9
Training loss: 0.6022473190045253
Validation loss: 2.4322485231655375

Epoch: 6| Step: 10
Training loss: 0.6628343107527881
Validation loss: 2.4224076028456185

Epoch: 6| Step: 11
Training loss: 0.9040841497102939
Validation loss: 2.4087091980436264

Epoch: 6| Step: 12
Training loss: 0.7283020524640947
Validation loss: 2.4193931086053126

Epoch: 6| Step: 13
Training loss: 0.8187922605134773
Validation loss: 2.4227384617815186

Epoch: 249| Step: 0
Training loss: 0.6803767119047434
Validation loss: 2.4195901043303802

Epoch: 6| Step: 1
Training loss: 0.8201488876666397
Validation loss: 2.4082156163388277

Epoch: 6| Step: 2
Training loss: 1.0598180806401722
Validation loss: 2.4475107820427073

Epoch: 6| Step: 3
Training loss: 0.5822740854692526
Validation loss: 2.4538669534024837

Epoch: 6| Step: 4
Training loss: 1.2729363888941578
Validation loss: 2.4862819284190665

Epoch: 6| Step: 5
Training loss: 0.9940907403987246
Validation loss: 2.4594212348366455

Epoch: 6| Step: 6
Training loss: 0.5391794713586513
Validation loss: 2.500465384615351

Epoch: 6| Step: 7
Training loss: 1.5569159863688342
Validation loss: 2.4679798759422065

Epoch: 6| Step: 8
Training loss: 0.6609481486010534
Validation loss: 2.4955458781115

Epoch: 6| Step: 9
Training loss: 0.38929392048546946
Validation loss: 2.4938997845289603

Epoch: 6| Step: 10
Training loss: 0.6319840035149435
Validation loss: 2.4779346128044133

Epoch: 6| Step: 11
Training loss: 0.8335010280362513
Validation loss: 2.429205924923708

Epoch: 6| Step: 12
Training loss: 0.57591966184333
Validation loss: 2.4843496996080883

Epoch: 6| Step: 13
Training loss: 0.9337641029875955
Validation loss: 2.4463067914895773

Epoch: 250| Step: 0
Training loss: 0.8806931366291038
Validation loss: 2.4646049531918948

Epoch: 6| Step: 1
Training loss: 0.730745273411669
Validation loss: 2.453872265874092

Epoch: 6| Step: 2
Training loss: 1.271601798968319
Validation loss: 2.4873416637524306

Epoch: 6| Step: 3
Training loss: 0.7663431497431579
Validation loss: 2.474462272125041

Epoch: 6| Step: 4
Training loss: 0.7772493544729552
Validation loss: 2.500648830674147

Epoch: 6| Step: 5
Training loss: 1.1695860825032829
Validation loss: 2.5340729597805165

Epoch: 6| Step: 6
Training loss: 1.0849997224236059
Validation loss: 2.5285315784927125

Epoch: 6| Step: 7
Training loss: 0.44985091468376304
Validation loss: 2.515488814194536

Epoch: 6| Step: 8
Training loss: 0.7644966920066305
Validation loss: 2.530698618203369

Epoch: 6| Step: 9
Training loss: 1.052708782953654
Validation loss: 2.52195995935026

Epoch: 6| Step: 10
Training loss: 0.4896092475634078
Validation loss: 2.5026397873274635

Epoch: 6| Step: 11
Training loss: 0.8548914733963944
Validation loss: 2.494967966638747

Epoch: 6| Step: 12
Training loss: 0.7978240327042624
Validation loss: 2.450360520921668

Epoch: 6| Step: 13
Training loss: 0.3326600795828227
Validation loss: 2.4423857357661074

Epoch: 251| Step: 0
Training loss: 0.7946603330708079
Validation loss: 2.447024849841742

Epoch: 6| Step: 1
Training loss: 0.4199331769974791
Validation loss: 2.472535642775953

Epoch: 6| Step: 2
Training loss: 0.6543742803079606
Validation loss: 2.4673029525701855

Epoch: 6| Step: 3
Training loss: 0.7095895921569632
Validation loss: 2.4726172391979637

Epoch: 6| Step: 4
Training loss: 0.8239431055898729
Validation loss: 2.4653440537518625

Epoch: 6| Step: 5
Training loss: 1.1267633394002299
Validation loss: 2.4674304485013874

Epoch: 6| Step: 6
Training loss: 0.7531153428974137
Validation loss: 2.460037267322447

Epoch: 6| Step: 7
Training loss: 0.816173757640573
Validation loss: 2.4298164505707147

Epoch: 6| Step: 8
Training loss: 0.7371343352716581
Validation loss: 2.444662663078915

Epoch: 6| Step: 9
Training loss: 0.426517881777708
Validation loss: 2.4375024947497335

Epoch: 6| Step: 10
Training loss: 1.2674899077907162
Validation loss: 2.4375420307230464

Epoch: 6| Step: 11
Training loss: 0.9977718205676508
Validation loss: 2.467102720330192

Epoch: 6| Step: 12
Training loss: 1.1348996107935208
Validation loss: 2.4780150672442405

Epoch: 6| Step: 13
Training loss: 0.9117753195190121
Validation loss: 2.5075615114624337

Epoch: 252| Step: 0
Training loss: 0.7680333076421859
Validation loss: 2.4783293593309077

Epoch: 6| Step: 1
Training loss: 0.9612861869062456
Validation loss: 2.468522064041784

Epoch: 6| Step: 2
Training loss: 0.47832186142969335
Validation loss: 2.4657599484919457

Epoch: 6| Step: 3
Training loss: 1.0179039841584157
Validation loss: 2.45817233786048

Epoch: 6| Step: 4
Training loss: 1.1215541837803251
Validation loss: 2.4278939242165345

Epoch: 6| Step: 5
Training loss: 0.6412863457847537
Validation loss: 2.4356682138952968

Epoch: 6| Step: 6
Training loss: 0.6381796710500138
Validation loss: 2.433835457820628

Epoch: 6| Step: 7
Training loss: 0.9600493816251557
Validation loss: 2.438474458790166

Epoch: 6| Step: 8
Training loss: 0.8028257740270162
Validation loss: 2.408872241235363

Epoch: 6| Step: 9
Training loss: 0.7164559866010903
Validation loss: 2.435106231108269

Epoch: 6| Step: 10
Training loss: 0.8519033047514033
Validation loss: 2.4492717991723456

Epoch: 6| Step: 11
Training loss: 0.7121921828058676
Validation loss: 2.482694841320359

Epoch: 6| Step: 12
Training loss: 0.610193802853851
Validation loss: 2.4909674981289847

Epoch: 6| Step: 13
Training loss: 1.4676387722550859
Validation loss: 2.4899504896215694

Epoch: 253| Step: 0
Training loss: 0.703218644581919
Validation loss: 2.4818654215955838

Epoch: 6| Step: 1
Training loss: 1.1134285812598876
Validation loss: 2.491477622183861

Epoch: 6| Step: 2
Training loss: 0.7917834664231824
Validation loss: 2.5035250760785273

Epoch: 6| Step: 3
Training loss: 1.1254052385985518
Validation loss: 2.4974525993801033

Epoch: 6| Step: 4
Training loss: 0.7563998633455691
Validation loss: 2.504908201276925

Epoch: 6| Step: 5
Training loss: 0.7034721577129562
Validation loss: 2.4875122052286587

Epoch: 6| Step: 6
Training loss: 0.5876698887486588
Validation loss: 2.47174431391453

Epoch: 6| Step: 7
Training loss: 0.7487799336940967
Validation loss: 2.481247252664274

Epoch: 6| Step: 8
Training loss: 1.1195510724077076
Validation loss: 2.456670293143143

Epoch: 6| Step: 9
Training loss: 0.6371232602531834
Validation loss: 2.4883672804611328

Epoch: 6| Step: 10
Training loss: 0.7420087498691338
Validation loss: 2.478050723929146

Epoch: 6| Step: 11
Training loss: 0.7923354452755258
Validation loss: 2.5005747329305787

Epoch: 6| Step: 12
Training loss: 0.7341325643790477
Validation loss: 2.474195019594174

Epoch: 6| Step: 13
Training loss: 0.8311791870243039
Validation loss: 2.4904444701722777

Epoch: 254| Step: 0
Training loss: 0.35604907443110145
Validation loss: 2.4841292240302417

Epoch: 6| Step: 1
Training loss: 1.0281254220515257
Validation loss: 2.500570866820847

Epoch: 6| Step: 2
Training loss: 0.6361443907094284
Validation loss: 2.4787460519089852

Epoch: 6| Step: 3
Training loss: 0.6616749196134405
Validation loss: 2.520222001851885

Epoch: 6| Step: 4
Training loss: 0.7982319516878371
Validation loss: 2.5056858613468833

Epoch: 6| Step: 5
Training loss: 0.9314449912622801
Validation loss: 2.4844181642389764

Epoch: 6| Step: 6
Training loss: 0.7539122586183808
Validation loss: 2.450507669796109

Epoch: 6| Step: 7
Training loss: 0.8017018678501368
Validation loss: 2.4396185701306767

Epoch: 6| Step: 8
Training loss: 0.8104522282137385
Validation loss: 2.4340946178053464

Epoch: 6| Step: 9
Training loss: 0.5773022441888455
Validation loss: 2.4442231465416087

Epoch: 6| Step: 10
Training loss: 0.7710723935834725
Validation loss: 2.452409729728931

Epoch: 6| Step: 11
Training loss: 1.286773035679631
Validation loss: 2.470716915913302

Epoch: 6| Step: 12
Training loss: 1.0198676478778643
Validation loss: 2.477617778004006

Epoch: 6| Step: 13
Training loss: 0.7442535554995067
Validation loss: 2.5071708812440634

Epoch: 255| Step: 0
Training loss: 0.9136604011536067
Validation loss: 2.502708538821066

Epoch: 6| Step: 1
Training loss: 0.6035891984950161
Validation loss: 2.5217939478957123

Epoch: 6| Step: 2
Training loss: 0.42694114046997644
Validation loss: 2.4933478287991706

Epoch: 6| Step: 3
Training loss: 0.8165721086009011
Validation loss: 2.488836874628315

Epoch: 6| Step: 4
Training loss: 0.8462260261757297
Validation loss: 2.4528962109551795

Epoch: 6| Step: 5
Training loss: 0.8204188686617052
Validation loss: 2.440361451611779

Epoch: 6| Step: 6
Training loss: 0.42223856413144845
Validation loss: 2.4697204568229236

Epoch: 6| Step: 7
Training loss: 0.7681696895700729
Validation loss: 2.4399636699057057

Epoch: 6| Step: 8
Training loss: 1.1583357890992696
Validation loss: 2.4146460482837875

Epoch: 6| Step: 9
Training loss: 0.8943979755385524
Validation loss: 2.4421764200191074

Epoch: 6| Step: 10
Training loss: 0.47811432184499925
Validation loss: 2.434608568257929

Epoch: 6| Step: 11
Training loss: 0.4720560945288153
Validation loss: 2.419849136200736

Epoch: 6| Step: 12
Training loss: 1.2611211063999064
Validation loss: 2.4615456908588604

Epoch: 6| Step: 13
Training loss: 1.3311755880414535
Validation loss: 2.5150830767862735

Epoch: 256| Step: 0
Training loss: 0.7836683988907639
Validation loss: 2.4940607842838687

Epoch: 6| Step: 1
Training loss: 0.6349704822678298
Validation loss: 2.4957841201650584

Epoch: 6| Step: 2
Training loss: 0.8202746791295211
Validation loss: 2.5008663337660977

Epoch: 6| Step: 3
Training loss: 0.9839242478400043
Validation loss: 2.484940625780448

Epoch: 6| Step: 4
Training loss: 0.9767728350147166
Validation loss: 2.4662005946448335

Epoch: 6| Step: 5
Training loss: 0.9751815797987554
Validation loss: 2.4629833274933404

Epoch: 6| Step: 6
Training loss: 0.6757450865843174
Validation loss: 2.4630605186190913

Epoch: 6| Step: 7
Training loss: 0.43715395184514866
Validation loss: 2.4684315532278913

Epoch: 6| Step: 8
Training loss: 1.1546436182750888
Validation loss: 2.487625076763524

Epoch: 6| Step: 9
Training loss: 0.5501712640795393
Validation loss: 2.484027725025502

Epoch: 6| Step: 10
Training loss: 0.7018540233354612
Validation loss: 2.4676236352775547

Epoch: 6| Step: 11
Training loss: 0.8677032243105781
Validation loss: 2.462949841499903

Epoch: 6| Step: 12
Training loss: 0.8507515081526229
Validation loss: 2.472825874410249

Epoch: 6| Step: 13
Training loss: 0.30682712399010126
Validation loss: 2.462766573839669

Epoch: 257| Step: 0
Training loss: 1.1380077800685913
Validation loss: 2.4471070370865906

Epoch: 6| Step: 1
Training loss: 0.6914883365502539
Validation loss: 2.428201557155675

Epoch: 6| Step: 2
Training loss: 0.7925419151942582
Validation loss: 2.4678055070379923

Epoch: 6| Step: 3
Training loss: 0.8110648464989964
Validation loss: 2.450361873696657

Epoch: 6| Step: 4
Training loss: 0.8671679451602052
Validation loss: 2.4597440915659634

Epoch: 6| Step: 5
Training loss: 0.8286751413267477
Validation loss: 2.4728114680363866

Epoch: 6| Step: 6
Training loss: 0.48341841222935295
Validation loss: 2.499395378380982

Epoch: 6| Step: 7
Training loss: 0.5252609376490261
Validation loss: 2.4503001684021064

Epoch: 6| Step: 8
Training loss: 0.4786305814962057
Validation loss: 2.4510009533461856

Epoch: 6| Step: 9
Training loss: 0.7253478366801929
Validation loss: 2.457296612401993

Epoch: 6| Step: 10
Training loss: 1.068345427204143
Validation loss: 2.4477937767445197

Epoch: 6| Step: 11
Training loss: 0.9638901913573314
Validation loss: 2.418130061511495

Epoch: 6| Step: 12
Training loss: 0.5931462681839196
Validation loss: 2.410886102133218

Epoch: 6| Step: 13
Training loss: 0.8485738823801537
Validation loss: 2.402374844166858

Epoch: 258| Step: 0
Training loss: 0.8824191271978508
Validation loss: 2.4040347618909554

Epoch: 6| Step: 1
Training loss: 0.6101201465587931
Validation loss: 2.4305381376596538

Epoch: 6| Step: 2
Training loss: 0.5498044977814531
Validation loss: 2.462837619872583

Epoch: 6| Step: 3
Training loss: 0.7549223698248549
Validation loss: 2.47328097972825

Epoch: 6| Step: 4
Training loss: 1.1590153385625201
Validation loss: 2.47975325493449

Epoch: 6| Step: 5
Training loss: 0.4006789681123236
Validation loss: 2.527356258062843

Epoch: 6| Step: 6
Training loss: 0.5164823051922405
Validation loss: 2.5373342059290547

Epoch: 6| Step: 7
Training loss: 0.8050307125251018
Validation loss: 2.545108506924269

Epoch: 6| Step: 8
Training loss: 0.36061526938257027
Validation loss: 2.5147797516019463

Epoch: 6| Step: 9
Training loss: 1.1819830784433594
Validation loss: 2.478837122066309

Epoch: 6| Step: 10
Training loss: 0.9090512489207457
Validation loss: 2.4644250157356713

Epoch: 6| Step: 11
Training loss: 0.8762963773287521
Validation loss: 2.4561486948984

Epoch: 6| Step: 12
Training loss: 0.9058497630304779
Validation loss: 2.419043997515513

Epoch: 6| Step: 13
Training loss: 0.6148522537593417
Validation loss: 2.4317776348788738

Epoch: 259| Step: 0
Training loss: 0.6213924241632127
Validation loss: 2.403428086110859

Epoch: 6| Step: 1
Training loss: 0.7500496291588473
Validation loss: 2.407823862683287

Epoch: 6| Step: 2
Training loss: 0.5591920169772813
Validation loss: 2.380924882162332

Epoch: 6| Step: 3
Training loss: 0.7601498610413278
Validation loss: 2.3945028590464905

Epoch: 6| Step: 4
Training loss: 0.8177596924480584
Validation loss: 2.4283979124870325

Epoch: 6| Step: 5
Training loss: 0.8165564877930724
Validation loss: 2.4252807191682324

Epoch: 6| Step: 6
Training loss: 1.0656575799251735
Validation loss: 2.4238608219768367

Epoch: 6| Step: 7
Training loss: 0.6938118975751588
Validation loss: 2.4114426751191975

Epoch: 6| Step: 8
Training loss: 0.7120443677499596
Validation loss: 2.444056770652211

Epoch: 6| Step: 9
Training loss: 0.7185912578926908
Validation loss: 2.4265821332782838

Epoch: 6| Step: 10
Training loss: 0.6949961939371303
Validation loss: 2.4903538862517016

Epoch: 6| Step: 11
Training loss: 1.0092641149501929
Validation loss: 2.5004417198401043

Epoch: 6| Step: 12
Training loss: 1.0142141078947935
Validation loss: 2.501532421825514

Epoch: 6| Step: 13
Training loss: 0.31126308024930543
Validation loss: 2.4983096099186657

Epoch: 260| Step: 0
Training loss: 0.7280765058879842
Validation loss: 2.5255336682419482

Epoch: 6| Step: 1
Training loss: 0.7721685152641689
Validation loss: 2.4793867835749643

Epoch: 6| Step: 2
Training loss: 0.5679737893658885
Validation loss: 2.462941833980165

Epoch: 6| Step: 3
Training loss: 0.8466446637188155
Validation loss: 2.435720660395678

Epoch: 6| Step: 4
Training loss: 0.6864846708332474
Validation loss: 2.426746890297528

Epoch: 6| Step: 5
Training loss: 0.8902058535296641
Validation loss: 2.3924631409496375

Epoch: 6| Step: 6
Training loss: 0.535974809332219
Validation loss: 2.3883115225809757

Epoch: 6| Step: 7
Training loss: 0.7353632749964684
Validation loss: 2.3523838989472896

Epoch: 6| Step: 8
Training loss: 0.41328508342847164
Validation loss: 2.3998463621236454

Epoch: 6| Step: 9
Training loss: 0.9594315304083706
Validation loss: 2.372702263726913

Epoch: 6| Step: 10
Training loss: 1.3537319610464635
Validation loss: 2.424825548139233

Epoch: 6| Step: 11
Training loss: 0.8027042652432637
Validation loss: 2.411321137824328

Epoch: 6| Step: 12
Training loss: 0.9062566756956273
Validation loss: 2.3976700649817024

Epoch: 6| Step: 13
Training loss: 0.41979618409268515
Validation loss: 2.408653128942109

Epoch: 261| Step: 0
Training loss: 0.972929889226966
Validation loss: 2.4126344226671828

Epoch: 6| Step: 1
Training loss: 0.606231258535244
Validation loss: 2.41419568431008

Epoch: 6| Step: 2
Training loss: 1.1433101558745729
Validation loss: 2.4151074740675518

Epoch: 6| Step: 3
Training loss: 0.6493247522881143
Validation loss: 2.4304824951332544

Epoch: 6| Step: 4
Training loss: 0.7054810785882877
Validation loss: 2.447099385251099

Epoch: 6| Step: 5
Training loss: 0.806437727785555
Validation loss: 2.4100980307714157

Epoch: 6| Step: 6
Training loss: 0.9851857434304115
Validation loss: 2.416383858987005

Epoch: 6| Step: 7
Training loss: 0.7827360896358182
Validation loss: 2.4174490964366218

Epoch: 6| Step: 8
Training loss: 0.7110048199314539
Validation loss: 2.4298530867480284

Epoch: 6| Step: 9
Training loss: 0.7657621611134807
Validation loss: 2.43487003390178

Epoch: 6| Step: 10
Training loss: 0.5835368505313435
Validation loss: 2.4239403023274275

Epoch: 6| Step: 11
Training loss: 0.5919726019589351
Validation loss: 2.4129722791782338

Epoch: 6| Step: 12
Training loss: 0.9021281855990635
Validation loss: 2.4656987793013134

Epoch: 6| Step: 13
Training loss: 0.9644405433696257
Validation loss: 2.490173511537479

Epoch: 262| Step: 0
Training loss: 0.9281032110154782
Validation loss: 2.4771074936479205

Epoch: 6| Step: 1
Training loss: 0.7382406395132406
Validation loss: 2.4770064733166812

Epoch: 6| Step: 2
Training loss: 0.7247521190447849
Validation loss: 2.504499801396913

Epoch: 6| Step: 3
Training loss: 0.5621637557964961
Validation loss: 2.505301729721631

Epoch: 6| Step: 4
Training loss: 0.9409963894814315
Validation loss: 2.477770092382029

Epoch: 6| Step: 5
Training loss: 1.1488179724905232
Validation loss: 2.509151672242082

Epoch: 6| Step: 6
Training loss: 0.4827354894410046
Validation loss: 2.503927501074886

Epoch: 6| Step: 7
Training loss: 0.7829802236361505
Validation loss: 2.482780312612989

Epoch: 6| Step: 8
Training loss: 0.5590874151112224
Validation loss: 2.435669516940695

Epoch: 6| Step: 9
Training loss: 0.823172605929356
Validation loss: 2.439535963512941

Epoch: 6| Step: 10
Training loss: 0.48790056265856996
Validation loss: 2.4229929915472437

Epoch: 6| Step: 11
Training loss: 0.9320541519715131
Validation loss: 2.435228581526661

Epoch: 6| Step: 12
Training loss: 0.7146376849562179
Validation loss: 2.4192050651281405

Epoch: 6| Step: 13
Training loss: 0.5984474629501605
Validation loss: 2.443248823757236

Epoch: 263| Step: 0
Training loss: 0.877696854010528
Validation loss: 2.455648229844168

Epoch: 6| Step: 1
Training loss: 0.8879020290758433
Validation loss: 2.465140675644482

Epoch: 6| Step: 2
Training loss: 0.6867711799057924
Validation loss: 2.458112860780646

Epoch: 6| Step: 3
Training loss: 1.1570890320768172
Validation loss: 2.4307637071523276

Epoch: 6| Step: 4
Training loss: 0.7523766055909933
Validation loss: 2.4161119425529427

Epoch: 6| Step: 5
Training loss: 0.6396821457229257
Validation loss: 2.412192605206679

Epoch: 6| Step: 6
Training loss: 0.8074419599525507
Validation loss: 2.4427767133850806

Epoch: 6| Step: 7
Training loss: 0.6557508568563618
Validation loss: 2.4444228119217684

Epoch: 6| Step: 8
Training loss: 0.8732018386573324
Validation loss: 2.4580856703917373

Epoch: 6| Step: 9
Training loss: 0.24643267650077694
Validation loss: 2.485869718714664

Epoch: 6| Step: 10
Training loss: 0.47942233693682734
Validation loss: 2.453093226064847

Epoch: 6| Step: 11
Training loss: 0.609111044032032
Validation loss: 2.4607596103110634

Epoch: 6| Step: 12
Training loss: 0.7370243171008372
Validation loss: 2.419617673276539

Epoch: 6| Step: 13
Training loss: 0.8235373550470728
Validation loss: 2.432337626347343

Epoch: 264| Step: 0
Training loss: 0.9074700791441728
Validation loss: 2.4473373174349193

Epoch: 6| Step: 1
Training loss: 0.7917515851370214
Validation loss: 2.4290437178161737

Epoch: 6| Step: 2
Training loss: 0.9155649731850225
Validation loss: 2.419723309654229

Epoch: 6| Step: 3
Training loss: 0.8338602228240599
Validation loss: 2.4437796768280267

Epoch: 6| Step: 4
Training loss: 0.5734137517184832
Validation loss: 2.4198898091760306

Epoch: 6| Step: 5
Training loss: 0.728328977509254
Validation loss: 2.4313407912419653

Epoch: 6| Step: 6
Training loss: 0.7358534519934448
Validation loss: 2.413631102384849

Epoch: 6| Step: 7
Training loss: 0.6271675194872957
Validation loss: 2.4480015565652904

Epoch: 6| Step: 8
Training loss: 0.5752416828421308
Validation loss: 2.489307503787672

Epoch: 6| Step: 9
Training loss: 0.7869044337626814
Validation loss: 2.490886697859481

Epoch: 6| Step: 10
Training loss: 0.5824050726919857
Validation loss: 2.4889665830738372

Epoch: 6| Step: 11
Training loss: 0.6636817064730222
Validation loss: 2.5109140040237787

Epoch: 6| Step: 12
Training loss: 0.9382104724676058
Validation loss: 2.49054369220471

Epoch: 6| Step: 13
Training loss: 0.5405673431786415
Validation loss: 2.445774111724566

Epoch: 265| Step: 0
Training loss: 0.6308285259817855
Validation loss: 2.4462841333622043

Epoch: 6| Step: 1
Training loss: 1.005514437594113
Validation loss: 2.412437520999916

Epoch: 6| Step: 2
Training loss: 0.8012978352923892
Validation loss: 2.400014192528958

Epoch: 6| Step: 3
Training loss: 0.4684356271045951
Validation loss: 2.409096638394376

Epoch: 6| Step: 4
Training loss: 0.7173333512144311
Validation loss: 2.4141374509938482

Epoch: 6| Step: 5
Training loss: 0.6712327593359926
Validation loss: 2.408918926207728

Epoch: 6| Step: 6
Training loss: 0.6459222752844325
Validation loss: 2.429978975348293

Epoch: 6| Step: 7
Training loss: 0.6163535701157201
Validation loss: 2.4673399963510154

Epoch: 6| Step: 8
Training loss: 0.44222458795086955
Validation loss: 2.481191506417897

Epoch: 6| Step: 9
Training loss: 0.8081732499660914
Validation loss: 2.5121842613221945

Epoch: 6| Step: 10
Training loss: 0.45703341817749094
Validation loss: 2.50212718131511

Epoch: 6| Step: 11
Training loss: 0.8334605517237166
Validation loss: 2.517536065954206

Epoch: 6| Step: 12
Training loss: 1.0255031560275478
Validation loss: 2.5046742989565915

Epoch: 6| Step: 13
Training loss: 0.7260775024093536
Validation loss: 2.4731743740213576

Epoch: 266| Step: 0
Training loss: 0.30148542634810827
Validation loss: 2.436007034850162

Epoch: 6| Step: 1
Training loss: 0.7866510992880569
Validation loss: 2.426359018296431

Epoch: 6| Step: 2
Training loss: 0.8514747224416902
Validation loss: 2.3996718402585

Epoch: 6| Step: 3
Training loss: 0.8692664237545769
Validation loss: 2.414935894271994

Epoch: 6| Step: 4
Training loss: 0.7127321668124653
Validation loss: 2.3890929873804505

Epoch: 6| Step: 5
Training loss: 0.7506553250554806
Validation loss: 2.405952444804229

Epoch: 6| Step: 6
Training loss: 0.659911612603286
Validation loss: 2.4643048462315824

Epoch: 6| Step: 7
Training loss: 0.5051481925588421
Validation loss: 2.445374173896269

Epoch: 6| Step: 8
Training loss: 0.5227196739044024
Validation loss: 2.466481113383538

Epoch: 6| Step: 9
Training loss: 0.4287053066570346
Validation loss: 2.494176581525216

Epoch: 6| Step: 10
Training loss: 0.8804076193004488
Validation loss: 2.4809991539632144

Epoch: 6| Step: 11
Training loss: 0.9452724605939735
Validation loss: 2.4638327148906014

Epoch: 6| Step: 12
Training loss: 0.7653992767795069
Validation loss: 2.4451627518056442

Epoch: 6| Step: 13
Training loss: 0.8304095156512129
Validation loss: 2.4400212143601645

Epoch: 267| Step: 0
Training loss: 0.661672509929918
Validation loss: 2.4252174835566778

Epoch: 6| Step: 1
Training loss: 1.096927821960582
Validation loss: 2.4010393874389115

Epoch: 6| Step: 2
Training loss: 0.7023083500750971
Validation loss: 2.391081285293081

Epoch: 6| Step: 3
Training loss: 0.36736934298494706
Validation loss: 2.396249251535999

Epoch: 6| Step: 4
Training loss: 0.9101069359251311
Validation loss: 2.410957920420044

Epoch: 6| Step: 5
Training loss: 0.6729186181039141
Validation loss: 2.432758815986399

Epoch: 6| Step: 6
Training loss: 0.6506050833109777
Validation loss: 2.420959605577507

Epoch: 6| Step: 7
Training loss: 0.45920291324291157
Validation loss: 2.4288667180698926

Epoch: 6| Step: 8
Training loss: 0.4498973861894823
Validation loss: 2.421157805878101

Epoch: 6| Step: 9
Training loss: 0.5966296885218481
Validation loss: 2.4485771148764712

Epoch: 6| Step: 10
Training loss: 0.6515728627211007
Validation loss: 2.4342496449578634

Epoch: 6| Step: 11
Training loss: 0.639783585809049
Validation loss: 2.4315991965438806

Epoch: 6| Step: 12
Training loss: 0.9199878644661151
Validation loss: 2.398803056716046

Epoch: 6| Step: 13
Training loss: 0.7453222230161084
Validation loss: 2.422637260589493

Epoch: 268| Step: 0
Training loss: 0.7115674005539872
Validation loss: 2.4178607075031775

Epoch: 6| Step: 1
Training loss: 0.5082951819324911
Validation loss: 2.414499142130046

Epoch: 6| Step: 2
Training loss: 0.7873735008364763
Validation loss: 2.4275503248438337

Epoch: 6| Step: 3
Training loss: 0.46812343047099186
Validation loss: 2.422207562666061

Epoch: 6| Step: 4
Training loss: 0.405490403525114
Validation loss: 2.421156942386549

Epoch: 6| Step: 5
Training loss: 0.6928826856013132
Validation loss: 2.40584323717414

Epoch: 6| Step: 6
Training loss: 0.8580749040888384
Validation loss: 2.454552618512227

Epoch: 6| Step: 7
Training loss: 0.552443788525666
Validation loss: 2.450625076230968

Epoch: 6| Step: 8
Training loss: 0.6630992410530323
Validation loss: 2.442241791981731

Epoch: 6| Step: 9
Training loss: 0.9896655433370456
Validation loss: 2.4277113603196283

Epoch: 6| Step: 10
Training loss: 0.5397228674242045
Validation loss: 2.4375507422025495

Epoch: 6| Step: 11
Training loss: 0.9877610778940477
Validation loss: 2.433861641446115

Epoch: 6| Step: 12
Training loss: 0.5789088528429172
Validation loss: 2.4408636147212177

Epoch: 6| Step: 13
Training loss: 0.8207310653208161
Validation loss: 2.430858399431181

Epoch: 269| Step: 0
Training loss: 1.0135463276697443
Validation loss: 2.422756492730612

Epoch: 6| Step: 1
Training loss: 0.7445510173146891
Validation loss: 2.4541795787878655

Epoch: 6| Step: 2
Training loss: 0.5445727251805392
Validation loss: 2.4607785654254513

Epoch: 6| Step: 3
Training loss: 0.6341643787130554
Validation loss: 2.4337060818440417

Epoch: 6| Step: 4
Training loss: 0.5737082359389055
Validation loss: 2.441349312067068

Epoch: 6| Step: 5
Training loss: 0.8494108121506706
Validation loss: 2.4343772815508995

Epoch: 6| Step: 6
Training loss: 0.7295209478099015
Validation loss: 2.4257969935591595

Epoch: 6| Step: 7
Training loss: 0.6728543529258856
Validation loss: 2.393670881834792

Epoch: 6| Step: 8
Training loss: 0.6953716467228442
Validation loss: 2.4143395550804905

Epoch: 6| Step: 9
Training loss: 0.3523674333144964
Validation loss: 2.4287474694939526

Epoch: 6| Step: 10
Training loss: 0.8346559558707783
Validation loss: 2.4264669232811205

Epoch: 6| Step: 11
Training loss: 0.5979432059145665
Validation loss: 2.424706928417084

Epoch: 6| Step: 12
Training loss: 0.332742814930812
Validation loss: 2.4281138563558318

Epoch: 6| Step: 13
Training loss: 0.9319261477253981
Validation loss: 2.4347944513052466

Epoch: 270| Step: 0
Training loss: 0.7357553536067698
Validation loss: 2.4607001587825623

Epoch: 6| Step: 1
Training loss: 0.8943685858474508
Validation loss: 2.454322726856589

Epoch: 6| Step: 2
Training loss: 0.32608822646533003
Validation loss: 2.446718313691304

Epoch: 6| Step: 3
Training loss: 0.5872628544991635
Validation loss: 2.4502197351250765

Epoch: 6| Step: 4
Training loss: 0.7702025375650308
Validation loss: 2.4484978803813653

Epoch: 6| Step: 5
Training loss: 0.8308390282640123
Validation loss: 2.4487145527992995

Epoch: 6| Step: 6
Training loss: 0.7488894585219888
Validation loss: 2.4139290205343364

Epoch: 6| Step: 7
Training loss: 0.5223433032363409
Validation loss: 2.354714881806411

Epoch: 6| Step: 8
Training loss: 1.0009631644492056
Validation loss: 2.3519240847334504

Epoch: 6| Step: 9
Training loss: 0.7085592293032508
Validation loss: 2.3577918076181943

Epoch: 6| Step: 10
Training loss: 0.7343014619409844
Validation loss: 2.3572447064760533

Epoch: 6| Step: 11
Training loss: 0.8854883875502768
Validation loss: 2.395873698518265

Epoch: 6| Step: 12
Training loss: 0.5336024985985542
Validation loss: 2.4467110168889272

Epoch: 6| Step: 13
Training loss: 0.4655300171513073
Validation loss: 2.4892475116036596

Epoch: 271| Step: 0
Training loss: 0.44381156413736156
Validation loss: 2.5210079229947184

Epoch: 6| Step: 1
Training loss: 0.892588742650026
Validation loss: 2.5321240128365248

Epoch: 6| Step: 2
Training loss: 0.8912901820344502
Validation loss: 2.538926029245193

Epoch: 6| Step: 3
Training loss: 0.9480433781091353
Validation loss: 2.549166773315724

Epoch: 6| Step: 4
Training loss: 0.7381024017879955
Validation loss: 2.5251961078878127

Epoch: 6| Step: 5
Training loss: 0.37900891830248107
Validation loss: 2.4759953573642854

Epoch: 6| Step: 6
Training loss: 0.5691968640023924
Validation loss: 2.4576807367322218

Epoch: 6| Step: 7
Training loss: 0.6656736239730487
Validation loss: 2.4395056845430294

Epoch: 6| Step: 8
Training loss: 0.473479665005372
Validation loss: 2.4428865330263254

Epoch: 6| Step: 9
Training loss: 0.5518132814865636
Validation loss: 2.4502853879025754

Epoch: 6| Step: 10
Training loss: 0.9642918664746086
Validation loss: 2.4463404418954617

Epoch: 6| Step: 11
Training loss: 1.0176308411399053
Validation loss: 2.4760794271482602

Epoch: 6| Step: 12
Training loss: 0.6315010751773987
Validation loss: 2.516917357426953

Epoch: 6| Step: 13
Training loss: 0.19884150446934237
Validation loss: 2.554407114462114

Epoch: 272| Step: 0
Training loss: 0.7300776286197483
Validation loss: 2.571101937942623

Epoch: 6| Step: 1
Training loss: 0.5714622039561854
Validation loss: 2.5757251382539184

Epoch: 6| Step: 2
Training loss: 0.7384960528134575
Validation loss: 2.526641505201042

Epoch: 6| Step: 3
Training loss: 0.4878559549197918
Validation loss: 2.521073559676326

Epoch: 6| Step: 4
Training loss: 0.6545408790300818
Validation loss: 2.5000166779648874

Epoch: 6| Step: 5
Training loss: 0.8072188477847839
Validation loss: 2.4752613162629715

Epoch: 6| Step: 6
Training loss: 0.816616268614029
Validation loss: 2.4566227248704346

Epoch: 6| Step: 7
Training loss: 0.7394015576840194
Validation loss: 2.420060681280024

Epoch: 6| Step: 8
Training loss: 0.7020873360184879
Validation loss: 2.417294204021555

Epoch: 6| Step: 9
Training loss: 0.7634297643231327
Validation loss: 2.3844614849443038

Epoch: 6| Step: 10
Training loss: 0.504545353573907
Validation loss: 2.36986391393927

Epoch: 6| Step: 11
Training loss: 0.6843025238817836
Validation loss: 2.391802721340196

Epoch: 6| Step: 12
Training loss: 0.6298759755791136
Validation loss: 2.38753692533113

Epoch: 6| Step: 13
Training loss: 0.8079470937375737
Validation loss: 2.387571860917082

Epoch: 273| Step: 0
Training loss: 0.8372141634976475
Validation loss: 2.425397201588705

Epoch: 6| Step: 1
Training loss: 0.5533624861211163
Validation loss: 2.422487031398263

Epoch: 6| Step: 2
Training loss: 0.5363959828657314
Validation loss: 2.441367522689312

Epoch: 6| Step: 3
Training loss: 0.5725020873768829
Validation loss: 2.471320235307317

Epoch: 6| Step: 4
Training loss: 0.780457896175272
Validation loss: 2.445161963368119

Epoch: 6| Step: 5
Training loss: 0.4993466041904016
Validation loss: 2.465116656677468

Epoch: 6| Step: 6
Training loss: 0.7846281258723024
Validation loss: 2.439669336572465

Epoch: 6| Step: 7
Training loss: 0.5579375567619403
Validation loss: 2.4440286634043344

Epoch: 6| Step: 8
Training loss: 0.8582854560042028
Validation loss: 2.4304543849048676

Epoch: 6| Step: 9
Training loss: 0.3876406345197523
Validation loss: 2.435396825289802

Epoch: 6| Step: 10
Training loss: 0.830036871389861
Validation loss: 2.430790324633872

Epoch: 6| Step: 11
Training loss: 0.6878828803194557
Validation loss: 2.451150387487296

Epoch: 6| Step: 12
Training loss: 0.6592118545030538
Validation loss: 2.4690067407762997

Epoch: 6| Step: 13
Training loss: 0.5049126798845187
Validation loss: 2.4636253355386453

Epoch: 274| Step: 0
Training loss: 0.7818622478905819
Validation loss: 2.4696756094251726

Epoch: 6| Step: 1
Training loss: 0.37181509080331426
Validation loss: 2.4703907112924033

Epoch: 6| Step: 2
Training loss: 0.7360900574998221
Validation loss: 2.4404118711686746

Epoch: 6| Step: 3
Training loss: 0.5698370323276803
Validation loss: 2.457210685576137

Epoch: 6| Step: 4
Training loss: 0.5447472186461788
Validation loss: 2.438589270227497

Epoch: 6| Step: 5
Training loss: 0.7753273580189147
Validation loss: 2.446351786967754

Epoch: 6| Step: 6
Training loss: 0.8100446868861634
Validation loss: 2.454562233114689

Epoch: 6| Step: 7
Training loss: 0.4689792390409009
Validation loss: 2.443279691142941

Epoch: 6| Step: 8
Training loss: 0.8410980793690752
Validation loss: 2.4399456631477054

Epoch: 6| Step: 9
Training loss: 0.786653789122564
Validation loss: 2.4372935095893387

Epoch: 6| Step: 10
Training loss: 0.48096914518175393
Validation loss: 2.4382205615384307

Epoch: 6| Step: 11
Training loss: 0.683282792346748
Validation loss: 2.442368325224373

Epoch: 6| Step: 12
Training loss: 0.6117478170102623
Validation loss: 2.4291504640098136

Epoch: 6| Step: 13
Training loss: 0.1773153752889519
Validation loss: 2.4469067007100023

Epoch: 275| Step: 0
Training loss: 0.40685908800644816
Validation loss: 2.4392137868433297

Epoch: 6| Step: 1
Training loss: 0.9343178147898396
Validation loss: 2.444801043812154

Epoch: 6| Step: 2
Training loss: 0.5469106935024474
Validation loss: 2.43413988589507

Epoch: 6| Step: 3
Training loss: 0.5386797610473981
Validation loss: 2.444967586888736

Epoch: 6| Step: 4
Training loss: 0.7617545486254296
Validation loss: 2.4533282236873752

Epoch: 6| Step: 5
Training loss: 0.6308283370091845
Validation loss: 2.4518116469255453

Epoch: 6| Step: 6
Training loss: 0.8216621195749225
Validation loss: 2.442152481720836

Epoch: 6| Step: 7
Training loss: 0.5705092626316194
Validation loss: 2.428294736180858

Epoch: 6| Step: 8
Training loss: 0.6080345669946235
Validation loss: 2.4219918033988908

Epoch: 6| Step: 9
Training loss: 0.2396769219890536
Validation loss: 2.4211719658250006

Epoch: 6| Step: 10
Training loss: 0.516894944070276
Validation loss: 2.39901787943818

Epoch: 6| Step: 11
Training loss: 0.6814268591304617
Validation loss: 2.4117346403566438

Epoch: 6| Step: 12
Training loss: 0.6938689602420811
Validation loss: 2.4252871291050897

Epoch: 6| Step: 13
Training loss: 0.819321606116281
Validation loss: 2.4046628501601135

Epoch: 276| Step: 0
Training loss: 0.6153725120839735
Validation loss: 2.4055509229628673

Epoch: 6| Step: 1
Training loss: 0.5469967297904332
Validation loss: 2.4131056553952717

Epoch: 6| Step: 2
Training loss: 0.6318724915014142
Validation loss: 2.408099968378515

Epoch: 6| Step: 3
Training loss: 0.34549670333642046
Validation loss: 2.4519151319752055

Epoch: 6| Step: 4
Training loss: 0.5357913126519243
Validation loss: 2.4435118566199074

Epoch: 6| Step: 5
Training loss: 0.3238238491977071
Validation loss: 2.4793393419713508

Epoch: 6| Step: 6
Training loss: 0.6708469954179503
Validation loss: 2.477534056360596

Epoch: 6| Step: 7
Training loss: 0.6968958539365679
Validation loss: 2.4795611289954205

Epoch: 6| Step: 8
Training loss: 0.7382580788826232
Validation loss: 2.4506494511596904

Epoch: 6| Step: 9
Training loss: 0.8881482268805538
Validation loss: 2.4249391033720347

Epoch: 6| Step: 10
Training loss: 0.6562988172266757
Validation loss: 2.411425031599792

Epoch: 6| Step: 11
Training loss: 0.6071391536295156
Validation loss: 2.4229147540515656

Epoch: 6| Step: 12
Training loss: 0.9167166754057215
Validation loss: 2.408743808461087

Epoch: 6| Step: 13
Training loss: 0.35896454051682786
Validation loss: 2.4265311849496953

Epoch: 277| Step: 0
Training loss: 0.640607973198127
Validation loss: 2.413519716821343

Epoch: 6| Step: 1
Training loss: 0.5943434911292399
Validation loss: 2.435511343397046

Epoch: 6| Step: 2
Training loss: 0.6532254456665687
Validation loss: 2.444330540324811

Epoch: 6| Step: 3
Training loss: 0.5579788985620688
Validation loss: 2.469352710123801

Epoch: 6| Step: 4
Training loss: 0.6820947396876822
Validation loss: 2.4657404270834875

Epoch: 6| Step: 5
Training loss: 0.7281411770836759
Validation loss: 2.4535461287945544

Epoch: 6| Step: 6
Training loss: 0.5458929508595449
Validation loss: 2.4691247662098594

Epoch: 6| Step: 7
Training loss: 0.4993889472264617
Validation loss: 2.4461096254235524

Epoch: 6| Step: 8
Training loss: 0.6535867965806227
Validation loss: 2.48965733687985

Epoch: 6| Step: 9
Training loss: 0.6459968318920575
Validation loss: 2.458003056529515

Epoch: 6| Step: 10
Training loss: 0.6412605761423626
Validation loss: 2.459803477613707

Epoch: 6| Step: 11
Training loss: 0.735346091200699
Validation loss: 2.4585572539293765

Epoch: 6| Step: 12
Training loss: 0.38769661929585336
Validation loss: 2.4585854286537816

Epoch: 6| Step: 13
Training loss: 0.845118437259844
Validation loss: 2.4598786805130124

Epoch: 278| Step: 0
Training loss: 0.2880373768369523
Validation loss: 2.4358895889918246

Epoch: 6| Step: 1
Training loss: 0.5667117906116304
Validation loss: 2.4338418915736795

Epoch: 6| Step: 2
Training loss: 0.47993315330590663
Validation loss: 2.4495807630133073

Epoch: 6| Step: 3
Training loss: 0.6878675215403164
Validation loss: 2.440645602482007

Epoch: 6| Step: 4
Training loss: 0.8424228544600109
Validation loss: 2.4574147700524187

Epoch: 6| Step: 5
Training loss: 0.8603694364009542
Validation loss: 2.451806626420349

Epoch: 6| Step: 6
Training loss: 0.5536008587498427
Validation loss: 2.4516762645647026

Epoch: 6| Step: 7
Training loss: 0.3921302784061949
Validation loss: 2.4469106154630937

Epoch: 6| Step: 8
Training loss: 0.646664988939167
Validation loss: 2.4757148314471835

Epoch: 6| Step: 9
Training loss: 0.8436515891999823
Validation loss: 2.493057088464602

Epoch: 6| Step: 10
Training loss: 0.45166464313649696
Validation loss: 2.4979701687323783

Epoch: 6| Step: 11
Training loss: 0.38980596508317916
Validation loss: 2.4960071631445278

Epoch: 6| Step: 12
Training loss: 0.5932604126464532
Validation loss: 2.4952482523775554

Epoch: 6| Step: 13
Training loss: 0.8953554778909872
Validation loss: 2.469310110761471

Epoch: 279| Step: 0
Training loss: 0.39241001458293967
Validation loss: 2.462129404329875

Epoch: 6| Step: 1
Training loss: 0.26301685493910015
Validation loss: 2.4431523116077662

Epoch: 6| Step: 2
Training loss: 0.48116715386934966
Validation loss: 2.4667735767836967

Epoch: 6| Step: 3
Training loss: 0.677504596729802
Validation loss: 2.4755853948616613

Epoch: 6| Step: 4
Training loss: 0.7079492163252303
Validation loss: 2.4624510002351996

Epoch: 6| Step: 5
Training loss: 0.8213972639550543
Validation loss: 2.500588997808804

Epoch: 6| Step: 6
Training loss: 0.6632567959468564
Validation loss: 2.503488008604504

Epoch: 6| Step: 7
Training loss: 0.9657495856544659
Validation loss: 2.5000553617192676

Epoch: 6| Step: 8
Training loss: 0.5344407247535937
Validation loss: 2.524657432786199

Epoch: 6| Step: 9
Training loss: 0.7846019553312568
Validation loss: 2.4709539081652436

Epoch: 6| Step: 10
Training loss: 0.42021729479444364
Validation loss: 2.4766988207260794

Epoch: 6| Step: 11
Training loss: 0.6501510912180122
Validation loss: 2.4291535593936957

Epoch: 6| Step: 12
Training loss: 0.4395689070023261
Validation loss: 2.4236049685713934

Epoch: 6| Step: 13
Training loss: 0.5472814411979171
Validation loss: 2.44270172282669

Epoch: 280| Step: 0
Training loss: 0.7195283158663922
Validation loss: 2.4468052910735025

Epoch: 6| Step: 1
Training loss: 0.4277998643322944
Validation loss: 2.4355011109655536

Epoch: 6| Step: 2
Training loss: 0.49009913976714853
Validation loss: 2.44251483829811

Epoch: 6| Step: 3
Training loss: 0.8262028609432902
Validation loss: 2.4720203861411867

Epoch: 6| Step: 4
Training loss: 0.4707483926746644
Validation loss: 2.472061227415016

Epoch: 6| Step: 5
Training loss: 0.6513363260395962
Validation loss: 2.500050348369633

Epoch: 6| Step: 6
Training loss: 0.8225586067932483
Validation loss: 2.489679128154784

Epoch: 6| Step: 7
Training loss: 0.32337158471314176
Validation loss: 2.5066235506723764

Epoch: 6| Step: 8
Training loss: 0.4740200544000022
Validation loss: 2.448705134569852

Epoch: 6| Step: 9
Training loss: 0.5520290552004413
Validation loss: 2.423365464259928

Epoch: 6| Step: 10
Training loss: 0.8940182343357937
Validation loss: 2.425586043360706

Epoch: 6| Step: 11
Training loss: 0.8147540371336267
Validation loss: 2.4005146583139503

Epoch: 6| Step: 12
Training loss: 0.26800970092695264
Validation loss: 2.4056612681448204

Epoch: 6| Step: 13
Training loss: 0.39824136880787675
Validation loss: 2.3845437159529714

Epoch: 281| Step: 0
Training loss: 0.49501259204954867
Validation loss: 2.4135182589514073

Epoch: 6| Step: 1
Training loss: 0.6508446560638754
Validation loss: 2.4401301993271702

Epoch: 6| Step: 2
Training loss: 0.9848177080858593
Validation loss: 2.427220509977214

Epoch: 6| Step: 3
Training loss: 0.33513064297752565
Validation loss: 2.4317586735151475

Epoch: 6| Step: 4
Training loss: 0.16557176944658816
Validation loss: 2.438099464280487

Epoch: 6| Step: 5
Training loss: 0.5284104755062783
Validation loss: 2.4471607249768637

Epoch: 6| Step: 6
Training loss: 0.719949136632845
Validation loss: 2.4749223800723628

Epoch: 6| Step: 7
Training loss: 0.6824388175481394
Validation loss: 2.453284572001487

Epoch: 6| Step: 8
Training loss: 0.5297075205932485
Validation loss: 2.4591627861219703

Epoch: 6| Step: 9
Training loss: 0.5941762648908903
Validation loss: 2.467720737234862

Epoch: 6| Step: 10
Training loss: 0.5984452966724996
Validation loss: 2.464992985607573

Epoch: 6| Step: 11
Training loss: 0.6939868076070974
Validation loss: 2.4353336554997664

Epoch: 6| Step: 12
Training loss: 0.5763983847003146
Validation loss: 2.428722957087523

Epoch: 6| Step: 13
Training loss: 0.8752737638815352
Validation loss: 2.4476537026933314

Epoch: 282| Step: 0
Training loss: 0.6886975738525307
Validation loss: 2.4349939870186317

Epoch: 6| Step: 1
Training loss: 0.615934766495289
Validation loss: 2.450523704347623

Epoch: 6| Step: 2
Training loss: 0.5413026289428009
Validation loss: 2.4451287177039194

Epoch: 6| Step: 3
Training loss: 0.8258096969742849
Validation loss: 2.4593489314765016

Epoch: 6| Step: 4
Training loss: 0.6542044275363733
Validation loss: 2.42112770261255

Epoch: 6| Step: 5
Training loss: 0.6792491507807461
Validation loss: 2.4493803767220124

Epoch: 6| Step: 6
Training loss: 0.618680644724056
Validation loss: 2.4454367645800748

Epoch: 6| Step: 7
Training loss: 0.7299669143285908
Validation loss: 2.444063251972397

Epoch: 6| Step: 8
Training loss: 0.4659970985688598
Validation loss: 2.4416500132948022

Epoch: 6| Step: 9
Training loss: 0.4323900371295667
Validation loss: 2.436390783465398

Epoch: 6| Step: 10
Training loss: 0.5334090788766961
Validation loss: 2.399761718219171

Epoch: 6| Step: 11
Training loss: 0.31672718114033377
Validation loss: 2.415460034608183

Epoch: 6| Step: 12
Training loss: 0.7734062882107837
Validation loss: 2.4506262269594346

Epoch: 6| Step: 13
Training loss: 0.30174901017371963
Validation loss: 2.44946745006112

Epoch: 283| Step: 0
Training loss: 0.6720471937731312
Validation loss: 2.4751086452648674

Epoch: 6| Step: 1
Training loss: 0.7844744706628541
Validation loss: 2.4629201522381323

Epoch: 6| Step: 2
Training loss: 0.44524610593314884
Validation loss: 2.4952660603950667

Epoch: 6| Step: 3
Training loss: 0.44149990269820805
Validation loss: 2.4953897667693834

Epoch: 6| Step: 4
Training loss: 0.5236812422601923
Validation loss: 2.4976167383633934

Epoch: 6| Step: 5
Training loss: 0.829748649283445
Validation loss: 2.516548746865966

Epoch: 6| Step: 6
Training loss: 0.6386597425142546
Validation loss: 2.498392592272291

Epoch: 6| Step: 7
Training loss: 0.430505494143598
Validation loss: 2.488443014023638

Epoch: 6| Step: 8
Training loss: 0.687416093214319
Validation loss: 2.4652426153349536

Epoch: 6| Step: 9
Training loss: 0.296978643796673
Validation loss: 2.4454641102849615

Epoch: 6| Step: 10
Training loss: 0.6061860296575899
Validation loss: 2.4113925657409254

Epoch: 6| Step: 11
Training loss: 0.653998896371861
Validation loss: 2.4065484111071314

Epoch: 6| Step: 12
Training loss: 0.3709406486705395
Validation loss: 2.412960482867187

Epoch: 6| Step: 13
Training loss: 0.8283289532254604
Validation loss: 2.400266619988763

Epoch: 284| Step: 0
Training loss: 0.6698998539366551
Validation loss: 2.4049709518015843

Epoch: 6| Step: 1
Training loss: 0.8227198562594347
Validation loss: 2.4323523999713945

Epoch: 6| Step: 2
Training loss: 0.5943065343949142
Validation loss: 2.4248846813827623

Epoch: 6| Step: 3
Training loss: 0.4750864276558828
Validation loss: 2.4333566242552482

Epoch: 6| Step: 4
Training loss: 0.8708571039876726
Validation loss: 2.4352364248863934

Epoch: 6| Step: 5
Training loss: 0.5311359114716772
Validation loss: 2.433574240246211

Epoch: 6| Step: 6
Training loss: 0.2913581317517695
Validation loss: 2.4606385762569603

Epoch: 6| Step: 7
Training loss: 0.6619775241338209
Validation loss: 2.4261961136625336

Epoch: 6| Step: 8
Training loss: 0.411217615075701
Validation loss: 2.44412434588331

Epoch: 6| Step: 9
Training loss: 0.44385176888586425
Validation loss: 2.4643761209907598

Epoch: 6| Step: 10
Training loss: 0.6137207303186405
Validation loss: 2.4311350536434126

Epoch: 6| Step: 11
Training loss: 0.787117780541153
Validation loss: 2.4649756278819357

Epoch: 6| Step: 12
Training loss: 0.24252085662403447
Validation loss: 2.4685756751087298

Epoch: 6| Step: 13
Training loss: 0.2789737726534774
Validation loss: 2.459798272532933

Epoch: 285| Step: 0
Training loss: 0.6970795455239907
Validation loss: 2.4348256764623195

Epoch: 6| Step: 1
Training loss: 0.38375524318480553
Validation loss: 2.438476809562255

Epoch: 6| Step: 2
Training loss: 0.6758882515047218
Validation loss: 2.438189007118644

Epoch: 6| Step: 3
Training loss: 0.6741337179974447
Validation loss: 2.4238001078858438

Epoch: 6| Step: 4
Training loss: 0.41113795913773177
Validation loss: 2.4416600244029896

Epoch: 6| Step: 5
Training loss: 0.6472480159153002
Validation loss: 2.4377040972163324

Epoch: 6| Step: 6
Training loss: 0.46982192818165164
Validation loss: 2.4535995378692492

Epoch: 6| Step: 7
Training loss: 0.6955914527158995
Validation loss: 2.464557466291553

Epoch: 6| Step: 8
Training loss: 0.6207364572130064
Validation loss: 2.4732837812198154

Epoch: 6| Step: 9
Training loss: 0.6648312326546154
Validation loss: 2.468515732100405

Epoch: 6| Step: 10
Training loss: 0.3928199137349964
Validation loss: 2.479663492664431

Epoch: 6| Step: 11
Training loss: 0.5736172698334048
Validation loss: 2.5209111823971178

Epoch: 6| Step: 12
Training loss: 0.3726663096287734
Validation loss: 2.4970277992002203

Epoch: 6| Step: 13
Training loss: 0.7458874082586444
Validation loss: 2.4629301014803127

Epoch: 286| Step: 0
Training loss: 0.45913982599645536
Validation loss: 2.4870013080047912

Epoch: 6| Step: 1
Training loss: 0.7702565139945745
Validation loss: 2.4875025175299013

Epoch: 6| Step: 2
Training loss: 0.23967309838886808
Validation loss: 2.430158189343149

Epoch: 6| Step: 3
Training loss: 0.5451976666143782
Validation loss: 2.431952049086514

Epoch: 6| Step: 4
Training loss: 0.3839609474649233
Validation loss: 2.4466789652905443

Epoch: 6| Step: 5
Training loss: 0.7624111061183894
Validation loss: 2.440945795687381

Epoch: 6| Step: 6
Training loss: 0.8447284323610988
Validation loss: 2.4615561285086964

Epoch: 6| Step: 7
Training loss: 0.4633402994230265
Validation loss: 2.441393640760449

Epoch: 6| Step: 8
Training loss: 0.4992477301124314
Validation loss: 2.4672237022393686

Epoch: 6| Step: 9
Training loss: 0.36024787879176395
Validation loss: 2.490115969901422

Epoch: 6| Step: 10
Training loss: 0.623131223129067
Validation loss: 2.485866227811831

Epoch: 6| Step: 11
Training loss: 0.7322433864546205
Validation loss: 2.4574060726562523

Epoch: 6| Step: 12
Training loss: 0.5883701434610701
Validation loss: 2.473830493329028

Epoch: 6| Step: 13
Training loss: 0.21557582626228666
Validation loss: 2.4428070515092672

Epoch: 287| Step: 0
Training loss: 0.6196345576275846
Validation loss: 2.463085865433298

Epoch: 6| Step: 1
Training loss: 0.6642538580346332
Validation loss: 2.4282855174677467

Epoch: 6| Step: 2
Training loss: 0.44616109737149795
Validation loss: 2.4284043804403552

Epoch: 6| Step: 3
Training loss: 0.6443035301437425
Validation loss: 2.430794508439256

Epoch: 6| Step: 4
Training loss: 0.5554532152195306
Validation loss: 2.4009308778209046

Epoch: 6| Step: 5
Training loss: 0.44286818329886235
Validation loss: 2.447175442636646

Epoch: 6| Step: 6
Training loss: 0.3225836254158133
Validation loss: 2.444642618223416

Epoch: 6| Step: 7
Training loss: 0.736721793660969
Validation loss: 2.4705658350153836

Epoch: 6| Step: 8
Training loss: 0.6293539029689018
Validation loss: 2.487538533935942

Epoch: 6| Step: 9
Training loss: 0.15343536627969864
Validation loss: 2.5311587555367394

Epoch: 6| Step: 10
Training loss: 0.6318606057871636
Validation loss: 2.548709442514922

Epoch: 6| Step: 11
Training loss: 0.8035220252094171
Validation loss: 2.5334559401498526

Epoch: 6| Step: 12
Training loss: 0.43925685314245017
Validation loss: 2.510060243490298

Epoch: 6| Step: 13
Training loss: 0.6729539148357541
Validation loss: 2.505806729904712

Epoch: 288| Step: 0
Training loss: 0.7724103561411372
Validation loss: 2.457444564425591

Epoch: 6| Step: 1
Training loss: 0.32457787949669353
Validation loss: 2.415695805525365

Epoch: 6| Step: 2
Training loss: 0.45839299189384974
Validation loss: 2.3968047471042877

Epoch: 6| Step: 3
Training loss: 0.5993398253110821
Validation loss: 2.4168423319003143

Epoch: 6| Step: 4
Training loss: 0.6976074107676011
Validation loss: 2.4219925337530435

Epoch: 6| Step: 5
Training loss: 0.6037036393019718
Validation loss: 2.444554576004065

Epoch: 6| Step: 6
Training loss: 0.334135322591163
Validation loss: 2.491574372755824

Epoch: 6| Step: 7
Training loss: 0.48293747935511666
Validation loss: 2.492623708788775

Epoch: 6| Step: 8
Training loss: 0.787432355851672
Validation loss: 2.5159420602650178

Epoch: 6| Step: 9
Training loss: 0.6821772477012593
Validation loss: 2.531226746090128

Epoch: 6| Step: 10
Training loss: 0.4874616075950264
Validation loss: 2.498448674013322

Epoch: 6| Step: 11
Training loss: 0.48873687848480135
Validation loss: 2.5020619851317316

Epoch: 6| Step: 12
Training loss: 0.5100517200910278
Validation loss: 2.48578193932556

Epoch: 6| Step: 13
Training loss: 0.5784527133319773
Validation loss: 2.4818008717673545

Epoch: 289| Step: 0
Training loss: 0.3629683100368873
Validation loss: 2.4135269859760746

Epoch: 6| Step: 1
Training loss: 0.5699677405096133
Validation loss: 2.4266606233479404

Epoch: 6| Step: 2
Training loss: 0.8476024909485583
Validation loss: 2.4236796493265937

Epoch: 6| Step: 3
Training loss: 0.4590425819661851
Validation loss: 2.432077651952885

Epoch: 6| Step: 4
Training loss: 0.44393408073452223
Validation loss: 2.4358470714078777

Epoch: 6| Step: 5
Training loss: 0.6843087952524259
Validation loss: 2.4439765724642406

Epoch: 6| Step: 6
Training loss: 0.6060003592518411
Validation loss: 2.4533613436102186

Epoch: 6| Step: 7
Training loss: 0.40352418563639597
Validation loss: 2.4373940065370294

Epoch: 6| Step: 8
Training loss: 0.4221236061579245
Validation loss: 2.480518588934107

Epoch: 6| Step: 9
Training loss: 0.764048958874868
Validation loss: 2.4537537192788506

Epoch: 6| Step: 10
Training loss: 0.38550624150172447
Validation loss: 2.498934569263764

Epoch: 6| Step: 11
Training loss: 0.555098690159372
Validation loss: 2.4688665970745025

Epoch: 6| Step: 12
Training loss: 0.5842028053068763
Validation loss: 2.4898208653819016

Epoch: 6| Step: 13
Training loss: 0.46500531762681907
Validation loss: 2.484448588230708

Epoch: 290| Step: 0
Training loss: 0.622345101644517
Validation loss: 2.455533353131686

Epoch: 6| Step: 1
Training loss: 0.5074068356488455
Validation loss: 2.4373284338160452

Epoch: 6| Step: 2
Training loss: 0.8684143460849815
Validation loss: 2.4302199371558633

Epoch: 6| Step: 3
Training loss: 0.5582163142467362
Validation loss: 2.423375700328225

Epoch: 6| Step: 4
Training loss: 0.6140859633372294
Validation loss: 2.4090538730112794

Epoch: 6| Step: 5
Training loss: 0.3037166533591582
Validation loss: 2.4086105898447046

Epoch: 6| Step: 6
Training loss: 0.4973093893086418
Validation loss: 2.422858391524774

Epoch: 6| Step: 7
Training loss: 0.450600266115099
Validation loss: 2.4364530672507136

Epoch: 6| Step: 8
Training loss: 0.7245275240422462
Validation loss: 2.444340024703829

Epoch: 6| Step: 9
Training loss: 0.36767953007016685
Validation loss: 2.5054406983633855

Epoch: 6| Step: 10
Training loss: 0.6634802116628332
Validation loss: 2.48569679401772

Epoch: 6| Step: 11
Training loss: 0.39521971205419854
Validation loss: 2.4946334490351343

Epoch: 6| Step: 12
Training loss: 0.4924704631429712
Validation loss: 2.495099593161248

Epoch: 6| Step: 13
Training loss: 0.4216019311820413
Validation loss: 2.512815174628853

Epoch: 291| Step: 0
Training loss: 0.5307609887982273
Validation loss: 2.45648501139047

Epoch: 6| Step: 1
Training loss: 0.6560888092443675
Validation loss: 2.4801897626670852

Epoch: 6| Step: 2
Training loss: 0.5154223766437215
Validation loss: 2.4610059680128913

Epoch: 6| Step: 3
Training loss: 0.37450023966757384
Validation loss: 2.4380551514011812

Epoch: 6| Step: 4
Training loss: 0.22963859270967632
Validation loss: 2.4351200709660925

Epoch: 6| Step: 5
Training loss: 0.7101438095295666
Validation loss: 2.4127887105488384

Epoch: 6| Step: 6
Training loss: 0.6310798566799626
Validation loss: 2.410699260356883

Epoch: 6| Step: 7
Training loss: 0.381809184900661
Validation loss: 2.4281444695379313

Epoch: 6| Step: 8
Training loss: 0.6014456697440507
Validation loss: 2.4188693933998247

Epoch: 6| Step: 9
Training loss: 0.6706669837132166
Validation loss: 2.4520267191027014

Epoch: 6| Step: 10
Training loss: 0.5131241521700547
Validation loss: 2.4495246833386335

Epoch: 6| Step: 11
Training loss: 0.3434298498327337
Validation loss: 2.444932516197504

Epoch: 6| Step: 12
Training loss: 0.6629512689440354
Validation loss: 2.4577156234248796

Epoch: 6| Step: 13
Training loss: 0.6991294079182432
Validation loss: 2.460163552733053

Epoch: 292| Step: 0
Training loss: 0.5606845062043262
Validation loss: 2.4757100100831595

Epoch: 6| Step: 1
Training loss: 0.5754927949131229
Validation loss: 2.4870308283369913

Epoch: 6| Step: 2
Training loss: 0.47088005571155045
Validation loss: 2.4661794072572385

Epoch: 6| Step: 3
Training loss: 0.47648815450625137
Validation loss: 2.465070726095169

Epoch: 6| Step: 4
Training loss: 0.693100314031796
Validation loss: 2.4409277756942123

Epoch: 6| Step: 5
Training loss: 0.7377347184721432
Validation loss: 2.476865110797483

Epoch: 6| Step: 6
Training loss: 0.5495843530529281
Validation loss: 2.441542311816774

Epoch: 6| Step: 7
Training loss: 0.2736237028186176
Validation loss: 2.4539912904304564

Epoch: 6| Step: 8
Training loss: 0.5731747277254896
Validation loss: 2.451522810785867

Epoch: 6| Step: 9
Training loss: 0.39559692509187083
Validation loss: 2.4298761882305095

Epoch: 6| Step: 10
Training loss: 0.6423508030405145
Validation loss: 2.424769150732476

Epoch: 6| Step: 11
Training loss: 0.590573144079413
Validation loss: 2.432265771101435

Epoch: 6| Step: 12
Training loss: 0.47505719442858985
Validation loss: 2.4362366175934973

Epoch: 6| Step: 13
Training loss: 0.5231961505226237
Validation loss: 2.427939107296645

Epoch: 293| Step: 0
Training loss: 0.5611542391910163
Validation loss: 2.434136230228697

Epoch: 6| Step: 1
Training loss: 0.629465221995669
Validation loss: 2.410778858795563

Epoch: 6| Step: 2
Training loss: 0.4795990958745753
Validation loss: 2.4160835749373764

Epoch: 6| Step: 3
Training loss: 0.5291446875215323
Validation loss: 2.4090871418994

Epoch: 6| Step: 4
Training loss: 0.8406911788473107
Validation loss: 2.416297153091552

Epoch: 6| Step: 5
Training loss: 0.2309978763520894
Validation loss: 2.437727742668855

Epoch: 6| Step: 6
Training loss: 0.3175837071715268
Validation loss: 2.438357608578637

Epoch: 6| Step: 7
Training loss: 0.39715750169057773
Validation loss: 2.4657703417906194

Epoch: 6| Step: 8
Training loss: 0.5735625325610612
Validation loss: 2.4322059793502273

Epoch: 6| Step: 9
Training loss: 0.43654675176091645
Validation loss: 2.444160811648895

Epoch: 6| Step: 10
Training loss: 0.45324573881373403
Validation loss: 2.454308805175091

Epoch: 6| Step: 11
Training loss: 0.8211430296188069
Validation loss: 2.4381700672259643

Epoch: 6| Step: 12
Training loss: 0.5048352335309226
Validation loss: 2.415783561311523

Epoch: 6| Step: 13
Training loss: 0.5278603178308949
Validation loss: 2.4255214120878263

Epoch: 294| Step: 0
Training loss: 0.6179816532837513
Validation loss: 2.449664983724334

Epoch: 6| Step: 1
Training loss: 0.41893184969240393
Validation loss: 2.4286735831936146

Epoch: 6| Step: 2
Training loss: 0.45818928781414797
Validation loss: 2.4504539945562467

Epoch: 6| Step: 3
Training loss: 0.35123432524924386
Validation loss: 2.4490483520370314

Epoch: 6| Step: 4
Training loss: 0.509191401573321
Validation loss: 2.4494795090883557

Epoch: 6| Step: 5
Training loss: 0.6322639348224206
Validation loss: 2.453430378324477

Epoch: 6| Step: 6
Training loss: 0.5859821811170415
Validation loss: 2.4634395294533467

Epoch: 6| Step: 7
Training loss: 0.539609189561608
Validation loss: 2.468915412234705

Epoch: 6| Step: 8
Training loss: 0.35125806130631015
Validation loss: 2.488811699939426

Epoch: 6| Step: 9
Training loss: 0.621450357806899
Validation loss: 2.4868485982403623

Epoch: 6| Step: 10
Training loss: 0.3125462855393707
Validation loss: 2.4609713068793626

Epoch: 6| Step: 11
Training loss: 0.7230700158899056
Validation loss: 2.458290951382431

Epoch: 6| Step: 12
Training loss: 0.6319384248560938
Validation loss: 2.4605801761915416

Epoch: 6| Step: 13
Training loss: 0.4630920840933004
Validation loss: 2.450204336825387

Epoch: 295| Step: 0
Training loss: 0.36526807333783345
Validation loss: 2.4488451626119363

Epoch: 6| Step: 1
Training loss: 0.3499776296619129
Validation loss: 2.450424018935027

Epoch: 6| Step: 2
Training loss: 0.3515582190358929
Validation loss: 2.4398290604469666

Epoch: 6| Step: 3
Training loss: 0.6910883285720348
Validation loss: 2.403771504633756

Epoch: 6| Step: 4
Training loss: 0.6388749199413591
Validation loss: 2.4298404154451907

Epoch: 6| Step: 5
Training loss: 0.6777356062556359
Validation loss: 2.446727209390211

Epoch: 6| Step: 6
Training loss: 0.4497483490261036
Validation loss: 2.4228583576653864

Epoch: 6| Step: 7
Training loss: 0.5404557729477151
Validation loss: 2.415627821862934

Epoch: 6| Step: 8
Training loss: 0.6012967748945955
Validation loss: 2.4049298985943666

Epoch: 6| Step: 9
Training loss: 0.3417333271351882
Validation loss: 2.4627226022704654

Epoch: 6| Step: 10
Training loss: 0.44335666941350776
Validation loss: 2.4573139036114404

Epoch: 6| Step: 11
Training loss: 0.732298939878141
Validation loss: 2.462459223815512

Epoch: 6| Step: 12
Training loss: 0.5312982705569718
Validation loss: 2.4862753952708254

Epoch: 6| Step: 13
Training loss: 0.3775025351546594
Validation loss: 2.509127155023009

Epoch: 296| Step: 0
Training loss: 0.2924268925017483
Validation loss: 2.4866107114739076

Epoch: 6| Step: 1
Training loss: 0.35694590911284363
Validation loss: 2.4550329297165905

Epoch: 6| Step: 2
Training loss: 0.15567252615938248
Validation loss: 2.4484650349593657

Epoch: 6| Step: 3
Training loss: 0.6286840342429837
Validation loss: 2.435934192269222

Epoch: 6| Step: 4
Training loss: 0.42058172502141533
Validation loss: 2.402433481048809

Epoch: 6| Step: 5
Training loss: 0.486347075556554
Validation loss: 2.4058836279947378

Epoch: 6| Step: 6
Training loss: 0.34125551130224946
Validation loss: 2.40253477886905

Epoch: 6| Step: 7
Training loss: 0.6700445568869329
Validation loss: 2.4080719662886603

Epoch: 6| Step: 8
Training loss: 0.656976570094828
Validation loss: 2.4145209658994045

Epoch: 6| Step: 9
Training loss: 0.5127646263134454
Validation loss: 2.4115561248831487

Epoch: 6| Step: 10
Training loss: 0.571838558057337
Validation loss: 2.4346871902193725

Epoch: 6| Step: 11
Training loss: 0.7308873899586291
Validation loss: 2.463594589743727

Epoch: 6| Step: 12
Training loss: 0.5709696863264994
Validation loss: 2.4364044213651583

Epoch: 6| Step: 13
Training loss: 0.5666933581666954
Validation loss: 2.480497114054714

Epoch: 297| Step: 0
Training loss: 0.6446581860015378
Validation loss: 2.4728773120275

Epoch: 6| Step: 1
Training loss: 0.3419695826564504
Validation loss: 2.473068408498901

Epoch: 6| Step: 2
Training loss: 0.5324164935348706
Validation loss: 2.45842387788887

Epoch: 6| Step: 3
Training loss: 0.5967952035819851
Validation loss: 2.4653535841543124

Epoch: 6| Step: 4
Training loss: 0.35050232296607864
Validation loss: 2.4819030191083553

Epoch: 6| Step: 5
Training loss: 0.6757854174887867
Validation loss: 2.459189279696338

Epoch: 6| Step: 6
Training loss: 0.5916189801336827
Validation loss: 2.470601261193249

Epoch: 6| Step: 7
Training loss: 0.514230344787088
Validation loss: 2.478472342448944

Epoch: 6| Step: 8
Training loss: 0.2852348062662977
Validation loss: 2.4495745453745283

Epoch: 6| Step: 9
Training loss: 0.533000194792864
Validation loss: 2.4747835903077497

Epoch: 6| Step: 10
Training loss: 0.5750456584549277
Validation loss: 2.4572699805298774

Epoch: 6| Step: 11
Training loss: 0.3722665824757739
Validation loss: 2.44533407366974

Epoch: 6| Step: 12
Training loss: 0.547962225142835
Validation loss: 2.4408467804443847

Epoch: 6| Step: 13
Training loss: 0.35852385361239925
Validation loss: 2.463769817647083

Epoch: 298| Step: 0
Training loss: 0.6982454740006789
Validation loss: 2.470299702314309

Epoch: 6| Step: 1
Training loss: 0.5792043765116098
Validation loss: 2.448707385483919

Epoch: 6| Step: 2
Training loss: 0.6004307492113818
Validation loss: 2.4700650614130484

Epoch: 6| Step: 3
Training loss: 0.44559466474093945
Validation loss: 2.4863707562906714

Epoch: 6| Step: 4
Training loss: 0.44653680715467386
Validation loss: 2.5106379627971833

Epoch: 6| Step: 5
Training loss: 0.6468836539606443
Validation loss: 2.4857998306284905

Epoch: 6| Step: 6
Training loss: 0.2313350060523976
Validation loss: 2.504491284915362

Epoch: 6| Step: 7
Training loss: 0.45263737716544616
Validation loss: 2.5278019828618623

Epoch: 6| Step: 8
Training loss: 0.5007819379542917
Validation loss: 2.471153403006922

Epoch: 6| Step: 9
Training loss: 0.3380679067897625
Validation loss: 2.4846758689630173

Epoch: 6| Step: 10
Training loss: 0.16921806919140586
Validation loss: 2.457205807038215

Epoch: 6| Step: 11
Training loss: 0.6944910833803893
Validation loss: 2.467032014828424

Epoch: 6| Step: 12
Training loss: 0.266314229426468
Validation loss: 2.448915107417344

Epoch: 6| Step: 13
Training loss: 0.7743519473089007
Validation loss: 2.488946461902832

Epoch: 299| Step: 0
Training loss: 0.5203985561195417
Validation loss: 2.454255695658266

Epoch: 6| Step: 1
Training loss: 0.64710139307324
Validation loss: 2.439200448425665

Epoch: 6| Step: 2
Training loss: 0.4727149643173036
Validation loss: 2.4299894884531095

Epoch: 6| Step: 3
Training loss: 0.4050181676474953
Validation loss: 2.4065176968451016

Epoch: 6| Step: 4
Training loss: 0.6168034722891589
Validation loss: 2.4401815340023205

Epoch: 6| Step: 5
Training loss: 0.2921153545558313
Validation loss: 2.4225944093613307

Epoch: 6| Step: 6
Training loss: 0.5356522649104137
Validation loss: 2.417254174614641

Epoch: 6| Step: 7
Training loss: 0.4257182503384893
Validation loss: 2.4401108269357557

Epoch: 6| Step: 8
Training loss: 0.388365811939416
Validation loss: 2.425011612323393

Epoch: 6| Step: 9
Training loss: 0.5608232727206474
Validation loss: 2.4023609202448566

Epoch: 6| Step: 10
Training loss: 0.34163398130819245
Validation loss: 2.402600813827401

Epoch: 6| Step: 11
Training loss: 0.5422063730786277
Validation loss: 2.428255293525657

Epoch: 6| Step: 12
Training loss: 0.5903305419701154
Validation loss: 2.4285856967623047

Epoch: 6| Step: 13
Training loss: 0.6228002460688727
Validation loss: 2.4292541683036113

Epoch: 300| Step: 0
Training loss: 0.6580392424090857
Validation loss: 2.46220021729855

Epoch: 6| Step: 1
Training loss: 0.43023947894738673
Validation loss: 2.489471099035793

Epoch: 6| Step: 2
Training loss: 0.22865482720316502
Validation loss: 2.453255064639482

Epoch: 6| Step: 3
Training loss: 0.48625346457122337
Validation loss: 2.453868809895836

Epoch: 6| Step: 4
Training loss: 0.5991908299433256
Validation loss: 2.4342179063644775

Epoch: 6| Step: 5
Training loss: 0.7097221298201124
Validation loss: 2.4466054140890865

Epoch: 6| Step: 6
Training loss: 0.6293053634137367
Validation loss: 2.4394511135613914

Epoch: 6| Step: 7
Training loss: 0.30384887310583053
Validation loss: 2.4345324257552

Epoch: 6| Step: 8
Training loss: 0.436797565861529
Validation loss: 2.4355794862312754

Epoch: 6| Step: 9
Training loss: 0.5362090454379426
Validation loss: 2.439693367537674

Epoch: 6| Step: 10
Training loss: 0.41789965192109835
Validation loss: 2.4582444583879597

Epoch: 6| Step: 11
Training loss: 0.19714158945905155
Validation loss: 2.446585897022436

Epoch: 6| Step: 12
Training loss: 0.5511710498784713
Validation loss: 2.440902622575578

Epoch: 6| Step: 13
Training loss: 0.5647626246104696
Validation loss: 2.477543900999658

Testing loss: 2.6022046238302075
