Epoch: 1| Step: 0
Training loss: 5.605698254502487
Validation loss: 5.834307816262834

Epoch: 6| Step: 1
Training loss: 4.805503614631288
Validation loss: 5.806021361379069

Epoch: 6| Step: 2
Training loss: 5.455890817606916
Validation loss: 5.775577625909019

Epoch: 6| Step: 3
Training loss: 6.339819080166111
Validation loss: 5.741969117585402

Epoch: 6| Step: 4
Training loss: 6.1969390696542925
Validation loss: 5.705665949011758

Epoch: 6| Step: 5
Training loss: 5.88580659457978
Validation loss: 5.6652275944854535

Epoch: 6| Step: 6
Training loss: 5.999271984437922
Validation loss: 5.618781247442709

Epoch: 6| Step: 7
Training loss: 5.134230326438606
Validation loss: 5.567924208083839

Epoch: 6| Step: 8
Training loss: 4.596661118874488
Validation loss: 5.510791853798811

Epoch: 6| Step: 9
Training loss: 5.347705826902223
Validation loss: 5.447352238854373

Epoch: 6| Step: 10
Training loss: 6.491457681226031
Validation loss: 5.377790573247498

Epoch: 6| Step: 11
Training loss: 5.53032663687881
Validation loss: 5.30426531056179

Epoch: 6| Step: 12
Training loss: 5.554293804998185
Validation loss: 5.227042428525193

Epoch: 6| Step: 13
Training loss: 4.6642563362673535
Validation loss: 5.145740245973352

Epoch: 2| Step: 0
Training loss: 5.711683566392457
Validation loss: 5.065002918525808

Epoch: 6| Step: 1
Training loss: 4.998833901802261
Validation loss: 4.98445919805531

Epoch: 6| Step: 2
Training loss: 5.129905399989536
Validation loss: 4.906391694323431

Epoch: 6| Step: 3
Training loss: 5.501911524736234
Validation loss: 4.831598343161601

Epoch: 6| Step: 4
Training loss: 5.247204354123779
Validation loss: 4.758435889146157

Epoch: 6| Step: 5
Training loss: 3.771721048697723
Validation loss: 4.687572975821189

Epoch: 6| Step: 6
Training loss: 4.53062718813803
Validation loss: 4.62527557013264

Epoch: 6| Step: 7
Training loss: 4.469532718001419
Validation loss: 4.563583952124

Epoch: 6| Step: 8
Training loss: 5.707551257537848
Validation loss: 4.504306585128804

Epoch: 6| Step: 9
Training loss: 4.784085299480974
Validation loss: 4.437689306163288

Epoch: 6| Step: 10
Training loss: 4.362840594355679
Validation loss: 4.367497012307587

Epoch: 6| Step: 11
Training loss: 3.5066092621585394
Validation loss: 4.3192012155515

Epoch: 6| Step: 12
Training loss: 3.606625124562232
Validation loss: 4.286233661069385

Epoch: 6| Step: 13
Training loss: 3.8306410636944705
Validation loss: 4.253998002127882

Epoch: 3| Step: 0
Training loss: 3.9635114564216347
Validation loss: 4.214174171921626

Epoch: 6| Step: 1
Training loss: 5.082855368901606
Validation loss: 4.172738185402768

Epoch: 6| Step: 2
Training loss: 5.070554942020049
Validation loss: 4.143476882061039

Epoch: 6| Step: 3
Training loss: 4.263283782225631
Validation loss: 4.120922447384152

Epoch: 6| Step: 4
Training loss: 3.430153782458372
Validation loss: 4.097428662384364

Epoch: 6| Step: 5
Training loss: 4.145845397216012
Validation loss: 4.0703886480551805

Epoch: 6| Step: 6
Training loss: 3.686346617241288
Validation loss: 4.044479819959352

Epoch: 6| Step: 7
Training loss: 3.539150885347757
Validation loss: 4.01694399669785

Epoch: 6| Step: 8
Training loss: 3.2815545803577892
Validation loss: 3.988322108306734

Epoch: 6| Step: 9
Training loss: 4.173390088370834
Validation loss: 3.9581106221488027

Epoch: 6| Step: 10
Training loss: 4.396434483696259
Validation loss: 3.929492872634996

Epoch: 6| Step: 11
Training loss: 4.525989082946961
Validation loss: 3.9182990871642063

Epoch: 6| Step: 12
Training loss: 4.835224943401899
Validation loss: 3.880461356923666

Epoch: 6| Step: 13
Training loss: 3.18773575453215
Validation loss: 3.8544076264988245

Epoch: 4| Step: 0
Training loss: 4.280824514811525
Validation loss: 3.837412806662012

Epoch: 6| Step: 1
Training loss: 3.586585557675212
Validation loss: 3.818251812764796

Epoch: 6| Step: 2
Training loss: 3.2636514203054405
Validation loss: 3.798291066742021

Epoch: 6| Step: 3
Training loss: 3.081072175812095
Validation loss: 3.7775067390117973

Epoch: 6| Step: 4
Training loss: 4.3992815037951125
Validation loss: 3.760065843592114

Epoch: 6| Step: 5
Training loss: 4.016665787650576
Validation loss: 3.7409787780074866

Epoch: 6| Step: 6
Training loss: 4.0694351861622025
Validation loss: 3.725445907099282

Epoch: 6| Step: 7
Training loss: 4.144684266511429
Validation loss: 3.7125121119927846

Epoch: 6| Step: 8
Training loss: 3.7502379024064587
Validation loss: 3.7013901814124615

Epoch: 6| Step: 9
Training loss: 4.843925226795228
Validation loss: 3.6907566179311284

Epoch: 6| Step: 10
Training loss: 3.2775603849084445
Validation loss: 3.6794615140278766

Epoch: 6| Step: 11
Training loss: 4.792349504108736
Validation loss: 3.6688751345267328

Epoch: 6| Step: 12
Training loss: 2.7049854909962536
Validation loss: 3.6567217888200005

Epoch: 6| Step: 13
Training loss: 3.93082807305341
Validation loss: 3.651424515270992

Epoch: 5| Step: 0
Training loss: 4.562269231107408
Validation loss: 3.6347152132429956

Epoch: 6| Step: 1
Training loss: 3.8897917441197376
Validation loss: 3.6242978537278727

Epoch: 6| Step: 2
Training loss: 3.336324271800696
Validation loss: 3.6122773697521886

Epoch: 6| Step: 3
Training loss: 3.9776005617253345
Validation loss: 3.60163700616698

Epoch: 6| Step: 4
Training loss: 3.6279571573236606
Validation loss: 3.588459721149686

Epoch: 6| Step: 5
Training loss: 3.697132783287712
Validation loss: 3.5766601358220713

Epoch: 6| Step: 6
Training loss: 3.3119647475315315
Validation loss: 3.5638733227944863

Epoch: 6| Step: 7
Training loss: 3.05210310546581
Validation loss: 3.5515416413446688

Epoch: 6| Step: 8
Training loss: 3.0826398396078165
Validation loss: 3.5364596319020283

Epoch: 6| Step: 9
Training loss: 3.9423445916372435
Validation loss: 3.526804744091525

Epoch: 6| Step: 10
Training loss: 4.2440718650953295
Validation loss: 3.5165157758328283

Epoch: 6| Step: 11
Training loss: 4.003416509682698
Validation loss: 3.5049255727077875

Epoch: 6| Step: 12
Training loss: 3.584381364253014
Validation loss: 3.490042181554905

Epoch: 6| Step: 13
Training loss: 4.281705957343564
Validation loss: 3.4820555351048577

Epoch: 6| Step: 0
Training loss: 3.9469578097755793
Validation loss: 3.4768528491553274

Epoch: 6| Step: 1
Training loss: 3.643539899000074
Validation loss: 3.478278477721946

Epoch: 6| Step: 2
Training loss: 3.5945590228123177
Validation loss: 3.4536292033230804

Epoch: 6| Step: 3
Training loss: 3.1380954253431446
Validation loss: 3.4463534376538227

Epoch: 6| Step: 4
Training loss: 3.756744677171714
Validation loss: 3.4408555672662886

Epoch: 6| Step: 5
Training loss: 3.783219510241363
Validation loss: 3.4306944658909506

Epoch: 6| Step: 6
Training loss: 3.4320163336589693
Validation loss: 3.423997506294381

Epoch: 6| Step: 7
Training loss: 3.4667137974200664
Validation loss: 3.4166447548472534

Epoch: 6| Step: 8
Training loss: 3.294555137136992
Validation loss: 3.4096686976917483

Epoch: 6| Step: 9
Training loss: 3.8472108224882735
Validation loss: 3.4044162510290907

Epoch: 6| Step: 10
Training loss: 3.403786844816921
Validation loss: 3.3938613476598816

Epoch: 6| Step: 11
Training loss: 4.163413850745338
Validation loss: 3.3857373657284984

Epoch: 6| Step: 12
Training loss: 3.7853768267693098
Validation loss: 3.3750496879271363

Epoch: 6| Step: 13
Training loss: 3.638846163381579
Validation loss: 3.365234873218152

Epoch: 7| Step: 0
Training loss: 4.202559762832727
Validation loss: 3.353945310107841

Epoch: 6| Step: 1
Training loss: 3.0618849156116554
Validation loss: 3.3440548076748327

Epoch: 6| Step: 2
Training loss: 3.0075759596519207
Validation loss: 3.332840303650105

Epoch: 6| Step: 3
Training loss: 3.506883527942188
Validation loss: 3.32677981945123

Epoch: 6| Step: 4
Training loss: 3.9649469371578654
Validation loss: 3.319283219011901

Epoch: 6| Step: 5
Training loss: 3.5651125781245883
Validation loss: 3.311527870322757

Epoch: 6| Step: 6
Training loss: 3.811383943890857
Validation loss: 3.305384065809966

Epoch: 6| Step: 7
Training loss: 3.724323615807798
Validation loss: 3.2991918002993033

Epoch: 6| Step: 8
Training loss: 3.477609952371738
Validation loss: 3.2872746519220093

Epoch: 6| Step: 9
Training loss: 3.403941080625676
Validation loss: 3.2843575758694437

Epoch: 6| Step: 10
Training loss: 3.3106047768719633
Validation loss: 3.2726044717391343

Epoch: 6| Step: 11
Training loss: 2.796663244318848
Validation loss: 3.268753935365412

Epoch: 6| Step: 12
Training loss: 3.7467749396955337
Validation loss: 3.262250592402232

Epoch: 6| Step: 13
Training loss: 3.9985000659121677
Validation loss: 3.2564040273973003

Epoch: 8| Step: 0
Training loss: 3.710951377441157
Validation loss: 3.247711908073789

Epoch: 6| Step: 1
Training loss: 3.8321940069602975
Validation loss: 3.2425304410862585

Epoch: 6| Step: 2
Training loss: 2.9721810842105274
Validation loss: 3.239350810333743

Epoch: 6| Step: 3
Training loss: 3.112445178181074
Validation loss: 3.233717154135925

Epoch: 6| Step: 4
Training loss: 3.237475544605164
Validation loss: 3.231285085218067

Epoch: 6| Step: 5
Training loss: 3.4719907725866377
Validation loss: 3.231209821033329

Epoch: 6| Step: 6
Training loss: 3.2334867722851395
Validation loss: 3.216617469171212

Epoch: 6| Step: 7
Training loss: 3.3332033767798452
Validation loss: 3.210082349424049

Epoch: 6| Step: 8
Training loss: 3.842933257874133
Validation loss: 3.2079203089027923

Epoch: 6| Step: 9
Training loss: 3.5545369881425124
Validation loss: 3.20344845879134

Epoch: 6| Step: 10
Training loss: 3.619596992947892
Validation loss: 3.198154457590515

Epoch: 6| Step: 11
Training loss: 3.4137777039483836
Validation loss: 3.1917129718440895

Epoch: 6| Step: 12
Training loss: 3.4293475493091448
Validation loss: 3.1935172520732853

Epoch: 6| Step: 13
Training loss: 3.870118912439686
Validation loss: 3.1858498558416457

Epoch: 9| Step: 0
Training loss: 2.6634416947582977
Validation loss: 3.1784867958981153

Epoch: 6| Step: 1
Training loss: 3.9437781041227593
Validation loss: 3.174139530576966

Epoch: 6| Step: 2
Training loss: 3.978950667718525
Validation loss: 3.1727740201170453

Epoch: 6| Step: 3
Training loss: 3.442308565245396
Validation loss: 3.168815891096722

Epoch: 6| Step: 4
Training loss: 3.7372327268842946
Validation loss: 3.161997348551385

Epoch: 6| Step: 5
Training loss: 2.9397334272499975
Validation loss: 3.1577411379435856

Epoch: 6| Step: 6
Training loss: 3.318841011250612
Validation loss: 3.1497314549605466

Epoch: 6| Step: 7
Training loss: 3.29096520269237
Validation loss: 3.1446425062393106

Epoch: 6| Step: 8
Training loss: 2.8064770103340755
Validation loss: 3.149443685651923

Epoch: 6| Step: 9
Training loss: 4.018660885785389
Validation loss: 3.1469933817711846

Epoch: 6| Step: 10
Training loss: 3.158452842149001
Validation loss: 3.133737632017984

Epoch: 6| Step: 11
Training loss: 3.5239549751652883
Validation loss: 3.132127469016634

Epoch: 6| Step: 12
Training loss: 3.162065040319991
Validation loss: 3.133200534392412

Epoch: 6| Step: 13
Training loss: 3.7033957853181723
Validation loss: 3.1291840237068285

Epoch: 10| Step: 0
Training loss: 4.381459290733787
Validation loss: 3.123261620807597

Epoch: 6| Step: 1
Training loss: 3.9553173152981373
Validation loss: 3.112762515416735

Epoch: 6| Step: 2
Training loss: 2.5786716690777634
Validation loss: 3.110893224729916

Epoch: 6| Step: 3
Training loss: 3.4088642692367648
Validation loss: 3.1170999734327203

Epoch: 6| Step: 4
Training loss: 2.8707021017951297
Validation loss: 3.101607511055379

Epoch: 6| Step: 5
Training loss: 3.453200257460815
Validation loss: 3.102063311205741

Epoch: 6| Step: 6
Training loss: 3.4323581038872257
Validation loss: 3.1065868570800115

Epoch: 6| Step: 7
Training loss: 3.152605577677893
Validation loss: 3.1134426854126134

Epoch: 6| Step: 8
Training loss: 2.9122480619117743
Validation loss: 3.121537749652832

Epoch: 6| Step: 9
Training loss: 3.060220298067621
Validation loss: 3.111257541292231

Epoch: 6| Step: 10
Training loss: 3.162139232699525
Validation loss: 3.1085113481893756

Epoch: 6| Step: 11
Training loss: 3.471234505783299
Validation loss: 3.079463899290846

Epoch: 6| Step: 12
Training loss: 3.668672764239708
Validation loss: 3.0755291967382536

Epoch: 6| Step: 13
Training loss: 3.4230244417379425
Validation loss: 3.0778529899263205

Epoch: 11| Step: 0
Training loss: 3.3735795034016145
Validation loss: 3.0769592871233207

Epoch: 6| Step: 1
Training loss: 2.9950587587531214
Validation loss: 3.070844207458126

Epoch: 6| Step: 2
Training loss: 3.0883444368753317
Validation loss: 3.065557322033618

Epoch: 6| Step: 3
Training loss: 3.418626471315405
Validation loss: 3.0616037230449664

Epoch: 6| Step: 4
Training loss: 3.1898839674747026
Validation loss: 3.058447986000657

Epoch: 6| Step: 5
Training loss: 4.118511761503015
Validation loss: 3.05769096548537

Epoch: 6| Step: 6
Training loss: 3.492803805114239
Validation loss: 3.0577263593378836

Epoch: 6| Step: 7
Training loss: 3.6176655990986584
Validation loss: 3.0530728719001154

Epoch: 6| Step: 8
Training loss: 3.418404548110275
Validation loss: 3.0488133098342214

Epoch: 6| Step: 9
Training loss: 3.7237791787470846
Validation loss: 3.0455510353244715

Epoch: 6| Step: 10
Training loss: 2.1974769863620462
Validation loss: 3.0433987130450832

Epoch: 6| Step: 11
Training loss: 3.5324888503755174
Validation loss: 3.0407120084042174

Epoch: 6| Step: 12
Training loss: 3.2122281861254454
Validation loss: 3.0386912066905865

Epoch: 6| Step: 13
Training loss: 2.7311661556826397
Validation loss: 3.0354638419385696

Epoch: 12| Step: 0
Training loss: 3.0300835006841256
Validation loss: 3.0393715623883204

Epoch: 6| Step: 1
Training loss: 3.3162808703478595
Validation loss: 3.0477483733978445

Epoch: 6| Step: 2
Training loss: 3.324681466125182
Validation loss: 3.0344482690821075

Epoch: 6| Step: 3
Training loss: 2.551334245216932
Validation loss: 3.0225853551799755

Epoch: 6| Step: 4
Training loss: 3.1395629301633776
Validation loss: 3.021383349311591

Epoch: 6| Step: 5
Training loss: 3.301469972526206
Validation loss: 3.0193910787363083

Epoch: 6| Step: 6
Training loss: 3.023307383494972
Validation loss: 3.0188831001495458

Epoch: 6| Step: 7
Training loss: 3.146507712999265
Validation loss: 3.0170204181123457

Epoch: 6| Step: 8
Training loss: 3.9557886610983672
Validation loss: 3.015720868115697

Epoch: 6| Step: 9
Training loss: 2.7975094890689225
Validation loss: 3.0146533187608298

Epoch: 6| Step: 10
Training loss: 3.403439823717615
Validation loss: 3.011747127898452

Epoch: 6| Step: 11
Training loss: 3.5746583095065354
Validation loss: 3.009821499163772

Epoch: 6| Step: 12
Training loss: 4.178607893937216
Validation loss: 3.0080318912675743

Epoch: 6| Step: 13
Training loss: 3.264173997551525
Validation loss: 3.0057180416039118

Epoch: 13| Step: 0
Training loss: 2.5372696870661553
Validation loss: 3.002143781806779

Epoch: 6| Step: 1
Training loss: 3.710809388208022
Validation loss: 3.0091340516571803

Epoch: 6| Step: 2
Training loss: 3.760924511939754
Validation loss: 3.0151686946147667

Epoch: 6| Step: 3
Training loss: 3.3698275454624125
Validation loss: 3.000992115277402

Epoch: 6| Step: 4
Training loss: 3.2098817597950915
Validation loss: 3.0014109216228513

Epoch: 6| Step: 5
Training loss: 2.4295900576760174
Validation loss: 2.9957317578503235

Epoch: 6| Step: 6
Training loss: 3.387130131535265
Validation loss: 2.9953208497891812

Epoch: 6| Step: 7
Training loss: 3.8902478628942676
Validation loss: 2.997498245067008

Epoch: 6| Step: 8
Training loss: 3.4433964874985263
Validation loss: 2.994911082037293

Epoch: 6| Step: 9
Training loss: 3.509765625
Validation loss: 2.9885350629412684

Epoch: 6| Step: 10
Training loss: 2.7404778087589565
Validation loss: 2.9894564327510267

Epoch: 6| Step: 11
Training loss: 3.442652637918001
Validation loss: 2.987767649221163

Epoch: 6| Step: 12
Training loss: 3.4255105132383044
Validation loss: 2.9863687212561882

Epoch: 6| Step: 13
Training loss: 2.5963923771277484
Validation loss: 2.984420660050067

Epoch: 14| Step: 0
Training loss: 3.2080650382548126
Validation loss: 2.9844570628607445

Epoch: 6| Step: 1
Training loss: 2.8694854591427945
Validation loss: 2.9834834728270274

Epoch: 6| Step: 2
Training loss: 3.407519462680999
Validation loss: 2.9799895890764225

Epoch: 6| Step: 3
Training loss: 2.793117108439515
Validation loss: 2.9787461695215853

Epoch: 6| Step: 4
Training loss: 3.4918824474391172
Validation loss: 2.979872044284661

Epoch: 6| Step: 5
Training loss: 3.676688946690728
Validation loss: 2.979666780579507

Epoch: 6| Step: 6
Training loss: 3.0328269081618564
Validation loss: 2.980125672748309

Epoch: 6| Step: 7
Training loss: 2.68305788423171
Validation loss: 2.9791090982871244

Epoch: 6| Step: 8
Training loss: 3.0599617852212075
Validation loss: 2.9833782713294292

Epoch: 6| Step: 9
Training loss: 3.565988806603751
Validation loss: 2.9824709138355443

Epoch: 6| Step: 10
Training loss: 2.9969042063573736
Validation loss: 2.9836549900250007

Epoch: 6| Step: 11
Training loss: 3.8667642997605043
Validation loss: 2.987690501352755

Epoch: 6| Step: 12
Training loss: 3.229910898072091
Validation loss: 2.9691652759885607

Epoch: 6| Step: 13
Training loss: 4.124327171246058
Validation loss: 2.9661612760341027

Epoch: 15| Step: 0
Training loss: 3.996749152975338
Validation loss: 2.9633842530406587

Epoch: 6| Step: 1
Training loss: 3.4194530817152264
Validation loss: 2.9634418711160566

Epoch: 6| Step: 2
Training loss: 3.358258154874016
Validation loss: 2.9642627215964388

Epoch: 6| Step: 3
Training loss: 4.3372750083769205
Validation loss: 2.9620922985150133

Epoch: 6| Step: 4
Training loss: 2.9158641982827573
Validation loss: 2.9588886631186604

Epoch: 6| Step: 5
Training loss: 2.9838585531546857
Validation loss: 2.9790653898816064

Epoch: 6| Step: 6
Training loss: 2.500705714754909
Validation loss: 2.955822237815473

Epoch: 6| Step: 7
Training loss: 2.9056768364897003
Validation loss: 2.9574607944286693

Epoch: 6| Step: 8
Training loss: 3.6531093835292947
Validation loss: 2.9561756933872765

Epoch: 6| Step: 9
Training loss: 2.6702619892698003
Validation loss: 2.958664601860876

Epoch: 6| Step: 10
Training loss: 2.9872633453231945
Validation loss: 2.9595590403851144

Epoch: 6| Step: 11
Training loss: 2.899605980775664
Validation loss: 2.9623458101503855

Epoch: 6| Step: 12
Training loss: 3.1824466815326757
Validation loss: 2.965599268055148

Epoch: 6| Step: 13
Training loss: 3.5659728941173388
Validation loss: 2.968315774090293

Epoch: 16| Step: 0
Training loss: 3.0632077391914483
Validation loss: 2.9596652392565694

Epoch: 6| Step: 1
Training loss: 3.3520954126330453
Validation loss: 2.968791192399895

Epoch: 6| Step: 2
Training loss: 3.826563053279041
Validation loss: 2.960576041134507

Epoch: 6| Step: 3
Training loss: 3.021915811856809
Validation loss: 2.9495072470693358

Epoch: 6| Step: 4
Training loss: 3.050989278228735
Validation loss: 2.9479730881067736

Epoch: 6| Step: 5
Training loss: 3.002963192140325
Validation loss: 2.951282746740603

Epoch: 6| Step: 6
Training loss: 3.1025312241697494
Validation loss: 2.9542086795623197

Epoch: 6| Step: 7
Training loss: 3.5999201341882823
Validation loss: 2.954002142894032

Epoch: 6| Step: 8
Training loss: 3.470860706845736
Validation loss: 2.9488569448848643

Epoch: 6| Step: 9
Training loss: 3.551303871226879
Validation loss: 2.9480550598638677

Epoch: 6| Step: 10
Training loss: 3.2999376291102935
Validation loss: 2.9460614063045805

Epoch: 6| Step: 11
Training loss: 2.7810718607913127
Validation loss: 2.93993873224855

Epoch: 6| Step: 12
Training loss: 2.878692577615904
Validation loss: 2.935901420693041

Epoch: 6| Step: 13
Training loss: 3.576718916166216
Validation loss: 2.933246160309133

Epoch: 17| Step: 0
Training loss: 3.339539345594162
Validation loss: 2.929658464622864

Epoch: 6| Step: 1
Training loss: 2.6678261223085866
Validation loss: 2.9279145971317133

Epoch: 6| Step: 2
Training loss: 3.188329999981454
Validation loss: 2.925827370578883

Epoch: 6| Step: 3
Training loss: 3.450676097135712
Validation loss: 2.926859112275269

Epoch: 6| Step: 4
Training loss: 3.6441646281132787
Validation loss: 2.9259896060915804

Epoch: 6| Step: 5
Training loss: 3.373812713888184
Validation loss: 2.922042917310698

Epoch: 6| Step: 6
Training loss: 2.6953506245888375
Validation loss: 2.921776901124125

Epoch: 6| Step: 7
Training loss: 3.2848189063938875
Validation loss: 2.9250990464940556

Epoch: 6| Step: 8
Training loss: 3.4510896648120797
Validation loss: 2.92243552313851

Epoch: 6| Step: 9
Training loss: 3.2979641963757236
Validation loss: 2.924069455135479

Epoch: 6| Step: 10
Training loss: 2.6498470550162
Validation loss: 2.9193360604773604

Epoch: 6| Step: 11
Training loss: 3.2136388400248417
Validation loss: 2.9185533729305284

Epoch: 6| Step: 12
Training loss: 3.2362771453249395
Validation loss: 2.9188919514543223

Epoch: 6| Step: 13
Training loss: 3.8237454021085773
Validation loss: 2.9213074523434135

Epoch: 18| Step: 0
Training loss: 3.6722789785667618
Validation loss: 2.92546012771459

Epoch: 6| Step: 1
Training loss: 2.9902761544885013
Validation loss: 2.9481711123280374

Epoch: 6| Step: 2
Training loss: 3.3280161092074856
Validation loss: 2.9771408261219183

Epoch: 6| Step: 3
Training loss: 2.5503460219238816
Validation loss: 2.9453069902755136

Epoch: 6| Step: 4
Training loss: 2.8544305461292594
Validation loss: 2.9376466042950358

Epoch: 6| Step: 5
Training loss: 3.692956540366161
Validation loss: 2.918736292810443

Epoch: 6| Step: 6
Training loss: 3.303455601138209
Validation loss: 2.9106934569066554

Epoch: 6| Step: 7
Training loss: 3.2875300300880097
Validation loss: 2.910978207486224

Epoch: 6| Step: 8
Training loss: 3.4552553259745915
Validation loss: 2.911064997658521

Epoch: 6| Step: 9
Training loss: 2.854939339923627
Validation loss: 2.9095112416903888

Epoch: 6| Step: 10
Training loss: 3.2778811645007613
Validation loss: 2.908548439268358

Epoch: 6| Step: 11
Training loss: 3.4502997945367264
Validation loss: 2.908114049516706

Epoch: 6| Step: 12
Training loss: 3.3799120161353913
Validation loss: 2.9105603410132015

Epoch: 6| Step: 13
Training loss: 2.67364951652477
Validation loss: 2.9085101124113173

Epoch: 19| Step: 0
Training loss: 2.6850965531533237
Validation loss: 2.911832553634176

Epoch: 6| Step: 1
Training loss: 3.248907932788694
Validation loss: 2.9134698010082696

Epoch: 6| Step: 2
Training loss: 2.935447462762811
Validation loss: 2.908946321060123

Epoch: 6| Step: 3
Training loss: 3.3534365663001915
Validation loss: 2.9051040284836516

Epoch: 6| Step: 4
Training loss: 2.7589818620407023
Validation loss: 2.9041787259130194

Epoch: 6| Step: 5
Training loss: 3.566240054015401
Validation loss: 2.9021413939001417

Epoch: 6| Step: 6
Training loss: 3.0075249076186035
Validation loss: 2.9013756143566005

Epoch: 6| Step: 7
Training loss: 2.8823203723848847
Validation loss: 2.900763838006553

Epoch: 6| Step: 8
Training loss: 3.419784116121792
Validation loss: 2.901212797712168

Epoch: 6| Step: 9
Training loss: 3.330410597864205
Validation loss: 2.9011258599323644

Epoch: 6| Step: 10
Training loss: 3.3421451603373113
Validation loss: 2.899880300476537

Epoch: 6| Step: 11
Training loss: 2.9701924885239808
Validation loss: 2.9098632559295554

Epoch: 6| Step: 12
Training loss: 3.577040862044401
Validation loss: 2.9258982779298193

Epoch: 6| Step: 13
Training loss: 3.930874654684665
Validation loss: 2.9365019594090156

Epoch: 20| Step: 0
Training loss: 3.487678091225963
Validation loss: 2.926470080993602

Epoch: 6| Step: 1
Training loss: 3.569060458760621
Validation loss: 2.901753795709217

Epoch: 6| Step: 2
Training loss: 3.39703915645928
Validation loss: 2.8934513534425608

Epoch: 6| Step: 3
Training loss: 2.762296322179628
Validation loss: 2.891528573751573

Epoch: 6| Step: 4
Training loss: 4.043487191246126
Validation loss: 2.8900203978269334

Epoch: 6| Step: 5
Training loss: 3.1762556821974215
Validation loss: 2.8897544412417018

Epoch: 6| Step: 6
Training loss: 2.855025521880815
Validation loss: 2.8917822661141113

Epoch: 6| Step: 7
Training loss: 3.3893344374333987
Validation loss: 2.891004512299453

Epoch: 6| Step: 8
Training loss: 2.8431742997170923
Validation loss: 2.8877331911976327

Epoch: 6| Step: 9
Training loss: 3.1937217576780714
Validation loss: 2.885211460316371

Epoch: 6| Step: 10
Training loss: 2.1039126277448705
Validation loss: 2.8857472210664894

Epoch: 6| Step: 11
Training loss: 2.583492540765488
Validation loss: 2.893087862543643

Epoch: 6| Step: 12
Training loss: 3.6363335066327402
Validation loss: 2.9101581475201517

Epoch: 6| Step: 13
Training loss: 3.3365555130479083
Validation loss: 2.900768647540025

Epoch: 21| Step: 0
Training loss: 2.6484056318948284
Validation loss: 2.9042033190019563

Epoch: 6| Step: 1
Training loss: 3.599368273090714
Validation loss: 2.9044549404149977

Epoch: 6| Step: 2
Training loss: 3.5182986794961755
Validation loss: 2.8913463079478467

Epoch: 6| Step: 3
Training loss: 3.031003647064864
Validation loss: 2.8827984394875883

Epoch: 6| Step: 4
Training loss: 2.7562056661141376
Validation loss: 2.8803390268260607

Epoch: 6| Step: 5
Training loss: 3.2257448504318953
Validation loss: 2.8807712338581526

Epoch: 6| Step: 6
Training loss: 3.0097885972618608
Validation loss: 2.8793742211834314

Epoch: 6| Step: 7
Training loss: 3.224826743033338
Validation loss: 2.881900747552473

Epoch: 6| Step: 8
Training loss: 3.2583389405757597
Validation loss: 2.8793539648399427

Epoch: 6| Step: 9
Training loss: 2.376036166985109
Validation loss: 2.877375623055317

Epoch: 6| Step: 10
Training loss: 3.9916957246257643
Validation loss: 2.875220097288966

Epoch: 6| Step: 11
Training loss: 3.1801040713956557
Validation loss: 2.8834952722990983

Epoch: 6| Step: 12
Training loss: 3.4160858373912815
Validation loss: 2.8800687153969275

Epoch: 6| Step: 13
Training loss: 2.9571363866299536
Validation loss: 2.879430657021214

Epoch: 22| Step: 0
Training loss: 3.5815109823575924
Validation loss: 2.8731581060874367

Epoch: 6| Step: 1
Training loss: 2.641666726033143
Validation loss: 2.868695598596478

Epoch: 6| Step: 2
Training loss: 3.3932059173294955
Validation loss: 2.867991942132153

Epoch: 6| Step: 3
Training loss: 3.31116185060521
Validation loss: 2.869205907664505

Epoch: 6| Step: 4
Training loss: 2.536421026834112
Validation loss: 2.868884539064954

Epoch: 6| Step: 5
Training loss: 2.8834298979478232
Validation loss: 2.869145782405085

Epoch: 6| Step: 6
Training loss: 3.4351015913820127
Validation loss: 2.8727812228418803

Epoch: 6| Step: 7
Training loss: 2.8082041675811373
Validation loss: 2.8646569051085704

Epoch: 6| Step: 8
Training loss: 3.557423236847082
Validation loss: 2.8657779121715734

Epoch: 6| Step: 9
Training loss: 3.2348797537906067
Validation loss: 2.8656311147455074

Epoch: 6| Step: 10
Training loss: 2.8122337215256636
Validation loss: 2.8707475926940913

Epoch: 6| Step: 11
Training loss: 3.5952514165789693
Validation loss: 2.872718952992158

Epoch: 6| Step: 12
Training loss: 3.399161426128348
Validation loss: 2.8674116382054797

Epoch: 6| Step: 13
Training loss: 2.790989399834147
Validation loss: 2.861281717387385

Epoch: 23| Step: 0
Training loss: 2.2395776319800853
Validation loss: 2.860270189200593

Epoch: 6| Step: 1
Training loss: 4.077778417833805
Validation loss: 2.863409651143755

Epoch: 6| Step: 2
Training loss: 2.8243733175145653
Validation loss: 2.8613296060244364

Epoch: 6| Step: 3
Training loss: 3.778507341422934
Validation loss: 2.8636807938252296

Epoch: 6| Step: 4
Training loss: 3.1254174525860843
Validation loss: 2.857438088910352

Epoch: 6| Step: 5
Training loss: 3.538147393286992
Validation loss: 2.860934954438969

Epoch: 6| Step: 6
Training loss: 3.192530682564954
Validation loss: 2.861135834389532

Epoch: 6| Step: 7
Training loss: 3.01853889058872
Validation loss: 2.854247758894661

Epoch: 6| Step: 8
Training loss: 3.463357944443914
Validation loss: 2.852857256277517

Epoch: 6| Step: 9
Training loss: 2.7112328096427825
Validation loss: 2.854012863246319

Epoch: 6| Step: 10
Training loss: 2.769185247719579
Validation loss: 2.8561992621818786

Epoch: 6| Step: 11
Training loss: 3.1842795165836004
Validation loss: 2.859259033003279

Epoch: 6| Step: 12
Training loss: 3.3297693909304504
Validation loss: 2.861322870179344

Epoch: 6| Step: 13
Training loss: 2.097496779647374
Validation loss: 2.8594965620608765

Epoch: 24| Step: 0
Training loss: 3.8247805563615396
Validation loss: 2.8617105873140227

Epoch: 6| Step: 1
Training loss: 3.1625943015291185
Validation loss: 2.8659829028471124

Epoch: 6| Step: 2
Training loss: 3.423086013056523
Validation loss: 2.874986547765875

Epoch: 6| Step: 3
Training loss: 2.7399468899890995
Validation loss: 2.863385620909954

Epoch: 6| Step: 4
Training loss: 3.2052846187670583
Validation loss: 2.8568915687679093

Epoch: 6| Step: 5
Training loss: 3.763727746933823
Validation loss: 2.855310793832782

Epoch: 6| Step: 6
Training loss: 3.47433928650948
Validation loss: 2.852075994167187

Epoch: 6| Step: 7
Training loss: 2.7244035540539504
Validation loss: 2.849171433095163

Epoch: 6| Step: 8
Training loss: 3.7122188885541334
Validation loss: 2.8472083139334137

Epoch: 6| Step: 9
Training loss: 3.1376641583906983
Validation loss: 2.846076277986825

Epoch: 6| Step: 10
Training loss: 2.644732288737247
Validation loss: 2.8465856463946797

Epoch: 6| Step: 11
Training loss: 2.489655359308992
Validation loss: 2.8465052215028024

Epoch: 6| Step: 12
Training loss: 3.0371702917926178
Validation loss: 2.846845110605129

Epoch: 6| Step: 13
Training loss: 2.009647940553445
Validation loss: 2.8476864176660066

Epoch: 25| Step: 0
Training loss: 3.7343870027101826
Validation loss: 2.8436253612870948

Epoch: 6| Step: 1
Training loss: 2.9857583559633687
Validation loss: 2.841682521824072

Epoch: 6| Step: 2
Training loss: 2.983771777479063
Validation loss: 2.8405518612711798

Epoch: 6| Step: 3
Training loss: 3.313032863151124
Validation loss: 2.839665438801997

Epoch: 6| Step: 4
Training loss: 2.817703942784939
Validation loss: 2.8377886183159613

Epoch: 6| Step: 5
Training loss: 3.280714009422506
Validation loss: 2.8360603541170746

Epoch: 6| Step: 6
Training loss: 3.087094787694484
Validation loss: 2.835227429716046

Epoch: 6| Step: 7
Training loss: 3.316816288881471
Validation loss: 2.840731347781824

Epoch: 6| Step: 8
Training loss: 3.3571167918761593
Validation loss: 2.8426624622405456

Epoch: 6| Step: 9
Training loss: 2.8338450549403995
Validation loss: 2.8405074237930137

Epoch: 6| Step: 10
Training loss: 2.8091538763382196
Validation loss: 2.8443486772245326

Epoch: 6| Step: 11
Training loss: 3.524568972376628
Validation loss: 2.8748586779543803

Epoch: 6| Step: 12
Training loss: 2.9390728574628104
Validation loss: 2.8526503688900178

Epoch: 6| Step: 13
Training loss: 2.7348750066003555
Validation loss: 2.846965530080105

Epoch: 26| Step: 0
Training loss: 3.422478052240278
Validation loss: 2.8372235334998517

Epoch: 6| Step: 1
Training loss: 3.1421960345910636
Validation loss: 2.833322666758583

Epoch: 6| Step: 2
Training loss: 3.510086783615987
Validation loss: 2.830950261117527

Epoch: 6| Step: 3
Training loss: 2.637962488782606
Validation loss: 2.829389937505787

Epoch: 6| Step: 4
Training loss: 3.2723694290212215
Validation loss: 2.8306770021414533

Epoch: 6| Step: 5
Training loss: 3.336197639703336
Validation loss: 2.8286297314393414

Epoch: 6| Step: 6
Training loss: 3.0968627683088097
Validation loss: 2.831332782275003

Epoch: 6| Step: 7
Training loss: 3.336573520037324
Validation loss: 2.8295587234465396

Epoch: 6| Step: 8
Training loss: 2.9166189643955343
Validation loss: 2.8264987521043077

Epoch: 6| Step: 9
Training loss: 2.912689949357615
Validation loss: 2.8272534345629476

Epoch: 6| Step: 10
Training loss: 3.2780580526521517
Validation loss: 2.826354303775165

Epoch: 6| Step: 11
Training loss: 2.9274343549370703
Validation loss: 2.8249539373637047

Epoch: 6| Step: 12
Training loss: 3.1631910089352475
Validation loss: 2.8260697673636064

Epoch: 6| Step: 13
Training loss: 2.8406945886261004
Validation loss: 2.8252447193088632

Epoch: 27| Step: 0
Training loss: 2.7142733846111913
Validation loss: 2.822312465238862

Epoch: 6| Step: 1
Training loss: 3.2913714570244474
Validation loss: 2.82636707589725

Epoch: 6| Step: 2
Training loss: 2.875689216598168
Validation loss: 2.852258117042684

Epoch: 6| Step: 3
Training loss: 2.5969729335051603
Validation loss: 2.846789618227847

Epoch: 6| Step: 4
Training loss: 3.622272912615337
Validation loss: 2.841510610818518

Epoch: 6| Step: 5
Training loss: 3.3696301444647956
Validation loss: 2.829560664143622

Epoch: 6| Step: 6
Training loss: 3.1097807499671437
Validation loss: 2.831588998222973

Epoch: 6| Step: 7
Training loss: 3.420996148110334
Validation loss: 2.8422413299024716

Epoch: 6| Step: 8
Training loss: 3.348265549040226
Validation loss: 2.830988870992902

Epoch: 6| Step: 9
Training loss: 3.1884590650840723
Validation loss: 2.826078758919954

Epoch: 6| Step: 10
Training loss: 2.872334945093312
Validation loss: 2.8230900471506533

Epoch: 6| Step: 11
Training loss: 3.456566937834061
Validation loss: 2.832023162660519

Epoch: 6| Step: 12
Training loss: 2.910161165578902
Validation loss: 2.818290552187518

Epoch: 6| Step: 13
Training loss: 3.1226460555699713
Validation loss: 2.826990554852584

Epoch: 28| Step: 0
Training loss: 3.5012123188141584
Validation loss: 2.838988433898823

Epoch: 6| Step: 1
Training loss: 3.501166285610706
Validation loss: 2.8328346510897577

Epoch: 6| Step: 2
Training loss: 3.131274219046183
Validation loss: 2.8259824256775796

Epoch: 6| Step: 3
Training loss: 3.6338256735675842
Validation loss: 2.8179230885188087

Epoch: 6| Step: 4
Training loss: 3.5722421318937707
Validation loss: 2.8148933281527366

Epoch: 6| Step: 5
Training loss: 2.302104368732255
Validation loss: 2.8139807719106864

Epoch: 6| Step: 6
Training loss: 2.0961781556221366
Validation loss: 2.812010697218036

Epoch: 6| Step: 7
Training loss: 3.8121375239924196
Validation loss: 2.8109489438997772

Epoch: 6| Step: 8
Training loss: 2.6706264322474786
Validation loss: 2.8109196797733533

Epoch: 6| Step: 9
Training loss: 2.5594272333388086
Validation loss: 2.8220323351167167

Epoch: 6| Step: 10
Training loss: 2.7380421489204902
Validation loss: 2.8358074382030853

Epoch: 6| Step: 11
Training loss: 3.5019114588116653
Validation loss: 2.811665749189165

Epoch: 6| Step: 12
Training loss: 2.7297398981962
Validation loss: 2.806722254298244

Epoch: 6| Step: 13
Training loss: 3.6751882336216832
Validation loss: 2.8106302005014703

Epoch: 29| Step: 0
Training loss: 2.8758593394510132
Validation loss: 2.8108552049584907

Epoch: 6| Step: 1
Training loss: 3.481226846011842
Validation loss: 2.806303625085249

Epoch: 6| Step: 2
Training loss: 3.1624551340169886
Validation loss: 2.8141074360020193

Epoch: 6| Step: 3
Training loss: 2.7910145999167115
Validation loss: 2.8054823178677006

Epoch: 6| Step: 4
Training loss: 3.4344124539444287
Validation loss: 2.801257373634481

Epoch: 6| Step: 5
Training loss: 3.005098302315515
Validation loss: 2.799931934294076

Epoch: 6| Step: 6
Training loss: 3.5658802258738755
Validation loss: 2.7980687443452066

Epoch: 6| Step: 7
Training loss: 2.6484892623479177
Validation loss: 2.79847918306291

Epoch: 6| Step: 8
Training loss: 2.857771460320329
Validation loss: 2.796669255888976

Epoch: 6| Step: 9
Training loss: 2.9067493953072634
Validation loss: 2.796084405167435

Epoch: 6| Step: 10
Training loss: 3.212093989620593
Validation loss: 2.7965704327630405

Epoch: 6| Step: 11
Training loss: 3.063176294507136
Validation loss: 2.7960725092367826

Epoch: 6| Step: 12
Training loss: 3.5188036303049737
Validation loss: 2.7963488298059995

Epoch: 6| Step: 13
Training loss: 2.8368804456915298
Validation loss: 2.79869542263381

Epoch: 30| Step: 0
Training loss: 3.6429590430018917
Validation loss: 2.795655666313239

Epoch: 6| Step: 1
Training loss: 3.092326597812175
Validation loss: 2.7991220166388677

Epoch: 6| Step: 2
Training loss: 3.1088219538982993
Validation loss: 2.808022124477082

Epoch: 6| Step: 3
Training loss: 2.8235643401626835
Validation loss: 2.81812509767092

Epoch: 6| Step: 4
Training loss: 3.0511207147484014
Validation loss: 2.7958205652948687

Epoch: 6| Step: 5
Training loss: 2.079892661552885
Validation loss: 2.7938467655701484

Epoch: 6| Step: 6
Training loss: 3.510076730873018
Validation loss: 2.7908612593824844

Epoch: 6| Step: 7
Training loss: 3.422208586854179
Validation loss: 2.7920677975587513

Epoch: 6| Step: 8
Training loss: 3.271959212275115
Validation loss: 2.7901645559401316

Epoch: 6| Step: 9
Training loss: 2.9541120544751696
Validation loss: 2.792695413494041

Epoch: 6| Step: 10
Training loss: 2.827171544324829
Validation loss: 2.790211489453657

Epoch: 6| Step: 11
Training loss: 2.9437471879755344
Validation loss: 2.795556975175368

Epoch: 6| Step: 12
Training loss: 2.9168870751797344
Validation loss: 2.8059878788008716

Epoch: 6| Step: 13
Training loss: 3.846033302032024
Validation loss: 2.7937395297370884

Epoch: 31| Step: 0
Training loss: 3.141335781761385
Validation loss: 2.790243160239732

Epoch: 6| Step: 1
Training loss: 2.914511474712438
Validation loss: 2.787028859179861

Epoch: 6| Step: 2
Training loss: 2.5871765303099856
Validation loss: 2.7865824409074076

Epoch: 6| Step: 3
Training loss: 2.9962581504866885
Validation loss: 2.7902335662437965

Epoch: 6| Step: 4
Training loss: 3.051326844569447
Validation loss: 2.7935191696301787

Epoch: 6| Step: 5
Training loss: 2.872506096603524
Validation loss: 2.803195915624269

Epoch: 6| Step: 6
Training loss: 2.8456190066711198
Validation loss: 2.8140559041301016

Epoch: 6| Step: 7
Training loss: 3.1870523774242105
Validation loss: 2.8058466432534583

Epoch: 6| Step: 8
Training loss: 2.9418361395268384
Validation loss: 2.8077342246381094

Epoch: 6| Step: 9
Training loss: 3.22343444676146
Validation loss: 2.814073827336662

Epoch: 6| Step: 10
Training loss: 3.5966079626044762
Validation loss: 2.8040442070481717

Epoch: 6| Step: 11
Training loss: 3.4226760275068426
Validation loss: 2.8062996786358227

Epoch: 6| Step: 12
Training loss: 3.4441552673146276
Validation loss: 2.7896624867359665

Epoch: 6| Step: 13
Training loss: 3.1767303437465197
Validation loss: 2.7819752334668664

Epoch: 32| Step: 0
Training loss: 3.4324898013792065
Validation loss: 2.7777590151806013

Epoch: 6| Step: 1
Training loss: 2.9391203935955597
Validation loss: 2.7838202160875687

Epoch: 6| Step: 2
Training loss: 3.462880159847413
Validation loss: 2.7932160656745326

Epoch: 6| Step: 3
Training loss: 3.521428992692275
Validation loss: 2.802562337978286

Epoch: 6| Step: 4
Training loss: 2.9105886253359574
Validation loss: 2.789597414927405

Epoch: 6| Step: 5
Training loss: 3.790782168558738
Validation loss: 2.7817514476091465

Epoch: 6| Step: 6
Training loss: 3.1471330766060204
Validation loss: 2.775285391824353

Epoch: 6| Step: 7
Training loss: 2.7454008310748725
Validation loss: 2.7728231296970343

Epoch: 6| Step: 8
Training loss: 2.165264580750094
Validation loss: 2.773463014851861

Epoch: 6| Step: 9
Training loss: 3.061257246452032
Validation loss: 2.7762528042743257

Epoch: 6| Step: 10
Training loss: 3.0832105732442026
Validation loss: 2.779039792195078

Epoch: 6| Step: 11
Training loss: 3.0361650084232945
Validation loss: 2.7921232848902546

Epoch: 6| Step: 12
Training loss: 3.085448098306985
Validation loss: 2.8034435123862047

Epoch: 6| Step: 13
Training loss: 2.332753745257039
Validation loss: 2.8100673386705255

Epoch: 33| Step: 0
Training loss: 3.4683169532791145
Validation loss: 2.8234922783860585

Epoch: 6| Step: 1
Training loss: 3.2833772575680573
Validation loss: 2.8362480175954117

Epoch: 6| Step: 2
Training loss: 2.705361471932566
Validation loss: 2.847747621665927

Epoch: 6| Step: 3
Training loss: 3.836931833957635
Validation loss: 2.8531671948788984

Epoch: 6| Step: 4
Training loss: 2.602603829957458
Validation loss: 2.854056479639485

Epoch: 6| Step: 5
Training loss: 3.1402493532148386
Validation loss: 2.843937055098747

Epoch: 6| Step: 6
Training loss: 2.9243206050254753
Validation loss: 2.8298443793734878

Epoch: 6| Step: 7
Training loss: 3.1418026666185894
Validation loss: 2.8242536485427983

Epoch: 6| Step: 8
Training loss: 3.5714976140569314
Validation loss: 2.820293958326487

Epoch: 6| Step: 9
Training loss: 2.5956736405809924
Validation loss: 2.8103797130486954

Epoch: 6| Step: 10
Training loss: 3.1871062390825973
Validation loss: 2.8072204714753055

Epoch: 6| Step: 11
Training loss: 3.203925353753473
Validation loss: 2.7909547265000834

Epoch: 6| Step: 12
Training loss: 3.2368227040334157
Validation loss: 2.7868279306373855

Epoch: 6| Step: 13
Training loss: 2.176697680129221
Validation loss: 2.7801955914649827

Epoch: 34| Step: 0
Training loss: 2.543151848877006
Validation loss: 2.772720492420569

Epoch: 6| Step: 1
Training loss: 4.103401280534454
Validation loss: 2.7647281372309345

Epoch: 6| Step: 2
Training loss: 2.8015684673460655
Validation loss: 2.761166828466231

Epoch: 6| Step: 3
Training loss: 3.2705942702348705
Validation loss: 2.7598091935273015

Epoch: 6| Step: 4
Training loss: 2.604090656442793
Validation loss: 2.75591594111557

Epoch: 6| Step: 5
Training loss: 3.542048459885225
Validation loss: 2.754375026010429

Epoch: 6| Step: 6
Training loss: 2.9132962689635318
Validation loss: 2.756798723655683

Epoch: 6| Step: 7
Training loss: 3.1014087552416956
Validation loss: 2.755013779307463

Epoch: 6| Step: 8
Training loss: 2.87591554742153
Validation loss: 2.756507108853785

Epoch: 6| Step: 9
Training loss: 3.3770122886933414
Validation loss: 2.7615959399047743

Epoch: 6| Step: 10
Training loss: 2.600984893004043
Validation loss: 2.7698093594428563

Epoch: 6| Step: 11
Training loss: 3.2829681257919363
Validation loss: 2.784130269263467

Epoch: 6| Step: 12
Training loss: 3.0573253900508224
Validation loss: 2.779475456324744

Epoch: 6| Step: 13
Training loss: 2.428848563337766
Validation loss: 2.7620437968489213

Epoch: 35| Step: 0
Training loss: 3.2040466471311224
Validation loss: 2.757461495302497

Epoch: 6| Step: 1
Training loss: 3.1820014950348936
Validation loss: 2.7525029002517822

Epoch: 6| Step: 2
Training loss: 3.209999411514561
Validation loss: 2.7494927644215146

Epoch: 6| Step: 3
Training loss: 2.7894291997315404
Validation loss: 2.7514440990211586

Epoch: 6| Step: 4
Training loss: 2.2447426090647737
Validation loss: 2.753002448112547

Epoch: 6| Step: 5
Training loss: 3.1390546981843688
Validation loss: 2.752062403599999

Epoch: 6| Step: 6
Training loss: 3.4949103542285944
Validation loss: 2.747780939329714

Epoch: 6| Step: 7
Training loss: 3.134245661218687
Validation loss: 2.7432844418956237

Epoch: 6| Step: 8
Training loss: 2.927964988415789
Validation loss: 2.748431518222084

Epoch: 6| Step: 9
Training loss: 3.4899545652388717
Validation loss: 2.7507385602691294

Epoch: 6| Step: 10
Training loss: 2.891265963037395
Validation loss: 2.7527515930979214

Epoch: 6| Step: 11
Training loss: 2.6449500784823092
Validation loss: 2.75858395444809

Epoch: 6| Step: 12
Training loss: 3.244928070352669
Validation loss: 2.7582611850301655

Epoch: 6| Step: 13
Training loss: 3.3755382532487332
Validation loss: 2.762628955918682

Epoch: 36| Step: 0
Training loss: 3.3161434073918867
Validation loss: 2.7663155091087464

Epoch: 6| Step: 1
Training loss: 2.6220339412049123
Validation loss: 2.7632750519023506

Epoch: 6| Step: 2
Training loss: 3.514860892439512
Validation loss: 2.7572267129771477

Epoch: 6| Step: 3
Training loss: 2.607987086152945
Validation loss: 2.7497972989818376

Epoch: 6| Step: 4
Training loss: 3.274843337410588
Validation loss: 2.7441944553638153

Epoch: 6| Step: 5
Training loss: 2.5573858074152107
Validation loss: 2.7489663369381905

Epoch: 6| Step: 6
Training loss: 3.271982238236324
Validation loss: 2.752265395145588

Epoch: 6| Step: 7
Training loss: 3.2318589011259617
Validation loss: 2.746633290385627

Epoch: 6| Step: 8
Training loss: 2.543245877636728
Validation loss: 2.7365412256300914

Epoch: 6| Step: 9
Training loss: 2.9281060184608547
Validation loss: 2.7336875095799815

Epoch: 6| Step: 10
Training loss: 3.0269017444463286
Validation loss: 2.7321131347971033

Epoch: 6| Step: 11
Training loss: 3.080236804578153
Validation loss: 2.744650922359029

Epoch: 6| Step: 12
Training loss: 3.3643146482408812
Validation loss: 2.74305412472785

Epoch: 6| Step: 13
Training loss: 3.489962763109461
Validation loss: 2.7500260436688357

Epoch: 37| Step: 0
Training loss: 3.2170138815692084
Validation loss: 2.745156939222691

Epoch: 6| Step: 1
Training loss: 2.53468974425064
Validation loss: 2.7360433422231627

Epoch: 6| Step: 2
Training loss: 3.3453891337355244
Validation loss: 2.74006957292384

Epoch: 6| Step: 3
Training loss: 3.246595213127943
Validation loss: 2.740650360517288

Epoch: 6| Step: 4
Training loss: 2.840401658950276
Validation loss: 2.7448100172520142

Epoch: 6| Step: 5
Training loss: 3.596133561196778
Validation loss: 2.7448301018211407

Epoch: 6| Step: 6
Training loss: 3.400033299900118
Validation loss: 2.7419925752821097

Epoch: 6| Step: 7
Training loss: 3.021992340492221
Validation loss: 2.734384930617528

Epoch: 6| Step: 8
Training loss: 2.4602144662674714
Validation loss: 2.7287500065448818

Epoch: 6| Step: 9
Training loss: 2.7908157266369176
Validation loss: 2.722745832855404

Epoch: 6| Step: 10
Training loss: 2.6041346026671883
Validation loss: 2.7191395756868433

Epoch: 6| Step: 11
Training loss: 3.3363898727693195
Validation loss: 2.720336857371357

Epoch: 6| Step: 12
Training loss: 2.876761353025861
Validation loss: 2.7258364851497774

Epoch: 6| Step: 13
Training loss: 3.7196970783486245
Validation loss: 2.7424652358157937

Epoch: 38| Step: 0
Training loss: 2.773629711099157
Validation loss: 2.741812757837576

Epoch: 6| Step: 1
Training loss: 2.834657154107962
Validation loss: 2.739846546809305

Epoch: 6| Step: 2
Training loss: 2.8404600794289627
Validation loss: 2.752698795268623

Epoch: 6| Step: 3
Training loss: 2.7419835202245664
Validation loss: 2.739958201079758

Epoch: 6| Step: 4
Training loss: 2.932320919308785
Validation loss: 2.718206833935155

Epoch: 6| Step: 5
Training loss: 3.5220795782696426
Validation loss: 2.710628681892482

Epoch: 6| Step: 6
Training loss: 3.126607862731577
Validation loss: 2.710280664102718

Epoch: 6| Step: 7
Training loss: 3.2298457918469308
Validation loss: 2.710050516212064

Epoch: 6| Step: 8
Training loss: 3.0728935283932017
Validation loss: 2.7113672265596374

Epoch: 6| Step: 9
Training loss: 3.0357412513368724
Validation loss: 2.710484510974411

Epoch: 6| Step: 10
Training loss: 3.536771255753946
Validation loss: 2.710760742696731

Epoch: 6| Step: 11
Training loss: 3.020740656691705
Validation loss: 2.7135645328670197

Epoch: 6| Step: 12
Training loss: 2.5680676892946797
Validation loss: 2.7197377701062244

Epoch: 6| Step: 13
Training loss: 3.4009320103647376
Validation loss: 2.7212254663317195

Epoch: 39| Step: 0
Training loss: 3.2805298514511656
Validation loss: 2.7197940751391125

Epoch: 6| Step: 1
Training loss: 3.1669982100813843
Validation loss: 2.7104141067230856

Epoch: 6| Step: 2
Training loss: 3.241059403470373
Validation loss: 2.7073714227474026

Epoch: 6| Step: 3
Training loss: 3.1945323784561013
Validation loss: 2.7055219703801514

Epoch: 6| Step: 4
Training loss: 3.0607596921660605
Validation loss: 2.7053456931521147

Epoch: 6| Step: 5
Training loss: 2.420410205501689
Validation loss: 2.703467432805008

Epoch: 6| Step: 6
Training loss: 2.5907078562924215
Validation loss: 2.7011829621835735

Epoch: 6| Step: 7
Training loss: 2.5459245651888587
Validation loss: 2.701368702280926

Epoch: 6| Step: 8
Training loss: 2.944180622717392
Validation loss: 2.697042574869047

Epoch: 6| Step: 9
Training loss: 3.448715778110524
Validation loss: 2.7003967270562113

Epoch: 6| Step: 10
Training loss: 2.9499612644044695
Validation loss: 2.700409031644734

Epoch: 6| Step: 11
Training loss: 3.091788700982167
Validation loss: 2.701971937335554

Epoch: 6| Step: 12
Training loss: 3.5191499797820773
Validation loss: 2.70619724903097

Epoch: 6| Step: 13
Training loss: 2.850947734459392
Validation loss: 2.719690050268235

Epoch: 40| Step: 0
Training loss: 2.484539098538304
Validation loss: 2.718300910193454

Epoch: 6| Step: 1
Training loss: 3.1228470061415257
Validation loss: 2.7317121524401493

Epoch: 6| Step: 2
Training loss: 3.357295044461235
Validation loss: 2.7420595995422805

Epoch: 6| Step: 3
Training loss: 2.71491505920287
Validation loss: 2.718885973513491

Epoch: 6| Step: 4
Training loss: 2.705633862419885
Validation loss: 2.709104223476459

Epoch: 6| Step: 5
Training loss: 2.5512978000078608
Validation loss: 2.706051633170717

Epoch: 6| Step: 6
Training loss: 3.2091187015403735
Validation loss: 2.6974205244740066

Epoch: 6| Step: 7
Training loss: 1.9239917666165889
Validation loss: 2.6941757128044457

Epoch: 6| Step: 8
Training loss: 3.560704899983376
Validation loss: 2.6915803722569924

Epoch: 6| Step: 9
Training loss: 3.197581784154617
Validation loss: 2.6922651772656407

Epoch: 6| Step: 10
Training loss: 3.9099055161243386
Validation loss: 2.690373261518484

Epoch: 6| Step: 11
Training loss: 2.434545242174367
Validation loss: 2.6873372403783087

Epoch: 6| Step: 12
Training loss: 3.5172603618272076
Validation loss: 2.697283120994212

Epoch: 6| Step: 13
Training loss: 3.2055883844091384
Validation loss: 2.698456971471237

Epoch: 41| Step: 0
Training loss: 2.856399906156202
Validation loss: 2.6943307023827736

Epoch: 6| Step: 1
Training loss: 3.0021934437903877
Validation loss: 2.7008991057018594

Epoch: 6| Step: 2
Training loss: 3.330300063626992
Validation loss: 2.7023613570864105

Epoch: 6| Step: 3
Training loss: 2.7364569013572715
Validation loss: 2.721678186057961

Epoch: 6| Step: 4
Training loss: 3.524303253791112
Validation loss: 2.7319031533614586

Epoch: 6| Step: 5
Training loss: 3.4818564580157627
Validation loss: 2.7170540028513743

Epoch: 6| Step: 6
Training loss: 3.000208688471094
Validation loss: 2.69135360515072

Epoch: 6| Step: 7
Training loss: 2.778968303717919
Validation loss: 2.6928867737876567

Epoch: 6| Step: 8
Training loss: 2.5374534790585286
Validation loss: 2.68865753375625

Epoch: 6| Step: 9
Training loss: 3.003834975330868
Validation loss: 2.683261770857052

Epoch: 6| Step: 10
Training loss: 3.208641995201263
Validation loss: 2.6823017015437696

Epoch: 6| Step: 11
Training loss: 3.3962346095360156
Validation loss: 2.6846728830837003

Epoch: 6| Step: 12
Training loss: 2.148719907752957
Validation loss: 2.6856198708615664

Epoch: 6| Step: 13
Training loss: 3.045374104486885
Validation loss: 2.681687687367804

Epoch: 42| Step: 0
Training loss: 2.6440133470899583
Validation loss: 2.6836514199653636

Epoch: 6| Step: 1
Training loss: 3.037818791493122
Validation loss: 2.6801722052991326

Epoch: 6| Step: 2
Training loss: 2.624441087348995
Validation loss: 2.682411130177663

Epoch: 6| Step: 3
Training loss: 2.2987145563559612
Validation loss: 2.6821702199494792

Epoch: 6| Step: 4
Training loss: 2.5955995147210813
Validation loss: 2.6933778158379

Epoch: 6| Step: 5
Training loss: 3.6559530284293236
Validation loss: 2.701897244588075

Epoch: 6| Step: 6
Training loss: 3.0845616617505964
Validation loss: 2.6936170912522996

Epoch: 6| Step: 7
Training loss: 2.9509472764675433
Validation loss: 2.6796337744031207

Epoch: 6| Step: 8
Training loss: 3.5320965587684414
Validation loss: 2.675719254118855

Epoch: 6| Step: 9
Training loss: 3.414778505573453
Validation loss: 2.6777692219159483

Epoch: 6| Step: 10
Training loss: 2.8506894800161255
Validation loss: 2.677599131392072

Epoch: 6| Step: 11
Training loss: 3.0382267212137197
Validation loss: 2.6795599457524353

Epoch: 6| Step: 12
Training loss: 3.1940239357717273
Validation loss: 2.680555776196894

Epoch: 6| Step: 13
Training loss: 3.2932694955062116
Validation loss: 2.6802673085683506

Epoch: 43| Step: 0
Training loss: 2.6984825179117053
Validation loss: 2.7084823961783644

Epoch: 6| Step: 1
Training loss: 2.5314255641758243
Validation loss: 2.7377364004066784

Epoch: 6| Step: 2
Training loss: 3.368915158896014
Validation loss: 2.7352178649835492

Epoch: 6| Step: 3
Training loss: 2.928881562323018
Validation loss: 2.6783048048010527

Epoch: 6| Step: 4
Training loss: 2.6046405717069643
Validation loss: 2.6840990644627243

Epoch: 6| Step: 5
Training loss: 2.971406731682469
Validation loss: 2.77772216009703

Epoch: 6| Step: 6
Training loss: 3.2644696541870184
Validation loss: 2.9170767400623103

Epoch: 6| Step: 7
Training loss: 3.1446040364246874
Validation loss: 2.9335705673328376

Epoch: 6| Step: 8
Training loss: 3.6176388419818286
Validation loss: 2.9317471889690485

Epoch: 6| Step: 9
Training loss: 3.1244814633268114
Validation loss: 2.8080348822942476

Epoch: 6| Step: 10
Training loss: 2.722916841008347
Validation loss: 2.7513657680789123

Epoch: 6| Step: 11
Training loss: 3.189602326864595
Validation loss: 2.7005239208152085

Epoch: 6| Step: 12
Training loss: 3.5978420677616834
Validation loss: 2.6748645701802896

Epoch: 6| Step: 13
Training loss: 3.0609812181825626
Validation loss: 2.6720674439828818

Epoch: 44| Step: 0
Training loss: 2.783364681440457
Validation loss: 2.687965586445601

Epoch: 6| Step: 1
Training loss: 2.1700331747797716
Validation loss: 2.739963916956847

Epoch: 6| Step: 2
Training loss: 3.1480906558137236
Validation loss: 2.742452266450197

Epoch: 6| Step: 3
Training loss: 3.513767141478805
Validation loss: 2.7685733627063045

Epoch: 6| Step: 4
Training loss: 3.3776198214969866
Validation loss: 2.6939511540206453

Epoch: 6| Step: 5
Training loss: 2.862824907145844
Validation loss: 2.6847834554577625

Epoch: 6| Step: 6
Training loss: 3.3532192874674553
Validation loss: 2.6926257100437505

Epoch: 6| Step: 7
Training loss: 2.7848984009104454
Validation loss: 2.700344839448849

Epoch: 6| Step: 8
Training loss: 3.0748037632299474
Validation loss: 2.690636973453076

Epoch: 6| Step: 9
Training loss: 3.1968232479735534
Validation loss: 2.685572733257719

Epoch: 6| Step: 10
Training loss: 2.7626093570933805
Validation loss: 2.699502334928518

Epoch: 6| Step: 11
Training loss: 3.0815955411282583
Validation loss: 2.709742781514391

Epoch: 6| Step: 12
Training loss: 3.46059965460936
Validation loss: 2.716482429238756

Epoch: 6| Step: 13
Training loss: 2.542675558084999
Validation loss: 2.70413853170434

Epoch: 45| Step: 0
Training loss: 1.8717079508376193
Validation loss: 2.6898588201224634

Epoch: 6| Step: 1
Training loss: 3.1253460501758217
Validation loss: 2.693595392772352

Epoch: 6| Step: 2
Training loss: 3.0750416450471714
Validation loss: 2.6845435316419035

Epoch: 6| Step: 3
Training loss: 2.7600606340852196
Validation loss: 2.6769550634788257

Epoch: 6| Step: 4
Training loss: 3.1501775055781205
Validation loss: 2.6723169693930897

Epoch: 6| Step: 5
Training loss: 3.284699434322771
Validation loss: 2.6715775593924525

Epoch: 6| Step: 6
Training loss: 3.5338966106582372
Validation loss: 2.672769738875391

Epoch: 6| Step: 7
Training loss: 3.507599890028136
Validation loss: 2.6722496608148374

Epoch: 6| Step: 8
Training loss: 2.8815551331445253
Validation loss: 2.6703395090634707

Epoch: 6| Step: 9
Training loss: 3.135441996492153
Validation loss: 2.668476545327828

Epoch: 6| Step: 10
Training loss: 2.62032947113965
Validation loss: 2.664099262683852

Epoch: 6| Step: 11
Training loss: 2.9625241499934534
Validation loss: 2.6646048018205533

Epoch: 6| Step: 12
Training loss: 3.1897389645338117
Validation loss: 2.6640761733565035

Epoch: 6| Step: 13
Training loss: 2.768375042396931
Validation loss: 2.6627951440753717

Epoch: 46| Step: 0
Training loss: 3.341236346181593
Validation loss: 2.6633347960355187

Epoch: 6| Step: 1
Training loss: 2.8059872136766146
Validation loss: 2.661288084972009

Epoch: 6| Step: 2
Training loss: 2.936570690144014
Validation loss: 2.6647575505485044

Epoch: 6| Step: 3
Training loss: 2.8154931989129364
Validation loss: 2.663892641980572

Epoch: 6| Step: 4
Training loss: 3.45241446110792
Validation loss: 2.668621269484063

Epoch: 6| Step: 5
Training loss: 2.857254659645072
Validation loss: 2.7002954430012838

Epoch: 6| Step: 6
Training loss: 3.084644829137356
Validation loss: 2.6924966502137617

Epoch: 6| Step: 7
Training loss: 3.297969401442585
Validation loss: 2.6594583417630564

Epoch: 6| Step: 8
Training loss: 3.1780422743811805
Validation loss: 2.6539185920476234

Epoch: 6| Step: 9
Training loss: 3.0887081793960824
Validation loss: 2.6553603562688157

Epoch: 6| Step: 10
Training loss: 2.255302010250553
Validation loss: 2.655376880042267

Epoch: 6| Step: 11
Training loss: 3.083340636236117
Validation loss: 2.661618207556564

Epoch: 6| Step: 12
Training loss: 2.4640452305122675
Validation loss: 2.6723961179524887

Epoch: 6| Step: 13
Training loss: 3.379237023188329
Validation loss: 2.674961218266724

Epoch: 47| Step: 0
Training loss: 2.512451634487161
Validation loss: 2.66770110588544

Epoch: 6| Step: 1
Training loss: 2.850456127675573
Validation loss: 2.665031835342064

Epoch: 6| Step: 2
Training loss: 3.129323333868373
Validation loss: 2.6611602643905643

Epoch: 6| Step: 3
Training loss: 2.8999223632943636
Validation loss: 2.6583297029199717

Epoch: 6| Step: 4
Training loss: 2.9685879311744743
Validation loss: 2.6583667406494307

Epoch: 6| Step: 5
Training loss: 3.1188287453657857
Validation loss: 2.660898136216296

Epoch: 6| Step: 6
Training loss: 2.8777704573464127
Validation loss: 2.661705976681579

Epoch: 6| Step: 7
Training loss: 3.1819250683356657
Validation loss: 2.6664548284722747

Epoch: 6| Step: 8
Training loss: 3.051868279250676
Validation loss: 2.6528782996138993

Epoch: 6| Step: 9
Training loss: 3.4045328834302526
Validation loss: 2.6511068914901035

Epoch: 6| Step: 10
Training loss: 2.3976399341275463
Validation loss: 2.646097055911462

Epoch: 6| Step: 11
Training loss: 3.242217943898859
Validation loss: 2.6464884173681704

Epoch: 6| Step: 12
Training loss: 3.112576164324842
Validation loss: 2.6447981399234424

Epoch: 6| Step: 13
Training loss: 3.3360391284193915
Validation loss: 2.6485253245463314

Epoch: 48| Step: 0
Training loss: 3.121780873694414
Validation loss: 2.645175447677465

Epoch: 6| Step: 1
Training loss: 3.5856353698974153
Validation loss: 2.645069213190513

Epoch: 6| Step: 2
Training loss: 3.3493269286894254
Validation loss: 2.643813006151781

Epoch: 6| Step: 3
Training loss: 2.867765196931479
Validation loss: 2.6410450866679818

Epoch: 6| Step: 4
Training loss: 2.723629223481635
Validation loss: 2.6413984666487837

Epoch: 6| Step: 5
Training loss: 3.0536494137550343
Validation loss: 2.6429536341338338

Epoch: 6| Step: 6
Training loss: 2.7858495504774674
Validation loss: 2.643198091542617

Epoch: 6| Step: 7
Training loss: 2.5375751540606837
Validation loss: 2.652302828573105

Epoch: 6| Step: 8
Training loss: 3.6018365519886117
Validation loss: 2.656955802325753

Epoch: 6| Step: 9
Training loss: 2.0956769587864392
Validation loss: 2.643477913555194

Epoch: 6| Step: 10
Training loss: 2.8413233201870685
Validation loss: 2.6395991979016498

Epoch: 6| Step: 11
Training loss: 2.7458463858572535
Validation loss: 2.633678187942516

Epoch: 6| Step: 12
Training loss: 3.2850450639812685
Validation loss: 2.6351427017478044

Epoch: 6| Step: 13
Training loss: 2.9348673284591142
Validation loss: 2.63449365503869

Epoch: 49| Step: 0
Training loss: 2.9288205097354583
Validation loss: 2.635688207112387

Epoch: 6| Step: 1
Training loss: 3.426269357286318
Validation loss: 2.6354108936253553

Epoch: 6| Step: 2
Training loss: 2.8344472116778916
Validation loss: 2.6388824493755645

Epoch: 6| Step: 3
Training loss: 2.7650810611976455
Validation loss: 2.648042257852491

Epoch: 6| Step: 4
Training loss: 3.0819297551412492
Validation loss: 2.6561157395309856

Epoch: 6| Step: 5
Training loss: 2.4585786686262896
Validation loss: 2.6618418525078282

Epoch: 6| Step: 6
Training loss: 2.5845091410169165
Validation loss: 2.6680574526834713

Epoch: 6| Step: 7
Training loss: 2.6769389745677
Validation loss: 2.6576226545268566

Epoch: 6| Step: 8
Training loss: 3.7432359090906835
Validation loss: 2.659877981851451

Epoch: 6| Step: 9
Training loss: 3.0709729442839326
Validation loss: 2.64978661276864

Epoch: 6| Step: 10
Training loss: 3.3339719319572283
Validation loss: 2.647503691274302

Epoch: 6| Step: 11
Training loss: 2.3608728163900903
Validation loss: 2.634352335874163

Epoch: 6| Step: 12
Training loss: 3.4574033720094373
Validation loss: 2.6293669597726343

Epoch: 6| Step: 13
Training loss: 2.4821421828077916
Validation loss: 2.6262923642067126

Epoch: 50| Step: 0
Training loss: 2.9465190328607656
Validation loss: 2.6247024543290216

Epoch: 6| Step: 1
Training loss: 3.140844384876813
Validation loss: 2.62340488497726

Epoch: 6| Step: 2
Training loss: 3.132290994136439
Validation loss: 2.6254649758843374

Epoch: 6| Step: 3
Training loss: 2.076497982679086
Validation loss: 2.6264544401773438

Epoch: 6| Step: 4
Training loss: 3.0527588983040106
Validation loss: 2.6214738231020576

Epoch: 6| Step: 5
Training loss: 2.701864488886997
Validation loss: 2.6240492679709426

Epoch: 6| Step: 6
Training loss: 3.0131607660601225
Validation loss: 2.6301069706542335

Epoch: 6| Step: 7
Training loss: 3.244705876685326
Validation loss: 2.633552316602969

Epoch: 6| Step: 8
Training loss: 3.2667412561218008
Validation loss: 2.6480938052613987

Epoch: 6| Step: 9
Training loss: 3.324342682766164
Validation loss: 2.642821319230543

Epoch: 6| Step: 10
Training loss: 2.673450028051812
Validation loss: 2.6364950168839356

Epoch: 6| Step: 11
Training loss: 3.0147196146845188
Validation loss: 2.63158516112675

Epoch: 6| Step: 12
Training loss: 2.4108636396050134
Validation loss: 2.6330341703323348

Epoch: 6| Step: 13
Training loss: 3.60352938683009
Validation loss: 2.6260619547322355

Epoch: 51| Step: 0
Training loss: 3.0739307002022667
Validation loss: 2.6193430546298933

Epoch: 6| Step: 1
Training loss: 3.371861446660956
Validation loss: 2.628932954025147

Epoch: 6| Step: 2
Training loss: 3.1340296181336367
Validation loss: 2.630357454244161

Epoch: 6| Step: 3
Training loss: 3.0811653419610496
Validation loss: 2.622693618535124

Epoch: 6| Step: 4
Training loss: 2.9840138801067804
Validation loss: 2.6259495267424846

Epoch: 6| Step: 5
Training loss: 3.108166483746653
Validation loss: 2.626880758172928

Epoch: 6| Step: 6
Training loss: 2.90020747264733
Validation loss: 2.632182493357587

Epoch: 6| Step: 7
Training loss: 2.7906894586686137
Validation loss: 2.653698955098657

Epoch: 6| Step: 8
Training loss: 3.423241608036837
Validation loss: 2.6420438036946914

Epoch: 6| Step: 9
Training loss: 2.8230786060087567
Validation loss: 2.611149698781191

Epoch: 6| Step: 10
Training loss: 2.687350069343895
Validation loss: 2.6192306093587403

Epoch: 6| Step: 11
Training loss: 2.843951040015522
Validation loss: 2.627403114424419

Epoch: 6| Step: 12
Training loss: 2.252224775937165
Validation loss: 2.6336859956280376

Epoch: 6| Step: 13
Training loss: 3.2120257016361484
Validation loss: 2.6476803221544905

Epoch: 52| Step: 0
Training loss: 2.657913225834217
Validation loss: 2.64968558365762

Epoch: 6| Step: 1
Training loss: 2.735954569573259
Validation loss: 2.6518461083249862

Epoch: 6| Step: 2
Training loss: 3.180579807757256
Validation loss: 2.6388503978737954

Epoch: 6| Step: 3
Training loss: 2.872595735420366
Validation loss: 2.6331493432050292

Epoch: 6| Step: 4
Training loss: 2.745109110263597
Validation loss: 2.630281780480065

Epoch: 6| Step: 5
Training loss: 3.828814510607771
Validation loss: 2.6277010821016487

Epoch: 6| Step: 6
Training loss: 3.1993284474477512
Validation loss: 2.625000806692129

Epoch: 6| Step: 7
Training loss: 3.0740265646824745
Validation loss: 2.620294794692557

Epoch: 6| Step: 8
Training loss: 3.1302825529637355
Validation loss: 2.6180860161982453

Epoch: 6| Step: 9
Training loss: 3.1593220179008292
Validation loss: 2.6167924117795134

Epoch: 6| Step: 10
Training loss: 2.37612486853472
Validation loss: 2.6207835686328793

Epoch: 6| Step: 11
Training loss: 2.772246542955366
Validation loss: 2.626442459692762

Epoch: 6| Step: 12
Training loss: 3.0001033129386836
Validation loss: 2.655060960316114

Epoch: 6| Step: 13
Training loss: 2.695163092411301
Validation loss: 2.641991661806512

Epoch: 53| Step: 0
Training loss: 2.877661758237792
Validation loss: 2.651655348571361

Epoch: 6| Step: 1
Training loss: 3.4207180627939087
Validation loss: 2.6509530070971956

Epoch: 6| Step: 2
Training loss: 2.8469558922071223
Validation loss: 2.662496667929469

Epoch: 6| Step: 3
Training loss: 2.3739742272383237
Validation loss: 2.6673528771511776

Epoch: 6| Step: 4
Training loss: 3.3371471204189236
Validation loss: 2.6578851964053523

Epoch: 6| Step: 5
Training loss: 2.8079018198113173
Validation loss: 2.621284017892804

Epoch: 6| Step: 6
Training loss: 3.16853434714816
Validation loss: 2.617115014483146

Epoch: 6| Step: 7
Training loss: 2.9856360202942875
Validation loss: 2.614884720025966

Epoch: 6| Step: 8
Training loss: 3.1053864474156785
Validation loss: 2.6141117835734917

Epoch: 6| Step: 9
Training loss: 3.0536733051027043
Validation loss: 2.6153480556357924

Epoch: 6| Step: 10
Training loss: 3.194388929981183
Validation loss: 2.6138218982418877

Epoch: 6| Step: 11
Training loss: 3.1495336702094034
Validation loss: 2.612926650698731

Epoch: 6| Step: 12
Training loss: 2.6434862334425246
Validation loss: 2.629650395413909

Epoch: 6| Step: 13
Training loss: 2.329836632236294
Validation loss: 2.616961524989668

Epoch: 54| Step: 0
Training loss: 2.4488688679888475
Validation loss: 2.613900482805989

Epoch: 6| Step: 1
Training loss: 1.9963840340731227
Validation loss: 2.607223240536458

Epoch: 6| Step: 2
Training loss: 3.3635860575257825
Validation loss: 2.6107086404771134

Epoch: 6| Step: 3
Training loss: 3.271406540585285
Validation loss: 2.607588258149282

Epoch: 6| Step: 4
Training loss: 2.9919446244036747
Validation loss: 2.6140870052714753

Epoch: 6| Step: 5
Training loss: 3.3163852578656883
Validation loss: 2.6175813278518816

Epoch: 6| Step: 6
Training loss: 2.927091460482536
Validation loss: 2.6129800897750215

Epoch: 6| Step: 7
Training loss: 2.5826016487139363
Validation loss: 2.6074687490674

Epoch: 6| Step: 8
Training loss: 3.2841359843676328
Validation loss: 2.6056628497393937

Epoch: 6| Step: 9
Training loss: 3.012773816339423
Validation loss: 2.6035583727431497

Epoch: 6| Step: 10
Training loss: 2.995921541559243
Validation loss: 2.606661917728269

Epoch: 6| Step: 11
Training loss: 3.0115138675649713
Validation loss: 2.6062054433333977

Epoch: 6| Step: 12
Training loss: 2.5558410280068506
Validation loss: 2.607599061921118

Epoch: 6| Step: 13
Training loss: 3.657969665409909
Validation loss: 2.6002469187722768

Epoch: 55| Step: 0
Training loss: 2.5074439802976767
Validation loss: 2.605638010769925

Epoch: 6| Step: 1
Training loss: 3.1542397319707907
Validation loss: 2.598830151346392

Epoch: 6| Step: 2
Training loss: 3.0063139910638426
Validation loss: 2.5917362224244176

Epoch: 6| Step: 3
Training loss: 2.2138219558678864
Validation loss: 2.594692891562435

Epoch: 6| Step: 4
Training loss: 3.1106181511047644
Validation loss: 2.599354250783955

Epoch: 6| Step: 5
Training loss: 2.741861612023354
Validation loss: 2.604089866900349

Epoch: 6| Step: 6
Training loss: 2.757110246935607
Validation loss: 2.6084792041480283

Epoch: 6| Step: 7
Training loss: 3.3568534436454414
Validation loss: 2.6122636845073064

Epoch: 6| Step: 8
Training loss: 2.4859372391331966
Validation loss: 2.6166436164247755

Epoch: 6| Step: 9
Training loss: 3.312340498628941
Validation loss: 2.622827992729037

Epoch: 6| Step: 10
Training loss: 2.764953014395356
Validation loss: 2.612634137578237

Epoch: 6| Step: 11
Training loss: 3.2069097721264406
Validation loss: 2.6086872745135365

Epoch: 6| Step: 12
Training loss: 3.568170150976318
Validation loss: 2.604434738307803

Epoch: 6| Step: 13
Training loss: 3.2854343437214353
Validation loss: 2.600797756174491

Epoch: 56| Step: 0
Training loss: 3.6277040064815895
Validation loss: 2.596666671215006

Epoch: 6| Step: 1
Training loss: 3.2487171282101457
Validation loss: 2.594329507322539

Epoch: 6| Step: 2
Training loss: 2.2513640825255656
Validation loss: 2.597682061392122

Epoch: 6| Step: 3
Training loss: 3.2102725786125546
Validation loss: 2.5995909844594993

Epoch: 6| Step: 4
Training loss: 3.1310715249492698
Validation loss: 2.609285470606691

Epoch: 6| Step: 5
Training loss: 3.2428445540916626
Validation loss: 2.613797618386122

Epoch: 6| Step: 6
Training loss: 2.556796728487273
Validation loss: 2.6114039219447434

Epoch: 6| Step: 7
Training loss: 3.001160873875532
Validation loss: 2.6160691902659567

Epoch: 6| Step: 8
Training loss: 2.5765328779767525
Validation loss: 2.6188955381445584

Epoch: 6| Step: 9
Training loss: 2.7709834027104754
Validation loss: 2.608392386141636

Epoch: 6| Step: 10
Training loss: 3.0650470029329058
Validation loss: 2.592568892753781

Epoch: 6| Step: 11
Training loss: 2.4141338053915886
Validation loss: 2.5906382552041256

Epoch: 6| Step: 12
Training loss: 3.0502261781471227
Validation loss: 2.588465719065623

Epoch: 6| Step: 13
Training loss: 3.092048254053534
Validation loss: 2.5880457192411357

Epoch: 57| Step: 0
Training loss: 3.0974810672209108
Validation loss: 2.5881846825858226

Epoch: 6| Step: 1
Training loss: 3.5542567400831175
Validation loss: 2.5917937048158928

Epoch: 6| Step: 2
Training loss: 2.4996971900657696
Validation loss: 2.596402983602987

Epoch: 6| Step: 3
Training loss: 1.948323688379872
Validation loss: 2.610379606372009

Epoch: 6| Step: 4
Training loss: 3.150621589003466
Validation loss: 2.6449178911465525

Epoch: 6| Step: 5
Training loss: 3.2516582366766302
Validation loss: 2.6706079840604517

Epoch: 6| Step: 6
Training loss: 2.939294469867016
Validation loss: 2.6394139956036518

Epoch: 6| Step: 7
Training loss: 2.7448527107954592
Validation loss: 2.61827263850968

Epoch: 6| Step: 8
Training loss: 3.4224843218648417
Validation loss: 2.591076463989057

Epoch: 6| Step: 9
Training loss: 2.361616976782144
Validation loss: 2.5841884673040414

Epoch: 6| Step: 10
Training loss: 3.061998287287656
Validation loss: 2.5824487847577964

Epoch: 6| Step: 11
Training loss: 3.0223910470009026
Validation loss: 2.580933717360252

Epoch: 6| Step: 12
Training loss: 3.131379444241135
Validation loss: 2.5874324262467807

Epoch: 6| Step: 13
Training loss: 2.657250339411492
Validation loss: 2.591591781321973

Epoch: 58| Step: 0
Training loss: 2.4291722772532385
Validation loss: 2.5893881442867848

Epoch: 6| Step: 1
Training loss: 3.5180815527627622
Validation loss: 2.589499549981143

Epoch: 6| Step: 2
Training loss: 2.767714147785374
Validation loss: 2.5852914048961257

Epoch: 6| Step: 3
Training loss: 3.043531569019959
Validation loss: 2.5833485924081225

Epoch: 6| Step: 4
Training loss: 3.2659397977383433
Validation loss: 2.584325769139565

Epoch: 6| Step: 5
Training loss: 2.894706195687325
Validation loss: 2.588137953539307

Epoch: 6| Step: 6
Training loss: 2.8695703733847715
Validation loss: 2.5893326708253124

Epoch: 6| Step: 7
Training loss: 2.9188448447392905
Validation loss: 2.589818052526522

Epoch: 6| Step: 8
Training loss: 2.9462113766896043
Validation loss: 2.6143482561617897

Epoch: 6| Step: 9
Training loss: 2.695826119399012
Validation loss: 2.5924695349867277

Epoch: 6| Step: 10
Training loss: 2.8644494227696655
Validation loss: 2.5755720527982677

Epoch: 6| Step: 11
Training loss: 2.8977459599237463
Validation loss: 2.5757222832104474

Epoch: 6| Step: 12
Training loss: 3.106850677683569
Validation loss: 2.5708447934478946

Epoch: 6| Step: 13
Training loss: 2.9656616208676447
Validation loss: 2.574024744167634

Epoch: 59| Step: 0
Training loss: 3.4027756636909268
Validation loss: 2.6048003415522474

Epoch: 6| Step: 1
Training loss: 3.264778575077812
Validation loss: 2.6342431482209263

Epoch: 6| Step: 2
Training loss: 2.9826126087606464
Validation loss: 2.6781371557715334

Epoch: 6| Step: 3
Training loss: 2.571037955361164
Validation loss: 2.697690125554399

Epoch: 6| Step: 4
Training loss: 2.646108587970697
Validation loss: 2.7271440979131487

Epoch: 6| Step: 5
Training loss: 3.2053049996351417
Validation loss: 2.7301887149020403

Epoch: 6| Step: 6
Training loss: 2.8883370907673402
Validation loss: 2.630582049483864

Epoch: 6| Step: 7
Training loss: 3.003849103406354
Validation loss: 2.597669851492783

Epoch: 6| Step: 8
Training loss: 2.6229439812516353
Validation loss: 2.5717577224507187

Epoch: 6| Step: 9
Training loss: 2.961882669374929
Validation loss: 2.5756982692682806

Epoch: 6| Step: 10
Training loss: 2.2248458937522044
Validation loss: 2.575569084610765

Epoch: 6| Step: 11
Training loss: 3.2128903281724788
Validation loss: 2.57987353164291

Epoch: 6| Step: 12
Training loss: 3.000658122036604
Validation loss: 2.5800763781994984

Epoch: 6| Step: 13
Training loss: 3.0146789648093972
Validation loss: 2.5805870215598885

Epoch: 60| Step: 0
Training loss: 3.361914522045443
Validation loss: 2.5816151164155174

Epoch: 6| Step: 1
Training loss: 3.2103113459582517
Validation loss: 2.583345044678795

Epoch: 6| Step: 2
Training loss: 2.095555907355385
Validation loss: 2.585410181041876

Epoch: 6| Step: 3
Training loss: 3.2072246832366154
Validation loss: 2.5853833338780876

Epoch: 6| Step: 4
Training loss: 3.03673128675538
Validation loss: 2.5868785318110405

Epoch: 6| Step: 5
Training loss: 3.4349315411049512
Validation loss: 2.584405766420905

Epoch: 6| Step: 6
Training loss: 3.2038832348562227
Validation loss: 2.5844644147071345

Epoch: 6| Step: 7
Training loss: 3.1463164575383327
Validation loss: 2.5821626083184306

Epoch: 6| Step: 8
Training loss: 2.6470845685592006
Validation loss: 2.5804956479368752

Epoch: 6| Step: 9
Training loss: 2.7102591685560604
Validation loss: 2.5788292672106747

Epoch: 6| Step: 10
Training loss: 3.071342625476892
Validation loss: 2.5771058773955704

Epoch: 6| Step: 11
Training loss: 2.4035683092790614
Validation loss: 2.5792243739014604

Epoch: 6| Step: 12
Training loss: 2.983260181176585
Validation loss: 2.5788903973084127

Epoch: 6| Step: 13
Training loss: 2.4494579143658024
Validation loss: 2.5759597033288464

Epoch: 61| Step: 0
Training loss: 3.3629222505482375
Validation loss: 2.575638429018002

Epoch: 6| Step: 1
Training loss: 3.360909896446385
Validation loss: 2.5751557465239143

Epoch: 6| Step: 2
Training loss: 2.7255814763097224
Validation loss: 2.5746638199149863

Epoch: 6| Step: 3
Training loss: 2.9288358137035972
Validation loss: 2.572912093542873

Epoch: 6| Step: 4
Training loss: 2.891070687241654
Validation loss: 2.569305669563598

Epoch: 6| Step: 5
Training loss: 2.907921095290508
Validation loss: 2.570376758960969

Epoch: 6| Step: 6
Training loss: 2.0082832704796716
Validation loss: 2.568847501065192

Epoch: 6| Step: 7
Training loss: 2.550497182360291
Validation loss: 2.568944341548905

Epoch: 6| Step: 8
Training loss: 3.3202088104213874
Validation loss: 2.562842626548395

Epoch: 6| Step: 9
Training loss: 2.873084217816884
Validation loss: 2.5588376245014284

Epoch: 6| Step: 10
Training loss: 2.9596852898189208
Validation loss: 2.5667283123344533

Epoch: 6| Step: 11
Training loss: 3.2130310213435864
Validation loss: 2.573489154643165

Epoch: 6| Step: 12
Training loss: 2.889115717940843
Validation loss: 2.578807990180987

Epoch: 6| Step: 13
Training loss: 2.8239962963749967
Validation loss: 2.5889803306601045

Epoch: 62| Step: 0
Training loss: 2.9365982944295737
Validation loss: 2.624035632241708

Epoch: 6| Step: 1
Training loss: 2.725981467348439
Validation loss: 2.6791899375904507

Epoch: 6| Step: 2
Training loss: 3.1749323499786444
Validation loss: 2.758958781128571

Epoch: 6| Step: 3
Training loss: 2.609594735584527
Validation loss: 2.771603428159766

Epoch: 6| Step: 4
Training loss: 2.2101029077796523
Validation loss: 2.66341640321867

Epoch: 6| Step: 5
Training loss: 3.292189029499526
Validation loss: 2.6210045719950927

Epoch: 6| Step: 6
Training loss: 2.5722480141884807
Validation loss: 2.602306281939057

Epoch: 6| Step: 7
Training loss: 3.3085603138068462
Validation loss: 2.5872996866957623

Epoch: 6| Step: 8
Training loss: 2.2538798048031556
Validation loss: 2.5623215263796673

Epoch: 6| Step: 9
Training loss: 3.1055184990118927
Validation loss: 2.5597030688414892

Epoch: 6| Step: 10
Training loss: 3.0550265306984628
Validation loss: 2.555969709276543

Epoch: 6| Step: 11
Training loss: 3.115308764295991
Validation loss: 2.5589479047407937

Epoch: 6| Step: 12
Training loss: 3.1376641583906983
Validation loss: 2.5686536225098098

Epoch: 6| Step: 13
Training loss: 3.8651509789196785
Validation loss: 2.5664092697405736

Epoch: 63| Step: 0
Training loss: 2.4386859845118822
Validation loss: 2.569784191484563

Epoch: 6| Step: 1
Training loss: 3.407875862914272
Validation loss: 2.568050550833152

Epoch: 6| Step: 2
Training loss: 2.763551354897536
Validation loss: 2.564539866041889

Epoch: 6| Step: 3
Training loss: 3.164553154472282
Validation loss: 2.5626576522964695

Epoch: 6| Step: 4
Training loss: 2.745861928170581
Validation loss: 2.56301189465001

Epoch: 6| Step: 5
Training loss: 2.708588475656009
Validation loss: 2.560480175640607

Epoch: 6| Step: 6
Training loss: 2.372184087946577
Validation loss: 2.55940793354651

Epoch: 6| Step: 7
Training loss: 3.394173869996295
Validation loss: 2.558686992865955

Epoch: 6| Step: 8
Training loss: 2.4795721881786705
Validation loss: 2.5596943524389073

Epoch: 6| Step: 9
Training loss: 3.0920440902724793
Validation loss: 2.5706216926819008

Epoch: 6| Step: 10
Training loss: 2.8757761032112326
Validation loss: 2.574704996532401

Epoch: 6| Step: 11
Training loss: 3.145712304892386
Validation loss: 2.5756517844798847

Epoch: 6| Step: 12
Training loss: 3.354181293589921
Validation loss: 2.575560438824454

Epoch: 6| Step: 13
Training loss: 3.0764990835400794
Validation loss: 2.570492493249623

Epoch: 64| Step: 0
Training loss: 3.268742437700382
Validation loss: 2.5738704664323993

Epoch: 6| Step: 1
Training loss: 3.111049795303415
Validation loss: 2.5714488119224663

Epoch: 6| Step: 2
Training loss: 2.9398322079584247
Validation loss: 2.564664643238083

Epoch: 6| Step: 3
Training loss: 2.5931379216502703
Validation loss: 2.552911147432141

Epoch: 6| Step: 4
Training loss: 2.80476273034659
Validation loss: 2.5536764767924183

Epoch: 6| Step: 5
Training loss: 2.7745486330550237
Validation loss: 2.554403323806423

Epoch: 6| Step: 6
Training loss: 3.049170152930301
Validation loss: 2.556233044704064

Epoch: 6| Step: 7
Training loss: 2.6500918642351814
Validation loss: 2.5570679251307293

Epoch: 6| Step: 8
Training loss: 3.36938404917718
Validation loss: 2.5547260653938566

Epoch: 6| Step: 9
Training loss: 2.878119393507874
Validation loss: 2.5554538066829875

Epoch: 6| Step: 10
Training loss: 2.560416979953963
Validation loss: 2.5588633104957634

Epoch: 6| Step: 11
Training loss: 3.146675165644445
Validation loss: 2.5608878978590086

Epoch: 6| Step: 12
Training loss: 2.4924262718690646
Validation loss: 2.5768599373716405

Epoch: 6| Step: 13
Training loss: 3.21627697799523
Validation loss: 2.5992697298367347

Epoch: 65| Step: 0
Training loss: 2.8824360092484462
Validation loss: 2.6128662835470418

Epoch: 6| Step: 1
Training loss: 3.0354666729126314
Validation loss: 2.6237583612781123

Epoch: 6| Step: 2
Training loss: 2.709110578857756
Validation loss: 2.6257460071758443

Epoch: 6| Step: 3
Training loss: 3.3094789656175103
Validation loss: 2.639377797260185

Epoch: 6| Step: 4
Training loss: 3.275090421636853
Validation loss: 2.620295482981888

Epoch: 6| Step: 5
Training loss: 2.3587033155680226
Validation loss: 2.568157421768667

Epoch: 6| Step: 6
Training loss: 2.759720960553956
Validation loss: 2.551135343702711

Epoch: 6| Step: 7
Training loss: 3.2202836614258668
Validation loss: 2.548523211098971

Epoch: 6| Step: 8
Training loss: 3.0838840267774
Validation loss: 2.54512648683498

Epoch: 6| Step: 9
Training loss: 3.427078540802516
Validation loss: 2.5513078574102326

Epoch: 6| Step: 10
Training loss: 2.7010121108641236
Validation loss: 2.5532811497854424

Epoch: 6| Step: 11
Training loss: 2.835477092770797
Validation loss: 2.552579499448994

Epoch: 6| Step: 12
Training loss: 2.3073749972092923
Validation loss: 2.548581184303224

Epoch: 6| Step: 13
Training loss: 3.1374913614465707
Validation loss: 2.546617731613586

Epoch: 66| Step: 0
Training loss: 3.1259989858321817
Validation loss: 2.5445765069862505

Epoch: 6| Step: 1
Training loss: 2.375636969026614
Validation loss: 2.5422444886204905

Epoch: 6| Step: 2
Training loss: 3.1815282194117165
Validation loss: 2.5449117168084983

Epoch: 6| Step: 3
Training loss: 2.945999186881498
Validation loss: 2.5442949447289562

Epoch: 6| Step: 4
Training loss: 2.772892514263833
Validation loss: 2.5418118992314658

Epoch: 6| Step: 5
Training loss: 3.3309791039687804
Validation loss: 2.5433443440846086

Epoch: 6| Step: 6
Training loss: 2.8383682804640475
Validation loss: 2.542645995153221

Epoch: 6| Step: 7
Training loss: 3.2287910653167446
Validation loss: 2.5500458296007906

Epoch: 6| Step: 8
Training loss: 2.861449609462427
Validation loss: 2.54546712422589

Epoch: 6| Step: 9
Training loss: 2.9897218111688435
Validation loss: 2.5420037632240957

Epoch: 6| Step: 10
Training loss: 2.77927637260204
Validation loss: 2.54089594700709

Epoch: 6| Step: 11
Training loss: 2.666283808483559
Validation loss: 2.541940836355276

Epoch: 6| Step: 12
Training loss: 2.7089725815915786
Validation loss: 2.5444591324612698

Epoch: 6| Step: 13
Training loss: 2.898065178084893
Validation loss: 2.544903828165132

Epoch: 67| Step: 0
Training loss: 2.9902994359349258
Validation loss: 2.5539845085205175

Epoch: 6| Step: 1
Training loss: 2.951553168617793
Validation loss: 2.557799936367273

Epoch: 6| Step: 2
Training loss: 2.7206444114379904
Validation loss: 2.5665661465197496

Epoch: 6| Step: 3
Training loss: 2.8840775854121468
Validation loss: 2.5754015297568

Epoch: 6| Step: 4
Training loss: 3.5842277090844616
Validation loss: 2.5630453846447883

Epoch: 6| Step: 5
Training loss: 2.5755972752864316
Validation loss: 2.562845208350757

Epoch: 6| Step: 6
Training loss: 3.180468114310763
Validation loss: 2.5476862701609444

Epoch: 6| Step: 7
Training loss: 2.508586253176084
Validation loss: 2.5370158989064997

Epoch: 6| Step: 8
Training loss: 2.92625466197676
Validation loss: 2.540100708286707

Epoch: 6| Step: 9
Training loss: 2.3951073804447858
Validation loss: 2.532994869977732

Epoch: 6| Step: 10
Training loss: 3.1293682847847113
Validation loss: 2.533257971594194

Epoch: 6| Step: 11
Training loss: 2.764440595386329
Validation loss: 2.5323349604842593

Epoch: 6| Step: 12
Training loss: 3.2544928087303613
Validation loss: 2.5320968234340513

Epoch: 6| Step: 13
Training loss: 2.551867780859735
Validation loss: 2.5326345007953486

Epoch: 68| Step: 0
Training loss: 3.0845554782122084
Validation loss: 2.5289191570836644

Epoch: 6| Step: 1
Training loss: 3.705455191754528
Validation loss: 2.5309554191570776

Epoch: 6| Step: 2
Training loss: 2.8008090859789596
Validation loss: 2.533149631323887

Epoch: 6| Step: 3
Training loss: 2.712812759017976
Validation loss: 2.535161811790532

Epoch: 6| Step: 4
Training loss: 2.992930825435544
Validation loss: 2.532973089521591

Epoch: 6| Step: 5
Training loss: 2.633009000514345
Validation loss: 2.5390305939114017

Epoch: 6| Step: 6
Training loss: 2.9073784390963895
Validation loss: 2.549168145059983

Epoch: 6| Step: 7
Training loss: 2.6229210750269085
Validation loss: 2.5505347315953615

Epoch: 6| Step: 8
Training loss: 3.1203279283779186
Validation loss: 2.560697545399023

Epoch: 6| Step: 9
Training loss: 2.6129660195302904
Validation loss: 2.5822476951649334

Epoch: 6| Step: 10
Training loss: 2.5645750994411975
Validation loss: 2.5611695998624557

Epoch: 6| Step: 11
Training loss: 2.3829891952288906
Validation loss: 2.5496111536944936

Epoch: 6| Step: 12
Training loss: 3.630666972906198
Validation loss: 2.541498396165157

Epoch: 6| Step: 13
Training loss: 1.976403512704766
Validation loss: 2.542665208426114

Epoch: 69| Step: 0
Training loss: 2.859839396469003
Validation loss: 2.537723705130367

Epoch: 6| Step: 1
Training loss: 2.2478627544604732
Validation loss: 2.5360933487508577

Epoch: 6| Step: 2
Training loss: 3.0846176222092976
Validation loss: 2.5428522287845476

Epoch: 6| Step: 3
Training loss: 2.7995785906975255
Validation loss: 2.5470226634331348

Epoch: 6| Step: 4
Training loss: 3.0721690847236642
Validation loss: 2.551289602527385

Epoch: 6| Step: 5
Training loss: 3.126278730075122
Validation loss: 2.547183082780615

Epoch: 6| Step: 6
Training loss: 3.5845146597648805
Validation loss: 2.5545558066981147

Epoch: 6| Step: 7
Training loss: 2.958079062983085
Validation loss: 2.555763381599949

Epoch: 6| Step: 8
Training loss: 2.5869394994502515
Validation loss: 2.544844248021095

Epoch: 6| Step: 9
Training loss: 2.8911399588814133
Validation loss: 2.53960343599197

Epoch: 6| Step: 10
Training loss: 3.3838830535737596
Validation loss: 2.5374600077395906

Epoch: 6| Step: 11
Training loss: 2.5192669397155396
Validation loss: 2.53875904677364

Epoch: 6| Step: 12
Training loss: 2.6660144624253417
Validation loss: 2.5352325496229735

Epoch: 6| Step: 13
Training loss: 2.442595999167469
Validation loss: 2.533974209950292

Epoch: 70| Step: 0
Training loss: 2.8310605825762183
Validation loss: 2.530219895056416

Epoch: 6| Step: 1
Training loss: 2.6135828502740415
Validation loss: 2.5340359375179893

Epoch: 6| Step: 2
Training loss: 2.683726478192854
Validation loss: 2.532914713534328

Epoch: 6| Step: 3
Training loss: 3.0248903238890525
Validation loss: 2.53965839571605

Epoch: 6| Step: 4
Training loss: 3.129530407471553
Validation loss: 2.5408329422530103

Epoch: 6| Step: 5
Training loss: 2.604234577565038
Validation loss: 2.5425085559263443

Epoch: 6| Step: 6
Training loss: 2.6519399343969714
Validation loss: 2.543007900389757

Epoch: 6| Step: 7
Training loss: 2.9350618023839763
Validation loss: 2.547272675363833

Epoch: 6| Step: 8
Training loss: 2.7058706286364167
Validation loss: 2.55212477716711

Epoch: 6| Step: 9
Training loss: 3.1532871956975
Validation loss: 2.5509883504640074

Epoch: 6| Step: 10
Training loss: 3.226942875865124
Validation loss: 2.5458494520179764

Epoch: 6| Step: 11
Training loss: 2.7136821649437843
Validation loss: 2.5463861222352433

Epoch: 6| Step: 12
Training loss: 3.318068807632328
Validation loss: 2.5430492810966787

Epoch: 6| Step: 13
Training loss: 2.751490969055761
Validation loss: 2.5385739778949894

Epoch: 71| Step: 0
Training loss: 3.238629477705016
Validation loss: 2.538174752278632

Epoch: 6| Step: 1
Training loss: 2.987308039543314
Validation loss: 2.536338865161013

Epoch: 6| Step: 2
Training loss: 2.490928020734437
Validation loss: 2.5297288910940137

Epoch: 6| Step: 3
Training loss: 2.8807827386522735
Validation loss: 2.53470838873278

Epoch: 6| Step: 4
Training loss: 3.082549038363149
Validation loss: 2.5365975964925016

Epoch: 6| Step: 5
Training loss: 3.3210281857354387
Validation loss: 2.531877203759867

Epoch: 6| Step: 6
Training loss: 2.4547176172265246
Validation loss: 2.542409672927151

Epoch: 6| Step: 7
Training loss: 3.076468549682024
Validation loss: 2.553912324618704

Epoch: 6| Step: 8
Training loss: 2.323611806912599
Validation loss: 2.556841688117474

Epoch: 6| Step: 9
Training loss: 2.8726455335544263
Validation loss: 2.5770790302666025

Epoch: 6| Step: 10
Training loss: 3.0490297181209733
Validation loss: 2.5839551576871433

Epoch: 6| Step: 11
Training loss: 2.9762012332540206
Validation loss: 2.5856070923769288

Epoch: 6| Step: 12
Training loss: 3.1779138365504913
Validation loss: 2.5992345011970532

Epoch: 6| Step: 13
Training loss: 2.0248180967033926
Validation loss: 2.620363379120783

Epoch: 72| Step: 0
Training loss: 2.78886143576732
Validation loss: 2.6441752879659037

Epoch: 6| Step: 1
Training loss: 3.0225702663486005
Validation loss: 2.6627706464582035

Epoch: 6| Step: 2
Training loss: 2.9579549377289798
Validation loss: 2.65665293272875

Epoch: 6| Step: 3
Training loss: 2.995671646643195
Validation loss: 2.6697643698754825

Epoch: 6| Step: 4
Training loss: 3.2350536869081066
Validation loss: 2.6789242873086727

Epoch: 6| Step: 5
Training loss: 3.286538938731866
Validation loss: 2.6487512102932333

Epoch: 6| Step: 6
Training loss: 2.520922278314185
Validation loss: 2.5882887451885055

Epoch: 6| Step: 7
Training loss: 3.232000539005348
Validation loss: 2.576351866869654

Epoch: 6| Step: 8
Training loss: 3.203426886498063
Validation loss: 2.570376137593575

Epoch: 6| Step: 9
Training loss: 2.7977559497733515
Validation loss: 2.5735486972121047

Epoch: 6| Step: 10
Training loss: 2.8762960415188545
Validation loss: 2.569856595950704

Epoch: 6| Step: 11
Training loss: 2.740905983939064
Validation loss: 2.5739222622256626

Epoch: 6| Step: 12
Training loss: 2.29245805658307
Validation loss: 2.5714324935719426

Epoch: 6| Step: 13
Training loss: 3.0629686269520264
Validation loss: 2.5640395307168538

Epoch: 73| Step: 0
Training loss: 3.301790884326753
Validation loss: 2.563383526857567

Epoch: 6| Step: 1
Training loss: 3.4597124467552787
Validation loss: 2.561567592585488

Epoch: 6| Step: 2
Training loss: 2.3305984772993686
Validation loss: 2.564350878365851

Epoch: 6| Step: 3
Training loss: 2.5211897248688326
Validation loss: 2.5745054250904524

Epoch: 6| Step: 4
Training loss: 3.2055650302857863
Validation loss: 2.582724421729245

Epoch: 6| Step: 5
Training loss: 2.6090570130440716
Validation loss: 2.5878177681324113

Epoch: 6| Step: 6
Training loss: 2.7220734200928933
Validation loss: 2.6017351739584282

Epoch: 6| Step: 7
Training loss: 3.088680699496136
Validation loss: 2.596419044303066

Epoch: 6| Step: 8
Training loss: 3.2328101164125456
Validation loss: 2.622485867620815

Epoch: 6| Step: 9
Training loss: 1.8730685776774803
Validation loss: 2.5891828934736063

Epoch: 6| Step: 10
Training loss: 2.68023764965769
Validation loss: 2.574657861528033

Epoch: 6| Step: 11
Training loss: 3.4086176491738227
Validation loss: 2.560294059440419

Epoch: 6| Step: 12
Training loss: 3.0950265427839403
Validation loss: 2.5466728741742446

Epoch: 6| Step: 13
Training loss: 2.8053126581461174
Validation loss: 2.5371857866496823

Epoch: 74| Step: 0
Training loss: 3.4285144233505926
Validation loss: 2.5264473964239675

Epoch: 6| Step: 1
Training loss: 2.319053745168433
Validation loss: 2.5285146521303115

Epoch: 6| Step: 2
Training loss: 3.153430094481057
Validation loss: 2.5388033877444887

Epoch: 6| Step: 3
Training loss: 2.9573314922500167
Validation loss: 2.5699717192308595

Epoch: 6| Step: 4
Training loss: 2.8719921133841613
Validation loss: 2.575900809654274

Epoch: 6| Step: 5
Training loss: 3.2781895488424166
Validation loss: 2.5733290766035184

Epoch: 6| Step: 6
Training loss: 2.708714081825784
Validation loss: 2.5778037767610247

Epoch: 6| Step: 7
Training loss: 2.778050500409362
Validation loss: 2.553029208328546

Epoch: 6| Step: 8
Training loss: 2.5874683654620485
Validation loss: 2.5463407897252184

Epoch: 6| Step: 9
Training loss: 2.803290058834651
Validation loss: 2.571482658610906

Epoch: 6| Step: 10
Training loss: 3.4825881002637438
Validation loss: 2.6249200102635624

Epoch: 6| Step: 11
Training loss: 2.976798621396589
Validation loss: 2.6668343911055965

Epoch: 6| Step: 12
Training loss: 2.6461475115693416
Validation loss: 2.6738499977950614

Epoch: 6| Step: 13
Training loss: 3.1567633183099346
Validation loss: 2.643141140278525

Epoch: 75| Step: 0
Training loss: 2.7735797684406114
Validation loss: 2.6307230449532875

Epoch: 6| Step: 1
Training loss: 3.3157171784871586
Validation loss: 2.6193385592998437

Epoch: 6| Step: 2
Training loss: 2.694074351881246
Validation loss: 2.578389320981358

Epoch: 6| Step: 3
Training loss: 2.8796822939580924
Validation loss: 2.5493102483355283

Epoch: 6| Step: 4
Training loss: 2.5779923838405994
Validation loss: 2.530768587330954

Epoch: 6| Step: 5
Training loss: 2.702659963836915
Validation loss: 2.52294265607547

Epoch: 6| Step: 6
Training loss: 3.2341040161428705
Validation loss: 2.5159609603464115

Epoch: 6| Step: 7
Training loss: 2.5083995856811394
Validation loss: 2.515033990581404

Epoch: 6| Step: 8
Training loss: 2.908994301904138
Validation loss: 2.5085212340610155

Epoch: 6| Step: 9
Training loss: 2.7755375178293695
Validation loss: 2.5145481102428473

Epoch: 6| Step: 10
Training loss: 2.5860774529608355
Validation loss: 2.515032395335025

Epoch: 6| Step: 11
Training loss: 3.2492269917168257
Validation loss: 2.511790377688114

Epoch: 6| Step: 12
Training loss: 3.220476594804046
Validation loss: 2.5161519860055996

Epoch: 6| Step: 13
Training loss: 2.797025793688335
Validation loss: 2.518848364484465

Epoch: 76| Step: 0
Training loss: 3.0640303233167567
Validation loss: 2.516949935975789

Epoch: 6| Step: 1
Training loss: 3.3912628558288165
Validation loss: 2.520621516021131

Epoch: 6| Step: 2
Training loss: 2.4545507479138564
Validation loss: 2.519452551728494

Epoch: 6| Step: 3
Training loss: 3.1186932820454767
Validation loss: 2.5145328744390203

Epoch: 6| Step: 4
Training loss: 1.9291078878501582
Validation loss: 2.519636551631973

Epoch: 6| Step: 5
Training loss: 2.9306474664225193
Validation loss: 2.52113155803374

Epoch: 6| Step: 6
Training loss: 3.290919561144326
Validation loss: 2.522967651761935

Epoch: 6| Step: 7
Training loss: 2.518154223384466
Validation loss: 2.533483441811088

Epoch: 6| Step: 8
Training loss: 2.6316584652883024
Validation loss: 2.547019599570806

Epoch: 6| Step: 9
Training loss: 3.3381140440514834
Validation loss: 2.574939334448261

Epoch: 6| Step: 10
Training loss: 2.7779724868774167
Validation loss: 2.597038072741258

Epoch: 6| Step: 11
Training loss: 2.7887456804803747
Validation loss: 2.626854430491406

Epoch: 6| Step: 12
Training loss: 2.8260678560191987
Validation loss: 2.676613701167216

Epoch: 6| Step: 13
Training loss: 3.1244646758281727
Validation loss: 2.7281300297255564

Epoch: 77| Step: 0
Training loss: 3.276183804014663
Validation loss: 2.63037803749784

Epoch: 6| Step: 1
Training loss: 3.100752333133542
Validation loss: 2.5946292980539987

Epoch: 6| Step: 2
Training loss: 3.0676400782057307
Validation loss: 2.5719186398980525

Epoch: 6| Step: 3
Training loss: 2.5784943287187705
Validation loss: 2.557961485331508

Epoch: 6| Step: 4
Training loss: 2.8961837519945766
Validation loss: 2.5365371744068783

Epoch: 6| Step: 5
Training loss: 3.137555344538015
Validation loss: 2.534866355112853

Epoch: 6| Step: 6
Training loss: 2.691324218917254
Validation loss: 2.532075709555539

Epoch: 6| Step: 7
Training loss: 2.5501908324398688
Validation loss: 2.532265167260331

Epoch: 6| Step: 8
Training loss: 2.961872043934152
Validation loss: 2.532569023033704

Epoch: 6| Step: 9
Training loss: 2.8878267507920783
Validation loss: 2.5263064659340055

Epoch: 6| Step: 10
Training loss: 2.9596714342607857
Validation loss: 2.5283466877468603

Epoch: 6| Step: 11
Training loss: 2.634252861694044
Validation loss: 2.530368004598805

Epoch: 6| Step: 12
Training loss: 2.7737967245078328
Validation loss: 2.5279133695830875

Epoch: 6| Step: 13
Training loss: 3.0135217160723675
Validation loss: 2.5253438405399837

Epoch: 78| Step: 0
Training loss: 2.5740469381740296
Validation loss: 2.5210429868583457

Epoch: 6| Step: 1
Training loss: 3.079208260867385
Validation loss: 2.523032382925455

Epoch: 6| Step: 2
Training loss: 2.3996062273603807
Validation loss: 2.5236425372039473

Epoch: 6| Step: 3
Training loss: 2.717464800960264
Validation loss: 2.5242760541022435

Epoch: 6| Step: 4
Training loss: 1.9950251695770893
Validation loss: 2.5279043123440985

Epoch: 6| Step: 5
Training loss: 2.8361597735939594
Validation loss: 2.5322985799686144

Epoch: 6| Step: 6
Training loss: 3.199720704287988
Validation loss: 2.5381891755110066

Epoch: 6| Step: 7
Training loss: 2.6888930680196075
Validation loss: 2.533326094033606

Epoch: 6| Step: 8
Training loss: 3.301647185554268
Validation loss: 2.542116925807482

Epoch: 6| Step: 9
Training loss: 2.4512208971691534
Validation loss: 2.539793055892881

Epoch: 6| Step: 10
Training loss: 3.502787433731628
Validation loss: 2.553768907378153

Epoch: 6| Step: 11
Training loss: 3.460496585909853
Validation loss: 2.537373663513733

Epoch: 6| Step: 12
Training loss: 2.9255129763729912
Validation loss: 2.5294095692290415

Epoch: 6| Step: 13
Training loss: 2.872692011034039
Validation loss: 2.5229201913478767

Epoch: 79| Step: 0
Training loss: 2.752279290714861
Validation loss: 2.513845462575445

Epoch: 6| Step: 1
Training loss: 3.038056116255119
Validation loss: 2.5103446232888116

Epoch: 6| Step: 2
Training loss: 3.3869450019491056
Validation loss: 2.516404727304291

Epoch: 6| Step: 3
Training loss: 3.2633939724029966
Validation loss: 2.5175726363766477

Epoch: 6| Step: 4
Training loss: 2.81892491916513
Validation loss: 2.5281116288871672

Epoch: 6| Step: 5
Training loss: 2.4225301533211097
Validation loss: 2.526075837936304

Epoch: 6| Step: 6
Training loss: 2.906217513364296
Validation loss: 2.5237724589600337

Epoch: 6| Step: 7
Training loss: 2.9330542178730536
Validation loss: 2.5270211644294642

Epoch: 6| Step: 8
Training loss: 2.9128546371989064
Validation loss: 2.537942286544219

Epoch: 6| Step: 9
Training loss: 2.370214560087768
Validation loss: 2.5275667993037962

Epoch: 6| Step: 10
Training loss: 3.2245185788436106
Validation loss: 2.522753016519808

Epoch: 6| Step: 11
Training loss: 2.2139462329431763
Validation loss: 2.520638241630315

Epoch: 6| Step: 12
Training loss: 2.917438750028603
Validation loss: 2.5208407474558965

Epoch: 6| Step: 13
Training loss: 2.7757014960210378
Validation loss: 2.5165191408579366

Epoch: 80| Step: 0
Training loss: 3.062892032365606
Validation loss: 2.51747376986304

Epoch: 6| Step: 1
Training loss: 2.216684158753332
Validation loss: 2.5161945338041334

Epoch: 6| Step: 2
Training loss: 3.5324807511957315
Validation loss: 2.5157081520453817

Epoch: 6| Step: 3
Training loss: 2.4908907874143016
Validation loss: 2.5122232133559894

Epoch: 6| Step: 4
Training loss: 3.1279045339782416
Validation loss: 2.511066277320288

Epoch: 6| Step: 5
Training loss: 2.99793792427237
Validation loss: 2.509563902864928

Epoch: 6| Step: 6
Training loss: 2.8417626447680706
Validation loss: 2.511139197712312

Epoch: 6| Step: 7
Training loss: 3.1463822313301164
Validation loss: 2.5203494074680988

Epoch: 6| Step: 8
Training loss: 3.0736075621401184
Validation loss: 2.5116520829123736

Epoch: 6| Step: 9
Training loss: 2.4952631898330173
Validation loss: 2.510450263282148

Epoch: 6| Step: 10
Training loss: 2.808539929888974
Validation loss: 2.5035899474454264

Epoch: 6| Step: 11
Training loss: 2.107206459101551
Validation loss: 2.4955248885050954

Epoch: 6| Step: 12
Training loss: 2.9163593311965563
Validation loss: 2.492996527347703

Epoch: 6| Step: 13
Training loss: 3.0175838137082303
Validation loss: 2.4937291704960445

Epoch: 81| Step: 0
Training loss: 3.214357508508486
Validation loss: 2.490024210622768

Epoch: 6| Step: 1
Training loss: 2.3807975879941536
Validation loss: 2.4879167514878175

Epoch: 6| Step: 2
Training loss: 2.5459838431445756
Validation loss: 2.492368009767035

Epoch: 6| Step: 3
Training loss: 2.5882796545740536
Validation loss: 2.489732865936532

Epoch: 6| Step: 4
Training loss: 3.2870359724239084
Validation loss: 2.4854633312855685

Epoch: 6| Step: 5
Training loss: 3.1548387752877454
Validation loss: 2.488200237315161

Epoch: 6| Step: 6
Training loss: 2.645588921098839
Validation loss: 2.491997442727337

Epoch: 6| Step: 7
Training loss: 2.9484792830716375
Validation loss: 2.4913489551522603

Epoch: 6| Step: 8
Training loss: 2.967448702258745
Validation loss: 2.4986135801820653

Epoch: 6| Step: 9
Training loss: 2.671430227280607
Validation loss: 2.502934785216693

Epoch: 6| Step: 10
Training loss: 3.000085193695938
Validation loss: 2.527800010792375

Epoch: 6| Step: 11
Training loss: 2.906121199840368
Validation loss: 2.556373855707672

Epoch: 6| Step: 12
Training loss: 2.6209436592529087
Validation loss: 2.585458297997851

Epoch: 6| Step: 13
Training loss: 3.063201512546918
Validation loss: 2.6346741833041967

Epoch: 82| Step: 0
Training loss: 2.2809091600778624
Validation loss: 2.612116544992557

Epoch: 6| Step: 1
Training loss: 3.2272785860758217
Validation loss: 2.6391114558984894

Epoch: 6| Step: 2
Training loss: 2.7833381272082436
Validation loss: 2.5578164539457817

Epoch: 6| Step: 3
Training loss: 2.8592749406160918
Validation loss: 2.5242268308083236

Epoch: 6| Step: 4
Training loss: 3.088239598204448
Validation loss: 2.4997304822375

Epoch: 6| Step: 5
Training loss: 2.770856661208387
Validation loss: 2.492680384160317

Epoch: 6| Step: 6
Training loss: 2.6879433554516545
Validation loss: 2.5079900350142923

Epoch: 6| Step: 7
Training loss: 2.7561067920252746
Validation loss: 2.5229473963228557

Epoch: 6| Step: 8
Training loss: 3.054150312170882
Validation loss: 2.528453621689052

Epoch: 6| Step: 9
Training loss: 3.2237307335173204
Validation loss: 2.5212815161830613

Epoch: 6| Step: 10
Training loss: 3.388989876109265
Validation loss: 2.5108983071364053

Epoch: 6| Step: 11
Training loss: 2.5213449972976623
Validation loss: 2.503530829997397

Epoch: 6| Step: 12
Training loss: 2.7665240017366663
Validation loss: 2.5045356890406927

Epoch: 6| Step: 13
Training loss: 2.98222457343039
Validation loss: 2.499834777130429

Epoch: 83| Step: 0
Training loss: 2.678354359868456
Validation loss: 2.5034216425488407

Epoch: 6| Step: 1
Training loss: 3.287265603879866
Validation loss: 2.5067658025016892

Epoch: 6| Step: 2
Training loss: 2.881840735922386
Validation loss: 2.5187431428791993

Epoch: 6| Step: 3
Training loss: 2.586029327698319
Validation loss: 2.532903100320536

Epoch: 6| Step: 4
Training loss: 2.9788445963308248
Validation loss: 2.56164626399463

Epoch: 6| Step: 5
Training loss: 2.924016973172251
Validation loss: 2.5794042253203835

Epoch: 6| Step: 6
Training loss: 3.5293552412855034
Validation loss: 2.566604447526259

Epoch: 6| Step: 7
Training loss: 3.869215801342489
Validation loss: 2.537710164708744

Epoch: 6| Step: 8
Training loss: 2.5720201750300715
Validation loss: 2.5084678824221625

Epoch: 6| Step: 9
Training loss: 2.5031217158340073
Validation loss: 2.4919410985197175

Epoch: 6| Step: 10
Training loss: 3.1415892681703017
Validation loss: 2.4906839165795844

Epoch: 6| Step: 11
Training loss: 2.6115319023425934
Validation loss: 2.4887632410366525

Epoch: 6| Step: 12
Training loss: 1.873787169797182
Validation loss: 2.4939191677536865

Epoch: 6| Step: 13
Training loss: 1.8903743483165103
Validation loss: 2.499525277380355

Epoch: 84| Step: 0
Training loss: 3.0569443426883707
Validation loss: 2.502206128400886

Epoch: 6| Step: 1
Training loss: 2.725586637293891
Validation loss: 2.5060836009676395

Epoch: 6| Step: 2
Training loss: 2.684521554980793
Validation loss: 2.503588897859729

Epoch: 6| Step: 3
Training loss: 2.7933110380838286
Validation loss: 2.5027375332918735

Epoch: 6| Step: 4
Training loss: 2.8285098999454386
Validation loss: 2.4998050247065926

Epoch: 6| Step: 5
Training loss: 2.8752431352057606
Validation loss: 2.497434437923556

Epoch: 6| Step: 6
Training loss: 3.236027834306927
Validation loss: 2.4953243935279277

Epoch: 6| Step: 7
Training loss: 2.440243766208468
Validation loss: 2.4951465563300608

Epoch: 6| Step: 8
Training loss: 3.546946251779507
Validation loss: 2.489125016033787

Epoch: 6| Step: 9
Training loss: 2.7008828803624674
Validation loss: 2.4905582162879476

Epoch: 6| Step: 10
Training loss: 2.834116958261509
Validation loss: 2.4996842759230495

Epoch: 6| Step: 11
Training loss: 3.0404581429941304
Validation loss: 2.4989011749260914

Epoch: 6| Step: 12
Training loss: 2.4851575854434875
Validation loss: 2.4980548151456685

Epoch: 6| Step: 13
Training loss: 3.1784170551071944
Validation loss: 2.504072793146967

Epoch: 85| Step: 0
Training loss: 2.1720247285675156
Validation loss: 2.4964831467652857

Epoch: 6| Step: 1
Training loss: 2.8330753059329212
Validation loss: 2.498715712752669

Epoch: 6| Step: 2
Training loss: 2.1817895741104416
Validation loss: 2.4969862841499997

Epoch: 6| Step: 3
Training loss: 3.083496364373009
Validation loss: 2.4982929513425365

Epoch: 6| Step: 4
Training loss: 3.2526879565785425
Validation loss: 2.501005079390939

Epoch: 6| Step: 5
Training loss: 2.7252906084400723
Validation loss: 2.4910470994006033

Epoch: 6| Step: 6
Training loss: 2.541681341743837
Validation loss: 2.4940080741341575

Epoch: 6| Step: 7
Training loss: 3.631743374265786
Validation loss: 2.5017465556091416

Epoch: 6| Step: 8
Training loss: 2.6002419359177282
Validation loss: 2.503219905890084

Epoch: 6| Step: 9
Training loss: 3.2596605945669346
Validation loss: 2.5086372784398074

Epoch: 6| Step: 10
Training loss: 3.2426636863222145
Validation loss: 2.5100150811951973

Epoch: 6| Step: 11
Training loss: 2.6731719499932955
Validation loss: 2.517611498423633

Epoch: 6| Step: 12
Training loss: 2.650229868725764
Validation loss: 2.522371794040898

Epoch: 6| Step: 13
Training loss: 2.852292654540553
Validation loss: 2.5250927361339395

Epoch: 86| Step: 0
Training loss: 1.926141360893529
Validation loss: 2.527020192546745

Epoch: 6| Step: 1
Training loss: 3.067504841521654
Validation loss: 2.5311168218853735

Epoch: 6| Step: 2
Training loss: 3.2875011661658013
Validation loss: 2.5217566833501546

Epoch: 6| Step: 3
Training loss: 2.631011618646176
Validation loss: 2.502605032616839

Epoch: 6| Step: 4
Training loss: 2.8184185907457278
Validation loss: 2.4928457192180744

Epoch: 6| Step: 5
Training loss: 3.2579554976953538
Validation loss: 2.4878466251628293

Epoch: 6| Step: 6
Training loss: 2.9414250549282683
Validation loss: 2.4840673523305146

Epoch: 6| Step: 7
Training loss: 2.0133784586331473
Validation loss: 2.4839371300307507

Epoch: 6| Step: 8
Training loss: 2.902933176394408
Validation loss: 2.4875827006518447

Epoch: 6| Step: 9
Training loss: 3.19899218901682
Validation loss: 2.48434346889042

Epoch: 6| Step: 10
Training loss: 2.8616372419950347
Validation loss: 2.4875270711351543

Epoch: 6| Step: 11
Training loss: 3.1998372394177563
Validation loss: 2.487835050945067

Epoch: 6| Step: 12
Training loss: 3.1011110837268117
Validation loss: 2.489429603169301

Epoch: 6| Step: 13
Training loss: 2.219892825383461
Validation loss: 2.4942172028738643

Epoch: 87| Step: 0
Training loss: 3.1778451141775537
Validation loss: 2.496947579542644

Epoch: 6| Step: 1
Training loss: 3.172086361011293
Validation loss: 2.503312477988517

Epoch: 6| Step: 2
Training loss: 2.45405250072203
Validation loss: 2.5080105288042938

Epoch: 6| Step: 3
Training loss: 2.6651168929295608
Validation loss: 2.516371767802942

Epoch: 6| Step: 4
Training loss: 2.3307042523691672
Validation loss: 2.500512156785321

Epoch: 6| Step: 5
Training loss: 2.966621680043629
Validation loss: 2.4839565992543626

Epoch: 6| Step: 6
Training loss: 2.7121857948970347
Validation loss: 2.4804977439844

Epoch: 6| Step: 7
Training loss: 2.9919787301720175
Validation loss: 2.4800704159499873

Epoch: 6| Step: 8
Training loss: 3.3184984704514586
Validation loss: 2.4880681396668605

Epoch: 6| Step: 9
Training loss: 2.496372834126612
Validation loss: 2.4946797725365037

Epoch: 6| Step: 10
Training loss: 2.730851524493436
Validation loss: 2.4917934303031033

Epoch: 6| Step: 11
Training loss: 3.492927489936081
Validation loss: 2.4931227360696107

Epoch: 6| Step: 12
Training loss: 2.7488831939970644
Validation loss: 2.495657787168281

Epoch: 6| Step: 13
Training loss: 2.231589334794258
Validation loss: 2.4914778578165926

Epoch: 88| Step: 0
Training loss: 2.986404767247382
Validation loss: 2.4907264074429465

Epoch: 6| Step: 1
Training loss: 2.713248024036008
Validation loss: 2.4884366256290082

Epoch: 6| Step: 2
Training loss: 3.4072055701201984
Validation loss: 2.486406920035565

Epoch: 6| Step: 3
Training loss: 2.9824984577491525
Validation loss: 2.4864942917575603

Epoch: 6| Step: 4
Training loss: 3.0384368644759987
Validation loss: 2.4946001566665696

Epoch: 6| Step: 5
Training loss: 2.587291812353552
Validation loss: 2.508188805139835

Epoch: 6| Step: 6
Training loss: 3.193647253843546
Validation loss: 2.535549682201293

Epoch: 6| Step: 7
Training loss: 2.2597767030910934
Validation loss: 2.562168140867266

Epoch: 6| Step: 8
Training loss: 3.036511760435755
Validation loss: 2.568153659394697

Epoch: 6| Step: 9
Training loss: 2.8931022957293937
Validation loss: 2.557904093550943

Epoch: 6| Step: 10
Training loss: 2.320048204776218
Validation loss: 2.5261110389925707

Epoch: 6| Step: 11
Training loss: 3.08147793868804
Validation loss: 2.5175354743140685

Epoch: 6| Step: 12
Training loss: 2.525930773211556
Validation loss: 2.5121532236586845

Epoch: 6| Step: 13
Training loss: 2.750217949293423
Validation loss: 2.5053760217549526

Epoch: 89| Step: 0
Training loss: 2.904568421548045
Validation loss: 2.4997924164759286

Epoch: 6| Step: 1
Training loss: 2.8721778950651506
Validation loss: 2.4923991647271326

Epoch: 6| Step: 2
Training loss: 2.6229114398091187
Validation loss: 2.484829394221569

Epoch: 6| Step: 3
Training loss: 3.359674484742922
Validation loss: 2.4896174963242146

Epoch: 6| Step: 4
Training loss: 2.789259019440998
Validation loss: 2.4840469004391577

Epoch: 6| Step: 5
Training loss: 2.6075165120641626
Validation loss: 2.4802308963071953

Epoch: 6| Step: 6
Training loss: 2.803535075902202
Validation loss: 2.4825364389432187

Epoch: 6| Step: 7
Training loss: 3.210004462123158
Validation loss: 2.4784122524579075

Epoch: 6| Step: 8
Training loss: 2.4409583573530176
Validation loss: 2.4798839558961396

Epoch: 6| Step: 9
Training loss: 2.912437497233712
Validation loss: 2.482917570725256

Epoch: 6| Step: 10
Training loss: 2.6451129583457202
Validation loss: 2.4752103018263063

Epoch: 6| Step: 11
Training loss: 2.6243170803553117
Validation loss: 2.479688915307567

Epoch: 6| Step: 12
Training loss: 3.1661349067597757
Validation loss: 2.4788717844400625

Epoch: 6| Step: 13
Training loss: 2.826996130126636
Validation loss: 2.484586928905657

Epoch: 90| Step: 0
Training loss: 3.0410038648315476
Validation loss: 2.4868052813476025

Epoch: 6| Step: 1
Training loss: 2.925089490776775
Validation loss: 2.500795325035282

Epoch: 6| Step: 2
Training loss: 2.6348804536516264
Validation loss: 2.491870371974128

Epoch: 6| Step: 3
Training loss: 2.7205566892629545
Validation loss: 2.4894895672801667

Epoch: 6| Step: 4
Training loss: 3.0037875108603123
Validation loss: 2.493041236984019

Epoch: 6| Step: 5
Training loss: 3.116033278242272
Validation loss: 2.4991529178136225

Epoch: 6| Step: 6
Training loss: 3.216692813378307
Validation loss: 2.493261079747563

Epoch: 6| Step: 7
Training loss: 3.083682702006293
Validation loss: 2.4839241453030994

Epoch: 6| Step: 8
Training loss: 3.1801100691453876
Validation loss: 2.491816922577228

Epoch: 6| Step: 9
Training loss: 2.434743447388667
Validation loss: 2.4812880149064425

Epoch: 6| Step: 10
Training loss: 2.6452985408299736
Validation loss: 2.4803070746892906

Epoch: 6| Step: 11
Training loss: 2.2923284673217115
Validation loss: 2.478111748576601

Epoch: 6| Step: 12
Training loss: 2.5021792450329534
Validation loss: 2.4826637194731984

Epoch: 6| Step: 13
Training loss: 2.7624955224738796
Validation loss: 2.4860429747773347

Epoch: 91| Step: 0
Training loss: 2.2388148445693674
Validation loss: 2.5065858826332246

Epoch: 6| Step: 1
Training loss: 2.5741637344154293
Validation loss: 2.524128708889093

Epoch: 6| Step: 2
Training loss: 2.497362271197079
Validation loss: 2.5580542301083993

Epoch: 6| Step: 3
Training loss: 2.8180268977812566
Validation loss: 2.5391975532249598

Epoch: 6| Step: 4
Training loss: 2.943655342151398
Validation loss: 2.5533070282277355

Epoch: 6| Step: 5
Training loss: 2.7764265260047813
Validation loss: 2.5541156772207327

Epoch: 6| Step: 6
Training loss: 3.400386698554597
Validation loss: 2.5639478713402166

Epoch: 6| Step: 7
Training loss: 2.8690786335521326
Validation loss: 2.5000623018438763

Epoch: 6| Step: 8
Training loss: 3.0954318628688267
Validation loss: 2.4768473578235435

Epoch: 6| Step: 9
Training loss: 3.135148925164319
Validation loss: 2.475735685602377

Epoch: 6| Step: 10
Training loss: 2.530851921521572
Validation loss: 2.482438226995822

Epoch: 6| Step: 11
Training loss: 3.0205259670990947
Validation loss: 2.495377311137381

Epoch: 6| Step: 12
Training loss: 2.7744212810096167
Validation loss: 2.497892984922541

Epoch: 6| Step: 13
Training loss: 3.491207113197206
Validation loss: 2.5068145372272013

Epoch: 92| Step: 0
Training loss: 3.202969282133383
Validation loss: 2.501636287531015

Epoch: 6| Step: 1
Training loss: 2.679141686907923
Validation loss: 2.4983723551304022

Epoch: 6| Step: 2
Training loss: 2.8899931345927388
Validation loss: 2.49845245721526

Epoch: 6| Step: 3
Training loss: 3.13601026692948
Validation loss: 2.4989416651022895

Epoch: 6| Step: 4
Training loss: 2.2370335694796815
Validation loss: 2.496377468730582

Epoch: 6| Step: 5
Training loss: 2.828550865186667
Validation loss: 2.49414420299659

Epoch: 6| Step: 6
Training loss: 3.530723465005484
Validation loss: 2.490719506149323

Epoch: 6| Step: 7
Training loss: 3.1217741528967684
Validation loss: 2.4842820049848244

Epoch: 6| Step: 8
Training loss: 3.3842155947354167
Validation loss: 2.480780304803754

Epoch: 6| Step: 9
Training loss: 2.5728998119301547
Validation loss: 2.481402803733543

Epoch: 6| Step: 10
Training loss: 1.6502031027896362
Validation loss: 2.4850558952941113

Epoch: 6| Step: 11
Training loss: 3.113936102905536
Validation loss: 2.506174827497611

Epoch: 6| Step: 12
Training loss: 2.711864126183204
Validation loss: 2.5204874254095655

Epoch: 6| Step: 13
Training loss: 2.5014708960283265
Validation loss: 2.5327863053113977

Epoch: 93| Step: 0
Training loss: 2.3610256054922485
Validation loss: 2.592484556026671

Epoch: 6| Step: 1
Training loss: 3.4330243190722953
Validation loss: 2.6688908682846666

Epoch: 6| Step: 2
Training loss: 2.5965158813272957
Validation loss: 2.724987504683408

Epoch: 6| Step: 3
Training loss: 3.212386423916036
Validation loss: 2.7373067713375314

Epoch: 6| Step: 4
Training loss: 3.580967469579761
Validation loss: 2.7148874341439906

Epoch: 6| Step: 5
Training loss: 2.17681870989289
Validation loss: 2.631430510197284

Epoch: 6| Step: 6
Training loss: 3.10194544505999
Validation loss: 2.556403410311457

Epoch: 6| Step: 7
Training loss: 3.0718226322588382
Validation loss: 2.5020230209151086

Epoch: 6| Step: 8
Training loss: 2.323366153034621
Validation loss: 2.4819044409408346

Epoch: 6| Step: 9
Training loss: 3.308904459842447
Validation loss: 2.467705448140135

Epoch: 6| Step: 10
Training loss: 2.9948071996313663
Validation loss: 2.473337460875339

Epoch: 6| Step: 11
Training loss: 1.980192266723802
Validation loss: 2.4830479523221993

Epoch: 6| Step: 12
Training loss: 3.283348502367741
Validation loss: 2.4765794413851396

Epoch: 6| Step: 13
Training loss: 2.0871158086415904
Validation loss: 2.4859620520884547

Epoch: 94| Step: 0
Training loss: 3.05952932340681
Validation loss: 2.483581322288115

Epoch: 6| Step: 1
Training loss: 1.9185383683086996
Validation loss: 2.488036266904837

Epoch: 6| Step: 2
Training loss: 2.5722361499948505
Validation loss: 2.4909189463410915

Epoch: 6| Step: 3
Training loss: 3.098888714860513
Validation loss: 2.4902683197352427

Epoch: 6| Step: 4
Training loss: 3.388649641947958
Validation loss: 2.4867744490826014

Epoch: 6| Step: 5
Training loss: 2.573488447360176
Validation loss: 2.485748028208344

Epoch: 6| Step: 6
Training loss: 2.9174807547724755
Validation loss: 2.480810635968572

Epoch: 6| Step: 7
Training loss: 2.9449580862174654
Validation loss: 2.478569506556633

Epoch: 6| Step: 8
Training loss: 3.4217186460961386
Validation loss: 2.4711632108199226

Epoch: 6| Step: 9
Training loss: 2.7792379409214103
Validation loss: 2.4737384439791135

Epoch: 6| Step: 10
Training loss: 2.982218017805723
Validation loss: 2.476533136452189

Epoch: 6| Step: 11
Training loss: 2.752261618981311
Validation loss: 2.4798580131909955

Epoch: 6| Step: 12
Training loss: 2.772920200298837
Validation loss: 2.484005299511382

Epoch: 6| Step: 13
Training loss: 2.627788787999743
Validation loss: 2.5021041669930506

Epoch: 95| Step: 0
Training loss: 2.9774993463446653
Validation loss: 2.516134429734696

Epoch: 6| Step: 1
Training loss: 3.1617026488636695
Validation loss: 2.5275461577667957

Epoch: 6| Step: 2
Training loss: 2.655903872209604
Validation loss: 2.509331518480046

Epoch: 6| Step: 3
Training loss: 2.968433242764278
Validation loss: 2.494299976036267

Epoch: 6| Step: 4
Training loss: 3.0577533293209957
Validation loss: 2.4811345241815284

Epoch: 6| Step: 5
Training loss: 2.9319515990963017
Validation loss: 2.479972082567092

Epoch: 6| Step: 6
Training loss: 3.1255968668281233
Validation loss: 2.478497728695467

Epoch: 6| Step: 7
Training loss: 3.0180840620565306
Validation loss: 2.469404642359158

Epoch: 6| Step: 8
Training loss: 2.281794443873996
Validation loss: 2.475019744656733

Epoch: 6| Step: 9
Training loss: 2.608723998952354
Validation loss: 2.481890001530477

Epoch: 6| Step: 10
Training loss: 2.727840878088503
Validation loss: 2.4965981523891045

Epoch: 6| Step: 11
Training loss: 2.9770073345530927
Validation loss: 2.493292221491865

Epoch: 6| Step: 12
Training loss: 2.5647710645208317
Validation loss: 2.508876593823081

Epoch: 6| Step: 13
Training loss: 2.285380869202259
Validation loss: 2.5268835987270846

Epoch: 96| Step: 0
Training loss: 2.0570748387929445
Validation loss: 2.554040546980722

Epoch: 6| Step: 1
Training loss: 3.1661064422026204
Validation loss: 2.550324009677534

Epoch: 6| Step: 2
Training loss: 3.1151186547864333
Validation loss: 2.5124003948576554

Epoch: 6| Step: 3
Training loss: 3.0771599045724134
Validation loss: 2.5061484275891637

Epoch: 6| Step: 4
Training loss: 2.7541903734749864
Validation loss: 2.494494651165047

Epoch: 6| Step: 5
Training loss: 2.5698347488294853
Validation loss: 2.4905217741631103

Epoch: 6| Step: 6
Training loss: 2.908769725278587
Validation loss: 2.485030350115906

Epoch: 6| Step: 7
Training loss: 1.983144062959291
Validation loss: 2.49941742066961

Epoch: 6| Step: 8
Training loss: 2.8364748274965326
Validation loss: 2.5047542383985544

Epoch: 6| Step: 9
Training loss: 3.007529981151379
Validation loss: 2.4825942223471955

Epoch: 6| Step: 10
Training loss: 2.815433244176994
Validation loss: 2.473868975145462

Epoch: 6| Step: 11
Training loss: 2.8391928576205725
Validation loss: 2.4776726517014214

Epoch: 6| Step: 12
Training loss: 3.490838184864798
Validation loss: 2.4801854182450613

Epoch: 6| Step: 13
Training loss: 2.800715702412465
Validation loss: 2.4839557942322377

Epoch: 97| Step: 0
Training loss: 3.187586764482422
Validation loss: 2.479777451065459

Epoch: 6| Step: 1
Training loss: 3.3064032535332992
Validation loss: 2.4700071291708334

Epoch: 6| Step: 2
Training loss: 2.781656385585222
Validation loss: 2.479482131400808

Epoch: 6| Step: 3
Training loss: 2.3266773203229696
Validation loss: 2.4795193716429624

Epoch: 6| Step: 4
Training loss: 3.0896982190067837
Validation loss: 2.504683840401759

Epoch: 6| Step: 5
Training loss: 3.2201654969802243
Validation loss: 2.50609871321246

Epoch: 6| Step: 6
Training loss: 2.9057559341991026
Validation loss: 2.5208254388332865

Epoch: 6| Step: 7
Training loss: 2.1432118621782683
Validation loss: 2.512265735851854

Epoch: 6| Step: 8
Training loss: 3.126331045876403
Validation loss: 2.4997905233257716

Epoch: 6| Step: 9
Training loss: 2.5116251546884087
Validation loss: 2.4876476028446173

Epoch: 6| Step: 10
Training loss: 2.846670977152197
Validation loss: 2.4790698675662592

Epoch: 6| Step: 11
Training loss: 2.2459125478878312
Validation loss: 2.474702091213624

Epoch: 6| Step: 12
Training loss: 2.785218568508625
Validation loss: 2.481417949027628

Epoch: 6| Step: 13
Training loss: 3.159461021572885
Validation loss: 2.472476808278762

Epoch: 98| Step: 0
Training loss: 3.041308673711286
Validation loss: 2.469872182888737

Epoch: 6| Step: 1
Training loss: 2.589947222315521
Validation loss: 2.474599865740541

Epoch: 6| Step: 2
Training loss: 2.642672946579237
Validation loss: 2.4746994682144545

Epoch: 6| Step: 3
Training loss: 2.734871955398782
Validation loss: 2.484112073034075

Epoch: 6| Step: 4
Training loss: 2.8639704563066233
Validation loss: 2.5033033962591706

Epoch: 6| Step: 5
Training loss: 2.9400973909816375
Validation loss: 2.4944847387913947

Epoch: 6| Step: 6
Training loss: 2.466371380254676
Validation loss: 2.5117530943524384

Epoch: 6| Step: 7
Training loss: 2.7770220735226925
Validation loss: 2.5152256778061974

Epoch: 6| Step: 8
Training loss: 2.3741485675707907
Validation loss: 2.534264944846106

Epoch: 6| Step: 9
Training loss: 2.77558837014354
Validation loss: 2.557311367714813

Epoch: 6| Step: 10
Training loss: 3.1782734794028484
Validation loss: 2.502840017406222

Epoch: 6| Step: 11
Training loss: 3.0941790658908017
Validation loss: 2.488292317304576

Epoch: 6| Step: 12
Training loss: 3.2664621548634654
Validation loss: 2.477059524032431

Epoch: 6| Step: 13
Training loss: 2.545311196117875
Validation loss: 2.4653983801918073

Epoch: 99| Step: 0
Training loss: 2.4061132615115355
Validation loss: 2.4700843410682025

Epoch: 6| Step: 1
Training loss: 3.060758134261071
Validation loss: 2.473795263920952

Epoch: 6| Step: 2
Training loss: 2.9092031262168416
Validation loss: 2.4794086687356702

Epoch: 6| Step: 3
Training loss: 2.9559006337356055
Validation loss: 2.479861191044817

Epoch: 6| Step: 4
Training loss: 2.701031971561104
Validation loss: 2.4755137552008475

Epoch: 6| Step: 5
Training loss: 3.326650373410043
Validation loss: 2.4805280222782113

Epoch: 6| Step: 6
Training loss: 2.7477753917904657
Validation loss: 2.477266588810432

Epoch: 6| Step: 7
Training loss: 3.091709890003477
Validation loss: 2.4685848259230307

Epoch: 6| Step: 8
Training loss: 2.8277889494642987
Validation loss: 2.4758306304172124

Epoch: 6| Step: 9
Training loss: 2.882866422154068
Validation loss: 2.48118543205334

Epoch: 6| Step: 10
Training loss: 2.979549001066413
Validation loss: 2.4741762392787585

Epoch: 6| Step: 11
Training loss: 2.328144969470512
Validation loss: 2.4854465443180365

Epoch: 6| Step: 12
Training loss: 2.797301190686483
Validation loss: 2.4881882711584633

Epoch: 6| Step: 13
Training loss: 2.2860336314787038
Validation loss: 2.482637870871167

Epoch: 100| Step: 0
Training loss: 2.911342957496095
Validation loss: 2.5025059097664615

Epoch: 6| Step: 1
Training loss: 2.8352704064856082
Validation loss: 2.5326957731257025

Epoch: 6| Step: 2
Training loss: 2.6698432023373844
Validation loss: 2.526811240242471

Epoch: 6| Step: 3
Training loss: 3.0815616535169745
Validation loss: 2.4984871214213116

Epoch: 6| Step: 4
Training loss: 3.0755313073135224
Validation loss: 2.4833046667516396

Epoch: 6| Step: 5
Training loss: 2.7750190631108578
Validation loss: 2.4836609115257224

Epoch: 6| Step: 6
Training loss: 2.7488785104171045
Validation loss: 2.477496672451616

Epoch: 6| Step: 7
Training loss: 3.020684460007962
Validation loss: 2.4718758786097252

Epoch: 6| Step: 8
Training loss: 2.6231632164258794
Validation loss: 2.4748973010563886

Epoch: 6| Step: 9
Training loss: 3.2461369370434894
Validation loss: 2.4734408496159292

Epoch: 6| Step: 10
Training loss: 2.081381977467545
Validation loss: 2.4740024848111313

Epoch: 6| Step: 11
Training loss: 3.178944793865003
Validation loss: 2.4872865967593287

Epoch: 6| Step: 12
Training loss: 2.4660058523945536
Validation loss: 2.4959173891730835

Epoch: 6| Step: 13
Training loss: 2.360714260733666
Validation loss: 2.499032095717909

Epoch: 101| Step: 0
Training loss: 2.595537052625667
Validation loss: 2.5114161188941213

Epoch: 6| Step: 1
Training loss: 2.3433564936586304
Validation loss: 2.520096470743713

Epoch: 6| Step: 2
Training loss: 2.8096630623431103
Validation loss: 2.512245155849688

Epoch: 6| Step: 3
Training loss: 3.0477653571896495
Validation loss: 2.511485425824802

Epoch: 6| Step: 4
Training loss: 2.907586559473351
Validation loss: 2.5193891084053

Epoch: 6| Step: 5
Training loss: 2.493269634589119
Validation loss: 2.5032198116694593

Epoch: 6| Step: 6
Training loss: 2.45159670123331
Validation loss: 2.508792369248962

Epoch: 6| Step: 7
Training loss: 2.9984433586059396
Validation loss: 2.5228174910156684

Epoch: 6| Step: 8
Training loss: 3.0113365237551513
Validation loss: 2.5259552430335286

Epoch: 6| Step: 9
Training loss: 3.371640970984194
Validation loss: 2.5304125777107687

Epoch: 6| Step: 10
Training loss: 2.8677402555991685
Validation loss: 2.5269610267068354

Epoch: 6| Step: 11
Training loss: 2.7061946836813324
Validation loss: 2.493342640536243

Epoch: 6| Step: 12
Training loss: 3.028685438575595
Validation loss: 2.47998471584334

Epoch: 6| Step: 13
Training loss: 2.1504625798659145
Validation loss: 2.481275231736864

Epoch: 102| Step: 0
Training loss: 3.066475759313694
Validation loss: 2.4748880767292243

Epoch: 6| Step: 1
Training loss: 2.817695058249593
Validation loss: 2.471989281317874

Epoch: 6| Step: 2
Training loss: 2.3121552081430368
Validation loss: 2.4721612857880753

Epoch: 6| Step: 3
Training loss: 2.919627258339105
Validation loss: 2.48225736693792

Epoch: 6| Step: 4
Training loss: 2.9405161206056993
Validation loss: 2.4815050769689084

Epoch: 6| Step: 5
Training loss: 3.1937881975073283
Validation loss: 2.4804954242507455

Epoch: 6| Step: 6
Training loss: 3.0795126948106577
Validation loss: 2.4793661927772943

Epoch: 6| Step: 7
Training loss: 2.682991504418298
Validation loss: 2.488827940939103

Epoch: 6| Step: 8
Training loss: 3.0073035664196897
Validation loss: 2.4900450072248845

Epoch: 6| Step: 9
Training loss: 2.688512478334607
Validation loss: 2.4868906536349336

Epoch: 6| Step: 10
Training loss: 2.019037832048333
Validation loss: 2.514570074759019

Epoch: 6| Step: 11
Training loss: 2.695974959633563
Validation loss: 2.5143924364353247

Epoch: 6| Step: 12
Training loss: 3.1277973624640723
Validation loss: 2.5649421663642116

Epoch: 6| Step: 13
Training loss: 2.344671958150886
Validation loss: 2.6006699917934393

Epoch: 103| Step: 0
Training loss: 2.1868429014472786
Validation loss: 2.6610160742573776

Epoch: 6| Step: 1
Training loss: 3.1996447008297424
Validation loss: 2.6905119478592683

Epoch: 6| Step: 2
Training loss: 2.681314847290921
Validation loss: 2.6329100948490516

Epoch: 6| Step: 3
Training loss: 3.0628724163707575
Validation loss: 2.6109386138894983

Epoch: 6| Step: 4
Training loss: 2.844388282324085
Validation loss: 2.51749926994999

Epoch: 6| Step: 5
Training loss: 2.982529953632722
Validation loss: 2.478502001602484

Epoch: 6| Step: 6
Training loss: 3.3715627615873127
Validation loss: 2.482596817384875

Epoch: 6| Step: 7
Training loss: 2.9341084807142224
Validation loss: 2.4966028225146086

Epoch: 6| Step: 8
Training loss: 2.460552367092071
Validation loss: 2.5132893648324854

Epoch: 6| Step: 9
Training loss: 3.0798025449402293
Validation loss: 2.541419511623398

Epoch: 6| Step: 10
Training loss: 2.7510453751488595
Validation loss: 2.6243037713200414

Epoch: 6| Step: 11
Training loss: 3.044301359460314
Validation loss: 2.5873201913823136

Epoch: 6| Step: 12
Training loss: 2.7888333095552893
Validation loss: 2.5704763214211597

Epoch: 6| Step: 13
Training loss: 3.0823825882503817
Validation loss: 2.5167228521187104

Epoch: 104| Step: 0
Training loss: 2.7781169260463385
Validation loss: 2.49245417893661

Epoch: 6| Step: 1
Training loss: 2.490698007545037
Validation loss: 2.476619047088236

Epoch: 6| Step: 2
Training loss: 2.8706270214815373
Validation loss: 2.479696355956214

Epoch: 6| Step: 3
Training loss: 2.837150041282711
Validation loss: 2.48765224185279

Epoch: 6| Step: 4
Training loss: 2.8724474978649694
Validation loss: 2.494611763211973

Epoch: 6| Step: 5
Training loss: 2.218875397913011
Validation loss: 2.539297005525841

Epoch: 6| Step: 6
Training loss: 3.562752430321358
Validation loss: 2.651071871076884

Epoch: 6| Step: 7
Training loss: 3.1622649938544716
Validation loss: 2.778158873356578

Epoch: 6| Step: 8
Training loss: 3.419055770227259
Validation loss: 2.7547497195017723

Epoch: 6| Step: 9
Training loss: 2.4339779570434765
Validation loss: 2.6209123626108677

Epoch: 6| Step: 10
Training loss: 2.563788857465463
Validation loss: 2.5466213133945708

Epoch: 6| Step: 11
Training loss: 3.1852250302046152
Validation loss: 2.507477726309912

Epoch: 6| Step: 12
Training loss: 2.9496955132539773
Validation loss: 2.4845677865509534

Epoch: 6| Step: 13
Training loss: 2.8233469861483753
Validation loss: 2.473892584781412

Epoch: 105| Step: 0
Training loss: 1.9833700083165335
Validation loss: 2.4621576048156886

Epoch: 6| Step: 1
Training loss: 2.8788658356644303
Validation loss: 2.4813136042945545

Epoch: 6| Step: 2
Training loss: 2.600418801690095
Validation loss: 2.49069048036501

Epoch: 6| Step: 3
Training loss: 3.2599831354840068
Validation loss: 2.505654201433634

Epoch: 6| Step: 4
Training loss: 2.670746771430821
Validation loss: 2.4999849924026742

Epoch: 6| Step: 5
Training loss: 2.9358740019618534
Validation loss: 2.502358942857617

Epoch: 6| Step: 6
Training loss: 2.7327371978418014
Validation loss: 2.4945165733520036

Epoch: 6| Step: 7
Training loss: 2.906721999694553
Validation loss: 2.5025492253400428

Epoch: 6| Step: 8
Training loss: 2.301995000971347
Validation loss: 2.5081751926643454

Epoch: 6| Step: 9
Training loss: 2.950508694512945
Validation loss: 2.5395495789520415

Epoch: 6| Step: 10
Training loss: 3.3262441272246517
Validation loss: 2.480615534923467

Epoch: 6| Step: 11
Training loss: 3.196373947419664
Validation loss: 2.4718161468326

Epoch: 6| Step: 12
Training loss: 2.6310991547537688
Validation loss: 2.472167621873144

Epoch: 6| Step: 13
Training loss: 3.2030743850802814
Validation loss: 2.4754205961011695

Epoch: 106| Step: 0
Training loss: 3.0776744842027868
Validation loss: 2.46962911276307

Epoch: 6| Step: 1
Training loss: 2.632789860749752
Validation loss: 2.4770775600958648

Epoch: 6| Step: 2
Training loss: 2.7961286689174534
Validation loss: 2.4879100206664293

Epoch: 6| Step: 3
Training loss: 2.8144320315775744
Validation loss: 2.484881446892285

Epoch: 6| Step: 4
Training loss: 2.8743182493522825
Validation loss: 2.471959586543807

Epoch: 6| Step: 5
Training loss: 3.195650339337612
Validation loss: 2.4522653440771496

Epoch: 6| Step: 6
Training loss: 3.0464846629976465
Validation loss: 2.4574308888948844

Epoch: 6| Step: 7
Training loss: 2.95206783688143
Validation loss: 2.4590939571630477

Epoch: 6| Step: 8
Training loss: 2.82537758928496
Validation loss: 2.474624086878494

Epoch: 6| Step: 9
Training loss: 2.7898616554115097
Validation loss: 2.489628100489344

Epoch: 6| Step: 10
Training loss: 2.6014838679347045
Validation loss: 2.4861829961975213

Epoch: 6| Step: 11
Training loss: 2.901863972373646
Validation loss: 2.4762689958635065

Epoch: 6| Step: 12
Training loss: 2.462948319729665
Validation loss: 2.468127587975389

Epoch: 6| Step: 13
Training loss: 2.476986532883886
Validation loss: 2.4620323734073812

Epoch: 107| Step: 0
Training loss: 2.5974809401017547
Validation loss: 2.458878066950873

Epoch: 6| Step: 1
Training loss: 2.2773542191279517
Validation loss: 2.460857777981577

Epoch: 6| Step: 2
Training loss: 2.9957187621837282
Validation loss: 2.4648403406074917

Epoch: 6| Step: 3
Training loss: 2.5188593005373128
Validation loss: 2.463119796085187

Epoch: 6| Step: 4
Training loss: 2.964828471067762
Validation loss: 2.459972115542124

Epoch: 6| Step: 5
Training loss: 2.2264781199745904
Validation loss: 2.4557971549323434

Epoch: 6| Step: 6
Training loss: 3.3547334054010127
Validation loss: 2.4511813098984256

Epoch: 6| Step: 7
Training loss: 2.3945694837893745
Validation loss: 2.4503663829412266

Epoch: 6| Step: 8
Training loss: 2.99418872015759
Validation loss: 2.452728611497274

Epoch: 6| Step: 9
Training loss: 2.8821382225081744
Validation loss: 2.4529011304639288

Epoch: 6| Step: 10
Training loss: 3.459012910799501
Validation loss: 2.455789147056229

Epoch: 6| Step: 11
Training loss: 1.9442683715423223
Validation loss: 2.4675206438312642

Epoch: 6| Step: 12
Training loss: 2.866095145126974
Validation loss: 2.4786590596987472

Epoch: 6| Step: 13
Training loss: 3.613182536658353
Validation loss: 2.485303941805516

Epoch: 108| Step: 0
Training loss: 2.9177491132198656
Validation loss: 2.5156588956230443

Epoch: 6| Step: 1
Training loss: 3.2230234757626857
Validation loss: 2.5152924356750916

Epoch: 6| Step: 2
Training loss: 2.3685395562490825
Validation loss: 2.501806152260803

Epoch: 6| Step: 3
Training loss: 3.696793305888221
Validation loss: 2.5026837095640246

Epoch: 6| Step: 4
Training loss: 2.2755553353743316
Validation loss: 2.4894819046333425

Epoch: 6| Step: 5
Training loss: 2.5210349157352425
Validation loss: 2.4819195217146737

Epoch: 6| Step: 6
Training loss: 2.8403781561199177
Validation loss: 2.475800227887277

Epoch: 6| Step: 7
Training loss: 2.686318248593612
Validation loss: 2.474108634143831

Epoch: 6| Step: 8
Training loss: 2.698920359038249
Validation loss: 2.468658562915659

Epoch: 6| Step: 9
Training loss: 1.7962646774722326
Validation loss: 2.4708070441888377

Epoch: 6| Step: 10
Training loss: 3.1447116965889075
Validation loss: 2.4708887537215904

Epoch: 6| Step: 11
Training loss: 3.127875569066251
Validation loss: 2.4714808658113276

Epoch: 6| Step: 12
Training loss: 2.288866262519546
Validation loss: 2.473545177180766

Epoch: 6| Step: 13
Training loss: 3.128345987019651
Validation loss: 2.46600170545748

Epoch: 109| Step: 0
Training loss: 2.707902248015676
Validation loss: 2.485527887078587

Epoch: 6| Step: 1
Training loss: 2.506063736917162
Validation loss: 2.5037897846408286

Epoch: 6| Step: 2
Training loss: 2.876353069847628
Validation loss: 2.5165271235733595

Epoch: 6| Step: 3
Training loss: 2.3648205496712045
Validation loss: 2.534017185907451

Epoch: 6| Step: 4
Training loss: 2.37848066961145
Validation loss: 2.5418201005504555

Epoch: 6| Step: 5
Training loss: 2.784403695280815
Validation loss: 2.561949291824355

Epoch: 6| Step: 6
Training loss: 2.844787408431414
Validation loss: 2.5698643631062157

Epoch: 6| Step: 7
Training loss: 3.1257411840760425
Validation loss: 2.555782151204275

Epoch: 6| Step: 8
Training loss: 3.1872666217413324
Validation loss: 2.519259128500414

Epoch: 6| Step: 9
Training loss: 3.0355587254264567
Validation loss: 2.4940542725401573

Epoch: 6| Step: 10
Training loss: 2.7684857072259743
Validation loss: 2.4707971924214083

Epoch: 6| Step: 11
Training loss: 2.525501647066566
Validation loss: 2.4766976624445327

Epoch: 6| Step: 12
Training loss: 3.2824569662139345
Validation loss: 2.4667276708175976

Epoch: 6| Step: 13
Training loss: 2.6413977581385235
Validation loss: 2.4657766677858564

Epoch: 110| Step: 0
Training loss: 2.5046369465410097
Validation loss: 2.456753540882571

Epoch: 6| Step: 1
Training loss: 2.652782196076749
Validation loss: 2.460450185149227

Epoch: 6| Step: 2
Training loss: 2.952629411075482
Validation loss: 2.45671705072113

Epoch: 6| Step: 3
Training loss: 2.539319491952175
Validation loss: 2.4485430528490193

Epoch: 6| Step: 4
Training loss: 2.358181076616532
Validation loss: 2.444827240286628

Epoch: 6| Step: 5
Training loss: 3.361329118018084
Validation loss: 2.4491146935822368

Epoch: 6| Step: 6
Training loss: 3.021873523037223
Validation loss: 2.4592265270066536

Epoch: 6| Step: 7
Training loss: 3.097224740643658
Validation loss: 2.473408034842559

Epoch: 6| Step: 8
Training loss: 3.277676916636024
Validation loss: 2.520896848446068

Epoch: 6| Step: 9
Training loss: 2.305687432047492
Validation loss: 2.5375436849090485

Epoch: 6| Step: 10
Training loss: 2.713779421962683
Validation loss: 2.5155213108602523

Epoch: 6| Step: 11
Training loss: 2.566955972030161
Validation loss: 2.4982809524606915

Epoch: 6| Step: 12
Training loss: 2.7119745475114803
Validation loss: 2.484765540438306

Epoch: 6| Step: 13
Training loss: 2.9925645237135434
Validation loss: 2.4792609675537816

Epoch: 111| Step: 0
Training loss: 2.6065604740798554
Validation loss: 2.4572232246052668

Epoch: 6| Step: 1
Training loss: 3.0124879638937947
Validation loss: 2.452961266401953

Epoch: 6| Step: 2
Training loss: 3.0076062416597367
Validation loss: 2.444830340988562

Epoch: 6| Step: 3
Training loss: 3.4179280131500973
Validation loss: 2.450590937009896

Epoch: 6| Step: 4
Training loss: 3.047961545045824
Validation loss: 2.4564521256124467

Epoch: 6| Step: 5
Training loss: 2.3479202807538826
Validation loss: 2.467359151836421

Epoch: 6| Step: 6
Training loss: 2.077454881970026
Validation loss: 2.4775747632860226

Epoch: 6| Step: 7
Training loss: 2.864363357883194
Validation loss: 2.502247747411663

Epoch: 6| Step: 8
Training loss: 3.0130360613113636
Validation loss: 2.5061994042857996

Epoch: 6| Step: 9
Training loss: 2.723420964780107
Validation loss: 2.5113715179295792

Epoch: 6| Step: 10
Training loss: 2.7723544732882774
Validation loss: 2.4919957206004066

Epoch: 6| Step: 11
Training loss: 2.4922286362078174
Validation loss: 2.480988506716621

Epoch: 6| Step: 12
Training loss: 2.565239535146896
Validation loss: 2.4698046831088734

Epoch: 6| Step: 13
Training loss: 2.6799854524416866
Validation loss: 2.4582210739002246

Epoch: 112| Step: 0
Training loss: 3.121667229169831
Validation loss: 2.453227259240206

Epoch: 6| Step: 1
Training loss: 3.162211613831278
Validation loss: 2.457269525656205

Epoch: 6| Step: 2
Training loss: 2.7455053879395463
Validation loss: 2.4594499239723975

Epoch: 6| Step: 3
Training loss: 2.831981411199393
Validation loss: 2.4639509625432843

Epoch: 6| Step: 4
Training loss: 3.2305303011915094
Validation loss: 2.46994756705314

Epoch: 6| Step: 5
Training loss: 3.5101549784906165
Validation loss: 2.469821581581474

Epoch: 6| Step: 6
Training loss: 2.850039893423249
Validation loss: 2.4655164864670835

Epoch: 6| Step: 7
Training loss: 2.5439981700362817
Validation loss: 2.4649491200571565

Epoch: 6| Step: 8
Training loss: 2.25570485300052
Validation loss: 2.4666841211452497

Epoch: 6| Step: 9
Training loss: 2.596199809045199
Validation loss: 2.476512882171294

Epoch: 6| Step: 10
Training loss: 2.5971256947613544
Validation loss: 2.4758659178417814

Epoch: 6| Step: 11
Training loss: 2.531778445242529
Validation loss: 2.4760535470833838

Epoch: 6| Step: 12
Training loss: 1.971087808558475
Validation loss: 2.4813790294801237

Epoch: 6| Step: 13
Training loss: 2.025815766463802
Validation loss: 2.4968642113657733

Epoch: 113| Step: 0
Training loss: 2.0703722675261464
Validation loss: 2.523361966365173

Epoch: 6| Step: 1
Training loss: 2.8784835277335867
Validation loss: 2.5514924980023497

Epoch: 6| Step: 2
Training loss: 2.3885808445450896
Validation loss: 2.604305655103149

Epoch: 6| Step: 3
Training loss: 2.789391591721272
Validation loss: 2.67629585320747

Epoch: 6| Step: 4
Training loss: 3.168662864194269
Validation loss: 2.620706657803089

Epoch: 6| Step: 5
Training loss: 2.868900795424411
Validation loss: 2.5620630343419326

Epoch: 6| Step: 6
Training loss: 2.0424802936551143
Validation loss: 2.532896654022617

Epoch: 6| Step: 7
Training loss: 3.0115471183666673
Validation loss: 2.5022065996948246

Epoch: 6| Step: 8
Training loss: 2.851110971314858
Validation loss: 2.475943951390853

Epoch: 6| Step: 9
Training loss: 3.2569882015568563
Validation loss: 2.461319531257329

Epoch: 6| Step: 10
Training loss: 2.9821353517410163
Validation loss: 2.4532609124276332

Epoch: 6| Step: 11
Training loss: 2.0153388478217025
Validation loss: 2.467669153691803

Epoch: 6| Step: 12
Training loss: 3.1056284353598427
Validation loss: 2.471243174062439

Epoch: 6| Step: 13
Training loss: 2.851020489745168
Validation loss: 2.481685861691123

Epoch: 114| Step: 0
Training loss: 3.0813994829853977
Validation loss: 2.478892183365886

Epoch: 6| Step: 1
Training loss: 2.772955710243436
Validation loss: 2.477586730001533

Epoch: 6| Step: 2
Training loss: 2.5084852225446443
Validation loss: 2.480610374804607

Epoch: 6| Step: 3
Training loss: 2.9912809188781537
Validation loss: 2.479847344504269

Epoch: 6| Step: 4
Training loss: 3.458916549836158
Validation loss: 2.47661330724552

Epoch: 6| Step: 5
Training loss: 2.657735611096636
Validation loss: 2.473888643812769

Epoch: 6| Step: 6
Training loss: 2.6496522531325724
Validation loss: 2.4740878771471784

Epoch: 6| Step: 7
Training loss: 3.266955820897087
Validation loss: 2.468926882011491

Epoch: 6| Step: 8
Training loss: 2.77631128277012
Validation loss: 2.4746649929207565

Epoch: 6| Step: 9
Training loss: 2.780692998423802
Validation loss: 2.4859597276568777

Epoch: 6| Step: 10
Training loss: 3.018229412422247
Validation loss: 2.512089367392759

Epoch: 6| Step: 11
Training loss: 2.4648925002607713
Validation loss: 2.537247445177976

Epoch: 6| Step: 12
Training loss: 1.8958516661487688
Validation loss: 2.5865212346019035

Epoch: 6| Step: 13
Training loss: 2.203037341382768
Validation loss: 2.629895144814384

Epoch: 115| Step: 0
Training loss: 1.624220954779761
Validation loss: 2.7391227285989426

Epoch: 6| Step: 1
Training loss: 2.583958724421534
Validation loss: 2.8316623464165342

Epoch: 6| Step: 2
Training loss: 2.641373116421652
Validation loss: 2.901450514844119

Epoch: 6| Step: 3
Training loss: 3.1078174466361776
Validation loss: 3.115734836660182

Epoch: 6| Step: 4
Training loss: 3.4745553040867296
Validation loss: 3.1143222811516003

Epoch: 6| Step: 5
Training loss: 2.3046824309729743
Validation loss: 2.944201673856018

Epoch: 6| Step: 6
Training loss: 3.4100312409969495
Validation loss: 2.7436789340175425

Epoch: 6| Step: 7
Training loss: 2.1450808295112607
Validation loss: 2.5909348139999038

Epoch: 6| Step: 8
Training loss: 3.1566266127894824
Validation loss: 2.546795080096003

Epoch: 6| Step: 9
Training loss: 3.461684721114625
Validation loss: 2.508385960041119

Epoch: 6| Step: 10
Training loss: 2.875767149368616
Validation loss: 2.48674707930252

Epoch: 6| Step: 11
Training loss: 3.200216619789076
Validation loss: 2.4963975176838247

Epoch: 6| Step: 12
Training loss: 2.853636773662432
Validation loss: 2.5108953329460237

Epoch: 6| Step: 13
Training loss: 3.0346448312799574
Validation loss: 2.5215666241781918

Epoch: 116| Step: 0
Training loss: 2.9661672500404292
Validation loss: 2.52634729926252

Epoch: 6| Step: 1
Training loss: 2.7136127562677403
Validation loss: 2.521158625714334

Epoch: 6| Step: 2
Training loss: 2.515040548919146
Validation loss: 2.5273124810936225

Epoch: 6| Step: 3
Training loss: 2.5627668288335803
Validation loss: 2.536675070571556

Epoch: 6| Step: 4
Training loss: 2.918194089305728
Validation loss: 2.5393826210780857

Epoch: 6| Step: 5
Training loss: 2.4008480719401164
Validation loss: 2.535924776839801

Epoch: 6| Step: 6
Training loss: 3.3474192229390036
Validation loss: 2.522026530831189

Epoch: 6| Step: 7
Training loss: 2.4386990850110815
Validation loss: 2.5090413663701328

Epoch: 6| Step: 8
Training loss: 2.9641260376566745
Validation loss: 2.4994019008262387

Epoch: 6| Step: 9
Training loss: 2.551826952038844
Validation loss: 2.4974219211463584

Epoch: 6| Step: 10
Training loss: 2.5651993838741505
Validation loss: 2.481113148143503

Epoch: 6| Step: 11
Training loss: 3.6579506334297194
Validation loss: 2.4806475412691347

Epoch: 6| Step: 12
Training loss: 2.4984324309087103
Validation loss: 2.4832596321205695

Epoch: 6| Step: 13
Training loss: 3.3666952176032243
Validation loss: 2.4792042935594907

Epoch: 117| Step: 0
Training loss: 2.0280873252531655
Validation loss: 2.494379226352474

Epoch: 6| Step: 1
Training loss: 1.9844002309081257
Validation loss: 2.4948669794901233

Epoch: 6| Step: 2
Training loss: 3.034267535992907
Validation loss: 2.4981561465113504

Epoch: 6| Step: 3
Training loss: 2.4789653878021167
Validation loss: 2.504501504689748

Epoch: 6| Step: 4
Training loss: 2.7793788830794566
Validation loss: 2.5248494565441004

Epoch: 6| Step: 5
Training loss: 3.40686673521846
Validation loss: 2.5561675325709436

Epoch: 6| Step: 6
Training loss: 2.5365526206620856
Validation loss: 2.547890722380667

Epoch: 6| Step: 7
Training loss: 3.1858450389277486
Validation loss: 2.573557612739512

Epoch: 6| Step: 8
Training loss: 3.0791051243338896
Validation loss: 2.5479115401918833

Epoch: 6| Step: 9
Training loss: 2.500549065376829
Validation loss: 2.5398685182505885

Epoch: 6| Step: 10
Training loss: 2.3754242969768
Validation loss: 2.5357592590619604

Epoch: 6| Step: 11
Training loss: 2.7451738143394597
Validation loss: 2.5250174205532008

Epoch: 6| Step: 12
Training loss: 2.942807698330461
Validation loss: 2.5136307653894883

Epoch: 6| Step: 13
Training loss: 3.248454533431848
Validation loss: 2.4927310891467713

Epoch: 118| Step: 0
Training loss: 2.831510256495922
Validation loss: 2.4790841941389803

Epoch: 6| Step: 1
Training loss: 3.2378795268765646
Validation loss: 2.4845843823784026

Epoch: 6| Step: 2
Training loss: 3.0335239650923396
Validation loss: 2.4820699205636783

Epoch: 6| Step: 3
Training loss: 2.2726669841052582
Validation loss: 2.4843975233028432

Epoch: 6| Step: 4
Training loss: 2.313987459747176
Validation loss: 2.492403942492872

Epoch: 6| Step: 5
Training loss: 2.5998705611653925
Validation loss: 2.4910960057959874

Epoch: 6| Step: 6
Training loss: 2.2881091739843913
Validation loss: 2.491985372382518

Epoch: 6| Step: 7
Training loss: 3.099941646888104
Validation loss: 2.4973212000466143

Epoch: 6| Step: 8
Training loss: 2.3966264379500313
Validation loss: 2.4963196110446635

Epoch: 6| Step: 9
Training loss: 3.262293233933001
Validation loss: 2.4976129723714227

Epoch: 6| Step: 10
Training loss: 2.593354344352328
Validation loss: 2.4909103535795265

Epoch: 6| Step: 11
Training loss: 3.665941744727052
Validation loss: 2.4934298730691906

Epoch: 6| Step: 12
Training loss: 2.2217273346539037
Validation loss: 2.5025739647596317

Epoch: 6| Step: 13
Training loss: 2.3530182752179214
Validation loss: 2.5163281726163693

Epoch: 119| Step: 0
Training loss: 2.6202542229701997
Validation loss: 2.542318548655861

Epoch: 6| Step: 1
Training loss: 3.096134384393013
Validation loss: 2.5615498681916975

Epoch: 6| Step: 2
Training loss: 1.971881253433589
Validation loss: 2.6194813970135535

Epoch: 6| Step: 3
Training loss: 2.806374725084876
Validation loss: 2.6698799948880847

Epoch: 6| Step: 4
Training loss: 2.962016611056529
Validation loss: 2.707440788794112

Epoch: 6| Step: 5
Training loss: 2.760560479406569
Validation loss: 2.7125473280697587

Epoch: 6| Step: 6
Training loss: 2.7422744432887187
Validation loss: 2.6825615796152404

Epoch: 6| Step: 7
Training loss: 3.569380289994616
Validation loss: 2.6625595609527433

Epoch: 6| Step: 8
Training loss: 2.6310518529951885
Validation loss: 2.6036528174314313

Epoch: 6| Step: 9
Training loss: 2.630478092876052
Validation loss: 2.5701236834410066

Epoch: 6| Step: 10
Training loss: 3.1002192819625582
Validation loss: 2.552070159241905

Epoch: 6| Step: 11
Training loss: 2.450605325461781
Validation loss: 2.546177592248811

Epoch: 6| Step: 12
Training loss: 2.810105809429027
Validation loss: 2.5333783888763657

Epoch: 6| Step: 13
Training loss: 2.3987202928064244
Validation loss: 2.5263103200585304

Epoch: 120| Step: 0
Training loss: 2.500185196692683
Validation loss: 2.5199452365267563

Epoch: 6| Step: 1
Training loss: 2.6907591464000538
Validation loss: 2.513651158116726

Epoch: 6| Step: 2
Training loss: 3.209713296416119
Validation loss: 2.5153666481892456

Epoch: 6| Step: 3
Training loss: 2.70661903314378
Validation loss: 2.5072001099021324

Epoch: 6| Step: 4
Training loss: 2.8258836832588483
Validation loss: 2.500632919671868

Epoch: 6| Step: 5
Training loss: 2.7498299806229407
Validation loss: 2.5114869059360494

Epoch: 6| Step: 6
Training loss: 2.8048439938550063
Validation loss: 2.512245674752521

Epoch: 6| Step: 7
Training loss: 2.567693982396958
Validation loss: 2.51867304223579

Epoch: 6| Step: 8
Training loss: 2.5777623701822643
Validation loss: 2.515534890717085

Epoch: 6| Step: 9
Training loss: 2.845978251649563
Validation loss: 2.519948638508821

Epoch: 6| Step: 10
Training loss: 2.6985442758362668
Validation loss: 2.5362253406558466

Epoch: 6| Step: 11
Training loss: 1.8835848415295415
Validation loss: 2.5357104467291642

Epoch: 6| Step: 12
Training loss: 2.633008819414632
Validation loss: 2.5447509150127323

Epoch: 6| Step: 13
Training loss: 3.0863257827817496
Validation loss: 2.5508446693309894

Epoch: 121| Step: 0
Training loss: 2.553168542273527
Validation loss: 2.552438726200841

Epoch: 6| Step: 1
Training loss: 2.500297147257694
Validation loss: 2.524891489207767

Epoch: 6| Step: 2
Training loss: 2.442765637168225
Validation loss: 2.5172119587149258

Epoch: 6| Step: 3
Training loss: 2.6358995761641903
Validation loss: 2.5110381513675644

Epoch: 6| Step: 4
Training loss: 2.409305366667645
Validation loss: 2.492344660520539

Epoch: 6| Step: 5
Training loss: 2.2127745851291554
Validation loss: 2.4973884490964045

Epoch: 6| Step: 6
Training loss: 2.5939733569939443
Validation loss: 2.4954755757956835

Epoch: 6| Step: 7
Training loss: 2.6080812456312548
Validation loss: 2.492914341297857

Epoch: 6| Step: 8
Training loss: 2.7632137498492506
Validation loss: 2.4910416644969566

Epoch: 6| Step: 9
Training loss: 2.4452270882896876
Validation loss: 2.497715159200406

Epoch: 6| Step: 10
Training loss: 3.2800562549046863
Validation loss: 2.504758500289945

Epoch: 6| Step: 11
Training loss: 3.2140685174614
Validation loss: 2.5096090222028264

Epoch: 6| Step: 12
Training loss: 3.014118035468797
Validation loss: 2.5139621310443325

Epoch: 6| Step: 13
Training loss: 2.8244342642583233
Validation loss: 2.5071713393344583

Epoch: 122| Step: 0
Training loss: 2.3446612811742127
Validation loss: 2.5152328706343625

Epoch: 6| Step: 1
Training loss: 2.3578858381207417
Validation loss: 2.515241302841048

Epoch: 6| Step: 2
Training loss: 2.3168090675919477
Validation loss: 2.519212483563275

Epoch: 6| Step: 3
Training loss: 2.830012918988722
Validation loss: 2.522665163848328

Epoch: 6| Step: 4
Training loss: 2.3613308511344373
Validation loss: 2.529299635986007

Epoch: 6| Step: 5
Training loss: 2.807638756710627
Validation loss: 2.5146812105975203

Epoch: 6| Step: 6
Training loss: 2.8607131245003363
Validation loss: 2.509272990942835

Epoch: 6| Step: 7
Training loss: 2.9476674831650524
Validation loss: 2.506613783423616

Epoch: 6| Step: 8
Training loss: 2.9067726895772346
Validation loss: 2.492629703854633

Epoch: 6| Step: 9
Training loss: 3.0454705547186305
Validation loss: 2.483451456449979

Epoch: 6| Step: 10
Training loss: 3.2263724430442546
Validation loss: 2.4839936774650293

Epoch: 6| Step: 11
Training loss: 2.2634595322106112
Validation loss: 2.4752419772438787

Epoch: 6| Step: 12
Training loss: 2.5482336995432333
Validation loss: 2.4813661605108197

Epoch: 6| Step: 13
Training loss: 2.0094235854852855
Validation loss: 2.4821104374214866

Epoch: 123| Step: 0
Training loss: 2.527274412356676
Validation loss: 2.485349676916918

Epoch: 6| Step: 1
Training loss: 2.6951274421298317
Validation loss: 2.498126692994709

Epoch: 6| Step: 2
Training loss: 2.1551846069780263
Validation loss: 2.508798352246283

Epoch: 6| Step: 3
Training loss: 2.3096953215045337
Validation loss: 2.5224487740905914

Epoch: 6| Step: 4
Training loss: 2.6970040583313026
Validation loss: 2.5488452096568524

Epoch: 6| Step: 5
Training loss: 3.1580491178822774
Validation loss: 2.5506287655936

Epoch: 6| Step: 6
Training loss: 3.0975618865178633
Validation loss: 2.548464245207358

Epoch: 6| Step: 7
Training loss: 2.6385174528914237
Validation loss: 2.545840352855353

Epoch: 6| Step: 8
Training loss: 2.2479159982401575
Validation loss: 2.536636506648217

Epoch: 6| Step: 9
Training loss: 2.38534081573052
Validation loss: 2.5161025192098623

Epoch: 6| Step: 10
Training loss: 2.65843075261841
Validation loss: 2.517697442066605

Epoch: 6| Step: 11
Training loss: 2.3506582555672684
Validation loss: 2.5223693923784154

Epoch: 6| Step: 12
Training loss: 3.106101148020753
Validation loss: 2.519276368906746

Epoch: 6| Step: 13
Training loss: 3.075070022157921
Validation loss: 2.512582910351611

Epoch: 124| Step: 0
Training loss: 2.9820013542965347
Validation loss: 2.5054827414843137

Epoch: 6| Step: 1
Training loss: 2.3115512860727385
Validation loss: 2.494156927918456

Epoch: 6| Step: 2
Training loss: 3.0215328239792925
Validation loss: 2.514420252640915

Epoch: 6| Step: 3
Training loss: 2.522996326536089
Validation loss: 2.5134230464248977

Epoch: 6| Step: 4
Training loss: 3.1989319687931466
Validation loss: 2.515764259474065

Epoch: 6| Step: 5
Training loss: 2.673697134728542
Validation loss: 2.5174150436294944

Epoch: 6| Step: 6
Training loss: 2.646453744633628
Validation loss: 2.486690821288536

Epoch: 6| Step: 7
Training loss: 2.757105058485772
Validation loss: 2.4811045090225154

Epoch: 6| Step: 8
Training loss: 1.7364422274710098
Validation loss: 2.4696092077469536

Epoch: 6| Step: 9
Training loss: 3.044790014283268
Validation loss: 2.46318645180205

Epoch: 6| Step: 10
Training loss: 2.78059396614562
Validation loss: 2.468282254696977

Epoch: 6| Step: 11
Training loss: 2.6221121388656554
Validation loss: 2.465430488422554

Epoch: 6| Step: 12
Training loss: 1.9184281989513865
Validation loss: 2.474054357006894

Epoch: 6| Step: 13
Training loss: 2.079911919342769
Validation loss: 2.4828778584714155

Epoch: 125| Step: 0
Training loss: 1.9955285871652162
Validation loss: 2.4893254171248964

Epoch: 6| Step: 1
Training loss: 2.7548636862095277
Validation loss: 2.5062878494733187

Epoch: 6| Step: 2
Training loss: 2.773489766232866
Validation loss: 2.5068378785077736

Epoch: 6| Step: 3
Training loss: 2.601925752957099
Validation loss: 2.5396180550211853

Epoch: 6| Step: 4
Training loss: 2.984003013875222
Validation loss: 2.562260282135183

Epoch: 6| Step: 5
Training loss: 2.3510381678018715
Validation loss: 2.598543360900783

Epoch: 6| Step: 6
Training loss: 2.2723014588700394
Validation loss: 2.6046806888060785

Epoch: 6| Step: 7
Training loss: 2.576774104528102
Validation loss: 2.6025095373190936

Epoch: 6| Step: 8
Training loss: 2.647598088566375
Validation loss: 2.6083764021142244

Epoch: 6| Step: 9
Training loss: 2.6705709029918103
Validation loss: 2.574748328152199

Epoch: 6| Step: 10
Training loss: 3.231848573121111
Validation loss: 2.5581574309151107

Epoch: 6| Step: 11
Training loss: 3.086728846814194
Validation loss: 2.528835036388274

Epoch: 6| Step: 12
Training loss: 2.2261300721120105
Validation loss: 2.5090980959434868

Epoch: 6| Step: 13
Training loss: 2.1963640728561935
Validation loss: 2.493321542928598

Epoch: 126| Step: 0
Training loss: 2.29150947262868
Validation loss: 2.4673829474053295

Epoch: 6| Step: 1
Training loss: 2.428791825527764
Validation loss: 2.4646557614561484

Epoch: 6| Step: 2
Training loss: 2.9606994694272166
Validation loss: 2.461119400752794

Epoch: 6| Step: 3
Training loss: 2.4649933831549737
Validation loss: 2.4553416321989956

Epoch: 6| Step: 4
Training loss: 2.6369887376240264
Validation loss: 2.4483304175242933

Epoch: 6| Step: 5
Training loss: 2.8309453737195946
Validation loss: 2.4511644387558293

Epoch: 6| Step: 6
Training loss: 2.299852167437166
Validation loss: 2.449150899248279

Epoch: 6| Step: 7
Training loss: 2.8181827354988997
Validation loss: 2.4584806696012658

Epoch: 6| Step: 8
Training loss: 2.8120707714188167
Validation loss: 2.4726517160860046

Epoch: 6| Step: 9
Training loss: 2.398389188298547
Validation loss: 2.5001037883749073

Epoch: 6| Step: 10
Training loss: 3.0415485481076256
Validation loss: 2.532397178499149

Epoch: 6| Step: 11
Training loss: 2.9281884185534888
Validation loss: 2.5772131855255243

Epoch: 6| Step: 12
Training loss: 2.3023622323735373
Validation loss: 2.5909151888666653

Epoch: 6| Step: 13
Training loss: 2.7041761526481185
Validation loss: 2.602156441501411

Epoch: 127| Step: 0
Training loss: 2.4044484912656494
Validation loss: 2.56176699307248

Epoch: 6| Step: 1
Training loss: 3.0311628506117434
Validation loss: 2.5246461573042995

Epoch: 6| Step: 2
Training loss: 2.136664743804463
Validation loss: 2.475222088364585

Epoch: 6| Step: 3
Training loss: 2.518452352727803
Validation loss: 2.4699755641051855

Epoch: 6| Step: 4
Training loss: 2.8403350111322903
Validation loss: 2.4601635808687017

Epoch: 6| Step: 5
Training loss: 2.9753795285523195
Validation loss: 2.461314105704645

Epoch: 6| Step: 6
Training loss: 2.110880787593741
Validation loss: 2.4674692971475376

Epoch: 6| Step: 7
Training loss: 2.5986547401073636
Validation loss: 2.4663985245142577

Epoch: 6| Step: 8
Training loss: 2.674102568491711
Validation loss: 2.4720885705310534

Epoch: 6| Step: 9
Training loss: 3.0546050780120804
Validation loss: 2.4796527032117663

Epoch: 6| Step: 10
Training loss: 2.354376544430365
Validation loss: 2.481860209328989

Epoch: 6| Step: 11
Training loss: 2.8369769248629058
Validation loss: 2.4794849664680645

Epoch: 6| Step: 12
Training loss: 2.4096762304347985
Validation loss: 2.495245736251525

Epoch: 6| Step: 13
Training loss: 2.563525762176676
Validation loss: 2.494276862770711

Epoch: 128| Step: 0
Training loss: 2.0193938276805774
Validation loss: 2.507499500740368

Epoch: 6| Step: 1
Training loss: 2.427548758177194
Validation loss: 2.5031149296255024

Epoch: 6| Step: 2
Training loss: 2.8774910790962185
Validation loss: 2.5116374705437465

Epoch: 6| Step: 3
Training loss: 2.3590989109210296
Validation loss: 2.51239384289324

Epoch: 6| Step: 4
Training loss: 2.834255087270593
Validation loss: 2.511729818141208

Epoch: 6| Step: 5
Training loss: 2.7166485612262035
Validation loss: 2.5223625248104025

Epoch: 6| Step: 6
Training loss: 2.578950229698503
Validation loss: 2.510939940326899

Epoch: 6| Step: 7
Training loss: 2.5680769732457662
Validation loss: 2.50289913170986

Epoch: 6| Step: 8
Training loss: 2.1889092401934347
Validation loss: 2.506311582816726

Epoch: 6| Step: 9
Training loss: 2.9010609889228793
Validation loss: 2.506560213222663

Epoch: 6| Step: 10
Training loss: 2.6886199569289504
Validation loss: 2.517709589737126

Epoch: 6| Step: 11
Training loss: 2.2113172656535385
Validation loss: 2.516136461381854

Epoch: 6| Step: 12
Training loss: 2.7661971023128475
Validation loss: 2.514240418626793

Epoch: 6| Step: 13
Training loss: 3.247297043305921
Validation loss: 2.5249463660782876

Epoch: 129| Step: 0
Training loss: 2.5687184129986536
Validation loss: 2.5372295700880523

Epoch: 6| Step: 1
Training loss: 2.3850039551260283
Validation loss: 2.54968398623481

Epoch: 6| Step: 2
Training loss: 2.4252044434247657
Validation loss: 2.5564596444451455

Epoch: 6| Step: 3
Training loss: 2.4890503465795177
Validation loss: 2.55855317780691

Epoch: 6| Step: 4
Training loss: 2.1650395029882277
Validation loss: 2.554368571350801

Epoch: 6| Step: 5
Training loss: 2.541567086525567
Validation loss: 2.55823487137786

Epoch: 6| Step: 6
Training loss: 2.733149837134174
Validation loss: 2.5544851563594686

Epoch: 6| Step: 7
Training loss: 2.633296571144998
Validation loss: 2.541035666797416

Epoch: 6| Step: 8
Training loss: 2.563306914029269
Validation loss: 2.5292888819082457

Epoch: 6| Step: 9
Training loss: 2.4549838270287854
Validation loss: 2.520934231463574

Epoch: 6| Step: 10
Training loss: 2.8318889713721473
Validation loss: 2.5147222092461434

Epoch: 6| Step: 11
Training loss: 2.9639352404151817
Validation loss: 2.511441122118666

Epoch: 6| Step: 12
Training loss: 2.5211111393799586
Validation loss: 2.4982289942667997

Epoch: 6| Step: 13
Training loss: 2.616124452512054
Validation loss: 2.4984858408766546

Epoch: 130| Step: 0
Training loss: 2.489225438993586
Validation loss: 2.509265093446879

Epoch: 6| Step: 1
Training loss: 2.8824237675110673
Validation loss: 2.5103894651220267

Epoch: 6| Step: 2
Training loss: 2.287023892910427
Validation loss: 2.501655657951858

Epoch: 6| Step: 3
Training loss: 2.2105760042920832
Validation loss: 2.505352889415106

Epoch: 6| Step: 4
Training loss: 2.264582426976991
Validation loss: 2.4988740538969387

Epoch: 6| Step: 5
Training loss: 2.75278730453894
Validation loss: 2.5119024101235374

Epoch: 6| Step: 6
Training loss: 3.016394956657019
Validation loss: 2.5086997203821317

Epoch: 6| Step: 7
Training loss: 2.1299393413305934
Validation loss: 2.5138254824105215

Epoch: 6| Step: 8
Training loss: 1.8889120870300122
Validation loss: 2.539735558393027

Epoch: 6| Step: 9
Training loss: 2.6504541331857796
Validation loss: 2.553780992886944

Epoch: 6| Step: 10
Training loss: 2.3889842667378938
Validation loss: 2.562601109992778

Epoch: 6| Step: 11
Training loss: 2.9424724293002957
Validation loss: 2.5637473385297564

Epoch: 6| Step: 12
Training loss: 3.26427873668539
Validation loss: 2.57279936176104

Epoch: 6| Step: 13
Training loss: 2.5256085106364017
Validation loss: 2.5476228637783924

Epoch: 131| Step: 0
Training loss: 2.4276065071540445
Validation loss: 2.5363911140589095

Epoch: 6| Step: 1
Training loss: 2.2257002382274114
Validation loss: 2.518135132587334

Epoch: 6| Step: 2
Training loss: 2.681970985773387
Validation loss: 2.507940553407617

Epoch: 6| Step: 3
Training loss: 2.7749614128660434
Validation loss: 2.5109797320147984

Epoch: 6| Step: 4
Training loss: 2.8305973606019417
Validation loss: 2.4871651384353615

Epoch: 6| Step: 5
Training loss: 2.439809243296852
Validation loss: 2.4987799897807546

Epoch: 6| Step: 6
Training loss: 2.634464820787663
Validation loss: 2.489810189962051

Epoch: 6| Step: 7
Training loss: 1.884712811456454
Validation loss: 2.4820191279245214

Epoch: 6| Step: 8
Training loss: 2.577162314345455
Validation loss: 2.4874072679217236

Epoch: 6| Step: 9
Training loss: 2.3698204178515745
Validation loss: 2.5034015341304916

Epoch: 6| Step: 10
Training loss: 2.2698822012765594
Validation loss: 2.511383942213589

Epoch: 6| Step: 11
Training loss: 2.6013495097450066
Validation loss: 2.533754892631111

Epoch: 6| Step: 12
Training loss: 3.3654661801692916
Validation loss: 2.5211893120327127

Epoch: 6| Step: 13
Training loss: 2.627333829726616
Validation loss: 2.5175293236923544

Epoch: 132| Step: 0
Training loss: 2.4403234903676974
Validation loss: 2.517375102123909

Epoch: 6| Step: 1
Training loss: 3.008552440437965
Validation loss: 2.51104809538627

Epoch: 6| Step: 2
Training loss: 2.4288739869437244
Validation loss: 2.5256172076435006

Epoch: 6| Step: 3
Training loss: 2.7964102076480977
Validation loss: 2.523383444732818

Epoch: 6| Step: 4
Training loss: 2.8014247266824035
Validation loss: 2.5150416039190358

Epoch: 6| Step: 5
Training loss: 2.238659572084934
Validation loss: 2.5082555397482014

Epoch: 6| Step: 6
Training loss: 2.5893641699569767
Validation loss: 2.5128730371289354

Epoch: 6| Step: 7
Training loss: 2.494208971967567
Validation loss: 2.499679128502745

Epoch: 6| Step: 8
Training loss: 2.4272949606734735
Validation loss: 2.4999718520928176

Epoch: 6| Step: 9
Training loss: 2.2883123529208222
Validation loss: 2.4969568722760616

Epoch: 6| Step: 10
Training loss: 2.135702445903681
Validation loss: 2.4959650312837027

Epoch: 6| Step: 11
Training loss: 2.0920651617313872
Validation loss: 2.495404974596711

Epoch: 6| Step: 12
Training loss: 2.788571012558895
Validation loss: 2.5067164767258694

Epoch: 6| Step: 13
Training loss: 2.7964729574209928
Validation loss: 2.5010735401279356

Epoch: 133| Step: 0
Training loss: 2.5473875688444663
Validation loss: 2.510690345257175

Epoch: 6| Step: 1
Training loss: 2.21629369461353
Validation loss: 2.5192786351230283

Epoch: 6| Step: 2
Training loss: 2.3408690993755665
Validation loss: 2.517121086365538

Epoch: 6| Step: 3
Training loss: 2.178112048599071
Validation loss: 2.5177399505111615

Epoch: 6| Step: 4
Training loss: 2.634276755459272
Validation loss: 2.528311634930904

Epoch: 6| Step: 5
Training loss: 2.2587541246825125
Validation loss: 2.5268630124824085

Epoch: 6| Step: 6
Training loss: 2.9422259360146237
Validation loss: 2.521813383065206

Epoch: 6| Step: 7
Training loss: 2.8927274738832867
Validation loss: 2.5148643964661237

Epoch: 6| Step: 8
Training loss: 2.048562089868736
Validation loss: 2.5144177240930454

Epoch: 6| Step: 9
Training loss: 2.5710613238255484
Validation loss: 2.5119982699302117

Epoch: 6| Step: 10
Training loss: 2.4906121419960012
Validation loss: 2.513812572520649

Epoch: 6| Step: 11
Training loss: 2.448270818103932
Validation loss: 2.5157196836258313

Epoch: 6| Step: 12
Training loss: 2.5702472898797177
Validation loss: 2.5374268549596017

Epoch: 6| Step: 13
Training loss: 2.9172404860111647
Validation loss: 2.5319429839303123

Epoch: 134| Step: 0
Training loss: 2.8128857665939764
Validation loss: 2.538485050845482

Epoch: 6| Step: 1
Training loss: 1.894379599882486
Validation loss: 2.5266654618375335

Epoch: 6| Step: 2
Training loss: 2.5617334103084817
Validation loss: 2.521591695522006

Epoch: 6| Step: 3
Training loss: 2.1987974261297434
Validation loss: 2.5218397521562843

Epoch: 6| Step: 4
Training loss: 2.805396795239749
Validation loss: 2.516127787643095

Epoch: 6| Step: 5
Training loss: 2.4397939989023825
Validation loss: 2.518601977742571

Epoch: 6| Step: 6
Training loss: 2.104287348644786
Validation loss: 2.524922806371977

Epoch: 6| Step: 7
Training loss: 2.78165887120341
Validation loss: 2.5221303154057555

Epoch: 6| Step: 8
Training loss: 2.27608019158227
Validation loss: 2.528094245921021

Epoch: 6| Step: 9
Training loss: 2.626029221534116
Validation loss: 2.5277337967408573

Epoch: 6| Step: 10
Training loss: 2.762189120928654
Validation loss: 2.5243607928614256

Epoch: 6| Step: 11
Training loss: 2.418148200504777
Validation loss: 2.544269419987625

Epoch: 6| Step: 12
Training loss: 2.1833348538730752
Validation loss: 2.5411707241112977

Epoch: 6| Step: 13
Training loss: 2.9528760048178624
Validation loss: 2.5289579552655352

Epoch: 135| Step: 0
Training loss: 2.518309682974434
Validation loss: 2.536696579219292

Epoch: 6| Step: 1
Training loss: 2.958979540528229
Validation loss: 2.533449451746189

Epoch: 6| Step: 2
Training loss: 3.0636560243398137
Validation loss: 2.5355246325992553

Epoch: 6| Step: 3
Training loss: 2.4863784677064094
Validation loss: 2.527545347356592

Epoch: 6| Step: 4
Training loss: 1.9515696932413469
Validation loss: 2.521111254286192

Epoch: 6| Step: 5
Training loss: 2.4625397809683323
Validation loss: 2.5074285602335564

Epoch: 6| Step: 6
Training loss: 2.517120106586383
Validation loss: 2.5079493464382407

Epoch: 6| Step: 7
Training loss: 2.297761707032452
Validation loss: 2.4863501305332885

Epoch: 6| Step: 8
Training loss: 2.3804735054091304
Validation loss: 2.485733668880183

Epoch: 6| Step: 9
Training loss: 2.546458766133791
Validation loss: 2.4914457570247333

Epoch: 6| Step: 10
Training loss: 2.746633636667972
Validation loss: 2.5091022871088784

Epoch: 6| Step: 11
Training loss: 1.9066730092461115
Validation loss: 2.5121710189932385

Epoch: 6| Step: 12
Training loss: 2.649985881983739
Validation loss: 2.5249862497516373

Epoch: 6| Step: 13
Training loss: 1.513169885889024
Validation loss: 2.5574310794712556

Epoch: 136| Step: 0
Training loss: 2.8195576595465845
Validation loss: 2.584605305417433

Epoch: 6| Step: 1
Training loss: 1.9640552311218789
Validation loss: 2.565913372328972

Epoch: 6| Step: 2
Training loss: 2.0627968314456626
Validation loss: 2.5645949021464984

Epoch: 6| Step: 3
Training loss: 1.3342568159810244
Validation loss: 2.56960543762169

Epoch: 6| Step: 4
Training loss: 2.719244024181963
Validation loss: 2.569281457951154

Epoch: 6| Step: 5
Training loss: 2.045334330792704
Validation loss: 2.5720410307759543

Epoch: 6| Step: 6
Training loss: 3.0323342812489034
Validation loss: 2.5483806414215437

Epoch: 6| Step: 7
Training loss: 2.524365895031279
Validation loss: 2.530151260386083

Epoch: 6| Step: 8
Training loss: 2.2149316948547906
Validation loss: 2.494404505181328

Epoch: 6| Step: 9
Training loss: 2.868220753770253
Validation loss: 2.4787300520252544

Epoch: 6| Step: 10
Training loss: 3.0151539172712933
Validation loss: 2.4741597321704294

Epoch: 6| Step: 11
Training loss: 2.671364540282752
Validation loss: 2.472625303512986

Epoch: 6| Step: 12
Training loss: 2.4825218534708218
Validation loss: 2.48806644470111

Epoch: 6| Step: 13
Training loss: 2.61785588625943
Validation loss: 2.5000545567538044

Epoch: 137| Step: 0
Training loss: 2.7090366526250826
Validation loss: 2.518897432334913

Epoch: 6| Step: 1
Training loss: 2.2705604202574734
Validation loss: 2.5321108398580674

Epoch: 6| Step: 2
Training loss: 2.450815267573026
Validation loss: 2.5417633155940162

Epoch: 6| Step: 3
Training loss: 2.8112919226167037
Validation loss: 2.5300558563276683

Epoch: 6| Step: 4
Training loss: 2.0801928564676104
Validation loss: 2.5159060418609065

Epoch: 6| Step: 5
Training loss: 2.520753738365742
Validation loss: 2.5147281302211235

Epoch: 6| Step: 6
Training loss: 2.3707886551422237
Validation loss: 2.49029870519803

Epoch: 6| Step: 7
Training loss: 2.8884275589717903
Validation loss: 2.4909592461928685

Epoch: 6| Step: 8
Training loss: 2.234831116544675
Validation loss: 2.480793912589674

Epoch: 6| Step: 9
Training loss: 2.3707082017035566
Validation loss: 2.4955190914717837

Epoch: 6| Step: 10
Training loss: 2.5337875268582026
Validation loss: 2.508158318529818

Epoch: 6| Step: 11
Training loss: 2.384217295299666
Validation loss: 2.5038504082449777

Epoch: 6| Step: 12
Training loss: 2.3815952881709737
Validation loss: 2.502876820994858

Epoch: 6| Step: 13
Training loss: 2.4554080908307463
Validation loss: 2.4948728335271064

Epoch: 138| Step: 0
Training loss: 2.7215467953686012
Validation loss: 2.490222786143114

Epoch: 6| Step: 1
Training loss: 2.6545501655498804
Validation loss: 2.4795221394624964

Epoch: 6| Step: 2
Training loss: 2.5369367415947273
Validation loss: 2.4967189490299164

Epoch: 6| Step: 3
Training loss: 2.4141849622558795
Validation loss: 2.4942759701182857

Epoch: 6| Step: 4
Training loss: 2.398402906534929
Validation loss: 2.4971801277315344

Epoch: 6| Step: 5
Training loss: 3.15788483534482
Validation loss: 2.5008752295769483

Epoch: 6| Step: 6
Training loss: 2.409341188977764
Validation loss: 2.49719020084997

Epoch: 6| Step: 7
Training loss: 2.351814738081182
Validation loss: 2.5077973209014117

Epoch: 6| Step: 8
Training loss: 2.1447554785510303
Validation loss: 2.5310136266140684

Epoch: 6| Step: 9
Training loss: 2.4231516764827603
Validation loss: 2.5478551908438507

Epoch: 6| Step: 10
Training loss: 2.109844692354035
Validation loss: 2.5521794391255472

Epoch: 6| Step: 11
Training loss: 2.1238937864525127
Validation loss: 2.5484364862278355

Epoch: 6| Step: 12
Training loss: 2.015775689694801
Validation loss: 2.5396800239517447

Epoch: 6| Step: 13
Training loss: 2.48487186861419
Validation loss: 2.5247575248510588

Epoch: 139| Step: 0
Training loss: 2.3671266654982146
Validation loss: 2.532027250442814

Epoch: 6| Step: 1
Training loss: 2.4710257941474016
Validation loss: 2.524685312580001

Epoch: 6| Step: 2
Training loss: 2.2452977105000698
Validation loss: 2.525032848947382

Epoch: 6| Step: 3
Training loss: 2.7733628813685614
Validation loss: 2.527330942637061

Epoch: 6| Step: 4
Training loss: 2.501699918728847
Validation loss: 2.514625991448718

Epoch: 6| Step: 5
Training loss: 2.0362934588904946
Validation loss: 2.505876110134422

Epoch: 6| Step: 6
Training loss: 2.747471253623911
Validation loss: 2.5013145333768736

Epoch: 6| Step: 7
Training loss: 2.5856411582583894
Validation loss: 2.4979639632650152

Epoch: 6| Step: 8
Training loss: 2.7165307820354427
Validation loss: 2.5072128616090805

Epoch: 6| Step: 9
Training loss: 2.0399270983366833
Validation loss: 2.5077475374952165

Epoch: 6| Step: 10
Training loss: 2.460579594819856
Validation loss: 2.515416263986865

Epoch: 6| Step: 11
Training loss: 1.9479713500264015
Validation loss: 2.498253505558582

Epoch: 6| Step: 12
Training loss: 2.836916919910351
Validation loss: 2.4949423832033477

Epoch: 6| Step: 13
Training loss: 1.9240125228886693
Validation loss: 2.5078591126551837

Epoch: 140| Step: 0
Training loss: 2.302243867227847
Validation loss: 2.501196410914274

Epoch: 6| Step: 1
Training loss: 2.922447760435691
Validation loss: 2.4992512648207663

Epoch: 6| Step: 2
Training loss: 3.0558633321789856
Validation loss: 2.5008690277301335

Epoch: 6| Step: 3
Training loss: 2.68999312332579
Validation loss: 2.512192641002098

Epoch: 6| Step: 4
Training loss: 2.3785977468912463
Validation loss: 2.5296906398222245

Epoch: 6| Step: 5
Training loss: 1.7839105379056923
Validation loss: 2.528898023770847

Epoch: 6| Step: 6
Training loss: 2.394322546471751
Validation loss: 2.53276112513533

Epoch: 6| Step: 7
Training loss: 2.669951521758408
Validation loss: 2.5116488585223316

Epoch: 6| Step: 8
Training loss: 2.077396465893684
Validation loss: 2.4989125650345017

Epoch: 6| Step: 9
Training loss: 2.1998261989953054
Validation loss: 2.5176786369904747

Epoch: 6| Step: 10
Training loss: 2.219912801868666
Validation loss: 2.5150417170639248

Epoch: 6| Step: 11
Training loss: 2.761864643478917
Validation loss: 2.507241246219852

Epoch: 6| Step: 12
Training loss: 2.2245437840143922
Validation loss: 2.5057299445314927

Epoch: 6| Step: 13
Training loss: 1.5834096672664026
Validation loss: 2.500473932238357

Epoch: 141| Step: 0
Training loss: 1.881473682577357
Validation loss: 2.523748838520541

Epoch: 6| Step: 1
Training loss: 2.387785677769813
Validation loss: 2.5342897752470837

Epoch: 6| Step: 2
Training loss: 2.21786212617829
Validation loss: 2.5313308644161476

Epoch: 6| Step: 3
Training loss: 3.020635050262206
Validation loss: 2.5223920693475024

Epoch: 6| Step: 4
Training loss: 2.295591657579721
Validation loss: 2.477063275734873

Epoch: 6| Step: 5
Training loss: 2.735947249573264
Validation loss: 2.459207994116555

Epoch: 6| Step: 6
Training loss: 2.6506266590734757
Validation loss: 2.4681799944368112

Epoch: 6| Step: 7
Training loss: 2.476348675182451
Validation loss: 2.4714243183760054

Epoch: 6| Step: 8
Training loss: 2.337245307143206
Validation loss: 2.4722061617200035

Epoch: 6| Step: 9
Training loss: 2.4714939947470147
Validation loss: 2.4806344793815587

Epoch: 6| Step: 10
Training loss: 2.546406708709288
Validation loss: 2.48683826777787

Epoch: 6| Step: 11
Training loss: 2.0966883296282073
Validation loss: 2.4800339571989563

Epoch: 6| Step: 12
Training loss: 2.610605920343357
Validation loss: 2.4688768324405577

Epoch: 6| Step: 13
Training loss: 1.540370791743309
Validation loss: 2.4523065572173817

Epoch: 142| Step: 0
Training loss: 2.2963012186234653
Validation loss: 2.4746210224721725

Epoch: 6| Step: 1
Training loss: 2.064200422832075
Validation loss: 2.501024398323493

Epoch: 6| Step: 2
Training loss: 1.6337765124854204
Validation loss: 2.5281452171606094

Epoch: 6| Step: 3
Training loss: 2.8323511403386648
Validation loss: 2.5335324619875803

Epoch: 6| Step: 4
Training loss: 2.452497073919357
Validation loss: 2.529016128614275

Epoch: 6| Step: 5
Training loss: 1.6764281120371642
Validation loss: 2.5351867284623375

Epoch: 6| Step: 6
Training loss: 2.552837670358931
Validation loss: 2.534677223828415

Epoch: 6| Step: 7
Training loss: 2.6882909453665347
Validation loss: 2.5076838389327722

Epoch: 6| Step: 8
Training loss: 2.466346826523223
Validation loss: 2.4974086046472412

Epoch: 6| Step: 9
Training loss: 1.9724065339313837
Validation loss: 2.4879307406566267

Epoch: 6| Step: 10
Training loss: 2.6381745113235526
Validation loss: 2.5009339772175503

Epoch: 6| Step: 11
Training loss: 2.578953095582366
Validation loss: 2.51062565224993

Epoch: 6| Step: 12
Training loss: 2.820968762916835
Validation loss: 2.509946194312143

Epoch: 6| Step: 13
Training loss: 2.238002153874538
Validation loss: 2.5072321541813825

Epoch: 143| Step: 0
Training loss: 2.233724432715144
Validation loss: 2.529221093676972

Epoch: 6| Step: 1
Training loss: 2.7968492560027656
Validation loss: 2.531365294105118

Epoch: 6| Step: 2
Training loss: 2.299026104772633
Validation loss: 2.5187864265483717

Epoch: 6| Step: 3
Training loss: 1.892378317222961
Validation loss: 2.5087941237861195

Epoch: 6| Step: 4
Training loss: 2.0774631450152095
Validation loss: 2.498133552274717

Epoch: 6| Step: 5
Training loss: 2.779611168982529
Validation loss: 2.494244762028106

Epoch: 6| Step: 6
Training loss: 2.6740894621817928
Validation loss: 2.497484589603628

Epoch: 6| Step: 7
Training loss: 2.387152449790855
Validation loss: 2.500924243615125

Epoch: 6| Step: 8
Training loss: 2.1151426230244765
Validation loss: 2.5221839574128073

Epoch: 6| Step: 9
Training loss: 2.2548560615495803
Validation loss: 2.541386259182239

Epoch: 6| Step: 10
Training loss: 2.3504076178077353
Validation loss: 2.5474121727109322

Epoch: 6| Step: 11
Training loss: 2.5098071380625595
Validation loss: 2.5511188813474313

Epoch: 6| Step: 12
Training loss: 2.1872639119949224
Validation loss: 2.548232860500628

Epoch: 6| Step: 13
Training loss: 2.60473787273905
Validation loss: 2.5435393737117846

Epoch: 144| Step: 0
Training loss: 1.6024073907572223
Validation loss: 2.523696611301468

Epoch: 6| Step: 1
Training loss: 2.429086985080033
Validation loss: 2.5159439631693616

Epoch: 6| Step: 2
Training loss: 1.6566574027469572
Validation loss: 2.513899541411644

Epoch: 6| Step: 3
Training loss: 2.8937084351555584
Validation loss: 2.494903253335952

Epoch: 6| Step: 4
Training loss: 2.187044368703733
Validation loss: 2.4762403338716683

Epoch: 6| Step: 5
Training loss: 1.7802931909516762
Validation loss: 2.4510917694607985

Epoch: 6| Step: 6
Training loss: 2.401049456028636
Validation loss: 2.4409884576156378

Epoch: 6| Step: 7
Training loss: 2.8011969732655766
Validation loss: 2.4312192511333492

Epoch: 6| Step: 8
Training loss: 2.3782900057479175
Validation loss: 2.439984099398345

Epoch: 6| Step: 9
Training loss: 2.8036623810722636
Validation loss: 2.4365545016147414

Epoch: 6| Step: 10
Training loss: 2.5754697130540842
Validation loss: 2.4568925817076757

Epoch: 6| Step: 11
Training loss: 2.0658527058314595
Validation loss: 2.478064463606289

Epoch: 6| Step: 12
Training loss: 2.4334665819377332
Validation loss: 2.4848554356529657

Epoch: 6| Step: 13
Training loss: 2.2747883666815465
Validation loss: 2.508229798503066

Epoch: 145| Step: 0
Training loss: 2.3680368039260995
Validation loss: 2.524321501542716

Epoch: 6| Step: 1
Training loss: 1.6985119983158352
Validation loss: 2.5290030864335264

Epoch: 6| Step: 2
Training loss: 1.9948536703036823
Validation loss: 2.501215495703581

Epoch: 6| Step: 3
Training loss: 2.5650794839720343
Validation loss: 2.528781670301234

Epoch: 6| Step: 4
Training loss: 2.214634046096529
Validation loss: 2.5206190577693075

Epoch: 6| Step: 5
Training loss: 2.604453190617781
Validation loss: 2.525933479011076

Epoch: 6| Step: 6
Training loss: 1.778412549948673
Validation loss: 2.5213246551059627

Epoch: 6| Step: 7
Training loss: 2.7365631939202224
Validation loss: 2.5201797865322177

Epoch: 6| Step: 8
Training loss: 2.3846053585901883
Validation loss: 2.512513362281876

Epoch: 6| Step: 9
Training loss: 2.669499819478145
Validation loss: 2.497534699217893

Epoch: 6| Step: 10
Training loss: 2.264971513884825
Validation loss: 2.49053750683412

Epoch: 6| Step: 11
Training loss: 2.4718370089884822
Validation loss: 2.488499238606613

Epoch: 6| Step: 12
Training loss: 2.5963483916855807
Validation loss: 2.495728607201982

Epoch: 6| Step: 13
Training loss: 2.0064286387168577
Validation loss: 2.478435281972014

Epoch: 146| Step: 0
Training loss: 2.3730380336769454
Validation loss: 2.470932776060928

Epoch: 6| Step: 1
Training loss: 2.8721808834122156
Validation loss: 2.472304617334585

Epoch: 6| Step: 2
Training loss: 2.564296929744386
Validation loss: 2.4684189532562497

Epoch: 6| Step: 3
Training loss: 1.7891626454938745
Validation loss: 2.469093972736347

Epoch: 6| Step: 4
Training loss: 2.2725564094819175
Validation loss: 2.4578079849738974

Epoch: 6| Step: 5
Training loss: 2.048335828083817
Validation loss: 2.471292843751516

Epoch: 6| Step: 6
Training loss: 2.4326912812381294
Validation loss: 2.475942677824547

Epoch: 6| Step: 7
Training loss: 2.3228080507438804
Validation loss: 2.4806670528458667

Epoch: 6| Step: 8
Training loss: 2.3002875272734675
Validation loss: 2.5004371691524296

Epoch: 6| Step: 9
Training loss: 2.507508066303214
Validation loss: 2.507823610937656

Epoch: 6| Step: 10
Training loss: 2.0351055234126214
Validation loss: 2.5414297937259858

Epoch: 6| Step: 11
Training loss: 2.3488973424962483
Validation loss: 2.598361242880682

Epoch: 6| Step: 12
Training loss: 2.2043546667369878
Validation loss: 2.5930789020512597

Epoch: 6| Step: 13
Training loss: 2.7668964459088117
Validation loss: 2.5937901857131616

Epoch: 147| Step: 0
Training loss: 1.9594736296487116
Validation loss: 2.5841346788594395

Epoch: 6| Step: 1
Training loss: 2.608678302154342
Validation loss: 2.5665994253274786

Epoch: 6| Step: 2
Training loss: 1.8098956503742225
Validation loss: 2.5503690040021008

Epoch: 6| Step: 3
Training loss: 2.1920409889774364
Validation loss: 2.5128560823179185

Epoch: 6| Step: 4
Training loss: 1.9439054249140135
Validation loss: 2.4953423653813105

Epoch: 6| Step: 5
Training loss: 2.346768076323848
Validation loss: 2.4859925139037133

Epoch: 6| Step: 6
Training loss: 2.2173620906638773
Validation loss: 2.4831823900918297

Epoch: 6| Step: 7
Training loss: 2.2060103764501786
Validation loss: 2.473772349768982

Epoch: 6| Step: 8
Training loss: 2.18123776670157
Validation loss: 2.4856943600141532

Epoch: 6| Step: 9
Training loss: 2.872102687306905
Validation loss: 2.495928177134064

Epoch: 6| Step: 10
Training loss: 2.6776212950799674
Validation loss: 2.4910300361715207

Epoch: 6| Step: 11
Training loss: 2.3452947993312616
Validation loss: 2.4923779058728632

Epoch: 6| Step: 12
Training loss: 2.5902669109244942
Validation loss: 2.499797722621544

Epoch: 6| Step: 13
Training loss: 2.285611933732648
Validation loss: 2.4999485195150783

Epoch: 148| Step: 0
Training loss: 2.270664057124026
Validation loss: 2.5113707737568087

Epoch: 6| Step: 1
Training loss: 2.085758958812148
Validation loss: 2.51193821190884

Epoch: 6| Step: 2
Training loss: 2.0584091306416434
Validation loss: 2.515732931732344

Epoch: 6| Step: 3
Training loss: 2.437730827161473
Validation loss: 2.522600026916841

Epoch: 6| Step: 4
Training loss: 1.6931975220236521
Validation loss: 2.5242656046297896

Epoch: 6| Step: 5
Training loss: 1.908161955499621
Validation loss: 2.5125994930608875

Epoch: 6| Step: 6
Training loss: 2.8156922767383397
Validation loss: 2.5366547446939416

Epoch: 6| Step: 7
Training loss: 1.8572917134500164
Validation loss: 2.537325462191539

Epoch: 6| Step: 8
Training loss: 2.5070187272055966
Validation loss: 2.536948348470254

Epoch: 6| Step: 9
Training loss: 2.3105783468442525
Validation loss: 2.5151639727490496

Epoch: 6| Step: 10
Training loss: 2.652511838550377
Validation loss: 2.498187782409373

Epoch: 6| Step: 11
Training loss: 2.3437485758459213
Validation loss: 2.501875372914171

Epoch: 6| Step: 12
Training loss: 2.800325960532004
Validation loss: 2.496222462078865

Epoch: 6| Step: 13
Training loss: 2.2430318379075005
Validation loss: 2.479101398015939

Epoch: 149| Step: 0
Training loss: 2.3183638999271343
Validation loss: 2.4750434966132424

Epoch: 6| Step: 1
Training loss: 2.1069466635783787
Validation loss: 2.465414691200327

Epoch: 6| Step: 2
Training loss: 2.359425424201185
Validation loss: 2.465581324336962

Epoch: 6| Step: 3
Training loss: 2.1170203786958397
Validation loss: 2.4693695314902495

Epoch: 6| Step: 4
Training loss: 2.601423196814732
Validation loss: 2.4752927333993835

Epoch: 6| Step: 5
Training loss: 2.681114950980486
Validation loss: 2.4730552112109074

Epoch: 6| Step: 6
Training loss: 2.0968947067130626
Validation loss: 2.4861812483887675

Epoch: 6| Step: 7
Training loss: 1.6987896256811135
Validation loss: 2.4800353403051045

Epoch: 6| Step: 8
Training loss: 3.015762721262167
Validation loss: 2.4927055341764355

Epoch: 6| Step: 9
Training loss: 2.285242219269638
Validation loss: 2.492480071791405

Epoch: 6| Step: 10
Training loss: 2.3884553725409803
Validation loss: 2.512781650782604

Epoch: 6| Step: 11
Training loss: 1.6831813227440398
Validation loss: 2.499190433229726

Epoch: 6| Step: 12
Training loss: 2.1882623706399533
Validation loss: 2.500479176447437

Epoch: 6| Step: 13
Training loss: 1.7869177210031613
Validation loss: 2.4868397316320654

Epoch: 150| Step: 0
Training loss: 2.5768143530201044
Validation loss: 2.5122333179989154

Epoch: 6| Step: 1
Training loss: 2.61297158543422
Validation loss: 2.5257237750154538

Epoch: 6| Step: 2
Training loss: 2.549183460474163
Validation loss: 2.523368559951907

Epoch: 6| Step: 3
Training loss: 2.1376540457557525
Validation loss: 2.526154305513856

Epoch: 6| Step: 4
Training loss: 1.9338514984657653
Validation loss: 2.509848837360605

Epoch: 6| Step: 5
Training loss: 1.9961279102843856
Validation loss: 2.4848488698663513

Epoch: 6| Step: 6
Training loss: 2.061414259455016
Validation loss: 2.4682169388458597

Epoch: 6| Step: 7
Training loss: 2.272630161464808
Validation loss: 2.489213177034462

Epoch: 6| Step: 8
Training loss: 2.303765788280349
Validation loss: 2.4920247682165417

Epoch: 6| Step: 9
Training loss: 2.4852863295712253
Validation loss: 2.495860424720215

Epoch: 6| Step: 10
Training loss: 2.016923707811861
Validation loss: 2.4948840637449634

Epoch: 6| Step: 11
Training loss: 2.479470840728806
Validation loss: 2.487576479062562

Epoch: 6| Step: 12
Training loss: 2.2054707909904656
Validation loss: 2.480092810888149

Epoch: 6| Step: 13
Training loss: 2.1403380709844577
Validation loss: 2.449640350447099

Epoch: 151| Step: 0
Training loss: 2.6560402282460407
Validation loss: 2.4678569968348816

Epoch: 6| Step: 1
Training loss: 2.3076758714237298
Validation loss: 2.4378729367464245

Epoch: 6| Step: 2
Training loss: 1.955730439925171
Validation loss: 2.4391574614599985

Epoch: 6| Step: 3
Training loss: 1.7635757572178556
Validation loss: 2.4284959829887205

Epoch: 6| Step: 4
Training loss: 2.3926564480164854
Validation loss: 2.436202349352125

Epoch: 6| Step: 5
Training loss: 2.506871222086846
Validation loss: 2.4602947061680904

Epoch: 6| Step: 6
Training loss: 2.2965266164627987
Validation loss: 2.477629583096216

Epoch: 6| Step: 7
Training loss: 2.625695999155361
Validation loss: 2.4986155593839983

Epoch: 6| Step: 8
Training loss: 2.061897999154477
Validation loss: 2.504260754663438

Epoch: 6| Step: 9
Training loss: 2.07285897895121
Validation loss: 2.5073404998511104

Epoch: 6| Step: 10
Training loss: 1.6339348399081506
Validation loss: 2.485236029729224

Epoch: 6| Step: 11
Training loss: 2.0939964035571674
Validation loss: 2.4861753017051793

Epoch: 6| Step: 12
Training loss: 2.352334032193841
Validation loss: 2.4864059157806047

Epoch: 6| Step: 13
Training loss: 2.317454829264457
Validation loss: 2.4802802278674103

Epoch: 152| Step: 0
Training loss: 2.8564411391529343
Validation loss: 2.4869227256011976

Epoch: 6| Step: 1
Training loss: 2.258063596074844
Validation loss: 2.4811579040122496

Epoch: 6| Step: 2
Training loss: 2.400883623219004
Validation loss: 2.464926135631269

Epoch: 6| Step: 3
Training loss: 1.4528421926633452
Validation loss: 2.462849351641958

Epoch: 6| Step: 4
Training loss: 2.0779524423188955
Validation loss: 2.460020230774754

Epoch: 6| Step: 5
Training loss: 2.1009100713135207
Validation loss: 2.463686193050113

Epoch: 6| Step: 6
Training loss: 2.1040787505362655
Validation loss: 2.4746580789499553

Epoch: 6| Step: 7
Training loss: 1.6249178352124165
Validation loss: 2.4754492385868025

Epoch: 6| Step: 8
Training loss: 2.1195153533530644
Validation loss: 2.4865245346636846

Epoch: 6| Step: 9
Training loss: 2.275151291731729
Validation loss: 2.5047942685724336

Epoch: 6| Step: 10
Training loss: 2.0836380417832316
Validation loss: 2.516126214486756

Epoch: 6| Step: 11
Training loss: 2.7790046801011195
Validation loss: 2.513300052726143

Epoch: 6| Step: 12
Training loss: 2.2209266409199886
Validation loss: 2.514269749654892

Epoch: 6| Step: 13
Training loss: 2.193148595205221
Validation loss: 2.51383469541565

Epoch: 153| Step: 0
Training loss: 2.531414167943829
Validation loss: 2.5164043136831546

Epoch: 6| Step: 1
Training loss: 2.1097998297238263
Validation loss: 2.519602851457595

Epoch: 6| Step: 2
Training loss: 2.1949027008180453
Validation loss: 2.499629837237321

Epoch: 6| Step: 3
Training loss: 2.454440013470307
Validation loss: 2.4777103666399594

Epoch: 6| Step: 4
Training loss: 2.297535185103447
Validation loss: 2.4575227176479695

Epoch: 6| Step: 5
Training loss: 2.6246141422601443
Validation loss: 2.454495755235888

Epoch: 6| Step: 6
Training loss: 2.3999102416738047
Validation loss: 2.458048179471946

Epoch: 6| Step: 7
Training loss: 1.1900961254468692
Validation loss: 2.441221758822234

Epoch: 6| Step: 8
Training loss: 1.9722006696618868
Validation loss: 2.4454251122920403

Epoch: 6| Step: 9
Training loss: 1.8255989032618365
Validation loss: 2.4552800002389734

Epoch: 6| Step: 10
Training loss: 2.507483630141187
Validation loss: 2.4465281486038437

Epoch: 6| Step: 11
Training loss: 1.9942854661488545
Validation loss: 2.458018185907207

Epoch: 6| Step: 12
Training loss: 1.9650020346012211
Validation loss: 2.4845805636144473

Epoch: 6| Step: 13
Training loss: 2.483392677195443
Validation loss: 2.497490967172082

Epoch: 154| Step: 0
Training loss: 1.975497958024615
Validation loss: 2.497775316473058

Epoch: 6| Step: 1
Training loss: 2.889317727252597
Validation loss: 2.5120324869752046

Epoch: 6| Step: 2
Training loss: 2.0870469246941346
Validation loss: 2.5296499121468283

Epoch: 6| Step: 3
Training loss: 1.7428908361019038
Validation loss: 2.5517631251192077

Epoch: 6| Step: 4
Training loss: 1.6200752459817482
Validation loss: 2.590246499835232

Epoch: 6| Step: 5
Training loss: 2.289976490849589
Validation loss: 2.5477085859421464

Epoch: 6| Step: 6
Training loss: 2.0547051374599463
Validation loss: 2.519557505613333

Epoch: 6| Step: 7
Training loss: 2.235603688271511
Validation loss: 2.4998166129828143

Epoch: 6| Step: 8
Training loss: 2.043310774989271
Validation loss: 2.474488245498791

Epoch: 6| Step: 9
Training loss: 2.4018244484458777
Validation loss: 2.4657961234075185

Epoch: 6| Step: 10
Training loss: 2.318123963767957
Validation loss: 2.4698035101762015

Epoch: 6| Step: 11
Training loss: 2.5563073112200287
Validation loss: 2.463538386938857

Epoch: 6| Step: 12
Training loss: 1.8754867557677342
Validation loss: 2.4794791619176966

Epoch: 6| Step: 13
Training loss: 2.3778232057139648
Validation loss: 2.5052542580027186

Epoch: 155| Step: 0
Training loss: 2.626878792657685
Validation loss: 2.527621854411278

Epoch: 6| Step: 1
Training loss: 1.7676230409089482
Validation loss: 2.545943414377113

Epoch: 6| Step: 2
Training loss: 2.7929588477752785
Validation loss: 2.586246969756259

Epoch: 6| Step: 3
Training loss: 2.26416779056765
Validation loss: 2.557904055465721

Epoch: 6| Step: 4
Training loss: 1.7503819729966374
Validation loss: 2.581503322797788

Epoch: 6| Step: 5
Training loss: 1.998461727803747
Validation loss: 2.569024202587055

Epoch: 6| Step: 6
Training loss: 2.045760688605572
Validation loss: 2.556014617256882

Epoch: 6| Step: 7
Training loss: 2.352255076064476
Validation loss: 2.553549640678082

Epoch: 6| Step: 8
Training loss: 2.0951667661002538
Validation loss: 2.5297493344362856

Epoch: 6| Step: 9
Training loss: 2.341225854328574
Validation loss: 2.5017358967497074

Epoch: 6| Step: 10
Training loss: 2.022596147512854
Validation loss: 2.455738679402472

Epoch: 6| Step: 11
Training loss: 1.5321405896002687
Validation loss: 2.4449629843282676

Epoch: 6| Step: 12
Training loss: 2.217192949714442
Validation loss: 2.442891712487087

Epoch: 6| Step: 13
Training loss: 2.5880500024625843
Validation loss: 2.46428184383286

Epoch: 156| Step: 0
Training loss: 2.088250524406865
Validation loss: 2.4507344672938003

Epoch: 6| Step: 1
Training loss: 2.280471459884053
Validation loss: 2.465780538544599

Epoch: 6| Step: 2
Training loss: 2.0904437478359017
Validation loss: 2.469057020684173

Epoch: 6| Step: 3
Training loss: 2.1498490568891637
Validation loss: 2.4723434484963747

Epoch: 6| Step: 4
Training loss: 2.028658578332344
Validation loss: 2.4780025449698337

Epoch: 6| Step: 5
Training loss: 1.9271325251168907
Validation loss: 2.466535464669

Epoch: 6| Step: 6
Training loss: 2.2654397822997994
Validation loss: 2.4820127601795616

Epoch: 6| Step: 7
Training loss: 1.9748160747403123
Validation loss: 2.4867022585623464

Epoch: 6| Step: 8
Training loss: 1.948019449986795
Validation loss: 2.495672985144505

Epoch: 6| Step: 9
Training loss: 1.7593743061721545
Validation loss: 2.512265186849894

Epoch: 6| Step: 10
Training loss: 2.3103300687786756
Validation loss: 2.554479424884358

Epoch: 6| Step: 11
Training loss: 2.244733049965338
Validation loss: 2.553134540154405

Epoch: 6| Step: 12
Training loss: 2.1541104966691824
Validation loss: 2.572876893602512

Epoch: 6| Step: 13
Training loss: 2.5961208308802335
Validation loss: 2.558043372425531

Epoch: 157| Step: 0
Training loss: 2.3611938337408063
Validation loss: 2.5366401454752476

Epoch: 6| Step: 1
Training loss: 1.9182561903731492
Validation loss: 2.514589692180375

Epoch: 6| Step: 2
Training loss: 2.026512843033203
Validation loss: 2.504032566130711

Epoch: 6| Step: 3
Training loss: 2.5120578851347797
Validation loss: 2.482571450336342

Epoch: 6| Step: 4
Training loss: 1.8798100762105412
Validation loss: 2.4444060734735626

Epoch: 6| Step: 5
Training loss: 1.8276730492273026
Validation loss: 2.4321618505414695

Epoch: 6| Step: 6
Training loss: 2.394159832723468
Validation loss: 2.4236891182620384

Epoch: 6| Step: 7
Training loss: 1.9753688178160924
Validation loss: 2.4181947286612204

Epoch: 6| Step: 8
Training loss: 2.3166977182772666
Validation loss: 2.4192279577995435

Epoch: 6| Step: 9
Training loss: 2.5710741207517556
Validation loss: 2.4367120445760553

Epoch: 6| Step: 10
Training loss: 1.673403103970922
Validation loss: 2.4563487419481955

Epoch: 6| Step: 11
Training loss: 1.6812746577954085
Validation loss: 2.4968115655329974

Epoch: 6| Step: 12
Training loss: 1.9990621394374297
Validation loss: 2.530366904318399

Epoch: 6| Step: 13
Training loss: 2.4437514127058937
Validation loss: 2.5861246078307794

Epoch: 158| Step: 0
Training loss: 1.4978387680631433
Validation loss: 2.5920410792946575

Epoch: 6| Step: 1
Training loss: 2.1577262800422488
Validation loss: 2.5942303928873027

Epoch: 6| Step: 2
Training loss: 1.3488140053538955
Validation loss: 2.5901334100048525

Epoch: 6| Step: 3
Training loss: 1.3096079525811555
Validation loss: 2.579893935365948

Epoch: 6| Step: 4
Training loss: 1.988534248009164
Validation loss: 2.556088267284433

Epoch: 6| Step: 5
Training loss: 2.74721472747401
Validation loss: 2.531312065421972

Epoch: 6| Step: 6
Training loss: 2.4755231439274823
Validation loss: 2.4974869310241012

Epoch: 6| Step: 7
Training loss: 2.314858342361933
Validation loss: 2.450916080342895

Epoch: 6| Step: 8
Training loss: 2.1473205992399946
Validation loss: 2.42600616067135

Epoch: 6| Step: 9
Training loss: 2.6209838662231313
Validation loss: 2.420370847257085

Epoch: 6| Step: 10
Training loss: 1.9471653460027663
Validation loss: 2.4167584291150526

Epoch: 6| Step: 11
Training loss: 1.5786985356028862
Validation loss: 2.4159555934316166

Epoch: 6| Step: 12
Training loss: 2.107432848854943
Validation loss: 2.4031505815543035

Epoch: 6| Step: 13
Training loss: 2.3050176868877243
Validation loss: 2.4191303283680305

Epoch: 159| Step: 0
Training loss: 2.049578213913768
Validation loss: 2.4006643808775805

Epoch: 6| Step: 1
Training loss: 1.6049187453667977
Validation loss: 2.3949972865273224

Epoch: 6| Step: 2
Training loss: 2.398220984412338
Validation loss: 2.4007002627134284

Epoch: 6| Step: 3
Training loss: 1.7260162041611826
Validation loss: 2.434008565986273

Epoch: 6| Step: 4
Training loss: 1.5872788042371042
Validation loss: 2.4642716934138815

Epoch: 6| Step: 5
Training loss: 1.9196153708483037
Validation loss: 2.5297150023364154

Epoch: 6| Step: 6
Training loss: 2.573061507829008
Validation loss: 2.5810198777162294

Epoch: 6| Step: 7
Training loss: 1.917024772472042
Validation loss: 2.617617746324486

Epoch: 6| Step: 8
Training loss: 1.816077155377339
Validation loss: 2.649319938927015

Epoch: 6| Step: 9
Training loss: 2.4396585541380187
Validation loss: 2.6659727546039393

Epoch: 6| Step: 10
Training loss: 2.435620194396852
Validation loss: 2.6288792180418312

Epoch: 6| Step: 11
Training loss: 1.8399043306067635
Validation loss: 2.5491710574998914

Epoch: 6| Step: 12
Training loss: 1.9585376659956109
Validation loss: 2.492981872473668

Epoch: 6| Step: 13
Training loss: 2.467144601073269
Validation loss: 2.4543135975515544

Epoch: 160| Step: 0
Training loss: 1.7357615521637322
Validation loss: 2.4153521452411213

Epoch: 6| Step: 1
Training loss: 1.8445419938107
Validation loss: 2.4036416964859253

Epoch: 6| Step: 2
Training loss: 2.178434059404111
Validation loss: 2.407294835069707

Epoch: 6| Step: 3
Training loss: 2.4287871136777084
Validation loss: 2.406678562064462

Epoch: 6| Step: 4
Training loss: 2.5039896601503067
Validation loss: 2.425578949330315

Epoch: 6| Step: 5
Training loss: 2.267447324096794
Validation loss: 2.426011469691858

Epoch: 6| Step: 6
Training loss: 2.30457184064923
Validation loss: 2.4649559608972957

Epoch: 6| Step: 7
Training loss: 1.47742779924868
Validation loss: 2.4952098136267127

Epoch: 6| Step: 8
Training loss: 1.8480393897602254
Validation loss: 2.526409230428491

Epoch: 6| Step: 9
Training loss: 1.810104760568343
Validation loss: 2.558150306667621

Epoch: 6| Step: 10
Training loss: 2.113277414145664
Validation loss: 2.5659858390610393

Epoch: 6| Step: 11
Training loss: 2.551075940247835
Validation loss: 2.587375571257372

Epoch: 6| Step: 12
Training loss: 1.3484430200280355
Validation loss: 2.5625995963785786

Epoch: 6| Step: 13
Training loss: 1.2818390957376242
Validation loss: 2.55112517005606

Epoch: 161| Step: 0
Training loss: 1.6595271096493522
Validation loss: 2.5383006972573883

Epoch: 6| Step: 1
Training loss: 2.3327989193315974
Validation loss: 2.5197681673965717

Epoch: 6| Step: 2
Training loss: 2.7095634210136357
Validation loss: 2.525004141966709

Epoch: 6| Step: 3
Training loss: 2.3082479614923086
Validation loss: 2.5167972669212966

Epoch: 6| Step: 4
Training loss: 2.0235546181266035
Validation loss: 2.4882140610703165

Epoch: 6| Step: 5
Training loss: 2.06299307737978
Validation loss: 2.457297740183994

Epoch: 6| Step: 6
Training loss: 2.252484327594119
Validation loss: 2.439685864782399

Epoch: 6| Step: 7
Training loss: 1.64385581020467
Validation loss: 2.450943801087986

Epoch: 6| Step: 8
Training loss: 1.6846113559311615
Validation loss: 2.43996267700531

Epoch: 6| Step: 9
Training loss: 2.195815710857212
Validation loss: 2.428786295647254

Epoch: 6| Step: 10
Training loss: 1.4563197630842801
Validation loss: 2.4359856985087145

Epoch: 6| Step: 11
Training loss: 2.0160013483285177
Validation loss: 2.431865822358884

Epoch: 6| Step: 12
Training loss: 1.3487474087609828
Validation loss: 2.458244410415729

Epoch: 6| Step: 13
Training loss: 1.6380526767500065
Validation loss: 2.482265652966099

Epoch: 162| Step: 0
Training loss: 2.301279218116282
Validation loss: 2.482845292328202

Epoch: 6| Step: 1
Training loss: 1.9282615427794179
Validation loss: 2.484718351138852

Epoch: 6| Step: 2
Training loss: 2.0306977915258124
Validation loss: 2.4712730465372856

Epoch: 6| Step: 3
Training loss: 1.783597503537854
Validation loss: 2.4527606441408953

Epoch: 6| Step: 4
Training loss: 2.1278149528786208
Validation loss: 2.4578303835373716

Epoch: 6| Step: 5
Training loss: 1.9341140201256697
Validation loss: 2.447881471009547

Epoch: 6| Step: 6
Training loss: 2.096640570053121
Validation loss: 2.449490830202318

Epoch: 6| Step: 7
Training loss: 2.2951451229511597
Validation loss: 2.475893929769761

Epoch: 6| Step: 8
Training loss: 2.098193790602375
Validation loss: 2.4750298986434447

Epoch: 6| Step: 9
Training loss: 1.2716197514577081
Validation loss: 2.4738523789381013

Epoch: 6| Step: 10
Training loss: 1.719795186689792
Validation loss: 2.486333286656489

Epoch: 6| Step: 11
Training loss: 1.8145590300598593
Validation loss: 2.482770292548466

Epoch: 6| Step: 12
Training loss: 1.9910625797248602
Validation loss: 2.4725222746741973

Epoch: 6| Step: 13
Training loss: 2.2078815813858985
Validation loss: 2.465236642060941

Epoch: 163| Step: 0
Training loss: 2.3594978755255056
Validation loss: 2.441597911243671

Epoch: 6| Step: 1
Training loss: 1.6569256394114928
Validation loss: 2.43577778621052

Epoch: 6| Step: 2
Training loss: 1.436247072274965
Validation loss: 2.4279361592453625

Epoch: 6| Step: 3
Training loss: 1.312280545734368
Validation loss: 2.442089716580463

Epoch: 6| Step: 4
Training loss: 1.8690735297682046
Validation loss: 2.4283317590121234

Epoch: 6| Step: 5
Training loss: 1.5921339181376364
Validation loss: 2.4285320152067125

Epoch: 6| Step: 6
Training loss: 1.6411564284159899
Validation loss: 2.4406978748028627

Epoch: 6| Step: 7
Training loss: 2.177627519799985
Validation loss: 2.4444943695930097

Epoch: 6| Step: 8
Training loss: 2.2254529899066444
Validation loss: 2.4614272555305816

Epoch: 6| Step: 9
Training loss: 2.129286089967642
Validation loss: 2.4814839303735443

Epoch: 6| Step: 10
Training loss: 1.4184823275229315
Validation loss: 2.4901464426728883

Epoch: 6| Step: 11
Training loss: 1.911136056062015
Validation loss: 2.5001192597686974

Epoch: 6| Step: 12
Training loss: 2.7188979360737116
Validation loss: 2.543400791355076

Epoch: 6| Step: 13
Training loss: 2.209715812328011
Validation loss: 2.535258396910337

Epoch: 164| Step: 0
Training loss: 1.9497368072521253
Validation loss: 2.521222571561479

Epoch: 6| Step: 1
Training loss: 1.538974197875349
Validation loss: 2.4916996452175866

Epoch: 6| Step: 2
Training loss: 1.894890945738906
Validation loss: 2.4852270583387472

Epoch: 6| Step: 3
Training loss: 2.126471963338397
Validation loss: 2.4717068030238467

Epoch: 6| Step: 4
Training loss: 1.7247072496646783
Validation loss: 2.4594107000452863

Epoch: 6| Step: 5
Training loss: 1.7922725614068715
Validation loss: 2.4589115739890994

Epoch: 6| Step: 6
Training loss: 2.0140588871321965
Validation loss: 2.4642296587698893

Epoch: 6| Step: 7
Training loss: 1.4851218503031334
Validation loss: 2.466433893354848

Epoch: 6| Step: 8
Training loss: 2.347266445708897
Validation loss: 2.4500747349071994

Epoch: 6| Step: 9
Training loss: 2.1434241044365185
Validation loss: 2.4543977864227506

Epoch: 6| Step: 10
Training loss: 1.6838026868567442
Validation loss: 2.4665476761858005

Epoch: 6| Step: 11
Training loss: 2.2530723364570666
Validation loss: 2.490719933299297

Epoch: 6| Step: 12
Training loss: 1.6904230585965492
Validation loss: 2.4799317613003353

Epoch: 6| Step: 13
Training loss: 1.4794751861904765
Validation loss: 2.4825171269084585

Epoch: 165| Step: 0
Training loss: 2.2153098071847834
Validation loss: 2.4952637733977956

Epoch: 6| Step: 1
Training loss: 1.8317101691335547
Validation loss: 2.5047449316061954

Epoch: 6| Step: 2
Training loss: 1.2008402544960912
Validation loss: 2.5343435473140645

Epoch: 6| Step: 3
Training loss: 2.434751379178553
Validation loss: 2.5573108093361943

Epoch: 6| Step: 4
Training loss: 2.142546967355493
Validation loss: 2.5523675602511866

Epoch: 6| Step: 5
Training loss: 1.4797872217687937
Validation loss: 2.512256286470528

Epoch: 6| Step: 6
Training loss: 2.0237954312857
Validation loss: 2.5102003029230464

Epoch: 6| Step: 7
Training loss: 1.6576668778728814
Validation loss: 2.488114688436064

Epoch: 6| Step: 8
Training loss: 1.9084197031768224
Validation loss: 2.458114293766602

Epoch: 6| Step: 9
Training loss: 1.6418801728781713
Validation loss: 2.4414961466984204

Epoch: 6| Step: 10
Training loss: 1.5927246385649945
Validation loss: 2.4494679629006684

Epoch: 6| Step: 11
Training loss: 2.3281024701353235
Validation loss: 2.4524382510496214

Epoch: 6| Step: 12
Training loss: 1.4804561886216772
Validation loss: 2.4278197109961925

Epoch: 6| Step: 13
Training loss: 2.227759431058955
Validation loss: 2.4457714220626485

Epoch: 166| Step: 0
Training loss: 1.415047402683108
Validation loss: 2.4383427483272007

Epoch: 6| Step: 1
Training loss: 1.9946667969932275
Validation loss: 2.4315892860820267

Epoch: 6| Step: 2
Training loss: 2.1141141424194045
Validation loss: 2.450056830712454

Epoch: 6| Step: 3
Training loss: 2.0197660505202646
Validation loss: 2.4696976875591377

Epoch: 6| Step: 4
Training loss: 1.7192757929333933
Validation loss: 2.4836344632640235

Epoch: 6| Step: 5
Training loss: 1.5421523626435014
Validation loss: 2.486484714537213

Epoch: 6| Step: 6
Training loss: 1.592972509689347
Validation loss: 2.518040219083003

Epoch: 6| Step: 7
Training loss: 1.6601322666006593
Validation loss: 2.5436479436997432

Epoch: 6| Step: 8
Training loss: 2.4663856870406073
Validation loss: 2.5552116489301517

Epoch: 6| Step: 9
Training loss: 1.626115855989237
Validation loss: 2.54186180417339

Epoch: 6| Step: 10
Training loss: 2.229912843925499
Validation loss: 2.5477063802335596

Epoch: 6| Step: 11
Training loss: 1.9023143601546155
Validation loss: 2.554291725265471

Epoch: 6| Step: 12
Training loss: 1.764917282457174
Validation loss: 2.5411190395834553

Epoch: 6| Step: 13
Training loss: 1.1019131258006816
Validation loss: 2.5152911687821975

Epoch: 167| Step: 0
Training loss: 2.3180993825361442
Validation loss: 2.4874689679130437

Epoch: 6| Step: 1
Training loss: 0.9514207455637654
Validation loss: 2.440738750210991

Epoch: 6| Step: 2
Training loss: 1.577333913000607
Validation loss: 2.4547966175457407

Epoch: 6| Step: 3
Training loss: 2.0997560813571394
Validation loss: 2.4263776869236984

Epoch: 6| Step: 4
Training loss: 2.120860836947409
Validation loss: 2.4273187191432095

Epoch: 6| Step: 5
Training loss: 2.1772226048751193
Validation loss: 2.426665239492858

Epoch: 6| Step: 6
Training loss: 1.1487761536652206
Validation loss: 2.436787277326116

Epoch: 6| Step: 7
Training loss: 1.6105194466952562
Validation loss: 2.4526731149214043

Epoch: 6| Step: 8
Training loss: 1.7079430421180997
Validation loss: 2.4510757480387997

Epoch: 6| Step: 9
Training loss: 1.545787853110028
Validation loss: 2.452517591345635

Epoch: 6| Step: 10
Training loss: 1.692702503683371
Validation loss: 2.4915300360267807

Epoch: 6| Step: 11
Training loss: 1.8622657679795274
Validation loss: 2.495097610656588

Epoch: 6| Step: 12
Training loss: 2.120966954946401
Validation loss: 2.4845243700460387

Epoch: 6| Step: 13
Training loss: 1.5998891136368913
Validation loss: 2.5149791277955478

Epoch: 168| Step: 0
Training loss: 1.6503821739567281
Validation loss: 2.5232916912740784

Epoch: 6| Step: 1
Training loss: 2.081733038123909
Validation loss: 2.583661950321766

Epoch: 6| Step: 2
Training loss: 1.6033394236987595
Validation loss: 2.5647166859221735

Epoch: 6| Step: 3
Training loss: 1.7108145194947744
Validation loss: 2.5483831664504595

Epoch: 6| Step: 4
Training loss: 1.2935644431353261
Validation loss: 2.4968385960221933

Epoch: 6| Step: 5
Training loss: 2.1071082474865825
Validation loss: 2.4957158337967367

Epoch: 6| Step: 6
Training loss: 1.4833669351493695
Validation loss: 2.460600717902914

Epoch: 6| Step: 7
Training loss: 1.8844957860189535
Validation loss: 2.4410108519282154

Epoch: 6| Step: 8
Training loss: 1.5265808541669459
Validation loss: 2.4621529984668675

Epoch: 6| Step: 9
Training loss: 1.9589089163246092
Validation loss: 2.488810797601333

Epoch: 6| Step: 10
Training loss: 1.3730208718671486
Validation loss: 2.5046850010942823

Epoch: 6| Step: 11
Training loss: 2.03841123740334
Validation loss: 2.5276778698075484

Epoch: 6| Step: 12
Training loss: 2.0036701859006607
Validation loss: 2.526144366158321

Epoch: 6| Step: 13
Training loss: 1.5913037993273127
Validation loss: 2.522429476957014

Epoch: 169| Step: 0
Training loss: 1.9163509468219797
Validation loss: 2.505690615824256

Epoch: 6| Step: 1
Training loss: 1.1119629667413824
Validation loss: 2.5154387773851528

Epoch: 6| Step: 2
Training loss: 1.1093239033711648
Validation loss: 2.5043887439992703

Epoch: 6| Step: 3
Training loss: 1.81663757820056
Validation loss: 2.547440810837214

Epoch: 6| Step: 4
Training loss: 1.9337239539495095
Validation loss: 2.5237286045884852

Epoch: 6| Step: 5
Training loss: 1.931363385770028
Validation loss: 2.494951496394668

Epoch: 6| Step: 6
Training loss: 1.6819547743007148
Validation loss: 2.474320172120427

Epoch: 6| Step: 7
Training loss: 1.350559457780006
Validation loss: 2.4344463851993066

Epoch: 6| Step: 8
Training loss: 1.8461760384344519
Validation loss: 2.4642754385769248

Epoch: 6| Step: 9
Training loss: 2.057347885200689
Validation loss: 2.4517350782681397

Epoch: 6| Step: 10
Training loss: 1.7723814386871921
Validation loss: 2.4700990529131324

Epoch: 6| Step: 11
Training loss: 1.6513255343606599
Validation loss: 2.4727805815495727

Epoch: 6| Step: 12
Training loss: 2.0400385950214877
Validation loss: 2.504667909484281

Epoch: 6| Step: 13
Training loss: 1.3664479026312963
Validation loss: 2.5403001992964582

Epoch: 170| Step: 0
Training loss: 1.5063483684915253
Validation loss: 2.543088979651083

Epoch: 6| Step: 1
Training loss: 1.9175474244063462
Validation loss: 2.54353489559539

Epoch: 6| Step: 2
Training loss: 1.5268354814109908
Validation loss: 2.530020036826784

Epoch: 6| Step: 3
Training loss: 1.1584101937314424
Validation loss: 2.527129003553407

Epoch: 6| Step: 4
Training loss: 1.863686379588318
Validation loss: 2.546816680943095

Epoch: 6| Step: 5
Training loss: 1.8241816318828104
Validation loss: 2.560327213505349

Epoch: 6| Step: 6
Training loss: 1.3118605191184405
Validation loss: 2.549777894759789

Epoch: 6| Step: 7
Training loss: 1.8316596006003172
Validation loss: 2.5544087724331286

Epoch: 6| Step: 8
Training loss: 1.5440623596722514
Validation loss: 2.567081584508956

Epoch: 6| Step: 9
Training loss: 1.9617851218750744
Validation loss: 2.560146015909856

Epoch: 6| Step: 10
Training loss: 1.3992446189887318
Validation loss: 2.569197824606855

Epoch: 6| Step: 11
Training loss: 1.7689452558923682
Validation loss: 2.5781701216690944

Epoch: 6| Step: 12
Training loss: 1.8858865043616422
Validation loss: 2.564642625938017

Epoch: 6| Step: 13
Training loss: 2.0065081326329133
Validation loss: 2.5412395342984238

Epoch: 171| Step: 0
Training loss: 1.4963582654136274
Validation loss: 2.48286577012172

Epoch: 6| Step: 1
Training loss: 1.3443507248989213
Validation loss: 2.448000455917741

Epoch: 6| Step: 2
Training loss: 1.948457802526793
Validation loss: 2.4195484388134907

Epoch: 6| Step: 3
Training loss: 1.6779435441496582
Validation loss: 2.3991931097675327

Epoch: 6| Step: 4
Training loss: 1.5073932598528672
Validation loss: 2.378810729038005

Epoch: 6| Step: 5
Training loss: 1.8532891572288777
Validation loss: 2.3708920305589336

Epoch: 6| Step: 6
Training loss: 1.4028607533824364
Validation loss: 2.4139750629055974

Epoch: 6| Step: 7
Training loss: 1.4486801092422663
Validation loss: 2.464806161134974

Epoch: 6| Step: 8
Training loss: 1.8211315751699026
Validation loss: 2.512516675353074

Epoch: 6| Step: 9
Training loss: 1.430657313204003
Validation loss: 2.562764679099951

Epoch: 6| Step: 10
Training loss: 2.249992476556703
Validation loss: 2.5839965205900453

Epoch: 6| Step: 11
Training loss: 1.6924996663125638
Validation loss: 2.5853854767035034

Epoch: 6| Step: 12
Training loss: 1.9276810689897474
Validation loss: 2.579673484033295

Epoch: 6| Step: 13
Training loss: 1.3366913481088099
Validation loss: 2.5843962375854317

Epoch: 172| Step: 0
Training loss: 1.9219081844783374
Validation loss: 2.594596259206632

Epoch: 6| Step: 1
Training loss: 1.9088700845912516
Validation loss: 2.6001584209078175

Epoch: 6| Step: 2
Training loss: 1.708833559193558
Validation loss: 2.621027458779026

Epoch: 6| Step: 3
Training loss: 1.2682279029333359
Validation loss: 2.6224473084103037

Epoch: 6| Step: 4
Training loss: 1.6605232820380538
Validation loss: 2.6088086361525233

Epoch: 6| Step: 5
Training loss: 1.9292517413281882
Validation loss: 2.609687200453884

Epoch: 6| Step: 6
Training loss: 1.3367469521540034
Validation loss: 2.559410159220245

Epoch: 6| Step: 7
Training loss: 1.4027745002397745
Validation loss: 2.5481633538152066

Epoch: 6| Step: 8
Training loss: 1.3352568381483847
Validation loss: 2.5303053435766545

Epoch: 6| Step: 9
Training loss: 1.5652523975558061
Validation loss: 2.505866877076464

Epoch: 6| Step: 10
Training loss: 1.7394550603602668
Validation loss: 2.4874558274458214

Epoch: 6| Step: 11
Training loss: 1.434397957811322
Validation loss: 2.4757284820902536

Epoch: 6| Step: 12
Training loss: 1.4903355635339997
Validation loss: 2.4604341480826473

Epoch: 6| Step: 13
Training loss: 2.124685039740461
Validation loss: 2.399481664164853

Epoch: 173| Step: 0
Training loss: 1.8161290111005157
Validation loss: 2.3645352139188414

Epoch: 6| Step: 1
Training loss: 1.417454313588138
Validation loss: 2.344629276741007

Epoch: 6| Step: 2
Training loss: 1.2321959952038124
Validation loss: 2.3534921922633263

Epoch: 6| Step: 3
Training loss: 1.4485453148871859
Validation loss: 2.3673174086792153

Epoch: 6| Step: 4
Training loss: 1.6975710542440199
Validation loss: 2.394308185979107

Epoch: 6| Step: 5
Training loss: 2.0492041927261244
Validation loss: 2.424042686498153

Epoch: 6| Step: 6
Training loss: 1.6778186426105341
Validation loss: 2.4669796052835076

Epoch: 6| Step: 7
Training loss: 1.689370425631264
Validation loss: 2.4872945506409514

Epoch: 6| Step: 8
Training loss: 1.0363460972015162
Validation loss: 2.5401722431378224

Epoch: 6| Step: 9
Training loss: 1.3380688179690512
Validation loss: 2.5739203080622017

Epoch: 6| Step: 10
Training loss: 2.067011666983356
Validation loss: 2.5937270059565853

Epoch: 6| Step: 11
Training loss: 1.1602973210014615
Validation loss: 2.6193762384028285

Epoch: 6| Step: 12
Training loss: 1.655644432060398
Validation loss: 2.651284660215719

Epoch: 6| Step: 13
Training loss: 1.9743061681850773
Validation loss: 2.6625563421493217

Epoch: 174| Step: 0
Training loss: 0.8760301112177554
Validation loss: 2.643985022924554

Epoch: 6| Step: 1
Training loss: 1.1631470735434484
Validation loss: 2.6069467451251027

Epoch: 6| Step: 2
Training loss: 1.3984407392922504
Validation loss: 2.57902271778804

Epoch: 6| Step: 3
Training loss: 1.2308057051191985
Validation loss: 2.5700695348026232

Epoch: 6| Step: 4
Training loss: 1.8834083848813388
Validation loss: 2.551958824336658

Epoch: 6| Step: 5
Training loss: 1.779367623456237
Validation loss: 2.509941907523462

Epoch: 6| Step: 6
Training loss: 1.673687033120534
Validation loss: 2.474346579034516

Epoch: 6| Step: 7
Training loss: 1.4943652813131536
Validation loss: 2.4685029113492876

Epoch: 6| Step: 8
Training loss: 1.603313772527661
Validation loss: 2.448323188876098

Epoch: 6| Step: 9
Training loss: 1.723471381648978
Validation loss: 2.458442915665253

Epoch: 6| Step: 10
Training loss: 1.933248284815056
Validation loss: 2.468826049779766

Epoch: 6| Step: 11
Training loss: 2.118404700124776
Validation loss: 2.4595057742127002

Epoch: 6| Step: 12
Training loss: 1.1135541079581193
Validation loss: 2.459213308602304

Epoch: 6| Step: 13
Training loss: 1.7280761159981077
Validation loss: 2.4716677637527673

Epoch: 175| Step: 0
Training loss: 1.92687548642024
Validation loss: 2.5083336888974888

Epoch: 6| Step: 1
Training loss: 1.955621573328446
Validation loss: 2.5286811043891833

Epoch: 6| Step: 2
Training loss: 1.6156828141336532
Validation loss: 2.532580090144441

Epoch: 6| Step: 3
Training loss: 1.334293536305948
Validation loss: 2.553029320794061

Epoch: 6| Step: 4
Training loss: 1.3971954029451017
Validation loss: 2.60130583331441

Epoch: 6| Step: 5
Training loss: 1.3517259267445176
Validation loss: 2.5544006240773363

Epoch: 6| Step: 6
Training loss: 1.3753899541504906
Validation loss: 2.543360193515239

Epoch: 6| Step: 7
Training loss: 1.5943865533318176
Validation loss: 2.5045661194353492

Epoch: 6| Step: 8
Training loss: 1.4999907811199455
Validation loss: 2.4881119919963823

Epoch: 6| Step: 9
Training loss: 1.6960247319190624
Validation loss: 2.4532694740408596

Epoch: 6| Step: 10
Training loss: 1.4607177405894438
Validation loss: 2.428521624580359

Epoch: 6| Step: 11
Training loss: 1.7731931408820687
Validation loss: 2.429839479601969

Epoch: 6| Step: 12
Training loss: 0.9110739996635038
Validation loss: 2.443866965975974

Epoch: 6| Step: 13
Training loss: 1.646347746152184
Validation loss: 2.4618621969226853

Epoch: 176| Step: 0
Training loss: 1.7697965242058378
Validation loss: 2.4731858406317455

Epoch: 6| Step: 1
Training loss: 1.2666055154260791
Validation loss: 2.4991008177198193

Epoch: 6| Step: 2
Training loss: 1.2230849809293511
Validation loss: 2.507809711268569

Epoch: 6| Step: 3
Training loss: 1.8269759259321254
Validation loss: 2.550285623998826

Epoch: 6| Step: 4
Training loss: 1.6053783084984101
Validation loss: 2.574727348964578

Epoch: 6| Step: 5
Training loss: 1.4025905891306178
Validation loss: 2.6134158050355896

Epoch: 6| Step: 6
Training loss: 1.4883933838580123
Validation loss: 2.6146723208310156

Epoch: 6| Step: 7
Training loss: 1.3265056836078009
Validation loss: 2.5687598226445414

Epoch: 6| Step: 8
Training loss: 1.5232113401339442
Validation loss: 2.5265957220376745

Epoch: 6| Step: 9
Training loss: 1.6043088858177816
Validation loss: 2.468773288910317

Epoch: 6| Step: 10
Training loss: 1.5734882789759532
Validation loss: 2.4270321619106583

Epoch: 6| Step: 11
Training loss: 1.6901227561112528
Validation loss: 2.411469035972145

Epoch: 6| Step: 12
Training loss: 1.3249810199457774
Validation loss: 2.392343967842127

Epoch: 6| Step: 13
Training loss: 1.804221683512036
Validation loss: 2.3941603606225152

Epoch: 177| Step: 0
Training loss: 1.7120757475432937
Validation loss: 2.4265885387209205

Epoch: 6| Step: 1
Training loss: 1.9169518286274692
Validation loss: 2.4643261896564463

Epoch: 6| Step: 2
Training loss: 1.3527721658616807
Validation loss: 2.524533869887719

Epoch: 6| Step: 3
Training loss: 1.439439625980844
Validation loss: 2.5153922634020693

Epoch: 6| Step: 4
Training loss: 1.2325171480668862
Validation loss: 2.528796255075427

Epoch: 6| Step: 5
Training loss: 1.5950026731558375
Validation loss: 2.5091670663911856

Epoch: 6| Step: 6
Training loss: 1.2548723628577565
Validation loss: 2.5120007029399747

Epoch: 6| Step: 7
Training loss: 0.9233216395366357
Validation loss: 2.5308585107891948

Epoch: 6| Step: 8
Training loss: 1.5204512059449404
Validation loss: 2.5304082749377224

Epoch: 6| Step: 9
Training loss: 1.299581988693639
Validation loss: 2.526318361135632

Epoch: 6| Step: 10
Training loss: 1.6801996913939143
Validation loss: 2.4999789452435284

Epoch: 6| Step: 11
Training loss: 1.8917714575872264
Validation loss: 2.492703079762424

Epoch: 6| Step: 12
Training loss: 1.9582657565638757
Validation loss: 2.4806572381699104

Epoch: 6| Step: 13
Training loss: 0.7486893009298198
Validation loss: 2.4468046498503204

Epoch: 178| Step: 0
Training loss: 0.9460280996488237
Validation loss: 2.434399457874975

Epoch: 6| Step: 1
Training loss: 1.45499496734378
Validation loss: 2.430896444679817

Epoch: 6| Step: 2
Training loss: 1.751060028554788
Validation loss: 2.4747315184424568

Epoch: 6| Step: 3
Training loss: 1.381480291854881
Validation loss: 2.478059262483796

Epoch: 6| Step: 4
Training loss: 1.7785158421687834
Validation loss: 2.497925270727582

Epoch: 6| Step: 5
Training loss: 1.7758642053926514
Validation loss: 2.5207539021049135

Epoch: 6| Step: 6
Training loss: 1.401412909954781
Validation loss: 2.526196259636455

Epoch: 6| Step: 7
Training loss: 1.8331951031447382
Validation loss: 2.5593290791411176

Epoch: 6| Step: 8
Training loss: 1.9562700508235737
Validation loss: 2.5100657975651006

Epoch: 6| Step: 9
Training loss: 0.9550621483837534
Validation loss: 2.46090145367906

Epoch: 6| Step: 10
Training loss: 1.2679602659720786
Validation loss: 2.4516322444013596

Epoch: 6| Step: 11
Training loss: 1.356653844240096
Validation loss: 2.446118230931667

Epoch: 6| Step: 12
Training loss: 1.497927187200465
Validation loss: 2.47372443155056

Epoch: 6| Step: 13
Training loss: 0.7439211223792623
Validation loss: 2.510860317281496

Epoch: 179| Step: 0
Training loss: 0.9971635048231846
Validation loss: 2.522069242794125

Epoch: 6| Step: 1
Training loss: 1.8100438411946018
Validation loss: 2.5642218668616366

Epoch: 6| Step: 2
Training loss: 1.5094265378126153
Validation loss: 2.599478049181689

Epoch: 6| Step: 3
Training loss: 1.4075705791414466
Validation loss: 2.53079257580879

Epoch: 6| Step: 4
Training loss: 1.5072538299486578
Validation loss: 2.5229517768522323

Epoch: 6| Step: 5
Training loss: 1.810958667331904
Validation loss: 2.498725531393723

Epoch: 6| Step: 6
Training loss: 1.5705874377919098
Validation loss: 2.4521882328841054

Epoch: 6| Step: 7
Training loss: 1.3652889475468477
Validation loss: 2.466387191098504

Epoch: 6| Step: 8
Training loss: 1.329279588468678
Validation loss: 2.428141840060756

Epoch: 6| Step: 9
Training loss: 1.6113750289101436
Validation loss: 2.4297734748415

Epoch: 6| Step: 10
Training loss: 1.2683964278927213
Validation loss: 2.415558026765061

Epoch: 6| Step: 11
Training loss: 1.7247075261389146
Validation loss: 2.433769452936317

Epoch: 6| Step: 12
Training loss: 1.2917387952457038
Validation loss: 2.4218569519026776

Epoch: 6| Step: 13
Training loss: 1.35308311344712
Validation loss: 2.4445273197536945

Epoch: 180| Step: 0
Training loss: 1.43313000737616
Validation loss: 2.4593521441703885

Epoch: 6| Step: 1
Training loss: 1.7636717398169246
Validation loss: 2.497327487695606

Epoch: 6| Step: 2
Training loss: 1.7827864595696268
Validation loss: 2.523693627814086

Epoch: 6| Step: 3
Training loss: 1.7605122497011079
Validation loss: 2.5682547988541

Epoch: 6| Step: 4
Training loss: 1.077283060578866
Validation loss: 2.5657109058259944

Epoch: 6| Step: 5
Training loss: 0.8049265682302454
Validation loss: 2.5350381622173273

Epoch: 6| Step: 6
Training loss: 1.8145961479263009
Validation loss: 2.5129600538380252

Epoch: 6| Step: 7
Training loss: 1.3530333349177173
Validation loss: 2.5129628246119244

Epoch: 6| Step: 8
Training loss: 1.360973558265745
Validation loss: 2.483943291585899

Epoch: 6| Step: 9
Training loss: 1.5041736711812739
Validation loss: 2.474145740778956

Epoch: 6| Step: 10
Training loss: 1.2487450976270762
Validation loss: 2.451633030758063

Epoch: 6| Step: 11
Training loss: 1.0086330060462652
Validation loss: 2.47182762389227

Epoch: 6| Step: 12
Training loss: 1.7121205877188876
Validation loss: 2.452350407162802

Epoch: 6| Step: 13
Training loss: 0.48009265353114794
Validation loss: 2.434960058204375

Epoch: 181| Step: 0
Training loss: 1.251317760145711
Validation loss: 2.4249294342203576

Epoch: 6| Step: 1
Training loss: 1.6835684719090944
Validation loss: 2.443466647796139

Epoch: 6| Step: 2
Training loss: 1.4800201783222304
Validation loss: 2.4323542728857204

Epoch: 6| Step: 3
Training loss: 1.3267589050764677
Validation loss: 2.4538379524328793

Epoch: 6| Step: 4
Training loss: 1.8059286498278504
Validation loss: 2.439999966704612

Epoch: 6| Step: 5
Training loss: 1.1075709543684193
Validation loss: 2.4509106390821773

Epoch: 6| Step: 6
Training loss: 1.1353653129140024
Validation loss: 2.453633222519839

Epoch: 6| Step: 7
Training loss: 1.5542978536483394
Validation loss: 2.437894355419357

Epoch: 6| Step: 8
Training loss: 1.4284464134283712
Validation loss: 2.4067477012653664

Epoch: 6| Step: 9
Training loss: 1.3796806430322246
Validation loss: 2.4001024426452626

Epoch: 6| Step: 10
Training loss: 1.5757051554488102
Validation loss: 2.383805670582084

Epoch: 6| Step: 11
Training loss: 1.1023976832550964
Validation loss: 2.3879232724964883

Epoch: 6| Step: 12
Training loss: 1.5055645407908678
Validation loss: 2.384166983605675

Epoch: 6| Step: 13
Training loss: 1.2961540056401382
Validation loss: 2.3730102282358563

Epoch: 182| Step: 0
Training loss: 1.170963594152511
Validation loss: 2.415690551304796

Epoch: 6| Step: 1
Training loss: 1.2425202697697024
Validation loss: 2.4366715534997785

Epoch: 6| Step: 2
Training loss: 1.1154316261740889
Validation loss: 2.4581371974411175

Epoch: 6| Step: 3
Training loss: 1.1564084537290789
Validation loss: 2.5003388082973004

Epoch: 6| Step: 4
Training loss: 1.5465721065017082
Validation loss: 2.523947409717993

Epoch: 6| Step: 5
Training loss: 1.3045192769952172
Validation loss: 2.561797843433911

Epoch: 6| Step: 6
Training loss: 1.7215135724643105
Validation loss: 2.5879953789710397

Epoch: 6| Step: 7
Training loss: 1.3213875361002987
Validation loss: 2.581660490879508

Epoch: 6| Step: 8
Training loss: 1.3450690161004473
Validation loss: 2.6088071355900357

Epoch: 6| Step: 9
Training loss: 1.9936850510305375
Validation loss: 2.61892005070101

Epoch: 6| Step: 10
Training loss: 1.3792982543834702
Validation loss: 2.610069915785222

Epoch: 6| Step: 11
Training loss: 1.4271499543986568
Validation loss: 2.5916265237924923

Epoch: 6| Step: 12
Training loss: 1.3061613792035611
Validation loss: 2.5001460965855187

Epoch: 6| Step: 13
Training loss: 1.0523487297682266
Validation loss: 2.4538355850343003

Epoch: 183| Step: 0
Training loss: 1.1806431619389195
Validation loss: 2.4043549073598145

Epoch: 6| Step: 1
Training loss: 1.3416795970854412
Validation loss: 2.3786509214662375

Epoch: 6| Step: 2
Training loss: 1.3842944377940365
Validation loss: 2.3797122997364473

Epoch: 6| Step: 3
Training loss: 1.2312884310228813
Validation loss: 2.3838462078832867

Epoch: 6| Step: 4
Training loss: 1.2985390707196394
Validation loss: 2.3814552157335727

Epoch: 6| Step: 5
Training loss: 1.3920583303277165
Validation loss: 2.410425427439937

Epoch: 6| Step: 6
Training loss: 1.2502616608458625
Validation loss: 2.4212631357724708

Epoch: 6| Step: 7
Training loss: 1.1164641806412636
Validation loss: 2.451499145712328

Epoch: 6| Step: 8
Training loss: 1.8288795022748061
Validation loss: 2.477372852850589

Epoch: 6| Step: 9
Training loss: 1.3909011738031085
Validation loss: 2.5048491282463936

Epoch: 6| Step: 10
Training loss: 1.4474293645777312
Validation loss: 2.524397923504493

Epoch: 6| Step: 11
Training loss: 1.055507764794048
Validation loss: 2.5149294941995666

Epoch: 6| Step: 12
Training loss: 1.4825291450298834
Validation loss: 2.547056105995612

Epoch: 6| Step: 13
Training loss: 2.1758139041114495
Validation loss: 2.5417271406328066

Epoch: 184| Step: 0
Training loss: 1.1376631441602951
Validation loss: 2.5321459337316607

Epoch: 6| Step: 1
Training loss: 1.3164778330552482
Validation loss: 2.5348082356213775

Epoch: 6| Step: 2
Training loss: 1.2910502511371522
Validation loss: 2.55074223299128

Epoch: 6| Step: 3
Training loss: 1.4035839664033745
Validation loss: 2.5298632447993428

Epoch: 6| Step: 4
Training loss: 1.25688952588869
Validation loss: 2.478037426961019

Epoch: 6| Step: 5
Training loss: 1.3521231221759682
Validation loss: 2.4532525785937995

Epoch: 6| Step: 6
Training loss: 1.005512007202964
Validation loss: 2.435753930272788

Epoch: 6| Step: 7
Training loss: 1.5690893467298923
Validation loss: 2.417720386914617

Epoch: 6| Step: 8
Training loss: 1.4534444150266022
Validation loss: 2.4263998705899166

Epoch: 6| Step: 9
Training loss: 1.3390357692547608
Validation loss: 2.4096581345899093

Epoch: 6| Step: 10
Training loss: 0.9616705106882083
Validation loss: 2.417736584305168

Epoch: 6| Step: 11
Training loss: 1.7264687353021573
Validation loss: 2.4173298676454533

Epoch: 6| Step: 12
Training loss: 1.6084103702549535
Validation loss: 2.4478164271818357

Epoch: 6| Step: 13
Training loss: 1.7604253719799283
Validation loss: 2.474498330698814

Epoch: 185| Step: 0
Training loss: 0.9770476700076963
Validation loss: 2.5056354021477167

Epoch: 6| Step: 1
Training loss: 1.2586449184707482
Validation loss: 2.5110525783493816

Epoch: 6| Step: 2
Training loss: 1.4877138833540424
Validation loss: 2.540701262872016

Epoch: 6| Step: 3
Training loss: 1.064908159621164
Validation loss: 2.5109158448842637

Epoch: 6| Step: 4
Training loss: 1.46544502633624
Validation loss: 2.505815683884477

Epoch: 6| Step: 5
Training loss: 1.4302139563657168
Validation loss: 2.4740985996829683

Epoch: 6| Step: 6
Training loss: 1.4381090615395205
Validation loss: 2.450666281911444

Epoch: 6| Step: 7
Training loss: 1.3973926071639704
Validation loss: 2.4199049893265103

Epoch: 6| Step: 8
Training loss: 1.584344900473573
Validation loss: 2.413013362358789

Epoch: 6| Step: 9
Training loss: 1.4331997945959447
Validation loss: 2.404787555412502

Epoch: 6| Step: 10
Training loss: 1.4221714255745344
Validation loss: 2.4211616029078065

Epoch: 6| Step: 11
Training loss: 1.1096028913225102
Validation loss: 2.4205035886088226

Epoch: 6| Step: 12
Training loss: 1.0777065183628054
Validation loss: 2.4224461353424007

Epoch: 6| Step: 13
Training loss: 1.2995943720427128
Validation loss: 2.4175029859163746

Epoch: 186| Step: 0
Training loss: 1.3308341724549961
Validation loss: 2.3971584060268043

Epoch: 6| Step: 1
Training loss: 1.528815689484691
Validation loss: 2.452825545361305

Epoch: 6| Step: 2
Training loss: 1.657461191358819
Validation loss: 2.4017470637824205

Epoch: 6| Step: 3
Training loss: 0.8147961742523859
Validation loss: 2.4283580943554965

Epoch: 6| Step: 4
Training loss: 1.1294585991947301
Validation loss: 2.437754437650596

Epoch: 6| Step: 5
Training loss: 1.0701072106172194
Validation loss: 2.432774862142294

Epoch: 6| Step: 6
Training loss: 1.5714986695718793
Validation loss: 2.4333225156307887

Epoch: 6| Step: 7
Training loss: 1.3013881149796327
Validation loss: 2.4575245286092566

Epoch: 6| Step: 8
Training loss: 1.1331129004647265
Validation loss: 2.4523162553715863

Epoch: 6| Step: 9
Training loss: 0.7860381454427997
Validation loss: 2.463266979968317

Epoch: 6| Step: 10
Training loss: 1.70344267515979
Validation loss: 2.4259103041172345

Epoch: 6| Step: 11
Training loss: 1.33785703296674
Validation loss: 2.378956464968295

Epoch: 6| Step: 12
Training loss: 1.3171386492484358
Validation loss: 2.422757055137459

Epoch: 6| Step: 13
Training loss: 1.0768388457159894
Validation loss: 2.3890578422537736

Epoch: 187| Step: 0
Training loss: 1.1911009350404456
Validation loss: 2.3905446800912054

Epoch: 6| Step: 1
Training loss: 0.9000696367238196
Validation loss: 2.4130247823154347

Epoch: 6| Step: 2
Training loss: 1.305479437500668
Validation loss: 2.4255632804545653

Epoch: 6| Step: 3
Training loss: 1.0339371322025184
Validation loss: 2.445564901490897

Epoch: 6| Step: 4
Training loss: 1.4106393340620123
Validation loss: 2.454851925133189

Epoch: 6| Step: 5
Training loss: 1.2857293703314512
Validation loss: 2.44960218292494

Epoch: 6| Step: 6
Training loss: 0.9154425416454551
Validation loss: 2.444192598914084

Epoch: 6| Step: 7
Training loss: 1.1169169171648077
Validation loss: 2.431479587222927

Epoch: 6| Step: 8
Training loss: 1.1784666704296727
Validation loss: 2.417688393157484

Epoch: 6| Step: 9
Training loss: 1.629335049694383
Validation loss: 2.4321681274511584

Epoch: 6| Step: 10
Training loss: 1.494469779665271
Validation loss: 2.422454191001425

Epoch: 6| Step: 11
Training loss: 1.536777717455798
Validation loss: 2.4222840597816697

Epoch: 6| Step: 12
Training loss: 1.222547581142613
Validation loss: 2.4454845850306075

Epoch: 6| Step: 13
Training loss: 1.3703256395464682
Validation loss: 2.46993634696953

Epoch: 188| Step: 0
Training loss: 1.2133093954089913
Validation loss: 2.479727922378093

Epoch: 6| Step: 1
Training loss: 1.159966604228902
Validation loss: 2.5034205160884455

Epoch: 6| Step: 2
Training loss: 1.596775698327045
Validation loss: 2.533667799864341

Epoch: 6| Step: 3
Training loss: 1.58527770199926
Validation loss: 2.5169303848228566

Epoch: 6| Step: 4
Training loss: 1.4395336195904396
Validation loss: 2.5021108370903677

Epoch: 6| Step: 5
Training loss: 1.6896598557132834
Validation loss: 2.4954542763733834

Epoch: 6| Step: 6
Training loss: 1.1822638263309333
Validation loss: 2.4848104796825026

Epoch: 6| Step: 7
Training loss: 1.0245650392015815
Validation loss: 2.4285243365138447

Epoch: 6| Step: 8
Training loss: 1.0431738948162237
Validation loss: 2.3920819232207884

Epoch: 6| Step: 9
Training loss: 1.0438751396952917
Validation loss: 2.391196639200825

Epoch: 6| Step: 10
Training loss: 1.384032750932906
Validation loss: 2.373858051553889

Epoch: 6| Step: 11
Training loss: 0.7894674338545076
Validation loss: 2.359684175855633

Epoch: 6| Step: 12
Training loss: 1.0224598881844544
Validation loss: 2.386663216416638

Epoch: 6| Step: 13
Training loss: 1.5081010453447643
Validation loss: 2.368123743906312

Epoch: 189| Step: 0
Training loss: 1.6924098607547124
Validation loss: 2.369510600882011

Epoch: 6| Step: 1
Training loss: 0.77486076796302
Validation loss: 2.3470429895127887

Epoch: 6| Step: 2
Training loss: 1.223561886910946
Validation loss: 2.3760757217555852

Epoch: 6| Step: 3
Training loss: 1.0959177605967214
Validation loss: 2.375946993839165

Epoch: 6| Step: 4
Training loss: 1.4369776232735214
Validation loss: 2.393046403253894

Epoch: 6| Step: 5
Training loss: 1.3878029466801427
Validation loss: 2.418457043970378

Epoch: 6| Step: 6
Training loss: 1.194618821660896
Validation loss: 2.455633133888207

Epoch: 6| Step: 7
Training loss: 1.0203774985016807
Validation loss: 2.504183297914832

Epoch: 6| Step: 8
Training loss: 1.187226213716152
Validation loss: 2.5506457999958587

Epoch: 6| Step: 9
Training loss: 1.5569329077120893
Validation loss: 2.5733531116582236

Epoch: 6| Step: 10
Training loss: 1.4211210830182195
Validation loss: 2.5508596530759577

Epoch: 6| Step: 11
Training loss: 1.1055343123226236
Validation loss: 2.537057211627644

Epoch: 6| Step: 12
Training loss: 1.157223678134591
Validation loss: 2.5262633268385732

Epoch: 6| Step: 13
Training loss: 1.1359302105991131
Validation loss: 2.4622915662477136

Epoch: 190| Step: 0
Training loss: 1.1349390524410274
Validation loss: 2.418502998549152

Epoch: 6| Step: 1
Training loss: 1.214730211453573
Validation loss: 2.331816536440422

Epoch: 6| Step: 2
Training loss: 0.908260614359894
Validation loss: 2.333049807118221

Epoch: 6| Step: 3
Training loss: 1.6261239199837478
Validation loss: 2.3444827765719944

Epoch: 6| Step: 4
Training loss: 0.8955589953722757
Validation loss: 2.3624656398688098

Epoch: 6| Step: 5
Training loss: 1.5570008209363553
Validation loss: 2.384413230896035

Epoch: 6| Step: 6
Training loss: 1.331826694924691
Validation loss: 2.4049733406519804

Epoch: 6| Step: 7
Training loss: 1.2758472320444094
Validation loss: 2.4197729678803483

Epoch: 6| Step: 8
Training loss: 1.1352470807926538
Validation loss: 2.487850433761173

Epoch: 6| Step: 9
Training loss: 1.3870813030129896
Validation loss: 2.511420770651936

Epoch: 6| Step: 10
Training loss: 1.4697757142424832
Validation loss: 2.475689151051819

Epoch: 6| Step: 11
Training loss: 1.185620376344633
Validation loss: 2.505811912822402

Epoch: 6| Step: 12
Training loss: 1.0744515461529744
Validation loss: 2.5198662317298166

Epoch: 6| Step: 13
Training loss: 0.7231101183072982
Validation loss: 2.5036332975103206

Epoch: 191| Step: 0
Training loss: 1.1430033096439107
Validation loss: 2.513564545763936

Epoch: 6| Step: 1
Training loss: 0.9602474433171669
Validation loss: 2.493745608720026

Epoch: 6| Step: 2
Training loss: 0.9316104268232095
Validation loss: 2.502066238289046

Epoch: 6| Step: 3
Training loss: 1.0985245172319626
Validation loss: 2.447891175175098

Epoch: 6| Step: 4
Training loss: 1.5435787492044997
Validation loss: 2.4820882052875004

Epoch: 6| Step: 5
Training loss: 1.3408957930377197
Validation loss: 2.4190457917127213

Epoch: 6| Step: 6
Training loss: 1.7049061971461963
Validation loss: 2.444007738000823

Epoch: 6| Step: 7
Training loss: 0.7132225204640218
Validation loss: 2.444851223699463

Epoch: 6| Step: 8
Training loss: 1.4712093135682067
Validation loss: 2.462687862499679

Epoch: 6| Step: 9
Training loss: 1.3665035171742683
Validation loss: 2.430062606287265

Epoch: 6| Step: 10
Training loss: 1.2506550026439855
Validation loss: 2.449145459822983

Epoch: 6| Step: 11
Training loss: 1.111831631428472
Validation loss: 2.4520191328047702

Epoch: 6| Step: 12
Training loss: 1.3380571916015103
Validation loss: 2.408325717012858

Epoch: 6| Step: 13
Training loss: 0.7571693522773533
Validation loss: 2.395376871576794

Epoch: 192| Step: 0
Training loss: 1.188223367518988
Validation loss: 2.3429499682000157

Epoch: 6| Step: 1
Training loss: 1.2219098039826461
Validation loss: 2.344600771920875

Epoch: 6| Step: 2
Training loss: 1.3097818475453
Validation loss: 2.328789722296566

Epoch: 6| Step: 3
Training loss: 1.4013347342850433
Validation loss: 2.3426678867352435

Epoch: 6| Step: 4
Training loss: 1.3463567245527968
Validation loss: 2.379285104533823

Epoch: 6| Step: 5
Training loss: 1.5719952273793851
Validation loss: 2.4128964993853232

Epoch: 6| Step: 6
Training loss: 0.846243036261211
Validation loss: 2.422018253192872

Epoch: 6| Step: 7
Training loss: 0.9488752709113086
Validation loss: 2.4345106173640683

Epoch: 6| Step: 8
Training loss: 1.3764911715400716
Validation loss: 2.4597290874509916

Epoch: 6| Step: 9
Training loss: 0.6720529808463642
Validation loss: 2.482447227053666

Epoch: 6| Step: 10
Training loss: 1.2860548130444698
Validation loss: 2.486280896273524

Epoch: 6| Step: 11
Training loss: 1.1602265821517181
Validation loss: 2.508121138612346

Epoch: 6| Step: 12
Training loss: 1.3072294496521186
Validation loss: 2.4877900684400203

Epoch: 6| Step: 13
Training loss: 0.8064726499920761
Validation loss: 2.4507608919341792

Epoch: 193| Step: 0
Training loss: 1.3988560311336289
Validation loss: 2.453939885267428

Epoch: 6| Step: 1
Training loss: 1.0333379358271164
Validation loss: 2.4242559346317116

Epoch: 6| Step: 2
Training loss: 1.2274229105498942
Validation loss: 2.3978044324342322

Epoch: 6| Step: 3
Training loss: 1.0284523439915407
Validation loss: 2.3871269442943195

Epoch: 6| Step: 4
Training loss: 1.2600798458958213
Validation loss: 2.368726266699911

Epoch: 6| Step: 5
Training loss: 1.2267184796136839
Validation loss: 2.399393134787315

Epoch: 6| Step: 6
Training loss: 1.472832059610963
Validation loss: 2.428524035129405

Epoch: 6| Step: 7
Training loss: 0.7595939540347221
Validation loss: 2.413953565813269

Epoch: 6| Step: 8
Training loss: 0.8618161296033551
Validation loss: 2.3966801169270457

Epoch: 6| Step: 9
Training loss: 1.1811862040251768
Validation loss: 2.396429656631325

Epoch: 6| Step: 10
Training loss: 1.4040061851430434
Validation loss: 2.394281520547195

Epoch: 6| Step: 11
Training loss: 1.346926992169623
Validation loss: 2.402232222590687

Epoch: 6| Step: 12
Training loss: 1.1286288121795238
Validation loss: 2.4261931973061985

Epoch: 6| Step: 13
Training loss: 1.2368419477413544
Validation loss: 2.4516999626967406

Epoch: 194| Step: 0
Training loss: 1.1262388296134354
Validation loss: 2.4399264489981443

Epoch: 6| Step: 1
Training loss: 1.1736779648488822
Validation loss: 2.492951044100291

Epoch: 6| Step: 2
Training loss: 0.6814288490779822
Validation loss: 2.5063571253507018

Epoch: 6| Step: 3
Training loss: 1.3871448130956512
Validation loss: 2.5301896951797382

Epoch: 6| Step: 4
Training loss: 1.1184973340844693
Validation loss: 2.499038458052754

Epoch: 6| Step: 5
Training loss: 1.6035047709647114
Validation loss: 2.53853784635492

Epoch: 6| Step: 6
Training loss: 1.6454560133028404
Validation loss: 2.4777594892007544

Epoch: 6| Step: 7
Training loss: 1.0489037058501214
Validation loss: 2.4083172851662527

Epoch: 6| Step: 8
Training loss: 1.1176638887971768
Validation loss: 2.413974667841701

Epoch: 6| Step: 9
Training loss: 1.4063286229513061
Validation loss: 2.3533678963864304

Epoch: 6| Step: 10
Training loss: 1.1009746633380983
Validation loss: 2.3429529870779486

Epoch: 6| Step: 11
Training loss: 0.7179754063875716
Validation loss: 2.3293710311398486

Epoch: 6| Step: 12
Training loss: 1.1546725776750857
Validation loss: 2.3151712484821876

Epoch: 6| Step: 13
Training loss: 1.158355805753078
Validation loss: 2.3155454898330814

Epoch: 195| Step: 0
Training loss: 1.6189858577739706
Validation loss: 2.316550501368155

Epoch: 6| Step: 1
Training loss: 1.4754763852242747
Validation loss: 2.325765756254411

Epoch: 6| Step: 2
Training loss: 1.172810295706674
Validation loss: 2.375170884517933

Epoch: 6| Step: 3
Training loss: 0.972202271680644
Validation loss: 2.363780005327213

Epoch: 6| Step: 4
Training loss: 1.0863935212907048
Validation loss: 2.4077934383257933

Epoch: 6| Step: 5
Training loss: 1.0577944732888034
Validation loss: 2.404835954979845

Epoch: 6| Step: 6
Training loss: 0.7746519322326353
Validation loss: 2.429604972516915

Epoch: 6| Step: 7
Training loss: 0.7452550837955388
Validation loss: 2.4286490220124226

Epoch: 6| Step: 8
Training loss: 1.0534775186393122
Validation loss: 2.4551874565319274

Epoch: 6| Step: 9
Training loss: 1.1166308957154263
Validation loss: 2.475065238397773

Epoch: 6| Step: 10
Training loss: 1.2531256221474794
Validation loss: 2.486626754468919

Epoch: 6| Step: 11
Training loss: 1.4341155305767748
Validation loss: 2.467834575004558

Epoch: 6| Step: 12
Training loss: 1.1998337650392794
Validation loss: 2.452259928286803

Epoch: 6| Step: 13
Training loss: 1.0559653558864213
Validation loss: 2.4636170856734183

Epoch: 196| Step: 0
Training loss: 0.9496621560132107
Validation loss: 2.435799231726581

Epoch: 6| Step: 1
Training loss: 1.145007298125617
Validation loss: 2.42396137875758

Epoch: 6| Step: 2
Training loss: 1.304056894640893
Validation loss: 2.408624186003913

Epoch: 6| Step: 3
Training loss: 1.1036299114630004
Validation loss: 2.385263013442906

Epoch: 6| Step: 4
Training loss: 1.1159079633621258
Validation loss: 2.3879551416797735

Epoch: 6| Step: 5
Training loss: 1.0783024517474018
Validation loss: 2.3655663308638486

Epoch: 6| Step: 6
Training loss: 1.1838918883253202
Validation loss: 2.3423251824690796

Epoch: 6| Step: 7
Training loss: 1.2262345865818869
Validation loss: 2.378042992334619

Epoch: 6| Step: 8
Training loss: 1.6539997432989915
Validation loss: 2.3969629967459616

Epoch: 6| Step: 9
Training loss: 1.2386361464944862
Validation loss: 2.4044581308269084

Epoch: 6| Step: 10
Training loss: 0.916478477291908
Validation loss: 2.397996297583761

Epoch: 6| Step: 11
Training loss: 0.9080337858762331
Validation loss: 2.4363117776868104

Epoch: 6| Step: 12
Training loss: 1.079940152452736
Validation loss: 2.429949407590586

Epoch: 6| Step: 13
Training loss: 0.8356081590118088
Validation loss: 2.4544620850337653

Epoch: 197| Step: 0
Training loss: 1.1417303086151622
Validation loss: 2.431326626198239

Epoch: 6| Step: 1
Training loss: 0.8391251439413069
Validation loss: 2.429726435107959

Epoch: 6| Step: 2
Training loss: 0.9233423613257257
Validation loss: 2.454492991573769

Epoch: 6| Step: 3
Training loss: 0.8660870692507986
Validation loss: 2.4395356450986303

Epoch: 6| Step: 4
Training loss: 1.0267628234775834
Validation loss: 2.394804437107251

Epoch: 6| Step: 5
Training loss: 1.1739999451775351
Validation loss: 2.4252496988089702

Epoch: 6| Step: 6
Training loss: 1.1746794141535264
Validation loss: 2.431146768095542

Epoch: 6| Step: 7
Training loss: 1.4036311029098887
Validation loss: 2.418091692949783

Epoch: 6| Step: 8
Training loss: 0.6671466341390202
Validation loss: 2.398145646077575

Epoch: 6| Step: 9
Training loss: 1.5361478675060893
Validation loss: 2.3822364050194853

Epoch: 6| Step: 10
Training loss: 1.1361841471844127
Validation loss: 2.391934608707856

Epoch: 6| Step: 11
Training loss: 1.012780122507208
Validation loss: 2.3977409538607937

Epoch: 6| Step: 12
Training loss: 1.1820834252338734
Validation loss: 2.357737982106306

Epoch: 6| Step: 13
Training loss: 1.2500472059873
Validation loss: 2.3693701916373993

Epoch: 198| Step: 0
Training loss: 1.1001865098798504
Validation loss: 2.362727420015829

Epoch: 6| Step: 1
Training loss: 0.7559525385571471
Validation loss: 2.3393942695182557

Epoch: 6| Step: 2
Training loss: 1.1276341435043016
Validation loss: 2.3653541709989905

Epoch: 6| Step: 3
Training loss: 1.359546606698094
Validation loss: 2.353028697462519

Epoch: 6| Step: 4
Training loss: 1.030255271426042
Validation loss: 2.362088823496083

Epoch: 6| Step: 5
Training loss: 0.7740491895027912
Validation loss: 2.4011854504583234

Epoch: 6| Step: 6
Training loss: 1.2534238653932197
Validation loss: 2.38902776374412

Epoch: 6| Step: 7
Training loss: 1.250278155849825
Validation loss: 2.405553430064835

Epoch: 6| Step: 8
Training loss: 0.6815102788691563
Validation loss: 2.460817915482954

Epoch: 6| Step: 9
Training loss: 0.9233026925716928
Validation loss: 2.417247978290826

Epoch: 6| Step: 10
Training loss: 0.755229441029895
Validation loss: 2.415901780856519

Epoch: 6| Step: 11
Training loss: 1.6011784535012532
Validation loss: 2.3877370920323138

Epoch: 6| Step: 12
Training loss: 1.1546394369113395
Validation loss: 2.391133660122098

Epoch: 6| Step: 13
Training loss: 1.2010457290532186
Validation loss: 2.387681040991828

Epoch: 199| Step: 0
Training loss: 1.2595390648381144
Validation loss: 2.386904055607506

Epoch: 6| Step: 1
Training loss: 0.8777045617941962
Validation loss: 2.428773989269395

Epoch: 6| Step: 2
Training loss: 1.2850363539217766
Validation loss: 2.384446551140524

Epoch: 6| Step: 3
Training loss: 1.1992062248048063
Validation loss: 2.431724742784109

Epoch: 6| Step: 4
Training loss: 1.1770767222981204
Validation loss: 2.4048178568261016

Epoch: 6| Step: 5
Training loss: 1.1812617932089202
Validation loss: 2.4320330422478373

Epoch: 6| Step: 6
Training loss: 1.106713662260372
Validation loss: 2.442578680386913

Epoch: 6| Step: 7
Training loss: 1.0983650932486049
Validation loss: 2.426250155435706

Epoch: 6| Step: 8
Training loss: 1.2044371348468528
Validation loss: 2.392832997023131

Epoch: 6| Step: 9
Training loss: 0.740771539089791
Validation loss: 2.391950490371462

Epoch: 6| Step: 10
Training loss: 0.9245943919983579
Validation loss: 2.392459119424195

Epoch: 6| Step: 11
Training loss: 0.7078864052695905
Validation loss: 2.425024593234062

Epoch: 6| Step: 12
Training loss: 1.1140116119532921
Validation loss: 2.4420380083982645

Epoch: 6| Step: 13
Training loss: 1.0899131506695854
Validation loss: 2.4411640825165355

Epoch: 200| Step: 0
Training loss: 0.9018259255321135
Validation loss: 2.463049351990948

Epoch: 6| Step: 1
Training loss: 0.8126064010789562
Validation loss: 2.4582810338128245

Epoch: 6| Step: 2
Training loss: 1.2018213020663784
Validation loss: 2.504398134007718

Epoch: 6| Step: 3
Training loss: 0.8645923376571995
Validation loss: 2.484259810859791

Epoch: 6| Step: 4
Training loss: 1.2750266053658916
Validation loss: 2.4673586312863045

Epoch: 6| Step: 5
Training loss: 1.1708164774992555
Validation loss: 2.4732973983774906

Epoch: 6| Step: 6
Training loss: 1.2159000232718178
Validation loss: 2.4447225827361843

Epoch: 6| Step: 7
Training loss: 0.7979853131584767
Validation loss: 2.410654665536398

Epoch: 6| Step: 8
Training loss: 1.0417126581847271
Validation loss: 2.3874288806610546

Epoch: 6| Step: 9
Training loss: 1.3104687367552181
Validation loss: 2.363841187869164

Epoch: 6| Step: 10
Training loss: 0.866817120336692
Validation loss: 2.3892454386195454

Epoch: 6| Step: 11
Training loss: 1.0404938898745792
Validation loss: 2.3639135271717704

Epoch: 6| Step: 12
Training loss: 1.1319589490422763
Validation loss: 2.379103108980132

Epoch: 6| Step: 13
Training loss: 1.3393695314609895
Validation loss: 2.34802993323741

Epoch: 201| Step: 0
Training loss: 0.8655715526509847
Validation loss: 2.375705391878847

Epoch: 6| Step: 1
Training loss: 1.066776979722539
Validation loss: 2.352064600263847

Epoch: 6| Step: 2
Training loss: 1.4962444976476013
Validation loss: 2.3647353670170683

Epoch: 6| Step: 3
Training loss: 1.1321126946741578
Validation loss: 2.365063555153861

Epoch: 6| Step: 4
Training loss: 0.9490652077905979
Validation loss: 2.382512067161599

Epoch: 6| Step: 5
Training loss: 1.0324971720400453
Validation loss: 2.374398559058345

Epoch: 6| Step: 6
Training loss: 0.9440702993758326
Validation loss: 2.4095951262850384

Epoch: 6| Step: 7
Training loss: 1.3651812410725022
Validation loss: 2.4375642295265205

Epoch: 6| Step: 8
Training loss: 1.084377568046761
Validation loss: 2.4252189877762036

Epoch: 6| Step: 9
Training loss: 1.0184948794835946
Validation loss: 2.4450009306837877

Epoch: 6| Step: 10
Training loss: 0.6167500551221411
Validation loss: 2.436474819324248

Epoch: 6| Step: 11
Training loss: 0.9800818542433846
Validation loss: 2.4025644129826804

Epoch: 6| Step: 12
Training loss: 1.0309380724241315
Validation loss: 2.391356885182858

Epoch: 6| Step: 13
Training loss: 0.8882096650091439
Validation loss: 2.4007676028463383

Epoch: 202| Step: 0
Training loss: 1.4216898703311998
Validation loss: 2.37832850763651

Epoch: 6| Step: 1
Training loss: 0.94564907923244
Validation loss: 2.369054631332369

Epoch: 6| Step: 2
Training loss: 1.0061688289719148
Validation loss: 2.345818509334598

Epoch: 6| Step: 3
Training loss: 1.525274255199244
Validation loss: 2.3286103907560225

Epoch: 6| Step: 4
Training loss: 0.9364628458957484
Validation loss: 2.3165511321659564

Epoch: 6| Step: 5
Training loss: 0.8554846008783181
Validation loss: 2.3051842072398676

Epoch: 6| Step: 6
Training loss: 1.1076667420736128
Validation loss: 2.321674174839392

Epoch: 6| Step: 7
Training loss: 1.00342301787431
Validation loss: 2.3223526507799623

Epoch: 6| Step: 8
Training loss: 0.8576952383360414
Validation loss: 2.380953335424897

Epoch: 6| Step: 9
Training loss: 0.9108886391571456
Validation loss: 2.3807789770646353

Epoch: 6| Step: 10
Training loss: 0.9176113975211998
Validation loss: 2.402834971158973

Epoch: 6| Step: 11
Training loss: 0.6977793193057352
Validation loss: 2.4307211014897248

Epoch: 6| Step: 12
Training loss: 1.1131770570417343
Validation loss: 2.422368695090739

Epoch: 6| Step: 13
Training loss: 0.9466765469608587
Validation loss: 2.374373797605027

Epoch: 203| Step: 0
Training loss: 0.9943304873609166
Validation loss: 2.4100602677766907

Epoch: 6| Step: 1
Training loss: 0.85282992615304
Validation loss: 2.411892709196617

Epoch: 6| Step: 2
Training loss: 1.3387846027393815
Validation loss: 2.36312832901584

Epoch: 6| Step: 3
Training loss: 1.1911302590808028
Validation loss: 2.375302783898656

Epoch: 6| Step: 4
Training loss: 1.3246195138888044
Validation loss: 2.343579801990519

Epoch: 6| Step: 5
Training loss: 1.3080849640575185
Validation loss: 2.341817687957645

Epoch: 6| Step: 6
Training loss: 1.068676889160851
Validation loss: 2.319144807445563

Epoch: 6| Step: 7
Training loss: 1.113322849500334
Validation loss: 2.2991257478181573

Epoch: 6| Step: 8
Training loss: 0.6246935808535578
Validation loss: 2.3166732137603328

Epoch: 6| Step: 9
Training loss: 0.5762204424545
Validation loss: 2.327013101361725

Epoch: 6| Step: 10
Training loss: 0.6392935896994991
Validation loss: 2.339229336190936

Epoch: 6| Step: 11
Training loss: 0.8607363928107928
Validation loss: 2.3394139038984503

Epoch: 6| Step: 12
Training loss: 1.053893235269755
Validation loss: 2.3781976971991523

Epoch: 6| Step: 13
Training loss: 1.0174508335503598
Validation loss: 2.394999324596309

Epoch: 204| Step: 0
Training loss: 1.2792218601277063
Validation loss: 2.4009116504194843

Epoch: 6| Step: 1
Training loss: 0.985431679227536
Validation loss: 2.427965249977318

Epoch: 6| Step: 2
Training loss: 1.0728663583954363
Validation loss: 2.383425055862287

Epoch: 6| Step: 3
Training loss: 1.1888420151197814
Validation loss: 2.3996631103866877

Epoch: 6| Step: 4
Training loss: 1.182034009286064
Validation loss: 2.4098658450985435

Epoch: 6| Step: 5
Training loss: 0.9114999961413595
Validation loss: 2.402998356640047

Epoch: 6| Step: 6
Training loss: 1.0106402801887235
Validation loss: 2.414123196689551

Epoch: 6| Step: 7
Training loss: 1.0075536587721647
Validation loss: 2.407536417815878

Epoch: 6| Step: 8
Training loss: 0.6792024218814882
Validation loss: 2.3991144840279723

Epoch: 6| Step: 9
Training loss: 0.9533914912652962
Validation loss: 2.366045167989134

Epoch: 6| Step: 10
Training loss: 0.7574512367793935
Validation loss: 2.410073151575821

Epoch: 6| Step: 11
Training loss: 1.0848096300814516
Validation loss: 2.3997696764298144

Epoch: 6| Step: 12
Training loss: 1.1104116297757327
Validation loss: 2.394509202555578

Epoch: 6| Step: 13
Training loss: 0.9258773367548301
Validation loss: 2.3747657925937875

Epoch: 205| Step: 0
Training loss: 1.0154706397496096
Validation loss: 2.4081443315901416

Epoch: 6| Step: 1
Training loss: 0.9765007304683517
Validation loss: 2.3933275905897515

Epoch: 6| Step: 2
Training loss: 0.782529507955109
Validation loss: 2.37949366227381

Epoch: 6| Step: 3
Training loss: 0.8483065734220067
Validation loss: 2.4088505666362776

Epoch: 6| Step: 4
Training loss: 0.8618962496765208
Validation loss: 2.3893199803393355

Epoch: 6| Step: 5
Training loss: 1.2020328072562991
Validation loss: 2.4110933400273526

Epoch: 6| Step: 6
Training loss: 1.1174278800956086
Validation loss: 2.4073861567748955

Epoch: 6| Step: 7
Training loss: 1.1825717252628847
Validation loss: 2.4461144810257514

Epoch: 6| Step: 8
Training loss: 1.3015177706466248
Validation loss: 2.447332711998399

Epoch: 6| Step: 9
Training loss: 0.4084569333625909
Validation loss: 2.4449188252063303

Epoch: 6| Step: 10
Training loss: 1.0423080694867637
Validation loss: 2.4493971502556535

Epoch: 6| Step: 11
Training loss: 1.2456906423006104
Validation loss: 2.3935508016912386

Epoch: 6| Step: 12
Training loss: 1.1124469508692223
Validation loss: 2.384394970202496

Epoch: 6| Step: 13
Training loss: 0.29314958713280553
Validation loss: 2.3689635580508326

Epoch: 206| Step: 0
Training loss: 0.8514305502479029
Validation loss: 2.354192066264327

Epoch: 6| Step: 1
Training loss: 1.0348199838002625
Validation loss: 2.358362050107908

Epoch: 6| Step: 2
Training loss: 1.2597606570123698
Validation loss: 2.355307582897053

Epoch: 6| Step: 3
Training loss: 1.3443405716591863
Validation loss: 2.3540071685131516

Epoch: 6| Step: 4
Training loss: 0.7756948186664215
Validation loss: 2.3429178534005732

Epoch: 6| Step: 5
Training loss: 1.2680750550220075
Validation loss: 2.3278622062907957

Epoch: 6| Step: 6
Training loss: 0.9345055441102578
Validation loss: 2.3327112133948926

Epoch: 6| Step: 7
Training loss: 1.0976335516378088
Validation loss: 2.3676772002154145

Epoch: 6| Step: 8
Training loss: 0.7312276641173235
Validation loss: 2.3788358592165717

Epoch: 6| Step: 9
Training loss: 0.7849026930082529
Validation loss: 2.4092047557554714

Epoch: 6| Step: 10
Training loss: 0.9963284982557786
Validation loss: 2.4365764327001678

Epoch: 6| Step: 11
Training loss: 0.9824266680075364
Validation loss: 2.4621604369246097

Epoch: 6| Step: 12
Training loss: 0.6160563473010621
Validation loss: 2.4539089252712394

Epoch: 6| Step: 13
Training loss: 1.0274632025485135
Validation loss: 2.4262986752474958

Epoch: 207| Step: 0
Training loss: 0.6826869945278041
Validation loss: 2.4060284379781747

Epoch: 6| Step: 1
Training loss: 0.6306619719148436
Validation loss: 2.414811357451628

Epoch: 6| Step: 2
Training loss: 1.1498916139527264
Validation loss: 2.3760451277053316

Epoch: 6| Step: 3
Training loss: 1.091616375082616
Validation loss: 2.3613374352083936

Epoch: 6| Step: 4
Training loss: 1.3213818525281535
Validation loss: 2.333365770486595

Epoch: 6| Step: 5
Training loss: 0.7625493143112725
Validation loss: 2.3437084300958975

Epoch: 6| Step: 6
Training loss: 1.1980521526288834
Validation loss: 2.380250001766426

Epoch: 6| Step: 7
Training loss: 1.2215829348959155
Validation loss: 2.3633787219968467

Epoch: 6| Step: 8
Training loss: 0.8776057136740855
Validation loss: 2.3693069537453275

Epoch: 6| Step: 9
Training loss: 0.8746638333470502
Validation loss: 2.3613911607612095

Epoch: 6| Step: 10
Training loss: 1.2053840533285136
Validation loss: 2.3948587462205992

Epoch: 6| Step: 11
Training loss: 0.42726614768783955
Validation loss: 2.4000483974581193

Epoch: 6| Step: 12
Training loss: 1.0905975688118825
Validation loss: 2.39807107134526

Epoch: 6| Step: 13
Training loss: 0.5520696248445849
Validation loss: 2.403299093453841

Epoch: 208| Step: 0
Training loss: 0.9767020774276323
Validation loss: 2.3744295468163434

Epoch: 6| Step: 1
Training loss: 0.9276525200320177
Validation loss: 2.3924792977055436

Epoch: 6| Step: 2
Training loss: 1.0922314047004322
Validation loss: 2.385884148665882

Epoch: 6| Step: 3
Training loss: 0.6132611313939809
Validation loss: 2.381101498365696

Epoch: 6| Step: 4
Training loss: 0.9078351659784879
Validation loss: 2.41530331212545

Epoch: 6| Step: 5
Training loss: 0.7240304202043282
Validation loss: 2.425629597420048

Epoch: 6| Step: 6
Training loss: 1.1699473484940641
Validation loss: 2.4236721710415567

Epoch: 6| Step: 7
Training loss: 0.6931524693349124
Validation loss: 2.4494491523467654

Epoch: 6| Step: 8
Training loss: 0.9522868363958877
Validation loss: 2.4477350974485432

Epoch: 6| Step: 9
Training loss: 1.002868056144767
Validation loss: 2.4695081594175017

Epoch: 6| Step: 10
Training loss: 1.499980131653491
Validation loss: 2.461852604060999

Epoch: 6| Step: 11
Training loss: 0.9643943450431258
Validation loss: 2.4525526497399284

Epoch: 6| Step: 12
Training loss: 0.7849432812992748
Validation loss: 2.4344878852517584

Epoch: 6| Step: 13
Training loss: 0.8482300885958421
Validation loss: 2.441849008491128

Epoch: 209| Step: 0
Training loss: 0.7118220433338923
Validation loss: 2.4393051568793997

Epoch: 6| Step: 1
Training loss: 0.9457678210611076
Validation loss: 2.448352932111008

Epoch: 6| Step: 2
Training loss: 0.9691106063578846
Validation loss: 2.4617772417307826

Epoch: 6| Step: 3
Training loss: 0.8103180343962662
Validation loss: 2.4106493333299457

Epoch: 6| Step: 4
Training loss: 0.37744503833755344
Validation loss: 2.45406424785048

Epoch: 6| Step: 5
Training loss: 1.098502270890234
Validation loss: 2.4122392886218598

Epoch: 6| Step: 6
Training loss: 1.3064256157618535
Validation loss: 2.4077945498996365

Epoch: 6| Step: 7
Training loss: 0.8591333222848506
Validation loss: 2.4329952033999307

Epoch: 6| Step: 8
Training loss: 0.728300988536092
Validation loss: 2.4577469782583625

Epoch: 6| Step: 9
Training loss: 1.2152282008397732
Validation loss: 2.405758239480768

Epoch: 6| Step: 10
Training loss: 0.6065005954478486
Validation loss: 2.4637794035642577

Epoch: 6| Step: 11
Training loss: 1.0185035407445353
Validation loss: 2.4351080061012778

Epoch: 6| Step: 12
Training loss: 1.0499314058695692
Validation loss: 2.4362657007607305

Epoch: 6| Step: 13
Training loss: 1.36086629863055
Validation loss: 2.425253744183982

Epoch: 210| Step: 0
Training loss: 0.8549629004834086
Validation loss: 2.3971088290286464

Epoch: 6| Step: 1
Training loss: 0.6620604460425195
Validation loss: 2.410984412576193

Epoch: 6| Step: 2
Training loss: 0.8129037074182478
Validation loss: 2.403965182614477

Epoch: 6| Step: 3
Training loss: 1.2375648905377148
Validation loss: 2.379364270784167

Epoch: 6| Step: 4
Training loss: 0.8969054718689394
Validation loss: 2.3966954146671484

Epoch: 6| Step: 5
Training loss: 1.3212554995044308
Validation loss: 2.3892912318589437

Epoch: 6| Step: 6
Training loss: 0.7309129149961482
Validation loss: 2.45723722106381

Epoch: 6| Step: 7
Training loss: 0.8933128488265469
Validation loss: 2.4313582079959217

Epoch: 6| Step: 8
Training loss: 1.1544795529160299
Validation loss: 2.4378874339108108

Epoch: 6| Step: 9
Training loss: 0.817162378045357
Validation loss: 2.45721528241032

Epoch: 6| Step: 10
Training loss: 0.7967957475932719
Validation loss: 2.440696750904596

Epoch: 6| Step: 11
Training loss: 0.8253115600326368
Validation loss: 2.422084813816093

Epoch: 6| Step: 12
Training loss: 1.0415406468774517
Validation loss: 2.4174107706215557

Epoch: 6| Step: 13
Training loss: 0.8274753829659665
Validation loss: 2.4329162253931482

Epoch: 211| Step: 0
Training loss: 0.6557615824093539
Validation loss: 2.40647327062193

Epoch: 6| Step: 1
Training loss: 1.0041174759166798
Validation loss: 2.41420005669001

Epoch: 6| Step: 2
Training loss: 0.8465013855271061
Validation loss: 2.3784010810613005

Epoch: 6| Step: 3
Training loss: 1.0287243519363414
Validation loss: 2.4197957047378664

Epoch: 6| Step: 4
Training loss: 1.1768273044185578
Validation loss: 2.417552161656283

Epoch: 6| Step: 5
Training loss: 0.9220211430460961
Validation loss: 2.421602165104991

Epoch: 6| Step: 6
Training loss: 0.8045162277908436
Validation loss: 2.3998023593527993

Epoch: 6| Step: 7
Training loss: 0.7339821434291598
Validation loss: 2.4667981657592306

Epoch: 6| Step: 8
Training loss: 0.723778796174901
Validation loss: 2.4642758994396505

Epoch: 6| Step: 9
Training loss: 1.270352611401142
Validation loss: 2.4375815786756894

Epoch: 6| Step: 10
Training loss: 0.6810809354370776
Validation loss: 2.449911757021216

Epoch: 6| Step: 11
Training loss: 1.1426328988273284
Validation loss: 2.4692869141238716

Epoch: 6| Step: 12
Training loss: 1.0483368872221934
Validation loss: 2.469698105888512

Epoch: 6| Step: 13
Training loss: 0.9878263670573412
Validation loss: 2.4492019297120393

Epoch: 212| Step: 0
Training loss: 0.8588863023645239
Validation loss: 2.4363877919769843

Epoch: 6| Step: 1
Training loss: 1.2040315655660845
Validation loss: 2.4227895099710652

Epoch: 6| Step: 2
Training loss: 1.1514851102872572
Validation loss: 2.4176057179924024

Epoch: 6| Step: 3
Training loss: 0.8858364606020379
Validation loss: 2.4360759751921246

Epoch: 6| Step: 4
Training loss: 0.6915039596913154
Validation loss: 2.4022639051485095

Epoch: 6| Step: 5
Training loss: 1.0028509983888347
Validation loss: 2.395121441796875

Epoch: 6| Step: 6
Training loss: 0.8433439195920912
Validation loss: 2.376006682146748

Epoch: 6| Step: 7
Training loss: 1.0795145892791314
Validation loss: 2.403863522216803

Epoch: 6| Step: 8
Training loss: 0.8845440585029967
Validation loss: 2.4240595084488086

Epoch: 6| Step: 9
Training loss: 0.6573042348958864
Validation loss: 2.402606612046699

Epoch: 6| Step: 10
Training loss: 0.8487499582012543
Validation loss: 2.4053596332352583

Epoch: 6| Step: 11
Training loss: 0.8931716514880618
Validation loss: 2.3897654611271704

Epoch: 6| Step: 12
Training loss: 0.7856227191294091
Validation loss: 2.427443829869123

Epoch: 6| Step: 13
Training loss: 1.1469875706612003
Validation loss: 2.4392586887749967

Epoch: 213| Step: 0
Training loss: 0.9229317120659707
Validation loss: 2.4123179478033507

Epoch: 6| Step: 1
Training loss: 1.0744471636598252
Validation loss: 2.429506358765183

Epoch: 6| Step: 2
Training loss: 1.0630577530805099
Validation loss: 2.419277212921187

Epoch: 6| Step: 3
Training loss: 0.9706006370183905
Validation loss: 2.425764319509544

Epoch: 6| Step: 4
Training loss: 1.2654778665802273
Validation loss: 2.416544439798422

Epoch: 6| Step: 5
Training loss: 0.7545387105598608
Validation loss: 2.373432544579754

Epoch: 6| Step: 6
Training loss: 1.0035652739351149
Validation loss: 2.3951419010933352

Epoch: 6| Step: 7
Training loss: 1.0862403831451308
Validation loss: 2.4310627842748964

Epoch: 6| Step: 8
Training loss: 0.7620806494558331
Validation loss: 2.416765362340549

Epoch: 6| Step: 9
Training loss: 0.6365092816436497
Validation loss: 2.4660383737452647

Epoch: 6| Step: 10
Training loss: 0.8855909662161559
Validation loss: 2.442785812343161

Epoch: 6| Step: 11
Training loss: 0.41657981762156393
Validation loss: 2.486148180028063

Epoch: 6| Step: 12
Training loss: 0.9476363253090917
Validation loss: 2.4981023959680493

Epoch: 6| Step: 13
Training loss: 0.6960451145499668
Validation loss: 2.4677953134568456

Epoch: 214| Step: 0
Training loss: 1.0088145279601326
Validation loss: 2.4575993568635797

Epoch: 6| Step: 1
Training loss: 0.9023932901630118
Validation loss: 2.451568694025066

Epoch: 6| Step: 2
Training loss: 0.9551760383451947
Validation loss: 2.4464738421980075

Epoch: 6| Step: 3
Training loss: 0.5043362106477324
Validation loss: 2.4455532802137046

Epoch: 6| Step: 4
Training loss: 0.8743286622798034
Validation loss: 2.455486550044623

Epoch: 6| Step: 5
Training loss: 0.7252207847373034
Validation loss: 2.4654445178349444

Epoch: 6| Step: 6
Training loss: 1.2277306503545256
Validation loss: 2.4472304301062007

Epoch: 6| Step: 7
Training loss: 0.7296158814663474
Validation loss: 2.4355488517696564

Epoch: 6| Step: 8
Training loss: 0.9000701665017371
Validation loss: 2.408984890455749

Epoch: 6| Step: 9
Training loss: 0.9038993340625794
Validation loss: 2.400691167630218

Epoch: 6| Step: 10
Training loss: 0.8116076410817522
Validation loss: 2.4095505163495115

Epoch: 6| Step: 11
Training loss: 0.9774393951184943
Validation loss: 2.4202999289885048

Epoch: 6| Step: 12
Training loss: 1.167591148755619
Validation loss: 2.4081153580513246

Epoch: 6| Step: 13
Training loss: 0.6339781586347557
Validation loss: 2.392253023536237

Epoch: 215| Step: 0
Training loss: 1.0505374781674202
Validation loss: 2.467589397737421

Epoch: 6| Step: 1
Training loss: 0.8838123297394781
Validation loss: 2.4180116471549074

Epoch: 6| Step: 2
Training loss: 0.5909565161717176
Validation loss: 2.4149000063299986

Epoch: 6| Step: 3
Training loss: 0.8136300884327411
Validation loss: 2.4367491630844036

Epoch: 6| Step: 4
Training loss: 0.9065056473145264
Validation loss: 2.4571053044979685

Epoch: 6| Step: 5
Training loss: 0.9683110257751041
Validation loss: 2.4177605151665924

Epoch: 6| Step: 6
Training loss: 0.7527425214230624
Validation loss: 2.4573425109377465

Epoch: 6| Step: 7
Training loss: 0.3325310703689725
Validation loss: 2.4518736095589255

Epoch: 6| Step: 8
Training loss: 0.8481746090665588
Validation loss: 2.483476752056968

Epoch: 6| Step: 9
Training loss: 0.9348228376505191
Validation loss: 2.4415058489428567

Epoch: 6| Step: 10
Training loss: 0.8037187244506201
Validation loss: 2.4390448814180856

Epoch: 6| Step: 11
Training loss: 1.1546707193396752
Validation loss: 2.415726419012647

Epoch: 6| Step: 12
Training loss: 1.0430216115063948
Validation loss: 2.4160930131617615

Epoch: 6| Step: 13
Training loss: 1.2014413422812475
Validation loss: 2.4010116073082437

Epoch: 216| Step: 0
Training loss: 0.9947078563010621
Validation loss: 2.3715178172685474

Epoch: 6| Step: 1
Training loss: 0.7967987772072368
Validation loss: 2.388032846595822

Epoch: 6| Step: 2
Training loss: 0.7030246027159003
Validation loss: 2.3998728877420437

Epoch: 6| Step: 3
Training loss: 1.0019505669931101
Validation loss: 2.4050901739665513

Epoch: 6| Step: 4
Training loss: 0.9355651598837821
Validation loss: 2.38629356111901

Epoch: 6| Step: 5
Training loss: 0.4415971292630038
Validation loss: 2.4597319890596916

Epoch: 6| Step: 6
Training loss: 0.6095453171034559
Validation loss: 2.450062489418968

Epoch: 6| Step: 7
Training loss: 0.8058060954348394
Validation loss: 2.4586272813918653

Epoch: 6| Step: 8
Training loss: 1.0138500255527712
Validation loss: 2.478911276988944

Epoch: 6| Step: 9
Training loss: 0.7519795202601505
Validation loss: 2.4841636845943333

Epoch: 6| Step: 10
Training loss: 1.354996084862152
Validation loss: 2.458299533019993

Epoch: 6| Step: 11
Training loss: 1.04648320851932
Validation loss: 2.4560728318844816

Epoch: 6| Step: 12
Training loss: 0.8272651310813958
Validation loss: 2.423081578092929

Epoch: 6| Step: 13
Training loss: 0.8847886307780081
Validation loss: 2.415863891572594

Epoch: 217| Step: 0
Training loss: 0.8122103981938074
Validation loss: 2.386779937972172

Epoch: 6| Step: 1
Training loss: 1.0116690251565388
Validation loss: 2.3800562762463553

Epoch: 6| Step: 2
Training loss: 0.9767825374666181
Validation loss: 2.415872142149944

Epoch: 6| Step: 3
Training loss: 0.9718603838345888
Validation loss: 2.3849503492630224

Epoch: 6| Step: 4
Training loss: 0.5155300284111819
Validation loss: 2.4180662227713063

Epoch: 6| Step: 5
Training loss: 0.8635136908465783
Validation loss: 2.3837844187119988

Epoch: 6| Step: 6
Training loss: 1.100079451205891
Validation loss: 2.3689089664032057

Epoch: 6| Step: 7
Training loss: 0.6284248689570543
Validation loss: 2.3925283539755844

Epoch: 6| Step: 8
Training loss: 0.843879795687484
Validation loss: 2.371359523635079

Epoch: 6| Step: 9
Training loss: 0.8689959459221218
Validation loss: 2.3514057510959163

Epoch: 6| Step: 10
Training loss: 0.6822830714104181
Validation loss: 2.3951657178726062

Epoch: 6| Step: 11
Training loss: 0.9402030441966027
Validation loss: 2.369865946578638

Epoch: 6| Step: 12
Training loss: 1.1891766807884787
Validation loss: 2.384589712905074

Epoch: 6| Step: 13
Training loss: 0.5205584245591619
Validation loss: 2.385339329353361

Epoch: 218| Step: 0
Training loss: 0.8428872253762384
Validation loss: 2.4078985798668557

Epoch: 6| Step: 1
Training loss: 1.0504798315037653
Validation loss: 2.41716337898495

Epoch: 6| Step: 2
Training loss: 0.5127829049989373
Validation loss: 2.45265127759695

Epoch: 6| Step: 3
Training loss: 0.9670007972280062
Validation loss: 2.4604242271694856

Epoch: 6| Step: 4
Training loss: 0.8448168755912084
Validation loss: 2.4567667459121747

Epoch: 6| Step: 5
Training loss: 0.6815051624609137
Validation loss: 2.4814493716407626

Epoch: 6| Step: 6
Training loss: 0.8009717761149968
Validation loss: 2.499613581295903

Epoch: 6| Step: 7
Training loss: 1.0891108629387736
Validation loss: 2.4693259655996735

Epoch: 6| Step: 8
Training loss: 0.7642987500366307
Validation loss: 2.460387748206624

Epoch: 6| Step: 9
Training loss: 0.977189038516091
Validation loss: 2.423953255131152

Epoch: 6| Step: 10
Training loss: 0.6781862055497476
Validation loss: 2.4391701390150446

Epoch: 6| Step: 11
Training loss: 0.7589325640276863
Validation loss: 2.412634137361815

Epoch: 6| Step: 12
Training loss: 1.0356194377558718
Validation loss: 2.420721461455873

Epoch: 6| Step: 13
Training loss: 1.2599025444912795
Validation loss: 2.440017305889719

Epoch: 219| Step: 0
Training loss: 0.9707352999414878
Validation loss: 2.4413792310962914

Epoch: 6| Step: 1
Training loss: 0.9583583116731492
Validation loss: 2.4710408365287986

Epoch: 6| Step: 2
Training loss: 0.7549292388496859
Validation loss: 2.467113920048722

Epoch: 6| Step: 3
Training loss: 0.45575094625110085
Validation loss: 2.4766473341223887

Epoch: 6| Step: 4
Training loss: 0.6105476979782796
Validation loss: 2.480962955825012

Epoch: 6| Step: 5
Training loss: 0.931490296205275
Validation loss: 2.4664116831022667

Epoch: 6| Step: 6
Training loss: 1.1347440366283645
Validation loss: 2.5089977623402264

Epoch: 6| Step: 7
Training loss: 0.7593493264964246
Validation loss: 2.461570774158565

Epoch: 6| Step: 8
Training loss: 0.760419784609181
Validation loss: 2.4608196896404

Epoch: 6| Step: 9
Training loss: 0.91941443700378
Validation loss: 2.4226485960274013

Epoch: 6| Step: 10
Training loss: 0.9738657222242709
Validation loss: 2.421372886684892

Epoch: 6| Step: 11
Training loss: 0.954282464298428
Validation loss: 2.422792041030892

Epoch: 6| Step: 12
Training loss: 0.6717880991249287
Validation loss: 2.401945453383577

Epoch: 6| Step: 13
Training loss: 1.1620841913139173
Validation loss: 2.379446182338003

Epoch: 220| Step: 0
Training loss: 0.9558801384507501
Validation loss: 2.3517004993324515

Epoch: 6| Step: 1
Training loss: 0.739474910973351
Validation loss: 2.361137320340655

Epoch: 6| Step: 2
Training loss: 0.8449444263850725
Validation loss: 2.366502937733643

Epoch: 6| Step: 3
Training loss: 0.5705974859684362
Validation loss: 2.3817183046806685

Epoch: 6| Step: 4
Training loss: 1.049769201344278
Validation loss: 2.403180911075694

Epoch: 6| Step: 5
Training loss: 1.0678973271026153
Validation loss: 2.416731587076516

Epoch: 6| Step: 6
Training loss: 0.9965648958040413
Validation loss: 2.447924650376042

Epoch: 6| Step: 7
Training loss: 0.8194900385965147
Validation loss: 2.4187322458794918

Epoch: 6| Step: 8
Training loss: 0.7075256389514886
Validation loss: 2.448194841870107

Epoch: 6| Step: 9
Training loss: 0.5758242059261206
Validation loss: 2.4433157298804757

Epoch: 6| Step: 10
Training loss: 0.6450193926387294
Validation loss: 2.4334084705558183

Epoch: 6| Step: 11
Training loss: 0.9451097633557407
Validation loss: 2.444052390323155

Epoch: 6| Step: 12
Training loss: 1.0805712603681075
Validation loss: 2.4842291379162083

Epoch: 6| Step: 13
Training loss: 0.9138930400037809
Validation loss: 2.4256433486678866

Epoch: 221| Step: 0
Training loss: 0.5730549963211156
Validation loss: 2.4172147496036804

Epoch: 6| Step: 1
Training loss: 0.7061457067469722
Validation loss: 2.4174228029143774

Epoch: 6| Step: 2
Training loss: 0.7254301702333351
Validation loss: 2.4294080512550145

Epoch: 6| Step: 3
Training loss: 0.9645325008095634
Validation loss: 2.4275149523590724

Epoch: 6| Step: 4
Training loss: 1.0262885530875847
Validation loss: 2.4173907251510918

Epoch: 6| Step: 5
Training loss: 0.7620448270413035
Validation loss: 2.416378820573085

Epoch: 6| Step: 6
Training loss: 0.8171565062733908
Validation loss: 2.421724441934794

Epoch: 6| Step: 7
Training loss: 0.7111812215712806
Validation loss: 2.4609934779459754

Epoch: 6| Step: 8
Training loss: 0.8362534897279555
Validation loss: 2.4567456723020045

Epoch: 6| Step: 9
Training loss: 0.6736646813352846
Validation loss: 2.4242189896745283

Epoch: 6| Step: 10
Training loss: 0.6920603443747102
Validation loss: 2.4642763592619676

Epoch: 6| Step: 11
Training loss: 1.1167563827021403
Validation loss: 2.4390033170049574

Epoch: 6| Step: 12
Training loss: 0.9677285377410774
Validation loss: 2.478713925858235

Epoch: 6| Step: 13
Training loss: 1.2413939814504484
Validation loss: 2.4957839188361133

Epoch: 222| Step: 0
Training loss: 1.1237296243248218
Validation loss: 2.5117200431909072

Epoch: 6| Step: 1
Training loss: 0.7554986768315844
Validation loss: 2.4631658816965887

Epoch: 6| Step: 2
Training loss: 0.6008837450000961
Validation loss: 2.4479924366748227

Epoch: 6| Step: 3
Training loss: 1.1169963219598307
Validation loss: 2.4392585153613604

Epoch: 6| Step: 4
Training loss: 0.4429192227726145
Validation loss: 2.4634899975250244

Epoch: 6| Step: 5
Training loss: 0.7554505102407465
Validation loss: 2.408915844199468

Epoch: 6| Step: 6
Training loss: 0.821852990497575
Validation loss: 2.4048016241257346

Epoch: 6| Step: 7
Training loss: 0.9163251081545969
Validation loss: 2.3893599541383033

Epoch: 6| Step: 8
Training loss: 0.7495323948695362
Validation loss: 2.376009319688175

Epoch: 6| Step: 9
Training loss: 0.3395931701269067
Validation loss: 2.3708652482799826

Epoch: 6| Step: 10
Training loss: 0.8430489700796159
Validation loss: 2.3315842046893933

Epoch: 6| Step: 11
Training loss: 0.5440072207602753
Validation loss: 2.339016447927009

Epoch: 6| Step: 12
Training loss: 1.1726760669434133
Validation loss: 2.380362388946208

Epoch: 6| Step: 13
Training loss: 0.9920609461055361
Validation loss: 2.368554591429283

Epoch: 223| Step: 0
Training loss: 0.9074593728799843
Validation loss: 2.4145199113065257

Epoch: 6| Step: 1
Training loss: 0.9479317436835752
Validation loss: 2.4211487018768785

Epoch: 6| Step: 2
Training loss: 0.6542953946680432
Validation loss: 2.4296354476786406

Epoch: 6| Step: 3
Training loss: 0.6808235058333958
Validation loss: 2.42344234267695

Epoch: 6| Step: 4
Training loss: 0.8818771673726051
Validation loss: 2.4866204165652257

Epoch: 6| Step: 5
Training loss: 1.0711321511539067
Validation loss: 2.4381365169788727

Epoch: 6| Step: 6
Training loss: 0.899803450103101
Validation loss: 2.4508409664470907

Epoch: 6| Step: 7
Training loss: 0.9473738461054685
Validation loss: 2.4337824545506668

Epoch: 6| Step: 8
Training loss: 0.3523951101826596
Validation loss: 2.432892511048575

Epoch: 6| Step: 9
Training loss: 1.001529239572418
Validation loss: 2.414600433841439

Epoch: 6| Step: 10
Training loss: 0.7283691586282637
Validation loss: 2.4106284595530942

Epoch: 6| Step: 11
Training loss: 0.33092120244832174
Validation loss: 2.375318997477938

Epoch: 6| Step: 12
Training loss: 0.8954308995754274
Validation loss: 2.3695194207453016

Epoch: 6| Step: 13
Training loss: 0.7674368225959567
Validation loss: 2.3802744107527842

Epoch: 224| Step: 0
Training loss: 0.49999099961763205
Validation loss: 2.380864362598642

Epoch: 6| Step: 1
Training loss: 0.8698677364747216
Validation loss: 2.337333679270314

Epoch: 6| Step: 2
Training loss: 0.8501674879775959
Validation loss: 2.385507788133296

Epoch: 6| Step: 3
Training loss: 0.9639822631288473
Validation loss: 2.3562468346945815

Epoch: 6| Step: 4
Training loss: 0.896280336119316
Validation loss: 2.3661038676598425

Epoch: 6| Step: 5
Training loss: 0.29095026856869083
Validation loss: 2.402490110396725

Epoch: 6| Step: 6
Training loss: 0.9654231629024798
Validation loss: 2.3943657666235447

Epoch: 6| Step: 7
Training loss: 0.8227711118263099
Validation loss: 2.3705127425417962

Epoch: 6| Step: 8
Training loss: 0.7371173140558691
Validation loss: 2.4136150861571144

Epoch: 6| Step: 9
Training loss: 0.9972306887539675
Validation loss: 2.4222371487237395

Epoch: 6| Step: 10
Training loss: 0.8866789216494907
Validation loss: 2.418549919496536

Epoch: 6| Step: 11
Training loss: 1.060240755810383
Validation loss: 2.3936753672120443

Epoch: 6| Step: 12
Training loss: 0.4188040470715644
Validation loss: 2.389202008883899

Epoch: 6| Step: 13
Training loss: 0.8054764222779603
Validation loss: 2.380321111641811

Epoch: 225| Step: 0
Training loss: 0.749788930120736
Validation loss: 2.3734405138430463

Epoch: 6| Step: 1
Training loss: 0.7812282177749554
Validation loss: 2.3660769168732725

Epoch: 6| Step: 2
Training loss: 0.8207056102687821
Validation loss: 2.383363112712436

Epoch: 6| Step: 3
Training loss: 0.4653419421522521
Validation loss: 2.371741838981347

Epoch: 6| Step: 4
Training loss: 0.6070777678861852
Validation loss: 2.4112358866841164

Epoch: 6| Step: 5
Training loss: 0.6236604640814688
Validation loss: 2.4283654452494066

Epoch: 6| Step: 6
Training loss: 1.2427708437669382
Validation loss: 2.435529565039555

Epoch: 6| Step: 7
Training loss: 0.746825493484593
Validation loss: 2.47613458963072

Epoch: 6| Step: 8
Training loss: 1.1349330653817116
Validation loss: 2.4371041732991428

Epoch: 6| Step: 9
Training loss: 0.4781499594363194
Validation loss: 2.423139351010256

Epoch: 6| Step: 10
Training loss: 0.9661344474402621
Validation loss: 2.4089143862038545

Epoch: 6| Step: 11
Training loss: 0.8417798104736083
Validation loss: 2.411979909292627

Epoch: 6| Step: 12
Training loss: 0.6750890240420175
Validation loss: 2.408514037238189

Epoch: 6| Step: 13
Training loss: 0.7974569028611697
Validation loss: 2.419514774450501

Epoch: 226| Step: 0
Training loss: 0.8900094833297396
Validation loss: 2.3746035708626003

Epoch: 6| Step: 1
Training loss: 0.6658239676167342
Validation loss: 2.3590162091748126

Epoch: 6| Step: 2
Training loss: 1.0148388681154832
Validation loss: 2.3830232432568894

Epoch: 6| Step: 3
Training loss: 0.6842296149799605
Validation loss: 2.3691076976329284

Epoch: 6| Step: 4
Training loss: 0.9483859015165415
Validation loss: 2.3331934437224437

Epoch: 6| Step: 5
Training loss: 1.171933541425141
Validation loss: 2.355838614970211

Epoch: 6| Step: 6
Training loss: 0.6516078292849934
Validation loss: 2.3732044705941804

Epoch: 6| Step: 7
Training loss: 0.32486350512744844
Validation loss: 2.3560036657420005

Epoch: 6| Step: 8
Training loss: 0.6267868962468891
Validation loss: 2.363735943936167

Epoch: 6| Step: 9
Training loss: 0.6903993634979634
Validation loss: 2.3651125183253567

Epoch: 6| Step: 10
Training loss: 0.7919184301159277
Validation loss: 2.3924829280850797

Epoch: 6| Step: 11
Training loss: 0.7221774602940744
Validation loss: 2.3974747102359912

Epoch: 6| Step: 12
Training loss: 0.989216508972782
Validation loss: 2.4031852512243943

Epoch: 6| Step: 13
Training loss: 0.2612076366108178
Validation loss: 2.396399438505206

Epoch: 227| Step: 0
Training loss: 0.8097518514887013
Validation loss: 2.423271132983547

Epoch: 6| Step: 1
Training loss: 0.6304115855644005
Validation loss: 2.433766082175087

Epoch: 6| Step: 2
Training loss: 0.6973822573612213
Validation loss: 2.4238903894412798

Epoch: 6| Step: 3
Training loss: 0.7225079770951287
Validation loss: 2.4436600148349523

Epoch: 6| Step: 4
Training loss: 0.31517261623389775
Validation loss: 2.474132089174687

Epoch: 6| Step: 5
Training loss: 0.8245878794157503
Validation loss: 2.4776117476485817

Epoch: 6| Step: 6
Training loss: 0.9847936194260418
Validation loss: 2.419906953845446

Epoch: 6| Step: 7
Training loss: 0.8880587632178969
Validation loss: 2.4080685010034073

Epoch: 6| Step: 8
Training loss: 0.7048722492292199
Validation loss: 2.431334620801322

Epoch: 6| Step: 9
Training loss: 0.7196528527702549
Validation loss: 2.445307338771663

Epoch: 6| Step: 10
Training loss: 0.7083294999261983
Validation loss: 2.413641816277983

Epoch: 6| Step: 11
Training loss: 0.5172555746125637
Validation loss: 2.430098232328104

Epoch: 6| Step: 12
Training loss: 1.3565896096867716
Validation loss: 2.4019109029703856

Epoch: 6| Step: 13
Training loss: 0.6803533427744164
Validation loss: 2.3862277861028924

Epoch: 228| Step: 0
Training loss: 1.0286901665642627
Validation loss: 2.3990140644585485

Epoch: 6| Step: 1
Training loss: 0.692898470853213
Validation loss: 2.3828691900440067

Epoch: 6| Step: 2
Training loss: 0.8008491301260386
Validation loss: 2.389186268830016

Epoch: 6| Step: 3
Training loss: 1.0305381398701607
Validation loss: 2.362562715811635

Epoch: 6| Step: 4
Training loss: 0.6779357215307286
Validation loss: 2.380888450873235

Epoch: 6| Step: 5
Training loss: 0.5861655236649652
Validation loss: 2.402008871539795

Epoch: 6| Step: 6
Training loss: 0.5663563410375954
Validation loss: 2.3580765775483146

Epoch: 6| Step: 7
Training loss: 0.6192606860699158
Validation loss: 2.4055950038821403

Epoch: 6| Step: 8
Training loss: 1.1685050830134716
Validation loss: 2.376184468220814

Epoch: 6| Step: 9
Training loss: 0.6432385514742027
Validation loss: 2.40067729267642

Epoch: 6| Step: 10
Training loss: 0.6185132768342357
Validation loss: 2.4158736856149514

Epoch: 6| Step: 11
Training loss: 0.8883258858691204
Validation loss: 2.3928005580039504

Epoch: 6| Step: 12
Training loss: 0.6083858972423497
Validation loss: 2.431264513183689

Epoch: 6| Step: 13
Training loss: 0.8609402360543809
Validation loss: 2.4266682202532417

Epoch: 229| Step: 0
Training loss: 0.4586714144291658
Validation loss: 2.4260085150712096

Epoch: 6| Step: 1
Training loss: 0.7912810080600844
Validation loss: 2.404542117374364

Epoch: 6| Step: 2
Training loss: 0.9291820915435791
Validation loss: 2.360687341810252

Epoch: 6| Step: 3
Training loss: 0.7904948085901573
Validation loss: 2.3889543321734172

Epoch: 6| Step: 4
Training loss: 0.8063506189296276
Validation loss: 2.3543591325820925

Epoch: 6| Step: 5
Training loss: 1.1596165181843137
Validation loss: 2.3697302610998507

Epoch: 6| Step: 6
Training loss: 0.6415746674496402
Validation loss: 2.344541912216786

Epoch: 6| Step: 7
Training loss: 0.7114771796244151
Validation loss: 2.3505372334213974

Epoch: 6| Step: 8
Training loss: 0.6398715496428506
Validation loss: 2.3746124409040594

Epoch: 6| Step: 9
Training loss: 0.8349925252728345
Validation loss: 2.3889774401449224

Epoch: 6| Step: 10
Training loss: 0.7569860297240549
Validation loss: 2.4192443681605855

Epoch: 6| Step: 11
Training loss: 0.3695893562554379
Validation loss: 2.413505010617583

Epoch: 6| Step: 12
Training loss: 0.9409578767240556
Validation loss: 2.4189936110819072

Epoch: 6| Step: 13
Training loss: 0.7335367897678354
Validation loss: 2.4089051390855825

Epoch: 230| Step: 0
Training loss: 1.0117011934031097
Validation loss: 2.434890567198494

Epoch: 6| Step: 1
Training loss: 0.6675514122097772
Validation loss: 2.4593108333186997

Epoch: 6| Step: 2
Training loss: 0.6807530918212231
Validation loss: 2.448533054962979

Epoch: 6| Step: 3
Training loss: 0.631464900837719
Validation loss: 2.438550797799161

Epoch: 6| Step: 4
Training loss: 0.6751410036808806
Validation loss: 2.4624194757356936

Epoch: 6| Step: 5
Training loss: 0.658883464800109
Validation loss: 2.408864632904986

Epoch: 6| Step: 6
Training loss: 0.4912180208032951
Validation loss: 2.422839914809986

Epoch: 6| Step: 7
Training loss: 1.0964270935208393
Validation loss: 2.3971126443667647

Epoch: 6| Step: 8
Training loss: 0.8111402063471362
Validation loss: 2.4291544427330027

Epoch: 6| Step: 9
Training loss: 0.8438503770814182
Validation loss: 2.4437244763811847

Epoch: 6| Step: 10
Training loss: 0.8103359821299303
Validation loss: 2.428940823571276

Epoch: 6| Step: 11
Training loss: 0.9342955182312301
Validation loss: 2.436777336413341

Epoch: 6| Step: 12
Training loss: 0.5986030160479999
Validation loss: 2.3886335446637066

Epoch: 6| Step: 13
Training loss: 0.4244290499755345
Validation loss: 2.385790617758434

Epoch: 231| Step: 0
Training loss: 0.5592733930232083
Validation loss: 2.408408967804841

Epoch: 6| Step: 1
Training loss: 0.9128578921233321
Validation loss: 2.4319925997650627

Epoch: 6| Step: 2
Training loss: 0.8391972026995611
Validation loss: 2.4256070071984572

Epoch: 6| Step: 3
Training loss: 0.8872813989839814
Validation loss: 2.4189277242343126

Epoch: 6| Step: 4
Training loss: 0.8435048347610455
Validation loss: 2.4645953886889296

Epoch: 6| Step: 5
Training loss: 0.73118531682779
Validation loss: 2.4979936927171216

Epoch: 6| Step: 6
Training loss: 0.646589218811822
Validation loss: 2.453493848087733

Epoch: 6| Step: 7
Training loss: 0.6002946845235363
Validation loss: 2.4741136327076623

Epoch: 6| Step: 8
Training loss: 0.7508351920892004
Validation loss: 2.437845137829767

Epoch: 6| Step: 9
Training loss: 1.0365845237602633
Validation loss: 2.449425862602831

Epoch: 6| Step: 10
Training loss: 0.6119572628781813
Validation loss: 2.4440575374187743

Epoch: 6| Step: 11
Training loss: 0.6091776308133214
Validation loss: 2.4470800868888647

Epoch: 6| Step: 12
Training loss: 0.41452721842197554
Validation loss: 2.445069360031698

Epoch: 6| Step: 13
Training loss: 0.9808571034978272
Validation loss: 2.3960835850916617

Epoch: 232| Step: 0
Training loss: 0.6354599661744098
Validation loss: 2.450654103714505

Epoch: 6| Step: 1
Training loss: 0.7412243667210245
Validation loss: 2.4361831351440077

Epoch: 6| Step: 2
Training loss: 0.7077511236598919
Validation loss: 2.4111254755217013

Epoch: 6| Step: 3
Training loss: 0.7508735734936504
Validation loss: 2.3739594650408047

Epoch: 6| Step: 4
Training loss: 0.5875088792495152
Validation loss: 2.4091259544894736

Epoch: 6| Step: 5
Training loss: 1.0127576994554999
Validation loss: 2.37303367782239

Epoch: 6| Step: 6
Training loss: 0.6852630940800322
Validation loss: 2.3718243110179134

Epoch: 6| Step: 7
Training loss: 1.0540470015163648
Validation loss: 2.354299635366683

Epoch: 6| Step: 8
Training loss: 0.7787661167148657
Validation loss: 2.3325846220887834

Epoch: 6| Step: 9
Training loss: 0.5967201930905393
Validation loss: 2.3615746510175954

Epoch: 6| Step: 10
Training loss: 0.8482833160189731
Validation loss: 2.3376117681551856

Epoch: 6| Step: 11
Training loss: 0.49732765176494015
Validation loss: 2.3619012127962273

Epoch: 6| Step: 12
Training loss: 0.8222660599297394
Validation loss: 2.329516481501717

Epoch: 6| Step: 13
Training loss: 0.23961164818560135
Validation loss: 2.392370974203877

Epoch: 233| Step: 0
Training loss: 0.6883889866314218
Validation loss: 2.414825393245453

Epoch: 6| Step: 1
Training loss: 0.8391297965171923
Validation loss: 2.399298548053156

Epoch: 6| Step: 2
Training loss: 1.0335715778074666
Validation loss: 2.4071112999551576

Epoch: 6| Step: 3
Training loss: 0.6577633257175385
Validation loss: 2.4251067057421354

Epoch: 6| Step: 4
Training loss: 0.681460468782978
Validation loss: 2.415130398148986

Epoch: 6| Step: 5
Training loss: 0.6242815179502973
Validation loss: 2.4360716857493747

Epoch: 6| Step: 6
Training loss: 0.44155197776249555
Validation loss: 2.4015493473940146

Epoch: 6| Step: 7
Training loss: 0.7416952408061734
Validation loss: 2.431554600201765

Epoch: 6| Step: 8
Training loss: 0.9002378917580047
Validation loss: 2.4079082077457508

Epoch: 6| Step: 9
Training loss: 0.8804912263020451
Validation loss: 2.432496867309856

Epoch: 6| Step: 10
Training loss: 0.6307085169827841
Validation loss: 2.39130065257946

Epoch: 6| Step: 11
Training loss: 0.7067438879946352
Validation loss: 2.3727775558306825

Epoch: 6| Step: 12
Training loss: 0.4994982645827533
Validation loss: 2.3542223361227785

Epoch: 6| Step: 13
Training loss: 0.8651517049247373
Validation loss: 2.3615777166485943

Epoch: 234| Step: 0
Training loss: 0.7605388012003438
Validation loss: 2.3684085396259986

Epoch: 6| Step: 1
Training loss: 0.6214651520811412
Validation loss: 2.3360620813130915

Epoch: 6| Step: 2
Training loss: 0.6736256170731885
Validation loss: 2.365565266096626

Epoch: 6| Step: 3
Training loss: 0.693873255322544
Validation loss: 2.3688849992709304

Epoch: 6| Step: 4
Training loss: 0.8436404969542396
Validation loss: 2.378025982319002

Epoch: 6| Step: 5
Training loss: 0.7266205795208748
Validation loss: 2.411139499279557

Epoch: 6| Step: 6
Training loss: 0.5122425514320085
Validation loss: 2.431593267140493

Epoch: 6| Step: 7
Training loss: 0.5996780853168578
Validation loss: 2.4157449681754493

Epoch: 6| Step: 8
Training loss: 0.725502512514061
Validation loss: 2.383832133794142

Epoch: 6| Step: 9
Training loss: 0.7756286178984015
Validation loss: 2.4103704692938566

Epoch: 6| Step: 10
Training loss: 0.8165269972291054
Validation loss: 2.4034388965524536

Epoch: 6| Step: 11
Training loss: 0.7610032462478153
Validation loss: 2.4118661207244574

Epoch: 6| Step: 12
Training loss: 0.6767925347122193
Validation loss: 2.4097851175489793

Epoch: 6| Step: 13
Training loss: 1.2475533860428245
Validation loss: 2.44573733144211

Epoch: 235| Step: 0
Training loss: 0.2100198352619597
Validation loss: 2.392136138748086

Epoch: 6| Step: 1
Training loss: 0.9418149828505022
Validation loss: 2.4400532057959454

Epoch: 6| Step: 2
Training loss: 0.783112898883043
Validation loss: 2.416074718146234

Epoch: 6| Step: 3
Training loss: 0.41897278808983185
Validation loss: 2.3905190429541237

Epoch: 6| Step: 4
Training loss: 0.7194315954195896
Validation loss: 2.4385887135745636

Epoch: 6| Step: 5
Training loss: 0.8344897273478765
Validation loss: 2.3831394045951706

Epoch: 6| Step: 6
Training loss: 0.6300825172077301
Validation loss: 2.413083434505649

Epoch: 6| Step: 7
Training loss: 0.9352750761661976
Validation loss: 2.40643254666252

Epoch: 6| Step: 8
Training loss: 0.8117316721382366
Validation loss: 2.4197728804753074

Epoch: 6| Step: 9
Training loss: 0.731511600684003
Validation loss: 2.4010503400979126

Epoch: 6| Step: 10
Training loss: 0.6515933534923677
Validation loss: 2.423215986924779

Epoch: 6| Step: 11
Training loss: 0.634742853783266
Validation loss: 2.4186382993836504

Epoch: 6| Step: 12
Training loss: 0.7267197059456102
Validation loss: 2.3936346718518386

Epoch: 6| Step: 13
Training loss: 0.9614781045310151
Validation loss: 2.453715046324358

Epoch: 236| Step: 0
Training loss: 0.7619515478969912
Validation loss: 2.4256113236021486

Epoch: 6| Step: 1
Training loss: 0.3701866708720768
Validation loss: 2.3900616447377034

Epoch: 6| Step: 2
Training loss: 0.577001304396902
Validation loss: 2.4042537182154056

Epoch: 6| Step: 3
Training loss: 0.7711329951633202
Validation loss: 2.3512161283783546

Epoch: 6| Step: 4
Training loss: 0.8720991550643987
Validation loss: 2.355045011727837

Epoch: 6| Step: 5
Training loss: 0.7871602233667705
Validation loss: 2.3680503753819404

Epoch: 6| Step: 6
Training loss: 0.5262458958771568
Validation loss: 2.3995693622854875

Epoch: 6| Step: 7
Training loss: 0.8272478028190718
Validation loss: 2.385954439494038

Epoch: 6| Step: 8
Training loss: 0.6086987141697292
Validation loss: 2.3892177161074595

Epoch: 6| Step: 9
Training loss: 0.530122851492664
Validation loss: 2.3968692574808803

Epoch: 6| Step: 10
Training loss: 0.9455828634733651
Validation loss: 2.3860814795023724

Epoch: 6| Step: 11
Training loss: 0.8486843642192251
Validation loss: 2.4083023843253817

Epoch: 6| Step: 12
Training loss: 0.7200157795607449
Validation loss: 2.3574692667448085

Epoch: 6| Step: 13
Training loss: 1.1221334175711166
Validation loss: 2.363122602083812

Epoch: 237| Step: 0
Training loss: 0.42132529013210707
Validation loss: 2.371360959315202

Epoch: 6| Step: 1
Training loss: 0.8620523189302187
Validation loss: 2.378701175234772

Epoch: 6| Step: 2
Training loss: 0.8837572292264211
Validation loss: 2.372344902798257

Epoch: 6| Step: 3
Training loss: 0.23987445386254905
Validation loss: 2.3873978533092908

Epoch: 6| Step: 4
Training loss: 0.4384621360801441
Validation loss: 2.3760094863888948

Epoch: 6| Step: 5
Training loss: 0.7637050455601787
Validation loss: 2.355399876426025

Epoch: 6| Step: 6
Training loss: 0.8900517408996944
Validation loss: 2.3938371072129834

Epoch: 6| Step: 7
Training loss: 0.6755502118438192
Validation loss: 2.392027193099401

Epoch: 6| Step: 8
Training loss: 0.9532908623633888
Validation loss: 2.3867191152033778

Epoch: 6| Step: 9
Training loss: 0.6852322152455681
Validation loss: 2.404881299440778

Epoch: 6| Step: 10
Training loss: 0.7704087497090524
Validation loss: 2.382247930544295

Epoch: 6| Step: 11
Training loss: 0.9226458607863133
Validation loss: 2.391517701436485

Epoch: 6| Step: 12
Training loss: 0.5451642662939354
Validation loss: 2.3704703252499613

Epoch: 6| Step: 13
Training loss: 0.567445603801139
Validation loss: 2.3703561933730066

Epoch: 238| Step: 0
Training loss: 0.6809779665207152
Validation loss: 2.366575976170445

Epoch: 6| Step: 1
Training loss: 0.24019358063732765
Validation loss: 2.3685993208237104

Epoch: 6| Step: 2
Training loss: 0.8151190434439907
Validation loss: 2.350405803936818

Epoch: 6| Step: 3
Training loss: 0.8391281627911942
Validation loss: 2.361332087719272

Epoch: 6| Step: 4
Training loss: 0.9276670732681181
Validation loss: 2.362953776654207

Epoch: 6| Step: 5
Training loss: 0.7672908332675865
Validation loss: 2.388040987746664

Epoch: 6| Step: 6
Training loss: 0.6957958984203672
Validation loss: 2.3947104088731526

Epoch: 6| Step: 7
Training loss: 0.7924137898314446
Validation loss: 2.3871741544052894

Epoch: 6| Step: 8
Training loss: 0.39815638479852217
Validation loss: 2.389785234125599

Epoch: 6| Step: 9
Training loss: 0.7275490164875899
Validation loss: 2.392981221486785

Epoch: 6| Step: 10
Training loss: 0.5610830155452975
Validation loss: 2.420512758054746

Epoch: 6| Step: 11
Training loss: 0.6424445387358838
Validation loss: 2.4545431798614548

Epoch: 6| Step: 12
Training loss: 0.8745071180979801
Validation loss: 2.415896701113327

Epoch: 6| Step: 13
Training loss: 0.6666375218418328
Validation loss: 2.4592712657743787

Epoch: 239| Step: 0
Training loss: 0.7870057750136178
Validation loss: 2.49187090849419

Epoch: 6| Step: 1
Training loss: 0.8332118581608365
Validation loss: 2.451917467247156

Epoch: 6| Step: 2
Training loss: 0.6075919302703333
Validation loss: 2.467163590260396

Epoch: 6| Step: 3
Training loss: 0.5498221413262568
Validation loss: 2.487088257872509

Epoch: 6| Step: 4
Training loss: 0.7738805715551054
Validation loss: 2.459337138706605

Epoch: 6| Step: 5
Training loss: 0.4991073985675534
Validation loss: 2.418171747226644

Epoch: 6| Step: 6
Training loss: 0.7757880588013729
Validation loss: 2.4257660421553586

Epoch: 6| Step: 7
Training loss: 0.6022176271592132
Validation loss: 2.406829010011859

Epoch: 6| Step: 8
Training loss: 0.5069635484164408
Validation loss: 2.4026069993766392

Epoch: 6| Step: 9
Training loss: 0.8756230043746567
Validation loss: 2.366180037673123

Epoch: 6| Step: 10
Training loss: 0.9948605551842301
Validation loss: 2.410434176297859

Epoch: 6| Step: 11
Training loss: 0.4489648516094014
Validation loss: 2.388562809980206

Epoch: 6| Step: 12
Training loss: 0.8307820286369585
Validation loss: 2.3704089406886393

Epoch: 6| Step: 13
Training loss: 0.54124440337849
Validation loss: 2.3930256164371198

Epoch: 240| Step: 0
Training loss: 0.7343839279606074
Validation loss: 2.386290050778927

Epoch: 6| Step: 1
Training loss: 0.6015301732877031
Validation loss: 2.41299805438999

Epoch: 6| Step: 2
Training loss: 0.9522675894497047
Validation loss: 2.3803256975656417

Epoch: 6| Step: 3
Training loss: 0.6242953619892688
Validation loss: 2.4017495284229646

Epoch: 6| Step: 4
Training loss: 0.3466206460026554
Validation loss: 2.4008484029600385

Epoch: 6| Step: 5
Training loss: 0.8482102372495938
Validation loss: 2.370339541888318

Epoch: 6| Step: 6
Training loss: 0.6027108663151252
Validation loss: 2.3426119977834103

Epoch: 6| Step: 7
Training loss: 0.7735609476234632
Validation loss: 2.3833998100388936

Epoch: 6| Step: 8
Training loss: 0.7492388200508102
Validation loss: 2.3902210095583007

Epoch: 6| Step: 9
Training loss: 0.6445842605523326
Validation loss: 2.401726330387388

Epoch: 6| Step: 10
Training loss: 0.6901292160574231
Validation loss: 2.3970907976638807

Epoch: 6| Step: 11
Training loss: 0.6437998465340826
Validation loss: 2.407556281788274

Epoch: 6| Step: 12
Training loss: 0.8471937895695801
Validation loss: 2.4185305290073167

Epoch: 6| Step: 13
Training loss: 0.6425512012534281
Validation loss: 2.404484410989607

Epoch: 241| Step: 0
Training loss: 0.7912017979937992
Validation loss: 2.3692671112213164

Epoch: 6| Step: 1
Training loss: 1.0549486190252415
Validation loss: 2.414296627190345

Epoch: 6| Step: 2
Training loss: 0.29160791327580216
Validation loss: 2.4250427107860286

Epoch: 6| Step: 3
Training loss: 0.5460146539733784
Validation loss: 2.3903931096361055

Epoch: 6| Step: 4
Training loss: 0.7142376440766662
Validation loss: 2.3892385478566136

Epoch: 6| Step: 5
Training loss: 0.9761394652580685
Validation loss: 2.3937572474318958

Epoch: 6| Step: 6
Training loss: 0.671230406164409
Validation loss: 2.3774221759673715

Epoch: 6| Step: 7
Training loss: 0.6143410630811843
Validation loss: 2.400247595006532

Epoch: 6| Step: 8
Training loss: 0.4012288507193928
Validation loss: 2.38600749202121

Epoch: 6| Step: 9
Training loss: 0.602146261769935
Validation loss: 2.4039709610135107

Epoch: 6| Step: 10
Training loss: 0.8213244055220447
Validation loss: 2.416089359899518

Epoch: 6| Step: 11
Training loss: 0.6538677117625753
Validation loss: 2.402070395765292

Epoch: 6| Step: 12
Training loss: 0.6613233733978185
Validation loss: 2.4129307745643573

Epoch: 6| Step: 13
Training loss: 0.7210372935767505
Validation loss: 2.407585823746709

Epoch: 242| Step: 0
Training loss: 0.5697489789306677
Validation loss: 2.4230010871808756

Epoch: 6| Step: 1
Training loss: 0.7311098681778796
Validation loss: 2.385095304823875

Epoch: 6| Step: 2
Training loss: 0.5886290212523436
Validation loss: 2.4011468426305584

Epoch: 6| Step: 3
Training loss: 0.5864727373087733
Validation loss: 2.41380538657072

Epoch: 6| Step: 4
Training loss: 1.0002843333375
Validation loss: 2.416595899424834

Epoch: 6| Step: 5
Training loss: 0.4574527427102867
Validation loss: 2.378912361374658

Epoch: 6| Step: 6
Training loss: 0.6970364062955069
Validation loss: 2.362386425504897

Epoch: 6| Step: 7
Training loss: 0.617272721213467
Validation loss: 2.399555038535099

Epoch: 6| Step: 8
Training loss: 0.374043994468122
Validation loss: 2.3648184487347255

Epoch: 6| Step: 9
Training loss: 0.8502326520716392
Validation loss: 2.378396244590564

Epoch: 6| Step: 10
Training loss: 0.7896693700317682
Validation loss: 2.4153729930550294

Epoch: 6| Step: 11
Training loss: 0.5613966823647009
Validation loss: 2.434923588360568

Epoch: 6| Step: 12
Training loss: 0.789825448296749
Validation loss: 2.458844878497756

Epoch: 6| Step: 13
Training loss: 1.09294529331387
Validation loss: 2.471133903456857

Epoch: 243| Step: 0
Training loss: 0.7806452508625441
Validation loss: 2.4669083475492193

Epoch: 6| Step: 1
Training loss: 0.5839598532539082
Validation loss: 2.415012235320682

Epoch: 6| Step: 2
Training loss: 0.9345642536090498
Validation loss: 2.367582780045038

Epoch: 6| Step: 3
Training loss: 0.6761848038572843
Validation loss: 2.319928250096166

Epoch: 6| Step: 4
Training loss: 0.7742720830968772
Validation loss: 2.255783745028341

Epoch: 6| Step: 5
Training loss: 0.5015943855774527
Validation loss: 2.307153991607984

Epoch: 6| Step: 6
Training loss: 0.8225640776930456
Validation loss: 2.3033945335054216

Epoch: 6| Step: 7
Training loss: 0.42932500287169645
Validation loss: 2.262266886895256

Epoch: 6| Step: 8
Training loss: 0.871281488142374
Validation loss: 2.2891661313131864

Epoch: 6| Step: 9
Training loss: 0.47428201445094215
Validation loss: 2.3228283848857028

Epoch: 6| Step: 10
Training loss: 0.41610688117547934
Validation loss: 2.3413538825243596

Epoch: 6| Step: 11
Training loss: 1.0878135886730695
Validation loss: 2.3972126821298176

Epoch: 6| Step: 12
Training loss: 0.5333814218070606
Validation loss: 2.4364178082347987

Epoch: 6| Step: 13
Training loss: 0.6997928713142434
Validation loss: 2.4172456604321098

Epoch: 244| Step: 0
Training loss: 0.6557841236777758
Validation loss: 2.388311969120045

Epoch: 6| Step: 1
Training loss: 0.3779246997750552
Validation loss: 2.4306403873560387

Epoch: 6| Step: 2
Training loss: 0.8667911964288946
Validation loss: 2.426476016837431

Epoch: 6| Step: 3
Training loss: 0.3497572857695724
Validation loss: 2.389895808428392

Epoch: 6| Step: 4
Training loss: 0.7831324975947955
Validation loss: 2.377973857832504

Epoch: 6| Step: 5
Training loss: 0.9061708744627971
Validation loss: 2.3741657657179798

Epoch: 6| Step: 6
Training loss: 0.6845969985353391
Validation loss: 2.358993733081599

Epoch: 6| Step: 7
Training loss: 0.6593104480042846
Validation loss: 2.3370645983663416

Epoch: 6| Step: 8
Training loss: 0.36054346614065147
Validation loss: 2.336049943819266

Epoch: 6| Step: 9
Training loss: 0.897669455594635
Validation loss: 2.3587133409793624

Epoch: 6| Step: 10
Training loss: 0.4823962061921833
Validation loss: 2.3599649430775878

Epoch: 6| Step: 11
Training loss: 0.7583874360022653
Validation loss: 2.3796830683658112

Epoch: 6| Step: 12
Training loss: 0.7673106807479924
Validation loss: 2.4305119097922505

Epoch: 6| Step: 13
Training loss: 0.652872453806216
Validation loss: 2.4330085336887803

Epoch: 245| Step: 0
Training loss: 0.8038334434467546
Validation loss: 2.4168062495089746

Epoch: 6| Step: 1
Training loss: 0.4995468589675565
Validation loss: 2.4487458920215217

Epoch: 6| Step: 2
Training loss: 0.3214466902568541
Validation loss: 2.4504024095195134

Epoch: 6| Step: 3
Training loss: 0.7069548254701885
Validation loss: 2.432295795540901

Epoch: 6| Step: 4
Training loss: 0.6572054084445583
Validation loss: 2.4441869056403287

Epoch: 6| Step: 5
Training loss: 0.8351506960106958
Validation loss: 2.4336620824167987

Epoch: 6| Step: 6
Training loss: 0.7082498912656345
Validation loss: 2.440314473625322

Epoch: 6| Step: 7
Training loss: 0.2767597551082471
Validation loss: 2.3993538805432357

Epoch: 6| Step: 8
Training loss: 0.8465189533714252
Validation loss: 2.401419632104672

Epoch: 6| Step: 9
Training loss: 0.8963427130443761
Validation loss: 2.393023489912068

Epoch: 6| Step: 10
Training loss: 0.939153611623565
Validation loss: 2.373537188445638

Epoch: 6| Step: 11
Training loss: 0.5304051581625314
Validation loss: 2.394855830240125

Epoch: 6| Step: 12
Training loss: 0.2751853800294941
Validation loss: 2.3994520507416572

Epoch: 6| Step: 13
Training loss: 0.7414380757100419
Validation loss: 2.4174248782826435

Epoch: 246| Step: 0
Training loss: 0.6573695895822307
Validation loss: 2.4484391331488076

Epoch: 6| Step: 1
Training loss: 0.9264089653347226
Validation loss: 2.4703663095881105

Epoch: 6| Step: 2
Training loss: 0.6022599375955171
Validation loss: 2.497101621307889

Epoch: 6| Step: 3
Training loss: 0.729515391929305
Validation loss: 2.4631167194478008

Epoch: 6| Step: 4
Training loss: 0.7485991747330548
Validation loss: 2.47136154665576

Epoch: 6| Step: 5
Training loss: 0.5004953970054368
Validation loss: 2.4337718108863586

Epoch: 6| Step: 6
Training loss: 0.667704055720854
Validation loss: 2.3942108574295604

Epoch: 6| Step: 7
Training loss: 0.26723558539760095
Validation loss: 2.388554009990437

Epoch: 6| Step: 8
Training loss: 0.5878099151668065
Validation loss: 2.3760410870235145

Epoch: 6| Step: 9
Training loss: 0.49702159590400863
Validation loss: 2.3708449557863815

Epoch: 6| Step: 10
Training loss: 0.7515771495636465
Validation loss: 2.34883145782153

Epoch: 6| Step: 11
Training loss: 0.7822107511105844
Validation loss: 2.3877180294899993

Epoch: 6| Step: 12
Training loss: 0.4858000925948964
Validation loss: 2.373621960182274

Epoch: 6| Step: 13
Training loss: 0.8919535315089099
Validation loss: 2.376713160235659

Epoch: 247| Step: 0
Training loss: 0.9103369799438132
Validation loss: 2.384479183907269

Epoch: 6| Step: 1
Training loss: 0.9404551026266259
Validation loss: 2.398256510497041

Epoch: 6| Step: 2
Training loss: 0.6191321050496941
Validation loss: 2.4262558453636816

Epoch: 6| Step: 3
Training loss: 0.6076555201358586
Validation loss: 2.4269419011026527

Epoch: 6| Step: 4
Training loss: 0.5185514690636941
Validation loss: 2.416223436204299

Epoch: 6| Step: 5
Training loss: 0.639468055508847
Validation loss: 2.444920002737343

Epoch: 6| Step: 6
Training loss: 0.5374713579575147
Validation loss: 2.425040850196428

Epoch: 6| Step: 7
Training loss: 0.5009265302098306
Validation loss: 2.404439831514021

Epoch: 6| Step: 8
Training loss: 0.5771584808456861
Validation loss: 2.391362382619961

Epoch: 6| Step: 9
Training loss: 0.7263956185931353
Validation loss: 2.390116698207109

Epoch: 6| Step: 10
Training loss: 0.2725659513283427
Validation loss: 2.4143121430122925

Epoch: 6| Step: 11
Training loss: 0.4469708799994065
Validation loss: 2.4137203840826014

Epoch: 6| Step: 12
Training loss: 0.9395162834778402
Validation loss: 2.377310648367869

Epoch: 6| Step: 13
Training loss: 0.6161767916884061
Validation loss: 2.396247574001861

Epoch: 248| Step: 0
Training loss: 0.9341349290146277
Validation loss: 2.375144712295535

Epoch: 6| Step: 1
Training loss: 0.5389930569797835
Validation loss: 2.424674362326493

Epoch: 6| Step: 2
Training loss: 0.6815266117615209
Validation loss: 2.39331787727656

Epoch: 6| Step: 3
Training loss: 0.7100118542742729
Validation loss: 2.434028372435057

Epoch: 6| Step: 4
Training loss: 0.7910970763668294
Validation loss: 2.430071366733769

Epoch: 6| Step: 5
Training loss: 0.3514850425162742
Validation loss: 2.441111130726373

Epoch: 6| Step: 6
Training loss: 0.4826838596655712
Validation loss: 2.406020725824667

Epoch: 6| Step: 7
Training loss: 0.6269589004963609
Validation loss: 2.4135828940569772

Epoch: 6| Step: 8
Training loss: 0.7818989537973768
Validation loss: 2.3994484618908896

Epoch: 6| Step: 9
Training loss: 0.6309551721358619
Validation loss: 2.3647142223802518

Epoch: 6| Step: 10
Training loss: 0.6849829808090913
Validation loss: 2.3622048004042004

Epoch: 6| Step: 11
Training loss: 0.7056013369245904
Validation loss: 2.3357040569032863

Epoch: 6| Step: 12
Training loss: 0.6396099282822966
Validation loss: 2.3535846887802543

Epoch: 6| Step: 13
Training loss: 0.6071250165594144
Validation loss: 2.3426998616066954

Epoch: 249| Step: 0
Training loss: 0.9468164381796066
Validation loss: 2.331534807899288

Epoch: 6| Step: 1
Training loss: 0.8367669099683865
Validation loss: 2.3566551229494124

Epoch: 6| Step: 2
Training loss: 0.5967574248425322
Validation loss: 2.3770862261355776

Epoch: 6| Step: 3
Training loss: 0.6966876030320669
Validation loss: 2.3918340892002528

Epoch: 6| Step: 4
Training loss: 0.6068471415811093
Validation loss: 2.440405224677326

Epoch: 6| Step: 5
Training loss: 0.5927806520730005
Validation loss: 2.4475271117048574

Epoch: 6| Step: 6
Training loss: 0.7658377760452844
Validation loss: 2.4333802403126126

Epoch: 6| Step: 7
Training loss: 0.2189090780447169
Validation loss: 2.393928994231257

Epoch: 6| Step: 8
Training loss: 0.46292329825805284
Validation loss: 2.3994934530197987

Epoch: 6| Step: 9
Training loss: 0.8577211591941295
Validation loss: 2.3903468017936333

Epoch: 6| Step: 10
Training loss: 0.2974257380097137
Validation loss: 2.3719971130619624

Epoch: 6| Step: 11
Training loss: 0.5104626680262287
Validation loss: 2.363484431439402

Epoch: 6| Step: 12
Training loss: 0.8557255329063441
Validation loss: 2.3626839596464495

Epoch: 6| Step: 13
Training loss: 0.5437537905681511
Validation loss: 2.369407776510695

Epoch: 250| Step: 0
Training loss: 0.46503359660429483
Validation loss: 2.340353830504201

Epoch: 6| Step: 1
Training loss: 0.7526854280910342
Validation loss: 2.382609557263404

Epoch: 6| Step: 2
Training loss: 0.5517954045545765
Validation loss: 2.3946281372954394

Epoch: 6| Step: 3
Training loss: 0.5146316149168103
Validation loss: 2.374082323251303

Epoch: 6| Step: 4
Training loss: 0.5846386309721561
Validation loss: 2.3954520717115537

Epoch: 6| Step: 5
Training loss: 0.4489995338611689
Validation loss: 2.364304876381972

Epoch: 6| Step: 6
Training loss: 1.115170077793657
Validation loss: 2.3792960318084706

Epoch: 6| Step: 7
Training loss: 0.9350192945702882
Validation loss: 2.4032684379375704

Epoch: 6| Step: 8
Training loss: 0.6635562986939446
Validation loss: 2.324552759878147

Epoch: 6| Step: 9
Training loss: 0.2836338056960144
Validation loss: 2.3141319294675773

Epoch: 6| Step: 10
Training loss: 0.7426052724660844
Validation loss: 2.3246744135429793

Epoch: 6| Step: 11
Training loss: 0.626908083810012
Validation loss: 2.3176146575553913

Epoch: 6| Step: 12
Training loss: 0.4763985648931929
Validation loss: 2.3523097049165957

Epoch: 6| Step: 13
Training loss: 0.2263937601286671
Validation loss: 2.342091211402698

Epoch: 251| Step: 0
Training loss: 0.4727877126677262
Validation loss: 2.3335963604895147

Epoch: 6| Step: 1
Training loss: 0.45222436255079473
Validation loss: 2.3232270455610196

Epoch: 6| Step: 2
Training loss: 0.7306455510416929
Validation loss: 2.3300241654000375

Epoch: 6| Step: 3
Training loss: 0.6342065784896306
Validation loss: 2.3480503240952677

Epoch: 6| Step: 4
Training loss: 0.5812223304807665
Validation loss: 2.356255604653052

Epoch: 6| Step: 5
Training loss: 0.6130258550792048
Validation loss: 2.376609696073889

Epoch: 6| Step: 6
Training loss: 0.5550104463728246
Validation loss: 2.348374369864819

Epoch: 6| Step: 7
Training loss: 0.5931575228393718
Validation loss: 2.3519010830517293

Epoch: 6| Step: 8
Training loss: 0.6650405861365164
Validation loss: 2.366266179144281

Epoch: 6| Step: 9
Training loss: 0.6707195282198297
Validation loss: 2.375382444960667

Epoch: 6| Step: 10
Training loss: 0.32850738224751713
Validation loss: 2.3410475575659406

Epoch: 6| Step: 11
Training loss: 0.6370075717517933
Validation loss: 2.3129413081657657

Epoch: 6| Step: 12
Training loss: 0.9145376812454398
Validation loss: 2.364677030712608

Epoch: 6| Step: 13
Training loss: 0.7876969409096266
Validation loss: 2.340081116531419

Epoch: 252| Step: 0
Training loss: 0.41036235535493687
Validation loss: 2.322758045700852

Epoch: 6| Step: 1
Training loss: 0.6027175910872504
Validation loss: 2.3447827760652658

Epoch: 6| Step: 2
Training loss: 0.7001503433833104
Validation loss: 2.337792066176292

Epoch: 6| Step: 3
Training loss: 0.6312591891989051
Validation loss: 2.326325037820824

Epoch: 6| Step: 4
Training loss: 0.6703202422790849
Validation loss: 2.3128694329559343

Epoch: 6| Step: 5
Training loss: 0.7101283656522164
Validation loss: 2.363718924778938

Epoch: 6| Step: 6
Training loss: 0.8023031891225122
Validation loss: 2.3743879698666097

Epoch: 6| Step: 7
Training loss: 0.6431198387569117
Validation loss: 2.3515308233407533

Epoch: 6| Step: 8
Training loss: 0.7107691722756951
Validation loss: 2.3551116195369297

Epoch: 6| Step: 9
Training loss: 0.4406520172385484
Validation loss: 2.3859256037215073

Epoch: 6| Step: 10
Training loss: 0.40189792413424597
Validation loss: 2.3726573955825896

Epoch: 6| Step: 11
Training loss: 0.7224934987498357
Validation loss: 2.3896897231939183

Epoch: 6| Step: 12
Training loss: 0.5558859008550583
Validation loss: 2.3591027257899753

Epoch: 6| Step: 13
Training loss: 0.6064453370713184
Validation loss: 2.3343820661543915

Epoch: 253| Step: 0
Training loss: 0.6368795086642103
Validation loss: 2.3486337228491463

Epoch: 6| Step: 1
Training loss: 0.9275258040630238
Validation loss: 2.339831723335969

Epoch: 6| Step: 2
Training loss: 0.9280543046736265
Validation loss: 2.322355266464993

Epoch: 6| Step: 3
Training loss: 0.5371353975407787
Validation loss: 2.3660297809713637

Epoch: 6| Step: 4
Training loss: 0.4066032744302075
Validation loss: 2.3655041853154493

Epoch: 6| Step: 5
Training loss: 0.7945063299211401
Validation loss: 2.3368463282344303

Epoch: 6| Step: 6
Training loss: 0.4025182808403078
Validation loss: 2.344036613632121

Epoch: 6| Step: 7
Training loss: 0.39720231623593705
Validation loss: 2.339276219771633

Epoch: 6| Step: 8
Training loss: 0.6702117737537603
Validation loss: 2.3762162564104305

Epoch: 6| Step: 9
Training loss: 0.5616899061158895
Validation loss: 2.3814487949304093

Epoch: 6| Step: 10
Training loss: 0.45519926235259883
Validation loss: 2.331934217902053

Epoch: 6| Step: 11
Training loss: 0.5391813230168444
Validation loss: 2.362683087262548

Epoch: 6| Step: 12
Training loss: 0.443626054727607
Validation loss: 2.329816615645222

Epoch: 6| Step: 13
Training loss: 0.48716288856164125
Validation loss: 2.328590972994935

Epoch: 254| Step: 0
Training loss: 0.6643194038261351
Validation loss: 2.3811307898420075

Epoch: 6| Step: 1
Training loss: 0.7509878328864141
Validation loss: 2.364924717138334

Epoch: 6| Step: 2
Training loss: 0.7838241132042115
Validation loss: 2.3369148007941045

Epoch: 6| Step: 3
Training loss: 0.6925603211293484
Validation loss: 2.371037589336214

Epoch: 6| Step: 4
Training loss: 0.5302414858133147
Validation loss: 2.39426780974834

Epoch: 6| Step: 5
Training loss: 0.6099804291556128
Validation loss: 2.3582636212143147

Epoch: 6| Step: 6
Training loss: 0.4787045164389686
Validation loss: 2.3721978366863214

Epoch: 6| Step: 7
Training loss: 0.7011977592089722
Validation loss: 2.3761980697426752

Epoch: 6| Step: 8
Training loss: 0.6043892127163768
Validation loss: 2.405117972008592

Epoch: 6| Step: 9
Training loss: 0.5325650320056705
Validation loss: 2.356085592421218

Epoch: 6| Step: 10
Training loss: 0.18386709885506958
Validation loss: 2.3868530433295625

Epoch: 6| Step: 11
Training loss: 0.3007850275174025
Validation loss: 2.3734283088049706

Epoch: 6| Step: 12
Training loss: 0.8720946100316657
Validation loss: 2.3871265131057684

Epoch: 6| Step: 13
Training loss: 0.3185365219129038
Validation loss: 2.392058409581292

Epoch: 255| Step: 0
Training loss: 0.6073492074166256
Validation loss: 2.3707770571472557

Epoch: 6| Step: 1
Training loss: 0.5977855118733162
Validation loss: 2.4213452466692695

Epoch: 6| Step: 2
Training loss: 0.5535787327016461
Validation loss: 2.3697870282643083

Epoch: 6| Step: 3
Training loss: 0.15980687646478609
Validation loss: 2.378471041175767

Epoch: 6| Step: 4
Training loss: 0.7930353822571533
Validation loss: 2.370073546789793

Epoch: 6| Step: 5
Training loss: 0.3510507992293216
Validation loss: 2.3764251055909953

Epoch: 6| Step: 6
Training loss: 0.7508759152118052
Validation loss: 2.3781785781355294

Epoch: 6| Step: 7
Training loss: 0.5105013160838051
Validation loss: 2.3663114972830606

Epoch: 6| Step: 8
Training loss: 0.3869913084744641
Validation loss: 2.3423352484293654

Epoch: 6| Step: 9
Training loss: 0.7822670991564246
Validation loss: 2.377902877214122

Epoch: 6| Step: 10
Training loss: 0.5662876925860066
Validation loss: 2.3646876211091588

Epoch: 6| Step: 11
Training loss: 0.8964544220618235
Validation loss: 2.3407825916968585

Epoch: 6| Step: 12
Training loss: 0.7221767174820809
Validation loss: 2.3206323109293843

Epoch: 6| Step: 13
Training loss: 0.32304631086713065
Validation loss: 2.3275696182241328

Epoch: 256| Step: 0
Training loss: 0.7389864102121919
Validation loss: 2.3508259007262478

Epoch: 6| Step: 1
Training loss: 0.3612272998251086
Validation loss: 2.3625521723159424

Epoch: 6| Step: 2
Training loss: 0.8113367116048542
Validation loss: 2.3866045814623567

Epoch: 6| Step: 3
Training loss: 0.6219757822694593
Validation loss: 2.4193518921618824

Epoch: 6| Step: 4
Training loss: 0.5820703429336084
Validation loss: 2.4195179616292006

Epoch: 6| Step: 5
Training loss: 0.6512130257476518
Validation loss: 2.407779272102706

Epoch: 6| Step: 6
Training loss: 0.5244181542263556
Validation loss: 2.408078465681194

Epoch: 6| Step: 7
Training loss: 0.5999129331518228
Validation loss: 2.425468361367546

Epoch: 6| Step: 8
Training loss: 0.2970464362005334
Validation loss: 2.447282293084021

Epoch: 6| Step: 9
Training loss: 0.3814840817611477
Validation loss: 2.4204631171244695

Epoch: 6| Step: 10
Training loss: 0.7167864806541567
Validation loss: 2.4421604083426045

Epoch: 6| Step: 11
Training loss: 0.5826497983485794
Validation loss: 2.4434478663212906

Epoch: 6| Step: 12
Training loss: 0.8000243168353844
Validation loss: 2.4377479374536732

Epoch: 6| Step: 13
Training loss: 0.5728391305879652
Validation loss: 2.402683019404568

Epoch: 257| Step: 0
Training loss: 0.5486365693324615
Validation loss: 2.3441684625520005

Epoch: 6| Step: 1
Training loss: 0.6259289513631248
Validation loss: 2.3300247111306893

Epoch: 6| Step: 2
Training loss: 0.5419837744807353
Validation loss: 2.350391551421914

Epoch: 6| Step: 3
Training loss: 0.5858867114625845
Validation loss: 2.411441782102517

Epoch: 6| Step: 4
Training loss: 0.8503793318791081
Validation loss: 2.4027767649863865

Epoch: 6| Step: 5
Training loss: 0.693460806291214
Validation loss: 2.42432881720891

Epoch: 6| Step: 6
Training loss: 0.3301245752640245
Validation loss: 2.4302810130272747

Epoch: 6| Step: 7
Training loss: 0.5356725721921919
Validation loss: 2.4255239138733082

Epoch: 6| Step: 8
Training loss: 0.6744128799759533
Validation loss: 2.459897491821434

Epoch: 6| Step: 9
Training loss: 0.48412642714971904
Validation loss: 2.418291933658799

Epoch: 6| Step: 10
Training loss: 0.6252837967278122
Validation loss: 2.399947703981275

Epoch: 6| Step: 11
Training loss: 0.5041528734049034
Validation loss: 2.3920429133877765

Epoch: 6| Step: 12
Training loss: 0.7971644156480905
Validation loss: 2.3502371034592793

Epoch: 6| Step: 13
Training loss: 0.17695981280423434
Validation loss: 2.366994660342423

Epoch: 258| Step: 0
Training loss: 0.37678142451864194
Validation loss: 2.34376844829559

Epoch: 6| Step: 1
Training loss: 0.44628727618304465
Validation loss: 2.331478041256111

Epoch: 6| Step: 2
Training loss: 0.5996423768147323
Validation loss: 2.3425278308023385

Epoch: 6| Step: 3
Training loss: 0.519692474818547
Validation loss: 2.344528482418709

Epoch: 6| Step: 4
Training loss: 0.36659253393323854
Validation loss: 2.357249034953421

Epoch: 6| Step: 5
Training loss: 0.7529289750270218
Validation loss: 2.36943914925813

Epoch: 6| Step: 6
Training loss: 0.7214398843857551
Validation loss: 2.373380395903245

Epoch: 6| Step: 7
Training loss: 0.7631998383787771
Validation loss: 2.4156204847407623

Epoch: 6| Step: 8
Training loss: 0.5594709218218555
Validation loss: 2.4215335865965204

Epoch: 6| Step: 9
Training loss: 0.6315628239754927
Validation loss: 2.449763533193037

Epoch: 6| Step: 10
Training loss: 0.7047518664819441
Validation loss: 2.4325666337844645

Epoch: 6| Step: 11
Training loss: 0.6785393148008055
Validation loss: 2.3981680000324177

Epoch: 6| Step: 12
Training loss: 0.5492069660946619
Validation loss: 2.3610447244723383

Epoch: 6| Step: 13
Training loss: 0.6078006262710423
Validation loss: 2.352871157140004

Epoch: 259| Step: 0
Training loss: 0.46420202116610465
Validation loss: 2.3486650980242145

Epoch: 6| Step: 1
Training loss: 0.28059629127786784
Validation loss: 2.3088029366522425

Epoch: 6| Step: 2
Training loss: 0.7708104534018382
Validation loss: 2.385741740479945

Epoch: 6| Step: 3
Training loss: 0.25493250103103704
Validation loss: 2.3384465615902155

Epoch: 6| Step: 4
Training loss: 0.6567522579251592
Validation loss: 2.3360297121449727

Epoch: 6| Step: 5
Training loss: 0.7235296384333525
Validation loss: 2.3106015823654875

Epoch: 6| Step: 6
Training loss: 0.7387323767275309
Validation loss: 2.3155903796295103

Epoch: 6| Step: 7
Training loss: 0.8696577612466138
Validation loss: 2.3105007088622895

Epoch: 6| Step: 8
Training loss: 0.5622862833713986
Validation loss: 2.3592175080243245

Epoch: 6| Step: 9
Training loss: 0.7664773050669793
Validation loss: 2.376288176375199

Epoch: 6| Step: 10
Training loss: 0.4272073433877993
Validation loss: 2.3839063017067073

Epoch: 6| Step: 11
Training loss: 0.6734474986809963
Validation loss: 2.4384804492594716

Epoch: 6| Step: 12
Training loss: 0.5664479733588685
Validation loss: 2.398589493587527

Epoch: 6| Step: 13
Training loss: 0.4195965948663992
Validation loss: 2.3778135465841155

Epoch: 260| Step: 0
Training loss: 0.7924034471389683
Validation loss: 2.3691279222259296

Epoch: 6| Step: 1
Training loss: 0.4672178341512945
Validation loss: 2.3628746828116896

Epoch: 6| Step: 2
Training loss: 0.44402303892151124
Validation loss: 2.303221055937675

Epoch: 6| Step: 3
Training loss: 0.7484272520124254
Validation loss: 2.296298392958266

Epoch: 6| Step: 4
Training loss: 0.4052755700480414
Validation loss: 2.2832776031028366

Epoch: 6| Step: 5
Training loss: 0.7438595058062758
Validation loss: 2.305132340732623

Epoch: 6| Step: 6
Training loss: 0.8485518615532305
Validation loss: 2.31014652882349

Epoch: 6| Step: 7
Training loss: 0.7231987643720823
Validation loss: 2.338834063016047

Epoch: 6| Step: 8
Training loss: 0.5322936409492484
Validation loss: 2.382110054277085

Epoch: 6| Step: 9
Training loss: 0.44589280915686996
Validation loss: 2.364012970646242

Epoch: 6| Step: 10
Training loss: 0.7315306263611814
Validation loss: 2.394689434701452

Epoch: 6| Step: 11
Training loss: 0.48969783526178357
Validation loss: 2.4343702944913153

Epoch: 6| Step: 12
Training loss: 0.444469892829585
Validation loss: 2.488601968608343

Epoch: 6| Step: 13
Training loss: 0.37534116087654057
Validation loss: 2.4320031916579055

Epoch: 261| Step: 0
Training loss: 0.7060213410877536
Validation loss: 2.4325129689429246

Epoch: 6| Step: 1
Training loss: 0.4527345652411179
Validation loss: 2.399683737682425

Epoch: 6| Step: 2
Training loss: 0.7600568590728872
Validation loss: 2.3616440115737274

Epoch: 6| Step: 3
Training loss: 0.3549405669778255
Validation loss: 2.3410574976103327

Epoch: 6| Step: 4
Training loss: 0.7949253991351166
Validation loss: 2.3380141120982367

Epoch: 6| Step: 5
Training loss: 0.8216964310122759
Validation loss: 2.3467886518379695

Epoch: 6| Step: 6
Training loss: 0.4031765291267426
Validation loss: 2.369674032420558

Epoch: 6| Step: 7
Training loss: 0.4303092965842737
Validation loss: 2.3381694913483364

Epoch: 6| Step: 8
Training loss: 0.6012056704336253
Validation loss: 2.355560749349513

Epoch: 6| Step: 9
Training loss: 0.3603891699377258
Validation loss: 2.3596446548657113

Epoch: 6| Step: 10
Training loss: 0.4572113041081453
Validation loss: 2.3746750732930333

Epoch: 6| Step: 11
Training loss: 0.7560322881645832
Validation loss: 2.383967593587763

Epoch: 6| Step: 12
Training loss: 0.6310647683266721
Validation loss: 2.392883450060264

Epoch: 6| Step: 13
Training loss: 0.37252723491877154
Validation loss: 2.403556106302822

Epoch: 262| Step: 0
Training loss: 0.4739323249080592
Validation loss: 2.385975298122892

Epoch: 6| Step: 1
Training loss: 0.6489344152101509
Validation loss: 2.362796677834439

Epoch: 6| Step: 2
Training loss: 0.3881156622029057
Validation loss: 2.325745438975914

Epoch: 6| Step: 3
Training loss: 0.7642280134108757
Validation loss: 2.2992687424273313

Epoch: 6| Step: 4
Training loss: 0.6123512651897787
Validation loss: 2.2972185504254066

Epoch: 6| Step: 5
Training loss: 0.389575081328172
Validation loss: 2.269200935998724

Epoch: 6| Step: 6
Training loss: 0.7869170074521402
Validation loss: 2.3110886096655983

Epoch: 6| Step: 7
Training loss: 0.5024580734943558
Validation loss: 2.305197620475847

Epoch: 6| Step: 8
Training loss: 0.8422697292518382
Validation loss: 2.2982850201961345

Epoch: 6| Step: 9
Training loss: 0.2589348148664342
Validation loss: 2.32005492313339

Epoch: 6| Step: 10
Training loss: 0.46695738391105174
Validation loss: 2.338553661139635

Epoch: 6| Step: 11
Training loss: 0.5251786041722997
Validation loss: 2.349916835597139

Epoch: 6| Step: 12
Training loss: 0.6040272688915294
Validation loss: 2.3684241888315385

Epoch: 6| Step: 13
Training loss: 0.46071520795497495
Validation loss: 2.417065188342423

Epoch: 263| Step: 0
Training loss: 0.5337896788810245
Validation loss: 2.4188384678159536

Epoch: 6| Step: 1
Training loss: 0.46363709214054677
Validation loss: 2.4303143257248463

Epoch: 6| Step: 2
Training loss: 0.6613881506945336
Validation loss: 2.409487439263805

Epoch: 6| Step: 3
Training loss: 0.6199116764299354
Validation loss: 2.3606806652442214

Epoch: 6| Step: 4
Training loss: 0.6810832545746649
Validation loss: 2.34086639650391

Epoch: 6| Step: 5
Training loss: 0.6813663488303185
Validation loss: 2.3060390752236954

Epoch: 6| Step: 6
Training loss: 0.2575916297850332
Validation loss: 2.2790674368151342

Epoch: 6| Step: 7
Training loss: 0.6419761644109885
Validation loss: 2.287584022706093

Epoch: 6| Step: 8
Training loss: 0.6450995973827339
Validation loss: 2.2992783095006804

Epoch: 6| Step: 9
Training loss: 0.5009054984986012
Validation loss: 2.2840122654551416

Epoch: 6| Step: 10
Training loss: 0.36424535571523503
Validation loss: 2.3020581034447694

Epoch: 6| Step: 11
Training loss: 0.583616210832102
Validation loss: 2.3125293234285484

Epoch: 6| Step: 12
Training loss: 0.5317403269606683
Validation loss: 2.2956018318614464

Epoch: 6| Step: 13
Training loss: 0.6870137792799035
Validation loss: 2.2937145677371262

Epoch: 264| Step: 0
Training loss: 0.6055711475045832
Validation loss: 2.299403580356174

Epoch: 6| Step: 1
Training loss: 0.49355927296521024
Validation loss: 2.3081641785780147

Epoch: 6| Step: 2
Training loss: 0.8737485996939117
Validation loss: 2.343600836488475

Epoch: 6| Step: 3
Training loss: 0.5072883541878943
Validation loss: 2.3026205625817187

Epoch: 6| Step: 4
Training loss: 0.5278875866924321
Validation loss: 2.3650409121489946

Epoch: 6| Step: 5
Training loss: 0.3195780265165239
Validation loss: 2.33873869542361

Epoch: 6| Step: 6
Training loss: 0.6867513264815799
Validation loss: 2.3326670619058545

Epoch: 6| Step: 7
Training loss: 0.34486189825149355
Validation loss: 2.3661722812331654

Epoch: 6| Step: 8
Training loss: 0.6736473615031391
Validation loss: 2.3728752541070675

Epoch: 6| Step: 9
Training loss: 0.5787338195664639
Validation loss: 2.350398052158801

Epoch: 6| Step: 10
Training loss: 0.4193966797115581
Validation loss: 2.374902740499114

Epoch: 6| Step: 11
Training loss: 0.3636551440331049
Validation loss: 2.375619304547518

Epoch: 6| Step: 12
Training loss: 0.637064202330987
Validation loss: 2.3592113228118223

Epoch: 6| Step: 13
Training loss: 0.36359619516846375
Validation loss: 2.345003124750724

Epoch: 265| Step: 0
Training loss: 0.8452122345018579
Validation loss: 2.3499081538048494

Epoch: 6| Step: 1
Training loss: 0.6768427103359481
Validation loss: 2.3836447884286462

Epoch: 6| Step: 2
Training loss: 0.6366839253081937
Validation loss: 2.3777767177592586

Epoch: 6| Step: 3
Training loss: 0.6874373580831199
Validation loss: 2.376569147525366

Epoch: 6| Step: 4
Training loss: 0.1590502335422118
Validation loss: 2.375125209765539

Epoch: 6| Step: 5
Training loss: 0.3459216467094452
Validation loss: 2.3510630305462765

Epoch: 6| Step: 6
Training loss: 0.585520914124467
Validation loss: 2.369773025376272

Epoch: 6| Step: 7
Training loss: 0.4247291234652382
Validation loss: 2.3742382336941636

Epoch: 6| Step: 8
Training loss: 0.4825284739725074
Validation loss: 2.3694975917401195

Epoch: 6| Step: 9
Training loss: 0.4072893309302645
Validation loss: 2.352822952550963

Epoch: 6| Step: 10
Training loss: 0.21099736106044922
Validation loss: 2.350850578146824

Epoch: 6| Step: 11
Training loss: 0.8003704971456099
Validation loss: 2.375948359849484

Epoch: 6| Step: 12
Training loss: 0.2902663910202627
Validation loss: 2.3602729353991463

Epoch: 6| Step: 13
Training loss: 0.6204723392441357
Validation loss: 2.3778903355285697

Epoch: 266| Step: 0
Training loss: 0.41701725475715046
Validation loss: 2.3438457805792297

Epoch: 6| Step: 1
Training loss: 0.688207630632496
Validation loss: 2.3619017544177496

Epoch: 6| Step: 2
Training loss: 0.34885708089602047
Validation loss: 2.3546555530825053

Epoch: 6| Step: 3
Training loss: 0.4838323629973788
Validation loss: 2.386801740494029

Epoch: 6| Step: 4
Training loss: 0.6126946480589046
Validation loss: 2.329589965902019

Epoch: 6| Step: 5
Training loss: 0.5297523875144455
Validation loss: 2.345962065717687

Epoch: 6| Step: 6
Training loss: 0.583177193680292
Validation loss: 2.3530057621442673

Epoch: 6| Step: 7
Training loss: 0.5001966566539192
Validation loss: 2.345124319891576

Epoch: 6| Step: 8
Training loss: 0.3068440485415826
Validation loss: 2.37042402133177

Epoch: 6| Step: 9
Training loss: 0.6683289744487879
Validation loss: 2.328836000333958

Epoch: 6| Step: 10
Training loss: 0.3846399518337295
Validation loss: 2.3346576230593077

Epoch: 6| Step: 11
Training loss: 0.7064946282648941
Validation loss: 2.3516849486895923

Epoch: 6| Step: 12
Training loss: 0.5836789917898124
Validation loss: 2.3500519294473188

Epoch: 6| Step: 13
Training loss: 0.5535945601838267
Validation loss: 2.3884137896554174

Epoch: 267| Step: 0
Training loss: 0.4056760327956578
Validation loss: 2.420805263951356

Epoch: 6| Step: 1
Training loss: 0.47953625260941524
Validation loss: 2.3934670453415356

Epoch: 6| Step: 2
Training loss: 0.6549548584182763
Validation loss: 2.393741755810167

Epoch: 6| Step: 3
Training loss: 0.7245842859906483
Validation loss: 2.4014147261638623

Epoch: 6| Step: 4
Training loss: 0.2743563608342569
Validation loss: 2.41077016967615

Epoch: 6| Step: 5
Training loss: 0.4887785858321678
Validation loss: 2.3932238399120465

Epoch: 6| Step: 6
Training loss: 0.4758530166444178
Validation loss: 2.3987225072625913

Epoch: 6| Step: 7
Training loss: 0.3058020064141857
Validation loss: 2.3677765408393667

Epoch: 6| Step: 8
Training loss: 0.6580231870563154
Validation loss: 2.369849370618763

Epoch: 6| Step: 9
Training loss: 0.14442615296423789
Validation loss: 2.3551125654807423

Epoch: 6| Step: 10
Training loss: 0.4483767205761795
Validation loss: 2.329408519623695

Epoch: 6| Step: 11
Training loss: 0.8168020064905612
Validation loss: 2.344056068042569

Epoch: 6| Step: 12
Training loss: 0.5736063591660454
Validation loss: 2.369969682431636

Epoch: 6| Step: 13
Training loss: 0.758238525193119
Validation loss: 2.3387115421931295

Epoch: 268| Step: 0
Training loss: 0.5242554266616473
Validation loss: 2.356620346392774

Epoch: 6| Step: 1
Training loss: 0.2510762295073059
Validation loss: 2.3606804610808765

Epoch: 6| Step: 2
Training loss: 0.5123865560255415
Validation loss: 2.3212919593495567

Epoch: 6| Step: 3
Training loss: 0.576746921972586
Validation loss: 2.34604420237003

Epoch: 6| Step: 4
Training loss: 0.7416068365488696
Validation loss: 2.33956384717997

Epoch: 6| Step: 5
Training loss: 0.1644676519216288
Validation loss: 2.3749997733201855

Epoch: 6| Step: 6
Training loss: 0.44818578627044214
Validation loss: 2.370496135415924

Epoch: 6| Step: 7
Training loss: 0.484713528375105
Validation loss: 2.351473795338922

Epoch: 6| Step: 8
Training loss: 0.5734038766675361
Validation loss: 2.365116513183745

Epoch: 6| Step: 9
Training loss: 0.6409973365085628
Validation loss: 2.3556737153324803

Epoch: 6| Step: 10
Training loss: 0.5491629559975711
Validation loss: 2.3865471089687857

Epoch: 6| Step: 11
Training loss: 0.8193876593431674
Validation loss: 2.3537791945382427

Epoch: 6| Step: 12
Training loss: 0.24720011381139728
Validation loss: 2.3506404077418037

Epoch: 6| Step: 13
Training loss: 0.44792193771927674
Validation loss: 2.322801824867317

Epoch: 269| Step: 0
Training loss: 0.5023250166987786
Validation loss: 2.3651688402736566

Epoch: 6| Step: 1
Training loss: 0.8550298252815347
Validation loss: 2.3204233786580337

Epoch: 6| Step: 2
Training loss: 0.6207919557168206
Validation loss: 2.314437870175953

Epoch: 6| Step: 3
Training loss: 0.15438439506637344
Validation loss: 2.321117599674641

Epoch: 6| Step: 4
Training loss: 0.40081143479329856
Validation loss: 2.31464219029612

Epoch: 6| Step: 5
Training loss: 0.5953433091408944
Validation loss: 2.301458647534222

Epoch: 6| Step: 6
Training loss: 0.763399314534372
Validation loss: 2.294286667347551

Epoch: 6| Step: 7
Training loss: 0.5075631042766227
Validation loss: 2.315702355651437

Epoch: 6| Step: 8
Training loss: 0.2751633809003427
Validation loss: 2.310047451047408

Epoch: 6| Step: 9
Training loss: 0.6108101792607102
Validation loss: 2.331939276062648

Epoch: 6| Step: 10
Training loss: 0.1579188925379477
Validation loss: 2.347478740872433

Epoch: 6| Step: 11
Training loss: 0.512022030479351
Validation loss: 2.354432568428364

Epoch: 6| Step: 12
Training loss: 0.2621559931632964
Validation loss: 2.3904850620097893

Epoch: 6| Step: 13
Training loss: 0.6039364529616099
Validation loss: 2.366428883580742

Epoch: 270| Step: 0
Training loss: 0.4968605873128869
Validation loss: 2.3780143015742534

Epoch: 6| Step: 1
Training loss: 0.4054459354104696
Validation loss: 2.370871075993824

Epoch: 6| Step: 2
Training loss: 0.5102830212331234
Validation loss: 2.3827155529401245

Epoch: 6| Step: 3
Training loss: 0.6904334428353273
Validation loss: 2.4212445102975244

Epoch: 6| Step: 4
Training loss: 0.3671639617517835
Validation loss: 2.3790982502300486

Epoch: 6| Step: 5
Training loss: 0.4137346841391822
Validation loss: 2.3955773928892827

Epoch: 6| Step: 6
Training loss: 0.5572582900370644
Validation loss: 2.381873575374073

Epoch: 6| Step: 7
Training loss: 0.45280228007638906
Validation loss: 2.359114545269991

Epoch: 6| Step: 8
Training loss: 0.6802609972893757
Validation loss: 2.3497380047116008

Epoch: 6| Step: 9
Training loss: 0.5627883595865831
Validation loss: 2.338894802569902

Epoch: 6| Step: 10
Training loss: 0.24315500817044902
Validation loss: 2.3632604584694175

Epoch: 6| Step: 11
Training loss: 0.32743542737135556
Validation loss: 2.3516753424506986

Epoch: 6| Step: 12
Training loss: 0.6993666764105778
Validation loss: 2.3457682199573404

Epoch: 6| Step: 13
Training loss: 0.7515200866659414
Validation loss: 2.372469162520511

Epoch: 271| Step: 0
Training loss: 0.289683654043599
Validation loss: 2.3417893629350366

Epoch: 6| Step: 1
Training loss: 0.6955552266817192
Validation loss: 2.368075102816222

Epoch: 6| Step: 2
Training loss: 0.44543866829674095
Validation loss: 2.358618689138162

Epoch: 6| Step: 3
Training loss: 0.27059238365031907
Validation loss: 2.3729697532246745

Epoch: 6| Step: 4
Training loss: 0.528235240016961
Validation loss: 2.3831799392449993

Epoch: 6| Step: 5
Training loss: 0.43162840398688473
Validation loss: 2.3956222656998385

Epoch: 6| Step: 6
Training loss: 0.5932769145510793
Validation loss: 2.3662643492610895

Epoch: 6| Step: 7
Training loss: 0.5426821604132892
Validation loss: 2.3797424798288023

Epoch: 6| Step: 8
Training loss: 0.4330618233176511
Validation loss: 2.380198952432058

Epoch: 6| Step: 9
Training loss: 0.6164182867269804
Validation loss: 2.373355806917073

Epoch: 6| Step: 10
Training loss: 0.6567328357116241
Validation loss: 2.371279789591023

Epoch: 6| Step: 11
Training loss: 0.5750995031590472
Validation loss: 2.3772030248381593

Epoch: 6| Step: 12
Training loss: 0.5478832759279986
Validation loss: 2.3682044410286696

Epoch: 6| Step: 13
Training loss: 0.38328731051543175
Validation loss: 2.371112831045569

Epoch: 272| Step: 0
Training loss: 0.30358382383052657
Validation loss: 2.3942882292269227

Epoch: 6| Step: 1
Training loss: 0.284059636822362
Validation loss: 2.3894328952632424

Epoch: 6| Step: 2
Training loss: 0.5048807465088593
Validation loss: 2.386057816479206

Epoch: 6| Step: 3
Training loss: 0.6581724255927226
Validation loss: 2.3715922648970813

Epoch: 6| Step: 4
Training loss: 0.21785133405580764
Validation loss: 2.3628188812241606

Epoch: 6| Step: 5
Training loss: 0.5123165802587796
Validation loss: 2.367490138483506

Epoch: 6| Step: 6
Training loss: 0.5904483349297494
Validation loss: 2.3606199122953693

Epoch: 6| Step: 7
Training loss: 0.5944118575372165
Validation loss: 2.3651606122649063

Epoch: 6| Step: 8
Training loss: 0.4117113152543875
Validation loss: 2.3784591470451857

Epoch: 6| Step: 9
Training loss: 0.6827850790213684
Validation loss: 2.3578203883644235

Epoch: 6| Step: 10
Training loss: 0.5456640460276295
Validation loss: 2.316950947055781

Epoch: 6| Step: 11
Training loss: 0.5121318227356764
Validation loss: 2.314608622766566

Epoch: 6| Step: 12
Training loss: 0.7231981462363098
Validation loss: 2.330879785030991

Epoch: 6| Step: 13
Training loss: 0.574593531988568
Validation loss: 2.3298658948163253

Epoch: 273| Step: 0
Training loss: 0.45469906782399105
Validation loss: 2.3440683007899334

Epoch: 6| Step: 1
Training loss: 0.40083539496636456
Validation loss: 2.3693776508815407

Epoch: 6| Step: 2
Training loss: 0.4037378103819519
Validation loss: 2.3659467331219406

Epoch: 6| Step: 3
Training loss: 0.6407072433155121
Validation loss: 2.355508651780443

Epoch: 6| Step: 4
Training loss: 0.7768466452643559
Validation loss: 2.4003793211579953

Epoch: 6| Step: 5
Training loss: 0.47989986825644293
Validation loss: 2.403678054886017

Epoch: 6| Step: 6
Training loss: 0.5726479044432332
Validation loss: 2.389219751059051

Epoch: 6| Step: 7
Training loss: 0.5418794806888041
Validation loss: 2.402389733752896

Epoch: 6| Step: 8
Training loss: 0.22236635342545974
Validation loss: 2.4163529822246788

Epoch: 6| Step: 9
Training loss: 0.43713130060727057
Validation loss: 2.398073359630302

Epoch: 6| Step: 10
Training loss: 0.5632475018807798
Validation loss: 2.4144978170418177

Epoch: 6| Step: 11
Training loss: 0.43595398492305487
Validation loss: 2.4035308282073484

Epoch: 6| Step: 12
Training loss: 0.6504095721993222
Validation loss: 2.390026269829187

Epoch: 6| Step: 13
Training loss: 0.14571970673978582
Validation loss: 2.397676283566494

Epoch: 274| Step: 0
Training loss: 0.4305323531280737
Validation loss: 2.3650332739204902

Epoch: 6| Step: 1
Training loss: 0.3985021202193734
Validation loss: 2.345284920970034

Epoch: 6| Step: 2
Training loss: 0.5504675438483584
Validation loss: 2.3698271065304133

Epoch: 6| Step: 3
Training loss: 0.43935382992790045
Validation loss: 2.3865726083088443

Epoch: 6| Step: 4
Training loss: 0.416004700136684
Validation loss: 2.3410642750384576

Epoch: 6| Step: 5
Training loss: 0.4998308879250395
Validation loss: 2.3415970077666666

Epoch: 6| Step: 6
Training loss: 0.691108402387521
Validation loss: 2.33051999371943

Epoch: 6| Step: 7
Training loss: 0.4963917325412227
Validation loss: 2.35874464729096

Epoch: 6| Step: 8
Training loss: 0.650210564693137
Validation loss: 2.362954705354537

Epoch: 6| Step: 9
Training loss: 0.5668699273972843
Validation loss: 2.324356172379715

Epoch: 6| Step: 10
Training loss: 0.39119349120343105
Validation loss: 2.3569584731631235

Epoch: 6| Step: 11
Training loss: 0.4332349340732616
Validation loss: 2.356518688774419

Epoch: 6| Step: 12
Training loss: 0.5772049516353771
Validation loss: 2.348795066292476

Epoch: 6| Step: 13
Training loss: 0.21049775097250353
Validation loss: 2.38062369151466

Epoch: 275| Step: 0
Training loss: 0.3365887937661659
Validation loss: 2.363366340794212

Epoch: 6| Step: 1
Training loss: 0.6079182206810099
Validation loss: 2.395516083423745

Epoch: 6| Step: 2
Training loss: 0.47042951110466563
Validation loss: 2.36691863460392

Epoch: 6| Step: 3
Training loss: 0.7671900731682598
Validation loss: 2.373377562630748

Epoch: 6| Step: 4
Training loss: 0.2818779293508628
Validation loss: 2.3634192083152765

Epoch: 6| Step: 5
Training loss: 0.5764966663518964
Validation loss: 2.3903641863763805

Epoch: 6| Step: 6
Training loss: 0.5132556868273879
Validation loss: 2.3951165673754238

Epoch: 6| Step: 7
Training loss: 0.4595671342771448
Validation loss: 2.390624716893629

Epoch: 6| Step: 8
Training loss: 0.4581248249818642
Validation loss: 2.3882151379598224

Epoch: 6| Step: 9
Training loss: 0.526131033781459
Validation loss: 2.3796767068807934

Epoch: 6| Step: 10
Training loss: 0.3997073787013859
Validation loss: 2.3603103110509682

Epoch: 6| Step: 11
Training loss: 0.431509351834549
Validation loss: 2.3898809257457247

Epoch: 6| Step: 12
Training loss: 0.47348514103157946
Validation loss: 2.3800212745046556

Epoch: 6| Step: 13
Training loss: 0.5215765196582769
Validation loss: 2.3899272404697594

Epoch: 276| Step: 0
Training loss: 0.674953571241632
Validation loss: 2.3629995244759856

Epoch: 6| Step: 1
Training loss: 0.2862295826872507
Validation loss: 2.3854386840512087

Epoch: 6| Step: 2
Training loss: 0.6009810721817388
Validation loss: 2.365038543666672

Epoch: 6| Step: 3
Training loss: 0.4270029651418289
Validation loss: 2.388744010222126

Epoch: 6| Step: 4
Training loss: 0.44380256583265887
Validation loss: 2.395627935271461

Epoch: 6| Step: 5
Training loss: 0.6104948562261661
Validation loss: 2.3499661241793883

Epoch: 6| Step: 6
Training loss: 0.29905425348342296
Validation loss: 2.3544044773807054

Epoch: 6| Step: 7
Training loss: 0.18423178574091117
Validation loss: 2.376159800901129

Epoch: 6| Step: 8
Training loss: 0.6589392103310305
Validation loss: 2.366712765921348

Epoch: 6| Step: 9
Training loss: 0.1517059043470943
Validation loss: 2.3650632771174163

Epoch: 6| Step: 10
Training loss: 0.6023810131456017
Validation loss: 2.3893485251506728

Epoch: 6| Step: 11
Training loss: 0.7365577805068085
Validation loss: 2.3904524340146485

Epoch: 6| Step: 12
Training loss: 0.43363261693014166
Validation loss: 2.3592259773490816

Epoch: 6| Step: 13
Training loss: 0.17026913992106862
Validation loss: 2.36494960950369

Epoch: 277| Step: 0
Training loss: 0.3371771186312332
Validation loss: 2.3915593707791607

Epoch: 6| Step: 1
Training loss: 0.44937154410443325
Validation loss: 2.372154692480312

Epoch: 6| Step: 2
Training loss: 0.6290933082036684
Validation loss: 2.3628407176812094

Epoch: 6| Step: 3
Training loss: 0.4377089239997395
Validation loss: 2.409247675412639

Epoch: 6| Step: 4
Training loss: 0.6324893455965016
Validation loss: 2.3706250949763343

Epoch: 6| Step: 5
Training loss: 0.5640757530113713
Validation loss: 2.369416504789179

Epoch: 6| Step: 6
Training loss: 0.699542221177573
Validation loss: 2.361711579016608

Epoch: 6| Step: 7
Training loss: 0.4156888475351799
Validation loss: 2.3577219069560353

Epoch: 6| Step: 8
Training loss: 0.4404211276083194
Validation loss: 2.3644599222801217

Epoch: 6| Step: 9
Training loss: 0.4265350528591952
Validation loss: 2.358523863931366

Epoch: 6| Step: 10
Training loss: 0.3164246871662786
Validation loss: 2.3340676155063

Epoch: 6| Step: 11
Training loss: 0.3042494241055482
Validation loss: 2.323112904033706

Epoch: 6| Step: 12
Training loss: 0.5949679481464478
Validation loss: 2.318414767152569

Epoch: 6| Step: 13
Training loss: 0.22004211655266
Validation loss: 2.3388723950821855

Epoch: 278| Step: 0
Training loss: 0.6767293640586761
Validation loss: 2.3398321054444726

Epoch: 6| Step: 1
Training loss: 0.3454940939811129
Validation loss: 2.321350537223277

Epoch: 6| Step: 2
Training loss: 0.6188801118088308
Validation loss: 2.3327396266682343

Epoch: 6| Step: 3
Training loss: 0.4404198080845257
Validation loss: 2.3566750736710014

Epoch: 6| Step: 4
Training loss: 0.3059991578031307
Validation loss: 2.3470598374074516

Epoch: 6| Step: 5
Training loss: 0.5961343174000462
Validation loss: 2.31868983510951

Epoch: 6| Step: 6
Training loss: 0.5903934166026903
Validation loss: 2.3306761530689695

Epoch: 6| Step: 7
Training loss: 0.2929398458845531
Validation loss: 2.3253906808504157

Epoch: 6| Step: 8
Training loss: 0.515666555406295
Validation loss: 2.371428409355293

Epoch: 6| Step: 9
Training loss: 0.2980036112931352
Validation loss: 2.355922950609919

Epoch: 6| Step: 10
Training loss: 0.21093745584840665
Validation loss: 2.3412935122617617

Epoch: 6| Step: 11
Training loss: 0.6145096885609546
Validation loss: 2.352905936266793

Epoch: 6| Step: 12
Training loss: 0.5426136749463656
Validation loss: 2.354368950547956

Epoch: 6| Step: 13
Training loss: 0.5480770252333222
Validation loss: 2.3401676060475194

Epoch: 279| Step: 0
Training loss: 0.4089734597921969
Validation loss: 2.301664525258764

Epoch: 6| Step: 1
Training loss: 0.4657555621107331
Validation loss: 2.346289869564749

Epoch: 6| Step: 2
Training loss: 0.715353986904419
Validation loss: 2.348428766409592

Epoch: 6| Step: 3
Training loss: 0.5005822367983453
Validation loss: 2.3338725808060348

Epoch: 6| Step: 4
Training loss: 0.641279909280387
Validation loss: 2.338410308837188

Epoch: 6| Step: 5
Training loss: 0.20320551450293148
Validation loss: 2.3332017921543975

Epoch: 6| Step: 6
Training loss: 0.4587916517448521
Validation loss: 2.337753781096949

Epoch: 6| Step: 7
Training loss: 0.3832538551713973
Validation loss: 2.3850215947064495

Epoch: 6| Step: 8
Training loss: 0.5186143111669568
Validation loss: 2.364875438956524

Epoch: 6| Step: 9
Training loss: 0.6141607210845461
Validation loss: 2.336617190127283

Epoch: 6| Step: 10
Training loss: 0.3952280821396345
Validation loss: 2.3659592145942296

Epoch: 6| Step: 11
Training loss: 0.4631364386995347
Validation loss: 2.392650363443507

Epoch: 6| Step: 12
Training loss: 0.34562676874229004
Validation loss: 2.4084985074813012

Epoch: 6| Step: 13
Training loss: 0.3527088865785415
Validation loss: 2.3945440653250416

Epoch: 280| Step: 0
Training loss: 0.3091934389007059
Validation loss: 2.390377032085574

Epoch: 6| Step: 1
Training loss: 0.2210535289183308
Validation loss: 2.3789103590956406

Epoch: 6| Step: 2
Training loss: 0.4959996201731012
Validation loss: 2.345337675768272

Epoch: 6| Step: 3
Training loss: 0.2765474304576425
Validation loss: 2.3657200332478565

Epoch: 6| Step: 4
Training loss: 0.5538629124828405
Validation loss: 2.340376212854227

Epoch: 6| Step: 5
Training loss: 0.6533739555471687
Validation loss: 2.364387114482646

Epoch: 6| Step: 6
Training loss: 0.49283421126915183
Validation loss: 2.3471698588483623

Epoch: 6| Step: 7
Training loss: 0.3911734735887828
Validation loss: 2.334951678576651

Epoch: 6| Step: 8
Training loss: 0.5607007709276761
Validation loss: 2.349005563327215

Epoch: 6| Step: 9
Training loss: 0.4925320040281536
Validation loss: 2.343462555462522

Epoch: 6| Step: 10
Training loss: 0.5602050696131678
Validation loss: 2.341228874334653

Epoch: 6| Step: 11
Training loss: 0.6396844984765908
Validation loss: 2.3648814554203064

Epoch: 6| Step: 12
Training loss: 0.5314700568458925
Validation loss: 2.3646773293931216

Epoch: 6| Step: 13
Training loss: 0.25498552554787485
Validation loss: 2.3331192602526056

Epoch: 281| Step: 0
Training loss: 0.33278278119640087
Validation loss: 2.3360470016198107

Epoch: 6| Step: 1
Training loss: 0.3126122273150886
Validation loss: 2.32908720273168

Epoch: 6| Step: 2
Training loss: 0.4898337744954967
Validation loss: 2.2769098647565973

Epoch: 6| Step: 3
Training loss: 0.3272425160430163
Validation loss: 2.282309481255649

Epoch: 6| Step: 4
Training loss: 0.6717920473921004
Validation loss: 2.298782748400418

Epoch: 6| Step: 5
Training loss: 0.539764941766251
Validation loss: 2.2995610813010616

Epoch: 6| Step: 6
Training loss: 0.4080236304957198
Validation loss: 2.329652146500835

Epoch: 6| Step: 7
Training loss: 0.3855073624512704
Validation loss: 2.368518027774355

Epoch: 6| Step: 8
Training loss: 0.44986744358831937
Validation loss: 2.3529385368730784

Epoch: 6| Step: 9
Training loss: 0.4035737393713333
Validation loss: 2.4105768826403864

Epoch: 6| Step: 10
Training loss: 0.46926100216417144
Validation loss: 2.416540828592644

Epoch: 6| Step: 11
Training loss: 0.48499467650175954
Validation loss: 2.424804436930185

Epoch: 6| Step: 12
Training loss: 0.7744600876435823
Validation loss: 2.4546410990066683

Epoch: 6| Step: 13
Training loss: 0.4761281144372536
Validation loss: 2.424912375146301

Epoch: 282| Step: 0
Training loss: 0.2855727015764724
Validation loss: 2.416373338673444

Epoch: 6| Step: 1
Training loss: 0.44108742196235917
Validation loss: 2.390739515922203

Epoch: 6| Step: 2
Training loss: 0.3402409260553812
Validation loss: 2.406086908041088

Epoch: 6| Step: 3
Training loss: 0.7662253847882385
Validation loss: 2.3730855867297183

Epoch: 6| Step: 4
Training loss: 0.51412613077779
Validation loss: 2.3841345223759363

Epoch: 6| Step: 5
Training loss: 0.20429178891679795
Validation loss: 2.3365453931320292

Epoch: 6| Step: 6
Training loss: 0.35263668832538464
Validation loss: 2.3466202790757564

Epoch: 6| Step: 7
Training loss: 0.26021803274063826
Validation loss: 2.334422303106645

Epoch: 6| Step: 8
Training loss: 0.6756783114845827
Validation loss: 2.3191426905557324

Epoch: 6| Step: 9
Training loss: 0.5197995002426411
Validation loss: 2.3310675603557693

Epoch: 6| Step: 10
Training loss: 0.6521185069200554
Validation loss: 2.381604158006921

Epoch: 6| Step: 11
Training loss: 0.2996882607109272
Validation loss: 2.336268100712628

Epoch: 6| Step: 12
Training loss: 0.6015831584603423
Validation loss: 2.400519476920201

Epoch: 6| Step: 13
Training loss: 0.213228718433055
Validation loss: 2.376112216045714

Epoch: 283| Step: 0
Training loss: 0.33264240789753186
Validation loss: 2.391218682880245

Epoch: 6| Step: 1
Training loss: 0.4215239017538102
Validation loss: 2.3779884873021673

Epoch: 6| Step: 2
Training loss: 0.7584102278978441
Validation loss: 2.3801227151268955

Epoch: 6| Step: 3
Training loss: 0.57232618825152
Validation loss: 2.363446936769417

Epoch: 6| Step: 4
Training loss: 0.27897393289603467
Validation loss: 2.338776788996859

Epoch: 6| Step: 5
Training loss: 0.2757193044626419
Validation loss: 2.357119877055593

Epoch: 6| Step: 6
Training loss: 0.5298478190547893
Validation loss: 2.324155142852944

Epoch: 6| Step: 7
Training loss: 0.38840260595229226
Validation loss: 2.3464729078998574

Epoch: 6| Step: 8
Training loss: 0.5009365846621979
Validation loss: 2.3116929664523154

Epoch: 6| Step: 9
Training loss: 0.7073336634202212
Validation loss: 2.3296571116773905

Epoch: 6| Step: 10
Training loss: 0.3608574146746889
Validation loss: 2.362649094421096

Epoch: 6| Step: 11
Training loss: 0.3043929901916246
Validation loss: 2.3174615993889804

Epoch: 6| Step: 12
Training loss: 0.4326117969461264
Validation loss: 2.323401278931144

Epoch: 6| Step: 13
Training loss: 0.36666451402957073
Validation loss: 2.337370972589811

Epoch: 284| Step: 0
Training loss: 0.412547705521593
Validation loss: 2.3068903114211965

Epoch: 6| Step: 1
Training loss: 0.33269968628121854
Validation loss: 2.311473924215974

Epoch: 6| Step: 2
Training loss: 0.39882831480075903
Validation loss: 2.318956362412319

Epoch: 6| Step: 3
Training loss: 0.37450023966757384
Validation loss: 2.3341140568938026

Epoch: 6| Step: 4
Training loss: 0.6173925904052103
Validation loss: 2.339714808625087

Epoch: 6| Step: 5
Training loss: 0.5385612977346383
Validation loss: 2.359059369259032

Epoch: 6| Step: 6
Training loss: 0.17052711473693605
Validation loss: 2.382570490255121

Epoch: 6| Step: 7
Training loss: 0.4519446554354755
Validation loss: 2.341098754311624

Epoch: 6| Step: 8
Training loss: 0.6552373475370868
Validation loss: 2.3497569525974145

Epoch: 6| Step: 9
Training loss: 0.44208491318204984
Validation loss: 2.3368045422684385

Epoch: 6| Step: 10
Training loss: 0.3758449373582516
Validation loss: 2.324648755208344

Epoch: 6| Step: 11
Training loss: 0.5273010519190481
Validation loss: 2.2868223909346654

Epoch: 6| Step: 12
Training loss: 0.5583431241851867
Validation loss: 2.2979359807965203

Epoch: 6| Step: 13
Training loss: 0.5627128939942218
Validation loss: 2.2777843022130084

Epoch: 285| Step: 0
Training loss: 0.20958691484116274
Validation loss: 2.2656193332509313

Epoch: 6| Step: 1
Training loss: 0.4592683116779878
Validation loss: 2.2626635677985405

Epoch: 6| Step: 2
Training loss: 0.7249428118150937
Validation loss: 2.280494812175539

Epoch: 6| Step: 3
Training loss: 0.3658432602495014
Validation loss: 2.295569996667947

Epoch: 6| Step: 4
Training loss: 0.518939721217703
Validation loss: 2.318687781931592

Epoch: 6| Step: 5
Training loss: 0.4937870434252852
Validation loss: 2.312650280442536

Epoch: 6| Step: 6
Training loss: 0.551025174284129
Validation loss: 2.342805074992726

Epoch: 6| Step: 7
Training loss: 0.4240823501854868
Validation loss: 2.342031523487532

Epoch: 6| Step: 8
Training loss: 0.4409773946026539
Validation loss: 2.355466375157758

Epoch: 6| Step: 9
Training loss: 0.40272970113622936
Validation loss: 2.318209883227878

Epoch: 6| Step: 10
Training loss: 0.54832544078577
Validation loss: 2.3612625448302276

Epoch: 6| Step: 11
Training loss: 0.31549429453287015
Validation loss: 2.348918405774706

Epoch: 6| Step: 12
Training loss: 0.4532122363598478
Validation loss: 2.3487962985624

Epoch: 6| Step: 13
Training loss: 0.2999011080389424
Validation loss: 2.358843541378098

Epoch: 286| Step: 0
Training loss: 0.21369448965790938
Validation loss: 2.3603796908392827

Epoch: 6| Step: 1
Training loss: 0.6283710168758171
Validation loss: 2.399159266639793

Epoch: 6| Step: 2
Training loss: 0.477543961513486
Validation loss: 2.392456225164691

Epoch: 6| Step: 3
Training loss: 0.4502569061313065
Validation loss: 2.3671191655871264

Epoch: 6| Step: 4
Training loss: 0.48932252863255643
Validation loss: 2.4012207127497796

Epoch: 6| Step: 5
Training loss: 0.302505542038364
Validation loss: 2.37474098908894

Epoch: 6| Step: 6
Training loss: 0.42199159706368916
Validation loss: 2.3807679311477745

Epoch: 6| Step: 7
Training loss: 0.5987582052062831
Validation loss: 2.3197414380065124

Epoch: 6| Step: 8
Training loss: 0.4333800227278791
Validation loss: 2.3478037450833025

Epoch: 6| Step: 9
Training loss: 0.1851562906418124
Validation loss: 2.333191339578853

Epoch: 6| Step: 10
Training loss: 0.666418563353359
Validation loss: 2.3434508080062204

Epoch: 6| Step: 11
Training loss: 0.4572506891311116
Validation loss: 2.3288127045611056

Epoch: 6| Step: 12
Training loss: 0.4806456201542483
Validation loss: 2.3340479284637157

Epoch: 6| Step: 13
Training loss: 0.35711798751616936
Validation loss: 2.3191907053425704

Epoch: 287| Step: 0
Training loss: 0.2970107922439538
Validation loss: 2.297350814876354

Epoch: 6| Step: 1
Training loss: 0.7331698248022622
Validation loss: 2.306960249847356

Epoch: 6| Step: 2
Training loss: 0.17284072152317334
Validation loss: 2.322562088886545

Epoch: 6| Step: 3
Training loss: 0.5941132137237873
Validation loss: 2.3220318076851774

Epoch: 6| Step: 4
Training loss: 0.24248145322565265
Validation loss: 2.3553374003227514

Epoch: 6| Step: 5
Training loss: 0.22301094346981526
Validation loss: 2.316308623123902

Epoch: 6| Step: 6
Training loss: 0.39446159729950847
Validation loss: 2.3117819782453455

Epoch: 6| Step: 7
Training loss: 0.3118179507624996
Validation loss: 2.2903992598388916

Epoch: 6| Step: 8
Training loss: 0.6239682741811484
Validation loss: 2.2726240733703715

Epoch: 6| Step: 9
Training loss: 0.6859414033192169
Validation loss: 2.2815364781946106

Epoch: 6| Step: 10
Training loss: 0.48756615727801966
Validation loss: 2.2892001715867694

Epoch: 6| Step: 11
Training loss: 0.46777112796985804
Validation loss: 2.27543775472781

Epoch: 6| Step: 12
Training loss: 0.2598771164345993
Validation loss: 2.3089475353516935

Epoch: 6| Step: 13
Training loss: 0.155566843993678
Validation loss: 2.2949272817226403

Epoch: 288| Step: 0
Training loss: 0.31846257742760936
Validation loss: 2.298329566698994

Epoch: 6| Step: 1
Training loss: 0.42168091795451595
Validation loss: 2.2876272394888737

Epoch: 6| Step: 2
Training loss: 0.6833119274678872
Validation loss: 2.3229255214415523

Epoch: 6| Step: 3
Training loss: 0.2661225623515927
Validation loss: 2.2877131226256346

Epoch: 6| Step: 4
Training loss: 0.6552162657127674
Validation loss: 2.301758767005099

Epoch: 6| Step: 5
Training loss: 0.41681336760848914
Validation loss: 2.3404298236985235

Epoch: 6| Step: 6
Training loss: 0.4027523447462198
Validation loss: 2.3446238255400975

Epoch: 6| Step: 7
Training loss: 0.2789886748175636
Validation loss: 2.3634800102514033

Epoch: 6| Step: 8
Training loss: 0.43080166372276346
Validation loss: 2.3490601962655178

Epoch: 6| Step: 9
Training loss: 0.39390455648866984
Validation loss: 2.342586639336349

Epoch: 6| Step: 10
Training loss: 0.48645621455164756
Validation loss: 2.3523834739231515

Epoch: 6| Step: 11
Training loss: 0.21618938390303033
Validation loss: 2.3189447942763435

Epoch: 6| Step: 12
Training loss: 0.6752312687885481
Validation loss: 2.365592162024001

Epoch: 6| Step: 13
Training loss: 0.31735604980313387
Validation loss: 2.3458620821711476

Epoch: 289| Step: 0
Training loss: 0.3874745352899482
Validation loss: 2.3278752146374653

Epoch: 6| Step: 1
Training loss: 0.6073496490419718
Validation loss: 2.335461930445222

Epoch: 6| Step: 2
Training loss: 0.3907176480095053
Validation loss: 2.383547282051258

Epoch: 6| Step: 3
Training loss: 0.2535548052025714
Validation loss: 2.369210130876304

Epoch: 6| Step: 4
Training loss: 0.2621419104722913
Validation loss: 2.4028852163198975

Epoch: 6| Step: 5
Training loss: 0.4151107008199181
Validation loss: 2.4460226641797194

Epoch: 6| Step: 6
Training loss: 0.35380070609372133
Validation loss: 2.421085881958855

Epoch: 6| Step: 7
Training loss: 0.4621635069948314
Validation loss: 2.398161579612219

Epoch: 6| Step: 8
Training loss: 0.46763519601685904
Validation loss: 2.3797300824986163

Epoch: 6| Step: 9
Training loss: 0.3971188734600801
Validation loss: 2.3866438198262134

Epoch: 6| Step: 10
Training loss: 0.6534616177822625
Validation loss: 2.405962191286728

Epoch: 6| Step: 11
Training loss: 0.6290517840015162
Validation loss: 2.363624833482098

Epoch: 6| Step: 12
Training loss: 0.5735643251790535
Validation loss: 2.3720598917813676

Epoch: 6| Step: 13
Training loss: 0.2290077534496812
Validation loss: 2.3345571317606137

Epoch: 290| Step: 0
Training loss: 0.3281756884160758
Validation loss: 2.34687406751462

Epoch: 6| Step: 1
Training loss: 0.46039510593017074
Validation loss: 2.362776156005368

Epoch: 6| Step: 2
Training loss: 0.5762060640180838
Validation loss: 2.3656274970076896

Epoch: 6| Step: 3
Training loss: 0.39385599949950123
Validation loss: 2.3579331922721707

Epoch: 6| Step: 4
Training loss: 0.4563794501094714
Validation loss: 2.3536956283922654

Epoch: 6| Step: 5
Training loss: 0.6891261289806311
Validation loss: 2.3677294647587708

Epoch: 6| Step: 6
Training loss: 0.45904860351490523
Validation loss: 2.3822130696965544

Epoch: 6| Step: 7
Training loss: 0.6055368200615772
Validation loss: 2.389883627891694

Epoch: 6| Step: 8
Training loss: 0.5928376868431944
Validation loss: 2.3701884997056895

Epoch: 6| Step: 9
Training loss: 0.2349337355166738
Validation loss: 2.370427644392239

Epoch: 6| Step: 10
Training loss: 0.44118016284678496
Validation loss: 2.341500846154127

Epoch: 6| Step: 11
Training loss: 0.27086420372332903
Validation loss: 2.378924102368673

Epoch: 6| Step: 12
Training loss: 0.46194096621984637
Validation loss: 2.373305186656033

Epoch: 6| Step: 13
Training loss: 0.2670975567193933
Validation loss: 2.3317377876607503

Epoch: 291| Step: 0
Training loss: 0.3804350616767997
Validation loss: 2.324555915139239

Epoch: 6| Step: 1
Training loss: 0.44464871642891435
Validation loss: 2.34489319187942

Epoch: 6| Step: 2
Training loss: 0.4065834291013269
Validation loss: 2.355893738551216

Epoch: 6| Step: 3
Training loss: 0.5892818629357786
Validation loss: 2.3674908011886315

Epoch: 6| Step: 4
Training loss: 0.260312787636258
Validation loss: 2.415402565182538

Epoch: 6| Step: 5
Training loss: 0.40037454712383896
Validation loss: 2.3828661948397194

Epoch: 6| Step: 6
Training loss: 0.385658390262712
Validation loss: 2.352563930087126

Epoch: 6| Step: 7
Training loss: 0.42360400061902015
Validation loss: 2.3445599923518614

Epoch: 6| Step: 8
Training loss: 0.23027353586028168
Validation loss: 2.3377597576988123

Epoch: 6| Step: 9
Training loss: 0.47024051204035044
Validation loss: 2.305133848244224

Epoch: 6| Step: 10
Training loss: 0.5605589702510807
Validation loss: 2.3071015515593656

Epoch: 6| Step: 11
Training loss: 0.6621499963413127
Validation loss: 2.3123827934772105

Epoch: 6| Step: 12
Training loss: 0.44846750551117137
Validation loss: 2.297979102184916

Epoch: 6| Step: 13
Training loss: 0.5187246327919525
Validation loss: 2.2695716991409625

Epoch: 292| Step: 0
Training loss: 0.1613879178429785
Validation loss: 2.2754943863431714

Epoch: 6| Step: 1
Training loss: 0.368911025886045
Validation loss: 2.3201534464907114

Epoch: 6| Step: 2
Training loss: 0.4950367939404228
Validation loss: 2.368088615593362

Epoch: 6| Step: 3
Training loss: 0.3863521148052568
Validation loss: 2.3677369757295743

Epoch: 6| Step: 4
Training loss: 0.34166626750914975
Validation loss: 2.362408748864775

Epoch: 6| Step: 5
Training loss: 0.4795029555469314
Validation loss: 2.396960530392349

Epoch: 6| Step: 6
Training loss: 0.45159693919919297
Validation loss: 2.4201262417385907

Epoch: 6| Step: 7
Training loss: 0.4456132408666472
Validation loss: 2.4116565951786986

Epoch: 6| Step: 8
Training loss: 0.4404187253953833
Validation loss: 2.4141221443122625

Epoch: 6| Step: 9
Training loss: 0.5911528857198376
Validation loss: 2.4262759339518385

Epoch: 6| Step: 10
Training loss: 0.5885546409954787
Validation loss: 2.4522756550063853

Epoch: 6| Step: 11
Training loss: 0.614799272995831
Validation loss: 2.41902801924577

Epoch: 6| Step: 12
Training loss: 0.4040265677009128
Validation loss: 2.403154813479479

Epoch: 6| Step: 13
Training loss: 0.18707428724646885
Validation loss: 2.400971513578866

Epoch: 293| Step: 0
Training loss: 0.16711129853977102
Validation loss: 2.3955281277682596

Epoch: 6| Step: 1
Training loss: 0.3822608983012506
Validation loss: 2.3851070820224782

Epoch: 6| Step: 2
Training loss: 0.26898570758136053
Validation loss: 2.4006241724226474

Epoch: 6| Step: 3
Training loss: 0.3575465500809331
Validation loss: 2.39592151524148

Epoch: 6| Step: 4
Training loss: 0.16997928855229427
Validation loss: 2.3581003245805245

Epoch: 6| Step: 5
Training loss: 0.3549368095572598
Validation loss: 2.3401687464569685

Epoch: 6| Step: 6
Training loss: 0.46903008993918927
Validation loss: 2.3557031597445377

Epoch: 6| Step: 7
Training loss: 0.4659817333959437
Validation loss: 2.3726554247618257

Epoch: 6| Step: 8
Training loss: 0.7507878774614399
Validation loss: 2.369182638136625

Epoch: 6| Step: 9
Training loss: 0.3900533307731704
Validation loss: 2.357546828163326

Epoch: 6| Step: 10
Training loss: 0.2157927879629805
Validation loss: 2.3900845360613383

Epoch: 6| Step: 11
Training loss: 0.35324768323671796
Validation loss: 2.3831230242315047

Epoch: 6| Step: 12
Training loss: 0.7624158750310284
Validation loss: 2.3913866771097436

Epoch: 6| Step: 13
Training loss: 0.5313120413063509
Validation loss: 2.4181182145587967

Epoch: 294| Step: 0
Training loss: 0.5745039251208368
Validation loss: 2.4549735807313833

Epoch: 6| Step: 1
Training loss: 0.48924700026452644
Validation loss: 2.4325966592529333

Epoch: 6| Step: 2
Training loss: 0.7619623039363129
Validation loss: 2.3776491067892844

Epoch: 6| Step: 3
Training loss: 0.36242702505963326
Validation loss: 2.392716909857283

Epoch: 6| Step: 4
Training loss: 0.21938757284386112
Validation loss: 2.3825842145676903

Epoch: 6| Step: 5
Training loss: 0.3082714812427114
Validation loss: 2.3670792461659422

Epoch: 6| Step: 6
Training loss: 0.3221082245192983
Validation loss: 2.326613868540717

Epoch: 6| Step: 7
Training loss: 0.477273801058226
Validation loss: 2.3377826177857908

Epoch: 6| Step: 8
Training loss: 0.4051663544524316
Validation loss: 2.331211393875114

Epoch: 6| Step: 9
Training loss: 0.4941327844532984
Validation loss: 2.3057537867952704

Epoch: 6| Step: 10
Training loss: 0.5563622029327687
Validation loss: 2.330982347436986

Epoch: 6| Step: 11
Training loss: 0.4121620542294129
Validation loss: 2.368112121492798

Epoch: 6| Step: 12
Training loss: 0.36530996754129913
Validation loss: 2.364545191835368

Epoch: 6| Step: 13
Training loss: 0.17753372813856966
Validation loss: 2.357727501303436

Epoch: 295| Step: 0
Training loss: 0.5326997385934196
Validation loss: 2.381151238537108

Epoch: 6| Step: 1
Training loss: 0.25894862599999946
Validation loss: 2.3256655713478613

Epoch: 6| Step: 2
Training loss: 0.47180123668409935
Validation loss: 2.3013573919353028

Epoch: 6| Step: 3
Training loss: 0.2631089028443083
Validation loss: 2.3275602538999216

Epoch: 6| Step: 4
Training loss: 0.3831365342760916
Validation loss: 2.3300721204430515

Epoch: 6| Step: 5
Training loss: 0.5601888968984323
Validation loss: 2.320700696287493

Epoch: 6| Step: 6
Training loss: 0.591305897310442
Validation loss: 2.319544661572349

Epoch: 6| Step: 7
Training loss: 0.16400151595245122
Validation loss: 2.3319848869613713

Epoch: 6| Step: 8
Training loss: 0.21344925268609374
Validation loss: 2.3430398435306334

Epoch: 6| Step: 9
Training loss: 0.5602466696487437
Validation loss: 2.321095462367038

Epoch: 6| Step: 10
Training loss: 0.32721973610158256
Validation loss: 2.3226055174339524

Epoch: 6| Step: 11
Training loss: 0.6003670642526074
Validation loss: 2.318003541222383

Epoch: 6| Step: 12
Training loss: 0.46854796824183176
Validation loss: 2.3179508765804218

Epoch: 6| Step: 13
Training loss: 0.32803725022952346
Validation loss: 2.3274613677732052

Epoch: 296| Step: 0
Training loss: 0.34123672361712826
Validation loss: 2.3632556723723552

Epoch: 6| Step: 1
Training loss: 0.2636657996714002
Validation loss: 2.347516670232075

Epoch: 6| Step: 2
Training loss: 0.34291884335089323
Validation loss: 2.3429494462696563

Epoch: 6| Step: 3
Training loss: 0.43407305438926014
Validation loss: 2.34533613780485

Epoch: 6| Step: 4
Training loss: 0.35363552526059033
Validation loss: 2.325401444653514

Epoch: 6| Step: 5
Training loss: 0.3368897581317988
Validation loss: 2.350436038571718

Epoch: 6| Step: 6
Training loss: 0.4165394668335309
Validation loss: 2.3421373513987542

Epoch: 6| Step: 7
Training loss: 0.4871360471714518
Validation loss: 2.3192679429938448

Epoch: 6| Step: 8
Training loss: 0.3206384094029378
Validation loss: 2.341831216499865

Epoch: 6| Step: 9
Training loss: 0.5422188224869381
Validation loss: 2.303902951802068

Epoch: 6| Step: 10
Training loss: 0.37575829846247033
Validation loss: 2.2521918307380897

Epoch: 6| Step: 11
Training loss: 0.34535910304854917
Validation loss: 2.2550321203825967

Epoch: 6| Step: 12
Training loss: 0.622696493994928
Validation loss: 2.240090025017129

Epoch: 6| Step: 13
Training loss: 0.6848662820878396
Validation loss: 2.258436267073361

Epoch: 297| Step: 0
Training loss: 0.4002370772530219
Validation loss: 2.262200876007415

Epoch: 6| Step: 1
Training loss: 0.421983598930506
Validation loss: 2.26956538144585

Epoch: 6| Step: 2
Training loss: 0.4464251020841668
Validation loss: 2.3081284253885457

Epoch: 6| Step: 3
Training loss: 0.4573345645025121
Validation loss: 2.3017131123712824

Epoch: 6| Step: 4
Training loss: 0.5281661226412827
Validation loss: 2.2829507356167467

Epoch: 6| Step: 5
Training loss: 0.368574364101035
Validation loss: 2.3228519051204897

Epoch: 6| Step: 6
Training loss: 0.44340076337373513
Validation loss: 2.2971236520090437

Epoch: 6| Step: 7
Training loss: 0.3420195807657315
Validation loss: 2.301491084653743

Epoch: 6| Step: 8
Training loss: 0.3359504741558618
Validation loss: 2.3082241769388387

Epoch: 6| Step: 9
Training loss: 0.5795407358783237
Validation loss: 2.326229222421822

Epoch: 6| Step: 10
Training loss: 0.34302613597253906
Validation loss: 2.3119406823310293

Epoch: 6| Step: 11
Training loss: 0.2933049879187122
Validation loss: 2.317743324125344

Epoch: 6| Step: 12
Training loss: 0.4320304284251784
Validation loss: 2.3049075130608543

Epoch: 6| Step: 13
Training loss: 0.5223758806530205
Validation loss: 2.2833302332646963

Epoch: 298| Step: 0
Training loss: 0.4451529233680326
Validation loss: 2.2854190989017815

Epoch: 6| Step: 1
Training loss: 0.33759877384299847
Validation loss: 2.290191332854852

Epoch: 6| Step: 2
Training loss: 0.5619273449677382
Validation loss: 2.3144616440421997

Epoch: 6| Step: 3
Training loss: 0.5072403251887202
Validation loss: 2.2965571540957823

Epoch: 6| Step: 4
Training loss: 0.38741353746978746
Validation loss: 2.3110438304366623

Epoch: 6| Step: 5
Training loss: 0.4764053679771178
Validation loss: 2.27556763781305

Epoch: 6| Step: 6
Training loss: 0.4232265580428889
Validation loss: 2.285379666679073

Epoch: 6| Step: 7
Training loss: 0.3975720824256382
Validation loss: 2.298033494614011

Epoch: 6| Step: 8
Training loss: 0.2403867982343454
Validation loss: 2.291702993073334

Epoch: 6| Step: 9
Training loss: 0.27476561755933365
Validation loss: 2.2985886914093494

Epoch: 6| Step: 10
Training loss: 0.4651864015073464
Validation loss: 2.2851132585428835

Epoch: 6| Step: 11
Training loss: 0.1167693466099819
Validation loss: 2.2839871431205827

Epoch: 6| Step: 12
Training loss: 0.2976349465063148
Validation loss: 2.287700846839649

Epoch: 6| Step: 13
Training loss: 0.5581997101814777
Validation loss: 2.363752995507768

Epoch: 299| Step: 0
Training loss: 0.37251139450567156
Validation loss: 2.375077635484393

Epoch: 6| Step: 1
Training loss: 0.4217313239253746
Validation loss: 2.328440401821776

Epoch: 6| Step: 2
Training loss: 0.13385556649491628
Validation loss: 2.3358896318975204

Epoch: 6| Step: 3
Training loss: 0.5579400138537682
Validation loss: 2.377407224904183

Epoch: 6| Step: 4
Training loss: 0.31766790643518805
Validation loss: 2.4026240055536188

Epoch: 6| Step: 5
Training loss: 0.37872034605161925
Validation loss: 2.4154744391631997

Epoch: 6| Step: 6
Training loss: 0.47473638899316667
Validation loss: 2.3591539528891383

Epoch: 6| Step: 7
Training loss: 0.4013042539834496
Validation loss: 2.3549361441971413

Epoch: 6| Step: 8
Training loss: 0.44089758943118096
Validation loss: 2.342477064751583

Epoch: 6| Step: 9
Training loss: 0.4368260847111501
Validation loss: 2.3037822666285193

Epoch: 6| Step: 10
Training loss: 0.18656642278703658
Validation loss: 2.326305829653424

Epoch: 6| Step: 11
Training loss: 0.5938356237411047
Validation loss: 2.3022501253141403

Epoch: 6| Step: 12
Training loss: 0.4277111378110325
Validation loss: 2.289088667534123

Epoch: 6| Step: 13
Training loss: 0.2604832881904589
Validation loss: 2.2973423696411444

Epoch: 300| Step: 0
Training loss: 0.2689433943403734
Validation loss: 2.2977219917998273

Epoch: 6| Step: 1
Training loss: 0.31089770095916247
Validation loss: 2.3235407180070635

Epoch: 6| Step: 2
Training loss: 0.4027070562530229
Validation loss: 2.348639001011613

Epoch: 6| Step: 3
Training loss: 0.43695545367106864
Validation loss: 2.3893835672922017

Epoch: 6| Step: 4
Training loss: 0.6440210808656303
Validation loss: 2.3636886865144198

Epoch: 6| Step: 5
Training loss: 0.42373438207151665
Validation loss: 2.3811000481020304

Epoch: 6| Step: 6
Training loss: 0.2947054694270412
Validation loss: 2.3875114040771357

Epoch: 6| Step: 7
Training loss: 0.3579104268696219
Validation loss: 2.368520585440997

Epoch: 6| Step: 8
Training loss: 0.48393868206795665
Validation loss: 2.375052665769855

Epoch: 6| Step: 9
Training loss: 0.2181760718063494
Validation loss: 2.3518840785362

Epoch: 6| Step: 10
Training loss: 0.4115316309608853
Validation loss: 2.378643591535364

Epoch: 6| Step: 11
Training loss: 0.5495514362652751
Validation loss: 2.4146422303912973

Epoch: 6| Step: 12
Training loss: 0.25497756307663744
Validation loss: 2.3894546660679694

Epoch: 6| Step: 13
Training loss: 0.38459007014817687
Validation loss: 2.4079180197742507

Epoch: 301| Step: 0
Training loss: 0.32981010706360386
Validation loss: 2.3815089691638

Epoch: 6| Step: 1
Training loss: 0.3129141209384937
Validation loss: 2.3827172857284706

Epoch: 6| Step: 2
Training loss: 0.29343546250177277
Validation loss: 2.393596979000744

Epoch: 6| Step: 3
Training loss: 0.43941785882799805
Validation loss: 2.390617958791445

Epoch: 6| Step: 4
Training loss: 0.302505431205291
Validation loss: 2.362778132896523

Epoch: 6| Step: 5
Training loss: 0.5911660436012692
Validation loss: 2.371472812125052

Epoch: 6| Step: 6
Training loss: 0.22289565249501472
Validation loss: 2.35821211223708

Epoch: 6| Step: 7
Training loss: 0.5276441777966053
Validation loss: 2.3416088493717377

Epoch: 6| Step: 8
Training loss: 0.3896846897785631
Validation loss: 2.36673503222665

Epoch: 6| Step: 9
Training loss: 0.4766102751251366
Validation loss: 2.3374728449271305

Epoch: 6| Step: 10
Training loss: 0.4600324959783095
Validation loss: 2.3380585924357296

Epoch: 6| Step: 11
Training loss: 0.2703061918944869
Validation loss: 2.365352478598616

Epoch: 6| Step: 12
Training loss: 0.3751672133528326
Validation loss: 2.3722977758065373

Epoch: 6| Step: 13
Training loss: 0.1307703897052784
Validation loss: 2.381690077450655

Epoch: 302| Step: 0
Training loss: 0.3748400267479309
Validation loss: 2.391911781713091

Epoch: 6| Step: 1
Training loss: 0.4481468348590418
Validation loss: 2.388874672962437

Epoch: 6| Step: 2
Training loss: 0.2710862155933658
Validation loss: 2.404427877124528

Epoch: 6| Step: 3
Training loss: 0.3466447517092637
Validation loss: 2.3815732587571126

Epoch: 6| Step: 4
Training loss: 0.2513268990526783
Validation loss: 2.3550077974449763

Epoch: 6| Step: 5
Training loss: 0.29779035846183916
Validation loss: 2.3484922826700605

Epoch: 6| Step: 6
Training loss: 0.34032878025861063
Validation loss: 2.345074237547728

Epoch: 6| Step: 7
Training loss: 0.28444251789033115
Validation loss: 2.3518266481462926

Epoch: 6| Step: 8
Training loss: 0.5737426237076797
Validation loss: 2.352616619734503

Epoch: 6| Step: 9
Training loss: 0.5060889706175438
Validation loss: 2.325621053503482

Epoch: 6| Step: 10
Training loss: 0.3672503559612006
Validation loss: 2.366264508522738

Epoch: 6| Step: 11
Training loss: 0.5163593842309048
Validation loss: 2.3433465283578894

Epoch: 6| Step: 12
Training loss: 0.41143695156055643
Validation loss: 2.379843356016214

Epoch: 6| Step: 13
Training loss: 0.44255155330394413
Validation loss: 2.350093969121458

Epoch: 303| Step: 0
Training loss: 0.36476174031188946
Validation loss: 2.3533927007486093

Epoch: 6| Step: 1
Training loss: 0.22659045901925146
Validation loss: 2.374589424718917

Epoch: 6| Step: 2
Training loss: 0.400427802616097
Validation loss: 2.360630984614409

Epoch: 6| Step: 3
Training loss: 0.26103498328274904
Validation loss: 2.3309263971670195

Epoch: 6| Step: 4
Training loss: 0.31932347824569113
Validation loss: 2.329992588722751

Epoch: 6| Step: 5
Training loss: 0.4454633055869053
Validation loss: 2.321382943766154

Epoch: 6| Step: 6
Training loss: 0.59641735847088
Validation loss: 2.287987605870554

Epoch: 6| Step: 7
Training loss: 0.5053522521114016
Validation loss: 2.343500996149811

Epoch: 6| Step: 8
Training loss: 0.47914424788509363
Validation loss: 2.317969654076896

Epoch: 6| Step: 9
Training loss: 0.2786436244247205
Validation loss: 2.321349573104027

Epoch: 6| Step: 10
Training loss: 0.4775126787319894
Validation loss: 2.3150850108338887

Epoch: 6| Step: 11
Training loss: 0.2793949595197737
Validation loss: 2.302749578769545

Epoch: 6| Step: 12
Training loss: 0.36597669103275926
Validation loss: 2.3206374102948097

Epoch: 6| Step: 13
Training loss: 0.23264091652529026
Validation loss: 2.317009400111477

Epoch: 304| Step: 0
Training loss: 0.1923380281633868
Validation loss: 2.317161368500123

Epoch: 6| Step: 1
Training loss: 0.3536532434502724
Validation loss: 2.356260496361876

Epoch: 6| Step: 2
Training loss: 0.37031507611887643
Validation loss: 2.3436139891069225

Epoch: 6| Step: 3
Training loss: 0.4621705357376669
Validation loss: 2.3354389919336414

Epoch: 6| Step: 4
Training loss: 0.4085738036792156
Validation loss: 2.3634640804558944

Epoch: 6| Step: 5
Training loss: 0.5227102095001513
Validation loss: 2.3640791186605066

Epoch: 6| Step: 6
Training loss: 0.4580932570020939
Validation loss: 2.364488922253829

Epoch: 6| Step: 7
Training loss: 0.29190688657471703
Validation loss: 2.354357867834775

Epoch: 6| Step: 8
Training loss: 0.5700380631754838
Validation loss: 2.418996718402853

Epoch: 6| Step: 9
Training loss: 0.4553796808691757
Validation loss: 2.370882475109905

Epoch: 6| Step: 10
Training loss: 0.526938275466618
Validation loss: 2.359410465307778

Epoch: 6| Step: 11
Training loss: 0.3941619957989227
Validation loss: 2.3477921683980347

Epoch: 6| Step: 12
Training loss: 0.5165931109654694
Validation loss: 2.3598712952502203

Epoch: 6| Step: 13
Training loss: 0.24419594710116518
Validation loss: 2.3674545936108107

Epoch: 305| Step: 0
Training loss: 0.6338286071572385
Validation loss: 2.3717844932173575

Epoch: 6| Step: 1
Training loss: 0.3670486228147444
Validation loss: 2.377334833578132

Epoch: 6| Step: 2
Training loss: 0.3866525458492423
Validation loss: 2.3749344708222

Epoch: 6| Step: 3
Training loss: 0.26148747431203634
Validation loss: 2.385663102331271

Epoch: 6| Step: 4
Training loss: 0.45243796518731105
Validation loss: 2.3831503158105987

Epoch: 6| Step: 5
Training loss: 0.5267456053273045
Validation loss: 2.377570493185364

Epoch: 6| Step: 6
Training loss: 0.43120565117284954
Validation loss: 2.3302000455160545

Epoch: 6| Step: 7
Training loss: 0.3736210742947124
Validation loss: 2.3957357514256987

Epoch: 6| Step: 8
Training loss: 0.4447384195669551
Validation loss: 2.360988698299854

Epoch: 6| Step: 9
Training loss: 0.44269572595334483
Validation loss: 2.3390025446993765

Epoch: 6| Step: 10
Training loss: 0.4451181757381595
Validation loss: 2.3272931196386035

Epoch: 6| Step: 11
Training loss: 0.466155565327188
Validation loss: 2.330776162199917

Epoch: 6| Step: 12
Training loss: 0.2350098436150579
Validation loss: 2.352659848730007

Epoch: 6| Step: 13
Training loss: 0.39362847556999264
Validation loss: 2.297911793306625

Epoch: 306| Step: 0
Training loss: 0.40501441491340906
Validation loss: 2.342973709890376

Epoch: 6| Step: 1
Training loss: 0.5577381223356862
Validation loss: 2.3509217839593832

Epoch: 6| Step: 2
Training loss: 0.5237574951436755
Validation loss: 2.357982261103156

Epoch: 6| Step: 3
Training loss: 0.2247623751779622
Validation loss: 2.3228927391082084

Epoch: 6| Step: 4
Training loss: 0.21386318115941058
Validation loss: 2.348214476278696

Epoch: 6| Step: 5
Training loss: 0.6010271142247962
Validation loss: 2.37773072486216

Epoch: 6| Step: 6
Training loss: 0.6547149688857689
Validation loss: 2.372679974545551

Epoch: 6| Step: 7
Training loss: 0.3244327275684477
Validation loss: 2.370139140595671

Epoch: 6| Step: 8
Training loss: 0.17711205576789063
Validation loss: 2.341459881209101

Epoch: 6| Step: 9
Training loss: 0.3820395548723264
Validation loss: 2.2959271656582403

Epoch: 6| Step: 10
Training loss: 0.34247442391888244
Validation loss: 2.285424277397748

Epoch: 6| Step: 11
Training loss: 0.43502437572584624
Validation loss: 2.2713360803323015

Epoch: 6| Step: 12
Training loss: 0.38156895193882645
Validation loss: 2.2491192067878805

Epoch: 6| Step: 13
Training loss: 0.175896029615769
Validation loss: 2.273119102785554

Epoch: 307| Step: 0
Training loss: 0.20876399568650417
Validation loss: 2.300145777986411

Epoch: 6| Step: 1
Training loss: 0.2989151771755736
Validation loss: 2.274797478295326

Epoch: 6| Step: 2
Training loss: 0.4598148867291232
Validation loss: 2.304860717315278

Epoch: 6| Step: 3
Training loss: 0.45345858100980857
Validation loss: 2.314794999638271

Epoch: 6| Step: 4
Training loss: 0.3874145759745739
Validation loss: 2.3425888214955743

Epoch: 6| Step: 5
Training loss: 0.43184115209584084
Validation loss: 2.3422616073293137

Epoch: 6| Step: 6
Training loss: 0.45211831439461625
Validation loss: 2.333179039915114

Epoch: 6| Step: 7
Training loss: 0.3170150151615161
Validation loss: 2.389513660770585

Epoch: 6| Step: 8
Training loss: 0.32055399095380066
Validation loss: 2.3884765238169288

Epoch: 6| Step: 9
Training loss: 0.30830119546518664
Validation loss: 2.401799411232626

Epoch: 6| Step: 10
Training loss: 0.6727160578953972
Validation loss: 2.3537446112962597

Epoch: 6| Step: 11
Training loss: 0.3050414255026017
Validation loss: 2.3569914500677887

Epoch: 6| Step: 12
Training loss: 0.46115026574266244
Validation loss: 2.374316498740391

Epoch: 6| Step: 13
Training loss: 0.21477661817938146
Validation loss: 2.312577318109007

Epoch: 308| Step: 0
Training loss: 0.5980147489543755
Validation loss: 2.3408263349365126

Epoch: 6| Step: 1
Training loss: 0.5030268010569959
Validation loss: 2.338308460896577

Epoch: 6| Step: 2
Training loss: 0.4522456812254347
Validation loss: 2.3471628079709332

Epoch: 6| Step: 3
Training loss: 0.4310656554361178
Validation loss: 2.307686278488091

Epoch: 6| Step: 4
Training loss: 0.2524748287543326
Validation loss: 2.3432424048952525

Epoch: 6| Step: 5
Training loss: 0.17375054932239886
Validation loss: 2.337728104564216

Epoch: 6| Step: 6
Training loss: 0.45877667861406046
Validation loss: 2.3618840371426915

Epoch: 6| Step: 7
Training loss: 0.38200862326051205
Validation loss: 2.420613100714695

Epoch: 6| Step: 8
Training loss: 0.5593061639211827
Validation loss: 2.4000376132697534

Epoch: 6| Step: 9
Training loss: 0.22891625717734237
Validation loss: 2.395572762321394

Epoch: 6| Step: 10
Training loss: 0.3335745231930346
Validation loss: 2.4080084874336034

Epoch: 6| Step: 11
Training loss: 0.22644330046034436
Validation loss: 2.386736786683581

Epoch: 6| Step: 12
Training loss: 0.42502495327791023
Validation loss: 2.38083944603655

Epoch: 6| Step: 13
Training loss: 0.28813191709676417
Validation loss: 2.359898369594214

Epoch: 309| Step: 0
Training loss: 0.38856424346184165
Validation loss: 2.328408873030997

Epoch: 6| Step: 1
Training loss: 0.5282676515405802
Validation loss: 2.344381623289185

Epoch: 6| Step: 2
Training loss: 0.25381441656392756
Validation loss: 2.334437549236993

Epoch: 6| Step: 3
Training loss: 0.3464797612069064
Validation loss: 2.3310665023757724

Epoch: 6| Step: 4
Training loss: 0.3825244598421756
Validation loss: 2.3259331540303863

Epoch: 6| Step: 5
Training loss: 0.2805469919160383
Validation loss: 2.320232804452642

Epoch: 6| Step: 6
Training loss: 0.22881839127186468
Validation loss: 2.3173668324398817

Epoch: 6| Step: 7
Training loss: 0.3143746414334203
Validation loss: 2.309462508264395

Epoch: 6| Step: 8
Training loss: 0.39047413773805695
Validation loss: 2.321255464082164

Epoch: 6| Step: 9
Training loss: 0.16003047842812984
Validation loss: 2.3025956460553263

Epoch: 6| Step: 10
Training loss: 0.41911833420324146
Validation loss: 2.3205020534739105

Epoch: 6| Step: 11
Training loss: 0.543163923135278
Validation loss: 2.315729519626625

Epoch: 6| Step: 12
Training loss: 0.33229471860976884
Validation loss: 2.29419438484296

Epoch: 6| Step: 13
Training loss: 0.659778351375869
Validation loss: 2.2642515348230727

Epoch: 310| Step: 0
Training loss: 0.3045411981334693
Validation loss: 2.294735772086595

Epoch: 6| Step: 1
Training loss: 0.36610687811933224
Validation loss: 2.2989929693809543

Epoch: 6| Step: 2
Training loss: 0.21219205421650367
Validation loss: 2.332835752709785

Epoch: 6| Step: 3
Training loss: 0.20311966302169343
Validation loss: 2.2839033811144884

Epoch: 6| Step: 4
Training loss: 0.522053554392964
Validation loss: 2.333885224472123

Epoch: 6| Step: 5
Training loss: 0.4735913288000446
Validation loss: 2.318837589214623

Epoch: 6| Step: 6
Training loss: 0.5098032151901665
Validation loss: 2.3158854818604535

Epoch: 6| Step: 7
Training loss: 0.3798993457638438
Validation loss: 2.281234896243637

Epoch: 6| Step: 8
Training loss: 0.2165922367575305
Validation loss: 2.3052785119444024

Epoch: 6| Step: 9
Training loss: 0.41440711885140696
Validation loss: 2.2981281457391014

Epoch: 6| Step: 10
Training loss: 0.24248165294712945
Validation loss: 2.2792805334392647

Epoch: 6| Step: 11
Training loss: 0.4155039080276506
Validation loss: 2.252493655763413

Epoch: 6| Step: 12
Training loss: 0.4421684301463157
Validation loss: 2.273575915324999

Epoch: 6| Step: 13
Training loss: 0.46529148881868465
Validation loss: 2.2756155209300903

Epoch: 311| Step: 0
Training loss: 0.3071163884509345
Validation loss: 2.2559299965962367

Epoch: 6| Step: 1
Training loss: 0.4077832741331575
Validation loss: 2.273424880721456

Epoch: 6| Step: 2
Training loss: 0.3238024279219473
Validation loss: 2.2588037965337073

Epoch: 6| Step: 3
Training loss: 0.4210815739330983
Validation loss: 2.2993118488557007

Epoch: 6| Step: 4
Training loss: 0.4150133910374118
Validation loss: 2.344022828769976

Epoch: 6| Step: 5
Training loss: 0.39592436530073244
Validation loss: 2.306836984099638

Epoch: 6| Step: 6
Training loss: 0.29766472131083477
Validation loss: 2.3299641595547054

Epoch: 6| Step: 7
Training loss: 0.18250798719054934
Validation loss: 2.301622827347989

Epoch: 6| Step: 8
Training loss: 0.5065890907307239
Validation loss: 2.277789906058381

Epoch: 6| Step: 9
Training loss: 0.32778812326903645
Validation loss: 2.325117912857408

Epoch: 6| Step: 10
Training loss: 0.3996204691639899
Validation loss: 2.298584950654111

Epoch: 6| Step: 11
Training loss: 0.42538712134901946
Validation loss: 2.318361770160478

Epoch: 6| Step: 12
Training loss: 0.4644865378511911
Validation loss: 2.3253125788079587

Epoch: 6| Step: 13
Training loss: 0.23712966492769297
Validation loss: 2.319900589382391

Epoch: 312| Step: 0
Training loss: 0.48682029362908474
Validation loss: 2.3089887029480303

Epoch: 6| Step: 1
Training loss: 0.37268592188525174
Validation loss: 2.3516830785720577

Epoch: 6| Step: 2
Training loss: 0.24721424900876504
Validation loss: 2.344545122585393

Epoch: 6| Step: 3
Training loss: 0.30562442607864754
Validation loss: 2.304342057619114

Epoch: 6| Step: 4
Training loss: 0.2950230102940037
Validation loss: 2.307725174586731

Epoch: 6| Step: 5
Training loss: 0.32814745599108447
Validation loss: 2.3485259864718793

Epoch: 6| Step: 6
Training loss: 0.22225175053311527
Validation loss: 2.3224762548224507

Epoch: 6| Step: 7
Training loss: 0.22728269484726954
Validation loss: 2.331783309048848

Epoch: 6| Step: 8
Training loss: 0.4252014762491238
Validation loss: 2.341522221764378

Epoch: 6| Step: 9
Training loss: 0.5948397273495539
Validation loss: 2.3114741842983784

Epoch: 6| Step: 10
Training loss: 0.39589737909417366
Validation loss: 2.2938735428153882

Epoch: 6| Step: 11
Training loss: 0.32006723038556484
Validation loss: 2.2907103309651786

Epoch: 6| Step: 12
Training loss: 0.39925082725458305
Validation loss: 2.285698458720739

Epoch: 6| Step: 13
Training loss: 0.3289192894822256
Validation loss: 2.2441482754439517

Epoch: 313| Step: 0
Training loss: 0.2867033936132717
Validation loss: 2.2483171792101726

Epoch: 6| Step: 1
Training loss: 0.4182779469749728
Validation loss: 2.2711422930098264

Epoch: 6| Step: 2
Training loss: 0.48304305451282953
Validation loss: 2.3044579142850785

Epoch: 6| Step: 3
Training loss: 0.3682597716408226
Validation loss: 2.2992339720438557

Epoch: 6| Step: 4
Training loss: 0.37064022660136525
Validation loss: 2.349495136498422

Epoch: 6| Step: 5
Training loss: 0.44111637285832694
Validation loss: 2.372279367820635

Epoch: 6| Step: 6
Training loss: 0.271856642793929
Validation loss: 2.4352863441919292

Epoch: 6| Step: 7
Training loss: 0.3798625126688267
Validation loss: 2.437758443344938

Epoch: 6| Step: 8
Training loss: 0.567963032647784
Validation loss: 2.4622450467586345

Epoch: 6| Step: 9
Training loss: 0.3853952513578895
Validation loss: 2.426726149703656

Epoch: 6| Step: 10
Training loss: 0.3075145974222268
Validation loss: 2.4104317715881907

Epoch: 6| Step: 11
Training loss: 0.3867678562929521
Validation loss: 2.3413652641181137

Epoch: 6| Step: 12
Training loss: 0.3903288672430871
Validation loss: 2.307840882521701

Epoch: 6| Step: 13
Training loss: 0.4084883428098626
Validation loss: 2.2928595692569504

Epoch: 314| Step: 0
Training loss: 0.31717474352736863
Validation loss: 2.3299535334616848

Epoch: 6| Step: 1
Training loss: 0.3846140529077657
Validation loss: 2.264325445219837

Epoch: 6| Step: 2
Training loss: 0.37647553068792744
Validation loss: 2.30585609093605

Epoch: 6| Step: 3
Training loss: 0.4433896898837233
Validation loss: 2.3043756067113494

Epoch: 6| Step: 4
Training loss: 0.5461191676259066
Validation loss: 2.285788106774592

Epoch: 6| Step: 5
Training loss: 0.24265620039419245
Validation loss: 2.3213096429749767

Epoch: 6| Step: 6
Training loss: 0.3050968159556028
Validation loss: 2.3645598417756553

Epoch: 6| Step: 7
Training loss: 0.3132571346676056
Validation loss: 2.355546791948184

Epoch: 6| Step: 8
Training loss: 0.5718388446989594
Validation loss: 2.391668420274825

Epoch: 6| Step: 9
Training loss: 0.38989766117000085
Validation loss: 2.35182407395968

Epoch: 6| Step: 10
Training loss: 0.39001600477194714
Validation loss: 2.3928213982024773

Epoch: 6| Step: 11
Training loss: 0.27676604103234137
Validation loss: 2.3735859476581256

Epoch: 6| Step: 12
Training loss: 0.3385128730364496
Validation loss: 2.4126584105117956

Epoch: 6| Step: 13
Training loss: 0.36034134847747024
Validation loss: 2.402050870111034

Epoch: 315| Step: 0
Training loss: 0.2494598006189446
Validation loss: 2.3844176111193205

Epoch: 6| Step: 1
Training loss: 0.35376296690235454
Validation loss: 2.367288588469773

Epoch: 6| Step: 2
Training loss: 0.501419317896024
Validation loss: 2.3585042082019942

Epoch: 6| Step: 3
Training loss: 0.29481427332911075
Validation loss: 2.3360329720731983

Epoch: 6| Step: 4
Training loss: 0.41040108049233737
Validation loss: 2.3512609924440455

Epoch: 6| Step: 5
Training loss: 0.3806118674432142
Validation loss: 2.3577390248561128

Epoch: 6| Step: 6
Training loss: 0.31453357875699045
Validation loss: 2.336336061324575

Epoch: 6| Step: 7
Training loss: 0.18090116046988786
Validation loss: 2.3650398737025746

Epoch: 6| Step: 8
Training loss: 0.525176845011637
Validation loss: 2.3799847082024415

Epoch: 6| Step: 9
Training loss: 0.5659807909243414
Validation loss: 2.392340831796752

Epoch: 6| Step: 10
Training loss: 0.29192269815672833
Validation loss: 2.408587057685571

Epoch: 6| Step: 11
Training loss: 0.3833556506495119
Validation loss: 2.4541125833755775

Epoch: 6| Step: 12
Training loss: 0.38833064526881406
Validation loss: 2.380827408142526

Epoch: 6| Step: 13
Training loss: 0.5123548267187402
Validation loss: 2.3752607473382286

Epoch: 316| Step: 0
Training loss: 0.4351560267339986
Validation loss: 2.3869880422441145

Epoch: 6| Step: 1
Training loss: 0.3522256847927821
Validation loss: 2.348755944387854

Epoch: 6| Step: 2
Training loss: 0.34418085579722013
Validation loss: 2.3107673037044867

Epoch: 6| Step: 3
Training loss: 0.44539452516794975
Validation loss: 2.3342879641739875

Epoch: 6| Step: 4
Training loss: 0.4378728980390456
Validation loss: 2.3572590273979546

Epoch: 6| Step: 5
Training loss: 0.5131141913294335
Validation loss: 2.3475152876774623

Epoch: 6| Step: 6
Training loss: 0.36647748275062614
Validation loss: 2.336888909898216

Epoch: 6| Step: 7
Training loss: 0.33235882700235186
Validation loss: 2.3269404208179423

Epoch: 6| Step: 8
Training loss: 0.43882425027732286
Validation loss: 2.3458653879952696

Epoch: 6| Step: 9
Training loss: 0.2682726401989811
Validation loss: 2.3379932751495485

Epoch: 6| Step: 10
Training loss: 0.42911994905107737
Validation loss: 2.347873083887298

Epoch: 6| Step: 11
Training loss: 0.2929289472880653
Validation loss: 2.4093402866698317

Epoch: 6| Step: 12
Training loss: 0.33582864150886715
Validation loss: 2.3818903141294303

Epoch: 6| Step: 13
Training loss: 0.3947586122060164
Validation loss: 2.390577303610136

Epoch: 317| Step: 0
Training loss: 0.3052762896013438
Validation loss: 2.379628011061873

Epoch: 6| Step: 1
Training loss: 0.27607750959833516
Validation loss: 2.3076946458759986

Epoch: 6| Step: 2
Training loss: 0.39819683959862107
Validation loss: 2.286112130657785

Epoch: 6| Step: 3
Training loss: 0.481200753825803
Validation loss: 2.312066376485905

Epoch: 6| Step: 4
Training loss: 0.3463183602011251
Validation loss: 2.315358936425005

Epoch: 6| Step: 5
Training loss: 0.30557327628527664
Validation loss: 2.2975877966309666

Epoch: 6| Step: 6
Training loss: 0.39343994588296183
Validation loss: 2.311573328462628

Epoch: 6| Step: 7
Training loss: 0.21797556541753238
Validation loss: 2.314055401688139

Epoch: 6| Step: 8
Training loss: 0.576820189826209
Validation loss: 2.356253411758489

Epoch: 6| Step: 9
Training loss: 0.3701570031483284
Validation loss: 2.3867885264613387

Epoch: 6| Step: 10
Training loss: 0.34276177584816236
Validation loss: 2.3849045420070234

Epoch: 6| Step: 11
Training loss: 0.2615866541220791
Validation loss: 2.3900233082650115

Epoch: 6| Step: 12
Training loss: 0.3886021307090228
Validation loss: 2.3654291258340634

Epoch: 6| Step: 13
Training loss: 0.4769206342948145
Validation loss: 2.3781557613973368

Epoch: 318| Step: 0
Training loss: 0.4384129569429579
Validation loss: 2.3224658941633796

Epoch: 6| Step: 1
Training loss: 0.3540894293245007
Validation loss: 2.3277075333283404

Epoch: 6| Step: 2
Training loss: 0.32128565360350814
Validation loss: 2.263591958854424

Epoch: 6| Step: 3
Training loss: 0.4015049013620114
Validation loss: 2.284666149253687

Epoch: 6| Step: 4
Training loss: 0.46154318632861924
Validation loss: 2.279616477483147

Epoch: 6| Step: 5
Training loss: 0.35072168893813993
Validation loss: 2.278743878249019

Epoch: 6| Step: 6
Training loss: 0.27575897040349495
Validation loss: 2.2842614736558464

Epoch: 6| Step: 7
Training loss: 0.49190428320688595
Validation loss: 2.327884655885201

Epoch: 6| Step: 8
Training loss: 0.25048512834196873
Validation loss: 2.3597898987056203

Epoch: 6| Step: 9
Training loss: 0.4016334782669292
Validation loss: 2.406847669286108

Epoch: 6| Step: 10
Training loss: 0.3642570966043673
Validation loss: 2.421837563544585

Epoch: 6| Step: 11
Training loss: 0.29401622436481806
Validation loss: 2.460873513823094

Epoch: 6| Step: 12
Training loss: 0.45415665487167567
Validation loss: 2.455327423942903

Epoch: 6| Step: 13
Training loss: 0.34076294511819355
Validation loss: 2.4276539419939183

Epoch: 319| Step: 0
Training loss: 0.36142508778045596
Validation loss: 2.433227930835836

Epoch: 6| Step: 1
Training loss: 0.3209121255398974
Validation loss: 2.3990606025211774

Epoch: 6| Step: 2
Training loss: 0.3371122026380145
Validation loss: 2.3821698539774787

Epoch: 6| Step: 3
Training loss: 0.4418724096672827
Validation loss: 2.3270795340818275

Epoch: 6| Step: 4
Training loss: 0.4097940935076926
Validation loss: 2.304879987967868

Epoch: 6| Step: 5
Training loss: 0.5304925792437538
Validation loss: 2.272412811354486

Epoch: 6| Step: 6
Training loss: 0.37981486754803934
Validation loss: 2.286585527856399

Epoch: 6| Step: 7
Training loss: 0.41287992855136635
Validation loss: 2.1965973201015263

Epoch: 6| Step: 8
Training loss: 0.202143360387466
Validation loss: 2.2717969143987347

Epoch: 6| Step: 9
Training loss: 0.31534067321068693
Validation loss: 2.245930725715789

Epoch: 6| Step: 10
Training loss: 0.41441434630273605
Validation loss: 2.2424725115604645

Epoch: 6| Step: 11
Training loss: 0.3280817298514886
Validation loss: 2.2716579195142974

Epoch: 6| Step: 12
Training loss: 0.34827214238960075
Validation loss: 2.2812031201535166

Epoch: 6| Step: 13
Training loss: 0.4260338200388313
Validation loss: 2.2783978442183432

Epoch: 320| Step: 0
Training loss: 0.42185546688495057
Validation loss: 2.3093800005133676

Epoch: 6| Step: 1
Training loss: 0.47946138924010234
Validation loss: 2.2644000554203294

Epoch: 6| Step: 2
Training loss: 0.1225239526190179
Validation loss: 2.3153313263110653

Epoch: 6| Step: 3
Training loss: 0.3766032952651706
Validation loss: 2.2831858569882346

Epoch: 6| Step: 4
Training loss: 0.31271488431049094
Validation loss: 2.310181136627372

Epoch: 6| Step: 5
Training loss: 0.40350455816405284
Validation loss: 2.29108245390983

Epoch: 6| Step: 6
Training loss: 0.16705542476876525
Validation loss: 2.324787833300088

Epoch: 6| Step: 7
Training loss: 0.30568392753034446
Validation loss: 2.3378915757185474

Epoch: 6| Step: 8
Training loss: 0.5562846333726724
Validation loss: 2.3235381422732555

Epoch: 6| Step: 9
Training loss: 0.1995588653023185
Validation loss: 2.319354684992496

Epoch: 6| Step: 10
Training loss: 0.2608639722009433
Validation loss: 2.3054798830962624

Epoch: 6| Step: 11
Training loss: 0.24146050889683798
Validation loss: 2.3117517825662497

Epoch: 6| Step: 12
Training loss: 0.3471352606064984
Validation loss: 2.3336657852736993

Epoch: 6| Step: 13
Training loss: 0.5120155114603293
Validation loss: 2.2889167380571

Epoch: 321| Step: 0
Training loss: 0.3606072116014849
Validation loss: 2.268894065939023

Epoch: 6| Step: 1
Training loss: 0.3990124126298593
Validation loss: 2.288501395643592

Epoch: 6| Step: 2
Training loss: 0.32543601902082075
Validation loss: 2.275230110031392

Epoch: 6| Step: 3
Training loss: 0.3646876276795622
Validation loss: 2.253609000641994

Epoch: 6| Step: 4
Training loss: 0.32610161532835735
Validation loss: 2.271038411560757

Epoch: 6| Step: 5
Training loss: 0.34263673322336513
Validation loss: 2.2847065436384044

Epoch: 6| Step: 6
Training loss: 0.40379713565756153
Validation loss: 2.288880429965924

Epoch: 6| Step: 7
Training loss: 0.3045833238379029
Validation loss: 2.285881743613499

Epoch: 6| Step: 8
Training loss: 0.3043748033511175
Validation loss: 2.319001346479724

Epoch: 6| Step: 9
Training loss: 0.3457275640610095
Validation loss: 2.3046325610304037

Epoch: 6| Step: 10
Training loss: 0.3516865405497896
Validation loss: 2.2905077564768357

Epoch: 6| Step: 11
Training loss: 0.3576196633987097
Validation loss: 2.3031725560126097

Epoch: 6| Step: 12
Training loss: 0.29397165934454234
Validation loss: 2.3005938080428887

Epoch: 6| Step: 13
Training loss: 0.30572751638864976
Validation loss: 2.28783485099654

Epoch: 322| Step: 0
Training loss: 0.2707009572744618
Validation loss: 2.3055978441599896

Epoch: 6| Step: 1
Training loss: 0.2811474083178741
Validation loss: 2.3277516081795953

Epoch: 6| Step: 2
Training loss: 0.31353877986115514
Validation loss: 2.3026660862200665

Epoch: 6| Step: 3
Training loss: 0.23942633163127244
Validation loss: 2.3487610088900865

Epoch: 6| Step: 4
Training loss: 0.287060947615838
Validation loss: 2.2911596802023575

Epoch: 6| Step: 5
Training loss: 0.5351460309688807
Validation loss: 2.295428126937313

Epoch: 6| Step: 6
Training loss: 0.4678922116158273
Validation loss: 2.2959590422377327

Epoch: 6| Step: 7
Training loss: 0.3282802418907116
Validation loss: 2.2727107016853307

Epoch: 6| Step: 8
Training loss: 0.24938987997065779
Validation loss: 2.292834028412675

Epoch: 6| Step: 9
Training loss: 0.3267571571831479
Validation loss: 2.261999677670806

Epoch: 6| Step: 10
Training loss: 0.2945134954388172
Validation loss: 2.2742322299407696

Epoch: 6| Step: 11
Training loss: 0.4044260749222989
Validation loss: 2.2962633612870222

Epoch: 6| Step: 12
Training loss: 0.24479301262884554
Validation loss: 2.3002535028470144

Epoch: 6| Step: 13
Training loss: 0.5390650431255116
Validation loss: 2.3184840140517284

Epoch: 323| Step: 0
Training loss: 0.23613634288284838
Validation loss: 2.278782034229901

Epoch: 6| Step: 1
Training loss: 0.19844249884248927
Validation loss: 2.2566254422576986

Epoch: 6| Step: 2
Training loss: 0.3134494662829328
Validation loss: 2.297441367093756

Epoch: 6| Step: 3
Training loss: 0.40415458202320204
Validation loss: 2.2584594635337227

Epoch: 6| Step: 4
Training loss: 0.42311280178027866
Validation loss: 2.251753374836845

Epoch: 6| Step: 5
Training loss: 0.45243131221624366
Validation loss: 2.2854119629566187

Epoch: 6| Step: 6
Training loss: 0.3978437412637409
Validation loss: 2.2904572454870378

Epoch: 6| Step: 7
Training loss: 0.25495038653155705
Validation loss: 2.2756938781713876

Epoch: 6| Step: 8
Training loss: 0.3199619608115131
Validation loss: 2.2929219811710464

Epoch: 6| Step: 9
Training loss: 0.3128090045973751
Validation loss: 2.333821062417376

Epoch: 6| Step: 10
Training loss: 0.19141531942250772
Validation loss: 2.3117595901870986

Epoch: 6| Step: 11
Training loss: 0.41002414937540205
Validation loss: 2.3391736149620503

Epoch: 6| Step: 12
Training loss: 0.3959492421685968
Validation loss: 2.35493058567507

Epoch: 6| Step: 13
Training loss: 0.527739087019524
Validation loss: 2.356364092993105

Epoch: 324| Step: 0
Training loss: 0.33268054979120903
Validation loss: 2.2768212410984456

Epoch: 6| Step: 1
Training loss: 0.31985198621110816
Validation loss: 2.2579238114196087

Epoch: 6| Step: 2
Training loss: 0.5012774837122448
Validation loss: 2.2315839440630767

Epoch: 6| Step: 3
Training loss: 0.45406748325897744
Validation loss: 2.1928920523225277

Epoch: 6| Step: 4
Training loss: 0.4782228469458759
Validation loss: 2.183828672289188

Epoch: 6| Step: 5
Training loss: 0.4750461530850266
Validation loss: 2.245293715401103

Epoch: 6| Step: 6
Training loss: 0.4099310847258943
Validation loss: 2.2573744507213584

Epoch: 6| Step: 7
Training loss: 0.3648373286725698
Validation loss: 2.305177517274453

Epoch: 6| Step: 8
Training loss: 0.2936492138293976
Validation loss: 2.315581621725791

Epoch: 6| Step: 9
Training loss: 0.34310657799190164
Validation loss: 2.331909655819518

Epoch: 6| Step: 10
Training loss: 0.3784763217357917
Validation loss: 2.37228236234304

Epoch: 6| Step: 11
Training loss: 0.4237693359104495
Validation loss: 2.3926968546529572

Epoch: 6| Step: 12
Training loss: 0.37547208952003996
Validation loss: 2.4115896675362025

Epoch: 6| Step: 13
Training loss: 0.3361868709027145
Validation loss: 2.425550988375287

Epoch: 325| Step: 0
Training loss: 0.41610116929800095
Validation loss: 2.40673093779864

Epoch: 6| Step: 1
Training loss: 0.3438424072905065
Validation loss: 2.3483117254089523

Epoch: 6| Step: 2
Training loss: 0.336765621489905
Validation loss: 2.3101200238622543

Epoch: 6| Step: 3
Training loss: 0.4020170348197297
Validation loss: 2.2805589805635496

Epoch: 6| Step: 4
Training loss: 0.25645594171720226
Validation loss: 2.2336817276191745

Epoch: 6| Step: 5
Training loss: 0.45418391967806887
Validation loss: 2.1818462726616357

Epoch: 6| Step: 6
Training loss: 0.3023808414664546
Validation loss: 2.193844970315272

Epoch: 6| Step: 7
Training loss: 0.37154323059499533
Validation loss: 2.2192395611995344

Epoch: 6| Step: 8
Training loss: 0.37968575041567987
Validation loss: 2.172192701178235

Epoch: 6| Step: 9
Training loss: 0.4847410111245575
Validation loss: 2.224999856366988

Epoch: 6| Step: 10
Training loss: 0.37083691191643203
Validation loss: 2.2528593223399844

Epoch: 6| Step: 11
Training loss: 0.34100194862094224
Validation loss: 2.30175321483162

Epoch: 6| Step: 12
Training loss: 0.4644395689915001
Validation loss: 2.280426811858417

Epoch: 6| Step: 13
Training loss: 0.30206438805376634
Validation loss: 2.338292836540181

Epoch: 326| Step: 0
Training loss: 0.2979957981765463
Validation loss: 2.330378894170171

Epoch: 6| Step: 1
Training loss: 0.5435557314348356
Validation loss: 2.3715400071103216

Epoch: 6| Step: 2
Training loss: 0.5030939815271197
Validation loss: 2.335908595536096

Epoch: 6| Step: 3
Training loss: 0.25450399902758
Validation loss: 2.297971611990048

Epoch: 6| Step: 4
Training loss: 0.39381619608467
Validation loss: 2.2524530661086946

Epoch: 6| Step: 5
Training loss: 0.4158113900620924
Validation loss: 2.245047809597766

Epoch: 6| Step: 6
Training loss: 0.3142731429889604
Validation loss: 2.2335395171718946

Epoch: 6| Step: 7
Training loss: 0.3290285544533663
Validation loss: 2.2389673937579997

Epoch: 6| Step: 8
Training loss: 0.29234343870748875
Validation loss: 2.2614403227997983

Epoch: 6| Step: 9
Training loss: 0.3676893984032176
Validation loss: 2.236411228365239

Epoch: 6| Step: 10
Training loss: 0.26679995075647883
Validation loss: 2.2589175456682247

Epoch: 6| Step: 11
Training loss: 0.40015568236787774
Validation loss: 2.2644414076724253

Epoch: 6| Step: 12
Training loss: 0.5062773167339828
Validation loss: 2.3154151886882195

Epoch: 6| Step: 13
Training loss: 0.17416135586698372
Validation loss: 2.2986749423465764

Epoch: 327| Step: 0
Training loss: 0.22353889125571705
Validation loss: 2.316832084604749

Epoch: 6| Step: 1
Training loss: 0.3489488189975449
Validation loss: 2.3424722766836816

Epoch: 6| Step: 2
Training loss: 0.22431481161119549
Validation loss: 2.3210881555623013

Epoch: 6| Step: 3
Training loss: 0.451761991000776
Validation loss: 2.3189394778229384

Epoch: 6| Step: 4
Training loss: 0.35306414864766816
Validation loss: 2.330614825329228

Epoch: 6| Step: 5
Training loss: 0.5342351406960276
Validation loss: 2.303013528777214

Epoch: 6| Step: 6
Training loss: 0.31528965820964017
Validation loss: 2.311738591447466

Epoch: 6| Step: 7
Training loss: 0.5150078634939488
Validation loss: 2.2961358694920677

Epoch: 6| Step: 8
Training loss: 0.40688368086336674
Validation loss: 2.290359414701513

Epoch: 6| Step: 9
Training loss: 0.3709421952616506
Validation loss: 2.266639079131744

Epoch: 6| Step: 10
Training loss: 0.40769042895649626
Validation loss: 2.262480429972235

Epoch: 6| Step: 11
Training loss: 0.23806897854821688
Validation loss: 2.288984963274459

Epoch: 6| Step: 12
Training loss: 0.2713284216082023
Validation loss: 2.2873861666370994

Epoch: 6| Step: 13
Training loss: 0.4104735827152415
Validation loss: 2.3076701546282234

Epoch: 328| Step: 0
Training loss: 0.36464750088539244
Validation loss: 2.297802191406581

Epoch: 6| Step: 1
Training loss: 0.4313499369441152
Validation loss: 2.3556658655311287

Epoch: 6| Step: 2
Training loss: 0.2189060914490348
Validation loss: 2.3682680731613948

Epoch: 6| Step: 3
Training loss: 0.44716819801499635
Validation loss: 2.386669131230915

Epoch: 6| Step: 4
Training loss: 0.30877941920009205
Validation loss: 2.4044580210079896

Epoch: 6| Step: 5
Training loss: 0.30574186998367636
Validation loss: 2.39188911098413

Epoch: 6| Step: 6
Training loss: 0.3938648525639091
Validation loss: 2.4180932392388184

Epoch: 6| Step: 7
Training loss: 0.28915778728881614
Validation loss: 2.4578094807211546

Epoch: 6| Step: 8
Training loss: 0.26406239447506935
Validation loss: 2.4351745568776146

Epoch: 6| Step: 9
Training loss: 0.3022104713758421
Validation loss: 2.4312031846927806

Epoch: 6| Step: 10
Training loss: 0.3672576999519285
Validation loss: 2.3956360409805555

Epoch: 6| Step: 11
Training loss: 0.31301194219079853
Validation loss: 2.3415042720019943

Epoch: 6| Step: 12
Training loss: 0.5513925339118958
Validation loss: 2.3291444046277707

Epoch: 6| Step: 13
Training loss: 0.3317625753891085
Validation loss: 2.2856377425924563

Epoch: 329| Step: 0
Training loss: 0.28318693180486065
Validation loss: 2.26242582867779

Epoch: 6| Step: 1
Training loss: 0.3683540400485844
Validation loss: 2.2482846317170315

Epoch: 6| Step: 2
Training loss: 0.5783378106291146
Validation loss: 2.2545363484065497

Epoch: 6| Step: 3
Training loss: 0.47183564571457176
Validation loss: 2.201209382903941

Epoch: 6| Step: 4
Training loss: 0.45638382529776783
Validation loss: 2.214972360978748

Epoch: 6| Step: 5
Training loss: 0.37638743355521687
Validation loss: 2.2187703472696723

Epoch: 6| Step: 6
Training loss: 0.3326021335530508
Validation loss: 2.2020708662025483

Epoch: 6| Step: 7
Training loss: 0.22336475682054327
Validation loss: 2.203431862631572

Epoch: 6| Step: 8
Training loss: 0.2842199683726884
Validation loss: 2.2059478266867942

Epoch: 6| Step: 9
Training loss: 0.2534513947597318
Validation loss: 2.1769942885453335

Epoch: 6| Step: 10
Training loss: 0.34296464070354404
Validation loss: 2.223382886379984

Epoch: 6| Step: 11
Training loss: 0.26864010926166465
Validation loss: 2.230155830780512

Epoch: 6| Step: 12
Training loss: 0.20539297730095318
Validation loss: 2.2275187711593567

Epoch: 6| Step: 13
Training loss: 0.46575397842866223
Validation loss: 2.212696012251179

Epoch: 330| Step: 0
Training loss: 0.2331795324279738
Validation loss: 2.268994179192694

Epoch: 6| Step: 1
Training loss: 0.3196100347713056
Validation loss: 2.293393695472552

Epoch: 6| Step: 2
Training loss: 0.5772689461157574
Validation loss: 2.306886681921839

Epoch: 6| Step: 3
Training loss: 0.3044714161441828
Validation loss: 2.2908488077392866

Epoch: 6| Step: 4
Training loss: 0.3757769166058128
Validation loss: 2.319198232020183

Epoch: 6| Step: 5
Training loss: 0.28094540102226323
Validation loss: 2.2478562628436967

Epoch: 6| Step: 6
Training loss: 0.4157072186712058
Validation loss: 2.242064923255987

Epoch: 6| Step: 7
Training loss: 0.3219973516784776
Validation loss: 2.2377641409774793

Epoch: 6| Step: 8
Training loss: 0.41401376977310433
Validation loss: 2.184794041754342

Epoch: 6| Step: 9
Training loss: 0.2929569496321406
Validation loss: 2.1504594475302308

Epoch: 6| Step: 10
Training loss: 0.3940565823043349
Validation loss: 2.1782878807827957

Epoch: 6| Step: 11
Training loss: 0.2865768346456387
Validation loss: 2.1642485472314745

Epoch: 6| Step: 12
Training loss: 0.4117244712822952
Validation loss: 2.1806277195499084

Epoch: 6| Step: 13
Training loss: 0.18587168322068592
Validation loss: 2.2025897672564754

Epoch: 331| Step: 0
Training loss: 0.5068904722418178
Validation loss: 2.221322713284293

Epoch: 6| Step: 1
Training loss: 0.2228944407877529
Validation loss: 2.2882456285276134

Epoch: 6| Step: 2
Training loss: 0.34919002892756407
Validation loss: 2.2926697911806153

Epoch: 6| Step: 3
Training loss: 0.2117152094105069
Validation loss: 2.296745719114719

Epoch: 6| Step: 4
Training loss: 0.4196934455740161
Validation loss: 2.3433331803241693

Epoch: 6| Step: 5
Training loss: 0.34104360135779677
Validation loss: 2.367726683192397

Epoch: 6| Step: 6
Training loss: 0.3720734964069296
Validation loss: 2.4009107433419037

Epoch: 6| Step: 7
Training loss: 0.20150519968593666
Validation loss: 2.3938018689538367

Epoch: 6| Step: 8
Training loss: 0.31135391836878623
Validation loss: 2.409734180588584

Epoch: 6| Step: 9
Training loss: 0.328327547863917
Validation loss: 2.383469857370822

Epoch: 6| Step: 10
Training loss: 0.20963064429180084
Validation loss: 2.3909303042736143

Epoch: 6| Step: 11
Training loss: 0.40522923975394026
Validation loss: 2.345378300810732

Epoch: 6| Step: 12
Training loss: 0.36187397734344345
Validation loss: 2.3310066179455453

Epoch: 6| Step: 13
Training loss: 0.29597592991507954
Validation loss: 2.3578694834628724

Epoch: 332| Step: 0
Training loss: 0.3591563969705338
Validation loss: 2.316514112620892

Epoch: 6| Step: 1
Training loss: 0.2561064829986277
Validation loss: 2.3327262267329436

Epoch: 6| Step: 2
Training loss: 0.42784099904692324
Validation loss: 2.338209222367313

Epoch: 6| Step: 3
Training loss: 0.1490516131002173
Validation loss: 2.311020406341762

Epoch: 6| Step: 4
Training loss: 0.19659256127585822
Validation loss: 2.326761483325087

Epoch: 6| Step: 5
Training loss: 0.4003681641768357
Validation loss: 2.3337149403225887

Epoch: 6| Step: 6
Training loss: 0.46508635272875654
Validation loss: 2.3336489928298136

Epoch: 6| Step: 7
Training loss: 0.2391770051229167
Validation loss: 2.3264072707879553

Epoch: 6| Step: 8
Training loss: 0.3036394311067478
Validation loss: 2.3490131374418124

Epoch: 6| Step: 9
Training loss: 0.25653191619983573
Validation loss: 2.3313025640860534

Epoch: 6| Step: 10
Training loss: 0.2169673352641118
Validation loss: 2.334814797476174

Epoch: 6| Step: 11
Training loss: 0.13771884121988112
Validation loss: 2.3237210497891616

Epoch: 6| Step: 12
Training loss: 0.39383541724732196
Validation loss: 2.3481179862788197

Epoch: 6| Step: 13
Training loss: 0.41802856872889566
Validation loss: 2.3773299178347735

Epoch: 333| Step: 0
Training loss: 0.36274909964619956
Validation loss: 2.379364017583937

Epoch: 6| Step: 1
Training loss: 0.49430830752815574
Validation loss: 2.365790821317892

Epoch: 6| Step: 2
Training loss: 0.39703556327173317
Validation loss: 2.3880400382066

Epoch: 6| Step: 3
Training loss: 0.22536226223046474
Validation loss: 2.394597024972262

Epoch: 6| Step: 4
Training loss: 0.169956784663385
Validation loss: 2.3450072702960303

Epoch: 6| Step: 5
Training loss: 0.3641535428204429
Validation loss: 2.374733361009117

Epoch: 6| Step: 6
Training loss: 0.20125052386861347
Validation loss: 2.3124327523725703

Epoch: 6| Step: 7
Training loss: 0.28787108345945345
Validation loss: 2.3263250312087456

Epoch: 6| Step: 8
Training loss: 0.2600831407342369
Validation loss: 2.322300643903179

Epoch: 6| Step: 9
Training loss: 0.2507744951615963
Validation loss: 2.281194283050408

Epoch: 6| Step: 10
Training loss: 0.3410739774473213
Validation loss: 2.290780106453538

Epoch: 6| Step: 11
Training loss: 0.262954215624424
Validation loss: 2.32700309471503

Epoch: 6| Step: 12
Training loss: 0.261241149683988
Validation loss: 2.3152026486062884

Epoch: 6| Step: 13
Training loss: 0.2889878460133447
Validation loss: 2.2822047320510808

Epoch: 334| Step: 0
Training loss: 0.30134064810308653
Validation loss: 2.2823750431037086

Epoch: 6| Step: 1
Training loss: 0.19039431512424004
Validation loss: 2.2872565836764656

Epoch: 6| Step: 2
Training loss: 0.3032799143027245
Validation loss: 2.261319460251106

Epoch: 6| Step: 3
Training loss: 0.3369881589928858
Validation loss: 2.297134620247516

Epoch: 6| Step: 4
Training loss: 0.4956668609027871
Validation loss: 2.29296166494234

Epoch: 6| Step: 5
Training loss: 0.23154327476220601
Validation loss: 2.310832869687719

Epoch: 6| Step: 6
Training loss: 0.38283908518128185
Validation loss: 2.308598531709707

Epoch: 6| Step: 7
Training loss: 0.24049801820009847
Validation loss: 2.2986024766086577

Epoch: 6| Step: 8
Training loss: 0.2219267573231509
Validation loss: 2.300052160088035

Epoch: 6| Step: 9
Training loss: 0.3424006442764997
Validation loss: 2.291201377759889

Epoch: 6| Step: 10
Training loss: 0.33768955488354613
Validation loss: 2.2933064650696355

Epoch: 6| Step: 11
Training loss: 0.18275829718002098
Validation loss: 2.2869377114892675

Epoch: 6| Step: 12
Training loss: 0.18875682332166632
Validation loss: 2.291816415303553

Epoch: 6| Step: 13
Training loss: 0.42837019045901253
Validation loss: 2.2859755840878617

Epoch: 335| Step: 0
Training loss: 0.14729381716406953
Validation loss: 2.3175357375957146

Epoch: 6| Step: 1
Training loss: 0.22707046095355812
Validation loss: 2.2909399750475994

Epoch: 6| Step: 2
Training loss: 0.2526780869124503
Validation loss: 2.3362201164813157

Epoch: 6| Step: 3
Training loss: 0.15321265528992287
Validation loss: 2.3018393460790243

Epoch: 6| Step: 4
Training loss: 0.26969378173425523
Validation loss: 2.3377858802044225

Epoch: 6| Step: 5
Training loss: 0.4201467045231316
Validation loss: 2.325083597395808

Epoch: 6| Step: 6
Training loss: 0.40602538428322743
Validation loss: 2.3292729758109596

Epoch: 6| Step: 7
Training loss: 0.3392565686033435
Validation loss: 2.3244585533448907

Epoch: 6| Step: 8
Training loss: 0.3052395929379224
Validation loss: 2.35883778665402

Epoch: 6| Step: 9
Training loss: 0.2556074664111517
Validation loss: 2.3178575857363755

Epoch: 6| Step: 10
Training loss: 0.2632092550078497
Validation loss: 2.323115053722444

Epoch: 6| Step: 11
Training loss: 0.24905148516508718
Validation loss: 2.3159526945419757

Epoch: 6| Step: 12
Training loss: 0.40893942759935686
Validation loss: 2.308430053199799

Epoch: 6| Step: 13
Training loss: 0.24214145776492593
Validation loss: 2.3020879206910756

Epoch: 336| Step: 0
Training loss: 0.17711700909302577
Validation loss: 2.2848286167637917

Epoch: 6| Step: 1
Training loss: 0.20447977059311248
Validation loss: 2.3158081369312318

Epoch: 6| Step: 2
Training loss: 0.23396766551986573
Validation loss: 2.29817766488606

Epoch: 6| Step: 3
Training loss: 0.2652699818819303
Validation loss: 2.3234806914684083

Epoch: 6| Step: 4
Training loss: 0.16389666418367888
Validation loss: 2.3192685061779086

Epoch: 6| Step: 5
Training loss: 0.348431686814744
Validation loss: 2.308258791351843

Epoch: 6| Step: 6
Training loss: 0.1875375471667692
Validation loss: 2.297197368546386

Epoch: 6| Step: 7
Training loss: 0.28434882095901426
Validation loss: 2.3071428148760083

Epoch: 6| Step: 8
Training loss: 0.31047097964126935
Validation loss: 2.3044161178463716

Epoch: 6| Step: 9
Training loss: 0.31042508070165054
Validation loss: 2.292812620978845

Epoch: 6| Step: 10
Training loss: 0.4165398066836168
Validation loss: 2.2586427974309697

Epoch: 6| Step: 11
Training loss: 0.572838974511024
Validation loss: 2.2413235572377785

Epoch: 6| Step: 12
Training loss: 0.12966584605096848
Validation loss: 2.2944144040770733

Epoch: 6| Step: 13
Training loss: 0.13583621192316858
Validation loss: 2.321623091924547

Epoch: 337| Step: 0
Training loss: 0.3335635339064404
Validation loss: 2.350311713053313

Epoch: 6| Step: 1
Training loss: 0.36322708136212745
Validation loss: 2.3516319776208463

Epoch: 6| Step: 2
Training loss: 0.2744536727608791
Validation loss: 2.3327627128848563

Epoch: 6| Step: 3
Training loss: 0.2463637112562313
Validation loss: 2.301846440564445

Epoch: 6| Step: 4
Training loss: 0.24361055432410306
Validation loss: 2.3134284961606326

Epoch: 6| Step: 5
Training loss: 0.1718026030393503
Validation loss: 2.2987095198829635

Epoch: 6| Step: 6
Training loss: 0.19920760478838836
Validation loss: 2.2767346396950243

Epoch: 6| Step: 7
Training loss: 0.26366774944327437
Validation loss: 2.2816809256921493

Epoch: 6| Step: 8
Training loss: 0.32131429184757376
Validation loss: 2.294357890566384

Epoch: 6| Step: 9
Training loss: 0.36851498906022256
Validation loss: 2.2590634496640423

Epoch: 6| Step: 10
Training loss: 0.2292831280306315
Validation loss: 2.2796830276737436

Epoch: 6| Step: 11
Training loss: 0.2449274050317952
Validation loss: 2.2890335815309815

Epoch: 6| Step: 12
Training loss: 0.4966221195870014
Validation loss: 2.301504488224213

Epoch: 6| Step: 13
Training loss: 0.35397637621939865
Validation loss: 2.2996776147104465

Epoch: 338| Step: 0
Training loss: 0.25415524231661574
Validation loss: 2.3558077842250698

Epoch: 6| Step: 1
Training loss: 0.29047220171621224
Validation loss: 2.3363274201416244

Epoch: 6| Step: 2
Training loss: 0.21975317899771912
Validation loss: 2.317818533939226

Epoch: 6| Step: 3
Training loss: 0.20484457795639954
Validation loss: 2.3099767348889118

Epoch: 6| Step: 4
Training loss: 0.303669647648295
Validation loss: 2.308737919858761

Epoch: 6| Step: 5
Training loss: 0.10208557302424946
Validation loss: 2.3160078636505412

Epoch: 6| Step: 6
Training loss: 0.30796523008459137
Validation loss: 2.316157865575476

Epoch: 6| Step: 7
Training loss: 0.4480904050000238
Validation loss: 2.302149129749596

Epoch: 6| Step: 8
Training loss: 0.27636833325475424
Validation loss: 2.288434908095913

Epoch: 6| Step: 9
Training loss: 0.3384245804516021
Validation loss: 2.3532961104137273

Epoch: 6| Step: 10
Training loss: 0.1744996184608584
Validation loss: 2.3302299765592798

Epoch: 6| Step: 11
Training loss: 0.39457830771629804
Validation loss: 2.3026635773164292

Epoch: 6| Step: 12
Training loss: 0.2411429274585109
Validation loss: 2.3478397938298645

Epoch: 6| Step: 13
Training loss: 0.16067117974385836
Validation loss: 2.3153217596885267

Epoch: 339| Step: 0
Training loss: 0.2713507591053129
Validation loss: 2.324997539962224

Epoch: 6| Step: 1
Training loss: 0.19641781849503862
Validation loss: 2.3871915277273774

Epoch: 6| Step: 2
Training loss: 0.2167210489273527
Validation loss: 2.3429202015708426

Epoch: 6| Step: 3
Training loss: 0.42278372063987407
Validation loss: 2.32108584108251

Epoch: 6| Step: 4
Training loss: 0.30725432292948246
Validation loss: 2.358258074340077

Epoch: 6| Step: 5
Training loss: 0.23368262702082968
Validation loss: 2.349924131856178

Epoch: 6| Step: 6
Training loss: 0.1766729625406291
Validation loss: 2.3325762164949535

Epoch: 6| Step: 7
Training loss: 0.35998324047257385
Validation loss: 2.3323537155241385

Epoch: 6| Step: 8
Training loss: 0.3663943429081757
Validation loss: 2.351128642241866

Epoch: 6| Step: 9
Training loss: 0.19193521704103284
Validation loss: 2.323784006887528

Epoch: 6| Step: 10
Training loss: 0.3526881317546729
Validation loss: 2.264572709362755

Epoch: 6| Step: 11
Training loss: 0.3326941100507852
Validation loss: 2.2511495299400246

Epoch: 6| Step: 12
Training loss: 0.2056640519941858
Validation loss: 2.2447425748028413

Epoch: 6| Step: 13
Training loss: 0.09595536059527245
Validation loss: 2.2492175752848795

Epoch: 340| Step: 0
Training loss: 0.2928882233894405
Validation loss: 2.248575951731898

Epoch: 6| Step: 1
Training loss: 0.26460385386921514
Validation loss: 2.2240613388211594

Epoch: 6| Step: 2
Training loss: 0.17314438881736444
Validation loss: 2.256715745679244

Epoch: 6| Step: 3
Training loss: 0.4004333101175142
Validation loss: 2.2346380118981175

Epoch: 6| Step: 4
Training loss: 0.40773563903039617
Validation loss: 2.251181869748139

Epoch: 6| Step: 5
Training loss: 0.29143936235003387
Validation loss: 2.260793117453698

Epoch: 6| Step: 6
Training loss: 0.17997343698509882
Validation loss: 2.2998246665581257

Epoch: 6| Step: 7
Training loss: 0.24652571837739615
Validation loss: 2.2906814355373517

Epoch: 6| Step: 8
Training loss: 0.13448886510471914
Validation loss: 2.3132102715848477

Epoch: 6| Step: 9
Training loss: 0.32533462793615076
Validation loss: 2.3561886499997633

Epoch: 6| Step: 10
Training loss: 0.18163354921402788
Validation loss: 2.3330763306865228

Epoch: 6| Step: 11
Training loss: 0.40770694930605633
Validation loss: 2.3636632830363835

Epoch: 6| Step: 12
Training loss: 0.37009822424468014
Validation loss: 2.3642577924398562

Epoch: 6| Step: 13
Training loss: 0.3183905931390298
Validation loss: 2.3271048998434902

Epoch: 341| Step: 0
Training loss: 0.33184788072276333
Validation loss: 2.3276969184102594

Epoch: 6| Step: 1
Training loss: 0.41410920941305956
Validation loss: 2.32153723418583

Epoch: 6| Step: 2
Training loss: 0.2649110005384661
Validation loss: 2.3212656976140322

Epoch: 6| Step: 3
Training loss: 0.18136345830957726
Validation loss: 2.294558105123891

Epoch: 6| Step: 4
Training loss: 0.36904558845553215
Validation loss: 2.312744149908556

Epoch: 6| Step: 5
Training loss: 0.470642655789937
Validation loss: 2.320126328233472

Epoch: 6| Step: 6
Training loss: 0.16916644227509423
Validation loss: 2.2967046133562103

Epoch: 6| Step: 7
Training loss: 0.3106742213912248
Validation loss: 2.309621489944105

Epoch: 6| Step: 8
Training loss: 0.28477823990874346
Validation loss: 2.3336253408312655

Epoch: 6| Step: 9
Training loss: 0.21337365988560283
Validation loss: 2.311301363349083

Epoch: 6| Step: 10
Training loss: 0.2882376578435569
Validation loss: 2.3207421149350544

Epoch: 6| Step: 11
Training loss: 0.1451383354518941
Validation loss: 2.3584174451616375

Epoch: 6| Step: 12
Training loss: 0.1670847351880693
Validation loss: 2.328757187643966

Epoch: 6| Step: 13
Training loss: 0.13135813561366774
Validation loss: 2.352147375857664

Epoch: 342| Step: 0
Training loss: 0.2629703939185888
Validation loss: 2.3595634971359214

Epoch: 6| Step: 1
Training loss: 0.32107314069186255
Validation loss: 2.3741755908608626

Epoch: 6| Step: 2
Training loss: 0.3054274474999904
Validation loss: 2.3888166433699394

Epoch: 6| Step: 3
Training loss: 0.3421140670367497
Validation loss: 2.33554428434104

Epoch: 6| Step: 4
Training loss: 0.3927283687523076
Validation loss: 2.3470605714178125

Epoch: 6| Step: 5
Training loss: 0.37261440514004496
Validation loss: 2.331637720820868

Epoch: 6| Step: 6
Training loss: 0.3579284538390163
Validation loss: 2.335728914942977

Epoch: 6| Step: 7
Training loss: 0.1814950133747323
Validation loss: 2.3156136733554415

Epoch: 6| Step: 8
Training loss: 0.24111918198451815
Validation loss: 2.3105485881267565

Epoch: 6| Step: 9
Training loss: 0.20280649816981108
Validation loss: 2.3172356059257178

Epoch: 6| Step: 10
Training loss: 0.1925941700470426
Validation loss: 2.286706691236077

Epoch: 6| Step: 11
Training loss: 0.1889368770909617
Validation loss: 2.273042421864358

Epoch: 6| Step: 12
Training loss: 0.2575319526578531
Validation loss: 2.283063911621947

Epoch: 6| Step: 13
Training loss: 0.13522764150603464
Validation loss: 2.2529219303256878

Epoch: 343| Step: 0
Training loss: 0.20947134021976965
Validation loss: 2.2756297877703973

Epoch: 6| Step: 1
Training loss: 0.27330727882379163
Validation loss: 2.2848434095270114

Epoch: 6| Step: 2
Training loss: 0.25056715052669054
Validation loss: 2.3001240978249955

Epoch: 6| Step: 3
Training loss: 0.1832086501274583
Validation loss: 2.2955683192677165

Epoch: 6| Step: 4
Training loss: 0.3539524014593169
Validation loss: 2.3246250926936827

Epoch: 6| Step: 5
Training loss: 0.4323021148276944
Validation loss: 2.3286533586168723

Epoch: 6| Step: 6
Training loss: 0.24584829866122412
Validation loss: 2.32367259849259

Epoch: 6| Step: 7
Training loss: 0.3710173076399503
Validation loss: 2.3328711558108934

Epoch: 6| Step: 8
Training loss: 0.19365498074012036
Validation loss: 2.337207957522903

Epoch: 6| Step: 9
Training loss: 0.2548434055309669
Validation loss: 2.3384605163603682

Epoch: 6| Step: 10
Training loss: 0.1742777688084196
Validation loss: 2.310851742742957

Epoch: 6| Step: 11
Training loss: 0.15868873593944732
Validation loss: 2.2829195345050493

Epoch: 6| Step: 12
Training loss: 0.33576176726639523
Validation loss: 2.2948729564276578

Epoch: 6| Step: 13
Training loss: 0.39781622975557024
Validation loss: 2.2694921003194244

Epoch: 344| Step: 0
Training loss: 0.27772507846473016
Validation loss: 2.29137332936902

Epoch: 6| Step: 1
Training loss: 0.4773412501492886
Validation loss: 2.2756388318013

Epoch: 6| Step: 2
Training loss: 0.23096830570372795
Validation loss: 2.298842181984539

Epoch: 6| Step: 3
Training loss: 0.1453342811093501
Validation loss: 2.273895254800029

Epoch: 6| Step: 4
Training loss: 0.17044707502265216
Validation loss: 2.290898550257738

Epoch: 6| Step: 5
Training loss: 0.35730939669126366
Validation loss: 2.252215948633469

Epoch: 6| Step: 6
Training loss: 0.11866358715521977
Validation loss: 2.266108844875757

Epoch: 6| Step: 7
Training loss: 0.2641412442642079
Validation loss: 2.3243311739615917

Epoch: 6| Step: 8
Training loss: 0.21147153504664182
Validation loss: 2.325667126728726

Epoch: 6| Step: 9
Training loss: 0.29676553314196313
Validation loss: 2.3163441570825856

Epoch: 6| Step: 10
Training loss: 0.3191515422247107
Validation loss: 2.304223335790301

Epoch: 6| Step: 11
Training loss: 0.24638323938284568
Validation loss: 2.3123247068527886

Epoch: 6| Step: 12
Training loss: 0.2463738421848871
Validation loss: 2.3074393935635773

Epoch: 6| Step: 13
Training loss: 0.22437106219372008
Validation loss: 2.277391259191715

Epoch: 345| Step: 0
Training loss: 0.306955516006816
Validation loss: 2.28097301559778

Epoch: 6| Step: 1
Training loss: 0.1987150968937822
Validation loss: 2.26141111628864

Epoch: 6| Step: 2
Training loss: 0.27637884701777826
Validation loss: 2.2790142312575123

Epoch: 6| Step: 3
Training loss: 0.1199797953295357
Validation loss: 2.2429649077510665

Epoch: 6| Step: 4
Training loss: 0.27820458934283926
Validation loss: 2.212140413418906

Epoch: 6| Step: 5
Training loss: 0.15847973718582703
Validation loss: 2.2681583027886227

Epoch: 6| Step: 6
Training loss: 0.17665378396691545
Validation loss: 2.2231720944783744

Epoch: 6| Step: 7
Training loss: 0.287042610035025
Validation loss: 2.218583430765762

Epoch: 6| Step: 8
Training loss: 0.2629736804556613
Validation loss: 2.2253651670836962

Epoch: 6| Step: 9
Training loss: 0.4608797910093129
Validation loss: 2.2570373337664167

Epoch: 6| Step: 10
Training loss: 0.20582879145111907
Validation loss: 2.2185273244324817

Epoch: 6| Step: 11
Training loss: 0.1375843168876623
Validation loss: 2.2305625202026276

Epoch: 6| Step: 12
Training loss: 0.1392405762779592
Validation loss: 2.2518461599548947

Epoch: 6| Step: 13
Training loss: 0.46965051618336706
Validation loss: 2.2192280809037706

Epoch: 346| Step: 0
Training loss: 0.21788311236517272
Validation loss: 2.2364888723602823

Epoch: 6| Step: 1
Training loss: 0.29404924145928113
Validation loss: 2.274361531481176

Epoch: 6| Step: 2
Training loss: 0.16399143019352286
Validation loss: 2.2865525698400386

Epoch: 6| Step: 3
Training loss: 0.3573037249288483
Validation loss: 2.289403367358063

Epoch: 6| Step: 4
Training loss: 0.2356508812995326
Validation loss: 2.3043717629864995

Epoch: 6| Step: 5
Training loss: 0.3375339279075638
Validation loss: 2.2949745732463955

Epoch: 6| Step: 6
Training loss: 0.18065588649085648
Validation loss: 2.3486024940697643

Epoch: 6| Step: 7
Training loss: 0.09900139407178205
Validation loss: 2.3103390879360224

Epoch: 6| Step: 8
Training loss: 0.3541139839295588
Validation loss: 2.3153019138033195

Epoch: 6| Step: 9
Training loss: 0.26152519641424327
Validation loss: 2.324452794004521

Epoch: 6| Step: 10
Training loss: 0.3271290787620028
Validation loss: 2.333100522823179

Epoch: 6| Step: 11
Training loss: 0.3021884672234253
Validation loss: 2.314419467221438

Epoch: 6| Step: 12
Training loss: 0.12595109904015309
Validation loss: 2.300601705904629

Epoch: 6| Step: 13
Training loss: 0.21222762891338934
Validation loss: 2.304601030794174

Epoch: 347| Step: 0
Training loss: 0.20981918695377116
Validation loss: 2.2967197431871584

Epoch: 6| Step: 1
Training loss: 0.14695866413618205
Validation loss: 2.269720048658399

Epoch: 6| Step: 2
Training loss: 0.35591495720510796
Validation loss: 2.2739987892867513

Epoch: 6| Step: 3
Training loss: 0.2230526256989071
Validation loss: 2.294170795974218

Epoch: 6| Step: 4
Training loss: 0.2627014953566365
Validation loss: 2.28295069743643

Epoch: 6| Step: 5
Training loss: 0.13512224888757898
Validation loss: 2.295096411315635

Epoch: 6| Step: 6
Training loss: 0.14569511775087074
Validation loss: 2.299015441618188

Epoch: 6| Step: 7
Training loss: 0.16628852741100703
Validation loss: 2.2928842209389098

Epoch: 6| Step: 8
Training loss: 0.3544455673626166
Validation loss: 2.306761382901771

Epoch: 6| Step: 9
Training loss: 0.3726108659343394
Validation loss: 2.305995499218196

Epoch: 6| Step: 10
Training loss: 0.4837223085466868
Validation loss: 2.322186831089007

Epoch: 6| Step: 11
Training loss: 0.12400709254776157
Validation loss: 2.3130442564477356

Epoch: 6| Step: 12
Training loss: 0.13080153681648057
Validation loss: 2.3367347960320366

Epoch: 6| Step: 13
Training loss: 0.25005497923937176
Validation loss: 2.3287662598312413

Epoch: 348| Step: 0
Training loss: 0.19768277054434993
Validation loss: 2.334660372100747

Epoch: 6| Step: 1
Training loss: 0.26837525355465214
Validation loss: 2.342518833799246

Epoch: 6| Step: 2
Training loss: 0.2938397240067283
Validation loss: 2.34236538092992

Epoch: 6| Step: 3
Training loss: 0.3043821222776206
Validation loss: 2.329391984286457

Epoch: 6| Step: 4
Training loss: 0.16881262800345287
Validation loss: 2.2861351169500397

Epoch: 6| Step: 5
Training loss: 0.23006211793458983
Validation loss: 2.302883602838974

Epoch: 6| Step: 6
Training loss: 0.2413722591481593
Validation loss: 2.3066816437190156

Epoch: 6| Step: 7
Training loss: 0.2010718161618655
Validation loss: 2.3232981826850985

Epoch: 6| Step: 8
Training loss: 0.21072957599510256
Validation loss: 2.2938027689359637

Epoch: 6| Step: 9
Training loss: 0.32437777927802997
Validation loss: 2.287241336886907

Epoch: 6| Step: 10
Training loss: 0.2881900017496765
Validation loss: 2.302935995330819

Epoch: 6| Step: 11
Training loss: 0.2793820391371958
Validation loss: 2.3084918149687135

Epoch: 6| Step: 12
Training loss: 0.34608996025404426
Validation loss: 2.309936106522271

Epoch: 6| Step: 13
Training loss: 0.14827305694753143
Validation loss: 2.28812015602344

Epoch: 349| Step: 0
Training loss: 0.32737413279027805
Validation loss: 2.305459653365687

Epoch: 6| Step: 1
Training loss: 0.3363369407783277
Validation loss: 2.3110699376617907

Epoch: 6| Step: 2
Training loss: 0.34150562411392466
Validation loss: 2.293256246012131

Epoch: 6| Step: 3
Training loss: 0.1711922980120467
Validation loss: 2.278256820357262

Epoch: 6| Step: 4
Training loss: 0.263287992419382
Validation loss: 2.2772262245446613

Epoch: 6| Step: 5
Training loss: 0.29307781732417676
Validation loss: 2.2893504529636566

Epoch: 6| Step: 6
Training loss: 0.24086341843380196
Validation loss: 2.241967767472833

Epoch: 6| Step: 7
Training loss: 0.17572442301792357
Validation loss: 2.2307792191616924

Epoch: 6| Step: 8
Training loss: 0.21409183182899005
Validation loss: 2.2526075209612144

Epoch: 6| Step: 9
Training loss: 0.0816301519347522
Validation loss: 2.255157320831114

Epoch: 6| Step: 10
Training loss: 0.198335860347143
Validation loss: 2.2897017489068694

Epoch: 6| Step: 11
Training loss: 0.4222991541873213
Validation loss: 2.26421176962384

Epoch: 6| Step: 12
Training loss: 0.2735161531950474
Validation loss: 2.280666421642871

Epoch: 6| Step: 13
Training loss: 0.2724011536778234
Validation loss: 2.30933231571468

Epoch: 350| Step: 0
Training loss: 0.1833998589668803
Validation loss: 2.294543324713178

Epoch: 6| Step: 1
Training loss: 0.4613281308141025
Validation loss: 2.2627293485046582

Epoch: 6| Step: 2
Training loss: 0.2135844866146852
Validation loss: 2.309630256573356

Epoch: 6| Step: 3
Training loss: 0.30367801401946565
Validation loss: 2.282729505055682

Epoch: 6| Step: 4
Training loss: 0.15962809610202078
Validation loss: 2.2873667390755714

Epoch: 6| Step: 5
Training loss: 0.20713526434089854
Validation loss: 2.312351368365509

Epoch: 6| Step: 6
Training loss: 0.27608169259478954
Validation loss: 2.2972009084519867

Epoch: 6| Step: 7
Training loss: 0.16887072752489998
Validation loss: 2.3013353889942714

Epoch: 6| Step: 8
Training loss: 0.3364058711523323
Validation loss: 2.30770566496416

Epoch: 6| Step: 9
Training loss: 0.1002369353635607
Validation loss: 2.2762920654617327

Epoch: 6| Step: 10
Training loss: 0.28642822743205937
Validation loss: 2.2632026608284903

Epoch: 6| Step: 11
Training loss: 0.17365902272698885
Validation loss: 2.285001813102874

Epoch: 6| Step: 12
Training loss: 0.33610678998194166
Validation loss: 2.2584204806305714

Epoch: 6| Step: 13
Training loss: 0.2010849329653857
Validation loss: 2.2595636958597427

Epoch: 351| Step: 0
Training loss: 0.23782982041323736
Validation loss: 2.255901200016368

Epoch: 6| Step: 1
Training loss: 0.16444711787472266
Validation loss: 2.219608568860478

Epoch: 6| Step: 2
Training loss: 0.3112915515357358
Validation loss: 2.2364830194511196

Epoch: 6| Step: 3
Training loss: 0.26054819441293986
Validation loss: 2.221089994196745

Epoch: 6| Step: 4
Training loss: 0.14910819966567435
Validation loss: 2.2453196682888605

Epoch: 6| Step: 5
Training loss: 0.3819417197197721
Validation loss: 2.2354945900140724

Epoch: 6| Step: 6
Training loss: 0.3249846225548489
Validation loss: 2.2456070664544243

Epoch: 6| Step: 7
Training loss: 0.17571729980255665
Validation loss: 2.268272322541371

Epoch: 6| Step: 8
Training loss: 0.15835763309275394
Validation loss: 2.291695957798365

Epoch: 6| Step: 9
Training loss: 0.3345609005541154
Validation loss: 2.3047329405428845

Epoch: 6| Step: 10
Training loss: 0.2067284348800482
Validation loss: 2.277150886544692

Epoch: 6| Step: 11
Training loss: 0.37264031830006905
Validation loss: 2.3021562756187377

Epoch: 6| Step: 12
Training loss: 0.12702953533362019
Validation loss: 2.3367720511860557

Epoch: 6| Step: 13
Training loss: 0.12010533189029113
Validation loss: 2.3329375110018358

Epoch: 352| Step: 0
Training loss: 0.2127653505803011
Validation loss: 2.3388164099516833

Epoch: 6| Step: 1
Training loss: 0.36920532789787597
Validation loss: 2.333773220659072

Epoch: 6| Step: 2
Training loss: 0.3737827253527037
Validation loss: 2.339638628393103

Epoch: 6| Step: 3
Training loss: 0.2638841269227969
Validation loss: 2.3020057260526854

Epoch: 6| Step: 4
Training loss: 0.23575784904585123
Validation loss: 2.322112164618454

Epoch: 6| Step: 5
Training loss: 0.19663424530410595
Validation loss: 2.2788992758349775

Epoch: 6| Step: 6
Training loss: 0.11351334702791459
Validation loss: 2.2851092946294553

Epoch: 6| Step: 7
Training loss: 0.15869596034631236
Validation loss: 2.2683419722437868

Epoch: 6| Step: 8
Training loss: 0.1856497429242089
Validation loss: 2.2885947881679516

Epoch: 6| Step: 9
Training loss: 0.17490926203844281
Validation loss: 2.2763667820686107

Epoch: 6| Step: 10
Training loss: 0.25111560458185306
Validation loss: 2.2978897091211556

Epoch: 6| Step: 11
Training loss: 0.4310063323332414
Validation loss: 2.271807844673049

Epoch: 6| Step: 12
Training loss: 0.1599889206775601
Validation loss: 2.2698425957100614

Epoch: 6| Step: 13
Training loss: 0.2566207158046488
Validation loss: 2.2866825951774525

Epoch: 353| Step: 0
Training loss: 0.22989607637395718
Validation loss: 2.2863584177939376

Epoch: 6| Step: 1
Training loss: 0.2341959428275777
Validation loss: 2.277538275422221

Epoch: 6| Step: 2
Training loss: 0.1470276992482613
Validation loss: 2.2870352570786245

Epoch: 6| Step: 3
Training loss: 0.27124809027144575
Validation loss: 2.303115090303374

Epoch: 6| Step: 4
Training loss: 0.2792627807294769
Validation loss: 2.3072012614128843

Epoch: 6| Step: 5
Training loss: 0.22587203177394913
Validation loss: 2.3417497060688324

Epoch: 6| Step: 6
Training loss: 0.19197096527873145
Validation loss: 2.314959290657098

Epoch: 6| Step: 7
Training loss: 0.22449999924279535
Validation loss: 2.3382824840172165

Epoch: 6| Step: 8
Training loss: 0.26465070378645794
Validation loss: 2.3009525859742808

Epoch: 6| Step: 9
Training loss: 0.4064901632395035
Validation loss: 2.314644294688329

Epoch: 6| Step: 10
Training loss: 0.12775822425570185
Validation loss: 2.29864240637719

Epoch: 6| Step: 11
Training loss: 0.20233210452823183
Validation loss: 2.287335536838063

Epoch: 6| Step: 12
Training loss: 0.2444345993161521
Validation loss: 2.3157919257070505

Epoch: 6| Step: 13
Training loss: 0.4057507932364936
Validation loss: 2.2885145425877598

Epoch: 354| Step: 0
Training loss: 0.1287838036409646
Validation loss: 2.312951607855377

Epoch: 6| Step: 1
Training loss: 0.25492862859647897
Validation loss: 2.2727330305356563

Epoch: 6| Step: 2
Training loss: 0.19765997645668718
Validation loss: 2.3131673105580703

Epoch: 6| Step: 3
Training loss: 0.15488281538627785
Validation loss: 2.3054391560224192

Epoch: 6| Step: 4
Training loss: 0.21786249161738372
Validation loss: 2.269844877168472

Epoch: 6| Step: 5
Training loss: 0.26490728803302793
Validation loss: 2.294389092837943

Epoch: 6| Step: 6
Training loss: 0.1294980840361745
Validation loss: 2.290286277292341

Epoch: 6| Step: 7
Training loss: 0.36344208797271543
Validation loss: 2.314145286409567

Epoch: 6| Step: 8
Training loss: 0.2845296114560688
Validation loss: 2.3076825024888445

Epoch: 6| Step: 9
Training loss: 0.1393016029407058
Validation loss: 2.27472165807607

Epoch: 6| Step: 10
Training loss: 0.18306849805800182
Validation loss: 2.294863507277587

Epoch: 6| Step: 11
Training loss: 0.44760157532534056
Validation loss: 2.2968367985767335

Epoch: 6| Step: 12
Training loss: 0.18597944932446586
Validation loss: 2.2815687693211952

Epoch: 6| Step: 13
Training loss: 0.20161741417983575
Validation loss: 2.304867551683365

Epoch: 355| Step: 0
Training loss: 0.2706581827043379
Validation loss: 2.27835298339871

Epoch: 6| Step: 1
Training loss: 0.2071981297293505
Validation loss: 2.279999461430312

Epoch: 6| Step: 2
Training loss: 0.3180289279500254
Validation loss: 2.2819503336256637

Epoch: 6| Step: 3
Training loss: 0.12354935123475119
Validation loss: 2.252023476923847

Epoch: 6| Step: 4
Training loss: 0.22494983577476385
Validation loss: 2.305565445359805

Epoch: 6| Step: 5
Training loss: 0.276773659327136
Validation loss: 2.2901003551547756

Epoch: 6| Step: 6
Training loss: 0.16116270308254318
Validation loss: 2.298389366701448

Epoch: 6| Step: 7
Training loss: 0.3332602475430127
Validation loss: 2.28179787510008

Epoch: 6| Step: 8
Training loss: 0.38067710623160667
Validation loss: 2.297735637154655

Epoch: 6| Step: 9
Training loss: 0.21635761954010768
Validation loss: 2.314399433599243

Epoch: 6| Step: 10
Training loss: 0.11091362602275366
Validation loss: 2.2949096651435377

Epoch: 6| Step: 11
Training loss: 0.2613926891861307
Validation loss: 2.3035659277358818

Epoch: 6| Step: 12
Training loss: 0.14363963669331417
Validation loss: 2.2679041955849715

Epoch: 6| Step: 13
Training loss: 0.17391320086158168
Validation loss: 2.2654019685527977

Epoch: 356| Step: 0
Training loss: 0.3323806943387715
Validation loss: 2.2703501055590647

Epoch: 6| Step: 1
Training loss: 0.1449871476618783
Validation loss: 2.2528907511540806

Epoch: 6| Step: 2
Training loss: 0.1401761760389858
Validation loss: 2.2362539472975995

Epoch: 6| Step: 3
Training loss: 0.25666974859018105
Validation loss: 2.2134730425529625

Epoch: 6| Step: 4
Training loss: 0.4367058903911201
Validation loss: 2.242677181853571

Epoch: 6| Step: 5
Training loss: 0.14811280777807723
Validation loss: 2.2371536636258047

Epoch: 6| Step: 6
Training loss: 0.1645540469154024
Validation loss: 2.2473503631686755

Epoch: 6| Step: 7
Training loss: 0.13419320678346927
Validation loss: 2.2688881712034465

Epoch: 6| Step: 8
Training loss: 0.2520705548244927
Validation loss: 2.252539191493555

Epoch: 6| Step: 9
Training loss: 0.2182156644360198
Validation loss: 2.3096471381793275

Epoch: 6| Step: 10
Training loss: 0.38462187894510097
Validation loss: 2.3282864257188396

Epoch: 6| Step: 11
Training loss: 0.1622278286291802
Validation loss: 2.336489683055248

Epoch: 6| Step: 12
Training loss: 0.2337571583636048
Validation loss: 2.3002967345897147

Epoch: 6| Step: 13
Training loss: 0.24086262191281577
Validation loss: 2.294519067941204

Epoch: 357| Step: 0
Training loss: 0.19377148186127016
Validation loss: 2.288100394365486

Epoch: 6| Step: 1
Training loss: 0.28676492438768314
Validation loss: 2.2641680504227253

Epoch: 6| Step: 2
Training loss: 0.3170857374314858
Validation loss: 2.2266033791324706

Epoch: 6| Step: 3
Training loss: 0.21550023608902835
Validation loss: 2.235014811742454

Epoch: 6| Step: 4
Training loss: 0.27631021727952365
Validation loss: 2.212168474168779

Epoch: 6| Step: 5
Training loss: 0.33198915102479304
Validation loss: 2.18281379257071

Epoch: 6| Step: 6
Training loss: 0.2840385479790593
Validation loss: 2.1754423521798962

Epoch: 6| Step: 7
Training loss: 0.27940211947448884
Validation loss: 2.170353189651862

Epoch: 6| Step: 8
Training loss: 0.20897835874364878
Validation loss: 2.214634595952228

Epoch: 6| Step: 9
Training loss: 0.2590659909076421
Validation loss: 2.186798934985465

Epoch: 6| Step: 10
Training loss: 0.40705959638710615
Validation loss: 2.202459667300664

Epoch: 6| Step: 11
Training loss: 0.0928246607664584
Validation loss: 2.254748280279694

Epoch: 6| Step: 12
Training loss: 0.29602786969341177
Validation loss: 2.272034186353504

Epoch: 6| Step: 13
Training loss: 0.11482223257263452
Validation loss: 2.30727984486187

Epoch: 358| Step: 0
Training loss: 0.26542578968725755
Validation loss: 2.2858330594408676

Epoch: 6| Step: 1
Training loss: 0.3172745974994968
Validation loss: 2.3223561352316424

Epoch: 6| Step: 2
Training loss: 0.32574772239161087
Validation loss: 2.310967006815437

Epoch: 6| Step: 3
Training loss: 0.15423943862973516
Validation loss: 2.3167745344513704

Epoch: 6| Step: 4
Training loss: 0.35482375346875755
Validation loss: 2.288713470518915

Epoch: 6| Step: 5
Training loss: 0.27210900605949123
Validation loss: 2.3122495678052437

Epoch: 6| Step: 6
Training loss: 0.1941136281913129
Validation loss: 2.2807394589476466

Epoch: 6| Step: 7
Training loss: 0.32030489377550825
Validation loss: 2.276570345716387

Epoch: 6| Step: 8
Training loss: 0.2394003307396015
Validation loss: 2.2759255837479935

Epoch: 6| Step: 9
Training loss: 0.12332118581124898
Validation loss: 2.2599623276293754

Epoch: 6| Step: 10
Training loss: 0.22208639470818003
Validation loss: 2.2890696282048126

Epoch: 6| Step: 11
Training loss: 0.20062762777146526
Validation loss: 2.2493325466044465

Epoch: 6| Step: 12
Training loss: 0.07344957554231514
Validation loss: 2.2677624728130086

Epoch: 6| Step: 13
Training loss: 0.41403926928148826
Validation loss: 2.2312923685317765

Epoch: 359| Step: 0
Training loss: 0.20172792270527282
Validation loss: 2.243300687077007

Epoch: 6| Step: 1
Training loss: 0.12332489756729353
Validation loss: 2.221899927602694

Epoch: 6| Step: 2
Training loss: 0.2404403113985909
Validation loss: 2.195601759743979

Epoch: 6| Step: 3
Training loss: 0.32704854550399054
Validation loss: 2.1874422713249264

Epoch: 6| Step: 4
Training loss: 0.2125176653812081
Validation loss: 2.183670552424346

Epoch: 6| Step: 5
Training loss: 0.4286899257368262
Validation loss: 2.2086331339478322

Epoch: 6| Step: 6
Training loss: 0.20725499065105485
Validation loss: 2.2291497279817323

Epoch: 6| Step: 7
Training loss: 0.1508023830289718
Validation loss: 2.2243041183505645

Epoch: 6| Step: 8
Training loss: 0.2760506154655141
Validation loss: 2.2938848518152786

Epoch: 6| Step: 9
Training loss: 0.18219816103082043
Validation loss: 2.302226010431159

Epoch: 6| Step: 10
Training loss: 0.41264870231916173
Validation loss: 2.295442635843016

Epoch: 6| Step: 11
Training loss: 0.1630335740868296
Validation loss: 2.3167066097320363

Epoch: 6| Step: 12
Training loss: 0.28088153438666186
Validation loss: 2.277607820737923

Epoch: 6| Step: 13
Training loss: 0.2278598276277813
Validation loss: 2.330670219900103

Epoch: 360| Step: 0
Training loss: 0.27349224904861386
Validation loss: 2.3152980954148976

Epoch: 6| Step: 1
Training loss: 0.2636029188622589
Validation loss: 2.3122929383631945

Epoch: 6| Step: 2
Training loss: 0.2203532289503867
Validation loss: 2.3137788858615673

Epoch: 6| Step: 3
Training loss: 0.1770841000110261
Validation loss: 2.299438803611

Epoch: 6| Step: 4
Training loss: 0.17852480633119774
Validation loss: 2.2743378806293872

Epoch: 6| Step: 5
Training loss: 0.22837540000312573
Validation loss: 2.27113026968104

Epoch: 6| Step: 6
Training loss: 0.22534618600722367
Validation loss: 2.2550895671202102

Epoch: 6| Step: 7
Training loss: 0.3893518873001686
Validation loss: 2.285000695647876

Epoch: 6| Step: 8
Training loss: 0.26732379771991194
Validation loss: 2.2575033982363686

Epoch: 6| Step: 9
Training loss: 0.1522509096373709
Validation loss: 2.2628130329840896

Epoch: 6| Step: 10
Training loss: 0.4139159861046332
Validation loss: 2.2991801404387786

Epoch: 6| Step: 11
Training loss: 0.41712990481105344
Validation loss: 2.2805986799291156

Epoch: 6| Step: 12
Training loss: 0.16686168947962454
Validation loss: 2.2612454334619407

Epoch: 6| Step: 13
Training loss: 0.16958760674018394
Validation loss: 2.2456230126124996

Epoch: 361| Step: 0
Training loss: 0.33517041343159387
Validation loss: 2.2748340697629708

Epoch: 6| Step: 1
Training loss: 0.28059152503320506
Validation loss: 2.2400818520094403

Epoch: 6| Step: 2
Training loss: 0.2384042578706603
Validation loss: 2.2157090877379306

Epoch: 6| Step: 3
Training loss: 0.387063287172113
Validation loss: 2.2002345638297633

Epoch: 6| Step: 4
Training loss: 0.35782446362347214
Validation loss: 2.2064268837761367

Epoch: 6| Step: 5
Training loss: 0.35789568821078255
Validation loss: 2.210457558151358

Epoch: 6| Step: 6
Training loss: 0.22157608669842627
Validation loss: 2.203359774791001

Epoch: 6| Step: 7
Training loss: 0.18103412153355963
Validation loss: 2.261270610052602

Epoch: 6| Step: 8
Training loss: 0.1703901415769496
Validation loss: 2.24695954844406

Epoch: 6| Step: 9
Training loss: 0.2462287865374982
Validation loss: 2.279157324039908

Epoch: 6| Step: 10
Training loss: 0.3654780059790514
Validation loss: 2.289945869938081

Epoch: 6| Step: 11
Training loss: 0.2505544236809125
Validation loss: 2.332446016044956

Epoch: 6| Step: 12
Training loss: 0.14819632563379678
Validation loss: 2.352865161720099

Epoch: 6| Step: 13
Training loss: 0.23208792922185262
Validation loss: 2.320546877216585

Epoch: 362| Step: 0
Training loss: 0.12273619045223684
Validation loss: 2.3340074368222794

Epoch: 6| Step: 1
Training loss: 0.20523827067360073
Validation loss: 2.3500788212894728

Epoch: 6| Step: 2
Training loss: 0.15675138852464213
Validation loss: 2.316478546684974

Epoch: 6| Step: 3
Training loss: 0.22943219963254835
Validation loss: 2.310978639291352

Epoch: 6| Step: 4
Training loss: 0.3203318752848746
Validation loss: 2.294119953843161

Epoch: 6| Step: 5
Training loss: 0.15684649929525982
Validation loss: 2.3399509389835353

Epoch: 6| Step: 6
Training loss: 0.13377012689619083
Validation loss: 2.2791642461686905

Epoch: 6| Step: 7
Training loss: 0.28741507571681396
Validation loss: 2.3047050195928045

Epoch: 6| Step: 8
Training loss: 0.3222372562753348
Validation loss: 2.302419910057654

Epoch: 6| Step: 9
Training loss: 0.3098500909892268
Validation loss: 2.2937852823085967

Epoch: 6| Step: 10
Training loss: 0.25797289858277406
Validation loss: 2.2930979978683634

Epoch: 6| Step: 11
Training loss: 0.30792605924325805
Validation loss: 2.30168511302082

Epoch: 6| Step: 12
Training loss: 0.19423605877816438
Validation loss: 2.2930636839711815

Epoch: 6| Step: 13
Training loss: 0.2209641592406389
Validation loss: 2.2655921732809037

Epoch: 363| Step: 0
Training loss: 0.17789648858057772
Validation loss: 2.2912622253375745

Epoch: 6| Step: 1
Training loss: 0.1843098311096818
Validation loss: 2.2937617110270025

Epoch: 6| Step: 2
Training loss: 0.25303460673512773
Validation loss: 2.2792842063358774

Epoch: 6| Step: 3
Training loss: 0.11582707872616761
Validation loss: 2.288585787495085

Epoch: 6| Step: 4
Training loss: 0.2935526306526983
Validation loss: 2.3006190510182063

Epoch: 6| Step: 5
Training loss: 0.26558255810220993
Validation loss: 2.2800506178676163

Epoch: 6| Step: 6
Training loss: 0.2571168820662546
Validation loss: 2.2521166294070296

Epoch: 6| Step: 7
Training loss: 0.1509356284074866
Validation loss: 2.276850171680614

Epoch: 6| Step: 8
Training loss: 0.24333446920197285
Validation loss: 2.2721724959220215

Epoch: 6| Step: 9
Training loss: 0.3085073036120677
Validation loss: 2.27819438591047

Epoch: 6| Step: 10
Training loss: 0.2023950813608014
Validation loss: 2.2825432473346554

Epoch: 6| Step: 11
Training loss: 0.23986192845594473
Validation loss: 2.259801241465086

Epoch: 6| Step: 12
Training loss: 0.37544528035357166
Validation loss: 2.307156245059938

Epoch: 6| Step: 13
Training loss: 0.2531777273997956
Validation loss: 2.2728205395790564

Epoch: 364| Step: 0
Training loss: 0.22546534597162834
Validation loss: 2.292805345357658

Epoch: 6| Step: 1
Training loss: 0.2976862213985096
Validation loss: 2.3020666382881685

Epoch: 6| Step: 2
Training loss: 0.3443440592690247
Validation loss: 2.3391876574549446

Epoch: 6| Step: 3
Training loss: 0.35525630009921744
Validation loss: 2.2895520829164298

Epoch: 6| Step: 4
Training loss: 0.24045991002640432
Validation loss: 2.304010751349008

Epoch: 6| Step: 5
Training loss: 0.21472634662286302
Validation loss: 2.3071643576909797

Epoch: 6| Step: 6
Training loss: 0.14683113381539484
Validation loss: 2.319221285012806

Epoch: 6| Step: 7
Training loss: 0.19590176382692276
Validation loss: 2.3167239250091485

Epoch: 6| Step: 8
Training loss: 0.22764117687807015
Validation loss: 2.300027504979869

Epoch: 6| Step: 9
Training loss: 0.1136729440278323
Validation loss: 2.3023848894091015

Epoch: 6| Step: 10
Training loss: 0.21422599062379508
Validation loss: 2.356446067521263

Epoch: 6| Step: 11
Training loss: 0.2654412559699831
Validation loss: 2.345070808169491

Epoch: 6| Step: 12
Training loss: 0.1999892220722282
Validation loss: 2.3484255766330353

Epoch: 6| Step: 13
Training loss: 0.08174030046236341
Validation loss: 2.3412006056989254

Epoch: 365| Step: 0
Training loss: 0.14515103372865407
Validation loss: 2.315872774793623

Epoch: 6| Step: 1
Training loss: 0.18761498184067174
Validation loss: 2.3064171636980277

Epoch: 6| Step: 2
Training loss: 0.23820771192598944
Validation loss: 2.3198054424512873

Epoch: 6| Step: 3
Training loss: 0.15442618251321225
Validation loss: 2.303459465730389

Epoch: 6| Step: 4
Training loss: 0.3514487400377509
Validation loss: 2.2893300633476854

Epoch: 6| Step: 5
Training loss: 0.21183208338969983
Validation loss: 2.3166186221117555

Epoch: 6| Step: 6
Training loss: 0.16906721204618239
Validation loss: 2.2817562393958517

Epoch: 6| Step: 7
Training loss: 0.35022189650556407
Validation loss: 2.329845996764038

Epoch: 6| Step: 8
Training loss: 0.1846103221176461
Validation loss: 2.316956795857765

Epoch: 6| Step: 9
Training loss: 0.3394192093739813
Validation loss: 2.3406527469676615

Epoch: 6| Step: 10
Training loss: 0.17963113107949097
Validation loss: 2.3136630183762126

Epoch: 6| Step: 11
Training loss: 0.18737550417047813
Validation loss: 2.335028142371042

Epoch: 6| Step: 12
Training loss: 0.1737296168202981
Validation loss: 2.3497981329279036

Epoch: 6| Step: 13
Training loss: 0.3903382011424135
Validation loss: 2.348090137946736

Epoch: 366| Step: 0
Training loss: 0.1680072141564399
Validation loss: 2.2939658890758348

Epoch: 6| Step: 1
Training loss: 0.24625265955093925
Validation loss: 2.3245956715031895

Epoch: 6| Step: 2
Training loss: 0.29135117611232797
Validation loss: 2.3226797414483618

Epoch: 6| Step: 3
Training loss: 0.19650817143033586
Validation loss: 2.3325993109231726

Epoch: 6| Step: 4
Training loss: 0.15408851945455818
Validation loss: 2.312634418442144

Epoch: 6| Step: 5
Training loss: 0.2914924172033505
Validation loss: 2.306794805122509

Epoch: 6| Step: 6
Training loss: 0.3441804877932021
Validation loss: 2.280577675862823

Epoch: 6| Step: 7
Training loss: 0.20831359630711696
Validation loss: 2.279944790000967

Epoch: 6| Step: 8
Training loss: 0.24027717023073195
Validation loss: 2.285492416741623

Epoch: 6| Step: 9
Training loss: 0.3123986437460085
Validation loss: 2.27591890183419

Epoch: 6| Step: 10
Training loss: 0.28832919954816927
Validation loss: 2.258128388258868

Epoch: 6| Step: 11
Training loss: 0.12164105281129846
Validation loss: 2.2985732844552653

Epoch: 6| Step: 12
Training loss: 0.16943302209411398
Validation loss: 2.318427162835647

Epoch: 6| Step: 13
Training loss: 0.246245405606916
Validation loss: 2.3439266408990154

Epoch: 367| Step: 0
Training loss: 0.1831810858673086
Validation loss: 2.3024547475697115

Epoch: 6| Step: 1
Training loss: 0.09704779856998876
Validation loss: 2.323992858757634

Epoch: 6| Step: 2
Training loss: 0.2088278870843459
Validation loss: 2.3485096130265872

Epoch: 6| Step: 3
Training loss: 0.18656924818604417
Validation loss: 2.3106475179328148

Epoch: 6| Step: 4
Training loss: 0.4276599558013592
Validation loss: 2.286852668033668

Epoch: 6| Step: 5
Training loss: 0.16272253676532653
Validation loss: 2.316608417296874

Epoch: 6| Step: 6
Training loss: 0.1318070697968214
Validation loss: 2.2802312286799578

Epoch: 6| Step: 7
Training loss: 0.15755684440817236
Validation loss: 2.260685031823687

Epoch: 6| Step: 8
Training loss: 0.26462550609379853
Validation loss: 2.267233760357234

Epoch: 6| Step: 9
Training loss: 0.13875559844931135
Validation loss: 2.280821079596183

Epoch: 6| Step: 10
Training loss: 0.323025495382153
Validation loss: 2.273435073297004

Epoch: 6| Step: 11
Training loss: 0.3633374816689795
Validation loss: 2.313941604886057

Epoch: 6| Step: 12
Training loss: 0.17808331830072704
Validation loss: 2.3112956602349373

Epoch: 6| Step: 13
Training loss: 0.27255128572535475
Validation loss: 2.316409275802974

Epoch: 368| Step: 0
Training loss: 0.16576526500962338
Validation loss: 2.3053179802301

Epoch: 6| Step: 1
Training loss: 0.3057365940801277
Validation loss: 2.3321420661742818

Epoch: 6| Step: 2
Training loss: 0.20138993527882315
Validation loss: 2.3377856619789146

Epoch: 6| Step: 3
Training loss: 0.35215143042724373
Validation loss: 2.3180927773984936

Epoch: 6| Step: 4
Training loss: 0.12792964382025285
Validation loss: 2.347571164185774

Epoch: 6| Step: 5
Training loss: 0.16915868504158313
Validation loss: 2.305561317294649

Epoch: 6| Step: 6
Training loss: 0.1805997785693086
Validation loss: 2.3335004695752284

Epoch: 6| Step: 7
Training loss: 0.15022851207479274
Validation loss: 2.338740182369297

Epoch: 6| Step: 8
Training loss: 0.13779091728732623
Validation loss: 2.2896369589280194

Epoch: 6| Step: 9
Training loss: 0.30132723461253974
Validation loss: 2.3276337091942096

Epoch: 6| Step: 10
Training loss: 0.26331347373023584
Validation loss: 2.314439990261349

Epoch: 6| Step: 11
Training loss: 0.28433552300315146
Validation loss: 2.3187011999747513

Epoch: 6| Step: 12
Training loss: 0.25293644781909475
Validation loss: 2.290604895418016

Epoch: 6| Step: 13
Training loss: 0.28528087975558114
Validation loss: 2.3250019295770774

Epoch: 369| Step: 0
Training loss: 0.28688240162228984
Validation loss: 2.3321254826133164

Epoch: 6| Step: 1
Training loss: 0.22050281312882364
Validation loss: 2.3188501188984056

Epoch: 6| Step: 2
Training loss: 0.16193966427302356
Validation loss: 2.351480819662126

Epoch: 6| Step: 3
Training loss: 0.22983137996017305
Validation loss: 2.3316001038008745

Epoch: 6| Step: 4
Training loss: 0.21728242165205566
Validation loss: 2.3418638191116172

Epoch: 6| Step: 5
Training loss: 0.1716344461296877
Validation loss: 2.3412493364704705

Epoch: 6| Step: 6
Training loss: 0.254747449805024
Validation loss: 2.333618494560102

Epoch: 6| Step: 7
Training loss: 0.39641079901166504
Validation loss: 2.331625256831433

Epoch: 6| Step: 8
Training loss: 0.1688238600404457
Validation loss: 2.359904366156825

Epoch: 6| Step: 9
Training loss: 0.2325386827729462
Validation loss: 2.363128497167641

Epoch: 6| Step: 10
Training loss: 0.13568216135573916
Validation loss: 2.355591600741069

Epoch: 6| Step: 11
Training loss: 0.19634459549793012
Validation loss: 2.3611472387845405

Epoch: 6| Step: 12
Training loss: 0.3457794213020382
Validation loss: 2.3434315465794318

Epoch: 6| Step: 13
Training loss: 0.15762912558496692
Validation loss: 2.334689901444202

Epoch: 370| Step: 0
Training loss: 0.2409151247967686
Validation loss: 2.294724444936484

Epoch: 6| Step: 1
Training loss: 0.1924197553610052
Validation loss: 2.276330847609426

Epoch: 6| Step: 2
Training loss: 0.34141050026209885
Validation loss: 2.2506039924232444

Epoch: 6| Step: 3
Training loss: 0.1537976215626956
Validation loss: 2.2853954497455433

Epoch: 6| Step: 4
Training loss: 0.23884592218944803
Validation loss: 2.2770418131486254

Epoch: 6| Step: 5
Training loss: 0.19544920905219837
Validation loss: 2.286038489534718

Epoch: 6| Step: 6
Training loss: 0.3456434424655267
Validation loss: 2.2650710999170927

Epoch: 6| Step: 7
Training loss: 0.11072255116913782
Validation loss: 2.285713810296236

Epoch: 6| Step: 8
Training loss: 0.2405421913387282
Validation loss: 2.2873427138555096

Epoch: 6| Step: 9
Training loss: 0.22294352219631378
Validation loss: 2.3057014583321473

Epoch: 6| Step: 10
Training loss: 0.27584168849826013
Validation loss: 2.297932975851811

Epoch: 6| Step: 11
Training loss: 0.27214264137619243
Validation loss: 2.313323606777864

Epoch: 6| Step: 12
Training loss: 0.12347236364285843
Validation loss: 2.347237851134802

Epoch: 6| Step: 13
Training loss: 0.4208504811025731
Validation loss: 2.3544697199397464

Epoch: 371| Step: 0
Training loss: 0.21769108947348628
Validation loss: 2.309324770203041

Epoch: 6| Step: 1
Training loss: 0.19068990681122405
Validation loss: 2.343064906031595

Epoch: 6| Step: 2
Training loss: 0.32278153709526636
Validation loss: 2.324052726459884

Epoch: 6| Step: 3
Training loss: 0.22129437069027022
Validation loss: 2.3332593513514857

Epoch: 6| Step: 4
Training loss: 0.12440392933515808
Validation loss: 2.302010486366894

Epoch: 6| Step: 5
Training loss: 0.17821589417889347
Validation loss: 2.2989101014909754

Epoch: 6| Step: 6
Training loss: 0.38620955727701844
Validation loss: 2.3165993478495737

Epoch: 6| Step: 7
Training loss: 0.2670886442446928
Validation loss: 2.2980547781120473

Epoch: 6| Step: 8
Training loss: 0.24154130805700016
Validation loss: 2.2839094857251645

Epoch: 6| Step: 9
Training loss: 0.2636308426189207
Validation loss: 2.3048429225033287

Epoch: 6| Step: 10
Training loss: 0.2885794340588636
Validation loss: 2.3088375901338765

Epoch: 6| Step: 11
Training loss: 0.21633428761144902
Validation loss: 2.312561852476866

Epoch: 6| Step: 12
Training loss: 0.2630868992437443
Validation loss: 2.327337270082307

Epoch: 6| Step: 13
Training loss: 0.3568929082849969
Validation loss: 2.3055066893702905

Epoch: 372| Step: 0
Training loss: 0.2302652122963417
Validation loss: 2.297282173006787

Epoch: 6| Step: 1
Training loss: 0.13750921348567666
Validation loss: 2.301557760880718

Epoch: 6| Step: 2
Training loss: 0.3249820892277076
Validation loss: 2.3065183713981092

Epoch: 6| Step: 3
Training loss: 0.28262998529548017
Validation loss: 2.3018370189271207

Epoch: 6| Step: 4
Training loss: 0.30972514808072993
Validation loss: 2.2997384364458653

Epoch: 6| Step: 5
Training loss: 0.21934792000980236
Validation loss: 2.270775401277821

Epoch: 6| Step: 6
Training loss: 0.28038602156113906
Validation loss: 2.2204630338264595

Epoch: 6| Step: 7
Training loss: 0.20215591932816054
Validation loss: 2.2537099760226265

Epoch: 6| Step: 8
Training loss: 0.3579031825199372
Validation loss: 2.23276406687012

Epoch: 6| Step: 9
Training loss: 0.18791655125653203
Validation loss: 2.2432753796617177

Epoch: 6| Step: 10
Training loss: 0.13582140168660323
Validation loss: 2.2434579849172396

Epoch: 6| Step: 11
Training loss: 0.13948213905883228
Validation loss: 2.2802009266208305

Epoch: 6| Step: 12
Training loss: 0.21138387709689063
Validation loss: 2.2798790334513597

Epoch: 6| Step: 13
Training loss: 0.3128042051718935
Validation loss: 2.2640096040583817

Epoch: 373| Step: 0
Training loss: 0.26730233619120713
Validation loss: 2.2769629629861456

Epoch: 6| Step: 1
Training loss: 0.22558174294539504
Validation loss: 2.3032792800439474

Epoch: 6| Step: 2
Training loss: 0.1664287923489659
Validation loss: 2.284899061055009

Epoch: 6| Step: 3
Training loss: 0.21346717597449247
Validation loss: 2.2771866386316693

Epoch: 6| Step: 4
Training loss: 0.2655406565553959
Validation loss: 2.288730600496095

Epoch: 6| Step: 5
Training loss: 0.30413193057998833
Validation loss: 2.3115807102595256

Epoch: 6| Step: 6
Training loss: 0.2873301533007134
Validation loss: 2.335190446163888

Epoch: 6| Step: 7
Training loss: 0.17348630922866576
Validation loss: 2.328591019234445

Epoch: 6| Step: 8
Training loss: 0.31438104028378355
Validation loss: 2.3041103429437104

Epoch: 6| Step: 9
Training loss: 0.16857409625180994
Validation loss: 2.3051643969675606

Epoch: 6| Step: 10
Training loss: 0.28387275979045445
Validation loss: 2.340745943605408

Epoch: 6| Step: 11
Training loss: 0.2622717807605295
Validation loss: 2.3279809859752287

Epoch: 6| Step: 12
Training loss: 0.28079847012351683
Validation loss: 2.3324706120472922

Epoch: 6| Step: 13
Training loss: 0.364807164647096
Validation loss: 2.296347776287916

Epoch: 374| Step: 0
Training loss: 0.26551488389036526
Validation loss: 2.3000651674459287

Epoch: 6| Step: 1
Training loss: 0.29758147204002267
Validation loss: 2.3099374116841442

Epoch: 6| Step: 2
Training loss: 0.2138272078260627
Validation loss: 2.3253785797119333

Epoch: 6| Step: 3
Training loss: 0.2672176160068962
Validation loss: 2.3082839727168167

Epoch: 6| Step: 4
Training loss: 0.2087532084041438
Validation loss: 2.317656410099316

Epoch: 6| Step: 5
Training loss: 0.3234828272216219
Validation loss: 2.3085474937208894

Epoch: 6| Step: 6
Training loss: 0.18645671829575539
Validation loss: 2.338452466258407

Epoch: 6| Step: 7
Training loss: 0.1726479921049082
Validation loss: 2.283642441318094

Epoch: 6| Step: 8
Training loss: 0.2060348446950601
Validation loss: 2.2908373774385664

Epoch: 6| Step: 9
Training loss: 0.20128981827205922
Validation loss: 2.304592078729236

Epoch: 6| Step: 10
Training loss: 0.38098083906727437
Validation loss: 2.3291343256871757

Epoch: 6| Step: 11
Training loss: 0.21277315065866362
Validation loss: 2.32230120690374

Epoch: 6| Step: 12
Training loss: 0.12874448625554147
Validation loss: 2.3065166085959343

Epoch: 6| Step: 13
Training loss: 0.10938723955472146
Validation loss: 2.3448595304323456

Epoch: 375| Step: 0
Training loss: 0.19361987050885818
Validation loss: 2.343458058759591

Epoch: 6| Step: 1
Training loss: 0.23644461795056382
Validation loss: 2.3342903012569116

Epoch: 6| Step: 2
Training loss: 0.2223021552666086
Validation loss: 2.305267304433902

Epoch: 6| Step: 3
Training loss: 0.3685632054770298
Validation loss: 2.3123303145767267

Epoch: 6| Step: 4
Training loss: 0.2101077608801261
Validation loss: 2.295803077491987

Epoch: 6| Step: 5
Training loss: 0.12707398603671957
Validation loss: 2.26927518452857

Epoch: 6| Step: 6
Training loss: 0.15957320898221705
Validation loss: 2.3148913292857993

Epoch: 6| Step: 7
Training loss: 0.19751668759960891
Validation loss: 2.2414708209286363

Epoch: 6| Step: 8
Training loss: 0.3381629904524784
Validation loss: 2.2885738770916673

Epoch: 6| Step: 9
Training loss: 0.2531466639631759
Validation loss: 2.284444855604351

Epoch: 6| Step: 10
Training loss: 0.27389645887023784
Validation loss: 2.320602623694944

Epoch: 6| Step: 11
Training loss: 0.1554994497707267
Validation loss: 2.347481407736574

Epoch: 6| Step: 12
Training loss: 0.214314580680312
Validation loss: 2.3249404113627823

Epoch: 6| Step: 13
Training loss: 0.0845649468655781
Validation loss: 2.3039232914523513

Epoch: 376| Step: 0
Training loss: 0.2557206542209779
Validation loss: 2.305791103344366

Epoch: 6| Step: 1
Training loss: 0.21956705873796878
Validation loss: 2.3302847977543077

Epoch: 6| Step: 2
Training loss: 0.2320814043164058
Validation loss: 2.3220349685799246

Epoch: 6| Step: 3
Training loss: 0.27047581948264526
Validation loss: 2.313704570764528

Epoch: 6| Step: 4
Training loss: 0.18583067221368413
Validation loss: 2.3074287176255988

Epoch: 6| Step: 5
Training loss: 0.1843365293712778
Validation loss: 2.29377005097424

Epoch: 6| Step: 6
Training loss: 0.2161055789752298
Validation loss: 2.327465792394291

Epoch: 6| Step: 7
Training loss: 0.20881747774152914
Validation loss: 2.3234110594468778

Epoch: 6| Step: 8
Training loss: 0.17901008874150787
Validation loss: 2.3032437281774345

Epoch: 6| Step: 9
Training loss: 0.21875136238763807
Validation loss: 2.318038665433645

Epoch: 6| Step: 10
Training loss: 0.23730483663420837
Validation loss: 2.2984327032187624

Epoch: 6| Step: 11
Training loss: 0.3319197186911463
Validation loss: 2.3333964654260217

Epoch: 6| Step: 12
Training loss: 0.11171687998240294
Validation loss: 2.279490011247951

Epoch: 6| Step: 13
Training loss: 0.37584872363707195
Validation loss: 2.2620976458494755

Epoch: 377| Step: 0
Training loss: 0.2292153900903966
Validation loss: 2.2647888485050354

Epoch: 6| Step: 1
Training loss: 0.18186744761107326
Validation loss: 2.284840342763031

Epoch: 6| Step: 2
Training loss: 0.12647668495857992
Validation loss: 2.3219448156999314

Epoch: 6| Step: 3
Training loss: 0.180353340799489
Validation loss: 2.276820467554443

Epoch: 6| Step: 4
Training loss: 0.21624021116603812
Validation loss: 2.329323466131647

Epoch: 6| Step: 5
Training loss: 0.3308946791079554
Validation loss: 2.321321397011448

Epoch: 6| Step: 6
Training loss: 0.3531764811570821
Validation loss: 2.314031551082917

Epoch: 6| Step: 7
Training loss: 0.3345107453648868
Validation loss: 2.326176659148873

Epoch: 6| Step: 8
Training loss: 0.07897647928566925
Validation loss: 2.2580776116435297

Epoch: 6| Step: 9
Training loss: 0.1854282200532028
Validation loss: 2.260695770877917

Epoch: 6| Step: 10
Training loss: 0.2089174644809772
Validation loss: 2.2107418386371998

Epoch: 6| Step: 11
Training loss: 0.17570240053678007
Validation loss: 2.2035388288779516

Epoch: 6| Step: 12
Training loss: 0.246226449036302
Validation loss: 2.275698224325421

Epoch: 6| Step: 13
Training loss: 0.38603803661071856
Validation loss: 2.2497259871007307

Epoch: 378| Step: 0
Training loss: 0.19846499658049718
Validation loss: 2.2611479034128714

Epoch: 6| Step: 1
Training loss: 0.1407656760709494
Validation loss: 2.271505319816568

Epoch: 6| Step: 2
Training loss: 0.3881322670838289
Validation loss: 2.3086243923034457

Epoch: 6| Step: 3
Training loss: 0.19569528263239078
Validation loss: 2.2911698389188935

Epoch: 6| Step: 4
Training loss: 0.29978813597875675
Validation loss: 2.2763828156988133

Epoch: 6| Step: 5
Training loss: 0.19011550808523964
Validation loss: 2.2690242264304823

Epoch: 6| Step: 6
Training loss: 0.24907701701284
Validation loss: 2.2260053477636785

Epoch: 6| Step: 7
Training loss: 0.2664779404417214
Validation loss: 2.2632734933492324

Epoch: 6| Step: 8
Training loss: 0.16782972215475475
Validation loss: 2.2679941646580217

Epoch: 6| Step: 9
Training loss: 0.23301465711109315
Validation loss: 2.2720297592837473

Epoch: 6| Step: 10
Training loss: 0.15528203832449652
Validation loss: 2.2871886605372005

Epoch: 6| Step: 11
Training loss: 0.11652606424049461
Validation loss: 2.266168165743936

Epoch: 6| Step: 12
Training loss: 0.29306538577539265
Validation loss: 2.3102620122867554

Epoch: 6| Step: 13
Training loss: 0.13919417651418864
Validation loss: 2.3631141597427145

Epoch: 379| Step: 0
Training loss: 0.1523502666351181
Validation loss: 2.3006799002373794

Epoch: 6| Step: 1
Training loss: 0.34647113813470254
Validation loss: 2.3617348151399233

Epoch: 6| Step: 2
Training loss: 0.2981052881397879
Validation loss: 2.3282071506728568

Epoch: 6| Step: 3
Training loss: 0.13012262304949382
Validation loss: 2.3246224139448763

Epoch: 6| Step: 4
Training loss: 0.2013998129136354
Validation loss: 2.2588189923949256

Epoch: 6| Step: 5
Training loss: 0.19364109131655247
Validation loss: 2.2829065291199573

Epoch: 6| Step: 6
Training loss: 0.28800412325589675
Validation loss: 2.2713753630161304

Epoch: 6| Step: 7
Training loss: 0.3142506439169005
Validation loss: 2.2424958045579917

Epoch: 6| Step: 8
Training loss: 0.2183568265080372
Validation loss: 2.233265120441509

Epoch: 6| Step: 9
Training loss: 0.20358781175011603
Validation loss: 2.2266541993753313

Epoch: 6| Step: 10
Training loss: 0.2752906942662642
Validation loss: 2.1867784909947554

Epoch: 6| Step: 11
Training loss: 0.1772096034127878
Validation loss: 2.183629184784446

Epoch: 6| Step: 12
Training loss: 0.26752372522848034
Validation loss: 2.173011543787883

Epoch: 6| Step: 13
Training loss: 0.33846420600115434
Validation loss: 2.1873323168261725

Epoch: 380| Step: 0
Training loss: 0.2664027188645982
Validation loss: 2.185686533757441

Epoch: 6| Step: 1
Training loss: 0.25130023197948165
Validation loss: 2.2071955172598803

Epoch: 6| Step: 2
Training loss: 0.18875150441523872
Validation loss: 2.2543879771335504

Epoch: 6| Step: 3
Training loss: 0.26631979672208184
Validation loss: 2.2768300197347835

Epoch: 6| Step: 4
Training loss: 0.3660942196812468
Validation loss: 2.261763019522758

Epoch: 6| Step: 5
Training loss: 0.2829766782242907
Validation loss: 2.2659522640935634

Epoch: 6| Step: 6
Training loss: 0.14129974822624652
Validation loss: 2.247949988589311

Epoch: 6| Step: 7
Training loss: 0.21627776397686851
Validation loss: 2.2409192366141553

Epoch: 6| Step: 8
Training loss: 0.29208069037376744
Validation loss: 2.2211078678972394

Epoch: 6| Step: 9
Training loss: 0.27402403458239977
Validation loss: 2.2339481416727445

Epoch: 6| Step: 10
Training loss: 0.38450369657517913
Validation loss: 2.2774109620898266

Epoch: 6| Step: 11
Training loss: 0.2711873797020576
Validation loss: 2.307748263315411

Epoch: 6| Step: 12
Training loss: 0.3146697299413837
Validation loss: 2.3502439274995037

Epoch: 6| Step: 13
Training loss: 0.4046178271730573
Validation loss: 2.3741596270076735

Epoch: 381| Step: 0
Training loss: 0.2622919353643308
Validation loss: 2.395387926114114

Epoch: 6| Step: 1
Training loss: 0.13336284994951336
Validation loss: 2.3949634023058897

Epoch: 6| Step: 2
Training loss: 0.3164145621632543
Validation loss: 2.3572327759332197

Epoch: 6| Step: 3
Training loss: 0.18578277449307204
Validation loss: 2.356492538940702

Epoch: 6| Step: 4
Training loss: 0.25630066940567736
Validation loss: 2.3427771919577856

Epoch: 6| Step: 5
Training loss: 0.30666708376500196
Validation loss: 2.348298480925453

Epoch: 6| Step: 6
Training loss: 0.3011794488847583
Validation loss: 2.3406985801735787

Epoch: 6| Step: 7
Training loss: 0.3758933631691635
Validation loss: 2.3242161584724035

Epoch: 6| Step: 8
Training loss: 0.2957298881483442
Validation loss: 2.337850804678189

Epoch: 6| Step: 9
Training loss: 0.3189728565551558
Validation loss: 2.279668360551102

Epoch: 6| Step: 10
Training loss: 0.33167102571039847
Validation loss: 2.3139535547798817

Epoch: 6| Step: 11
Training loss: 0.5184482386179923
Validation loss: 2.301175746841044

Epoch: 6| Step: 12
Training loss: 0.19011313709014585
Validation loss: 2.3130665722219517

Epoch: 6| Step: 13
Training loss: 0.24008095502193993
Validation loss: 2.3776338994556827

Epoch: 382| Step: 0
Training loss: 0.311735899890862
Validation loss: 2.423687047200007

Epoch: 6| Step: 1
Training loss: 0.32135948174695983
Validation loss: 2.476251585438306

Epoch: 6| Step: 2
Training loss: 0.2636140548040127
Validation loss: 2.4890145374464305

Epoch: 6| Step: 3
Training loss: 0.27765910259320664
Validation loss: 2.4352783825631596

Epoch: 6| Step: 4
Training loss: 0.18680724676383745
Validation loss: 2.394050699677943

Epoch: 6| Step: 5
Training loss: 0.2776256928081018
Validation loss: 2.337672120542254

Epoch: 6| Step: 6
Training loss: 0.37999556959229774
Validation loss: 2.3200245826348436

Epoch: 6| Step: 7
Training loss: 0.39547784008851333
Validation loss: 2.2880974947085546

Epoch: 6| Step: 8
Training loss: 0.3036985732134532
Validation loss: 2.26881188514147

Epoch: 6| Step: 9
Training loss: 0.33003103608791895
Validation loss: 2.298846746443459

Epoch: 6| Step: 10
Training loss: 0.24621839243009197
Validation loss: 2.2887122714269124

Epoch: 6| Step: 11
Training loss: 0.4220980301934619
Validation loss: 2.2558179151474222

Epoch: 6| Step: 12
Training loss: 0.29481671207824506
Validation loss: 2.317172203168088

Epoch: 6| Step: 13
Training loss: 0.38185942984897114
Validation loss: 2.322567767923074

Epoch: 383| Step: 0
Training loss: 0.35333282001513555
Validation loss: 2.41299449365445

Epoch: 6| Step: 1
Training loss: 0.5027889610361672
Validation loss: 2.442680617083232

Epoch: 6| Step: 2
Training loss: 0.35328637377107924
Validation loss: 2.381372322581979

Epoch: 6| Step: 3
Training loss: 0.35180014949107397
Validation loss: 2.29811553012775

Epoch: 6| Step: 4
Training loss: 0.2658198707683405
Validation loss: 2.2755440062565535

Epoch: 6| Step: 5
Training loss: 0.4794065161967174
Validation loss: 2.2461241891875168

Epoch: 6| Step: 6
Training loss: 0.3299064867142203
Validation loss: 2.220708398995521

Epoch: 6| Step: 7
Training loss: 0.29358182973248365
Validation loss: 2.236021209188856

Epoch: 6| Step: 8
Training loss: 0.24925197511385902
Validation loss: 2.1969169901972907

Epoch: 6| Step: 9
Training loss: 0.2520806632938272
Validation loss: 2.233853349889774

Epoch: 6| Step: 10
Training loss: 0.29809321621943924
Validation loss: 2.2558771090198206

Epoch: 6| Step: 11
Training loss: 0.3579132787716579
Validation loss: 2.2760362751538974

Epoch: 6| Step: 12
Training loss: 0.29708632677441815
Validation loss: 2.321931190060899

Epoch: 6| Step: 13
Training loss: 0.28966369485830484
Validation loss: 2.353544853504493

Epoch: 384| Step: 0
Training loss: 0.3846130455844621
Validation loss: 2.3487968901390515

Epoch: 6| Step: 1
Training loss: 0.1963681588301606
Validation loss: 2.3517607626890378

Epoch: 6| Step: 2
Training loss: 0.35896514243326183
Validation loss: 2.3258954731317463

Epoch: 6| Step: 3
Training loss: 0.42368094354202657
Validation loss: 2.3721798915499135

Epoch: 6| Step: 4
Training loss: 0.259056931540506
Validation loss: 2.3550307633403884

Epoch: 6| Step: 5
Training loss: 0.36152198333695085
Validation loss: 2.318349363069717

Epoch: 6| Step: 6
Training loss: 0.3244781605361517
Validation loss: 2.341357695647745

Epoch: 6| Step: 7
Training loss: 0.2913619035823962
Validation loss: 2.298571926554947

Epoch: 6| Step: 8
Training loss: 0.29327572316900113
Validation loss: 2.3412988819769187

Epoch: 6| Step: 9
Training loss: 0.2553039812700253
Validation loss: 2.312520482427942

Epoch: 6| Step: 10
Training loss: 0.2596205686393983
Validation loss: 2.3640840212913887

Epoch: 6| Step: 11
Training loss: 0.25423375062582737
Validation loss: 2.3271670196054197

Epoch: 6| Step: 12
Training loss: 0.35236537173426913
Validation loss: 2.33609641273988

Epoch: 6| Step: 13
Training loss: 0.30072589463974475
Validation loss: 2.3468132657493377

Epoch: 385| Step: 0
Training loss: 0.3975387796942796
Validation loss: 2.3103549324063435

Epoch: 6| Step: 1
Training loss: 0.22074266940286877
Validation loss: 2.2531054178364087

Epoch: 6| Step: 2
Training loss: 0.2734033018252554
Validation loss: 2.2628773323119376

Epoch: 6| Step: 3
Training loss: 0.3678543447515068
Validation loss: 2.2654941225421874

Epoch: 6| Step: 4
Training loss: 0.2386385006210292
Validation loss: 2.2228292713649087

Epoch: 6| Step: 5
Training loss: 0.23677738300774076
Validation loss: 2.244907679268883

Epoch: 6| Step: 6
Training loss: 0.38652218533660554
Validation loss: 2.2466326146612303

Epoch: 6| Step: 7
Training loss: 0.37609583956712866
Validation loss: 2.2484630584603877

Epoch: 6| Step: 8
Training loss: 0.15369910324278097
Validation loss: 2.2645365271847275

Epoch: 6| Step: 9
Training loss: 0.4198549439074077
Validation loss: 2.2617076253131234

Epoch: 6| Step: 10
Training loss: 0.4240158298254511
Validation loss: 2.283473456388427

Epoch: 6| Step: 11
Training loss: 0.2596610152628755
Validation loss: 2.2950792054212092

Epoch: 6| Step: 12
Training loss: 0.221459518867853
Validation loss: 2.3067368289551653

Epoch: 6| Step: 13
Training loss: 0.3696863893184278
Validation loss: 2.3468568539803076

Epoch: 386| Step: 0
Training loss: 0.3378150282067364
Validation loss: 2.3253719969042845

Epoch: 6| Step: 1
Training loss: 0.24090505038828824
Validation loss: 2.359961634734787

Epoch: 6| Step: 2
Training loss: 0.3063140150233927
Validation loss: 2.3866881371652515

Epoch: 6| Step: 3
Training loss: 0.25678407848982754
Validation loss: 2.422304640499201

Epoch: 6| Step: 4
Training loss: 0.26158053036326606
Validation loss: 2.418469121409058

Epoch: 6| Step: 5
Training loss: 0.4105929275366259
Validation loss: 2.4492260403779835

Epoch: 6| Step: 6
Training loss: 0.18344069249041145
Validation loss: 2.3929066941832

Epoch: 6| Step: 7
Training loss: 0.17487763102994683
Validation loss: 2.404328674296447

Epoch: 6| Step: 8
Training loss: 0.2322455947815438
Validation loss: 2.40120759461434

Epoch: 6| Step: 9
Training loss: 0.33313001700482825
Validation loss: 2.4061953289766107

Epoch: 6| Step: 10
Training loss: 0.4874238382658541
Validation loss: 2.4009933511306825

Epoch: 6| Step: 11
Training loss: 0.4168951381697697
Validation loss: 2.3767625920742406

Epoch: 6| Step: 12
Training loss: 0.44433597103579886
Validation loss: 2.393964904735986

Epoch: 6| Step: 13
Training loss: 0.30049318911487133
Validation loss: 2.3904880455230146

Epoch: 387| Step: 0
Training loss: 0.3844547855718851
Validation loss: 2.4080471569187374

Epoch: 6| Step: 1
Training loss: 0.27618021756835376
Validation loss: 2.426558893729816

Epoch: 6| Step: 2
Training loss: 0.424324852054943
Validation loss: 2.3948814081064236

Epoch: 6| Step: 3
Training loss: 0.2952352967844713
Validation loss: 2.3806755329209723

Epoch: 6| Step: 4
Training loss: 0.2221478547433555
Validation loss: 2.3618391556065332

Epoch: 6| Step: 5
Training loss: 0.2702787924019798
Validation loss: 2.3630616217100906

Epoch: 6| Step: 6
Training loss: 0.280238850549586
Validation loss: 2.3064469168107724

Epoch: 6| Step: 7
Training loss: 0.3198163563002132
Validation loss: 2.2632557408259277

Epoch: 6| Step: 8
Training loss: 0.282595383568197
Validation loss: 2.214660616125391

Epoch: 6| Step: 9
Training loss: 0.2906207022810616
Validation loss: 2.2104423186124

Epoch: 6| Step: 10
Training loss: 0.22843421398779165
Validation loss: 2.2316725083636406

Epoch: 6| Step: 11
Training loss: 0.32746221952336424
Validation loss: 2.24852559674165

Epoch: 6| Step: 12
Training loss: 0.23381929480961386
Validation loss: 2.2659009109882753

Epoch: 6| Step: 13
Training loss: 0.5435478634942225
Validation loss: 2.272193722667744

Epoch: 388| Step: 0
Training loss: 0.2459749661739577
Validation loss: 2.298231886966405

Epoch: 6| Step: 1
Training loss: 0.27188878846555314
Validation loss: 2.330710660625296

Epoch: 6| Step: 2
Training loss: 0.15618797501686038
Validation loss: 2.3472933126702564

Epoch: 6| Step: 3
Training loss: 0.2043572243709233
Validation loss: 2.384069071145375

Epoch: 6| Step: 4
Training loss: 0.2607666604204757
Validation loss: 2.388702495682114

Epoch: 6| Step: 5
Training loss: 0.22930556480669043
Validation loss: 2.432595934190267

Epoch: 6| Step: 6
Training loss: 0.5228261366466321
Validation loss: 2.4137569778013632

Epoch: 6| Step: 7
Training loss: 0.44045227060550096
Validation loss: 2.3831597338608432

Epoch: 6| Step: 8
Training loss: 0.24762448067974108
Validation loss: 2.3139166025304845

Epoch: 6| Step: 9
Training loss: 0.30282150983447004
Validation loss: 2.272867105056691

Epoch: 6| Step: 10
Training loss: 0.3368039158434898
Validation loss: 2.1980525153017614

Epoch: 6| Step: 11
Training loss: 0.40531941348424483
Validation loss: 2.230303504264529

Epoch: 6| Step: 12
Training loss: 0.3626562916148769
Validation loss: 2.22381094324819

Epoch: 6| Step: 13
Training loss: 0.2673467066973104
Validation loss: 2.25817698401507

Epoch: 389| Step: 0
Training loss: 0.25502583083051183
Validation loss: 2.3072084227466307

Epoch: 6| Step: 1
Training loss: 0.34907685112886166
Validation loss: 2.326746452433969

Epoch: 6| Step: 2
Training loss: 0.25170666076594056
Validation loss: 2.3082154605022396

Epoch: 6| Step: 3
Training loss: 0.28124724492736963
Validation loss: 2.3845210111888897

Epoch: 6| Step: 4
Training loss: 0.3680842993666518
Validation loss: 2.3862606346243935

Epoch: 6| Step: 5
Training loss: 0.36980757432848227
Validation loss: 2.337653593428831

Epoch: 6| Step: 6
Training loss: 0.21709528138441647
Validation loss: 2.3817234589341654

Epoch: 6| Step: 7
Training loss: 0.2967723869871312
Validation loss: 2.29059293283794

Epoch: 6| Step: 8
Training loss: 0.4348508122453564
Validation loss: 2.3047857665088816

Epoch: 6| Step: 9
Training loss: 0.37659116770414763
Validation loss: 2.2727731124994577

Epoch: 6| Step: 10
Training loss: 0.4894071491930562
Validation loss: 2.2666568973350034

Epoch: 6| Step: 11
Training loss: 0.39906775424040425
Validation loss: 2.281363063723799

Epoch: 6| Step: 12
Training loss: 0.2127090607290381
Validation loss: 2.2432807760105704

Epoch: 6| Step: 13
Training loss: 0.32959667057455233
Validation loss: 2.2917285235904545

Epoch: 390| Step: 0
Training loss: 0.27098538489275353
Validation loss: 2.3053091293665045

Epoch: 6| Step: 1
Training loss: 0.4314073475979524
Validation loss: 2.300690341733417

Epoch: 6| Step: 2
Training loss: 0.2824286295187294
Validation loss: 2.293120454648379

Epoch: 6| Step: 3
Training loss: 0.23866079151747016
Validation loss: 2.329085965537625

Epoch: 6| Step: 4
Training loss: 0.17559766189248985
Validation loss: 2.340065067711104

Epoch: 6| Step: 5
Training loss: 0.36190800916505905
Validation loss: 2.324343701329549

Epoch: 6| Step: 6
Training loss: 0.32260359179690146
Validation loss: 2.3044190364628907

Epoch: 6| Step: 7
Training loss: 0.37648754323563116
Validation loss: 2.2816389524603977

Epoch: 6| Step: 8
Training loss: 0.3707528606530794
Validation loss: 2.2431944465853544

Epoch: 6| Step: 9
Training loss: 0.24602752884490703
Validation loss: 2.251657189581621

Epoch: 6| Step: 10
Training loss: 0.2597515417884838
Validation loss: 2.2644536719967325

Epoch: 6| Step: 11
Training loss: 0.314242179676186
Validation loss: 2.2672590960301386

Epoch: 6| Step: 12
Training loss: 0.13608210698897158
Validation loss: 2.265565039011339

Epoch: 6| Step: 13
Training loss: 0.23548143214731465
Validation loss: 2.2774024823111736

Epoch: 391| Step: 0
Training loss: 0.20077325159313125
Validation loss: 2.2939820712630445

Epoch: 6| Step: 1
Training loss: 0.3047974950363948
Validation loss: 2.319673759309004

Epoch: 6| Step: 2
Training loss: 0.3982652965237346
Validation loss: 2.3502759018345465

Epoch: 6| Step: 3
Training loss: 0.32373912218591006
Validation loss: 2.3643140019216458

Epoch: 6| Step: 4
Training loss: 0.2181288210034099
Validation loss: 2.353261131156941

Epoch: 6| Step: 5
Training loss: 0.3574345487421739
Validation loss: 2.3334710894263124

Epoch: 6| Step: 6
Training loss: 0.277089472513857
Validation loss: 2.364994474287181

Epoch: 6| Step: 7
Training loss: 0.3187447771878668
Validation loss: 2.3576269315050227

Epoch: 6| Step: 8
Training loss: 0.26050210822674585
Validation loss: 2.397198094585397

Epoch: 6| Step: 9
Training loss: 0.29837552870186995
Validation loss: 2.3770202739941446

Epoch: 6| Step: 10
Training loss: 0.27539902532224275
Validation loss: 2.3601713498381494

Epoch: 6| Step: 11
Training loss: 0.18231186868351018
Validation loss: 2.2964195707929753

Epoch: 6| Step: 12
Training loss: 0.38960499150801314
Validation loss: 2.245303092854229

Epoch: 6| Step: 13
Training loss: 0.2248657422049936
Validation loss: 2.2577901223756296

Epoch: 392| Step: 0
Training loss: 0.2410488742540964
Validation loss: 2.196136398246562

Epoch: 6| Step: 1
Training loss: 0.25911224626161306
Validation loss: 2.2052431068009817

Epoch: 6| Step: 2
Training loss: 0.28399051517947993
Validation loss: 2.172470365285566

Epoch: 6| Step: 3
Training loss: 0.3751320407782512
Validation loss: 2.1692409907507124

Epoch: 6| Step: 4
Training loss: 0.40749650236980733
Validation loss: 2.1748451850841426

Epoch: 6| Step: 5
Training loss: 0.4058167641734546
Validation loss: 2.1790833594708667

Epoch: 6| Step: 6
Training loss: 0.26230923385259114
Validation loss: 2.22669979205418

Epoch: 6| Step: 7
Training loss: 0.27478595390532135
Validation loss: 2.2759944675937795

Epoch: 6| Step: 8
Training loss: 0.33224514074482087
Validation loss: 2.289606755597315

Epoch: 6| Step: 9
Training loss: 0.185133604282454
Validation loss: 2.3423531847097965

Epoch: 6| Step: 10
Training loss: 0.27136445999147585
Validation loss: 2.2798656927779994

Epoch: 6| Step: 11
Training loss: 0.4077780668842031
Validation loss: 2.2777387810100165

Epoch: 6| Step: 12
Training loss: 0.26033127656332566
Validation loss: 2.3057945588998643

Epoch: 6| Step: 13
Training loss: 0.41519732879714705
Validation loss: 2.29424418444552

Epoch: 393| Step: 0
Training loss: 0.24063423653004104
Validation loss: 2.362079635635833

Epoch: 6| Step: 1
Training loss: 0.3590264703520616
Validation loss: 2.331872606624442

Epoch: 6| Step: 2
Training loss: 0.3008955824903614
Validation loss: 2.332417495876235

Epoch: 6| Step: 3
Training loss: 0.47157599215611185
Validation loss: 2.367002342604586

Epoch: 6| Step: 4
Training loss: 0.3438066630912515
Validation loss: 2.3288811295891154

Epoch: 6| Step: 5
Training loss: 0.3400027243070289
Validation loss: 2.3664588799166384

Epoch: 6| Step: 6
Training loss: 0.44199087873493503
Validation loss: 2.3791609741097437

Epoch: 6| Step: 7
Training loss: 0.22142271027795427
Validation loss: 2.3454826912411066

Epoch: 6| Step: 8
Training loss: 0.28386799606558744
Validation loss: 2.3491955243507006

Epoch: 6| Step: 9
Training loss: 0.3205578724822223
Validation loss: 2.396556021546241

Epoch: 6| Step: 10
Training loss: 0.2859718729423287
Validation loss: 2.3996618155660627

Epoch: 6| Step: 11
Training loss: 0.37858274748491866
Validation loss: 2.3965201054739502

Epoch: 6| Step: 12
Training loss: 0.39967923117786647
Validation loss: 2.4108976151079955

Epoch: 6| Step: 13
Training loss: 0.3123023719534759
Validation loss: 2.374904162163104

Epoch: 394| Step: 0
Training loss: 0.29561554885579866
Validation loss: 2.3025060993148667

Epoch: 6| Step: 1
Training loss: 0.3182545003572795
Validation loss: 2.304404926722775

Epoch: 6| Step: 2
Training loss: 0.20634314608395268
Validation loss: 2.309500446453923

Epoch: 6| Step: 3
Training loss: 0.33360947654514966
Validation loss: 2.29143607320925

Epoch: 6| Step: 4
Training loss: 0.3181536425154034
Validation loss: 2.251369335367852

Epoch: 6| Step: 5
Training loss: 0.27354633345234114
Validation loss: 2.2702644684026096

Epoch: 6| Step: 6
Training loss: 0.4144862364001225
Validation loss: 2.294236200446111

Epoch: 6| Step: 7
Training loss: 0.2626358588913752
Validation loss: 2.3227818480899

Epoch: 6| Step: 8
Training loss: 0.21481108850687433
Validation loss: 2.332407480540788

Epoch: 6| Step: 9
Training loss: 0.2825737108429499
Validation loss: 2.3431877178205243

Epoch: 6| Step: 10
Training loss: 0.1734892510195546
Validation loss: 2.3663679049894792

Epoch: 6| Step: 11
Training loss: 0.2223573904216298
Validation loss: 2.3819426058375437

Epoch: 6| Step: 12
Training loss: 0.3182136342471795
Validation loss: 2.3858579505173423

Epoch: 6| Step: 13
Training loss: 0.3083627053180753
Validation loss: 2.397795610764913

Epoch: 395| Step: 0
Training loss: 0.232295474775316
Validation loss: 2.3719326238995593

Epoch: 6| Step: 1
Training loss: 0.1923863754329812
Validation loss: 2.328451086016927

Epoch: 6| Step: 2
Training loss: 0.21520937239576715
Validation loss: 2.268268801346619

Epoch: 6| Step: 3
Training loss: 0.21048473403658774
Validation loss: 2.2712304531128145

Epoch: 6| Step: 4
Training loss: 0.30323734954272963
Validation loss: 2.2637911595821487

Epoch: 6| Step: 5
Training loss: 0.2939672493590671
Validation loss: 2.2607746327562177

Epoch: 6| Step: 6
Training loss: 0.3548861959544893
Validation loss: 2.248449764554472

Epoch: 6| Step: 7
Training loss: 0.255933561562591
Validation loss: 2.2746813112202076

Epoch: 6| Step: 8
Training loss: 0.358622530278836
Validation loss: 2.2178110605431955

Epoch: 6| Step: 9
Training loss: 0.22995574883111494
Validation loss: 2.2475451131324986

Epoch: 6| Step: 10
Training loss: 0.3452279872091832
Validation loss: 2.248932026676643

Epoch: 6| Step: 11
Training loss: 0.3275492248596444
Validation loss: 2.2310994476708697

Epoch: 6| Step: 12
Training loss: 0.3095776650310748
Validation loss: 2.258464865601544

Epoch: 6| Step: 13
Training loss: 0.3278563512304451
Validation loss: 2.2557842035957427

Epoch: 396| Step: 0
Training loss: 0.23220042088780138
Validation loss: 2.3093203874228605

Epoch: 6| Step: 1
Training loss: 0.2362262884734468
Validation loss: 2.2935852026004886

Epoch: 6| Step: 2
Training loss: 0.29213685499465053
Validation loss: 2.3015306824942754

Epoch: 6| Step: 3
Training loss: 0.22345825112290524
Validation loss: 2.317233346786977

Epoch: 6| Step: 4
Training loss: 0.27012065352879955
Validation loss: 2.280882898703965

Epoch: 6| Step: 5
Training loss: 0.2107203566846222
Validation loss: 2.2559602939743115

Epoch: 6| Step: 6
Training loss: 0.18480032258330714
Validation loss: 2.25280546481186

Epoch: 6| Step: 7
Training loss: 0.18996574422444779
Validation loss: 2.2417814471560846

Epoch: 6| Step: 8
Training loss: 0.3592687117920517
Validation loss: 2.2537383990607753

Epoch: 6| Step: 9
Training loss: 0.356287087634828
Validation loss: 2.2556509639669415

Epoch: 6| Step: 10
Training loss: 0.23209683746815457
Validation loss: 2.238887069847501

Epoch: 6| Step: 11
Training loss: 0.27295817188189647
Validation loss: 2.2633422315957454

Epoch: 6| Step: 12
Training loss: 0.24032838269145423
Validation loss: 2.25249296150129

Epoch: 6| Step: 13
Training loss: 0.35539431368996766
Validation loss: 2.27154785442251

Epoch: 397| Step: 0
Training loss: 0.25285514999902065
Validation loss: 2.2726565057936856

Epoch: 6| Step: 1
Training loss: 0.30667790714729126
Validation loss: 2.30086840481862

Epoch: 6| Step: 2
Training loss: 0.34570716596924844
Validation loss: 2.3254901141816444

Epoch: 6| Step: 3
Training loss: 0.24368715515366698
Validation loss: 2.2857680274593872

Epoch: 6| Step: 4
Training loss: 0.1865982983938339
Validation loss: 2.27234729094328

Epoch: 6| Step: 5
Training loss: 0.22249442627976357
Validation loss: 2.2563254612286943

Epoch: 6| Step: 6
Training loss: 0.2638415320607161
Validation loss: 2.243968275759201

Epoch: 6| Step: 7
Training loss: 0.18019730354100544
Validation loss: 2.220425188435094

Epoch: 6| Step: 8
Training loss: 0.19017506718685145
Validation loss: 2.213697206267171

Epoch: 6| Step: 9
Training loss: 0.23515217989824277
Validation loss: 2.16024911747589

Epoch: 6| Step: 10
Training loss: 0.25999224250022807
Validation loss: 2.206283971053252

Epoch: 6| Step: 11
Training loss: 0.2333582759763612
Validation loss: 2.206262402710379

Epoch: 6| Step: 12
Training loss: 0.2564151783980466
Validation loss: 2.20713566068394

Epoch: 6| Step: 13
Training loss: 0.26279405064184697
Validation loss: 2.21404573457058

Epoch: 398| Step: 0
Training loss: 0.1887135966987527
Validation loss: 2.2246205544077626

Epoch: 6| Step: 1
Training loss: 0.17744895528503002
Validation loss: 2.203319205000422

Epoch: 6| Step: 2
Training loss: 0.20012358334127467
Validation loss: 2.2629786554171267

Epoch: 6| Step: 3
Training loss: 0.36391070397985703
Validation loss: 2.242523662093715

Epoch: 6| Step: 4
Training loss: 0.3177352357115952
Validation loss: 2.2778365460843144

Epoch: 6| Step: 5
Training loss: 0.17014906482746409
Validation loss: 2.2665192420249287

Epoch: 6| Step: 6
Training loss: 0.20074445261125487
Validation loss: 2.270420713118032

Epoch: 6| Step: 7
Training loss: 0.22858639786761695
Validation loss: 2.29284524526467

Epoch: 6| Step: 8
Training loss: 0.27649378488636533
Validation loss: 2.2640266650407415

Epoch: 6| Step: 9
Training loss: 0.30687422874648995
Validation loss: 2.247652821219549

Epoch: 6| Step: 10
Training loss: 0.13311328207300832
Validation loss: 2.235165431313571

Epoch: 6| Step: 11
Training loss: 0.15940141739406552
Validation loss: 2.2407244073147505

Epoch: 6| Step: 12
Training loss: 0.2185432615182562
Validation loss: 2.17612605405009

Epoch: 6| Step: 13
Training loss: 0.21006870608992553
Validation loss: 2.2038706682171902

Epoch: 399| Step: 0
Training loss: 0.11472631243378789
Validation loss: 2.1599576775321427

Epoch: 6| Step: 1
Training loss: 0.2514410952122088
Validation loss: 2.1803519955132296

Epoch: 6| Step: 2
Training loss: 0.17757087565174198
Validation loss: 2.1732450023992795

Epoch: 6| Step: 3
Training loss: 0.20282348849912266
Validation loss: 2.1435448852557126

Epoch: 6| Step: 4
Training loss: 0.18153382309587116
Validation loss: 2.1378463016988523

Epoch: 6| Step: 5
Training loss: 0.2430649520934744
Validation loss: 2.1981941718246674

Epoch: 6| Step: 6
Training loss: 0.38153005382354394
Validation loss: 2.1968013393408814

Epoch: 6| Step: 7
Training loss: 0.14283294637797156
Validation loss: 2.2055153604674542

Epoch: 6| Step: 8
Training loss: 0.2166749594244606
Validation loss: 2.1609075191110567

Epoch: 6| Step: 9
Training loss: 0.3001563404923104
Validation loss: 2.174831393440146

Epoch: 6| Step: 10
Training loss: 0.14788105467689153
Validation loss: 2.1833714188847995

Epoch: 6| Step: 11
Training loss: 0.2397083478064831
Validation loss: 2.2387941905168227

Epoch: 6| Step: 12
Training loss: 0.12350765118083785
Validation loss: 2.213406738473426

Epoch: 6| Step: 13
Training loss: 0.1053509893674045
Validation loss: 2.199644266986996

Epoch: 400| Step: 0
Training loss: 0.16441445405659236
Validation loss: 2.2551506211483963

Epoch: 6| Step: 1
Training loss: 0.14996578849623474
Validation loss: 2.228155557915091

Epoch: 6| Step: 2
Training loss: 0.19819129328133636
Validation loss: 2.229560980673948

Epoch: 6| Step: 3
Training loss: 0.20158020725391548
Validation loss: 2.262985083262247

Epoch: 6| Step: 4
Training loss: 0.41643467246098587
Validation loss: 2.2257081478680094

Epoch: 6| Step: 5
Training loss: 0.19069634376668052
Validation loss: 2.2360974685948136

Epoch: 6| Step: 6
Training loss: 0.10582233252415581
Validation loss: 2.269068905623254

Epoch: 6| Step: 7
Training loss: 0.21799551755010893
Validation loss: 2.2618569808210616

Epoch: 6| Step: 8
Training loss: 0.1737270918845484
Validation loss: 2.235923736904374

Epoch: 6| Step: 9
Training loss: 0.31654048944833235
Validation loss: 2.2366981708529403

Epoch: 6| Step: 10
Training loss: 0.15715612883382038
Validation loss: 2.2255088545398154

Epoch: 6| Step: 11
Training loss: 0.17454889965547848
Validation loss: 2.235958906482435

Epoch: 6| Step: 12
Training loss: 0.25011664887822627
Validation loss: 2.2228132724074823

Epoch: 6| Step: 13
Training loss: 0.1641319105366933
Validation loss: 2.1913071254383696

Epoch: 401| Step: 0
Training loss: 0.16218891260785115
Validation loss: 2.214303297624505

Epoch: 6| Step: 1
Training loss: 0.12915363560081164
Validation loss: 2.2005677192665245

Epoch: 6| Step: 2
Training loss: 0.24612903342034625
Validation loss: 2.181267440843232

Epoch: 6| Step: 3
Training loss: 0.2783045044809959
Validation loss: 2.173622393372138

Epoch: 6| Step: 4
Training loss: 0.1590093391557711
Validation loss: 2.175710124811796

Epoch: 6| Step: 5
Training loss: 0.25986688117537426
Validation loss: 2.1667552197095135

Epoch: 6| Step: 6
Training loss: 0.15373940501110223
Validation loss: 2.205982258866899

Epoch: 6| Step: 7
Training loss: 0.14525684372697809
Validation loss: 2.208826133906706

Epoch: 6| Step: 8
Training loss: 0.34137793888404006
Validation loss: 2.1775756536769415

Epoch: 6| Step: 9
Training loss: 0.17841933385100225
Validation loss: 2.198767105949453

Epoch: 6| Step: 10
Training loss: 0.21218870095206677
Validation loss: 2.1718993794585355

Epoch: 6| Step: 11
Training loss: 0.1480455116672197
Validation loss: 2.1867143160501565

Epoch: 6| Step: 12
Training loss: 0.12496149692010705
Validation loss: 2.1983081014366985

Epoch: 6| Step: 13
Training loss: 0.20652985587553563
Validation loss: 2.210749398246575

Epoch: 402| Step: 0
Training loss: 0.1117745616859241
Validation loss: 2.194722173556715

Epoch: 6| Step: 1
Training loss: 0.1846374308947485
Validation loss: 2.2326132697932883

Epoch: 6| Step: 2
Training loss: 0.1946766995148222
Validation loss: 2.20648590793195

Epoch: 6| Step: 3
Training loss: 0.20616294403507127
Validation loss: 2.2166549702971934

Epoch: 6| Step: 4
Training loss: 0.1924481740768287
Validation loss: 2.1973149729374892

Epoch: 6| Step: 5
Training loss: 0.20883381848292867
Validation loss: 2.197039565404172

Epoch: 6| Step: 6
Training loss: 0.17344742780915925
Validation loss: 2.190437815206388

Epoch: 6| Step: 7
Training loss: 0.18880418359750234
Validation loss: 2.200852771666093

Epoch: 6| Step: 8
Training loss: 0.1978222669959333
Validation loss: 2.1788843022989077

Epoch: 6| Step: 9
Training loss: 0.25729183159692914
Validation loss: 2.1628284145218313

Epoch: 6| Step: 10
Training loss: 0.14217877308819618
Validation loss: 2.1822959196383227

Epoch: 6| Step: 11
Training loss: 0.17112032518452192
Validation loss: 2.1906374287403017

Epoch: 6| Step: 12
Training loss: 0.2726055704799059
Validation loss: 2.2127053691252736

Epoch: 6| Step: 13
Training loss: 0.31644734951635534
Validation loss: 2.1876915550448865

Epoch: 403| Step: 0
Training loss: 0.14174126935071826
Validation loss: 2.2135956946673505

Epoch: 6| Step: 1
Training loss: 0.22199913568478805
Validation loss: 2.1835782360942204

Epoch: 6| Step: 2
Training loss: 0.25301327300028315
Validation loss: 2.2024651531778616

Epoch: 6| Step: 3
Training loss: 0.12403271107282832
Validation loss: 2.1829576105932085

Epoch: 6| Step: 4
Training loss: 0.1342117773716237
Validation loss: 2.2374478743171253

Epoch: 6| Step: 5
Training loss: 0.1843533729541597
Validation loss: 2.213895785087326

Epoch: 6| Step: 6
Training loss: 0.20552376057866273
Validation loss: 2.203744203543491

Epoch: 6| Step: 7
Training loss: 0.14525097703358897
Validation loss: 2.226078453909542

Epoch: 6| Step: 8
Training loss: 0.3495741671943143
Validation loss: 2.1928673725668033

Epoch: 6| Step: 9
Training loss: 0.14577822552290118
Validation loss: 2.221630001456843

Epoch: 6| Step: 10
Training loss: 0.12657842359329866
Validation loss: 2.233543991263851

Epoch: 6| Step: 11
Training loss: 0.22868463184156324
Validation loss: 2.2119865611505416

Epoch: 6| Step: 12
Training loss: 0.17090194698544986
Validation loss: 2.199714992399936

Epoch: 6| Step: 13
Training loss: 0.4158641378189808
Validation loss: 2.182171837222648

Epoch: 404| Step: 0
Training loss: 0.24867485931456165
Validation loss: 2.213743215188404

Epoch: 6| Step: 1
Training loss: 0.24024634602811643
Validation loss: 2.2027420715378314

Epoch: 6| Step: 2
Training loss: 0.256014929506523
Validation loss: 2.2031552683516025

Epoch: 6| Step: 3
Training loss: 0.21081789475829257
Validation loss: 2.194190974836289

Epoch: 6| Step: 4
Training loss: 0.1157990376583608
Validation loss: 2.237274280147614

Epoch: 6| Step: 5
Training loss: 0.24504411983759322
Validation loss: 2.21394775796375

Epoch: 6| Step: 6
Training loss: 0.22638939130632418
Validation loss: 2.221949531460438

Epoch: 6| Step: 7
Training loss: 0.16603639136190318
Validation loss: 2.2342024183697027

Epoch: 6| Step: 8
Training loss: 0.14415846251653155
Validation loss: 2.2093378687611698

Epoch: 6| Step: 9
Training loss: 0.294920258170237
Validation loss: 2.213545204656815

Epoch: 6| Step: 10
Training loss: 0.09885771764454568
Validation loss: 2.1749956244326962

Epoch: 6| Step: 11
Training loss: 0.18554906341868366
Validation loss: 2.185533859969441

Epoch: 6| Step: 12
Training loss: 0.12139315660979091
Validation loss: 2.2260590763332475

Epoch: 6| Step: 13
Training loss: 0.1815680492163715
Validation loss: 2.226784654122759

Epoch: 405| Step: 0
Training loss: 0.20939662416015478
Validation loss: 2.210240593581953

Epoch: 6| Step: 1
Training loss: 0.16076132983671734
Validation loss: 2.192348287468459

Epoch: 6| Step: 2
Training loss: 0.23097059601190686
Validation loss: 2.2078623007147864

Epoch: 6| Step: 3
Training loss: 0.13968491244639739
Validation loss: 2.186792743924575

Epoch: 6| Step: 4
Training loss: 0.23711516421947582
Validation loss: 2.1980688146143565

Epoch: 6| Step: 5
Training loss: 0.2221910234163877
Validation loss: 2.1930909187785814

Epoch: 6| Step: 6
Training loss: 0.1302308317456461
Validation loss: 2.195987334214523

Epoch: 6| Step: 7
Training loss: 0.10669183619301578
Validation loss: 2.2157211089519

Epoch: 6| Step: 8
Training loss: 0.13978152169223157
Validation loss: 2.2366604362627074

Epoch: 6| Step: 9
Training loss: 0.1674147830196226
Validation loss: 2.2178770176681795

Epoch: 6| Step: 10
Training loss: 0.30286231260139984
Validation loss: 2.2016304897303254

Epoch: 6| Step: 11
Training loss: 0.14672667491094654
Validation loss: 2.2253711022259988

Epoch: 6| Step: 12
Training loss: 0.20858228630540263
Validation loss: 2.202947938335341

Epoch: 6| Step: 13
Training loss: 0.13664825529383298
Validation loss: 2.229911740252041

Epoch: 406| Step: 0
Training loss: 0.1630736820390208
Validation loss: 2.1936938211526837

Epoch: 6| Step: 1
Training loss: 0.13684478808460304
Validation loss: 2.1964517760351923

Epoch: 6| Step: 2
Training loss: 0.24370491821368928
Validation loss: 2.2208916326920947

Epoch: 6| Step: 3
Training loss: 0.1661277560611095
Validation loss: 2.1924745429551873

Epoch: 6| Step: 4
Training loss: 0.1499932103805916
Validation loss: 2.197504936576328

Epoch: 6| Step: 5
Training loss: 0.17031814692698694
Validation loss: 2.2187470605493647

Epoch: 6| Step: 6
Training loss: 0.2851385999468961
Validation loss: 2.2235464754235927

Epoch: 6| Step: 7
Training loss: 0.22037938097073642
Validation loss: 2.2086035396170445

Epoch: 6| Step: 8
Training loss: 0.2503842887136212
Validation loss: 2.260864518153576

Epoch: 6| Step: 9
Training loss: 0.14611719524728423
Validation loss: 2.257346311960463

Epoch: 6| Step: 10
Training loss: 0.20351113700677384
Validation loss: 2.286503199197105

Epoch: 6| Step: 11
Training loss: 0.1048203689126958
Validation loss: 2.2367690948468373

Epoch: 6| Step: 12
Training loss: 0.15667054088051516
Validation loss: 2.2167391853149625

Epoch: 6| Step: 13
Training loss: 0.07103207396647382
Validation loss: 2.254847574261328

Epoch: 407| Step: 0
Training loss: 0.12075409630872265
Validation loss: 2.265532706491498

Epoch: 6| Step: 1
Training loss: 0.18822824594736579
Validation loss: 2.264740265577467

Epoch: 6| Step: 2
Training loss: 0.07180093844561385
Validation loss: 2.2714278682893245

Epoch: 6| Step: 3
Training loss: 0.10995902234267892
Validation loss: 2.2838186394408733

Epoch: 6| Step: 4
Training loss: 0.20222600655703127
Validation loss: 2.261625046790032

Epoch: 6| Step: 5
Training loss: 0.31658859649973187
Validation loss: 2.265829777612764

Epoch: 6| Step: 6
Training loss: 0.0748360585499354
Validation loss: 2.268682341319754

Epoch: 6| Step: 7
Training loss: 0.1866063837295392
Validation loss: 2.2450152238417846

Epoch: 6| Step: 8
Training loss: 0.2664641141276837
Validation loss: 2.221573188516263

Epoch: 6| Step: 9
Training loss: 0.09254345747759186
Validation loss: 2.2318671687171547

Epoch: 6| Step: 10
Training loss: 0.14919450622858496
Validation loss: 2.2126751983939883

Epoch: 6| Step: 11
Training loss: 0.18714851973373972
Validation loss: 2.2042212550475186

Epoch: 6| Step: 12
Training loss: 0.25794727963911407
Validation loss: 2.2091261678200076

Epoch: 6| Step: 13
Training loss: 0.21108543541978902
Validation loss: 2.210699919965983

Epoch: 408| Step: 0
Training loss: 0.14515241962795214
Validation loss: 2.2063614842759685

Epoch: 6| Step: 1
Training loss: 0.21743437540222113
Validation loss: 2.193666089709768

Epoch: 6| Step: 2
Training loss: 0.1258063830268699
Validation loss: 2.1459557983866646

Epoch: 6| Step: 3
Training loss: 0.28527726257676583
Validation loss: 2.169510763926845

Epoch: 6| Step: 4
Training loss: 0.21567590119615887
Validation loss: 2.136538055692899

Epoch: 6| Step: 5
Training loss: 0.12208954468859677
Validation loss: 2.161153786458593

Epoch: 6| Step: 6
Training loss: 0.16692590792436024
Validation loss: 2.187963411435098

Epoch: 6| Step: 7
Training loss: 0.14594606033394159
Validation loss: 2.172880089925015

Epoch: 6| Step: 8
Training loss: 0.19262608284989363
Validation loss: 2.1780873537955485

Epoch: 6| Step: 9
Training loss: 0.09893192129106805
Validation loss: 2.1945609251789167

Epoch: 6| Step: 10
Training loss: 0.21656006259840155
Validation loss: 2.199840650865688

Epoch: 6| Step: 11
Training loss: 0.12927431964348512
Validation loss: 2.1801578609505086

Epoch: 6| Step: 12
Training loss: 0.28905148098537675
Validation loss: 2.2045883698179662

Epoch: 6| Step: 13
Training loss: 0.11646796900899584
Validation loss: 2.2041601656598777

Epoch: 409| Step: 0
Training loss: 0.2647473899840532
Validation loss: 2.19494197087514

Epoch: 6| Step: 1
Training loss: 0.21874190213337308
Validation loss: 2.2066655549979184

Epoch: 6| Step: 2
Training loss: 0.2708776816713737
Validation loss: 2.205112736719879

Epoch: 6| Step: 3
Training loss: 0.1875191519810588
Validation loss: 2.2259888671953205

Epoch: 6| Step: 4
Training loss: 0.18958281964103216
Validation loss: 2.1721268374552594

Epoch: 6| Step: 5
Training loss: 0.15106704857646053
Validation loss: 2.2219998218481702

Epoch: 6| Step: 6
Training loss: 0.24612135959333414
Validation loss: 2.141332143821103

Epoch: 6| Step: 7
Training loss: 0.20796808570853167
Validation loss: 2.174608045628094

Epoch: 6| Step: 8
Training loss: 0.19456608242115261
Validation loss: 2.164349566064175

Epoch: 6| Step: 9
Training loss: 0.16690375122352522
Validation loss: 2.163597418570127

Epoch: 6| Step: 10
Training loss: 0.12074144705647488
Validation loss: 2.1872300176240125

Epoch: 6| Step: 11
Training loss: 0.18805806239614262
Validation loss: 2.20719901160675

Epoch: 6| Step: 12
Training loss: 0.1476371104334513
Validation loss: 2.2141821505169093

Epoch: 6| Step: 13
Training loss: 0.10061153067749717
Validation loss: 2.228293828679481

Epoch: 410| Step: 0
Training loss: 0.24450432199527486
Validation loss: 2.2660290972624475

Epoch: 6| Step: 1
Training loss: 0.17794754533312682
Validation loss: 2.254182247679467

Epoch: 6| Step: 2
Training loss: 0.182508466863841
Validation loss: 2.2458434673752423

Epoch: 6| Step: 3
Training loss: 0.20967848653224475
Validation loss: 2.2460076085960927

Epoch: 6| Step: 4
Training loss: 0.10080621266048322
Validation loss: 2.2350566950531587

Epoch: 6| Step: 5
Training loss: 0.11025620028167767
Validation loss: 2.210493076075424

Epoch: 6| Step: 6
Training loss: 0.060156825220776235
Validation loss: 2.2630007710247204

Epoch: 6| Step: 7
Training loss: 0.15731052265659853
Validation loss: 2.221559300379852

Epoch: 6| Step: 8
Training loss: 0.18420947087920397
Validation loss: 2.2189144736207136

Epoch: 6| Step: 9
Training loss: 0.22493294339176814
Validation loss: 2.206585978911557

Epoch: 6| Step: 10
Training loss: 0.1996913614631015
Validation loss: 2.198516799540583

Epoch: 6| Step: 11
Training loss: 0.2539834858724191
Validation loss: 2.2251502505843566

Epoch: 6| Step: 12
Training loss: 0.16507779180490398
Validation loss: 2.2384451114102943

Epoch: 6| Step: 13
Training loss: 0.21783606308740994
Validation loss: 2.202227414641748

Epoch: 411| Step: 0
Training loss: 0.15939417237544176
Validation loss: 2.228135808357492

Epoch: 6| Step: 1
Training loss: 0.102995763702564
Validation loss: 2.2315055946193443

Epoch: 6| Step: 2
Training loss: 0.20751234154307704
Validation loss: 2.234497478859164

Epoch: 6| Step: 3
Training loss: 0.10523161897965615
Validation loss: 2.2483796257708164

Epoch: 6| Step: 4
Training loss: 0.21050215761139066
Validation loss: 2.2555796352076216

Epoch: 6| Step: 5
Training loss: 0.25421902392184476
Validation loss: 2.2568960463448997

Epoch: 6| Step: 6
Training loss: 0.23532181072939135
Validation loss: 2.3038740905327177

Epoch: 6| Step: 7
Training loss: 0.2637242865570598
Validation loss: 2.2445421369738803

Epoch: 6| Step: 8
Training loss: 0.09109184732625698
Validation loss: 2.222796970006504

Epoch: 6| Step: 9
Training loss: 0.12050850248216546
Validation loss: 2.2224180839817405

Epoch: 6| Step: 10
Training loss: 0.15548981279477328
Validation loss: 2.2229032938772812

Epoch: 6| Step: 11
Training loss: 0.0936776269271416
Validation loss: 2.2450935688567863

Epoch: 6| Step: 12
Training loss: 0.09340521373441965
Validation loss: 2.260555824641376

Epoch: 6| Step: 13
Training loss: 0.10395941879792595
Validation loss: 2.229021034470982

Epoch: 412| Step: 0
Training loss: 0.25668000974331595
Validation loss: 2.1945499527354086

Epoch: 6| Step: 1
Training loss: 0.11836530163848664
Validation loss: 2.174152121592412

Epoch: 6| Step: 2
Training loss: 0.18481526947849033
Validation loss: 2.197153112668764

Epoch: 6| Step: 3
Training loss: 0.1103249239206646
Validation loss: 2.2159805160034773

Epoch: 6| Step: 4
Training loss: 0.09538657034521042
Validation loss: 2.217182908772497

Epoch: 6| Step: 5
Training loss: 0.24457911976515892
Validation loss: 2.2049985605119415

Epoch: 6| Step: 6
Training loss: 0.19328561975262387
Validation loss: 2.171909318134777

Epoch: 6| Step: 7
Training loss: 0.17353438085791748
Validation loss: 2.1665304843599906

Epoch: 6| Step: 8
Training loss: 0.12137659556988163
Validation loss: 2.184089111503867

Epoch: 6| Step: 9
Training loss: 0.11795215679463121
Validation loss: 2.1989333645296893

Epoch: 6| Step: 10
Training loss: 0.1901771337878885
Validation loss: 2.1836456633717622

Epoch: 6| Step: 11
Training loss: 0.23644546874309164
Validation loss: 2.179778752082014

Epoch: 6| Step: 12
Training loss: 0.0964055026611222
Validation loss: 2.1669736586324184

Epoch: 6| Step: 13
Training loss: 0.13880071564788424
Validation loss: 2.1990227955590087

Epoch: 413| Step: 0
Training loss: 0.09157096681246356
Validation loss: 2.208309706501363

Epoch: 6| Step: 1
Training loss: 0.19027155644006413
Validation loss: 2.1923367596118286

Epoch: 6| Step: 2
Training loss: 0.19488396361915786
Validation loss: 2.2166099655661466

Epoch: 6| Step: 3
Training loss: 0.11276551527678956
Validation loss: 2.2198885813099483

Epoch: 6| Step: 4
Training loss: 0.23720711794051075
Validation loss: 2.2209217627952347

Epoch: 6| Step: 5
Training loss: 0.12267306100240193
Validation loss: 2.2209083842580184

Epoch: 6| Step: 6
Training loss: 0.17300190825732917
Validation loss: 2.239827356878298

Epoch: 6| Step: 7
Training loss: 0.17393103778484434
Validation loss: 2.2412273747662224

Epoch: 6| Step: 8
Training loss: 0.1558070938841899
Validation loss: 2.2282892658121254

Epoch: 6| Step: 9
Training loss: 0.15027883015756943
Validation loss: 2.218991354432997

Epoch: 6| Step: 10
Training loss: 0.2487137308468635
Validation loss: 2.228138489199057

Epoch: 6| Step: 11
Training loss: 0.24923182725228962
Validation loss: 2.2135709996363997

Epoch: 6| Step: 12
Training loss: 0.23720805237425835
Validation loss: 2.2280582132797293

Epoch: 6| Step: 13
Training loss: 0.11623295407145263
Validation loss: 2.2490725576985033

Epoch: 414| Step: 0
Training loss: 0.1485721328927928
Validation loss: 2.239061876293518

Epoch: 6| Step: 1
Training loss: 0.14924653328890178
Validation loss: 2.2559862528478263

Epoch: 6| Step: 2
Training loss: 0.11793727233745473
Validation loss: 2.2417094689469446

Epoch: 6| Step: 3
Training loss: 0.27506377391004455
Validation loss: 2.289411916344305

Epoch: 6| Step: 4
Training loss: 0.15730713621913928
Validation loss: 2.255833618659112

Epoch: 6| Step: 5
Training loss: 0.22255271043487504
Validation loss: 2.251904578221454

Epoch: 6| Step: 6
Training loss: 0.19609891877068397
Validation loss: 2.2052549043195446

Epoch: 6| Step: 7
Training loss: 0.18607210808569224
Validation loss: 2.218406406843253

Epoch: 6| Step: 8
Training loss: 0.27634249196062227
Validation loss: 2.188822062863346

Epoch: 6| Step: 9
Training loss: 0.19574385693107882
Validation loss: 2.184760979156425

Epoch: 6| Step: 10
Training loss: 0.10509330983683697
Validation loss: 2.1876603649324555

Epoch: 6| Step: 11
Training loss: 0.14416823032345188
Validation loss: 2.1751627724305003

Epoch: 6| Step: 12
Training loss: 0.27008116641220425
Validation loss: 2.161817435184695

Epoch: 6| Step: 13
Training loss: 0.1167214982859499
Validation loss: 2.2255326093202212

Epoch: 415| Step: 0
Training loss: 0.2422118174742383
Validation loss: 2.1586742864764106

Epoch: 6| Step: 1
Training loss: 0.07362597367985921
Validation loss: 2.177074035712602

Epoch: 6| Step: 2
Training loss: 0.15261302893513595
Validation loss: 2.191460163549344

Epoch: 6| Step: 3
Training loss: 0.09862910159844562
Validation loss: 2.157349736287398

Epoch: 6| Step: 4
Training loss: 0.15490822457306933
Validation loss: 2.2029314833967435

Epoch: 6| Step: 5
Training loss: 0.19036985582250743
Validation loss: 2.204194101800675

Epoch: 6| Step: 6
Training loss: 0.13062734102131748
Validation loss: 2.201265875903445

Epoch: 6| Step: 7
Training loss: 0.1883848688695774
Validation loss: 2.202824888877466

Epoch: 6| Step: 8
Training loss: 0.2560726034383924
Validation loss: 2.2031775818601353

Epoch: 6| Step: 9
Training loss: 0.0990397067502306
Validation loss: 2.1886356177701023

Epoch: 6| Step: 10
Training loss: 0.15886635746585445
Validation loss: 2.171651120884979

Epoch: 6| Step: 11
Training loss: 0.21848701949920887
Validation loss: 2.181255354038631

Epoch: 6| Step: 12
Training loss: 0.16640963640483503
Validation loss: 2.2052926168368896

Epoch: 6| Step: 13
Training loss: 0.09405698780688304
Validation loss: 2.171314187458188

Epoch: 416| Step: 0
Training loss: 0.14242644275992827
Validation loss: 2.1840906262667383

Epoch: 6| Step: 1
Training loss: 0.1179206405838888
Validation loss: 2.183860268123345

Epoch: 6| Step: 2
Training loss: 0.12794276163400442
Validation loss: 2.2113147325217786

Epoch: 6| Step: 3
Training loss: 0.12633839475258823
Validation loss: 2.198934001087216

Epoch: 6| Step: 4
Training loss: 0.09693893199627862
Validation loss: 2.212143312974751

Epoch: 6| Step: 5
Training loss: 0.14483277339967904
Validation loss: 2.1846888009447847

Epoch: 6| Step: 6
Training loss: 0.18834356448106
Validation loss: 2.2254816609417336

Epoch: 6| Step: 7
Training loss: 0.24892015746368581
Validation loss: 2.174072547893187

Epoch: 6| Step: 8
Training loss: 0.23818209414227048
Validation loss: 2.2080207281495103

Epoch: 6| Step: 9
Training loss: 0.2761879869048019
Validation loss: 2.2060119766837554

Epoch: 6| Step: 10
Training loss: 0.2135953002348805
Validation loss: 2.1914033089675544

Epoch: 6| Step: 11
Training loss: 0.19418641669048248
Validation loss: 2.1833627887471385

Epoch: 6| Step: 12
Training loss: 0.20068852216697278
Validation loss: 2.2423613654767536

Epoch: 6| Step: 13
Training loss: 0.08925618456100941
Validation loss: 2.189178043505189

Epoch: 417| Step: 0
Training loss: 0.14153296025599557
Validation loss: 2.216054111350256

Epoch: 6| Step: 1
Training loss: 0.15726539179732063
Validation loss: 2.207765217277744

Epoch: 6| Step: 2
Training loss: 0.12230413549463737
Validation loss: 2.176108494764972

Epoch: 6| Step: 3
Training loss: 0.11827265659721811
Validation loss: 2.1771904193416196

Epoch: 6| Step: 4
Training loss: 0.11850776026411085
Validation loss: 2.1430334098650894

Epoch: 6| Step: 5
Training loss: 0.18935074940506214
Validation loss: 2.154598027124307

Epoch: 6| Step: 6
Training loss: 0.19496403125531656
Validation loss: 2.1572901348374907

Epoch: 6| Step: 7
Training loss: 0.16121587057586856
Validation loss: 2.1541730756119444

Epoch: 6| Step: 8
Training loss: 0.13507915734712367
Validation loss: 2.163301188789158

Epoch: 6| Step: 9
Training loss: 0.16651963414164836
Validation loss: 2.183898399689256

Epoch: 6| Step: 10
Training loss: 0.22583487840654135
Validation loss: 2.202007572649209

Epoch: 6| Step: 11
Training loss: 0.19686531769694773
Validation loss: 2.2125007184449634

Epoch: 6| Step: 12
Training loss: 0.21162952710833774
Validation loss: 2.255013257634283

Epoch: 6| Step: 13
Training loss: 0.3030263046950027
Validation loss: 2.210906891766937

Epoch: 418| Step: 0
Training loss: 0.1905852342777527
Validation loss: 2.221536928007774

Epoch: 6| Step: 1
Training loss: 0.09957201575000602
Validation loss: 2.241645922802914

Epoch: 6| Step: 2
Training loss: 0.22930647457895456
Validation loss: 2.219004007439569

Epoch: 6| Step: 3
Training loss: 0.2732308151572543
Validation loss: 2.213158280952936

Epoch: 6| Step: 4
Training loss: 0.07224561762285468
Validation loss: 2.2372019185779104

Epoch: 6| Step: 5
Training loss: 0.2006535936936351
Validation loss: 2.272548887387426

Epoch: 6| Step: 6
Training loss: 0.14305002685107954
Validation loss: 2.2421034999103844

Epoch: 6| Step: 7
Training loss: 0.15287931764958973
Validation loss: 2.2356049101152418

Epoch: 6| Step: 8
Training loss: 0.16279166048893828
Validation loss: 2.230011474487517

Epoch: 6| Step: 9
Training loss: 0.20263295917010768
Validation loss: 2.2599588921776115

Epoch: 6| Step: 10
Training loss: 0.1151025227893916
Validation loss: 2.2365024614587026

Epoch: 6| Step: 11
Training loss: 0.13438470883004752
Validation loss: 2.249780696062133

Epoch: 6| Step: 12
Training loss: 0.14314512619371692
Validation loss: 2.2444863711483074

Epoch: 6| Step: 13
Training loss: 0.21555635873159754
Validation loss: 2.2340804316836205

Epoch: 419| Step: 0
Training loss: 0.1942527823120046
Validation loss: 2.2013547533313296

Epoch: 6| Step: 1
Training loss: 0.14896374828215414
Validation loss: 2.2271689325479587

Epoch: 6| Step: 2
Training loss: 0.20180428736856262
Validation loss: 2.197413341155542

Epoch: 6| Step: 3
Training loss: 0.12215319680633382
Validation loss: 2.1994646111598493

Epoch: 6| Step: 4
Training loss: 0.11913079862251424
Validation loss: 2.1895150485825767

Epoch: 6| Step: 5
Training loss: 0.1240674526477584
Validation loss: 2.167871464057239

Epoch: 6| Step: 6
Training loss: 0.19335643689013715
Validation loss: 2.156824313368309

Epoch: 6| Step: 7
Training loss: 0.09414450768026139
Validation loss: 2.1670882920717944

Epoch: 6| Step: 8
Training loss: 0.15043721158673953
Validation loss: 2.142162726676632

Epoch: 6| Step: 9
Training loss: 0.12565010116567762
Validation loss: 2.1635020532715576

Epoch: 6| Step: 10
Training loss: 0.2289394458747417
Validation loss: 2.1642053951656544

Epoch: 6| Step: 11
Training loss: 0.2805002338303052
Validation loss: 2.1600404368728365

Epoch: 6| Step: 12
Training loss: 0.12180343446324995
Validation loss: 2.1587424393641825

Epoch: 6| Step: 13
Training loss: 0.1950910361695611
Validation loss: 2.155186831384

Epoch: 420| Step: 0
Training loss: 0.11863005393435055
Validation loss: 2.1577516118286044

Epoch: 6| Step: 1
Training loss: 0.1164940183141461
Validation loss: 2.174898338087183

Epoch: 6| Step: 2
Training loss: 0.270655292286867
Validation loss: 2.2102591187212246

Epoch: 6| Step: 3
Training loss: 0.12218394521874118
Validation loss: 2.1877663908687515

Epoch: 6| Step: 4
Training loss: 0.12381874298630792
Validation loss: 2.198721020340192

Epoch: 6| Step: 5
Training loss: 0.21608090095631957
Validation loss: 2.1867153008416462

Epoch: 6| Step: 6
Training loss: 0.12205435457826992
Validation loss: 2.1908350321727013

Epoch: 6| Step: 7
Training loss: 0.20039038109718038
Validation loss: 2.22047106718662

Epoch: 6| Step: 8
Training loss: 0.08312640694004785
Validation loss: 2.2229662346587977

Epoch: 6| Step: 9
Training loss: 0.20511003881727588
Validation loss: 2.2328023977648246

Epoch: 6| Step: 10
Training loss: 0.09850028548586569
Validation loss: 2.229996063929385

Epoch: 6| Step: 11
Training loss: 0.16307351070731624
Validation loss: 2.20916148550198

Epoch: 6| Step: 12
Training loss: 0.23001291973429594
Validation loss: 2.2299887787966868

Epoch: 6| Step: 13
Training loss: 0.25614022718212626
Validation loss: 2.225828787424219

Epoch: 421| Step: 0
Training loss: 0.28440580515590425
Validation loss: 2.2389975119052816

Epoch: 6| Step: 1
Training loss: 0.1872299156469697
Validation loss: 2.269545995624736

Epoch: 6| Step: 2
Training loss: 0.17935240639804886
Validation loss: 2.244954718091934

Epoch: 6| Step: 3
Training loss: 0.18062440591602238
Validation loss: 2.2115859727176446

Epoch: 6| Step: 4
Training loss: 0.17377548277898577
Validation loss: 2.2120422481156163

Epoch: 6| Step: 5
Training loss: 0.15774306762232132
Validation loss: 2.2073701250431266

Epoch: 6| Step: 6
Training loss: 0.14440972786780795
Validation loss: 2.2153814564153453

Epoch: 6| Step: 7
Training loss: 0.15875945759558174
Validation loss: 2.266020474201903

Epoch: 6| Step: 8
Training loss: 0.17996458789724204
Validation loss: 2.226985473410531

Epoch: 6| Step: 9
Training loss: 0.1401651931703483
Validation loss: 2.2008260675544506

Epoch: 6| Step: 10
Training loss: 0.23332223486192222
Validation loss: 2.187046441142025

Epoch: 6| Step: 11
Training loss: 0.0966581214587326
Validation loss: 2.178768369206255

Epoch: 6| Step: 12
Training loss: 0.22483647516979577
Validation loss: 2.1617184931756332

Epoch: 6| Step: 13
Training loss: 0.13714511329492382
Validation loss: 2.203289362433735

Epoch: 422| Step: 0
Training loss: 0.2050258297319325
Validation loss: 2.185001442948351

Epoch: 6| Step: 1
Training loss: 0.18455649632004034
Validation loss: 2.207500522652345

Epoch: 6| Step: 2
Training loss: 0.13023008085470159
Validation loss: 2.2109175467778392

Epoch: 6| Step: 3
Training loss: 0.3291408390865721
Validation loss: 2.2066613990477437

Epoch: 6| Step: 4
Training loss: 0.15819061488856886
Validation loss: 2.219548962143955

Epoch: 6| Step: 5
Training loss: 0.21737565288423719
Validation loss: 2.236980436274264

Epoch: 6| Step: 6
Training loss: 0.09367676695902415
Validation loss: 2.226400402640145

Epoch: 6| Step: 7
Training loss: 0.12252221574461811
Validation loss: 2.256322989988826

Epoch: 6| Step: 8
Training loss: 0.13663321271566517
Validation loss: 2.2272488238447874

Epoch: 6| Step: 9
Training loss: 0.17980874159156446
Validation loss: 2.242148436565168

Epoch: 6| Step: 10
Training loss: 0.1896629646151016
Validation loss: 2.232778846341688

Epoch: 6| Step: 11
Training loss: 0.1664417296182668
Validation loss: 2.2321971086510257

Epoch: 6| Step: 12
Training loss: 0.12374237457898035
Validation loss: 2.201050086662644

Epoch: 6| Step: 13
Training loss: 0.1315974020250759
Validation loss: 2.187417148011368

Epoch: 423| Step: 0
Training loss: 0.17164388745540674
Validation loss: 2.1992351887126684

Epoch: 6| Step: 1
Training loss: 0.13238891202551625
Validation loss: 2.193699789394372

Epoch: 6| Step: 2
Training loss: 0.05050793326172402
Validation loss: 2.186027179876178

Epoch: 6| Step: 3
Training loss: 0.14241364541605583
Validation loss: 2.198632643940747

Epoch: 6| Step: 4
Training loss: 0.15084617531318142
Validation loss: 2.169249997340947

Epoch: 6| Step: 5
Training loss: 0.3090674952844865
Validation loss: 2.1791916879222795

Epoch: 6| Step: 6
Training loss: 0.22436888715657527
Validation loss: 2.174495153213005

Epoch: 6| Step: 7
Training loss: 0.17522196274641044
Validation loss: 2.1915940771672333

Epoch: 6| Step: 8
Training loss: 0.21994704310859234
Validation loss: 2.178286885119875

Epoch: 6| Step: 9
Training loss: 0.12343691889107004
Validation loss: 2.180530403494119

Epoch: 6| Step: 10
Training loss: 0.1868693155680822
Validation loss: 2.1885719778386235

Epoch: 6| Step: 11
Training loss: 0.1281339528863572
Validation loss: 2.20597361375655

Epoch: 6| Step: 12
Training loss: 0.1503419921318687
Validation loss: 2.185495470720259

Epoch: 6| Step: 13
Training loss: 0.16490474291191037
Validation loss: 2.203705124151653

Epoch: 424| Step: 0
Training loss: 0.23918711337857465
Validation loss: 2.2105876895608643

Epoch: 6| Step: 1
Training loss: 0.21973480209160431
Validation loss: 2.184443726329065

Epoch: 6| Step: 2
Training loss: 0.2031060906925358
Validation loss: 2.194316442006812

Epoch: 6| Step: 3
Training loss: 0.23713268121495729
Validation loss: 2.188701112373315

Epoch: 6| Step: 4
Training loss: 0.1485254504000325
Validation loss: 2.1829786038637233

Epoch: 6| Step: 5
Training loss: 0.10811210308721014
Validation loss: 2.1547217800859104

Epoch: 6| Step: 6
Training loss: 0.19342552363677462
Validation loss: 2.1688198610639167

Epoch: 6| Step: 7
Training loss: 0.07201025600515214
Validation loss: 2.218788017237262

Epoch: 6| Step: 8
Training loss: 0.10745205888639477
Validation loss: 2.1818227763234797

Epoch: 6| Step: 9
Training loss: 0.1685140927739843
Validation loss: 2.1622094598817796

Epoch: 6| Step: 10
Training loss: 0.13012895707811437
Validation loss: 2.158920208898654

Epoch: 6| Step: 11
Training loss: 0.19918441476578067
Validation loss: 2.2268413554023407

Epoch: 6| Step: 12
Training loss: 0.14908816130699268
Validation loss: 2.2127619764428874

Epoch: 6| Step: 13
Training loss: 0.060803318310800034
Validation loss: 2.2091671473726553

Epoch: 425| Step: 0
Training loss: 0.12704467406904008
Validation loss: 2.2293944260201912

Epoch: 6| Step: 1
Training loss: 0.27833705650959306
Validation loss: 2.1969329682801715

Epoch: 6| Step: 2
Training loss: 0.193549707927991
Validation loss: 2.228604926088724

Epoch: 6| Step: 3
Training loss: 0.15702296633720644
Validation loss: 2.2247216874083655

Epoch: 6| Step: 4
Training loss: 0.22400705598570325
Validation loss: 2.232532728751973

Epoch: 6| Step: 5
Training loss: 0.21319970608685615
Validation loss: 2.2347726741225125

Epoch: 6| Step: 6
Training loss: 0.14271115929063274
Validation loss: 2.2161130063436567

Epoch: 6| Step: 7
Training loss: 0.10952557264054005
Validation loss: 2.2695512289768662

Epoch: 6| Step: 8
Training loss: 0.14299857188141898
Validation loss: 2.2626937659503414

Epoch: 6| Step: 9
Training loss: 0.15453792406216973
Validation loss: 2.270253801713037

Epoch: 6| Step: 10
Training loss: 0.11301465563290479
Validation loss: 2.2544639757392897

Epoch: 6| Step: 11
Training loss: 0.11993985926567378
Validation loss: 2.2276918349039083

Epoch: 6| Step: 12
Training loss: 0.11927851530042848
Validation loss: 2.2450159683772335

Epoch: 6| Step: 13
Training loss: 0.08299245411775186
Validation loss: 2.211844784216443

Epoch: 426| Step: 0
Training loss: 0.19045943003470656
Validation loss: 2.211351937385457

Epoch: 6| Step: 1
Training loss: 0.21864664667501343
Validation loss: 2.1938867856866766

Epoch: 6| Step: 2
Training loss: 0.0666719269105268
Validation loss: 2.219052291999066

Epoch: 6| Step: 3
Training loss: 0.166044933873471
Validation loss: 2.1847288330990007

Epoch: 6| Step: 4
Training loss: 0.1167905282685135
Validation loss: 2.1963556034896863

Epoch: 6| Step: 5
Training loss: 0.09897282979425825
Validation loss: 2.180290250268789

Epoch: 6| Step: 6
Training loss: 0.10548625465230459
Validation loss: 2.1740027942561966

Epoch: 6| Step: 7
Training loss: 0.2534416496369877
Validation loss: 2.1814768698867146

Epoch: 6| Step: 8
Training loss: 0.13141505557753666
Validation loss: 2.2016825134389424

Epoch: 6| Step: 9
Training loss: 0.15960399267576145
Validation loss: 2.199915581493067

Epoch: 6| Step: 10
Training loss: 0.1228762457814518
Validation loss: 2.193378573940793

Epoch: 6| Step: 11
Training loss: 0.09644309388579592
Validation loss: 2.2111651914529418

Epoch: 6| Step: 12
Training loss: 0.24877151012869014
Validation loss: 2.2093213015729063

Epoch: 6| Step: 13
Training loss: 0.14842341381294927
Validation loss: 2.21182975185502

Epoch: 427| Step: 0
Training loss: 0.14008013815850678
Validation loss: 2.210066403399336

Epoch: 6| Step: 1
Training loss: 0.28567658595016054
Validation loss: 2.217664894376755

Epoch: 6| Step: 2
Training loss: 0.08071812014476179
Validation loss: 2.2392826461311164

Epoch: 6| Step: 3
Training loss: 0.13065300511215502
Validation loss: 2.216737092063861

Epoch: 6| Step: 4
Training loss: 0.11022490431657489
Validation loss: 2.248577363196833

Epoch: 6| Step: 5
Training loss: 0.12193128679871242
Validation loss: 2.239079248161202

Epoch: 6| Step: 6
Training loss: 0.17083316101282625
Validation loss: 2.2448090059942967

Epoch: 6| Step: 7
Training loss: 0.14213523926123364
Validation loss: 2.239706324419401

Epoch: 6| Step: 8
Training loss: 0.11627685857003868
Validation loss: 2.2295960956792893

Epoch: 6| Step: 9
Training loss: 0.08635793598405514
Validation loss: 2.2405120499859272

Epoch: 6| Step: 10
Training loss: 0.25738012296516444
Validation loss: 2.221665482699331

Epoch: 6| Step: 11
Training loss: 0.11930178076969035
Validation loss: 2.252903495408135

Epoch: 6| Step: 12
Training loss: 0.15738322467423332
Validation loss: 2.2498604698168903

Epoch: 6| Step: 13
Training loss: 0.1866929247884994
Validation loss: 2.2172224906789624

Epoch: 428| Step: 0
Training loss: 0.12750482260241322
Validation loss: 2.2143383127619676

Epoch: 6| Step: 1
Training loss: 0.1286738352345426
Validation loss: 2.2077441394993293

Epoch: 6| Step: 2
Training loss: 0.24528224296820822
Validation loss: 2.183273673242459

Epoch: 6| Step: 3
Training loss: 0.12414635176920338
Validation loss: 2.2025550285943187

Epoch: 6| Step: 4
Training loss: 0.2007667851711053
Validation loss: 2.181509624713158

Epoch: 6| Step: 5
Training loss: 0.19010806188555496
Validation loss: 2.191599288444984

Epoch: 6| Step: 6
Training loss: 0.1115124581806518
Validation loss: 2.1829725393706463

Epoch: 6| Step: 7
Training loss: 0.15286222896896592
Validation loss: 2.219503409114728

Epoch: 6| Step: 8
Training loss: 0.10916103995390872
Validation loss: 2.192429443524141

Epoch: 6| Step: 9
Training loss: 0.24429938685605293
Validation loss: 2.1959636517945245

Epoch: 6| Step: 10
Training loss: 0.1829510049986257
Validation loss: 2.1897778723705836

Epoch: 6| Step: 11
Training loss: 0.08625072055667699
Validation loss: 2.181444736838585

Epoch: 6| Step: 12
Training loss: 0.15003064657104653
Validation loss: 2.189426297070487

Epoch: 6| Step: 13
Training loss: 0.18062337468745893
Validation loss: 2.1995525231774375

Epoch: 429| Step: 0
Training loss: 0.1414921502283955
Validation loss: 2.1872358968429517

Epoch: 6| Step: 1
Training loss: 0.11831863004156368
Validation loss: 2.1948858757510927

Epoch: 6| Step: 2
Training loss: 0.1442790602038013
Validation loss: 2.2229464505297716

Epoch: 6| Step: 3
Training loss: 0.20647342674509553
Validation loss: 2.226556690081112

Epoch: 6| Step: 4
Training loss: 0.14875243056739798
Validation loss: 2.2109275663141026

Epoch: 6| Step: 5
Training loss: 0.09529049631090757
Validation loss: 2.2105003361587947

Epoch: 6| Step: 6
Training loss: 0.14506738046722217
Validation loss: 2.2417582942584637

Epoch: 6| Step: 7
Training loss: 0.2411854996955368
Validation loss: 2.216912478833863

Epoch: 6| Step: 8
Training loss: 0.10973043250935151
Validation loss: 2.229864638178787

Epoch: 6| Step: 9
Training loss: 0.16062638432466547
Validation loss: 2.2421142776548333

Epoch: 6| Step: 10
Training loss: 0.10067216177418023
Validation loss: 2.235380308420974

Epoch: 6| Step: 11
Training loss: 0.21311617635824562
Validation loss: 2.186855972577189

Epoch: 6| Step: 12
Training loss: 0.19410245854107014
Validation loss: 2.206233962689009

Epoch: 6| Step: 13
Training loss: 0.09439500318046565
Validation loss: 2.227462665463242

Epoch: 430| Step: 0
Training loss: 0.153385561525787
Validation loss: 2.177672908707742

Epoch: 6| Step: 1
Training loss: 0.1356790107424186
Validation loss: 2.1772760018558874

Epoch: 6| Step: 2
Training loss: 0.13043342843164776
Validation loss: 2.216449551940795

Epoch: 6| Step: 3
Training loss: 0.12902472571325538
Validation loss: 2.166343929574693

Epoch: 6| Step: 4
Training loss: 0.2707250528413195
Validation loss: 2.1696818053459688

Epoch: 6| Step: 5
Training loss: 0.11023707062786539
Validation loss: 2.178175409186575

Epoch: 6| Step: 6
Training loss: 0.11093958597505528
Validation loss: 2.176626273357701

Epoch: 6| Step: 7
Training loss: 0.1500371395266931
Validation loss: 2.160137226942439

Epoch: 6| Step: 8
Training loss: 0.2803673138391904
Validation loss: 2.1872568795246035

Epoch: 6| Step: 9
Training loss: 0.14741952579892714
Validation loss: 2.2010080637781986

Epoch: 6| Step: 10
Training loss: 0.14811414081267626
Validation loss: 2.199187378319091

Epoch: 6| Step: 11
Training loss: 0.11239423913181582
Validation loss: 2.193859377450708

Epoch: 6| Step: 12
Training loss: 0.14142471319395092
Validation loss: 2.1742129481162675

Epoch: 6| Step: 13
Training loss: 0.17737219662161408
Validation loss: 2.187154136071195

Epoch: 431| Step: 0
Training loss: 0.10227686647566706
Validation loss: 2.1871747960309476

Epoch: 6| Step: 1
Training loss: 0.14255863213215228
Validation loss: 2.200849118725829

Epoch: 6| Step: 2
Training loss: 0.24294269397523058
Validation loss: 2.2220941011435413

Epoch: 6| Step: 3
Training loss: 0.14392959529623417
Validation loss: 2.2084518850835497

Epoch: 6| Step: 4
Training loss: 0.12168604449938253
Validation loss: 2.2253964139556444

Epoch: 6| Step: 5
Training loss: 0.26870251834954184
Validation loss: 2.2340649946857796

Epoch: 6| Step: 6
Training loss: 0.19653717416104152
Validation loss: 2.235054162445488

Epoch: 6| Step: 7
Training loss: 0.19229770849978237
Validation loss: 2.22576503436843

Epoch: 6| Step: 8
Training loss: 0.10513578945644249
Validation loss: 2.21162006528945

Epoch: 6| Step: 9
Training loss: 0.11961873848192177
Validation loss: 2.2490328940123887

Epoch: 6| Step: 10
Training loss: 0.12652567280569924
Validation loss: 2.2360855073388035

Epoch: 6| Step: 11
Training loss: 0.14714681249277714
Validation loss: 2.22072026673837

Epoch: 6| Step: 12
Training loss: 0.11706014308985506
Validation loss: 2.225169589990623

Epoch: 6| Step: 13
Training loss: 0.17375349199950568
Validation loss: 2.222206526255636

Epoch: 432| Step: 0
Training loss: 0.12359203943884557
Validation loss: 2.219407910293783

Epoch: 6| Step: 1
Training loss: 0.16308782199524632
Validation loss: 2.2251925888721207

Epoch: 6| Step: 2
Training loss: 0.09032839174929053
Validation loss: 2.226248355761301

Epoch: 6| Step: 3
Training loss: 0.12049474150686358
Validation loss: 2.2531514924681755

Epoch: 6| Step: 4
Training loss: 0.1351354886244487
Validation loss: 2.234991295390065

Epoch: 6| Step: 5
Training loss: 0.14942986897154248
Validation loss: 2.254255015486353

Epoch: 6| Step: 6
Training loss: 0.11158037469222817
Validation loss: 2.2295646998315717

Epoch: 6| Step: 7
Training loss: 0.14362843883164142
Validation loss: 2.2374624853563443

Epoch: 6| Step: 8
Training loss: 0.17099832068212661
Validation loss: 2.208601174583892

Epoch: 6| Step: 9
Training loss: 0.2988654967232671
Validation loss: 2.207909890749114

Epoch: 6| Step: 10
Training loss: 0.08024526517056162
Validation loss: 2.235302046167881

Epoch: 6| Step: 11
Training loss: 0.13697592525369848
Validation loss: 2.1715613565338976

Epoch: 6| Step: 12
Training loss: 0.25106750503044867
Validation loss: 2.2126372313842833

Epoch: 6| Step: 13
Training loss: 0.13635064706881392
Validation loss: 2.212202839946797

Epoch: 433| Step: 0
Training loss: 0.2173646588555634
Validation loss: 2.208239428179262

Epoch: 6| Step: 1
Training loss: 0.17734348364318472
Validation loss: 2.2274704652627344

Epoch: 6| Step: 2
Training loss: 0.17759902747168263
Validation loss: 2.2464963370795803

Epoch: 6| Step: 3
Training loss: 0.08383049285189541
Validation loss: 2.270866414875599

Epoch: 6| Step: 4
Training loss: 0.13138703107052457
Validation loss: 2.264365696386906

Epoch: 6| Step: 5
Training loss: 0.23099141741988188
Validation loss: 2.279326341026994

Epoch: 6| Step: 6
Training loss: 0.11866501163628233
Validation loss: 2.246483446354042

Epoch: 6| Step: 7
Training loss: 0.19724548350325796
Validation loss: 2.2486696759822453

Epoch: 6| Step: 8
Training loss: 0.14698070364683993
Validation loss: 2.2481965479287274

Epoch: 6| Step: 9
Training loss: 0.09018526784608942
Validation loss: 2.2798779084254037

Epoch: 6| Step: 10
Training loss: 0.17408461346375498
Validation loss: 2.2198825056303155

Epoch: 6| Step: 11
Training loss: 0.10845454799997443
Validation loss: 2.230582998776415

Epoch: 6| Step: 12
Training loss: 0.1422051162077335
Validation loss: 2.2355293110753944

Epoch: 6| Step: 13
Training loss: 0.10361970311720559
Validation loss: 2.2172477127480064

Epoch: 434| Step: 0
Training loss: 0.15444519061179704
Validation loss: 2.2360165176284883

Epoch: 6| Step: 1
Training loss: 0.15432573603864408
Validation loss: 2.230000780226762

Epoch: 6| Step: 2
Training loss: 0.1460766203420593
Validation loss: 2.252871402781825

Epoch: 6| Step: 3
Training loss: 0.22917812853384206
Validation loss: 2.273850821518403

Epoch: 6| Step: 4
Training loss: 0.133664609286872
Validation loss: 2.26747084444012

Epoch: 6| Step: 5
Training loss: 0.11635271207727828
Validation loss: 2.2464278394171138

Epoch: 6| Step: 6
Training loss: 0.2408176567382898
Validation loss: 2.3060036131534862

Epoch: 6| Step: 7
Training loss: 0.22214368750382404
Validation loss: 2.2849902761390717

Epoch: 6| Step: 8
Training loss: 0.206721947501806
Validation loss: 2.2667319824331598

Epoch: 6| Step: 9
Training loss: 0.11749857305613953
Validation loss: 2.2891192315967976

Epoch: 6| Step: 10
Training loss: 0.07589621978460764
Validation loss: 2.258538208262451

Epoch: 6| Step: 11
Training loss: 0.11450817522333878
Validation loss: 2.2647861793519337

Epoch: 6| Step: 12
Training loss: 0.13103227437913315
Validation loss: 2.2467036084430703

Epoch: 6| Step: 13
Training loss: 0.0974278066889633
Validation loss: 2.243690671446896

Epoch: 435| Step: 0
Training loss: 0.22232225531332972
Validation loss: 2.222247832759139

Epoch: 6| Step: 1
Training loss: 0.13540576163423299
Validation loss: 2.2571247136325616

Epoch: 6| Step: 2
Training loss: 0.13301801208286396
Validation loss: 2.2416051630281437

Epoch: 6| Step: 3
Training loss: 0.10720851690757494
Validation loss: 2.2088194387743045

Epoch: 6| Step: 4
Training loss: 0.13932719328071355
Validation loss: 2.215528680991922

Epoch: 6| Step: 5
Training loss: 0.24042711822103818
Validation loss: 2.199679046373086

Epoch: 6| Step: 6
Training loss: 0.0883086462680068
Validation loss: 2.2181316844672905

Epoch: 6| Step: 7
Training loss: 0.1130341597433815
Validation loss: 2.2005575011105356

Epoch: 6| Step: 8
Training loss: 0.10626963896729294
Validation loss: 2.22532623805606

Epoch: 6| Step: 9
Training loss: 0.18683428601510668
Validation loss: 2.1787654375890027

Epoch: 6| Step: 10
Training loss: 0.13388994687429842
Validation loss: 2.195813341974601

Epoch: 6| Step: 11
Training loss: 0.2163855714937137
Validation loss: 2.223118553293537

Epoch: 6| Step: 12
Training loss: 0.20962813860341212
Validation loss: 2.199772608193148

Epoch: 6| Step: 13
Training loss: 0.08461138463561636
Validation loss: 2.217213230335982

Epoch: 436| Step: 0
Training loss: 0.1697717419929762
Validation loss: 2.1602030420448943

Epoch: 6| Step: 1
Training loss: 0.24519253518775813
Validation loss: 2.180422490164328

Epoch: 6| Step: 2
Training loss: 0.12631515717106334
Validation loss: 2.217786238480472

Epoch: 6| Step: 3
Training loss: 0.1577320325714353
Validation loss: 2.232353308371161

Epoch: 6| Step: 4
Training loss: 0.23092454355154904
Validation loss: 2.209389188254202

Epoch: 6| Step: 5
Training loss: 0.09643806743949337
Validation loss: 2.1974803077526315

Epoch: 6| Step: 6
Training loss: 0.10910880529480842
Validation loss: 2.228036090265654

Epoch: 6| Step: 7
Training loss: 0.14385485245883936
Validation loss: 2.2557410671670977

Epoch: 6| Step: 8
Training loss: 0.1706907372595455
Validation loss: 2.2436306573007925

Epoch: 6| Step: 9
Training loss: 0.09841015204994145
Validation loss: 2.262433943630887

Epoch: 6| Step: 10
Training loss: 0.10798825592217344
Validation loss: 2.23794499249013

Epoch: 6| Step: 11
Training loss: 0.13643294160657382
Validation loss: 2.2737419776748147

Epoch: 6| Step: 12
Training loss: 0.2148820322782259
Validation loss: 2.2673571682467064

Epoch: 6| Step: 13
Training loss: 0.11779613197138872
Validation loss: 2.2310196327859906

Epoch: 437| Step: 0
Training loss: 0.06600317216830574
Validation loss: 2.2501832871430865

Epoch: 6| Step: 1
Training loss: 0.11313951603346374
Validation loss: 2.222610478640237

Epoch: 6| Step: 2
Training loss: 0.0684202944561459
Validation loss: 2.2529736776947713

Epoch: 6| Step: 3
Training loss: 0.09167978245291813
Validation loss: 2.225188371036187

Epoch: 6| Step: 4
Training loss: 0.17898453161731462
Validation loss: 2.2215958467061627

Epoch: 6| Step: 5
Training loss: 0.14958561292742503
Validation loss: 2.2550517764899336

Epoch: 6| Step: 6
Training loss: 0.10835466274254756
Validation loss: 2.2256598802798044

Epoch: 6| Step: 7
Training loss: 0.07917908413755469
Validation loss: 2.1969715538355232

Epoch: 6| Step: 8
Training loss: 0.14087917616085976
Validation loss: 2.225859755398247

Epoch: 6| Step: 9
Training loss: 0.24095178497458344
Validation loss: 2.197741361282238

Epoch: 6| Step: 10
Training loss: 0.2757418671927785
Validation loss: 2.2149346642536467

Epoch: 6| Step: 11
Training loss: 0.08876967057656747
Validation loss: 2.202455473441343

Epoch: 6| Step: 12
Training loss: 0.07536852999555518
Validation loss: 2.1935856876377775

Epoch: 6| Step: 13
Training loss: 0.07678558026920708
Validation loss: 2.181688799356365

Epoch: 438| Step: 0
Training loss: 0.10779728315607608
Validation loss: 2.208452954789568

Epoch: 6| Step: 1
Training loss: 0.2078741656141573
Validation loss: 2.204293104207863

Epoch: 6| Step: 2
Training loss: 0.20993297301962394
Validation loss: 2.219412816002957

Epoch: 6| Step: 3
Training loss: 0.1516585529878841
Validation loss: 2.2151725845991446

Epoch: 6| Step: 4
Training loss: 0.10575446969617955
Validation loss: 2.217799849700222

Epoch: 6| Step: 5
Training loss: 0.06103586196491425
Validation loss: 2.2431019673312864

Epoch: 6| Step: 6
Training loss: 0.1634085200274821
Validation loss: 2.2284131110967285

Epoch: 6| Step: 7
Training loss: 0.11940463316191409
Validation loss: 2.2254876280278353

Epoch: 6| Step: 8
Training loss: 0.17156726749758383
Validation loss: 2.223307205570379

Epoch: 6| Step: 9
Training loss: 0.10240712533191976
Validation loss: 2.2227891630344003

Epoch: 6| Step: 10
Training loss: 0.09413338293022558
Validation loss: 2.2322014085675774

Epoch: 6| Step: 11
Training loss: 0.12771619935752096
Validation loss: 2.2490856404688717

Epoch: 6| Step: 12
Training loss: 0.09890363827642436
Validation loss: 2.226400379610679

Epoch: 6| Step: 13
Training loss: 0.0755533297137387
Validation loss: 2.2224352819926025

Epoch: 439| Step: 0
Training loss: 0.10030801116103905
Validation loss: 2.200974991405456

Epoch: 6| Step: 1
Training loss: 0.050440853243484476
Validation loss: 2.216574174396368

Epoch: 6| Step: 2
Training loss: 0.13390795443995782
Validation loss: 2.2503742045848156

Epoch: 6| Step: 3
Training loss: 0.15665064943728718
Validation loss: 2.233534376775806

Epoch: 6| Step: 4
Training loss: 0.07643874503721818
Validation loss: 2.234085236323438

Epoch: 6| Step: 5
Training loss: 0.09051825941773735
Validation loss: 2.259115111676704

Epoch: 6| Step: 6
Training loss: 0.1457692683939472
Validation loss: 2.247350892471598

Epoch: 6| Step: 7
Training loss: 0.21815917573952437
Validation loss: 2.2372145763063505

Epoch: 6| Step: 8
Training loss: 0.24011553949796188
Validation loss: 2.2419194498644806

Epoch: 6| Step: 9
Training loss: 0.10737864751637874
Validation loss: 2.233128035713056

Epoch: 6| Step: 10
Training loss: 0.20596325911488342
Validation loss: 2.2253453305528206

Epoch: 6| Step: 11
Training loss: 0.13057946401623663
Validation loss: 2.249474034423921

Epoch: 6| Step: 12
Training loss: 0.1488028096773363
Validation loss: 2.216754772456307

Epoch: 6| Step: 13
Training loss: 0.11174229077095231
Validation loss: 2.2153053437134167

Epoch: 440| Step: 0
Training loss: 0.20939249670169804
Validation loss: 2.206401165037569

Epoch: 6| Step: 1
Training loss: 0.08779181383113735
Validation loss: 2.2154462656412677

Epoch: 6| Step: 2
Training loss: 0.059206124890547725
Validation loss: 2.248816134284006

Epoch: 6| Step: 3
Training loss: 0.15718006251999678
Validation loss: 2.238453290394026

Epoch: 6| Step: 4
Training loss: 0.16286559838894726
Validation loss: 2.237845539656574

Epoch: 6| Step: 5
Training loss: 0.11847238669125332
Validation loss: 2.2365850723448184

Epoch: 6| Step: 6
Training loss: 0.09499243656749813
Validation loss: 2.246238661447825

Epoch: 6| Step: 7
Training loss: 0.23174953987946248
Validation loss: 2.2401855319235757

Epoch: 6| Step: 8
Training loss: 0.1436767124380139
Validation loss: 2.2411673810211927

Epoch: 6| Step: 9
Training loss: 0.21653738902876993
Validation loss: 2.2549184060410394

Epoch: 6| Step: 10
Training loss: 0.13055161682685146
Validation loss: 2.2693363872963643

Epoch: 6| Step: 11
Training loss: 0.09582939867653253
Validation loss: 2.2287374866683147

Epoch: 6| Step: 12
Training loss: 0.17450542513316747
Validation loss: 2.209126311138942

Epoch: 6| Step: 13
Training loss: 0.08273101263535268
Validation loss: 2.206484847729103

Epoch: 441| Step: 0
Training loss: 0.08614777448026631
Validation loss: 2.220537421537718

Epoch: 6| Step: 1
Training loss: 0.07726084089752026
Validation loss: 2.2183381836125347

Epoch: 6| Step: 2
Training loss: 0.12320784983649198
Validation loss: 2.2284802160108175

Epoch: 6| Step: 3
Training loss: 0.15198147933325518
Validation loss: 2.234489887730851

Epoch: 6| Step: 4
Training loss: 0.08560814111565027
Validation loss: 2.264318099576366

Epoch: 6| Step: 5
Training loss: 0.23068926654946456
Validation loss: 2.272430487828966

Epoch: 6| Step: 6
Training loss: 0.1627212547236212
Validation loss: 2.2743071438484455

Epoch: 6| Step: 7
Training loss: 0.29521824932247737
Validation loss: 2.2487045618508867

Epoch: 6| Step: 8
Training loss: 0.10655108280211237
Validation loss: 2.2929286118584096

Epoch: 6| Step: 9
Training loss: 0.14049659933483463
Validation loss: 2.2631855992981786

Epoch: 6| Step: 10
Training loss: 0.0961078338846786
Validation loss: 2.2408076513885162

Epoch: 6| Step: 11
Training loss: 0.09185756543877387
Validation loss: 2.2201857704157

Epoch: 6| Step: 12
Training loss: 0.14763788633847494
Validation loss: 2.2618155028275084

Epoch: 6| Step: 13
Training loss: 0.0475112898132224
Validation loss: 2.214084633835048

Epoch: 442| Step: 0
Training loss: 0.09471692203348663
Validation loss: 2.2225544347482225

Epoch: 6| Step: 1
Training loss: 0.23911390063643223
Validation loss: 2.24138903806423

Epoch: 6| Step: 2
Training loss: 0.1270398650585348
Validation loss: 2.1967709748346023

Epoch: 6| Step: 3
Training loss: 0.09754175627001727
Validation loss: 2.198655238880882

Epoch: 6| Step: 4
Training loss: 0.22155196758034498
Validation loss: 2.2280148357644802

Epoch: 6| Step: 5
Training loss: 0.133515628482111
Validation loss: 2.23215286749545

Epoch: 6| Step: 6
Training loss: 0.1293787820696296
Validation loss: 2.226047592914908

Epoch: 6| Step: 7
Training loss: 0.11832651683097895
Validation loss: 2.2508003675385546

Epoch: 6| Step: 8
Training loss: 0.12205950116918877
Validation loss: 2.2382937985428026

Epoch: 6| Step: 9
Training loss: 0.0887142059348931
Validation loss: 2.25038785337498

Epoch: 6| Step: 10
Training loss: 0.10852373030418927
Validation loss: 2.24488743329205

Epoch: 6| Step: 11
Training loss: 0.07465506285705173
Validation loss: 2.235569615132747

Epoch: 6| Step: 12
Training loss: 0.20855806666993132
Validation loss: 2.249966867264476

Epoch: 6| Step: 13
Training loss: 0.072315762499611
Validation loss: 2.251192753638072

Epoch: 443| Step: 0
Training loss: 0.08229536725226233
Validation loss: 2.2594952324005657

Epoch: 6| Step: 1
Training loss: 0.11889470625846107
Validation loss: 2.2504501188778567

Epoch: 6| Step: 2
Training loss: 0.11492248936948574
Validation loss: 2.204961268211523

Epoch: 6| Step: 3
Training loss: 0.08284436289932186
Validation loss: 2.216105663425743

Epoch: 6| Step: 4
Training loss: 0.11615834528696077
Validation loss: 2.2238961069127265

Epoch: 6| Step: 5
Training loss: 0.17343726845459476
Validation loss: 2.2250633502185413

Epoch: 6| Step: 6
Training loss: 0.18270513895135623
Validation loss: 2.2148884132877815

Epoch: 6| Step: 7
Training loss: 0.21207049524563223
Validation loss: 2.206671641799629

Epoch: 6| Step: 8
Training loss: 0.1423472403214586
Validation loss: 2.2035861132403043

Epoch: 6| Step: 9
Training loss: 0.08429089323462265
Validation loss: 2.205267484724132

Epoch: 6| Step: 10
Training loss: 0.08498182259289787
Validation loss: 2.2049662444302425

Epoch: 6| Step: 11
Training loss: 0.2543885272410344
Validation loss: 2.2094769394757763

Epoch: 6| Step: 12
Training loss: 0.09513186237781449
Validation loss: 2.210770701617837

Epoch: 6| Step: 13
Training loss: 0.1715739604895116
Validation loss: 2.205644862333248

Epoch: 444| Step: 0
Training loss: 0.09250732201194192
Validation loss: 2.259723491454766

Epoch: 6| Step: 1
Training loss: 0.23230161681197592
Validation loss: 2.214202652070752

Epoch: 6| Step: 2
Training loss: 0.12093759281687169
Validation loss: 2.27003217821153

Epoch: 6| Step: 3
Training loss: 0.15962660834160114
Validation loss: 2.233707888016119

Epoch: 6| Step: 4
Training loss: 0.09809596250128551
Validation loss: 2.2369400046389702

Epoch: 6| Step: 5
Training loss: 0.08885456351858304
Validation loss: 2.238845235006005

Epoch: 6| Step: 6
Training loss: 0.21106690393506783
Validation loss: 2.1970700307769113

Epoch: 6| Step: 7
Training loss: 0.08893743295827873
Validation loss: 2.227935591001852

Epoch: 6| Step: 8
Training loss: 0.08530091085597494
Validation loss: 2.193660212531793

Epoch: 6| Step: 9
Training loss: 0.21891312817775463
Validation loss: 2.2047236569741684

Epoch: 6| Step: 10
Training loss: 0.12641362217080943
Validation loss: 2.207859780455632

Epoch: 6| Step: 11
Training loss: 0.14375285658900555
Validation loss: 2.2107745689271128

Epoch: 6| Step: 12
Training loss: 0.13828473383076417
Validation loss: 2.2056490681439627

Epoch: 6| Step: 13
Training loss: 0.10048869441534135
Validation loss: 2.212754203000809

Epoch: 445| Step: 0
Training loss: 0.1654890179220943
Validation loss: 2.2126449727956174

Epoch: 6| Step: 1
Training loss: 0.09387004636807474
Validation loss: 2.2127821511174224

Epoch: 6| Step: 2
Training loss: 0.11915944685550522
Validation loss: 2.197301037647727

Epoch: 6| Step: 3
Training loss: 0.13981541740850717
Validation loss: 2.1815922856500998

Epoch: 6| Step: 4
Training loss: 0.2071259569878073
Validation loss: 2.2365186032058157

Epoch: 6| Step: 5
Training loss: 0.20471235990617911
Validation loss: 2.165763776499871

Epoch: 6| Step: 6
Training loss: 0.057092471608756086
Validation loss: 2.214836905801397

Epoch: 6| Step: 7
Training loss: 0.17840854931016364
Validation loss: 2.2037425575300285

Epoch: 6| Step: 8
Training loss: 0.1653528897714098
Validation loss: 2.1914222840557596

Epoch: 6| Step: 9
Training loss: 0.11808984175223983
Validation loss: 2.200523270350009

Epoch: 6| Step: 10
Training loss: 0.08622303581819611
Validation loss: 2.239415168362913

Epoch: 6| Step: 11
Training loss: 0.11469450663516105
Validation loss: 2.183713583987826

Epoch: 6| Step: 12
Training loss: 0.10286347976124784
Validation loss: 2.217444607071878

Epoch: 6| Step: 13
Training loss: 0.13999068064197717
Validation loss: 2.217494687480052

Epoch: 446| Step: 0
Training loss: 0.08820813366680104
Validation loss: 2.1807618792624837

Epoch: 6| Step: 1
Training loss: 0.15187012580224227
Validation loss: 2.198123795765425

Epoch: 6| Step: 2
Training loss: 0.09662386698817307
Validation loss: 2.2220609941839062

Epoch: 6| Step: 3
Training loss: 0.09577123009262954
Validation loss: 2.1826889867196435

Epoch: 6| Step: 4
Training loss: 0.20054975627201024
Validation loss: 2.1925353733035644

Epoch: 6| Step: 5
Training loss: 0.0816266036427421
Validation loss: 2.223950565404588

Epoch: 6| Step: 6
Training loss: 0.17123140867629505
Validation loss: 2.212585472636413

Epoch: 6| Step: 7
Training loss: 0.204719802622563
Validation loss: 2.255931981887547

Epoch: 6| Step: 8
Training loss: 0.13263133258693874
Validation loss: 2.2332320677374735

Epoch: 6| Step: 9
Training loss: 0.10557106141899107
Validation loss: 2.22172603075188

Epoch: 6| Step: 10
Training loss: 0.2197777582501676
Validation loss: 2.2449023576337743

Epoch: 6| Step: 11
Training loss: 0.14208530143477544
Validation loss: 2.2316682510807184

Epoch: 6| Step: 12
Training loss: 0.08871064703829543
Validation loss: 2.2031189278360594

Epoch: 6| Step: 13
Training loss: 0.1338284010029723
Validation loss: 2.202287040844962

Epoch: 447| Step: 0
Training loss: 0.22061677948493097
Validation loss: 2.2125877704085255

Epoch: 6| Step: 1
Training loss: 0.22932525407158885
Validation loss: 2.1794759825850996

Epoch: 6| Step: 2
Training loss: 0.15760120041327733
Validation loss: 2.2232934470332615

Epoch: 6| Step: 3
Training loss: 0.11910889156032767
Validation loss: 2.2038102467199727

Epoch: 6| Step: 4
Training loss: 0.11376114024378783
Validation loss: 2.1855648687048763

Epoch: 6| Step: 5
Training loss: 0.06571767541566434
Validation loss: 2.15832284121953

Epoch: 6| Step: 6
Training loss: 0.15967688112729095
Validation loss: 2.1794625207823097

Epoch: 6| Step: 7
Training loss: 0.09258581564140976
Validation loss: 2.203375289617989

Epoch: 6| Step: 8
Training loss: 0.0740078766302159
Validation loss: 2.2137134621902352

Epoch: 6| Step: 9
Training loss: 0.1570592250387664
Validation loss: 2.249098783005391

Epoch: 6| Step: 10
Training loss: 0.10544892407323309
Validation loss: 2.263314265573879

Epoch: 6| Step: 11
Training loss: 0.18926340612564066
Validation loss: 2.2261500548134756

Epoch: 6| Step: 12
Training loss: 0.13396246316643567
Validation loss: 2.2453093869039016

Epoch: 6| Step: 13
Training loss: 0.1188868140766582
Validation loss: 2.2128278552536225

Epoch: 448| Step: 0
Training loss: 0.09738722940000226
Validation loss: 2.221219124134811

Epoch: 6| Step: 1
Training loss: 0.0817499759698462
Validation loss: 2.1818110051468995

Epoch: 6| Step: 2
Training loss: 0.09796046556614194
Validation loss: 2.193349625857061

Epoch: 6| Step: 3
Training loss: 0.1132690406665294
Validation loss: 2.174921715920791

Epoch: 6| Step: 4
Training loss: 0.07825433634855594
Validation loss: 2.16552333585168

Epoch: 6| Step: 5
Training loss: 0.1306412287719703
Validation loss: 2.172848704899504

Epoch: 6| Step: 6
Training loss: 0.10999131265928132
Validation loss: 2.1676186165491975

Epoch: 6| Step: 7
Training loss: 0.11646127184505557
Validation loss: 2.1490720734657707

Epoch: 6| Step: 8
Training loss: 0.07372968559607096
Validation loss: 2.172445779821904

Epoch: 6| Step: 9
Training loss: 0.2107507974387815
Validation loss: 2.1789229033282793

Epoch: 6| Step: 10
Training loss: 0.12412014517432907
Validation loss: 2.1428375677844658

Epoch: 6| Step: 11
Training loss: 0.254522178094821
Validation loss: 2.1690016683688196

Epoch: 6| Step: 12
Training loss: 0.19279935444205878
Validation loss: 2.1442548836487476

Epoch: 6| Step: 13
Training loss: 0.13046147217696094
Validation loss: 2.111205836834214

Epoch: 449| Step: 0
Training loss: 0.13292580567778145
Validation loss: 2.142833952331455

Epoch: 6| Step: 1
Training loss: 0.11264053795327368
Validation loss: 2.15107263730826

Epoch: 6| Step: 2
Training loss: 0.19816900885161393
Validation loss: 2.1668660417844694

Epoch: 6| Step: 3
Training loss: 0.09670495175183166
Validation loss: 2.1699929105055844

Epoch: 6| Step: 4
Training loss: 0.1574392952757966
Validation loss: 2.2128634996423098

Epoch: 6| Step: 5
Training loss: 0.23673839267274582
Validation loss: 2.2066525887211665

Epoch: 6| Step: 6
Training loss: 0.10309478848250259
Validation loss: 2.1985473097426453

Epoch: 6| Step: 7
Training loss: 0.21535870652827444
Validation loss: 2.185753228038309

Epoch: 6| Step: 8
Training loss: 0.0972997452358643
Validation loss: 2.2336055234664407

Epoch: 6| Step: 9
Training loss: 0.1194882870424435
Validation loss: 2.188237840762182

Epoch: 6| Step: 10
Training loss: 0.10589390733401319
Validation loss: 2.208695587641785

Epoch: 6| Step: 11
Training loss: 0.08538388070314318
Validation loss: 2.206442124325609

Epoch: 6| Step: 12
Training loss: 0.12388540832269103
Validation loss: 2.228878221853592

Epoch: 6| Step: 13
Training loss: 0.13801648175079342
Validation loss: 2.1741497786300052

Epoch: 450| Step: 0
Training loss: 0.211362542965164
Validation loss: 2.2239634760745557

Epoch: 6| Step: 1
Training loss: 0.11874892381757665
Validation loss: 2.19073229708897

Epoch: 6| Step: 2
Training loss: 0.11118639323078801
Validation loss: 2.1808983987631256

Epoch: 6| Step: 3
Training loss: 0.13195548112481112
Validation loss: 2.20325772989567

Epoch: 6| Step: 4
Training loss: 0.12156597475709718
Validation loss: 2.2113221765588356

Epoch: 6| Step: 5
Training loss: 0.1828758121962643
Validation loss: 2.198184541506659

Epoch: 6| Step: 6
Training loss: 0.06572442073635679
Validation loss: 2.176899559890985

Epoch: 6| Step: 7
Training loss: 0.10090400350373081
Validation loss: 2.1400159869642934

Epoch: 6| Step: 8
Training loss: 0.2000566514068107
Validation loss: 2.1573407845886314

Epoch: 6| Step: 9
Training loss: 0.09788315162231538
Validation loss: 2.1384621761281073

Epoch: 6| Step: 10
Training loss: 0.17112703565692222
Validation loss: 2.1326412850550214

Epoch: 6| Step: 11
Training loss: 0.10039167719040981
Validation loss: 2.0993975498864916

Epoch: 6| Step: 12
Training loss: 0.19465445290062194
Validation loss: 2.137583513876618

Epoch: 6| Step: 13
Training loss: 0.07497669928421878
Validation loss: 2.1354895784629675

Epoch: 451| Step: 0
Training loss: 0.10936054066040733
Validation loss: 2.1372906865260983

Epoch: 6| Step: 1
Training loss: 0.12470305458127084
Validation loss: 2.1744848803294756

Epoch: 6| Step: 2
Training loss: 0.07370656617610388
Validation loss: 2.165536074561748

Epoch: 6| Step: 3
Training loss: 0.15339665425708815
Validation loss: 2.1730075284576427

Epoch: 6| Step: 4
Training loss: 0.16049611850899606
Validation loss: 2.167396465294149

Epoch: 6| Step: 5
Training loss: 0.11320681017056454
Validation loss: 2.194797402743162

Epoch: 6| Step: 6
Training loss: 0.21936159128253782
Validation loss: 2.16799997567561

Epoch: 6| Step: 7
Training loss: 0.17837735085919762
Validation loss: 2.1465726101234406

Epoch: 6| Step: 8
Training loss: 0.06782384641273036
Validation loss: 2.1829259823162257

Epoch: 6| Step: 9
Training loss: 0.08293158453102611
Validation loss: 2.158496990770305

Epoch: 6| Step: 10
Training loss: 0.08369421180821027
Validation loss: 2.1530689067348305

Epoch: 6| Step: 11
Training loss: 0.14308765891474456
Validation loss: 2.182784824761254

Epoch: 6| Step: 12
Training loss: 0.16648433939496166
Validation loss: 2.1672267635554676

Epoch: 6| Step: 13
Training loss: 0.2609392914168031
Validation loss: 2.1552985465445516

Epoch: 452| Step: 0
Training loss: 0.13954498220237904
Validation loss: 2.1771447224613647

Epoch: 6| Step: 1
Training loss: 0.1347770133251459
Validation loss: 2.1871635940107246

Epoch: 6| Step: 2
Training loss: 0.1878684913144881
Validation loss: 2.2283658243353397

Epoch: 6| Step: 3
Training loss: 0.17143284755614535
Validation loss: 2.221069179935136

Epoch: 6| Step: 4
Training loss: 0.11775544346995369
Validation loss: 2.236330142595465

Epoch: 6| Step: 5
Training loss: 0.07958816748884087
Validation loss: 2.2149038670363

Epoch: 6| Step: 6
Training loss: 0.07505015506700569
Validation loss: 2.2088273409666423

Epoch: 6| Step: 7
Training loss: 0.20297279524204204
Validation loss: 2.2228623368959877

Epoch: 6| Step: 8
Training loss: 0.15553860844057202
Validation loss: 2.2294684838201717

Epoch: 6| Step: 9
Training loss: 0.07553569432359072
Validation loss: 2.2304612733158797

Epoch: 6| Step: 10
Training loss: 0.08411568534156746
Validation loss: 2.234669419928363

Epoch: 6| Step: 11
Training loss: 0.13156549477509943
Validation loss: 2.2249812206366686

Epoch: 6| Step: 12
Training loss: 0.1787819851421944
Validation loss: 2.204456506184406

Epoch: 6| Step: 13
Training loss: 0.11791838966780013
Validation loss: 2.1954072492373746

Epoch: 453| Step: 0
Training loss: 0.12091261637281901
Validation loss: 2.2010316441673408

Epoch: 6| Step: 1
Training loss: 0.09232082384104599
Validation loss: 2.217552290458753

Epoch: 6| Step: 2
Training loss: 0.09813925505922313
Validation loss: 2.1982458109519265

Epoch: 6| Step: 3
Training loss: 0.18215012618494283
Validation loss: 2.216062985523427

Epoch: 6| Step: 4
Training loss: 0.20427991749277982
Validation loss: 2.2426762093472465

Epoch: 6| Step: 5
Training loss: 0.13501351818643426
Validation loss: 2.268042899995165

Epoch: 6| Step: 6
Training loss: 0.18785387659263772
Validation loss: 2.272101197832903

Epoch: 6| Step: 7
Training loss: 0.092983319639519
Validation loss: 2.2352018965351768

Epoch: 6| Step: 8
Training loss: 0.09619424786703121
Validation loss: 2.257688442074625

Epoch: 6| Step: 9
Training loss: 0.13122794215726216
Validation loss: 2.232766067018749

Epoch: 6| Step: 10
Training loss: 0.11100480328243167
Validation loss: 2.2449903114519603

Epoch: 6| Step: 11
Training loss: 0.06221585765064432
Validation loss: 2.2384557573112094

Epoch: 6| Step: 12
Training loss: 0.21743672260245234
Validation loss: 2.2102779278740163

Epoch: 6| Step: 13
Training loss: 0.24833197241822003
Validation loss: 2.2261196407757766

Epoch: 454| Step: 0
Training loss: 0.07563302904355534
Validation loss: 2.240976473139314

Epoch: 6| Step: 1
Training loss: 0.10607549312235534
Validation loss: 2.208966827388162

Epoch: 6| Step: 2
Training loss: 0.10399658553457077
Validation loss: 2.204269090005722

Epoch: 6| Step: 3
Training loss: 0.09590194932680081
Validation loss: 2.211773998108157

Epoch: 6| Step: 4
Training loss: 0.18973500626270604
Validation loss: 2.200741781778031

Epoch: 6| Step: 5
Training loss: 0.10535984686364396
Validation loss: 2.225222710854777

Epoch: 6| Step: 6
Training loss: 0.13225919808164405
Validation loss: 2.1997141719284885

Epoch: 6| Step: 7
Training loss: 0.13473583666214212
Validation loss: 2.214890773343683

Epoch: 6| Step: 8
Training loss: 0.19277967386873712
Validation loss: 2.2134811093891726

Epoch: 6| Step: 9
Training loss: 0.19049705878625464
Validation loss: 2.2050116577204877

Epoch: 6| Step: 10
Training loss: 0.1494766428420925
Validation loss: 2.2200597998511706

Epoch: 6| Step: 11
Training loss: 0.10825267648691807
Validation loss: 2.205649487446056

Epoch: 6| Step: 12
Training loss: 0.13665889383397814
Validation loss: 2.1820447617956673

Epoch: 6| Step: 13
Training loss: 0.10466846410424492
Validation loss: 2.191997896923058

Epoch: 455| Step: 0
Training loss: 0.09946182018185296
Validation loss: 2.1815273673297737

Epoch: 6| Step: 1
Training loss: 0.0784898701459829
Validation loss: 2.195387484167937

Epoch: 6| Step: 2
Training loss: 0.062264109046220005
Validation loss: 2.2308216813186017

Epoch: 6| Step: 3
Training loss: 0.14500563969208902
Validation loss: 2.177385164339565

Epoch: 6| Step: 4
Training loss: 0.15696339469681106
Validation loss: 2.1993357702787075

Epoch: 6| Step: 5
Training loss: 0.11119515860782829
Validation loss: 2.221152859400407

Epoch: 6| Step: 6
Training loss: 0.1041533243058552
Validation loss: 2.1953275666376553

Epoch: 6| Step: 7
Training loss: 0.09865198798786695
Validation loss: 2.1668568788748073

Epoch: 6| Step: 8
Training loss: 0.17279226288080513
Validation loss: 2.197070228557165

Epoch: 6| Step: 9
Training loss: 0.09154028235633015
Validation loss: 2.2068091530960525

Epoch: 6| Step: 10
Training loss: 0.11081330994273982
Validation loss: 2.2168115212496624

Epoch: 6| Step: 11
Training loss: 0.21548319936191937
Validation loss: 2.2084904284177385

Epoch: 6| Step: 12
Training loss: 0.21390480860244707
Validation loss: 2.215010638652999

Epoch: 6| Step: 13
Training loss: 0.07386661111736906
Validation loss: 2.221018983901269

Epoch: 456| Step: 0
Training loss: 0.1283422253970721
Validation loss: 2.2206839290974734

Epoch: 6| Step: 1
Training loss: 0.07059960228804416
Validation loss: 2.2315063323174593

Epoch: 6| Step: 2
Training loss: 0.073394140926799
Validation loss: 2.2134362590286587

Epoch: 6| Step: 3
Training loss: 0.10380387210245773
Validation loss: 2.2171555040771196

Epoch: 6| Step: 4
Training loss: 0.09805969348262376
Validation loss: 2.2034524630457137

Epoch: 6| Step: 5
Training loss: 0.09782139166431758
Validation loss: 2.230225028223606

Epoch: 6| Step: 6
Training loss: 0.1952478301749508
Validation loss: 2.2415897812813514

Epoch: 6| Step: 7
Training loss: 0.18569826675819706
Validation loss: 2.208124055269968

Epoch: 6| Step: 8
Training loss: 0.1596583908894736
Validation loss: 2.238355194446963

Epoch: 6| Step: 9
Training loss: 0.18902993867608184
Validation loss: 2.236869988032274

Epoch: 6| Step: 10
Training loss: 0.14242867907092363
Validation loss: 2.2215606776575823

Epoch: 6| Step: 11
Training loss: 0.0844524805968946
Validation loss: 2.2464428861895867

Epoch: 6| Step: 12
Training loss: 0.13068986703470406
Validation loss: 2.2354293791992785

Epoch: 6| Step: 13
Training loss: 0.17679951634206037
Validation loss: 2.2566206770885224

Epoch: 457| Step: 0
Training loss: 0.09587540981299636
Validation loss: 2.2328922036566845

Epoch: 6| Step: 1
Training loss: 0.09313226873077324
Validation loss: 2.207278380631557

Epoch: 6| Step: 2
Training loss: 0.09832377221950746
Validation loss: 2.2345194943048203

Epoch: 6| Step: 3
Training loss: 0.12356883558664247
Validation loss: 2.2437046539690506

Epoch: 6| Step: 4
Training loss: 0.16467190142018792
Validation loss: 2.217268214283992

Epoch: 6| Step: 5
Training loss: 0.12355422072634475
Validation loss: 2.194747767503464

Epoch: 6| Step: 6
Training loss: 0.11432024073528456
Validation loss: 2.232382814087531

Epoch: 6| Step: 7
Training loss: 0.2207966834071449
Validation loss: 2.2295145645590004

Epoch: 6| Step: 8
Training loss: 0.08904387128656625
Validation loss: 2.2392372598474033

Epoch: 6| Step: 9
Training loss: 0.12279298868811707
Validation loss: 2.2120146986051643

Epoch: 6| Step: 10
Training loss: 0.07520451737083234
Validation loss: 2.1872107272049437

Epoch: 6| Step: 11
Training loss: 0.1129422747782744
Validation loss: 2.216677292480586

Epoch: 6| Step: 12
Training loss: 0.09994145743566488
Validation loss: 2.194278805763427

Epoch: 6| Step: 13
Training loss: 0.2389680002469393
Validation loss: 2.1906101135545764

Epoch: 458| Step: 0
Training loss: 0.09164772700492124
Validation loss: 2.217681061104062

Epoch: 6| Step: 1
Training loss: 0.06315830482257427
Validation loss: 2.212637322916507

Epoch: 6| Step: 2
Training loss: 0.10150443764907703
Validation loss: 2.2135022086885923

Epoch: 6| Step: 3
Training loss: 0.15686601561773494
Validation loss: 2.1815173302771256

Epoch: 6| Step: 4
Training loss: 0.2679788971250382
Validation loss: 2.204304514583883

Epoch: 6| Step: 5
Training loss: 0.08339398816678004
Validation loss: 2.2015373649441217

Epoch: 6| Step: 6
Training loss: 0.08745347557249782
Validation loss: 2.212515137351068

Epoch: 6| Step: 7
Training loss: 0.0711439595975254
Validation loss: 2.2016284563466364

Epoch: 6| Step: 8
Training loss: 0.09205685992681474
Validation loss: 2.191370781868164

Epoch: 6| Step: 9
Training loss: 0.22670340267214084
Validation loss: 2.2000427188808964

Epoch: 6| Step: 10
Training loss: 0.15487726521509568
Validation loss: 2.207283542829509

Epoch: 6| Step: 11
Training loss: 0.061680430727316646
Validation loss: 2.2053823398280934

Epoch: 6| Step: 12
Training loss: 0.09592464170584128
Validation loss: 2.230977255121742

Epoch: 6| Step: 13
Training loss: 0.08102196009724114
Validation loss: 2.209451208668292

Epoch: 459| Step: 0
Training loss: 0.10702657358715358
Validation loss: 2.229664459938464

Epoch: 6| Step: 1
Training loss: 0.1660811351101733
Validation loss: 2.2411979729072806

Epoch: 6| Step: 2
Training loss: 0.07100425618197688
Validation loss: 2.260742681916038

Epoch: 6| Step: 3
Training loss: 0.10284868451477054
Validation loss: 2.2193660397922432

Epoch: 6| Step: 4
Training loss: 0.05234612487985161
Validation loss: 2.214155435805472

Epoch: 6| Step: 5
Training loss: 0.17346953255166422
Validation loss: 2.2059330763485274

Epoch: 6| Step: 6
Training loss: 0.11919758951372872
Validation loss: 2.2150560601256677

Epoch: 6| Step: 7
Training loss: 0.135938310620752
Validation loss: 2.200854744903624

Epoch: 6| Step: 8
Training loss: 0.14582983648558212
Validation loss: 2.17779189955864

Epoch: 6| Step: 9
Training loss: 0.19906766622777153
Validation loss: 2.2241473982966107

Epoch: 6| Step: 10
Training loss: 0.10578640150489024
Validation loss: 2.251432102070348

Epoch: 6| Step: 11
Training loss: 0.06903982398116204
Validation loss: 2.2250417902221464

Epoch: 6| Step: 12
Training loss: 0.06433611421033891
Validation loss: 2.2193285025995864

Epoch: 6| Step: 13
Training loss: 0.25497360366351424
Validation loss: 2.2253566134006504

Epoch: 460| Step: 0
Training loss: 0.09040788095099518
Validation loss: 2.2170473886079534

Epoch: 6| Step: 1
Training loss: 0.16048266711703724
Validation loss: 2.1907646511164307

Epoch: 6| Step: 2
Training loss: 0.09675828070406005
Validation loss: 2.2257493162468305

Epoch: 6| Step: 3
Training loss: 0.24674247582924874
Validation loss: 2.2280645267037475

Epoch: 6| Step: 4
Training loss: 0.0997788726208022
Validation loss: 2.2229830236404995

Epoch: 6| Step: 5
Training loss: 0.1001601698520482
Validation loss: 2.199208374033932

Epoch: 6| Step: 6
Training loss: 0.1859470769675795
Validation loss: 2.1716118652643437

Epoch: 6| Step: 7
Training loss: 0.12415039142916806
Validation loss: 2.1869784183076617

Epoch: 6| Step: 8
Training loss: 0.09540032147699748
Validation loss: 2.1927951496153484

Epoch: 6| Step: 9
Training loss: 0.1370383342142697
Validation loss: 2.1737860452487006

Epoch: 6| Step: 10
Training loss: 0.12268995942537927
Validation loss: 2.1586237428349637

Epoch: 6| Step: 11
Training loss: 0.06779196126019439
Validation loss: 2.174435528312461

Epoch: 6| Step: 12
Training loss: 0.1430608207992391
Validation loss: 2.204014506859747

Epoch: 6| Step: 13
Training loss: 0.14662646078396724
Validation loss: 2.2295014790575594

Epoch: 461| Step: 0
Training loss: 0.11281332022297424
Validation loss: 2.263040533996886

Epoch: 6| Step: 1
Training loss: 0.08712794475884302
Validation loss: 2.237772694204361

Epoch: 6| Step: 2
Training loss: 0.18360244446316143
Validation loss: 2.259047856553663

Epoch: 6| Step: 3
Training loss: 0.15774032221631173
Validation loss: 2.280457479646533

Epoch: 6| Step: 4
Training loss: 0.2440340954105063
Validation loss: 2.269932156195827

Epoch: 6| Step: 5
Training loss: 0.10321185687981518
Validation loss: 2.234067971931837

Epoch: 6| Step: 6
Training loss: 0.08799159025771784
Validation loss: 2.2449168818993104

Epoch: 6| Step: 7
Training loss: 0.11391007252154378
Validation loss: 2.221930154796859

Epoch: 6| Step: 8
Training loss: 0.09435558430422397
Validation loss: 2.201311896588865

Epoch: 6| Step: 9
Training loss: 0.1713013613036046
Validation loss: 2.2188502844666913

Epoch: 6| Step: 10
Training loss: 0.10441537511580626
Validation loss: 2.1939081639898856

Epoch: 6| Step: 11
Training loss: 0.1284699932934602
Validation loss: 2.1981811914406397

Epoch: 6| Step: 12
Training loss: 0.17115987671239172
Validation loss: 2.166136833829679

Epoch: 6| Step: 13
Training loss: 0.11913320252482694
Validation loss: 2.1989343823221303

Epoch: 462| Step: 0
Training loss: 0.12838265981544986
Validation loss: 2.1943196256477537

Epoch: 6| Step: 1
Training loss: 0.11113048879543894
Validation loss: 2.1918929657393575

Epoch: 6| Step: 2
Training loss: 0.14033856625561744
Validation loss: 2.1902978095082997

Epoch: 6| Step: 3
Training loss: 0.1226026562213091
Validation loss: 2.196355987506598

Epoch: 6| Step: 4
Training loss: 0.08084146478653913
Validation loss: 2.2217824786239273

Epoch: 6| Step: 5
Training loss: 0.15837730426662608
Validation loss: 2.2311418879342133

Epoch: 6| Step: 6
Training loss: 0.31018300601656096
Validation loss: 2.2109699879547304

Epoch: 6| Step: 7
Training loss: 0.20678082200977896
Validation loss: 2.192905564372583

Epoch: 6| Step: 8
Training loss: 0.09883819574000484
Validation loss: 2.16179511219863

Epoch: 6| Step: 9
Training loss: 0.07735276326248378
Validation loss: 2.1486900913466496

Epoch: 6| Step: 10
Training loss: 0.11308598954853448
Validation loss: 2.1382399960506904

Epoch: 6| Step: 11
Training loss: 0.11340251138027004
Validation loss: 2.1382632783139353

Epoch: 6| Step: 12
Training loss: 0.1386859846324572
Validation loss: 2.1682647068495973

Epoch: 6| Step: 13
Training loss: 0.19085328355110234
Validation loss: 2.1579407347915343

Epoch: 463| Step: 0
Training loss: 0.1545522845409784
Validation loss: 2.155546670790444

Epoch: 6| Step: 1
Training loss: 0.1476947434017635
Validation loss: 2.1798862668476757

Epoch: 6| Step: 2
Training loss: 0.1380076687010624
Validation loss: 2.2171113825112005

Epoch: 6| Step: 3
Training loss: 0.2084592389090194
Validation loss: 2.2308806449650165

Epoch: 6| Step: 4
Training loss: 0.215542834977895
Validation loss: 2.2364294220929057

Epoch: 6| Step: 5
Training loss: 0.20459394063921765
Validation loss: 2.262637299168869

Epoch: 6| Step: 6
Training loss: 0.18163992768840867
Validation loss: 2.2404396173459187

Epoch: 6| Step: 7
Training loss: 0.08492810064199575
Validation loss: 2.236001911472278

Epoch: 6| Step: 8
Training loss: 0.1565703148614158
Validation loss: 2.226658503087797

Epoch: 6| Step: 9
Training loss: 0.14941706062250953
Validation loss: 2.193334224203416

Epoch: 6| Step: 10
Training loss: 0.16757321917415532
Validation loss: 2.150088930067468

Epoch: 6| Step: 11
Training loss: 0.13490016413576875
Validation loss: 2.1555305304313452

Epoch: 6| Step: 12
Training loss: 0.13100219875002875
Validation loss: 2.11936199373511

Epoch: 6| Step: 13
Training loss: 0.11504701560982107
Validation loss: 2.1479671580193864

Epoch: 464| Step: 0
Training loss: 0.14442243861825446
Validation loss: 2.1319970470402745

Epoch: 6| Step: 1
Training loss: 0.20332651046408579
Validation loss: 2.1439428650681225

Epoch: 6| Step: 2
Training loss: 0.08165369682065068
Validation loss: 2.155450812815539

Epoch: 6| Step: 3
Training loss: 0.1995043390508477
Validation loss: 2.1652145082643997

Epoch: 6| Step: 4
Training loss: 0.17638449473072423
Validation loss: 2.179558535982461

Epoch: 6| Step: 5
Training loss: 0.14979691168188886
Validation loss: 2.1452316475439237

Epoch: 6| Step: 6
Training loss: 0.11202518678163069
Validation loss: 2.1709595830961184

Epoch: 6| Step: 7
Training loss: 0.10118227172513364
Validation loss: 2.162703390619768

Epoch: 6| Step: 8
Training loss: 0.13509892973631207
Validation loss: 2.197336246718279

Epoch: 6| Step: 9
Training loss: 0.1380878561660871
Validation loss: 2.1910507319999235

Epoch: 6| Step: 10
Training loss: 0.1588464126622662
Validation loss: 2.228415325679719

Epoch: 6| Step: 11
Training loss: 0.189860741125734
Validation loss: 2.2305550541767762

Epoch: 6| Step: 12
Training loss: 0.13871242037909468
Validation loss: 2.2226089549497514

Epoch: 6| Step: 13
Training loss: 0.14659664937626282
Validation loss: 2.276893235838873

Epoch: 465| Step: 0
Training loss: 0.09011452754030025
Validation loss: 2.22368297720006

Epoch: 6| Step: 1
Training loss: 0.06890455897520435
Validation loss: 2.258220351481137

Epoch: 6| Step: 2
Training loss: 0.10149904249355075
Validation loss: 2.1901233207888606

Epoch: 6| Step: 3
Training loss: 0.1527208588124571
Validation loss: 2.2168565614966442

Epoch: 6| Step: 4
Training loss: 0.17425371960927954
Validation loss: 2.2212515927059977

Epoch: 6| Step: 5
Training loss: 0.13933897074485033
Validation loss: 2.222301880586325

Epoch: 6| Step: 6
Training loss: 0.09813290617307947
Validation loss: 2.2369151937080582

Epoch: 6| Step: 7
Training loss: 0.22419450010692257
Validation loss: 2.2149278625824422

Epoch: 6| Step: 8
Training loss: 0.11930167538266068
Validation loss: 2.202401612543171

Epoch: 6| Step: 9
Training loss: 0.12573029599660993
Validation loss: 2.1977004999669685

Epoch: 6| Step: 10
Training loss: 0.09947598632834981
Validation loss: 2.2199284077230614

Epoch: 6| Step: 11
Training loss: 0.10573606259152203
Validation loss: 2.209939567160221

Epoch: 6| Step: 12
Training loss: 0.1928803260621638
Validation loss: 2.23901717538811

Epoch: 6| Step: 13
Training loss: 0.2766186005325722
Validation loss: 2.2667061505808674

Epoch: 466| Step: 0
Training loss: 0.13383048175177426
Validation loss: 2.2160175719640467

Epoch: 6| Step: 1
Training loss: 0.14660507315851937
Validation loss: 2.213759788078861

Epoch: 6| Step: 2
Training loss: 0.18704119815995765
Validation loss: 2.1738580818995206

Epoch: 6| Step: 3
Training loss: 0.1098396021438297
Validation loss: 2.1520219856434037

Epoch: 6| Step: 4
Training loss: 0.08799214857368655
Validation loss: 2.1514420445973217

Epoch: 6| Step: 5
Training loss: 0.08930716746463209
Validation loss: 2.148260086207107

Epoch: 6| Step: 6
Training loss: 0.1771286294076674
Validation loss: 2.147130462034424

Epoch: 6| Step: 7
Training loss: 0.22229882044365545
Validation loss: 2.1546592747853803

Epoch: 6| Step: 8
Training loss: 0.2180468549219257
Validation loss: 2.1520160525117387

Epoch: 6| Step: 9
Training loss: 0.16349860763941237
Validation loss: 2.1748257323575384

Epoch: 6| Step: 10
Training loss: 0.09478339230750954
Validation loss: 2.157099831733031

Epoch: 6| Step: 11
Training loss: 0.13380739685066734
Validation loss: 2.1933435210785452

Epoch: 6| Step: 12
Training loss: 0.10142823661301843
Validation loss: 2.2263821082449406

Epoch: 6| Step: 13
Training loss: 0.05580795453943698
Validation loss: 2.2296902104337337

Epoch: 467| Step: 0
Training loss: 0.18832864046228023
Validation loss: 2.234952465782531

Epoch: 6| Step: 1
Training loss: 0.21087963582151426
Validation loss: 2.245619778410183

Epoch: 6| Step: 2
Training loss: 0.1769564866174036
Validation loss: 2.2098531626188826

Epoch: 6| Step: 3
Training loss: 0.09257276817307865
Validation loss: 2.1901343016556836

Epoch: 6| Step: 4
Training loss: 0.10382817874014377
Validation loss: 2.180647382685319

Epoch: 6| Step: 5
Training loss: 0.09974334160253655
Validation loss: 2.1281523031141156

Epoch: 6| Step: 6
Training loss: 0.13495374072438923
Validation loss: 2.1276925580049326

Epoch: 6| Step: 7
Training loss: 0.09265434752886503
Validation loss: 2.117125334188573

Epoch: 6| Step: 8
Training loss: 0.23213059742094447
Validation loss: 2.13930259188985

Epoch: 6| Step: 9
Training loss: 0.10809049166593103
Validation loss: 2.1387585253657164

Epoch: 6| Step: 10
Training loss: 0.1405310913286083
Validation loss: 2.134632538283456

Epoch: 6| Step: 11
Training loss: 0.16689467232007918
Validation loss: 2.145129878093017

Epoch: 6| Step: 12
Training loss: 0.18291735331993725
Validation loss: 2.2243527252456983

Epoch: 6| Step: 13
Training loss: 0.17263784504659094
Validation loss: 2.220992878929737

Epoch: 468| Step: 0
Training loss: 0.24249441941712427
Validation loss: 2.2271816990949325

Epoch: 6| Step: 1
Training loss: 0.1526349658828806
Validation loss: 2.215512116704941

Epoch: 6| Step: 2
Training loss: 0.1369326212952797
Validation loss: 2.190282203217665

Epoch: 6| Step: 3
Training loss: 0.1052268574556384
Validation loss: 2.2011733518020944

Epoch: 6| Step: 4
Training loss: 0.20189640901557152
Validation loss: 2.177097734027927

Epoch: 6| Step: 5
Training loss: 0.13958171103967615
Validation loss: 2.1671917691587113

Epoch: 6| Step: 6
Training loss: 0.24833020226426983
Validation loss: 2.1969131930152055

Epoch: 6| Step: 7
Training loss: 0.09022666869345951
Validation loss: 2.1530230872514418

Epoch: 6| Step: 8
Training loss: 0.11596768830609272
Validation loss: 2.2078762901037603

Epoch: 6| Step: 9
Training loss: 0.14775237279929512
Validation loss: 2.1927959902124576

Epoch: 6| Step: 10
Training loss: 0.10074180267189485
Validation loss: 2.2181197107017767

Epoch: 6| Step: 11
Training loss: 0.18744480790993398
Validation loss: 2.2340634116774436

Epoch: 6| Step: 12
Training loss: 0.2361627346797644
Validation loss: 2.255426875180795

Epoch: 6| Step: 13
Training loss: 0.08761079800200024
Validation loss: 2.265953216145015

Epoch: 469| Step: 0
Training loss: 0.09502505926378997
Validation loss: 2.282860902302304

Epoch: 6| Step: 1
Training loss: 0.14729689005646002
Validation loss: 2.282782042008189

Epoch: 6| Step: 2
Training loss: 0.11289882234161042
Validation loss: 2.278710297172223

Epoch: 6| Step: 3
Training loss: 0.2541445274299671
Validation loss: 2.2943046708588137

Epoch: 6| Step: 4
Training loss: 0.14266101831278213
Validation loss: 2.2618642607850212

Epoch: 6| Step: 5
Training loss: 0.2212464556706477
Validation loss: 2.226829770390791

Epoch: 6| Step: 6
Training loss: 0.22738992936465616
Validation loss: 2.211284120235548

Epoch: 6| Step: 7
Training loss: 0.10705205374081304
Validation loss: 2.194663255299428

Epoch: 6| Step: 8
Training loss: 0.10203218975189333
Validation loss: 2.205502874176878

Epoch: 6| Step: 9
Training loss: 0.11672964058666417
Validation loss: 2.228766649742925

Epoch: 6| Step: 10
Training loss: 0.1794076274147175
Validation loss: 2.210859925156259

Epoch: 6| Step: 11
Training loss: 0.19988453631527175
Validation loss: 2.2213567279736037

Epoch: 6| Step: 12
Training loss: 0.19013627752204879
Validation loss: 2.236457033083082

Epoch: 6| Step: 13
Training loss: 0.16025444834987673
Validation loss: 2.2296985048905413

Epoch: 470| Step: 0
Training loss: 0.09488286072159316
Validation loss: 2.2312660585986426

Epoch: 6| Step: 1
Training loss: 0.16489924201908238
Validation loss: 2.227000391382884

Epoch: 6| Step: 2
Training loss: 0.10719016400605062
Validation loss: 2.236693394749453

Epoch: 6| Step: 3
Training loss: 0.14463618052217597
Validation loss: 2.215074552515015

Epoch: 6| Step: 4
Training loss: 0.08811037354800658
Validation loss: 2.204197850675443

Epoch: 6| Step: 5
Training loss: 0.1571415618105393
Validation loss: 2.2470788394311105

Epoch: 6| Step: 6
Training loss: 0.13491047800564007
Validation loss: 2.2325661770619996

Epoch: 6| Step: 7
Training loss: 0.12230295519361943
Validation loss: 2.2283251932500945

Epoch: 6| Step: 8
Training loss: 0.12759074964506248
Validation loss: 2.2016952414660826

Epoch: 6| Step: 9
Training loss: 0.13326984787184498
Validation loss: 2.1828345341293764

Epoch: 6| Step: 10
Training loss: 0.19049869167449315
Validation loss: 2.166721862329715

Epoch: 6| Step: 11
Training loss: 0.25477399001064976
Validation loss: 2.1613099708645085

Epoch: 6| Step: 12
Training loss: 0.11945569090523006
Validation loss: 2.156180367720911

Epoch: 6| Step: 13
Training loss: 0.1363698321708597
Validation loss: 2.1970077436968247

Epoch: 471| Step: 0
Training loss: 0.11291251927219059
Validation loss: 2.1678892378789056

Epoch: 6| Step: 1
Training loss: 0.12621747128981003
Validation loss: 2.1310905216202514

Epoch: 6| Step: 2
Training loss: 0.17512801439596234
Validation loss: 2.1402023157999195

Epoch: 6| Step: 3
Training loss: 0.16305174440571146
Validation loss: 2.150652076793512

Epoch: 6| Step: 4
Training loss: 0.08447930414578265
Validation loss: 2.160953055749099

Epoch: 6| Step: 5
Training loss: 0.11454191913454913
Validation loss: 2.1520021628084454

Epoch: 6| Step: 6
Training loss: 0.16577929898299562
Validation loss: 2.1404399134619547

Epoch: 6| Step: 7
Training loss: 0.11832951556206846
Validation loss: 2.1563305060273077

Epoch: 6| Step: 8
Training loss: 0.16321875252231607
Validation loss: 2.1711315358898817

Epoch: 6| Step: 9
Training loss: 0.17123925149209676
Validation loss: 2.1622725584866074

Epoch: 6| Step: 10
Training loss: 0.1241446826048425
Validation loss: 2.1659685951607974

Epoch: 6| Step: 11
Training loss: 0.1514146053736905
Validation loss: 2.1277703570885844

Epoch: 6| Step: 12
Training loss: 0.18519752139045678
Validation loss: 2.147486224440162

Epoch: 6| Step: 13
Training loss: 0.16350412717474785
Validation loss: 2.1598352886850125

Epoch: 472| Step: 0
Training loss: 0.18851812428202158
Validation loss: 2.19447929245965

Epoch: 6| Step: 1
Training loss: 0.1795311745360426
Validation loss: 2.1897313411762926

Epoch: 6| Step: 2
Training loss: 0.09560870358972756
Validation loss: 2.20785935838016

Epoch: 6| Step: 3
Training loss: 0.14236150904020917
Validation loss: 2.226997216472839

Epoch: 6| Step: 4
Training loss: 0.23531319871421313
Validation loss: 2.273381934392376

Epoch: 6| Step: 5
Training loss: 0.22253747750337724
Validation loss: 2.2598957032093354

Epoch: 6| Step: 6
Training loss: 0.17889516746144152
Validation loss: 2.228975011387608

Epoch: 6| Step: 7
Training loss: 0.12675350340585476
Validation loss: 2.2308275967724387

Epoch: 6| Step: 8
Training loss: 0.10093821714282304
Validation loss: 2.2567756924410847

Epoch: 6| Step: 9
Training loss: 0.10297341765965938
Validation loss: 2.210452245200733

Epoch: 6| Step: 10
Training loss: 0.15856121297914677
Validation loss: 2.210064657043436

Epoch: 6| Step: 11
Training loss: 0.1270356790185754
Validation loss: 2.1896493036109193

Epoch: 6| Step: 12
Training loss: 0.21772153945883635
Validation loss: 2.1614077650476355

Epoch: 6| Step: 13
Training loss: 0.11158016602572925
Validation loss: 2.1698764740046457

Epoch: 473| Step: 0
Training loss: 0.14909910528303422
Validation loss: 2.1413599137030195

Epoch: 6| Step: 1
Training loss: 0.22458693350759074
Validation loss: 2.1908566078794514

Epoch: 6| Step: 2
Training loss: 0.21679431467005006
Validation loss: 2.1854212187414204

Epoch: 6| Step: 3
Training loss: 0.1343356959392642
Validation loss: 2.1920558032652906

Epoch: 6| Step: 4
Training loss: 0.15559816293765852
Validation loss: 2.247098903945881

Epoch: 6| Step: 5
Training loss: 0.13116216502054612
Validation loss: 2.2275579415326883

Epoch: 6| Step: 6
Training loss: 0.18724240052001032
Validation loss: 2.2396885550740784

Epoch: 6| Step: 7
Training loss: 0.13525734907375053
Validation loss: 2.263179126145748

Epoch: 6| Step: 8
Training loss: 0.14124251918689423
Validation loss: 2.2307044463712566

Epoch: 6| Step: 9
Training loss: 0.10777962242068866
Validation loss: 2.2337858382946467

Epoch: 6| Step: 10
Training loss: 0.20508610846102662
Validation loss: 2.2275866211518287

Epoch: 6| Step: 11
Training loss: 0.16001288463636296
Validation loss: 2.2712101875297894

Epoch: 6| Step: 12
Training loss: 0.111925305306093
Validation loss: 2.269979629361956

Epoch: 6| Step: 13
Training loss: 0.09489231748310571
Validation loss: 2.237652812007968

Epoch: 474| Step: 0
Training loss: 0.10138387285477456
Validation loss: 2.2456995327316505

Epoch: 6| Step: 1
Training loss: 0.16192417596354383
Validation loss: 2.270300538967699

Epoch: 6| Step: 2
Training loss: 0.13254897536160898
Validation loss: 2.277093847761432

Epoch: 6| Step: 3
Training loss: 0.16428039477196285
Validation loss: 2.2801232161660137

Epoch: 6| Step: 4
Training loss: 0.15661719805792168
Validation loss: 2.271774592710384

Epoch: 6| Step: 5
Training loss: 0.1977758136435495
Validation loss: 2.229923290857516

Epoch: 6| Step: 6
Training loss: 0.19207293344369306
Validation loss: 2.237155140740114

Epoch: 6| Step: 7
Training loss: 0.11023094539592677
Validation loss: 2.2199532485616955

Epoch: 6| Step: 8
Training loss: 0.09323692990947155
Validation loss: 2.215291917370691

Epoch: 6| Step: 9
Training loss: 0.07049086253406948
Validation loss: 2.207057642073338

Epoch: 6| Step: 10
Training loss: 0.1265968605776167
Validation loss: 2.2174789835705564

Epoch: 6| Step: 11
Training loss: 0.2473084956484345
Validation loss: 2.2243812030092522

Epoch: 6| Step: 12
Training loss: 0.22533431614189095
Validation loss: 2.192376295759213

Epoch: 6| Step: 13
Training loss: 0.20331294278173725
Validation loss: 2.209145804168095

Epoch: 475| Step: 0
Training loss: 0.17200135874766007
Validation loss: 2.187602249662231

Epoch: 6| Step: 1
Training loss: 0.1872756529770053
Validation loss: 2.1618271948963437

Epoch: 6| Step: 2
Training loss: 0.11670560300593856
Validation loss: 2.1787353122427833

Epoch: 6| Step: 3
Training loss: 0.13844624821079926
Validation loss: 2.1970422824392326

Epoch: 6| Step: 4
Training loss: 0.21251682397215163
Validation loss: 2.1716163972925053

Epoch: 6| Step: 5
Training loss: 0.11211815560410483
Validation loss: 2.178634207347578

Epoch: 6| Step: 6
Training loss: 0.12698146797120535
Validation loss: 2.2366294625219214

Epoch: 6| Step: 7
Training loss: 0.15590983556316337
Validation loss: 2.251009839817626

Epoch: 6| Step: 8
Training loss: 0.17696044435163347
Validation loss: 2.2830277785458386

Epoch: 6| Step: 9
Training loss: 0.17086496842852247
Validation loss: 2.2662465567883605

Epoch: 6| Step: 10
Training loss: 0.09791885829647332
Validation loss: 2.2674811810806745

Epoch: 6| Step: 11
Training loss: 0.08507510166295956
Validation loss: 2.2720719122880606

Epoch: 6| Step: 12
Training loss: 0.223577742480098
Validation loss: 2.2418073294933794

Epoch: 6| Step: 13
Training loss: 0.15747518015566725
Validation loss: 2.230842285646993

Epoch: 476| Step: 0
Training loss: 0.11446969039347424
Validation loss: 2.2015636074517198

Epoch: 6| Step: 1
Training loss: 0.148508920553343
Validation loss: 2.159688736738289

Epoch: 6| Step: 2
Training loss: 0.2020135512421474
Validation loss: 2.1585662864396493

Epoch: 6| Step: 3
Training loss: 0.14921566625474406
Validation loss: 2.1448446860222203

Epoch: 6| Step: 4
Training loss: 0.15550337266944245
Validation loss: 2.1683307410899832

Epoch: 6| Step: 5
Training loss: 0.13256905487046713
Validation loss: 2.1681143899023376

Epoch: 6| Step: 6
Training loss: 0.14123931457182048
Validation loss: 2.135572491014451

Epoch: 6| Step: 7
Training loss: 0.21356200299694986
Validation loss: 2.134497483154352

Epoch: 6| Step: 8
Training loss: 0.10571915429568246
Validation loss: 2.1727066837913087

Epoch: 6| Step: 9
Training loss: 0.14231434027294915
Validation loss: 2.1636995543025095

Epoch: 6| Step: 10
Training loss: 0.18577178574847297
Validation loss: 2.1864908688767284

Epoch: 6| Step: 11
Training loss: 0.1344794469045452
Validation loss: 2.1757178432564563

Epoch: 6| Step: 12
Training loss: 0.12783195314922235
Validation loss: 2.1926535061542705

Epoch: 6| Step: 13
Training loss: 0.08832061014627195
Validation loss: 2.1955592927933036

Epoch: 477| Step: 0
Training loss: 0.0683317707730421
Validation loss: 2.1923743447089703

Epoch: 6| Step: 1
Training loss: 0.1037335710559001
Validation loss: 2.2149460481662655

Epoch: 6| Step: 2
Training loss: 0.20716741870207586
Validation loss: 2.1997869928221716

Epoch: 6| Step: 3
Training loss: 0.17876099057521588
Validation loss: 2.1636282742594433

Epoch: 6| Step: 4
Training loss: 0.20159922272659128
Validation loss: 2.1642085745341317

Epoch: 6| Step: 5
Training loss: 0.1413215763057252
Validation loss: 2.1557952308551505

Epoch: 6| Step: 6
Training loss: 0.14113459706596967
Validation loss: 2.1434744398741037

Epoch: 6| Step: 7
Training loss: 0.11025170221820366
Validation loss: 2.141437255155087

Epoch: 6| Step: 8
Training loss: 0.059990049029981
Validation loss: 2.1432313799564757

Epoch: 6| Step: 9
Training loss: 0.0819431126626858
Validation loss: 2.111973119627196

Epoch: 6| Step: 10
Training loss: 0.14955115418015866
Validation loss: 2.173607531293891

Epoch: 6| Step: 11
Training loss: 0.0967082838672351
Validation loss: 2.156494378830824

Epoch: 6| Step: 12
Training loss: 0.11650359144911719
Validation loss: 2.141707286048114

Epoch: 6| Step: 13
Training loss: 0.1142318851038887
Validation loss: 2.168691218348704

Epoch: 478| Step: 0
Training loss: 0.14367796995418153
Validation loss: 2.1856497919485234

Epoch: 6| Step: 1
Training loss: 0.09478092108681065
Validation loss: 2.182495804460459

Epoch: 6| Step: 2
Training loss: 0.22535030229083536
Validation loss: 2.216004920415442

Epoch: 6| Step: 3
Training loss: 0.11843202488958922
Validation loss: 2.206238655415107

Epoch: 6| Step: 4
Training loss: 0.23813313430249272
Validation loss: 2.215055754579823

Epoch: 6| Step: 5
Training loss: 0.10877089049027208
Validation loss: 2.214057866420771

Epoch: 6| Step: 6
Training loss: 0.1528548324200102
Validation loss: 2.181370634323178

Epoch: 6| Step: 7
Training loss: 0.10701771915139595
Validation loss: 2.138585397040769

Epoch: 6| Step: 8
Training loss: 0.12658873127264772
Validation loss: 2.155887166914265

Epoch: 6| Step: 9
Training loss: 0.09760250997087272
Validation loss: 2.1863483145453526

Epoch: 6| Step: 10
Training loss: 0.0725730112828373
Validation loss: 2.1743913033084397

Epoch: 6| Step: 11
Training loss: 0.1283690283170131
Validation loss: 2.2027138971046076

Epoch: 6| Step: 12
Training loss: 0.1082752662095237
Validation loss: 2.178257749420418

Epoch: 6| Step: 13
Training loss: 0.1289605185398565
Validation loss: 2.185255251928282

Epoch: 479| Step: 0
Training loss: 0.21244918482137687
Validation loss: 2.1729900141692977

Epoch: 6| Step: 1
Training loss: 0.12426933182413873
Validation loss: 2.172302829557564

Epoch: 6| Step: 2
Training loss: 0.14906872002601843
Validation loss: 2.1575776849067023

Epoch: 6| Step: 3
Training loss: 0.1085485673121523
Validation loss: 2.181099913219663

Epoch: 6| Step: 4
Training loss: 0.14219280982321003
Validation loss: 2.1779194144077487

Epoch: 6| Step: 5
Training loss: 0.11394002524876913
Validation loss: 2.206463069597581

Epoch: 6| Step: 6
Training loss: 0.07458999292159466
Validation loss: 2.242931373916184

Epoch: 6| Step: 7
Training loss: 0.20439535652063295
Validation loss: 2.2480149542356718

Epoch: 6| Step: 8
Training loss: 0.1988544030801744
Validation loss: 2.227960573272437

Epoch: 6| Step: 9
Training loss: 0.08531347664598922
Validation loss: 2.2440575525453723

Epoch: 6| Step: 10
Training loss: 0.13435989616586644
Validation loss: 2.252705308098296

Epoch: 6| Step: 11
Training loss: 0.1179518488593733
Validation loss: 2.25206652575992

Epoch: 6| Step: 12
Training loss: 0.11870041018845387
Validation loss: 2.234748018088019

Epoch: 6| Step: 13
Training loss: 0.21322120582846904
Validation loss: 2.2232217126173386

Epoch: 480| Step: 0
Training loss: 0.07851860908986652
Validation loss: 2.2048717734188026

Epoch: 6| Step: 1
Training loss: 0.09943184740357155
Validation loss: 2.2243501677727866

Epoch: 6| Step: 2
Training loss: 0.10103253412595806
Validation loss: 2.2016565494792864

Epoch: 6| Step: 3
Training loss: 0.1245073355108913
Validation loss: 2.172584622559118

Epoch: 6| Step: 4
Training loss: 0.20294001298763586
Validation loss: 2.173617919780512

Epoch: 6| Step: 5
Training loss: 0.27886654974643693
Validation loss: 2.1676377099597377

Epoch: 6| Step: 6
Training loss: 0.16862793697778564
Validation loss: 2.172693518098446

Epoch: 6| Step: 7
Training loss: 0.11097425973363442
Validation loss: 2.2058593984298684

Epoch: 6| Step: 8
Training loss: 0.20083102266148425
Validation loss: 2.1935515122855844

Epoch: 6| Step: 9
Training loss: 0.09217018453784469
Validation loss: 2.1874905634382076

Epoch: 6| Step: 10
Training loss: 0.21460365404433746
Validation loss: 2.2090761251537137

Epoch: 6| Step: 11
Training loss: 0.13807483882086535
Validation loss: 2.2039962159564217

Epoch: 6| Step: 12
Training loss: 0.12887431963020424
Validation loss: 2.2085438773270702

Epoch: 6| Step: 13
Training loss: 0.20905056912258718
Validation loss: 2.2191402722358005

Epoch: 481| Step: 0
Training loss: 0.1485335641508532
Validation loss: 2.223405904319632

Epoch: 6| Step: 1
Training loss: 0.2421372269165963
Validation loss: 2.2278247921587977

Epoch: 6| Step: 2
Training loss: 0.11442261409611977
Validation loss: 2.2222486968240887

Epoch: 6| Step: 3
Training loss: 0.09722939663009689
Validation loss: 2.2557101070996275

Epoch: 6| Step: 4
Training loss: 0.13582757281475633
Validation loss: 2.2348122163595976

Epoch: 6| Step: 5
Training loss: 0.12414112289621748
Validation loss: 2.250372281034033

Epoch: 6| Step: 6
Training loss: 0.20584909750022715
Validation loss: 2.245833452362356

Epoch: 6| Step: 7
Training loss: 0.10646169431426776
Validation loss: 2.2706198236801565

Epoch: 6| Step: 8
Training loss: 0.12317024585653502
Validation loss: 2.2100053996033755

Epoch: 6| Step: 9
Training loss: 0.19766638432030137
Validation loss: 2.257054683705477

Epoch: 6| Step: 10
Training loss: 0.17828543615483242
Validation loss: 2.236031006744874

Epoch: 6| Step: 11
Training loss: 0.13320858180707315
Validation loss: 2.2315093656801457

Epoch: 6| Step: 12
Training loss: 0.11637895123199801
Validation loss: 2.2550470995115064

Epoch: 6| Step: 13
Training loss: 0.06563991607018946
Validation loss: 2.2591235951313084

Epoch: 482| Step: 0
Training loss: 0.1944439266875352
Validation loss: 2.2567579512826996

Epoch: 6| Step: 1
Training loss: 0.2111574015736282
Validation loss: 2.2739284582771733

Epoch: 6| Step: 2
Training loss: 0.25311272673816426
Validation loss: 2.318815406093767

Epoch: 6| Step: 3
Training loss: 0.1571646681086191
Validation loss: 2.319857419621713

Epoch: 6| Step: 4
Training loss: 0.1328401747087605
Validation loss: 2.3241422813481467

Epoch: 6| Step: 5
Training loss: 0.1879079077181388
Validation loss: 2.3077743644984094

Epoch: 6| Step: 6
Training loss: 0.09131262255261582
Validation loss: 2.298781095648852

Epoch: 6| Step: 7
Training loss: 0.08647316641225614
Validation loss: 2.2288725076863134

Epoch: 6| Step: 8
Training loss: 0.12528842938615178
Validation loss: 2.2409441038857607

Epoch: 6| Step: 9
Training loss: 0.20414895780471576
Validation loss: 2.192961036790172

Epoch: 6| Step: 10
Training loss: 0.158417321242499
Validation loss: 2.1937015306640983

Epoch: 6| Step: 11
Training loss: 0.16312489072934871
Validation loss: 2.172776366948225

Epoch: 6| Step: 12
Training loss: 0.22891949559970193
Validation loss: 2.153262274670157

Epoch: 6| Step: 13
Training loss: 0.220740526119171
Validation loss: 2.129636439292277

Epoch: 483| Step: 0
Training loss: 0.15329651131517302
Validation loss: 2.136724271484267

Epoch: 6| Step: 1
Training loss: 0.21715984374226555
Validation loss: 2.1388007033377137

Epoch: 6| Step: 2
Training loss: 0.21446102037470244
Validation loss: 2.1100815550184664

Epoch: 6| Step: 3
Training loss: 0.11522799005438189
Validation loss: 2.1509742734204504

Epoch: 6| Step: 4
Training loss: 0.21692275782955528
Validation loss: 2.151304482845508

Epoch: 6| Step: 5
Training loss: 0.11473925144004987
Validation loss: 2.1859160341734953

Epoch: 6| Step: 6
Training loss: 0.1371535336061836
Validation loss: 2.21588110472606

Epoch: 6| Step: 7
Training loss: 0.14200151457448956
Validation loss: 2.224702558445966

Epoch: 6| Step: 8
Training loss: 0.23018624076012023
Validation loss: 2.221876279076746

Epoch: 6| Step: 9
Training loss: 0.15211788575903243
Validation loss: 2.2565653188201065

Epoch: 6| Step: 10
Training loss: 0.1084108087851774
Validation loss: 2.216483750137567

Epoch: 6| Step: 11
Training loss: 0.14576156303380064
Validation loss: 2.2057888450403733

Epoch: 6| Step: 12
Training loss: 0.2213039490826189
Validation loss: 2.171435982447064

Epoch: 6| Step: 13
Training loss: 0.0764014348997483
Validation loss: 2.174833325454346

Epoch: 484| Step: 0
Training loss: 0.17088775601384937
Validation loss: 2.177850861654942

Epoch: 6| Step: 1
Training loss: 0.21638162038956565
Validation loss: 2.2002889729589294

Epoch: 6| Step: 2
Training loss: 0.09273174252425231
Validation loss: 2.1942062968690093

Epoch: 6| Step: 3
Training loss: 0.11662650935718327
Validation loss: 2.221682323628687

Epoch: 6| Step: 4
Training loss: 0.11079212455480345
Validation loss: 2.2082566472222576

Epoch: 6| Step: 5
Training loss: 0.13580467651960534
Validation loss: 2.241219065783249

Epoch: 6| Step: 6
Training loss: 0.17676439852589576
Validation loss: 2.2185315988434713

Epoch: 6| Step: 7
Training loss: 0.1374520662593709
Validation loss: 2.2245763999718244

Epoch: 6| Step: 8
Training loss: 0.1871531477120242
Validation loss: 2.254563126460785

Epoch: 6| Step: 9
Training loss: 0.1008382013480127
Validation loss: 2.2300760436256737

Epoch: 6| Step: 10
Training loss: 0.19119304343358595
Validation loss: 2.231572238348471

Epoch: 6| Step: 11
Training loss: 0.11830914473322673
Validation loss: 2.1927486473748066

Epoch: 6| Step: 12
Training loss: 0.12909113745214718
Validation loss: 2.2159084858467923

Epoch: 6| Step: 13
Training loss: 0.1481799539099152
Validation loss: 2.204846598138949

Epoch: 485| Step: 0
Training loss: 0.21901810769007968
Validation loss: 2.2179573072339207

Epoch: 6| Step: 1
Training loss: 0.2151619375636509
Validation loss: 2.196159177625817

Epoch: 6| Step: 2
Training loss: 0.11484287320016408
Validation loss: 2.2101287191561756

Epoch: 6| Step: 3
Training loss: 0.17548711858076593
Validation loss: 2.1890057106115033

Epoch: 6| Step: 4
Training loss: 0.10573924663330883
Validation loss: 2.194957153349123

Epoch: 6| Step: 5
Training loss: 0.1306577524164035
Validation loss: 2.1919218979732094

Epoch: 6| Step: 6
Training loss: 0.11483137330036315
Validation loss: 2.2187515829572586

Epoch: 6| Step: 7
Training loss: 0.10920731002286824
Validation loss: 2.1952536332046693

Epoch: 6| Step: 8
Training loss: 0.1453375300005551
Validation loss: 2.186659838804354

Epoch: 6| Step: 9
Training loss: 0.1526274789953304
Validation loss: 2.212235132595216

Epoch: 6| Step: 10
Training loss: 0.19748779099186617
Validation loss: 2.2159034555297885

Epoch: 6| Step: 11
Training loss: 0.12057667747657876
Validation loss: 2.218209829036369

Epoch: 6| Step: 12
Training loss: 0.12494176014511225
Validation loss: 2.2542158848148075

Epoch: 6| Step: 13
Training loss: 0.07775647146463112
Validation loss: 2.2643754165877863

Epoch: 486| Step: 0
Training loss: 0.14513538369735307
Validation loss: 2.299168836299448

Epoch: 6| Step: 1
Training loss: 0.188458338039223
Validation loss: 2.2364313690990043

Epoch: 6| Step: 2
Training loss: 0.14226436057201827
Validation loss: 2.252094918314461

Epoch: 6| Step: 3
Training loss: 0.11385954623486272
Validation loss: 2.2270828591791942

Epoch: 6| Step: 4
Training loss: 0.09488549614633321
Validation loss: 2.1966139476597784

Epoch: 6| Step: 5
Training loss: 0.10762848491874899
Validation loss: 2.2082579358588292

Epoch: 6| Step: 6
Training loss: 0.11023634406642008
Validation loss: 2.2042616640189836

Epoch: 6| Step: 7
Training loss: 0.10981369594993103
Validation loss: 2.163726538895298

Epoch: 6| Step: 8
Training loss: 0.12310449447016321
Validation loss: 2.1799157153609774

Epoch: 6| Step: 9
Training loss: 0.18982506648303268
Validation loss: 2.157182019748507

Epoch: 6| Step: 10
Training loss: 0.09274447139485391
Validation loss: 2.218069266748557

Epoch: 6| Step: 11
Training loss: 0.17292189379531953
Validation loss: 2.1884596317994096

Epoch: 6| Step: 12
Training loss: 0.13053936760373788
Validation loss: 2.2032201829752123

Epoch: 6| Step: 13
Training loss: 0.08661362606143905
Validation loss: 2.1904496143422856

Epoch: 487| Step: 0
Training loss: 0.13371120052774266
Validation loss: 2.2330155433802403

Epoch: 6| Step: 1
Training loss: 0.14113876086342397
Validation loss: 2.235209743879287

Epoch: 6| Step: 2
Training loss: 0.1540477528197388
Validation loss: 2.216838391585502

Epoch: 6| Step: 3
Training loss: 0.11234381864728674
Validation loss: 2.2085770719948616

Epoch: 6| Step: 4
Training loss: 0.15167477028239723
Validation loss: 2.2433158062500667

Epoch: 6| Step: 5
Training loss: 0.11281997390409915
Validation loss: 2.205769272949449

Epoch: 6| Step: 6
Training loss: 0.09359887976750411
Validation loss: 2.188484952244424

Epoch: 6| Step: 7
Training loss: 0.09843210061720839
Validation loss: 2.193880366896654

Epoch: 6| Step: 8
Training loss: 0.09679967485955258
Validation loss: 2.190481232880822

Epoch: 6| Step: 9
Training loss: 0.2018613019966861
Validation loss: 2.201753972713959

Epoch: 6| Step: 10
Training loss: 0.14604765322881835
Validation loss: 2.1843265056325034

Epoch: 6| Step: 11
Training loss: 0.18845526421732883
Validation loss: 2.174931271256511

Epoch: 6| Step: 12
Training loss: 0.19351403957636903
Validation loss: 2.2141523339464233

Epoch: 6| Step: 13
Training loss: 0.23911760075423422
Validation loss: 2.1701223071268108

Epoch: 488| Step: 0
Training loss: 0.1224044917642349
Validation loss: 2.2154711173924286

Epoch: 6| Step: 1
Training loss: 0.09160836119320986
Validation loss: 2.193060224535822

Epoch: 6| Step: 2
Training loss: 0.12265950490192382
Validation loss: 2.242100447007092

Epoch: 6| Step: 3
Training loss: 0.1421895283774435
Validation loss: 2.2459487732712042

Epoch: 6| Step: 4
Training loss: 0.22142227284476002
Validation loss: 2.23668981868257

Epoch: 6| Step: 5
Training loss: 0.14872817390259466
Validation loss: 2.2264765805079842

Epoch: 6| Step: 6
Training loss: 0.22070542055809778
Validation loss: 2.1623762245280056

Epoch: 6| Step: 7
Training loss: 0.16582251144047505
Validation loss: 2.1457375687152376

Epoch: 6| Step: 8
Training loss: 0.12276283662612172
Validation loss: 2.1349707937571223

Epoch: 6| Step: 9
Training loss: 0.2222000853411951
Validation loss: 2.1282963427285067

Epoch: 6| Step: 10
Training loss: 0.14891798905796072
Validation loss: 2.1539471209167877

Epoch: 6| Step: 11
Training loss: 0.13626435928185554
Validation loss: 2.2032616697340797

Epoch: 6| Step: 12
Training loss: 0.16811506973245244
Validation loss: 2.255252816002814

Epoch: 6| Step: 13
Training loss: 0.13395910525235513
Validation loss: 2.241120778037357

Epoch: 489| Step: 0
Training loss: 0.13855629120149474
Validation loss: 2.285513910687743

Epoch: 6| Step: 1
Training loss: 0.10705779974970059
Validation loss: 2.2926873097977927

Epoch: 6| Step: 2
Training loss: 0.21225231616123502
Validation loss: 2.3250946140124817

Epoch: 6| Step: 3
Training loss: 0.2024804029430578
Validation loss: 2.3133384312109

Epoch: 6| Step: 4
Training loss: 0.151879299538588
Validation loss: 2.2986183417539183

Epoch: 6| Step: 5
Training loss: 0.22189242704213227
Validation loss: 2.2641744199764813

Epoch: 6| Step: 6
Training loss: 0.09868190034872736
Validation loss: 2.217493320972081

Epoch: 6| Step: 7
Training loss: 0.09508994297814874
Validation loss: 2.1745488028489977

Epoch: 6| Step: 8
Training loss: 0.18917553021409725
Validation loss: 2.1274876278649257

Epoch: 6| Step: 9
Training loss: 0.13190518432644002
Validation loss: 2.110168388038298

Epoch: 6| Step: 10
Training loss: 0.237745096138542
Validation loss: 2.094888526045144

Epoch: 6| Step: 11
Training loss: 0.18287854183649682
Validation loss: 2.1123058471612786

Epoch: 6| Step: 12
Training loss: 0.1441015092245217
Validation loss: 2.113468517233861

Epoch: 6| Step: 13
Training loss: 0.24552531669325545
Validation loss: 2.1408289707469113

Epoch: 490| Step: 0
Training loss: 0.1114445044578142
Validation loss: 2.1779792058313214

Epoch: 6| Step: 1
Training loss: 0.16848998922174335
Validation loss: 2.1568407209915486

Epoch: 6| Step: 2
Training loss: 0.13763743056514763
Validation loss: 2.1634157087234374

Epoch: 6| Step: 3
Training loss: 0.10566667246812259
Validation loss: 2.185118429749104

Epoch: 6| Step: 4
Training loss: 0.21988844947820296
Validation loss: 2.19834200809273

Epoch: 6| Step: 5
Training loss: 0.10488036950247982
Validation loss: 2.204142625002505

Epoch: 6| Step: 6
Training loss: 0.18911012097088414
Validation loss: 2.192460908980349

Epoch: 6| Step: 7
Training loss: 0.17316355807805098
Validation loss: 2.1841059827689455

Epoch: 6| Step: 8
Training loss: 0.09814210670475032
Validation loss: 2.1962662401115485

Epoch: 6| Step: 9
Training loss: 0.15501139980548956
Validation loss: 2.173814948409219

Epoch: 6| Step: 10
Training loss: 0.12116568489914421
Validation loss: 2.1988997811954065

Epoch: 6| Step: 11
Training loss: 0.1017236760333972
Validation loss: 2.1948089833783464

Epoch: 6| Step: 12
Training loss: 0.20425640055375793
Validation loss: 2.227327182605276

Epoch: 6| Step: 13
Training loss: 0.20547353680912708
Validation loss: 2.2280569556554948

Epoch: 491| Step: 0
Training loss: 0.19153071268896021
Validation loss: 2.2618640726374077

Epoch: 6| Step: 1
Training loss: 0.14671860088548
Validation loss: 2.2891260082497173

Epoch: 6| Step: 2
Training loss: 0.2753808175362944
Validation loss: 2.3513488083737655

Epoch: 6| Step: 3
Training loss: 0.14009103462358302
Validation loss: 2.338789804597299

Epoch: 6| Step: 4
Training loss: 0.19475935809981862
Validation loss: 2.3152539318654353

Epoch: 6| Step: 5
Training loss: 0.2201607039185848
Validation loss: 2.2888167838536244

Epoch: 6| Step: 6
Training loss: 0.16451167312579773
Validation loss: 2.2399566129450363

Epoch: 6| Step: 7
Training loss: 0.16645691507791213
Validation loss: 2.2117710122955283

Epoch: 6| Step: 8
Training loss: 0.0860648512065463
Validation loss: 2.1961587970764795

Epoch: 6| Step: 9
Training loss: 0.15827867093484566
Validation loss: 2.1587525276803774

Epoch: 6| Step: 10
Training loss: 0.1251856572538818
Validation loss: 2.1539783356264226

Epoch: 6| Step: 11
Training loss: 0.23005823169190417
Validation loss: 2.1303332201150527

Epoch: 6| Step: 12
Training loss: 0.1902160032514905
Validation loss: 2.1258455147044515

Epoch: 6| Step: 13
Training loss: 0.18618648111577452
Validation loss: 2.1570085841080484

Epoch: 492| Step: 0
Training loss: 0.1408335278747652
Validation loss: 2.1952656762192606

Epoch: 6| Step: 1
Training loss: 0.149099067805035
Validation loss: 2.2384836044259524

Epoch: 6| Step: 2
Training loss: 0.2240337791816253
Validation loss: 2.265607469014937

Epoch: 6| Step: 3
Training loss: 0.324054687998093
Validation loss: 2.286392187598374

Epoch: 6| Step: 4
Training loss: 0.15256664891209887
Validation loss: 2.2452333518903407

Epoch: 6| Step: 5
Training loss: 0.429519932758417
Validation loss: 2.2423399909500676

Epoch: 6| Step: 6
Training loss: 0.2655242981478243
Validation loss: 2.1976456884561673

Epoch: 6| Step: 7
Training loss: 0.20981711851348553
Validation loss: 2.180717823408922

Epoch: 6| Step: 8
Training loss: 0.2642516649296622
Validation loss: 2.217769087068693

Epoch: 6| Step: 9
Training loss: 0.37409345006416883
Validation loss: 2.2732055058548086

Epoch: 6| Step: 10
Training loss: 0.23628139822069436
Validation loss: 2.3018340313261696

Epoch: 6| Step: 11
Training loss: 0.29556209975740044
Validation loss: 2.3607263468916098

Epoch: 6| Step: 12
Training loss: 0.39076966467961216
Validation loss: 2.439681989400609

Epoch: 6| Step: 13
Training loss: 0.2811488658481892
Validation loss: 2.442975214100386

Epoch: 493| Step: 0
Training loss: 0.36156929833986684
Validation loss: 2.442062838036397

Epoch: 6| Step: 1
Training loss: 0.2823690299035834
Validation loss: 2.4278129196855636

Epoch: 6| Step: 2
Training loss: 0.28271560800610485
Validation loss: 2.394105398532624

Epoch: 6| Step: 3
Training loss: 0.25707506426697546
Validation loss: 2.3707699921341208

Epoch: 6| Step: 4
Training loss: 0.25255321041166956
Validation loss: 2.310542453484982

Epoch: 6| Step: 5
Training loss: 0.17669668247042467
Validation loss: 2.305914701831125

Epoch: 6| Step: 6
Training loss: 0.2116926416437738
Validation loss: 2.2643089293765706

Epoch: 6| Step: 7
Training loss: 0.30506089145960813
Validation loss: 2.2773724262902544

Epoch: 6| Step: 8
Training loss: 0.30759549745658027
Validation loss: 2.304746168421227

Epoch: 6| Step: 9
Training loss: 0.3358277429883702
Validation loss: 2.332204295798222

Epoch: 6| Step: 10
Training loss: 0.24434137101996672
Validation loss: 2.239013526891068

Epoch: 6| Step: 11
Training loss: 0.27481497804289234
Validation loss: 2.206793840732315

Epoch: 6| Step: 12
Training loss: 0.1782980772363515
Validation loss: 2.2241477331384245

Epoch: 6| Step: 13
Training loss: 0.14972442605524383
Validation loss: 2.1815769032276147

Epoch: 494| Step: 0
Training loss: 0.28938077467724077
Validation loss: 2.209366891065777

Epoch: 6| Step: 1
Training loss: 0.3870022052805559
Validation loss: 2.185272438564757

Epoch: 6| Step: 2
Training loss: 0.5146598163193721
Validation loss: 2.174671037940652

Epoch: 6| Step: 3
Training loss: 0.33860584042047304
Validation loss: 2.171743817903666

Epoch: 6| Step: 4
Training loss: 0.3586047251897994
Validation loss: 2.1936133990608186

Epoch: 6| Step: 5
Training loss: 0.4328720685268615
Validation loss: 2.2464028536778735

Epoch: 6| Step: 6
Training loss: 0.26339000187727885
Validation loss: 2.3331195459416123

Epoch: 6| Step: 7
Training loss: 0.33692409113456895
Validation loss: 2.3909204418300467

Epoch: 6| Step: 8
Training loss: 0.4897317018990035
Validation loss: 2.453930948853762

Epoch: 6| Step: 9
Training loss: 0.31436236475585494
Validation loss: 2.385097146056259

Epoch: 6| Step: 10
Training loss: 0.23273533431947419
Validation loss: 2.3433422081149895

Epoch: 6| Step: 11
Training loss: 0.26563349878515274
Validation loss: 2.3079700017734646

Epoch: 6| Step: 12
Training loss: 0.2358096875483806
Validation loss: 2.2729516510472227

Epoch: 6| Step: 13
Training loss: 0.11367094901451671
Validation loss: 2.235207852582415

Epoch: 495| Step: 0
Training loss: 0.28690915035356135
Validation loss: 2.228229011156352

Epoch: 6| Step: 1
Training loss: 0.2860657805474943
Validation loss: 2.192054633750666

Epoch: 6| Step: 2
Training loss: 0.29899361958202747
Validation loss: 2.2180921950673094

Epoch: 6| Step: 3
Training loss: 0.2920724254581213
Validation loss: 2.2406002098969897

Epoch: 6| Step: 4
Training loss: 0.34285211339451904
Validation loss: 2.240762072323334

Epoch: 6| Step: 5
Training loss: 0.3211214271738667
Validation loss: 2.3093391174222275

Epoch: 6| Step: 6
Training loss: 0.4647529256871205
Validation loss: 2.312269794121734

Epoch: 6| Step: 7
Training loss: 0.2612393814420364
Validation loss: 2.2778516419865906

Epoch: 6| Step: 8
Training loss: 0.3252854551640304
Validation loss: 2.269618342005351

Epoch: 6| Step: 9
Training loss: 0.3875677634024665
Validation loss: 2.260348016762429

Epoch: 6| Step: 10
Training loss: 0.22228261483796555
Validation loss: 2.2251507782553626

Epoch: 6| Step: 11
Training loss: 0.1706858811736471
Validation loss: 2.26123594525992

Epoch: 6| Step: 12
Training loss: 0.33142600152177365
Validation loss: 2.271177077507956

Epoch: 6| Step: 13
Training loss: 0.38247062052922237
Validation loss: 2.2327264116136387

Epoch: 496| Step: 0
Training loss: 0.18361982201039612
Validation loss: 2.265564423438327

Epoch: 6| Step: 1
Training loss: 0.18190074056838465
Validation loss: 2.2710280137850827

Epoch: 6| Step: 2
Training loss: 0.2189618515315152
Validation loss: 2.3044063429294006

Epoch: 6| Step: 3
Training loss: 0.1410944837042065
Validation loss: 2.3081444516381695

Epoch: 6| Step: 4
Training loss: 0.38072374325223646
Validation loss: 2.3197559351966826

Epoch: 6| Step: 5
Training loss: 0.3672540279749218
Validation loss: 2.322570580393166

Epoch: 6| Step: 6
Training loss: 0.3084368125614131
Validation loss: 2.333132265659791

Epoch: 6| Step: 7
Training loss: 0.20404922690461247
Validation loss: 2.283121089832974

Epoch: 6| Step: 8
Training loss: 0.3095316336262081
Validation loss: 2.315267143924969

Epoch: 6| Step: 9
Training loss: 0.324306636985938
Validation loss: 2.25624372594881

Epoch: 6| Step: 10
Training loss: 0.40724251622114244
Validation loss: 2.22352941830949

Epoch: 6| Step: 11
Training loss: 0.32302851688202666
Validation loss: 2.1635961566541857

Epoch: 6| Step: 12
Training loss: 0.29627988797331306
Validation loss: 2.2023339417535457

Epoch: 6| Step: 13
Training loss: 0.42032162468517625
Validation loss: 2.1711692097051736

Epoch: 497| Step: 0
Training loss: 0.38025429417369316
Validation loss: 2.202569210568596

Epoch: 6| Step: 1
Training loss: 0.34996641031936465
Validation loss: 2.2689764917657635

Epoch: 6| Step: 2
Training loss: 0.3414020219449393
Validation loss: 2.2873335972966493

Epoch: 6| Step: 3
Training loss: 0.6469513742077486
Validation loss: 2.3359339995904502

Epoch: 6| Step: 4
Training loss: 0.27228918096803395
Validation loss: 2.2476942993758957

Epoch: 6| Step: 5
Training loss: 0.2404754096280817
Validation loss: 2.1840749891212847

Epoch: 6| Step: 6
Training loss: 0.3013529113433955
Validation loss: 2.209096558044823

Epoch: 6| Step: 7
Training loss: 0.5448342803228408
Validation loss: 2.2164735440545997

Epoch: 6| Step: 8
Training loss: 0.5544138219802347
Validation loss: 2.269547284478604

Epoch: 6| Step: 9
Training loss: 0.275099471915323
Validation loss: 2.2741845803544707

Epoch: 6| Step: 10
Training loss: 0.26563638774920256
Validation loss: 2.2667616163172575

Epoch: 6| Step: 11
Training loss: 0.3356528628804985
Validation loss: 2.3373144787616864

Epoch: 6| Step: 12
Training loss: 0.5305647357287369
Validation loss: 2.357682530856039

Epoch: 6| Step: 13
Training loss: 0.7134586527258062
Validation loss: 2.3311215804841736

Epoch: 498| Step: 0
Training loss: 0.25100158685395363
Validation loss: 2.3145196150092144

Epoch: 6| Step: 1
Training loss: 0.25637834637716356
Validation loss: 2.2988060752672737

Epoch: 6| Step: 2
Training loss: 0.34459526003701063
Validation loss: 2.289929044607333

Epoch: 6| Step: 3
Training loss: 0.3295745733043782
Validation loss: 2.282872456765267

Epoch: 6| Step: 4
Training loss: 0.41503062520146367
Validation loss: 2.290970479162685

Epoch: 6| Step: 5
Training loss: 0.6071033930775266
Validation loss: 2.309722860248724

Epoch: 6| Step: 6
Training loss: 0.37827667551847566
Validation loss: 2.257531041055571

Epoch: 6| Step: 7
Training loss: 0.397515557962324
Validation loss: 2.237404233123101

Epoch: 6| Step: 8
Training loss: 0.2942951186745178
Validation loss: 2.2493099182130702

Epoch: 6| Step: 9
Training loss: 0.4872882817321915
Validation loss: 2.3050763463490034

Epoch: 6| Step: 10
Training loss: 0.4873302812295899
Validation loss: 2.385069597287831

Epoch: 6| Step: 11
Training loss: 0.34927499220082664
Validation loss: 2.3342199164747246

Epoch: 6| Step: 12
Training loss: 0.3649496304690592
Validation loss: 2.3252833239745203

Epoch: 6| Step: 13
Training loss: 0.3340367950884246
Validation loss: 2.3011682002074743

Epoch: 499| Step: 0
Training loss: 0.35092335989260987
Validation loss: 2.30249898181012

Epoch: 6| Step: 1
Training loss: 0.38489158621145225
Validation loss: 2.2845345660367125

Epoch: 6| Step: 2
Training loss: 0.28540977547440766
Validation loss: 2.281430936125836

Epoch: 6| Step: 3
Training loss: 0.3897603383396764
Validation loss: 2.3091832498255966

Epoch: 6| Step: 4
Training loss: 0.3622730786295301
Validation loss: 2.310910617430976

Epoch: 6| Step: 5
Training loss: 0.3155035635116694
Validation loss: 2.356264437683495

Epoch: 6| Step: 6
Training loss: 0.28974266191641657
Validation loss: 2.3275010822189164

Epoch: 6| Step: 7
Training loss: 0.37441792612962765
Validation loss: 2.356550216796074

Epoch: 6| Step: 8
Training loss: 0.27277658151789214
Validation loss: 2.3259532329740584

Epoch: 6| Step: 9
Training loss: 0.18638008161022324
Validation loss: 2.321897284605999

Epoch: 6| Step: 10
Training loss: 0.48142551899858377
Validation loss: 2.3002932969656333

Epoch: 6| Step: 11
Training loss: 0.33251409764268675
Validation loss: 2.2733161921250824

Epoch: 6| Step: 12
Training loss: 0.30458019274324455
Validation loss: 2.266845420816931

Epoch: 6| Step: 13
Training loss: 0.35007104280370044
Validation loss: 2.2564561649407273

Epoch: 500| Step: 0
Training loss: 0.26494062840494836
Validation loss: 2.22091816248758

Epoch: 6| Step: 1
Training loss: 0.37156923851017903
Validation loss: 2.2209584356189813

Epoch: 6| Step: 2
Training loss: 0.17623745740063007
Validation loss: 2.2264103277421965

Epoch: 6| Step: 3
Training loss: 0.41296319964312916
Validation loss: 2.237211169521193

Epoch: 6| Step: 4
Training loss: 0.27068257109321336
Validation loss: 2.215006684990622

Epoch: 6| Step: 5
Training loss: 0.2604097397200886
Validation loss: 2.2145472239054365

Epoch: 6| Step: 6
Training loss: 0.30240938523994954
Validation loss: 2.1565526536165276

Epoch: 6| Step: 7
Training loss: 0.229964148393871
Validation loss: 2.1506087413178903

Epoch: 6| Step: 8
Training loss: 0.49383363498292726
Validation loss: 2.1727828150463804

Epoch: 6| Step: 9
Training loss: 0.16098217714400154
Validation loss: 2.173601577470367

Epoch: 6| Step: 10
Training loss: 0.271867276224501
Validation loss: 2.2278854334524136

Epoch: 6| Step: 11
Training loss: 0.31482049557966674
Validation loss: 2.3030935663817096

Epoch: 6| Step: 12
Training loss: 0.34063639228038484
Validation loss: 2.2866690385804325

Epoch: 6| Step: 13
Training loss: 0.13751520051165733
Validation loss: 2.255780211726447

Epoch: 501| Step: 0
Training loss: 0.2589057803106566
Validation loss: 2.2862035317054596

Epoch: 6| Step: 1
Training loss: 0.41211161680651354
Validation loss: 2.2669584842944697

Epoch: 6| Step: 2
Training loss: 0.5960791729785833
Validation loss: 2.271193310317186

Epoch: 6| Step: 3
Training loss: 0.26752041103800167
Validation loss: 2.258480382143696

Epoch: 6| Step: 4
Training loss: 0.16800518527855993
Validation loss: 2.2421763544419115

Epoch: 6| Step: 5
Training loss: 0.21037457551873687
Validation loss: 2.238084335411554

Epoch: 6| Step: 6
Training loss: 0.46825516331194067
Validation loss: 2.246032573621206

Epoch: 6| Step: 7
Training loss: 0.3657889414308208
Validation loss: 2.243378484020754

Epoch: 6| Step: 8
Training loss: 0.3410241902642319
Validation loss: 2.234417499666121

Epoch: 6| Step: 9
Training loss: 0.2650164336606082
Validation loss: 2.17958043709134

Epoch: 6| Step: 10
Training loss: 0.2948346545863876
Validation loss: 2.188600620429393

Epoch: 6| Step: 11
Training loss: 0.32190360340318797
Validation loss: 2.1556329056667893

Epoch: 6| Step: 12
Training loss: 0.1823250274558539
Validation loss: 2.137701458670267

Epoch: 6| Step: 13
Training loss: 0.24067366374237148
Validation loss: 2.1382498855583787

Epoch: 502| Step: 0
Training loss: 0.23181215821511217
Validation loss: 2.1205129421015876

Epoch: 6| Step: 1
Training loss: 0.30564885208261283
Validation loss: 2.1046573723028956

Epoch: 6| Step: 2
Training loss: 0.5324646863286978
Validation loss: 2.0999949639538817

Epoch: 6| Step: 3
Training loss: 0.23571484967418185
Validation loss: 2.128535267588089

Epoch: 6| Step: 4
Training loss: 0.26709068061097757
Validation loss: 2.1827563146212183

Epoch: 6| Step: 5
Training loss: 0.3853361286179639
Validation loss: 2.233813705752908

Epoch: 6| Step: 6
Training loss: 0.2834349768420108
Validation loss: 2.2326555015798886

Epoch: 6| Step: 7
Training loss: 0.3005214659201026
Validation loss: 2.2473504818055483

Epoch: 6| Step: 8
Training loss: 0.4022295150804064
Validation loss: 2.256502834644589

Epoch: 6| Step: 9
Training loss: 0.18125945263910553
Validation loss: 2.2123445655447522

Epoch: 6| Step: 10
Training loss: 0.1904846405554388
Validation loss: 2.225197673652231

Epoch: 6| Step: 11
Training loss: 0.26745634718808886
Validation loss: 2.240954685863173

Epoch: 6| Step: 12
Training loss: 0.4217223845046468
Validation loss: 2.2385773000077682

Epoch: 6| Step: 13
Training loss: 0.24639865364019992
Validation loss: 2.266570918743988

Epoch: 503| Step: 0
Training loss: 0.21923122946903886
Validation loss: 2.241112652829371

Epoch: 6| Step: 1
Training loss: 0.27454365015657045
Validation loss: 2.209669238070055

Epoch: 6| Step: 2
Training loss: 0.2511354381419868
Validation loss: 2.19326132231558

Epoch: 6| Step: 3
Training loss: 0.34890339072491316
Validation loss: 2.1984697921280545

Epoch: 6| Step: 4
Training loss: 0.16669860486642157
Validation loss: 2.214560259432565

Epoch: 6| Step: 5
Training loss: 0.36471537061035453
Validation loss: 2.2370092071044554

Epoch: 6| Step: 6
Training loss: 0.42965285421626687
Validation loss: 2.25564826297476

Epoch: 6| Step: 7
Training loss: 0.25872070561312777
Validation loss: 2.263068602806027

Epoch: 6| Step: 8
Training loss: 0.3157589024068773
Validation loss: 2.2732940043291974

Epoch: 6| Step: 9
Training loss: 0.20892284949354065
Validation loss: 2.3463325191283735

Epoch: 6| Step: 10
Training loss: 0.25088087996571046
Validation loss: 2.3376001870566725

Epoch: 6| Step: 11
Training loss: 0.32446421098404576
Validation loss: 2.3624590573113755

Epoch: 6| Step: 12
Training loss: 0.3220729367419335
Validation loss: 2.391751127011911

Epoch: 6| Step: 13
Training loss: 0.5609580469220229
Validation loss: 2.370963243230213

Epoch: 504| Step: 0
Training loss: 0.3524377524085307
Validation loss: 2.3400692986922507

Epoch: 6| Step: 1
Training loss: 0.27887376334285074
Validation loss: 2.3168381295618325

Epoch: 6| Step: 2
Training loss: 0.16343246124881047
Validation loss: 2.2570556406458615

Epoch: 6| Step: 3
Training loss: 0.39315957807322843
Validation loss: 2.2500583682129114

Epoch: 6| Step: 4
Training loss: 0.2714315266936799
Validation loss: 2.2226198895108618

Epoch: 6| Step: 5
Training loss: 0.3788804704213947
Validation loss: 2.2195776863431105

Epoch: 6| Step: 6
Training loss: 0.3434380069135373
Validation loss: 2.1691554906897714

Epoch: 6| Step: 7
Training loss: 0.2298935971124664
Validation loss: 2.180791488170708

Epoch: 6| Step: 8
Training loss: 0.3636378107394338
Validation loss: 2.1668542724711393

Epoch: 6| Step: 9
Training loss: 0.24049895533723428
Validation loss: 2.213843288730774

Epoch: 6| Step: 10
Training loss: 0.23836011832092271
Validation loss: 2.201869065231722

Epoch: 6| Step: 11
Training loss: 0.36196398074270114
Validation loss: 2.186003004888437

Epoch: 6| Step: 12
Training loss: 0.4084773990257375
Validation loss: 2.1920404264371784

Epoch: 6| Step: 13
Training loss: 0.24536129016781033
Validation loss: 2.1814030790162446

Epoch: 505| Step: 0
Training loss: 0.455931898165012
Validation loss: 2.1995469053240275

Epoch: 6| Step: 1
Training loss: 0.3814633202587071
Validation loss: 2.2382933163483627

Epoch: 6| Step: 2
Training loss: 0.2435569576472716
Validation loss: 2.250390743522163

Epoch: 6| Step: 3
Training loss: 0.3262792399154257
Validation loss: 2.251965220548659

Epoch: 6| Step: 4
Training loss: 0.2616313105030363
Validation loss: 2.25738965961137

Epoch: 6| Step: 5
Training loss: 0.31223302404255265
Validation loss: 2.294165132128865

Epoch: 6| Step: 6
Training loss: 0.23770054425113865
Validation loss: 2.2724325478284704

Epoch: 6| Step: 7
Training loss: 0.37343094313224134
Validation loss: 2.2820875760097445

Epoch: 6| Step: 8
Training loss: 0.3307144419578665
Validation loss: 2.271321502653917

Epoch: 6| Step: 9
Training loss: 0.3691267586177551
Validation loss: 2.252368842204954

Epoch: 6| Step: 10
Training loss: 0.2540763871830415
Validation loss: 2.2149331306530975

Epoch: 6| Step: 11
Training loss: 0.23402524123167684
Validation loss: 2.1720358705702787

Epoch: 6| Step: 12
Training loss: 0.32306078289311435
Validation loss: 2.1760236603932475

Epoch: 6| Step: 13
Training loss: 0.5178705792727533
Validation loss: 2.1353807653915267

Epoch: 506| Step: 0
Training loss: 0.3212034812970177
Validation loss: 2.162921445210569

Epoch: 6| Step: 1
Training loss: 0.3180004155655611
Validation loss: 2.187324492274154

Epoch: 6| Step: 2
Training loss: 0.2752438688522169
Validation loss: 2.1880969924920555

Epoch: 6| Step: 3
Training loss: 0.37535509542739287
Validation loss: 2.2048333790253007

Epoch: 6| Step: 4
Training loss: 0.21606190997852276
Validation loss: 2.2484376392625136

Epoch: 6| Step: 5
Training loss: 0.2715447447912905
Validation loss: 2.3439631244193024

Epoch: 6| Step: 6
Training loss: 0.23462399925258326
Validation loss: 2.331554490322789

Epoch: 6| Step: 7
Training loss: 0.38265857716075075
Validation loss: 2.3240755399154365

Epoch: 6| Step: 8
Training loss: 0.25064926477107924
Validation loss: 2.3437005828788666

Epoch: 6| Step: 9
Training loss: 0.3578384973002069
Validation loss: 2.3543396451624043

Epoch: 6| Step: 10
Training loss: 0.30393582325197716
Validation loss: 2.3342170828955884

Epoch: 6| Step: 11
Training loss: 0.2577044809794129
Validation loss: 2.288967661601077

Epoch: 6| Step: 12
Training loss: 0.3757539164224202
Validation loss: 2.253621546879543

Epoch: 6| Step: 13
Training loss: 0.14634099937296097
Validation loss: 2.240490085414543

Epoch: 507| Step: 0
Training loss: 0.20736280918561645
Validation loss: 2.2002239304903193

Epoch: 6| Step: 1
Training loss: 0.3815661792124728
Validation loss: 2.212605375043865

Epoch: 6| Step: 2
Training loss: 0.26710273111833016
Validation loss: 2.2162906200383725

Epoch: 6| Step: 3
Training loss: 0.41865472563770534
Validation loss: 2.217668971616843

Epoch: 6| Step: 4
Training loss: 0.36620054103081123
Validation loss: 2.185410454672598

Epoch: 6| Step: 5
Training loss: 0.3650627753085767
Validation loss: 2.194336898425775

Epoch: 6| Step: 6
Training loss: 0.23503225675838205
Validation loss: 2.242231351081961

Epoch: 6| Step: 7
Training loss: 0.21891434490476566
Validation loss: 2.242908312898817

Epoch: 6| Step: 8
Training loss: 0.23697564974819627
Validation loss: 2.290168437648124

Epoch: 6| Step: 9
Training loss: 0.23151714481808258
Validation loss: 2.3072139606813344

Epoch: 6| Step: 10
Training loss: 0.3748322747570224
Validation loss: 2.3629028266834444

Epoch: 6| Step: 11
Training loss: 0.4775772079491418
Validation loss: 2.34510804677267

Epoch: 6| Step: 12
Training loss: 0.29949368427858375
Validation loss: 2.3564966903835294

Epoch: 6| Step: 13
Training loss: 0.2270744475469365
Validation loss: 2.3360309758409685

Epoch: 508| Step: 0
Training loss: 0.2478352342161569
Validation loss: 2.3494326354084247

Epoch: 6| Step: 1
Training loss: 0.23253465368576096
Validation loss: 2.3132375158035825

Epoch: 6| Step: 2
Training loss: 0.24733802555036297
Validation loss: 2.3104331866727237

Epoch: 6| Step: 3
Training loss: 0.330743671709909
Validation loss: 2.3022307062609713

Epoch: 6| Step: 4
Training loss: 0.24177365168405654
Validation loss: 2.308055624451668

Epoch: 6| Step: 5
Training loss: 0.2416893928148892
Validation loss: 2.266168673824046

Epoch: 6| Step: 6
Training loss: 0.3350557799125245
Validation loss: 2.323757485924067

Epoch: 6| Step: 7
Training loss: 0.386726475648101
Validation loss: 2.2896732886122746

Epoch: 6| Step: 8
Training loss: 0.33743072920335493
Validation loss: 2.2853687923408574

Epoch: 6| Step: 9
Training loss: 0.22285015463488808
Validation loss: 2.289594741334987

Epoch: 6| Step: 10
Training loss: 0.12724380959534187
Validation loss: 2.3181678802152823

Epoch: 6| Step: 11
Training loss: 0.2984186246405224
Validation loss: 2.30546605228468

Epoch: 6| Step: 12
Training loss: 0.26708532465541046
Validation loss: 2.3229522599345738

Epoch: 6| Step: 13
Training loss: 0.5341470209765113
Validation loss: 2.3340559146746855

Epoch: 509| Step: 0
Training loss: 0.31779629109926966
Validation loss: 2.331712728749046

Epoch: 6| Step: 1
Training loss: 0.17756928122735938
Validation loss: 2.314109297710946

Epoch: 6| Step: 2
Training loss: 0.31112260053390633
Validation loss: 2.2951603205866618

Epoch: 6| Step: 3
Training loss: 0.24536603477101096
Validation loss: 2.300469685196523

Epoch: 6| Step: 4
Training loss: 0.2450448343554069
Validation loss: 2.313547331248684

Epoch: 6| Step: 5
Training loss: 0.18750427161755098
Validation loss: 2.294109004157347

Epoch: 6| Step: 6
Training loss: 0.186817456734511
Validation loss: 2.2867273430367994

Epoch: 6| Step: 7
Training loss: 0.2498014078528938
Validation loss: 2.3282970852957305

Epoch: 6| Step: 8
Training loss: 0.2829676207968026
Validation loss: 2.3002191246144084

Epoch: 6| Step: 9
Training loss: 0.21855515078579887
Validation loss: 2.2942282834647476

Epoch: 6| Step: 10
Training loss: 0.3376840389878519
Validation loss: 2.2901650827697293

Epoch: 6| Step: 11
Training loss: 0.2414635096544529
Validation loss: 2.2770250551562015

Epoch: 6| Step: 12
Training loss: 0.22903357600309954
Validation loss: 2.2257186133839273

Epoch: 6| Step: 13
Training loss: 0.25700838224957395
Validation loss: 2.2528143417256214

Epoch: 510| Step: 0
Training loss: 0.21696362655108933
Validation loss: 2.2360883609405326

Epoch: 6| Step: 1
Training loss: 0.17619631823961954
Validation loss: 2.2152515811481126

Epoch: 6| Step: 2
Training loss: 0.26638079155238314
Validation loss: 2.2040605701842924

Epoch: 6| Step: 3
Training loss: 0.36713011272898033
Validation loss: 2.2251546562877835

Epoch: 6| Step: 4
Training loss: 0.21762712122153435
Validation loss: 2.2354685230611224

Epoch: 6| Step: 5
Training loss: 0.21875848072506188
Validation loss: 2.23161109288217

Epoch: 6| Step: 6
Training loss: 0.17821359480723376
Validation loss: 2.2521035275328867

Epoch: 6| Step: 7
Training loss: 0.21874133160990897
Validation loss: 2.271981191838272

Epoch: 6| Step: 8
Training loss: 0.17348126297483532
Validation loss: 2.275077951640284

Epoch: 6| Step: 9
Training loss: 0.27553002907611307
Validation loss: 2.3013241968141918

Epoch: 6| Step: 10
Training loss: 0.21288113179170387
Validation loss: 2.3110797648174874

Epoch: 6| Step: 11
Training loss: 0.27924175652244265
Validation loss: 2.2610482284899027

Epoch: 6| Step: 12
Training loss: 0.182128098309645
Validation loss: 2.2291446263401826

Epoch: 6| Step: 13
Training loss: 0.216808378928203
Validation loss: 2.2568738868187133

Epoch: 511| Step: 0
Training loss: 0.22922649830709074
Validation loss: 2.222995987212443

Epoch: 6| Step: 1
Training loss: 0.20399727050448857
Validation loss: 2.2463218837764987

Epoch: 6| Step: 2
Training loss: 0.2196059171281591
Validation loss: 2.204511523974345

Epoch: 6| Step: 3
Training loss: 0.17579522607131903
Validation loss: 2.2094611443506538

Epoch: 6| Step: 4
Training loss: 0.1374837047501172
Validation loss: 2.22447015376621

Epoch: 6| Step: 5
Training loss: 0.19541149491628923
Validation loss: 2.248643061462727

Epoch: 6| Step: 6
Training loss: 0.1595192487856021
Validation loss: 2.2367894220419857

Epoch: 6| Step: 7
Training loss: 0.1390694640591089
Validation loss: 2.2496471048527176

Epoch: 6| Step: 8
Training loss: 0.22699721329980396
Validation loss: 2.2735610813868945

Epoch: 6| Step: 9
Training loss: 0.16735406893660787
Validation loss: 2.2137816027051778

Epoch: 6| Step: 10
Training loss: 0.16147136379287338
Validation loss: 2.2231061468455335

Epoch: 6| Step: 11
Training loss: 0.30584017034384453
Validation loss: 2.2079722435671467

Epoch: 6| Step: 12
Training loss: 0.1409478190972903
Validation loss: 2.234198060341733

Epoch: 6| Step: 13
Training loss: 0.1330199304737746
Validation loss: 2.185356536312586

Epoch: 512| Step: 0
Training loss: 0.2140877165873404
Validation loss: 2.2067349183325167

Epoch: 6| Step: 1
Training loss: 0.14301377197285461
Validation loss: 2.212433679841704

Epoch: 6| Step: 2
Training loss: 0.20613215106787872
Validation loss: 2.1910457610335117

Epoch: 6| Step: 3
Training loss: 0.17621409318449574
Validation loss: 2.195104266889084

Epoch: 6| Step: 4
Training loss: 0.19282433631154142
Validation loss: 2.178478970200773

Epoch: 6| Step: 5
Training loss: 0.21330610905911185
Validation loss: 2.208791952945278

Epoch: 6| Step: 6
Training loss: 0.1897831431532652
Validation loss: 2.222231015150387

Epoch: 6| Step: 7
Training loss: 0.18016815169393172
Validation loss: 2.2114818631467137

Epoch: 6| Step: 8
Training loss: 0.2171847850986646
Validation loss: 2.246295870852989

Epoch: 6| Step: 9
Training loss: 0.10987368216554276
Validation loss: 2.2448107561555495

Epoch: 6| Step: 10
Training loss: 0.218834358366248
Validation loss: 2.204938784980524

Epoch: 6| Step: 11
Training loss: 0.2036862688498499
Validation loss: 2.2323715173705967

Epoch: 6| Step: 12
Training loss: 0.19878538530471426
Validation loss: 2.2441105987260217

Epoch: 6| Step: 13
Training loss: 0.17899148318338745
Validation loss: 2.2565123461567556

Epoch: 513| Step: 0
Training loss: 0.09543715712817342
Validation loss: 2.24997987134309

Epoch: 6| Step: 1
Training loss: 0.1929298021803162
Validation loss: 2.2870442156531663

Epoch: 6| Step: 2
Training loss: 0.22275310216856395
Validation loss: 2.266915466068104

Epoch: 6| Step: 3
Training loss: 0.21036248068070745
Validation loss: 2.268755497749637

Epoch: 6| Step: 4
Training loss: 0.22465778326746894
Validation loss: 2.254722224720072

Epoch: 6| Step: 5
Training loss: 0.12565051623878581
Validation loss: 2.233323723991682

Epoch: 6| Step: 6
Training loss: 0.11286278830258115
Validation loss: 2.2053933051657397

Epoch: 6| Step: 7
Training loss: 0.1715250136551256
Validation loss: 2.2012195071915106

Epoch: 6| Step: 8
Training loss: 0.1769704225014183
Validation loss: 2.188932851367219

Epoch: 6| Step: 9
Training loss: 0.21175425960147687
Validation loss: 2.170323729509833

Epoch: 6| Step: 10
Training loss: 0.153496786471055
Validation loss: 2.1729556959952574

Epoch: 6| Step: 11
Training loss: 0.14965312507315706
Validation loss: 2.1644670188264774

Epoch: 6| Step: 12
Training loss: 0.16936334258428878
Validation loss: 2.1763984380832344

Epoch: 6| Step: 13
Training loss: 0.14901229346767975
Validation loss: 2.202007248993579

Epoch: 514| Step: 0
Training loss: 0.12990724720961003
Validation loss: 2.22657951862284

Epoch: 6| Step: 1
Training loss: 0.14304321673979678
Validation loss: 2.2637802245744476

Epoch: 6| Step: 2
Training loss: 0.16214206090274585
Validation loss: 2.272954997495953

Epoch: 6| Step: 3
Training loss: 0.10083445615708124
Validation loss: 2.296218953612908

Epoch: 6| Step: 4
Training loss: 0.14860350962857755
Validation loss: 2.284399312818362

Epoch: 6| Step: 5
Training loss: 0.18471593007048948
Validation loss: 2.320147660441971

Epoch: 6| Step: 6
Training loss: 0.19725865644478155
Validation loss: 2.303434145368687

Epoch: 6| Step: 7
Training loss: 0.151996130361521
Validation loss: 2.289563413261608

Epoch: 6| Step: 8
Training loss: 0.14316526779354397
Validation loss: 2.242080807706602

Epoch: 6| Step: 9
Training loss: 0.25266477342806765
Validation loss: 2.2599824212592403

Epoch: 6| Step: 10
Training loss: 0.15817797425586191
Validation loss: 2.2293907074409565

Epoch: 6| Step: 11
Training loss: 0.21307825866625651
Validation loss: 2.2131996671379306

Epoch: 6| Step: 12
Training loss: 0.13580154932255598
Validation loss: 2.21240461897169

Epoch: 6| Step: 13
Training loss: 0.06351640991134165
Validation loss: 2.2192358461093167

Epoch: 515| Step: 0
Training loss: 0.09430341001841029
Validation loss: 2.2300343527332855

Epoch: 6| Step: 1
Training loss: 0.17658585672419308
Validation loss: 2.2333682467159535

Epoch: 6| Step: 2
Training loss: 0.14496610280206343
Validation loss: 2.227778929635069

Epoch: 6| Step: 3
Training loss: 0.19839098002100145
Validation loss: 2.236692475517422

Epoch: 6| Step: 4
Training loss: 0.13778801090613296
Validation loss: 2.281075830984841

Epoch: 6| Step: 5
Training loss: 0.12894127109946593
Validation loss: 2.2380327397704187

Epoch: 6| Step: 6
Training loss: 0.13646482319966138
Validation loss: 2.2449371861362897

Epoch: 6| Step: 7
Training loss: 0.14646137692796643
Validation loss: 2.241536586236883

Epoch: 6| Step: 8
Training loss: 0.13969677308684758
Validation loss: 2.218956595841322

Epoch: 6| Step: 9
Training loss: 0.1309128979214926
Validation loss: 2.2442560677351584

Epoch: 6| Step: 10
Training loss: 0.10251866092265219
Validation loss: 2.1734032520449666

Epoch: 6| Step: 11
Training loss: 0.16297079350186036
Validation loss: 2.204724823256786

Epoch: 6| Step: 12
Training loss: 0.15480439099676405
Validation loss: 2.2028110675828847

Epoch: 6| Step: 13
Training loss: 0.17537695697636024
Validation loss: 2.1921260852707127

Epoch: 516| Step: 0
Training loss: 0.18092502613586642
Validation loss: 2.1984980984956035

Epoch: 6| Step: 1
Training loss: 0.13610853528755731
Validation loss: 2.2227399100847975

Epoch: 6| Step: 2
Training loss: 0.15126884711488267
Validation loss: 2.240813693785664

Epoch: 6| Step: 3
Training loss: 0.10779282072388524
Validation loss: 2.2446442671707527

Epoch: 6| Step: 4
Training loss: 0.12619723723519002
Validation loss: 2.2279258378179283

Epoch: 6| Step: 5
Training loss: 0.20590681944452982
Validation loss: 2.22553859182063

Epoch: 6| Step: 6
Training loss: 0.12884879276687447
Validation loss: 2.210986313208021

Epoch: 6| Step: 7
Training loss: 0.09868375010550322
Validation loss: 2.225864284662284

Epoch: 6| Step: 8
Training loss: 0.11560679321381077
Validation loss: 2.2083432465708266

Epoch: 6| Step: 9
Training loss: 0.07635845356337069
Validation loss: 2.2351796905353636

Epoch: 6| Step: 10
Training loss: 0.19779285942067834
Validation loss: 2.2108434777940276

Epoch: 6| Step: 11
Training loss: 0.09033390764916648
Validation loss: 2.2085415429908157

Epoch: 6| Step: 12
Training loss: 0.14652805948556796
Validation loss: 2.2294295884953224

Epoch: 6| Step: 13
Training loss: 0.14117379524474505
Validation loss: 2.2211723894261315

Epoch: 517| Step: 0
Training loss: 0.12912128315180185
Validation loss: 2.2265151693296508

Epoch: 6| Step: 1
Training loss: 0.11531021564309234
Validation loss: 2.266241956081074

Epoch: 6| Step: 2
Training loss: 0.1035203437809274
Validation loss: 2.250338135882788

Epoch: 6| Step: 3
Training loss: 0.1352357542341167
Validation loss: 2.225192935077638

Epoch: 6| Step: 4
Training loss: 0.11727796877167272
Validation loss: 2.201494040133977

Epoch: 6| Step: 5
Training loss: 0.11863826935106392
Validation loss: 2.21750337293647

Epoch: 6| Step: 6
Training loss: 0.19668258770922925
Validation loss: 2.219047674315058

Epoch: 6| Step: 7
Training loss: 0.1798396192253579
Validation loss: 2.2267682219196128

Epoch: 6| Step: 8
Training loss: 0.14056138745627098
Validation loss: 2.210328316801509

Epoch: 6| Step: 9
Training loss: 0.175917233744776
Validation loss: 2.202303067854695

Epoch: 6| Step: 10
Training loss: 0.18910593487578753
Validation loss: 2.17755093159888

Epoch: 6| Step: 11
Training loss: 0.09251668939781878
Validation loss: 2.196687388912973

Epoch: 6| Step: 12
Training loss: 0.11487598372303869
Validation loss: 2.1663319595009134

Epoch: 6| Step: 13
Training loss: 0.1084062384470419
Validation loss: 2.1515786181280534

Epoch: 518| Step: 0
Training loss: 0.11216791780986422
Validation loss: 2.161467773638284

Epoch: 6| Step: 1
Training loss: 0.13500633028429856
Validation loss: 2.172355144925098

Epoch: 6| Step: 2
Training loss: 0.12169304341208119
Validation loss: 2.1899209836938898

Epoch: 6| Step: 3
Training loss: 0.11160943812326192
Validation loss: 2.198104580539247

Epoch: 6| Step: 4
Training loss: 0.09621150392589413
Validation loss: 2.209757412065174

Epoch: 6| Step: 5
Training loss: 0.08264911792106157
Validation loss: 2.2166846872831303

Epoch: 6| Step: 6
Training loss: 0.16953319183679003
Validation loss: 2.205313031309092

Epoch: 6| Step: 7
Training loss: 0.1508277633553586
Validation loss: 2.20369191447748

Epoch: 6| Step: 8
Training loss: 0.12164027186436192
Validation loss: 2.2035786779715645

Epoch: 6| Step: 9
Training loss: 0.16066028204694116
Validation loss: 2.1810671254997556

Epoch: 6| Step: 10
Training loss: 0.1657842032900262
Validation loss: 2.2051052891597744

Epoch: 6| Step: 11
Training loss: 0.14154506740222286
Validation loss: 2.171035042316142

Epoch: 6| Step: 12
Training loss: 0.05772710071351023
Validation loss: 2.210587477333925

Epoch: 6| Step: 13
Training loss: 0.10550241462884401
Validation loss: 2.187443207737492

Epoch: 519| Step: 0
Training loss: 0.12378298360838015
Validation loss: 2.1691385368251033

Epoch: 6| Step: 1
Training loss: 0.08995293119899009
Validation loss: 2.1761238439794623

Epoch: 6| Step: 2
Training loss: 0.11660136425697944
Validation loss: 2.1803156020926475

Epoch: 6| Step: 3
Training loss: 0.17508532198233956
Validation loss: 2.2098693313902955

Epoch: 6| Step: 4
Training loss: 0.08505382885818809
Validation loss: 2.205033207197028

Epoch: 6| Step: 5
Training loss: 0.1678082453332215
Validation loss: 2.1740800858405147

Epoch: 6| Step: 6
Training loss: 0.08735688321918546
Validation loss: 2.174175376566024

Epoch: 6| Step: 7
Training loss: 0.10892503004548659
Validation loss: 2.1654806803679203

Epoch: 6| Step: 8
Training loss: 0.13620935638796589
Validation loss: 2.1646160352040575

Epoch: 6| Step: 9
Training loss: 0.09427280979385355
Validation loss: 2.195532467081986

Epoch: 6| Step: 10
Training loss: 0.07637570997035378
Validation loss: 2.1810098389572805

Epoch: 6| Step: 11
Training loss: 0.2146319645955263
Validation loss: 2.195831934540507

Epoch: 6| Step: 12
Training loss: 0.09811531884732828
Validation loss: 2.206909845417752

Epoch: 6| Step: 13
Training loss: 0.053293773400810554
Validation loss: 2.2015181498177236

Epoch: 520| Step: 0
Training loss: 0.08103811715123609
Validation loss: 2.2061320298226383

Epoch: 6| Step: 1
Training loss: 0.10408547833633533
Validation loss: 2.2160987398329626

Epoch: 6| Step: 2
Training loss: 0.18190738614121882
Validation loss: 2.2173963846210136

Epoch: 6| Step: 3
Training loss: 0.15095535366228308
Validation loss: 2.201886141983463

Epoch: 6| Step: 4
Training loss: 0.13157468270461617
Validation loss: 2.2178684062079133

Epoch: 6| Step: 5
Training loss: 0.13433968224038365
Validation loss: 2.210245106717563

Epoch: 6| Step: 6
Training loss: 0.08919326464161635
Validation loss: 2.192809180179418

Epoch: 6| Step: 7
Training loss: 0.11745673880955688
Validation loss: 2.1832473463680135

Epoch: 6| Step: 8
Training loss: 0.06706324415114005
Validation loss: 2.213638398133746

Epoch: 6| Step: 9
Training loss: 0.18173846819261777
Validation loss: 2.183191339001861

Epoch: 6| Step: 10
Training loss: 0.07029711700753065
Validation loss: 2.190607776199353

Epoch: 6| Step: 11
Training loss: 0.11017014774282652
Validation loss: 2.1796601425667

Epoch: 6| Step: 12
Training loss: 0.10936008079138634
Validation loss: 2.1633608077187882

Epoch: 6| Step: 13
Training loss: 0.10514161361618445
Validation loss: 2.167579389612464

Epoch: 521| Step: 0
Training loss: 0.17450763460662488
Validation loss: 2.1672189113649845

Epoch: 6| Step: 1
Training loss: 0.08868106802789223
Validation loss: 2.1715895694723204

Epoch: 6| Step: 2
Training loss: 0.11798824676553582
Validation loss: 2.1455647902563473

Epoch: 6| Step: 3
Training loss: 0.12999099872219094
Validation loss: 2.146798945730076

Epoch: 6| Step: 4
Training loss: 0.16754809090428283
Validation loss: 2.125899429154657

Epoch: 6| Step: 5
Training loss: 0.11690123083918372
Validation loss: 2.1329828190041553

Epoch: 6| Step: 6
Training loss: 0.13338733839159836
Validation loss: 2.148327633909602

Epoch: 6| Step: 7
Training loss: 0.1083571553020127
Validation loss: 2.163085610391004

Epoch: 6| Step: 8
Training loss: 0.15290260513611162
Validation loss: 2.1818716910036686

Epoch: 6| Step: 9
Training loss: 0.14905596186936212
Validation loss: 2.217149498378615

Epoch: 6| Step: 10
Training loss: 0.0699922167865987
Validation loss: 2.188251946237005

Epoch: 6| Step: 11
Training loss: 0.10449138088449761
Validation loss: 2.2007362671419775

Epoch: 6| Step: 12
Training loss: 0.07767482937792378
Validation loss: 2.1819341358201623

Epoch: 6| Step: 13
Training loss: 0.11517728991827916
Validation loss: 2.1665774345560345

Epoch: 522| Step: 0
Training loss: 0.1249521991110611
Validation loss: 2.1825794681493167

Epoch: 6| Step: 1
Training loss: 0.12856107795014163
Validation loss: 2.1928078964935107

Epoch: 6| Step: 2
Training loss: 0.11856813543049935
Validation loss: 2.200053892030219

Epoch: 6| Step: 3
Training loss: 0.15841108946595545
Validation loss: 2.1817501389962795

Epoch: 6| Step: 4
Training loss: 0.11665772454514992
Validation loss: 2.2034339132575043

Epoch: 6| Step: 5
Training loss: 0.1483855407525085
Validation loss: 2.2055434921395687

Epoch: 6| Step: 6
Training loss: 0.1157535922070321
Validation loss: 2.238042312024111

Epoch: 6| Step: 7
Training loss: 0.1056223166353453
Validation loss: 2.2185740270393044

Epoch: 6| Step: 8
Training loss: 0.18364322279857784
Validation loss: 2.250814948849977

Epoch: 6| Step: 9
Training loss: 0.14258310230921242
Validation loss: 2.250046996169321

Epoch: 6| Step: 10
Training loss: 0.10814671026965712
Validation loss: 2.23049500957114

Epoch: 6| Step: 11
Training loss: 0.14782271311600798
Validation loss: 2.2281921904935174

Epoch: 6| Step: 12
Training loss: 0.10900025371699158
Validation loss: 2.2135056270630864

Epoch: 6| Step: 13
Training loss: 0.10493782419310266
Validation loss: 2.226616323353403

Epoch: 523| Step: 0
Training loss: 0.1312832869598935
Validation loss: 2.2013810457627945

Epoch: 6| Step: 1
Training loss: 0.08329879583964435
Validation loss: 2.195069560423344

Epoch: 6| Step: 2
Training loss: 0.15961059216013293
Validation loss: 2.2219117171572957

Epoch: 6| Step: 3
Training loss: 0.08890688711585056
Validation loss: 2.176250432877496

Epoch: 6| Step: 4
Training loss: 0.15541255165239762
Validation loss: 2.17650586658721

Epoch: 6| Step: 5
Training loss: 0.08439145016138795
Validation loss: 2.1981066530463074

Epoch: 6| Step: 6
Training loss: 0.16554141477119522
Validation loss: 2.201216543748761

Epoch: 6| Step: 7
Training loss: 0.15275324902419316
Validation loss: 2.1963164042308705

Epoch: 6| Step: 8
Training loss: 0.1725711109865294
Validation loss: 2.1831461082741903

Epoch: 6| Step: 9
Training loss: 0.1583704593281517
Validation loss: 2.196565952997034

Epoch: 6| Step: 10
Training loss: 0.0860742651115
Validation loss: 2.2108741228513713

Epoch: 6| Step: 11
Training loss: 0.08493350397254457
Validation loss: 2.202323844124275

Epoch: 6| Step: 12
Training loss: 0.1743305798920429
Validation loss: 2.2033146293913846

Epoch: 6| Step: 13
Training loss: 0.1651629710747143
Validation loss: 2.2028678837681794

Epoch: 524| Step: 0
Training loss: 0.18700133013443462
Validation loss: 2.2337707280695804

Epoch: 6| Step: 1
Training loss: 0.14794875292814844
Validation loss: 2.241028993961111

Epoch: 6| Step: 2
Training loss: 0.09743618010458295
Validation loss: 2.2150498137880392

Epoch: 6| Step: 3
Training loss: 0.0985995557635385
Validation loss: 2.2490729310044846

Epoch: 6| Step: 4
Training loss: 0.11544358933027507
Validation loss: 2.2172716326334942

Epoch: 6| Step: 5
Training loss: 0.10901632421749617
Validation loss: 2.2196792720141225

Epoch: 6| Step: 6
Training loss: 0.12403524147390933
Validation loss: 2.1877859072323442

Epoch: 6| Step: 7
Training loss: 0.06545997744078282
Validation loss: 2.2025638244669974

Epoch: 6| Step: 8
Training loss: 0.15795476279889328
Validation loss: 2.2062495790225705

Epoch: 6| Step: 9
Training loss: 0.10670731174613528
Validation loss: 2.1824508570946817

Epoch: 6| Step: 10
Training loss: 0.08192305582364344
Validation loss: 2.171610005937733

Epoch: 6| Step: 11
Training loss: 0.1611642228925087
Validation loss: 2.184771219562404

Epoch: 6| Step: 12
Training loss: 0.09606331560400441
Validation loss: 2.1728815210647645

Epoch: 6| Step: 13
Training loss: 0.1090081696530095
Validation loss: 2.197040440550038

Epoch: 525| Step: 0
Training loss: 0.14048061641094212
Validation loss: 2.1736532600778267

Epoch: 6| Step: 1
Training loss: 0.09165957511036463
Validation loss: 2.1720776761770297

Epoch: 6| Step: 2
Training loss: 0.10324864777563925
Validation loss: 2.1863597165604713

Epoch: 6| Step: 3
Training loss: 0.10644424070466131
Validation loss: 2.168081969830407

Epoch: 6| Step: 4
Training loss: 0.08965052683271761
Validation loss: 2.1556738984019765

Epoch: 6| Step: 5
Training loss: 0.1128010107038666
Validation loss: 2.131574112923056

Epoch: 6| Step: 6
Training loss: 0.16503328956574562
Validation loss: 2.1681434260177803

Epoch: 6| Step: 7
Training loss: 0.07773010467416429
Validation loss: 2.1844858196517087

Epoch: 6| Step: 8
Training loss: 0.10037718100274473
Validation loss: 2.1492806280217773

Epoch: 6| Step: 9
Training loss: 0.1932285714118885
Validation loss: 2.1405736966321793

Epoch: 6| Step: 10
Training loss: 0.12283617099113087
Validation loss: 2.1873967317737417

Epoch: 6| Step: 11
Training loss: 0.11318230006981957
Validation loss: 2.181592175776038

Epoch: 6| Step: 12
Training loss: 0.1377065938021182
Validation loss: 2.190600292198772

Epoch: 6| Step: 13
Training loss: 0.2005601860832999
Validation loss: 2.202927801027718

Epoch: 526| Step: 0
Training loss: 0.10096090294957576
Validation loss: 2.1894939154219872

Epoch: 6| Step: 1
Training loss: 0.09734641515411287
Validation loss: 2.202659958143995

Epoch: 6| Step: 2
Training loss: 0.09713585001650255
Validation loss: 2.1858993938483238

Epoch: 6| Step: 3
Training loss: 0.05557169486825199
Validation loss: 2.182681407443877

Epoch: 6| Step: 4
Training loss: 0.09623131674409749
Validation loss: 2.2082048329606745

Epoch: 6| Step: 5
Training loss: 0.10997392804669845
Validation loss: 2.193126276681151

Epoch: 6| Step: 6
Training loss: 0.09210752113230324
Validation loss: 2.169789971066457

Epoch: 6| Step: 7
Training loss: 0.13880914287853033
Validation loss: 2.152029042719179

Epoch: 6| Step: 8
Training loss: 0.10313859690992647
Validation loss: 2.153859978226872

Epoch: 6| Step: 9
Training loss: 0.08302062440620149
Validation loss: 2.1643884346062032

Epoch: 6| Step: 10
Training loss: 0.09631513973680828
Validation loss: 2.133199526315129

Epoch: 6| Step: 11
Training loss: 0.16598005474723312
Validation loss: 2.1696569333561486

Epoch: 6| Step: 12
Training loss: 0.14542008642103194
Validation loss: 2.1582639111862103

Epoch: 6| Step: 13
Training loss: 0.202948603698427
Validation loss: 2.16061162355434

Epoch: 527| Step: 0
Training loss: 0.06882352947325353
Validation loss: 2.1615646824406927

Epoch: 6| Step: 1
Training loss: 0.08207132575341491
Validation loss: 2.1627641615975612

Epoch: 6| Step: 2
Training loss: 0.12555382645832586
Validation loss: 2.1623181701178935

Epoch: 6| Step: 3
Training loss: 0.11510835642834542
Validation loss: 2.182388874621892

Epoch: 6| Step: 4
Training loss: 0.16602299056823897
Validation loss: 2.1662786477877423

Epoch: 6| Step: 5
Training loss: 0.0861569198944523
Validation loss: 2.173316953178843

Epoch: 6| Step: 6
Training loss: 0.09983345613710215
Validation loss: 2.1787433817934168

Epoch: 6| Step: 7
Training loss: 0.1207710203240672
Validation loss: 2.192187464109762

Epoch: 6| Step: 8
Training loss: 0.12627272576040227
Validation loss: 2.1726282683937534

Epoch: 6| Step: 9
Training loss: 0.10510532583691357
Validation loss: 2.208039257400035

Epoch: 6| Step: 10
Training loss: 0.1589435159352475
Validation loss: 2.1776789373383365

Epoch: 6| Step: 11
Training loss: 0.0953534804248571
Validation loss: 2.1761614125187685

Epoch: 6| Step: 12
Training loss: 0.1675208129335652
Validation loss: 2.1979278545117253

Epoch: 6| Step: 13
Training loss: 0.11558866187594898
Validation loss: 2.1770742335430846

Epoch: 528| Step: 0
Training loss: 0.11225884372615307
Validation loss: 2.170076938677396

Epoch: 6| Step: 1
Training loss: 0.061510101644124904
Validation loss: 2.1390117718858117

Epoch: 6| Step: 2
Training loss: 0.16468425284266255
Validation loss: 2.1688380006362142

Epoch: 6| Step: 3
Training loss: 0.08877085085686402
Validation loss: 2.1677908248931885

Epoch: 6| Step: 4
Training loss: 0.07836600027001724
Validation loss: 2.192772253449999

Epoch: 6| Step: 5
Training loss: 0.08093078749301587
Validation loss: 2.1816440175040976

Epoch: 6| Step: 6
Training loss: 0.1635182185179233
Validation loss: 2.173687425121382

Epoch: 6| Step: 7
Training loss: 0.12463561980484274
Validation loss: 2.149487349327849

Epoch: 6| Step: 8
Training loss: 0.0762173840706141
Validation loss: 2.1516001034396943

Epoch: 6| Step: 9
Training loss: 0.06819589002978492
Validation loss: 2.158454134670079

Epoch: 6| Step: 10
Training loss: 0.08747296703356494
Validation loss: 2.1917360534439467

Epoch: 6| Step: 11
Training loss: 0.15380613536989332
Validation loss: 2.1902071876512075

Epoch: 6| Step: 12
Training loss: 0.13692175915643637
Validation loss: 2.1620935682056563

Epoch: 6| Step: 13
Training loss: 0.08173419607201596
Validation loss: 2.140646748244806

Epoch: 529| Step: 0
Training loss: 0.08298815326137643
Validation loss: 2.155199470010725

Epoch: 6| Step: 1
Training loss: 0.13178332656570305
Validation loss: 2.1411583031563763

Epoch: 6| Step: 2
Training loss: 0.12693803404099835
Validation loss: 2.1524712151652023

Epoch: 6| Step: 3
Training loss: 0.12553695743986332
Validation loss: 2.1395605974075456

Epoch: 6| Step: 4
Training loss: 0.10166136807792207
Validation loss: 2.1390014688149783

Epoch: 6| Step: 5
Training loss: 0.14527890422040715
Validation loss: 2.123036629091849

Epoch: 6| Step: 6
Training loss: 0.0857061175551553
Validation loss: 2.140297630169205

Epoch: 6| Step: 7
Training loss: 0.06921199345281032
Validation loss: 2.1597612697046618

Epoch: 6| Step: 8
Training loss: 0.11456387437692167
Validation loss: 2.1454821688644206

Epoch: 6| Step: 9
Training loss: 0.05978731590789377
Validation loss: 2.1844965401606404

Epoch: 6| Step: 10
Training loss: 0.0892655279551973
Validation loss: 2.1758103069281995

Epoch: 6| Step: 11
Training loss: 0.11446578505870746
Validation loss: 2.151968611291185

Epoch: 6| Step: 12
Training loss: 0.0949245527070302
Validation loss: 2.188625530150284

Epoch: 6| Step: 13
Training loss: 0.20367406034010538
Validation loss: 2.1888628627030133

Epoch: 530| Step: 0
Training loss: 0.0827292818171365
Validation loss: 2.1603886965956978

Epoch: 6| Step: 1
Training loss: 0.08185499704507669
Validation loss: 2.1633304400076834

Epoch: 6| Step: 2
Training loss: 0.10000366822607748
Validation loss: 2.1679701465416317

Epoch: 6| Step: 3
Training loss: 0.1704405344908716
Validation loss: 2.1783787066296103

Epoch: 6| Step: 4
Training loss: 0.1620781420298845
Validation loss: 2.2091853531070806

Epoch: 6| Step: 5
Training loss: 0.0831999938223437
Validation loss: 2.1796231471492473

Epoch: 6| Step: 6
Training loss: 0.13077732616950746
Validation loss: 2.205954536054809

Epoch: 6| Step: 7
Training loss: 0.11054294161319551
Validation loss: 2.1905930831920193

Epoch: 6| Step: 8
Training loss: 0.10654825954429947
Validation loss: 2.171220088273355

Epoch: 6| Step: 9
Training loss: 0.08745328920869336
Validation loss: 2.2081433266895756

Epoch: 6| Step: 10
Training loss: 0.10232869776479409
Validation loss: 2.200080656202674

Epoch: 6| Step: 11
Training loss: 0.16847197977719322
Validation loss: 2.1779409520924635

Epoch: 6| Step: 12
Training loss: 0.09813086096608324
Validation loss: 2.1619409960484877

Epoch: 6| Step: 13
Training loss: 0.08293719934626044
Validation loss: 2.142510004755748

Epoch: 531| Step: 0
Training loss: 0.15904643911693028
Validation loss: 2.2030219143619623

Epoch: 6| Step: 1
Training loss: 0.07879096144741035
Validation loss: 2.2028004641378636

Epoch: 6| Step: 2
Training loss: 0.10588783430587778
Validation loss: 2.1760365820942

Epoch: 6| Step: 3
Training loss: 0.11156126756949046
Validation loss: 2.196272626248743

Epoch: 6| Step: 4
Training loss: 0.10574864406201122
Validation loss: 2.1965148929613663

Epoch: 6| Step: 5
Training loss: 0.12142400928349974
Validation loss: 2.191841651225397

Epoch: 6| Step: 6
Training loss: 0.10172155653250446
Validation loss: 2.1990824719306867

Epoch: 6| Step: 7
Training loss: 0.10651980427112442
Validation loss: 2.171756033192813

Epoch: 6| Step: 8
Training loss: 0.059116113306123874
Validation loss: 2.191337801535669

Epoch: 6| Step: 9
Training loss: 0.08120993316326608
Validation loss: 2.2114662770953966

Epoch: 6| Step: 10
Training loss: 0.10608262208774834
Validation loss: 2.2049824461299727

Epoch: 6| Step: 11
Training loss: 0.12370008081918835
Validation loss: 2.1822157054190603

Epoch: 6| Step: 12
Training loss: 0.1847256304660322
Validation loss: 2.1903317283882933

Epoch: 6| Step: 13
Training loss: 0.0935494045127753
Validation loss: 2.1946475930258598

Epoch: 532| Step: 0
Training loss: 0.08673137849924122
Validation loss: 2.1901410574190616

Epoch: 6| Step: 1
Training loss: 0.1721167002836338
Validation loss: 2.1710893519180985

Epoch: 6| Step: 2
Training loss: 0.10395397635431942
Validation loss: 2.136749627895686

Epoch: 6| Step: 3
Training loss: 0.14824956365435876
Validation loss: 2.12789847319213

Epoch: 6| Step: 4
Training loss: 0.11636789125125338
Validation loss: 2.1593437886970177

Epoch: 6| Step: 5
Training loss: 0.12759935522415447
Validation loss: 2.1164981494896433

Epoch: 6| Step: 6
Training loss: 0.09417872943810154
Validation loss: 2.15100866310953

Epoch: 6| Step: 7
Training loss: 0.18828982654206164
Validation loss: 2.1545889515520265

Epoch: 6| Step: 8
Training loss: 0.15703220082464878
Validation loss: 2.173736184388623

Epoch: 6| Step: 9
Training loss: 0.1012501130574384
Validation loss: 2.1979361982653383

Epoch: 6| Step: 10
Training loss: 0.0811445157835157
Validation loss: 2.2001377619589455

Epoch: 6| Step: 11
Training loss: 0.1069260294080816
Validation loss: 2.214637120656325

Epoch: 6| Step: 12
Training loss: 0.11285098759368412
Validation loss: 2.22607838826607

Epoch: 6| Step: 13
Training loss: 0.19102513069262686
Validation loss: 2.2311626036326175

Epoch: 533| Step: 0
Training loss: 0.1439766165288043
Validation loss: 2.241176792325864

Epoch: 6| Step: 1
Training loss: 0.13476967459965938
Validation loss: 2.213055425196563

Epoch: 6| Step: 2
Training loss: 0.10175425510448471
Validation loss: 2.2364294518969565

Epoch: 6| Step: 3
Training loss: 0.18215014663669968
Validation loss: 2.179498087427142

Epoch: 6| Step: 4
Training loss: 0.10763795967196604
Validation loss: 2.191249535670551

Epoch: 6| Step: 5
Training loss: 0.10561486119360033
Validation loss: 2.172421493231413

Epoch: 6| Step: 6
Training loss: 0.16073888541221662
Validation loss: 2.17840928469527

Epoch: 6| Step: 7
Training loss: 0.12035985794871794
Validation loss: 2.164550529570219

Epoch: 6| Step: 8
Training loss: 0.20145364120927348
Validation loss: 2.169503890746207

Epoch: 6| Step: 9
Training loss: 0.2011314369965129
Validation loss: 2.13124680350912

Epoch: 6| Step: 10
Training loss: 0.09158230621856328
Validation loss: 2.1415770835362737

Epoch: 6| Step: 11
Training loss: 0.08841498044413772
Validation loss: 2.1448273881930926

Epoch: 6| Step: 12
Training loss: 0.16384372429535565
Validation loss: 2.193824206941425

Epoch: 6| Step: 13
Training loss: 0.12126171092374458
Validation loss: 2.206595492979038

Epoch: 534| Step: 0
Training loss: 0.14002027558490582
Validation loss: 2.2128109104418474

Epoch: 6| Step: 1
Training loss: 0.16064588204137695
Validation loss: 2.217532413519209

Epoch: 6| Step: 2
Training loss: 0.10992291421541354
Validation loss: 2.190214060239545

Epoch: 6| Step: 3
Training loss: 0.150298796522788
Validation loss: 2.1893358229812754

Epoch: 6| Step: 4
Training loss: 0.10202202095072477
Validation loss: 2.2490820692876135

Epoch: 6| Step: 5
Training loss: 0.14516753533700533
Validation loss: 2.1960584114614967

Epoch: 6| Step: 6
Training loss: 0.09915694166363621
Validation loss: 2.1583974950903713

Epoch: 6| Step: 7
Training loss: 0.10945647474849736
Validation loss: 2.173926446286172

Epoch: 6| Step: 8
Training loss: 0.2232590930107876
Validation loss: 2.1606306273069396

Epoch: 6| Step: 9
Training loss: 0.11927531008738058
Validation loss: 2.1699632493563725

Epoch: 6| Step: 10
Training loss: 0.14831093989354277
Validation loss: 2.173866173092691

Epoch: 6| Step: 11
Training loss: 0.17605866687747157
Validation loss: 2.179217293689112

Epoch: 6| Step: 12
Training loss: 0.15171794244883288
Validation loss: 2.184003783643398

Epoch: 6| Step: 13
Training loss: 0.1598734452192151
Validation loss: 2.2014315707895435

Epoch: 535| Step: 0
Training loss: 0.16612532861833526
Validation loss: 2.225028180096819

Epoch: 6| Step: 1
Training loss: 0.12773418776472176
Validation loss: 2.2122793398245393

Epoch: 6| Step: 2
Training loss: 0.1761856090664755
Validation loss: 2.216126482660384

Epoch: 6| Step: 3
Training loss: 0.1826940364601411
Validation loss: 2.2506935903247562

Epoch: 6| Step: 4
Training loss: 0.17931216887360052
Validation loss: 2.2397135722206247

Epoch: 6| Step: 5
Training loss: 0.24744326822717144
Validation loss: 2.2377793027125477

Epoch: 6| Step: 6
Training loss: 0.15123903941211184
Validation loss: 2.2491529367407446

Epoch: 6| Step: 7
Training loss: 0.1949311825626622
Validation loss: 2.2133366657180225

Epoch: 6| Step: 8
Training loss: 0.10156384338810914
Validation loss: 2.197791237443468

Epoch: 6| Step: 9
Training loss: 0.10153156964946528
Validation loss: 2.190840371341048

Epoch: 6| Step: 10
Training loss: 0.1647697599063098
Validation loss: 2.1685715165278383

Epoch: 6| Step: 11
Training loss: 0.13137091817104268
Validation loss: 2.164806906812933

Epoch: 6| Step: 12
Training loss: 0.1192697973879617
Validation loss: 2.174370383939172

Epoch: 6| Step: 13
Training loss: 0.09995428377719852
Validation loss: 2.1200427298497186

Epoch: 536| Step: 0
Training loss: 0.18370746580879302
Validation loss: 2.1422959505134944

Epoch: 6| Step: 1
Training loss: 0.10739261055182973
Validation loss: 2.1447668913092244

Epoch: 6| Step: 2
Training loss: 0.10559494363308278
Validation loss: 2.1486236736218842

Epoch: 6| Step: 3
Training loss: 0.09242840402037847
Validation loss: 2.1578985507593393

Epoch: 6| Step: 4
Training loss: 0.16384146764738247
Validation loss: 2.16883153608168

Epoch: 6| Step: 5
Training loss: 0.15468365442909696
Validation loss: 2.1629855429381104

Epoch: 6| Step: 6
Training loss: 0.17402645647917442
Validation loss: 2.1458642310038556

Epoch: 6| Step: 7
Training loss: 0.17958528265002052
Validation loss: 2.1457907396392746

Epoch: 6| Step: 8
Training loss: 0.12298020570027315
Validation loss: 2.18350488872023

Epoch: 6| Step: 9
Training loss: 0.07708620627737117
Validation loss: 2.1853102475160915

Epoch: 6| Step: 10
Training loss: 0.12726177695670046
Validation loss: 2.2193029281752463

Epoch: 6| Step: 11
Training loss: 0.1086452269499118
Validation loss: 2.219953234703887

Epoch: 6| Step: 12
Training loss: 0.17681862643790636
Validation loss: 2.214877182442921

Epoch: 6| Step: 13
Training loss: 0.08763410167301869
Validation loss: 2.2215670378192827

Epoch: 537| Step: 0
Training loss: 0.11277314214135906
Validation loss: 2.2163238710300193

Epoch: 6| Step: 1
Training loss: 0.14146801142481863
Validation loss: 2.245845936448322

Epoch: 6| Step: 2
Training loss: 0.14625325089289454
Validation loss: 2.236565218982094

Epoch: 6| Step: 3
Training loss: 0.09848534541474309
Validation loss: 2.2091254204725397

Epoch: 6| Step: 4
Training loss: 0.15759520820610215
Validation loss: 2.20300859818555

Epoch: 6| Step: 5
Training loss: 0.06774412601399851
Validation loss: 2.186438999023024

Epoch: 6| Step: 6
Training loss: 0.16252840990446688
Validation loss: 2.154817322497529

Epoch: 6| Step: 7
Training loss: 0.09983530787923088
Validation loss: 2.148535564492761

Epoch: 6| Step: 8
Training loss: 0.06942910664112507
Validation loss: 2.162720930128427

Epoch: 6| Step: 9
Training loss: 0.11361280377900664
Validation loss: 2.165564723807327

Epoch: 6| Step: 10
Training loss: 0.10160827522146072
Validation loss: 2.153615501636505

Epoch: 6| Step: 11
Training loss: 0.1241381145065001
Validation loss: 2.139011074948426

Epoch: 6| Step: 12
Training loss: 0.12263025795044553
Validation loss: 2.170311566401982

Epoch: 6| Step: 13
Training loss: 0.12428914165955886
Validation loss: 2.1659772709321197

Epoch: 538| Step: 0
Training loss: 0.14093063836829262
Validation loss: 2.138619434528325

Epoch: 6| Step: 1
Training loss: 0.12759072044787748
Validation loss: 2.1658426031842537

Epoch: 6| Step: 2
Training loss: 0.14725167539789782
Validation loss: 2.1980579293694835

Epoch: 6| Step: 3
Training loss: 0.14556576387669798
Validation loss: 2.186709968014572

Epoch: 6| Step: 4
Training loss: 0.11903068676272228
Validation loss: 2.2184196363716184

Epoch: 6| Step: 5
Training loss: 0.0991249929328281
Validation loss: 2.1874347331305724

Epoch: 6| Step: 6
Training loss: 0.07075953433092108
Validation loss: 2.1871253183481842

Epoch: 6| Step: 7
Training loss: 0.11122124544105746
Validation loss: 2.194841773724341

Epoch: 6| Step: 8
Training loss: 0.08864432990980424
Validation loss: 2.1674550691100993

Epoch: 6| Step: 9
Training loss: 0.16053639050518895
Validation loss: 2.1678125403718442

Epoch: 6| Step: 10
Training loss: 0.17934097171631547
Validation loss: 2.194694949217446

Epoch: 6| Step: 11
Training loss: 0.1646640964722855
Validation loss: 2.171174188395134

Epoch: 6| Step: 12
Training loss: 0.08621087267432047
Validation loss: 2.1822575656478995

Epoch: 6| Step: 13
Training loss: 0.07228599403038095
Validation loss: 2.20071839748281

Epoch: 539| Step: 0
Training loss: 0.1577869167930875
Validation loss: 2.193417894660994

Epoch: 6| Step: 1
Training loss: 0.06690278315637872
Validation loss: 2.189202395389526

Epoch: 6| Step: 2
Training loss: 0.16084166724370527
Validation loss: 2.195315693874238

Epoch: 6| Step: 3
Training loss: 0.09245921175643161
Validation loss: 2.201733310997394

Epoch: 6| Step: 4
Training loss: 0.07351539518541339
Validation loss: 2.2015675875846314

Epoch: 6| Step: 5
Training loss: 0.08808577911802547
Validation loss: 2.217431090786547

Epoch: 6| Step: 6
Training loss: 0.10809817698766164
Validation loss: 2.2345993975706944

Epoch: 6| Step: 7
Training loss: 0.14985561574469256
Validation loss: 2.217831420472801

Epoch: 6| Step: 8
Training loss: 0.09809067895079565
Validation loss: 2.1960963253901027

Epoch: 6| Step: 9
Training loss: 0.1090956893675851
Validation loss: 2.178620758582678

Epoch: 6| Step: 10
Training loss: 0.10903219161907614
Validation loss: 2.183301277773871

Epoch: 6| Step: 11
Training loss: 0.0819705784179623
Validation loss: 2.1859781154190134

Epoch: 6| Step: 12
Training loss: 0.10029817361521357
Validation loss: 2.1983528102994727

Epoch: 6| Step: 13
Training loss: 0.10435740521744206
Validation loss: 2.1700387585800636

Epoch: 540| Step: 0
Training loss: 0.0891921682643086
Validation loss: 2.171058198425454

Epoch: 6| Step: 1
Training loss: 0.1440976637108358
Validation loss: 2.1820967079067937

Epoch: 6| Step: 2
Training loss: 0.08016875999456867
Validation loss: 2.1608957906035307

Epoch: 6| Step: 3
Training loss: 0.09230478774269915
Validation loss: 2.189580157433493

Epoch: 6| Step: 4
Training loss: 0.06537185076983866
Validation loss: 2.193964249057089

Epoch: 6| Step: 5
Training loss: 0.20047226334107404
Validation loss: 2.1747868817859772

Epoch: 6| Step: 6
Training loss: 0.13294009082495242
Validation loss: 2.1829961889193856

Epoch: 6| Step: 7
Training loss: 0.08877805809471796
Validation loss: 2.215648901720347

Epoch: 6| Step: 8
Training loss: 0.09288141592366583
Validation loss: 2.236725952741555

Epoch: 6| Step: 9
Training loss: 0.11838256715728848
Validation loss: 2.230849963309248

Epoch: 6| Step: 10
Training loss: 0.10717787340715641
Validation loss: 2.218703084447063

Epoch: 6| Step: 11
Training loss: 0.07936376806167024
Validation loss: 2.211255596692701

Epoch: 6| Step: 12
Training loss: 0.09720376567785802
Validation loss: 2.196629336821375

Epoch: 6| Step: 13
Training loss: 0.07513923535695075
Validation loss: 2.1852533983443956

Epoch: 541| Step: 0
Training loss: 0.04802107467163189
Validation loss: 2.181251511962735

Epoch: 6| Step: 1
Training loss: 0.17213763414956243
Validation loss: 2.1733250463866125

Epoch: 6| Step: 2
Training loss: 0.09443375963198462
Validation loss: 2.1374417738728

Epoch: 6| Step: 3
Training loss: 0.10457012799217867
Validation loss: 2.159989300605541

Epoch: 6| Step: 4
Training loss: 0.06930380063031857
Validation loss: 2.142218639464918

Epoch: 6| Step: 5
Training loss: 0.10621616652293792
Validation loss: 2.1157119144205545

Epoch: 6| Step: 6
Training loss: 0.10894937380486677
Validation loss: 2.1311443298451014

Epoch: 6| Step: 7
Training loss: 0.08877116034998922
Validation loss: 2.1223877540815597

Epoch: 6| Step: 8
Training loss: 0.11034048075439253
Validation loss: 2.1315038080324924

Epoch: 6| Step: 9
Training loss: 0.13481611190709386
Validation loss: 2.1431427231726348

Epoch: 6| Step: 10
Training loss: 0.09051452451307263
Validation loss: 2.147918599130649

Epoch: 6| Step: 11
Training loss: 0.09250979859738008
Validation loss: 2.1739631152973926

Epoch: 6| Step: 12
Training loss: 0.05183288689571981
Validation loss: 2.1689080348825507

Epoch: 6| Step: 13
Training loss: 0.18950715228651918
Validation loss: 2.1465253668817716

Epoch: 542| Step: 0
Training loss: 0.1474931252320071
Validation loss: 2.1666994774687103

Epoch: 6| Step: 1
Training loss: 0.12778557967241558
Validation loss: 2.211535689532981

Epoch: 6| Step: 2
Training loss: 0.06511975658042256
Validation loss: 2.168657970541551

Epoch: 6| Step: 3
Training loss: 0.16251517830167383
Validation loss: 2.218556333412017

Epoch: 6| Step: 4
Training loss: 0.08878498677248416
Validation loss: 2.2030778314164663

Epoch: 6| Step: 5
Training loss: 0.07698914827205727
Validation loss: 2.170894564694705

Epoch: 6| Step: 6
Training loss: 0.08972329897295145
Validation loss: 2.1789080356359136

Epoch: 6| Step: 7
Training loss: 0.10872597226164062
Validation loss: 2.194906384094738

Epoch: 6| Step: 8
Training loss: 0.08469613782531411
Validation loss: 2.219278226763865

Epoch: 6| Step: 9
Training loss: 0.10480700955571519
Validation loss: 2.18060203276548

Epoch: 6| Step: 10
Training loss: 0.08426306748395047
Validation loss: 2.1628459636843944

Epoch: 6| Step: 11
Training loss: 0.10189132461635253
Validation loss: 2.1777409296697248

Epoch: 6| Step: 12
Training loss: 0.12790701570614862
Validation loss: 2.1585692241121395

Epoch: 6| Step: 13
Training loss: 0.060383603470002434
Validation loss: 2.155918696297867

Epoch: 543| Step: 0
Training loss: 0.07306512410890474
Validation loss: 2.170144566901104

Epoch: 6| Step: 1
Training loss: 0.09446930116536192
Validation loss: 2.14225595293862

Epoch: 6| Step: 2
Training loss: 0.05439532089345102
Validation loss: 2.1672425015638597

Epoch: 6| Step: 3
Training loss: 0.1406337020088929
Validation loss: 2.158049447419826

Epoch: 6| Step: 4
Training loss: 0.17727512720832678
Validation loss: 2.166648253732571

Epoch: 6| Step: 5
Training loss: 0.06717254824388606
Validation loss: 2.183860000473391

Epoch: 6| Step: 6
Training loss: 0.13398276875814868
Validation loss: 2.185172568826252

Epoch: 6| Step: 7
Training loss: 0.07896604821519974
Validation loss: 2.192189838372304

Epoch: 6| Step: 8
Training loss: 0.06639411057982357
Validation loss: 2.2012021078996558

Epoch: 6| Step: 9
Training loss: 0.08352336661211181
Validation loss: 2.2088968351696354

Epoch: 6| Step: 10
Training loss: 0.07852485967769006
Validation loss: 2.184819093146334

Epoch: 6| Step: 11
Training loss: 0.12604357541296773
Validation loss: 2.188064894860003

Epoch: 6| Step: 12
Training loss: 0.1727999378418921
Validation loss: 2.19548621899155

Epoch: 6| Step: 13
Training loss: 0.11002115985566319
Validation loss: 2.196287779680753

Epoch: 544| Step: 0
Training loss: 0.07871564869944493
Validation loss: 2.1843102704347848

Epoch: 6| Step: 1
Training loss: 0.06263627157120073
Validation loss: 2.1830167825376265

Epoch: 6| Step: 2
Training loss: 0.08788936931984688
Validation loss: 2.1865143766065556

Epoch: 6| Step: 3
Training loss: 0.10835777413547791
Validation loss: 2.177308591162166

Epoch: 6| Step: 4
Training loss: 0.1321022381763842
Validation loss: 2.1771941991117414

Epoch: 6| Step: 5
Training loss: 0.1495681479300651
Validation loss: 2.1860209385471294

Epoch: 6| Step: 6
Training loss: 0.10095888274493717
Validation loss: 2.178562102687258

Epoch: 6| Step: 7
Training loss: 0.10361465179946297
Validation loss: 2.165294956854416

Epoch: 6| Step: 8
Training loss: 0.17073841777646728
Validation loss: 2.1380224344933687

Epoch: 6| Step: 9
Training loss: 0.12917282976808434
Validation loss: 2.16431048420514

Epoch: 6| Step: 10
Training loss: 0.09553900581793025
Validation loss: 2.1614932003438567

Epoch: 6| Step: 11
Training loss: 0.05455535010446625
Validation loss: 2.1632947153919275

Epoch: 6| Step: 12
Training loss: 0.13722490893333306
Validation loss: 2.1718547882369568

Epoch: 6| Step: 13
Training loss: 0.061656786576138906
Validation loss: 2.1868526766669105

Epoch: 545| Step: 0
Training loss: 0.1224566715963724
Validation loss: 2.1590251574096913

Epoch: 6| Step: 1
Training loss: 0.12451383551499944
Validation loss: 2.1573842213110277

Epoch: 6| Step: 2
Training loss: 0.08521122076851863
Validation loss: 2.1949662593960104

Epoch: 6| Step: 3
Training loss: 0.10503316044850458
Validation loss: 2.183142874284714

Epoch: 6| Step: 4
Training loss: 0.07690860494021441
Validation loss: 2.214421286840923

Epoch: 6| Step: 5
Training loss: 0.1654364018164208
Validation loss: 2.1702479785914157

Epoch: 6| Step: 6
Training loss: 0.10733357181353514
Validation loss: 2.164694471414807

Epoch: 6| Step: 7
Training loss: 0.12806112511540482
Validation loss: 2.155191327769813

Epoch: 6| Step: 8
Training loss: 0.15168285064974998
Validation loss: 2.192436913387967

Epoch: 6| Step: 9
Training loss: 0.10031267657814052
Validation loss: 2.1670206879536558

Epoch: 6| Step: 10
Training loss: 0.1504269593178906
Validation loss: 2.129490152999839

Epoch: 6| Step: 11
Training loss: 0.09477660735035685
Validation loss: 2.1508175360382094

Epoch: 6| Step: 12
Training loss: 0.15776859465852358
Validation loss: 2.1711690621095423

Epoch: 6| Step: 13
Training loss: 0.09987738028006642
Validation loss: 2.16649209384923

Epoch: 546| Step: 0
Training loss: 0.06265785726545309
Validation loss: 2.1840351204669606

Epoch: 6| Step: 1
Training loss: 0.14881167183188582
Validation loss: 2.2077720688840556

Epoch: 6| Step: 2
Training loss: 0.13817196719589186
Validation loss: 2.17239294739315

Epoch: 6| Step: 3
Training loss: 0.11813754580243274
Validation loss: 2.1810537384593602

Epoch: 6| Step: 4
Training loss: 0.13092298527388058
Validation loss: 2.209837575521224

Epoch: 6| Step: 5
Training loss: 0.07912691910843521
Validation loss: 2.2158771693924595

Epoch: 6| Step: 6
Training loss: 0.10694383546042069
Validation loss: 2.208506846871674

Epoch: 6| Step: 7
Training loss: 0.14287971580078496
Validation loss: 2.2162506310868575

Epoch: 6| Step: 8
Training loss: 0.1639499050875939
Validation loss: 2.193455606452193

Epoch: 6| Step: 9
Training loss: 0.11621385458482662
Validation loss: 2.182506756749696

Epoch: 6| Step: 10
Training loss: 0.0863237479122963
Validation loss: 2.1694653218315167

Epoch: 6| Step: 11
Training loss: 0.10053460190746129
Validation loss: 2.188446041926915

Epoch: 6| Step: 12
Training loss: 0.09150686513702988
Validation loss: 2.147060429966251

Epoch: 6| Step: 13
Training loss: 0.08751907491958723
Validation loss: 2.1662667128563537

Epoch: 547| Step: 0
Training loss: 0.10333932402412856
Validation loss: 2.1692249605584877

Epoch: 6| Step: 1
Training loss: 0.12299227638534613
Validation loss: 2.181267973253447

Epoch: 6| Step: 2
Training loss: 0.08586946416867873
Validation loss: 2.134117148436471

Epoch: 6| Step: 3
Training loss: 0.10021274742144931
Validation loss: 2.1176625258351534

Epoch: 6| Step: 4
Training loss: 0.14341933817977875
Validation loss: 2.1526638888947582

Epoch: 6| Step: 5
Training loss: 0.11504185483746243
Validation loss: 2.1574219854633405

Epoch: 6| Step: 6
Training loss: 0.1462561482478014
Validation loss: 2.1352685532325317

Epoch: 6| Step: 7
Training loss: 0.1303006099518313
Validation loss: 2.1735879737244335

Epoch: 6| Step: 8
Training loss: 0.0863652313542297
Validation loss: 2.178350564261928

Epoch: 6| Step: 9
Training loss: 0.06279373806234477
Validation loss: 2.179450123428803

Epoch: 6| Step: 10
Training loss: 0.07725242957693347
Validation loss: 2.176157638612178

Epoch: 6| Step: 11
Training loss: 0.07240210995920662
Validation loss: 2.1721744963833802

Epoch: 6| Step: 12
Training loss: 0.13148663482038672
Validation loss: 2.170611158035664

Epoch: 6| Step: 13
Training loss: 0.1479226582672538
Validation loss: 2.155176365950217

Epoch: 548| Step: 0
Training loss: 0.04491638326247698
Validation loss: 2.1769026977553474

Epoch: 6| Step: 1
Training loss: 0.08838577401891268
Validation loss: 2.1621382907832807

Epoch: 6| Step: 2
Training loss: 0.08250528980133749
Validation loss: 2.1606314267275053

Epoch: 6| Step: 3
Training loss: 0.06699195088825759
Validation loss: 2.1715248329059054

Epoch: 6| Step: 4
Training loss: 0.08157387735863214
Validation loss: 2.1858964729676615

Epoch: 6| Step: 5
Training loss: 0.09993086153351295
Validation loss: 2.1744198299862347

Epoch: 6| Step: 6
Training loss: 0.09219750778381398
Validation loss: 2.1819365379826783

Epoch: 6| Step: 7
Training loss: 0.04156496521309102
Validation loss: 2.1761708510852786

Epoch: 6| Step: 8
Training loss: 0.07317030240042353
Validation loss: 2.182510810398368

Epoch: 6| Step: 9
Training loss: 0.19404100437254698
Validation loss: 2.1975160797560074

Epoch: 6| Step: 10
Training loss: 0.12009571240127336
Validation loss: 2.187952406784255

Epoch: 6| Step: 11
Training loss: 0.11671299633592867
Validation loss: 2.1939449991531186

Epoch: 6| Step: 12
Training loss: 0.14042160769630596
Validation loss: 2.1766615418445405

Epoch: 6| Step: 13
Training loss: 0.057917919330134605
Validation loss: 2.203675155352855

Epoch: 549| Step: 0
Training loss: 0.11214386578910908
Validation loss: 2.228440705218868

Epoch: 6| Step: 1
Training loss: 0.1364203944197439
Validation loss: 2.1848946814975423

Epoch: 6| Step: 2
Training loss: 0.09254699477388127
Validation loss: 2.175318585642695

Epoch: 6| Step: 3
Training loss: 0.11905111796624393
Validation loss: 2.2040970100329176

Epoch: 6| Step: 4
Training loss: 0.07091114387461162
Validation loss: 2.218600529083446

Epoch: 6| Step: 5
Training loss: 0.08793741676052792
Validation loss: 2.2022496607207747

Epoch: 6| Step: 6
Training loss: 0.10870370752415114
Validation loss: 2.2020636155820488

Epoch: 6| Step: 7
Training loss: 0.08516156963041481
Validation loss: 2.204267538517373

Epoch: 6| Step: 8
Training loss: 0.16910770087006916
Validation loss: 2.190092640556813

Epoch: 6| Step: 9
Training loss: 0.08502344046679197
Validation loss: 2.1821445602780574

Epoch: 6| Step: 10
Training loss: 0.13135826323270042
Validation loss: 2.1975758862864896

Epoch: 6| Step: 11
Training loss: 0.09384198444546277
Validation loss: 2.1388073815202477

Epoch: 6| Step: 12
Training loss: 0.13024389655508017
Validation loss: 2.1557201051245216

Epoch: 6| Step: 13
Training loss: 0.14447089816771094
Validation loss: 2.1440984068466737

Epoch: 550| Step: 0
Training loss: 0.11018911997431358
Validation loss: 2.1588606769310172

Epoch: 6| Step: 1
Training loss: 0.12172155532493294
Validation loss: 2.157585818142042

Epoch: 6| Step: 2
Training loss: 0.17424166703994168
Validation loss: 2.1742363050209446

Epoch: 6| Step: 3
Training loss: 0.12357853516102923
Validation loss: 2.1531256001641887

Epoch: 6| Step: 4
Training loss: 0.10165003067438091
Validation loss: 2.159711003152114

Epoch: 6| Step: 5
Training loss: 0.08218242985439611
Validation loss: 2.1863618646915866

Epoch: 6| Step: 6
Training loss: 0.0853827517719805
Validation loss: 2.1623242474859756

Epoch: 6| Step: 7
Training loss: 0.07594734809442305
Validation loss: 2.181596812221608

Epoch: 6| Step: 8
Training loss: 0.13788648955760188
Validation loss: 2.1829111336677243

Epoch: 6| Step: 9
Training loss: 0.1268810727986855
Validation loss: 2.1925194175439304

Epoch: 6| Step: 10
Training loss: 0.13337404382724036
Validation loss: 2.201674927937587

Epoch: 6| Step: 11
Training loss: 0.10453253261281054
Validation loss: 2.197081878891199

Epoch: 6| Step: 12
Training loss: 0.061818608776586285
Validation loss: 2.1970812231276313

Epoch: 6| Step: 13
Training loss: 0.07660687168014114
Validation loss: 2.190475327261595

Epoch: 551| Step: 0
Training loss: 0.08923317926173814
Validation loss: 2.1758754635670017

Epoch: 6| Step: 1
Training loss: 0.1739996374704706
Validation loss: 2.1681587003731013

Epoch: 6| Step: 2
Training loss: 0.09660034102559609
Validation loss: 2.168791788517838

Epoch: 6| Step: 3
Training loss: 0.0655944159743371
Validation loss: 2.18032272162098

Epoch: 6| Step: 4
Training loss: 0.07172772255829787
Validation loss: 2.192837642038661

Epoch: 6| Step: 5
Training loss: 0.06130086093842228
Validation loss: 2.1899257377162487

Epoch: 6| Step: 6
Training loss: 0.06988951157839216
Validation loss: 2.152962475939335

Epoch: 6| Step: 7
Training loss: 0.09093721106244096
Validation loss: 2.1511020041630085

Epoch: 6| Step: 8
Training loss: 0.08014291375369559
Validation loss: 2.1555550816643296

Epoch: 6| Step: 9
Training loss: 0.14161136856325804
Validation loss: 2.152938556908237

Epoch: 6| Step: 10
Training loss: 0.057309127263780145
Validation loss: 2.1747873273726546

Epoch: 6| Step: 11
Training loss: 0.10103207783163717
Validation loss: 2.1881993279009833

Epoch: 6| Step: 12
Training loss: 0.10525273790133997
Validation loss: 2.1855069798238937

Epoch: 6| Step: 13
Training loss: 0.04886204256788149
Validation loss: 2.1957288018979284

Epoch: 552| Step: 0
Training loss: 0.07693869109262136
Validation loss: 2.1918401383103077

Epoch: 6| Step: 1
Training loss: 0.0708617704064403
Validation loss: 2.1980155775213577

Epoch: 6| Step: 2
Training loss: 0.14575989540224255
Validation loss: 2.184994260640992

Epoch: 6| Step: 3
Training loss: 0.04993744062001227
Validation loss: 2.2164848547142175

Epoch: 6| Step: 4
Training loss: 0.07579514680841289
Validation loss: 2.172307749592451

Epoch: 6| Step: 5
Training loss: 0.08496721288371674
Validation loss: 2.205354399069004

Epoch: 6| Step: 6
Training loss: 0.15394943691556748
Validation loss: 2.1702687380647547

Epoch: 6| Step: 7
Training loss: 0.06965876363135425
Validation loss: 2.190690604063384

Epoch: 6| Step: 8
Training loss: 0.05726350106415807
Validation loss: 2.2062116946176786

Epoch: 6| Step: 9
Training loss: 0.05551057912346479
Validation loss: 2.163369591416198

Epoch: 6| Step: 10
Training loss: 0.09833978332851034
Validation loss: 2.183445865615177

Epoch: 6| Step: 11
Training loss: 0.14042112353531203
Validation loss: 2.171256984821049

Epoch: 6| Step: 12
Training loss: 0.08697404827354882
Validation loss: 2.15590511237139

Epoch: 6| Step: 13
Training loss: 0.10652724009218524
Validation loss: 2.154364420846814

Epoch: 553| Step: 0
Training loss: 0.1372091354263073
Validation loss: 2.177877154737907

Epoch: 6| Step: 1
Training loss: 0.09137973971539792
Validation loss: 2.18213717413314

Epoch: 6| Step: 2
Training loss: 0.06125174621177789
Validation loss: 2.1548302868948706

Epoch: 6| Step: 3
Training loss: 0.0996280961114984
Validation loss: 2.1706754450085506

Epoch: 6| Step: 4
Training loss: 0.09570733372523063
Validation loss: 2.178401038557109

Epoch: 6| Step: 5
Training loss: 0.0854183631773078
Validation loss: 2.2006241902947

Epoch: 6| Step: 6
Training loss: 0.09365250564577113
Validation loss: 2.1918579446757533

Epoch: 6| Step: 7
Training loss: 0.06486852040621877
Validation loss: 2.1934213060584775

Epoch: 6| Step: 8
Training loss: 0.09674147355904354
Validation loss: 2.2084918713057076

Epoch: 6| Step: 9
Training loss: 0.07199687860721433
Validation loss: 2.2232779899094046

Epoch: 6| Step: 10
Training loss: 0.13586032995422526
Validation loss: 2.195937390230093

Epoch: 6| Step: 11
Training loss: 0.0942401292847002
Validation loss: 2.1971383835058984

Epoch: 6| Step: 12
Training loss: 0.12998407761560063
Validation loss: 2.202623292583792

Epoch: 6| Step: 13
Training loss: 0.07087116689046935
Validation loss: 2.1785383979428055

Epoch: 554| Step: 0
Training loss: 0.08362279447557322
Validation loss: 2.191625318913496

Epoch: 6| Step: 1
Training loss: 0.07215880540995756
Validation loss: 2.1985137747338657

Epoch: 6| Step: 2
Training loss: 0.11684239355326803
Validation loss: 2.180426524172839

Epoch: 6| Step: 3
Training loss: 0.09010570629087074
Validation loss: 2.179151922273441

Epoch: 6| Step: 4
Training loss: 0.08160386695365285
Validation loss: 2.179570302856929

Epoch: 6| Step: 5
Training loss: 0.07723782587956537
Validation loss: 2.1973975514830357

Epoch: 6| Step: 6
Training loss: 0.09141743135125203
Validation loss: 2.1800777147616026

Epoch: 6| Step: 7
Training loss: 0.13921858915968316
Validation loss: 2.2136632834991157

Epoch: 6| Step: 8
Training loss: 0.07021310854533142
Validation loss: 2.2068232177006983

Epoch: 6| Step: 9
Training loss: 0.1105390744776473
Validation loss: 2.1856693512568315

Epoch: 6| Step: 10
Training loss: 0.07584949890733761
Validation loss: 2.2131708074548198

Epoch: 6| Step: 11
Training loss: 0.06633459460649437
Validation loss: 2.2128137019538494

Epoch: 6| Step: 12
Training loss: 0.149425680668726
Validation loss: 2.227399533212412

Epoch: 6| Step: 13
Training loss: 0.19581924503628254
Validation loss: 2.2145274322850526

Epoch: 555| Step: 0
Training loss: 0.09960122168588342
Validation loss: 2.234570532040305

Epoch: 6| Step: 1
Training loss: 0.09034561879835493
Validation loss: 2.183860090863949

Epoch: 6| Step: 2
Training loss: 0.09106775640883288
Validation loss: 2.201626801983117

Epoch: 6| Step: 3
Training loss: 0.07270640544307438
Validation loss: 2.2078855199401004

Epoch: 6| Step: 4
Training loss: 0.09889187170440161
Validation loss: 2.191193192752514

Epoch: 6| Step: 5
Training loss: 0.08858938076877759
Validation loss: 2.2407690970445318

Epoch: 6| Step: 6
Training loss: 0.07882318255314665
Validation loss: 2.2259397483891115

Epoch: 6| Step: 7
Training loss: 0.09765861031540914
Validation loss: 2.2298691725295336

Epoch: 6| Step: 8
Training loss: 0.0817892928330205
Validation loss: 2.193655771038966

Epoch: 6| Step: 9
Training loss: 0.14442396047989647
Validation loss: 2.240793534665279

Epoch: 6| Step: 10
Training loss: 0.10824478273642996
Validation loss: 2.206771279168849

Epoch: 6| Step: 11
Training loss: 0.08409626294247464
Validation loss: 2.20823062937292

Epoch: 6| Step: 12
Training loss: 0.14481642657748958
Validation loss: 2.2066443441475307

Epoch: 6| Step: 13
Training loss: 0.07869026016608886
Validation loss: 2.210802916039594

Epoch: 556| Step: 0
Training loss: 0.05746921838804937
Validation loss: 2.224855719779843

Epoch: 6| Step: 1
Training loss: 0.0792215637971352
Validation loss: 2.217040804449433

Epoch: 6| Step: 2
Training loss: 0.07857595173467666
Validation loss: 2.212583557510692

Epoch: 6| Step: 3
Training loss: 0.07726968219430504
Validation loss: 2.2039686868429835

Epoch: 6| Step: 4
Training loss: 0.16942109383418197
Validation loss: 2.214811048591639

Epoch: 6| Step: 5
Training loss: 0.06394149266685227
Validation loss: 2.2409268929077704

Epoch: 6| Step: 6
Training loss: 0.09393937633420929
Validation loss: 2.221270063524108

Epoch: 6| Step: 7
Training loss: 0.09857996856385282
Validation loss: 2.236094596661007

Epoch: 6| Step: 8
Training loss: 0.12454385529718175
Validation loss: 2.216185413325897

Epoch: 6| Step: 9
Training loss: 0.09845733140060843
Validation loss: 2.1939906160333766

Epoch: 6| Step: 10
Training loss: 0.08849450975666215
Validation loss: 2.205811790887581

Epoch: 6| Step: 11
Training loss: 0.1260405237629464
Validation loss: 2.2017522808940186

Epoch: 6| Step: 12
Training loss: 0.1368353891103059
Validation loss: 2.1739578051392767

Epoch: 6| Step: 13
Training loss: 0.1304842996753525
Validation loss: 2.2097965851988217

Epoch: 557| Step: 0
Training loss: 0.05099281156198076
Validation loss: 2.1841038482650292

Epoch: 6| Step: 1
Training loss: 0.15962259423646846
Validation loss: 2.158604272784076

Epoch: 6| Step: 2
Training loss: 0.09813965363030136
Validation loss: 2.16476961137113

Epoch: 6| Step: 3
Training loss: 0.062231474195842545
Validation loss: 2.184196499778387

Epoch: 6| Step: 4
Training loss: 0.10474724701561813
Validation loss: 2.1669438331166515

Epoch: 6| Step: 5
Training loss: 0.0795213398679713
Validation loss: 2.1785868556536054

Epoch: 6| Step: 6
Training loss: 0.07830153725388289
Validation loss: 2.190305331118957

Epoch: 6| Step: 7
Training loss: 0.07245943461193723
Validation loss: 2.1714602003689953

Epoch: 6| Step: 8
Training loss: 0.05913334974341486
Validation loss: 2.176593187394661

Epoch: 6| Step: 9
Training loss: 0.08912904119157437
Validation loss: 2.1972226931663057

Epoch: 6| Step: 10
Training loss: 0.13744059466086736
Validation loss: 2.181109921633214

Epoch: 6| Step: 11
Training loss: 0.09795548845878753
Validation loss: 2.2010646574524637

Epoch: 6| Step: 12
Training loss: 0.07343766828781487
Validation loss: 2.2086499320595774

Epoch: 6| Step: 13
Training loss: 0.08013740531818804
Validation loss: 2.202057697367611

Epoch: 558| Step: 0
Training loss: 0.06967241952644403
Validation loss: 2.1900796636608773

Epoch: 6| Step: 1
Training loss: 0.0885729792801544
Validation loss: 2.1909264527008845

Epoch: 6| Step: 2
Training loss: 0.08101145614043624
Validation loss: 2.211836642448577

Epoch: 6| Step: 3
Training loss: 0.09971651224609973
Validation loss: 2.1926173800537803

Epoch: 6| Step: 4
Training loss: 0.07681638749173554
Validation loss: 2.210923916105247

Epoch: 6| Step: 5
Training loss: 0.05734099649489019
Validation loss: 2.1697688460559785

Epoch: 6| Step: 6
Training loss: 0.11473347614798093
Validation loss: 2.19260540609258

Epoch: 6| Step: 7
Training loss: 0.13262547620171886
Validation loss: 2.1893251214850578

Epoch: 6| Step: 8
Training loss: 0.0904180735551498
Validation loss: 2.1939475780471014

Epoch: 6| Step: 9
Training loss: 0.0537268441661459
Validation loss: 2.1754247823677355

Epoch: 6| Step: 10
Training loss: 0.07083156837106391
Validation loss: 2.1609812900351493

Epoch: 6| Step: 11
Training loss: 0.07102619986280943
Validation loss: 2.1605961908358235

Epoch: 6| Step: 12
Training loss: 0.15695472579754924
Validation loss: 2.1670956064776528

Epoch: 6| Step: 13
Training loss: 0.09301237657476263
Validation loss: 2.183693363813698

Epoch: 559| Step: 0
Training loss: 0.06399324747431834
Validation loss: 2.164153331750083

Epoch: 6| Step: 1
Training loss: 0.07347860010516954
Validation loss: 2.177462790909364

Epoch: 6| Step: 2
Training loss: 0.12863205155078908
Validation loss: 2.1709564266041905

Epoch: 6| Step: 3
Training loss: 0.13367159761481429
Validation loss: 2.172601066327755

Epoch: 6| Step: 4
Training loss: 0.09818386124892606
Validation loss: 2.2094338277884624

Epoch: 6| Step: 5
Training loss: 0.14559757101232346
Validation loss: 2.1903754349164237

Epoch: 6| Step: 6
Training loss: 0.09387341958454075
Validation loss: 2.147373125685075

Epoch: 6| Step: 7
Training loss: 0.06828372720593807
Validation loss: 2.162783543230081

Epoch: 6| Step: 8
Training loss: 0.10083247960073383
Validation loss: 2.189058959533663

Epoch: 6| Step: 9
Training loss: 0.09051548654870656
Validation loss: 2.1778829261898704

Epoch: 6| Step: 10
Training loss: 0.0844986219685249
Validation loss: 2.1730797265845574

Epoch: 6| Step: 11
Training loss: 0.06195683942004737
Validation loss: 2.186970651687265

Epoch: 6| Step: 12
Training loss: 0.10055576723817343
Validation loss: 2.199055251734381

Epoch: 6| Step: 13
Training loss: 0.1352519644587527
Validation loss: 2.1982766654468864

Epoch: 560| Step: 0
Training loss: 0.08881449971508099
Validation loss: 2.19349007782355

Epoch: 6| Step: 1
Training loss: 0.13200621734412116
Validation loss: 2.1720177907534453

Epoch: 6| Step: 2
Training loss: 0.10347965353226002
Validation loss: 2.1706607499482398

Epoch: 6| Step: 3
Training loss: 0.09336871355827085
Validation loss: 2.1787843009444727

Epoch: 6| Step: 4
Training loss: 0.06461860265071173
Validation loss: 2.189499171508299

Epoch: 6| Step: 5
Training loss: 0.13978103531416525
Validation loss: 2.182981622011435

Epoch: 6| Step: 6
Training loss: 0.1144994479232705
Validation loss: 2.1782282155260706

Epoch: 6| Step: 7
Training loss: 0.09663481586176738
Validation loss: 2.176210789598865

Epoch: 6| Step: 8
Training loss: 0.06648848854858722
Validation loss: 2.1870877596775444

Epoch: 6| Step: 9
Training loss: 0.07365822252429026
Validation loss: 2.2009126063373468

Epoch: 6| Step: 10
Training loss: 0.11056426740449932
Validation loss: 2.181123746450245

Epoch: 6| Step: 11
Training loss: 0.0810324971720574
Validation loss: 2.1939778491514788

Epoch: 6| Step: 12
Training loss: 0.06750637625340855
Validation loss: 2.2114485891995184

Epoch: 6| Step: 13
Training loss: 0.04519279304808008
Validation loss: 2.1844931878801677

Epoch: 561| Step: 0
Training loss: 0.09010350988769777
Validation loss: 2.202705937482613

Epoch: 6| Step: 1
Training loss: 0.05928980336597872
Validation loss: 2.1959996370410177

Epoch: 6| Step: 2
Training loss: 0.08069083113704775
Validation loss: 2.20679310769714

Epoch: 6| Step: 3
Training loss: 0.0535505805398935
Validation loss: 2.1918431360683748

Epoch: 6| Step: 4
Training loss: 0.0884174873906897
Validation loss: 2.1761597508697403

Epoch: 6| Step: 5
Training loss: 0.07334432473950983
Validation loss: 2.1840023932459447

Epoch: 6| Step: 6
Training loss: 0.07690861099495003
Validation loss: 2.196586798703058

Epoch: 6| Step: 7
Training loss: 0.06743753671247386
Validation loss: 2.164700529084227

Epoch: 6| Step: 8
Training loss: 0.12461477764220462
Validation loss: 2.1941450057593497

Epoch: 6| Step: 9
Training loss: 0.09851346963465273
Validation loss: 2.1675463595246787

Epoch: 6| Step: 10
Training loss: 0.10971483161772186
Validation loss: 2.169665715786714

Epoch: 6| Step: 11
Training loss: 0.08968432940052566
Validation loss: 2.1849582654448128

Epoch: 6| Step: 12
Training loss: 0.07456448612661551
Validation loss: 2.1746717499741797

Epoch: 6| Step: 13
Training loss: 0.159907799582608
Validation loss: 2.1666598824741112

Epoch: 562| Step: 0
Training loss: 0.11534227556667548
Validation loss: 2.1745122038407216

Epoch: 6| Step: 1
Training loss: 0.12613986025459936
Validation loss: 2.1718475441574245

Epoch: 6| Step: 2
Training loss: 0.09658256623184568
Validation loss: 2.146461091138333

Epoch: 6| Step: 3
Training loss: 0.06754491491648354
Validation loss: 2.156881325429703

Epoch: 6| Step: 4
Training loss: 0.05356796047999472
Validation loss: 2.157151555546839

Epoch: 6| Step: 5
Training loss: 0.11281472363750532
Validation loss: 2.1790168198782576

Epoch: 6| Step: 6
Training loss: 0.08545156203190458
Validation loss: 2.17109668708775

Epoch: 6| Step: 7
Training loss: 0.07361357941115458
Validation loss: 2.1913256310580853

Epoch: 6| Step: 8
Training loss: 0.12851808365901998
Validation loss: 2.177860691360544

Epoch: 6| Step: 9
Training loss: 0.07768897331349138
Validation loss: 2.170817758435302

Epoch: 6| Step: 10
Training loss: 0.10452208135933885
Validation loss: 2.1776780508799343

Epoch: 6| Step: 11
Training loss: 0.14641579612135883
Validation loss: 2.1931205839190735

Epoch: 6| Step: 12
Training loss: 0.072245543499223
Validation loss: 2.195411742653835

Epoch: 6| Step: 13
Training loss: 0.061485430164322966
Validation loss: 2.1778468737870544

Epoch: 563| Step: 0
Training loss: 0.14169618141920406
Validation loss: 2.1851049399397584

Epoch: 6| Step: 1
Training loss: 0.06561065315483304
Validation loss: 2.1683466844911528

Epoch: 6| Step: 2
Training loss: 0.08092112337316892
Validation loss: 2.177508102015189

Epoch: 6| Step: 3
Training loss: 0.05726628007488095
Validation loss: 2.169823603237276

Epoch: 6| Step: 4
Training loss: 0.11013934736231905
Validation loss: 2.173496549011829

Epoch: 6| Step: 5
Training loss: 0.14274121454448155
Validation loss: 2.1642487717019385

Epoch: 6| Step: 6
Training loss: 0.07999505991695888
Validation loss: 2.1526736621200286

Epoch: 6| Step: 7
Training loss: 0.05476655950442788
Validation loss: 2.1411190129090407

Epoch: 6| Step: 8
Training loss: 0.12569375786219117
Validation loss: 2.174534386846211

Epoch: 6| Step: 9
Training loss: 0.07377066369231558
Validation loss: 2.172690913386807

Epoch: 6| Step: 10
Training loss: 0.05592103252884781
Validation loss: 2.1725663266478747

Epoch: 6| Step: 11
Training loss: 0.0615738783042076
Validation loss: 2.18621348859501

Epoch: 6| Step: 12
Training loss: 0.0949598860280344
Validation loss: 2.2012796451753758

Epoch: 6| Step: 13
Training loss: 0.05501764769913516
Validation loss: 2.186416378675051

Epoch: 564| Step: 0
Training loss: 0.07178398996840005
Validation loss: 2.1815229169996355

Epoch: 6| Step: 1
Training loss: 0.13501653257660273
Validation loss: 2.1977955486839234

Epoch: 6| Step: 2
Training loss: 0.1084416792940917
Validation loss: 2.1849268497548318

Epoch: 6| Step: 3
Training loss: 0.07961551860617
Validation loss: 2.191936325058457

Epoch: 6| Step: 4
Training loss: 0.06772342920134532
Validation loss: 2.1609716380187773

Epoch: 6| Step: 5
Training loss: 0.0741837883469112
Validation loss: 2.159037065580392

Epoch: 6| Step: 6
Training loss: 0.17539528753459502
Validation loss: 2.1833541245242793

Epoch: 6| Step: 7
Training loss: 0.07413518115880759
Validation loss: 2.175814309427499

Epoch: 6| Step: 8
Training loss: 0.05196181167316864
Validation loss: 2.1640302206175814

Epoch: 6| Step: 9
Training loss: 0.047983619873430305
Validation loss: 2.1661240329675118

Epoch: 6| Step: 10
Training loss: 0.07452722490586011
Validation loss: 2.180842882835666

Epoch: 6| Step: 11
Training loss: 0.0471766225012218
Validation loss: 2.162032985292844

Epoch: 6| Step: 12
Training loss: 0.04629899564228759
Validation loss: 2.187371978295041

Epoch: 6| Step: 13
Training loss: 0.057769033807104624
Validation loss: 2.173553574762127

Epoch: 565| Step: 0
Training loss: 0.06523365931203993
Validation loss: 2.169981539451952

Epoch: 6| Step: 1
Training loss: 0.09281602685020066
Validation loss: 2.147799319350202

Epoch: 6| Step: 2
Training loss: 0.0761486776192964
Validation loss: 2.144142253521807

Epoch: 6| Step: 3
Training loss: 0.07253840230991593
Validation loss: 2.1420257706206836

Epoch: 6| Step: 4
Training loss: 0.06279802049928969
Validation loss: 2.1534241100938827

Epoch: 6| Step: 5
Training loss: 0.06766428416301386
Validation loss: 2.1743345866267854

Epoch: 6| Step: 6
Training loss: 0.07260502873512782
Validation loss: 2.171855461650651

Epoch: 6| Step: 7
Training loss: 0.07572491655968533
Validation loss: 2.1818219614611856

Epoch: 6| Step: 8
Training loss: 0.1483577401049518
Validation loss: 2.1960487046527506

Epoch: 6| Step: 9
Training loss: 0.09967113431537823
Validation loss: 2.2205994076618363

Epoch: 6| Step: 10
Training loss: 0.13021121419262796
Validation loss: 2.200935329294727

Epoch: 6| Step: 11
Training loss: 0.08404426878664553
Validation loss: 2.192970265105795

Epoch: 6| Step: 12
Training loss: 0.0883260431838928
Validation loss: 2.184724743668843

Epoch: 6| Step: 13
Training loss: 0.1740775461987641
Validation loss: 2.1923079594383386

Epoch: 566| Step: 0
Training loss: 0.07202002313715614
Validation loss: 2.190109611308297

Epoch: 6| Step: 1
Training loss: 0.08744451901142215
Validation loss: 2.148990305968519

Epoch: 6| Step: 2
Training loss: 0.11029009246318221
Validation loss: 2.171178627466475

Epoch: 6| Step: 3
Training loss: 0.10894888228144661
Validation loss: 2.1709860027417838

Epoch: 6| Step: 4
Training loss: 0.06653578830065603
Validation loss: 2.158586133911459

Epoch: 6| Step: 5
Training loss: 0.05760431549988317
Validation loss: 2.1760027673202

Epoch: 6| Step: 6
Training loss: 0.12311995697464921
Validation loss: 2.146399915305641

Epoch: 6| Step: 7
Training loss: 0.05937456582563168
Validation loss: 2.1523146657052696

Epoch: 6| Step: 8
Training loss: 0.08635871785291561
Validation loss: 2.159574805029842

Epoch: 6| Step: 9
Training loss: 0.08148037912550475
Validation loss: 2.173462845698378

Epoch: 6| Step: 10
Training loss: 0.051860289520206444
Validation loss: 2.166553082182666

Epoch: 6| Step: 11
Training loss: 0.11445335218908266
Validation loss: 2.1797516239604975

Epoch: 6| Step: 12
Training loss: 0.1266199434867462
Validation loss: 2.164197988071872

Epoch: 6| Step: 13
Training loss: 0.07979840176848885
Validation loss: 2.13671417874734

Epoch: 567| Step: 0
Training loss: 0.12534213926107307
Validation loss: 2.1536170765208418

Epoch: 6| Step: 1
Training loss: 0.0834956810478139
Validation loss: 2.158504539759928

Epoch: 6| Step: 2
Training loss: 0.06557698181856497
Validation loss: 2.1350885917062286

Epoch: 6| Step: 3
Training loss: 0.06134431930412393
Validation loss: 2.138710431058421

Epoch: 6| Step: 4
Training loss: 0.10098044334494823
Validation loss: 2.1305651866902315

Epoch: 6| Step: 5
Training loss: 0.10659100247837193
Validation loss: 2.1840116588284793

Epoch: 6| Step: 6
Training loss: 0.09248775364865114
Validation loss: 2.1615659176713478

Epoch: 6| Step: 7
Training loss: 0.08092831618904409
Validation loss: 2.1587178911290996

Epoch: 6| Step: 8
Training loss: 0.15630526757314983
Validation loss: 2.1783338620249335

Epoch: 6| Step: 9
Training loss: 0.08786313368742046
Validation loss: 2.197004580287507

Epoch: 6| Step: 10
Training loss: 0.07468334458275303
Validation loss: 2.1878784877708344

Epoch: 6| Step: 11
Training loss: 0.09215360175842535
Validation loss: 2.192400067211239

Epoch: 6| Step: 12
Training loss: 0.03319106338710433
Validation loss: 2.188211684472478

Epoch: 6| Step: 13
Training loss: 0.13185500960679056
Validation loss: 2.183971544271713

Epoch: 568| Step: 0
Training loss: 0.09979122056078232
Validation loss: 2.20019236748598

Epoch: 6| Step: 1
Training loss: 0.092937590281873
Validation loss: 2.1848858344397457

Epoch: 6| Step: 2
Training loss: 0.05730609639833983
Validation loss: 2.2046479437958872

Epoch: 6| Step: 3
Training loss: 0.06074654818027524
Validation loss: 2.1871331805353718

Epoch: 6| Step: 4
Training loss: 0.07979612006657022
Validation loss: 2.1913891617742243

Epoch: 6| Step: 5
Training loss: 0.10179433588182686
Validation loss: 2.2075221151895734

Epoch: 6| Step: 6
Training loss: 0.09190428314192668
Validation loss: 2.185690133160009

Epoch: 6| Step: 7
Training loss: 0.08368739860758576
Validation loss: 2.1855535810154123

Epoch: 6| Step: 8
Training loss: 0.0639504569378083
Validation loss: 2.187991445392418

Epoch: 6| Step: 9
Training loss: 0.24166307275390786
Validation loss: 2.1762900548192188

Epoch: 6| Step: 10
Training loss: 0.06627814825728372
Validation loss: 2.204897557667576

Epoch: 6| Step: 11
Training loss: 0.06547216915179063
Validation loss: 2.2032593158385585

Epoch: 6| Step: 12
Training loss: 0.131160290463835
Validation loss: 2.205109343118886

Epoch: 6| Step: 13
Training loss: 0.07420954521721272
Validation loss: 2.185844895999217

Epoch: 569| Step: 0
Training loss: 0.0772531046862676
Validation loss: 2.1921715873871808

Epoch: 6| Step: 1
Training loss: 0.07261620361334654
Validation loss: 2.1747336193747286

Epoch: 6| Step: 2
Training loss: 0.055736895646187154
Validation loss: 2.19648598679561

Epoch: 6| Step: 3
Training loss: 0.08334746154091618
Validation loss: 2.1594691418484295

Epoch: 6| Step: 4
Training loss: 0.1301102189116483
Validation loss: 2.157704482658078

Epoch: 6| Step: 5
Training loss: 0.14805665851968064
Validation loss: 2.1686725710084445

Epoch: 6| Step: 6
Training loss: 0.1365383320161509
Validation loss: 2.1656728323626115

Epoch: 6| Step: 7
Training loss: 0.10535553754606473
Validation loss: 2.168137281600728

Epoch: 6| Step: 8
Training loss: 0.0993921210727079
Validation loss: 2.151275827806778

Epoch: 6| Step: 9
Training loss: 0.07091595062981591
Validation loss: 2.132206785084546

Epoch: 6| Step: 10
Training loss: 0.07445690568729542
Validation loss: 2.1136075183976017

Epoch: 6| Step: 11
Training loss: 0.08252726467845785
Validation loss: 2.140081106152057

Epoch: 6| Step: 12
Training loss: 0.15131585265868633
Validation loss: 2.1549149925652022

Epoch: 6| Step: 13
Training loss: 0.131764965027222
Validation loss: 2.1836591451727942

Epoch: 570| Step: 0
Training loss: 0.08762872670108104
Validation loss: 2.170300406096994

Epoch: 6| Step: 1
Training loss: 0.05490841692511521
Validation loss: 2.1760856916334865

Epoch: 6| Step: 2
Training loss: 0.07361149188321575
Validation loss: 2.203249873469162

Epoch: 6| Step: 3
Training loss: 0.1336968514870967
Validation loss: 2.2251128870113543

Epoch: 6| Step: 4
Training loss: 0.13300468060227358
Validation loss: 2.231926882935228

Epoch: 6| Step: 5
Training loss: 0.21626768737188837
Validation loss: 2.2327850384886614

Epoch: 6| Step: 6
Training loss: 0.1194463387751561
Validation loss: 2.223572715862193

Epoch: 6| Step: 7
Training loss: 0.08446163039381512
Validation loss: 2.211881709530565

Epoch: 6| Step: 8
Training loss: 0.07360713318706842
Validation loss: 2.194230687877928

Epoch: 6| Step: 9
Training loss: 0.09943557049433546
Validation loss: 2.1912057559050098

Epoch: 6| Step: 10
Training loss: 0.11396732245906534
Validation loss: 2.157008245380774

Epoch: 6| Step: 11
Training loss: 0.07100749258808096
Validation loss: 2.172599394875774

Epoch: 6| Step: 12
Training loss: 0.10942500963641336
Validation loss: 2.157447436085256

Epoch: 6| Step: 13
Training loss: 0.20104418099927868
Validation loss: 2.178154665632434

Epoch: 571| Step: 0
Training loss: 0.10894726664971134
Validation loss: 2.1957633811896753

Epoch: 6| Step: 1
Training loss: 0.1210842359558539
Validation loss: 2.1774722308989447

Epoch: 6| Step: 2
Training loss: 0.09042545848375047
Validation loss: 2.199808037587554

Epoch: 6| Step: 3
Training loss: 0.1252510559671397
Validation loss: 2.2040207141006447

Epoch: 6| Step: 4
Training loss: 0.18083676512013763
Validation loss: 2.210576657212165

Epoch: 6| Step: 5
Training loss: 0.12128008457563562
Validation loss: 2.20494576280006

Epoch: 6| Step: 6
Training loss: 0.11997915881691719
Validation loss: 2.1884535315373705

Epoch: 6| Step: 7
Training loss: 0.15511711216667534
Validation loss: 2.1533745724319084

Epoch: 6| Step: 8
Training loss: 0.1020637120719789
Validation loss: 2.1303353140280947

Epoch: 6| Step: 9
Training loss: 0.15089879938724582
Validation loss: 2.138373403136918

Epoch: 6| Step: 10
Training loss: 0.15612227464684042
Validation loss: 2.1149657363519108

Epoch: 6| Step: 11
Training loss: 0.1208821763363537
Validation loss: 2.138433927143065

Epoch: 6| Step: 12
Training loss: 0.17120251986720525
Validation loss: 2.1443294659812406

Epoch: 6| Step: 13
Training loss: 0.12851343848736677
Validation loss: 2.134942566720491

Epoch: 572| Step: 0
Training loss: 0.12106884807989157
Validation loss: 2.166751034831775

Epoch: 6| Step: 1
Training loss: 0.0677162366008078
Validation loss: 2.213734042200586

Epoch: 6| Step: 2
Training loss: 0.08813804134294081
Validation loss: 2.252031586102714

Epoch: 6| Step: 3
Training loss: 0.12249626231208555
Validation loss: 2.216374240485509

Epoch: 6| Step: 4
Training loss: 0.2726595848338631
Validation loss: 2.2360948150656834

Epoch: 6| Step: 5
Training loss: 0.1556505147095235
Validation loss: 2.243604965965726

Epoch: 6| Step: 6
Training loss: 0.20237868092201203
Validation loss: 2.248607558985268

Epoch: 6| Step: 7
Training loss: 0.17666675266415224
Validation loss: 2.2343372221590707

Epoch: 6| Step: 8
Training loss: 0.15059587789695694
Validation loss: 2.2063578532374306

Epoch: 6| Step: 9
Training loss: 0.1536792635244471
Validation loss: 2.215017003154981

Epoch: 6| Step: 10
Training loss: 0.118272093578474
Validation loss: 2.1924497959419136

Epoch: 6| Step: 11
Training loss: 0.15393754911944665
Validation loss: 2.206342292571962

Epoch: 6| Step: 12
Training loss: 0.17467354271735225
Validation loss: 2.1930280335492998

Epoch: 6| Step: 13
Training loss: 0.14544554152385897
Validation loss: 2.2191639019760436

Epoch: 573| Step: 0
Training loss: 0.19997458967077822
Validation loss: 2.2024917058874784

Epoch: 6| Step: 1
Training loss: 0.14782274461734007
Validation loss: 2.2336644601087823

Epoch: 6| Step: 2
Training loss: 0.12844506039608336
Validation loss: 2.2314761927637736

Epoch: 6| Step: 3
Training loss: 0.21974761862001552
Validation loss: 2.213837199934396

Epoch: 6| Step: 4
Training loss: 0.1906582170218349
Validation loss: 2.2157365114799052

Epoch: 6| Step: 5
Training loss: 0.15928304861997986
Validation loss: 2.154686083474867

Epoch: 6| Step: 6
Training loss: 0.14576703222026707
Validation loss: 2.1418752831151973

Epoch: 6| Step: 7
Training loss: 0.10814479415858841
Validation loss: 2.1444802618410344

Epoch: 6| Step: 8
Training loss: 0.14248626833140005
Validation loss: 2.1186468314345217

Epoch: 6| Step: 9
Training loss: 0.10163062360172996
Validation loss: 2.1741658373639603

Epoch: 6| Step: 10
Training loss: 0.2608933742698415
Validation loss: 2.1673495156890876

Epoch: 6| Step: 11
Training loss: 0.1445796086626763
Validation loss: 2.186516932607732

Epoch: 6| Step: 12
Training loss: 0.09898113837065113
Validation loss: 2.1952583715913847

Epoch: 6| Step: 13
Training loss: 0.047917306267747296
Validation loss: 2.224199326415104

Epoch: 574| Step: 0
Training loss: 0.15251431942179586
Validation loss: 2.2417485417463614

Epoch: 6| Step: 1
Training loss: 0.14868440923007903
Validation loss: 2.277381778595754

Epoch: 6| Step: 2
Training loss: 0.1722547767752633
Validation loss: 2.273327795100188

Epoch: 6| Step: 3
Training loss: 0.16615818298166818
Validation loss: 2.238791434262213

Epoch: 6| Step: 4
Training loss: 0.16193973903661363
Validation loss: 2.2426223061744217

Epoch: 6| Step: 5
Training loss: 0.12256196006012081
Validation loss: 2.203484725704235

Epoch: 6| Step: 6
Training loss: 0.13854413798166848
Validation loss: 2.2038228525295405

Epoch: 6| Step: 7
Training loss: 0.1426472169872041
Validation loss: 2.1801912635128833

Epoch: 6| Step: 8
Training loss: 0.11897474998923588
Validation loss: 2.189329625628122

Epoch: 6| Step: 9
Training loss: 0.1321341215402748
Validation loss: 2.186385794166677

Epoch: 6| Step: 10
Training loss: 0.1488712648760739
Validation loss: 2.192132892784691

Epoch: 6| Step: 11
Training loss: 0.16334152751758585
Validation loss: 2.2115296030774276

Epoch: 6| Step: 12
Training loss: 0.11165052711720708
Validation loss: 2.2207539925311517

Epoch: 6| Step: 13
Training loss: 0.10370785480522716
Validation loss: 2.1979481624307535

Epoch: 575| Step: 0
Training loss: 0.0771739380375943
Validation loss: 2.195056631636975

Epoch: 6| Step: 1
Training loss: 0.15266150567994305
Validation loss: 2.1764507085990217

Epoch: 6| Step: 2
Training loss: 0.12362156360308027
Validation loss: 2.2038542896724795

Epoch: 6| Step: 3
Training loss: 0.1386168196012754
Validation loss: 2.1987264502513026

Epoch: 6| Step: 4
Training loss: 0.12152462488769658
Validation loss: 2.1850476947291932

Epoch: 6| Step: 5
Training loss: 0.1002659987055832
Validation loss: 2.1618679990264544

Epoch: 6| Step: 6
Training loss: 0.12357442781959141
Validation loss: 2.1718419762213093

Epoch: 6| Step: 7
Training loss: 0.15040444644977657
Validation loss: 2.164191789216346

Epoch: 6| Step: 8
Training loss: 0.11400480460537914
Validation loss: 2.1683006617148415

Epoch: 6| Step: 9
Training loss: 0.19560339246191655
Validation loss: 2.1400181474731776

Epoch: 6| Step: 10
Training loss: 0.1412307487931322
Validation loss: 2.188440680223982

Epoch: 6| Step: 11
Training loss: 0.07054755208439309
Validation loss: 2.157543214857513

Epoch: 6| Step: 12
Training loss: 0.12455410329436108
Validation loss: 2.20906479628923

Epoch: 6| Step: 13
Training loss: 0.10042103889287016
Validation loss: 2.2146728088524776

Epoch: 576| Step: 0
Training loss: 0.23786614954525856
Validation loss: 2.218211111890789

Epoch: 6| Step: 1
Training loss: 0.06254599041424039
Validation loss: 2.212891533700678

Epoch: 6| Step: 2
Training loss: 0.0673661902560788
Validation loss: 2.224068525796292

Epoch: 6| Step: 3
Training loss: 0.14506824715531977
Validation loss: 2.1872812410773617

Epoch: 6| Step: 4
Training loss: 0.10449479893068306
Validation loss: 2.209718799757497

Epoch: 6| Step: 5
Training loss: 0.14589862695806782
Validation loss: 2.2289902334819702

Epoch: 6| Step: 6
Training loss: 0.09567949431483891
Validation loss: 2.204121238959464

Epoch: 6| Step: 7
Training loss: 0.12921815042921683
Validation loss: 2.23668565576674

Epoch: 6| Step: 8
Training loss: 0.23117750101053608
Validation loss: 2.205473263415218

Epoch: 6| Step: 9
Training loss: 0.1400250378639471
Validation loss: 2.218643619217657

Epoch: 6| Step: 10
Training loss: 0.14903622893585125
Validation loss: 2.215200255700338

Epoch: 6| Step: 11
Training loss: 0.14191759293583023
Validation loss: 2.203318195051171

Epoch: 6| Step: 12
Training loss: 0.0829416403958703
Validation loss: 2.194133910597926

Epoch: 6| Step: 13
Training loss: 0.07006030086206046
Validation loss: 2.1868197120154944

Epoch: 577| Step: 0
Training loss: 0.0686781975642363
Validation loss: 2.1918929177857076

Epoch: 6| Step: 1
Training loss: 0.1558532565452818
Validation loss: 2.158316730016196

Epoch: 6| Step: 2
Training loss: 0.13035763446039567
Validation loss: 2.1805875979977274

Epoch: 6| Step: 3
Training loss: 0.11147274695840312
Validation loss: 2.1885469430480904

Epoch: 6| Step: 4
Training loss: 0.12495882503540086
Validation loss: 2.173764255587349

Epoch: 6| Step: 5
Training loss: 0.11336703998197767
Validation loss: 2.1831566885766573

Epoch: 6| Step: 6
Training loss: 0.08006096574648111
Validation loss: 2.1763509205383933

Epoch: 6| Step: 7
Training loss: 0.18761000783709825
Validation loss: 2.1827120908395377

Epoch: 6| Step: 8
Training loss: 0.1663969373111951
Validation loss: 2.1826763099462245

Epoch: 6| Step: 9
Training loss: 0.13023912701464138
Validation loss: 2.16066963957546

Epoch: 6| Step: 10
Training loss: 0.1601307662600119
Validation loss: 2.14963168995717

Epoch: 6| Step: 11
Training loss: 0.15561513670339833
Validation loss: 2.1167680715177837

Epoch: 6| Step: 12
Training loss: 0.09524416838744976
Validation loss: 2.1302358857857246

Epoch: 6| Step: 13
Training loss: 0.14458018196305783
Validation loss: 2.1169685995594953

Epoch: 578| Step: 0
Training loss: 0.10325946241885992
Validation loss: 2.126587370765737

Epoch: 6| Step: 1
Training loss: 0.13565362470011438
Validation loss: 2.161594833015522

Epoch: 6| Step: 2
Training loss: 0.12493614338948844
Validation loss: 2.157471342855505

Epoch: 6| Step: 3
Training loss: 0.09443205839090456
Validation loss: 2.187130161083747

Epoch: 6| Step: 4
Training loss: 0.13476194846625375
Validation loss: 2.182222613161059

Epoch: 6| Step: 5
Training loss: 0.17426832588529179
Validation loss: 2.182530724087739

Epoch: 6| Step: 6
Training loss: 0.1811432746200502
Validation loss: 2.2104760600166156

Epoch: 6| Step: 7
Training loss: 0.1544266770428807
Validation loss: 2.244703972122357

Epoch: 6| Step: 8
Training loss: 0.10487847363609626
Validation loss: 2.2106286756515034

Epoch: 6| Step: 9
Training loss: 0.12055832408596397
Validation loss: 2.238270768774558

Epoch: 6| Step: 10
Training loss: 0.10635118960281063
Validation loss: 2.2315014685602943

Epoch: 6| Step: 11
Training loss: 0.1264035728227672
Validation loss: 2.244979230054416

Epoch: 6| Step: 12
Training loss: 0.11763175362323657
Validation loss: 2.2350071802175586

Epoch: 6| Step: 13
Training loss: 0.09422355497263807
Validation loss: 2.201349212863282

Epoch: 579| Step: 0
Training loss: 0.09418244264101813
Validation loss: 2.18777562586262

Epoch: 6| Step: 1
Training loss: 0.1359208803869531
Validation loss: 2.1514961159692154

Epoch: 6| Step: 2
Training loss: 0.16125051649883262
Validation loss: 2.1580832869107027

Epoch: 6| Step: 3
Training loss: 0.16039748167422338
Validation loss: 2.15584547455025

Epoch: 6| Step: 4
Training loss: 0.22067506156003047
Validation loss: 2.162301396208811

Epoch: 6| Step: 5
Training loss: 0.16522365607446543
Validation loss: 2.191895845295612

Epoch: 6| Step: 6
Training loss: 0.09604379782239536
Validation loss: 2.209201895785221

Epoch: 6| Step: 7
Training loss: 0.08324588406722425
Validation loss: 2.235538954253635

Epoch: 6| Step: 8
Training loss: 0.14237090951906223
Validation loss: 2.2154549287528003

Epoch: 6| Step: 9
Training loss: 0.12860997426756934
Validation loss: 2.2544568788388464

Epoch: 6| Step: 10
Training loss: 0.19054143512338328
Validation loss: 2.258888546572566

Epoch: 6| Step: 11
Training loss: 0.12812805084922674
Validation loss: 2.2059867830387145

Epoch: 6| Step: 12
Training loss: 0.0995773750215879
Validation loss: 2.2081956323221927

Epoch: 6| Step: 13
Training loss: 0.10622577601463797
Validation loss: 2.1851855279357038

Epoch: 580| Step: 0
Training loss: 0.09409796690098776
Validation loss: 2.173610116625811

Epoch: 6| Step: 1
Training loss: 0.10411603014756352
Validation loss: 2.1781330803331262

Epoch: 6| Step: 2
Training loss: 0.12314456513152537
Validation loss: 2.156227253179665

Epoch: 6| Step: 3
Training loss: 0.1207902010923277
Validation loss: 2.1338289718892396

Epoch: 6| Step: 4
Training loss: 0.11793455582002939
Validation loss: 2.145806073944423

Epoch: 6| Step: 5
Training loss: 0.08836960875359458
Validation loss: 2.171777824115912

Epoch: 6| Step: 6
Training loss: 0.1463013777495721
Validation loss: 2.1582452062705277

Epoch: 6| Step: 7
Training loss: 0.11368157912318946
Validation loss: 2.1667534839978444

Epoch: 6| Step: 8
Training loss: 0.06479001863924758
Validation loss: 2.163777145799621

Epoch: 6| Step: 9
Training loss: 0.10266835825709461
Validation loss: 2.2152179900210816

Epoch: 6| Step: 10
Training loss: 0.07735342846627004
Validation loss: 2.199259475863939

Epoch: 6| Step: 11
Training loss: 0.06193047555648478
Validation loss: 2.1932648464602993

Epoch: 6| Step: 12
Training loss: 0.09519733365761769
Validation loss: 2.221697631460569

Epoch: 6| Step: 13
Training loss: 0.19633951060763555
Validation loss: 2.2126970468851908

Epoch: 581| Step: 0
Training loss: 0.17673017485980552
Validation loss: 2.205403900794286

Epoch: 6| Step: 1
Training loss: 0.1788253105512056
Validation loss: 2.184480026916942

Epoch: 6| Step: 2
Training loss: 0.1255502436505813
Validation loss: 2.1699051445105697

Epoch: 6| Step: 3
Training loss: 0.12928006849516693
Validation loss: 2.2003943688321956

Epoch: 6| Step: 4
Training loss: 0.07868512939771123
Validation loss: 2.1811112357115823

Epoch: 6| Step: 5
Training loss: 0.08703672133323007
Validation loss: 2.207431887454492

Epoch: 6| Step: 6
Training loss: 0.05572195138228072
Validation loss: 2.1829860388340867

Epoch: 6| Step: 7
Training loss: 0.07876187254895367
Validation loss: 2.203605965319825

Epoch: 6| Step: 8
Training loss: 0.10108320223926105
Validation loss: 2.2042156339734267

Epoch: 6| Step: 9
Training loss: 0.08478018837737593
Validation loss: 2.2212147544835292

Epoch: 6| Step: 10
Training loss: 0.06558415342316132
Validation loss: 2.1895260822617804

Epoch: 6| Step: 11
Training loss: 0.09763052601566287
Validation loss: 2.2136474122781857

Epoch: 6| Step: 12
Training loss: 0.11723148394724674
Validation loss: 2.209741831253033

Epoch: 6| Step: 13
Training loss: 0.11089747354908819
Validation loss: 2.1790604568800602

Epoch: 582| Step: 0
Training loss: 0.13248913331276163
Validation loss: 2.2004729149519573

Epoch: 6| Step: 1
Training loss: 0.13359375780785968
Validation loss: 2.217487327749514

Epoch: 6| Step: 2
Training loss: 0.11137851193887072
Validation loss: 2.1721621406402343

Epoch: 6| Step: 3
Training loss: 0.12605893598690152
Validation loss: 2.196709700432134

Epoch: 6| Step: 4
Training loss: 0.09329882477770671
Validation loss: 2.1739279769747464

Epoch: 6| Step: 5
Training loss: 0.12328368438981156
Validation loss: 2.1650030848477746

Epoch: 6| Step: 6
Training loss: 0.1083615687106302
Validation loss: 2.1807743508605935

Epoch: 6| Step: 7
Training loss: 0.10190752003301506
Validation loss: 2.150517760679748

Epoch: 6| Step: 8
Training loss: 0.16538245124602644
Validation loss: 2.1750057363711477

Epoch: 6| Step: 9
Training loss: 0.05382744118072046
Validation loss: 2.1819587030796463

Epoch: 6| Step: 10
Training loss: 0.10716437775755379
Validation loss: 2.1701806878990064

Epoch: 6| Step: 11
Training loss: 0.09439353803431387
Validation loss: 2.2132798350682754

Epoch: 6| Step: 12
Training loss: 0.13625509798285496
Validation loss: 2.2048638291444873

Epoch: 6| Step: 13
Training loss: 0.05632013875400319
Validation loss: 2.201869980955083

Epoch: 583| Step: 0
Training loss: 0.1485983265935129
Validation loss: 2.185674718585214

Epoch: 6| Step: 1
Training loss: 0.07638860704569889
Validation loss: 2.199431004174825

Epoch: 6| Step: 2
Training loss: 0.06899231734839734
Validation loss: 2.1906478616862297

Epoch: 6| Step: 3
Training loss: 0.10037719955920306
Validation loss: 2.204274426000793

Epoch: 6| Step: 4
Training loss: 0.1242992757904656
Validation loss: 2.207996093839653

Epoch: 6| Step: 5
Training loss: 0.0854049949647999
Validation loss: 2.2282939701903466

Epoch: 6| Step: 6
Training loss: 0.10122851329212369
Validation loss: 2.2185734885597825

Epoch: 6| Step: 7
Training loss: 0.12596254492551928
Validation loss: 2.2126168456733724

Epoch: 6| Step: 8
Training loss: 0.08186595589248018
Validation loss: 2.239855706998322

Epoch: 6| Step: 9
Training loss: 0.05922753764868005
Validation loss: 2.2165379951887814

Epoch: 6| Step: 10
Training loss: 0.089360982172401
Validation loss: 2.199331046796254

Epoch: 6| Step: 11
Training loss: 0.1167447747410559
Validation loss: 2.2176807478278775

Epoch: 6| Step: 12
Training loss: 0.09822400040388542
Validation loss: 2.211734950407911

Epoch: 6| Step: 13
Training loss: 0.15777487542370075
Validation loss: 2.198259968830421

Epoch: 584| Step: 0
Training loss: 0.06049251423338235
Validation loss: 2.1989138584989893

Epoch: 6| Step: 1
Training loss: 0.12374454589827479
Validation loss: 2.208499951693075

Epoch: 6| Step: 2
Training loss: 0.0799874833632549
Validation loss: 2.190939999690406

Epoch: 6| Step: 3
Training loss: 0.07488373820011784
Validation loss: 2.189424863865282

Epoch: 6| Step: 4
Training loss: 0.09325742462018738
Validation loss: 2.17040124719697

Epoch: 6| Step: 5
Training loss: 0.10227168508923433
Validation loss: 2.1826834945955866

Epoch: 6| Step: 6
Training loss: 0.15516852187214697
Validation loss: 2.172731877499183

Epoch: 6| Step: 7
Training loss: 0.10878839458349573
Validation loss: 2.15428343376465

Epoch: 6| Step: 8
Training loss: 0.10253456650822705
Validation loss: 2.1494277608001044

Epoch: 6| Step: 9
Training loss: 0.11566022806662357
Validation loss: 2.182412091751713

Epoch: 6| Step: 10
Training loss: 0.07378393091762304
Validation loss: 2.177767794427276

Epoch: 6| Step: 11
Training loss: 0.09819879028385865
Validation loss: 2.199292692349244

Epoch: 6| Step: 12
Training loss: 0.107904701612882
Validation loss: 2.232203437932368

Epoch: 6| Step: 13
Training loss: 0.07801629490739503
Validation loss: 2.225097215553549

Epoch: 585| Step: 0
Training loss: 0.09992978976580497
Validation loss: 2.2162885535466907

Epoch: 6| Step: 1
Training loss: 0.12585973127469785
Validation loss: 2.194776127130833

Epoch: 6| Step: 2
Training loss: 0.134104558576211
Validation loss: 2.1966113123746687

Epoch: 6| Step: 3
Training loss: 0.1118869101122475
Validation loss: 2.202694443174387

Epoch: 6| Step: 4
Training loss: 0.07693732021901115
Validation loss: 2.174926609993008

Epoch: 6| Step: 5
Training loss: 0.07708297438903094
Validation loss: 2.1823379116595087

Epoch: 6| Step: 6
Training loss: 0.09484797493449953
Validation loss: 2.1915191199588504

Epoch: 6| Step: 7
Training loss: 0.07918571775722015
Validation loss: 2.171606133811173

Epoch: 6| Step: 8
Training loss: 0.14495868241147566
Validation loss: 2.1584186250925006

Epoch: 6| Step: 9
Training loss: 0.05948575263999529
Validation loss: 2.169213182475348

Epoch: 6| Step: 10
Training loss: 0.1373339571624232
Validation loss: 2.1810451905396935

Epoch: 6| Step: 11
Training loss: 0.10463149597512071
Validation loss: 2.179334001636416

Epoch: 6| Step: 12
Training loss: 0.08261504373406896
Validation loss: 2.163097569985212

Epoch: 6| Step: 13
Training loss: 0.06508074776331954
Validation loss: 2.1665604646589163

Epoch: 586| Step: 0
Training loss: 0.16351890197984215
Validation loss: 2.165667602496939

Epoch: 6| Step: 1
Training loss: 0.07382597327250431
Validation loss: 2.1674504846175515

Epoch: 6| Step: 2
Training loss: 0.05100627248977625
Validation loss: 2.1599835397958347

Epoch: 6| Step: 3
Training loss: 0.06770019146065988
Validation loss: 2.198272702679657

Epoch: 6| Step: 4
Training loss: 0.08349915549035364
Validation loss: 2.18529740645937

Epoch: 6| Step: 5
Training loss: 0.12789332622921493
Validation loss: 2.187769896327492

Epoch: 6| Step: 6
Training loss: 0.11909483983530407
Validation loss: 2.174969108512096

Epoch: 6| Step: 7
Training loss: 0.07279481953529303
Validation loss: 2.184543944482113

Epoch: 6| Step: 8
Training loss: 0.12203500236989218
Validation loss: 2.177222239855639

Epoch: 6| Step: 9
Training loss: 0.10013614007802345
Validation loss: 2.170597146973894

Epoch: 6| Step: 10
Training loss: 0.06928375456459376
Validation loss: 2.1447727590306607

Epoch: 6| Step: 11
Training loss: 0.10003070918565331
Validation loss: 2.1104402854827193

Epoch: 6| Step: 12
Training loss: 0.07663048030097883
Validation loss: 2.1544644282220418

Epoch: 6| Step: 13
Training loss: 0.05393353847858069
Validation loss: 2.1340433131963876

Epoch: 587| Step: 0
Training loss: 0.053591158998183355
Validation loss: 2.1393473355429515

Epoch: 6| Step: 1
Training loss: 0.08268356384840528
Validation loss: 2.147093438641763

Epoch: 6| Step: 2
Training loss: 0.11917174433166734
Validation loss: 2.1466874193952568

Epoch: 6| Step: 3
Training loss: 0.05476090494540718
Validation loss: 2.123721614671298

Epoch: 6| Step: 4
Training loss: 0.08846718504770325
Validation loss: 2.129605201848405

Epoch: 6| Step: 5
Training loss: 0.09803018503884423
Validation loss: 2.1217485932835207

Epoch: 6| Step: 6
Training loss: 0.12301875731716203
Validation loss: 2.1368074633596876

Epoch: 6| Step: 7
Training loss: 0.0650147189155337
Validation loss: 2.134179159847651

Epoch: 6| Step: 8
Training loss: 0.09220607336088545
Validation loss: 2.1274202945404914

Epoch: 6| Step: 9
Training loss: 0.10536567189689366
Validation loss: 2.154081933703973

Epoch: 6| Step: 10
Training loss: 0.09730664617649039
Validation loss: 2.1541673929672585

Epoch: 6| Step: 11
Training loss: 0.15168555219631177
Validation loss: 2.1835623745554824

Epoch: 6| Step: 12
Training loss: 0.11251629506088957
Validation loss: 2.176209317650434

Epoch: 6| Step: 13
Training loss: 0.06117149955505191
Validation loss: 2.1792600896816

Epoch: 588| Step: 0
Training loss: 0.07034196501169866
Validation loss: 2.172537870624213

Epoch: 6| Step: 1
Training loss: 0.08714617851933949
Validation loss: 2.1825735000386164

Epoch: 6| Step: 2
Training loss: 0.11786877172374723
Validation loss: 2.161356386245776

Epoch: 6| Step: 3
Training loss: 0.06499504083046173
Validation loss: 2.159179916059392

Epoch: 6| Step: 4
Training loss: 0.07331989933988874
Validation loss: 2.146390497512333

Epoch: 6| Step: 5
Training loss: 0.11105156310091156
Validation loss: 2.1729171057624677

Epoch: 6| Step: 6
Training loss: 0.08720532380383676
Validation loss: 2.167950250764154

Epoch: 6| Step: 7
Training loss: 0.16275193510208916
Validation loss: 2.1816039545964907

Epoch: 6| Step: 8
Training loss: 0.11523858967848379
Validation loss: 2.1878042697978284

Epoch: 6| Step: 9
Training loss: 0.06659855765894439
Validation loss: 2.186071540646837

Epoch: 6| Step: 10
Training loss: 0.13656279660984885
Validation loss: 2.2022168665924076

Epoch: 6| Step: 11
Training loss: 0.07857073645540415
Validation loss: 2.2112264954132606

Epoch: 6| Step: 12
Training loss: 0.10679020696193221
Validation loss: 2.2239539187277697

Epoch: 6| Step: 13
Training loss: 0.14214323947896834
Validation loss: 2.2121258002717616

Epoch: 589| Step: 0
Training loss: 0.12711939560606078
Validation loss: 2.222497294776007

Epoch: 6| Step: 1
Training loss: 0.11803304091936295
Validation loss: 2.1950180386983478

Epoch: 6| Step: 2
Training loss: 0.15812246597656976
Validation loss: 2.1851026204537995

Epoch: 6| Step: 3
Training loss: 0.08862888957959149
Validation loss: 2.1592380946204526

Epoch: 6| Step: 4
Training loss: 0.09283132754684566
Validation loss: 2.159244692377912

Epoch: 6| Step: 5
Training loss: 0.10630530152347133
Validation loss: 2.166231994080695

Epoch: 6| Step: 6
Training loss: 0.06577769294780643
Validation loss: 2.1589614800127546

Epoch: 6| Step: 7
Training loss: 0.114686191425342
Validation loss: 2.1679814294061632

Epoch: 6| Step: 8
Training loss: 0.1584349628956373
Validation loss: 2.139242335433216

Epoch: 6| Step: 9
Training loss: 0.10457268404061577
Validation loss: 2.1489203030464687

Epoch: 6| Step: 10
Training loss: 0.16312364610570543
Validation loss: 2.167736792172218

Epoch: 6| Step: 11
Training loss: 0.07868253429691746
Validation loss: 2.1698055504748384

Epoch: 6| Step: 12
Training loss: 0.1606009403904607
Validation loss: 2.15144506528034

Epoch: 6| Step: 13
Training loss: 0.08634854221989614
Validation loss: 2.194082303806439

Epoch: 590| Step: 0
Training loss: 0.11431286781422886
Validation loss: 2.1981254046561385

Epoch: 6| Step: 1
Training loss: 0.2351208739428212
Validation loss: 2.2120801106034818

Epoch: 6| Step: 2
Training loss: 0.23195749260094675
Validation loss: 2.21206375343923

Epoch: 6| Step: 3
Training loss: 0.0885565800121732
Validation loss: 2.2250749812961783

Epoch: 6| Step: 4
Training loss: 0.10072130982373953
Validation loss: 2.1982307590678394

Epoch: 6| Step: 5
Training loss: 0.13268120671341246
Validation loss: 2.183569491716131

Epoch: 6| Step: 6
Training loss: 0.18167280096741834
Validation loss: 2.154845197283039

Epoch: 6| Step: 7
Training loss: 0.08935390012437772
Validation loss: 2.141660279030282

Epoch: 6| Step: 8
Training loss: 0.13371185525305612
Validation loss: 2.15262131622454

Epoch: 6| Step: 9
Training loss: 0.12771238551885636
Validation loss: 2.166356139810183

Epoch: 6| Step: 10
Training loss: 0.1746037356428185
Validation loss: 2.1745509237428804

Epoch: 6| Step: 11
Training loss: 0.09935234136141893
Validation loss: 2.167698450817893

Epoch: 6| Step: 12
Training loss: 0.09619686672764714
Validation loss: 2.148944220575278

Epoch: 6| Step: 13
Training loss: 0.06741852781290637
Validation loss: 2.172843167845403

Epoch: 591| Step: 0
Training loss: 0.09584947509289826
Validation loss: 2.1890332100681564

Epoch: 6| Step: 1
Training loss: 0.09614736255464232
Validation loss: 2.2099256163535776

Epoch: 6| Step: 2
Training loss: 0.053710874644156005
Validation loss: 2.226693738413347

Epoch: 6| Step: 3
Training loss: 0.10425873105333039
Validation loss: 2.2352179926217057

Epoch: 6| Step: 4
Training loss: 0.1963544802996275
Validation loss: 2.231107976464271

Epoch: 6| Step: 5
Training loss: 0.07861925185377189
Validation loss: 2.2119983432751478

Epoch: 6| Step: 6
Training loss: 0.10177511188971325
Validation loss: 2.2168771603199766

Epoch: 6| Step: 7
Training loss: 0.09265311620214896
Validation loss: 2.2372407188839825

Epoch: 6| Step: 8
Training loss: 0.13164877144710796
Validation loss: 2.2147952903499615

Epoch: 6| Step: 9
Training loss: 0.10812664324278015
Validation loss: 2.1804177354096503

Epoch: 6| Step: 10
Training loss: 0.102264404296875
Validation loss: 2.1902214466531587

Epoch: 6| Step: 11
Training loss: 0.0821628876736582
Validation loss: 2.206209749411638

Epoch: 6| Step: 12
Training loss: 0.09198777659991864
Validation loss: 2.188050549161704

Epoch: 6| Step: 13
Training loss: 0.14024059420000323
Validation loss: 2.195860406254519

Epoch: 592| Step: 0
Training loss: 0.08669362348533949
Validation loss: 2.1614223255331426

Epoch: 6| Step: 1
Training loss: 0.1394492910162628
Validation loss: 2.162065791317464

Epoch: 6| Step: 2
Training loss: 0.08830834570017264
Validation loss: 2.150228663201778

Epoch: 6| Step: 3
Training loss: 0.1418766047160104
Validation loss: 2.167714969496554

Epoch: 6| Step: 4
Training loss: 0.08867548607518784
Validation loss: 2.1418937753575555

Epoch: 6| Step: 5
Training loss: 0.11621692385601755
Validation loss: 2.131886266655869

Epoch: 6| Step: 6
Training loss: 0.10760620514621211
Validation loss: 2.119933799914289

Epoch: 6| Step: 7
Training loss: 0.11673538892436096
Validation loss: 2.132320695479466

Epoch: 6| Step: 8
Training loss: 0.11500467424378241
Validation loss: 2.1358980486127157

Epoch: 6| Step: 9
Training loss: 0.09551664596304012
Validation loss: 2.1701261878076044

Epoch: 6| Step: 10
Training loss: 0.076167161502255
Validation loss: 2.1492629317151377

Epoch: 6| Step: 11
Training loss: 0.11353878639516776
Validation loss: 2.162049058137191

Epoch: 6| Step: 12
Training loss: 0.1579478995488732
Validation loss: 2.1484900725225913

Epoch: 6| Step: 13
Training loss: 0.08628411724828115
Validation loss: 2.156626202325796

Epoch: 593| Step: 0
Training loss: 0.055633624438272425
Validation loss: 2.183395544341725

Epoch: 6| Step: 1
Training loss: 0.07855675720682687
Validation loss: 2.178458791465899

Epoch: 6| Step: 2
Training loss: 0.06673403790352403
Validation loss: 2.2037955794996145

Epoch: 6| Step: 3
Training loss: 0.14916814874822046
Validation loss: 2.2246954680122775

Epoch: 6| Step: 4
Training loss: 0.07525225749661298
Validation loss: 2.218779475749869

Epoch: 6| Step: 5
Training loss: 0.06924922315926985
Validation loss: 2.2180015339127377

Epoch: 6| Step: 6
Training loss: 0.09469909368015107
Validation loss: 2.229444094547261

Epoch: 6| Step: 7
Training loss: 0.08054816299577883
Validation loss: 2.2408861046100665

Epoch: 6| Step: 8
Training loss: 0.08962601732464064
Validation loss: 2.2456240914399808

Epoch: 6| Step: 9
Training loss: 0.0910745773619239
Validation loss: 2.2317452071660377

Epoch: 6| Step: 10
Training loss: 0.09991507742713267
Validation loss: 2.2471232265249355

Epoch: 6| Step: 11
Training loss: 0.14356567704052892
Validation loss: 2.2328279834774984

Epoch: 6| Step: 12
Training loss: 0.08645030390364455
Validation loss: 2.217924196318047

Epoch: 6| Step: 13
Training loss: 0.03921408299446216
Validation loss: 2.2110482908514584

Epoch: 594| Step: 0
Training loss: 0.0622572206834545
Validation loss: 2.2043535584080165

Epoch: 6| Step: 1
Training loss: 0.12410314506696009
Validation loss: 2.198894293418459

Epoch: 6| Step: 2
Training loss: 0.07890090688234418
Validation loss: 2.187575703144525

Epoch: 6| Step: 3
Training loss: 0.08416142210204275
Validation loss: 2.1868327780086285

Epoch: 6| Step: 4
Training loss: 0.08190322717905284
Validation loss: 2.214348709583283

Epoch: 6| Step: 5
Training loss: 0.1038175758430568
Validation loss: 2.1819292545284865

Epoch: 6| Step: 6
Training loss: 0.10455294206518144
Validation loss: 2.174957891954078

Epoch: 6| Step: 7
Training loss: 0.07681699975175092
Validation loss: 2.1985917986071444

Epoch: 6| Step: 8
Training loss: 0.09158119776454897
Validation loss: 2.187238832930226

Epoch: 6| Step: 9
Training loss: 0.05596481189259592
Validation loss: 2.22435309492073

Epoch: 6| Step: 10
Training loss: 0.15763874993677593
Validation loss: 2.2199760214439905

Epoch: 6| Step: 11
Training loss: 0.14498456539844962
Validation loss: 2.2021311148154594

Epoch: 6| Step: 12
Training loss: 0.10770361107700359
Validation loss: 2.2076993360325434

Epoch: 6| Step: 13
Training loss: 0.06503241837275481
Validation loss: 2.2080687391268805

Epoch: 595| Step: 0
Training loss: 0.09287007970085844
Validation loss: 2.183734609905819

Epoch: 6| Step: 1
Training loss: 0.12214514536701546
Validation loss: 2.2038825902787633

Epoch: 6| Step: 2
Training loss: 0.12201894060637895
Validation loss: 2.2278759711787273

Epoch: 6| Step: 3
Training loss: 0.09359468568674874
Validation loss: 2.205503642512383

Epoch: 6| Step: 4
Training loss: 0.08066154988695996
Validation loss: 2.2209908162360708

Epoch: 6| Step: 5
Training loss: 0.09137125975759397
Validation loss: 2.1898993475523856

Epoch: 6| Step: 6
Training loss: 0.16290612501501472
Validation loss: 2.206868889002252

Epoch: 6| Step: 7
Training loss: 0.04278620503231241
Validation loss: 2.1955663313647653

Epoch: 6| Step: 8
Training loss: 0.09302144280362502
Validation loss: 2.1955822462996593

Epoch: 6| Step: 9
Training loss: 0.06376953008163942
Validation loss: 2.2287840834510835

Epoch: 6| Step: 10
Training loss: 0.07870809985363145
Validation loss: 2.2397954345756164

Epoch: 6| Step: 11
Training loss: 0.09106909609660718
Validation loss: 2.2469161878331176

Epoch: 6| Step: 12
Training loss: 0.09557241154709605
Validation loss: 2.203099670648551

Epoch: 6| Step: 13
Training loss: 0.062434751008588085
Validation loss: 2.1892831276480944

Epoch: 596| Step: 0
Training loss: 0.08889947032387166
Validation loss: 2.191065620845613

Epoch: 6| Step: 1
Training loss: 0.1388623849759959
Validation loss: 2.200743246054864

Epoch: 6| Step: 2
Training loss: 0.1107231567823691
Validation loss: 2.209781527882962

Epoch: 6| Step: 3
Training loss: 0.09393191569208734
Validation loss: 2.1820032111832743

Epoch: 6| Step: 4
Training loss: 0.07925769326476956
Validation loss: 2.1514566498880807

Epoch: 6| Step: 5
Training loss: 0.1515345786124981
Validation loss: 2.1802377443295637

Epoch: 6| Step: 6
Training loss: 0.11898925420584293
Validation loss: 2.178003084981465

Epoch: 6| Step: 7
Training loss: 0.07863928086518952
Validation loss: 2.172586230892739

Epoch: 6| Step: 8
Training loss: 0.12800812682508117
Validation loss: 2.162578545013564

Epoch: 6| Step: 9
Training loss: 0.07556797548519799
Validation loss: 2.1766093423494173

Epoch: 6| Step: 10
Training loss: 0.06375481434248918
Validation loss: 2.1838302019066993

Epoch: 6| Step: 11
Training loss: 0.15370786486878552
Validation loss: 2.201166106377908

Epoch: 6| Step: 12
Training loss: 0.0663155925635876
Validation loss: 2.1661987759862824

Epoch: 6| Step: 13
Training loss: 0.08344667768187566
Validation loss: 2.200502398440931

Epoch: 597| Step: 0
Training loss: 0.06674096656646182
Validation loss: 2.2238632711706576

Epoch: 6| Step: 1
Training loss: 0.12271317388116948
Validation loss: 2.2246429983310883

Epoch: 6| Step: 2
Training loss: 0.0943132161880486
Validation loss: 2.2108775226779316

Epoch: 6| Step: 3
Training loss: 0.09508330722844559
Validation loss: 2.219357791043965

Epoch: 6| Step: 4
Training loss: 0.1220881258365084
Validation loss: 2.2079960241753813

Epoch: 6| Step: 5
Training loss: 0.07729007298483681
Validation loss: 2.1912093067550398

Epoch: 6| Step: 6
Training loss: 0.1068119637616482
Validation loss: 2.1795185864756745

Epoch: 6| Step: 7
Training loss: 0.09803489235686182
Validation loss: 2.170473789507881

Epoch: 6| Step: 8
Training loss: 0.13724680151104787
Validation loss: 2.152981766602556

Epoch: 6| Step: 9
Training loss: 0.08545662984044497
Validation loss: 2.146705464149629

Epoch: 6| Step: 10
Training loss: 0.0945229849867201
Validation loss: 2.149143849411794

Epoch: 6| Step: 11
Training loss: 0.07756328708816454
Validation loss: 2.162667490281691

Epoch: 6| Step: 12
Training loss: 0.14291631096493504
Validation loss: 2.1510737188632256

Epoch: 6| Step: 13
Training loss: 0.08590634550735948
Validation loss: 2.14676188945222

Epoch: 598| Step: 0
Training loss: 0.11591153886247024
Validation loss: 2.1410979690123026

Epoch: 6| Step: 1
Training loss: 0.1166993943217086
Validation loss: 2.1610825114179297

Epoch: 6| Step: 2
Training loss: 0.10186888258066625
Validation loss: 2.1713709186876113

Epoch: 6| Step: 3
Training loss: 0.13141882574299027
Validation loss: 2.164238393324195

Epoch: 6| Step: 4
Training loss: 0.09279049164475285
Validation loss: 2.1927050507016963

Epoch: 6| Step: 5
Training loss: 0.11036368531336871
Validation loss: 2.187606978840309

Epoch: 6| Step: 6
Training loss: 0.13340528115943648
Validation loss: 2.164660416693778

Epoch: 6| Step: 7
Training loss: 0.0585526421509722
Validation loss: 2.1926368719466462

Epoch: 6| Step: 8
Training loss: 0.10784931970825214
Validation loss: 2.1572634607093657

Epoch: 6| Step: 9
Training loss: 0.07484792065099648
Validation loss: 2.1664646242216365

Epoch: 6| Step: 10
Training loss: 0.10362426886513426
Validation loss: 2.1542409079758444

Epoch: 6| Step: 11
Training loss: 0.08339475594553329
Validation loss: 2.144220266976605

Epoch: 6| Step: 12
Training loss: 0.08065624430086278
Validation loss: 2.13336146569097

Epoch: 6| Step: 13
Training loss: 0.07560636825834506
Validation loss: 2.14006133053891

Epoch: 599| Step: 0
Training loss: 0.09270418493583399
Validation loss: 2.143885570668754

Epoch: 6| Step: 1
Training loss: 0.11930452470291818
Validation loss: 2.1252565446207416

Epoch: 6| Step: 2
Training loss: 0.08028845959739823
Validation loss: 2.1130399154669384

Epoch: 6| Step: 3
Training loss: 0.1241406390080285
Validation loss: 2.1621257834235177

Epoch: 6| Step: 4
Training loss: 0.07436118136787155
Validation loss: 2.1513187536178924

Epoch: 6| Step: 5
Training loss: 0.09415063092569359
Validation loss: 2.1567396297907186

Epoch: 6| Step: 6
Training loss: 0.15988214809075565
Validation loss: 2.1700188315595015

Epoch: 6| Step: 7
Training loss: 0.09887157001676802
Validation loss: 2.199095729694147

Epoch: 6| Step: 8
Training loss: 0.13428964731895904
Validation loss: 2.174104080925033

Epoch: 6| Step: 9
Training loss: 0.0978733605720097
Validation loss: 2.200720819331037

Epoch: 6| Step: 10
Training loss: 0.11409993553503532
Validation loss: 2.1988737132585103

Epoch: 6| Step: 11
Training loss: 0.09534920724306425
Validation loss: 2.2152639274315495

Epoch: 6| Step: 12
Training loss: 0.14683441301362748
Validation loss: 2.2320105326466826

Epoch: 6| Step: 13
Training loss: 0.06763545991572678
Validation loss: 2.2221138547893635

Epoch: 600| Step: 0
Training loss: 0.10406578712455332
Validation loss: 2.2131022270581746

Epoch: 6| Step: 1
Training loss: 0.04322704255868044
Validation loss: 2.1882637348998473

Epoch: 6| Step: 2
Training loss: 0.0752473038361878
Validation loss: 2.1810293781664267

Epoch: 6| Step: 3
Training loss: 0.07340146230582834
Validation loss: 2.1670669792452815

Epoch: 6| Step: 4
Training loss: 0.09054182794738398
Validation loss: 2.1302929083527946

Epoch: 6| Step: 5
Training loss: 0.08537372523964648
Validation loss: 2.1578108429214606

Epoch: 6| Step: 6
Training loss: 0.12595157227566478
Validation loss: 2.180766917754386

Epoch: 6| Step: 7
Training loss: 0.10838062552433922
Validation loss: 2.1703960854219693

Epoch: 6| Step: 8
Training loss: 0.08544338206384353
Validation loss: 2.1631188134795254

Epoch: 6| Step: 9
Training loss: 0.08029938577756136
Validation loss: 2.18138520258714

Epoch: 6| Step: 10
Training loss: 0.13379426236036948
Validation loss: 2.177826140935231

Epoch: 6| Step: 11
Training loss: 0.12857274783187067
Validation loss: 2.2043605933219035

Epoch: 6| Step: 12
Training loss: 0.09510866749730493
Validation loss: 2.218961564358611

Epoch: 6| Step: 13
Training loss: 0.14788401460458772
Validation loss: 2.2241097181849714

Epoch: 601| Step: 0
Training loss: 0.11448690075546217
Validation loss: 2.2202560071805926

Epoch: 6| Step: 1
Training loss: 0.06433298010360598
Validation loss: 2.257011660723198

Epoch: 6| Step: 2
Training loss: 0.10059894088839107
Validation loss: 2.2387033353860337

Epoch: 6| Step: 3
Training loss: 0.14020063690423165
Validation loss: 2.2300322340251455

Epoch: 6| Step: 4
Training loss: 0.16904593651875358
Validation loss: 2.2262071781858506

Epoch: 6| Step: 5
Training loss: 0.13017883125503882
Validation loss: 2.220446053761305

Epoch: 6| Step: 6
Training loss: 0.12518760639582288
Validation loss: 2.1610346757857157

Epoch: 6| Step: 7
Training loss: 0.09207671710054138
Validation loss: 2.1703488729194222

Epoch: 6| Step: 8
Training loss: 0.0480026249725042
Validation loss: 2.187334841984567

Epoch: 6| Step: 9
Training loss: 0.09499406894879017
Validation loss: 2.1594069217690723

Epoch: 6| Step: 10
Training loss: 0.0862573987700231
Validation loss: 2.174880607401131

Epoch: 6| Step: 11
Training loss: 0.067291031402408
Validation loss: 2.181141308848628

Epoch: 6| Step: 12
Training loss: 0.11446257933017856
Validation loss: 2.193980605617075

Epoch: 6| Step: 13
Training loss: 0.07489285079403031
Validation loss: 2.1497988602726084

Epoch: 602| Step: 0
Training loss: 0.11469068609848093
Validation loss: 2.156416008140756

Epoch: 6| Step: 1
Training loss: 0.09531889878353257
Validation loss: 2.1381360446483897

Epoch: 6| Step: 2
Training loss: 0.11011067827573165
Validation loss: 2.156680351150416

Epoch: 6| Step: 3
Training loss: 0.0641221921189371
Validation loss: 2.1740009534836195

Epoch: 6| Step: 4
Training loss: 0.11388910337858561
Validation loss: 2.1876932331297034

Epoch: 6| Step: 5
Training loss: 0.05615946268482696
Validation loss: 2.1740817809169752

Epoch: 6| Step: 6
Training loss: 0.09027571082296182
Validation loss: 2.170083881515065

Epoch: 6| Step: 7
Training loss: 0.0823233150735764
Validation loss: 2.1828285508608727

Epoch: 6| Step: 8
Training loss: 0.09586865356887364
Validation loss: 2.196232351018493

Epoch: 6| Step: 9
Training loss: 0.12393894847060964
Validation loss: 2.2144789836569223

Epoch: 6| Step: 10
Training loss: 0.09258054456486481
Validation loss: 2.205793159245132

Epoch: 6| Step: 11
Training loss: 0.0687698032294683
Validation loss: 2.2225330666906724

Epoch: 6| Step: 12
Training loss: 0.07223073658453326
Validation loss: 2.219936499026959

Epoch: 6| Step: 13
Training loss: 0.07729242866625473
Validation loss: 2.2020104349038556

Epoch: 603| Step: 0
Training loss: 0.054097914314522155
Validation loss: 2.201102023924395

Epoch: 6| Step: 1
Training loss: 0.0994968152327253
Validation loss: 2.1924816580790574

Epoch: 6| Step: 2
Training loss: 0.05591512204131474
Validation loss: 2.1886820557133344

Epoch: 6| Step: 3
Training loss: 0.1047159455213275
Validation loss: 2.1925036966925475

Epoch: 6| Step: 4
Training loss: 0.07334560404682383
Validation loss: 2.1555234955232843

Epoch: 6| Step: 5
Training loss: 0.13677109669875243
Validation loss: 2.1956801597270674

Epoch: 6| Step: 6
Training loss: 0.1342627708156551
Validation loss: 2.1811758373198167

Epoch: 6| Step: 7
Training loss: 0.08137874856275391
Validation loss: 2.180829556428207

Epoch: 6| Step: 8
Training loss: 0.06375422272066941
Validation loss: 2.2018677006693133

Epoch: 6| Step: 9
Training loss: 0.09522720647906008
Validation loss: 2.182797086902062

Epoch: 6| Step: 10
Training loss: 0.0657320119368664
Validation loss: 2.1910282259574276

Epoch: 6| Step: 11
Training loss: 0.07711965893323319
Validation loss: 2.20641837518847

Epoch: 6| Step: 12
Training loss: 0.11518858953696491
Validation loss: 2.179876168728504

Epoch: 6| Step: 13
Training loss: 0.06743141163228437
Validation loss: 2.2066891251779253

Epoch: 604| Step: 0
Training loss: 0.12333480510553067
Validation loss: 2.218316238711087

Epoch: 6| Step: 1
Training loss: 0.07132252796040339
Validation loss: 2.197363068492495

Epoch: 6| Step: 2
Training loss: 0.06741920124423498
Validation loss: 2.220006779476798

Epoch: 6| Step: 3
Training loss: 0.11898380652609347
Validation loss: 2.2211211754031868

Epoch: 6| Step: 4
Training loss: 0.06707574496322061
Validation loss: 2.19534571723271

Epoch: 6| Step: 5
Training loss: 0.11385351363928688
Validation loss: 2.180049865384155

Epoch: 6| Step: 6
Training loss: 0.06264812083794012
Validation loss: 2.194308009132998

Epoch: 6| Step: 7
Training loss: 0.09294591230494072
Validation loss: 2.18176790433259

Epoch: 6| Step: 8
Training loss: 0.0890230656206399
Validation loss: 2.206220620000469

Epoch: 6| Step: 9
Training loss: 0.1161261056566624
Validation loss: 2.1841820488588284

Epoch: 6| Step: 10
Training loss: 0.08270983787800862
Validation loss: 2.177860149877407

Epoch: 6| Step: 11
Training loss: 0.08167166462067095
Validation loss: 2.2007039327378335

Epoch: 6| Step: 12
Training loss: 0.09471298395740321
Validation loss: 2.193813539317613

Epoch: 6| Step: 13
Training loss: 0.07301845074007592
Validation loss: 2.211779759926955

Epoch: 605| Step: 0
Training loss: 0.0757723749017235
Validation loss: 2.2061539140626363

Epoch: 6| Step: 1
Training loss: 0.09148767830205483
Validation loss: 2.213009124529418

Epoch: 6| Step: 2
Training loss: 0.13179213891284952
Validation loss: 2.2081664001591195

Epoch: 6| Step: 3
Training loss: 0.053908522184832025
Validation loss: 2.2020157792827333

Epoch: 6| Step: 4
Training loss: 0.09075071888368308
Validation loss: 2.198497897928585

Epoch: 6| Step: 5
Training loss: 0.08047607733411112
Validation loss: 2.2069595387698655

Epoch: 6| Step: 6
Training loss: 0.082702135598329
Validation loss: 2.1888329471894847

Epoch: 6| Step: 7
Training loss: 0.06681277855394853
Validation loss: 2.1926377734030384

Epoch: 6| Step: 8
Training loss: 0.12871726951016285
Validation loss: 2.172603505949147

Epoch: 6| Step: 9
Training loss: 0.05547101232790991
Validation loss: 2.1887833178304583

Epoch: 6| Step: 10
Training loss: 0.09303835639266048
Validation loss: 2.200573434702825

Epoch: 6| Step: 11
Training loss: 0.11892645769432775
Validation loss: 2.1786134534527304

Epoch: 6| Step: 12
Training loss: 0.07420232239668888
Validation loss: 2.172991059450243

Epoch: 6| Step: 13
Training loss: 0.039276770680504065
Validation loss: 2.1768379282620187

Epoch: 606| Step: 0
Training loss: 0.10577474903065871
Validation loss: 2.182659287858883

Epoch: 6| Step: 1
Training loss: 0.10764210839951456
Validation loss: 2.1524261315316844

Epoch: 6| Step: 2
Training loss: 0.09064176400285553
Validation loss: 2.1592833168152095

Epoch: 6| Step: 3
Training loss: 0.09650601094245145
Validation loss: 2.15599891564431

Epoch: 6| Step: 4
Training loss: 0.13378044434794706
Validation loss: 2.1551168388143185

Epoch: 6| Step: 5
Training loss: 0.0959128203939642
Validation loss: 2.1817965713276273

Epoch: 6| Step: 6
Training loss: 0.09179226884039784
Validation loss: 2.156760405175285

Epoch: 6| Step: 7
Training loss: 0.08833722981295163
Validation loss: 2.1685137597916486

Epoch: 6| Step: 8
Training loss: 0.04875999943413384
Validation loss: 2.157422020220791

Epoch: 6| Step: 9
Training loss: 0.0681320907900982
Validation loss: 2.15381200926287

Epoch: 6| Step: 10
Training loss: 0.10779488132782444
Validation loss: 2.1552195370239087

Epoch: 6| Step: 11
Training loss: 0.06970890566912886
Validation loss: 2.1711683985194594

Epoch: 6| Step: 12
Training loss: 0.09922622404708309
Validation loss: 2.170502780477256

Epoch: 6| Step: 13
Training loss: 0.0626732540839591
Validation loss: 2.1759745942239612

Epoch: 607| Step: 0
Training loss: 0.08104482269005246
Validation loss: 2.197561898988379

Epoch: 6| Step: 1
Training loss: 0.07062494871888789
Validation loss: 2.210529300870696

Epoch: 6| Step: 2
Training loss: 0.05877100637137003
Validation loss: 2.2111531393832293

Epoch: 6| Step: 3
Training loss: 0.06831765264019435
Validation loss: 2.22722883488685

Epoch: 6| Step: 4
Training loss: 0.07938794112215841
Validation loss: 2.1884957635693403

Epoch: 6| Step: 5
Training loss: 0.04948005811406905
Validation loss: 2.1918786006503885

Epoch: 6| Step: 6
Training loss: 0.11210545406728921
Validation loss: 2.2333549708605553

Epoch: 6| Step: 7
Training loss: 0.12249025209967038
Validation loss: 2.211166190861641

Epoch: 6| Step: 8
Training loss: 0.09841378130580761
Validation loss: 2.2126750674703897

Epoch: 6| Step: 9
Training loss: 0.06492264196881592
Validation loss: 2.224483267711908

Epoch: 6| Step: 10
Training loss: 0.09753569791564658
Validation loss: 2.205449485246419

Epoch: 6| Step: 11
Training loss: 0.06317148623251333
Validation loss: 2.2315619128681017

Epoch: 6| Step: 12
Training loss: 0.09450449919712689
Validation loss: 2.1876423755727568

Epoch: 6| Step: 13
Training loss: 0.0403599326212985
Validation loss: 2.2242765262168898

Epoch: 608| Step: 0
Training loss: 0.0634400996605707
Validation loss: 2.20500877785272

Epoch: 6| Step: 1
Training loss: 0.07123188116243831
Validation loss: 2.203487672716897

Epoch: 6| Step: 2
Training loss: 0.08346540879924946
Validation loss: 2.1960488260610864

Epoch: 6| Step: 3
Training loss: 0.07612978249064724
Validation loss: 2.204798674550588

Epoch: 6| Step: 4
Training loss: 0.15158957480431492
Validation loss: 2.2081349501036693

Epoch: 6| Step: 5
Training loss: 0.06438043136276186
Validation loss: 2.205214393516679

Epoch: 6| Step: 6
Training loss: 0.09497797430686253
Validation loss: 2.2233000968497554

Epoch: 6| Step: 7
Training loss: 0.05966847766028615
Validation loss: 2.2006194663741048

Epoch: 6| Step: 8
Training loss: 0.11682271607742176
Validation loss: 2.2075425758195744

Epoch: 6| Step: 9
Training loss: 0.09137245229921419
Validation loss: 2.1898832479095054

Epoch: 6| Step: 10
Training loss: 0.0701015473564197
Validation loss: 2.2156628662439237

Epoch: 6| Step: 11
Training loss: 0.08525502345083955
Validation loss: 2.202019356941598

Epoch: 6| Step: 12
Training loss: 0.09027090324103046
Validation loss: 2.197143526210137

Epoch: 6| Step: 13
Training loss: 0.04130158618576285
Validation loss: 2.2160629681707564

Epoch: 609| Step: 0
Training loss: 0.07400330531444388
Validation loss: 2.211857359882701

Epoch: 6| Step: 1
Training loss: 0.10058804389451738
Validation loss: 2.1980808276260575

Epoch: 6| Step: 2
Training loss: 0.1062372562886248
Validation loss: 2.207537075269265

Epoch: 6| Step: 3
Training loss: 0.10086865183733716
Validation loss: 2.1880618169400106

Epoch: 6| Step: 4
Training loss: 0.07424145903255544
Validation loss: 2.1998841428361287

Epoch: 6| Step: 5
Training loss: 0.10956929184273365
Validation loss: 2.205357793455365

Epoch: 6| Step: 6
Training loss: 0.12803794560884194
Validation loss: 2.1885086769368454

Epoch: 6| Step: 7
Training loss: 0.09257039387931405
Validation loss: 2.2073543241335805

Epoch: 6| Step: 8
Training loss: 0.07238807163494514
Validation loss: 2.2220026150842522

Epoch: 6| Step: 9
Training loss: 0.059356489401825877
Validation loss: 2.219138470059946

Epoch: 6| Step: 10
Training loss: 0.10741035226230429
Validation loss: 2.200880500499966

Epoch: 6| Step: 11
Training loss: 0.10421049169680556
Validation loss: 2.2276308315805577

Epoch: 6| Step: 12
Training loss: 0.06029160006816749
Validation loss: 2.2195450985727807

Epoch: 6| Step: 13
Training loss: 0.17409444616819134
Validation loss: 2.222218487806498

Epoch: 610| Step: 0
Training loss: 0.08535995725816832
Validation loss: 2.2178232706281626

Epoch: 6| Step: 1
Training loss: 0.049699539095838526
Validation loss: 2.201476099768098

Epoch: 6| Step: 2
Training loss: 0.06091006621250947
Validation loss: 2.2247931343570193

Epoch: 6| Step: 3
Training loss: 0.14591185905074266
Validation loss: 2.212880427832273

Epoch: 6| Step: 4
Training loss: 0.09486844556706724
Validation loss: 2.1871919083921125

Epoch: 6| Step: 5
Training loss: 0.12208876661046111
Validation loss: 2.2191726938225544

Epoch: 6| Step: 6
Training loss: 0.06217333990654386
Validation loss: 2.2336229796634535

Epoch: 6| Step: 7
Training loss: 0.09423151140158412
Validation loss: 2.2718434314582874

Epoch: 6| Step: 8
Training loss: 0.08080616734556753
Validation loss: 2.236135248798582

Epoch: 6| Step: 9
Training loss: 0.08298693282122026
Validation loss: 2.2469804069684565

Epoch: 6| Step: 10
Training loss: 0.08039053592547199
Validation loss: 2.2327153566124456

Epoch: 6| Step: 11
Training loss: 0.11446868966413694
Validation loss: 2.226766181845014

Epoch: 6| Step: 12
Training loss: 0.12081048890984246
Validation loss: 2.249404892901881

Epoch: 6| Step: 13
Training loss: 0.054390049395327725
Validation loss: 2.218683156576998

Epoch: 611| Step: 0
Training loss: 0.054812157278881585
Validation loss: 2.2127841919197193

Epoch: 6| Step: 1
Training loss: 0.07585445621368075
Validation loss: 2.229813286932842

Epoch: 6| Step: 2
Training loss: 0.04728182444125792
Validation loss: 2.2209011224142974

Epoch: 6| Step: 3
Training loss: 0.07746031050589423
Validation loss: 2.222847948202835

Epoch: 6| Step: 4
Training loss: 0.07318293081736171
Validation loss: 2.1926763486079763

Epoch: 6| Step: 5
Training loss: 0.1679973688806549
Validation loss: 2.218435018719318

Epoch: 6| Step: 6
Training loss: 0.05860507577473107
Validation loss: 2.198120341807226

Epoch: 6| Step: 7
Training loss: 0.09286667505416372
Validation loss: 2.21311933412992

Epoch: 6| Step: 8
Training loss: 0.06775964189776024
Validation loss: 2.1982495755103963

Epoch: 6| Step: 9
Training loss: 0.07002702683533321
Validation loss: 2.1602184366291906

Epoch: 6| Step: 10
Training loss: 0.051692374716402034
Validation loss: 2.213657382399176

Epoch: 6| Step: 11
Training loss: 0.05800145319878546
Validation loss: 2.22067250302367

Epoch: 6| Step: 12
Training loss: 0.0806468966140183
Validation loss: 2.204168605037891

Epoch: 6| Step: 13
Training loss: 0.100328690538415
Validation loss: 2.219743910715837

Epoch: 612| Step: 0
Training loss: 0.054053484386833495
Validation loss: 2.2127386531382705

Epoch: 6| Step: 1
Training loss: 0.06615113593171049
Validation loss: 2.2063466010467745

Epoch: 6| Step: 2
Training loss: 0.12689131185596791
Validation loss: 2.2264935341563334

Epoch: 6| Step: 3
Training loss: 0.07294379805273297
Validation loss: 2.2048909058346378

Epoch: 6| Step: 4
Training loss: 0.12043630651695282
Validation loss: 2.2281035056889102

Epoch: 6| Step: 5
Training loss: 0.07373543905721962
Validation loss: 2.2301591506331166

Epoch: 6| Step: 6
Training loss: 0.08978095659081235
Validation loss: 2.210360744700206

Epoch: 6| Step: 7
Training loss: 0.05832857087859298
Validation loss: 2.217836429656116

Epoch: 6| Step: 8
Training loss: 0.06888159463252981
Validation loss: 2.238257530587962

Epoch: 6| Step: 9
Training loss: 0.06016076128318367
Validation loss: 2.2109108631966357

Epoch: 6| Step: 10
Training loss: 0.08639030213225829
Validation loss: 2.1975610298830985

Epoch: 6| Step: 11
Training loss: 0.0674457497997373
Validation loss: 2.191664678107235

Epoch: 6| Step: 12
Training loss: 0.059158882097166944
Validation loss: 2.2007083291357086

Epoch: 6| Step: 13
Training loss: 0.0995702058784809
Validation loss: 2.2034439930015397

Epoch: 613| Step: 0
Training loss: 0.057276880548973355
Validation loss: 2.1859415781778124

Epoch: 6| Step: 1
Training loss: 0.051046773089857986
Validation loss: 2.1892403566205787

Epoch: 6| Step: 2
Training loss: 0.13431135960525692
Validation loss: 2.1759875079692312

Epoch: 6| Step: 3
Training loss: 0.0503652987672617
Validation loss: 2.177117574471271

Epoch: 6| Step: 4
Training loss: 0.07689440830173405
Validation loss: 2.202208599009752

Epoch: 6| Step: 5
Training loss: 0.09085314680124222
Validation loss: 2.206629525562838

Epoch: 6| Step: 6
Training loss: 0.08599293340628245
Validation loss: 2.2074666434393744

Epoch: 6| Step: 7
Training loss: 0.09454725933863667
Validation loss: 2.208980820807471

Epoch: 6| Step: 8
Training loss: 0.08356230046142173
Validation loss: 2.2231678912594814

Epoch: 6| Step: 9
Training loss: 0.06221331470320893
Validation loss: 2.1978455682532227

Epoch: 6| Step: 10
Training loss: 0.12858626357774872
Validation loss: 2.1995328186683336

Epoch: 6| Step: 11
Training loss: 0.07727480450054419
Validation loss: 2.2005551699523513

Epoch: 6| Step: 12
Training loss: 0.0787398167016809
Validation loss: 2.221644494391993

Epoch: 6| Step: 13
Training loss: 0.05399816398029776
Validation loss: 2.2230708682072944

Epoch: 614| Step: 0
Training loss: 0.10738831776216676
Validation loss: 2.205027828858051

Epoch: 6| Step: 1
Training loss: 0.08176986740335511
Validation loss: 2.240260204261373

Epoch: 6| Step: 2
Training loss: 0.07756192125028433
Validation loss: 2.2227830168555087

Epoch: 6| Step: 3
Training loss: 0.05518657021830128
Validation loss: 2.233480382102645

Epoch: 6| Step: 4
Training loss: 0.11305844659640527
Validation loss: 2.1997763549884275

Epoch: 6| Step: 5
Training loss: 0.08144894335678574
Validation loss: 2.215111179790671

Epoch: 6| Step: 6
Training loss: 0.049654547332658984
Validation loss: 2.192828528906026

Epoch: 6| Step: 7
Training loss: 0.08191738855015404
Validation loss: 2.202311455563767

Epoch: 6| Step: 8
Training loss: 0.09385283115500877
Validation loss: 2.187124538281705

Epoch: 6| Step: 9
Training loss: 0.06745746872006965
Validation loss: 2.1858181146063345

Epoch: 6| Step: 10
Training loss: 0.05574157404411667
Validation loss: 2.1766746393699785

Epoch: 6| Step: 11
Training loss: 0.11560772367232018
Validation loss: 2.1874265485582054

Epoch: 6| Step: 12
Training loss: 0.08951201561835492
Validation loss: 2.1797288989297976

Epoch: 6| Step: 13
Training loss: 0.08519874920881144
Validation loss: 2.1645714180041904

Epoch: 615| Step: 0
Training loss: 0.09040454325431309
Validation loss: 2.194483801794835

Epoch: 6| Step: 1
Training loss: 0.0782781024640814
Validation loss: 2.158669403061491

Epoch: 6| Step: 2
Training loss: 0.06422562981737917
Validation loss: 2.163161055111656

Epoch: 6| Step: 3
Training loss: 0.08039377096543317
Validation loss: 2.16757099582864

Epoch: 6| Step: 4
Training loss: 0.08120937409210292
Validation loss: 2.174223897322977

Epoch: 6| Step: 5
Training loss: 0.11732224426716414
Validation loss: 2.2016528303364855

Epoch: 6| Step: 6
Training loss: 0.0729662242152066
Validation loss: 2.179663873359853

Epoch: 6| Step: 7
Training loss: 0.07487588076777969
Validation loss: 2.200152541537372

Epoch: 6| Step: 8
Training loss: 0.07419220550079285
Validation loss: 2.184462001978062

Epoch: 6| Step: 9
Training loss: 0.11821143721798277
Validation loss: 2.21848280258395

Epoch: 6| Step: 10
Training loss: 0.063007410974045
Validation loss: 2.2404712375444076

Epoch: 6| Step: 11
Training loss: 0.07043046460011229
Validation loss: 2.2225654595474524

Epoch: 6| Step: 12
Training loss: 0.08430646523623438
Validation loss: 2.192318135357711

Epoch: 6| Step: 13
Training loss: 0.127871966262155
Validation loss: 2.2049340639088935

Epoch: 616| Step: 0
Training loss: 0.08602234596721904
Validation loss: 2.1963033217033425

Epoch: 6| Step: 1
Training loss: 0.07859257609019646
Validation loss: 2.210679263004094

Epoch: 6| Step: 2
Training loss: 0.11778296737324695
Validation loss: 2.1848416044802774

Epoch: 6| Step: 3
Training loss: 0.06637728283704702
Validation loss: 2.172618033882057

Epoch: 6| Step: 4
Training loss: 0.1120415715127576
Validation loss: 2.1368554919219838

Epoch: 6| Step: 5
Training loss: 0.11635847503403207
Validation loss: 2.1586890292870207

Epoch: 6| Step: 6
Training loss: 0.07528699203004276
Validation loss: 2.161793559874463

Epoch: 6| Step: 7
Training loss: 0.08037426897082847
Validation loss: 2.191897577472024

Epoch: 6| Step: 8
Training loss: 0.08068740024512468
Validation loss: 2.185516203250754

Epoch: 6| Step: 9
Training loss: 0.07442972351338419
Validation loss: 2.1893901329415297

Epoch: 6| Step: 10
Training loss: 0.07163197205140241
Validation loss: 2.1946643831236585

Epoch: 6| Step: 11
Training loss: 0.12369967802366441
Validation loss: 2.2044939413403957

Epoch: 6| Step: 12
Training loss: 0.06143385367121117
Validation loss: 2.2143646316383063

Epoch: 6| Step: 13
Training loss: 0.13295331670397828
Validation loss: 2.207133506056209

Epoch: 617| Step: 0
Training loss: 0.09304989230935302
Validation loss: 2.200529690150838

Epoch: 6| Step: 1
Training loss: 0.08331935145632675
Validation loss: 2.2083449374045143

Epoch: 6| Step: 2
Training loss: 0.053307767062885245
Validation loss: 2.2222473851525972

Epoch: 6| Step: 3
Training loss: 0.11583099846650757
Validation loss: 2.2100470814691584

Epoch: 6| Step: 4
Training loss: 0.10128798431634717
Validation loss: 2.190108815331721

Epoch: 6| Step: 5
Training loss: 0.07619626926176186
Validation loss: 2.20088907301288

Epoch: 6| Step: 6
Training loss: 0.09235579194301692
Validation loss: 2.217921844113464

Epoch: 6| Step: 7
Training loss: 0.11385070377210026
Validation loss: 2.218754744246623

Epoch: 6| Step: 8
Training loss: 0.07719455921754123
Validation loss: 2.215363201501489

Epoch: 6| Step: 9
Training loss: 0.10648705600153845
Validation loss: 2.2324555448799828

Epoch: 6| Step: 10
Training loss: 0.07785880514966399
Validation loss: 2.206847233151534

Epoch: 6| Step: 11
Training loss: 0.06515704828569177
Validation loss: 2.2432731066087284

Epoch: 6| Step: 12
Training loss: 0.05812675422795163
Validation loss: 2.238057034875654

Epoch: 6| Step: 13
Training loss: 0.046722337360185245
Validation loss: 2.2099025612519116

Epoch: 618| Step: 0
Training loss: 0.07225379331490929
Validation loss: 2.219870380782955

Epoch: 6| Step: 1
Training loss: 0.11154896599289503
Validation loss: 2.2319938971393807

Epoch: 6| Step: 2
Training loss: 0.0845712874226396
Validation loss: 2.222962674566496

Epoch: 6| Step: 3
Training loss: 0.12019311629536869
Validation loss: 2.2273817315802145

Epoch: 6| Step: 4
Training loss: 0.0985707238675444
Validation loss: 2.200143910806969

Epoch: 6| Step: 5
Training loss: 0.1096176028409284
Validation loss: 2.1864134121700105

Epoch: 6| Step: 6
Training loss: 0.05711244484534432
Validation loss: 2.186595557496255

Epoch: 6| Step: 7
Training loss: 0.0838980341819122
Validation loss: 2.179845345448991

Epoch: 6| Step: 8
Training loss: 0.0956525523020311
Validation loss: 2.1893818374138316

Epoch: 6| Step: 9
Training loss: 0.08126713590385426
Validation loss: 2.1726406822542588

Epoch: 6| Step: 10
Training loss: 0.07148573149764618
Validation loss: 2.201398285843711

Epoch: 6| Step: 11
Training loss: 0.086236514811605
Validation loss: 2.1853684888439533

Epoch: 6| Step: 12
Training loss: 0.09187313726703711
Validation loss: 2.200010120251107

Epoch: 6| Step: 13
Training loss: 0.08817319745345122
Validation loss: 2.2020809597529927

Epoch: 619| Step: 0
Training loss: 0.059648675265459736
Validation loss: 2.192599602071062

Epoch: 6| Step: 1
Training loss: 0.132265986055083
Validation loss: 2.1842878175901013

Epoch: 6| Step: 2
Training loss: 0.06216958369543317
Validation loss: 2.2077358429736953

Epoch: 6| Step: 3
Training loss: 0.06146934000388087
Validation loss: 2.2195483291886595

Epoch: 6| Step: 4
Training loss: 0.07635469993094572
Validation loss: 2.2518648249573157

Epoch: 6| Step: 5
Training loss: 0.06462550231832448
Validation loss: 2.2365805418666356

Epoch: 6| Step: 6
Training loss: 0.07917709629578332
Validation loss: 2.2286366118211234

Epoch: 6| Step: 7
Training loss: 0.0892082001349393
Validation loss: 2.2079595871377364

Epoch: 6| Step: 8
Training loss: 0.07787080179642446
Validation loss: 2.2420568151907707

Epoch: 6| Step: 9
Training loss: 0.1167365497271143
Validation loss: 2.2570606729529827

Epoch: 6| Step: 10
Training loss: 0.12040291120106288
Validation loss: 2.2234561283300116

Epoch: 6| Step: 11
Training loss: 0.08758150949157273
Validation loss: 2.2379240772444007

Epoch: 6| Step: 12
Training loss: 0.08636038941087294
Validation loss: 2.221321010978112

Epoch: 6| Step: 13
Training loss: 0.09331504934677629
Validation loss: 2.2180671270759658

Epoch: 620| Step: 0
Training loss: 0.05675370339984811
Validation loss: 2.2141395825854695

Epoch: 6| Step: 1
Training loss: 0.05932178206352357
Validation loss: 2.1992815269894694

Epoch: 6| Step: 2
Training loss: 0.10238294979116817
Validation loss: 2.191484865586581

Epoch: 6| Step: 3
Training loss: 0.08686451088752536
Validation loss: 2.188730945062992

Epoch: 6| Step: 4
Training loss: 0.09389496066582484
Validation loss: 2.1941972384924555

Epoch: 6| Step: 5
Training loss: 0.07499194822204676
Validation loss: 2.170798356419607

Epoch: 6| Step: 6
Training loss: 0.10715224934110314
Validation loss: 2.183797715206608

Epoch: 6| Step: 7
Training loss: 0.11136658322141246
Validation loss: 2.1778243116343763

Epoch: 6| Step: 8
Training loss: 0.07227492594791836
Validation loss: 2.177848967631963

Epoch: 6| Step: 9
Training loss: 0.08486504733988232
Validation loss: 2.165069730686704

Epoch: 6| Step: 10
Training loss: 0.06452872437621752
Validation loss: 2.2026541451177932

Epoch: 6| Step: 11
Training loss: 0.06848416518523662
Validation loss: 2.1473833766505512

Epoch: 6| Step: 12
Training loss: 0.07507617913680817
Validation loss: 2.16830024198868

Epoch: 6| Step: 13
Training loss: 0.09255516576365677
Validation loss: 2.171576164734722

Epoch: 621| Step: 0
Training loss: 0.06590355962871086
Validation loss: 2.1710218676668163

Epoch: 6| Step: 1
Training loss: 0.0612580958010653
Validation loss: 2.18986294422093

Epoch: 6| Step: 2
Training loss: 0.10107852631756221
Validation loss: 2.1938573634489402

Epoch: 6| Step: 3
Training loss: 0.08028704152074327
Validation loss: 2.193306849972122

Epoch: 6| Step: 4
Training loss: 0.08656494875656463
Validation loss: 2.1921929409018723

Epoch: 6| Step: 5
Training loss: 0.07148603114309812
Validation loss: 2.2262115760397485

Epoch: 6| Step: 6
Training loss: 0.0792667406824401
Validation loss: 2.2142926988486327

Epoch: 6| Step: 7
Training loss: 0.06136373955785378
Validation loss: 2.2230761135217105

Epoch: 6| Step: 8
Training loss: 0.08639701267467682
Validation loss: 2.1995886111330516

Epoch: 6| Step: 9
Training loss: 0.10400366447313171
Validation loss: 2.2118049919033385

Epoch: 6| Step: 10
Training loss: 0.06822704381345988
Validation loss: 2.206740637545272

Epoch: 6| Step: 11
Training loss: 0.07934212603208592
Validation loss: 2.239177283765679

Epoch: 6| Step: 12
Training loss: 0.0768677155214558
Validation loss: 2.1999530438103987

Epoch: 6| Step: 13
Training loss: 0.07746364086702796
Validation loss: 2.211153623438282

Epoch: 622| Step: 0
Training loss: 0.07316132213961585
Validation loss: 2.2087144849741587

Epoch: 6| Step: 1
Training loss: 0.12461555489549296
Validation loss: 2.1883979829344202

Epoch: 6| Step: 2
Training loss: 0.10907443505922737
Validation loss: 2.2023606258358157

Epoch: 6| Step: 3
Training loss: 0.07657816322830077
Validation loss: 2.200879999625158

Epoch: 6| Step: 4
Training loss: 0.10780226375526523
Validation loss: 2.174684557106959

Epoch: 6| Step: 5
Training loss: 0.08391750246033935
Validation loss: 2.183469592225167

Epoch: 6| Step: 6
Training loss: 0.07823794664344427
Validation loss: 2.1577191631836956

Epoch: 6| Step: 7
Training loss: 0.0481173181130999
Validation loss: 2.180188221512366

Epoch: 6| Step: 8
Training loss: 0.08275583111917213
Validation loss: 2.1553512312312426

Epoch: 6| Step: 9
Training loss: 0.07280749389216389
Validation loss: 2.170514783062252

Epoch: 6| Step: 10
Training loss: 0.11796609199763149
Validation loss: 2.156526388223535

Epoch: 6| Step: 11
Training loss: 0.0545315135714438
Validation loss: 2.1556217264514426

Epoch: 6| Step: 12
Training loss: 0.10890544850014813
Validation loss: 2.1901632629742553

Epoch: 6| Step: 13
Training loss: 0.06877276222593429
Validation loss: 2.1683530653656926

Epoch: 623| Step: 0
Training loss: 0.10652928146430174
Validation loss: 2.1782958790230316

Epoch: 6| Step: 1
Training loss: 0.08014646382109057
Validation loss: 2.1791386778760735

Epoch: 6| Step: 2
Training loss: 0.11098967520705379
Validation loss: 2.180582606706029

Epoch: 6| Step: 3
Training loss: 0.09856279645226936
Validation loss: 2.1824575749725126

Epoch: 6| Step: 4
Training loss: 0.09354082255665826
Validation loss: 2.187218996976157

Epoch: 6| Step: 5
Training loss: 0.10016832415782456
Validation loss: 2.1768097770157375

Epoch: 6| Step: 6
Training loss: 0.1085508752478118
Validation loss: 2.174975082755438

Epoch: 6| Step: 7
Training loss: 0.09107236853349553
Validation loss: 2.18767502314539

Epoch: 6| Step: 8
Training loss: 0.08288191054733735
Validation loss: 2.2067176795736825

Epoch: 6| Step: 9
Training loss: 0.0707506528515063
Validation loss: 2.200505683226888

Epoch: 6| Step: 10
Training loss: 0.08370637904406239
Validation loss: 2.212230847177218

Epoch: 6| Step: 11
Training loss: 0.09216175204694901
Validation loss: 2.220054677321147

Epoch: 6| Step: 12
Training loss: 0.07837351373848146
Validation loss: 2.2139582674923055

Epoch: 6| Step: 13
Training loss: 0.07201155577936813
Validation loss: 2.19960263565985

Epoch: 624| Step: 0
Training loss: 0.052617692339626904
Validation loss: 2.1856717358254607

Epoch: 6| Step: 1
Training loss: 0.0702787722385739
Validation loss: 2.1847990844415275

Epoch: 6| Step: 2
Training loss: 0.07654955654796815
Validation loss: 2.181790779090416

Epoch: 6| Step: 3
Training loss: 0.06440416918807716
Validation loss: 2.167688307157381

Epoch: 6| Step: 4
Training loss: 0.0562793415088599
Validation loss: 2.1659820822418916

Epoch: 6| Step: 5
Training loss: 0.10908848411304774
Validation loss: 2.1600707790336706

Epoch: 6| Step: 6
Training loss: 0.05488135685466655
Validation loss: 2.1585273160275626

Epoch: 6| Step: 7
Training loss: 0.1008108642596779
Validation loss: 2.1368374959594094

Epoch: 6| Step: 8
Training loss: 0.09822888331643773
Validation loss: 2.161107463406362

Epoch: 6| Step: 9
Training loss: 0.11735992462391114
Validation loss: 2.159117663304518

Epoch: 6| Step: 10
Training loss: 0.08022034912963745
Validation loss: 2.131224115811331

Epoch: 6| Step: 11
Training loss: 0.060651331441969686
Validation loss: 2.149233441920604

Epoch: 6| Step: 12
Training loss: 0.06939244989504996
Validation loss: 2.1698215421143323

Epoch: 6| Step: 13
Training loss: 0.17455257050757222
Validation loss: 2.2082368357914866

Epoch: 625| Step: 0
Training loss: 0.08114962016652541
Validation loss: 2.191933225382011

Epoch: 6| Step: 1
Training loss: 0.1656416889095693
Validation loss: 2.2274776734639525

Epoch: 6| Step: 2
Training loss: 0.07836363823609092
Validation loss: 2.2055673983157043

Epoch: 6| Step: 3
Training loss: 0.051630340004998734
Validation loss: 2.2314326145779027

Epoch: 6| Step: 4
Training loss: 0.09647079982315977
Validation loss: 2.192551220206832

Epoch: 6| Step: 5
Training loss: 0.07964698518904156
Validation loss: 2.1669668714574564

Epoch: 6| Step: 6
Training loss: 0.09001159538635056
Validation loss: 2.1779110522351557

Epoch: 6| Step: 7
Training loss: 0.05602747675413074
Validation loss: 2.188040112032975

Epoch: 6| Step: 8
Training loss: 0.09497091396278964
Validation loss: 2.161503879518446

Epoch: 6| Step: 9
Training loss: 0.06897805087736619
Validation loss: 2.164826520028196

Epoch: 6| Step: 10
Training loss: 0.10752605241754055
Validation loss: 2.1600741193691166

Epoch: 6| Step: 11
Training loss: 0.056840500779503526
Validation loss: 2.174610225409029

Epoch: 6| Step: 12
Training loss: 0.06805710380069253
Validation loss: 2.1539006518005177

Epoch: 6| Step: 13
Training loss: 0.13940032178352152
Validation loss: 2.170347710607182

Epoch: 626| Step: 0
Training loss: 0.07825322357597463
Validation loss: 2.1510165160752583

Epoch: 6| Step: 1
Training loss: 0.09185179629843235
Validation loss: 2.178261559703797

Epoch: 6| Step: 2
Training loss: 0.08101985941482441
Validation loss: 2.2009028038737006

Epoch: 6| Step: 3
Training loss: 0.06172099448903284
Validation loss: 2.180817795760429

Epoch: 6| Step: 4
Training loss: 0.07861643245849621
Validation loss: 2.2045437478761243

Epoch: 6| Step: 5
Training loss: 0.07999744072188096
Validation loss: 2.20186242753581

Epoch: 6| Step: 6
Training loss: 0.1141772393660095
Validation loss: 2.188528678668745

Epoch: 6| Step: 7
Training loss: 0.10024534355738773
Validation loss: 2.183276565928153

Epoch: 6| Step: 8
Training loss: 0.07616671825951238
Validation loss: 2.1933820499760293

Epoch: 6| Step: 9
Training loss: 0.11474240479728261
Validation loss: 2.1786985811721413

Epoch: 6| Step: 10
Training loss: 0.052664591393151425
Validation loss: 2.186911339375914

Epoch: 6| Step: 11
Training loss: 0.08320044157240994
Validation loss: 2.1852809778678646

Epoch: 6| Step: 12
Training loss: 0.07457595121467261
Validation loss: 2.18211804311443

Epoch: 6| Step: 13
Training loss: 0.08208901778174767
Validation loss: 2.173889668161985

Epoch: 627| Step: 0
Training loss: 0.0731057867868259
Validation loss: 2.165756166401863

Epoch: 6| Step: 1
Training loss: 0.08353135552276557
Validation loss: 2.1699081997455107

Epoch: 6| Step: 2
Training loss: 0.07715829653457261
Validation loss: 2.1789854579457737

Epoch: 6| Step: 3
Training loss: 0.0803428380065726
Validation loss: 2.193608036548245

Epoch: 6| Step: 4
Training loss: 0.07344250940931178
Validation loss: 2.1936172598046446

Epoch: 6| Step: 5
Training loss: 0.11632878474989312
Validation loss: 2.203757838746301

Epoch: 6| Step: 6
Training loss: 0.16110618833739068
Validation loss: 2.190788483352891

Epoch: 6| Step: 7
Training loss: 0.07912080730818608
Validation loss: 2.183091716959879

Epoch: 6| Step: 8
Training loss: 0.05108341768767573
Validation loss: 2.1938337076999996

Epoch: 6| Step: 9
Training loss: 0.12204066870286681
Validation loss: 2.171578404225032

Epoch: 6| Step: 10
Training loss: 0.12629611863147308
Validation loss: 2.179227577791399

Epoch: 6| Step: 11
Training loss: 0.04581883558590672
Validation loss: 2.178970595386385

Epoch: 6| Step: 12
Training loss: 0.10825345937793363
Validation loss: 2.1771991763878082

Epoch: 6| Step: 13
Training loss: 0.05713806934720319
Validation loss: 2.2221300145301144

Epoch: 628| Step: 0
Training loss: 0.07325384682995836
Validation loss: 2.2019143654293436

Epoch: 6| Step: 1
Training loss: 0.05661042205640854
Validation loss: 2.200655590420632

Epoch: 6| Step: 2
Training loss: 0.0687394204452588
Validation loss: 2.2122085705182863

Epoch: 6| Step: 3
Training loss: 0.09277396954835615
Validation loss: 2.212049946989867

Epoch: 6| Step: 4
Training loss: 0.06450309405880768
Validation loss: 2.185982880361753

Epoch: 6| Step: 5
Training loss: 0.062199275163556535
Validation loss: 2.1875567532866684

Epoch: 6| Step: 6
Training loss: 0.12493330696239306
Validation loss: 2.1812203990082963

Epoch: 6| Step: 7
Training loss: 0.10648300658401176
Validation loss: 2.1944723952616907

Epoch: 6| Step: 8
Training loss: 0.07021662347737206
Validation loss: 2.196918377672451

Epoch: 6| Step: 9
Training loss: 0.04099363066555875
Validation loss: 2.1872126623494474

Epoch: 6| Step: 10
Training loss: 0.1408105394461421
Validation loss: 2.1998002087555695

Epoch: 6| Step: 11
Training loss: 0.07578587542506696
Validation loss: 2.187817844908285

Epoch: 6| Step: 12
Training loss: 0.13642158911455185
Validation loss: 2.1740136778953905

Epoch: 6| Step: 13
Training loss: 0.09633021336168915
Validation loss: 2.141528104418555

Epoch: 629| Step: 0
Training loss: 0.09255924595709494
Validation loss: 2.1309019042223225

Epoch: 6| Step: 1
Training loss: 0.1954233236609165
Validation loss: 2.1348915885176187

Epoch: 6| Step: 2
Training loss: 0.17319973400721322
Validation loss: 2.105503336547987

Epoch: 6| Step: 3
Training loss: 0.05911566825044787
Validation loss: 2.148950564816624

Epoch: 6| Step: 4
Training loss: 0.08927925695331754
Validation loss: 2.2031407323336802

Epoch: 6| Step: 5
Training loss: 0.21557045191329438
Validation loss: 2.2464503861435072

Epoch: 6| Step: 6
Training loss: 0.11397538777846238
Validation loss: 2.2436032465722575

Epoch: 6| Step: 7
Training loss: 0.2074880957635751
Validation loss: 2.2319078984277367

Epoch: 6| Step: 8
Training loss: 0.1483902730601197
Validation loss: 2.225554902936737

Epoch: 6| Step: 9
Training loss: 0.09919073918455208
Validation loss: 2.1516022666145456

Epoch: 6| Step: 10
Training loss: 0.13710994611659205
Validation loss: 2.176245002842389

Epoch: 6| Step: 11
Training loss: 0.09854667981819311
Validation loss: 2.1556064239144823

Epoch: 6| Step: 12
Training loss: 0.15268562543798073
Validation loss: 2.11596599405867

Epoch: 6| Step: 13
Training loss: 0.09771777122514864
Validation loss: 2.107954784241858

Epoch: 630| Step: 0
Training loss: 0.08691146932440962
Validation loss: 2.1619279972140224

Epoch: 6| Step: 1
Training loss: 0.13281886702590676
Validation loss: 2.131734287080008

Epoch: 6| Step: 2
Training loss: 0.26313125854352276
Validation loss: 2.1731645001069175

Epoch: 6| Step: 3
Training loss: 0.131295367472287
Validation loss: 2.180170707879088

Epoch: 6| Step: 4
Training loss: 0.09595773363157215
Validation loss: 2.206574429296678

Epoch: 6| Step: 5
Training loss: 0.16143324039162193
Validation loss: 2.253272021178475

Epoch: 6| Step: 6
Training loss: 0.248333382531829
Validation loss: 2.2526528114151296

Epoch: 6| Step: 7
Training loss: 0.2314390511611436
Validation loss: 2.287342942497532

Epoch: 6| Step: 8
Training loss: 0.12538084485187412
Validation loss: 2.233502095368881

Epoch: 6| Step: 9
Training loss: 0.12694717540004424
Validation loss: 2.2173965268273372

Epoch: 6| Step: 10
Training loss: 0.16407098067026646
Validation loss: 2.127967968345913

Epoch: 6| Step: 11
Training loss: 0.1664956557839083
Validation loss: 2.1165119721005903

Epoch: 6| Step: 12
Training loss: 0.16827097583353195
Validation loss: 2.1320650158960337

Epoch: 6| Step: 13
Training loss: 0.18380536403378275
Validation loss: 2.109131670566649

Epoch: 631| Step: 0
Training loss: 0.194907464620412
Validation loss: 2.1455275674853933

Epoch: 6| Step: 1
Training loss: 0.224233827515979
Validation loss: 2.1572897030165716

Epoch: 6| Step: 2
Training loss: 0.11667882669320971
Validation loss: 2.179027357287434

Epoch: 6| Step: 3
Training loss: 0.13042433148195032
Validation loss: 2.1578816646787913

Epoch: 6| Step: 4
Training loss: 0.10600281530478788
Validation loss: 2.1896460359066614

Epoch: 6| Step: 5
Training loss: 0.13308737163705905
Validation loss: 2.2171245821874956

Epoch: 6| Step: 6
Training loss: 0.09946775653905071
Validation loss: 2.2284014404956185

Epoch: 6| Step: 7
Training loss: 0.1531060416299346
Validation loss: 2.27181401902477

Epoch: 6| Step: 8
Training loss: 0.1281888462532544
Validation loss: 2.2736917566464117

Epoch: 6| Step: 9
Training loss: 0.17597847576561956
Validation loss: 2.258726054751552

Epoch: 6| Step: 10
Training loss: 0.11924692399103357
Validation loss: 2.261166890719893

Epoch: 6| Step: 11
Training loss: 0.1308764901996326
Validation loss: 2.2274527398710235

Epoch: 6| Step: 12
Training loss: 0.13681271593670208
Validation loss: 2.193371327312972

Epoch: 6| Step: 13
Training loss: 0.11101564673786635
Validation loss: 2.21023533462485

Epoch: 632| Step: 0
Training loss: 0.09496084225805568
Validation loss: 2.1856369998046525

Epoch: 6| Step: 1
Training loss: 0.12624318348781882
Validation loss: 2.166195293018542

Epoch: 6| Step: 2
Training loss: 0.11369449777074668
Validation loss: 2.1529929071333784

Epoch: 6| Step: 3
Training loss: 0.13872592168308626
Validation loss: 2.159953836740002

Epoch: 6| Step: 4
Training loss: 0.09224047916536654
Validation loss: 2.1527895226380376

Epoch: 6| Step: 5
Training loss: 0.1034860658727802
Validation loss: 2.166413125718759

Epoch: 6| Step: 6
Training loss: 0.12567326904191486
Validation loss: 2.161532557893687

Epoch: 6| Step: 7
Training loss: 0.13339510225117232
Validation loss: 2.1813842670997348

Epoch: 6| Step: 8
Training loss: 0.08031017421163832
Validation loss: 2.1508098182273683

Epoch: 6| Step: 9
Training loss: 0.138913836738648
Validation loss: 2.1424614914976337

Epoch: 6| Step: 10
Training loss: 0.050941779795715465
Validation loss: 2.144092380048303

Epoch: 6| Step: 11
Training loss: 0.12287798144127744
Validation loss: 2.1826723212047363

Epoch: 6| Step: 12
Training loss: 0.10465809316541258
Validation loss: 2.1849736064626093

Epoch: 6| Step: 13
Training loss: 0.09551729923555076
Validation loss: 2.1636952177789337

Epoch: 633| Step: 0
Training loss: 0.11147533688869675
Validation loss: 2.1583312953192313

Epoch: 6| Step: 1
Training loss: 0.07811955790638715
Validation loss: 2.199692396108176

Epoch: 6| Step: 2
Training loss: 0.05295225450628134
Validation loss: 2.1672675523764693

Epoch: 6| Step: 3
Training loss: 0.13498189407366656
Validation loss: 2.1822268153600777

Epoch: 6| Step: 4
Training loss: 0.06818097541434529
Validation loss: 2.1897121582587284

Epoch: 6| Step: 5
Training loss: 0.0996680834674418
Validation loss: 2.1846512300156995

Epoch: 6| Step: 6
Training loss: 0.08012011636581709
Validation loss: 2.1804827185109255

Epoch: 6| Step: 7
Training loss: 0.09385663167247554
Validation loss: 2.2056445409548155

Epoch: 6| Step: 8
Training loss: 0.04573414190211452
Validation loss: 2.222119378671985

Epoch: 6| Step: 9
Training loss: 0.11716106831966937
Validation loss: 2.2185324400891084

Epoch: 6| Step: 10
Training loss: 0.1359705890197113
Validation loss: 2.2245935501820275

Epoch: 6| Step: 11
Training loss: 0.06443314531626415
Validation loss: 2.1743631995283947

Epoch: 6| Step: 12
Training loss: 0.08357259246427765
Validation loss: 2.206558611070972

Epoch: 6| Step: 13
Training loss: 0.061096543912223154
Validation loss: 2.1765608382567074

Epoch: 634| Step: 0
Training loss: 0.09328129947284045
Validation loss: 2.165083890006398

Epoch: 6| Step: 1
Training loss: 0.0816194951854111
Validation loss: 2.182483690981309

Epoch: 6| Step: 2
Training loss: 0.08883679572423783
Validation loss: 2.183193681655129

Epoch: 6| Step: 3
Training loss: 0.1413268351034721
Validation loss: 2.166036849935655

Epoch: 6| Step: 4
Training loss: 0.12499615916669428
Validation loss: 2.1745095500231977

Epoch: 6| Step: 5
Training loss: 0.07469713856141051
Validation loss: 2.173806583420273

Epoch: 6| Step: 6
Training loss: 0.07313778748128966
Validation loss: 2.1598580995844463

Epoch: 6| Step: 7
Training loss: 0.11042503004369485
Validation loss: 2.132643264907047

Epoch: 6| Step: 8
Training loss: 0.102300325128068
Validation loss: 2.1509240211216727

Epoch: 6| Step: 9
Training loss: 0.062036599401815835
Validation loss: 2.149152761891662

Epoch: 6| Step: 10
Training loss: 0.07373161504498608
Validation loss: 2.171387336818477

Epoch: 6| Step: 11
Training loss: 0.08658159886636642
Validation loss: 2.1768931581390425

Epoch: 6| Step: 12
Training loss: 0.06699584333715414
Validation loss: 2.1706759315943396

Epoch: 6| Step: 13
Training loss: 0.05529346617094603
Validation loss: 2.1689132428984514

Epoch: 635| Step: 0
Training loss: 0.067478982050593
Validation loss: 2.161967765432644

Epoch: 6| Step: 1
Training loss: 0.07871038055696168
Validation loss: 2.1544314421930477

Epoch: 6| Step: 2
Training loss: 0.08790916406291492
Validation loss: 2.135451903653992

Epoch: 6| Step: 3
Training loss: 0.12257827357616866
Validation loss: 2.1498004451079207

Epoch: 6| Step: 4
Training loss: 0.05959302828696303
Validation loss: 2.1525095919349297

Epoch: 6| Step: 5
Training loss: 0.1157004822037036
Validation loss: 2.1128147301704883

Epoch: 6| Step: 6
Training loss: 0.06991000008042082
Validation loss: 2.1379540743644827

Epoch: 6| Step: 7
Training loss: 0.13031505423267825
Validation loss: 2.119363058207908

Epoch: 6| Step: 8
Training loss: 0.06517884580765321
Validation loss: 2.132440878938868

Epoch: 6| Step: 9
Training loss: 0.11529814038898613
Validation loss: 2.117166629327097

Epoch: 6| Step: 10
Training loss: 0.10998121078097271
Validation loss: 2.149943054038403

Epoch: 6| Step: 11
Training loss: 0.10280772390113208
Validation loss: 2.134213406047629

Epoch: 6| Step: 12
Training loss: 0.1148577694542607
Validation loss: 2.144077362300258

Epoch: 6| Step: 13
Training loss: 0.061223791448889515
Validation loss: 2.1402535717724116

Epoch: 636| Step: 0
Training loss: 0.0906824377981632
Validation loss: 2.1497364908879626

Epoch: 6| Step: 1
Training loss: 0.07523484862704351
Validation loss: 2.1642050107744772

Epoch: 6| Step: 2
Training loss: 0.09948691619609971
Validation loss: 2.186108786956057

Epoch: 6| Step: 3
Training loss: 0.07242619550444625
Validation loss: 2.177599059865968

Epoch: 6| Step: 4
Training loss: 0.06471675723137828
Validation loss: 2.1744529596294058

Epoch: 6| Step: 5
Training loss: 0.10472188641055563
Validation loss: 2.195393949348039

Epoch: 6| Step: 6
Training loss: 0.060931629118178655
Validation loss: 2.199569043895783

Epoch: 6| Step: 7
Training loss: 0.05107208105248901
Validation loss: 2.201090556181793

Epoch: 6| Step: 8
Training loss: 0.11039369335891211
Validation loss: 2.1909548781726196

Epoch: 6| Step: 9
Training loss: 0.11573655411203665
Validation loss: 2.209144636738061

Epoch: 6| Step: 10
Training loss: 0.07324416475806016
Validation loss: 2.181127651633709

Epoch: 6| Step: 11
Training loss: 0.10054438390068988
Validation loss: 2.1743105964441813

Epoch: 6| Step: 12
Training loss: 0.08036370932954032
Validation loss: 2.1719155634245726

Epoch: 6| Step: 13
Training loss: 0.12873717259190307
Validation loss: 2.2054266303672367

Epoch: 637| Step: 0
Training loss: 0.11384372583981178
Validation loss: 2.1725839204615296

Epoch: 6| Step: 1
Training loss: 0.12884806996213036
Validation loss: 2.1857551219560993

Epoch: 6| Step: 2
Training loss: 0.052399503671444476
Validation loss: 2.186451915450986

Epoch: 6| Step: 3
Training loss: 0.060465388685144464
Validation loss: 2.160236950453383

Epoch: 6| Step: 4
Training loss: 0.08163152956604756
Validation loss: 2.1743903300310836

Epoch: 6| Step: 5
Training loss: 0.06829447731093524
Validation loss: 2.186053267312869

Epoch: 6| Step: 6
Training loss: 0.07178566034624409
Validation loss: 2.171118239023652

Epoch: 6| Step: 7
Training loss: 0.09863935108984648
Validation loss: 2.1666750809133

Epoch: 6| Step: 8
Training loss: 0.06980286451733353
Validation loss: 2.208978658114786

Epoch: 6| Step: 9
Training loss: 0.08666806286174733
Validation loss: 2.1906066775917994

Epoch: 6| Step: 10
Training loss: 0.06061954521066062
Validation loss: 2.2216960096385097

Epoch: 6| Step: 11
Training loss: 0.11988681317935007
Validation loss: 2.195361651283211

Epoch: 6| Step: 12
Training loss: 0.08229563885570311
Validation loss: 2.1944698870781285

Epoch: 6| Step: 13
Training loss: 0.08324815512129403
Validation loss: 2.1600482629373112

Epoch: 638| Step: 0
Training loss: 0.11585422874848714
Validation loss: 2.2080885131715937

Epoch: 6| Step: 1
Training loss: 0.06549400399583188
Validation loss: 2.2201828548052402

Epoch: 6| Step: 2
Training loss: 0.08033071490896591
Validation loss: 2.20410370875118

Epoch: 6| Step: 3
Training loss: 0.1058803711722806
Validation loss: 2.175629764991461

Epoch: 6| Step: 4
Training loss: 0.06219715454707362
Validation loss: 2.189060729088301

Epoch: 6| Step: 5
Training loss: 0.07563669843771445
Validation loss: 2.1751443060920317

Epoch: 6| Step: 6
Training loss: 0.055194726999583096
Validation loss: 2.195102737536409

Epoch: 6| Step: 7
Training loss: 0.1253152240304893
Validation loss: 2.1782538031955787

Epoch: 6| Step: 8
Training loss: 0.10623770337614402
Validation loss: 2.1929338133835388

Epoch: 6| Step: 9
Training loss: 0.07238199234058798
Validation loss: 2.198519199326452

Epoch: 6| Step: 10
Training loss: 0.1237578138259089
Validation loss: 2.2189671018651778

Epoch: 6| Step: 11
Training loss: 0.07896115356926037
Validation loss: 2.224340976289986

Epoch: 6| Step: 12
Training loss: 0.07156245183734855
Validation loss: 2.214587035823489

Epoch: 6| Step: 13
Training loss: 0.07360108815295317
Validation loss: 2.2128076537699393

Epoch: 639| Step: 0
Training loss: 0.0579907844256299
Validation loss: 2.199114581285947

Epoch: 6| Step: 1
Training loss: 0.05167918035254038
Validation loss: 2.183665722561514

Epoch: 6| Step: 2
Training loss: 0.1305846347795208
Validation loss: 2.2007016891037363

Epoch: 6| Step: 3
Training loss: 0.07775031482266351
Validation loss: 2.1787223335939894

Epoch: 6| Step: 4
Training loss: 0.07145689777550941
Validation loss: 2.17043821790392

Epoch: 6| Step: 5
Training loss: 0.07493578103562056
Validation loss: 2.200289265991156

Epoch: 6| Step: 6
Training loss: 0.13210211832609878
Validation loss: 2.1717398014099816

Epoch: 6| Step: 7
Training loss: 0.09097368354549844
Validation loss: 2.158872263308418

Epoch: 6| Step: 8
Training loss: 0.06999275568107582
Validation loss: 2.193740878316854

Epoch: 6| Step: 9
Training loss: 0.1024038149480438
Validation loss: 2.16246341406688

Epoch: 6| Step: 10
Training loss: 0.0924558070894426
Validation loss: 2.1754619157632247

Epoch: 6| Step: 11
Training loss: 0.08462877125204356
Validation loss: 2.215607256394299

Epoch: 6| Step: 12
Training loss: 0.04731530286185342
Validation loss: 2.19777771227141

Epoch: 6| Step: 13
Training loss: 0.06321981665262502
Validation loss: 2.2199704483454

Epoch: 640| Step: 0
Training loss: 0.05538810329117845
Validation loss: 2.2244368182499366

Epoch: 6| Step: 1
Training loss: 0.04324501266141237
Validation loss: 2.2091301958328318

Epoch: 6| Step: 2
Training loss: 0.13483597812600034
Validation loss: 2.214717460539441

Epoch: 6| Step: 3
Training loss: 0.13479601475936498
Validation loss: 2.2364359623530694

Epoch: 6| Step: 4
Training loss: 0.10677300330802472
Validation loss: 2.2186099101649988

Epoch: 6| Step: 5
Training loss: 0.06492910053427121
Validation loss: 2.228362928631411

Epoch: 6| Step: 6
Training loss: 0.08553893148217274
Validation loss: 2.2278507129364975

Epoch: 6| Step: 7
Training loss: 0.10709704357338871
Validation loss: 2.2437320000456107

Epoch: 6| Step: 8
Training loss: 0.056305713182933356
Validation loss: 2.214010931336387

Epoch: 6| Step: 9
Training loss: 0.0763040062946304
Validation loss: 2.2116232083729988

Epoch: 6| Step: 10
Training loss: 0.11902443113247171
Validation loss: 2.2138193897035543

Epoch: 6| Step: 11
Training loss: 0.061488974470686665
Validation loss: 2.243404827886041

Epoch: 6| Step: 12
Training loss: 0.07324714325987103
Validation loss: 2.2147832603489945

Epoch: 6| Step: 13
Training loss: 0.10222543709980553
Validation loss: 2.2301098575559193

Epoch: 641| Step: 0
Training loss: 0.06781751589968361
Validation loss: 2.1967206437071405

Epoch: 6| Step: 1
Training loss: 0.0765957865806129
Validation loss: 2.2042826082031057

Epoch: 6| Step: 2
Training loss: 0.07836077101748476
Validation loss: 2.2180566046533476

Epoch: 6| Step: 3
Training loss: 0.11745422526782151
Validation loss: 2.2178095468486263

Epoch: 6| Step: 4
Training loss: 0.09229999503672175
Validation loss: 2.2012821619043423

Epoch: 6| Step: 5
Training loss: 0.08341351826129297
Validation loss: 2.1813122133850538

Epoch: 6| Step: 6
Training loss: 0.08569170197625697
Validation loss: 2.18641461870555

Epoch: 6| Step: 7
Training loss: 0.06641411033559542
Validation loss: 2.185434050859247

Epoch: 6| Step: 8
Training loss: 0.06658748830385573
Validation loss: 2.165083447751075

Epoch: 6| Step: 9
Training loss: 0.1166807183959905
Validation loss: 2.1674834777262486

Epoch: 6| Step: 10
Training loss: 0.052237358432549647
Validation loss: 2.173163566979132

Epoch: 6| Step: 11
Training loss: 0.059327109843558934
Validation loss: 2.1963307799805007

Epoch: 6| Step: 12
Training loss: 0.09665993768124276
Validation loss: 2.2201304205059467

Epoch: 6| Step: 13
Training loss: 0.04906740449200171
Validation loss: 2.211728343733523

Epoch: 642| Step: 0
Training loss: 0.13327458581888704
Validation loss: 2.199036329394408

Epoch: 6| Step: 1
Training loss: 0.12983029960347273
Validation loss: 2.1964848873348815

Epoch: 6| Step: 2
Training loss: 0.08518191353342641
Validation loss: 2.1957881655798075

Epoch: 6| Step: 3
Training loss: 0.06742733714454066
Validation loss: 2.166296618108238

Epoch: 6| Step: 4
Training loss: 0.07884584406843645
Validation loss: 2.145476959085983

Epoch: 6| Step: 5
Training loss: 0.09244535559030478
Validation loss: 2.147332441888535

Epoch: 6| Step: 6
Training loss: 0.09416462683296914
Validation loss: 2.1633683776570383

Epoch: 6| Step: 7
Training loss: 0.09507459434906222
Validation loss: 2.1360458559581836

Epoch: 6| Step: 8
Training loss: 0.08035933731882249
Validation loss: 2.1653392557599846

Epoch: 6| Step: 9
Training loss: 0.07173543472105538
Validation loss: 2.1433539274943554

Epoch: 6| Step: 10
Training loss: 0.1076055343881978
Validation loss: 2.1243213964045657

Epoch: 6| Step: 11
Training loss: 0.1359046403040041
Validation loss: 2.159634121445165

Epoch: 6| Step: 12
Training loss: 0.05055215860283661
Validation loss: 2.1722291704998695

Epoch: 6| Step: 13
Training loss: 0.03956553543069157
Validation loss: 2.186385586625805

Epoch: 643| Step: 0
Training loss: 0.056258602775921256
Validation loss: 2.1796730321241613

Epoch: 6| Step: 1
Training loss: 0.07602079398408663
Validation loss: 2.207617771665417

Epoch: 6| Step: 2
Training loss: 0.10384162366591704
Validation loss: 2.223654874985033

Epoch: 6| Step: 3
Training loss: 0.0962107198467263
Validation loss: 2.2187763162288867

Epoch: 6| Step: 4
Training loss: 0.0887051036937235
Validation loss: 2.22830722989114

Epoch: 6| Step: 5
Training loss: 0.10375819934335981
Validation loss: 2.188737561968099

Epoch: 6| Step: 6
Training loss: 0.10784174619198685
Validation loss: 2.218175404343313

Epoch: 6| Step: 7
Training loss: 0.09737586778956775
Validation loss: 2.2102909764013776

Epoch: 6| Step: 8
Training loss: 0.06034073809738027
Validation loss: 2.205755517175568

Epoch: 6| Step: 9
Training loss: 0.06467833331943988
Validation loss: 2.177100310652191

Epoch: 6| Step: 10
Training loss: 0.053745126680054635
Validation loss: 2.212003724368235

Epoch: 6| Step: 11
Training loss: 0.0751291175638592
Validation loss: 2.19366068613078

Epoch: 6| Step: 12
Training loss: 0.07682294023912144
Validation loss: 2.1757798814481135

Epoch: 6| Step: 13
Training loss: 0.12420770892971436
Validation loss: 2.150354511350077

Epoch: 644| Step: 0
Training loss: 0.08946541760034954
Validation loss: 2.1614054118286496

Epoch: 6| Step: 1
Training loss: 0.1122365993920333
Validation loss: 2.1538253498864397

Epoch: 6| Step: 2
Training loss: 0.060813279268950804
Validation loss: 2.1920051843471327

Epoch: 6| Step: 3
Training loss: 0.11321148697354687
Validation loss: 2.206658342419669

Epoch: 6| Step: 4
Training loss: 0.09067658362158709
Validation loss: 2.201435505744452

Epoch: 6| Step: 5
Training loss: 0.10085789479204435
Validation loss: 2.2111314825937987

Epoch: 6| Step: 6
Training loss: 0.06796095408750674
Validation loss: 2.1879054981361996

Epoch: 6| Step: 7
Training loss: 0.07966288625894972
Validation loss: 2.1872048102643733

Epoch: 6| Step: 8
Training loss: 0.07755302620556476
Validation loss: 2.1887111902743683

Epoch: 6| Step: 9
Training loss: 0.06715569367074031
Validation loss: 2.198409506145846

Epoch: 6| Step: 10
Training loss: 0.12268184452532772
Validation loss: 2.1999588389195828

Epoch: 6| Step: 11
Training loss: 0.08050070887232769
Validation loss: 2.1995123726933223

Epoch: 6| Step: 12
Training loss: 0.0804789791272044
Validation loss: 2.1564280683274757

Epoch: 6| Step: 13
Training loss: 0.13010022602827684
Validation loss: 2.12119161864676

Epoch: 645| Step: 0
Training loss: 0.06188384523590688
Validation loss: 2.102958574438755

Epoch: 6| Step: 1
Training loss: 0.11020117614626013
Validation loss: 2.1178791051878902

Epoch: 6| Step: 2
Training loss: 0.11007316039391639
Validation loss: 2.1223238815732905

Epoch: 6| Step: 3
Training loss: 0.1154650867872185
Validation loss: 2.1353418645255493

Epoch: 6| Step: 4
Training loss: 0.07898146731517382
Validation loss: 2.1492138987298453

Epoch: 6| Step: 5
Training loss: 0.11979055188185517
Validation loss: 2.1294968164392998

Epoch: 6| Step: 6
Training loss: 0.08827346233604237
Validation loss: 2.1381514242591715

Epoch: 6| Step: 7
Training loss: 0.07614315848810019
Validation loss: 2.1427339267659393

Epoch: 6| Step: 8
Training loss: 0.07754786823342999
Validation loss: 2.174711074139367

Epoch: 6| Step: 9
Training loss: 0.09056220756704689
Validation loss: 2.1518894672962117

Epoch: 6| Step: 10
Training loss: 0.13147118584434864
Validation loss: 2.1704596440892887

Epoch: 6| Step: 11
Training loss: 0.10136673013955134
Validation loss: 2.1464362137340975

Epoch: 6| Step: 12
Training loss: 0.09525191245731014
Validation loss: 2.193024817054903

Epoch: 6| Step: 13
Training loss: 0.039701408965318236
Validation loss: 2.1735460745012096

Epoch: 646| Step: 0
Training loss: 0.04428828236836056
Validation loss: 2.1606194551140283

Epoch: 6| Step: 1
Training loss: 0.06987687106433833
Validation loss: 2.169267613324443

Epoch: 6| Step: 2
Training loss: 0.12385393559627084
Validation loss: 2.1452593325906784

Epoch: 6| Step: 3
Training loss: 0.12414256704742738
Validation loss: 2.187222287646035

Epoch: 6| Step: 4
Training loss: 0.05487141592681105
Validation loss: 2.161691307996809

Epoch: 6| Step: 5
Training loss: 0.11350114625034789
Validation loss: 2.1579055517880725

Epoch: 6| Step: 6
Training loss: 0.07702553895242055
Validation loss: 2.1852259874092734

Epoch: 6| Step: 7
Training loss: 0.08227162394971264
Validation loss: 2.173966879452252

Epoch: 6| Step: 8
Training loss: 0.052747892483988035
Validation loss: 2.1865180558403314

Epoch: 6| Step: 9
Training loss: 0.0516412700462741
Validation loss: 2.220868732986239

Epoch: 6| Step: 10
Training loss: 0.14219053050364375
Validation loss: 2.2312583421543337

Epoch: 6| Step: 11
Training loss: 0.09452667481408673
Validation loss: 2.1785450113853395

Epoch: 6| Step: 12
Training loss: 0.10793707153763189
Validation loss: 2.2152865593091176

Epoch: 6| Step: 13
Training loss: 0.0793946863245652
Validation loss: 2.2051203749188355

Epoch: 647| Step: 0
Training loss: 0.10751499128328157
Validation loss: 2.197455153956302

Epoch: 6| Step: 1
Training loss: 0.12581577686044731
Validation loss: 2.204456047987788

Epoch: 6| Step: 2
Training loss: 0.04045944529654564
Validation loss: 2.1992794427671574

Epoch: 6| Step: 3
Training loss: 0.06393674422541762
Validation loss: 2.1941768409432014

Epoch: 6| Step: 4
Training loss: 0.06761580420081273
Validation loss: 2.1766014509822984

Epoch: 6| Step: 5
Training loss: 0.07090883231346858
Validation loss: 2.2013990241689387

Epoch: 6| Step: 6
Training loss: 0.11091808045024457
Validation loss: 2.187780357009522

Epoch: 6| Step: 7
Training loss: 0.10787270185082462
Validation loss: 2.158075151986408

Epoch: 6| Step: 8
Training loss: 0.10009818193251112
Validation loss: 2.1908847891131895

Epoch: 6| Step: 9
Training loss: 0.07269232338956036
Validation loss: 2.1962243959209533

Epoch: 6| Step: 10
Training loss: 0.11519787097054658
Validation loss: 2.1747895482318764

Epoch: 6| Step: 11
Training loss: 0.09022654999001176
Validation loss: 2.1925047923033234

Epoch: 6| Step: 12
Training loss: 0.04814361228994364
Validation loss: 2.2087832306220236

Epoch: 6| Step: 13
Training loss: 0.07128646924253426
Validation loss: 2.2255100989168115

Epoch: 648| Step: 0
Training loss: 0.12085558173324368
Validation loss: 2.244350213973111

Epoch: 6| Step: 1
Training loss: 0.08320323715739683
Validation loss: 2.195742087499735

Epoch: 6| Step: 2
Training loss: 0.11813933137337537
Validation loss: 2.2036640069627245

Epoch: 6| Step: 3
Training loss: 0.04171236922994794
Validation loss: 2.196461903577601

Epoch: 6| Step: 4
Training loss: 0.06672745047129063
Validation loss: 2.1687439128122072

Epoch: 6| Step: 5
Training loss: 0.08271014753068738
Validation loss: 2.1865953241817255

Epoch: 6| Step: 6
Training loss: 0.13254149921806996
Validation loss: 2.177177197159557

Epoch: 6| Step: 7
Training loss: 0.06594749072169365
Validation loss: 2.1870495099412737

Epoch: 6| Step: 8
Training loss: 0.08887812788136322
Validation loss: 2.1776913641992808

Epoch: 6| Step: 9
Training loss: 0.11006921329392123
Validation loss: 2.179223366867945

Epoch: 6| Step: 10
Training loss: 0.10088116180763954
Validation loss: 2.1916888210574794

Epoch: 6| Step: 11
Training loss: 0.08489288970265202
Validation loss: 2.173986643516805

Epoch: 6| Step: 12
Training loss: 0.07100224606015419
Validation loss: 2.1840708802731315

Epoch: 6| Step: 13
Training loss: 0.07337859484941793
Validation loss: 2.190991440044044

Epoch: 649| Step: 0
Training loss: 0.08653750714248033
Validation loss: 2.204634572321703

Epoch: 6| Step: 1
Training loss: 0.08456575081836583
Validation loss: 2.193295306406504

Epoch: 6| Step: 2
Training loss: 0.04813886535608125
Validation loss: 2.1792981893952055

Epoch: 6| Step: 3
Training loss: 0.07529121946091372
Validation loss: 2.200671042184261

Epoch: 6| Step: 4
Training loss: 0.06724676274241902
Validation loss: 2.1803243066094256

Epoch: 6| Step: 5
Training loss: 0.12214166463258437
Validation loss: 2.157154633598769

Epoch: 6| Step: 6
Training loss: 0.14588371468118308
Validation loss: 2.15709221008465

Epoch: 6| Step: 7
Training loss: 0.10258689400553309
Validation loss: 2.1319221436048315

Epoch: 6| Step: 8
Training loss: 0.03991740048634239
Validation loss: 2.12707385399058

Epoch: 6| Step: 9
Training loss: 0.096519076713138
Validation loss: 2.1269534178906255

Epoch: 6| Step: 10
Training loss: 0.11386269123759864
Validation loss: 2.105895798757237

Epoch: 6| Step: 11
Training loss: 0.1922212687342699
Validation loss: 2.08936888780013

Epoch: 6| Step: 12
Training loss: 0.14789561443103985
Validation loss: 2.1243197512276843

Epoch: 6| Step: 13
Training loss: 0.2022049221421459
Validation loss: 2.136275872573365

Epoch: 650| Step: 0
Training loss: 0.16865984000470044
Validation loss: 2.152732316021296

Epoch: 6| Step: 1
Training loss: 0.1111517395635877
Validation loss: 2.193709478549503

Epoch: 6| Step: 2
Training loss: 0.13297486198175723
Validation loss: 2.2156200045153223

Epoch: 6| Step: 3
Training loss: 0.192362595478609
Validation loss: 2.267007965638924

Epoch: 6| Step: 4
Training loss: 0.16703377590642596
Validation loss: 2.2848505814693665

Epoch: 6| Step: 5
Training loss: 0.18859986733831896
Validation loss: 2.261757619381641

Epoch: 6| Step: 6
Training loss: 0.14928765653239334
Validation loss: 2.2438281956924344

Epoch: 6| Step: 7
Training loss: 0.12839251073720062
Validation loss: 2.2168729700288825

Epoch: 6| Step: 8
Training loss: 0.12295741659138525
Validation loss: 2.206006765751853

Epoch: 6| Step: 9
Training loss: 0.11987291091320773
Validation loss: 2.1751217863286048

Epoch: 6| Step: 10
Training loss: 0.142858151875066
Validation loss: 2.1770812217755937

Epoch: 6| Step: 11
Training loss: 0.1586927149792038
Validation loss: 2.1804333682139263

Epoch: 6| Step: 12
Training loss: 0.21073481747500267
Validation loss: 2.1741945479952336

Epoch: 6| Step: 13
Training loss: 0.23737819930165943
Validation loss: 2.2118611157625225

Epoch: 651| Step: 0
Training loss: 0.2643489621238544
Validation loss: 2.1941074775752334

Epoch: 6| Step: 1
Training loss: 0.3218802951636442
Validation loss: 2.2469328169727762

Epoch: 6| Step: 2
Training loss: 0.19571357554478674
Validation loss: 2.2178581602604894

Epoch: 6| Step: 3
Training loss: 0.10286165989773667
Validation loss: 2.2504559309052032

Epoch: 6| Step: 4
Training loss: 0.12691087019578426
Validation loss: 2.231922709987088

Epoch: 6| Step: 5
Training loss: 0.3175736073903437
Validation loss: 2.251835540359

Epoch: 6| Step: 6
Training loss: 0.13163637669440548
Validation loss: 2.2368038030012083

Epoch: 6| Step: 7
Training loss: 0.22988531650939342
Validation loss: 2.200710036319639

Epoch: 6| Step: 8
Training loss: 0.23868123861821927
Validation loss: 2.168058972309162

Epoch: 6| Step: 9
Training loss: 0.28104658188043496
Validation loss: 2.1223392579941733

Epoch: 6| Step: 10
Training loss: 0.15549703010140892
Validation loss: 2.1078237915004197

Epoch: 6| Step: 11
Training loss: 0.2518389983040736
Validation loss: 2.100850531912922

Epoch: 6| Step: 12
Training loss: 0.23763190578046037
Validation loss: 2.140458718130442

Epoch: 6| Step: 13
Training loss: 0.22108910154706274
Validation loss: 2.1293454573191077

Epoch: 652| Step: 0
Training loss: 0.15286787666940985
Validation loss: 2.1688543374690097

Epoch: 6| Step: 1
Training loss: 0.2729888232164966
Validation loss: 2.1498816326665495

Epoch: 6| Step: 2
Training loss: 0.18030944249752467
Validation loss: 2.188636536101971

Epoch: 6| Step: 3
Training loss: 0.11945196807331014
Validation loss: 2.176661805079608

Epoch: 6| Step: 4
Training loss: 0.17326749984424508
Validation loss: 2.1913467828204407

Epoch: 6| Step: 5
Training loss: 0.2322281984186582
Validation loss: 2.222341792518838

Epoch: 6| Step: 6
Training loss: 0.13131606420475883
Validation loss: 2.264163650998679

Epoch: 6| Step: 7
Training loss: 0.42917130415302773
Validation loss: 2.2757268481273605

Epoch: 6| Step: 8
Training loss: 0.14224753527190445
Validation loss: 2.2752232412857496

Epoch: 6| Step: 9
Training loss: 0.21723387037941738
Validation loss: 2.2910615851211387

Epoch: 6| Step: 10
Training loss: 0.13854637645899762
Validation loss: 2.311104432912922

Epoch: 6| Step: 11
Training loss: 0.16282531334580222
Validation loss: 2.292197115373464

Epoch: 6| Step: 12
Training loss: 0.10370770214084651
Validation loss: 2.2924156628078873

Epoch: 6| Step: 13
Training loss: 0.3189809967280685
Validation loss: 2.270516175761782

Epoch: 653| Step: 0
Training loss: 0.18863538859194762
Validation loss: 2.255579655666013

Epoch: 6| Step: 1
Training loss: 0.1259489990361181
Validation loss: 2.223540418962553

Epoch: 6| Step: 2
Training loss: 0.2445034383003528
Validation loss: 2.2641619254211944

Epoch: 6| Step: 3
Training loss: 0.17557358130747255
Validation loss: 2.1996793721194745

Epoch: 6| Step: 4
Training loss: 0.1582956043787718
Validation loss: 2.2100119136611123

Epoch: 6| Step: 5
Training loss: 0.16679802699886115
Validation loss: 2.210783223094247

Epoch: 6| Step: 6
Training loss: 0.1985884494059106
Validation loss: 2.1710223211113053

Epoch: 6| Step: 7
Training loss: 0.25664937020415357
Validation loss: 2.1724773877982813

Epoch: 6| Step: 8
Training loss: 0.23091610632617007
Validation loss: 2.1936608430232045

Epoch: 6| Step: 9
Training loss: 0.15031164746032802
Validation loss: 2.250014094282372

Epoch: 6| Step: 10
Training loss: 0.1859579952548754
Validation loss: 2.2590046025711623

Epoch: 6| Step: 11
Training loss: 0.24248469483852034
Validation loss: 2.2505342138169793

Epoch: 6| Step: 12
Training loss: 0.13435724135531457
Validation loss: 2.265355801316023

Epoch: 6| Step: 13
Training loss: 0.14289621900117208
Validation loss: 2.2648708696614346

Epoch: 654| Step: 0
Training loss: 0.25767763540652905
Validation loss: 2.2321780540867326

Epoch: 6| Step: 1
Training loss: 0.12726785820581718
Validation loss: 2.191217311648564

Epoch: 6| Step: 2
Training loss: 0.22833984493770831
Validation loss: 2.148648715408761

Epoch: 6| Step: 3
Training loss: 0.13685434973852525
Validation loss: 2.100230627389886

Epoch: 6| Step: 4
Training loss: 0.2376095183610311
Validation loss: 2.0881072110008283

Epoch: 6| Step: 5
Training loss: 0.2518443974535011
Validation loss: 2.101489424640598

Epoch: 6| Step: 6
Training loss: 0.22182212992165362
Validation loss: 2.109161401383771

Epoch: 6| Step: 7
Training loss: 0.16594526258368833
Validation loss: 2.141416252695205

Epoch: 6| Step: 8
Training loss: 0.16280035037654997
Validation loss: 2.179990638779795

Epoch: 6| Step: 9
Training loss: 0.2429791095647118
Validation loss: 2.205802955666361

Epoch: 6| Step: 10
Training loss: 0.1713284667916635
Validation loss: 2.228706988310706

Epoch: 6| Step: 11
Training loss: 0.23021016727913773
Validation loss: 2.209340303207782

Epoch: 6| Step: 12
Training loss: 0.13828773079249188
Validation loss: 2.200868675164767

Epoch: 6| Step: 13
Training loss: 0.3217187576330998
Validation loss: 2.159459030762336

Epoch: 655| Step: 0
Training loss: 0.1386125330147578
Validation loss: 2.158331032818004

Epoch: 6| Step: 1
Training loss: 0.12211407067879695
Validation loss: 2.1042602968619453

Epoch: 6| Step: 2
Training loss: 0.14818168229629677
Validation loss: 2.0861406358350094

Epoch: 6| Step: 3
Training loss: 0.23162175145061079
Validation loss: 2.0945646011183117

Epoch: 6| Step: 4
Training loss: 0.1867620729121232
Validation loss: 2.106376097962408

Epoch: 6| Step: 5
Training loss: 0.18550316145097398
Validation loss: 2.146616701842554

Epoch: 6| Step: 6
Training loss: 0.36760578274427935
Validation loss: 2.16271933579516

Epoch: 6| Step: 7
Training loss: 0.3068644684579059
Validation loss: 2.1877165433758865

Epoch: 6| Step: 8
Training loss: 0.17714168952109907
Validation loss: 2.2599138831366266

Epoch: 6| Step: 9
Training loss: 0.24957115674738087
Validation loss: 2.281956964175341

Epoch: 6| Step: 10
Training loss: 0.1825040681104701
Validation loss: 2.2661110667406734

Epoch: 6| Step: 11
Training loss: 0.28675412887454227
Validation loss: 2.228608776254222

Epoch: 6| Step: 12
Training loss: 0.24229073631444753
Validation loss: 2.206484104134473

Epoch: 6| Step: 13
Training loss: 0.2012762521124166
Validation loss: 2.2050744825473116

Epoch: 656| Step: 0
Training loss: 0.21078346951152435
Validation loss: 2.106714144132044

Epoch: 6| Step: 1
Training loss: 0.3665264753898586
Validation loss: 2.111752344502156

Epoch: 6| Step: 2
Training loss: 0.2257915567071758
Validation loss: 2.0770529335558696

Epoch: 6| Step: 3
Training loss: 0.24407507970238757
Validation loss: 2.1168131619030803

Epoch: 6| Step: 4
Training loss: 0.22600305479441055
Validation loss: 2.1379912488281274

Epoch: 6| Step: 5
Training loss: 0.21771344611599738
Validation loss: 2.190071934376291

Epoch: 6| Step: 6
Training loss: 0.17372874301441396
Validation loss: 2.2102628007648137

Epoch: 6| Step: 7
Training loss: 0.22832784517913632
Validation loss: 2.197334437159879

Epoch: 6| Step: 8
Training loss: 0.33108657638317857
Validation loss: 2.230670813269878

Epoch: 6| Step: 9
Training loss: 0.14408965566473264
Validation loss: 2.1771438322528742

Epoch: 6| Step: 10
Training loss: 0.17239176485114754
Validation loss: 2.166336589850446

Epoch: 6| Step: 11
Training loss: 0.1789219970103071
Validation loss: 2.173940230699363

Epoch: 6| Step: 12
Training loss: 0.19764407840389406
Validation loss: 2.163087130380756

Epoch: 6| Step: 13
Training loss: 0.2378900631301333
Validation loss: 2.163655701696034

Epoch: 657| Step: 0
Training loss: 0.1876004764438234
Validation loss: 2.1498293606941163

Epoch: 6| Step: 1
Training loss: 0.3444451542410322
Validation loss: 2.1630985453807727

Epoch: 6| Step: 2
Training loss: 0.3070903444568124
Validation loss: 2.177954252916707

Epoch: 6| Step: 3
Training loss: 0.1649711062679831
Validation loss: 2.1836666946397734

Epoch: 6| Step: 4
Training loss: 0.15042489763596856
Validation loss: 2.214186325059458

Epoch: 6| Step: 5
Training loss: 0.20312104771510353
Validation loss: 2.2711776272197555

Epoch: 6| Step: 6
Training loss: 0.1850511554441014
Validation loss: 2.342563340227732

Epoch: 6| Step: 7
Training loss: 0.3215438620872301
Validation loss: 2.4004755324109217

Epoch: 6| Step: 8
Training loss: 0.2441862826569644
Validation loss: 2.3666611115325296

Epoch: 6| Step: 9
Training loss: 0.22225004084547031
Validation loss: 2.3707839285781906

Epoch: 6| Step: 10
Training loss: 0.14323003219574168
Validation loss: 2.299820386619954

Epoch: 6| Step: 11
Training loss: 0.17649509865112367
Validation loss: 2.247098529741525

Epoch: 6| Step: 12
Training loss: 0.27718668506420807
Validation loss: 2.2047525251945728

Epoch: 6| Step: 13
Training loss: 0.2459867259835643
Validation loss: 2.1885062398172814

Epoch: 658| Step: 0
Training loss: 0.28379323579538024
Validation loss: 2.2178967770864326

Epoch: 6| Step: 1
Training loss: 0.20035620945989183
Validation loss: 2.200779963322495

Epoch: 6| Step: 2
Training loss: 0.2220193722290756
Validation loss: 2.1831042750644656

Epoch: 6| Step: 3
Training loss: 0.2699789392681466
Validation loss: 2.2048770980722616

Epoch: 6| Step: 4
Training loss: 0.2749403525818237
Validation loss: 2.2257063763505394

Epoch: 6| Step: 5
Training loss: 0.21287743938804515
Validation loss: 2.227683387973482

Epoch: 6| Step: 6
Training loss: 0.32366839197758396
Validation loss: 2.243207463638852

Epoch: 6| Step: 7
Training loss: 0.1540728705496409
Validation loss: 2.218818281048268

Epoch: 6| Step: 8
Training loss: 0.151308208173086
Validation loss: 2.20454815347835

Epoch: 6| Step: 9
Training loss: 0.203218246111479
Validation loss: 2.167863701416119

Epoch: 6| Step: 10
Training loss: 0.19069963541866192
Validation loss: 2.1540366023105357

Epoch: 6| Step: 11
Training loss: 0.18432430241123068
Validation loss: 2.1442402370751963

Epoch: 6| Step: 12
Training loss: 0.25252565494358387
Validation loss: 2.1464880464101745

Epoch: 6| Step: 13
Training loss: 0.4129968281039896
Validation loss: 2.11700797321652

Epoch: 659| Step: 0
Training loss: 0.20309428753116235
Validation loss: 2.1077418024949655

Epoch: 6| Step: 1
Training loss: 0.18987082614040474
Validation loss: 2.100680781605075

Epoch: 6| Step: 2
Training loss: 0.21652900195898897
Validation loss: 2.1318404572817267

Epoch: 6| Step: 3
Training loss: 0.18739959889718105
Validation loss: 2.099922651999387

Epoch: 6| Step: 4
Training loss: 0.21686661088422196
Validation loss: 2.128206481959013

Epoch: 6| Step: 5
Training loss: 0.2449381809191086
Validation loss: 2.097220800278371

Epoch: 6| Step: 6
Training loss: 0.38581876356836087
Validation loss: 2.095167403594409

Epoch: 6| Step: 7
Training loss: 0.41303420588366524
Validation loss: 2.098463622213821

Epoch: 6| Step: 8
Training loss: 0.23741765728060185
Validation loss: 2.077415324160364

Epoch: 6| Step: 9
Training loss: 0.35141048323683843
Validation loss: 2.111663308792843

Epoch: 6| Step: 10
Training loss: 0.3073658112877953
Validation loss: 2.1149928918142713

Epoch: 6| Step: 11
Training loss: 0.21872782594828397
Validation loss: 2.161753490788235

Epoch: 6| Step: 12
Training loss: 0.31835581771641797
Validation loss: 2.144664998498015

Epoch: 6| Step: 13
Training loss: 0.37806906089317777
Validation loss: 2.219455750602615

Epoch: 660| Step: 0
Training loss: 0.24853088435190865
Validation loss: 2.2462490815270066

Epoch: 6| Step: 1
Training loss: 0.3127302275398599
Validation loss: 2.2114036831256265

Epoch: 6| Step: 2
Training loss: 0.3688619459887305
Validation loss: 2.2271097986882817

Epoch: 6| Step: 3
Training loss: 0.38388778542753976
Validation loss: 2.1915048957208834

Epoch: 6| Step: 4
Training loss: 0.23670994833518563
Validation loss: 2.242224524167544

Epoch: 6| Step: 5
Training loss: 0.2083777509466552
Validation loss: 2.2332115078432286

Epoch: 6| Step: 6
Training loss: 0.2753174055444008
Validation loss: 2.267184986142423

Epoch: 6| Step: 7
Training loss: 0.40476010455571343
Validation loss: 2.2916264020527906

Epoch: 6| Step: 8
Training loss: 0.29408380027918407
Validation loss: 2.3084404010589252

Epoch: 6| Step: 9
Training loss: 0.2921907139157692
Validation loss: 2.3098690700417586

Epoch: 6| Step: 10
Training loss: 0.2461713940885998
Validation loss: 2.362830683742502

Epoch: 6| Step: 11
Training loss: 0.33224907630019884
Validation loss: 2.360560897061088

Epoch: 6| Step: 12
Training loss: 0.7347374285530707
Validation loss: 2.3679343074759243

Epoch: 6| Step: 13
Training loss: 0.6209296483549912
Validation loss: 2.2878888800716273

Epoch: 661| Step: 0
Training loss: 0.3694127608618485
Validation loss: 2.2022629046559787

Epoch: 6| Step: 1
Training loss: 0.5515265866439681
Validation loss: 2.0948638965080133

Epoch: 6| Step: 2
Training loss: 0.6119871152537468
Validation loss: 2.047911773980575

Epoch: 6| Step: 3
Training loss: 0.5365110914589452
Validation loss: 2.0380925991516836

Epoch: 6| Step: 4
Training loss: 0.5882805833141506
Validation loss: 2.036821733935733

Epoch: 6| Step: 5
Training loss: 1.1617806618873672
Validation loss: 2.072525411895082

Epoch: 6| Step: 6
Training loss: 0.4550741956811319
Validation loss: 2.1269033287887056

Epoch: 6| Step: 7
Training loss: 0.37926132239814614
Validation loss: 2.3227370989331613

Epoch: 6| Step: 8
Training loss: 0.435943422995087
Validation loss: 2.3967676046916844

Epoch: 6| Step: 9
Training loss: 0.9557124490687684
Validation loss: 2.509679912311566

Epoch: 6| Step: 10
Training loss: 0.7458147655782875
Validation loss: 2.413256375108887

Epoch: 6| Step: 11
Training loss: 0.502637315226887
Validation loss: 2.2751266349589825

Epoch: 6| Step: 12
Training loss: 1.0146271719002868
Validation loss: 2.280603678834671

Epoch: 6| Step: 13
Training loss: 0.9837060805117787
Validation loss: 2.29920056535449

Epoch: 662| Step: 0
Training loss: 0.8906523717053845
Validation loss: 2.1972721663255754

Epoch: 6| Step: 1
Training loss: 0.9460249808886296
Validation loss: 2.2401355370750378

Epoch: 6| Step: 2
Training loss: 1.2014634189505797
Validation loss: 2.297289608536524

Epoch: 6| Step: 3
Training loss: 1.0454974434272672
Validation loss: 2.4051989979665094

Epoch: 6| Step: 4
Training loss: 0.8818284010116249
Validation loss: 2.364191292127275

Epoch: 6| Step: 5
Training loss: 0.8643972510661732
Validation loss: 2.365091599270113

Epoch: 6| Step: 6
Training loss: 1.124466716679178
Validation loss: 2.374449626749648

Epoch: 6| Step: 7
Training loss: 0.892549476748095
Validation loss: 2.3969373132813843

Epoch: 6| Step: 8
Training loss: 1.297907866095541
Validation loss: 2.4762065819709296

Epoch: 6| Step: 9
Training loss: 0.6621907052020587
Validation loss: 2.479620452434899

Epoch: 6| Step: 10
Training loss: 0.8283592468624273
Validation loss: 2.5769204108296235

Epoch: 6| Step: 11
Training loss: 0.8736800387619446
Validation loss: 2.528292453524152

Epoch: 6| Step: 12
Training loss: 1.591968138673061
Validation loss: 2.4677870266286903

Epoch: 6| Step: 13
Training loss: 0.922585876003296
Validation loss: 2.342609766399916

Epoch: 663| Step: 0
Training loss: 0.7403572403289477
Validation loss: 2.3146235491741174

Epoch: 6| Step: 1
Training loss: 0.5582213861296113
Validation loss: 2.285506812615376

Epoch: 6| Step: 2
Training loss: 1.0556803233599623
Validation loss: 2.222470368567365

Epoch: 6| Step: 3
Training loss: 0.968804880864191
Validation loss: 2.2884414576829144

Epoch: 6| Step: 4
Training loss: 1.2128012803936543
Validation loss: 2.344429257861171

Epoch: 6| Step: 5
Training loss: 1.2877787815966317
Validation loss: 2.268467634896878

Epoch: 6| Step: 6
Training loss: 1.090616369349917
Validation loss: 2.1985697364826318

Epoch: 6| Step: 7
Training loss: 1.1462443683781283
Validation loss: 2.2135844977986503

Epoch: 6| Step: 8
Training loss: 1.1909446947915954
Validation loss: 2.2578894233792313

Epoch: 6| Step: 9
Training loss: 0.7328936468878827
Validation loss: 2.3288751596485633

Epoch: 6| Step: 10
Training loss: 1.1782493161451013
Validation loss: 2.393328302912116

Epoch: 6| Step: 11
Training loss: 1.153974613961663
Validation loss: 2.2781816011173563

Epoch: 6| Step: 12
Training loss: 0.545731520681977
Validation loss: 2.241558221751138

Epoch: 6| Step: 13
Training loss: 1.1107325240054073
Validation loss: 2.2310459398797584

Epoch: 664| Step: 0
Training loss: 0.8413176621863261
Validation loss: 2.321598177815717

Epoch: 6| Step: 1
Training loss: 0.7904130312270109
Validation loss: 2.4137112137928525

Epoch: 6| Step: 2
Training loss: 1.0832345379505697
Validation loss: 2.4835766018710053

Epoch: 6| Step: 3
Training loss: 1.4049842648286843
Validation loss: 2.4985863062298836

Epoch: 6| Step: 4
Training loss: 0.7666920213722286
Validation loss: 2.4321980497998092

Epoch: 6| Step: 5
Training loss: 1.082297942969757
Validation loss: 2.415509621280285

Epoch: 6| Step: 6
Training loss: 0.7985910376269652
Validation loss: 2.3329397329554338

Epoch: 6| Step: 7
Training loss: 0.6693823507494827
Validation loss: 2.332134164099105

Epoch: 6| Step: 8
Training loss: 0.8204720841447004
Validation loss: 2.4069228332318224

Epoch: 6| Step: 9
Training loss: 0.9061173637932455
Validation loss: 2.4460738531829755

Epoch: 6| Step: 10
Training loss: 0.6755696003844517
Validation loss: 2.4408303000076215

Epoch: 6| Step: 11
Training loss: 0.9636966202693559
Validation loss: 2.4528269861395064

Epoch: 6| Step: 12
Training loss: 0.642684881276033
Validation loss: 2.4402655653853866

Epoch: 6| Step: 13
Training loss: 0.6492738959696516
Validation loss: 2.516922398293616

Epoch: 665| Step: 0
Training loss: 0.5780916462117666
Validation loss: 2.5003113439972706

Epoch: 6| Step: 1
Training loss: 1.3589650555427388
Validation loss: 2.5251641377623146

Epoch: 6| Step: 2
Training loss: 0.5879832603494913
Validation loss: 2.475003843945679

Epoch: 6| Step: 3
Training loss: 0.5745280204974743
Validation loss: 2.3860831566628797

Epoch: 6| Step: 4
Training loss: 0.761929800677284
Validation loss: 2.38947027453407

Epoch: 6| Step: 5
Training loss: 1.0036778765427932
Validation loss: 2.396021975616159

Epoch: 6| Step: 6
Training loss: 0.9918360650942611
Validation loss: 2.3986886617701852

Epoch: 6| Step: 7
Training loss: 0.43387249415208967
Validation loss: 2.3980451506586915

Epoch: 6| Step: 8
Training loss: 0.5747501224253866
Validation loss: 2.434485389518895

Epoch: 6| Step: 9
Training loss: 0.5080952664035997
Validation loss: 2.510358509943504

Epoch: 6| Step: 10
Training loss: 0.8342767064635647
Validation loss: 2.5219220863158425

Epoch: 6| Step: 11
Training loss: 0.8147364061994293
Validation loss: 2.4848687642289744

Epoch: 6| Step: 12
Training loss: 0.8269534911531945
Validation loss: 2.4164570224905595

Epoch: 6| Step: 13
Training loss: 0.5278176615379648
Validation loss: 2.3490435198730424

Epoch: 666| Step: 0
Training loss: 0.4019904576231827
Validation loss: 2.3376818764439924

Epoch: 6| Step: 1
Training loss: 0.4011902244999516
Validation loss: 2.2912601531764087

Epoch: 6| Step: 2
Training loss: 0.6550305708091879
Validation loss: 2.265844523565885

Epoch: 6| Step: 3
Training loss: 0.5808565202551791
Validation loss: 2.1944405900668578

Epoch: 6| Step: 4
Training loss: 0.5260408483316332
Validation loss: 2.2100259602034007

Epoch: 6| Step: 5
Training loss: 0.45518191222354676
Validation loss: 2.1902290086153333

Epoch: 6| Step: 6
Training loss: 0.33479600855289315
Validation loss: 2.1826861690127273

Epoch: 6| Step: 7
Training loss: 0.48456248377388256
Validation loss: 2.1899902092476977

Epoch: 6| Step: 8
Training loss: 0.4143729575496642
Validation loss: 2.2276464432091485

Epoch: 6| Step: 9
Training loss: 0.7576684716596583
Validation loss: 2.1956600538415767

Epoch: 6| Step: 10
Training loss: 0.5107625224221031
Validation loss: 2.1199889294713925

Epoch: 6| Step: 11
Training loss: 0.357510769321719
Validation loss: 2.115199768191144

Epoch: 6| Step: 12
Training loss: 0.6246880229510761
Validation loss: 2.0844404375827374

Epoch: 6| Step: 13
Training loss: 0.5610656198808127
Validation loss: 2.0796320210627544

Epoch: 667| Step: 0
Training loss: 0.6098561221604297
Validation loss: 2.1011831851050093

Epoch: 6| Step: 1
Training loss: 0.3468123491087197
Validation loss: 2.0846742439091126

Epoch: 6| Step: 2
Training loss: 0.684996294164727
Validation loss: 2.0972481793927393

Epoch: 6| Step: 3
Training loss: 0.2504137906265342
Validation loss: 2.14302159848807

Epoch: 6| Step: 4
Training loss: 0.4196859184740935
Validation loss: 2.1300536233230765

Epoch: 6| Step: 5
Training loss: 0.48232986561199365
Validation loss: 2.1747998238020547

Epoch: 6| Step: 6
Training loss: 0.5223488660739273
Validation loss: 2.163105509431559

Epoch: 6| Step: 7
Training loss: 0.4429162453511562
Validation loss: 2.148025166459912

Epoch: 6| Step: 8
Training loss: 0.4527186347390931
Validation loss: 2.1589627292009377

Epoch: 6| Step: 9
Training loss: 0.42469824849632754
Validation loss: 2.1329514622995607

Epoch: 6| Step: 10
Training loss: 0.3795976328363463
Validation loss: 2.1582742124286964

Epoch: 6| Step: 11
Training loss: 0.45588229921782175
Validation loss: 2.1344451142801226

Epoch: 6| Step: 12
Training loss: 0.3394370769925854
Validation loss: 2.17738044887074

Epoch: 6| Step: 13
Training loss: 0.2742862199991714
Validation loss: 2.1934330234014072

Epoch: 668| Step: 0
Training loss: 0.3875699741496077
Validation loss: 2.2279877518604243

Epoch: 6| Step: 1
Training loss: 0.4364449005821508
Validation loss: 2.2473681380964585

Epoch: 6| Step: 2
Training loss: 0.3443097520588065
Validation loss: 2.294944340742746

Epoch: 6| Step: 3
Training loss: 0.3579628607649713
Validation loss: 2.3163722841496908

Epoch: 6| Step: 4
Training loss: 0.33319116953323014
Validation loss: 2.3498561649294256

Epoch: 6| Step: 5
Training loss: 0.5452920620211611
Validation loss: 2.3827098682450134

Epoch: 6| Step: 6
Training loss: 0.3844164120455321
Validation loss: 2.3878122734860567

Epoch: 6| Step: 7
Training loss: 0.33886923225951215
Validation loss: 2.3460607435470315

Epoch: 6| Step: 8
Training loss: 0.3549122489011752
Validation loss: 2.348943078132716

Epoch: 6| Step: 9
Training loss: 0.21539805604598533
Validation loss: 2.3497935959807825

Epoch: 6| Step: 10
Training loss: 0.26249664622389624
Validation loss: 2.3234960038777754

Epoch: 6| Step: 11
Training loss: 0.38494557079532354
Validation loss: 2.3107981873288037

Epoch: 6| Step: 12
Training loss: 0.40352701058439594
Validation loss: 2.2624774493227475

Epoch: 6| Step: 13
Training loss: 0.26208913983663346
Validation loss: 2.260374713491558

Epoch: 669| Step: 0
Training loss: 0.5119231885833742
Validation loss: 2.279086611164142

Epoch: 6| Step: 1
Training loss: 0.27622669544567957
Validation loss: 2.2888065329275555

Epoch: 6| Step: 2
Training loss: 0.246034478815522
Validation loss: 2.2704911728257047

Epoch: 6| Step: 3
Training loss: 0.3436457844460784
Validation loss: 2.2820810750280796

Epoch: 6| Step: 4
Training loss: 0.39589143209559186
Validation loss: 2.2855922432048943

Epoch: 6| Step: 5
Training loss: 0.40047359072185273
Validation loss: 2.289441660341679

Epoch: 6| Step: 6
Training loss: 0.3504952443585216
Validation loss: 2.312172045812411

Epoch: 6| Step: 7
Training loss: 0.30408991385256995
Validation loss: 2.2861195049564484

Epoch: 6| Step: 8
Training loss: 0.40292303733496787
Validation loss: 2.2665520445719745

Epoch: 6| Step: 9
Training loss: 0.3540181124237355
Validation loss: 2.252542801580167

Epoch: 6| Step: 10
Training loss: 0.3078837375214131
Validation loss: 2.2534745505070677

Epoch: 6| Step: 11
Training loss: 0.26203920189671887
Validation loss: 2.2473762173033567

Epoch: 6| Step: 12
Training loss: 0.4381063550935284
Validation loss: 2.2171448270115803

Epoch: 6| Step: 13
Training loss: 0.293473609798774
Validation loss: 2.1930113513307976

Epoch: 670| Step: 0
Training loss: 0.29998093186814695
Validation loss: 2.1628181158571094

Epoch: 6| Step: 1
Training loss: 0.4098675029356344
Validation loss: 2.1491687109812467

Epoch: 6| Step: 2
Training loss: 0.3198282023174504
Validation loss: 2.1752021873084457

Epoch: 6| Step: 3
Training loss: 0.4043221028146248
Validation loss: 2.140057162641831

Epoch: 6| Step: 4
Training loss: 0.21983800816849478
Validation loss: 2.1626989175570337

Epoch: 6| Step: 5
Training loss: 0.2978992361469342
Validation loss: 2.142680956968095

Epoch: 6| Step: 6
Training loss: 0.31859216194823436
Validation loss: 2.169091662747543

Epoch: 6| Step: 7
Training loss: 0.3394441337843301
Validation loss: 2.187801655539435

Epoch: 6| Step: 8
Training loss: 0.24692998074693884
Validation loss: 2.1805756749579888

Epoch: 6| Step: 9
Training loss: 0.2363902632936031
Validation loss: 2.210906259816152

Epoch: 6| Step: 10
Training loss: 0.301295781653514
Validation loss: 2.2379144145593863

Epoch: 6| Step: 11
Training loss: 0.2843482052053318
Validation loss: 2.2738369832223233

Epoch: 6| Step: 12
Training loss: 0.36236532685790085
Validation loss: 2.2814236635372267

Epoch: 6| Step: 13
Training loss: 0.3930971690395489
Validation loss: 2.2811575002848588

Epoch: 671| Step: 0
Training loss: 0.31360616411347475
Validation loss: 2.2736073131604186

Epoch: 6| Step: 1
Training loss: 0.15744758258796335
Validation loss: 2.2060287639588405

Epoch: 6| Step: 2
Training loss: 0.22682125836951253
Validation loss: 2.210892133059983

Epoch: 6| Step: 3
Training loss: 0.1778402118173381
Validation loss: 2.2112264751241986

Epoch: 6| Step: 4
Training loss: 0.20119049393499144
Validation loss: 2.197978216896809

Epoch: 6| Step: 5
Training loss: 0.2599257069136985
Validation loss: 2.2015858381136484

Epoch: 6| Step: 6
Training loss: 0.20918903846391543
Validation loss: 2.1693696546340253

Epoch: 6| Step: 7
Training loss: 0.36091986608984516
Validation loss: 2.1664130825262196

Epoch: 6| Step: 8
Training loss: 0.21983650000356642
Validation loss: 2.151716214777433

Epoch: 6| Step: 9
Training loss: 0.19927813075081352
Validation loss: 2.161908393277537

Epoch: 6| Step: 10
Training loss: 0.296154578611257
Validation loss: 2.1365396347660264

Epoch: 6| Step: 11
Training loss: 0.3133394648623302
Validation loss: 2.191100831831831

Epoch: 6| Step: 12
Training loss: 0.25080946172399204
Validation loss: 2.170173859957782

Epoch: 6| Step: 13
Training loss: 0.3421936239278099
Validation loss: 2.21264232010672

Epoch: 672| Step: 0
Training loss: 0.3097092109291216
Validation loss: 2.230258442749237

Epoch: 6| Step: 1
Training loss: 0.15795672619958082
Validation loss: 2.2029701398993176

Epoch: 6| Step: 2
Training loss: 0.21493286538735992
Validation loss: 2.1661343141393243

Epoch: 6| Step: 3
Training loss: 0.19005693976909896
Validation loss: 2.16444237384194

Epoch: 6| Step: 4
Training loss: 0.24691200461885676
Validation loss: 2.1544401554991315

Epoch: 6| Step: 5
Training loss: 0.1799177477583121
Validation loss: 2.1777224663577552

Epoch: 6| Step: 6
Training loss: 0.18299322121017186
Validation loss: 2.150129475263825

Epoch: 6| Step: 7
Training loss: 0.24876393279156636
Validation loss: 2.1673284147971503

Epoch: 6| Step: 8
Training loss: 0.16600658728738812
Validation loss: 2.153584017992797

Epoch: 6| Step: 9
Training loss: 0.1692282727116663
Validation loss: 2.143096849967821

Epoch: 6| Step: 10
Training loss: 0.21503595944139758
Validation loss: 2.1117776499168768

Epoch: 6| Step: 11
Training loss: 0.27398517801054534
Validation loss: 2.121286608893433

Epoch: 6| Step: 12
Training loss: 0.21005051941828987
Validation loss: 2.10920384911724

Epoch: 6| Step: 13
Training loss: 0.2334285142106172
Validation loss: 2.150650489009684

Epoch: 673| Step: 0
Training loss: 0.23442743032842647
Validation loss: 2.1455248120982375

Epoch: 6| Step: 1
Training loss: 0.21332097085384197
Validation loss: 2.1512129256432915

Epoch: 6| Step: 2
Training loss: 0.15855492811990635
Validation loss: 2.150323992148712

Epoch: 6| Step: 3
Training loss: 0.16078381167485112
Validation loss: 2.175622479277299

Epoch: 6| Step: 4
Training loss: 0.1699601820813003
Validation loss: 2.2331602634058245

Epoch: 6| Step: 5
Training loss: 0.1367090630505538
Validation loss: 2.204713955757959

Epoch: 6| Step: 6
Training loss: 0.19228034994260965
Validation loss: 2.2138084996842764

Epoch: 6| Step: 7
Training loss: 0.11602182789156676
Validation loss: 2.2404253312410254

Epoch: 6| Step: 8
Training loss: 0.19123331354000778
Validation loss: 2.2047828970718326

Epoch: 6| Step: 9
Training loss: 0.17140771460103021
Validation loss: 2.2350759315370348

Epoch: 6| Step: 10
Training loss: 0.2248795087371873
Validation loss: 2.249429958694326

Epoch: 6| Step: 11
Training loss: 0.17642290306214084
Validation loss: 2.2631745582831444

Epoch: 6| Step: 12
Training loss: 0.18259912289299635
Validation loss: 2.2458078327436244

Epoch: 6| Step: 13
Training loss: 0.1562132911476198
Validation loss: 2.2844980166035502

Epoch: 674| Step: 0
Training loss: 0.14297948807377267
Validation loss: 2.2877768722796716

Epoch: 6| Step: 1
Training loss: 0.15282140335326305
Validation loss: 2.2827594290557744

Epoch: 6| Step: 2
Training loss: 0.21019160884365412
Validation loss: 2.2829982752305473

Epoch: 6| Step: 3
Training loss: 0.2364085352270961
Validation loss: 2.26101300243559

Epoch: 6| Step: 4
Training loss: 0.15010984640562644
Validation loss: 2.266736599110605

Epoch: 6| Step: 5
Training loss: 0.21847569774263526
Validation loss: 2.2577789993375417

Epoch: 6| Step: 6
Training loss: 0.19763546446119387
Validation loss: 2.2465719407912887

Epoch: 6| Step: 7
Training loss: 0.1685721625930932
Validation loss: 2.2341096564025413

Epoch: 6| Step: 8
Training loss: 0.21645565501866995
Validation loss: 2.2152879213920893

Epoch: 6| Step: 9
Training loss: 0.16439526733944282
Validation loss: 2.2092080205656424

Epoch: 6| Step: 10
Training loss: 0.11849195526878974
Validation loss: 2.1953370816179927

Epoch: 6| Step: 11
Training loss: 0.19561702829334143
Validation loss: 2.2122432213280354

Epoch: 6| Step: 12
Training loss: 0.14222590168938512
Validation loss: 2.2079544472749153

Epoch: 6| Step: 13
Training loss: 0.1597109803761988
Validation loss: 2.2132302928915037

Epoch: 675| Step: 0
Training loss: 0.19689192169370343
Validation loss: 2.2260998616395993

Epoch: 6| Step: 1
Training loss: 0.09809752899794794
Validation loss: 2.2249140799011853

Epoch: 6| Step: 2
Training loss: 0.12548547585761746
Validation loss: 2.2188549747733033

Epoch: 6| Step: 3
Training loss: 0.1340040442706911
Validation loss: 2.2134171182433056

Epoch: 6| Step: 4
Training loss: 0.12409087472772504
Validation loss: 2.217361260535894

Epoch: 6| Step: 5
Training loss: 0.10904319280088577
Validation loss: 2.2541120342142325

Epoch: 6| Step: 6
Training loss: 0.11950503572972593
Validation loss: 2.2469026195003727

Epoch: 6| Step: 7
Training loss: 0.14598978469127968
Validation loss: 2.265839041223386

Epoch: 6| Step: 8
Training loss: 0.12732990546531722
Validation loss: 2.2306073554838646

Epoch: 6| Step: 9
Training loss: 0.2122149111833493
Validation loss: 2.2333273754704654

Epoch: 6| Step: 10
Training loss: 0.14824092547818088
Validation loss: 2.223566515355026

Epoch: 6| Step: 11
Training loss: 0.139412260078628
Validation loss: 2.234508130373949

Epoch: 6| Step: 12
Training loss: 0.1340275052775554
Validation loss: 2.257034556627946

Epoch: 6| Step: 13
Training loss: 0.24965258390003212
Validation loss: 2.2412857907138934

Epoch: 676| Step: 0
Training loss: 0.1702139744432742
Validation loss: 2.24796423884852

Epoch: 6| Step: 1
Training loss: 0.1325345496801534
Validation loss: 2.2677125119266464

Epoch: 6| Step: 2
Training loss: 0.1752259490274382
Validation loss: 2.249501566216031

Epoch: 6| Step: 3
Training loss: 0.11444711490383366
Validation loss: 2.256829470558028

Epoch: 6| Step: 4
Training loss: 0.12579702550869346
Validation loss: 2.242399920454136

Epoch: 6| Step: 5
Training loss: 0.15225423726244225
Validation loss: 2.2695003204754305

Epoch: 6| Step: 6
Training loss: 0.14090742784229074
Validation loss: 2.239546125083345

Epoch: 6| Step: 7
Training loss: 0.17435070309514986
Validation loss: 2.2430518094728953

Epoch: 6| Step: 8
Training loss: 0.14090140649191343
Validation loss: 2.2280560754331695

Epoch: 6| Step: 9
Training loss: 0.14906954470768052
Validation loss: 2.192569883696781

Epoch: 6| Step: 10
Training loss: 0.11460205127534598
Validation loss: 2.202907807841395

Epoch: 6| Step: 11
Training loss: 0.18158234922732652
Validation loss: 2.180622669567739

Epoch: 6| Step: 12
Training loss: 0.14224724064775382
Validation loss: 2.2017711312809403

Epoch: 6| Step: 13
Training loss: 0.11769845356312206
Validation loss: 2.1970253774907516

Epoch: 677| Step: 0
Training loss: 0.1441435834276072
Validation loss: 2.1916051752438337

Epoch: 6| Step: 1
Training loss: 0.1429145188999703
Validation loss: 2.1934089686084537

Epoch: 6| Step: 2
Training loss: 0.0947410533085651
Validation loss: 2.210598024872167

Epoch: 6| Step: 3
Training loss: 0.14170409469575557
Validation loss: 2.2276747891035074

Epoch: 6| Step: 4
Training loss: 0.19190637294738638
Validation loss: 2.224123161032827

Epoch: 6| Step: 5
Training loss: 0.16999962003749572
Validation loss: 2.2248805620656684

Epoch: 6| Step: 6
Training loss: 0.1241052763049715
Validation loss: 2.2183526327595193

Epoch: 6| Step: 7
Training loss: 0.09819056252281222
Validation loss: 2.2124723901886245

Epoch: 6| Step: 8
Training loss: 0.19677957765432902
Validation loss: 2.1766837780287767

Epoch: 6| Step: 9
Training loss: 0.13250179973315696
Validation loss: 2.232873134931722

Epoch: 6| Step: 10
Training loss: 0.11977805357444261
Validation loss: 2.2072843597614358

Epoch: 6| Step: 11
Training loss: 0.12274896798408962
Validation loss: 2.191478445610502

Epoch: 6| Step: 12
Training loss: 0.1069039342847442
Validation loss: 2.206501794647523

Epoch: 6| Step: 13
Training loss: 0.10744814551512916
Validation loss: 2.193314467336291

Epoch: 678| Step: 0
Training loss: 0.12829104921593568
Validation loss: 2.1897077175386306

Epoch: 6| Step: 1
Training loss: 0.13969800642897803
Validation loss: 2.1822424234570166

Epoch: 6| Step: 2
Training loss: 0.17846050329631075
Validation loss: 2.22254171890434

Epoch: 6| Step: 3
Training loss: 0.17368156169281485
Validation loss: 2.170234373905668

Epoch: 6| Step: 4
Training loss: 0.10854498090583682
Validation loss: 2.19684280159294

Epoch: 6| Step: 5
Training loss: 0.10582242053225062
Validation loss: 2.231846976456958

Epoch: 6| Step: 6
Training loss: 0.1716802208624183
Validation loss: 2.1965005370910906

Epoch: 6| Step: 7
Training loss: 0.09056099921385502
Validation loss: 2.2065923444766953

Epoch: 6| Step: 8
Training loss: 0.14507157904134563
Validation loss: 2.226510221698392

Epoch: 6| Step: 9
Training loss: 0.11058119284996436
Validation loss: 2.210713048337317

Epoch: 6| Step: 10
Training loss: 0.19922664103119944
Validation loss: 2.235713792574144

Epoch: 6| Step: 11
Training loss: 0.12394775123733692
Validation loss: 2.2286781597668526

Epoch: 6| Step: 12
Training loss: 0.11179434879415809
Validation loss: 2.251355274621389

Epoch: 6| Step: 13
Training loss: 0.16754762954492206
Validation loss: 2.223832656395967

Epoch: 679| Step: 0
Training loss: 0.14394265253929742
Validation loss: 2.197544685390178

Epoch: 6| Step: 1
Training loss: 0.1424054184119844
Validation loss: 2.20899804857815

Epoch: 6| Step: 2
Training loss: 0.1593635526921701
Validation loss: 2.2160275979410913

Epoch: 6| Step: 3
Training loss: 0.12801196095388787
Validation loss: 2.191154445187245

Epoch: 6| Step: 4
Training loss: 0.17308014233460337
Validation loss: 2.2067001043526893

Epoch: 6| Step: 5
Training loss: 0.14434178279866677
Validation loss: 2.2301615439586953

Epoch: 6| Step: 6
Training loss: 0.09306325316716808
Validation loss: 2.2336662344965292

Epoch: 6| Step: 7
Training loss: 0.10886339185795953
Validation loss: 2.249174449693981

Epoch: 6| Step: 8
Training loss: 0.10933730633946268
Validation loss: 2.242509926570167

Epoch: 6| Step: 9
Training loss: 0.15027508694343672
Validation loss: 2.254168488801233

Epoch: 6| Step: 10
Training loss: 0.10366631282382376
Validation loss: 2.2430439141311096

Epoch: 6| Step: 11
Training loss: 0.11002985723827978
Validation loss: 2.24320052198162

Epoch: 6| Step: 12
Training loss: 0.12338628204289676
Validation loss: 2.235671138091992

Epoch: 6| Step: 13
Training loss: 0.22092581797663446
Validation loss: 2.2337090018648142

Epoch: 680| Step: 0
Training loss: 0.14997139002230397
Validation loss: 2.238143984552103

Epoch: 6| Step: 1
Training loss: 0.15874946119186997
Validation loss: 2.2551831405980485

Epoch: 6| Step: 2
Training loss: 0.14980442191327958
Validation loss: 2.1903930354941017

Epoch: 6| Step: 3
Training loss: 0.08849251542258357
Validation loss: 2.190063482817777

Epoch: 6| Step: 4
Training loss: 0.10222235315655417
Validation loss: 2.2003802474062955

Epoch: 6| Step: 5
Training loss: 0.11192435671611035
Validation loss: 2.2348762286764834

Epoch: 6| Step: 6
Training loss: 0.18425294545781265
Validation loss: 2.2250680009286476

Epoch: 6| Step: 7
Training loss: 0.13282377531771172
Validation loss: 2.2323825844100087

Epoch: 6| Step: 8
Training loss: 0.1238221840982671
Validation loss: 2.173450129267269

Epoch: 6| Step: 9
Training loss: 0.10981491719746178
Validation loss: 2.2094973756219463

Epoch: 6| Step: 10
Training loss: 0.12861502869967806
Validation loss: 2.1871608101995816

Epoch: 6| Step: 11
Training loss: 0.09798258615283402
Validation loss: 2.1975015017695547

Epoch: 6| Step: 12
Training loss: 0.14683319521548213
Validation loss: 2.186029477271843

Epoch: 6| Step: 13
Training loss: 0.07888448622798887
Validation loss: 2.203475501866529

Epoch: 681| Step: 0
Training loss: 0.10621197963398346
Validation loss: 2.221262321587801

Epoch: 6| Step: 1
Training loss: 0.18445033255906707
Validation loss: 2.2362941649267976

Epoch: 6| Step: 2
Training loss: 0.14463137689575573
Validation loss: 2.2110035502813132

Epoch: 6| Step: 3
Training loss: 0.08853622786796754
Validation loss: 2.2209905599863604

Epoch: 6| Step: 4
Training loss: 0.1623281243912053
Validation loss: 2.2186350881516317

Epoch: 6| Step: 5
Training loss: 0.14685102353304308
Validation loss: 2.1990366919587556

Epoch: 6| Step: 6
Training loss: 0.11963595155483715
Validation loss: 2.2337542072409415

Epoch: 6| Step: 7
Training loss: 0.1208630332812314
Validation loss: 2.189477841484726

Epoch: 6| Step: 8
Training loss: 0.1344149976352488
Validation loss: 2.209131525736922

Epoch: 6| Step: 9
Training loss: 0.10601801369884808
Validation loss: 2.2112134477689365

Epoch: 6| Step: 10
Training loss: 0.11111040744293768
Validation loss: 2.210434053960042

Epoch: 6| Step: 11
Training loss: 0.10412565457114269
Validation loss: 2.211410699669213

Epoch: 6| Step: 12
Training loss: 0.10544003872904424
Validation loss: 2.2422480015314954

Epoch: 6| Step: 13
Training loss: 0.07664602295164813
Validation loss: 2.220236560312964

Epoch: 682| Step: 0
Training loss: 0.089651077414478
Validation loss: 2.2243609808265625

Epoch: 6| Step: 1
Training loss: 0.1256839325373425
Validation loss: 2.2471002912395357

Epoch: 6| Step: 2
Training loss: 0.10500260053263946
Validation loss: 2.2360712811225367

Epoch: 6| Step: 3
Training loss: 0.12088274260717194
Validation loss: 2.2283190646417177

Epoch: 6| Step: 4
Training loss: 0.13019871119868118
Validation loss: 2.2416234752835145

Epoch: 6| Step: 5
Training loss: 0.1061685884849841
Validation loss: 2.248218444906783

Epoch: 6| Step: 6
Training loss: 0.07049207141819736
Validation loss: 2.2319476022595537

Epoch: 6| Step: 7
Training loss: 0.1036719859696853
Validation loss: 2.2252935438053805

Epoch: 6| Step: 8
Training loss: 0.11892469960392889
Validation loss: 2.2448053383599436

Epoch: 6| Step: 9
Training loss: 0.16203116058266212
Validation loss: 2.243008529903473

Epoch: 6| Step: 10
Training loss: 0.09653634223985891
Validation loss: 2.2203181610770755

Epoch: 6| Step: 11
Training loss: 0.07863912986718832
Validation loss: 2.2204042605653376

Epoch: 6| Step: 12
Training loss: 0.12228222572801117
Validation loss: 2.2318649368835066

Epoch: 6| Step: 13
Training loss: 0.12974518819984215
Validation loss: 2.2120861486079004

Epoch: 683| Step: 0
Training loss: 0.09577261095462826
Validation loss: 2.2130728343953168

Epoch: 6| Step: 1
Training loss: 0.09311046118021898
Validation loss: 2.181500077038609

Epoch: 6| Step: 2
Training loss: 0.06814515403556999
Validation loss: 2.172364595308753

Epoch: 6| Step: 3
Training loss: 0.09255387274250769
Validation loss: 2.1756895892913057

Epoch: 6| Step: 4
Training loss: 0.10479948278293351
Validation loss: 2.1998149069851896

Epoch: 6| Step: 5
Training loss: 0.12452953809497225
Validation loss: 2.207716246339652

Epoch: 6| Step: 6
Training loss: 0.11266313652174927
Validation loss: 2.2114537142755304

Epoch: 6| Step: 7
Training loss: 0.07935618111311564
Validation loss: 2.214648658610026

Epoch: 6| Step: 8
Training loss: 0.10179675577966203
Validation loss: 2.1848511569131612

Epoch: 6| Step: 9
Training loss: 0.1340738731619666
Validation loss: 2.2395826863895825

Epoch: 6| Step: 10
Training loss: 0.1374375656738402
Validation loss: 2.224795517898991

Epoch: 6| Step: 11
Training loss: 0.10606890367099284
Validation loss: 2.238695507158976

Epoch: 6| Step: 12
Training loss: 0.09139668708075278
Validation loss: 2.225681063538583

Epoch: 6| Step: 13
Training loss: 0.11434447026319114
Validation loss: 2.217386634505936

Epoch: 684| Step: 0
Training loss: 0.1167380057005034
Validation loss: 2.244163627659771

Epoch: 6| Step: 1
Training loss: 0.10424297240009724
Validation loss: 2.2093239797161877

Epoch: 6| Step: 2
Training loss: 0.13805273350156422
Validation loss: 2.2460492826378555

Epoch: 6| Step: 3
Training loss: 0.08853329824656152
Validation loss: 2.2090510709009843

Epoch: 6| Step: 4
Training loss: 0.10028346888671989
Validation loss: 2.210922993116284

Epoch: 6| Step: 5
Training loss: 0.1472181696535193
Validation loss: 2.217161127033461

Epoch: 6| Step: 6
Training loss: 0.11797374973691567
Validation loss: 2.2079228389019527

Epoch: 6| Step: 7
Training loss: 0.10262050119429113
Validation loss: 2.2096022469867447

Epoch: 6| Step: 8
Training loss: 0.138102315446722
Validation loss: 2.1996731555414373

Epoch: 6| Step: 9
Training loss: 0.07771548288412797
Validation loss: 2.2173016801208787

Epoch: 6| Step: 10
Training loss: 0.07158815011677955
Validation loss: 2.201335288554489

Epoch: 6| Step: 11
Training loss: 0.11649431411381042
Validation loss: 2.1842454059011223

Epoch: 6| Step: 12
Training loss: 0.1017711129163548
Validation loss: 2.1813077261823723

Epoch: 6| Step: 13
Training loss: 0.0973346134248517
Validation loss: 2.1850594226576416

Epoch: 685| Step: 0
Training loss: 0.12217389861549667
Validation loss: 2.184727225490354

Epoch: 6| Step: 1
Training loss: 0.13786094254198417
Validation loss: 2.1909775979249164

Epoch: 6| Step: 2
Training loss: 0.10975523828255555
Validation loss: 2.1988053433531256

Epoch: 6| Step: 3
Training loss: 0.1042544878861567
Validation loss: 2.2219445852006414

Epoch: 6| Step: 4
Training loss: 0.0977267868883535
Validation loss: 2.187516806870454

Epoch: 6| Step: 5
Training loss: 0.1002335858258216
Validation loss: 2.202646348224645

Epoch: 6| Step: 6
Training loss: 0.06603769097234684
Validation loss: 2.2181842492266477

Epoch: 6| Step: 7
Training loss: 0.16318680162547006
Validation loss: 2.213991691305868

Epoch: 6| Step: 8
Training loss: 0.10978706259125122
Validation loss: 2.2333411020386555

Epoch: 6| Step: 9
Training loss: 0.13471259580327197
Validation loss: 2.238174162459832

Epoch: 6| Step: 10
Training loss: 0.1066191854339345
Validation loss: 2.240571820426102

Epoch: 6| Step: 11
Training loss: 0.12081347994720236
Validation loss: 2.2257360853644066

Epoch: 6| Step: 12
Training loss: 0.09625001274145958
Validation loss: 2.2363285296655997

Epoch: 6| Step: 13
Training loss: 0.15369657645701745
Validation loss: 2.2114411131286364

Epoch: 686| Step: 0
Training loss: 0.10779263064522723
Validation loss: 2.2476892815987393

Epoch: 6| Step: 1
Training loss: 0.1436382491654829
Validation loss: 2.2379026789518126

Epoch: 6| Step: 2
Training loss: 0.09882380623107286
Validation loss: 2.2032552514940056

Epoch: 6| Step: 3
Training loss: 0.12436074472328
Validation loss: 2.223194022582827

Epoch: 6| Step: 4
Training loss: 0.18322316773833933
Validation loss: 2.222991547246577

Epoch: 6| Step: 5
Training loss: 0.17299858134093213
Validation loss: 2.2327782188591203

Epoch: 6| Step: 6
Training loss: 0.13268388803986073
Validation loss: 2.1992323123548156

Epoch: 6| Step: 7
Training loss: 0.12695008787777126
Validation loss: 2.2321105377623294

Epoch: 6| Step: 8
Training loss: 0.10197996575461657
Validation loss: 2.1971222733162588

Epoch: 6| Step: 9
Training loss: 0.07877664887638261
Validation loss: 2.21355737515304

Epoch: 6| Step: 10
Training loss: 0.0888289694297196
Validation loss: 2.2216879357048827

Epoch: 6| Step: 11
Training loss: 0.09047898890973158
Validation loss: 2.2352279043767664

Epoch: 6| Step: 12
Training loss: 0.13608257236850005
Validation loss: 2.199971038547559

Epoch: 6| Step: 13
Training loss: 0.12911471936104726
Validation loss: 2.222862996586964

Epoch: 687| Step: 0
Training loss: 0.08836408880799072
Validation loss: 2.212127640609972

Epoch: 6| Step: 1
Training loss: 0.10700315886473817
Validation loss: 2.2077709901392133

Epoch: 6| Step: 2
Training loss: 0.06748599983435553
Validation loss: 2.215837673365698

Epoch: 6| Step: 3
Training loss: 0.09808061900545109
Validation loss: 2.2117129318744917

Epoch: 6| Step: 4
Training loss: 0.07254392288186093
Validation loss: 2.190376736413644

Epoch: 6| Step: 5
Training loss: 0.10008811905248896
Validation loss: 2.221825571662616

Epoch: 6| Step: 6
Training loss: 0.11534558199639687
Validation loss: 2.2020002612802028

Epoch: 6| Step: 7
Training loss: 0.06961206738138395
Validation loss: 2.2077964531377514

Epoch: 6| Step: 8
Training loss: 0.06893410902338186
Validation loss: 2.2092021882154413

Epoch: 6| Step: 9
Training loss: 0.15236735161111017
Validation loss: 2.2311343192853523

Epoch: 6| Step: 10
Training loss: 0.1141095952566362
Validation loss: 2.205493585549011

Epoch: 6| Step: 11
Training loss: 0.08171218742693341
Validation loss: 2.2084484832640583

Epoch: 6| Step: 12
Training loss: 0.12882359340000862
Validation loss: 2.217894287879873

Epoch: 6| Step: 13
Training loss: 0.11766060062485499
Validation loss: 2.203167945689354

Epoch: 688| Step: 0
Training loss: 0.10489846508786882
Validation loss: 2.195841085410897

Epoch: 6| Step: 1
Training loss: 0.10163901271318328
Validation loss: 2.191165985406546

Epoch: 6| Step: 2
Training loss: 0.13074274701812802
Validation loss: 2.1960495609315913

Epoch: 6| Step: 3
Training loss: 0.1377971759372846
Validation loss: 2.1952023908257416

Epoch: 6| Step: 4
Training loss: 0.11762716151591551
Validation loss: 2.178544289438452

Epoch: 6| Step: 5
Training loss: 0.11075727605545163
Validation loss: 2.191075727652331

Epoch: 6| Step: 6
Training loss: 0.06720793532495391
Validation loss: 2.189638722483528

Epoch: 6| Step: 7
Training loss: 0.11821115359354087
Validation loss: 2.2402661880568955

Epoch: 6| Step: 8
Training loss: 0.12007203843048278
Validation loss: 2.2009488245796387

Epoch: 6| Step: 9
Training loss: 0.08153274609109468
Validation loss: 2.190761785285991

Epoch: 6| Step: 10
Training loss: 0.19239343333094186
Validation loss: 2.203924157044151

Epoch: 6| Step: 11
Training loss: 0.09281603186723586
Validation loss: 2.1853428038201868

Epoch: 6| Step: 12
Training loss: 0.11445941826375383
Validation loss: 2.2048180738693057

Epoch: 6| Step: 13
Training loss: 0.07453233576129686
Validation loss: 2.200549656013644

Epoch: 689| Step: 0
Training loss: 0.12986571694205667
Validation loss: 2.226037435575437

Epoch: 6| Step: 1
Training loss: 0.10639280371494714
Validation loss: 2.191032810258708

Epoch: 6| Step: 2
Training loss: 0.0924711774611849
Validation loss: 2.1972593829249747

Epoch: 6| Step: 3
Training loss: 0.10821536215293882
Validation loss: 2.1795141790935886

Epoch: 6| Step: 4
Training loss: 0.09963044710356865
Validation loss: 2.201623167793608

Epoch: 6| Step: 5
Training loss: 0.1134879142677304
Validation loss: 2.222158177561254

Epoch: 6| Step: 6
Training loss: 0.08371164985118676
Validation loss: 2.192308043048992

Epoch: 6| Step: 7
Training loss: 0.0866058838359343
Validation loss: 2.187689419937903

Epoch: 6| Step: 8
Training loss: 0.10734998725139025
Validation loss: 2.1991747033896005

Epoch: 6| Step: 9
Training loss: 0.09917094945257826
Validation loss: 2.197436072298042

Epoch: 6| Step: 10
Training loss: 0.08023946488717644
Validation loss: 2.1996848427868505

Epoch: 6| Step: 11
Training loss: 0.12273677472707291
Validation loss: 2.2135795519564763

Epoch: 6| Step: 12
Training loss: 0.11939563974733002
Validation loss: 2.217818848627024

Epoch: 6| Step: 13
Training loss: 0.10197678762738525
Validation loss: 2.2315765302786357

Epoch: 690| Step: 0
Training loss: 0.11929384525626234
Validation loss: 2.216680534215173

Epoch: 6| Step: 1
Training loss: 0.12283216013926646
Validation loss: 2.2233936937606757

Epoch: 6| Step: 2
Training loss: 0.1138340476477872
Validation loss: 2.2219148647201115

Epoch: 6| Step: 3
Training loss: 0.07868737525964141
Validation loss: 2.229322977904231

Epoch: 6| Step: 4
Training loss: 0.08214839450075019
Validation loss: 2.243056367454313

Epoch: 6| Step: 5
Training loss: 0.09446237040817863
Validation loss: 2.207482372703128

Epoch: 6| Step: 6
Training loss: 0.10523741571158175
Validation loss: 2.220281165923163

Epoch: 6| Step: 7
Training loss: 0.1077445472578917
Validation loss: 2.223425657841102

Epoch: 6| Step: 8
Training loss: 0.08480548339041544
Validation loss: 2.2297575706718007

Epoch: 6| Step: 9
Training loss: 0.12496427681203372
Validation loss: 2.2353997193064603

Epoch: 6| Step: 10
Training loss: 0.0765643340981008
Validation loss: 2.2459250366707244

Epoch: 6| Step: 11
Training loss: 0.11010662679110282
Validation loss: 2.2075514354335977

Epoch: 6| Step: 12
Training loss: 0.08668266525070391
Validation loss: 2.216791885440472

Epoch: 6| Step: 13
Training loss: 0.06786634922596722
Validation loss: 2.1905602342214974

Epoch: 691| Step: 0
Training loss: 0.12679134477882045
Validation loss: 2.218346013182788

Epoch: 6| Step: 1
Training loss: 0.10352892160488869
Validation loss: 2.2063437937998476

Epoch: 6| Step: 2
Training loss: 0.09406072066769107
Validation loss: 2.202426532917157

Epoch: 6| Step: 3
Training loss: 0.06633621267046681
Validation loss: 2.214569987552028

Epoch: 6| Step: 4
Training loss: 0.10957973766078535
Validation loss: 2.224975136395256

Epoch: 6| Step: 5
Training loss: 0.10637441076155833
Validation loss: 2.205439802915588

Epoch: 6| Step: 6
Training loss: 0.09216029687160204
Validation loss: 2.245624167928259

Epoch: 6| Step: 7
Training loss: 0.1380335259149532
Validation loss: 2.244211269809532

Epoch: 6| Step: 8
Training loss: 0.1349907804802489
Validation loss: 2.2330256239172335

Epoch: 6| Step: 9
Training loss: 0.1423866998798527
Validation loss: 2.2435988942356015

Epoch: 6| Step: 10
Training loss: 0.10125454651079124
Validation loss: 2.247585962513989

Epoch: 6| Step: 11
Training loss: 0.11250488432904124
Validation loss: 2.233487826871618

Epoch: 6| Step: 12
Training loss: 0.09532997799697929
Validation loss: 2.2482031012798003

Epoch: 6| Step: 13
Training loss: 0.09801529208485081
Validation loss: 2.2512078057153397

Epoch: 692| Step: 0
Training loss: 0.10946813092504541
Validation loss: 2.2413010733190366

Epoch: 6| Step: 1
Training loss: 0.10983245417113285
Validation loss: 2.2539339249927686

Epoch: 6| Step: 2
Training loss: 0.130563001795161
Validation loss: 2.2185782222062964

Epoch: 6| Step: 3
Training loss: 0.12318231682080034
Validation loss: 2.221057958412887

Epoch: 6| Step: 4
Training loss: 0.12489891435271216
Validation loss: 2.2550274473423966

Epoch: 6| Step: 5
Training loss: 0.13658761138405268
Validation loss: 2.2257294912023777

Epoch: 6| Step: 6
Training loss: 0.11302150346700875
Validation loss: 2.221478633228061

Epoch: 6| Step: 7
Training loss: 0.11955466789031564
Validation loss: 2.1978866280775247

Epoch: 6| Step: 8
Training loss: 0.0666161473657061
Validation loss: 2.183138228792537

Epoch: 6| Step: 9
Training loss: 0.09851694382972905
Validation loss: 2.1904281270869386

Epoch: 6| Step: 10
Training loss: 0.07973064068274882
Validation loss: 2.205965721097991

Epoch: 6| Step: 11
Training loss: 0.09259890653051384
Validation loss: 2.1892603598646896

Epoch: 6| Step: 12
Training loss: 0.0984836290525825
Validation loss: 2.205619704594965

Epoch: 6| Step: 13
Training loss: 0.1249462511316813
Validation loss: 2.21284663040768

Epoch: 693| Step: 0
Training loss: 0.1685821787051283
Validation loss: 2.203020611025694

Epoch: 6| Step: 1
Training loss: 0.10349448006072562
Validation loss: 2.2037140073367136

Epoch: 6| Step: 2
Training loss: 0.14641969524393839
Validation loss: 2.2142377614236493

Epoch: 6| Step: 3
Training loss: 0.10774625871717128
Validation loss: 2.1726748773798357

Epoch: 6| Step: 4
Training loss: 0.10316275335432387
Validation loss: 2.2003947731157325

Epoch: 6| Step: 5
Training loss: 0.08692966813990355
Validation loss: 2.1944051791568424

Epoch: 6| Step: 6
Training loss: 0.08960754504908627
Validation loss: 2.2050019263798872

Epoch: 6| Step: 7
Training loss: 0.06567036786234434
Validation loss: 2.20357351363855

Epoch: 6| Step: 8
Training loss: 0.10148441540817854
Validation loss: 2.2013445644493275

Epoch: 6| Step: 9
Training loss: 0.08187052614878088
Validation loss: 2.212754131748475

Epoch: 6| Step: 10
Training loss: 0.09684919659690477
Validation loss: 2.191264478152466

Epoch: 6| Step: 11
Training loss: 0.0977719860906467
Validation loss: 2.217228410618249

Epoch: 6| Step: 12
Training loss: 0.09733283849703622
Validation loss: 2.202847801590406

Epoch: 6| Step: 13
Training loss: 0.09479087927075565
Validation loss: 2.2302762079137852

Epoch: 694| Step: 0
Training loss: 0.08558238960130844
Validation loss: 2.2102330681891034

Epoch: 6| Step: 1
Training loss: 0.13817423866335543
Validation loss: 2.225213815030265

Epoch: 6| Step: 2
Training loss: 0.09787788037194363
Validation loss: 2.248620560664093

Epoch: 6| Step: 3
Training loss: 0.1349259266247754
Validation loss: 2.247728413405346

Epoch: 6| Step: 4
Training loss: 0.08717190076544204
Validation loss: 2.218386755393473

Epoch: 6| Step: 5
Training loss: 0.12274069764322833
Validation loss: 2.223605800890473

Epoch: 6| Step: 6
Training loss: 0.08247453263980883
Validation loss: 2.2284659326153853

Epoch: 6| Step: 7
Training loss: 0.11709171990425803
Validation loss: 2.2174842860441326

Epoch: 6| Step: 8
Training loss: 0.12067052499711682
Validation loss: 2.235330290395175

Epoch: 6| Step: 9
Training loss: 0.09531325121098888
Validation loss: 2.240379240338676

Epoch: 6| Step: 10
Training loss: 0.1351701773374946
Validation loss: 2.2530454911876676

Epoch: 6| Step: 11
Training loss: 0.1066844816817286
Validation loss: 2.2486549171587895

Epoch: 6| Step: 12
Training loss: 0.08683749372981422
Validation loss: 2.25365665299465

Epoch: 6| Step: 13
Training loss: 0.10008354552759587
Validation loss: 2.261179720695494

Epoch: 695| Step: 0
Training loss: 0.08077223523639236
Validation loss: 2.241568369947404

Epoch: 6| Step: 1
Training loss: 0.09608821368357492
Validation loss: 2.2735960758172045

Epoch: 6| Step: 2
Training loss: 0.11435467942093303
Validation loss: 2.2355205577536714

Epoch: 6| Step: 3
Training loss: 0.10337591640084677
Validation loss: 2.238703102921523

Epoch: 6| Step: 4
Training loss: 0.06139811550805395
Validation loss: 2.21505186233873

Epoch: 6| Step: 5
Training loss: 0.087294416015402
Validation loss: 2.1987562206637157

Epoch: 6| Step: 6
Training loss: 0.1136388150541361
Validation loss: 2.2249275322920914

Epoch: 6| Step: 7
Training loss: 0.16454466856517772
Validation loss: 2.230066825161216

Epoch: 6| Step: 8
Training loss: 0.1030164504959079
Validation loss: 2.25320485020649

Epoch: 6| Step: 9
Training loss: 0.0925729039888891
Validation loss: 2.2213021839617966

Epoch: 6| Step: 10
Training loss: 0.1252099375283506
Validation loss: 2.235236909446838

Epoch: 6| Step: 11
Training loss: 0.10095630900101953
Validation loss: 2.221432868763477

Epoch: 6| Step: 12
Training loss: 0.09994389890030263
Validation loss: 2.267029321030827

Epoch: 6| Step: 13
Training loss: 0.09223115945917452
Validation loss: 2.245523676066874

Epoch: 696| Step: 0
Training loss: 0.1088981152031703
Validation loss: 2.255934942207064

Epoch: 6| Step: 1
Training loss: 0.12473393227021862
Validation loss: 2.24478817583004

Epoch: 6| Step: 2
Training loss: 0.11488443922144764
Validation loss: 2.236012226195026

Epoch: 6| Step: 3
Training loss: 0.10914165434901471
Validation loss: 2.2496366275797097

Epoch: 6| Step: 4
Training loss: 0.11528574073515895
Validation loss: 2.2438986338356033

Epoch: 6| Step: 5
Training loss: 0.06209177946569406
Validation loss: 2.2093001539321127

Epoch: 6| Step: 6
Training loss: 0.10455373484435393
Validation loss: 2.239278726736925

Epoch: 6| Step: 7
Training loss: 0.07936071400602758
Validation loss: 2.2129772909193566

Epoch: 6| Step: 8
Training loss: 0.09799740329715473
Validation loss: 2.193611296597497

Epoch: 6| Step: 9
Training loss: 0.10125798184375011
Validation loss: 2.223698016474698

Epoch: 6| Step: 10
Training loss: 0.09301070440731825
Validation loss: 2.2211859071827456

Epoch: 6| Step: 11
Training loss: 0.07969157907386724
Validation loss: 2.209626046599194

Epoch: 6| Step: 12
Training loss: 0.11700334384309154
Validation loss: 2.2150694416034686

Epoch: 6| Step: 13
Training loss: 0.06065734852226493
Validation loss: 2.1889731022096512

Epoch: 697| Step: 0
Training loss: 0.10231347018307957
Validation loss: 2.1867464118178086

Epoch: 6| Step: 1
Training loss: 0.1001025687152031
Validation loss: 2.2266664887665786

Epoch: 6| Step: 2
Training loss: 0.08488049206412514
Validation loss: 2.2021538880638207

Epoch: 6| Step: 3
Training loss: 0.09840620088258052
Validation loss: 2.207962994935371

Epoch: 6| Step: 4
Training loss: 0.07681943055772361
Validation loss: 2.1920123694124527

Epoch: 6| Step: 5
Training loss: 0.07615667277024282
Validation loss: 2.2226963664958714

Epoch: 6| Step: 6
Training loss: 0.09382671455987567
Validation loss: 2.1995654103857074

Epoch: 6| Step: 7
Training loss: 0.07546902049353797
Validation loss: 2.20525744760901

Epoch: 6| Step: 8
Training loss: 0.10375925400551714
Validation loss: 2.2115642813336143

Epoch: 6| Step: 9
Training loss: 0.08859726501905904
Validation loss: 2.2182969308550895

Epoch: 6| Step: 10
Training loss: 0.11414229838262796
Validation loss: 2.2029573366135518

Epoch: 6| Step: 11
Training loss: 0.10619615564886485
Validation loss: 2.205146263798655

Epoch: 6| Step: 12
Training loss: 0.11992020077732672
Validation loss: 2.2296042539452534

Epoch: 6| Step: 13
Training loss: 0.12370092028601835
Validation loss: 2.2250130057890947

Epoch: 698| Step: 0
Training loss: 0.05312238662266224
Validation loss: 2.23224793648851

Epoch: 6| Step: 1
Training loss: 0.09938261456526454
Validation loss: 2.2307867381628363

Epoch: 6| Step: 2
Training loss: 0.07067372661929598
Validation loss: 2.2383420220435037

Epoch: 6| Step: 3
Training loss: 0.11377285882888717
Validation loss: 2.2418082477716728

Epoch: 6| Step: 4
Training loss: 0.12203359051534533
Validation loss: 2.2588515787682644

Epoch: 6| Step: 5
Training loss: 0.0928206273575981
Validation loss: 2.254084743551512

Epoch: 6| Step: 6
Training loss: 0.12357316167580376
Validation loss: 2.198670142692522

Epoch: 6| Step: 7
Training loss: 0.10877044097169242
Validation loss: 2.182033015314334

Epoch: 6| Step: 8
Training loss: 0.08118383620528384
Validation loss: 2.188943500321463

Epoch: 6| Step: 9
Training loss: 0.09593491802406716
Validation loss: 2.1785678040728698

Epoch: 6| Step: 10
Training loss: 0.13586560134703235
Validation loss: 2.186731370465827

Epoch: 6| Step: 11
Training loss: 0.11636315322444296
Validation loss: 2.181851554221044

Epoch: 6| Step: 12
Training loss: 0.13032863940091816
Validation loss: 2.1695462124843736

Epoch: 6| Step: 13
Training loss: 0.15368196633682502
Validation loss: 2.190897163887577

Epoch: 699| Step: 0
Training loss: 0.10036028392367684
Validation loss: 2.1833431987951313

Epoch: 6| Step: 1
Training loss: 0.1304443239429432
Validation loss: 2.191814506317251

Epoch: 6| Step: 2
Training loss: 0.10072882234888622
Validation loss: 2.172772877415946

Epoch: 6| Step: 3
Training loss: 0.1026612099228795
Validation loss: 2.2010921576627416

Epoch: 6| Step: 4
Training loss: 0.12995752179329767
Validation loss: 2.2122867354218734

Epoch: 6| Step: 5
Training loss: 0.10211437926693107
Validation loss: 2.2155380397882416

Epoch: 6| Step: 6
Training loss: 0.12758960365053487
Validation loss: 2.2039373606735007

Epoch: 6| Step: 7
Training loss: 0.07119209082526794
Validation loss: 2.249658878906379

Epoch: 6| Step: 8
Training loss: 0.10866968052593418
Validation loss: 2.21509871229165

Epoch: 6| Step: 9
Training loss: 0.08749461498038666
Validation loss: 2.244390525252788

Epoch: 6| Step: 10
Training loss: 0.09649667854473154
Validation loss: 2.2351635861442976

Epoch: 6| Step: 11
Training loss: 0.0956267421850434
Validation loss: 2.2526549907875646

Epoch: 6| Step: 12
Training loss: 0.11735235380791362
Validation loss: 2.233837643348838

Epoch: 6| Step: 13
Training loss: 0.09710958058833413
Validation loss: 2.232010712399304

Epoch: 700| Step: 0
Training loss: 0.12389434644229058
Validation loss: 2.2049884611332944

Epoch: 6| Step: 1
Training loss: 0.07562165340593052
Validation loss: 2.2528738334280822

Epoch: 6| Step: 2
Training loss: 0.09577566433934792
Validation loss: 2.241194258756125

Epoch: 6| Step: 3
Training loss: 0.11601335895778511
Validation loss: 2.192731640928884

Epoch: 6| Step: 4
Training loss: 0.08860280985484378
Validation loss: 2.208018664948074

Epoch: 6| Step: 5
Training loss: 0.05760454588748581
Validation loss: 2.2008735336705967

Epoch: 6| Step: 6
Training loss: 0.07674391234823652
Validation loss: 2.222736707751803

Epoch: 6| Step: 7
Training loss: 0.10007566349983875
Validation loss: 2.2218103512511287

Epoch: 6| Step: 8
Training loss: 0.131073243182023
Validation loss: 2.2609203281815344

Epoch: 6| Step: 9
Training loss: 0.07788583087898157
Validation loss: 2.193803230104719

Epoch: 6| Step: 10
Training loss: 0.11347782410069708
Validation loss: 2.222307071333866

Epoch: 6| Step: 11
Training loss: 0.1301769496925382
Validation loss: 2.251356929166328

Epoch: 6| Step: 12
Training loss: 0.10376553238943706
Validation loss: 2.240147602018507

Epoch: 6| Step: 13
Training loss: 0.12667200802167528
Validation loss: 2.2453998622750673

Epoch: 701| Step: 0
Training loss: 0.11295170369153085
Validation loss: 2.251624081231706

Epoch: 6| Step: 1
Training loss: 0.11757902861086346
Validation loss: 2.1923828791523716

Epoch: 6| Step: 2
Training loss: 0.05749194425992003
Validation loss: 2.2297466958330285

Epoch: 6| Step: 3
Training loss: 0.1556724364207305
Validation loss: 2.1989267226354903

Epoch: 6| Step: 4
Training loss: 0.1407608859187218
Validation loss: 2.2371912982232574

Epoch: 6| Step: 5
Training loss: 0.07288798516022403
Validation loss: 2.2144450624455945

Epoch: 6| Step: 6
Training loss: 0.12539333804038688
Validation loss: 2.209582911135685

Epoch: 6| Step: 7
Training loss: 0.12229281936564737
Validation loss: 2.2462698964320253

Epoch: 6| Step: 8
Training loss: 0.10827774769484623
Validation loss: 2.2179854209563006

Epoch: 6| Step: 9
Training loss: 0.0832803934913879
Validation loss: 2.229174548577846

Epoch: 6| Step: 10
Training loss: 0.07584760184619321
Validation loss: 2.2219596893151707

Epoch: 6| Step: 11
Training loss: 0.07932204847597504
Validation loss: 2.2017188203174647

Epoch: 6| Step: 12
Training loss: 0.09527652894213158
Validation loss: 2.2133671957574403

Epoch: 6| Step: 13
Training loss: 0.06933140739900877
Validation loss: 2.225045683998877

Epoch: 702| Step: 0
Training loss: 0.06734414304100808
Validation loss: 2.2189895590681115

Epoch: 6| Step: 1
Training loss: 0.06963252717563889
Validation loss: 2.2323600701561994

Epoch: 6| Step: 2
Training loss: 0.08315042138378553
Validation loss: 2.2023172962679958

Epoch: 6| Step: 3
Training loss: 0.09793313827186582
Validation loss: 2.2319437802515862

Epoch: 6| Step: 4
Training loss: 0.14045126434860816
Validation loss: 2.2452724455754876

Epoch: 6| Step: 5
Training loss: 0.08029979171102405
Validation loss: 2.212349975924165

Epoch: 6| Step: 6
Training loss: 0.08366720891367323
Validation loss: 2.2287578140738438

Epoch: 6| Step: 7
Training loss: 0.10989879458024951
Validation loss: 2.206288726419348

Epoch: 6| Step: 8
Training loss: 0.0903142911657492
Validation loss: 2.2194108084406827

Epoch: 6| Step: 9
Training loss: 0.09074916924406383
Validation loss: 2.26466391790097

Epoch: 6| Step: 10
Training loss: 0.0863953553000193
Validation loss: 2.235025540797095

Epoch: 6| Step: 11
Training loss: 0.08608806490084808
Validation loss: 2.2239623031663394

Epoch: 6| Step: 12
Training loss: 0.1066266536293731
Validation loss: 2.246467879471887

Epoch: 6| Step: 13
Training loss: 0.11577070823998128
Validation loss: 2.256084698622897

Epoch: 703| Step: 0
Training loss: 0.09108208800041406
Validation loss: 2.2199394692377314

Epoch: 6| Step: 1
Training loss: 0.0659443096231055
Validation loss: 2.2533504761771113

Epoch: 6| Step: 2
Training loss: 0.09646236674466531
Validation loss: 2.236811917500456

Epoch: 6| Step: 3
Training loss: 0.06434929315924261
Validation loss: 2.2287723509537534

Epoch: 6| Step: 4
Training loss: 0.12391367884009474
Validation loss: 2.2448794756010515

Epoch: 6| Step: 5
Training loss: 0.12000509009145661
Validation loss: 2.2363151057336754

Epoch: 6| Step: 6
Training loss: 0.0996898391577744
Validation loss: 2.213230384109619

Epoch: 6| Step: 7
Training loss: 0.10432303186376302
Validation loss: 2.216268953011517

Epoch: 6| Step: 8
Training loss: 0.11992360620149935
Validation loss: 2.2325216900164424

Epoch: 6| Step: 9
Training loss: 0.0752616874242151
Validation loss: 2.201131515292335

Epoch: 6| Step: 10
Training loss: 0.05020183342757222
Validation loss: 2.217722199315827

Epoch: 6| Step: 11
Training loss: 0.12539556618340023
Validation loss: 2.182193327944148

Epoch: 6| Step: 12
Training loss: 0.07717865340119964
Validation loss: 2.2214680207939628

Epoch: 6| Step: 13
Training loss: 0.06414883483217315
Validation loss: 2.2040788465959467

Epoch: 704| Step: 0
Training loss: 0.0729388216823591
Validation loss: 2.25460680165528

Epoch: 6| Step: 1
Training loss: 0.08643518816944942
Validation loss: 2.21347373283902

Epoch: 6| Step: 2
Training loss: 0.08638434575232899
Validation loss: 2.2160954654345573

Epoch: 6| Step: 3
Training loss: 0.0924993078908287
Validation loss: 2.2107351191559927

Epoch: 6| Step: 4
Training loss: 0.1380271430342702
Validation loss: 2.227571754291018

Epoch: 6| Step: 5
Training loss: 0.06996376591518255
Validation loss: 2.2249169962251254

Epoch: 6| Step: 6
Training loss: 0.08337369949478955
Validation loss: 2.214313944396622

Epoch: 6| Step: 7
Training loss: 0.07068990707662758
Validation loss: 2.222381157814362

Epoch: 6| Step: 8
Training loss: 0.10570554289269203
Validation loss: 2.222279699113781

Epoch: 6| Step: 9
Training loss: 0.10747346072924828
Validation loss: 2.2338617780801524

Epoch: 6| Step: 10
Training loss: 0.12738658559031366
Validation loss: 2.2172136593026557

Epoch: 6| Step: 11
Training loss: 0.11222435939444098
Validation loss: 2.2176527157882213

Epoch: 6| Step: 12
Training loss: 0.10919082410787728
Validation loss: 2.217698621839637

Epoch: 6| Step: 13
Training loss: 0.10958418256856045
Validation loss: 2.208240942048728

Epoch: 705| Step: 0
Training loss: 0.08638084450296667
Validation loss: 2.2010497558778064

Epoch: 6| Step: 1
Training loss: 0.0942222304832132
Validation loss: 2.1920130465745524

Epoch: 6| Step: 2
Training loss: 0.0670291909655195
Validation loss: 2.205233271854407

Epoch: 6| Step: 3
Training loss: 0.07330913662776782
Validation loss: 2.203009875927545

Epoch: 6| Step: 4
Training loss: 0.10292518214982643
Validation loss: 2.1878878898506913

Epoch: 6| Step: 5
Training loss: 0.10435715087300271
Validation loss: 2.201504998055235

Epoch: 6| Step: 6
Training loss: 0.09758239814619388
Validation loss: 2.201380753458178

Epoch: 6| Step: 7
Training loss: 0.13766316789440636
Validation loss: 2.214810363063001

Epoch: 6| Step: 8
Training loss: 0.05071148297996913
Validation loss: 2.219148216810243

Epoch: 6| Step: 9
Training loss: 0.11525550745498396
Validation loss: 2.204935577141056

Epoch: 6| Step: 10
Training loss: 0.10496279989193806
Validation loss: 2.201628966657709

Epoch: 6| Step: 11
Training loss: 0.10220880456950064
Validation loss: 2.250501101761704

Epoch: 6| Step: 12
Training loss: 0.09442489804900435
Validation loss: 2.2369919503808515

Epoch: 6| Step: 13
Training loss: 0.11270671700830526
Validation loss: 2.2385803949350813

Epoch: 706| Step: 0
Training loss: 0.07533793733097069
Validation loss: 2.2359215962591996

Epoch: 6| Step: 1
Training loss: 0.08854454283624226
Validation loss: 2.2552824222543224

Epoch: 6| Step: 2
Training loss: 0.12694954500285852
Validation loss: 2.2336377132808085

Epoch: 6| Step: 3
Training loss: 0.08953859502145932
Validation loss: 2.244215315384585

Epoch: 6| Step: 4
Training loss: 0.1107146526599222
Validation loss: 2.2551479331984927

Epoch: 6| Step: 5
Training loss: 0.08958787347503626
Validation loss: 2.2176830216802115

Epoch: 6| Step: 6
Training loss: 0.1208904043372868
Validation loss: 2.24571711866814

Epoch: 6| Step: 7
Training loss: 0.09361311734442049
Validation loss: 2.218146525605669

Epoch: 6| Step: 8
Training loss: 0.1095818878968112
Validation loss: 2.210210388914989

Epoch: 6| Step: 9
Training loss: 0.07459666008980047
Validation loss: 2.238243065620566

Epoch: 6| Step: 10
Training loss: 0.08822237030347789
Validation loss: 2.242973730315824

Epoch: 6| Step: 11
Training loss: 0.14176218853879202
Validation loss: 2.229265777397959

Epoch: 6| Step: 12
Training loss: 0.09087216015061979
Validation loss: 2.2348195746717026

Epoch: 6| Step: 13
Training loss: 0.08106621694719637
Validation loss: 2.233181682458623

Epoch: 707| Step: 0
Training loss: 0.0996507250285127
Validation loss: 2.2142709992467364

Epoch: 6| Step: 1
Training loss: 0.08630804890005073
Validation loss: 2.204750815036229

Epoch: 6| Step: 2
Training loss: 0.06973603822663632
Validation loss: 2.242905258804986

Epoch: 6| Step: 3
Training loss: 0.08465916654949696
Validation loss: 2.260599192400797

Epoch: 6| Step: 4
Training loss: 0.08614018499520455
Validation loss: 2.276939349288986

Epoch: 6| Step: 5
Training loss: 0.09188658814756848
Validation loss: 2.265856620765061

Epoch: 6| Step: 6
Training loss: 0.11924038681308205
Validation loss: 2.2553407009311135

Epoch: 6| Step: 7
Training loss: 0.0841801103461813
Validation loss: 2.2766981626632234

Epoch: 6| Step: 8
Training loss: 0.10537280911241691
Validation loss: 2.248650961086756

Epoch: 6| Step: 9
Training loss: 0.08808568396182904
Validation loss: 2.276334312410872

Epoch: 6| Step: 10
Training loss: 0.07307190491747867
Validation loss: 2.2149712081938278

Epoch: 6| Step: 11
Training loss: 0.13865915428165204
Validation loss: 2.222948679208309

Epoch: 6| Step: 12
Training loss: 0.12552861853023922
Validation loss: 2.245778744844404

Epoch: 6| Step: 13
Training loss: 0.08340756703598609
Validation loss: 2.2388879664225194

Epoch: 708| Step: 0
Training loss: 0.09522326994560193
Validation loss: 2.2241404957029336

Epoch: 6| Step: 1
Training loss: 0.09784251569093042
Validation loss: 2.2179763961238486

Epoch: 6| Step: 2
Training loss: 0.1121029950031172
Validation loss: 2.2215170128643362

Epoch: 6| Step: 3
Training loss: 0.07166007576597679
Validation loss: 2.1966579423323758

Epoch: 6| Step: 4
Training loss: 0.05598215975266015
Validation loss: 2.2298409200630416

Epoch: 6| Step: 5
Training loss: 0.061524037327945605
Validation loss: 2.225651792649196

Epoch: 6| Step: 6
Training loss: 0.08218347525985838
Validation loss: 2.238333473569168

Epoch: 6| Step: 7
Training loss: 0.09286920222653601
Validation loss: 2.2389016634792442

Epoch: 6| Step: 8
Training loss: 0.09710449273226493
Validation loss: 2.23113714675954

Epoch: 6| Step: 9
Training loss: 0.1056066159467717
Validation loss: 2.24702253073972

Epoch: 6| Step: 10
Training loss: 0.08035756410950039
Validation loss: 2.23969588534673

Epoch: 6| Step: 11
Training loss: 0.0748821462582683
Validation loss: 2.217553715889802

Epoch: 6| Step: 12
Training loss: 0.08339447396215796
Validation loss: 2.195050911179464

Epoch: 6| Step: 13
Training loss: 0.07938413422885184
Validation loss: 2.2172581586520117

Epoch: 709| Step: 0
Training loss: 0.0873269016584927
Validation loss: 2.197565711965002

Epoch: 6| Step: 1
Training loss: 0.07503559440132572
Validation loss: 2.2020486020183605

Epoch: 6| Step: 2
Training loss: 0.0883841434001906
Validation loss: 2.222614120613832

Epoch: 6| Step: 3
Training loss: 0.057740959481130776
Validation loss: 2.2050166140606087

Epoch: 6| Step: 4
Training loss: 0.09891723000866284
Validation loss: 2.199983947775516

Epoch: 6| Step: 5
Training loss: 0.12228249990992844
Validation loss: 2.21168096775112

Epoch: 6| Step: 6
Training loss: 0.05948171906720699
Validation loss: 2.2305677444520073

Epoch: 6| Step: 7
Training loss: 0.09362786503159182
Validation loss: 2.2321283530776337

Epoch: 6| Step: 8
Training loss: 0.08057511022541272
Validation loss: 2.2194740870736416

Epoch: 6| Step: 9
Training loss: 0.07670264676221414
Validation loss: 2.2314977968610696

Epoch: 6| Step: 10
Training loss: 0.11817690093860138
Validation loss: 2.239914881057505

Epoch: 6| Step: 11
Training loss: 0.07651945431883753
Validation loss: 2.2209009711977794

Epoch: 6| Step: 12
Training loss: 0.07780726911205409
Validation loss: 2.2566312105471305

Epoch: 6| Step: 13
Training loss: 0.07207900191339472
Validation loss: 2.2191395120874455

Epoch: 710| Step: 0
Training loss: 0.08435296801945098
Validation loss: 2.2387330059045194

Epoch: 6| Step: 1
Training loss: 0.05961947679229613
Validation loss: 2.2492749431438934

Epoch: 6| Step: 2
Training loss: 0.09895055409857484
Validation loss: 2.2687707331730507

Epoch: 6| Step: 3
Training loss: 0.07650084251052068
Validation loss: 2.2142510042805874

Epoch: 6| Step: 4
Training loss: 0.07608996474409527
Validation loss: 2.22874397990962

Epoch: 6| Step: 5
Training loss: 0.09116012824449143
Validation loss: 2.2392963974433937

Epoch: 6| Step: 6
Training loss: 0.09154245954713355
Validation loss: 2.2354701563938235

Epoch: 6| Step: 7
Training loss: 0.10171795831539214
Validation loss: 2.2000021100616776

Epoch: 6| Step: 8
Training loss: 0.15090918622899804
Validation loss: 2.207040325396238

Epoch: 6| Step: 9
Training loss: 0.04542495629921807
Validation loss: 2.1989617651922146

Epoch: 6| Step: 10
Training loss: 0.11041522932316675
Validation loss: 2.2242963668048135

Epoch: 6| Step: 11
Training loss: 0.10104999159735503
Validation loss: 2.2349183465821856

Epoch: 6| Step: 12
Training loss: 0.11210174468122233
Validation loss: 2.216242772714122

Epoch: 6| Step: 13
Training loss: 0.09463648593493064
Validation loss: 2.2194192383418776

Epoch: 711| Step: 0
Training loss: 0.11322121015661317
Validation loss: 2.2336832839266143

Epoch: 6| Step: 1
Training loss: 0.10182849274446427
Validation loss: 2.2263286266974904

Epoch: 6| Step: 2
Training loss: 0.10007071248728854
Validation loss: 2.242199031100872

Epoch: 6| Step: 3
Training loss: 0.057795462965442614
Validation loss: 2.2530806017271683

Epoch: 6| Step: 4
Training loss: 0.10314327424866633
Validation loss: 2.2193589216244614

Epoch: 6| Step: 5
Training loss: 0.12687368108035665
Validation loss: 2.2336688800073374

Epoch: 6| Step: 6
Training loss: 0.05642157776645214
Validation loss: 2.2152527488316123

Epoch: 6| Step: 7
Training loss: 0.09714160734124483
Validation loss: 2.215065218958526

Epoch: 6| Step: 8
Training loss: 0.12124455966984894
Validation loss: 2.2322835711002593

Epoch: 6| Step: 9
Training loss: 0.0879039648317043
Validation loss: 2.2046557045395176

Epoch: 6| Step: 10
Training loss: 0.08946965431351946
Validation loss: 2.223927434368622

Epoch: 6| Step: 11
Training loss: 0.09947094929127676
Validation loss: 2.255262730076526

Epoch: 6| Step: 12
Training loss: 0.10965575220642422
Validation loss: 2.2237234253546228

Epoch: 6| Step: 13
Training loss: 0.10225040131597413
Validation loss: 2.2224819336233046

Epoch: 712| Step: 0
Training loss: 0.12687528131012196
Validation loss: 2.2556684160604257

Epoch: 6| Step: 1
Training loss: 0.08428794312376894
Validation loss: 2.20901617969117

Epoch: 6| Step: 2
Training loss: 0.08872948972013703
Validation loss: 2.230125573682787

Epoch: 6| Step: 3
Training loss: 0.09557225075973955
Validation loss: 2.2261414315950105

Epoch: 6| Step: 4
Training loss: 0.11570658753292841
Validation loss: 2.223161976757764

Epoch: 6| Step: 5
Training loss: 0.11386908730808121
Validation loss: 2.2390633286772714

Epoch: 6| Step: 6
Training loss: 0.09263622778437283
Validation loss: 2.262086971815869

Epoch: 6| Step: 7
Training loss: 0.09161148220919915
Validation loss: 2.2602040014196465

Epoch: 6| Step: 8
Training loss: 0.11810559804715952
Validation loss: 2.251727751700604

Epoch: 6| Step: 9
Training loss: 0.10596836047099548
Validation loss: 2.2479425158771646

Epoch: 6| Step: 10
Training loss: 0.08057541074429152
Validation loss: 2.2782023062852006

Epoch: 6| Step: 11
Training loss: 0.09384704077575387
Validation loss: 2.2443179619150366

Epoch: 6| Step: 12
Training loss: 0.07086458291133163
Validation loss: 2.2169232159946146

Epoch: 6| Step: 13
Training loss: 0.07864978487727434
Validation loss: 2.251877612586199

Epoch: 713| Step: 0
Training loss: 0.09353912001005625
Validation loss: 2.2525077230613295

Epoch: 6| Step: 1
Training loss: 0.10198791977110695
Validation loss: 2.240015774467515

Epoch: 6| Step: 2
Training loss: 0.05967702063344506
Validation loss: 2.2330102886935768

Epoch: 6| Step: 3
Training loss: 0.0862649590496427
Validation loss: 2.190847009666451

Epoch: 6| Step: 4
Training loss: 0.12602788042567215
Validation loss: 2.235962860932898

Epoch: 6| Step: 5
Training loss: 0.07402580994701913
Validation loss: 2.1993018194947997

Epoch: 6| Step: 6
Training loss: 0.15205103923797772
Validation loss: 2.206747286125992

Epoch: 6| Step: 7
Training loss: 0.11201580043496435
Validation loss: 2.2164743953343953

Epoch: 6| Step: 8
Training loss: 0.11090637932396617
Validation loss: 2.2221677763761107

Epoch: 6| Step: 9
Training loss: 0.09393909378247933
Validation loss: 2.215681207202721

Epoch: 6| Step: 10
Training loss: 0.09094215751466429
Validation loss: 2.2327170495135213

Epoch: 6| Step: 11
Training loss: 0.05188750715890935
Validation loss: 2.226609243619385

Epoch: 6| Step: 12
Training loss: 0.1414328392068314
Validation loss: 2.238873060100545

Epoch: 6| Step: 13
Training loss: 0.1711780603824271
Validation loss: 2.2256894529892026

Epoch: 714| Step: 0
Training loss: 0.10527713464816171
Validation loss: 2.217551230922428

Epoch: 6| Step: 1
Training loss: 0.08358723144873886
Validation loss: 2.2436315256997417

Epoch: 6| Step: 2
Training loss: 0.07979024919856076
Validation loss: 2.235831096803792

Epoch: 6| Step: 3
Training loss: 0.11858621567702869
Validation loss: 2.2025155896086988

Epoch: 6| Step: 4
Training loss: 0.11238495819037643
Validation loss: 2.2102197415231037

Epoch: 6| Step: 5
Training loss: 0.15391844202538169
Validation loss: 2.210964649566693

Epoch: 6| Step: 6
Training loss: 0.12386590985854563
Validation loss: 2.228195124962619

Epoch: 6| Step: 7
Training loss: 0.09242231278626176
Validation loss: 2.2059567034555227

Epoch: 6| Step: 8
Training loss: 0.18576530850146306
Validation loss: 2.2028226875546513

Epoch: 6| Step: 9
Training loss: 0.0950081856708273
Validation loss: 2.184782681438053

Epoch: 6| Step: 10
Training loss: 0.11797162614562566
Validation loss: 2.169556577213995

Epoch: 6| Step: 11
Training loss: 0.11048690547561979
Validation loss: 2.185634042798336

Epoch: 6| Step: 12
Training loss: 0.09045507968471556
Validation loss: 2.1736071061055693

Epoch: 6| Step: 13
Training loss: 0.10614598034944295
Validation loss: 2.171709820602694

Epoch: 715| Step: 0
Training loss: 0.072691647561744
Validation loss: 2.1791267486732835

Epoch: 6| Step: 1
Training loss: 0.1250357502239706
Validation loss: 2.1716160555313992

Epoch: 6| Step: 2
Training loss: 0.09315122679892039
Validation loss: 2.1301909904657554

Epoch: 6| Step: 3
Training loss: 0.10699640023418552
Validation loss: 2.166038176709145

Epoch: 6| Step: 4
Training loss: 0.09078076742474034
Validation loss: 2.2124863336269764

Epoch: 6| Step: 5
Training loss: 0.1136993306223936
Validation loss: 2.2335278968870913

Epoch: 6| Step: 6
Training loss: 0.08818144631965869
Validation loss: 2.221844648087522

Epoch: 6| Step: 7
Training loss: 0.0575093395517287
Validation loss: 2.1993534990564676

Epoch: 6| Step: 8
Training loss: 0.10800030339025118
Validation loss: 2.22601833404312

Epoch: 6| Step: 9
Training loss: 0.12663941871685122
Validation loss: 2.26911167457638

Epoch: 6| Step: 10
Training loss: 0.11017086628738974
Validation loss: 2.2275363469858847

Epoch: 6| Step: 11
Training loss: 0.10930702958505979
Validation loss: 2.270828380468303

Epoch: 6| Step: 12
Training loss: 0.08615425798723517
Validation loss: 2.2524522329791075

Epoch: 6| Step: 13
Training loss: 0.05989004146864902
Validation loss: 2.2433155262663065

Epoch: 716| Step: 0
Training loss: 0.11406409722999648
Validation loss: 2.2456917334588713

Epoch: 6| Step: 1
Training loss: 0.10923462613185629
Validation loss: 2.247944472869118

Epoch: 6| Step: 2
Training loss: 0.052637954708019394
Validation loss: 2.2483000879581483

Epoch: 6| Step: 3
Training loss: 0.06389927233141186
Validation loss: 2.2519433756558933

Epoch: 6| Step: 4
Training loss: 0.06195877097573201
Validation loss: 2.237457789943386

Epoch: 6| Step: 5
Training loss: 0.10943181401551363
Validation loss: 2.2355420906571437

Epoch: 6| Step: 6
Training loss: 0.09688238607982906
Validation loss: 2.222747779511631

Epoch: 6| Step: 7
Training loss: 0.07211770887251501
Validation loss: 2.211845881257825

Epoch: 6| Step: 8
Training loss: 0.1270952529541661
Validation loss: 2.2407847893226336

Epoch: 6| Step: 9
Training loss: 0.10835859064644769
Validation loss: 2.229761711455219

Epoch: 6| Step: 10
Training loss: 0.11703459778187703
Validation loss: 2.2357820440154885

Epoch: 6| Step: 11
Training loss: 0.06115093313032137
Validation loss: 2.2366411285876584

Epoch: 6| Step: 12
Training loss: 0.07815995328530723
Validation loss: 2.2629001603713763

Epoch: 6| Step: 13
Training loss: 0.09784685607068841
Validation loss: 2.239473362994085

Epoch: 717| Step: 0
Training loss: 0.06951654109857085
Validation loss: 2.2316247989900986

Epoch: 6| Step: 1
Training loss: 0.057943000774859976
Validation loss: 2.256896626229108

Epoch: 6| Step: 2
Training loss: 0.07831226198102395
Validation loss: 2.2497153939620143

Epoch: 6| Step: 3
Training loss: 0.05870818050748796
Validation loss: 2.244103402253581

Epoch: 6| Step: 4
Training loss: 0.05949798672502147
Validation loss: 2.2607447639053224

Epoch: 6| Step: 5
Training loss: 0.053505202221651144
Validation loss: 2.223700652228242

Epoch: 6| Step: 6
Training loss: 0.13057241718433568
Validation loss: 2.2281833508206397

Epoch: 6| Step: 7
Training loss: 0.11056584677312932
Validation loss: 2.220825385602181

Epoch: 6| Step: 8
Training loss: 0.09828373540455683
Validation loss: 2.2155314870149976

Epoch: 6| Step: 9
Training loss: 0.10642112667149405
Validation loss: 2.227985332970904

Epoch: 6| Step: 10
Training loss: 0.07639886584416863
Validation loss: 2.1901505241147157

Epoch: 6| Step: 11
Training loss: 0.11116805615571299
Validation loss: 2.198143763654425

Epoch: 6| Step: 12
Training loss: 0.08777470361554437
Validation loss: 2.2183683379960963

Epoch: 6| Step: 13
Training loss: 0.10371065660571549
Validation loss: 2.2441356191257382

Epoch: 718| Step: 0
Training loss: 0.0777361491015237
Validation loss: 2.2152901375235974

Epoch: 6| Step: 1
Training loss: 0.0923410932365262
Validation loss: 2.2602505429813737

Epoch: 6| Step: 2
Training loss: 0.11239732570367449
Validation loss: 2.211644705020508

Epoch: 6| Step: 3
Training loss: 0.0934087881896485
Validation loss: 2.235883451842909

Epoch: 6| Step: 4
Training loss: 0.0946856538196025
Validation loss: 2.211247798825578

Epoch: 6| Step: 5
Training loss: 0.07016211228739276
Validation loss: 2.232275097329912

Epoch: 6| Step: 6
Training loss: 0.08341612806904122
Validation loss: 2.2115743037358104

Epoch: 6| Step: 7
Training loss: 0.07404474829847398
Validation loss: 2.244084848768398

Epoch: 6| Step: 8
Training loss: 0.09114084797803632
Validation loss: 2.233657922636978

Epoch: 6| Step: 9
Training loss: 0.08649987476865573
Validation loss: 2.2069006085967664

Epoch: 6| Step: 10
Training loss: 0.0877153635997058
Validation loss: 2.229181884385536

Epoch: 6| Step: 11
Training loss: 0.10545200638849675
Validation loss: 2.2359881100890004

Epoch: 6| Step: 12
Training loss: 0.05775977933381272
Validation loss: 2.2245052076692122

Epoch: 6| Step: 13
Training loss: 0.06487023964383545
Validation loss: 2.2312362135282013

Epoch: 719| Step: 0
Training loss: 0.06904193170569899
Validation loss: 2.2178286751558116

Epoch: 6| Step: 1
Training loss: 0.10358317438432713
Validation loss: 2.238289388922325

Epoch: 6| Step: 2
Training loss: 0.08108222734857899
Validation loss: 2.224265232991731

Epoch: 6| Step: 3
Training loss: 0.08944387700447233
Validation loss: 2.21589064714347

Epoch: 6| Step: 4
Training loss: 0.09332782339893238
Validation loss: 2.1774924376136147

Epoch: 6| Step: 5
Training loss: 0.115203465341065
Validation loss: 2.2202467190767257

Epoch: 6| Step: 6
Training loss: 0.10126326568261296
Validation loss: 2.2155490254465393

Epoch: 6| Step: 7
Training loss: 0.07033042546764155
Validation loss: 2.2099503915612777

Epoch: 6| Step: 8
Training loss: 0.08070586301437108
Validation loss: 2.213105275944675

Epoch: 6| Step: 9
Training loss: 0.11880132952407355
Validation loss: 2.217798085737092

Epoch: 6| Step: 10
Training loss: 0.1055906968308978
Validation loss: 2.2351879491377353

Epoch: 6| Step: 11
Training loss: 0.11795755737462241
Validation loss: 2.227396442603525

Epoch: 6| Step: 12
Training loss: 0.07973256800160913
Validation loss: 2.2280881981450333

Epoch: 6| Step: 13
Training loss: 0.07440516626441161
Validation loss: 2.2341446640555973

Epoch: 720| Step: 0
Training loss: 0.10966691588170689
Validation loss: 2.236878258158266

Epoch: 6| Step: 1
Training loss: 0.10390652767660569
Validation loss: 2.21377951128967

Epoch: 6| Step: 2
Training loss: 0.09815744533314999
Validation loss: 2.2015911043407046

Epoch: 6| Step: 3
Training loss: 0.06225842489304454
Validation loss: 2.2101549791269415

Epoch: 6| Step: 4
Training loss: 0.11509015870479278
Validation loss: 2.205140961302767

Epoch: 6| Step: 5
Training loss: 0.07160225747703004
Validation loss: 2.204761871304219

Epoch: 6| Step: 6
Training loss: 0.05812773958923029
Validation loss: 2.2186534652033725

Epoch: 6| Step: 7
Training loss: 0.06829372727923584
Validation loss: 2.2082141995776077

Epoch: 6| Step: 8
Training loss: 0.07902801886009912
Validation loss: 2.2175648262437164

Epoch: 6| Step: 9
Training loss: 0.13146357756591362
Validation loss: 2.188329795341136

Epoch: 6| Step: 10
Training loss: 0.052672256865258685
Validation loss: 2.230611487219343

Epoch: 6| Step: 11
Training loss: 0.08254118358795089
Validation loss: 2.216917300733246

Epoch: 6| Step: 12
Training loss: 0.0831656330107277
Validation loss: 2.23407809075195

Epoch: 6| Step: 13
Training loss: 0.17432605492310824
Validation loss: 2.238772296692456

Epoch: 721| Step: 0
Training loss: 0.08112150333837698
Validation loss: 2.2191987789066063

Epoch: 6| Step: 1
Training loss: 0.04938604140863794
Validation loss: 2.1908804824108565

Epoch: 6| Step: 2
Training loss: 0.08189093987896216
Validation loss: 2.1827729019786264

Epoch: 6| Step: 3
Training loss: 0.11797967822254594
Validation loss: 2.2206790888246872

Epoch: 6| Step: 4
Training loss: 0.09066099118113669
Validation loss: 2.2079651383038637

Epoch: 6| Step: 5
Training loss: 0.12202918695056472
Validation loss: 2.199931217332131

Epoch: 6| Step: 6
Training loss: 0.09489829433772987
Validation loss: 2.1967466344961815

Epoch: 6| Step: 7
Training loss: 0.09061716802231613
Validation loss: 2.1979654603468215

Epoch: 6| Step: 8
Training loss: 0.1067119461197346
Validation loss: 2.182859933916938

Epoch: 6| Step: 9
Training loss: 0.06796569200739845
Validation loss: 2.197058554824326

Epoch: 6| Step: 10
Training loss: 0.13794316649713442
Validation loss: 2.2058496435174435

Epoch: 6| Step: 11
Training loss: 0.10284474086921659
Validation loss: 2.2493359464282063

Epoch: 6| Step: 12
Training loss: 0.12718929185237762
Validation loss: 2.2413832620023006

Epoch: 6| Step: 13
Training loss: 0.06568810332621905
Validation loss: 2.2489466953370214

Epoch: 722| Step: 0
Training loss: 0.08755503269214988
Validation loss: 2.243815446165897

Epoch: 6| Step: 1
Training loss: 0.10913685861094745
Validation loss: 2.2521203007867054

Epoch: 6| Step: 2
Training loss: 0.11375808658256388
Validation loss: 2.2740317094134825

Epoch: 6| Step: 3
Training loss: 0.09988599589395347
Validation loss: 2.2553287252204757

Epoch: 6| Step: 4
Training loss: 0.043842401805644714
Validation loss: 2.270571366645787

Epoch: 6| Step: 5
Training loss: 0.12954035764916058
Validation loss: 2.2809829510655413

Epoch: 6| Step: 6
Training loss: 0.09188949194133204
Validation loss: 2.2216327859263414

Epoch: 6| Step: 7
Training loss: 0.07424974421776599
Validation loss: 2.23475906016604

Epoch: 6| Step: 8
Training loss: 0.07850230421872756
Validation loss: 2.236116755741738

Epoch: 6| Step: 9
Training loss: 0.08696586693752663
Validation loss: 2.244209588863242

Epoch: 6| Step: 10
Training loss: 0.09088010767903568
Validation loss: 2.214305466115409

Epoch: 6| Step: 11
Training loss: 0.0814355210838181
Validation loss: 2.215734492487609

Epoch: 6| Step: 12
Training loss: 0.06898259068251893
Validation loss: 2.176520931490437

Epoch: 6| Step: 13
Training loss: 0.11704309228511754
Validation loss: 2.20087722151514

Epoch: 723| Step: 0
Training loss: 0.11208392296279096
Validation loss: 2.2035787756970553

Epoch: 6| Step: 1
Training loss: 0.057174770170887436
Validation loss: 2.187934228835816

Epoch: 6| Step: 2
Training loss: 0.07944009887907048
Validation loss: 2.2039776189828393

Epoch: 6| Step: 3
Training loss: 0.09963981312957447
Validation loss: 2.2025547690358116

Epoch: 6| Step: 4
Training loss: 0.06175612166235709
Validation loss: 2.20379542012967

Epoch: 6| Step: 5
Training loss: 0.08710319321769003
Validation loss: 2.204737441860372

Epoch: 6| Step: 6
Training loss: 0.08157942008583481
Validation loss: 2.203948127313327

Epoch: 6| Step: 7
Training loss: 0.10510665495607857
Validation loss: 2.194444862328645

Epoch: 6| Step: 8
Training loss: 0.06989280626559044
Validation loss: 2.2258502228941874

Epoch: 6| Step: 9
Training loss: 0.09557485743049766
Validation loss: 2.211157223992955

Epoch: 6| Step: 10
Training loss: 0.08542607675255569
Validation loss: 2.2100081273782646

Epoch: 6| Step: 11
Training loss: 0.06870889206856805
Validation loss: 2.203433987138176

Epoch: 6| Step: 12
Training loss: 0.08236569392700761
Validation loss: 2.23867506844063

Epoch: 6| Step: 13
Training loss: 0.0699080584104146
Validation loss: 2.2162752320610646

Epoch: 724| Step: 0
Training loss: 0.11527719348720457
Validation loss: 2.2288313302828398

Epoch: 6| Step: 1
Training loss: 0.05941638249476843
Validation loss: 2.201603184884067

Epoch: 6| Step: 2
Training loss: 0.07582876372564525
Validation loss: 2.2249762471262997

Epoch: 6| Step: 3
Training loss: 0.09356742206780612
Validation loss: 2.214980093650041

Epoch: 6| Step: 4
Training loss: 0.10536512829967594
Validation loss: 2.21230127855668

Epoch: 6| Step: 5
Training loss: 0.07333673414706113
Validation loss: 2.2102507414547663

Epoch: 6| Step: 6
Training loss: 0.0645867393285145
Validation loss: 2.2118103027636233

Epoch: 6| Step: 7
Training loss: 0.09413371436685682
Validation loss: 2.2188909480959738

Epoch: 6| Step: 8
Training loss: 0.07810837747643133
Validation loss: 2.2186363199180335

Epoch: 6| Step: 9
Training loss: 0.07445129554398215
Validation loss: 2.2317324627039232

Epoch: 6| Step: 10
Training loss: 0.0602644864690109
Validation loss: 2.218328482996684

Epoch: 6| Step: 11
Training loss: 0.07508374892734399
Validation loss: 2.242660936112963

Epoch: 6| Step: 12
Training loss: 0.08827640321811962
Validation loss: 2.2607474321600285

Epoch: 6| Step: 13
Training loss: 0.07099889791688559
Validation loss: 2.2240004030587532

Epoch: 725| Step: 0
Training loss: 0.06149885655373301
Validation loss: 2.2235327518027956

Epoch: 6| Step: 1
Training loss: 0.06977207063821003
Validation loss: 2.2553910555096897

Epoch: 6| Step: 2
Training loss: 0.07738200575760898
Validation loss: 2.265722745230306

Epoch: 6| Step: 3
Training loss: 0.08150021065881481
Validation loss: 2.2613786121446426

Epoch: 6| Step: 4
Training loss: 0.12200277367452332
Validation loss: 2.2539372638490804

Epoch: 6| Step: 5
Training loss: 0.06505060336959635
Validation loss: 2.2717399144116333

Epoch: 6| Step: 6
Training loss: 0.07561940270489884
Validation loss: 2.2623141121122945

Epoch: 6| Step: 7
Training loss: 0.08309019432497852
Validation loss: 2.250138877812079

Epoch: 6| Step: 8
Training loss: 0.12234871968714879
Validation loss: 2.2611634021103826

Epoch: 6| Step: 9
Training loss: 0.10523857944446703
Validation loss: 2.2232318669657567

Epoch: 6| Step: 10
Training loss: 0.09021918490978575
Validation loss: 2.2538378546911835

Epoch: 6| Step: 11
Training loss: 0.06155788123527365
Validation loss: 2.2250129113094057

Epoch: 6| Step: 12
Training loss: 0.1165427431795147
Validation loss: 2.222149651912256

Epoch: 6| Step: 13
Training loss: 0.0814622833903197
Validation loss: 2.2431980957107807

Epoch: 726| Step: 0
Training loss: 0.08377835320900491
Validation loss: 2.2410638888084677

Epoch: 6| Step: 1
Training loss: 0.09682769716478239
Validation loss: 2.2492517437157487

Epoch: 6| Step: 2
Training loss: 0.10832773514719699
Validation loss: 2.222481661973219

Epoch: 6| Step: 3
Training loss: 0.0549785202046964
Validation loss: 2.23251071553235

Epoch: 6| Step: 4
Training loss: 0.08886598753904988
Validation loss: 2.2504209713684946

Epoch: 6| Step: 5
Training loss: 0.10332007200793597
Validation loss: 2.215435123833718

Epoch: 6| Step: 6
Training loss: 0.09995906819141953
Validation loss: 2.200738775755592

Epoch: 6| Step: 7
Training loss: 0.08134054711591047
Validation loss: 2.2192432699300055

Epoch: 6| Step: 8
Training loss: 0.1296730498800662
Validation loss: 2.2243669255634293

Epoch: 6| Step: 9
Training loss: 0.06698342146393885
Validation loss: 2.2112860366315896

Epoch: 6| Step: 10
Training loss: 0.12973982605617285
Validation loss: 2.218483866875481

Epoch: 6| Step: 11
Training loss: 0.07796486595948962
Validation loss: 2.194097528450258

Epoch: 6| Step: 12
Training loss: 0.07092909202762701
Validation loss: 2.2025057037809685

Epoch: 6| Step: 13
Training loss: 0.12244713034661976
Validation loss: 2.2012915183809674

Epoch: 727| Step: 0
Training loss: 0.09962299665174229
Validation loss: 2.2013207428478476

Epoch: 6| Step: 1
Training loss: 0.04638248474473697
Validation loss: 2.2346568229262793

Epoch: 6| Step: 2
Training loss: 0.07089352288564997
Validation loss: 2.241326860548751

Epoch: 6| Step: 3
Training loss: 0.10582279016544954
Validation loss: 2.249452357943519

Epoch: 6| Step: 4
Training loss: 0.10763068711615595
Validation loss: 2.240778368727525

Epoch: 6| Step: 5
Training loss: 0.10430834096396441
Validation loss: 2.2309744386487593

Epoch: 6| Step: 6
Training loss: 0.09010851760881017
Validation loss: 2.2572221392567946

Epoch: 6| Step: 7
Training loss: 0.12354721040681385
Validation loss: 2.2631952979477705

Epoch: 6| Step: 8
Training loss: 0.10449378288691087
Validation loss: 2.229465406140919

Epoch: 6| Step: 9
Training loss: 0.07349059260468568
Validation loss: 2.2334934155972364

Epoch: 6| Step: 10
Training loss: 0.09208276039786055
Validation loss: 2.2275810521326833

Epoch: 6| Step: 11
Training loss: 0.12473320428694773
Validation loss: 2.2434568050602195

Epoch: 6| Step: 12
Training loss: 0.12286868893306369
Validation loss: 2.2423063382980386

Epoch: 6| Step: 13
Training loss: 0.13759087599326592
Validation loss: 2.2301407086054446

Epoch: 728| Step: 0
Training loss: 0.06985290311621878
Validation loss: 2.2067410034907393

Epoch: 6| Step: 1
Training loss: 0.05758908766546656
Validation loss: 2.23691877342585

Epoch: 6| Step: 2
Training loss: 0.10120590587609996
Validation loss: 2.2137830913610257

Epoch: 6| Step: 3
Training loss: 0.05855687689871096
Validation loss: 2.2244923975263386

Epoch: 6| Step: 4
Training loss: 0.07077680050104405
Validation loss: 2.236264975061381

Epoch: 6| Step: 5
Training loss: 0.09545564279780888
Validation loss: 2.2141055936495095

Epoch: 6| Step: 6
Training loss: 0.1039844011096076
Validation loss: 2.2366455345805427

Epoch: 6| Step: 7
Training loss: 0.06955453504219815
Validation loss: 2.2361047636340436

Epoch: 6| Step: 8
Training loss: 0.037932461139711625
Validation loss: 2.2516242036284075

Epoch: 6| Step: 9
Training loss: 0.09697553374908682
Validation loss: 2.223000832531307

Epoch: 6| Step: 10
Training loss: 0.09640642040151069
Validation loss: 2.2253828676311356

Epoch: 6| Step: 11
Training loss: 0.06794102585652662
Validation loss: 2.2354736828058015

Epoch: 6| Step: 12
Training loss: 0.09709347692217331
Validation loss: 2.266087378426088

Epoch: 6| Step: 13
Training loss: 0.08935774086319975
Validation loss: 2.2517674197200517

Epoch: 729| Step: 0
Training loss: 0.10864594700765591
Validation loss: 2.2625416244841356

Epoch: 6| Step: 1
Training loss: 0.0578012556984794
Validation loss: 2.2499483221083

Epoch: 6| Step: 2
Training loss: 0.10039210856488118
Validation loss: 2.224523630151454

Epoch: 6| Step: 3
Training loss: 0.09217190731854413
Validation loss: 2.217765942291658

Epoch: 6| Step: 4
Training loss: 0.10060306977226172
Validation loss: 2.21620597385166

Epoch: 6| Step: 5
Training loss: 0.0817898109331466
Validation loss: 2.2250686697590676

Epoch: 6| Step: 6
Training loss: 0.05554454294572634
Validation loss: 2.1951170380226155

Epoch: 6| Step: 7
Training loss: 0.07290206135638555
Validation loss: 2.23463483980879

Epoch: 6| Step: 8
Training loss: 0.08190442681202759
Validation loss: 2.204832694173292

Epoch: 6| Step: 9
Training loss: 0.04688576733584386
Validation loss: 2.2215505681768404

Epoch: 6| Step: 10
Training loss: 0.08152209088886257
Validation loss: 2.211196756086108

Epoch: 6| Step: 11
Training loss: 0.12954193931621244
Validation loss: 2.2469359548715513

Epoch: 6| Step: 12
Training loss: 0.10485441935298029
Validation loss: 2.2473172655180624

Epoch: 6| Step: 13
Training loss: 0.05567207822473517
Validation loss: 2.2066281755621717

Epoch: 730| Step: 0
Training loss: 0.07001772988634497
Validation loss: 2.2156699485575237

Epoch: 6| Step: 1
Training loss: 0.053107208628210736
Validation loss: 2.2492969934630853

Epoch: 6| Step: 2
Training loss: 0.06416611636506912
Validation loss: 2.2373671374961783

Epoch: 6| Step: 3
Training loss: 0.10151742888778596
Validation loss: 2.264489522659686

Epoch: 6| Step: 4
Training loss: 0.12473773264723247
Validation loss: 2.2664775592234525

Epoch: 6| Step: 5
Training loss: 0.08319118105090406
Validation loss: 2.2597333501780166

Epoch: 6| Step: 6
Training loss: 0.10163796812099117
Validation loss: 2.259210796718243

Epoch: 6| Step: 7
Training loss: 0.10316598973465559
Validation loss: 2.2649805750071965

Epoch: 6| Step: 8
Training loss: 0.0729909402201162
Validation loss: 2.2685508045533775

Epoch: 6| Step: 9
Training loss: 0.08654063615731036
Validation loss: 2.2423232934509705

Epoch: 6| Step: 10
Training loss: 0.08879867469793641
Validation loss: 2.2485495703999234

Epoch: 6| Step: 11
Training loss: 0.06959516796651087
Validation loss: 2.265265257792895

Epoch: 6| Step: 12
Training loss: 0.0866942197024899
Validation loss: 2.2433154776976916

Epoch: 6| Step: 13
Training loss: 0.030153648969666193
Validation loss: 2.25012128997537

Epoch: 731| Step: 0
Training loss: 0.06269714064621426
Validation loss: 2.279929608445066

Epoch: 6| Step: 1
Training loss: 0.06746087873331502
Validation loss: 2.2388131864809266

Epoch: 6| Step: 2
Training loss: 0.04981717486070139
Validation loss: 2.2294655096310434

Epoch: 6| Step: 3
Training loss: 0.08474003640704181
Validation loss: 2.2541865704837662

Epoch: 6| Step: 4
Training loss: 0.04972555381249296
Validation loss: 2.2067659887096345

Epoch: 6| Step: 5
Training loss: 0.05584859377182236
Validation loss: 2.2421345958376007

Epoch: 6| Step: 6
Training loss: 0.12138223892992693
Validation loss: 2.215503936921599

Epoch: 6| Step: 7
Training loss: 0.0899414019009965
Validation loss: 2.217652959129444

Epoch: 6| Step: 8
Training loss: 0.09522942162447404
Validation loss: 2.220820683007297

Epoch: 6| Step: 9
Training loss: 0.0690617108299943
Validation loss: 2.2337711641856663

Epoch: 6| Step: 10
Training loss: 0.11185861815223042
Validation loss: 2.233862003015081

Epoch: 6| Step: 11
Training loss: 0.07492782651674183
Validation loss: 2.2610002891511423

Epoch: 6| Step: 12
Training loss: 0.10720098934011744
Validation loss: 2.251198254709179

Epoch: 6| Step: 13
Training loss: 0.05904948307459327
Validation loss: 2.2403343568814833

Epoch: 732| Step: 0
Training loss: 0.07764666871423324
Validation loss: 2.2403362209643354

Epoch: 6| Step: 1
Training loss: 0.06373896282383601
Validation loss: 2.224144976022919

Epoch: 6| Step: 2
Training loss: 0.08836020487826507
Validation loss: 2.2511918512874614

Epoch: 6| Step: 3
Training loss: 0.10512019329246014
Validation loss: 2.252057145733803

Epoch: 6| Step: 4
Training loss: 0.0605289390362351
Validation loss: 2.2547714254277373

Epoch: 6| Step: 5
Training loss: 0.10707985877533384
Validation loss: 2.2497188724051145

Epoch: 6| Step: 6
Training loss: 0.09570746022740133
Validation loss: 2.244125961480994

Epoch: 6| Step: 7
Training loss: 0.06460560477440987
Validation loss: 2.2440543126596206

Epoch: 6| Step: 8
Training loss: 0.050576926868590735
Validation loss: 2.233146466846377

Epoch: 6| Step: 9
Training loss: 0.05168112660910666
Validation loss: 2.2688554645775145

Epoch: 6| Step: 10
Training loss: 0.1097374004173457
Validation loss: 2.286497095344614

Epoch: 6| Step: 11
Training loss: 0.05511707795238355
Validation loss: 2.2520168550037587

Epoch: 6| Step: 12
Training loss: 0.04886077742764316
Validation loss: 2.2359839997540285

Epoch: 6| Step: 13
Training loss: 0.0777086728223249
Validation loss: 2.2361579193659358

Epoch: 733| Step: 0
Training loss: 0.07917370861611048
Validation loss: 2.231051807052477

Epoch: 6| Step: 1
Training loss: 0.060194509124593364
Validation loss: 2.260970810496992

Epoch: 6| Step: 2
Training loss: 0.1150839276090692
Validation loss: 2.235726477074439

Epoch: 6| Step: 3
Training loss: 0.07015610228652526
Validation loss: 2.249218552086578

Epoch: 6| Step: 4
Training loss: 0.08989154539494108
Validation loss: 2.232871110194069

Epoch: 6| Step: 5
Training loss: 0.0513322197174997
Validation loss: 2.244223308272549

Epoch: 6| Step: 6
Training loss: 0.0671544767330255
Validation loss: 2.271729035157116

Epoch: 6| Step: 7
Training loss: 0.06584794245622239
Validation loss: 2.24551594011688

Epoch: 6| Step: 8
Training loss: 0.05246203796328914
Validation loss: 2.2407426867244054

Epoch: 6| Step: 9
Training loss: 0.09672395097494478
Validation loss: 2.2488168433611953

Epoch: 6| Step: 10
Training loss: 0.07630381100763321
Validation loss: 2.2072950578106316

Epoch: 6| Step: 11
Training loss: 0.08496767872341625
Validation loss: 2.2000945628166795

Epoch: 6| Step: 12
Training loss: 0.1370192902934245
Validation loss: 2.2512447962648086

Epoch: 6| Step: 13
Training loss: 0.07424022338823752
Validation loss: 2.2021127454031966

Epoch: 734| Step: 0
Training loss: 0.10943756698157561
Validation loss: 2.244875547135582

Epoch: 6| Step: 1
Training loss: 0.07175682384389266
Validation loss: 2.2325586953448977

Epoch: 6| Step: 2
Training loss: 0.08524505748467658
Validation loss: 2.2178999320809347

Epoch: 6| Step: 3
Training loss: 0.06894254233114633
Validation loss: 2.252117349682051

Epoch: 6| Step: 4
Training loss: 0.08203260954229799
Validation loss: 2.2396718684270347

Epoch: 6| Step: 5
Training loss: 0.15842458741954663
Validation loss: 2.257912267805587

Epoch: 6| Step: 6
Training loss: 0.06855579155252993
Validation loss: 2.232410078364112

Epoch: 6| Step: 7
Training loss: 0.09258312984410427
Validation loss: 2.2412472892049244

Epoch: 6| Step: 8
Training loss: 0.0892842170257709
Validation loss: 2.223620374910319

Epoch: 6| Step: 9
Training loss: 0.1114132037406873
Validation loss: 2.2362323771118553

Epoch: 6| Step: 10
Training loss: 0.06265056623568693
Validation loss: 2.217300762099166

Epoch: 6| Step: 11
Training loss: 0.07114630933519049
Validation loss: 2.2626158513365398

Epoch: 6| Step: 12
Training loss: 0.08403653920105428
Validation loss: 2.230055238512422

Epoch: 6| Step: 13
Training loss: 0.07602105737781902
Validation loss: 2.254758163030582

Epoch: 735| Step: 0
Training loss: 0.0910993309830503
Validation loss: 2.2527550291099674

Epoch: 6| Step: 1
Training loss: 0.06631202885490035
Validation loss: 2.237445392539221

Epoch: 6| Step: 2
Training loss: 0.05523428515962473
Validation loss: 2.2583610083285075

Epoch: 6| Step: 3
Training loss: 0.06824560575543842
Validation loss: 2.2436949470514786

Epoch: 6| Step: 4
Training loss: 0.0882422882373331
Validation loss: 2.2309660202346326

Epoch: 6| Step: 5
Training loss: 0.08853629624217484
Validation loss: 2.2544018827887595

Epoch: 6| Step: 6
Training loss: 0.10130184912307194
Validation loss: 2.2550603937461275

Epoch: 6| Step: 7
Training loss: 0.07002558050267416
Validation loss: 2.26620428977207

Epoch: 6| Step: 8
Training loss: 0.09586409247059685
Validation loss: 2.2511054972654767

Epoch: 6| Step: 9
Training loss: 0.08293874335381121
Validation loss: 2.244015090935363

Epoch: 6| Step: 10
Training loss: 0.07056287058216834
Validation loss: 2.2606394498108218

Epoch: 6| Step: 11
Training loss: 0.10388220351049926
Validation loss: 2.259435036123042

Epoch: 6| Step: 12
Training loss: 0.10107251410037371
Validation loss: 2.2427048110879007

Epoch: 6| Step: 13
Training loss: 0.1187450886325605
Validation loss: 2.210807514417086

Epoch: 736| Step: 0
Training loss: 0.07183929287208335
Validation loss: 2.2175083392183987

Epoch: 6| Step: 1
Training loss: 0.0967169025349462
Validation loss: 2.2568534252996297

Epoch: 6| Step: 2
Training loss: 0.09767266135600242
Validation loss: 2.2397826311893474

Epoch: 6| Step: 3
Training loss: 0.06545820255373216
Validation loss: 2.209189314286459

Epoch: 6| Step: 4
Training loss: 0.09786797460101113
Validation loss: 2.2262054819178068

Epoch: 6| Step: 5
Training loss: 0.0714250208725797
Validation loss: 2.248349499325942

Epoch: 6| Step: 6
Training loss: 0.07830654746309738
Validation loss: 2.2127732151269823

Epoch: 6| Step: 7
Training loss: 0.05953284946055139
Validation loss: 2.216418834762473

Epoch: 6| Step: 8
Training loss: 0.11567002721349205
Validation loss: 2.232729636935517

Epoch: 6| Step: 9
Training loss: 0.10556017039440425
Validation loss: 2.221280967744027

Epoch: 6| Step: 10
Training loss: 0.06608432335623592
Validation loss: 2.226015490565744

Epoch: 6| Step: 11
Training loss: 0.07822311022623177
Validation loss: 2.2133012994097947

Epoch: 6| Step: 12
Training loss: 0.08341702403768618
Validation loss: 2.242448851343351

Epoch: 6| Step: 13
Training loss: 0.07661441483123596
Validation loss: 2.227241869282398

Epoch: 737| Step: 0
Training loss: 0.06731200990347928
Validation loss: 2.237317406523174

Epoch: 6| Step: 1
Training loss: 0.07920158502639787
Validation loss: 2.2347888633518878

Epoch: 6| Step: 2
Training loss: 0.06314364943875322
Validation loss: 2.2100062899151327

Epoch: 6| Step: 3
Training loss: 0.07463943939233614
Validation loss: 2.2307694134796194

Epoch: 6| Step: 4
Training loss: 0.1072955602646152
Validation loss: 2.223116971139406

Epoch: 6| Step: 5
Training loss: 0.07442754312995667
Validation loss: 2.256851307346308

Epoch: 6| Step: 6
Training loss: 0.07973012088271572
Validation loss: 2.267330360950532

Epoch: 6| Step: 7
Training loss: 0.08505342645201729
Validation loss: 2.253812410801796

Epoch: 6| Step: 8
Training loss: 0.046600536653302396
Validation loss: 2.236204062022303

Epoch: 6| Step: 9
Training loss: 0.07812276479384558
Validation loss: 2.2412521837144923

Epoch: 6| Step: 10
Training loss: 0.07797062045015304
Validation loss: 2.227845245841448

Epoch: 6| Step: 11
Training loss: 0.07532340756745962
Validation loss: 2.2420035431810197

Epoch: 6| Step: 12
Training loss: 0.07207119406184233
Validation loss: 2.244258331225243

Epoch: 6| Step: 13
Training loss: 0.06007467031467296
Validation loss: 2.244634442680819

Epoch: 738| Step: 0
Training loss: 0.05661697140438319
Validation loss: 2.2718268873286656

Epoch: 6| Step: 1
Training loss: 0.09814353012409419
Validation loss: 2.231084879416663

Epoch: 6| Step: 2
Training loss: 0.07039364794507233
Validation loss: 2.218281016511291

Epoch: 6| Step: 3
Training loss: 0.09614488280223568
Validation loss: 2.206431510154411

Epoch: 6| Step: 4
Training loss: 0.0864710985329381
Validation loss: 2.214822448765777

Epoch: 6| Step: 5
Training loss: 0.08090995885662575
Validation loss: 2.2259451637304806

Epoch: 6| Step: 6
Training loss: 0.06642808274788496
Validation loss: 2.213626461443772

Epoch: 6| Step: 7
Training loss: 0.07019691769012265
Validation loss: 2.1999459703304813

Epoch: 6| Step: 8
Training loss: 0.07838461179520713
Validation loss: 2.2236812755478623

Epoch: 6| Step: 9
Training loss: 0.07969185662982592
Validation loss: 2.2073743734418496

Epoch: 6| Step: 10
Training loss: 0.09066004609855664
Validation loss: 2.19136044712474

Epoch: 6| Step: 11
Training loss: 0.06459278090783063
Validation loss: 2.2238498584536392

Epoch: 6| Step: 12
Training loss: 0.06348252268465929
Validation loss: 2.199591134458897

Epoch: 6| Step: 13
Training loss: 0.041394369652240005
Validation loss: 2.221206147884272

Epoch: 739| Step: 0
Training loss: 0.05479885157932604
Validation loss: 2.2177757910179365

Epoch: 6| Step: 1
Training loss: 0.06314804456749734
Validation loss: 2.224700116610554

Epoch: 6| Step: 2
Training loss: 0.06768274587929173
Validation loss: 2.209273724535828

Epoch: 6| Step: 3
Training loss: 0.08809847097612547
Validation loss: 2.229697313153532

Epoch: 6| Step: 4
Training loss: 0.08505120907774325
Validation loss: 2.240228546753239

Epoch: 6| Step: 5
Training loss: 0.10310676189463645
Validation loss: 2.2072589576392647

Epoch: 6| Step: 6
Training loss: 0.0986768558102856
Validation loss: 2.243445150439236

Epoch: 6| Step: 7
Training loss: 0.07035030898164088
Validation loss: 2.246390296795343

Epoch: 6| Step: 8
Training loss: 0.07226217751398864
Validation loss: 2.2302845306521624

Epoch: 6| Step: 9
Training loss: 0.1156096812359017
Validation loss: 2.220455638906858

Epoch: 6| Step: 10
Training loss: 0.06341355938469238
Validation loss: 2.2145434939975828

Epoch: 6| Step: 11
Training loss: 0.0801925016803428
Validation loss: 2.2095702940985307

Epoch: 6| Step: 12
Training loss: 0.10788383853404275
Validation loss: 2.212472103404888

Epoch: 6| Step: 13
Training loss: 0.08456184937328315
Validation loss: 2.208840560551043

Epoch: 740| Step: 0
Training loss: 0.08459178980013714
Validation loss: 2.2432327889628434

Epoch: 6| Step: 1
Training loss: 0.05773166219418681
Validation loss: 2.2307216483027545

Epoch: 6| Step: 2
Training loss: 0.11664642352787048
Validation loss: 2.2331236090040045

Epoch: 6| Step: 3
Training loss: 0.08658054202515986
Validation loss: 2.258698707471832

Epoch: 6| Step: 4
Training loss: 0.06369486098408436
Validation loss: 2.2736148582508786

Epoch: 6| Step: 5
Training loss: 0.07985733285751044
Validation loss: 2.2845058663085207

Epoch: 6| Step: 6
Training loss: 0.07303722950292635
Validation loss: 2.2901437209112414

Epoch: 6| Step: 7
Training loss: 0.07305875696860446
Validation loss: 2.2704179814254855

Epoch: 6| Step: 8
Training loss: 0.1166382155326029
Validation loss: 2.275507660542816

Epoch: 6| Step: 9
Training loss: 0.11581290222958639
Validation loss: 2.287545181425333

Epoch: 6| Step: 10
Training loss: 0.09309243521701509
Validation loss: 2.2802330432829185

Epoch: 6| Step: 11
Training loss: 0.07946598326370401
Validation loss: 2.26578933776098

Epoch: 6| Step: 12
Training loss: 0.07235001778382417
Validation loss: 2.2720495188310883

Epoch: 6| Step: 13
Training loss: 0.060158940354169584
Validation loss: 2.2625010043350318

Epoch: 741| Step: 0
Training loss: 0.07085918122615206
Validation loss: 2.2434517405240557

Epoch: 6| Step: 1
Training loss: 0.08642192875093682
Validation loss: 2.2479793990727277

Epoch: 6| Step: 2
Training loss: 0.09108321786588439
Validation loss: 2.229220822557865

Epoch: 6| Step: 3
Training loss: 0.0789061711565889
Validation loss: 2.2003028042705006

Epoch: 6| Step: 4
Training loss: 0.14683730524374444
Validation loss: 2.2100176742738604

Epoch: 6| Step: 5
Training loss: 0.06022290107527341
Validation loss: 2.2069946402184

Epoch: 6| Step: 6
Training loss: 0.05901750477323813
Validation loss: 2.195621842810988

Epoch: 6| Step: 7
Training loss: 0.05948686226488718
Validation loss: 2.228625698728281

Epoch: 6| Step: 8
Training loss: 0.08068044856268353
Validation loss: 2.1990002358727208

Epoch: 6| Step: 9
Training loss: 0.06352516661009995
Validation loss: 2.23186281302121

Epoch: 6| Step: 10
Training loss: 0.0955262398446395
Validation loss: 2.214341856618686

Epoch: 6| Step: 11
Training loss: 0.09503048385742806
Validation loss: 2.2457264161561277

Epoch: 6| Step: 12
Training loss: 0.07968508398844008
Validation loss: 2.2249345341285527

Epoch: 6| Step: 13
Training loss: 0.027622645142689996
Validation loss: 2.2346812723226144

Epoch: 742| Step: 0
Training loss: 0.06981532833881031
Validation loss: 2.2349716039430527

Epoch: 6| Step: 1
Training loss: 0.08505476779851612
Validation loss: 2.2343488835561716

Epoch: 6| Step: 2
Training loss: 0.07959622667613284
Validation loss: 2.2238624140733694

Epoch: 6| Step: 3
Training loss: 0.07483773858411615
Validation loss: 2.2422359193062524

Epoch: 6| Step: 4
Training loss: 0.04310055857729149
Validation loss: 2.2282254099997236

Epoch: 6| Step: 5
Training loss: 0.09858022836650264
Validation loss: 2.213538589813198

Epoch: 6| Step: 6
Training loss: 0.10251249241588757
Validation loss: 2.221734300708654

Epoch: 6| Step: 7
Training loss: 0.07965885283212329
Validation loss: 2.1962798936526156

Epoch: 6| Step: 8
Training loss: 0.07812812322095737
Validation loss: 2.198721754900564

Epoch: 6| Step: 9
Training loss: 0.07019218774335328
Validation loss: 2.1984318762770125

Epoch: 6| Step: 10
Training loss: 0.09595224498611725
Validation loss: 2.210757801454362

Epoch: 6| Step: 11
Training loss: 0.13611810760765083
Validation loss: 2.1997586593368266

Epoch: 6| Step: 12
Training loss: 0.08936177424294747
Validation loss: 2.2073509792738344

Epoch: 6| Step: 13
Training loss: 0.04641938063504651
Validation loss: 2.1901136889278803

Epoch: 743| Step: 0
Training loss: 0.0715209898433497
Validation loss: 2.216588630416015

Epoch: 6| Step: 1
Training loss: 0.09017333447311879
Validation loss: 2.177523225914479

Epoch: 6| Step: 2
Training loss: 0.0795646522299048
Validation loss: 2.219114726256404

Epoch: 6| Step: 3
Training loss: 0.10931233756825946
Validation loss: 2.1909254885241336

Epoch: 6| Step: 4
Training loss: 0.10244465069137772
Validation loss: 2.2269191888731403

Epoch: 6| Step: 5
Training loss: 0.0865625925786594
Validation loss: 2.2074209095966917

Epoch: 6| Step: 6
Training loss: 0.08180192841602169
Validation loss: 2.223425163198094

Epoch: 6| Step: 7
Training loss: 0.06760538356275521
Validation loss: 2.2025507604243084

Epoch: 6| Step: 8
Training loss: 0.09727727310875997
Validation loss: 2.1887112687515655

Epoch: 6| Step: 9
Training loss: 0.07556732845655686
Validation loss: 2.1693131570577693

Epoch: 6| Step: 10
Training loss: 0.08753084081998803
Validation loss: 2.2255696029973295

Epoch: 6| Step: 11
Training loss: 0.050244752678141456
Validation loss: 2.227048363285343

Epoch: 6| Step: 12
Training loss: 0.06119612258283396
Validation loss: 2.2234208705223355

Epoch: 6| Step: 13
Training loss: 0.0516025603433966
Validation loss: 2.227888588685416

Epoch: 744| Step: 0
Training loss: 0.06701829001379034
Validation loss: 2.1961792415876693

Epoch: 6| Step: 1
Training loss: 0.11390106227296089
Validation loss: 2.210459789563617

Epoch: 6| Step: 2
Training loss: 0.05432209271468702
Validation loss: 2.2436396732079897

Epoch: 6| Step: 3
Training loss: 0.08303144342983573
Validation loss: 2.227487900483807

Epoch: 6| Step: 4
Training loss: 0.09106261223371785
Validation loss: 2.2355838944247126

Epoch: 6| Step: 5
Training loss: 0.07184581669472702
Validation loss: 2.20944686795735

Epoch: 6| Step: 6
Training loss: 0.04817262298109687
Validation loss: 2.2314658794764344

Epoch: 6| Step: 7
Training loss: 0.07940607561777627
Validation loss: 2.2458279885196055

Epoch: 6| Step: 8
Training loss: 0.062370969902900406
Validation loss: 2.241101773606762

Epoch: 6| Step: 9
Training loss: 0.07515678409537324
Validation loss: 2.2095419358132764

Epoch: 6| Step: 10
Training loss: 0.07068039755381815
Validation loss: 2.2084004544230678

Epoch: 6| Step: 11
Training loss: 0.08643745084955634
Validation loss: 2.184736008651639

Epoch: 6| Step: 12
Training loss: 0.06626830780357026
Validation loss: 2.194009095513466

Epoch: 6| Step: 13
Training loss: 0.09181647903027274
Validation loss: 2.2081782061497957

Epoch: 745| Step: 0
Training loss: 0.04215352812085804
Validation loss: 2.1933576457312545

Epoch: 6| Step: 1
Training loss: 0.09816812829410758
Validation loss: 2.194182202649826

Epoch: 6| Step: 2
Training loss: 0.10855621162489425
Validation loss: 2.200559619072202

Epoch: 6| Step: 3
Training loss: 0.07606667198385876
Validation loss: 2.2362586521166175

Epoch: 6| Step: 4
Training loss: 0.06409358398605712
Validation loss: 2.2222147534699532

Epoch: 6| Step: 5
Training loss: 0.08349489188862969
Validation loss: 2.210232356012806

Epoch: 6| Step: 6
Training loss: 0.11874710427693806
Validation loss: 2.229205841818132

Epoch: 6| Step: 7
Training loss: 0.052135169291520726
Validation loss: 2.2553863201277373

Epoch: 6| Step: 8
Training loss: 0.07955948420290512
Validation loss: 2.2457356074405994

Epoch: 6| Step: 9
Training loss: 0.07465166022082759
Validation loss: 2.257458199419623

Epoch: 6| Step: 10
Training loss: 0.10759372836269812
Validation loss: 2.2428564556044672

Epoch: 6| Step: 11
Training loss: 0.06480439870676877
Validation loss: 2.2616029857426163

Epoch: 6| Step: 12
Training loss: 0.06589671251405677
Validation loss: 2.2595211784599387

Epoch: 6| Step: 13
Training loss: 0.06261299394711432
Validation loss: 2.2654161582593937

Epoch: 746| Step: 0
Training loss: 0.0745954053592829
Validation loss: 2.2627944129714845

Epoch: 6| Step: 1
Training loss: 0.07032685000957452
Validation loss: 2.267154372887689

Epoch: 6| Step: 2
Training loss: 0.05635657694395894
Validation loss: 2.257597140793209

Epoch: 6| Step: 3
Training loss: 0.08819634460492749
Validation loss: 2.253102382116123

Epoch: 6| Step: 4
Training loss: 0.10763917099580747
Validation loss: 2.245479456579084

Epoch: 6| Step: 5
Training loss: 0.09163435286044302
Validation loss: 2.262750653356033

Epoch: 6| Step: 6
Training loss: 0.08256775671379735
Validation loss: 2.241371087616289

Epoch: 6| Step: 7
Training loss: 0.09226437491103838
Validation loss: 2.243380175303227

Epoch: 6| Step: 8
Training loss: 0.06549441992854549
Validation loss: 2.259856498911064

Epoch: 6| Step: 9
Training loss: 0.13963762654959624
Validation loss: 2.275877595636887

Epoch: 6| Step: 10
Training loss: 0.06208239305160728
Validation loss: 2.217049701268758

Epoch: 6| Step: 11
Training loss: 0.09022709189578497
Validation loss: 2.236123631111379

Epoch: 6| Step: 12
Training loss: 0.06723805787542425
Validation loss: 2.212208518369573

Epoch: 6| Step: 13
Training loss: 0.050827539419048724
Validation loss: 2.213742516879975

Epoch: 747| Step: 0
Training loss: 0.059686867238730096
Validation loss: 2.2167346651622504

Epoch: 6| Step: 1
Training loss: 0.041232260728797356
Validation loss: 2.214900512743458

Epoch: 6| Step: 2
Training loss: 0.10547059110518019
Validation loss: 2.2220701408730297

Epoch: 6| Step: 3
Training loss: 0.06425717941946284
Validation loss: 2.226823085640169

Epoch: 6| Step: 4
Training loss: 0.08283820776655741
Validation loss: 2.22240268306102

Epoch: 6| Step: 5
Training loss: 0.11564520968557264
Validation loss: 2.217865116505675

Epoch: 6| Step: 6
Training loss: 0.06875322846396681
Validation loss: 2.235112372698385

Epoch: 6| Step: 7
Training loss: 0.10295542245062304
Validation loss: 2.2111175485828736

Epoch: 6| Step: 8
Training loss: 0.0918744956216786
Validation loss: 2.217567606569139

Epoch: 6| Step: 9
Training loss: 0.08520912226394876
Validation loss: 2.1966502309427662

Epoch: 6| Step: 10
Training loss: 0.07988144400060967
Validation loss: 2.2568010614588787

Epoch: 6| Step: 11
Training loss: 0.05358866515588585
Validation loss: 2.2282719743468653

Epoch: 6| Step: 12
Training loss: 0.07875925632697629
Validation loss: 2.236930158918869

Epoch: 6| Step: 13
Training loss: 0.05735491811153763
Validation loss: 2.232697698695014

Epoch: 748| Step: 0
Training loss: 0.13509832998882335
Validation loss: 2.244112433397263

Epoch: 6| Step: 1
Training loss: 0.08991679042158605
Validation loss: 2.222219108464852

Epoch: 6| Step: 2
Training loss: 0.044154511647316506
Validation loss: 2.2135689717200555

Epoch: 6| Step: 3
Training loss: 0.09461483806521359
Validation loss: 2.2371873745922115

Epoch: 6| Step: 4
Training loss: 0.06470029931783165
Validation loss: 2.1900647411890133

Epoch: 6| Step: 5
Training loss: 0.10571238845811642
Validation loss: 2.1586755138602083

Epoch: 6| Step: 6
Training loss: 0.08794947349482643
Validation loss: 2.177195329509008

Epoch: 6| Step: 7
Training loss: 0.09261846146497749
Validation loss: 2.1733424323493122

Epoch: 6| Step: 8
Training loss: 0.08271773928873988
Validation loss: 2.1828191172995504

Epoch: 6| Step: 9
Training loss: 0.08846991684567582
Validation loss: 2.1731105136996933

Epoch: 6| Step: 10
Training loss: 0.08460461777498157
Validation loss: 2.1822606100502546

Epoch: 6| Step: 11
Training loss: 0.0618219776866943
Validation loss: 2.193925767776526

Epoch: 6| Step: 12
Training loss: 0.07337966097133156
Validation loss: 2.204791914282779

Epoch: 6| Step: 13
Training loss: 0.04582436651782091
Validation loss: 2.2045575117925207

Epoch: 749| Step: 0
Training loss: 0.09247272342203595
Validation loss: 2.1976983897485214

Epoch: 6| Step: 1
Training loss: 0.10184644017202947
Validation loss: 2.2175688082929153

Epoch: 6| Step: 2
Training loss: 0.10494768384839809
Validation loss: 2.230187862323919

Epoch: 6| Step: 3
Training loss: 0.07144675385286733
Validation loss: 2.2341025395967478

Epoch: 6| Step: 4
Training loss: 0.09246533077618238
Validation loss: 2.226619410151837

Epoch: 6| Step: 5
Training loss: 0.0715696417793032
Validation loss: 2.2332053926444155

Epoch: 6| Step: 6
Training loss: 0.11075495523525045
Validation loss: 2.2254624889774672

Epoch: 6| Step: 7
Training loss: 0.1216456388592928
Validation loss: 2.2322642778225017

Epoch: 6| Step: 8
Training loss: 0.07800889925135263
Validation loss: 2.219688778469019

Epoch: 6| Step: 9
Training loss: 0.04428863459676632
Validation loss: 2.226594404773862

Epoch: 6| Step: 10
Training loss: 0.10088135567689048
Validation loss: 2.1769566289817526

Epoch: 6| Step: 11
Training loss: 0.05874167287560273
Validation loss: 2.149080999365212

Epoch: 6| Step: 12
Training loss: 0.09484641859300381
Validation loss: 2.1688656730617333

Epoch: 6| Step: 13
Training loss: 0.12298620332801435
Validation loss: 2.158120347470084

Epoch: 750| Step: 0
Training loss: 0.09056547775269748
Validation loss: 2.1358967319231636

Epoch: 6| Step: 1
Training loss: 0.11033686818550993
Validation loss: 2.1590052842883343

Epoch: 6| Step: 2
Training loss: 0.1415431198007718
Validation loss: 2.1698837234830606

Epoch: 6| Step: 3
Training loss: 0.10798869576032223
Validation loss: 2.176792542406645

Epoch: 6| Step: 4
Training loss: 0.11599186676488749
Validation loss: 2.1741622636898144

Epoch: 6| Step: 5
Training loss: 0.07635439804672235
Validation loss: 2.1884236941873882

Epoch: 6| Step: 6
Training loss: 0.08950169381677968
Validation loss: 2.2294340831966957

Epoch: 6| Step: 7
Training loss: 0.09785329965659842
Validation loss: 2.2215026668110402

Epoch: 6| Step: 8
Training loss: 0.09461067425617717
Validation loss: 2.1967565331119516

Epoch: 6| Step: 9
Training loss: 0.1442947127506029
Validation loss: 2.2108953137041674

Epoch: 6| Step: 10
Training loss: 0.06238646178299807
Validation loss: 2.2356743866863495

Epoch: 6| Step: 11
Training loss: 0.09472383908161698
Validation loss: 2.2262516710768967

Epoch: 6| Step: 12
Training loss: 0.09645044718686163
Validation loss: 2.222251913126985

Epoch: 6| Step: 13
Training loss: 0.07216969450563569
Validation loss: 2.2258088456061187

Epoch: 751| Step: 0
Training loss: 0.08830302758957191
Validation loss: 2.1992282679620003

Epoch: 6| Step: 1
Training loss: 0.07611213077285517
Validation loss: 2.205800897363886

Epoch: 6| Step: 2
Training loss: 0.056301245013035184
Validation loss: 2.2152719391414886

Epoch: 6| Step: 3
Training loss: 0.07695393247229138
Validation loss: 2.188616758498348

Epoch: 6| Step: 4
Training loss: 0.11344626345556716
Validation loss: 2.1884408929878973

Epoch: 6| Step: 5
Training loss: 0.10171287664693211
Validation loss: 2.2214595490439244

Epoch: 6| Step: 6
Training loss: 0.08594069691693815
Validation loss: 2.1905601192382638

Epoch: 6| Step: 7
Training loss: 0.0542247750627006
Validation loss: 2.218716829275262

Epoch: 6| Step: 8
Training loss: 0.10177750479290684
Validation loss: 2.214347145186214

Epoch: 6| Step: 9
Training loss: 0.09052726679760606
Validation loss: 2.2110111634918077

Epoch: 6| Step: 10
Training loss: 0.05625876831881753
Validation loss: 2.2111675601203906

Epoch: 6| Step: 11
Training loss: 0.10163111386377695
Validation loss: 2.2052813708359937

Epoch: 6| Step: 12
Training loss: 0.13228669285497804
Validation loss: 2.2510711371735064

Epoch: 6| Step: 13
Training loss: 0.0380941253810644
Validation loss: 2.2448385644073827

Epoch: 752| Step: 0
Training loss: 0.10474296139783805
Validation loss: 2.2031159084751826

Epoch: 6| Step: 1
Training loss: 0.07450734671868811
Validation loss: 2.2377258062869156

Epoch: 6| Step: 2
Training loss: 0.08623478145334235
Validation loss: 2.183944951860888

Epoch: 6| Step: 3
Training loss: 0.0517042688303461
Validation loss: 2.2492598748550425

Epoch: 6| Step: 4
Training loss: 0.08673257846377028
Validation loss: 2.265439068240874

Epoch: 6| Step: 5
Training loss: 0.13391395642373352
Validation loss: 2.2199733526867553

Epoch: 6| Step: 6
Training loss: 0.05885437184518873
Validation loss: 2.255980340862385

Epoch: 6| Step: 7
Training loss: 0.0675470520531661
Validation loss: 2.2351933050839854

Epoch: 6| Step: 8
Training loss: 0.0691357934201127
Validation loss: 2.256279203714331

Epoch: 6| Step: 9
Training loss: 0.05788227297757613
Validation loss: 2.22974074359401

Epoch: 6| Step: 10
Training loss: 0.052086202224555365
Validation loss: 2.2504350157385726

Epoch: 6| Step: 11
Training loss: 0.0940508683670806
Validation loss: 2.21878108352779

Epoch: 6| Step: 12
Training loss: 0.051205749801814984
Validation loss: 2.2357079892364635

Epoch: 6| Step: 13
Training loss: 0.0744949771976852
Validation loss: 2.2566300801794124

Epoch: 753| Step: 0
Training loss: 0.08044611881115418
Validation loss: 2.2611654737918014

Epoch: 6| Step: 1
Training loss: 0.09594790625904327
Validation loss: 2.2649588573416835

Epoch: 6| Step: 2
Training loss: 0.08710204112822738
Validation loss: 2.2374743189449027

Epoch: 6| Step: 3
Training loss: 0.0530281932685485
Validation loss: 2.2080585906593813

Epoch: 6| Step: 4
Training loss: 0.10668615776926141
Validation loss: 2.2361313651604173

Epoch: 6| Step: 5
Training loss: 0.0857412687960613
Validation loss: 2.2262293510425737

Epoch: 6| Step: 6
Training loss: 0.07397007692256453
Validation loss: 2.2183083893892914

Epoch: 6| Step: 7
Training loss: 0.07864669717489012
Validation loss: 2.2311163851504556

Epoch: 6| Step: 8
Training loss: 0.05927819796579876
Validation loss: 2.2398782181587245

Epoch: 6| Step: 9
Training loss: 0.07403018802369835
Validation loss: 2.233854157822256

Epoch: 6| Step: 10
Training loss: 0.06925515384917694
Validation loss: 2.2469373981723075

Epoch: 6| Step: 11
Training loss: 0.06110138351832218
Validation loss: 2.225263660106231

Epoch: 6| Step: 12
Training loss: 0.06977704595440212
Validation loss: 2.2325745831267936

Epoch: 6| Step: 13
Training loss: 0.05697503928744521
Validation loss: 2.243492056520579

Epoch: 754| Step: 0
Training loss: 0.07248398293539011
Validation loss: 2.2409619628026434

Epoch: 6| Step: 1
Training loss: 0.07823960124296504
Validation loss: 2.271243371565713

Epoch: 6| Step: 2
Training loss: 0.09284409291959365
Validation loss: 2.2417202228547217

Epoch: 6| Step: 3
Training loss: 0.07007514442263271
Validation loss: 2.244298734967364

Epoch: 6| Step: 4
Training loss: 0.0926465371221113
Validation loss: 2.25483043757291

Epoch: 6| Step: 5
Training loss: 0.0894525761150195
Validation loss: 2.250311747867913

Epoch: 6| Step: 6
Training loss: 0.07384596551060899
Validation loss: 2.2576518151513776

Epoch: 6| Step: 7
Training loss: 0.09744047645802696
Validation loss: 2.243581609353987

Epoch: 6| Step: 8
Training loss: 0.10573099346962972
Validation loss: 2.2386500156400717

Epoch: 6| Step: 9
Training loss: 0.07785134967194908
Validation loss: 2.2274634975812666

Epoch: 6| Step: 10
Training loss: 0.07983899465348583
Validation loss: 2.225731926149374

Epoch: 6| Step: 11
Training loss: 0.06427671754428262
Validation loss: 2.2104470975065293

Epoch: 6| Step: 12
Training loss: 0.06655204419948757
Validation loss: 2.1895269094781273

Epoch: 6| Step: 13
Training loss: 0.09522008147872132
Validation loss: 2.196927291800205

Epoch: 755| Step: 0
Training loss: 0.08442232528858028
Validation loss: 2.2107625564741626

Epoch: 6| Step: 1
Training loss: 0.09534574948836466
Validation loss: 2.200035350875383

Epoch: 6| Step: 2
Training loss: 0.09470709866210401
Validation loss: 2.1928400468705527

Epoch: 6| Step: 3
Training loss: 0.06231636398343647
Validation loss: 2.1855522191692733

Epoch: 6| Step: 4
Training loss: 0.07900414826364312
Validation loss: 2.2034848333232033

Epoch: 6| Step: 5
Training loss: 0.09673582720479057
Validation loss: 2.221949213017172

Epoch: 6| Step: 6
Training loss: 0.06339912092177788
Validation loss: 2.1969472717310503

Epoch: 6| Step: 7
Training loss: 0.07442138953694312
Validation loss: 2.202265193845284

Epoch: 6| Step: 8
Training loss: 0.06579370795798768
Validation loss: 2.245427616420825

Epoch: 6| Step: 9
Training loss: 0.0892749381800106
Validation loss: 2.247985905444439

Epoch: 6| Step: 10
Training loss: 0.052504058614310664
Validation loss: 2.2237306448371927

Epoch: 6| Step: 11
Training loss: 0.05514561199675655
Validation loss: 2.234962900915127

Epoch: 6| Step: 12
Training loss: 0.06593496315491881
Validation loss: 2.232921360115193

Epoch: 6| Step: 13
Training loss: 0.07149091974638629
Validation loss: 2.2591678176333287

Epoch: 756| Step: 0
Training loss: 0.09198938636807655
Validation loss: 2.2012510921538477

Epoch: 6| Step: 1
Training loss: 0.06132937471064075
Validation loss: 2.218664780926677

Epoch: 6| Step: 2
Training loss: 0.07850547174499682
Validation loss: 2.205863937962182

Epoch: 6| Step: 3
Training loss: 0.07481249053934304
Validation loss: 2.219727049882657

Epoch: 6| Step: 4
Training loss: 0.07889108854460986
Validation loss: 2.2322899684683546

Epoch: 6| Step: 5
Training loss: 0.06742999249542812
Validation loss: 2.2295461184982512

Epoch: 6| Step: 6
Training loss: 0.08360501206819608
Validation loss: 2.224347832160098

Epoch: 6| Step: 7
Training loss: 0.07930075325901265
Validation loss: 2.171225239824266

Epoch: 6| Step: 8
Training loss: 0.08039949061458634
Validation loss: 2.2111965149328596

Epoch: 6| Step: 9
Training loss: 0.0964687869572669
Validation loss: 2.2235147482853956

Epoch: 6| Step: 10
Training loss: 0.044523794717120445
Validation loss: 2.204417596927958

Epoch: 6| Step: 11
Training loss: 0.05341988077176411
Validation loss: 2.2105550487022545

Epoch: 6| Step: 12
Training loss: 0.09588701234495084
Validation loss: 2.2222298338291426

Epoch: 6| Step: 13
Training loss: 0.0778911428329105
Validation loss: 2.252776597566252

Epoch: 757| Step: 0
Training loss: 0.07117349912232881
Validation loss: 2.233080171455924

Epoch: 6| Step: 1
Training loss: 0.11473773357697145
Validation loss: 2.2495380426434264

Epoch: 6| Step: 2
Training loss: 0.0932585780628499
Validation loss: 2.2244619259618386

Epoch: 6| Step: 3
Training loss: 0.09974355168909996
Validation loss: 2.2265574333048357

Epoch: 6| Step: 4
Training loss: 0.044074993057603394
Validation loss: 2.221487401488451

Epoch: 6| Step: 5
Training loss: 0.11572853910405917
Validation loss: 2.2043736082604504

Epoch: 6| Step: 6
Training loss: 0.08637933506762376
Validation loss: 2.1902302241686162

Epoch: 6| Step: 7
Training loss: 0.07981391094419878
Validation loss: 2.2156603548577207

Epoch: 6| Step: 8
Training loss: 0.061668168992164284
Validation loss: 2.189293550654004

Epoch: 6| Step: 9
Training loss: 0.09064114751502435
Validation loss: 2.16721138444945

Epoch: 6| Step: 10
Training loss: 0.13620387265498077
Validation loss: 2.185593563313796

Epoch: 6| Step: 11
Training loss: 0.0820307816764542
Validation loss: 2.232436321415889

Epoch: 6| Step: 12
Training loss: 0.11707966134257043
Validation loss: 2.200632027553665

Epoch: 6| Step: 13
Training loss: 0.08195541486822978
Validation loss: 2.2285565494059956

Epoch: 758| Step: 0
Training loss: 0.06510637597467994
Validation loss: 2.1947167401632215

Epoch: 6| Step: 1
Training loss: 0.08593016831594447
Validation loss: 2.2275969190244975

Epoch: 6| Step: 2
Training loss: 0.07067659931619176
Validation loss: 2.2443663403994756

Epoch: 6| Step: 3
Training loss: 0.07982018261051652
Validation loss: 2.242993630963925

Epoch: 6| Step: 4
Training loss: 0.0963077664344606
Validation loss: 2.2643539059666895

Epoch: 6| Step: 5
Training loss: 0.10216915985329046
Validation loss: 2.2437552302664026

Epoch: 6| Step: 6
Training loss: 0.09743133871401255
Validation loss: 2.239251866080134

Epoch: 6| Step: 7
Training loss: 0.05286640839801011
Validation loss: 2.24537658912786

Epoch: 6| Step: 8
Training loss: 0.08119838684591064
Validation loss: 2.268347408415595

Epoch: 6| Step: 9
Training loss: 0.07765512728023427
Validation loss: 2.251971314403763

Epoch: 6| Step: 10
Training loss: 0.12226982596983332
Validation loss: 2.2640525976688726

Epoch: 6| Step: 11
Training loss: 0.13586671866410127
Validation loss: 2.256457493083089

Epoch: 6| Step: 12
Training loss: 0.12514151817466948
Validation loss: 2.2371026263782343

Epoch: 6| Step: 13
Training loss: 0.0880837993193151
Validation loss: 2.246446670690919

Epoch: 759| Step: 0
Training loss: 0.06800321028780187
Validation loss: 2.2229694972067944

Epoch: 6| Step: 1
Training loss: 0.08552854670401436
Validation loss: 2.2619839435811135

Epoch: 6| Step: 2
Training loss: 0.04668635915220271
Validation loss: 2.2171722052448124

Epoch: 6| Step: 3
Training loss: 0.08662440219482967
Validation loss: 2.2426338267518684

Epoch: 6| Step: 4
Training loss: 0.09857902382117245
Validation loss: 2.2181323328517832

Epoch: 6| Step: 5
Training loss: 0.10969612969308126
Validation loss: 2.2254958033705976

Epoch: 6| Step: 6
Training loss: 0.08979345033154468
Validation loss: 2.210190014167732

Epoch: 6| Step: 7
Training loss: 0.08295972777735759
Validation loss: 2.2172683079374735

Epoch: 6| Step: 8
Training loss: 0.07953011430442851
Validation loss: 2.2289120873106083

Epoch: 6| Step: 9
Training loss: 0.0999345334157264
Validation loss: 2.217198630966552

Epoch: 6| Step: 10
Training loss: 0.08269979887312864
Validation loss: 2.2076709351343213

Epoch: 6| Step: 11
Training loss: 0.07324024197855523
Validation loss: 2.2318727109603858

Epoch: 6| Step: 12
Training loss: 0.09085545321468957
Validation loss: 2.224730228552196

Epoch: 6| Step: 13
Training loss: 0.06920784212560974
Validation loss: 2.2375149786690636

Epoch: 760| Step: 0
Training loss: 0.08093372764228349
Validation loss: 2.2209358142126496

Epoch: 6| Step: 1
Training loss: 0.06172370106117152
Validation loss: 2.2117442817906765

Epoch: 6| Step: 2
Training loss: 0.10855173320394716
Validation loss: 2.2395107806035006

Epoch: 6| Step: 3
Training loss: 0.09685400939229673
Validation loss: 2.2247685682274265

Epoch: 6| Step: 4
Training loss: 0.08174725315800994
Validation loss: 2.230271184714348

Epoch: 6| Step: 5
Training loss: 0.05340931907795068
Validation loss: 2.2216382175358302

Epoch: 6| Step: 6
Training loss: 0.06716656192283493
Validation loss: 2.2326407264589596

Epoch: 6| Step: 7
Training loss: 0.09427342723031722
Validation loss: 2.252917123754519

Epoch: 6| Step: 8
Training loss: 0.07319675307902737
Validation loss: 2.233062470501742

Epoch: 6| Step: 9
Training loss: 0.06894884721810297
Validation loss: 2.268584691966171

Epoch: 6| Step: 10
Training loss: 0.05986395753039753
Validation loss: 2.2550919703655157

Epoch: 6| Step: 11
Training loss: 0.08737867450423313
Validation loss: 2.2355979041425256

Epoch: 6| Step: 12
Training loss: 0.07994792110627418
Validation loss: 2.2292606121972147

Epoch: 6| Step: 13
Training loss: 0.0527297190094273
Validation loss: 2.2466762089614147

Epoch: 761| Step: 0
Training loss: 0.05352173773806485
Validation loss: 2.2347570531974204

Epoch: 6| Step: 1
Training loss: 0.0713372981825608
Validation loss: 2.209474124603155

Epoch: 6| Step: 2
Training loss: 0.07139169151217518
Validation loss: 2.2435108732991753

Epoch: 6| Step: 3
Training loss: 0.03754386676855029
Validation loss: 2.2438479739390655

Epoch: 6| Step: 4
Training loss: 0.09265396556804262
Validation loss: 2.228843559360963

Epoch: 6| Step: 5
Training loss: 0.09013561855649026
Validation loss: 2.2080161942124725

Epoch: 6| Step: 6
Training loss: 0.07692930934991656
Validation loss: 2.218556544876656

Epoch: 6| Step: 7
Training loss: 0.05840301862501138
Validation loss: 2.213475548892587

Epoch: 6| Step: 8
Training loss: 0.0817999986199703
Validation loss: 2.214360097087132

Epoch: 6| Step: 9
Training loss: 0.05705555053556
Validation loss: 2.2218626235998666

Epoch: 6| Step: 10
Training loss: 0.08561211182278218
Validation loss: 2.202721690267102

Epoch: 6| Step: 11
Training loss: 0.06475632329253125
Validation loss: 2.2133337474557724

Epoch: 6| Step: 12
Training loss: 0.07724486734644062
Validation loss: 2.248400424942724

Epoch: 6| Step: 13
Training loss: 0.0631975829131252
Validation loss: 2.263871674537534

Epoch: 762| Step: 0
Training loss: 0.06593008989576775
Validation loss: 2.2099193114324405

Epoch: 6| Step: 1
Training loss: 0.05680538336110293
Validation loss: 2.2235855197740704

Epoch: 6| Step: 2
Training loss: 0.08224146735052795
Validation loss: 2.2511935389774713

Epoch: 6| Step: 3
Training loss: 0.09056715393415908
Validation loss: 2.2507980291894794

Epoch: 6| Step: 4
Training loss: 0.07549476139240814
Validation loss: 2.2422253210802463

Epoch: 6| Step: 5
Training loss: 0.039715885883986196
Validation loss: 2.268186425529857

Epoch: 6| Step: 6
Training loss: 0.1239556329964649
Validation loss: 2.2514618769836767

Epoch: 6| Step: 7
Training loss: 0.03475202524806619
Validation loss: 2.2402074399734424

Epoch: 6| Step: 8
Training loss: 0.10824450311073341
Validation loss: 2.2359726856883655

Epoch: 6| Step: 9
Training loss: 0.1308967408878817
Validation loss: 2.222279099237307

Epoch: 6| Step: 10
Training loss: 0.07694407145982493
Validation loss: 2.1873724383122917

Epoch: 6| Step: 11
Training loss: 0.08655676103152253
Validation loss: 2.212587180649658

Epoch: 6| Step: 12
Training loss: 0.12098472825089557
Validation loss: 2.2251271135854553

Epoch: 6| Step: 13
Training loss: 0.11550586046021392
Validation loss: 2.2228304725507284

Epoch: 763| Step: 0
Training loss: 0.1373859677726588
Validation loss: 2.2076025914897377

Epoch: 6| Step: 1
Training loss: 0.07881039141149243
Validation loss: 2.1900409326826584

Epoch: 6| Step: 2
Training loss: 0.09152054284305322
Validation loss: 2.219065083291732

Epoch: 6| Step: 3
Training loss: 0.08529962797136895
Validation loss: 2.2251037343956774

Epoch: 6| Step: 4
Training loss: 0.09454827884324687
Validation loss: 2.250905228550609

Epoch: 6| Step: 5
Training loss: 0.11268005664508156
Validation loss: 2.237351610597038

Epoch: 6| Step: 6
Training loss: 0.11025107289703731
Validation loss: 2.237231578069159

Epoch: 6| Step: 7
Training loss: 0.08971036463382416
Validation loss: 2.266103925993945

Epoch: 6| Step: 8
Training loss: 0.10169165908265664
Validation loss: 2.227077782732199

Epoch: 6| Step: 9
Training loss: 0.0866079350554299
Validation loss: 2.2397801886254918

Epoch: 6| Step: 10
Training loss: 0.06258737521317219
Validation loss: 2.2132752024451023

Epoch: 6| Step: 11
Training loss: 0.0634468669388563
Validation loss: 2.239680744026349

Epoch: 6| Step: 12
Training loss: 0.10647506035712126
Validation loss: 2.2225412901009163

Epoch: 6| Step: 13
Training loss: 0.09979647473848824
Validation loss: 2.203969467345253

Epoch: 764| Step: 0
Training loss: 0.14338217639714443
Validation loss: 2.225583465532611

Epoch: 6| Step: 1
Training loss: 0.09950410665910392
Validation loss: 2.2196901459353082

Epoch: 6| Step: 2
Training loss: 0.05416806932537524
Validation loss: 2.2550518742584607

Epoch: 6| Step: 3
Training loss: 0.10556460369310894
Validation loss: 2.245580480139558

Epoch: 6| Step: 4
Training loss: 0.04994930280617344
Validation loss: 2.210738047806323

Epoch: 6| Step: 5
Training loss: 0.09270194461147528
Validation loss: 2.2140624279329306

Epoch: 6| Step: 6
Training loss: 0.08491926705989197
Validation loss: 2.225741816222456

Epoch: 6| Step: 7
Training loss: 0.09319123005965275
Validation loss: 2.2299636134637075

Epoch: 6| Step: 8
Training loss: 0.07281725640785727
Validation loss: 2.243869961624004

Epoch: 6| Step: 9
Training loss: 0.08923753136536623
Validation loss: 2.2557426258707842

Epoch: 6| Step: 10
Training loss: 0.09050601493983265
Validation loss: 2.2547653647225947

Epoch: 6| Step: 11
Training loss: 0.06945964026921123
Validation loss: 2.222082858261801

Epoch: 6| Step: 12
Training loss: 0.11629033782177664
Validation loss: 2.2541784980579735

Epoch: 6| Step: 13
Training loss: 0.10025019769072364
Validation loss: 2.2331364316268782

Epoch: 765| Step: 0
Training loss: 0.11194801081964065
Validation loss: 2.253665963798595

Epoch: 6| Step: 1
Training loss: 0.06434904350078036
Validation loss: 2.201690601351272

Epoch: 6| Step: 2
Training loss: 0.08229106674498772
Validation loss: 2.255467880179919

Epoch: 6| Step: 3
Training loss: 0.05489757965341062
Validation loss: 2.2057766409787636

Epoch: 6| Step: 4
Training loss: 0.08237709924106205
Validation loss: 2.20707961325399

Epoch: 6| Step: 5
Training loss: 0.10397384101538627
Validation loss: 2.1922715154140646

Epoch: 6| Step: 6
Training loss: 0.11964022135258567
Validation loss: 2.226130589186249

Epoch: 6| Step: 7
Training loss: 0.08581168002405731
Validation loss: 2.199656090746291

Epoch: 6| Step: 8
Training loss: 0.11507637296457807
Validation loss: 2.239692327809532

Epoch: 6| Step: 9
Training loss: 0.10071584035296513
Validation loss: 2.2344146410621537

Epoch: 6| Step: 10
Training loss: 0.09227295446717577
Validation loss: 2.2135745227168013

Epoch: 6| Step: 11
Training loss: 0.07533013036543564
Validation loss: 2.23285827628832

Epoch: 6| Step: 12
Training loss: 0.05416584275991496
Validation loss: 2.2449299923136032

Epoch: 6| Step: 13
Training loss: 0.09143299665136707
Validation loss: 2.2156171205016246

Epoch: 766| Step: 0
Training loss: 0.08028378477954255
Validation loss: 2.2194203547411626

Epoch: 6| Step: 1
Training loss: 0.07778624763924248
Validation loss: 2.21355048296703

Epoch: 6| Step: 2
Training loss: 0.05799819757429444
Validation loss: 2.2381056592311985

Epoch: 6| Step: 3
Training loss: 0.057552195925767866
Validation loss: 2.22872094348336

Epoch: 6| Step: 4
Training loss: 0.07365963545954654
Validation loss: 2.214357425324191

Epoch: 6| Step: 5
Training loss: 0.08980252522590419
Validation loss: 2.2198548085892478

Epoch: 6| Step: 6
Training loss: 0.056065521289860705
Validation loss: 2.243127470993802

Epoch: 6| Step: 7
Training loss: 0.1204964921478305
Validation loss: 2.2341708511610348

Epoch: 6| Step: 8
Training loss: 0.08264308911200441
Validation loss: 2.2163222458539966

Epoch: 6| Step: 9
Training loss: 0.09553746073359055
Validation loss: 2.21118270190913

Epoch: 6| Step: 10
Training loss: 0.09106853874798058
Validation loss: 2.2597992448251034

Epoch: 6| Step: 11
Training loss: 0.05730269156206411
Validation loss: 2.22217298777023

Epoch: 6| Step: 12
Training loss: 0.07241838650495742
Validation loss: 2.235277428085792

Epoch: 6| Step: 13
Training loss: 0.07924409963445812
Validation loss: 2.22733119957136

Epoch: 767| Step: 0
Training loss: 0.07878707842581664
Validation loss: 2.228663016062283

Epoch: 6| Step: 1
Training loss: 0.07690023986772175
Validation loss: 2.251959794920467

Epoch: 6| Step: 2
Training loss: 0.08676120893536339
Validation loss: 2.254242908341727

Epoch: 6| Step: 3
Training loss: 0.05800499564052177
Validation loss: 2.2657411957825193

Epoch: 6| Step: 4
Training loss: 0.13221108079711022
Validation loss: 2.231713166959269

Epoch: 6| Step: 5
Training loss: 0.12585699336085357
Validation loss: 2.201940193040716

Epoch: 6| Step: 6
Training loss: 0.04636618008921185
Validation loss: 2.2271818659999845

Epoch: 6| Step: 7
Training loss: 0.0670837628636371
Validation loss: 2.1969268717085977

Epoch: 6| Step: 8
Training loss: 0.08261444062430395
Validation loss: 2.2124111326281817

Epoch: 6| Step: 9
Training loss: 0.08631448260346451
Validation loss: 2.2132951210922567

Epoch: 6| Step: 10
Training loss: 0.07925319560889282
Validation loss: 2.220972720547572

Epoch: 6| Step: 11
Training loss: 0.07023991043164197
Validation loss: 2.221318122248094

Epoch: 6| Step: 12
Training loss: 0.037671144302960174
Validation loss: 2.2569782146223347

Epoch: 6| Step: 13
Training loss: 0.12242846400623458
Validation loss: 2.2152549777282395

Epoch: 768| Step: 0
Training loss: 0.09049948558937794
Validation loss: 2.2214838424882752

Epoch: 6| Step: 1
Training loss: 0.0806591338390703
Validation loss: 2.2351095075277163

Epoch: 6| Step: 2
Training loss: 0.11351241991332008
Validation loss: 2.2413026140414276

Epoch: 6| Step: 3
Training loss: 0.04899636134512744
Validation loss: 2.234718225829315

Epoch: 6| Step: 4
Training loss: 0.06816859189262882
Validation loss: 2.228622293192796

Epoch: 6| Step: 5
Training loss: 0.11358465063152066
Validation loss: 2.257161928925127

Epoch: 6| Step: 6
Training loss: 0.0812923869883468
Validation loss: 2.2527213155365216

Epoch: 6| Step: 7
Training loss: 0.0777212228862855
Validation loss: 2.22779321743519

Epoch: 6| Step: 8
Training loss: 0.08697563037374549
Validation loss: 2.244859508019076

Epoch: 6| Step: 9
Training loss: 0.08485633340978137
Validation loss: 2.259190220760667

Epoch: 6| Step: 10
Training loss: 0.09790085675896765
Validation loss: 2.221657852918376

Epoch: 6| Step: 11
Training loss: 0.05942072025657106
Validation loss: 2.210595183594141

Epoch: 6| Step: 12
Training loss: 0.06300596609916294
Validation loss: 2.246307857629131

Epoch: 6| Step: 13
Training loss: 0.09944920190503624
Validation loss: 2.21997598391281

Epoch: 769| Step: 0
Training loss: 0.05130184608411069
Validation loss: 2.2208457580112957

Epoch: 6| Step: 1
Training loss: 0.09392996244272114
Validation loss: 2.225772297044141

Epoch: 6| Step: 2
Training loss: 0.06733245280780562
Validation loss: 2.222645572830121

Epoch: 6| Step: 3
Training loss: 0.08118492028063437
Validation loss: 2.22060078899836

Epoch: 6| Step: 4
Training loss: 0.07003248938094037
Validation loss: 2.2155209976775585

Epoch: 6| Step: 5
Training loss: 0.06661560212659383
Validation loss: 2.1936675218970034

Epoch: 6| Step: 6
Training loss: 0.07478750482230352
Validation loss: 2.22198843311568

Epoch: 6| Step: 7
Training loss: 0.04633997268340474
Validation loss: 2.2169306816731527

Epoch: 6| Step: 8
Training loss: 0.07850541242919974
Validation loss: 2.2586658192465783

Epoch: 6| Step: 9
Training loss: 0.10096885884189671
Validation loss: 2.2056242887887576

Epoch: 6| Step: 10
Training loss: 0.07965737970358473
Validation loss: 2.228383853085127

Epoch: 6| Step: 11
Training loss: 0.08160370717533233
Validation loss: 2.2527632898542613

Epoch: 6| Step: 12
Training loss: 0.07787474246502966
Validation loss: 2.2066797700949006

Epoch: 6| Step: 13
Training loss: 0.07842716552657276
Validation loss: 2.241167803115193

Epoch: 770| Step: 0
Training loss: 0.06917441722281796
Validation loss: 2.2606962165418953

Epoch: 6| Step: 1
Training loss: 0.056491015009027826
Validation loss: 2.2472231968102263

Epoch: 6| Step: 2
Training loss: 0.07555005382449771
Validation loss: 2.2577439595926037

Epoch: 6| Step: 3
Training loss: 0.060761352563709195
Validation loss: 2.237659770875279

Epoch: 6| Step: 4
Training loss: 0.0834639889079751
Validation loss: 2.237385532849265

Epoch: 6| Step: 5
Training loss: 0.08988324624047699
Validation loss: 2.270788063222005

Epoch: 6| Step: 6
Training loss: 0.06740990384376189
Validation loss: 2.2481679111454484

Epoch: 6| Step: 7
Training loss: 0.058322499174169914
Validation loss: 2.2201556534185265

Epoch: 6| Step: 8
Training loss: 0.06591503348702953
Validation loss: 2.243429521336336

Epoch: 6| Step: 9
Training loss: 0.07743671734963174
Validation loss: 2.210123041189584

Epoch: 6| Step: 10
Training loss: 0.04629419787204951
Validation loss: 2.202000136707304

Epoch: 6| Step: 11
Training loss: 0.057178211128729575
Validation loss: 2.203258130163095

Epoch: 6| Step: 12
Training loss: 0.07737996272328222
Validation loss: 2.2132381741227896

Epoch: 6| Step: 13
Training loss: 0.06132969360714526
Validation loss: 2.221634942647314

Epoch: 771| Step: 0
Training loss: 0.05355855392895278
Validation loss: 2.215282485784952

Epoch: 6| Step: 1
Training loss: 0.06732573718048261
Validation loss: 2.2137327984419577

Epoch: 6| Step: 2
Training loss: 0.06168681922774164
Validation loss: 2.212699454463919

Epoch: 6| Step: 3
Training loss: 0.06303496442081132
Validation loss: 2.2342318136085675

Epoch: 6| Step: 4
Training loss: 0.07150585055215097
Validation loss: 2.2319150620027353

Epoch: 6| Step: 5
Training loss: 0.047137424894269
Validation loss: 2.202504972810518

Epoch: 6| Step: 6
Training loss: 0.06552977166602603
Validation loss: 2.2463603222754998

Epoch: 6| Step: 7
Training loss: 0.08719290515337098
Validation loss: 2.268526486262416

Epoch: 6| Step: 8
Training loss: 0.06562195115159707
Validation loss: 2.212964588104341

Epoch: 6| Step: 9
Training loss: 0.11482199735353346
Validation loss: 2.2530588305149157

Epoch: 6| Step: 10
Training loss: 0.08847415386062395
Validation loss: 2.2527308452911012

Epoch: 6| Step: 11
Training loss: 0.07443100919017488
Validation loss: 2.261634688653874

Epoch: 6| Step: 12
Training loss: 0.09036963942927927
Validation loss: 2.234885775448401

Epoch: 6| Step: 13
Training loss: 0.06376586059357602
Validation loss: 2.218578084120083

Epoch: 772| Step: 0
Training loss: 0.04800959202794897
Validation loss: 2.2368285200409437

Epoch: 6| Step: 1
Training loss: 0.04957620720951691
Validation loss: 2.2395588508368593

Epoch: 6| Step: 2
Training loss: 0.07187360031382163
Validation loss: 2.216475623096731

Epoch: 6| Step: 3
Training loss: 0.0837954403154995
Validation loss: 2.228566448225337

Epoch: 6| Step: 4
Training loss: 0.11735366326070677
Validation loss: 2.225785234004482

Epoch: 6| Step: 5
Training loss: 0.06144129855801146
Validation loss: 2.20630828809242

Epoch: 6| Step: 6
Training loss: 0.09594254809713874
Validation loss: 2.221095994434411

Epoch: 6| Step: 7
Training loss: 0.09983255590748841
Validation loss: 2.1999456854097676

Epoch: 6| Step: 8
Training loss: 0.09753240361703273
Validation loss: 2.209751849159376

Epoch: 6| Step: 9
Training loss: 0.04229396679825347
Validation loss: 2.223269204495848

Epoch: 6| Step: 10
Training loss: 0.06088252438039315
Validation loss: 2.211698126965076

Epoch: 6| Step: 11
Training loss: 0.0551699133090478
Validation loss: 2.2122888352015053

Epoch: 6| Step: 12
Training loss: 0.07789303794995428
Validation loss: 2.2532209496682825

Epoch: 6| Step: 13
Training loss: 0.06795722998081143
Validation loss: 2.200179065061962

Epoch: 773| Step: 0
Training loss: 0.088317204112373
Validation loss: 2.2460236706173835

Epoch: 6| Step: 1
Training loss: 0.07471457923207717
Validation loss: 2.188809334938012

Epoch: 6| Step: 2
Training loss: 0.11116666127496322
Validation loss: 2.2185784174913863

Epoch: 6| Step: 3
Training loss: 0.05183994775738234
Validation loss: 2.2214766736936977

Epoch: 6| Step: 4
Training loss: 0.05673111888437059
Validation loss: 2.201343038849723

Epoch: 6| Step: 5
Training loss: 0.06882914165694239
Validation loss: 2.1889130020701235

Epoch: 6| Step: 6
Training loss: 0.07391284340608206
Validation loss: 2.2025285313539045

Epoch: 6| Step: 7
Training loss: 0.09049874978591613
Validation loss: 2.186255219510521

Epoch: 6| Step: 8
Training loss: 0.0682270165127677
Validation loss: 2.2038265272958704

Epoch: 6| Step: 9
Training loss: 0.07480117998789333
Validation loss: 2.207065156223727

Epoch: 6| Step: 10
Training loss: 0.08040293668776566
Validation loss: 2.2027746361387903

Epoch: 6| Step: 11
Training loss: 0.06541247283737979
Validation loss: 2.1761189060656827

Epoch: 6| Step: 12
Training loss: 0.0746240341804535
Validation loss: 2.1816771346093367

Epoch: 6| Step: 13
Training loss: 0.07993176506279806
Validation loss: 2.209023357588605

Epoch: 774| Step: 0
Training loss: 0.06991334042595597
Validation loss: 2.184733821078665

Epoch: 6| Step: 1
Training loss: 0.1597906044177027
Validation loss: 2.1786553364145305

Epoch: 6| Step: 2
Training loss: 0.05710817433620201
Validation loss: 2.2138207700594674

Epoch: 6| Step: 3
Training loss: 0.05687734039699822
Validation loss: 2.2044184208821185

Epoch: 6| Step: 4
Training loss: 0.056864739032142515
Validation loss: 2.204536257692543

Epoch: 6| Step: 5
Training loss: 0.08247722579611286
Validation loss: 2.1913331523580357

Epoch: 6| Step: 6
Training loss: 0.06404429880792895
Validation loss: 2.210201632462435

Epoch: 6| Step: 7
Training loss: 0.10113215974116005
Validation loss: 2.2263944713932373

Epoch: 6| Step: 8
Training loss: 0.07862580833375842
Validation loss: 2.2585877208454943

Epoch: 6| Step: 9
Training loss: 0.08573473504771081
Validation loss: 2.2559662474902504

Epoch: 6| Step: 10
Training loss: 0.09235056824532553
Validation loss: 2.222945315719246

Epoch: 6| Step: 11
Training loss: 0.09319155485342262
Validation loss: 2.2023103747262187

Epoch: 6| Step: 12
Training loss: 0.04176074944597719
Validation loss: 2.213186775630191

Epoch: 6| Step: 13
Training loss: 0.06313503159115169
Validation loss: 2.226012358014571

Epoch: 775| Step: 0
Training loss: 0.06955810333720033
Validation loss: 2.22782536119822

Epoch: 6| Step: 1
Training loss: 0.07405769919074441
Validation loss: 2.253213232180917

Epoch: 6| Step: 2
Training loss: 0.06095106435464283
Validation loss: 2.229627633086039

Epoch: 6| Step: 3
Training loss: 0.07399721398276134
Validation loss: 2.2309609583691863

Epoch: 6| Step: 4
Training loss: 0.06481265448493903
Validation loss: 2.218875263889116

Epoch: 6| Step: 5
Training loss: 0.05874826799665162
Validation loss: 2.251213247960057

Epoch: 6| Step: 6
Training loss: 0.07956678547952117
Validation loss: 2.236694947815181

Epoch: 6| Step: 7
Training loss: 0.07979773360422193
Validation loss: 2.2170790458340326

Epoch: 6| Step: 8
Training loss: 0.07797841685365885
Validation loss: 2.1894074545624376

Epoch: 6| Step: 9
Training loss: 0.04990734011875375
Validation loss: 2.1956763218756867

Epoch: 6| Step: 10
Training loss: 0.08991312375474785
Validation loss: 2.195251360060006

Epoch: 6| Step: 11
Training loss: 0.07612772114260097
Validation loss: 2.2088891508387505

Epoch: 6| Step: 12
Training loss: 0.06190298527382582
Validation loss: 2.213480451824407

Epoch: 6| Step: 13
Training loss: 0.08106573156008866
Validation loss: 2.2229487559001826

Epoch: 776| Step: 0
Training loss: 0.07226887901815557
Validation loss: 2.223550486537291

Epoch: 6| Step: 1
Training loss: 0.0953352240535978
Validation loss: 2.2164203048754842

Epoch: 6| Step: 2
Training loss: 0.048528004029133216
Validation loss: 2.2228434641152695

Epoch: 6| Step: 3
Training loss: 0.05670231509779997
Validation loss: 2.232745202004724

Epoch: 6| Step: 4
Training loss: 0.08850882659824104
Validation loss: 2.219535489859435

Epoch: 6| Step: 5
Training loss: 0.06516346218023322
Validation loss: 2.2312351444042027

Epoch: 6| Step: 6
Training loss: 0.060748625533720686
Validation loss: 2.221973325735237

Epoch: 6| Step: 7
Training loss: 0.07507193339377764
Validation loss: 2.2247091982887808

Epoch: 6| Step: 8
Training loss: 0.07983212950065291
Validation loss: 2.227490677630653

Epoch: 6| Step: 9
Training loss: 0.06886193959217059
Validation loss: 2.225786858029982

Epoch: 6| Step: 10
Training loss: 0.08021733349098194
Validation loss: 2.231920163485587

Epoch: 6| Step: 11
Training loss: 0.04829225461429199
Validation loss: 2.2101555045783603

Epoch: 6| Step: 12
Training loss: 0.07179231876718542
Validation loss: 2.2375520589554636

Epoch: 6| Step: 13
Training loss: 0.05946299391430727
Validation loss: 2.236037395684468

Epoch: 777| Step: 0
Training loss: 0.06421228044991983
Validation loss: 2.228478083170697

Epoch: 6| Step: 1
Training loss: 0.0611617606303983
Validation loss: 2.220034428430878

Epoch: 6| Step: 2
Training loss: 0.07334756264531037
Validation loss: 2.204055305786603

Epoch: 6| Step: 3
Training loss: 0.07303341675263123
Validation loss: 2.248324995601103

Epoch: 6| Step: 4
Training loss: 0.08802340332583138
Validation loss: 2.2550596070533926

Epoch: 6| Step: 5
Training loss: 0.07657869530192817
Validation loss: 2.281037552656767

Epoch: 6| Step: 6
Training loss: 0.08304061802379653
Validation loss: 2.2668808327465046

Epoch: 6| Step: 7
Training loss: 0.08257810218218846
Validation loss: 2.247782719340059

Epoch: 6| Step: 8
Training loss: 0.09762244593152553
Validation loss: 2.235791284780813

Epoch: 6| Step: 9
Training loss: 0.0789951945619027
Validation loss: 2.2448421080789585

Epoch: 6| Step: 10
Training loss: 0.09354470544175349
Validation loss: 2.226836267467942

Epoch: 6| Step: 11
Training loss: 0.11418078344695473
Validation loss: 2.24148303937824

Epoch: 6| Step: 12
Training loss: 0.08907684808734914
Validation loss: 2.20989926636196

Epoch: 6| Step: 13
Training loss: 0.07617283478156658
Validation loss: 2.224515809647461

Epoch: 778| Step: 0
Training loss: 0.07836706390481397
Validation loss: 2.2153695383748433

Epoch: 6| Step: 1
Training loss: 0.045839502664897225
Validation loss: 2.211108215714587

Epoch: 6| Step: 2
Training loss: 0.08950896706493652
Validation loss: 2.2018313502550204

Epoch: 6| Step: 3
Training loss: 0.060813853558514916
Validation loss: 2.2102615440339775

Epoch: 6| Step: 4
Training loss: 0.07935470529987554
Validation loss: 2.20572019435415

Epoch: 6| Step: 5
Training loss: 0.04993415348706434
Validation loss: 2.2286222063432333

Epoch: 6| Step: 6
Training loss: 0.07597211785542245
Validation loss: 2.2289017040748247

Epoch: 6| Step: 7
Training loss: 0.08797919790651448
Validation loss: 2.241878450348717

Epoch: 6| Step: 8
Training loss: 0.04307715331598133
Validation loss: 2.2451552583936745

Epoch: 6| Step: 9
Training loss: 0.06704399021714996
Validation loss: 2.2695780868516473

Epoch: 6| Step: 10
Training loss: 0.07072613167934405
Validation loss: 2.2530779357712505

Epoch: 6| Step: 11
Training loss: 0.10335348584646697
Validation loss: 2.277003439984143

Epoch: 6| Step: 12
Training loss: 0.0879050137079978
Validation loss: 2.2831321635174784

Epoch: 6| Step: 13
Training loss: 0.1154751767085099
Validation loss: 2.2173542668687203

Epoch: 779| Step: 0
Training loss: 0.07374849793755296
Validation loss: 2.24791501802132

Epoch: 6| Step: 1
Training loss: 0.07919846298007689
Validation loss: 2.243219152637096

Epoch: 6| Step: 2
Training loss: 0.0633128144874463
Validation loss: 2.22088591644526

Epoch: 6| Step: 3
Training loss: 0.07632399920750171
Validation loss: 2.238536900650135

Epoch: 6| Step: 4
Training loss: 0.07625719940287691
Validation loss: 2.2329830759464806

Epoch: 6| Step: 5
Training loss: 0.08587562164781969
Validation loss: 2.2078615128801102

Epoch: 6| Step: 6
Training loss: 0.08099291354821977
Validation loss: 2.214167439113821

Epoch: 6| Step: 7
Training loss: 0.07195964033013555
Validation loss: 2.2471782150388293

Epoch: 6| Step: 8
Training loss: 0.06667274058445903
Validation loss: 2.246444207698805

Epoch: 6| Step: 9
Training loss: 0.08253390000875994
Validation loss: 2.225392187290065

Epoch: 6| Step: 10
Training loss: 0.0766132478491702
Validation loss: 2.2726860060259453

Epoch: 6| Step: 11
Training loss: 0.07947522669001165
Validation loss: 2.2680093611121284

Epoch: 6| Step: 12
Training loss: 0.066143649154681
Validation loss: 2.261090074306461

Epoch: 6| Step: 13
Training loss: 0.048371831829450526
Validation loss: 2.24587688695659

Epoch: 780| Step: 0
Training loss: 0.04424804680764714
Validation loss: 2.238201821795993

Epoch: 6| Step: 1
Training loss: 0.09930925409151266
Validation loss: 2.264435786077036

Epoch: 6| Step: 2
Training loss: 0.07016974434604645
Validation loss: 2.2808480205693415

Epoch: 6| Step: 3
Training loss: 0.053923256582524955
Validation loss: 2.243866840288451

Epoch: 6| Step: 4
Training loss: 0.09356771071862503
Validation loss: 2.2510343086221236

Epoch: 6| Step: 5
Training loss: 0.07144326359338231
Validation loss: 2.2553544759603823

Epoch: 6| Step: 6
Training loss: 0.09704857108796412
Validation loss: 2.253330643674048

Epoch: 6| Step: 7
Training loss: 0.08270898210457633
Validation loss: 2.246436145111036

Epoch: 6| Step: 8
Training loss: 0.05225030489911322
Validation loss: 2.2039981479947794

Epoch: 6| Step: 9
Training loss: 0.055727044663775996
Validation loss: 2.239704392278918

Epoch: 6| Step: 10
Training loss: 0.056651936421037684
Validation loss: 2.231405715194334

Epoch: 6| Step: 11
Training loss: 0.05061593105477757
Validation loss: 2.2341755810211117

Epoch: 6| Step: 12
Training loss: 0.07725608233025592
Validation loss: 2.2703401760670574

Epoch: 6| Step: 13
Training loss: 0.054046432692919984
Validation loss: 2.239714123931633

Epoch: 781| Step: 0
Training loss: 0.07875624978151996
Validation loss: 2.238191144333945

Epoch: 6| Step: 1
Training loss: 0.09716436484856403
Validation loss: 2.238189344325537

Epoch: 6| Step: 2
Training loss: 0.08484692981198774
Validation loss: 2.2293882971888372

Epoch: 6| Step: 3
Training loss: 0.09840684443682228
Validation loss: 2.2227952676760263

Epoch: 6| Step: 4
Training loss: 0.13197687174777142
Validation loss: 2.245200422852303

Epoch: 6| Step: 5
Training loss: 0.06690394899107736
Validation loss: 2.2278066650989192

Epoch: 6| Step: 6
Training loss: 0.08816462827170533
Validation loss: 2.233394956595673

Epoch: 6| Step: 7
Training loss: 0.0677763394111029
Validation loss: 2.1789936524582183

Epoch: 6| Step: 8
Training loss: 0.08417146934700445
Validation loss: 2.1924571274666484

Epoch: 6| Step: 9
Training loss: 0.08177966183587834
Validation loss: 2.2217582219074608

Epoch: 6| Step: 10
Training loss: 0.09679457071377211
Validation loss: 2.205193564264734

Epoch: 6| Step: 11
Training loss: 0.1045086125807112
Validation loss: 2.196716469234026

Epoch: 6| Step: 12
Training loss: 0.07607385245983002
Validation loss: 2.213383493484561

Epoch: 6| Step: 13
Training loss: 0.0959672251899767
Validation loss: 2.2167012653600593

Epoch: 782| Step: 0
Training loss: 0.10146387061202225
Validation loss: 2.2067531452945794

Epoch: 6| Step: 1
Training loss: 0.07829991964606935
Validation loss: 2.2455753690191647

Epoch: 6| Step: 2
Training loss: 0.07855083817033139
Validation loss: 2.2233170833680416

Epoch: 6| Step: 3
Training loss: 0.10879965581631303
Validation loss: 2.2412137290984924

Epoch: 6| Step: 4
Training loss: 0.07152604858240813
Validation loss: 2.2133211471671492

Epoch: 6| Step: 5
Training loss: 0.08919413651299826
Validation loss: 2.2566573340961744

Epoch: 6| Step: 6
Training loss: 0.09584359156430995
Validation loss: 2.232172117519064

Epoch: 6| Step: 7
Training loss: 0.11114797740102886
Validation loss: 2.234966240869915

Epoch: 6| Step: 8
Training loss: 0.09361453998816946
Validation loss: 2.2515787330805073

Epoch: 6| Step: 9
Training loss: 0.07749817440359241
Validation loss: 2.233930176764362

Epoch: 6| Step: 10
Training loss: 0.05558388146949512
Validation loss: 2.217897064902567

Epoch: 6| Step: 11
Training loss: 0.07672288782008961
Validation loss: 2.2036734551193953

Epoch: 6| Step: 12
Training loss: 0.052728701215622925
Validation loss: 2.2140933624836916

Epoch: 6| Step: 13
Training loss: 0.04921221349091151
Validation loss: 2.1907276138600777

Epoch: 783| Step: 0
Training loss: 0.064041070435902
Validation loss: 2.190085062321134

Epoch: 6| Step: 1
Training loss: 0.06319491920202613
Validation loss: 2.1991194436670893

Epoch: 6| Step: 2
Training loss: 0.09630311491991231
Validation loss: 2.2270718083954035

Epoch: 6| Step: 3
Training loss: 0.09165000326067642
Validation loss: 2.1786766500178896

Epoch: 6| Step: 4
Training loss: 0.07148739255987793
Validation loss: 2.2160696923202057

Epoch: 6| Step: 5
Training loss: 0.07726762715012644
Validation loss: 2.169530100058886

Epoch: 6| Step: 6
Training loss: 0.054743731488921435
Validation loss: 2.2245128219218704

Epoch: 6| Step: 7
Training loss: 0.10184045042684185
Validation loss: 2.193389844737101

Epoch: 6| Step: 8
Training loss: 0.08148398521783634
Validation loss: 2.2397985438439205

Epoch: 6| Step: 9
Training loss: 0.08386577504625006
Validation loss: 2.2204782305687067

Epoch: 6| Step: 10
Training loss: 0.06371385164805753
Validation loss: 2.212808237677315

Epoch: 6| Step: 11
Training loss: 0.06978584782460312
Validation loss: 2.2298378066823403

Epoch: 6| Step: 12
Training loss: 0.06095548197859306
Validation loss: 2.219713026039161

Epoch: 6| Step: 13
Training loss: 0.04311479193480948
Validation loss: 2.196844252131074

Epoch: 784| Step: 0
Training loss: 0.06412052544705951
Validation loss: 2.222371054949855

Epoch: 6| Step: 1
Training loss: 0.04652472595941762
Validation loss: 2.2074464799944913

Epoch: 6| Step: 2
Training loss: 0.07820383505065392
Validation loss: 2.2617220660290958

Epoch: 6| Step: 3
Training loss: 0.05613277550445909
Validation loss: 2.2115845335871183

Epoch: 6| Step: 4
Training loss: 0.06576355048728064
Validation loss: 2.2367422418752323

Epoch: 6| Step: 5
Training loss: 0.09023047744293151
Validation loss: 2.227623619846989

Epoch: 6| Step: 6
Training loss: 0.07039383978282084
Validation loss: 2.226312099006932

Epoch: 6| Step: 7
Training loss: 0.10906050801849042
Validation loss: 2.2297198393472533

Epoch: 6| Step: 8
Training loss: 0.08496168289734528
Validation loss: 2.2178437171393663

Epoch: 6| Step: 9
Training loss: 0.050391977036989895
Validation loss: 2.237005221842248

Epoch: 6| Step: 10
Training loss: 0.07936261510346465
Validation loss: 2.2277834193237576

Epoch: 6| Step: 11
Training loss: 0.08010945637607478
Validation loss: 2.2487389022417505

Epoch: 6| Step: 12
Training loss: 0.070663137482577
Validation loss: 2.2517153355192914

Epoch: 6| Step: 13
Training loss: 0.11731217825032021
Validation loss: 2.257670291351213

Epoch: 785| Step: 0
Training loss: 0.056899011653563016
Validation loss: 2.2451199485493025

Epoch: 6| Step: 1
Training loss: 0.08695013926264834
Validation loss: 2.238300104284992

Epoch: 6| Step: 2
Training loss: 0.07317828887860503
Validation loss: 2.25647955785564

Epoch: 6| Step: 3
Training loss: 0.10018285986274221
Validation loss: 2.252324664626726

Epoch: 6| Step: 4
Training loss: 0.05437190023375394
Validation loss: 2.2237034096064363

Epoch: 6| Step: 5
Training loss: 0.0662963181651419
Validation loss: 2.250410762559584

Epoch: 6| Step: 6
Training loss: 0.06732309500960212
Validation loss: 2.243751821986515

Epoch: 6| Step: 7
Training loss: 0.13601118644733556
Validation loss: 2.214736428899529

Epoch: 6| Step: 8
Training loss: 0.046901042479046084
Validation loss: 2.2163405935015548

Epoch: 6| Step: 9
Training loss: 0.12614903730496857
Validation loss: 2.1953030742486264

Epoch: 6| Step: 10
Training loss: 0.12226518716215767
Validation loss: 2.2264865783861807

Epoch: 6| Step: 11
Training loss: 0.04943253987777899
Validation loss: 2.251536388262458

Epoch: 6| Step: 12
Training loss: 0.07505980270547695
Validation loss: 2.221129302182082

Epoch: 6| Step: 13
Training loss: 0.08369662648037224
Validation loss: 2.2126864085535964

Epoch: 786| Step: 0
Training loss: 0.09285612938433961
Validation loss: 2.203368958390338

Epoch: 6| Step: 1
Training loss: 0.1031389942210746
Validation loss: 2.2084325461255885

Epoch: 6| Step: 2
Training loss: 0.08232852171108906
Validation loss: 2.205208219280507

Epoch: 6| Step: 3
Training loss: 0.06852834798719268
Validation loss: 2.236411975191929

Epoch: 6| Step: 4
Training loss: 0.08864932025460827
Validation loss: 2.2319129259839507

Epoch: 6| Step: 5
Training loss: 0.0883449784380013
Validation loss: 2.214274238425836

Epoch: 6| Step: 6
Training loss: 0.09262007535456862
Validation loss: 2.219424418938059

Epoch: 6| Step: 7
Training loss: 0.08204586035181519
Validation loss: 2.2081511459687415

Epoch: 6| Step: 8
Training loss: 0.06828354307902786
Validation loss: 2.2206652490669425

Epoch: 6| Step: 9
Training loss: 0.0936174001330788
Validation loss: 2.2146381184982333

Epoch: 6| Step: 10
Training loss: 0.06164633684261833
Validation loss: 2.224446914037248

Epoch: 6| Step: 11
Training loss: 0.09498088164321168
Validation loss: 2.23547182040225

Epoch: 6| Step: 12
Training loss: 0.08426808519660656
Validation loss: 2.2051056530514472

Epoch: 6| Step: 13
Training loss: 0.05388387884459581
Validation loss: 2.234805482642513

Epoch: 787| Step: 0
Training loss: 0.0773374830702906
Validation loss: 2.241289544747205

Epoch: 6| Step: 1
Training loss: 0.08422497728075155
Validation loss: 2.226789616686438

Epoch: 6| Step: 2
Training loss: 0.06587083685679558
Validation loss: 2.2373068325511394

Epoch: 6| Step: 3
Training loss: 0.06718377072497124
Validation loss: 2.2694031576152613

Epoch: 6| Step: 4
Training loss: 0.09026477475035785
Validation loss: 2.2539082313867698

Epoch: 6| Step: 5
Training loss: 0.06937349672235288
Validation loss: 2.2346839496139235

Epoch: 6| Step: 6
Training loss: 0.06036489772995895
Validation loss: 2.2476205606624813

Epoch: 6| Step: 7
Training loss: 0.07900525930068844
Validation loss: 2.2294632322722547

Epoch: 6| Step: 8
Training loss: 0.10977597052125157
Validation loss: 2.238513865366223

Epoch: 6| Step: 9
Training loss: 0.08802721483142013
Validation loss: 2.2112316975225985

Epoch: 6| Step: 10
Training loss: 0.07747673248752426
Validation loss: 2.1973192664449916

Epoch: 6| Step: 11
Training loss: 0.06084954075816312
Validation loss: 2.2197835970937243

Epoch: 6| Step: 12
Training loss: 0.08329436544685581
Validation loss: 2.2038085425192646

Epoch: 6| Step: 13
Training loss: 0.14639328349575395
Validation loss: 2.229134121706046

Epoch: 788| Step: 0
Training loss: 0.08781525241027092
Validation loss: 2.2201417171542417

Epoch: 6| Step: 1
Training loss: 0.06246772320110074
Validation loss: 2.2640127214028483

Epoch: 6| Step: 2
Training loss: 0.04637055868444716
Validation loss: 2.23296733573001

Epoch: 6| Step: 3
Training loss: 0.09728341456969686
Validation loss: 2.249283095854743

Epoch: 6| Step: 4
Training loss: 0.07468668030943432
Validation loss: 2.2431874911735665

Epoch: 6| Step: 5
Training loss: 0.06501883358293174
Validation loss: 2.2583957535745802

Epoch: 6| Step: 6
Training loss: 0.1340019036663113
Validation loss: 2.2469718465767996

Epoch: 6| Step: 7
Training loss: 0.07776402885472922
Validation loss: 2.275598657238262

Epoch: 6| Step: 8
Training loss: 0.09649499919637954
Validation loss: 2.222568174790931

Epoch: 6| Step: 9
Training loss: 0.08213298596966434
Validation loss: 2.245248360995514

Epoch: 6| Step: 10
Training loss: 0.061085243654268456
Validation loss: 2.2135896804688513

Epoch: 6| Step: 11
Training loss: 0.0730524020220466
Validation loss: 2.2435310902761105

Epoch: 6| Step: 12
Training loss: 0.06618773748789282
Validation loss: 2.222070781186007

Epoch: 6| Step: 13
Training loss: 0.11436450899715123
Validation loss: 2.2311660690609725

Epoch: 789| Step: 0
Training loss: 0.08435305910583801
Validation loss: 2.2334933599281346

Epoch: 6| Step: 1
Training loss: 0.06129534006032339
Validation loss: 2.236682629853895

Epoch: 6| Step: 2
Training loss: 0.06980055961721002
Validation loss: 2.2422185821854215

Epoch: 6| Step: 3
Training loss: 0.08221340957697851
Validation loss: 2.248452477044424

Epoch: 6| Step: 4
Training loss: 0.07307178383712913
Validation loss: 2.212613377841854

Epoch: 6| Step: 5
Training loss: 0.08172478649899778
Validation loss: 2.245212654118343

Epoch: 6| Step: 6
Training loss: 0.07291616676647397
Validation loss: 2.2586151236676666

Epoch: 6| Step: 7
Training loss: 0.10239002204582433
Validation loss: 2.2710862705164794

Epoch: 6| Step: 8
Training loss: 0.0784068952511448
Validation loss: 2.2639660649629274

Epoch: 6| Step: 9
Training loss: 0.0713779013494152
Validation loss: 2.2590341795125237

Epoch: 6| Step: 10
Training loss: 0.05200773529358162
Validation loss: 2.2413731046755125

Epoch: 6| Step: 11
Training loss: 0.10341583246144508
Validation loss: 2.257301572232455

Epoch: 6| Step: 12
Training loss: 0.06239866818989218
Validation loss: 2.240196900241552

Epoch: 6| Step: 13
Training loss: 0.09001850154070105
Validation loss: 2.224233280976698

Epoch: 790| Step: 0
Training loss: 0.06400406341254058
Validation loss: 2.253101486646127

Epoch: 6| Step: 1
Training loss: 0.07730994641813597
Validation loss: 2.237985483004953

Epoch: 6| Step: 2
Training loss: 0.07205923351947427
Validation loss: 2.2619732613607453

Epoch: 6| Step: 3
Training loss: 0.08762388017580998
Validation loss: 2.2130433104402654

Epoch: 6| Step: 4
Training loss: 0.07774687096303545
Validation loss: 2.221725195331066

Epoch: 6| Step: 5
Training loss: 0.056765988982430474
Validation loss: 2.223540643788643

Epoch: 6| Step: 6
Training loss: 0.04273580132079505
Validation loss: 2.217052082150536

Epoch: 6| Step: 7
Training loss: 0.08968492650450283
Validation loss: 2.2014877911249697

Epoch: 6| Step: 8
Training loss: 0.04326579255584448
Validation loss: 2.189007262376591

Epoch: 6| Step: 9
Training loss: 0.08505890941451807
Validation loss: 2.1954322627251113

Epoch: 6| Step: 10
Training loss: 0.07704017986860216
Validation loss: 2.2111556958883547

Epoch: 6| Step: 11
Training loss: 0.14315040257795703
Validation loss: 2.202652123445059

Epoch: 6| Step: 12
Training loss: 0.10055334526086732
Validation loss: 2.225553624891384

Epoch: 6| Step: 13
Training loss: 0.09039920165306267
Validation loss: 2.2215598017852076

Epoch: 791| Step: 0
Training loss: 0.06387837221627699
Validation loss: 2.2430377320179464

Epoch: 6| Step: 1
Training loss: 0.06479503873054183
Validation loss: 2.231104389721379

Epoch: 6| Step: 2
Training loss: 0.11563377749788653
Validation loss: 2.2701470236494896

Epoch: 6| Step: 3
Training loss: 0.11457840049124776
Validation loss: 2.26572502574548

Epoch: 6| Step: 4
Training loss: 0.11440272393246326
Validation loss: 2.2790324341570476

Epoch: 6| Step: 5
Training loss: 0.09962294523514517
Validation loss: 2.2675130171852778

Epoch: 6| Step: 6
Training loss: 0.10486767053965344
Validation loss: 2.2722840504727615

Epoch: 6| Step: 7
Training loss: 0.048196836344200036
Validation loss: 2.2289542080739118

Epoch: 6| Step: 8
Training loss: 0.10516902491015066
Validation loss: 2.2438093038822506

Epoch: 6| Step: 9
Training loss: 0.08795788893129217
Validation loss: 2.249579731055601

Epoch: 6| Step: 10
Training loss: 0.08680599705928212
Validation loss: 2.2193100814659705

Epoch: 6| Step: 11
Training loss: 0.09675536420956443
Validation loss: 2.221629607961286

Epoch: 6| Step: 12
Training loss: 0.08163416782195589
Validation loss: 2.232267556640656

Epoch: 6| Step: 13
Training loss: 0.06792739550061959
Validation loss: 2.1813690677236552

Epoch: 792| Step: 0
Training loss: 0.10749089451279827
Validation loss: 2.1926066326052336

Epoch: 6| Step: 1
Training loss: 0.10095175174510651
Validation loss: 2.222214426989197

Epoch: 6| Step: 2
Training loss: 0.11092727002808082
Validation loss: 2.1940942393285554

Epoch: 6| Step: 3
Training loss: 0.08785948201599876
Validation loss: 2.231430832095201

Epoch: 6| Step: 4
Training loss: 0.10607583992424595
Validation loss: 2.203894728636986

Epoch: 6| Step: 5
Training loss: 0.07205358533399923
Validation loss: 2.2251228702784522

Epoch: 6| Step: 6
Training loss: 0.08343883413773363
Validation loss: 2.213808668755593

Epoch: 6| Step: 7
Training loss: 0.12341605917710044
Validation loss: 2.2294202138443664

Epoch: 6| Step: 8
Training loss: 0.0721444066960714
Validation loss: 2.215265121291579

Epoch: 6| Step: 9
Training loss: 0.07902856095506894
Validation loss: 2.2417632574108564

Epoch: 6| Step: 10
Training loss: 0.08242284878160051
Validation loss: 2.248815062687829

Epoch: 6| Step: 11
Training loss: 0.09537991617501336
Validation loss: 2.2420584937490564

Epoch: 6| Step: 12
Training loss: 0.11249213952842975
Validation loss: 2.2420637558153196

Epoch: 6| Step: 13
Training loss: 0.08679663301016984
Validation loss: 2.2342808969893557

Epoch: 793| Step: 0
Training loss: 0.0828575316612006
Validation loss: 2.237824826824433

Epoch: 6| Step: 1
Training loss: 0.09541349961544189
Validation loss: 2.22335577487789

Epoch: 6| Step: 2
Training loss: 0.08901514584675346
Validation loss: 2.2481450532274403

Epoch: 6| Step: 3
Training loss: 0.10224391603382331
Validation loss: 2.2189188348041187

Epoch: 6| Step: 4
Training loss: 0.08200545700199482
Validation loss: 2.2413022137053478

Epoch: 6| Step: 5
Training loss: 0.06914510793215375
Validation loss: 2.223585751513186

Epoch: 6| Step: 6
Training loss: 0.0796160654741876
Validation loss: 2.2355249607946064

Epoch: 6| Step: 7
Training loss: 0.07414710200470305
Validation loss: 2.23907715747594

Epoch: 6| Step: 8
Training loss: 0.0689102152410103
Validation loss: 2.25746928542708

Epoch: 6| Step: 9
Training loss: 0.0649535698362713
Validation loss: 2.250128732095496

Epoch: 6| Step: 10
Training loss: 0.05311146767150123
Validation loss: 2.243532826579412

Epoch: 6| Step: 11
Training loss: 0.06702541856142388
Validation loss: 2.2449338441720017

Epoch: 6| Step: 12
Training loss: 0.1314450438271394
Validation loss: 2.253411457300025

Epoch: 6| Step: 13
Training loss: 0.12312848548506243
Validation loss: 2.2451653900457944

Epoch: 794| Step: 0
Training loss: 0.08635662027151109
Validation loss: 2.2262641901200793

Epoch: 6| Step: 1
Training loss: 0.0629298212392133
Validation loss: 2.2347784403121476

Epoch: 6| Step: 2
Training loss: 0.07247339807292222
Validation loss: 2.2655906349322685

Epoch: 6| Step: 3
Training loss: 0.05576561356352253
Validation loss: 2.2385780942106153

Epoch: 6| Step: 4
Training loss: 0.06853912087119171
Validation loss: 2.232682074160609

Epoch: 6| Step: 5
Training loss: 0.056475746717878986
Validation loss: 2.229267926159344

Epoch: 6| Step: 6
Training loss: 0.0628838967935864
Validation loss: 2.228112728824527

Epoch: 6| Step: 7
Training loss: 0.08276423732598165
Validation loss: 2.2183849208255455

Epoch: 6| Step: 8
Training loss: 0.061216900126717586
Validation loss: 2.208295460393835

Epoch: 6| Step: 9
Training loss: 0.1173468539466198
Validation loss: 2.2310065457703483

Epoch: 6| Step: 10
Training loss: 0.07058319331346276
Validation loss: 2.205165020069372

Epoch: 6| Step: 11
Training loss: 0.07657964086365193
Validation loss: 2.19090001783962

Epoch: 6| Step: 12
Training loss: 0.03934993196164815
Validation loss: 2.20571443065368

Epoch: 6| Step: 13
Training loss: 0.07201982916530188
Validation loss: 2.2207555573211595

Epoch: 795| Step: 0
Training loss: 0.0779108689228473
Validation loss: 2.2310607594596132

Epoch: 6| Step: 1
Training loss: 0.07980179502293355
Validation loss: 2.2173655048220793

Epoch: 6| Step: 2
Training loss: 0.10193157077820464
Validation loss: 2.224551946691808

Epoch: 6| Step: 3
Training loss: 0.09317304979716333
Validation loss: 2.217391681401852

Epoch: 6| Step: 4
Training loss: 0.0483155261631986
Validation loss: 2.231113552766533

Epoch: 6| Step: 5
Training loss: 0.10861540893984065
Validation loss: 2.25588782635739

Epoch: 6| Step: 6
Training loss: 0.0498882998993362
Validation loss: 2.269993279982777

Epoch: 6| Step: 7
Training loss: 0.07350762270995062
Validation loss: 2.2588687490737986

Epoch: 6| Step: 8
Training loss: 0.07846607321860678
Validation loss: 2.2484447112647596

Epoch: 6| Step: 9
Training loss: 0.07827948257503071
Validation loss: 2.271463906836217

Epoch: 6| Step: 10
Training loss: 0.060426176421653585
Validation loss: 2.254567255229909

Epoch: 6| Step: 11
Training loss: 0.06477155918227101
Validation loss: 2.2654539146225674

Epoch: 6| Step: 12
Training loss: 0.08286432880100374
Validation loss: 2.264840045433494

Epoch: 6| Step: 13
Training loss: 0.03388291847455632
Validation loss: 2.2475571833562293

Epoch: 796| Step: 0
Training loss: 0.06198139838633864
Validation loss: 2.2710681851039984

Epoch: 6| Step: 1
Training loss: 0.055741477973822444
Validation loss: 2.261195407094751

Epoch: 6| Step: 2
Training loss: 0.06252409798252895
Validation loss: 2.265130505824991

Epoch: 6| Step: 3
Training loss: 0.07471912261250951
Validation loss: 2.237481458253354

Epoch: 6| Step: 4
Training loss: 0.06709695386899284
Validation loss: 2.2699322428765742

Epoch: 6| Step: 5
Training loss: 0.05893103361823826
Validation loss: 2.242403057550654

Epoch: 6| Step: 6
Training loss: 0.0412852163652756
Validation loss: 2.2543233594735073

Epoch: 6| Step: 7
Training loss: 0.0622383429624481
Validation loss: 2.2460867310887367

Epoch: 6| Step: 8
Training loss: 0.08381139050939837
Validation loss: 2.2539692963724938

Epoch: 6| Step: 9
Training loss: 0.07228831630871216
Validation loss: 2.2514086749295505

Epoch: 6| Step: 10
Training loss: 0.06582871505125162
Validation loss: 2.2269219278760914

Epoch: 6| Step: 11
Training loss: 0.044081648633527704
Validation loss: 2.1952827990826247

Epoch: 6| Step: 12
Training loss: 0.03222740598499512
Validation loss: 2.2168080614255943

Epoch: 6| Step: 13
Training loss: 0.05070120435685981
Validation loss: 2.2040180219526824

Epoch: 797| Step: 0
Training loss: 0.05439537225754556
Validation loss: 2.2085011450016183

Epoch: 6| Step: 1
Training loss: 0.07614395045450004
Validation loss: 2.187001385093705

Epoch: 6| Step: 2
Training loss: 0.03926866337524758
Validation loss: 2.2120804455335255

Epoch: 6| Step: 3
Training loss: 0.09569560722095787
Validation loss: 2.2120917960393434

Epoch: 6| Step: 4
Training loss: 0.06663478417084191
Validation loss: 2.2072339088930386

Epoch: 6| Step: 5
Training loss: 0.07518042070141663
Validation loss: 2.257427583722477

Epoch: 6| Step: 6
Training loss: 0.07398548612797495
Validation loss: 2.2072216466171275

Epoch: 6| Step: 7
Training loss: 0.07465277677666617
Validation loss: 2.2470540192289983

Epoch: 6| Step: 8
Training loss: 0.0774125034422822
Validation loss: 2.241013287377498

Epoch: 6| Step: 9
Training loss: 0.07890743995940082
Validation loss: 2.2510687683566175

Epoch: 6| Step: 10
Training loss: 0.04975328878663632
Validation loss: 2.2688579255567896

Epoch: 6| Step: 11
Training loss: 0.060568346169633816
Validation loss: 2.243247146328871

Epoch: 6| Step: 12
Training loss: 0.08542316311994892
Validation loss: 2.2616246296475695

Epoch: 6| Step: 13
Training loss: 0.04215302548879291
Validation loss: 2.2533683795485673

Epoch: 798| Step: 0
Training loss: 0.06263610801482294
Validation loss: 2.2447735542286322

Epoch: 6| Step: 1
Training loss: 0.07479594119759893
Validation loss: 2.2341801209659375

Epoch: 6| Step: 2
Training loss: 0.062198316870975455
Validation loss: 2.2620648807072077

Epoch: 6| Step: 3
Training loss: 0.09494756696277082
Validation loss: 2.2575336040917042

Epoch: 6| Step: 4
Training loss: 0.07423180540604057
Validation loss: 2.2277364040150456

Epoch: 6| Step: 5
Training loss: 0.056590798264679075
Validation loss: 2.221203666425966

Epoch: 6| Step: 6
Training loss: 0.0774918289837763
Validation loss: 2.2501534423326626

Epoch: 6| Step: 7
Training loss: 0.07288870069390314
Validation loss: 2.220507943723761

Epoch: 6| Step: 8
Training loss: 0.05765115617526229
Validation loss: 2.2436054495895363

Epoch: 6| Step: 9
Training loss: 0.06926027387192268
Validation loss: 2.2393156135344334

Epoch: 6| Step: 10
Training loss: 0.07858780335497022
Validation loss: 2.2204726327532818

Epoch: 6| Step: 11
Training loss: 0.057423853191374025
Validation loss: 2.232849813310111

Epoch: 6| Step: 12
Training loss: 0.09076999993467379
Validation loss: 2.2416301484920202

Epoch: 6| Step: 13
Training loss: 0.07158890466099631
Validation loss: 2.2431658453735173

Epoch: 799| Step: 0
Training loss: 0.04639199879360502
Validation loss: 2.262310511952292

Epoch: 6| Step: 1
Training loss: 0.06954458904366162
Validation loss: 2.2637946707548084

Epoch: 6| Step: 2
Training loss: 0.11719367885194801
Validation loss: 2.2809718231139553

Epoch: 6| Step: 3
Training loss: 0.08729722185238384
Validation loss: 2.253787921824922

Epoch: 6| Step: 4
Training loss: 0.08410256962365849
Validation loss: 2.2554734013710007

Epoch: 6| Step: 5
Training loss: 0.08342475520533311
Validation loss: 2.2506580461538093

Epoch: 6| Step: 6
Training loss: 0.05785890767310251
Validation loss: 2.2719887637679514

Epoch: 6| Step: 7
Training loss: 0.038140709935132404
Validation loss: 2.2637031661522085

Epoch: 6| Step: 8
Training loss: 0.058367863995825345
Validation loss: 2.2739599059232716

Epoch: 6| Step: 9
Training loss: 0.062395238994247204
Validation loss: 2.2830899839678542

Epoch: 6| Step: 10
Training loss: 0.07129212921548696
Validation loss: 2.255874581603791

Epoch: 6| Step: 11
Training loss: 0.10082198657804198
Validation loss: 2.279678042493249

Epoch: 6| Step: 12
Training loss: 0.06279983349499185
Validation loss: 2.257143594513004

Epoch: 6| Step: 13
Training loss: 0.0695009819328457
Validation loss: 2.227536893081276

Epoch: 800| Step: 0
Training loss: 0.04480596286950663
Validation loss: 2.249224577017431

Epoch: 6| Step: 1
Training loss: 0.05093044591983546
Validation loss: 2.2395801869451613

Epoch: 6| Step: 2
Training loss: 0.06689661259441346
Validation loss: 2.2539199814749873

Epoch: 6| Step: 3
Training loss: 0.049935116336357215
Validation loss: 2.2454397728090236

Epoch: 6| Step: 4
Training loss: 0.06215267606316371
Validation loss: 2.261425469340523

Epoch: 6| Step: 5
Training loss: 0.07485584322600766
Validation loss: 2.2548570501204614

Epoch: 6| Step: 6
Training loss: 0.050273470200570235
Validation loss: 2.2573744132441282

Epoch: 6| Step: 7
Training loss: 0.057806840423048976
Validation loss: 2.2490610079797766

Epoch: 6| Step: 8
Training loss: 0.038283917093302026
Validation loss: 2.2285005308080104

Epoch: 6| Step: 9
Training loss: 0.05761476083268183
Validation loss: 2.2567669800644525

Epoch: 6| Step: 10
Training loss: 0.10179889201217517
Validation loss: 2.221367676777308

Epoch: 6| Step: 11
Training loss: 0.07896826250052624
Validation loss: 2.2346356325447365

Epoch: 6| Step: 12
Training loss: 0.07553035543142451
Validation loss: 2.2289177194266045

Epoch: 6| Step: 13
Training loss: 0.06787220864786753
Validation loss: 2.2373939139324674

Testing loss: 2.5097983204204106
