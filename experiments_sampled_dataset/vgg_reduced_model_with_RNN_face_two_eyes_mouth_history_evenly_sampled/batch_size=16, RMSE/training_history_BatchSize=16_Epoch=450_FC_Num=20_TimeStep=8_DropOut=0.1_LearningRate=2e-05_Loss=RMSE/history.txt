Epoch: 1| Step: 0
Training loss: 5.339414745362833
Validation loss: 5.840225515968675

Epoch: 6| Step: 1
Training loss: 5.659709736420862
Validation loss: 5.814901056468683

Epoch: 6| Step: 2
Training loss: 5.970097414688402
Validation loss: 5.789978467690948

Epoch: 6| Step: 3
Training loss: 5.237376704619761
Validation loss: 5.764431972479154

Epoch: 6| Step: 4
Training loss: 4.787338469247879
Validation loss: 5.73621236974352

Epoch: 6| Step: 5
Training loss: 6.222824831952138
Validation loss: 5.7042630298450625

Epoch: 6| Step: 6
Training loss: 6.122761531429421
Validation loss: 5.667605412206922

Epoch: 6| Step: 7
Training loss: 6.6941398385984545
Validation loss: 5.627327878262119

Epoch: 6| Step: 8
Training loss: 4.450237636436054
Validation loss: 5.581720813872714

Epoch: 6| Step: 9
Training loss: 5.783345600448629
Validation loss: 5.532290199172345

Epoch: 6| Step: 10
Training loss: 5.268987561138629
Validation loss: 5.477340013206297

Epoch: 6| Step: 11
Training loss: 5.817512565832005
Validation loss: 5.418009798614375

Epoch: 6| Step: 12
Training loss: 5.900486955105744
Validation loss: 5.355237852783706

Epoch: 6| Step: 13
Training loss: 5.434805366800177
Validation loss: 5.289207774104624

Epoch: 2| Step: 0
Training loss: 4.529055570464063
Validation loss: 5.223904176857306

Epoch: 6| Step: 1
Training loss: 4.534675934136498
Validation loss: 5.1546994957863586

Epoch: 6| Step: 2
Training loss: 6.126263546526864
Validation loss: 5.09025912609799

Epoch: 6| Step: 3
Training loss: 4.945390408400929
Validation loss: 5.026199672773538

Epoch: 6| Step: 4
Training loss: 4.920061824999398
Validation loss: 4.9627960126711255

Epoch: 6| Step: 5
Training loss: 5.199475540709611
Validation loss: 4.903176000901551

Epoch: 6| Step: 6
Training loss: 4.853570642293808
Validation loss: 4.8450707420265005

Epoch: 6| Step: 7
Training loss: 4.169001471900085
Validation loss: 4.791433148715153

Epoch: 6| Step: 8
Training loss: 5.1453842811431265
Validation loss: 4.741716568183584

Epoch: 6| Step: 9
Training loss: 5.527332707586143
Validation loss: 4.690525780891811

Epoch: 6| Step: 10
Training loss: 3.6534714533691783
Validation loss: 4.636522437682333

Epoch: 6| Step: 11
Training loss: 4.493693489069549
Validation loss: 4.587105036842422

Epoch: 6| Step: 12
Training loss: 4.102225346364873
Validation loss: 4.536825999435671

Epoch: 6| Step: 13
Training loss: 6.741722966144938
Validation loss: 4.486747390569293

Epoch: 3| Step: 0
Training loss: 4.625654844371531
Validation loss: 4.437101972246521

Epoch: 6| Step: 1
Training loss: 4.120316592154063
Validation loss: 4.39291013725918

Epoch: 6| Step: 2
Training loss: 4.086218275412062
Validation loss: 4.343266143019095

Epoch: 6| Step: 3
Training loss: 4.460226827421536
Validation loss: 4.288480269703824

Epoch: 6| Step: 4
Training loss: 4.084619021258669
Validation loss: 4.260666187516331

Epoch: 6| Step: 5
Training loss: 3.9723452405990916
Validation loss: 4.240798464439729

Epoch: 6| Step: 6
Training loss: 5.157034704435198
Validation loss: 4.223651997730527

Epoch: 6| Step: 7
Training loss: 4.891976361757998
Validation loss: 4.202960073511645

Epoch: 6| Step: 8
Training loss: 3.7798618259102583
Validation loss: 4.1834841864062895

Epoch: 6| Step: 9
Training loss: 5.208470070633465
Validation loss: 4.167342584402012

Epoch: 6| Step: 10
Training loss: 4.340159736893107
Validation loss: 4.148534916814104

Epoch: 6| Step: 11
Training loss: 4.9073751337894835
Validation loss: 4.133870003457655

Epoch: 6| Step: 12
Training loss: 3.4876830131611687
Validation loss: 4.116119887071515

Epoch: 6| Step: 13
Training loss: 2.802928745029587
Validation loss: 4.100648377136524

Epoch: 4| Step: 0
Training loss: 3.716140985875576
Validation loss: 4.085876475681789

Epoch: 6| Step: 1
Training loss: 4.845236863840986
Validation loss: 4.068546683924358

Epoch: 6| Step: 2
Training loss: 4.173020794858479
Validation loss: 4.048710726493697

Epoch: 6| Step: 3
Training loss: 4.501020527726531
Validation loss: 4.025197911910999

Epoch: 6| Step: 4
Training loss: 4.872991686185481
Validation loss: 4.0080149373027565

Epoch: 6| Step: 5
Training loss: 4.141304852795682
Validation loss: 3.992364479150628

Epoch: 6| Step: 6
Training loss: 3.5193070182541493
Validation loss: 3.9793728890584266

Epoch: 6| Step: 7
Training loss: 3.3649951852024316
Validation loss: 3.9499293769492962

Epoch: 6| Step: 8
Training loss: 2.5686453656421344
Validation loss: 3.932890115971541

Epoch: 6| Step: 9
Training loss: 4.175534133093736
Validation loss: 3.921660428480707

Epoch: 6| Step: 10
Training loss: 4.633293963111816
Validation loss: 3.907284265904418

Epoch: 6| Step: 11
Training loss: 3.6883706826790985
Validation loss: 3.8913018470221763

Epoch: 6| Step: 12
Training loss: 4.3813478467085245
Validation loss: 3.875753368509378

Epoch: 6| Step: 13
Training loss: 4.949891969677178
Validation loss: 3.855475649371557

Epoch: 5| Step: 0
Training loss: 3.6349580725097517
Validation loss: 3.8400530393545376

Epoch: 6| Step: 1
Training loss: 3.414230237807675
Validation loss: 3.825210761887485

Epoch: 6| Step: 2
Training loss: 4.462109734061747
Validation loss: 3.8149198897572347

Epoch: 6| Step: 3
Training loss: 4.482576122414131
Validation loss: 3.797339934161967

Epoch: 6| Step: 4
Training loss: 3.8808003974507006
Validation loss: 3.7777229537239077

Epoch: 6| Step: 5
Training loss: 4.310368328951203
Validation loss: 3.758743176001824

Epoch: 6| Step: 6
Training loss: 3.9023549916942684
Validation loss: 3.7414419136337025

Epoch: 6| Step: 7
Training loss: 3.8366284651280935
Validation loss: 3.7246624754242346

Epoch: 6| Step: 8
Training loss: 3.8687912206965085
Validation loss: 3.708497911492618

Epoch: 6| Step: 9
Training loss: 3.6724351820864007
Validation loss: 3.693087669140305

Epoch: 6| Step: 10
Training loss: 4.639446892492867
Validation loss: 3.6727577211422555

Epoch: 6| Step: 11
Training loss: 3.2029409960487754
Validation loss: 3.6687808909866733

Epoch: 6| Step: 12
Training loss: 3.530837448462245
Validation loss: 3.655012548348886

Epoch: 6| Step: 13
Training loss: 3.6454807365305113
Validation loss: 3.6335403396019252

Epoch: 6| Step: 0
Training loss: 3.2545089255143305
Validation loss: 3.612662097195102

Epoch: 6| Step: 1
Training loss: 3.7025382949322014
Validation loss: 3.5853082309063597

Epoch: 6| Step: 2
Training loss: 4.008654530134491
Validation loss: 3.5656340334654724

Epoch: 6| Step: 3
Training loss: 3.466093128394999
Validation loss: 3.5452605995047604

Epoch: 6| Step: 4
Training loss: 4.268087605457663
Validation loss: 3.520599138034158

Epoch: 6| Step: 5
Training loss: 4.039191179420842
Validation loss: 3.477266802531183

Epoch: 6| Step: 6
Training loss: 3.881408191841819
Validation loss: 3.493410884156379

Epoch: 6| Step: 7
Training loss: 3.053434695542285
Validation loss: 3.4520995622438417

Epoch: 6| Step: 8
Training loss: 3.405027537633647
Validation loss: 3.4099541692240405

Epoch: 6| Step: 9
Training loss: 3.211673698582562
Validation loss: 3.409419562717767

Epoch: 6| Step: 10
Training loss: 4.056490635016018
Validation loss: 3.476205644662145

Epoch: 6| Step: 11
Training loss: 4.280755007453462
Validation loss: 3.3848543796609776

Epoch: 6| Step: 12
Training loss: 3.79362065756204
Validation loss: 3.3969680326758263

Epoch: 6| Step: 13
Training loss: 2.3423771206963075
Validation loss: 3.396725477330829

Epoch: 7| Step: 0
Training loss: 3.6368170867310425
Validation loss: 3.3977172706947236

Epoch: 6| Step: 1
Training loss: 4.117246797485699
Validation loss: 3.3784410260618634

Epoch: 6| Step: 2
Training loss: 3.7886688342536
Validation loss: 3.348775840909176

Epoch: 6| Step: 3
Training loss: 3.0672219133122613
Validation loss: 3.337968125695838

Epoch: 6| Step: 4
Training loss: 4.164432129906743
Validation loss: 3.365164584116183

Epoch: 6| Step: 5
Training loss: 3.6675650767538017
Validation loss: 3.3047251054729414

Epoch: 6| Step: 6
Training loss: 3.4022935760687654
Validation loss: 3.2932961588156373

Epoch: 6| Step: 7
Training loss: 3.1727260706850333
Validation loss: 3.2912266248783935

Epoch: 6| Step: 8
Training loss: 3.539755241855178
Validation loss: 3.288708309286416

Epoch: 6| Step: 9
Training loss: 3.2785272836903987
Validation loss: 3.2819239942307368

Epoch: 6| Step: 10
Training loss: 3.4410972499790637
Validation loss: 3.278046678340443

Epoch: 6| Step: 11
Training loss: 3.634298697381594
Validation loss: 3.2649344434266925

Epoch: 6| Step: 12
Training loss: 3.1758635300303686
Validation loss: 3.255048223023942

Epoch: 6| Step: 13
Training loss: 3.4756346418071735
Validation loss: 3.253089597361491

Epoch: 8| Step: 0
Training loss: 3.6367195367043994
Validation loss: 3.2531700670894366

Epoch: 6| Step: 1
Training loss: 3.7651407397385643
Validation loss: 3.232413815486229

Epoch: 6| Step: 2
Training loss: 3.344439569119786
Validation loss: 3.223496424144213

Epoch: 6| Step: 3
Training loss: 3.7392881625824974
Validation loss: 3.2203909807404645

Epoch: 6| Step: 4
Training loss: 3.0569064381226236
Validation loss: 3.217582711599002

Epoch: 6| Step: 5
Training loss: 3.8418725863949175
Validation loss: 3.208918861769614

Epoch: 6| Step: 6
Training loss: 3.7000107687716097
Validation loss: 3.1992288035122445

Epoch: 6| Step: 7
Training loss: 3.42330860781508
Validation loss: 3.1889621309546485

Epoch: 6| Step: 8
Training loss: 3.3681933677418225
Validation loss: 3.1821532811054714

Epoch: 6| Step: 9
Training loss: 2.477069598246215
Validation loss: 3.173798958845516

Epoch: 6| Step: 10
Training loss: 3.1250454708605906
Validation loss: 3.16893739572766

Epoch: 6| Step: 11
Training loss: 2.989769817920428
Validation loss: 3.162164908409331

Epoch: 6| Step: 12
Training loss: 4.352289601367299
Validation loss: 3.1612218998935115

Epoch: 6| Step: 13
Training loss: 3.0843761502063773
Validation loss: 3.147850165656864

Epoch: 9| Step: 0
Training loss: 3.7763514038734676
Validation loss: 3.144071864219448

Epoch: 6| Step: 1
Training loss: 3.514247912802846
Validation loss: 3.1415795377772846

Epoch: 6| Step: 2
Training loss: 3.349856780677318
Validation loss: 3.139398611183431

Epoch: 6| Step: 3
Training loss: 2.4301978062939784
Validation loss: 3.139577236257124

Epoch: 6| Step: 4
Training loss: 3.388554938769487
Validation loss: 3.1316908139986706

Epoch: 6| Step: 5
Training loss: 3.820247594988016
Validation loss: 3.1298836348614154

Epoch: 6| Step: 6
Training loss: 2.6817576250195665
Validation loss: 3.133506808642043

Epoch: 6| Step: 7
Training loss: 4.144857985176953
Validation loss: 3.1387560083017947

Epoch: 6| Step: 8
Training loss: 2.4282606050190436
Validation loss: 3.130616169858384

Epoch: 6| Step: 9
Training loss: 3.3789289705251284
Validation loss: 3.1227209743341406

Epoch: 6| Step: 10
Training loss: 3.8074623970684636
Validation loss: 3.107266643007686

Epoch: 6| Step: 11
Training loss: 3.193061912751162
Validation loss: 3.1107237140552777

Epoch: 6| Step: 12
Training loss: 3.0673406841563366
Validation loss: 3.110619601622394

Epoch: 6| Step: 13
Training loss: 4.496372668300662
Validation loss: 3.1106467096944685

Epoch: 10| Step: 0
Training loss: 4.404496297106581
Validation loss: 3.107813663639489

Epoch: 6| Step: 1
Training loss: 3.1817199060199766
Validation loss: 3.1004349903857817

Epoch: 6| Step: 2
Training loss: 2.6934923301008324
Validation loss: 3.0951553422687446

Epoch: 6| Step: 3
Training loss: 3.006793753763856
Validation loss: 3.096389583325517

Epoch: 6| Step: 4
Training loss: 3.1188084109537475
Validation loss: 3.087118511554391

Epoch: 6| Step: 5
Training loss: 3.5929358845613772
Validation loss: 3.0833101684666833

Epoch: 6| Step: 6
Training loss: 3.554493926090981
Validation loss: 3.0804807182262337

Epoch: 6| Step: 7
Training loss: 3.5706939159642213
Validation loss: 3.078294401961035

Epoch: 6| Step: 8
Training loss: 3.1402865554872106
Validation loss: 3.0723665179124837

Epoch: 6| Step: 9
Training loss: 2.5824098987500714
Validation loss: 3.0697327331836255

Epoch: 6| Step: 10
Training loss: 3.6037981289584837
Validation loss: 3.0674034560630923

Epoch: 6| Step: 11
Training loss: 3.2510509259011515
Validation loss: 3.065781342831484

Epoch: 6| Step: 12
Training loss: 3.837413123324741
Validation loss: 3.063082991311175

Epoch: 6| Step: 13
Training loss: 2.99092015451207
Validation loss: 3.0607191059695773

Epoch: 11| Step: 0
Training loss: 3.6911198580619935
Validation loss: 3.0562113924731658

Epoch: 6| Step: 1
Training loss: 3.58969431369972
Validation loss: 3.054835127724138

Epoch: 6| Step: 2
Training loss: 3.048609156935019
Validation loss: 3.054590848982973

Epoch: 6| Step: 3
Training loss: 3.815493799651713
Validation loss: 3.051789677252998

Epoch: 6| Step: 4
Training loss: 3.6222642243439274
Validation loss: 3.0567343244488856

Epoch: 6| Step: 5
Training loss: 3.4948559152048015
Validation loss: 3.0424525489847736

Epoch: 6| Step: 6
Training loss: 2.866361826575565
Validation loss: 3.038662969056383

Epoch: 6| Step: 7
Training loss: 3.5687176170149235
Validation loss: 3.0383453699802256

Epoch: 6| Step: 8
Training loss: 2.8970005966991774
Validation loss: 3.0380538226905465

Epoch: 6| Step: 9
Training loss: 3.2229503890387576
Validation loss: 3.042508068910729

Epoch: 6| Step: 10
Training loss: 3.872265496932687
Validation loss: 3.0353706649332826

Epoch: 6| Step: 11
Training loss: 2.7054050950292914
Validation loss: 3.030894524303776

Epoch: 6| Step: 12
Training loss: 2.9652533568647974
Validation loss: 3.021801589624049

Epoch: 6| Step: 13
Training loss: 2.7866122384513012
Validation loss: 3.021771178386939

Epoch: 12| Step: 0
Training loss: 3.2676939912399603
Validation loss: 3.01638955127434

Epoch: 6| Step: 1
Training loss: 3.6779026635188887
Validation loss: 3.0227829381296822

Epoch: 6| Step: 2
Training loss: 3.863543649060826
Validation loss: 3.006167986122073

Epoch: 6| Step: 3
Training loss: 4.211045753913479
Validation loss: 2.9981792421131224

Epoch: 6| Step: 4
Training loss: 2.814896812648189
Validation loss: 2.990130738223933

Epoch: 6| Step: 5
Training loss: 2.8155042920927547
Validation loss: 2.9909367135754272

Epoch: 6| Step: 6
Training loss: 2.991905896354222
Validation loss: 2.9898248627585433

Epoch: 6| Step: 7
Training loss: 2.8841089987718695
Validation loss: 2.9913363344250534

Epoch: 6| Step: 8
Training loss: 3.612124762136714
Validation loss: 2.9944170271928843

Epoch: 6| Step: 9
Training loss: 3.1434522969403638
Validation loss: 2.9904532504461283

Epoch: 6| Step: 10
Training loss: 3.1483099748328205
Validation loss: 2.9863552272901197

Epoch: 6| Step: 11
Training loss: 2.831209808131699
Validation loss: 2.979303188338233

Epoch: 6| Step: 12
Training loss: 3.240830323530235
Validation loss: 3.00025694782448

Epoch: 6| Step: 13
Training loss: 3.2527468883923767
Validation loss: 2.9945145211334756

Epoch: 13| Step: 0
Training loss: 3.489781449041294
Validation loss: 2.9722533508220454

Epoch: 6| Step: 1
Training loss: 3.0543918320184424
Validation loss: 2.965874144811373

Epoch: 6| Step: 2
Training loss: 3.142239132100812
Validation loss: 2.96528684369378

Epoch: 6| Step: 3
Training loss: 3.578874001548185
Validation loss: 2.9643151621366908

Epoch: 6| Step: 4
Training loss: 2.757940100292564
Validation loss: 2.966590475002943

Epoch: 6| Step: 5
Training loss: 3.527134885972638
Validation loss: 2.974298959834046

Epoch: 6| Step: 6
Training loss: 2.7751796354970146
Validation loss: 3.0032620068449623

Epoch: 6| Step: 7
Training loss: 4.155284798199805
Validation loss: 3.0376014013636046

Epoch: 6| Step: 8
Training loss: 2.7675252302306803
Validation loss: 3.020793204771219

Epoch: 6| Step: 9
Training loss: 3.4607936579518754
Validation loss: 3.0184102072286474

Epoch: 6| Step: 10
Training loss: 3.657680394697024
Validation loss: 2.965227594582014

Epoch: 6| Step: 11
Training loss: 3.133815842535154
Validation loss: 2.9713735062233666

Epoch: 6| Step: 12
Training loss: 3.1129340118168694
Validation loss: 2.9642889151724368

Epoch: 6| Step: 13
Training loss: 2.9039082270326366
Validation loss: 2.957246293551336

Epoch: 14| Step: 0
Training loss: 3.1685229097813967
Validation loss: 2.951740296829579

Epoch: 6| Step: 1
Training loss: 2.236069896731506
Validation loss: 2.9546984784155663

Epoch: 6| Step: 2
Training loss: 3.63942688968018
Validation loss: 2.9803950491311415

Epoch: 6| Step: 3
Training loss: 3.448648580599465
Validation loss: 2.9525612920688227

Epoch: 6| Step: 4
Training loss: 3.8000427344077585
Validation loss: 2.937688754686504

Epoch: 6| Step: 5
Training loss: 2.377810170892805
Validation loss: 2.929735221665543

Epoch: 6| Step: 6
Training loss: 3.040577488809338
Validation loss: 2.929875842750266

Epoch: 6| Step: 7
Training loss: 3.430884914743975
Validation loss: 2.9231790814421554

Epoch: 6| Step: 8
Training loss: 3.2787178078109798
Validation loss: 2.918096946402752

Epoch: 6| Step: 9
Training loss: 3.3976666858869824
Validation loss: 2.9138797609349236

Epoch: 6| Step: 10
Training loss: 3.7089580195466323
Validation loss: 2.9143887811438174

Epoch: 6| Step: 11
Training loss: 3.0258371061866947
Validation loss: 2.9184686769235704

Epoch: 6| Step: 12
Training loss: 3.4233634881533517
Validation loss: 2.9380238139515833

Epoch: 6| Step: 13
Training loss: 2.777224853374309
Validation loss: 2.9475996930548773

Epoch: 15| Step: 0
Training loss: 3.2125094758721504
Validation loss: 2.9747834962810122

Epoch: 6| Step: 1
Training loss: 3.1712593270338703
Validation loss: 2.9685144569551096

Epoch: 6| Step: 2
Training loss: 3.49569764690458
Validation loss: 2.9353445763901744

Epoch: 6| Step: 3
Training loss: 3.1887125439090784
Validation loss: 2.9196958138219182

Epoch: 6| Step: 4
Training loss: 2.7262517976120906
Validation loss: 2.909304443313085

Epoch: 6| Step: 5
Training loss: 3.5288707178204786
Validation loss: 2.9111876666344494

Epoch: 6| Step: 6
Training loss: 2.815238636532868
Validation loss: 2.9109963419544176

Epoch: 6| Step: 7
Training loss: 3.2981690673891353
Validation loss: 2.9080580689493094

Epoch: 6| Step: 8
Training loss: 3.534047866643924
Validation loss: 2.9029710708601053

Epoch: 6| Step: 9
Training loss: 3.3582733477085642
Validation loss: 2.898306266932229

Epoch: 6| Step: 10
Training loss: 2.6901845609180346
Validation loss: 2.892238555273374

Epoch: 6| Step: 11
Training loss: 3.314112720531643
Validation loss: 2.894879465031064

Epoch: 6| Step: 12
Training loss: 3.5564767882534736
Validation loss: 2.9001281299085893

Epoch: 6| Step: 13
Training loss: 3.1318778072992433
Validation loss: 2.909007247008046

Epoch: 16| Step: 0
Training loss: 2.952163297494026
Validation loss: 2.8941622185473532

Epoch: 6| Step: 1
Training loss: 2.9370123275794255
Validation loss: 2.887947388649235

Epoch: 6| Step: 2
Training loss: 3.2164222670557745
Validation loss: 2.8933973370479036

Epoch: 6| Step: 3
Training loss: 2.6714495046799382
Validation loss: 2.8952017513158834

Epoch: 6| Step: 4
Training loss: 3.4832300605857576
Validation loss: 2.9021203530308775

Epoch: 6| Step: 5
Training loss: 2.7399327063824304
Validation loss: 2.9002295916631597

Epoch: 6| Step: 6
Training loss: 3.191144766770281
Validation loss: 2.898709498160284

Epoch: 6| Step: 7
Training loss: 3.4752946577770962
Validation loss: 2.8965763694807785

Epoch: 6| Step: 8
Training loss: 3.6223559767036217
Validation loss: 2.8966069693448424

Epoch: 6| Step: 9
Training loss: 3.546354684182126
Validation loss: 2.8917518607664654

Epoch: 6| Step: 10
Training loss: 3.656272170822871
Validation loss: 2.8877697146800387

Epoch: 6| Step: 11
Training loss: 3.5519467026432094
Validation loss: 2.884957556254607

Epoch: 6| Step: 12
Training loss: 3.1064150729921605
Validation loss: 2.888555134312812

Epoch: 6| Step: 13
Training loss: 1.8520813548961095
Validation loss: 2.9023299033540035

Epoch: 17| Step: 0
Training loss: 2.944455454663818
Validation loss: 2.9406849707379394

Epoch: 6| Step: 1
Training loss: 2.787898828003467
Validation loss: 2.955757904599677

Epoch: 6| Step: 2
Training loss: 3.809017905067269
Validation loss: 2.956486591049421

Epoch: 6| Step: 3
Training loss: 3.214923250459901
Validation loss: 2.880929997383071

Epoch: 6| Step: 4
Training loss: 3.268227885981862
Validation loss: 2.8751670357295653

Epoch: 6| Step: 5
Training loss: 3.1555134130926334
Validation loss: 2.878833558286917

Epoch: 6| Step: 6
Training loss: 2.8385414800148068
Validation loss: 2.8931566499219934

Epoch: 6| Step: 7
Training loss: 3.0125167719583845
Validation loss: 2.9140938118223385

Epoch: 6| Step: 8
Training loss: 3.8596811520617935
Validation loss: 2.8910696373361375

Epoch: 6| Step: 9
Training loss: 3.4419875936689115
Validation loss: 2.883662566276189

Epoch: 6| Step: 10
Training loss: 2.897186255991198
Validation loss: 2.8903550083725302

Epoch: 6| Step: 11
Training loss: 2.9866021119816026
Validation loss: 2.917354968960328

Epoch: 6| Step: 12
Training loss: 3.2626644750768827
Validation loss: 2.9061575830898025

Epoch: 6| Step: 13
Training loss: 3.3494022405434554
Validation loss: 2.9004145457504737

Epoch: 18| Step: 0
Training loss: 3.26860268372103
Validation loss: 2.8851469743203664

Epoch: 6| Step: 1
Training loss: 4.182992359465374
Validation loss: 2.873891538289881

Epoch: 6| Step: 2
Training loss: 3.0675224070830427
Validation loss: 2.8677779124577

Epoch: 6| Step: 3
Training loss: 2.9570431828730497
Validation loss: 2.8668863078459825

Epoch: 6| Step: 4
Training loss: 2.9974653344778623
Validation loss: 2.8915410916855517

Epoch: 6| Step: 5
Training loss: 2.7193717684032865
Validation loss: 2.9050362502856864

Epoch: 6| Step: 6
Training loss: 2.846231907588934
Validation loss: 2.914753972022737

Epoch: 6| Step: 7
Training loss: 2.745088091967162
Validation loss: 2.9183817094335587

Epoch: 6| Step: 8
Training loss: 2.8085742254732518
Validation loss: 2.925057881226697

Epoch: 6| Step: 9
Training loss: 3.6844332598997194
Validation loss: 2.949479851386707

Epoch: 6| Step: 10
Training loss: 3.8023467647618134
Validation loss: 2.9345681110271653

Epoch: 6| Step: 11
Training loss: 3.078459126109276
Validation loss: 2.9075104847621818

Epoch: 6| Step: 12
Training loss: 3.2580460938061075
Validation loss: 2.904821744657257

Epoch: 6| Step: 13
Training loss: 2.9322760374331387
Validation loss: 2.904142236659071

Epoch: 19| Step: 0
Training loss: 2.7540356761197877
Validation loss: 2.9082467899080098

Epoch: 6| Step: 1
Training loss: 3.221350350939198
Validation loss: 2.9091663192924733

Epoch: 6| Step: 2
Training loss: 3.3556408377273828
Validation loss: 2.905194391954069

Epoch: 6| Step: 3
Training loss: 3.196220586027488
Validation loss: 2.907046210420788

Epoch: 6| Step: 4
Training loss: 3.362746706849731
Validation loss: 2.921953175790729

Epoch: 6| Step: 5
Training loss: 3.5500780338790947
Validation loss: 2.927561963459122

Epoch: 6| Step: 6
Training loss: 3.617107744758901
Validation loss: 2.925700732640912

Epoch: 6| Step: 7
Training loss: 3.7916218402155057
Validation loss: 2.8977282410649035

Epoch: 6| Step: 8
Training loss: 3.0223006444773013
Validation loss: 2.926004294909095

Epoch: 6| Step: 9
Training loss: 2.7319040523564766
Validation loss: 3.005045955821774

Epoch: 6| Step: 10
Training loss: 3.1918901615891957
Validation loss: 3.1195873449903484

Epoch: 6| Step: 11
Training loss: 3.41737829721404
Validation loss: 3.1688513778233247

Epoch: 6| Step: 12
Training loss: 3.392319497554192
Validation loss: 3.1040513212041754

Epoch: 6| Step: 13
Training loss: 3.0187015948156386
Validation loss: 2.996432327914304

Epoch: 20| Step: 0
Training loss: 1.944434032715064
Validation loss: 2.934170106521046

Epoch: 6| Step: 1
Training loss: 4.000125883028948
Validation loss: 3.018040355348008

Epoch: 6| Step: 2
Training loss: 2.486611565123444
Validation loss: 2.9846759067397053

Epoch: 6| Step: 3
Training loss: 3.194851942377897
Validation loss: 2.9775255999812034

Epoch: 6| Step: 4
Training loss: 3.0220066992573735
Validation loss: 2.9669706062628176

Epoch: 6| Step: 5
Training loss: 3.1077573008978967
Validation loss: 2.9655030763510664

Epoch: 6| Step: 6
Training loss: 3.4470202307310784
Validation loss: 2.9459686858311813

Epoch: 6| Step: 7
Training loss: 3.3123341644809177
Validation loss: 2.9122513084420127

Epoch: 6| Step: 8
Training loss: 2.6307213512710628
Validation loss: 2.9077895258452027

Epoch: 6| Step: 9
Training loss: 4.062321585625523
Validation loss: 2.926048240011292

Epoch: 6| Step: 10
Training loss: 3.999836679939135
Validation loss: 2.91631402170594

Epoch: 6| Step: 11
Training loss: 3.066259140081892
Validation loss: 2.8936174587238157

Epoch: 6| Step: 12
Training loss: 2.8726292662589072
Validation loss: 2.8954388029609106

Epoch: 6| Step: 13
Training loss: 3.5576949256363912
Validation loss: 2.9024727601843128

Epoch: 21| Step: 0
Training loss: 3.6255333606730233
Validation loss: 2.883710322386403

Epoch: 6| Step: 1
Training loss: 3.4291624740506976
Validation loss: 2.879078446254406

Epoch: 6| Step: 2
Training loss: 3.499378694156605
Validation loss: 2.879258336698732

Epoch: 6| Step: 3
Training loss: 3.155644424810857
Validation loss: 2.8946855852166133

Epoch: 6| Step: 4
Training loss: 3.1801727449533526
Validation loss: 2.8647194280578705

Epoch: 6| Step: 5
Training loss: 2.2106996010619024
Validation loss: 2.8636682830187814

Epoch: 6| Step: 6
Training loss: 2.9239173320037777
Validation loss: 2.860409058389553

Epoch: 6| Step: 7
Training loss: 2.2661688842395997
Validation loss: 2.855537717286627

Epoch: 6| Step: 8
Training loss: 3.5546551713416585
Validation loss: 2.8557497270133663

Epoch: 6| Step: 9
Training loss: 3.3646515326580646
Validation loss: 2.8517968621326997

Epoch: 6| Step: 10
Training loss: 3.403764850585459
Validation loss: 2.8529139452907204

Epoch: 6| Step: 11
Training loss: 2.9472507403119828
Validation loss: 2.8509693409318735

Epoch: 6| Step: 12
Training loss: 3.4727673335808196
Validation loss: 2.8511792545574814

Epoch: 6| Step: 13
Training loss: 3.100863668663649
Validation loss: 2.850993576530529

Epoch: 22| Step: 0
Training loss: 3.058794075944905
Validation loss: 2.8534267694956106

Epoch: 6| Step: 1
Training loss: 3.30551360786671
Validation loss: 2.8543861495789233

Epoch: 6| Step: 2
Training loss: 3.641487510574882
Validation loss: 2.862321902854007

Epoch: 6| Step: 3
Training loss: 3.6714624051352858
Validation loss: 2.8388683307617932

Epoch: 6| Step: 4
Training loss: 2.502314068787637
Validation loss: 2.825129879452285

Epoch: 6| Step: 5
Training loss: 3.453985460879192
Validation loss: 2.8156161574893543

Epoch: 6| Step: 6
Training loss: 3.3613511062004924
Validation loss: 2.808938573311912

Epoch: 6| Step: 7
Training loss: 3.139493823953487
Validation loss: 2.804797163518478

Epoch: 6| Step: 8
Training loss: 3.326608231616725
Validation loss: 2.8100021126127968

Epoch: 6| Step: 9
Training loss: 3.333565719769151
Validation loss: 2.808888649689417

Epoch: 6| Step: 10
Training loss: 3.3893748145197486
Validation loss: 2.8066394645001225

Epoch: 6| Step: 11
Training loss: 2.803390840748691
Validation loss: 2.803749459815744

Epoch: 6| Step: 12
Training loss: 1.8617596121148408
Validation loss: 2.7962161252977653

Epoch: 6| Step: 13
Training loss: 2.6371353837500573
Validation loss: 2.800372515017237

Epoch: 23| Step: 0
Training loss: 3.3243544446636375
Validation loss: 2.7961661120509125

Epoch: 6| Step: 1
Training loss: 3.0733255060500335
Validation loss: 2.793078207264417

Epoch: 6| Step: 2
Training loss: 2.042852278064343
Validation loss: 2.790412487644587

Epoch: 6| Step: 3
Training loss: 3.20946013905069
Validation loss: 2.788982337467666

Epoch: 6| Step: 4
Training loss: 2.5070661818750444
Validation loss: 2.7876178919041146

Epoch: 6| Step: 5
Training loss: 3.133955673206163
Validation loss: 2.7846601604407946

Epoch: 6| Step: 6
Training loss: 2.6979132889145925
Validation loss: 2.7870186056244886

Epoch: 6| Step: 7
Training loss: 3.4843734946482874
Validation loss: 2.784119079620529

Epoch: 6| Step: 8
Training loss: 3.5654996323339914
Validation loss: 2.7864846584919283

Epoch: 6| Step: 9
Training loss: 3.061401325814333
Validation loss: 2.7810511751302838

Epoch: 6| Step: 10
Training loss: 2.7344461486279252
Validation loss: 2.782682187647561

Epoch: 6| Step: 11
Training loss: 3.564374999143817
Validation loss: 2.78867745613323

Epoch: 6| Step: 12
Training loss: 3.650953319893719
Validation loss: 2.7903539279851075

Epoch: 6| Step: 13
Training loss: 3.2304256487073295
Validation loss: 2.781622422620461

Epoch: 24| Step: 0
Training loss: 2.6794840120955077
Validation loss: 2.7811529445178693

Epoch: 6| Step: 1
Training loss: 3.080699792605278
Validation loss: 2.777786463515399

Epoch: 6| Step: 2
Training loss: 2.6056532215430166
Validation loss: 2.773876288004416

Epoch: 6| Step: 3
Training loss: 2.6705306390955608
Validation loss: 2.771304579384522

Epoch: 6| Step: 4
Training loss: 2.9214730215738243
Validation loss: 2.7711949485269844

Epoch: 6| Step: 5
Training loss: 4.081279134135221
Validation loss: 2.768257665521704

Epoch: 6| Step: 6
Training loss: 3.2183991768764093
Validation loss: 2.767492478726322

Epoch: 6| Step: 7
Training loss: 2.5657395145633544
Validation loss: 2.7654620234330074

Epoch: 6| Step: 8
Training loss: 2.910721159516492
Validation loss: 2.76467982620813

Epoch: 6| Step: 9
Training loss: 3.129504200237897
Validation loss: 2.7644808018553335

Epoch: 6| Step: 10
Training loss: 3.2921176231293807
Validation loss: 2.7656248776404713

Epoch: 6| Step: 11
Training loss: 3.3346519405258963
Validation loss: 2.7668443219754217

Epoch: 6| Step: 12
Training loss: 3.08137921106884
Validation loss: 2.771108969049653

Epoch: 6| Step: 13
Training loss: 3.7965092737955515
Validation loss: 2.7759392992339533

Epoch: 25| Step: 0
Training loss: 2.6828634498303843
Validation loss: 2.7684672342255428

Epoch: 6| Step: 1
Training loss: 2.816360028822786
Validation loss: 2.774382196233216

Epoch: 6| Step: 2
Training loss: 2.9484393371996793
Validation loss: 2.7658941370749752

Epoch: 6| Step: 3
Training loss: 2.783416418636222
Validation loss: 2.7612048868218464

Epoch: 6| Step: 4
Training loss: 3.5796019325369635
Validation loss: 2.754632499128572

Epoch: 6| Step: 5
Training loss: 3.3251269094010603
Validation loss: 2.757750739999982

Epoch: 6| Step: 6
Training loss: 3.0326572573047557
Validation loss: 2.757065261449107

Epoch: 6| Step: 7
Training loss: 2.6520360394556355
Validation loss: 2.75867282411654

Epoch: 6| Step: 8
Training loss: 3.3267788022495095
Validation loss: 2.756630566016349

Epoch: 6| Step: 9
Training loss: 3.127044009258559
Validation loss: 2.7563709394619886

Epoch: 6| Step: 10
Training loss: 3.6067277191927127
Validation loss: 2.7557788596790753

Epoch: 6| Step: 11
Training loss: 2.585283732678986
Validation loss: 2.7510327518907935

Epoch: 6| Step: 12
Training loss: 3.594965455548483
Validation loss: 2.7502418348339863

Epoch: 6| Step: 13
Training loss: 2.880884533788448
Validation loss: 2.7472711524418973

Epoch: 26| Step: 0
Training loss: 3.131003449683298
Validation loss: 2.7444112618052143

Epoch: 6| Step: 1
Training loss: 3.7949375813895894
Validation loss: 2.7434641740936367

Epoch: 6| Step: 2
Training loss: 2.531849448725568
Validation loss: 2.749541743216754

Epoch: 6| Step: 3
Training loss: 3.988261881303973
Validation loss: 2.7555423561005106

Epoch: 6| Step: 4
Training loss: 3.523467543784743
Validation loss: 2.764057185699152

Epoch: 6| Step: 5
Training loss: 2.563944339761021
Validation loss: 2.7572302815072023

Epoch: 6| Step: 6
Training loss: 2.800271470669985
Validation loss: 2.7486862892991555

Epoch: 6| Step: 7
Training loss: 3.1157639391193306
Validation loss: 2.7455578310846747

Epoch: 6| Step: 8
Training loss: 2.7283347417338035
Validation loss: 2.7493405245874114

Epoch: 6| Step: 9
Training loss: 2.789358598822006
Validation loss: 2.7482633747312506

Epoch: 6| Step: 10
Training loss: 2.867338337685532
Validation loss: 2.752733481094199

Epoch: 6| Step: 11
Training loss: 2.5244273792262395
Validation loss: 2.768214024369694

Epoch: 6| Step: 12
Training loss: 3.137360199629108
Validation loss: 2.778688044213531

Epoch: 6| Step: 13
Training loss: 3.419073761110037
Validation loss: 2.761356330501822

Epoch: 27| Step: 0
Training loss: 3.3801429558041423
Validation loss: 2.7512690728588955

Epoch: 6| Step: 1
Training loss: 3.30142028762279
Validation loss: 2.742133270298664

Epoch: 6| Step: 2
Training loss: 3.034453910956587
Validation loss: 2.7357587303378135

Epoch: 6| Step: 3
Training loss: 3.7893302901504327
Validation loss: 2.7336585549816497

Epoch: 6| Step: 4
Training loss: 3.3927754557248186
Validation loss: 2.7319590575264336

Epoch: 6| Step: 5
Training loss: 2.7163318973839714
Validation loss: 2.7344599097409694

Epoch: 6| Step: 6
Training loss: 2.7385459260458824
Validation loss: 2.7393196384864638

Epoch: 6| Step: 7
Training loss: 3.0505943094533468
Validation loss: 2.7381054395507145

Epoch: 6| Step: 8
Training loss: 2.3151936694345348
Validation loss: 2.7364205271052935

Epoch: 6| Step: 9
Training loss: 3.6186419008017072
Validation loss: 2.7356546228109213

Epoch: 6| Step: 10
Training loss: 2.9756197500232644
Validation loss: 2.7356375774557065

Epoch: 6| Step: 11
Training loss: 2.893550238089306
Validation loss: 2.733486209929084

Epoch: 6| Step: 12
Training loss: 2.6785298952788157
Validation loss: 2.7330306594520075

Epoch: 6| Step: 13
Training loss: 2.7498258188745646
Validation loss: 2.729104450352371

Epoch: 28| Step: 0
Training loss: 3.1477613456642186
Validation loss: 2.7322023822480035

Epoch: 6| Step: 1
Training loss: 3.1598221610523494
Validation loss: 2.729875738454709

Epoch: 6| Step: 2
Training loss: 2.9839224746901416
Validation loss: 2.733975724046884

Epoch: 6| Step: 3
Training loss: 3.095224356708149
Validation loss: 2.7335286845602975

Epoch: 6| Step: 4
Training loss: 2.925129103460499
Validation loss: 2.7316554886736015

Epoch: 6| Step: 5
Training loss: 3.4846521104861705
Validation loss: 2.731018167926532

Epoch: 6| Step: 6
Training loss: 3.353904066211728
Validation loss: 2.729860927785648

Epoch: 6| Step: 7
Training loss: 2.1627921772522765
Validation loss: 2.7261242535323085

Epoch: 6| Step: 8
Training loss: 3.4012306398445666
Validation loss: 2.7293153196454014

Epoch: 6| Step: 9
Training loss: 2.960596231003104
Validation loss: 2.7226678146502987

Epoch: 6| Step: 10
Training loss: 2.496904745867676
Validation loss: 2.733065462630135

Epoch: 6| Step: 11
Training loss: 3.001585223674395
Validation loss: 2.7359197131920374

Epoch: 6| Step: 12
Training loss: 2.992082001342675
Validation loss: 2.7386186756463915

Epoch: 6| Step: 13
Training loss: 3.811168500680096
Validation loss: 2.72470030403344

Epoch: 29| Step: 0
Training loss: 2.3507745886594513
Validation loss: 2.7154847101468267

Epoch: 6| Step: 1
Training loss: 2.647202915745245
Validation loss: 2.7107464479898002

Epoch: 6| Step: 2
Training loss: 3.5809634748149812
Validation loss: 2.7074686640586294

Epoch: 6| Step: 3
Training loss: 2.8473715724903506
Validation loss: 2.707713984120245

Epoch: 6| Step: 4
Training loss: 3.2363755677912134
Validation loss: 2.707197587921866

Epoch: 6| Step: 5
Training loss: 3.256134406031422
Validation loss: 2.7076253478346786

Epoch: 6| Step: 6
Training loss: 2.2660351612161
Validation loss: 2.706174200584557

Epoch: 6| Step: 7
Training loss: 3.7015234465690594
Validation loss: 2.706559324496585

Epoch: 6| Step: 8
Training loss: 2.5870808727244308
Validation loss: 2.7061319540630655

Epoch: 6| Step: 9
Training loss: 3.03675578227034
Validation loss: 2.7052584182790818

Epoch: 6| Step: 10
Training loss: 3.5188201626275335
Validation loss: 2.70549614265186

Epoch: 6| Step: 11
Training loss: 3.201710756293856
Validation loss: 2.7068710503482

Epoch: 6| Step: 12
Training loss: 3.270401231607254
Validation loss: 2.7185146299210454

Epoch: 6| Step: 13
Training loss: 2.4638529628565307
Validation loss: 2.7297797611501604

Epoch: 30| Step: 0
Training loss: 3.316897801791134
Validation loss: 2.7280463617032615

Epoch: 6| Step: 1
Training loss: 3.0421378062558206
Validation loss: 2.7274076204696427

Epoch: 6| Step: 2
Training loss: 3.1257472861384294
Validation loss: 2.7090420996907945

Epoch: 6| Step: 3
Training loss: 2.7096322295014192
Validation loss: 2.7010383269532947

Epoch: 6| Step: 4
Training loss: 3.0768234676963817
Validation loss: 2.698211192667313

Epoch: 6| Step: 5
Training loss: 3.188071106255323
Validation loss: 2.6987686405222933

Epoch: 6| Step: 6
Training loss: 3.3684725333972896
Validation loss: 2.701418347669991

Epoch: 6| Step: 7
Training loss: 3.243541756415408
Validation loss: 2.699058635646277

Epoch: 6| Step: 8
Training loss: 3.119231125409065
Validation loss: 2.698703121171857

Epoch: 6| Step: 9
Training loss: 2.260809048349857
Validation loss: 2.6981425204859026

Epoch: 6| Step: 10
Training loss: 3.0189431075414896
Validation loss: 2.695977890349264

Epoch: 6| Step: 11
Training loss: 3.208009298896155
Validation loss: 2.696060477786991

Epoch: 6| Step: 12
Training loss: 2.589073745620238
Validation loss: 2.6974224718521476

Epoch: 6| Step: 13
Training loss: 3.2812446230889725
Validation loss: 2.7005240157464394

Epoch: 31| Step: 0
Training loss: 3.1048922789434696
Validation loss: 2.6989275163471005

Epoch: 6| Step: 1
Training loss: 3.1461818746193924
Validation loss: 2.6973011291656923

Epoch: 6| Step: 2
Training loss: 2.5926299836727127
Validation loss: 2.6992626290797053

Epoch: 6| Step: 3
Training loss: 3.2300719602145187
Validation loss: 2.697341428750111

Epoch: 6| Step: 4
Training loss: 2.900139075265838
Validation loss: 2.693182314066771

Epoch: 6| Step: 5
Training loss: 2.9624370713129515
Validation loss: 2.69147222130192

Epoch: 6| Step: 6
Training loss: 2.8477593967087476
Validation loss: 2.6929331655249285

Epoch: 6| Step: 7
Training loss: 3.6472691497017617
Validation loss: 2.694395420353134

Epoch: 6| Step: 8
Training loss: 3.09634768156758
Validation loss: 2.6935648327244905

Epoch: 6| Step: 9
Training loss: 3.9159183328390967
Validation loss: 2.6901176412670775

Epoch: 6| Step: 10
Training loss: 2.4655101135331168
Validation loss: 2.6889308564998604

Epoch: 6| Step: 11
Training loss: 2.6839215607302744
Validation loss: 2.6862857858253535

Epoch: 6| Step: 12
Training loss: 3.024518906349928
Validation loss: 2.6891882597674557

Epoch: 6| Step: 13
Training loss: 2.1660618549225656
Validation loss: 2.685031426775687

Epoch: 32| Step: 0
Training loss: 2.7386739016693933
Validation loss: 2.6839180131721965

Epoch: 6| Step: 1
Training loss: 2.78237035238518
Validation loss: 2.6840777250540855

Epoch: 6| Step: 2
Training loss: 3.172203610690944
Validation loss: 2.683564473676239

Epoch: 6| Step: 3
Training loss: 2.893062903808534
Validation loss: 2.685021152262925

Epoch: 6| Step: 4
Training loss: 3.135223754490683
Validation loss: 2.6834564677791692

Epoch: 6| Step: 5
Training loss: 3.2388498798665437
Validation loss: 2.682041553592596

Epoch: 6| Step: 6
Training loss: 3.3055890524170533
Validation loss: 2.6829574247771713

Epoch: 6| Step: 7
Training loss: 3.338228033433043
Validation loss: 2.685054719726764

Epoch: 6| Step: 8
Training loss: 3.278100382200596
Validation loss: 2.6877327932890704

Epoch: 6| Step: 9
Training loss: 2.292328155300203
Validation loss: 2.697734723212006

Epoch: 6| Step: 10
Training loss: 3.0514951449459833
Validation loss: 2.7039326458179413

Epoch: 6| Step: 11
Training loss: 2.2361215021222387
Validation loss: 2.71246333344384

Epoch: 6| Step: 12
Training loss: 3.6331416811544517
Validation loss: 2.7331916228980186

Epoch: 6| Step: 13
Training loss: 3.0696820492692654
Validation loss: 2.6924915514855607

Epoch: 33| Step: 0
Training loss: 3.0489016321816167
Validation loss: 2.680142927948596

Epoch: 6| Step: 1
Training loss: 3.247682185066038
Validation loss: 2.677325332625031

Epoch: 6| Step: 2
Training loss: 3.015258450541109
Validation loss: 2.674494997507625

Epoch: 6| Step: 3
Training loss: 2.813415039406728
Validation loss: 2.676046196814819

Epoch: 6| Step: 4
Training loss: 2.717390224622429
Validation loss: 2.676636857138396

Epoch: 6| Step: 5
Training loss: 3.389192480722616
Validation loss: 2.679045356138929

Epoch: 6| Step: 6
Training loss: 2.8476622781571996
Validation loss: 2.6789975564421096

Epoch: 6| Step: 7
Training loss: 2.2018645448244274
Validation loss: 2.677350036990405

Epoch: 6| Step: 8
Training loss: 3.3327235299855484
Validation loss: 2.6792957463574023

Epoch: 6| Step: 9
Training loss: 3.503602762166892
Validation loss: 2.6761482520621724

Epoch: 6| Step: 10
Training loss: 3.38333147045767
Validation loss: 2.6780433151353327

Epoch: 6| Step: 11
Training loss: 3.310332254750393
Validation loss: 2.6734422712884665

Epoch: 6| Step: 12
Training loss: 2.491944973902956
Validation loss: 2.67028001837899

Epoch: 6| Step: 13
Training loss: 2.4023677669658214
Validation loss: 2.671454782717027

Epoch: 34| Step: 0
Training loss: 3.1754447505362924
Validation loss: 2.6717087504984787

Epoch: 6| Step: 1
Training loss: 2.58672917628052
Validation loss: 2.680870787705248

Epoch: 6| Step: 2
Training loss: 3.0505124021264596
Validation loss: 2.689129960175274

Epoch: 6| Step: 3
Training loss: 2.4475738501780073
Validation loss: 2.7045733803561136

Epoch: 6| Step: 4
Training loss: 3.110264329869755
Validation loss: 2.724550561192573

Epoch: 6| Step: 5
Training loss: 3.201481392811851
Validation loss: 2.730653820889419

Epoch: 6| Step: 6
Training loss: 3.014913366284539
Validation loss: 2.7019806852903603

Epoch: 6| Step: 7
Training loss: 2.9381820211616465
Validation loss: 2.7036984587161945

Epoch: 6| Step: 8
Training loss: 2.1460771391301776
Validation loss: 2.700166184845825

Epoch: 6| Step: 9
Training loss: 3.497229024166582
Validation loss: 2.6940531466785345

Epoch: 6| Step: 10
Training loss: 3.5365637574847133
Validation loss: 2.6889641911523166

Epoch: 6| Step: 11
Training loss: 3.10958938242967
Validation loss: 2.6691714016422736

Epoch: 6| Step: 12
Training loss: 3.1342684818017146
Validation loss: 2.6655083308103027

Epoch: 6| Step: 13
Training loss: 3.123018781143182
Validation loss: 2.6663466765960457

Epoch: 35| Step: 0
Training loss: 2.4553888650801863
Validation loss: 2.6705980937139335

Epoch: 6| Step: 1
Training loss: 3.2316052652880125
Validation loss: 2.6675364597331988

Epoch: 6| Step: 2
Training loss: 3.7211552382792425
Validation loss: 2.6682861295014058

Epoch: 6| Step: 3
Training loss: 3.2996357572270147
Validation loss: 2.669140416922867

Epoch: 6| Step: 4
Training loss: 3.0675856733599667
Validation loss: 2.6688823557524337

Epoch: 6| Step: 5
Training loss: 2.9689443424259157
Validation loss: 2.669458924796462

Epoch: 6| Step: 6
Training loss: 2.9764638168516924
Validation loss: 2.6673130510108183

Epoch: 6| Step: 7
Training loss: 2.7092005197206586
Validation loss: 2.6679761757943465

Epoch: 6| Step: 8
Training loss: 3.161966717655259
Validation loss: 2.668053664954482

Epoch: 6| Step: 9
Training loss: 2.9230197561133426
Validation loss: 2.6648348523895344

Epoch: 6| Step: 10
Training loss: 2.6349375494083778
Validation loss: 2.66321364063112

Epoch: 6| Step: 11
Training loss: 2.8415639670450132
Validation loss: 2.6623645645382283

Epoch: 6| Step: 12
Training loss: 2.6559561174168604
Validation loss: 2.6609984072472117

Epoch: 6| Step: 13
Training loss: 3.696769572259778
Validation loss: 2.662367345445993

Epoch: 36| Step: 0
Training loss: 3.1365360192532847
Validation loss: 2.659073951767134

Epoch: 6| Step: 1
Training loss: 3.979200286456912
Validation loss: 2.6577452512496818

Epoch: 6| Step: 2
Training loss: 3.677864805756044
Validation loss: 2.6558347880583693

Epoch: 6| Step: 3
Training loss: 2.424361398515657
Validation loss: 2.6590965070323827

Epoch: 6| Step: 4
Training loss: 2.612533485161499
Validation loss: 2.65548294834426

Epoch: 6| Step: 5
Training loss: 2.5971163310486327
Validation loss: 2.661348634946732

Epoch: 6| Step: 6
Training loss: 3.0224099791241392
Validation loss: 2.6686847088675174

Epoch: 6| Step: 7
Training loss: 2.8942271290343604
Validation loss: 2.6717748109256

Epoch: 6| Step: 8
Training loss: 2.581944635874706
Validation loss: 2.684633017854345

Epoch: 6| Step: 9
Training loss: 3.0306235383782116
Validation loss: 2.6947174171503216

Epoch: 6| Step: 10
Training loss: 2.910430362772044
Validation loss: 2.7039189455132795

Epoch: 6| Step: 11
Training loss: 2.6432717506223113
Validation loss: 2.691263024985562

Epoch: 6| Step: 12
Training loss: 3.251132767678258
Validation loss: 2.6769029427173914

Epoch: 6| Step: 13
Training loss: 2.782017634036288
Validation loss: 2.6636626303425865

Epoch: 37| Step: 0
Training loss: 3.039147226285214
Validation loss: 2.659257625793272

Epoch: 6| Step: 1
Training loss: 2.7406984291113634
Validation loss: 2.6548098651607535

Epoch: 6| Step: 2
Training loss: 3.6075281479676504
Validation loss: 2.6528467699353286

Epoch: 6| Step: 3
Training loss: 3.29444730786061
Validation loss: 2.660389392095066

Epoch: 6| Step: 4
Training loss: 2.81550446145394
Validation loss: 2.6617299851868297

Epoch: 6| Step: 5
Training loss: 3.1281167318899845
Validation loss: 2.6678639593450253

Epoch: 6| Step: 6
Training loss: 2.6380635314880103
Validation loss: 2.667183984164146

Epoch: 6| Step: 7
Training loss: 3.1090629075962926
Validation loss: 2.663957906942125

Epoch: 6| Step: 8
Training loss: 2.5012103965327244
Validation loss: 2.661400936061578

Epoch: 6| Step: 9
Training loss: 3.165164105829822
Validation loss: 2.6588410906109434

Epoch: 6| Step: 10
Training loss: 3.2725657028235315
Validation loss: 2.6571811084028587

Epoch: 6| Step: 11
Training loss: 2.578097256597885
Validation loss: 2.6552010131570767

Epoch: 6| Step: 12
Training loss: 3.2240663344987253
Validation loss: 2.6548859917845546

Epoch: 6| Step: 13
Training loss: 2.927835677762918
Validation loss: 2.6496683945286366

Epoch: 38| Step: 0
Training loss: 2.940458228543816
Validation loss: 2.6530369917926024

Epoch: 6| Step: 1
Training loss: 3.0788940398470936
Validation loss: 2.6569048697390945

Epoch: 6| Step: 2
Training loss: 2.2918100370006718
Validation loss: 2.673282010313544

Epoch: 6| Step: 3
Training loss: 2.6605860605183973
Validation loss: 2.6829691185019526

Epoch: 6| Step: 4
Training loss: 3.668756207488493
Validation loss: 2.727205453078994

Epoch: 6| Step: 5
Training loss: 2.867727452297659
Validation loss: 2.7459629272560395

Epoch: 6| Step: 6
Training loss: 2.462021265113156
Validation loss: 2.7548749155812944

Epoch: 6| Step: 7
Training loss: 2.660312911250592
Validation loss: 2.7519458857496653

Epoch: 6| Step: 8
Training loss: 2.827641735622492
Validation loss: 2.764854798975536

Epoch: 6| Step: 9
Training loss: 2.859371664743615
Validation loss: 2.747068051289652

Epoch: 6| Step: 10
Training loss: 3.36416667488129
Validation loss: 2.699879236114613

Epoch: 6| Step: 11
Training loss: 3.569716255601811
Validation loss: 2.665765755953642

Epoch: 6| Step: 12
Training loss: 3.3923228710825746
Validation loss: 2.6478163735901137

Epoch: 6| Step: 13
Training loss: 3.051627497217657
Validation loss: 2.652654360906655

Epoch: 39| Step: 0
Training loss: 3.2779477896125466
Validation loss: 2.6648624037121076

Epoch: 6| Step: 1
Training loss: 3.2569917152587538
Validation loss: 2.6840914979797996

Epoch: 6| Step: 2
Training loss: 2.6626547396830005
Validation loss: 2.6877296084482354

Epoch: 6| Step: 3
Training loss: 2.9161667168240744
Validation loss: 2.6975187222823256

Epoch: 6| Step: 4
Training loss: 3.044585477929939
Validation loss: 2.6976336746770584

Epoch: 6| Step: 5
Training loss: 3.4014410667489754
Validation loss: 2.6955908162155207

Epoch: 6| Step: 6
Training loss: 3.4769739486161626
Validation loss: 2.6722660830324907

Epoch: 6| Step: 7
Training loss: 2.8764294926665137
Validation loss: 2.6596763194411537

Epoch: 6| Step: 8
Training loss: 2.9525583520819247
Validation loss: 2.6538233936669684

Epoch: 6| Step: 9
Training loss: 2.9884138489269683
Validation loss: 2.6513807667873412

Epoch: 6| Step: 10
Training loss: 2.850647662005164
Validation loss: 2.647607710922816

Epoch: 6| Step: 11
Training loss: 2.785740431289103
Validation loss: 2.641677734945995

Epoch: 6| Step: 12
Training loss: 2.8070058777424505
Validation loss: 2.6410309077357583

Epoch: 6| Step: 13
Training loss: 2.8940653355202204
Validation loss: 2.6433562990088983

Epoch: 40| Step: 0
Training loss: 3.02546942985648
Validation loss: 2.638583971213162

Epoch: 6| Step: 1
Training loss: 3.1065986545087076
Validation loss: 2.636521524446283

Epoch: 6| Step: 2
Training loss: 3.2917675212104953
Validation loss: 2.639764443485337

Epoch: 6| Step: 3
Training loss: 3.1028874639621837
Validation loss: 2.639384629410137

Epoch: 6| Step: 4
Training loss: 3.074777089544968
Validation loss: 2.6376649299658856

Epoch: 6| Step: 5
Training loss: 2.618325967986757
Validation loss: 2.636657971798639

Epoch: 6| Step: 6
Training loss: 3.235516775088623
Validation loss: 2.633740162086635

Epoch: 6| Step: 7
Training loss: 2.699888993559766
Validation loss: 2.6380338383136324

Epoch: 6| Step: 8
Training loss: 3.0565151981055156
Validation loss: 2.6363712540299584

Epoch: 6| Step: 9
Training loss: 3.174720127055586
Validation loss: 2.637772097303709

Epoch: 6| Step: 10
Training loss: 2.7419676950723386
Validation loss: 2.654366512511354

Epoch: 6| Step: 11
Training loss: 2.9808478957934845
Validation loss: 2.6697772765615104

Epoch: 6| Step: 12
Training loss: 2.8525589547513355
Validation loss: 2.7229281258674805

Epoch: 6| Step: 13
Training loss: 2.924207113672413
Validation loss: 2.7226246771811504

Epoch: 41| Step: 0
Training loss: 2.8671595600648203
Validation loss: 2.7057543500969725

Epoch: 6| Step: 1
Training loss: 3.5421689444023525
Validation loss: 2.685202552118631

Epoch: 6| Step: 2
Training loss: 3.1501378468218646
Validation loss: 2.6782965155420335

Epoch: 6| Step: 3
Training loss: 2.279823902590933
Validation loss: 2.6722010305808555

Epoch: 6| Step: 4
Training loss: 3.2809190855736663
Validation loss: 2.672657603791357

Epoch: 6| Step: 5
Training loss: 2.4450116932283152
Validation loss: 2.675859181863782

Epoch: 6| Step: 6
Training loss: 3.542577215092162
Validation loss: 2.677233949387859

Epoch: 6| Step: 7
Training loss: 2.783972789686239
Validation loss: 2.662979789839846

Epoch: 6| Step: 8
Training loss: 3.278224167537503
Validation loss: 2.658339140328243

Epoch: 6| Step: 9
Training loss: 2.856296570646561
Validation loss: 2.6519431225844654

Epoch: 6| Step: 10
Training loss: 2.4867766665690128
Validation loss: 2.642822170924942

Epoch: 6| Step: 11
Training loss: 2.8572206146013523
Validation loss: 2.638454093655648

Epoch: 6| Step: 12
Training loss: 2.719191416718285
Validation loss: 2.6362980624345322

Epoch: 6| Step: 13
Training loss: 4.193346866612108
Validation loss: 2.631141665784617

Epoch: 42| Step: 0
Training loss: 3.074971554012069
Validation loss: 2.6262131283927506

Epoch: 6| Step: 1
Training loss: 2.884083041441283
Validation loss: 2.620393871274443

Epoch: 6| Step: 2
Training loss: 2.949456898756045
Validation loss: 2.6225589285554314

Epoch: 6| Step: 3
Training loss: 2.711935689563116
Validation loss: 2.6215582892383944

Epoch: 6| Step: 4
Training loss: 2.218047554682718
Validation loss: 2.62816429641896

Epoch: 6| Step: 5
Training loss: 3.4218113166073905
Validation loss: 2.6295092381088647

Epoch: 6| Step: 6
Training loss: 3.0331763998943377
Validation loss: 2.6285805831975684

Epoch: 6| Step: 7
Training loss: 2.8926562621325216
Validation loss: 2.629804266846067

Epoch: 6| Step: 8
Training loss: 3.5087091536092845
Validation loss: 2.620923695411083

Epoch: 6| Step: 9
Training loss: 3.1351741726570004
Validation loss: 2.6221170430073246

Epoch: 6| Step: 10
Training loss: 2.555021584973915
Validation loss: 2.622502409860583

Epoch: 6| Step: 11
Training loss: 3.262234182234809
Validation loss: 2.6181958757004793

Epoch: 6| Step: 12
Training loss: 3.110622443316334
Validation loss: 2.63332543084405

Epoch: 6| Step: 13
Training loss: 2.3738657602023197
Validation loss: 2.634399637732741

Epoch: 43| Step: 0
Training loss: 2.9124009864578073
Validation loss: 2.666426152841207

Epoch: 6| Step: 1
Training loss: 3.86701635116857
Validation loss: 2.656725960156278

Epoch: 6| Step: 2
Training loss: 2.674069936335634
Validation loss: 2.6254391925415796

Epoch: 6| Step: 3
Training loss: 3.0164502847812096
Validation loss: 2.6172894377945366

Epoch: 6| Step: 4
Training loss: 2.606152766401327
Validation loss: 2.6175524777154746

Epoch: 6| Step: 5
Training loss: 2.3115526269214786
Validation loss: 2.623193759104357

Epoch: 6| Step: 6
Training loss: 3.3870512943173616
Validation loss: 2.6237233217210894

Epoch: 6| Step: 7
Training loss: 2.8039436735353886
Validation loss: 2.630394273779062

Epoch: 6| Step: 8
Training loss: 3.134744177058636
Validation loss: 2.6312869892770236

Epoch: 6| Step: 9
Training loss: 3.0105969508129347
Validation loss: 2.629834046115847

Epoch: 6| Step: 10
Training loss: 2.9329018824618798
Validation loss: 2.6284977491406836

Epoch: 6| Step: 11
Training loss: 2.990995881970886
Validation loss: 2.629224189134376

Epoch: 6| Step: 12
Training loss: 3.3400401989008213
Validation loss: 2.625872809202594

Epoch: 6| Step: 13
Training loss: 2.649380136364752
Validation loss: 2.6245459805098292

Epoch: 44| Step: 0
Training loss: 3.1812872084444535
Validation loss: 2.618722949195572

Epoch: 6| Step: 1
Training loss: 2.824370869487689
Validation loss: 2.620937537089458

Epoch: 6| Step: 2
Training loss: 2.8357434587326686
Validation loss: 2.620647236811394

Epoch: 6| Step: 3
Training loss: 2.8481774709998384
Validation loss: 2.6229429716070127

Epoch: 6| Step: 4
Training loss: 3.090317179872771
Validation loss: 2.6338160328727835

Epoch: 6| Step: 5
Training loss: 2.6378043193529854
Validation loss: 2.646282525786767

Epoch: 6| Step: 6
Training loss: 3.163022169346022
Validation loss: 2.6632932031509107

Epoch: 6| Step: 7
Training loss: 2.9502454170687322
Validation loss: 2.68440376530008

Epoch: 6| Step: 8
Training loss: 2.871400985368364
Validation loss: 2.6670488803372385

Epoch: 6| Step: 9
Training loss: 3.1193561706402693
Validation loss: 2.6420501311751603

Epoch: 6| Step: 10
Training loss: 2.918376929805152
Validation loss: 2.631830822557284

Epoch: 6| Step: 11
Training loss: 2.6773996623924035
Validation loss: 2.6344911979458017

Epoch: 6| Step: 12
Training loss: 3.217114375553892
Validation loss: 2.627817098451177

Epoch: 6| Step: 13
Training loss: 3.5076968167606775
Validation loss: 2.635746665552336

Epoch: 45| Step: 0
Training loss: 3.1903676615775867
Validation loss: 2.62476824056211

Epoch: 6| Step: 1
Training loss: 2.6989304296085863
Validation loss: 2.619797617649618

Epoch: 6| Step: 2
Training loss: 2.754738712970706
Validation loss: 2.607332112373136

Epoch: 6| Step: 3
Training loss: 2.697943953642449
Validation loss: 2.607126457055693

Epoch: 6| Step: 4
Training loss: 3.096120215395971
Validation loss: 2.606263912881169

Epoch: 6| Step: 5
Training loss: 2.7289873505911086
Validation loss: 2.6099229227158394

Epoch: 6| Step: 6
Training loss: 3.145923604785793
Validation loss: 2.605484788270943

Epoch: 6| Step: 7
Training loss: 3.892813193596849
Validation loss: 2.6112223817983944

Epoch: 6| Step: 8
Training loss: 2.5894837740610557
Validation loss: 2.6065413826330572

Epoch: 6| Step: 9
Training loss: 2.9392763002255133
Validation loss: 2.604342059392008

Epoch: 6| Step: 10
Training loss: 2.542688122806661
Validation loss: 2.6016439656500823

Epoch: 6| Step: 11
Training loss: 3.2722210865921904
Validation loss: 2.605584596246326

Epoch: 6| Step: 12
Training loss: 2.7656232758425063
Validation loss: 2.604534884764554

Epoch: 6| Step: 13
Training loss: 3.0658992664090543
Validation loss: 2.606982286498714

Epoch: 46| Step: 0
Training loss: 3.352105796901495
Validation loss: 2.6075373139620432

Epoch: 6| Step: 1
Training loss: 3.032769520379865
Validation loss: 2.608345369449279

Epoch: 6| Step: 2
Training loss: 2.90412858220163
Validation loss: 2.6161550567871292

Epoch: 6| Step: 3
Training loss: 2.9775081544087016
Validation loss: 2.62069517341703

Epoch: 6| Step: 4
Training loss: 3.1321816891408236
Validation loss: 2.618501323460423

Epoch: 6| Step: 5
Training loss: 2.843723171233335
Validation loss: 2.610352136049551

Epoch: 6| Step: 6
Training loss: 2.832642882498263
Validation loss: 2.605822228312744

Epoch: 6| Step: 7
Training loss: 2.96106520405059
Validation loss: 2.606106422490465

Epoch: 6| Step: 8
Training loss: 2.4190375657367955
Validation loss: 2.6038183593803166

Epoch: 6| Step: 9
Training loss: 2.4427412365701637
Validation loss: 2.609922247898461

Epoch: 6| Step: 10
Training loss: 3.0860336095595353
Validation loss: 2.5996643244518305

Epoch: 6| Step: 11
Training loss: 3.039264740870742
Validation loss: 2.5976893091422766

Epoch: 6| Step: 12
Training loss: 3.4895475167481336
Validation loss: 2.603746683689494

Epoch: 6| Step: 13
Training loss: 2.5709557931216063
Validation loss: 2.6040774773532145

Epoch: 47| Step: 0
Training loss: 2.4055516604401044
Validation loss: 2.615693612135483

Epoch: 6| Step: 1
Training loss: 2.8792411371326363
Validation loss: 2.6331701538750294

Epoch: 6| Step: 2
Training loss: 2.8110501260973426
Validation loss: 2.6513164086258043

Epoch: 6| Step: 3
Training loss: 3.3914249724578953
Validation loss: 2.6530676002660543

Epoch: 6| Step: 4
Training loss: 2.0407823347160785
Validation loss: 2.6381458961069

Epoch: 6| Step: 5
Training loss: 3.437638713465452
Validation loss: 2.639765535071931

Epoch: 6| Step: 6
Training loss: 2.926121527692283
Validation loss: 2.6192429311435927

Epoch: 6| Step: 7
Training loss: 2.9932190235064096
Validation loss: 2.619173681157566

Epoch: 6| Step: 8
Training loss: 3.1154976377788923
Validation loss: 2.605235437094252

Epoch: 6| Step: 9
Training loss: 2.9101138118235363
Validation loss: 2.60752388880306

Epoch: 6| Step: 10
Training loss: 2.8074456469334965
Validation loss: 2.592976943809515

Epoch: 6| Step: 11
Training loss: 2.6301569464671335
Validation loss: 2.590420863333932

Epoch: 6| Step: 12
Training loss: 3.1452460003875853
Validation loss: 2.5933192943573973

Epoch: 6| Step: 13
Training loss: 3.850299620426081
Validation loss: 2.590470895204262

Epoch: 48| Step: 0
Training loss: 3.0367736827140104
Validation loss: 2.584331580245169

Epoch: 6| Step: 1
Training loss: 2.539092360100861
Validation loss: 2.586691996854534

Epoch: 6| Step: 2
Training loss: 3.355904707382094
Validation loss: 2.5834610464525953

Epoch: 6| Step: 3
Training loss: 2.2914522475299286
Validation loss: 2.584315392841344

Epoch: 6| Step: 4
Training loss: 3.297784327351709
Validation loss: 2.5815165734370216

Epoch: 6| Step: 5
Training loss: 2.390829439085799
Validation loss: 2.581656395661564

Epoch: 6| Step: 6
Training loss: 2.9237195073136357
Validation loss: 2.5806194738358106

Epoch: 6| Step: 7
Training loss: 2.502562735244703
Validation loss: 2.5789904815060543

Epoch: 6| Step: 8
Training loss: 2.936673636570719
Validation loss: 2.576151818956771

Epoch: 6| Step: 9
Training loss: 3.1940428955981317
Validation loss: 2.591980397816155

Epoch: 6| Step: 10
Training loss: 3.373991921659973
Validation loss: 2.6008922754798256

Epoch: 6| Step: 11
Training loss: 3.1245396084203194
Validation loss: 2.6203695212143474

Epoch: 6| Step: 12
Training loss: 2.7629415996287334
Validation loss: 2.6414175245329132

Epoch: 6| Step: 13
Training loss: 3.4455832031194866
Validation loss: 2.638868924295507

Epoch: 49| Step: 0
Training loss: 3.2451116037794274
Validation loss: 2.6720441222479985

Epoch: 6| Step: 1
Training loss: 2.4126858535886284
Validation loss: 2.670412439650784

Epoch: 6| Step: 2
Training loss: 2.811874998372034
Validation loss: 2.6760771839629456

Epoch: 6| Step: 3
Training loss: 2.82203211890853
Validation loss: 2.6649892252057588

Epoch: 6| Step: 4
Training loss: 2.7239081023759244
Validation loss: 2.6344468910589858

Epoch: 6| Step: 5
Training loss: 4.051517842639179
Validation loss: 2.6066502996683623

Epoch: 6| Step: 6
Training loss: 2.910949516988246
Validation loss: 2.5829980571786

Epoch: 6| Step: 7
Training loss: 2.227330767949277
Validation loss: 2.5730599794450613

Epoch: 6| Step: 8
Training loss: 2.847679525314259
Validation loss: 2.5734429845949425

Epoch: 6| Step: 9
Training loss: 2.9338346298617406
Validation loss: 2.579076661552894

Epoch: 6| Step: 10
Training loss: 3.196619191007796
Validation loss: 2.5848658128315

Epoch: 6| Step: 11
Training loss: 2.6216023572765064
Validation loss: 2.596745944750036

Epoch: 6| Step: 12
Training loss: 3.140170847381497
Validation loss: 2.5974163064573577

Epoch: 6| Step: 13
Training loss: 3.436568255293501
Validation loss: 2.5902612388292727

Epoch: 50| Step: 0
Training loss: 3.335278912824318
Validation loss: 2.58839875513806

Epoch: 6| Step: 1
Training loss: 2.2878012453596233
Validation loss: 2.5837305853824137

Epoch: 6| Step: 2
Training loss: 3.690326577184851
Validation loss: 2.5794744823536626

Epoch: 6| Step: 3
Training loss: 2.890279883325329
Validation loss: 2.571512668636387

Epoch: 6| Step: 4
Training loss: 2.7770625104836566
Validation loss: 2.5673339853086548

Epoch: 6| Step: 5
Training loss: 2.7093708007498365
Validation loss: 2.5740394485648306

Epoch: 6| Step: 6
Training loss: 3.0248550128081746
Validation loss: 2.5759089905176373

Epoch: 6| Step: 7
Training loss: 3.0862520854289355
Validation loss: 2.5954276376152774

Epoch: 6| Step: 8
Training loss: 2.5343883509348943
Validation loss: 2.6128280866978315

Epoch: 6| Step: 9
Training loss: 2.9930990638334056
Validation loss: 2.656672933013752

Epoch: 6| Step: 10
Training loss: 3.1211128472995995
Validation loss: 2.669127282405205

Epoch: 6| Step: 11
Training loss: 2.4456459281215066
Validation loss: 2.64986696638791

Epoch: 6| Step: 12
Training loss: 3.038250576893414
Validation loss: 2.6229542848824754

Epoch: 6| Step: 13
Training loss: 3.340399516304574
Validation loss: 2.608182913211782

Epoch: 51| Step: 0
Training loss: 3.3083640134783705
Validation loss: 2.581315872045907

Epoch: 6| Step: 1
Training loss: 2.935196967980978
Validation loss: 2.568897242555504

Epoch: 6| Step: 2
Training loss: 2.841892516109664
Validation loss: 2.5684318385964815

Epoch: 6| Step: 3
Training loss: 3.339012140618137
Validation loss: 2.5718341054662877

Epoch: 6| Step: 4
Training loss: 3.479595926875857
Validation loss: 2.568444149558892

Epoch: 6| Step: 5
Training loss: 2.3746080577085507
Validation loss: 2.5709709787455832

Epoch: 6| Step: 6
Training loss: 2.715120370068775
Validation loss: 2.5746143192807356

Epoch: 6| Step: 7
Training loss: 2.8399357629952573
Validation loss: 2.5787046440283024

Epoch: 6| Step: 8
Training loss: 3.3079742608320197
Validation loss: 2.580557372377875

Epoch: 6| Step: 9
Training loss: 2.2756374765508274
Validation loss: 2.5818078657440906

Epoch: 6| Step: 10
Training loss: 2.993835473482996
Validation loss: 2.5811511107123333

Epoch: 6| Step: 11
Training loss: 2.6426909902622797
Validation loss: 2.580064447659558

Epoch: 6| Step: 12
Training loss: 2.953554798315967
Validation loss: 2.5787987100684373

Epoch: 6| Step: 13
Training loss: 2.9528181935946933
Validation loss: 2.5749782695544283

Epoch: 52| Step: 0
Training loss: 3.446490650761457
Validation loss: 2.5717896072975415

Epoch: 6| Step: 1
Training loss: 2.719147576387735
Validation loss: 2.5680869839029445

Epoch: 6| Step: 2
Training loss: 2.7210606369557873
Validation loss: 2.5695251501686527

Epoch: 6| Step: 3
Training loss: 2.936234546554129
Validation loss: 2.5748199418654423

Epoch: 6| Step: 4
Training loss: 2.7392691273719074
Validation loss: 2.5755012593002022

Epoch: 6| Step: 5
Training loss: 3.5393684709674984
Validation loss: 2.584057385585729

Epoch: 6| Step: 6
Training loss: 2.5271073338395436
Validation loss: 2.576142989033715

Epoch: 6| Step: 7
Training loss: 3.300181389649642
Validation loss: 2.578153028488066

Epoch: 6| Step: 8
Training loss: 3.0509800571426275
Validation loss: 2.599173241008254

Epoch: 6| Step: 9
Training loss: 2.783312943282983
Validation loss: 2.6425221780611223

Epoch: 6| Step: 10
Training loss: 3.1111543251245526
Validation loss: 2.6787359755330016

Epoch: 6| Step: 11
Training loss: 2.99559699246203
Validation loss: 2.6605469463432083

Epoch: 6| Step: 12
Training loss: 2.713018932013536
Validation loss: 2.640181954566258

Epoch: 6| Step: 13
Training loss: 2.447373761515034
Validation loss: 2.621603632445704

Epoch: 53| Step: 0
Training loss: 2.1375523254057796
Validation loss: 2.601272660970325

Epoch: 6| Step: 1
Training loss: 3.1670095023906106
Validation loss: 2.5804973984274335

Epoch: 6| Step: 2
Training loss: 3.1561675108148557
Validation loss: 2.5754517832227015

Epoch: 6| Step: 3
Training loss: 3.373880553911983
Validation loss: 2.56031967475067

Epoch: 6| Step: 4
Training loss: 3.269496247572495
Validation loss: 2.5517221620072363

Epoch: 6| Step: 5
Training loss: 2.974961698910652
Validation loss: 2.553117186980363

Epoch: 6| Step: 6
Training loss: 1.993017823958331
Validation loss: 2.5557710511545837

Epoch: 6| Step: 7
Training loss: 2.7664193774399064
Validation loss: 2.5568541240682894

Epoch: 6| Step: 8
Training loss: 2.7284829445631456
Validation loss: 2.563587721204253

Epoch: 6| Step: 9
Training loss: 2.801349151368157
Validation loss: 2.5612604648348656

Epoch: 6| Step: 10
Training loss: 2.9163524640097838
Validation loss: 2.5541075058477656

Epoch: 6| Step: 11
Training loss: 3.37917521734759
Validation loss: 2.5521519209531345

Epoch: 6| Step: 12
Training loss: 3.2922883875107427
Validation loss: 2.5566092992738416

Epoch: 6| Step: 13
Training loss: 2.6297859885165464
Validation loss: 2.5525125336423424

Epoch: 54| Step: 0
Training loss: 2.47246976272716
Validation loss: 2.5553712487098497

Epoch: 6| Step: 1
Training loss: 2.9035597624516734
Validation loss: 2.5575154584623294

Epoch: 6| Step: 2
Training loss: 3.3615492770708113
Validation loss: 2.566318844801326

Epoch: 6| Step: 3
Training loss: 3.3799261240814196
Validation loss: 2.5794534899235324

Epoch: 6| Step: 4
Training loss: 3.3690816061406776
Validation loss: 2.5834532725436437

Epoch: 6| Step: 5
Training loss: 2.797265734097889
Validation loss: 2.5857357606587605

Epoch: 6| Step: 6
Training loss: 2.4782860952500356
Validation loss: 2.5678203824310417

Epoch: 6| Step: 7
Training loss: 3.1843091664046277
Validation loss: 2.5498540846199607

Epoch: 6| Step: 8
Training loss: 2.590268659760282
Validation loss: 2.547608201123363

Epoch: 6| Step: 9
Training loss: 2.6611887178760694
Validation loss: 2.543999486119698

Epoch: 6| Step: 10
Training loss: 2.971007121506113
Validation loss: 2.537819481586092

Epoch: 6| Step: 11
Training loss: 2.3144025451026424
Validation loss: 2.541641005923284

Epoch: 6| Step: 12
Training loss: 3.2262961806517527
Validation loss: 2.5404273689470025

Epoch: 6| Step: 13
Training loss: 3.0500840722675813
Validation loss: 2.5374182964325236

Epoch: 55| Step: 0
Training loss: 3.314545485693838
Validation loss: 2.5415959932563483

Epoch: 6| Step: 1
Training loss: 2.422868291142873
Validation loss: 2.543058863041675

Epoch: 6| Step: 2
Training loss: 3.034364967840329
Validation loss: 2.545922709363483

Epoch: 6| Step: 3
Training loss: 3.068449042143434
Validation loss: 2.549809499465624

Epoch: 6| Step: 4
Training loss: 3.5676831469609764
Validation loss: 2.5596121555933053

Epoch: 6| Step: 5
Training loss: 3.065613701320285
Validation loss: 2.5715515639077164

Epoch: 6| Step: 6
Training loss: 2.83576430955754
Validation loss: 2.5744664878121664

Epoch: 6| Step: 7
Training loss: 2.2709690601722254
Validation loss: 2.617217577591698

Epoch: 6| Step: 8
Training loss: 2.9171999489222857
Validation loss: 2.6863842685002046

Epoch: 6| Step: 9
Training loss: 3.083321923587068
Validation loss: 2.702284022555596

Epoch: 6| Step: 10
Training loss: 2.2416407752639422
Validation loss: 2.6896032243723256

Epoch: 6| Step: 11
Training loss: 3.0617779250289896
Validation loss: 2.686700093761586

Epoch: 6| Step: 12
Training loss: 2.9778644587899423
Validation loss: 2.6461593204899874

Epoch: 6| Step: 13
Training loss: 3.4278759875483744
Validation loss: 2.633452429621794

Epoch: 56| Step: 0
Training loss: 2.4464184877189803
Validation loss: 2.5843331436267603

Epoch: 6| Step: 1
Training loss: 2.6796439031051738
Validation loss: 2.586124619230797

Epoch: 6| Step: 2
Training loss: 3.1889036491338953
Validation loss: 2.594607198097623

Epoch: 6| Step: 3
Training loss: 2.284779992060851
Validation loss: 2.640896377361061

Epoch: 6| Step: 4
Training loss: 3.2300532118721943
Validation loss: 2.669329769625386

Epoch: 6| Step: 5
Training loss: 3.2438722208918205
Validation loss: 2.684938493565991

Epoch: 6| Step: 6
Training loss: 2.748899759928819
Validation loss: 2.678555428866853

Epoch: 6| Step: 7
Training loss: 3.4381627224265854
Validation loss: 2.6035951970968783

Epoch: 6| Step: 8
Training loss: 2.760052255052893
Validation loss: 2.5586355108719876

Epoch: 6| Step: 9
Training loss: 2.7524299289747622
Validation loss: 2.5569160312023964

Epoch: 6| Step: 10
Training loss: 3.444929936420435
Validation loss: 2.5612180190754033

Epoch: 6| Step: 11
Training loss: 3.284012421866747
Validation loss: 2.5785263032593906

Epoch: 6| Step: 12
Training loss: 2.9778745467877337
Validation loss: 2.588862990792702

Epoch: 6| Step: 13
Training loss: 2.6822269073866103
Validation loss: 2.6279578764438853

Epoch: 57| Step: 0
Training loss: 2.8913946003590296
Validation loss: 2.6298239205390703

Epoch: 6| Step: 1
Training loss: 3.1884264628050967
Validation loss: 2.5999874032648584

Epoch: 6| Step: 2
Training loss: 3.0608500492987227
Validation loss: 2.595618217500112

Epoch: 6| Step: 3
Training loss: 2.1878599688127998
Validation loss: 2.5875917293891986

Epoch: 6| Step: 4
Training loss: 2.263970132421814
Validation loss: 2.582809799752043

Epoch: 6| Step: 5
Training loss: 3.4526927556639975
Validation loss: 2.5798245026243607

Epoch: 6| Step: 6
Training loss: 3.2267305270356874
Validation loss: 2.566131705473528

Epoch: 6| Step: 7
Training loss: 2.511169088682713
Validation loss: 2.557438626740865

Epoch: 6| Step: 8
Training loss: 2.9364206481947592
Validation loss: 2.562664217805492

Epoch: 6| Step: 9
Training loss: 2.801941784163408
Validation loss: 2.565686413487808

Epoch: 6| Step: 10
Training loss: 3.0376208497170514
Validation loss: 2.5419010109458884

Epoch: 6| Step: 11
Training loss: 3.309759337789452
Validation loss: 2.535208935846425

Epoch: 6| Step: 12
Training loss: 3.183852408731205
Validation loss: 2.5361104327681514

Epoch: 6| Step: 13
Training loss: 1.886171060051683
Validation loss: 2.535309537582078

Epoch: 58| Step: 0
Training loss: 2.8086247342964503
Validation loss: 2.5420492517390754

Epoch: 6| Step: 1
Training loss: 2.4610831081365436
Validation loss: 2.5455154866080574

Epoch: 6| Step: 2
Training loss: 3.074841602246569
Validation loss: 2.5406962858328006

Epoch: 6| Step: 3
Training loss: 2.6804612713595213
Validation loss: 2.540161975120521

Epoch: 6| Step: 4
Training loss: 2.459138145820005
Validation loss: 2.5424877805911588

Epoch: 6| Step: 5
Training loss: 2.740150673336313
Validation loss: 2.541663765632457

Epoch: 6| Step: 6
Training loss: 2.8654874912162667
Validation loss: 2.549894950057284

Epoch: 6| Step: 7
Training loss: 3.0341370981380935
Validation loss: 2.5498465953337095

Epoch: 6| Step: 8
Training loss: 2.75162128860084
Validation loss: 2.5585802724320934

Epoch: 6| Step: 9
Training loss: 2.779286924064231
Validation loss: 2.5613976595400425

Epoch: 6| Step: 10
Training loss: 3.6433760436388294
Validation loss: 2.5786242874459635

Epoch: 6| Step: 11
Training loss: 3.3598450797560497
Validation loss: 2.57008774806412

Epoch: 6| Step: 12
Training loss: 2.8074607633055177
Validation loss: 2.565433446873742

Epoch: 6| Step: 13
Training loss: 3.313527649593276
Validation loss: 2.5385332150012077

Epoch: 59| Step: 0
Training loss: 2.1158943309107094
Validation loss: 2.5354052656976043

Epoch: 6| Step: 1
Training loss: 2.586890284255101
Validation loss: 2.5486441926553725

Epoch: 6| Step: 2
Training loss: 2.404334556848294
Validation loss: 2.5409212322134245

Epoch: 6| Step: 3
Training loss: 3.2917762126480095
Validation loss: 2.546016916721853

Epoch: 6| Step: 4
Training loss: 2.6523545367508934
Validation loss: 2.538904484705973

Epoch: 6| Step: 5
Training loss: 2.9460443452603906
Validation loss: 2.5396451679392626

Epoch: 6| Step: 6
Training loss: 2.143672806042292
Validation loss: 2.5459664120304377

Epoch: 6| Step: 7
Training loss: 3.550556977326679
Validation loss: 2.5525496896577495

Epoch: 6| Step: 8
Training loss: 3.260696415381421
Validation loss: 2.552053636617118

Epoch: 6| Step: 9
Training loss: 2.5944056773732633
Validation loss: 2.555952787587614

Epoch: 6| Step: 10
Training loss: 3.378101336795952
Validation loss: 2.5501755582603955

Epoch: 6| Step: 11
Training loss: 3.377995045126968
Validation loss: 2.53737725127126

Epoch: 6| Step: 12
Training loss: 2.7641288029129574
Validation loss: 2.528631146138034

Epoch: 6| Step: 13
Training loss: 3.136689562442036
Validation loss: 2.517612929110644

Epoch: 60| Step: 0
Training loss: 2.6178519700749585
Validation loss: 2.51776751285274

Epoch: 6| Step: 1
Training loss: 3.310834501931821
Validation loss: 2.520161683572718

Epoch: 6| Step: 2
Training loss: 3.111447970757577
Validation loss: 2.5219832072178106

Epoch: 6| Step: 3
Training loss: 2.5748407888728213
Validation loss: 2.521542372041756

Epoch: 6| Step: 4
Training loss: 3.1125602318018264
Validation loss: 2.518539211277795

Epoch: 6| Step: 5
Training loss: 3.1590005201802396
Validation loss: 2.5181396212588676

Epoch: 6| Step: 6
Training loss: 3.2584242577968308
Validation loss: 2.519190394665274

Epoch: 6| Step: 7
Training loss: 2.388873986141039
Validation loss: 2.522102882059832

Epoch: 6| Step: 8
Training loss: 3.0703252350443586
Validation loss: 2.5302684556536796

Epoch: 6| Step: 9
Training loss: 2.3507853392910594
Validation loss: 2.5359824618308937

Epoch: 6| Step: 10
Training loss: 2.789370479729657
Validation loss: 2.5531501852219605

Epoch: 6| Step: 11
Training loss: 3.393582087344422
Validation loss: 2.552164583668631

Epoch: 6| Step: 12
Training loss: 2.706082528727222
Validation loss: 2.545117851457302

Epoch: 6| Step: 13
Training loss: 2.3880130236604393
Validation loss: 2.536079401848184

Epoch: 61| Step: 0
Training loss: 2.878992045766185
Validation loss: 2.5411264274754792

Epoch: 6| Step: 1
Training loss: 2.8200889773569133
Validation loss: 2.5256524095091613

Epoch: 6| Step: 2
Training loss: 2.9277148306552454
Validation loss: 2.5202042125041086

Epoch: 6| Step: 3
Training loss: 1.5298586382417592
Validation loss: 2.518986851405916

Epoch: 6| Step: 4
Training loss: 2.5361811325176435
Validation loss: 2.517214640277825

Epoch: 6| Step: 5
Training loss: 3.222542019755801
Validation loss: 2.517690162600418

Epoch: 6| Step: 6
Training loss: 2.801391705286891
Validation loss: 2.5175545778048996

Epoch: 6| Step: 7
Training loss: 3.313335097508821
Validation loss: 2.520172119543948

Epoch: 6| Step: 8
Training loss: 2.940022947520274
Validation loss: 2.5265852841882546

Epoch: 6| Step: 9
Training loss: 2.8840541078356745
Validation loss: 2.529013014553913

Epoch: 6| Step: 10
Training loss: 2.8831457756942864
Validation loss: 2.535704253245309

Epoch: 6| Step: 11
Training loss: 3.0070898203449246
Validation loss: 2.542603658089114

Epoch: 6| Step: 12
Training loss: 3.6427633529899017
Validation loss: 2.5596087893013366

Epoch: 6| Step: 13
Training loss: 2.525870363909415
Validation loss: 2.5549214634065667

Epoch: 62| Step: 0
Training loss: 3.049756218595002
Validation loss: 2.5672994078899816

Epoch: 6| Step: 1
Training loss: 2.958962619814827
Validation loss: 2.566524422793453

Epoch: 6| Step: 2
Training loss: 2.415981480596944
Validation loss: 2.556019820730285

Epoch: 6| Step: 3
Training loss: 3.1381555974152824
Validation loss: 2.5425159034816844

Epoch: 6| Step: 4
Training loss: 2.426279898237688
Validation loss: 2.525674789033001

Epoch: 6| Step: 5
Training loss: 3.28398759264815
Validation loss: 2.52081170950388

Epoch: 6| Step: 6
Training loss: 2.9786228848515104
Validation loss: 2.5127580698622247

Epoch: 6| Step: 7
Training loss: 2.4432728216147015
Validation loss: 2.5122386958320932

Epoch: 6| Step: 8
Training loss: 3.7683472982825816
Validation loss: 2.5111559752487778

Epoch: 6| Step: 9
Training loss: 2.780047124422097
Validation loss: 2.515504271985343

Epoch: 6| Step: 10
Training loss: 2.45021088140231
Validation loss: 2.510809524045491

Epoch: 6| Step: 11
Training loss: 2.7893968910625
Validation loss: 2.5141983802206997

Epoch: 6| Step: 12
Training loss: 2.870759407350281
Validation loss: 2.5112922474884085

Epoch: 6| Step: 13
Training loss: 3.1069484424371128
Validation loss: 2.5100959321388547

Epoch: 63| Step: 0
Training loss: 2.4205111693573915
Validation loss: 2.510865225834243

Epoch: 6| Step: 1
Training loss: 2.3011516797447618
Validation loss: 2.5122314607559404

Epoch: 6| Step: 2
Training loss: 2.937880146508537
Validation loss: 2.5130029821274573

Epoch: 6| Step: 3
Training loss: 2.7710544717831875
Validation loss: 2.5180746564009118

Epoch: 6| Step: 4
Training loss: 3.143638569428775
Validation loss: 2.5142306758696757

Epoch: 6| Step: 5
Training loss: 2.489180038751682
Validation loss: 2.530261208301057

Epoch: 6| Step: 6
Training loss: 3.0347945735482154
Validation loss: 2.5438296472857855

Epoch: 6| Step: 7
Training loss: 3.1909086663622057
Validation loss: 2.5670411284902945

Epoch: 6| Step: 8
Training loss: 3.3792710300295496
Validation loss: 2.560686404585028

Epoch: 6| Step: 9
Training loss: 2.71357980849001
Validation loss: 2.572979999560042

Epoch: 6| Step: 10
Training loss: 2.782620038976043
Validation loss: 2.59934208523121

Epoch: 6| Step: 11
Training loss: 2.252678230846775
Validation loss: 2.588912883438856

Epoch: 6| Step: 12
Training loss: 3.380434817273217
Validation loss: 2.600577467548712

Epoch: 6| Step: 13
Training loss: 3.602998194981784
Validation loss: 2.5622345501510475

Epoch: 64| Step: 0
Training loss: 3.396169322111771
Validation loss: 2.507596299712379

Epoch: 6| Step: 1
Training loss: 2.711747194238243
Validation loss: 2.4998129210667535

Epoch: 6| Step: 2
Training loss: 2.6216719283891643
Validation loss: 2.506312866011671

Epoch: 6| Step: 3
Training loss: 3.342881990230937
Validation loss: 2.5150042454407613

Epoch: 6| Step: 4
Training loss: 2.641488289652047
Validation loss: 2.5286453196546796

Epoch: 6| Step: 5
Training loss: 2.6811069477040363
Validation loss: 2.5394492617883486

Epoch: 6| Step: 6
Training loss: 2.5049100342697255
Validation loss: 2.5454052810771914

Epoch: 6| Step: 7
Training loss: 2.940068846434951
Validation loss: 2.5447561284214872

Epoch: 6| Step: 8
Training loss: 3.1764545923341396
Validation loss: 2.5473476132209165

Epoch: 6| Step: 9
Training loss: 2.4187041167409458
Validation loss: 2.533942819508209

Epoch: 6| Step: 10
Training loss: 2.5833180232260906
Validation loss: 2.527743299825253

Epoch: 6| Step: 11
Training loss: 3.4215459796068743
Validation loss: 2.516866702726267

Epoch: 6| Step: 12
Training loss: 3.3141619273967073
Validation loss: 2.5084565924223856

Epoch: 6| Step: 13
Training loss: 2.8555724494358485
Validation loss: 2.503285365835993

Epoch: 65| Step: 0
Training loss: 2.917356700107414
Validation loss: 2.50053257550566

Epoch: 6| Step: 1
Training loss: 3.106594510229613
Validation loss: 2.504841371347089

Epoch: 6| Step: 2
Training loss: 3.2012633333297167
Validation loss: 2.5156239584929105

Epoch: 6| Step: 3
Training loss: 2.6134606087436234
Validation loss: 2.5421162904732904

Epoch: 6| Step: 4
Training loss: 2.6985971974539744
Validation loss: 2.5679604821849624

Epoch: 6| Step: 5
Training loss: 3.6076945566862033
Validation loss: 2.5611096503775483

Epoch: 6| Step: 6
Training loss: 2.76783061036784
Validation loss: 2.553923661614416

Epoch: 6| Step: 7
Training loss: 1.8695078203109656
Validation loss: 2.526733479954806

Epoch: 6| Step: 8
Training loss: 2.826366067263616
Validation loss: 2.5141340558570007

Epoch: 6| Step: 9
Training loss: 3.5344879698975618
Validation loss: 2.504776882428126

Epoch: 6| Step: 10
Training loss: 2.520297526854885
Validation loss: 2.505585749213774

Epoch: 6| Step: 11
Training loss: 2.8586556618974486
Validation loss: 2.4969570324421944

Epoch: 6| Step: 12
Training loss: 2.772297197634871
Validation loss: 2.502712229538645

Epoch: 6| Step: 13
Training loss: 2.634272954192937
Validation loss: 2.5027342887099433

Epoch: 66| Step: 0
Training loss: 2.687429205383419
Validation loss: 2.4993338066436976

Epoch: 6| Step: 1
Training loss: 2.5451498917542326
Validation loss: 2.5007841316143473

Epoch: 6| Step: 2
Training loss: 3.559354363734145
Validation loss: 2.5025288384403233

Epoch: 6| Step: 3
Training loss: 3.035005897126604
Validation loss: 2.50198849894011

Epoch: 6| Step: 4
Training loss: 2.736743968920388
Validation loss: 2.499011843237521

Epoch: 6| Step: 5
Training loss: 3.1324876726277853
Validation loss: 2.501427111863605

Epoch: 6| Step: 6
Training loss: 2.91394140897035
Validation loss: 2.5025451348608945

Epoch: 6| Step: 7
Training loss: 2.865223058302464
Validation loss: 2.5031085674102966

Epoch: 6| Step: 8
Training loss: 2.67578125
Validation loss: 2.5111260392021206

Epoch: 6| Step: 9
Training loss: 3.0335832248360743
Validation loss: 2.5180013626346334

Epoch: 6| Step: 10
Training loss: 2.27171559358311
Validation loss: 2.517858622526706

Epoch: 6| Step: 11
Training loss: 3.26682036940015
Validation loss: 2.521004392277326

Epoch: 6| Step: 12
Training loss: 2.7903747036255364
Validation loss: 2.512065411562206

Epoch: 6| Step: 13
Training loss: 2.556410462209452
Validation loss: 2.5117934988117008

Epoch: 67| Step: 0
Training loss: 2.9972457958665726
Validation loss: 2.51536019160198

Epoch: 6| Step: 1
Training loss: 3.000721685706757
Validation loss: 2.5206174029993536

Epoch: 6| Step: 2
Training loss: 2.9085382456764255
Validation loss: 2.5171368391657705

Epoch: 6| Step: 3
Training loss: 2.0751378668519522
Validation loss: 2.5137036062885776

Epoch: 6| Step: 4
Training loss: 2.5997392376936395
Validation loss: 2.5181532205918233

Epoch: 6| Step: 5
Training loss: 2.8214761547194387
Validation loss: 2.5195514911850654

Epoch: 6| Step: 6
Training loss: 2.623360621477227
Validation loss: 2.5214469035492098

Epoch: 6| Step: 7
Training loss: 3.4007420235038124
Validation loss: 2.513988396892209

Epoch: 6| Step: 8
Training loss: 2.948074300660408
Validation loss: 2.5051942844153428

Epoch: 6| Step: 9
Training loss: 3.24706840342989
Validation loss: 2.508205179261608

Epoch: 6| Step: 10
Training loss: 2.8639691243452043
Validation loss: 2.504606897774978

Epoch: 6| Step: 11
Training loss: 2.7982469315980234
Validation loss: 2.5079475596216794

Epoch: 6| Step: 12
Training loss: 2.938783405849118
Validation loss: 2.5041935655262577

Epoch: 6| Step: 13
Training loss: 2.5610553111546053
Validation loss: 2.5105939698763304

Epoch: 68| Step: 0
Training loss: 3.1036434543372393
Validation loss: 2.529472901086751

Epoch: 6| Step: 1
Training loss: 2.6712398554922148
Validation loss: 2.517327210383471

Epoch: 6| Step: 2
Training loss: 2.673625974627597
Validation loss: 2.523804303996849

Epoch: 6| Step: 3
Training loss: 2.376409915236762
Validation loss: 2.518338460667478

Epoch: 6| Step: 4
Training loss: 3.4385791818505442
Validation loss: 2.533279186937376

Epoch: 6| Step: 5
Training loss: 2.792405377102254
Validation loss: 2.5299874695193556

Epoch: 6| Step: 6
Training loss: 2.5004262560805843
Validation loss: 2.5312261424579154

Epoch: 6| Step: 7
Training loss: 2.797264370373968
Validation loss: 2.5607415505397744

Epoch: 6| Step: 8
Training loss: 3.3973431809410886
Validation loss: 2.58938012679661

Epoch: 6| Step: 9
Training loss: 3.2204665264255037
Validation loss: 2.5363308720247764

Epoch: 6| Step: 10
Training loss: 2.566364166054069
Validation loss: 2.5119219228461414

Epoch: 6| Step: 11
Training loss: 2.625717337550378
Validation loss: 2.5032111372119847

Epoch: 6| Step: 12
Training loss: 3.055017009631564
Validation loss: 2.49477295234096

Epoch: 6| Step: 13
Training loss: 2.6824890261636263
Validation loss: 2.493870485310496

Epoch: 69| Step: 0
Training loss: 3.081727064856735
Validation loss: 2.49774133109188

Epoch: 6| Step: 1
Training loss: 3.2365405807791556
Validation loss: 2.5028427707033525

Epoch: 6| Step: 2
Training loss: 2.820992173907145
Validation loss: 2.5101919508054995

Epoch: 6| Step: 3
Training loss: 3.0094435195807194
Validation loss: 2.511792378147105

Epoch: 6| Step: 4
Training loss: 3.1673423815789157
Validation loss: 2.520252340497322

Epoch: 6| Step: 5
Training loss: 3.020604898870113
Validation loss: 2.5246365430477895

Epoch: 6| Step: 6
Training loss: 2.560445194276868
Validation loss: 2.511351986638942

Epoch: 6| Step: 7
Training loss: 2.7453935362612976
Validation loss: 2.5063438762711576

Epoch: 6| Step: 8
Training loss: 2.7487416422787563
Validation loss: 2.4967719659437377

Epoch: 6| Step: 9
Training loss: 2.864284115971961
Validation loss: 2.4941754364995012

Epoch: 6| Step: 10
Training loss: 2.368190238257399
Validation loss: 2.4989137468738964

Epoch: 6| Step: 11
Training loss: 2.774332767035363
Validation loss: 2.494401247190852

Epoch: 6| Step: 12
Training loss: 2.884576852003133
Validation loss: 2.5038260868976563

Epoch: 6| Step: 13
Training loss: 3.098832242735273
Validation loss: 2.5055394216858295

Epoch: 70| Step: 0
Training loss: 2.682104149840804
Validation loss: 2.511645764777947

Epoch: 6| Step: 1
Training loss: 2.2607122365726595
Validation loss: 2.533051542818574

Epoch: 6| Step: 2
Training loss: 3.411145812806246
Validation loss: 2.533430698830452

Epoch: 6| Step: 3
Training loss: 3.087386551598964
Validation loss: 2.521605316904296

Epoch: 6| Step: 4
Training loss: 3.2355155960813033
Validation loss: 2.511233138834885

Epoch: 6| Step: 5
Training loss: 3.2798136155741036
Validation loss: 2.4988745309489055

Epoch: 6| Step: 6
Training loss: 3.4262180028212517
Validation loss: 2.492552858133803

Epoch: 6| Step: 7
Training loss: 2.63479982980253
Validation loss: 2.4888813932379685

Epoch: 6| Step: 8
Training loss: 3.0101572384747275
Validation loss: 2.494530880067512

Epoch: 6| Step: 9
Training loss: 2.1804011007412205
Validation loss: 2.4957377658011586

Epoch: 6| Step: 10
Training loss: 2.5708961635765886
Validation loss: 2.4932234709997854

Epoch: 6| Step: 11
Training loss: 2.7354535400818434
Validation loss: 2.493680228357963

Epoch: 6| Step: 12
Training loss: 2.7626182461800974
Validation loss: 2.4922484068568096

Epoch: 6| Step: 13
Training loss: 1.860096767328432
Validation loss: 2.501138786676459

Epoch: 71| Step: 0
Training loss: 3.453233259756581
Validation loss: 2.5052103895321736

Epoch: 6| Step: 1
Training loss: 2.7792171807299972
Validation loss: 2.5100717601642755

Epoch: 6| Step: 2
Training loss: 2.6985130878192596
Validation loss: 2.5021959463810344

Epoch: 6| Step: 3
Training loss: 2.6663514984169567
Validation loss: 2.500771643392031

Epoch: 6| Step: 4
Training loss: 2.9697761769840225
Validation loss: 2.5018767214026703

Epoch: 6| Step: 5
Training loss: 3.3534684175113525
Validation loss: 2.509508791774327

Epoch: 6| Step: 6
Training loss: 2.8306590156086417
Validation loss: 2.509681358756619

Epoch: 6| Step: 7
Training loss: 2.4680248112845646
Validation loss: 2.526819278710926

Epoch: 6| Step: 8
Training loss: 2.746324510496814
Validation loss: 2.5362661861275018

Epoch: 6| Step: 9
Training loss: 2.9721408151508317
Validation loss: 2.559259859792853

Epoch: 6| Step: 10
Training loss: 2.26009013781094
Validation loss: 2.5836109094287347

Epoch: 6| Step: 11
Training loss: 2.965343247305583
Validation loss: 2.569252277990256

Epoch: 6| Step: 12
Training loss: 2.6406913613552567
Validation loss: 2.5744774455160835

Epoch: 6| Step: 13
Training loss: 3.0715806201039784
Validation loss: 2.554598390248696

Epoch: 72| Step: 0
Training loss: 2.8452597163340916
Validation loss: 2.5428007014345546

Epoch: 6| Step: 1
Training loss: 2.741680391812585
Validation loss: 2.529185891813664

Epoch: 6| Step: 2
Training loss: 2.41156597734838
Validation loss: 2.5225597559132673

Epoch: 6| Step: 3
Training loss: 2.5977764818862514
Validation loss: 2.5106362483508313

Epoch: 6| Step: 4
Training loss: 2.8546458675060955
Validation loss: 2.500406759252686

Epoch: 6| Step: 5
Training loss: 3.0802750412640076
Validation loss: 2.51097017059144

Epoch: 6| Step: 6
Training loss: 2.759142676452415
Validation loss: 2.494890724373671

Epoch: 6| Step: 7
Training loss: 3.731113941261481
Validation loss: 2.4890468591075647

Epoch: 6| Step: 8
Training loss: 2.39117355535567
Validation loss: 2.484870407211663

Epoch: 6| Step: 9
Training loss: 2.856563499157552
Validation loss: 2.494258912018939

Epoch: 6| Step: 10
Training loss: 2.6539701663527384
Validation loss: 2.498882134016451

Epoch: 6| Step: 11
Training loss: 2.7626574268622273
Validation loss: 2.4910908118140025

Epoch: 6| Step: 12
Training loss: 2.787928075379853
Validation loss: 2.4928516469042283

Epoch: 6| Step: 13
Training loss: 3.5781671113447153
Validation loss: 2.4899169606338485

Epoch: 73| Step: 0
Training loss: 2.596084830733437
Validation loss: 2.493159182335655

Epoch: 6| Step: 1
Training loss: 2.9659934648067527
Validation loss: 2.4907397632702257

Epoch: 6| Step: 2
Training loss: 2.6319996289250076
Validation loss: 2.4969782132960536

Epoch: 6| Step: 3
Training loss: 2.504981608980019
Validation loss: 2.5004823670537184

Epoch: 6| Step: 4
Training loss: 2.8221633206209127
Validation loss: 2.506160997450063

Epoch: 6| Step: 5
Training loss: 3.404691427087642
Validation loss: 2.51042637452737

Epoch: 6| Step: 6
Training loss: 2.415935888185014
Validation loss: 2.5171452436064343

Epoch: 6| Step: 7
Training loss: 2.8078560530182872
Validation loss: 2.5316932069418456

Epoch: 6| Step: 8
Training loss: 2.873374479431432
Validation loss: 2.5524963834878225

Epoch: 6| Step: 9
Training loss: 2.839966993005782
Validation loss: 2.5606524742606216

Epoch: 6| Step: 10
Training loss: 3.0254297124653813
Validation loss: 2.530761850945414

Epoch: 6| Step: 11
Training loss: 2.6035901664943193
Validation loss: 2.512788545555829

Epoch: 6| Step: 12
Training loss: 2.996293957721622
Validation loss: 2.4963990262524436

Epoch: 6| Step: 13
Training loss: 3.405942150518447
Validation loss: 2.484229022335985

Epoch: 74| Step: 0
Training loss: 3.170944904331154
Validation loss: 2.485391917554726

Epoch: 6| Step: 1
Training loss: 2.738925308473736
Validation loss: 2.4787424051443145

Epoch: 6| Step: 2
Training loss: 2.5509041585709564
Validation loss: 2.4825040335505184

Epoch: 6| Step: 3
Training loss: 2.805388126686095
Validation loss: 2.4837544634240274

Epoch: 6| Step: 4
Training loss: 2.805988233290109
Validation loss: 2.4840668683067726

Epoch: 6| Step: 5
Training loss: 2.938260892976543
Validation loss: 2.4888650866642754

Epoch: 6| Step: 6
Training loss: 3.0637352456928593
Validation loss: 2.4830521513219166

Epoch: 6| Step: 7
Training loss: 2.767586395100558
Validation loss: 2.4888481392920743

Epoch: 6| Step: 8
Training loss: 2.7163146939672873
Validation loss: 2.4974276999049008

Epoch: 6| Step: 9
Training loss: 2.0929609491502625
Validation loss: 2.5067121148696625

Epoch: 6| Step: 10
Training loss: 3.5922068060662693
Validation loss: 2.5093496229479015

Epoch: 6| Step: 11
Training loss: 2.727998808818568
Validation loss: 2.520668956658837

Epoch: 6| Step: 12
Training loss: 2.7719277154324424
Validation loss: 2.5551775877141054

Epoch: 6| Step: 13
Training loss: 2.684960074385409
Validation loss: 2.560399549977348

Epoch: 75| Step: 0
Training loss: 2.2435230703542843
Validation loss: 2.5486519651098574

Epoch: 6| Step: 1
Training loss: 2.821660530667995
Validation loss: 2.5214039870987097

Epoch: 6| Step: 2
Training loss: 2.8786895960285825
Validation loss: 2.496493267365981

Epoch: 6| Step: 3
Training loss: 2.930868414339069
Validation loss: 2.4826428450338165

Epoch: 6| Step: 4
Training loss: 3.066455388738445
Validation loss: 2.477868742834753

Epoch: 6| Step: 5
Training loss: 2.6310163308089516
Validation loss: 2.4774021635009986

Epoch: 6| Step: 6
Training loss: 3.6234866962654486
Validation loss: 2.479669085875057

Epoch: 6| Step: 7
Training loss: 2.8938850783259547
Validation loss: 2.47936507503351

Epoch: 6| Step: 8
Training loss: 3.248399780700323
Validation loss: 2.4784761933802244

Epoch: 6| Step: 9
Training loss: 2.6512792414626825
Validation loss: 2.47246983116087

Epoch: 6| Step: 10
Training loss: 2.6234256019345197
Validation loss: 2.476021274275928

Epoch: 6| Step: 11
Training loss: 2.6663173406996994
Validation loss: 2.4829441654945734

Epoch: 6| Step: 12
Training loss: 2.7053146754649693
Validation loss: 2.474080881776255

Epoch: 6| Step: 13
Training loss: 2.5904425249613574
Validation loss: 2.476990007321661

Epoch: 76| Step: 0
Training loss: 2.3862923648644463
Validation loss: 2.473663576417357

Epoch: 6| Step: 1
Training loss: 2.3186275645215177
Validation loss: 2.478362557877006

Epoch: 6| Step: 2
Training loss: 3.044776389394396
Validation loss: 2.4927038495631817

Epoch: 6| Step: 3
Training loss: 3.516770104307749
Validation loss: 2.513134165945746

Epoch: 6| Step: 4
Training loss: 2.7661590922535937
Validation loss: 2.529425664085432

Epoch: 6| Step: 5
Training loss: 2.897873815955112
Validation loss: 2.5345107091771064

Epoch: 6| Step: 6
Training loss: 2.972217502372377
Validation loss: 2.497642856885711

Epoch: 6| Step: 7
Training loss: 2.980754793572309
Validation loss: 2.4831302697994895

Epoch: 6| Step: 8
Training loss: 2.6367099790074024
Validation loss: 2.4796433766453343

Epoch: 6| Step: 9
Training loss: 2.8983277662537077
Validation loss: 2.4727801652967885

Epoch: 6| Step: 10
Training loss: 3.1566436824210227
Validation loss: 2.4795394669558086

Epoch: 6| Step: 11
Training loss: 2.8256275256474073
Validation loss: 2.4776271680700956

Epoch: 6| Step: 12
Training loss: 2.670179665767689
Validation loss: 2.4871699458396566

Epoch: 6| Step: 13
Training loss: 2.5559668647636125
Validation loss: 2.4885095116946063

Epoch: 77| Step: 0
Training loss: 2.658103744812921
Validation loss: 2.4878741940896454

Epoch: 6| Step: 1
Training loss: 3.0026995910321057
Validation loss: 2.4872246716691766

Epoch: 6| Step: 2
Training loss: 2.9426119538224556
Validation loss: 2.4816485465237705

Epoch: 6| Step: 3
Training loss: 2.856184717012419
Validation loss: 2.4780028387846644

Epoch: 6| Step: 4
Training loss: 2.9809325171110173
Validation loss: 2.4766599315668274

Epoch: 6| Step: 5
Training loss: 2.957652340445604
Validation loss: 2.4792034683811974

Epoch: 6| Step: 6
Training loss: 2.3048960445901217
Validation loss: 2.479034387898212

Epoch: 6| Step: 7
Training loss: 3.0148085047195607
Validation loss: 2.483835146332327

Epoch: 6| Step: 8
Training loss: 2.470092504985353
Validation loss: 2.5219817078537186

Epoch: 6| Step: 9
Training loss: 2.99659344859168
Validation loss: 2.5515926687170167

Epoch: 6| Step: 10
Training loss: 2.7016673485270477
Validation loss: 2.5534405921221954

Epoch: 6| Step: 11
Training loss: 2.8626140321898164
Validation loss: 2.5724453799391673

Epoch: 6| Step: 12
Training loss: 3.169219009030027
Validation loss: 2.5949572972966126

Epoch: 6| Step: 13
Training loss: 2.954136427996731
Validation loss: 2.598008317425514

Epoch: 78| Step: 0
Training loss: 2.8414266967876847
Validation loss: 2.541117696786627

Epoch: 6| Step: 1
Training loss: 2.822076219585139
Validation loss: 2.5085566840053124

Epoch: 6| Step: 2
Training loss: 2.894239485601046
Validation loss: 2.4789922860926286

Epoch: 6| Step: 3
Training loss: 3.0600264544371947
Validation loss: 2.4770450491349396

Epoch: 6| Step: 4
Training loss: 2.6956017380472908
Validation loss: 2.4864476033621012

Epoch: 6| Step: 5
Training loss: 2.771043716895283
Validation loss: 2.4954269648093526

Epoch: 6| Step: 6
Training loss: 3.2488970719057706
Validation loss: 2.529461018692837

Epoch: 6| Step: 7
Training loss: 2.8315110985149228
Validation loss: 2.5405481194757713

Epoch: 6| Step: 8
Training loss: 2.7594418129873106
Validation loss: 2.5500333705007847

Epoch: 6| Step: 9
Training loss: 2.842914668211127
Validation loss: 2.537871413117844

Epoch: 6| Step: 10
Training loss: 2.5522845338152904
Validation loss: 2.5319963319872367

Epoch: 6| Step: 11
Training loss: 2.60545255321404
Validation loss: 2.528362389871808

Epoch: 6| Step: 12
Training loss: 3.0625962222806224
Validation loss: 2.532963928921565

Epoch: 6| Step: 13
Training loss: 3.5259601502830797
Validation loss: 2.514299269990951

Epoch: 79| Step: 0
Training loss: 3.180396148670097
Validation loss: 2.4946279284273922

Epoch: 6| Step: 1
Training loss: 2.5981432006580176
Validation loss: 2.4862469857750495

Epoch: 6| Step: 2
Training loss: 2.6190717149014136
Validation loss: 2.4941594739228963

Epoch: 6| Step: 3
Training loss: 2.7891221667834265
Validation loss: 2.521858054516089

Epoch: 6| Step: 4
Training loss: 2.4046041631603394
Validation loss: 2.526245124893659

Epoch: 6| Step: 5
Training loss: 2.843695671484817
Validation loss: 2.5540309148932616

Epoch: 6| Step: 6
Training loss: 2.9904053163908784
Validation loss: 2.5316698320433235

Epoch: 6| Step: 7
Training loss: 2.787836398366593
Validation loss: 2.511683209954573

Epoch: 6| Step: 8
Training loss: 2.859756360913744
Validation loss: 2.5278626380795735

Epoch: 6| Step: 9
Training loss: 2.7546780417848473
Validation loss: 2.5014427134294093

Epoch: 6| Step: 10
Training loss: 3.173156028597354
Validation loss: 2.4975270068512905

Epoch: 6| Step: 11
Training loss: 2.5271656380438094
Validation loss: 2.509535249294235

Epoch: 6| Step: 12
Training loss: 3.369374567285509
Validation loss: 2.4919016612401492

Epoch: 6| Step: 13
Training loss: 2.5385279635650573
Validation loss: 2.495482711518657

Epoch: 80| Step: 0
Training loss: 2.6503040859006535
Validation loss: 2.492977388893845

Epoch: 6| Step: 1
Training loss: 2.2119321708695843
Validation loss: 2.4835082389443355

Epoch: 6| Step: 2
Training loss: 2.365679068306526
Validation loss: 2.4911841011612617

Epoch: 6| Step: 3
Training loss: 2.432633848987
Validation loss: 2.5031485225091563

Epoch: 6| Step: 4
Training loss: 2.8029390373337195
Validation loss: 2.514702885443788

Epoch: 6| Step: 5
Training loss: 3.037381293092605
Validation loss: 2.5215219912825675

Epoch: 6| Step: 6
Training loss: 2.7789902668741657
Validation loss: 2.518727893773558

Epoch: 6| Step: 7
Training loss: 2.606284315583161
Validation loss: 2.5091997690660404

Epoch: 6| Step: 8
Training loss: 3.3471420053355723
Validation loss: 2.5074754581185488

Epoch: 6| Step: 9
Training loss: 2.865331064372749
Validation loss: 2.4963527243848143

Epoch: 6| Step: 10
Training loss: 3.1300406429589227
Validation loss: 2.4826815237907924

Epoch: 6| Step: 11
Training loss: 2.5490762757853536
Validation loss: 2.479568392712654

Epoch: 6| Step: 12
Training loss: 3.310464629555434
Validation loss: 2.4808204603714947

Epoch: 6| Step: 13
Training loss: 3.336245949129209
Validation loss: 2.4872045930965716

Epoch: 81| Step: 0
Training loss: 3.1371160994239036
Validation loss: 2.486988257840525

Epoch: 6| Step: 1
Training loss: 2.5914314662107856
Validation loss: 2.4760195824527305

Epoch: 6| Step: 2
Training loss: 2.6907580831226072
Validation loss: 2.4900177861317396

Epoch: 6| Step: 3
Training loss: 3.2643745620145874
Validation loss: 2.4891965317351095

Epoch: 6| Step: 4
Training loss: 2.9308767117639984
Validation loss: 2.4876645991019233

Epoch: 6| Step: 5
Training loss: 2.6279774083483027
Validation loss: 2.4780378790570383

Epoch: 6| Step: 6
Training loss: 2.562542798685082
Validation loss: 2.4839427652224884

Epoch: 6| Step: 7
Training loss: 3.059573897071392
Validation loss: 2.48018234003708

Epoch: 6| Step: 8
Training loss: 3.0236152379826438
Validation loss: 2.4780564438898303

Epoch: 6| Step: 9
Training loss: 3.098152342201048
Validation loss: 2.4776786963943365

Epoch: 6| Step: 10
Training loss: 2.777727618294412
Validation loss: 2.4742609656073853

Epoch: 6| Step: 11
Training loss: 2.2597584505882224
Validation loss: 2.4737788485760808

Epoch: 6| Step: 12
Training loss: 2.7249275267876607
Validation loss: 2.4762142080502643

Epoch: 6| Step: 13
Training loss: 2.3776334918840027
Validation loss: 2.467959145306782

Epoch: 82| Step: 0
Training loss: 2.9949239065855733
Validation loss: 2.4752454054519912

Epoch: 6| Step: 1
Training loss: 3.023897042454365
Validation loss: 2.4735802474344504

Epoch: 6| Step: 2
Training loss: 3.303815866507266
Validation loss: 2.4775290243421506

Epoch: 6| Step: 3
Training loss: 2.3684270150405164
Validation loss: 2.473951753479131

Epoch: 6| Step: 4
Training loss: 2.4130750692162173
Validation loss: 2.476017508569963

Epoch: 6| Step: 5
Training loss: 2.871305662885231
Validation loss: 2.4824131144415698

Epoch: 6| Step: 6
Training loss: 2.5323994228503977
Validation loss: 2.4730630263442395

Epoch: 6| Step: 7
Training loss: 2.5218521665463562
Validation loss: 2.4702038812233234

Epoch: 6| Step: 8
Training loss: 1.8687170300079081
Validation loss: 2.4723752829991743

Epoch: 6| Step: 9
Training loss: 3.2489463858931567
Validation loss: 2.4718170185558375

Epoch: 6| Step: 10
Training loss: 3.029324893588188
Validation loss: 2.4708440447730786

Epoch: 6| Step: 11
Training loss: 2.5809750611416904
Validation loss: 2.472481607952087

Epoch: 6| Step: 12
Training loss: 2.8434676145423516
Validation loss: 2.4737372428576996

Epoch: 6| Step: 13
Training loss: 3.658182269361266
Validation loss: 2.4694972020587107

Epoch: 83| Step: 0
Training loss: 2.4665894530643446
Validation loss: 2.471638272560576

Epoch: 6| Step: 1
Training loss: 1.8724014076995286
Validation loss: 2.470011588020405

Epoch: 6| Step: 2
Training loss: 2.625966212151878
Validation loss: 2.481577071566983

Epoch: 6| Step: 3
Training loss: 2.7690439589163502
Validation loss: 2.4822984756111195

Epoch: 6| Step: 4
Training loss: 3.3313018966554435
Validation loss: 2.4809218477558814

Epoch: 6| Step: 5
Training loss: 3.507178438309709
Validation loss: 2.4927080549234444

Epoch: 6| Step: 6
Training loss: 2.824473600377985
Validation loss: 2.5205485882203678

Epoch: 6| Step: 7
Training loss: 2.143548903750739
Validation loss: 2.5373685970984132

Epoch: 6| Step: 8
Training loss: 2.7953720743175694
Validation loss: 2.5452401793809463

Epoch: 6| Step: 9
Training loss: 3.266926337320976
Validation loss: 2.5731088025938473

Epoch: 6| Step: 10
Training loss: 2.859931266332205
Validation loss: 2.5206513006484426

Epoch: 6| Step: 11
Training loss: 2.7341667749958507
Validation loss: 2.492051444279461

Epoch: 6| Step: 12
Training loss: 3.2997455845642953
Validation loss: 2.4873920658213624

Epoch: 6| Step: 13
Training loss: 1.8306957330449907
Validation loss: 2.4671154371712785

Epoch: 84| Step: 0
Training loss: 2.8311959975189263
Validation loss: 2.470645942368352

Epoch: 6| Step: 1
Training loss: 2.859367995957098
Validation loss: 2.462429527597312

Epoch: 6| Step: 2
Training loss: 2.784885473584626
Validation loss: 2.479413927514753

Epoch: 6| Step: 3
Training loss: 2.7055653928525216
Validation loss: 2.4822277206390013

Epoch: 6| Step: 4
Training loss: 2.3974676998377134
Validation loss: 2.509494232306575

Epoch: 6| Step: 5
Training loss: 2.7154497307339023
Validation loss: 2.504119438046932

Epoch: 6| Step: 6
Training loss: 3.391181443080718
Validation loss: 2.513478655616226

Epoch: 6| Step: 7
Training loss: 2.8833824359336355
Validation loss: 2.4988765314884187

Epoch: 6| Step: 8
Training loss: 3.0390772488194493
Validation loss: 2.4930793698304474

Epoch: 6| Step: 9
Training loss: 3.2223749581308154
Validation loss: 2.489920745473248

Epoch: 6| Step: 10
Training loss: 1.9709407787861246
Validation loss: 2.4793438708938496

Epoch: 6| Step: 11
Training loss: 2.7883861587211527
Validation loss: 2.465967969361053

Epoch: 6| Step: 12
Training loss: 2.5949689459734206
Validation loss: 2.458454473926715

Epoch: 6| Step: 13
Training loss: 2.883638919961258
Validation loss: 2.4621868670075733

Epoch: 85| Step: 0
Training loss: 3.03320045250003
Validation loss: 2.4664957895543314

Epoch: 6| Step: 1
Training loss: 2.8237716299767794
Validation loss: 2.463442445944108

Epoch: 6| Step: 2
Training loss: 2.4594886995859757
Validation loss: 2.468844341211238

Epoch: 6| Step: 3
Training loss: 2.765712068555725
Validation loss: 2.470704102433904

Epoch: 6| Step: 4
Training loss: 2.90649495066728
Validation loss: 2.4655096310652636

Epoch: 6| Step: 5
Training loss: 3.002976847952848
Validation loss: 2.4722591272340027

Epoch: 6| Step: 6
Training loss: 3.0570178106935297
Validation loss: 2.4674662685315187

Epoch: 6| Step: 7
Training loss: 3.037985956698237
Validation loss: 2.4634207498759015

Epoch: 6| Step: 8
Training loss: 2.8847338881971227
Validation loss: 2.4714720752875965

Epoch: 6| Step: 9
Training loss: 2.884427411728413
Validation loss: 2.467680379928372

Epoch: 6| Step: 10
Training loss: 2.7370543513450363
Validation loss: 2.4824178029913626

Epoch: 6| Step: 11
Training loss: 2.4789847192327947
Validation loss: 2.490364156836143

Epoch: 6| Step: 12
Training loss: 2.779229962849668
Validation loss: 2.4951054826138455

Epoch: 6| Step: 13
Training loss: 1.6831899632248957
Validation loss: 2.501681309027998

Epoch: 86| Step: 0
Training loss: 3.2589206045990253
Validation loss: 2.4985216045593495

Epoch: 6| Step: 1
Training loss: 3.317014101575215
Validation loss: 2.5075048498754304

Epoch: 6| Step: 2
Training loss: 2.7643648714297866
Validation loss: 2.513278424943891

Epoch: 6| Step: 3
Training loss: 2.991872267888186
Validation loss: 2.5145640315795985

Epoch: 6| Step: 4
Training loss: 2.5370772361922262
Validation loss: 2.5077779759406864

Epoch: 6| Step: 5
Training loss: 3.056485868686213
Validation loss: 2.4878964353156174

Epoch: 6| Step: 6
Training loss: 2.3502952227916696
Validation loss: 2.472772366375816

Epoch: 6| Step: 7
Training loss: 2.5125829654489342
Validation loss: 2.4740646812667895

Epoch: 6| Step: 8
Training loss: 2.4100580179979003
Validation loss: 2.463664479877712

Epoch: 6| Step: 9
Training loss: 3.202764723450553
Validation loss: 2.4636227860751716

Epoch: 6| Step: 10
Training loss: 2.9353988924880414
Validation loss: 2.4574535287473585

Epoch: 6| Step: 11
Training loss: 2.168410137711404
Validation loss: 2.4685329613402947

Epoch: 6| Step: 12
Training loss: 2.4087681660464524
Validation loss: 2.4531624574755737

Epoch: 6| Step: 13
Training loss: 3.0512030745808354
Validation loss: 2.466428167228276

Epoch: 87| Step: 0
Training loss: 2.55754689938975
Validation loss: 2.4586461231289305

Epoch: 6| Step: 1
Training loss: 3.1616993308973234
Validation loss: 2.470991127536764

Epoch: 6| Step: 2
Training loss: 2.652587429982271
Validation loss: 2.468323637143905

Epoch: 6| Step: 3
Training loss: 2.8544945261707833
Validation loss: 2.469692143390686

Epoch: 6| Step: 4
Training loss: 2.2250435985622685
Validation loss: 2.4601314497485705

Epoch: 6| Step: 5
Training loss: 1.7407523774636604
Validation loss: 2.4591280669521307

Epoch: 6| Step: 6
Training loss: 2.7812018229565956
Validation loss: 2.467867802019189

Epoch: 6| Step: 7
Training loss: 2.879295457387556
Validation loss: 2.4670836158497886

Epoch: 6| Step: 8
Training loss: 2.659529781656032
Validation loss: 2.4726282501229453

Epoch: 6| Step: 9
Training loss: 3.0685183497864363
Validation loss: 2.479070813780307

Epoch: 6| Step: 10
Training loss: 3.1405478700494704
Validation loss: 2.512462804497866

Epoch: 6| Step: 11
Training loss: 3.0799225336711844
Validation loss: 2.532365576162141

Epoch: 6| Step: 12
Training loss: 2.8336194024871895
Validation loss: 2.5196871404743755

Epoch: 6| Step: 13
Training loss: 3.3741805883264697
Validation loss: 2.5277690593937696

Epoch: 88| Step: 0
Training loss: 2.754008406239121
Validation loss: 2.5146945778452374

Epoch: 6| Step: 1
Training loss: 2.0110209319525296
Validation loss: 2.469972907024827

Epoch: 6| Step: 2
Training loss: 3.080846832083476
Validation loss: 2.468982314361453

Epoch: 6| Step: 3
Training loss: 3.0295054341185796
Validation loss: 2.4806404062771183

Epoch: 6| Step: 4
Training loss: 2.59598830746808
Validation loss: 2.48627099652214

Epoch: 6| Step: 5
Training loss: 2.76054303341851
Validation loss: 2.5033329219999927

Epoch: 6| Step: 6
Training loss: 2.8160918294390713
Validation loss: 2.486823842582665

Epoch: 6| Step: 7
Training loss: 2.811154870390862
Validation loss: 2.476880566918205

Epoch: 6| Step: 8
Training loss: 2.3852537563171654
Validation loss: 2.4683911940413474

Epoch: 6| Step: 9
Training loss: 2.8234786334099917
Validation loss: 2.4681809874113756

Epoch: 6| Step: 10
Training loss: 2.8451631828398356
Validation loss: 2.4590248917052824

Epoch: 6| Step: 11
Training loss: 3.3247491612862516
Validation loss: 2.4554577676188942

Epoch: 6| Step: 12
Training loss: 3.08341424853028
Validation loss: 2.4680627416901504

Epoch: 6| Step: 13
Training loss: 2.6678737550861347
Validation loss: 2.4814898774520056

Epoch: 89| Step: 0
Training loss: 2.1621409123575033
Validation loss: 2.4988781257633765

Epoch: 6| Step: 1
Training loss: 3.0191416421208177
Validation loss: 2.512325114093543

Epoch: 6| Step: 2
Training loss: 2.6522295875306767
Validation loss: 2.5604464989026825

Epoch: 6| Step: 3
Training loss: 2.9239142334514665
Validation loss: 2.5785420358604534

Epoch: 6| Step: 4
Training loss: 2.2566424971525363
Validation loss: 2.560322712684233

Epoch: 6| Step: 5
Training loss: 2.6157568821991966
Validation loss: 2.5455032561082493

Epoch: 6| Step: 6
Training loss: 2.2589563554361516
Validation loss: 2.5111921628515117

Epoch: 6| Step: 7
Training loss: 3.0774671752071603
Validation loss: 2.4882480313061284

Epoch: 6| Step: 8
Training loss: 3.0087559397012416
Validation loss: 2.4778721198164253

Epoch: 6| Step: 9
Training loss: 3.167611550020572
Validation loss: 2.469772430371444

Epoch: 6| Step: 10
Training loss: 2.820477171763748
Validation loss: 2.4603274499312873

Epoch: 6| Step: 11
Training loss: 2.5188600577643423
Validation loss: 2.4528443114702987

Epoch: 6| Step: 12
Training loss: 3.089006891748626
Validation loss: 2.4521032122650284

Epoch: 6| Step: 13
Training loss: 3.5828205599321956
Validation loss: 2.454184035055498

Epoch: 90| Step: 0
Training loss: 2.376153364709877
Validation loss: 2.4538609085584606

Epoch: 6| Step: 1
Training loss: 3.0327978213395745
Validation loss: 2.459285429354255

Epoch: 6| Step: 2
Training loss: 2.820953549894798
Validation loss: 2.458042874982616

Epoch: 6| Step: 3
Training loss: 2.97252840225857
Validation loss: 2.4702214998054868

Epoch: 6| Step: 4
Training loss: 2.8853495529210154
Validation loss: 2.4677741854701942

Epoch: 6| Step: 5
Training loss: 2.431956124424429
Validation loss: 2.4685515031498326

Epoch: 6| Step: 6
Training loss: 2.131741880333183
Validation loss: 2.481374820417065

Epoch: 6| Step: 7
Training loss: 2.914927336374403
Validation loss: 2.4858220398803295

Epoch: 6| Step: 8
Training loss: 3.0796244885304516
Validation loss: 2.4796486866202807

Epoch: 6| Step: 9
Training loss: 2.983061656267395
Validation loss: 2.479806719337773

Epoch: 6| Step: 10
Training loss: 2.7323581778114354
Validation loss: 2.494480731694173

Epoch: 6| Step: 11
Training loss: 2.895191606364082
Validation loss: 2.5003047429232734

Epoch: 6| Step: 12
Training loss: 2.496710043030818
Validation loss: 2.5152556720796575

Epoch: 6| Step: 13
Training loss: 2.943754963151834
Validation loss: 2.523992299357892

Epoch: 91| Step: 0
Training loss: 3.231483383161958
Validation loss: 2.4942564370354146

Epoch: 6| Step: 1
Training loss: 2.607737867088497
Validation loss: 2.4980203768774283

Epoch: 6| Step: 2
Training loss: 3.492081130624512
Validation loss: 2.494139328861503

Epoch: 6| Step: 3
Training loss: 2.5801562081591487
Validation loss: 2.4992464498824267

Epoch: 6| Step: 4
Training loss: 2.682751474813956
Validation loss: 2.5032283601284266

Epoch: 6| Step: 5
Training loss: 2.449446136773194
Validation loss: 2.507527656160968

Epoch: 6| Step: 6
Training loss: 2.775949807045832
Validation loss: 2.5133263509936317

Epoch: 6| Step: 7
Training loss: 2.845037818483022
Validation loss: 2.498708243582957

Epoch: 6| Step: 8
Training loss: 2.785035204296772
Validation loss: 2.4615164470819644

Epoch: 6| Step: 9
Training loss: 2.597181141937005
Validation loss: 2.4555093675614885

Epoch: 6| Step: 10
Training loss: 2.515907792965608
Validation loss: 2.4556050276018

Epoch: 6| Step: 11
Training loss: 3.0904875228128827
Validation loss: 2.467244666091107

Epoch: 6| Step: 12
Training loss: 2.7131106765955995
Validation loss: 2.460746946052586

Epoch: 6| Step: 13
Training loss: 2.441362499607993
Validation loss: 2.4656291803851986

Epoch: 92| Step: 0
Training loss: 2.5104857840197257
Validation loss: 2.4582350036689147

Epoch: 6| Step: 1
Training loss: 2.2607221499516976
Validation loss: 2.4593850339087107

Epoch: 6| Step: 2
Training loss: 2.5636859103505505
Validation loss: 2.4661737325158595

Epoch: 6| Step: 3
Training loss: 2.1865348866730727
Validation loss: 2.4721203880941123

Epoch: 6| Step: 4
Training loss: 3.3591004725219324
Validation loss: 2.478042541745035

Epoch: 6| Step: 5
Training loss: 3.1217912603532243
Validation loss: 2.4830348989320226

Epoch: 6| Step: 6
Training loss: 2.600245053407189
Validation loss: 2.50330981840114

Epoch: 6| Step: 7
Training loss: 3.0396023542938972
Validation loss: 2.5059052168072644

Epoch: 6| Step: 8
Training loss: 3.0739662231495735
Validation loss: 2.5082426430954525

Epoch: 6| Step: 9
Training loss: 2.759118999905522
Validation loss: 2.515106069688509

Epoch: 6| Step: 10
Training loss: 2.749108343354659
Validation loss: 2.5064314172976667

Epoch: 6| Step: 11
Training loss: 2.570700387180866
Validation loss: 2.5060862074860095

Epoch: 6| Step: 12
Training loss: 3.301732105785759
Validation loss: 2.516338848112399

Epoch: 6| Step: 13
Training loss: 2.4774114555603397
Validation loss: 2.474397551963666

Epoch: 93| Step: 0
Training loss: 2.9873543292806555
Validation loss: 2.4682091218709123

Epoch: 6| Step: 1
Training loss: 2.7532544385984576
Validation loss: 2.4559841649761287

Epoch: 6| Step: 2
Training loss: 3.1032201531487726
Validation loss: 2.4492210046289045

Epoch: 6| Step: 3
Training loss: 3.3022301738512643
Validation loss: 2.4491784468497806

Epoch: 6| Step: 4
Training loss: 2.765633793186498
Validation loss: 2.4497445697661053

Epoch: 6| Step: 5
Training loss: 2.1721989232293755
Validation loss: 2.4440000544338356

Epoch: 6| Step: 6
Training loss: 1.7962937451519643
Validation loss: 2.4447091422449887

Epoch: 6| Step: 7
Training loss: 2.696466613472305
Validation loss: 2.4528756036769286

Epoch: 6| Step: 8
Training loss: 3.1572564663755487
Validation loss: 2.4524048897269886

Epoch: 6| Step: 9
Training loss: 2.673182920265917
Validation loss: 2.454054933724616

Epoch: 6| Step: 10
Training loss: 2.572733564978777
Validation loss: 2.4504620920540074

Epoch: 6| Step: 11
Training loss: 2.559421550993446
Validation loss: 2.4573791895059163

Epoch: 6| Step: 12
Training loss: 2.8953614067644904
Validation loss: 2.457361773565955

Epoch: 6| Step: 13
Training loss: 3.1112022973124467
Validation loss: 2.466383928320743

Epoch: 94| Step: 0
Training loss: 2.5686432308088594
Validation loss: 2.47379625049629

Epoch: 6| Step: 1
Training loss: 3.0792742292710362
Validation loss: 2.480650282510248

Epoch: 6| Step: 2
Training loss: 3.0204257207766267
Validation loss: 2.50324928514165

Epoch: 6| Step: 3
Training loss: 2.802945161662045
Validation loss: 2.491609351810124

Epoch: 6| Step: 4
Training loss: 3.0092110689222547
Validation loss: 2.4744334783479505

Epoch: 6| Step: 5
Training loss: 2.554649796047266
Validation loss: 2.47211622134042

Epoch: 6| Step: 6
Training loss: 3.211591742103024
Validation loss: 2.4612604505213467

Epoch: 6| Step: 7
Training loss: 1.8547293705701164
Validation loss: 2.45101695904487

Epoch: 6| Step: 8
Training loss: 3.0770549947629955
Validation loss: 2.4514449902129916

Epoch: 6| Step: 9
Training loss: 2.6610026308467436
Validation loss: 2.445070430543872

Epoch: 6| Step: 10
Training loss: 1.9283236730471516
Validation loss: 2.4474511134316255

Epoch: 6| Step: 11
Training loss: 2.980989463186085
Validation loss: 2.447996580084516

Epoch: 6| Step: 12
Training loss: 2.7702866399755375
Validation loss: 2.4485806767406437

Epoch: 6| Step: 13
Training loss: 2.8261939774857043
Validation loss: 2.445938898712393

Epoch: 95| Step: 0
Training loss: 2.8534908933305383
Validation loss: 2.4480543347049264

Epoch: 6| Step: 1
Training loss: 2.8876890376580455
Validation loss: 2.4548724218336946

Epoch: 6| Step: 2
Training loss: 2.9274786595088753
Validation loss: 2.4634204928271335

Epoch: 6| Step: 3
Training loss: 3.203598359649844
Validation loss: 2.4684527846369844

Epoch: 6| Step: 4
Training loss: 2.7932871390311202
Validation loss: 2.4816407894190644

Epoch: 6| Step: 5
Training loss: 2.2382818891114926
Validation loss: 2.500582894698161

Epoch: 6| Step: 6
Training loss: 3.0678921932094148
Validation loss: 2.5124336207377995

Epoch: 6| Step: 7
Training loss: 2.331959683392022
Validation loss: 2.525818348028619

Epoch: 6| Step: 8
Training loss: 2.4366169821722203
Validation loss: 2.5310430539619166

Epoch: 6| Step: 9
Training loss: 3.16934117928982
Validation loss: 2.5040520726081574

Epoch: 6| Step: 10
Training loss: 2.8225163437511194
Validation loss: 2.4880404234831883

Epoch: 6| Step: 11
Training loss: 1.9285517759684188
Validation loss: 2.5005736318434515

Epoch: 6| Step: 12
Training loss: 2.693001726843347
Validation loss: 2.5184347595595957

Epoch: 6| Step: 13
Training loss: 3.0777366122060816
Validation loss: 2.55208391227657

Epoch: 96| Step: 0
Training loss: 2.0979526530578942
Validation loss: 2.574465221160724

Epoch: 6| Step: 1
Training loss: 2.89599753447159
Validation loss: 2.6034136658499927

Epoch: 6| Step: 2
Training loss: 2.445933595212912
Validation loss: 2.6022295431888542

Epoch: 6| Step: 3
Training loss: 2.763587675395809
Validation loss: 2.6132337846477776

Epoch: 6| Step: 4
Training loss: 2.294224877534085
Validation loss: 2.575983786488866

Epoch: 6| Step: 5
Training loss: 2.9244096339523504
Validation loss: 2.528191566480752

Epoch: 6| Step: 6
Training loss: 3.3503094089018073
Validation loss: 2.4941257866921953

Epoch: 6| Step: 7
Training loss: 2.156337349269585
Validation loss: 2.465050896590042

Epoch: 6| Step: 8
Training loss: 2.798822843516039
Validation loss: 2.472238791273777

Epoch: 6| Step: 9
Training loss: 3.1519701049665017
Validation loss: 2.4692161102387438

Epoch: 6| Step: 10
Training loss: 3.5071194310275793
Validation loss: 2.4682261029347132

Epoch: 6| Step: 11
Training loss: 2.635117243668376
Validation loss: 2.4689980721438816

Epoch: 6| Step: 12
Training loss: 2.899720763870696
Validation loss: 2.466083485844497

Epoch: 6| Step: 13
Training loss: 2.9759538483784023
Validation loss: 2.455609601341892

Epoch: 97| Step: 0
Training loss: 3.0046585787820934
Validation loss: 2.4598773871651374

Epoch: 6| Step: 1
Training loss: 2.5922868577380695
Validation loss: 2.449773872442391

Epoch: 6| Step: 2
Training loss: 3.2123509472656373
Validation loss: 2.4547969486012837

Epoch: 6| Step: 3
Training loss: 2.7512385440295004
Validation loss: 2.480596450801236

Epoch: 6| Step: 4
Training loss: 2.494786739676328
Validation loss: 2.5054836992107976

Epoch: 6| Step: 5
Training loss: 2.927717762315276
Validation loss: 2.5484573196999785

Epoch: 6| Step: 6
Training loss: 1.7923881571418694
Validation loss: 2.5992253216307173

Epoch: 6| Step: 7
Training loss: 3.376048737522164
Validation loss: 2.609099081433051

Epoch: 6| Step: 8
Training loss: 3.3823131871143364
Validation loss: 2.584291904160746

Epoch: 6| Step: 9
Training loss: 2.534547706298007
Validation loss: 2.5209184556130495

Epoch: 6| Step: 10
Training loss: 2.7921876468669082
Validation loss: 2.5028514157088835

Epoch: 6| Step: 11
Training loss: 2.7515264956075334
Validation loss: 2.492578260393006

Epoch: 6| Step: 12
Training loss: 2.5238819026250887
Validation loss: 2.4813685026764665

Epoch: 6| Step: 13
Training loss: 2.7359486438604876
Validation loss: 2.481077042596846

Epoch: 98| Step: 0
Training loss: 2.7360998326653805
Validation loss: 2.481593930164648

Epoch: 6| Step: 1
Training loss: 2.4910386645403286
Validation loss: 2.510841890851321

Epoch: 6| Step: 2
Training loss: 2.7919459037240117
Validation loss: 2.5443156347762637

Epoch: 6| Step: 3
Training loss: 2.4415310514976554
Validation loss: 2.562052050559254

Epoch: 6| Step: 4
Training loss: 2.982388779132429
Validation loss: 2.562044610938426

Epoch: 6| Step: 5
Training loss: 2.8253610498395925
Validation loss: 2.540770969153879

Epoch: 6| Step: 6
Training loss: 3.023790757786491
Validation loss: 2.507855545025672

Epoch: 6| Step: 7
Training loss: 3.0503421716582513
Validation loss: 2.5181066299981274

Epoch: 6| Step: 8
Training loss: 2.6394173834665686
Validation loss: 2.5137647332488657

Epoch: 6| Step: 9
Training loss: 2.259015670208662
Validation loss: 2.510669152446179

Epoch: 6| Step: 10
Training loss: 3.0581523630370864
Validation loss: 2.5487020705685257

Epoch: 6| Step: 11
Training loss: 2.9716310675758906
Validation loss: 2.5367765575500267

Epoch: 6| Step: 12
Training loss: 2.998057690330655
Validation loss: 2.557530605607891

Epoch: 6| Step: 13
Training loss: 2.7295084343769593
Validation loss: 2.5381427239254277

Epoch: 99| Step: 0
Training loss: 2.378831583489298
Validation loss: 2.507503166003296

Epoch: 6| Step: 1
Training loss: 3.0526984487849216
Validation loss: 2.4801814118191485

Epoch: 6| Step: 2
Training loss: 2.4851723596985518
Validation loss: 2.463393569161638

Epoch: 6| Step: 3
Training loss: 2.5784009381213537
Validation loss: 2.455280576209168

Epoch: 6| Step: 4
Training loss: 3.056571360037895
Validation loss: 2.4531009835663333

Epoch: 6| Step: 5
Training loss: 3.2700076832812277
Validation loss: 2.4503348860606393

Epoch: 6| Step: 6
Training loss: 2.6792320109022674
Validation loss: 2.4451346132356395

Epoch: 6| Step: 7
Training loss: 2.7604009567869348
Validation loss: 2.444158804084512

Epoch: 6| Step: 8
Training loss: 2.4478234023055077
Validation loss: 2.4396432520573454

Epoch: 6| Step: 9
Training loss: 2.8893616261008725
Validation loss: 2.444279358863434

Epoch: 6| Step: 10
Training loss: 2.4775351169841957
Validation loss: 2.435555305732474

Epoch: 6| Step: 11
Training loss: 2.973987817478946
Validation loss: 2.4254395926621912

Epoch: 6| Step: 12
Training loss: 2.953115150394867
Validation loss: 2.4320872357647816

Epoch: 6| Step: 13
Training loss: 2.301020922264395
Validation loss: 2.436247978148367

Epoch: 100| Step: 0
Training loss: 2.193041512614343
Validation loss: 2.456209826376378

Epoch: 6| Step: 1
Training loss: 2.972521825249886
Validation loss: 2.4573632247251247

Epoch: 6| Step: 2
Training loss: 3.0998425843664323
Validation loss: 2.4589519386354906

Epoch: 6| Step: 3
Training loss: 3.215390720860059
Validation loss: 2.4737267985694307

Epoch: 6| Step: 4
Training loss: 2.662960506964309
Validation loss: 2.4547158919218344

Epoch: 6| Step: 5
Training loss: 2.8168032468227233
Validation loss: 2.458554766988713

Epoch: 6| Step: 6
Training loss: 2.494480907435171
Validation loss: 2.4649906395825947

Epoch: 6| Step: 7
Training loss: 2.631329670694355
Validation loss: 2.4741377270114326

Epoch: 6| Step: 8
Training loss: 2.571370379606927
Validation loss: 2.47504326563068

Epoch: 6| Step: 9
Training loss: 2.6715723948307173
Validation loss: 2.4828686090693517

Epoch: 6| Step: 10
Training loss: 2.612834533007209
Validation loss: 2.483753520026433

Epoch: 6| Step: 11
Training loss: 2.8764571767875458
Validation loss: 2.4912465761390634

Epoch: 6| Step: 12
Training loss: 2.7476807264290457
Validation loss: 2.4996190796106963

Epoch: 6| Step: 13
Training loss: 2.6843208316404645
Validation loss: 2.5089787551396405

Epoch: 101| Step: 0
Training loss: 2.2275870124442396
Validation loss: 2.4872955514450403

Epoch: 6| Step: 1
Training loss: 2.292067914572386
Validation loss: 2.490073266830826

Epoch: 6| Step: 2
Training loss: 3.1274628661563693
Validation loss: 2.467082841691766

Epoch: 6| Step: 3
Training loss: 2.539281841487434
Validation loss: 2.468227751283025

Epoch: 6| Step: 4
Training loss: 3.2201135210201572
Validation loss: 2.4607195055604634

Epoch: 6| Step: 5
Training loss: 2.451922273707654
Validation loss: 2.4633403276860406

Epoch: 6| Step: 6
Training loss: 2.845762106887036
Validation loss: 2.455525407037033

Epoch: 6| Step: 7
Training loss: 2.7523498898907888
Validation loss: 2.4699401572367563

Epoch: 6| Step: 8
Training loss: 2.682130461851565
Validation loss: 2.4648958523778104

Epoch: 6| Step: 9
Training loss: 2.2889012615194546
Validation loss: 2.456582841655096

Epoch: 6| Step: 10
Training loss: 2.8674422730386366
Validation loss: 2.452045929394397

Epoch: 6| Step: 11
Training loss: 3.0020084016137223
Validation loss: 2.4520901405133415

Epoch: 6| Step: 12
Training loss: 3.1909137471878157
Validation loss: 2.458269109733472

Epoch: 6| Step: 13
Training loss: 2.4648054455472574
Validation loss: 2.464277294511168

Epoch: 102| Step: 0
Training loss: 2.4942708171898382
Validation loss: 2.4528494192134533

Epoch: 6| Step: 1
Training loss: 2.8458654898022435
Validation loss: 2.447585270184247

Epoch: 6| Step: 2
Training loss: 2.4838590266080924
Validation loss: 2.462101929265904

Epoch: 6| Step: 3
Training loss: 3.1189142096028855
Validation loss: 2.4575040655036027

Epoch: 6| Step: 4
Training loss: 2.920211399995984
Validation loss: 2.4458689041710957

Epoch: 6| Step: 5
Training loss: 3.151762538872564
Validation loss: 2.4475930870393916

Epoch: 6| Step: 6
Training loss: 2.6298887052303552
Validation loss: 2.4449796576246845

Epoch: 6| Step: 7
Training loss: 1.9736772670958338
Validation loss: 2.4424742392711614

Epoch: 6| Step: 8
Training loss: 2.7861322990601525
Validation loss: 2.4503186054515336

Epoch: 6| Step: 9
Training loss: 2.4364473074905058
Validation loss: 2.4494280772692214

Epoch: 6| Step: 10
Training loss: 2.2564563308165484
Validation loss: 2.4455347988518183

Epoch: 6| Step: 11
Training loss: 3.14761879549066
Validation loss: 2.4453651228346263

Epoch: 6| Step: 12
Training loss: 2.9652702416813836
Validation loss: 2.457817347982103

Epoch: 6| Step: 13
Training loss: 2.494746123490847
Validation loss: 2.4359328041188473

Epoch: 103| Step: 0
Training loss: 2.798195639019637
Validation loss: 2.444991363413505

Epoch: 6| Step: 1
Training loss: 3.3760125795826057
Validation loss: 2.4486994915715377

Epoch: 6| Step: 2
Training loss: 2.8066143759374045
Validation loss: 2.4462632026244613

Epoch: 6| Step: 3
Training loss: 2.3354648890239753
Validation loss: 2.443911764582055

Epoch: 6| Step: 4
Training loss: 2.345129598846977
Validation loss: 2.442570722061172

Epoch: 6| Step: 5
Training loss: 2.65298278930695
Validation loss: 2.4417006742410696

Epoch: 6| Step: 6
Training loss: 2.3024096595694075
Validation loss: 2.458459746244462

Epoch: 6| Step: 7
Training loss: 2.8997041551366745
Validation loss: 2.450260486739037

Epoch: 6| Step: 8
Training loss: 3.1261780616387305
Validation loss: 2.458919446585924

Epoch: 6| Step: 9
Training loss: 2.5083717364373963
Validation loss: 2.4588387218194563

Epoch: 6| Step: 10
Training loss: 2.80212761561538
Validation loss: 2.485670906823763

Epoch: 6| Step: 11
Training loss: 2.3071001258952246
Validation loss: 2.520180893294685

Epoch: 6| Step: 12
Training loss: 2.810445840701586
Validation loss: 2.5422051469732008

Epoch: 6| Step: 13
Training loss: 2.5106673583753825
Validation loss: 2.5651208504212906

Epoch: 104| Step: 0
Training loss: 2.416498331806184
Validation loss: 2.548133315289813

Epoch: 6| Step: 1
Training loss: 2.498741882372099
Validation loss: 2.529391904296796

Epoch: 6| Step: 2
Training loss: 3.146999892301167
Validation loss: 2.5334760994290146

Epoch: 6| Step: 3
Training loss: 3.018451058254326
Validation loss: 2.513171117667991

Epoch: 6| Step: 4
Training loss: 2.659090116955714
Validation loss: 2.482022866965855

Epoch: 6| Step: 5
Training loss: 2.901761434264836
Validation loss: 2.4676152408646983

Epoch: 6| Step: 6
Training loss: 2.384463579324857
Validation loss: 2.464693811319199

Epoch: 6| Step: 7
Training loss: 2.486808209093966
Validation loss: 2.4611256048501553

Epoch: 6| Step: 8
Training loss: 2.945989637171485
Validation loss: 2.4698461661614712

Epoch: 6| Step: 9
Training loss: 2.2244367122208772
Validation loss: 2.4466581154686975

Epoch: 6| Step: 10
Training loss: 2.8924589370806553
Validation loss: 2.450551897159611

Epoch: 6| Step: 11
Training loss: 2.8417770752102336
Validation loss: 2.453756541236621

Epoch: 6| Step: 12
Training loss: 2.5543453442387696
Validation loss: 2.4584387027884866

Epoch: 6| Step: 13
Training loss: 3.041436138736229
Validation loss: 2.4751221506191126

Epoch: 105| Step: 0
Training loss: 2.1680129587975623
Validation loss: 2.4914304581462052

Epoch: 6| Step: 1
Training loss: 2.4208379678687306
Validation loss: 2.5155490259198383

Epoch: 6| Step: 2
Training loss: 2.5644089636156164
Validation loss: 2.481843191398601

Epoch: 6| Step: 3
Training loss: 2.71118848886531
Validation loss: 2.498495917965544

Epoch: 6| Step: 4
Training loss: 3.049441621040527
Validation loss: 2.5072876097863266

Epoch: 6| Step: 5
Training loss: 3.233089173002492
Validation loss: 2.462268841774512

Epoch: 6| Step: 6
Training loss: 2.220181285570144
Validation loss: 2.4651687647266796

Epoch: 6| Step: 7
Training loss: 2.275599444716532
Validation loss: 2.461065176734503

Epoch: 6| Step: 8
Training loss: 2.907986194110825
Validation loss: 2.455950761005916

Epoch: 6| Step: 9
Training loss: 2.6324180058446487
Validation loss: 2.457716382800813

Epoch: 6| Step: 10
Training loss: 3.3088511397263196
Validation loss: 2.468447053846614

Epoch: 6| Step: 11
Training loss: 2.692966136482903
Validation loss: 2.4680466289217526

Epoch: 6| Step: 12
Training loss: 2.5186778434470427
Validation loss: 2.4720174553996883

Epoch: 6| Step: 13
Training loss: 3.072469870634541
Validation loss: 2.4629408305662635

Epoch: 106| Step: 0
Training loss: 2.736108023635835
Validation loss: 2.448678372613461

Epoch: 6| Step: 1
Training loss: 2.5311776610033716
Validation loss: 2.4514520642946565

Epoch: 6| Step: 2
Training loss: 2.908853656674269
Validation loss: 2.4481785637841127

Epoch: 6| Step: 3
Training loss: 3.108932540313824
Validation loss: 2.4464860888824393

Epoch: 6| Step: 4
Training loss: 2.7930820255383653
Validation loss: 2.447773472130785

Epoch: 6| Step: 5
Training loss: 2.222024891622062
Validation loss: 2.4400244031210647

Epoch: 6| Step: 6
Training loss: 3.275010197747348
Validation loss: 2.4295415423943414

Epoch: 6| Step: 7
Training loss: 2.711276777952151
Validation loss: 2.437802400386336

Epoch: 6| Step: 8
Training loss: 2.7401840847020114
Validation loss: 2.4357045083958715

Epoch: 6| Step: 9
Training loss: 2.396257434847366
Validation loss: 2.444468034524471

Epoch: 6| Step: 10
Training loss: 2.4094986227062853
Validation loss: 2.462358312058247

Epoch: 6| Step: 11
Training loss: 2.8087258341029346
Validation loss: 2.459330025282129

Epoch: 6| Step: 12
Training loss: 2.168069483160878
Validation loss: 2.4429449987462246

Epoch: 6| Step: 13
Training loss: 2.679521561091868
Validation loss: 2.437364880035338

Epoch: 107| Step: 0
Training loss: 2.45553528771108
Validation loss: 2.445925932369537

Epoch: 6| Step: 1
Training loss: 3.0095099081220784
Validation loss: 2.4435475981722

Epoch: 6| Step: 2
Training loss: 2.5135387038587447
Validation loss: 2.460179056468628

Epoch: 6| Step: 3
Training loss: 3.108303786504662
Validation loss: 2.4730940005255166

Epoch: 6| Step: 4
Training loss: 2.226330125963566
Validation loss: 2.473580950119599

Epoch: 6| Step: 5
Training loss: 2.6338593979589255
Validation loss: 2.5043812303293027

Epoch: 6| Step: 6
Training loss: 2.7212125653139556
Validation loss: 2.534960353931496

Epoch: 6| Step: 7
Training loss: 2.9473796845163514
Validation loss: 2.540450331768034

Epoch: 6| Step: 8
Training loss: 3.118985912138301
Validation loss: 2.5073985173167146

Epoch: 6| Step: 9
Training loss: 2.927879976261921
Validation loss: 2.479794063444674

Epoch: 6| Step: 10
Training loss: 2.4115748751487036
Validation loss: 2.4684613756048033

Epoch: 6| Step: 11
Training loss: 2.456391704635888
Validation loss: 2.455475680458825

Epoch: 6| Step: 12
Training loss: 2.4514838882592174
Validation loss: 2.4583888547316963

Epoch: 6| Step: 13
Training loss: 2.4732643090904882
Validation loss: 2.467751787820015

Epoch: 108| Step: 0
Training loss: 2.713851637656738
Validation loss: 2.469204396779508

Epoch: 6| Step: 1
Training loss: 3.020085805722377
Validation loss: 2.4680536673642086

Epoch: 6| Step: 2
Training loss: 2.977775586856523
Validation loss: 2.4840775591205086

Epoch: 6| Step: 3
Training loss: 2.902946809981125
Validation loss: 2.4993325757678893

Epoch: 6| Step: 4
Training loss: 2.4883718908260524
Validation loss: 2.493900094974243

Epoch: 6| Step: 5
Training loss: 2.256708000383062
Validation loss: 2.498499580019445

Epoch: 6| Step: 6
Training loss: 2.8835583887487424
Validation loss: 2.515101646444315

Epoch: 6| Step: 7
Training loss: 2.7116724606549574
Validation loss: 2.507047027095572

Epoch: 6| Step: 8
Training loss: 2.472069741546114
Validation loss: 2.5220210427402905

Epoch: 6| Step: 9
Training loss: 1.9008644195561197
Validation loss: 2.5669328737970676

Epoch: 6| Step: 10
Training loss: 2.99644832179132
Validation loss: 2.6064495231913365

Epoch: 6| Step: 11
Training loss: 2.9027153588438144
Validation loss: 2.6073726885229993

Epoch: 6| Step: 12
Training loss: 2.550879857726245
Validation loss: 2.593974680335962

Epoch: 6| Step: 13
Training loss: 3.235653094913384
Validation loss: 2.56761887504823

Epoch: 109| Step: 0
Training loss: 2.955846753351208
Validation loss: 2.5240414754254643

Epoch: 6| Step: 1
Training loss: 2.502987983373006
Validation loss: 2.5179203277280697

Epoch: 6| Step: 2
Training loss: 2.7543891212857923
Validation loss: 2.483852515986455

Epoch: 6| Step: 3
Training loss: 2.057547200103039
Validation loss: 2.4743072881959214

Epoch: 6| Step: 4
Training loss: 2.750632040044698
Validation loss: 2.465576819003914

Epoch: 6| Step: 5
Training loss: 2.6171570733422573
Validation loss: 2.468493648587789

Epoch: 6| Step: 6
Training loss: 2.5062397335917184
Validation loss: 2.455556174911721

Epoch: 6| Step: 7
Training loss: 2.3309139469714526
Validation loss: 2.450713543705556

Epoch: 6| Step: 8
Training loss: 2.735133300266561
Validation loss: 2.453788729713743

Epoch: 6| Step: 9
Training loss: 2.6774376858566677
Validation loss: 2.4531805480098035

Epoch: 6| Step: 10
Training loss: 2.9536019399295608
Validation loss: 2.442141348085749

Epoch: 6| Step: 11
Training loss: 2.862112267233594
Validation loss: 2.4437542913234664

Epoch: 6| Step: 12
Training loss: 3.4141544006688456
Validation loss: 2.4285398965563534

Epoch: 6| Step: 13
Training loss: 2.5965821763258496
Validation loss: 2.4181709346165063

Epoch: 110| Step: 0
Training loss: 2.3634561773457716
Validation loss: 2.4249246435040375

Epoch: 6| Step: 1
Training loss: 2.3056452426037297
Validation loss: 2.420610412220047

Epoch: 6| Step: 2
Training loss: 2.6368853028994215
Validation loss: 2.4357780072341755

Epoch: 6| Step: 3
Training loss: 2.6449576503197294
Validation loss: 2.45462065050644

Epoch: 6| Step: 4
Training loss: 2.6812630962060884
Validation loss: 2.4809001691802663

Epoch: 6| Step: 5
Training loss: 2.5974389006814844
Validation loss: 2.4962296757731885

Epoch: 6| Step: 6
Training loss: 3.019442972765621
Validation loss: 2.5363853922339405

Epoch: 6| Step: 7
Training loss: 2.6857631304974845
Validation loss: 2.5565855349850204

Epoch: 6| Step: 8
Training loss: 2.674389999572241
Validation loss: 2.579618781058658

Epoch: 6| Step: 9
Training loss: 3.1651934827629726
Validation loss: 2.5695752237420386

Epoch: 6| Step: 10
Training loss: 2.2827939596082527
Validation loss: 2.561773167577695

Epoch: 6| Step: 11
Training loss: 2.7620303829325765
Validation loss: 2.534356196840675

Epoch: 6| Step: 12
Training loss: 2.9182728477439177
Validation loss: 2.5266670345197144

Epoch: 6| Step: 13
Training loss: 3.035569092940824
Validation loss: 2.5371870961625382

Epoch: 111| Step: 0
Training loss: 2.969478477645396
Validation loss: 2.52489557496021

Epoch: 6| Step: 1
Training loss: 2.8650308340387327
Validation loss: 2.554807210275459

Epoch: 6| Step: 2
Training loss: 2.7192785691961845
Validation loss: 2.5546852641907924

Epoch: 6| Step: 3
Training loss: 2.953657475659713
Validation loss: 2.5089000834977786

Epoch: 6| Step: 4
Training loss: 2.160827642752788
Validation loss: 2.4741500621306685

Epoch: 6| Step: 5
Training loss: 2.45620941827461
Validation loss: 2.455900293541643

Epoch: 6| Step: 6
Training loss: 2.7845384680374714
Validation loss: 2.450975809989376

Epoch: 6| Step: 7
Training loss: 2.7365795730628024
Validation loss: 2.448946989211859

Epoch: 6| Step: 8
Training loss: 2.0302010982483023
Validation loss: 2.4524249343813187

Epoch: 6| Step: 9
Training loss: 2.569516600778447
Validation loss: 2.454056803656265

Epoch: 6| Step: 10
Training loss: 3.0028610891555005
Validation loss: 2.458284640016791

Epoch: 6| Step: 11
Training loss: 2.4202753506217323
Validation loss: 2.453830044727639

Epoch: 6| Step: 12
Training loss: 2.388661394696704
Validation loss: 2.4753795005925365

Epoch: 6| Step: 13
Training loss: 3.566425503096991
Validation loss: 2.4712800747532215

Epoch: 112| Step: 0
Training loss: 3.022078334275287
Validation loss: 2.5080092715213853

Epoch: 6| Step: 1
Training loss: 2.3588956636493363
Validation loss: 2.4921012917770047

Epoch: 6| Step: 2
Training loss: 2.9047631182582445
Validation loss: 2.4714113197723067

Epoch: 6| Step: 3
Training loss: 2.711620409695438
Validation loss: 2.443838405465617

Epoch: 6| Step: 4
Training loss: 2.5357591943582616
Validation loss: 2.436880898135716

Epoch: 6| Step: 5
Training loss: 2.7865359191550816
Validation loss: 2.434730482494471

Epoch: 6| Step: 6
Training loss: 2.643386570545506
Validation loss: 2.4300808213131675

Epoch: 6| Step: 7
Training loss: 2.495579148618176
Validation loss: 2.446474358808763

Epoch: 6| Step: 8
Training loss: 2.455760147907921
Validation loss: 2.4541867625045746

Epoch: 6| Step: 9
Training loss: 2.563274917664477
Validation loss: 2.4821964803586374

Epoch: 6| Step: 10
Training loss: 3.412681317665032
Validation loss: 2.499670489961046

Epoch: 6| Step: 11
Training loss: 2.609244703134875
Validation loss: 2.4846347686702313

Epoch: 6| Step: 12
Training loss: 2.9612995017001458
Validation loss: 2.4450688703849353

Epoch: 6| Step: 13
Training loss: 1.2435525076026077
Validation loss: 2.4453988700667546

Epoch: 113| Step: 0
Training loss: 2.5319374940457915
Validation loss: 2.459932926516468

Epoch: 6| Step: 1
Training loss: 2.8468682934946905
Validation loss: 2.50579879795327

Epoch: 6| Step: 2
Training loss: 2.78300189445231
Validation loss: 2.5384657130211967

Epoch: 6| Step: 3
Training loss: 2.9057984360208557
Validation loss: 2.544772857598788

Epoch: 6| Step: 4
Training loss: 2.340554665908063
Validation loss: 2.5042423257404725

Epoch: 6| Step: 5
Training loss: 3.140854253040528
Validation loss: 2.466312492259144

Epoch: 6| Step: 6
Training loss: 2.09902221986333
Validation loss: 2.452261701840542

Epoch: 6| Step: 7
Training loss: 2.466465726176985
Validation loss: 2.4372290173247455

Epoch: 6| Step: 8
Training loss: 3.124577608172373
Validation loss: 2.4266721449419073

Epoch: 6| Step: 9
Training loss: 2.8981936781501223
Validation loss: 2.4447738770829686

Epoch: 6| Step: 10
Training loss: 2.125397140192872
Validation loss: 2.4599295749316297

Epoch: 6| Step: 11
Training loss: 2.4782677204072305
Validation loss: 2.4829166337210062

Epoch: 6| Step: 12
Training loss: 3.0184000321813644
Validation loss: 2.4878497948733296

Epoch: 6| Step: 13
Training loss: 2.8002902868203154
Validation loss: 2.4991199626224887

Epoch: 114| Step: 0
Training loss: 2.6489545379343467
Validation loss: 2.4808067240741547

Epoch: 6| Step: 1
Training loss: 2.170228951852936
Validation loss: 2.4539633204763733

Epoch: 6| Step: 2
Training loss: 2.247401114082247
Validation loss: 2.458543421919307

Epoch: 6| Step: 3
Training loss: 2.436509542482925
Validation loss: 2.453806660483869

Epoch: 6| Step: 4
Training loss: 2.7012837925341384
Validation loss: 2.4567205663474487

Epoch: 6| Step: 5
Training loss: 2.703913579146651
Validation loss: 2.451545982572116

Epoch: 6| Step: 6
Training loss: 3.4794649160013913
Validation loss: 2.458642085774959

Epoch: 6| Step: 7
Training loss: 2.946715812388343
Validation loss: 2.4993405251634684

Epoch: 6| Step: 8
Training loss: 2.605418420674413
Validation loss: 2.494005367619481

Epoch: 6| Step: 9
Training loss: 2.1652754816719146
Validation loss: 2.4968615459366275

Epoch: 6| Step: 10
Training loss: 2.9259336302003507
Validation loss: 2.528037474117878

Epoch: 6| Step: 11
Training loss: 2.3277406311207147
Validation loss: 2.5307787486027977

Epoch: 6| Step: 12
Training loss: 2.3366430741596087
Validation loss: 2.5642365055009546

Epoch: 6| Step: 13
Training loss: 3.529977079538601
Validation loss: 2.574916663266412

Epoch: 115| Step: 0
Training loss: 2.8309979257094295
Validation loss: 2.5830356212661814

Epoch: 6| Step: 1
Training loss: 3.293496375842176
Validation loss: 2.5657968639693416

Epoch: 6| Step: 2
Training loss: 2.409114173397323
Validation loss: 2.571003260238285

Epoch: 6| Step: 3
Training loss: 2.621418098586186
Validation loss: 2.5706916552120846

Epoch: 6| Step: 4
Training loss: 2.8832084569919196
Validation loss: 2.576608945314678

Epoch: 6| Step: 5
Training loss: 2.2518984944316722
Validation loss: 2.525786831865919

Epoch: 6| Step: 6
Training loss: 2.179187129297213
Validation loss: 2.50461100228756

Epoch: 6| Step: 7
Training loss: 2.5685299892832023
Validation loss: 2.494028219227826

Epoch: 6| Step: 8
Training loss: 2.0619936234739114
Validation loss: 2.497978699749546

Epoch: 6| Step: 9
Training loss: 2.571880013332371
Validation loss: 2.5162252465302215

Epoch: 6| Step: 10
Training loss: 2.9758444092593477
Validation loss: 2.526348272418862

Epoch: 6| Step: 11
Training loss: 3.0220609779290175
Validation loss: 2.5632996970796453

Epoch: 6| Step: 12
Training loss: 3.063245098792834
Validation loss: 2.536888916988649

Epoch: 6| Step: 13
Training loss: 1.645476515837392
Validation loss: 2.516301222097898

Epoch: 116| Step: 0
Training loss: 2.6625792549766443
Validation loss: 2.50687774962473

Epoch: 6| Step: 1
Training loss: 3.119883812428238
Validation loss: 2.490719061501561

Epoch: 6| Step: 2
Training loss: 2.1643999298008274
Validation loss: 2.479589674542402

Epoch: 6| Step: 3
Training loss: 2.4864045496220246
Validation loss: 2.4689675418682593

Epoch: 6| Step: 4
Training loss: 2.6782562615399645
Validation loss: 2.4847887493994048

Epoch: 6| Step: 5
Training loss: 2.446752739552131
Validation loss: 2.475097154417674

Epoch: 6| Step: 6
Training loss: 2.3949139586345676
Validation loss: 2.469462119497387

Epoch: 6| Step: 7
Training loss: 2.627854112596638
Validation loss: 2.475471823424767

Epoch: 6| Step: 8
Training loss: 2.8741632985528236
Validation loss: 2.4884095893822407

Epoch: 6| Step: 9
Training loss: 2.653171505649628
Validation loss: 2.5016496957887826

Epoch: 6| Step: 10
Training loss: 2.1750408124931226
Validation loss: 2.499611292122664

Epoch: 6| Step: 11
Training loss: 3.0887262418937813
Validation loss: 2.489936888634148

Epoch: 6| Step: 12
Training loss: 3.1818116237523255
Validation loss: 2.4798069012877337

Epoch: 6| Step: 13
Training loss: 2.4473991875152974
Validation loss: 2.459522785138604

Epoch: 117| Step: 0
Training loss: 1.8393780874264645
Validation loss: 2.469719541281469

Epoch: 6| Step: 1
Training loss: 2.1465854499490824
Validation loss: 2.4698109723020796

Epoch: 6| Step: 2
Training loss: 2.201770555507899
Validation loss: 2.475514164262589

Epoch: 6| Step: 3
Training loss: 3.1441666859710096
Validation loss: 2.4922143556223673

Epoch: 6| Step: 4
Training loss: 2.686613513319769
Validation loss: 2.5147464038034153

Epoch: 6| Step: 5
Training loss: 3.3709989779733056
Validation loss: 2.5961543095022694

Epoch: 6| Step: 6
Training loss: 2.8525378923632485
Validation loss: 2.5427686910208145

Epoch: 6| Step: 7
Training loss: 2.584889179267033
Validation loss: 2.5056678143040694

Epoch: 6| Step: 8
Training loss: 2.6014692959972363
Validation loss: 2.4617986700724193

Epoch: 6| Step: 9
Training loss: 2.743467635308481
Validation loss: 2.4305743357865026

Epoch: 6| Step: 10
Training loss: 2.7267729669787406
Validation loss: 2.4249078809441382

Epoch: 6| Step: 11
Training loss: 2.917666254871673
Validation loss: 2.433386859636604

Epoch: 6| Step: 12
Training loss: 3.042247838625429
Validation loss: 2.452677129698409

Epoch: 6| Step: 13
Training loss: 2.2779393668608123
Validation loss: 2.47338076902094

Epoch: 118| Step: 0
Training loss: 2.65142527704551
Validation loss: 2.4781562239918977

Epoch: 6| Step: 1
Training loss: 2.095166083332786
Validation loss: 2.4864941525690263

Epoch: 6| Step: 2
Training loss: 2.5937270197941897
Validation loss: 2.488307492269156

Epoch: 6| Step: 3
Training loss: 3.2756976425597024
Validation loss: 2.518188251923495

Epoch: 6| Step: 4
Training loss: 2.9082103393547185
Validation loss: 2.5604765772019213

Epoch: 6| Step: 5
Training loss: 2.869144613680005
Validation loss: 2.59807238672401

Epoch: 6| Step: 6
Training loss: 2.074612510074006
Validation loss: 2.6092513960669677

Epoch: 6| Step: 7
Training loss: 2.8379655632526637
Validation loss: 2.6048388795285273

Epoch: 6| Step: 8
Training loss: 3.0955661875765927
Validation loss: 2.577576735026752

Epoch: 6| Step: 9
Training loss: 1.9498433123506376
Validation loss: 2.5324781733151545

Epoch: 6| Step: 10
Training loss: 3.3443833936636924
Validation loss: 2.4731731197604416

Epoch: 6| Step: 11
Training loss: 2.3895807915307925
Validation loss: 2.450044493054624

Epoch: 6| Step: 12
Training loss: 2.026060547205434
Validation loss: 2.441027520187424

Epoch: 6| Step: 13
Training loss: 2.397082514527069
Validation loss: 2.445719889204245

Epoch: 119| Step: 0
Training loss: 2.5213299622004643
Validation loss: 2.4677357353530947

Epoch: 6| Step: 1
Training loss: 2.9040019867525055
Validation loss: 2.502921257859301

Epoch: 6| Step: 2
Training loss: 2.910468045115456
Validation loss: 2.5159245585723493

Epoch: 6| Step: 3
Training loss: 2.120938402532338
Validation loss: 2.4996007610782653

Epoch: 6| Step: 4
Training loss: 2.792832847436578
Validation loss: 2.496204883746692

Epoch: 6| Step: 5
Training loss: 2.993886121868661
Validation loss: 2.4977563860405443

Epoch: 6| Step: 6
Training loss: 2.0137546348400046
Validation loss: 2.463365024821984

Epoch: 6| Step: 7
Training loss: 2.533356719996604
Validation loss: 2.4334906931184603

Epoch: 6| Step: 8
Training loss: 2.768753523641372
Validation loss: 2.4340942576035878

Epoch: 6| Step: 9
Training loss: 2.4035112722857446
Validation loss: 2.4383889337214355

Epoch: 6| Step: 10
Training loss: 2.5953305495872954
Validation loss: 2.456126339972049

Epoch: 6| Step: 11
Training loss: 3.0866145296685077
Validation loss: 2.461480971651084

Epoch: 6| Step: 12
Training loss: 2.358113741227285
Validation loss: 2.4863179831283517

Epoch: 6| Step: 13
Training loss: 2.0075934027086673
Validation loss: 2.520099081079682

Epoch: 120| Step: 0
Training loss: 2.0396599022348476
Validation loss: 2.5594345994345735

Epoch: 6| Step: 1
Training loss: 2.9816853651210664
Validation loss: 2.5969473559355545

Epoch: 6| Step: 2
Training loss: 2.8017127112198597
Validation loss: 2.631999787691523

Epoch: 6| Step: 3
Training loss: 3.1706208253513783
Validation loss: 2.6682360559687353

Epoch: 6| Step: 4
Training loss: 2.9148156059662966
Validation loss: 2.666891807299147

Epoch: 6| Step: 5
Training loss: 2.5347315075383463
Validation loss: 2.6438064695613157

Epoch: 6| Step: 6
Training loss: 2.4442540031962947
Validation loss: 2.6205388002758268

Epoch: 6| Step: 7
Training loss: 2.956335512501175
Validation loss: 2.6227370653770836

Epoch: 6| Step: 8
Training loss: 2.4550546236817685
Validation loss: 2.5032698699732174

Epoch: 6| Step: 9
Training loss: 2.900656290442424
Validation loss: 2.42128642085575

Epoch: 6| Step: 10
Training loss: 2.2900124098928765
Validation loss: 2.403727111910503

Epoch: 6| Step: 11
Training loss: 2.754369039405725
Validation loss: 2.433813735878441

Epoch: 6| Step: 12
Training loss: 3.025637907754385
Validation loss: 2.481190745960757

Epoch: 6| Step: 13
Training loss: 3.5202417873657645
Validation loss: 2.5052770991022135

Epoch: 121| Step: 0
Training loss: 2.811911373000685
Validation loss: 2.5136614711949123

Epoch: 6| Step: 1
Training loss: 2.6355165806905343
Validation loss: 2.4870292594532306

Epoch: 6| Step: 2
Training loss: 2.7333501148484065
Validation loss: 2.4874143824727772

Epoch: 6| Step: 3
Training loss: 3.123827905191001
Validation loss: 2.4865292639186136

Epoch: 6| Step: 4
Training loss: 2.6972554598208616
Validation loss: 2.5660073902555474

Epoch: 6| Step: 5
Training loss: 2.469224135826227
Validation loss: 2.6265015602185815

Epoch: 6| Step: 6
Training loss: 3.0130417585951386
Validation loss: 2.6802474508697443

Epoch: 6| Step: 7
Training loss: 3.2214945230871144
Validation loss: 2.6853168259697293

Epoch: 6| Step: 8
Training loss: 2.7224379332922655
Validation loss: 2.6165028058014426

Epoch: 6| Step: 9
Training loss: 2.3308164669004436
Validation loss: 2.554980036951316

Epoch: 6| Step: 10
Training loss: 2.4946057297471294
Validation loss: 2.5241762181824337

Epoch: 6| Step: 11
Training loss: 2.8006659873750306
Validation loss: 2.5070115138781244

Epoch: 6| Step: 12
Training loss: 2.5056093229439487
Validation loss: 2.4853979321274586

Epoch: 6| Step: 13
Training loss: 2.447077397614753
Validation loss: 2.4886226735661605

Epoch: 122| Step: 0
Training loss: 2.475118125639736
Validation loss: 2.447981765778623

Epoch: 6| Step: 1
Training loss: 2.6099502934366785
Validation loss: 2.4421052914926955

Epoch: 6| Step: 2
Training loss: 2.4551145418875757
Validation loss: 2.4226072963441876

Epoch: 6| Step: 3
Training loss: 2.285600250669258
Validation loss: 2.4220628848783354

Epoch: 6| Step: 4
Training loss: 2.8780468262235672
Validation loss: 2.430663526708318

Epoch: 6| Step: 5
Training loss: 3.388018894219436
Validation loss: 2.455266476190261

Epoch: 6| Step: 6
Training loss: 2.7025916835819843
Validation loss: 2.492289934995481

Epoch: 6| Step: 7
Training loss: 2.436380373743296
Validation loss: 2.481327936509607

Epoch: 6| Step: 8
Training loss: 2.4376788929558284
Validation loss: 2.4653012746334064

Epoch: 6| Step: 9
Training loss: 3.0967034008473955
Validation loss: 2.4459807582223116

Epoch: 6| Step: 10
Training loss: 2.7620707804168805
Validation loss: 2.440381096721608

Epoch: 6| Step: 11
Training loss: 2.4431345445120067
Validation loss: 2.446676319059462

Epoch: 6| Step: 12
Training loss: 2.1564403947446418
Validation loss: 2.4390832934997224

Epoch: 6| Step: 13
Training loss: 2.447019036390855
Validation loss: 2.435099231138055

Epoch: 123| Step: 0
Training loss: 2.7759254149715304
Validation loss: 2.4607227539706162

Epoch: 6| Step: 1
Training loss: 2.9180331344344306
Validation loss: 2.4477036609716625

Epoch: 6| Step: 2
Training loss: 2.586740789662318
Validation loss: 2.4576255366174764

Epoch: 6| Step: 3
Training loss: 2.7038403925994494
Validation loss: 2.462089698822745

Epoch: 6| Step: 4
Training loss: 2.5856283412189764
Validation loss: 2.4735820715134786

Epoch: 6| Step: 5
Training loss: 2.488653756948253
Validation loss: 2.4544811201159855

Epoch: 6| Step: 6
Training loss: 2.769750330859117
Validation loss: 2.4411363667614174

Epoch: 6| Step: 7
Training loss: 2.680652589200174
Validation loss: 2.4440708178614003

Epoch: 6| Step: 8
Training loss: 2.001999808906904
Validation loss: 2.434066162755412

Epoch: 6| Step: 9
Training loss: 2.536661838354795
Validation loss: 2.4289665544015246

Epoch: 6| Step: 10
Training loss: 2.2732032052139166
Validation loss: 2.442702397661724

Epoch: 6| Step: 11
Training loss: 2.300637621193371
Validation loss: 2.4536685219994223

Epoch: 6| Step: 12
Training loss: 2.803068325868948
Validation loss: 2.4973786136500142

Epoch: 6| Step: 13
Training loss: 2.7839019647580168
Validation loss: 2.5039672608642474

Epoch: 124| Step: 0
Training loss: 2.720291227008831
Validation loss: 2.545011661012138

Epoch: 6| Step: 1
Training loss: 3.161246999163729
Validation loss: 2.518309734892461

Epoch: 6| Step: 2
Training loss: 2.899098611376282
Validation loss: 2.5134130684530906

Epoch: 6| Step: 3
Training loss: 2.4766632925997203
Validation loss: 2.522752698446828

Epoch: 6| Step: 4
Training loss: 2.7377042720299993
Validation loss: 2.4981704395669206

Epoch: 6| Step: 5
Training loss: 2.5761586406561596
Validation loss: 2.4777949312532552

Epoch: 6| Step: 6
Training loss: 2.6123703992903415
Validation loss: 2.462315536768454

Epoch: 6| Step: 7
Training loss: 2.2124878532809005
Validation loss: 2.4618554406861715

Epoch: 6| Step: 8
Training loss: 2.589324484849629
Validation loss: 2.45521394601576

Epoch: 6| Step: 9
Training loss: 2.817078149146892
Validation loss: 2.4577301777417144

Epoch: 6| Step: 10
Training loss: 2.413077736890406
Validation loss: 2.452965789680242

Epoch: 6| Step: 11
Training loss: 2.531929113393146
Validation loss: 2.4610904258693864

Epoch: 6| Step: 12
Training loss: 2.19625692992835
Validation loss: 2.467176106761152

Epoch: 6| Step: 13
Training loss: 2.1433150937425074
Validation loss: 2.461858715713739

Epoch: 125| Step: 0
Training loss: 3.0235685571462048
Validation loss: 2.4514351422039797

Epoch: 6| Step: 1
Training loss: 2.6845839893135603
Validation loss: 2.44974413337847

Epoch: 6| Step: 2
Training loss: 1.90660817267762
Validation loss: 2.4454552257162767

Epoch: 6| Step: 3
Training loss: 2.620577310773705
Validation loss: 2.446516999253884

Epoch: 6| Step: 4
Training loss: 2.2687209450618866
Validation loss: 2.451805016175955

Epoch: 6| Step: 5
Training loss: 2.186103374958151
Validation loss: 2.4463327080177595

Epoch: 6| Step: 6
Training loss: 2.4139734146816014
Validation loss: 2.4399915928311673

Epoch: 6| Step: 7
Training loss: 2.3675268955978925
Validation loss: 2.4392636904393683

Epoch: 6| Step: 8
Training loss: 2.8201296422120485
Validation loss: 2.4730573031272507

Epoch: 6| Step: 9
Training loss: 2.8227538640184435
Validation loss: 2.505128939845018

Epoch: 6| Step: 10
Training loss: 2.644975498136455
Validation loss: 2.519263681314259

Epoch: 6| Step: 11
Training loss: 2.295749622164237
Validation loss: 2.500178449681236

Epoch: 6| Step: 12
Training loss: 2.609151590799813
Validation loss: 2.4992753845064786

Epoch: 6| Step: 13
Training loss: 3.1211194167436496
Validation loss: 2.468074422134996

Epoch: 126| Step: 0
Training loss: 2.11999145865969
Validation loss: 2.429690911238835

Epoch: 6| Step: 1
Training loss: 2.562103054657073
Validation loss: 2.4285980843202863

Epoch: 6| Step: 2
Training loss: 2.488492133338333
Validation loss: 2.425009182953941

Epoch: 6| Step: 3
Training loss: 2.6196991213359073
Validation loss: 2.4357321896541504

Epoch: 6| Step: 4
Training loss: 2.3273110214856887
Validation loss: 2.418951205608172

Epoch: 6| Step: 5
Training loss: 3.409071567364935
Validation loss: 2.4198229434470915

Epoch: 6| Step: 6
Training loss: 2.595089302363919
Validation loss: 2.4105991489686156

Epoch: 6| Step: 7
Training loss: 2.393390925395418
Validation loss: 2.4050217556676685

Epoch: 6| Step: 8
Training loss: 2.612742187371517
Validation loss: 2.403905912831826

Epoch: 6| Step: 9
Training loss: 2.610595874363626
Validation loss: 2.3998122397762156

Epoch: 6| Step: 10
Training loss: 2.959057535708589
Validation loss: 2.3840300275164203

Epoch: 6| Step: 11
Training loss: 2.493817887302378
Validation loss: 2.402043026719362

Epoch: 6| Step: 12
Training loss: 1.710740308850935
Validation loss: 2.4224965579085493

Epoch: 6| Step: 13
Training loss: 2.816265044462112
Validation loss: 2.489963405857652

Epoch: 127| Step: 0
Training loss: 2.2515429398628815
Validation loss: 2.5764445556179054

Epoch: 6| Step: 1
Training loss: 3.1056007980966696
Validation loss: 2.6671226275724695

Epoch: 6| Step: 2
Training loss: 2.9692268390180985
Validation loss: 2.680863421534884

Epoch: 6| Step: 3
Training loss: 2.994480778134205
Validation loss: 2.653364283941378

Epoch: 6| Step: 4
Training loss: 2.466950062203432
Validation loss: 2.546081902643173

Epoch: 6| Step: 5
Training loss: 2.3235062220247746
Validation loss: 2.4683328725008664

Epoch: 6| Step: 6
Training loss: 2.8692164089719117
Validation loss: 2.439276232916349

Epoch: 6| Step: 7
Training loss: 3.0923784086212565
Validation loss: 2.4447502761859674

Epoch: 6| Step: 8
Training loss: 2.3152929399992246
Validation loss: 2.455832265679409

Epoch: 6| Step: 9
Training loss: 1.9634770822064243
Validation loss: 2.4623994093694934

Epoch: 6| Step: 10
Training loss: 2.2291118817118547
Validation loss: 2.475438022727254

Epoch: 6| Step: 11
Training loss: 2.0165760251107
Validation loss: 2.4798828197777754

Epoch: 6| Step: 12
Training loss: 2.806392735714792
Validation loss: 2.476438441141667

Epoch: 6| Step: 13
Training loss: 2.5256630735069288
Validation loss: 2.4757382961131325

Epoch: 128| Step: 0
Training loss: 2.3474331208636148
Validation loss: 2.4861331444974217

Epoch: 6| Step: 1
Training loss: 2.9551910762038722
Validation loss: 2.5018484993132195

Epoch: 6| Step: 2
Training loss: 2.131450399782312
Validation loss: 2.518731211902121

Epoch: 6| Step: 3
Training loss: 3.1743890730246784
Validation loss: 2.558904719326382

Epoch: 6| Step: 4
Training loss: 2.5398423156452616
Validation loss: 2.529191870154223

Epoch: 6| Step: 5
Training loss: 2.5413472855649597
Validation loss: 2.5572171142837266

Epoch: 6| Step: 6
Training loss: 2.9883865637079805
Validation loss: 2.563086365832643

Epoch: 6| Step: 7
Training loss: 2.762020628750589
Validation loss: 2.5520810880435576

Epoch: 6| Step: 8
Training loss: 2.29947157470095
Validation loss: 2.5365451385939197

Epoch: 6| Step: 9
Training loss: 2.3693517479224777
Validation loss: 2.5340492117735662

Epoch: 6| Step: 10
Training loss: 2.344564881126458
Validation loss: 2.5065371802821157

Epoch: 6| Step: 11
Training loss: 2.4256246765026415
Validation loss: 2.496591202634714

Epoch: 6| Step: 12
Training loss: 2.649455997122518
Validation loss: 2.4831530057132274

Epoch: 6| Step: 13
Training loss: 2.6686741802514176
Validation loss: 2.4378503274756858

Epoch: 129| Step: 0
Training loss: 2.776917157897396
Validation loss: 2.40498886012696

Epoch: 6| Step: 1
Training loss: 1.624108289932281
Validation loss: 2.415184538921303

Epoch: 6| Step: 2
Training loss: 2.8883744009906076
Validation loss: 2.418771181392473

Epoch: 6| Step: 3
Training loss: 2.9917613390834137
Validation loss: 2.4446220682613604

Epoch: 6| Step: 4
Training loss: 1.7490572433569893
Validation loss: 2.447030642849572

Epoch: 6| Step: 5
Training loss: 2.8945981325564043
Validation loss: 2.4557392065914567

Epoch: 6| Step: 6
Training loss: 2.17047337374539
Validation loss: 2.4620491981917745

Epoch: 6| Step: 7
Training loss: 2.3308217859601568
Validation loss: 2.4639799776602853

Epoch: 6| Step: 8
Training loss: 2.2004534167434247
Validation loss: 2.4693540761130417

Epoch: 6| Step: 9
Training loss: 3.3291402351816557
Validation loss: 2.5026547006406688

Epoch: 6| Step: 10
Training loss: 2.4631087155930254
Validation loss: 2.5419651631527325

Epoch: 6| Step: 11
Training loss: 2.60735329527087
Validation loss: 2.5193785928729726

Epoch: 6| Step: 12
Training loss: 2.2271577808960594
Validation loss: 2.479965189594532

Epoch: 6| Step: 13
Training loss: 3.0223962533466144
Validation loss: 2.4679321288423

Epoch: 130| Step: 0
Training loss: 2.4756801248724516
Validation loss: 2.476382206711688

Epoch: 6| Step: 1
Training loss: 2.4893685305408613
Validation loss: 2.489367210291117

Epoch: 6| Step: 2
Training loss: 1.8379568479243884
Validation loss: 2.471654544983673

Epoch: 6| Step: 3
Training loss: 2.4656454919463924
Validation loss: 2.47681555699404

Epoch: 6| Step: 4
Training loss: 2.5419773683178297
Validation loss: 2.4698505993522817

Epoch: 6| Step: 5
Training loss: 2.2164623663504313
Validation loss: 2.4835048004645532

Epoch: 6| Step: 6
Training loss: 2.3703524642120097
Validation loss: 2.495373756483391

Epoch: 6| Step: 7
Training loss: 2.969679516285109
Validation loss: 2.4801159312659697

Epoch: 6| Step: 8
Training loss: 2.95710316901891
Validation loss: 2.487145874710311

Epoch: 6| Step: 9
Training loss: 2.4350281922511914
Validation loss: 2.49668569422548

Epoch: 6| Step: 10
Training loss: 2.4811239984070106
Validation loss: 2.4916604654540406

Epoch: 6| Step: 11
Training loss: 2.674144918373743
Validation loss: 2.474972779725177

Epoch: 6| Step: 12
Training loss: 2.4023612169080457
Validation loss: 2.4645922161158547

Epoch: 6| Step: 13
Training loss: 2.6557224422972445
Validation loss: 2.4661822087596628

Epoch: 131| Step: 0
Training loss: 2.710757202836863
Validation loss: 2.4554840485094007

Epoch: 6| Step: 1
Training loss: 1.973510073960588
Validation loss: 2.465614701808717

Epoch: 6| Step: 2
Training loss: 2.3603959053744865
Validation loss: 2.4865055371343443

Epoch: 6| Step: 3
Training loss: 2.534790200725562
Validation loss: 2.500862183128614

Epoch: 6| Step: 4
Training loss: 3.0538264863612126
Validation loss: 2.5226421011258706

Epoch: 6| Step: 5
Training loss: 2.1230830353550014
Validation loss: 2.5044202643157036

Epoch: 6| Step: 6
Training loss: 2.6239256703967606
Validation loss: 2.4910618099097115

Epoch: 6| Step: 7
Training loss: 2.6156014718258827
Validation loss: 2.4713626815047727

Epoch: 6| Step: 8
Training loss: 2.309586932584227
Validation loss: 2.47488176729036

Epoch: 6| Step: 9
Training loss: 2.640540669014442
Validation loss: 2.4603121534464547

Epoch: 6| Step: 10
Training loss: 2.3704723568285972
Validation loss: 2.4631378769766368

Epoch: 6| Step: 11
Training loss: 2.009945815954985
Validation loss: 2.467233591135544

Epoch: 6| Step: 12
Training loss: 3.0220126952050466
Validation loss: 2.44870412950988

Epoch: 6| Step: 13
Training loss: 2.4964144743944883
Validation loss: 2.464999613902586

Epoch: 132| Step: 0
Training loss: 2.9136799006333027
Validation loss: 2.4852228753923677

Epoch: 6| Step: 1
Training loss: 2.3230221529104274
Validation loss: 2.493382864200131

Epoch: 6| Step: 2
Training loss: 2.003900777054539
Validation loss: 2.5317881397118454

Epoch: 6| Step: 3
Training loss: 2.6980532657011325
Validation loss: 2.557057111383432

Epoch: 6| Step: 4
Training loss: 2.3334492472966866
Validation loss: 2.5343228062023306

Epoch: 6| Step: 5
Training loss: 2.453721478102609
Validation loss: 2.500614277425453

Epoch: 6| Step: 6
Training loss: 2.098901588550061
Validation loss: 2.4690286570729234

Epoch: 6| Step: 7
Training loss: 2.7266237967959843
Validation loss: 2.450765810498945

Epoch: 6| Step: 8
Training loss: 2.7303215281863475
Validation loss: 2.4686728398310946

Epoch: 6| Step: 9
Training loss: 1.9674270059891075
Validation loss: 2.4670702566539218

Epoch: 6| Step: 10
Training loss: 2.6679853715281103
Validation loss: 2.4982079605011056

Epoch: 6| Step: 11
Training loss: 2.7575092094869373
Validation loss: 2.5718453315627774

Epoch: 6| Step: 12
Training loss: 2.8570764193303537
Validation loss: 2.655013429829341

Epoch: 6| Step: 13
Training loss: 2.489518317699751
Validation loss: 2.733082764155655

Epoch: 133| Step: 0
Training loss: 2.8132969892634128
Validation loss: 2.7157385742426725

Epoch: 6| Step: 1
Training loss: 2.7445840389084206
Validation loss: 2.6016651495333236

Epoch: 6| Step: 2
Training loss: 2.2333940606852063
Validation loss: 2.5161209743611055

Epoch: 6| Step: 3
Training loss: 1.3741508809777827
Validation loss: 2.4733283038049922

Epoch: 6| Step: 4
Training loss: 3.1524084904674847
Validation loss: 2.452059954882401

Epoch: 6| Step: 5
Training loss: 3.2819715887184753
Validation loss: 2.4623240325404963

Epoch: 6| Step: 6
Training loss: 2.7352188987933683
Validation loss: 2.4764211043731486

Epoch: 6| Step: 7
Training loss: 1.46191928126156
Validation loss: 2.5021301771982873

Epoch: 6| Step: 8
Training loss: 2.582792092096713
Validation loss: 2.526792424870813

Epoch: 6| Step: 9
Training loss: 2.5277567176733355
Validation loss: 2.538656377251734

Epoch: 6| Step: 10
Training loss: 2.45366589845634
Validation loss: 2.536381344194171

Epoch: 6| Step: 11
Training loss: 3.2178853179051385
Validation loss: 2.5028559174505327

Epoch: 6| Step: 12
Training loss: 2.469237943305667
Validation loss: 2.458060954629408

Epoch: 6| Step: 13
Training loss: 1.8895230194974968
Validation loss: 2.4427486176456044

Epoch: 134| Step: 0
Training loss: 2.349781464500093
Validation loss: 2.429390175199932

Epoch: 6| Step: 1
Training loss: 2.0571170265982937
Validation loss: 2.43603430013673

Epoch: 6| Step: 2
Training loss: 2.2163713626583235
Validation loss: 2.436849348987478

Epoch: 6| Step: 3
Training loss: 2.5192716716149555
Validation loss: 2.451112959664858

Epoch: 6| Step: 4
Training loss: 2.4388531572432184
Validation loss: 2.462320538449563

Epoch: 6| Step: 5
Training loss: 2.4593137197845576
Validation loss: 2.4897957994895523

Epoch: 6| Step: 6
Training loss: 2.967763636511046
Validation loss: 2.5317182534425284

Epoch: 6| Step: 7
Training loss: 2.6024277539811096
Validation loss: 2.5788928129379536

Epoch: 6| Step: 8
Training loss: 2.4344365358226616
Validation loss: 2.665372594764656

Epoch: 6| Step: 9
Training loss: 2.3255867658597458
Validation loss: 2.7021863868975675

Epoch: 6| Step: 10
Training loss: 2.939202809368903
Validation loss: 2.7510630724006577

Epoch: 6| Step: 11
Training loss: 2.960061137367045
Validation loss: 2.72614184455258

Epoch: 6| Step: 12
Training loss: 2.9607722656525977
Validation loss: 2.6645763751922584

Epoch: 6| Step: 13
Training loss: 2.1717833355558054
Validation loss: 2.6175078341543747

Epoch: 135| Step: 0
Training loss: 2.888816308878581
Validation loss: 2.571783573469997

Epoch: 6| Step: 1
Training loss: 2.231437833343593
Validation loss: 2.569243043188004

Epoch: 6| Step: 2
Training loss: 2.0628478017073952
Validation loss: 2.5692198906793915

Epoch: 6| Step: 3
Training loss: 2.151585717169464
Validation loss: 2.5677131470243215

Epoch: 6| Step: 4
Training loss: 2.7440374063105346
Validation loss: 2.567701878899714

Epoch: 6| Step: 5
Training loss: 2.7128329727495406
Validation loss: 2.5331291597608665

Epoch: 6| Step: 6
Training loss: 2.7511653165076946
Validation loss: 2.4736969764534034

Epoch: 6| Step: 7
Training loss: 2.08110830380251
Validation loss: 2.469518110795683

Epoch: 6| Step: 8
Training loss: 2.20182556356718
Validation loss: 2.4539299292188037

Epoch: 6| Step: 9
Training loss: 2.816909723874028
Validation loss: 2.4287786304246253

Epoch: 6| Step: 10
Training loss: 2.5489059494823736
Validation loss: 2.4312328758641586

Epoch: 6| Step: 11
Training loss: 2.445324882500348
Validation loss: 2.436382180427255

Epoch: 6| Step: 12
Training loss: 2.3950802047774715
Validation loss: 2.4283431950820464

Epoch: 6| Step: 13
Training loss: 2.676687802634711
Validation loss: 2.47221191905386

Epoch: 136| Step: 0
Training loss: 2.756166826234516
Validation loss: 2.478591164144447

Epoch: 6| Step: 1
Training loss: 3.1011310728949226
Validation loss: 2.487809661052792

Epoch: 6| Step: 2
Training loss: 2.834486408840991
Validation loss: 2.4898416425748544

Epoch: 6| Step: 3
Training loss: 2.5756405043048556
Validation loss: 2.4922805507993564

Epoch: 6| Step: 4
Training loss: 1.5822615090920644
Validation loss: 2.4950216408570967

Epoch: 6| Step: 5
Training loss: 2.1334586369948263
Validation loss: 2.4703037953360103

Epoch: 6| Step: 6
Training loss: 2.660434433876002
Validation loss: 2.4670633390642864

Epoch: 6| Step: 7
Training loss: 2.550574208104156
Validation loss: 2.492124879903926

Epoch: 6| Step: 8
Training loss: 2.3239446398236003
Validation loss: 2.487824524666613

Epoch: 6| Step: 9
Training loss: 2.50891022706998
Validation loss: 2.4935682459716757

Epoch: 6| Step: 10
Training loss: 2.6075542744943188
Validation loss: 2.4985777747221967

Epoch: 6| Step: 11
Training loss: 2.3351104190702605
Validation loss: 2.496036447552878

Epoch: 6| Step: 12
Training loss: 2.161229782583569
Validation loss: 2.4976434922421022

Epoch: 6| Step: 13
Training loss: 1.958020658760072
Validation loss: 2.500602147178159

Epoch: 137| Step: 0
Training loss: 1.692518190317151
Validation loss: 2.4828258629200395

Epoch: 6| Step: 1
Training loss: 2.6500217796726235
Validation loss: 2.4630473254743595

Epoch: 6| Step: 2
Training loss: 2.7773953418258883
Validation loss: 2.470494266936295

Epoch: 6| Step: 3
Training loss: 2.477250734602253
Validation loss: 2.4566850686214408

Epoch: 6| Step: 4
Training loss: 2.035035347596399
Validation loss: 2.4419580924541453

Epoch: 6| Step: 5
Training loss: 2.827331347305235
Validation loss: 2.430154273976682

Epoch: 6| Step: 6
Training loss: 2.1671028676246977
Validation loss: 2.4300616974313307

Epoch: 6| Step: 7
Training loss: 2.753615170510067
Validation loss: 2.430545143382501

Epoch: 6| Step: 8
Training loss: 1.6404525666220258
Validation loss: 2.4112177467254865

Epoch: 6| Step: 9
Training loss: 1.9658001189466738
Validation loss: 2.4155574281897088

Epoch: 6| Step: 10
Training loss: 2.0158930164136906
Validation loss: 2.4072430078168163

Epoch: 6| Step: 11
Training loss: 2.6554523841239113
Validation loss: 2.416798414755804

Epoch: 6| Step: 12
Training loss: 2.6433135120984397
Validation loss: 2.417866552891084

Epoch: 6| Step: 13
Training loss: 3.396054048132826
Validation loss: 2.427752128082554

Epoch: 138| Step: 0
Training loss: 2.7446246063139017
Validation loss: 2.4407128572626604

Epoch: 6| Step: 1
Training loss: 2.5199422811528436
Validation loss: 2.465851153092826

Epoch: 6| Step: 2
Training loss: 1.9483228929673388
Validation loss: 2.491926818086826

Epoch: 6| Step: 3
Training loss: 1.9988192410669536
Validation loss: 2.507334980637672

Epoch: 6| Step: 4
Training loss: 2.0649748317117638
Validation loss: 2.5477184522384326

Epoch: 6| Step: 5
Training loss: 2.626728034036817
Validation loss: 2.595295129184594

Epoch: 6| Step: 6
Training loss: 2.789577831883
Validation loss: 2.633782593501844

Epoch: 6| Step: 7
Training loss: 2.1601309748959285
Validation loss: 2.641673047623582

Epoch: 6| Step: 8
Training loss: 2.4473171609260884
Validation loss: 2.6113253663141336

Epoch: 6| Step: 9
Training loss: 2.7869951723328636
Validation loss: 2.5881024426241455

Epoch: 6| Step: 10
Training loss: 2.1404442258365988
Validation loss: 2.537665904144081

Epoch: 6| Step: 11
Training loss: 2.361233314144213
Validation loss: 2.5258724993704003

Epoch: 6| Step: 12
Training loss: 2.5814882477916354
Validation loss: 2.4952313586333643

Epoch: 6| Step: 13
Training loss: 1.949523168120433
Validation loss: 2.477486200551351

Epoch: 139| Step: 0
Training loss: 2.520092710878578
Validation loss: 2.4531663167868034

Epoch: 6| Step: 1
Training loss: 2.0202603527399092
Validation loss: 2.4309497587022135

Epoch: 6| Step: 2
Training loss: 2.560090397490439
Validation loss: 2.416427645745998

Epoch: 6| Step: 3
Training loss: 3.2027651700994637
Validation loss: 2.405031067816792

Epoch: 6| Step: 4
Training loss: 1.8545321057981599
Validation loss: 2.4052435287312015

Epoch: 6| Step: 5
Training loss: 1.9240575043695678
Validation loss: 2.4601489857183916

Epoch: 6| Step: 6
Training loss: 2.692472072445855
Validation loss: 2.463638578137905

Epoch: 6| Step: 7
Training loss: 2.4777707783591145
Validation loss: 2.48047620897994

Epoch: 6| Step: 8
Training loss: 2.3448935198654195
Validation loss: 2.4995374210588626

Epoch: 6| Step: 9
Training loss: 2.4091647441077395
Validation loss: 2.4848483921850955

Epoch: 6| Step: 10
Training loss: 1.9387001504398327
Validation loss: 2.4667041152410647

Epoch: 6| Step: 11
Training loss: 2.0632416518779833
Validation loss: 2.458228682773701

Epoch: 6| Step: 12
Training loss: 2.473174946212903
Validation loss: 2.469827684932592

Epoch: 6| Step: 13
Training loss: 2.772964480183945
Validation loss: 2.4803598765188806

Epoch: 140| Step: 0
Training loss: 2.0244036985685026
Validation loss: 2.4980295978865157

Epoch: 6| Step: 1
Training loss: 2.3187573291426244
Validation loss: 2.5225521774617

Epoch: 6| Step: 2
Training loss: 2.324542880497472
Validation loss: 2.5219478819629053

Epoch: 6| Step: 3
Training loss: 2.416584462927208
Validation loss: 2.5156705914993127

Epoch: 6| Step: 4
Training loss: 2.6735650679241596
Validation loss: 2.505931672475435

Epoch: 6| Step: 5
Training loss: 2.477751437457263
Validation loss: 2.5136524186969864

Epoch: 6| Step: 6
Training loss: 2.0734896482968606
Validation loss: 2.4924318755246833

Epoch: 6| Step: 7
Training loss: 2.8168834858646554
Validation loss: 2.4790895601192453

Epoch: 6| Step: 8
Training loss: 2.139625705892486
Validation loss: 2.481887411951397

Epoch: 6| Step: 9
Training loss: 2.380591786644378
Validation loss: 2.5305503243829923

Epoch: 6| Step: 10
Training loss: 2.888099350591444
Validation loss: 2.526564587957442

Epoch: 6| Step: 11
Training loss: 1.8170512705126487
Validation loss: 2.5502050158118275

Epoch: 6| Step: 12
Training loss: 2.7879779320422253
Validation loss: 2.570336214174276

Epoch: 6| Step: 13
Training loss: 1.7514745766778985
Validation loss: 2.558427647122179

Epoch: 141| Step: 0
Training loss: 2.8764009794010494
Validation loss: 2.5171948793429797

Epoch: 6| Step: 1
Training loss: 1.7104283102044222
Validation loss: 2.458161107310522

Epoch: 6| Step: 2
Training loss: 2.305783596276738
Validation loss: 2.4229209184249996

Epoch: 6| Step: 3
Training loss: 1.6653908455820765
Validation loss: 2.38523568692329

Epoch: 6| Step: 4
Training loss: 2.0518578600741324
Validation loss: 2.3945967005823308

Epoch: 6| Step: 5
Training loss: 2.3519477401947992
Validation loss: 2.3992506907134854

Epoch: 6| Step: 6
Training loss: 2.351957269020909
Validation loss: 2.4235396947388574

Epoch: 6| Step: 7
Training loss: 2.6285981540476375
Validation loss: 2.480417995888029

Epoch: 6| Step: 8
Training loss: 1.4703542186562775
Validation loss: 2.530684664869216

Epoch: 6| Step: 9
Training loss: 2.8372641578836695
Validation loss: 2.5767051080668386

Epoch: 6| Step: 10
Training loss: 2.9949148313101923
Validation loss: 2.578264336970696

Epoch: 6| Step: 11
Training loss: 2.7655874131229377
Validation loss: 2.5414119298952853

Epoch: 6| Step: 12
Training loss: 2.3439880250227807
Validation loss: 2.5184563583298414

Epoch: 6| Step: 13
Training loss: 2.6819128466504667
Validation loss: 2.469207056763339

Epoch: 142| Step: 0
Training loss: 2.4349177449646326
Validation loss: 2.456426371684277

Epoch: 6| Step: 1
Training loss: 1.8393996040754441
Validation loss: 2.4502098853303393

Epoch: 6| Step: 2
Training loss: 2.216411486496116
Validation loss: 2.4616544372924443

Epoch: 6| Step: 3
Training loss: 2.6695495658427033
Validation loss: 2.471438723500001

Epoch: 6| Step: 4
Training loss: 2.5570795368748414
Validation loss: 2.50173746255914

Epoch: 6| Step: 5
Training loss: 2.3314777784570904
Validation loss: 2.5161384644987597

Epoch: 6| Step: 6
Training loss: 2.2699243201861505
Validation loss: 2.5207541390690373

Epoch: 6| Step: 7
Training loss: 2.168121167572936
Validation loss: 2.5183931148812335

Epoch: 6| Step: 8
Training loss: 1.7074068472433714
Validation loss: 2.5392692861604744

Epoch: 6| Step: 9
Training loss: 2.307235188937516
Validation loss: 2.537466036297855

Epoch: 6| Step: 10
Training loss: 2.6105709419014445
Validation loss: 2.549080474636106

Epoch: 6| Step: 11
Training loss: 2.689293373920589
Validation loss: 2.5276961724923828

Epoch: 6| Step: 12
Training loss: 1.6813050753850423
Validation loss: 2.5141726508766413

Epoch: 6| Step: 13
Training loss: 2.3713966942809734
Validation loss: 2.4851166612680387

Epoch: 143| Step: 0
Training loss: 2.6524566491527746
Validation loss: 2.474247257651744

Epoch: 6| Step: 1
Training loss: 1.5497343050978432
Validation loss: 2.475193605860557

Epoch: 6| Step: 2
Training loss: 2.0996720557504256
Validation loss: 2.475161469952413

Epoch: 6| Step: 3
Training loss: 2.4052968304790165
Validation loss: 2.4704796114057914

Epoch: 6| Step: 4
Training loss: 2.828379245521035
Validation loss: 2.469918111370605

Epoch: 6| Step: 5
Training loss: 2.158077626441655
Validation loss: 2.46925967754842

Epoch: 6| Step: 6
Training loss: 2.51731521973855
Validation loss: 2.504399512871142

Epoch: 6| Step: 7
Training loss: 2.134407090131545
Validation loss: 2.520357149187898

Epoch: 6| Step: 8
Training loss: 1.7161132701356483
Validation loss: 2.5551514683562595

Epoch: 6| Step: 9
Training loss: 2.6105238161577002
Validation loss: 2.605456029514659

Epoch: 6| Step: 10
Training loss: 2.358333534627126
Validation loss: 2.6471770923334605

Epoch: 6| Step: 11
Training loss: 2.0839332352631703
Validation loss: 2.623297704847514

Epoch: 6| Step: 12
Training loss: 2.076081497364087
Validation loss: 2.544245826604262

Epoch: 6| Step: 13
Training loss: 2.758004762685535
Validation loss: 2.4916567707129333

Epoch: 144| Step: 0
Training loss: 2.120184884556568
Validation loss: 2.441373103353615

Epoch: 6| Step: 1
Training loss: 2.3276214054949134
Validation loss: 2.426037302391371

Epoch: 6| Step: 2
Training loss: 2.4203696217701025
Validation loss: 2.4728301083919053

Epoch: 6| Step: 3
Training loss: 2.5205886869229177
Validation loss: 2.4925883767927677

Epoch: 6| Step: 4
Training loss: 2.106051277724623
Validation loss: 2.504093838052532

Epoch: 6| Step: 5
Training loss: 2.1691659182257674
Validation loss: 2.5406559989523494

Epoch: 6| Step: 6
Training loss: 1.57420337754688
Validation loss: 2.569589411858615

Epoch: 6| Step: 7
Training loss: 2.494563676985937
Validation loss: 2.631268756322098

Epoch: 6| Step: 8
Training loss: 3.070515633189662
Validation loss: 2.604614743641399

Epoch: 6| Step: 9
Training loss: 2.4021660963911047
Validation loss: 2.5501255290022464

Epoch: 6| Step: 10
Training loss: 1.7804145861660459
Validation loss: 2.517987235089756

Epoch: 6| Step: 11
Training loss: 2.1983027066441654
Validation loss: 2.49865432536477

Epoch: 6| Step: 12
Training loss: 1.5685765934277685
Validation loss: 2.505927767570909

Epoch: 6| Step: 13
Training loss: 2.7013749648266234
Validation loss: 2.507747645346616

Epoch: 145| Step: 0
Training loss: 2.560581885010466
Validation loss: 2.514500187088824

Epoch: 6| Step: 1
Training loss: 2.3732320328678007
Validation loss: 2.537663409870966

Epoch: 6| Step: 2
Training loss: 2.521187077022201
Validation loss: 2.5531024845865766

Epoch: 6| Step: 3
Training loss: 2.3444766126276892
Validation loss: 2.5055606343525336

Epoch: 6| Step: 4
Training loss: 2.1290065916719967
Validation loss: 2.451910974275986

Epoch: 6| Step: 5
Training loss: 2.179198507607575
Validation loss: 2.4338304386809053

Epoch: 6| Step: 6
Training loss: 2.3596522692522113
Validation loss: 2.4091789766720755

Epoch: 6| Step: 7
Training loss: 2.102767315357988
Validation loss: 2.4212110971641505

Epoch: 6| Step: 8
Training loss: 1.9104889188004344
Validation loss: 2.450588698287234

Epoch: 6| Step: 9
Training loss: 2.1892599383018942
Validation loss: 2.484616208622465

Epoch: 6| Step: 10
Training loss: 2.709828438483814
Validation loss: 2.5256690053742616

Epoch: 6| Step: 11
Training loss: 2.3884226309495524
Validation loss: 2.521342380625765

Epoch: 6| Step: 12
Training loss: 2.429786312142399
Validation loss: 2.5012246526608894

Epoch: 6| Step: 13
Training loss: 2.2144581292527024
Validation loss: 2.4946418398833345

Epoch: 146| Step: 0
Training loss: 2.3167654341174013
Validation loss: 2.4998811878151215

Epoch: 6| Step: 1
Training loss: 2.1229029012676133
Validation loss: 2.5301362766060347

Epoch: 6| Step: 2
Training loss: 2.282628100373931
Validation loss: 2.5780898414021767

Epoch: 6| Step: 3
Training loss: 2.2755145780012143
Validation loss: 2.6319426954141316

Epoch: 6| Step: 4
Training loss: 1.9627518486195965
Validation loss: 2.647428116402215

Epoch: 6| Step: 5
Training loss: 1.8637278919200757
Validation loss: 2.651272835445744

Epoch: 6| Step: 6
Training loss: 2.8256913141013635
Validation loss: 2.628650455305035

Epoch: 6| Step: 7
Training loss: 2.084361420319801
Validation loss: 2.6127260150695077

Epoch: 6| Step: 8
Training loss: 2.507967174668091
Validation loss: 2.611148196618637

Epoch: 6| Step: 9
Training loss: 2.0692307435140154
Validation loss: 2.525102904001798

Epoch: 6| Step: 10
Training loss: 2.3863748905197246
Validation loss: 2.44660882060076

Epoch: 6| Step: 11
Training loss: 1.8160665214891312
Validation loss: 2.406993486350932

Epoch: 6| Step: 12
Training loss: 2.2378279674705577
Validation loss: 2.3883726386196074

Epoch: 6| Step: 13
Training loss: 2.2580875638365687
Validation loss: 2.3585255161225778

Epoch: 147| Step: 0
Training loss: 2.191038049782729
Validation loss: 2.3739177535074227

Epoch: 6| Step: 1
Training loss: 2.833070256604559
Validation loss: 2.374949965843181

Epoch: 6| Step: 2
Training loss: 2.5060096987013742
Validation loss: 2.3941422138921555

Epoch: 6| Step: 3
Training loss: 2.7268540191018107
Validation loss: 2.423943980774193

Epoch: 6| Step: 4
Training loss: 2.2363192762174826
Validation loss: 2.441371590185761

Epoch: 6| Step: 5
Training loss: 1.885996235941815
Validation loss: 2.445328008780845

Epoch: 6| Step: 6
Training loss: 1.4829316198901483
Validation loss: 2.49399212076563

Epoch: 6| Step: 7
Training loss: 2.087017337027
Validation loss: 2.5323535858587443

Epoch: 6| Step: 8
Training loss: 2.2973851266728373
Validation loss: 2.565747537981943

Epoch: 6| Step: 9
Training loss: 2.193861295045102
Validation loss: 2.5910418551359715

Epoch: 6| Step: 10
Training loss: 2.0789027085358316
Validation loss: 2.578566391177211

Epoch: 6| Step: 11
Training loss: 2.027582231728444
Validation loss: 2.585434463726751

Epoch: 6| Step: 12
Training loss: 2.0048168113907834
Validation loss: 2.6145775750837137

Epoch: 6| Step: 13
Training loss: 1.5912577271854464
Validation loss: 2.5950141877092334

Epoch: 148| Step: 0
Training loss: 2.265945306695325
Validation loss: 2.5472074204029425

Epoch: 6| Step: 1
Training loss: 2.3680382134730746
Validation loss: 2.510117987700792

Epoch: 6| Step: 2
Training loss: 2.4825703526234855
Validation loss: 2.497919145714056

Epoch: 6| Step: 3
Training loss: 2.1548255970209422
Validation loss: 2.4432059583867733

Epoch: 6| Step: 4
Training loss: 2.286173276286499
Validation loss: 2.4188131369255985

Epoch: 6| Step: 5
Training loss: 2.5385346318772157
Validation loss: 2.420493499795123

Epoch: 6| Step: 6
Training loss: 2.279895641715971
Validation loss: 2.404688467636052

Epoch: 6| Step: 7
Training loss: 2.141443249321232
Validation loss: 2.424377303566916

Epoch: 6| Step: 8
Training loss: 1.9511770070784609
Validation loss: 2.4059601379969338

Epoch: 6| Step: 9
Training loss: 1.6424039369590757
Validation loss: 2.415920170562373

Epoch: 6| Step: 10
Training loss: 2.4295597349471096
Validation loss: 2.4148690288512835

Epoch: 6| Step: 11
Training loss: 1.6951455592218219
Validation loss: 2.4395756325668025

Epoch: 6| Step: 12
Training loss: 1.927091017699171
Validation loss: 2.4758118894310948

Epoch: 6| Step: 13
Training loss: 1.7714816159665325
Validation loss: 2.508098105696412

Epoch: 149| Step: 0
Training loss: 1.926032059684906
Validation loss: 2.5739488111123716

Epoch: 6| Step: 1
Training loss: 2.620214914723756
Validation loss: 2.6420698199152404

Epoch: 6| Step: 2
Training loss: 2.1142399952338167
Validation loss: 2.6890152086544257

Epoch: 6| Step: 3
Training loss: 1.953710666585162
Validation loss: 2.6946994992165343

Epoch: 6| Step: 4
Training loss: 1.6274014847760732
Validation loss: 2.676895160524861

Epoch: 6| Step: 5
Training loss: 1.9769225263837444
Validation loss: 2.64458429279081

Epoch: 6| Step: 6
Training loss: 2.0322733722008683
Validation loss: 2.5864274063062966

Epoch: 6| Step: 7
Training loss: 1.9136796840953012
Validation loss: 2.525718266537829

Epoch: 6| Step: 8
Training loss: 2.0303335616698717
Validation loss: 2.4756262953752626

Epoch: 6| Step: 9
Training loss: 2.133059085662478
Validation loss: 2.4287804965950723

Epoch: 6| Step: 10
Training loss: 2.36569962780652
Validation loss: 2.4027637892492195

Epoch: 6| Step: 11
Training loss: 2.3505965875654558
Validation loss: 2.38143404138886

Epoch: 6| Step: 12
Training loss: 2.253237937604614
Validation loss: 2.366481650184794

Epoch: 6| Step: 13
Training loss: 2.6216023572765064
Validation loss: 2.3662433027941225

Epoch: 150| Step: 0
Training loss: 2.4428217576188094
Validation loss: 2.373865157593832

Epoch: 6| Step: 1
Training loss: 1.3075137108107624
Validation loss: 2.3762872582800694

Epoch: 6| Step: 2
Training loss: 1.8836276873676283
Validation loss: 2.382717664994302

Epoch: 6| Step: 3
Training loss: 2.332789210045485
Validation loss: 2.4188079085544065

Epoch: 6| Step: 4
Training loss: 2.208208428455289
Validation loss: 2.431339597644621

Epoch: 6| Step: 5
Training loss: 2.337393112594708
Validation loss: 2.4408825347637575

Epoch: 6| Step: 6
Training loss: 1.5640650731083667
Validation loss: 2.472516954578849

Epoch: 6| Step: 7
Training loss: 2.216018499772285
Validation loss: 2.468383097198666

Epoch: 6| Step: 8
Training loss: 1.6746548510552746
Validation loss: 2.4692424388440077

Epoch: 6| Step: 9
Training loss: 2.0671590720922994
Validation loss: 2.4780320049059994

Epoch: 6| Step: 10
Training loss: 2.0403855514828444
Validation loss: 2.5041430199501225

Epoch: 6| Step: 11
Training loss: 2.460074137059016
Validation loss: 2.5567989333724968

Epoch: 6| Step: 12
Training loss: 2.5492760509489063
Validation loss: 2.5972255584442094

Epoch: 6| Step: 13
Training loss: 2.05332884451553
Validation loss: 2.6142424909664954

Epoch: 151| Step: 0
Training loss: 2.0909342264843347
Validation loss: 2.614663049371401

Epoch: 6| Step: 1
Training loss: 1.9773092555515548
Validation loss: 2.5407911884459398

Epoch: 6| Step: 2
Training loss: 1.8830943549568646
Validation loss: 2.4698130773461706

Epoch: 6| Step: 3
Training loss: 2.0808442187021363
Validation loss: 2.4205226121915775

Epoch: 6| Step: 4
Training loss: 2.2063373926592873
Validation loss: 2.3873487823553496

Epoch: 6| Step: 5
Training loss: 2.168222553415054
Validation loss: 2.370415302711471

Epoch: 6| Step: 6
Training loss: 2.270990897028966
Validation loss: 2.3534473108190697

Epoch: 6| Step: 7
Training loss: 2.1460695846524667
Validation loss: 2.3599271312293437

Epoch: 6| Step: 8
Training loss: 1.4564257634393145
Validation loss: 2.3745778328721743

Epoch: 6| Step: 9
Training loss: 2.502877867806335
Validation loss: 2.3973197035782507

Epoch: 6| Step: 10
Training loss: 1.9431148509401321
Validation loss: 2.4240157347528237

Epoch: 6| Step: 11
Training loss: 2.394218586209247
Validation loss: 2.476578663984509

Epoch: 6| Step: 12
Training loss: 2.52177246717268
Validation loss: 2.502622711456784

Epoch: 6| Step: 13
Training loss: 1.6269581807253755
Validation loss: 2.553104301052734

Epoch: 152| Step: 0
Training loss: 2.1115911074726257
Validation loss: 2.5816976216182845

Epoch: 6| Step: 1
Training loss: 2.1557300327689757
Validation loss: 2.6047679100407897

Epoch: 6| Step: 2
Training loss: 1.9874932127062948
Validation loss: 2.612925526314777

Epoch: 6| Step: 3
Training loss: 1.9275054331899577
Validation loss: 2.600951871807341

Epoch: 6| Step: 4
Training loss: 1.6929809429044733
Validation loss: 2.5821142661287233

Epoch: 6| Step: 5
Training loss: 2.368627733280852
Validation loss: 2.5405497875003

Epoch: 6| Step: 6
Training loss: 2.0923482273348175
Validation loss: 2.4998878248746137

Epoch: 6| Step: 7
Training loss: 2.2320814832696683
Validation loss: 2.4704813137679538

Epoch: 6| Step: 8
Training loss: 2.3479395741448394
Validation loss: 2.460625535262164

Epoch: 6| Step: 9
Training loss: 1.960395768554517
Validation loss: 2.4381183400554076

Epoch: 6| Step: 10
Training loss: 2.117321953252066
Validation loss: 2.4560063599256328

Epoch: 6| Step: 11
Training loss: 1.9953432109145162
Validation loss: 2.4650453149304963

Epoch: 6| Step: 12
Training loss: 1.7020274834436673
Validation loss: 2.4464487764903398

Epoch: 6| Step: 13
Training loss: 1.9345958232401144
Validation loss: 2.4847435306731263

Epoch: 153| Step: 0
Training loss: 1.9655008298046812
Validation loss: 2.495282743288382

Epoch: 6| Step: 1
Training loss: 2.3470358639785966
Validation loss: 2.516448404702412

Epoch: 6| Step: 2
Training loss: 1.9991957120175454
Validation loss: 2.5279864084224464

Epoch: 6| Step: 3
Training loss: 2.509626926493391
Validation loss: 2.549427731357012

Epoch: 6| Step: 4
Training loss: 2.246911153913644
Validation loss: 2.5841203672283464

Epoch: 6| Step: 5
Training loss: 2.2703949274693307
Validation loss: 2.5071367706573593

Epoch: 6| Step: 6
Training loss: 2.195277746611035
Validation loss: 2.482937879624693

Epoch: 6| Step: 7
Training loss: 1.6201735493040559
Validation loss: 2.4738530577111764

Epoch: 6| Step: 8
Training loss: 1.8173937010605437
Validation loss: 2.466077280185963

Epoch: 6| Step: 9
Training loss: 1.963468825172199
Validation loss: 2.454459510907362

Epoch: 6| Step: 10
Training loss: 1.7569872466022343
Validation loss: 2.447545083634287

Epoch: 6| Step: 11
Training loss: 1.921469668932911
Validation loss: 2.4301834531423943

Epoch: 6| Step: 12
Training loss: 1.4523193422988556
Validation loss: 2.435782329821339

Epoch: 6| Step: 13
Training loss: 1.67933054835013
Validation loss: 2.4348981700125085

Epoch: 154| Step: 0
Training loss: 1.8315449864400044
Validation loss: 2.465743171901002

Epoch: 6| Step: 1
Training loss: 2.3552303668046983
Validation loss: 2.467574987803795

Epoch: 6| Step: 2
Training loss: 1.5592522246011729
Validation loss: 2.487152032439278

Epoch: 6| Step: 3
Training loss: 2.155432615291817
Validation loss: 2.4959582882711624

Epoch: 6| Step: 4
Training loss: 1.8250785288180176
Validation loss: 2.4992343940321273

Epoch: 6| Step: 5
Training loss: 2.3922444760983046
Validation loss: 2.5126592671950707

Epoch: 6| Step: 6
Training loss: 1.648353610683852
Validation loss: 2.5140623481024553

Epoch: 6| Step: 7
Training loss: 1.8789945014641722
Validation loss: 2.5372183979665976

Epoch: 6| Step: 8
Training loss: 1.3551263294239841
Validation loss: 2.5347781359235473

Epoch: 6| Step: 9
Training loss: 2.0336347226306675
Validation loss: 2.5348966312532135

Epoch: 6| Step: 10
Training loss: 1.8553797007825454
Validation loss: 2.5475938744877613

Epoch: 6| Step: 11
Training loss: 2.149440683757224
Validation loss: 2.5124810394565915

Epoch: 6| Step: 12
Training loss: 2.6031647751277798
Validation loss: 2.5280919734103127

Epoch: 6| Step: 13
Training loss: 1.4470541692742835
Validation loss: 2.4913343157977126

Epoch: 155| Step: 0
Training loss: 1.753576234894715
Validation loss: 2.4614001652886417

Epoch: 6| Step: 1
Training loss: 1.6025303591085642
Validation loss: 2.4592902334026947

Epoch: 6| Step: 2
Training loss: 2.1562820653327983
Validation loss: 2.44685819140723

Epoch: 6| Step: 3
Training loss: 1.628966991289178
Validation loss: 2.4590142462696547

Epoch: 6| Step: 4
Training loss: 2.6483696222749886
Validation loss: 2.48405867497799

Epoch: 6| Step: 5
Training loss: 1.409644332492027
Validation loss: 2.4687736565134184

Epoch: 6| Step: 6
Training loss: 2.316969392971938
Validation loss: 2.4629641057081884

Epoch: 6| Step: 7
Training loss: 2.0201837603389228
Validation loss: 2.4813338989429132

Epoch: 6| Step: 8
Training loss: 1.9366016150933767
Validation loss: 2.4998556987586205

Epoch: 6| Step: 9
Training loss: 2.2219239220149207
Validation loss: 2.534872040418369

Epoch: 6| Step: 10
Training loss: 1.678876175218321
Validation loss: 2.552111905314511

Epoch: 6| Step: 11
Training loss: 1.9892234143825778
Validation loss: 2.540491756152042

Epoch: 6| Step: 12
Training loss: 1.7797688801339109
Validation loss: 2.5690381068508192

Epoch: 6| Step: 13
Training loss: 1.460105455065109
Validation loss: 2.5888467970634164

Epoch: 156| Step: 0
Training loss: 1.976336439873479
Validation loss: 2.5755572287478907

Epoch: 6| Step: 1
Training loss: 2.2250431699529556
Validation loss: 2.5706415365681563

Epoch: 6| Step: 2
Training loss: 1.7767987767688949
Validation loss: 2.547558255286755

Epoch: 6| Step: 3
Training loss: 1.8123760838735907
Validation loss: 2.5360580168527997

Epoch: 6| Step: 4
Training loss: 1.5050836091247333
Validation loss: 2.4947985210723163

Epoch: 6| Step: 5
Training loss: 2.15108523813474
Validation loss: 2.4611092112493504

Epoch: 6| Step: 6
Training loss: 2.1752030376507117
Validation loss: 2.4588867518421926

Epoch: 6| Step: 7
Training loss: 1.8372045162611355
Validation loss: 2.451322138776319

Epoch: 6| Step: 8
Training loss: 2.0321214420493714
Validation loss: 2.4253439256484963

Epoch: 6| Step: 9
Training loss: 1.8699832559539717
Validation loss: 2.4228607278213623

Epoch: 6| Step: 10
Training loss: 1.6126561466287603
Validation loss: 2.412891905241868

Epoch: 6| Step: 11
Training loss: 2.071382756971513
Validation loss: 2.4177932793541097

Epoch: 6| Step: 12
Training loss: 2.096778160167189
Validation loss: 2.420873748722636

Epoch: 6| Step: 13
Training loss: 1.228535177442156
Validation loss: 2.4125970840366255

Epoch: 157| Step: 0
Training loss: 1.9221139154565474
Validation loss: 2.424528591436067

Epoch: 6| Step: 1
Training loss: 2.033925685691533
Validation loss: 2.4368484631773613

Epoch: 6| Step: 2
Training loss: 1.832589135701824
Validation loss: 2.4506698757834493

Epoch: 6| Step: 3
Training loss: 2.2227710231653055
Validation loss: 2.474972500052198

Epoch: 6| Step: 4
Training loss: 1.8087935203478365
Validation loss: 2.5022414086049967

Epoch: 6| Step: 5
Training loss: 1.7123465810397827
Validation loss: 2.530870296469515

Epoch: 6| Step: 6
Training loss: 2.245837918514556
Validation loss: 2.527963383090697

Epoch: 6| Step: 7
Training loss: 2.0126379783197232
Validation loss: 2.479933948723908

Epoch: 6| Step: 8
Training loss: 1.7714497858306575
Validation loss: 2.460860200088859

Epoch: 6| Step: 9
Training loss: 1.8459788928824536
Validation loss: 2.455058617856627

Epoch: 6| Step: 10
Training loss: 1.8557704961262322
Validation loss: 2.443704782615289

Epoch: 6| Step: 11
Training loss: 1.8779427006707536
Validation loss: 2.455175497588577

Epoch: 6| Step: 12
Training loss: 1.3708249342099705
Validation loss: 2.458361956257849

Epoch: 6| Step: 13
Training loss: 1.8919877744646647
Validation loss: 2.4723105434605848

Epoch: 158| Step: 0
Training loss: 1.7294981152407591
Validation loss: 2.501725364913743

Epoch: 6| Step: 1
Training loss: 1.7531208412270678
Validation loss: 2.512406019268237

Epoch: 6| Step: 2
Training loss: 1.71884626639144
Validation loss: 2.542001248498831

Epoch: 6| Step: 3
Training loss: 2.135878821503909
Validation loss: 2.596767629632824

Epoch: 6| Step: 4
Training loss: 1.6043065823395288
Validation loss: 2.5358379941518048

Epoch: 6| Step: 5
Training loss: 2.2514578017300684
Validation loss: 2.5345622209736196

Epoch: 6| Step: 6
Training loss: 1.4138236081146636
Validation loss: 2.493527101020118

Epoch: 6| Step: 7
Training loss: 2.0321967632816422
Validation loss: 2.4753067115756515

Epoch: 6| Step: 8
Training loss: 1.6293460243144986
Validation loss: 2.4574998499741807

Epoch: 6| Step: 9
Training loss: 2.130453181166184
Validation loss: 2.4567889150088775

Epoch: 6| Step: 10
Training loss: 2.072917177848817
Validation loss: 2.462636861646314

Epoch: 6| Step: 11
Training loss: 1.2219003894246148
Validation loss: 2.447772065558485

Epoch: 6| Step: 12
Training loss: 2.1292354784133622
Validation loss: 2.4441083915464437

Epoch: 6| Step: 13
Training loss: 1.997911554939273
Validation loss: 2.4534487469199044

Epoch: 159| Step: 0
Training loss: 2.0421976709440917
Validation loss: 2.4614646762360004

Epoch: 6| Step: 1
Training loss: 1.5780870791874226
Validation loss: 2.4480700669740063

Epoch: 6| Step: 2
Training loss: 2.120722448401845
Validation loss: 2.4502460868456644

Epoch: 6| Step: 3
Training loss: 2.217845678727643
Validation loss: 2.467509368036892

Epoch: 6| Step: 4
Training loss: 1.710087255739078
Validation loss: 2.4923870603272102

Epoch: 6| Step: 5
Training loss: 1.9950076020366032
Validation loss: 2.519112777711875

Epoch: 6| Step: 6
Training loss: 1.8837323612837769
Validation loss: 2.5313544475275442

Epoch: 6| Step: 7
Training loss: 1.4577726467037098
Validation loss: 2.5426968410455877

Epoch: 6| Step: 8
Training loss: 1.5572447328501393
Validation loss: 2.536010312146403

Epoch: 6| Step: 9
Training loss: 2.1344608183513007
Validation loss: 2.5051419405355637

Epoch: 6| Step: 10
Training loss: 1.9216224070224874
Validation loss: 2.4918901171737633

Epoch: 6| Step: 11
Training loss: 1.6950565267944075
Validation loss: 2.4421525950934386

Epoch: 6| Step: 12
Training loss: 1.760185030834383
Validation loss: 2.4288261471319714

Epoch: 6| Step: 13
Training loss: 1.4326148575943904
Validation loss: 2.418662319367869

Epoch: 160| Step: 0
Training loss: 1.8352898287237551
Validation loss: 2.413384663341851

Epoch: 6| Step: 1
Training loss: 1.3851725810250624
Validation loss: 2.4249206446256704

Epoch: 6| Step: 2
Training loss: 1.1162019664173615
Validation loss: 2.4228567514601527

Epoch: 6| Step: 3
Training loss: 2.0674658440163687
Validation loss: 2.409625386393188

Epoch: 6| Step: 4
Training loss: 1.7306274616834243
Validation loss: 2.435133338037259

Epoch: 6| Step: 5
Training loss: 2.0067938807180723
Validation loss: 2.4664918097429913

Epoch: 6| Step: 6
Training loss: 1.7520574328140697
Validation loss: 2.504681459649803

Epoch: 6| Step: 7
Training loss: 1.6372807159361797
Validation loss: 2.5399603284438306

Epoch: 6| Step: 8
Training loss: 2.2634018086041157
Validation loss: 2.5747627635660746

Epoch: 6| Step: 9
Training loss: 1.7695631820121758
Validation loss: 2.559659310258013

Epoch: 6| Step: 10
Training loss: 1.8267629391065934
Validation loss: 2.505999928037096

Epoch: 6| Step: 11
Training loss: 2.1343813984050324
Validation loss: 2.470591468789674

Epoch: 6| Step: 12
Training loss: 1.8587443460302808
Validation loss: 2.4096503383018395

Epoch: 6| Step: 13
Training loss: 2.015544564468229
Validation loss: 2.394448737791972

Epoch: 161| Step: 0
Training loss: 1.9686705558127848
Validation loss: 2.3845910546128724

Epoch: 6| Step: 1
Training loss: 2.27820519828133
Validation loss: 2.3919622032719596

Epoch: 6| Step: 2
Training loss: 1.9904824533731211
Validation loss: 2.43181523984601

Epoch: 6| Step: 3
Training loss: 1.8110557589949352
Validation loss: 2.4627482778648657

Epoch: 6| Step: 4
Training loss: 1.3828206035139503
Validation loss: 2.4986596298232064

Epoch: 6| Step: 5
Training loss: 1.6245514910971435
Validation loss: 2.5501620482658978

Epoch: 6| Step: 6
Training loss: 1.828336850142364
Validation loss: 2.579226746478055

Epoch: 6| Step: 7
Training loss: 1.8495043167843526
Validation loss: 2.5773402039120175

Epoch: 6| Step: 8
Training loss: 1.719836706460895
Validation loss: 2.5519182420932363

Epoch: 6| Step: 9
Training loss: 1.6438434820825263
Validation loss: 2.5405727774690923

Epoch: 6| Step: 10
Training loss: 1.588114179614128
Validation loss: 2.5457568053937787

Epoch: 6| Step: 11
Training loss: 1.4881225661538644
Validation loss: 2.552882141370302

Epoch: 6| Step: 12
Training loss: 2.081198004912227
Validation loss: 2.5012198866194626

Epoch: 6| Step: 13
Training loss: 1.988087343005017
Validation loss: 2.460833207782203

Epoch: 162| Step: 0
Training loss: 1.7935214385513245
Validation loss: 2.409123196244178

Epoch: 6| Step: 1
Training loss: 2.0846368399302864
Validation loss: 2.3834120947022215

Epoch: 6| Step: 2
Training loss: 1.5542306660147143
Validation loss: 2.3686055475438907

Epoch: 6| Step: 3
Training loss: 2.1477789962066933
Validation loss: 2.36607023384549

Epoch: 6| Step: 4
Training loss: 1.594589461105583
Validation loss: 2.3601989111580832

Epoch: 6| Step: 5
Training loss: 1.9972344589860693
Validation loss: 2.3673244054839566

Epoch: 6| Step: 6
Training loss: 1.9154380371061133
Validation loss: 2.399327674005814

Epoch: 6| Step: 7
Training loss: 1.6233516549258626
Validation loss: 2.409324354707725

Epoch: 6| Step: 8
Training loss: 2.20489701235988
Validation loss: 2.4508911348560525

Epoch: 6| Step: 9
Training loss: 1.4023580736369157
Validation loss: 2.5420581889944645

Epoch: 6| Step: 10
Training loss: 1.4952404487175972
Validation loss: 2.6282839335099504

Epoch: 6| Step: 11
Training loss: 1.8917517969186708
Validation loss: 2.641589895276517

Epoch: 6| Step: 12
Training loss: 1.869097128175645
Validation loss: 2.5925611590100908

Epoch: 6| Step: 13
Training loss: 1.44242529267379
Validation loss: 2.5521467075846123

Epoch: 163| Step: 0
Training loss: 1.7378833786892014
Validation loss: 2.5233483554814873

Epoch: 6| Step: 1
Training loss: 1.976293130846733
Validation loss: 2.4800645693544907

Epoch: 6| Step: 2
Training loss: 2.092369535474013
Validation loss: 2.4568234460177063

Epoch: 6| Step: 3
Training loss: 1.4272830108764682
Validation loss: 2.3957520380624127

Epoch: 6| Step: 4
Training loss: 1.4586442706732576
Validation loss: 2.350925062494743

Epoch: 6| Step: 5
Training loss: 1.9191699335774708
Validation loss: 2.3345705486399235

Epoch: 6| Step: 6
Training loss: 2.2003188422379436
Validation loss: 2.3398272456770473

Epoch: 6| Step: 7
Training loss: 1.6897395778650088
Validation loss: 2.3832376252495755

Epoch: 6| Step: 8
Training loss: 1.7996963244813171
Validation loss: 2.4463349747381065

Epoch: 6| Step: 9
Training loss: 2.308744319130146
Validation loss: 2.553668216172375

Epoch: 6| Step: 10
Training loss: 1.6937578517830358
Validation loss: 2.581316326909769

Epoch: 6| Step: 11
Training loss: 1.7268069685389993
Validation loss: 2.6148190380873024

Epoch: 6| Step: 12
Training loss: 1.6159760733806579
Validation loss: 2.631974895322534

Epoch: 6| Step: 13
Training loss: 2.250586645153874
Validation loss: 2.638937695333806

Epoch: 164| Step: 0
Training loss: 2.077689333113905
Validation loss: 2.55856679078526

Epoch: 6| Step: 1
Training loss: 1.8883468521837352
Validation loss: 2.517402494319291

Epoch: 6| Step: 2
Training loss: 1.6522078221461836
Validation loss: 2.456129065786147

Epoch: 6| Step: 3
Training loss: 1.7625779723106525
Validation loss: 2.409936683199862

Epoch: 6| Step: 4
Training loss: 1.535224194758139
Validation loss: 2.388611225980208

Epoch: 6| Step: 5
Training loss: 1.3557268056459368
Validation loss: 2.3671863910178743

Epoch: 6| Step: 6
Training loss: 1.8565572978783003
Validation loss: 2.3620926471027817

Epoch: 6| Step: 7
Training loss: 2.0688224756735534
Validation loss: 2.371081226899184

Epoch: 6| Step: 8
Training loss: 1.7541008992072291
Validation loss: 2.379080765544074

Epoch: 6| Step: 9
Training loss: 1.5055289889420262
Validation loss: 2.432719487861786

Epoch: 6| Step: 10
Training loss: 1.3654227065479623
Validation loss: 2.4423168313014503

Epoch: 6| Step: 11
Training loss: 1.456665156703373
Validation loss: 2.4454260070513487

Epoch: 6| Step: 12
Training loss: 1.9313119082111248
Validation loss: 2.4678396693819638

Epoch: 6| Step: 13
Training loss: 2.4965227740406677
Validation loss: 2.511150814590955

Epoch: 165| Step: 0
Training loss: 1.7146422109155155
Validation loss: 2.5429489623662866

Epoch: 6| Step: 1
Training loss: 1.6187967595597004
Validation loss: 2.5633810826112673

Epoch: 6| Step: 2
Training loss: 1.5802649162420113
Validation loss: 2.599985764498427

Epoch: 6| Step: 3
Training loss: 2.3152793471858577
Validation loss: 2.6458308463988867

Epoch: 6| Step: 4
Training loss: 1.5840841654659734
Validation loss: 2.58466363872183

Epoch: 6| Step: 5
Training loss: 1.9367991379600034
Validation loss: 2.508545212495773

Epoch: 6| Step: 6
Training loss: 1.2891175691806023
Validation loss: 2.4358751725529593

Epoch: 6| Step: 7
Training loss: 1.390779293801638
Validation loss: 2.4205293598797177

Epoch: 6| Step: 8
Training loss: 1.8000093406858744
Validation loss: 2.3660698437849197

Epoch: 6| Step: 9
Training loss: 1.8122401873406706
Validation loss: 2.354955874340718

Epoch: 6| Step: 10
Training loss: 1.4976118468227662
Validation loss: 2.353571172246031

Epoch: 6| Step: 11
Training loss: 1.6767718181791667
Validation loss: 2.331460830606635

Epoch: 6| Step: 12
Training loss: 2.352120266791365
Validation loss: 2.323557778792486

Epoch: 6| Step: 13
Training loss: 1.744075351019086
Validation loss: 2.347818547258729

Epoch: 166| Step: 0
Training loss: 1.8502469439265457
Validation loss: 2.384995917010646

Epoch: 6| Step: 1
Training loss: 1.8688916206919486
Validation loss: 2.434126591291788

Epoch: 6| Step: 2
Training loss: 1.0625865564431807
Validation loss: 2.4775486815439316

Epoch: 6| Step: 3
Training loss: 1.5181451668465795
Validation loss: 2.5531800412192327

Epoch: 6| Step: 4
Training loss: 2.1946720804647524
Validation loss: 2.57777851619163

Epoch: 6| Step: 5
Training loss: 1.964430293422514
Validation loss: 2.642665100448952

Epoch: 6| Step: 6
Training loss: 1.7729957467300856
Validation loss: 2.599663114454154

Epoch: 6| Step: 7
Training loss: 1.9279232222516582
Validation loss: 2.5506622865113293

Epoch: 6| Step: 8
Training loss: 1.3307955203400303
Validation loss: 2.526583123455703

Epoch: 6| Step: 9
Training loss: 1.8612702271622215
Validation loss: 2.4627260791353263

Epoch: 6| Step: 10
Training loss: 1.4597644686471036
Validation loss: 2.4442813464009925

Epoch: 6| Step: 11
Training loss: 1.483473333259875
Validation loss: 2.4095330866618987

Epoch: 6| Step: 12
Training loss: 1.8150353950012716
Validation loss: 2.389977500090683

Epoch: 6| Step: 13
Training loss: 2.002685412944383
Validation loss: 2.3820527908310742

Epoch: 167| Step: 0
Training loss: 1.1390673832206553
Validation loss: 2.404821581579483

Epoch: 6| Step: 1
Training loss: 1.2680492025390082
Validation loss: 2.4252857433170756

Epoch: 6| Step: 2
Training loss: 1.2565665382409543
Validation loss: 2.4984115291714684

Epoch: 6| Step: 3
Training loss: 2.1955911588463364
Validation loss: 2.565138384237518

Epoch: 6| Step: 4
Training loss: 1.8753161481717882
Validation loss: 2.5768263443723907

Epoch: 6| Step: 5
Training loss: 1.998672998792828
Validation loss: 2.5171895833901563

Epoch: 6| Step: 6
Training loss: 1.8376175356272788
Validation loss: 2.4844475243672526

Epoch: 6| Step: 7
Training loss: 1.7104678271406057
Validation loss: 2.4677318229899723

Epoch: 6| Step: 8
Training loss: 1.48476926687226
Validation loss: 2.4539958682229

Epoch: 6| Step: 9
Training loss: 1.6376233935274376
Validation loss: 2.4533002999899804

Epoch: 6| Step: 10
Training loss: 1.9637381930029698
Validation loss: 2.4510933592554163

Epoch: 6| Step: 11
Training loss: 1.7337046522000743
Validation loss: 2.461926968587681

Epoch: 6| Step: 12
Training loss: 1.6470207888154549
Validation loss: 2.432370622091234

Epoch: 6| Step: 13
Training loss: 1.768943436360383
Validation loss: 2.455609326771568

Epoch: 168| Step: 0
Training loss: 1.7733230890011609
Validation loss: 2.461122404887855

Epoch: 6| Step: 1
Training loss: 1.7931268493493888
Validation loss: 2.4769633475884825

Epoch: 6| Step: 2
Training loss: 1.7830847944292374
Validation loss: 2.493183298233854

Epoch: 6| Step: 3
Training loss: 1.3628322441212106
Validation loss: 2.499764704142383

Epoch: 6| Step: 4
Training loss: 0.88998456984442
Validation loss: 2.4691214229489

Epoch: 6| Step: 5
Training loss: 2.1037286988764885
Validation loss: 2.468933449644405

Epoch: 6| Step: 6
Training loss: 1.025618987312801
Validation loss: 2.4409840759815102

Epoch: 6| Step: 7
Training loss: 1.9095553523668938
Validation loss: 2.41021720035466

Epoch: 6| Step: 8
Training loss: 2.095911874177936
Validation loss: 2.4156188981322564

Epoch: 6| Step: 9
Training loss: 1.3201572846137593
Validation loss: 2.4145555564497787

Epoch: 6| Step: 10
Training loss: 1.9210903768056053
Validation loss: 2.3918217625822678

Epoch: 6| Step: 11
Training loss: 1.6046298543201827
Validation loss: 2.4087501176591557

Epoch: 6| Step: 12
Training loss: 1.507699517479101
Validation loss: 2.421187220525949

Epoch: 6| Step: 13
Training loss: 1.4891270114177746
Validation loss: 2.4127681671333843

Epoch: 169| Step: 0
Training loss: 1.9252823808317476
Validation loss: 2.4283258485513675

Epoch: 6| Step: 1
Training loss: 1.6601902857264756
Validation loss: 2.471522844552432

Epoch: 6| Step: 2
Training loss: 1.4014671369789962
Validation loss: 2.5199875931142213

Epoch: 6| Step: 3
Training loss: 1.9295733336989476
Validation loss: 2.521725891091011

Epoch: 6| Step: 4
Training loss: 1.2733394374418163
Validation loss: 2.5357784234160197

Epoch: 6| Step: 5
Training loss: 1.1750929329015642
Validation loss: 2.522494772771879

Epoch: 6| Step: 6
Training loss: 1.7489196985130346
Validation loss: 2.523552519155722

Epoch: 6| Step: 7
Training loss: 1.2434352150527197
Validation loss: 2.4590170976370604

Epoch: 6| Step: 8
Training loss: 1.499887939081939
Validation loss: 2.4529625550354575

Epoch: 6| Step: 9
Training loss: 1.8677357782438482
Validation loss: 2.440475921638705

Epoch: 6| Step: 10
Training loss: 1.8115627233147462
Validation loss: 2.4217231186828108

Epoch: 6| Step: 11
Training loss: 1.7439199822818852
Validation loss: 2.4242728772425677

Epoch: 6| Step: 12
Training loss: 1.8050473997914223
Validation loss: 2.418736987916143

Epoch: 6| Step: 13
Training loss: 1.3481447523117576
Validation loss: 2.4271051760694142

Epoch: 170| Step: 0
Training loss: 1.4368832965360756
Validation loss: 2.4338503993117104

Epoch: 6| Step: 1
Training loss: 1.718620156672184
Validation loss: 2.4354005780136823

Epoch: 6| Step: 2
Training loss: 1.3141597970328613
Validation loss: 2.429896555883515

Epoch: 6| Step: 3
Training loss: 1.6763090711820046
Validation loss: 2.459702348507128

Epoch: 6| Step: 4
Training loss: 1.2161949959183864
Validation loss: 2.477249973970263

Epoch: 6| Step: 5
Training loss: 1.4490944534013441
Validation loss: 2.4726349831446273

Epoch: 6| Step: 6
Training loss: 1.7090604754261742
Validation loss: 2.47435745793391

Epoch: 6| Step: 7
Training loss: 1.5875572614780482
Validation loss: 2.4686717816307833

Epoch: 6| Step: 8
Training loss: 1.327530357530976
Validation loss: 2.4648330189263428

Epoch: 6| Step: 9
Training loss: 2.431474034987543
Validation loss: 2.419549153747003

Epoch: 6| Step: 10
Training loss: 1.584860374847141
Validation loss: 2.3790964361432807

Epoch: 6| Step: 11
Training loss: 1.8150585794584826
Validation loss: 2.3741129172192452

Epoch: 6| Step: 12
Training loss: 1.658906138358032
Validation loss: 2.3697518629436263

Epoch: 6| Step: 13
Training loss: 1.4546386874457156
Validation loss: 2.376569257554287

Epoch: 171| Step: 0
Training loss: 1.61772375383988
Validation loss: 2.3906034816754986

Epoch: 6| Step: 1
Training loss: 1.408966154018238
Validation loss: 2.4491554834711864

Epoch: 6| Step: 2
Training loss: 1.248404056258672
Validation loss: 2.49367091518957

Epoch: 6| Step: 3
Training loss: 1.7427568403456442
Validation loss: 2.521524743497871

Epoch: 6| Step: 4
Training loss: 1.1793217376180605
Validation loss: 2.5608366503191697

Epoch: 6| Step: 5
Training loss: 1.0490152486887434
Validation loss: 2.5583689185289047

Epoch: 6| Step: 6
Training loss: 1.5343300340826804
Validation loss: 2.528565336587538

Epoch: 6| Step: 7
Training loss: 1.9035894243795055
Validation loss: 2.542509132680461

Epoch: 6| Step: 8
Training loss: 1.6466468377920764
Validation loss: 2.4852648324498388

Epoch: 6| Step: 9
Training loss: 1.485826124315358
Validation loss: 2.4549420677731186

Epoch: 6| Step: 10
Training loss: 2.282093049087259
Validation loss: 2.4357367975532176

Epoch: 6| Step: 11
Training loss: 1.923871375822518
Validation loss: 2.4095508131914696

Epoch: 6| Step: 12
Training loss: 1.4777863289929045
Validation loss: 2.399703984480615

Epoch: 6| Step: 13
Training loss: 1.0956989363048
Validation loss: 2.3991076472570443

Epoch: 172| Step: 0
Training loss: 1.4371156593345031
Validation loss: 2.378312198158021

Epoch: 6| Step: 1
Training loss: 1.8085422055374336
Validation loss: 2.415958531696137

Epoch: 6| Step: 2
Training loss: 1.5537775338296629
Validation loss: 2.4019018967910926

Epoch: 6| Step: 3
Training loss: 1.9509756239673886
Validation loss: 2.4059604938864165

Epoch: 6| Step: 4
Training loss: 2.0053315624337458
Validation loss: 2.387007006975278

Epoch: 6| Step: 5
Training loss: 1.6958404984506363
Validation loss: 2.3915429483938904

Epoch: 6| Step: 6
Training loss: 1.2407197738307723
Validation loss: 2.411802132126425

Epoch: 6| Step: 7
Training loss: 1.355902522704811
Validation loss: 2.4299274198586405

Epoch: 6| Step: 8
Training loss: 1.2274190256793356
Validation loss: 2.467140676342478

Epoch: 6| Step: 9
Training loss: 1.6150500781677404
Validation loss: 2.476719255663186

Epoch: 6| Step: 10
Training loss: 1.6893561715767875
Validation loss: 2.509104277450206

Epoch: 6| Step: 11
Training loss: 1.4453652861982245
Validation loss: 2.4989575355786795

Epoch: 6| Step: 12
Training loss: 1.4830959230089278
Validation loss: 2.48666427947649

Epoch: 6| Step: 13
Training loss: 1.2702286902601427
Validation loss: 2.476092182785632

Epoch: 173| Step: 0
Training loss: 1.481069075725681
Validation loss: 2.471551407737437

Epoch: 6| Step: 1
Training loss: 1.5668390679699662
Validation loss: 2.4389122299804233

Epoch: 6| Step: 2
Training loss: 2.099443579936578
Validation loss: 2.4286049763565054

Epoch: 6| Step: 3
Training loss: 1.494643980521623
Validation loss: 2.3990249120219875

Epoch: 6| Step: 4
Training loss: 1.4965304143321372
Validation loss: 2.3891120952872926

Epoch: 6| Step: 5
Training loss: 1.9086663612172723
Validation loss: 2.3744356373227125

Epoch: 6| Step: 6
Training loss: 1.6164267404547228
Validation loss: 2.385672182709017

Epoch: 6| Step: 7
Training loss: 1.2291586062064674
Validation loss: 2.415372237879492

Epoch: 6| Step: 8
Training loss: 1.7781176548489341
Validation loss: 2.4466716468907657

Epoch: 6| Step: 9
Training loss: 1.5346765132597007
Validation loss: 2.4758109150491867

Epoch: 6| Step: 10
Training loss: 1.3124550857125108
Validation loss: 2.505306961778403

Epoch: 6| Step: 11
Training loss: 1.3750676225159617
Validation loss: 2.5213860543390956

Epoch: 6| Step: 12
Training loss: 1.1916254561085349
Validation loss: 2.567498194479038

Epoch: 6| Step: 13
Training loss: 1.4253990183546814
Validation loss: 2.587174053051638

Epoch: 174| Step: 0
Training loss: 1.0101437478645268
Validation loss: 2.573244378293927

Epoch: 6| Step: 1
Training loss: 1.403249803867595
Validation loss: 2.568337806608914

Epoch: 6| Step: 2
Training loss: 1.4409612366692923
Validation loss: 2.529255068600528

Epoch: 6| Step: 3
Training loss: 1.2737760971285927
Validation loss: 2.502899133758397

Epoch: 6| Step: 4
Training loss: 1.555637242049482
Validation loss: 2.4616479804183418

Epoch: 6| Step: 5
Training loss: 1.2638788304376984
Validation loss: 2.439454411310968

Epoch: 6| Step: 6
Training loss: 1.8472206941118667
Validation loss: 2.400876159352066

Epoch: 6| Step: 7
Training loss: 1.1885887475458201
Validation loss: 2.3599019143032653

Epoch: 6| Step: 8
Training loss: 1.8702286091970628
Validation loss: 2.394089280591967

Epoch: 6| Step: 9
Training loss: 1.7183939478284576
Validation loss: 2.400304422247717

Epoch: 6| Step: 10
Training loss: 1.6023938510154028
Validation loss: 2.406329265663825

Epoch: 6| Step: 11
Training loss: 1.882892527798715
Validation loss: 2.4226355187876676

Epoch: 6| Step: 12
Training loss: 1.8680006993719258
Validation loss: 2.4501203481059926

Epoch: 6| Step: 13
Training loss: 0.6901604803368929
Validation loss: 2.490506360495956

Epoch: 175| Step: 0
Training loss: 1.2990350314666652
Validation loss: 2.4871248884287738

Epoch: 6| Step: 1
Training loss: 1.6290151436173839
Validation loss: 2.513663365116954

Epoch: 6| Step: 2
Training loss: 0.7771962088114988
Validation loss: 2.513128767586598

Epoch: 6| Step: 3
Training loss: 1.660940330696744
Validation loss: 2.5247340050143827

Epoch: 6| Step: 4
Training loss: 1.7366424722261407
Validation loss: 2.4982542156702916

Epoch: 6| Step: 5
Training loss: 1.1445210427099235
Validation loss: 2.4850225953145513

Epoch: 6| Step: 6
Training loss: 1.972375710056244
Validation loss: 2.4593612539902177

Epoch: 6| Step: 7
Training loss: 1.4790220413783755
Validation loss: 2.4499528653497626

Epoch: 6| Step: 8
Training loss: 1.6406122842931712
Validation loss: 2.414832017780572

Epoch: 6| Step: 9
Training loss: 1.5094100316249215
Validation loss: 2.417614752624162

Epoch: 6| Step: 10
Training loss: 1.9060882749900234
Validation loss: 2.4263521124845076

Epoch: 6| Step: 11
Training loss: 1.1910540951439628
Validation loss: 2.4466020851126227

Epoch: 6| Step: 12
Training loss: 1.3528295762713007
Validation loss: 2.4767193426111955

Epoch: 6| Step: 13
Training loss: 1.0923465443781253
Validation loss: 2.478958578899819

Epoch: 176| Step: 0
Training loss: 1.5106888449091072
Validation loss: 2.5048110200344205

Epoch: 6| Step: 1
Training loss: 1.2285461421990906
Validation loss: 2.526660225306133

Epoch: 6| Step: 2
Training loss: 1.4712264914242823
Validation loss: 2.54237370984421

Epoch: 6| Step: 3
Training loss: 1.5311973718435279
Validation loss: 2.5490277938953074

Epoch: 6| Step: 4
Training loss: 1.5597109507267346
Validation loss: 2.5188683037891133

Epoch: 6| Step: 5
Training loss: 1.2451433246337567
Validation loss: 2.5126765648738236

Epoch: 6| Step: 6
Training loss: 1.5806508764982334
Validation loss: 2.4739060833027375

Epoch: 6| Step: 7
Training loss: 1.4745914281296124
Validation loss: 2.4607298279471

Epoch: 6| Step: 8
Training loss: 1.52497856250141
Validation loss: 2.450723550479426

Epoch: 6| Step: 9
Training loss: 1.1957450034363946
Validation loss: 2.4284486683160065

Epoch: 6| Step: 10
Training loss: 1.709719289527001
Validation loss: 2.4444953344342255

Epoch: 6| Step: 11
Training loss: 1.7444946339886336
Validation loss: 2.4483228093021077

Epoch: 6| Step: 12
Training loss: 1.4211065710159434
Validation loss: 2.429750686803575

Epoch: 6| Step: 13
Training loss: 1.4694716121531406
Validation loss: 2.418374123175204

Epoch: 177| Step: 0
Training loss: 1.005193337969367
Validation loss: 2.431679537796554

Epoch: 6| Step: 1
Training loss: 2.0045671767341795
Validation loss: 2.420323454247136

Epoch: 6| Step: 2
Training loss: 1.1364533943793893
Validation loss: 2.4631973716647773

Epoch: 6| Step: 3
Training loss: 1.6607494057547032
Validation loss: 2.499927985271868

Epoch: 6| Step: 4
Training loss: 1.0406780447055846
Validation loss: 2.5043169209909726

Epoch: 6| Step: 5
Training loss: 1.0791700522665482
Validation loss: 2.507078981300985

Epoch: 6| Step: 6
Training loss: 1.4940398537555768
Validation loss: 2.5669622279323066

Epoch: 6| Step: 7
Training loss: 1.8442157868217122
Validation loss: 2.5615941489222562

Epoch: 6| Step: 8
Training loss: 1.3104327133643654
Validation loss: 2.554770281766527

Epoch: 6| Step: 9
Training loss: 1.376861655802225
Validation loss: 2.522921619024458

Epoch: 6| Step: 10
Training loss: 1.2428061426281642
Validation loss: 2.484067128379243

Epoch: 6| Step: 11
Training loss: 1.709116973092542
Validation loss: 2.457728982357083

Epoch: 6| Step: 12
Training loss: 1.4455344364810587
Validation loss: 2.436608749232037

Epoch: 6| Step: 13
Training loss: 2.01349095180194
Validation loss: 2.4028996925224835

Epoch: 178| Step: 0
Training loss: 1.1173056693370016
Validation loss: 2.410488650146305

Epoch: 6| Step: 1
Training loss: 1.4492178451658648
Validation loss: 2.4008142083609108

Epoch: 6| Step: 2
Training loss: 1.7290456185619034
Validation loss: 2.4156303949180025

Epoch: 6| Step: 3
Training loss: 1.68032725371144
Validation loss: 2.4016533367171364

Epoch: 6| Step: 4
Training loss: 0.8485968508634769
Validation loss: 2.4490458397384582

Epoch: 6| Step: 5
Training loss: 1.3742051861794635
Validation loss: 2.479918762837098

Epoch: 6| Step: 6
Training loss: 1.4312518790286861
Validation loss: 2.505511266433066

Epoch: 6| Step: 7
Training loss: 1.4966071221642616
Validation loss: 2.5121953728237494

Epoch: 6| Step: 8
Training loss: 2.0347297792724723
Validation loss: 2.4733873652504625

Epoch: 6| Step: 9
Training loss: 0.9800175088174732
Validation loss: 2.4324830083113733

Epoch: 6| Step: 10
Training loss: 1.5152871453383874
Validation loss: 2.402691257626278

Epoch: 6| Step: 11
Training loss: 1.9113390796128376
Validation loss: 2.372229482692752

Epoch: 6| Step: 12
Training loss: 1.3061963795877076
Validation loss: 2.3874189693910797

Epoch: 6| Step: 13
Training loss: 1.1834000532835252
Validation loss: 2.40968809229431

Epoch: 179| Step: 0
Training loss: 1.3437935578139741
Validation loss: 2.47670887363486

Epoch: 6| Step: 1
Training loss: 1.0785228713806614
Validation loss: 2.473551163556325

Epoch: 6| Step: 2
Training loss: 2.1083466460319054
Validation loss: 2.5224143090848394

Epoch: 6| Step: 3
Training loss: 1.636040084814138
Validation loss: 2.5405715534550164

Epoch: 6| Step: 4
Training loss: 0.9486993695245439
Validation loss: 2.5819648266362605

Epoch: 6| Step: 5
Training loss: 1.1971947305172708
Validation loss: 2.596703228012343

Epoch: 6| Step: 6
Training loss: 1.8792608802787973
Validation loss: 2.58858040939326

Epoch: 6| Step: 7
Training loss: 1.1357239765206206
Validation loss: 2.541615915489417

Epoch: 6| Step: 8
Training loss: 1.0672267789300478
Validation loss: 2.467483445878029

Epoch: 6| Step: 9
Training loss: 1.293839636751979
Validation loss: 2.4029240800082676

Epoch: 6| Step: 10
Training loss: 1.1611539102471151
Validation loss: 2.358899796734553

Epoch: 6| Step: 11
Training loss: 2.0843889867951004
Validation loss: 2.3619571033578866

Epoch: 6| Step: 12
Training loss: 1.354132309502243
Validation loss: 2.3421135870007452

Epoch: 6| Step: 13
Training loss: 1.7631570903314762
Validation loss: 2.352815107403359

Epoch: 180| Step: 0
Training loss: 1.128620731982388
Validation loss: 2.3448422572835472

Epoch: 6| Step: 1
Training loss: 1.332642266871814
Validation loss: 2.364333596882267

Epoch: 6| Step: 2
Training loss: 1.5950515518706598
Validation loss: 2.4174607584352588

Epoch: 6| Step: 3
Training loss: 1.1602619778015473
Validation loss: 2.4610960737900927

Epoch: 6| Step: 4
Training loss: 1.3039476501218992
Validation loss: 2.5076159042159682

Epoch: 6| Step: 5
Training loss: 1.46477660978946
Validation loss: 2.5749675698512595

Epoch: 6| Step: 6
Training loss: 1.815235310162902
Validation loss: 2.56370453495398

Epoch: 6| Step: 7
Training loss: 1.46076719545986
Validation loss: 2.5385735042638955

Epoch: 6| Step: 8
Training loss: 1.3740760126202087
Validation loss: 2.5048479159446093

Epoch: 6| Step: 9
Training loss: 1.5241081131160967
Validation loss: 2.465441561599408

Epoch: 6| Step: 10
Training loss: 1.5569701187069278
Validation loss: 2.4233280254401293

Epoch: 6| Step: 11
Training loss: 1.2554225132136412
Validation loss: 2.4454017163428206

Epoch: 6| Step: 12
Training loss: 1.3970965130862458
Validation loss: 2.4238942514667094

Epoch: 6| Step: 13
Training loss: 1.7243542941579628
Validation loss: 2.4017273551063387

Epoch: 181| Step: 0
Training loss: 1.412984405434223
Validation loss: 2.39312635585193

Epoch: 6| Step: 1
Training loss: 1.151438884751461
Validation loss: 2.387374604947094

Epoch: 6| Step: 2
Training loss: 1.9180143704398107
Validation loss: 2.4001491977947604

Epoch: 6| Step: 3
Training loss: 1.4680290887845437
Validation loss: 2.39494540188764

Epoch: 6| Step: 4
Training loss: 0.8281101009540114
Validation loss: 2.4029652731033657

Epoch: 6| Step: 5
Training loss: 1.5172003984148552
Validation loss: 2.4389471791170596

Epoch: 6| Step: 6
Training loss: 1.4764909676476745
Validation loss: 2.477028671885952

Epoch: 6| Step: 7
Training loss: 1.1832088436317214
Validation loss: 2.476393688490347

Epoch: 6| Step: 8
Training loss: 1.45625640474802
Validation loss: 2.4684422458091633

Epoch: 6| Step: 9
Training loss: 1.3460152628063025
Validation loss: 2.467654091796124

Epoch: 6| Step: 10
Training loss: 1.2501447593791193
Validation loss: 2.473825810266454

Epoch: 6| Step: 11
Training loss: 1.4223037743945928
Validation loss: 2.4466542186483546

Epoch: 6| Step: 12
Training loss: 1.5015465393170828
Validation loss: 2.4386935203035414

Epoch: 6| Step: 13
Training loss: 1.8860308733867646
Validation loss: 2.430833060912515

Epoch: 182| Step: 0
Training loss: 1.7497855463778949
Validation loss: 2.4080507997588225

Epoch: 6| Step: 1
Training loss: 1.6355237581538575
Validation loss: 2.4054189140922775

Epoch: 6| Step: 2
Training loss: 1.4780795261735273
Validation loss: 2.3996189894075144

Epoch: 6| Step: 3
Training loss: 1.4177570447697958
Validation loss: 2.431475925448147

Epoch: 6| Step: 4
Training loss: 1.7657723829483738
Validation loss: 2.449965558198182

Epoch: 6| Step: 5
Training loss: 1.3016865647114302
Validation loss: 2.468699442152495

Epoch: 6| Step: 6
Training loss: 1.1291484638919371
Validation loss: 2.489515318996759

Epoch: 6| Step: 7
Training loss: 1.1790094511188776
Validation loss: 2.4623959466190084

Epoch: 6| Step: 8
Training loss: 0.8992119146728562
Validation loss: 2.4800996363165155

Epoch: 6| Step: 9
Training loss: 1.2095834360222286
Validation loss: 2.484956973066033

Epoch: 6| Step: 10
Training loss: 1.3223802074557374
Validation loss: 2.4730367539635143

Epoch: 6| Step: 11
Training loss: 1.4299471259845842
Validation loss: 2.484854872341344

Epoch: 6| Step: 12
Training loss: 0.8788223565646747
Validation loss: 2.491567247447031

Epoch: 6| Step: 13
Training loss: 1.7970280457708465
Validation loss: 2.4918132455581388

Epoch: 183| Step: 0
Training loss: 0.9477157938868941
Validation loss: 2.4836081169108812

Epoch: 6| Step: 1
Training loss: 1.334739728123219
Validation loss: 2.4499698724959886

Epoch: 6| Step: 2
Training loss: 1.5538381432154635
Validation loss: 2.4249016803904313

Epoch: 6| Step: 3
Training loss: 1.673677488868813
Validation loss: 2.3927814790161643

Epoch: 6| Step: 4
Training loss: 1.3365312561850025
Validation loss: 2.354143947528354

Epoch: 6| Step: 5
Training loss: 1.2071761257298392
Validation loss: 2.370271530888062

Epoch: 6| Step: 6
Training loss: 1.4241352770392774
Validation loss: 2.3622286638420245

Epoch: 6| Step: 7
Training loss: 1.7778610650394626
Validation loss: 2.388961379358453

Epoch: 6| Step: 8
Training loss: 1.0160673498636414
Validation loss: 2.419208979140708

Epoch: 6| Step: 9
Training loss: 1.5791883757347975
Validation loss: 2.464110752138154

Epoch: 6| Step: 10
Training loss: 1.476299686354798
Validation loss: 2.5121320095121713

Epoch: 6| Step: 11
Training loss: 0.3513900969894576
Validation loss: 2.53833863799643

Epoch: 6| Step: 12
Training loss: 1.2058893128964556
Validation loss: 2.5811567988542174

Epoch: 6| Step: 13
Training loss: 1.8596261119373811
Validation loss: 2.5595913167626745

Epoch: 184| Step: 0
Training loss: 1.3641340763500036
Validation loss: 2.5609197818965774

Epoch: 6| Step: 1
Training loss: 1.1725136606034736
Validation loss: 2.516130968594812

Epoch: 6| Step: 2
Training loss: 1.4081566071465734
Validation loss: 2.468794309696908

Epoch: 6| Step: 3
Training loss: 1.2242008969892442
Validation loss: 2.42043259638082

Epoch: 6| Step: 4
Training loss: 0.8781059860397326
Validation loss: 2.4043100221295997

Epoch: 6| Step: 5
Training loss: 1.4732727055711985
Validation loss: 2.3918837390873997

Epoch: 6| Step: 6
Training loss: 1.3177940682525917
Validation loss: 2.357337403757848

Epoch: 6| Step: 7
Training loss: 1.4244599373011775
Validation loss: 2.361843726400546

Epoch: 6| Step: 8
Training loss: 1.513531527011597
Validation loss: 2.346882278800096

Epoch: 6| Step: 9
Training loss: 1.1975429394216843
Validation loss: 2.364407628835015

Epoch: 6| Step: 10
Training loss: 1.3382630212792757
Validation loss: 2.3842984874679822

Epoch: 6| Step: 11
Training loss: 1.852935796795755
Validation loss: 2.4109813592595857

Epoch: 6| Step: 12
Training loss: 1.2272265149416508
Validation loss: 2.4685053259551344

Epoch: 6| Step: 13
Training loss: 1.4795713900778131
Validation loss: 2.517365962160439

Epoch: 185| Step: 0
Training loss: 1.3410798090512717
Validation loss: 2.5669702035862083

Epoch: 6| Step: 1
Training loss: 1.5041399093037369
Validation loss: 2.5689344539854075

Epoch: 6| Step: 2
Training loss: 1.429038979449181
Validation loss: 2.5916386800602234

Epoch: 6| Step: 3
Training loss: 1.4027140773918283
Validation loss: 2.5754589825440406

Epoch: 6| Step: 4
Training loss: 1.1052547827381816
Validation loss: 2.512566813718919

Epoch: 6| Step: 5
Training loss: 1.2053544332080237
Validation loss: 2.452320102424395

Epoch: 6| Step: 6
Training loss: 1.9575941909402976
Validation loss: 2.4193183490435164

Epoch: 6| Step: 7
Training loss: 1.271926123414075
Validation loss: 2.3765832376580898

Epoch: 6| Step: 8
Training loss: 1.0818721502785529
Validation loss: 2.3671092088092447

Epoch: 6| Step: 9
Training loss: 1.1825757574609752
Validation loss: 2.363090587855036

Epoch: 6| Step: 10
Training loss: 1.1320881599563932
Validation loss: 2.3452875848632884

Epoch: 6| Step: 11
Training loss: 1.7761337688948275
Validation loss: 2.368781161803413

Epoch: 6| Step: 12
Training loss: 1.030513384751078
Validation loss: 2.387823234745149

Epoch: 6| Step: 13
Training loss: 0.7957413032672515
Validation loss: 2.4142098850915703

Epoch: 186| Step: 0
Training loss: 1.4104674780448907
Validation loss: 2.4503792881231563

Epoch: 6| Step: 1
Training loss: 1.7469802415294895
Validation loss: 2.473013496910011

Epoch: 6| Step: 2
Training loss: 1.2731843006254318
Validation loss: 2.478053947551224

Epoch: 6| Step: 3
Training loss: 1.3469841649541419
Validation loss: 2.5228983645618994

Epoch: 6| Step: 4
Training loss: 1.218398214579105
Validation loss: 2.4915290852839176

Epoch: 6| Step: 5
Training loss: 0.9608248202621439
Validation loss: 2.517087806252141

Epoch: 6| Step: 6
Training loss: 1.1109854600643365
Validation loss: 2.4743990822335475

Epoch: 6| Step: 7
Training loss: 1.316003754885804
Validation loss: 2.4749068920412913

Epoch: 6| Step: 8
Training loss: 1.1214933314641757
Validation loss: 2.46278064757395

Epoch: 6| Step: 9
Training loss: 1.9003341682100807
Validation loss: 2.4384870231991114

Epoch: 6| Step: 10
Training loss: 1.0081526899230273
Validation loss: 2.453759456176634

Epoch: 6| Step: 11
Training loss: 1.030214714799382
Validation loss: 2.4402049721216934

Epoch: 6| Step: 12
Training loss: 1.358366317972619
Validation loss: 2.468790761419795

Epoch: 6| Step: 13
Training loss: 1.2528089433915963
Validation loss: 2.4807641185924263

Epoch: 187| Step: 0
Training loss: 1.1106027069172844
Validation loss: 2.4842305940201648

Epoch: 6| Step: 1
Training loss: 0.9858084641063636
Validation loss: 2.5115348171763907

Epoch: 6| Step: 2
Training loss: 1.334065425080564
Validation loss: 2.527580980817344

Epoch: 6| Step: 3
Training loss: 1.5393773255541663
Validation loss: 2.5329705481188056

Epoch: 6| Step: 4
Training loss: 1.1215263356191985
Validation loss: 2.508986514574367

Epoch: 6| Step: 5
Training loss: 1.3479059402691518
Validation loss: 2.477803968869657

Epoch: 6| Step: 6
Training loss: 1.4658865103618992
Validation loss: 2.4481505310851324

Epoch: 6| Step: 7
Training loss: 1.1402344753661313
Validation loss: 2.424851125991969

Epoch: 6| Step: 8
Training loss: 1.0891490075494983
Validation loss: 2.3881721049222695

Epoch: 6| Step: 9
Training loss: 1.6701222438956538
Validation loss: 2.4157740613892367

Epoch: 6| Step: 10
Training loss: 1.27133491915154
Validation loss: 2.434841297840327

Epoch: 6| Step: 11
Training loss: 1.3445803715866627
Validation loss: 2.4633727036648496

Epoch: 6| Step: 12
Training loss: 1.6180806665104681
Validation loss: 2.495030012418567

Epoch: 6| Step: 13
Training loss: 0.6239010925232654
Validation loss: 2.503105113863655

Epoch: 188| Step: 0
Training loss: 0.8861530869173884
Validation loss: 2.4981399989955806

Epoch: 6| Step: 1
Training loss: 1.2678543518695775
Validation loss: 2.4896816663818484

Epoch: 6| Step: 2
Training loss: 1.0045920675228437
Validation loss: 2.4663005352870218

Epoch: 6| Step: 3
Training loss: 1.0030736773425117
Validation loss: 2.4306647491147584

Epoch: 6| Step: 4
Training loss: 1.025140873602248
Validation loss: 2.4176126593920624

Epoch: 6| Step: 5
Training loss: 1.3452000445817072
Validation loss: 2.4140715245291493

Epoch: 6| Step: 6
Training loss: 1.2566183831141158
Validation loss: 2.41611680644879

Epoch: 6| Step: 7
Training loss: 1.1057144808531427
Validation loss: 2.402060218324642

Epoch: 6| Step: 8
Training loss: 1.1911445705516657
Validation loss: 2.4200761564392925

Epoch: 6| Step: 9
Training loss: 1.5581094472195367
Validation loss: 2.4185654960110092

Epoch: 6| Step: 10
Training loss: 1.3839719835846935
Validation loss: 2.408245874619335

Epoch: 6| Step: 11
Training loss: 1.3504092638110425
Validation loss: 2.4484679394463824

Epoch: 6| Step: 12
Training loss: 1.9961728194191486
Validation loss: 2.4890814122614215

Epoch: 6| Step: 13
Training loss: 0.9729253557512876
Validation loss: 2.578116534316457

Epoch: 189| Step: 0
Training loss: 1.5079548032347099
Validation loss: 2.5819880366325876

Epoch: 6| Step: 1
Training loss: 1.1471835706160838
Validation loss: 2.5769373291361997

Epoch: 6| Step: 2
Training loss: 1.0246229222485905
Validation loss: 2.506651976729326

Epoch: 6| Step: 3
Training loss: 1.6885221705722184
Validation loss: 2.466977003690166

Epoch: 6| Step: 4
Training loss: 0.821375748167973
Validation loss: 2.4077155182759387

Epoch: 6| Step: 5
Training loss: 0.8760689949251549
Validation loss: 2.3991961882374992

Epoch: 6| Step: 6
Training loss: 1.540413510428798
Validation loss: 2.373908075247013

Epoch: 6| Step: 7
Training loss: 1.4937019053102565
Validation loss: 2.377904182804854

Epoch: 6| Step: 8
Training loss: 1.3790302599075859
Validation loss: 2.3796020160649762

Epoch: 6| Step: 9
Training loss: 1.4380344558322964
Validation loss: 2.374646233882226

Epoch: 6| Step: 10
Training loss: 1.3854620598644087
Validation loss: 2.3814481156558958

Epoch: 6| Step: 11
Training loss: 1.0852786473674125
Validation loss: 2.4274222873011424

Epoch: 6| Step: 12
Training loss: 1.1257538918553494
Validation loss: 2.4772664936026962

Epoch: 6| Step: 13
Training loss: 1.6266879338427198
Validation loss: 2.541395480211294

Epoch: 190| Step: 0
Training loss: 0.9456825792995015
Validation loss: 2.5663979869007827

Epoch: 6| Step: 1
Training loss: 1.2233394383755416
Validation loss: 2.5391956228187365

Epoch: 6| Step: 2
Training loss: 1.5034622131359054
Validation loss: 2.460462088239139

Epoch: 6| Step: 3
Training loss: 0.6501728873311796
Validation loss: 2.4108985731908854

Epoch: 6| Step: 4
Training loss: 1.7847801830744148
Validation loss: 2.3662758204060035

Epoch: 6| Step: 5
Training loss: 2.092527801438366
Validation loss: 2.347649677242772

Epoch: 6| Step: 6
Training loss: 1.6570521157770643
Validation loss: 2.333393249606755

Epoch: 6| Step: 7
Training loss: 1.1852048477941446
Validation loss: 2.3481604732642105

Epoch: 6| Step: 8
Training loss: 0.854162743412095
Validation loss: 2.3651880103065785

Epoch: 6| Step: 9
Training loss: 1.0322715439103833
Validation loss: 2.399045690135796

Epoch: 6| Step: 10
Training loss: 1.4900914994889962
Validation loss: 2.4152853529065803

Epoch: 6| Step: 11
Training loss: 1.2528169362690673
Validation loss: 2.4681921064141257

Epoch: 6| Step: 12
Training loss: 1.0130502783149724
Validation loss: 2.5363443707878743

Epoch: 6| Step: 13
Training loss: 1.0106021802563516
Validation loss: 2.585018084603966

Epoch: 191| Step: 0
Training loss: 1.2564264088220696
Validation loss: 2.5806153213342164

Epoch: 6| Step: 1
Training loss: 1.0109456175488547
Validation loss: 2.509918200847234

Epoch: 6| Step: 2
Training loss: 1.017634472595668
Validation loss: 2.47854732333901

Epoch: 6| Step: 3
Training loss: 1.3271438564869888
Validation loss: 2.4119504174335433

Epoch: 6| Step: 4
Training loss: 1.7056756474686727
Validation loss: 2.4104325830849107

Epoch: 6| Step: 5
Training loss: 1.34291538667317
Validation loss: 2.3896697949218284

Epoch: 6| Step: 6
Training loss: 1.3765731395435836
Validation loss: 2.378540525530266

Epoch: 6| Step: 7
Training loss: 1.4116765753268048
Validation loss: 2.350103894356522

Epoch: 6| Step: 8
Training loss: 1.1141786405100171
Validation loss: 2.362978733178836

Epoch: 6| Step: 9
Training loss: 1.2768483732474936
Validation loss: 2.385809141776852

Epoch: 6| Step: 10
Training loss: 1.0165792237391647
Validation loss: 2.3803082305121124

Epoch: 6| Step: 11
Training loss: 1.2111133078653398
Validation loss: 2.377781443360975

Epoch: 6| Step: 12
Training loss: 1.4384251810027429
Validation loss: 2.4123603620141365

Epoch: 6| Step: 13
Training loss: 1.4067271800531693
Validation loss: 2.4472210522582225

Epoch: 192| Step: 0
Training loss: 1.404008435164215
Validation loss: 2.4550696281706172

Epoch: 6| Step: 1
Training loss: 1.1714923997014615
Validation loss: 2.457339091137774

Epoch: 6| Step: 2
Training loss: 1.0524750285686109
Validation loss: 2.444828227017024

Epoch: 6| Step: 3
Training loss: 1.6302680673918684
Validation loss: 2.473823029855779

Epoch: 6| Step: 4
Training loss: 0.9271327909214518
Validation loss: 2.4718280159325863

Epoch: 6| Step: 5
Training loss: 1.1902961937750642
Validation loss: 2.4730758887621986

Epoch: 6| Step: 6
Training loss: 0.755667255441206
Validation loss: 2.41788715000419

Epoch: 6| Step: 7
Training loss: 0.9525682668176586
Validation loss: 2.425783328785533

Epoch: 6| Step: 8
Training loss: 1.0256968013868641
Validation loss: 2.4375974511038545

Epoch: 6| Step: 9
Training loss: 1.048400393879717
Validation loss: 2.4536169888725463

Epoch: 6| Step: 10
Training loss: 1.690793955146808
Validation loss: 2.488216302001255

Epoch: 6| Step: 11
Training loss: 1.4021650960283103
Validation loss: 2.4817922164467014

Epoch: 6| Step: 12
Training loss: 1.7336604390461872
Validation loss: 2.4926027809694435

Epoch: 6| Step: 13
Training loss: 0.9783324414714364
Validation loss: 2.4823418298376563

Epoch: 193| Step: 0
Training loss: 1.401676837590919
Validation loss: 2.492225612992255

Epoch: 6| Step: 1
Training loss: 1.0323938903595298
Validation loss: 2.4667054289133774

Epoch: 6| Step: 2
Training loss: 0.8446458017187888
Validation loss: 2.4525148933995964

Epoch: 6| Step: 3
Training loss: 0.721158553132566
Validation loss: 2.456022645627997

Epoch: 6| Step: 4
Training loss: 1.253963861300635
Validation loss: 2.449500046557279

Epoch: 6| Step: 5
Training loss: 1.4269453757028923
Validation loss: 2.480495514166949

Epoch: 6| Step: 6
Training loss: 1.028824699721166
Validation loss: 2.4424741783938937

Epoch: 6| Step: 7
Training loss: 0.6915663625382622
Validation loss: 2.4830582531259124

Epoch: 6| Step: 8
Training loss: 1.0456199524570082
Validation loss: 2.470686011543102

Epoch: 6| Step: 9
Training loss: 1.5954142090659027
Validation loss: 2.4921861472974642

Epoch: 6| Step: 10
Training loss: 1.2367960690627111
Validation loss: 2.4874436052030577

Epoch: 6| Step: 11
Training loss: 1.181476978918797
Validation loss: 2.4864977446617376

Epoch: 6| Step: 12
Training loss: 1.028815082516913
Validation loss: 2.463926050700894

Epoch: 6| Step: 13
Training loss: 2.309650624594644
Validation loss: 2.462754948374837

Epoch: 194| Step: 0
Training loss: 1.1997034540926523
Validation loss: 2.435866936053093

Epoch: 6| Step: 1
Training loss: 1.3811729754897706
Validation loss: 2.425854764158674

Epoch: 6| Step: 2
Training loss: 1.0444023766116945
Validation loss: 2.3801296193560493

Epoch: 6| Step: 3
Training loss: 1.2918073157161656
Validation loss: 2.3572807522269854

Epoch: 6| Step: 4
Training loss: 1.0331156068018317
Validation loss: 2.3767275925231273

Epoch: 6| Step: 5
Training loss: 0.9048656545157231
Validation loss: 2.370643200035508

Epoch: 6| Step: 6
Training loss: 1.290166301357814
Validation loss: 2.3827959506251766

Epoch: 6| Step: 7
Training loss: 0.9045739295314879
Validation loss: 2.416434430331035

Epoch: 6| Step: 8
Training loss: 1.2877794295843366
Validation loss: 2.4473762200122375

Epoch: 6| Step: 9
Training loss: 1.347531166353199
Validation loss: 2.4759709715505553

Epoch: 6| Step: 10
Training loss: 1.0006082592242254
Validation loss: 2.493432032971817

Epoch: 6| Step: 11
Training loss: 1.5897917118038345
Validation loss: 2.524234341264224

Epoch: 6| Step: 12
Training loss: 1.2156838704345705
Validation loss: 2.530779907457248

Epoch: 6| Step: 13
Training loss: 0.7801322952587089
Validation loss: 2.520685082916028

Epoch: 195| Step: 0
Training loss: 1.1647599454292628
Validation loss: 2.5200348264568446

Epoch: 6| Step: 1
Training loss: 1.2870199030572442
Validation loss: 2.5024808741232616

Epoch: 6| Step: 2
Training loss: 1.151315365984846
Validation loss: 2.477205718239685

Epoch: 6| Step: 3
Training loss: 0.85107421875
Validation loss: 2.457636853586967

Epoch: 6| Step: 4
Training loss: 1.0759536881992064
Validation loss: 2.420288186663607

Epoch: 6| Step: 5
Training loss: 1.0053029715833817
Validation loss: 2.407030287779024

Epoch: 6| Step: 6
Training loss: 1.0443942725585198
Validation loss: 2.3889297693463334

Epoch: 6| Step: 7
Training loss: 1.0842779638313884
Validation loss: 2.406705146597594

Epoch: 6| Step: 8
Training loss: 1.4189725323223672
Validation loss: 2.414863623144982

Epoch: 6| Step: 9
Training loss: 0.978973098993147
Validation loss: 2.443125063847859

Epoch: 6| Step: 10
Training loss: 1.297855190619341
Validation loss: 2.4540429285205594

Epoch: 6| Step: 11
Training loss: 0.9119144206843977
Validation loss: 2.473618877202527

Epoch: 6| Step: 12
Training loss: 1.2978235016394857
Validation loss: 2.476301580164577

Epoch: 6| Step: 13
Training loss: 1.8228718852037664
Validation loss: 2.50935327631376

Epoch: 196| Step: 0
Training loss: 1.12281045830167
Validation loss: 2.510926124273411

Epoch: 6| Step: 1
Training loss: 0.7575744963043002
Validation loss: 2.5253993166666007

Epoch: 6| Step: 2
Training loss: 1.6654632833390939
Validation loss: 2.4933926185028032

Epoch: 6| Step: 3
Training loss: 1.0225152672558195
Validation loss: 2.465831624089087

Epoch: 6| Step: 4
Training loss: 1.8419028905977464
Validation loss: 2.4479066058292274

Epoch: 6| Step: 5
Training loss: 0.6667395988943244
Validation loss: 2.4239613882761994

Epoch: 6| Step: 6
Training loss: 0.9200631132453557
Validation loss: 2.43334567583398

Epoch: 6| Step: 7
Training loss: 1.3283156762969792
Validation loss: 2.4443988652080217

Epoch: 6| Step: 8
Training loss: 1.1178066432032667
Validation loss: 2.447834968294478

Epoch: 6| Step: 9
Training loss: 0.8740435209044737
Validation loss: 2.4571362169162603

Epoch: 6| Step: 10
Training loss: 0.9630057244828871
Validation loss: 2.4741256047657947

Epoch: 6| Step: 11
Training loss: 1.2101252631301522
Validation loss: 2.454378548841288

Epoch: 6| Step: 12
Training loss: 0.970558171031897
Validation loss: 2.4962007304933183

Epoch: 6| Step: 13
Training loss: 1.2457513129410933
Validation loss: 2.4850422994983696

Epoch: 197| Step: 0
Training loss: 1.1246052685285342
Validation loss: 2.4593559515512045

Epoch: 6| Step: 1
Training loss: 1.0105586525695591
Validation loss: 2.4735079008881367

Epoch: 6| Step: 2
Training loss: 1.1184322651870893
Validation loss: 2.4885770779285195

Epoch: 6| Step: 3
Training loss: 1.3141008332928776
Validation loss: 2.4665801903926767

Epoch: 6| Step: 4
Training loss: 0.9461759611867872
Validation loss: 2.444831412129693

Epoch: 6| Step: 5
Training loss: 1.2022284102314904
Validation loss: 2.4248780980544784

Epoch: 6| Step: 6
Training loss: 1.165313662760884
Validation loss: 2.41547641007154

Epoch: 6| Step: 7
Training loss: 1.2820332156950243
Validation loss: 2.3998876593217338

Epoch: 6| Step: 8
Training loss: 1.0283217036137313
Validation loss: 2.411096601602589

Epoch: 6| Step: 9
Training loss: 0.9689585861099648
Validation loss: 2.4265852255994775

Epoch: 6| Step: 10
Training loss: 1.1616273024378265
Validation loss: 2.4154032147421103

Epoch: 6| Step: 11
Training loss: 1.685037087165348
Validation loss: 2.383226709055372

Epoch: 6| Step: 12
Training loss: 0.8762559732187287
Validation loss: 2.431804963398479

Epoch: 6| Step: 13
Training loss: 0.4252125152626464
Validation loss: 2.4637915985659067

Epoch: 198| Step: 0
Training loss: 0.9700048379679105
Validation loss: 2.4964367093640463

Epoch: 6| Step: 1
Training loss: 1.6118422919005913
Validation loss: 2.511607510635275

Epoch: 6| Step: 2
Training loss: 1.3737419181634596
Validation loss: 2.526722413615651

Epoch: 6| Step: 3
Training loss: 1.0004161326512748
Validation loss: 2.5036468138527805

Epoch: 6| Step: 4
Training loss: 1.144517918011089
Validation loss: 2.4747409406964818

Epoch: 6| Step: 5
Training loss: 1.58162535181677
Validation loss: 2.4911923533816402

Epoch: 6| Step: 6
Training loss: 0.4401474955821958
Validation loss: 2.4558876778183745

Epoch: 6| Step: 7
Training loss: 1.0737972472945831
Validation loss: 2.4776073604212736

Epoch: 6| Step: 8
Training loss: 1.0060335767690212
Validation loss: 2.444696353418454

Epoch: 6| Step: 9
Training loss: 1.2782403907825037
Validation loss: 2.41757905661846

Epoch: 6| Step: 10
Training loss: 0.6805761819641793
Validation loss: 2.418182825307219

Epoch: 6| Step: 11
Training loss: 1.0072793067613017
Validation loss: 2.4068135652468463

Epoch: 6| Step: 12
Training loss: 1.1078275176457522
Validation loss: 2.422122813767033

Epoch: 6| Step: 13
Training loss: 0.883336510892467
Validation loss: 2.431961535884952

Epoch: 199| Step: 0
Training loss: 2.0760228129550184
Validation loss: 2.4645041979487137

Epoch: 6| Step: 1
Training loss: 1.2200808961031595
Validation loss: 2.4821445314710098

Epoch: 6| Step: 2
Training loss: 1.029356518633366
Validation loss: 2.5038111964318928

Epoch: 6| Step: 3
Training loss: 0.9490396150072551
Validation loss: 2.509444388066704

Epoch: 6| Step: 4
Training loss: 0.8764223391286547
Validation loss: 2.5162768234436164

Epoch: 6| Step: 5
Training loss: 0.9653565746654691
Validation loss: 2.4806326421444065

Epoch: 6| Step: 6
Training loss: 0.9715173020130196
Validation loss: 2.464035793889595

Epoch: 6| Step: 7
Training loss: 0.9540460232643553
Validation loss: 2.463060659652287

Epoch: 6| Step: 8
Training loss: 0.8649942654766887
Validation loss: 2.449324217622206

Epoch: 6| Step: 9
Training loss: 1.4683733518056532
Validation loss: 2.40321258326007

Epoch: 6| Step: 10
Training loss: 0.964639896989125
Validation loss: 2.3824140802311287

Epoch: 6| Step: 11
Training loss: 0.9151666607231215
Validation loss: 2.3783216881850837

Epoch: 6| Step: 12
Training loss: 0.6266573865013981
Validation loss: 2.3911852361458164

Epoch: 6| Step: 13
Training loss: 0.9502665697844486
Validation loss: 2.407850738011164

Epoch: 200| Step: 0
Training loss: 0.9086339769453929
Validation loss: 2.4044105542429217

Epoch: 6| Step: 1
Training loss: 1.2226422098834442
Validation loss: 2.4164244141762006

Epoch: 6| Step: 2
Training loss: 0.8380323881431823
Validation loss: 2.4366591154521053

Epoch: 6| Step: 3
Training loss: 1.1689751413311191
Validation loss: 2.463462415357579

Epoch: 6| Step: 4
Training loss: 1.7093863924473256
Validation loss: 2.4913184528411505

Epoch: 6| Step: 5
Training loss: 1.0297266951237065
Validation loss: 2.4866871758655287

Epoch: 6| Step: 6
Training loss: 0.8077219441936238
Validation loss: 2.476282288869017

Epoch: 6| Step: 7
Training loss: 1.0371642017420009
Validation loss: 2.5029252621982376

Epoch: 6| Step: 8
Training loss: 0.966766110325698
Validation loss: 2.498026169645543

Epoch: 6| Step: 9
Training loss: 0.9771172435599532
Validation loss: 2.5157302052806805

Epoch: 6| Step: 10
Training loss: 1.0040112154816738
Validation loss: 2.4928548472729894

Epoch: 6| Step: 11
Training loss: 1.0024141139771396
Validation loss: 2.4576398150380734

Epoch: 6| Step: 12
Training loss: 1.2355963543594535
Validation loss: 2.4560059037741016

Epoch: 6| Step: 13
Training loss: 1.2164799015628545
Validation loss: 2.419645799741035

Epoch: 201| Step: 0
Training loss: 1.7480921563618403
Validation loss: 2.3957565965887304

Epoch: 6| Step: 1
Training loss: 1.0408234553075792
Validation loss: 2.4008023074626244

Epoch: 6| Step: 2
Training loss: 0.9873377401099898
Validation loss: 2.401227569127691

Epoch: 6| Step: 3
Training loss: 1.043441493874144
Validation loss: 2.4001325853104913

Epoch: 6| Step: 4
Training loss: 0.9510465692154927
Validation loss: 2.375224555668407

Epoch: 6| Step: 5
Training loss: 0.8220663667395172
Validation loss: 2.3916399781862303

Epoch: 6| Step: 6
Training loss: 0.9507610209185114
Validation loss: 2.40649200616032

Epoch: 6| Step: 7
Training loss: 1.0620414080799776
Validation loss: 2.416663820847083

Epoch: 6| Step: 8
Training loss: 0.7905290402163893
Validation loss: 2.4504974675527826

Epoch: 6| Step: 9
Training loss: 1.2071392912179189
Validation loss: 2.4540110578244643

Epoch: 6| Step: 10
Training loss: 0.8473765531447747
Validation loss: 2.435386703959399

Epoch: 6| Step: 11
Training loss: 1.3558911811353322
Validation loss: 2.4374533544409895

Epoch: 6| Step: 12
Training loss: 1.016181206621113
Validation loss: 2.423419843670888

Epoch: 6| Step: 13
Training loss: 1.2830927553134235
Validation loss: 2.410803075655916

Epoch: 202| Step: 0
Training loss: 1.5818730781510344
Validation loss: 2.4113211814142352

Epoch: 6| Step: 1
Training loss: 1.2843218938610295
Validation loss: 2.41350378536211

Epoch: 6| Step: 2
Training loss: 0.8241497209759197
Validation loss: 2.3988820763195973

Epoch: 6| Step: 3
Training loss: 0.88564494313121
Validation loss: 2.412615046265076

Epoch: 6| Step: 4
Training loss: 1.141088104296762
Validation loss: 2.420027444072487

Epoch: 6| Step: 5
Training loss: 1.1660766074433424
Validation loss: 2.386733071301177

Epoch: 6| Step: 6
Training loss: 1.0187824173900697
Validation loss: 2.43424058044138

Epoch: 6| Step: 7
Training loss: 0.9910300705232434
Validation loss: 2.4273267470136712

Epoch: 6| Step: 8
Training loss: 1.1758796422604572
Validation loss: 2.4455863607689423

Epoch: 6| Step: 9
Training loss: 1.2296596228264323
Validation loss: 2.432562938340898

Epoch: 6| Step: 10
Training loss: 1.1079750361470684
Validation loss: 2.451529692228475

Epoch: 6| Step: 11
Training loss: 1.0029254084925758
Validation loss: 2.450585254416417

Epoch: 6| Step: 12
Training loss: 0.5502948642484824
Validation loss: 2.442356413726597

Epoch: 6| Step: 13
Training loss: 0.8469733726545058
Validation loss: 2.463104355614897

Epoch: 203| Step: 0
Training loss: 1.2853587260653119
Validation loss: 2.456176589344317

Epoch: 6| Step: 1
Training loss: 0.9182708892315665
Validation loss: 2.470348856524431

Epoch: 6| Step: 2
Training loss: 1.0988162281790488
Validation loss: 2.460393348768057

Epoch: 6| Step: 3
Training loss: 0.3544708329591621
Validation loss: 2.450743074345437

Epoch: 6| Step: 4
Training loss: 0.7804861912578019
Validation loss: 2.432465049461285

Epoch: 6| Step: 5
Training loss: 0.8346594193568452
Validation loss: 2.419730063809209

Epoch: 6| Step: 6
Training loss: 1.3465646496850996
Validation loss: 2.421593440715478

Epoch: 6| Step: 7
Training loss: 0.964139426452965
Validation loss: 2.436735937425244

Epoch: 6| Step: 8
Training loss: 1.7979218460426858
Validation loss: 2.4209567538618972

Epoch: 6| Step: 9
Training loss: 0.869647274862154
Validation loss: 2.411321548207327

Epoch: 6| Step: 10
Training loss: 1.0631618682191712
Validation loss: 2.417317961093235

Epoch: 6| Step: 11
Training loss: 0.9815704721383925
Validation loss: 2.4192464546824355

Epoch: 6| Step: 12
Training loss: 0.834600073928519
Validation loss: 2.4113779464998526

Epoch: 6| Step: 13
Training loss: 1.165637237648221
Validation loss: 2.4366644996342317

Epoch: 204| Step: 0
Training loss: 0.7274334926945506
Validation loss: 2.465935175740486

Epoch: 6| Step: 1
Training loss: 1.0184339559656677
Validation loss: 2.4893860675515826

Epoch: 6| Step: 2
Training loss: 1.1458488405507685
Validation loss: 2.494268386414072

Epoch: 6| Step: 3
Training loss: 1.1563597446631622
Validation loss: 2.4869239502489497

Epoch: 6| Step: 4
Training loss: 0.991405389062434
Validation loss: 2.4687448098878524

Epoch: 6| Step: 5
Training loss: 1.1050799329681547
Validation loss: 2.4698464785921774

Epoch: 6| Step: 6
Training loss: 0.9127076696518122
Validation loss: 2.4495432716994174

Epoch: 6| Step: 7
Training loss: 0.9177864055931009
Validation loss: 2.430349089432418

Epoch: 6| Step: 8
Training loss: 0.9939504865023333
Validation loss: 2.4081754040882215

Epoch: 6| Step: 9
Training loss: 0.7878448609208895
Validation loss: 2.4103444038065964

Epoch: 6| Step: 10
Training loss: 0.9865356529142664
Validation loss: 2.429776452316361

Epoch: 6| Step: 11
Training loss: 0.908687044242872
Validation loss: 2.4112577338751104

Epoch: 6| Step: 12
Training loss: 1.761347560305799
Validation loss: 2.425086154618826

Epoch: 6| Step: 13
Training loss: 0.8168854105839836
Validation loss: 2.4301270302781113

Epoch: 205| Step: 0
Training loss: 1.2617490782502891
Validation loss: 2.4353868123836504

Epoch: 6| Step: 1
Training loss: 0.9029061682606706
Validation loss: 2.4071374979008064

Epoch: 6| Step: 2
Training loss: 0.8488220074183456
Validation loss: 2.4169439560531973

Epoch: 6| Step: 3
Training loss: 1.4901174196918154
Validation loss: 2.396776138138373

Epoch: 6| Step: 4
Training loss: 0.9955621834363547
Validation loss: 2.404010409666522

Epoch: 6| Step: 5
Training loss: 1.0901101719884803
Validation loss: 2.398527007366639

Epoch: 6| Step: 6
Training loss: 1.2090982559134733
Validation loss: 2.4284826986587404

Epoch: 6| Step: 7
Training loss: 0.8435565938749188
Validation loss: 2.414458091663268

Epoch: 6| Step: 8
Training loss: 0.7359186546682706
Validation loss: 2.415867215683192

Epoch: 6| Step: 9
Training loss: 0.8890872529511026
Validation loss: 2.436889256398089

Epoch: 6| Step: 10
Training loss: 1.1712517161646823
Validation loss: 2.4417461005478778

Epoch: 6| Step: 11
Training loss: 0.9973175310253147
Validation loss: 2.430643562055724

Epoch: 6| Step: 12
Training loss: 0.905646682384924
Validation loss: 2.4746448316077667

Epoch: 6| Step: 13
Training loss: 0.9850784694572099
Validation loss: 2.470779257071599

Epoch: 206| Step: 0
Training loss: 1.7111016460393618
Validation loss: 2.4648821547439126

Epoch: 6| Step: 1
Training loss: 0.8628488208458306
Validation loss: 2.482989913613372

Epoch: 6| Step: 2
Training loss: 0.8614051421110078
Validation loss: 2.471851231246168

Epoch: 6| Step: 3
Training loss: 1.1241108241443527
Validation loss: 2.4428420047423063

Epoch: 6| Step: 4
Training loss: 1.0728690806579675
Validation loss: 2.4367344944973834

Epoch: 6| Step: 5
Training loss: 0.7178573870709295
Validation loss: 2.4437849194366197

Epoch: 6| Step: 6
Training loss: 0.8555699815469684
Validation loss: 2.420002541953867

Epoch: 6| Step: 7
Training loss: 1.295304646025293
Validation loss: 2.4119718824238214

Epoch: 6| Step: 8
Training loss: 0.9298390817885602
Validation loss: 2.3997997196522967

Epoch: 6| Step: 9
Training loss: 0.67348028963101
Validation loss: 2.385061962471388

Epoch: 6| Step: 10
Training loss: 1.1937094516758011
Validation loss: 2.3837376114479008

Epoch: 6| Step: 11
Training loss: 0.8182995758422886
Validation loss: 2.4091956358483317

Epoch: 6| Step: 12
Training loss: 1.0160989682437391
Validation loss: 2.3997048193689268

Epoch: 6| Step: 13
Training loss: 0.49193398440683217
Validation loss: 2.4045545163178836

Epoch: 207| Step: 0
Training loss: 0.7845661735852834
Validation loss: 2.4070913662783764

Epoch: 6| Step: 1
Training loss: 1.4771101808820675
Validation loss: 2.4305928813296944

Epoch: 6| Step: 2
Training loss: 1.0272802761181068
Validation loss: 2.4180813581794385

Epoch: 6| Step: 3
Training loss: 1.5138421338217645
Validation loss: 2.437315355663824

Epoch: 6| Step: 4
Training loss: 1.085948751926447
Validation loss: 2.4303675544171566

Epoch: 6| Step: 5
Training loss: 0.9292711239133586
Validation loss: 2.427991518288872

Epoch: 6| Step: 6
Training loss: 0.6859960578827433
Validation loss: 2.4088143421839914

Epoch: 6| Step: 7
Training loss: 0.9286247718863131
Validation loss: 2.4074733880572796

Epoch: 6| Step: 8
Training loss: 0.41452358772221765
Validation loss: 2.4253605530679545

Epoch: 6| Step: 9
Training loss: 0.9386970507118559
Validation loss: 2.4007132789701764

Epoch: 6| Step: 10
Training loss: 1.2915175208255698
Validation loss: 2.4027503519814415

Epoch: 6| Step: 11
Training loss: 0.7293045640161088
Validation loss: 2.3993205343923303

Epoch: 6| Step: 12
Training loss: 0.964791578357231
Validation loss: 2.351695155547953

Epoch: 6| Step: 13
Training loss: 0.6147830336957931
Validation loss: 2.3805981674911085

Epoch: 208| Step: 0
Training loss: 0.8866191925757855
Validation loss: 2.37688376681196

Epoch: 6| Step: 1
Training loss: 1.265789727687758
Validation loss: 2.4002161619342695

Epoch: 6| Step: 2
Training loss: 0.8991948791570209
Validation loss: 2.4198104940161596

Epoch: 6| Step: 3
Training loss: 1.4883289079219444
Validation loss: 2.406510403854733

Epoch: 6| Step: 4
Training loss: 1.2750539057686803
Validation loss: 2.4220990286745105

Epoch: 6| Step: 5
Training loss: 0.9860354149708423
Validation loss: 2.406903065750591

Epoch: 6| Step: 6
Training loss: 0.8823432688089433
Validation loss: 2.4121305367372385

Epoch: 6| Step: 7
Training loss: 1.146646309485227
Validation loss: 2.4036889448608036

Epoch: 6| Step: 8
Training loss: 1.1514479436532767
Validation loss: 2.403381270346894

Epoch: 6| Step: 9
Training loss: 0.6314533850227307
Validation loss: 2.3853797728834403

Epoch: 6| Step: 10
Training loss: 0.7934474533676731
Validation loss: 2.368677728896639

Epoch: 6| Step: 11
Training loss: 0.3894039142092556
Validation loss: 2.371616601385343

Epoch: 6| Step: 12
Training loss: 0.7550518443768205
Validation loss: 2.3620298232554

Epoch: 6| Step: 13
Training loss: 0.9330461244660762
Validation loss: 2.3671041472821823

Epoch: 209| Step: 0
Training loss: 0.9051483956800727
Validation loss: 2.3873708776712936

Epoch: 6| Step: 1
Training loss: 0.8771054957497636
Validation loss: 2.3865202644369705

Epoch: 6| Step: 2
Training loss: 0.7466656155947826
Validation loss: 2.3839469491359138

Epoch: 6| Step: 3
Training loss: 1.1156368030596908
Validation loss: 2.3769099215034197

Epoch: 6| Step: 4
Training loss: 0.981740271432427
Validation loss: 2.38960614156017

Epoch: 6| Step: 5
Training loss: 0.5163771028127265
Validation loss: 2.4070861007311923

Epoch: 6| Step: 6
Training loss: 0.9354776185588429
Validation loss: 2.4114322682649973

Epoch: 6| Step: 7
Training loss: 1.0441696168675698
Validation loss: 2.410307370057853

Epoch: 6| Step: 8
Training loss: 0.6446595497747739
Validation loss: 2.438991955619765

Epoch: 6| Step: 9
Training loss: 0.9553483140076559
Validation loss: 2.4269065435177053

Epoch: 6| Step: 10
Training loss: 1.5872667126192548
Validation loss: 2.441633574766105

Epoch: 6| Step: 11
Training loss: 1.0400072549603576
Validation loss: 2.4277758599031856

Epoch: 6| Step: 12
Training loss: 1.1207582190963388
Validation loss: 2.438117003094068

Epoch: 6| Step: 13
Training loss: 0.7672096513397669
Validation loss: 2.421119010397046

Epoch: 210| Step: 0
Training loss: 0.7741936734446814
Validation loss: 2.4072794231120604

Epoch: 6| Step: 1
Training loss: 0.6825168737833803
Validation loss: 2.4040322398753093

Epoch: 6| Step: 2
Training loss: 1.2795044242868856
Validation loss: 2.3900336871315453

Epoch: 6| Step: 3
Training loss: 1.4447542504285875
Validation loss: 2.395308667088956

Epoch: 6| Step: 4
Training loss: 0.8226020469089141
Validation loss: 2.4080850725805063

Epoch: 6| Step: 5
Training loss: 0.6516028897141766
Validation loss: 2.4156477063230466

Epoch: 6| Step: 6
Training loss: 0.8252478227329509
Validation loss: 2.3979959137853943

Epoch: 6| Step: 7
Training loss: 1.1899017339893674
Validation loss: 2.4293123547884714

Epoch: 6| Step: 8
Training loss: 0.8608656699233201
Validation loss: 2.4412698550609546

Epoch: 6| Step: 9
Training loss: 0.7953316197223648
Validation loss: 2.4268860314034804

Epoch: 6| Step: 10
Training loss: 0.9704035521216609
Validation loss: 2.428893223085994

Epoch: 6| Step: 11
Training loss: 0.9303412182686888
Validation loss: 2.4271534601486744

Epoch: 6| Step: 12
Training loss: 1.1048214368545597
Validation loss: 2.4224064905691693

Epoch: 6| Step: 13
Training loss: 0.7704121151905393
Validation loss: 2.3845218116138485

Epoch: 211| Step: 0
Training loss: 0.947194708303059
Validation loss: 2.3935468066276937

Epoch: 6| Step: 1
Training loss: 0.6233715299728131
Validation loss: 2.360829907183119

Epoch: 6| Step: 2
Training loss: 1.0677031850303025
Validation loss: 2.371290147249186

Epoch: 6| Step: 3
Training loss: 1.1141674596878308
Validation loss: 2.3998471964282992

Epoch: 6| Step: 4
Training loss: 0.9908690515972216
Validation loss: 2.423676954978254

Epoch: 6| Step: 5
Training loss: 0.82993586499254
Validation loss: 2.45754073644472

Epoch: 6| Step: 6
Training loss: 1.079796863101558
Validation loss: 2.4462039741375152

Epoch: 6| Step: 7
Training loss: 0.9846009797365877
Validation loss: 2.4657469824096454

Epoch: 6| Step: 8
Training loss: 1.3012077846513523
Validation loss: 2.452791121119171

Epoch: 6| Step: 9
Training loss: 0.7484713313792566
Validation loss: 2.4535427340044222

Epoch: 6| Step: 10
Training loss: 0.7639080570205037
Validation loss: 2.4271912122786103

Epoch: 6| Step: 11
Training loss: 0.7964649641469591
Validation loss: 2.4138614783104

Epoch: 6| Step: 12
Training loss: 0.9072113528583268
Validation loss: 2.3995211289294622

Epoch: 6| Step: 13
Training loss: 1.2982744226977456
Validation loss: 2.3493179414549967

Epoch: 212| Step: 0
Training loss: 0.8816872235829961
Validation loss: 2.3678319159412142

Epoch: 6| Step: 1
Training loss: 0.6919055364429434
Validation loss: 2.3533716382997096

Epoch: 6| Step: 2
Training loss: 1.15915315464316
Validation loss: 2.3542870071439457

Epoch: 6| Step: 3
Training loss: 0.6167302671274765
Validation loss: 2.3828720071894316

Epoch: 6| Step: 4
Training loss: 0.9610470034847161
Validation loss: 2.3871267461516448

Epoch: 6| Step: 5
Training loss: 1.0551893382545334
Validation loss: 2.406058078075027

Epoch: 6| Step: 6
Training loss: 0.7540997271748864
Validation loss: 2.4352070236056904

Epoch: 6| Step: 7
Training loss: 1.377993057059084
Validation loss: 2.489411541258185

Epoch: 6| Step: 8
Training loss: 0.7735275062054647
Validation loss: 2.4988356124423423

Epoch: 6| Step: 9
Training loss: 0.8188637064826259
Validation loss: 2.5039887039000277

Epoch: 6| Step: 10
Training loss: 0.9799574168354103
Validation loss: 2.4824650639049386

Epoch: 6| Step: 11
Training loss: 1.15551115606874
Validation loss: 2.417372161043448

Epoch: 6| Step: 12
Training loss: 0.864479303803927
Validation loss: 2.3817091920063875

Epoch: 6| Step: 13
Training loss: 1.3717903476049036
Validation loss: 2.3543164275203488

Epoch: 213| Step: 0
Training loss: 0.9356395062358539
Validation loss: 2.331966220119892

Epoch: 6| Step: 1
Training loss: 0.9946736703499122
Validation loss: 2.3865673845004376

Epoch: 6| Step: 2
Training loss: 1.1254234576641224
Validation loss: 2.4273577482223585

Epoch: 6| Step: 3
Training loss: 0.7694987178838905
Validation loss: 2.4436958811593663

Epoch: 6| Step: 4
Training loss: 0.8820253762251485
Validation loss: 2.457985821274288

Epoch: 6| Step: 5
Training loss: 1.0568004776337763
Validation loss: 2.4964753541161144

Epoch: 6| Step: 6
Training loss: 1.01915701943981
Validation loss: 2.504641171783966

Epoch: 6| Step: 7
Training loss: 1.0151246819234367
Validation loss: 2.505641953368024

Epoch: 6| Step: 8
Training loss: 1.0625522264098701
Validation loss: 2.4933342442876336

Epoch: 6| Step: 9
Training loss: 0.7822145992130977
Validation loss: 2.4314595085464394

Epoch: 6| Step: 10
Training loss: 0.5293625231356803
Validation loss: 2.4008052054088687

Epoch: 6| Step: 11
Training loss: 1.4265810042953768
Validation loss: 2.38644981302367

Epoch: 6| Step: 12
Training loss: 0.7686024206284685
Validation loss: 2.396571481070088

Epoch: 6| Step: 13
Training loss: 0.9652290964696256
Validation loss: 2.3669316573787356

Epoch: 214| Step: 0
Training loss: 0.9054717964864962
Validation loss: 2.360938015391135

Epoch: 6| Step: 1
Training loss: 1.0050973913345438
Validation loss: 2.382667743408528

Epoch: 6| Step: 2
Training loss: 1.0546027255426205
Validation loss: 2.374145774628304

Epoch: 6| Step: 3
Training loss: 0.8230791575324706
Validation loss: 2.4118441387366056

Epoch: 6| Step: 4
Training loss: 1.464138176426805
Validation loss: 2.4535162541667184

Epoch: 6| Step: 5
Training loss: 0.839926853060507
Validation loss: 2.4444819356921372

Epoch: 6| Step: 6
Training loss: 1.255591522651557
Validation loss: 2.402447068415186

Epoch: 6| Step: 7
Training loss: 0.8775045110037727
Validation loss: 2.4035748069839866

Epoch: 6| Step: 8
Training loss: 0.4635125340368797
Validation loss: 2.3808498014086505

Epoch: 6| Step: 9
Training loss: 0.7762103228172812
Validation loss: 2.3520388630551317

Epoch: 6| Step: 10
Training loss: 0.7432342375858777
Validation loss: 2.3637327661395395

Epoch: 6| Step: 11
Training loss: 0.9664634669148983
Validation loss: 2.367792944000909

Epoch: 6| Step: 12
Training loss: 0.6120508571324884
Validation loss: 2.382045035493089

Epoch: 6| Step: 13
Training loss: 1.347883166683503
Validation loss: 2.375143388997515

Epoch: 215| Step: 0
Training loss: 0.6177325678719704
Validation loss: 2.398499854411869

Epoch: 6| Step: 1
Training loss: 0.7484995615160925
Validation loss: 2.435955500120345

Epoch: 6| Step: 2
Training loss: 0.7575679659804005
Validation loss: 2.446419597461582

Epoch: 6| Step: 3
Training loss: 0.7982186975049371
Validation loss: 2.4638234145415883

Epoch: 6| Step: 4
Training loss: 1.0909105774117949
Validation loss: 2.47317617248528

Epoch: 6| Step: 5
Training loss: 1.016199272363016
Validation loss: 2.4411079895936414

Epoch: 6| Step: 6
Training loss: 0.7868913675170918
Validation loss: 2.4260546642286696

Epoch: 6| Step: 7
Training loss: 0.5984535633451177
Validation loss: 2.399172347890186

Epoch: 6| Step: 8
Training loss: 0.9958538290066737
Validation loss: 2.394909982972232

Epoch: 6| Step: 9
Training loss: 1.16499496082313
Validation loss: 2.383343566640508

Epoch: 6| Step: 10
Training loss: 0.7186000916428671
Validation loss: 2.3701220938657896

Epoch: 6| Step: 11
Training loss: 0.9423161142098647
Validation loss: 2.3630132615601602

Epoch: 6| Step: 12
Training loss: 1.467537724596548
Validation loss: 2.3788944916753065

Epoch: 6| Step: 13
Training loss: 1.2130080702183794
Validation loss: 2.3666703254773105

Epoch: 216| Step: 0
Training loss: 0.538703605486338
Validation loss: 2.4066371917839935

Epoch: 6| Step: 1
Training loss: 0.9433487917225478
Validation loss: 2.398904971640472

Epoch: 6| Step: 2
Training loss: 1.2928887656558827
Validation loss: 2.43713315249369

Epoch: 6| Step: 3
Training loss: 0.8222310473495421
Validation loss: 2.441327613400914

Epoch: 6| Step: 4
Training loss: 0.5759876797322082
Validation loss: 2.389098516853341

Epoch: 6| Step: 5
Training loss: 0.5229558294254203
Validation loss: 2.4007996955572684

Epoch: 6| Step: 6
Training loss: 0.9737357464923632
Validation loss: 2.39801111600241

Epoch: 6| Step: 7
Training loss: 0.9290863144918242
Validation loss: 2.383150126481052

Epoch: 6| Step: 8
Training loss: 1.0820067915923643
Validation loss: 2.4108884479049593

Epoch: 6| Step: 9
Training loss: 0.9420631934005037
Validation loss: 2.406204893885072

Epoch: 6| Step: 10
Training loss: 0.7916811933355851
Validation loss: 2.3970325926478866

Epoch: 6| Step: 11
Training loss: 1.2177900788883993
Validation loss: 2.4188868215234165

Epoch: 6| Step: 12
Training loss: 0.7971576114735481
Validation loss: 2.410163517066779

Epoch: 6| Step: 13
Training loss: 1.0816175861322777
Validation loss: 2.4422833941778967

Epoch: 217| Step: 0
Training loss: 0.8748069959040695
Validation loss: 2.418420373492849

Epoch: 6| Step: 1
Training loss: 1.1996955048159148
Validation loss: 2.4419148989203032

Epoch: 6| Step: 2
Training loss: 0.8318838785960193
Validation loss: 2.419017359942067

Epoch: 6| Step: 3
Training loss: 1.2106127888108456
Validation loss: 2.424582922026901

Epoch: 6| Step: 4
Training loss: 0.5924226077755754
Validation loss: 2.425773509757977

Epoch: 6| Step: 5
Training loss: 1.0016721811211524
Validation loss: 2.39003738772932

Epoch: 6| Step: 6
Training loss: 0.5258445055520858
Validation loss: 2.398770413614255

Epoch: 6| Step: 7
Training loss: 0.5978140529167716
Validation loss: 2.402126086499139

Epoch: 6| Step: 8
Training loss: 0.514740676865855
Validation loss: 2.3983685210083934

Epoch: 6| Step: 9
Training loss: 1.1753952051633199
Validation loss: 2.432238042486718

Epoch: 6| Step: 10
Training loss: 0.8677524410423382
Validation loss: 2.4162788235481227

Epoch: 6| Step: 11
Training loss: 0.9480927936010102
Validation loss: 2.3986406084304535

Epoch: 6| Step: 12
Training loss: 1.1171433233316583
Validation loss: 2.4157152946466485

Epoch: 6| Step: 13
Training loss: 0.4763350647578306
Validation loss: 2.426464163088964

Epoch: 218| Step: 0
Training loss: 0.8490600212996058
Validation loss: 2.4268981931285474

Epoch: 6| Step: 1
Training loss: 0.9223540403065739
Validation loss: 2.4124865311417674

Epoch: 6| Step: 2
Training loss: 0.6686660517828875
Validation loss: 2.3990196031230657

Epoch: 6| Step: 3
Training loss: 1.131197811208493
Validation loss: 2.4146153382851163

Epoch: 6| Step: 4
Training loss: 0.6307378598744714
Validation loss: 2.4257693199347985

Epoch: 6| Step: 5
Training loss: 0.9950559707694785
Validation loss: 2.405559074631497

Epoch: 6| Step: 6
Training loss: 0.6696753312365741
Validation loss: 2.4239363192761303

Epoch: 6| Step: 7
Training loss: 0.7610285052451013
Validation loss: 2.4300807052674487

Epoch: 6| Step: 8
Training loss: 1.0311534720818478
Validation loss: 2.4317156699099964

Epoch: 6| Step: 9
Training loss: 0.7453175846462229
Validation loss: 2.4112380853932707

Epoch: 6| Step: 10
Training loss: 0.9486451790443198
Validation loss: 2.415381180564951

Epoch: 6| Step: 11
Training loss: 0.9631528052512891
Validation loss: 2.411616308487589

Epoch: 6| Step: 12
Training loss: 1.0877550681015198
Validation loss: 2.3978821239479995

Epoch: 6| Step: 13
Training loss: 0.5792076695516628
Validation loss: 2.4380673541502063

Epoch: 219| Step: 0
Training loss: 1.2438600424387711
Validation loss: 2.402904076921721

Epoch: 6| Step: 1
Training loss: 1.171524147917988
Validation loss: 2.4187247936345786

Epoch: 6| Step: 2
Training loss: 0.8268311307403974
Validation loss: 2.4099944228501484

Epoch: 6| Step: 3
Training loss: 1.0232263594785018
Validation loss: 2.38144010483099

Epoch: 6| Step: 4
Training loss: 0.6038627243642022
Validation loss: 2.3487355940381245

Epoch: 6| Step: 5
Training loss: 0.694423128171769
Validation loss: 2.3472217969106626

Epoch: 6| Step: 6
Training loss: 0.8053449889006953
Validation loss: 2.3620489373631526

Epoch: 6| Step: 7
Training loss: 0.7943821980099993
Validation loss: 2.361429218403501

Epoch: 6| Step: 8
Training loss: 0.7697332281730541
Validation loss: 2.382749690951656

Epoch: 6| Step: 9
Training loss: 0.8367385591215459
Validation loss: 2.4178184682444157

Epoch: 6| Step: 10
Training loss: 0.4971057901668351
Validation loss: 2.417926488242581

Epoch: 6| Step: 11
Training loss: 1.026193242890663
Validation loss: 2.450584687934773

Epoch: 6| Step: 12
Training loss: 0.9292237222941625
Validation loss: 2.457679267506028

Epoch: 6| Step: 13
Training loss: 0.6698484463946407
Validation loss: 2.4685673426093206

Epoch: 220| Step: 0
Training loss: 1.3558004891267088
Validation loss: 2.4591774621838307

Epoch: 6| Step: 1
Training loss: 0.8956061821908619
Validation loss: 2.432957507084659

Epoch: 6| Step: 2
Training loss: 1.1838360528976895
Validation loss: 2.410598537463566

Epoch: 6| Step: 3
Training loss: 0.6987770646164712
Validation loss: 2.3790275973438946

Epoch: 6| Step: 4
Training loss: 0.4814953729629027
Validation loss: 2.352522760030297

Epoch: 6| Step: 5
Training loss: 0.7508846866674412
Validation loss: 2.3242571212566863

Epoch: 6| Step: 6
Training loss: 0.8532021861389488
Validation loss: 2.3138877963620392

Epoch: 6| Step: 7
Training loss: 0.6215236543510326
Validation loss: 2.321125053835029

Epoch: 6| Step: 8
Training loss: 0.9243596102637296
Validation loss: 2.323811116108391

Epoch: 6| Step: 9
Training loss: 0.6187036458386632
Validation loss: 2.387854530341871

Epoch: 6| Step: 10
Training loss: 0.8734428992471341
Validation loss: 2.4226988122683046

Epoch: 6| Step: 11
Training loss: 0.5905040556585073
Validation loss: 2.4895842934004766

Epoch: 6| Step: 12
Training loss: 0.9967809363683787
Validation loss: 2.505941059771453

Epoch: 6| Step: 13
Training loss: 1.419570900463542
Validation loss: 2.4656509693128306

Epoch: 221| Step: 0
Training loss: 0.8048719916834732
Validation loss: 2.4316871801694386

Epoch: 6| Step: 1
Training loss: 1.209944828840636
Validation loss: 2.396595277759186

Epoch: 6| Step: 2
Training loss: 0.5780613322898379
Validation loss: 2.393182957978962

Epoch: 6| Step: 3
Training loss: 0.6638506158621741
Validation loss: 2.336520887752336

Epoch: 6| Step: 4
Training loss: 1.0679624053610344
Validation loss: 2.333110039071719

Epoch: 6| Step: 5
Training loss: 0.9625131668081971
Validation loss: 2.3360564745889256

Epoch: 6| Step: 6
Training loss: 0.7496337791235395
Validation loss: 2.3153033006457506

Epoch: 6| Step: 7
Training loss: 0.8417100618210385
Validation loss: 2.3114650375874626

Epoch: 6| Step: 8
Training loss: 1.1357812325349943
Validation loss: 2.2827087432444646

Epoch: 6| Step: 9
Training loss: 1.0076270117579316
Validation loss: 2.3288234519972226

Epoch: 6| Step: 10
Training loss: 0.7044704492068996
Validation loss: 2.3469551795983223

Epoch: 6| Step: 11
Training loss: 0.6470982382908802
Validation loss: 2.3980805414422894

Epoch: 6| Step: 12
Training loss: 0.7640736491320144
Validation loss: 2.412042969026273

Epoch: 6| Step: 13
Training loss: 0.6217266912305485
Validation loss: 2.432720327753621

Epoch: 222| Step: 0
Training loss: 0.6174675752644138
Validation loss: 2.4281803771103307

Epoch: 6| Step: 1
Training loss: 0.8171952373072702
Validation loss: 2.447823554427916

Epoch: 6| Step: 2
Training loss: 1.10168001887261
Validation loss: 2.4446893835296377

Epoch: 6| Step: 3
Training loss: 0.5809889812343823
Validation loss: 2.4593948980342333

Epoch: 6| Step: 4
Training loss: 0.7705294336493348
Validation loss: 2.4176823119364395

Epoch: 6| Step: 5
Training loss: 0.5715678521057459
Validation loss: 2.415964931349108

Epoch: 6| Step: 6
Training loss: 0.9185053454219164
Validation loss: 2.3771096258071944

Epoch: 6| Step: 7
Training loss: 0.7520446721616322
Validation loss: 2.3808041949548975

Epoch: 6| Step: 8
Training loss: 1.218152951447819
Validation loss: 2.3902914710144203

Epoch: 6| Step: 9
Training loss: 0.9229045872870134
Validation loss: 2.379281923261422

Epoch: 6| Step: 10
Training loss: 0.6796252342730286
Validation loss: 2.3867579123733313

Epoch: 6| Step: 11
Training loss: 0.9396281565077412
Validation loss: 2.3626083182080655

Epoch: 6| Step: 12
Training loss: 0.7655864238752067
Validation loss: 2.373099630567763

Epoch: 6| Step: 13
Training loss: 0.8022765178797177
Validation loss: 2.4048899288204137

Epoch: 223| Step: 0
Training loss: 1.0746484070611808
Validation loss: 2.385485849659298

Epoch: 6| Step: 1
Training loss: 0.4706639000468671
Validation loss: 2.4098406603167164

Epoch: 6| Step: 2
Training loss: 0.8264787613504714
Validation loss: 2.421672303142444

Epoch: 6| Step: 3
Training loss: 0.8467821809359733
Validation loss: 2.4063811983571264

Epoch: 6| Step: 4
Training loss: 0.7353614512636059
Validation loss: 2.3986673686195172

Epoch: 6| Step: 5
Training loss: 0.6325101247738544
Validation loss: 2.4082719170455107

Epoch: 6| Step: 6
Training loss: 0.8838207597475394
Validation loss: 2.4089411354939

Epoch: 6| Step: 7
Training loss: 1.2484242043485443
Validation loss: 2.4063026948232187

Epoch: 6| Step: 8
Training loss: 0.5646523780645667
Validation loss: 2.40671171678916

Epoch: 6| Step: 9
Training loss: 0.8299784521959707
Validation loss: 2.4182280467153423

Epoch: 6| Step: 10
Training loss: 0.7138549970637494
Validation loss: 2.424652186134334

Epoch: 6| Step: 11
Training loss: 0.7668301575599159
Validation loss: 2.401109853868071

Epoch: 6| Step: 12
Training loss: 0.581256171162978
Validation loss: 2.3882141664831704

Epoch: 6| Step: 13
Training loss: 1.0755575818794996
Validation loss: 2.365750389673535

Epoch: 224| Step: 0
Training loss: 1.1536556728566294
Validation loss: 2.374904229630053

Epoch: 6| Step: 1
Training loss: 0.7980549621919145
Validation loss: 2.3304949354637743

Epoch: 6| Step: 2
Training loss: 0.36549282619308887
Validation loss: 2.316247629970048

Epoch: 6| Step: 3
Training loss: 0.9509223124945719
Validation loss: 2.3336478349530685

Epoch: 6| Step: 4
Training loss: 0.9172622234312927
Validation loss: 2.3172072769188565

Epoch: 6| Step: 5
Training loss: 1.01928205111956
Validation loss: 2.343981972429746

Epoch: 6| Step: 6
Training loss: 0.9303139891787121
Validation loss: 2.3790368463685074

Epoch: 6| Step: 7
Training loss: 0.5019189251481508
Validation loss: 2.3744294194132776

Epoch: 6| Step: 8
Training loss: 0.6126363485733292
Validation loss: 2.421163177413358

Epoch: 6| Step: 9
Training loss: 0.5970361022831906
Validation loss: 2.4551188314742127

Epoch: 6| Step: 10
Training loss: 0.9122906980460745
Validation loss: 2.437284246024694

Epoch: 6| Step: 11
Training loss: 0.8789140489020305
Validation loss: 2.4129960947377374

Epoch: 6| Step: 12
Training loss: 0.756058777522399
Validation loss: 2.3809840844427077

Epoch: 6| Step: 13
Training loss: 0.5264972533148028
Validation loss: 2.3664211024979194

Epoch: 225| Step: 0
Training loss: 0.44846336874963966
Validation loss: 2.346161909665887

Epoch: 6| Step: 1
Training loss: 0.7446637655134501
Validation loss: 2.361678166512101

Epoch: 6| Step: 2
Training loss: 0.924184847263918
Validation loss: 2.324020629612069

Epoch: 6| Step: 3
Training loss: 1.1640508254317044
Validation loss: 2.3237301515674598

Epoch: 6| Step: 4
Training loss: 0.7267089203994253
Validation loss: 2.331105718799827

Epoch: 6| Step: 5
Training loss: 0.9221241501158771
Validation loss: 2.3661052306849553

Epoch: 6| Step: 6
Training loss: 0.8273369980663537
Validation loss: 2.3440491067769678

Epoch: 6| Step: 7
Training loss: 0.3458216943371754
Validation loss: 2.3788311728897527

Epoch: 6| Step: 8
Training loss: 0.7260882973348219
Validation loss: 2.4154136639239736

Epoch: 6| Step: 9
Training loss: 0.8709436124731543
Validation loss: 2.4243728126026394

Epoch: 6| Step: 10
Training loss: 0.8380691942699647
Validation loss: 2.464158612817602

Epoch: 6| Step: 11
Training loss: 0.8546411003056933
Validation loss: 2.462356169407156

Epoch: 6| Step: 12
Training loss: 0.8539084222457074
Validation loss: 2.427570055674816

Epoch: 6| Step: 13
Training loss: 0.8733806270856506
Validation loss: 2.426445278007717

Epoch: 226| Step: 0
Training loss: 0.5639598235199988
Validation loss: 2.38212152122219

Epoch: 6| Step: 1
Training loss: 0.8836175067112786
Validation loss: 2.3773450796649107

Epoch: 6| Step: 2
Training loss: 1.2441570095258947
Validation loss: 2.3430506211719786

Epoch: 6| Step: 3
Training loss: 0.4740044777453457
Validation loss: 2.3769408285259215

Epoch: 6| Step: 4
Training loss: 0.4533328861989359
Validation loss: 2.3749945791082254

Epoch: 6| Step: 5
Training loss: 0.7348724871594259
Validation loss: 2.3859749467736764

Epoch: 6| Step: 6
Training loss: 0.7237031107127367
Validation loss: 2.4287888299574836

Epoch: 6| Step: 7
Training loss: 0.6209135453893165
Validation loss: 2.4643860733272667

Epoch: 6| Step: 8
Training loss: 1.1365469052176
Validation loss: 2.460910380406593

Epoch: 6| Step: 9
Training loss: 1.0442466193964774
Validation loss: 2.4281041760906503

Epoch: 6| Step: 10
Training loss: 0.6851994430167835
Validation loss: 2.3860889810528993

Epoch: 6| Step: 11
Training loss: 0.6674707352012961
Validation loss: 2.339603420837524

Epoch: 6| Step: 12
Training loss: 0.7905573518181156
Validation loss: 2.349777269008294

Epoch: 6| Step: 13
Training loss: 0.8342990326319919
Validation loss: 2.3264388038395625

Epoch: 227| Step: 0
Training loss: 0.377786180322519
Validation loss: 2.32103855196111

Epoch: 6| Step: 1
Training loss: 0.7902428891019806
Validation loss: 2.306971517475719

Epoch: 6| Step: 2
Training loss: 0.9404648628667891
Validation loss: 2.3281831438823604

Epoch: 6| Step: 3
Training loss: 0.8922875263107067
Validation loss: 2.343962223193397

Epoch: 6| Step: 4
Training loss: 0.8907843999266657
Validation loss: 2.3877970788076746

Epoch: 6| Step: 5
Training loss: 1.181551137010467
Validation loss: 2.4053128296193744

Epoch: 6| Step: 6
Training loss: 0.6989615835880789
Validation loss: 2.4328727564700654

Epoch: 6| Step: 7
Training loss: 0.42340525613463037
Validation loss: 2.4633663267457977

Epoch: 6| Step: 8
Training loss: 0.9687421244639554
Validation loss: 2.4490591517511726

Epoch: 6| Step: 9
Training loss: 0.6045345852331709
Validation loss: 2.4711256786590208

Epoch: 6| Step: 10
Training loss: 0.8891398444833021
Validation loss: 2.455370635246087

Epoch: 6| Step: 11
Training loss: 0.7173549963473136
Validation loss: 2.4057791741624612

Epoch: 6| Step: 12
Training loss: 0.5936973950020965
Validation loss: 2.3771499203279856

Epoch: 6| Step: 13
Training loss: 0.7701400439986875
Validation loss: 2.368283510586051

Epoch: 228| Step: 0
Training loss: 0.6446313491310373
Validation loss: 2.336685758268731

Epoch: 6| Step: 1
Training loss: 1.250743597108417
Validation loss: 2.324037788635217

Epoch: 6| Step: 2
Training loss: 0.5641116260893299
Validation loss: 2.3338533913676023

Epoch: 6| Step: 3
Training loss: 1.0979935205959788
Validation loss: 2.303224278544267

Epoch: 6| Step: 4
Training loss: 0.7798057940385001
Validation loss: 2.327162853296134

Epoch: 6| Step: 5
Training loss: 0.5545538083000141
Validation loss: 2.3421296390237107

Epoch: 6| Step: 6
Training loss: 0.6718567246901326
Validation loss: 2.3385773400306955

Epoch: 6| Step: 7
Training loss: 0.7405519634562577
Validation loss: 2.3856669268401465

Epoch: 6| Step: 8
Training loss: 0.42747702324897824
Validation loss: 2.39320958209047

Epoch: 6| Step: 9
Training loss: 0.6341559901155418
Validation loss: 2.408367870480718

Epoch: 6| Step: 10
Training loss: 0.7081515041418032
Validation loss: 2.418432328679772

Epoch: 6| Step: 11
Training loss: 0.6326027039686286
Validation loss: 2.4217817740438017

Epoch: 6| Step: 12
Training loss: 0.9149562020580932
Validation loss: 2.409907099317359

Epoch: 6| Step: 13
Training loss: 1.0260059653846774
Validation loss: 2.396439925914833

Epoch: 229| Step: 0
Training loss: 0.8832230415106356
Validation loss: 2.3783729017711446

Epoch: 6| Step: 1
Training loss: 1.1878417175922689
Validation loss: 2.3540666769320273

Epoch: 6| Step: 2
Training loss: 0.6662391891461228
Validation loss: 2.3610561612575602

Epoch: 6| Step: 3
Training loss: 0.480734573270483
Validation loss: 2.334012420742545

Epoch: 6| Step: 4
Training loss: 0.8303385247576535
Validation loss: 2.33790663474174

Epoch: 6| Step: 5
Training loss: 0.5380198581781502
Validation loss: 2.3203991421851375

Epoch: 6| Step: 6
Training loss: 0.5281339588195447
Validation loss: 2.349469962004174

Epoch: 6| Step: 7
Training loss: 0.8294725789877581
Validation loss: 2.3792225649486083

Epoch: 6| Step: 8
Training loss: 0.6396766714606101
Validation loss: 2.3874942489122666

Epoch: 6| Step: 9
Training loss: 0.7789990996305383
Validation loss: 2.38624577976366

Epoch: 6| Step: 10
Training loss: 0.883362084196745
Validation loss: 2.4184620987252785

Epoch: 6| Step: 11
Training loss: 0.682067016327939
Validation loss: 2.3951645255140326

Epoch: 6| Step: 12
Training loss: 0.6778695359246352
Validation loss: 2.40369393841582

Epoch: 6| Step: 13
Training loss: 0.8986870460586044
Validation loss: 2.3737858128068354

Epoch: 230| Step: 0
Training loss: 0.9013063486713457
Validation loss: 2.371431749807804

Epoch: 6| Step: 1
Training loss: 0.8150705608878744
Validation loss: 2.36607210234308

Epoch: 6| Step: 2
Training loss: 0.5535522987207043
Validation loss: 2.355309068634368

Epoch: 6| Step: 3
Training loss: 0.7239161463093358
Validation loss: 2.3444751440822436

Epoch: 6| Step: 4
Training loss: 0.7011238868039401
Validation loss: 2.348205758715339

Epoch: 6| Step: 5
Training loss: 0.8512009719420025
Validation loss: 2.3786944322943233

Epoch: 6| Step: 6
Training loss: 0.7303636444687134
Validation loss: 2.3818410823501597

Epoch: 6| Step: 7
Training loss: 0.8370016223590947
Validation loss: 2.360485578029822

Epoch: 6| Step: 8
Training loss: 0.8312867464820481
Validation loss: 2.387010703136366

Epoch: 6| Step: 9
Training loss: 0.5635848181016515
Validation loss: 2.378116584570949

Epoch: 6| Step: 10
Training loss: 0.417847803032424
Validation loss: 2.3979772305349267

Epoch: 6| Step: 11
Training loss: 0.6338065075934772
Validation loss: 2.3826192496730574

Epoch: 6| Step: 12
Training loss: 1.0971670995351475
Validation loss: 2.3864239750538

Epoch: 6| Step: 13
Training loss: 0.22498491653906005
Validation loss: 2.347071924519067

Epoch: 231| Step: 0
Training loss: 0.5203168851650444
Validation loss: 2.3352128428732803

Epoch: 6| Step: 1
Training loss: 0.9994698549717818
Validation loss: 2.377791710164645

Epoch: 6| Step: 2
Training loss: 0.7957153484171551
Validation loss: 2.3620301694835866

Epoch: 6| Step: 3
Training loss: 0.6749973712092885
Validation loss: 2.372131892370951

Epoch: 6| Step: 4
Training loss: 0.5099175179390187
Validation loss: 2.36936520148301

Epoch: 6| Step: 5
Training loss: 0.9414358807091284
Validation loss: 2.3517141846852008

Epoch: 6| Step: 6
Training loss: 0.6375823453939503
Validation loss: 2.357333162444128

Epoch: 6| Step: 7
Training loss: 0.6028357568252163
Validation loss: 2.3306622814857283

Epoch: 6| Step: 8
Training loss: 0.4593709413517826
Validation loss: 2.3342652365245677

Epoch: 6| Step: 9
Training loss: 0.8784802570067717
Validation loss: 2.344263766183467

Epoch: 6| Step: 10
Training loss: 0.7814346858119381
Validation loss: 2.3269218930912245

Epoch: 6| Step: 11
Training loss: 0.7048497133842038
Validation loss: 2.3250574413361753

Epoch: 6| Step: 12
Training loss: 0.9195570171573618
Validation loss: 2.369603490181493

Epoch: 6| Step: 13
Training loss: 0.674056105815499
Validation loss: 2.3678493440243322

Epoch: 232| Step: 0
Training loss: 0.28512641019025076
Validation loss: 2.3654401279550332

Epoch: 6| Step: 1
Training loss: 0.3158458173334483
Validation loss: 2.358528636804268

Epoch: 6| Step: 2
Training loss: 0.8044784422476078
Validation loss: 2.365615205059997

Epoch: 6| Step: 3
Training loss: 0.8540013936498201
Validation loss: 2.359283615001712

Epoch: 6| Step: 4
Training loss: 0.36077711001367246
Validation loss: 2.3551542181995466

Epoch: 6| Step: 5
Training loss: 0.5882021056657993
Validation loss: 2.32357392259567

Epoch: 6| Step: 6
Training loss: 0.7240507537982231
Validation loss: 2.3327129289272475

Epoch: 6| Step: 7
Training loss: 0.8809657064403357
Validation loss: 2.345949069146694

Epoch: 6| Step: 8
Training loss: 1.0786199124824452
Validation loss: 2.3204984563125257

Epoch: 6| Step: 9
Training loss: 0.7653214378349049
Validation loss: 2.353222583542312

Epoch: 6| Step: 10
Training loss: 0.7876253164581646
Validation loss: 2.348669059732441

Epoch: 6| Step: 11
Training loss: 0.8857304783628615
Validation loss: 2.3622119246779176

Epoch: 6| Step: 12
Training loss: 0.6911112700278511
Validation loss: 2.340780025078692

Epoch: 6| Step: 13
Training loss: 0.6695718323416764
Validation loss: 2.3515230654595154

Epoch: 233| Step: 0
Training loss: 0.6815544445571009
Validation loss: 2.3396638774429737

Epoch: 6| Step: 1
Training loss: 1.105308440214191
Validation loss: 2.374167297963512

Epoch: 6| Step: 2
Training loss: 0.34778999584840636
Validation loss: 2.355068955878576

Epoch: 6| Step: 3
Training loss: 0.3597627082565647
Validation loss: 2.3703815575687677

Epoch: 6| Step: 4
Training loss: 0.5231645071500161
Validation loss: 2.408534619599921

Epoch: 6| Step: 5
Training loss: 1.0032685031624715
Validation loss: 2.3979131658508974

Epoch: 6| Step: 6
Training loss: 0.7427874098132405
Validation loss: 2.407541228757358

Epoch: 6| Step: 7
Training loss: 0.5955472148047084
Validation loss: 2.3594107763355088

Epoch: 6| Step: 8
Training loss: 0.4525627561383312
Validation loss: 2.3596406898558353

Epoch: 6| Step: 9
Training loss: 0.7075037773489791
Validation loss: 2.346453365910254

Epoch: 6| Step: 10
Training loss: 0.8425320912936308
Validation loss: 2.359152160413141

Epoch: 6| Step: 11
Training loss: 0.7817625271946599
Validation loss: 2.3603176924848563

Epoch: 6| Step: 12
Training loss: 0.8410907447813694
Validation loss: 2.3634688433523485

Epoch: 6| Step: 13
Training loss: 0.8783875354628573
Validation loss: 2.346640818195472

Epoch: 234| Step: 0
Training loss: 0.8187214635287644
Validation loss: 2.3555087475560925

Epoch: 6| Step: 1
Training loss: 0.5659188640017995
Validation loss: 2.3451783053680275

Epoch: 6| Step: 2
Training loss: 0.30057543363802436
Validation loss: 2.3244409080131865

Epoch: 6| Step: 3
Training loss: 0.656510051791251
Validation loss: 2.34644911147851

Epoch: 6| Step: 4
Training loss: 0.4967836104024557
Validation loss: 2.3491401802972476

Epoch: 6| Step: 5
Training loss: 0.5062431146600881
Validation loss: 2.395228791350011

Epoch: 6| Step: 6
Training loss: 0.6183207766739435
Validation loss: 2.3611348534809276

Epoch: 6| Step: 7
Training loss: 0.9203952616085943
Validation loss: 2.3511834946217403

Epoch: 6| Step: 8
Training loss: 0.7211274755987217
Validation loss: 2.352640942748436

Epoch: 6| Step: 9
Training loss: 0.7989461200747145
Validation loss: 2.357244825563665

Epoch: 6| Step: 10
Training loss: 0.494867355848428
Validation loss: 2.3349264889150922

Epoch: 6| Step: 11
Training loss: 1.1283222522689207
Validation loss: 2.3498134145800225

Epoch: 6| Step: 12
Training loss: 0.9264376281169964
Validation loss: 2.3543823057033606

Epoch: 6| Step: 13
Training loss: 0.6656683410718346
Validation loss: 2.351077654091963

Epoch: 235| Step: 0
Training loss: 0.9323636813915758
Validation loss: 2.33812557560012

Epoch: 6| Step: 1
Training loss: 0.6256617618929805
Validation loss: 2.3711633808022334

Epoch: 6| Step: 2
Training loss: 0.7123928056356861
Validation loss: 2.3560817253349264

Epoch: 6| Step: 3
Training loss: 0.3890886995004468
Validation loss: 2.3604154258805643

Epoch: 6| Step: 4
Training loss: 0.643073380996546
Validation loss: 2.3530140163133395

Epoch: 6| Step: 5
Training loss: 0.6813342436052178
Validation loss: 2.3655470436015156

Epoch: 6| Step: 6
Training loss: 0.9620283804412815
Validation loss: 2.354188130729443

Epoch: 6| Step: 7
Training loss: 0.6988816967341241
Validation loss: 2.3625256416494915

Epoch: 6| Step: 8
Training loss: 0.7550829070719828
Validation loss: 2.360823739225916

Epoch: 6| Step: 9
Training loss: 0.6423335668025296
Validation loss: 2.357357863095534

Epoch: 6| Step: 10
Training loss: 0.5723187158323491
Validation loss: 2.362310986158463

Epoch: 6| Step: 11
Training loss: 0.9764846770749005
Validation loss: 2.3328837823767086

Epoch: 6| Step: 12
Training loss: 0.47424134164506665
Validation loss: 2.3341950431886587

Epoch: 6| Step: 13
Training loss: 0.5055688443492616
Validation loss: 2.325684191756913

Epoch: 236| Step: 0
Training loss: 0.9352281381865778
Validation loss: 2.3410680464732407

Epoch: 6| Step: 1
Training loss: 0.8372937190389873
Validation loss: 2.333028010217892

Epoch: 6| Step: 2
Training loss: 0.38813585671614514
Validation loss: 2.3601866153776516

Epoch: 6| Step: 3
Training loss: 0.664644524817506
Validation loss: 2.3601853450634693

Epoch: 6| Step: 4
Training loss: 0.48312144965363807
Validation loss: 2.3654252241682734

Epoch: 6| Step: 5
Training loss: 0.6273667346738991
Validation loss: 2.3857923499251936

Epoch: 6| Step: 6
Training loss: 0.91357340320773
Validation loss: 2.409379866600322

Epoch: 6| Step: 7
Training loss: 0.6117359300249545
Validation loss: 2.358671869584629

Epoch: 6| Step: 8
Training loss: 0.3851011913942339
Validation loss: 2.369028532218988

Epoch: 6| Step: 9
Training loss: 0.8878847094303941
Validation loss: 2.333070308023537

Epoch: 6| Step: 10
Training loss: 0.6202211307909135
Validation loss: 2.340866776526977

Epoch: 6| Step: 11
Training loss: 0.6144898526709519
Validation loss: 2.3206463352620514

Epoch: 6| Step: 12
Training loss: 0.9066111404114847
Validation loss: 2.345786737624647

Epoch: 6| Step: 13
Training loss: 0.6814979906787204
Validation loss: 2.3373741083537722

Epoch: 237| Step: 0
Training loss: 0.6775269204594273
Validation loss: 2.3351006392506783

Epoch: 6| Step: 1
Training loss: 0.5388368604255318
Validation loss: 2.3608556690893088

Epoch: 6| Step: 2
Training loss: 0.7256536644687936
Validation loss: 2.370358539237228

Epoch: 6| Step: 3
Training loss: 0.7355230164469607
Validation loss: 2.3521285796539564

Epoch: 6| Step: 4
Training loss: 0.9187876842840865
Validation loss: 2.388476396089802

Epoch: 6| Step: 5
Training loss: 0.8342096529227226
Validation loss: 2.3761334351173193

Epoch: 6| Step: 6
Training loss: 0.7760870662099575
Validation loss: 2.3641240758711395

Epoch: 6| Step: 7
Training loss: 0.5929917462982313
Validation loss: 2.353633533482832

Epoch: 6| Step: 8
Training loss: 0.7364433461507349
Validation loss: 2.345181216981434

Epoch: 6| Step: 9
Training loss: 0.42983808479749647
Validation loss: 2.351964764960052

Epoch: 6| Step: 10
Training loss: 0.39955815558456265
Validation loss: 2.3440667871481238

Epoch: 6| Step: 11
Training loss: 0.6950686595126898
Validation loss: 2.364544675755963

Epoch: 6| Step: 12
Training loss: 0.8939142556407945
Validation loss: 2.3793387038895895

Epoch: 6| Step: 13
Training loss: 0.5681803313149157
Validation loss: 2.3883822429707053

Epoch: 238| Step: 0
Training loss: 0.5240797401463158
Validation loss: 2.39468920372975

Epoch: 6| Step: 1
Training loss: 0.324051894489843
Validation loss: 2.4263780440447174

Epoch: 6| Step: 2
Training loss: 0.4977506916255926
Validation loss: 2.4366930511193305

Epoch: 6| Step: 3
Training loss: 0.5795647246936071
Validation loss: 2.414829638682791

Epoch: 6| Step: 4
Training loss: 0.49592013587671957
Validation loss: 2.3858322898818307

Epoch: 6| Step: 5
Training loss: 0.5088068104172702
Validation loss: 2.395529892490536

Epoch: 6| Step: 6
Training loss: 0.868451546098654
Validation loss: 2.3633807081465856

Epoch: 6| Step: 7
Training loss: 0.3409531779753564
Validation loss: 2.329610950093231

Epoch: 6| Step: 8
Training loss: 0.9200151724186231
Validation loss: 2.345284007134802

Epoch: 6| Step: 9
Training loss: 0.823448544451716
Validation loss: 2.323899730484149

Epoch: 6| Step: 10
Training loss: 0.9850693932889838
Validation loss: 2.2989038711126626

Epoch: 6| Step: 11
Training loss: 0.7007919599890561
Validation loss: 2.344220825813547

Epoch: 6| Step: 12
Training loss: 0.869372904738665
Validation loss: 2.33773449685629

Epoch: 6| Step: 13
Training loss: 0.7994848410604858
Validation loss: 2.3508507995216017

Epoch: 239| Step: 0
Training loss: 0.5991509639192646
Validation loss: 2.364171814725877

Epoch: 6| Step: 1
Training loss: 0.7694412798497032
Validation loss: 2.3704828115631997

Epoch: 6| Step: 2
Training loss: 0.5399366561065272
Validation loss: 2.3849574297776353

Epoch: 6| Step: 3
Training loss: 0.2855751018427811
Validation loss: 2.3822063275492993

Epoch: 6| Step: 4
Training loss: 0.7433868355021335
Validation loss: 2.367694344671953

Epoch: 6| Step: 5
Training loss: 0.5549401258700155
Validation loss: 2.377282056608193

Epoch: 6| Step: 6
Training loss: 1.1459623899895799
Validation loss: 2.353625023883361

Epoch: 6| Step: 7
Training loss: 0.853686422547168
Validation loss: 2.363077978404193

Epoch: 6| Step: 8
Training loss: 0.5971879308550292
Validation loss: 2.347199923822883

Epoch: 6| Step: 9
Training loss: 0.8108311901345178
Validation loss: 2.385311376584828

Epoch: 6| Step: 10
Training loss: 0.5186336766085157
Validation loss: 2.37912760300693

Epoch: 6| Step: 11
Training loss: 0.5520198503618848
Validation loss: 2.377238669289204

Epoch: 6| Step: 12
Training loss: 0.38600715518283896
Validation loss: 2.3971563248765433

Epoch: 6| Step: 13
Training loss: 0.6419702919016428
Validation loss: 2.386934083548462

Epoch: 240| Step: 0
Training loss: 0.7124205829463487
Validation loss: 2.390530529081851

Epoch: 6| Step: 1
Training loss: 0.6479198273789156
Validation loss: 2.3903971464345575

Epoch: 6| Step: 2
Training loss: 0.7362995901068049
Validation loss: 2.348180823685283

Epoch: 6| Step: 3
Training loss: 0.7529263626203339
Validation loss: 2.33135251671497

Epoch: 6| Step: 4
Training loss: 0.5986654698983672
Validation loss: 2.3187803229467145

Epoch: 6| Step: 5
Training loss: 0.5352685629500152
Validation loss: 2.324436180951768

Epoch: 6| Step: 6
Training loss: 0.8420561636748142
Validation loss: 2.3132915178772655

Epoch: 6| Step: 7
Training loss: 0.49046566435106687
Validation loss: 2.318906949795288

Epoch: 6| Step: 8
Training loss: 0.9596220487425247
Validation loss: 2.3590674647772687

Epoch: 6| Step: 9
Training loss: 0.8333854579518254
Validation loss: 2.313138767144972

Epoch: 6| Step: 10
Training loss: 0.5870096443024114
Validation loss: 2.327891991464876

Epoch: 6| Step: 11
Training loss: 0.4441317917239796
Validation loss: 2.32495539218091

Epoch: 6| Step: 12
Training loss: 0.4453324597888125
Validation loss: 2.323792813861133

Epoch: 6| Step: 13
Training loss: 0.5143898417393094
Validation loss: 2.362286059477441

Epoch: 241| Step: 0
Training loss: 0.8479134305725079
Validation loss: 2.3602829492557413

Epoch: 6| Step: 1
Training loss: 0.7511188982345776
Validation loss: 2.3780675301606635

Epoch: 6| Step: 2
Training loss: 0.5949370414218363
Validation loss: 2.4109327768196294

Epoch: 6| Step: 3
Training loss: 0.5039594163865931
Validation loss: 2.396751162372059

Epoch: 6| Step: 4
Training loss: 0.6244749247767738
Validation loss: 2.3716216181505305

Epoch: 6| Step: 5
Training loss: 0.6288201646351904
Validation loss: 2.3720943203991705

Epoch: 6| Step: 6
Training loss: 0.6003764461711977
Validation loss: 2.3754425910159456

Epoch: 6| Step: 7
Training loss: 0.5224222044090167
Validation loss: 2.338341569802757

Epoch: 6| Step: 8
Training loss: 0.7412591046550928
Validation loss: 2.3437469569907723

Epoch: 6| Step: 9
Training loss: 0.658756917377903
Validation loss: 2.348978189356676

Epoch: 6| Step: 10
Training loss: 0.7187811388651112
Validation loss: 2.3599601041290463

Epoch: 6| Step: 11
Training loss: 0.6605658078991065
Validation loss: 2.3809098018114576

Epoch: 6| Step: 12
Training loss: 0.7466992622382062
Validation loss: 2.3479586479135386

Epoch: 6| Step: 13
Training loss: 0.5030896571285691
Validation loss: 2.379770226000433

Epoch: 242| Step: 0
Training loss: 0.48287522485674966
Validation loss: 2.3491361118893064

Epoch: 6| Step: 1
Training loss: 0.49202792290404296
Validation loss: 2.3599745258936444

Epoch: 6| Step: 2
Training loss: 0.8112422671779749
Validation loss: 2.3602234134595634

Epoch: 6| Step: 3
Training loss: 0.7054035988904336
Validation loss: 2.3675311706260285

Epoch: 6| Step: 4
Training loss: 0.4573925579002707
Validation loss: 2.364527829387822

Epoch: 6| Step: 5
Training loss: 1.0311416800282014
Validation loss: 2.340116856168866

Epoch: 6| Step: 6
Training loss: 0.5455533542327512
Validation loss: 2.3099900670258187

Epoch: 6| Step: 7
Training loss: 0.2511115842751342
Validation loss: 2.3214063571677066

Epoch: 6| Step: 8
Training loss: 0.50139402727093
Validation loss: 2.315334574967645

Epoch: 6| Step: 9
Training loss: 0.6544629242131419
Validation loss: 2.322341488135736

Epoch: 6| Step: 10
Training loss: 0.8230726037985089
Validation loss: 2.309312075881472

Epoch: 6| Step: 11
Training loss: 0.7676794553076038
Validation loss: 2.3150196112366834

Epoch: 6| Step: 12
Training loss: 0.6195561311398881
Validation loss: 2.3469246401436967

Epoch: 6| Step: 13
Training loss: 0.6548029294826969
Validation loss: 2.3729933479767977

Epoch: 243| Step: 0
Training loss: 0.46404940589901283
Validation loss: 2.3730484889916355

Epoch: 6| Step: 1
Training loss: 0.6017948296492492
Validation loss: 2.377888017039869

Epoch: 6| Step: 2
Training loss: 0.49843779536988886
Validation loss: 2.402843420109793

Epoch: 6| Step: 3
Training loss: 0.4821623749037054
Validation loss: 2.389422438146753

Epoch: 6| Step: 4
Training loss: 0.5018555364480671
Validation loss: 2.4025433675924153

Epoch: 6| Step: 5
Training loss: 0.9327708172710434
Validation loss: 2.4130853213131767

Epoch: 6| Step: 6
Training loss: 0.7774817952787697
Validation loss: 2.3675475993097366

Epoch: 6| Step: 7
Training loss: 0.7411285877343613
Validation loss: 2.3406675324831543

Epoch: 6| Step: 8
Training loss: 0.5803397259875949
Validation loss: 2.3388643573589123

Epoch: 6| Step: 9
Training loss: 0.675684684954326
Validation loss: 2.340102288470091

Epoch: 6| Step: 10
Training loss: 0.6073448892852092
Validation loss: 2.329497201704169

Epoch: 6| Step: 11
Training loss: 0.880319840329855
Validation loss: 2.3184766708204103

Epoch: 6| Step: 12
Training loss: 0.41323438641913823
Validation loss: 2.31425116766271

Epoch: 6| Step: 13
Training loss: 0.7875044141373219
Validation loss: 2.3306196586569614

Epoch: 244| Step: 0
Training loss: 0.5553700451935739
Validation loss: 2.3326911555299805

Epoch: 6| Step: 1
Training loss: 0.7461974386493828
Validation loss: 2.352027070691493

Epoch: 6| Step: 2
Training loss: 0.3948997061192454
Validation loss: 2.3454793335059594

Epoch: 6| Step: 3
Training loss: 0.5643525611497576
Validation loss: 2.38142510363709

Epoch: 6| Step: 4
Training loss: 0.9004331235309939
Validation loss: 2.384098977798254

Epoch: 6| Step: 5
Training loss: 0.789377546208157
Validation loss: 2.3504302938028725

Epoch: 6| Step: 6
Training loss: 0.2101429527358582
Validation loss: 2.3605651184570506

Epoch: 6| Step: 7
Training loss: 0.767554595819595
Validation loss: 2.3563208906121482

Epoch: 6| Step: 8
Training loss: 1.0095951371730245
Validation loss: 2.3450135421685503

Epoch: 6| Step: 9
Training loss: 0.2705503492272724
Validation loss: 2.305179591938733

Epoch: 6| Step: 10
Training loss: 0.5637583432986375
Validation loss: 2.345724866142892

Epoch: 6| Step: 11
Training loss: 0.6920264528185351
Validation loss: 2.343436937650717

Epoch: 6| Step: 12
Training loss: 0.4757507790515513
Validation loss: 2.3513492166855103

Epoch: 6| Step: 13
Training loss: 0.38127479394431035
Validation loss: 2.362423655946505

Epoch: 245| Step: 0
Training loss: 0.6508712367459454
Validation loss: 2.3624530205713814

Epoch: 6| Step: 1
Training loss: 0.3323603401652487
Validation loss: 2.3735392730239955

Epoch: 6| Step: 2
Training loss: 0.5705198668682481
Validation loss: 2.343758453572659

Epoch: 6| Step: 3
Training loss: 0.770050106276106
Validation loss: 2.3441901113006622

Epoch: 6| Step: 4
Training loss: 0.8100605804253441
Validation loss: 2.359570518019725

Epoch: 6| Step: 5
Training loss: 0.8246883482818461
Validation loss: 2.3455022833986767

Epoch: 6| Step: 6
Training loss: 0.6913769387104369
Validation loss: 2.375507684750713

Epoch: 6| Step: 7
Training loss: 0.5643604294848837
Validation loss: 2.358243408352611

Epoch: 6| Step: 8
Training loss: 0.40549595250956616
Validation loss: 2.380984024146682

Epoch: 6| Step: 9
Training loss: 0.8736887370886103
Validation loss: 2.358228973555368

Epoch: 6| Step: 10
Training loss: 0.3872298898960884
Validation loss: 2.3661129060835684

Epoch: 6| Step: 11
Training loss: 0.35975597753853944
Validation loss: 2.3818726120740656

Epoch: 6| Step: 12
Training loss: 0.6278320046675702
Validation loss: 2.3364623890271288

Epoch: 6| Step: 13
Training loss: 0.7478653411113988
Validation loss: 2.3736913823581696

Epoch: 246| Step: 0
Training loss: 0.6730534620178567
Validation loss: 2.342349929746968

Epoch: 6| Step: 1
Training loss: 0.8834784030249991
Validation loss: 2.3433180697462457

Epoch: 6| Step: 2
Training loss: 0.755162472264177
Validation loss: 2.3453890302691347

Epoch: 6| Step: 3
Training loss: 0.483974953006293
Validation loss: 2.3533753540627287

Epoch: 6| Step: 4
Training loss: 0.5547494987977193
Validation loss: 2.313320948742655

Epoch: 6| Step: 5
Training loss: 0.539306364322728
Validation loss: 2.348080684046908

Epoch: 6| Step: 6
Training loss: 0.2501748040137234
Validation loss: 2.320448919651365

Epoch: 6| Step: 7
Training loss: 0.6266091612376573
Validation loss: 2.322776167369389

Epoch: 6| Step: 8
Training loss: 0.728756616735764
Validation loss: 2.335684796350468

Epoch: 6| Step: 9
Training loss: 0.6343376242615619
Validation loss: 2.329402663016459

Epoch: 6| Step: 10
Training loss: 0.9532630382699643
Validation loss: 2.383852381872943

Epoch: 6| Step: 11
Training loss: 0.31535187224967465
Validation loss: 2.378400063538521

Epoch: 6| Step: 12
Training loss: 0.5413419930334261
Validation loss: 2.3829965472945704

Epoch: 6| Step: 13
Training loss: 0.46481691811962267
Validation loss: 2.375791613132419

Epoch: 247| Step: 0
Training loss: 0.7572741611841405
Validation loss: 2.4003165167942035

Epoch: 6| Step: 1
Training loss: 0.42103972575013854
Validation loss: 2.406420022630721

Epoch: 6| Step: 2
Training loss: 0.5549876515844788
Validation loss: 2.388065037446999

Epoch: 6| Step: 3
Training loss: 0.6936147944692451
Validation loss: 2.361308417701166

Epoch: 6| Step: 4
Training loss: 0.4024885157907455
Validation loss: 2.3420145315992724

Epoch: 6| Step: 5
Training loss: 0.8915454057137072
Validation loss: 2.325851255087479

Epoch: 6| Step: 6
Training loss: 0.25763827997468713
Validation loss: 2.321266439780788

Epoch: 6| Step: 7
Training loss: 0.7074342285290905
Validation loss: 2.3013957425026654

Epoch: 6| Step: 8
Training loss: 0.6988477735065408
Validation loss: 2.3037849178644403

Epoch: 6| Step: 9
Training loss: 0.5724214725693415
Validation loss: 2.3182739813784052

Epoch: 6| Step: 10
Training loss: 0.5575138938352853
Validation loss: 2.3261174732121583

Epoch: 6| Step: 11
Training loss: 0.7148428328044406
Validation loss: 2.356861520990708

Epoch: 6| Step: 12
Training loss: 0.4287897615374045
Validation loss: 2.3686080006701604

Epoch: 6| Step: 13
Training loss: 0.8960591556486396
Validation loss: 2.371408428161974

Epoch: 248| Step: 0
Training loss: 0.7079317880788875
Validation loss: 2.3457239514544588

Epoch: 6| Step: 1
Training loss: 0.8263365669320583
Validation loss: 2.3720434792188048

Epoch: 6| Step: 2
Training loss: 0.7102036513822039
Validation loss: 2.338672834236282

Epoch: 6| Step: 3
Training loss: 0.4632642823275463
Validation loss: 2.335866069534965

Epoch: 6| Step: 4
Training loss: 0.8323654792975567
Validation loss: 2.372338890133507

Epoch: 6| Step: 5
Training loss: 0.5156663820249088
Validation loss: 2.3629920277394403

Epoch: 6| Step: 6
Training loss: 0.42542929495482584
Validation loss: 2.3565690304941045

Epoch: 6| Step: 7
Training loss: 0.325963850556326
Validation loss: 2.363508156677204

Epoch: 6| Step: 8
Training loss: 0.737285042810521
Validation loss: 2.3664749368838263

Epoch: 6| Step: 9
Training loss: 0.45666373384478337
Validation loss: 2.337299424697993

Epoch: 6| Step: 10
Training loss: 0.7048492694250481
Validation loss: 2.3593894698903966

Epoch: 6| Step: 11
Training loss: 0.4795284529449338
Validation loss: 2.3696253441761606

Epoch: 6| Step: 12
Training loss: 0.4442709068247595
Validation loss: 2.367524256727888

Epoch: 6| Step: 13
Training loss: 0.8984171657748992
Validation loss: 2.3616739139973535

Epoch: 249| Step: 0
Training loss: 0.5408621339618779
Validation loss: 2.359074270881112

Epoch: 6| Step: 1
Training loss: 0.8224931705620329
Validation loss: 2.3517784166974383

Epoch: 6| Step: 2
Training loss: 0.7258679341267436
Validation loss: 2.38582504863502

Epoch: 6| Step: 3
Training loss: 0.6645828452352647
Validation loss: 2.381175118273621

Epoch: 6| Step: 4
Training loss: 0.6454050787404062
Validation loss: 2.3733392996187055

Epoch: 6| Step: 5
Training loss: 0.44557647242893256
Validation loss: 2.3349781278405457

Epoch: 6| Step: 6
Training loss: 0.7499344320246408
Validation loss: 2.3647757282040653

Epoch: 6| Step: 7
Training loss: 0.5068039782964104
Validation loss: 2.3613295929711304

Epoch: 6| Step: 8
Training loss: 0.6803374416701384
Validation loss: 2.381350034886794

Epoch: 6| Step: 9
Training loss: 0.3667947616760019
Validation loss: 2.3782784405615067

Epoch: 6| Step: 10
Training loss: 0.42435298011405764
Validation loss: 2.3565987922522864

Epoch: 6| Step: 11
Training loss: 0.6054089424373912
Validation loss: 2.33925950376777

Epoch: 6| Step: 12
Training loss: 0.7247592328928636
Validation loss: 2.323546179502157

Epoch: 6| Step: 13
Training loss: 0.43597828663995275
Validation loss: 2.3488879147652657

Epoch: 250| Step: 0
Training loss: 0.7247679914653994
Validation loss: 2.332369271948823

Epoch: 6| Step: 1
Training loss: 0.7072300921133183
Validation loss: 2.3451681461209475

Epoch: 6| Step: 2
Training loss: 0.5892845180631444
Validation loss: 2.3361039990787145

Epoch: 6| Step: 3
Training loss: 0.6390951311505864
Validation loss: 2.3524217552122666

Epoch: 6| Step: 4
Training loss: 0.40241811120700943
Validation loss: 2.3674354408484066

Epoch: 6| Step: 5
Training loss: 0.488892744541618
Validation loss: 2.375303279292732

Epoch: 6| Step: 6
Training loss: 0.7544241198814126
Validation loss: 2.3612114443644856

Epoch: 6| Step: 7
Training loss: 0.5390408829487267
Validation loss: 2.3688979630775955

Epoch: 6| Step: 8
Training loss: 0.4530358062302411
Validation loss: 2.3965065818501405

Epoch: 6| Step: 9
Training loss: 0.5428736212298095
Validation loss: 2.3557710885668275

Epoch: 6| Step: 10
Training loss: 0.5678903801120215
Validation loss: 2.391653203467207

Epoch: 6| Step: 11
Training loss: 0.698613464241118
Validation loss: 2.3564014044424617

Epoch: 6| Step: 12
Training loss: 0.682668986831419
Validation loss: 2.3641630269625704

Epoch: 6| Step: 13
Training loss: 0.6835407781512822
Validation loss: 2.3501561646423315

Epoch: 251| Step: 0
Training loss: 0.5347429057520553
Validation loss: 2.333500698638412

Epoch: 6| Step: 1
Training loss: 0.6828984893845242
Validation loss: 2.3230187464325667

Epoch: 6| Step: 2
Training loss: 0.3684836298413327
Validation loss: 2.349540770480626

Epoch: 6| Step: 3
Training loss: 0.6295352893812423
Validation loss: 2.359377951139014

Epoch: 6| Step: 4
Training loss: 0.7500609134733263
Validation loss: 2.3282792796679614

Epoch: 6| Step: 5
Training loss: 0.5665425629850555
Validation loss: 2.3194780558732493

Epoch: 6| Step: 6
Training loss: 0.7200404896874885
Validation loss: 2.379147692855893

Epoch: 6| Step: 7
Training loss: 0.40795529521961144
Validation loss: 2.347223462518313

Epoch: 6| Step: 8
Training loss: 0.7152089921248399
Validation loss: 2.3687772407667804

Epoch: 6| Step: 9
Training loss: 0.6231989420845714
Validation loss: 2.375252812244174

Epoch: 6| Step: 10
Training loss: 0.5726268786799456
Validation loss: 2.3777319728643946

Epoch: 6| Step: 11
Training loss: 0.6190727990962792
Validation loss: 2.3569935846289765

Epoch: 6| Step: 12
Training loss: 0.7023486619890023
Validation loss: 2.3812486325523468

Epoch: 6| Step: 13
Training loss: 0.2213260333564616
Validation loss: 2.348614053116377

Epoch: 252| Step: 0
Training loss: 0.8116888251860345
Validation loss: 2.331766339231351

Epoch: 6| Step: 1
Training loss: 0.6281684670662461
Validation loss: 2.3279480168667184

Epoch: 6| Step: 2
Training loss: 0.2620704621993903
Validation loss: 2.349610935806979

Epoch: 6| Step: 3
Training loss: 0.8609288126927784
Validation loss: 2.3384150484879256

Epoch: 6| Step: 4
Training loss: 0.7182969033487988
Validation loss: 2.327963700742249

Epoch: 6| Step: 5
Training loss: 0.8079121246000364
Validation loss: 2.3150271287739486

Epoch: 6| Step: 6
Training loss: 0.5727279930399208
Validation loss: 2.3248198536678504

Epoch: 6| Step: 7
Training loss: 0.37392663325454034
Validation loss: 2.338743788743041

Epoch: 6| Step: 8
Training loss: 0.5865144051216143
Validation loss: 2.345501075083736

Epoch: 6| Step: 9
Training loss: 0.41673680152313913
Validation loss: 2.348246741353113

Epoch: 6| Step: 10
Training loss: 0.5837657098065309
Validation loss: 2.3717002014032933

Epoch: 6| Step: 11
Training loss: 0.5404932137097697
Validation loss: 2.3735441107508595

Epoch: 6| Step: 12
Training loss: 0.20650822773399077
Validation loss: 2.356819695579371

Epoch: 6| Step: 13
Training loss: 0.5036845643681834
Validation loss: 2.385231363016985

Epoch: 253| Step: 0
Training loss: 0.7891412827848074
Validation loss: 2.367794414324955

Epoch: 6| Step: 1
Training loss: 0.5839300991594987
Validation loss: 2.3409056907814985

Epoch: 6| Step: 2
Training loss: 0.5933852078990379
Validation loss: 2.3661577834805256

Epoch: 6| Step: 3
Training loss: 0.37586747605785936
Validation loss: 2.358943770226222

Epoch: 6| Step: 4
Training loss: 0.3575430492677723
Validation loss: 2.326106909450194

Epoch: 6| Step: 5
Training loss: 0.5526936384630393
Validation loss: 2.307293580357057

Epoch: 6| Step: 6
Training loss: 0.5879517583649952
Validation loss: 2.3170929458983514

Epoch: 6| Step: 7
Training loss: 0.661160174075495
Validation loss: 2.337726357071481

Epoch: 6| Step: 8
Training loss: 0.47499953822063284
Validation loss: 2.3385510005381422

Epoch: 6| Step: 9
Training loss: 1.0028747721850932
Validation loss: 2.3592316420216126

Epoch: 6| Step: 10
Training loss: 0.455609056902882
Validation loss: 2.347025973830177

Epoch: 6| Step: 11
Training loss: 0.5664930868997999
Validation loss: 2.373546621958171

Epoch: 6| Step: 12
Training loss: 0.5168919747550815
Validation loss: 2.37304698654263

Epoch: 6| Step: 13
Training loss: 0.28342773475353866
Validation loss: 2.3715508019765457

Epoch: 254| Step: 0
Training loss: 0.6608938577009553
Validation loss: 2.3592905736947296

Epoch: 6| Step: 1
Training loss: 0.4928178686310354
Validation loss: 2.3540282840840865

Epoch: 6| Step: 2
Training loss: 0.5118235415256276
Validation loss: 2.336324889777748

Epoch: 6| Step: 3
Training loss: 0.5101570292959059
Validation loss: 2.3394982201652175

Epoch: 6| Step: 4
Training loss: 0.35388185699136493
Validation loss: 2.342751026621296

Epoch: 6| Step: 5
Training loss: 0.7228766028069674
Validation loss: 2.3428613401324774

Epoch: 6| Step: 6
Training loss: 0.5452274846479107
Validation loss: 2.3404155460323226

Epoch: 6| Step: 7
Training loss: 0.2643570650839547
Validation loss: 2.344935228377817

Epoch: 6| Step: 8
Training loss: 0.7196913235654314
Validation loss: 2.361904738218258

Epoch: 6| Step: 9
Training loss: 0.6555729734289878
Validation loss: 2.3474184888112775

Epoch: 6| Step: 10
Training loss: 0.5106030013763099
Validation loss: 2.3438757011586318

Epoch: 6| Step: 11
Training loss: 0.8447416976719422
Validation loss: 2.3381329437406957

Epoch: 6| Step: 12
Training loss: 0.6118510876542961
Validation loss: 2.348116172822782

Epoch: 6| Step: 13
Training loss: 0.20701617959790625
Validation loss: 2.3604819815230225

Epoch: 255| Step: 0
Training loss: 0.1347840061644466
Validation loss: 2.371832390529124

Epoch: 6| Step: 1
Training loss: 0.19491495682053533
Validation loss: 2.360528088944068

Epoch: 6| Step: 2
Training loss: 0.8141908657911885
Validation loss: 2.3778324324697384

Epoch: 6| Step: 3
Training loss: 0.7495260330473507
Validation loss: 2.3782221369511145

Epoch: 6| Step: 4
Training loss: 0.5380563606676756
Validation loss: 2.3596599504305056

Epoch: 6| Step: 5
Training loss: 0.41073230073052214
Validation loss: 2.358806526138937

Epoch: 6| Step: 6
Training loss: 0.6439222290603847
Validation loss: 2.335841532334193

Epoch: 6| Step: 7
Training loss: 0.6332797221238995
Validation loss: 2.3368570233644697

Epoch: 6| Step: 8
Training loss: 0.7141838988899959
Validation loss: 2.3270234368175915

Epoch: 6| Step: 9
Training loss: 0.7253434403643868
Validation loss: 2.329268412917866

Epoch: 6| Step: 10
Training loss: 0.6802968768392275
Validation loss: 2.3242471617550016

Epoch: 6| Step: 11
Training loss: 0.613049724635918
Validation loss: 2.322532510208805

Epoch: 6| Step: 12
Training loss: 0.261841930040262
Validation loss: 2.3187307473686287

Epoch: 6| Step: 13
Training loss: 0.22388657078109547
Validation loss: 2.334175085664464

Epoch: 256| Step: 0
Training loss: 0.19992348429191295
Validation loss: 2.3178252941529722

Epoch: 6| Step: 1
Training loss: 0.5469029828133068
Validation loss: 2.3326659741535765

Epoch: 6| Step: 2
Training loss: 0.7354833882424849
Validation loss: 2.341591169874931

Epoch: 6| Step: 3
Training loss: 0.8060374001825297
Validation loss: 2.387447802696723

Epoch: 6| Step: 4
Training loss: 0.5766682700959922
Validation loss: 2.3766197834830938

Epoch: 6| Step: 5
Training loss: 0.6418959408234894
Validation loss: 2.3856372133935464

Epoch: 6| Step: 6
Training loss: 0.5779534420431371
Validation loss: 2.385260347979059

Epoch: 6| Step: 7
Training loss: 0.48461634253167346
Validation loss: 2.3780999992828393

Epoch: 6| Step: 8
Training loss: 0.39389621502427413
Validation loss: 2.384591744818032

Epoch: 6| Step: 9
Training loss: 0.6535033467126097
Validation loss: 2.401187435230458

Epoch: 6| Step: 10
Training loss: 0.7205829054886076
Validation loss: 2.3759662387589002

Epoch: 6| Step: 11
Training loss: 0.5516212496929328
Validation loss: 2.365172635596988

Epoch: 6| Step: 12
Training loss: 0.2787272506676716
Validation loss: 2.343396579251741

Epoch: 6| Step: 13
Training loss: 0.09892797684186488
Validation loss: 2.353446489476961

Epoch: 257| Step: 0
Training loss: 0.5892840123255209
Validation loss: 2.3487389793173024

Epoch: 6| Step: 1
Training loss: 0.6227761520520869
Validation loss: 2.346197416538511

Epoch: 6| Step: 2
Training loss: 0.4846691960925108
Validation loss: 2.3253617671114544

Epoch: 6| Step: 3
Training loss: 0.44251454730825474
Validation loss: 2.3510010831032035

Epoch: 6| Step: 4
Training loss: 0.2798460782549015
Validation loss: 2.360766725580421

Epoch: 6| Step: 5
Training loss: 0.2369564153767934
Validation loss: 2.3775266280604113

Epoch: 6| Step: 6
Training loss: 0.6839284023212137
Validation loss: 2.3612889686333807

Epoch: 6| Step: 7
Training loss: 0.4543970110833985
Validation loss: 2.360981068135479

Epoch: 6| Step: 8
Training loss: 0.4839611746805471
Validation loss: 2.377152297098854

Epoch: 6| Step: 9
Training loss: 0.5813641661637433
Validation loss: 2.3682624798981333

Epoch: 6| Step: 10
Training loss: 0.8134158914387328
Validation loss: 2.375924145959305

Epoch: 6| Step: 11
Training loss: 0.642131429855772
Validation loss: 2.343225314022301

Epoch: 6| Step: 12
Training loss: 0.44140162507731595
Validation loss: 2.3575125535624575

Epoch: 6| Step: 13
Training loss: 0.9228424233281758
Validation loss: 2.356463400305983

Epoch: 258| Step: 0
Training loss: 0.7428658046060231
Validation loss: 2.3653236084353026

Epoch: 6| Step: 1
Training loss: 0.4160769242807238
Validation loss: 2.3725295470795493

Epoch: 6| Step: 2
Training loss: 0.7623046968828064
Validation loss: 2.3538140637167984

Epoch: 6| Step: 3
Training loss: 0.7543276463953197
Validation loss: 2.3325802819134296

Epoch: 6| Step: 4
Training loss: 0.3889296936963256
Validation loss: 2.3160233378184407

Epoch: 6| Step: 5
Training loss: 0.3853086522104371
Validation loss: 2.311104509452605

Epoch: 6| Step: 6
Training loss: 0.5385663333706372
Validation loss: 2.326859968958117

Epoch: 6| Step: 7
Training loss: 0.5936448355449541
Validation loss: 2.32934869162139

Epoch: 6| Step: 8
Training loss: 0.306890179594684
Validation loss: 2.3343001931980583

Epoch: 6| Step: 9
Training loss: 0.807518691268818
Validation loss: 2.347781711988083

Epoch: 6| Step: 10
Training loss: 0.6427704079903467
Validation loss: 2.364194095202955

Epoch: 6| Step: 11
Training loss: 0.3988410177958445
Validation loss: 2.364532505031378

Epoch: 6| Step: 12
Training loss: 0.3569201716079415
Validation loss: 2.375792420275124

Epoch: 6| Step: 13
Training loss: 0.23395717252566203
Validation loss: 2.36451591282466

Epoch: 259| Step: 0
Training loss: 0.16123775186153053
Validation loss: 2.3578570939892414

Epoch: 6| Step: 1
Training loss: 0.6438604389751861
Validation loss: 2.3804691028511584

Epoch: 6| Step: 2
Training loss: 0.4743299564391936
Validation loss: 2.375127748983828

Epoch: 6| Step: 3
Training loss: 0.5092239425033922
Validation loss: 2.356644745026366

Epoch: 6| Step: 4
Training loss: 0.5372262723466085
Validation loss: 2.3530985212795272

Epoch: 6| Step: 5
Training loss: 0.5562601495738358
Validation loss: 2.3191734830980555

Epoch: 6| Step: 6
Training loss: 0.7385270047761285
Validation loss: 2.333581420861913

Epoch: 6| Step: 7
Training loss: 0.41993468509030973
Validation loss: 2.3635278011630776

Epoch: 6| Step: 8
Training loss: 0.4934017854827178
Validation loss: 2.3345735530966825

Epoch: 6| Step: 9
Training loss: 0.6872429367124312
Validation loss: 2.3686256324742923

Epoch: 6| Step: 10
Training loss: 0.7156675834146475
Validation loss: 2.37953767967747

Epoch: 6| Step: 11
Training loss: 0.4805096244483241
Validation loss: 2.3586312278668244

Epoch: 6| Step: 12
Training loss: 0.6007489983244318
Validation loss: 2.3969590605791504

Epoch: 6| Step: 13
Training loss: 0.3893075470032877
Validation loss: 2.371191240334965

Epoch: 260| Step: 0
Training loss: 0.3809696135781424
Validation loss: 2.379896253925496

Epoch: 6| Step: 1
Training loss: 0.5808093410509892
Validation loss: 2.35840985015932

Epoch: 6| Step: 2
Training loss: 0.46023180653793194
Validation loss: 2.3614830911390325

Epoch: 6| Step: 3
Training loss: 0.7053545254215564
Validation loss: 2.3689535040532586

Epoch: 6| Step: 4
Training loss: 0.5150123192878492
Validation loss: 2.3447614012055653

Epoch: 6| Step: 5
Training loss: 0.5990660750193376
Validation loss: 2.339355743266614

Epoch: 6| Step: 6
Training loss: 0.3884030279697596
Validation loss: 2.354946929717375

Epoch: 6| Step: 7
Training loss: 0.39800395940124284
Validation loss: 2.372690305022067

Epoch: 6| Step: 8
Training loss: 0.47208647631244
Validation loss: 2.3733792239247533

Epoch: 6| Step: 9
Training loss: 0.5635493345555714
Validation loss: 2.3752762164861116

Epoch: 6| Step: 10
Training loss: 0.7533802312274064
Validation loss: 2.334047914596835

Epoch: 6| Step: 11
Training loss: 0.5599411140288645
Validation loss: 2.3414516826596232

Epoch: 6| Step: 12
Training loss: 0.6082303961665035
Validation loss: 2.3548118461524057

Epoch: 6| Step: 13
Training loss: 0.443866120847189
Validation loss: 2.3689093543729864

Epoch: 261| Step: 0
Training loss: 0.5107318592668367
Validation loss: 2.357928314905915

Epoch: 6| Step: 1
Training loss: 0.4939644691791964
Validation loss: 2.3935607346970076

Epoch: 6| Step: 2
Training loss: 0.5933020558399901
Validation loss: 2.3719735921623633

Epoch: 6| Step: 3
Training loss: 0.5541673020906558
Validation loss: 2.3513632153573045

Epoch: 6| Step: 4
Training loss: 0.6336940700071152
Validation loss: 2.3506557640778647

Epoch: 6| Step: 5
Training loss: 0.71933490339832
Validation loss: 2.352622647933788

Epoch: 6| Step: 6
Training loss: 0.4931801217363216
Validation loss: 2.3566150861063018

Epoch: 6| Step: 7
Training loss: 0.47174138204711363
Validation loss: 2.3587304951592767

Epoch: 6| Step: 8
Training loss: 0.30357398229414434
Validation loss: 2.3459477938549695

Epoch: 6| Step: 9
Training loss: 0.4433642147657098
Validation loss: 2.381655207361077

Epoch: 6| Step: 10
Training loss: 0.693609423613907
Validation loss: 2.3434188444750608

Epoch: 6| Step: 11
Training loss: 0.12773776035314036
Validation loss: 2.4032644888966392

Epoch: 6| Step: 12
Training loss: 0.6709730614884356
Validation loss: 2.376778857715843

Epoch: 6| Step: 13
Training loss: 0.5090517328855378
Validation loss: 2.375216670102586

Epoch: 262| Step: 0
Training loss: 0.6374071296663008
Validation loss: 2.3530655442921145

Epoch: 6| Step: 1
Training loss: 0.29070298471424355
Validation loss: 2.3605377085714583

Epoch: 6| Step: 2
Training loss: 0.20884618022485943
Validation loss: 2.361990007489441

Epoch: 6| Step: 3
Training loss: 0.4258852140558255
Validation loss: 2.354160984724678

Epoch: 6| Step: 4
Training loss: 0.48269068221263656
Validation loss: 2.3489722391156262

Epoch: 6| Step: 5
Training loss: 0.7691713062558363
Validation loss: 2.3261994490194553

Epoch: 6| Step: 6
Training loss: 0.5026754384740552
Validation loss: 2.330489269694266

Epoch: 6| Step: 7
Training loss: 0.519729547732158
Validation loss: 2.3229369373192155

Epoch: 6| Step: 8
Training loss: 0.20741093206186006
Validation loss: 2.3439887530226744

Epoch: 6| Step: 9
Training loss: 0.7215357573696922
Validation loss: 2.376078925662626

Epoch: 6| Step: 10
Training loss: 0.57682964473156
Validation loss: 2.3720453640862327

Epoch: 6| Step: 11
Training loss: 0.6290370734013119
Validation loss: 2.370203922999958

Epoch: 6| Step: 12
Training loss: 0.4745511933759162
Validation loss: 2.3770948690608855

Epoch: 6| Step: 13
Training loss: 0.6418057933891227
Validation loss: 2.4062294929183494

Epoch: 263| Step: 0
Training loss: 0.6596873271369075
Validation loss: 2.3866342952181907

Epoch: 6| Step: 1
Training loss: 0.23556990408097392
Validation loss: 2.395041620558799

Epoch: 6| Step: 2
Training loss: 0.5844954228886852
Validation loss: 2.3788029523532788

Epoch: 6| Step: 3
Training loss: 0.6607701984887608
Validation loss: 2.36673100489623

Epoch: 6| Step: 4
Training loss: 0.7507444898674347
Validation loss: 2.325047811086495

Epoch: 6| Step: 5
Training loss: 0.36619472213449145
Validation loss: 2.3715077638300817

Epoch: 6| Step: 6
Training loss: 0.34006131541419676
Validation loss: 2.341009909963279

Epoch: 6| Step: 7
Training loss: 0.6902962735135323
Validation loss: 2.3590315213117887

Epoch: 6| Step: 8
Training loss: 0.3644696966821464
Validation loss: 2.358262245503753

Epoch: 6| Step: 9
Training loss: 0.5417855633556639
Validation loss: 2.335372562915371

Epoch: 6| Step: 10
Training loss: 0.5405528709496987
Validation loss: 2.3944758719115256

Epoch: 6| Step: 11
Training loss: 0.35595127514448544
Validation loss: 2.392402959341972

Epoch: 6| Step: 12
Training loss: 0.5993041961107372
Validation loss: 2.355466830100225

Epoch: 6| Step: 13
Training loss: 0.3859414660292486
Validation loss: 2.357577918347934

Epoch: 264| Step: 0
Training loss: 0.3466476855484254
Validation loss: 2.359315638782506

Epoch: 6| Step: 1
Training loss: 0.45002534847920983
Validation loss: 2.343460235731556

Epoch: 6| Step: 2
Training loss: 0.34302488706139417
Validation loss: 2.340907318446203

Epoch: 6| Step: 3
Training loss: 0.4782718582502367
Validation loss: 2.321238161623936

Epoch: 6| Step: 4
Training loss: 0.3855710193065704
Validation loss: 2.312025986646578

Epoch: 6| Step: 5
Training loss: 0.9954561474202506
Validation loss: 2.3065368824068075

Epoch: 6| Step: 6
Training loss: 0.3989906771856599
Validation loss: 2.320360011077045

Epoch: 6| Step: 7
Training loss: 0.6469722877357441
Validation loss: 2.3208116050029015

Epoch: 6| Step: 8
Training loss: 0.22712380660283624
Validation loss: 2.3174093383821353

Epoch: 6| Step: 9
Training loss: 0.44235072745880716
Validation loss: 2.3305213467552655

Epoch: 6| Step: 10
Training loss: 0.23629883513734581
Validation loss: 2.3859141733255362

Epoch: 6| Step: 11
Training loss: 0.6833591603616439
Validation loss: 2.371246679485347

Epoch: 6| Step: 12
Training loss: 0.7453310598305756
Validation loss: 2.368726806219707

Epoch: 6| Step: 13
Training loss: 0.5163743902353802
Validation loss: 2.3710686166942274

Epoch: 265| Step: 0
Training loss: 0.41465829773731544
Validation loss: 2.3529790513849638

Epoch: 6| Step: 1
Training loss: 0.40453679802583237
Validation loss: 2.36124760978957

Epoch: 6| Step: 2
Training loss: 0.46797564442544004
Validation loss: 2.3484067730195957

Epoch: 6| Step: 3
Training loss: 0.44974983997352724
Validation loss: 2.341741338025455

Epoch: 6| Step: 4
Training loss: 0.6613682337594877
Validation loss: 2.3637634311564124

Epoch: 6| Step: 5
Training loss: 0.4204076042496585
Validation loss: 2.357075139189757

Epoch: 6| Step: 6
Training loss: 0.6817400840622874
Validation loss: 2.33672684859856

Epoch: 6| Step: 7
Training loss: 0.4676691468637099
Validation loss: 2.3476815487737914

Epoch: 6| Step: 8
Training loss: 0.2777135291237115
Validation loss: 2.3499803400013666

Epoch: 6| Step: 9
Training loss: 0.5890329864555691
Validation loss: 2.3860448406108397

Epoch: 6| Step: 10
Training loss: 0.7295539554045578
Validation loss: 2.396391051348444

Epoch: 6| Step: 11
Training loss: 0.5199104875310601
Validation loss: 2.3951645437098144

Epoch: 6| Step: 12
Training loss: 0.5729904271819077
Validation loss: 2.37726171428411

Epoch: 6| Step: 13
Training loss: 0.47701776364876763
Validation loss: 2.361770106342421

Epoch: 266| Step: 0
Training loss: 0.24710122770711127
Validation loss: 2.343790287232152

Epoch: 6| Step: 1
Training loss: 0.7312625916529915
Validation loss: 2.3304115293913163

Epoch: 6| Step: 2
Training loss: 0.35686687466913275
Validation loss: 2.353867520437446

Epoch: 6| Step: 3
Training loss: 0.7196666428611767
Validation loss: 2.351624351982357

Epoch: 6| Step: 4
Training loss: 0.41101799310735426
Validation loss: 2.325615587511071

Epoch: 6| Step: 5
Training loss: 0.5968039175717402
Validation loss: 2.308110637442896

Epoch: 6| Step: 6
Training loss: 0.5078581862805872
Validation loss: 2.3133122492939946

Epoch: 6| Step: 7
Training loss: 0.4359697931558968
Validation loss: 2.3388581068124825

Epoch: 6| Step: 8
Training loss: 0.5403996069408346
Validation loss: 2.3269949165657047

Epoch: 6| Step: 9
Training loss: 0.4289650305264858
Validation loss: 2.352179335762145

Epoch: 6| Step: 10
Training loss: 0.4233213286437366
Validation loss: 2.3550836176863115

Epoch: 6| Step: 11
Training loss: 0.5402899602509702
Validation loss: 2.334794966305751

Epoch: 6| Step: 12
Training loss: 0.5115013243041883
Validation loss: 2.350158674660194

Epoch: 6| Step: 13
Training loss: 0.6154787335211955
Validation loss: 2.374141356556957

Epoch: 267| Step: 0
Training loss: 0.5122537509786464
Validation loss: 2.32344858340819

Epoch: 6| Step: 1
Training loss: 0.5764245465239906
Validation loss: 2.340433104882203

Epoch: 6| Step: 2
Training loss: 0.45730432682572186
Validation loss: 2.342693024345838

Epoch: 6| Step: 3
Training loss: 0.45537614682556043
Validation loss: 2.3321188968644586

Epoch: 6| Step: 4
Training loss: 0.5780457622766386
Validation loss: 2.3463755579735834

Epoch: 6| Step: 5
Training loss: 0.37296250272967496
Validation loss: 2.356246261308653

Epoch: 6| Step: 6
Training loss: 0.508029539236917
Validation loss: 2.3786381099695917

Epoch: 6| Step: 7
Training loss: 0.5287989565322495
Validation loss: 2.3758300923846525

Epoch: 6| Step: 8
Training loss: 0.4014680647483044
Validation loss: 2.365442629883198

Epoch: 6| Step: 9
Training loss: 0.36161219796847177
Validation loss: 2.3696953989349367

Epoch: 6| Step: 10
Training loss: 0.5978373832728525
Validation loss: 2.386876450361923

Epoch: 6| Step: 11
Training loss: 0.5643286914351001
Validation loss: 2.398902038136256

Epoch: 6| Step: 12
Training loss: 0.4897008477529861
Validation loss: 2.3851453475740865

Epoch: 6| Step: 13
Training loss: 0.8549224293527564
Validation loss: 2.3508103541127205

Epoch: 268| Step: 0
Training loss: 0.399743445643882
Validation loss: 2.3564808303312206

Epoch: 6| Step: 1
Training loss: 0.35497276581142334
Validation loss: 2.3109150060700894

Epoch: 6| Step: 2
Training loss: 0.41575245301285113
Validation loss: 2.3372909417315206

Epoch: 6| Step: 3
Training loss: 0.8268587039601731
Validation loss: 2.3506980775962876

Epoch: 6| Step: 4
Training loss: 0.18585229131372982
Validation loss: 2.3596759450188425

Epoch: 6| Step: 5
Training loss: 0.5610534293151274
Validation loss: 2.36079838392024

Epoch: 6| Step: 6
Training loss: 0.8053039855862194
Validation loss: 2.369063648759184

Epoch: 6| Step: 7
Training loss: 0.3649393613950438
Validation loss: 2.372280139415727

Epoch: 6| Step: 8
Training loss: 0.6266196008476663
Validation loss: 2.377229647823792

Epoch: 6| Step: 9
Training loss: 0.2962356634936441
Validation loss: 2.387320240479829

Epoch: 6| Step: 10
Training loss: 0.48372418766007735
Validation loss: 2.3826772548219624

Epoch: 6| Step: 11
Training loss: 0.4289401404049266
Validation loss: 2.372259177659871

Epoch: 6| Step: 12
Training loss: 0.5740457910090195
Validation loss: 2.3469333886817747

Epoch: 6| Step: 13
Training loss: 0.12343659445877138
Validation loss: 2.358100264242949

Epoch: 269| Step: 0
Training loss: 0.658184492713434
Validation loss: 2.3556042040127685

Epoch: 6| Step: 1
Training loss: 0.4111407136497682
Validation loss: 2.3418174788656283

Epoch: 6| Step: 2
Training loss: 0.4610767154268081
Validation loss: 2.340135448682351

Epoch: 6| Step: 3
Training loss: 0.5047893031756774
Validation loss: 2.334224050418891

Epoch: 6| Step: 4
Training loss: 0.5449781764761887
Validation loss: 2.32926909612796

Epoch: 6| Step: 5
Training loss: 0.2201538678183184
Validation loss: 2.33998966359549

Epoch: 6| Step: 6
Training loss: 0.39394628007398336
Validation loss: 2.296492116575711

Epoch: 6| Step: 7
Training loss: 0.6236544907861372
Validation loss: 2.3326526317686915

Epoch: 6| Step: 8
Training loss: 0.6681979494441886
Validation loss: 2.3268127597269683

Epoch: 6| Step: 9
Training loss: 0.5211076268488792
Validation loss: 2.325516233956528

Epoch: 6| Step: 10
Training loss: 0.6765669956894851
Validation loss: 2.329069159886388

Epoch: 6| Step: 11
Training loss: 0.22196901237024383
Validation loss: 2.333044090413543

Epoch: 6| Step: 12
Training loss: 0.28114459923813384
Validation loss: 2.3737009634904336

Epoch: 6| Step: 13
Training loss: 0.47250374784951116
Validation loss: 2.3645043024933456

Epoch: 270| Step: 0
Training loss: 0.28187668704693175
Validation loss: 2.3751217185383413

Epoch: 6| Step: 1
Training loss: 0.4461384358380246
Validation loss: 2.3839806522739955

Epoch: 6| Step: 2
Training loss: 0.39845470316530124
Validation loss: 2.3761832485358436

Epoch: 6| Step: 3
Training loss: 0.5972777021745095
Validation loss: 2.3732916738747827

Epoch: 6| Step: 4
Training loss: 0.2494276170027233
Validation loss: 2.371823098278203

Epoch: 6| Step: 5
Training loss: 0.4083061088354943
Validation loss: 2.349006176132928

Epoch: 6| Step: 6
Training loss: 0.6753356214004737
Validation loss: 2.361862293328592

Epoch: 6| Step: 7
Training loss: 0.533607748582448
Validation loss: 2.3673972615573664

Epoch: 6| Step: 8
Training loss: 0.40660620625263166
Validation loss: 2.3592423894317016

Epoch: 6| Step: 9
Training loss: 0.46692502485319015
Validation loss: 2.337096619184755

Epoch: 6| Step: 10
Training loss: 0.4618299218093895
Validation loss: 2.345070436480124

Epoch: 6| Step: 11
Training loss: 0.3709703340596996
Validation loss: 2.3687028339973972

Epoch: 6| Step: 12
Training loss: 0.5515207507188743
Validation loss: 2.3756359163270533

Epoch: 6| Step: 13
Training loss: 0.9490623502257037
Validation loss: 2.3605128956632693

Epoch: 271| Step: 0
Training loss: 0.6230791854851286
Validation loss: 2.3693025964414685

Epoch: 6| Step: 1
Training loss: 0.3777154911847806
Validation loss: 2.373857192995951

Epoch: 6| Step: 2
Training loss: 0.3545624634413059
Validation loss: 2.3729683152768395

Epoch: 6| Step: 3
Training loss: 0.48728713498965076
Validation loss: 2.3674899987956373

Epoch: 6| Step: 4
Training loss: 0.14173653845302353
Validation loss: 2.3493218960605784

Epoch: 6| Step: 5
Training loss: 0.5921018463030601
Validation loss: 2.341091868024654

Epoch: 6| Step: 6
Training loss: 0.4105931089956441
Validation loss: 2.361671341317197

Epoch: 6| Step: 7
Training loss: 0.32471374275327136
Validation loss: 2.3523384756928363

Epoch: 6| Step: 8
Training loss: 0.6584692397250442
Validation loss: 2.3227834109202283

Epoch: 6| Step: 9
Training loss: 0.6431869822477718
Validation loss: 2.334873552684479

Epoch: 6| Step: 10
Training loss: 0.46698674127393597
Validation loss: 2.336268717408052

Epoch: 6| Step: 11
Training loss: 0.5458941519198813
Validation loss: 2.321038784463205

Epoch: 6| Step: 12
Training loss: 0.43880207578694896
Validation loss: 2.3405720013673323

Epoch: 6| Step: 13
Training loss: 0.5034634914591208
Validation loss: 2.374725461937147

Epoch: 272| Step: 0
Training loss: 0.4250818159787626
Validation loss: 2.374169651939923

Epoch: 6| Step: 1
Training loss: 0.6243792550721917
Validation loss: 2.3931355610999345

Epoch: 6| Step: 2
Training loss: 0.3282457992171605
Validation loss: 2.384541879668796

Epoch: 6| Step: 3
Training loss: 0.6146229930516748
Validation loss: 2.382425359553961

Epoch: 6| Step: 4
Training loss: 0.5029605596751853
Validation loss: 2.387666554658106

Epoch: 6| Step: 5
Training loss: 0.5604086250191458
Validation loss: 2.3447257818376626

Epoch: 6| Step: 6
Training loss: 0.4295849070749893
Validation loss: 2.351435061701356

Epoch: 6| Step: 7
Training loss: 0.6784997844878425
Validation loss: 2.341784366555547

Epoch: 6| Step: 8
Training loss: 0.36237363339232564
Validation loss: 2.334203292761355

Epoch: 6| Step: 9
Training loss: 0.3860666962257057
Validation loss: 2.3050187968630413

Epoch: 6| Step: 10
Training loss: 0.6814728013822288
Validation loss: 2.3087967862683496

Epoch: 6| Step: 11
Training loss: 0.6073936136914225
Validation loss: 2.3577068940323977

Epoch: 6| Step: 12
Training loss: 0.2936468034430306
Validation loss: 2.35527455193896

Epoch: 6| Step: 13
Training loss: 0.23656617935272328
Validation loss: 2.387371560629784

Epoch: 273| Step: 0
Training loss: 0.40047269770849137
Validation loss: 2.3958290139293568

Epoch: 6| Step: 1
Training loss: 0.4616402102571988
Validation loss: 2.3926908588449454

Epoch: 6| Step: 2
Training loss: 0.2722044390281062
Validation loss: 2.3666615697391893

Epoch: 6| Step: 3
Training loss: 0.5859109491054739
Validation loss: 2.3624483066295867

Epoch: 6| Step: 4
Training loss: 0.5382832132644174
Validation loss: 2.3068196518434663

Epoch: 6| Step: 5
Training loss: 0.4359041296926294
Validation loss: 2.299755553416578

Epoch: 6| Step: 6
Training loss: 0.5704744187519796
Validation loss: 2.2843235172625795

Epoch: 6| Step: 7
Training loss: 0.3732488993905072
Validation loss: 2.2981395598571046

Epoch: 6| Step: 8
Training loss: 0.4827615106070689
Validation loss: 2.304606238493865

Epoch: 6| Step: 9
Training loss: 0.6541426291777322
Validation loss: 2.33504640815622

Epoch: 6| Step: 10
Training loss: 0.29182487976423377
Validation loss: 2.3283772950233708

Epoch: 6| Step: 11
Training loss: 0.7137560046823588
Validation loss: 2.3588050360835284

Epoch: 6| Step: 12
Training loss: 0.6177313617532941
Validation loss: 2.3854022625899662

Epoch: 6| Step: 13
Training loss: 0.4507347234981876
Validation loss: 2.367329419432845

Epoch: 274| Step: 0
Training loss: 0.5634846546246552
Validation loss: 2.3750439711571354

Epoch: 6| Step: 1
Training loss: 0.2399970952990708
Validation loss: 2.3660085065018857

Epoch: 6| Step: 2
Training loss: 0.30257695935313145
Validation loss: 2.3492137378182036

Epoch: 6| Step: 3
Training loss: 0.4366016189917823
Validation loss: 2.320303332886359

Epoch: 6| Step: 4
Training loss: 0.6138827053418399
Validation loss: 2.324440573832539

Epoch: 6| Step: 5
Training loss: 0.4869062365696017
Validation loss: 2.308729161500485

Epoch: 6| Step: 6
Training loss: 0.43420279746386603
Validation loss: 2.2889482541826145

Epoch: 6| Step: 7
Training loss: 0.6025087667357663
Validation loss: 2.3080756020641786

Epoch: 6| Step: 8
Training loss: 0.37988204759849287
Validation loss: 2.3073021080562124

Epoch: 6| Step: 9
Training loss: 0.4429310481528882
Validation loss: 2.3199986308758223

Epoch: 6| Step: 10
Training loss: 0.36307519791157794
Validation loss: 2.332428990596948

Epoch: 6| Step: 11
Training loss: 0.672940451808892
Validation loss: 2.325406242514357

Epoch: 6| Step: 12
Training loss: 0.6694788232350085
Validation loss: 2.3714215478997294

Epoch: 6| Step: 13
Training loss: 0.43584243941169853
Validation loss: 2.3622851098947275

Epoch: 275| Step: 0
Training loss: 0.7311849907563731
Validation loss: 2.359568641657436

Epoch: 6| Step: 1
Training loss: 0.37996047140622113
Validation loss: 2.3846826770633553

Epoch: 6| Step: 2
Training loss: 0.32845888861238615
Validation loss: 2.348066401041633

Epoch: 6| Step: 3
Training loss: 0.5128820170183525
Validation loss: 2.374356119409443

Epoch: 6| Step: 4
Training loss: 0.41494035332398693
Validation loss: 2.3781115771952104

Epoch: 6| Step: 5
Training loss: 0.46163875771191837
Validation loss: 2.3659912821083173

Epoch: 6| Step: 6
Training loss: 0.29058968011492237
Validation loss: 2.3472839423889136

Epoch: 6| Step: 7
Training loss: 0.41398436330898575
Validation loss: 2.338503989501665

Epoch: 6| Step: 8
Training loss: 0.4037358911606061
Validation loss: 2.3511123888737124

Epoch: 6| Step: 9
Training loss: 0.3613255887329166
Validation loss: 2.3393906236005275

Epoch: 6| Step: 10
Training loss: 0.5955936268712709
Validation loss: 2.353777858139331

Epoch: 6| Step: 11
Training loss: 0.48266802234068495
Validation loss: 2.3462843714142605

Epoch: 6| Step: 12
Training loss: 0.7013975327549798
Validation loss: 2.3327779632678527

Epoch: 6| Step: 13
Training loss: 0.4104936937319366
Validation loss: 2.3580972930231168

Epoch: 276| Step: 0
Training loss: 0.4338067880278355
Validation loss: 2.3781966310804017

Epoch: 6| Step: 1
Training loss: 0.38055008287199604
Validation loss: 2.3773934308070657

Epoch: 6| Step: 2
Training loss: 0.6244324014146466
Validation loss: 2.3964302867287413

Epoch: 6| Step: 3
Training loss: 0.4988496033443936
Validation loss: 2.4351882279073775

Epoch: 6| Step: 4
Training loss: 0.7717478241959309
Validation loss: 2.4196738262857362

Epoch: 6| Step: 5
Training loss: 0.42408618014736826
Validation loss: 2.3910922085148454

Epoch: 6| Step: 6
Training loss: 0.5204746600788651
Validation loss: 2.368439386565554

Epoch: 6| Step: 7
Training loss: 0.5897343262485247
Validation loss: 2.366348221245319

Epoch: 6| Step: 8
Training loss: 0.3379751110845079
Validation loss: 2.3140506511958554

Epoch: 6| Step: 9
Training loss: 0.43755706346848133
Validation loss: 2.3115685590063486

Epoch: 6| Step: 10
Training loss: 0.6044964274071318
Validation loss: 2.3178053131959016

Epoch: 6| Step: 11
Training loss: 0.2609589779175004
Validation loss: 2.3194698017307784

Epoch: 6| Step: 12
Training loss: 0.3117792281182471
Validation loss: 2.311175189994794

Epoch: 6| Step: 13
Training loss: 0.17397302310465615
Validation loss: 2.321616266576317

Epoch: 277| Step: 0
Training loss: 0.6712517398051584
Validation loss: 2.358696491546999

Epoch: 6| Step: 1
Training loss: 0.3388433090723552
Validation loss: 2.3449935884381716

Epoch: 6| Step: 2
Training loss: 0.4356339029855458
Validation loss: 2.381317901827465

Epoch: 6| Step: 3
Training loss: 0.4627773935112357
Validation loss: 2.3654023776183055

Epoch: 6| Step: 4
Training loss: 0.643512105039487
Validation loss: 2.363141157336613

Epoch: 6| Step: 5
Training loss: 0.3625939132452034
Validation loss: 2.350939673812933

Epoch: 6| Step: 6
Training loss: 0.5707691402492574
Validation loss: 2.317073144780029

Epoch: 6| Step: 7
Training loss: 0.32481797696359405
Validation loss: 2.3592427262892217

Epoch: 6| Step: 8
Training loss: 0.5366153734091434
Validation loss: 2.351260350242033

Epoch: 6| Step: 9
Training loss: 0.18652182972799283
Validation loss: 2.3512824755812476

Epoch: 6| Step: 10
Training loss: 0.3776829231826997
Validation loss: 2.3392128335606635

Epoch: 6| Step: 11
Training loss: 0.21704068950890326
Validation loss: 2.351486365624664

Epoch: 6| Step: 12
Training loss: 0.5546877686405874
Validation loss: 2.369022969428173

Epoch: 6| Step: 13
Training loss: 0.674021087881153
Validation loss: 2.3834998032718175

Epoch: 278| Step: 0
Training loss: 0.3170106084504625
Validation loss: 2.382711214777124

Epoch: 6| Step: 1
Training loss: 0.5846872342148324
Validation loss: 2.3596226676910868

Epoch: 6| Step: 2
Training loss: 0.48010587557737305
Validation loss: 2.367192939853039

Epoch: 6| Step: 3
Training loss: 0.4473824660761924
Validation loss: 2.378377349169349

Epoch: 6| Step: 4
Training loss: 0.26922581823350233
Validation loss: 2.334701187326216

Epoch: 6| Step: 5
Training loss: 0.4560274038383318
Validation loss: 2.3485293425801563

Epoch: 6| Step: 6
Training loss: 0.48739861632327974
Validation loss: 2.3503425499029733

Epoch: 6| Step: 7
Training loss: 0.7688393362596398
Validation loss: 2.356153343744363

Epoch: 6| Step: 8
Training loss: 0.27961395511462594
Validation loss: 2.3696698629527044

Epoch: 6| Step: 9
Training loss: 0.5000418407099874
Validation loss: 2.3912122834691254

Epoch: 6| Step: 10
Training loss: 0.47439553109572147
Validation loss: 2.3462481042768824

Epoch: 6| Step: 11
Training loss: 0.5353623153569704
Validation loss: 2.3560537067232734

Epoch: 6| Step: 12
Training loss: 0.2660453639723232
Validation loss: 2.3317417252178707

Epoch: 6| Step: 13
Training loss: 0.36611111106850047
Validation loss: 2.358392506678188

Epoch: 279| Step: 0
Training loss: 0.5389003786301959
Validation loss: 2.375843753124636

Epoch: 6| Step: 1
Training loss: 0.2797109029344914
Validation loss: 2.367602447028537

Epoch: 6| Step: 2
Training loss: 0.5343096642958316
Validation loss: 2.357813069786646

Epoch: 6| Step: 3
Training loss: 0.37092984243842975
Validation loss: 2.360612114236947

Epoch: 6| Step: 4
Training loss: 0.4803769869131727
Validation loss: 2.3446313031018486

Epoch: 6| Step: 5
Training loss: 0.48514609333900166
Validation loss: 2.347754663345668

Epoch: 6| Step: 6
Training loss: 0.3622688214011117
Validation loss: 2.32809269611449

Epoch: 6| Step: 7
Training loss: 0.37213228365427076
Validation loss: 2.359284496248949

Epoch: 6| Step: 8
Training loss: 0.5702832880769175
Validation loss: 2.3277433916350767

Epoch: 6| Step: 9
Training loss: 0.5183398417721472
Validation loss: 2.3548036108050554

Epoch: 6| Step: 10
Training loss: 0.4841611143845436
Validation loss: 2.3680619591252565

Epoch: 6| Step: 11
Training loss: 0.5778063334027138
Validation loss: 2.3438832748968172

Epoch: 6| Step: 12
Training loss: 0.45877440499398153
Validation loss: 2.3878048444518862

Epoch: 6| Step: 13
Training loss: 0.10952027074011308
Validation loss: 2.356388244594713

Epoch: 280| Step: 0
Training loss: 0.2904896174707704
Validation loss: 2.3766220072055146

Epoch: 6| Step: 1
Training loss: 0.38046253755420567
Validation loss: 2.3514840200122635

Epoch: 6| Step: 2
Training loss: 0.6001485332776508
Validation loss: 2.382100289572877

Epoch: 6| Step: 3
Training loss: 0.5123767844227459
Validation loss: 2.358359818407854

Epoch: 6| Step: 4
Training loss: 0.15055018791033706
Validation loss: 2.375934973777693

Epoch: 6| Step: 5
Training loss: 0.4768726402814285
Validation loss: 2.374494910165657

Epoch: 6| Step: 6
Training loss: 0.4614106352404255
Validation loss: 2.349227362359898

Epoch: 6| Step: 7
Training loss: 0.35143731325549243
Validation loss: 2.3485869529322567

Epoch: 6| Step: 8
Training loss: 0.48685051923816014
Validation loss: 2.361896086109003

Epoch: 6| Step: 9
Training loss: 0.3648348780662198
Validation loss: 2.3592305754820635

Epoch: 6| Step: 10
Training loss: 0.33301969266490694
Validation loss: 2.3501820460048646

Epoch: 6| Step: 11
Training loss: 0.5411871903164523
Validation loss: 2.369816744100483

Epoch: 6| Step: 12
Training loss: 0.6446652359846322
Validation loss: 2.3693549885128458

Epoch: 6| Step: 13
Training loss: 0.5270148487858376
Validation loss: 2.378094321341899

Epoch: 281| Step: 0
Training loss: 0.5812523770027369
Validation loss: 2.3942527936298976

Epoch: 6| Step: 1
Training loss: 0.539641304535033
Validation loss: 2.3610767197522136

Epoch: 6| Step: 2
Training loss: 0.5272094555564004
Validation loss: 2.3641756382168406

Epoch: 6| Step: 3
Training loss: 0.44051209755088916
Validation loss: 2.3592170755381026

Epoch: 6| Step: 4
Training loss: 0.33591122857209743
Validation loss: 2.3402900969235834

Epoch: 6| Step: 5
Training loss: 0.13559294805313762
Validation loss: 2.3417153422992785

Epoch: 6| Step: 6
Training loss: 0.6416230219905826
Validation loss: 2.3800933013783467

Epoch: 6| Step: 7
Training loss: 0.4649844237251632
Validation loss: 2.362190384116379

Epoch: 6| Step: 8
Training loss: 0.4371583490148834
Validation loss: 2.377878237962792

Epoch: 6| Step: 9
Training loss: 0.5698607236124464
Validation loss: 2.3574768180169774

Epoch: 6| Step: 10
Training loss: 0.3993833198934408
Validation loss: 2.3637087204924936

Epoch: 6| Step: 11
Training loss: 0.2941862114058947
Validation loss: 2.3517875406992332

Epoch: 6| Step: 12
Training loss: 0.21122534856353256
Validation loss: 2.354249042576542

Epoch: 6| Step: 13
Training loss: 0.15608468250862467
Validation loss: 2.353513008000144

Epoch: 282| Step: 0
Training loss: 0.27640622136281384
Validation loss: 2.3512579553394346

Epoch: 6| Step: 1
Training loss: 0.501432779952962
Validation loss: 2.3411393516195567

Epoch: 6| Step: 2
Training loss: 0.40189599612667454
Validation loss: 2.3609322972622193

Epoch: 6| Step: 3
Training loss: 0.4411943821800555
Validation loss: 2.362351679601932

Epoch: 6| Step: 4
Training loss: 0.3553624256122013
Validation loss: 2.3713792511876757

Epoch: 6| Step: 5
Training loss: 0.5197951428202234
Validation loss: 2.340034280574431

Epoch: 6| Step: 6
Training loss: 0.22610130724505817
Validation loss: 2.3372407727023257

Epoch: 6| Step: 7
Training loss: 0.3893310095244671
Validation loss: 2.3493505602046914

Epoch: 6| Step: 8
Training loss: 0.6709905613890598
Validation loss: 2.356193811138297

Epoch: 6| Step: 9
Training loss: 0.3917822480442698
Validation loss: 2.335249002001108

Epoch: 6| Step: 10
Training loss: 0.4306174705024273
Validation loss: 2.3361862049671585

Epoch: 6| Step: 11
Training loss: 0.49435548295319487
Validation loss: 2.331872936441832

Epoch: 6| Step: 12
Training loss: 0.4303091234394647
Validation loss: 2.346464909868773

Epoch: 6| Step: 13
Training loss: 0.5323062382126306
Validation loss: 2.3439208900198016

Epoch: 283| Step: 0
Training loss: 0.5417755518803565
Validation loss: 2.3386160312064237

Epoch: 6| Step: 1
Training loss: 0.5361258640082226
Validation loss: 2.3467100881251413

Epoch: 6| Step: 2
Training loss: 0.42911043431413437
Validation loss: 2.359964361361434

Epoch: 6| Step: 3
Training loss: 0.4399241318100313
Validation loss: 2.352859925180919

Epoch: 6| Step: 4
Training loss: 0.29842606467662436
Validation loss: 2.35815490064454

Epoch: 6| Step: 5
Training loss: 0.31605261596785345
Validation loss: 2.3691716074068467

Epoch: 6| Step: 6
Training loss: 0.4585112060396333
Validation loss: 2.3582112572233536

Epoch: 6| Step: 7
Training loss: 0.4348243056845825
Validation loss: 2.3651041470400527

Epoch: 6| Step: 8
Training loss: 0.518519973311326
Validation loss: 2.3430267388410813

Epoch: 6| Step: 9
Training loss: 0.4928117305529483
Validation loss: 2.354762576800927

Epoch: 6| Step: 10
Training loss: 0.4077335193491296
Validation loss: 2.3302319255031745

Epoch: 6| Step: 11
Training loss: 0.26900117691484543
Validation loss: 2.3479140210135174

Epoch: 6| Step: 12
Training loss: 0.4588719818807808
Validation loss: 2.348551176542671

Epoch: 6| Step: 13
Training loss: 0.5577986600638867
Validation loss: 2.3484776877820743

Epoch: 284| Step: 0
Training loss: 0.25557682947543053
Validation loss: 2.3435812984444766

Epoch: 6| Step: 1
Training loss: 0.5041462230741032
Validation loss: 2.3276290458894633

Epoch: 6| Step: 2
Training loss: 0.13579257880514461
Validation loss: 2.357387307678226

Epoch: 6| Step: 3
Training loss: 0.33496743243179256
Validation loss: 2.337106846974563

Epoch: 6| Step: 4
Training loss: 0.6137602569437782
Validation loss: 2.3558387368494187

Epoch: 6| Step: 5
Training loss: 0.4540572934465874
Validation loss: 2.3236138121592718

Epoch: 6| Step: 6
Training loss: 0.23506225912725334
Validation loss: 2.352230382862048

Epoch: 6| Step: 7
Training loss: 0.1820119630640238
Validation loss: 2.324861430223192

Epoch: 6| Step: 8
Training loss: 0.4140143096519405
Validation loss: 2.3443754497839335

Epoch: 6| Step: 9
Training loss: 0.2557377708266933
Validation loss: 2.372717770624146

Epoch: 6| Step: 10
Training loss: 0.5655177019891796
Validation loss: 2.373691421778999

Epoch: 6| Step: 11
Training loss: 0.5709838573592406
Validation loss: 2.383285362035667

Epoch: 6| Step: 12
Training loss: 0.46891532207841063
Validation loss: 2.368235225676009

Epoch: 6| Step: 13
Training loss: 0.7398986860461323
Validation loss: 2.345523380444437

Epoch: 285| Step: 0
Training loss: 0.4086064440649942
Validation loss: 2.3325516490829656

Epoch: 6| Step: 1
Training loss: 0.32410587506081945
Validation loss: 2.3330148308854604

Epoch: 6| Step: 2
Training loss: 0.5901680364383693
Validation loss: 2.345456865958825

Epoch: 6| Step: 3
Training loss: 0.5738756361392614
Validation loss: 2.3430264357593917

Epoch: 6| Step: 4
Training loss: 0.5187960420421514
Validation loss: 2.3421924603188793

Epoch: 6| Step: 5
Training loss: 0.34488188186642654
Validation loss: 2.3557806936117065

Epoch: 6| Step: 6
Training loss: 0.3745318510570326
Validation loss: 2.3089824820003866

Epoch: 6| Step: 7
Training loss: 0.4907698727187403
Validation loss: 2.361963714448848

Epoch: 6| Step: 8
Training loss: 0.4634450015170238
Validation loss: 2.355740116009209

Epoch: 6| Step: 9
Training loss: 0.4645156664244103
Validation loss: 2.411022591201303

Epoch: 6| Step: 10
Training loss: 0.2912944379762995
Validation loss: 2.3837633290468196

Epoch: 6| Step: 11
Training loss: 0.4507792362055762
Validation loss: 2.381425343699997

Epoch: 6| Step: 12
Training loss: 0.30158390354632436
Validation loss: 2.3733824487544983

Epoch: 6| Step: 13
Training loss: 0.30819087953016144
Validation loss: 2.3828785457297053

Epoch: 286| Step: 0
Training loss: 0.3439565601491865
Validation loss: 2.3655725390161706

Epoch: 6| Step: 1
Training loss: 0.47809675918650407
Validation loss: 2.3576001969843103

Epoch: 6| Step: 2
Training loss: 0.41635948619954855
Validation loss: 2.3391386809772765

Epoch: 6| Step: 3
Training loss: 0.5104764462192383
Validation loss: 2.348734392298317

Epoch: 6| Step: 4
Training loss: 0.3438844417882941
Validation loss: 2.349788101391697

Epoch: 6| Step: 5
Training loss: 0.38798640779032845
Validation loss: 2.3542313254237115

Epoch: 6| Step: 6
Training loss: 0.32251154446454217
Validation loss: 2.3746893527930437

Epoch: 6| Step: 7
Training loss: 0.5341036392000796
Validation loss: 2.3872956597657473

Epoch: 6| Step: 8
Training loss: 0.5825425276969453
Validation loss: 2.3420820616676976

Epoch: 6| Step: 9
Training loss: 0.40186853955357577
Validation loss: 2.3431427784986534

Epoch: 6| Step: 10
Training loss: 0.38894471220096777
Validation loss: 2.341433347224643

Epoch: 6| Step: 11
Training loss: 0.35722510335967333
Validation loss: 2.368882612987742

Epoch: 6| Step: 12
Training loss: 0.36653047989282944
Validation loss: 2.3297666718996193

Epoch: 6| Step: 13
Training loss: 0.49113660974292994
Validation loss: 2.3611871512781875

Epoch: 287| Step: 0
Training loss: 0.4098245641978436
Validation loss: 2.350118795493507

Epoch: 6| Step: 1
Training loss: 0.45837699797740755
Validation loss: 2.346010291076356

Epoch: 6| Step: 2
Training loss: 0.3443533414271187
Validation loss: 2.353247351306966

Epoch: 6| Step: 3
Training loss: 0.26256958175512546
Validation loss: 2.3703737532297486

Epoch: 6| Step: 4
Training loss: 0.34009409047847305
Validation loss: 2.3906624533904135

Epoch: 6| Step: 5
Training loss: 0.3947605939461858
Validation loss: 2.3558045048673546

Epoch: 6| Step: 6
Training loss: 0.5439161912666551
Validation loss: 2.3560940927257215

Epoch: 6| Step: 7
Training loss: 0.3455769691239256
Validation loss: 2.3242939080067666

Epoch: 6| Step: 8
Training loss: 0.25544011366748165
Validation loss: 2.3289315169509286

Epoch: 6| Step: 9
Training loss: 0.6798526081059586
Validation loss: 2.316305738857277

Epoch: 6| Step: 10
Training loss: 0.17726170915067163
Validation loss: 2.319200365992994

Epoch: 6| Step: 11
Training loss: 0.3536247169396409
Validation loss: 2.288678008269616

Epoch: 6| Step: 12
Training loss: 0.48038748697474076
Validation loss: 2.328642445258267

Epoch: 6| Step: 13
Training loss: 0.7915657673499876
Validation loss: 2.319876836996552

Epoch: 288| Step: 0
Training loss: 0.40566609675522275
Validation loss: 2.3194652297764757

Epoch: 6| Step: 1
Training loss: 0.44357502939804316
Validation loss: 2.3157115614594628

Epoch: 6| Step: 2
Training loss: 0.29331906037845085
Validation loss: 2.3546169629697546

Epoch: 6| Step: 3
Training loss: 0.2549357158376814
Validation loss: 2.354806097905853

Epoch: 6| Step: 4
Training loss: 0.5833380449195592
Validation loss: 2.384077157549044

Epoch: 6| Step: 5
Training loss: 0.23053264540396973
Validation loss: 2.3912582266584206

Epoch: 6| Step: 6
Training loss: 0.3714969452376836
Validation loss: 2.39117974258994

Epoch: 6| Step: 7
Training loss: 0.6023591451495783
Validation loss: 2.3954272763853734

Epoch: 6| Step: 8
Training loss: 0.552084874804762
Validation loss: 2.40207177787036

Epoch: 6| Step: 9
Training loss: 0.46626524399185454
Validation loss: 2.3450734231118457

Epoch: 6| Step: 10
Training loss: 0.19117875105913115
Validation loss: 2.341448139581013

Epoch: 6| Step: 11
Training loss: 0.39468739507315864
Validation loss: 2.3591767458495148

Epoch: 6| Step: 12
Training loss: 0.537024779160078
Validation loss: 2.3345035529716998

Epoch: 6| Step: 13
Training loss: 0.1464658216806746
Validation loss: 2.3220852099991443

Epoch: 289| Step: 0
Training loss: 0.2630679525842123
Validation loss: 2.362729612869425

Epoch: 6| Step: 1
Training loss: 0.4074121505147327
Validation loss: 2.3435986344876296

Epoch: 6| Step: 2
Training loss: 0.32709927545357614
Validation loss: 2.341619140658869

Epoch: 6| Step: 3
Training loss: 0.3874763235426809
Validation loss: 2.381400992801149

Epoch: 6| Step: 4
Training loss: 0.27659484329326495
Validation loss: 2.356263273511888

Epoch: 6| Step: 5
Training loss: 0.3635462542939401
Validation loss: 2.40454281384709

Epoch: 6| Step: 6
Training loss: 0.3473842499768753
Validation loss: 2.4101284632661013

Epoch: 6| Step: 7
Training loss: 0.3385914276916545
Validation loss: 2.4161736456088385

Epoch: 6| Step: 8
Training loss: 0.32511308564102515
Validation loss: 2.379084198699135

Epoch: 6| Step: 9
Training loss: 0.7022544133586457
Validation loss: 2.3556443625134778

Epoch: 6| Step: 10
Training loss: 0.48838002540965114
Validation loss: 2.3457517534928796

Epoch: 6| Step: 11
Training loss: 0.44283618389856544
Validation loss: 2.333410777251217

Epoch: 6| Step: 12
Training loss: 0.5478221049013499
Validation loss: 2.3188323490764224

Epoch: 6| Step: 13
Training loss: 0.5663147951152635
Validation loss: 2.3691742704119405

Epoch: 290| Step: 0
Training loss: 0.4590156382200937
Validation loss: 2.3508053921738807

Epoch: 6| Step: 1
Training loss: 0.38927868578004204
Validation loss: 2.345072064260476

Epoch: 6| Step: 2
Training loss: 0.5124788535802954
Validation loss: 2.3264524336574506

Epoch: 6| Step: 3
Training loss: 0.41617713622700264
Validation loss: 2.3217528039582938

Epoch: 6| Step: 4
Training loss: 0.3725287149229626
Validation loss: 2.3074033591584255

Epoch: 6| Step: 5
Training loss: 0.32668209715003194
Validation loss: 2.3159670682251816

Epoch: 6| Step: 6
Training loss: 0.4816762436120366
Validation loss: 2.3456521817610048

Epoch: 6| Step: 7
Training loss: 0.3452904819356035
Validation loss: 2.324422767338769

Epoch: 6| Step: 8
Training loss: 0.23977779015747375
Validation loss: 2.327141305580678

Epoch: 6| Step: 9
Training loss: 0.6079401583334514
Validation loss: 2.3667703322752343

Epoch: 6| Step: 10
Training loss: 0.3692330945974112
Validation loss: 2.3362223539677216

Epoch: 6| Step: 11
Training loss: 0.23902886783661126
Validation loss: 2.3593646383869533

Epoch: 6| Step: 12
Training loss: 0.646246321721188
Validation loss: 2.340118972161337

Epoch: 6| Step: 13
Training loss: 0.41105555082493506
Validation loss: 2.3518188465481287

Epoch: 291| Step: 0
Training loss: 0.2974744441772508
Validation loss: 2.3571207661812776

Epoch: 6| Step: 1
Training loss: 0.3005282341075016
Validation loss: 2.3265070502019953

Epoch: 6| Step: 2
Training loss: 0.3732739701006279
Validation loss: 2.3366989983577886

Epoch: 6| Step: 3
Training loss: 0.3940335902500716
Validation loss: 2.3864365868368895

Epoch: 6| Step: 4
Training loss: 0.5544399730019604
Validation loss: 2.3820408828360793

Epoch: 6| Step: 5
Training loss: 0.3917744889714677
Validation loss: 2.368174340145778

Epoch: 6| Step: 6
Training loss: 0.5519494188188336
Validation loss: 2.360176151965639

Epoch: 6| Step: 7
Training loss: 0.32653651156892666
Validation loss: 2.406234358145528

Epoch: 6| Step: 8
Training loss: 0.2944205235352716
Validation loss: 2.3730123510887355

Epoch: 6| Step: 9
Training loss: 0.4378935202129387
Validation loss: 2.4020642483230765

Epoch: 6| Step: 10
Training loss: 0.4802427923564189
Validation loss: 2.3402212381027145

Epoch: 6| Step: 11
Training loss: 0.435245888892735
Validation loss: 2.366771759365761

Epoch: 6| Step: 12
Training loss: 0.5738902287540918
Validation loss: 2.3513488072834803

Epoch: 6| Step: 13
Training loss: 0.17419744754784283
Validation loss: 2.3495508415347874

Epoch: 292| Step: 0
Training loss: 0.2897011943571959
Validation loss: 2.352697846569232

Epoch: 6| Step: 1
Training loss: 0.3816324848099533
Validation loss: 2.3443697574160445

Epoch: 6| Step: 2
Training loss: 0.42661368513596837
Validation loss: 2.3629273595336593

Epoch: 6| Step: 3
Training loss: 0.13152753290519267
Validation loss: 2.3589177043321072

Epoch: 6| Step: 4
Training loss: 0.44905284637608395
Validation loss: 2.3910482279834224

Epoch: 6| Step: 5
Training loss: 0.43933120731776143
Validation loss: 2.376078257800225

Epoch: 6| Step: 6
Training loss: 0.5944354968967245
Validation loss: 2.377228692347715

Epoch: 6| Step: 7
Training loss: 0.5129446240926588
Validation loss: 2.36171256899345

Epoch: 6| Step: 8
Training loss: 0.4122837655863845
Validation loss: 2.353190964091513

Epoch: 6| Step: 9
Training loss: 0.30600641353125435
Validation loss: 2.3588453536513763

Epoch: 6| Step: 10
Training loss: 0.23620625182939528
Validation loss: 2.329044390372035

Epoch: 6| Step: 11
Training loss: 0.5443195582821482
Validation loss: 2.361161450262226

Epoch: 6| Step: 12
Training loss: 0.4950805289336695
Validation loss: 2.340090575087128

Epoch: 6| Step: 13
Training loss: 0.16018652048380785
Validation loss: 2.352495982215811

Epoch: 293| Step: 0
Training loss: 0.39378304872631026
Validation loss: 2.3440379424605493

Epoch: 6| Step: 1
Training loss: 0.45969692679567303
Validation loss: 2.3601464125077944

Epoch: 6| Step: 2
Training loss: 0.3830510777883401
Validation loss: 2.3633745425075374

Epoch: 6| Step: 3
Training loss: 0.5407183550015455
Validation loss: 2.3419907002764995

Epoch: 6| Step: 4
Training loss: 0.31319405253081084
Validation loss: 2.3400256355191895

Epoch: 6| Step: 5
Training loss: 0.40494831326415176
Validation loss: 2.3538674540012177

Epoch: 6| Step: 6
Training loss: 0.5618312091757062
Validation loss: 2.3500770682537873

Epoch: 6| Step: 7
Training loss: 0.28524760520424597
Validation loss: 2.3440835858926294

Epoch: 6| Step: 8
Training loss: 0.3313599363570415
Validation loss: 2.325753447082407

Epoch: 6| Step: 9
Training loss: 0.41076502353314087
Validation loss: 2.338310690902863

Epoch: 6| Step: 10
Training loss: 0.35082030896606375
Validation loss: 2.3213406022478655

Epoch: 6| Step: 11
Training loss: 0.4183961341017392
Validation loss: 2.3280984833396445

Epoch: 6| Step: 12
Training loss: 0.3316926463813102
Validation loss: 2.3469992130390653

Epoch: 6| Step: 13
Training loss: 0.18722324012627578
Validation loss: 2.32586691672838

Epoch: 294| Step: 0
Training loss: 0.24548983269088248
Validation loss: 2.3502920955408797

Epoch: 6| Step: 1
Training loss: 0.4325360982085883
Validation loss: 2.3679810395392837

Epoch: 6| Step: 2
Training loss: 0.4118213822423986
Validation loss: 2.383555476704904

Epoch: 6| Step: 3
Training loss: 0.43357556966521926
Validation loss: 2.3764859178170994

Epoch: 6| Step: 4
Training loss: 0.4820048889173387
Validation loss: 2.346872681304353

Epoch: 6| Step: 5
Training loss: 0.24181349393709842
Validation loss: 2.407231412399829

Epoch: 6| Step: 6
Training loss: 0.38316410810991625
Validation loss: 2.3599575111133646

Epoch: 6| Step: 7
Training loss: 0.4707142049031464
Validation loss: 2.381506790372501

Epoch: 6| Step: 8
Training loss: 0.27902365705729004
Validation loss: 2.354350056657529

Epoch: 6| Step: 9
Training loss: 0.3041704265261943
Validation loss: 2.3645091494896917

Epoch: 6| Step: 10
Training loss: 0.5495188971403636
Validation loss: 2.3640100101111665

Epoch: 6| Step: 11
Training loss: 0.24399172247512277
Validation loss: 2.345845284141291

Epoch: 6| Step: 12
Training loss: 0.55986819236008
Validation loss: 2.3618811103007515

Epoch: 6| Step: 13
Training loss: 0.13854411109283207
Validation loss: 2.349648128095795

Epoch: 295| Step: 0
Training loss: 0.15575362277142077
Validation loss: 2.364535957683277

Epoch: 6| Step: 1
Training loss: 0.263663736853576
Validation loss: 2.33426402980614

Epoch: 6| Step: 2
Training loss: 0.32577256069899213
Validation loss: 2.358067026701321

Epoch: 6| Step: 3
Training loss: 0.2524289509930542
Validation loss: 2.351031120892696

Epoch: 6| Step: 4
Training loss: 0.6196360726689844
Validation loss: 2.352808138820102

Epoch: 6| Step: 5
Training loss: 0.1238932978064754
Validation loss: 2.344736502255019

Epoch: 6| Step: 6
Training loss: 0.47699102302717156
Validation loss: 2.3672575451390867

Epoch: 6| Step: 7
Training loss: 0.4382898829624786
Validation loss: 2.3684464379649492

Epoch: 6| Step: 8
Training loss: 0.4737309619631271
Validation loss: 2.373841578526747

Epoch: 6| Step: 9
Training loss: 0.2827949739789896
Validation loss: 2.3808094020658697

Epoch: 6| Step: 10
Training loss: 0.5512608273193244
Validation loss: 2.385648278137356

Epoch: 6| Step: 11
Training loss: 0.43816929099483365
Validation loss: 2.352220930344102

Epoch: 6| Step: 12
Training loss: 0.4300888961011427
Validation loss: 2.3399281088449713

Epoch: 6| Step: 13
Training loss: 0.21260792221634944
Validation loss: 2.35098407643985

Epoch: 296| Step: 0
Training loss: 0.36637225857596983
Validation loss: 2.336760380352706

Epoch: 6| Step: 1
Training loss: 0.38114435342461594
Validation loss: 2.307426554433896

Epoch: 6| Step: 2
Training loss: 0.48193028534871574
Validation loss: 2.321896655812663

Epoch: 6| Step: 3
Training loss: 0.5295270018352297
Validation loss: 2.3339676584414097

Epoch: 6| Step: 4
Training loss: 0.3889990536536054
Validation loss: 2.324482833517039

Epoch: 6| Step: 5
Training loss: 0.3372597289481276
Validation loss: 2.3098849160713453

Epoch: 6| Step: 6
Training loss: 0.34901009242199243
Validation loss: 2.3174789881198126

Epoch: 6| Step: 7
Training loss: 0.5109345053955421
Validation loss: 2.337534082671049

Epoch: 6| Step: 8
Training loss: 0.2211774438489099
Validation loss: 2.3505924333367543

Epoch: 6| Step: 9
Training loss: 0.2768750461337221
Validation loss: 2.351718425231584

Epoch: 6| Step: 10
Training loss: 0.32131556717559373
Validation loss: 2.372061731243636

Epoch: 6| Step: 11
Training loss: 0.370208487409575
Validation loss: 2.3502079898042085

Epoch: 6| Step: 12
Training loss: 0.416525872602717
Validation loss: 2.353118420990315

Epoch: 6| Step: 13
Training loss: 0.48467453032307667
Validation loss: 2.3821632042595464

Epoch: 297| Step: 0
Training loss: 0.5808201420662076
Validation loss: 2.356639659392255

Epoch: 6| Step: 1
Training loss: 0.3977791264717288
Validation loss: 2.3531244893036645

Epoch: 6| Step: 2
Training loss: 0.41645123952625485
Validation loss: 2.327271351163922

Epoch: 6| Step: 3
Training loss: 0.370793391694849
Validation loss: 2.3305081749730117

Epoch: 6| Step: 4
Training loss: 0.292542236123461
Validation loss: 2.3141794145583727

Epoch: 6| Step: 5
Training loss: 0.45631063332755184
Validation loss: 2.310700648585745

Epoch: 6| Step: 6
Training loss: 0.23155183393029732
Validation loss: 2.3168200289458265

Epoch: 6| Step: 7
Training loss: 0.27675710340151943
Validation loss: 2.367979608305719

Epoch: 6| Step: 8
Training loss: 0.42311695747677036
Validation loss: 2.370452721226426

Epoch: 6| Step: 9
Training loss: 0.14095128142142116
Validation loss: 2.3700642562964225

Epoch: 6| Step: 10
Training loss: 0.3961681739966754
Validation loss: 2.4047200144220353

Epoch: 6| Step: 11
Training loss: 0.23318768806419263
Validation loss: 2.401766138262381

Epoch: 6| Step: 12
Training loss: 0.6135614811839373
Validation loss: 2.325506025192612

Epoch: 6| Step: 13
Training loss: 0.516404343224957
Validation loss: 2.333761490888905

Epoch: 298| Step: 0
Training loss: 0.3369868987590266
Validation loss: 2.32342218495415

Epoch: 6| Step: 1
Training loss: 0.41779823033481667
Validation loss: 2.3389212902716237

Epoch: 6| Step: 2
Training loss: 0.2137147804574339
Validation loss: 2.336870585012983

Epoch: 6| Step: 3
Training loss: 0.5429114990788663
Validation loss: 2.34330886681829

Epoch: 6| Step: 4
Training loss: 0.36858443083065356
Validation loss: 2.3742898700832895

Epoch: 6| Step: 5
Training loss: 0.37981608375966475
Validation loss: 2.3695004534545223

Epoch: 6| Step: 6
Training loss: 0.44568202096654974
Validation loss: 2.3867630380209364

Epoch: 6| Step: 7
Training loss: 0.554842484004629
Validation loss: 2.3901330799801306

Epoch: 6| Step: 8
Training loss: 0.24074818938060694
Validation loss: 2.3729659374212946

Epoch: 6| Step: 9
Training loss: 0.42410086720348045
Validation loss: 2.412609663136106

Epoch: 6| Step: 10
Training loss: 0.4247395081776315
Validation loss: 2.403198913814113

Epoch: 6| Step: 11
Training loss: 0.19755119954789915
Validation loss: 2.3866108782916253

Epoch: 6| Step: 12
Training loss: 0.48391119994162135
Validation loss: 2.3738770075160915

Epoch: 6| Step: 13
Training loss: 0.19845265458278527
Validation loss: 2.340415343934999

Epoch: 299| Step: 0
Training loss: 0.38128391959215097
Validation loss: 2.357460712268221

Epoch: 6| Step: 1
Training loss: 0.1968773239997662
Validation loss: 2.32552457081407

Epoch: 6| Step: 2
Training loss: 0.3635083380927397
Validation loss: 2.3579352205185873

Epoch: 6| Step: 3
Training loss: 0.1639098240396323
Validation loss: 2.356500334856922

Epoch: 6| Step: 4
Training loss: 0.4825434357852499
Validation loss: 2.3565507705262347

Epoch: 6| Step: 5
Training loss: 0.2991456482834869
Validation loss: 2.359626915075097

Epoch: 6| Step: 6
Training loss: 0.186975490556954
Validation loss: 2.3767442467130544

Epoch: 6| Step: 7
Training loss: 0.5717685871447323
Validation loss: 2.3461523540240026

Epoch: 6| Step: 8
Training loss: 0.46748607624962923
Validation loss: 2.3547080903203295

Epoch: 6| Step: 9
Training loss: 0.4201965320949262
Validation loss: 2.3540847514329326

Epoch: 6| Step: 10
Training loss: 0.3956636098429203
Validation loss: 2.347321966091207

Epoch: 6| Step: 11
Training loss: 0.1598563351808682
Validation loss: 2.3324156998897023

Epoch: 6| Step: 12
Training loss: 0.6542478400687808
Validation loss: 2.336930510057659

Epoch: 6| Step: 13
Training loss: 0.12305138973248998
Validation loss: 2.3387300239299567

Epoch: 300| Step: 0
Training loss: 0.4085901059631884
Validation loss: 2.3336733850067675

Epoch: 6| Step: 1
Training loss: 0.3584282054544131
Validation loss: 2.3138391651963075

Epoch: 6| Step: 2
Training loss: 0.3561754433096909
Validation loss: 2.3327999369635464

Epoch: 6| Step: 3
Training loss: 0.3150829145132283
Validation loss: 2.330101006538581

Epoch: 6| Step: 4
Training loss: 0.3506585261182053
Validation loss: 2.338052573834825

Epoch: 6| Step: 5
Training loss: 0.5294676783119194
Validation loss: 2.3355416038463623

Epoch: 6| Step: 6
Training loss: 0.40306864869498177
Validation loss: 2.3412836203031904

Epoch: 6| Step: 7
Training loss: 0.3406856237936135
Validation loss: 2.3886625141004685

Epoch: 6| Step: 8
Training loss: 0.19258670362202773
Validation loss: 2.37940811603817

Epoch: 6| Step: 9
Training loss: 0.3542677534052328
Validation loss: 2.3646759389835124

Epoch: 6| Step: 10
Training loss: 0.542053411651465
Validation loss: 2.3712108438739214

Epoch: 6| Step: 11
Training loss: 0.301392491502711
Validation loss: 2.3806408251161177

Epoch: 6| Step: 12
Training loss: 0.46295191363112087
Validation loss: 2.368700154227815

Epoch: 6| Step: 13
Training loss: 0.2661620489108868
Validation loss: 2.352984006560968

Epoch: 301| Step: 0
Training loss: 0.5010169832754587
Validation loss: 2.3591305533363003

Epoch: 6| Step: 1
Training loss: 0.14584282577365662
Validation loss: 2.313037103207066

Epoch: 6| Step: 2
Training loss: 0.17304158945385778
Validation loss: 2.3531948958469315

Epoch: 6| Step: 3
Training loss: 0.2995126028330827
Validation loss: 2.3463659616829684

Epoch: 6| Step: 4
Training loss: 0.2103636848831604
Validation loss: 2.332639230234625

Epoch: 6| Step: 5
Training loss: 0.5995865609367331
Validation loss: 2.342138096802944

Epoch: 6| Step: 6
Training loss: 0.47802126513348236
Validation loss: 2.2929697226983325

Epoch: 6| Step: 7
Training loss: 0.28979890687254567
Validation loss: 2.3517657607653772

Epoch: 6| Step: 8
Training loss: 0.3618364418649767
Validation loss: 2.346782457900746

Epoch: 6| Step: 9
Training loss: 0.45748793778907837
Validation loss: 2.364668471954959

Epoch: 6| Step: 10
Training loss: 0.42071500883611596
Validation loss: 2.3659266557895897

Epoch: 6| Step: 11
Training loss: 0.12768598450682353
Validation loss: 2.3778649398412424

Epoch: 6| Step: 12
Training loss: 0.46209958244260285
Validation loss: 2.3671752589312107

Epoch: 6| Step: 13
Training loss: 0.25220824048811397
Validation loss: 2.350854827339351

Epoch: 302| Step: 0
Training loss: 0.29418998496612975
Validation loss: 2.3980497753834147

Epoch: 6| Step: 1
Training loss: 0.3998341298408785
Validation loss: 2.3484561620670834

Epoch: 6| Step: 2
Training loss: 0.47342962252166143
Validation loss: 2.338997876659837

Epoch: 6| Step: 3
Training loss: 0.5054513766149351
Validation loss: 2.3153747343642466

Epoch: 6| Step: 4
Training loss: 0.31980732880467627
Validation loss: 2.352947101798188

Epoch: 6| Step: 5
Training loss: 0.6123043467932914
Validation loss: 2.318272044498431

Epoch: 6| Step: 6
Training loss: 0.3737139903299023
Validation loss: 2.350522602150863

Epoch: 6| Step: 7
Training loss: 0.32724366581311254
Validation loss: 2.345616510889553

Epoch: 6| Step: 8
Training loss: 0.35761235065616426
Validation loss: 2.3437016810970492

Epoch: 6| Step: 9
Training loss: 0.321198795705654
Validation loss: 2.344989758815556

Epoch: 6| Step: 10
Training loss: 0.2559007072551877
Validation loss: 2.360274454397319

Epoch: 6| Step: 11
Training loss: 0.2779274158291119
Validation loss: 2.3519130308304153

Epoch: 6| Step: 12
Training loss: 0.24128170751323982
Validation loss: 2.3523807875508638

Epoch: 6| Step: 13
Training loss: 0.13816613670045397
Validation loss: 2.339416816659016

Epoch: 303| Step: 0
Training loss: 0.395771117925939
Validation loss: 2.3476804529633397

Epoch: 6| Step: 1
Training loss: 0.1053344613390342
Validation loss: 2.3489202016944972

Epoch: 6| Step: 2
Training loss: 0.2291754545708725
Validation loss: 2.3368653087928815

Epoch: 6| Step: 3
Training loss: 0.4988168785362852
Validation loss: 2.299494265792671

Epoch: 6| Step: 4
Training loss: 0.2887804743344908
Validation loss: 2.3249418580645775

Epoch: 6| Step: 5
Training loss: 0.578952248994205
Validation loss: 2.3189999568741295

Epoch: 6| Step: 6
Training loss: 0.1252529892203071
Validation loss: 2.299706011392792

Epoch: 6| Step: 7
Training loss: 0.6045509026380348
Validation loss: 2.326489541620051

Epoch: 6| Step: 8
Training loss: 0.37636039264525695
Validation loss: 2.288184012257605

Epoch: 6| Step: 9
Training loss: 0.457062483804359
Validation loss: 2.29865826343992

Epoch: 6| Step: 10
Training loss: 0.2920161719024434
Validation loss: 2.3576347475925026

Epoch: 6| Step: 11
Training loss: 0.2917648119079834
Validation loss: 2.3566065845534507

Epoch: 6| Step: 12
Training loss: 0.5422798561786568
Validation loss: 2.374907544143952

Epoch: 6| Step: 13
Training loss: 0.17207238394175622
Validation loss: 2.3832929347760903

Epoch: 304| Step: 0
Training loss: 0.49485946659223273
Validation loss: 2.3895399363172083

Epoch: 6| Step: 1
Training loss: 0.3859996467623305
Validation loss: 2.340221167992675

Epoch: 6| Step: 2
Training loss: 0.29468760754369916
Validation loss: 2.3046527796668066

Epoch: 6| Step: 3
Training loss: 0.3249722996241001
Validation loss: 2.316739603536505

Epoch: 6| Step: 4
Training loss: 0.3832529220345242
Validation loss: 2.325716736328878

Epoch: 6| Step: 5
Training loss: 0.28999567188946546
Validation loss: 2.3363676861357114

Epoch: 6| Step: 6
Training loss: 0.5307316214442611
Validation loss: 2.320850303220979

Epoch: 6| Step: 7
Training loss: 0.44893478042647644
Validation loss: 2.340109035799038

Epoch: 6| Step: 8
Training loss: 0.39084426448083903
Validation loss: 2.3538855452794145

Epoch: 6| Step: 9
Training loss: 0.49006342852007906
Validation loss: 2.3924752483471354

Epoch: 6| Step: 10
Training loss: 0.2951730201969161
Validation loss: 2.3841758470999785

Epoch: 6| Step: 11
Training loss: 0.20213922304538756
Validation loss: 2.3871041395217314

Epoch: 6| Step: 12
Training loss: 0.3076914137646179
Validation loss: 2.3902816021811457

Epoch: 6| Step: 13
Training loss: 0.4057581748761739
Validation loss: 2.3620365812079984

Epoch: 305| Step: 0
Training loss: 0.26643861255238976
Validation loss: 2.3663053539062857

Epoch: 6| Step: 1
Training loss: 0.46788362865659944
Validation loss: 2.3259019067612305

Epoch: 6| Step: 2
Training loss: 0.408117403949892
Validation loss: 2.3384376892117045

Epoch: 6| Step: 3
Training loss: 0.3602281891641865
Validation loss: 2.3187425794328744

Epoch: 6| Step: 4
Training loss: 0.2988900762430602
Validation loss: 2.3231250462176467

Epoch: 6| Step: 5
Training loss: 0.47868887431406526
Validation loss: 2.299466846479374

Epoch: 6| Step: 6
Training loss: 0.27763843998759535
Validation loss: 2.2969080080137445

Epoch: 6| Step: 7
Training loss: 0.532898085535941
Validation loss: 2.3224263364637596

Epoch: 6| Step: 8
Training loss: 0.3371701248790332
Validation loss: 2.3469905707003966

Epoch: 6| Step: 9
Training loss: 0.5429040335090285
Validation loss: 2.359074857706965

Epoch: 6| Step: 10
Training loss: 0.31925702067745715
Validation loss: 2.3412378204501763

Epoch: 6| Step: 11
Training loss: 0.24221098693664064
Validation loss: 2.3575502056835584

Epoch: 6| Step: 12
Training loss: 0.38643107648011843
Validation loss: 2.3644618966792663

Epoch: 6| Step: 13
Training loss: 0.14541548801789733
Validation loss: 2.3527744397002026

Epoch: 306| Step: 0
Training loss: 0.18866196837391086
Validation loss: 2.348857656382779

Epoch: 6| Step: 1
Training loss: 0.16994335871842892
Validation loss: 2.338753416308688

Epoch: 6| Step: 2
Training loss: 0.29968199564758613
Validation loss: 2.3189591195646515

Epoch: 6| Step: 3
Training loss: 0.28526886584408256
Validation loss: 2.314285616604222

Epoch: 6| Step: 4
Training loss: 0.638703091759677
Validation loss: 2.3320514432589667

Epoch: 6| Step: 5
Training loss: 0.2755041497172433
Validation loss: 2.3378825192040202

Epoch: 6| Step: 6
Training loss: 0.4264864549867383
Validation loss: 2.305569091950203

Epoch: 6| Step: 7
Training loss: 0.4467240265264103
Validation loss: 2.3048934975163338

Epoch: 6| Step: 8
Training loss: 0.3449843094201662
Validation loss: 2.2918111858124104

Epoch: 6| Step: 9
Training loss: 0.404148111294325
Validation loss: 2.3004577889586724

Epoch: 6| Step: 10
Training loss: 0.4666135419966029
Validation loss: 2.3023511286967553

Epoch: 6| Step: 11
Training loss: 0.343252363660805
Validation loss: 2.293541140716735

Epoch: 6| Step: 12
Training loss: 0.3239133154489056
Validation loss: 2.322272020664393

Epoch: 6| Step: 13
Training loss: 0.36006852279311335
Validation loss: 2.313350123240829

Epoch: 307| Step: 0
Training loss: 0.3455722582690309
Validation loss: 2.3227066488820953

Epoch: 6| Step: 1
Training loss: 0.45921047404419396
Validation loss: 2.3018943439179034

Epoch: 6| Step: 2
Training loss: 0.4145983880950188
Validation loss: 2.2952207616348375

Epoch: 6| Step: 3
Training loss: 0.4312248644206973
Validation loss: 2.3184622270002353

Epoch: 6| Step: 4
Training loss: 0.3721837348971752
Validation loss: 2.3174077011273706

Epoch: 6| Step: 5
Training loss: 0.2503362569834005
Validation loss: 2.303628026770076

Epoch: 6| Step: 6
Training loss: 0.24344210068220215
Validation loss: 2.304192344571255

Epoch: 6| Step: 7
Training loss: 0.13994146162033316
Validation loss: 2.310729699734407

Epoch: 6| Step: 8
Training loss: 0.3361714679450484
Validation loss: 2.3108980488593724

Epoch: 6| Step: 9
Training loss: 0.5815374084258083
Validation loss: 2.321517837876614

Epoch: 6| Step: 10
Training loss: 0.14059157769075992
Validation loss: 2.311655202317081

Epoch: 6| Step: 11
Training loss: 0.32191223651343576
Validation loss: 2.3315241238159388

Epoch: 6| Step: 12
Training loss: 0.3548005499467813
Validation loss: 2.355021796685496

Epoch: 6| Step: 13
Training loss: 0.5293239290987893
Validation loss: 2.3416155649891275

Epoch: 308| Step: 0
Training loss: 0.3332339774513208
Validation loss: 2.356448755242686

Epoch: 6| Step: 1
Training loss: 0.4586933430758106
Validation loss: 2.365381863764512

Epoch: 6| Step: 2
Training loss: 0.41900698334603315
Validation loss: 2.3435708560638155

Epoch: 6| Step: 3
Training loss: 0.44267362757759976
Validation loss: 2.3684887697331574

Epoch: 6| Step: 4
Training loss: 0.23925989111172571
Validation loss: 2.3580868393657366

Epoch: 6| Step: 5
Training loss: 0.3731589024283932
Validation loss: 2.3489404795036615

Epoch: 6| Step: 6
Training loss: 0.31900780994621836
Validation loss: 2.362799931755119

Epoch: 6| Step: 7
Training loss: 0.39366928211773167
Validation loss: 2.3705760693895512

Epoch: 6| Step: 8
Training loss: 0.31539671167486993
Validation loss: 2.36483737227277

Epoch: 6| Step: 9
Training loss: 0.15477956045727784
Validation loss: 2.3333868465205514

Epoch: 6| Step: 10
Training loss: 0.4250305978194913
Validation loss: 2.3407343177760436

Epoch: 6| Step: 11
Training loss: 0.2562090689836273
Validation loss: 2.3305859373521605

Epoch: 6| Step: 12
Training loss: 0.3761387066662069
Validation loss: 2.380509163890154

Epoch: 6| Step: 13
Training loss: 0.4552673470356912
Validation loss: 2.3177206734336497

Epoch: 309| Step: 0
Training loss: 0.33936864154964075
Validation loss: 2.3461815048930283

Epoch: 6| Step: 1
Training loss: 0.25657597138214366
Validation loss: 2.353429742314219

Epoch: 6| Step: 2
Training loss: 0.34919120244688107
Validation loss: 2.3635534718378204

Epoch: 6| Step: 3
Training loss: 0.3605514426887457
Validation loss: 2.3660505692951417

Epoch: 6| Step: 4
Training loss: 0.3620649094424882
Validation loss: 2.3831462086469357

Epoch: 6| Step: 5
Training loss: 0.27027791027961257
Validation loss: 2.361347592201641

Epoch: 6| Step: 6
Training loss: 0.3055715207543269
Validation loss: 2.3590138164406675

Epoch: 6| Step: 7
Training loss: 0.2523319590031182
Validation loss: 2.354849829135137

Epoch: 6| Step: 8
Training loss: 0.38370577075815177
Validation loss: 2.3420393631614718

Epoch: 6| Step: 9
Training loss: 0.5721310922849638
Validation loss: 2.3303371308492893

Epoch: 6| Step: 10
Training loss: 0.4390812465969032
Validation loss: 2.3280135510220132

Epoch: 6| Step: 11
Training loss: 0.39417358275764974
Validation loss: 2.3403977186809697

Epoch: 6| Step: 12
Training loss: 0.2401691596359336
Validation loss: 2.3208638103853256

Epoch: 6| Step: 13
Training loss: 0.34861524521621085
Validation loss: 2.2934852540078023

Epoch: 310| Step: 0
Training loss: 0.3664562166871054
Validation loss: 2.3237018200966943

Epoch: 6| Step: 1
Training loss: 0.17824107035784864
Validation loss: 2.2995988160657435

Epoch: 6| Step: 2
Training loss: 0.16033643960207317
Validation loss: 2.331073689165608

Epoch: 6| Step: 3
Training loss: 0.3202600319852249
Validation loss: 2.3312426725234645

Epoch: 6| Step: 4
Training loss: 0.4765894366296708
Validation loss: 2.3250730090896043

Epoch: 6| Step: 5
Training loss: 0.08157792741108251
Validation loss: 2.371239430456014

Epoch: 6| Step: 6
Training loss: 0.31151629831390854
Validation loss: 2.3315285366036678

Epoch: 6| Step: 7
Training loss: 0.4829904703558597
Validation loss: 2.3221333295438162

Epoch: 6| Step: 8
Training loss: 0.3809558452792117
Validation loss: 2.3236935004196715

Epoch: 6| Step: 9
Training loss: 0.28945561046279705
Validation loss: 2.3006716566536465

Epoch: 6| Step: 10
Training loss: 0.5564490272984438
Validation loss: 2.314198589334384

Epoch: 6| Step: 11
Training loss: 0.29660023974713123
Validation loss: 2.3198775066726207

Epoch: 6| Step: 12
Training loss: 0.4720087108262875
Validation loss: 2.328939957714698

Epoch: 6| Step: 13
Training loss: 0.1434337145174946
Validation loss: 2.3498015783179897

Epoch: 311| Step: 0
Training loss: 0.25284352547165656
Validation loss: 2.349598983414205

Epoch: 6| Step: 1
Training loss: 0.3954115950731822
Validation loss: 2.3634063630634485

Epoch: 6| Step: 2
Training loss: 0.2450983032611986
Validation loss: 2.3756325186564515

Epoch: 6| Step: 3
Training loss: 0.2966792188870494
Validation loss: 2.3681557258177586

Epoch: 6| Step: 4
Training loss: 0.3991863842290548
Validation loss: 2.3635712452027633

Epoch: 6| Step: 5
Training loss: 0.23740721477499807
Validation loss: 2.3388256689210882

Epoch: 6| Step: 6
Training loss: 0.5174362851969639
Validation loss: 2.3365469220696085

Epoch: 6| Step: 7
Training loss: 0.44323513626160743
Validation loss: 2.324184814492165

Epoch: 6| Step: 8
Training loss: 0.31134084055742567
Validation loss: 2.3182753924301105

Epoch: 6| Step: 9
Training loss: 0.2782108827927089
Validation loss: 2.311968722699856

Epoch: 6| Step: 10
Training loss: 0.5002475662076922
Validation loss: 2.3141009922915114

Epoch: 6| Step: 11
Training loss: 0.2212410759473095
Validation loss: 2.2968099335302665

Epoch: 6| Step: 12
Training loss: 0.4368717758048821
Validation loss: 2.2985012616536435

Epoch: 6| Step: 13
Training loss: 0.4478999807517475
Validation loss: 2.3242386377686177

Epoch: 312| Step: 0
Training loss: 0.22268142892450837
Validation loss: 2.3158671003722384

Epoch: 6| Step: 1
Training loss: 0.2105353371709129
Validation loss: 2.3324164445538087

Epoch: 6| Step: 2
Training loss: 0.5376377350629936
Validation loss: 2.3390585341428736

Epoch: 6| Step: 3
Training loss: 0.4320796615214047
Validation loss: 2.346711208968605

Epoch: 6| Step: 4
Training loss: 0.3071268927624903
Validation loss: 2.3744976449358863

Epoch: 6| Step: 5
Training loss: 0.32150066793321963
Validation loss: 2.3566305161016143

Epoch: 6| Step: 6
Training loss: 0.3036584348773702
Validation loss: 2.3940468497442695

Epoch: 6| Step: 7
Training loss: 0.3959393442979595
Validation loss: 2.3857540077114545

Epoch: 6| Step: 8
Training loss: 0.43452196173701163
Validation loss: 2.367736143103309

Epoch: 6| Step: 9
Training loss: 0.313910317914399
Validation loss: 2.3556995809665415

Epoch: 6| Step: 10
Training loss: 0.40541517238139
Validation loss: 2.3740160565657153

Epoch: 6| Step: 11
Training loss: 0.26076723185644235
Validation loss: 2.3546854108827056

Epoch: 6| Step: 12
Training loss: 0.3427098207045322
Validation loss: 2.3577037559528438

Epoch: 6| Step: 13
Training loss: 0.14018826085103983
Validation loss: 2.3263952371992995

Epoch: 313| Step: 0
Training loss: 0.49124121146069555
Validation loss: 2.326465198092006

Epoch: 6| Step: 1
Training loss: 0.5091002934654527
Validation loss: 2.3565179223535417

Epoch: 6| Step: 2
Training loss: 0.3872448396443578
Validation loss: 2.3614155996668322

Epoch: 6| Step: 3
Training loss: 0.2584699426558223
Validation loss: 2.3632349625192517

Epoch: 6| Step: 4
Training loss: 0.1650377815242014
Validation loss: 2.452851405032557

Epoch: 6| Step: 5
Training loss: 0.5177087295141821
Validation loss: 2.4567084781651007

Epoch: 6| Step: 6
Training loss: 0.41449317486945314
Validation loss: 2.457493323765395

Epoch: 6| Step: 7
Training loss: 0.22546390023306134
Validation loss: 2.4146736110376463

Epoch: 6| Step: 8
Training loss: 0.4626782247883081
Validation loss: 2.3914430867153125

Epoch: 6| Step: 9
Training loss: 0.4924579513094953
Validation loss: 2.3505646339523802

Epoch: 6| Step: 10
Training loss: 0.23482479803246603
Validation loss: 2.324776165160205

Epoch: 6| Step: 11
Training loss: 0.374896571678091
Validation loss: 2.288897744479043

Epoch: 6| Step: 12
Training loss: 0.407127752597535
Validation loss: 2.300369750428721

Epoch: 6| Step: 13
Training loss: 0.23008805692313844
Validation loss: 2.3244830276250474

Epoch: 314| Step: 0
Training loss: 0.5806723739383327
Validation loss: 2.3551974887869176

Epoch: 6| Step: 1
Training loss: 0.3384149155165576
Validation loss: 2.360456229114405

Epoch: 6| Step: 2
Training loss: 0.29052134275249264
Validation loss: 2.441624368616705

Epoch: 6| Step: 3
Training loss: 0.4808190472175796
Validation loss: 2.458855383913566

Epoch: 6| Step: 4
Training loss: 0.36457201622246355
Validation loss: 2.474136910505087

Epoch: 6| Step: 5
Training loss: 0.2974323511946507
Validation loss: 2.429788752561864

Epoch: 6| Step: 6
Training loss: 0.3313930661368184
Validation loss: 2.4524711728800557

Epoch: 6| Step: 7
Training loss: 0.5022218927215425
Validation loss: 2.3966502661837517

Epoch: 6| Step: 8
Training loss: 0.3306427139267436
Validation loss: 2.405518430045555

Epoch: 6| Step: 9
Training loss: 0.39462624718653566
Validation loss: 2.359357682085551

Epoch: 6| Step: 10
Training loss: 0.32113097455401624
Validation loss: 2.321430484839003

Epoch: 6| Step: 11
Training loss: 0.3488506843816062
Validation loss: 2.2959403058123002

Epoch: 6| Step: 12
Training loss: 0.6150779404137827
Validation loss: 2.2770060148782845

Epoch: 6| Step: 13
Training loss: 0.34800817058209543
Validation loss: 2.2966895453765237

Epoch: 315| Step: 0
Training loss: 0.28133763166666814
Validation loss: 2.2879016237865866

Epoch: 6| Step: 1
Training loss: 0.3943989031299114
Validation loss: 2.299701620314083

Epoch: 6| Step: 2
Training loss: 0.36018115307155385
Validation loss: 2.3165679334575167

Epoch: 6| Step: 3
Training loss: 0.3468741395441329
Validation loss: 2.3087270000824565

Epoch: 6| Step: 4
Training loss: 0.17246315307749285
Validation loss: 2.303842749657832

Epoch: 6| Step: 5
Training loss: 0.48304464320876944
Validation loss: 2.338322944935834

Epoch: 6| Step: 6
Training loss: 0.47943372816805857
Validation loss: 2.3584797956515233

Epoch: 6| Step: 7
Training loss: 0.24580268449921722
Validation loss: 2.364557075725128

Epoch: 6| Step: 8
Training loss: 0.35861083345298217
Validation loss: 2.3415480970115277

Epoch: 6| Step: 9
Training loss: 0.3256681630197981
Validation loss: 2.3501978462995408

Epoch: 6| Step: 10
Training loss: 0.5038837161681285
Validation loss: 2.3433172371956434

Epoch: 6| Step: 11
Training loss: 0.5075401162514075
Validation loss: 2.34891569797691

Epoch: 6| Step: 12
Training loss: 0.4057531252615504
Validation loss: 2.371960558700498

Epoch: 6| Step: 13
Training loss: 0.4251121723580617
Validation loss: 2.3605473254445557

Epoch: 316| Step: 0
Training loss: 0.3128338222877517
Validation loss: 2.3947206218322727

Epoch: 6| Step: 1
Training loss: 0.5714039222475852
Validation loss: 2.392935250847596

Epoch: 6| Step: 2
Training loss: 0.3899880747928148
Validation loss: 2.395500245197789

Epoch: 6| Step: 3
Training loss: 0.23742642047142246
Validation loss: 2.4131035911856613

Epoch: 6| Step: 4
Training loss: 0.176931169760468
Validation loss: 2.4021981079869836

Epoch: 6| Step: 5
Training loss: 0.2026728770156499
Validation loss: 2.4262081203491723

Epoch: 6| Step: 6
Training loss: 0.41252222218043777
Validation loss: 2.40307107982244

Epoch: 6| Step: 7
Training loss: 0.29456671746608115
Validation loss: 2.401932562277061

Epoch: 6| Step: 8
Training loss: 0.4727929288112667
Validation loss: 2.4160238294319303

Epoch: 6| Step: 9
Training loss: 0.49393775605334217
Validation loss: 2.3940660533049862

Epoch: 6| Step: 10
Training loss: 0.2082346364521507
Validation loss: 2.3865568562842836

Epoch: 6| Step: 11
Training loss: 0.4755385921653742
Validation loss: 2.393101290573794

Epoch: 6| Step: 12
Training loss: 0.337408857931361
Validation loss: 2.3960879279317755

Epoch: 6| Step: 13
Training loss: 0.21189201697370613
Validation loss: 2.34905192001826

Epoch: 317| Step: 0
Training loss: 0.36316075941752
Validation loss: 2.3694724052585037

Epoch: 6| Step: 1
Training loss: 0.4691200861695098
Validation loss: 2.3856725491472037

Epoch: 6| Step: 2
Training loss: 0.37602927098577316
Validation loss: 2.374396931408443

Epoch: 6| Step: 3
Training loss: 0.20456276580135935
Validation loss: 2.4009151505932107

Epoch: 6| Step: 4
Training loss: 0.3707686556265781
Validation loss: 2.3861531816282064

Epoch: 6| Step: 5
Training loss: 0.5100085969275144
Validation loss: 2.380081202084408

Epoch: 6| Step: 6
Training loss: 0.4390096164227969
Validation loss: 2.3858970366278207

Epoch: 6| Step: 7
Training loss: 0.23397383530813243
Validation loss: 2.411019479983114

Epoch: 6| Step: 8
Training loss: 0.31385858377985626
Validation loss: 2.3822091169603423

Epoch: 6| Step: 9
Training loss: 0.2974273161694771
Validation loss: 2.35133365663253

Epoch: 6| Step: 10
Training loss: 0.19885531166537
Validation loss: 2.3583328367370666

Epoch: 6| Step: 11
Training loss: 0.23952723533963732
Validation loss: 2.386269954989728

Epoch: 6| Step: 12
Training loss: 0.4665651584250566
Validation loss: 2.3207505026348523

Epoch: 6| Step: 13
Training loss: 0.1575374077564131
Validation loss: 2.3536504327753947

Epoch: 318| Step: 0
Training loss: 0.2758766511808069
Validation loss: 2.354068770039737

Epoch: 6| Step: 1
Training loss: 0.40931599242694633
Validation loss: 2.361755088758423

Epoch: 6| Step: 2
Training loss: 0.4267779941282414
Validation loss: 2.3646425515611305

Epoch: 6| Step: 3
Training loss: 0.2031740899555304
Validation loss: 2.3558501259982663

Epoch: 6| Step: 4
Training loss: 0.5461117731921241
Validation loss: 2.360869398015959

Epoch: 6| Step: 5
Training loss: 0.2619970464703744
Validation loss: 2.3924112785046745

Epoch: 6| Step: 6
Training loss: 0.4163407143557542
Validation loss: 2.3861953582796334

Epoch: 6| Step: 7
Training loss: 0.276462673231287
Validation loss: 2.375984646234188

Epoch: 6| Step: 8
Training loss: 0.1246617068296269
Validation loss: 2.3766843007911187

Epoch: 6| Step: 9
Training loss: 0.3246494901913368
Validation loss: 2.368272582835295

Epoch: 6| Step: 10
Training loss: 0.3848262100156591
Validation loss: 2.3929133836833762

Epoch: 6| Step: 11
Training loss: 0.269160028873793
Validation loss: 2.3806615219287135

Epoch: 6| Step: 12
Training loss: 0.36482693390413085
Validation loss: 2.35272556735524

Epoch: 6| Step: 13
Training loss: 0.3126840287983665
Validation loss: 2.3690533046325717

Epoch: 319| Step: 0
Training loss: 0.2787453868723733
Validation loss: 2.3804602901721252

Epoch: 6| Step: 1
Training loss: 0.4724173138945385
Validation loss: 2.3512558264745023

Epoch: 6| Step: 2
Training loss: 0.26612551599777745
Validation loss: 2.3523199352201423

Epoch: 6| Step: 3
Training loss: 0.4944042663495846
Validation loss: 2.381637479877003

Epoch: 6| Step: 4
Training loss: 0.34934805581906
Validation loss: 2.3863220502787197

Epoch: 6| Step: 5
Training loss: 0.3675819469743724
Validation loss: 2.3805944896421694

Epoch: 6| Step: 6
Training loss: 0.28016830758796746
Validation loss: 2.3948849545597506

Epoch: 6| Step: 7
Training loss: 0.23085953830254938
Validation loss: 2.358747485097791

Epoch: 6| Step: 8
Training loss: 0.3908999047928931
Validation loss: 2.385340620126348

Epoch: 6| Step: 9
Training loss: 0.18519230141532286
Validation loss: 2.3608222493577804

Epoch: 6| Step: 10
Training loss: 0.25312585477331445
Validation loss: 2.3567110857100615

Epoch: 6| Step: 11
Training loss: 0.41784600211291106
Validation loss: 2.3571785635255376

Epoch: 6| Step: 12
Training loss: 0.3371510874379235
Validation loss: 2.329753038637984

Epoch: 6| Step: 13
Training loss: 0.37320689818527353
Validation loss: 2.3990935344674424

Epoch: 320| Step: 0
Training loss: 0.30846031539387025
Validation loss: 2.416685518722355

Epoch: 6| Step: 1
Training loss: 0.26802173791271394
Validation loss: 2.387607468145584

Epoch: 6| Step: 2
Training loss: 0.22349461612414642
Validation loss: 2.3849475662828734

Epoch: 6| Step: 3
Training loss: 0.2064610131536016
Validation loss: 2.396205102468883

Epoch: 6| Step: 4
Training loss: 0.35070461931460517
Validation loss: 2.3909718567956113

Epoch: 6| Step: 5
Training loss: 0.42817847829793415
Validation loss: 2.3798644136313314

Epoch: 6| Step: 6
Training loss: 0.30191656831482994
Validation loss: 2.3822850824948585

Epoch: 6| Step: 7
Training loss: 0.33298491234221594
Validation loss: 2.349665442289724

Epoch: 6| Step: 8
Training loss: 0.449539418416464
Validation loss: 2.348715507656905

Epoch: 6| Step: 9
Training loss: 0.3908200921206256
Validation loss: 2.3460546383858984

Epoch: 6| Step: 10
Training loss: 0.4193955427502334
Validation loss: 2.354532141760816

Epoch: 6| Step: 11
Training loss: 0.511703898672997
Validation loss: 2.377273069816088

Epoch: 6| Step: 12
Training loss: 0.2510322479338383
Validation loss: 2.386296379593378

Epoch: 6| Step: 13
Training loss: 0.1111760104114595
Validation loss: 2.3855105516531254

Epoch: 321| Step: 0
Training loss: 0.19238594943359782
Validation loss: 2.3882803537329518

Epoch: 6| Step: 1
Training loss: 0.33881876926641963
Validation loss: 2.4283569436319024

Epoch: 6| Step: 2
Training loss: 0.378029112835122
Validation loss: 2.4477309604040243

Epoch: 6| Step: 3
Training loss: 0.27700921151186375
Validation loss: 2.411984824035978

Epoch: 6| Step: 4
Training loss: 0.29041214911141217
Validation loss: 2.4316862281687186

Epoch: 6| Step: 5
Training loss: 0.3998659557513387
Validation loss: 2.388789199205514

Epoch: 6| Step: 6
Training loss: 0.31103495263971825
Validation loss: 2.4185557579187504

Epoch: 6| Step: 7
Training loss: 0.2823089558537472
Validation loss: 2.4013051755122157

Epoch: 6| Step: 8
Training loss: 0.2818146574005911
Validation loss: 2.3685569931960426

Epoch: 6| Step: 9
Training loss: 0.36587307412540243
Validation loss: 2.3959193417990825

Epoch: 6| Step: 10
Training loss: 0.2508470223235832
Validation loss: 2.3728334684135004

Epoch: 6| Step: 11
Training loss: 0.41193791298258836
Validation loss: 2.3528697085433548

Epoch: 6| Step: 12
Training loss: 0.5053743371536924
Validation loss: 2.316301844095532

Epoch: 6| Step: 13
Training loss: 0.36201146436815607
Validation loss: 2.35336056069405

Epoch: 322| Step: 0
Training loss: 0.2784343686553893
Validation loss: 2.3385544855198703

Epoch: 6| Step: 1
Training loss: 0.34826730754150975
Validation loss: 2.366542755839412

Epoch: 6| Step: 2
Training loss: 0.1782811735054407
Validation loss: 2.340249339461461

Epoch: 6| Step: 3
Training loss: 0.49067446343928106
Validation loss: 2.380887140458414

Epoch: 6| Step: 4
Training loss: 0.29544127749615934
Validation loss: 2.378373912838166

Epoch: 6| Step: 5
Training loss: 0.31814370134090714
Validation loss: 2.3475824154426372

Epoch: 6| Step: 6
Training loss: 0.3065949059681266
Validation loss: 2.3318909619906267

Epoch: 6| Step: 7
Training loss: 0.40795003537602065
Validation loss: 2.385629967793445

Epoch: 6| Step: 8
Training loss: 0.3564096302305323
Validation loss: 2.349319384057473

Epoch: 6| Step: 9
Training loss: 0.2626121843262305
Validation loss: 2.3315844944148356

Epoch: 6| Step: 10
Training loss: 0.1453373890245348
Validation loss: 2.3498423192908535

Epoch: 6| Step: 11
Training loss: 0.3721789504317587
Validation loss: 2.3272996975630993

Epoch: 6| Step: 12
Training loss: 0.27775824829166945
Validation loss: 2.354921044930142

Epoch: 6| Step: 13
Training loss: 0.3167070089647182
Validation loss: 2.347906905220013

Epoch: 323| Step: 0
Training loss: 0.4317922714150879
Validation loss: 2.3591351842558694

Epoch: 6| Step: 1
Training loss: 0.1877688030816135
Validation loss: 2.3859441202450618

Epoch: 6| Step: 2
Training loss: 0.301477814677387
Validation loss: 2.394806768122127

Epoch: 6| Step: 3
Training loss: 0.22339709323372553
Validation loss: 2.406661794387857

Epoch: 6| Step: 4
Training loss: 0.16508835276573144
Validation loss: 2.4089823267976698

Epoch: 6| Step: 5
Training loss: 0.3309926112667019
Validation loss: 2.4264730184081995

Epoch: 6| Step: 6
Training loss: 0.47000431089250433
Validation loss: 2.4321653405263373

Epoch: 6| Step: 7
Training loss: 0.2757837046873302
Validation loss: 2.417737358623713

Epoch: 6| Step: 8
Training loss: 0.42028470000610224
Validation loss: 2.3907450898412352

Epoch: 6| Step: 9
Training loss: 0.25613416228375774
Validation loss: 2.383426555264969

Epoch: 6| Step: 10
Training loss: 0.47564562162591434
Validation loss: 2.358006108836449

Epoch: 6| Step: 11
Training loss: 0.3412282737341242
Validation loss: 2.377281845782656

Epoch: 6| Step: 12
Training loss: 0.2689466632928218
Validation loss: 2.342283790855775

Epoch: 6| Step: 13
Training loss: 0.30040208028274307
Validation loss: 2.3749664835354065

Epoch: 324| Step: 0
Training loss: 0.390287062378779
Validation loss: 2.3833033034214552

Epoch: 6| Step: 1
Training loss: 0.29611356865173405
Validation loss: 2.401601673267647

Epoch: 6| Step: 2
Training loss: 0.27220302940416463
Validation loss: 2.413011374564739

Epoch: 6| Step: 3
Training loss: 0.35344558359172273
Validation loss: 2.3879282850635595

Epoch: 6| Step: 4
Training loss: 0.21166446595161778
Validation loss: 2.4222665079300767

Epoch: 6| Step: 5
Training loss: 0.15543618460184144
Validation loss: 2.413022548049632

Epoch: 6| Step: 6
Training loss: 0.24730240245505153
Validation loss: 2.398474593705914

Epoch: 6| Step: 7
Training loss: 0.4954050645466956
Validation loss: 2.439199496204264

Epoch: 6| Step: 8
Training loss: 0.25312865101571275
Validation loss: 2.4066623088923453

Epoch: 6| Step: 9
Training loss: 0.32487155503563364
Validation loss: 2.3873590289546853

Epoch: 6| Step: 10
Training loss: 0.4044377731053505
Validation loss: 2.4061539237513685

Epoch: 6| Step: 11
Training loss: 0.34818055767683537
Validation loss: 2.3788446913845176

Epoch: 6| Step: 12
Training loss: 0.18696519955364765
Validation loss: 2.376763272687868

Epoch: 6| Step: 13
Training loss: 0.2888427620878807
Validation loss: 2.369043161198106

Epoch: 325| Step: 0
Training loss: 0.25495441936321694
Validation loss: 2.3638891672313593

Epoch: 6| Step: 1
Training loss: 0.10952108283613445
Validation loss: 2.3679103846114784

Epoch: 6| Step: 2
Training loss: 0.3443648085496753
Validation loss: 2.3814234931696094

Epoch: 6| Step: 3
Training loss: 0.3196359444229985
Validation loss: 2.3375349633440012

Epoch: 6| Step: 4
Training loss: 0.23690953733898035
Validation loss: 2.3309671161010654

Epoch: 6| Step: 5
Training loss: 0.3757898238506588
Validation loss: 2.3691380387860796

Epoch: 6| Step: 6
Training loss: 0.3106664151611422
Validation loss: 2.3627125587948115

Epoch: 6| Step: 7
Training loss: 0.35575354349699806
Validation loss: 2.344541456247864

Epoch: 6| Step: 8
Training loss: 0.5152998968633974
Validation loss: 2.3792210133309606

Epoch: 6| Step: 9
Training loss: 0.35692445088377894
Validation loss: 2.3471419599463377

Epoch: 6| Step: 10
Training loss: 0.14297259643466723
Validation loss: 2.368026389274982

Epoch: 6| Step: 11
Training loss: 0.1790035541237522
Validation loss: 2.3757713772845794

Epoch: 6| Step: 12
Training loss: 0.4462931359436981
Validation loss: 2.376646335337194

Epoch: 6| Step: 13
Training loss: 0.17982041584566635
Validation loss: 2.368838211989854

Epoch: 326| Step: 0
Training loss: 0.2368890788466474
Validation loss: 2.3639261365036384

Epoch: 6| Step: 1
Training loss: 0.4021246230052809
Validation loss: 2.364133747285336

Epoch: 6| Step: 2
Training loss: 0.3533767722564073
Validation loss: 2.3349104032924046

Epoch: 6| Step: 3
Training loss: 0.19141405440009326
Validation loss: 2.335167709458217

Epoch: 6| Step: 4
Training loss: 0.3194421480736684
Validation loss: 2.3549943620147356

Epoch: 6| Step: 5
Training loss: 0.47601998827243186
Validation loss: 2.3663667512052613

Epoch: 6| Step: 6
Training loss: 0.26777296560122077
Validation loss: 2.3713487538442686

Epoch: 6| Step: 7
Training loss: 0.33151987751028866
Validation loss: 2.336752136790433

Epoch: 6| Step: 8
Training loss: 0.2630190361389601
Validation loss: 2.3440856419806932

Epoch: 6| Step: 9
Training loss: 0.32236707997734576
Validation loss: 2.309732381245561

Epoch: 6| Step: 10
Training loss: 0.19483903718585366
Validation loss: 2.355838885933798

Epoch: 6| Step: 11
Training loss: 0.3795031143005406
Validation loss: 2.3533253410999255

Epoch: 6| Step: 12
Training loss: 0.2541616622374805
Validation loss: 2.3651697952020765

Epoch: 6| Step: 13
Training loss: 0.337239735528428
Validation loss: 2.384705500154565

Epoch: 327| Step: 0
Training loss: 0.36487933359058916
Validation loss: 2.3704972363607943

Epoch: 6| Step: 1
Training loss: 0.4296288190133083
Validation loss: 2.385591577835156

Epoch: 6| Step: 2
Training loss: 0.12297412068685057
Validation loss: 2.3734819216093364

Epoch: 6| Step: 3
Training loss: 0.378942114322333
Validation loss: 2.402567416708133

Epoch: 6| Step: 4
Training loss: 0.311603523889982
Validation loss: 2.3731121640828863

Epoch: 6| Step: 5
Training loss: 0.31059868098538945
Validation loss: 2.385621773817984

Epoch: 6| Step: 6
Training loss: 0.23401742520263624
Validation loss: 2.3767239607292936

Epoch: 6| Step: 7
Training loss: 0.1762403849758947
Validation loss: 2.381000068219224

Epoch: 6| Step: 8
Training loss: 0.3343819488266822
Validation loss: 2.391104643429179

Epoch: 6| Step: 9
Training loss: 0.2672535396409322
Validation loss: 2.3730307731046687

Epoch: 6| Step: 10
Training loss: 0.20741788281982954
Validation loss: 2.3754800436581522

Epoch: 6| Step: 11
Training loss: 0.45185044687554426
Validation loss: 2.377003833127642

Epoch: 6| Step: 12
Training loss: 0.29135552340643844
Validation loss: 2.3816949459828174

Epoch: 6| Step: 13
Training loss: 0.3307753765934405
Validation loss: 2.36238895508391

Epoch: 328| Step: 0
Training loss: 0.5506279914766036
Validation loss: 2.347555563256451

Epoch: 6| Step: 1
Training loss: 0.22653033587270915
Validation loss: 2.385656148565371

Epoch: 6| Step: 2
Training loss: 0.37253567486383016
Validation loss: 2.342433719247354

Epoch: 6| Step: 3
Training loss: 0.29179316854101767
Validation loss: 2.3948358668114804

Epoch: 6| Step: 4
Training loss: 0.21468732514575573
Validation loss: 2.3571090759191167

Epoch: 6| Step: 5
Training loss: 0.26490751303483856
Validation loss: 2.3836191141850214

Epoch: 6| Step: 6
Training loss: 0.2780939218752281
Validation loss: 2.3575841078457356

Epoch: 6| Step: 7
Training loss: 0.34585070288750647
Validation loss: 2.3797902080852524

Epoch: 6| Step: 8
Training loss: 0.28123998624141044
Validation loss: 2.364482311717972

Epoch: 6| Step: 9
Training loss: 0.3245234034750916
Validation loss: 2.4042449756573188

Epoch: 6| Step: 10
Training loss: 0.2465182533498815
Validation loss: 2.3831243398713604

Epoch: 6| Step: 11
Training loss: 0.28303709753986955
Validation loss: 2.3965422002067656

Epoch: 6| Step: 12
Training loss: 0.14623503763330167
Validation loss: 2.4165312255597193

Epoch: 6| Step: 13
Training loss: 0.3676648385292686
Validation loss: 2.4149664993457605

Epoch: 329| Step: 0
Training loss: 0.3122876280132618
Validation loss: 2.39986789585051

Epoch: 6| Step: 1
Training loss: 0.3559367065487827
Validation loss: 2.367747603869548

Epoch: 6| Step: 2
Training loss: 0.35156656898686944
Validation loss: 2.383415512475546

Epoch: 6| Step: 3
Training loss: 0.2787761903228197
Validation loss: 2.3495119864496896

Epoch: 6| Step: 4
Training loss: 0.36820659847065934
Validation loss: 2.3399552753480566

Epoch: 6| Step: 5
Training loss: 0.28636649422437416
Validation loss: 2.357734607029733

Epoch: 6| Step: 6
Training loss: 0.27864889190754
Validation loss: 2.3511787907962884

Epoch: 6| Step: 7
Training loss: 0.3479420633621506
Validation loss: 2.3742245637163917

Epoch: 6| Step: 8
Training loss: 0.31559914209179135
Validation loss: 2.36880337673977

Epoch: 6| Step: 9
Training loss: 0.21883011100328156
Validation loss: 2.3844795344017466

Epoch: 6| Step: 10
Training loss: 0.3008881911368366
Validation loss: 2.3669443648994286

Epoch: 6| Step: 11
Training loss: 0.2502726915401073
Validation loss: 2.416863700407318

Epoch: 6| Step: 12
Training loss: 0.33744208933999637
Validation loss: 2.3994809194799376

Epoch: 6| Step: 13
Training loss: 0.12498917011195647
Validation loss: 2.418269028946133

Epoch: 330| Step: 0
Training loss: 0.43561503813530483
Validation loss: 2.4055212419807197

Epoch: 6| Step: 1
Training loss: 0.3743349177726702
Validation loss: 2.420905751742864

Epoch: 6| Step: 2
Training loss: 0.26940644180296336
Validation loss: 2.387120944698679

Epoch: 6| Step: 3
Training loss: 0.4281075648078057
Validation loss: 2.347156774487008

Epoch: 6| Step: 4
Training loss: 0.18228811305987436
Validation loss: 2.371896550058486

Epoch: 6| Step: 5
Training loss: 0.12170545984732692
Validation loss: 2.362329000836689

Epoch: 6| Step: 6
Training loss: 0.2752880013441613
Validation loss: 2.3630380238033744

Epoch: 6| Step: 7
Training loss: 0.2863974145212163
Validation loss: 2.337691643271564

Epoch: 6| Step: 8
Training loss: 0.10310438629235424
Validation loss: 2.3627894506207947

Epoch: 6| Step: 9
Training loss: 0.36991693721001384
Validation loss: 2.3591665398465214

Epoch: 6| Step: 10
Training loss: 0.30621670619836516
Validation loss: 2.381645162269416

Epoch: 6| Step: 11
Training loss: 0.35612059133417795
Validation loss: 2.40906459236254

Epoch: 6| Step: 12
Training loss: 0.32607939545531384
Validation loss: 2.3962100174709366

Epoch: 6| Step: 13
Training loss: 0.3580591118203303
Validation loss: 2.4035305807527907

Epoch: 331| Step: 0
Training loss: 0.4908620000729879
Validation loss: 2.3765620031856076

Epoch: 6| Step: 1
Training loss: 0.26459108413897764
Validation loss: 2.376493764651392

Epoch: 6| Step: 2
Training loss: 0.14114029833602645
Validation loss: 2.38062087763149

Epoch: 6| Step: 3
Training loss: 0.24869745647261352
Validation loss: 2.367355918463667

Epoch: 6| Step: 4
Training loss: 0.38890396549692613
Validation loss: 2.363826134096799

Epoch: 6| Step: 5
Training loss: 0.3232200015657077
Validation loss: 2.3906027572812087

Epoch: 6| Step: 6
Training loss: 0.3189727397649367
Validation loss: 2.3964784293187025

Epoch: 6| Step: 7
Training loss: 0.4781270220346017
Validation loss: 2.38096235516359

Epoch: 6| Step: 8
Training loss: 0.25312073315450345
Validation loss: 2.3966507967432715

Epoch: 6| Step: 9
Training loss: 0.3251117450002363
Validation loss: 2.385782252406844

Epoch: 6| Step: 10
Training loss: 0.3317929254040348
Validation loss: 2.391877432559562

Epoch: 6| Step: 11
Training loss: 0.21237952449597527
Validation loss: 2.357799624790065

Epoch: 6| Step: 12
Training loss: 0.2235325917721388
Validation loss: 2.34499754760325

Epoch: 6| Step: 13
Training loss: 0.10061713540399972
Validation loss: 2.3759579062543383

Epoch: 332| Step: 0
Training loss: 0.4134673754104347
Validation loss: 2.35151865339844

Epoch: 6| Step: 1
Training loss: 0.377606098126262
Validation loss: 2.361725112463423

Epoch: 6| Step: 2
Training loss: 0.33769694604252415
Validation loss: 2.3704296516735055

Epoch: 6| Step: 3
Training loss: 0.27904720751478085
Validation loss: 2.3305185152793757

Epoch: 6| Step: 4
Training loss: 0.29723583428065214
Validation loss: 2.3476823770467234

Epoch: 6| Step: 5
Training loss: 0.3474256307794802
Validation loss: 2.3687341608850265

Epoch: 6| Step: 6
Training loss: 0.23467106398415585
Validation loss: 2.3566420733020923

Epoch: 6| Step: 7
Training loss: 0.22871085736202462
Validation loss: 2.3809686550706344

Epoch: 6| Step: 8
Training loss: 0.296102635896958
Validation loss: 2.3828049682304493

Epoch: 6| Step: 9
Training loss: 0.10659250529146015
Validation loss: 2.383480638540852

Epoch: 6| Step: 10
Training loss: 0.45368741746715946
Validation loss: 2.393837474543186

Epoch: 6| Step: 11
Training loss: 0.1865429693251402
Validation loss: 2.392184099839167

Epoch: 6| Step: 12
Training loss: 0.20887034861660786
Validation loss: 2.3747982280536317

Epoch: 6| Step: 13
Training loss: 0.15389007347799008
Validation loss: 2.3658176938213997

Epoch: 333| Step: 0
Training loss: 0.18890386775544307
Validation loss: 2.3774850556700007

Epoch: 6| Step: 1
Training loss: 0.32737169760982526
Validation loss: 2.3970166024109982

Epoch: 6| Step: 2
Training loss: 0.41914098122786914
Validation loss: 2.3641167263831866

Epoch: 6| Step: 3
Training loss: 0.21853941760952947
Validation loss: 2.357626138803551

Epoch: 6| Step: 4
Training loss: 0.3009331307336638
Validation loss: 2.3269727175639257

Epoch: 6| Step: 5
Training loss: 0.4114514925746197
Validation loss: 2.348161209659937

Epoch: 6| Step: 6
Training loss: 0.2543713930703767
Validation loss: 2.303732469841987

Epoch: 6| Step: 7
Training loss: 0.330762841420145
Validation loss: 2.337211585456307

Epoch: 6| Step: 8
Training loss: 0.37788791080593975
Validation loss: 2.334220975771158

Epoch: 6| Step: 9
Training loss: 0.3074409343235297
Validation loss: 2.326094931893559

Epoch: 6| Step: 10
Training loss: 0.16879836621164732
Validation loss: 2.3436223406189716

Epoch: 6| Step: 11
Training loss: 0.22285587998670348
Validation loss: 2.3415508877789235

Epoch: 6| Step: 12
Training loss: 0.23349992788015556
Validation loss: 2.325174814378958

Epoch: 6| Step: 13
Training loss: 0.175852443265279
Validation loss: 2.3112057769979115

Epoch: 334| Step: 0
Training loss: 0.21753922085543057
Validation loss: 2.3253985231571126

Epoch: 6| Step: 1
Training loss: 0.41880838784204455
Validation loss: 2.3708449103709666

Epoch: 6| Step: 2
Training loss: 0.4149557950134711
Validation loss: 2.323005629501093

Epoch: 6| Step: 3
Training loss: 0.18284808570573255
Validation loss: 2.3233566084619683

Epoch: 6| Step: 4
Training loss: 0.1528334510907895
Validation loss: 2.363510410632912

Epoch: 6| Step: 5
Training loss: 0.4329260246867432
Validation loss: 2.3633304800656814

Epoch: 6| Step: 6
Training loss: 0.2918913421507696
Validation loss: 2.360186349258021

Epoch: 6| Step: 7
Training loss: 0.333366201190956
Validation loss: 2.3915974371558586

Epoch: 6| Step: 8
Training loss: 0.21891848002434092
Validation loss: 2.404271105671041

Epoch: 6| Step: 9
Training loss: 0.36348630388869146
Validation loss: 2.4106313351850135

Epoch: 6| Step: 10
Training loss: 0.22219380658155358
Validation loss: 2.4019280901847

Epoch: 6| Step: 11
Training loss: 0.24738430531730657
Validation loss: 2.403304781183567

Epoch: 6| Step: 12
Training loss: 0.24611344334355062
Validation loss: 2.404597918780109

Epoch: 6| Step: 13
Training loss: 0.17357412275369838
Validation loss: 2.386520949787317

Epoch: 335| Step: 0
Training loss: 0.3397337198265603
Validation loss: 2.377644304909534

Epoch: 6| Step: 1
Training loss: 0.16322575360689615
Validation loss: 2.389100189749759

Epoch: 6| Step: 2
Training loss: 0.17641856901473277
Validation loss: 2.4061613531341592

Epoch: 6| Step: 3
Training loss: 0.3751387736719576
Validation loss: 2.3827247317009337

Epoch: 6| Step: 4
Training loss: 0.12022354875372046
Validation loss: 2.38758449509083

Epoch: 6| Step: 5
Training loss: 0.27678061790432895
Validation loss: 2.3710845818965476

Epoch: 6| Step: 6
Training loss: 0.28380040292469316
Validation loss: 2.406887354113932

Epoch: 6| Step: 7
Training loss: 0.26203677085742627
Validation loss: 2.3808031119669892

Epoch: 6| Step: 8
Training loss: 0.3041324205367371
Validation loss: 2.3954783308149716

Epoch: 6| Step: 9
Training loss: 0.22720999929004002
Validation loss: 2.3881648739905335

Epoch: 6| Step: 10
Training loss: 0.1320441050732666
Validation loss: 2.3687710696934974

Epoch: 6| Step: 11
Training loss: 0.3261072014747234
Validation loss: 2.407805284439788

Epoch: 6| Step: 12
Training loss: 0.5359908230337567
Validation loss: 2.388504691238222

Epoch: 6| Step: 13
Training loss: 0.19533887685050189
Validation loss: 2.3744682063130043

Epoch: 336| Step: 0
Training loss: 0.42557436615267513
Validation loss: 2.3500999072500397

Epoch: 6| Step: 1
Training loss: 0.16296252989488172
Validation loss: 2.3701264004481146

Epoch: 6| Step: 2
Training loss: 0.21496143585707417
Validation loss: 2.3346793039974445

Epoch: 6| Step: 3
Training loss: 0.29558675232264914
Validation loss: 2.3241255734191206

Epoch: 6| Step: 4
Training loss: 0.12101662779454744
Validation loss: 2.3721340019603505

Epoch: 6| Step: 5
Training loss: 0.09646620444191391
Validation loss: 2.3170612867647224

Epoch: 6| Step: 6
Training loss: 0.44657543185004495
Validation loss: 2.348392175416865

Epoch: 6| Step: 7
Training loss: 0.23980905517985102
Validation loss: 2.369019095865411

Epoch: 6| Step: 8
Training loss: 0.31904634416124006
Validation loss: 2.3417569913738916

Epoch: 6| Step: 9
Training loss: 0.32475980172110946
Validation loss: 2.3474946065945135

Epoch: 6| Step: 10
Training loss: 0.35479964697362243
Validation loss: 2.37520132199221

Epoch: 6| Step: 11
Training loss: 0.1221725569731738
Validation loss: 2.3691367816578546

Epoch: 6| Step: 12
Training loss: 0.31044052510240105
Validation loss: 2.3757489248199737

Epoch: 6| Step: 13
Training loss: 0.20997606267343377
Validation loss: 2.3708138979272633

Epoch: 337| Step: 0
Training loss: 0.11378623365008499
Validation loss: 2.3567205343599436

Epoch: 6| Step: 1
Training loss: 0.31011926252692207
Validation loss: 2.3831388462855547

Epoch: 6| Step: 2
Training loss: 0.28746832901204034
Validation loss: 2.348529019468298

Epoch: 6| Step: 3
Training loss: 0.1776806047868183
Validation loss: 2.370844877931384

Epoch: 6| Step: 4
Training loss: 0.14791892468604972
Validation loss: 2.365578420408605

Epoch: 6| Step: 5
Training loss: 0.2552842818673324
Validation loss: 2.369435860635537

Epoch: 6| Step: 6
Training loss: 0.35701716288815893
Validation loss: 2.3619215273172305

Epoch: 6| Step: 7
Training loss: 0.2973514548269154
Validation loss: 2.3829213451564946

Epoch: 6| Step: 8
Training loss: 0.22983726367835594
Validation loss: 2.360086549022151

Epoch: 6| Step: 9
Training loss: 0.3048125035057357
Validation loss: 2.347877244019392

Epoch: 6| Step: 10
Training loss: 0.36632176057506194
Validation loss: 2.364862324096478

Epoch: 6| Step: 11
Training loss: 0.3716155950598878
Validation loss: 2.350856156130561

Epoch: 6| Step: 12
Training loss: 0.2579063764798552
Validation loss: 2.351723872523778

Epoch: 6| Step: 13
Training loss: 0.3292142522293726
Validation loss: 2.3942624646034547

Epoch: 338| Step: 0
Training loss: 0.27139008895027794
Validation loss: 2.387136614603391

Epoch: 6| Step: 1
Training loss: 0.23319425390293935
Validation loss: 2.3469112851517844

Epoch: 6| Step: 2
Training loss: 0.38108615481357294
Validation loss: 2.373887952935238

Epoch: 6| Step: 3
Training loss: 0.2579533741167795
Validation loss: 2.3867472453626926

Epoch: 6| Step: 4
Training loss: 0.3335153286526673
Validation loss: 2.386596736719882

Epoch: 6| Step: 5
Training loss: 0.14077094240378674
Validation loss: 2.328858697030954

Epoch: 6| Step: 6
Training loss: 0.3449039165103022
Validation loss: 2.373178112486543

Epoch: 6| Step: 7
Training loss: 0.21378783055763761
Validation loss: 2.3429041768485845

Epoch: 6| Step: 8
Training loss: 0.3918874177684006
Validation loss: 2.3187531897361473

Epoch: 6| Step: 9
Training loss: 0.3750484951769227
Validation loss: 2.3288529463706706

Epoch: 6| Step: 10
Training loss: 0.33060957656321277
Validation loss: 2.3297715256934346

Epoch: 6| Step: 11
Training loss: 0.16336084369745357
Validation loss: 2.3333416338375956

Epoch: 6| Step: 12
Training loss: 0.17919320036632957
Validation loss: 2.341835560329828

Epoch: 6| Step: 13
Training loss: 0.33275404403315567
Validation loss: 2.332479678584033

Epoch: 339| Step: 0
Training loss: 0.29043918842919153
Validation loss: 2.3896254770931007

Epoch: 6| Step: 1
Training loss: 0.2018685268834669
Validation loss: 2.32218659373396

Epoch: 6| Step: 2
Training loss: 0.23351912789702312
Validation loss: 2.3737726521369815

Epoch: 6| Step: 3
Training loss: 0.23205370553528126
Validation loss: 2.3725659214097545

Epoch: 6| Step: 4
Training loss: 0.3861978857135139
Validation loss: 2.3527431163290493

Epoch: 6| Step: 5
Training loss: 0.37201131518136726
Validation loss: 2.3775815102877296

Epoch: 6| Step: 6
Training loss: 0.257633580632691
Validation loss: 2.3680984940970005

Epoch: 6| Step: 7
Training loss: 0.13927907045818888
Validation loss: 2.3598730361216873

Epoch: 6| Step: 8
Training loss: 0.46352899369764566
Validation loss: 2.351004692477972

Epoch: 6| Step: 9
Training loss: 0.13085867041782462
Validation loss: 2.3846898056745576

Epoch: 6| Step: 10
Training loss: 0.27610170263333966
Validation loss: 2.375265961474963

Epoch: 6| Step: 11
Training loss: 0.3258099403829629
Validation loss: 2.3802632779467183

Epoch: 6| Step: 12
Training loss: 0.40963041112921006
Validation loss: 2.3979038592023683

Epoch: 6| Step: 13
Training loss: 0.17552909249155885
Validation loss: 2.389241165962591

Epoch: 340| Step: 0
Training loss: 0.4706992944585287
Validation loss: 2.3688855809609124

Epoch: 6| Step: 1
Training loss: 0.27998480738567005
Validation loss: 2.3749497488736453

Epoch: 6| Step: 2
Training loss: 0.37660244456808023
Validation loss: 2.377415515126672

Epoch: 6| Step: 3
Training loss: 0.28289357071896487
Validation loss: 2.3581490583557927

Epoch: 6| Step: 4
Training loss: 0.2884921297639463
Validation loss: 2.3496983093392165

Epoch: 6| Step: 5
Training loss: 0.34566435084598746
Validation loss: 2.338248154536684

Epoch: 6| Step: 6
Training loss: 0.25902536507989365
Validation loss: 2.309541767367757

Epoch: 6| Step: 7
Training loss: 0.3641059088306874
Validation loss: 2.3378986753917164

Epoch: 6| Step: 8
Training loss: 0.3275006007232689
Validation loss: 2.312419466469401

Epoch: 6| Step: 9
Training loss: 0.3116437745335601
Validation loss: 2.3499063111835863

Epoch: 6| Step: 10
Training loss: 0.4328430137482049
Validation loss: 2.3713315882404014

Epoch: 6| Step: 11
Training loss: 0.25372482567203375
Validation loss: 2.4367586653989726

Epoch: 6| Step: 12
Training loss: 0.2735052569771541
Validation loss: 2.4536264457139283

Epoch: 6| Step: 13
Training loss: 0.3668809585152406
Validation loss: 2.4378377292887405

Epoch: 341| Step: 0
Training loss: 0.4114452995779075
Validation loss: 2.427642584254676

Epoch: 6| Step: 1
Training loss: 0.2524336881951879
Validation loss: 2.4026814199848525

Epoch: 6| Step: 2
Training loss: 0.20925969856271032
Validation loss: 2.385744269473312

Epoch: 6| Step: 3
Training loss: 0.31686019123618797
Validation loss: 2.385617269000075

Epoch: 6| Step: 4
Training loss: 0.22322072036868998
Validation loss: 2.366049139602605

Epoch: 6| Step: 5
Training loss: 0.3308355005290988
Validation loss: 2.3585284878899104

Epoch: 6| Step: 6
Training loss: 0.5906809997249365
Validation loss: 2.3583452136561833

Epoch: 6| Step: 7
Training loss: 0.37295115576014065
Validation loss: 2.359082691274763

Epoch: 6| Step: 8
Training loss: 0.20274312546207945
Validation loss: 2.387565509713679

Epoch: 6| Step: 9
Training loss: 0.37749085096299767
Validation loss: 2.396588615651396

Epoch: 6| Step: 10
Training loss: 0.4287345375742782
Validation loss: 2.4169315326297918

Epoch: 6| Step: 11
Training loss: 0.3572836436639668
Validation loss: 2.4614695411254663

Epoch: 6| Step: 12
Training loss: 0.40721307819097186
Validation loss: 2.4466116864258862

Epoch: 6| Step: 13
Training loss: 0.4556484986617789
Validation loss: 2.4932745248194963

Epoch: 342| Step: 0
Training loss: 0.2645078334820172
Validation loss: 2.4453712971855732

Epoch: 6| Step: 1
Training loss: 0.2624009479106523
Validation loss: 2.413725570899465

Epoch: 6| Step: 2
Training loss: 0.3433611469418369
Validation loss: 2.3837023067004526

Epoch: 6| Step: 3
Training loss: 0.3325711964984832
Validation loss: 2.3801451166386682

Epoch: 6| Step: 4
Training loss: 0.4507539968995723
Validation loss: 2.3559611809160694

Epoch: 6| Step: 5
Training loss: 0.3690124773691698
Validation loss: 2.382351626551616

Epoch: 6| Step: 6
Training loss: 0.5051372189628645
Validation loss: 2.39782927534653

Epoch: 6| Step: 7
Training loss: 0.3996589301772079
Validation loss: 2.3883512771119353

Epoch: 6| Step: 8
Training loss: 0.3795653441040076
Validation loss: 2.407180019365436

Epoch: 6| Step: 9
Training loss: 0.39995564348927337
Validation loss: 2.4214601985175355

Epoch: 6| Step: 10
Training loss: 0.3347598993441596
Validation loss: 2.3984911699761224

Epoch: 6| Step: 11
Training loss: 0.2641430071836439
Validation loss: 2.4133292780926334

Epoch: 6| Step: 12
Training loss: 0.31765151167158157
Validation loss: 2.395879245512532

Epoch: 6| Step: 13
Training loss: 0.2462095336414073
Validation loss: 2.3934002935086167

Epoch: 343| Step: 0
Training loss: 0.23842210202475353
Validation loss: 2.4065641952644543

Epoch: 6| Step: 1
Training loss: 0.27413798933482536
Validation loss: 2.3829770928875877

Epoch: 6| Step: 2
Training loss: 0.3340905450194952
Validation loss: 2.3765471934175886

Epoch: 6| Step: 3
Training loss: 0.22751451941154024
Validation loss: 2.379022672705844

Epoch: 6| Step: 4
Training loss: 0.337303875964701
Validation loss: 2.3967392701791

Epoch: 6| Step: 5
Training loss: 0.4210392833581233
Validation loss: 2.373663761156279

Epoch: 6| Step: 6
Training loss: 0.41836165740087755
Validation loss: 2.3770495834069214

Epoch: 6| Step: 7
Training loss: 0.20667757558455588
Validation loss: 2.3961212955318825

Epoch: 6| Step: 8
Training loss: 0.446833272466308
Validation loss: 2.403736678641529

Epoch: 6| Step: 9
Training loss: 0.23479862076469601
Validation loss: 2.3733657358688807

Epoch: 6| Step: 10
Training loss: 0.3077541954473488
Validation loss: 2.377164845509141

Epoch: 6| Step: 11
Training loss: 0.22032665112546684
Validation loss: 2.3889310635450194

Epoch: 6| Step: 12
Training loss: 0.2705111864891753
Validation loss: 2.371130986440023

Epoch: 6| Step: 13
Training loss: 0.15118000393088676
Validation loss: 2.405839565150861

Epoch: 344| Step: 0
Training loss: 0.18496321180288774
Validation loss: 2.3813449691788287

Epoch: 6| Step: 1
Training loss: 0.18708420387064112
Validation loss: 2.3851910663698312

Epoch: 6| Step: 2
Training loss: 0.3551393806489091
Validation loss: 2.387305596246525

Epoch: 6| Step: 3
Training loss: 0.18153267390552483
Validation loss: 2.3840722250611326

Epoch: 6| Step: 4
Training loss: 0.3276398341660399
Validation loss: 2.3694099080010322

Epoch: 6| Step: 5
Training loss: 0.3962959819131336
Validation loss: 2.3851105779808437

Epoch: 6| Step: 6
Training loss: 0.372689640300669
Validation loss: 2.3639632483474426

Epoch: 6| Step: 7
Training loss: 0.37764609093154944
Validation loss: 2.378564550575192

Epoch: 6| Step: 8
Training loss: 0.25037150793549423
Validation loss: 2.382365293478083

Epoch: 6| Step: 9
Training loss: 0.4025950526611933
Validation loss: 2.390295643122086

Epoch: 6| Step: 10
Training loss: 0.2697560299101291
Validation loss: 2.3899716170627596

Epoch: 6| Step: 11
Training loss: 0.26921733599007497
Validation loss: 2.4176676183284074

Epoch: 6| Step: 12
Training loss: 0.21634263918132887
Validation loss: 2.4400104933687397

Epoch: 6| Step: 13
Training loss: 0.17505451017598825
Validation loss: 2.411564370000305

Epoch: 345| Step: 0
Training loss: 0.21362267194442544
Validation loss: 2.4034732084725223

Epoch: 6| Step: 1
Training loss: 0.21090273217373207
Validation loss: 2.383596901812833

Epoch: 6| Step: 2
Training loss: 0.47460799354383565
Validation loss: 2.3688218804598344

Epoch: 6| Step: 3
Training loss: 0.1590644793958733
Validation loss: 2.365985525265775

Epoch: 6| Step: 4
Training loss: 0.3196253616970971
Validation loss: 2.3905813438509256

Epoch: 6| Step: 5
Training loss: 0.3984755329604545
Validation loss: 2.337267534989928

Epoch: 6| Step: 6
Training loss: 0.25384737946196656
Validation loss: 2.3729868510706895

Epoch: 6| Step: 7
Training loss: 0.2628433065922051
Validation loss: 2.3621662180379737

Epoch: 6| Step: 8
Training loss: 0.30073757597676043
Validation loss: 2.3802807065569356

Epoch: 6| Step: 9
Training loss: 0.1859192274235164
Validation loss: 2.37848106194809

Epoch: 6| Step: 10
Training loss: 0.30803081012952555
Validation loss: 2.379100518510043

Epoch: 6| Step: 11
Training loss: 0.32588182904719204
Validation loss: 2.3846656708695297

Epoch: 6| Step: 12
Training loss: 0.21631177120587466
Validation loss: 2.3981695115973776

Epoch: 6| Step: 13
Training loss: 0.14187407743263253
Validation loss: 2.3686057347890035

Epoch: 346| Step: 0
Training loss: 0.20661410105611874
Validation loss: 2.3888702067417897

Epoch: 6| Step: 1
Training loss: 0.3320159010985858
Validation loss: 2.390195923465743

Epoch: 6| Step: 2
Training loss: 0.4147537507387137
Validation loss: 2.365592549995895

Epoch: 6| Step: 3
Training loss: 0.27503613050404446
Validation loss: 2.403517576019978

Epoch: 6| Step: 4
Training loss: 0.2001107293061767
Validation loss: 2.392713218760871

Epoch: 6| Step: 5
Training loss: 0.3624535021063995
Validation loss: 2.3263435052828285

Epoch: 6| Step: 6
Training loss: 0.20192189814499467
Validation loss: 2.3309978195304604

Epoch: 6| Step: 7
Training loss: 0.3552778381108669
Validation loss: 2.353714789485969

Epoch: 6| Step: 8
Training loss: 0.388351423342913
Validation loss: 2.3474986243357256

Epoch: 6| Step: 9
Training loss: 0.2684317428761981
Validation loss: 2.3996928205590935

Epoch: 6| Step: 10
Training loss: 0.19587660389227113
Validation loss: 2.3654992766868923

Epoch: 6| Step: 11
Training loss: 0.26517335979263335
Validation loss: 2.4003453537750303

Epoch: 6| Step: 12
Training loss: 0.26712650974919866
Validation loss: 2.439891845915838

Epoch: 6| Step: 13
Training loss: 0.16115091973492643
Validation loss: 2.4275897900415835

Epoch: 347| Step: 0
Training loss: 0.2827484295385714
Validation loss: 2.428697375677414

Epoch: 6| Step: 1
Training loss: 0.14757496801647735
Validation loss: 2.430174860832269

Epoch: 6| Step: 2
Training loss: 0.238270462292225
Validation loss: 2.417036122336785

Epoch: 6| Step: 3
Training loss: 0.25740061717037205
Validation loss: 2.390077286245244

Epoch: 6| Step: 4
Training loss: 0.41785415076603993
Validation loss: 2.3642677731536756

Epoch: 6| Step: 5
Training loss: 0.2482475610327024
Validation loss: 2.3324484934626044

Epoch: 6| Step: 6
Training loss: 0.18872066364559337
Validation loss: 2.350245102288317

Epoch: 6| Step: 7
Training loss: 0.37298267870665064
Validation loss: 2.3517970396522623

Epoch: 6| Step: 8
Training loss: 0.21671932998722634
Validation loss: 2.360101634794056

Epoch: 6| Step: 9
Training loss: 0.4055422890774416
Validation loss: 2.354522199806043

Epoch: 6| Step: 10
Training loss: 0.3163937224745576
Validation loss: 2.330502062620339

Epoch: 6| Step: 11
Training loss: 0.3644815938773735
Validation loss: 2.3617336797166186

Epoch: 6| Step: 12
Training loss: 0.26969249711871596
Validation loss: 2.364163735059713

Epoch: 6| Step: 13
Training loss: 0.1592019246956829
Validation loss: 2.391165551917639

Epoch: 348| Step: 0
Training loss: 0.15691140379397056
Validation loss: 2.400556219542747

Epoch: 6| Step: 1
Training loss: 0.24407817804873097
Validation loss: 2.401539114370273

Epoch: 6| Step: 2
Training loss: 0.350763663719805
Validation loss: 2.4106050374884336

Epoch: 6| Step: 3
Training loss: 0.2096261393624712
Validation loss: 2.3877690544243864

Epoch: 6| Step: 4
Training loss: 0.3324289744747521
Validation loss: 2.40370925497725

Epoch: 6| Step: 5
Training loss: 0.09993532555536416
Validation loss: 2.3665349540068674

Epoch: 6| Step: 6
Training loss: 0.3404924187173328
Validation loss: 2.363625672979751

Epoch: 6| Step: 7
Training loss: 0.4602301390930036
Validation loss: 2.3857298191978606

Epoch: 6| Step: 8
Training loss: 0.3339305968237754
Validation loss: 2.3470962640330373

Epoch: 6| Step: 9
Training loss: 0.3087860908341182
Validation loss: 2.3513903489604684

Epoch: 6| Step: 10
Training loss: 0.14535887988113932
Validation loss: 2.3780392348009984

Epoch: 6| Step: 11
Training loss: 0.25651048121314357
Validation loss: 2.366769548322862

Epoch: 6| Step: 12
Training loss: 0.3144534804063767
Validation loss: 2.39677318598427

Epoch: 6| Step: 13
Training loss: 0.14905242537995236
Validation loss: 2.3558187262666483

Epoch: 349| Step: 0
Training loss: 0.29938089444563476
Validation loss: 2.3665581514379532

Epoch: 6| Step: 1
Training loss: 0.28777927952503046
Validation loss: 2.3992117525621492

Epoch: 6| Step: 2
Training loss: 0.22103670112115156
Validation loss: 2.3765147678045877

Epoch: 6| Step: 3
Training loss: 0.1719118642287244
Validation loss: 2.3831576781365467

Epoch: 6| Step: 4
Training loss: 0.3473192682016928
Validation loss: 2.354417616739522

Epoch: 6| Step: 5
Training loss: 0.32123750777391324
Validation loss: 2.3726712914972783

Epoch: 6| Step: 6
Training loss: 0.25556140759207313
Validation loss: 2.3463507313287937

Epoch: 6| Step: 7
Training loss: 0.2958263145652905
Validation loss: 2.357966201208545

Epoch: 6| Step: 8
Training loss: 0.32577007924054197
Validation loss: 2.343415164341699

Epoch: 6| Step: 9
Training loss: 0.28711910620566217
Validation loss: 2.3542680521601

Epoch: 6| Step: 10
Training loss: 0.2170913002970881
Validation loss: 2.3616668526892

Epoch: 6| Step: 11
Training loss: 0.3408737031494416
Validation loss: 2.320998872182773

Epoch: 6| Step: 12
Training loss: 0.2665968953936299
Validation loss: 2.315799672104792

Epoch: 6| Step: 13
Training loss: 0.21664699322227102
Validation loss: 2.3717008829292245

Epoch: 350| Step: 0
Training loss: 0.228389215963349
Validation loss: 2.3598764521368794

Epoch: 6| Step: 1
Training loss: 0.43159748742151777
Validation loss: 2.359421422423307

Epoch: 6| Step: 2
Training loss: 0.22388285189213367
Validation loss: 2.384667488782504

Epoch: 6| Step: 3
Training loss: 0.11511726409163968
Validation loss: 2.4023893442536846

Epoch: 6| Step: 4
Training loss: 0.13543058898467303
Validation loss: 2.3734423457544906

Epoch: 6| Step: 5
Training loss: 0.22053554384187474
Validation loss: 2.413297531000827

Epoch: 6| Step: 6
Training loss: 0.31734480410184335
Validation loss: 2.3836264578546498

Epoch: 6| Step: 7
Training loss: 0.28878652440713615
Validation loss: 2.39571319071967

Epoch: 6| Step: 8
Training loss: 0.14921240818068474
Validation loss: 2.3840322701349983

Epoch: 6| Step: 9
Training loss: 0.18922745153074094
Validation loss: 2.37924002704244

Epoch: 6| Step: 10
Training loss: 0.23647762330533229
Validation loss: 2.3935375419104328

Epoch: 6| Step: 11
Training loss: 0.423471151049399
Validation loss: 2.3832925970151693

Epoch: 6| Step: 12
Training loss: 0.3004767375088689
Validation loss: 2.375202659289316

Epoch: 6| Step: 13
Training loss: 0.3462424623963458
Validation loss: 2.367011711183236

Epoch: 351| Step: 0
Training loss: 0.3497574348845592
Validation loss: 2.39035073678321

Epoch: 6| Step: 1
Training loss: 0.1530165792061701
Validation loss: 2.407105189349962

Epoch: 6| Step: 2
Training loss: 0.15357794042893078
Validation loss: 2.357808282417655

Epoch: 6| Step: 3
Training loss: 0.387171586135294
Validation loss: 2.3825158074187742

Epoch: 6| Step: 4
Training loss: 0.35526317898292925
Validation loss: 2.3628348479190366

Epoch: 6| Step: 5
Training loss: 0.26930722311095023
Validation loss: 2.3786219281757894

Epoch: 6| Step: 6
Training loss: 0.15820785797951253
Validation loss: 2.3600677742272147

Epoch: 6| Step: 7
Training loss: 0.2786711104981139
Validation loss: 2.357620784527648

Epoch: 6| Step: 8
Training loss: 0.15764360620063866
Validation loss: 2.3807709919852997

Epoch: 6| Step: 9
Training loss: 0.22647490945795912
Validation loss: 2.378569046116414

Epoch: 6| Step: 10
Training loss: 0.3105079098613863
Validation loss: 2.3810052827079455

Epoch: 6| Step: 11
Training loss: 0.1598488952092022
Validation loss: 2.3916340767374082

Epoch: 6| Step: 12
Training loss: 0.32714548821329753
Validation loss: 2.4019641111044803

Epoch: 6| Step: 13
Training loss: 0.11398487013172648
Validation loss: 2.4083522849606323

Epoch: 352| Step: 0
Training loss: 0.1500816825651565
Validation loss: 2.39737951848313

Epoch: 6| Step: 1
Training loss: 0.22330481617763057
Validation loss: 2.4219045827106154

Epoch: 6| Step: 2
Training loss: 0.2497052451835552
Validation loss: 2.41200495987088

Epoch: 6| Step: 3
Training loss: 0.2672339822815014
Validation loss: 2.4303069290373887

Epoch: 6| Step: 4
Training loss: 0.281452119574204
Validation loss: 2.3975070908242584

Epoch: 6| Step: 5
Training loss: 0.2849747589712682
Validation loss: 2.4372146997957986

Epoch: 6| Step: 6
Training loss: 0.4481191861135962
Validation loss: 2.4208545325170707

Epoch: 6| Step: 7
Training loss: 0.3067379693701032
Validation loss: 2.4189580769086

Epoch: 6| Step: 8
Training loss: 0.33889565911635133
Validation loss: 2.4022030406088235

Epoch: 6| Step: 9
Training loss: 0.17718791795106065
Validation loss: 2.378185576403309

Epoch: 6| Step: 10
Training loss: 0.150956433325003
Validation loss: 2.4248680126399913

Epoch: 6| Step: 11
Training loss: 0.26141259805344313
Validation loss: 2.4001048502271187

Epoch: 6| Step: 12
Training loss: 0.24379455452643306
Validation loss: 2.4205886902175755

Epoch: 6| Step: 13
Training loss: 0.286659394130849
Validation loss: 2.4144191938385817

Epoch: 353| Step: 0
Training loss: 0.2896641321232324
Validation loss: 2.403925446880343

Epoch: 6| Step: 1
Training loss: 0.2802261418966877
Validation loss: 2.3981733471624613

Epoch: 6| Step: 2
Training loss: 0.43997127926896945
Validation loss: 2.3956227873908795

Epoch: 6| Step: 3
Training loss: 0.17307083855203204
Validation loss: 2.398698863134882

Epoch: 6| Step: 4
Training loss: 0.24104847243671065
Validation loss: 2.394207609525054

Epoch: 6| Step: 5
Training loss: 0.26124103560422324
Validation loss: 2.396783892873679

Epoch: 6| Step: 6
Training loss: 0.1963761359521268
Validation loss: 2.3303945732364943

Epoch: 6| Step: 7
Training loss: 0.27853004182844343
Validation loss: 2.3482678923459432

Epoch: 6| Step: 8
Training loss: 0.33482720733378685
Validation loss: 2.3758351158989175

Epoch: 6| Step: 9
Training loss: 0.10171858091677252
Validation loss: 2.3398081083615203

Epoch: 6| Step: 10
Training loss: 0.12682166262116953
Validation loss: 2.341004405435191

Epoch: 6| Step: 11
Training loss: 0.3510555851306096
Validation loss: 2.388086301141672

Epoch: 6| Step: 12
Training loss: 0.16466658504657164
Validation loss: 2.342249290718808

Epoch: 6| Step: 13
Training loss: 0.3847898098078635
Validation loss: 2.35161149027045

Epoch: 354| Step: 0
Training loss: 0.2461172652741368
Validation loss: 2.3674150057943417

Epoch: 6| Step: 1
Training loss: 0.09300414060916971
Validation loss: 2.353088337667763

Epoch: 6| Step: 2
Training loss: 0.2940138423281986
Validation loss: 2.353498700775089

Epoch: 6| Step: 3
Training loss: 0.24339573712504717
Validation loss: 2.3509613894292034

Epoch: 6| Step: 4
Training loss: 0.17881058171498995
Validation loss: 2.354471672773344

Epoch: 6| Step: 5
Training loss: 0.19913159128069266
Validation loss: 2.3509346756160525

Epoch: 6| Step: 6
Training loss: 0.13862912096540456
Validation loss: 2.383382462321374

Epoch: 6| Step: 7
Training loss: 0.4252116917270858
Validation loss: 2.352757560266768

Epoch: 6| Step: 8
Training loss: 0.25561893609836067
Validation loss: 2.3662714748550995

Epoch: 6| Step: 9
Training loss: 0.33122918360458753
Validation loss: 2.3705245240569006

Epoch: 6| Step: 10
Training loss: 0.3206904670178095
Validation loss: 2.3551116312387683

Epoch: 6| Step: 11
Training loss: 0.15764710947085434
Validation loss: 2.3640819077718236

Epoch: 6| Step: 12
Training loss: 0.1513704976365951
Validation loss: 2.368998467237947

Epoch: 6| Step: 13
Training loss: 0.23121166104749538
Validation loss: 2.3799374459603793

Epoch: 355| Step: 0
Training loss: 0.37679777749159343
Validation loss: 2.399740166980898

Epoch: 6| Step: 1
Training loss: 0.409443663160429
Validation loss: 2.384582702254534

Epoch: 6| Step: 2
Training loss: 0.14306322947024933
Validation loss: 2.3831594192092798

Epoch: 6| Step: 3
Training loss: 0.13078127850768076
Validation loss: 2.3841596545043373

Epoch: 6| Step: 4
Training loss: 0.34433113090462253
Validation loss: 2.3899261892375994

Epoch: 6| Step: 5
Training loss: 0.17114226250068412
Validation loss: 2.4004764743620335

Epoch: 6| Step: 6
Training loss: 0.1654476153805231
Validation loss: 2.362420536069308

Epoch: 6| Step: 7
Training loss: 0.16798035448486184
Validation loss: 2.3872938868088687

Epoch: 6| Step: 8
Training loss: 0.0839907593850972
Validation loss: 2.407810184280434

Epoch: 6| Step: 9
Training loss: 0.1336684971554832
Validation loss: 2.409509032592209

Epoch: 6| Step: 10
Training loss: 0.30447178320209256
Validation loss: 2.389722153483841

Epoch: 6| Step: 11
Training loss: 0.1879190788216432
Validation loss: 2.377298774312809

Epoch: 6| Step: 12
Training loss: 0.2435032420823771
Validation loss: 2.3862447591399065

Epoch: 6| Step: 13
Training loss: 0.27737198269558017
Validation loss: 2.3874818359974292

Epoch: 356| Step: 0
Training loss: 0.1176569872208659
Validation loss: 2.4200910313972877

Epoch: 6| Step: 1
Training loss: 0.18647166227582457
Validation loss: 2.431291767861063

Epoch: 6| Step: 2
Training loss: 0.07264243938078023
Validation loss: 2.413967264629682

Epoch: 6| Step: 3
Training loss: 0.2695947102460721
Validation loss: 2.3599155944620693

Epoch: 6| Step: 4
Training loss: 0.11600246483243533
Validation loss: 2.3885926807611195

Epoch: 6| Step: 5
Training loss: 0.30594989708632053
Validation loss: 2.36111650938816

Epoch: 6| Step: 6
Training loss: 0.17018715112855634
Validation loss: 2.3349049068930103

Epoch: 6| Step: 7
Training loss: 0.23899594982558064
Validation loss: 2.362093472221752

Epoch: 6| Step: 8
Training loss: 0.2810311127955754
Validation loss: 2.358214238219485

Epoch: 6| Step: 9
Training loss: 0.3698454088013504
Validation loss: 2.3379392361583986

Epoch: 6| Step: 10
Training loss: 0.35089703201714006
Validation loss: 2.340861938620641

Epoch: 6| Step: 11
Training loss: 0.27177055972723874
Validation loss: 2.3699700437256697

Epoch: 6| Step: 12
Training loss: 0.21799550900568926
Validation loss: 2.378955365782963

Epoch: 6| Step: 13
Training loss: 0.1827391456904351
Validation loss: 2.381234090399483

Epoch: 357| Step: 0
Training loss: 0.22687418643290613
Validation loss: 2.378604399032365

Epoch: 6| Step: 1
Training loss: 0.28547989755129705
Validation loss: 2.348074373965205

Epoch: 6| Step: 2
Training loss: 0.35822443675100013
Validation loss: 2.3875650219641815

Epoch: 6| Step: 3
Training loss: 0.18936884863780476
Validation loss: 2.3770158272923885

Epoch: 6| Step: 4
Training loss: 0.16236830335688007
Validation loss: 2.352349028186001

Epoch: 6| Step: 5
Training loss: 0.29377551576706906
Validation loss: 2.366877942235631

Epoch: 6| Step: 6
Training loss: 0.24512037905860767
Validation loss: 2.3459232112967396

Epoch: 6| Step: 7
Training loss: 0.09669363518491661
Validation loss: 2.344201413233962

Epoch: 6| Step: 8
Training loss: 0.1797893484311662
Validation loss: 2.3910783368294974

Epoch: 6| Step: 9
Training loss: 0.11540804723057589
Validation loss: 2.379029459436327

Epoch: 6| Step: 10
Training loss: 0.14457077053093367
Validation loss: 2.359451355187921

Epoch: 6| Step: 11
Training loss: 0.37811243335869954
Validation loss: 2.4056044075933705

Epoch: 6| Step: 12
Training loss: 0.18492519230641136
Validation loss: 2.4132954361486743

Epoch: 6| Step: 13
Training loss: 0.1064408371360768
Validation loss: 2.3668188192924777

Epoch: 358| Step: 0
Training loss: 0.22749748996251215
Validation loss: 2.3617525785819242

Epoch: 6| Step: 1
Training loss: 0.20447963395521185
Validation loss: 2.370772577649138

Epoch: 6| Step: 2
Training loss: 0.12118164840871598
Validation loss: 2.338424712214907

Epoch: 6| Step: 3
Training loss: 0.3782381676552171
Validation loss: 2.385383688123804

Epoch: 6| Step: 4
Training loss: 0.3361259973999921
Validation loss: 2.3443965607972976

Epoch: 6| Step: 5
Training loss: 0.2397166620590509
Validation loss: 2.3425073158119365

Epoch: 6| Step: 6
Training loss: 0.3013887834011622
Validation loss: 2.3219268404609683

Epoch: 6| Step: 7
Training loss: 0.11624657861740571
Validation loss: 2.371773617536882

Epoch: 6| Step: 8
Training loss: 0.16487958075730128
Validation loss: 2.3610582970300724

Epoch: 6| Step: 9
Training loss: 0.10774196272998018
Validation loss: 2.3645716890004373

Epoch: 6| Step: 10
Training loss: 0.27359289113622876
Validation loss: 2.310817891614296

Epoch: 6| Step: 11
Training loss: 0.28872724371162234
Validation loss: 2.351384402642916

Epoch: 6| Step: 12
Training loss: 0.22395241899591325
Validation loss: 2.373575791731608

Epoch: 6| Step: 13
Training loss: 0.11448367934824574
Validation loss: 2.3627991863592137

Epoch: 359| Step: 0
Training loss: 0.19758723264000283
Validation loss: 2.3472218886556395

Epoch: 6| Step: 1
Training loss: 0.28440774372774474
Validation loss: 2.338455842853643

Epoch: 6| Step: 2
Training loss: 0.30584382447604025
Validation loss: 2.3950963545829866

Epoch: 6| Step: 3
Training loss: 0.20532904215730421
Validation loss: 2.4126549082482214

Epoch: 6| Step: 4
Training loss: 0.1609475428956882
Validation loss: 2.3840649978242032

Epoch: 6| Step: 5
Training loss: 0.14253362196253577
Validation loss: 2.354501057633105

Epoch: 6| Step: 6
Training loss: 0.2778279148326491
Validation loss: 2.3827348464800937

Epoch: 6| Step: 7
Training loss: 0.12266305825600025
Validation loss: 2.382554924819921

Epoch: 6| Step: 8
Training loss: 0.30695744566523475
Validation loss: 2.390331668807975

Epoch: 6| Step: 9
Training loss: 0.37575484835376805
Validation loss: 2.402476608106831

Epoch: 6| Step: 10
Training loss: 0.20083224691661694
Validation loss: 2.4206059269761204

Epoch: 6| Step: 11
Training loss: 0.24235787090429706
Validation loss: 2.4016370788916372

Epoch: 6| Step: 12
Training loss: 0.165581337103772
Validation loss: 2.4232112398998087

Epoch: 6| Step: 13
Training loss: 0.29998976123742327
Validation loss: 2.4346699731261814

Epoch: 360| Step: 0
Training loss: 0.42302487105667497
Validation loss: 2.4424328203365193

Epoch: 6| Step: 1
Training loss: 0.16144239567471436
Validation loss: 2.431177548712084

Epoch: 6| Step: 2
Training loss: 0.21006546966918807
Validation loss: 2.42742806425131

Epoch: 6| Step: 3
Training loss: 0.18688448569294816
Validation loss: 2.4042941261425668

Epoch: 6| Step: 4
Training loss: 0.2486968947517743
Validation loss: 2.426452985467227

Epoch: 6| Step: 5
Training loss: 0.3511494435241996
Validation loss: 2.4049236731818513

Epoch: 6| Step: 6
Training loss: 0.25563489370156695
Validation loss: 2.3940265221738697

Epoch: 6| Step: 7
Training loss: 0.14574193999945023
Validation loss: 2.3916562905704097

Epoch: 6| Step: 8
Training loss: 0.2687031006366896
Validation loss: 2.3789453965798613

Epoch: 6| Step: 9
Training loss: 0.13468896371616962
Validation loss: 2.3740038582661556

Epoch: 6| Step: 10
Training loss: 0.1556727654622015
Validation loss: 2.362196541993451

Epoch: 6| Step: 11
Training loss: 0.2249078177656767
Validation loss: 2.383716955862682

Epoch: 6| Step: 12
Training loss: 0.27829498711189227
Validation loss: 2.3444610091486076

Epoch: 6| Step: 13
Training loss: 0.227791952637718
Validation loss: 2.3476069522342033

Epoch: 361| Step: 0
Training loss: 0.13721434821442452
Validation loss: 2.367110659522024

Epoch: 6| Step: 1
Training loss: 0.4226177529450151
Validation loss: 2.340933720679745

Epoch: 6| Step: 2
Training loss: 0.1190318486540891
Validation loss: 2.347117522057551

Epoch: 6| Step: 3
Training loss: 0.18616919307081642
Validation loss: 2.327532243860073

Epoch: 6| Step: 4
Training loss: 0.2761737834211612
Validation loss: 2.3802100666903545

Epoch: 6| Step: 5
Training loss: 0.08357533381271623
Validation loss: 2.3563474851554926

Epoch: 6| Step: 6
Training loss: 0.14397747684581508
Validation loss: 2.371379171188068

Epoch: 6| Step: 7
Training loss: 0.3166284605033673
Validation loss: 2.3629095815967665

Epoch: 6| Step: 8
Training loss: 0.2329930891579728
Validation loss: 2.387832445406254

Epoch: 6| Step: 9
Training loss: 0.2272136719201415
Validation loss: 2.3800087310563307

Epoch: 6| Step: 10
Training loss: 0.21555788820177282
Validation loss: 2.369391521940353

Epoch: 6| Step: 11
Training loss: 0.13456679617795853
Validation loss: 2.360841296143437

Epoch: 6| Step: 12
Training loss: 0.3022347542110017
Validation loss: 2.3635414202028304

Epoch: 6| Step: 13
Training loss: 0.2841168888090576
Validation loss: 2.357704556239641

Epoch: 362| Step: 0
Training loss: 0.33930896467839405
Validation loss: 2.3720802911435825

Epoch: 6| Step: 1
Training loss: 0.2607006940079594
Validation loss: 2.387564923447898

Epoch: 6| Step: 2
Training loss: 0.2424578926186545
Validation loss: 2.377754292855937

Epoch: 6| Step: 3
Training loss: 0.35912318321960823
Validation loss: 2.392293923504229

Epoch: 6| Step: 4
Training loss: 0.24134768729361353
Validation loss: 2.4107055389146654

Epoch: 6| Step: 5
Training loss: 0.14824113908278852
Validation loss: 2.4045486017861815

Epoch: 6| Step: 6
Training loss: 0.24714082910274005
Validation loss: 2.402673113441721

Epoch: 6| Step: 7
Training loss: 0.0841781465606203
Validation loss: 2.3931758525240605

Epoch: 6| Step: 8
Training loss: 0.3036414799888005
Validation loss: 2.3732649500020777

Epoch: 6| Step: 9
Training loss: 0.16765575300429203
Validation loss: 2.3400924555645037

Epoch: 6| Step: 10
Training loss: 0.17167350488841887
Validation loss: 2.384061704106667

Epoch: 6| Step: 11
Training loss: 0.21542550132191118
Validation loss: 2.343749554541761

Epoch: 6| Step: 12
Training loss: 0.2234232474496424
Validation loss: 2.311760420240829

Epoch: 6| Step: 13
Training loss: 0.3420631788153999
Validation loss: 2.3298741385361486

Epoch: 363| Step: 0
Training loss: 0.3896984938207959
Validation loss: 2.3431159919574345

Epoch: 6| Step: 1
Training loss: 0.23026220312046067
Validation loss: 2.365318917014029

Epoch: 6| Step: 2
Training loss: 0.25458558974902384
Validation loss: 2.3405484719032024

Epoch: 6| Step: 3
Training loss: 0.1963747321539205
Validation loss: 2.381976742011605

Epoch: 6| Step: 4
Training loss: 0.23538306725818148
Validation loss: 2.381983779704734

Epoch: 6| Step: 5
Training loss: 0.31466261478358787
Validation loss: 2.3946889636583286

Epoch: 6| Step: 6
Training loss: 0.21767767267445098
Validation loss: 2.4143964143129852

Epoch: 6| Step: 7
Training loss: 0.3420152892758035
Validation loss: 2.3839920016105927

Epoch: 6| Step: 8
Training loss: 0.11309886917730277
Validation loss: 2.385096571007185

Epoch: 6| Step: 9
Training loss: 0.1380873435891741
Validation loss: 2.402236506291588

Epoch: 6| Step: 10
Training loss: 0.19339639135983797
Validation loss: 2.3734618874954228

Epoch: 6| Step: 11
Training loss: 0.15999875233022184
Validation loss: 2.3771561257291833

Epoch: 6| Step: 12
Training loss: 0.08566389093412309
Validation loss: 2.3760686109978195

Epoch: 6| Step: 13
Training loss: 0.4014456270889812
Validation loss: 2.378498169487218

Epoch: 364| Step: 0
Training loss: 0.2086171372836466
Validation loss: 2.388956487002417

Epoch: 6| Step: 1
Training loss: 0.09825502410357112
Validation loss: 2.366381530434355

Epoch: 6| Step: 2
Training loss: 0.21288187551454954
Validation loss: 2.3435348532314375

Epoch: 6| Step: 3
Training loss: 0.27345683165742457
Validation loss: 2.3525476441356905

Epoch: 6| Step: 4
Training loss: 0.2473313833242938
Validation loss: 2.3770489082677586

Epoch: 6| Step: 5
Training loss: 0.36313076388960003
Validation loss: 2.340135550564733

Epoch: 6| Step: 6
Training loss: 0.11250034371959312
Validation loss: 2.370440265577551

Epoch: 6| Step: 7
Training loss: 0.2015005778039358
Validation loss: 2.3779969016321214

Epoch: 6| Step: 8
Training loss: 0.23477474931196385
Validation loss: 2.3783009586142425

Epoch: 6| Step: 9
Training loss: 0.20893089109164747
Validation loss: 2.383324839521413

Epoch: 6| Step: 10
Training loss: 0.20086668067266703
Validation loss: 2.4059286298481593

Epoch: 6| Step: 11
Training loss: 0.3592221722931386
Validation loss: 2.4113361242006905

Epoch: 6| Step: 12
Training loss: 0.15381897785313575
Validation loss: 2.4083211098921495

Epoch: 6| Step: 13
Training loss: 0.21346689675271757
Validation loss: 2.3755334493588496

Epoch: 365| Step: 0
Training loss: 0.18856694717650477
Validation loss: 2.3681727439417624

Epoch: 6| Step: 1
Training loss: 0.22294686408518427
Validation loss: 2.3617812573930697

Epoch: 6| Step: 2
Training loss: 0.13728130950075454
Validation loss: 2.360932990040444

Epoch: 6| Step: 3
Training loss: 0.25961768447843564
Validation loss: 2.351734574121508

Epoch: 6| Step: 4
Training loss: 0.20468590786729648
Validation loss: 2.3644112340080445

Epoch: 6| Step: 5
Training loss: 0.22152738338609412
Validation loss: 2.416040675382016

Epoch: 6| Step: 6
Training loss: 0.18482026830517
Validation loss: 2.3994737522764655

Epoch: 6| Step: 7
Training loss: 0.33289491859716364
Validation loss: 2.4229228081525407

Epoch: 6| Step: 8
Training loss: 0.19568097642145166
Validation loss: 2.4322172090587753

Epoch: 6| Step: 9
Training loss: 0.340397723082123
Validation loss: 2.4230481437391775

Epoch: 6| Step: 10
Training loss: 0.31977426852304464
Validation loss: 2.4289672414961307

Epoch: 6| Step: 11
Training loss: 0.2755970823547384
Validation loss: 2.412976006218317

Epoch: 6| Step: 12
Training loss: 0.18125462279508311
Validation loss: 2.4222874719213623

Epoch: 6| Step: 13
Training loss: 0.11707949827303421
Validation loss: 2.4015353322182897

Epoch: 366| Step: 0
Training loss: 0.1746780693480506
Validation loss: 2.3700563697866275

Epoch: 6| Step: 1
Training loss: 0.3989352875304095
Validation loss: 2.3925510588289667

Epoch: 6| Step: 2
Training loss: 0.16221669103439743
Validation loss: 2.379977872491783

Epoch: 6| Step: 3
Training loss: 0.218309000513602
Validation loss: 2.365585889441639

Epoch: 6| Step: 4
Training loss: 0.28101312410855367
Validation loss: 2.370850455370451

Epoch: 6| Step: 5
Training loss: 0.25212558492082976
Validation loss: 2.3409305362960686

Epoch: 6| Step: 6
Training loss: 0.1741015555416223
Validation loss: 2.37382567020529

Epoch: 6| Step: 7
Training loss: 0.2504519609141869
Validation loss: 2.3759553042626274

Epoch: 6| Step: 8
Training loss: 0.16460388413420182
Validation loss: 2.375868410237756

Epoch: 6| Step: 9
Training loss: 0.1511225908361897
Validation loss: 2.378921873793448

Epoch: 6| Step: 10
Training loss: 0.2954950888366003
Validation loss: 2.385632719888267

Epoch: 6| Step: 11
Training loss: 0.21585075025693176
Validation loss: 2.359856492630718

Epoch: 6| Step: 12
Training loss: 0.2334032417345592
Validation loss: 2.371151141878874

Epoch: 6| Step: 13
Training loss: 0.1541128630658676
Validation loss: 2.3902807350432203

Epoch: 367| Step: 0
Training loss: 0.1385454420839695
Validation loss: 2.375301164963045

Epoch: 6| Step: 1
Training loss: 0.2854936771962024
Validation loss: 2.3701331104371546

Epoch: 6| Step: 2
Training loss: 0.30404234096981547
Validation loss: 2.360749411359689

Epoch: 6| Step: 3
Training loss: 0.30533262571068215
Validation loss: 2.3467443211304158

Epoch: 6| Step: 4
Training loss: 0.16816647668538864
Validation loss: 2.3582131248816705

Epoch: 6| Step: 5
Training loss: 0.22556887805722953
Validation loss: 2.354537221058929

Epoch: 6| Step: 6
Training loss: 0.2034867440084107
Validation loss: 2.3441655841299065

Epoch: 6| Step: 7
Training loss: 0.15212315703163515
Validation loss: 2.3376069799920565

Epoch: 6| Step: 8
Training loss: 0.21161499542758283
Validation loss: 2.3673391576174887

Epoch: 6| Step: 9
Training loss: 0.142868823426487
Validation loss: 2.392884084573393

Epoch: 6| Step: 10
Training loss: 0.12777730733573506
Validation loss: 2.364010030715636

Epoch: 6| Step: 11
Training loss: 0.33331969973379183
Validation loss: 2.378546488566794

Epoch: 6| Step: 12
Training loss: 0.1723900414893237
Validation loss: 2.400470377304582

Epoch: 6| Step: 13
Training loss: 0.3225158413611437
Validation loss: 2.3975370586786555

Epoch: 368| Step: 0
Training loss: 0.14776222447631915
Validation loss: 2.3931128355462508

Epoch: 6| Step: 1
Training loss: 0.23149511549896648
Validation loss: 2.401347862171596

Epoch: 6| Step: 2
Training loss: 0.11546410275090563
Validation loss: 2.3789714494000385

Epoch: 6| Step: 3
Training loss: 0.16043080080814986
Validation loss: 2.395553239354936

Epoch: 6| Step: 4
Training loss: 0.30551709429150997
Validation loss: 2.4069549093765383

Epoch: 6| Step: 5
Training loss: 0.29485111777232975
Validation loss: 2.394174399696245

Epoch: 6| Step: 6
Training loss: 0.20079973670072598
Validation loss: 2.361000281943278

Epoch: 6| Step: 7
Training loss: 0.12688697411966804
Validation loss: 2.3729774917674455

Epoch: 6| Step: 8
Training loss: 0.21763276145258806
Validation loss: 2.350184796794745

Epoch: 6| Step: 9
Training loss: 0.3282060296053393
Validation loss: 2.362130144819489

Epoch: 6| Step: 10
Training loss: 0.13915223216200207
Validation loss: 2.361615542777248

Epoch: 6| Step: 11
Training loss: 0.17975573695316396
Validation loss: 2.366117157662937

Epoch: 6| Step: 12
Training loss: 0.26304627128692676
Validation loss: 2.342881291779505

Epoch: 6| Step: 13
Training loss: 0.28562486368923146
Validation loss: 2.358548703199776

Epoch: 369| Step: 0
Training loss: 0.21256083571318907
Validation loss: 2.3415002625879793

Epoch: 6| Step: 1
Training loss: 0.10023451032800378
Validation loss: 2.350494007924501

Epoch: 6| Step: 2
Training loss: 0.22963284179502502
Validation loss: 2.353293590669638

Epoch: 6| Step: 3
Training loss: 0.1625508421443385
Validation loss: 2.347099455070039

Epoch: 6| Step: 4
Training loss: 0.23074862894651077
Validation loss: 2.3601341924897223

Epoch: 6| Step: 5
Training loss: 0.1899827162040141
Validation loss: 2.3552262403420388

Epoch: 6| Step: 6
Training loss: 0.12352642209384408
Validation loss: 2.3503067576971275

Epoch: 6| Step: 7
Training loss: 0.09658133195058843
Validation loss: 2.381734612900752

Epoch: 6| Step: 8
Training loss: 0.24484554756298307
Validation loss: 2.3884255354637083

Epoch: 6| Step: 9
Training loss: 0.2838519851647406
Validation loss: 2.35767218953255

Epoch: 6| Step: 10
Training loss: 0.3085732634299179
Validation loss: 2.373631291833195

Epoch: 6| Step: 11
Training loss: 0.2920462771938141
Validation loss: 2.354901487588565

Epoch: 6| Step: 12
Training loss: 0.18066668121914375
Validation loss: 2.3541976189073646

Epoch: 6| Step: 13
Training loss: 0.2763360211487458
Validation loss: 2.3667532656139967

Epoch: 370| Step: 0
Training loss: 0.20304171982400554
Validation loss: 2.345831007196684

Epoch: 6| Step: 1
Training loss: 0.3644819209425479
Validation loss: 2.3544047376206443

Epoch: 6| Step: 2
Training loss: 0.17131862754955177
Validation loss: 2.3494169595453758

Epoch: 6| Step: 3
Training loss: 0.20486705453965323
Validation loss: 2.351532967764624

Epoch: 6| Step: 4
Training loss: 0.19393742018024007
Validation loss: 2.357957127751904

Epoch: 6| Step: 5
Training loss: 0.11898939509080377
Validation loss: 2.3749825385746566

Epoch: 6| Step: 6
Training loss: 0.2402557735682212
Validation loss: 2.3858553528754296

Epoch: 6| Step: 7
Training loss: 0.2600822097077116
Validation loss: 2.3909167136485134

Epoch: 6| Step: 8
Training loss: 0.21652758257657753
Validation loss: 2.3906819401597375

Epoch: 6| Step: 9
Training loss: 0.3984625191406682
Validation loss: 2.402994213788242

Epoch: 6| Step: 10
Training loss: 0.0973804680625851
Validation loss: 2.3890598285166256

Epoch: 6| Step: 11
Training loss: 0.22623447810192487
Validation loss: 2.429906173355015

Epoch: 6| Step: 12
Training loss: 0.12817131403319312
Validation loss: 2.4098691748231675

Epoch: 6| Step: 13
Training loss: 0.25285657908653497
Validation loss: 2.399697861957454

Epoch: 371| Step: 0
Training loss: 0.12981223576628562
Validation loss: 2.3861784353866597

Epoch: 6| Step: 1
Training loss: 0.29552032686247715
Validation loss: 2.3726733744053

Epoch: 6| Step: 2
Training loss: 0.12557216171244448
Validation loss: 2.366830015336948

Epoch: 6| Step: 3
Training loss: 0.1331586324379713
Validation loss: 2.3875577089310127

Epoch: 6| Step: 4
Training loss: 0.37960852598357187
Validation loss: 2.3589551215616584

Epoch: 6| Step: 5
Training loss: 0.32247799898109464
Validation loss: 2.3576490269998236

Epoch: 6| Step: 6
Training loss: 0.18711637949724294
Validation loss: 2.3734116929157127

Epoch: 6| Step: 7
Training loss: 0.18409190670004283
Validation loss: 2.362861143471927

Epoch: 6| Step: 8
Training loss: 0.24304547156502282
Validation loss: 2.335864079745177

Epoch: 6| Step: 9
Training loss: 0.17355176838633554
Validation loss: 2.362488214233676

Epoch: 6| Step: 10
Training loss: 0.2023153491321905
Validation loss: 2.350341791830271

Epoch: 6| Step: 11
Training loss: 0.1177875652664645
Validation loss: 2.3632401180323614

Epoch: 6| Step: 12
Training loss: 0.09175018381144538
Validation loss: 2.3601130218375435

Epoch: 6| Step: 13
Training loss: 0.24138848723951983
Validation loss: 2.3640957963477165

Epoch: 372| Step: 0
Training loss: 0.2269207407683917
Validation loss: 2.381333673434821

Epoch: 6| Step: 1
Training loss: 0.26208422180554836
Validation loss: 2.398795748820836

Epoch: 6| Step: 2
Training loss: 0.17535485899119582
Validation loss: 2.3854028837783154

Epoch: 6| Step: 3
Training loss: 0.31744392393551707
Validation loss: 2.403702498466987

Epoch: 6| Step: 4
Training loss: 0.17961683127584588
Validation loss: 2.3710814317887823

Epoch: 6| Step: 5
Training loss: 0.11511495026898823
Validation loss: 2.3767562335587487

Epoch: 6| Step: 6
Training loss: 0.1983735724976491
Validation loss: 2.3794560600182537

Epoch: 6| Step: 7
Training loss: 0.2604652677324974
Validation loss: 2.3685049828738474

Epoch: 6| Step: 8
Training loss: 0.18314106913033418
Validation loss: 2.347826242038198

Epoch: 6| Step: 9
Training loss: 0.20292853978321712
Validation loss: 2.3416847208236713

Epoch: 6| Step: 10
Training loss: 0.13427958399897902
Validation loss: 2.3428125455018614

Epoch: 6| Step: 11
Training loss: 0.27336760036220054
Validation loss: 2.3450464481796836

Epoch: 6| Step: 12
Training loss: 0.21683083517414087
Validation loss: 2.3464198956481477

Epoch: 6| Step: 13
Training loss: 0.10630536722966895
Validation loss: 2.3451442916400915

Epoch: 373| Step: 0
Training loss: 0.22030130452597957
Validation loss: 2.402307433300636

Epoch: 6| Step: 1
Training loss: 0.15114127497521937
Validation loss: 2.390416389771941

Epoch: 6| Step: 2
Training loss: 0.2305738241900058
Validation loss: 2.3916014435152486

Epoch: 6| Step: 3
Training loss: 0.27814419176557637
Validation loss: 2.34824435402136

Epoch: 6| Step: 4
Training loss: 0.18255921325872326
Validation loss: 2.3519476115739124

Epoch: 6| Step: 5
Training loss: 0.2683500168902522
Validation loss: 2.3500979186031565

Epoch: 6| Step: 6
Training loss: 0.1818041731710053
Validation loss: 2.34038963142667

Epoch: 6| Step: 7
Training loss: 0.07988676898457248
Validation loss: 2.3464303925427394

Epoch: 6| Step: 8
Training loss: 0.13182938877371225
Validation loss: 2.346698276631064

Epoch: 6| Step: 9
Training loss: 0.3314846476298193
Validation loss: 2.359470829725169

Epoch: 6| Step: 10
Training loss: 0.27528187112676444
Validation loss: 2.331074606578284

Epoch: 6| Step: 11
Training loss: 0.17282658197100229
Validation loss: 2.367616470875065

Epoch: 6| Step: 12
Training loss: 0.1855215356489707
Validation loss: 2.3517370813646226

Epoch: 6| Step: 13
Training loss: 0.16721674672229445
Validation loss: 2.3659111358049922

Epoch: 374| Step: 0
Training loss: 0.27490462036274227
Validation loss: 2.4078806857293613

Epoch: 6| Step: 1
Training loss: 0.2010053482423537
Validation loss: 2.3908509167748573

Epoch: 6| Step: 2
Training loss: 0.1471046412755231
Validation loss: 2.3835930669915877

Epoch: 6| Step: 3
Training loss: 0.34302574500953914
Validation loss: 2.427120648035239

Epoch: 6| Step: 4
Training loss: 0.12306498591032193
Validation loss: 2.429860183070777

Epoch: 6| Step: 5
Training loss: 0.16826085263658672
Validation loss: 2.4022451072868103

Epoch: 6| Step: 6
Training loss: 0.17257541753666464
Validation loss: 2.3847557526493333

Epoch: 6| Step: 7
Training loss: 0.16211761315796203
Validation loss: 2.3728658373726317

Epoch: 6| Step: 8
Training loss: 0.12816507945402822
Validation loss: 2.3746395690336066

Epoch: 6| Step: 9
Training loss: 0.0967161081088847
Validation loss: 2.3679727671705506

Epoch: 6| Step: 10
Training loss: 0.2185496962917411
Validation loss: 2.3636071638311837

Epoch: 6| Step: 11
Training loss: 0.3056196966666761
Validation loss: 2.3902270533913432

Epoch: 6| Step: 12
Training loss: 0.2383883657614046
Validation loss: 2.3470286291935722

Epoch: 6| Step: 13
Training loss: 0.19677682313305916
Validation loss: 2.374121482422986

Epoch: 375| Step: 0
Training loss: 0.11829073870404516
Validation loss: 2.369533370765653

Epoch: 6| Step: 1
Training loss: 0.21242538853300355
Validation loss: 2.3404796445077642

Epoch: 6| Step: 2
Training loss: 0.319030066942444
Validation loss: 2.3444914117528612

Epoch: 6| Step: 3
Training loss: 0.3002420273658528
Validation loss: 2.3490975074983003

Epoch: 6| Step: 4
Training loss: 0.2408918208052798
Validation loss: 2.3386337112702886

Epoch: 6| Step: 5
Training loss: 0.25845636538801237
Validation loss: 2.3411010643368813

Epoch: 6| Step: 6
Training loss: 0.23956996251542062
Validation loss: 2.3485301077874547

Epoch: 6| Step: 7
Training loss: 0.33906441701180107
Validation loss: 2.374234832403732

Epoch: 6| Step: 8
Training loss: 0.1809266115776502
Validation loss: 2.3670347458152494

Epoch: 6| Step: 9
Training loss: 0.17560394669998458
Validation loss: 2.390366211772057

Epoch: 6| Step: 10
Training loss: 0.16254213318769634
Validation loss: 2.368270101757966

Epoch: 6| Step: 11
Training loss: 0.13902176785518197
Validation loss: 2.39363678069754

Epoch: 6| Step: 12
Training loss: 0.2013684395752099
Validation loss: 2.399775372524644

Epoch: 6| Step: 13
Training loss: 0.1262549127080858
Validation loss: 2.3909210658736697

Epoch: 376| Step: 0
Training loss: 0.11823972139915333
Validation loss: 2.347833210667291

Epoch: 6| Step: 1
Training loss: 0.26914939921434455
Validation loss: 2.3764188648386506

Epoch: 6| Step: 2
Training loss: 0.12454097254550535
Validation loss: 2.3507159544295173

Epoch: 6| Step: 3
Training loss: 0.14492408102983595
Validation loss: 2.322097485071112

Epoch: 6| Step: 4
Training loss: 0.2649998039118923
Validation loss: 2.3241745166011163

Epoch: 6| Step: 5
Training loss: 0.28773680398761486
Validation loss: 2.339427998645202

Epoch: 6| Step: 6
Training loss: 0.19319643032940395
Validation loss: 2.3475976044992644

Epoch: 6| Step: 7
Training loss: 0.20229138282149647
Validation loss: 2.302360027676632

Epoch: 6| Step: 8
Training loss: 0.30700246758509964
Validation loss: 2.3270651241041045

Epoch: 6| Step: 9
Training loss: 0.1908311475725086
Validation loss: 2.3329037089146105

Epoch: 6| Step: 10
Training loss: 0.1579108186895457
Validation loss: 2.358436739640329

Epoch: 6| Step: 11
Training loss: 0.24992432044866866
Validation loss: 2.3854972423445595

Epoch: 6| Step: 12
Training loss: 0.31407188619755183
Validation loss: 2.3809031130414815

Epoch: 6| Step: 13
Training loss: 0.1523454861664266
Validation loss: 2.3905256640665598

Epoch: 377| Step: 0
Training loss: 0.19751608405834295
Validation loss: 2.3440130303566775

Epoch: 6| Step: 1
Training loss: 0.20574791838901194
Validation loss: 2.4024836364351363

Epoch: 6| Step: 2
Training loss: 0.27176345915834127
Validation loss: 2.386255320963129

Epoch: 6| Step: 3
Training loss: 0.10438993834623862
Validation loss: 2.403637254770962

Epoch: 6| Step: 4
Training loss: 0.17660324968334928
Validation loss: 2.443877579835069

Epoch: 6| Step: 5
Training loss: 0.147833385383209
Validation loss: 2.3676354445962766

Epoch: 6| Step: 6
Training loss: 0.1198712754749941
Validation loss: 2.400139289919183

Epoch: 6| Step: 7
Training loss: 0.42579132908081885
Validation loss: 2.3816260385883954

Epoch: 6| Step: 8
Training loss: 0.1614871608215161
Validation loss: 2.3589348108377868

Epoch: 6| Step: 9
Training loss: 0.20742930526499911
Validation loss: 2.371137815219635

Epoch: 6| Step: 10
Training loss: 0.08630837801517649
Validation loss: 2.3463181927026167

Epoch: 6| Step: 11
Training loss: 0.2952440283378953
Validation loss: 2.334381973904789

Epoch: 6| Step: 12
Training loss: 0.14982206450221341
Validation loss: 2.3649371476354637

Epoch: 6| Step: 13
Training loss: 0.12266873353859965
Validation loss: 2.3242004476536513

Epoch: 378| Step: 0
Training loss: 0.34574114057067545
Validation loss: 2.292828965605045

Epoch: 6| Step: 1
Training loss: 0.2475486467458527
Validation loss: 2.3399877989213986

Epoch: 6| Step: 2
Training loss: 0.12800978562734996
Validation loss: 2.3040816472756696

Epoch: 6| Step: 3
Training loss: 0.28001877383321055
Validation loss: 2.357683927020942

Epoch: 6| Step: 4
Training loss: 0.1116833832587265
Validation loss: 2.373460934823081

Epoch: 6| Step: 5
Training loss: 0.1663819814724751
Validation loss: 2.364388204718694

Epoch: 6| Step: 6
Training loss: 0.12885517495680077
Validation loss: 2.3665092430925765

Epoch: 6| Step: 7
Training loss: 0.16410981358899288
Validation loss: 2.3429033966732384

Epoch: 6| Step: 8
Training loss: 0.22869884449223205
Validation loss: 2.350653342384714

Epoch: 6| Step: 9
Training loss: 0.11842578088912815
Validation loss: 2.3755111673167004

Epoch: 6| Step: 10
Training loss: 0.20189413946910278
Validation loss: 2.345968861760237

Epoch: 6| Step: 11
Training loss: 0.21471645745741447
Validation loss: 2.366519696919268

Epoch: 6| Step: 12
Training loss: 0.12286279927158185
Validation loss: 2.3233536270163238

Epoch: 6| Step: 13
Training loss: 0.3275201991091092
Validation loss: 2.3610044265457972

Epoch: 379| Step: 0
Training loss: 0.2714091683924283
Validation loss: 2.335244342376578

Epoch: 6| Step: 1
Training loss: 0.11439310117573091
Validation loss: 2.377023899942706

Epoch: 6| Step: 2
Training loss: 0.31567668397206106
Validation loss: 2.347022430974337

Epoch: 6| Step: 3
Training loss: 0.1886914071344759
Validation loss: 2.3640647479617036

Epoch: 6| Step: 4
Training loss: 0.21293296742856702
Validation loss: 2.36925382482086

Epoch: 6| Step: 5
Training loss: 0.11453364163538884
Validation loss: 2.357396617138006

Epoch: 6| Step: 6
Training loss: 0.1301356486265476
Validation loss: 2.3440958469315154

Epoch: 6| Step: 7
Training loss: 0.16042383449402145
Validation loss: 2.390482848502244

Epoch: 6| Step: 8
Training loss: 0.17149774373283044
Validation loss: 2.403370754451306

Epoch: 6| Step: 9
Training loss: 0.31154925439699765
Validation loss: 2.404168852533201

Epoch: 6| Step: 10
Training loss: 0.23828777710776883
Validation loss: 2.4213051291229006

Epoch: 6| Step: 11
Training loss: 0.13093345594875444
Validation loss: 2.3830757252591424

Epoch: 6| Step: 12
Training loss: 0.23658338270649312
Validation loss: 2.397471553634545

Epoch: 6| Step: 13
Training loss: 0.19724889249937946
Validation loss: 2.374631799740845

Epoch: 380| Step: 0
Training loss: 0.2006679073987932
Validation loss: 2.3978952046817477

Epoch: 6| Step: 1
Training loss: 0.1787721497810609
Validation loss: 2.3901752362776123

Epoch: 6| Step: 2
Training loss: 0.1491818462294546
Validation loss: 2.37117181610822

Epoch: 6| Step: 3
Training loss: 0.2351639502395702
Validation loss: 2.3697105371290044

Epoch: 6| Step: 4
Training loss: 0.16576770334327925
Validation loss: 2.348235676690019

Epoch: 6| Step: 5
Training loss: 0.26983273272175556
Validation loss: 2.3725375615173467

Epoch: 6| Step: 6
Training loss: 0.15215209985911168
Validation loss: 2.392309966739922

Epoch: 6| Step: 7
Training loss: 0.218690114679702
Validation loss: 2.3951494208269275

Epoch: 6| Step: 8
Training loss: 0.2662527996014546
Validation loss: 2.416435647204554

Epoch: 6| Step: 9
Training loss: 0.20295983715618834
Validation loss: 2.3874534154409415

Epoch: 6| Step: 10
Training loss: 0.27216704730811037
Validation loss: 2.4090221030981804

Epoch: 6| Step: 11
Training loss: 0.27436024419778404
Validation loss: 2.4393500119382376

Epoch: 6| Step: 12
Training loss: 0.2603594081237402
Validation loss: 2.401055530261339

Epoch: 6| Step: 13
Training loss: 0.16505256575019067
Validation loss: 2.371937867509209

Epoch: 381| Step: 0
Training loss: 0.23010638408332157
Validation loss: 2.3677232010867955

Epoch: 6| Step: 1
Training loss: 0.2152930070803848
Validation loss: 2.3855637607413325

Epoch: 6| Step: 2
Training loss: 0.2678987851016729
Validation loss: 2.354837776231096

Epoch: 6| Step: 3
Training loss: 0.15339415891784244
Validation loss: 2.3437986252638905

Epoch: 6| Step: 4
Training loss: 0.1803425789575097
Validation loss: 2.367155943624031

Epoch: 6| Step: 5
Training loss: 0.16804823547231112
Validation loss: 2.3690007089359204

Epoch: 6| Step: 6
Training loss: 0.19058182336831528
Validation loss: 2.3896165592510576

Epoch: 6| Step: 7
Training loss: 0.3106223800326101
Validation loss: 2.3777201391892224

Epoch: 6| Step: 8
Training loss: 0.1654806605763122
Validation loss: 2.415418773339868

Epoch: 6| Step: 9
Training loss: 0.2566399787650834
Validation loss: 2.4060491236461257

Epoch: 6| Step: 10
Training loss: 0.32357743042041426
Validation loss: 2.3736487064965903

Epoch: 6| Step: 11
Training loss: 0.1776146957393824
Validation loss: 2.3790910455981087

Epoch: 6| Step: 12
Training loss: 0.308956560698706
Validation loss: 2.3689659810465042

Epoch: 6| Step: 13
Training loss: 0.1103065660612433
Validation loss: 2.344190794262908

Epoch: 382| Step: 0
Training loss: 0.18026708341664727
Validation loss: 2.3620680730229786

Epoch: 6| Step: 1
Training loss: 0.16726601887014697
Validation loss: 2.384221616744023

Epoch: 6| Step: 2
Training loss: 0.23443621789616756
Validation loss: 2.395548710406363

Epoch: 6| Step: 3
Training loss: 0.2955201503802693
Validation loss: 2.3802698193449534

Epoch: 6| Step: 4
Training loss: 0.23282053760760765
Validation loss: 2.363483347836926

Epoch: 6| Step: 5
Training loss: 0.3023746198720384
Validation loss: 2.392319076540847

Epoch: 6| Step: 6
Training loss: 0.3130021590609322
Validation loss: 2.387422150558868

Epoch: 6| Step: 7
Training loss: 0.09309146979921012
Validation loss: 2.347221827492322

Epoch: 6| Step: 8
Training loss: 0.20817741679060775
Validation loss: 2.3793852733800986

Epoch: 6| Step: 9
Training loss: 0.13110362928445957
Validation loss: 2.3668184916369177

Epoch: 6| Step: 10
Training loss: 0.13352943902513992
Validation loss: 2.3530713409148367

Epoch: 6| Step: 11
Training loss: 0.1594420184613336
Validation loss: 2.354863732152049

Epoch: 6| Step: 12
Training loss: 0.2150509268859777
Validation loss: 2.3693904258916247

Epoch: 6| Step: 13
Training loss: 0.14601818287600546
Validation loss: 2.3945349543533

Epoch: 383| Step: 0
Training loss: 0.12638274219419254
Validation loss: 2.387871682918373

Epoch: 6| Step: 1
Training loss: 0.2508259629410835
Validation loss: 2.3679232211288586

Epoch: 6| Step: 2
Training loss: 0.3148457936488007
Validation loss: 2.359604490023414

Epoch: 6| Step: 3
Training loss: 0.2921882277494945
Validation loss: 2.3256275281276646

Epoch: 6| Step: 4
Training loss: 0.19399611315815374
Validation loss: 2.3659128738576207

Epoch: 6| Step: 5
Training loss: 0.18791257646772647
Validation loss: 2.340682858960445

Epoch: 6| Step: 6
Training loss: 0.1879156393423426
Validation loss: 2.331304580861981

Epoch: 6| Step: 7
Training loss: 0.09671342627089277
Validation loss: 2.327573250717078

Epoch: 6| Step: 8
Training loss: 0.14851515395136444
Validation loss: 2.344837042186714

Epoch: 6| Step: 9
Training loss: 0.27904854251519906
Validation loss: 2.356340853955401

Epoch: 6| Step: 10
Training loss: 0.1841392832801436
Validation loss: 2.3354451808286636

Epoch: 6| Step: 11
Training loss: 0.1395938539869691
Validation loss: 2.3960657985167817

Epoch: 6| Step: 12
Training loss: 0.1583737348210172
Validation loss: 2.3928454593179316

Epoch: 6| Step: 13
Training loss: 0.1333828069373745
Validation loss: 2.3952959874993014

Epoch: 384| Step: 0
Training loss: 0.2652451520030937
Validation loss: 2.4164043265735167

Epoch: 6| Step: 1
Training loss: 0.15546706261030618
Validation loss: 2.41283148092282

Epoch: 6| Step: 2
Training loss: 0.23946183517072242
Validation loss: 2.429972558797743

Epoch: 6| Step: 3
Training loss: 0.09373941461089617
Validation loss: 2.413334223549873

Epoch: 6| Step: 4
Training loss: 0.2561250283049032
Validation loss: 2.395686513103527

Epoch: 6| Step: 5
Training loss: 0.15898321465296097
Validation loss: 2.4002541091774248

Epoch: 6| Step: 6
Training loss: 0.21153739115304168
Validation loss: 2.3880791327508026

Epoch: 6| Step: 7
Training loss: 0.2521157737749746
Validation loss: 2.396565494955747

Epoch: 6| Step: 8
Training loss: 0.10014325010674519
Validation loss: 2.3807000979940565

Epoch: 6| Step: 9
Training loss: 0.1423645771840051
Validation loss: 2.4045702906412982

Epoch: 6| Step: 10
Training loss: 0.23157481501853067
Validation loss: 2.3957841733478524

Epoch: 6| Step: 11
Training loss: 0.11197976918021463
Validation loss: 2.3832975472516473

Epoch: 6| Step: 12
Training loss: 0.14395052642903228
Validation loss: 2.4035356093017217

Epoch: 6| Step: 13
Training loss: 0.1867277813566774
Validation loss: 2.3957697071188937

Epoch: 385| Step: 0
Training loss: 0.17404668975883233
Validation loss: 2.3902576949070773

Epoch: 6| Step: 1
Training loss: 0.12535188736105263
Validation loss: 2.3891032919554753

Epoch: 6| Step: 2
Training loss: 0.2006314806322265
Validation loss: 2.389680422066935

Epoch: 6| Step: 3
Training loss: 0.183210652975514
Validation loss: 2.3821531618481058

Epoch: 6| Step: 4
Training loss: 0.12162298638748964
Validation loss: 2.3757915883138554

Epoch: 6| Step: 5
Training loss: 0.09575370016648914
Validation loss: 2.3913420651958535

Epoch: 6| Step: 6
Training loss: 0.12999049720511188
Validation loss: 2.3929155917285767

Epoch: 6| Step: 7
Training loss: 0.251812548195462
Validation loss: 2.3963374252710388

Epoch: 6| Step: 8
Training loss: 0.21235990429160329
Validation loss: 2.4088024238720744

Epoch: 6| Step: 9
Training loss: 0.18336234829429776
Validation loss: 2.390820933738927

Epoch: 6| Step: 10
Training loss: 0.2768923349744767
Validation loss: 2.405712786868281

Epoch: 6| Step: 11
Training loss: 0.26662784488785907
Validation loss: 2.365468201745762

Epoch: 6| Step: 12
Training loss: 0.25235205125883914
Validation loss: 2.36950728098262

Epoch: 6| Step: 13
Training loss: 0.1667310893203608
Validation loss: 2.377684504651534

Epoch: 386| Step: 0
Training loss: 0.1430749337320676
Validation loss: 2.3712028087346027

Epoch: 6| Step: 1
Training loss: 0.1314568827667953
Validation loss: 2.372868951078998

Epoch: 6| Step: 2
Training loss: 0.17838748991009737
Validation loss: 2.364570829781162

Epoch: 6| Step: 3
Training loss: 0.2537838127129908
Validation loss: 2.346543159497532

Epoch: 6| Step: 4
Training loss: 0.15157320707392663
Validation loss: 2.3604442534400305

Epoch: 6| Step: 5
Training loss: 0.21269989218917612
Validation loss: 2.3518637830499634

Epoch: 6| Step: 6
Training loss: 0.1504260182533714
Validation loss: 2.3886163594568703

Epoch: 6| Step: 7
Training loss: 0.17201931811573157
Validation loss: 2.3812026851829176

Epoch: 6| Step: 8
Training loss: 0.15199005198001758
Validation loss: 2.393138993575521

Epoch: 6| Step: 9
Training loss: 0.1983201291810579
Validation loss: 2.373367478183925

Epoch: 6| Step: 10
Training loss: 0.108946706729419
Validation loss: 2.3662079645468235

Epoch: 6| Step: 11
Training loss: 0.28626772723631855
Validation loss: 2.356002808838679

Epoch: 6| Step: 12
Training loss: 0.2004459672768407
Validation loss: 2.3409907910767633

Epoch: 6| Step: 13
Training loss: 0.35866081757514984
Validation loss: 2.344243707101286

Epoch: 387| Step: 0
Training loss: 0.21305268794859436
Validation loss: 2.3607970593676804

Epoch: 6| Step: 1
Training loss: 0.2207122648929118
Validation loss: 2.38061423650942

Epoch: 6| Step: 2
Training loss: 0.168487159135724
Validation loss: 2.3717456794532117

Epoch: 6| Step: 3
Training loss: 0.12983563649136748
Validation loss: 2.390483605642168

Epoch: 6| Step: 4
Training loss: 0.30007134920279976
Validation loss: 2.37863537888197

Epoch: 6| Step: 5
Training loss: 0.28414835544125716
Validation loss: 2.3817488145559316

Epoch: 6| Step: 6
Training loss: 0.2908690166489134
Validation loss: 2.390526307516742

Epoch: 6| Step: 7
Training loss: 0.144628698128622
Validation loss: 2.418869605369973

Epoch: 6| Step: 8
Training loss: 0.20431286765643414
Validation loss: 2.3935594665648594

Epoch: 6| Step: 9
Training loss: 0.14541963811514574
Validation loss: 2.3846786133906694

Epoch: 6| Step: 10
Training loss: 0.11363437302699068
Validation loss: 2.4050979551909593

Epoch: 6| Step: 11
Training loss: 0.1354990916168901
Validation loss: 2.39547262236198

Epoch: 6| Step: 12
Training loss: 0.17856813155264065
Validation loss: 2.3907903546652998

Epoch: 6| Step: 13
Training loss: 0.21733682425329132
Validation loss: 2.3399059785829883

Epoch: 388| Step: 0
Training loss: 0.1720399282000675
Validation loss: 2.3700015647955364

Epoch: 6| Step: 1
Training loss: 0.11007368074059085
Validation loss: 2.332003122166504

Epoch: 6| Step: 2
Training loss: 0.34414862148247694
Validation loss: 2.370869746525901

Epoch: 6| Step: 3
Training loss: 0.12976123741536275
Validation loss: 2.366020786654582

Epoch: 6| Step: 4
Training loss: 0.20302535327194363
Validation loss: 2.3623052865461176

Epoch: 6| Step: 5
Training loss: 0.17061743385880215
Validation loss: 2.359456550477994

Epoch: 6| Step: 6
Training loss: 0.18237504868640733
Validation loss: 2.387207320668178

Epoch: 6| Step: 7
Training loss: 0.10073704156531076
Validation loss: 2.3881677874059832

Epoch: 6| Step: 8
Training loss: 0.10048905123016189
Validation loss: 2.3853275210588207

Epoch: 6| Step: 9
Training loss: 0.20095452353712545
Validation loss: 2.4030325903036878

Epoch: 6| Step: 10
Training loss: 0.3083201052216631
Validation loss: 2.419193574733289

Epoch: 6| Step: 11
Training loss: 0.17843209071403082
Validation loss: 2.4003964445781736

Epoch: 6| Step: 12
Training loss: 0.17491652464766216
Validation loss: 2.395105968632095

Epoch: 6| Step: 13
Training loss: 0.15920024575248637
Validation loss: 2.4380759438815045

Epoch: 389| Step: 0
Training loss: 0.11439958563501168
Validation loss: 2.3895387357871196

Epoch: 6| Step: 1
Training loss: 0.22147120953003305
Validation loss: 2.3916252489231433

Epoch: 6| Step: 2
Training loss: 0.2290223689658639
Validation loss: 2.3890068555765898

Epoch: 6| Step: 3
Training loss: 0.3120245893566925
Validation loss: 2.4188537690290293

Epoch: 6| Step: 4
Training loss: 0.08833235626488177
Validation loss: 2.387177936221262

Epoch: 6| Step: 5
Training loss: 0.18101566227437946
Validation loss: 2.4207851015045665

Epoch: 6| Step: 6
Training loss: 0.2236174199166706
Validation loss: 2.4220021617054615

Epoch: 6| Step: 7
Training loss: 0.19797505387504066
Validation loss: 2.3885211055336044

Epoch: 6| Step: 8
Training loss: 0.1362090623779581
Validation loss: 2.3887915006746834

Epoch: 6| Step: 9
Training loss: 0.3371320710216799
Validation loss: 2.3783259982445024

Epoch: 6| Step: 10
Training loss: 0.1337089646862816
Validation loss: 2.4156678851178786

Epoch: 6| Step: 11
Training loss: 0.09415149151146865
Validation loss: 2.3781391623684125

Epoch: 6| Step: 12
Training loss: 0.08617140085050118
Validation loss: 2.3903481702998737

Epoch: 6| Step: 13
Training loss: 0.2950303718118252
Validation loss: 2.407013087204734

Epoch: 390| Step: 0
Training loss: 0.15028642785188742
Validation loss: 2.3961108873984074

Epoch: 6| Step: 1
Training loss: 0.28281356063138074
Validation loss: 2.3754861784166463

Epoch: 6| Step: 2
Training loss: 0.18772970473964826
Validation loss: 2.376520930636041

Epoch: 6| Step: 3
Training loss: 0.12155614523715666
Validation loss: 2.3899584779441865

Epoch: 6| Step: 4
Training loss: 0.07445264339291255
Validation loss: 2.356135139310731

Epoch: 6| Step: 5
Training loss: 0.1853053679549246
Validation loss: 2.352348172675938

Epoch: 6| Step: 6
Training loss: 0.11629788968454526
Validation loss: 2.3700528472957534

Epoch: 6| Step: 7
Training loss: 0.391205661260074
Validation loss: 2.380899522611406

Epoch: 6| Step: 8
Training loss: 0.124397779204602
Validation loss: 2.3837223762772495

Epoch: 6| Step: 9
Training loss: 0.17548500635384898
Validation loss: 2.388235203426499

Epoch: 6| Step: 10
Training loss: 0.07818294998502365
Validation loss: 2.3756635804259196

Epoch: 6| Step: 11
Training loss: 0.2583900686741201
Validation loss: 2.4209788251847777

Epoch: 6| Step: 12
Training loss: 0.207834198184637
Validation loss: 2.392317794891149

Epoch: 6| Step: 13
Training loss: 0.11615584373813588
Validation loss: 2.3991598885404217

Epoch: 391| Step: 0
Training loss: 0.27374172997284696
Validation loss: 2.3972962701864824

Epoch: 6| Step: 1
Training loss: 0.1367185728889408
Validation loss: 2.3895766401683063

Epoch: 6| Step: 2
Training loss: 0.23915339156989346
Validation loss: 2.3554471532140777

Epoch: 6| Step: 3
Training loss: 0.1679900399843263
Validation loss: 2.3932541217007466

Epoch: 6| Step: 4
Training loss: 0.19848325006742323
Validation loss: 2.361871313793027

Epoch: 6| Step: 5
Training loss: 0.14444665108260157
Validation loss: 2.396876952018691

Epoch: 6| Step: 6
Training loss: 0.17452364444810048
Validation loss: 2.3947169873512886

Epoch: 6| Step: 7
Training loss: 0.2784392521007825
Validation loss: 2.365073438704948

Epoch: 6| Step: 8
Training loss: 0.20780831382952175
Validation loss: 2.3932966659542756

Epoch: 6| Step: 9
Training loss: 0.14127821341982677
Validation loss: 2.3845421731733287

Epoch: 6| Step: 10
Training loss: 0.18287163617527175
Validation loss: 2.378992161274717

Epoch: 6| Step: 11
Training loss: 0.18932761134466536
Validation loss: 2.4005985617675605

Epoch: 6| Step: 12
Training loss: 0.21312421704872828
Validation loss: 2.36162677054552

Epoch: 6| Step: 13
Training loss: 0.13491477176719055
Validation loss: 2.362042026411661

Epoch: 392| Step: 0
Training loss: 0.24944717408491301
Validation loss: 2.36396240029393

Epoch: 6| Step: 1
Training loss: 0.24884012992800153
Validation loss: 2.335533383698383

Epoch: 6| Step: 2
Training loss: 0.166529656262108
Validation loss: 2.3783626013666352

Epoch: 6| Step: 3
Training loss: 0.13362719496422099
Validation loss: 2.367451119226535

Epoch: 6| Step: 4
Training loss: 0.24346178664525853
Validation loss: 2.376980231269038

Epoch: 6| Step: 5
Training loss: 0.23753204756900084
Validation loss: 2.3593199735115444

Epoch: 6| Step: 6
Training loss: 0.26257834968228133
Validation loss: 2.364171470437887

Epoch: 6| Step: 7
Training loss: 0.1934523792275579
Validation loss: 2.3754089426532605

Epoch: 6| Step: 8
Training loss: 0.2494661173795674
Validation loss: 2.3844721159493565

Epoch: 6| Step: 9
Training loss: 0.13825356831394914
Validation loss: 2.342544344005169

Epoch: 6| Step: 10
Training loss: 0.17214712902876278
Validation loss: 2.3359341439090535

Epoch: 6| Step: 11
Training loss: 0.15627892941645835
Validation loss: 2.3786061024819065

Epoch: 6| Step: 12
Training loss: 0.13135287476564037
Validation loss: 2.38269502298738

Epoch: 6| Step: 13
Training loss: 0.22804861357530298
Validation loss: 2.383635352935607

Epoch: 393| Step: 0
Training loss: 0.2560768368101064
Validation loss: 2.3766282528178713

Epoch: 6| Step: 1
Training loss: 0.19562386489575406
Validation loss: 2.3696189805733643

Epoch: 6| Step: 2
Training loss: 0.2598591686268833
Validation loss: 2.381085256331186

Epoch: 6| Step: 3
Training loss: 0.2720968349917609
Validation loss: 2.395677330498736

Epoch: 6| Step: 4
Training loss: 0.2446918825266179
Validation loss: 2.3742242138675866

Epoch: 6| Step: 5
Training loss: 0.15511866719393444
Validation loss: 2.3914226970798547

Epoch: 6| Step: 6
Training loss: 0.08945363286136569
Validation loss: 2.3711777419954414

Epoch: 6| Step: 7
Training loss: 0.18666286150816136
Validation loss: 2.3625636435805775

Epoch: 6| Step: 8
Training loss: 0.12240638247812176
Validation loss: 2.395487425356335

Epoch: 6| Step: 9
Training loss: 0.1506038244486903
Validation loss: 2.3680574490502493

Epoch: 6| Step: 10
Training loss: 0.14401957435072343
Validation loss: 2.356159054430217

Epoch: 6| Step: 11
Training loss: 0.15457592851541
Validation loss: 2.381264568259855

Epoch: 6| Step: 12
Training loss: 0.10057943749027008
Validation loss: 2.3887252610478833

Epoch: 6| Step: 13
Training loss: 0.20826975130361858
Validation loss: 2.3721261072014586

Epoch: 394| Step: 0
Training loss: 0.10056057397255727
Validation loss: 2.3720172184501798

Epoch: 6| Step: 1
Training loss: 0.17512858341602425
Validation loss: 2.398068073212827

Epoch: 6| Step: 2
Training loss: 0.12742590535921658
Validation loss: 2.368093591116619

Epoch: 6| Step: 3
Training loss: 0.13770624212080515
Validation loss: 2.42361712190315

Epoch: 6| Step: 4
Training loss: 0.09861493184639986
Validation loss: 2.381389557912069

Epoch: 6| Step: 5
Training loss: 0.15178792377374442
Validation loss: 2.369359622170672

Epoch: 6| Step: 6
Training loss: 0.25758827457904815
Validation loss: 2.368913607426669

Epoch: 6| Step: 7
Training loss: 0.3333460412980663
Validation loss: 2.359238224347489

Epoch: 6| Step: 8
Training loss: 0.2575206260383026
Validation loss: 2.387916530904629

Epoch: 6| Step: 9
Training loss: 0.13989899572328277
Validation loss: 2.3519862242291336

Epoch: 6| Step: 10
Training loss: 0.07147026548125748
Validation loss: 2.3685338088473746

Epoch: 6| Step: 11
Training loss: 0.22633053974184167
Validation loss: 2.36333349568981

Epoch: 6| Step: 12
Training loss: 0.10888370800560143
Validation loss: 2.347544026845283

Epoch: 6| Step: 13
Training loss: 0.19357964463530028
Validation loss: 2.3477905468713467

Epoch: 395| Step: 0
Training loss: 0.1268578171604437
Validation loss: 2.339143878091277

Epoch: 6| Step: 1
Training loss: 0.15979188083085583
Validation loss: 2.3788318076486

Epoch: 6| Step: 2
Training loss: 0.08031908858025076
Validation loss: 2.3509035210215843

Epoch: 6| Step: 3
Training loss: 0.21089645268932986
Validation loss: 2.3601330334856123

Epoch: 6| Step: 4
Training loss: 0.19210243125674714
Validation loss: 2.359540591112792

Epoch: 6| Step: 5
Training loss: 0.18285808891411942
Validation loss: 2.3967746502959444

Epoch: 6| Step: 6
Training loss: 0.2796309813608766
Validation loss: 2.3743494278331045

Epoch: 6| Step: 7
Training loss: 0.13670607916835642
Validation loss: 2.3739431660426495

Epoch: 6| Step: 8
Training loss: 0.2197843857021752
Validation loss: 2.3685661838008603

Epoch: 6| Step: 9
Training loss: 0.23883586188435532
Validation loss: 2.369026989074747

Epoch: 6| Step: 10
Training loss: 0.2800295762424023
Validation loss: 2.3432748626049813

Epoch: 6| Step: 11
Training loss: 0.13778963307993974
Validation loss: 2.3664494430663754

Epoch: 6| Step: 12
Training loss: 0.11416694092311543
Validation loss: 2.3533323364751872

Epoch: 6| Step: 13
Training loss: 0.19913162869605128
Validation loss: 2.3744958473079616

Epoch: 396| Step: 0
Training loss: 0.22629014449385224
Validation loss: 2.3527301656615873

Epoch: 6| Step: 1
Training loss: 0.2067267680036843
Validation loss: 2.349327090289583

Epoch: 6| Step: 2
Training loss: 0.13301789305769884
Validation loss: 2.353318903462599

Epoch: 6| Step: 3
Training loss: 0.2096499424200345
Validation loss: 2.363921155462284

Epoch: 6| Step: 4
Training loss: 0.2412765737954187
Validation loss: 2.352140101208951

Epoch: 6| Step: 5
Training loss: 0.11140734380423173
Validation loss: 2.367109531550948

Epoch: 6| Step: 6
Training loss: 0.0894551841215658
Validation loss: 2.350397739120373

Epoch: 6| Step: 7
Training loss: 0.2476627950675915
Validation loss: 2.381128810961441

Epoch: 6| Step: 8
Training loss: 0.14669096048773086
Validation loss: 2.3659637449222117

Epoch: 6| Step: 9
Training loss: 0.10524778708251863
Validation loss: 2.337334847934608

Epoch: 6| Step: 10
Training loss: 0.1550408426626149
Validation loss: 2.363360460405321

Epoch: 6| Step: 11
Training loss: 0.09316285870332144
Validation loss: 2.366443657005146

Epoch: 6| Step: 12
Training loss: 0.15391612456928816
Validation loss: 2.3650594957101307

Epoch: 6| Step: 13
Training loss: 0.3141627777910406
Validation loss: 2.388203919795697

Epoch: 397| Step: 0
Training loss: 0.1330348005656595
Validation loss: 2.40414998265945

Epoch: 6| Step: 1
Training loss: 0.3485733323420736
Validation loss: 2.3912910690624534

Epoch: 6| Step: 2
Training loss: 0.2124211094776879
Validation loss: 2.386216003691999

Epoch: 6| Step: 3
Training loss: 0.11903253326490422
Validation loss: 2.387681317602426

Epoch: 6| Step: 4
Training loss: 0.19428499790606035
Validation loss: 2.364670344270541

Epoch: 6| Step: 5
Training loss: 0.26685100804925294
Validation loss: 2.3549414675637936

Epoch: 6| Step: 6
Training loss: 0.2949066663445859
Validation loss: 2.324246609152795

Epoch: 6| Step: 7
Training loss: 0.11219733539120595
Validation loss: 2.332127847146551

Epoch: 6| Step: 8
Training loss: 0.12995509954055284
Validation loss: 2.3384113591093185

Epoch: 6| Step: 9
Training loss: 0.13904983430682463
Validation loss: 2.371535366362123

Epoch: 6| Step: 10
Training loss: 0.09382365730664319
Validation loss: 2.382339775469589

Epoch: 6| Step: 11
Training loss: 0.20793579538344337
Validation loss: 2.3647011315610458

Epoch: 6| Step: 12
Training loss: 0.11298370335568808
Validation loss: 2.3742491350671044

Epoch: 6| Step: 13
Training loss: 0.13129902049114736
Validation loss: 2.4093277500876322

Epoch: 398| Step: 0
Training loss: 0.1217085513236009
Validation loss: 2.4150463249585283

Epoch: 6| Step: 1
Training loss: 0.12381405314203567
Validation loss: 2.4239638906141665

Epoch: 6| Step: 2
Training loss: 0.1485591126735036
Validation loss: 2.431458232767027

Epoch: 6| Step: 3
Training loss: 0.20998975866469918
Validation loss: 2.3984262884968963

Epoch: 6| Step: 4
Training loss: 0.15886758854451713
Validation loss: 2.3814779750241803

Epoch: 6| Step: 5
Training loss: 0.19097356157603834
Validation loss: 2.357882084344288

Epoch: 6| Step: 6
Training loss: 0.1689352241988022
Validation loss: 2.362687993875279

Epoch: 6| Step: 7
Training loss: 0.2904646990259138
Validation loss: 2.334115490221361

Epoch: 6| Step: 8
Training loss: 0.2165227910169282
Validation loss: 2.341347119073864

Epoch: 6| Step: 9
Training loss: 0.17337895341696125
Validation loss: 2.3422422709989514

Epoch: 6| Step: 10
Training loss: 0.23001978673772558
Validation loss: 2.3374322031316663

Epoch: 6| Step: 11
Training loss: 0.22234763122623863
Validation loss: 2.3270467433417155

Epoch: 6| Step: 12
Training loss: 0.18316720557531277
Validation loss: 2.3581130964749533

Epoch: 6| Step: 13
Training loss: 0.14529519260046575
Validation loss: 2.359415953515099

Epoch: 399| Step: 0
Training loss: 0.19848833634415156
Validation loss: 2.352320168444824

Epoch: 6| Step: 1
Training loss: 0.14456037923747356
Validation loss: 2.353664196650317

Epoch: 6| Step: 2
Training loss: 0.10299787958807366
Validation loss: 2.385598007906092

Epoch: 6| Step: 3
Training loss: 0.10420591141605642
Validation loss: 2.3942025289937074

Epoch: 6| Step: 4
Training loss: 0.15308111812503483
Validation loss: 2.381539697013574

Epoch: 6| Step: 5
Training loss: 0.18041538960670755
Validation loss: 2.369588914969647

Epoch: 6| Step: 6
Training loss: 0.23333254087404376
Validation loss: 2.356396318283167

Epoch: 6| Step: 7
Training loss: 0.13899610788312944
Validation loss: 2.379224605216523

Epoch: 6| Step: 8
Training loss: 0.22253551890796286
Validation loss: 2.3549402112938935

Epoch: 6| Step: 9
Training loss: 0.2638170478445068
Validation loss: 2.355373333223287

Epoch: 6| Step: 10
Training loss: 0.23188451147236233
Validation loss: 2.374604786500719

Epoch: 6| Step: 11
Training loss: 0.12483258137141699
Validation loss: 2.3513151913721178

Epoch: 6| Step: 12
Training loss: 0.24291987586859645
Validation loss: 2.3523795397217193

Epoch: 6| Step: 13
Training loss: 0.2066380167113251
Validation loss: 2.3659863899307663

Epoch: 400| Step: 0
Training loss: 0.1512652207530629
Validation loss: 2.3658910787586445

Epoch: 6| Step: 1
Training loss: 0.20710774573941126
Validation loss: 2.3762120433992915

Epoch: 6| Step: 2
Training loss: 0.24737686619914862
Validation loss: 2.359688288003966

Epoch: 6| Step: 3
Training loss: 0.21308932524592117
Validation loss: 2.3924728630907346

Epoch: 6| Step: 4
Training loss: 0.14018206909287687
Validation loss: 2.392788999203654

Epoch: 6| Step: 5
Training loss: 0.16913309300767812
Validation loss: 2.369747170011736

Epoch: 6| Step: 6
Training loss: 0.11774102060614149
Validation loss: 2.3932663429275127

Epoch: 6| Step: 7
Training loss: 0.20614802700711246
Validation loss: 2.3494615437127053

Epoch: 6| Step: 8
Training loss: 0.17770857152069455
Validation loss: 2.382975843329047

Epoch: 6| Step: 9
Training loss: 0.07999551396346335
Validation loss: 2.3998396908807385

Epoch: 6| Step: 10
Training loss: 0.15410520019879156
Validation loss: 2.383167796456811

Epoch: 6| Step: 11
Training loss: 0.17533182335163788
Validation loss: 2.382465235976206

Epoch: 6| Step: 12
Training loss: 0.30043217603530475
Validation loss: 2.3495842230062816

Epoch: 6| Step: 13
Training loss: 0.1647340337096128
Validation loss: 2.382503659093682

Epoch: 401| Step: 0
Training loss: 0.12279639407829551
Validation loss: 2.359730410765714

Epoch: 6| Step: 1
Training loss: 0.18587579184044753
Validation loss: 2.3757957783311356

Epoch: 6| Step: 2
Training loss: 0.09704729475060486
Validation loss: 2.363722109101641

Epoch: 6| Step: 3
Training loss: 0.1224662691382412
Validation loss: 2.382919658239741

Epoch: 6| Step: 4
Training loss: 0.13962033796040496
Validation loss: 2.3631744726756967

Epoch: 6| Step: 5
Training loss: 0.2488872155492369
Validation loss: 2.3728885461595444

Epoch: 6| Step: 6
Training loss: 0.30209165457522347
Validation loss: 2.382675183618085

Epoch: 6| Step: 7
Training loss: 0.23069177763070087
Validation loss: 2.34908779682369

Epoch: 6| Step: 8
Training loss: 0.2472493951301196
Validation loss: 2.396721745184931

Epoch: 6| Step: 9
Training loss: 0.20667585422361948
Validation loss: 2.349659350859019

Epoch: 6| Step: 10
Training loss: 0.12013877891692909
Validation loss: 2.3778957530532248

Epoch: 6| Step: 11
Training loss: 0.14353435398302725
Validation loss: 2.3808247759387062

Epoch: 6| Step: 12
Training loss: 0.16882673964666822
Validation loss: 2.3820895707641947

Epoch: 6| Step: 13
Training loss: 0.2513089187298594
Validation loss: 2.4212685981309083

Epoch: 402| Step: 0
Training loss: 0.19760172133238954
Validation loss: 2.3809839057080557

Epoch: 6| Step: 1
Training loss: 0.08843464437329338
Validation loss: 2.385568561187829

Epoch: 6| Step: 2
Training loss: 0.25306415297481144
Validation loss: 2.372328024559108

Epoch: 6| Step: 3
Training loss: 0.1667201967006791
Validation loss: 2.3874735039532133

Epoch: 6| Step: 4
Training loss: 0.18487527670333406
Validation loss: 2.355954869633981

Epoch: 6| Step: 5
Training loss: 0.06405062056512738
Validation loss: 2.3450974461184853

Epoch: 6| Step: 6
Training loss: 0.31136925687665773
Validation loss: 2.330173779933973

Epoch: 6| Step: 7
Training loss: 0.2507067317114778
Validation loss: 2.345981713428306

Epoch: 6| Step: 8
Training loss: 0.14644520553784396
Validation loss: 2.339834560798272

Epoch: 6| Step: 9
Training loss: 0.18807039325373107
Validation loss: 2.3446422472789177

Epoch: 6| Step: 10
Training loss: 0.1482825725564774
Validation loss: 2.37633610454799

Epoch: 6| Step: 11
Training loss: 0.16266859643490453
Validation loss: 2.3638332724632556

Epoch: 6| Step: 12
Training loss: 0.1200840214167018
Validation loss: 2.3754991083571113

Epoch: 6| Step: 13
Training loss: 0.19281527520320188
Validation loss: 2.3776692662760746

Epoch: 403| Step: 0
Training loss: 0.13471355676297567
Validation loss: 2.4117624048648216

Epoch: 6| Step: 1
Training loss: 0.15206221707165257
Validation loss: 2.425340657335866

Epoch: 6| Step: 2
Training loss: 0.26447326944053473
Validation loss: 2.399433376692566

Epoch: 6| Step: 3
Training loss: 0.21739756216237002
Validation loss: 2.419997537557932

Epoch: 6| Step: 4
Training loss: 0.21825357716371882
Validation loss: 2.4230244534306573

Epoch: 6| Step: 5
Training loss: 0.0951113994803438
Validation loss: 2.3987933944298483

Epoch: 6| Step: 6
Training loss: 0.1638163923210831
Validation loss: 2.389662371125959

Epoch: 6| Step: 7
Training loss: 0.2825313097558487
Validation loss: 2.3857738279255036

Epoch: 6| Step: 8
Training loss: 0.18714951500754634
Validation loss: 2.356595727759345

Epoch: 6| Step: 9
Training loss: 0.2619515564982769
Validation loss: 2.3515364923777495

Epoch: 6| Step: 10
Training loss: 0.1464345020588905
Validation loss: 2.357230795479017

Epoch: 6| Step: 11
Training loss: 0.09907711161967676
Validation loss: 2.3892811593207477

Epoch: 6| Step: 12
Training loss: 0.2589889330340588
Validation loss: 2.4206617515198934

Epoch: 6| Step: 13
Training loss: 0.21681600778369733
Validation loss: 2.398816524644772

Epoch: 404| Step: 0
Training loss: 0.1279532287136994
Validation loss: 2.399129416288601

Epoch: 6| Step: 1
Training loss: 0.15783123764369159
Validation loss: 2.3816176532267206

Epoch: 6| Step: 2
Training loss: 0.2355424020193842
Validation loss: 2.380383005790259

Epoch: 6| Step: 3
Training loss: 0.233288743166403
Validation loss: 2.367114914724443

Epoch: 6| Step: 4
Training loss: 0.18835436362993324
Validation loss: 2.365543885848679

Epoch: 6| Step: 5
Training loss: 0.14774592441700116
Validation loss: 2.383021083062798

Epoch: 6| Step: 6
Training loss: 0.10228183817439393
Validation loss: 2.363440391655679

Epoch: 6| Step: 7
Training loss: 0.10692627764195611
Validation loss: 2.330152465249447

Epoch: 6| Step: 8
Training loss: 0.24244822035352875
Validation loss: 2.3368342551521173

Epoch: 6| Step: 9
Training loss: 0.28721571270047813
Validation loss: 2.3600894487609234

Epoch: 6| Step: 10
Training loss: 0.1808300080978819
Validation loss: 2.3063399369737305

Epoch: 6| Step: 11
Training loss: 0.19801359668259666
Validation loss: 2.336646451175235

Epoch: 6| Step: 12
Training loss: 0.23709944495283358
Validation loss: 2.3311305890326186

Epoch: 6| Step: 13
Training loss: 0.10646081514072252
Validation loss: 2.3621781388577165

Epoch: 405| Step: 0
Training loss: 0.12400759573257641
Validation loss: 2.3439341717486175

Epoch: 6| Step: 1
Training loss: 0.26282204616323296
Validation loss: 2.3393790513082404

Epoch: 6| Step: 2
Training loss: 0.19503681753812108
Validation loss: 2.3804468842402464

Epoch: 6| Step: 3
Training loss: 0.25638694825361574
Validation loss: 2.3769523915922255

Epoch: 6| Step: 4
Training loss: 0.17613473953340109
Validation loss: 2.3781819576158405

Epoch: 6| Step: 5
Training loss: 0.3095361107064751
Validation loss: 2.358511806161377

Epoch: 6| Step: 6
Training loss: 0.10525322014023515
Validation loss: 2.3664604594018477

Epoch: 6| Step: 7
Training loss: 0.13393140446413987
Validation loss: 2.3402964978277607

Epoch: 6| Step: 8
Training loss: 0.17542444149507128
Validation loss: 2.3868314491102303

Epoch: 6| Step: 9
Training loss: 0.17079207789132012
Validation loss: 2.3557124676978534

Epoch: 6| Step: 10
Training loss: 0.2127679243751421
Validation loss: 2.342409463440157

Epoch: 6| Step: 11
Training loss: 0.11589160288325771
Validation loss: 2.341251134440572

Epoch: 6| Step: 12
Training loss: 0.1915090246066108
Validation loss: 2.336801199490529

Epoch: 6| Step: 13
Training loss: 0.21299365813872537
Validation loss: 2.3539159704638895

Epoch: 406| Step: 0
Training loss: 0.20581702678068273
Validation loss: 2.3315143347258975

Epoch: 6| Step: 1
Training loss: 0.25170460354001734
Validation loss: 2.3596093465414856

Epoch: 6| Step: 2
Training loss: 0.2944252430505001
Validation loss: 2.3637326902194316

Epoch: 6| Step: 3
Training loss: 0.19772020217581684
Validation loss: 2.4025836303584733

Epoch: 6| Step: 4
Training loss: 0.13212106742077032
Validation loss: 2.3938892750339096

Epoch: 6| Step: 5
Training loss: 0.20713266551820758
Validation loss: 2.3928499995433583

Epoch: 6| Step: 6
Training loss: 0.10953776986366295
Validation loss: 2.3805694076431756

Epoch: 6| Step: 7
Training loss: 0.09221938478942307
Validation loss: 2.3710823673068933

Epoch: 6| Step: 8
Training loss: 0.14998061780081376
Validation loss: 2.3593869501343816

Epoch: 6| Step: 9
Training loss: 0.17719421468185856
Validation loss: 2.379262782740501

Epoch: 6| Step: 10
Training loss: 0.11742667586207034
Validation loss: 2.401208727119988

Epoch: 6| Step: 11
Training loss: 0.19979846978231638
Validation loss: 2.41702289487628

Epoch: 6| Step: 12
Training loss: 0.27282993392034427
Validation loss: 2.3887298544482

Epoch: 6| Step: 13
Training loss: 0.10938771633748634
Validation loss: 2.383807662296648

Epoch: 407| Step: 0
Training loss: 0.1882508562019148
Validation loss: 2.333686532332737

Epoch: 6| Step: 1
Training loss: 0.15607783249772164
Validation loss: 2.355361690342191

Epoch: 6| Step: 2
Training loss: 0.24290791390802546
Validation loss: 2.3657356444294932

Epoch: 6| Step: 3
Training loss: 0.12441931643089528
Validation loss: 2.3553513535227375

Epoch: 6| Step: 4
Training loss: 0.14603101510450042
Validation loss: 2.333614880265717

Epoch: 6| Step: 5
Training loss: 0.26678720236093506
Validation loss: 2.3486458346070878

Epoch: 6| Step: 6
Training loss: 0.19663629138340608
Validation loss: 2.33292019463615

Epoch: 6| Step: 7
Training loss: 0.27531233141284506
Validation loss: 2.3385335800736704

Epoch: 6| Step: 8
Training loss: 0.18768387957157434
Validation loss: 2.348468253999933

Epoch: 6| Step: 9
Training loss: 0.15302923234213578
Validation loss: 2.3478951194007327

Epoch: 6| Step: 10
Training loss: 0.10589629951015835
Validation loss: 2.3447785842027686

Epoch: 6| Step: 11
Training loss: 0.1584448850949562
Validation loss: 2.3342826848619835

Epoch: 6| Step: 12
Training loss: 0.09219938157179593
Validation loss: 2.331514100519539

Epoch: 6| Step: 13
Training loss: 0.10914458971461269
Validation loss: 2.3952591984357614

Epoch: 408| Step: 0
Training loss: 0.19136144152500623
Validation loss: 2.3758307344196097

Epoch: 6| Step: 1
Training loss: 0.2500248837007966
Validation loss: 2.369590931075589

Epoch: 6| Step: 2
Training loss: 0.07923404466484567
Validation loss: 2.360182168460369

Epoch: 6| Step: 3
Training loss: 0.1929119597973759
Validation loss: 2.367322697706716

Epoch: 6| Step: 4
Training loss: 0.20618398505779503
Validation loss: 2.3697027424803045

Epoch: 6| Step: 5
Training loss: 0.20518971994542934
Validation loss: 2.3815654997046733

Epoch: 6| Step: 6
Training loss: 0.11427987937089669
Validation loss: 2.3727025338451373

Epoch: 6| Step: 7
Training loss: 0.3051719238037458
Validation loss: 2.3905621667216206

Epoch: 6| Step: 8
Training loss: 0.16992640215225205
Validation loss: 2.4000216569401926

Epoch: 6| Step: 9
Training loss: 0.1658248085248179
Validation loss: 2.3517590659568905

Epoch: 6| Step: 10
Training loss: 0.10178134338625265
Validation loss: 2.3614162108805004

Epoch: 6| Step: 11
Training loss: 0.09762589459705387
Validation loss: 2.3711300809440994

Epoch: 6| Step: 12
Training loss: 0.176300025056425
Validation loss: 2.3680224756494423

Epoch: 6| Step: 13
Training loss: 0.3035243279818445
Validation loss: 2.3842415367915875

Epoch: 409| Step: 0
Training loss: 0.24224485210484026
Validation loss: 2.3698070677525345

Epoch: 6| Step: 1
Training loss: 0.18356891220577592
Validation loss: 2.3770974166903156

Epoch: 6| Step: 2
Training loss: 0.1056920619117653
Validation loss: 2.3850411925943478

Epoch: 6| Step: 3
Training loss: 0.194879184703662
Validation loss: 2.406268932777844

Epoch: 6| Step: 4
Training loss: 0.1942215491789028
Validation loss: 2.3278742950691225

Epoch: 6| Step: 5
Training loss: 0.27729764743223817
Validation loss: 2.3534212564876844

Epoch: 6| Step: 6
Training loss: 0.11392742464478256
Validation loss: 2.3714501346445047

Epoch: 6| Step: 7
Training loss: 0.12491936616125808
Validation loss: 2.346087317805047

Epoch: 6| Step: 8
Training loss: 0.14045511023565205
Validation loss: 2.3583821853169087

Epoch: 6| Step: 9
Training loss: 0.2238193383747412
Validation loss: 2.373807950128759

Epoch: 6| Step: 10
Training loss: 0.1929936466295457
Validation loss: 2.354053420176969

Epoch: 6| Step: 11
Training loss: 0.18457162442825945
Validation loss: 2.382024040204934

Epoch: 6| Step: 12
Training loss: 0.0969286035855449
Validation loss: 2.347130657427094

Epoch: 6| Step: 13
Training loss: 0.09034668571580591
Validation loss: 2.3343556782266206

Epoch: 410| Step: 0
Training loss: 0.16623099886254258
Validation loss: 2.3949503258975113

Epoch: 6| Step: 1
Training loss: 0.14950724420012398
Validation loss: 2.3761463787982087

Epoch: 6| Step: 2
Training loss: 0.23888191745409607
Validation loss: 2.385841607622418

Epoch: 6| Step: 3
Training loss: 0.23526813880493022
Validation loss: 2.3979896382992125

Epoch: 6| Step: 4
Training loss: 0.23589272232068312
Validation loss: 2.4214939480570545

Epoch: 6| Step: 5
Training loss: 0.1396765380543571
Validation loss: 2.436232000116817

Epoch: 6| Step: 6
Training loss: 0.12978639106938059
Validation loss: 2.3993940354936725

Epoch: 6| Step: 7
Training loss: 0.09614139069869614
Validation loss: 2.4044443703707405

Epoch: 6| Step: 8
Training loss: 0.14652233267774126
Validation loss: 2.4114862220384867

Epoch: 6| Step: 9
Training loss: 0.11721137121575828
Validation loss: 2.38481524951165

Epoch: 6| Step: 10
Training loss: 0.13331209211604533
Validation loss: 2.390662481271663

Epoch: 6| Step: 11
Training loss: 0.09225709680329233
Validation loss: 2.367236353179459

Epoch: 6| Step: 12
Training loss: 0.18941948778875575
Validation loss: 2.3502994855321204

Epoch: 6| Step: 13
Training loss: 0.30731335121628073
Validation loss: 2.3900418606181133

Epoch: 411| Step: 0
Training loss: 0.2289171115394489
Validation loss: 2.3722105251829286

Epoch: 6| Step: 1
Training loss: 0.16457239456181666
Validation loss: 2.3835789247241075

Epoch: 6| Step: 2
Training loss: 0.23836092320442337
Validation loss: 2.368476984586003

Epoch: 6| Step: 3
Training loss: 0.13247175543170636
Validation loss: 2.3893836273762648

Epoch: 6| Step: 4
Training loss: 0.14568952440698854
Validation loss: 2.39396649605786

Epoch: 6| Step: 5
Training loss: 0.13265166642051401
Validation loss: 2.393703132881073

Epoch: 6| Step: 6
Training loss: 0.21008251130279793
Validation loss: 2.4142547067889626

Epoch: 6| Step: 7
Training loss: 0.08914412848485789
Validation loss: 2.372124586606276

Epoch: 6| Step: 8
Training loss: 0.1403318966604077
Validation loss: 2.388746116946131

Epoch: 6| Step: 9
Training loss: 0.1754285505874206
Validation loss: 2.374512728761989

Epoch: 6| Step: 10
Training loss: 0.2656338213409495
Validation loss: 2.400224204084861

Epoch: 6| Step: 11
Training loss: 0.16363687596269502
Validation loss: 2.3818315740556115

Epoch: 6| Step: 12
Training loss: 0.14878184132016797
Validation loss: 2.386736563266705

Epoch: 6| Step: 13
Training loss: 0.13790942515087734
Validation loss: 2.384310705138739

Epoch: 412| Step: 0
Training loss: 0.23197502970735903
Validation loss: 2.3514288023231456

Epoch: 6| Step: 1
Training loss: 0.1673780856806021
Validation loss: 2.35929457569455

Epoch: 6| Step: 2
Training loss: 0.2249355270148704
Validation loss: 2.369665366756523

Epoch: 6| Step: 3
Training loss: 0.1536330417114379
Validation loss: 2.3705240995816297

Epoch: 6| Step: 4
Training loss: 0.25774950645040623
Validation loss: 2.3293067502421416

Epoch: 6| Step: 5
Training loss: 0.15222774270226416
Validation loss: 2.3363551563052876

Epoch: 6| Step: 6
Training loss: 0.10656960256740111
Validation loss: 2.3531555616554045

Epoch: 6| Step: 7
Training loss: 0.19266143219499138
Validation loss: 2.3626178094637353

Epoch: 6| Step: 8
Training loss: 0.19342737254560888
Validation loss: 2.326525304650935

Epoch: 6| Step: 9
Training loss: 0.21656370941528993
Validation loss: 2.334628379361

Epoch: 6| Step: 10
Training loss: 0.11962220309414888
Validation loss: 2.354565335020798

Epoch: 6| Step: 11
Training loss: 0.1446539963332206
Validation loss: 2.36743315814326

Epoch: 6| Step: 12
Training loss: 0.13670306115732675
Validation loss: 2.3828271237009844

Epoch: 6| Step: 13
Training loss: 0.1150399038028232
Validation loss: 2.3655981593254465

Epoch: 413| Step: 0
Training loss: 0.15222735115260067
Validation loss: 2.3624377946357296

Epoch: 6| Step: 1
Training loss: 0.131108317651305
Validation loss: 2.3885785187238917

Epoch: 6| Step: 2
Training loss: 0.14903816610323586
Validation loss: 2.3663129387343784

Epoch: 6| Step: 3
Training loss: 0.08884809100199204
Validation loss: 2.381826232484877

Epoch: 6| Step: 4
Training loss: 0.21736051131447726
Validation loss: 2.381631726408701

Epoch: 6| Step: 5
Training loss: 0.08380703722171343
Validation loss: 2.3836104766325175

Epoch: 6| Step: 6
Training loss: 0.16529483275301748
Validation loss: 2.389952009725557

Epoch: 6| Step: 7
Training loss: 0.15551984776348335
Validation loss: 2.372014764526562

Epoch: 6| Step: 8
Training loss: 0.14744169854981443
Validation loss: 2.3957984543696274

Epoch: 6| Step: 9
Training loss: 0.2820874039390537
Validation loss: 2.381509341624959

Epoch: 6| Step: 10
Training loss: 0.24831909351010675
Validation loss: 2.377766725285551

Epoch: 6| Step: 11
Training loss: 0.16405962759864015
Validation loss: 2.364224826887456

Epoch: 6| Step: 12
Training loss: 0.0895351105002496
Validation loss: 2.3850168345424705

Epoch: 6| Step: 13
Training loss: 0.0663789384440347
Validation loss: 2.3806956947782703

Epoch: 414| Step: 0
Training loss: 0.1810336482427339
Validation loss: 2.371025740090106

Epoch: 6| Step: 1
Training loss: 0.11222735935463375
Validation loss: 2.3478338603582314

Epoch: 6| Step: 2
Training loss: 0.08447676025740727
Validation loss: 2.371542879332179

Epoch: 6| Step: 3
Training loss: 0.3109423440527149
Validation loss: 2.367861288201537

Epoch: 6| Step: 4
Training loss: 0.23531953902437389
Validation loss: 2.3595695477874132

Epoch: 6| Step: 5
Training loss: 0.16391217065596397
Validation loss: 2.362867101051373

Epoch: 6| Step: 6
Training loss: 0.14463484762842455
Validation loss: 2.3799426143039564

Epoch: 6| Step: 7
Training loss: 0.14926466609870848
Validation loss: 2.3450403217931894

Epoch: 6| Step: 8
Training loss: 0.10938588156385044
Validation loss: 2.353883365968999

Epoch: 6| Step: 9
Training loss: 0.18124898096324296
Validation loss: 2.34461691079023

Epoch: 6| Step: 10
Training loss: 0.13246090716016012
Validation loss: 2.3643097752917983

Epoch: 6| Step: 11
Training loss: 0.11630273447083668
Validation loss: 2.3665005745061354

Epoch: 6| Step: 12
Training loss: 0.11251594741694573
Validation loss: 2.3548984856610553

Epoch: 6| Step: 13
Training loss: 0.09178642456955123
Validation loss: 2.3844973353679335

Epoch: 415| Step: 0
Training loss: 0.2557556000130925
Validation loss: 2.385069296324109

Epoch: 6| Step: 1
Training loss: 0.23496394864988518
Validation loss: 2.4462239517029922

Epoch: 6| Step: 2
Training loss: 0.09224236217691278
Validation loss: 2.4152855171618617

Epoch: 6| Step: 3
Training loss: 0.07953449969594233
Validation loss: 2.4135587369539

Epoch: 6| Step: 4
Training loss: 0.16854839335300786
Validation loss: 2.4276925662522757

Epoch: 6| Step: 5
Training loss: 0.18908311164042138
Validation loss: 2.420192528140728

Epoch: 6| Step: 6
Training loss: 0.16167849417460592
Validation loss: 2.3781768102396095

Epoch: 6| Step: 7
Training loss: 0.0859392447727988
Validation loss: 2.395737460885706

Epoch: 6| Step: 8
Training loss: 0.14198932828477534
Validation loss: 2.3527684227861068

Epoch: 6| Step: 9
Training loss: 0.2306545849951785
Validation loss: 2.3698926687549924

Epoch: 6| Step: 10
Training loss: 0.16492436729221316
Validation loss: 2.3595204283045987

Epoch: 6| Step: 11
Training loss: 0.13238307305628624
Validation loss: 2.3302624944996277

Epoch: 6| Step: 12
Training loss: 0.0665491264076166
Validation loss: 2.3850936129955516

Epoch: 6| Step: 13
Training loss: 0.1045033636087963
Validation loss: 2.391772915838045

Epoch: 416| Step: 0
Training loss: 0.1326220071897156
Validation loss: 2.3982752460883803

Epoch: 6| Step: 1
Training loss: 0.14258840602230083
Validation loss: 2.3508003037219862

Epoch: 6| Step: 2
Training loss: 0.18619637499795702
Validation loss: 2.3957328555067066

Epoch: 6| Step: 3
Training loss: 0.14718132793744057
Validation loss: 2.3681935978916635

Epoch: 6| Step: 4
Training loss: 0.10859175361197858
Validation loss: 2.421132399720768

Epoch: 6| Step: 5
Training loss: 0.11237465710529294
Validation loss: 2.376769529793875

Epoch: 6| Step: 6
Training loss: 0.14347475122917772
Validation loss: 2.3880425502733305

Epoch: 6| Step: 7
Training loss: 0.14404307219938023
Validation loss: 2.380176439949186

Epoch: 6| Step: 8
Training loss: 0.23290084724296733
Validation loss: 2.4007536930952993

Epoch: 6| Step: 9
Training loss: 0.22633250664501267
Validation loss: 2.3701312716413705

Epoch: 6| Step: 10
Training loss: 0.09181227453397589
Validation loss: 2.383437270481071

Epoch: 6| Step: 11
Training loss: 0.1907607990179058
Validation loss: 2.41468978268222

Epoch: 6| Step: 12
Training loss: 0.07936470097742417
Validation loss: 2.3732919968559427

Epoch: 6| Step: 13
Training loss: 0.11297365059254584
Validation loss: 2.3934363120948996

Epoch: 417| Step: 0
Training loss: 0.08291744755022995
Validation loss: 2.4162501364089137

Epoch: 6| Step: 1
Training loss: 0.09098481590043628
Validation loss: 2.3571403061969662

Epoch: 6| Step: 2
Training loss: 0.12543308959120225
Validation loss: 2.3827941242910144

Epoch: 6| Step: 3
Training loss: 0.10044173672481188
Validation loss: 2.3924619702824574

Epoch: 6| Step: 4
Training loss: 0.2453740434530797
Validation loss: 2.3831768174958294

Epoch: 6| Step: 5
Training loss: 0.06947825828832517
Validation loss: 2.3847182575546064

Epoch: 6| Step: 6
Training loss: 0.23770450928448653
Validation loss: 2.3813374483777716

Epoch: 6| Step: 7
Training loss: 0.10703694996657397
Validation loss: 2.369785566749191

Epoch: 6| Step: 8
Training loss: 0.22750859199794637
Validation loss: 2.3694893316985755

Epoch: 6| Step: 9
Training loss: 0.09196609766936964
Validation loss: 2.339251567103647

Epoch: 6| Step: 10
Training loss: 0.16380033095372074
Validation loss: 2.381290137085353

Epoch: 6| Step: 11
Training loss: 0.09037073697987827
Validation loss: 2.3901882181459273

Epoch: 6| Step: 12
Training loss: 0.2087758084150314
Validation loss: 2.4041954296290484

Epoch: 6| Step: 13
Training loss: 0.25862278904898583
Validation loss: 2.3763101037474894

Epoch: 418| Step: 0
Training loss: 0.16507616133995576
Validation loss: 2.360645973511847

Epoch: 6| Step: 1
Training loss: 0.2312925937449378
Validation loss: 2.3865310044343557

Epoch: 6| Step: 2
Training loss: 0.06343649553339943
Validation loss: 2.380405618093823

Epoch: 6| Step: 3
Training loss: 0.1203703344971992
Validation loss: 2.397383052151526

Epoch: 6| Step: 4
Training loss: 0.1621499412979681
Validation loss: 2.380853868386082

Epoch: 6| Step: 5
Training loss: 0.09908283604032421
Validation loss: 2.374173243369161

Epoch: 6| Step: 6
Training loss: 0.11475529735259726
Validation loss: 2.3508187523066604

Epoch: 6| Step: 7
Training loss: 0.18333113941772816
Validation loss: 2.396659081906987

Epoch: 6| Step: 8
Training loss: 0.18474530194959052
Validation loss: 2.392637371629707

Epoch: 6| Step: 9
Training loss: 0.2158125276154015
Validation loss: 2.370608342644855

Epoch: 6| Step: 10
Training loss: 0.2492859522579379
Validation loss: 2.3922098970278673

Epoch: 6| Step: 11
Training loss: 0.13531373694076945
Validation loss: 2.3905246130975564

Epoch: 6| Step: 12
Training loss: 0.19225241022372558
Validation loss: 2.3940859385578697

Epoch: 6| Step: 13
Training loss: 0.0917012193114238
Validation loss: 2.3947056101590283

Epoch: 419| Step: 0
Training loss: 0.2546279041796963
Validation loss: 2.4256344728809913

Epoch: 6| Step: 1
Training loss: 0.07863990854004774
Validation loss: 2.4290869966893527

Epoch: 6| Step: 2
Training loss: 0.22344168779143325
Validation loss: 2.451488404851702

Epoch: 6| Step: 3
Training loss: 0.14198461221167386
Validation loss: 2.4091849591125243

Epoch: 6| Step: 4
Training loss: 0.1301037479630089
Validation loss: 2.4168052152720945

Epoch: 6| Step: 5
Training loss: 0.18110909164126143
Validation loss: 2.393352939495014

Epoch: 6| Step: 6
Training loss: 0.12015519277482044
Validation loss: 2.4104389942184588

Epoch: 6| Step: 7
Training loss: 0.23314317606822674
Validation loss: 2.390288450790034

Epoch: 6| Step: 8
Training loss: 0.14519391989790578
Validation loss: 2.4100299737705626

Epoch: 6| Step: 9
Training loss: 0.1283291992175981
Validation loss: 2.3518227130133846

Epoch: 6| Step: 10
Training loss: 0.1590200220208362
Validation loss: 2.360296816739583

Epoch: 6| Step: 11
Training loss: 0.1306165891202742
Validation loss: 2.3780009034144727

Epoch: 6| Step: 12
Training loss: 0.07382932881478889
Validation loss: 2.326034036370555

Epoch: 6| Step: 13
Training loss: 0.10119475212816688
Validation loss: 2.355328913205845

Epoch: 420| Step: 0
Training loss: 0.10824641315495265
Validation loss: 2.3452619306912665

Epoch: 6| Step: 1
Training loss: 0.08051297699208505
Validation loss: 2.344433471124787

Epoch: 6| Step: 2
Training loss: 0.06018871462444074
Validation loss: 2.3246884394060725

Epoch: 6| Step: 3
Training loss: 0.2417338799178196
Validation loss: 2.347210784210797

Epoch: 6| Step: 4
Training loss: 0.18549966713523305
Validation loss: 2.331588097562777

Epoch: 6| Step: 5
Training loss: 0.15602040708048723
Validation loss: 2.3458885832748266

Epoch: 6| Step: 6
Training loss: 0.154677549196252
Validation loss: 2.3574230478429974

Epoch: 6| Step: 7
Training loss: 0.16246411564647234
Validation loss: 2.33141560421438

Epoch: 6| Step: 8
Training loss: 0.15249739748266217
Validation loss: 2.3746617534552055

Epoch: 6| Step: 9
Training loss: 0.13948567114837052
Validation loss: 2.365890824116498

Epoch: 6| Step: 10
Training loss: 0.10833369289011464
Validation loss: 2.3674613095481356

Epoch: 6| Step: 11
Training loss: 0.16722340777530653
Validation loss: 2.369742548470834

Epoch: 6| Step: 12
Training loss: 0.2921030988526575
Validation loss: 2.406406335182874

Epoch: 6| Step: 13
Training loss: 0.08105898179318058
Validation loss: 2.353804578349358

Epoch: 421| Step: 0
Training loss: 0.1955340559320492
Validation loss: 2.381085145972613

Epoch: 6| Step: 1
Training loss: 0.1139772140405341
Validation loss: 2.345179631363243

Epoch: 6| Step: 2
Training loss: 0.08532778148934739
Validation loss: 2.4029336947453195

Epoch: 6| Step: 3
Training loss: 0.17633319666595187
Validation loss: 2.383510085778062

Epoch: 6| Step: 4
Training loss: 0.1567558801580857
Validation loss: 2.3930754194348456

Epoch: 6| Step: 5
Training loss: 0.22084278987634248
Validation loss: 2.41355477394653

Epoch: 6| Step: 6
Training loss: 0.17278867321036956
Validation loss: 2.4317044905981535

Epoch: 6| Step: 7
Training loss: 0.12005571792904056
Validation loss: 2.40827483381377

Epoch: 6| Step: 8
Training loss: 0.2214384741205877
Validation loss: 2.3905541065440743

Epoch: 6| Step: 9
Training loss: 0.24811200916240386
Validation loss: 2.3946673357205843

Epoch: 6| Step: 10
Training loss: 0.2004496191980309
Validation loss: 2.406017420608453

Epoch: 6| Step: 11
Training loss: 0.27648656309048314
Validation loss: 2.382748206185886

Epoch: 6| Step: 12
Training loss: 0.1651636646468595
Validation loss: 2.4245090140228855

Epoch: 6| Step: 13
Training loss: 0.12820023037689654
Validation loss: 2.39409208507004

Epoch: 422| Step: 0
Training loss: 0.2997609954707148
Validation loss: 2.397571285047371

Epoch: 6| Step: 1
Training loss: 0.13733759196844206
Validation loss: 2.411790597958392

Epoch: 6| Step: 2
Training loss: 0.19851290253953371
Validation loss: 2.3776607882499077

Epoch: 6| Step: 3
Training loss: 0.17231555310333596
Validation loss: 2.353357558434976

Epoch: 6| Step: 4
Training loss: 0.19321613593433207
Validation loss: 2.3851860792201003

Epoch: 6| Step: 5
Training loss: 0.28665562540283823
Validation loss: 2.3819437154834575

Epoch: 6| Step: 6
Training loss: 0.15136446796558364
Validation loss: 2.363359512339039

Epoch: 6| Step: 7
Training loss: 0.121927479149628
Validation loss: 2.3834646810796607

Epoch: 6| Step: 8
Training loss: 0.24469456200865033
Validation loss: 2.3810407512646172

Epoch: 6| Step: 9
Training loss: 0.19828804312598364
Validation loss: 2.4054058742728888

Epoch: 6| Step: 10
Training loss: 0.1248447900019787
Validation loss: 2.4098916577906393

Epoch: 6| Step: 11
Training loss: 0.1357258711415045
Validation loss: 2.3849375861174313

Epoch: 6| Step: 12
Training loss: 0.2084440126073643
Validation loss: 2.3783505687216597

Epoch: 6| Step: 13
Training loss: 0.17277469650075478
Validation loss: 2.3828474392238217

Epoch: 423| Step: 0
Training loss: 0.1693724266257932
Validation loss: 2.364419629431782

Epoch: 6| Step: 1
Training loss: 0.26593822355877966
Validation loss: 2.3545370740697487

Epoch: 6| Step: 2
Training loss: 0.24980637383506962
Validation loss: 2.3756192754105694

Epoch: 6| Step: 3
Training loss: 0.21761398293897447
Validation loss: 2.378861910542192

Epoch: 6| Step: 4
Training loss: 0.1686151950656428
Validation loss: 2.337222222425867

Epoch: 6| Step: 5
Training loss: 0.1824249234649343
Validation loss: 2.327884943868535

Epoch: 6| Step: 6
Training loss: 0.21261196973188312
Validation loss: 2.3211314769406965

Epoch: 6| Step: 7
Training loss: 0.13810169502360273
Validation loss: 2.3589074608008342

Epoch: 6| Step: 8
Training loss: 0.19276377915572127
Validation loss: 2.404225086992313

Epoch: 6| Step: 9
Training loss: 0.24382734416529853
Validation loss: 2.4171743725970525

Epoch: 6| Step: 10
Training loss: 0.17999912274994598
Validation loss: 2.4348837024298136

Epoch: 6| Step: 11
Training loss: 0.19848353159906296
Validation loss: 2.459222497902761

Epoch: 6| Step: 12
Training loss: 0.25498238441919396
Validation loss: 2.4955007387336616

Epoch: 6| Step: 13
Training loss: 0.31278420875804747
Validation loss: 2.457689104576694

Epoch: 424| Step: 0
Training loss: 0.17961474687292714
Validation loss: 2.4778610090741524

Epoch: 6| Step: 1
Training loss: 0.22548105022587472
Validation loss: 2.4367557501113195

Epoch: 6| Step: 2
Training loss: 0.1710768830681706
Validation loss: 2.423590187638806

Epoch: 6| Step: 3
Training loss: 0.21433503003534032
Validation loss: 2.3796064347712274

Epoch: 6| Step: 4
Training loss: 0.3388776640138282
Validation loss: 2.3650694388959823

Epoch: 6| Step: 5
Training loss: 0.2202531058149854
Validation loss: 2.3738433188726096

Epoch: 6| Step: 6
Training loss: 0.17828957333472145
Validation loss: 2.3740393957897874

Epoch: 6| Step: 7
Training loss: 0.14482757759957943
Validation loss: 2.403268845962094

Epoch: 6| Step: 8
Training loss: 0.13373638424688258
Validation loss: 2.392387090862079

Epoch: 6| Step: 9
Training loss: 0.09235168763399017
Validation loss: 2.404494042410461

Epoch: 6| Step: 10
Training loss: 0.1745258803724093
Validation loss: 2.398830776926929

Epoch: 6| Step: 11
Training loss: 0.2028504956013702
Validation loss: 2.3906449374673753

Epoch: 6| Step: 12
Training loss: 0.285762169244247
Validation loss: 2.3845706837949274

Epoch: 6| Step: 13
Training loss: 0.1198099168233839
Validation loss: 2.3945310947596354

Epoch: 425| Step: 0
Training loss: 0.14851377434859248
Validation loss: 2.375789314716529

Epoch: 6| Step: 1
Training loss: 0.18658109842181234
Validation loss: 2.3508089767667917

Epoch: 6| Step: 2
Training loss: 0.25567586884657295
Validation loss: 2.351901087411846

Epoch: 6| Step: 3
Training loss: 0.14641686473298213
Validation loss: 2.336245998328949

Epoch: 6| Step: 4
Training loss: 0.26308243883011273
Validation loss: 2.372439475449586

Epoch: 6| Step: 5
Training loss: 0.24986196969203253
Validation loss: 2.3684014394041943

Epoch: 6| Step: 6
Training loss: 0.2114735961128786
Validation loss: 2.354520930246645

Epoch: 6| Step: 7
Training loss: 0.15649775889196627
Validation loss: 2.3298701157101513

Epoch: 6| Step: 8
Training loss: 0.14951814504375935
Validation loss: 2.3715023706292375

Epoch: 6| Step: 9
Training loss: 0.09545413539112554
Validation loss: 2.3560110851515725

Epoch: 6| Step: 10
Training loss: 0.1654692804005653
Validation loss: 2.413458909885432

Epoch: 6| Step: 11
Training loss: 0.24363430927325094
Validation loss: 2.400550735150665

Epoch: 6| Step: 12
Training loss: 0.10051815749182749
Validation loss: 2.3818231463641206

Epoch: 6| Step: 13
Training loss: 0.11242944173684614
Validation loss: 2.3603631894566983

Epoch: 426| Step: 0
Training loss: 0.07438657633463264
Validation loss: 2.3773075555763863

Epoch: 6| Step: 1
Training loss: 0.15766155889927816
Validation loss: 2.362873639073376

Epoch: 6| Step: 2
Training loss: 0.1477126505778587
Validation loss: 2.389901150467175

Epoch: 6| Step: 3
Training loss: 0.15057766417895677
Validation loss: 2.3866258572290957

Epoch: 6| Step: 4
Training loss: 0.23214697408431528
Validation loss: 2.4077732819106963

Epoch: 6| Step: 5
Training loss: 0.22112879593298965
Validation loss: 2.388427213929951

Epoch: 6| Step: 6
Training loss: 0.1722151738634631
Validation loss: 2.3833021295995884

Epoch: 6| Step: 7
Training loss: 0.1851618134189908
Validation loss: 2.422832876225978

Epoch: 6| Step: 8
Training loss: 0.2822644561354833
Validation loss: 2.4107045291781986

Epoch: 6| Step: 9
Training loss: 0.24502576209637622
Validation loss: 2.399777315197555

Epoch: 6| Step: 10
Training loss: 0.2102579632911174
Validation loss: 2.393157935071926

Epoch: 6| Step: 11
Training loss: 0.16758069967857384
Validation loss: 2.3822614307263006

Epoch: 6| Step: 12
Training loss: 0.10426309016945308
Validation loss: 2.3750987871627407

Epoch: 6| Step: 13
Training loss: 0.13528791750530048
Validation loss: 2.366171957280168

Epoch: 427| Step: 0
Training loss: 0.12623284759239578
Validation loss: 2.348448437148438

Epoch: 6| Step: 1
Training loss: 0.25149426334466835
Validation loss: 2.3592285434593765

Epoch: 6| Step: 2
Training loss: 0.22062285828834136
Validation loss: 2.409107718300632

Epoch: 6| Step: 3
Training loss: 0.13893282877405008
Validation loss: 2.3855940940921037

Epoch: 6| Step: 4
Training loss: 0.2230570682260832
Validation loss: 2.4089513929457294

Epoch: 6| Step: 5
Training loss: 0.13297276084041654
Validation loss: 2.3884313329428304

Epoch: 6| Step: 6
Training loss: 0.11746185294766008
Validation loss: 2.4052270558870896

Epoch: 6| Step: 7
Training loss: 0.11648472022831172
Validation loss: 2.37737337250287

Epoch: 6| Step: 8
Training loss: 0.250446487122702
Validation loss: 2.364076335374631

Epoch: 6| Step: 9
Training loss: 0.11707815791238678
Validation loss: 2.3834729448550855

Epoch: 6| Step: 10
Training loss: 0.19968627784546036
Validation loss: 2.380736905555054

Epoch: 6| Step: 11
Training loss: 0.22842177069453062
Validation loss: 2.3643507531147208

Epoch: 6| Step: 12
Training loss: 0.145301204929472
Validation loss: 2.368172561533843

Epoch: 6| Step: 13
Training loss: 0.18241302787353053
Validation loss: 2.3707763991454676

Epoch: 428| Step: 0
Training loss: 0.18568269878062227
Validation loss: 2.422014765522222

Epoch: 6| Step: 1
Training loss: 0.23367170672472803
Validation loss: 2.394099063590948

Epoch: 6| Step: 2
Training loss: 0.10742570696845138
Validation loss: 2.4122940862274214

Epoch: 6| Step: 3
Training loss: 0.17129824058101828
Validation loss: 2.3875484115781194

Epoch: 6| Step: 4
Training loss: 0.12697513096159152
Validation loss: 2.392898224074948

Epoch: 6| Step: 5
Training loss: 0.14147547665970892
Validation loss: 2.4106724529431496

Epoch: 6| Step: 6
Training loss: 0.08323510410597476
Validation loss: 2.426627637649479

Epoch: 6| Step: 7
Training loss: 0.16486161754371112
Validation loss: 2.4135675174722446

Epoch: 6| Step: 8
Training loss: 0.15434391777360026
Validation loss: 2.387040884926248

Epoch: 6| Step: 9
Training loss: 0.15640948024542795
Validation loss: 2.412882708428872

Epoch: 6| Step: 10
Training loss: 0.14227176438291966
Validation loss: 2.4108658407803953

Epoch: 6| Step: 11
Training loss: 0.22264882962092516
Validation loss: 2.4068706443440173

Epoch: 6| Step: 12
Training loss: 0.23613264337853873
Validation loss: 2.392206280165611

Epoch: 6| Step: 13
Training loss: 0.11409396462641025
Validation loss: 2.390130493956378

Epoch: 429| Step: 0
Training loss: 0.13399350771904997
Validation loss: 2.385356789121458

Epoch: 6| Step: 1
Training loss: 0.1684167288515922
Validation loss: 2.3901009202000143

Epoch: 6| Step: 2
Training loss: 0.12189919876455513
Validation loss: 2.35509108680214

Epoch: 6| Step: 3
Training loss: 0.16910133434059083
Validation loss: 2.3642010849857065

Epoch: 6| Step: 4
Training loss: 0.16599111937127475
Validation loss: 2.3368804188593466

Epoch: 6| Step: 5
Training loss: 0.1134459679177915
Validation loss: 2.385627386559884

Epoch: 6| Step: 6
Training loss: 0.14804751212352857
Validation loss: 2.367089708576425

Epoch: 6| Step: 7
Training loss: 0.2510693745867257
Validation loss: 2.360213368393951

Epoch: 6| Step: 8
Training loss: 0.20360903655460166
Validation loss: 2.369119628973364

Epoch: 6| Step: 9
Training loss: 0.22892467047099088
Validation loss: 2.374460803548305

Epoch: 6| Step: 10
Training loss: 0.14126771178643546
Validation loss: 2.3757733703392616

Epoch: 6| Step: 11
Training loss: 0.1075439193327198
Validation loss: 2.3990563858145104

Epoch: 6| Step: 12
Training loss: 0.13625125658042034
Validation loss: 2.4022590815039124

Epoch: 6| Step: 13
Training loss: 0.13643963114751165
Validation loss: 2.3770418462574825

Epoch: 430| Step: 0
Training loss: 0.1622145839910191
Validation loss: 2.3792831515940303

Epoch: 6| Step: 1
Training loss: 0.14762012781594983
Validation loss: 2.379516988711791

Epoch: 6| Step: 2
Training loss: 0.2127635646635428
Validation loss: 2.3962923165806544

Epoch: 6| Step: 3
Training loss: 0.21186689212218213
Validation loss: 2.385259230203011

Epoch: 6| Step: 4
Training loss: 0.095765949570499
Validation loss: 2.3582478534903104

Epoch: 6| Step: 5
Training loss: 0.12702436649023388
Validation loss: 2.385032222677434

Epoch: 6| Step: 6
Training loss: 0.12322066915702355
Validation loss: 2.394916795330907

Epoch: 6| Step: 7
Training loss: 0.08998811049705348
Validation loss: 2.379842270167289

Epoch: 6| Step: 8
Training loss: 0.1906768564137624
Validation loss: 2.356989537390555

Epoch: 6| Step: 9
Training loss: 0.19882111977338335
Validation loss: 2.3847341625516

Epoch: 6| Step: 10
Training loss: 0.11867129013690889
Validation loss: 2.403642248966646

Epoch: 6| Step: 11
Training loss: 0.18134082130119505
Validation loss: 2.347837092022031

Epoch: 6| Step: 12
Training loss: 0.0867961179715714
Validation loss: 2.3785902475821743

Epoch: 6| Step: 13
Training loss: 0.10302378209904675
Validation loss: 2.3694535209018586

Epoch: 431| Step: 0
Training loss: 0.07992783259488824
Validation loss: 2.3571099617860147

Epoch: 6| Step: 1
Training loss: 0.13183578915057842
Validation loss: 2.3446369825339306

Epoch: 6| Step: 2
Training loss: 0.15875098650543193
Validation loss: 2.367566405746291

Epoch: 6| Step: 3
Training loss: 0.14637109827091146
Validation loss: 2.364819840686657

Epoch: 6| Step: 4
Training loss: 0.11714089579536285
Validation loss: 2.3772245091697113

Epoch: 6| Step: 5
Training loss: 0.232580115041013
Validation loss: 2.3892976251491738

Epoch: 6| Step: 6
Training loss: 0.1283870123041231
Validation loss: 2.3860480187757345

Epoch: 6| Step: 7
Training loss: 0.11409909889202202
Validation loss: 2.3723414642129126

Epoch: 6| Step: 8
Training loss: 0.2405840956612315
Validation loss: 2.3743191397789847

Epoch: 6| Step: 9
Training loss: 0.26603227134749613
Validation loss: 2.3762297218128436

Epoch: 6| Step: 10
Training loss: 0.1406580104760085
Validation loss: 2.378290899355376

Epoch: 6| Step: 11
Training loss: 0.18021930902790265
Validation loss: 2.3970045457596023

Epoch: 6| Step: 12
Training loss: 0.1462925099474683
Validation loss: 2.3857774899996187

Epoch: 6| Step: 13
Training loss: 0.1458424617828143
Validation loss: 2.3920353833525274

Epoch: 432| Step: 0
Training loss: 0.14425826712277687
Validation loss: 2.412846955697829

Epoch: 6| Step: 1
Training loss: 0.1289999433510863
Validation loss: 2.39432160531177

Epoch: 6| Step: 2
Training loss: 0.12522981796017016
Validation loss: 2.4233353090761307

Epoch: 6| Step: 3
Training loss: 0.11545241466184437
Validation loss: 2.403885305768937

Epoch: 6| Step: 4
Training loss: 0.14813881236273926
Validation loss: 2.400596106624527

Epoch: 6| Step: 5
Training loss: 0.2214762893088921
Validation loss: 2.4116189905318692

Epoch: 6| Step: 6
Training loss: 0.1340705388777843
Validation loss: 2.3911460219154232

Epoch: 6| Step: 7
Training loss: 0.20214794914444614
Validation loss: 2.398757121768258

Epoch: 6| Step: 8
Training loss: 0.13239873920311082
Validation loss: 2.3818734279192366

Epoch: 6| Step: 9
Training loss: 0.15687349613198368
Validation loss: 2.3581928392936096

Epoch: 6| Step: 10
Training loss: 0.09268971731320803
Validation loss: 2.390047734355767

Epoch: 6| Step: 11
Training loss: 0.13441379896302733
Validation loss: 2.3757404302290888

Epoch: 6| Step: 12
Training loss: 0.30539703893281495
Validation loss: 2.3436101290624

Epoch: 6| Step: 13
Training loss: 0.0793275342826872
Validation loss: 2.3294140488020934

Epoch: 433| Step: 0
Training loss: 0.07398439726582468
Validation loss: 2.37780616124238

Epoch: 6| Step: 1
Training loss: 0.12816781166124933
Validation loss: 2.352970478949416

Epoch: 6| Step: 2
Training loss: 0.10933300046393389
Validation loss: 2.3431650154990327

Epoch: 6| Step: 3
Training loss: 0.21004182898508783
Validation loss: 2.358287943057499

Epoch: 6| Step: 4
Training loss: 0.14070658833606184
Validation loss: 2.351263657471489

Epoch: 6| Step: 5
Training loss: 0.08471382311787813
Validation loss: 2.3696299410625508

Epoch: 6| Step: 6
Training loss: 0.1778184042354286
Validation loss: 2.3637084775456674

Epoch: 6| Step: 7
Training loss: 0.160736590968213
Validation loss: 2.381593462530738

Epoch: 6| Step: 8
Training loss: 0.22658167133116927
Validation loss: 2.373119175670967

Epoch: 6| Step: 9
Training loss: 0.16238626709053702
Validation loss: 2.3775027526533816

Epoch: 6| Step: 10
Training loss: 0.12019222520862097
Validation loss: 2.4043864371975827

Epoch: 6| Step: 11
Training loss: 0.2117843142829976
Validation loss: 2.4248349882833677

Epoch: 6| Step: 12
Training loss: 0.09987419585804203
Validation loss: 2.4177705313530753

Epoch: 6| Step: 13
Training loss: 0.12263180723043779
Validation loss: 2.4188876587993624

Epoch: 434| Step: 0
Training loss: 0.11056867694527801
Validation loss: 2.4097323847776435

Epoch: 6| Step: 1
Training loss: 0.06281667813477745
Validation loss: 2.4175439910427223

Epoch: 6| Step: 2
Training loss: 0.2625156057351083
Validation loss: 2.4186152246473203

Epoch: 6| Step: 3
Training loss: 0.13888572268718272
Validation loss: 2.3892437347080446

Epoch: 6| Step: 4
Training loss: 0.164280065963626
Validation loss: 2.3917712308768717

Epoch: 6| Step: 5
Training loss: 0.07587631667933482
Validation loss: 2.3875574651896985

Epoch: 6| Step: 6
Training loss: 0.1603133896102166
Validation loss: 2.392487936992548

Epoch: 6| Step: 7
Training loss: 0.09816551933012083
Validation loss: 2.384645107177895

Epoch: 6| Step: 8
Training loss: 0.10430226044198673
Validation loss: 2.360932090405986

Epoch: 6| Step: 9
Training loss: 0.12369841316190427
Validation loss: 2.358030365657802

Epoch: 6| Step: 10
Training loss: 0.11979421754553639
Validation loss: 2.376867410209021

Epoch: 6| Step: 11
Training loss: 0.23004315568751468
Validation loss: 2.3820277360262034

Epoch: 6| Step: 12
Training loss: 0.0937796933118979
Validation loss: 2.389829461564282

Epoch: 6| Step: 13
Training loss: 0.255365550343903
Validation loss: 2.386160846258902

Epoch: 435| Step: 0
Training loss: 0.10305838094800017
Validation loss: 2.3586295029260502

Epoch: 6| Step: 1
Training loss: 0.12788412141663158
Validation loss: 2.3867083073080058

Epoch: 6| Step: 2
Training loss: 0.10741740997745092
Validation loss: 2.4224421985155815

Epoch: 6| Step: 3
Training loss: 0.2500231255325923
Validation loss: 2.419843458753297

Epoch: 6| Step: 4
Training loss: 0.10677301203047804
Validation loss: 2.404480587091058

Epoch: 6| Step: 5
Training loss: 0.11495016497329076
Validation loss: 2.412656968591395

Epoch: 6| Step: 6
Training loss: 0.08872054125740095
Validation loss: 2.425601397130466

Epoch: 6| Step: 7
Training loss: 0.1551868329154805
Validation loss: 2.3888066841984155

Epoch: 6| Step: 8
Training loss: 0.14173763577252635
Validation loss: 2.408493778549322

Epoch: 6| Step: 9
Training loss: 0.1532512800955088
Validation loss: 2.3979568558332103

Epoch: 6| Step: 10
Training loss: 0.20459980360018906
Validation loss: 2.3881041436588766

Epoch: 6| Step: 11
Training loss: 0.12570227104072387
Validation loss: 2.3743204748736235

Epoch: 6| Step: 12
Training loss: 0.20570519263376186
Validation loss: 2.3853320178259163

Epoch: 6| Step: 13
Training loss: 0.1735813714754915
Validation loss: 2.369372016957943

Epoch: 436| Step: 0
Training loss: 0.20340069071571323
Validation loss: 2.3684373012870004

Epoch: 6| Step: 1
Training loss: 0.10555225175084719
Validation loss: 2.36865476111127

Epoch: 6| Step: 2
Training loss: 0.15622445136050372
Validation loss: 2.3627435414026166

Epoch: 6| Step: 3
Training loss: 0.16378358565675608
Validation loss: 2.3157565028352742

Epoch: 6| Step: 4
Training loss: 0.23106509980887152
Validation loss: 2.3519713202084667

Epoch: 6| Step: 5
Training loss: 0.13555859424377922
Validation loss: 2.3704785705175797

Epoch: 6| Step: 6
Training loss: 0.18861625119972208
Validation loss: 2.3545139509241775

Epoch: 6| Step: 7
Training loss: 0.12547657685671365
Validation loss: 2.367085924178893

Epoch: 6| Step: 8
Training loss: 0.11300838426800683
Validation loss: 2.376483641647781

Epoch: 6| Step: 9
Training loss: 0.13968257886850266
Validation loss: 2.3653284223213413

Epoch: 6| Step: 10
Training loss: 0.1565651933168078
Validation loss: 2.388360739056522

Epoch: 6| Step: 11
Training loss: 0.11209465372148258
Validation loss: 2.38993851007854

Epoch: 6| Step: 12
Training loss: 0.19577026129326405
Validation loss: 2.3872548685377724

Epoch: 6| Step: 13
Training loss: 0.14621325516246053
Validation loss: 2.3918218220691645

Epoch: 437| Step: 0
Training loss: 0.13334138831627948
Validation loss: 2.407005945624589

Epoch: 6| Step: 1
Training loss: 0.14851563053843464
Validation loss: 2.3953125661001198

Epoch: 6| Step: 2
Training loss: 0.13281846033073433
Validation loss: 2.4151210527588405

Epoch: 6| Step: 3
Training loss: 0.10832753740985172
Validation loss: 2.406718032379548

Epoch: 6| Step: 4
Training loss: 0.11633372831972083
Validation loss: 2.4165377393312446

Epoch: 6| Step: 5
Training loss: 0.1457111678575455
Validation loss: 2.364149751999544

Epoch: 6| Step: 6
Training loss: 0.23686732108620911
Validation loss: 2.3825905284781177

Epoch: 6| Step: 7
Training loss: 0.1328008239886957
Validation loss: 2.392237527531723

Epoch: 6| Step: 8
Training loss: 0.10760617918146353
Validation loss: 2.4159257023028236

Epoch: 6| Step: 9
Training loss: 0.19350982361630584
Validation loss: 2.3830316322789202

Epoch: 6| Step: 10
Training loss: 0.12833086838408875
Validation loss: 2.3861773782054754

Epoch: 6| Step: 11
Training loss: 0.21331795841155224
Validation loss: 2.3771206358785655

Epoch: 6| Step: 12
Training loss: 0.08567816172977212
Validation loss: 2.370064121086971

Epoch: 6| Step: 13
Training loss: 0.27988659682447364
Validation loss: 2.379295748431573

Epoch: 438| Step: 0
Training loss: 0.13925072249331258
Validation loss: 2.3579110404568686

Epoch: 6| Step: 1
Training loss: 0.13431372409775752
Validation loss: 2.3639346979489537

Epoch: 6| Step: 2
Training loss: 0.1210768326355491
Validation loss: 2.343204966514418

Epoch: 6| Step: 3
Training loss: 0.11613135457847933
Validation loss: 2.358731510298498

Epoch: 6| Step: 4
Training loss: 0.10286421312997894
Validation loss: 2.3714229657048818

Epoch: 6| Step: 5
Training loss: 0.12504596908023827
Validation loss: 2.352982603793974

Epoch: 6| Step: 6
Training loss: 0.1102550134865075
Validation loss: 2.3543048393028654

Epoch: 6| Step: 7
Training loss: 0.21811102458921156
Validation loss: 2.370114148057544

Epoch: 6| Step: 8
Training loss: 0.2341677146440747
Validation loss: 2.376934935341864

Epoch: 6| Step: 9
Training loss: 0.0996868075672604
Validation loss: 2.3973253124586114

Epoch: 6| Step: 10
Training loss: 0.16059330874380762
Validation loss: 2.3976902849462185

Epoch: 6| Step: 11
Training loss: 0.23677612434015938
Validation loss: 2.4342761448102936

Epoch: 6| Step: 12
Training loss: 0.1619425742765166
Validation loss: 2.439837249947577

Epoch: 6| Step: 13
Training loss: 0.13733055961682572
Validation loss: 2.463349516681373

Epoch: 439| Step: 0
Training loss: 0.20365516542839826
Validation loss: 2.418703231704902

Epoch: 6| Step: 1
Training loss: 0.16041559643718695
Validation loss: 2.4354072265840645

Epoch: 6| Step: 2
Training loss: 0.1954230853773982
Validation loss: 2.4174795753125298

Epoch: 6| Step: 3
Training loss: 0.10114513434133537
Validation loss: 2.4105034811054478

Epoch: 6| Step: 4
Training loss: 0.14240875374118844
Validation loss: 2.398675643077171

Epoch: 6| Step: 5
Training loss: 0.21501035299436194
Validation loss: 2.337416241963429

Epoch: 6| Step: 6
Training loss: 0.15337044813393666
Validation loss: 2.370911148910481

Epoch: 6| Step: 7
Training loss: 0.11949590179017927
Validation loss: 2.364303071275355

Epoch: 6| Step: 8
Training loss: 0.11527495962654959
Validation loss: 2.3484784060666417

Epoch: 6| Step: 9
Training loss: 0.10111354670895942
Validation loss: 2.363716406926734

Epoch: 6| Step: 10
Training loss: 0.17791164905551238
Validation loss: 2.3291609241119016

Epoch: 6| Step: 11
Training loss: 0.23254645238611232
Validation loss: 2.3487626537594752

Epoch: 6| Step: 12
Training loss: 0.11884126026932003
Validation loss: 2.366999056824071

Epoch: 6| Step: 13
Training loss: 0.11395191750199853
Validation loss: 2.3552051322458705

Epoch: 440| Step: 0
Training loss: 0.11269508176677494
Validation loss: 2.337292191035085

Epoch: 6| Step: 1
Training loss: 0.214528589572511
Validation loss: 2.3791328075914637

Epoch: 6| Step: 2
Training loss: 0.12638826150295965
Validation loss: 2.3741415941169115

Epoch: 6| Step: 3
Training loss: 0.20095026902640892
Validation loss: 2.3836113195777107

Epoch: 6| Step: 4
Training loss: 0.16521827853824428
Validation loss: 2.38535989028447

Epoch: 6| Step: 5
Training loss: 0.1563291528011242
Validation loss: 2.392534411803054

Epoch: 6| Step: 6
Training loss: 0.15714693718748035
Validation loss: 2.393587611657341

Epoch: 6| Step: 7
Training loss: 0.2003318600069504
Validation loss: 2.4170998733378455

Epoch: 6| Step: 8
Training loss: 0.1374151612941155
Validation loss: 2.3662691693588838

Epoch: 6| Step: 9
Training loss: 0.17461956600344122
Validation loss: 2.3767517529254016

Epoch: 6| Step: 10
Training loss: 0.0995912582153373
Validation loss: 2.35727881748987

Epoch: 6| Step: 11
Training loss: 0.13450274882202054
Validation loss: 2.358677615746609

Epoch: 6| Step: 12
Training loss: 0.13094664268621434
Validation loss: 2.358622143381958

Epoch: 6| Step: 13
Training loss: 0.12135037026040388
Validation loss: 2.3529749460333518

Epoch: 441| Step: 0
Training loss: 0.0988454886400235
Validation loss: 2.365233598938644

Epoch: 6| Step: 1
Training loss: 0.09769337901963267
Validation loss: 2.3873221530184425

Epoch: 6| Step: 2
Training loss: 0.21117952378816232
Validation loss: 2.3545647122295694

Epoch: 6| Step: 3
Training loss: 0.1123232577353611
Validation loss: 2.364161707277131

Epoch: 6| Step: 4
Training loss: 0.08522900953022323
Validation loss: 2.3458959182902945

Epoch: 6| Step: 5
Training loss: 0.1297062843001401
Validation loss: 2.3822253002150586

Epoch: 6| Step: 6
Training loss: 0.12087810064908106
Validation loss: 2.3705428559087514

Epoch: 6| Step: 7
Training loss: 0.08044479902536474
Validation loss: 2.3809253591587702

Epoch: 6| Step: 8
Training loss: 0.24549479484187167
Validation loss: 2.3551581956609375

Epoch: 6| Step: 9
Training loss: 0.1282002158477085
Validation loss: 2.3747539695069717

Epoch: 6| Step: 10
Training loss: 0.09823019170613957
Validation loss: 2.3775152284514838

Epoch: 6| Step: 11
Training loss: 0.24733420742180143
Validation loss: 2.374930291699123

Epoch: 6| Step: 12
Training loss: 0.07477892738398659
Validation loss: 2.3654529171857477

Epoch: 6| Step: 13
Training loss: 0.0911866255712384
Validation loss: 2.4055620351862297

Epoch: 442| Step: 0
Training loss: 0.14388235156734258
Validation loss: 2.393814414022042

Epoch: 6| Step: 1
Training loss: 0.08861221163169097
Validation loss: 2.3736620401194157

Epoch: 6| Step: 2
Training loss: 0.10318928687156059
Validation loss: 2.386020343457412

Epoch: 6| Step: 3
Training loss: 0.12092869030361217
Validation loss: 2.3885889773884426

Epoch: 6| Step: 4
Training loss: 0.1393459485229838
Validation loss: 2.3733174927852168

Epoch: 6| Step: 5
Training loss: 0.08650552443650743
Validation loss: 2.3782040152095614

Epoch: 6| Step: 6
Training loss: 0.21018889716027428
Validation loss: 2.3889765897034194

Epoch: 6| Step: 7
Training loss: 0.10666895043066002
Validation loss: 2.3737992088379953

Epoch: 6| Step: 8
Training loss: 0.1834325996244774
Validation loss: 2.3795754885722293

Epoch: 6| Step: 9
Training loss: 0.06456731665273659
Validation loss: 2.3814493423329464

Epoch: 6| Step: 10
Training loss: 0.11729464004250259
Validation loss: 2.384583269901902

Epoch: 6| Step: 11
Training loss: 0.10672545534853506
Validation loss: 2.370946122140962

Epoch: 6| Step: 12
Training loss: 0.15294390231116312
Validation loss: 2.4138216691766994

Epoch: 6| Step: 13
Training loss: 0.27863115052134385
Validation loss: 2.3690289861802336

Epoch: 443| Step: 0
Training loss: 0.07592819434514199
Validation loss: 2.3728682034441158

Epoch: 6| Step: 1
Training loss: 0.09851314347943627
Validation loss: 2.3517194259558107

Epoch: 6| Step: 2
Training loss: 0.10305487459264225
Validation loss: 2.347971764929366

Epoch: 6| Step: 3
Training loss: 0.16286576422102708
Validation loss: 2.359643200649272

Epoch: 6| Step: 4
Training loss: 0.11463965084971733
Validation loss: 2.363172888824557

Epoch: 6| Step: 5
Training loss: 0.10754013487769266
Validation loss: 2.365130178897783

Epoch: 6| Step: 6
Training loss: 0.18086779679861503
Validation loss: 2.3617626339258613

Epoch: 6| Step: 7
Training loss: 0.12669266612204788
Validation loss: 2.382225077451227

Epoch: 6| Step: 8
Training loss: 0.07429106853110248
Validation loss: 2.3918018365323825

Epoch: 6| Step: 9
Training loss: 0.28966675569893624
Validation loss: 2.387900873096264

Epoch: 6| Step: 10
Training loss: 0.18280293203241607
Validation loss: 2.3766770651109086

Epoch: 6| Step: 11
Training loss: 0.13919135965229767
Validation loss: 2.3909841942285186

Epoch: 6| Step: 12
Training loss: 0.1339250972842158
Validation loss: 2.3843138555092356

Epoch: 6| Step: 13
Training loss: 0.13193079044009542
Validation loss: 2.3642414704744628

Epoch: 444| Step: 0
Training loss: 0.14751122735014913
Validation loss: 2.3771630579865133

Epoch: 6| Step: 1
Training loss: 0.09437539201617137
Validation loss: 2.378109482610584

Epoch: 6| Step: 2
Training loss: 0.20752707074998777
Validation loss: 2.362702012712651

Epoch: 6| Step: 3
Training loss: 0.17310451060110313
Validation loss: 2.3679910603152603

Epoch: 6| Step: 4
Training loss: 0.10368941221980252
Validation loss: 2.3924492461380167

Epoch: 6| Step: 5
Training loss: 0.2297988871287041
Validation loss: 2.3964579231305425

Epoch: 6| Step: 6
Training loss: 0.1798011482581611
Validation loss: 2.460633000216513

Epoch: 6| Step: 7
Training loss: 0.1451820849658082
Validation loss: 2.43032501670437

Epoch: 6| Step: 8
Training loss: 0.21805790851741544
Validation loss: 2.4091815765667546

Epoch: 6| Step: 9
Training loss: 0.08746566290312312
Validation loss: 2.4117369528820083

Epoch: 6| Step: 10
Training loss: 0.13686972184433888
Validation loss: 2.3644245538549202

Epoch: 6| Step: 11
Training loss: 0.11981383451998097
Validation loss: 2.3754387856601964

Epoch: 6| Step: 12
Training loss: 0.1427528864920275
Validation loss: 2.3672863229501395

Epoch: 6| Step: 13
Training loss: 0.13456496212846675
Validation loss: 2.3534550569107178

Epoch: 445| Step: 0
Training loss: 0.08201596991960117
Validation loss: 2.3670925144472865

Epoch: 6| Step: 1
Training loss: 0.149251119737642
Validation loss: 2.358562500446015

Epoch: 6| Step: 2
Training loss: 0.1125123219232344
Validation loss: 2.378985788243619

Epoch: 6| Step: 3
Training loss: 0.26637153343350906
Validation loss: 2.365264779929692

Epoch: 6| Step: 4
Training loss: 0.13484502609418242
Validation loss: 2.3903727673499513

Epoch: 6| Step: 5
Training loss: 0.10677103201529772
Validation loss: 2.3440804000462325

Epoch: 6| Step: 6
Training loss: 0.11754993579225681
Validation loss: 2.3503963593511954

Epoch: 6| Step: 7
Training loss: 0.12293855501186711
Validation loss: 2.3441793353439935

Epoch: 6| Step: 8
Training loss: 0.10050459229832913
Validation loss: 2.3262350853655342

Epoch: 6| Step: 9
Training loss: 0.12243679727388682
Validation loss: 2.353724331852861

Epoch: 6| Step: 10
Training loss: 0.15477848339438663
Validation loss: 2.3744800151675727

Epoch: 6| Step: 11
Training loss: 0.19483136998104567
Validation loss: 2.374270146469219

Epoch: 6| Step: 12
Training loss: 0.14698634289859383
Validation loss: 2.3453566930890646

Epoch: 6| Step: 13
Training loss: 0.23121189467188002
Validation loss: 2.359026829874846

Epoch: 446| Step: 0
Training loss: 0.10640250228802244
Validation loss: 2.3141249130817036

Epoch: 6| Step: 1
Training loss: 0.14359688300906256
Validation loss: 2.31230711693772

Epoch: 6| Step: 2
Training loss: 0.20552273646628919
Validation loss: 2.323037794999757

Epoch: 6| Step: 3
Training loss: 0.20031440728004105
Validation loss: 2.308545971780943

Epoch: 6| Step: 4
Training loss: 0.12049604386249999
Validation loss: 2.2970637096829294

Epoch: 6| Step: 5
Training loss: 0.11497908941147555
Validation loss: 2.3277650543729127

Epoch: 6| Step: 6
Training loss: 0.18126388159571882
Validation loss: 2.3289430096134733

Epoch: 6| Step: 7
Training loss: 0.12872067010924096
Validation loss: 2.362342757012932

Epoch: 6| Step: 8
Training loss: 0.1723206659214726
Validation loss: 2.3445789689629604

Epoch: 6| Step: 9
Training loss: 0.0751972291132426
Validation loss: 2.382623690759002

Epoch: 6| Step: 10
Training loss: 0.2252412780540127
Validation loss: 2.4151572038476536

Epoch: 6| Step: 11
Training loss: 0.22240306446430683
Validation loss: 2.3933751625463886

Epoch: 6| Step: 12
Training loss: 0.09694835631133994
Validation loss: 2.4068251174078394

Epoch: 6| Step: 13
Training loss: 0.14253014580270265
Validation loss: 2.402784874719848

Epoch: 447| Step: 0
Training loss: 0.21102850328485614
Validation loss: 2.4097036838030186

Epoch: 6| Step: 1
Training loss: 0.15612002569716102
Validation loss: 2.402943583630813

Epoch: 6| Step: 2
Training loss: 0.24430293981760123
Validation loss: 2.3973261348081274

Epoch: 6| Step: 3
Training loss: 0.186555919515188
Validation loss: 2.391399545735166

Epoch: 6| Step: 4
Training loss: 0.1117269082858608
Validation loss: 2.3949750999361834

Epoch: 6| Step: 5
Training loss: 0.11606786239039783
Validation loss: 2.3825955388145243

Epoch: 6| Step: 6
Training loss: 0.1866899615803315
Validation loss: 2.38994896225529

Epoch: 6| Step: 7
Training loss: 0.12294470996179391
Validation loss: 2.4276918355009394

Epoch: 6| Step: 8
Training loss: 0.11295923965964794
Validation loss: 2.3897222950904933

Epoch: 6| Step: 9
Training loss: 0.15048395703914896
Validation loss: 2.3788257763550216

Epoch: 6| Step: 10
Training loss: 0.1227436302636376
Validation loss: 2.352281317689178

Epoch: 6| Step: 11
Training loss: 0.18327119575299294
Validation loss: 2.392289201922288

Epoch: 6| Step: 12
Training loss: 0.10912169347584261
Validation loss: 2.3549969234829207

Epoch: 6| Step: 13
Training loss: 0.09478700813262425
Validation loss: 2.353474127372519

Epoch: 448| Step: 0
Training loss: 0.22858803571806302
Validation loss: 2.345100667751674

Epoch: 6| Step: 1
Training loss: 0.12279333378206789
Validation loss: 2.3520020535505224

Epoch: 6| Step: 2
Training loss: 0.10657634894022704
Validation loss: 2.355316585471208

Epoch: 6| Step: 3
Training loss: 0.13502938264289682
Validation loss: 2.360682797012558

Epoch: 6| Step: 4
Training loss: 0.14648993163695945
Validation loss: 2.373218449994676

Epoch: 6| Step: 5
Training loss: 0.2117706376009323
Validation loss: 2.406126311348323

Epoch: 6| Step: 6
Training loss: 0.1318409106411548
Validation loss: 2.427670749217344

Epoch: 6| Step: 7
Training loss: 0.1885116623526421
Validation loss: 2.448137355239212

Epoch: 6| Step: 8
Training loss: 0.10627082206953106
Validation loss: 2.447058854428821

Epoch: 6| Step: 9
Training loss: 0.13850972272214207
Validation loss: 2.4607223580773696

Epoch: 6| Step: 10
Training loss: 0.11690085640145714
Validation loss: 2.441673133094247

Epoch: 6| Step: 11
Training loss: 0.25498118639713135
Validation loss: 2.437179822063194

Epoch: 6| Step: 12
Training loss: 0.1406446946446037
Validation loss: 2.4172257005592894

Epoch: 6| Step: 13
Training loss: 0.14253856162278292
Validation loss: 2.399849954652376

Epoch: 449| Step: 0
Training loss: 0.13141223496949458
Validation loss: 2.400814260150245

Epoch: 6| Step: 1
Training loss: 0.20050064621081584
Validation loss: 2.372759176957444

Epoch: 6| Step: 2
Training loss: 0.1459968592390833
Validation loss: 2.384095577672024

Epoch: 6| Step: 3
Training loss: 0.09754603842590884
Validation loss: 2.389285121816739

Epoch: 6| Step: 4
Training loss: 0.1278410597280135
Validation loss: 2.4157326144637215

Epoch: 6| Step: 5
Training loss: 0.1845071472590151
Validation loss: 2.41104748505544

Epoch: 6| Step: 6
Training loss: 0.10641384972168141
Validation loss: 2.3786956291366628

Epoch: 6| Step: 7
Training loss: 0.14227835613435474
Validation loss: 2.38708216416872

Epoch: 6| Step: 8
Training loss: 0.19733857231868493
Validation loss: 2.359352805490895

Epoch: 6| Step: 9
Training loss: 0.1795526081126298
Validation loss: 2.390377687373084

Epoch: 6| Step: 10
Training loss: 0.09872300207502914
Validation loss: 2.3974077852784457

Epoch: 6| Step: 11
Training loss: 0.13520886604290347
Validation loss: 2.3411824185890313

Epoch: 6| Step: 12
Training loss: 0.248839067011919
Validation loss: 2.373890529654678

Epoch: 6| Step: 13
Training loss: 0.11958008373255812
Validation loss: 2.388584613937626

Epoch: 450| Step: 0
Training loss: 0.10385969398929328
Validation loss: 2.3872712505856675

Epoch: 6| Step: 1
Training loss: 0.20027040143331676
Validation loss: 2.419075870017321

Epoch: 6| Step: 2
Training loss: 0.07140567139176184
Validation loss: 2.411164442962091

Epoch: 6| Step: 3
Training loss: 0.15552005735903413
Validation loss: 2.417442388932609

Epoch: 6| Step: 4
Training loss: 0.1089599517063254
Validation loss: 2.386118781272013

Epoch: 6| Step: 5
Training loss: 0.1142145547735635
Validation loss: 2.400731441170293

Epoch: 6| Step: 6
Training loss: 0.1415483506291376
Validation loss: 2.3921518465319447

Epoch: 6| Step: 7
Training loss: 0.22992025182308531
Validation loss: 2.381854633272606

Epoch: 6| Step: 8
Training loss: 0.11948672038625203
Validation loss: 2.3883537974384437

Epoch: 6| Step: 9
Training loss: 0.1217320753450006
Validation loss: 2.385875627838686

Epoch: 6| Step: 10
Training loss: 0.12967276259643798
Validation loss: 2.363813178264508

Epoch: 6| Step: 11
Training loss: 0.18497718892710577
Validation loss: 2.4135855585144523

Epoch: 6| Step: 12
Training loss: 0.21096131402270168
Validation loss: 2.359693581094257

Epoch: 6| Step: 13
Training loss: 0.1220199824527356
Validation loss: 2.3718797800912834

Testing loss: 2.500797492091095
