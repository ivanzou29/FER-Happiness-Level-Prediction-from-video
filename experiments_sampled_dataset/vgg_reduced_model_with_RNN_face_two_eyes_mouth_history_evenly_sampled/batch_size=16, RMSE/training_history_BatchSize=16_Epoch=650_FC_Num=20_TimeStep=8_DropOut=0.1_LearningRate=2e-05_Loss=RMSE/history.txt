Epoch: 1| Step: 0
Training loss: 6.256018830410064
Validation loss: 5.803216989992713

Epoch: 6| Step: 1
Training loss: 6.087200068109266
Validation loss: 5.777533177882194

Epoch: 6| Step: 2
Training loss: 5.282206251260867
Validation loss: 5.752642631963864

Epoch: 6| Step: 3
Training loss: 4.602149187649803
Validation loss: 5.725144615555356

Epoch: 6| Step: 4
Training loss: 5.627479176425579
Validation loss: 5.695454007041404

Epoch: 6| Step: 5
Training loss: 5.268404897517328
Validation loss: 5.661581679867819

Epoch: 6| Step: 6
Training loss: 7.038211614429634
Validation loss: 5.624380302247613

Epoch: 6| Step: 7
Training loss: 5.298212203306841
Validation loss: 5.582832959888653

Epoch: 6| Step: 8
Training loss: 6.819933833810897
Validation loss: 5.538231127617003

Epoch: 6| Step: 9
Training loss: 4.54853460168273
Validation loss: 5.489539676665535

Epoch: 6| Step: 10
Training loss: 6.080827205502047
Validation loss: 5.43862931977213

Epoch: 6| Step: 11
Training loss: 4.5118197871533
Validation loss: 5.38456249772272

Epoch: 6| Step: 12
Training loss: 5.283766107654228
Validation loss: 5.330174917692253

Epoch: 6| Step: 13
Training loss: 5.250610316087669
Validation loss: 5.275092290177774

Epoch: 2| Step: 0
Training loss: 4.8301687513611755
Validation loss: 5.219919998190181

Epoch: 6| Step: 1
Training loss: 4.074701852949451
Validation loss: 5.166309915320433

Epoch: 6| Step: 2
Training loss: 6.19664420093871
Validation loss: 5.1133350165273805

Epoch: 6| Step: 3
Training loss: 5.2054540788242525
Validation loss: 5.064282242206595

Epoch: 6| Step: 4
Training loss: 4.645330746868595
Validation loss: 5.016902780882108

Epoch: 6| Step: 5
Training loss: 5.089075670234052
Validation loss: 4.968032724259604

Epoch: 6| Step: 6
Training loss: 4.5056100420016305
Validation loss: 4.917735928159033

Epoch: 6| Step: 7
Training loss: 4.8254999721986795
Validation loss: 4.864092837841235

Epoch: 6| Step: 8
Training loss: 5.579111733236179
Validation loss: 4.807742903835215

Epoch: 6| Step: 9
Training loss: 5.272306736406173
Validation loss: 4.754645549405824

Epoch: 6| Step: 10
Training loss: 5.051024818300529
Validation loss: 4.706594624005607

Epoch: 6| Step: 11
Training loss: 4.08326718542796
Validation loss: 4.655173759348672

Epoch: 6| Step: 12
Training loss: 5.236406256702157
Validation loss: 4.605432744533285

Epoch: 6| Step: 13
Training loss: 4.13144896427798
Validation loss: 4.560906491974836

Epoch: 3| Step: 0
Training loss: 5.1721567497839755
Validation loss: 4.534957492614366

Epoch: 6| Step: 1
Training loss: 3.5765902630222963
Validation loss: 4.513724082712683

Epoch: 6| Step: 2
Training loss: 5.136951560194734
Validation loss: 4.493558801733262

Epoch: 6| Step: 3
Training loss: 3.658424969497979
Validation loss: 4.470848297071774

Epoch: 6| Step: 4
Training loss: 4.365555296159155
Validation loss: 4.447599413481325

Epoch: 6| Step: 5
Training loss: 3.589493860039971
Validation loss: 4.420265789950415

Epoch: 6| Step: 6
Training loss: 3.4685250974035577
Validation loss: 4.392831936045829

Epoch: 6| Step: 7
Training loss: 4.50668601203092
Validation loss: 4.367477827356956

Epoch: 6| Step: 8
Training loss: 6.0783603495164895
Validation loss: 4.349674318837743

Epoch: 6| Step: 9
Training loss: 4.2073603849315555
Validation loss: 4.32633796494735

Epoch: 6| Step: 10
Training loss: 5.2151462195755105
Validation loss: 4.300734806211447

Epoch: 6| Step: 11
Training loss: 4.2514527025944275
Validation loss: 4.28391737210727

Epoch: 6| Step: 12
Training loss: 4.8403456014402355
Validation loss: 4.268674273608885

Epoch: 6| Step: 13
Training loss: 3.772392681155094
Validation loss: 4.249888764288367

Epoch: 4| Step: 0
Training loss: 4.84065275535236
Validation loss: 4.231671383530817

Epoch: 6| Step: 1
Training loss: 4.328915079765629
Validation loss: 4.212082222061835

Epoch: 6| Step: 2
Training loss: 3.4465610724333877
Validation loss: 4.1983868678535865

Epoch: 6| Step: 3
Training loss: 2.8923712327364592
Validation loss: 4.183309198828019

Epoch: 6| Step: 4
Training loss: 5.3696269303911635
Validation loss: 4.167955240327171

Epoch: 6| Step: 5
Training loss: 4.083509843605408
Validation loss: 4.151354052376047

Epoch: 6| Step: 6
Training loss: 4.3621629120192305
Validation loss: 4.132354144564343

Epoch: 6| Step: 7
Training loss: 4.604963046742638
Validation loss: 4.119487105220983

Epoch: 6| Step: 8
Training loss: 4.38886548826093
Validation loss: 4.106488694654929

Epoch: 6| Step: 9
Training loss: 4.554401054993572
Validation loss: 4.093675848351853

Epoch: 6| Step: 10
Training loss: 3.6897663974993367
Validation loss: 4.079657314880084

Epoch: 6| Step: 11
Training loss: 4.125000924774991
Validation loss: 4.069176573388436

Epoch: 6| Step: 12
Training loss: 4.257733209554144
Validation loss: 4.059509878244944

Epoch: 6| Step: 13
Training loss: 4.4173012523489845
Validation loss: 4.046443027847737

Epoch: 5| Step: 0
Training loss: 4.7279520813761495
Validation loss: 4.03504071299911

Epoch: 6| Step: 1
Training loss: 4.48909667785784
Validation loss: 4.020553793805096

Epoch: 6| Step: 2
Training loss: 3.735185479355148
Validation loss: 4.008371881451377

Epoch: 6| Step: 3
Training loss: 3.6016886724187844
Validation loss: 3.992917589559811

Epoch: 6| Step: 4
Training loss: 3.4233641845986917
Validation loss: 3.976911933706291

Epoch: 6| Step: 5
Training loss: 3.6185416206094696
Validation loss: 3.9667253420812445

Epoch: 6| Step: 6
Training loss: 4.040488841631134
Validation loss: 3.9528867484472547

Epoch: 6| Step: 7
Training loss: 4.601546334463328
Validation loss: 3.939646328463064

Epoch: 6| Step: 8
Training loss: 3.8259639946399457
Validation loss: 3.928346634990902

Epoch: 6| Step: 9
Training loss: 3.484320122667279
Validation loss: 3.9176503117697625

Epoch: 6| Step: 10
Training loss: 5.537174478783931
Validation loss: 3.9070252769376936

Epoch: 6| Step: 11
Training loss: 3.8822353862875776
Validation loss: 3.8975043304765973

Epoch: 6| Step: 12
Training loss: 4.3434039739649695
Validation loss: 3.888929736796453

Epoch: 6| Step: 13
Training loss: 3.234993106180242
Validation loss: 3.8775122970392726

Epoch: 6| Step: 0
Training loss: 4.699122148061523
Validation loss: 3.870748658799854

Epoch: 6| Step: 1
Training loss: 3.846012845022381
Validation loss: 3.860684737926095

Epoch: 6| Step: 2
Training loss: 3.7056726633224515
Validation loss: 3.8501435536348656

Epoch: 6| Step: 3
Training loss: 3.4580123629859214
Validation loss: 3.8416481944581364

Epoch: 6| Step: 4
Training loss: 3.96051444478598
Validation loss: 3.83116232256063

Epoch: 6| Step: 5
Training loss: 4.237287920030491
Validation loss: 3.820638029779974

Epoch: 6| Step: 6
Training loss: 3.908042069395122
Validation loss: 3.813958170083786

Epoch: 6| Step: 7
Training loss: 4.712352331463514
Validation loss: 3.8064088798590205

Epoch: 6| Step: 8
Training loss: 4.166987495786262
Validation loss: 3.796704017229063

Epoch: 6| Step: 9
Training loss: 2.9752118908731964
Validation loss: 3.7869096579450843

Epoch: 6| Step: 10
Training loss: 3.4355044034292033
Validation loss: 3.774966296321451

Epoch: 6| Step: 11
Training loss: 4.106043868791638
Validation loss: 3.7664293497196226

Epoch: 6| Step: 12
Training loss: 3.868591423667209
Validation loss: 3.756512666939993

Epoch: 6| Step: 13
Training loss: 4.5921686266199435
Validation loss: 3.745388552272646

Epoch: 7| Step: 0
Training loss: 3.9649073703716513
Validation loss: 3.733010988467097

Epoch: 6| Step: 1
Training loss: 4.910090990019781
Validation loss: 3.7197443700423216

Epoch: 6| Step: 2
Training loss: 3.804526950339153
Validation loss: 3.706828272482836

Epoch: 6| Step: 3
Training loss: 3.286561572372278
Validation loss: 3.6951418240625364

Epoch: 6| Step: 4
Training loss: 2.9620707011725966
Validation loss: 3.694383520532317

Epoch: 6| Step: 5
Training loss: 4.191560968136975
Validation loss: 3.6867361012683175

Epoch: 6| Step: 6
Training loss: 4.787827100610142
Validation loss: 3.6779850358465054

Epoch: 6| Step: 7
Training loss: 4.034378611993687
Validation loss: 3.6662177643569653

Epoch: 6| Step: 8
Training loss: 3.834043450855041
Validation loss: 3.652072772070979

Epoch: 6| Step: 9
Training loss: 3.0768008409575347
Validation loss: 3.6483267086389413

Epoch: 6| Step: 10
Training loss: 3.9122529558181203
Validation loss: 3.6418363177457014

Epoch: 6| Step: 11
Training loss: 3.9699942973598006
Validation loss: 3.643635039552075

Epoch: 6| Step: 12
Training loss: 3.5340358581537212
Validation loss: 3.6309673272515193

Epoch: 6| Step: 13
Training loss: 2.6882560021507187
Validation loss: 3.614649671174141

Epoch: 8| Step: 0
Training loss: 3.2846449954251797
Validation loss: 3.6098078241941756

Epoch: 6| Step: 1
Training loss: 3.5885096282340823
Validation loss: 3.611529426046871

Epoch: 6| Step: 2
Training loss: 4.048721893580444
Validation loss: 3.604131475207213

Epoch: 6| Step: 3
Training loss: 4.127540961743341
Validation loss: 3.5941452001676297

Epoch: 6| Step: 4
Training loss: 3.4966563193062368
Validation loss: 3.5921054867140727

Epoch: 6| Step: 5
Training loss: 3.896293096221407
Validation loss: 3.572658270569375

Epoch: 6| Step: 6
Training loss: 3.20376148878189
Validation loss: 3.573473580783566

Epoch: 6| Step: 7
Training loss: 3.3362918281434286
Validation loss: 3.5780530220985427

Epoch: 6| Step: 8
Training loss: 3.930155853209587
Validation loss: 3.575408010034652

Epoch: 6| Step: 9
Training loss: 4.145454325516252
Validation loss: 3.5610662992525994

Epoch: 6| Step: 10
Training loss: 3.4379485791296034
Validation loss: 3.545500187776419

Epoch: 6| Step: 11
Training loss: 3.2720380536597014
Validation loss: 3.5418439170498

Epoch: 6| Step: 12
Training loss: 4.249253151290236
Validation loss: 3.5378151544262413

Epoch: 6| Step: 13
Training loss: 5.059538363481207
Validation loss: 3.53553361008904

Epoch: 9| Step: 0
Training loss: 3.8179107792752123
Validation loss: 3.5426919880162147

Epoch: 6| Step: 1
Training loss: 4.074385408264432
Validation loss: 3.5205078896894055

Epoch: 6| Step: 2
Training loss: 3.8005137648361416
Validation loss: 3.5173145809097095

Epoch: 6| Step: 3
Training loss: 3.6992277731377547
Validation loss: 3.513089207932114

Epoch: 6| Step: 4
Training loss: 3.583686071969301
Validation loss: 3.510653602479359

Epoch: 6| Step: 5
Training loss: 4.0038219312767955
Validation loss: 3.509289534487467

Epoch: 6| Step: 6
Training loss: 3.6179572783774083
Validation loss: 3.5056227669847635

Epoch: 6| Step: 7
Training loss: 4.035353353880405
Validation loss: 3.497285774902386

Epoch: 6| Step: 8
Training loss: 4.304061373333322
Validation loss: 3.4923805047121452

Epoch: 6| Step: 9
Training loss: 3.632907661094023
Validation loss: 3.488490122456316

Epoch: 6| Step: 10
Training loss: 3.5718874473054525
Validation loss: 3.486081635805769

Epoch: 6| Step: 11
Training loss: 3.22544623547948
Validation loss: 3.481696328422371

Epoch: 6| Step: 12
Training loss: 3.119955034176487
Validation loss: 3.476265490847341

Epoch: 6| Step: 13
Training loss: 3.0490922734006305
Validation loss: 3.4729967447652914

Epoch: 10| Step: 0
Training loss: 3.922324470205487
Validation loss: 3.471382489514393

Epoch: 6| Step: 1
Training loss: 4.181648151047058
Validation loss: 3.471789863056273

Epoch: 6| Step: 2
Training loss: 3.663957866809587
Validation loss: 3.4635599470646894

Epoch: 6| Step: 3
Training loss: 4.103264388355577
Validation loss: 3.455398407364096

Epoch: 6| Step: 4
Training loss: 3.1613578633783677
Validation loss: 3.448893170691947

Epoch: 6| Step: 5
Training loss: 4.3711816746490975
Validation loss: 3.444509853653207

Epoch: 6| Step: 6
Training loss: 3.1704713318182436
Validation loss: 3.4394675492319187

Epoch: 6| Step: 7
Training loss: 3.7800195126307403
Validation loss: 3.4341810758840885

Epoch: 6| Step: 8
Training loss: 2.9300543390124063
Validation loss: 3.4296419793444053

Epoch: 6| Step: 9
Training loss: 3.36003666948563
Validation loss: 3.428930127162713

Epoch: 6| Step: 10
Training loss: 3.502010721561701
Validation loss: 3.43507192032332

Epoch: 6| Step: 11
Training loss: 3.7262052288776104
Validation loss: 3.448664946714187

Epoch: 6| Step: 12
Training loss: 3.2474460837548222
Validation loss: 3.435632089672707

Epoch: 6| Step: 13
Training loss: 4.165308667453831
Validation loss: 3.4561153054283635

Epoch: 11| Step: 0
Training loss: 3.5100217119724584
Validation loss: 3.4534290279921023

Epoch: 6| Step: 1
Training loss: 2.8820776687734795
Validation loss: 3.4805003711983034

Epoch: 6| Step: 2
Training loss: 3.1926415059416593
Validation loss: 3.4882806679358236

Epoch: 6| Step: 3
Training loss: 4.358683213339557
Validation loss: 3.471217000897515

Epoch: 6| Step: 4
Training loss: 3.6801644763264236
Validation loss: 3.466560631409024

Epoch: 6| Step: 5
Training loss: 3.1791391860620806
Validation loss: 3.4576994849668097

Epoch: 6| Step: 6
Training loss: 4.020798019227748
Validation loss: 3.4633198074512856

Epoch: 6| Step: 7
Training loss: 4.102015878960031
Validation loss: 3.465985147532268

Epoch: 6| Step: 8
Training loss: 3.721633818760898
Validation loss: 3.464369373047492

Epoch: 6| Step: 9
Training loss: 4.148100471096445
Validation loss: 3.4605489222096573

Epoch: 6| Step: 10
Training loss: 3.609068490096986
Validation loss: 3.4511392348110164

Epoch: 6| Step: 11
Training loss: 3.5603245567935278
Validation loss: 3.452210742905527

Epoch: 6| Step: 12
Training loss: 3.634708689018739
Validation loss: 3.4578234883213566

Epoch: 6| Step: 13
Training loss: 3.636639685339856
Validation loss: 3.4571612200699877

Epoch: 12| Step: 0
Training loss: 3.1531323435672354
Validation loss: 3.454010200694863

Epoch: 6| Step: 1
Training loss: 3.777174337349475
Validation loss: 3.4452226061693696

Epoch: 6| Step: 2
Training loss: 3.6172669898376375
Validation loss: 3.438188473843423

Epoch: 6| Step: 3
Training loss: 3.288770069161123
Validation loss: 3.4366033598442907

Epoch: 6| Step: 4
Training loss: 4.155050233613025
Validation loss: 3.4369779770265643

Epoch: 6| Step: 5
Training loss: 3.2510518059312177
Validation loss: 3.4303880119509254

Epoch: 6| Step: 6
Training loss: 4.057535747716111
Validation loss: 3.423504712387851

Epoch: 6| Step: 7
Training loss: 2.4057182616235595
Validation loss: 3.4204455012095556

Epoch: 6| Step: 8
Training loss: 3.394816958362576
Validation loss: 3.416769103208639

Epoch: 6| Step: 9
Training loss: 4.023811989549971
Validation loss: 3.414415203440132

Epoch: 6| Step: 10
Training loss: 3.750441843069895
Validation loss: 3.4114602040155213

Epoch: 6| Step: 11
Training loss: 4.266128007344462
Validation loss: 3.401144273810637

Epoch: 6| Step: 12
Training loss: 4.08843672631879
Validation loss: 3.3937161205389987

Epoch: 6| Step: 13
Training loss: 3.1660794834707318
Validation loss: 3.383947970454218

Epoch: 13| Step: 0
Training loss: 3.2652822798349908
Validation loss: 3.3811823386503184

Epoch: 6| Step: 1
Training loss: 3.8458778260296547
Validation loss: 3.37906727214809

Epoch: 6| Step: 2
Training loss: 3.136229518490534
Validation loss: 3.3773341142290385

Epoch: 6| Step: 3
Training loss: 4.186499632724776
Validation loss: 3.3774037811624322

Epoch: 6| Step: 4
Training loss: 3.187790651720526
Validation loss: 3.3749963843152706

Epoch: 6| Step: 5
Training loss: 4.799930158742791
Validation loss: 3.3733806530823682

Epoch: 6| Step: 6
Training loss: 4.171290210213414
Validation loss: 3.370700689546577

Epoch: 6| Step: 7
Training loss: 3.6856969530916803
Validation loss: 3.3682053403310186

Epoch: 6| Step: 8
Training loss: 2.721374034656965
Validation loss: 3.3660237160036326

Epoch: 6| Step: 9
Training loss: 3.5786905299877256
Validation loss: 3.365088962232909

Epoch: 6| Step: 10
Training loss: 3.323172739779057
Validation loss: 3.3634469882311406

Epoch: 6| Step: 11
Training loss: 2.548186356584962
Validation loss: 3.3622690481582973

Epoch: 6| Step: 12
Training loss: 3.9836978112480836
Validation loss: 3.361502391368674

Epoch: 6| Step: 13
Training loss: 3.1558086728795485
Validation loss: 3.359612450264823

Epoch: 14| Step: 0
Training loss: 3.263152578281547
Validation loss: 3.35774936210014

Epoch: 6| Step: 1
Training loss: 3.211289138288158
Validation loss: 3.355976681566201

Epoch: 6| Step: 2
Training loss: 3.463511592571892
Validation loss: 3.3534877403097063

Epoch: 6| Step: 3
Training loss: 4.07428312022196
Validation loss: 3.352013112840989

Epoch: 6| Step: 4
Training loss: 3.58662171993904
Validation loss: 3.3509710155063748

Epoch: 6| Step: 5
Training loss: 3.005214926956498
Validation loss: 3.349909634841439

Epoch: 6| Step: 6
Training loss: 3.365428491662706
Validation loss: 3.3494040545467385

Epoch: 6| Step: 7
Training loss: 3.4529128894130823
Validation loss: 3.3491236982493975

Epoch: 6| Step: 8
Training loss: 4.0600479942454095
Validation loss: 3.343132593033417

Epoch: 6| Step: 9
Training loss: 4.078248471550394
Validation loss: 3.3415227845587876

Epoch: 6| Step: 10
Training loss: 3.946621940032872
Validation loss: 3.3399125808889365

Epoch: 6| Step: 11
Training loss: 3.0454170064281825
Validation loss: 3.337171441961793

Epoch: 6| Step: 12
Training loss: 4.226764667068803
Validation loss: 3.336055983962591

Epoch: 6| Step: 13
Training loss: 2.6104575098916487
Validation loss: 3.334238113130861

Epoch: 15| Step: 0
Training loss: 3.5770981827022035
Validation loss: 3.3334668460892383

Epoch: 6| Step: 1
Training loss: 3.325674094798595
Validation loss: 3.331027142747269

Epoch: 6| Step: 2
Training loss: 3.069008586733562
Validation loss: 3.3297418509437455

Epoch: 6| Step: 3
Training loss: 4.041024592939541
Validation loss: 3.3274585519359996

Epoch: 6| Step: 4
Training loss: 3.974325393916678
Validation loss: 3.3218706132746787

Epoch: 6| Step: 5
Training loss: 3.4135212414646223
Validation loss: 3.31482167995407

Epoch: 6| Step: 6
Training loss: 3.552516668443011
Validation loss: 3.308240112911439

Epoch: 6| Step: 7
Training loss: 2.5325057129263575
Validation loss: 3.3056862937594245

Epoch: 6| Step: 8
Training loss: 3.8582825137609675
Validation loss: 3.3061746271679513

Epoch: 6| Step: 9
Training loss: 3.592795336429251
Validation loss: 3.303353898461508

Epoch: 6| Step: 10
Training loss: 3.569929440439516
Validation loss: 3.2977865693227857

Epoch: 6| Step: 11
Training loss: 3.8091269408425648
Validation loss: 3.293580997173387

Epoch: 6| Step: 12
Training loss: 3.3476796099316246
Validation loss: 3.292012220017485

Epoch: 6| Step: 13
Training loss: 3.9764295154811125
Validation loss: 3.2912852475323615

Epoch: 16| Step: 0
Training loss: 2.8349400807663723
Validation loss: 3.289625177833806

Epoch: 6| Step: 1
Training loss: 3.3283010803351103
Validation loss: 3.2879115693264827

Epoch: 6| Step: 2
Training loss: 3.7427563961576507
Validation loss: 3.2869275517395793

Epoch: 6| Step: 3
Training loss: 4.013345865713768
Validation loss: 3.2859958905577487

Epoch: 6| Step: 4
Training loss: 2.402414410800248
Validation loss: 3.2864823617494427

Epoch: 6| Step: 5
Training loss: 3.957764326992902
Validation loss: 3.2833506386376166

Epoch: 6| Step: 6
Training loss: 3.2237626829337893
Validation loss: 3.282512311432567

Epoch: 6| Step: 7
Training loss: 3.8427857220658153
Validation loss: 3.2814787972916686

Epoch: 6| Step: 8
Training loss: 4.088315895148088
Validation loss: 3.279571335071211

Epoch: 6| Step: 9
Training loss: 3.0107037012521505
Validation loss: 3.2790691654306543

Epoch: 6| Step: 10
Training loss: 3.4968442313823824
Validation loss: 3.2775886386755833

Epoch: 6| Step: 11
Training loss: 3.3851093485312513
Validation loss: 3.276810071531475

Epoch: 6| Step: 12
Training loss: 3.5402827232954515
Validation loss: 3.275511764010218

Epoch: 6| Step: 13
Training loss: 4.467282781288649
Validation loss: 3.274508850597481

Epoch: 17| Step: 0
Training loss: 3.5242224789470544
Validation loss: 3.2730459161665646

Epoch: 6| Step: 1
Training loss: 3.5228923367397655
Validation loss: 3.2716369994915837

Epoch: 6| Step: 2
Training loss: 2.820063614364488
Validation loss: 3.2709909300141913

Epoch: 6| Step: 3
Training loss: 4.2673854897884524
Validation loss: 3.2695175540902977

Epoch: 6| Step: 4
Training loss: 3.6161369627273694
Validation loss: 3.2687744067559334

Epoch: 6| Step: 5
Training loss: 3.5437642038319703
Validation loss: 3.267464647670907

Epoch: 6| Step: 6
Training loss: 3.463784177316244
Validation loss: 3.26603479253216

Epoch: 6| Step: 7
Training loss: 3.448015532367886
Validation loss: 3.26448941425137

Epoch: 6| Step: 8
Training loss: 3.628223564392819
Validation loss: 3.264126834706516

Epoch: 6| Step: 9
Training loss: 3.653105467653554
Validation loss: 3.262762983145061

Epoch: 6| Step: 10
Training loss: 3.0913950887367223
Validation loss: 3.2606235236584147

Epoch: 6| Step: 11
Training loss: 3.542184829206095
Validation loss: 3.2600685606601294

Epoch: 6| Step: 12
Training loss: 3.5127035930452166
Validation loss: 3.2580540364061465

Epoch: 6| Step: 13
Training loss: 3.3288245383786768
Validation loss: 3.2587803412978698

Epoch: 18| Step: 0
Training loss: 3.222835725352731
Validation loss: 3.256248435669061

Epoch: 6| Step: 1
Training loss: 3.5367572341621694
Validation loss: 3.2554109868454484

Epoch: 6| Step: 2
Training loss: 4.088894592732676
Validation loss: 3.2538762243053783

Epoch: 6| Step: 3
Training loss: 4.179681111268482
Validation loss: 3.2530808419660624

Epoch: 6| Step: 4
Training loss: 3.634144134929822
Validation loss: 3.2522957646899147

Epoch: 6| Step: 5
Training loss: 3.27208556159895
Validation loss: 3.2507469148797097

Epoch: 6| Step: 6
Training loss: 2.852080666480665
Validation loss: 3.2492164885296413

Epoch: 6| Step: 7
Training loss: 3.4393821418711625
Validation loss: 3.248483580147572

Epoch: 6| Step: 8
Training loss: 3.5105038112309455
Validation loss: 3.24742660996675

Epoch: 6| Step: 9
Training loss: 3.6934249605824028
Validation loss: 3.2460205398410222

Epoch: 6| Step: 10
Training loss: 3.1371706664356402
Validation loss: 3.2453808691074757

Epoch: 6| Step: 11
Training loss: 2.674444290622139
Validation loss: 3.2436424875984375

Epoch: 6| Step: 12
Training loss: 3.921977980276151
Validation loss: 3.243477077929897

Epoch: 6| Step: 13
Training loss: 3.573387107610565
Validation loss: 3.242490517206795

Epoch: 19| Step: 0
Training loss: 3.173315763932431
Validation loss: 3.2411404993402124

Epoch: 6| Step: 1
Training loss: 4.333777967285191
Validation loss: 3.240199456437833

Epoch: 6| Step: 2
Training loss: 3.647638335503637
Validation loss: 3.2391758527206305

Epoch: 6| Step: 3
Training loss: 4.0962689053957995
Validation loss: 3.2383733005721607

Epoch: 6| Step: 4
Training loss: 3.511954871398235
Validation loss: 3.237087870662231

Epoch: 6| Step: 5
Training loss: 3.5662135796035996
Validation loss: 3.2364584808986963

Epoch: 6| Step: 6
Training loss: 3.306147692418915
Validation loss: 3.234868741198603

Epoch: 6| Step: 7
Training loss: 3.1057595554681687
Validation loss: 3.233822096480249

Epoch: 6| Step: 8
Training loss: 3.103812144130151
Validation loss: 3.232996983873955

Epoch: 6| Step: 9
Training loss: 3.1948958220832244
Validation loss: 3.2319137151504367

Epoch: 6| Step: 10
Training loss: 4.019993406072115
Validation loss: 3.2305733661714786

Epoch: 6| Step: 11
Training loss: 3.7903532051833833
Validation loss: 3.2295428487967537

Epoch: 6| Step: 12
Training loss: 2.580491892623953
Validation loss: 3.2285114228227

Epoch: 6| Step: 13
Training loss: 2.578251783548088
Validation loss: 3.2275634951361183

Epoch: 20| Step: 0
Training loss: 2.886168472638701
Validation loss: 3.2264790004612585

Epoch: 6| Step: 1
Training loss: 3.807480932176701
Validation loss: 3.225473243260024

Epoch: 6| Step: 2
Training loss: 3.5537070462760365
Validation loss: 3.22441535318747

Epoch: 6| Step: 3
Training loss: 3.86194824425872
Validation loss: 3.2233246693730817

Epoch: 6| Step: 4
Training loss: 3.4052632153649984
Validation loss: 3.222594061556308

Epoch: 6| Step: 5
Training loss: 3.3618149523984693
Validation loss: 3.2209006481100673

Epoch: 6| Step: 6
Training loss: 3.2571707626332898
Validation loss: 3.22005313690342

Epoch: 6| Step: 7
Training loss: 4.236177743412013
Validation loss: 3.2191379296225087

Epoch: 6| Step: 8
Training loss: 2.999138549463728
Validation loss: 3.217905371994896

Epoch: 6| Step: 9
Training loss: 3.4690282211761274
Validation loss: 3.2165163236365575

Epoch: 6| Step: 10
Training loss: 3.2616994526001006
Validation loss: 3.2154042096037494

Epoch: 6| Step: 11
Training loss: 3.1048130326793446
Validation loss: 3.214819605062116

Epoch: 6| Step: 12
Training loss: 3.439027204250101
Validation loss: 3.213230006988394

Epoch: 6| Step: 13
Training loss: 4.038191858307016
Validation loss: 3.2124345650418236

Epoch: 21| Step: 0
Training loss: 3.0864739446709755
Validation loss: 3.2115203078601193

Epoch: 6| Step: 1
Training loss: 3.7477237150613965
Validation loss: 3.210493239421437

Epoch: 6| Step: 2
Training loss: 4.289183456855453
Validation loss: 3.2099988364922054

Epoch: 6| Step: 3
Training loss: 3.4082905667955483
Validation loss: 3.2085418478929135

Epoch: 6| Step: 4
Training loss: 3.1703504083509375
Validation loss: 3.207365671294197

Epoch: 6| Step: 5
Training loss: 3.39229166581703
Validation loss: 3.2068702154013353

Epoch: 6| Step: 6
Training loss: 3.1693628444600264
Validation loss: 3.205710995163808

Epoch: 6| Step: 7
Training loss: 3.9412450993752737
Validation loss: 3.204467336901161

Epoch: 6| Step: 8
Training loss: 3.7743861425632947
Validation loss: 3.2036568917117916

Epoch: 6| Step: 9
Training loss: 3.188206313920426
Validation loss: 3.2023385391749537

Epoch: 6| Step: 10
Training loss: 3.8036999057125005
Validation loss: 3.2015759443808958

Epoch: 6| Step: 11
Training loss: 3.0863498846787834
Validation loss: 3.200585249160272

Epoch: 6| Step: 12
Training loss: 3.4803368129190977
Validation loss: 3.1996945848127103

Epoch: 6| Step: 13
Training loss: 1.7785362854077402
Validation loss: 3.1984320067638916

Epoch: 22| Step: 0
Training loss: 3.2459982664017857
Validation loss: 3.197353019288933

Epoch: 6| Step: 1
Training loss: 1.686211553295084
Validation loss: 3.1967027487326627

Epoch: 6| Step: 2
Training loss: 3.191570301111739
Validation loss: 3.195942216717794

Epoch: 6| Step: 3
Training loss: 3.723075594904833
Validation loss: 3.195222308320148

Epoch: 6| Step: 4
Training loss: 2.825190164697825
Validation loss: 3.194029151300347

Epoch: 6| Step: 5
Training loss: 3.808116581686968
Validation loss: 3.1935069991552103

Epoch: 6| Step: 6
Training loss: 4.179633195470823
Validation loss: 3.1920331874682386

Epoch: 6| Step: 7
Training loss: 3.813476437459985
Validation loss: 3.191359099449258

Epoch: 6| Step: 8
Training loss: 2.93417267350681
Validation loss: 3.1903821046692205

Epoch: 6| Step: 9
Training loss: 4.037514956420029
Validation loss: 3.18890675550012

Epoch: 6| Step: 10
Training loss: 3.846163232498453
Validation loss: 3.1881748589331345

Epoch: 6| Step: 11
Training loss: 2.7288973629312867
Validation loss: 3.187094152464097

Epoch: 6| Step: 12
Training loss: 3.966342706567649
Validation loss: 3.1855165123970828

Epoch: 6| Step: 13
Training loss: 3.558617333209452
Validation loss: 3.1844537145868803

Epoch: 23| Step: 0
Training loss: 4.168879773180371
Validation loss: 3.183401142199837

Epoch: 6| Step: 1
Training loss: 4.133206382975868
Validation loss: 3.1824145009985934

Epoch: 6| Step: 2
Training loss: 3.783259338686007
Validation loss: 3.180622365821553

Epoch: 6| Step: 3
Training loss: 3.3578308815007
Validation loss: 3.1793319778729345

Epoch: 6| Step: 4
Training loss: 2.637429736317855
Validation loss: 3.178369456981665

Epoch: 6| Step: 5
Training loss: 3.518046176913127
Validation loss: 3.1783677211997716

Epoch: 6| Step: 6
Training loss: 3.9123992126938303
Validation loss: 3.177052179214397

Epoch: 6| Step: 7
Training loss: 3.4997223335206415
Validation loss: 3.175814937862967

Epoch: 6| Step: 8
Training loss: 2.738335841528529
Validation loss: 3.1745560676524236

Epoch: 6| Step: 9
Training loss: 3.6453130441625183
Validation loss: 3.1738086308463562

Epoch: 6| Step: 10
Training loss: 3.0161458094434432
Validation loss: 3.172357829284107

Epoch: 6| Step: 11
Training loss: 2.9029586366550886
Validation loss: 3.171880394198401

Epoch: 6| Step: 12
Training loss: 3.0990999761102045
Validation loss: 3.17188665239461

Epoch: 6| Step: 13
Training loss: 3.2672255394799543
Validation loss: 3.1701385450484088

Epoch: 24| Step: 0
Training loss: 2.539104191364445
Validation loss: 3.1692736591086508

Epoch: 6| Step: 1
Training loss: 3.8447095712175345
Validation loss: 3.168881709177892

Epoch: 6| Step: 2
Training loss: 2.8896783051747232
Validation loss: 3.1671743104783103

Epoch: 6| Step: 3
Training loss: 3.0643916613199567
Validation loss: 3.166689823003362

Epoch: 6| Step: 4
Training loss: 3.1683140200836153
Validation loss: 3.1655389049153566

Epoch: 6| Step: 5
Training loss: 2.3068432052765244
Validation loss: 3.1648271190536135

Epoch: 6| Step: 6
Training loss: 4.0663949927798075
Validation loss: 3.164373027553501

Epoch: 6| Step: 7
Training loss: 3.9309624789671247
Validation loss: 3.1636631170591767

Epoch: 6| Step: 8
Training loss: 3.5534256592351063
Validation loss: 3.1639918821924615

Epoch: 6| Step: 9
Training loss: 3.0647314855749297
Validation loss: 3.1628919803476596

Epoch: 6| Step: 10
Training loss: 3.7090748820579087
Validation loss: 3.1612009623272113

Epoch: 6| Step: 11
Training loss: 3.4857164204253688
Validation loss: 3.1601153616891016

Epoch: 6| Step: 12
Training loss: 3.1793338663339785
Validation loss: 3.158901529168668

Epoch: 6| Step: 13
Training loss: 5.233804153515719
Validation loss: 3.158164449398354

Epoch: 25| Step: 0
Training loss: 3.8059422110150893
Validation loss: 3.157198758170015

Epoch: 6| Step: 1
Training loss: 3.6246653435233247
Validation loss: 3.1560661378515724

Epoch: 6| Step: 2
Training loss: 3.398574721098198
Validation loss: 3.1545492191373854

Epoch: 6| Step: 3
Training loss: 3.2651628231090672
Validation loss: 3.1538692134544477

Epoch: 6| Step: 4
Training loss: 3.0593126799146124
Validation loss: 3.1536719093163637

Epoch: 6| Step: 5
Training loss: 3.439263047745036
Validation loss: 3.1520549715446715

Epoch: 6| Step: 6
Training loss: 3.1147589150293613
Validation loss: 3.1511137896204144

Epoch: 6| Step: 7
Training loss: 3.388341882122293
Validation loss: 3.150750372912874

Epoch: 6| Step: 8
Training loss: 2.6028387015300933
Validation loss: 3.1487448283366106

Epoch: 6| Step: 9
Training loss: 3.3598162693925255
Validation loss: 3.1486022803501537

Epoch: 6| Step: 10
Training loss: 3.862887000785159
Validation loss: 3.147743886616128

Epoch: 6| Step: 11
Training loss: 2.9148072628210824
Validation loss: 3.1465622931282025

Epoch: 6| Step: 12
Training loss: 3.44150850488337
Validation loss: 3.145738355907

Epoch: 6| Step: 13
Training loss: 4.865377466156516
Validation loss: 3.1449151492347607

Epoch: 26| Step: 0
Training loss: 3.4035863698460704
Validation loss: 3.1440945841277883

Epoch: 6| Step: 1
Training loss: 3.2116006505173273
Validation loss: 3.143034596980861

Epoch: 6| Step: 2
Training loss: 2.5890896765250098
Validation loss: 3.142326839549225

Epoch: 6| Step: 3
Training loss: 3.3121709120322724
Validation loss: 3.1409194866179733

Epoch: 6| Step: 4
Training loss: 4.264922478922765
Validation loss: 3.1404235200552573

Epoch: 6| Step: 5
Training loss: 3.516225805867234
Validation loss: 3.1396517150797494

Epoch: 6| Step: 6
Training loss: 3.603581919486729
Validation loss: 3.1383922846043846

Epoch: 6| Step: 7
Training loss: 3.501692771275672
Validation loss: 3.1371302597747697

Epoch: 6| Step: 8
Training loss: 3.6457632584876487
Validation loss: 3.1369494579860278

Epoch: 6| Step: 9
Training loss: 3.7173017999779274
Validation loss: 3.13633803993885

Epoch: 6| Step: 10
Training loss: 3.2586857565285805
Validation loss: 3.134709349397934

Epoch: 6| Step: 11
Training loss: 2.9262313598404135
Validation loss: 3.133170095721957

Epoch: 6| Step: 12
Training loss: 3.7232825601975588
Validation loss: 3.1325713713298198

Epoch: 6| Step: 13
Training loss: 2.035145003567774
Validation loss: 3.131628525168933

Epoch: 27| Step: 0
Training loss: 3.532884202758434
Validation loss: 3.13100486128042

Epoch: 6| Step: 1
Training loss: 3.5668764504268804
Validation loss: 3.1298056471718705

Epoch: 6| Step: 2
Training loss: 3.579696510067161
Validation loss: 3.1288165276156357

Epoch: 6| Step: 3
Training loss: 3.412387043966377
Validation loss: 3.1279813560841014

Epoch: 6| Step: 4
Training loss: 3.631942940284769
Validation loss: 3.126429220718233

Epoch: 6| Step: 5
Training loss: 4.113552276579614
Validation loss: 3.1256748807915313

Epoch: 6| Step: 6
Training loss: 3.3259533884861967
Validation loss: 3.125282225631547

Epoch: 6| Step: 7
Training loss: 3.1282069726163244
Validation loss: 3.124053193091981

Epoch: 6| Step: 8
Training loss: 2.7478794244802542
Validation loss: 3.1233020755595224

Epoch: 6| Step: 9
Training loss: 3.339265757734962
Validation loss: 3.122169610754347

Epoch: 6| Step: 10
Training loss: 3.039583999881231
Validation loss: 3.121607185210414

Epoch: 6| Step: 11
Training loss: 2.8611478052183297
Validation loss: 3.1198321214924567

Epoch: 6| Step: 12
Training loss: 3.451159163636749
Validation loss: 3.11989980779976

Epoch: 6| Step: 13
Training loss: 3.833052721671626
Validation loss: 3.1183334005594165

Epoch: 28| Step: 0
Training loss: 3.3552425072883842
Validation loss: 3.1179490297360557

Epoch: 6| Step: 1
Training loss: 3.326454853916043
Validation loss: 3.116970824819848

Epoch: 6| Step: 2
Training loss: 3.7909160052598825
Validation loss: 3.118570389506611

Epoch: 6| Step: 3
Training loss: 3.318838712436915
Validation loss: 3.1157923369990805

Epoch: 6| Step: 4
Training loss: 3.105022662290471
Validation loss: 3.114155686109814

Epoch: 6| Step: 5
Training loss: 3.378861655233176
Validation loss: 3.1134945993495604

Epoch: 6| Step: 6
Training loss: 3.0886481246913156
Validation loss: 3.1125374859742103

Epoch: 6| Step: 7
Training loss: 3.944372204819029
Validation loss: 3.112368845714253

Epoch: 6| Step: 8
Training loss: 2.9673641785002864
Validation loss: 3.1124497569823038

Epoch: 6| Step: 9
Training loss: 3.182339848446539
Validation loss: 3.1101526285716967

Epoch: 6| Step: 10
Training loss: 3.955576261068532
Validation loss: 3.1095167970637614

Epoch: 6| Step: 11
Training loss: 2.982949760400146
Validation loss: 3.1089572486732866

Epoch: 6| Step: 12
Training loss: 3.411799258991476
Validation loss: 3.1077425249563473

Epoch: 6| Step: 13
Training loss: 3.53071320091172
Validation loss: 3.108023770537472

Epoch: 29| Step: 0
Training loss: 3.179111287912491
Validation loss: 3.1048617287144604

Epoch: 6| Step: 1
Training loss: 3.5109574592814123
Validation loss: 3.1059816374082003

Epoch: 6| Step: 2
Training loss: 3.952148558152642
Validation loss: 3.104059689226872

Epoch: 6| Step: 3
Training loss: 3.439197606609299
Validation loss: 3.1043811555239995

Epoch: 6| Step: 4
Training loss: 3.6144590035785167
Validation loss: 3.1024649867615848

Epoch: 6| Step: 5
Training loss: 2.510820242915914
Validation loss: 3.1032572540977927

Epoch: 6| Step: 6
Training loss: 4.2296334496078964
Validation loss: 3.1018363154194377

Epoch: 6| Step: 7
Training loss: 2.9961270127818667
Validation loss: 3.1009005249825807

Epoch: 6| Step: 8
Training loss: 2.8244343486711836
Validation loss: 3.099512574760273

Epoch: 6| Step: 9
Training loss: 3.336887340533553
Validation loss: 3.098631111476706

Epoch: 6| Step: 10
Training loss: 3.3301700523418694
Validation loss: 3.0982107373212067

Epoch: 6| Step: 11
Training loss: 3.5313088741289613
Validation loss: 3.0970046333017334

Epoch: 6| Step: 12
Training loss: 3.573240185799863
Validation loss: 3.095710251867475

Epoch: 6| Step: 13
Training loss: 2.4723278146927083
Validation loss: 3.0943640295036494

Epoch: 30| Step: 0
Training loss: 3.4540809930561553
Validation loss: 3.093278298910344

Epoch: 6| Step: 1
Training loss: 3.3969347207189853
Validation loss: 3.093250274488111

Epoch: 6| Step: 2
Training loss: 2.9227949519972998
Validation loss: 3.0928967773203637

Epoch: 6| Step: 3
Training loss: 3.8247424070099765
Validation loss: 3.0956264111745635

Epoch: 6| Step: 4
Training loss: 3.1678992097985668
Validation loss: 3.0954734018535843

Epoch: 6| Step: 5
Training loss: 3.3317287079640323
Validation loss: 3.1014551224877427

Epoch: 6| Step: 6
Training loss: 3.9958760937791773
Validation loss: 3.0892333829553675

Epoch: 6| Step: 7
Training loss: 3.72058855015519
Validation loss: 3.0866661356964467

Epoch: 6| Step: 8
Training loss: 2.693355391556835
Validation loss: 3.089910528441631

Epoch: 6| Step: 9
Training loss: 3.619465121170074
Validation loss: 3.1077916436366926

Epoch: 6| Step: 10
Training loss: 3.313470662249757
Validation loss: 3.0987338645147737

Epoch: 6| Step: 11
Training loss: 3.5616229132066897
Validation loss: 3.1013815730368504

Epoch: 6| Step: 12
Training loss: 3.0252951107622787
Validation loss: 3.1021418616314524

Epoch: 6| Step: 13
Training loss: 2.5553828701701784
Validation loss: 3.1082001637747614

Epoch: 31| Step: 0
Training loss: 3.5436910042401712
Validation loss: 3.1028981939495757

Epoch: 6| Step: 1
Training loss: 2.9397321296159764
Validation loss: 3.097237409728597

Epoch: 6| Step: 2
Training loss: 3.6015054363107493
Validation loss: 3.0919259010567552

Epoch: 6| Step: 3
Training loss: 3.6409524271014604
Validation loss: 3.089381353951606

Epoch: 6| Step: 4
Training loss: 3.3818758401215807
Validation loss: 3.0819136999548165

Epoch: 6| Step: 5
Training loss: 3.3498462470911097
Validation loss: 3.0799164207266845

Epoch: 6| Step: 6
Training loss: 4.2760171583668205
Validation loss: 3.0801379880704

Epoch: 6| Step: 7
Training loss: 2.8292824078697842
Validation loss: 3.0777072517872015

Epoch: 6| Step: 8
Training loss: 4.159490942252626
Validation loss: 3.0803152865651797

Epoch: 6| Step: 9
Training loss: 2.5148187138951634
Validation loss: 3.0757587441529335

Epoch: 6| Step: 10
Training loss: 3.326081270785945
Validation loss: 3.0735424513441076

Epoch: 6| Step: 11
Training loss: 3.161549867983901
Validation loss: 3.0739133130402454

Epoch: 6| Step: 12
Training loss: 3.0562487268737764
Validation loss: 3.072697474005598

Epoch: 6| Step: 13
Training loss: 2.426818036381748
Validation loss: 3.073276198544766

Epoch: 32| Step: 0
Training loss: 3.8009064546920035
Validation loss: 3.073085708654455

Epoch: 6| Step: 1
Training loss: 3.1332830898504174
Validation loss: 3.0730515795430726

Epoch: 6| Step: 2
Training loss: 2.953105300756883
Validation loss: 3.073232797942876

Epoch: 6| Step: 3
Training loss: 2.806952282001573
Validation loss: 3.073475726819568

Epoch: 6| Step: 4
Training loss: 3.183419102283916
Validation loss: 3.0730760091213027

Epoch: 6| Step: 5
Training loss: 3.1916889266257926
Validation loss: 3.074498180931469

Epoch: 6| Step: 6
Training loss: 3.2175901230503507
Validation loss: 3.0698513509336087

Epoch: 6| Step: 7
Training loss: 3.8267257935965886
Validation loss: 3.0715129774127625

Epoch: 6| Step: 8
Training loss: 3.8101337781833604
Validation loss: 3.064958151321667

Epoch: 6| Step: 9
Training loss: 2.9108128978129493
Validation loss: 3.0631012718709343

Epoch: 6| Step: 10
Training loss: 3.749704476473936
Validation loss: 3.061937326922809

Epoch: 6| Step: 11
Training loss: 3.132816152974803
Validation loss: 3.0626077287723104

Epoch: 6| Step: 12
Training loss: 3.271565705612176
Validation loss: 3.0624701101063727

Epoch: 6| Step: 13
Training loss: 3.968333064729077
Validation loss: 3.0614204873143116

Epoch: 33| Step: 0
Training loss: 2.7412960853303514
Validation loss: 3.0621792723898476

Epoch: 6| Step: 1
Training loss: 3.361026517645961
Validation loss: 3.060358760099416

Epoch: 6| Step: 2
Training loss: 3.3605401436023192
Validation loss: 3.061235512950863

Epoch: 6| Step: 3
Training loss: 2.8640598628005454
Validation loss: 3.0593179541516515

Epoch: 6| Step: 4
Training loss: 2.5547548804306985
Validation loss: 3.0595503082018904

Epoch: 6| Step: 5
Training loss: 2.1982009727922214
Validation loss: 3.0613014876188434

Epoch: 6| Step: 6
Training loss: 3.4728234919128047
Validation loss: 3.0584562457718953

Epoch: 6| Step: 7
Training loss: 4.056617351055648
Validation loss: 3.0573078162148697

Epoch: 6| Step: 8
Training loss: 3.968502247203543
Validation loss: 3.053728375886384

Epoch: 6| Step: 9
Training loss: 3.7125480931310553
Validation loss: 3.054694962584859

Epoch: 6| Step: 10
Training loss: 4.307893144463568
Validation loss: 3.0519116963890447

Epoch: 6| Step: 11
Training loss: 2.805714708688375
Validation loss: 3.0540422892674575

Epoch: 6| Step: 12
Training loss: 3.09635168556176
Validation loss: 3.050813093020948

Epoch: 6| Step: 13
Training loss: 3.7721886631617245
Validation loss: 3.050904495115135

Epoch: 34| Step: 0
Training loss: 2.9735289005859062
Validation loss: 3.0505104574478157

Epoch: 6| Step: 1
Training loss: 3.7946767212454615
Validation loss: 3.0496388821559246

Epoch: 6| Step: 2
Training loss: 3.9516585574046097
Validation loss: 3.0478286752556003

Epoch: 6| Step: 3
Training loss: 3.4574370237670893
Validation loss: 3.04991765127127

Epoch: 6| Step: 4
Training loss: 3.8586223656071565
Validation loss: 3.048324765921687

Epoch: 6| Step: 5
Training loss: 3.5333282296725668
Validation loss: 3.045298692110263

Epoch: 6| Step: 6
Training loss: 3.750137072283237
Validation loss: 3.04650756875411

Epoch: 6| Step: 7
Training loss: 3.167974921242833
Validation loss: 3.0473787297840724

Epoch: 6| Step: 8
Training loss: 2.9779832708171967
Validation loss: 3.044798848284431

Epoch: 6| Step: 9
Training loss: 3.7510894464431646
Validation loss: 3.04094742550638

Epoch: 6| Step: 10
Training loss: 2.5929268139663044
Validation loss: 3.045292736959908

Epoch: 6| Step: 11
Training loss: 2.405267589219697
Validation loss: 3.0448963245484704

Epoch: 6| Step: 12
Training loss: 2.602666580482909
Validation loss: 3.0527216303957476

Epoch: 6| Step: 13
Training loss: 3.2238453653702646
Validation loss: 3.0634886732288353

Epoch: 35| Step: 0
Training loss: 3.6666020618873842
Validation loss: 3.1088510518014476

Epoch: 6| Step: 1
Training loss: 2.5808995893442077
Validation loss: 3.0376729260285034

Epoch: 6| Step: 2
Training loss: 2.9695237606990865
Validation loss: 3.0425786895677915

Epoch: 6| Step: 3
Training loss: 3.7274930100148373
Validation loss: 3.1129295844368463

Epoch: 6| Step: 4
Training loss: 2.8007683108574897
Validation loss: 3.130561943092692

Epoch: 6| Step: 5
Training loss: 3.8152377195276244
Validation loss: 3.155806045718613

Epoch: 6| Step: 6
Training loss: 3.643114540345547
Validation loss: 3.182563771850419

Epoch: 6| Step: 7
Training loss: 4.430280803796559
Validation loss: 3.2055301803262513

Epoch: 6| Step: 8
Training loss: 2.0004298225112724
Validation loss: 3.16740355367135

Epoch: 6| Step: 9
Training loss: 3.3997777641818288
Validation loss: 3.1704201955913933

Epoch: 6| Step: 10
Training loss: 3.33775219482368
Validation loss: 3.1735972536738792

Epoch: 6| Step: 11
Training loss: 3.5605251794971213
Validation loss: 3.1751102565631455

Epoch: 6| Step: 12
Training loss: 3.706331434207593
Validation loss: 3.1856037952481286

Epoch: 6| Step: 13
Training loss: 3.78883785879674
Validation loss: 3.154967778714157

Epoch: 36| Step: 0
Training loss: 3.610902405274881
Validation loss: 3.1487369324227115

Epoch: 6| Step: 1
Training loss: 3.401876318933251
Validation loss: 3.1530640534948366

Epoch: 6| Step: 2
Training loss: 2.8700882792436637
Validation loss: 3.1553242374639177

Epoch: 6| Step: 3
Training loss: 3.870327008450804
Validation loss: 3.178235428761704

Epoch: 6| Step: 4
Training loss: 3.758705461325098
Validation loss: 3.1622833998791755

Epoch: 6| Step: 5
Training loss: 3.123189477962999
Validation loss: 3.1494265721129815

Epoch: 6| Step: 6
Training loss: 2.833796425915721
Validation loss: 3.13327318147754

Epoch: 6| Step: 7
Training loss: 3.6409492839412665
Validation loss: 3.123015909684605

Epoch: 6| Step: 8
Training loss: 3.392890138393953
Validation loss: 3.1065121780528924

Epoch: 6| Step: 9
Training loss: 2.94404295417299
Validation loss: 3.090104070407555

Epoch: 6| Step: 10
Training loss: 3.761147650824965
Validation loss: 3.084108851005552

Epoch: 6| Step: 11
Training loss: 2.792785297050882
Validation loss: 3.0745777165982044

Epoch: 6| Step: 12
Training loss: 3.2941585395983584
Validation loss: 3.0703861674760438

Epoch: 6| Step: 13
Training loss: 4.307861044481873
Validation loss: 3.0684101450953563

Epoch: 37| Step: 0
Training loss: 3.6282993954876295
Validation loss: 3.0651638122677447

Epoch: 6| Step: 1
Training loss: 3.198213263227986
Validation loss: 3.0607333199105042

Epoch: 6| Step: 2
Training loss: 3.2505272657667654
Validation loss: 3.0575001992735618

Epoch: 6| Step: 3
Training loss: 4.000584082874698
Validation loss: 3.0567685124584947

Epoch: 6| Step: 4
Training loss: 3.3698029240337144
Validation loss: 3.054214963422115

Epoch: 6| Step: 5
Training loss: 3.5032174444464235
Validation loss: 3.053452859230747

Epoch: 6| Step: 6
Training loss: 4.013086370006851
Validation loss: 3.051440284220209

Epoch: 6| Step: 7
Training loss: 3.056819396229845
Validation loss: 3.0501568129082655

Epoch: 6| Step: 8
Training loss: 2.693958240788597
Validation loss: 3.050213345738878

Epoch: 6| Step: 9
Training loss: 3.7005049695993244
Validation loss: 3.04534816133149

Epoch: 6| Step: 10
Training loss: 1.9338052036762599
Validation loss: 3.0448158729456036

Epoch: 6| Step: 11
Training loss: 3.455137193001305
Validation loss: 3.0442790350073725

Epoch: 6| Step: 12
Training loss: 3.250511129240809
Validation loss: 3.0417989184298238

Epoch: 6| Step: 13
Training loss: 3.064050398768174
Validation loss: 3.0423737593392404

Epoch: 38| Step: 0
Training loss: 3.4700103394631903
Validation loss: 3.0415570341460705

Epoch: 6| Step: 1
Training loss: 2.9103128890310996
Validation loss: 3.040768739592515

Epoch: 6| Step: 2
Training loss: 3.1390814332974935
Validation loss: 3.0382891209036744

Epoch: 6| Step: 3
Training loss: 3.294799874788268
Validation loss: 3.03923802689132

Epoch: 6| Step: 4
Training loss: 3.4571700073671336
Validation loss: 3.039854585090097

Epoch: 6| Step: 5
Training loss: 3.493310120653484
Validation loss: 3.0390290533871402

Epoch: 6| Step: 6
Training loss: 2.8892593044425947
Validation loss: 3.035765516697296

Epoch: 6| Step: 7
Training loss: 2.911886676176217
Validation loss: 3.0345304064059744

Epoch: 6| Step: 8
Training loss: 2.803779051141664
Validation loss: 3.0316338989001053

Epoch: 6| Step: 9
Training loss: 3.7124444411516375
Validation loss: 3.0318588340602712

Epoch: 6| Step: 10
Training loss: 3.8334305101323
Validation loss: 3.029169514437746

Epoch: 6| Step: 11
Training loss: 3.6549671237369763
Validation loss: 3.0286657203829273

Epoch: 6| Step: 12
Training loss: 2.8644912057569467
Validation loss: 3.027189403122905

Epoch: 6| Step: 13
Training loss: 4.23713172054931
Validation loss: 3.0296344500889387

Epoch: 39| Step: 0
Training loss: 3.6262813802661187
Validation loss: 3.0276222116285156

Epoch: 6| Step: 1
Training loss: 2.8575967564392477
Validation loss: 3.0279763019835335

Epoch: 6| Step: 2
Training loss: 3.5556008978442697
Validation loss: 3.029376052146792

Epoch: 6| Step: 3
Training loss: 3.065616812194405
Validation loss: 3.068668728186588

Epoch: 6| Step: 4
Training loss: 3.5887610262784775
Validation loss: 3.1505071392919266

Epoch: 6| Step: 5
Training loss: 3.392379096061713
Validation loss: 3.1598659057354173

Epoch: 6| Step: 6
Training loss: 3.5299430386537596
Validation loss: 3.1543983787795833

Epoch: 6| Step: 7
Training loss: 3.0741712864625392
Validation loss: 3.1358435348431093

Epoch: 6| Step: 8
Training loss: 3.0719705623070594
Validation loss: 3.099034839215544

Epoch: 6| Step: 9
Training loss: 3.2582053260992447
Validation loss: 3.065252588500048

Epoch: 6| Step: 10
Training loss: 2.866551632754001
Validation loss: 3.018801837247544

Epoch: 6| Step: 11
Training loss: 3.1924371816837027
Validation loss: 3.020669256442503

Epoch: 6| Step: 12
Training loss: 3.68058438719647
Validation loss: 3.0205682391382758

Epoch: 6| Step: 13
Training loss: 4.387919505352078
Validation loss: 3.011289213281741

Epoch: 40| Step: 0
Training loss: 3.578091417180012
Validation loss: 2.993917686336748

Epoch: 6| Step: 1
Training loss: 3.699241952309759
Validation loss: 2.9899225381630083

Epoch: 6| Step: 2
Training loss: 2.7839289418173694
Validation loss: 2.9864114046756316

Epoch: 6| Step: 3
Training loss: 3.1107614771094654
Validation loss: 2.9930970818520986

Epoch: 6| Step: 4
Training loss: 2.5862023716371785
Validation loss: 2.9874078576532592

Epoch: 6| Step: 5
Training loss: 3.5687439392359055
Validation loss: 2.9907348245754486

Epoch: 6| Step: 6
Training loss: 2.5115600345946434
Validation loss: 2.994631203538653

Epoch: 6| Step: 7
Training loss: 3.332926121316128
Validation loss: 3.015190612223632

Epoch: 6| Step: 8
Training loss: 4.035016333489053
Validation loss: 3.020358905022274

Epoch: 6| Step: 9
Training loss: 3.83589448924143
Validation loss: 3.0216667465529317

Epoch: 6| Step: 10
Training loss: 2.8544412374109283
Validation loss: 3.012564216330664

Epoch: 6| Step: 11
Training loss: 3.942469654728441
Validation loss: 3.004961836952376

Epoch: 6| Step: 12
Training loss: 2.4514541281092987
Validation loss: 2.98849634989787

Epoch: 6| Step: 13
Training loss: 3.3262904309005674
Validation loss: 2.984922216613306

Epoch: 41| Step: 0
Training loss: 3.5055355166832967
Validation loss: 2.9836749025730906

Epoch: 6| Step: 1
Training loss: 3.2539104997439985
Validation loss: 2.982463036731463

Epoch: 6| Step: 2
Training loss: 2.995142819369863
Validation loss: 2.9826602064923406

Epoch: 6| Step: 3
Training loss: 3.581972277706012
Validation loss: 2.9806442388634244

Epoch: 6| Step: 4
Training loss: 3.708797568648416
Validation loss: 2.97789539847959

Epoch: 6| Step: 5
Training loss: 3.369542548489926
Validation loss: 2.976608931005141

Epoch: 6| Step: 6
Training loss: 3.1557251144427654
Validation loss: 2.976030542439002

Epoch: 6| Step: 7
Training loss: 3.3377883386536578
Validation loss: 2.9737578178730284

Epoch: 6| Step: 8
Training loss: 3.2916342496281685
Validation loss: 2.9731985857660135

Epoch: 6| Step: 9
Training loss: 3.615034414209354
Validation loss: 2.9733716377643136

Epoch: 6| Step: 10
Training loss: 3.035782718688525
Validation loss: 2.9741138931696276

Epoch: 6| Step: 11
Training loss: 2.9685784541308786
Validation loss: 2.9764494709352105

Epoch: 6| Step: 12
Training loss: 2.8418010698530036
Validation loss: 2.98281869939176

Epoch: 6| Step: 13
Training loss: 2.6607739687815566
Validation loss: 2.9806236068055614

Epoch: 42| Step: 0
Training loss: 3.420433542088594
Validation loss: 2.980386476253815

Epoch: 6| Step: 1
Training loss: 2.7672524701444408
Validation loss: 2.9723781511504193

Epoch: 6| Step: 2
Training loss: 3.769184503765409
Validation loss: 2.9744193157273586

Epoch: 6| Step: 3
Training loss: 2.7217229614540583
Validation loss: 2.969434885190447

Epoch: 6| Step: 4
Training loss: 3.6549698634542516
Validation loss: 2.967824344072679

Epoch: 6| Step: 5
Training loss: 3.6967673794712
Validation loss: 2.9650696666721195

Epoch: 6| Step: 6
Training loss: 3.292225239034555
Validation loss: 2.9633604097662896

Epoch: 6| Step: 7
Training loss: 3.138806172259083
Validation loss: 2.9634089975559457

Epoch: 6| Step: 8
Training loss: 2.665123512884201
Validation loss: 2.9626488816380854

Epoch: 6| Step: 9
Training loss: 3.315455144186142
Validation loss: 2.962840818204901

Epoch: 6| Step: 10
Training loss: 3.285484705776621
Validation loss: 2.9632555112682333

Epoch: 6| Step: 11
Training loss: 3.0136006730692824
Validation loss: 2.9607376999641963

Epoch: 6| Step: 12
Training loss: 3.401620641306982
Validation loss: 2.9618693884335503

Epoch: 6| Step: 13
Training loss: 3.1766335257542377
Validation loss: 2.9593429408282965

Epoch: 43| Step: 0
Training loss: 3.0570839459863737
Validation loss: 2.959538407727236

Epoch: 6| Step: 1
Training loss: 3.700528679270506
Validation loss: 2.9596218322861105

Epoch: 6| Step: 2
Training loss: 3.0279304182052593
Validation loss: 2.9592269323153824

Epoch: 6| Step: 3
Training loss: 3.308796954079412
Validation loss: 2.9598728990898455

Epoch: 6| Step: 4
Training loss: 3.161186964945881
Validation loss: 2.978619085808322

Epoch: 6| Step: 5
Training loss: 3.2670279231750783
Validation loss: 3.0068631725355885

Epoch: 6| Step: 6
Training loss: 3.685134387522599
Validation loss: 3.001540742047636

Epoch: 6| Step: 7
Training loss: 3.475428295499449
Validation loss: 2.9656343268697936

Epoch: 6| Step: 8
Training loss: 3.16376605116843
Validation loss: 2.9502118837722167

Epoch: 6| Step: 9
Training loss: 2.6822950838431407
Validation loss: 2.951172111282485

Epoch: 6| Step: 10
Training loss: 3.611022044982637
Validation loss: 2.95159974115724

Epoch: 6| Step: 11
Training loss: 2.708389888075134
Validation loss: 2.954916548692203

Epoch: 6| Step: 12
Training loss: 2.65963063249737
Validation loss: 2.9540946554796284

Epoch: 6| Step: 13
Training loss: 3.996569115787393
Validation loss: 2.958664802885557

Epoch: 44| Step: 0
Training loss: 3.8169385993622256
Validation loss: 2.956796012411575

Epoch: 6| Step: 1
Training loss: 4.023517852277131
Validation loss: 2.9541815470321264

Epoch: 6| Step: 2
Training loss: 2.694522996349529
Validation loss: 2.9514229665900498

Epoch: 6| Step: 3
Training loss: 2.841973724630342
Validation loss: 2.9502684548047684

Epoch: 6| Step: 4
Training loss: 2.8716264918154124
Validation loss: 2.9488645118506005

Epoch: 6| Step: 5
Training loss: 3.3213617080779128
Validation loss: 2.947412630742375

Epoch: 6| Step: 6
Training loss: 3.038801716498196
Validation loss: 2.9464679461286583

Epoch: 6| Step: 7
Training loss: 3.219937892338543
Validation loss: 2.947097174514941

Epoch: 6| Step: 8
Training loss: 3.04937141069536
Validation loss: 2.944716291505716

Epoch: 6| Step: 9
Training loss: 3.5455448832707095
Validation loss: 2.944715043079353

Epoch: 6| Step: 10
Training loss: 3.5068757775427706
Validation loss: 2.9448214812787192

Epoch: 6| Step: 11
Training loss: 3.1508487526765947
Validation loss: 2.9431029335153798

Epoch: 6| Step: 12
Training loss: 2.8565015686233837
Validation loss: 2.9433888526845595

Epoch: 6| Step: 13
Training loss: 3.1483246662376687
Validation loss: 2.9407921667704104

Epoch: 45| Step: 0
Training loss: 2.2919247799791598
Validation loss: 2.941831913028344

Epoch: 6| Step: 1
Training loss: 3.5918988311385895
Validation loss: 2.9408005512665203

Epoch: 6| Step: 2
Training loss: 3.545857153221179
Validation loss: 2.9395523337450493

Epoch: 6| Step: 3
Training loss: 3.3254808121286668
Validation loss: 2.9408558736962083

Epoch: 6| Step: 4
Training loss: 2.915677111651628
Validation loss: 2.9458339587832585

Epoch: 6| Step: 5
Training loss: 2.938368810856752
Validation loss: 2.949277400190338

Epoch: 6| Step: 6
Training loss: 3.44563606801531
Validation loss: 2.973608112540764

Epoch: 6| Step: 7
Training loss: 4.089396250962689
Validation loss: 2.9661944699916005

Epoch: 6| Step: 8
Training loss: 3.3087593406484874
Validation loss: 2.931597740529362

Epoch: 6| Step: 9
Training loss: 4.001677161513716
Validation loss: 2.9345386775261564

Epoch: 6| Step: 10
Training loss: 3.012019873382539
Validation loss: 2.9331104328349342

Epoch: 6| Step: 11
Training loss: 2.1429646646681118
Validation loss: 2.933664102610431

Epoch: 6| Step: 12
Training loss: 3.3443192327245157
Validation loss: 2.9343678836613254

Epoch: 6| Step: 13
Training loss: 2.340805849389507
Validation loss: 2.934274867072825

Epoch: 46| Step: 0
Training loss: 3.8629689644858725
Validation loss: 2.933381724191514

Epoch: 6| Step: 1
Training loss: 3.0198843331323215
Validation loss: 2.9376301750780245

Epoch: 6| Step: 2
Training loss: 3.027371786664529
Validation loss: 2.934153558233525

Epoch: 6| Step: 3
Training loss: 2.9009135484513116
Validation loss: 2.931260773034418

Epoch: 6| Step: 4
Training loss: 2.9217176752013505
Validation loss: 2.9290623212880345

Epoch: 6| Step: 5
Training loss: 3.702776928731699
Validation loss: 2.928632095614369

Epoch: 6| Step: 6
Training loss: 3.355872453023129
Validation loss: 2.9250886423909384

Epoch: 6| Step: 7
Training loss: 2.8553780725278313
Validation loss: 2.924160460800123

Epoch: 6| Step: 8
Training loss: 3.2692602630941883
Validation loss: 2.9249056149226025

Epoch: 6| Step: 9
Training loss: 3.061638224273568
Validation loss: 2.922218462691825

Epoch: 6| Step: 10
Training loss: 2.8155977779177515
Validation loss: 2.9221075462378936

Epoch: 6| Step: 11
Training loss: 3.217751060952166
Validation loss: 2.9194623431277913

Epoch: 6| Step: 12
Training loss: 3.8094472701467232
Validation loss: 2.9189847275199305

Epoch: 6| Step: 13
Training loss: 3.36185934777631
Validation loss: 2.918360362240101

Epoch: 47| Step: 0
Training loss: 3.4245976455364033
Validation loss: 2.919334554434639

Epoch: 6| Step: 1
Training loss: 2.7622510081487968
Validation loss: 2.9198237113819547

Epoch: 6| Step: 2
Training loss: 2.938362481947621
Validation loss: 2.918199374371637

Epoch: 6| Step: 3
Training loss: 3.748829340996664
Validation loss: 2.916515299536024

Epoch: 6| Step: 4
Training loss: 3.272078858066499
Validation loss: 2.913731467217805

Epoch: 6| Step: 5
Training loss: 3.4289608404994523
Validation loss: 2.9132007781964284

Epoch: 6| Step: 6
Training loss: 3.773336910699917
Validation loss: 2.913938468728896

Epoch: 6| Step: 7
Training loss: 3.1659508615561434
Validation loss: 2.9128558051083506

Epoch: 6| Step: 8
Training loss: 3.0367988059657556
Validation loss: 2.917532052076517

Epoch: 6| Step: 9
Training loss: 2.752744345703083
Validation loss: 2.9144437261726255

Epoch: 6| Step: 10
Training loss: 2.7939173228019527
Validation loss: 2.9306725162111182

Epoch: 6| Step: 11
Training loss: 3.0942625911962236
Validation loss: 2.9455701216423913

Epoch: 6| Step: 12
Training loss: 3.2065191382760934
Validation loss: 2.949716261693051

Epoch: 6| Step: 13
Training loss: 3.4464477606294928
Validation loss: 2.9808182621979777

Epoch: 48| Step: 0
Training loss: 3.6309204424749546
Validation loss: 3.0036274384147603

Epoch: 6| Step: 1
Training loss: 3.1387604449913793
Validation loss: 2.9153272741106906

Epoch: 6| Step: 2
Training loss: 3.396188136250924
Validation loss: 2.912307755059406

Epoch: 6| Step: 3
Training loss: 3.3620027422601613
Validation loss: 2.90965042866284

Epoch: 6| Step: 4
Training loss: 3.448315339026894
Validation loss: 2.913826790144309

Epoch: 6| Step: 5
Training loss: 3.1657463208643875
Validation loss: 2.9222667923415533

Epoch: 6| Step: 6
Training loss: 2.719564206329954
Validation loss: 2.9231572518465176

Epoch: 6| Step: 7
Training loss: 2.948552057560629
Validation loss: 2.936781577860133

Epoch: 6| Step: 8
Training loss: 3.187266771348254
Validation loss: 2.9382351714836314

Epoch: 6| Step: 9
Training loss: 3.3771875144582215
Validation loss: 2.944542016860693

Epoch: 6| Step: 10
Training loss: 3.0076943906904052
Validation loss: 2.9179555134300683

Epoch: 6| Step: 11
Training loss: 3.0014562251406476
Validation loss: 2.910975907589183

Epoch: 6| Step: 12
Training loss: 3.242289125619257
Validation loss: 2.906267677488891

Epoch: 6| Step: 13
Training loss: 3.4727699424232017
Validation loss: 2.907050670040557

Epoch: 49| Step: 0
Training loss: 3.070039460366594
Validation loss: 2.90743907429656

Epoch: 6| Step: 1
Training loss: 3.025770130329103
Validation loss: 2.9047108840947695

Epoch: 6| Step: 2
Training loss: 3.592267070484665
Validation loss: 2.904529247800657

Epoch: 6| Step: 3
Training loss: 2.959535291896674
Validation loss: 2.903203940964354

Epoch: 6| Step: 4
Training loss: 2.677431808728855
Validation loss: 2.904050067825437

Epoch: 6| Step: 5
Training loss: 3.996113200061109
Validation loss: 2.904967350611013

Epoch: 6| Step: 6
Training loss: 3.0414825453400844
Validation loss: 2.9045697454831427

Epoch: 6| Step: 7
Training loss: 3.415072154320296
Validation loss: 2.908156124592392

Epoch: 6| Step: 8
Training loss: 3.5640636827064704
Validation loss: 2.9039597808634015

Epoch: 6| Step: 9
Training loss: 2.6004139423972417
Validation loss: 2.902361418598884

Epoch: 6| Step: 10
Training loss: 3.2931309272045253
Validation loss: 2.8996184346623926

Epoch: 6| Step: 11
Training loss: 3.572961671655141
Validation loss: 2.899433231733524

Epoch: 6| Step: 12
Training loss: 2.8506098579953028
Validation loss: 2.8973033753567

Epoch: 6| Step: 13
Training loss: 2.6463595089892586
Validation loss: 2.8950755279463407

Epoch: 50| Step: 0
Training loss: 3.757548047315012
Validation loss: 2.8942681030297646

Epoch: 6| Step: 1
Training loss: 3.4078774020570592
Validation loss: 2.8910262157830577

Epoch: 6| Step: 2
Training loss: 3.2190867127527323
Validation loss: 2.89120297051288

Epoch: 6| Step: 3
Training loss: 3.082223555025147
Validation loss: 2.8893466179088962

Epoch: 6| Step: 4
Training loss: 2.6978917261883124
Validation loss: 2.8889178094042074

Epoch: 6| Step: 5
Training loss: 2.7701549607873748
Validation loss: 2.887896607131361

Epoch: 6| Step: 6
Training loss: 3.025767293671822
Validation loss: 2.8879536522774365

Epoch: 6| Step: 7
Training loss: 2.957998301559074
Validation loss: 2.888105603238218

Epoch: 6| Step: 8
Training loss: 3.4504956207313935
Validation loss: 2.8904768524741336

Epoch: 6| Step: 9
Training loss: 2.7028060460308536
Validation loss: 2.892409212397839

Epoch: 6| Step: 10
Training loss: 3.104560536906848
Validation loss: 2.8962441710178886

Epoch: 6| Step: 11
Training loss: 3.1548628072034117
Validation loss: 2.9010005986388037

Epoch: 6| Step: 12
Training loss: 3.587673988509428
Validation loss: 2.9067208831207396

Epoch: 6| Step: 13
Training loss: 3.7514548976199826
Validation loss: 2.916966930585067

Epoch: 51| Step: 0
Training loss: 3.2530605870446676
Validation loss: 2.9039160841579332

Epoch: 6| Step: 1
Training loss: 2.2920966236325797
Validation loss: 2.8936740358259496

Epoch: 6| Step: 2
Training loss: 3.0389319541370123
Validation loss: 2.9021328102615405

Epoch: 6| Step: 3
Training loss: 3.640020099207123
Validation loss: 2.9093429050997366

Epoch: 6| Step: 4
Training loss: 3.9901136771240076
Validation loss: 2.8929701489313486

Epoch: 6| Step: 5
Training loss: 2.7177879122020667
Validation loss: 2.881089869768712

Epoch: 6| Step: 6
Training loss: 3.3994004562443156
Validation loss: 2.88408520322775

Epoch: 6| Step: 7
Training loss: 2.7743138607719366
Validation loss: 2.881167773909345

Epoch: 6| Step: 8
Training loss: 3.7298712606431446
Validation loss: 2.8800791904484337

Epoch: 6| Step: 9
Training loss: 3.1653143019496426
Validation loss: 2.8832811860046825

Epoch: 6| Step: 10
Training loss: 3.0100675774272427
Validation loss: 2.88030982508585

Epoch: 6| Step: 11
Training loss: 2.9755046897239694
Validation loss: 2.8796621110022698

Epoch: 6| Step: 12
Training loss: 3.081784005153337
Validation loss: 2.878041435356568

Epoch: 6| Step: 13
Training loss: 3.1371890578886896
Validation loss: 2.879694352385433

Epoch: 52| Step: 0
Training loss: 2.9972687049948337
Validation loss: 2.8741939568616264

Epoch: 6| Step: 1
Training loss: 2.9420909312683663
Validation loss: 2.8759398446779936

Epoch: 6| Step: 2
Training loss: 3.102407959979874
Validation loss: 2.8743410090876558

Epoch: 6| Step: 3
Training loss: 2.4454328123482503
Validation loss: 2.872677519922052

Epoch: 6| Step: 4
Training loss: 3.402876557107977
Validation loss: 2.871656859392467

Epoch: 6| Step: 5
Training loss: 3.4547998845709778
Validation loss: 2.87034847611588

Epoch: 6| Step: 6
Training loss: 3.132285513753951
Validation loss: 2.8706956665697145

Epoch: 6| Step: 7
Training loss: 3.9270168200997917
Validation loss: 2.869440505734089

Epoch: 6| Step: 8
Training loss: 3.517667050166925
Validation loss: 2.868335455733598

Epoch: 6| Step: 9
Training loss: 2.6057240419695153
Validation loss: 2.867366097063668

Epoch: 6| Step: 10
Training loss: 3.6993218702628035
Validation loss: 2.86869879253819

Epoch: 6| Step: 11
Training loss: 2.4529247809664083
Validation loss: 2.8680533188516826

Epoch: 6| Step: 12
Training loss: 3.377324751818819
Validation loss: 2.8658966335427425

Epoch: 6| Step: 13
Training loss: 2.8204371036467806
Validation loss: 2.8648621495981756

Epoch: 53| Step: 0
Training loss: 3.057295444536014
Validation loss: 2.8682719488875246

Epoch: 6| Step: 1
Training loss: 3.5719674112642448
Validation loss: 2.871034934919167

Epoch: 6| Step: 2
Training loss: 2.5702298507620465
Validation loss: 2.866171540925938

Epoch: 6| Step: 3
Training loss: 2.8318652295087396
Validation loss: 2.8633028278685777

Epoch: 6| Step: 4
Training loss: 3.600071132804862
Validation loss: 2.8647673576662043

Epoch: 6| Step: 5
Training loss: 3.631715013994228
Validation loss: 2.8605814011102955

Epoch: 6| Step: 6
Training loss: 4.004134187490557
Validation loss: 2.858805864673742

Epoch: 6| Step: 7
Training loss: 2.477977168134258
Validation loss: 2.8614793593514807

Epoch: 6| Step: 8
Training loss: 2.8078313437345908
Validation loss: 2.859042106090498

Epoch: 6| Step: 9
Training loss: 2.9297060546287437
Validation loss: 2.86146785937081

Epoch: 6| Step: 10
Training loss: 2.7597807433624735
Validation loss: 2.859197408324422

Epoch: 6| Step: 11
Training loss: 2.84777061536251
Validation loss: 2.8590314140800404

Epoch: 6| Step: 12
Training loss: 3.2903641324734223
Validation loss: 2.8593644473072053

Epoch: 6| Step: 13
Training loss: 3.697758903182696
Validation loss: 2.8603281106639593

Epoch: 54| Step: 0
Training loss: 3.4889444402117906
Validation loss: 2.8623131903984964

Epoch: 6| Step: 1
Training loss: 2.951912121237485
Validation loss: 2.8610805654270774

Epoch: 6| Step: 2
Training loss: 3.3939187360935783
Validation loss: 2.86271474233112

Epoch: 6| Step: 3
Training loss: 3.2723091019684682
Validation loss: 2.859128921152568

Epoch: 6| Step: 4
Training loss: 2.795561668587763
Validation loss: 2.8611553658102924

Epoch: 6| Step: 5
Training loss: 2.9852568436989744
Validation loss: 2.8541890475733442

Epoch: 6| Step: 6
Training loss: 3.589986538875069
Validation loss: 2.8533605597848046

Epoch: 6| Step: 7
Training loss: 2.670392523069297
Validation loss: 2.852398235521152

Epoch: 6| Step: 8
Training loss: 3.0274834582178505
Validation loss: 2.8522312388754085

Epoch: 6| Step: 9
Training loss: 2.7506142710498374
Validation loss: 2.852989675957125

Epoch: 6| Step: 10
Training loss: 3.9676339089499195
Validation loss: 2.850872293962708

Epoch: 6| Step: 11
Training loss: 3.023548212907538
Validation loss: 2.850041434284214

Epoch: 6| Step: 12
Training loss: 2.7647786542651254
Validation loss: 2.8502526628764153

Epoch: 6| Step: 13
Training loss: 3.271600977399638
Validation loss: 2.8467601254739083

Epoch: 55| Step: 0
Training loss: 3.0278408110081747
Validation loss: 2.8461366591033643

Epoch: 6| Step: 1
Training loss: 3.1556258387044123
Validation loss: 2.847228655810774

Epoch: 6| Step: 2
Training loss: 3.0269556202806207
Validation loss: 2.8456325292665263

Epoch: 6| Step: 3
Training loss: 3.2458093474990948
Validation loss: 2.8485534551845335

Epoch: 6| Step: 4
Training loss: 3.263589178803443
Validation loss: 2.846857633207127

Epoch: 6| Step: 5
Training loss: 3.7462011805176867
Validation loss: 2.8462725961477195

Epoch: 6| Step: 6
Training loss: 2.67099511008206
Validation loss: 2.8443633955829384

Epoch: 6| Step: 7
Training loss: 3.331768638216939
Validation loss: 2.8420582927230216

Epoch: 6| Step: 8
Training loss: 3.0337039413696645
Validation loss: 2.845915921414763

Epoch: 6| Step: 9
Training loss: 3.8505372700528957
Validation loss: 2.845267831824618

Epoch: 6| Step: 10
Training loss: 3.022334407690787
Validation loss: 2.846519143367317

Epoch: 6| Step: 11
Training loss: 2.5956207331202794
Validation loss: 2.8451593479589534

Epoch: 6| Step: 12
Training loss: 3.198337456834874
Validation loss: 2.844952358541382

Epoch: 6| Step: 13
Training loss: 2.3058349856237577
Validation loss: 2.8438426330256537

Epoch: 56| Step: 0
Training loss: 2.4453974212428222
Validation loss: 2.84334557637081

Epoch: 6| Step: 1
Training loss: 2.764300185313883
Validation loss: 2.8415435088308065

Epoch: 6| Step: 2
Training loss: 3.1505559037162643
Validation loss: 2.841231417995551

Epoch: 6| Step: 3
Training loss: 3.6544370150339964
Validation loss: 2.8403262343929416

Epoch: 6| Step: 4
Training loss: 2.6385528740919066
Validation loss: 2.840550224108515

Epoch: 6| Step: 5
Training loss: 3.697150452800385
Validation loss: 2.840246433778072

Epoch: 6| Step: 6
Training loss: 3.4075158243238692
Validation loss: 2.839750813198541

Epoch: 6| Step: 7
Training loss: 3.6259240912830855
Validation loss: 2.837515134284514

Epoch: 6| Step: 8
Training loss: 3.589379879408304
Validation loss: 2.8363071111409703

Epoch: 6| Step: 9
Training loss: 3.12602705290566
Validation loss: 2.8363460620608216

Epoch: 6| Step: 10
Training loss: 2.7316179599419
Validation loss: 2.83529927008875

Epoch: 6| Step: 11
Training loss: 3.3442529317941796
Validation loss: 2.836168906712451

Epoch: 6| Step: 12
Training loss: 2.713158480972148
Validation loss: 2.834656550878579

Epoch: 6| Step: 13
Training loss: 2.40375389332885
Validation loss: 2.8613026544851987

Epoch: 57| Step: 0
Training loss: 2.6411627949780785
Validation loss: 2.8956015060193896

Epoch: 6| Step: 1
Training loss: 3.257477594446401
Validation loss: 2.9178987517086914

Epoch: 6| Step: 2
Training loss: 2.7397918235050303
Validation loss: 2.9675036972189703

Epoch: 6| Step: 3
Training loss: 2.8147295274092468
Validation loss: 2.954094769164854

Epoch: 6| Step: 4
Training loss: 3.8941347767880403
Validation loss: 2.9283679509013996

Epoch: 6| Step: 5
Training loss: 2.996990124477119
Validation loss: 2.8956339329179004

Epoch: 6| Step: 6
Training loss: 2.8031666492102514
Validation loss: 2.8881125571170987

Epoch: 6| Step: 7
Training loss: 3.3031944707893035
Validation loss: 2.8890295776996555

Epoch: 6| Step: 8
Training loss: 3.0305624899904813
Validation loss: 2.8924226562807527

Epoch: 6| Step: 9
Training loss: 3.7441986986889026
Validation loss: 2.891223653691535

Epoch: 6| Step: 10
Training loss: 3.198794084061073
Validation loss: 2.8885183953294633

Epoch: 6| Step: 11
Training loss: 3.6208301106662844
Validation loss: 2.8796794042012275

Epoch: 6| Step: 12
Training loss: 3.384896497623167
Validation loss: 2.8691954581419563

Epoch: 6| Step: 13
Training loss: 2.7833508904030886
Validation loss: 2.8578728407658285

Epoch: 58| Step: 0
Training loss: 3.124464065371977
Validation loss: 2.858294824447067

Epoch: 6| Step: 1
Training loss: 3.139502481298291
Validation loss: 2.8564130941024892

Epoch: 6| Step: 2
Training loss: 3.051247301049701
Validation loss: 2.860322344920942

Epoch: 6| Step: 3
Training loss: 3.2078991550757547
Validation loss: 2.8645154092889045

Epoch: 6| Step: 4
Training loss: 3.0180810601817236
Validation loss: 2.863524472409168

Epoch: 6| Step: 5
Training loss: 2.9181073218435394
Validation loss: 2.860994336473467

Epoch: 6| Step: 6
Training loss: 3.286660520175141
Validation loss: 2.8554078309079567

Epoch: 6| Step: 7
Training loss: 3.43711656686087
Validation loss: 2.8539400890270983

Epoch: 6| Step: 8
Training loss: 4.165582948259238
Validation loss: 2.852905681713943

Epoch: 6| Step: 9
Training loss: 3.055466340429087
Validation loss: 2.84982049708115

Epoch: 6| Step: 10
Training loss: 3.3691363790734115
Validation loss: 2.84724319721069

Epoch: 6| Step: 11
Training loss: 2.2592301191675364
Validation loss: 2.8469054898232136

Epoch: 6| Step: 12
Training loss: 2.9586718907297964
Validation loss: 2.846180338548971

Epoch: 6| Step: 13
Training loss: 2.7068808157379873
Validation loss: 2.847169628669677

Epoch: 59| Step: 0
Training loss: 3.3595129650085513
Validation loss: 2.8452323431643576

Epoch: 6| Step: 1
Training loss: 2.332500263635226
Validation loss: 2.850065924236965

Epoch: 6| Step: 2
Training loss: 2.628985150132404
Validation loss: 2.857684122274309

Epoch: 6| Step: 3
Training loss: 2.67688473411356
Validation loss: 2.859197243344596

Epoch: 6| Step: 4
Training loss: 2.9297387690826495
Validation loss: 2.859732222885758

Epoch: 6| Step: 5
Training loss: 3.806153565235933
Validation loss: 2.863588159743168

Epoch: 6| Step: 6
Training loss: 3.6561922248122887
Validation loss: 2.8656403579074032

Epoch: 6| Step: 7
Training loss: 3.0702281678244114
Validation loss: 2.8571956853040525

Epoch: 6| Step: 8
Training loss: 3.375854666542127
Validation loss: 2.8440756617517

Epoch: 6| Step: 9
Training loss: 2.724793918061427
Validation loss: 2.8422960388832235

Epoch: 6| Step: 10
Training loss: 3.3109040644326972
Validation loss: 2.8397386492552323

Epoch: 6| Step: 11
Training loss: 3.1738242187475962
Validation loss: 2.8374369017011967

Epoch: 6| Step: 12
Training loss: 3.299033665055412
Validation loss: 2.838372814571126

Epoch: 6| Step: 13
Training loss: 3.4636646832105047
Validation loss: 2.837420802086063

Epoch: 60| Step: 0
Training loss: 3.1586164912882486
Validation loss: 2.834657618060908

Epoch: 6| Step: 1
Training loss: 2.9698408833018894
Validation loss: 2.834261386341424

Epoch: 6| Step: 2
Training loss: 2.724485989309694
Validation loss: 2.8351371139869666

Epoch: 6| Step: 3
Training loss: 2.876350748949343
Validation loss: 2.840935323935289

Epoch: 6| Step: 4
Training loss: 3.272479442884487
Validation loss: 2.850423515103862

Epoch: 6| Step: 5
Training loss: 3.089928164094618
Validation loss: 2.837135688509589

Epoch: 6| Step: 6
Training loss: 3.020177063961758
Validation loss: 2.8377506863636923

Epoch: 6| Step: 7
Training loss: 2.1476159206807046
Validation loss: 2.836381928539125

Epoch: 6| Step: 8
Training loss: 3.4669055330683194
Validation loss: 2.841252277270259

Epoch: 6| Step: 9
Training loss: 2.7958834291642236
Validation loss: 2.8472298821533744

Epoch: 6| Step: 10
Training loss: 3.4034090005929913
Validation loss: 2.853170403508094

Epoch: 6| Step: 11
Training loss: 3.9416912720593067
Validation loss: 2.8511620078902733

Epoch: 6| Step: 12
Training loss: 3.4604060537844212
Validation loss: 2.8320718882144678

Epoch: 6| Step: 13
Training loss: 3.374614269678271
Validation loss: 2.829553050841135

Epoch: 61| Step: 0
Training loss: 2.750955155695243
Validation loss: 2.8270698409628667

Epoch: 6| Step: 1
Training loss: 3.4922991911843795
Validation loss: 2.8288402424578427

Epoch: 6| Step: 2
Training loss: 3.2600498338412587
Validation loss: 2.828454328366719

Epoch: 6| Step: 3
Training loss: 3.5919049377946126
Validation loss: 2.828564964241708

Epoch: 6| Step: 4
Training loss: 2.787778500042913
Validation loss: 2.8301101477016273

Epoch: 6| Step: 5
Training loss: 3.298539595693141
Validation loss: 2.8283121884082085

Epoch: 6| Step: 6
Training loss: 2.2825290804260794
Validation loss: 2.826271578827696

Epoch: 6| Step: 7
Training loss: 3.5290631299705284
Validation loss: 2.8256728866551404

Epoch: 6| Step: 8
Training loss: 3.1091753258163233
Validation loss: 2.8248329661699567

Epoch: 6| Step: 9
Training loss: 3.0452453950365332
Validation loss: 2.824598397122164

Epoch: 6| Step: 10
Training loss: 3.3805008317427
Validation loss: 2.8240985733878654

Epoch: 6| Step: 11
Training loss: 2.420578935905361
Validation loss: 2.8214971237000337

Epoch: 6| Step: 12
Training loss: 3.1169679798663648
Validation loss: 2.81935045908821

Epoch: 6| Step: 13
Training loss: 3.806272204104147
Validation loss: 2.819967674736866

Epoch: 62| Step: 0
Training loss: 3.124333730243069
Validation loss: 2.82145155108645

Epoch: 6| Step: 1
Training loss: 2.588801615894412
Validation loss: 2.820608819361473

Epoch: 6| Step: 2
Training loss: 4.044157433951593
Validation loss: 2.821329090348979

Epoch: 6| Step: 3
Training loss: 3.3996525138108815
Validation loss: 2.8220696489495998

Epoch: 6| Step: 4
Training loss: 2.6334873319414958
Validation loss: 2.8243059982715697

Epoch: 6| Step: 5
Training loss: 3.0482772339222417
Validation loss: 2.8334538803901306

Epoch: 6| Step: 6
Training loss: 2.6713349984568975
Validation loss: 2.8371270925335805

Epoch: 6| Step: 7
Training loss: 3.560512322840441
Validation loss: 2.8318446659212286

Epoch: 6| Step: 8
Training loss: 3.876018759415367
Validation loss: 2.82434406540611

Epoch: 6| Step: 9
Training loss: 2.898447206383259
Validation loss: 2.815496954008823

Epoch: 6| Step: 10
Training loss: 3.2502959190043286
Validation loss: 2.8124073792660362

Epoch: 6| Step: 11
Training loss: 2.9097002120135165
Validation loss: 2.8132376465764377

Epoch: 6| Step: 12
Training loss: 2.8030321767146216
Validation loss: 2.812446374963055

Epoch: 6| Step: 13
Training loss: 2.2160537885892793
Validation loss: 2.8135104990386073

Epoch: 63| Step: 0
Training loss: 2.595321638721634
Validation loss: 2.8144560580453124

Epoch: 6| Step: 1
Training loss: 3.2151743462781814
Validation loss: 2.814645307699035

Epoch: 6| Step: 2
Training loss: 2.996791077076204
Validation loss: 2.8143859656240178

Epoch: 6| Step: 3
Training loss: 3.6955045041291807
Validation loss: 2.8141232708900494

Epoch: 6| Step: 4
Training loss: 3.0699970578356632
Validation loss: 2.8127572665483567

Epoch: 6| Step: 5
Training loss: 3.478567304018484
Validation loss: 2.812740066837979

Epoch: 6| Step: 6
Training loss: 2.5109041830153895
Validation loss: 2.811394763025965

Epoch: 6| Step: 7
Training loss: 2.90466856229538
Validation loss: 2.8111964067994815

Epoch: 6| Step: 8
Training loss: 3.125402806070813
Validation loss: 2.810498786034902

Epoch: 6| Step: 9
Training loss: 3.3452619895346745
Validation loss: 2.8093225037780662

Epoch: 6| Step: 10
Training loss: 3.0654114877306973
Validation loss: 2.807880655261645

Epoch: 6| Step: 11
Training loss: 3.0967682266690595
Validation loss: 2.807803035026245

Epoch: 6| Step: 12
Training loss: 3.0698589737400552
Validation loss: 2.8071510303609872

Epoch: 6| Step: 13
Training loss: 3.614638021240463
Validation loss: 2.8071016612666178

Epoch: 64| Step: 0
Training loss: 2.7408583155701924
Validation loss: 2.8057952209786743

Epoch: 6| Step: 1
Training loss: 3.4176325169441526
Validation loss: 2.802704829355797

Epoch: 6| Step: 2
Training loss: 2.8160575407445823
Validation loss: 2.803752064830522

Epoch: 6| Step: 3
Training loss: 2.8715479485017195
Validation loss: 2.802634411941775

Epoch: 6| Step: 4
Training loss: 3.617666389946391
Validation loss: 2.7993054471938366

Epoch: 6| Step: 5
Training loss: 3.70455171166491
Validation loss: 2.801491407044589

Epoch: 6| Step: 6
Training loss: 2.6684875430694985
Validation loss: 2.801269962753093

Epoch: 6| Step: 7
Training loss: 3.231292435092563
Validation loss: 2.799032218417685

Epoch: 6| Step: 8
Training loss: 2.680132948438822
Validation loss: 2.8105427511663366

Epoch: 6| Step: 9
Training loss: 3.3741800230488437
Validation loss: 2.8111769942794247

Epoch: 6| Step: 10
Training loss: 2.960789014973293
Validation loss: 2.817357426965473

Epoch: 6| Step: 11
Training loss: 2.8442410893897083
Validation loss: 2.8137918912002933

Epoch: 6| Step: 12
Training loss: 3.424295205323023
Validation loss: 2.8139885904194655

Epoch: 6| Step: 13
Training loss: 2.866745751051508
Validation loss: 2.80757381665017

Epoch: 65| Step: 0
Training loss: 1.9458103385508696
Validation loss: 2.8050801746116965

Epoch: 6| Step: 1
Training loss: 2.6687150081868753
Validation loss: 2.799032981364372

Epoch: 6| Step: 2
Training loss: 2.2886106285941183
Validation loss: 2.7979810064027757

Epoch: 6| Step: 3
Training loss: 3.027189228667357
Validation loss: 2.8020669961283726

Epoch: 6| Step: 4
Training loss: 3.148596369140408
Validation loss: 2.8004967398311966

Epoch: 6| Step: 5
Training loss: 2.9407510825682723
Validation loss: 2.8046539027669444

Epoch: 6| Step: 6
Training loss: 3.04426502045576
Validation loss: 2.802956243223313

Epoch: 6| Step: 7
Training loss: 3.764207755295185
Validation loss: 2.801501454808301

Epoch: 6| Step: 8
Training loss: 2.8982486303440247
Validation loss: 2.791755300800532

Epoch: 6| Step: 9
Training loss: 4.033925432823841
Validation loss: 2.791393733805666

Epoch: 6| Step: 10
Training loss: 4.088331057556572
Validation loss: 2.7949921390959225

Epoch: 6| Step: 11
Training loss: 3.5477267011557907
Validation loss: 2.7936611119093513

Epoch: 6| Step: 12
Training loss: 2.1041747240976094
Validation loss: 2.789373807698197

Epoch: 6| Step: 13
Training loss: 3.1487876375560453
Validation loss: 2.7883203243480286

Epoch: 66| Step: 0
Training loss: 3.7507743036054455
Validation loss: 2.7891483350550685

Epoch: 6| Step: 1
Training loss: 2.609554627226268
Validation loss: 2.793067083758227

Epoch: 6| Step: 2
Training loss: 3.0363234702118413
Validation loss: 2.7938901861806458

Epoch: 6| Step: 3
Training loss: 2.577750901332413
Validation loss: 2.7919002105287865

Epoch: 6| Step: 4
Training loss: 3.5608457773605533
Validation loss: 2.79144647109737

Epoch: 6| Step: 5
Training loss: 3.1009428620842296
Validation loss: 2.790245120931643

Epoch: 6| Step: 6
Training loss: 3.6493906740537
Validation loss: 2.790950410214854

Epoch: 6| Step: 7
Training loss: 2.574851437329231
Validation loss: 2.787864173244659

Epoch: 6| Step: 8
Training loss: 3.3362919710677206
Validation loss: 2.7894006629079797

Epoch: 6| Step: 9
Training loss: 2.8898545346725295
Validation loss: 2.7887594053104197

Epoch: 6| Step: 10
Training loss: 2.887985261377572
Validation loss: 2.7873614919441216

Epoch: 6| Step: 11
Training loss: 3.64036670472537
Validation loss: 2.7864728214016456

Epoch: 6| Step: 12
Training loss: 2.8995183281606196
Validation loss: 2.786857663922916

Epoch: 6| Step: 13
Training loss: 2.3694450264627274
Validation loss: 2.7857152019010765

Epoch: 67| Step: 0
Training loss: 2.7457711042454322
Validation loss: 2.7830722024892123

Epoch: 6| Step: 1
Training loss: 3.4487878134943766
Validation loss: 2.782185245052596

Epoch: 6| Step: 2
Training loss: 3.2931517779799493
Validation loss: 2.7799460864259777

Epoch: 6| Step: 3
Training loss: 3.4681805667354526
Validation loss: 2.7785929253608384

Epoch: 6| Step: 4
Training loss: 3.1368631636082167
Validation loss: 2.7786734438989233

Epoch: 6| Step: 5
Training loss: 3.6506521295611467
Validation loss: 2.7787108463839543

Epoch: 6| Step: 6
Training loss: 3.3417058382727074
Validation loss: 2.7764530475415796

Epoch: 6| Step: 7
Training loss: 3.2048312969113675
Validation loss: 2.774481959362062

Epoch: 6| Step: 8
Training loss: 2.862446620393479
Validation loss: 2.7731280123978848

Epoch: 6| Step: 9
Training loss: 2.6634859149117167
Validation loss: 2.7751509595357384

Epoch: 6| Step: 10
Training loss: 2.316667873281627
Validation loss: 2.7743377301391767

Epoch: 6| Step: 11
Training loss: 3.077360261522726
Validation loss: 2.77777737839672

Epoch: 6| Step: 12
Training loss: 2.9482078992499337
Validation loss: 2.776993341810037

Epoch: 6| Step: 13
Training loss: 2.9293858894225506
Validation loss: 2.7780230491464137

Epoch: 68| Step: 0
Training loss: 3.0276678883931814
Validation loss: 2.783366092501136

Epoch: 6| Step: 1
Training loss: 2.903801163195155
Validation loss: 2.7883903226780467

Epoch: 6| Step: 2
Training loss: 3.2166338139834503
Validation loss: 2.794259694696351

Epoch: 6| Step: 3
Training loss: 3.2664329587934287
Validation loss: 2.7881953924443232

Epoch: 6| Step: 4
Training loss: 2.7461707591386935
Validation loss: 2.7721898449034783

Epoch: 6| Step: 5
Training loss: 3.4559209904999455
Validation loss: 2.7677740830567297

Epoch: 6| Step: 6
Training loss: 3.41863470074869
Validation loss: 2.7669580972032417

Epoch: 6| Step: 7
Training loss: 3.2902319634474124
Validation loss: 2.7714182806584367

Epoch: 6| Step: 8
Training loss: 2.587891730542217
Validation loss: 2.7725021797940266

Epoch: 6| Step: 9
Training loss: 3.1644562652839774
Validation loss: 2.773484651868686

Epoch: 6| Step: 10
Training loss: 3.468479042811469
Validation loss: 2.773354557315938

Epoch: 6| Step: 11
Training loss: 3.0274321118656924
Validation loss: 2.7675150702285976

Epoch: 6| Step: 12
Training loss: 2.832342385926052
Validation loss: 2.7685101157701273

Epoch: 6| Step: 13
Training loss: 2.5003818220386753
Validation loss: 2.7674413646328246

Epoch: 69| Step: 0
Training loss: 3.119464090734001
Validation loss: 2.767768017062752

Epoch: 6| Step: 1
Training loss: 2.8642080350153827
Validation loss: 2.7689554878450897

Epoch: 6| Step: 2
Training loss: 2.4594041679620617
Validation loss: 2.7682026305484904

Epoch: 6| Step: 3
Training loss: 3.336307406855236
Validation loss: 2.768545570234817

Epoch: 6| Step: 4
Training loss: 3.0910037403608563
Validation loss: 2.767973207743603

Epoch: 6| Step: 5
Training loss: 3.2741940154495524
Validation loss: 2.7668007965897954

Epoch: 6| Step: 6
Training loss: 3.2328658706588644
Validation loss: 2.7673105450109543

Epoch: 6| Step: 7
Training loss: 3.233630108404255
Validation loss: 2.7664874519789833

Epoch: 6| Step: 8
Training loss: 3.063703962063418
Validation loss: 2.765744438857526

Epoch: 6| Step: 9
Training loss: 3.289475077578601
Validation loss: 2.7675315616864906

Epoch: 6| Step: 10
Training loss: 3.5743518908774687
Validation loss: 2.7679203270076695

Epoch: 6| Step: 11
Training loss: 3.149043552576005
Validation loss: 2.767090163847228

Epoch: 6| Step: 12
Training loss: 2.4654099287214253
Validation loss: 2.7615070909672945

Epoch: 6| Step: 13
Training loss: 2.758650006866054
Validation loss: 2.760141464758557

Epoch: 70| Step: 0
Training loss: 2.8660141209575922
Validation loss: 2.761784234540929

Epoch: 6| Step: 1
Training loss: 3.040091293871492
Validation loss: 2.761162680091404

Epoch: 6| Step: 2
Training loss: 3.0607512794696974
Validation loss: 2.7598405081556323

Epoch: 6| Step: 3
Training loss: 3.149756522078566
Validation loss: 2.7589208372114244

Epoch: 6| Step: 4
Training loss: 2.9083570820040086
Validation loss: 2.7616449648985903

Epoch: 6| Step: 5
Training loss: 3.4444662079755903
Validation loss: 2.759751195827562

Epoch: 6| Step: 6
Training loss: 2.7187479830328813
Validation loss: 2.7558904424138486

Epoch: 6| Step: 7
Training loss: 3.565653158439427
Validation loss: 2.7563658221667553

Epoch: 6| Step: 8
Training loss: 3.1472806485364244
Validation loss: 2.75699109702272

Epoch: 6| Step: 9
Training loss: 3.153487705809769
Validation loss: 2.7553173761388234

Epoch: 6| Step: 10
Training loss: 2.6141786502769784
Validation loss: 2.7552229875876244

Epoch: 6| Step: 11
Training loss: 2.9412459168930667
Validation loss: 2.755010295376936

Epoch: 6| Step: 12
Training loss: 2.574232272169056
Validation loss: 2.750101054060439

Epoch: 6| Step: 13
Training loss: 4.15323156445418
Validation loss: 2.7542529160600786

Epoch: 71| Step: 0
Training loss: 3.523385396432589
Validation loss: 2.7565723796076194

Epoch: 6| Step: 1
Training loss: 2.8920339089142884
Validation loss: 2.7500264193551343

Epoch: 6| Step: 2
Training loss: 3.427918831842463
Validation loss: 2.750791665060367

Epoch: 6| Step: 3
Training loss: 2.6432481185659604
Validation loss: 2.751485685222317

Epoch: 6| Step: 4
Training loss: 2.331094780630281
Validation loss: 2.748415830936093

Epoch: 6| Step: 5
Training loss: 2.8684564843377114
Validation loss: 2.749685327270588

Epoch: 6| Step: 6
Training loss: 3.2416428441706215
Validation loss: 2.7492258971766037

Epoch: 6| Step: 7
Training loss: 2.7594575379276067
Validation loss: 2.747898542473819

Epoch: 6| Step: 8
Training loss: 3.619065260784393
Validation loss: 2.7472830501926144

Epoch: 6| Step: 9
Training loss: 3.30789368123951
Validation loss: 2.7466525047895702

Epoch: 6| Step: 10
Training loss: 3.162013918947955
Validation loss: 2.747252156992852

Epoch: 6| Step: 11
Training loss: 3.5070891112315143
Validation loss: 2.748201886146093

Epoch: 6| Step: 12
Training loss: 2.6696300333137
Validation loss: 2.7465069242829636

Epoch: 6| Step: 13
Training loss: 2.558129933956187
Validation loss: 2.7424003715477694

Epoch: 72| Step: 0
Training loss: 2.298244976017047
Validation loss: 2.7444771901367355

Epoch: 6| Step: 1
Training loss: 2.289271634804381
Validation loss: 2.7440651854161113

Epoch: 6| Step: 2
Training loss: 3.1860626570292996
Validation loss: 2.7453498790302358

Epoch: 6| Step: 3
Training loss: 3.6284392254478446
Validation loss: 2.744484431339563

Epoch: 6| Step: 4
Training loss: 3.609280143250981
Validation loss: 2.7431306238798814

Epoch: 6| Step: 5
Training loss: 2.988582820261063
Validation loss: 2.740408084327099

Epoch: 6| Step: 6
Training loss: 3.101332495013862
Validation loss: 2.7421904916428246

Epoch: 6| Step: 7
Training loss: 2.7793977548891435
Validation loss: 2.742577876205402

Epoch: 6| Step: 8
Training loss: 3.292122837440066
Validation loss: 2.7412028889680915

Epoch: 6| Step: 9
Training loss: 3.407684584031093
Validation loss: 2.742508970749179

Epoch: 6| Step: 10
Training loss: 2.9200655796577504
Validation loss: 2.743913455418232

Epoch: 6| Step: 11
Training loss: 3.473887994255264
Validation loss: 2.7599267625090564

Epoch: 6| Step: 12
Training loss: 3.0048129892155835
Validation loss: 2.7624373250360716

Epoch: 6| Step: 13
Training loss: 2.443415189085736
Validation loss: 2.7504594862730904

Epoch: 73| Step: 0
Training loss: 3.3660943542601753
Validation loss: 2.7369185685757307

Epoch: 6| Step: 1
Training loss: 2.459346002313265
Validation loss: 2.738660816995681

Epoch: 6| Step: 2
Training loss: 2.8077245224048206
Validation loss: 2.7366392047169636

Epoch: 6| Step: 3
Training loss: 2.9688254898913664
Validation loss: 2.737809877551487

Epoch: 6| Step: 4
Training loss: 3.670704496780631
Validation loss: 2.7360798995149547

Epoch: 6| Step: 5
Training loss: 3.549814896391785
Validation loss: 2.7358862235115287

Epoch: 6| Step: 6
Training loss: 3.4119816424825173
Validation loss: 2.7342143706269795

Epoch: 6| Step: 7
Training loss: 2.780239478849514
Validation loss: 2.7363345042819947

Epoch: 6| Step: 8
Training loss: 2.988258591110989
Validation loss: 2.73288580638321

Epoch: 6| Step: 9
Training loss: 3.1392703954458363
Validation loss: 2.7364273305680533

Epoch: 6| Step: 10
Training loss: 2.3295645135746925
Validation loss: 2.733655303607277

Epoch: 6| Step: 11
Training loss: 3.011470324293288
Validation loss: 2.734601045749133

Epoch: 6| Step: 12
Training loss: 2.8369794460516164
Validation loss: 2.732624326311508

Epoch: 6| Step: 13
Training loss: 3.4277034921151506
Validation loss: 2.7329813162786123

Epoch: 74| Step: 0
Training loss: 2.4972377776143655
Validation loss: 2.7333647265333467

Epoch: 6| Step: 1
Training loss: 2.958805171966261
Validation loss: 2.733302164637876

Epoch: 6| Step: 2
Training loss: 3.240835031823004
Validation loss: 2.7353704081610206

Epoch: 6| Step: 3
Training loss: 3.4727016999539124
Validation loss: 2.7313741758089702

Epoch: 6| Step: 4
Training loss: 3.1633140149613626
Validation loss: 2.732305304920891

Epoch: 6| Step: 5
Training loss: 2.9416250930168193
Validation loss: 2.7332133470406994

Epoch: 6| Step: 6
Training loss: 3.7237256526503204
Validation loss: 2.727754861007918

Epoch: 6| Step: 7
Training loss: 2.732266381442812
Validation loss: 2.7294728170726015

Epoch: 6| Step: 8
Training loss: 3.083041838880174
Validation loss: 2.727615296576845

Epoch: 6| Step: 9
Training loss: 2.6067102954299575
Validation loss: 2.725573390089799

Epoch: 6| Step: 10
Training loss: 2.748386776853488
Validation loss: 2.7278019435366194

Epoch: 6| Step: 11
Training loss: 3.9089044935767854
Validation loss: 2.7294956917917927

Epoch: 6| Step: 12
Training loss: 2.575823131957803
Validation loss: 2.7261099848425707

Epoch: 6| Step: 13
Training loss: 2.631091905497286
Validation loss: 2.7289122953200846

Epoch: 75| Step: 0
Training loss: 3.6895552258073367
Validation loss: 2.7306586671651045

Epoch: 6| Step: 1
Training loss: 3.1285423038567792
Validation loss: 2.7323522011394012

Epoch: 6| Step: 2
Training loss: 3.2170928837414112
Validation loss: 2.7379417078434365

Epoch: 6| Step: 3
Training loss: 2.969440259495367
Validation loss: 2.753927232645937

Epoch: 6| Step: 4
Training loss: 2.9589569795555244
Validation loss: 2.769227574724536

Epoch: 6| Step: 5
Training loss: 2.9225836725714376
Validation loss: 2.7568952918818788

Epoch: 6| Step: 6
Training loss: 2.6509769834010664
Validation loss: 2.7359029421660064

Epoch: 6| Step: 7
Training loss: 3.621825834505061
Validation loss: 2.727526832366545

Epoch: 6| Step: 8
Training loss: 3.223223789987564
Validation loss: 2.726269093480607

Epoch: 6| Step: 9
Training loss: 3.0301506959310243
Validation loss: 2.7238470795280416

Epoch: 6| Step: 10
Training loss: 2.341336648114638
Validation loss: 2.726798751124641

Epoch: 6| Step: 11
Training loss: 3.3616518333560443
Validation loss: 2.730233161052392

Epoch: 6| Step: 12
Training loss: 3.0562420179890815
Validation loss: 2.7366658401752804

Epoch: 6| Step: 13
Training loss: 1.694248269751055
Validation loss: 2.734469216594286

Epoch: 76| Step: 0
Training loss: 3.0945051408343773
Validation loss: 2.7347061491115108

Epoch: 6| Step: 1
Training loss: 3.6000096744831214
Validation loss: 2.746020169625199

Epoch: 6| Step: 2
Training loss: 3.1475937993114464
Validation loss: 2.761191768720848

Epoch: 6| Step: 3
Training loss: 3.499808442459549
Validation loss: 2.77179360217072

Epoch: 6| Step: 4
Training loss: 3.066982803082583
Validation loss: 2.7634018405510337

Epoch: 6| Step: 5
Training loss: 2.701725415534907
Validation loss: 2.7549239019821274

Epoch: 6| Step: 6
Training loss: 2.916086920385964
Validation loss: 2.7402462939478696

Epoch: 6| Step: 7
Training loss: 3.129059405632474
Validation loss: 2.7329304553788893

Epoch: 6| Step: 8
Training loss: 2.836956923353074
Validation loss: 2.736192885219109

Epoch: 6| Step: 9
Training loss: 3.222157868659822
Validation loss: 2.740009576178801

Epoch: 6| Step: 10
Training loss: 3.0713441780130166
Validation loss: 2.7395013433307587

Epoch: 6| Step: 11
Training loss: 2.9545678544695906
Validation loss: 2.727986483951425

Epoch: 6| Step: 12
Training loss: 2.519798560341379
Validation loss: 2.7141021945699264

Epoch: 6| Step: 13
Training loss: 2.663561015878712
Validation loss: 2.7142978556413335

Epoch: 77| Step: 0
Training loss: 2.348531804123429
Validation loss: 2.7130414243317333

Epoch: 6| Step: 1
Training loss: 3.4267791025539123
Validation loss: 2.7134027811433605

Epoch: 6| Step: 2
Training loss: 2.2666383778919856
Validation loss: 2.7165501187608037

Epoch: 6| Step: 3
Training loss: 3.5217099575036377
Validation loss: 2.718291437639731

Epoch: 6| Step: 4
Training loss: 3.011108494937725
Validation loss: 2.7172095612095117

Epoch: 6| Step: 5
Training loss: 3.604544706124776
Validation loss: 2.714192139095595

Epoch: 6| Step: 6
Training loss: 3.4140465777481976
Validation loss: 2.7190920574872726

Epoch: 6| Step: 7
Training loss: 2.921444131834406
Validation loss: 2.7163417089831867

Epoch: 6| Step: 8
Training loss: 3.8010266372803088
Validation loss: 2.7130557041119756

Epoch: 6| Step: 9
Training loss: 2.5258259999080543
Validation loss: 2.707735748876206

Epoch: 6| Step: 10
Training loss: 2.5819920985590725
Validation loss: 2.7097206866100696

Epoch: 6| Step: 11
Training loss: 2.9160740023146015
Validation loss: 2.709678793404832

Epoch: 6| Step: 12
Training loss: 2.8069512627382647
Validation loss: 2.7089159920117085

Epoch: 6| Step: 13
Training loss: 3.2951638359587747
Validation loss: 2.7040938187647114

Epoch: 78| Step: 0
Training loss: 3.4491045577607835
Validation loss: 2.7073711699220695

Epoch: 6| Step: 1
Training loss: 3.1988481952104224
Validation loss: 2.70149988909333

Epoch: 6| Step: 2
Training loss: 3.08386098797265
Validation loss: 2.705110942244212

Epoch: 6| Step: 3
Training loss: 3.2996945731109526
Validation loss: 2.704656454139055

Epoch: 6| Step: 4
Training loss: 3.0346140334230554
Validation loss: 2.7053268032220874

Epoch: 6| Step: 5
Training loss: 3.0829495027844276
Validation loss: 2.7057408958868625

Epoch: 6| Step: 6
Training loss: 2.8183420330103583
Validation loss: 2.7071620113660617

Epoch: 6| Step: 7
Training loss: 3.498874755902977
Validation loss: 2.7076567660638378

Epoch: 6| Step: 8
Training loss: 2.6155078565464587
Validation loss: 2.7066287511371065

Epoch: 6| Step: 9
Training loss: 3.0411035896176974
Validation loss: 2.7053425565269342

Epoch: 6| Step: 10
Training loss: 2.9223320751388355
Validation loss: 2.7038617580801914

Epoch: 6| Step: 11
Training loss: 2.5263871943061695
Validation loss: 2.7056220297714595

Epoch: 6| Step: 12
Training loss: 3.0454642918093042
Validation loss: 2.706461218845807

Epoch: 6| Step: 13
Training loss: 2.88966658916232
Validation loss: 2.705822127031711

Epoch: 79| Step: 0
Training loss: 2.53159772580244
Validation loss: 2.706159805863385

Epoch: 6| Step: 1
Training loss: 1.747902635132308
Validation loss: 2.706405537265503

Epoch: 6| Step: 2
Training loss: 2.6396805919702695
Validation loss: 2.7107792571382814

Epoch: 6| Step: 3
Training loss: 3.2541878934421096
Validation loss: 2.720142724890879

Epoch: 6| Step: 4
Training loss: 3.4702483369202066
Validation loss: 2.7184224669876875

Epoch: 6| Step: 5
Training loss: 2.906424568429853
Validation loss: 2.7120179668714286

Epoch: 6| Step: 6
Training loss: 2.838971829265532
Validation loss: 2.7082571815657697

Epoch: 6| Step: 7
Training loss: 3.805387773241556
Validation loss: 2.7089676917882604

Epoch: 6| Step: 8
Training loss: 3.3166204771982137
Validation loss: 2.7047307408424928

Epoch: 6| Step: 9
Training loss: 2.908039813455212
Validation loss: 2.7058694661315643

Epoch: 6| Step: 10
Training loss: 3.3069636304878136
Validation loss: 2.6984293498822693

Epoch: 6| Step: 11
Training loss: 3.5904154026619084
Validation loss: 2.694563389811063

Epoch: 6| Step: 12
Training loss: 3.0459386707325966
Validation loss: 2.6990450673235866

Epoch: 6| Step: 13
Training loss: 2.3576409238926064
Validation loss: 2.697041873847405

Epoch: 80| Step: 0
Training loss: 2.641316881899154
Validation loss: 2.6959412247934527

Epoch: 6| Step: 1
Training loss: 2.450385830140375
Validation loss: 2.6946710875262614

Epoch: 6| Step: 2
Training loss: 2.9579550989339864
Validation loss: 2.6958157319706797

Epoch: 6| Step: 3
Training loss: 3.0265674407871392
Validation loss: 2.6900642945672057

Epoch: 6| Step: 4
Training loss: 2.795046245758767
Validation loss: 2.6970417578817734

Epoch: 6| Step: 5
Training loss: 2.8613396237503594
Validation loss: 2.7039730181736457

Epoch: 6| Step: 6
Training loss: 3.0117003839825864
Validation loss: 2.7188642423844835

Epoch: 6| Step: 7
Training loss: 3.14403580263248
Validation loss: 2.7154738361868844

Epoch: 6| Step: 8
Training loss: 3.19392495469304
Validation loss: 2.6979145147122052

Epoch: 6| Step: 9
Training loss: 2.9994323511318126
Validation loss: 2.6895598577904942

Epoch: 6| Step: 10
Training loss: 3.8057634214881135
Validation loss: 2.6874443214412413

Epoch: 6| Step: 11
Training loss: 3.4472347787660302
Validation loss: 2.6873952335313707

Epoch: 6| Step: 12
Training loss: 3.0640354589098724
Validation loss: 2.6913564856511187

Epoch: 6| Step: 13
Training loss: 2.8306738395629987
Validation loss: 2.6885540176672844

Epoch: 81| Step: 0
Training loss: 3.359693219394054
Validation loss: 2.6856762000722085

Epoch: 6| Step: 1
Training loss: 3.359062712592444
Validation loss: 2.690442856187158

Epoch: 6| Step: 2
Training loss: 3.206145411638987
Validation loss: 2.6945835140079684

Epoch: 6| Step: 3
Training loss: 2.686676076520749
Validation loss: 2.6948724459701654

Epoch: 6| Step: 4
Training loss: 2.8502990431918045
Validation loss: 2.6987665278776896

Epoch: 6| Step: 5
Training loss: 3.1892047885848775
Validation loss: 2.6986180211567374

Epoch: 6| Step: 6
Training loss: 2.777822547127969
Validation loss: 2.705354900215778

Epoch: 6| Step: 7
Training loss: 2.5929182626395564
Validation loss: 2.7074622877793404

Epoch: 6| Step: 8
Training loss: 3.1081551310683677
Validation loss: 2.7010656551591428

Epoch: 6| Step: 9
Training loss: 2.8836048556981853
Validation loss: 2.6940082397049294

Epoch: 6| Step: 10
Training loss: 2.7759566780139866
Validation loss: 2.691724590898769

Epoch: 6| Step: 11
Training loss: 3.6313063914242263
Validation loss: 2.6977724505631486

Epoch: 6| Step: 12
Training loss: 2.968624554041633
Validation loss: 2.6922475572473923

Epoch: 6| Step: 13
Training loss: 2.7731156283296117
Validation loss: 2.6827210473423255

Epoch: 82| Step: 0
Training loss: 2.7668699059655997
Validation loss: 2.6798631088015448

Epoch: 6| Step: 1
Training loss: 3.224170158136534
Validation loss: 2.682469944694707

Epoch: 6| Step: 2
Training loss: 3.0063534851662066
Validation loss: 2.680292608006351

Epoch: 6| Step: 3
Training loss: 2.92128874257244
Validation loss: 2.6807015299366395

Epoch: 6| Step: 4
Training loss: 3.273009788957754
Validation loss: 2.6809932928627376

Epoch: 6| Step: 5
Training loss: 3.2391391625466266
Validation loss: 2.682277770125394

Epoch: 6| Step: 6
Training loss: 2.802692862279675
Validation loss: 2.6827265401949285

Epoch: 6| Step: 7
Training loss: 3.266502882945238
Validation loss: 2.681261147608981

Epoch: 6| Step: 8
Training loss: 2.8079374817303453
Validation loss: 2.681630294475541

Epoch: 6| Step: 9
Training loss: 3.077229635849507
Validation loss: 2.681414466703625

Epoch: 6| Step: 10
Training loss: 2.8634228014337157
Validation loss: 2.678816441718993

Epoch: 6| Step: 11
Training loss: 2.651106038589222
Validation loss: 2.675916151492458

Epoch: 6| Step: 12
Training loss: 3.558602191734979
Validation loss: 2.6780377073759354

Epoch: 6| Step: 13
Training loss: 2.711938590741389
Validation loss: 2.6783444761120556

Epoch: 83| Step: 0
Training loss: 2.8768855007327234
Validation loss: 2.674685119398808

Epoch: 6| Step: 1
Training loss: 2.582887816210834
Validation loss: 2.675527922708458

Epoch: 6| Step: 2
Training loss: 2.830790912384069
Validation loss: 2.6770395937953837

Epoch: 6| Step: 3
Training loss: 3.2307633585055573
Validation loss: 2.672102195945247

Epoch: 6| Step: 4
Training loss: 2.6864615807298544
Validation loss: 2.6741243843969875

Epoch: 6| Step: 5
Training loss: 3.7179818522075556
Validation loss: 2.671950428379022

Epoch: 6| Step: 6
Training loss: 3.505049605079766
Validation loss: 2.67060687532208

Epoch: 6| Step: 7
Training loss: 3.328300363997859
Validation loss: 2.676038480148673

Epoch: 6| Step: 8
Training loss: 3.304349408542158
Validation loss: 2.680388157966831

Epoch: 6| Step: 9
Training loss: 1.8524165376917172
Validation loss: 2.699856262870258

Epoch: 6| Step: 10
Training loss: 3.356521601138764
Validation loss: 2.732040759967981

Epoch: 6| Step: 11
Training loss: 2.5048375056818766
Validation loss: 2.702016912148341

Epoch: 6| Step: 12
Training loss: 3.1250012207028868
Validation loss: 2.681431530724514

Epoch: 6| Step: 13
Training loss: 2.88057979972869
Validation loss: 2.673709717521282

Epoch: 84| Step: 0
Training loss: 3.213762289147637
Validation loss: 2.6713810571908367

Epoch: 6| Step: 1
Training loss: 2.990713050048348
Validation loss: 2.6746600482373846

Epoch: 6| Step: 2
Training loss: 2.8014754495111798
Validation loss: 2.6781442585400566

Epoch: 6| Step: 3
Training loss: 2.503794460806504
Validation loss: 2.6931487403393852

Epoch: 6| Step: 4
Training loss: 2.9834855436854193
Validation loss: 2.7242175644958513

Epoch: 6| Step: 5
Training loss: 3.261375034518982
Validation loss: 2.882958227823382

Epoch: 6| Step: 6
Training loss: 3.6088171854031525
Validation loss: 2.9499414110700877

Epoch: 6| Step: 7
Training loss: 3.6286257008161553
Validation loss: 2.8860363290255604

Epoch: 6| Step: 8
Training loss: 3.2445672918458506
Validation loss: 2.761449190200149

Epoch: 6| Step: 9
Training loss: 3.0120087915624048
Validation loss: 2.700800283767887

Epoch: 6| Step: 10
Training loss: 2.929765623958361
Validation loss: 2.7252261538069704

Epoch: 6| Step: 11
Training loss: 2.905767093038741
Validation loss: 2.82533552457071

Epoch: 6| Step: 12
Training loss: 3.649956789152867
Validation loss: 2.894194372805164

Epoch: 6| Step: 13
Training loss: 3.0502346198722305
Validation loss: 2.9169387186566107

Epoch: 85| Step: 0
Training loss: 2.616919933705005
Validation loss: 2.9140924112782463

Epoch: 6| Step: 1
Training loss: 2.531948040445657
Validation loss: 2.9144992498326987

Epoch: 6| Step: 2
Training loss: 3.5553629809786895
Validation loss: 2.9227449469831672

Epoch: 6| Step: 3
Training loss: 3.7617461301573645
Validation loss: 2.753258114701302

Epoch: 6| Step: 4
Training loss: 2.8350468858074573
Validation loss: 2.688822373008714

Epoch: 6| Step: 5
Training loss: 3.6875554743327914
Validation loss: 2.7882294491210784

Epoch: 6| Step: 6
Training loss: 2.386330131196468
Validation loss: 2.7698746878787133

Epoch: 6| Step: 7
Training loss: 3.463115618131439
Validation loss: 2.7349972234064976

Epoch: 6| Step: 8
Training loss: 2.518684753633053
Validation loss: 2.710339443265698

Epoch: 6| Step: 9
Training loss: 3.1241847691520674
Validation loss: 2.7046309404216458

Epoch: 6| Step: 10
Training loss: 2.8589657349909845
Validation loss: 2.697646160076037

Epoch: 6| Step: 11
Training loss: 3.242357511544033
Validation loss: 2.708953611906609

Epoch: 6| Step: 12
Training loss: 3.1071143438725324
Validation loss: 2.7093504060079225

Epoch: 6| Step: 13
Training loss: 2.8067879210109044
Validation loss: 2.69980779660264

Epoch: 86| Step: 0
Training loss: 3.318855953500828
Validation loss: 2.69857495049399

Epoch: 6| Step: 1
Training loss: 2.998499813098275
Validation loss: 2.7008766014887557

Epoch: 6| Step: 2
Training loss: 2.9512544389406177
Validation loss: 2.6888772059477524

Epoch: 6| Step: 3
Training loss: 2.8233546706665305
Validation loss: 2.6876807174724453

Epoch: 6| Step: 4
Training loss: 3.8870926720259664
Validation loss: 2.684019798239319

Epoch: 6| Step: 5
Training loss: 3.6019294866239857
Validation loss: 2.684876730139281

Epoch: 6| Step: 6
Training loss: 3.1427808356000955
Validation loss: 2.680169875213293

Epoch: 6| Step: 7
Training loss: 3.071284715318863
Validation loss: 2.6935783877269976

Epoch: 6| Step: 8
Training loss: 2.977947883903136
Validation loss: 2.7028404122544765

Epoch: 6| Step: 9
Training loss: 2.070018473925138
Validation loss: 2.680347367241264

Epoch: 6| Step: 10
Training loss: 3.136629970334528
Validation loss: 2.6798456119599567

Epoch: 6| Step: 11
Training loss: 2.6110402350128963
Validation loss: 2.685433795655106

Epoch: 6| Step: 12
Training loss: 2.758411720598815
Validation loss: 2.6857775810835136

Epoch: 6| Step: 13
Training loss: 2.549840967043701
Validation loss: 2.682323433560193

Epoch: 87| Step: 0
Training loss: 3.0092357884548657
Validation loss: 2.688597969726564

Epoch: 6| Step: 1
Training loss: 3.106309309149507
Validation loss: 2.6902021768186297

Epoch: 6| Step: 2
Training loss: 2.615682322832238
Validation loss: 2.6900113127699625

Epoch: 6| Step: 3
Training loss: 2.6823448595618116
Validation loss: 2.695109374726901

Epoch: 6| Step: 4
Training loss: 3.276586506491395
Validation loss: 2.6804566312949767

Epoch: 6| Step: 5
Training loss: 2.801549829985206
Validation loss: 2.6816567927740578

Epoch: 6| Step: 6
Training loss: 3.392350140313836
Validation loss: 2.693101523185863

Epoch: 6| Step: 7
Training loss: 2.708215407714105
Validation loss: 2.698025022354694

Epoch: 6| Step: 8
Training loss: 2.824047542463605
Validation loss: 2.6874585722019386

Epoch: 6| Step: 9
Training loss: 3.1539567226616874
Validation loss: 2.670486003760021

Epoch: 6| Step: 10
Training loss: 2.9166323705200874
Validation loss: 2.657395972572916

Epoch: 6| Step: 11
Training loss: 3.35566115799122
Validation loss: 2.658477206571588

Epoch: 6| Step: 12
Training loss: 3.0922962202376874
Validation loss: 2.6620426278701843

Epoch: 6| Step: 13
Training loss: 3.297578131015453
Validation loss: 2.6589938619168154

Epoch: 88| Step: 0
Training loss: 3.011722708178738
Validation loss: 2.6647166812195233

Epoch: 6| Step: 1
Training loss: 3.128920880115609
Validation loss: 2.667360248915398

Epoch: 6| Step: 2
Training loss: 2.5645165301210597
Validation loss: 2.6680968439775197

Epoch: 6| Step: 3
Training loss: 2.7900162463244973
Validation loss: 2.665898520702827

Epoch: 6| Step: 4
Training loss: 3.6526711709856405
Validation loss: 2.673950511788739

Epoch: 6| Step: 5
Training loss: 2.5871962511836384
Validation loss: 2.670595209062631

Epoch: 6| Step: 6
Training loss: 2.773069201448191
Validation loss: 2.6754510543896166

Epoch: 6| Step: 7
Training loss: 2.5902614803216273
Validation loss: 2.6704939409479507

Epoch: 6| Step: 8
Training loss: 3.1878099477828967
Validation loss: 2.668829147488182

Epoch: 6| Step: 9
Training loss: 2.9729042300681714
Validation loss: 2.677134913685021

Epoch: 6| Step: 10
Training loss: 3.5446910436209476
Validation loss: 2.676602232534772

Epoch: 6| Step: 11
Training loss: 2.80503141796992
Validation loss: 2.6686827654956096

Epoch: 6| Step: 12
Training loss: 3.1896636201972406
Validation loss: 2.6730666027789995

Epoch: 6| Step: 13
Training loss: 3.280579125986061
Validation loss: 2.670144795652619

Epoch: 89| Step: 0
Training loss: 3.63407393673898
Validation loss: 2.665317538932748

Epoch: 6| Step: 1
Training loss: 2.9149605438545825
Validation loss: 2.664788083081085

Epoch: 6| Step: 2
Training loss: 2.872451813960149
Validation loss: 2.6620918664392677

Epoch: 6| Step: 3
Training loss: 3.352779709812701
Validation loss: 2.6597032562296197

Epoch: 6| Step: 4
Training loss: 2.3405417291270223
Validation loss: 2.658670118920853

Epoch: 6| Step: 5
Training loss: 2.972711108950931
Validation loss: 2.65704002720117

Epoch: 6| Step: 6
Training loss: 3.10111661920165
Validation loss: 2.654827297177043

Epoch: 6| Step: 7
Training loss: 2.829712480153578
Validation loss: 2.663394877884842

Epoch: 6| Step: 8
Training loss: 2.582129680009741
Validation loss: 2.6735999269912547

Epoch: 6| Step: 9
Training loss: 2.8157713620231486
Validation loss: 2.6723162815515678

Epoch: 6| Step: 10
Training loss: 2.824453594737517
Validation loss: 2.672606542622228

Epoch: 6| Step: 11
Training loss: 3.0523935275367498
Validation loss: 2.677663689838663

Epoch: 6| Step: 12
Training loss: 3.552350225331546
Validation loss: 2.67630001339126

Epoch: 6| Step: 13
Training loss: 3.391601703093504
Validation loss: 2.68109570769779

Epoch: 90| Step: 0
Training loss: 3.0543774693812598
Validation loss: 2.68029870219834

Epoch: 6| Step: 1
Training loss: 2.0139344688899166
Validation loss: 2.6818950286142664

Epoch: 6| Step: 2
Training loss: 3.5282344939656687
Validation loss: 2.694604446742797

Epoch: 6| Step: 3
Training loss: 2.679518624814909
Validation loss: 2.7091015075778797

Epoch: 6| Step: 4
Training loss: 3.290476442988582
Validation loss: 2.7091103725636

Epoch: 6| Step: 5
Training loss: 2.678777690393658
Validation loss: 2.7159115490073615

Epoch: 6| Step: 6
Training loss: 3.29608101346163
Validation loss: 2.6965015082835184

Epoch: 6| Step: 7
Training loss: 3.1855497190648707
Validation loss: 2.686813461400119

Epoch: 6| Step: 8
Training loss: 2.8962040030457628
Validation loss: 2.679322993973967

Epoch: 6| Step: 9
Training loss: 3.3917884061242596
Validation loss: 2.675959316694324

Epoch: 6| Step: 10
Training loss: 3.154563377625276
Validation loss: 2.678102235147731

Epoch: 6| Step: 11
Training loss: 2.6778298214207403
Validation loss: 2.671651740090386

Epoch: 6| Step: 12
Training loss: 3.057978815498099
Validation loss: 2.670490863226452

Epoch: 6| Step: 13
Training loss: 3.080746536442386
Validation loss: 2.668593748323053

Epoch: 91| Step: 0
Training loss: 3.4387801127638897
Validation loss: 2.6640800196670273

Epoch: 6| Step: 1
Training loss: 3.024357145745114
Validation loss: 2.665702492340666

Epoch: 6| Step: 2
Training loss: 3.319574251567499
Validation loss: 2.667050951781622

Epoch: 6| Step: 3
Training loss: 3.48798282794925
Validation loss: 2.6658606086494268

Epoch: 6| Step: 4
Training loss: 2.501777207967013
Validation loss: 2.6683329143589045

Epoch: 6| Step: 5
Training loss: 2.817803701501457
Validation loss: 2.6681739577950623

Epoch: 6| Step: 6
Training loss: 2.805228008584198
Validation loss: 2.6693416498226

Epoch: 6| Step: 7
Training loss: 1.912830750531482
Validation loss: 2.6714262562419004

Epoch: 6| Step: 8
Training loss: 3.5137717554592087
Validation loss: 2.671908929313517

Epoch: 6| Step: 9
Training loss: 2.56893076759501
Validation loss: 2.6744928944452635

Epoch: 6| Step: 10
Training loss: 3.231894606259876
Validation loss: 2.667737251449784

Epoch: 6| Step: 11
Training loss: 3.0553224493947266
Validation loss: 2.6708953026540203

Epoch: 6| Step: 12
Training loss: 2.814494972526762
Validation loss: 2.6729620138981733

Epoch: 6| Step: 13
Training loss: 3.585751464273228
Validation loss: 2.667005987139129

Epoch: 92| Step: 0
Training loss: 2.777901766447032
Validation loss: 2.6650458562799355

Epoch: 6| Step: 1
Training loss: 2.78455362314276
Validation loss: 2.6565730825558362

Epoch: 6| Step: 2
Training loss: 3.2557288809050844
Validation loss: 2.659661407990645

Epoch: 6| Step: 3
Training loss: 2.7008984165967633
Validation loss: 2.656763844309651

Epoch: 6| Step: 4
Training loss: 3.1675891201907147
Validation loss: 2.6574213677170078

Epoch: 6| Step: 5
Training loss: 2.78248345958801
Validation loss: 2.6557257147538316

Epoch: 6| Step: 6
Training loss: 2.579960302742429
Validation loss: 2.657579623659739

Epoch: 6| Step: 7
Training loss: 3.4988844319827974
Validation loss: 2.6639150553985447

Epoch: 6| Step: 8
Training loss: 2.686474804176306
Validation loss: 2.661928838982497

Epoch: 6| Step: 9
Training loss: 3.439940539888553
Validation loss: 2.667733798648441

Epoch: 6| Step: 10
Training loss: 2.894045563798503
Validation loss: 2.689636751807336

Epoch: 6| Step: 11
Training loss: 2.8737232856454598
Validation loss: 2.7006064698544865

Epoch: 6| Step: 12
Training loss: 3.5231298747967066
Validation loss: 2.6730484591539634

Epoch: 6| Step: 13
Training loss: 2.834781127231279
Validation loss: 2.674403736116263

Epoch: 93| Step: 0
Training loss: 2.6466180633899397
Validation loss: 2.665053894802279

Epoch: 6| Step: 1
Training loss: 2.8448708808976715
Validation loss: 2.6589436615989746

Epoch: 6| Step: 2
Training loss: 3.6492641909201144
Validation loss: 2.6635212052283173

Epoch: 6| Step: 3
Training loss: 2.3013243884196037
Validation loss: 2.6623740762321937

Epoch: 6| Step: 4
Training loss: 2.716393688349496
Validation loss: 2.6610246553067536

Epoch: 6| Step: 5
Training loss: 2.9976912197432513
Validation loss: 2.6637876784644696

Epoch: 6| Step: 6
Training loss: 2.7323452636798327
Validation loss: 2.663998591596805

Epoch: 6| Step: 7
Training loss: 3.074405805042195
Validation loss: 2.6601841109433773

Epoch: 6| Step: 8
Training loss: 2.586553494478195
Validation loss: 2.65891489676671

Epoch: 6| Step: 9
Training loss: 3.0323613282753303
Validation loss: 2.661831755266561

Epoch: 6| Step: 10
Training loss: 3.0946983656316434
Validation loss: 2.6599000544171494

Epoch: 6| Step: 11
Training loss: 3.5830627753262587
Validation loss: 2.6596298131749987

Epoch: 6| Step: 12
Training loss: 3.0764307306762837
Validation loss: 2.6592396713822692

Epoch: 6| Step: 13
Training loss: 3.7946063512761135
Validation loss: 2.660619438109861

Epoch: 94| Step: 0
Training loss: 3.44663744165757
Validation loss: 2.6593797008126345

Epoch: 6| Step: 1
Training loss: 2.645168931898999
Validation loss: 2.6601633487378

Epoch: 6| Step: 2
Training loss: 2.8963101952643786
Validation loss: 2.66514629975434

Epoch: 6| Step: 3
Training loss: 2.7009045957560174
Validation loss: 2.6658432257003484

Epoch: 6| Step: 4
Training loss: 3.071694099633561
Validation loss: 2.670823899925422

Epoch: 6| Step: 5
Training loss: 2.94250451566468
Validation loss: 2.6784075961816156

Epoch: 6| Step: 6
Training loss: 2.901931343197127
Validation loss: 2.69037535312008

Epoch: 6| Step: 7
Training loss: 2.5949555318620217
Validation loss: 2.693222095107881

Epoch: 6| Step: 8
Training loss: 2.460037987423497
Validation loss: 2.6859757998821134

Epoch: 6| Step: 9
Training loss: 3.637480069135353
Validation loss: 2.6744545789284286

Epoch: 6| Step: 10
Training loss: 3.2521501911010375
Validation loss: 2.6654050294657834

Epoch: 6| Step: 11
Training loss: 2.9123413894097716
Validation loss: 2.6595185266095176

Epoch: 6| Step: 12
Training loss: 2.989929622217384
Validation loss: 2.6544813402473033

Epoch: 6| Step: 13
Training loss: 3.619046814758288
Validation loss: 2.6480437836198636

Epoch: 95| Step: 0
Training loss: 2.417552018498464
Validation loss: 2.6456294415194557

Epoch: 6| Step: 1
Training loss: 3.669408351179394
Validation loss: 2.644757833104772

Epoch: 6| Step: 2
Training loss: 2.6227381816449022
Validation loss: 2.644856616069578

Epoch: 6| Step: 3
Training loss: 3.0218746276034705
Validation loss: 2.645276518207045

Epoch: 6| Step: 4
Training loss: 2.038038910349274
Validation loss: 2.6438499738011787

Epoch: 6| Step: 5
Training loss: 2.8948822838234416
Validation loss: 2.643637553067332

Epoch: 6| Step: 6
Training loss: 2.6263128358276933
Validation loss: 2.6412816782982027

Epoch: 6| Step: 7
Training loss: 2.6539657644494263
Validation loss: 2.6368391053727223

Epoch: 6| Step: 8
Training loss: 3.9326510166241153
Validation loss: 2.638601665880913

Epoch: 6| Step: 9
Training loss: 3.597931924834347
Validation loss: 2.636574527103422

Epoch: 6| Step: 10
Training loss: 2.8882471150162865
Validation loss: 2.6365466393402754

Epoch: 6| Step: 11
Training loss: 3.3637635420204517
Validation loss: 2.6406121100441022

Epoch: 6| Step: 12
Training loss: 2.7999930449808117
Validation loss: 2.6518738709640615

Epoch: 6| Step: 13
Training loss: 2.7391410925166184
Validation loss: 2.6598627778060124

Epoch: 96| Step: 0
Training loss: 2.5413556351592095
Validation loss: 2.679025030056286

Epoch: 6| Step: 1
Training loss: 3.911015281863923
Validation loss: 2.6671342398151068

Epoch: 6| Step: 2
Training loss: 3.46331168345739
Validation loss: 2.6792579741214575

Epoch: 6| Step: 3
Training loss: 2.414601682429224
Validation loss: 2.674018932814509

Epoch: 6| Step: 4
Training loss: 3.080700721297689
Validation loss: 2.6704388870208935

Epoch: 6| Step: 5
Training loss: 2.676685843044708
Validation loss: 2.6613846336749623

Epoch: 6| Step: 6
Training loss: 2.7201176853525966
Validation loss: 2.66844421280963

Epoch: 6| Step: 7
Training loss: 2.9180007789825173
Validation loss: 2.670814596860434

Epoch: 6| Step: 8
Training loss: 2.354446214490514
Validation loss: 2.7094773223177233

Epoch: 6| Step: 9
Training loss: 2.3659221427276975
Validation loss: 2.7248579115606653

Epoch: 6| Step: 10
Training loss: 3.6185518991275623
Validation loss: 2.7411885837338317

Epoch: 6| Step: 11
Training loss: 2.99554080162729
Validation loss: 2.7093727168295585

Epoch: 6| Step: 12
Training loss: 3.2481169013516418
Validation loss: 2.689363284416413

Epoch: 6| Step: 13
Training loss: 3.348231369701579
Validation loss: 2.6743806859060255

Epoch: 97| Step: 0
Training loss: 3.343192365976396
Validation loss: 2.677690319301632

Epoch: 6| Step: 1
Training loss: 3.027625679916596
Validation loss: 2.660906886249096

Epoch: 6| Step: 2
Training loss: 2.772307173659606
Validation loss: 2.647490305133291

Epoch: 6| Step: 3
Training loss: 2.1776708756157075
Validation loss: 2.6374017370656033

Epoch: 6| Step: 4
Training loss: 2.6708148838622012
Validation loss: 2.6342030151686946

Epoch: 6| Step: 5
Training loss: 3.0385330641220105
Validation loss: 2.6340144094682425

Epoch: 6| Step: 6
Training loss: 3.6577902915831175
Validation loss: 2.6294533104691236

Epoch: 6| Step: 7
Training loss: 2.8737445246182616
Validation loss: 2.6457953462852415

Epoch: 6| Step: 8
Training loss: 3.135555293840697
Validation loss: 2.6550850800832873

Epoch: 6| Step: 9
Training loss: 3.1400419234860544
Validation loss: 2.662064446305249

Epoch: 6| Step: 10
Training loss: 3.0322276632948886
Validation loss: 2.663639050226672

Epoch: 6| Step: 11
Training loss: 2.9693419819936997
Validation loss: 2.6475760628003213

Epoch: 6| Step: 12
Training loss: 3.0156680089225776
Validation loss: 2.6438377405181237

Epoch: 6| Step: 13
Training loss: 2.844697731466499
Validation loss: 2.62697479767312

Epoch: 98| Step: 0
Training loss: 2.52150999923439
Validation loss: 2.6184305764368365

Epoch: 6| Step: 1
Training loss: 2.8618138652868987
Validation loss: 2.6221252234002614

Epoch: 6| Step: 2
Training loss: 2.926659893934658
Validation loss: 2.6224162007910037

Epoch: 6| Step: 3
Training loss: 3.3498211941043516
Validation loss: 2.6211614645712498

Epoch: 6| Step: 4
Training loss: 3.245545782852072
Validation loss: 2.6226729661751897

Epoch: 6| Step: 5
Training loss: 2.753421042694795
Validation loss: 2.6204988061057746

Epoch: 6| Step: 6
Training loss: 3.310107824868528
Validation loss: 2.6265388827907885

Epoch: 6| Step: 7
Training loss: 3.187938435638522
Validation loss: 2.6240467962132885

Epoch: 6| Step: 8
Training loss: 2.755799766669086
Validation loss: 2.635752384687175

Epoch: 6| Step: 9
Training loss: 2.6134311422060637
Validation loss: 2.6369450161621946

Epoch: 6| Step: 10
Training loss: 3.3640552653559572
Validation loss: 2.6312507424594527

Epoch: 6| Step: 11
Training loss: 3.0460628111707035
Validation loss: 2.651637264372888

Epoch: 6| Step: 12
Training loss: 2.6002904399627873
Validation loss: 2.663906742534996

Epoch: 6| Step: 13
Training loss: 3.091275699568809
Validation loss: 2.7058246325713227

Epoch: 99| Step: 0
Training loss: 2.924951901814744
Validation loss: 2.6832926431499473

Epoch: 6| Step: 1
Training loss: 2.8734730521777645
Validation loss: 2.638111119557103

Epoch: 6| Step: 2
Training loss: 2.9589779290358833
Validation loss: 2.6265517285902997

Epoch: 6| Step: 3
Training loss: 3.345558889367599
Validation loss: 2.626510046128515

Epoch: 6| Step: 4
Training loss: 2.6026033719188635
Validation loss: 2.6278258796143783

Epoch: 6| Step: 5
Training loss: 3.314957049337538
Validation loss: 2.639302755118024

Epoch: 6| Step: 6
Training loss: 2.878340397663942
Validation loss: 2.658836908895

Epoch: 6| Step: 7
Training loss: 3.110358921204011
Validation loss: 2.690692767927375

Epoch: 6| Step: 8
Training loss: 3.1026640120318567
Validation loss: 2.705691315597604

Epoch: 6| Step: 9
Training loss: 3.2259333184121006
Validation loss: 2.697356002640864

Epoch: 6| Step: 10
Training loss: 2.9748331487973565
Validation loss: 2.665948130402955

Epoch: 6| Step: 11
Training loss: 3.0559588272157225
Validation loss: 2.675382637409416

Epoch: 6| Step: 12
Training loss: 2.8357084828111834
Validation loss: 2.6630183291796157

Epoch: 6| Step: 13
Training loss: 2.4691853199809
Validation loss: 2.6513014927026965

Epoch: 100| Step: 0
Training loss: 2.699355479419571
Validation loss: 2.6567598880173167

Epoch: 6| Step: 1
Training loss: 3.4226321423518993
Validation loss: 2.6603744942777334

Epoch: 6| Step: 2
Training loss: 3.0269130868069216
Validation loss: 2.6503701652475726

Epoch: 6| Step: 3
Training loss: 2.7743778837343247
Validation loss: 2.6508169420832517

Epoch: 6| Step: 4
Training loss: 2.788773978560707
Validation loss: 2.6498953302321526

Epoch: 6| Step: 5
Training loss: 2.5674960117624837
Validation loss: 2.634878320916329

Epoch: 6| Step: 6
Training loss: 2.755391125062864
Validation loss: 2.6235519078269713

Epoch: 6| Step: 7
Training loss: 2.776425839025007
Validation loss: 2.614826459913359

Epoch: 6| Step: 8
Training loss: 3.0442017394296785
Validation loss: 2.6109031057522247

Epoch: 6| Step: 9
Training loss: 3.328939705290921
Validation loss: 2.6087997634623843

Epoch: 6| Step: 10
Training loss: 2.686787000600658
Validation loss: 2.610899521821928

Epoch: 6| Step: 11
Training loss: 3.641741012640714
Validation loss: 2.6117709623265246

Epoch: 6| Step: 12
Training loss: 3.2193496293712514
Validation loss: 2.6095225740874515

Epoch: 6| Step: 13
Training loss: 2.6546373745394143
Validation loss: 2.6136602836275333

Epoch: 101| Step: 0
Training loss: 3.2390324327588735
Validation loss: 2.6134393821581487

Epoch: 6| Step: 1
Training loss: 2.969719658153352
Validation loss: 2.6161338314850293

Epoch: 6| Step: 2
Training loss: 2.6653496549729008
Validation loss: 2.6119673321181147

Epoch: 6| Step: 3
Training loss: 2.902587223237396
Validation loss: 2.6161605718097394

Epoch: 6| Step: 4
Training loss: 3.3022440360803325
Validation loss: 2.619259090123736

Epoch: 6| Step: 5
Training loss: 3.1706507532903747
Validation loss: 2.61834269610269

Epoch: 6| Step: 6
Training loss: 2.2597126604234936
Validation loss: 2.6243493640588467

Epoch: 6| Step: 7
Training loss: 2.978487128449747
Validation loss: 2.6206400065768896

Epoch: 6| Step: 8
Training loss: 3.111845022632916
Validation loss: 2.615368237497735

Epoch: 6| Step: 9
Training loss: 2.8323582111906367
Validation loss: 2.617969245460266

Epoch: 6| Step: 10
Training loss: 3.10291235926072
Validation loss: 2.6150941511949575

Epoch: 6| Step: 11
Training loss: 3.0087583169477483
Validation loss: 2.6175384212755346

Epoch: 6| Step: 12
Training loss: 2.6024315101486626
Validation loss: 2.6235271664048763

Epoch: 6| Step: 13
Training loss: 3.451975359213219
Validation loss: 2.6301989181254193

Epoch: 102| Step: 0
Training loss: 3.106189111615573
Validation loss: 2.620916140216384

Epoch: 6| Step: 1
Training loss: 3.0390584205266644
Validation loss: 2.616067667409175

Epoch: 6| Step: 2
Training loss: 3.34108749342679
Validation loss: 2.618361073408349

Epoch: 6| Step: 3
Training loss: 2.4557139347988866
Validation loss: 2.61616854642564

Epoch: 6| Step: 4
Training loss: 2.8349489953567795
Validation loss: 2.6111857651501156

Epoch: 6| Step: 5
Training loss: 3.2179205853589297
Validation loss: 2.608458317376599

Epoch: 6| Step: 6
Training loss: 2.525971265513129
Validation loss: 2.6077061337380636

Epoch: 6| Step: 7
Training loss: 2.6056765540666866
Validation loss: 2.608592489266493

Epoch: 6| Step: 8
Training loss: 2.9902110930470185
Validation loss: 2.6166231475350465

Epoch: 6| Step: 9
Training loss: 2.370216169518422
Validation loss: 2.609011170756851

Epoch: 6| Step: 10
Training loss: 3.3114086728583714
Validation loss: 2.6088759591256663

Epoch: 6| Step: 11
Training loss: 2.658878596558209
Validation loss: 2.6036499797196258

Epoch: 6| Step: 12
Training loss: 3.7772561411279058
Validation loss: 2.6066674400504475

Epoch: 6| Step: 13
Training loss: 2.879386872088444
Validation loss: 2.5994239715682212

Epoch: 103| Step: 0
Training loss: 3.2505718608400818
Validation loss: 2.593362369326827

Epoch: 6| Step: 1
Training loss: 2.8390836892310887
Validation loss: 2.5957789841359586

Epoch: 6| Step: 2
Training loss: 2.624952043367739
Validation loss: 2.59633863415672

Epoch: 6| Step: 3
Training loss: 3.198829711063992
Validation loss: 2.5950157268726586

Epoch: 6| Step: 4
Training loss: 2.4734823525290626
Validation loss: 2.593855317902368

Epoch: 6| Step: 5
Training loss: 3.0452558861564345
Validation loss: 2.59572514945383

Epoch: 6| Step: 6
Training loss: 2.7060089603058626
Validation loss: 2.595348149963465

Epoch: 6| Step: 7
Training loss: 2.786504603682103
Validation loss: 2.590628030856029

Epoch: 6| Step: 8
Training loss: 2.8602947152617504
Validation loss: 2.5968173694199503

Epoch: 6| Step: 9
Training loss: 2.536151520164685
Validation loss: 2.5975700394336236

Epoch: 6| Step: 10
Training loss: 3.453798944635223
Validation loss: 2.6084225995484718

Epoch: 6| Step: 11
Training loss: 3.5119634252394665
Validation loss: 2.6004774654248903

Epoch: 6| Step: 12
Training loss: 2.845379540681662
Validation loss: 2.60281164409549

Epoch: 6| Step: 13
Training loss: 3.0139693226509223
Validation loss: 2.6070468422870623

Epoch: 104| Step: 0
Training loss: 2.7752026595612334
Validation loss: 2.5995334353342905

Epoch: 6| Step: 1
Training loss: 2.708742863918986
Validation loss: 2.6029831242388095

Epoch: 6| Step: 2
Training loss: 2.943867052994752
Validation loss: 2.609847413792424

Epoch: 6| Step: 3
Training loss: 2.899684257419178
Validation loss: 2.6138908427793557

Epoch: 6| Step: 4
Training loss: 2.624214236410881
Validation loss: 2.618528564862662

Epoch: 6| Step: 5
Training loss: 3.23442836846444
Validation loss: 2.621617646553442

Epoch: 6| Step: 6
Training loss: 3.105458769392374
Validation loss: 2.6308918161858093

Epoch: 6| Step: 7
Training loss: 2.5473363727583727
Validation loss: 2.6254134001573717

Epoch: 6| Step: 8
Training loss: 3.811219047102908
Validation loss: 2.622361100462109

Epoch: 6| Step: 9
Training loss: 3.1806087424668017
Validation loss: 2.597915464019188

Epoch: 6| Step: 10
Training loss: 2.653221558160613
Validation loss: 2.5930906432008394

Epoch: 6| Step: 11
Training loss: 2.9029407323660403
Validation loss: 2.5897969360604693

Epoch: 6| Step: 12
Training loss: 2.744584473252126
Validation loss: 2.5896226305383876

Epoch: 6| Step: 13
Training loss: 3.1185648463756217
Validation loss: 2.5892784258779646

Epoch: 105| Step: 0
Training loss: 3.7646391911770367
Validation loss: 2.592068461800398

Epoch: 6| Step: 1
Training loss: 2.2607856367315025
Validation loss: 2.589278473402691

Epoch: 6| Step: 2
Training loss: 2.9054561063897055
Validation loss: 2.586194749703911

Epoch: 6| Step: 3
Training loss: 2.556280823314223
Validation loss: 2.575106631662781

Epoch: 6| Step: 4
Training loss: 2.536960236216331
Validation loss: 2.5712514604072223

Epoch: 6| Step: 5
Training loss: 2.7204625666208857
Validation loss: 2.57040076876131

Epoch: 6| Step: 6
Training loss: 2.406666112813419
Validation loss: 2.5699458858978614

Epoch: 6| Step: 7
Training loss: 3.3162122833718337
Validation loss: 2.5736594263702735

Epoch: 6| Step: 8
Training loss: 3.458311027240438
Validation loss: 2.572026441539641

Epoch: 6| Step: 9
Training loss: 2.826956070069153
Validation loss: 2.567773736058681

Epoch: 6| Step: 10
Training loss: 2.829020490133246
Validation loss: 2.567021755114543

Epoch: 6| Step: 11
Training loss: 3.1973789686690424
Validation loss: 2.566013110967799

Epoch: 6| Step: 12
Training loss: 3.2815080813683726
Validation loss: 2.562257916860546

Epoch: 6| Step: 13
Training loss: 2.9750043340058374
Validation loss: 2.5621656894580624

Epoch: 106| Step: 0
Training loss: 2.635986769056906
Validation loss: 2.56095324919778

Epoch: 6| Step: 1
Training loss: 3.0441583504412244
Validation loss: 2.567077861503315

Epoch: 6| Step: 2
Training loss: 3.0745413585492205
Validation loss: 2.577972031695

Epoch: 6| Step: 3
Training loss: 3.2384709025435283
Validation loss: 2.5769967641787725

Epoch: 6| Step: 4
Training loss: 3.41175271819448
Validation loss: 2.578349487832949

Epoch: 6| Step: 5
Training loss: 2.511746751976248
Validation loss: 2.5717968153752957

Epoch: 6| Step: 6
Training loss: 3.141473608046662
Validation loss: 2.55729050412064

Epoch: 6| Step: 7
Training loss: 2.897939305019374
Validation loss: 2.5565152676473772

Epoch: 6| Step: 8
Training loss: 2.549247151858714
Validation loss: 2.5547892593599215

Epoch: 6| Step: 9
Training loss: 2.713532099398821
Validation loss: 2.555353633830038

Epoch: 6| Step: 10
Training loss: 2.8209446755940557
Validation loss: 2.555672208833755

Epoch: 6| Step: 11
Training loss: 2.869051875435582
Validation loss: 2.560789224007898

Epoch: 6| Step: 12
Training loss: 3.2054274308816346
Validation loss: 2.5601978770797023

Epoch: 6| Step: 13
Training loss: 2.705391523474576
Validation loss: 2.5633551388533466

Epoch: 107| Step: 0
Training loss: 3.0097711700447785
Validation loss: 2.5676904030537235

Epoch: 6| Step: 1
Training loss: 2.51705560226164
Validation loss: 2.5728648539505747

Epoch: 6| Step: 2
Training loss: 2.7641142258621083
Validation loss: 2.590732048751431

Epoch: 6| Step: 3
Training loss: 3.0590411525226573
Validation loss: 2.587319366996775

Epoch: 6| Step: 4
Training loss: 2.6405639641383534
Validation loss: 2.609273998832445

Epoch: 6| Step: 5
Training loss: 2.2836854032119893
Validation loss: 2.587888431745495

Epoch: 6| Step: 6
Training loss: 2.98102929279993
Validation loss: 2.577509736359922

Epoch: 6| Step: 7
Training loss: 3.1518433278837623
Validation loss: 2.590238061396781

Epoch: 6| Step: 8
Training loss: 3.610744068043947
Validation loss: 2.5552546780443426

Epoch: 6| Step: 9
Training loss: 2.1936280654102394
Validation loss: 2.5558646146582573

Epoch: 6| Step: 10
Training loss: 2.8548648472210445
Validation loss: 2.553344130512367

Epoch: 6| Step: 11
Training loss: 3.0662098426848483
Validation loss: 2.5560292567629728

Epoch: 6| Step: 12
Training loss: 2.9374902603312605
Validation loss: 2.557716909864941

Epoch: 6| Step: 13
Training loss: 4.062770893161743
Validation loss: 2.5579190529813336

Epoch: 108| Step: 0
Training loss: 3.1712593270338703
Validation loss: 2.5602304275857066

Epoch: 6| Step: 1
Training loss: 2.7694289776382814
Validation loss: 2.559748629915148

Epoch: 6| Step: 2
Training loss: 2.3918047219371523
Validation loss: 2.556803101492757

Epoch: 6| Step: 3
Training loss: 2.749664632982006
Validation loss: 2.5556616018426705

Epoch: 6| Step: 4
Training loss: 3.166018034776998
Validation loss: 2.553380319605383

Epoch: 6| Step: 5
Training loss: 3.0026395629666864
Validation loss: 2.554860187268606

Epoch: 6| Step: 6
Training loss: 2.341811230180407
Validation loss: 2.550482168341398

Epoch: 6| Step: 7
Training loss: 2.695114703453363
Validation loss: 2.548183866573328

Epoch: 6| Step: 8
Training loss: 3.3335964734799632
Validation loss: 2.548816467618076

Epoch: 6| Step: 9
Training loss: 2.9499181057182478
Validation loss: 2.552388231063439

Epoch: 6| Step: 10
Training loss: 2.837983205378642
Validation loss: 2.5562085377746224

Epoch: 6| Step: 11
Training loss: 2.947795115055359
Validation loss: 2.5631412711154407

Epoch: 6| Step: 12
Training loss: 3.5993481363763546
Validation loss: 2.572342216176206

Epoch: 6| Step: 13
Training loss: 2.9665223447291518
Validation loss: 2.579422314030756

Epoch: 109| Step: 0
Training loss: 2.8923966211095866
Validation loss: 2.568547622592461

Epoch: 6| Step: 1
Training loss: 2.9842626740252887
Validation loss: 2.563263736044971

Epoch: 6| Step: 2
Training loss: 2.99857805249656
Validation loss: 2.5590898135765343

Epoch: 6| Step: 3
Training loss: 3.0338963234173177
Validation loss: 2.546937532183834

Epoch: 6| Step: 4
Training loss: 3.2467419359332155
Validation loss: 2.551418817800533

Epoch: 6| Step: 5
Training loss: 2.2517777942912756
Validation loss: 2.5477954321874567

Epoch: 6| Step: 6
Training loss: 3.4026304840248858
Validation loss: 2.5504901462775513

Epoch: 6| Step: 7
Training loss: 3.24704549450102
Validation loss: 2.5496768322781596

Epoch: 6| Step: 8
Training loss: 3.0584808757508988
Validation loss: 2.547532688773929

Epoch: 6| Step: 9
Training loss: 2.598207435355428
Validation loss: 2.551060842206152

Epoch: 6| Step: 10
Training loss: 2.442079399386456
Validation loss: 2.549950949703628

Epoch: 6| Step: 11
Training loss: 3.277807409795525
Validation loss: 2.5529310240437613

Epoch: 6| Step: 12
Training loss: 2.781841858028129
Validation loss: 2.55349459642211

Epoch: 6| Step: 13
Training loss: 2.5057927730091025
Validation loss: 2.550303861942569

Epoch: 110| Step: 0
Training loss: 2.6325210726946047
Validation loss: 2.549968295269218

Epoch: 6| Step: 1
Training loss: 3.187719000978477
Validation loss: 2.5558827616373483

Epoch: 6| Step: 2
Training loss: 3.085001743260514
Validation loss: 2.5582082040076006

Epoch: 6| Step: 3
Training loss: 2.9141436609006064
Validation loss: 2.566527384460223

Epoch: 6| Step: 4
Training loss: 2.779163992755143
Validation loss: 2.5781969256170436

Epoch: 6| Step: 5
Training loss: 2.983295664913552
Validation loss: 2.5777559485475963

Epoch: 6| Step: 6
Training loss: 2.565934275712336
Validation loss: 2.5902023654885027

Epoch: 6| Step: 7
Training loss: 2.504362401014281
Validation loss: 2.6004782471916026

Epoch: 6| Step: 8
Training loss: 3.113163006498262
Validation loss: 2.589176850672576

Epoch: 6| Step: 9
Training loss: 3.516773629633412
Validation loss: 2.60231455613169

Epoch: 6| Step: 10
Training loss: 2.20019932190741
Validation loss: 2.581343287878543

Epoch: 6| Step: 11
Training loss: 2.9209168847106373
Validation loss: 2.5722101689737875

Epoch: 6| Step: 12
Training loss: 3.1097979234010764
Validation loss: 2.5633013993054594

Epoch: 6| Step: 13
Training loss: 3.4797546133584554
Validation loss: 2.564323915693927

Epoch: 111| Step: 0
Training loss: 2.314621648004936
Validation loss: 2.5548208070893534

Epoch: 6| Step: 1
Training loss: 2.9570904301273377
Validation loss: 2.5431160122175607

Epoch: 6| Step: 2
Training loss: 2.98995529855848
Validation loss: 2.5455696952947777

Epoch: 6| Step: 3
Training loss: 3.0523688450785644
Validation loss: 2.5459600743292934

Epoch: 6| Step: 4
Training loss: 3.2123199234301536
Validation loss: 2.547758256142335

Epoch: 6| Step: 5
Training loss: 3.0062067675108977
Validation loss: 2.546722054206427

Epoch: 6| Step: 6
Training loss: 2.864739893478568
Validation loss: 2.5461147453772734

Epoch: 6| Step: 7
Training loss: 3.1304039579292855
Validation loss: 2.545305668591376

Epoch: 6| Step: 8
Training loss: 3.1995737626398366
Validation loss: 2.5400268964673263

Epoch: 6| Step: 9
Training loss: 2.5245440156347922
Validation loss: 2.5431360798010023

Epoch: 6| Step: 10
Training loss: 3.3426280768771073
Validation loss: 2.541149834935819

Epoch: 6| Step: 11
Training loss: 2.913771218476675
Validation loss: 2.5434034352269794

Epoch: 6| Step: 12
Training loss: 2.5661368264923587
Validation loss: 2.5397711469976403

Epoch: 6| Step: 13
Training loss: 2.566550054832354
Validation loss: 2.542824105580936

Epoch: 112| Step: 0
Training loss: 3.2999165322122725
Validation loss: 2.546760784512025

Epoch: 6| Step: 1
Training loss: 2.686509593066836
Validation loss: 2.549631145018745

Epoch: 6| Step: 2
Training loss: 2.8310161165555496
Validation loss: 2.5500681478557787

Epoch: 6| Step: 3
Training loss: 2.529146521381755
Validation loss: 2.549913850326762

Epoch: 6| Step: 4
Training loss: 2.7138107859490854
Validation loss: 2.5564210149493687

Epoch: 6| Step: 5
Training loss: 3.0822165932665433
Validation loss: 2.5471710027028616

Epoch: 6| Step: 6
Training loss: 2.7921616034862504
Validation loss: 2.5506035645607934

Epoch: 6| Step: 7
Training loss: 2.9896484438798425
Validation loss: 2.5548991564415253

Epoch: 6| Step: 8
Training loss: 2.7571922231471824
Validation loss: 2.558334853252785

Epoch: 6| Step: 9
Training loss: 2.432461152036051
Validation loss: 2.565418561240383

Epoch: 6| Step: 10
Training loss: 3.3308884873610487
Validation loss: 2.5726504275094757

Epoch: 6| Step: 11
Training loss: 2.8885373386626223
Validation loss: 2.5911471881307415

Epoch: 6| Step: 12
Training loss: 3.000404966360075
Validation loss: 2.59091567667681

Epoch: 6| Step: 13
Training loss: 3.55679399724223
Validation loss: 2.6240405816376127

Epoch: 113| Step: 0
Training loss: 3.002119587121882
Validation loss: 2.6036117018162668

Epoch: 6| Step: 1
Training loss: 2.985075064630619
Validation loss: 2.5938327744964367

Epoch: 6| Step: 2
Training loss: 2.671599792227328
Validation loss: 2.5587241914737846

Epoch: 6| Step: 3
Training loss: 2.941645679633153
Validation loss: 2.5419320903099236

Epoch: 6| Step: 4
Training loss: 2.6362354881209162
Validation loss: 2.5399707083013934

Epoch: 6| Step: 5
Training loss: 3.348622987053608
Validation loss: 2.542352559300608

Epoch: 6| Step: 6
Training loss: 2.842996686151903
Validation loss: 2.5429798797202063

Epoch: 6| Step: 7
Training loss: 2.899090551956317
Validation loss: 2.540456265436228

Epoch: 6| Step: 8
Training loss: 2.8572806938165587
Validation loss: 2.543477808243576

Epoch: 6| Step: 9
Training loss: 3.1090589199722296
Validation loss: 2.546114313424264

Epoch: 6| Step: 10
Training loss: 2.565578007703301
Validation loss: 2.5454491306069413

Epoch: 6| Step: 11
Training loss: 3.279396041997452
Validation loss: 2.547477385695401

Epoch: 6| Step: 12
Training loss: 3.1555501331885707
Validation loss: 2.545880853747753

Epoch: 6| Step: 13
Training loss: 2.343428322651615
Validation loss: 2.5440086664376103

Epoch: 114| Step: 0
Training loss: 2.805811239831007
Validation loss: 2.5428207836046366

Epoch: 6| Step: 1
Training loss: 3.024549176379335
Validation loss: 2.5453900859481484

Epoch: 6| Step: 2
Training loss: 2.4986452246525914
Validation loss: 2.545148423161307

Epoch: 6| Step: 3
Training loss: 3.080482470883087
Validation loss: 2.543340021862016

Epoch: 6| Step: 4
Training loss: 2.7555710974976235
Validation loss: 2.546453073977866

Epoch: 6| Step: 5
Training loss: 3.291319301642022
Validation loss: 2.5468164665360344

Epoch: 6| Step: 6
Training loss: 3.131993821782319
Validation loss: 2.5527383157617916

Epoch: 6| Step: 7
Training loss: 2.6177069760516516
Validation loss: 2.561180767602465

Epoch: 6| Step: 8
Training loss: 2.9295999335871823
Validation loss: 2.5712929917742975

Epoch: 6| Step: 9
Training loss: 2.412921327158158
Validation loss: 2.5781544623706663

Epoch: 6| Step: 10
Training loss: 2.5276602262428063
Validation loss: 2.5842217086558263

Epoch: 6| Step: 11
Training loss: 3.0993853790361734
Validation loss: 2.580753158464935

Epoch: 6| Step: 12
Training loss: 3.0332106708695576
Validation loss: 2.564966595845248

Epoch: 6| Step: 13
Training loss: 3.8748264889171318
Validation loss: 2.556134176118702

Epoch: 115| Step: 0
Training loss: 3.096787320001531
Validation loss: 2.559248835931462

Epoch: 6| Step: 1
Training loss: 3.124015042531312
Validation loss: 2.5573404142620975

Epoch: 6| Step: 2
Training loss: 3.0193265818411397
Validation loss: 2.5489371295018874

Epoch: 6| Step: 3
Training loss: 2.716308813182514
Validation loss: 2.539562135416966

Epoch: 6| Step: 4
Training loss: 2.4841058933212565
Validation loss: 2.543193474211519

Epoch: 6| Step: 5
Training loss: 2.9135416092029867
Validation loss: 2.5417549915456363

Epoch: 6| Step: 6
Training loss: 2.937479708987017
Validation loss: 2.56376313382367

Epoch: 6| Step: 7
Training loss: 2.7582319335124543
Validation loss: 2.5789389062947974

Epoch: 6| Step: 8
Training loss: 2.9137001937347167
Validation loss: 2.5802340584473384

Epoch: 6| Step: 9
Training loss: 2.9553272573436002
Validation loss: 2.579921805519657

Epoch: 6| Step: 10
Training loss: 2.807155362832471
Validation loss: 2.5574922789759635

Epoch: 6| Step: 11
Training loss: 3.41090914355805
Validation loss: 2.5396737331481485

Epoch: 6| Step: 12
Training loss: 2.5456886570887978
Validation loss: 2.5309749997253688

Epoch: 6| Step: 13
Training loss: 2.949061752081555
Validation loss: 2.5339985636554654

Epoch: 116| Step: 0
Training loss: 2.3066417619797686
Validation loss: 2.5334649264400526

Epoch: 6| Step: 1
Training loss: 2.844712314642057
Validation loss: 2.526918477576742

Epoch: 6| Step: 2
Training loss: 3.003627808840184
Validation loss: 2.5240673936389713

Epoch: 6| Step: 3
Training loss: 2.510617977528512
Validation loss: 2.524132084411872

Epoch: 6| Step: 4
Training loss: 3.2812023341031895
Validation loss: 2.5234937769196613

Epoch: 6| Step: 5
Training loss: 2.659301889492659
Validation loss: 2.524808833544027

Epoch: 6| Step: 6
Training loss: 3.408145062408356
Validation loss: 2.5267225952310333

Epoch: 6| Step: 7
Training loss: 3.286118156774525
Validation loss: 2.528669274542123

Epoch: 6| Step: 8
Training loss: 3.151564642433115
Validation loss: 2.527451958772465

Epoch: 6| Step: 9
Training loss: 2.5045182407085784
Validation loss: 2.53220431959572

Epoch: 6| Step: 10
Training loss: 2.769068669909711
Validation loss: 2.5226983205884808

Epoch: 6| Step: 11
Training loss: 3.090265488808494
Validation loss: 2.5220734032558156

Epoch: 6| Step: 12
Training loss: 2.885050248843942
Validation loss: 2.52352190830552

Epoch: 6| Step: 13
Training loss: 2.699469945235452
Validation loss: 2.5214283267350264

Epoch: 117| Step: 0
Training loss: 3.3800425123893163
Validation loss: 2.520151278075972

Epoch: 6| Step: 1
Training loss: 2.426769405467782
Validation loss: 2.526469140798637

Epoch: 6| Step: 2
Training loss: 2.7474268232047137
Validation loss: 2.544455499274706

Epoch: 6| Step: 3
Training loss: 2.873211511683249
Validation loss: 2.556397704196594

Epoch: 6| Step: 4
Training loss: 2.5015217917738073
Validation loss: 2.5682663944575523

Epoch: 6| Step: 5
Training loss: 3.2436971435944497
Validation loss: 2.5701121356176455

Epoch: 6| Step: 6
Training loss: 3.2530913689273846
Validation loss: 2.5716491269893504

Epoch: 6| Step: 7
Training loss: 2.8125782425911323
Validation loss: 2.5551446678281633

Epoch: 6| Step: 8
Training loss: 3.046907082413224
Validation loss: 2.5442327395629625

Epoch: 6| Step: 9
Training loss: 2.896835336753147
Validation loss: 2.5313529911861385

Epoch: 6| Step: 10
Training loss: 3.354488065181237
Validation loss: 2.5235666236718135

Epoch: 6| Step: 11
Training loss: 2.480752090731548
Validation loss: 2.5255215845974037

Epoch: 6| Step: 12
Training loss: 2.365859663296015
Validation loss: 2.5255964923139986

Epoch: 6| Step: 13
Training loss: 3.2525535235446856
Validation loss: 2.5290075517610267

Epoch: 118| Step: 0
Training loss: 2.7711958301499604
Validation loss: 2.528511997252863

Epoch: 6| Step: 1
Training loss: 3.153900631797309
Validation loss: 2.5327156681953427

Epoch: 6| Step: 2
Training loss: 2.919890193703546
Validation loss: 2.5305920496138006

Epoch: 6| Step: 3
Training loss: 2.529367665364325
Validation loss: 2.535295656139016

Epoch: 6| Step: 4
Training loss: 2.9281933038616614
Validation loss: 2.533486380377003

Epoch: 6| Step: 5
Training loss: 3.0736646528522527
Validation loss: 2.529408102646041

Epoch: 6| Step: 6
Training loss: 2.951379492252326
Validation loss: 2.5271280733045387

Epoch: 6| Step: 7
Training loss: 2.959743772448447
Validation loss: 2.5264239085549094

Epoch: 6| Step: 8
Training loss: 2.512370023639263
Validation loss: 2.5241518408037

Epoch: 6| Step: 9
Training loss: 3.052326509511475
Validation loss: 2.5228127759287835

Epoch: 6| Step: 10
Training loss: 2.820168615670522
Validation loss: 2.5152757020375374

Epoch: 6| Step: 11
Training loss: 2.432753318306884
Validation loss: 2.5178757442324144

Epoch: 6| Step: 12
Training loss: 3.2430971638971196
Validation loss: 2.5164973685758234

Epoch: 6| Step: 13
Training loss: 3.312557867732305
Validation loss: 2.5117791291591924

Epoch: 119| Step: 0
Training loss: 2.864279454614793
Validation loss: 2.514625506170564

Epoch: 6| Step: 1
Training loss: 2.6136443337782613
Validation loss: 2.5135177084538185

Epoch: 6| Step: 2
Training loss: 2.787437157713717
Validation loss: 2.5149165573569787

Epoch: 6| Step: 3
Training loss: 2.618374774426034
Validation loss: 2.516302603608075

Epoch: 6| Step: 4
Training loss: 2.759344178110793
Validation loss: 2.510675688489501

Epoch: 6| Step: 5
Training loss: 3.0766300502043324
Validation loss: 2.512609732401955

Epoch: 6| Step: 6
Training loss: 3.128282730134961
Validation loss: 2.521240368976184

Epoch: 6| Step: 7
Training loss: 2.933659741996594
Validation loss: 2.5185296663385364

Epoch: 6| Step: 8
Training loss: 3.103645605266623
Validation loss: 2.5244744589214574

Epoch: 6| Step: 9
Training loss: 3.536034372766784
Validation loss: 2.518479443095907

Epoch: 6| Step: 10
Training loss: 2.2971537933346853
Validation loss: 2.524821922774914

Epoch: 6| Step: 11
Training loss: 2.773823627940482
Validation loss: 2.5295869009210636

Epoch: 6| Step: 12
Training loss: 3.177744878881687
Validation loss: 2.5222664409282682

Epoch: 6| Step: 13
Training loss: 2.442190108538874
Validation loss: 2.53349296178086

Epoch: 120| Step: 0
Training loss: 2.4063252028566455
Validation loss: 2.5338725141099125

Epoch: 6| Step: 1
Training loss: 3.3666311986080992
Validation loss: 2.526554320445412

Epoch: 6| Step: 2
Training loss: 3.441632509100551
Validation loss: 2.5342520642200164

Epoch: 6| Step: 3
Training loss: 2.2358065200924893
Validation loss: 2.541613366590075

Epoch: 6| Step: 4
Training loss: 2.7824932277216585
Validation loss: 2.5499941912461646

Epoch: 6| Step: 5
Training loss: 2.985968838242305
Validation loss: 2.5618758883460693

Epoch: 6| Step: 6
Training loss: 2.828352776728261
Validation loss: 2.568692594008057

Epoch: 6| Step: 7
Training loss: 2.976817523113899
Validation loss: 2.564357897411653

Epoch: 6| Step: 8
Training loss: 2.70652874222481
Validation loss: 2.546295012404026

Epoch: 6| Step: 9
Training loss: 3.2260319086472706
Validation loss: 2.533556135912024

Epoch: 6| Step: 10
Training loss: 2.8094089051981106
Validation loss: 2.526365673486917

Epoch: 6| Step: 11
Training loss: 2.780990845682659
Validation loss: 2.5268195648202747

Epoch: 6| Step: 12
Training loss: 3.0635403792763274
Validation loss: 2.520881236092499

Epoch: 6| Step: 13
Training loss: 3.0168397660585597
Validation loss: 2.524420247124217

Epoch: 121| Step: 0
Training loss: 2.827138654991711
Validation loss: 2.5231958236280256

Epoch: 6| Step: 1
Training loss: 2.674913251664559
Validation loss: 2.524779236056131

Epoch: 6| Step: 2
Training loss: 2.573946624404003
Validation loss: 2.5221528725504925

Epoch: 6| Step: 3
Training loss: 3.3303504631124516
Validation loss: 2.5197857716029968

Epoch: 6| Step: 4
Training loss: 2.4594656281695544
Validation loss: 2.51809186012097

Epoch: 6| Step: 5
Training loss: 2.738729181806868
Validation loss: 2.5192998776215347

Epoch: 6| Step: 6
Training loss: 3.337986051334884
Validation loss: 2.5276419841522046

Epoch: 6| Step: 7
Training loss: 2.982334577860398
Validation loss: 2.5463083808200326

Epoch: 6| Step: 8
Training loss: 2.7994224838314343
Validation loss: 2.57029363702143

Epoch: 6| Step: 9
Training loss: 2.7517749953439146
Validation loss: 2.6229653039169976

Epoch: 6| Step: 10
Training loss: 3.1548080927645743
Validation loss: 2.691873872198452

Epoch: 6| Step: 11
Training loss: 3.1558405544486146
Validation loss: 2.738735313054703

Epoch: 6| Step: 12
Training loss: 3.66785460793183
Validation loss: 2.6978283293304774

Epoch: 6| Step: 13
Training loss: 2.1783563521126545
Validation loss: 2.5510720964058455

Epoch: 122| Step: 0
Training loss: 3.003767667631909
Validation loss: 2.519399009287338

Epoch: 6| Step: 1
Training loss: 2.910510805792476
Validation loss: 2.535229878017117

Epoch: 6| Step: 2
Training loss: 2.524027280118999
Validation loss: 2.5729582372479567

Epoch: 6| Step: 3
Training loss: 2.6593082549598233
Validation loss: 2.606638134728164

Epoch: 6| Step: 4
Training loss: 2.9741657850571133
Validation loss: 2.605339800681669

Epoch: 6| Step: 5
Training loss: 3.4584000975510643
Validation loss: 2.6267338830935234

Epoch: 6| Step: 6
Training loss: 3.6399569573844315
Validation loss: 2.648563307608033

Epoch: 6| Step: 7
Training loss: 2.8024818864929517
Validation loss: 2.628891742298567

Epoch: 6| Step: 8
Training loss: 3.1921341064887288
Validation loss: 2.5761468979676594

Epoch: 6| Step: 9
Training loss: 3.1897963685481137
Validation loss: 2.567593811319429

Epoch: 6| Step: 10
Training loss: 2.546624013317211
Validation loss: 2.5475916012577784

Epoch: 6| Step: 11
Training loss: 2.766959434170559
Validation loss: 2.538354641897895

Epoch: 6| Step: 12
Training loss: 3.019750747499927
Validation loss: 2.53867034635116

Epoch: 6| Step: 13
Training loss: 2.5142329374570576
Validation loss: 2.5370178926113827

Epoch: 123| Step: 0
Training loss: 2.906464271439996
Validation loss: 2.557894360753831

Epoch: 6| Step: 1
Training loss: 2.858558246301369
Validation loss: 2.569158282018138

Epoch: 6| Step: 2
Training loss: 2.6370087188646
Validation loss: 2.591399025673187

Epoch: 6| Step: 3
Training loss: 2.847022552518821
Validation loss: 2.628274594968275

Epoch: 6| Step: 4
Training loss: 2.842929931442696
Validation loss: 2.69533711083774

Epoch: 6| Step: 5
Training loss: 3.3323772648776777
Validation loss: 2.7406183776165562

Epoch: 6| Step: 6
Training loss: 2.9378183070663972
Validation loss: 2.6790686537681387

Epoch: 6| Step: 7
Training loss: 2.4597145553843696
Validation loss: 2.6319422785212105

Epoch: 6| Step: 8
Training loss: 2.6447319281433272
Validation loss: 2.575350132032497

Epoch: 6| Step: 9
Training loss: 3.0889855891886002
Validation loss: 2.5536993917540944

Epoch: 6| Step: 10
Training loss: 2.927761411128503
Validation loss: 2.536066380828505

Epoch: 6| Step: 11
Training loss: 3.0696846900079713
Validation loss: 2.535437444910363

Epoch: 6| Step: 12
Training loss: 3.4296977883708157
Validation loss: 2.5475601833814663

Epoch: 6| Step: 13
Training loss: 2.966986363219219
Validation loss: 2.561704836892001

Epoch: 124| Step: 0
Training loss: 3.1125487419509605
Validation loss: 2.5508733322366623

Epoch: 6| Step: 1
Training loss: 2.7268365323319363
Validation loss: 2.5355770105040296

Epoch: 6| Step: 2
Training loss: 2.5192574758900452
Validation loss: 2.5301441960940214

Epoch: 6| Step: 3
Training loss: 3.023753699197513
Validation loss: 2.5349476780914126

Epoch: 6| Step: 4
Training loss: 2.422881378765297
Validation loss: 2.5321558642098103

Epoch: 6| Step: 5
Training loss: 2.9714507015682736
Validation loss: 2.5330382522018704

Epoch: 6| Step: 6
Training loss: 3.73434077929535
Validation loss: 2.532411107212543

Epoch: 6| Step: 7
Training loss: 1.9709930357904362
Validation loss: 2.521388470156071

Epoch: 6| Step: 8
Training loss: 3.1851926942321165
Validation loss: 2.516250154592136

Epoch: 6| Step: 9
Training loss: 2.3587837741619118
Validation loss: 2.5136480851947214

Epoch: 6| Step: 10
Training loss: 2.7682753110803504
Validation loss: 2.5302135969437285

Epoch: 6| Step: 11
Training loss: 3.464723466679776
Validation loss: 2.57163983599641

Epoch: 6| Step: 12
Training loss: 2.888645793598451
Validation loss: 2.5771433473150904

Epoch: 6| Step: 13
Training loss: 3.502755578986088
Validation loss: 2.609893293451924

Epoch: 125| Step: 0
Training loss: 2.089941175810259
Validation loss: 2.6261161447040844

Epoch: 6| Step: 1
Training loss: 3.427735905225798
Validation loss: 2.6011591625169546

Epoch: 6| Step: 2
Training loss: 3.073136368133701
Validation loss: 2.5696405626559264

Epoch: 6| Step: 3
Training loss: 2.6935351717578486
Validation loss: 2.557935951640391

Epoch: 6| Step: 4
Training loss: 2.5485903340346527
Validation loss: 2.5630165457864966

Epoch: 6| Step: 5
Training loss: 3.272473031582024
Validation loss: 2.5507336065748207

Epoch: 6| Step: 6
Training loss: 3.0943040448002974
Validation loss: 2.5091777514097484

Epoch: 6| Step: 7
Training loss: 2.8275471302425137
Validation loss: 2.519827834811295

Epoch: 6| Step: 8
Training loss: 2.967381854770546
Validation loss: 2.535509159859672

Epoch: 6| Step: 9
Training loss: 3.1778074512859855
Validation loss: 2.5346624033472502

Epoch: 6| Step: 10
Training loss: 2.620256406744378
Validation loss: 2.5486727173566717

Epoch: 6| Step: 11
Training loss: 2.7579186610896493
Validation loss: 2.569229754194433

Epoch: 6| Step: 12
Training loss: 3.3589698724647676
Validation loss: 2.6126610147894183

Epoch: 6| Step: 13
Training loss: 2.890765707354523
Validation loss: 2.713693994567195

Epoch: 126| Step: 0
Training loss: 2.9883216206933976
Validation loss: 2.810369843892365

Epoch: 6| Step: 1
Training loss: 3.608746362412789
Validation loss: 2.8940665234137155

Epoch: 6| Step: 2
Training loss: 3.626806138058874
Validation loss: 2.8561894310736022

Epoch: 6| Step: 3
Training loss: 2.8169870822598124
Validation loss: 2.7589879083259516

Epoch: 6| Step: 4
Training loss: 3.3211862648565167
Validation loss: 2.6630250823874544

Epoch: 6| Step: 5
Training loss: 2.9961141215083185
Validation loss: 2.576704839435785

Epoch: 6| Step: 6
Training loss: 3.497282335490067
Validation loss: 2.5501105138005142

Epoch: 6| Step: 7
Training loss: 2.713305931077909
Validation loss: 2.543430937177945

Epoch: 6| Step: 8
Training loss: 3.0509333261252083
Validation loss: 2.5350295956257707

Epoch: 6| Step: 9
Training loss: 2.6688755443623005
Validation loss: 2.543208851814543

Epoch: 6| Step: 10
Training loss: 2.7653648124762027
Validation loss: 2.5422162134802186

Epoch: 6| Step: 11
Training loss: 2.890500947507034
Validation loss: 2.538818649559677

Epoch: 6| Step: 12
Training loss: 2.5550543378811237
Validation loss: 2.538578508187086

Epoch: 6| Step: 13
Training loss: 2.5030044621889984
Validation loss: 2.5734158850695916

Epoch: 127| Step: 0
Training loss: 2.531712242588494
Validation loss: 2.570931506307181

Epoch: 6| Step: 1
Training loss: 3.3935227909921863
Validation loss: 2.563751559350604

Epoch: 6| Step: 2
Training loss: 2.8886649419921873
Validation loss: 2.549420193556126

Epoch: 6| Step: 3
Training loss: 2.562551172257251
Validation loss: 2.539486710897188

Epoch: 6| Step: 4
Training loss: 2.793007334195897
Validation loss: 2.5213778978894292

Epoch: 6| Step: 5
Training loss: 2.7817934341145834
Validation loss: 2.5202721568014574

Epoch: 6| Step: 6
Training loss: 2.7095050820139144
Validation loss: 2.5143943797664816

Epoch: 6| Step: 7
Training loss: 2.4628313800120525
Validation loss: 2.5173993638559535

Epoch: 6| Step: 8
Training loss: 3.112528213311826
Validation loss: 2.5122241174895006

Epoch: 6| Step: 9
Training loss: 3.3946668029339633
Validation loss: 2.5154863178046427

Epoch: 6| Step: 10
Training loss: 3.146078357038408
Validation loss: 2.5127368598019553

Epoch: 6| Step: 11
Training loss: 2.429719979906247
Validation loss: 2.512385607760951

Epoch: 6| Step: 12
Training loss: 3.0233359307471086
Validation loss: 2.507321096664114

Epoch: 6| Step: 13
Training loss: 3.303893514713721
Validation loss: 2.511888145195584

Epoch: 128| Step: 0
Training loss: 3.074069842327564
Validation loss: 2.514403761976888

Epoch: 6| Step: 1
Training loss: 3.2307607018354694
Validation loss: 2.514575270199509

Epoch: 6| Step: 2
Training loss: 2.2587804072602222
Validation loss: 2.5120145192066015

Epoch: 6| Step: 3
Training loss: 3.1076907096155595
Validation loss: 2.506724678835861

Epoch: 6| Step: 4
Training loss: 3.2777333624752636
Validation loss: 2.5099516311794168

Epoch: 6| Step: 5
Training loss: 2.6283865382345417
Validation loss: 2.505785542852362

Epoch: 6| Step: 6
Training loss: 3.2633492603114655
Validation loss: 2.5047681089656395

Epoch: 6| Step: 7
Training loss: 2.94642193285702
Validation loss: 2.5053605833349613

Epoch: 6| Step: 8
Training loss: 2.8379591784562344
Validation loss: 2.516984594973839

Epoch: 6| Step: 9
Training loss: 2.3931398814374525
Validation loss: 2.514668517151536

Epoch: 6| Step: 10
Training loss: 2.760943399713384
Validation loss: 2.509256109887303

Epoch: 6| Step: 11
Training loss: 2.8879839404919743
Validation loss: 2.5205912509805874

Epoch: 6| Step: 12
Training loss: 2.6868086524468544
Validation loss: 2.535240743406421

Epoch: 6| Step: 13
Training loss: 2.3318917953225817
Validation loss: 2.5399124154243107

Epoch: 129| Step: 0
Training loss: 2.8692189018317196
Validation loss: 2.561215865038954

Epoch: 6| Step: 1
Training loss: 2.9722114059710942
Validation loss: 2.57928575107008

Epoch: 6| Step: 2
Training loss: 3.107042520841702
Validation loss: 2.566953739915791

Epoch: 6| Step: 3
Training loss: 2.7773331911554298
Validation loss: 2.535903875790586

Epoch: 6| Step: 4
Training loss: 2.6426082589629805
Validation loss: 2.512076601659737

Epoch: 6| Step: 5
Training loss: 2.9519647811814993
Validation loss: 2.498291851302061

Epoch: 6| Step: 6
Training loss: 2.8207414887284745
Validation loss: 2.494088566162168

Epoch: 6| Step: 7
Training loss: 3.1673889005787976
Validation loss: 2.4920463829374233

Epoch: 6| Step: 8
Training loss: 2.993217749059719
Validation loss: 2.4969063773370563

Epoch: 6| Step: 9
Training loss: 2.6486187988162566
Validation loss: 2.5003296470704433

Epoch: 6| Step: 10
Training loss: 3.1967415074195142
Validation loss: 2.4982528262318735

Epoch: 6| Step: 11
Training loss: 2.273882950077751
Validation loss: 2.50826438584471

Epoch: 6| Step: 12
Training loss: 2.8666562619870644
Validation loss: 2.5071797516179726

Epoch: 6| Step: 13
Training loss: 3.150838159131869
Validation loss: 2.5108351357189798

Epoch: 130| Step: 0
Training loss: 2.9509631120321074
Validation loss: 2.5182356528865135

Epoch: 6| Step: 1
Training loss: 3.385674021793614
Validation loss: 2.5182671342641134

Epoch: 6| Step: 2
Training loss: 2.981720227918462
Validation loss: 2.520584397892417

Epoch: 6| Step: 3
Training loss: 3.280057854025876
Validation loss: 2.506785544403349

Epoch: 6| Step: 4
Training loss: 2.7364630873490823
Validation loss: 2.515030178297642

Epoch: 6| Step: 5
Training loss: 2.66743644888914
Validation loss: 2.5110680057661448

Epoch: 6| Step: 6
Training loss: 3.3380053362658013
Validation loss: 2.5117814256146116

Epoch: 6| Step: 7
Training loss: 2.028570432490022
Validation loss: 2.50416374485515

Epoch: 6| Step: 8
Training loss: 2.6256043782885192
Validation loss: 2.5086263029349416

Epoch: 6| Step: 9
Training loss: 3.0682561846111054
Validation loss: 2.507589461205082

Epoch: 6| Step: 10
Training loss: 3.073610044367044
Validation loss: 2.5060343343962628

Epoch: 6| Step: 11
Training loss: 2.774564787957427
Validation loss: 2.507992444313369

Epoch: 6| Step: 12
Training loss: 2.2869846951765287
Validation loss: 2.506710396715544

Epoch: 6| Step: 13
Training loss: 2.9172731768015723
Validation loss: 2.5019021499068654

Epoch: 131| Step: 0
Training loss: 2.989769339451624
Validation loss: 2.498023593202104

Epoch: 6| Step: 1
Training loss: 3.04067754121807
Validation loss: 2.4922107859132585

Epoch: 6| Step: 2
Training loss: 2.8502000035830477
Validation loss: 2.4942133834407034

Epoch: 6| Step: 3
Training loss: 2.4822858747659384
Validation loss: 2.494492453899926

Epoch: 6| Step: 4
Training loss: 3.11245084670141
Validation loss: 2.4896805079621096

Epoch: 6| Step: 5
Training loss: 2.599208006909719
Validation loss: 2.491431865795127

Epoch: 6| Step: 6
Training loss: 2.9864504323180023
Validation loss: 2.4935819371584618

Epoch: 6| Step: 7
Training loss: 3.16850755956638
Validation loss: 2.4942937167285617

Epoch: 6| Step: 8
Training loss: 3.0355747479337367
Validation loss: 2.5032299588006928

Epoch: 6| Step: 9
Training loss: 2.7208946801397143
Validation loss: 2.507412123784443

Epoch: 6| Step: 10
Training loss: 2.914839817311321
Validation loss: 2.518624470298555

Epoch: 6| Step: 11
Training loss: 2.726476279920341
Validation loss: 2.5228704934733384

Epoch: 6| Step: 12
Training loss: 2.6707091883364145
Validation loss: 2.5360516735968495

Epoch: 6| Step: 13
Training loss: 2.687320703247618
Validation loss: 2.554895157803888

Epoch: 132| Step: 0
Training loss: 3.188125997669189
Validation loss: 2.5850878875870156

Epoch: 6| Step: 1
Training loss: 2.8220960731130553
Validation loss: 2.5691950226790468

Epoch: 6| Step: 2
Training loss: 2.607794551433328
Validation loss: 2.5599076488988604

Epoch: 6| Step: 3
Training loss: 3.3203616149860036
Validation loss: 2.5735833565251047

Epoch: 6| Step: 4
Training loss: 2.9149912972426675
Validation loss: 2.6260910247502425

Epoch: 6| Step: 5
Training loss: 3.0976046814059517
Validation loss: 2.6224018419502024

Epoch: 6| Step: 6
Training loss: 2.859446040037089
Validation loss: 2.6120033214377556

Epoch: 6| Step: 7
Training loss: 2.7714189087526533
Validation loss: 2.577398736457926

Epoch: 6| Step: 8
Training loss: 2.572511978343958
Validation loss: 2.539489853504049

Epoch: 6| Step: 9
Training loss: 2.9021860236415433
Validation loss: 2.522140055091682

Epoch: 6| Step: 10
Training loss: 2.9013374401559
Validation loss: 2.5102487667162365

Epoch: 6| Step: 11
Training loss: 2.722102761620916
Validation loss: 2.495772287953193

Epoch: 6| Step: 12
Training loss: 2.6706136659774047
Validation loss: 2.4910689521012195

Epoch: 6| Step: 13
Training loss: 2.785037258864621
Validation loss: 2.4944232169612612

Epoch: 133| Step: 0
Training loss: 1.9708388615450705
Validation loss: 2.493402581485746

Epoch: 6| Step: 1
Training loss: 2.850442912168603
Validation loss: 2.4939344390299847

Epoch: 6| Step: 2
Training loss: 2.974562566317525
Validation loss: 2.4989936454098727

Epoch: 6| Step: 3
Training loss: 2.9906502303092597
Validation loss: 2.5001369992527147

Epoch: 6| Step: 4
Training loss: 2.493794942273989
Validation loss: 2.492475346627751

Epoch: 6| Step: 5
Training loss: 2.998867138907839
Validation loss: 2.4863245316311358

Epoch: 6| Step: 6
Training loss: 2.9584065996867004
Validation loss: 2.4892183038713513

Epoch: 6| Step: 7
Training loss: 2.884953063371473
Validation loss: 2.4945340330629557

Epoch: 6| Step: 8
Training loss: 2.5224977993459334
Validation loss: 2.5023499181127273

Epoch: 6| Step: 9
Training loss: 2.9955634054325735
Validation loss: 2.5232257810711642

Epoch: 6| Step: 10
Training loss: 3.316198335741929
Validation loss: 2.545876701982778

Epoch: 6| Step: 11
Training loss: 2.857426881296879
Validation loss: 2.5768871787578784

Epoch: 6| Step: 12
Training loss: 3.433422097351851
Validation loss: 2.598659459643774

Epoch: 6| Step: 13
Training loss: 2.9667419066871243
Validation loss: 2.571491628157908

Epoch: 134| Step: 0
Training loss: 2.4537652024640098
Validation loss: 2.5367171619628515

Epoch: 6| Step: 1
Training loss: 2.805262259668429
Validation loss: 2.5352685047954893

Epoch: 6| Step: 2
Training loss: 3.4220171337133505
Validation loss: 2.5119750623277044

Epoch: 6| Step: 3
Training loss: 2.807881526279002
Validation loss: 2.5102665643176416

Epoch: 6| Step: 4
Training loss: 3.511916039412574
Validation loss: 2.513328259448459

Epoch: 6| Step: 5
Training loss: 2.464675051180207
Validation loss: 2.504016075652016

Epoch: 6| Step: 6
Training loss: 3.1630986005265203
Validation loss: 2.496997810816031

Epoch: 6| Step: 7
Training loss: 2.5007864668701445
Validation loss: 2.4978835016962453

Epoch: 6| Step: 8
Training loss: 2.5086012696112188
Validation loss: 2.484687257732408

Epoch: 6| Step: 9
Training loss: 3.044600669846633
Validation loss: 2.4880754037927133

Epoch: 6| Step: 10
Training loss: 2.973572358016427
Validation loss: 2.4859095425047317

Epoch: 6| Step: 11
Training loss: 2.826668295664888
Validation loss: 2.478433832807048

Epoch: 6| Step: 12
Training loss: 2.317471701439976
Validation loss: 2.4828653013517314

Epoch: 6| Step: 13
Training loss: 2.7654795635366956
Validation loss: 2.477700869799253

Epoch: 135| Step: 0
Training loss: 2.659813857485092
Validation loss: 2.4796140764622736

Epoch: 6| Step: 1
Training loss: 2.4161988715432603
Validation loss: 2.4779518386295

Epoch: 6| Step: 2
Training loss: 3.4683370258458903
Validation loss: 2.478750920114267

Epoch: 6| Step: 3
Training loss: 2.790266701314649
Validation loss: 2.484590552646586

Epoch: 6| Step: 4
Training loss: 2.594560611401351
Validation loss: 2.4883950383347133

Epoch: 6| Step: 5
Training loss: 2.9309961270033758
Validation loss: 2.483808138441195

Epoch: 6| Step: 6
Training loss: 2.8063719215330307
Validation loss: 2.487099982966461

Epoch: 6| Step: 7
Training loss: 3.4075655015567787
Validation loss: 2.4965489409753334

Epoch: 6| Step: 8
Training loss: 2.643834978906762
Validation loss: 2.5141010431342696

Epoch: 6| Step: 9
Training loss: 2.9978286514634482
Validation loss: 2.519742278215345

Epoch: 6| Step: 10
Training loss: 2.947173888824553
Validation loss: 2.5364428605620564

Epoch: 6| Step: 11
Training loss: 2.6071184646152155
Validation loss: 2.570540594238567

Epoch: 6| Step: 12
Training loss: 2.387344403214699
Validation loss: 2.567400378798081

Epoch: 6| Step: 13
Training loss: 3.2535011799565274
Validation loss: 2.6052671847945508

Epoch: 136| Step: 0
Training loss: 3.0825179456697374
Validation loss: 2.5698072970099313

Epoch: 6| Step: 1
Training loss: 2.6871005803865566
Validation loss: 2.568003962549922

Epoch: 6| Step: 2
Training loss: 3.1056113924099558
Validation loss: 2.5447066907730065

Epoch: 6| Step: 3
Training loss: 2.9351894950456217
Validation loss: 2.513522133975424

Epoch: 6| Step: 4
Training loss: 2.9138013298262573
Validation loss: 2.489645835437545

Epoch: 6| Step: 5
Training loss: 2.8526279914886743
Validation loss: 2.4790721095242034

Epoch: 6| Step: 6
Training loss: 2.8028286270084246
Validation loss: 2.479937456247376

Epoch: 6| Step: 7
Training loss: 2.7896767161671434
Validation loss: 2.4788977829706758

Epoch: 6| Step: 8
Training loss: 2.4056850612374605
Validation loss: 2.4753894873993167

Epoch: 6| Step: 9
Training loss: 2.6394909110645344
Validation loss: 2.476133027302503

Epoch: 6| Step: 10
Training loss: 2.6616654785128118
Validation loss: 2.472185006099087

Epoch: 6| Step: 11
Training loss: 3.076732339815919
Validation loss: 2.4782355560874136

Epoch: 6| Step: 12
Training loss: 3.0909917075799678
Validation loss: 2.4904007124435634

Epoch: 6| Step: 13
Training loss: 2.5781399813130066
Validation loss: 2.50722043632339

Epoch: 137| Step: 0
Training loss: 2.878545979249051
Validation loss: 2.548509343284935

Epoch: 6| Step: 1
Training loss: 3.0249376148695264
Validation loss: 2.569014143191742

Epoch: 6| Step: 2
Training loss: 3.0900702893802507
Validation loss: 2.584794807721553

Epoch: 6| Step: 3
Training loss: 3.222074106985021
Validation loss: 2.5953959295724305

Epoch: 6| Step: 4
Training loss: 2.4971218708013185
Validation loss: 2.6143081373787656

Epoch: 6| Step: 5
Training loss: 2.9886721685686366
Validation loss: 2.6271903933647853

Epoch: 6| Step: 6
Training loss: 2.1946137426019936
Validation loss: 2.605712420711767

Epoch: 6| Step: 7
Training loss: 3.4807446645509357
Validation loss: 2.5959175305447544

Epoch: 6| Step: 8
Training loss: 2.539284564357725
Validation loss: 2.572532684607407

Epoch: 6| Step: 9
Training loss: 3.3528882230153685
Validation loss: 2.549721783728525

Epoch: 6| Step: 10
Training loss: 2.9662592025852
Validation loss: 2.529928689230782

Epoch: 6| Step: 11
Training loss: 2.6755289000531337
Validation loss: 2.513524078489425

Epoch: 6| Step: 12
Training loss: 2.849843967918155
Validation loss: 2.504682725767956

Epoch: 6| Step: 13
Training loss: 2.434742370230023
Validation loss: 2.4984153791265866

Epoch: 138| Step: 0
Training loss: 2.7089894795936944
Validation loss: 2.5035063468223018

Epoch: 6| Step: 1
Training loss: 2.9005875748577123
Validation loss: 2.508022385053342

Epoch: 6| Step: 2
Training loss: 3.35769582965534
Validation loss: 2.5172584940686065

Epoch: 6| Step: 3
Training loss: 2.8695394655562354
Validation loss: 2.523513220331628

Epoch: 6| Step: 4
Training loss: 3.0549147733547226
Validation loss: 2.5052118559543035

Epoch: 6| Step: 5
Training loss: 2.977919542044271
Validation loss: 2.5096702999683904

Epoch: 6| Step: 6
Training loss: 2.495851412427972
Validation loss: 2.511460067810964

Epoch: 6| Step: 7
Training loss: 2.6638590715436985
Validation loss: 2.502970835620469

Epoch: 6| Step: 8
Training loss: 2.8754308626489395
Validation loss: 2.5015214248837734

Epoch: 6| Step: 9
Training loss: 2.4134016891760623
Validation loss: 2.5014285897274564

Epoch: 6| Step: 10
Training loss: 2.8014740878364974
Validation loss: 2.496065396791978

Epoch: 6| Step: 11
Training loss: 2.7179425673883513
Validation loss: 2.4941060823190737

Epoch: 6| Step: 12
Training loss: 3.10731169519077
Validation loss: 2.4988138163775817

Epoch: 6| Step: 13
Training loss: 2.7093966719696696
Validation loss: 2.492452294612533

Epoch: 139| Step: 0
Training loss: 3.3748392137445498
Validation loss: 2.4846623381539263

Epoch: 6| Step: 1
Training loss: 2.0265057840403573
Validation loss: 2.4930103070257728

Epoch: 6| Step: 2
Training loss: 2.8539278436319506
Validation loss: 2.519287877031097

Epoch: 6| Step: 3
Training loss: 3.059104126578724
Validation loss: 2.528791421879243

Epoch: 6| Step: 4
Training loss: 3.1686147085347214
Validation loss: 2.516652422196887

Epoch: 6| Step: 5
Training loss: 2.8401543658574995
Validation loss: 2.5082493704589637

Epoch: 6| Step: 6
Training loss: 2.831250229050246
Validation loss: 2.4916190842464685

Epoch: 6| Step: 7
Training loss: 2.3997572458203322
Validation loss: 2.4734365596739263

Epoch: 6| Step: 8
Training loss: 2.772268301360639
Validation loss: 2.465787651034953

Epoch: 6| Step: 9
Training loss: 2.9846629058811924
Validation loss: 2.463927778920619

Epoch: 6| Step: 10
Training loss: 2.912591721559859
Validation loss: 2.4710724595716265

Epoch: 6| Step: 11
Training loss: 3.0717027928309326
Validation loss: 2.469378393346249

Epoch: 6| Step: 12
Training loss: 2.3007406286206074
Validation loss: 2.4690186985303804

Epoch: 6| Step: 13
Training loss: 3.180866894390443
Validation loss: 2.4728352888929

Epoch: 140| Step: 0
Training loss: 3.0546898415012604
Validation loss: 2.4645801436578254

Epoch: 6| Step: 1
Training loss: 2.3869495935763223
Validation loss: 2.465751702649568

Epoch: 6| Step: 2
Training loss: 3.053287585330827
Validation loss: 2.4675876346808456

Epoch: 6| Step: 3
Training loss: 2.319122523076039
Validation loss: 2.472074445565043

Epoch: 6| Step: 4
Training loss: 2.5947971298505337
Validation loss: 2.474231195519714

Epoch: 6| Step: 5
Training loss: 2.883018093479738
Validation loss: 2.4744520318895127

Epoch: 6| Step: 6
Training loss: 2.7591149385796188
Validation loss: 2.4741644726261565

Epoch: 6| Step: 7
Training loss: 3.2850566762740954
Validation loss: 2.471678610880091

Epoch: 6| Step: 8
Training loss: 2.8488130875314424
Validation loss: 2.476076144010508

Epoch: 6| Step: 9
Training loss: 2.6938315925720753
Validation loss: 2.4710330170748436

Epoch: 6| Step: 10
Training loss: 3.164392826121279
Validation loss: 2.4688117425980076

Epoch: 6| Step: 11
Training loss: 2.830076440109057
Validation loss: 2.469619725504794

Epoch: 6| Step: 12
Training loss: 2.7635467824494344
Validation loss: 2.4705134975833696

Epoch: 6| Step: 13
Training loss: 2.8370471811495923
Validation loss: 2.4691728525997685

Epoch: 141| Step: 0
Training loss: 2.884659834299209
Validation loss: 2.4664392878964914

Epoch: 6| Step: 1
Training loss: 2.7441369759206165
Validation loss: 2.460319283829249

Epoch: 6| Step: 2
Training loss: 2.68086016828794
Validation loss: 2.4691979523805707

Epoch: 6| Step: 3
Training loss: 2.810684381001487
Validation loss: 2.4664599928485096

Epoch: 6| Step: 4
Training loss: 3.306955267350738
Validation loss: 2.4698863178543102

Epoch: 6| Step: 5
Training loss: 2.9716854640717765
Validation loss: 2.4752498662582787

Epoch: 6| Step: 6
Training loss: 2.6012817781222153
Validation loss: 2.470023347471008

Epoch: 6| Step: 7
Training loss: 2.4362948446124606
Validation loss: 2.4762044399142824

Epoch: 6| Step: 8
Training loss: 2.5019986746317207
Validation loss: 2.487813818009751

Epoch: 6| Step: 9
Training loss: 3.1982706642339105
Validation loss: 2.5361763108677624

Epoch: 6| Step: 10
Training loss: 2.657740634706869
Validation loss: 2.6067333981949274

Epoch: 6| Step: 11
Training loss: 3.184022989180493
Validation loss: 2.6562379454327743

Epoch: 6| Step: 12
Training loss: 3.093035991233598
Validation loss: 2.6815819385644377

Epoch: 6| Step: 13
Training loss: 2.9956499987139558
Validation loss: 2.742340753923474

Epoch: 142| Step: 0
Training loss: 2.9731088862645043
Validation loss: 2.6780043860533307

Epoch: 6| Step: 1
Training loss: 3.0253338842322814
Validation loss: 2.6067347553813427

Epoch: 6| Step: 2
Training loss: 2.5778993450014656
Validation loss: 2.551840767666332

Epoch: 6| Step: 3
Training loss: 2.9588496514296945
Validation loss: 2.5255787743196985

Epoch: 6| Step: 4
Training loss: 3.2252688273675827
Validation loss: 2.5107063467065185

Epoch: 6| Step: 5
Training loss: 2.7965603443648543
Validation loss: 2.4955881362119157

Epoch: 6| Step: 6
Training loss: 2.599350363928096
Validation loss: 2.4922027397120563

Epoch: 6| Step: 7
Training loss: 2.757350980271783
Validation loss: 2.4897964028696493

Epoch: 6| Step: 8
Training loss: 3.071084427801213
Validation loss: 2.4834342027048666

Epoch: 6| Step: 9
Training loss: 2.8603567303747273
Validation loss: 2.4829302101810846

Epoch: 6| Step: 10
Training loss: 2.6384931457210743
Validation loss: 2.4794228485954024

Epoch: 6| Step: 11
Training loss: 2.393903491325674
Validation loss: 2.478822134235089

Epoch: 6| Step: 12
Training loss: 2.5956242235762614
Validation loss: 2.481712718099357

Epoch: 6| Step: 13
Training loss: 3.277661641177352
Validation loss: 2.480559962576018

Epoch: 143| Step: 0
Training loss: 2.9704450085103384
Validation loss: 2.4880817786896587

Epoch: 6| Step: 1
Training loss: 2.9440539678934456
Validation loss: 2.4808532163672163

Epoch: 6| Step: 2
Training loss: 2.7962311584356274
Validation loss: 2.4773462536357886

Epoch: 6| Step: 3
Training loss: 2.497911725478154
Validation loss: 2.4869910874435677

Epoch: 6| Step: 4
Training loss: 2.927266903660914
Validation loss: 2.4897830327149673

Epoch: 6| Step: 5
Training loss: 2.6723901798533207
Validation loss: 2.4955190914717837

Epoch: 6| Step: 6
Training loss: 3.005826378555085
Validation loss: 2.502482104987201

Epoch: 6| Step: 7
Training loss: 3.024770201474571
Validation loss: 2.519094972389513

Epoch: 6| Step: 8
Training loss: 2.6555283407610633
Validation loss: 2.514239782366256

Epoch: 6| Step: 9
Training loss: 3.2303136121776195
Validation loss: 2.52152670064952

Epoch: 6| Step: 10
Training loss: 2.749414121466976
Validation loss: 2.5167425963871257

Epoch: 6| Step: 11
Training loss: 2.5542508840030136
Validation loss: 2.515889172194819

Epoch: 6| Step: 12
Training loss: 2.851819672157565
Validation loss: 2.5119104779316643

Epoch: 6| Step: 13
Training loss: 2.326626801226677
Validation loss: 2.513823723226491

Epoch: 144| Step: 0
Training loss: 2.070163476726786
Validation loss: 2.5250683950158486

Epoch: 6| Step: 1
Training loss: 2.5631468351932134
Validation loss: 2.5375260028510027

Epoch: 6| Step: 2
Training loss: 1.879117259907735
Validation loss: 2.5267310104009706

Epoch: 6| Step: 3
Training loss: 2.6650238539896756
Validation loss: 2.515790986465343

Epoch: 6| Step: 4
Training loss: 3.1384751282551644
Validation loss: 2.506142154910388

Epoch: 6| Step: 5
Training loss: 3.0130930336643442
Validation loss: 2.4983288829953487

Epoch: 6| Step: 6
Training loss: 3.1231798593383724
Validation loss: 2.497551219146904

Epoch: 6| Step: 7
Training loss: 2.9166832151397633
Validation loss: 2.483634820925922

Epoch: 6| Step: 8
Training loss: 3.499605974088648
Validation loss: 2.4766428789385326

Epoch: 6| Step: 9
Training loss: 3.1327441581444506
Validation loss: 2.475042165614774

Epoch: 6| Step: 10
Training loss: 3.080303215360392
Validation loss: 2.4671068290470886

Epoch: 6| Step: 11
Training loss: 2.3185020087955106
Validation loss: 2.467130836951552

Epoch: 6| Step: 12
Training loss: 2.598519226367164
Validation loss: 2.4707837619971404

Epoch: 6| Step: 13
Training loss: 3.2005974450291235
Validation loss: 2.4739030791471777

Epoch: 145| Step: 0
Training loss: 2.36113769167231
Validation loss: 2.4890943608158875

Epoch: 6| Step: 1
Training loss: 3.09274583954177
Validation loss: 2.4911258439681228

Epoch: 6| Step: 2
Training loss: 2.8564214408724733
Validation loss: 2.53440509999443

Epoch: 6| Step: 3
Training loss: 2.364726685423271
Validation loss: 2.594019561886227

Epoch: 6| Step: 4
Training loss: 3.4354343103094926
Validation loss: 2.653803407649453

Epoch: 6| Step: 5
Training loss: 2.2275339249447548
Validation loss: 2.7329836698152232

Epoch: 6| Step: 6
Training loss: 3.306808476432327
Validation loss: 2.8215015431758435

Epoch: 6| Step: 7
Training loss: 2.56786863330898
Validation loss: 2.814171147608494

Epoch: 6| Step: 8
Training loss: 3.3843390211903364
Validation loss: 2.7888592314223515

Epoch: 6| Step: 9
Training loss: 3.093002228966399
Validation loss: 2.721799294854669

Epoch: 6| Step: 10
Training loss: 2.886751786431394
Validation loss: 2.6435849228233033

Epoch: 6| Step: 11
Training loss: 2.800906807653534
Validation loss: 2.5688801475508933

Epoch: 6| Step: 12
Training loss: 2.819324859396533
Validation loss: 2.5396258874025066

Epoch: 6| Step: 13
Training loss: 2.8852733663695784
Validation loss: 2.504260333917959

Epoch: 146| Step: 0
Training loss: 3.15923432622766
Validation loss: 2.491808792798044

Epoch: 6| Step: 1
Training loss: 2.896963397573377
Validation loss: 2.4906858372374203

Epoch: 6| Step: 2
Training loss: 2.583783500169999
Validation loss: 2.4961713555796727

Epoch: 6| Step: 3
Training loss: 3.087146995225429
Validation loss: 2.4943713700892114

Epoch: 6| Step: 4
Training loss: 2.864954606473855
Validation loss: 2.493696750176478

Epoch: 6| Step: 5
Training loss: 2.367409270822984
Validation loss: 2.486314825900409

Epoch: 6| Step: 6
Training loss: 2.5990074830896046
Validation loss: 2.492120401983176

Epoch: 6| Step: 7
Training loss: 3.092450726424162
Validation loss: 2.486684037663388

Epoch: 6| Step: 8
Training loss: 2.414371013988628
Validation loss: 2.49198105572579

Epoch: 6| Step: 9
Training loss: 2.4705464068379377
Validation loss: 2.488529612189304

Epoch: 6| Step: 10
Training loss: 3.1137547916603663
Validation loss: 2.4914511015260703

Epoch: 6| Step: 11
Training loss: 2.8602430349738133
Validation loss: 2.492344710922232

Epoch: 6| Step: 12
Training loss: 3.2708324910221513
Validation loss: 2.494187507552053

Epoch: 6| Step: 13
Training loss: 3.1895523943522797
Validation loss: 2.492431881696103

Epoch: 147| Step: 0
Training loss: 2.9022132977706576
Validation loss: 2.4977256479018703

Epoch: 6| Step: 1
Training loss: 2.8996359103300513
Validation loss: 2.4998551634394994

Epoch: 6| Step: 2
Training loss: 2.728288164535839
Validation loss: 2.5011737457441257

Epoch: 6| Step: 3
Training loss: 2.7303622201813362
Validation loss: 2.5086106499833343

Epoch: 6| Step: 4
Training loss: 3.346539341099016
Validation loss: 2.500507422193797

Epoch: 6| Step: 5
Training loss: 2.8517094822457585
Validation loss: 2.5003653310645393

Epoch: 6| Step: 6
Training loss: 2.4892505332867283
Validation loss: 2.5015652571012703

Epoch: 6| Step: 7
Training loss: 2.9460119737328703
Validation loss: 2.501935150424409

Epoch: 6| Step: 8
Training loss: 3.139071711464521
Validation loss: 2.5318965331779153

Epoch: 6| Step: 9
Training loss: 2.69504481658757
Validation loss: 2.537577756519523

Epoch: 6| Step: 10
Training loss: 2.9918139351501445
Validation loss: 2.5694079455180043

Epoch: 6| Step: 11
Training loss: 2.492392887274178
Validation loss: 2.580931777445248

Epoch: 6| Step: 12
Training loss: 3.074680317954565
Validation loss: 2.592685847363976

Epoch: 6| Step: 13
Training loss: 2.6803471501252085
Validation loss: 2.580941489918544

Epoch: 148| Step: 0
Training loss: 2.530960443206429
Validation loss: 2.5524299990524337

Epoch: 6| Step: 1
Training loss: 2.830597529060074
Validation loss: 2.538430259624084

Epoch: 6| Step: 2
Training loss: 2.7428600214761434
Validation loss: 2.537910935080365

Epoch: 6| Step: 3
Training loss: 3.2805279618524965
Validation loss: 2.5134112824608064

Epoch: 6| Step: 4
Training loss: 3.211371250974336
Validation loss: 2.509155650801382

Epoch: 6| Step: 5
Training loss: 2.632101172279615
Validation loss: 2.504760261746781

Epoch: 6| Step: 6
Training loss: 3.1429751888003428
Validation loss: 2.4917803579099576

Epoch: 6| Step: 7
Training loss: 2.7674557935428465
Validation loss: 2.495579883118136

Epoch: 6| Step: 8
Training loss: 2.737230564601353
Validation loss: 2.489314624236221

Epoch: 6| Step: 9
Training loss: 2.684101795153609
Validation loss: 2.4916549053347374

Epoch: 6| Step: 10
Training loss: 3.174070453489238
Validation loss: 2.4910982029695727

Epoch: 6| Step: 11
Training loss: 2.490932040751137
Validation loss: 2.4849543144664987

Epoch: 6| Step: 12
Training loss: 2.644620141658259
Validation loss: 2.4850209085878916

Epoch: 6| Step: 13
Training loss: 2.6938822171716965
Validation loss: 2.4890325301402134

Epoch: 149| Step: 0
Training loss: 2.597062534946897
Validation loss: 2.4837526736519187

Epoch: 6| Step: 1
Training loss: 2.8511307062850153
Validation loss: 2.4889800729738796

Epoch: 6| Step: 2
Training loss: 2.570380769420104
Validation loss: 2.4879891406711456

Epoch: 6| Step: 3
Training loss: 2.542580570530972
Validation loss: 2.488552841159855

Epoch: 6| Step: 4
Training loss: 2.659915056091329
Validation loss: 2.4902049451484807

Epoch: 6| Step: 5
Training loss: 2.6372610481096603
Validation loss: 2.4979075263127597

Epoch: 6| Step: 6
Training loss: 2.969274534767269
Validation loss: 2.511337305149613

Epoch: 6| Step: 7
Training loss: 3.1177132146465523
Validation loss: 2.5177372796900737

Epoch: 6| Step: 8
Training loss: 3.0358125622653334
Validation loss: 2.5320654026304

Epoch: 6| Step: 9
Training loss: 3.136441305201505
Validation loss: 2.530046645647305

Epoch: 6| Step: 10
Training loss: 2.8133304641431787
Validation loss: 2.5560203091822364

Epoch: 6| Step: 11
Training loss: 2.987908313891864
Validation loss: 2.549794247132159

Epoch: 6| Step: 12
Training loss: 2.797550652584878
Validation loss: 2.5449336972947867

Epoch: 6| Step: 13
Training loss: 2.4701551470505834
Validation loss: 2.5362394211929145

Epoch: 150| Step: 0
Training loss: 2.5034864909952486
Validation loss: 2.5413719257166423

Epoch: 6| Step: 1
Training loss: 2.7808109751316867
Validation loss: 2.5423240957859634

Epoch: 6| Step: 2
Training loss: 2.1821819511516742
Validation loss: 2.5336677715331057

Epoch: 6| Step: 3
Training loss: 2.7546239472326755
Validation loss: 2.5265997471985706

Epoch: 6| Step: 4
Training loss: 2.213661483812959
Validation loss: 2.5164386735501054

Epoch: 6| Step: 5
Training loss: 3.4761312495870276
Validation loss: 2.512643041218827

Epoch: 6| Step: 6
Training loss: 2.649234078041491
Validation loss: 2.505943883319174

Epoch: 6| Step: 7
Training loss: 3.1445909956474827
Validation loss: 2.5278320733378776

Epoch: 6| Step: 8
Training loss: 3.3679852525293046
Validation loss: 2.516348922474879

Epoch: 6| Step: 9
Training loss: 2.1875952563662846
Validation loss: 2.501455123486727

Epoch: 6| Step: 10
Training loss: 2.840221017914456
Validation loss: 2.492607820097496

Epoch: 6| Step: 11
Training loss: 2.7404478809708954
Validation loss: 2.487917662393661

Epoch: 6| Step: 12
Training loss: 2.7585806060624805
Validation loss: 2.4847310768719764

Epoch: 6| Step: 13
Training loss: 3.3523148979273594
Validation loss: 2.4794256382359623

Epoch: 151| Step: 0
Training loss: 2.7883056981582626
Validation loss: 2.473300070543803

Epoch: 6| Step: 1
Training loss: 2.9041860491316998
Validation loss: 2.4665762221503886

Epoch: 6| Step: 2
Training loss: 2.7800846873221077
Validation loss: 2.463844850059523

Epoch: 6| Step: 3
Training loss: 2.777944250416637
Validation loss: 2.4679164998155274

Epoch: 6| Step: 4
Training loss: 2.663734572467496
Validation loss: 2.459020508848129

Epoch: 6| Step: 5
Training loss: 3.100921795294068
Validation loss: 2.4581157288375803

Epoch: 6| Step: 6
Training loss: 2.8229036131459657
Validation loss: 2.464907831764712

Epoch: 6| Step: 7
Training loss: 2.8786874426580407
Validation loss: 2.4665963210551705

Epoch: 6| Step: 8
Training loss: 2.540556576641467
Validation loss: 2.464462851750489

Epoch: 6| Step: 9
Training loss: 2.7219188244310284
Validation loss: 2.46635784361381

Epoch: 6| Step: 10
Training loss: 2.924822457948937
Validation loss: 2.467657274977214

Epoch: 6| Step: 11
Training loss: 2.5279984488482485
Validation loss: 2.4713300507570413

Epoch: 6| Step: 12
Training loss: 2.879696534381176
Validation loss: 2.480509367424464

Epoch: 6| Step: 13
Training loss: 2.544178852044204
Validation loss: 2.4892856521017435

Epoch: 152| Step: 0
Training loss: 2.9621891808326475
Validation loss: 2.501683123889828

Epoch: 6| Step: 1
Training loss: 3.2400392332174137
Validation loss: 2.5008197486413537

Epoch: 6| Step: 2
Training loss: 2.689776498805317
Validation loss: 2.507286841906964

Epoch: 6| Step: 3
Training loss: 2.294963014923806
Validation loss: 2.4950023401780297

Epoch: 6| Step: 4
Training loss: 2.6485365227386
Validation loss: 2.4916557912094985

Epoch: 6| Step: 5
Training loss: 2.789521508152572
Validation loss: 2.510941524900448

Epoch: 6| Step: 6
Training loss: 2.231333336222185
Validation loss: 2.4916039716363234

Epoch: 6| Step: 7
Training loss: 2.866297945069931
Validation loss: 2.496650178408174

Epoch: 6| Step: 8
Training loss: 2.398405491121405
Validation loss: 2.48619860680776

Epoch: 6| Step: 9
Training loss: 3.2467770368026483
Validation loss: 2.4937746667938585

Epoch: 6| Step: 10
Training loss: 2.92682933497235
Validation loss: 2.4731292782771224

Epoch: 6| Step: 11
Training loss: 3.2371713832377065
Validation loss: 2.4724569407049137

Epoch: 6| Step: 12
Training loss: 2.830758738897011
Validation loss: 2.463222435543294

Epoch: 6| Step: 13
Training loss: 2.089601534773364
Validation loss: 2.4579039977935926

Epoch: 153| Step: 0
Training loss: 3.175284821958736
Validation loss: 2.4453561283515213

Epoch: 6| Step: 1
Training loss: 2.5592092458035065
Validation loss: 2.4507501614368477

Epoch: 6| Step: 2
Training loss: 2.8430253667139183
Validation loss: 2.442887921423024

Epoch: 6| Step: 3
Training loss: 3.3013811457915
Validation loss: 2.4470800345072394

Epoch: 6| Step: 4
Training loss: 2.3174142943895077
Validation loss: 2.448878360962738

Epoch: 6| Step: 5
Training loss: 3.206838399871154
Validation loss: 2.465993735916816

Epoch: 6| Step: 6
Training loss: 3.1782937334217873
Validation loss: 2.4775308196449894

Epoch: 6| Step: 7
Training loss: 2.748500068130201
Validation loss: 2.4973376433701673

Epoch: 6| Step: 8
Training loss: 2.577894165802414
Validation loss: 2.5446414501034043

Epoch: 6| Step: 9
Training loss: 2.7139288588823067
Validation loss: 2.5730468715725756

Epoch: 6| Step: 10
Training loss: 2.6296144526326724
Validation loss: 2.589950923335142

Epoch: 6| Step: 11
Training loss: 2.8097620034482866
Validation loss: 2.5949196568249495

Epoch: 6| Step: 12
Training loss: 2.3162719275913197
Validation loss: 2.5801939825295226

Epoch: 6| Step: 13
Training loss: 2.634182084193412
Validation loss: 2.551689983204671

Epoch: 154| Step: 0
Training loss: 2.890682075555608
Validation loss: 2.4839002016630065

Epoch: 6| Step: 1
Training loss: 3.266411645497517
Validation loss: 2.475121921715417

Epoch: 6| Step: 2
Training loss: 2.673259086608427
Validation loss: 2.4414270895447947

Epoch: 6| Step: 3
Training loss: 2.9761241680206427
Validation loss: 2.444088425009437

Epoch: 6| Step: 4
Training loss: 2.4233177563753907
Validation loss: 2.4576142289841503

Epoch: 6| Step: 5
Training loss: 2.5059208375524533
Validation loss: 2.468767739550635

Epoch: 6| Step: 6
Training loss: 3.459670409672993
Validation loss: 2.466111609928158

Epoch: 6| Step: 7
Training loss: 2.5361057378464325
Validation loss: 2.472496277537493

Epoch: 6| Step: 8
Training loss: 2.7824726631898695
Validation loss: 2.4697733106010737

Epoch: 6| Step: 9
Training loss: 2.71737364207623
Validation loss: 2.46458589384166

Epoch: 6| Step: 10
Training loss: 2.5774481607398565
Validation loss: 2.4608525941430988

Epoch: 6| Step: 11
Training loss: 2.5194832730715544
Validation loss: 2.4546220447989864

Epoch: 6| Step: 12
Training loss: 2.867707332708367
Validation loss: 2.4565550801840073

Epoch: 6| Step: 13
Training loss: 3.318987269998649
Validation loss: 2.448448099030079

Epoch: 155| Step: 0
Training loss: 2.795984051693031
Validation loss: 2.4501996985878645

Epoch: 6| Step: 1
Training loss: 3.1406040475630377
Validation loss: 2.4635957230975976

Epoch: 6| Step: 2
Training loss: 2.467917483027633
Validation loss: 2.490877116428732

Epoch: 6| Step: 3
Training loss: 2.752357686007775
Validation loss: 2.5580957452374853

Epoch: 6| Step: 4
Training loss: 2.860351729205782
Validation loss: 2.6354416649828623

Epoch: 6| Step: 5
Training loss: 3.2459665358458416
Validation loss: 2.7178038885237026

Epoch: 6| Step: 6
Training loss: 2.7880613950594504
Validation loss: 2.7042872642439724

Epoch: 6| Step: 7
Training loss: 2.861898174071265
Validation loss: 2.663388739239337

Epoch: 6| Step: 8
Training loss: 2.3008485016765525
Validation loss: 2.594452597873103

Epoch: 6| Step: 9
Training loss: 3.1732063693872363
Validation loss: 2.522018459806175

Epoch: 6| Step: 10
Training loss: 3.0863358252617203
Validation loss: 2.4894460903801097

Epoch: 6| Step: 11
Training loss: 2.9909563445052703
Validation loss: 2.4904457929391097

Epoch: 6| Step: 12
Training loss: 2.4213569333120915
Validation loss: 2.471312748692581

Epoch: 6| Step: 13
Training loss: 2.1491210959687543
Validation loss: 2.477349151167602

Epoch: 156| Step: 0
Training loss: 2.534124367170754
Validation loss: 2.4707257885006757

Epoch: 6| Step: 1
Training loss: 2.9338461694936293
Validation loss: 2.471939714812923

Epoch: 6| Step: 2
Training loss: 3.0043044998217017
Validation loss: 2.4761444305157516

Epoch: 6| Step: 3
Training loss: 2.4426807220351674
Validation loss: 2.4635413548238825

Epoch: 6| Step: 4
Training loss: 3.2582831831745094
Validation loss: 2.473320599899017

Epoch: 6| Step: 5
Training loss: 2.9778710239987376
Validation loss: 2.477159993179891

Epoch: 6| Step: 6
Training loss: 2.9824688800937285
Validation loss: 2.4925681429236715

Epoch: 6| Step: 7
Training loss: 2.9512998400449946
Validation loss: 2.489620493874404

Epoch: 6| Step: 8
Training loss: 2.830919771114731
Validation loss: 2.482423240252225

Epoch: 6| Step: 9
Training loss: 2.693961603832691
Validation loss: 2.4941210276429406

Epoch: 6| Step: 10
Training loss: 2.68074855428093
Validation loss: 2.5315340005088345

Epoch: 6| Step: 11
Training loss: 2.2172481128023507
Validation loss: 2.560121017711752

Epoch: 6| Step: 12
Training loss: 3.091991502777307
Validation loss: 2.5979048355948495

Epoch: 6| Step: 13
Training loss: 2.121965822683466
Validation loss: 2.612157435467994

Epoch: 157| Step: 0
Training loss: 2.8004122907364746
Validation loss: 2.632940387172802

Epoch: 6| Step: 1
Training loss: 2.4030571103272567
Validation loss: 2.6444652991019595

Epoch: 6| Step: 2
Training loss: 2.8006556015879664
Validation loss: 2.5892742743917068

Epoch: 6| Step: 3
Training loss: 3.2122722737979017
Validation loss: 2.6021964185792545

Epoch: 6| Step: 4
Training loss: 2.8943134591436834
Validation loss: 2.592637425510481

Epoch: 6| Step: 5
Training loss: 2.495584020968417
Validation loss: 2.5585414184438835

Epoch: 6| Step: 6
Training loss: 2.47343608497102
Validation loss: 2.515641965702512

Epoch: 6| Step: 7
Training loss: 2.8375569073184255
Validation loss: 2.4955472567296266

Epoch: 6| Step: 8
Training loss: 2.9211449348513527
Validation loss: 2.4926889276247737

Epoch: 6| Step: 9
Training loss: 2.8939847649079016
Validation loss: 2.4999535330689184

Epoch: 6| Step: 10
Training loss: 2.7868398149745515
Validation loss: 2.485790437401113

Epoch: 6| Step: 11
Training loss: 2.9436431930182594
Validation loss: 2.470423491428256

Epoch: 6| Step: 12
Training loss: 2.516155021227991
Validation loss: 2.473129870174457

Epoch: 6| Step: 13
Training loss: 3.5544986213555845
Validation loss: 2.4715031072682314

Epoch: 158| Step: 0
Training loss: 3.009479486824293
Validation loss: 2.4699181944062514

Epoch: 6| Step: 1
Training loss: 3.031497591269705
Validation loss: 2.472228801072235

Epoch: 6| Step: 2
Training loss: 2.862254876048579
Validation loss: 2.4785016033773775

Epoch: 6| Step: 3
Training loss: 3.2291657150431226
Validation loss: 2.477813704833958

Epoch: 6| Step: 4
Training loss: 2.459280855153377
Validation loss: 2.47462467841829

Epoch: 6| Step: 5
Training loss: 3.2517651386168147
Validation loss: 2.4897128106806257

Epoch: 6| Step: 6
Training loss: 2.839059839578074
Validation loss: 2.487766297003085

Epoch: 6| Step: 7
Training loss: 2.8742114105089427
Validation loss: 2.4908687736222346

Epoch: 6| Step: 8
Training loss: 2.511939435076886
Validation loss: 2.488889136016204

Epoch: 6| Step: 9
Training loss: 2.8379329670361533
Validation loss: 2.481286248668424

Epoch: 6| Step: 10
Training loss: 2.3815257115582926
Validation loss: 2.4771080990837335

Epoch: 6| Step: 11
Training loss: 2.4043778902437567
Validation loss: 2.4754397688006953

Epoch: 6| Step: 12
Training loss: 2.749603329573417
Validation loss: 2.479531563673562

Epoch: 6| Step: 13
Training loss: 1.9886357379268307
Validation loss: 2.470895369054145

Epoch: 159| Step: 0
Training loss: 2.919974295359307
Validation loss: 2.480630573926858

Epoch: 6| Step: 1
Training loss: 2.694165502662616
Validation loss: 2.4789665119310587

Epoch: 6| Step: 2
Training loss: 2.692064977017572
Validation loss: 2.493177343059005

Epoch: 6| Step: 3
Training loss: 2.4616512171889604
Validation loss: 2.5035969996259198

Epoch: 6| Step: 4
Training loss: 3.2586809276990905
Validation loss: 2.50948909887881

Epoch: 6| Step: 5
Training loss: 3.137700327522836
Validation loss: 2.506535715658135

Epoch: 6| Step: 6
Training loss: 2.6921954278281235
Validation loss: 2.524590791561006

Epoch: 6| Step: 7
Training loss: 3.473117724759917
Validation loss: 2.531733476960147

Epoch: 6| Step: 8
Training loss: 2.791255398722449
Validation loss: 2.531074670785858

Epoch: 6| Step: 9
Training loss: 3.029334023184541
Validation loss: 2.515135359533348

Epoch: 6| Step: 10
Training loss: 2.4141563224461136
Validation loss: 2.508719235533506

Epoch: 6| Step: 11
Training loss: 2.4157103805948714
Validation loss: 2.488656691791175

Epoch: 6| Step: 12
Training loss: 2.0487287440893462
Validation loss: 2.482688461884622

Epoch: 6| Step: 13
Training loss: 2.2973290857411217
Validation loss: 2.4816360518812117

Epoch: 160| Step: 0
Training loss: 2.6211641532436523
Validation loss: 2.47374225978978

Epoch: 6| Step: 1
Training loss: 2.840959458338133
Validation loss: 2.456243306146442

Epoch: 6| Step: 2
Training loss: 2.099941152928853
Validation loss: 2.4525608448378007

Epoch: 6| Step: 3
Training loss: 2.9997320055469188
Validation loss: 2.4546632319479915

Epoch: 6| Step: 4
Training loss: 2.600868017846839
Validation loss: 2.4525136447753675

Epoch: 6| Step: 5
Training loss: 2.374409752832675
Validation loss: 2.455363940498692

Epoch: 6| Step: 6
Training loss: 2.581290688551937
Validation loss: 2.4570213137815915

Epoch: 6| Step: 7
Training loss: 3.320191289147841
Validation loss: 2.459376290318106

Epoch: 6| Step: 8
Training loss: 2.836228032638596
Validation loss: 2.454998466461647

Epoch: 6| Step: 9
Training loss: 2.8204163931100106
Validation loss: 2.4649836641556724

Epoch: 6| Step: 10
Training loss: 2.2774362954234117
Validation loss: 2.4623805297201047

Epoch: 6| Step: 11
Training loss: 3.080976530555846
Validation loss: 2.483557767596127

Epoch: 6| Step: 12
Training loss: 3.0699131829725688
Validation loss: 2.489243073821843

Epoch: 6| Step: 13
Training loss: 3.0736263339315024
Validation loss: 2.515699186398677

Epoch: 161| Step: 0
Training loss: 2.7924616426652733
Validation loss: 2.497260485693483

Epoch: 6| Step: 1
Training loss: 3.1609154391685674
Validation loss: 2.4782979799136724

Epoch: 6| Step: 2
Training loss: 3.008544357239078
Validation loss: 2.480762308061551

Epoch: 6| Step: 3
Training loss: 2.8077570447503057
Validation loss: 2.466483896873633

Epoch: 6| Step: 4
Training loss: 2.638270394865189
Validation loss: 2.4594096425505034

Epoch: 6| Step: 5
Training loss: 2.7267149961831647
Validation loss: 2.458518055906545

Epoch: 6| Step: 6
Training loss: 2.542278424625806
Validation loss: 2.4492754479485255

Epoch: 6| Step: 7
Training loss: 2.447649147079394
Validation loss: 2.4484199935052997

Epoch: 6| Step: 8
Training loss: 2.8420858020004633
Validation loss: 2.444605770579833

Epoch: 6| Step: 9
Training loss: 2.481562720129303
Validation loss: 2.4502473005288192

Epoch: 6| Step: 10
Training loss: 2.8785463105532125
Validation loss: 2.4582363708823562

Epoch: 6| Step: 11
Training loss: 2.890753500891676
Validation loss: 2.4690968072720088

Epoch: 6| Step: 12
Training loss: 2.7289275047595
Validation loss: 2.492565893563061

Epoch: 6| Step: 13
Training loss: 2.5026961093702393
Validation loss: 2.4779365630014327

Epoch: 162| Step: 0
Training loss: 2.966763122647867
Validation loss: 2.4646651998657423

Epoch: 6| Step: 1
Training loss: 2.95731343342742
Validation loss: 2.4559854822947256

Epoch: 6| Step: 2
Training loss: 2.922024483350341
Validation loss: 2.4456455276911777

Epoch: 6| Step: 3
Training loss: 2.454727815507022
Validation loss: 2.4487870790716784

Epoch: 6| Step: 4
Training loss: 2.1495806617767044
Validation loss: 2.4464303018934084

Epoch: 6| Step: 5
Training loss: 2.4294449173013106
Validation loss: 2.444774052726939

Epoch: 6| Step: 6
Training loss: 2.054529684409815
Validation loss: 2.4480653995597197

Epoch: 6| Step: 7
Training loss: 2.7010698388853505
Validation loss: 2.4560494820420504

Epoch: 6| Step: 8
Training loss: 3.2075984327832643
Validation loss: 2.458974244416161

Epoch: 6| Step: 9
Training loss: 2.656149738887905
Validation loss: 2.489183692882824

Epoch: 6| Step: 10
Training loss: 2.868522312544973
Validation loss: 2.4980663533012466

Epoch: 6| Step: 11
Training loss: 2.1669902070884373
Validation loss: 2.507671272615935

Epoch: 6| Step: 12
Training loss: 3.512297416085102
Validation loss: 2.533511184004184

Epoch: 6| Step: 13
Training loss: 3.323714651756933
Validation loss: 2.554661724854546

Epoch: 163| Step: 0
Training loss: 2.5103421866315223
Validation loss: 2.5390482493364304

Epoch: 6| Step: 1
Training loss: 2.793261959450812
Validation loss: 2.540871258854261

Epoch: 6| Step: 2
Training loss: 3.0515017080038143
Validation loss: 2.5545088880019726

Epoch: 6| Step: 3
Training loss: 2.63269966404395
Validation loss: 2.523724014117645

Epoch: 6| Step: 4
Training loss: 2.9700905433493707
Validation loss: 2.486478276776805

Epoch: 6| Step: 5
Training loss: 1.99415676547551
Validation loss: 2.468447635442474

Epoch: 6| Step: 6
Training loss: 2.565103836188642
Validation loss: 2.4635506570181933

Epoch: 6| Step: 7
Training loss: 3.076731719889122
Validation loss: 2.4633958971945855

Epoch: 6| Step: 8
Training loss: 2.9610677806204
Validation loss: 2.448967355279967

Epoch: 6| Step: 9
Training loss: 3.1644285390605362
Validation loss: 2.4536055415633493

Epoch: 6| Step: 10
Training loss: 2.827935649792561
Validation loss: 2.45096496119217

Epoch: 6| Step: 11
Training loss: 2.8480400172218903
Validation loss: 2.451115833820579

Epoch: 6| Step: 12
Training loss: 2.392760874717041
Validation loss: 2.4571151955125146

Epoch: 6| Step: 13
Training loss: 3.0693205573011886
Validation loss: 2.4717160081076557

Epoch: 164| Step: 0
Training loss: 2.3217976245335317
Validation loss: 2.469981524880919

Epoch: 6| Step: 1
Training loss: 3.1375918188755847
Validation loss: 2.473947907940196

Epoch: 6| Step: 2
Training loss: 2.7881652927629785
Validation loss: 2.4753475535181697

Epoch: 6| Step: 3
Training loss: 2.8789428542979083
Validation loss: 2.4777461906697

Epoch: 6| Step: 4
Training loss: 2.4963832442586966
Validation loss: 2.49462794384236

Epoch: 6| Step: 5
Training loss: 2.9024518533240578
Validation loss: 2.4919016272901167

Epoch: 6| Step: 6
Training loss: 2.3672447071779694
Validation loss: 2.493870818888898

Epoch: 6| Step: 7
Training loss: 2.7205579161660247
Validation loss: 2.5013430792117113

Epoch: 6| Step: 8
Training loss: 2.7876056531376143
Validation loss: 2.5026973580544656

Epoch: 6| Step: 9
Training loss: 3.1808800862605535
Validation loss: 2.4922546661581038

Epoch: 6| Step: 10
Training loss: 2.9402693011410403
Validation loss: 2.473372833621572

Epoch: 6| Step: 11
Training loss: 2.0209254869770863
Validation loss: 2.4680485884901344

Epoch: 6| Step: 12
Training loss: 3.0804148255943873
Validation loss: 2.453706861350204

Epoch: 6| Step: 13
Training loss: 2.6448174776728655
Validation loss: 2.4342643458952327

Epoch: 165| Step: 0
Training loss: 2.4124639953140283
Validation loss: 2.4436648018678007

Epoch: 6| Step: 1
Training loss: 2.8149085010679773
Validation loss: 2.4525118755850714

Epoch: 6| Step: 2
Training loss: 3.1246203382652395
Validation loss: 2.4517477378402597

Epoch: 6| Step: 3
Training loss: 2.940606767231019
Validation loss: 2.44631501432267

Epoch: 6| Step: 4
Training loss: 2.636783582102254
Validation loss: 2.454499620806444

Epoch: 6| Step: 5
Training loss: 3.055350541452215
Validation loss: 2.4431431521047138

Epoch: 6| Step: 6
Training loss: 3.1879568333593076
Validation loss: 2.4406733526956566

Epoch: 6| Step: 7
Training loss: 2.139426905464565
Validation loss: 2.448222719084478

Epoch: 6| Step: 8
Training loss: 2.9636668808446123
Validation loss: 2.4499796479153955

Epoch: 6| Step: 9
Training loss: 2.9354854737216236
Validation loss: 2.4438568639897826

Epoch: 6| Step: 10
Training loss: 2.8341721433747193
Validation loss: 2.453752311955492

Epoch: 6| Step: 11
Training loss: 2.3881837434988964
Validation loss: 2.448073825403678

Epoch: 6| Step: 12
Training loss: 2.525153459474589
Validation loss: 2.4513915739366516

Epoch: 6| Step: 13
Training loss: 2.33576612577493
Validation loss: 2.4534771433128677

Epoch: 166| Step: 0
Training loss: 2.779852012153283
Validation loss: 2.450609595742208

Epoch: 6| Step: 1
Training loss: 1.8476915416613324
Validation loss: 2.4551562021445217

Epoch: 6| Step: 2
Training loss: 2.5555203914526627
Validation loss: 2.4584020202145678

Epoch: 6| Step: 3
Training loss: 2.8444365626298795
Validation loss: 2.4490309909544674

Epoch: 6| Step: 4
Training loss: 2.7329483234029714
Validation loss: 2.4531791048266824

Epoch: 6| Step: 5
Training loss: 2.390681047966857
Validation loss: 2.451448573008622

Epoch: 6| Step: 6
Training loss: 2.734552868098866
Validation loss: 2.4552061074805467

Epoch: 6| Step: 7
Training loss: 2.8303438197506128
Validation loss: 2.4535052384491634

Epoch: 6| Step: 8
Training loss: 2.4804337626715567
Validation loss: 2.4554124258439614

Epoch: 6| Step: 9
Training loss: 2.6515570079092448
Validation loss: 2.4591217619049686

Epoch: 6| Step: 10
Training loss: 3.1867209585770877
Validation loss: 2.469694823609979

Epoch: 6| Step: 11
Training loss: 2.7073603618537314
Validation loss: 2.4709022945911285

Epoch: 6| Step: 12
Training loss: 3.178831092919152
Validation loss: 2.462144397461783

Epoch: 6| Step: 13
Training loss: 3.470767285167723
Validation loss: 2.4643530370744493

Epoch: 167| Step: 0
Training loss: 2.9731348682534096
Validation loss: 2.4674006832774253

Epoch: 6| Step: 1
Training loss: 2.1174225060921166
Validation loss: 2.4710603077642275

Epoch: 6| Step: 2
Training loss: 2.6549055399497563
Validation loss: 2.4747487743325136

Epoch: 6| Step: 3
Training loss: 2.6092531095805858
Validation loss: 2.4848490865252058

Epoch: 6| Step: 4
Training loss: 2.770761493717191
Validation loss: 2.482689474871547

Epoch: 6| Step: 5
Training loss: 3.3003507254364153
Validation loss: 2.47809143788525

Epoch: 6| Step: 6
Training loss: 3.252762134259927
Validation loss: 2.4689028168091687

Epoch: 6| Step: 7
Training loss: 2.688156757393314
Validation loss: 2.459630608949563

Epoch: 6| Step: 8
Training loss: 2.388340775007255
Validation loss: 2.457018449664131

Epoch: 6| Step: 9
Training loss: 2.848645366841122
Validation loss: 2.4471926408888387

Epoch: 6| Step: 10
Training loss: 2.4396577723282302
Validation loss: 2.447342385342994

Epoch: 6| Step: 11
Training loss: 2.5894471292027808
Validation loss: 2.446967224931967

Epoch: 6| Step: 12
Training loss: 2.712431658046476
Validation loss: 2.4461762877130413

Epoch: 6| Step: 13
Training loss: 2.8840097975227184
Validation loss: 2.447878670555742

Epoch: 168| Step: 0
Training loss: 2.499485153590639
Validation loss: 2.4568662637111514

Epoch: 6| Step: 1
Training loss: 2.543160848789105
Validation loss: 2.4490283101034347

Epoch: 6| Step: 2
Training loss: 2.3179307009431924
Validation loss: 2.442974068163164

Epoch: 6| Step: 3
Training loss: 2.8850758669181533
Validation loss: 2.4508134244571624

Epoch: 6| Step: 4
Training loss: 3.0920365337666147
Validation loss: 2.4492975634351626

Epoch: 6| Step: 5
Training loss: 2.6983295748211056
Validation loss: 2.462748319503561

Epoch: 6| Step: 6
Training loss: 3.1909053787648527
Validation loss: 2.4740445865605762

Epoch: 6| Step: 7
Training loss: 2.8112369668335337
Validation loss: 2.485109719637411

Epoch: 6| Step: 8
Training loss: 2.4704802039379543
Validation loss: 2.4848294607673123

Epoch: 6| Step: 9
Training loss: 3.142383595497991
Validation loss: 2.4684509806545716

Epoch: 6| Step: 10
Training loss: 2.684487717274791
Validation loss: 2.4582989104377435

Epoch: 6| Step: 11
Training loss: 2.747855477354344
Validation loss: 2.4534009934059138

Epoch: 6| Step: 12
Training loss: 2.4387698655954453
Validation loss: 2.4472979747965327

Epoch: 6| Step: 13
Training loss: 2.695532925203195
Validation loss: 2.4414700932512647

Epoch: 169| Step: 0
Training loss: 2.5085223848021987
Validation loss: 2.441757774592152

Epoch: 6| Step: 1
Training loss: 2.7783095857383
Validation loss: 2.445043764061378

Epoch: 6| Step: 2
Training loss: 2.7933645541495564
Validation loss: 2.4499799361965464

Epoch: 6| Step: 3
Training loss: 2.8122348236534482
Validation loss: 2.442578761203276

Epoch: 6| Step: 4
Training loss: 3.0632580188822787
Validation loss: 2.449288838261578

Epoch: 6| Step: 5
Training loss: 2.2070028387620972
Validation loss: 2.4464665079901393

Epoch: 6| Step: 6
Training loss: 2.579673718069636
Validation loss: 2.4505599796878403

Epoch: 6| Step: 7
Training loss: 2.8165081709410216
Validation loss: 2.453954442128775

Epoch: 6| Step: 8
Training loss: 2.5570095137089814
Validation loss: 2.4858736870969236

Epoch: 6| Step: 9
Training loss: 3.0954589747472445
Validation loss: 2.5124211240952268

Epoch: 6| Step: 10
Training loss: 2.504980276490797
Validation loss: 2.5485425897991694

Epoch: 6| Step: 11
Training loss: 2.730881819362021
Validation loss: 2.575554022648824

Epoch: 6| Step: 12
Training loss: 2.969462580239376
Validation loss: 2.578010331304457

Epoch: 6| Step: 13
Training loss: 3.4110725631220142
Validation loss: 2.5549747490821604

Epoch: 170| Step: 0
Training loss: 3.0340108981053078
Validation loss: 2.5331491435221043

Epoch: 6| Step: 1
Training loss: 3.2761693948772956
Validation loss: 2.5207853357607966

Epoch: 6| Step: 2
Training loss: 2.910648422097823
Validation loss: 2.499178792555491

Epoch: 6| Step: 3
Training loss: 2.422263329659703
Validation loss: 2.4664301046957164

Epoch: 6| Step: 4
Training loss: 2.767104620529739
Validation loss: 2.4577641948484663

Epoch: 6| Step: 5
Training loss: 2.2487931723741736
Validation loss: 2.4521923362726383

Epoch: 6| Step: 6
Training loss: 2.496827210313934
Validation loss: 2.4460065906892567

Epoch: 6| Step: 7
Training loss: 3.0760094203135044
Validation loss: 2.4467638836368044

Epoch: 6| Step: 8
Training loss: 2.3532867700258633
Validation loss: 2.444794190355587

Epoch: 6| Step: 9
Training loss: 2.5332412422741815
Validation loss: 2.4470341886308518

Epoch: 6| Step: 10
Training loss: 2.3582693376608654
Validation loss: 2.442735749812871

Epoch: 6| Step: 11
Training loss: 2.5926325585549526
Validation loss: 2.447308815232243

Epoch: 6| Step: 12
Training loss: 3.0416689485166866
Validation loss: 2.4448744162496183

Epoch: 6| Step: 13
Training loss: 2.9936018108731477
Validation loss: 2.4575490922478513

Epoch: 171| Step: 0
Training loss: 3.1105856527392626
Validation loss: 2.4551741464216654

Epoch: 6| Step: 1
Training loss: 2.4760578014301178
Validation loss: 2.4786151476929685

Epoch: 6| Step: 2
Training loss: 2.7188111221633746
Validation loss: 2.490264358356088

Epoch: 6| Step: 3
Training loss: 3.089455755012947
Validation loss: 2.501746030429658

Epoch: 6| Step: 4
Training loss: 1.952631163153981
Validation loss: 2.520121877152901

Epoch: 6| Step: 5
Training loss: 2.4245327056862696
Validation loss: 2.535577229905764

Epoch: 6| Step: 6
Training loss: 2.681281235875292
Validation loss: 2.548140723088474

Epoch: 6| Step: 7
Training loss: 2.7023944198212004
Validation loss: 2.548085790373718

Epoch: 6| Step: 8
Training loss: 2.7073851074751487
Validation loss: 2.5354045043117566

Epoch: 6| Step: 9
Training loss: 3.426950670513412
Validation loss: 2.5337551992049896

Epoch: 6| Step: 10
Training loss: 2.3650840755623803
Validation loss: 2.527602169769325

Epoch: 6| Step: 11
Training loss: 2.9367402088368695
Validation loss: 2.515008582722306

Epoch: 6| Step: 12
Training loss: 2.7609309647055857
Validation loss: 2.502629673144395

Epoch: 6| Step: 13
Training loss: 2.5540455236119284
Validation loss: 2.499811523264888

Epoch: 172| Step: 0
Training loss: 2.5391466332214847
Validation loss: 2.484471525676423

Epoch: 6| Step: 1
Training loss: 3.6505000882296987
Validation loss: 2.473121418779297

Epoch: 6| Step: 2
Training loss: 2.4171317628575593
Validation loss: 2.463907577090411

Epoch: 6| Step: 3
Training loss: 3.37802666477771
Validation loss: 2.461042441978905

Epoch: 6| Step: 4
Training loss: 2.589302201993717
Validation loss: 2.4690768450113314

Epoch: 6| Step: 5
Training loss: 3.1292820394066942
Validation loss: 2.44935172245464

Epoch: 6| Step: 6
Training loss: 2.843677394065824
Validation loss: 2.4434876575705373

Epoch: 6| Step: 7
Training loss: 3.2001084428532276
Validation loss: 2.4492104500378735

Epoch: 6| Step: 8
Training loss: 2.4065993414608555
Validation loss: 2.444752901956283

Epoch: 6| Step: 9
Training loss: 2.5792516847401425
Validation loss: 2.453265300349581

Epoch: 6| Step: 10
Training loss: 2.406726443199102
Validation loss: 2.449655758571138

Epoch: 6| Step: 11
Training loss: 1.5721665250455357
Validation loss: 2.4577414994448126

Epoch: 6| Step: 12
Training loss: 2.331262611989123
Validation loss: 2.4528142396389243

Epoch: 6| Step: 13
Training loss: 2.303265562905281
Validation loss: 2.4544232336641745

Epoch: 173| Step: 0
Training loss: 2.338985839892219
Validation loss: 2.464737040434956

Epoch: 6| Step: 1
Training loss: 2.7269322710233
Validation loss: 2.4698865358256827

Epoch: 6| Step: 2
Training loss: 3.113249698416814
Validation loss: 2.4758176326849957

Epoch: 6| Step: 3
Training loss: 2.676686199333906
Validation loss: 2.472634151626773

Epoch: 6| Step: 4
Training loss: 2.6908901035262236
Validation loss: 2.472583735409575

Epoch: 6| Step: 5
Training loss: 2.247975816440486
Validation loss: 2.472732245994545

Epoch: 6| Step: 6
Training loss: 2.9665069137022027
Validation loss: 2.466018217274079

Epoch: 6| Step: 7
Training loss: 2.469370317389495
Validation loss: 2.4731759133407034

Epoch: 6| Step: 8
Training loss: 2.923673188634535
Validation loss: 2.4600867787287015

Epoch: 6| Step: 9
Training loss: 2.9463316269816513
Validation loss: 2.4547093750215065

Epoch: 6| Step: 10
Training loss: 3.4199560349968
Validation loss: 2.451761081190647

Epoch: 6| Step: 11
Training loss: 2.205875924792928
Validation loss: 2.4562953122864473

Epoch: 6| Step: 12
Training loss: 2.304301704832358
Validation loss: 2.4555720047576197

Epoch: 6| Step: 13
Training loss: 2.7396317877793512
Validation loss: 2.4566242046423548

Epoch: 174| Step: 0
Training loss: 3.0225791008303435
Validation loss: 2.4505286725578936

Epoch: 6| Step: 1
Training loss: 2.122753526622919
Validation loss: 2.4537013834412216

Epoch: 6| Step: 2
Training loss: 2.8794191646314666
Validation loss: 2.4542480264170425

Epoch: 6| Step: 3
Training loss: 2.713278339712843
Validation loss: 2.4455022407050637

Epoch: 6| Step: 4
Training loss: 3.0456163202949216
Validation loss: 2.4455091705381786

Epoch: 6| Step: 5
Training loss: 2.473371983694843
Validation loss: 2.4564958806846136

Epoch: 6| Step: 6
Training loss: 2.820741742298576
Validation loss: 2.461694827779917

Epoch: 6| Step: 7
Training loss: 2.7033059825838497
Validation loss: 2.45784923034037

Epoch: 6| Step: 8
Training loss: 2.606502482307872
Validation loss: 2.451040447826405

Epoch: 6| Step: 9
Training loss: 2.628909152115783
Validation loss: 2.458577097227448

Epoch: 6| Step: 10
Training loss: 2.9285588646330134
Validation loss: 2.4659334697200768

Epoch: 6| Step: 11
Training loss: 2.6660753627693685
Validation loss: 2.4587293680947795

Epoch: 6| Step: 12
Training loss: 3.003503343326593
Validation loss: 2.4477702170091473

Epoch: 6| Step: 13
Training loss: 1.6336653822778555
Validation loss: 2.454689121345672

Epoch: 175| Step: 0
Training loss: 2.2954701389638053
Validation loss: 2.4638185272465263

Epoch: 6| Step: 1
Training loss: 2.6848845063842264
Validation loss: 2.448500576471509

Epoch: 6| Step: 2
Training loss: 3.0890853086024093
Validation loss: 2.45288667709263

Epoch: 6| Step: 3
Training loss: 2.230313858559895
Validation loss: 2.449973858741356

Epoch: 6| Step: 4
Training loss: 2.7289876126867547
Validation loss: 2.449846204108095

Epoch: 6| Step: 5
Training loss: 2.566968417904768
Validation loss: 2.446631608794942

Epoch: 6| Step: 6
Training loss: 2.808990917322855
Validation loss: 2.4478671628981705

Epoch: 6| Step: 7
Training loss: 2.484161175817005
Validation loss: 2.4498319032858134

Epoch: 6| Step: 8
Training loss: 2.5441620776471074
Validation loss: 2.44580504000358

Epoch: 6| Step: 9
Training loss: 2.9357435778554355
Validation loss: 2.4527618022290927

Epoch: 6| Step: 10
Training loss: 2.738729181806868
Validation loss: 2.4564493380604517

Epoch: 6| Step: 11
Training loss: 3.1067874435829195
Validation loss: 2.4685053841133535

Epoch: 6| Step: 12
Training loss: 2.9046066724377373
Validation loss: 2.4757183066341577

Epoch: 6| Step: 13
Training loss: 2.5351448705385495
Validation loss: 2.4795014846510424

Epoch: 176| Step: 0
Training loss: 2.943909328546752
Validation loss: 2.4878190270771463

Epoch: 6| Step: 1
Training loss: 2.982339694246764
Validation loss: 2.4840147562522485

Epoch: 6| Step: 2
Training loss: 2.311031597045247
Validation loss: 2.480853964527377

Epoch: 6| Step: 3
Training loss: 2.1626147994952993
Validation loss: 2.4714633345228387

Epoch: 6| Step: 4
Training loss: 2.59046581041503
Validation loss: 2.4785032738536947

Epoch: 6| Step: 5
Training loss: 2.7746465062617784
Validation loss: 2.4607738361669917

Epoch: 6| Step: 6
Training loss: 3.311999877026689
Validation loss: 2.464630783925622

Epoch: 6| Step: 7
Training loss: 2.7488421690347504
Validation loss: 2.460520733872349

Epoch: 6| Step: 8
Training loss: 2.7383948722916163
Validation loss: 2.4502082886847183

Epoch: 6| Step: 9
Training loss: 3.1186694301067286
Validation loss: 2.45246072687942

Epoch: 6| Step: 10
Training loss: 2.9977185793379943
Validation loss: 2.4566757352129005

Epoch: 6| Step: 11
Training loss: 2.350173793615905
Validation loss: 2.4519641377160886

Epoch: 6| Step: 12
Training loss: 2.4719534262309795
Validation loss: 2.460148551176319

Epoch: 6| Step: 13
Training loss: 1.4388434724910413
Validation loss: 2.4550625232657612

Epoch: 177| Step: 0
Training loss: 2.35213699166987
Validation loss: 2.462053235685591

Epoch: 6| Step: 1
Training loss: 2.2915656558808
Validation loss: 2.460766015342278

Epoch: 6| Step: 2
Training loss: 2.912240530088532
Validation loss: 2.4627418082440684

Epoch: 6| Step: 3
Training loss: 3.062854201405908
Validation loss: 2.471306513114624

Epoch: 6| Step: 4
Training loss: 2.4565627192638004
Validation loss: 2.4757514242171226

Epoch: 6| Step: 5
Training loss: 2.749812206445257
Validation loss: 2.478855685050163

Epoch: 6| Step: 6
Training loss: 2.6611235844163392
Validation loss: 2.473963064157899

Epoch: 6| Step: 7
Training loss: 2.900739470288103
Validation loss: 2.4836674309072237

Epoch: 6| Step: 8
Training loss: 2.938180560552515
Validation loss: 2.479244307138745

Epoch: 6| Step: 9
Training loss: 1.7954171278887965
Validation loss: 2.4892258509515206

Epoch: 6| Step: 10
Training loss: 3.2875494659531537
Validation loss: 2.4766421910963516

Epoch: 6| Step: 11
Training loss: 2.614480329412195
Validation loss: 2.468809626316007

Epoch: 6| Step: 12
Training loss: 2.963132019871457
Validation loss: 2.4584266616377843

Epoch: 6| Step: 13
Training loss: 2.1913384683771473
Validation loss: 2.4505577932441853

Epoch: 178| Step: 0
Training loss: 2.4099795680149474
Validation loss: 2.4518202998621073

Epoch: 6| Step: 1
Training loss: 2.858654661069161
Validation loss: 2.44203138837855

Epoch: 6| Step: 2
Training loss: 3.040898491692839
Validation loss: 2.4424766150578385

Epoch: 6| Step: 3
Training loss: 2.677368762364471
Validation loss: 2.4435270075263955

Epoch: 6| Step: 4
Training loss: 2.1078501523375595
Validation loss: 2.441692814373196

Epoch: 6| Step: 5
Training loss: 2.6423009486011457
Validation loss: 2.436387730947636

Epoch: 6| Step: 6
Training loss: 2.6301774328449916
Validation loss: 2.436400770148803

Epoch: 6| Step: 7
Training loss: 2.9591418133136624
Validation loss: 2.4542681333157415

Epoch: 6| Step: 8
Training loss: 2.473676666822817
Validation loss: 2.4610587589400055

Epoch: 6| Step: 9
Training loss: 2.1355710477770953
Validation loss: 2.4671585729395162

Epoch: 6| Step: 10
Training loss: 2.975849857275544
Validation loss: 2.4920196214348938

Epoch: 6| Step: 11
Training loss: 2.9526757599974904
Validation loss: 2.507904956753905

Epoch: 6| Step: 12
Training loss: 2.999359062392539
Validation loss: 2.5109079566395414

Epoch: 6| Step: 13
Training loss: 2.8124748228853558
Validation loss: 2.5045061355112868

Epoch: 179| Step: 0
Training loss: 3.2174890511184935
Validation loss: 2.501538642011731

Epoch: 6| Step: 1
Training loss: 2.4000168362662735
Validation loss: 2.4928596046259

Epoch: 6| Step: 2
Training loss: 2.1922069589481272
Validation loss: 2.4906163570639928

Epoch: 6| Step: 3
Training loss: 2.636751934831683
Validation loss: 2.492587783345074

Epoch: 6| Step: 4
Training loss: 2.6093232840706913
Validation loss: 2.4692129560615164

Epoch: 6| Step: 5
Training loss: 2.949429414816676
Validation loss: 2.4589722823079314

Epoch: 6| Step: 6
Training loss: 2.5174702576108663
Validation loss: 2.4523624279699967

Epoch: 6| Step: 7
Training loss: 2.810036831000111
Validation loss: 2.452650451847092

Epoch: 6| Step: 8
Training loss: 2.4084787327083053
Validation loss: 2.4462495798640913

Epoch: 6| Step: 9
Training loss: 2.9918775273414586
Validation loss: 2.452011086452097

Epoch: 6| Step: 10
Training loss: 2.6731994201846754
Validation loss: 2.455593788964363

Epoch: 6| Step: 11
Training loss: 2.6717255310725707
Validation loss: 2.4617984565917803

Epoch: 6| Step: 12
Training loss: 2.768716065347383
Validation loss: 2.461309435282658

Epoch: 6| Step: 13
Training loss: 2.8186582326224516
Validation loss: 2.4736737245708285

Epoch: 180| Step: 0
Training loss: 2.716403430830837
Validation loss: 2.4761842968298615

Epoch: 6| Step: 1
Training loss: 2.842739722242958
Validation loss: 2.4823439717619955

Epoch: 6| Step: 2
Training loss: 2.443461244504106
Validation loss: 2.485136116092938

Epoch: 6| Step: 3
Training loss: 2.2028501082105345
Validation loss: 2.5033511722586095

Epoch: 6| Step: 4
Training loss: 2.4742852460130167
Validation loss: 2.4853311510902127

Epoch: 6| Step: 5
Training loss: 2.6760284086923325
Validation loss: 2.490307141535156

Epoch: 6| Step: 6
Training loss: 2.72873520291869
Validation loss: 2.48325360617453

Epoch: 6| Step: 7
Training loss: 2.4172796151697136
Validation loss: 2.485473670557106

Epoch: 6| Step: 8
Training loss: 3.006216125931898
Validation loss: 2.4724703703354916

Epoch: 6| Step: 9
Training loss: 2.3533052089224538
Validation loss: 2.477854401992131

Epoch: 6| Step: 10
Training loss: 2.6881529436253313
Validation loss: 2.473017979365151

Epoch: 6| Step: 11
Training loss: 2.6749700277200192
Validation loss: 2.4723599573622086

Epoch: 6| Step: 12
Training loss: 3.1014473458924403
Validation loss: 2.470083341593654

Epoch: 6| Step: 13
Training loss: 3.5933482069888414
Validation loss: 2.4670203242523345

Epoch: 181| Step: 0
Training loss: 3.1417513673193067
Validation loss: 2.4586414038451987

Epoch: 6| Step: 1
Training loss: 2.74331268092648
Validation loss: 2.4683378121355477

Epoch: 6| Step: 2
Training loss: 3.2677033304053156
Validation loss: 2.4831409610321535

Epoch: 6| Step: 3
Training loss: 2.7785176775241083
Validation loss: 2.4822795159674733

Epoch: 6| Step: 4
Training loss: 2.4846122196592524
Validation loss: 2.4743756691044427

Epoch: 6| Step: 5
Training loss: 2.7028355085117144
Validation loss: 2.4808425126920404

Epoch: 6| Step: 6
Training loss: 3.16532123158859
Validation loss: 2.4949594094002934

Epoch: 6| Step: 7
Training loss: 2.0416873100430846
Validation loss: 2.4977978857252627

Epoch: 6| Step: 8
Training loss: 2.526104064380482
Validation loss: 2.48353699873545

Epoch: 6| Step: 9
Training loss: 2.2658066249263324
Validation loss: 2.486846070523139

Epoch: 6| Step: 10
Training loss: 2.460493162701073
Validation loss: 2.4883777137820067

Epoch: 6| Step: 11
Training loss: 2.7026020933447032
Validation loss: 2.485839555502307

Epoch: 6| Step: 12
Training loss: 2.9448366463762183
Validation loss: 2.4881978820042105

Epoch: 6| Step: 13
Training loss: 1.1704691783296726
Validation loss: 2.482144804138891

Epoch: 182| Step: 0
Training loss: 3.041283744502508
Validation loss: 2.482927303674658

Epoch: 6| Step: 1
Training loss: 2.8403855427447002
Validation loss: 2.4700568247530823

Epoch: 6| Step: 2
Training loss: 3.1251837104203894
Validation loss: 2.459308629636815

Epoch: 6| Step: 3
Training loss: 3.1574330142927964
Validation loss: 2.4663336837007237

Epoch: 6| Step: 4
Training loss: 2.620506982745639
Validation loss: 2.470321681470695

Epoch: 6| Step: 5
Training loss: 3.4419716620600345
Validation loss: 2.4636719215762324

Epoch: 6| Step: 6
Training loss: 2.3143533033259995
Validation loss: 2.458032646651663

Epoch: 6| Step: 7
Training loss: 2.8118972980253623
Validation loss: 2.4655290295259076

Epoch: 6| Step: 8
Training loss: 1.7840447168604863
Validation loss: 2.467438951597725

Epoch: 6| Step: 9
Training loss: 2.711782274351152
Validation loss: 2.4626864956755923

Epoch: 6| Step: 10
Training loss: 2.3344364510533047
Validation loss: 2.4689588939949827

Epoch: 6| Step: 11
Training loss: 2.1513072320217472
Validation loss: 2.4902386205622147

Epoch: 6| Step: 12
Training loss: 2.1019352578773938
Validation loss: 2.4954735067814924

Epoch: 6| Step: 13
Training loss: 2.2632522259853705
Validation loss: 2.4999817591176043

Epoch: 183| Step: 0
Training loss: 2.7490864016434937
Validation loss: 2.4986077143887977

Epoch: 6| Step: 1
Training loss: 2.587538762193856
Validation loss: 2.485416080452883

Epoch: 6| Step: 2
Training loss: 1.856724107608258
Validation loss: 2.472154628214746

Epoch: 6| Step: 3
Training loss: 2.941024289401502
Validation loss: 2.455490172881181

Epoch: 6| Step: 4
Training loss: 2.276187976409017
Validation loss: 2.441160175875903

Epoch: 6| Step: 5
Training loss: 2.220686376503464
Validation loss: 2.4374789344081362

Epoch: 6| Step: 6
Training loss: 3.0912115298421434
Validation loss: 2.436111267042818

Epoch: 6| Step: 7
Training loss: 2.941727862563567
Validation loss: 2.4382145204871204

Epoch: 6| Step: 8
Training loss: 2.6633000779094864
Validation loss: 2.437031155224987

Epoch: 6| Step: 9
Training loss: 2.8523968037853913
Validation loss: 2.439868227740627

Epoch: 6| Step: 10
Training loss: 2.596410466957651
Validation loss: 2.438290859223099

Epoch: 6| Step: 11
Training loss: 2.631666709540739
Validation loss: 2.443503204162709

Epoch: 6| Step: 12
Training loss: 2.934330143042309
Validation loss: 2.4508112832192284

Epoch: 6| Step: 13
Training loss: 3.1145326403997173
Validation loss: 2.460054445999804

Epoch: 184| Step: 0
Training loss: 3.2181004729959684
Validation loss: 2.463092113496117

Epoch: 6| Step: 1
Training loss: 2.429322537306418
Validation loss: 2.4770122986685745

Epoch: 6| Step: 2
Training loss: 2.8485795814789943
Validation loss: 2.478901737693633

Epoch: 6| Step: 3
Training loss: 2.5881078549747367
Validation loss: 2.487560552465111

Epoch: 6| Step: 4
Training loss: 1.9650215083685039
Validation loss: 2.490978564819553

Epoch: 6| Step: 5
Training loss: 2.546857026393634
Validation loss: 2.496389992285021

Epoch: 6| Step: 6
Training loss: 2.865384150609898
Validation loss: 2.5002793043250753

Epoch: 6| Step: 7
Training loss: 2.5058464353231775
Validation loss: 2.5149084033708644

Epoch: 6| Step: 8
Training loss: 2.953220103513682
Validation loss: 2.5087615874985203

Epoch: 6| Step: 9
Training loss: 2.775647725298078
Validation loss: 2.5024003400897086

Epoch: 6| Step: 10
Training loss: 2.563032699668085
Validation loss: 2.505536604844643

Epoch: 6| Step: 11
Training loss: 3.132504569352479
Validation loss: 2.495597041078419

Epoch: 6| Step: 12
Training loss: 2.286775455482056
Validation loss: 2.5033954122749886

Epoch: 6| Step: 13
Training loss: 2.228009419700393
Validation loss: 2.505487646759043

Epoch: 185| Step: 0
Training loss: 2.727785027678421
Validation loss: 2.481511140220057

Epoch: 6| Step: 1
Training loss: 2.5782881251660124
Validation loss: 2.4785382439567027

Epoch: 6| Step: 2
Training loss: 2.5899437242086694
Validation loss: 2.4826912313341345

Epoch: 6| Step: 3
Training loss: 2.78667734776812
Validation loss: 2.4856512581604395

Epoch: 6| Step: 4
Training loss: 3.0951154373654104
Validation loss: 2.478338549126886

Epoch: 6| Step: 5
Training loss: 2.1926279181612185
Validation loss: 2.476142627995706

Epoch: 6| Step: 6
Training loss: 2.2813637064984014
Validation loss: 2.475875530442959

Epoch: 6| Step: 7
Training loss: 2.75982652989788
Validation loss: 2.4688816754558265

Epoch: 6| Step: 8
Training loss: 2.4241429692335443
Validation loss: 2.4592631420327042

Epoch: 6| Step: 9
Training loss: 3.1218004250234763
Validation loss: 2.4697100204606475

Epoch: 6| Step: 10
Training loss: 2.868556555914061
Validation loss: 2.487063353074168

Epoch: 6| Step: 11
Training loss: 2.9355658798973128
Validation loss: 2.5169642903671643

Epoch: 6| Step: 12
Training loss: 2.0715006172166364
Validation loss: 2.5273728214383584

Epoch: 6| Step: 13
Training loss: 2.7043971778025497
Validation loss: 2.5167974920346032

Epoch: 186| Step: 0
Training loss: 2.6364413193166647
Validation loss: 2.4909588468717443

Epoch: 6| Step: 1
Training loss: 2.547607878103247
Validation loss: 2.4594729017243044

Epoch: 6| Step: 2
Training loss: 2.4888224589568964
Validation loss: 2.4446175159117334

Epoch: 6| Step: 3
Training loss: 2.6150995380720516
Validation loss: 2.43914653802549

Epoch: 6| Step: 4
Training loss: 2.7885115049828344
Validation loss: 2.435843749303925

Epoch: 6| Step: 5
Training loss: 2.6054378204568787
Validation loss: 2.434803708548957

Epoch: 6| Step: 6
Training loss: 2.670789263793656
Validation loss: 2.4418464089947753

Epoch: 6| Step: 7
Training loss: 2.351074573679231
Validation loss: 2.449209880098084

Epoch: 6| Step: 8
Training loss: 2.62311440819035
Validation loss: 2.4624220680892246

Epoch: 6| Step: 9
Training loss: 2.746522612204492
Validation loss: 2.4818390926165037

Epoch: 6| Step: 10
Training loss: 3.0723174637036323
Validation loss: 2.4810340909534556

Epoch: 6| Step: 11
Training loss: 3.0944826433832513
Validation loss: 2.4994887639375563

Epoch: 6| Step: 12
Training loss: 2.6212626600346343
Validation loss: 2.5028000963060797

Epoch: 6| Step: 13
Training loss: 1.8737110157805414
Validation loss: 2.5319892586679473

Epoch: 187| Step: 0
Training loss: 2.866067028169603
Validation loss: 2.5485898934480744

Epoch: 6| Step: 1
Training loss: 2.8180356966658717
Validation loss: 2.541727890038469

Epoch: 6| Step: 2
Training loss: 2.7891496917174625
Validation loss: 2.5422638682899783

Epoch: 6| Step: 3
Training loss: 2.4543514223182954
Validation loss: 2.500438332841516

Epoch: 6| Step: 4
Training loss: 2.2570203823779984
Validation loss: 2.489616256525692

Epoch: 6| Step: 5
Training loss: 2.128147150896272
Validation loss: 2.475164468437657

Epoch: 6| Step: 6
Training loss: 2.998866820896296
Validation loss: 2.4613368494081604

Epoch: 6| Step: 7
Training loss: 3.1187519937329236
Validation loss: 2.4511889646795866

Epoch: 6| Step: 8
Training loss: 2.4553892534806776
Validation loss: 2.4478168188784966

Epoch: 6| Step: 9
Training loss: 2.3968389197547206
Validation loss: 2.4454217114698427

Epoch: 6| Step: 10
Training loss: 3.0378563063631483
Validation loss: 2.4404471034684483

Epoch: 6| Step: 11
Training loss: 2.693505341998465
Validation loss: 2.4466619976134725

Epoch: 6| Step: 12
Training loss: 3.01477766238867
Validation loss: 2.4650078466606224

Epoch: 6| Step: 13
Training loss: 1.7550855040846156
Validation loss: 2.480721101592332

Epoch: 188| Step: 0
Training loss: 2.341230742400278
Validation loss: 2.50287002797667

Epoch: 6| Step: 1
Training loss: 2.817416915819376
Validation loss: 2.5225985116590537

Epoch: 6| Step: 2
Training loss: 2.821176835016911
Validation loss: 2.556030675976185

Epoch: 6| Step: 3
Training loss: 2.1848255702388197
Validation loss: 2.548611314116049

Epoch: 6| Step: 4
Training loss: 3.145784002932024
Validation loss: 2.5754809332575874

Epoch: 6| Step: 5
Training loss: 2.456740806406337
Validation loss: 2.575895157677658

Epoch: 6| Step: 6
Training loss: 2.7833120866828787
Validation loss: 2.556592503151841

Epoch: 6| Step: 7
Training loss: 3.185657043236001
Validation loss: 2.50642600757057

Epoch: 6| Step: 8
Training loss: 2.5223434485862017
Validation loss: 2.492934546133793

Epoch: 6| Step: 9
Training loss: 2.8956863219636757
Validation loss: 2.4673311001588716

Epoch: 6| Step: 10
Training loss: 2.37991487014211
Validation loss: 2.4605753220463207

Epoch: 6| Step: 11
Training loss: 2.9662764031818143
Validation loss: 2.4639332299320276

Epoch: 6| Step: 12
Training loss: 2.1333495641130678
Validation loss: 2.462133725426598

Epoch: 6| Step: 13
Training loss: 2.7058025175156346
Validation loss: 2.468006261363061

Epoch: 189| Step: 0
Training loss: 3.0628347408536873
Validation loss: 2.4717503243579797

Epoch: 6| Step: 1
Training loss: 2.7894560378651994
Validation loss: 2.4806739242327214

Epoch: 6| Step: 2
Training loss: 3.083526055438856
Validation loss: 2.5021791856082904

Epoch: 6| Step: 3
Training loss: 1.7942215940882629
Validation loss: 2.5250263835722984

Epoch: 6| Step: 4
Training loss: 2.6539708850301365
Validation loss: 2.553717449715362

Epoch: 6| Step: 5
Training loss: 2.596869006649221
Validation loss: 2.5824798000266664

Epoch: 6| Step: 6
Training loss: 2.475209055847143
Validation loss: 2.564503419566894

Epoch: 6| Step: 7
Training loss: 3.164442703574603
Validation loss: 2.5606502937180693

Epoch: 6| Step: 8
Training loss: 2.9686115433379388
Validation loss: 2.5408699714193825

Epoch: 6| Step: 9
Training loss: 2.0302417306777416
Validation loss: 2.5078401499816665

Epoch: 6| Step: 10
Training loss: 2.8234176660378343
Validation loss: 2.48470529207935

Epoch: 6| Step: 11
Training loss: 2.68002628598204
Validation loss: 2.4758115508308367

Epoch: 6| Step: 12
Training loss: 2.372675310095385
Validation loss: 2.452723955038415

Epoch: 6| Step: 13
Training loss: 2.3180339684486584
Validation loss: 2.45687404895073

Epoch: 190| Step: 0
Training loss: 2.7607653319687793
Validation loss: 2.4494870870293997

Epoch: 6| Step: 1
Training loss: 3.0912693752078053
Validation loss: 2.445906845905184

Epoch: 6| Step: 2
Training loss: 1.9813135515965135
Validation loss: 2.4502376904435805

Epoch: 6| Step: 3
Training loss: 2.7595484297826554
Validation loss: 2.4430558376199425

Epoch: 6| Step: 4
Training loss: 3.0765066782089803
Validation loss: 2.4385809603689337

Epoch: 6| Step: 5
Training loss: 3.09743796273362
Validation loss: 2.4439848403754545

Epoch: 6| Step: 6
Training loss: 2.957049310545903
Validation loss: 2.446243851554014

Epoch: 6| Step: 7
Training loss: 2.6554620808368647
Validation loss: 2.4584713784640577

Epoch: 6| Step: 8
Training loss: 2.7256880180353322
Validation loss: 2.4585065271413793

Epoch: 6| Step: 9
Training loss: 2.299346631998323
Validation loss: 2.4708015590574535

Epoch: 6| Step: 10
Training loss: 2.7000467932143093
Validation loss: 2.4837215619632134

Epoch: 6| Step: 11
Training loss: 1.8631050458400666
Validation loss: 2.4840241107840235

Epoch: 6| Step: 12
Training loss: 2.275213327990633
Validation loss: 2.4828160743313608

Epoch: 6| Step: 13
Training loss: 2.5155252946322304
Validation loss: 2.488333205736076

Epoch: 191| Step: 0
Training loss: 2.6152053842796614
Validation loss: 2.4936689135580434

Epoch: 6| Step: 1
Training loss: 2.5559796439839277
Validation loss: 2.5100819449617617

Epoch: 6| Step: 2
Training loss: 2.4302898285946184
Validation loss: 2.5256112644888784

Epoch: 6| Step: 3
Training loss: 1.9398823519555795
Validation loss: 2.5451320953323986

Epoch: 6| Step: 4
Training loss: 2.4435272037185305
Validation loss: 2.559659784995234

Epoch: 6| Step: 5
Training loss: 1.8398153055831004
Validation loss: 2.529726990451682

Epoch: 6| Step: 6
Training loss: 3.1093105903740317
Validation loss: 2.513714374519806

Epoch: 6| Step: 7
Training loss: 2.3538739070195978
Validation loss: 2.508337872141695

Epoch: 6| Step: 8
Training loss: 3.313469510980192
Validation loss: 2.4883829041548267

Epoch: 6| Step: 9
Training loss: 2.5270298758500505
Validation loss: 2.493256816710993

Epoch: 6| Step: 10
Training loss: 2.942909292375389
Validation loss: 2.4871723536612995

Epoch: 6| Step: 11
Training loss: 2.4906730235602037
Validation loss: 2.4742106032621662

Epoch: 6| Step: 12
Training loss: 2.965329739792565
Validation loss: 2.4558004375172158

Epoch: 6| Step: 13
Training loss: 3.1548972677441545
Validation loss: 2.456514477867518

Epoch: 192| Step: 0
Training loss: 2.991434904027527
Validation loss: 2.451502801630787

Epoch: 6| Step: 1
Training loss: 2.5652889798322582
Validation loss: 2.451064395022988

Epoch: 6| Step: 2
Training loss: 2.9476485562925534
Validation loss: 2.4658562463696394

Epoch: 6| Step: 3
Training loss: 3.2346323988950343
Validation loss: 2.4927413242256122

Epoch: 6| Step: 4
Training loss: 2.5695761695524015
Validation loss: 2.52504457755038

Epoch: 6| Step: 5
Training loss: 2.768027345197035
Validation loss: 2.572194939835303

Epoch: 6| Step: 6
Training loss: 3.0140038120217825
Validation loss: 2.6016370087692313

Epoch: 6| Step: 7
Training loss: 1.887296915813063
Validation loss: 2.5952087878285446

Epoch: 6| Step: 8
Training loss: 3.072134161850788
Validation loss: 2.5997806236049166

Epoch: 6| Step: 9
Training loss: 2.6590435821186618
Validation loss: 2.593851989132586

Epoch: 6| Step: 10
Training loss: 2.2667381971890683
Validation loss: 2.5515292438639445

Epoch: 6| Step: 11
Training loss: 2.819386338092971
Validation loss: 2.5001005039727207

Epoch: 6| Step: 12
Training loss: 2.557730259677183
Validation loss: 2.475026794343247

Epoch: 6| Step: 13
Training loss: 1.214810925987807
Validation loss: 2.464512915024769

Epoch: 193| Step: 0
Training loss: 2.484299088763843
Validation loss: 2.4635370996748502

Epoch: 6| Step: 1
Training loss: 1.8310199866503538
Validation loss: 2.477805199058969

Epoch: 6| Step: 2
Training loss: 3.0287503032865226
Validation loss: 2.500774218541977

Epoch: 6| Step: 3
Training loss: 2.887383700584218
Validation loss: 2.508874662567204

Epoch: 6| Step: 4
Training loss: 2.3182486143705567
Validation loss: 2.5101196922879025

Epoch: 6| Step: 5
Training loss: 2.5080972194962996
Validation loss: 2.473951737935332

Epoch: 6| Step: 6
Training loss: 2.242825088497539
Validation loss: 2.4732081165109956

Epoch: 6| Step: 7
Training loss: 2.2927264681810495
Validation loss: 2.4993784901023064

Epoch: 6| Step: 8
Training loss: 2.8248811950007986
Validation loss: 2.5268699824632854

Epoch: 6| Step: 9
Training loss: 3.002533161065966
Validation loss: 2.5524290519104675

Epoch: 6| Step: 10
Training loss: 3.192972459597261
Validation loss: 2.5942747927171697

Epoch: 6| Step: 11
Training loss: 2.942762814357858
Validation loss: 2.636178421448097

Epoch: 6| Step: 12
Training loss: 2.401711282979699
Validation loss: 2.6385959723537216

Epoch: 6| Step: 13
Training loss: 3.591852499866655
Validation loss: 2.6302102216342

Epoch: 194| Step: 0
Training loss: 2.348114629036707
Validation loss: 2.609978689335311

Epoch: 6| Step: 1
Training loss: 2.964805150440434
Validation loss: 2.629277381797473

Epoch: 6| Step: 2
Training loss: 2.8189480088207244
Validation loss: 2.6191066170098747

Epoch: 6| Step: 3
Training loss: 2.829197801316587
Validation loss: 2.5898269773790306

Epoch: 6| Step: 4
Training loss: 2.693038733236746
Validation loss: 2.552337565178634

Epoch: 6| Step: 5
Training loss: 2.6694869585077705
Validation loss: 2.519794247583159

Epoch: 6| Step: 6
Training loss: 3.1059959875745333
Validation loss: 2.5125828067890463

Epoch: 6| Step: 7
Training loss: 2.247124636050223
Validation loss: 2.5134277775965614

Epoch: 6| Step: 8
Training loss: 1.6760925146165742
Validation loss: 2.5010703636010376

Epoch: 6| Step: 9
Training loss: 2.825400204288251
Validation loss: 2.508634079810666

Epoch: 6| Step: 10
Training loss: 2.826717637730127
Validation loss: 2.507571943131884

Epoch: 6| Step: 11
Training loss: 2.4492890318988048
Validation loss: 2.486922751372411

Epoch: 6| Step: 12
Training loss: 2.51318269251186
Validation loss: 2.5041851636861283

Epoch: 6| Step: 13
Training loss: 2.7910747374994487
Validation loss: 2.498030928952017

Epoch: 195| Step: 0
Training loss: 2.599907425919633
Validation loss: 2.488602912228257

Epoch: 6| Step: 1
Training loss: 2.6784843212677845
Validation loss: 2.495447065574216

Epoch: 6| Step: 2
Training loss: 2.385439565845726
Validation loss: 2.4970075150633058

Epoch: 6| Step: 3
Training loss: 2.772332973557104
Validation loss: 2.4985602027000824

Epoch: 6| Step: 4
Training loss: 2.3367569420644974
Validation loss: 2.5160254102020096

Epoch: 6| Step: 5
Training loss: 2.963687797031996
Validation loss: 2.522068860596469

Epoch: 6| Step: 6
Training loss: 2.5503377017634135
Validation loss: 2.556776321928611

Epoch: 6| Step: 7
Training loss: 2.748098149258458
Validation loss: 2.559498738862554

Epoch: 6| Step: 8
Training loss: 2.730158754141404
Validation loss: 2.579358345023548

Epoch: 6| Step: 9
Training loss: 2.82224061948265
Validation loss: 2.5593789375085874

Epoch: 6| Step: 10
Training loss: 2.919083674633483
Validation loss: 2.5560123113966413

Epoch: 6| Step: 11
Training loss: 2.942849178938334
Validation loss: 2.5437288796052306

Epoch: 6| Step: 12
Training loss: 1.7951622802994338
Validation loss: 2.5546752431655193

Epoch: 6| Step: 13
Training loss: 2.1124741005297403
Validation loss: 2.572282056665434

Epoch: 196| Step: 0
Training loss: 3.093387929363332
Validation loss: 2.5859083414362365

Epoch: 6| Step: 1
Training loss: 1.8209406215155868
Validation loss: 2.5754127552345003

Epoch: 6| Step: 2
Training loss: 2.659851325619884
Validation loss: 2.5722860073455895

Epoch: 6| Step: 3
Training loss: 2.45699185338298
Validation loss: 2.5765182087047993

Epoch: 6| Step: 4
Training loss: 2.3488308575219534
Validation loss: 2.5547935280948524

Epoch: 6| Step: 5
Training loss: 3.047164199015491
Validation loss: 2.54205940624178

Epoch: 6| Step: 6
Training loss: 2.631218945825136
Validation loss: 2.5281608465124

Epoch: 6| Step: 7
Training loss: 2.4749770038191454
Validation loss: 2.5206882438781624

Epoch: 6| Step: 8
Training loss: 2.2764140042040633
Validation loss: 2.509577399524231

Epoch: 6| Step: 9
Training loss: 2.4449901429272125
Validation loss: 2.502158104620005

Epoch: 6| Step: 10
Training loss: 2.6986026750913616
Validation loss: 2.505698690332405

Epoch: 6| Step: 11
Training loss: 2.417630715845214
Validation loss: 2.4951364410552075

Epoch: 6| Step: 12
Training loss: 3.0093096289263794
Validation loss: 2.492165975998175

Epoch: 6| Step: 13
Training loss: 2.89846579648418
Validation loss: 2.4749253715963557

Epoch: 197| Step: 0
Training loss: 2.7471599652374215
Validation loss: 2.471243313072569

Epoch: 6| Step: 1
Training loss: 2.873082226212236
Validation loss: 2.4707467812620867

Epoch: 6| Step: 2
Training loss: 2.7588569889314627
Validation loss: 2.461200099671642

Epoch: 6| Step: 3
Training loss: 2.611960494994304
Validation loss: 2.4639579128014475

Epoch: 6| Step: 4
Training loss: 2.6625175582951526
Validation loss: 2.468934855582841

Epoch: 6| Step: 5
Training loss: 2.6761836953570968
Validation loss: 2.472617063976633

Epoch: 6| Step: 6
Training loss: 2.185171141043514
Validation loss: 2.481721269363354

Epoch: 6| Step: 7
Training loss: 2.449071268268215
Validation loss: 2.494585452635457

Epoch: 6| Step: 8
Training loss: 2.1578543402767756
Validation loss: 2.481485419081572

Epoch: 6| Step: 9
Training loss: 2.577538255912676
Validation loss: 2.4945041359696885

Epoch: 6| Step: 10
Training loss: 2.7875693034636018
Validation loss: 2.5093864260749643

Epoch: 6| Step: 11
Training loss: 2.7799125627447974
Validation loss: 2.537777830737714

Epoch: 6| Step: 12
Training loss: 2.0771261697354833
Validation loss: 2.5363244849773485

Epoch: 6| Step: 13
Training loss: 3.411959281812588
Validation loss: 2.5537904462266194

Epoch: 198| Step: 0
Training loss: 2.390966752501206
Validation loss: 2.538911904790421

Epoch: 6| Step: 1
Training loss: 2.682740632540379
Validation loss: 2.537631378094675

Epoch: 6| Step: 2
Training loss: 2.7296210243240515
Validation loss: 2.526911565558134

Epoch: 6| Step: 3
Training loss: 1.8533152078981763
Validation loss: 2.5034393555598826

Epoch: 6| Step: 4
Training loss: 2.4006029722617876
Validation loss: 2.504271754419785

Epoch: 6| Step: 5
Training loss: 3.2089659492395533
Validation loss: 2.4984874518181432

Epoch: 6| Step: 6
Training loss: 2.1287906720346643
Validation loss: 2.5077029172865926

Epoch: 6| Step: 7
Training loss: 2.4838240870353347
Validation loss: 2.512876156907802

Epoch: 6| Step: 8
Training loss: 2.4989730633111646
Validation loss: 2.5092713246039073

Epoch: 6| Step: 9
Training loss: 2.7928376280409792
Validation loss: 2.5211826273320437

Epoch: 6| Step: 10
Training loss: 2.822196521375014
Validation loss: 2.5335850895211225

Epoch: 6| Step: 11
Training loss: 2.806043206902543
Validation loss: 2.542695407332393

Epoch: 6| Step: 12
Training loss: 2.8514892568718655
Validation loss: 2.5347998553576865

Epoch: 6| Step: 13
Training loss: 2.0683256007850983
Validation loss: 2.580880550447265

Epoch: 199| Step: 0
Training loss: 1.7177145873588802
Validation loss: 2.588523211194378

Epoch: 6| Step: 1
Training loss: 2.6496997627184196
Validation loss: 2.59286210832546

Epoch: 6| Step: 2
Training loss: 2.625136780581205
Validation loss: 2.5588643784857323

Epoch: 6| Step: 3
Training loss: 2.4800147414538425
Validation loss: 2.5340501455517503

Epoch: 6| Step: 4
Training loss: 2.547593653102018
Validation loss: 2.538394579503977

Epoch: 6| Step: 5
Training loss: 2.4618075331473883
Validation loss: 2.549085980902958

Epoch: 6| Step: 6
Training loss: 2.8235043034886362
Validation loss: 2.548986143146232

Epoch: 6| Step: 7
Training loss: 2.059973816936721
Validation loss: 2.5455797501511044

Epoch: 6| Step: 8
Training loss: 2.355956980650906
Validation loss: 2.542131716947665

Epoch: 6| Step: 9
Training loss: 2.916100655994006
Validation loss: 2.535933273686253

Epoch: 6| Step: 10
Training loss: 2.6450234522798377
Validation loss: 2.5311597501383636

Epoch: 6| Step: 11
Training loss: 2.2683056987431036
Validation loss: 2.52442569953323

Epoch: 6| Step: 12
Training loss: 3.5954129559385066
Validation loss: 2.523877418071572

Epoch: 6| Step: 13
Training loss: 2.3666101135517508
Validation loss: 2.5215005702621816

Epoch: 200| Step: 0
Training loss: 2.348639309372511
Validation loss: 2.522456347771188

Epoch: 6| Step: 1
Training loss: 2.64385923696525
Validation loss: 2.50600813965332

Epoch: 6| Step: 2
Training loss: 2.458693095461672
Validation loss: 2.520551188934258

Epoch: 6| Step: 3
Training loss: 2.3611643492237913
Validation loss: 2.505456709806206

Epoch: 6| Step: 4
Training loss: 2.7936673657786204
Validation loss: 2.509394876905577

Epoch: 6| Step: 5
Training loss: 3.0090320047062775
Validation loss: 2.5051189876807576

Epoch: 6| Step: 6
Training loss: 2.3891847548006875
Validation loss: 2.503702078038898

Epoch: 6| Step: 7
Training loss: 1.8812271978574242
Validation loss: 2.5230868013394887

Epoch: 6| Step: 8
Training loss: 2.111463064280327
Validation loss: 2.511120805997819

Epoch: 6| Step: 9
Training loss: 2.5790589461584648
Validation loss: 2.528193161536088

Epoch: 6| Step: 10
Training loss: 2.4957397400932577
Validation loss: 2.527433754737362

Epoch: 6| Step: 11
Training loss: 2.6942686851655626
Validation loss: 2.5338082399748383

Epoch: 6| Step: 12
Training loss: 3.041934345607788
Validation loss: 2.552186549905651

Epoch: 6| Step: 13
Training loss: 2.6446993843396664
Validation loss: 2.5568271966441545

Epoch: 201| Step: 0
Training loss: 2.1238226153267346
Validation loss: 2.589228774933411

Epoch: 6| Step: 1
Training loss: 2.6907160833273847
Validation loss: 2.621253111632831

Epoch: 6| Step: 2
Training loss: 2.594639637057795
Validation loss: 2.632812355888399

Epoch: 6| Step: 3
Training loss: 2.687118503196263
Validation loss: 2.6220314607033193

Epoch: 6| Step: 4
Training loss: 2.774977221696174
Validation loss: 2.598561581767754

Epoch: 6| Step: 5
Training loss: 2.3870929231171942
Validation loss: 2.597319413184056

Epoch: 6| Step: 6
Training loss: 2.829740621319868
Validation loss: 2.5802434536189263

Epoch: 6| Step: 7
Training loss: 2.5633340734208736
Validation loss: 2.5529762756831573

Epoch: 6| Step: 8
Training loss: 2.779562105778162
Validation loss: 2.537772420148294

Epoch: 6| Step: 9
Training loss: 2.1837180005039794
Validation loss: 2.5407981101287938

Epoch: 6| Step: 10
Training loss: 2.8398343470442677
Validation loss: 2.5252010565941703

Epoch: 6| Step: 11
Training loss: 2.2503657573537055
Validation loss: 2.527938495620036

Epoch: 6| Step: 12
Training loss: 2.2534377009394735
Validation loss: 2.5369382796148914

Epoch: 6| Step: 13
Training loss: 2.519626633368927
Validation loss: 2.56453806667241

Epoch: 202| Step: 0
Training loss: 2.734998446643674
Validation loss: 2.5689513690007537

Epoch: 6| Step: 1
Training loss: 2.928942613637962
Validation loss: 2.579800510967719

Epoch: 6| Step: 2
Training loss: 2.2658510292693164
Validation loss: 2.599494972552178

Epoch: 6| Step: 3
Training loss: 2.6068237990347307
Validation loss: 2.596230061647586

Epoch: 6| Step: 4
Training loss: 2.422539798185265
Validation loss: 2.590885356083836

Epoch: 6| Step: 5
Training loss: 1.9794444909769222
Validation loss: 2.5882884668644355

Epoch: 6| Step: 6
Training loss: 2.2840848057396625
Validation loss: 2.5674539107311642

Epoch: 6| Step: 7
Training loss: 1.8670338842814105
Validation loss: 2.5771606292328673

Epoch: 6| Step: 8
Training loss: 2.499842257291514
Validation loss: 2.5584043341107594

Epoch: 6| Step: 9
Training loss: 3.070472150151099
Validation loss: 2.570818187077133

Epoch: 6| Step: 10
Training loss: 2.2236795600597756
Validation loss: 2.5700711826697002

Epoch: 6| Step: 11
Training loss: 2.502704492649273
Validation loss: 2.561467903035026

Epoch: 6| Step: 12
Training loss: 2.7549020252010834
Validation loss: 2.5743146186335495

Epoch: 6| Step: 13
Training loss: 2.860248703180017
Validation loss: 2.572864767262485

Epoch: 203| Step: 0
Training loss: 2.9094099688041815
Validation loss: 2.5604967520224036

Epoch: 6| Step: 1
Training loss: 3.0339959674926593
Validation loss: 2.5329647932642048

Epoch: 6| Step: 2
Training loss: 1.5690604765149052
Validation loss: 2.5170596406416252

Epoch: 6| Step: 3
Training loss: 2.6873181303719296
Validation loss: 2.5021890029533154

Epoch: 6| Step: 4
Training loss: 2.257000945598521
Validation loss: 2.5146249260795375

Epoch: 6| Step: 5
Training loss: 2.58290572370326
Validation loss: 2.511145117947452

Epoch: 6| Step: 6
Training loss: 2.4973148230711733
Validation loss: 2.5186202069325727

Epoch: 6| Step: 7
Training loss: 2.9557243089453933
Validation loss: 2.55488803248703

Epoch: 6| Step: 8
Training loss: 2.3667550777881696
Validation loss: 2.563154589675129

Epoch: 6| Step: 9
Training loss: 2.072766616476784
Validation loss: 2.5722350367272333

Epoch: 6| Step: 10
Training loss: 2.9019694645311636
Validation loss: 2.6007226940180996

Epoch: 6| Step: 11
Training loss: 2.2854012121641842
Validation loss: 2.622591186002972

Epoch: 6| Step: 12
Training loss: 2.2154395968795617
Validation loss: 2.6329305451998875

Epoch: 6| Step: 13
Training loss: 2.314391007374482
Validation loss: 2.615767749259707

Epoch: 204| Step: 0
Training loss: 2.445561502959658
Validation loss: 2.5963052359175856

Epoch: 6| Step: 1
Training loss: 2.503868067029216
Validation loss: 2.5845699433537006

Epoch: 6| Step: 2
Training loss: 2.252855396410029
Validation loss: 2.5605455564084054

Epoch: 6| Step: 3
Training loss: 2.2258693753943333
Validation loss: 2.511707076548869

Epoch: 6| Step: 4
Training loss: 3.032268549679109
Validation loss: 2.5109567212367128

Epoch: 6| Step: 5
Training loss: 2.245636417435272
Validation loss: 2.4897308786436505

Epoch: 6| Step: 6
Training loss: 2.0692307435140154
Validation loss: 2.4853151007634473

Epoch: 6| Step: 7
Training loss: 2.8422451858580398
Validation loss: 2.4602391926983476

Epoch: 6| Step: 8
Training loss: 2.2148465487884654
Validation loss: 2.461215398970803

Epoch: 6| Step: 9
Training loss: 2.2408945429584883
Validation loss: 2.4690053072332794

Epoch: 6| Step: 10
Training loss: 2.5915909019099734
Validation loss: 2.4810928640887133

Epoch: 6| Step: 11
Training loss: 2.9556225100640083
Validation loss: 2.498330833690863

Epoch: 6| Step: 12
Training loss: 2.646536265635192
Validation loss: 2.526966356964624

Epoch: 6| Step: 13
Training loss: 2.8316749506472396
Validation loss: 2.555656017455833

Epoch: 205| Step: 0
Training loss: 2.0185174814014837
Validation loss: 2.5807333302433495

Epoch: 6| Step: 1
Training loss: 2.496731337901062
Validation loss: 2.6111523624176343

Epoch: 6| Step: 2
Training loss: 2.6396919723911814
Validation loss: 2.6513375031135964

Epoch: 6| Step: 3
Training loss: 2.558599154634082
Validation loss: 2.662994311110364

Epoch: 6| Step: 4
Training loss: 2.8178064090679427
Validation loss: 2.6242262583292746

Epoch: 6| Step: 5
Training loss: 2.457023487169772
Validation loss: 2.580643873124673

Epoch: 6| Step: 6
Training loss: 2.1655554734115796
Validation loss: 2.542436274592619

Epoch: 6| Step: 7
Training loss: 2.707819572038875
Validation loss: 2.49453994337712

Epoch: 6| Step: 8
Training loss: 2.3072607125874636
Validation loss: 2.4881817625918634

Epoch: 6| Step: 9
Training loss: 2.6781798812246143
Validation loss: 2.485767909186763

Epoch: 6| Step: 10
Training loss: 2.9664414916859885
Validation loss: 2.4923080531932817

Epoch: 6| Step: 11
Training loss: 2.0920368986504374
Validation loss: 2.5206884147408672

Epoch: 6| Step: 12
Training loss: 2.287218620629582
Validation loss: 2.5361755385942675

Epoch: 6| Step: 13
Training loss: 2.896600763370893
Validation loss: 2.549394659793913

Epoch: 206| Step: 0
Training loss: 2.2187158286458613
Validation loss: 2.5698863596111288

Epoch: 6| Step: 1
Training loss: 2.3738595332405685
Validation loss: 2.5766604393124437

Epoch: 6| Step: 2
Training loss: 3.0204173536102976
Validation loss: 2.5911172007050944

Epoch: 6| Step: 3
Training loss: 1.755802208772898
Validation loss: 2.6114887579580475

Epoch: 6| Step: 4
Training loss: 2.557432793622637
Validation loss: 2.636490963082977

Epoch: 6| Step: 5
Training loss: 2.615872454132476
Validation loss: 2.6727123990758237

Epoch: 6| Step: 6
Training loss: 2.906898344180346
Validation loss: 2.6821153120222

Epoch: 6| Step: 7
Training loss: 2.429192299377708
Validation loss: 2.6702396915317532

Epoch: 6| Step: 8
Training loss: 2.1115078915722467
Validation loss: 2.666965161878404

Epoch: 6| Step: 9
Training loss: 2.495081832247066
Validation loss: 2.6398923842660587

Epoch: 6| Step: 10
Training loss: 2.666293197546587
Validation loss: 2.613114984070114

Epoch: 6| Step: 11
Training loss: 2.4678051263052474
Validation loss: 2.5800312799320855

Epoch: 6| Step: 12
Training loss: 2.438554975649041
Validation loss: 2.5619234556489348

Epoch: 6| Step: 13
Training loss: 2.4784738764091263
Validation loss: 2.544918460063113

Epoch: 207| Step: 0
Training loss: 3.029204789612229
Validation loss: 2.524009546030664

Epoch: 6| Step: 1
Training loss: 2.371461842856689
Validation loss: 2.489673765948532

Epoch: 6| Step: 2
Training loss: 2.5783124450975055
Validation loss: 2.482798682970438

Epoch: 6| Step: 3
Training loss: 1.574917243115445
Validation loss: 2.4815016522430637

Epoch: 6| Step: 4
Training loss: 2.617765903611482
Validation loss: 2.474408511451791

Epoch: 6| Step: 5
Training loss: 2.689123860733585
Validation loss: 2.4816656587618318

Epoch: 6| Step: 6
Training loss: 2.176126613635847
Validation loss: 2.487307783691518

Epoch: 6| Step: 7
Training loss: 2.728473157832097
Validation loss: 2.483130581074984

Epoch: 6| Step: 8
Training loss: 2.64638950980228
Validation loss: 2.5152055720249376

Epoch: 6| Step: 9
Training loss: 2.381790692477195
Validation loss: 2.517155614680125

Epoch: 6| Step: 10
Training loss: 2.6230498744921884
Validation loss: 2.5250916203564313

Epoch: 6| Step: 11
Training loss: 2.2229641934015185
Validation loss: 2.544664051503143

Epoch: 6| Step: 12
Training loss: 2.6056242157222806
Validation loss: 2.565588751561533

Epoch: 6| Step: 13
Training loss: 1.6405907036965874
Validation loss: 2.5602136852600488

Epoch: 208| Step: 0
Training loss: 2.219358548807304
Validation loss: 2.569639785474718

Epoch: 6| Step: 1
Training loss: 2.291693623702128
Validation loss: 2.6065003243855527

Epoch: 6| Step: 2
Training loss: 1.9873374392648224
Validation loss: 2.612013070504574

Epoch: 6| Step: 3
Training loss: 2.8817108447731705
Validation loss: 2.6343967114980265

Epoch: 6| Step: 4
Training loss: 2.2917982815025724
Validation loss: 2.6313615824152436

Epoch: 6| Step: 5
Training loss: 2.4977047874643366
Validation loss: 2.6355295665766483

Epoch: 6| Step: 6
Training loss: 3.3640803540823967
Validation loss: 2.611921148304308

Epoch: 6| Step: 7
Training loss: 2.1370519067996354
Validation loss: 2.634415344171475

Epoch: 6| Step: 8
Training loss: 2.74334353345023
Validation loss: 2.6302690659590704

Epoch: 6| Step: 9
Training loss: 1.8748265504083867
Validation loss: 2.620825035999872

Epoch: 6| Step: 10
Training loss: 2.3666794234814046
Validation loss: 2.5920750507282984

Epoch: 6| Step: 11
Training loss: 2.808521423681912
Validation loss: 2.6046152928632473

Epoch: 6| Step: 12
Training loss: 2.079362199822469
Validation loss: 2.5706682315294116

Epoch: 6| Step: 13
Training loss: 2.3562977914997423
Validation loss: 2.55970365073517

Epoch: 209| Step: 0
Training loss: 2.5753348308752755
Validation loss: 2.545039735867412

Epoch: 6| Step: 1
Training loss: 2.9883112488281816
Validation loss: 2.5178872516311888

Epoch: 6| Step: 2
Training loss: 2.5767011930151966
Validation loss: 2.5309404016468773

Epoch: 6| Step: 3
Training loss: 2.342605921936757
Validation loss: 2.504982442041277

Epoch: 6| Step: 4
Training loss: 2.2684221561520967
Validation loss: 2.4805364163998758

Epoch: 6| Step: 5
Training loss: 2.4015693222673713
Validation loss: 2.4684298364699613

Epoch: 6| Step: 6
Training loss: 2.6376457788758856
Validation loss: 2.462133658788056

Epoch: 6| Step: 7
Training loss: 2.4518156019450488
Validation loss: 2.4418169660408036

Epoch: 6| Step: 8
Training loss: 1.97104758965702
Validation loss: 2.4430991788765377

Epoch: 6| Step: 9
Training loss: 2.582749905897978
Validation loss: 2.4559707057391345

Epoch: 6| Step: 10
Training loss: 2.2298506165835037
Validation loss: 2.4755646015751087

Epoch: 6| Step: 11
Training loss: 2.730355758402895
Validation loss: 2.5221391194451317

Epoch: 6| Step: 12
Training loss: 2.4122274887263315
Validation loss: 2.5591507480195554

Epoch: 6| Step: 13
Training loss: 2.5762985695781837
Validation loss: 2.601581803387906

Epoch: 210| Step: 0
Training loss: 2.097263519632779
Validation loss: 2.617722874704967

Epoch: 6| Step: 1
Training loss: 2.788266364838385
Validation loss: 2.652742070971734

Epoch: 6| Step: 2
Training loss: 2.5248917207068398
Validation loss: 2.692452618973495

Epoch: 6| Step: 3
Training loss: 2.469494284932733
Validation loss: 2.668979759323151

Epoch: 6| Step: 4
Training loss: 2.8811286619375718
Validation loss: 2.6533011468685204

Epoch: 6| Step: 5
Training loss: 2.4265676013232156
Validation loss: 2.6264350863088626

Epoch: 6| Step: 6
Training loss: 2.59785265646122
Validation loss: 2.608133955368158

Epoch: 6| Step: 7
Training loss: 2.23954558821224
Validation loss: 2.6094412846503734

Epoch: 6| Step: 8
Training loss: 2.4846735361057335
Validation loss: 2.617807863385733

Epoch: 6| Step: 9
Training loss: 2.736227922694687
Validation loss: 2.6184020548396765

Epoch: 6| Step: 10
Training loss: 2.44467749592498
Validation loss: 2.6336117024356653

Epoch: 6| Step: 11
Training loss: 2.258312024887551
Validation loss: 2.579328503806705

Epoch: 6| Step: 12
Training loss: 2.366664816179582
Validation loss: 2.585722346237883

Epoch: 6| Step: 13
Training loss: 1.769337355072771
Validation loss: 2.577430888707202

Epoch: 211| Step: 0
Training loss: 2.1964857556988147
Validation loss: 2.5666828776538666

Epoch: 6| Step: 1
Training loss: 2.183176509185084
Validation loss: 2.558534754179647

Epoch: 6| Step: 2
Training loss: 2.0318224760440353
Validation loss: 2.544923063679021

Epoch: 6| Step: 3
Training loss: 2.6758750732011296
Validation loss: 2.5391154571639536

Epoch: 6| Step: 4
Training loss: 2.601705278024152
Validation loss: 2.531465932127398

Epoch: 6| Step: 5
Training loss: 2.871139256123213
Validation loss: 2.5329301272252187

Epoch: 6| Step: 6
Training loss: 2.6425970715437757
Validation loss: 2.5252902666700954

Epoch: 6| Step: 7
Training loss: 2.488746108584233
Validation loss: 2.5184721007422066

Epoch: 6| Step: 8
Training loss: 2.464333942486353
Validation loss: 2.511986239560391

Epoch: 6| Step: 9
Training loss: 2.483107141353239
Validation loss: 2.4896607941497844

Epoch: 6| Step: 10
Training loss: 2.712153708859163
Validation loss: 2.4907996999569586

Epoch: 6| Step: 11
Training loss: 2.46355171013385
Validation loss: 2.4808738459742803

Epoch: 6| Step: 12
Training loss: 2.3844160843855593
Validation loss: 2.4848192070273964

Epoch: 6| Step: 13
Training loss: 2.326857253669653
Validation loss: 2.4838432877599987

Epoch: 212| Step: 0
Training loss: 2.245011203117709
Validation loss: 2.48835583126545

Epoch: 6| Step: 1
Training loss: 2.4989955791725844
Validation loss: 2.4833689813504667

Epoch: 6| Step: 2
Training loss: 2.298496737776792
Validation loss: 2.4812772382003296

Epoch: 6| Step: 3
Training loss: 2.3541326829826126
Validation loss: 2.4916464694453584

Epoch: 6| Step: 4
Training loss: 2.473202806183495
Validation loss: 2.516255656288488

Epoch: 6| Step: 5
Training loss: 2.1070026762103016
Validation loss: 2.546616021256021

Epoch: 6| Step: 6
Training loss: 2.6732157416257363
Validation loss: 2.539884155705833

Epoch: 6| Step: 7
Training loss: 2.706924854736358
Validation loss: 2.5492123140260357

Epoch: 6| Step: 8
Training loss: 2.112200278965784
Validation loss: 2.5281428544460662

Epoch: 6| Step: 9
Training loss: 2.8037772654118815
Validation loss: 2.5162371572961426

Epoch: 6| Step: 10
Training loss: 2.7581039145065858
Validation loss: 2.50748685579774

Epoch: 6| Step: 11
Training loss: 2.8364966815920334
Validation loss: 2.48514969693325

Epoch: 6| Step: 12
Training loss: 1.6887849930893841
Validation loss: 2.491016561489507

Epoch: 6| Step: 13
Training loss: 2.9056100448384354
Validation loss: 2.5083040094329188

Epoch: 213| Step: 0
Training loss: 2.306239132739259
Validation loss: 2.5227298092814863

Epoch: 6| Step: 1
Training loss: 2.0805168441387627
Validation loss: 2.532713033410819

Epoch: 6| Step: 2
Training loss: 2.3370130225468815
Validation loss: 2.5452890617668156

Epoch: 6| Step: 3
Training loss: 2.5400250767048163
Validation loss: 2.5441609047350457

Epoch: 6| Step: 4
Training loss: 2.383023412156444
Validation loss: 2.5692397563686904

Epoch: 6| Step: 5
Training loss: 2.343134277846354
Validation loss: 2.5896199289173634

Epoch: 6| Step: 6
Training loss: 2.378654880115291
Validation loss: 2.6049527540125283

Epoch: 6| Step: 7
Training loss: 2.571293327771339
Validation loss: 2.6186924982822286

Epoch: 6| Step: 8
Training loss: 2.4805489114138637
Validation loss: 2.6076879905309345

Epoch: 6| Step: 9
Training loss: 2.677242932342995
Validation loss: 2.603955721935696

Epoch: 6| Step: 10
Training loss: 2.920810444334483
Validation loss: 2.623263678920322

Epoch: 6| Step: 11
Training loss: 2.752992562303012
Validation loss: 2.5855740373941845

Epoch: 6| Step: 12
Training loss: 2.0980792480425743
Validation loss: 2.571021690242154

Epoch: 6| Step: 13
Training loss: 1.206756807502874
Validation loss: 2.5563157202603968

Epoch: 214| Step: 0
Training loss: 2.5569096504573263
Validation loss: 2.557915510071752

Epoch: 6| Step: 1
Training loss: 2.8545571684251865
Validation loss: 2.5729879092328365

Epoch: 6| Step: 2
Training loss: 1.853287677797164
Validation loss: 2.564475880187255

Epoch: 6| Step: 3
Training loss: 2.3522871048010034
Validation loss: 2.568872882388976

Epoch: 6| Step: 4
Training loss: 2.941668859666506
Validation loss: 2.5363777368344356

Epoch: 6| Step: 5
Training loss: 2.460533084639975
Validation loss: 2.556397461510934

Epoch: 6| Step: 6
Training loss: 1.7987118164632967
Validation loss: 2.56494556863466

Epoch: 6| Step: 7
Training loss: 2.592054617282794
Validation loss: 2.554075420334095

Epoch: 6| Step: 8
Training loss: 1.8854590844990693
Validation loss: 2.5511931249049398

Epoch: 6| Step: 9
Training loss: 2.0985223839606495
Validation loss: 2.5648294810966754

Epoch: 6| Step: 10
Training loss: 2.332688333281901
Validation loss: 2.565472044590933

Epoch: 6| Step: 11
Training loss: 2.372969210888328
Validation loss: 2.581470584698118

Epoch: 6| Step: 12
Training loss: 2.529954932192141
Validation loss: 2.59510503828015

Epoch: 6| Step: 13
Training loss: 2.7338605996335583
Validation loss: 2.6095351323000973

Epoch: 215| Step: 0
Training loss: 2.6531607222202216
Validation loss: 2.6158898868966776

Epoch: 6| Step: 1
Training loss: 2.1855943280915797
Validation loss: 2.6123606132843804

Epoch: 6| Step: 2
Training loss: 2.0641336617919577
Validation loss: 2.6316559831427253

Epoch: 6| Step: 3
Training loss: 2.267522293704631
Validation loss: 2.6291253682839746

Epoch: 6| Step: 4
Training loss: 2.302074023842148
Validation loss: 2.635541200319907

Epoch: 6| Step: 5
Training loss: 2.2851617796741324
Validation loss: 2.646116008261832

Epoch: 6| Step: 6
Training loss: 2.7139491521503794
Validation loss: 2.628858970220959

Epoch: 6| Step: 7
Training loss: 1.8824596786740204
Validation loss: 2.5882790999048906

Epoch: 6| Step: 8
Training loss: 2.341021971914369
Validation loss: 2.5666352037846107

Epoch: 6| Step: 9
Training loss: 2.0555940086044346
Validation loss: 2.5708667775754246

Epoch: 6| Step: 10
Training loss: 2.3570665598984997
Validation loss: 2.5448262369018853

Epoch: 6| Step: 11
Training loss: 2.5947343727829857
Validation loss: 2.5290458964860525

Epoch: 6| Step: 12
Training loss: 2.907476679018782
Validation loss: 2.5143845366665536

Epoch: 6| Step: 13
Training loss: 2.3258326977417187
Validation loss: 2.5166750141791225

Epoch: 216| Step: 0
Training loss: 2.2933800505529853
Validation loss: 2.522840749272201

Epoch: 6| Step: 1
Training loss: 1.9539896157534435
Validation loss: 2.54806775286801

Epoch: 6| Step: 2
Training loss: 2.7674156469706794
Validation loss: 2.573215074900906

Epoch: 6| Step: 3
Training loss: 2.0713611178385007
Validation loss: 2.5914983987629427

Epoch: 6| Step: 4
Training loss: 2.286751475619679
Validation loss: 2.6116040947035515

Epoch: 6| Step: 5
Training loss: 2.4732462825348116
Validation loss: 2.5983703169699064

Epoch: 6| Step: 6
Training loss: 2.008043446598941
Validation loss: 2.60068315266338

Epoch: 6| Step: 7
Training loss: 2.2187475285046205
Validation loss: 2.6129351856009495

Epoch: 6| Step: 8
Training loss: 1.7990049260799867
Validation loss: 2.5929147467893228

Epoch: 6| Step: 9
Training loss: 1.738475660103792
Validation loss: 2.5934789797443094

Epoch: 6| Step: 10
Training loss: 2.4770968369184594
Validation loss: 2.5939037002191223

Epoch: 6| Step: 11
Training loss: 2.872331458875099
Validation loss: 2.5737236884266506

Epoch: 6| Step: 12
Training loss: 2.9182620635190584
Validation loss: 2.5859112858593742

Epoch: 6| Step: 13
Training loss: 3.151460242515563
Validation loss: 2.5687673246532334

Epoch: 217| Step: 0
Training loss: 1.9552161047050585
Validation loss: 2.559260363653806

Epoch: 6| Step: 1
Training loss: 1.7277493777433348
Validation loss: 2.5477311319579017

Epoch: 6| Step: 2
Training loss: 2.117819941466667
Validation loss: 2.5560128148947925

Epoch: 6| Step: 3
Training loss: 2.192596166887511
Validation loss: 2.536428062526343

Epoch: 6| Step: 4
Training loss: 2.8868353669145987
Validation loss: 2.5330640803848494

Epoch: 6| Step: 5
Training loss: 2.7126985925499016
Validation loss: 2.526300798391606

Epoch: 6| Step: 6
Training loss: 2.1420615172399082
Validation loss: 2.5328123779726006

Epoch: 6| Step: 7
Training loss: 2.1197568498481205
Validation loss: 2.526284804386464

Epoch: 6| Step: 8
Training loss: 2.3466485982257095
Validation loss: 2.536070481936318

Epoch: 6| Step: 9
Training loss: 2.298555654552749
Validation loss: 2.5333023380133155

Epoch: 6| Step: 10
Training loss: 1.9043257334552122
Validation loss: 2.5405127960494487

Epoch: 6| Step: 11
Training loss: 2.7461059049117553
Validation loss: 2.562626419130399

Epoch: 6| Step: 12
Training loss: 2.927136258951195
Validation loss: 2.5579860456214774

Epoch: 6| Step: 13
Training loss: 2.691075984362627
Validation loss: 2.577706796704688

Epoch: 218| Step: 0
Training loss: 1.6265286811295734
Validation loss: 2.607567998375662

Epoch: 6| Step: 1
Training loss: 2.0509088966970888
Validation loss: 2.6559103119410805

Epoch: 6| Step: 2
Training loss: 2.5594128877213196
Validation loss: 2.69286593623003

Epoch: 6| Step: 3
Training loss: 2.815820302339469
Validation loss: 2.7278964585761503

Epoch: 6| Step: 4
Training loss: 2.846466778862691
Validation loss: 2.6306824781382394

Epoch: 6| Step: 5
Training loss: 1.854699419042762
Validation loss: 2.572408800309802

Epoch: 6| Step: 6
Training loss: 2.2402592784824393
Validation loss: 2.5268421521380118

Epoch: 6| Step: 7
Training loss: 2.3949219227848224
Validation loss: 2.4913088879918943

Epoch: 6| Step: 8
Training loss: 2.5566948986194
Validation loss: 2.460377710926674

Epoch: 6| Step: 9
Training loss: 2.3648337569087055
Validation loss: 2.453216358743817

Epoch: 6| Step: 10
Training loss: 2.678759533771277
Validation loss: 2.435312669069505

Epoch: 6| Step: 11
Training loss: 2.3421575604154556
Validation loss: 2.4554562140599114

Epoch: 6| Step: 12
Training loss: 2.373103940929079
Validation loss: 2.4596196159256074

Epoch: 6| Step: 13
Training loss: 2.7650513134794292
Validation loss: 2.4762608595564704

Epoch: 219| Step: 0
Training loss: 2.122982862923554
Validation loss: 2.5197593698256044

Epoch: 6| Step: 1
Training loss: 2.46431594735312
Validation loss: 2.547306662635534

Epoch: 6| Step: 2
Training loss: 2.8615670895307943
Validation loss: 2.577235338148328

Epoch: 6| Step: 3
Training loss: 2.989470919490438
Validation loss: 2.6214853177680353

Epoch: 6| Step: 4
Training loss: 1.5691972254638882
Validation loss: 2.6001862000571507

Epoch: 6| Step: 5
Training loss: 2.206979180456016
Validation loss: 2.575670785386572

Epoch: 6| Step: 6
Training loss: 2.1657498938806943
Validation loss: 2.5692177872562114

Epoch: 6| Step: 7
Training loss: 2.1071926554413567
Validation loss: 2.5537644602498824

Epoch: 6| Step: 8
Training loss: 2.726108108738945
Validation loss: 2.544523571795138

Epoch: 6| Step: 9
Training loss: 2.4957760413147807
Validation loss: 2.5566817028337607

Epoch: 6| Step: 10
Training loss: 2.066831260197572
Validation loss: 2.5527195177511213

Epoch: 6| Step: 11
Training loss: 2.4999073011378297
Validation loss: 2.5599685278234645

Epoch: 6| Step: 12
Training loss: 1.8595317485998735
Validation loss: 2.5470893830533137

Epoch: 6| Step: 13
Training loss: 3.350586364443648
Validation loss: 2.5674992229312994

Epoch: 220| Step: 0
Training loss: 1.787143661086749
Validation loss: 2.5810582582425163

Epoch: 6| Step: 1
Training loss: 2.5897742444776184
Validation loss: 2.606847832097909

Epoch: 6| Step: 2
Training loss: 2.317055005062326
Validation loss: 2.595844265918355

Epoch: 6| Step: 3
Training loss: 1.9012143270041415
Validation loss: 2.594073707691185

Epoch: 6| Step: 4
Training loss: 2.64944411871313
Validation loss: 2.5906535827444555

Epoch: 6| Step: 5
Training loss: 3.0300177202871117
Validation loss: 2.567475088143452

Epoch: 6| Step: 6
Training loss: 2.712645242907223
Validation loss: 2.576365459437949

Epoch: 6| Step: 7
Training loss: 2.5832680929826406
Validation loss: 2.5882691822020956

Epoch: 6| Step: 8
Training loss: 1.5557400001818729
Validation loss: 2.5968448343421966

Epoch: 6| Step: 9
Training loss: 2.462286104313849
Validation loss: 2.6027967939544077

Epoch: 6| Step: 10
Training loss: 2.3857998491611925
Validation loss: 2.5848130640126867

Epoch: 6| Step: 11
Training loss: 2.248864205107257
Validation loss: 2.572054946141092

Epoch: 6| Step: 12
Training loss: 2.169068203759069
Validation loss: 2.5464812567704525

Epoch: 6| Step: 13
Training loss: 2.518645942753513
Validation loss: 2.5269430981287733

Epoch: 221| Step: 0
Training loss: 2.2501924220562333
Validation loss: 2.5462597525932478

Epoch: 6| Step: 1
Training loss: 2.320738063023384
Validation loss: 2.5352642446443254

Epoch: 6| Step: 2
Training loss: 2.298416139670672
Validation loss: 2.5172529864166284

Epoch: 6| Step: 3
Training loss: 1.8505012915585373
Validation loss: 2.5191348662727897

Epoch: 6| Step: 4
Training loss: 2.4123688222374233
Validation loss: 2.4988420224703036

Epoch: 6| Step: 5
Training loss: 2.968446736155228
Validation loss: 2.4890002165329106

Epoch: 6| Step: 6
Training loss: 2.218255538646327
Validation loss: 2.513705526695367

Epoch: 6| Step: 7
Training loss: 1.9998055005865925
Validation loss: 2.512013663984149

Epoch: 6| Step: 8
Training loss: 2.5071676500683626
Validation loss: 2.539952774658509

Epoch: 6| Step: 9
Training loss: 2.3250400662815367
Validation loss: 2.5512074820745942

Epoch: 6| Step: 10
Training loss: 2.462812115403363
Validation loss: 2.5511888903409243

Epoch: 6| Step: 11
Training loss: 2.4045864150902787
Validation loss: 2.552114458796285

Epoch: 6| Step: 12
Training loss: 2.491659652632045
Validation loss: 2.558711861798794

Epoch: 6| Step: 13
Training loss: 1.5198434543305395
Validation loss: 2.585225985548856

Epoch: 222| Step: 0
Training loss: 1.943412987051009
Validation loss: 2.581699767502862

Epoch: 6| Step: 1
Training loss: 2.579189566252266
Validation loss: 2.6045854378617697

Epoch: 6| Step: 2
Training loss: 1.8062312141682317
Validation loss: 2.579415737507161

Epoch: 6| Step: 3
Training loss: 2.5640388148281437
Validation loss: 2.538694163220827

Epoch: 6| Step: 4
Training loss: 2.2308114184430208
Validation loss: 2.5203752039537903

Epoch: 6| Step: 5
Training loss: 2.273098425469909
Validation loss: 2.503598951336657

Epoch: 6| Step: 6
Training loss: 2.9638232659945802
Validation loss: 2.4804683029979264

Epoch: 6| Step: 7
Training loss: 2.0712674223881344
Validation loss: 2.4904107965126436

Epoch: 6| Step: 8
Training loss: 2.4741704802988567
Validation loss: 2.477691224444234

Epoch: 6| Step: 9
Training loss: 2.3903546149241355
Validation loss: 2.4558442078539513

Epoch: 6| Step: 10
Training loss: 1.941408706141555
Validation loss: 2.4905260768793966

Epoch: 6| Step: 11
Training loss: 2.665573541786297
Validation loss: 2.4831809416324355

Epoch: 6| Step: 12
Training loss: 2.3788331870899926
Validation loss: 2.5191037040962456

Epoch: 6| Step: 13
Training loss: 1.870271123621236
Validation loss: 2.5449944700343834

Epoch: 223| Step: 0
Training loss: 2.215786741564774
Validation loss: 2.573496962635976

Epoch: 6| Step: 1
Training loss: 2.747689490270439
Validation loss: 2.625068476145641

Epoch: 6| Step: 2
Training loss: 2.2478059031361735
Validation loss: 2.640629095996763

Epoch: 6| Step: 3
Training loss: 2.4111280661405288
Validation loss: 2.6434351043678483

Epoch: 6| Step: 4
Training loss: 2.285976582191115
Validation loss: 2.6201530942296087

Epoch: 6| Step: 5
Training loss: 2.543604523718948
Validation loss: 2.598045955579244

Epoch: 6| Step: 6
Training loss: 2.969990360745287
Validation loss: 2.5847138217076715

Epoch: 6| Step: 7
Training loss: 1.7739523253802985
Validation loss: 2.559751744141136

Epoch: 6| Step: 8
Training loss: 2.252227210696082
Validation loss: 2.542586128180512

Epoch: 6| Step: 9
Training loss: 2.223062541814633
Validation loss: 2.5260296517583156

Epoch: 6| Step: 10
Training loss: 2.206390125698487
Validation loss: 2.497169536130138

Epoch: 6| Step: 11
Training loss: 2.0276135097954393
Validation loss: 2.4892383167663605

Epoch: 6| Step: 12
Training loss: 2.081077142358911
Validation loss: 2.4901720578790827

Epoch: 6| Step: 13
Training loss: 2.090297984732805
Validation loss: 2.4971429794195785

Epoch: 224| Step: 0
Training loss: 2.0842974784195616
Validation loss: 2.48288439746193

Epoch: 6| Step: 1
Training loss: 2.3423553386302576
Validation loss: 2.505703725120882

Epoch: 6| Step: 2
Training loss: 2.404185412602145
Validation loss: 2.5168471122202685

Epoch: 6| Step: 3
Training loss: 2.3679024903866908
Validation loss: 2.536276355697583

Epoch: 6| Step: 4
Training loss: 2.098371046523746
Validation loss: 2.5579009364845753

Epoch: 6| Step: 5
Training loss: 2.3839874872608924
Validation loss: 2.5525281092045202

Epoch: 6| Step: 6
Training loss: 2.2666460564555204
Validation loss: 2.567979656803183

Epoch: 6| Step: 7
Training loss: 2.614574619800491
Validation loss: 2.585885059556232

Epoch: 6| Step: 8
Training loss: 1.6730053369467752
Validation loss: 2.567494767133938

Epoch: 6| Step: 9
Training loss: 2.369281509877388
Validation loss: 2.5700672176124457

Epoch: 6| Step: 10
Training loss: 2.429151862368176
Validation loss: 2.5492003003843995

Epoch: 6| Step: 11
Training loss: 2.7835053289878764
Validation loss: 2.551081911506702

Epoch: 6| Step: 12
Training loss: 1.5734484281037302
Validation loss: 2.5523470856365766

Epoch: 6| Step: 13
Training loss: 2.310582783823882
Validation loss: 2.5166018395840744

Epoch: 225| Step: 0
Training loss: 2.188390496062537
Validation loss: 2.5143406291811115

Epoch: 6| Step: 1
Training loss: 1.907525495706259
Validation loss: 2.5208860951326537

Epoch: 6| Step: 2
Training loss: 2.2493982570046867
Validation loss: 2.5196908510900164

Epoch: 6| Step: 3
Training loss: 2.0876729653706194
Validation loss: 2.5308621604561004

Epoch: 6| Step: 4
Training loss: 2.984030339176281
Validation loss: 2.5168853030234573

Epoch: 6| Step: 5
Training loss: 2.6275538782172614
Validation loss: 2.5316436007827456

Epoch: 6| Step: 6
Training loss: 2.498916200317349
Validation loss: 2.5350724960491045

Epoch: 6| Step: 7
Training loss: 2.4582722112093887
Validation loss: 2.532547308762335

Epoch: 6| Step: 8
Training loss: 2.226165414838626
Validation loss: 2.559825639170545

Epoch: 6| Step: 9
Training loss: 2.069616236657152
Validation loss: 2.554345688486927

Epoch: 6| Step: 10
Training loss: 2.2821911477314814
Validation loss: 2.5421432769095635

Epoch: 6| Step: 11
Training loss: 2.0174956401792024
Validation loss: 2.5626065621977836

Epoch: 6| Step: 12
Training loss: 2.106628664655808
Validation loss: 2.552994402021921

Epoch: 6| Step: 13
Training loss: 1.747296970562996
Validation loss: 2.5540577132057694

Epoch: 226| Step: 0
Training loss: 2.255541229933339
Validation loss: 2.524548344650484

Epoch: 6| Step: 1
Training loss: 2.9412180319822796
Validation loss: 2.5031424512433165

Epoch: 6| Step: 2
Training loss: 2.0378234138541655
Validation loss: 2.4889896591323653

Epoch: 6| Step: 3
Training loss: 2.588642284707145
Validation loss: 2.483594082749726

Epoch: 6| Step: 4
Training loss: 2.1520258120013382
Validation loss: 2.4799368080847035

Epoch: 6| Step: 5
Training loss: 2.2202768579316183
Validation loss: 2.4666606836348954

Epoch: 6| Step: 6
Training loss: 1.9986104906741127
Validation loss: 2.475393719067398

Epoch: 6| Step: 7
Training loss: 2.1030675327560844
Validation loss: 2.496794853837489

Epoch: 6| Step: 8
Training loss: 2.21273191712843
Validation loss: 2.5067470902998017

Epoch: 6| Step: 9
Training loss: 2.383934682284096
Validation loss: 2.518823200695896

Epoch: 6| Step: 10
Training loss: 2.445237423655305
Validation loss: 2.5363109679144578

Epoch: 6| Step: 11
Training loss: 1.9503347378529419
Validation loss: 2.565481739646664

Epoch: 6| Step: 12
Training loss: 1.922089851589412
Validation loss: 2.559332830447357

Epoch: 6| Step: 13
Training loss: 2.5206395749957813
Validation loss: 2.571769686541686

Epoch: 227| Step: 0
Training loss: 2.390954587070374
Validation loss: 2.5539619614964666

Epoch: 6| Step: 1
Training loss: 2.0109948494654124
Validation loss: 2.528314583563706

Epoch: 6| Step: 2
Training loss: 1.8689955253445458
Validation loss: 2.5304297147716937

Epoch: 6| Step: 3
Training loss: 2.225047348890236
Validation loss: 2.5082361589710964

Epoch: 6| Step: 4
Training loss: 2.199621891994831
Validation loss: 2.49763277840787

Epoch: 6| Step: 5
Training loss: 2.1504051492115654
Validation loss: 2.4974571052075296

Epoch: 6| Step: 6
Training loss: 1.7635142444957883
Validation loss: 2.525685428575613

Epoch: 6| Step: 7
Training loss: 2.5843752841418848
Validation loss: 2.5435043266717248

Epoch: 6| Step: 8
Training loss: 2.467959313587432
Validation loss: 2.533482271038526

Epoch: 6| Step: 9
Training loss: 2.36206134175132
Validation loss: 2.5364182624819462

Epoch: 6| Step: 10
Training loss: 2.602638732261261
Validation loss: 2.53204957463509

Epoch: 6| Step: 11
Training loss: 1.207001225860403
Validation loss: 2.5181131869508073

Epoch: 6| Step: 12
Training loss: 2.8146981867903613
Validation loss: 2.5382566989852178

Epoch: 6| Step: 13
Training loss: 2.457594765963544
Validation loss: 2.5393829350489625

Epoch: 228| Step: 0
Training loss: 2.392193747025798
Validation loss: 2.5460153821721487

Epoch: 6| Step: 1
Training loss: 2.3580863414419473
Validation loss: 2.554484254639014

Epoch: 6| Step: 2
Training loss: 1.4892149872172473
Validation loss: 2.5658878668134255

Epoch: 6| Step: 3
Training loss: 2.5507685382053085
Validation loss: 2.5619040455741833

Epoch: 6| Step: 4
Training loss: 2.625290990777
Validation loss: 2.5635132265843246

Epoch: 6| Step: 5
Training loss: 1.9777899387547706
Validation loss: 2.5637286862382416

Epoch: 6| Step: 6
Training loss: 1.9747870994450936
Validation loss: 2.5533485843969044

Epoch: 6| Step: 7
Training loss: 2.157614676918744
Validation loss: 2.535770994667984

Epoch: 6| Step: 8
Training loss: 2.40295620686364
Validation loss: 2.5162953374265813

Epoch: 6| Step: 9
Training loss: 2.2327497213199243
Validation loss: 2.520431186129013

Epoch: 6| Step: 10
Training loss: 1.843037419092971
Validation loss: 2.4839812508664587

Epoch: 6| Step: 11
Training loss: 2.50730258594307
Validation loss: 2.5024272169845885

Epoch: 6| Step: 12
Training loss: 2.5527673440451806
Validation loss: 2.4776272984443164

Epoch: 6| Step: 13
Training loss: 2.179222905130487
Validation loss: 2.5192058221109774

Epoch: 229| Step: 0
Training loss: 2.152105577864136
Validation loss: 2.514936427936518

Epoch: 6| Step: 1
Training loss: 1.9572864602104103
Validation loss: 2.5285776145430536

Epoch: 6| Step: 2
Training loss: 2.3586680382587475
Validation loss: 2.523407680698865

Epoch: 6| Step: 3
Training loss: 1.760631623396164
Validation loss: 2.534646338709531

Epoch: 6| Step: 4
Training loss: 2.166738790143079
Validation loss: 2.523889939250096

Epoch: 6| Step: 5
Training loss: 2.7156701017262592
Validation loss: 2.5372117969242622

Epoch: 6| Step: 6
Training loss: 2.8509694776128827
Validation loss: 2.535962296191938

Epoch: 6| Step: 7
Training loss: 1.964899202629835
Validation loss: 2.542905858100483

Epoch: 6| Step: 8
Training loss: 2.7401337934810335
Validation loss: 2.571842769760311

Epoch: 6| Step: 9
Training loss: 1.9481523612594227
Validation loss: 2.5822303996385734

Epoch: 6| Step: 10
Training loss: 1.8210551175569674
Validation loss: 2.5742092561559957

Epoch: 6| Step: 11
Training loss: 2.492749763608888
Validation loss: 2.572534902912204

Epoch: 6| Step: 12
Training loss: 2.1619924842781475
Validation loss: 2.5474379950424635

Epoch: 6| Step: 13
Training loss: 2.0099549496285065
Validation loss: 2.5151521257022544

Epoch: 230| Step: 0
Training loss: 2.2604433986882078
Validation loss: 2.47565884257177

Epoch: 6| Step: 1
Training loss: 1.9323874670034051
Validation loss: 2.4668780148443257

Epoch: 6| Step: 2
Training loss: 2.454895546860618
Validation loss: 2.449021661873315

Epoch: 6| Step: 3
Training loss: 2.0808263444865895
Validation loss: 2.4743054232073223

Epoch: 6| Step: 4
Training loss: 2.563351931494157
Validation loss: 2.502219415782268

Epoch: 6| Step: 5
Training loss: 2.240230969374046
Validation loss: 2.488182560064767

Epoch: 6| Step: 6
Training loss: 2.193452746475129
Validation loss: 2.515066082850182

Epoch: 6| Step: 7
Training loss: 1.9350591481949433
Validation loss: 2.5332245978522656

Epoch: 6| Step: 8
Training loss: 2.4633107201446376
Validation loss: 2.534752354536667

Epoch: 6| Step: 9
Training loss: 1.9879761707251657
Validation loss: 2.585458098694003

Epoch: 6| Step: 10
Training loss: 2.12620263568886
Validation loss: 2.590450844965374

Epoch: 6| Step: 11
Training loss: 2.44358691673804
Validation loss: 2.594089935004791

Epoch: 6| Step: 12
Training loss: 2.3789999556603574
Validation loss: 2.6105039768960947

Epoch: 6| Step: 13
Training loss: 2.385503431405274
Validation loss: 2.6009362294190033

Epoch: 231| Step: 0
Training loss: 2.2109297357968796
Validation loss: 2.6030401317486147

Epoch: 6| Step: 1
Training loss: 1.8849120404390918
Validation loss: 2.6009092409032384

Epoch: 6| Step: 2
Training loss: 2.3043173282567224
Validation loss: 2.5744076376516905

Epoch: 6| Step: 3
Training loss: 2.246799523965392
Validation loss: 2.5261019311449724

Epoch: 6| Step: 4
Training loss: 2.3826428962757085
Validation loss: 2.521640242329091

Epoch: 6| Step: 5
Training loss: 2.2245774371472766
Validation loss: 2.5212847536741907

Epoch: 6| Step: 6
Training loss: 2.87091205047924
Validation loss: 2.541297151106848

Epoch: 6| Step: 7
Training loss: 2.690602840106372
Validation loss: 2.555126050060824

Epoch: 6| Step: 8
Training loss: 1.1010544058292249
Validation loss: 2.5830266411884

Epoch: 6| Step: 9
Training loss: 2.007905475526954
Validation loss: 2.5929210834237133

Epoch: 6| Step: 10
Training loss: 2.059838629763036
Validation loss: 2.62152137493882

Epoch: 6| Step: 11
Training loss: 2.2729904941371815
Validation loss: 2.6030787863905407

Epoch: 6| Step: 12
Training loss: 2.2496782708617906
Validation loss: 2.6230915230005927

Epoch: 6| Step: 13
Training loss: 2.4602641804273575
Validation loss: 2.581723862655411

Epoch: 232| Step: 0
Training loss: 2.4049667305340394
Validation loss: 2.5513342723471664

Epoch: 6| Step: 1
Training loss: 1.9688634688360787
Validation loss: 2.5275054939224675

Epoch: 6| Step: 2
Training loss: 1.924818374685766
Validation loss: 2.4819864740794015

Epoch: 6| Step: 3
Training loss: 1.8222853811814244
Validation loss: 2.467147888822825

Epoch: 6| Step: 4
Training loss: 2.7004216076908154
Validation loss: 2.4827076486747948

Epoch: 6| Step: 5
Training loss: 1.9774176515584836
Validation loss: 2.484705110488089

Epoch: 6| Step: 6
Training loss: 2.287035151709796
Validation loss: 2.5098111789125657

Epoch: 6| Step: 7
Training loss: 1.3497934395331526
Validation loss: 2.510416092070698

Epoch: 6| Step: 8
Training loss: 2.269572535022782
Validation loss: 2.541244623765151

Epoch: 6| Step: 9
Training loss: 2.450988616779964
Validation loss: 2.5591341218470354

Epoch: 6| Step: 10
Training loss: 2.2400476964913385
Validation loss: 2.5730264842943322

Epoch: 6| Step: 11
Training loss: 3.020624000048733
Validation loss: 2.540706496194271

Epoch: 6| Step: 12
Training loss: 2.2842928306736616
Validation loss: 2.5417059151133823

Epoch: 6| Step: 13
Training loss: 1.4860375179159948
Validation loss: 2.5343327590033797

Epoch: 233| Step: 0
Training loss: 2.349546563251506
Validation loss: 2.519688309008572

Epoch: 6| Step: 1
Training loss: 2.21742327070325
Validation loss: 2.538378000181578

Epoch: 6| Step: 2
Training loss: 2.394837501444554
Validation loss: 2.529820463778653

Epoch: 6| Step: 3
Training loss: 2.401136240610199
Validation loss: 2.5598282720872803

Epoch: 6| Step: 4
Training loss: 2.404552802464543
Validation loss: 2.5552799114615103

Epoch: 6| Step: 5
Training loss: 1.997040824392624
Validation loss: 2.5629720155593665

Epoch: 6| Step: 6
Training loss: 0.9921058561120131
Validation loss: 2.5650158149157973

Epoch: 6| Step: 7
Training loss: 2.0076062285748297
Validation loss: 2.547513940405038

Epoch: 6| Step: 8
Training loss: 1.774848410352339
Validation loss: 2.512330603976788

Epoch: 6| Step: 9
Training loss: 2.215658586298624
Validation loss: 2.5030227424963924

Epoch: 6| Step: 10
Training loss: 2.587525033138644
Validation loss: 2.4752298303703917

Epoch: 6| Step: 11
Training loss: 2.0140322520941876
Validation loss: 2.4621138191642804

Epoch: 6| Step: 12
Training loss: 2.432831425920884
Validation loss: 2.45513872762348

Epoch: 6| Step: 13
Training loss: 2.2070349229090014
Validation loss: 2.4553199376373294

Epoch: 234| Step: 0
Training loss: 2.7555561290846335
Validation loss: 2.447418255009044

Epoch: 6| Step: 1
Training loss: 2.181966704312985
Validation loss: 2.476285245621289

Epoch: 6| Step: 2
Training loss: 2.1260277002060572
Validation loss: 2.478473392327391

Epoch: 6| Step: 3
Training loss: 2.3053396563063586
Validation loss: 2.4939035730895287

Epoch: 6| Step: 4
Training loss: 1.961185029353516
Validation loss: 2.5195028822544274

Epoch: 6| Step: 5
Training loss: 2.3582478034839167
Validation loss: 2.5394772648820005

Epoch: 6| Step: 6
Training loss: 2.0477746049485326
Validation loss: 2.5507927767932186

Epoch: 6| Step: 7
Training loss: 2.161576257882228
Validation loss: 2.5908935781913907

Epoch: 6| Step: 8
Training loss: 2.157748378985975
Validation loss: 2.6005272791696084

Epoch: 6| Step: 9
Training loss: 1.9071654951140933
Validation loss: 2.618421241916531

Epoch: 6| Step: 10
Training loss: 2.5355980345637006
Validation loss: 2.600007267556079

Epoch: 6| Step: 11
Training loss: 1.855934743087527
Validation loss: 2.5815189051770364

Epoch: 6| Step: 12
Training loss: 2.095956579064376
Validation loss: 2.5539757033400847

Epoch: 6| Step: 13
Training loss: 1.268520528026535
Validation loss: 2.5298752560257913

Epoch: 235| Step: 0
Training loss: 2.6902767297150474
Validation loss: 2.4938657381097924

Epoch: 6| Step: 1
Training loss: 2.1729496554403016
Validation loss: 2.4705125242248385

Epoch: 6| Step: 2
Training loss: 2.2460836659080696
Validation loss: 2.477042022912304

Epoch: 6| Step: 3
Training loss: 2.008664436535758
Validation loss: 2.448903416458372

Epoch: 6| Step: 4
Training loss: 2.2947290477500584
Validation loss: 2.4352053392205866

Epoch: 6| Step: 5
Training loss: 1.7925841473735729
Validation loss: 2.424753862530528

Epoch: 6| Step: 6
Training loss: 1.7758176183102183
Validation loss: 2.4333637145749196

Epoch: 6| Step: 7
Training loss: 1.691816460816011
Validation loss: 2.4236051965229524

Epoch: 6| Step: 8
Training loss: 2.3471399840846554
Validation loss: 2.4536214304893624

Epoch: 6| Step: 9
Training loss: 2.3374915423724727
Validation loss: 2.478100201307411

Epoch: 6| Step: 10
Training loss: 2.302508756473885
Validation loss: 2.517616810799706

Epoch: 6| Step: 11
Training loss: 1.9355457047998796
Validation loss: 2.5842439678608518

Epoch: 6| Step: 12
Training loss: 2.1067579070183124
Validation loss: 2.6214543786752813

Epoch: 6| Step: 13
Training loss: 2.928587684187484
Validation loss: 2.6402826069627885

Epoch: 236| Step: 0
Training loss: 2.190057403996592
Validation loss: 2.554781327461513

Epoch: 6| Step: 1
Training loss: 2.251115522419025
Validation loss: 2.5250303543785866

Epoch: 6| Step: 2
Training loss: 1.9807215422059683
Validation loss: 2.5144233745783655

Epoch: 6| Step: 3
Training loss: 2.231878419743687
Validation loss: 2.5057718272889864

Epoch: 6| Step: 4
Training loss: 1.4585427633404089
Validation loss: 2.516014013502543

Epoch: 6| Step: 5
Training loss: 1.8796301575346597
Validation loss: 2.523283484088677

Epoch: 6| Step: 6
Training loss: 2.4314744272081574
Validation loss: 2.4933503900244713

Epoch: 6| Step: 7
Training loss: 2.444560657493797
Validation loss: 2.47790314148176

Epoch: 6| Step: 8
Training loss: 2.116058499030587
Validation loss: 2.461020493495556

Epoch: 6| Step: 9
Training loss: 2.54240690197785
Validation loss: 2.4474649253806566

Epoch: 6| Step: 10
Training loss: 2.0178598242354875
Validation loss: 2.4491992077024345

Epoch: 6| Step: 11
Training loss: 2.26266222630374
Validation loss: 2.4697359358579094

Epoch: 6| Step: 12
Training loss: 2.5593523371511693
Validation loss: 2.5362591712129348

Epoch: 6| Step: 13
Training loss: 2.520679490200147
Validation loss: 2.5954657132267527

Epoch: 237| Step: 0
Training loss: 2.0251465873879195
Validation loss: 2.6855528995151756

Epoch: 6| Step: 1
Training loss: 2.43911552689245
Validation loss: 2.7228897542369115

Epoch: 6| Step: 2
Training loss: 2.697552002130676
Validation loss: 2.7443648079934566

Epoch: 6| Step: 3
Training loss: 2.1215914147699566
Validation loss: 2.707847069439859

Epoch: 6| Step: 4
Training loss: 2.306625224037017
Validation loss: 2.660499244058688

Epoch: 6| Step: 5
Training loss: 2.7617074407753326
Validation loss: 2.610133983671547

Epoch: 6| Step: 6
Training loss: 1.8715757254940408
Validation loss: 2.59605700572231

Epoch: 6| Step: 7
Training loss: 1.5140167040438826
Validation loss: 2.580252861672607

Epoch: 6| Step: 8
Training loss: 2.277057086575763
Validation loss: 2.5592743850726523

Epoch: 6| Step: 9
Training loss: 2.247467735322017
Validation loss: 2.541803509279468

Epoch: 6| Step: 10
Training loss: 2.221021644476513
Validation loss: 2.5187533740388957

Epoch: 6| Step: 11
Training loss: 2.5898036119391534
Validation loss: 2.4841059273778323

Epoch: 6| Step: 12
Training loss: 2.456635120280742
Validation loss: 2.4788835401243174

Epoch: 6| Step: 13
Training loss: 2.1536112686083473
Validation loss: 2.469181318548146

Epoch: 238| Step: 0
Training loss: 2.54567311017387
Validation loss: 2.4817424345963905

Epoch: 6| Step: 1
Training loss: 2.419621754555788
Validation loss: 2.4907460531236953

Epoch: 6| Step: 2
Training loss: 2.247718183813085
Validation loss: 2.4908465373230992

Epoch: 6| Step: 3
Training loss: 2.2847329293734164
Validation loss: 2.4657545451861664

Epoch: 6| Step: 4
Training loss: 2.081130070710579
Validation loss: 2.4515649942847992

Epoch: 6| Step: 5
Training loss: 1.7490810297478094
Validation loss: 2.4440292864749087

Epoch: 6| Step: 6
Training loss: 2.3084547385045524
Validation loss: 2.44995254305729

Epoch: 6| Step: 7
Training loss: 2.578159771309079
Validation loss: 2.476888490044551

Epoch: 6| Step: 8
Training loss: 1.9088304907634575
Validation loss: 2.509530107777877

Epoch: 6| Step: 9
Training loss: 2.1251940919087113
Validation loss: 2.5222819928714713

Epoch: 6| Step: 10
Training loss: 2.4318927925221723
Validation loss: 2.544654956161459

Epoch: 6| Step: 11
Training loss: 2.3476950440716307
Validation loss: 2.5642794081700475

Epoch: 6| Step: 12
Training loss: 2.1046443308910896
Validation loss: 2.614207568046976

Epoch: 6| Step: 13
Training loss: 2.4189804006841484
Validation loss: 2.6319108886322846

Epoch: 239| Step: 0
Training loss: 2.1195865566238403
Validation loss: 2.6063905915819663

Epoch: 6| Step: 1
Training loss: 2.2001598776898557
Validation loss: 2.575755033658493

Epoch: 6| Step: 2
Training loss: 2.2670069196046043
Validation loss: 2.5215941213087123

Epoch: 6| Step: 3
Training loss: 2.471666858267525
Validation loss: 2.528998355509274

Epoch: 6| Step: 4
Training loss: 1.9104632109529518
Validation loss: 2.532716716844894

Epoch: 6| Step: 5
Training loss: 1.4734028105227281
Validation loss: 2.5290855837336275

Epoch: 6| Step: 6
Training loss: 1.8587969995545448
Validation loss: 2.5318143056829605

Epoch: 6| Step: 7
Training loss: 2.6346417419854373
Validation loss: 2.579213734553353

Epoch: 6| Step: 8
Training loss: 2.624617321639955
Validation loss: 2.5452741137190813

Epoch: 6| Step: 9
Training loss: 1.91533024124142
Validation loss: 2.535283915299138

Epoch: 6| Step: 10
Training loss: 1.775780361190419
Validation loss: 2.5278734519747643

Epoch: 6| Step: 11
Training loss: 2.3640366537089363
Validation loss: 2.53961279068636

Epoch: 6| Step: 12
Training loss: 2.3029958950176748
Validation loss: 2.538292209345792

Epoch: 6| Step: 13
Training loss: 1.9142220566867127
Validation loss: 2.5156746596174426

Epoch: 240| Step: 0
Training loss: 1.8671225692121296
Validation loss: 2.5154013514248734

Epoch: 6| Step: 1
Training loss: 1.431862349468879
Validation loss: 2.4871753711656543

Epoch: 6| Step: 2
Training loss: 2.777157462051938
Validation loss: 2.4624996141160964

Epoch: 6| Step: 3
Training loss: 2.0746334257690826
Validation loss: 2.4379416508169363

Epoch: 6| Step: 4
Training loss: 1.8963634322758254
Validation loss: 2.4305822347728614

Epoch: 6| Step: 5
Training loss: 2.0808296672690467
Validation loss: 2.4251068780534846

Epoch: 6| Step: 6
Training loss: 1.928070131878289
Validation loss: 2.4389908929507222

Epoch: 6| Step: 7
Training loss: 2.400763759679669
Validation loss: 2.4376235417352246

Epoch: 6| Step: 8
Training loss: 2.2022366728096294
Validation loss: 2.4530877237941056

Epoch: 6| Step: 9
Training loss: 2.368251448129996
Validation loss: 2.466594558328114

Epoch: 6| Step: 10
Training loss: 2.3316248247247464
Validation loss: 2.49850399417759

Epoch: 6| Step: 11
Training loss: 2.423068730663009
Validation loss: 2.5164504523961266

Epoch: 6| Step: 12
Training loss: 1.7224316785796985
Validation loss: 2.5530219984753666

Epoch: 6| Step: 13
Training loss: 2.447331871359955
Validation loss: 2.5835001736478467

Epoch: 241| Step: 0
Training loss: 2.174590464654171
Validation loss: 2.59723333357448

Epoch: 6| Step: 1
Training loss: 1.961511474743063
Validation loss: 2.611195621338868

Epoch: 6| Step: 2
Training loss: 2.103338462573456
Validation loss: 2.5910381358861083

Epoch: 6| Step: 3
Training loss: 1.7395322948285803
Validation loss: 2.5715139716350084

Epoch: 6| Step: 4
Training loss: 2.174743185556911
Validation loss: 2.5557170999734393

Epoch: 6| Step: 5
Training loss: 1.6122117457643528
Validation loss: 2.536491456659576

Epoch: 6| Step: 6
Training loss: 2.406975574833837
Validation loss: 2.5130395726104515

Epoch: 6| Step: 7
Training loss: 2.0757261499364574
Validation loss: 2.501675987406922

Epoch: 6| Step: 8
Training loss: 2.1891535367694175
Validation loss: 2.486711087000707

Epoch: 6| Step: 9
Training loss: 2.1289009864112107
Validation loss: 2.4965256883372855

Epoch: 6| Step: 10
Training loss: 1.7711688752262762
Validation loss: 2.5107651532755173

Epoch: 6| Step: 11
Training loss: 2.5701175140350503
Validation loss: 2.505300171767938

Epoch: 6| Step: 12
Training loss: 2.007755263882029
Validation loss: 2.533950266768203

Epoch: 6| Step: 13
Training loss: 2.4808251312636247
Validation loss: 2.5234853580657775

Epoch: 242| Step: 0
Training loss: 2.640776048662717
Validation loss: 2.532383381313739

Epoch: 6| Step: 1
Training loss: 2.214217593643848
Validation loss: 2.5414471913967027

Epoch: 6| Step: 2
Training loss: 1.3902385045992685
Validation loss: 2.5662653411377434

Epoch: 6| Step: 3
Training loss: 2.2039081453127927
Validation loss: 2.5445358029738387

Epoch: 6| Step: 4
Training loss: 1.869675897469497
Validation loss: 2.5423216484351996

Epoch: 6| Step: 5
Training loss: 1.9034641734089177
Validation loss: 2.5411622034145562

Epoch: 6| Step: 6
Training loss: 1.7590819797463977
Validation loss: 2.525662348770642

Epoch: 6| Step: 7
Training loss: 2.4027486320398834
Validation loss: 2.506434558391177

Epoch: 6| Step: 8
Training loss: 1.9767528939805485
Validation loss: 2.4758268188606674

Epoch: 6| Step: 9
Training loss: 2.2532929589343147
Validation loss: 2.488470335789839

Epoch: 6| Step: 10
Training loss: 1.3401787786646076
Validation loss: 2.4694116322901207

Epoch: 6| Step: 11
Training loss: 2.234515312430872
Validation loss: 2.4578826763061707

Epoch: 6| Step: 12
Training loss: 1.9066046713151272
Validation loss: 2.499194934385312

Epoch: 6| Step: 13
Training loss: 2.545064645482039
Validation loss: 2.499252251605024

Epoch: 243| Step: 0
Training loss: 2.1107297714657496
Validation loss: 2.526035767474241

Epoch: 6| Step: 1
Training loss: 1.8823647500905405
Validation loss: 2.5390679250048667

Epoch: 6| Step: 2
Training loss: 1.9718678929220488
Validation loss: 2.5447811274495606

Epoch: 6| Step: 3
Training loss: 2.0026701745579487
Validation loss: 2.566664451453802

Epoch: 6| Step: 4
Training loss: 1.8904073290404746
Validation loss: 2.563467332892691

Epoch: 6| Step: 5
Training loss: 2.389542677471674
Validation loss: 2.555244992343025

Epoch: 6| Step: 6
Training loss: 1.283883296282733
Validation loss: 2.5671714443231757

Epoch: 6| Step: 7
Training loss: 2.217701408933261
Validation loss: 2.569533534908824

Epoch: 6| Step: 8
Training loss: 1.7280725288358103
Validation loss: 2.5811497956939866

Epoch: 6| Step: 9
Training loss: 2.127537726707673
Validation loss: 2.579684164714731

Epoch: 6| Step: 10
Training loss: 2.259357807943484
Validation loss: 2.595044311876005

Epoch: 6| Step: 11
Training loss: 2.46634653651706
Validation loss: 2.548611641032573

Epoch: 6| Step: 12
Training loss: 1.7806973854956203
Validation loss: 2.554876699770612

Epoch: 6| Step: 13
Training loss: 2.380186140651178
Validation loss: 2.5274458556122155

Epoch: 244| Step: 0
Training loss: 1.6304094070726594
Validation loss: 2.4962954843662404

Epoch: 6| Step: 1
Training loss: 1.9902897790566352
Validation loss: 2.4922650153151262

Epoch: 6| Step: 2
Training loss: 1.8999079280429048
Validation loss: 2.486464774334723

Epoch: 6| Step: 3
Training loss: 1.9870523728416851
Validation loss: 2.491938461774239

Epoch: 6| Step: 4
Training loss: 1.8048964870708035
Validation loss: 2.4826812955840727

Epoch: 6| Step: 5
Training loss: 1.7332678345384847
Validation loss: 2.4794304534087432

Epoch: 6| Step: 6
Training loss: 1.9939249876714449
Validation loss: 2.4850347716932877

Epoch: 6| Step: 7
Training loss: 2.064837431708551
Validation loss: 2.5046171928214944

Epoch: 6| Step: 8
Training loss: 2.3998321553984714
Validation loss: 2.4967758040520875

Epoch: 6| Step: 9
Training loss: 2.046438505500034
Validation loss: 2.5137715967702188

Epoch: 6| Step: 10
Training loss: 2.045650902388019
Validation loss: 2.5321437828063247

Epoch: 6| Step: 11
Training loss: 1.729970614894848
Validation loss: 2.549320838511233

Epoch: 6| Step: 12
Training loss: 2.239359065219273
Validation loss: 2.550439844756634

Epoch: 6| Step: 13
Training loss: 2.539959370596027
Validation loss: 2.582429261912811

Epoch: 245| Step: 0
Training loss: 2.2678322399132376
Validation loss: 2.5896921628986083

Epoch: 6| Step: 1
Training loss: 2.1775550392106062
Validation loss: 2.6062671451393693

Epoch: 6| Step: 2
Training loss: 2.1063878135986394
Validation loss: 2.6003144160880036

Epoch: 6| Step: 3
Training loss: 1.9849117484280885
Validation loss: 2.5913995351565915

Epoch: 6| Step: 4
Training loss: 1.5285050058130036
Validation loss: 2.551962030946298

Epoch: 6| Step: 5
Training loss: 2.120197591570424
Validation loss: 2.5335405853782755

Epoch: 6| Step: 6
Training loss: 1.9418739047260714
Validation loss: 2.5219189899259056

Epoch: 6| Step: 7
Training loss: 1.7277998827099112
Validation loss: 2.5292080880296406

Epoch: 6| Step: 8
Training loss: 2.3663746662620246
Validation loss: 2.5140659874818896

Epoch: 6| Step: 9
Training loss: 2.1974741654510312
Validation loss: 2.5081453794700006

Epoch: 6| Step: 10
Training loss: 1.9648639533822445
Validation loss: 2.5250687930038995

Epoch: 6| Step: 11
Training loss: 1.2020587407356156
Validation loss: 2.513077955931973

Epoch: 6| Step: 12
Training loss: 1.9979614955525473
Validation loss: 2.4988777697702793

Epoch: 6| Step: 13
Training loss: 1.7068903186156794
Validation loss: 2.471763546244952

Epoch: 246| Step: 0
Training loss: 2.4696375543099847
Validation loss: 2.483682894241938

Epoch: 6| Step: 1
Training loss: 1.6188468344456728
Validation loss: 2.498831030616504

Epoch: 6| Step: 2
Training loss: 2.2807672068113964
Validation loss: 2.514901310533339

Epoch: 6| Step: 3
Training loss: 1.56445754451818
Validation loss: 2.5478323787785997

Epoch: 6| Step: 4
Training loss: 1.8860323271342305
Validation loss: 2.5751184637160947

Epoch: 6| Step: 5
Training loss: 1.843264176322865
Validation loss: 2.5767881147159657

Epoch: 6| Step: 6
Training loss: 2.0982704897138857
Validation loss: 2.5622605012531547

Epoch: 6| Step: 7
Training loss: 2.4425007312347975
Validation loss: 2.551041544439313

Epoch: 6| Step: 8
Training loss: 1.6155223289937206
Validation loss: 2.5263380507068973

Epoch: 6| Step: 9
Training loss: 1.7845858741591942
Validation loss: 2.4718229359979573

Epoch: 6| Step: 10
Training loss: 1.9456683832975423
Validation loss: 2.4625180248939422

Epoch: 6| Step: 11
Training loss: 1.6704021633194475
Validation loss: 2.4380723540525677

Epoch: 6| Step: 12
Training loss: 2.1477920949969294
Validation loss: 2.4483375042698508

Epoch: 6| Step: 13
Training loss: 2.0712974652484557
Validation loss: 2.475473144871671

Epoch: 247| Step: 0
Training loss: 1.9890543515741934
Validation loss: 2.478225266272033

Epoch: 6| Step: 1
Training loss: 2.0470589125615812
Validation loss: 2.4922276795595333

Epoch: 6| Step: 2
Training loss: 2.158298680188081
Validation loss: 2.5074147483478346

Epoch: 6| Step: 3
Training loss: 2.2948084247223686
Validation loss: 2.5312368163962247

Epoch: 6| Step: 4
Training loss: 1.814947646045401
Validation loss: 2.5494692934416086

Epoch: 6| Step: 5
Training loss: 2.1636238617605055
Validation loss: 2.5935617777174094

Epoch: 6| Step: 6
Training loss: 1.8439612833290464
Validation loss: 2.6473310848487284

Epoch: 6| Step: 7
Training loss: 1.9626983396567734
Validation loss: 2.638346571176228

Epoch: 6| Step: 8
Training loss: 1.8790772294825302
Validation loss: 2.6092587384256007

Epoch: 6| Step: 9
Training loss: 1.7008636580808372
Validation loss: 2.5666370366430082

Epoch: 6| Step: 10
Training loss: 1.5443563282176362
Validation loss: 2.538568177170345

Epoch: 6| Step: 11
Training loss: 1.6721916968318462
Validation loss: 2.50667477031998

Epoch: 6| Step: 12
Training loss: 2.2735891389908187
Validation loss: 2.4790507198391434

Epoch: 6| Step: 13
Training loss: 2.2667174763688087
Validation loss: 2.4490134790088516

Epoch: 248| Step: 0
Training loss: 1.6016726572253521
Validation loss: 2.465902918655685

Epoch: 6| Step: 1
Training loss: 1.6566137238350946
Validation loss: 2.4473259056993983

Epoch: 6| Step: 2
Training loss: 2.3252346863791455
Validation loss: 2.490539988086723

Epoch: 6| Step: 3
Training loss: 1.6101143629316366
Validation loss: 2.489251676458303

Epoch: 6| Step: 4
Training loss: 1.5138087450720101
Validation loss: 2.4936329137299835

Epoch: 6| Step: 5
Training loss: 2.05169517860878
Validation loss: 2.4919097649967155

Epoch: 6| Step: 6
Training loss: 2.0253557811009557
Validation loss: 2.499651500550771

Epoch: 6| Step: 7
Training loss: 2.422877934660987
Validation loss: 2.4894314135754247

Epoch: 6| Step: 8
Training loss: 2.0139136331141576
Validation loss: 2.496865964017363

Epoch: 6| Step: 9
Training loss: 2.30736662755115
Validation loss: 2.5128826953722676

Epoch: 6| Step: 10
Training loss: 1.5531561128811955
Validation loss: 2.541338408353599

Epoch: 6| Step: 11
Training loss: 2.0731036103519163
Validation loss: 2.534131002558161

Epoch: 6| Step: 12
Training loss: 1.5273071440775965
Validation loss: 2.530657126714353

Epoch: 6| Step: 13
Training loss: 1.9953234356346765
Validation loss: 2.5351804234753876

Epoch: 249| Step: 0
Training loss: 2.010948255816952
Validation loss: 2.572922433128702

Epoch: 6| Step: 1
Training loss: 1.671140348935922
Validation loss: 2.5745464369528466

Epoch: 6| Step: 2
Training loss: 2.8247544240973443
Validation loss: 2.5775718137742434

Epoch: 6| Step: 3
Training loss: 2.1702519122043777
Validation loss: 2.564763969639479

Epoch: 6| Step: 4
Training loss: 1.9050063156664028
Validation loss: 2.584751306309323

Epoch: 6| Step: 5
Training loss: 1.6665035485871649
Validation loss: 2.6077705737912433

Epoch: 6| Step: 6
Training loss: 1.7520228683555603
Validation loss: 2.6066744557923034

Epoch: 6| Step: 7
Training loss: 2.003805830969543
Validation loss: 2.569552306690438

Epoch: 6| Step: 8
Training loss: 2.249746308329733
Validation loss: 2.547472482778788

Epoch: 6| Step: 9
Training loss: 1.2055768877379514
Validation loss: 2.5452532008087965

Epoch: 6| Step: 10
Training loss: 1.4896717534354333
Validation loss: 2.543349982719366

Epoch: 6| Step: 11
Training loss: 1.795742440929114
Validation loss: 2.536375993292237

Epoch: 6| Step: 12
Training loss: 1.6631298048200158
Validation loss: 2.5183698766274083

Epoch: 6| Step: 13
Training loss: 2.1520040974489363
Validation loss: 2.49752210441794

Epoch: 250| Step: 0
Training loss: 2.161382785687128
Validation loss: 2.4963887697136546

Epoch: 6| Step: 1
Training loss: 1.7664097755123624
Validation loss: 2.520036698803523

Epoch: 6| Step: 2
Training loss: 1.6615154850456582
Validation loss: 2.49168705487598

Epoch: 6| Step: 3
Training loss: 1.6814545319098726
Validation loss: 2.507401765576202

Epoch: 6| Step: 4
Training loss: 1.9694942097129646
Validation loss: 2.492818235096957

Epoch: 6| Step: 5
Training loss: 1.2350086565525131
Validation loss: 2.4847167230161933

Epoch: 6| Step: 6
Training loss: 1.9186027395791336
Validation loss: 2.491590651309032

Epoch: 6| Step: 7
Training loss: 2.2291657872658774
Validation loss: 2.481090891574105

Epoch: 6| Step: 8
Training loss: 2.0660945895274874
Validation loss: 2.4951428523667296

Epoch: 6| Step: 9
Training loss: 1.7922728939714632
Validation loss: 2.5187512579876876

Epoch: 6| Step: 10
Training loss: 1.9114420489068837
Validation loss: 2.5370971504583886

Epoch: 6| Step: 11
Training loss: 2.142706089145324
Validation loss: 2.546195167910704

Epoch: 6| Step: 12
Training loss: 1.6841114779337003
Validation loss: 2.572370545862265

Epoch: 6| Step: 13
Training loss: 2.1898215917091566
Validation loss: 2.598201329673997

Epoch: 251| Step: 0
Training loss: 1.8199078679083072
Validation loss: 2.617900714843458

Epoch: 6| Step: 1
Training loss: 2.0204706423674414
Validation loss: 2.6241580269105467

Epoch: 6| Step: 2
Training loss: 2.083110937328009
Validation loss: 2.612974383589094

Epoch: 6| Step: 3
Training loss: 1.0976155229391116
Validation loss: 2.6015534340886712

Epoch: 6| Step: 4
Training loss: 2.031498116231576
Validation loss: 2.596465595679968

Epoch: 6| Step: 5
Training loss: 1.805624450282102
Validation loss: 2.585170836301487

Epoch: 6| Step: 6
Training loss: 2.259752120205973
Validation loss: 2.5847667153748284

Epoch: 6| Step: 7
Training loss: 1.4231461931408844
Validation loss: 2.5353351575837495

Epoch: 6| Step: 8
Training loss: 1.8597830957666974
Validation loss: 2.518181726216867

Epoch: 6| Step: 9
Training loss: 1.825676411208792
Validation loss: 2.496058487664339

Epoch: 6| Step: 10
Training loss: 2.026934455613579
Validation loss: 2.5092441818200797

Epoch: 6| Step: 11
Training loss: 1.7707141013302803
Validation loss: 2.5026377308946053

Epoch: 6| Step: 12
Training loss: 1.939802462952318
Validation loss: 2.5013693750775587

Epoch: 6| Step: 13
Training loss: 2.389112006224005
Validation loss: 2.5168259040243846

Epoch: 252| Step: 0
Training loss: 2.0703291982301244
Validation loss: 2.528235657779675

Epoch: 6| Step: 1
Training loss: 2.318918753598542
Validation loss: 2.5443155128572217

Epoch: 6| Step: 2
Training loss: 1.8322935912913902
Validation loss: 2.536698324057075

Epoch: 6| Step: 3
Training loss: 1.9052109935388057
Validation loss: 2.548890774719557

Epoch: 6| Step: 4
Training loss: 1.1186025767451673
Validation loss: 2.553343821270321

Epoch: 6| Step: 5
Training loss: 2.1575242852074146
Validation loss: 2.5409938487243897

Epoch: 6| Step: 6
Training loss: 2.0855425628657542
Validation loss: 2.520397231610191

Epoch: 6| Step: 7
Training loss: 1.1481523224596368
Validation loss: 2.5455525805972323

Epoch: 6| Step: 8
Training loss: 1.6388601347274057
Validation loss: 2.559463383497545

Epoch: 6| Step: 9
Training loss: 2.428304100550122
Validation loss: 2.570234652416065

Epoch: 6| Step: 10
Training loss: 1.6346831488911473
Validation loss: 2.5794160307029936

Epoch: 6| Step: 11
Training loss: 1.9011604028139717
Validation loss: 2.5694902689966974

Epoch: 6| Step: 12
Training loss: 1.4766952212796969
Validation loss: 2.5817588337403197

Epoch: 6| Step: 13
Training loss: 1.2210637162725735
Validation loss: 2.581125084348507

Epoch: 253| Step: 0
Training loss: 1.6312817420648154
Validation loss: 2.5432169795785677

Epoch: 6| Step: 1
Training loss: 1.7664211807396057
Validation loss: 2.526877477961295

Epoch: 6| Step: 2
Training loss: 2.3857229999484244
Validation loss: 2.5548180666598443

Epoch: 6| Step: 3
Training loss: 1.687961656505564
Validation loss: 2.529672404266012

Epoch: 6| Step: 4
Training loss: 1.839153703034031
Validation loss: 2.5466346750642894

Epoch: 6| Step: 5
Training loss: 1.5867753845655763
Validation loss: 2.556081704943678

Epoch: 6| Step: 6
Training loss: 1.7051586643349763
Validation loss: 2.574487024008776

Epoch: 6| Step: 7
Training loss: 1.7071359981985075
Validation loss: 2.589408614614642

Epoch: 6| Step: 8
Training loss: 1.9417296971035307
Validation loss: 2.5828761408400482

Epoch: 6| Step: 9
Training loss: 1.7540238304911675
Validation loss: 2.561911755785425

Epoch: 6| Step: 10
Training loss: 1.7751157105031348
Validation loss: 2.559910984754119

Epoch: 6| Step: 11
Training loss: 2.1074914505356386
Validation loss: 2.5496941787031004

Epoch: 6| Step: 12
Training loss: 1.7744903128180312
Validation loss: 2.5352879377892017

Epoch: 6| Step: 13
Training loss: 0.9926920531553409
Validation loss: 2.5408682582017383

Epoch: 254| Step: 0
Training loss: 1.8287222775009193
Validation loss: 2.5138676820619428

Epoch: 6| Step: 1
Training loss: 1.4419648863476089
Validation loss: 2.5357165198874285

Epoch: 6| Step: 2
Training loss: 1.3713562108290356
Validation loss: 2.531347964877619

Epoch: 6| Step: 3
Training loss: 1.9671651728350026
Validation loss: 2.5412420795374686

Epoch: 6| Step: 4
Training loss: 1.6243759570939054
Validation loss: 2.552130603331585

Epoch: 6| Step: 5
Training loss: 1.694643723732978
Validation loss: 2.5560589848524913

Epoch: 6| Step: 6
Training loss: 1.6993335904305404
Validation loss: 2.586038621517037

Epoch: 6| Step: 7
Training loss: 2.229510366973078
Validation loss: 2.590693504777244

Epoch: 6| Step: 8
Training loss: 1.460786454659384
Validation loss: 2.587012772483564

Epoch: 6| Step: 9
Training loss: 2.1544264670549844
Validation loss: 2.588113778434776

Epoch: 6| Step: 10
Training loss: 2.0540904058675933
Validation loss: 2.590329956352002

Epoch: 6| Step: 11
Training loss: 2.181289794908636
Validation loss: 2.57913692300232

Epoch: 6| Step: 12
Training loss: 1.3686028701926058
Validation loss: 2.5866119131880603

Epoch: 6| Step: 13
Training loss: 1.5124191514782868
Validation loss: 2.567186716244227

Epoch: 255| Step: 0
Training loss: 1.5750492451553084
Validation loss: 2.5455401337468637

Epoch: 6| Step: 1
Training loss: 1.8580546459501766
Validation loss: 2.5422606575151097

Epoch: 6| Step: 2
Training loss: 1.9176421654630884
Validation loss: 2.5471765926080745

Epoch: 6| Step: 3
Training loss: 2.189909888203377
Validation loss: 2.563546743030946

Epoch: 6| Step: 4
Training loss: 1.9174544194460206
Validation loss: 2.5891757664719806

Epoch: 6| Step: 5
Training loss: 2.024567159852549
Validation loss: 2.5809338027840227

Epoch: 6| Step: 6
Training loss: 1.7135879680403474
Validation loss: 2.601234315560969

Epoch: 6| Step: 7
Training loss: 1.347691455325938
Validation loss: 2.6221519388000005

Epoch: 6| Step: 8
Training loss: 1.5843550581119104
Validation loss: 2.6076538788952344

Epoch: 6| Step: 9
Training loss: 1.2824289433833247
Validation loss: 2.604466802877671

Epoch: 6| Step: 10
Training loss: 2.074108286069589
Validation loss: 2.584638193259754

Epoch: 6| Step: 11
Training loss: 1.121544405115497
Validation loss: 2.569349143128786

Epoch: 6| Step: 12
Training loss: 1.9830592441567578
Validation loss: 2.5651259274848286

Epoch: 6| Step: 13
Training loss: 1.7373303502092101
Validation loss: 2.5541872983215415

Epoch: 256| Step: 0
Training loss: 1.242895584302764
Validation loss: 2.584667421696946

Epoch: 6| Step: 1
Training loss: 1.8799385518319316
Validation loss: 2.559680344838351

Epoch: 6| Step: 2
Training loss: 1.6543354989218977
Validation loss: 2.5601439881449117

Epoch: 6| Step: 3
Training loss: 1.6665936771940788
Validation loss: 2.553976634851717

Epoch: 6| Step: 4
Training loss: 2.06391869505348
Validation loss: 2.5633847499799423

Epoch: 6| Step: 5
Training loss: 1.7709824293612293
Validation loss: 2.5403693438847017

Epoch: 6| Step: 6
Training loss: 1.3556058523005061
Validation loss: 2.5566106991128192

Epoch: 6| Step: 7
Training loss: 2.078375550274424
Validation loss: 2.5672004681853733

Epoch: 6| Step: 8
Training loss: 1.8242094705415084
Validation loss: 2.5608641402389174

Epoch: 6| Step: 9
Training loss: 1.9625938077240592
Validation loss: 2.562308847824626

Epoch: 6| Step: 10
Training loss: 2.0474788561277704
Validation loss: 2.576406073525148

Epoch: 6| Step: 11
Training loss: 1.5513765744219818
Validation loss: 2.5806568430692574

Epoch: 6| Step: 12
Training loss: 1.3227458403022117
Validation loss: 2.5999720656722007

Epoch: 6| Step: 13
Training loss: 1.6316574610891095
Validation loss: 2.60906702564549

Epoch: 257| Step: 0
Training loss: 1.7679215071329668
Validation loss: 2.647174966599799

Epoch: 6| Step: 1
Training loss: 1.7956010365837303
Validation loss: 2.620812937832262

Epoch: 6| Step: 2
Training loss: 1.2828871339374486
Validation loss: 2.643190272188691

Epoch: 6| Step: 3
Training loss: 1.7285772797531667
Validation loss: 2.6310834363137428

Epoch: 6| Step: 4
Training loss: 1.824093800090423
Validation loss: 2.6327430080813174

Epoch: 6| Step: 5
Training loss: 1.7209856924939617
Validation loss: 2.626489567260008

Epoch: 6| Step: 6
Training loss: 1.7362629006045913
Validation loss: 2.588785638654057

Epoch: 6| Step: 7
Training loss: 2.14495789777789
Validation loss: 2.5685064660386145

Epoch: 6| Step: 8
Training loss: 1.3456342925917144
Validation loss: 2.560352346866198

Epoch: 6| Step: 9
Training loss: 1.3960934391885933
Validation loss: 2.544118843791444

Epoch: 6| Step: 10
Training loss: 1.8983028034415577
Validation loss: 2.5689901972716482

Epoch: 6| Step: 11
Training loss: 1.5495925306208114
Validation loss: 2.566694955293025

Epoch: 6| Step: 12
Training loss: 1.816964340611648
Validation loss: 2.5753437113510893

Epoch: 6| Step: 13
Training loss: 1.9842893326657787
Validation loss: 2.56272416793783

Epoch: 258| Step: 0
Training loss: 1.4213581193715459
Validation loss: 2.6002466801791426

Epoch: 6| Step: 1
Training loss: 1.6970660023124717
Validation loss: 2.5775258511295958

Epoch: 6| Step: 2
Training loss: 1.4638609984650688
Validation loss: 2.5748703714603454

Epoch: 6| Step: 3
Training loss: 1.9242475797884049
Validation loss: 2.5746273683907077

Epoch: 6| Step: 4
Training loss: 1.413936124602585
Validation loss: 2.5761935419987623

Epoch: 6| Step: 5
Training loss: 1.9181210832254414
Validation loss: 2.571234979282692

Epoch: 6| Step: 6
Training loss: 2.117781552238788
Validation loss: 2.5749187978765615

Epoch: 6| Step: 7
Training loss: 1.5494348941750444
Validation loss: 2.585033420179223

Epoch: 6| Step: 8
Training loss: 1.5844103596671018
Validation loss: 2.566938054139216

Epoch: 6| Step: 9
Training loss: 1.723209145324404
Validation loss: 2.594788209249065

Epoch: 6| Step: 10
Training loss: 1.5327728639663467
Validation loss: 2.5955172430171918

Epoch: 6| Step: 11
Training loss: 1.437382403000271
Validation loss: 2.5869161426153036

Epoch: 6| Step: 12
Training loss: 1.853921345401334
Validation loss: 2.5995033119068105

Epoch: 6| Step: 13
Training loss: 1.9457817890384288
Validation loss: 2.5714963975475076

Epoch: 259| Step: 0
Training loss: 1.5461240544753816
Validation loss: 2.572546739818043

Epoch: 6| Step: 1
Training loss: 1.5883136856662499
Validation loss: 2.5782595641914803

Epoch: 6| Step: 2
Training loss: 1.636362988539288
Validation loss: 2.550470116454023

Epoch: 6| Step: 3
Training loss: 1.1800182459923825
Validation loss: 2.55786511453304

Epoch: 6| Step: 4
Training loss: 2.3465811351158608
Validation loss: 2.5754334660477416

Epoch: 6| Step: 5
Training loss: 1.4780233110285255
Validation loss: 2.5820526181238903

Epoch: 6| Step: 6
Training loss: 1.157296197140144
Validation loss: 2.5825206107998637

Epoch: 6| Step: 7
Training loss: 1.6688977408283712
Validation loss: 2.571099030403171

Epoch: 6| Step: 8
Training loss: 1.6537215167971293
Validation loss: 2.555633308627198

Epoch: 6| Step: 9
Training loss: 1.8866521535299476
Validation loss: 2.5416294033305213

Epoch: 6| Step: 10
Training loss: 1.4682232338238657
Validation loss: 2.5160288714871033

Epoch: 6| Step: 11
Training loss: 1.8096908636231503
Validation loss: 2.49066183302522

Epoch: 6| Step: 12
Training loss: 2.1205505462357235
Validation loss: 2.5081158316771837

Epoch: 6| Step: 13
Training loss: 1.8563546404902085
Validation loss: 2.506626116742204

Epoch: 260| Step: 0
Training loss: 1.750615692822122
Validation loss: 2.510661080649152

Epoch: 6| Step: 1
Training loss: 1.45435084658551
Validation loss: 2.533123963916639

Epoch: 6| Step: 2
Training loss: 1.7716875895535384
Validation loss: 2.582486599054329

Epoch: 6| Step: 3
Training loss: 1.7994524175824462
Validation loss: 2.571212197668077

Epoch: 6| Step: 4
Training loss: 1.454093856227481
Validation loss: 2.59337998800302

Epoch: 6| Step: 5
Training loss: 2.0482478306396947
Validation loss: 2.595029468657131

Epoch: 6| Step: 6
Training loss: 1.6473541315593394
Validation loss: 2.5792733030065866

Epoch: 6| Step: 7
Training loss: 1.490753443400353
Validation loss: 2.607754300366695

Epoch: 6| Step: 8
Training loss: 1.6613724864756727
Validation loss: 2.6096049249171456

Epoch: 6| Step: 9
Training loss: 1.3457634944136445
Validation loss: 2.6245401763937597

Epoch: 6| Step: 10
Training loss: 1.5080525893950056
Validation loss: 2.599687890203

Epoch: 6| Step: 11
Training loss: 1.8925022232062763
Validation loss: 2.5613541521054133

Epoch: 6| Step: 12
Training loss: 1.511684052613759
Validation loss: 2.5749365795882384

Epoch: 6| Step: 13
Training loss: 1.9092732204150593
Validation loss: 2.559531964327331

Epoch: 261| Step: 0
Training loss: 1.886413170372023
Validation loss: 2.5865333861202986

Epoch: 6| Step: 1
Training loss: 1.8155868158576547
Validation loss: 2.5781045027260165

Epoch: 6| Step: 2
Training loss: 1.700788031982021
Validation loss: 2.5580634561962796

Epoch: 6| Step: 3
Training loss: 1.6259036852568143
Validation loss: 2.579319986910605

Epoch: 6| Step: 4
Training loss: 2.023185684854252
Validation loss: 2.5646887035146615

Epoch: 6| Step: 5
Training loss: 1.685829890284257
Validation loss: 2.560080195341772

Epoch: 6| Step: 6
Training loss: 1.2978218942068445
Validation loss: 2.5545688087407634

Epoch: 6| Step: 7
Training loss: 1.5150991884501441
Validation loss: 2.583687263507907

Epoch: 6| Step: 8
Training loss: 1.4335633152529788
Validation loss: 2.586734704486687

Epoch: 6| Step: 9
Training loss: 1.9117857802424814
Validation loss: 2.607059063337572

Epoch: 6| Step: 10
Training loss: 1.5025078154755753
Validation loss: 2.610916260207094

Epoch: 6| Step: 11
Training loss: 1.9818097452027075
Validation loss: 2.6123335102136944

Epoch: 6| Step: 12
Training loss: 1.0935632273740323
Validation loss: 2.603372851726709

Epoch: 6| Step: 13
Training loss: 1.598681132821964
Validation loss: 2.614210640443173

Epoch: 262| Step: 0
Training loss: 2.1132462757763277
Validation loss: 2.59130602892941

Epoch: 6| Step: 1
Training loss: 1.1172971338217408
Validation loss: 2.6186250341262443

Epoch: 6| Step: 2
Training loss: 1.427821374582992
Validation loss: 2.5979425788614257

Epoch: 6| Step: 3
Training loss: 1.831423856014169
Validation loss: 2.6276080598607914

Epoch: 6| Step: 4
Training loss: 1.6596211367601874
Validation loss: 2.6130720286835922

Epoch: 6| Step: 5
Training loss: 1.4283526082706142
Validation loss: 2.6407817967077625

Epoch: 6| Step: 6
Training loss: 2.0055769412285085
Validation loss: 2.6480331971384166

Epoch: 6| Step: 7
Training loss: 1.8076772654074542
Validation loss: 2.644199114368433

Epoch: 6| Step: 8
Training loss: 1.49351450448389
Validation loss: 2.668966819964359

Epoch: 6| Step: 9
Training loss: 1.8857603304369002
Validation loss: 2.63240250953298

Epoch: 6| Step: 10
Training loss: 1.136024918793327
Validation loss: 2.6032286722177846

Epoch: 6| Step: 11
Training loss: 1.7906488440292505
Validation loss: 2.602698881564542

Epoch: 6| Step: 12
Training loss: 1.638664090998534
Validation loss: 2.6010928787143657

Epoch: 6| Step: 13
Training loss: 1.0202136332118668
Validation loss: 2.5924278711701487

Epoch: 263| Step: 0
Training loss: 1.5180809336863184
Validation loss: 2.585219707401931

Epoch: 6| Step: 1
Training loss: 1.4298526689353173
Validation loss: 2.567850357384788

Epoch: 6| Step: 2
Training loss: 1.5893305669612192
Validation loss: 2.5705946751111597

Epoch: 6| Step: 3
Training loss: 1.8075278912894557
Validation loss: 2.576576879321635

Epoch: 6| Step: 4
Training loss: 1.4950662376248967
Validation loss: 2.583336954845334

Epoch: 6| Step: 5
Training loss: 1.9139843360355584
Validation loss: 2.573478778483373

Epoch: 6| Step: 6
Training loss: 1.7958086913410336
Validation loss: 2.594477477231586

Epoch: 6| Step: 7
Training loss: 1.5327048105407912
Validation loss: 2.5648058499463136

Epoch: 6| Step: 8
Training loss: 1.6024799231403783
Validation loss: 2.570089207393743

Epoch: 6| Step: 9
Training loss: 1.1109432365172798
Validation loss: 2.5639905078759524

Epoch: 6| Step: 10
Training loss: 1.3994205365560295
Validation loss: 2.58501835038766

Epoch: 6| Step: 11
Training loss: 1.600944883771463
Validation loss: 2.6133879909184285

Epoch: 6| Step: 12
Training loss: 2.0133429331687456
Validation loss: 2.631625426647812

Epoch: 6| Step: 13
Training loss: 1.6133927498403564
Validation loss: 2.674133298227264

Epoch: 264| Step: 0
Training loss: 1.7084570894152686
Validation loss: 2.7042896740366293

Epoch: 6| Step: 1
Training loss: 1.3603619905771789
Validation loss: 2.7052691252918404

Epoch: 6| Step: 2
Training loss: 1.5127764803816681
Validation loss: 2.654594014251469

Epoch: 6| Step: 3
Training loss: 1.3100330237965376
Validation loss: 2.659942351885509

Epoch: 6| Step: 4
Training loss: 1.8868842200464313
Validation loss: 2.596241283963082

Epoch: 6| Step: 5
Training loss: 1.4393753589757223
Validation loss: 2.5438437905412905

Epoch: 6| Step: 6
Training loss: 1.5323564852401892
Validation loss: 2.5297167423622495

Epoch: 6| Step: 7
Training loss: 1.757883434983671
Validation loss: 2.5159500860791164

Epoch: 6| Step: 8
Training loss: 1.736799384273137
Validation loss: 2.505995456495382

Epoch: 6| Step: 9
Training loss: 1.9918041383977807
Validation loss: 2.4792765007669004

Epoch: 6| Step: 10
Training loss: 1.7947171730645262
Validation loss: 2.4924897977422065

Epoch: 6| Step: 11
Training loss: 1.8187150617566776
Validation loss: 2.505796431560727

Epoch: 6| Step: 12
Training loss: 1.4868993876935772
Validation loss: 2.509400691943188

Epoch: 6| Step: 13
Training loss: 0.8302579438157731
Validation loss: 2.5512057150040404

Epoch: 265| Step: 0
Training loss: 2.0739076887608725
Validation loss: 2.595180972193746

Epoch: 6| Step: 1
Training loss: 1.1545265343657924
Validation loss: 2.616062588273617

Epoch: 6| Step: 2
Training loss: 1.439330635397501
Validation loss: 2.6454381268898235

Epoch: 6| Step: 3
Training loss: 1.4762692437787062
Validation loss: 2.6891786074465656

Epoch: 6| Step: 4
Training loss: 1.7084128508630871
Validation loss: 2.672273062300531

Epoch: 6| Step: 5
Training loss: 1.293677098528438
Validation loss: 2.6616471704838034

Epoch: 6| Step: 6
Training loss: 1.458907078095898
Validation loss: 2.602546032730382

Epoch: 6| Step: 7
Training loss: 1.9757852345370248
Validation loss: 2.589832124795508

Epoch: 6| Step: 8
Training loss: 1.7165848011878673
Validation loss: 2.6090026839399183

Epoch: 6| Step: 9
Training loss: 1.5957455576901023
Validation loss: 2.6130181990462846

Epoch: 6| Step: 10
Training loss: 1.6864275173350842
Validation loss: 2.6159284986641183

Epoch: 6| Step: 11
Training loss: 1.4523789326149732
Validation loss: 2.581037245916185

Epoch: 6| Step: 12
Training loss: 1.3034046742035712
Validation loss: 2.5461593901951884

Epoch: 6| Step: 13
Training loss: 1.8524180178191663
Validation loss: 2.503179190984423

Epoch: 266| Step: 0
Training loss: 1.7116470607438259
Validation loss: 2.511735946220545

Epoch: 6| Step: 1
Training loss: 1.4318276318324956
Validation loss: 2.5044487573494725

Epoch: 6| Step: 2
Training loss: 1.856175466768656
Validation loss: 2.516164263401585

Epoch: 6| Step: 3
Training loss: 2.1876793924070324
Validation loss: 2.5292108551942483

Epoch: 6| Step: 4
Training loss: 1.6739694186280565
Validation loss: 2.5192599558228084

Epoch: 6| Step: 5
Training loss: 1.4167988472402353
Validation loss: 2.5056919581669983

Epoch: 6| Step: 6
Training loss: 1.4546497508066925
Validation loss: 2.5438068731937893

Epoch: 6| Step: 7
Training loss: 1.7404442520396934
Validation loss: 2.544068434435114

Epoch: 6| Step: 8
Training loss: 1.463711965117247
Validation loss: 2.574126690204939

Epoch: 6| Step: 9
Training loss: 1.356262106775488
Validation loss: 2.563308022673347

Epoch: 6| Step: 10
Training loss: 0.9651939590495868
Validation loss: 2.597134578708059

Epoch: 6| Step: 11
Training loss: 1.2249485744659077
Validation loss: 2.5799812264604816

Epoch: 6| Step: 12
Training loss: 1.5596546205247162
Validation loss: 2.610165906530267

Epoch: 6| Step: 13
Training loss: 1.5956771269493206
Validation loss: 2.6138104640321127

Epoch: 267| Step: 0
Training loss: 1.1614663789524649
Validation loss: 2.6166900171745913

Epoch: 6| Step: 1
Training loss: 1.2542281168503202
Validation loss: 2.601471694602686

Epoch: 6| Step: 2
Training loss: 1.4190732579263463
Validation loss: 2.6302236976690554

Epoch: 6| Step: 3
Training loss: 1.6044014680445329
Validation loss: 2.625928017432716

Epoch: 6| Step: 4
Training loss: 1.2110722620640935
Validation loss: 2.6105549535364743

Epoch: 6| Step: 5
Training loss: 1.8072062828569426
Validation loss: 2.6195969338082925

Epoch: 6| Step: 6
Training loss: 1.6657100634298205
Validation loss: 2.5985737707056606

Epoch: 6| Step: 7
Training loss: 2.1195648471912754
Validation loss: 2.5924563353861707

Epoch: 6| Step: 8
Training loss: 0.9858152661370294
Validation loss: 2.554617887945092

Epoch: 6| Step: 9
Training loss: 1.247061518053368
Validation loss: 2.5573815560390827

Epoch: 6| Step: 10
Training loss: 1.5942657234669144
Validation loss: 2.5630716676126926

Epoch: 6| Step: 11
Training loss: 1.6203491707076032
Validation loss: 2.5550647316715547

Epoch: 6| Step: 12
Training loss: 1.229424508847665
Validation loss: 2.5470336420751263

Epoch: 6| Step: 13
Training loss: 1.6429390709155853
Validation loss: 2.550118465756204

Epoch: 268| Step: 0
Training loss: 1.64089963521661
Validation loss: 2.522299066255719

Epoch: 6| Step: 1
Training loss: 1.1849851581593684
Validation loss: 2.537629306072262

Epoch: 6| Step: 2
Training loss: 1.5055810099596998
Validation loss: 2.5586387812548343

Epoch: 6| Step: 3
Training loss: 1.62477931945051
Validation loss: 2.5598154244494986

Epoch: 6| Step: 4
Training loss: 1.0964264411692564
Validation loss: 2.56416115090824

Epoch: 6| Step: 5
Training loss: 1.2460939413327636
Validation loss: 2.5691848506974955

Epoch: 6| Step: 6
Training loss: 1.8130387130450358
Validation loss: 2.576593768044763

Epoch: 6| Step: 7
Training loss: 1.4716862486634184
Validation loss: 2.6017131038157504

Epoch: 6| Step: 8
Training loss: 1.684062140290078
Validation loss: 2.5994741930836067

Epoch: 6| Step: 9
Training loss: 1.7226832381229906
Validation loss: 2.581328118581881

Epoch: 6| Step: 10
Training loss: 1.2660385680598851
Validation loss: 2.5754088332411134

Epoch: 6| Step: 11
Training loss: 1.5951881651666042
Validation loss: 2.5625468624220895

Epoch: 6| Step: 12
Training loss: 1.324213078579531
Validation loss: 2.563401350583156

Epoch: 6| Step: 13
Training loss: 1.1635348769183063
Validation loss: 2.539612604945488

Epoch: 269| Step: 0
Training loss: 1.5172993957554533
Validation loss: 2.5428259485449747

Epoch: 6| Step: 1
Training loss: 1.3056225652384392
Validation loss: 2.573648239564267

Epoch: 6| Step: 2
Training loss: 1.330496790753393
Validation loss: 2.5655459257472577

Epoch: 6| Step: 3
Training loss: 1.326880556401295
Validation loss: 2.5513499013240293

Epoch: 6| Step: 4
Training loss: 1.3392301438928103
Validation loss: 2.5631346398151713

Epoch: 6| Step: 5
Training loss: 1.7253293427908107
Validation loss: 2.588031576833571

Epoch: 6| Step: 6
Training loss: 1.509974219752651
Validation loss: 2.5908688771582744

Epoch: 6| Step: 7
Training loss: 1.5278144754953735
Validation loss: 2.578649323993173

Epoch: 6| Step: 8
Training loss: 1.1870890458410175
Validation loss: 2.5728576169796575

Epoch: 6| Step: 9
Training loss: 1.2899116262578991
Validation loss: 2.573757902132448

Epoch: 6| Step: 10
Training loss: 1.7521156057076144
Validation loss: 2.576033959430425

Epoch: 6| Step: 11
Training loss: 1.3757337866355808
Validation loss: 2.5711058924303045

Epoch: 6| Step: 12
Training loss: 1.6543117193751788
Validation loss: 2.577502320468604

Epoch: 6| Step: 13
Training loss: 1.4905454378467524
Validation loss: 2.5842190797594293

Epoch: 270| Step: 0
Training loss: 1.6832415218935788
Validation loss: 2.6112611126524707

Epoch: 6| Step: 1
Training loss: 1.6757254780200566
Validation loss: 2.626022006117847

Epoch: 6| Step: 2
Training loss: 1.3511744917981807
Validation loss: 2.6341794418977793

Epoch: 6| Step: 3
Training loss: 1.0184913681406087
Validation loss: 2.653645853943092

Epoch: 6| Step: 4
Training loss: 1.5066004808342846
Validation loss: 2.684722959435867

Epoch: 6| Step: 5
Training loss: 2.1258926760551624
Validation loss: 2.641481885124293

Epoch: 6| Step: 6
Training loss: 1.2040839398928387
Validation loss: 2.5758588984946598

Epoch: 6| Step: 7
Training loss: 1.340663381173844
Validation loss: 2.5220764120388846

Epoch: 6| Step: 8
Training loss: 1.6000363405392213
Validation loss: 2.4883445942505524

Epoch: 6| Step: 9
Training loss: 1.4249211473566115
Validation loss: 2.4711154214844115

Epoch: 6| Step: 10
Training loss: 1.3663464384254727
Validation loss: 2.456114720131318

Epoch: 6| Step: 11
Training loss: 1.244811639133406
Validation loss: 2.4687037299417702

Epoch: 6| Step: 12
Training loss: 1.3678773284114223
Validation loss: 2.4817750255412996

Epoch: 6| Step: 13
Training loss: 1.8134945081275848
Validation loss: 2.4951195922760343

Epoch: 271| Step: 0
Training loss: 1.551816503472372
Validation loss: 2.5205794996214816

Epoch: 6| Step: 1
Training loss: 0.965110958025376
Validation loss: 2.527516279931208

Epoch: 6| Step: 2
Training loss: 1.3288068031090952
Validation loss: 2.5560082743809898

Epoch: 6| Step: 3
Training loss: 1.044901795951942
Validation loss: 2.585434764172606

Epoch: 6| Step: 4
Training loss: 1.7997160634633829
Validation loss: 2.6163440337582493

Epoch: 6| Step: 5
Training loss: 1.4763204386264195
Validation loss: 2.641512340218397

Epoch: 6| Step: 6
Training loss: 1.6317639794455843
Validation loss: 2.6515128266609738

Epoch: 6| Step: 7
Training loss: 1.7481590533357907
Validation loss: 2.624968340556327

Epoch: 6| Step: 8
Training loss: 1.9344395492704067
Validation loss: 2.6024046169333372

Epoch: 6| Step: 9
Training loss: 1.2137276775692092
Validation loss: 2.5884762327346653

Epoch: 6| Step: 10
Training loss: 1.3221513031035215
Validation loss: 2.5665723394451825

Epoch: 6| Step: 11
Training loss: 1.4824936036459226
Validation loss: 2.5759175316297416

Epoch: 6| Step: 12
Training loss: 1.2750012678252256
Validation loss: 2.6064200541106537

Epoch: 6| Step: 13
Training loss: 1.2168350826038898
Validation loss: 2.5626156818600814

Epoch: 272| Step: 0
Training loss: 1.1809594579160858
Validation loss: 2.5491133320386994

Epoch: 6| Step: 1
Training loss: 1.2322975736827408
Validation loss: 2.561859938316844

Epoch: 6| Step: 2
Training loss: 1.2427515632590402
Validation loss: 2.5511825897307676

Epoch: 6| Step: 3
Training loss: 1.2075695331369265
Validation loss: 2.5593056065572353

Epoch: 6| Step: 4
Training loss: 1.6379163634963796
Validation loss: 2.5747856481810567

Epoch: 6| Step: 5
Training loss: 1.8478090251320278
Validation loss: 2.570421010305924

Epoch: 6| Step: 6
Training loss: 1.3989945479662378
Validation loss: 2.5684241754068085

Epoch: 6| Step: 7
Training loss: 1.1095846273596381
Validation loss: 2.586589329943777

Epoch: 6| Step: 8
Training loss: 1.341096698144852
Validation loss: 2.604757241174172

Epoch: 6| Step: 9
Training loss: 1.8685661557199418
Validation loss: 2.591770575707914

Epoch: 6| Step: 10
Training loss: 1.4013830522975017
Validation loss: 2.6369842111272415

Epoch: 6| Step: 11
Training loss: 1.5475641892390324
Validation loss: 2.629776075272323

Epoch: 6| Step: 12
Training loss: 1.2354126443952897
Validation loss: 2.6513550701222144

Epoch: 6| Step: 13
Training loss: 1.641483845027333
Validation loss: 2.66121568752278

Epoch: 273| Step: 0
Training loss: 1.0829877240972536
Validation loss: 2.6974864959964218

Epoch: 6| Step: 1
Training loss: 1.3886675827882857
Validation loss: 2.6754387394622996

Epoch: 6| Step: 2
Training loss: 1.652460765978837
Validation loss: 2.677444726328574

Epoch: 6| Step: 3
Training loss: 1.7892253418486934
Validation loss: 2.6606102583503963

Epoch: 6| Step: 4
Training loss: 1.266968332098119
Validation loss: 2.63379367430391

Epoch: 6| Step: 5
Training loss: 1.462587536531476
Validation loss: 2.5917071424542444

Epoch: 6| Step: 6
Training loss: 1.0125435666730647
Validation loss: 2.554261563094684

Epoch: 6| Step: 7
Training loss: 1.5459565798150943
Validation loss: 2.5480065131346716

Epoch: 6| Step: 8
Training loss: 1.0145950964233363
Validation loss: 2.5405816815735234

Epoch: 6| Step: 9
Training loss: 1.774881052679212
Validation loss: 2.5345264550446074

Epoch: 6| Step: 10
Training loss: 1.1248108916816166
Validation loss: 2.5621925787873527

Epoch: 6| Step: 11
Training loss: 1.3495498842854479
Validation loss: 2.555325542871748

Epoch: 6| Step: 12
Training loss: 1.5737523602020285
Validation loss: 2.579349946501226

Epoch: 6| Step: 13
Training loss: 1.4755898153076115
Validation loss: 2.572961616962092

Epoch: 274| Step: 0
Training loss: 1.3587408230777847
Validation loss: 2.576080593564408

Epoch: 6| Step: 1
Training loss: 1.7786856144654122
Validation loss: 2.592978801550302

Epoch: 6| Step: 2
Training loss: 1.069618334126317
Validation loss: 2.585989499217558

Epoch: 6| Step: 3
Training loss: 1.4960369368241424
Validation loss: 2.5998013493475463

Epoch: 6| Step: 4
Training loss: 1.1500679431415597
Validation loss: 2.6356390579115123

Epoch: 6| Step: 5
Training loss: 1.3539894232541096
Validation loss: 2.637020587181237

Epoch: 6| Step: 6
Training loss: 1.7160793015622817
Validation loss: 2.6571588224611205

Epoch: 6| Step: 7
Training loss: 0.8203409099200554
Validation loss: 2.6519598300549827

Epoch: 6| Step: 8
Training loss: 1.1641832839464328
Validation loss: 2.688017060662622

Epoch: 6| Step: 9
Training loss: 1.291476584363648
Validation loss: 2.673885193031516

Epoch: 6| Step: 10
Training loss: 1.243878443234293
Validation loss: 2.654565882172884

Epoch: 6| Step: 11
Training loss: 1.5749653827556536
Validation loss: 2.6294856578568826

Epoch: 6| Step: 12
Training loss: 1.6332543610275625
Validation loss: 2.60315986482614

Epoch: 6| Step: 13
Training loss: 1.47809597898225
Validation loss: 2.5448079314942875

Epoch: 275| Step: 0
Training loss: 1.4587415214756352
Validation loss: 2.556627190281352

Epoch: 6| Step: 1
Training loss: 1.5056593943998688
Validation loss: 2.5120816195833173

Epoch: 6| Step: 2
Training loss: 1.0973879123010204
Validation loss: 2.4981369347014915

Epoch: 6| Step: 3
Training loss: 1.6345868121105356
Validation loss: 2.46356523409688

Epoch: 6| Step: 4
Training loss: 1.0389287762172665
Validation loss: 2.5200907892353834

Epoch: 6| Step: 5
Training loss: 1.5317248950941218
Validation loss: 2.545039809400945

Epoch: 6| Step: 6
Training loss: 0.8893912620961011
Validation loss: 2.5697319052510665

Epoch: 6| Step: 7
Training loss: 1.627405440341969
Validation loss: 2.592550317292972

Epoch: 6| Step: 8
Training loss: 1.3566001106185677
Validation loss: 2.647902279477948

Epoch: 6| Step: 9
Training loss: 1.43647074132719
Validation loss: 2.657926241188405

Epoch: 6| Step: 10
Training loss: 1.3189955243258138
Validation loss: 2.6894287796497984

Epoch: 6| Step: 11
Training loss: 1.4706900749286134
Validation loss: 2.705704510440723

Epoch: 6| Step: 12
Training loss: 1.7666151932949121
Validation loss: 2.6772493911275226

Epoch: 6| Step: 13
Training loss: 1.1588015369365587
Validation loss: 2.6956578491638297

Epoch: 276| Step: 0
Training loss: 1.3285987009231899
Validation loss: 2.639568391970937

Epoch: 6| Step: 1
Training loss: 1.4705251963511667
Validation loss: 2.6190098272893656

Epoch: 6| Step: 2
Training loss: 1.5838419030553212
Validation loss: 2.6095243945064386

Epoch: 6| Step: 3
Training loss: 0.723795554616642
Validation loss: 2.5875044627025074

Epoch: 6| Step: 4
Training loss: 1.1661783740586473
Validation loss: 2.5765807657078126

Epoch: 6| Step: 5
Training loss: 1.3247818551337844
Validation loss: 2.539691930203765

Epoch: 6| Step: 6
Training loss: 1.4235578366781154
Validation loss: 2.556237712186417

Epoch: 6| Step: 7
Training loss: 1.1554539491893239
Validation loss: 2.558702590958209

Epoch: 6| Step: 8
Training loss: 1.7703151692760037
Validation loss: 2.5572110681271982

Epoch: 6| Step: 9
Training loss: 1.2818156133665353
Validation loss: 2.60029818621073

Epoch: 6| Step: 10
Training loss: 1.5419731694619645
Validation loss: 2.619047922236395

Epoch: 6| Step: 11
Training loss: 1.1834489085390694
Validation loss: 2.6199311315288027

Epoch: 6| Step: 12
Training loss: 1.4164590496441638
Validation loss: 2.6334367816907585

Epoch: 6| Step: 13
Training loss: 1.7692219377539684
Validation loss: 2.664326433712083

Epoch: 277| Step: 0
Training loss: 1.6153678054773335
Validation loss: 2.6408116196479

Epoch: 6| Step: 1
Training loss: 1.1646180331406752
Validation loss: 2.62946803346447

Epoch: 6| Step: 2
Training loss: 1.642430211504984
Validation loss: 2.593793136014611

Epoch: 6| Step: 3
Training loss: 1.542013833761936
Validation loss: 2.5458889961417692

Epoch: 6| Step: 4
Training loss: 1.0765464393956896
Validation loss: 2.533767480341948

Epoch: 6| Step: 5
Training loss: 1.2946321787652169
Validation loss: 2.5289294109395004

Epoch: 6| Step: 6
Training loss: 1.035264149926327
Validation loss: 2.5371202313297783

Epoch: 6| Step: 7
Training loss: 0.6766035776684762
Validation loss: 2.5107810490796405

Epoch: 6| Step: 8
Training loss: 1.2721415284972115
Validation loss: 2.5506355510243703

Epoch: 6| Step: 9
Training loss: 1.2480232343986781
Validation loss: 2.5429365894722458

Epoch: 6| Step: 10
Training loss: 1.5012943723094019
Validation loss: 2.56762504746249

Epoch: 6| Step: 11
Training loss: 1.621315814515466
Validation loss: 2.6194476772692306

Epoch: 6| Step: 12
Training loss: 1.8204399358976888
Validation loss: 2.671931215040422

Epoch: 6| Step: 13
Training loss: 1.1735879712704669
Validation loss: 2.6806432791220884

Epoch: 278| Step: 0
Training loss: 1.1598391115490783
Validation loss: 2.650845795271517

Epoch: 6| Step: 1
Training loss: 0.9505507930406173
Validation loss: 2.6122593693467615

Epoch: 6| Step: 2
Training loss: 1.5001427264657408
Validation loss: 2.573231831266078

Epoch: 6| Step: 3
Training loss: 1.4099112850038173
Validation loss: 2.508292294538124

Epoch: 6| Step: 4
Training loss: 0.8925104428596653
Validation loss: 2.51228062416781

Epoch: 6| Step: 5
Training loss: 1.2378609602874566
Validation loss: 2.4852274090663604

Epoch: 6| Step: 6
Training loss: 1.217100445397339
Validation loss: 2.4977100847017666

Epoch: 6| Step: 7
Training loss: 1.6757313114007966
Validation loss: 2.4824195451881153

Epoch: 6| Step: 8
Training loss: 1.8205665771245951
Validation loss: 2.492619193709927

Epoch: 6| Step: 9
Training loss: 1.2687189408432793
Validation loss: 2.523924427782284

Epoch: 6| Step: 10
Training loss: 1.6928403910451313
Validation loss: 2.529466250439512

Epoch: 6| Step: 11
Training loss: 1.437755727826514
Validation loss: 2.5818615909576073

Epoch: 6| Step: 12
Training loss: 0.9268507433525562
Validation loss: 2.547549142101189

Epoch: 6| Step: 13
Training loss: 1.8424459468619845
Validation loss: 2.5713761781170303

Epoch: 279| Step: 0
Training loss: 1.858537180658229
Validation loss: 2.5799176330150058

Epoch: 6| Step: 1
Training loss: 1.123044752036037
Validation loss: 2.5915752485242862

Epoch: 6| Step: 2
Training loss: 1.508760934709495
Validation loss: 2.617819758035777

Epoch: 6| Step: 3
Training loss: 1.149038767254423
Validation loss: 2.635180304694615

Epoch: 6| Step: 4
Training loss: 1.1371073369984528
Validation loss: 2.61108757038395

Epoch: 6| Step: 5
Training loss: 1.558465020162607
Validation loss: 2.6387449220577683

Epoch: 6| Step: 6
Training loss: 1.9444960753837013
Validation loss: 2.5720995224464276

Epoch: 6| Step: 7
Training loss: 1.1117850438696673
Validation loss: 2.5872284322905292

Epoch: 6| Step: 8
Training loss: 0.8303985336347727
Validation loss: 2.5873766036985213

Epoch: 6| Step: 9
Training loss: 1.235387073353247
Validation loss: 2.546715067085853

Epoch: 6| Step: 10
Training loss: 1.4531244257443843
Validation loss: 2.544539601276842

Epoch: 6| Step: 11
Training loss: 1.070709377689468
Validation loss: 2.535316356934484

Epoch: 6| Step: 12
Training loss: 1.0291207034288796
Validation loss: 2.54589165756914

Epoch: 6| Step: 13
Training loss: 1.3566781401012373
Validation loss: 2.549656977052547

Epoch: 280| Step: 0
Training loss: 1.2483344425829723
Validation loss: 2.538751389443465

Epoch: 6| Step: 1
Training loss: 1.4449586177299003
Validation loss: 2.5763078427751527

Epoch: 6| Step: 2
Training loss: 0.9647546333207659
Validation loss: 2.5672632886840874

Epoch: 6| Step: 3
Training loss: 1.013529214393727
Validation loss: 2.574869155785184

Epoch: 6| Step: 4
Training loss: 1.2960215138545268
Validation loss: 2.5686605030462575

Epoch: 6| Step: 5
Training loss: 1.084420880932848
Validation loss: 2.567136612059749

Epoch: 6| Step: 6
Training loss: 0.8826081030881032
Validation loss: 2.56843742415152

Epoch: 6| Step: 7
Training loss: 1.5445186508351751
Validation loss: 2.559822848015461

Epoch: 6| Step: 8
Training loss: 1.1531606591146246
Validation loss: 2.571734075214348

Epoch: 6| Step: 9
Training loss: 1.754204399748097
Validation loss: 2.585562696397766

Epoch: 6| Step: 10
Training loss: 1.050486867289679
Validation loss: 2.5692571353532028

Epoch: 6| Step: 11
Training loss: 1.4029632305185813
Validation loss: 2.5852001906074187

Epoch: 6| Step: 12
Training loss: 1.4954944336486908
Validation loss: 2.6144655769270666

Epoch: 6| Step: 13
Training loss: 0.9282991958678787
Validation loss: 2.605707882189228

Epoch: 281| Step: 0
Training loss: 0.8187011878918596
Validation loss: 2.6187555798857747

Epoch: 6| Step: 1
Training loss: 1.5233019646239698
Validation loss: 2.6184989306640096

Epoch: 6| Step: 2
Training loss: 0.8476438037995748
Validation loss: 2.631694701619529

Epoch: 6| Step: 3
Training loss: 1.4203474621723942
Validation loss: 2.6180912030373755

Epoch: 6| Step: 4
Training loss: 1.2760680942004532
Validation loss: 2.607189999429037

Epoch: 6| Step: 5
Training loss: 1.5770938639455103
Validation loss: 2.593434828245664

Epoch: 6| Step: 6
Training loss: 1.1618563849490289
Validation loss: 2.589938886835807

Epoch: 6| Step: 7
Training loss: 1.1779871427388104
Validation loss: 2.5664092747351797

Epoch: 6| Step: 8
Training loss: 1.3990851239966933
Validation loss: 2.552961595574078

Epoch: 6| Step: 9
Training loss: 0.6619765111798425
Validation loss: 2.568510711976242

Epoch: 6| Step: 10
Training loss: 1.4805222151872919
Validation loss: 2.5455880888840365

Epoch: 6| Step: 11
Training loss: 1.3514394538744248
Validation loss: 2.5447129167478124

Epoch: 6| Step: 12
Training loss: 1.2934342667105374
Validation loss: 2.5718524178738966

Epoch: 6| Step: 13
Training loss: 1.647114733740779
Validation loss: 2.592563242505259

Epoch: 282| Step: 0
Training loss: 1.0012233522943341
Validation loss: 2.593230142892599

Epoch: 6| Step: 1
Training loss: 1.427627914362943
Validation loss: 2.6117651229495618

Epoch: 6| Step: 2
Training loss: 1.264355293380573
Validation loss: 2.6179531886847776

Epoch: 6| Step: 3
Training loss: 1.0709329185243135
Validation loss: 2.5999779078710077

Epoch: 6| Step: 4
Training loss: 1.1450883986985658
Validation loss: 2.6366571890915

Epoch: 6| Step: 5
Training loss: 0.6426951293166021
Validation loss: 2.596492189039567

Epoch: 6| Step: 6
Training loss: 1.5000381464876047
Validation loss: 2.5840115373099204

Epoch: 6| Step: 7
Training loss: 1.0448434960747341
Validation loss: 2.571655373468524

Epoch: 6| Step: 8
Training loss: 0.8036115545517815
Validation loss: 2.594780258832255

Epoch: 6| Step: 9
Training loss: 1.503789168915553
Validation loss: 2.5697846463943685

Epoch: 6| Step: 10
Training loss: 1.7068296265411778
Validation loss: 2.5940989756102653

Epoch: 6| Step: 11
Training loss: 1.302657049306263
Validation loss: 2.5856619834571575

Epoch: 6| Step: 12
Training loss: 1.129455538370647
Validation loss: 2.5953515578123834

Epoch: 6| Step: 13
Training loss: 1.2917676804124187
Validation loss: 2.5867160702816556

Epoch: 283| Step: 0
Training loss: 1.271311195873591
Validation loss: 2.5564584009617337

Epoch: 6| Step: 1
Training loss: 1.1518317685472423
Validation loss: 2.5574527739269746

Epoch: 6| Step: 2
Training loss: 1.228816785423552
Validation loss: 2.540806125535057

Epoch: 6| Step: 3
Training loss: 1.5173778033508354
Validation loss: 2.5323615824377055

Epoch: 6| Step: 4
Training loss: 1.2054448736648327
Validation loss: 2.5206546569272197

Epoch: 6| Step: 5
Training loss: 1.0556933092835206
Validation loss: 2.5273692184645706

Epoch: 6| Step: 6
Training loss: 1.4398275688036268
Validation loss: 2.5244840402833955

Epoch: 6| Step: 7
Training loss: 1.2803195738463156
Validation loss: 2.5442737159448594

Epoch: 6| Step: 8
Training loss: 1.105565043322961
Validation loss: 2.572242417971573

Epoch: 6| Step: 9
Training loss: 1.2417322440186416
Validation loss: 2.6005645033042497

Epoch: 6| Step: 10
Training loss: 1.142291641184331
Validation loss: 2.6092726134914432

Epoch: 6| Step: 11
Training loss: 1.2986876447613185
Validation loss: 2.6332704064254786

Epoch: 6| Step: 12
Training loss: 1.0816262929951195
Validation loss: 2.6451408081302157

Epoch: 6| Step: 13
Training loss: 1.329307209504944
Validation loss: 2.6499839403776817

Epoch: 284| Step: 0
Training loss: 1.3436809344618124
Validation loss: 2.620874325086896

Epoch: 6| Step: 1
Training loss: 1.4799927925243663
Validation loss: 2.6090040743373124

Epoch: 6| Step: 2
Training loss: 1.3657956258996748
Validation loss: 2.6092112333042157

Epoch: 6| Step: 3
Training loss: 1.1002905245241112
Validation loss: 2.6118789653795433

Epoch: 6| Step: 4
Training loss: 1.3345299159584751
Validation loss: 2.575730361128982

Epoch: 6| Step: 5
Training loss: 0.9702040312212045
Validation loss: 2.545520369123189

Epoch: 6| Step: 6
Training loss: 1.3570147226191358
Validation loss: 2.5366829120397743

Epoch: 6| Step: 7
Training loss: 1.0747778529914658
Validation loss: 2.531659316888738

Epoch: 6| Step: 8
Training loss: 0.953984826403133
Validation loss: 2.5145230272933285

Epoch: 6| Step: 9
Training loss: 1.6202740538697626
Validation loss: 2.5346569547530193

Epoch: 6| Step: 10
Training loss: 1.1377173163778795
Validation loss: 2.5131508373358

Epoch: 6| Step: 11
Training loss: 0.5873495254171761
Validation loss: 2.5482929690552836

Epoch: 6| Step: 12
Training loss: 0.967134667156805
Validation loss: 2.584943885256836

Epoch: 6| Step: 13
Training loss: 1.047240520832347
Validation loss: 2.5857860715530268

Epoch: 285| Step: 0
Training loss: 1.5618484664562151
Validation loss: 2.5875780229068726

Epoch: 6| Step: 1
Training loss: 1.1428615642359903
Validation loss: 2.5718330528303266

Epoch: 6| Step: 2
Training loss: 1.2289447368553668
Validation loss: 2.5495306780296105

Epoch: 6| Step: 3
Training loss: 1.0007733096806086
Validation loss: 2.580721449429389

Epoch: 6| Step: 4
Training loss: 1.3882886999098873
Validation loss: 2.5700964770972514

Epoch: 6| Step: 5
Training loss: 0.9852528971639384
Validation loss: 2.5569018529727265

Epoch: 6| Step: 6
Training loss: 1.148711191378991
Validation loss: 2.551787528063459

Epoch: 6| Step: 7
Training loss: 1.2794290488883004
Validation loss: 2.5168176900149106

Epoch: 6| Step: 8
Training loss: 1.2210222239178408
Validation loss: 2.5221848996495617

Epoch: 6| Step: 9
Training loss: 1.178526856871817
Validation loss: 2.5055426252888653

Epoch: 6| Step: 10
Training loss: 0.8807655166051767
Validation loss: 2.536592480520618

Epoch: 6| Step: 11
Training loss: 1.0779033377734717
Validation loss: 2.5302731497548216

Epoch: 6| Step: 12
Training loss: 1.251487752561121
Validation loss: 2.549988929230676

Epoch: 6| Step: 13
Training loss: 0.9232771926354324
Validation loss: 2.5575747293901956

Epoch: 286| Step: 0
Training loss: 0.8324940070661139
Validation loss: 2.552518866122181

Epoch: 6| Step: 1
Training loss: 1.3002043123350642
Validation loss: 2.575412259510793

Epoch: 6| Step: 2
Training loss: 1.3007358852414688
Validation loss: 2.5617953356300287

Epoch: 6| Step: 3
Training loss: 1.1856050932665418
Validation loss: 2.552910400807217

Epoch: 6| Step: 4
Training loss: 1.0962918853587498
Validation loss: 2.5263756221192812

Epoch: 6| Step: 5
Training loss: 0.9748731114887328
Validation loss: 2.535074943319292

Epoch: 6| Step: 6
Training loss: 0.9972758739765105
Validation loss: 2.5303082220035296

Epoch: 6| Step: 7
Training loss: 1.1351779838523972
Validation loss: 2.542175440414243

Epoch: 6| Step: 8
Training loss: 1.015359579763569
Validation loss: 2.537134262440716

Epoch: 6| Step: 9
Training loss: 1.11341584044574
Validation loss: 2.522084278566577

Epoch: 6| Step: 10
Training loss: 1.101377106344711
Validation loss: 2.5274948275552234

Epoch: 6| Step: 11
Training loss: 1.2993059469703037
Validation loss: 2.515499152860658

Epoch: 6| Step: 12
Training loss: 1.5293299256086976
Validation loss: 2.5604192898575158

Epoch: 6| Step: 13
Training loss: 1.3566345566191795
Validation loss: 2.529916688391318

Epoch: 287| Step: 0
Training loss: 1.0605800335444282
Validation loss: 2.555033723756192

Epoch: 6| Step: 1
Training loss: 0.7670997118785617
Validation loss: 2.5716138748701725

Epoch: 6| Step: 2
Training loss: 1.0073325026925493
Validation loss: 2.512650368976847

Epoch: 6| Step: 3
Training loss: 1.3262240999301262
Validation loss: 2.517547715432206

Epoch: 6| Step: 4
Training loss: 1.1877242428719357
Validation loss: 2.516557659569219

Epoch: 6| Step: 5
Training loss: 1.2468257655316182
Validation loss: 2.5585392932158117

Epoch: 6| Step: 6
Training loss: 1.2331790683684873
Validation loss: 2.5184880751438645

Epoch: 6| Step: 7
Training loss: 1.0793365636894638
Validation loss: 2.556726790827399

Epoch: 6| Step: 8
Training loss: 1.3201974220461064
Validation loss: 2.5421548408527026

Epoch: 6| Step: 9
Training loss: 1.002175170803567
Validation loss: 2.5599989682449933

Epoch: 6| Step: 10
Training loss: 0.8207467519211907
Validation loss: 2.594126464865979

Epoch: 6| Step: 11
Training loss: 1.0462828142678493
Validation loss: 2.577751495064446

Epoch: 6| Step: 12
Training loss: 1.2522889637519954
Validation loss: 2.556330273801927

Epoch: 6| Step: 13
Training loss: 1.5662900353602376
Validation loss: 2.53638583494052

Epoch: 288| Step: 0
Training loss: 1.27302741252095
Validation loss: 2.528707904209511

Epoch: 6| Step: 1
Training loss: 1.2501255449191442
Validation loss: 2.5505245284141145

Epoch: 6| Step: 2
Training loss: 1.2484626853417262
Validation loss: 2.5580070027607156

Epoch: 6| Step: 3
Training loss: 0.7511480604375116
Validation loss: 2.538964241089142

Epoch: 6| Step: 4
Training loss: 1.1897977383008407
Validation loss: 2.503122746668326

Epoch: 6| Step: 5
Training loss: 1.1747067633427244
Validation loss: 2.5005705869351846

Epoch: 6| Step: 6
Training loss: 1.1792819102735002
Validation loss: 2.490448645377879

Epoch: 6| Step: 7
Training loss: 1.0435816075063673
Validation loss: 2.5024032321742467

Epoch: 6| Step: 8
Training loss: 0.8839283870239946
Validation loss: 2.5055038205912235

Epoch: 6| Step: 9
Training loss: 1.559907440838643
Validation loss: 2.4977890225750006

Epoch: 6| Step: 10
Training loss: 0.6102134609386838
Validation loss: 2.551490149874371

Epoch: 6| Step: 11
Training loss: 1.1470531501960555
Validation loss: 2.5737161017545587

Epoch: 6| Step: 12
Training loss: 1.3272207435520544
Validation loss: 2.557586430549953

Epoch: 6| Step: 13
Training loss: 1.1017445623489994
Validation loss: 2.5335547132161955

Epoch: 289| Step: 0
Training loss: 0.9945987327916633
Validation loss: 2.527357120773029

Epoch: 6| Step: 1
Training loss: 1.7735542561416466
Validation loss: 2.534357244811419

Epoch: 6| Step: 2
Training loss: 1.104193986998556
Validation loss: 2.5373163920728405

Epoch: 6| Step: 3
Training loss: 1.0094288129604552
Validation loss: 2.5402445611401028

Epoch: 6| Step: 4
Training loss: 1.0059140681239358
Validation loss: 2.554453435880507

Epoch: 6| Step: 5
Training loss: 1.1781879519534113
Validation loss: 2.544981017152037

Epoch: 6| Step: 6
Training loss: 1.2759791560010187
Validation loss: 2.5691035632038295

Epoch: 6| Step: 7
Training loss: 1.0293851810917674
Validation loss: 2.5781999051973266

Epoch: 6| Step: 8
Training loss: 1.1618147276152557
Validation loss: 2.600563749658821

Epoch: 6| Step: 9
Training loss: 0.8000420857326703
Validation loss: 2.580419850159385

Epoch: 6| Step: 10
Training loss: 0.9160733072627579
Validation loss: 2.6273860937046627

Epoch: 6| Step: 11
Training loss: 1.2709090986752916
Validation loss: 2.572606581230166

Epoch: 6| Step: 12
Training loss: 1.3911005557152025
Validation loss: 2.5620763144798047

Epoch: 6| Step: 13
Training loss: 0.8617812714155334
Validation loss: 2.5753579114878256

Epoch: 290| Step: 0
Training loss: 1.1434031580761435
Validation loss: 2.5071100086706983

Epoch: 6| Step: 1
Training loss: 0.990663243707782
Validation loss: 2.5063288268765915

Epoch: 6| Step: 2
Training loss: 1.519670887000657
Validation loss: 2.475944301362618

Epoch: 6| Step: 3
Training loss: 1.1740145162403046
Validation loss: 2.4628922420488366

Epoch: 6| Step: 4
Training loss: 1.603224473510612
Validation loss: 2.4724604018072327

Epoch: 6| Step: 5
Training loss: 1.0721673416648703
Validation loss: 2.4690974198635374

Epoch: 6| Step: 6
Training loss: 1.2074572357755808
Validation loss: 2.5100611596377234

Epoch: 6| Step: 7
Training loss: 1.1562623719249416
Validation loss: 2.5271642320390524

Epoch: 6| Step: 8
Training loss: 1.0949963688899065
Validation loss: 2.5465880936423204

Epoch: 6| Step: 9
Training loss: 0.9212976037592496
Validation loss: 2.5571489084782684

Epoch: 6| Step: 10
Training loss: 1.028236958167583
Validation loss: 2.594463998821683

Epoch: 6| Step: 11
Training loss: 1.0178884080755393
Validation loss: 2.56767543665237

Epoch: 6| Step: 12
Training loss: 1.1684976356296344
Validation loss: 2.600258509245444

Epoch: 6| Step: 13
Training loss: 0.7692413946023109
Validation loss: 2.610975557039368

Epoch: 291| Step: 0
Training loss: 1.0861326632322097
Validation loss: 2.613903727198044

Epoch: 6| Step: 1
Training loss: 1.214013113148991
Validation loss: 2.6005309542879633

Epoch: 6| Step: 2
Training loss: 1.3058180336622935
Validation loss: 2.5876689918915328

Epoch: 6| Step: 3
Training loss: 1.2197790447638637
Validation loss: 2.6155879371167496

Epoch: 6| Step: 4
Training loss: 0.7164416355392073
Validation loss: 2.6003340314089

Epoch: 6| Step: 5
Training loss: 1.3830440779920958
Validation loss: 2.559893865791853

Epoch: 6| Step: 6
Training loss: 1.124468253882095
Validation loss: 2.5459454443898113

Epoch: 6| Step: 7
Training loss: 1.058604110160328
Validation loss: 2.567200182581942

Epoch: 6| Step: 8
Training loss: 0.9615922883446529
Validation loss: 2.5475614191324243

Epoch: 6| Step: 9
Training loss: 1.2293686566094646
Validation loss: 2.5548094800954746

Epoch: 6| Step: 10
Training loss: 0.9407519524153847
Validation loss: 2.5487437480884094

Epoch: 6| Step: 11
Training loss: 1.1352885579389
Validation loss: 2.5236492499275363

Epoch: 6| Step: 12
Training loss: 0.9696100170713369
Validation loss: 2.520755011666349

Epoch: 6| Step: 13
Training loss: 0.9059838528994199
Validation loss: 2.5330021004000187

Epoch: 292| Step: 0
Training loss: 0.8455004019620674
Validation loss: 2.5437314404943363

Epoch: 6| Step: 1
Training loss: 0.8482243967529209
Validation loss: 2.519586274141677

Epoch: 6| Step: 2
Training loss: 0.9931311737886542
Validation loss: 2.5492344319113944

Epoch: 6| Step: 3
Training loss: 1.256756119761185
Validation loss: 2.542060470198152

Epoch: 6| Step: 4
Training loss: 0.4868840789438121
Validation loss: 2.582011189825823

Epoch: 6| Step: 5
Training loss: 1.060705801786299
Validation loss: 2.559156056310851

Epoch: 6| Step: 6
Training loss: 1.363830980227005
Validation loss: 2.584483822985325

Epoch: 6| Step: 7
Training loss: 1.2246216403766745
Validation loss: 2.5682708134801873

Epoch: 6| Step: 8
Training loss: 0.8940747024679424
Validation loss: 2.5519511614073265

Epoch: 6| Step: 9
Training loss: 1.0884741924978123
Validation loss: 2.5090536438203657

Epoch: 6| Step: 10
Training loss: 1.186828172271168
Validation loss: 2.5613520041888096

Epoch: 6| Step: 11
Training loss: 1.2524864738937032
Validation loss: 2.5451616142783573

Epoch: 6| Step: 12
Training loss: 0.5116768157316923
Validation loss: 2.5156111159209336

Epoch: 6| Step: 13
Training loss: 1.534218227356471
Validation loss: 2.554209751016766

Epoch: 293| Step: 0
Training loss: 1.0201661920727634
Validation loss: 2.5613990492555536

Epoch: 6| Step: 1
Training loss: 0.9544513416546837
Validation loss: 2.517563470654463

Epoch: 6| Step: 2
Training loss: 0.9836730270615313
Validation loss: 2.5070023698768935

Epoch: 6| Step: 3
Training loss: 1.2751186016495506
Validation loss: 2.522930873499147

Epoch: 6| Step: 4
Training loss: 0.8979391955199489
Validation loss: 2.5180861109680404

Epoch: 6| Step: 5
Training loss: 1.1394799115233487
Validation loss: 2.463435363106318

Epoch: 6| Step: 6
Training loss: 0.5872447372402079
Validation loss: 2.5156382256758096

Epoch: 6| Step: 7
Training loss: 1.062988449468148
Validation loss: 2.4885132080179377

Epoch: 6| Step: 8
Training loss: 1.0126741236030643
Validation loss: 2.495986647831411

Epoch: 6| Step: 9
Training loss: 1.1744672460296455
Validation loss: 2.4887440442764492

Epoch: 6| Step: 10
Training loss: 1.3170919471916824
Validation loss: 2.514195991781254

Epoch: 6| Step: 11
Training loss: 1.0048439604103985
Validation loss: 2.5085601934080857

Epoch: 6| Step: 12
Training loss: 1.2085952748915971
Validation loss: 2.5167816846515043

Epoch: 6| Step: 13
Training loss: 0.8672398388163697
Validation loss: 2.5483136392173606

Epoch: 294| Step: 0
Training loss: 1.1219420197851502
Validation loss: 2.5471697526719654

Epoch: 6| Step: 1
Training loss: 0.8462190529983955
Validation loss: 2.5988017954139897

Epoch: 6| Step: 2
Training loss: 1.1324770200473666
Validation loss: 2.614082859350028

Epoch: 6| Step: 3
Training loss: 1.196133699254523
Validation loss: 2.5808037408242996

Epoch: 6| Step: 4
Training loss: 1.1144269435413183
Validation loss: 2.602503972681875

Epoch: 6| Step: 5
Training loss: 1.1286790876619515
Validation loss: 2.565917719970983

Epoch: 6| Step: 6
Training loss: 1.1528832158864384
Validation loss: 2.52043163672362

Epoch: 6| Step: 7
Training loss: 0.7290785917949885
Validation loss: 2.5220359395400864

Epoch: 6| Step: 8
Training loss: 0.8813542838653161
Validation loss: 2.5166677745394788

Epoch: 6| Step: 9
Training loss: 1.0022882269260647
Validation loss: 2.4793199616052117

Epoch: 6| Step: 10
Training loss: 1.3441405505019868
Validation loss: 2.480880195975337

Epoch: 6| Step: 11
Training loss: 1.352428930322696
Validation loss: 2.488601389662323

Epoch: 6| Step: 12
Training loss: 1.121019367581569
Validation loss: 2.502025864253744

Epoch: 6| Step: 13
Training loss: 0.9324819416823689
Validation loss: 2.483344030993816

Epoch: 295| Step: 0
Training loss: 0.904625456005117
Validation loss: 2.486600224344815

Epoch: 6| Step: 1
Training loss: 0.7636617284232424
Validation loss: 2.5275844201925994

Epoch: 6| Step: 2
Training loss: 1.0829891000271368
Validation loss: 2.5001953817744114

Epoch: 6| Step: 3
Training loss: 0.9878419947844385
Validation loss: 2.5261153881570833

Epoch: 6| Step: 4
Training loss: 1.0806964670159707
Validation loss: 2.546038245255898

Epoch: 6| Step: 5
Training loss: 0.8100652159821993
Validation loss: 2.5565529922212753

Epoch: 6| Step: 6
Training loss: 1.0692233370368005
Validation loss: 2.589296166401766

Epoch: 6| Step: 7
Training loss: 0.9266652260970392
Validation loss: 2.5478185207881885

Epoch: 6| Step: 8
Training loss: 1.2848407856757302
Validation loss: 2.569803017300905

Epoch: 6| Step: 9
Training loss: 0.583483554593629
Validation loss: 2.5644473208329326

Epoch: 6| Step: 10
Training loss: 1.1320037059184094
Validation loss: 2.5219226728607174

Epoch: 6| Step: 11
Training loss: 1.327413570370666
Validation loss: 2.5362417288571115

Epoch: 6| Step: 12
Training loss: 1.0468667442793353
Validation loss: 2.492234059265128

Epoch: 6| Step: 13
Training loss: 0.9783926941789923
Validation loss: 2.510963357608407

Epoch: 296| Step: 0
Training loss: 1.090306829698534
Validation loss: 2.5102908733067553

Epoch: 6| Step: 1
Training loss: 1.0280917965243612
Validation loss: 2.491917950515109

Epoch: 6| Step: 2
Training loss: 1.036602176416384
Validation loss: 2.5228425844785276

Epoch: 6| Step: 3
Training loss: 1.1059471146768438
Validation loss: 2.4996502877793962

Epoch: 6| Step: 4
Training loss: 0.8586811385662854
Validation loss: 2.508586708964127

Epoch: 6| Step: 5
Training loss: 1.0251012775349548
Validation loss: 2.5144987097708302

Epoch: 6| Step: 6
Training loss: 0.9909677291681529
Validation loss: 2.498210215043571

Epoch: 6| Step: 7
Training loss: 0.7945310864593728
Validation loss: 2.492833426731687

Epoch: 6| Step: 8
Training loss: 0.9467268522589216
Validation loss: 2.5034934733214405

Epoch: 6| Step: 9
Training loss: 0.9068389491586426
Validation loss: 2.5234669415345

Epoch: 6| Step: 10
Training loss: 0.9729059350826172
Validation loss: 2.529043943125926

Epoch: 6| Step: 11
Training loss: 0.9798770045928947
Validation loss: 2.509001251712283

Epoch: 6| Step: 12
Training loss: 1.1482819951452499
Validation loss: 2.5590734875435497

Epoch: 6| Step: 13
Training loss: 0.7973382762531922
Validation loss: 2.53208641332376

Epoch: 297| Step: 0
Training loss: 0.6195848958864328
Validation loss: 2.5577506195352133

Epoch: 6| Step: 1
Training loss: 0.8551685381298693
Validation loss: 2.5464495946488417

Epoch: 6| Step: 2
Training loss: 1.3140545675829802
Validation loss: 2.5569027032075113

Epoch: 6| Step: 3
Training loss: 1.150066595637109
Validation loss: 2.528486332448892

Epoch: 6| Step: 4
Training loss: 0.6855867814406644
Validation loss: 2.555274759654902

Epoch: 6| Step: 5
Training loss: 0.7508943708704884
Validation loss: 2.5388076661916785

Epoch: 6| Step: 6
Training loss: 0.638939011261638
Validation loss: 2.5450844126374825

Epoch: 6| Step: 7
Training loss: 0.9779538428369114
Validation loss: 2.5454571958247603

Epoch: 6| Step: 8
Training loss: 1.2930544453138226
Validation loss: 2.566777642446117

Epoch: 6| Step: 9
Training loss: 1.2150638295114324
Validation loss: 2.5406938389320946

Epoch: 6| Step: 10
Training loss: 0.9766878276513651
Validation loss: 2.5236776569033688

Epoch: 6| Step: 11
Training loss: 1.1744388254797742
Validation loss: 2.5178105108878754

Epoch: 6| Step: 12
Training loss: 0.9870664948787365
Validation loss: 2.5095331959579505

Epoch: 6| Step: 13
Training loss: 0.7269359162275412
Validation loss: 2.5064324513734966

Epoch: 298| Step: 0
Training loss: 0.9306145541781415
Validation loss: 2.5329582443937984

Epoch: 6| Step: 1
Training loss: 0.9477738108601
Validation loss: 2.5595681090005304

Epoch: 6| Step: 2
Training loss: 0.909524264326008
Validation loss: 2.5696792518161398

Epoch: 6| Step: 3
Training loss: 0.8904125897271503
Validation loss: 2.5844278306091146

Epoch: 6| Step: 4
Training loss: 1.1402001830904656
Validation loss: 2.5836259670882047

Epoch: 6| Step: 5
Training loss: 1.2517162938106383
Validation loss: 2.6234238585893266

Epoch: 6| Step: 6
Training loss: 0.9189039296025397
Validation loss: 2.591393273944855

Epoch: 6| Step: 7
Training loss: 0.8310549743867014
Validation loss: 2.5845511070621168

Epoch: 6| Step: 8
Training loss: 0.8248382698826556
Validation loss: 2.5609541351263188

Epoch: 6| Step: 9
Training loss: 1.0126316856179587
Validation loss: 2.558985737714694

Epoch: 6| Step: 10
Training loss: 1.2934967530294215
Validation loss: 2.5350649135415972

Epoch: 6| Step: 11
Training loss: 1.0689466908921887
Validation loss: 2.4971258793068483

Epoch: 6| Step: 12
Training loss: 0.8228505425907517
Validation loss: 2.503000954214697

Epoch: 6| Step: 13
Training loss: 0.5517648071925968
Validation loss: 2.475446677481339

Epoch: 299| Step: 0
Training loss: 0.8793346801927773
Validation loss: 2.4991874994730887

Epoch: 6| Step: 1
Training loss: 0.6211146944941063
Validation loss: 2.498522464400016

Epoch: 6| Step: 2
Training loss: 0.9561333005417425
Validation loss: 2.5134487686528537

Epoch: 6| Step: 3
Training loss: 0.9457702474239307
Validation loss: 2.5172047730696097

Epoch: 6| Step: 4
Training loss: 0.737563091747524
Validation loss: 2.5025987295444447

Epoch: 6| Step: 5
Training loss: 0.7789156562137739
Validation loss: 2.542887426962813

Epoch: 6| Step: 6
Training loss: 1.1661184703256855
Validation loss: 2.5298253188229833

Epoch: 6| Step: 7
Training loss: 0.9945399113927447
Validation loss: 2.5122321873258833

Epoch: 6| Step: 8
Training loss: 0.8294765311951435
Validation loss: 2.5312481607612503

Epoch: 6| Step: 9
Training loss: 1.0366106288847072
Validation loss: 2.5271538376224725

Epoch: 6| Step: 10
Training loss: 0.8527225677050243
Validation loss: 2.490405818306429

Epoch: 6| Step: 11
Training loss: 0.9061382487882592
Validation loss: 2.4717600074161172

Epoch: 6| Step: 12
Training loss: 1.1592696684418649
Validation loss: 2.5071408597803226

Epoch: 6| Step: 13
Training loss: 1.550799545064864
Validation loss: 2.47828847860085

Epoch: 300| Step: 0
Training loss: 0.8137936929906018
Validation loss: 2.481958152351544

Epoch: 6| Step: 1
Training loss: 1.0234881672438423
Validation loss: 2.4762472817304575

Epoch: 6| Step: 2
Training loss: 0.9356356520928725
Validation loss: 2.4985146765721997

Epoch: 6| Step: 3
Training loss: 0.9850025901179461
Validation loss: 2.4875983797710557

Epoch: 6| Step: 4
Training loss: 0.7283777510442281
Validation loss: 2.496707036536603

Epoch: 6| Step: 5
Training loss: 1.033608023731633
Validation loss: 2.5159534037953346

Epoch: 6| Step: 6
Training loss: 1.1751462926494758
Validation loss: 2.5054348413913328

Epoch: 6| Step: 7
Training loss: 1.0135372123868687
Validation loss: 2.542606426303307

Epoch: 6| Step: 8
Training loss: 1.0983559221386674
Validation loss: 2.5678508580625823

Epoch: 6| Step: 9
Training loss: 1.026201781093767
Validation loss: 2.517167044912471

Epoch: 6| Step: 10
Training loss: 0.8376643446616755
Validation loss: 2.5238460046427234

Epoch: 6| Step: 11
Training loss: 0.8533348049086558
Validation loss: 2.5230934251113526

Epoch: 6| Step: 12
Training loss: 0.8612502705168057
Validation loss: 2.5275649786846146

Epoch: 6| Step: 13
Training loss: 0.9211570724451021
Validation loss: 2.542282631678731

Epoch: 301| Step: 0
Training loss: 0.5323110250945495
Validation loss: 2.5352137957397893

Epoch: 6| Step: 1
Training loss: 1.1761230276170105
Validation loss: 2.5321185678922444

Epoch: 6| Step: 2
Training loss: 0.9024631701956431
Validation loss: 2.5213573927715847

Epoch: 6| Step: 3
Training loss: 0.9808521508999452
Validation loss: 2.516548606283584

Epoch: 6| Step: 4
Training loss: 0.8462693783275425
Validation loss: 2.488813195594997

Epoch: 6| Step: 5
Training loss: 0.9644335905856993
Validation loss: 2.4984859722145987

Epoch: 6| Step: 6
Training loss: 1.0022099037628078
Validation loss: 2.522721909707141

Epoch: 6| Step: 7
Training loss: 1.0683550233072363
Validation loss: 2.4985870203511538

Epoch: 6| Step: 8
Training loss: 1.065024014591739
Validation loss: 2.50151839650169

Epoch: 6| Step: 9
Training loss: 0.6772973798215371
Validation loss: 2.538525259071202

Epoch: 6| Step: 10
Training loss: 0.9261908289121492
Validation loss: 2.508655445656234

Epoch: 6| Step: 11
Training loss: 1.12785818690786
Validation loss: 2.5139985627632426

Epoch: 6| Step: 12
Training loss: 0.9485231841596529
Validation loss: 2.488095379514273

Epoch: 6| Step: 13
Training loss: 0.7422805326277893
Validation loss: 2.5067537071352555

Epoch: 302| Step: 0
Training loss: 1.1311300477560144
Validation loss: 2.5449387763517377

Epoch: 6| Step: 1
Training loss: 1.0580580929165209
Validation loss: 2.5058045937128566

Epoch: 6| Step: 2
Training loss: 0.9185640717857833
Validation loss: 2.517625549669599

Epoch: 6| Step: 3
Training loss: 0.925103788739092
Validation loss: 2.4912428951909726

Epoch: 6| Step: 4
Training loss: 0.94759572363372
Validation loss: 2.4710713764623877

Epoch: 6| Step: 5
Training loss: 0.7985940977486525
Validation loss: 2.453570587026739

Epoch: 6| Step: 6
Training loss: 0.5489298770292292
Validation loss: 2.5127330664787344

Epoch: 6| Step: 7
Training loss: 0.8255155224233163
Validation loss: 2.497124591390995

Epoch: 6| Step: 8
Training loss: 0.8321964655073413
Validation loss: 2.5028912950196154

Epoch: 6| Step: 9
Training loss: 1.2816269482897586
Validation loss: 2.495744235145822

Epoch: 6| Step: 10
Training loss: 0.9786753876212645
Validation loss: 2.495996859803057

Epoch: 6| Step: 11
Training loss: 0.7833829754121664
Validation loss: 2.5080661046789694

Epoch: 6| Step: 12
Training loss: 0.9028768244638696
Validation loss: 2.5302929711670408

Epoch: 6| Step: 13
Training loss: 0.8771305372050604
Validation loss: 2.52197286616178

Epoch: 303| Step: 0
Training loss: 0.44331282316653514
Validation loss: 2.5398312953197046

Epoch: 6| Step: 1
Training loss: 1.075765266382826
Validation loss: 2.538313583598189

Epoch: 6| Step: 2
Training loss: 1.0646471879077353
Validation loss: 2.5678194289853575

Epoch: 6| Step: 3
Training loss: 1.0641289733647636
Validation loss: 2.5163717270515606

Epoch: 6| Step: 4
Training loss: 0.6489939542600469
Validation loss: 2.5155441321116956

Epoch: 6| Step: 5
Training loss: 1.0300407255324875
Validation loss: 2.5079283405299924

Epoch: 6| Step: 6
Training loss: 0.8805012112229533
Validation loss: 2.4454301254559647

Epoch: 6| Step: 7
Training loss: 1.1791079278521037
Validation loss: 2.4634800712271736

Epoch: 6| Step: 8
Training loss: 0.7590495365774385
Validation loss: 2.491928563923262

Epoch: 6| Step: 9
Training loss: 0.9087785108205002
Validation loss: 2.5018680289674657

Epoch: 6| Step: 10
Training loss: 0.8133626173433132
Validation loss: 2.505285434859516

Epoch: 6| Step: 11
Training loss: 1.0147828351798642
Validation loss: 2.5133062391985073

Epoch: 6| Step: 12
Training loss: 0.9033567019169587
Validation loss: 2.5460293773520326

Epoch: 6| Step: 13
Training loss: 0.8800581440898734
Validation loss: 2.5313637142143577

Epoch: 304| Step: 0
Training loss: 1.0431381830898918
Validation loss: 2.5591764629269464

Epoch: 6| Step: 1
Training loss: 0.7533659110437979
Validation loss: 2.5716001694590607

Epoch: 6| Step: 2
Training loss: 0.8435766960465018
Validation loss: 2.5964543526120187

Epoch: 6| Step: 3
Training loss: 1.1265702944418456
Validation loss: 2.568734840408414

Epoch: 6| Step: 4
Training loss: 0.8907566307906702
Validation loss: 2.537224686016861

Epoch: 6| Step: 5
Training loss: 1.0650879812837346
Validation loss: 2.507195334769457

Epoch: 6| Step: 6
Training loss: 0.895966590166923
Validation loss: 2.48319398289855

Epoch: 6| Step: 7
Training loss: 0.8505910179082814
Validation loss: 2.47540373895747

Epoch: 6| Step: 8
Training loss: 0.551246987245938
Validation loss: 2.4553968251898053

Epoch: 6| Step: 9
Training loss: 0.875457201446992
Validation loss: 2.4411859685149198

Epoch: 6| Step: 10
Training loss: 0.8949024479729282
Validation loss: 2.4620571815419448

Epoch: 6| Step: 11
Training loss: 0.82096611504551
Validation loss: 2.4562913503899884

Epoch: 6| Step: 12
Training loss: 0.8194595261890307
Validation loss: 2.4592719485719234

Epoch: 6| Step: 13
Training loss: 1.0817063046810775
Validation loss: 2.4395035796188878

Epoch: 305| Step: 0
Training loss: 0.7382097159148073
Validation loss: 2.455662113657011

Epoch: 6| Step: 1
Training loss: 1.2112030722519929
Validation loss: 2.4897115356625528

Epoch: 6| Step: 2
Training loss: 0.861544246763872
Validation loss: 2.535828335384433

Epoch: 6| Step: 3
Training loss: 0.743672100764001
Validation loss: 2.5645638155294246

Epoch: 6| Step: 4
Training loss: 0.9275498377322109
Validation loss: 2.5693667269143314

Epoch: 6| Step: 5
Training loss: 1.0909640115943864
Validation loss: 2.5654322147351083

Epoch: 6| Step: 6
Training loss: 0.8073682851221274
Validation loss: 2.557476508104313

Epoch: 6| Step: 7
Training loss: 1.1092374474582753
Validation loss: 2.545888746412535

Epoch: 6| Step: 8
Training loss: 0.8111652267670051
Validation loss: 2.5260923244588365

Epoch: 6| Step: 9
Training loss: 0.7288947461233402
Validation loss: 2.452124073812529

Epoch: 6| Step: 10
Training loss: 0.9277166746358337
Validation loss: 2.4407288416728394

Epoch: 6| Step: 11
Training loss: 1.081001425157255
Validation loss: 2.4584567023582817

Epoch: 6| Step: 12
Training loss: 1.0718624281076459
Validation loss: 2.4373630441032414

Epoch: 6| Step: 13
Training loss: 0.43801961423119873
Validation loss: 2.4525787704736466

Epoch: 306| Step: 0
Training loss: 0.7720304077860306
Validation loss: 2.4471106299000525

Epoch: 6| Step: 1
Training loss: 0.8986053973341708
Validation loss: 2.4585415762550866

Epoch: 6| Step: 2
Training loss: 0.7703369105806351
Validation loss: 2.511032984341887

Epoch: 6| Step: 3
Training loss: 0.7719528900260402
Validation loss: 2.5427057064566925

Epoch: 6| Step: 4
Training loss: 0.889414181734203
Validation loss: 2.5867325320556978

Epoch: 6| Step: 5
Training loss: 1.2320021505553809
Validation loss: 2.5855996650073028

Epoch: 6| Step: 6
Training loss: 0.8788147603206596
Validation loss: 2.559605460063271

Epoch: 6| Step: 7
Training loss: 0.9864750214520962
Validation loss: 2.6011818917766165

Epoch: 6| Step: 8
Training loss: 0.9662698870015093
Validation loss: 2.5487793547454727

Epoch: 6| Step: 9
Training loss: 0.7714664505433563
Validation loss: 2.5591134183696838

Epoch: 6| Step: 10
Training loss: 0.6997540944597361
Validation loss: 2.524037071395023

Epoch: 6| Step: 11
Training loss: 0.8697448002110744
Validation loss: 2.496333557232655

Epoch: 6| Step: 12
Training loss: 0.8091690670479379
Validation loss: 2.4750888557845605

Epoch: 6| Step: 13
Training loss: 1.132660164949311
Validation loss: 2.473412515546217

Epoch: 307| Step: 0
Training loss: 0.7762515959669529
Validation loss: 2.4698037198509324

Epoch: 6| Step: 1
Training loss: 0.6170605637597155
Validation loss: 2.4916957982612513

Epoch: 6| Step: 2
Training loss: 0.8102397290796728
Validation loss: 2.5228458128531943

Epoch: 6| Step: 3
Training loss: 0.8130314629344761
Validation loss: 2.5099038184154865

Epoch: 6| Step: 4
Training loss: 1.0660191766184195
Validation loss: 2.5206353135125252

Epoch: 6| Step: 5
Training loss: 0.8853448651689729
Validation loss: 2.5174320125437166

Epoch: 6| Step: 6
Training loss: 0.7053183994207056
Validation loss: 2.5149920582002196

Epoch: 6| Step: 7
Training loss: 1.068454773041668
Validation loss: 2.532344820368418

Epoch: 6| Step: 8
Training loss: 0.6679964561739591
Validation loss: 2.5176291085458145

Epoch: 6| Step: 9
Training loss: 0.7999742488888911
Validation loss: 2.529944265005338

Epoch: 6| Step: 10
Training loss: 1.3889640146706421
Validation loss: 2.527945023521523

Epoch: 6| Step: 11
Training loss: 0.9861782451098431
Validation loss: 2.523249163581226

Epoch: 6| Step: 12
Training loss: 0.6366298121958233
Validation loss: 2.5292748883621634

Epoch: 6| Step: 13
Training loss: 0.530635365990347
Validation loss: 2.515556644832517

Epoch: 308| Step: 0
Training loss: 0.504801287977235
Validation loss: 2.4954182663447617

Epoch: 6| Step: 1
Training loss: 0.9219103660911858
Validation loss: 2.485519661434447

Epoch: 6| Step: 2
Training loss: 0.5982802381130856
Validation loss: 2.503220816347893

Epoch: 6| Step: 3
Training loss: 0.8721912808474713
Validation loss: 2.5045114357646887

Epoch: 6| Step: 4
Training loss: 1.0226004285855126
Validation loss: 2.4797847611876667

Epoch: 6| Step: 5
Training loss: 1.152852091762142
Validation loss: 2.4652929934603507

Epoch: 6| Step: 6
Training loss: 0.6504548187193488
Validation loss: 2.47526920495681

Epoch: 6| Step: 7
Training loss: 0.7300578711054103
Validation loss: 2.4819058219716754

Epoch: 6| Step: 8
Training loss: 0.9704110763528552
Validation loss: 2.479865760365556

Epoch: 6| Step: 9
Training loss: 1.1381600278086412
Validation loss: 2.5162759778204062

Epoch: 6| Step: 10
Training loss: 0.6222153379304508
Validation loss: 2.5101956152009186

Epoch: 6| Step: 11
Training loss: 0.8277795178937721
Validation loss: 2.5040312597554073

Epoch: 6| Step: 12
Training loss: 0.7394362200352786
Validation loss: 2.5268242298184904

Epoch: 6| Step: 13
Training loss: 0.83633670009616
Validation loss: 2.552999181867107

Epoch: 309| Step: 0
Training loss: 0.7484975308929878
Validation loss: 2.5018045352585316

Epoch: 6| Step: 1
Training loss: 0.7425514533456814
Validation loss: 2.5268738534829343

Epoch: 6| Step: 2
Training loss: 1.184377278751003
Validation loss: 2.5139694569969646

Epoch: 6| Step: 3
Training loss: 0.6536535943977637
Validation loss: 2.5228489192834638

Epoch: 6| Step: 4
Training loss: 0.9197448106512035
Validation loss: 2.4866398467380613

Epoch: 6| Step: 5
Training loss: 1.0318586691771932
Validation loss: 2.5346607749399546

Epoch: 6| Step: 6
Training loss: 0.7776805205693782
Validation loss: 2.505451106631438

Epoch: 6| Step: 7
Training loss: 0.4945988396471714
Validation loss: 2.5076965973807255

Epoch: 6| Step: 8
Training loss: 0.8497672800235776
Validation loss: 2.496013179869545

Epoch: 6| Step: 9
Training loss: 0.7390052837781722
Validation loss: 2.51763313276831

Epoch: 6| Step: 10
Training loss: 0.8315474845508254
Validation loss: 2.5168439586570894

Epoch: 6| Step: 11
Training loss: 0.8108362623464355
Validation loss: 2.50050243333127

Epoch: 6| Step: 12
Training loss: 0.8277071132374075
Validation loss: 2.49952922613364

Epoch: 6| Step: 13
Training loss: 0.48636188926075086
Validation loss: 2.494470064911821

Epoch: 310| Step: 0
Training loss: 0.9050239951814802
Validation loss: 2.5113328900694594

Epoch: 6| Step: 1
Training loss: 0.5331950763472202
Validation loss: 2.494974955850397

Epoch: 6| Step: 2
Training loss: 1.182153763759846
Validation loss: 2.5397387834636853

Epoch: 6| Step: 3
Training loss: 0.6596657550359553
Validation loss: 2.518050066218706

Epoch: 6| Step: 4
Training loss: 0.30762801378363414
Validation loss: 2.4929715674264514

Epoch: 6| Step: 5
Training loss: 0.8391568235661667
Validation loss: 2.520102922317408

Epoch: 6| Step: 6
Training loss: 0.9354845635482635
Validation loss: 2.5326938099278355

Epoch: 6| Step: 7
Training loss: 0.4591844163372882
Validation loss: 2.5440820997268245

Epoch: 6| Step: 8
Training loss: 0.9608768661101765
Validation loss: 2.530182251036126

Epoch: 6| Step: 9
Training loss: 0.705380108271477
Validation loss: 2.531959624627064

Epoch: 6| Step: 10
Training loss: 0.8245956137849303
Validation loss: 2.51620346762968

Epoch: 6| Step: 11
Training loss: 0.7736101054244597
Validation loss: 2.5430335703587095

Epoch: 6| Step: 12
Training loss: 1.1434010729078912
Validation loss: 2.532817005616709

Epoch: 6| Step: 13
Training loss: 0.7539953861019516
Validation loss: 2.5293967044191135

Epoch: 311| Step: 0
Training loss: 0.6155989520376332
Validation loss: 2.5403341743945607

Epoch: 6| Step: 1
Training loss: 1.0812069614201816
Validation loss: 2.552743347153708

Epoch: 6| Step: 2
Training loss: 0.7903042832592643
Validation loss: 2.533999431691983

Epoch: 6| Step: 3
Training loss: 0.883187273533669
Validation loss: 2.5550676780260217

Epoch: 6| Step: 4
Training loss: 0.6914327153027651
Validation loss: 2.54194925056308

Epoch: 6| Step: 5
Training loss: 0.773378042382483
Validation loss: 2.499865125278841

Epoch: 6| Step: 6
Training loss: 0.9830596249252341
Validation loss: 2.5115025164631444

Epoch: 6| Step: 7
Training loss: 0.7718018856246978
Validation loss: 2.4915202332742434

Epoch: 6| Step: 8
Training loss: 0.8624472062912177
Validation loss: 2.5123124158864076

Epoch: 6| Step: 9
Training loss: 0.9254205057223981
Validation loss: 2.551948744385252

Epoch: 6| Step: 10
Training loss: 0.6612644261767786
Validation loss: 2.483629206195897

Epoch: 6| Step: 11
Training loss: 0.7646710427792863
Validation loss: 2.505922380286298

Epoch: 6| Step: 12
Training loss: 0.442563018136973
Validation loss: 2.5139110078640976

Epoch: 6| Step: 13
Training loss: 0.86970333785379
Validation loss: 2.501083455088978

Epoch: 312| Step: 0
Training loss: 0.9161720711639629
Validation loss: 2.4851032329244793

Epoch: 6| Step: 1
Training loss: 0.6788294846447247
Validation loss: 2.5196834868302194

Epoch: 6| Step: 2
Training loss: 0.3743451878454534
Validation loss: 2.537888303844536

Epoch: 6| Step: 3
Training loss: 0.8841487258064068
Validation loss: 2.5320776904445474

Epoch: 6| Step: 4
Training loss: 0.601560369710742
Validation loss: 2.5394065731082143

Epoch: 6| Step: 5
Training loss: 0.7124822831879112
Validation loss: 2.5417798032415053

Epoch: 6| Step: 6
Training loss: 0.7730638776839838
Validation loss: 2.530543737352122

Epoch: 6| Step: 7
Training loss: 0.7453913952797785
Validation loss: 2.523198828024583

Epoch: 6| Step: 8
Training loss: 0.9367257735980916
Validation loss: 2.4965416655640364

Epoch: 6| Step: 9
Training loss: 0.7355413711187967
Validation loss: 2.5199276659894543

Epoch: 6| Step: 10
Training loss: 0.9618867357119351
Validation loss: 2.4503059803458935

Epoch: 6| Step: 11
Training loss: 0.949096671837319
Validation loss: 2.4782549676917713

Epoch: 6| Step: 12
Training loss: 0.9484870508061114
Validation loss: 2.4656637451083876

Epoch: 6| Step: 13
Training loss: 0.8980875411746669
Validation loss: 2.450502431631569

Epoch: 313| Step: 0
Training loss: 0.46351756522568077
Validation loss: 2.471058060612216

Epoch: 6| Step: 1
Training loss: 0.7936508176818723
Validation loss: 2.4362537762621956

Epoch: 6| Step: 2
Training loss: 0.8214620256127323
Validation loss: 2.4800290692873794

Epoch: 6| Step: 3
Training loss: 0.7659489471812794
Validation loss: 2.4821028893632016

Epoch: 6| Step: 4
Training loss: 0.8119688498718602
Validation loss: 2.4928744083065024

Epoch: 6| Step: 5
Training loss: 0.5553143679748958
Validation loss: 2.508658103153083

Epoch: 6| Step: 6
Training loss: 0.9368724311961355
Validation loss: 2.5092225997922846

Epoch: 6| Step: 7
Training loss: 0.6845491109440885
Validation loss: 2.5092209793958475

Epoch: 6| Step: 8
Training loss: 0.8774765933140125
Validation loss: 2.518071946229064

Epoch: 6| Step: 9
Training loss: 0.7212845439340678
Validation loss: 2.5132859844374944

Epoch: 6| Step: 10
Training loss: 0.9239631860570475
Validation loss: 2.513022570976325

Epoch: 6| Step: 11
Training loss: 0.8636795091917058
Validation loss: 2.496002821603145

Epoch: 6| Step: 12
Training loss: 1.0809951393660417
Validation loss: 2.4828752988334575

Epoch: 6| Step: 13
Training loss: 0.506293681108711
Validation loss: 2.4875804272022726

Epoch: 314| Step: 0
Training loss: 1.023677186344426
Validation loss: 2.4815232408506223

Epoch: 6| Step: 1
Training loss: 0.9247807758466594
Validation loss: 2.4877463073035293

Epoch: 6| Step: 2
Training loss: 1.0235441312495606
Validation loss: 2.4773950859076104

Epoch: 6| Step: 3
Training loss: 0.8859921473850467
Validation loss: 2.4693781618337804

Epoch: 6| Step: 4
Training loss: 0.6193405694947732
Validation loss: 2.478504489215014

Epoch: 6| Step: 5
Training loss: 0.8028393604838178
Validation loss: 2.480929147272722

Epoch: 6| Step: 6
Training loss: 1.0040960466448199
Validation loss: 2.472098390189319

Epoch: 6| Step: 7
Training loss: 0.5757113151573384
Validation loss: 2.5039978220489614

Epoch: 6| Step: 8
Training loss: 0.7735022700769
Validation loss: 2.4957857739379237

Epoch: 6| Step: 9
Training loss: 0.3058346647022244
Validation loss: 2.5275821015815434

Epoch: 6| Step: 10
Training loss: 0.79993725471007
Validation loss: 2.541139793825568

Epoch: 6| Step: 11
Training loss: 0.5423907489903396
Validation loss: 2.529077923470271

Epoch: 6| Step: 12
Training loss: 0.7879860588985075
Validation loss: 2.5472038515235536

Epoch: 6| Step: 13
Training loss: 0.5252230635830328
Validation loss: 2.56061439509301

Epoch: 315| Step: 0
Training loss: 0.8068357882733878
Validation loss: 2.516087026885694

Epoch: 6| Step: 1
Training loss: 0.7101269807228918
Validation loss: 2.5211299783395105

Epoch: 6| Step: 2
Training loss: 0.7092687283538525
Validation loss: 2.512709112704044

Epoch: 6| Step: 3
Training loss: 0.6749688264924557
Validation loss: 2.5227229508243876

Epoch: 6| Step: 4
Training loss: 0.7452924729701493
Validation loss: 2.472130707468056

Epoch: 6| Step: 5
Training loss: 0.872748748603564
Validation loss: 2.4647891866726828

Epoch: 6| Step: 6
Training loss: 0.6849984695250406
Validation loss: 2.4766727442510796

Epoch: 6| Step: 7
Training loss: 0.6834806294169519
Validation loss: 2.445399458192578

Epoch: 6| Step: 8
Training loss: 0.6742620425508478
Validation loss: 2.4900294243321497

Epoch: 6| Step: 9
Training loss: 0.8687384199838923
Validation loss: 2.4790163826178424

Epoch: 6| Step: 10
Training loss: 0.7351924729215119
Validation loss: 2.51832830111762

Epoch: 6| Step: 11
Training loss: 0.9529558875971409
Validation loss: 2.462910997551866

Epoch: 6| Step: 12
Training loss: 0.9567330654929216
Validation loss: 2.5156436482031745

Epoch: 6| Step: 13
Training loss: 0.7387592443542936
Validation loss: 2.4955484329717623

Epoch: 316| Step: 0
Training loss: 0.6414101371693812
Validation loss: 2.51421163277459

Epoch: 6| Step: 1
Training loss: 0.9209485005012001
Validation loss: 2.500189421255931

Epoch: 6| Step: 2
Training loss: 0.7358513459722287
Validation loss: 2.4733229807790797

Epoch: 6| Step: 3
Training loss: 0.9699920567452734
Validation loss: 2.4631586169653916

Epoch: 6| Step: 4
Training loss: 0.7788964488064231
Validation loss: 2.481614562395129

Epoch: 6| Step: 5
Training loss: 0.6213895465235536
Validation loss: 2.4434633292319816

Epoch: 6| Step: 6
Training loss: 0.7845100286607398
Validation loss: 2.4619474365834844

Epoch: 6| Step: 7
Training loss: 0.8626250798294878
Validation loss: 2.4998810544994687

Epoch: 6| Step: 8
Training loss: 0.6019599889404754
Validation loss: 2.500586106701638

Epoch: 6| Step: 9
Training loss: 0.5229211794391253
Validation loss: 2.5388405505181906

Epoch: 6| Step: 10
Training loss: 0.7498282394824036
Validation loss: 2.499253537911569

Epoch: 6| Step: 11
Training loss: 0.6605802900907445
Validation loss: 2.520289024594272

Epoch: 6| Step: 12
Training loss: 1.069015440965834
Validation loss: 2.5054448526713915

Epoch: 6| Step: 13
Training loss: 0.8747281946635407
Validation loss: 2.499379408626562

Epoch: 317| Step: 0
Training loss: 0.5968254647995485
Validation loss: 2.4925619862326935

Epoch: 6| Step: 1
Training loss: 0.9306792090865588
Validation loss: 2.471389725819155

Epoch: 6| Step: 2
Training loss: 0.6573350881953863
Validation loss: 2.481557108459058

Epoch: 6| Step: 3
Training loss: 0.5773981267489077
Validation loss: 2.5019030424000412

Epoch: 6| Step: 4
Training loss: 0.9885944277340655
Validation loss: 2.4671772861384245

Epoch: 6| Step: 5
Training loss: 0.6012716705001685
Validation loss: 2.492252899977227

Epoch: 6| Step: 6
Training loss: 0.41740907649803727
Validation loss: 2.535331749957455

Epoch: 6| Step: 7
Training loss: 0.5482353185557014
Validation loss: 2.463622860998217

Epoch: 6| Step: 8
Training loss: 0.747157591664313
Validation loss: 2.4999441525158796

Epoch: 6| Step: 9
Training loss: 0.6714947533817929
Validation loss: 2.4614491795565407

Epoch: 6| Step: 10
Training loss: 1.1948979974252167
Validation loss: 2.4637024623254384

Epoch: 6| Step: 11
Training loss: 0.7950889168203986
Validation loss: 2.498035426039312

Epoch: 6| Step: 12
Training loss: 0.7782394386307674
Validation loss: 2.494010406483416

Epoch: 6| Step: 13
Training loss: 0.6367521452775874
Validation loss: 2.4917695283278545

Epoch: 318| Step: 0
Training loss: 0.6483984096648207
Validation loss: 2.5400948454460766

Epoch: 6| Step: 1
Training loss: 0.9612987428567059
Validation loss: 2.5459634707510137

Epoch: 6| Step: 2
Training loss: 0.8000861151361183
Validation loss: 2.5609043444659805

Epoch: 6| Step: 3
Training loss: 1.0724484925250548
Validation loss: 2.4887083115996393

Epoch: 6| Step: 4
Training loss: 0.6178125524062587
Validation loss: 2.4784494787788476

Epoch: 6| Step: 5
Training loss: 0.8434817982842696
Validation loss: 2.4792544407213093

Epoch: 6| Step: 6
Training loss: 0.6259438778442347
Validation loss: 2.470093660136973

Epoch: 6| Step: 7
Training loss: 0.8738817494376883
Validation loss: 2.4858332109507124

Epoch: 6| Step: 8
Training loss: 0.7142210369119394
Validation loss: 2.466507480018121

Epoch: 6| Step: 9
Training loss: 0.7725278340729345
Validation loss: 2.487009070036841

Epoch: 6| Step: 10
Training loss: 0.6127211327260593
Validation loss: 2.4520616914653828

Epoch: 6| Step: 11
Training loss: 0.5353596989745042
Validation loss: 2.4862196751501617

Epoch: 6| Step: 12
Training loss: 0.5599606202959241
Validation loss: 2.4695718689296124

Epoch: 6| Step: 13
Training loss: 0.8286753211458208
Validation loss: 2.47426857851518

Epoch: 319| Step: 0
Training loss: 0.6271817750009003
Validation loss: 2.5230308537019894

Epoch: 6| Step: 1
Training loss: 0.8009447628648967
Validation loss: 2.536135475067929

Epoch: 6| Step: 2
Training loss: 1.0450773604747312
Validation loss: 2.527460544961826

Epoch: 6| Step: 3
Training loss: 0.6653950280517144
Validation loss: 2.5569469912257046

Epoch: 6| Step: 4
Training loss: 0.8003907158527165
Validation loss: 2.5370082282310844

Epoch: 6| Step: 5
Training loss: 0.8254857742775135
Validation loss: 2.5447025139211763

Epoch: 6| Step: 6
Training loss: 0.979224825545461
Validation loss: 2.5004433197813865

Epoch: 6| Step: 7
Training loss: 0.7391425059203587
Validation loss: 2.488238206350956

Epoch: 6| Step: 8
Training loss: 0.5115106756563589
Validation loss: 2.478096829809152

Epoch: 6| Step: 9
Training loss: 0.5599797267309509
Validation loss: 2.493943887931171

Epoch: 6| Step: 10
Training loss: 0.6914181896838304
Validation loss: 2.457420924038859

Epoch: 6| Step: 11
Training loss: 0.7588193830915203
Validation loss: 2.4840067196244986

Epoch: 6| Step: 12
Training loss: 0.5323088416098908
Validation loss: 2.4949991528390028

Epoch: 6| Step: 13
Training loss: 0.5252805119385086
Validation loss: 2.5197407622564594

Epoch: 320| Step: 0
Training loss: 0.5859021494056248
Validation loss: 2.520140965106998

Epoch: 6| Step: 1
Training loss: 0.802024285921458
Validation loss: 2.5016523028278055

Epoch: 6| Step: 2
Training loss: 0.6181247451596559
Validation loss: 2.5144018094767375

Epoch: 6| Step: 3
Training loss: 0.5888283686708865
Validation loss: 2.506080405216928

Epoch: 6| Step: 4
Training loss: 0.7820688152913375
Validation loss: 2.496260627461336

Epoch: 6| Step: 5
Training loss: 0.434972564034849
Validation loss: 2.4884141090084717

Epoch: 6| Step: 6
Training loss: 0.821111453488866
Validation loss: 2.4973260936353667

Epoch: 6| Step: 7
Training loss: 0.7247783124643203
Validation loss: 2.502730289699308

Epoch: 6| Step: 8
Training loss: 0.8101900349325521
Validation loss: 2.48957034029672

Epoch: 6| Step: 9
Training loss: 0.7805856932127277
Validation loss: 2.5137267846744296

Epoch: 6| Step: 10
Training loss: 0.8082082815545081
Validation loss: 2.504137554091271

Epoch: 6| Step: 11
Training loss: 0.7288566384394656
Validation loss: 2.477509294550835

Epoch: 6| Step: 12
Training loss: 0.7315942997072669
Validation loss: 2.499941578049117

Epoch: 6| Step: 13
Training loss: 1.0243929996270653
Validation loss: 2.485125340600143

Epoch: 321| Step: 0
Training loss: 0.9278230966005914
Validation loss: 2.494380184231127

Epoch: 6| Step: 1
Training loss: 0.7129595997507643
Validation loss: 2.5194738863734285

Epoch: 6| Step: 2
Training loss: 0.712497257762785
Validation loss: 2.5143116466700657

Epoch: 6| Step: 3
Training loss: 0.8104313411871368
Validation loss: 2.5029616819787535

Epoch: 6| Step: 4
Training loss: 0.6193291891422692
Validation loss: 2.5073429169314956

Epoch: 6| Step: 5
Training loss: 0.5942921672828654
Validation loss: 2.5512550709294954

Epoch: 6| Step: 6
Training loss: 0.7324938522575621
Validation loss: 2.5332563352001536

Epoch: 6| Step: 7
Training loss: 0.7921377252896281
Validation loss: 2.5274691422794433

Epoch: 6| Step: 8
Training loss: 0.85313990373833
Validation loss: 2.512093916872468

Epoch: 6| Step: 9
Training loss: 0.4638520569592373
Validation loss: 2.4744656661880895

Epoch: 6| Step: 10
Training loss: 0.7373873026458982
Validation loss: 2.4647404406092215

Epoch: 6| Step: 11
Training loss: 0.6657750206892927
Validation loss: 2.4764726826368935

Epoch: 6| Step: 12
Training loss: 0.8807010212256153
Validation loss: 2.482251565772228

Epoch: 6| Step: 13
Training loss: 0.48808171582237553
Validation loss: 2.4856584808749

Epoch: 322| Step: 0
Training loss: 0.5304948825607333
Validation loss: 2.5152809000974243

Epoch: 6| Step: 1
Training loss: 0.9386920979163251
Validation loss: 2.5115261591887723

Epoch: 6| Step: 2
Training loss: 0.5619555858747507
Validation loss: 2.5075132497938526

Epoch: 6| Step: 3
Training loss: 0.6197657272509971
Validation loss: 2.5491870406614643

Epoch: 6| Step: 4
Training loss: 0.7273285631669658
Validation loss: 2.6024119520114977

Epoch: 6| Step: 5
Training loss: 0.6262845190893778
Validation loss: 2.589692080733562

Epoch: 6| Step: 6
Training loss: 0.624594533050912
Validation loss: 2.5639666220244957

Epoch: 6| Step: 7
Training loss: 1.0023864641848137
Validation loss: 2.5330872728971556

Epoch: 6| Step: 8
Training loss: 0.6349873551664137
Validation loss: 2.509507747728861

Epoch: 6| Step: 9
Training loss: 0.6399397557931659
Validation loss: 2.4560281371483335

Epoch: 6| Step: 10
Training loss: 0.7494276962650691
Validation loss: 2.4576002842222593

Epoch: 6| Step: 11
Training loss: 1.044950110508556
Validation loss: 2.4898597734402133

Epoch: 6| Step: 12
Training loss: 0.829822312374243
Validation loss: 2.4483640144638503

Epoch: 6| Step: 13
Training loss: 0.5944535955376329
Validation loss: 2.4485828968829306

Epoch: 323| Step: 0
Training loss: 0.89409116889032
Validation loss: 2.456549193275845

Epoch: 6| Step: 1
Training loss: 0.93305449294138
Validation loss: 2.47095026650069

Epoch: 6| Step: 2
Training loss: 1.050470639518912
Validation loss: 2.456338664159022

Epoch: 6| Step: 3
Training loss: 0.5734621889791837
Validation loss: 2.526248536658381

Epoch: 6| Step: 4
Training loss: 0.8854971381625301
Validation loss: 2.5577761791314853

Epoch: 6| Step: 5
Training loss: 0.9245959391743847
Validation loss: 2.5925004135620244

Epoch: 6| Step: 6
Training loss: 0.825440355744386
Validation loss: 2.6059418040505355

Epoch: 6| Step: 7
Training loss: 0.6432158717172743
Validation loss: 2.586646909864529

Epoch: 6| Step: 8
Training loss: 0.8666279336331371
Validation loss: 2.5984903643750275

Epoch: 6| Step: 9
Training loss: 0.5749408567114755
Validation loss: 2.5710440298262527

Epoch: 6| Step: 10
Training loss: 0.8217486933554766
Validation loss: 2.570394782539551

Epoch: 6| Step: 11
Training loss: 0.5950811672546099
Validation loss: 2.526194511096797

Epoch: 6| Step: 12
Training loss: 0.5755007698623983
Validation loss: 2.504628226837094

Epoch: 6| Step: 13
Training loss: 0.9823646604588692
Validation loss: 2.480416930295832

Epoch: 324| Step: 0
Training loss: 0.620463141111231
Validation loss: 2.4954317696527233

Epoch: 6| Step: 1
Training loss: 0.5063936218174926
Validation loss: 2.4627878712615803

Epoch: 6| Step: 2
Training loss: 0.5634079598856788
Validation loss: 2.4976262872677046

Epoch: 6| Step: 3
Training loss: 0.7052256675479321
Validation loss: 2.4722036195500396

Epoch: 6| Step: 4
Training loss: 0.5814155035351285
Validation loss: 2.4614796416509686

Epoch: 6| Step: 5
Training loss: 0.5933643393594531
Validation loss: 2.506649041478242

Epoch: 6| Step: 6
Training loss: 0.5678243839277873
Validation loss: 2.520136644796641

Epoch: 6| Step: 7
Training loss: 0.8291081404677771
Validation loss: 2.514719127438395

Epoch: 6| Step: 8
Training loss: 0.9054099826650879
Validation loss: 2.5232496390727954

Epoch: 6| Step: 9
Training loss: 0.8331625683978688
Validation loss: 2.5894600015925344

Epoch: 6| Step: 10
Training loss: 1.1015008679186102
Validation loss: 2.5605487342430306

Epoch: 6| Step: 11
Training loss: 0.70887650438962
Validation loss: 2.5485606913406493

Epoch: 6| Step: 12
Training loss: 0.8289455451244166
Validation loss: 2.5687049596103457

Epoch: 6| Step: 13
Training loss: 0.7140897933451698
Validation loss: 2.5589155463046307

Epoch: 325| Step: 0
Training loss: 0.7315984140450884
Validation loss: 2.5532495087309774

Epoch: 6| Step: 1
Training loss: 0.6012054473644125
Validation loss: 2.504914742117784

Epoch: 6| Step: 2
Training loss: 0.3217341693630935
Validation loss: 2.5700470451019055

Epoch: 6| Step: 3
Training loss: 0.5059409646474622
Validation loss: 2.5092895500619377

Epoch: 6| Step: 4
Training loss: 0.594216238974984
Validation loss: 2.5133132498354276

Epoch: 6| Step: 5
Training loss: 1.1247796266668233
Validation loss: 2.513336676624775

Epoch: 6| Step: 6
Training loss: 0.5585918026336657
Validation loss: 2.5024245656765167

Epoch: 6| Step: 7
Training loss: 0.889057520096547
Validation loss: 2.4731340201897054

Epoch: 6| Step: 8
Training loss: 0.796594345934774
Validation loss: 2.5461647175161977

Epoch: 6| Step: 9
Training loss: 0.8531014072383801
Validation loss: 2.486937227536033

Epoch: 6| Step: 10
Training loss: 0.6365486807205664
Validation loss: 2.5107493114872526

Epoch: 6| Step: 11
Training loss: 0.6246121395162032
Validation loss: 2.5200041978009704

Epoch: 6| Step: 12
Training loss: 0.7283293048593016
Validation loss: 2.527667704183967

Epoch: 6| Step: 13
Training loss: 0.838359283768618
Validation loss: 2.520065241109281

Epoch: 326| Step: 0
Training loss: 0.6669909810939172
Validation loss: 2.515392593616773

Epoch: 6| Step: 1
Training loss: 0.8248005481411049
Validation loss: 2.521896881022009

Epoch: 6| Step: 2
Training loss: 0.41833300182372457
Validation loss: 2.5231546507408074

Epoch: 6| Step: 3
Training loss: 0.6938165795965986
Validation loss: 2.5088629574898547

Epoch: 6| Step: 4
Training loss: 0.3497454948332823
Validation loss: 2.530008153962658

Epoch: 6| Step: 5
Training loss: 0.42735655310384185
Validation loss: 2.5098421990634

Epoch: 6| Step: 6
Training loss: 0.8697241035459218
Validation loss: 2.5144104035247956

Epoch: 6| Step: 7
Training loss: 0.9370262538464391
Validation loss: 2.502995750369019

Epoch: 6| Step: 8
Training loss: 0.6304339695900932
Validation loss: 2.51740644456334

Epoch: 6| Step: 9
Training loss: 0.6460185605710291
Validation loss: 2.504958884927013

Epoch: 6| Step: 10
Training loss: 0.8888320275504606
Validation loss: 2.483864521609016

Epoch: 6| Step: 11
Training loss: 0.49271807758408565
Validation loss: 2.4982969225667153

Epoch: 6| Step: 12
Training loss: 0.7688094108388612
Validation loss: 2.507263460839122

Epoch: 6| Step: 13
Training loss: 0.17172766461024574
Validation loss: 2.5248832851918412

Epoch: 327| Step: 0
Training loss: 0.6098634278516387
Validation loss: 2.5416614452397863

Epoch: 6| Step: 1
Training loss: 0.5758868013319138
Validation loss: 2.493948980372426

Epoch: 6| Step: 2
Training loss: 0.3701326673989588
Validation loss: 2.529071387342608

Epoch: 6| Step: 3
Training loss: 0.7696241526026705
Validation loss: 2.549623119147317

Epoch: 6| Step: 4
Training loss: 0.755118388815906
Validation loss: 2.5303231470148364

Epoch: 6| Step: 5
Training loss: 0.9207450925109487
Validation loss: 2.5095126175536557

Epoch: 6| Step: 6
Training loss: 0.5858173247122076
Validation loss: 2.554835841769874

Epoch: 6| Step: 7
Training loss: 0.9658352471750391
Validation loss: 2.5119805856340753

Epoch: 6| Step: 8
Training loss: 0.8308630250492814
Validation loss: 2.5457868165746276

Epoch: 6| Step: 9
Training loss: 0.5795431528028723
Validation loss: 2.5165426391654493

Epoch: 6| Step: 10
Training loss: 0.4913173279718554
Validation loss: 2.529526567784985

Epoch: 6| Step: 11
Training loss: 0.48131644669606155
Validation loss: 2.5042957899221308

Epoch: 6| Step: 12
Training loss: 0.36766354159263165
Validation loss: 2.518836611355283

Epoch: 6| Step: 13
Training loss: 0.6505249159730373
Validation loss: 2.5119028989895615

Epoch: 328| Step: 0
Training loss: 0.4549555306397069
Validation loss: 2.5152374429670368

Epoch: 6| Step: 1
Training loss: 0.3803674112516303
Validation loss: 2.5122661542361664

Epoch: 6| Step: 2
Training loss: 0.6059437027171578
Validation loss: 2.492119147227808

Epoch: 6| Step: 3
Training loss: 0.7808134385108422
Validation loss: 2.513719305035629

Epoch: 6| Step: 4
Training loss: 1.0090456375031547
Validation loss: 2.4897501357537895

Epoch: 6| Step: 5
Training loss: 0.5371086536749418
Validation loss: 2.494761132802668

Epoch: 6| Step: 6
Training loss: 0.5776010665145337
Validation loss: 2.46638995702428

Epoch: 6| Step: 7
Training loss: 0.6909017500304876
Validation loss: 2.49266047603641

Epoch: 6| Step: 8
Training loss: 0.598437851589488
Validation loss: 2.482045917721412

Epoch: 6| Step: 9
Training loss: 0.5944780604145707
Validation loss: 2.4842156789758754

Epoch: 6| Step: 10
Training loss: 0.4180398327999421
Validation loss: 2.463468120279888

Epoch: 6| Step: 11
Training loss: 0.7610462447839005
Validation loss: 2.5075191305379105

Epoch: 6| Step: 12
Training loss: 0.7643622280497974
Validation loss: 2.50001184399168

Epoch: 6| Step: 13
Training loss: 0.6635406912332867
Validation loss: 2.5218290963888466

Epoch: 329| Step: 0
Training loss: 0.7370480526562962
Validation loss: 2.546444853854044

Epoch: 6| Step: 1
Training loss: 0.39937391755579726
Validation loss: 2.522533343533887

Epoch: 6| Step: 2
Training loss: 0.6495198787439889
Validation loss: 2.530173595051205

Epoch: 6| Step: 3
Training loss: 0.5143468794894072
Validation loss: 2.532044687406414

Epoch: 6| Step: 4
Training loss: 0.5288710623323856
Validation loss: 2.553505957359759

Epoch: 6| Step: 5
Training loss: 0.7816688559189039
Validation loss: 2.4853520999115464

Epoch: 6| Step: 6
Training loss: 0.7750561278537832
Validation loss: 2.5013670198680433

Epoch: 6| Step: 7
Training loss: 0.9546075765616371
Validation loss: 2.527233002101923

Epoch: 6| Step: 8
Training loss: 0.5921228600000901
Validation loss: 2.467881886656275

Epoch: 6| Step: 9
Training loss: 0.7655611206186764
Validation loss: 2.471835823537363

Epoch: 6| Step: 10
Training loss: 0.38774254652886253
Validation loss: 2.493008036469135

Epoch: 6| Step: 11
Training loss: 0.44950921992159126
Validation loss: 2.487440772507561

Epoch: 6| Step: 12
Training loss: 0.5099594799942817
Validation loss: 2.524276221675315

Epoch: 6| Step: 13
Training loss: 0.6352415911971053
Validation loss: 2.4639274230801727

Epoch: 330| Step: 0
Training loss: 0.6009275627802403
Validation loss: 2.5032781601846845

Epoch: 6| Step: 1
Training loss: 0.49155238212071883
Validation loss: 2.5044361318073416

Epoch: 6| Step: 2
Training loss: 0.8028400657854067
Validation loss: 2.4920540521010714

Epoch: 6| Step: 3
Training loss: 0.6376907091427334
Validation loss: 2.5307617780100142

Epoch: 6| Step: 4
Training loss: 0.5406818393088616
Validation loss: 2.542791016688586

Epoch: 6| Step: 5
Training loss: 0.7246159967083942
Validation loss: 2.5269746008851515

Epoch: 6| Step: 6
Training loss: 0.5438145149806538
Validation loss: 2.5100808970693427

Epoch: 6| Step: 7
Training loss: 0.4905033665423883
Validation loss: 2.526705662330679

Epoch: 6| Step: 8
Training loss: 0.7002979666186179
Validation loss: 2.531930526877161

Epoch: 6| Step: 9
Training loss: 0.7778849035996849
Validation loss: 2.525981400919732

Epoch: 6| Step: 10
Training loss: 0.7745537457518933
Validation loss: 2.5040442292881715

Epoch: 6| Step: 11
Training loss: 0.49312762135242877
Validation loss: 2.486821968424813

Epoch: 6| Step: 12
Training loss: 0.7359753479508963
Validation loss: 2.5017898100376645

Epoch: 6| Step: 13
Training loss: 0.3057920535308169
Validation loss: 2.4936173105931143

Epoch: 331| Step: 0
Training loss: 0.552324311428291
Validation loss: 2.4813027951543067

Epoch: 6| Step: 1
Training loss: 0.6829333794135143
Validation loss: 2.468219145999465

Epoch: 6| Step: 2
Training loss: 0.23724472010327796
Validation loss: 2.466076545215403

Epoch: 6| Step: 3
Training loss: 0.7579758458227063
Validation loss: 2.518056274618425

Epoch: 6| Step: 4
Training loss: 0.5064198397443421
Validation loss: 2.5146709511459227

Epoch: 6| Step: 5
Training loss: 0.8584541936305924
Validation loss: 2.5286846421297566

Epoch: 6| Step: 6
Training loss: 0.7933703753761964
Validation loss: 2.550623696862021

Epoch: 6| Step: 7
Training loss: 0.5852633858200555
Validation loss: 2.5033474036284846

Epoch: 6| Step: 8
Training loss: 0.8051087471266597
Validation loss: 2.533209921686472

Epoch: 6| Step: 9
Training loss: 0.5142450362203781
Validation loss: 2.477851001189991

Epoch: 6| Step: 10
Training loss: 0.49057074325776134
Validation loss: 2.522033466402957

Epoch: 6| Step: 11
Training loss: 0.7613216049517981
Validation loss: 2.5033999058699505

Epoch: 6| Step: 12
Training loss: 0.3893266845656882
Validation loss: 2.5013062100093153

Epoch: 6| Step: 13
Training loss: 0.7896804278486892
Validation loss: 2.5120363283013116

Epoch: 332| Step: 0
Training loss: 0.25306640523722246
Validation loss: 2.5004116785865595

Epoch: 6| Step: 1
Training loss: 0.64844308414123
Validation loss: 2.4863154239386684

Epoch: 6| Step: 2
Training loss: 0.5487617371070779
Validation loss: 2.49751500326312

Epoch: 6| Step: 3
Training loss: 0.889312848340853
Validation loss: 2.509222459821133

Epoch: 6| Step: 4
Training loss: 0.5265679197853148
Validation loss: 2.530514215045734

Epoch: 6| Step: 5
Training loss: 0.619357050184258
Validation loss: 2.5410676062252

Epoch: 6| Step: 6
Training loss: 0.7035317833721827
Validation loss: 2.561146103106782

Epoch: 6| Step: 7
Training loss: 0.7451121878799952
Validation loss: 2.5867602482532677

Epoch: 6| Step: 8
Training loss: 0.7245288814450844
Validation loss: 2.54988690088674

Epoch: 6| Step: 9
Training loss: 0.4201878437266092
Validation loss: 2.544821030688524

Epoch: 6| Step: 10
Training loss: 0.5292369625628246
Validation loss: 2.5376775379914824

Epoch: 6| Step: 11
Training loss: 0.7139637434299627
Validation loss: 2.558561712729967

Epoch: 6| Step: 12
Training loss: 0.5637288446115205
Validation loss: 2.5445591186213163

Epoch: 6| Step: 13
Training loss: 0.7241654179924083
Validation loss: 2.522066088645249

Epoch: 333| Step: 0
Training loss: 0.7168025294608377
Validation loss: 2.550785511371772

Epoch: 6| Step: 1
Training loss: 0.7281082691677122
Validation loss: 2.4847882748017938

Epoch: 6| Step: 2
Training loss: 0.577960815828991
Validation loss: 2.527677734915275

Epoch: 6| Step: 3
Training loss: 0.767249388830315
Validation loss: 2.480089948606147

Epoch: 6| Step: 4
Training loss: 0.33277645632282093
Validation loss: 2.4927077453581594

Epoch: 6| Step: 5
Training loss: 0.5764763496358313
Validation loss: 2.495940403022624

Epoch: 6| Step: 6
Training loss: 0.5829327916834215
Validation loss: 2.492606522647702

Epoch: 6| Step: 7
Training loss: 0.6324040542928606
Validation loss: 2.521548204816758

Epoch: 6| Step: 8
Training loss: 0.6137359294327326
Validation loss: 2.5093599455316764

Epoch: 6| Step: 9
Training loss: 0.5462416114424907
Validation loss: 2.5061598374411265

Epoch: 6| Step: 10
Training loss: 0.32029019254835933
Validation loss: 2.5565637499403433

Epoch: 6| Step: 11
Training loss: 0.6690875048465975
Validation loss: 2.55121281844941

Epoch: 6| Step: 12
Training loss: 0.7019056343397584
Validation loss: 2.544074477564467

Epoch: 6| Step: 13
Training loss: 0.6369368758761426
Validation loss: 2.5780308283327558

Epoch: 334| Step: 0
Training loss: 0.7814510849613403
Validation loss: 2.5556996369403424

Epoch: 6| Step: 1
Training loss: 0.4806862780642624
Validation loss: 2.573941662346967

Epoch: 6| Step: 2
Training loss: 0.35043967338556153
Validation loss: 2.558112794055631

Epoch: 6| Step: 3
Training loss: 0.6830535061795889
Validation loss: 2.5282476067725494

Epoch: 6| Step: 4
Training loss: 0.7878352526383182
Validation loss: 2.5222430879315483

Epoch: 6| Step: 5
Training loss: 0.7209632218116592
Validation loss: 2.5158611021974084

Epoch: 6| Step: 6
Training loss: 0.5557528728182626
Validation loss: 2.510376068823144

Epoch: 6| Step: 7
Training loss: 0.7193816767829312
Validation loss: 2.517892583788847

Epoch: 6| Step: 8
Training loss: 0.6432538407467199
Validation loss: 2.526751182749924

Epoch: 6| Step: 9
Training loss: 0.6349330739924913
Validation loss: 2.514479549418178

Epoch: 6| Step: 10
Training loss: 0.5958207311386812
Validation loss: 2.5164688662833967

Epoch: 6| Step: 11
Training loss: 0.37127339883399596
Validation loss: 2.556294080338795

Epoch: 6| Step: 12
Training loss: 0.6572300087553591
Validation loss: 2.511457853744708

Epoch: 6| Step: 13
Training loss: 0.8616359791987982
Validation loss: 2.5399666750595613

Epoch: 335| Step: 0
Training loss: 0.6845499816574664
Validation loss: 2.53191827733117

Epoch: 6| Step: 1
Training loss: 0.7512310177377269
Validation loss: 2.519535872529974

Epoch: 6| Step: 2
Training loss: 0.6535769473147357
Validation loss: 2.5151447379604055

Epoch: 6| Step: 3
Training loss: 0.4573518981312012
Validation loss: 2.549805943779824

Epoch: 6| Step: 4
Training loss: 0.6463677569079241
Validation loss: 2.5260367062444584

Epoch: 6| Step: 5
Training loss: 0.3394777146400346
Validation loss: 2.5366839105392076

Epoch: 6| Step: 6
Training loss: 0.5823208133406658
Validation loss: 2.519115399243908

Epoch: 6| Step: 7
Training loss: 0.6751150916138252
Validation loss: 2.5049681233785823

Epoch: 6| Step: 8
Training loss: 0.2485745591741062
Validation loss: 2.483739844849725

Epoch: 6| Step: 9
Training loss: 0.5641686009505831
Validation loss: 2.487138623330991

Epoch: 6| Step: 10
Training loss: 0.6114472099561841
Validation loss: 2.5295514274693813

Epoch: 6| Step: 11
Training loss: 0.5818143350791697
Validation loss: 2.565757284952963

Epoch: 6| Step: 12
Training loss: 0.7140809037990095
Validation loss: 2.5586245684852624

Epoch: 6| Step: 13
Training loss: 0.7619072705288584
Validation loss: 2.5250495849325025

Epoch: 336| Step: 0
Training loss: 0.47883766392613825
Validation loss: 2.5303753225657966

Epoch: 6| Step: 1
Training loss: 0.7440837928516212
Validation loss: 2.534453063011853

Epoch: 6| Step: 2
Training loss: 0.3925746329232901
Validation loss: 2.5207760484926274

Epoch: 6| Step: 3
Training loss: 0.7471584293034219
Validation loss: 2.5378791872501387

Epoch: 6| Step: 4
Training loss: 0.5695744271780865
Validation loss: 2.5126623686190936

Epoch: 6| Step: 5
Training loss: 0.5125891584672005
Validation loss: 2.535161576173108

Epoch: 6| Step: 6
Training loss: 0.7676184257818415
Validation loss: 2.5342957992077175

Epoch: 6| Step: 7
Training loss: 0.4449227116202643
Validation loss: 2.525181216025185

Epoch: 6| Step: 8
Training loss: 0.31589686044634485
Validation loss: 2.5656255733161655

Epoch: 6| Step: 9
Training loss: 0.38546449347327333
Validation loss: 2.5392902604677414

Epoch: 6| Step: 10
Training loss: 0.7663499164001096
Validation loss: 2.5116947406212056

Epoch: 6| Step: 11
Training loss: 0.7101668907853926
Validation loss: 2.528431013279718

Epoch: 6| Step: 12
Training loss: 0.45695364529597504
Validation loss: 2.527682590018347

Epoch: 6| Step: 13
Training loss: 0.48945120455645974
Validation loss: 2.5440266914067085

Epoch: 337| Step: 0
Training loss: 0.43540947290650195
Validation loss: 2.5371297861549307

Epoch: 6| Step: 1
Training loss: 0.3882279472683336
Validation loss: 2.5381828890926306

Epoch: 6| Step: 2
Training loss: 0.6093798417119102
Validation loss: 2.5159203680727344

Epoch: 6| Step: 3
Training loss: 0.6376459123016042
Validation loss: 2.5197914283640177

Epoch: 6| Step: 4
Training loss: 0.734613907282892
Validation loss: 2.525345067874149

Epoch: 6| Step: 5
Training loss: 0.5097210744047393
Validation loss: 2.5505434069309376

Epoch: 6| Step: 6
Training loss: 0.6102053535816725
Validation loss: 2.512453383407801

Epoch: 6| Step: 7
Training loss: 0.4234565301257625
Validation loss: 2.5114284265874462

Epoch: 6| Step: 8
Training loss: 0.44532894639547466
Validation loss: 2.5233009611552712

Epoch: 6| Step: 9
Training loss: 0.691060168187583
Validation loss: 2.5039922770389245

Epoch: 6| Step: 10
Training loss: 0.44265725084185603
Validation loss: 2.5005590080481404

Epoch: 6| Step: 11
Training loss: 0.7062986171496617
Validation loss: 2.532286839406263

Epoch: 6| Step: 12
Training loss: 0.7089789103988353
Validation loss: 2.5047626332122785

Epoch: 6| Step: 13
Training loss: 0.5653663296689392
Validation loss: 2.5037922092445726

Epoch: 338| Step: 0
Training loss: 0.4973734173209067
Validation loss: 2.53801459333955

Epoch: 6| Step: 1
Training loss: 0.6484606635311172
Validation loss: 2.5126222291267806

Epoch: 6| Step: 2
Training loss: 0.655506984973183
Validation loss: 2.508637683122309

Epoch: 6| Step: 3
Training loss: 0.4067821318766376
Validation loss: 2.505291139710577

Epoch: 6| Step: 4
Training loss: 0.7440070886017884
Validation loss: 2.5160274847320045

Epoch: 6| Step: 5
Training loss: 0.6411820060345128
Validation loss: 2.4964012865363268

Epoch: 6| Step: 6
Training loss: 0.28608498808331007
Validation loss: 2.5193004719001153

Epoch: 6| Step: 7
Training loss: 0.49624918207346197
Validation loss: 2.481544989914697

Epoch: 6| Step: 8
Training loss: 0.670853303726567
Validation loss: 2.5129003998448822

Epoch: 6| Step: 9
Training loss: 0.8254879404408234
Validation loss: 2.505570471189986

Epoch: 6| Step: 10
Training loss: 0.22871817065104466
Validation loss: 2.534248359750756

Epoch: 6| Step: 11
Training loss: 0.5809986504212429
Validation loss: 2.5568774757789665

Epoch: 6| Step: 12
Training loss: 0.6339602716721123
Validation loss: 2.5766167552955856

Epoch: 6| Step: 13
Training loss: 0.2864649410641669
Validation loss: 2.5236917363401763

Epoch: 339| Step: 0
Training loss: 0.590744644237622
Validation loss: 2.562709074497694

Epoch: 6| Step: 1
Training loss: 0.4944029402041274
Validation loss: 2.537254961044298

Epoch: 6| Step: 2
Training loss: 0.3751360527235641
Validation loss: 2.5447368986977446

Epoch: 6| Step: 3
Training loss: 0.6597673523396386
Validation loss: 2.524231957623643

Epoch: 6| Step: 4
Training loss: 0.4373002618154269
Validation loss: 2.4950326566856287

Epoch: 6| Step: 5
Training loss: 0.6864099096682162
Validation loss: 2.482610384234878

Epoch: 6| Step: 6
Training loss: 0.5074023718018783
Validation loss: 2.5135320957052736

Epoch: 6| Step: 7
Training loss: 0.47290629874080264
Validation loss: 2.489617893801019

Epoch: 6| Step: 8
Training loss: 0.558424543882591
Validation loss: 2.527252449714113

Epoch: 6| Step: 9
Training loss: 0.8572811975840305
Validation loss: 2.540217558569381

Epoch: 6| Step: 10
Training loss: 0.5778881309448238
Validation loss: 2.489409083081577

Epoch: 6| Step: 11
Training loss: 0.4401459382528132
Validation loss: 2.5118221944933325

Epoch: 6| Step: 12
Training loss: 0.6711900901698277
Validation loss: 2.5098487852675584

Epoch: 6| Step: 13
Training loss: 0.5214585715778624
Validation loss: 2.5197179820664664

Epoch: 340| Step: 0
Training loss: 0.6348158361676463
Validation loss: 2.5495901959177356

Epoch: 6| Step: 1
Training loss: 0.5520301079434573
Validation loss: 2.5512868050482456

Epoch: 6| Step: 2
Training loss: 0.6445084076503916
Validation loss: 2.5199851413652707

Epoch: 6| Step: 3
Training loss: 0.6017475091385805
Validation loss: 2.567176424459378

Epoch: 6| Step: 4
Training loss: 0.6961781331815827
Validation loss: 2.549720228283026

Epoch: 6| Step: 5
Training loss: 0.7104249720679906
Validation loss: 2.485280527739294

Epoch: 6| Step: 6
Training loss: 0.7613139323932052
Validation loss: 2.4830265834644223

Epoch: 6| Step: 7
Training loss: 0.36116642813563926
Validation loss: 2.5097420596652396

Epoch: 6| Step: 8
Training loss: 0.38796246066086637
Validation loss: 2.4946309579805845

Epoch: 6| Step: 9
Training loss: 0.4402647703521044
Validation loss: 2.480538530945129

Epoch: 6| Step: 10
Training loss: 0.3508999515361921
Validation loss: 2.492810959081518

Epoch: 6| Step: 11
Training loss: 0.6699857542316949
Validation loss: 2.474384911918976

Epoch: 6| Step: 12
Training loss: 0.6600746239754325
Validation loss: 2.5389802117655873

Epoch: 6| Step: 13
Training loss: 0.43160487583617285
Validation loss: 2.5293273571725963

Epoch: 341| Step: 0
Training loss: 0.5096609658562177
Validation loss: 2.5083662399337308

Epoch: 6| Step: 1
Training loss: 0.6081483427940797
Validation loss: 2.498329477131598

Epoch: 6| Step: 2
Training loss: 0.7057326388302981
Validation loss: 2.5451566278306097

Epoch: 6| Step: 3
Training loss: 0.6364098484116462
Validation loss: 2.5181252257178515

Epoch: 6| Step: 4
Training loss: 0.7886560734171495
Validation loss: 2.5323126013501303

Epoch: 6| Step: 5
Training loss: 0.5249711812147724
Validation loss: 2.568665644972689

Epoch: 6| Step: 6
Training loss: 0.5267916579754045
Validation loss: 2.5311981680994546

Epoch: 6| Step: 7
Training loss: 0.32417499292920393
Validation loss: 2.5155041150384143

Epoch: 6| Step: 8
Training loss: 0.440625234022146
Validation loss: 2.499674048760779

Epoch: 6| Step: 9
Training loss: 0.4226404768843996
Validation loss: 2.4976861818680636

Epoch: 6| Step: 10
Training loss: 0.7439300559580897
Validation loss: 2.4886865169746946

Epoch: 6| Step: 11
Training loss: 0.2939626999081714
Validation loss: 2.47615018179868

Epoch: 6| Step: 12
Training loss: 0.6853233038054598
Validation loss: 2.481759744521753

Epoch: 6| Step: 13
Training loss: 0.5871674661837543
Validation loss: 2.508605152981204

Epoch: 342| Step: 0
Training loss: 0.7615219253168896
Validation loss: 2.5038303442255736

Epoch: 6| Step: 1
Training loss: 0.563361356121003
Validation loss: 2.5377062041457554

Epoch: 6| Step: 2
Training loss: 0.6105259028351576
Validation loss: 2.5316584439993273

Epoch: 6| Step: 3
Training loss: 0.5053839198157277
Validation loss: 2.550828144798404

Epoch: 6| Step: 4
Training loss: 0.4423143952876062
Validation loss: 2.6038103410324136

Epoch: 6| Step: 5
Training loss: 0.4144371065573104
Validation loss: 2.5544769279603443

Epoch: 6| Step: 6
Training loss: 0.7130135208174739
Validation loss: 2.5405481588302647

Epoch: 6| Step: 7
Training loss: 0.4356523394659862
Validation loss: 2.5525083123151764

Epoch: 6| Step: 8
Training loss: 0.316899609635252
Validation loss: 2.509319726139597

Epoch: 6| Step: 9
Training loss: 0.55602369419732
Validation loss: 2.5085689617837734

Epoch: 6| Step: 10
Training loss: 0.78189754352957
Validation loss: 2.504204950501881

Epoch: 6| Step: 11
Training loss: 0.6045988170639969
Validation loss: 2.4836977753269607

Epoch: 6| Step: 12
Training loss: 0.583218279345924
Validation loss: 2.4719066161672187

Epoch: 6| Step: 13
Training loss: 0.6914103017569752
Validation loss: 2.4472529370042415

Epoch: 343| Step: 0
Training loss: 0.44289383835097024
Validation loss: 2.477305276998939

Epoch: 6| Step: 1
Training loss: 0.8104128071775609
Validation loss: 2.4803520926452163

Epoch: 6| Step: 2
Training loss: 0.693770939278988
Validation loss: 2.4719623721617046

Epoch: 6| Step: 3
Training loss: 0.6858138952787726
Validation loss: 2.4757017704580018

Epoch: 6| Step: 4
Training loss: 0.452966925573606
Validation loss: 2.5096366574988602

Epoch: 6| Step: 5
Training loss: 0.36169369736459617
Validation loss: 2.4914458990235695

Epoch: 6| Step: 6
Training loss: 0.5387044076590884
Validation loss: 2.541348791661492

Epoch: 6| Step: 7
Training loss: 0.493712997860808
Validation loss: 2.5310102541916155

Epoch: 6| Step: 8
Training loss: 0.5237323443002031
Validation loss: 2.508386847161249

Epoch: 6| Step: 9
Training loss: 0.4091560156627856
Validation loss: 2.571994704157868

Epoch: 6| Step: 10
Training loss: 0.4609051547582226
Validation loss: 2.5359645929882646

Epoch: 6| Step: 11
Training loss: 0.68681628735597
Validation loss: 2.544233521986133

Epoch: 6| Step: 12
Training loss: 0.5718062187481099
Validation loss: 2.5527737657739227

Epoch: 6| Step: 13
Training loss: 0.5463627459710378
Validation loss: 2.549965638096679

Epoch: 344| Step: 0
Training loss: 0.731555558619429
Validation loss: 2.563020673287968

Epoch: 6| Step: 1
Training loss: 0.3232583448169313
Validation loss: 2.580393563075492

Epoch: 6| Step: 2
Training loss: 0.5903534613191136
Validation loss: 2.553536064202449

Epoch: 6| Step: 3
Training loss: 0.36399721534418406
Validation loss: 2.5690694965709477

Epoch: 6| Step: 4
Training loss: 0.5938966971424227
Validation loss: 2.527151325365761

Epoch: 6| Step: 5
Training loss: 0.74688566830729
Validation loss: 2.506265907502045

Epoch: 6| Step: 6
Training loss: 0.5720553483760836
Validation loss: 2.511507229306405

Epoch: 6| Step: 7
Training loss: 0.6883197578803327
Validation loss: 2.4951197366344453

Epoch: 6| Step: 8
Training loss: 0.39058585924509637
Validation loss: 2.4782077516604395

Epoch: 6| Step: 9
Training loss: 0.4517461581444154
Validation loss: 2.51514220504447

Epoch: 6| Step: 10
Training loss: 0.5435768399811546
Validation loss: 2.505400173034414

Epoch: 6| Step: 11
Training loss: 0.33138125131539103
Validation loss: 2.515186436423096

Epoch: 6| Step: 12
Training loss: 0.7028395815220211
Validation loss: 2.51636789641874

Epoch: 6| Step: 13
Training loss: 0.7631489556104033
Validation loss: 2.5316177864618634

Epoch: 345| Step: 0
Training loss: 0.6318079899498538
Validation loss: 2.5452188995573133

Epoch: 6| Step: 1
Training loss: 0.7030374260513405
Validation loss: 2.57026862580698

Epoch: 6| Step: 2
Training loss: 0.3628242243039672
Validation loss: 2.529369508504356

Epoch: 6| Step: 3
Training loss: 0.4623139406671442
Validation loss: 2.535754659029276

Epoch: 6| Step: 4
Training loss: 0.6411442861737183
Validation loss: 2.529363996563997

Epoch: 6| Step: 5
Training loss: 0.45212029190290975
Validation loss: 2.5410354226445806

Epoch: 6| Step: 6
Training loss: 0.48619856123497573
Validation loss: 2.5236324866244098

Epoch: 6| Step: 7
Training loss: 0.6442270196702634
Validation loss: 2.526069752763589

Epoch: 6| Step: 8
Training loss: 0.7309893216815657
Validation loss: 2.4998712506520064

Epoch: 6| Step: 9
Training loss: 0.36817768183037297
Validation loss: 2.514695019273118

Epoch: 6| Step: 10
Training loss: 0.4056803671104449
Validation loss: 2.5308520167393973

Epoch: 6| Step: 11
Training loss: 0.6329020919486167
Validation loss: 2.523593645932753

Epoch: 6| Step: 12
Training loss: 0.5186852472175706
Validation loss: 2.4752589944700953

Epoch: 6| Step: 13
Training loss: 0.6783853312447775
Validation loss: 2.4946522747089492

Epoch: 346| Step: 0
Training loss: 0.29098244292265024
Validation loss: 2.500873489986096

Epoch: 6| Step: 1
Training loss: 0.4581830923607082
Validation loss: 2.5107826169061016

Epoch: 6| Step: 2
Training loss: 0.5160456011235488
Validation loss: 2.503782511839417

Epoch: 6| Step: 3
Training loss: 0.7874034398537423
Validation loss: 2.5091153612112276

Epoch: 6| Step: 4
Training loss: 0.4713368245793167
Validation loss: 2.5329322020795915

Epoch: 6| Step: 5
Training loss: 0.34714399595693346
Validation loss: 2.5436189101153417

Epoch: 6| Step: 6
Training loss: 0.34875334464626234
Validation loss: 2.5312609705857527

Epoch: 6| Step: 7
Training loss: 0.4136151110036756
Validation loss: 2.5341965057170937

Epoch: 6| Step: 8
Training loss: 0.7377632382535632
Validation loss: 2.5767751631048204

Epoch: 6| Step: 9
Training loss: 0.740885264704487
Validation loss: 2.5814286102837403

Epoch: 6| Step: 10
Training loss: 0.5146480321430151
Validation loss: 2.5649500613438643

Epoch: 6| Step: 11
Training loss: 0.6840456095876164
Validation loss: 2.5617850652168475

Epoch: 6| Step: 12
Training loss: 0.5865229415764428
Validation loss: 2.562055015394729

Epoch: 6| Step: 13
Training loss: 0.45361206580123425
Validation loss: 2.5585304546127983

Epoch: 347| Step: 0
Training loss: 0.3743891111207731
Validation loss: 2.5227805799825287

Epoch: 6| Step: 1
Training loss: 0.7091743067708253
Validation loss: 2.518526931208504

Epoch: 6| Step: 2
Training loss: 0.6216131473732962
Validation loss: 2.5386720368160134

Epoch: 6| Step: 3
Training loss: 0.6698441529856725
Validation loss: 2.5416243368248654

Epoch: 6| Step: 4
Training loss: 0.45818453960011296
Validation loss: 2.5449305483146802

Epoch: 6| Step: 5
Training loss: 0.5931193616576962
Validation loss: 2.539152227666849

Epoch: 6| Step: 6
Training loss: 0.6645403769391274
Validation loss: 2.5512145036180853

Epoch: 6| Step: 7
Training loss: 0.49712515417916237
Validation loss: 2.5715371204369513

Epoch: 6| Step: 8
Training loss: 0.4238648816180363
Validation loss: 2.5671637628910244

Epoch: 6| Step: 9
Training loss: 0.5247834394758313
Validation loss: 2.550891044384549

Epoch: 6| Step: 10
Training loss: 0.6135695441949996
Validation loss: 2.5541829532957254

Epoch: 6| Step: 11
Training loss: 0.5579555573795933
Validation loss: 2.601194566145278

Epoch: 6| Step: 12
Training loss: 0.460962698942714
Validation loss: 2.5747365277535796

Epoch: 6| Step: 13
Training loss: 0.4895184216856414
Validation loss: 2.5915665502895155

Epoch: 348| Step: 0
Training loss: 0.7835756400574269
Validation loss: 2.6212993266305884

Epoch: 6| Step: 1
Training loss: 0.6068419604436884
Validation loss: 2.5839317833013484

Epoch: 6| Step: 2
Training loss: 0.601892578921983
Validation loss: 2.5827315665332415

Epoch: 6| Step: 3
Training loss: 0.5340146327567739
Validation loss: 2.5979846619373794

Epoch: 6| Step: 4
Training loss: 0.5284120547024119
Validation loss: 2.572115783739736

Epoch: 6| Step: 5
Training loss: 0.3949519265774646
Validation loss: 2.564647737934913

Epoch: 6| Step: 6
Training loss: 0.5425423244367548
Validation loss: 2.5516138019466585

Epoch: 6| Step: 7
Training loss: 0.4158292361798514
Validation loss: 2.5767358223608907

Epoch: 6| Step: 8
Training loss: 0.4901321730143546
Validation loss: 2.5323798846785404

Epoch: 6| Step: 9
Training loss: 0.6480937644178228
Validation loss: 2.5569464498120205

Epoch: 6| Step: 10
Training loss: 0.6118149449117125
Validation loss: 2.505403834717449

Epoch: 6| Step: 11
Training loss: 0.439431660445847
Validation loss: 2.497274113521566

Epoch: 6| Step: 12
Training loss: 0.44453065399505404
Validation loss: 2.52525214663618

Epoch: 6| Step: 13
Training loss: 0.19429128699402265
Validation loss: 2.5444122190193585

Epoch: 349| Step: 0
Training loss: 0.6109294383500066
Validation loss: 2.5398025017429666

Epoch: 6| Step: 1
Training loss: 0.545991429032834
Validation loss: 2.5086309593549516

Epoch: 6| Step: 2
Training loss: 0.2794222916935578
Validation loss: 2.569380496122753

Epoch: 6| Step: 3
Training loss: 0.5262635930586911
Validation loss: 2.5551587012970116

Epoch: 6| Step: 4
Training loss: 0.3627624909651311
Validation loss: 2.5672904324338464

Epoch: 6| Step: 5
Training loss: 0.41739572479167936
Validation loss: 2.571026624032383

Epoch: 6| Step: 6
Training loss: 0.7938148231769695
Validation loss: 2.5648737022084798

Epoch: 6| Step: 7
Training loss: 0.5596623370010881
Validation loss: 2.517560202411157

Epoch: 6| Step: 8
Training loss: 0.40849137053835793
Validation loss: 2.536138394387487

Epoch: 6| Step: 9
Training loss: 0.594463772647677
Validation loss: 2.5168109906473055

Epoch: 6| Step: 10
Training loss: 0.3723015054421287
Validation loss: 2.5174750611160137

Epoch: 6| Step: 11
Training loss: 0.589393191011344
Validation loss: 2.5140385059069867

Epoch: 6| Step: 12
Training loss: 0.5197277987987633
Validation loss: 2.564819552681587

Epoch: 6| Step: 13
Training loss: 0.4775712952140292
Validation loss: 2.547115488460866

Epoch: 350| Step: 0
Training loss: 0.4782030914461186
Validation loss: 2.546106493954556

Epoch: 6| Step: 1
Training loss: 0.6490361311454995
Validation loss: 2.5320888756295337

Epoch: 6| Step: 2
Training loss: 0.4876158185464604
Validation loss: 2.513288076529197

Epoch: 6| Step: 3
Training loss: 0.7475727859834236
Validation loss: 2.490908793314455

Epoch: 6| Step: 4
Training loss: 0.22976302540076046
Validation loss: 2.5192343443191842

Epoch: 6| Step: 5
Training loss: 0.493375842256796
Validation loss: 2.5166591535653167

Epoch: 6| Step: 6
Training loss: 0.4446760615514955
Validation loss: 2.527344660389438

Epoch: 6| Step: 7
Training loss: 0.47076762220508594
Validation loss: 2.568468403998419

Epoch: 6| Step: 8
Training loss: 0.42881745772560054
Validation loss: 2.5435049505721214

Epoch: 6| Step: 9
Training loss: 0.3949576802157607
Validation loss: 2.5497569614787996

Epoch: 6| Step: 10
Training loss: 0.6695858304401101
Validation loss: 2.5585656324925563

Epoch: 6| Step: 11
Training loss: 0.42128010591298265
Validation loss: 2.544966555853788

Epoch: 6| Step: 12
Training loss: 0.5067644895788396
Validation loss: 2.504589034366568

Epoch: 6| Step: 13
Training loss: 0.7309423125370768
Validation loss: 2.5006091949697216

Epoch: 351| Step: 0
Training loss: 0.6638165411129819
Validation loss: 2.503490556383696

Epoch: 6| Step: 1
Training loss: 0.5017724212859991
Validation loss: 2.5497665674831613

Epoch: 6| Step: 2
Training loss: 0.5393878121031267
Validation loss: 2.563497997782245

Epoch: 6| Step: 3
Training loss: 0.3562842018039291
Validation loss: 2.5622837346555634

Epoch: 6| Step: 4
Training loss: 0.40059093023989545
Validation loss: 2.5319654739047146

Epoch: 6| Step: 5
Training loss: 0.3481009350374261
Validation loss: 2.5434633101764494

Epoch: 6| Step: 6
Training loss: 0.6439730452263184
Validation loss: 2.5427442852040745

Epoch: 6| Step: 7
Training loss: 0.7383434531836531
Validation loss: 2.5491594836491904

Epoch: 6| Step: 8
Training loss: 0.3459983685639678
Validation loss: 2.559938975322718

Epoch: 6| Step: 9
Training loss: 0.4451439521780629
Validation loss: 2.5548099667719173

Epoch: 6| Step: 10
Training loss: 0.5061806501760417
Validation loss: 2.5544653023784596

Epoch: 6| Step: 11
Training loss: 0.4637438800952916
Validation loss: 2.57540755709883

Epoch: 6| Step: 12
Training loss: 0.4046399416281589
Validation loss: 2.5355143371663362

Epoch: 6| Step: 13
Training loss: 0.5624375573573765
Validation loss: 2.5664215274733846

Epoch: 352| Step: 0
Training loss: 0.45253781387229286
Validation loss: 2.534177566120569

Epoch: 6| Step: 1
Training loss: 0.4169193892173059
Validation loss: 2.542026346727147

Epoch: 6| Step: 2
Training loss: 0.7766842368666623
Validation loss: 2.543378919584993

Epoch: 6| Step: 3
Training loss: 0.5521169658229211
Validation loss: 2.495049886737213

Epoch: 6| Step: 4
Training loss: 0.6858471595866085
Validation loss: 2.55246532528841

Epoch: 6| Step: 5
Training loss: 0.22586130287194744
Validation loss: 2.556577507380605

Epoch: 6| Step: 6
Training loss: 0.5338769644234649
Validation loss: 2.558757158484586

Epoch: 6| Step: 7
Training loss: 0.3299833082543744
Validation loss: 2.5354570484989236

Epoch: 6| Step: 8
Training loss: 0.5837175403939625
Validation loss: 2.533490157805385

Epoch: 6| Step: 9
Training loss: 0.3431265226966132
Validation loss: 2.5376305779770054

Epoch: 6| Step: 10
Training loss: 0.5280201847415849
Validation loss: 2.5184714385754696

Epoch: 6| Step: 11
Training loss: 0.5810766648696271
Validation loss: 2.5457626521739605

Epoch: 6| Step: 12
Training loss: 0.5894164501836807
Validation loss: 2.5200910099853644

Epoch: 6| Step: 13
Training loss: 0.20039491704616372
Validation loss: 2.527545312871046

Epoch: 353| Step: 0
Training loss: 0.5802955862034211
Validation loss: 2.5510745243077606

Epoch: 6| Step: 1
Training loss: 0.3783454677901669
Validation loss: 2.5658558296962823

Epoch: 6| Step: 2
Training loss: 0.5255232576201532
Validation loss: 2.5369581757719835

Epoch: 6| Step: 3
Training loss: 0.40170285187891913
Validation loss: 2.5540485720195982

Epoch: 6| Step: 4
Training loss: 0.4243159145971332
Validation loss: 2.54195314652449

Epoch: 6| Step: 5
Training loss: 0.5121297277949742
Validation loss: 2.4992181724465588

Epoch: 6| Step: 6
Training loss: 0.6485273459822538
Validation loss: 2.533645194473475

Epoch: 6| Step: 7
Training loss: 0.35762158010421613
Validation loss: 2.5136940695042895

Epoch: 6| Step: 8
Training loss: 0.6285095385250229
Validation loss: 2.499062606464233

Epoch: 6| Step: 9
Training loss: 0.6639790650853478
Validation loss: 2.5426706549834646

Epoch: 6| Step: 10
Training loss: 0.5848032845581015
Validation loss: 2.5393585845235855

Epoch: 6| Step: 11
Training loss: 0.44285186423010203
Validation loss: 2.5308475941715343

Epoch: 6| Step: 12
Training loss: 0.4457120942961003
Validation loss: 2.527334565952722

Epoch: 6| Step: 13
Training loss: 0.18986203611868377
Validation loss: 2.5680127336065426

Epoch: 354| Step: 0
Training loss: 0.40296244042061785
Validation loss: 2.51105461410817

Epoch: 6| Step: 1
Training loss: 0.39945272990669217
Validation loss: 2.518441925917321

Epoch: 6| Step: 2
Training loss: 0.3449558543730431
Validation loss: 2.5296040694187307

Epoch: 6| Step: 3
Training loss: 0.5713298293998142
Validation loss: 2.522835422491903

Epoch: 6| Step: 4
Training loss: 0.6190290621296577
Validation loss: 2.515372661412678

Epoch: 6| Step: 5
Training loss: 0.5839898099614489
Validation loss: 2.5202581660857817

Epoch: 6| Step: 6
Training loss: 0.4011511673824855
Validation loss: 2.5312082096540767

Epoch: 6| Step: 7
Training loss: 0.22404306586829378
Validation loss: 2.5534543448035643

Epoch: 6| Step: 8
Training loss: 0.4632589588945921
Validation loss: 2.5366361650499663

Epoch: 6| Step: 9
Training loss: 0.3311980958076173
Validation loss: 2.513216979116456

Epoch: 6| Step: 10
Training loss: 0.41294140462875456
Validation loss: 2.5135069429498538

Epoch: 6| Step: 11
Training loss: 0.7297575236994793
Validation loss: 2.4926947708357083

Epoch: 6| Step: 12
Training loss: 0.7440477848961055
Validation loss: 2.5440387637415016

Epoch: 6| Step: 13
Training loss: 0.6185836452767874
Validation loss: 2.5047206302036376

Epoch: 355| Step: 0
Training loss: 0.45056874970392985
Validation loss: 2.46658528943953

Epoch: 6| Step: 1
Training loss: 0.4179484995276886
Validation loss: 2.518746707301073

Epoch: 6| Step: 2
Training loss: 0.4238438757153928
Validation loss: 2.49815118784459

Epoch: 6| Step: 3
Training loss: 0.5668942946795775
Validation loss: 2.48537241367334

Epoch: 6| Step: 4
Training loss: 0.6032326785010448
Validation loss: 2.50720897199257

Epoch: 6| Step: 5
Training loss: 0.5353801286849413
Validation loss: 2.4809416279087557

Epoch: 6| Step: 6
Training loss: 0.4684496871248508
Validation loss: 2.4871004787692157

Epoch: 6| Step: 7
Training loss: 0.6580296862378443
Validation loss: 2.450027415273075

Epoch: 6| Step: 8
Training loss: 0.5529568766892686
Validation loss: 2.4607921582815004

Epoch: 6| Step: 9
Training loss: 0.5329253203122147
Validation loss: 2.468514614636209

Epoch: 6| Step: 10
Training loss: 0.6945205636162457
Validation loss: 2.44673513271694

Epoch: 6| Step: 11
Training loss: 0.32041332937411626
Validation loss: 2.449278680135851

Epoch: 6| Step: 12
Training loss: 0.4883137043657712
Validation loss: 2.4535561501374725

Epoch: 6| Step: 13
Training loss: 0.44138839145419245
Validation loss: 2.456882978572413

Epoch: 356| Step: 0
Training loss: 0.3145304756515075
Validation loss: 2.5072109720169555

Epoch: 6| Step: 1
Training loss: 0.5267755909240285
Validation loss: 2.4830166573160284

Epoch: 6| Step: 2
Training loss: 0.6035509808995424
Validation loss: 2.5233861136416604

Epoch: 6| Step: 3
Training loss: 0.3519177972673945
Validation loss: 2.4923127869030597

Epoch: 6| Step: 4
Training loss: 0.31926453518320935
Validation loss: 2.546659775948615

Epoch: 6| Step: 5
Training loss: 0.725970857981144
Validation loss: 2.534168574770202

Epoch: 6| Step: 6
Training loss: 0.45893340132092364
Validation loss: 2.5048442882469937

Epoch: 6| Step: 7
Training loss: 0.7233970350644008
Validation loss: 2.5874021312198767

Epoch: 6| Step: 8
Training loss: 0.44462562591663113
Validation loss: 2.5601833985954046

Epoch: 6| Step: 9
Training loss: 0.5019136108994929
Validation loss: 2.5514702092875465

Epoch: 6| Step: 10
Training loss: 0.3836221113422481
Validation loss: 2.551343120305161

Epoch: 6| Step: 11
Training loss: 0.6114542285666602
Validation loss: 2.5348384108139834

Epoch: 6| Step: 12
Training loss: 0.6660021112139348
Validation loss: 2.513569358772855

Epoch: 6| Step: 13
Training loss: 0.31858523963161983
Validation loss: 2.481034742962646

Epoch: 357| Step: 0
Training loss: 0.6176030655227687
Validation loss: 2.540491510937822

Epoch: 6| Step: 1
Training loss: 0.49881354768464026
Validation loss: 2.507307497882147

Epoch: 6| Step: 2
Training loss: 0.5567382191549419
Validation loss: 2.5103604686521113

Epoch: 6| Step: 3
Training loss: 0.6023485324536173
Validation loss: 2.512488732975664

Epoch: 6| Step: 4
Training loss: 0.5182700660195799
Validation loss: 2.5190808794731225

Epoch: 6| Step: 5
Training loss: 0.5592778958050958
Validation loss: 2.502299682605769

Epoch: 6| Step: 6
Training loss: 0.365831814659952
Validation loss: 2.5345918185165988

Epoch: 6| Step: 7
Training loss: 0.4242480434750258
Validation loss: 2.4827693188322906

Epoch: 6| Step: 8
Training loss: 0.4600684815722612
Validation loss: 2.5048670112926885

Epoch: 6| Step: 9
Training loss: 0.5449435322057201
Validation loss: 2.5152215926538783

Epoch: 6| Step: 10
Training loss: 0.47544022037334105
Validation loss: 2.529352928810951

Epoch: 6| Step: 11
Training loss: 0.42152803776436415
Validation loss: 2.528326390228136

Epoch: 6| Step: 12
Training loss: 0.313398226638413
Validation loss: 2.524971463767004

Epoch: 6| Step: 13
Training loss: 0.4231171159559134
Validation loss: 2.533001418247398

Epoch: 358| Step: 0
Training loss: 0.4507617324755711
Validation loss: 2.55445346398121

Epoch: 6| Step: 1
Training loss: 0.35543540127441314
Validation loss: 2.54651101477891

Epoch: 6| Step: 2
Training loss: 0.534976288546318
Validation loss: 2.5355586777537895

Epoch: 6| Step: 3
Training loss: 0.30505963365927213
Validation loss: 2.5570860284805206

Epoch: 6| Step: 4
Training loss: 0.4055525588370496
Validation loss: 2.5497317809874533

Epoch: 6| Step: 5
Training loss: 0.5157319738221388
Validation loss: 2.549565997178494

Epoch: 6| Step: 6
Training loss: 0.17353017324357098
Validation loss: 2.527282500071244

Epoch: 6| Step: 7
Training loss: 0.6228121611368853
Validation loss: 2.5309569116856836

Epoch: 6| Step: 8
Training loss: 0.6863228082858017
Validation loss: 2.5249003359094253

Epoch: 6| Step: 9
Training loss: 0.4272025298660713
Validation loss: 2.5058432894001905

Epoch: 6| Step: 10
Training loss: 0.5382980233334911
Validation loss: 2.501654499952923

Epoch: 6| Step: 11
Training loss: 0.5007448608698456
Validation loss: 2.5044470013035407

Epoch: 6| Step: 12
Training loss: 0.4357301471847213
Validation loss: 2.5195819579676275

Epoch: 6| Step: 13
Training loss: 0.4047787692275901
Validation loss: 2.5492309543672134

Epoch: 359| Step: 0
Training loss: 0.5196315697205807
Validation loss: 2.5351640890874254

Epoch: 6| Step: 1
Training loss: 0.25783790116454836
Validation loss: 2.558434028590517

Epoch: 6| Step: 2
Training loss: 0.3819210221112086
Validation loss: 2.5288721986572824

Epoch: 6| Step: 3
Training loss: 0.4645187620299361
Validation loss: 2.537681279884521

Epoch: 6| Step: 4
Training loss: 0.7013849556270219
Validation loss: 2.5192938508757874

Epoch: 6| Step: 5
Training loss: 0.3615471253551037
Validation loss: 2.5329044747998983

Epoch: 6| Step: 6
Training loss: 0.5273628796533929
Validation loss: 2.5224710245075155

Epoch: 6| Step: 7
Training loss: 0.5652380636710421
Validation loss: 2.5169585865103867

Epoch: 6| Step: 8
Training loss: 0.4643473980480043
Validation loss: 2.557295324055074

Epoch: 6| Step: 9
Training loss: 0.4420598010823894
Validation loss: 2.510203818198253

Epoch: 6| Step: 10
Training loss: 0.4417671820985815
Validation loss: 2.5196734486928802

Epoch: 6| Step: 11
Training loss: 0.37627311999869123
Validation loss: 2.5078879366665574

Epoch: 6| Step: 12
Training loss: 0.5606448788983175
Validation loss: 2.510094121317034

Epoch: 6| Step: 13
Training loss: 0.4714448079444612
Validation loss: 2.5398675285733217

Epoch: 360| Step: 0
Training loss: 0.6133413589080307
Validation loss: 2.50298242741982

Epoch: 6| Step: 1
Training loss: 0.4505210409733582
Validation loss: 2.50063132549048

Epoch: 6| Step: 2
Training loss: 0.5078769349519757
Validation loss: 2.499416647295254

Epoch: 6| Step: 3
Training loss: 0.5841119939367141
Validation loss: 2.539930028383604

Epoch: 6| Step: 4
Training loss: 0.5528722260914644
Validation loss: 2.512895253991666

Epoch: 6| Step: 5
Training loss: 0.44971630902821064
Validation loss: 2.5652289647177033

Epoch: 6| Step: 6
Training loss: 0.5161674997944812
Validation loss: 2.5135776629509357

Epoch: 6| Step: 7
Training loss: 0.3858278010523056
Validation loss: 2.5421368389158085

Epoch: 6| Step: 8
Training loss: 0.6417734040828665
Validation loss: 2.5297220536392953

Epoch: 6| Step: 9
Training loss: 0.2639409423123086
Validation loss: 2.5646911205253993

Epoch: 6| Step: 10
Training loss: 0.3500964432060902
Validation loss: 2.5511078760700276

Epoch: 6| Step: 11
Training loss: 0.42300391150756017
Validation loss: 2.559212269027528

Epoch: 6| Step: 12
Training loss: 0.5026543020697437
Validation loss: 2.53708894700818

Epoch: 6| Step: 13
Training loss: 0.44339306741150597
Validation loss: 2.540324716392931

Epoch: 361| Step: 0
Training loss: 0.1831877256643883
Validation loss: 2.5475173090937107

Epoch: 6| Step: 1
Training loss: 0.4900868258379651
Validation loss: 2.4849963090711187

Epoch: 6| Step: 2
Training loss: 0.4686244319577563
Validation loss: 2.52939176341469

Epoch: 6| Step: 3
Training loss: 0.5768297997287172
Validation loss: 2.4974833916905954

Epoch: 6| Step: 4
Training loss: 0.4796534498226061
Validation loss: 2.5116308747401193

Epoch: 6| Step: 5
Training loss: 0.3970578373245383
Validation loss: 2.5231388908054924

Epoch: 6| Step: 6
Training loss: 0.22136127610102788
Validation loss: 2.5211816938722804

Epoch: 6| Step: 7
Training loss: 0.47114089932312114
Validation loss: 2.4972295299724863

Epoch: 6| Step: 8
Training loss: 0.3890840654639304
Validation loss: 2.470568194164903

Epoch: 6| Step: 9
Training loss: 0.4786931545482923
Validation loss: 2.5260514880235645

Epoch: 6| Step: 10
Training loss: 0.6867345102908103
Validation loss: 2.47583308654345

Epoch: 6| Step: 11
Training loss: 0.5799747464831788
Validation loss: 2.4821288395905414

Epoch: 6| Step: 12
Training loss: 0.5119566037033509
Validation loss: 2.4990287298905534

Epoch: 6| Step: 13
Training loss: 0.5200916222403483
Validation loss: 2.5135187661327723

Epoch: 362| Step: 0
Training loss: 0.43652446157860164
Validation loss: 2.540124634874384

Epoch: 6| Step: 1
Training loss: 0.2615941021285389
Validation loss: 2.5194742099479948

Epoch: 6| Step: 2
Training loss: 0.3493239553658008
Validation loss: 2.535544075762918

Epoch: 6| Step: 3
Training loss: 0.5500658949478598
Validation loss: 2.5357112909263306

Epoch: 6| Step: 4
Training loss: 0.500947471800209
Validation loss: 2.5473284030602334

Epoch: 6| Step: 5
Training loss: 0.3319685820735581
Validation loss: 2.5253497178308106

Epoch: 6| Step: 6
Training loss: 0.7363523281986628
Validation loss: 2.52191511384214

Epoch: 6| Step: 7
Training loss: 0.3339300278733142
Validation loss: 2.482055608126138

Epoch: 6| Step: 8
Training loss: 0.4746469553444841
Validation loss: 2.4890123971425266

Epoch: 6| Step: 9
Training loss: 0.4647891068598238
Validation loss: 2.4374055804698855

Epoch: 6| Step: 10
Training loss: 0.48328054512532453
Validation loss: 2.469263949829778

Epoch: 6| Step: 11
Training loss: 0.6016447333074372
Validation loss: 2.435851465966117

Epoch: 6| Step: 12
Training loss: 0.38233990594438205
Validation loss: 2.4615003450990875

Epoch: 6| Step: 13
Training loss: 0.6753582595298097
Validation loss: 2.440563169283363

Epoch: 363| Step: 0
Training loss: 0.3782190205985095
Validation loss: 2.4558829944671032

Epoch: 6| Step: 1
Training loss: 0.5950088707879705
Validation loss: 2.4950849763264706

Epoch: 6| Step: 2
Training loss: 0.31606459126262454
Validation loss: 2.5043073382238306

Epoch: 6| Step: 3
Training loss: 0.3169695232043068
Validation loss: 2.563235265701251

Epoch: 6| Step: 4
Training loss: 0.39663915009118245
Validation loss: 2.562913097515992

Epoch: 6| Step: 5
Training loss: 0.35042505637333965
Validation loss: 2.5607518872081245

Epoch: 6| Step: 6
Training loss: 0.6502675807824566
Validation loss: 2.557762795480779

Epoch: 6| Step: 7
Training loss: 0.3452102250757376
Validation loss: 2.5512837010888143

Epoch: 6| Step: 8
Training loss: 0.47705734076621936
Validation loss: 2.553673545397224

Epoch: 6| Step: 9
Training loss: 0.21593101389593602
Validation loss: 2.5172101509753166

Epoch: 6| Step: 10
Training loss: 0.48956156912239956
Validation loss: 2.5239133412545836

Epoch: 6| Step: 11
Training loss: 0.6030244773147967
Validation loss: 2.532268390708923

Epoch: 6| Step: 12
Training loss: 0.7486618740970666
Validation loss: 2.49683018688746

Epoch: 6| Step: 13
Training loss: 0.3416412108037058
Validation loss: 2.524255190152375

Epoch: 364| Step: 0
Training loss: 0.5052198100670859
Validation loss: 2.5303573077456236

Epoch: 6| Step: 1
Training loss: 0.2727028377922468
Validation loss: 2.5221398578994996

Epoch: 6| Step: 2
Training loss: 0.3503787988136284
Validation loss: 2.5381475287091955

Epoch: 6| Step: 3
Training loss: 0.3904898218862822
Validation loss: 2.566265002484441

Epoch: 6| Step: 4
Training loss: 0.338069791094226
Validation loss: 2.5479370666813614

Epoch: 6| Step: 5
Training loss: 0.665357986586704
Validation loss: 2.523298915972881

Epoch: 6| Step: 6
Training loss: 0.6838130926002897
Validation loss: 2.5597697684195397

Epoch: 6| Step: 7
Training loss: 0.5874455436872591
Validation loss: 2.5773281065294

Epoch: 6| Step: 8
Training loss: 0.36785649168615603
Validation loss: 2.5958184085992935

Epoch: 6| Step: 9
Training loss: 0.3430395370459613
Validation loss: 2.5722220293005975

Epoch: 6| Step: 10
Training loss: 0.5386776033778792
Validation loss: 2.541354222882298

Epoch: 6| Step: 11
Training loss: 0.504740859243184
Validation loss: 2.576693609637764

Epoch: 6| Step: 12
Training loss: 0.38218491551047046
Validation loss: 2.5298279059467452

Epoch: 6| Step: 13
Training loss: 0.37794770584722276
Validation loss: 2.512178642027796

Epoch: 365| Step: 0
Training loss: 0.409689446887665
Validation loss: 2.5257115039947435

Epoch: 6| Step: 1
Training loss: 0.5412280495401539
Validation loss: 2.5102951452020035

Epoch: 6| Step: 2
Training loss: 0.36190096836108104
Validation loss: 2.479613866583214

Epoch: 6| Step: 3
Training loss: 0.2785328906513943
Validation loss: 2.4752916733684964

Epoch: 6| Step: 4
Training loss: 0.5388624124014685
Validation loss: 2.5185450184349354

Epoch: 6| Step: 5
Training loss: 0.5538807764907896
Validation loss: 2.5300164589019642

Epoch: 6| Step: 6
Training loss: 0.3966932826903125
Validation loss: 2.5276912514909555

Epoch: 6| Step: 7
Training loss: 0.42008131681892963
Validation loss: 2.514929577787806

Epoch: 6| Step: 8
Training loss: 0.31648279370939536
Validation loss: 2.5059574547182804

Epoch: 6| Step: 9
Training loss: 0.36830023314048893
Validation loss: 2.51583858417161

Epoch: 6| Step: 10
Training loss: 0.7206827383078434
Validation loss: 2.541059090227116

Epoch: 6| Step: 11
Training loss: 0.3245517675005208
Validation loss: 2.518731761530357

Epoch: 6| Step: 12
Training loss: 0.38968937403053144
Validation loss: 2.5241551792245747

Epoch: 6| Step: 13
Training loss: 0.7556694639894829
Validation loss: 2.5479656299866336

Epoch: 366| Step: 0
Training loss: 0.3566295826801669
Validation loss: 2.532225774342031

Epoch: 6| Step: 1
Training loss: 0.3633155601460524
Validation loss: 2.551439768595067

Epoch: 6| Step: 2
Training loss: 0.6063603389259608
Validation loss: 2.5704187831952696

Epoch: 6| Step: 3
Training loss: 0.39929404472492935
Validation loss: 2.5382977844646515

Epoch: 6| Step: 4
Training loss: 0.4228798414117272
Validation loss: 2.527189605942531

Epoch: 6| Step: 5
Training loss: 0.32144131285148914
Validation loss: 2.5155668960859168

Epoch: 6| Step: 6
Training loss: 0.627937115140326
Validation loss: 2.527955551083544

Epoch: 6| Step: 7
Training loss: 0.5207022184004908
Validation loss: 2.5477601730171253

Epoch: 6| Step: 8
Training loss: 0.45947362917919704
Validation loss: 2.5136806816379424

Epoch: 6| Step: 9
Training loss: 0.4225664124405741
Validation loss: 2.5181332160677354

Epoch: 6| Step: 10
Training loss: 0.43510649103821325
Validation loss: 2.5305383153476817

Epoch: 6| Step: 11
Training loss: 0.40776266400067973
Validation loss: 2.557580214362484

Epoch: 6| Step: 12
Training loss: 0.5953307441859457
Validation loss: 2.5342492165741386

Epoch: 6| Step: 13
Training loss: 0.31541126303703304
Validation loss: 2.528642586341773

Epoch: 367| Step: 0
Training loss: 0.3952779596490204
Validation loss: 2.542337210803108

Epoch: 6| Step: 1
Training loss: 0.3600538724750639
Validation loss: 2.592610522167268

Epoch: 6| Step: 2
Training loss: 0.3240994843040137
Validation loss: 2.5415901489951205

Epoch: 6| Step: 3
Training loss: 0.21864667223193465
Validation loss: 2.5526811761289645

Epoch: 6| Step: 4
Training loss: 0.3134297130906758
Validation loss: 2.5167389853255155

Epoch: 6| Step: 5
Training loss: 0.5117072475392735
Validation loss: 2.5419234602169953

Epoch: 6| Step: 6
Training loss: 0.5156858581694368
Validation loss: 2.53177639880761

Epoch: 6| Step: 7
Training loss: 0.6160165325924919
Validation loss: 2.5326610720252853

Epoch: 6| Step: 8
Training loss: 0.5600965332377558
Validation loss: 2.5227518407674108

Epoch: 6| Step: 9
Training loss: 0.3601931505476562
Validation loss: 2.5595629407852414

Epoch: 6| Step: 10
Training loss: 0.6130672980638107
Validation loss: 2.4903394021541465

Epoch: 6| Step: 11
Training loss: 0.4145331137479029
Validation loss: 2.46636398983798

Epoch: 6| Step: 12
Training loss: 0.48309075938653284
Validation loss: 2.4966283252710157

Epoch: 6| Step: 13
Training loss: 0.36602849866441556
Validation loss: 2.505852298494634

Epoch: 368| Step: 0
Training loss: 0.5940057805900715
Validation loss: 2.5284241241536414

Epoch: 6| Step: 1
Training loss: 0.40196146905392394
Validation loss: 2.5187195617909706

Epoch: 6| Step: 2
Training loss: 0.46680091313486916
Validation loss: 2.47420588050932

Epoch: 6| Step: 3
Training loss: 0.41364351703101254
Validation loss: 2.5271124913314775

Epoch: 6| Step: 4
Training loss: 0.3447213645305427
Validation loss: 2.518724518641983

Epoch: 6| Step: 5
Training loss: 0.36585175256407104
Validation loss: 2.5335064159628518

Epoch: 6| Step: 6
Training loss: 0.40070405183128227
Validation loss: 2.5452047679720207

Epoch: 6| Step: 7
Training loss: 0.6878652902646069
Validation loss: 2.51999513248163

Epoch: 6| Step: 8
Training loss: 0.3560783692235677
Validation loss: 2.5386638576418328

Epoch: 6| Step: 9
Training loss: 0.47099984974463915
Validation loss: 2.4994261749634403

Epoch: 6| Step: 10
Training loss: 0.4347993054501093
Validation loss: 2.516886035379972

Epoch: 6| Step: 11
Training loss: 0.17921179537595033
Validation loss: 2.5254645082881995

Epoch: 6| Step: 12
Training loss: 0.48854478971978343
Validation loss: 2.515758022999372

Epoch: 6| Step: 13
Training loss: 0.23920588027052014
Validation loss: 2.526773549498205

Epoch: 369| Step: 0
Training loss: 0.37770744314507887
Validation loss: 2.530634102382527

Epoch: 6| Step: 1
Training loss: 0.5199668606872183
Validation loss: 2.539814723357092

Epoch: 6| Step: 2
Training loss: 0.434756704069264
Validation loss: 2.5338663080396278

Epoch: 6| Step: 3
Training loss: 0.17584545234600518
Validation loss: 2.545406014292498

Epoch: 6| Step: 4
Training loss: 0.40931040421661585
Validation loss: 2.5119187590173206

Epoch: 6| Step: 5
Training loss: 0.6447289828232223
Validation loss: 2.522552032132448

Epoch: 6| Step: 6
Training loss: 0.4760478477021099
Validation loss: 2.5558987319155184

Epoch: 6| Step: 7
Training loss: 0.4883900788144229
Validation loss: 2.526549273428946

Epoch: 6| Step: 8
Training loss: 0.3595572299846247
Validation loss: 2.554839577597809

Epoch: 6| Step: 9
Training loss: 0.26883916872637986
Validation loss: 2.495146816275131

Epoch: 6| Step: 10
Training loss: 0.3816529052382911
Validation loss: 2.546145501451416

Epoch: 6| Step: 11
Training loss: 0.3804918716893355
Validation loss: 2.5377687763785306

Epoch: 6| Step: 12
Training loss: 0.47024995508350925
Validation loss: 2.492474152735669

Epoch: 6| Step: 13
Training loss: 0.6629921308858859
Validation loss: 2.5070233411064735

Epoch: 370| Step: 0
Training loss: 0.5195554856692209
Validation loss: 2.47494168300377

Epoch: 6| Step: 1
Training loss: 0.41420036395985754
Validation loss: 2.4966932207866237

Epoch: 6| Step: 2
Training loss: 0.42171899242189215
Validation loss: 2.4869347937156556

Epoch: 6| Step: 3
Training loss: 0.30124460175928686
Validation loss: 2.50670041094413

Epoch: 6| Step: 4
Training loss: 0.46659543467314557
Validation loss: 2.535148516057176

Epoch: 6| Step: 5
Training loss: 0.2196177234236694
Validation loss: 2.495859175696928

Epoch: 6| Step: 6
Training loss: 0.24703931802535134
Validation loss: 2.5314290773200856

Epoch: 6| Step: 7
Training loss: 0.5049921503967726
Validation loss: 2.545713917853687

Epoch: 6| Step: 8
Training loss: 0.4542718383502697
Validation loss: 2.5242030770036363

Epoch: 6| Step: 9
Training loss: 0.31742359779635865
Validation loss: 2.518058104148843

Epoch: 6| Step: 10
Training loss: 0.3721096788942136
Validation loss: 2.5588137907378012

Epoch: 6| Step: 11
Training loss: 0.5101874933416872
Validation loss: 2.5635006344275886

Epoch: 6| Step: 12
Training loss: 0.6558606264194458
Validation loss: 2.543611813935206

Epoch: 6| Step: 13
Training loss: 0.43845127771961157
Validation loss: 2.5596893046637574

Epoch: 371| Step: 0
Training loss: 0.28886675006041507
Validation loss: 2.5424180039071866

Epoch: 6| Step: 1
Training loss: 0.4698841837720994
Validation loss: 2.5354943199749207

Epoch: 6| Step: 2
Training loss: 0.19696560318914685
Validation loss: 2.5447129842461615

Epoch: 6| Step: 3
Training loss: 0.4875254923928776
Validation loss: 2.5652607628196673

Epoch: 6| Step: 4
Training loss: 0.5213403681536939
Validation loss: 2.526107218054321

Epoch: 6| Step: 5
Training loss: 0.3494045147516239
Validation loss: 2.5015489783805545

Epoch: 6| Step: 6
Training loss: 0.3074066168017117
Validation loss: 2.5312982927053156

Epoch: 6| Step: 7
Training loss: 0.6310428553339469
Validation loss: 2.4909231181784084

Epoch: 6| Step: 8
Training loss: 0.5269235703060661
Validation loss: 2.5442832464247696

Epoch: 6| Step: 9
Training loss: 0.32973141490744806
Validation loss: 2.5105022748905013

Epoch: 6| Step: 10
Training loss: 0.6514243768524705
Validation loss: 2.530655332631256

Epoch: 6| Step: 11
Training loss: 0.4349400351289172
Validation loss: 2.5123776409679817

Epoch: 6| Step: 12
Training loss: 0.40560399558019805
Validation loss: 2.530051967377827

Epoch: 6| Step: 13
Training loss: 0.28786466473699673
Validation loss: 2.523212910133238

Epoch: 372| Step: 0
Training loss: 0.4209427423016218
Validation loss: 2.530900056714099

Epoch: 6| Step: 1
Training loss: 0.5289571312190435
Validation loss: 2.5353109491814423

Epoch: 6| Step: 2
Training loss: 0.41042954558612116
Validation loss: 2.5334919741666115

Epoch: 6| Step: 3
Training loss: 0.5432311597173697
Validation loss: 2.526517309771896

Epoch: 6| Step: 4
Training loss: 0.5881827759614339
Validation loss: 2.5288327341303374

Epoch: 6| Step: 5
Training loss: 0.36887149991269025
Validation loss: 2.548610484250837

Epoch: 6| Step: 6
Training loss: 0.325375435464328
Validation loss: 2.54565328112335

Epoch: 6| Step: 7
Training loss: 0.5135238492194824
Validation loss: 2.518889491735384

Epoch: 6| Step: 8
Training loss: 0.5065304638606279
Validation loss: 2.519184714166415

Epoch: 6| Step: 9
Training loss: 0.42635230170776467
Validation loss: 2.5219224288905955

Epoch: 6| Step: 10
Training loss: 0.40995325787363224
Validation loss: 2.515535338112247

Epoch: 6| Step: 11
Training loss: 0.20701298543148597
Validation loss: 2.529728283050768

Epoch: 6| Step: 12
Training loss: 0.36011648392993917
Validation loss: 2.524521827154931

Epoch: 6| Step: 13
Training loss: 0.20503931132363445
Validation loss: 2.5559902747300107

Epoch: 373| Step: 0
Training loss: 0.3915355179571038
Validation loss: 2.538065123943313

Epoch: 6| Step: 1
Training loss: 0.37989846322345505
Validation loss: 2.5727288766036014

Epoch: 6| Step: 2
Training loss: 0.4163000898322623
Validation loss: 2.5785008210938316

Epoch: 6| Step: 3
Training loss: 0.4780779179597764
Validation loss: 2.55596980155265

Epoch: 6| Step: 4
Training loss: 0.5435711105996333
Validation loss: 2.547089989468349

Epoch: 6| Step: 5
Training loss: 0.5444785061088989
Validation loss: 2.5633965361292645

Epoch: 6| Step: 6
Training loss: 0.3818620638677564
Validation loss: 2.551782667586217

Epoch: 6| Step: 7
Training loss: 0.32640471684966393
Validation loss: 2.5457641939251605

Epoch: 6| Step: 8
Training loss: 0.37478993413134915
Validation loss: 2.5263161002195176

Epoch: 6| Step: 9
Training loss: 0.5248391472676254
Validation loss: 2.525399205000903

Epoch: 6| Step: 10
Training loss: 0.40023852925301245
Validation loss: 2.5042627130228494

Epoch: 6| Step: 11
Training loss: 0.4260296053527637
Validation loss: 2.5133295314108666

Epoch: 6| Step: 12
Training loss: 0.3699699249803129
Validation loss: 2.5220814537754404

Epoch: 6| Step: 13
Training loss: 0.24722047999315208
Validation loss: 2.497138869818329

Epoch: 374| Step: 0
Training loss: 0.38303434989068835
Validation loss: 2.4833432510653086

Epoch: 6| Step: 1
Training loss: 0.6432388294642195
Validation loss: 2.510619143646556

Epoch: 6| Step: 2
Training loss: 0.20622552777092287
Validation loss: 2.4728081836699753

Epoch: 6| Step: 3
Training loss: 0.42045493779058685
Validation loss: 2.5192297237800085

Epoch: 6| Step: 4
Training loss: 0.3495307279812253
Validation loss: 2.5165643555363926

Epoch: 6| Step: 5
Training loss: 0.352981311123715
Validation loss: 2.558117943153184

Epoch: 6| Step: 6
Training loss: 0.640118189120881
Validation loss: 2.547828355466368

Epoch: 6| Step: 7
Training loss: 0.3370133516266008
Validation loss: 2.5406924505040895

Epoch: 6| Step: 8
Training loss: 0.548032598112399
Validation loss: 2.5741240171371897

Epoch: 6| Step: 9
Training loss: 0.5891738017440177
Validation loss: 2.5437120679744396

Epoch: 6| Step: 10
Training loss: 0.350335331767438
Validation loss: 2.55365378850897

Epoch: 6| Step: 11
Training loss: 0.37562935390265834
Validation loss: 2.552507055858847

Epoch: 6| Step: 12
Training loss: 0.35125901580588825
Validation loss: 2.540084021006017

Epoch: 6| Step: 13
Training loss: 0.4117793890870558
Validation loss: 2.5226094111289017

Epoch: 375| Step: 0
Training loss: 0.4637119234139032
Validation loss: 2.4916527498077246

Epoch: 6| Step: 1
Training loss: 0.20075259913404458
Validation loss: 2.47493600763645

Epoch: 6| Step: 2
Training loss: 0.6965831333559731
Validation loss: 2.5041239032128075

Epoch: 6| Step: 3
Training loss: 0.20514843961457913
Validation loss: 2.489924831981363

Epoch: 6| Step: 4
Training loss: 0.3430172631747609
Validation loss: 2.477089249779353

Epoch: 6| Step: 5
Training loss: 0.502683886858296
Validation loss: 2.4639469921474864

Epoch: 6| Step: 6
Training loss: 0.2983493085443083
Validation loss: 2.50701092895755

Epoch: 6| Step: 7
Training loss: 0.3548642982436004
Validation loss: 2.5146205942532163

Epoch: 6| Step: 8
Training loss: 0.5324991350659434
Validation loss: 2.5641429385413437

Epoch: 6| Step: 9
Training loss: 0.5193193046371011
Validation loss: 2.5945883516768196

Epoch: 6| Step: 10
Training loss: 0.5684691123288103
Validation loss: 2.6218909228159157

Epoch: 6| Step: 11
Training loss: 0.6133848698056923
Validation loss: 2.5703156318474667

Epoch: 6| Step: 12
Training loss: 0.44404441576542186
Validation loss: 2.5390228460227084

Epoch: 6| Step: 13
Training loss: 0.29216085302252404
Validation loss: 2.5234315953969317

Epoch: 376| Step: 0
Training loss: 0.44961475664061556
Validation loss: 2.481870154563814

Epoch: 6| Step: 1
Training loss: 0.5116806307273679
Validation loss: 2.461082777926591

Epoch: 6| Step: 2
Training loss: 0.5958899783393945
Validation loss: 2.457886371751861

Epoch: 6| Step: 3
Training loss: 0.46164480995376844
Validation loss: 2.4245899227526704

Epoch: 6| Step: 4
Training loss: 0.5036894753399986
Validation loss: 2.453234132244236

Epoch: 6| Step: 5
Training loss: 0.7009743329871247
Validation loss: 2.4603231569219832

Epoch: 6| Step: 6
Training loss: 0.3979004625279877
Validation loss: 2.493502357176236

Epoch: 6| Step: 7
Training loss: 0.5717032211042151
Validation loss: 2.50483986581602

Epoch: 6| Step: 8
Training loss: 0.4911787807488206
Validation loss: 2.5080617078611027

Epoch: 6| Step: 9
Training loss: 0.38848978118884625
Validation loss: 2.4899814792093675

Epoch: 6| Step: 10
Training loss: 0.3621483848653209
Validation loss: 2.5105002407261567

Epoch: 6| Step: 11
Training loss: 0.4387721401453727
Validation loss: 2.520693260422704

Epoch: 6| Step: 12
Training loss: 0.22829614189917408
Validation loss: 2.523819673781376

Epoch: 6| Step: 13
Training loss: 0.2750513001839954
Validation loss: 2.520799587969342

Epoch: 377| Step: 0
Training loss: 0.5610006801546703
Validation loss: 2.5247468052427884

Epoch: 6| Step: 1
Training loss: 0.6288076524865194
Validation loss: 2.5576115818229517

Epoch: 6| Step: 2
Training loss: 0.5358318880970372
Validation loss: 2.5078884401152437

Epoch: 6| Step: 3
Training loss: 0.5893539011506959
Validation loss: 2.5408930503058422

Epoch: 6| Step: 4
Training loss: 0.4130539036227277
Validation loss: 2.479320624405275

Epoch: 6| Step: 5
Training loss: 0.5656298874280331
Validation loss: 2.4934632992998393

Epoch: 6| Step: 6
Training loss: 0.50832182944158
Validation loss: 2.474933464127125

Epoch: 6| Step: 7
Training loss: 0.41148424871735007
Validation loss: 2.520980963523598

Epoch: 6| Step: 8
Training loss: 0.4863957430853248
Validation loss: 2.543789392896809

Epoch: 6| Step: 9
Training loss: 0.46007839250160043
Validation loss: 2.5185897671956554

Epoch: 6| Step: 10
Training loss: 0.45695208002350224
Validation loss: 2.5513354761254363

Epoch: 6| Step: 11
Training loss: 0.44717886137332463
Validation loss: 2.5278643448992666

Epoch: 6| Step: 12
Training loss: 0.3629901293773468
Validation loss: 2.508737040920129

Epoch: 6| Step: 13
Training loss: 0.19876637239917655
Validation loss: 2.5383486326194493

Epoch: 378| Step: 0
Training loss: 0.3493526624420872
Validation loss: 2.529207791040732

Epoch: 6| Step: 1
Training loss: 0.4440101854728328
Validation loss: 2.5493335776368613

Epoch: 6| Step: 2
Training loss: 0.5221052153137805
Validation loss: 2.5526279882009915

Epoch: 6| Step: 3
Training loss: 0.6599400183124472
Validation loss: 2.559631072248962

Epoch: 6| Step: 4
Training loss: 0.2702212554534912
Validation loss: 2.537885765848554

Epoch: 6| Step: 5
Training loss: 0.4454863694050569
Validation loss: 2.5513385046602415

Epoch: 6| Step: 6
Training loss: 0.26876671484045456
Validation loss: 2.5550355508897775

Epoch: 6| Step: 7
Training loss: 0.42899033602920283
Validation loss: 2.566260576011944

Epoch: 6| Step: 8
Training loss: 0.467724473019166
Validation loss: 2.5785846637275935

Epoch: 6| Step: 9
Training loss: 0.5295103142483927
Validation loss: 2.537542552380056

Epoch: 6| Step: 10
Training loss: 0.6130555825011875
Validation loss: 2.56309964266877

Epoch: 6| Step: 11
Training loss: 0.44672744555714694
Validation loss: 2.5730190983247656

Epoch: 6| Step: 12
Training loss: 0.36830545235025575
Validation loss: 2.5601543672804006

Epoch: 6| Step: 13
Training loss: 0.39061613072816753
Validation loss: 2.545049825051226

Epoch: 379| Step: 0
Training loss: 0.21915517476513108
Validation loss: 2.53807266718546

Epoch: 6| Step: 1
Training loss: 0.5569000175156867
Validation loss: 2.526830495796451

Epoch: 6| Step: 2
Training loss: 0.44241299221007235
Validation loss: 2.533844914483895

Epoch: 6| Step: 3
Training loss: 0.3288239573193967
Validation loss: 2.473031902499045

Epoch: 6| Step: 4
Training loss: 0.5406866622775446
Validation loss: 2.527617258840046

Epoch: 6| Step: 5
Training loss: 0.4098547781225157
Validation loss: 2.4969647327249263

Epoch: 6| Step: 6
Training loss: 0.46448122842654344
Validation loss: 2.5290507971122773

Epoch: 6| Step: 7
Training loss: 0.25499548924420806
Validation loss: 2.5242188737123596

Epoch: 6| Step: 8
Training loss: 0.32712406807847993
Validation loss: 2.5054238375322497

Epoch: 6| Step: 9
Training loss: 0.5751446894339085
Validation loss: 2.5754877865959536

Epoch: 6| Step: 10
Training loss: 0.22820738846225322
Validation loss: 2.520026487096348

Epoch: 6| Step: 11
Training loss: 0.4364689359841367
Validation loss: 2.545565497702782

Epoch: 6| Step: 12
Training loss: 0.3835251267033795
Validation loss: 2.579307232883135

Epoch: 6| Step: 13
Training loss: 0.7810186043427118
Validation loss: 2.5562177619994277

Epoch: 380| Step: 0
Training loss: 0.46759475767657643
Validation loss: 2.5429304912152686

Epoch: 6| Step: 1
Training loss: 0.1534485857429788
Validation loss: 2.5280436539340787

Epoch: 6| Step: 2
Training loss: 0.4882241177513179
Validation loss: 2.524532979302229

Epoch: 6| Step: 3
Training loss: 0.45033154526091285
Validation loss: 2.513783524771065

Epoch: 6| Step: 4
Training loss: 0.27059549501197605
Validation loss: 2.506198465245378

Epoch: 6| Step: 5
Training loss: 0.28574930209561056
Validation loss: 2.5128332988872963

Epoch: 6| Step: 6
Training loss: 0.3437490463243607
Validation loss: 2.5048574081137236

Epoch: 6| Step: 7
Training loss: 0.4882600703414374
Validation loss: 2.5158256940377157

Epoch: 6| Step: 8
Training loss: 0.48794060077759405
Validation loss: 2.5370362794883934

Epoch: 6| Step: 9
Training loss: 0.34527082407506393
Validation loss: 2.5430448071577607

Epoch: 6| Step: 10
Training loss: 0.38969841734545463
Validation loss: 2.545508779177198

Epoch: 6| Step: 11
Training loss: 0.6230534998622246
Validation loss: 2.541851982718621

Epoch: 6| Step: 12
Training loss: 0.5150970009773677
Validation loss: 2.537016712354449

Epoch: 6| Step: 13
Training loss: 0.5178618894791699
Validation loss: 2.5753641300579293

Epoch: 381| Step: 0
Training loss: 0.3348785721743908
Validation loss: 2.548141857949656

Epoch: 6| Step: 1
Training loss: 0.27358413579181906
Validation loss: 2.5356391954753983

Epoch: 6| Step: 2
Training loss: 0.40569726314970833
Validation loss: 2.4746664054444794

Epoch: 6| Step: 3
Training loss: 0.3227566071136166
Validation loss: 2.485862770936602

Epoch: 6| Step: 4
Training loss: 0.33810649436895174
Validation loss: 2.4898152074562674

Epoch: 6| Step: 5
Training loss: 0.409784275499618
Validation loss: 2.4682133938933744

Epoch: 6| Step: 6
Training loss: 0.2884878038864687
Validation loss: 2.440631038719277

Epoch: 6| Step: 7
Training loss: 0.31403433118294266
Validation loss: 2.458938154719137

Epoch: 6| Step: 8
Training loss: 0.6073690802393034
Validation loss: 2.4833245105122814

Epoch: 6| Step: 9
Training loss: 0.5807670843178975
Validation loss: 2.4893849035876867

Epoch: 6| Step: 10
Training loss: 0.48704385752754503
Validation loss: 2.453046531093686

Epoch: 6| Step: 11
Training loss: 0.46368661678696454
Validation loss: 2.4695135908444046

Epoch: 6| Step: 12
Training loss: 0.2206441243395785
Validation loss: 2.5278706265537387

Epoch: 6| Step: 13
Training loss: 0.4604353189645858
Validation loss: 2.496181824065398

Epoch: 382| Step: 0
Training loss: 0.5668500805627531
Validation loss: 2.488729550809813

Epoch: 6| Step: 1
Training loss: 0.17021644753484622
Validation loss: 2.5184944249734635

Epoch: 6| Step: 2
Training loss: 0.32213557538105975
Validation loss: 2.527154935751262

Epoch: 6| Step: 3
Training loss: 0.41746422808551314
Validation loss: 2.536299339928044

Epoch: 6| Step: 4
Training loss: 0.3671071390723999
Validation loss: 2.5137161475484837

Epoch: 6| Step: 5
Training loss: 0.3083205885229225
Validation loss: 2.5181045678709038

Epoch: 6| Step: 6
Training loss: 0.35678116117504544
Validation loss: 2.4792484970699458

Epoch: 6| Step: 7
Training loss: 0.2943298005069892
Validation loss: 2.484149120028167

Epoch: 6| Step: 8
Training loss: 0.6218437848331942
Validation loss: 2.5283548125896695

Epoch: 6| Step: 9
Training loss: 0.3375049661341625
Validation loss: 2.5388174640812227

Epoch: 6| Step: 10
Training loss: 0.5256820494437596
Validation loss: 2.529864909228583

Epoch: 6| Step: 11
Training loss: 0.4779952041373417
Validation loss: 2.540241627364456

Epoch: 6| Step: 12
Training loss: 0.42774656792249816
Validation loss: 2.531466135682081

Epoch: 6| Step: 13
Training loss: 0.38799451145611175
Validation loss: 2.5544887612309406

Epoch: 383| Step: 0
Training loss: 0.33513167675784583
Validation loss: 2.5208099379064457

Epoch: 6| Step: 1
Training loss: 0.30819596837078483
Validation loss: 2.497539893656212

Epoch: 6| Step: 2
Training loss: 0.2777109401811375
Validation loss: 2.4966525647649176

Epoch: 6| Step: 3
Training loss: 0.4298001055120904
Validation loss: 2.5037921242606127

Epoch: 6| Step: 4
Training loss: 0.6352682383252469
Validation loss: 2.485965970823549

Epoch: 6| Step: 5
Training loss: 0.5572628358412562
Validation loss: 2.4859533803182297

Epoch: 6| Step: 6
Training loss: 0.3205874937365309
Validation loss: 2.479625747984587

Epoch: 6| Step: 7
Training loss: 0.3210862049784897
Validation loss: 2.5266528854180432

Epoch: 6| Step: 8
Training loss: 0.49337253507699574
Validation loss: 2.5204777912212477

Epoch: 6| Step: 9
Training loss: 0.41521024876120993
Validation loss: 2.5179963310548783

Epoch: 6| Step: 10
Training loss: 0.3986083206809389
Validation loss: 2.5271460974494317

Epoch: 6| Step: 11
Training loss: 0.48780231638706795
Validation loss: 2.5342438642051457

Epoch: 6| Step: 12
Training loss: 0.48103319523542615
Validation loss: 2.5549239869882525

Epoch: 6| Step: 13
Training loss: 0.43141434205620016
Validation loss: 2.5161469935203895

Epoch: 384| Step: 0
Training loss: 0.3999067033802541
Validation loss: 2.4966439095901136

Epoch: 6| Step: 1
Training loss: 0.3572394734213898
Validation loss: 2.5181617916563646

Epoch: 6| Step: 2
Training loss: 0.41585428395685387
Validation loss: 2.4825880721590217

Epoch: 6| Step: 3
Training loss: 0.30641598582423385
Validation loss: 2.485135836532134

Epoch: 6| Step: 4
Training loss: 0.5792304630499883
Validation loss: 2.5200860314073634

Epoch: 6| Step: 5
Training loss: 0.5002827440952359
Validation loss: 2.4963890721473665

Epoch: 6| Step: 6
Training loss: 0.30370832485044225
Validation loss: 2.4839548958065967

Epoch: 6| Step: 7
Training loss: 0.30189480187447815
Validation loss: 2.524213800444393

Epoch: 6| Step: 8
Training loss: 0.4355639467186616
Validation loss: 2.4960402796026377

Epoch: 6| Step: 9
Training loss: 0.26558992210346966
Validation loss: 2.493410021309584

Epoch: 6| Step: 10
Training loss: 0.5481787807652764
Validation loss: 2.5116719793181357

Epoch: 6| Step: 11
Training loss: 0.4031399007009861
Validation loss: 2.51022289782517

Epoch: 6| Step: 12
Training loss: 0.27848770729309613
Validation loss: 2.500787243921414

Epoch: 6| Step: 13
Training loss: 0.3909095871899017
Validation loss: 2.5237193017402437

Epoch: 385| Step: 0
Training loss: 0.26218998176936925
Validation loss: 2.5113855979635007

Epoch: 6| Step: 1
Training loss: 0.4550330012793197
Validation loss: 2.5128403914407715

Epoch: 6| Step: 2
Training loss: 0.48961977789214406
Validation loss: 2.4783975185871725

Epoch: 6| Step: 3
Training loss: 0.18049655056138023
Validation loss: 2.516873430211214

Epoch: 6| Step: 4
Training loss: 0.37976166428613745
Validation loss: 2.520141925401018

Epoch: 6| Step: 5
Training loss: 0.4248928986965747
Validation loss: 2.47443498165829

Epoch: 6| Step: 6
Training loss: 0.5191151379485057
Validation loss: 2.4811278700208326

Epoch: 6| Step: 7
Training loss: 0.4499849667952058
Validation loss: 2.508190495961947

Epoch: 6| Step: 8
Training loss: 0.3770884532826762
Validation loss: 2.4994521345722354

Epoch: 6| Step: 9
Training loss: 0.2806618421622035
Validation loss: 2.494237821133787

Epoch: 6| Step: 10
Training loss: 0.3022167086760603
Validation loss: 2.5381936681089443

Epoch: 6| Step: 11
Training loss: 0.36770931663417733
Validation loss: 2.547942969834301

Epoch: 6| Step: 12
Training loss: 0.4671735161822305
Validation loss: 2.5401178072360984

Epoch: 6| Step: 13
Training loss: 0.534654256566462
Validation loss: 2.5177320408810453

Epoch: 386| Step: 0
Training loss: 0.5405974441738164
Validation loss: 2.5234946099650974

Epoch: 6| Step: 1
Training loss: 0.40783459395268495
Validation loss: 2.5402144582409028

Epoch: 6| Step: 2
Training loss: 0.3206927903028382
Validation loss: 2.510715990820944

Epoch: 6| Step: 3
Training loss: 0.35944135716689796
Validation loss: 2.530886490421364

Epoch: 6| Step: 4
Training loss: 0.4369550785462313
Validation loss: 2.544606371898228

Epoch: 6| Step: 5
Training loss: 0.3947369445311263
Validation loss: 2.5402698346645662

Epoch: 6| Step: 6
Training loss: 0.4950291180956972
Validation loss: 2.5217686884577066

Epoch: 6| Step: 7
Training loss: 0.22318230774564785
Validation loss: 2.5178216958160933

Epoch: 6| Step: 8
Training loss: 0.23153165019738695
Validation loss: 2.54997969202476

Epoch: 6| Step: 9
Training loss: 0.32839324749234644
Validation loss: 2.524148578044015

Epoch: 6| Step: 10
Training loss: 0.43004444208695003
Validation loss: 2.5148355545530054

Epoch: 6| Step: 11
Training loss: 0.5224447657854226
Validation loss: 2.5061807625286354

Epoch: 6| Step: 12
Training loss: 0.333798518529602
Validation loss: 2.484794312502037

Epoch: 6| Step: 13
Training loss: 0.28394256609361107
Validation loss: 2.525612164844713

Epoch: 387| Step: 0
Training loss: 0.3105337032187814
Validation loss: 2.5429481745071922

Epoch: 6| Step: 1
Training loss: 0.44746437820716856
Validation loss: 2.5095882380695618

Epoch: 6| Step: 2
Training loss: 0.5959195353656284
Validation loss: 2.503231821698092

Epoch: 6| Step: 3
Training loss: 0.23423514166917644
Validation loss: 2.5189421636398404

Epoch: 6| Step: 4
Training loss: 0.4044808968700126
Validation loss: 2.5153879084368107

Epoch: 6| Step: 5
Training loss: 0.43197725727783703
Validation loss: 2.5184501458266766

Epoch: 6| Step: 6
Training loss: 0.30458806934188415
Validation loss: 2.4927201906750827

Epoch: 6| Step: 7
Training loss: 0.3208086311854684
Validation loss: 2.4919743446265357

Epoch: 6| Step: 8
Training loss: 0.344994211442042
Validation loss: 2.473013240858327

Epoch: 6| Step: 9
Training loss: 0.4925164379968659
Validation loss: 2.496434190328163

Epoch: 6| Step: 10
Training loss: 0.4428318431078055
Validation loss: 2.486205253583847

Epoch: 6| Step: 11
Training loss: 0.481580363244934
Validation loss: 2.5229379422386375

Epoch: 6| Step: 12
Training loss: 0.1551303924381004
Validation loss: 2.5280465592740198

Epoch: 6| Step: 13
Training loss: 0.2131698946498391
Validation loss: 2.5040086345784522

Epoch: 388| Step: 0
Training loss: 0.24990350380882062
Validation loss: 2.5492402450714597

Epoch: 6| Step: 1
Training loss: 0.48824726749423164
Validation loss: 2.5460596712810752

Epoch: 6| Step: 2
Training loss: 0.22955063420575575
Validation loss: 2.5483363805781214

Epoch: 6| Step: 3
Training loss: 0.5335776442502956
Validation loss: 2.567163698978856

Epoch: 6| Step: 4
Training loss: 0.3758185116382064
Validation loss: 2.5243904409550812

Epoch: 6| Step: 5
Training loss: 0.3192349195376279
Validation loss: 2.5256779863816563

Epoch: 6| Step: 6
Training loss: 0.438106559169423
Validation loss: 2.5094962897610444

Epoch: 6| Step: 7
Training loss: 0.431857783723825
Validation loss: 2.5432888859236105

Epoch: 6| Step: 8
Training loss: 0.5008633134229202
Validation loss: 2.528114267453193

Epoch: 6| Step: 9
Training loss: 0.24004101919272167
Validation loss: 2.5137996804114473

Epoch: 6| Step: 10
Training loss: 0.4260985915465355
Validation loss: 2.5234479686484734

Epoch: 6| Step: 11
Training loss: 0.23318380598497435
Validation loss: 2.526989873270355

Epoch: 6| Step: 12
Training loss: 0.32804811803114836
Validation loss: 2.517351014302427

Epoch: 6| Step: 13
Training loss: 0.4743276474178074
Validation loss: 2.5203682689046465

Epoch: 389| Step: 0
Training loss: 0.26403879138219155
Validation loss: 2.5189575183109176

Epoch: 6| Step: 1
Training loss: 0.3945331951131178
Validation loss: 2.5095179654623823

Epoch: 6| Step: 2
Training loss: 0.22502487561680484
Validation loss: 2.541218603317995

Epoch: 6| Step: 3
Training loss: 0.32843457105439444
Validation loss: 2.545290419989159

Epoch: 6| Step: 4
Training loss: 0.45324254977609507
Validation loss: 2.522250500620583

Epoch: 6| Step: 5
Training loss: 0.432095680468112
Validation loss: 2.573941974094309

Epoch: 6| Step: 6
Training loss: 0.3464122546634391
Validation loss: 2.582990392044687

Epoch: 6| Step: 7
Training loss: 0.29407156327293943
Validation loss: 2.5457141655859874

Epoch: 6| Step: 8
Training loss: 0.4074332721173101
Validation loss: 2.570277739727813

Epoch: 6| Step: 9
Training loss: 0.472067489899675
Validation loss: 2.57106016916755

Epoch: 6| Step: 10
Training loss: 0.24138325547759412
Validation loss: 2.541349673327769

Epoch: 6| Step: 11
Training loss: 0.5992372830744025
Validation loss: 2.5482934459100104

Epoch: 6| Step: 12
Training loss: 0.534684857663482
Validation loss: 2.5316956964644257

Epoch: 6| Step: 13
Training loss: 0.420677109164521
Validation loss: 2.505065657477913

Epoch: 390| Step: 0
Training loss: 0.38379768187184116
Validation loss: 2.5231751463330414

Epoch: 6| Step: 1
Training loss: 0.4220223699240644
Validation loss: 2.4899054784090437

Epoch: 6| Step: 2
Training loss: 0.24127176421330407
Validation loss: 2.5094727127028085

Epoch: 6| Step: 3
Training loss: 0.3096351074375483
Validation loss: 2.5130015182114134

Epoch: 6| Step: 4
Training loss: 0.5898374342422372
Validation loss: 2.500241585820748

Epoch: 6| Step: 5
Training loss: 0.1986551540417134
Validation loss: 2.541903943814885

Epoch: 6| Step: 6
Training loss: 0.237482679199754
Validation loss: 2.5300373579239985

Epoch: 6| Step: 7
Training loss: 0.339018620231433
Validation loss: 2.519902094845018

Epoch: 6| Step: 8
Training loss: 0.17444190948931057
Validation loss: 2.5554659704985276

Epoch: 6| Step: 9
Training loss: 0.4720092159408035
Validation loss: 2.5525181741199945

Epoch: 6| Step: 10
Training loss: 0.4559524879057632
Validation loss: 2.524191789843676

Epoch: 6| Step: 11
Training loss: 0.3193942842055094
Validation loss: 2.5358716650914848

Epoch: 6| Step: 12
Training loss: 0.4794442644274862
Validation loss: 2.5485165467918374

Epoch: 6| Step: 13
Training loss: 0.3678091346891425
Validation loss: 2.5618304226454365

Epoch: 391| Step: 0
Training loss: 0.41165445176753107
Validation loss: 2.545701450140647

Epoch: 6| Step: 1
Training loss: 0.26102346614602173
Validation loss: 2.560390839950891

Epoch: 6| Step: 2
Training loss: 0.3727375565606767
Validation loss: 2.568571353060857

Epoch: 6| Step: 3
Training loss: 0.33834214444306693
Validation loss: 2.546726900685875

Epoch: 6| Step: 4
Training loss: 0.3634166670229733
Validation loss: 2.5567634373970662

Epoch: 6| Step: 5
Training loss: 0.40633959882540754
Validation loss: 2.549064540086535

Epoch: 6| Step: 6
Training loss: 0.2649029848366208
Validation loss: 2.5418470245740314

Epoch: 6| Step: 7
Training loss: 0.4457871601075309
Validation loss: 2.5196527918385634

Epoch: 6| Step: 8
Training loss: 0.5368231270702312
Validation loss: 2.5296575341944796

Epoch: 6| Step: 9
Training loss: 0.35643661697441525
Validation loss: 2.5262071517021516

Epoch: 6| Step: 10
Training loss: 0.43129445344443923
Validation loss: 2.5335728742833217

Epoch: 6| Step: 11
Training loss: 0.26246190248775547
Validation loss: 2.5580720488751822

Epoch: 6| Step: 12
Training loss: 0.4087067923617739
Validation loss: 2.561461969999804

Epoch: 6| Step: 13
Training loss: 0.37815936696900787
Validation loss: 2.5385850062033986

Epoch: 392| Step: 0
Training loss: 0.2978344021215689
Validation loss: 2.544361608922123

Epoch: 6| Step: 1
Training loss: 0.3532421255401655
Validation loss: 2.552391298525395

Epoch: 6| Step: 2
Training loss: 0.385048641160381
Validation loss: 2.5320224634072948

Epoch: 6| Step: 3
Training loss: 0.5125136280573909
Validation loss: 2.5716073451700314

Epoch: 6| Step: 4
Training loss: 0.43709339252396484
Validation loss: 2.5485425296951987

Epoch: 6| Step: 5
Training loss: 0.29567947091518426
Validation loss: 2.5544988236327

Epoch: 6| Step: 6
Training loss: 0.47535107588368886
Validation loss: 2.523237902126502

Epoch: 6| Step: 7
Training loss: 0.41385364663339214
Validation loss: 2.5444440193383095

Epoch: 6| Step: 8
Training loss: 0.31283339359196155
Validation loss: 2.5327572605831947

Epoch: 6| Step: 9
Training loss: 0.329645279354911
Validation loss: 2.50334328475505

Epoch: 6| Step: 10
Training loss: 0.19570840763721134
Validation loss: 2.512876461948105

Epoch: 6| Step: 11
Training loss: 0.3714904070664292
Validation loss: 2.528684799272438

Epoch: 6| Step: 12
Training loss: 0.6364586889970434
Validation loss: 2.539669673189287

Epoch: 6| Step: 13
Training loss: 0.2587172930543168
Validation loss: 2.504958231980991

Epoch: 393| Step: 0
Training loss: 0.22218383061722935
Validation loss: 2.5150242661883992

Epoch: 6| Step: 1
Training loss: 0.30503235154861164
Validation loss: 2.5098271829027268

Epoch: 6| Step: 2
Training loss: 0.4172555953611177
Validation loss: 2.517015113197444

Epoch: 6| Step: 3
Training loss: 0.2579256445247062
Validation loss: 2.542702763421906

Epoch: 6| Step: 4
Training loss: 0.5588086121815034
Validation loss: 2.536180437068499

Epoch: 6| Step: 5
Training loss: 0.3358146975310653
Validation loss: 2.5808635144539394

Epoch: 6| Step: 6
Training loss: 0.29441170429197844
Validation loss: 2.528428182398186

Epoch: 6| Step: 7
Training loss: 0.4638644087858796
Validation loss: 2.5369349004156168

Epoch: 6| Step: 8
Training loss: 0.427571723007655
Validation loss: 2.5548767599764277

Epoch: 6| Step: 9
Training loss: 0.435701300097538
Validation loss: 2.5091552819624314

Epoch: 6| Step: 10
Training loss: 0.2984551114982382
Validation loss: 2.4912691854999154

Epoch: 6| Step: 11
Training loss: 0.2055181052395366
Validation loss: 2.5188889787811575

Epoch: 6| Step: 12
Training loss: 0.32642383323557905
Validation loss: 2.5303874807998974

Epoch: 6| Step: 13
Training loss: 0.427149176368022
Validation loss: 2.489663593942826

Epoch: 394| Step: 0
Training loss: 0.2510524887242711
Validation loss: 2.4868222921243452

Epoch: 6| Step: 1
Training loss: 0.2634286677191094
Validation loss: 2.4816913501406668

Epoch: 6| Step: 2
Training loss: 0.5871254640203392
Validation loss: 2.4899868783326258

Epoch: 6| Step: 3
Training loss: 0.39575831639364917
Validation loss: 2.479172858001873

Epoch: 6| Step: 4
Training loss: 0.3857829398345709
Validation loss: 2.4838018423720847

Epoch: 6| Step: 5
Training loss: 0.4091244025198364
Validation loss: 2.4638092455733016

Epoch: 6| Step: 6
Training loss: 0.2674565143311389
Validation loss: 2.443878658212322

Epoch: 6| Step: 7
Training loss: 0.1789262652132959
Validation loss: 2.5009309788763616

Epoch: 6| Step: 8
Training loss: 0.2562328263087157
Validation loss: 2.4989834143953034

Epoch: 6| Step: 9
Training loss: 0.46793093647970485
Validation loss: 2.5027542549860944

Epoch: 6| Step: 10
Training loss: 0.47251048086541336
Validation loss: 2.50375866441805

Epoch: 6| Step: 11
Training loss: 0.2782518001354216
Validation loss: 2.507874773364236

Epoch: 6| Step: 12
Training loss: 0.3174547202007359
Validation loss: 2.477585573169821

Epoch: 6| Step: 13
Training loss: 0.181165905467949
Validation loss: 2.5224180471952824

Epoch: 395| Step: 0
Training loss: 0.3057000501611124
Validation loss: 2.4954085554034795

Epoch: 6| Step: 1
Training loss: 0.3529427982464279
Validation loss: 2.543160992940664

Epoch: 6| Step: 2
Training loss: 0.3465745148498028
Validation loss: 2.5411121318900274

Epoch: 6| Step: 3
Training loss: 0.4864968309818725
Validation loss: 2.546453203848562

Epoch: 6| Step: 4
Training loss: 0.2891724609312999
Validation loss: 2.5529964475155884

Epoch: 6| Step: 5
Training loss: 0.3048587342357642
Validation loss: 2.5393091397201126

Epoch: 6| Step: 6
Training loss: 0.24134960127161983
Validation loss: 2.566997334206335

Epoch: 6| Step: 7
Training loss: 0.4702024527528364
Validation loss: 2.524210790146544

Epoch: 6| Step: 8
Training loss: 0.39248606802882247
Validation loss: 2.514729023259528

Epoch: 6| Step: 9
Training loss: 0.36433422115621444
Validation loss: 2.532002713752628

Epoch: 6| Step: 10
Training loss: 0.24830550880105465
Validation loss: 2.5686027514791747

Epoch: 6| Step: 11
Training loss: 0.25326151051398377
Validation loss: 2.5397713983378005

Epoch: 6| Step: 12
Training loss: 0.41562225656392715
Validation loss: 2.5431328156918696

Epoch: 6| Step: 13
Training loss: 0.43369939737016405
Validation loss: 2.5378280023940594

Epoch: 396| Step: 0
Training loss: 0.4201009678957295
Validation loss: 2.5281002745037893

Epoch: 6| Step: 1
Training loss: 0.4339497797076161
Validation loss: 2.531992503730281

Epoch: 6| Step: 2
Training loss: 0.4523200086513575
Validation loss: 2.5465206400747165

Epoch: 6| Step: 3
Training loss: 0.40666533293401125
Validation loss: 2.539315703003792

Epoch: 6| Step: 4
Training loss: 0.38998834225764084
Validation loss: 2.5354095862798998

Epoch: 6| Step: 5
Training loss: 0.12649544599689003
Validation loss: 2.520524547509095

Epoch: 6| Step: 6
Training loss: 0.4157406430949183
Validation loss: 2.548224365430203

Epoch: 6| Step: 7
Training loss: 0.43664538836990785
Validation loss: 2.570819530316048

Epoch: 6| Step: 8
Training loss: 0.33393382085807866
Validation loss: 2.57242934296749

Epoch: 6| Step: 9
Training loss: 0.2594233818201139
Validation loss: 2.560497249632592

Epoch: 6| Step: 10
Training loss: 0.3660452913131256
Validation loss: 2.537357876714131

Epoch: 6| Step: 11
Training loss: 0.24589751003293478
Validation loss: 2.543310590133043

Epoch: 6| Step: 12
Training loss: 0.3738014418945649
Validation loss: 2.5200996690661333

Epoch: 6| Step: 13
Training loss: 0.20616934962314243
Validation loss: 2.5458164789792477

Epoch: 397| Step: 0
Training loss: 0.22485502327445664
Validation loss: 2.523042858843346

Epoch: 6| Step: 1
Training loss: 0.22595955101347243
Validation loss: 2.53387920630871

Epoch: 6| Step: 2
Training loss: 0.40497385005357894
Validation loss: 2.5039176024948975

Epoch: 6| Step: 3
Training loss: 0.3453620693824997
Validation loss: 2.551196838935367

Epoch: 6| Step: 4
Training loss: 0.28240195767356274
Validation loss: 2.5326275608502944

Epoch: 6| Step: 5
Training loss: 0.38163722885010753
Validation loss: 2.566237456534898

Epoch: 6| Step: 6
Training loss: 0.4275440506798791
Validation loss: 2.5606416718967044

Epoch: 6| Step: 7
Training loss: 0.46046776193150973
Validation loss: 2.550688150315547

Epoch: 6| Step: 8
Training loss: 0.28798933834219537
Validation loss: 2.578273383351724

Epoch: 6| Step: 9
Training loss: 0.4954319090967462
Validation loss: 2.547390863731399

Epoch: 6| Step: 10
Training loss: 0.41683964317718686
Validation loss: 2.5416526044284766

Epoch: 6| Step: 11
Training loss: 0.40076652187479217
Validation loss: 2.5464863790506183

Epoch: 6| Step: 12
Training loss: 0.2584511908487703
Validation loss: 2.5357729702692176

Epoch: 6| Step: 13
Training loss: 0.14216151183388756
Validation loss: 2.517788919813993

Epoch: 398| Step: 0
Training loss: 0.46437387199316194
Validation loss: 2.499242171411112

Epoch: 6| Step: 1
Training loss: 0.38276403470660264
Validation loss: 2.4934795891684574

Epoch: 6| Step: 2
Training loss: 0.2243299487638247
Validation loss: 2.514131777865594

Epoch: 6| Step: 3
Training loss: 0.2518543966683936
Validation loss: 2.495333320396793

Epoch: 6| Step: 4
Training loss: 0.38021937663444527
Validation loss: 2.502991527213559

Epoch: 6| Step: 5
Training loss: 0.28277385668954713
Validation loss: 2.5052716827893606

Epoch: 6| Step: 6
Training loss: 0.4527179928992682
Validation loss: 2.5250560939052487

Epoch: 6| Step: 7
Training loss: 0.4350424270109302
Validation loss: 2.507392872216147

Epoch: 6| Step: 8
Training loss: 0.2570909894491551
Validation loss: 2.5167495322593356

Epoch: 6| Step: 9
Training loss: 0.3652226655276413
Validation loss: 2.5120997185186904

Epoch: 6| Step: 10
Training loss: 0.4735433120324142
Validation loss: 2.5459555561650635

Epoch: 6| Step: 11
Training loss: 0.27269909475621823
Validation loss: 2.4965996906152244

Epoch: 6| Step: 12
Training loss: 0.4262217771298331
Validation loss: 2.5436455258428134

Epoch: 6| Step: 13
Training loss: 0.35344034520967865
Validation loss: 2.5630325886417538

Epoch: 399| Step: 0
Training loss: 0.4061378544293314
Validation loss: 2.5451042335290492

Epoch: 6| Step: 1
Training loss: 0.44974819993108944
Validation loss: 2.546562356316423

Epoch: 6| Step: 2
Training loss: 0.2678317935052091
Validation loss: 2.547196862201985

Epoch: 6| Step: 3
Training loss: 0.10045118008456105
Validation loss: 2.5305450604329067

Epoch: 6| Step: 4
Training loss: 0.26583471154111793
Validation loss: 2.503137647886595

Epoch: 6| Step: 5
Training loss: 0.1911228085941753
Validation loss: 2.5149669180075094

Epoch: 6| Step: 6
Training loss: 0.3715578489918847
Validation loss: 2.5112807379428315

Epoch: 6| Step: 7
Training loss: 0.4668140488023151
Validation loss: 2.535093724522444

Epoch: 6| Step: 8
Training loss: 0.4409329569181747
Validation loss: 2.5142128604447396

Epoch: 6| Step: 9
Training loss: 0.20247285030998108
Validation loss: 2.5115922284129515

Epoch: 6| Step: 10
Training loss: 0.5026468314870586
Validation loss: 2.5350226025715368

Epoch: 6| Step: 11
Training loss: 0.37384108438221486
Validation loss: 2.4958265683670007

Epoch: 6| Step: 12
Training loss: 0.38105839151198234
Validation loss: 2.5203194687291424

Epoch: 6| Step: 13
Training loss: 0.3336260027336182
Validation loss: 2.520583078736916

Epoch: 400| Step: 0
Training loss: 0.4968549340472899
Validation loss: 2.5383526199540296

Epoch: 6| Step: 1
Training loss: 0.26020111063779555
Validation loss: 2.506363900734962

Epoch: 6| Step: 2
Training loss: 0.33168196538444655
Validation loss: 2.513792150507959

Epoch: 6| Step: 3
Training loss: 0.38880492573657466
Validation loss: 2.5237697508436274

Epoch: 6| Step: 4
Training loss: 0.4818193789243549
Validation loss: 2.5644316822061457

Epoch: 6| Step: 5
Training loss: 0.24900138607750066
Validation loss: 2.491895616069555

Epoch: 6| Step: 6
Training loss: 0.4496383697413969
Validation loss: 2.5536219051066134

Epoch: 6| Step: 7
Training loss: 0.36852952540733336
Validation loss: 2.5800876161274475

Epoch: 6| Step: 8
Training loss: 0.3708461939621157
Validation loss: 2.511050137274355

Epoch: 6| Step: 9
Training loss: 0.20651621002659318
Validation loss: 2.528439422763687

Epoch: 6| Step: 10
Training loss: 0.3918773032307814
Validation loss: 2.519914165759737

Epoch: 6| Step: 11
Training loss: 0.3671165560100992
Validation loss: 2.47366921014005

Epoch: 6| Step: 12
Training loss: 0.21255293144823983
Validation loss: 2.4838503010500927

Epoch: 6| Step: 13
Training loss: 0.29571502339097994
Validation loss: 2.5046931300210247

Epoch: 401| Step: 0
Training loss: 0.23722999087864668
Validation loss: 2.5044117250433833

Epoch: 6| Step: 1
Training loss: 0.3492768693730986
Validation loss: 2.4866373523150607

Epoch: 6| Step: 2
Training loss: 0.5410998998342607
Validation loss: 2.4739730318126116

Epoch: 6| Step: 3
Training loss: 0.23277493916331396
Validation loss: 2.5346309415240005

Epoch: 6| Step: 4
Training loss: 0.2986474831310128
Validation loss: 2.4866250152198512

Epoch: 6| Step: 5
Training loss: 0.35272896425611155
Validation loss: 2.4758058536415652

Epoch: 6| Step: 6
Training loss: 0.3058420826784724
Validation loss: 2.4879203157656824

Epoch: 6| Step: 7
Training loss: 0.32700639744210996
Validation loss: 2.5466375682546922

Epoch: 6| Step: 8
Training loss: 0.23112100502376215
Validation loss: 2.5390562245785993

Epoch: 6| Step: 9
Training loss: 0.26105811592167116
Validation loss: 2.553719966455774

Epoch: 6| Step: 10
Training loss: 0.3877304214992342
Validation loss: 2.5509228965952495

Epoch: 6| Step: 11
Training loss: 0.5285639456731109
Validation loss: 2.53025733993071

Epoch: 6| Step: 12
Training loss: 0.4063593643874349
Validation loss: 2.5633101484482683

Epoch: 6| Step: 13
Training loss: 0.22717829579384524
Validation loss: 2.54927678003401

Epoch: 402| Step: 0
Training loss: 0.30969997301976104
Validation loss: 2.5249292638896286

Epoch: 6| Step: 1
Training loss: 0.491098834796425
Validation loss: 2.5255552377691837

Epoch: 6| Step: 2
Training loss: 0.21246102059712146
Validation loss: 2.5207203821355786

Epoch: 6| Step: 3
Training loss: 0.37349801471034483
Validation loss: 2.5190895868042555

Epoch: 6| Step: 4
Training loss: 0.31472146094378745
Validation loss: 2.5180552554971207

Epoch: 6| Step: 5
Training loss: 0.48454915269181836
Validation loss: 2.511099656125317

Epoch: 6| Step: 6
Training loss: 0.505568254867926
Validation loss: 2.5116350667825924

Epoch: 6| Step: 7
Training loss: 0.30352036363199336
Validation loss: 2.5027323650063424

Epoch: 6| Step: 8
Training loss: 0.35553883291364213
Validation loss: 2.508211769764346

Epoch: 6| Step: 9
Training loss: 0.29887075681079456
Validation loss: 2.5355390527071506

Epoch: 6| Step: 10
Training loss: 0.2137537093426273
Validation loss: 2.525970052692011

Epoch: 6| Step: 11
Training loss: 0.1887735389090652
Validation loss: 2.5205126661573756

Epoch: 6| Step: 12
Training loss: 0.22517829658690972
Validation loss: 2.543844661265011

Epoch: 6| Step: 13
Training loss: 0.16722322955660698
Validation loss: 2.5607288241165507

Epoch: 403| Step: 0
Training loss: 0.5301103147826197
Validation loss: 2.572376187644218

Epoch: 6| Step: 1
Training loss: 0.27596565165620074
Validation loss: 2.594860144248108

Epoch: 6| Step: 2
Training loss: 0.36565623679771103
Validation loss: 2.535633514417583

Epoch: 6| Step: 3
Training loss: 0.35318705005174933
Validation loss: 2.5359837972377584

Epoch: 6| Step: 4
Training loss: 0.25067039844363637
Validation loss: 2.5232555146375053

Epoch: 6| Step: 5
Training loss: 0.4732390507158395
Validation loss: 2.5210539083067025

Epoch: 6| Step: 6
Training loss: 0.2825846792425444
Validation loss: 2.5004935372194055

Epoch: 6| Step: 7
Training loss: 0.3558974562869982
Validation loss: 2.5030782493686936

Epoch: 6| Step: 8
Training loss: 0.26443458728813546
Validation loss: 2.5150987689615443

Epoch: 6| Step: 9
Training loss: 0.16779747814024246
Validation loss: 2.4994959169219855

Epoch: 6| Step: 10
Training loss: 0.3546904542774732
Validation loss: 2.5024980954067737

Epoch: 6| Step: 11
Training loss: 0.23658587059370495
Validation loss: 2.512286114148275

Epoch: 6| Step: 12
Training loss: 0.3688286366102617
Validation loss: 2.5166519505522076

Epoch: 6| Step: 13
Training loss: 0.5109813123111446
Validation loss: 2.555298782937027

Epoch: 404| Step: 0
Training loss: 0.31869808269749306
Validation loss: 2.510868165856197

Epoch: 6| Step: 1
Training loss: 0.30113897477877816
Validation loss: 2.558064647788301

Epoch: 6| Step: 2
Training loss: 0.2603241788023438
Validation loss: 2.4996893571826075

Epoch: 6| Step: 3
Training loss: 0.15806288449054742
Validation loss: 2.5388549336167148

Epoch: 6| Step: 4
Training loss: 0.31860192543305266
Validation loss: 2.5014274490462114

Epoch: 6| Step: 5
Training loss: 0.33240990084857497
Validation loss: 2.480744660483341

Epoch: 6| Step: 6
Training loss: 0.5055166136353749
Validation loss: 2.5009034903268286

Epoch: 6| Step: 7
Training loss: 0.34925339332808025
Validation loss: 2.5023403718662838

Epoch: 6| Step: 8
Training loss: 0.3209153178459997
Validation loss: 2.551297991931886

Epoch: 6| Step: 9
Training loss: 0.42683298247661916
Validation loss: 2.5140179648906154

Epoch: 6| Step: 10
Training loss: 0.286212532473223
Validation loss: 2.5118060924753585

Epoch: 6| Step: 11
Training loss: 0.1785671301733119
Validation loss: 2.525368743429382

Epoch: 6| Step: 12
Training loss: 0.455487308811131
Validation loss: 2.545180119600089

Epoch: 6| Step: 13
Training loss: 0.2924931416767129
Validation loss: 2.5430919081257914

Epoch: 405| Step: 0
Training loss: 0.19340688911575238
Validation loss: 2.5156866927299557

Epoch: 6| Step: 1
Training loss: 0.3408378006347781
Validation loss: 2.530269907553366

Epoch: 6| Step: 2
Training loss: 0.27244980765413107
Validation loss: 2.541306829440376

Epoch: 6| Step: 3
Training loss: 0.29333130337724395
Validation loss: 2.558891888591543

Epoch: 6| Step: 4
Training loss: 0.38782940906852914
Validation loss: 2.5052936570039543

Epoch: 6| Step: 5
Training loss: 0.4441596215848228
Validation loss: 2.52785364455071

Epoch: 6| Step: 6
Training loss: 0.3088987388527362
Validation loss: 2.5228053120501706

Epoch: 6| Step: 7
Training loss: 0.42376147682266935
Validation loss: 2.5166517936768518

Epoch: 6| Step: 8
Training loss: 0.2367043613555406
Validation loss: 2.5139796249840938

Epoch: 6| Step: 9
Training loss: 0.30171489719042754
Validation loss: 2.548035067612457

Epoch: 6| Step: 10
Training loss: 0.3021534051961446
Validation loss: 2.507886751900622

Epoch: 6| Step: 11
Training loss: 0.37328830116737066
Validation loss: 2.5112826995051063

Epoch: 6| Step: 12
Training loss: 0.3778112260341069
Validation loss: 2.547289943808731

Epoch: 6| Step: 13
Training loss: 0.45624432103006307
Validation loss: 2.5412161332128496

Epoch: 406| Step: 0
Training loss: 0.3440012447146142
Validation loss: 2.5174143926412946

Epoch: 6| Step: 1
Training loss: 0.3270271531936068
Validation loss: 2.5364191711303943

Epoch: 6| Step: 2
Training loss: 0.3013918734889544
Validation loss: 2.517536920318978

Epoch: 6| Step: 3
Training loss: 0.2590487346972422
Validation loss: 2.544975870688012

Epoch: 6| Step: 4
Training loss: 0.3807378134765356
Validation loss: 2.5155251348840126

Epoch: 6| Step: 5
Training loss: 0.3235020702058507
Validation loss: 2.545191610317829

Epoch: 6| Step: 6
Training loss: 0.3892123810726751
Validation loss: 2.4910917596367654

Epoch: 6| Step: 7
Training loss: 0.3800941409022999
Validation loss: 2.5179545365851337

Epoch: 6| Step: 8
Training loss: 0.31063771868481577
Validation loss: 2.470019467792611

Epoch: 6| Step: 9
Training loss: 0.2703015749713627
Validation loss: 2.490569181863211

Epoch: 6| Step: 10
Training loss: 0.36882786898451575
Validation loss: 2.477919036779209

Epoch: 6| Step: 11
Training loss: 0.4593472284239423
Validation loss: 2.475551424843531

Epoch: 6| Step: 12
Training loss: 0.3948377042246389
Validation loss: 2.4827461632741383

Epoch: 6| Step: 13
Training loss: 0.2842028369192184
Validation loss: 2.487079459119548

Epoch: 407| Step: 0
Training loss: 0.37915347577649544
Validation loss: 2.528239098292323

Epoch: 6| Step: 1
Training loss: 0.21546999086571808
Validation loss: 2.5204103020485866

Epoch: 6| Step: 2
Training loss: 0.29447824066892714
Validation loss: 2.5291655645391566

Epoch: 6| Step: 3
Training loss: 0.3527408033188652
Validation loss: 2.543070202049985

Epoch: 6| Step: 4
Training loss: 0.4952079193226912
Validation loss: 2.508448873250537

Epoch: 6| Step: 5
Training loss: 0.4643022284085992
Validation loss: 2.476806004451872

Epoch: 6| Step: 6
Training loss: 0.17972445108043594
Validation loss: 2.513582718164554

Epoch: 6| Step: 7
Training loss: 0.2753303137135276
Validation loss: 2.475528407336031

Epoch: 6| Step: 8
Training loss: 0.20244460593315824
Validation loss: 2.506011855178317

Epoch: 6| Step: 9
Training loss: 0.35745753959780774
Validation loss: 2.4660181881656413

Epoch: 6| Step: 10
Training loss: 0.31490816635846425
Validation loss: 2.470368718740474

Epoch: 6| Step: 11
Training loss: 0.27543701971474
Validation loss: 2.4689027513917043

Epoch: 6| Step: 12
Training loss: 0.5762464572028029
Validation loss: 2.463298929689609

Epoch: 6| Step: 13
Training loss: 0.15725058022674046
Validation loss: 2.4883885200065157

Epoch: 408| Step: 0
Training loss: 0.49143747676251126
Validation loss: 2.4653645744875683

Epoch: 6| Step: 1
Training loss: 0.22466567619246422
Validation loss: 2.4913232002650654

Epoch: 6| Step: 2
Training loss: 0.22228377122332735
Validation loss: 2.526283588671508

Epoch: 6| Step: 3
Training loss: 0.4318391507364341
Validation loss: 2.4987740520479944

Epoch: 6| Step: 4
Training loss: 0.28219959433777875
Validation loss: 2.530869303780036

Epoch: 6| Step: 5
Training loss: 0.30257894155883136
Validation loss: 2.4984309399854783

Epoch: 6| Step: 6
Training loss: 0.3492515906951003
Validation loss: 2.507581197515303

Epoch: 6| Step: 7
Training loss: 0.44089948207758184
Validation loss: 2.5007716761965058

Epoch: 6| Step: 8
Training loss: 0.26645218853032915
Validation loss: 2.5094578899659568

Epoch: 6| Step: 9
Training loss: 0.2199981367509141
Validation loss: 2.484782765851801

Epoch: 6| Step: 10
Training loss: 0.268402889005488
Validation loss: 2.483079794129288

Epoch: 6| Step: 11
Training loss: 0.28554766716175334
Validation loss: 2.4650359642964403

Epoch: 6| Step: 12
Training loss: 0.27804789009991504
Validation loss: 2.48379508182109

Epoch: 6| Step: 13
Training loss: 0.35230087518453373
Validation loss: 2.4940620105661413

Epoch: 409| Step: 0
Training loss: 0.3431545432110583
Validation loss: 2.4737266275720837

Epoch: 6| Step: 1
Training loss: 0.2564159919845396
Validation loss: 2.50010346639499

Epoch: 6| Step: 2
Training loss: 0.4980019044207732
Validation loss: 2.532574248359919

Epoch: 6| Step: 3
Training loss: 0.25248554072667795
Validation loss: 2.531995361001691

Epoch: 6| Step: 4
Training loss: 0.2780992533521495
Validation loss: 2.491625383198114

Epoch: 6| Step: 5
Training loss: 0.2811056534906342
Validation loss: 2.526431230843127

Epoch: 6| Step: 6
Training loss: 0.337808775497499
Validation loss: 2.552758760625544

Epoch: 6| Step: 7
Training loss: 0.15662342985527633
Validation loss: 2.5442297539588776

Epoch: 6| Step: 8
Training loss: 0.3896226802716486
Validation loss: 2.5748661808135713

Epoch: 6| Step: 9
Training loss: 0.44273232974671684
Validation loss: 2.5346745389943828

Epoch: 6| Step: 10
Training loss: 0.4469816814142359
Validation loss: 2.5469884705608625

Epoch: 6| Step: 11
Training loss: 0.2557790644743987
Validation loss: 2.558408304216728

Epoch: 6| Step: 12
Training loss: 0.22678716799744258
Validation loss: 2.5456104351436815

Epoch: 6| Step: 13
Training loss: 0.2511261965209042
Validation loss: 2.5068523613644893

Epoch: 410| Step: 0
Training loss: 0.2365456990382166
Validation loss: 2.5079461162654955

Epoch: 6| Step: 1
Training loss: 0.2717947797702734
Validation loss: 2.512883382986359

Epoch: 6| Step: 2
Training loss: 0.27492315779330057
Validation loss: 2.506844971661441

Epoch: 6| Step: 3
Training loss: 0.3422874200286231
Validation loss: 2.4995197860387934

Epoch: 6| Step: 4
Training loss: 0.24780979240400702
Validation loss: 2.4838401924105074

Epoch: 6| Step: 5
Training loss: 0.23642563187642915
Validation loss: 2.493001518890632

Epoch: 6| Step: 6
Training loss: 0.3508836762347985
Validation loss: 2.5109007973672486

Epoch: 6| Step: 7
Training loss: 0.2870885880399539
Validation loss: 2.4990743176929766

Epoch: 6| Step: 8
Training loss: 0.38292923918428046
Validation loss: 2.4726696712905496

Epoch: 6| Step: 9
Training loss: 0.6069322188615763
Validation loss: 2.520447950635286

Epoch: 6| Step: 10
Training loss: 0.32887457198952835
Validation loss: 2.5178061254864383

Epoch: 6| Step: 11
Training loss: 0.2852428252599159
Validation loss: 2.480375111383496

Epoch: 6| Step: 12
Training loss: 0.18737144831777092
Validation loss: 2.494008929363403

Epoch: 6| Step: 13
Training loss: 0.44628345310684303
Validation loss: 2.489313591288411

Epoch: 411| Step: 0
Training loss: 0.17732417801059155
Validation loss: 2.4900567518566064

Epoch: 6| Step: 1
Training loss: 0.33632422521370514
Validation loss: 2.4869340824335198

Epoch: 6| Step: 2
Training loss: 0.18706052656181063
Validation loss: 2.4872876892986766

Epoch: 6| Step: 3
Training loss: 0.4616052672060037
Validation loss: 2.4823069319083677

Epoch: 6| Step: 4
Training loss: 0.37897209696480383
Validation loss: 2.5121839077249057

Epoch: 6| Step: 5
Training loss: 0.3700163610810357
Validation loss: 2.5070896752188014

Epoch: 6| Step: 6
Training loss: 0.3842464953283195
Validation loss: 2.523024750008131

Epoch: 6| Step: 7
Training loss: 0.3309380542473119
Validation loss: 2.5397972014524854

Epoch: 6| Step: 8
Training loss: 0.23450968369374328
Validation loss: 2.517663738847175

Epoch: 6| Step: 9
Training loss: 0.34567292938257843
Validation loss: 2.5021070763257027

Epoch: 6| Step: 10
Training loss: 0.3264400156651993
Validation loss: 2.5299916078401647

Epoch: 6| Step: 11
Training loss: 0.16309993935057063
Validation loss: 2.508580823569101

Epoch: 6| Step: 12
Training loss: 0.3676558814673111
Validation loss: 2.4925735117597223

Epoch: 6| Step: 13
Training loss: 0.12004202918183086
Validation loss: 2.4881107514476835

Epoch: 412| Step: 0
Training loss: 0.25879142328301147
Validation loss: 2.5553415146259075

Epoch: 6| Step: 1
Training loss: 0.35732149058987095
Validation loss: 2.5305458405031835

Epoch: 6| Step: 2
Training loss: 0.35009895441514244
Validation loss: 2.5328039101312414

Epoch: 6| Step: 3
Training loss: 0.09865141211662477
Validation loss: 2.5534963260166883

Epoch: 6| Step: 4
Training loss: 0.35795060120510913
Validation loss: 2.5497124450085202

Epoch: 6| Step: 5
Training loss: 0.23841041441098054
Validation loss: 2.530154018413287

Epoch: 6| Step: 6
Training loss: 0.456668318405552
Validation loss: 2.5525588583072074

Epoch: 6| Step: 7
Training loss: 0.20739782017883837
Validation loss: 2.5205328740335946

Epoch: 6| Step: 8
Training loss: 0.23975369194716414
Validation loss: 2.535919673158142

Epoch: 6| Step: 9
Training loss: 0.21823678951712586
Validation loss: 2.526535269782616

Epoch: 6| Step: 10
Training loss: 0.5433251562800134
Validation loss: 2.4897917385111725

Epoch: 6| Step: 11
Training loss: 0.294102218167145
Validation loss: 2.476442288506844

Epoch: 6| Step: 12
Training loss: 0.41222558936607256
Validation loss: 2.5000513317621826

Epoch: 6| Step: 13
Training loss: 0.28203177412412345
Validation loss: 2.498980810727234

Epoch: 413| Step: 0
Training loss: 0.3178928795540268
Validation loss: 2.526703470755199

Epoch: 6| Step: 1
Training loss: 0.233126070401084
Validation loss: 2.524787597795396

Epoch: 6| Step: 2
Training loss: 0.30275368167471917
Validation loss: 2.508812540731992

Epoch: 6| Step: 3
Training loss: 0.31095061058889856
Validation loss: 2.5324432191902457

Epoch: 6| Step: 4
Training loss: 0.36110659845091964
Validation loss: 2.498885688039922

Epoch: 6| Step: 5
Training loss: 0.24119821893311597
Validation loss: 2.479138148133345

Epoch: 6| Step: 6
Training loss: 0.3250504592091301
Validation loss: 2.503831190468464

Epoch: 6| Step: 7
Training loss: 0.31800402368318137
Validation loss: 2.5058081253853817

Epoch: 6| Step: 8
Training loss: 0.3179393407919469
Validation loss: 2.483300748978675

Epoch: 6| Step: 9
Training loss: 0.3573671100955702
Validation loss: 2.506041769966502

Epoch: 6| Step: 10
Training loss: 0.35121631532068387
Validation loss: 2.4875664072071384

Epoch: 6| Step: 11
Training loss: 0.18265970520523797
Validation loss: 2.5348339759853284

Epoch: 6| Step: 12
Training loss: 0.375092514864906
Validation loss: 2.509634303408041

Epoch: 6| Step: 13
Training loss: 0.09427486954613994
Validation loss: 2.521078252593943

Epoch: 414| Step: 0
Training loss: 0.3060753830544417
Validation loss: 2.480867983188329

Epoch: 6| Step: 1
Training loss: 0.4346302119774452
Validation loss: 2.5292201297348655

Epoch: 6| Step: 2
Training loss: 0.1897905432154558
Validation loss: 2.528747698141534

Epoch: 6| Step: 3
Training loss: 0.3588090462225213
Validation loss: 2.5468218257005293

Epoch: 6| Step: 4
Training loss: 0.15997631152823028
Validation loss: 2.5707243311322148

Epoch: 6| Step: 5
Training loss: 0.23678528099409815
Validation loss: 2.5238674920960182

Epoch: 6| Step: 6
Training loss: 0.3283896400831483
Validation loss: 2.5026100049952684

Epoch: 6| Step: 7
Training loss: 0.2640601654626703
Validation loss: 2.4926336830729205

Epoch: 6| Step: 8
Training loss: 0.35211574679869184
Validation loss: 2.5329230377892458

Epoch: 6| Step: 9
Training loss: 0.2015309508716731
Validation loss: 2.537403779908359

Epoch: 6| Step: 10
Training loss: 0.37585613749665253
Validation loss: 2.5112351846559844

Epoch: 6| Step: 11
Training loss: 0.408350794606973
Validation loss: 2.521511301637635

Epoch: 6| Step: 12
Training loss: 0.42309346668953246
Validation loss: 2.5187805924669324

Epoch: 6| Step: 13
Training loss: 0.23905855562035278
Validation loss: 2.569259555050915

Epoch: 415| Step: 0
Training loss: 0.3186232754363975
Validation loss: 2.5457921567594153

Epoch: 6| Step: 1
Training loss: 0.32980500156740505
Validation loss: 2.5619724289845243

Epoch: 6| Step: 2
Training loss: 0.36249475557545624
Validation loss: 2.529432547949919

Epoch: 6| Step: 3
Training loss: 0.4516777571264366
Validation loss: 2.5312113625390498

Epoch: 6| Step: 4
Training loss: 0.37204668265372143
Validation loss: 2.517347476419241

Epoch: 6| Step: 5
Training loss: 0.5010812512448666
Validation loss: 2.517750623330359

Epoch: 6| Step: 6
Training loss: 0.27930290375718514
Validation loss: 2.494545698494827

Epoch: 6| Step: 7
Training loss: 0.3420295141602127
Validation loss: 2.4736154063208198

Epoch: 6| Step: 8
Training loss: 0.24274168904080123
Validation loss: 2.4824553947199153

Epoch: 6| Step: 9
Training loss: 0.28498556960113974
Validation loss: 2.458767810996438

Epoch: 6| Step: 10
Training loss: 0.3401628508867
Validation loss: 2.4692636965039454

Epoch: 6| Step: 11
Training loss: 0.3578305019197941
Validation loss: 2.486844025255773

Epoch: 6| Step: 12
Training loss: 0.26497722626841486
Validation loss: 2.4811444609593942

Epoch: 6| Step: 13
Training loss: 0.2210818897476497
Validation loss: 2.5331544425422434

Epoch: 416| Step: 0
Training loss: 0.31068407782552104
Validation loss: 2.522074160534325

Epoch: 6| Step: 1
Training loss: 0.2658719569705989
Validation loss: 2.518365918732773

Epoch: 6| Step: 2
Training loss: 0.21367368261489741
Validation loss: 2.539873056831911

Epoch: 6| Step: 3
Training loss: 0.17255994475634054
Validation loss: 2.539848896224445

Epoch: 6| Step: 4
Training loss: 0.12924083002144615
Validation loss: 2.5465320331322534

Epoch: 6| Step: 5
Training loss: 0.3674337494748452
Validation loss: 2.5337501938505835

Epoch: 6| Step: 6
Training loss: 0.4285332174523732
Validation loss: 2.5320529228925888

Epoch: 6| Step: 7
Training loss: 0.33658555089137093
Validation loss: 2.5372824866979093

Epoch: 6| Step: 8
Training loss: 0.3451362962943082
Validation loss: 2.513319971786699

Epoch: 6| Step: 9
Training loss: 0.27435780012924776
Validation loss: 2.4943001487066017

Epoch: 6| Step: 10
Training loss: 0.27152212141253385
Validation loss: 2.5281965280831433

Epoch: 6| Step: 11
Training loss: 0.3809113687091052
Validation loss: 2.493803953774023

Epoch: 6| Step: 12
Training loss: 0.5361583821742945
Validation loss: 2.483038004577542

Epoch: 6| Step: 13
Training loss: 0.2735759656998369
Validation loss: 2.5021165215156453

Epoch: 417| Step: 0
Training loss: 0.28086786005310416
Validation loss: 2.4753591623043625

Epoch: 6| Step: 1
Training loss: 0.3910799047966157
Validation loss: 2.465068163566743

Epoch: 6| Step: 2
Training loss: 0.3632701338841323
Validation loss: 2.456913547626938

Epoch: 6| Step: 3
Training loss: 0.3043714253256811
Validation loss: 2.4647523437825156

Epoch: 6| Step: 4
Training loss: 0.2886426557276276
Validation loss: 2.4884054499042843

Epoch: 6| Step: 5
Training loss: 0.3456336991593271
Validation loss: 2.502390871895832

Epoch: 6| Step: 6
Training loss: 0.30869675377929817
Validation loss: 2.5138268581425662

Epoch: 6| Step: 7
Training loss: 0.2547681557893146
Validation loss: 2.528260254350888

Epoch: 6| Step: 8
Training loss: 0.305787351076665
Validation loss: 2.5216839978062557

Epoch: 6| Step: 9
Training loss: 0.3599206886412716
Validation loss: 2.549802106569439

Epoch: 6| Step: 10
Training loss: 0.4628461341562127
Validation loss: 2.546568161985644

Epoch: 6| Step: 11
Training loss: 0.26489925815579923
Validation loss: 2.548835459366894

Epoch: 6| Step: 12
Training loss: 0.24846544768324674
Validation loss: 2.5416847902805366

Epoch: 6| Step: 13
Training loss: 0.2067513643286639
Validation loss: 2.5354717040742645

Epoch: 418| Step: 0
Training loss: 0.23810545111433878
Validation loss: 2.52382259414159

Epoch: 6| Step: 1
Training loss: 0.5786583991507553
Validation loss: 2.558265149043394

Epoch: 6| Step: 2
Training loss: 0.3587961303147692
Validation loss: 2.5334065420532195

Epoch: 6| Step: 3
Training loss: 0.3037410856045592
Validation loss: 2.5663334375149343

Epoch: 6| Step: 4
Training loss: 0.1710534237668819
Validation loss: 2.558513684629844

Epoch: 6| Step: 5
Training loss: 0.2815034307318231
Validation loss: 2.5773692734058087

Epoch: 6| Step: 6
Training loss: 0.3457953012285915
Validation loss: 2.51953507887586

Epoch: 6| Step: 7
Training loss: 0.29862081280308034
Validation loss: 2.5672411738389536

Epoch: 6| Step: 8
Training loss: 0.37634235769342306
Validation loss: 2.546151258734561

Epoch: 6| Step: 9
Training loss: 0.32006401798146805
Validation loss: 2.553027275326732

Epoch: 6| Step: 10
Training loss: 0.1786256597118328
Validation loss: 2.5354160706784996

Epoch: 6| Step: 11
Training loss: 0.37222014686771376
Validation loss: 2.5378576871099083

Epoch: 6| Step: 12
Training loss: 0.34484486265569064
Validation loss: 2.5793063631977

Epoch: 6| Step: 13
Training loss: 0.09037190665528075
Validation loss: 2.519941426586247

Epoch: 419| Step: 0
Training loss: 0.2881533269135116
Validation loss: 2.577766329121514

Epoch: 6| Step: 1
Training loss: 0.4196475885292633
Validation loss: 2.562200060002155

Epoch: 6| Step: 2
Training loss: 0.3359619176107977
Validation loss: 2.5345769752837706

Epoch: 6| Step: 3
Training loss: 0.26654099555440686
Validation loss: 2.5276771476774007

Epoch: 6| Step: 4
Training loss: 0.28392209835462523
Validation loss: 2.5479124578217935

Epoch: 6| Step: 5
Training loss: 0.2789104162166811
Validation loss: 2.567087047171086

Epoch: 6| Step: 6
Training loss: 0.3038595884534908
Validation loss: 2.5253110647106665

Epoch: 6| Step: 7
Training loss: 0.2581785377880625
Validation loss: 2.5276569188213833

Epoch: 6| Step: 8
Training loss: 0.30950171255090847
Validation loss: 2.5184344928566844

Epoch: 6| Step: 9
Training loss: 0.441086476043387
Validation loss: 2.536696395791445

Epoch: 6| Step: 10
Training loss: 0.26738321208157717
Validation loss: 2.533319614405097

Epoch: 6| Step: 11
Training loss: 0.21304703137874983
Validation loss: 2.5095252584183028

Epoch: 6| Step: 12
Training loss: 0.38862774469014355
Validation loss: 2.5029079424516323

Epoch: 6| Step: 13
Training loss: 0.19992599980942785
Validation loss: 2.457982789317041

Epoch: 420| Step: 0
Training loss: 0.28064884736531037
Validation loss: 2.4846706048122513

Epoch: 6| Step: 1
Training loss: 0.3711203515406348
Validation loss: 2.460260621931822

Epoch: 6| Step: 2
Training loss: 0.3768042433443588
Validation loss: 2.4490412244299042

Epoch: 6| Step: 3
Training loss: 0.3781352112707531
Validation loss: 2.457226066052948

Epoch: 6| Step: 4
Training loss: 0.32771426560880473
Validation loss: 2.4597131155138094

Epoch: 6| Step: 5
Training loss: 0.2998084897474308
Validation loss: 2.496969475060569

Epoch: 6| Step: 6
Training loss: 0.24734644480506626
Validation loss: 2.4861997957220074

Epoch: 6| Step: 7
Training loss: 0.31009905693774364
Validation loss: 2.4981821629311227

Epoch: 6| Step: 8
Training loss: 0.23831639265217233
Validation loss: 2.544480385390441

Epoch: 6| Step: 9
Training loss: 0.31677524807977253
Validation loss: 2.513534993340382

Epoch: 6| Step: 10
Training loss: 0.40761699301802307
Validation loss: 2.5446677055485183

Epoch: 6| Step: 11
Training loss: 0.29524940341433753
Validation loss: 2.5422152862310012

Epoch: 6| Step: 12
Training loss: 0.26986863954195006
Validation loss: 2.544105538438375

Epoch: 6| Step: 13
Training loss: 0.1947731677789432
Validation loss: 2.537378593016506

Epoch: 421| Step: 0
Training loss: 0.2909326114919917
Validation loss: 2.5222505382277527

Epoch: 6| Step: 1
Training loss: 0.36304681658513466
Validation loss: 2.5038871012509913

Epoch: 6| Step: 2
Training loss: 0.4050269054965382
Validation loss: 2.5484486935968516

Epoch: 6| Step: 3
Training loss: 0.3769074446913282
Validation loss: 2.52354906107881

Epoch: 6| Step: 4
Training loss: 0.1811367141273809
Validation loss: 2.4750750840524303

Epoch: 6| Step: 5
Training loss: 0.23623222580658812
Validation loss: 2.5189550625061554

Epoch: 6| Step: 6
Training loss: 0.34900604699970667
Validation loss: 2.4937239619517495

Epoch: 6| Step: 7
Training loss: 0.3213998203626628
Validation loss: 2.5044259680666108

Epoch: 6| Step: 8
Training loss: 0.14699190590350214
Validation loss: 2.4840097301377724

Epoch: 6| Step: 9
Training loss: 0.24556700024130568
Validation loss: 2.490961893237464

Epoch: 6| Step: 10
Training loss: 0.37043722201163626
Validation loss: 2.53845772052249

Epoch: 6| Step: 11
Training loss: 0.17847477051003746
Validation loss: 2.4701943887339364

Epoch: 6| Step: 12
Training loss: 0.266060612217284
Validation loss: 2.4859292824556642

Epoch: 6| Step: 13
Training loss: 0.45526053902557806
Validation loss: 2.482080846174892

Epoch: 422| Step: 0
Training loss: 0.18698686678623833
Validation loss: 2.5101693515396035

Epoch: 6| Step: 1
Training loss: 0.30984833564385167
Validation loss: 2.499890187630724

Epoch: 6| Step: 2
Training loss: 0.2960704894981959
Validation loss: 2.4718424363352973

Epoch: 6| Step: 3
Training loss: 0.2691317652336159
Validation loss: 2.4894719671513856

Epoch: 6| Step: 4
Training loss: 0.28719137928016536
Validation loss: 2.472513966362019

Epoch: 6| Step: 5
Training loss: 0.2803208713068237
Validation loss: 2.5406567557372868

Epoch: 6| Step: 6
Training loss: 0.23276105542769968
Validation loss: 2.4943086691505347

Epoch: 6| Step: 7
Training loss: 0.272168347618844
Validation loss: 2.5243329429973516

Epoch: 6| Step: 8
Training loss: 0.3889668940845173
Validation loss: 2.5010067271488734

Epoch: 6| Step: 9
Training loss: 0.5164515199887624
Validation loss: 2.5588068942437463

Epoch: 6| Step: 10
Training loss: 0.4566794940992779
Validation loss: 2.5281880285572207

Epoch: 6| Step: 11
Training loss: 0.3700812933836315
Validation loss: 2.5243341180133227

Epoch: 6| Step: 12
Training loss: 0.23374318953144754
Validation loss: 2.5253846660849173

Epoch: 6| Step: 13
Training loss: 0.21708662414222535
Validation loss: 2.5300607240928343

Epoch: 423| Step: 0
Training loss: 0.25218110526673837
Validation loss: 2.5372517429204877

Epoch: 6| Step: 1
Training loss: 0.3128802132273152
Validation loss: 2.5303262858051414

Epoch: 6| Step: 2
Training loss: 0.20083346188971124
Validation loss: 2.5358386229712644

Epoch: 6| Step: 3
Training loss: 0.34523168843784996
Validation loss: 2.5117909533305585

Epoch: 6| Step: 4
Training loss: 0.24860357156050045
Validation loss: 2.535890306949513

Epoch: 6| Step: 5
Training loss: 0.3120729150590755
Validation loss: 2.5786107644478555

Epoch: 6| Step: 6
Training loss: 0.28584113242924614
Validation loss: 2.5588595569984016

Epoch: 6| Step: 7
Training loss: 0.18797688635437568
Validation loss: 2.5481180861242

Epoch: 6| Step: 8
Training loss: 0.22933356301896612
Validation loss: 2.560856039452738

Epoch: 6| Step: 9
Training loss: 0.4344079560875518
Validation loss: 2.5387853287201425

Epoch: 6| Step: 10
Training loss: 0.2944004932225802
Validation loss: 2.5424392980988326

Epoch: 6| Step: 11
Training loss: 0.2674723228058189
Validation loss: 2.552187296742333

Epoch: 6| Step: 12
Training loss: 0.4675958730441275
Validation loss: 2.5592729581419857

Epoch: 6| Step: 13
Training loss: 0.4489242417593535
Validation loss: 2.5383076843103907

Epoch: 424| Step: 0
Training loss: 0.5210546373046558
Validation loss: 2.4863436759269915

Epoch: 6| Step: 1
Training loss: 0.3144733825224106
Validation loss: 2.5481642753787295

Epoch: 6| Step: 2
Training loss: 0.31111084213320894
Validation loss: 2.536531101192113

Epoch: 6| Step: 3
Training loss: 0.23304376828370096
Validation loss: 2.524298757613054

Epoch: 6| Step: 4
Training loss: 0.31023857119625187
Validation loss: 2.539203219241444

Epoch: 6| Step: 5
Training loss: 0.2645891130121494
Validation loss: 2.5523910449125213

Epoch: 6| Step: 6
Training loss: 0.30779622030050574
Validation loss: 2.515930933722693

Epoch: 6| Step: 7
Training loss: 0.23220585152403925
Validation loss: 2.5337636567845987

Epoch: 6| Step: 8
Training loss: 0.28066547900474903
Validation loss: 2.500620537827981

Epoch: 6| Step: 9
Training loss: 0.3832956301592075
Validation loss: 2.524274415947938

Epoch: 6| Step: 10
Training loss: 0.2309365132353353
Validation loss: 2.522310804521495

Epoch: 6| Step: 11
Training loss: 0.31637723813269447
Validation loss: 2.504229009167348

Epoch: 6| Step: 12
Training loss: 0.30283515237222713
Validation loss: 2.535957196123995

Epoch: 6| Step: 13
Training loss: 0.2363578840702857
Validation loss: 2.551883037878236

Epoch: 425| Step: 0
Training loss: 0.2375037531807134
Validation loss: 2.575823006553724

Epoch: 6| Step: 1
Training loss: 0.2768186514457959
Validation loss: 2.597196881959539

Epoch: 6| Step: 2
Training loss: 0.3200002404301455
Validation loss: 2.5348056404328556

Epoch: 6| Step: 3
Training loss: 0.19091299299307463
Validation loss: 2.5303106353810887

Epoch: 6| Step: 4
Training loss: 0.2703294958162882
Validation loss: 2.567110796134337

Epoch: 6| Step: 5
Training loss: 0.48331529306857424
Validation loss: 2.544693657481604

Epoch: 6| Step: 6
Training loss: 0.25085355661036757
Validation loss: 2.536933944962374

Epoch: 6| Step: 7
Training loss: 0.35493538214684284
Validation loss: 2.491785893057249

Epoch: 6| Step: 8
Training loss: 0.33551322404123807
Validation loss: 2.507960296284009

Epoch: 6| Step: 9
Training loss: 0.30590233336690736
Validation loss: 2.5016133793706867

Epoch: 6| Step: 10
Training loss: 0.397671842737771
Validation loss: 2.5023844750564064

Epoch: 6| Step: 11
Training loss: 0.36354707406002035
Validation loss: 2.5341123143735187

Epoch: 6| Step: 12
Training loss: 0.3575668249497132
Validation loss: 2.520459433576252

Epoch: 6| Step: 13
Training loss: 0.33031161926209857
Validation loss: 2.5312375992917215

Epoch: 426| Step: 0
Training loss: 0.27463819642845255
Validation loss: 2.553020345628719

Epoch: 6| Step: 1
Training loss: 0.29592442162365284
Validation loss: 2.582476351367159

Epoch: 6| Step: 2
Training loss: 0.2286736927931162
Validation loss: 2.5784791983393003

Epoch: 6| Step: 3
Training loss: 0.24631558365477813
Validation loss: 2.5750312865399834

Epoch: 6| Step: 4
Training loss: 0.26347780503078294
Validation loss: 2.593863434231685

Epoch: 6| Step: 5
Training loss: 0.32236673329564036
Validation loss: 2.64277703559384

Epoch: 6| Step: 6
Training loss: 0.2887587368869515
Validation loss: 2.563776225664675

Epoch: 6| Step: 7
Training loss: 0.23972239639419068
Validation loss: 2.6150902191107854

Epoch: 6| Step: 8
Training loss: 0.3756498824905502
Validation loss: 2.6110507652950434

Epoch: 6| Step: 9
Training loss: 0.41869497934105065
Validation loss: 2.5801133966037373

Epoch: 6| Step: 10
Training loss: 0.3438448341641681
Validation loss: 2.5805831372334365

Epoch: 6| Step: 11
Training loss: 0.32109792293612177
Validation loss: 2.5625900549862695

Epoch: 6| Step: 12
Training loss: 0.36700333379899563
Validation loss: 2.576637866850443

Epoch: 6| Step: 13
Training loss: 0.4004713209756578
Validation loss: 2.5774552575075167

Epoch: 427| Step: 0
Training loss: 0.24649369574333208
Validation loss: 2.5593776553769

Epoch: 6| Step: 1
Training loss: 0.38812334084885636
Validation loss: 2.569727122610271

Epoch: 6| Step: 2
Training loss: 0.3389832685337792
Validation loss: 2.569982484622394

Epoch: 6| Step: 3
Training loss: 0.3973910483509263
Validation loss: 2.5546911828591954

Epoch: 6| Step: 4
Training loss: 0.23694165250761406
Validation loss: 2.4945353248855575

Epoch: 6| Step: 5
Training loss: 0.3672104483393143
Validation loss: 2.5537374962318338

Epoch: 6| Step: 6
Training loss: 0.3523172224762668
Validation loss: 2.4863906828121944

Epoch: 6| Step: 7
Training loss: 0.24346897051593996
Validation loss: 2.5325647006421894

Epoch: 6| Step: 8
Training loss: 0.2758804726345189
Validation loss: 2.5322691575934657

Epoch: 6| Step: 9
Training loss: 0.2121252774060874
Validation loss: 2.5271213698216535

Epoch: 6| Step: 10
Training loss: 0.28997200855455507
Validation loss: 2.5500075091034886

Epoch: 6| Step: 11
Training loss: 0.31942239226827585
Validation loss: 2.5526700716336492

Epoch: 6| Step: 12
Training loss: 0.21495684334739573
Validation loss: 2.520060993914209

Epoch: 6| Step: 13
Training loss: 0.17765349339851916
Validation loss: 2.59076495480373

Epoch: 428| Step: 0
Training loss: 0.3444690012328318
Validation loss: 2.5991937348769527

Epoch: 6| Step: 1
Training loss: 0.2190428204478537
Validation loss: 2.5592687539758963

Epoch: 6| Step: 2
Training loss: 0.26723077602045114
Validation loss: 2.563540823807323

Epoch: 6| Step: 3
Training loss: 0.3570837912933072
Validation loss: 2.547527330098532

Epoch: 6| Step: 4
Training loss: 0.3017796011653848
Validation loss: 2.5896795539983173

Epoch: 6| Step: 5
Training loss: 0.26639081848735363
Validation loss: 2.5917472846666367

Epoch: 6| Step: 6
Training loss: 0.47502686148534184
Validation loss: 2.5731805037807147

Epoch: 6| Step: 7
Training loss: 0.445342882692626
Validation loss: 2.54532046235257

Epoch: 6| Step: 8
Training loss: 0.19921439296969337
Validation loss: 2.57926631958088

Epoch: 6| Step: 9
Training loss: 0.19574015527818647
Validation loss: 2.5488546259835894

Epoch: 6| Step: 10
Training loss: 0.33869124800415107
Validation loss: 2.5710150593248517

Epoch: 6| Step: 11
Training loss: 0.1793577859507233
Validation loss: 2.5576489820061954

Epoch: 6| Step: 12
Training loss: 0.17725781068352553
Validation loss: 2.544658544735023

Epoch: 6| Step: 13
Training loss: 0.3597701015463129
Validation loss: 2.5940041050024067

Epoch: 429| Step: 0
Training loss: 0.23907234632871613
Validation loss: 2.560123797526648

Epoch: 6| Step: 1
Training loss: 0.3034878368249964
Validation loss: 2.5662816543840186

Epoch: 6| Step: 2
Training loss: 0.2442795548918843
Validation loss: 2.5858446280570195

Epoch: 6| Step: 3
Training loss: 0.3400614468712985
Validation loss: 2.573187761761903

Epoch: 6| Step: 4
Training loss: 0.2972028829000923
Validation loss: 2.534960253811418

Epoch: 6| Step: 5
Training loss: 0.25930273071830623
Validation loss: 2.5402739421057556

Epoch: 6| Step: 6
Training loss: 0.3880702975020105
Validation loss: 2.5313825330798356

Epoch: 6| Step: 7
Training loss: 0.3481690664326614
Validation loss: 2.5060958560814384

Epoch: 6| Step: 8
Training loss: 0.3180332502699721
Validation loss: 2.4915288054114906

Epoch: 6| Step: 9
Training loss: 0.32586287521059165
Validation loss: 2.5058206662610996

Epoch: 6| Step: 10
Training loss: 0.49736273657115243
Validation loss: 2.478359126739844

Epoch: 6| Step: 11
Training loss: 0.2237945288431493
Validation loss: 2.5077997104514282

Epoch: 6| Step: 12
Training loss: 0.3100985884215449
Validation loss: 2.524125043900094

Epoch: 6| Step: 13
Training loss: 0.37044050040589904
Validation loss: 2.4976132869741305

Epoch: 430| Step: 0
Training loss: 0.37386294674104836
Validation loss: 2.4697568778662378

Epoch: 6| Step: 1
Training loss: 0.24514119156103284
Validation loss: 2.511192773341197

Epoch: 6| Step: 2
Training loss: 0.32489769866071955
Validation loss: 2.4959167610808026

Epoch: 6| Step: 3
Training loss: 0.4662036717795171
Validation loss: 2.5012917893328

Epoch: 6| Step: 4
Training loss: 0.26697466666519354
Validation loss: 2.5385079827610966

Epoch: 6| Step: 5
Training loss: 0.24859631878132862
Validation loss: 2.525984334511781

Epoch: 6| Step: 6
Training loss: 0.2053281077893021
Validation loss: 2.5262423757913677

Epoch: 6| Step: 7
Training loss: 0.1839041115694005
Validation loss: 2.5215306362989627

Epoch: 6| Step: 8
Training loss: 0.21420771344314138
Validation loss: 2.496492528000265

Epoch: 6| Step: 9
Training loss: 0.1827603355386517
Validation loss: 2.512668917842737

Epoch: 6| Step: 10
Training loss: 0.2556313962299392
Validation loss: 2.520901397285194

Epoch: 6| Step: 11
Training loss: 0.23017465286075406
Validation loss: 2.5574189661020803

Epoch: 6| Step: 12
Training loss: 0.3021944954110764
Validation loss: 2.5380701399796215

Epoch: 6| Step: 13
Training loss: 0.4579564535467823
Validation loss: 2.5306394735297078

Epoch: 431| Step: 0
Training loss: 0.3022544378999222
Validation loss: 2.5776257744764193

Epoch: 6| Step: 1
Training loss: 0.31199531332952574
Validation loss: 2.5538942891154903

Epoch: 6| Step: 2
Training loss: 0.18868189088129478
Validation loss: 2.5673619478714436

Epoch: 6| Step: 3
Training loss: 0.3000924534196143
Validation loss: 2.5779959488803494

Epoch: 6| Step: 4
Training loss: 0.2704463021203827
Validation loss: 2.543861799546468

Epoch: 6| Step: 5
Training loss: 0.22084710817440914
Validation loss: 2.5558718706568446

Epoch: 6| Step: 6
Training loss: 0.33008983974999173
Validation loss: 2.5278562864284866

Epoch: 6| Step: 7
Training loss: 0.20601058777316947
Validation loss: 2.5431223711193307

Epoch: 6| Step: 8
Training loss: 0.26183222687675856
Validation loss: 2.521804409643024

Epoch: 6| Step: 9
Training loss: 0.33445336502020245
Validation loss: 2.5156239269012017

Epoch: 6| Step: 10
Training loss: 0.33672402592395684
Validation loss: 2.541026714847735

Epoch: 6| Step: 11
Training loss: 0.10158413876586336
Validation loss: 2.538236587774801

Epoch: 6| Step: 12
Training loss: 0.24375463872554873
Validation loss: 2.5054535869280237

Epoch: 6| Step: 13
Training loss: 0.48368849866098285
Validation loss: 2.4974388570438353

Epoch: 432| Step: 0
Training loss: 0.24173079005106723
Validation loss: 2.5136473896307057

Epoch: 6| Step: 1
Training loss: 0.3301333432029797
Validation loss: 2.4826080019352545

Epoch: 6| Step: 2
Training loss: 0.34187849977504664
Validation loss: 2.509124651792881

Epoch: 6| Step: 3
Training loss: 0.37327027746642727
Validation loss: 2.503649193540671

Epoch: 6| Step: 4
Training loss: 0.1932804062006918
Validation loss: 2.5004573137131194

Epoch: 6| Step: 5
Training loss: 0.2286711269688337
Validation loss: 2.546213035436205

Epoch: 6| Step: 6
Training loss: 0.2320076272158781
Validation loss: 2.5092540874836655

Epoch: 6| Step: 7
Training loss: 0.2659476788609037
Validation loss: 2.547941997882669

Epoch: 6| Step: 8
Training loss: 0.2618285703127696
Validation loss: 2.5400282216734813

Epoch: 6| Step: 9
Training loss: 0.2327653206634222
Validation loss: 2.554591351412275

Epoch: 6| Step: 10
Training loss: 0.43856752807161664
Validation loss: 2.554995650650624

Epoch: 6| Step: 11
Training loss: 0.16018328787363065
Validation loss: 2.5369211107298097

Epoch: 6| Step: 12
Training loss: 0.2420153621386713
Validation loss: 2.532452507200938

Epoch: 6| Step: 13
Training loss: 0.2919528003269235
Validation loss: 2.526034965713454

Epoch: 433| Step: 0
Training loss: 0.25646602259362017
Validation loss: 2.508379094558769

Epoch: 6| Step: 1
Training loss: 0.23577352345562155
Validation loss: 2.516411973813323

Epoch: 6| Step: 2
Training loss: 0.32405738951608815
Validation loss: 2.531016159852907

Epoch: 6| Step: 3
Training loss: 0.2300017118260701
Validation loss: 2.5014841893648105

Epoch: 6| Step: 4
Training loss: 0.21609052942541968
Validation loss: 2.504087318614414

Epoch: 6| Step: 5
Training loss: 0.40726988491082106
Validation loss: 2.4956740514133737

Epoch: 6| Step: 6
Training loss: 0.16035369007404374
Validation loss: 2.5557384067384756

Epoch: 6| Step: 7
Training loss: 0.24912333261283107
Validation loss: 2.54041640060736

Epoch: 6| Step: 8
Training loss: 0.20044227811841445
Validation loss: 2.510374018217037

Epoch: 6| Step: 9
Training loss: 0.29229609516447813
Validation loss: 2.5207011968656343

Epoch: 6| Step: 10
Training loss: 0.20676966101524685
Validation loss: 2.5576753795657647

Epoch: 6| Step: 11
Training loss: 0.14762420962636486
Validation loss: 2.563581273063052

Epoch: 6| Step: 12
Training loss: 0.40806975307670545
Validation loss: 2.529079476406308

Epoch: 6| Step: 13
Training loss: 0.38647200679324456
Validation loss: 2.5389960763224027

Epoch: 434| Step: 0
Training loss: 0.25506734197236874
Validation loss: 2.5802959540744475

Epoch: 6| Step: 1
Training loss: 0.3403137070745634
Validation loss: 2.5649032028494463

Epoch: 6| Step: 2
Training loss: 0.3370678094763662
Validation loss: 2.5868050270348895

Epoch: 6| Step: 3
Training loss: 0.29524184547374827
Validation loss: 2.553445914292168

Epoch: 6| Step: 4
Training loss: 0.2574854712878161
Validation loss: 2.5607034992271753

Epoch: 6| Step: 5
Training loss: 0.2460053527349504
Validation loss: 2.559309222669407

Epoch: 6| Step: 6
Training loss: 0.22948475277809147
Validation loss: 2.52226620868004

Epoch: 6| Step: 7
Training loss: 0.2473559556577376
Validation loss: 2.538949722296991

Epoch: 6| Step: 8
Training loss: 0.388172826077812
Validation loss: 2.5171118293724173

Epoch: 6| Step: 9
Training loss: 0.35754802958095294
Validation loss: 2.5059014550872964

Epoch: 6| Step: 10
Training loss: 0.2785733060240796
Validation loss: 2.5239021302494415

Epoch: 6| Step: 11
Training loss: 0.2564348345066436
Validation loss: 2.4962794773217505

Epoch: 6| Step: 12
Training loss: 0.3086266319043263
Validation loss: 2.4814577078904474

Epoch: 6| Step: 13
Training loss: 0.2248331116604425
Validation loss: 2.524841277775774

Epoch: 435| Step: 0
Training loss: 0.28534886635009876
Validation loss: 2.511810133681788

Epoch: 6| Step: 1
Training loss: 0.32306230501274946
Validation loss: 2.5475056487324954

Epoch: 6| Step: 2
Training loss: 0.3951504258239085
Validation loss: 2.547853465217844

Epoch: 6| Step: 3
Training loss: 0.31247527501522737
Validation loss: 2.534682387157296

Epoch: 6| Step: 4
Training loss: 0.28270564616103844
Validation loss: 2.5645939924849412

Epoch: 6| Step: 5
Training loss: 0.1929157060622597
Validation loss: 2.5487927096281924

Epoch: 6| Step: 6
Training loss: 0.15408064986789696
Validation loss: 2.5726385093675104

Epoch: 6| Step: 7
Training loss: 0.23138772272127395
Validation loss: 2.607178356189935

Epoch: 6| Step: 8
Training loss: 0.2428501201388616
Validation loss: 2.6079430770547933

Epoch: 6| Step: 9
Training loss: 0.23986710021581437
Validation loss: 2.5802102255970882

Epoch: 6| Step: 10
Training loss: 0.24616525004923495
Validation loss: 2.568683947033365

Epoch: 6| Step: 11
Training loss: 0.31943213037699686
Validation loss: 2.574120354113612

Epoch: 6| Step: 12
Training loss: 0.23309961446659014
Validation loss: 2.562434445995058

Epoch: 6| Step: 13
Training loss: 0.24021227665190223
Validation loss: 2.5531978161859965

Epoch: 436| Step: 0
Training loss: 0.2190203698822617
Validation loss: 2.5773874957579177

Epoch: 6| Step: 1
Training loss: 0.2487162771321321
Validation loss: 2.5529092409523293

Epoch: 6| Step: 2
Training loss: 0.17478774430834132
Validation loss: 2.550795269785808

Epoch: 6| Step: 3
Training loss: 0.3497597142057307
Validation loss: 2.566459645841353

Epoch: 6| Step: 4
Training loss: 0.3430201085767707
Validation loss: 2.5676254737998407

Epoch: 6| Step: 5
Training loss: 0.20558262486935583
Validation loss: 2.5444487479922477

Epoch: 6| Step: 6
Training loss: 0.3580776930981737
Validation loss: 2.5187797924679702

Epoch: 6| Step: 7
Training loss: 0.2670846830493627
Validation loss: 2.5412138628527052

Epoch: 6| Step: 8
Training loss: 0.2496546878787313
Validation loss: 2.5465078466080078

Epoch: 6| Step: 9
Training loss: 0.3480249121829505
Validation loss: 2.522876853612138

Epoch: 6| Step: 10
Training loss: 0.2724866547291476
Validation loss: 2.530116402797112

Epoch: 6| Step: 11
Training loss: 0.2873064778866663
Validation loss: 2.5632302559041933

Epoch: 6| Step: 12
Training loss: 0.33024959511988367
Validation loss: 2.5514536425865626

Epoch: 6| Step: 13
Training loss: 0.21433349183892708
Validation loss: 2.53268007053683

Epoch: 437| Step: 0
Training loss: 0.24163190116144348
Validation loss: 2.541831054260013

Epoch: 6| Step: 1
Training loss: 0.11567769203157564
Validation loss: 2.53599954305704

Epoch: 6| Step: 2
Training loss: 0.34300253621309235
Validation loss: 2.5317826991081396

Epoch: 6| Step: 3
Training loss: 0.259753793432643
Validation loss: 2.519283367000477

Epoch: 6| Step: 4
Training loss: 0.37110710120025514
Validation loss: 2.5268250211831447

Epoch: 6| Step: 5
Training loss: 0.19931347782688233
Validation loss: 2.510686868443547

Epoch: 6| Step: 6
Training loss: 0.2176639726532565
Validation loss: 2.512217741606511

Epoch: 6| Step: 7
Training loss: 0.2819246835757414
Validation loss: 2.5277973805188494

Epoch: 6| Step: 8
Training loss: 0.3416669544164485
Validation loss: 2.4844266576924157

Epoch: 6| Step: 9
Training loss: 0.244874857233112
Validation loss: 2.539656805842675

Epoch: 6| Step: 10
Training loss: 0.22922547445594496
Validation loss: 2.5503943179239785

Epoch: 6| Step: 11
Training loss: 0.27069770950691313
Validation loss: 2.525628128597745

Epoch: 6| Step: 12
Training loss: 0.20497276687873528
Validation loss: 2.5561345110995193

Epoch: 6| Step: 13
Training loss: 0.36487974197636175
Validation loss: 2.5601601210985008

Epoch: 438| Step: 0
Training loss: 0.3904437979991241
Validation loss: 2.5904247358777535

Epoch: 6| Step: 1
Training loss: 0.18549717689304127
Validation loss: 2.5679615723477585

Epoch: 6| Step: 2
Training loss: 0.2941289309219919
Validation loss: 2.5506405041462616

Epoch: 6| Step: 3
Training loss: 0.2993260144034191
Validation loss: 2.5551010087692165

Epoch: 6| Step: 4
Training loss: 0.19471506297172084
Validation loss: 2.561781439590045

Epoch: 6| Step: 5
Training loss: 0.36591748496421433
Validation loss: 2.5233286344537795

Epoch: 6| Step: 6
Training loss: 0.2594213427082279
Validation loss: 2.5544370009306614

Epoch: 6| Step: 7
Training loss: 0.13418624562057865
Validation loss: 2.552835078435474

Epoch: 6| Step: 8
Training loss: 0.18949665474014896
Validation loss: 2.5038402165295555

Epoch: 6| Step: 9
Training loss: 0.2972475023798367
Validation loss: 2.5071272058260634

Epoch: 6| Step: 10
Training loss: 0.24345789242441795
Validation loss: 2.5278075872021324

Epoch: 6| Step: 11
Training loss: 0.35391709940534855
Validation loss: 2.5243404368884494

Epoch: 6| Step: 12
Training loss: 0.25639222257229044
Validation loss: 2.5478238114352094

Epoch: 6| Step: 13
Training loss: 0.37805908905498525
Validation loss: 2.522321574629583

Epoch: 439| Step: 0
Training loss: 0.27611526221947424
Validation loss: 2.5367634531976218

Epoch: 6| Step: 1
Training loss: 0.32277701290827515
Validation loss: 2.539181875194529

Epoch: 6| Step: 2
Training loss: 0.28918822879175904
Validation loss: 2.53046306661429

Epoch: 6| Step: 3
Training loss: 0.35000779449775504
Validation loss: 2.560636075093418

Epoch: 6| Step: 4
Training loss: 0.2835904071285067
Validation loss: 2.5654767602178548

Epoch: 6| Step: 5
Training loss: 0.3184691982758363
Validation loss: 2.5542538779671466

Epoch: 6| Step: 6
Training loss: 0.26031293074445133
Validation loss: 2.5566977187585236

Epoch: 6| Step: 7
Training loss: 0.16452233835595234
Validation loss: 2.5079749147442505

Epoch: 6| Step: 8
Training loss: 0.3069219817035289
Validation loss: 2.532185567836082

Epoch: 6| Step: 9
Training loss: 0.24688136750471934
Validation loss: 2.4852676018651025

Epoch: 6| Step: 10
Training loss: 0.2288562078750996
Validation loss: 2.507165892347934

Epoch: 6| Step: 11
Training loss: 0.2943387234561652
Validation loss: 2.5177226084517295

Epoch: 6| Step: 12
Training loss: 0.24613337727554394
Validation loss: 2.490144938552474

Epoch: 6| Step: 13
Training loss: 0.3419099130360182
Validation loss: 2.466685693615357

Epoch: 440| Step: 0
Training loss: 0.1635759382015213
Validation loss: 2.524855348185439

Epoch: 6| Step: 1
Training loss: 0.15369036535622474
Validation loss: 2.533836178940818

Epoch: 6| Step: 2
Training loss: 0.32473977289548644
Validation loss: 2.5767572776764336

Epoch: 6| Step: 3
Training loss: 0.551108567395843
Validation loss: 2.5953769456520943

Epoch: 6| Step: 4
Training loss: 0.3177439938006836
Validation loss: 2.549817989003601

Epoch: 6| Step: 5
Training loss: 0.31567037039129464
Validation loss: 2.512484103092175

Epoch: 6| Step: 6
Training loss: 0.2925669903539961
Validation loss: 2.479171392722902

Epoch: 6| Step: 7
Training loss: 0.3461870265839689
Validation loss: 2.428146746902531

Epoch: 6| Step: 8
Training loss: 0.6599519176380438
Validation loss: 2.437451732610907

Epoch: 6| Step: 9
Training loss: 0.34978814056638285
Validation loss: 2.4500299924865074

Epoch: 6| Step: 10
Training loss: 0.31528769683825697
Validation loss: 2.468667886328183

Epoch: 6| Step: 11
Training loss: 0.35041716824872515
Validation loss: 2.4889423341329002

Epoch: 6| Step: 12
Training loss: 0.2950888154929071
Validation loss: 2.565850089649724

Epoch: 6| Step: 13
Training loss: 0.40210555720142793
Validation loss: 2.599155632012216

Epoch: 441| Step: 0
Training loss: 0.408507238386965
Validation loss: 2.59048532811333

Epoch: 6| Step: 1
Training loss: 0.3366435305491477
Validation loss: 2.5597923434063463

Epoch: 6| Step: 2
Training loss: 0.23942796534525937
Validation loss: 2.502619192703544

Epoch: 6| Step: 3
Training loss: 0.3661689632520566
Validation loss: 2.5302169719478274

Epoch: 6| Step: 4
Training loss: 0.35554457474100465
Validation loss: 2.4662392370936965

Epoch: 6| Step: 5
Training loss: 0.17637146303522172
Validation loss: 2.479842167796957

Epoch: 6| Step: 6
Training loss: 0.2220157059604847
Validation loss: 2.4819984040308687

Epoch: 6| Step: 7
Training loss: 0.3013791915668523
Validation loss: 2.4844095789181764

Epoch: 6| Step: 8
Training loss: 0.390960949439195
Validation loss: 2.4476054339118143

Epoch: 6| Step: 9
Training loss: 0.5001592978396829
Validation loss: 2.496669845246614

Epoch: 6| Step: 10
Training loss: 0.6222697227328737
Validation loss: 2.4983712448636406

Epoch: 6| Step: 11
Training loss: 0.40967277005715935
Validation loss: 2.4845629297431295

Epoch: 6| Step: 12
Training loss: 0.2607571744004972
Validation loss: 2.507457183690559

Epoch: 6| Step: 13
Training loss: 0.13310542480960605
Validation loss: 2.5240668756429536

Epoch: 442| Step: 0
Training loss: 0.5119837009491737
Validation loss: 2.5595210708455247

Epoch: 6| Step: 1
Training loss: 0.3287123917509516
Validation loss: 2.5965607722682735

Epoch: 6| Step: 2
Training loss: 0.3795786917549581
Validation loss: 2.5630892414527513

Epoch: 6| Step: 3
Training loss: 0.40664829389832674
Validation loss: 2.604042203492551

Epoch: 6| Step: 4
Training loss: 0.29126270737165655
Validation loss: 2.5737686661303254

Epoch: 6| Step: 5
Training loss: 0.3369280273197049
Validation loss: 2.548597430686971

Epoch: 6| Step: 6
Training loss: 0.3053571482549235
Validation loss: 2.502337262515433

Epoch: 6| Step: 7
Training loss: 0.28368473537566186
Validation loss: 2.5119879040983673

Epoch: 6| Step: 8
Training loss: 0.2564100643666936
Validation loss: 2.4719315321060504

Epoch: 6| Step: 9
Training loss: 0.3444106191398321
Validation loss: 2.5054372214274

Epoch: 6| Step: 10
Training loss: 0.5610619813301143
Validation loss: 2.5158846733942957

Epoch: 6| Step: 11
Training loss: 0.37835108012043583
Validation loss: 2.5083464726572804

Epoch: 6| Step: 12
Training loss: 0.3560621318363257
Validation loss: 2.5486792525040607

Epoch: 6| Step: 13
Training loss: 0.21652015002220631
Validation loss: 2.5340930433349484

Epoch: 443| Step: 0
Training loss: 0.27074185379221305
Validation loss: 2.5977700727187334

Epoch: 6| Step: 1
Training loss: 0.45881261655480976
Validation loss: 2.587763549879535

Epoch: 6| Step: 2
Training loss: 0.35618694818242774
Validation loss: 2.57172927037876

Epoch: 6| Step: 3
Training loss: 0.34268137246998187
Validation loss: 2.621980104895768

Epoch: 6| Step: 4
Training loss: 0.3022780640291356
Validation loss: 2.5811839179188327

Epoch: 6| Step: 5
Training loss: 0.4020133838026946
Validation loss: 2.5757905207199556

Epoch: 6| Step: 6
Training loss: 0.3054076511714312
Validation loss: 2.5395915898932464

Epoch: 6| Step: 7
Training loss: 0.3897790140286485
Validation loss: 2.534747083130621

Epoch: 6| Step: 8
Training loss: 0.31635303991797675
Validation loss: 2.509587959189576

Epoch: 6| Step: 9
Training loss: 0.29121219473553983
Validation loss: 2.4771001994284134

Epoch: 6| Step: 10
Training loss: 0.38518934591291426
Validation loss: 2.501047711638988

Epoch: 6| Step: 11
Training loss: 0.2792622337999813
Validation loss: 2.4812486697064995

Epoch: 6| Step: 12
Training loss: 0.3162973946652494
Validation loss: 2.441840592664156

Epoch: 6| Step: 13
Training loss: 0.15175799096095763
Validation loss: 2.5149008171532676

Epoch: 444| Step: 0
Training loss: 0.30129730244994796
Validation loss: 2.515456053147766

Epoch: 6| Step: 1
Training loss: 0.20534962438953527
Validation loss: 2.5326625954340187

Epoch: 6| Step: 2
Training loss: 0.3442073185841148
Validation loss: 2.534389699320218

Epoch: 6| Step: 3
Training loss: 0.2540996255295016
Validation loss: 2.524089679555201

Epoch: 6| Step: 4
Training loss: 0.2715489290180485
Validation loss: 2.5426627896346865

Epoch: 6| Step: 5
Training loss: 0.3717305191248612
Validation loss: 2.541042774459561

Epoch: 6| Step: 6
Training loss: 0.4181050942761825
Validation loss: 2.5572278621914193

Epoch: 6| Step: 7
Training loss: 0.23277175437957615
Validation loss: 2.550626298068381

Epoch: 6| Step: 8
Training loss: 0.27024445642048894
Validation loss: 2.5604160167425896

Epoch: 6| Step: 9
Training loss: 0.17180906461567869
Validation loss: 2.5409431584334135

Epoch: 6| Step: 10
Training loss: 0.32570737325853716
Validation loss: 2.552788074888075

Epoch: 6| Step: 11
Training loss: 0.30039400711437475
Validation loss: 2.558259807838298

Epoch: 6| Step: 12
Training loss: 0.2286821557364295
Validation loss: 2.570639071299234

Epoch: 6| Step: 13
Training loss: 0.3515994052589809
Validation loss: 2.5535797399781637

Epoch: 445| Step: 0
Training loss: 0.21100280775048402
Validation loss: 2.5498831095436727

Epoch: 6| Step: 1
Training loss: 0.3163890245246336
Validation loss: 2.528323685468545

Epoch: 6| Step: 2
Training loss: 0.3062413890756882
Validation loss: 2.5107493952146593

Epoch: 6| Step: 3
Training loss: 0.2929049867541513
Validation loss: 2.5076787191783563

Epoch: 6| Step: 4
Training loss: 0.3764120577011421
Validation loss: 2.5007026930737517

Epoch: 6| Step: 5
Training loss: 0.23381332806927746
Validation loss: 2.532441509382712

Epoch: 6| Step: 6
Training loss: 0.20940812546323273
Validation loss: 2.527608579871542

Epoch: 6| Step: 7
Training loss: 0.28750290143580687
Validation loss: 2.4898972368530465

Epoch: 6| Step: 8
Training loss: 0.35232119815829377
Validation loss: 2.49865754600345

Epoch: 6| Step: 9
Training loss: 0.24696785230930798
Validation loss: 2.510456507836449

Epoch: 6| Step: 10
Training loss: 0.12091379484090445
Validation loss: 2.504263961949641

Epoch: 6| Step: 11
Training loss: 0.2485108803995012
Validation loss: 2.515479831969311

Epoch: 6| Step: 12
Training loss: 0.23648994202326118
Validation loss: 2.512402670337328

Epoch: 6| Step: 13
Training loss: 0.12259578520480639
Validation loss: 2.50195451238349

Epoch: 446| Step: 0
Training loss: 0.2291580039612303
Validation loss: 2.553250924468954

Epoch: 6| Step: 1
Training loss: 0.22140209109291029
Validation loss: 2.5415373982304588

Epoch: 6| Step: 2
Training loss: 0.24994474038704356
Validation loss: 2.5509385562319338

Epoch: 6| Step: 3
Training loss: 0.25690092417731536
Validation loss: 2.5596105275344723

Epoch: 6| Step: 4
Training loss: 0.18263103820171275
Validation loss: 2.5393391422988207

Epoch: 6| Step: 5
Training loss: 0.2636514161261253
Validation loss: 2.5798332667826034

Epoch: 6| Step: 6
Training loss: 0.3034351482752017
Validation loss: 2.5576904545990695

Epoch: 6| Step: 7
Training loss: 0.3082169755692948
Validation loss: 2.555323060820085

Epoch: 6| Step: 8
Training loss: 0.24933848927617588
Validation loss: 2.553488006332251

Epoch: 6| Step: 9
Training loss: 0.29939922288524323
Validation loss: 2.548198562134066

Epoch: 6| Step: 10
Training loss: 0.31889979591922324
Validation loss: 2.5313097563019724

Epoch: 6| Step: 11
Training loss: 0.3114711873114244
Validation loss: 2.55444550544832

Epoch: 6| Step: 12
Training loss: 0.20173940879291735
Validation loss: 2.520506681470367

Epoch: 6| Step: 13
Training loss: 0.21384048295190758
Validation loss: 2.538431658378802

Epoch: 447| Step: 0
Training loss: 0.22985125919058952
Validation loss: 2.548946467039401

Epoch: 6| Step: 1
Training loss: 0.1270691048429594
Validation loss: 2.53525755357356

Epoch: 6| Step: 2
Training loss: 0.1819557512256769
Validation loss: 2.5763754597809863

Epoch: 6| Step: 3
Training loss: 0.2722469843390039
Validation loss: 2.562631887287856

Epoch: 6| Step: 4
Training loss: 0.24817856724479906
Validation loss: 2.5701546419647934

Epoch: 6| Step: 5
Training loss: 0.2596452046688509
Validation loss: 2.5679991567249516

Epoch: 6| Step: 6
Training loss: 0.263092393236596
Validation loss: 2.5413802020948975

Epoch: 6| Step: 7
Training loss: 0.26306240143596227
Validation loss: 2.526013014114678

Epoch: 6| Step: 8
Training loss: 0.10393688567708888
Validation loss: 2.5519290464741182

Epoch: 6| Step: 9
Training loss: 0.2162885807328924
Validation loss: 2.533596946502282

Epoch: 6| Step: 10
Training loss: 0.4513933208036077
Validation loss: 2.5695007984493046

Epoch: 6| Step: 11
Training loss: 0.35416426611068075
Validation loss: 2.5688071507009886

Epoch: 6| Step: 12
Training loss: 0.25029469049273084
Validation loss: 2.576416993128624

Epoch: 6| Step: 13
Training loss: 0.35065279989820464
Validation loss: 2.567580783874862

Epoch: 448| Step: 0
Training loss: 0.25380838415438844
Validation loss: 2.539888144667224

Epoch: 6| Step: 1
Training loss: 0.264401408538118
Validation loss: 2.5245217428688003

Epoch: 6| Step: 2
Training loss: 0.22231673405593802
Validation loss: 2.5361344955586396

Epoch: 6| Step: 3
Training loss: 0.3030341233365778
Validation loss: 2.5315883414908806

Epoch: 6| Step: 4
Training loss: 0.29181167993942986
Validation loss: 2.5471199794054202

Epoch: 6| Step: 5
Training loss: 0.3549934395331659
Validation loss: 2.5830935662340404

Epoch: 6| Step: 6
Training loss: 0.16444673276606253
Validation loss: 2.5299248831782597

Epoch: 6| Step: 7
Training loss: 0.22342892476946083
Validation loss: 2.5694537350982642

Epoch: 6| Step: 8
Training loss: 0.252700628300502
Validation loss: 2.558456353834597

Epoch: 6| Step: 9
Training loss: 0.26659074698507335
Validation loss: 2.5500358984171867

Epoch: 6| Step: 10
Training loss: 0.3699382862934071
Validation loss: 2.575298297265142

Epoch: 6| Step: 11
Training loss: 0.23237634260898862
Validation loss: 2.545390312561397

Epoch: 6| Step: 12
Training loss: 0.22018340197162348
Validation loss: 2.5389974878915837

Epoch: 6| Step: 13
Training loss: 0.10167811305687939
Validation loss: 2.559836959992252

Epoch: 449| Step: 0
Training loss: 0.26425084727285897
Validation loss: 2.555793569179064

Epoch: 6| Step: 1
Training loss: 0.20644853565944438
Validation loss: 2.5682963382529604

Epoch: 6| Step: 2
Training loss: 0.15738644970411697
Validation loss: 2.553655944908473

Epoch: 6| Step: 3
Training loss: 0.41868353714799345
Validation loss: 2.5488286138243414

Epoch: 6| Step: 4
Training loss: 0.27343811307565896
Validation loss: 2.5246127814202617

Epoch: 6| Step: 5
Training loss: 0.21460734278574561
Validation loss: 2.5151474675949244

Epoch: 6| Step: 6
Training loss: 0.1996206082581744
Validation loss: 2.505771715771716

Epoch: 6| Step: 7
Training loss: 0.33130037986262656
Validation loss: 2.5346800183992992

Epoch: 6| Step: 8
Training loss: 0.22345608387204358
Validation loss: 2.5305211769960394

Epoch: 6| Step: 9
Training loss: 0.1401477769482803
Validation loss: 2.4798499310447424

Epoch: 6| Step: 10
Training loss: 0.19851282747557655
Validation loss: 2.4981939293406095

Epoch: 6| Step: 11
Training loss: 0.33193010023657366
Validation loss: 2.5310049157374563

Epoch: 6| Step: 12
Training loss: 0.22000567193197437
Validation loss: 2.4996666665532663

Epoch: 6| Step: 13
Training loss: 0.27385380253139435
Validation loss: 2.49893187654845

Epoch: 450| Step: 0
Training loss: 0.3554723341205707
Validation loss: 2.470825636374667

Epoch: 6| Step: 1
Training loss: 0.24910745886227417
Validation loss: 2.441526956441458

Epoch: 6| Step: 2
Training loss: 0.2463982529875514
Validation loss: 2.463165037094628

Epoch: 6| Step: 3
Training loss: 0.35482026778764975
Validation loss: 2.4990447880571827

Epoch: 6| Step: 4
Training loss: 0.26042162731532176
Validation loss: 2.500370460667315

Epoch: 6| Step: 5
Training loss: 0.30252637793470905
Validation loss: 2.4994944538131993

Epoch: 6| Step: 6
Training loss: 0.16307811375656595
Validation loss: 2.4935456029668974

Epoch: 6| Step: 7
Training loss: 0.3235558316400404
Validation loss: 2.4733806550067614

Epoch: 6| Step: 8
Training loss: 0.30867976185100987
Validation loss: 2.477153823031598

Epoch: 6| Step: 9
Training loss: 0.3873508373933926
Validation loss: 2.5435485435955694

Epoch: 6| Step: 10
Training loss: 0.33472952898491476
Validation loss: 2.515292913690024

Epoch: 6| Step: 11
Training loss: 0.20918119378353434
Validation loss: 2.5021102530733406

Epoch: 6| Step: 12
Training loss: 0.24070620528952122
Validation loss: 2.5310962842509137

Epoch: 6| Step: 13
Training loss: 0.3004966603258561
Validation loss: 2.535847839909987

Epoch: 451| Step: 0
Training loss: 0.368164791035627
Validation loss: 2.5412572560902524

Epoch: 6| Step: 1
Training loss: 0.3367387951506842
Validation loss: 2.556940979522148

Epoch: 6| Step: 2
Training loss: 0.3884999455644626
Validation loss: 2.5491135211100975

Epoch: 6| Step: 3
Training loss: 0.4390067652287499
Validation loss: 2.601715521903735

Epoch: 6| Step: 4
Training loss: 0.2958142126087396
Validation loss: 2.5870778795899287

Epoch: 6| Step: 5
Training loss: 0.3637275825225793
Validation loss: 2.5697475210998864

Epoch: 6| Step: 6
Training loss: 0.12434512943011748
Validation loss: 2.5811354516210483

Epoch: 6| Step: 7
Training loss: 0.33434544949661626
Validation loss: 2.5555638798317584

Epoch: 6| Step: 8
Training loss: 0.29424453156445096
Validation loss: 2.6048300198894805

Epoch: 6| Step: 9
Training loss: 0.3151061344348007
Validation loss: 2.5857676094671476

Epoch: 6| Step: 10
Training loss: 0.3915694834823937
Validation loss: 2.6058814128203873

Epoch: 6| Step: 11
Training loss: 0.5262414502516277
Validation loss: 2.5585272361954114

Epoch: 6| Step: 12
Training loss: 0.24819647415371027
Validation loss: 2.543721192891121

Epoch: 6| Step: 13
Training loss: 0.29426112904484303
Validation loss: 2.522559827053244

Epoch: 452| Step: 0
Training loss: 0.31548653671962174
Validation loss: 2.5358084874826474

Epoch: 6| Step: 1
Training loss: 0.3305562636201329
Validation loss: 2.52227376817102

Epoch: 6| Step: 2
Training loss: 0.20119266958074286
Validation loss: 2.5281065373190397

Epoch: 6| Step: 3
Training loss: 0.39071570297037966
Validation loss: 2.483778183459559

Epoch: 6| Step: 4
Training loss: 0.3177673240781637
Validation loss: 2.50128953244328

Epoch: 6| Step: 5
Training loss: 0.4980042682449474
Validation loss: 2.4512501811513117

Epoch: 6| Step: 6
Training loss: 0.2018229125648416
Validation loss: 2.4356251161705864

Epoch: 6| Step: 7
Training loss: 0.3090321770306081
Validation loss: 2.487490946864082

Epoch: 6| Step: 8
Training loss: 0.24576655844147907
Validation loss: 2.5032691623084347

Epoch: 6| Step: 9
Training loss: 0.1441906188442338
Validation loss: 2.520100267225219

Epoch: 6| Step: 10
Training loss: 0.36119349265420353
Validation loss: 2.51646718229698

Epoch: 6| Step: 11
Training loss: 0.3620772560467082
Validation loss: 2.547718871844475

Epoch: 6| Step: 12
Training loss: 0.2982748557075303
Validation loss: 2.5749634600064937

Epoch: 6| Step: 13
Training loss: 0.19282607506828572
Validation loss: 2.5599573097303474

Epoch: 453| Step: 0
Training loss: 0.24625563216908988
Validation loss: 2.588232707351543

Epoch: 6| Step: 1
Training loss: 0.49541153143404826
Validation loss: 2.6025763662148536

Epoch: 6| Step: 2
Training loss: 0.2142828642422881
Validation loss: 2.582435839696554

Epoch: 6| Step: 3
Training loss: 0.23208055357720817
Validation loss: 2.549996726741536

Epoch: 6| Step: 4
Training loss: 0.3361226613951815
Validation loss: 2.5799489425342657

Epoch: 6| Step: 5
Training loss: 0.2872468528392554
Validation loss: 2.549236904303642

Epoch: 6| Step: 6
Training loss: 0.21832618358756006
Validation loss: 2.569025061283674

Epoch: 6| Step: 7
Training loss: 0.23448706967476865
Validation loss: 2.569238917201337

Epoch: 6| Step: 8
Training loss: 0.36572546760486946
Validation loss: 2.567504591844817

Epoch: 6| Step: 9
Training loss: 0.45807351167808985
Validation loss: 2.5704413274900673

Epoch: 6| Step: 10
Training loss: 0.3526265572050722
Validation loss: 2.557063593020322

Epoch: 6| Step: 11
Training loss: 0.4051976696105082
Validation loss: 2.5695447062056402

Epoch: 6| Step: 12
Training loss: 0.2938217587784207
Validation loss: 2.588595470332224

Epoch: 6| Step: 13
Training loss: 0.2524608552918735
Validation loss: 2.578873887463711

Epoch: 454| Step: 0
Training loss: 0.23270814560228345
Validation loss: 2.5271041900366806

Epoch: 6| Step: 1
Training loss: 0.26479941984531574
Validation loss: 2.561475974863341

Epoch: 6| Step: 2
Training loss: 0.36299287979378186
Validation loss: 2.5474451874898527

Epoch: 6| Step: 3
Training loss: 0.4474434811314494
Validation loss: 2.5678128846444315

Epoch: 6| Step: 4
Training loss: 0.29324500728301794
Validation loss: 2.545191754354372

Epoch: 6| Step: 5
Training loss: 0.42120364423662443
Validation loss: 2.5632299548559847

Epoch: 6| Step: 6
Training loss: 0.30389871955701
Validation loss: 2.5456657546111394

Epoch: 6| Step: 7
Training loss: 0.21434153900418787
Validation loss: 2.598312242053945

Epoch: 6| Step: 8
Training loss: 0.29220060737299997
Validation loss: 2.578727339071277

Epoch: 6| Step: 9
Training loss: 0.3316654097211365
Validation loss: 2.5668243009277245

Epoch: 6| Step: 10
Training loss: 0.3351057312422634
Validation loss: 2.566133661572056

Epoch: 6| Step: 11
Training loss: 0.31598549405661736
Validation loss: 2.5616001907381585

Epoch: 6| Step: 12
Training loss: 0.23147524064755315
Validation loss: 2.5302219113407878

Epoch: 6| Step: 13
Training loss: 0.3989396017008167
Validation loss: 2.5602355283657956

Epoch: 455| Step: 0
Training loss: 0.4062944901386878
Validation loss: 2.506695612359775

Epoch: 6| Step: 1
Training loss: 0.3291959315984305
Validation loss: 2.5041137310383963

Epoch: 6| Step: 2
Training loss: 0.23716876371863493
Validation loss: 2.4999910210889142

Epoch: 6| Step: 3
Training loss: 0.22240489022591137
Validation loss: 2.4994265349811946

Epoch: 6| Step: 4
Training loss: 0.3066347449643985
Validation loss: 2.5334760822266063

Epoch: 6| Step: 5
Training loss: 0.3472873251864251
Validation loss: 2.505290552341758

Epoch: 6| Step: 6
Training loss: 0.16933325509099423
Validation loss: 2.5462494799263915

Epoch: 6| Step: 7
Training loss: 0.2836561591465632
Validation loss: 2.525078493943251

Epoch: 6| Step: 8
Training loss: 0.4216597679136749
Validation loss: 2.531531703743475

Epoch: 6| Step: 9
Training loss: 0.18927926019759803
Validation loss: 2.541662163396753

Epoch: 6| Step: 10
Training loss: 0.22829607662797324
Validation loss: 2.541633572120056

Epoch: 6| Step: 11
Training loss: 0.34130982711198043
Validation loss: 2.539789443789715

Epoch: 6| Step: 12
Training loss: 0.3154432098985983
Validation loss: 2.57339613031902

Epoch: 6| Step: 13
Training loss: 0.4545533096924368
Validation loss: 2.5413364886525645

Epoch: 456| Step: 0
Training loss: 0.3501593137791744
Validation loss: 2.5646630698660595

Epoch: 6| Step: 1
Training loss: 0.27713339175353385
Validation loss: 2.5758637334468095

Epoch: 6| Step: 2
Training loss: 0.31223450349817405
Validation loss: 2.540628571905058

Epoch: 6| Step: 3
Training loss: 0.3042225101671566
Validation loss: 2.5218995301564906

Epoch: 6| Step: 4
Training loss: 0.24296296471580123
Validation loss: 2.5251349870875734

Epoch: 6| Step: 5
Training loss: 0.17968318768178018
Validation loss: 2.545950015940259

Epoch: 6| Step: 6
Training loss: 0.23351701413785067
Validation loss: 2.519118148491282

Epoch: 6| Step: 7
Training loss: 0.25952069487859836
Validation loss: 2.5392283769288704

Epoch: 6| Step: 8
Training loss: 0.3943765544709585
Validation loss: 2.5842382498090135

Epoch: 6| Step: 9
Training loss: 0.23489674668793545
Validation loss: 2.5491711892434687

Epoch: 6| Step: 10
Training loss: 0.3466725845683836
Validation loss: 2.5450517157614345

Epoch: 6| Step: 11
Training loss: 0.15862673688881537
Validation loss: 2.5626653452346497

Epoch: 6| Step: 12
Training loss: 0.3347033296932341
Validation loss: 2.576714156937261

Epoch: 6| Step: 13
Training loss: 0.2862190793549165
Validation loss: 2.529447955495092

Epoch: 457| Step: 0
Training loss: 0.21955717551390783
Validation loss: 2.5397949293192426

Epoch: 6| Step: 1
Training loss: 0.25048954537650836
Validation loss: 2.5683124219936104

Epoch: 6| Step: 2
Training loss: 0.31137491590130445
Validation loss: 2.609141624703278

Epoch: 6| Step: 3
Training loss: 0.29897428192016073
Validation loss: 2.5586495131711415

Epoch: 6| Step: 4
Training loss: 0.2844926349762605
Validation loss: 2.610500386525541

Epoch: 6| Step: 5
Training loss: 0.4036218287395651
Validation loss: 2.537399342491025

Epoch: 6| Step: 6
Training loss: 0.21351456857888218
Validation loss: 2.5334923505933995

Epoch: 6| Step: 7
Training loss: 0.13600271595362454
Validation loss: 2.5267952514974663

Epoch: 6| Step: 8
Training loss: 0.3050549321266573
Validation loss: 2.5192394914707847

Epoch: 6| Step: 9
Training loss: 0.21578172191979847
Validation loss: 2.5119650974848247

Epoch: 6| Step: 10
Training loss: 0.2138683545503171
Validation loss: 2.5162498693186635

Epoch: 6| Step: 11
Training loss: 0.19616268131858106
Validation loss: 2.4912996770948195

Epoch: 6| Step: 12
Training loss: 0.3068598067179928
Validation loss: 2.5031866580790934

Epoch: 6| Step: 13
Training loss: 0.2248865821870962
Validation loss: 2.5383445816507755

Epoch: 458| Step: 0
Training loss: 0.3257619371795974
Validation loss: 2.540383916626458

Epoch: 6| Step: 1
Training loss: 0.19576555158693051
Validation loss: 2.567291821705595

Epoch: 6| Step: 2
Training loss: 0.29922224993937185
Validation loss: 2.5529144387048417

Epoch: 6| Step: 3
Training loss: 0.28878213843960376
Validation loss: 2.5182561600088835

Epoch: 6| Step: 4
Training loss: 0.22977517718732782
Validation loss: 2.489450892349833

Epoch: 6| Step: 5
Training loss: 0.24335211257752384
Validation loss: 2.502348051997551

Epoch: 6| Step: 6
Training loss: 0.19445273948376804
Validation loss: 2.5023767105171384

Epoch: 6| Step: 7
Training loss: 0.2481273760789924
Validation loss: 2.4958949318228267

Epoch: 6| Step: 8
Training loss: 0.34299718178489375
Validation loss: 2.525515601629016

Epoch: 6| Step: 9
Training loss: 0.2512198133981147
Validation loss: 2.5345306228734863

Epoch: 6| Step: 10
Training loss: 0.30217252708036074
Validation loss: 2.534026810099106

Epoch: 6| Step: 11
Training loss: 0.24961791792504784
Validation loss: 2.5486175144580026

Epoch: 6| Step: 12
Training loss: 0.2984859027856398
Validation loss: 2.5500236820582636

Epoch: 6| Step: 13
Training loss: 0.26248764849168593
Validation loss: 2.5350778952094037

Epoch: 459| Step: 0
Training loss: 0.1995254661241542
Validation loss: 2.549788203482896

Epoch: 6| Step: 1
Training loss: 0.2215503197511205
Validation loss: 2.56751451786496

Epoch: 6| Step: 2
Training loss: 0.3178065361881241
Validation loss: 2.539826925734261

Epoch: 6| Step: 3
Training loss: 0.28229746208482476
Validation loss: 2.551651128786704

Epoch: 6| Step: 4
Training loss: 0.34080815771776046
Validation loss: 2.5827018903541874

Epoch: 6| Step: 5
Training loss: 0.28002130152788046
Validation loss: 2.579371676751907

Epoch: 6| Step: 6
Training loss: 0.20859278775111076
Validation loss: 2.5709446658483035

Epoch: 6| Step: 7
Training loss: 0.195473128070789
Validation loss: 2.6028481313310903

Epoch: 6| Step: 8
Training loss: 0.2267086692083215
Validation loss: 2.5748631361436165

Epoch: 6| Step: 9
Training loss: 0.24376056079727929
Validation loss: 2.5568346644806956

Epoch: 6| Step: 10
Training loss: 0.3016343342506219
Validation loss: 2.5548510258745365

Epoch: 6| Step: 11
Training loss: 0.24583466076223104
Validation loss: 2.544209855216175

Epoch: 6| Step: 12
Training loss: 0.37567284937805484
Validation loss: 2.5519850577409047

Epoch: 6| Step: 13
Training loss: 0.2334285142106172
Validation loss: 2.5621594658698745

Epoch: 460| Step: 0
Training loss: 0.19791380457732746
Validation loss: 2.4990839007789294

Epoch: 6| Step: 1
Training loss: 0.31735750537626045
Validation loss: 2.5193901076533307

Epoch: 6| Step: 2
Training loss: 0.24853828143420154
Validation loss: 2.5150528990157244

Epoch: 6| Step: 3
Training loss: 0.3125620065207305
Validation loss: 2.488374491171124

Epoch: 6| Step: 4
Training loss: 0.3063725192359835
Validation loss: 2.499124654706676

Epoch: 6| Step: 5
Training loss: 0.26062516290215904
Validation loss: 2.5294813395390148

Epoch: 6| Step: 6
Training loss: 0.23599826238738084
Validation loss: 2.526382349905376

Epoch: 6| Step: 7
Training loss: 0.2988820494821961
Validation loss: 2.5380486818603094

Epoch: 6| Step: 8
Training loss: 0.14463534987968613
Validation loss: 2.551811356122824

Epoch: 6| Step: 9
Training loss: 0.2684351290819049
Validation loss: 2.5341022807858145

Epoch: 6| Step: 10
Training loss: 0.3324657514329175
Validation loss: 2.5485150549905855

Epoch: 6| Step: 11
Training loss: 0.17111131760796697
Validation loss: 2.562002462351848

Epoch: 6| Step: 12
Training loss: 0.24236650926965836
Validation loss: 2.5456030562368777

Epoch: 6| Step: 13
Training loss: 0.2506656873643503
Validation loss: 2.5609655120231967

Epoch: 461| Step: 0
Training loss: 0.28849941258726036
Validation loss: 2.550016509953102

Epoch: 6| Step: 1
Training loss: 0.2412549723844071
Validation loss: 2.5693894520552334

Epoch: 6| Step: 2
Training loss: 0.31450172901663803
Validation loss: 2.5459514352338215

Epoch: 6| Step: 3
Training loss: 0.16104153446407576
Validation loss: 2.540743225004383

Epoch: 6| Step: 4
Training loss: 0.2231952684680089
Validation loss: 2.528347441118507

Epoch: 6| Step: 5
Training loss: 0.1267793493093139
Validation loss: 2.5041839188150092

Epoch: 6| Step: 6
Training loss: 0.23169426063879972
Validation loss: 2.551099438306813

Epoch: 6| Step: 7
Training loss: 0.23842988303280954
Validation loss: 2.489625902018347

Epoch: 6| Step: 8
Training loss: 0.18349297781222793
Validation loss: 2.529879897149227

Epoch: 6| Step: 9
Training loss: 0.3486654870031239
Validation loss: 2.5041718140490974

Epoch: 6| Step: 10
Training loss: 0.22437852523340224
Validation loss: 2.5522112802791628

Epoch: 6| Step: 11
Training loss: 0.1397357214404575
Validation loss: 2.538122533532734

Epoch: 6| Step: 12
Training loss: 0.3245834459582922
Validation loss: 2.5221729717397565

Epoch: 6| Step: 13
Training loss: 0.34353214643221414
Validation loss: 2.53377254940485

Epoch: 462| Step: 0
Training loss: 0.2857593794557406
Validation loss: 2.529213090209606

Epoch: 6| Step: 1
Training loss: 0.24312255688986745
Validation loss: 2.58489930730157

Epoch: 6| Step: 2
Training loss: 0.31464355341828243
Validation loss: 2.5462407718379083

Epoch: 6| Step: 3
Training loss: 0.34581737462339196
Validation loss: 2.5645215134136223

Epoch: 6| Step: 4
Training loss: 0.23753826592262722
Validation loss: 2.547807269322415

Epoch: 6| Step: 5
Training loss: 0.2513506435590556
Validation loss: 2.552106194627104

Epoch: 6| Step: 6
Training loss: 0.21050199833689318
Validation loss: 2.5192897616353633

Epoch: 6| Step: 7
Training loss: 0.1771316999879071
Validation loss: 2.5175560421283323

Epoch: 6| Step: 8
Training loss: 0.27116688338257194
Validation loss: 2.5276716018732674

Epoch: 6| Step: 9
Training loss: 0.28085272599415695
Validation loss: 2.4993270952859934

Epoch: 6| Step: 10
Training loss: 0.29229227166352273
Validation loss: 2.547760375269972

Epoch: 6| Step: 11
Training loss: 0.26774609994496634
Validation loss: 2.508816967400487

Epoch: 6| Step: 12
Training loss: 0.22930585723388325
Validation loss: 2.5094051584386823

Epoch: 6| Step: 13
Training loss: 0.15038480375839292
Validation loss: 2.5346006971052217

Epoch: 463| Step: 0
Training loss: 0.21666557184884203
Validation loss: 2.5336785677344107

Epoch: 6| Step: 1
Training loss: 0.21384279120661084
Validation loss: 2.492162221314314

Epoch: 6| Step: 2
Training loss: 0.20623247332230488
Validation loss: 2.5161653790624

Epoch: 6| Step: 3
Training loss: 0.26587903273213825
Validation loss: 2.5406574449159063

Epoch: 6| Step: 4
Training loss: 0.2972740703490913
Validation loss: 2.5215885804261826

Epoch: 6| Step: 5
Training loss: 0.35236997062744907
Validation loss: 2.5144804945419605

Epoch: 6| Step: 6
Training loss: 0.19759707413169403
Validation loss: 2.5441330751216817

Epoch: 6| Step: 7
Training loss: 0.21533891662523186
Validation loss: 2.5345235136386184

Epoch: 6| Step: 8
Training loss: 0.16955537294784392
Validation loss: 2.5340671527992886

Epoch: 6| Step: 9
Training loss: 0.361151574794014
Validation loss: 2.544525605963118

Epoch: 6| Step: 10
Training loss: 0.30149444642337336
Validation loss: 2.556386433328774

Epoch: 6| Step: 11
Training loss: 0.17438752462671148
Validation loss: 2.561126603058235

Epoch: 6| Step: 12
Training loss: 0.23257919404819194
Validation loss: 2.520720730975808

Epoch: 6| Step: 13
Training loss: 0.1898068733662573
Validation loss: 2.5545252211289204

Epoch: 464| Step: 0
Training loss: 0.21967157311584623
Validation loss: 2.487413663855604

Epoch: 6| Step: 1
Training loss: 0.3267210032724245
Validation loss: 2.495935264315271

Epoch: 6| Step: 2
Training loss: 0.17862536773750567
Validation loss: 2.527557825007798

Epoch: 6| Step: 3
Training loss: 0.34660219212868987
Validation loss: 2.5050427021332147

Epoch: 6| Step: 4
Training loss: 0.24168794393732945
Validation loss: 2.545013572904399

Epoch: 6| Step: 5
Training loss: 0.2718797316084664
Validation loss: 2.4846957698696794

Epoch: 6| Step: 6
Training loss: 0.18678065235526742
Validation loss: 2.5199275622200665

Epoch: 6| Step: 7
Training loss: 0.22874642804489004
Validation loss: 2.4735903047261747

Epoch: 6| Step: 8
Training loss: 0.30243813571756695
Validation loss: 2.493600162142687

Epoch: 6| Step: 9
Training loss: 0.1401650403475939
Validation loss: 2.5241529823877267

Epoch: 6| Step: 10
Training loss: 0.22148328642939266
Validation loss: 2.563369614424533

Epoch: 6| Step: 11
Training loss: 0.1833947300155347
Validation loss: 2.5505113640286403

Epoch: 6| Step: 12
Training loss: 0.23481324866436712
Validation loss: 2.562391655505075

Epoch: 6| Step: 13
Training loss: 0.19536087390758186
Validation loss: 2.5859722683717443

Epoch: 465| Step: 0
Training loss: 0.20616763305347624
Validation loss: 2.5421944827840357

Epoch: 6| Step: 1
Training loss: 0.3154694027301144
Validation loss: 2.5322860512670546

Epoch: 6| Step: 2
Training loss: 0.30469730557044433
Validation loss: 2.5600175916319845

Epoch: 6| Step: 3
Training loss: 0.19036376007535238
Validation loss: 2.5245015293486404

Epoch: 6| Step: 4
Training loss: 0.2039840761647835
Validation loss: 2.580766842585724

Epoch: 6| Step: 5
Training loss: 0.1932861497731338
Validation loss: 2.541169887780855

Epoch: 6| Step: 6
Training loss: 0.29175039633598965
Validation loss: 2.575708350831594

Epoch: 6| Step: 7
Training loss: 0.1848245212327114
Validation loss: 2.5480004209749674

Epoch: 6| Step: 8
Training loss: 0.3574524746496353
Validation loss: 2.556556341478709

Epoch: 6| Step: 9
Training loss: 0.22239556025920842
Validation loss: 2.5529214364737496

Epoch: 6| Step: 10
Training loss: 0.180970092565569
Validation loss: 2.568549639730724

Epoch: 6| Step: 11
Training loss: 0.2672780156880388
Validation loss: 2.552721742226429

Epoch: 6| Step: 12
Training loss: 0.13926240611157506
Validation loss: 2.526219114349094

Epoch: 6| Step: 13
Training loss: 0.19929720698754785
Validation loss: 2.5570938720225556

Epoch: 466| Step: 0
Training loss: 0.290138035080786
Validation loss: 2.5447495509616065

Epoch: 6| Step: 1
Training loss: 0.27465188252275935
Validation loss: 2.5183040941452273

Epoch: 6| Step: 2
Training loss: 0.28300404621827363
Validation loss: 2.491312083139275

Epoch: 6| Step: 3
Training loss: 0.3051062787066329
Validation loss: 2.491966332125431

Epoch: 6| Step: 4
Training loss: 0.2854106760904591
Validation loss: 2.4773047957934042

Epoch: 6| Step: 5
Training loss: 0.24871007613303567
Validation loss: 2.484020863948103

Epoch: 6| Step: 6
Training loss: 0.1767612899522507
Validation loss: 2.4707756294164267

Epoch: 6| Step: 7
Training loss: 0.2640400047426522
Validation loss: 2.484512607000853

Epoch: 6| Step: 8
Training loss: 0.22079946727606356
Validation loss: 2.522262554197991

Epoch: 6| Step: 9
Training loss: 0.2593759180535305
Validation loss: 2.536599586483519

Epoch: 6| Step: 10
Training loss: 0.30480520713534043
Validation loss: 2.52670784984579

Epoch: 6| Step: 11
Training loss: 0.19161981229360425
Validation loss: 2.579288733865257

Epoch: 6| Step: 12
Training loss: 0.2855444969360019
Validation loss: 2.615675683599502

Epoch: 6| Step: 13
Training loss: 0.13554634401948468
Validation loss: 2.6044357364250024

Epoch: 467| Step: 0
Training loss: 0.298208554313151
Validation loss: 2.639534602982174

Epoch: 6| Step: 1
Training loss: 0.2501883691186077
Validation loss: 2.643709429206553

Epoch: 6| Step: 2
Training loss: 0.26820589476926704
Validation loss: 2.6033676719987464

Epoch: 6| Step: 3
Training loss: 0.3107753608878275
Validation loss: 2.5977791996961423

Epoch: 6| Step: 4
Training loss: 0.21198664358357322
Validation loss: 2.5972325991972958

Epoch: 6| Step: 5
Training loss: 0.2243547904123137
Validation loss: 2.5621999769554877

Epoch: 6| Step: 6
Training loss: 0.18331738225585256
Validation loss: 2.559224879279136

Epoch: 6| Step: 7
Training loss: 0.19919421474987503
Validation loss: 2.543696256010717

Epoch: 6| Step: 8
Training loss: 0.25938607215229154
Validation loss: 2.5209801652398163

Epoch: 6| Step: 9
Training loss: 0.2740563066363431
Validation loss: 2.5105699558677395

Epoch: 6| Step: 10
Training loss: 0.18931535253582782
Validation loss: 2.5178714536351254

Epoch: 6| Step: 11
Training loss: 0.238502024947873
Validation loss: 2.510696808748129

Epoch: 6| Step: 12
Training loss: 0.22941034359144766
Validation loss: 2.514624781311633

Epoch: 6| Step: 13
Training loss: 0.1765493987294937
Validation loss: 2.532697006007112

Epoch: 468| Step: 0
Training loss: 0.26632572758234246
Validation loss: 2.494842069109305

Epoch: 6| Step: 1
Training loss: 0.21633438232178082
Validation loss: 2.554956862557862

Epoch: 6| Step: 2
Training loss: 0.2647535389887909
Validation loss: 2.547171890405589

Epoch: 6| Step: 3
Training loss: 0.23932884874487848
Validation loss: 2.5376598730299156

Epoch: 6| Step: 4
Training loss: 0.18553591244085255
Validation loss: 2.526499761601951

Epoch: 6| Step: 5
Training loss: 0.1766237572516924
Validation loss: 2.525420699033962

Epoch: 6| Step: 6
Training loss: 0.29983038279608537
Validation loss: 2.4993999514795067

Epoch: 6| Step: 7
Training loss: 0.21440380307485818
Validation loss: 2.5098099230424125

Epoch: 6| Step: 8
Training loss: 0.18524090485504616
Validation loss: 2.5081094433062106

Epoch: 6| Step: 9
Training loss: 0.16250315488907208
Validation loss: 2.5369646693491337

Epoch: 6| Step: 10
Training loss: 0.12363362063464681
Validation loss: 2.4838677665850697

Epoch: 6| Step: 11
Training loss: 0.2825571651558422
Validation loss: 2.511894063155244

Epoch: 6| Step: 12
Training loss: 0.19319943835994283
Validation loss: 2.5093663409353955

Epoch: 6| Step: 13
Training loss: 0.21587948397931242
Validation loss: 2.5014216390453474

Epoch: 469| Step: 0
Training loss: 0.1720009580650649
Validation loss: 2.5209825550057974

Epoch: 6| Step: 1
Training loss: 0.3366995971967884
Validation loss: 2.5558390891072187

Epoch: 6| Step: 2
Training loss: 0.127086671866147
Validation loss: 2.5232968263393354

Epoch: 6| Step: 3
Training loss: 0.25308941249519523
Validation loss: 2.5265392341587414

Epoch: 6| Step: 4
Training loss: 0.19207005323695492
Validation loss: 2.5178218719643146

Epoch: 6| Step: 5
Training loss: 0.22238158970290092
Validation loss: 2.5202541338482334

Epoch: 6| Step: 6
Training loss: 0.1500790948752063
Validation loss: 2.5404663375035206

Epoch: 6| Step: 7
Training loss: 0.22799127689675533
Validation loss: 2.556812699072677

Epoch: 6| Step: 8
Training loss: 0.3310688432125765
Validation loss: 2.556474268366372

Epoch: 6| Step: 9
Training loss: 0.17777927586074124
Validation loss: 2.5481858455039843

Epoch: 6| Step: 10
Training loss: 0.2546990707905088
Validation loss: 2.574908305016076

Epoch: 6| Step: 11
Training loss: 0.09964700530341519
Validation loss: 2.5687355100776283

Epoch: 6| Step: 12
Training loss: 0.13414866437243542
Validation loss: 2.5525570183530295

Epoch: 6| Step: 13
Training loss: 0.22297957853181624
Validation loss: 2.539232729371293

Epoch: 470| Step: 0
Training loss: 0.31335313690451216
Validation loss: 2.5182361537574574

Epoch: 6| Step: 1
Training loss: 0.2939364916723121
Validation loss: 2.565393369087765

Epoch: 6| Step: 2
Training loss: 0.271117408335739
Validation loss: 2.54695594860776

Epoch: 6| Step: 3
Training loss: 0.14827900505979333
Validation loss: 2.5558196899994017

Epoch: 6| Step: 4
Training loss: 0.29702772428375596
Validation loss: 2.5847613505786535

Epoch: 6| Step: 5
Training loss: 0.17336113490053304
Validation loss: 2.572764085544273

Epoch: 6| Step: 6
Training loss: 0.21645386512875991
Validation loss: 2.543665326199186

Epoch: 6| Step: 7
Training loss: 0.21211113094776216
Validation loss: 2.563332939285002

Epoch: 6| Step: 8
Training loss: 0.1470206426306896
Validation loss: 2.5837975859574014

Epoch: 6| Step: 9
Training loss: 0.267596529585241
Validation loss: 2.575990371774259

Epoch: 6| Step: 10
Training loss: 0.3187274326488654
Validation loss: 2.559374377924855

Epoch: 6| Step: 11
Training loss: 0.16081257990328438
Validation loss: 2.5467604125629633

Epoch: 6| Step: 12
Training loss: 0.28084015123899775
Validation loss: 2.5500828476375714

Epoch: 6| Step: 13
Training loss: 0.12911759015893762
Validation loss: 2.5909440595491273

Epoch: 471| Step: 0
Training loss: 0.16236170697880156
Validation loss: 2.5819079564974303

Epoch: 6| Step: 1
Training loss: 0.1906280169482769
Validation loss: 2.5183270540758604

Epoch: 6| Step: 2
Training loss: 0.3070452262279349
Validation loss: 2.586399238519289

Epoch: 6| Step: 3
Training loss: 0.32754524420749104
Validation loss: 2.572999502934898

Epoch: 6| Step: 4
Training loss: 0.26628772022904523
Validation loss: 2.5552592369529927

Epoch: 6| Step: 5
Training loss: 0.127282873475351
Validation loss: 2.559858393703866

Epoch: 6| Step: 6
Training loss: 0.26439763251841114
Validation loss: 2.586404799149021

Epoch: 6| Step: 7
Training loss: 0.22217660405071546
Validation loss: 2.538383785181616

Epoch: 6| Step: 8
Training loss: 0.13727699478036023
Validation loss: 2.6114872775874494

Epoch: 6| Step: 9
Training loss: 0.2098393287675806
Validation loss: 2.575215679621708

Epoch: 6| Step: 10
Training loss: 0.2685429241031617
Validation loss: 2.532470957593939

Epoch: 6| Step: 11
Training loss: 0.31806651494015836
Validation loss: 2.5517428370429807

Epoch: 6| Step: 12
Training loss: 0.20758741278323523
Validation loss: 2.5819740467171037

Epoch: 6| Step: 13
Training loss: 0.1868855720738235
Validation loss: 2.568186808824238

Epoch: 472| Step: 0
Training loss: 0.1885881834622955
Validation loss: 2.5488540949205847

Epoch: 6| Step: 1
Training loss: 0.1887250655485548
Validation loss: 2.585800533585206

Epoch: 6| Step: 2
Training loss: 0.28709476459722927
Validation loss: 2.566423494339086

Epoch: 6| Step: 3
Training loss: 0.2745079205825975
Validation loss: 2.626986216546993

Epoch: 6| Step: 4
Training loss: 0.1455746439613497
Validation loss: 2.594885040940223

Epoch: 6| Step: 5
Training loss: 0.20926734448289527
Validation loss: 2.5781334124564914

Epoch: 6| Step: 6
Training loss: 0.15508716734652717
Validation loss: 2.5688664215670105

Epoch: 6| Step: 7
Training loss: 0.18425201541142563
Validation loss: 2.611171553675897

Epoch: 6| Step: 8
Training loss: 0.1916144173263601
Validation loss: 2.5539043915024355

Epoch: 6| Step: 9
Training loss: 0.17304528689893575
Validation loss: 2.556343103353995

Epoch: 6| Step: 10
Training loss: 0.21564846187602885
Validation loss: 2.532517527383444

Epoch: 6| Step: 11
Training loss: 0.17587891620506754
Validation loss: 2.5678241582721486

Epoch: 6| Step: 12
Training loss: 0.14768821683121275
Validation loss: 2.5595123307860526

Epoch: 6| Step: 13
Training loss: 0.4323380303702475
Validation loss: 2.5381259692288456

Epoch: 473| Step: 0
Training loss: 0.37199214805114916
Validation loss: 2.5496634171727988

Epoch: 6| Step: 1
Training loss: 0.20156306591989484
Validation loss: 2.53763379056915

Epoch: 6| Step: 2
Training loss: 0.1400922113113265
Validation loss: 2.5076239899044754

Epoch: 6| Step: 3
Training loss: 0.1333761037335761
Validation loss: 2.55006596228394

Epoch: 6| Step: 4
Training loss: 0.1911787997738785
Validation loss: 2.5540493940953275

Epoch: 6| Step: 5
Training loss: 0.16659565744075494
Validation loss: 2.5782618591039226

Epoch: 6| Step: 6
Training loss: 0.19022277937686005
Validation loss: 2.5413472926263654

Epoch: 6| Step: 7
Training loss: 0.1569495515240924
Validation loss: 2.5848035834178766

Epoch: 6| Step: 8
Training loss: 0.31691578469031245
Validation loss: 2.5622783357923318

Epoch: 6| Step: 9
Training loss: 0.21639379196940037
Validation loss: 2.552236555839373

Epoch: 6| Step: 10
Training loss: 0.29726682705329144
Validation loss: 2.559304937425669

Epoch: 6| Step: 11
Training loss: 0.24930222557253062
Validation loss: 2.5535958802692216

Epoch: 6| Step: 12
Training loss: 0.12321283864569492
Validation loss: 2.5370558944691584

Epoch: 6| Step: 13
Training loss: 0.23429575216107598
Validation loss: 2.538742526380611

Epoch: 474| Step: 0
Training loss: 0.1049030284472166
Validation loss: 2.5592930763384403

Epoch: 6| Step: 1
Training loss: 0.1273203161243954
Validation loss: 2.5467783460830193

Epoch: 6| Step: 2
Training loss: 0.18699139915413285
Validation loss: 2.506686949930402

Epoch: 6| Step: 3
Training loss: 0.2630913312623867
Validation loss: 2.5442629289321137

Epoch: 6| Step: 4
Training loss: 0.2888498297190482
Validation loss: 2.5159043967282626

Epoch: 6| Step: 5
Training loss: 0.23349343445530732
Validation loss: 2.5350927168009636

Epoch: 6| Step: 6
Training loss: 0.18596827188275555
Validation loss: 2.5268682668555114

Epoch: 6| Step: 7
Training loss: 0.24471863035847713
Validation loss: 2.569492875048966

Epoch: 6| Step: 8
Training loss: 0.12277554311472955
Validation loss: 2.5472014662291267

Epoch: 6| Step: 9
Training loss: 0.1733960235248925
Validation loss: 2.560681975477286

Epoch: 6| Step: 10
Training loss: 0.22565833081980624
Validation loss: 2.538045925341436

Epoch: 6| Step: 11
Training loss: 0.3073279580275774
Validation loss: 2.5357323179166906

Epoch: 6| Step: 12
Training loss: 0.17146608628786253
Validation loss: 2.551169685992405

Epoch: 6| Step: 13
Training loss: 0.17589728975779303
Validation loss: 2.579098920432546

Epoch: 475| Step: 0
Training loss: 0.15835869757456106
Validation loss: 2.531121553914235

Epoch: 6| Step: 1
Training loss: 0.20744674303656782
Validation loss: 2.572091439105156

Epoch: 6| Step: 2
Training loss: 0.24887464977663193
Validation loss: 2.5588473587201213

Epoch: 6| Step: 3
Training loss: 0.24125260213328148
Validation loss: 2.552186155141856

Epoch: 6| Step: 4
Training loss: 0.18733354968633184
Validation loss: 2.5095968445154284

Epoch: 6| Step: 5
Training loss: 0.36948021905342465
Validation loss: 2.532669945235638

Epoch: 6| Step: 6
Training loss: 0.17043384070432194
Validation loss: 2.5442820090816123

Epoch: 6| Step: 7
Training loss: 0.28773715355282714
Validation loss: 2.5481474276156475

Epoch: 6| Step: 8
Training loss: 0.15969013211942074
Validation loss: 2.5584348392367646

Epoch: 6| Step: 9
Training loss: 0.20331929158037806
Validation loss: 2.546591114735917

Epoch: 6| Step: 10
Training loss: 0.1905203970029356
Validation loss: 2.549455418707038

Epoch: 6| Step: 11
Training loss: 0.2607884169611388
Validation loss: 2.5254091351075347

Epoch: 6| Step: 12
Training loss: 0.17835500323317702
Validation loss: 2.5945311569808336

Epoch: 6| Step: 13
Training loss: 0.1375191420538907
Validation loss: 2.5574410696496326

Epoch: 476| Step: 0
Training loss: 0.1849169629519947
Validation loss: 2.583440072523649

Epoch: 6| Step: 1
Training loss: 0.30828545054664097
Validation loss: 2.546565847571843

Epoch: 6| Step: 2
Training loss: 0.2891461277180174
Validation loss: 2.5605876398702887

Epoch: 6| Step: 3
Training loss: 0.18532919914629659
Validation loss: 2.546663760840359

Epoch: 6| Step: 4
Training loss: 0.2661378901590884
Validation loss: 2.5677837538883663

Epoch: 6| Step: 5
Training loss: 0.18264605044170762
Validation loss: 2.556870089281952

Epoch: 6| Step: 6
Training loss: 0.20998157133689882
Validation loss: 2.5772355927979365

Epoch: 6| Step: 7
Training loss: 0.21863598065911863
Validation loss: 2.545200433800096

Epoch: 6| Step: 8
Training loss: 0.16366966651209475
Validation loss: 2.563657264696403

Epoch: 6| Step: 9
Training loss: 0.1462071656808931
Validation loss: 2.5483882245486655

Epoch: 6| Step: 10
Training loss: 0.1229905612692416
Validation loss: 2.532592709000867

Epoch: 6| Step: 11
Training loss: 0.1978153274659483
Validation loss: 2.539992123941153

Epoch: 6| Step: 12
Training loss: 0.22091779986585774
Validation loss: 2.529960019027044

Epoch: 6| Step: 13
Training loss: 0.18918985577765285
Validation loss: 2.506312105505221

Epoch: 477| Step: 0
Training loss: 0.2839252735749284
Validation loss: 2.5306769202999617

Epoch: 6| Step: 1
Training loss: 0.13840572579164642
Validation loss: 2.5363391380673437

Epoch: 6| Step: 2
Training loss: 0.2499249762974383
Validation loss: 2.5105236960625215

Epoch: 6| Step: 3
Training loss: 0.13833679764595952
Validation loss: 2.556843034688317

Epoch: 6| Step: 4
Training loss: 0.26833028954996935
Validation loss: 2.577865832177352

Epoch: 6| Step: 5
Training loss: 0.15592781466830036
Validation loss: 2.554600587999465

Epoch: 6| Step: 6
Training loss: 0.22015400318870057
Validation loss: 2.563576638951558

Epoch: 6| Step: 7
Training loss: 0.13349496580036666
Validation loss: 2.562810802444675

Epoch: 6| Step: 8
Training loss: 0.2636928126181301
Validation loss: 2.555545042415227

Epoch: 6| Step: 9
Training loss: 0.3116590987759698
Validation loss: 2.5976395870380253

Epoch: 6| Step: 10
Training loss: 0.0860595594906631
Validation loss: 2.5740504130664283

Epoch: 6| Step: 11
Training loss: 0.211838053770642
Validation loss: 2.5756488382816967

Epoch: 6| Step: 12
Training loss: 0.1950468259152943
Validation loss: 2.5469106166776827

Epoch: 6| Step: 13
Training loss: 0.15086122057322665
Validation loss: 2.5475085650857183

Epoch: 478| Step: 0
Training loss: 0.19128926263712656
Validation loss: 2.5601546431555455

Epoch: 6| Step: 1
Training loss: 0.2163774712221451
Validation loss: 2.584563260899881

Epoch: 6| Step: 2
Training loss: 0.1688374522332166
Validation loss: 2.5634346834776798

Epoch: 6| Step: 3
Training loss: 0.17082577386757833
Validation loss: 2.5829758021244573

Epoch: 6| Step: 4
Training loss: 0.16490608139708984
Validation loss: 2.562857283068774

Epoch: 6| Step: 5
Training loss: 0.3135732460066285
Validation loss: 2.574153042281648

Epoch: 6| Step: 6
Training loss: 0.11490997218451746
Validation loss: 2.5704730032665326

Epoch: 6| Step: 7
Training loss: 0.10131123988864005
Validation loss: 2.584393202158883

Epoch: 6| Step: 8
Training loss: 0.2740756490156372
Validation loss: 2.5523450130052217

Epoch: 6| Step: 9
Training loss: 0.1683761291841282
Validation loss: 2.537249591271538

Epoch: 6| Step: 10
Training loss: 0.29712329068572885
Validation loss: 2.5403538855156933

Epoch: 6| Step: 11
Training loss: 0.17141067033212784
Validation loss: 2.5601671406189093

Epoch: 6| Step: 12
Training loss: 0.1661547470591588
Validation loss: 2.5359342168799457

Epoch: 6| Step: 13
Training loss: 0.25935431593265224
Validation loss: 2.5222689849851414

Epoch: 479| Step: 0
Training loss: 0.30694848903496014
Validation loss: 2.497830806528737

Epoch: 6| Step: 1
Training loss: 0.24592756533642493
Validation loss: 2.5497313144562783

Epoch: 6| Step: 2
Training loss: 0.11111780846382091
Validation loss: 2.5545467239954553

Epoch: 6| Step: 3
Training loss: 0.2052804040135004
Validation loss: 2.513154542300813

Epoch: 6| Step: 4
Training loss: 0.2626571627572089
Validation loss: 2.5243569012313083

Epoch: 6| Step: 5
Training loss: 0.19217293808206706
Validation loss: 2.5068828618111825

Epoch: 6| Step: 6
Training loss: 0.2027698860599668
Validation loss: 2.528285622324593

Epoch: 6| Step: 7
Training loss: 0.20324862826096773
Validation loss: 2.569449945688017

Epoch: 6| Step: 8
Training loss: 0.16496186454199915
Validation loss: 2.57064525640716

Epoch: 6| Step: 9
Training loss: 0.21284439739923589
Validation loss: 2.576354621211395

Epoch: 6| Step: 10
Training loss: 0.2859479157056852
Validation loss: 2.58047965404108

Epoch: 6| Step: 11
Training loss: 0.24432248018256006
Validation loss: 2.56166625546895

Epoch: 6| Step: 12
Training loss: 0.2688907116307878
Validation loss: 2.5483658563713414

Epoch: 6| Step: 13
Training loss: 0.11754066180950541
Validation loss: 2.5623561579652705

Epoch: 480| Step: 0
Training loss: 0.22857821658817976
Validation loss: 2.5220613757112917

Epoch: 6| Step: 1
Training loss: 0.15189998746894498
Validation loss: 2.5655201068058058

Epoch: 6| Step: 2
Training loss: 0.33135308964752247
Validation loss: 2.5545291596298343

Epoch: 6| Step: 3
Training loss: 0.2861422254036124
Validation loss: 2.5329666110142743

Epoch: 6| Step: 4
Training loss: 0.09253664415322625
Validation loss: 2.529843562397195

Epoch: 6| Step: 5
Training loss: 0.26385152842310483
Validation loss: 2.550619813139397

Epoch: 6| Step: 6
Training loss: 0.16456885762072967
Validation loss: 2.5468664017549845

Epoch: 6| Step: 7
Training loss: 0.10386901937779543
Validation loss: 2.489049785247239

Epoch: 6| Step: 8
Training loss: 0.3772946130260824
Validation loss: 2.5032126580605985

Epoch: 6| Step: 9
Training loss: 0.2407670666814065
Validation loss: 2.5473586463171753

Epoch: 6| Step: 10
Training loss: 0.22241508239032018
Validation loss: 2.52099538546808

Epoch: 6| Step: 11
Training loss: 0.14906743926136207
Validation loss: 2.535296051510423

Epoch: 6| Step: 12
Training loss: 0.2275372288183893
Validation loss: 2.5349453373926116

Epoch: 6| Step: 13
Training loss: 0.18578589253123198
Validation loss: 2.5207655926474715

Epoch: 481| Step: 0
Training loss: 0.35939614606923337
Validation loss: 2.54517887765668

Epoch: 6| Step: 1
Training loss: 0.21014880269975872
Validation loss: 2.5574741825115033

Epoch: 6| Step: 2
Training loss: 0.17420635435885246
Validation loss: 2.5655618323761495

Epoch: 6| Step: 3
Training loss: 0.4221465861376176
Validation loss: 2.519356778650922

Epoch: 6| Step: 4
Training loss: 0.43139986944678554
Validation loss: 2.5243988181998094

Epoch: 6| Step: 5
Training loss: 0.2442416249213728
Validation loss: 2.5702029407863654

Epoch: 6| Step: 6
Training loss: 0.31758044618553605
Validation loss: 2.5633861351178235

Epoch: 6| Step: 7
Training loss: 0.19572156982912142
Validation loss: 2.5688927178292182

Epoch: 6| Step: 8
Training loss: 0.2532240726712323
Validation loss: 2.5465900486456503

Epoch: 6| Step: 9
Training loss: 0.2727632383722998
Validation loss: 2.5693363765246393

Epoch: 6| Step: 10
Training loss: 0.2800343520515541
Validation loss: 2.5520378813589746

Epoch: 6| Step: 11
Training loss: 0.22624453891043436
Validation loss: 2.5048354669172013

Epoch: 6| Step: 12
Training loss: 0.2586350324472375
Validation loss: 2.474871376517945

Epoch: 6| Step: 13
Training loss: 0.3065115420056959
Validation loss: 2.496405357301411

Epoch: 482| Step: 0
Training loss: 0.20664660692119843
Validation loss: 2.5044737779272963

Epoch: 6| Step: 1
Training loss: 0.29771651661630666
Validation loss: 2.5205227589275627

Epoch: 6| Step: 2
Training loss: 0.23272440959112997
Validation loss: 2.545367559483348

Epoch: 6| Step: 3
Training loss: 0.27987037146550153
Validation loss: 2.5194546509100895

Epoch: 6| Step: 4
Training loss: 0.2791449794007939
Validation loss: 2.5375966252765543

Epoch: 6| Step: 5
Training loss: 0.2134509630551017
Validation loss: 2.57864797489106

Epoch: 6| Step: 6
Training loss: 0.2878322583560238
Validation loss: 2.5544638863099243

Epoch: 6| Step: 7
Training loss: 0.26740671501016705
Validation loss: 2.5404941982018308

Epoch: 6| Step: 8
Training loss: 0.3303205965145145
Validation loss: 2.5734286902111676

Epoch: 6| Step: 9
Training loss: 0.189906992405678
Validation loss: 2.5504054856029925

Epoch: 6| Step: 10
Training loss: 0.2639656972924255
Validation loss: 2.5915921023221173

Epoch: 6| Step: 11
Training loss: 0.24156198169657583
Validation loss: 2.601634555134012

Epoch: 6| Step: 12
Training loss: 0.22553715033818839
Validation loss: 2.532574057041501

Epoch: 6| Step: 13
Training loss: 0.23932940910479517
Validation loss: 2.5587103929744583

Epoch: 483| Step: 0
Training loss: 0.29121972933622053
Validation loss: 2.5712273179665734

Epoch: 6| Step: 1
Training loss: 0.2515590898507747
Validation loss: 2.4875771159594464

Epoch: 6| Step: 2
Training loss: 0.25306628747236426
Validation loss: 2.5281808147877958

Epoch: 6| Step: 3
Training loss: 0.25296680075051725
Validation loss: 2.487160305253023

Epoch: 6| Step: 4
Training loss: 0.32566465125408767
Validation loss: 2.508927492608739

Epoch: 6| Step: 5
Training loss: 0.27621009324810236
Validation loss: 2.5109691404263024

Epoch: 6| Step: 6
Training loss: 0.23946514877325548
Validation loss: 2.509260641005473

Epoch: 6| Step: 7
Training loss: 0.1681557545841606
Validation loss: 2.5315083653296844

Epoch: 6| Step: 8
Training loss: 0.21727138861425724
Validation loss: 2.565893160167922

Epoch: 6| Step: 9
Training loss: 0.19043495953426862
Validation loss: 2.5411455150337097

Epoch: 6| Step: 10
Training loss: 0.3452541863065433
Validation loss: 2.5650934630881146

Epoch: 6| Step: 11
Training loss: 0.16173281078671228
Validation loss: 2.5759445162623056

Epoch: 6| Step: 12
Training loss: 0.20508411035431856
Validation loss: 2.56860621577144

Epoch: 6| Step: 13
Training loss: 0.20657381769763203
Validation loss: 2.5819773203045466

Epoch: 484| Step: 0
Training loss: 0.1720061343791636
Validation loss: 2.5657071038934296

Epoch: 6| Step: 1
Training loss: 0.2706267030191027
Validation loss: 2.5417080251663005

Epoch: 6| Step: 2
Training loss: 0.30573360882878176
Validation loss: 2.5281034393772304

Epoch: 6| Step: 3
Training loss: 0.17139716265991226
Validation loss: 2.5429068672624062

Epoch: 6| Step: 4
Training loss: 0.12436346315666022
Validation loss: 2.5198683539663254

Epoch: 6| Step: 5
Training loss: 0.23081795858285875
Validation loss: 2.533116759143443

Epoch: 6| Step: 6
Training loss: 0.22837769184655832
Validation loss: 2.539341881765557

Epoch: 6| Step: 7
Training loss: 0.24169589724329563
Validation loss: 2.505386568942281

Epoch: 6| Step: 8
Training loss: 0.17340251165881462
Validation loss: 2.537933808545367

Epoch: 6| Step: 9
Training loss: 0.1361530726720691
Validation loss: 2.5204420420800613

Epoch: 6| Step: 10
Training loss: 0.14396515376950747
Validation loss: 2.5303450870572948

Epoch: 6| Step: 11
Training loss: 0.23708634869602724
Validation loss: 2.5343709108767207

Epoch: 6| Step: 12
Training loss: 0.2532954719264105
Validation loss: 2.5018910075485015

Epoch: 6| Step: 13
Training loss: 0.32299505969084125
Validation loss: 2.513312552648709

Epoch: 485| Step: 0
Training loss: 0.3089387148602288
Validation loss: 2.532667969364885

Epoch: 6| Step: 1
Training loss: 0.19855804836769173
Validation loss: 2.541557133811034

Epoch: 6| Step: 2
Training loss: 0.21683535363268702
Validation loss: 2.4796589053952087

Epoch: 6| Step: 3
Training loss: 0.28175948937521444
Validation loss: 2.5003691503280505

Epoch: 6| Step: 4
Training loss: 0.24795088074447524
Validation loss: 2.5270569655689403

Epoch: 6| Step: 5
Training loss: 0.15707642631329435
Validation loss: 2.500931324326453

Epoch: 6| Step: 6
Training loss: 0.2359583144448666
Validation loss: 2.5001143952315523

Epoch: 6| Step: 7
Training loss: 0.2804501205887844
Validation loss: 2.4969691670503007

Epoch: 6| Step: 8
Training loss: 0.19736631108921304
Validation loss: 2.508561243979656

Epoch: 6| Step: 9
Training loss: 0.19305731559503053
Validation loss: 2.4761201341745496

Epoch: 6| Step: 10
Training loss: 0.2008804413955179
Validation loss: 2.5139715515791625

Epoch: 6| Step: 11
Training loss: 0.1709086987275879
Validation loss: 2.554697631362264

Epoch: 6| Step: 12
Training loss: 0.23267157148710685
Validation loss: 2.521976101748894

Epoch: 6| Step: 13
Training loss: 0.13579893641190546
Validation loss: 2.5706508321664803

Epoch: 486| Step: 0
Training loss: 0.2774903756053538
Validation loss: 2.561116017655814

Epoch: 6| Step: 1
Training loss: 0.203660497519554
Validation loss: 2.5620780295257437

Epoch: 6| Step: 2
Training loss: 0.2053888328680103
Validation loss: 2.6049196640317493

Epoch: 6| Step: 3
Training loss: 0.14633025644911943
Validation loss: 2.5763504668111445

Epoch: 6| Step: 4
Training loss: 0.2856584724871474
Validation loss: 2.6020824037656936

Epoch: 6| Step: 5
Training loss: 0.19694368133238654
Validation loss: 2.533982801355558

Epoch: 6| Step: 6
Training loss: 0.1493594624606588
Validation loss: 2.5439116325303766

Epoch: 6| Step: 7
Training loss: 0.21686272007863255
Validation loss: 2.566127020022064

Epoch: 6| Step: 8
Training loss: 0.12285549933792261
Validation loss: 2.536979192427913

Epoch: 6| Step: 9
Training loss: 0.22505398572862065
Validation loss: 2.5163360830934858

Epoch: 6| Step: 10
Training loss: 0.31239339679142214
Validation loss: 2.4960856279881045

Epoch: 6| Step: 11
Training loss: 0.21010015440971042
Validation loss: 2.515877594517931

Epoch: 6| Step: 12
Training loss: 0.24894571774466354
Validation loss: 2.476010793029522

Epoch: 6| Step: 13
Training loss: 0.25587042573549545
Validation loss: 2.4823234178872147

Epoch: 487| Step: 0
Training loss: 0.13573984102924286
Validation loss: 2.47488963259232

Epoch: 6| Step: 1
Training loss: 0.27618032547730115
Validation loss: 2.504862828392767

Epoch: 6| Step: 2
Training loss: 0.17804792016372464
Validation loss: 2.490273701250494

Epoch: 6| Step: 3
Training loss: 0.22837770000254368
Validation loss: 2.536537856619311

Epoch: 6| Step: 4
Training loss: 0.2679511067223619
Validation loss: 2.487519737903672

Epoch: 6| Step: 5
Training loss: 0.17060189813852605
Validation loss: 2.508441680387707

Epoch: 6| Step: 6
Training loss: 0.1479898906739568
Validation loss: 2.538660800353774

Epoch: 6| Step: 7
Training loss: 0.14260088072734875
Validation loss: 2.4523918817824257

Epoch: 6| Step: 8
Training loss: 0.1533806068775946
Validation loss: 2.5492689561857307

Epoch: 6| Step: 9
Training loss: 0.1642253669055383
Validation loss: 2.5290653965531913

Epoch: 6| Step: 10
Training loss: 0.2611568454134477
Validation loss: 2.5463350706254646

Epoch: 6| Step: 11
Training loss: 0.11717361526885775
Validation loss: 2.5552799525956593

Epoch: 6| Step: 12
Training loss: 0.20568807811302284
Validation loss: 2.5468012888861367

Epoch: 6| Step: 13
Training loss: 0.1527778236853887
Validation loss: 2.538126123766883

Epoch: 488| Step: 0
Training loss: 0.21174476822613025
Validation loss: 2.5351597428058796

Epoch: 6| Step: 1
Training loss: 0.226967843607632
Validation loss: 2.52716341694142

Epoch: 6| Step: 2
Training loss: 0.21721917339970234
Validation loss: 2.518932916901237

Epoch: 6| Step: 3
Training loss: 0.19006443697197337
Validation loss: 2.5286470492643622

Epoch: 6| Step: 4
Training loss: 0.14892989606331916
Validation loss: 2.532911408925574

Epoch: 6| Step: 5
Training loss: 0.1369245887007708
Validation loss: 2.5516890528676486

Epoch: 6| Step: 6
Training loss: 0.19327394929634067
Validation loss: 2.560808743644319

Epoch: 6| Step: 7
Training loss: 0.19799009746957674
Validation loss: 2.5398289444856887

Epoch: 6| Step: 8
Training loss: 0.2596052147769875
Validation loss: 2.530763595316443

Epoch: 6| Step: 9
Training loss: 0.21248941500330595
Validation loss: 2.5054547293575347

Epoch: 6| Step: 10
Training loss: 0.1434449860129841
Validation loss: 2.5023894130408744

Epoch: 6| Step: 11
Training loss: 0.24898418042283343
Validation loss: 2.5678573498929422

Epoch: 6| Step: 12
Training loss: 0.17732638387474842
Validation loss: 2.5467535126211964

Epoch: 6| Step: 13
Training loss: 0.10606587001513398
Validation loss: 2.5518103841376565

Epoch: 489| Step: 0
Training loss: 0.17826269039801645
Validation loss: 2.586819144434856

Epoch: 6| Step: 1
Training loss: 0.1287594305908566
Validation loss: 2.577441577687102

Epoch: 6| Step: 2
Training loss: 0.17754538412558393
Validation loss: 2.534148676438278

Epoch: 6| Step: 3
Training loss: 0.18944769782718626
Validation loss: 2.5360121186154707

Epoch: 6| Step: 4
Training loss: 0.17316245014826337
Validation loss: 2.561081964895231

Epoch: 6| Step: 5
Training loss: 0.10444553171460547
Validation loss: 2.572736755659824

Epoch: 6| Step: 6
Training loss: 0.17466185504357717
Validation loss: 2.5405781054047774

Epoch: 6| Step: 7
Training loss: 0.18313577019784077
Validation loss: 2.552349221544957

Epoch: 6| Step: 8
Training loss: 0.1639989888920377
Validation loss: 2.545352424560213

Epoch: 6| Step: 9
Training loss: 0.1302925830710125
Validation loss: 2.5633693138927436

Epoch: 6| Step: 10
Training loss: 0.32162580843756045
Validation loss: 2.551997475166588

Epoch: 6| Step: 11
Training loss: 0.1696683483134903
Validation loss: 2.534477642233486

Epoch: 6| Step: 12
Training loss: 0.21912637756053915
Validation loss: 2.5390111587672357

Epoch: 6| Step: 13
Training loss: 0.2840595319066189
Validation loss: 2.5397988649232466

Epoch: 490| Step: 0
Training loss: 0.15348503351560566
Validation loss: 2.4759282409210144

Epoch: 6| Step: 1
Training loss: 0.14354243193751373
Validation loss: 2.4931322271218095

Epoch: 6| Step: 2
Training loss: 0.17510833686384047
Validation loss: 2.524231291381987

Epoch: 6| Step: 3
Training loss: 0.1891299273314846
Validation loss: 2.530195824144476

Epoch: 6| Step: 4
Training loss: 0.21076158853201105
Validation loss: 2.520915373244598

Epoch: 6| Step: 5
Training loss: 0.18209079619840543
Validation loss: 2.4745821804305725

Epoch: 6| Step: 6
Training loss: 0.1798458748997652
Validation loss: 2.515130255966402

Epoch: 6| Step: 7
Training loss: 0.3137457099180505
Validation loss: 2.5196353449188384

Epoch: 6| Step: 8
Training loss: 0.16376434777461213
Validation loss: 2.517088842061056

Epoch: 6| Step: 9
Training loss: 0.22207196854885622
Validation loss: 2.515410430242278

Epoch: 6| Step: 10
Training loss: 0.31002784636622566
Validation loss: 2.5624679235276075

Epoch: 6| Step: 11
Training loss: 0.17165032245222062
Validation loss: 2.544170992365696

Epoch: 6| Step: 12
Training loss: 0.16271612073218422
Validation loss: 2.564053058576265

Epoch: 6| Step: 13
Training loss: 0.22018429021907732
Validation loss: 2.542694694508443

Epoch: 491| Step: 0
Training loss: 0.21799454348411068
Validation loss: 2.524409451949264

Epoch: 6| Step: 1
Training loss: 0.15055668320351803
Validation loss: 2.563832643559957

Epoch: 6| Step: 2
Training loss: 0.176568319638309
Validation loss: 2.558731523524403

Epoch: 6| Step: 3
Training loss: 0.27581346123806866
Validation loss: 2.5323716138111547

Epoch: 6| Step: 4
Training loss: 0.15623062728948187
Validation loss: 2.551229813279289

Epoch: 6| Step: 5
Training loss: 0.16981303357520322
Validation loss: 2.5357044124805146

Epoch: 6| Step: 6
Training loss: 0.23978100617643816
Validation loss: 2.534178328886673

Epoch: 6| Step: 7
Training loss: 0.21884715953874373
Validation loss: 2.5365665720375565

Epoch: 6| Step: 8
Training loss: 0.12340836558384491
Validation loss: 2.534890179911481

Epoch: 6| Step: 9
Training loss: 0.24977140853671997
Validation loss: 2.513202117768964

Epoch: 6| Step: 10
Training loss: 0.14373315370366152
Validation loss: 2.539876749059994

Epoch: 6| Step: 11
Training loss: 0.15124383637976646
Validation loss: 2.552465413673694

Epoch: 6| Step: 12
Training loss: 0.14865625725409937
Validation loss: 2.5797230073392954

Epoch: 6| Step: 13
Training loss: 0.28206666951190396
Validation loss: 2.545259732649394

Epoch: 492| Step: 0
Training loss: 0.14318653830592853
Validation loss: 2.5757867625284323

Epoch: 6| Step: 1
Training loss: 0.1286971679638963
Validation loss: 2.5676037165263024

Epoch: 6| Step: 2
Training loss: 0.1406068061609219
Validation loss: 2.5390896410631303

Epoch: 6| Step: 3
Training loss: 0.17772231218253687
Validation loss: 2.5599898022081957

Epoch: 6| Step: 4
Training loss: 0.25251180231724907
Validation loss: 2.5120674587465652

Epoch: 6| Step: 5
Training loss: 0.1162996034006161
Validation loss: 2.545669859388362

Epoch: 6| Step: 6
Training loss: 0.20895093133303042
Validation loss: 2.5330408009375653

Epoch: 6| Step: 7
Training loss: 0.24372734184591738
Validation loss: 2.529676127597439

Epoch: 6| Step: 8
Training loss: 0.15285241353680076
Validation loss: 2.496202464097446

Epoch: 6| Step: 9
Training loss: 0.2220113516635298
Validation loss: 2.544631024820252

Epoch: 6| Step: 10
Training loss: 0.2528379855849034
Validation loss: 2.494084389854733

Epoch: 6| Step: 11
Training loss: 0.1970410721317431
Validation loss: 2.504488209967071

Epoch: 6| Step: 12
Training loss: 0.1853044833979031
Validation loss: 2.5448832275190063

Epoch: 6| Step: 13
Training loss: 0.16781775762892445
Validation loss: 2.5313586788123543

Epoch: 493| Step: 0
Training loss: 0.19888803669862665
Validation loss: 2.531333059074668

Epoch: 6| Step: 1
Training loss: 0.1656750832714472
Validation loss: 2.559457530954603

Epoch: 6| Step: 2
Training loss: 0.17125812825348333
Validation loss: 2.570089963990491

Epoch: 6| Step: 3
Training loss: 0.24193339707451345
Validation loss: 2.527647169966179

Epoch: 6| Step: 4
Training loss: 0.187651453838312
Validation loss: 2.522878123808891

Epoch: 6| Step: 5
Training loss: 0.16251241035938688
Validation loss: 2.54420481702491

Epoch: 6| Step: 6
Training loss: 0.13777629013288115
Validation loss: 2.5529755069853746

Epoch: 6| Step: 7
Training loss: 0.13356362443753197
Validation loss: 2.5521130966717855

Epoch: 6| Step: 8
Training loss: 0.19037600029465293
Validation loss: 2.549398513204154

Epoch: 6| Step: 9
Training loss: 0.2338795033657956
Validation loss: 2.5259364994350233

Epoch: 6| Step: 10
Training loss: 0.15203311623999025
Validation loss: 2.5477498943252

Epoch: 6| Step: 11
Training loss: 0.16547701360224007
Validation loss: 2.5532843175843305

Epoch: 6| Step: 12
Training loss: 0.11461133957825727
Validation loss: 2.5259159633227752

Epoch: 6| Step: 13
Training loss: 0.2842562857363159
Validation loss: 2.4888593853640137

Epoch: 494| Step: 0
Training loss: 0.1329087932104757
Validation loss: 2.532184895587717

Epoch: 6| Step: 1
Training loss: 0.17768331989130778
Validation loss: 2.536280129981481

Epoch: 6| Step: 2
Training loss: 0.14306317739130506
Validation loss: 2.5117146662885887

Epoch: 6| Step: 3
Training loss: 0.19338303238227403
Validation loss: 2.5403305312717688

Epoch: 6| Step: 4
Training loss: 0.16468744234522004
Validation loss: 2.528987231162693

Epoch: 6| Step: 5
Training loss: 0.1330299560666752
Validation loss: 2.531883164607665

Epoch: 6| Step: 6
Training loss: 0.16036970173021742
Validation loss: 2.5187059186952223

Epoch: 6| Step: 7
Training loss: 0.2130835909762321
Validation loss: 2.524377020955276

Epoch: 6| Step: 8
Training loss: 0.26661383073127604
Validation loss: 2.5220066276774764

Epoch: 6| Step: 9
Training loss: 0.15314476630055765
Validation loss: 2.5593902502895607

Epoch: 6| Step: 10
Training loss: 0.1835113401306543
Validation loss: 2.4952615963306117

Epoch: 6| Step: 11
Training loss: 0.23571837398980008
Validation loss: 2.5210558856532574

Epoch: 6| Step: 12
Training loss: 0.16278021819142302
Validation loss: 2.534382289767098

Epoch: 6| Step: 13
Training loss: 0.16432670482091818
Validation loss: 2.5260812299391704

Epoch: 495| Step: 0
Training loss: 0.15429147276294003
Validation loss: 2.5280871657403634

Epoch: 6| Step: 1
Training loss: 0.15223063034993048
Validation loss: 2.5209170023952687

Epoch: 6| Step: 2
Training loss: 0.16931828909559848
Validation loss: 2.4898930200528677

Epoch: 6| Step: 3
Training loss: 0.08708214045417519
Validation loss: 2.4990960937902362

Epoch: 6| Step: 4
Training loss: 0.13405974356389605
Validation loss: 2.53887677569651

Epoch: 6| Step: 5
Training loss: 0.26668878323264367
Validation loss: 2.5113844531279046

Epoch: 6| Step: 6
Training loss: 0.29279950657598425
Validation loss: 2.480349216192294

Epoch: 6| Step: 7
Training loss: 0.2456217887416129
Validation loss: 2.510841469166596

Epoch: 6| Step: 8
Training loss: 0.157183113965979
Validation loss: 2.5071671694817477

Epoch: 6| Step: 9
Training loss: 0.22728538288296268
Validation loss: 2.4981005497702253

Epoch: 6| Step: 10
Training loss: 0.18300281953463543
Validation loss: 2.5212407512994313

Epoch: 6| Step: 11
Training loss: 0.15392460156934856
Validation loss: 2.516432876304183

Epoch: 6| Step: 12
Training loss: 0.23929570734858172
Validation loss: 2.4863044396026686

Epoch: 6| Step: 13
Training loss: 0.1786746525016908
Validation loss: 2.531318403844266

Epoch: 496| Step: 0
Training loss: 0.11901075679958606
Validation loss: 2.5269788242861475

Epoch: 6| Step: 1
Training loss: 0.16181794363245783
Validation loss: 2.5224419590798446

Epoch: 6| Step: 2
Training loss: 0.12820570776346843
Validation loss: 2.549188504916395

Epoch: 6| Step: 3
Training loss: 0.2525319245193361
Validation loss: 2.5091983759824683

Epoch: 6| Step: 4
Training loss: 0.1824249234649343
Validation loss: 2.5507241012009847

Epoch: 6| Step: 5
Training loss: 0.1554105501168737
Validation loss: 2.530667883588505

Epoch: 6| Step: 6
Training loss: 0.2669203253410028
Validation loss: 2.5269180778509495

Epoch: 6| Step: 7
Training loss: 0.25202562338879936
Validation loss: 2.5068492657912858

Epoch: 6| Step: 8
Training loss: 0.30326238547000206
Validation loss: 2.5130887906012402

Epoch: 6| Step: 9
Training loss: 0.16854566923484476
Validation loss: 2.503993351539151

Epoch: 6| Step: 10
Training loss: 0.23255318050118584
Validation loss: 2.4974184633287644

Epoch: 6| Step: 11
Training loss: 0.16758534564843405
Validation loss: 2.563733986050736

Epoch: 6| Step: 12
Training loss: 0.19783120234155066
Validation loss: 2.5519396684770626

Epoch: 6| Step: 13
Training loss: 0.18673257936155832
Validation loss: 2.540319481779579

Epoch: 497| Step: 0
Training loss: 0.10954168085013774
Validation loss: 2.5564771684716474

Epoch: 6| Step: 1
Training loss: 0.2858814919447261
Validation loss: 2.5430700830955013

Epoch: 6| Step: 2
Training loss: 0.13333457825745101
Validation loss: 2.52775325824857

Epoch: 6| Step: 3
Training loss: 0.19211596654107102
Validation loss: 2.4933820868976753

Epoch: 6| Step: 4
Training loss: 0.19564679147839592
Validation loss: 2.530461036845059

Epoch: 6| Step: 5
Training loss: 0.16709971173040133
Validation loss: 2.5587628633454234

Epoch: 6| Step: 6
Training loss: 0.23307331536257153
Validation loss: 2.55601495275486

Epoch: 6| Step: 7
Training loss: 0.14991477517138455
Validation loss: 2.611013798171955

Epoch: 6| Step: 8
Training loss: 0.23504509500779106
Validation loss: 2.5979059733874914

Epoch: 6| Step: 9
Training loss: 0.35104190640578115
Validation loss: 2.60225802136617

Epoch: 6| Step: 10
Training loss: 0.28776940235360354
Validation loss: 2.597593635040674

Epoch: 6| Step: 11
Training loss: 0.15197937133174796
Validation loss: 2.6172450096486175

Epoch: 6| Step: 12
Training loss: 0.28136852204243185
Validation loss: 2.6245381681001887

Epoch: 6| Step: 13
Training loss: 0.20938267586999915
Validation loss: 2.628033281553173

Epoch: 498| Step: 0
Training loss: 0.23974685513439595
Validation loss: 2.6157696407979136

Epoch: 6| Step: 1
Training loss: 0.18889693585097167
Validation loss: 2.607811170153092

Epoch: 6| Step: 2
Training loss: 0.19681586558207242
Validation loss: 2.6211123334632593

Epoch: 6| Step: 3
Training loss: 0.2661911596730494
Validation loss: 2.538250896525486

Epoch: 6| Step: 4
Training loss: 0.1720084625868072
Validation loss: 2.5584640238336576

Epoch: 6| Step: 5
Training loss: 0.13510478919813995
Validation loss: 2.532676430575172

Epoch: 6| Step: 6
Training loss: 0.16965023339340093
Validation loss: 2.534105801347428

Epoch: 6| Step: 7
Training loss: 0.2175238337831546
Validation loss: 2.46931966323192

Epoch: 6| Step: 8
Training loss: 0.27669198727981265
Validation loss: 2.446285844178138

Epoch: 6| Step: 9
Training loss: 0.15901094397407345
Validation loss: 2.495557103246036

Epoch: 6| Step: 10
Training loss: 0.29201054595085113
Validation loss: 2.4839824124601138

Epoch: 6| Step: 11
Training loss: 0.12883874541737642
Validation loss: 2.465797083032616

Epoch: 6| Step: 12
Training loss: 0.320686447694963
Validation loss: 2.470609843652588

Epoch: 6| Step: 13
Training loss: 0.20164965401335322
Validation loss: 2.511997764753812

Epoch: 499| Step: 0
Training loss: 0.1855956063775882
Validation loss: 2.510426215220586

Epoch: 6| Step: 1
Training loss: 0.26138616182583907
Validation loss: 2.5395218184304262

Epoch: 6| Step: 2
Training loss: 0.1439862608410951
Validation loss: 2.5022836069076

Epoch: 6| Step: 3
Training loss: 0.23731329003585064
Validation loss: 2.514204370746709

Epoch: 6| Step: 4
Training loss: 0.17006370500826717
Validation loss: 2.516355238988399

Epoch: 6| Step: 5
Training loss: 0.18384131520844368
Validation loss: 2.5350200480540734

Epoch: 6| Step: 6
Training loss: 0.11650906716848279
Validation loss: 2.4795604523018695

Epoch: 6| Step: 7
Training loss: 0.20382306386177082
Validation loss: 2.5356119365945524

Epoch: 6| Step: 8
Training loss: 0.1355378925744197
Validation loss: 2.512950033731066

Epoch: 6| Step: 9
Training loss: 0.21450152450299872
Validation loss: 2.5455852025575885

Epoch: 6| Step: 10
Training loss: 0.1424943468787874
Validation loss: 2.492663325940843

Epoch: 6| Step: 11
Training loss: 0.17123108233775614
Validation loss: 2.5458269205548505

Epoch: 6| Step: 12
Training loss: 0.2795281553017164
Validation loss: 2.559366319501844

Epoch: 6| Step: 13
Training loss: 0.16759642654463933
Validation loss: 2.522985324078005

Epoch: 500| Step: 0
Training loss: 0.16043391233072965
Validation loss: 2.5460473497527465

Epoch: 6| Step: 1
Training loss: 0.3980046333158311
Validation loss: 2.5469352120663276

Epoch: 6| Step: 2
Training loss: 0.20230787320012483
Validation loss: 2.552252123794478

Epoch: 6| Step: 3
Training loss: 0.18357335646973008
Validation loss: 2.5468049630171383

Epoch: 6| Step: 4
Training loss: 0.27643653080559255
Validation loss: 2.561886934426122

Epoch: 6| Step: 5
Training loss: 0.27848104553852115
Validation loss: 2.537662032412891

Epoch: 6| Step: 6
Training loss: 0.19040850007959514
Validation loss: 2.534548978737702

Epoch: 6| Step: 7
Training loss: 0.15894215653558894
Validation loss: 2.542429000920369

Epoch: 6| Step: 8
Training loss: 0.12040368470360845
Validation loss: 2.556292246081758

Epoch: 6| Step: 9
Training loss: 0.19933050424451074
Validation loss: 2.5711664284362534

Epoch: 6| Step: 10
Training loss: 0.1781425923310025
Validation loss: 2.57250983575737

Epoch: 6| Step: 11
Training loss: 0.22796916015148852
Validation loss: 2.5408615667540304

Epoch: 6| Step: 12
Training loss: 0.14681400087514238
Validation loss: 2.542791132631526

Epoch: 6| Step: 13
Training loss: 0.11836396797005892
Validation loss: 2.5612508974343147

Epoch: 501| Step: 0
Training loss: 0.18107309175876524
Validation loss: 2.569593962295557

Epoch: 6| Step: 1
Training loss: 0.23063367664483714
Validation loss: 2.5878355493797027

Epoch: 6| Step: 2
Training loss: 0.11680599738381568
Validation loss: 2.5469959008134078

Epoch: 6| Step: 3
Training loss: 0.22177086858060768
Validation loss: 2.5694903378396132

Epoch: 6| Step: 4
Training loss: 0.17442202106699697
Validation loss: 2.5344495753011818

Epoch: 6| Step: 5
Training loss: 0.1856359569128642
Validation loss: 2.56357355087261

Epoch: 6| Step: 6
Training loss: 0.16183894937941234
Validation loss: 2.5344582101074207

Epoch: 6| Step: 7
Training loss: 0.1749706545986886
Validation loss: 2.5462854879437216

Epoch: 6| Step: 8
Training loss: 0.25585898188204087
Validation loss: 2.5542123766744482

Epoch: 6| Step: 9
Training loss: 0.20577833437175633
Validation loss: 2.5534645945089376

Epoch: 6| Step: 10
Training loss: 0.23562927006968043
Validation loss: 2.5611414856096006

Epoch: 6| Step: 11
Training loss: 0.27613953289057125
Validation loss: 2.530224524402415

Epoch: 6| Step: 12
Training loss: 0.23886479386684456
Validation loss: 2.5419758424232666

Epoch: 6| Step: 13
Training loss: 0.1451668617077604
Validation loss: 2.509248970422273

Epoch: 502| Step: 0
Training loss: 0.14308019968661373
Validation loss: 2.500193329995957

Epoch: 6| Step: 1
Training loss: 0.20301817872836933
Validation loss: 2.525785914317563

Epoch: 6| Step: 2
Training loss: 0.14214555231632478
Validation loss: 2.524862254664167

Epoch: 6| Step: 3
Training loss: 0.3339507548939237
Validation loss: 2.54327732663282

Epoch: 6| Step: 4
Training loss: 0.15940996492406118
Validation loss: 2.540808803385442

Epoch: 6| Step: 5
Training loss: 0.14853310016159554
Validation loss: 2.576099777403859

Epoch: 6| Step: 6
Training loss: 0.13972045801919417
Validation loss: 2.5348513268921855

Epoch: 6| Step: 7
Training loss: 0.17529041851600688
Validation loss: 2.5383900781720974

Epoch: 6| Step: 8
Training loss: 0.1521907857642025
Validation loss: 2.5426424017227167

Epoch: 6| Step: 9
Training loss: 0.2613548196749222
Validation loss: 2.5199838086708573

Epoch: 6| Step: 10
Training loss: 0.1465609286860518
Validation loss: 2.539156852843287

Epoch: 6| Step: 11
Training loss: 0.17379804415225117
Validation loss: 2.541199747835432

Epoch: 6| Step: 12
Training loss: 0.17867628918571377
Validation loss: 2.557550798655282

Epoch: 6| Step: 13
Training loss: 0.15794338874534058
Validation loss: 2.57926827466368

Epoch: 503| Step: 0
Training loss: 0.21348267221040448
Validation loss: 2.553248998663485

Epoch: 6| Step: 1
Training loss: 0.16556933385239106
Validation loss: 2.546334512356875

Epoch: 6| Step: 2
Training loss: 0.18548715533850416
Validation loss: 2.5350809765381017

Epoch: 6| Step: 3
Training loss: 0.12131105813241151
Validation loss: 2.5699526532447026

Epoch: 6| Step: 4
Training loss: 0.3282126355081538
Validation loss: 2.5473659426466564

Epoch: 6| Step: 5
Training loss: 0.20443320821993785
Validation loss: 2.54788703170407

Epoch: 6| Step: 6
Training loss: 0.15779170947464224
Validation loss: 2.552427752226222

Epoch: 6| Step: 7
Training loss: 0.1925621745717519
Validation loss: 2.527692364853154

Epoch: 6| Step: 8
Training loss: 0.3376977623695656
Validation loss: 2.5190371876745994

Epoch: 6| Step: 9
Training loss: 0.16375845028280023
Validation loss: 2.548345823935066

Epoch: 6| Step: 10
Training loss: 0.2166229443879063
Validation loss: 2.5392165331188745

Epoch: 6| Step: 11
Training loss: 0.15848621894691162
Validation loss: 2.5529208294355046

Epoch: 6| Step: 12
Training loss: 0.17837973165618715
Validation loss: 2.543081454312484

Epoch: 6| Step: 13
Training loss: 0.12106774035427595
Validation loss: 2.5163848734130423

Epoch: 504| Step: 0
Training loss: 0.12104831119914888
Validation loss: 2.548917249404484

Epoch: 6| Step: 1
Training loss: 0.18463665410762847
Validation loss: 2.5365479503098185

Epoch: 6| Step: 2
Training loss: 0.1697964205154398
Validation loss: 2.524798701045718

Epoch: 6| Step: 3
Training loss: 0.15609826826977605
Validation loss: 2.5596981512837598

Epoch: 6| Step: 4
Training loss: 0.24107928679540663
Validation loss: 2.5374240755379067

Epoch: 6| Step: 5
Training loss: 0.1509802641420976
Validation loss: 2.5323994967509686

Epoch: 6| Step: 6
Training loss: 0.1708796899594216
Validation loss: 2.5265243730433204

Epoch: 6| Step: 7
Training loss: 0.23863425449991582
Validation loss: 2.533085515957419

Epoch: 6| Step: 8
Training loss: 0.15907696176674468
Validation loss: 2.531097593875721

Epoch: 6| Step: 9
Training loss: 0.09871668129782435
Validation loss: 2.5378164490403017

Epoch: 6| Step: 10
Training loss: 0.24180409631745906
Validation loss: 2.523265059479975

Epoch: 6| Step: 11
Training loss: 0.15953588125921073
Validation loss: 2.4899109477106767

Epoch: 6| Step: 12
Training loss: 0.2702153963084029
Validation loss: 2.4860087331031515

Epoch: 6| Step: 13
Training loss: 0.17982523241997259
Validation loss: 2.5460823285603036

Epoch: 505| Step: 0
Training loss: 0.14725177659305255
Validation loss: 2.4694440921780876

Epoch: 6| Step: 1
Training loss: 0.12571586573954954
Validation loss: 2.4890912550022706

Epoch: 6| Step: 2
Training loss: 0.16510564262400296
Validation loss: 2.534554340577125

Epoch: 6| Step: 3
Training loss: 0.12188201113854875
Validation loss: 2.552307443194092

Epoch: 6| Step: 4
Training loss: 0.10677846342441381
Validation loss: 2.5488371984093767

Epoch: 6| Step: 5
Training loss: 0.16490747069932984
Validation loss: 2.554569358686771

Epoch: 6| Step: 6
Training loss: 0.1673799830568126
Validation loss: 2.5305770623653125

Epoch: 6| Step: 7
Training loss: 0.2837910567421623
Validation loss: 2.5539877607682673

Epoch: 6| Step: 8
Training loss: 0.10319222910364848
Validation loss: 2.546710267393015

Epoch: 6| Step: 9
Training loss: 0.21993992936336565
Validation loss: 2.5446104476562703

Epoch: 6| Step: 10
Training loss: 0.11706697703622714
Validation loss: 2.532467399328784

Epoch: 6| Step: 11
Training loss: 0.2810081263101912
Validation loss: 2.5201025316833303

Epoch: 6| Step: 12
Training loss: 0.1552477401485996
Validation loss: 2.5469431568243572

Epoch: 6| Step: 13
Training loss: 0.14070206093690277
Validation loss: 2.5457638898044883

Epoch: 506| Step: 0
Training loss: 0.14234319038783594
Validation loss: 2.5631772213660216

Epoch: 6| Step: 1
Training loss: 0.15458655025518628
Validation loss: 2.561164724158237

Epoch: 6| Step: 2
Training loss: 0.2332551428513078
Validation loss: 2.5469169540266474

Epoch: 6| Step: 3
Training loss: 0.12428034808604001
Validation loss: 2.516642689796109

Epoch: 6| Step: 4
Training loss: 0.2539697714355927
Validation loss: 2.545771588477214

Epoch: 6| Step: 5
Training loss: 0.1301761197932106
Validation loss: 2.5001895819840154

Epoch: 6| Step: 6
Training loss: 0.17154225738979004
Validation loss: 2.5499189094101813

Epoch: 6| Step: 7
Training loss: 0.2468631162076836
Validation loss: 2.5619834521337848

Epoch: 6| Step: 8
Training loss: 0.21894598594105963
Validation loss: 2.494775953972746

Epoch: 6| Step: 9
Training loss: 0.13947246374681344
Validation loss: 2.50370849455051

Epoch: 6| Step: 10
Training loss: 0.13702799020019504
Validation loss: 2.536219919678774

Epoch: 6| Step: 11
Training loss: 0.15282341442252872
Validation loss: 2.5673792856457656

Epoch: 6| Step: 12
Training loss: 0.298940400616967
Validation loss: 2.5378503937490238

Epoch: 6| Step: 13
Training loss: 0.11586881815161765
Validation loss: 2.501388141857087

Epoch: 507| Step: 0
Training loss: 0.10280740231047862
Validation loss: 2.550534944684713

Epoch: 6| Step: 1
Training loss: 0.23410211412507081
Validation loss: 2.552933677627738

Epoch: 6| Step: 2
Training loss: 0.1857295793171091
Validation loss: 2.5729479785130023

Epoch: 6| Step: 3
Training loss: 0.256004554385785
Validation loss: 2.566677684810893

Epoch: 6| Step: 4
Training loss: 0.14218061372828475
Validation loss: 2.545792200060887

Epoch: 6| Step: 5
Training loss: 0.18010646241289335
Validation loss: 2.557296443826395

Epoch: 6| Step: 6
Training loss: 0.23646725744192548
Validation loss: 2.5528695555220304

Epoch: 6| Step: 7
Training loss: 0.24569367631656544
Validation loss: 2.5402728980897

Epoch: 6| Step: 8
Training loss: 0.14856346332147854
Validation loss: 2.4924151838349533

Epoch: 6| Step: 9
Training loss: 0.15783336189916622
Validation loss: 2.4964850193182615

Epoch: 6| Step: 10
Training loss: 0.3204997259836617
Validation loss: 2.4784363566912377

Epoch: 6| Step: 11
Training loss: 0.1528079102222798
Validation loss: 2.5046783972174755

Epoch: 6| Step: 12
Training loss: 0.24593929711815857
Validation loss: 2.489395312304557

Epoch: 6| Step: 13
Training loss: 0.10767829375204678
Validation loss: 2.500273416806095

Epoch: 508| Step: 0
Training loss: 0.16465177181935814
Validation loss: 2.542823654921583

Epoch: 6| Step: 1
Training loss: 0.2606766436201891
Validation loss: 2.536757438633942

Epoch: 6| Step: 2
Training loss: 0.2269350967206431
Validation loss: 2.531447323514412

Epoch: 6| Step: 3
Training loss: 0.12152257867507799
Validation loss: 2.5825432013319713

Epoch: 6| Step: 4
Training loss: 0.06334461657044743
Validation loss: 2.5560448826080573

Epoch: 6| Step: 5
Training loss: 0.10993177186379144
Validation loss: 2.5358058372085943

Epoch: 6| Step: 6
Training loss: 0.22247541345347205
Validation loss: 2.5345071942354047

Epoch: 6| Step: 7
Training loss: 0.2844720365738201
Validation loss: 2.5161988089215077

Epoch: 6| Step: 8
Training loss: 0.18667173232573367
Validation loss: 2.5229902471453896

Epoch: 6| Step: 9
Training loss: 0.1507788144048336
Validation loss: 2.521705073139309

Epoch: 6| Step: 10
Training loss: 0.1138359988964246
Validation loss: 2.5448625390641615

Epoch: 6| Step: 11
Training loss: 0.2070499897518814
Validation loss: 2.5256911726107547

Epoch: 6| Step: 12
Training loss: 0.22496902861950813
Validation loss: 2.512338565306605

Epoch: 6| Step: 13
Training loss: 0.13895331285987955
Validation loss: 2.5251308296397146

Epoch: 509| Step: 0
Training loss: 0.1075544666075487
Validation loss: 2.5492201652008912

Epoch: 6| Step: 1
Training loss: 0.23248097125241624
Validation loss: 2.5446079133425266

Epoch: 6| Step: 2
Training loss: 0.15201855454556415
Validation loss: 2.5939459866903385

Epoch: 6| Step: 3
Training loss: 0.13991559756290672
Validation loss: 2.577273282652014

Epoch: 6| Step: 4
Training loss: 0.3636259269164891
Validation loss: 2.5910943099413264

Epoch: 6| Step: 5
Training loss: 0.20769008135561792
Validation loss: 2.553818003962656

Epoch: 6| Step: 6
Training loss: 0.31631177504312635
Validation loss: 2.526907001160316

Epoch: 6| Step: 7
Training loss: 0.2588797068644592
Validation loss: 2.5268155694321814

Epoch: 6| Step: 8
Training loss: 0.17746490969485276
Validation loss: 2.495316021413008

Epoch: 6| Step: 9
Training loss: 0.1404130716269258
Validation loss: 2.5182023467812717

Epoch: 6| Step: 10
Training loss: 0.2889930280765136
Validation loss: 2.4933170064929326

Epoch: 6| Step: 11
Training loss: 0.3314676213216928
Validation loss: 2.486736497903356

Epoch: 6| Step: 12
Training loss: 0.2426553637014932
Validation loss: 2.4997552649367973

Epoch: 6| Step: 13
Training loss: 0.12209192466152471
Validation loss: 2.480732918785657

Epoch: 510| Step: 0
Training loss: 0.22182653831402965
Validation loss: 2.461025516559184

Epoch: 6| Step: 1
Training loss: 0.2335444356860237
Validation loss: 2.5142180902720748

Epoch: 6| Step: 2
Training loss: 0.14417655698550036
Validation loss: 2.519916664375906

Epoch: 6| Step: 3
Training loss: 0.1716740853585798
Validation loss: 2.5167397019357565

Epoch: 6| Step: 4
Training loss: 0.1349229723339595
Validation loss: 2.517408558180677

Epoch: 6| Step: 5
Training loss: 0.2644239649057484
Validation loss: 2.493014963305743

Epoch: 6| Step: 6
Training loss: 0.28295319150535986
Validation loss: 2.5253177349299456

Epoch: 6| Step: 7
Training loss: 0.17180674454744374
Validation loss: 2.5208968616664933

Epoch: 6| Step: 8
Training loss: 0.4173083034016997
Validation loss: 2.533262234107287

Epoch: 6| Step: 9
Training loss: 0.23539283991954424
Validation loss: 2.5113071563778697

Epoch: 6| Step: 10
Training loss: 0.11274636531995773
Validation loss: 2.533328848604379

Epoch: 6| Step: 11
Training loss: 0.15122656904747633
Validation loss: 2.526185405072387

Epoch: 6| Step: 12
Training loss: 0.15208938956177556
Validation loss: 2.504747628051464

Epoch: 6| Step: 13
Training loss: 0.1534696447027494
Validation loss: 2.5060646463418017

Epoch: 511| Step: 0
Training loss: 0.2929254118336069
Validation loss: 2.4859526171927517

Epoch: 6| Step: 1
Training loss: 0.32496756520180503
Validation loss: 2.481748983809539

Epoch: 6| Step: 2
Training loss: 0.1932765128095596
Validation loss: 2.455135420659491

Epoch: 6| Step: 3
Training loss: 0.26862041709384543
Validation loss: 2.491257192921975

Epoch: 6| Step: 4
Training loss: 0.2788558358755349
Validation loss: 2.507431061067266

Epoch: 6| Step: 5
Training loss: 0.17085336363255266
Validation loss: 2.4827098132588294

Epoch: 6| Step: 6
Training loss: 0.23743446161083825
Validation loss: 2.524429396075015

Epoch: 6| Step: 7
Training loss: 0.20806808672961935
Validation loss: 2.55337604850785

Epoch: 6| Step: 8
Training loss: 0.12078022361753542
Validation loss: 2.530573240065819

Epoch: 6| Step: 9
Training loss: 0.18382087821310816
Validation loss: 2.560477612479457

Epoch: 6| Step: 10
Training loss: 0.14414280163535223
Validation loss: 2.5656424322074787

Epoch: 6| Step: 11
Training loss: 0.2488413275744856
Validation loss: 2.5336519565834745

Epoch: 6| Step: 12
Training loss: 0.29292129132204575
Validation loss: 2.574972463226189

Epoch: 6| Step: 13
Training loss: 0.24841103142865853
Validation loss: 2.589110315559998

Epoch: 512| Step: 0
Training loss: 0.2246764290274667
Validation loss: 2.5654901166169726

Epoch: 6| Step: 1
Training loss: 0.28939859079882563
Validation loss: 2.560289873973294

Epoch: 6| Step: 2
Training loss: 0.15867498459579252
Validation loss: 2.574511783136967

Epoch: 6| Step: 3
Training loss: 0.13201444338309107
Validation loss: 2.5375375403522806

Epoch: 6| Step: 4
Training loss: 0.13367482340964928
Validation loss: 2.5577605969390844

Epoch: 6| Step: 5
Training loss: 0.14040877354941708
Validation loss: 2.5138807364795643

Epoch: 6| Step: 6
Training loss: 0.33332748954339364
Validation loss: 2.520596028959316

Epoch: 6| Step: 7
Training loss: 0.2612583894158301
Validation loss: 2.526707207339519

Epoch: 6| Step: 8
Training loss: 0.17452351103882324
Validation loss: 2.5404336366925557

Epoch: 6| Step: 9
Training loss: 0.1482120860300961
Validation loss: 2.510842152745067

Epoch: 6| Step: 10
Training loss: 0.15617467733657917
Validation loss: 2.510663727343712

Epoch: 6| Step: 11
Training loss: 0.17297049918664376
Validation loss: 2.5517432941644302

Epoch: 6| Step: 12
Training loss: 0.15570822607394327
Validation loss: 2.521722300381488

Epoch: 6| Step: 13
Training loss: 0.15931232168899262
Validation loss: 2.5411148063913465

Epoch: 513| Step: 0
Training loss: 0.13452786743749773
Validation loss: 2.5522840386216945

Epoch: 6| Step: 1
Training loss: 0.18355862301741432
Validation loss: 2.5422131352535375

Epoch: 6| Step: 2
Training loss: 0.310620557093172
Validation loss: 2.532583623956955

Epoch: 6| Step: 3
Training loss: 0.2505333843114118
Validation loss: 2.554068123347881

Epoch: 6| Step: 4
Training loss: 0.15585778601273836
Validation loss: 2.5538401567456988

Epoch: 6| Step: 5
Training loss: 0.2014659657819219
Validation loss: 2.527626100058493

Epoch: 6| Step: 6
Training loss: 0.13264950399241365
Validation loss: 2.543000577442634

Epoch: 6| Step: 7
Training loss: 0.18104341218770473
Validation loss: 2.557435939237797

Epoch: 6| Step: 8
Training loss: 0.16819320142701236
Validation loss: 2.553777760453116

Epoch: 6| Step: 9
Training loss: 0.15129957842654654
Validation loss: 2.572953039135328

Epoch: 6| Step: 10
Training loss: 0.17342186182848465
Validation loss: 2.5443382380626387

Epoch: 6| Step: 11
Training loss: 0.15634365851052487
Validation loss: 2.5790693426107842

Epoch: 6| Step: 12
Training loss: 0.15256592859527984
Validation loss: 2.5818798784151356

Epoch: 6| Step: 13
Training loss: 0.11414229838262796
Validation loss: 2.5652877546197406

Epoch: 514| Step: 0
Training loss: 0.17014862146783172
Validation loss: 2.5287643963615754

Epoch: 6| Step: 1
Training loss: 0.16890254609478234
Validation loss: 2.549848129588531

Epoch: 6| Step: 2
Training loss: 0.14250004603150945
Validation loss: 2.525587459248391

Epoch: 6| Step: 3
Training loss: 0.24693232667467094
Validation loss: 2.5287468237401725

Epoch: 6| Step: 4
Training loss: 0.18498100526377645
Validation loss: 2.502912041556217

Epoch: 6| Step: 5
Training loss: 0.21535798000804698
Validation loss: 2.498903904863583

Epoch: 6| Step: 6
Training loss: 0.11408980153872846
Validation loss: 2.5206705991903826

Epoch: 6| Step: 7
Training loss: 0.16329943792901366
Validation loss: 2.542850117664736

Epoch: 6| Step: 8
Training loss: 0.13480915527545145
Validation loss: 2.4843444007128865

Epoch: 6| Step: 9
Training loss: 0.31122756827385084
Validation loss: 2.4957911476649826

Epoch: 6| Step: 10
Training loss: 0.12760585829203894
Validation loss: 2.490646788716837

Epoch: 6| Step: 11
Training loss: 0.1584413289278987
Validation loss: 2.501168666987695

Epoch: 6| Step: 12
Training loss: 0.1699538146069259
Validation loss: 2.5502562206566433

Epoch: 6| Step: 13
Training loss: 0.06076366889531563
Validation loss: 2.5239449354066723

Epoch: 515| Step: 0
Training loss: 0.16996857670015764
Validation loss: 2.5197663136724806

Epoch: 6| Step: 1
Training loss: 0.19391836419023042
Validation loss: 2.5127786818821214

Epoch: 6| Step: 2
Training loss: 0.1424543941240848
Validation loss: 2.5587845575305925

Epoch: 6| Step: 3
Training loss: 0.16890772914150598
Validation loss: 2.5376832043710977

Epoch: 6| Step: 4
Training loss: 0.262995778517693
Validation loss: 2.529004679963337

Epoch: 6| Step: 5
Training loss: 0.1233865915114782
Validation loss: 2.538560899989033

Epoch: 6| Step: 6
Training loss: 0.1184095009014939
Validation loss: 2.520104313950817

Epoch: 6| Step: 7
Training loss: 0.20074352474030766
Validation loss: 2.5444717407673014

Epoch: 6| Step: 8
Training loss: 0.21330886843652805
Validation loss: 2.5287555621643083

Epoch: 6| Step: 9
Training loss: 0.1605602263493444
Validation loss: 2.5477179742698346

Epoch: 6| Step: 10
Training loss: 0.14037476899577264
Validation loss: 2.5494090703317847

Epoch: 6| Step: 11
Training loss: 0.14762865091165053
Validation loss: 2.564470441453448

Epoch: 6| Step: 12
Training loss: 0.22603193180082132
Validation loss: 2.5738822981921987

Epoch: 6| Step: 13
Training loss: 0.1968596690884448
Validation loss: 2.5249601749653157

Epoch: 516| Step: 0
Training loss: 0.1377903360159919
Validation loss: 2.534493866745981

Epoch: 6| Step: 1
Training loss: 0.19718153265917962
Validation loss: 2.536713097272057

Epoch: 6| Step: 2
Training loss: 0.20474007309905437
Validation loss: 2.5566914613042906

Epoch: 6| Step: 3
Training loss: 0.11136552115658525
Validation loss: 2.5406727914525855

Epoch: 6| Step: 4
Training loss: 0.2253807257423747
Validation loss: 2.5513828128990923

Epoch: 6| Step: 5
Training loss: 0.28425991590695904
Validation loss: 2.585600914306049

Epoch: 6| Step: 6
Training loss: 0.16921569708749867
Validation loss: 2.54024238225442

Epoch: 6| Step: 7
Training loss: 0.19834500732912871
Validation loss: 2.534027166212718

Epoch: 6| Step: 8
Training loss: 0.2019539418010316
Validation loss: 2.5149827525968154

Epoch: 6| Step: 9
Training loss: 0.1809854072436635
Validation loss: 2.553446150230403

Epoch: 6| Step: 10
Training loss: 0.157720831411923
Validation loss: 2.5202469258515174

Epoch: 6| Step: 11
Training loss: 0.24043924233658318
Validation loss: 2.5406433293299795

Epoch: 6| Step: 12
Training loss: 0.19538035167849876
Validation loss: 2.506421292332853

Epoch: 6| Step: 13
Training loss: 0.19223774121467355
Validation loss: 2.5149453524698346

Epoch: 517| Step: 0
Training loss: 0.29894749121106934
Validation loss: 2.5341308406949765

Epoch: 6| Step: 1
Training loss: 0.1390224444639792
Validation loss: 2.527762562477861

Epoch: 6| Step: 2
Training loss: 0.18365676285505128
Validation loss: 2.539634247703487

Epoch: 6| Step: 3
Training loss: 0.14183427170405896
Validation loss: 2.5735718476348897

Epoch: 6| Step: 4
Training loss: 0.3442291366769375
Validation loss: 2.6152224578079832

Epoch: 6| Step: 5
Training loss: 0.24346612453501743
Validation loss: 2.606625476009525

Epoch: 6| Step: 6
Training loss: 0.19195283969707347
Validation loss: 2.6028970300238563

Epoch: 6| Step: 7
Training loss: 0.09782097275511656
Validation loss: 2.5954458872698507

Epoch: 6| Step: 8
Training loss: 0.2408055284700349
Validation loss: 2.596379467027973

Epoch: 6| Step: 9
Training loss: 0.18985306909238941
Validation loss: 2.575666936445239

Epoch: 6| Step: 10
Training loss: 0.10835569415341831
Validation loss: 2.5582230093377887

Epoch: 6| Step: 11
Training loss: 0.19246764660478882
Validation loss: 2.5898283300616787

Epoch: 6| Step: 12
Training loss: 0.19473686267543544
Validation loss: 2.557440496262967

Epoch: 6| Step: 13
Training loss: 0.16579566296080595
Validation loss: 2.5381764259030066

Epoch: 518| Step: 0
Training loss: 0.18583970302911224
Validation loss: 2.5316728071436567

Epoch: 6| Step: 1
Training loss: 0.167124868408585
Validation loss: 2.511085104350127

Epoch: 6| Step: 2
Training loss: 0.19971676828388765
Validation loss: 2.5054574547123534

Epoch: 6| Step: 3
Training loss: 0.22328895886556507
Validation loss: 2.49830178756427

Epoch: 6| Step: 4
Training loss: 0.18956499631114052
Validation loss: 2.4952650309383335

Epoch: 6| Step: 5
Training loss: 0.2295215993661093
Validation loss: 2.4795796922455677

Epoch: 6| Step: 6
Training loss: 0.1909637591384474
Validation loss: 2.48854884614468

Epoch: 6| Step: 7
Training loss: 0.14121049614464046
Validation loss: 2.4908593583414675

Epoch: 6| Step: 8
Training loss: 0.15736074230867836
Validation loss: 2.5394618010826733

Epoch: 6| Step: 9
Training loss: 0.130880475122373
Validation loss: 2.523988631631543

Epoch: 6| Step: 10
Training loss: 0.13989617973870824
Validation loss: 2.544155004898563

Epoch: 6| Step: 11
Training loss: 0.19966491590910737
Validation loss: 2.5294173795040074

Epoch: 6| Step: 12
Training loss: 0.21530038683276723
Validation loss: 2.5566386656492517

Epoch: 6| Step: 13
Training loss: 0.341104514650693
Validation loss: 2.5296717652996294

Epoch: 519| Step: 0
Training loss: 0.17966393647975543
Validation loss: 2.5441416271827815

Epoch: 6| Step: 1
Training loss: 0.16774189955700108
Validation loss: 2.5538968428228004

Epoch: 6| Step: 2
Training loss: 0.1781954600865271
Validation loss: 2.546568388494059

Epoch: 6| Step: 3
Training loss: 0.2733563984078974
Validation loss: 2.55307953715572

Epoch: 6| Step: 4
Training loss: 0.11400017668685271
Validation loss: 2.547432886752119

Epoch: 6| Step: 5
Training loss: 0.1451119921281799
Validation loss: 2.526799593904112

Epoch: 6| Step: 6
Training loss: 0.1813899535778644
Validation loss: 2.532155792326997

Epoch: 6| Step: 7
Training loss: 0.14266038507399484
Validation loss: 2.5422049392362314

Epoch: 6| Step: 8
Training loss: 0.14091276818802104
Validation loss: 2.4864668694038468

Epoch: 6| Step: 9
Training loss: 0.22203751810878358
Validation loss: 2.527443320823529

Epoch: 6| Step: 10
Training loss: 0.14307718594401123
Validation loss: 2.5023134417886985

Epoch: 6| Step: 11
Training loss: 0.23443481953491213
Validation loss: 2.501713101199694

Epoch: 6| Step: 12
Training loss: 0.1351513043088597
Validation loss: 2.504547001833095

Epoch: 6| Step: 13
Training loss: 0.32390261944780113
Validation loss: 2.5291879514944755

Epoch: 520| Step: 0
Training loss: 0.21943231165485488
Validation loss: 2.5308581765146942

Epoch: 6| Step: 1
Training loss: 0.19985653194385294
Validation loss: 2.5239896920326195

Epoch: 6| Step: 2
Training loss: 0.1143514624332825
Validation loss: 2.5728527783711974

Epoch: 6| Step: 3
Training loss: 0.2965408251351444
Validation loss: 2.533090349562884

Epoch: 6| Step: 4
Training loss: 0.20704521276065696
Validation loss: 2.525633102341347

Epoch: 6| Step: 5
Training loss: 0.19427231365352352
Validation loss: 2.556327715505528

Epoch: 6| Step: 6
Training loss: 0.13762508793030304
Validation loss: 2.547975742296931

Epoch: 6| Step: 7
Training loss: 0.25601776694879275
Validation loss: 2.5718918761784915

Epoch: 6| Step: 8
Training loss: 0.17600042136945188
Validation loss: 2.5329941999683507

Epoch: 6| Step: 9
Training loss: 0.17558912798366552
Validation loss: 2.5297527070195813

Epoch: 6| Step: 10
Training loss: 0.18600704951988817
Validation loss: 2.552905412925358

Epoch: 6| Step: 11
Training loss: 0.22640444734433587
Validation loss: 2.5750534678888672

Epoch: 6| Step: 12
Training loss: 0.1522969455223746
Validation loss: 2.554953894502504

Epoch: 6| Step: 13
Training loss: 0.104231460109377
Validation loss: 2.579998186302708

Epoch: 521| Step: 0
Training loss: 0.118957445155395
Validation loss: 2.5225128864280446

Epoch: 6| Step: 1
Training loss: 0.2183716942821374
Validation loss: 2.5182483130816653

Epoch: 6| Step: 2
Training loss: 0.1669830855181195
Validation loss: 2.5243091998392027

Epoch: 6| Step: 3
Training loss: 0.1248640013503492
Validation loss: 2.5264905886925497

Epoch: 6| Step: 4
Training loss: 0.2330422336833605
Validation loss: 2.5235147563740905

Epoch: 6| Step: 5
Training loss: 0.23452614837780505
Validation loss: 2.5634984298062458

Epoch: 6| Step: 6
Training loss: 0.09598144621295253
Validation loss: 2.512643894186468

Epoch: 6| Step: 7
Training loss: 0.2208717090548262
Validation loss: 2.540342482410582

Epoch: 6| Step: 8
Training loss: 0.11460207971836746
Validation loss: 2.478046128501719

Epoch: 6| Step: 9
Training loss: 0.1885044393528926
Validation loss: 2.500178496079819

Epoch: 6| Step: 10
Training loss: 0.13869741365835972
Validation loss: 2.5128107315385093

Epoch: 6| Step: 11
Training loss: 0.1732288703831815
Validation loss: 2.4674268660541765

Epoch: 6| Step: 12
Training loss: 0.0955795151548766
Validation loss: 2.508494136304109

Epoch: 6| Step: 13
Training loss: 0.2023938113406243
Validation loss: 2.5210965309926103

Epoch: 522| Step: 0
Training loss: 0.16857850491074944
Validation loss: 2.48343090038591

Epoch: 6| Step: 1
Training loss: 0.21685443148519082
Validation loss: 2.5082623452661172

Epoch: 6| Step: 2
Training loss: 0.22647828970632802
Validation loss: 2.4751450792046263

Epoch: 6| Step: 3
Training loss: 0.07234804183451869
Validation loss: 2.4793195676475235

Epoch: 6| Step: 4
Training loss: 0.19591222241051662
Validation loss: 2.5143459013112137

Epoch: 6| Step: 5
Training loss: 0.12462615943443968
Validation loss: 2.4970363462703697

Epoch: 6| Step: 6
Training loss: 0.20400038406158272
Validation loss: 2.5088740964739293

Epoch: 6| Step: 7
Training loss: 0.15550006067138358
Validation loss: 2.5170123896624395

Epoch: 6| Step: 8
Training loss: 0.1260251092150154
Validation loss: 2.502025061971494

Epoch: 6| Step: 9
Training loss: 0.16653351506507277
Validation loss: 2.4839355973802366

Epoch: 6| Step: 10
Training loss: 0.1392901165104103
Validation loss: 2.4949530561866213

Epoch: 6| Step: 11
Training loss: 0.21606601348141113
Validation loss: 2.4985269554722946

Epoch: 6| Step: 12
Training loss: 0.14502867595983296
Validation loss: 2.4868923349700003

Epoch: 6| Step: 13
Training loss: 0.062059708671401786
Validation loss: 2.4807355467729884

Epoch: 523| Step: 0
Training loss: 0.13638017147321813
Validation loss: 2.541907708734259

Epoch: 6| Step: 1
Training loss: 0.15717724210170841
Validation loss: 2.517174453198933

Epoch: 6| Step: 2
Training loss: 0.1613672862425451
Validation loss: 2.472780150263997

Epoch: 6| Step: 3
Training loss: 0.27021393494889184
Validation loss: 2.491124604920284

Epoch: 6| Step: 4
Training loss: 0.18050688014628596
Validation loss: 2.5316639355015957

Epoch: 6| Step: 5
Training loss: 0.1947510469552963
Validation loss: 2.5410342755294972

Epoch: 6| Step: 6
Training loss: 0.1976218359468919
Validation loss: 2.514624423469806

Epoch: 6| Step: 7
Training loss: 0.20539565254695122
Validation loss: 2.5540716211561443

Epoch: 6| Step: 8
Training loss: 0.1375210450604747
Validation loss: 2.5433393152666253

Epoch: 6| Step: 9
Training loss: 0.1276411121432427
Validation loss: 2.551225652633842

Epoch: 6| Step: 10
Training loss: 0.15218026608109822
Validation loss: 2.5504455400768555

Epoch: 6| Step: 11
Training loss: 0.2274095141931554
Validation loss: 2.5664590904520055

Epoch: 6| Step: 12
Training loss: 0.24872601268837066
Validation loss: 2.563881482436885

Epoch: 6| Step: 13
Training loss: 0.1319724894578034
Validation loss: 2.5559607614873507

Epoch: 524| Step: 0
Training loss: 0.20550204467800404
Validation loss: 2.535567279967463

Epoch: 6| Step: 1
Training loss: 0.19836578838051339
Validation loss: 2.5131259582318415

Epoch: 6| Step: 2
Training loss: 0.0980861214818714
Validation loss: 2.5278200544313534

Epoch: 6| Step: 3
Training loss: 0.24015615321785957
Validation loss: 2.534096515349781

Epoch: 6| Step: 4
Training loss: 0.17475026098526553
Validation loss: 2.51462926503483

Epoch: 6| Step: 5
Training loss: 0.34120995401853205
Validation loss: 2.5145177139885218

Epoch: 6| Step: 6
Training loss: 0.1444533498998514
Validation loss: 2.5132403144882978

Epoch: 6| Step: 7
Training loss: 0.14206091596162493
Validation loss: 2.524064772171758

Epoch: 6| Step: 8
Training loss: 0.14967055526463774
Validation loss: 2.5106013291431823

Epoch: 6| Step: 9
Training loss: 0.18923879081003117
Validation loss: 2.5235385232611605

Epoch: 6| Step: 10
Training loss: 0.20979196713384068
Validation loss: 2.5456298355139553

Epoch: 6| Step: 11
Training loss: 0.1264162375226068
Validation loss: 2.5416244427344044

Epoch: 6| Step: 12
Training loss: 0.25782914541435703
Validation loss: 2.5768425937446353

Epoch: 6| Step: 13
Training loss: 0.29954534987971293
Validation loss: 2.5448737048265673

Epoch: 525| Step: 0
Training loss: 0.08957267377147414
Validation loss: 2.55232121805217

Epoch: 6| Step: 1
Training loss: 0.12687561897070473
Validation loss: 2.527807419863162

Epoch: 6| Step: 2
Training loss: 0.21410753514269712
Validation loss: 2.5069386222133256

Epoch: 6| Step: 3
Training loss: 0.2227408348840662
Validation loss: 2.5198742943877774

Epoch: 6| Step: 4
Training loss: 0.20765232101121978
Validation loss: 2.5340194465284434

Epoch: 6| Step: 5
Training loss: 0.1983394384262624
Validation loss: 2.5196568051980495

Epoch: 6| Step: 6
Training loss: 0.17491472499694177
Validation loss: 2.527424966605511

Epoch: 6| Step: 7
Training loss: 0.30408304117649926
Validation loss: 2.5125395937886297

Epoch: 6| Step: 8
Training loss: 0.2450118959589627
Validation loss: 2.535834093850129

Epoch: 6| Step: 9
Training loss: 0.24729659532880788
Validation loss: 2.5206107442428953

Epoch: 6| Step: 10
Training loss: 0.15375383401370254
Validation loss: 2.502901568443337

Epoch: 6| Step: 11
Training loss: 0.283070855658128
Validation loss: 2.5581960622500994

Epoch: 6| Step: 12
Training loss: 0.18220802613537854
Validation loss: 2.5374916850415046

Epoch: 6| Step: 13
Training loss: 0.13432698805965615
Validation loss: 2.517584147197458

Epoch: 526| Step: 0
Training loss: 0.2174671225527322
Validation loss: 2.5523112399758707

Epoch: 6| Step: 1
Training loss: 0.23635148492543953
Validation loss: 2.5712239240082013

Epoch: 6| Step: 2
Training loss: 0.19201198409846665
Validation loss: 2.555814278484683

Epoch: 6| Step: 3
Training loss: 0.14942305668705966
Validation loss: 2.562743508778968

Epoch: 6| Step: 4
Training loss: 0.1324774288012613
Validation loss: 2.5552181026411662

Epoch: 6| Step: 5
Training loss: 0.140763737534504
Validation loss: 2.5677034564001993

Epoch: 6| Step: 6
Training loss: 0.13979146875186485
Validation loss: 2.549328233305873

Epoch: 6| Step: 7
Training loss: 0.2011175823094434
Validation loss: 2.5497050166396305

Epoch: 6| Step: 8
Training loss: 0.22417340468067373
Validation loss: 2.5935379655271813

Epoch: 6| Step: 9
Training loss: 0.14775573240211842
Validation loss: 2.570390777089149

Epoch: 6| Step: 10
Training loss: 0.18060711143442137
Validation loss: 2.629361193598656

Epoch: 6| Step: 11
Training loss: 0.09762929544389211
Validation loss: 2.6095092436303866

Epoch: 6| Step: 12
Training loss: 0.2759646392211994
Validation loss: 2.581488430022967

Epoch: 6| Step: 13
Training loss: 0.19371103810213328
Validation loss: 2.596785357494658

Epoch: 527| Step: 0
Training loss: 0.2560623761382303
Validation loss: 2.584850935958588

Epoch: 6| Step: 1
Training loss: 0.2111252020241475
Validation loss: 2.6079552010112406

Epoch: 6| Step: 2
Training loss: 0.10536604313240636
Validation loss: 2.54296696460285

Epoch: 6| Step: 3
Training loss: 0.12246674823512108
Validation loss: 2.578863014050892

Epoch: 6| Step: 4
Training loss: 0.20054621762865285
Validation loss: 2.5268736023817215

Epoch: 6| Step: 5
Training loss: 0.12352934360022261
Validation loss: 2.5671989962288873

Epoch: 6| Step: 6
Training loss: 0.2300262729524561
Validation loss: 2.5361174576972285

Epoch: 6| Step: 7
Training loss: 0.13705738907924783
Validation loss: 2.5512318034129384

Epoch: 6| Step: 8
Training loss: 0.15058381194161946
Validation loss: 2.5406368774448023

Epoch: 6| Step: 9
Training loss: 0.13944609194205435
Validation loss: 2.5452810765932865

Epoch: 6| Step: 10
Training loss: 0.13006621870474236
Validation loss: 2.5511186572528617

Epoch: 6| Step: 11
Training loss: 0.1673373453266349
Validation loss: 2.522218644097134

Epoch: 6| Step: 12
Training loss: 0.16573740141083312
Validation loss: 2.551823886912398

Epoch: 6| Step: 13
Training loss: 0.13733664258809222
Validation loss: 2.525079329511689

Epoch: 528| Step: 0
Training loss: 0.23832453662859682
Validation loss: 2.563993868415121

Epoch: 6| Step: 1
Training loss: 0.10548723023598562
Validation loss: 2.5604864498678057

Epoch: 6| Step: 2
Training loss: 0.2180051383541588
Validation loss: 2.592132978077281

Epoch: 6| Step: 3
Training loss: 0.149891719379484
Validation loss: 2.550767805526407

Epoch: 6| Step: 4
Training loss: 0.17976736284234118
Validation loss: 2.5267840058470643

Epoch: 6| Step: 5
Training loss: 0.24476288649959682
Validation loss: 2.5842289326509476

Epoch: 6| Step: 6
Training loss: 0.11152799132715152
Validation loss: 2.558574051144362

Epoch: 6| Step: 7
Training loss: 0.16233324196799537
Validation loss: 2.5728908034505182

Epoch: 6| Step: 8
Training loss: 0.12787229400765993
Validation loss: 2.5697828626686183

Epoch: 6| Step: 9
Training loss: 0.19844244252455057
Validation loss: 2.582065577517199

Epoch: 6| Step: 10
Training loss: 0.25044516328016525
Validation loss: 2.577403411116519

Epoch: 6| Step: 11
Training loss: 0.2513291668833255
Validation loss: 2.5421537592879124

Epoch: 6| Step: 12
Training loss: 0.2413728301979497
Validation loss: 2.5816857889344087

Epoch: 6| Step: 13
Training loss: 0.30472421424918394
Validation loss: 2.5843044589952133

Epoch: 529| Step: 0
Training loss: 0.1480676913158474
Validation loss: 2.5503571204549926

Epoch: 6| Step: 1
Training loss: 0.22860329731255294
Validation loss: 2.5292171983755396

Epoch: 6| Step: 2
Training loss: 0.2190448272803106
Validation loss: 2.5575465946654066

Epoch: 6| Step: 3
Training loss: 0.41538396529017085
Validation loss: 2.6091359612158995

Epoch: 6| Step: 4
Training loss: 0.3599310181013063
Validation loss: 2.5444307630404897

Epoch: 6| Step: 5
Training loss: 0.32654721256229347
Validation loss: 2.5644965618656563

Epoch: 6| Step: 6
Training loss: 0.12435369374377592
Validation loss: 2.5611193779627692

Epoch: 6| Step: 7
Training loss: 0.2954994508073354
Validation loss: 2.532982359395682

Epoch: 6| Step: 8
Training loss: 0.2339955835093741
Validation loss: 2.518589035334552

Epoch: 6| Step: 9
Training loss: 0.41894559704608636
Validation loss: 2.544996176445078

Epoch: 6| Step: 10
Training loss: 0.3045946860165478
Validation loss: 2.511646166679136

Epoch: 6| Step: 11
Training loss: 0.21918789426878535
Validation loss: 2.5365262943571367

Epoch: 6| Step: 12
Training loss: 0.24609334128209642
Validation loss: 2.5422144810012544

Epoch: 6| Step: 13
Training loss: 0.42262415244021156
Validation loss: 2.5328613109335985

Epoch: 530| Step: 0
Training loss: 0.3115308993889834
Validation loss: 2.5622876797406087

Epoch: 6| Step: 1
Training loss: 0.29190087565179307
Validation loss: 2.5923165300072384

Epoch: 6| Step: 2
Training loss: 0.2482843388772807
Validation loss: 2.531174325261228

Epoch: 6| Step: 3
Training loss: 0.2465872584629273
Validation loss: 2.553324372079236

Epoch: 6| Step: 4
Training loss: 0.3001879004293706
Validation loss: 2.5545587330666804

Epoch: 6| Step: 5
Training loss: 0.23911149358169162
Validation loss: 2.5534504653862715

Epoch: 6| Step: 6
Training loss: 0.3780043180839705
Validation loss: 2.5440454982252425

Epoch: 6| Step: 7
Training loss: 0.26024307028021304
Validation loss: 2.5513583096217216

Epoch: 6| Step: 8
Training loss: 0.24648230018286563
Validation loss: 2.5562658262160287

Epoch: 6| Step: 9
Training loss: 0.1805955086625903
Validation loss: 2.5883966375872345

Epoch: 6| Step: 10
Training loss: 0.23098899829766045
Validation loss: 2.571277307543071

Epoch: 6| Step: 11
Training loss: 0.4086569130035901
Validation loss: 2.5476046358243023

Epoch: 6| Step: 12
Training loss: 0.3127406981470069
Validation loss: 2.557657874774647

Epoch: 6| Step: 13
Training loss: 0.4437708688583755
Validation loss: 2.544880736290204

Epoch: 531| Step: 0
Training loss: 0.4922288846979157
Validation loss: 2.557718951832439

Epoch: 6| Step: 1
Training loss: 0.20413562727663578
Validation loss: 2.5967191901037956

Epoch: 6| Step: 2
Training loss: 0.4371528610675151
Validation loss: 2.6645439063508904

Epoch: 6| Step: 3
Training loss: 0.42667340943228943
Validation loss: 2.6793662401576444

Epoch: 6| Step: 4
Training loss: 0.2673944552933052
Validation loss: 2.6408042664831064

Epoch: 6| Step: 5
Training loss: 0.16512498932368427
Validation loss: 2.5788504098610328

Epoch: 6| Step: 6
Training loss: 0.2523003632416607
Validation loss: 2.542796115148354

Epoch: 6| Step: 7
Training loss: 0.19260572696058606
Validation loss: 2.5121737023652697

Epoch: 6| Step: 8
Training loss: 0.45782144817682013
Validation loss: 2.512771999292599

Epoch: 6| Step: 9
Training loss: 0.1582464582648037
Validation loss: 2.497938935467788

Epoch: 6| Step: 10
Training loss: 0.2643858391544093
Validation loss: 2.4653738957990896

Epoch: 6| Step: 11
Training loss: 0.4704544550188201
Validation loss: 2.504764758010705

Epoch: 6| Step: 12
Training loss: 0.39586086763018113
Validation loss: 2.5027044455292593

Epoch: 6| Step: 13
Training loss: 0.2967660101546272
Validation loss: 2.529300862414214

Epoch: 532| Step: 0
Training loss: 0.39479924532712873
Validation loss: 2.532734094655864

Epoch: 6| Step: 1
Training loss: 0.3971502040757336
Validation loss: 2.556075785483231

Epoch: 6| Step: 2
Training loss: 0.40818607714522864
Validation loss: 2.596178774110268

Epoch: 6| Step: 3
Training loss: 0.3607023026042021
Validation loss: 2.574916468124724

Epoch: 6| Step: 4
Training loss: 0.6858901335539838
Validation loss: 2.598713572896334

Epoch: 6| Step: 5
Training loss: 0.3925486121779813
Validation loss: 2.568478049815569

Epoch: 6| Step: 6
Training loss: 0.41108902722976665
Validation loss: 2.543703554278734

Epoch: 6| Step: 7
Training loss: 0.32705119951095557
Validation loss: 2.4927937351514244

Epoch: 6| Step: 8
Training loss: 0.420701089073079
Validation loss: 2.474982680128279

Epoch: 6| Step: 9
Training loss: 0.41307381686561984
Validation loss: 2.470136424237811

Epoch: 6| Step: 10
Training loss: 0.48287852678386106
Validation loss: 2.495526320554135

Epoch: 6| Step: 11
Training loss: 0.6506806606116119
Validation loss: 2.4837259848383497

Epoch: 6| Step: 12
Training loss: 0.37938306243725484
Validation loss: 2.556328955041069

Epoch: 6| Step: 13
Training loss: 0.4281713613760339
Validation loss: 2.5184589897066205

Epoch: 533| Step: 0
Training loss: 0.42169090068797754
Validation loss: 2.5708476424402784

Epoch: 6| Step: 1
Training loss: 0.3345885584143359
Validation loss: 2.6313691831241948

Epoch: 6| Step: 2
Training loss: 0.6482024628598023
Validation loss: 2.672062633435998

Epoch: 6| Step: 3
Training loss: 0.7184684865540483
Validation loss: 2.59730034560564

Epoch: 6| Step: 4
Training loss: 0.2692045083377683
Validation loss: 2.536578374149989

Epoch: 6| Step: 5
Training loss: 0.38172458283523186
Validation loss: 2.52402012758817

Epoch: 6| Step: 6
Training loss: 0.4247603820847667
Validation loss: 2.5376231344459934

Epoch: 6| Step: 7
Training loss: 0.43797953755338326
Validation loss: 2.467034629872818

Epoch: 6| Step: 8
Training loss: 0.3282073689572056
Validation loss: 2.491539676168501

Epoch: 6| Step: 9
Training loss: 0.32013370594652457
Validation loss: 2.4243293935267634

Epoch: 6| Step: 10
Training loss: 0.47704768887535653
Validation loss: 2.4394707528659376

Epoch: 6| Step: 11
Training loss: 0.2740983878184646
Validation loss: 2.4676618741679652

Epoch: 6| Step: 12
Training loss: 0.39899906153078546
Validation loss: 2.475942282294065

Epoch: 6| Step: 13
Training loss: 0.41941472855975404
Validation loss: 2.493640296322686

Epoch: 534| Step: 0
Training loss: 0.2186608132702211
Validation loss: 2.519478264801849

Epoch: 6| Step: 1
Training loss: 0.28939780557379785
Validation loss: 2.6148504674645374

Epoch: 6| Step: 2
Training loss: 0.32696875576998935
Validation loss: 2.5964335557207097

Epoch: 6| Step: 3
Training loss: 0.521820217386652
Validation loss: 2.613196955829842

Epoch: 6| Step: 4
Training loss: 0.3531562284991625
Validation loss: 2.6148007961885886

Epoch: 6| Step: 5
Training loss: 0.34358418323404943
Validation loss: 2.6009342866810297

Epoch: 6| Step: 6
Training loss: 0.372933775049386
Validation loss: 2.5809009248529415

Epoch: 6| Step: 7
Training loss: 0.3077064505751719
Validation loss: 2.5880997007848268

Epoch: 6| Step: 8
Training loss: 0.28277139312262284
Validation loss: 2.5562765440254815

Epoch: 6| Step: 9
Training loss: 0.2765861829757625
Validation loss: 2.5393022796015963

Epoch: 6| Step: 10
Training loss: 0.33372715196732244
Validation loss: 2.5324407157238786

Epoch: 6| Step: 11
Training loss: 0.2960689670185802
Validation loss: 2.5066360301949424

Epoch: 6| Step: 12
Training loss: 0.3967870299396087
Validation loss: 2.5025597337329084

Epoch: 6| Step: 13
Training loss: 0.30664004186101
Validation loss: 2.5074849009787967

Epoch: 535| Step: 0
Training loss: 0.3585552527347061
Validation loss: 2.5351428510908853

Epoch: 6| Step: 1
Training loss: 0.2807791663014531
Validation loss: 2.5951168265714792

Epoch: 6| Step: 2
Training loss: 0.22822973512143183
Validation loss: 2.608756304631474

Epoch: 6| Step: 3
Training loss: 0.3042366898727649
Validation loss: 2.6043380854804004

Epoch: 6| Step: 4
Training loss: 0.2915385112318187
Validation loss: 2.6467215088313902

Epoch: 6| Step: 5
Training loss: 0.23582010601212222
Validation loss: 2.6369946786392657

Epoch: 6| Step: 6
Training loss: 0.30511419056221617
Validation loss: 2.6200903407877743

Epoch: 6| Step: 7
Training loss: 0.190238103105489
Validation loss: 2.616820941123931

Epoch: 6| Step: 8
Training loss: 0.3433727990869032
Validation loss: 2.648999580590356

Epoch: 6| Step: 9
Training loss: 0.26164237374068444
Validation loss: 2.598139151154755

Epoch: 6| Step: 10
Training loss: 0.1846347272579377
Validation loss: 2.595807623941244

Epoch: 6| Step: 11
Training loss: 0.3050465180341651
Validation loss: 2.5863475875282904

Epoch: 6| Step: 12
Training loss: 0.2621974552615188
Validation loss: 2.529737110810951

Epoch: 6| Step: 13
Training loss: 0.21463068887850448
Validation loss: 2.528440123383768

Epoch: 536| Step: 0
Training loss: 0.17021039605690366
Validation loss: 2.548311439565566

Epoch: 6| Step: 1
Training loss: 0.15763781056919893
Validation loss: 2.5561362812818533

Epoch: 6| Step: 2
Training loss: 0.29494256458594337
Validation loss: 2.53713613075721

Epoch: 6| Step: 3
Training loss: 0.21602551815287346
Validation loss: 2.5046257610766007

Epoch: 6| Step: 4
Training loss: 0.2954168649967821
Validation loss: 2.524090718076943

Epoch: 6| Step: 5
Training loss: 0.18404622830161455
Validation loss: 2.5276542574647256

Epoch: 6| Step: 6
Training loss: 0.191383204727154
Validation loss: 2.573034625475397

Epoch: 6| Step: 7
Training loss: 0.16031536478974137
Validation loss: 2.5633283434792795

Epoch: 6| Step: 8
Training loss: 0.256391743093258
Validation loss: 2.5549234411322264

Epoch: 6| Step: 9
Training loss: 0.22882229043145494
Validation loss: 2.5473526713625594

Epoch: 6| Step: 10
Training loss: 0.15956402816444118
Validation loss: 2.5636624551574805

Epoch: 6| Step: 11
Training loss: 0.1352690815589161
Validation loss: 2.579978077529765

Epoch: 6| Step: 12
Training loss: 0.3393700027097895
Validation loss: 2.52592744830165

Epoch: 6| Step: 13
Training loss: 0.2519103021233092
Validation loss: 2.5442251722639866

Epoch: 537| Step: 0
Training loss: 0.21421787825225483
Validation loss: 2.5444656653327664

Epoch: 6| Step: 1
Training loss: 0.127827829476959
Validation loss: 2.560998898644274

Epoch: 6| Step: 2
Training loss: 0.23203570878596655
Validation loss: 2.557214449605659

Epoch: 6| Step: 3
Training loss: 0.19211754688817095
Validation loss: 2.543785912947882

Epoch: 6| Step: 4
Training loss: 0.2630386661237753
Validation loss: 2.5401867276931904

Epoch: 6| Step: 5
Training loss: 0.19517611510157484
Validation loss: 2.5148052147827937

Epoch: 6| Step: 6
Training loss: 0.22800840017306057
Validation loss: 2.537564582554478

Epoch: 6| Step: 7
Training loss: 0.22552296143394765
Validation loss: 2.5477975392095527

Epoch: 6| Step: 8
Training loss: 0.20302190365092454
Validation loss: 2.54544864717649

Epoch: 6| Step: 9
Training loss: 0.27728997636036723
Validation loss: 2.506215240054982

Epoch: 6| Step: 10
Training loss: 0.2869186546420421
Validation loss: 2.5508178975645888

Epoch: 6| Step: 11
Training loss: 0.3519398042145787
Validation loss: 2.5532132705919075

Epoch: 6| Step: 12
Training loss: 0.18625385715663742
Validation loss: 2.535573435870793

Epoch: 6| Step: 13
Training loss: 0.16059849899887757
Validation loss: 2.535706035668021

Epoch: 538| Step: 0
Training loss: 0.2925034961328479
Validation loss: 2.5747667587302954

Epoch: 6| Step: 1
Training loss: 0.20642327161222201
Validation loss: 2.5471573982675983

Epoch: 6| Step: 2
Training loss: 0.2083323458807114
Validation loss: 2.6146623042018993

Epoch: 6| Step: 3
Training loss: 0.2685482509882082
Validation loss: 2.531682824031671

Epoch: 6| Step: 4
Training loss: 0.29039420274732414
Validation loss: 2.528570772961323

Epoch: 6| Step: 5
Training loss: 0.22631393148458864
Validation loss: 2.5268555646256994

Epoch: 6| Step: 6
Training loss: 0.1510045537625115
Validation loss: 2.526814566018587

Epoch: 6| Step: 7
Training loss: 0.2628900168016492
Validation loss: 2.549084467309328

Epoch: 6| Step: 8
Training loss: 0.12311895469405675
Validation loss: 2.5254857018010877

Epoch: 6| Step: 9
Training loss: 0.24285904778156178
Validation loss: 2.514311649219114

Epoch: 6| Step: 10
Training loss: 0.16709423850883273
Validation loss: 2.491076253272799

Epoch: 6| Step: 11
Training loss: 0.20027631656012565
Validation loss: 2.5099928071764217

Epoch: 6| Step: 12
Training loss: 0.19719961213819456
Validation loss: 2.491405716116997

Epoch: 6| Step: 13
Training loss: 0.18043587166329267
Validation loss: 2.534606881148232

Epoch: 539| Step: 0
Training loss: 0.17349778622539624
Validation loss: 2.5415612906148604

Epoch: 6| Step: 1
Training loss: 0.15287437705445647
Validation loss: 2.5750649786194786

Epoch: 6| Step: 2
Training loss: 0.1613135739985011
Validation loss: 2.566580158491627

Epoch: 6| Step: 3
Training loss: 0.2412187520973669
Validation loss: 2.5870755954707225

Epoch: 6| Step: 4
Training loss: 0.1422225751687222
Validation loss: 2.5780087640885228

Epoch: 6| Step: 5
Training loss: 0.26919955423723474
Validation loss: 2.6015493637798355

Epoch: 6| Step: 6
Training loss: 0.18726437386423841
Validation loss: 2.596864257204276

Epoch: 6| Step: 7
Training loss: 0.18225069039610403
Validation loss: 2.6098324288358468

Epoch: 6| Step: 8
Training loss: 0.18853326053391475
Validation loss: 2.5695436765766715

Epoch: 6| Step: 9
Training loss: 0.22033627158623437
Validation loss: 2.595307952813064

Epoch: 6| Step: 10
Training loss: 0.20839114976347642
Validation loss: 2.573504321333722

Epoch: 6| Step: 11
Training loss: 0.19080469424815452
Validation loss: 2.5647735744128743

Epoch: 6| Step: 12
Training loss: 0.1935869476810502
Validation loss: 2.5747541170635797

Epoch: 6| Step: 13
Training loss: 0.3383061935003322
Validation loss: 2.5780826121376057

Epoch: 540| Step: 0
Training loss: 0.18806338110616255
Validation loss: 2.5812520353784025

Epoch: 6| Step: 1
Training loss: 0.30250791878226857
Validation loss: 2.550981008217449

Epoch: 6| Step: 2
Training loss: 0.25355822847344756
Validation loss: 2.5647726798080672

Epoch: 6| Step: 3
Training loss: 0.2595224604763217
Validation loss: 2.5226308430586566

Epoch: 6| Step: 4
Training loss: 0.24205255594420952
Validation loss: 2.5203091162692743

Epoch: 6| Step: 5
Training loss: 0.2614247962953055
Validation loss: 2.4772490374094644

Epoch: 6| Step: 6
Training loss: 0.1315806991058995
Validation loss: 2.509885233793353

Epoch: 6| Step: 7
Training loss: 0.16058749777876355
Validation loss: 2.44288018133749

Epoch: 6| Step: 8
Training loss: 0.1674475790488091
Validation loss: 2.464979629381678

Epoch: 6| Step: 9
Training loss: 0.13999606261080977
Validation loss: 2.4906772272029225

Epoch: 6| Step: 10
Training loss: 0.17698455725062948
Validation loss: 2.4729424125237305

Epoch: 6| Step: 11
Training loss: 0.13961449457354694
Validation loss: 2.466928910350383

Epoch: 6| Step: 12
Training loss: 0.15904282613094606
Validation loss: 2.5146456012974663

Epoch: 6| Step: 13
Training loss: 0.15707261385271729
Validation loss: 2.5218090168237803

Epoch: 541| Step: 0
Training loss: 0.21068324554321224
Validation loss: 2.548697655839702

Epoch: 6| Step: 1
Training loss: 0.1494958504117675
Validation loss: 2.52836698484915

Epoch: 6| Step: 2
Training loss: 0.2513469382594548
Validation loss: 2.539306811623103

Epoch: 6| Step: 3
Training loss: 0.1434222927841716
Validation loss: 2.527305820703695

Epoch: 6| Step: 4
Training loss: 0.13919821770817772
Validation loss: 2.527036255954915

Epoch: 6| Step: 5
Training loss: 0.16957958319119745
Validation loss: 2.51183004159345

Epoch: 6| Step: 6
Training loss: 0.15836947725515113
Validation loss: 2.539936936263921

Epoch: 6| Step: 7
Training loss: 0.229906430647648
Validation loss: 2.521591166850662

Epoch: 6| Step: 8
Training loss: 0.25337408490667346
Validation loss: 2.4931595669085818

Epoch: 6| Step: 9
Training loss: 0.16561707734106512
Validation loss: 2.5117847478164026

Epoch: 6| Step: 10
Training loss: 0.2050512750396675
Validation loss: 2.502938926271656

Epoch: 6| Step: 11
Training loss: 0.09933692941384176
Validation loss: 2.48844399376147

Epoch: 6| Step: 12
Training loss: 0.2180887343254499
Validation loss: 2.5190974107572828

Epoch: 6| Step: 13
Training loss: 0.11277727538086901
Validation loss: 2.5422951660736666

Epoch: 542| Step: 0
Training loss: 0.17211157599525345
Validation loss: 2.50687093881402

Epoch: 6| Step: 1
Training loss: 0.14147820854756668
Validation loss: 2.5198678844496296

Epoch: 6| Step: 2
Training loss: 0.19977058388079186
Validation loss: 2.527704011388514

Epoch: 6| Step: 3
Training loss: 0.1489373999894255
Validation loss: 2.4984506974678515

Epoch: 6| Step: 4
Training loss: 0.23152375803217767
Validation loss: 2.522227564208198

Epoch: 6| Step: 5
Training loss: 0.10739803049569968
Validation loss: 2.4919982551819677

Epoch: 6| Step: 6
Training loss: 0.21906622101239626
Validation loss: 2.5103984170532128

Epoch: 6| Step: 7
Training loss: 0.1127948058998471
Validation loss: 2.5257679484708944

Epoch: 6| Step: 8
Training loss: 0.18909209547830458
Validation loss: 2.4963965872795795

Epoch: 6| Step: 9
Training loss: 0.15888278864880848
Validation loss: 2.521449993401749

Epoch: 6| Step: 10
Training loss: 0.18396444637953482
Validation loss: 2.498835208224279

Epoch: 6| Step: 11
Training loss: 0.2009431223579598
Validation loss: 2.484736880502747

Epoch: 6| Step: 12
Training loss: 0.16471553444442194
Validation loss: 2.514763609903623

Epoch: 6| Step: 13
Training loss: 0.21556046321743916
Validation loss: 2.4671626950717602

Epoch: 543| Step: 0
Training loss: 0.14622033800606787
Validation loss: 2.464998892650935

Epoch: 6| Step: 1
Training loss: 0.16329241719000023
Validation loss: 2.5162710477295507

Epoch: 6| Step: 2
Training loss: 0.14612642422611
Validation loss: 2.4846705336192305

Epoch: 6| Step: 3
Training loss: 0.1783019320655278
Validation loss: 2.5052852977382725

Epoch: 6| Step: 4
Training loss: 0.1758104194174912
Validation loss: 2.523852002742424

Epoch: 6| Step: 5
Training loss: 0.1431936602942796
Validation loss: 2.5040210872046473

Epoch: 6| Step: 6
Training loss: 0.16175166269682997
Validation loss: 2.5191892487971335

Epoch: 6| Step: 7
Training loss: 0.25706094958660713
Validation loss: 2.519975688375619

Epoch: 6| Step: 8
Training loss: 0.17676818142821643
Validation loss: 2.5424675999996538

Epoch: 6| Step: 9
Training loss: 0.19453226648394498
Validation loss: 2.5294550379478626

Epoch: 6| Step: 10
Training loss: 0.09418991310240664
Validation loss: 2.5377417174108716

Epoch: 6| Step: 11
Training loss: 0.12626842577952638
Validation loss: 2.5644238751032478

Epoch: 6| Step: 12
Training loss: 0.14853120656878646
Validation loss: 2.563352674577731

Epoch: 6| Step: 13
Training loss: 0.08091816837913202
Validation loss: 2.5609928203736354

Epoch: 544| Step: 0
Training loss: 0.10779371495307419
Validation loss: 2.55538555481631

Epoch: 6| Step: 1
Training loss: 0.12218889961270356
Validation loss: 2.5365656341323675

Epoch: 6| Step: 2
Training loss: 0.18398646699724386
Validation loss: 2.577248398855573

Epoch: 6| Step: 3
Training loss: 0.26751745886736966
Validation loss: 2.5590850100450915

Epoch: 6| Step: 4
Training loss: 0.19242096537143866
Validation loss: 2.544809781080827

Epoch: 6| Step: 5
Training loss: 0.15994369544327589
Validation loss: 2.560125758215599

Epoch: 6| Step: 6
Training loss: 0.11643939442457699
Validation loss: 2.5607481570021595

Epoch: 6| Step: 7
Training loss: 0.13976339130525112
Validation loss: 2.5241497201373404

Epoch: 6| Step: 8
Training loss: 0.10948752677434599
Validation loss: 2.5352677464021434

Epoch: 6| Step: 9
Training loss: 0.21087721563666545
Validation loss: 2.533117231770716

Epoch: 6| Step: 10
Training loss: 0.17707875657244568
Validation loss: 2.5230054162546143

Epoch: 6| Step: 11
Training loss: 0.19251145259118227
Validation loss: 2.4916744572685756

Epoch: 6| Step: 12
Training loss: 0.1320586478005041
Validation loss: 2.497377906368932

Epoch: 6| Step: 13
Training loss: 0.12123919412425514
Validation loss: 2.496007037838731

Epoch: 545| Step: 0
Training loss: 0.1767034763258817
Validation loss: 2.4890999771222977

Epoch: 6| Step: 1
Training loss: 0.20019529389171978
Validation loss: 2.496801433901261

Epoch: 6| Step: 2
Training loss: 0.12359705041657507
Validation loss: 2.5027182823856395

Epoch: 6| Step: 3
Training loss: 0.1701312857478479
Validation loss: 2.495834099573303

Epoch: 6| Step: 4
Training loss: 0.13660717907628167
Validation loss: 2.4953928508745338

Epoch: 6| Step: 5
Training loss: 0.1718150435256298
Validation loss: 2.504310865865695

Epoch: 6| Step: 6
Training loss: 0.21363316975178495
Validation loss: 2.4930624469929157

Epoch: 6| Step: 7
Training loss: 0.22461712865300296
Validation loss: 2.5210783115731332

Epoch: 6| Step: 8
Training loss: 0.16187149426997963
Validation loss: 2.5410500571442896

Epoch: 6| Step: 9
Training loss: 0.1631179024442115
Validation loss: 2.508148566456883

Epoch: 6| Step: 10
Training loss: 0.1069927226286838
Validation loss: 2.5233628949545475

Epoch: 6| Step: 11
Training loss: 0.1672052396293539
Validation loss: 2.550967133665364

Epoch: 6| Step: 12
Training loss: 0.18978338851804236
Validation loss: 2.5676916400992713

Epoch: 6| Step: 13
Training loss: 0.1752002864203877
Validation loss: 2.5630677547412937

Epoch: 546| Step: 0
Training loss: 0.21130676972518445
Validation loss: 2.5748732667761094

Epoch: 6| Step: 1
Training loss: 0.23180150336314134
Validation loss: 2.5731852471253025

Epoch: 6| Step: 2
Training loss: 0.1435475120567668
Validation loss: 2.595107566252272

Epoch: 6| Step: 3
Training loss: 0.17763518615363505
Validation loss: 2.588256908088452

Epoch: 6| Step: 4
Training loss: 0.15046174361850204
Validation loss: 2.559183189381173

Epoch: 6| Step: 5
Training loss: 0.19812876646631433
Validation loss: 2.564113159203154

Epoch: 6| Step: 6
Training loss: 0.17246467590600348
Validation loss: 2.546623984626773

Epoch: 6| Step: 7
Training loss: 0.20654185049056395
Validation loss: 2.576855264960469

Epoch: 6| Step: 8
Training loss: 0.21714526184252284
Validation loss: 2.564420882015944

Epoch: 6| Step: 9
Training loss: 0.17317335703194192
Validation loss: 2.5403223629879927

Epoch: 6| Step: 10
Training loss: 0.18084272880654792
Validation loss: 2.533831769675648

Epoch: 6| Step: 11
Training loss: 0.13821804304673072
Validation loss: 2.5530618090622927

Epoch: 6| Step: 12
Training loss: 0.2058275245189197
Validation loss: 2.548960041810769

Epoch: 6| Step: 13
Training loss: 0.1486327430734961
Validation loss: 2.5481021878124532

Epoch: 547| Step: 0
Training loss: 0.22994967373917924
Validation loss: 2.519487843795803

Epoch: 6| Step: 1
Training loss: 0.21604211551695657
Validation loss: 2.547832531218591

Epoch: 6| Step: 2
Training loss: 0.12611595839822096
Validation loss: 2.5264388920282856

Epoch: 6| Step: 3
Training loss: 0.20266804280671327
Validation loss: 2.5110468049121444

Epoch: 6| Step: 4
Training loss: 0.1474094490450579
Validation loss: 2.5615781140719123

Epoch: 6| Step: 5
Training loss: 0.20973638902657882
Validation loss: 2.5465460375533073

Epoch: 6| Step: 6
Training loss: 0.15152311599905824
Validation loss: 2.5068057156719155

Epoch: 6| Step: 7
Training loss: 0.11979766930868713
Validation loss: 2.5053223161084093

Epoch: 6| Step: 8
Training loss: 0.09704298098995207
Validation loss: 2.510266458106359

Epoch: 6| Step: 9
Training loss: 0.2187226482730157
Validation loss: 2.4993212137298224

Epoch: 6| Step: 10
Training loss: 0.10573197119928507
Validation loss: 2.4816847201995276

Epoch: 6| Step: 11
Training loss: 0.193345233130358
Validation loss: 2.47407839386072

Epoch: 6| Step: 12
Training loss: 0.18040408424995058
Validation loss: 2.4720622966089723

Epoch: 6| Step: 13
Training loss: 0.17834506077248802
Validation loss: 2.48152220259342

Epoch: 548| Step: 0
Training loss: 0.1438739043073087
Validation loss: 2.492768242529186

Epoch: 6| Step: 1
Training loss: 0.13695681145380212
Validation loss: 2.501129077958431

Epoch: 6| Step: 2
Training loss: 0.20628627761495294
Validation loss: 2.4843750433400373

Epoch: 6| Step: 3
Training loss: 0.15259327383082316
Validation loss: 2.4916467174088512

Epoch: 6| Step: 4
Training loss: 0.10827227716989177
Validation loss: 2.5141523164225696

Epoch: 6| Step: 5
Training loss: 0.12075160512785353
Validation loss: 2.504248755711723

Epoch: 6| Step: 6
Training loss: 0.22285539521808906
Validation loss: 2.5174426044365754

Epoch: 6| Step: 7
Training loss: 0.12597935695653797
Validation loss: 2.530076052830868

Epoch: 6| Step: 8
Training loss: 0.1375796122798213
Validation loss: 2.5359772748653877

Epoch: 6| Step: 9
Training loss: 0.2786245189369947
Validation loss: 2.506021575669473

Epoch: 6| Step: 10
Training loss: 0.17510971436306408
Validation loss: 2.531333659643096

Epoch: 6| Step: 11
Training loss: 0.19648345886380914
Validation loss: 2.4796028577295965

Epoch: 6| Step: 12
Training loss: 0.1259426026813246
Validation loss: 2.5097192071058716

Epoch: 6| Step: 13
Training loss: 0.06267286772359006
Validation loss: 2.510644007768428

Epoch: 549| Step: 0
Training loss: 0.1380137420727969
Validation loss: 2.4876712543275046

Epoch: 6| Step: 1
Training loss: 0.16844396678740337
Validation loss: 2.5188068559049914

Epoch: 6| Step: 2
Training loss: 0.20589979053704816
Validation loss: 2.5072514691000234

Epoch: 6| Step: 3
Training loss: 0.11409706235485069
Validation loss: 2.4772863303658785

Epoch: 6| Step: 4
Training loss: 0.08871939704870022
Validation loss: 2.4890448707519797

Epoch: 6| Step: 5
Training loss: 0.16251993469694326
Validation loss: 2.5079186381625975

Epoch: 6| Step: 6
Training loss: 0.18454655489329808
Validation loss: 2.495606263337021

Epoch: 6| Step: 7
Training loss: 0.27297853370431446
Validation loss: 2.4613222882959316

Epoch: 6| Step: 8
Training loss: 0.15760712148296327
Validation loss: 2.5113326736537704

Epoch: 6| Step: 9
Training loss: 0.14497364487045092
Validation loss: 2.478249434391426

Epoch: 6| Step: 10
Training loss: 0.22137232406793173
Validation loss: 2.494368231276956

Epoch: 6| Step: 11
Training loss: 0.17704412549864776
Validation loss: 2.515121814213803

Epoch: 6| Step: 12
Training loss: 0.11414855232360925
Validation loss: 2.4788974003219377

Epoch: 6| Step: 13
Training loss: 0.09364834877379748
Validation loss: 2.501908265169453

Epoch: 550| Step: 0
Training loss: 0.14356671497018147
Validation loss: 2.473810040747142

Epoch: 6| Step: 1
Training loss: 0.16440850624380912
Validation loss: 2.5416068001617127

Epoch: 6| Step: 2
Training loss: 0.24936575455365773
Validation loss: 2.471024794016169

Epoch: 6| Step: 3
Training loss: 0.11708652596629028
Validation loss: 2.5135555173951603

Epoch: 6| Step: 4
Training loss: 0.15048760222740387
Validation loss: 2.5151582209806542

Epoch: 6| Step: 5
Training loss: 0.2010625338389825
Validation loss: 2.50654966637136

Epoch: 6| Step: 6
Training loss: 0.07902255645653027
Validation loss: 2.4956951517328054

Epoch: 6| Step: 7
Training loss: 0.17847656557246352
Validation loss: 2.511870452979866

Epoch: 6| Step: 8
Training loss: 0.13183227110109064
Validation loss: 2.4636755011589284

Epoch: 6| Step: 9
Training loss: 0.15333987068756183
Validation loss: 2.4805197273450523

Epoch: 6| Step: 10
Training loss: 0.1120406322195056
Validation loss: 2.4708302587195945

Epoch: 6| Step: 11
Training loss: 0.14241402471002895
Validation loss: 2.4682177292667427

Epoch: 6| Step: 12
Training loss: 0.1643294705405394
Validation loss: 2.4942916755125046

Epoch: 6| Step: 13
Training loss: 0.12131017525753214
Validation loss: 2.4612732798338257

Epoch: 551| Step: 0
Training loss: 0.18589683456675682
Validation loss: 2.462948327015845

Epoch: 6| Step: 1
Training loss: 0.10537197830352159
Validation loss: 2.4404939638765257

Epoch: 6| Step: 2
Training loss: 0.10415080267587266
Validation loss: 2.4497689953150736

Epoch: 6| Step: 3
Training loss: 0.11741956145087952
Validation loss: 2.4571742987114167

Epoch: 6| Step: 4
Training loss: 0.14491295671398446
Validation loss: 2.4735708190101993

Epoch: 6| Step: 5
Training loss: 0.10310447662043826
Validation loss: 2.5061039927073634

Epoch: 6| Step: 6
Training loss: 0.2139071684093836
Validation loss: 2.5084425163878845

Epoch: 6| Step: 7
Training loss: 0.13284966005052826
Validation loss: 2.5113603951267507

Epoch: 6| Step: 8
Training loss: 0.1315632437052966
Validation loss: 2.500017602920087

Epoch: 6| Step: 9
Training loss: 0.1296058512663384
Validation loss: 2.500292568110141

Epoch: 6| Step: 10
Training loss: 0.15364187378280328
Validation loss: 2.517180482472894

Epoch: 6| Step: 11
Training loss: 0.1823845263523373
Validation loss: 2.53004617751282

Epoch: 6| Step: 12
Training loss: 0.2128278132179351
Validation loss: 2.521368134415701

Epoch: 6| Step: 13
Training loss: 0.14655876178284966
Validation loss: 2.532472038232509

Epoch: 552| Step: 0
Training loss: 0.1847195702994236
Validation loss: 2.5128170120561113

Epoch: 6| Step: 1
Training loss: 0.10434740499805296
Validation loss: 2.5434428682048833

Epoch: 6| Step: 2
Training loss: 0.18318642416110695
Validation loss: 2.529666885131555

Epoch: 6| Step: 3
Training loss: 0.13337958106259734
Validation loss: 2.554134843359017

Epoch: 6| Step: 4
Training loss: 0.13857418971636026
Validation loss: 2.5587717943226043

Epoch: 6| Step: 5
Training loss: 0.14162412660965792
Validation loss: 2.533835250142597

Epoch: 6| Step: 6
Training loss: 0.10644477879101705
Validation loss: 2.5421991319222164

Epoch: 6| Step: 7
Training loss: 0.13172573145762675
Validation loss: 2.515709751448991

Epoch: 6| Step: 8
Training loss: 0.2233563175639283
Validation loss: 2.527328861155502

Epoch: 6| Step: 9
Training loss: 0.17837165979026104
Validation loss: 2.516158311673909

Epoch: 6| Step: 10
Training loss: 0.1694339895106374
Validation loss: 2.52051533429185

Epoch: 6| Step: 11
Training loss: 0.10668218574825339
Validation loss: 2.4684773537699534

Epoch: 6| Step: 12
Training loss: 0.17647693510276696
Validation loss: 2.518724348663886

Epoch: 6| Step: 13
Training loss: 0.0794658221167848
Validation loss: 2.4924079014999982

Epoch: 553| Step: 0
Training loss: 0.17184236064854957
Validation loss: 2.488367274279632

Epoch: 6| Step: 1
Training loss: 0.09357992281853199
Validation loss: 2.493393748465409

Epoch: 6| Step: 2
Training loss: 0.13247883480323602
Validation loss: 2.4992271951651723

Epoch: 6| Step: 3
Training loss: 0.20117141205077002
Validation loss: 2.4935820201771803

Epoch: 6| Step: 4
Training loss: 0.18073364155164506
Validation loss: 2.510538148210744

Epoch: 6| Step: 5
Training loss: 0.21562175333647166
Validation loss: 2.5204144571114964

Epoch: 6| Step: 6
Training loss: 0.1075645539610199
Validation loss: 2.475965830743528

Epoch: 6| Step: 7
Training loss: 0.11304540583111279
Validation loss: 2.5144881263779983

Epoch: 6| Step: 8
Training loss: 0.1103120243505322
Validation loss: 2.4764879983503203

Epoch: 6| Step: 9
Training loss: 0.15093453008482288
Validation loss: 2.465514663699432

Epoch: 6| Step: 10
Training loss: 0.1573828932912718
Validation loss: 2.5089650815553592

Epoch: 6| Step: 11
Training loss: 0.1952843836573988
Validation loss: 2.4925660092709605

Epoch: 6| Step: 12
Training loss: 0.13165513108695015
Validation loss: 2.4868752751906933

Epoch: 6| Step: 13
Training loss: 0.0966909575395872
Validation loss: 2.4919295062834936

Epoch: 554| Step: 0
Training loss: 0.12792954190078487
Validation loss: 2.4813429515650864

Epoch: 6| Step: 1
Training loss: 0.1518204762168327
Validation loss: 2.4947775056536288

Epoch: 6| Step: 2
Training loss: 0.17251592042612812
Validation loss: 2.501211643908747

Epoch: 6| Step: 3
Training loss: 0.1471986901834317
Validation loss: 2.4979021961387216

Epoch: 6| Step: 4
Training loss: 0.1540840286413614
Validation loss: 2.536086322238702

Epoch: 6| Step: 5
Training loss: 0.09170754123738813
Validation loss: 2.5088893395636718

Epoch: 6| Step: 6
Training loss: 0.17846944783507993
Validation loss: 2.5471451726322476

Epoch: 6| Step: 7
Training loss: 0.12584397635570976
Validation loss: 2.529134346538769

Epoch: 6| Step: 8
Training loss: 0.20057102396793558
Validation loss: 2.5173416527512456

Epoch: 6| Step: 9
Training loss: 0.1795088149080646
Validation loss: 2.5180376565001206

Epoch: 6| Step: 10
Training loss: 0.12899766917026628
Validation loss: 2.5290703219765254

Epoch: 6| Step: 11
Training loss: 0.15338833023007012
Validation loss: 2.5301095187667357

Epoch: 6| Step: 12
Training loss: 0.1348598261562558
Validation loss: 2.514814277402853

Epoch: 6| Step: 13
Training loss: 0.1325714293628509
Validation loss: 2.495045653471804

Epoch: 555| Step: 0
Training loss: 0.13794263987953292
Validation loss: 2.5574983410073124

Epoch: 6| Step: 1
Training loss: 0.1112939840803814
Validation loss: 2.5368284831461567

Epoch: 6| Step: 2
Training loss: 0.2145297096124902
Validation loss: 2.529075685294462

Epoch: 6| Step: 3
Training loss: 0.1609341523831535
Validation loss: 2.534659096971343

Epoch: 6| Step: 4
Training loss: 0.10378809822562052
Validation loss: 2.5688333313054303

Epoch: 6| Step: 5
Training loss: 0.2692848129382051
Validation loss: 2.553401268361831

Epoch: 6| Step: 6
Training loss: 0.13812676599072687
Validation loss: 2.546385079215012

Epoch: 6| Step: 7
Training loss: 0.11386497325281975
Validation loss: 2.5438788117414184

Epoch: 6| Step: 8
Training loss: 0.14731152019166793
Validation loss: 2.5796690701337477

Epoch: 6| Step: 9
Training loss: 0.11975758696654368
Validation loss: 2.5585310608210996

Epoch: 6| Step: 10
Training loss: 0.2213376300843054
Validation loss: 2.549285438532201

Epoch: 6| Step: 11
Training loss: 0.20093420488731847
Validation loss: 2.5605306984273337

Epoch: 6| Step: 12
Training loss: 0.10080471597319438
Validation loss: 2.52318609004951

Epoch: 6| Step: 13
Training loss: 0.1253556615742338
Validation loss: 2.5304230686654785

Epoch: 556| Step: 0
Training loss: 0.1099701933412395
Validation loss: 2.5164635484277156

Epoch: 6| Step: 1
Training loss: 0.16816030713007488
Validation loss: 2.516304251027406

Epoch: 6| Step: 2
Training loss: 0.19505352971279613
Validation loss: 2.4984074370484906

Epoch: 6| Step: 3
Training loss: 0.14682136555687175
Validation loss: 2.5001826270883423

Epoch: 6| Step: 4
Training loss: 0.13719287812894054
Validation loss: 2.511279950357027

Epoch: 6| Step: 5
Training loss: 0.24615356687153966
Validation loss: 2.5247064273384194

Epoch: 6| Step: 6
Training loss: 0.1621204510317509
Validation loss: 2.5296942617848974

Epoch: 6| Step: 7
Training loss: 0.12085149358956668
Validation loss: 2.5375832973435153

Epoch: 6| Step: 8
Training loss: 0.10091147474063207
Validation loss: 2.547622527678399

Epoch: 6| Step: 9
Training loss: 0.19462596395348164
Validation loss: 2.5261307591029687

Epoch: 6| Step: 10
Training loss: 0.1581081293552556
Validation loss: 2.5455545605663628

Epoch: 6| Step: 11
Training loss: 0.11276271133496078
Validation loss: 2.538897710837067

Epoch: 6| Step: 12
Training loss: 0.09802845120683232
Validation loss: 2.5436712846189242

Epoch: 6| Step: 13
Training loss: 0.13716894007940042
Validation loss: 2.559029522843073

Epoch: 557| Step: 0
Training loss: 0.13319764671358988
Validation loss: 2.53952972480164

Epoch: 6| Step: 1
Training loss: 0.14373906938832473
Validation loss: 2.5366130059961995

Epoch: 6| Step: 2
Training loss: 0.14440296253225834
Validation loss: 2.5560880065162084

Epoch: 6| Step: 3
Training loss: 0.1929975167736094
Validation loss: 2.552089095135317

Epoch: 6| Step: 4
Training loss: 0.16023998281373744
Validation loss: 2.534952892446579

Epoch: 6| Step: 5
Training loss: 0.13866865127469868
Validation loss: 2.5297609418600224

Epoch: 6| Step: 6
Training loss: 0.15377918143839472
Validation loss: 2.541263565167617

Epoch: 6| Step: 7
Training loss: 0.16955710864292775
Validation loss: 2.5512489352793515

Epoch: 6| Step: 8
Training loss: 0.1504237027142924
Validation loss: 2.531731558076943

Epoch: 6| Step: 9
Training loss: 0.10449815893490727
Validation loss: 2.5537976810143896

Epoch: 6| Step: 10
Training loss: 0.16060620578326296
Validation loss: 2.537978289692802

Epoch: 6| Step: 11
Training loss: 0.11394802302790807
Validation loss: 2.5451867674620487

Epoch: 6| Step: 12
Training loss: 0.16391145474267824
Validation loss: 2.535018858776657

Epoch: 6| Step: 13
Training loss: 0.21433659429155807
Validation loss: 2.524031318517115

Epoch: 558| Step: 0
Training loss: 0.10558121918703972
Validation loss: 2.542703065388119

Epoch: 6| Step: 1
Training loss: 0.09627786130151206
Validation loss: 2.5337454029876505

Epoch: 6| Step: 2
Training loss: 0.15044151411220294
Validation loss: 2.5414172964215145

Epoch: 6| Step: 3
Training loss: 0.0629442082954872
Validation loss: 2.545610194450867

Epoch: 6| Step: 4
Training loss: 0.17220544477512711
Validation loss: 2.543108939583979

Epoch: 6| Step: 5
Training loss: 0.20227993728492266
Validation loss: 2.523283737071146

Epoch: 6| Step: 6
Training loss: 0.10758476045709943
Validation loss: 2.5526016152749933

Epoch: 6| Step: 7
Training loss: 0.19080745688857706
Validation loss: 2.5232934499531914

Epoch: 6| Step: 8
Training loss: 0.11419939928087841
Validation loss: 2.5179904472907286

Epoch: 6| Step: 9
Training loss: 0.1614508812989435
Validation loss: 2.5561597518781425

Epoch: 6| Step: 10
Training loss: 0.17514255839388534
Validation loss: 2.5320763838578237

Epoch: 6| Step: 11
Training loss: 0.18232795944422112
Validation loss: 2.5451875883710713

Epoch: 6| Step: 12
Training loss: 0.1625728359122813
Validation loss: 2.5474205084647097

Epoch: 6| Step: 13
Training loss: 0.10585236543765722
Validation loss: 2.5427916236246135

Epoch: 559| Step: 0
Training loss: 0.21934187380875123
Validation loss: 2.526138323774202

Epoch: 6| Step: 1
Training loss: 0.09253430415874768
Validation loss: 2.544307486339515

Epoch: 6| Step: 2
Training loss: 0.17245504189908914
Validation loss: 2.5475815488072047

Epoch: 6| Step: 3
Training loss: 0.0916385858460116
Validation loss: 2.5260322387099885

Epoch: 6| Step: 4
Training loss: 0.10498731280351145
Validation loss: 2.5353797677419707

Epoch: 6| Step: 5
Training loss: 0.11305869372209595
Validation loss: 2.5555448187087855

Epoch: 6| Step: 6
Training loss: 0.12049107396684024
Validation loss: 2.5882786561694746

Epoch: 6| Step: 7
Training loss: 0.234617624268013
Validation loss: 2.5520687056811386

Epoch: 6| Step: 8
Training loss: 0.14169450537784073
Validation loss: 2.565926360781455

Epoch: 6| Step: 9
Training loss: 0.14134494284987378
Validation loss: 2.5572550209834395

Epoch: 6| Step: 10
Training loss: 0.12724352414631873
Validation loss: 2.5459460183514415

Epoch: 6| Step: 11
Training loss: 0.11765036565699093
Validation loss: 2.552562867635081

Epoch: 6| Step: 12
Training loss: 0.15188918398725004
Validation loss: 2.5158266498648483

Epoch: 6| Step: 13
Training loss: 0.2050727661885886
Validation loss: 2.5406069073454565

Epoch: 560| Step: 0
Training loss: 0.1449577186965174
Validation loss: 2.4983652697319214

Epoch: 6| Step: 1
Training loss: 0.11923206447481703
Validation loss: 2.497187856071443

Epoch: 6| Step: 2
Training loss: 0.08017556147481368
Validation loss: 2.5138630154557724

Epoch: 6| Step: 3
Training loss: 0.10873276471166538
Validation loss: 2.5150851082633925

Epoch: 6| Step: 4
Training loss: 0.11942243859261528
Validation loss: 2.5097714779942266

Epoch: 6| Step: 5
Training loss: 0.1907266990440185
Validation loss: 2.4856778726713107

Epoch: 6| Step: 6
Training loss: 0.22822302645652037
Validation loss: 2.511823227880813

Epoch: 6| Step: 7
Training loss: 0.07116426361244857
Validation loss: 2.5056441889437346

Epoch: 6| Step: 8
Training loss: 0.12603436112577948
Validation loss: 2.5256143025541244

Epoch: 6| Step: 9
Training loss: 0.12496615860725963
Validation loss: 2.4774728022491934

Epoch: 6| Step: 10
Training loss: 0.11190382276495021
Validation loss: 2.5226456254861076

Epoch: 6| Step: 11
Training loss: 0.16233845117419113
Validation loss: 2.4936952893194553

Epoch: 6| Step: 12
Training loss: 0.1512088562830297
Validation loss: 2.507871656563813

Epoch: 6| Step: 13
Training loss: 0.0686100960015777
Validation loss: 2.5414548204299128

Epoch: 561| Step: 0
Training loss: 0.18362177979792363
Validation loss: 2.5343162820841245

Epoch: 6| Step: 1
Training loss: 0.1957425532721073
Validation loss: 2.566534768135314

Epoch: 6| Step: 2
Training loss: 0.12556530855701514
Validation loss: 2.529024306045545

Epoch: 6| Step: 3
Training loss: 0.19951410464868838
Validation loss: 2.4964823863450993

Epoch: 6| Step: 4
Training loss: 0.10273676387199643
Validation loss: 2.519126477629043

Epoch: 6| Step: 5
Training loss: 0.08898988051124673
Validation loss: 2.5195986711454945

Epoch: 6| Step: 6
Training loss: 0.15252322238046626
Validation loss: 2.523957333347809

Epoch: 6| Step: 7
Training loss: 0.1589473714106857
Validation loss: 2.525824175496671

Epoch: 6| Step: 8
Training loss: 0.10991499637318472
Validation loss: 2.5248634106496826

Epoch: 6| Step: 9
Training loss: 0.16543898573216573
Validation loss: 2.5520860900930984

Epoch: 6| Step: 10
Training loss: 0.19493970579187855
Validation loss: 2.5297270102131

Epoch: 6| Step: 11
Training loss: 0.18884126432046383
Validation loss: 2.5444180588136973

Epoch: 6| Step: 12
Training loss: 0.10110208799772276
Validation loss: 2.5318822583814966

Epoch: 6| Step: 13
Training loss: 0.07909561652924291
Validation loss: 2.4976806423475453

Epoch: 562| Step: 0
Training loss: 0.12141613960489898
Validation loss: 2.5188962659782326

Epoch: 6| Step: 1
Training loss: 0.18543888764333108
Validation loss: 2.521449158664072

Epoch: 6| Step: 2
Training loss: 0.1326761527570793
Validation loss: 2.521530383140607

Epoch: 6| Step: 3
Training loss: 0.12337073213433505
Validation loss: 2.542536927385175

Epoch: 6| Step: 4
Training loss: 0.12852956180312464
Validation loss: 2.5389205057402626

Epoch: 6| Step: 5
Training loss: 0.14825521117888885
Validation loss: 2.529615138859958

Epoch: 6| Step: 6
Training loss: 0.09657111959657877
Validation loss: 2.5628268605922955

Epoch: 6| Step: 7
Training loss: 0.2335255647740887
Validation loss: 2.5516945303978074

Epoch: 6| Step: 8
Training loss: 0.08999602743659893
Validation loss: 2.558389728236281

Epoch: 6| Step: 9
Training loss: 0.20013303951195902
Validation loss: 2.534455328301639

Epoch: 6| Step: 10
Training loss: 0.12179946224383835
Validation loss: 2.527047429469133

Epoch: 6| Step: 11
Training loss: 0.15147753969129435
Validation loss: 2.5485305161655023

Epoch: 6| Step: 12
Training loss: 0.2317204992237291
Validation loss: 2.5131784612276244

Epoch: 6| Step: 13
Training loss: 0.14374978568226968
Validation loss: 2.5490036116918464

Epoch: 563| Step: 0
Training loss: 0.10014245496182855
Validation loss: 2.5443379488853224

Epoch: 6| Step: 1
Training loss: 0.12784937893138917
Validation loss: 2.5304362251021075

Epoch: 6| Step: 2
Training loss: 0.09868709090488094
Validation loss: 2.5188534615357576

Epoch: 6| Step: 3
Training loss: 0.12370186514994064
Validation loss: 2.493587395312066

Epoch: 6| Step: 4
Training loss: 0.16908456873391497
Validation loss: 2.484534401609521

Epoch: 6| Step: 5
Training loss: 0.17921058972113468
Validation loss: 2.518627104044377

Epoch: 6| Step: 6
Training loss: 0.23302383367772264
Validation loss: 2.5292448069425535

Epoch: 6| Step: 7
Training loss: 0.10841664170002974
Validation loss: 2.5042280939574617

Epoch: 6| Step: 8
Training loss: 0.13842139658472233
Validation loss: 2.4982522248941796

Epoch: 6| Step: 9
Training loss: 0.1317865349784282
Validation loss: 2.505516565583379

Epoch: 6| Step: 10
Training loss: 0.08111898905059546
Validation loss: 2.4853261374372546

Epoch: 6| Step: 11
Training loss: 0.09526017894822972
Validation loss: 2.520463399880434

Epoch: 6| Step: 12
Training loss: 0.1599967790629614
Validation loss: 2.495453025092161

Epoch: 6| Step: 13
Training loss: 0.22507351727256264
Validation loss: 2.495144556909761

Epoch: 564| Step: 0
Training loss: 0.18817127783342516
Validation loss: 2.490903361196642

Epoch: 6| Step: 1
Training loss: 0.1606861918498903
Validation loss: 2.48203033521926

Epoch: 6| Step: 2
Training loss: 0.12191678119623842
Validation loss: 2.4826800502565365

Epoch: 6| Step: 3
Training loss: 0.13172296699434555
Validation loss: 2.4787725450898916

Epoch: 6| Step: 4
Training loss: 0.10739692918524853
Validation loss: 2.491615764995042

Epoch: 6| Step: 5
Training loss: 0.17315021942313685
Validation loss: 2.48357691670339

Epoch: 6| Step: 6
Training loss: 0.1793474836544115
Validation loss: 2.475250035596831

Epoch: 6| Step: 7
Training loss: 0.2085920019469435
Validation loss: 2.467879401840644

Epoch: 6| Step: 8
Training loss: 0.11827642048584668
Validation loss: 2.4692861884143325

Epoch: 6| Step: 9
Training loss: 0.11153155696460042
Validation loss: 2.500318472071275

Epoch: 6| Step: 10
Training loss: 0.12481602153146336
Validation loss: 2.51887516154625

Epoch: 6| Step: 11
Training loss: 0.17023265852638333
Validation loss: 2.479452508010996

Epoch: 6| Step: 12
Training loss: 0.12530154126782314
Validation loss: 2.479719680596031

Epoch: 6| Step: 13
Training loss: 0.10452065570242264
Validation loss: 2.478921497769495

Epoch: 565| Step: 0
Training loss: 0.21742841305704805
Validation loss: 2.4646598690514527

Epoch: 6| Step: 1
Training loss: 0.06986814730971469
Validation loss: 2.479275514304256

Epoch: 6| Step: 2
Training loss: 0.18767983038301012
Validation loss: 2.4844908637938747

Epoch: 6| Step: 3
Training loss: 0.22755845441577416
Validation loss: 2.47591546787213

Epoch: 6| Step: 4
Training loss: 0.08519790750405469
Validation loss: 2.4511497774702224

Epoch: 6| Step: 5
Training loss: 0.13371834661142545
Validation loss: 2.4685087136691193

Epoch: 6| Step: 6
Training loss: 0.09511043007598993
Validation loss: 2.503134812980052

Epoch: 6| Step: 7
Training loss: 0.1549469676643182
Validation loss: 2.5137246766301313

Epoch: 6| Step: 8
Training loss: 0.1215567275223715
Validation loss: 2.5098276892821003

Epoch: 6| Step: 9
Training loss: 0.15460839392190304
Validation loss: 2.5605519751497057

Epoch: 6| Step: 10
Training loss: 0.09790926581509954
Validation loss: 2.519243539579069

Epoch: 6| Step: 11
Training loss: 0.09823423053833376
Validation loss: 2.5372902212088504

Epoch: 6| Step: 12
Training loss: 0.1529462162308153
Validation loss: 2.5452927471455946

Epoch: 6| Step: 13
Training loss: 0.10645509814857188
Validation loss: 2.516645525785317

Epoch: 566| Step: 0
Training loss: 0.17875227945048114
Validation loss: 2.541596047724719

Epoch: 6| Step: 1
Training loss: 0.10516495573671783
Validation loss: 2.514690601932428

Epoch: 6| Step: 2
Training loss: 0.17531062279000487
Validation loss: 2.5217173036749894

Epoch: 6| Step: 3
Training loss: 0.12195311833466554
Validation loss: 2.547199241965222

Epoch: 6| Step: 4
Training loss: 0.13863290319711186
Validation loss: 2.530688295539435

Epoch: 6| Step: 5
Training loss: 0.15652865953066858
Validation loss: 2.566372806360321

Epoch: 6| Step: 6
Training loss: 0.12436400983167871
Validation loss: 2.547289246611972

Epoch: 6| Step: 7
Training loss: 0.1164193248446442
Validation loss: 2.5214057224382946

Epoch: 6| Step: 8
Training loss: 0.21051193506504698
Validation loss: 2.514688565039277

Epoch: 6| Step: 9
Training loss: 0.1472963210071502
Validation loss: 2.539577590529543

Epoch: 6| Step: 10
Training loss: 0.1759228083386469
Validation loss: 2.525962132296096

Epoch: 6| Step: 11
Training loss: 0.1035654290066522
Validation loss: 2.554247373141507

Epoch: 6| Step: 12
Training loss: 0.1855890226177962
Validation loss: 2.5275116004887392

Epoch: 6| Step: 13
Training loss: 0.19270678897616877
Validation loss: 2.5388046565365774

Epoch: 567| Step: 0
Training loss: 0.09585727713449281
Validation loss: 2.54048975810956

Epoch: 6| Step: 1
Training loss: 0.12636131113766497
Validation loss: 2.5295772284195994

Epoch: 6| Step: 2
Training loss: 0.08992700761817411
Validation loss: 2.5542618330824194

Epoch: 6| Step: 3
Training loss: 0.10993335608338169
Validation loss: 2.5337611009978764

Epoch: 6| Step: 4
Training loss: 0.12189500427521051
Validation loss: 2.543974796845706

Epoch: 6| Step: 5
Training loss: 0.08599770940163545
Validation loss: 2.544748091960027

Epoch: 6| Step: 6
Training loss: 0.1363627225920196
Validation loss: 2.558487230087675

Epoch: 6| Step: 7
Training loss: 0.17951368134726606
Validation loss: 2.547866814388695

Epoch: 6| Step: 8
Training loss: 0.17611777094380668
Validation loss: 2.5277280745889223

Epoch: 6| Step: 9
Training loss: 0.1580813728240947
Validation loss: 2.532085227730776

Epoch: 6| Step: 10
Training loss: 0.2234011787290392
Validation loss: 2.5220069895544004

Epoch: 6| Step: 11
Training loss: 0.09677480584597889
Validation loss: 2.5288947473667283

Epoch: 6| Step: 12
Training loss: 0.19526380885682926
Validation loss: 2.490480757992529

Epoch: 6| Step: 13
Training loss: 0.10404270863129024
Validation loss: 2.5333635729402757

Epoch: 568| Step: 0
Training loss: 0.17501129428997753
Validation loss: 2.5441142896078803

Epoch: 6| Step: 1
Training loss: 0.12485693403628453
Validation loss: 2.5301425409676637

Epoch: 6| Step: 2
Training loss: 0.16618713047033848
Validation loss: 2.572998276412168

Epoch: 6| Step: 3
Training loss: 0.13416550573839894
Validation loss: 2.569755369392342

Epoch: 6| Step: 4
Training loss: 0.17582958404632618
Validation loss: 2.55765719318393

Epoch: 6| Step: 5
Training loss: 0.13083969509118018
Validation loss: 2.553169927431318

Epoch: 6| Step: 6
Training loss: 0.17715220421063896
Validation loss: 2.5735745093224747

Epoch: 6| Step: 7
Training loss: 0.12803683271240715
Validation loss: 2.5649531037880755

Epoch: 6| Step: 8
Training loss: 0.2528326813242642
Validation loss: 2.553257150945543

Epoch: 6| Step: 9
Training loss: 0.12156482176414454
Validation loss: 2.575154622572125

Epoch: 6| Step: 10
Training loss: 0.11326095793932787
Validation loss: 2.5204523243201957

Epoch: 6| Step: 11
Training loss: 0.11982460363896741
Validation loss: 2.5022967320041944

Epoch: 6| Step: 12
Training loss: 0.13090697888744884
Validation loss: 2.5373255692908865

Epoch: 6| Step: 13
Training loss: 0.07144486046528671
Validation loss: 2.5150032434308236

Epoch: 569| Step: 0
Training loss: 0.1273049833815754
Validation loss: 2.499273446857243

Epoch: 6| Step: 1
Training loss: 0.15788717863539287
Validation loss: 2.541204246712509

Epoch: 6| Step: 2
Training loss: 0.134524357482912
Validation loss: 2.508549397431166

Epoch: 6| Step: 3
Training loss: 0.18347341570918016
Validation loss: 2.513325074439527

Epoch: 6| Step: 4
Training loss: 0.19454138166401697
Validation loss: 2.5107581712608846

Epoch: 6| Step: 5
Training loss: 0.15344443429866797
Validation loss: 2.5063169030338113

Epoch: 6| Step: 6
Training loss: 0.14050009929281845
Validation loss: 2.536120837985687

Epoch: 6| Step: 7
Training loss: 0.14368104239584087
Validation loss: 2.5225013259404023

Epoch: 6| Step: 8
Training loss: 0.0852701763695049
Validation loss: 2.5178332278985245

Epoch: 6| Step: 9
Training loss: 0.1165023883551228
Validation loss: 2.492897909933012

Epoch: 6| Step: 10
Training loss: 0.11700300555133558
Validation loss: 2.5336327741211693

Epoch: 6| Step: 11
Training loss: 0.1014383134494937
Validation loss: 2.527255464504117

Epoch: 6| Step: 12
Training loss: 0.1778440765708991
Validation loss: 2.496751026946303

Epoch: 6| Step: 13
Training loss: 0.13251744481624986
Validation loss: 2.503569597692282

Epoch: 570| Step: 0
Training loss: 0.09199931771087579
Validation loss: 2.5192041913448797

Epoch: 6| Step: 1
Training loss: 0.08750843290581252
Validation loss: 2.5233390888223193

Epoch: 6| Step: 2
Training loss: 0.11774140423685107
Validation loss: 2.5352744647481007

Epoch: 6| Step: 3
Training loss: 0.16416073310564616
Validation loss: 2.5263519357047537

Epoch: 6| Step: 4
Training loss: 0.18324237028985796
Validation loss: 2.546273491200977

Epoch: 6| Step: 5
Training loss: 0.1562672009536892
Validation loss: 2.50289845261978

Epoch: 6| Step: 6
Training loss: 0.129715927007381
Validation loss: 2.5333687551377335

Epoch: 6| Step: 7
Training loss: 0.14029545051708883
Validation loss: 2.505005629484061

Epoch: 6| Step: 8
Training loss: 0.20863800222359144
Validation loss: 2.524608124521238

Epoch: 6| Step: 9
Training loss: 0.1163125635617865
Validation loss: 2.524065831525167

Epoch: 6| Step: 10
Training loss: 0.16386100339075854
Validation loss: 2.5172457586235506

Epoch: 6| Step: 11
Training loss: 0.19205132599094538
Validation loss: 2.505204814459604

Epoch: 6| Step: 12
Training loss: 0.09353747717255412
Validation loss: 2.558968834968025

Epoch: 6| Step: 13
Training loss: 0.11237536984150485
Validation loss: 2.5157189672345592

Epoch: 571| Step: 0
Training loss: 0.08952642981217823
Validation loss: 2.5725791251067838

Epoch: 6| Step: 1
Training loss: 0.15034987157563084
Validation loss: 2.5530516335530047

Epoch: 6| Step: 2
Training loss: 0.1210561047766785
Validation loss: 2.56457819231196

Epoch: 6| Step: 3
Training loss: 0.14955376345961713
Validation loss: 2.5278164419533007

Epoch: 6| Step: 4
Training loss: 0.15284504697908838
Validation loss: 2.5283026374223128

Epoch: 6| Step: 5
Training loss: 0.12274699529283907
Validation loss: 2.500203847265312

Epoch: 6| Step: 6
Training loss: 0.24685615938459612
Validation loss: 2.5145240014574646

Epoch: 6| Step: 7
Training loss: 0.1391186166971491
Validation loss: 2.4832027974837367

Epoch: 6| Step: 8
Training loss: 0.10015913773180947
Validation loss: 2.4983108433507715

Epoch: 6| Step: 9
Training loss: 0.1510213839680576
Validation loss: 2.5092759139295375

Epoch: 6| Step: 10
Training loss: 0.14137372728301068
Validation loss: 2.487267289654619

Epoch: 6| Step: 11
Training loss: 0.16439645701501054
Validation loss: 2.4845873127417915

Epoch: 6| Step: 12
Training loss: 0.07748068718846972
Validation loss: 2.488458566157193

Epoch: 6| Step: 13
Training loss: 0.249633915908147
Validation loss: 2.5001374555557008

Epoch: 572| Step: 0
Training loss: 0.10364394511686573
Validation loss: 2.513645923030289

Epoch: 6| Step: 1
Training loss: 0.10800219619524669
Validation loss: 2.550873672933359

Epoch: 6| Step: 2
Training loss: 0.13585038298495675
Validation loss: 2.5580352426627186

Epoch: 6| Step: 3
Training loss: 0.12327577100116975
Validation loss: 2.5660031751434764

Epoch: 6| Step: 4
Training loss: 0.11300269770988887
Validation loss: 2.5535697156184036

Epoch: 6| Step: 5
Training loss: 0.2045425323918197
Validation loss: 2.5711913222374436

Epoch: 6| Step: 6
Training loss: 0.12707652183815085
Validation loss: 2.5523896231733496

Epoch: 6| Step: 7
Training loss: 0.17991448660955459
Validation loss: 2.5364705653334805

Epoch: 6| Step: 8
Training loss: 0.11444942188456486
Validation loss: 2.549741123658443

Epoch: 6| Step: 9
Training loss: 0.1939098248855367
Validation loss: 2.5729313109706298

Epoch: 6| Step: 10
Training loss: 0.1280606451305143
Validation loss: 2.5456407964966625

Epoch: 6| Step: 11
Training loss: 0.08893368926097396
Validation loss: 2.541062191542837

Epoch: 6| Step: 12
Training loss: 0.12766504943757506
Validation loss: 2.5145280867235726

Epoch: 6| Step: 13
Training loss: 0.23082691584082993
Validation loss: 2.5448218809299785

Epoch: 573| Step: 0
Training loss: 0.13115513529473113
Validation loss: 2.5222990052722922

Epoch: 6| Step: 1
Training loss: 0.11111866336312551
Validation loss: 2.5048557439547

Epoch: 6| Step: 2
Training loss: 0.12670949153026892
Validation loss: 2.5509140878817456

Epoch: 6| Step: 3
Training loss: 0.11960202129090877
Validation loss: 2.5637533382730164

Epoch: 6| Step: 4
Training loss: 0.1728537661740624
Validation loss: 2.498924090509504

Epoch: 6| Step: 5
Training loss: 0.1927416983064736
Validation loss: 2.5039710418712384

Epoch: 6| Step: 6
Training loss: 0.16701266514556054
Validation loss: 2.494480688272784

Epoch: 6| Step: 7
Training loss: 0.22863494170771603
Validation loss: 2.5043265160056625

Epoch: 6| Step: 8
Training loss: 0.19309717761860856
Validation loss: 2.546723238018646

Epoch: 6| Step: 9
Training loss: 0.18204426780289407
Validation loss: 2.4957625501414724

Epoch: 6| Step: 10
Training loss: 0.229247461872756
Validation loss: 2.494614139186629

Epoch: 6| Step: 11
Training loss: 0.15362844058910496
Validation loss: 2.520200042090323

Epoch: 6| Step: 12
Training loss: 0.17978831241288584
Validation loss: 2.502876380555456

Epoch: 6| Step: 13
Training loss: 0.21591503774516072
Validation loss: 2.5395291776557016

Epoch: 574| Step: 0
Training loss: 0.16828709752470272
Validation loss: 2.5390556907089215

Epoch: 6| Step: 1
Training loss: 0.1378476267658429
Validation loss: 2.5271684155602876

Epoch: 6| Step: 2
Training loss: 0.15682621447114053
Validation loss: 2.52020673321187

Epoch: 6| Step: 3
Training loss: 0.1501549943202585
Validation loss: 2.520116270979888

Epoch: 6| Step: 4
Training loss: 0.12290467643918636
Validation loss: 2.536922693222843

Epoch: 6| Step: 5
Training loss: 0.12140927431274663
Validation loss: 2.5215323840059556

Epoch: 6| Step: 6
Training loss: 0.2056977765162731
Validation loss: 2.523988828679286

Epoch: 6| Step: 7
Training loss: 0.22498707734191248
Validation loss: 2.538188466471667

Epoch: 6| Step: 8
Training loss: 0.22463382090346612
Validation loss: 2.5784485425939865

Epoch: 6| Step: 9
Training loss: 0.10921043123509529
Validation loss: 2.582835522287342

Epoch: 6| Step: 10
Training loss: 0.209210941462419
Validation loss: 2.5890089298190095

Epoch: 6| Step: 11
Training loss: 0.08493858350254979
Validation loss: 2.5784069375721645

Epoch: 6| Step: 12
Training loss: 0.1266998405317795
Validation loss: 2.5588013663148836

Epoch: 6| Step: 13
Training loss: 0.1093458877715909
Validation loss: 2.5883764781789202

Epoch: 575| Step: 0
Training loss: 0.18460139260164565
Validation loss: 2.56666823898361

Epoch: 6| Step: 1
Training loss: 0.18587885821454983
Validation loss: 2.57339819795017

Epoch: 6| Step: 2
Training loss: 0.12025286989569361
Validation loss: 2.552017486975126

Epoch: 6| Step: 3
Training loss: 0.2515209839012925
Validation loss: 2.562162708741426

Epoch: 6| Step: 4
Training loss: 0.1377813800721172
Validation loss: 2.570482813103532

Epoch: 6| Step: 5
Training loss: 0.18013864356738055
Validation loss: 2.545894222324553

Epoch: 6| Step: 6
Training loss: 0.11114792293671598
Validation loss: 2.5364114733819583

Epoch: 6| Step: 7
Training loss: 0.19754757890528363
Validation loss: 2.541802450258494

Epoch: 6| Step: 8
Training loss: 0.1138344076290875
Validation loss: 2.5159522656235254

Epoch: 6| Step: 9
Training loss: 0.1309136235538852
Validation loss: 2.5060522642258993

Epoch: 6| Step: 10
Training loss: 0.2383726757568365
Validation loss: 2.5085225033509944

Epoch: 6| Step: 11
Training loss: 0.14329728905149303
Validation loss: 2.512192856323225

Epoch: 6| Step: 12
Training loss: 0.13472140319183082
Validation loss: 2.5018678096836693

Epoch: 6| Step: 13
Training loss: 0.09748230224089648
Validation loss: 2.493597386303291

Epoch: 576| Step: 0
Training loss: 0.28742729801952493
Validation loss: 2.482346074440022

Epoch: 6| Step: 1
Training loss: 0.2019766847308136
Validation loss: 2.4911651700383866

Epoch: 6| Step: 2
Training loss: 0.2165075037704236
Validation loss: 2.4700415812551118

Epoch: 6| Step: 3
Training loss: 0.13041287013576974
Validation loss: 2.4833360500063435

Epoch: 6| Step: 4
Training loss: 0.1454713570927634
Validation loss: 2.472459346264858

Epoch: 6| Step: 5
Training loss: 0.133623368621731
Validation loss: 2.5047227865110195

Epoch: 6| Step: 6
Training loss: 0.1405249080486638
Validation loss: 2.4910470664680666

Epoch: 6| Step: 7
Training loss: 0.13427726052021569
Validation loss: 2.5250033434319086

Epoch: 6| Step: 8
Training loss: 0.13574252368693263
Validation loss: 2.5634352315216486

Epoch: 6| Step: 9
Training loss: 0.09250334524214336
Validation loss: 2.5333562443781483

Epoch: 6| Step: 10
Training loss: 0.1153546287756899
Validation loss: 2.544176811553079

Epoch: 6| Step: 11
Training loss: 0.18282532687711556
Validation loss: 2.556145406978583

Epoch: 6| Step: 12
Training loss: 0.26268076235952303
Validation loss: 2.5505419623001435

Epoch: 6| Step: 13
Training loss: 0.31039336146913415
Validation loss: 2.5893674995457667

Epoch: 577| Step: 0
Training loss: 0.18830779034979317
Validation loss: 2.6154528606263767

Epoch: 6| Step: 1
Training loss: 0.12671771598234116
Validation loss: 2.5807794821171335

Epoch: 6| Step: 2
Training loss: 0.33545235045191396
Validation loss: 2.591560827125944

Epoch: 6| Step: 3
Training loss: 0.15360174044783134
Validation loss: 2.5593892376103904

Epoch: 6| Step: 4
Training loss: 0.25162431419495135
Validation loss: 2.5446148226284393

Epoch: 6| Step: 5
Training loss: 0.15037870979172385
Validation loss: 2.5375576308356935

Epoch: 6| Step: 6
Training loss: 0.20255059859585928
Validation loss: 2.5427785996732077

Epoch: 6| Step: 7
Training loss: 0.17237033775517033
Validation loss: 2.5166019623363844

Epoch: 6| Step: 8
Training loss: 0.13180735242857325
Validation loss: 2.5208085151358484

Epoch: 6| Step: 9
Training loss: 0.35045094135700616
Validation loss: 2.532938808202169

Epoch: 6| Step: 10
Training loss: 0.17889655224365533
Validation loss: 2.491302679824252

Epoch: 6| Step: 11
Training loss: 0.1903068733323139
Validation loss: 2.54312692657517

Epoch: 6| Step: 12
Training loss: 0.21218590067231236
Validation loss: 2.553356854585254

Epoch: 6| Step: 13
Training loss: 0.15738515378261972
Validation loss: 2.566418514739657

Epoch: 578| Step: 0
Training loss: 0.19174262093292688
Validation loss: 2.5195691447275146

Epoch: 6| Step: 1
Training loss: 0.2367517914074854
Validation loss: 2.533607862404133

Epoch: 6| Step: 2
Training loss: 0.25384103964664534
Validation loss: 2.5604702038279483

Epoch: 6| Step: 3
Training loss: 0.24792912459260738
Validation loss: 2.5277997182018366

Epoch: 6| Step: 4
Training loss: 0.13035920621131047
Validation loss: 2.5465301596286354

Epoch: 6| Step: 5
Training loss: 0.25878454240414256
Validation loss: 2.5505198585177213

Epoch: 6| Step: 6
Training loss: 0.17065041118776825
Validation loss: 2.550231694491592

Epoch: 6| Step: 7
Training loss: 0.20543716427213035
Validation loss: 2.53565998344836

Epoch: 6| Step: 8
Training loss: 0.21299375433450976
Validation loss: 2.540033419543194

Epoch: 6| Step: 9
Training loss: 0.27221411459931316
Validation loss: 2.548777005123771

Epoch: 6| Step: 10
Training loss: 0.14402548473735458
Validation loss: 2.587248082416411

Epoch: 6| Step: 11
Training loss: 0.18297742308364626
Validation loss: 2.5733732462981016

Epoch: 6| Step: 12
Training loss: 0.10841507826910178
Validation loss: 2.534071070995574

Epoch: 6| Step: 13
Training loss: 0.15006614955005634
Validation loss: 2.583046075156925

Epoch: 579| Step: 0
Training loss: 0.16136343087057797
Validation loss: 2.5468644650823524

Epoch: 6| Step: 1
Training loss: 0.259245329926087
Validation loss: 2.537433436246235

Epoch: 6| Step: 2
Training loss: 0.15553125533919646
Validation loss: 2.5742199789288893

Epoch: 6| Step: 3
Training loss: 0.22314782004572623
Validation loss: 2.544014178643315

Epoch: 6| Step: 4
Training loss: 0.17994239599000636
Validation loss: 2.5541849145302846

Epoch: 6| Step: 5
Training loss: 0.19866778348129047
Validation loss: 2.545098589211602

Epoch: 6| Step: 6
Training loss: 0.13801201456314702
Validation loss: 2.5132319270809425

Epoch: 6| Step: 7
Training loss: 0.16218599553963148
Validation loss: 2.550823638271852

Epoch: 6| Step: 8
Training loss: 0.12379901585960011
Validation loss: 2.509212528490407

Epoch: 6| Step: 9
Training loss: 0.10002834897987378
Validation loss: 2.485276079263554

Epoch: 6| Step: 10
Training loss: 0.11454689510352047
Validation loss: 2.515235623615865

Epoch: 6| Step: 11
Training loss: 0.22267107328629684
Validation loss: 2.52362637905243

Epoch: 6| Step: 12
Training loss: 0.137871609097939
Validation loss: 2.514809274106638

Epoch: 6| Step: 13
Training loss: 0.24619083911387069
Validation loss: 2.5312284739359003

Epoch: 580| Step: 0
Training loss: 0.2014370993936587
Validation loss: 2.527684664109046

Epoch: 6| Step: 1
Training loss: 0.15205962021260974
Validation loss: 2.5059632961466494

Epoch: 6| Step: 2
Training loss: 0.1729826026372947
Validation loss: 2.5367945333532576

Epoch: 6| Step: 3
Training loss: 0.1452369921891173
Validation loss: 2.5483674931229734

Epoch: 6| Step: 4
Training loss: 0.22727806446733573
Validation loss: 2.5326452062508924

Epoch: 6| Step: 5
Training loss: 0.1417774817706092
Validation loss: 2.5508148246929534

Epoch: 6| Step: 6
Training loss: 0.101985883382797
Validation loss: 2.568448724981802

Epoch: 6| Step: 7
Training loss: 0.20360143430353111
Validation loss: 2.522590259534939

Epoch: 6| Step: 8
Training loss: 0.13531748795511275
Validation loss: 2.5401724147084295

Epoch: 6| Step: 9
Training loss: 0.15321646046313742
Validation loss: 2.5451346467514337

Epoch: 6| Step: 10
Training loss: 0.21430623699158044
Validation loss: 2.5344006836267523

Epoch: 6| Step: 11
Training loss: 0.12648306166760478
Validation loss: 2.522097843415527

Epoch: 6| Step: 12
Training loss: 0.113948603325246
Validation loss: 2.5183306954360676

Epoch: 6| Step: 13
Training loss: 0.14589204557171914
Validation loss: 2.52189306538923

Epoch: 581| Step: 0
Training loss: 0.1415504692241157
Validation loss: 2.533447078799651

Epoch: 6| Step: 1
Training loss: 0.0944833533662522
Validation loss: 2.5314938888427916

Epoch: 6| Step: 2
Training loss: 0.22294292065099702
Validation loss: 2.5374585943048027

Epoch: 6| Step: 3
Training loss: 0.12026224061932816
Validation loss: 2.529392909728576

Epoch: 6| Step: 4
Training loss: 0.18845968220281661
Validation loss: 2.545249418679091

Epoch: 6| Step: 5
Training loss: 0.17666640473592282
Validation loss: 2.5331793243094407

Epoch: 6| Step: 6
Training loss: 0.15726915220994397
Validation loss: 2.5391819574795793

Epoch: 6| Step: 7
Training loss: 0.08832948841596111
Validation loss: 2.5024412643628664

Epoch: 6| Step: 8
Training loss: 0.12540868171617564
Validation loss: 2.557327462399803

Epoch: 6| Step: 9
Training loss: 0.10523430941097535
Validation loss: 2.5501789701786333

Epoch: 6| Step: 10
Training loss: 0.12329074368588512
Validation loss: 2.5363264595157253

Epoch: 6| Step: 11
Training loss: 0.2515684192269097
Validation loss: 2.529669048803953

Epoch: 6| Step: 12
Training loss: 0.17707038345857246
Validation loss: 2.5499345907958566

Epoch: 6| Step: 13
Training loss: 0.09414053576611607
Validation loss: 2.5614731734964207

Epoch: 582| Step: 0
Training loss: 0.11006106904435642
Validation loss: 2.534235867495956

Epoch: 6| Step: 1
Training loss: 0.13604267398082553
Validation loss: 2.541539584579828

Epoch: 6| Step: 2
Training loss: 0.19945874437484107
Validation loss: 2.504312399354428

Epoch: 6| Step: 3
Training loss: 0.13317675287501343
Validation loss: 2.4929947627207416

Epoch: 6| Step: 4
Training loss: 0.24960649336463378
Validation loss: 2.4945592239968666

Epoch: 6| Step: 5
Training loss: 0.12672819605661592
Validation loss: 2.512585791735932

Epoch: 6| Step: 6
Training loss: 0.20727198477778713
Validation loss: 2.5094970161013204

Epoch: 6| Step: 7
Training loss: 0.11202545281365311
Validation loss: 2.5217522499142437

Epoch: 6| Step: 8
Training loss: 0.20832848344561872
Validation loss: 2.5534501170014594

Epoch: 6| Step: 9
Training loss: 0.13261487225630977
Validation loss: 2.532188246703547

Epoch: 6| Step: 10
Training loss: 0.11982674879715642
Validation loss: 2.5320728483249284

Epoch: 6| Step: 11
Training loss: 0.1909521711303969
Validation loss: 2.5522307218809983

Epoch: 6| Step: 12
Training loss: 0.19322812799001488
Validation loss: 2.539215855664599

Epoch: 6| Step: 13
Training loss: 0.0479440136587949
Validation loss: 2.524407903249165

Epoch: 583| Step: 0
Training loss: 0.15956746592603227
Validation loss: 2.564376737071421

Epoch: 6| Step: 1
Training loss: 0.1333438538210536
Validation loss: 2.5202641554317657

Epoch: 6| Step: 2
Training loss: 0.1552329700446709
Validation loss: 2.547046784677831

Epoch: 6| Step: 3
Training loss: 0.13935092766252483
Validation loss: 2.5229701067092893

Epoch: 6| Step: 4
Training loss: 0.18534796241986284
Validation loss: 2.5157197692259126

Epoch: 6| Step: 5
Training loss: 0.20499723746601592
Validation loss: 2.5119963767938875

Epoch: 6| Step: 6
Training loss: 0.07498669481474708
Validation loss: 2.5226588865079442

Epoch: 6| Step: 7
Training loss: 0.12307030212575684
Validation loss: 2.4954925757539876

Epoch: 6| Step: 8
Training loss: 0.07632844068799678
Validation loss: 2.4846541271847435

Epoch: 6| Step: 9
Training loss: 0.16676381875733304
Validation loss: 2.497095317690433

Epoch: 6| Step: 10
Training loss: 0.19701576460958092
Validation loss: 2.4841151623687123

Epoch: 6| Step: 11
Training loss: 0.18006304183317026
Validation loss: 2.5259736130054047

Epoch: 6| Step: 12
Training loss: 0.11225525141116223
Validation loss: 2.494119360431745

Epoch: 6| Step: 13
Training loss: 0.09927229787974415
Validation loss: 2.5399433717591298

Epoch: 584| Step: 0
Training loss: 0.12804553923221443
Validation loss: 2.5607104812168604

Epoch: 6| Step: 1
Training loss: 0.14441486776311602
Validation loss: 2.5441407454763856

Epoch: 6| Step: 2
Training loss: 0.12254052199910309
Validation loss: 2.571815051293169

Epoch: 6| Step: 3
Training loss: 0.20274702080479268
Validation loss: 2.5514183947838216

Epoch: 6| Step: 4
Training loss: 0.15115720889686599
Validation loss: 2.5625960521869087

Epoch: 6| Step: 5
Training loss: 0.21403064316707965
Validation loss: 2.5852237573092274

Epoch: 6| Step: 6
Training loss: 0.09631475295464831
Validation loss: 2.5944682576135087

Epoch: 6| Step: 7
Training loss: 0.1594894180786155
Validation loss: 2.552667312826426

Epoch: 6| Step: 8
Training loss: 0.15851270150298996
Validation loss: 2.5727908232510472

Epoch: 6| Step: 9
Training loss: 0.15335118535698117
Validation loss: 2.591603540090202

Epoch: 6| Step: 10
Training loss: 0.1304593805272401
Validation loss: 2.5705025284089515

Epoch: 6| Step: 11
Training loss: 0.14917564068959213
Validation loss: 2.572161259996276

Epoch: 6| Step: 12
Training loss: 0.1909141832839828
Validation loss: 2.5741589341149593

Epoch: 6| Step: 13
Training loss: 0.20157696391114924
Validation loss: 2.5491042636350163

Epoch: 585| Step: 0
Training loss: 0.09892144791506827
Validation loss: 2.568157084862228

Epoch: 6| Step: 1
Training loss: 0.17151213401709234
Validation loss: 2.5743882151504365

Epoch: 6| Step: 2
Training loss: 0.1536973884262768
Validation loss: 2.5319404576938935

Epoch: 6| Step: 3
Training loss: 0.09001119703768994
Validation loss: 2.5157907775662913

Epoch: 6| Step: 4
Training loss: 0.10925884976677157
Validation loss: 2.5184189843392106

Epoch: 6| Step: 5
Training loss: 0.16294324651548683
Validation loss: 2.538579996738721

Epoch: 6| Step: 6
Training loss: 0.19316019530711448
Validation loss: 2.548935491104499

Epoch: 6| Step: 7
Training loss: 0.22718322336665886
Validation loss: 2.5192595996569893

Epoch: 6| Step: 8
Training loss: 0.17676513087681472
Validation loss: 2.5348026012472844

Epoch: 6| Step: 9
Training loss: 0.12236791573018996
Validation loss: 2.5195461808531974

Epoch: 6| Step: 10
Training loss: 0.19734702932875442
Validation loss: 2.5451977998528275

Epoch: 6| Step: 11
Training loss: 0.0906086578103942
Validation loss: 2.520634267973289

Epoch: 6| Step: 12
Training loss: 0.12999094857057011
Validation loss: 2.5791777339897113

Epoch: 6| Step: 13
Training loss: 0.10689784458349755
Validation loss: 2.557019100488253

Epoch: 586| Step: 0
Training loss: 0.20281937421484178
Validation loss: 2.560373386766976

Epoch: 6| Step: 1
Training loss: 0.23050506758239347
Validation loss: 2.566457945710274

Epoch: 6| Step: 2
Training loss: 0.1375910452126991
Validation loss: 2.5563599592798227

Epoch: 6| Step: 3
Training loss: 0.12736277876896535
Validation loss: 2.567683276301904

Epoch: 6| Step: 4
Training loss: 0.14314195766730126
Validation loss: 2.5799289421861786

Epoch: 6| Step: 5
Training loss: 0.14613989697873248
Validation loss: 2.584130226448666

Epoch: 6| Step: 6
Training loss: 0.12504946951681178
Validation loss: 2.586862204754228

Epoch: 6| Step: 7
Training loss: 0.12324091582692594
Validation loss: 2.5912918004359655

Epoch: 6| Step: 8
Training loss: 0.2189405837216188
Validation loss: 2.6148422554891497

Epoch: 6| Step: 9
Training loss: 0.20033649025680023
Validation loss: 2.5749209852527573

Epoch: 6| Step: 10
Training loss: 0.2670519590969109
Validation loss: 2.557146649507039

Epoch: 6| Step: 11
Training loss: 0.0948632915073489
Validation loss: 2.577696006883479

Epoch: 6| Step: 12
Training loss: 0.1456393728817312
Validation loss: 2.562926522290671

Epoch: 6| Step: 13
Training loss: 0.13437067429654978
Validation loss: 2.569824068612133

Epoch: 587| Step: 0
Training loss: 0.10649482642875135
Validation loss: 2.5692219432116405

Epoch: 6| Step: 1
Training loss: 0.14447885929832227
Validation loss: 2.5434682893606557

Epoch: 6| Step: 2
Training loss: 0.15640045313424983
Validation loss: 2.520225795092611

Epoch: 6| Step: 3
Training loss: 0.12239090591684783
Validation loss: 2.5396517979874

Epoch: 6| Step: 4
Training loss: 0.18515388632122734
Validation loss: 2.5113085850418386

Epoch: 6| Step: 5
Training loss: 0.05871637149797936
Validation loss: 2.51593864980849

Epoch: 6| Step: 6
Training loss: 0.11562027406055585
Validation loss: 2.506213610298006

Epoch: 6| Step: 7
Training loss: 0.15159792387797003
Validation loss: 2.4838383056800826

Epoch: 6| Step: 8
Training loss: 0.13382925696709863
Validation loss: 2.5023241407049395

Epoch: 6| Step: 9
Training loss: 0.19664049714621934
Validation loss: 2.521619422145294

Epoch: 6| Step: 10
Training loss: 0.15326720733362445
Validation loss: 2.5056438789303797

Epoch: 6| Step: 11
Training loss: 0.11061947295557602
Validation loss: 2.4945462585903946

Epoch: 6| Step: 12
Training loss: 0.18428820288461417
Validation loss: 2.540202001886274

Epoch: 6| Step: 13
Training loss: 0.22719418498807195
Validation loss: 2.483003369905596

Epoch: 588| Step: 0
Training loss: 0.09855394231580314
Validation loss: 2.494024326523409

Epoch: 6| Step: 1
Training loss: 0.19340125506988917
Validation loss: 2.458231748842705

Epoch: 6| Step: 2
Training loss: 0.146640294063969
Validation loss: 2.5169132352963173

Epoch: 6| Step: 3
Training loss: 0.20717088021352353
Validation loss: 2.4677780084254253

Epoch: 6| Step: 4
Training loss: 0.14670629856789913
Validation loss: 2.495424663576837

Epoch: 6| Step: 5
Training loss: 0.11144290829220255
Validation loss: 2.5070581628996536

Epoch: 6| Step: 6
Training loss: 0.14761195754724313
Validation loss: 2.521322104758127

Epoch: 6| Step: 7
Training loss: 0.10617712779100155
Validation loss: 2.530761033461017

Epoch: 6| Step: 8
Training loss: 0.13405702028435165
Validation loss: 2.502505875960291

Epoch: 6| Step: 9
Training loss: 0.2118162377630736
Validation loss: 2.57096388950639

Epoch: 6| Step: 10
Training loss: 0.09211006407767133
Validation loss: 2.5609300207428656

Epoch: 6| Step: 11
Training loss: 0.15097009193402008
Validation loss: 2.558769261511062

Epoch: 6| Step: 12
Training loss: 0.15279281893175092
Validation loss: 2.5506157515070034

Epoch: 6| Step: 13
Training loss: 0.24518262134164506
Validation loss: 2.5745811072300464

Epoch: 589| Step: 0
Training loss: 0.14712491180819168
Validation loss: 2.594274942922293

Epoch: 6| Step: 1
Training loss: 0.20588233935482317
Validation loss: 2.5528878699040876

Epoch: 6| Step: 2
Training loss: 0.12625924265426658
Validation loss: 2.5421382336141476

Epoch: 6| Step: 3
Training loss: 0.15724569405677988
Validation loss: 2.536568584793049

Epoch: 6| Step: 4
Training loss: 0.09321282388276098
Validation loss: 2.5182929205216347

Epoch: 6| Step: 5
Training loss: 0.08149978784978934
Validation loss: 2.4919735149323934

Epoch: 6| Step: 6
Training loss: 0.2081770767893984
Validation loss: 2.4954526562825516

Epoch: 6| Step: 7
Training loss: 0.19162203828086807
Validation loss: 2.501899006197024

Epoch: 6| Step: 8
Training loss: 0.24148417452776413
Validation loss: 2.492430036440858

Epoch: 6| Step: 9
Training loss: 0.13945620984851467
Validation loss: 2.5040546392655565

Epoch: 6| Step: 10
Training loss: 0.12994850619786943
Validation loss: 2.5186277727863566

Epoch: 6| Step: 11
Training loss: 0.1849782764400361
Validation loss: 2.49448851053386

Epoch: 6| Step: 12
Training loss: 0.12302136535217253
Validation loss: 2.5212546409823586

Epoch: 6| Step: 13
Training loss: 0.23261289200231886
Validation loss: 2.5274196180426247

Epoch: 590| Step: 0
Training loss: 0.1242153905018377
Validation loss: 2.5505440572532474

Epoch: 6| Step: 1
Training loss: 0.07481971047047593
Validation loss: 2.548756972901478

Epoch: 6| Step: 2
Training loss: 0.10076085871288583
Validation loss: 2.5769480072304782

Epoch: 6| Step: 3
Training loss: 0.24512218759003956
Validation loss: 2.533822137660796

Epoch: 6| Step: 4
Training loss: 0.1281942442120019
Validation loss: 2.5695490561839387

Epoch: 6| Step: 5
Training loss: 0.12397224390959151
Validation loss: 2.562875625107797

Epoch: 6| Step: 6
Training loss: 0.08562721242621985
Validation loss: 2.5776745892181316

Epoch: 6| Step: 7
Training loss: 0.1337954944261831
Validation loss: 2.558447269447744

Epoch: 6| Step: 8
Training loss: 0.1948362552299587
Validation loss: 2.575575976533842

Epoch: 6| Step: 9
Training loss: 0.09651820828990344
Validation loss: 2.5723867306973047

Epoch: 6| Step: 10
Training loss: 0.1341511914063481
Validation loss: 2.5239460745449644

Epoch: 6| Step: 11
Training loss: 0.16972441545715342
Validation loss: 2.526305203549655

Epoch: 6| Step: 12
Training loss: 0.09443883851722926
Validation loss: 2.5529001087085095

Epoch: 6| Step: 13
Training loss: 0.079995595458717
Validation loss: 2.578184849158442

Epoch: 591| Step: 0
Training loss: 0.10557682187116088
Validation loss: 2.5302059682121554

Epoch: 6| Step: 1
Training loss: 0.09735622093443673
Validation loss: 2.5560956971617457

Epoch: 6| Step: 2
Training loss: 0.13047462096110815
Validation loss: 2.572684695347775

Epoch: 6| Step: 3
Training loss: 0.14405201382444208
Validation loss: 2.53979226655011

Epoch: 6| Step: 4
Training loss: 0.08370492708004872
Validation loss: 2.548226110926023

Epoch: 6| Step: 5
Training loss: 0.15482895288680124
Validation loss: 2.556587280788852

Epoch: 6| Step: 6
Training loss: 0.16308219128720344
Validation loss: 2.5548134106322613

Epoch: 6| Step: 7
Training loss: 0.19422343846107182
Validation loss: 2.578086195946125

Epoch: 6| Step: 8
Training loss: 0.16978200000517943
Validation loss: 2.514973016792831

Epoch: 6| Step: 9
Training loss: 0.11580402394819873
Validation loss: 2.5456511521851284

Epoch: 6| Step: 10
Training loss: 0.07349265822207826
Validation loss: 2.537162027361548

Epoch: 6| Step: 11
Training loss: 0.20626675508818224
Validation loss: 2.5271024786457397

Epoch: 6| Step: 12
Training loss: 0.12731883121145388
Validation loss: 2.515267831224376

Epoch: 6| Step: 13
Training loss: 0.15278440714550973
Validation loss: 2.5071456973913

Epoch: 592| Step: 0
Training loss: 0.10429424182553905
Validation loss: 2.4948897255887656

Epoch: 6| Step: 1
Training loss: 0.12375945434434843
Validation loss: 2.4974999571242265

Epoch: 6| Step: 2
Training loss: 0.11804674961479794
Validation loss: 2.5402365207499846

Epoch: 6| Step: 3
Training loss: 0.1305071017723518
Validation loss: 2.522328832471394

Epoch: 6| Step: 4
Training loss: 0.12641622278838202
Validation loss: 2.5297081678843982

Epoch: 6| Step: 5
Training loss: 0.19786895419443748
Validation loss: 2.5516889704835766

Epoch: 6| Step: 6
Training loss: 0.21064612786364842
Validation loss: 2.55527281932232

Epoch: 6| Step: 7
Training loss: 0.12322463713157365
Validation loss: 2.5144034127700534

Epoch: 6| Step: 8
Training loss: 0.09821786086353315
Validation loss: 2.5353691264128058

Epoch: 6| Step: 9
Training loss: 0.13362996881977982
Validation loss: 2.546237165357578

Epoch: 6| Step: 10
Training loss: 0.13330611892465538
Validation loss: 2.5481096993294026

Epoch: 6| Step: 11
Training loss: 0.1254127512629032
Validation loss: 2.561022635994841

Epoch: 6| Step: 12
Training loss: 0.13509989484162407
Validation loss: 2.56441205768645

Epoch: 6| Step: 13
Training loss: 0.12534314977007133
Validation loss: 2.5307142763581685

Epoch: 593| Step: 0
Training loss: 0.1788733322977501
Validation loss: 2.5307384765615297

Epoch: 6| Step: 1
Training loss: 0.10147843641594514
Validation loss: 2.537039642384876

Epoch: 6| Step: 2
Training loss: 0.20231626979437412
Validation loss: 2.5652259665734807

Epoch: 6| Step: 3
Training loss: 0.09245563080889184
Validation loss: 2.565321054008878

Epoch: 6| Step: 4
Training loss: 0.10942615436769094
Validation loss: 2.5367350800771056

Epoch: 6| Step: 5
Training loss: 0.18325810491988462
Validation loss: 2.5563345555078705

Epoch: 6| Step: 6
Training loss: 0.18440107629936664
Validation loss: 2.547993890123342

Epoch: 6| Step: 7
Training loss: 0.11772427806071901
Validation loss: 2.5629356108062065

Epoch: 6| Step: 8
Training loss: 0.11999090270735455
Validation loss: 2.525077497961555

Epoch: 6| Step: 9
Training loss: 0.15577056763963776
Validation loss: 2.5086886623761733

Epoch: 6| Step: 10
Training loss: 0.11317992611752813
Validation loss: 2.5282460153005615

Epoch: 6| Step: 11
Training loss: 0.14732489721128592
Validation loss: 2.5357148072319844

Epoch: 6| Step: 12
Training loss: 0.09223253273614454
Validation loss: 2.5155327811306267

Epoch: 6| Step: 13
Training loss: 0.09380973958974195
Validation loss: 2.5272973161534837

Epoch: 594| Step: 0
Training loss: 0.18443172034964694
Validation loss: 2.5472047955761736

Epoch: 6| Step: 1
Training loss: 0.13704975793746493
Validation loss: 2.550855755642413

Epoch: 6| Step: 2
Training loss: 0.13935918128047942
Validation loss: 2.5570824172449242

Epoch: 6| Step: 3
Training loss: 0.12772885056894528
Validation loss: 2.570599792225552

Epoch: 6| Step: 4
Training loss: 0.14859078674089388
Validation loss: 2.5393748096518904

Epoch: 6| Step: 5
Training loss: 0.07386386248580626
Validation loss: 2.555032003981816

Epoch: 6| Step: 6
Training loss: 0.1973938478019387
Validation loss: 2.578140910060064

Epoch: 6| Step: 7
Training loss: 0.174083388349049
Validation loss: 2.606540684318767

Epoch: 6| Step: 8
Training loss: 0.07155808546576176
Validation loss: 2.6082021646530533

Epoch: 6| Step: 9
Training loss: 0.18102318408380838
Validation loss: 2.574954835085649

Epoch: 6| Step: 10
Training loss: 0.1286591632657726
Validation loss: 2.5713507327696754

Epoch: 6| Step: 11
Training loss: 0.10060118587429619
Validation loss: 2.5966552577236137

Epoch: 6| Step: 12
Training loss: 0.15171753730642848
Validation loss: 2.5960311673100978

Epoch: 6| Step: 13
Training loss: 0.11168053963927511
Validation loss: 2.614066690929086

Epoch: 595| Step: 0
Training loss: 0.08801290959135047
Validation loss: 2.6167979852197214

Epoch: 6| Step: 1
Training loss: 0.09652315819768198
Validation loss: 2.60784973638183

Epoch: 6| Step: 2
Training loss: 0.08672490055164299
Validation loss: 2.595007187369069

Epoch: 6| Step: 3
Training loss: 0.121585953124497
Validation loss: 2.6126179243759964

Epoch: 6| Step: 4
Training loss: 0.168294380281414
Validation loss: 2.5793012325446254

Epoch: 6| Step: 5
Training loss: 0.11521601126519514
Validation loss: 2.5900040584660218

Epoch: 6| Step: 6
Training loss: 0.19416056440414292
Validation loss: 2.6191844361623486

Epoch: 6| Step: 7
Training loss: 0.13614734041254964
Validation loss: 2.6130529288892714

Epoch: 6| Step: 8
Training loss: 0.15615539070673162
Validation loss: 2.6022355773531842

Epoch: 6| Step: 9
Training loss: 0.09644309871414865
Validation loss: 2.579876765166297

Epoch: 6| Step: 10
Training loss: 0.19328889621977094
Validation loss: 2.608922210603208

Epoch: 6| Step: 11
Training loss: 0.16173017341699764
Validation loss: 2.5719365191036903

Epoch: 6| Step: 12
Training loss: 0.06590664731042048
Validation loss: 2.5999783377774395

Epoch: 6| Step: 13
Training loss: 0.16069449717310982
Validation loss: 2.584236821286107

Epoch: 596| Step: 0
Training loss: 0.1461720952675086
Validation loss: 2.5604375937920025

Epoch: 6| Step: 1
Training loss: 0.205775691256395
Validation loss: 2.535742776752386

Epoch: 6| Step: 2
Training loss: 0.09855040327354457
Validation loss: 2.4834470299890494

Epoch: 6| Step: 3
Training loss: 0.18811687678481703
Validation loss: 2.5100000068292934

Epoch: 6| Step: 4
Training loss: 0.1599393224493099
Validation loss: 2.466138330317308

Epoch: 6| Step: 5
Training loss: 0.22137026260795342
Validation loss: 2.463586473104112

Epoch: 6| Step: 6
Training loss: 0.11439834006118506
Validation loss: 2.4801071491243256

Epoch: 6| Step: 7
Training loss: 0.16455370167480995
Validation loss: 2.5547544268585463

Epoch: 6| Step: 8
Training loss: 0.1690917840969203
Validation loss: 2.5519610831283606

Epoch: 6| Step: 9
Training loss: 0.12067694997457688
Validation loss: 2.562845288375585

Epoch: 6| Step: 10
Training loss: 0.28009314503424054
Validation loss: 2.6017510362035785

Epoch: 6| Step: 11
Training loss: 0.21479665066560338
Validation loss: 2.5804269879322055

Epoch: 6| Step: 12
Training loss: 0.14898077777906613
Validation loss: 2.587936166806431

Epoch: 6| Step: 13
Training loss: 0.13875891411988728
Validation loss: 2.5708093557873206

Epoch: 597| Step: 0
Training loss: 0.12937136748646125
Validation loss: 2.535864369051493

Epoch: 6| Step: 1
Training loss: 0.15011118652276717
Validation loss: 2.567904053149319

Epoch: 6| Step: 2
Training loss: 0.2053968768004475
Validation loss: 2.549411522443043

Epoch: 6| Step: 3
Training loss: 0.17802567766323357
Validation loss: 2.4963227874550102

Epoch: 6| Step: 4
Training loss: 0.22509343604643595
Validation loss: 2.574326285530668

Epoch: 6| Step: 5
Training loss: 0.2532863679494684
Validation loss: 2.577978465719112

Epoch: 6| Step: 6
Training loss: 0.16490755541250246
Validation loss: 2.588785042501244

Epoch: 6| Step: 7
Training loss: 0.14871077103401328
Validation loss: 2.579851126414244

Epoch: 6| Step: 8
Training loss: 0.15409612271337486
Validation loss: 2.5687119308296262

Epoch: 6| Step: 9
Training loss: 0.1719737094584788
Validation loss: 2.5851201326243283

Epoch: 6| Step: 10
Training loss: 0.19880155749339304
Validation loss: 2.5850597894998186

Epoch: 6| Step: 11
Training loss: 0.1851664005185208
Validation loss: 2.5776014346392375

Epoch: 6| Step: 12
Training loss: 0.12088426805821893
Validation loss: 2.560230899213032

Epoch: 6| Step: 13
Training loss: 0.16587747547858075
Validation loss: 2.551558010605086

Epoch: 598| Step: 0
Training loss: 0.10246518970847164
Validation loss: 2.5345192957293

Epoch: 6| Step: 1
Training loss: 0.11841869111165584
Validation loss: 2.5415509006099293

Epoch: 6| Step: 2
Training loss: 0.14558360666753586
Validation loss: 2.5288771254706495

Epoch: 6| Step: 3
Training loss: 0.1747620706448316
Validation loss: 2.5420050904251976

Epoch: 6| Step: 4
Training loss: 0.17634864468856787
Validation loss: 2.5139540942947356

Epoch: 6| Step: 5
Training loss: 0.22610947105464196
Validation loss: 2.562891304238626

Epoch: 6| Step: 6
Training loss: 0.16328767188918128
Validation loss: 2.509316102863542

Epoch: 6| Step: 7
Training loss: 0.17504074099280134
Validation loss: 2.5178457882983345

Epoch: 6| Step: 8
Training loss: 0.12344768503276422
Validation loss: 2.5308004020751995

Epoch: 6| Step: 9
Training loss: 0.15745351534938246
Validation loss: 2.497797373058231

Epoch: 6| Step: 10
Training loss: 0.14819029878726955
Validation loss: 2.508131620594008

Epoch: 6| Step: 11
Training loss: 0.18742275633769703
Validation loss: 2.5092802917623938

Epoch: 6| Step: 12
Training loss: 0.1074091036747389
Validation loss: 2.4930448196433925

Epoch: 6| Step: 13
Training loss: 0.17923266439126212
Validation loss: 2.558951294944302

Epoch: 599| Step: 0
Training loss: 0.20092041076439887
Validation loss: 2.498930748577119

Epoch: 6| Step: 1
Training loss: 0.19485430377622434
Validation loss: 2.558315278665943

Epoch: 6| Step: 2
Training loss: 0.1281322375439842
Validation loss: 2.531518803134243

Epoch: 6| Step: 3
Training loss: 0.12808579100809564
Validation loss: 2.567703304640701

Epoch: 6| Step: 4
Training loss: 0.11976560450813133
Validation loss: 2.5430561895768022

Epoch: 6| Step: 5
Training loss: 0.10243543201986838
Validation loss: 2.5464003036436007

Epoch: 6| Step: 6
Training loss: 0.13936026390503034
Validation loss: 2.5560975425922874

Epoch: 6| Step: 7
Training loss: 0.07997902110819295
Validation loss: 2.5268665553047853

Epoch: 6| Step: 8
Training loss: 0.06592662895676113
Validation loss: 2.5514005858171322

Epoch: 6| Step: 9
Training loss: 0.22827649442509215
Validation loss: 2.5458744161427567

Epoch: 6| Step: 10
Training loss: 0.20683482586757354
Validation loss: 2.5382342556640065

Epoch: 6| Step: 11
Training loss: 0.12129213249387807
Validation loss: 2.5457227274411736

Epoch: 6| Step: 12
Training loss: 0.08926668081321888
Validation loss: 2.520395856413043

Epoch: 6| Step: 13
Training loss: 0.09705816707194123
Validation loss: 2.5451311162636965

Epoch: 600| Step: 0
Training loss: 0.19531192779457196
Validation loss: 2.5365762370898994

Epoch: 6| Step: 1
Training loss: 0.14101198381916677
Validation loss: 2.5452901341934537

Epoch: 6| Step: 2
Training loss: 0.2564205102482661
Validation loss: 2.553892182857136

Epoch: 6| Step: 3
Training loss: 0.13779904131144077
Validation loss: 2.563515165679961

Epoch: 6| Step: 4
Training loss: 0.1736495086143295
Validation loss: 2.5081599753869894

Epoch: 6| Step: 5
Training loss: 0.15873718188380342
Validation loss: 2.514190385013025

Epoch: 6| Step: 6
Training loss: 0.12280967343938487
Validation loss: 2.506794087350154

Epoch: 6| Step: 7
Training loss: 0.10218798617588545
Validation loss: 2.5091141525033103

Epoch: 6| Step: 8
Training loss: 0.303028972398842
Validation loss: 2.5100092839228383

Epoch: 6| Step: 9
Training loss: 0.13126433044492702
Validation loss: 2.461089825868196

Epoch: 6| Step: 10
Training loss: 0.20942289032462633
Validation loss: 2.510522454079146

Epoch: 6| Step: 11
Training loss: 0.22329357186628337
Validation loss: 2.5154355639640356

Epoch: 6| Step: 12
Training loss: 0.0828623956489021
Validation loss: 2.4988098716234908

Epoch: 6| Step: 13
Training loss: 0.1242445454114964
Validation loss: 2.525023120927378

Epoch: 601| Step: 0
Training loss: 0.16572544318099763
Validation loss: 2.520962641575973

Epoch: 6| Step: 1
Training loss: 0.3004066066186253
Validation loss: 2.5226874611358974

Epoch: 6| Step: 2
Training loss: 0.15700373052611366
Validation loss: 2.524301814522866

Epoch: 6| Step: 3
Training loss: 0.18458917309505313
Validation loss: 2.5475282076138477

Epoch: 6| Step: 4
Training loss: 0.10407410522564707
Validation loss: 2.5475732623862437

Epoch: 6| Step: 5
Training loss: 0.12268108918225472
Validation loss: 2.559088051447903

Epoch: 6| Step: 6
Training loss: 0.12150959170219916
Validation loss: 2.5077242680639813

Epoch: 6| Step: 7
Training loss: 0.20653283204800152
Validation loss: 2.526447389320917

Epoch: 6| Step: 8
Training loss: 0.16540008198941908
Validation loss: 2.540369976123735

Epoch: 6| Step: 9
Training loss: 0.274441564953349
Validation loss: 2.5291608714232443

Epoch: 6| Step: 10
Training loss: 0.19186195310539186
Validation loss: 2.5072026242563465

Epoch: 6| Step: 11
Training loss: 0.20348323813267805
Validation loss: 2.5216303065306094

Epoch: 6| Step: 12
Training loss: 0.2530241683001004
Validation loss: 2.5046982630428944

Epoch: 6| Step: 13
Training loss: 0.17177563742895643
Validation loss: 2.495911189900488

Epoch: 602| Step: 0
Training loss: 0.1830955400953992
Validation loss: 2.5144777376750476

Epoch: 6| Step: 1
Training loss: 0.12288875486863131
Validation loss: 2.48001452747381

Epoch: 6| Step: 2
Training loss: 0.16777076252768805
Validation loss: 2.4995927181529627

Epoch: 6| Step: 3
Training loss: 0.14462373970277204
Validation loss: 2.5259723687231297

Epoch: 6| Step: 4
Training loss: 0.18107512851454038
Validation loss: 2.4986608143472515

Epoch: 6| Step: 5
Training loss: 0.1274188522317126
Validation loss: 2.514975674239874

Epoch: 6| Step: 6
Training loss: 0.1738591005822487
Validation loss: 2.5419394294461832

Epoch: 6| Step: 7
Training loss: 0.19805921369410107
Validation loss: 2.579431484560904

Epoch: 6| Step: 8
Training loss: 0.27043530976422614
Validation loss: 2.5557321795360313

Epoch: 6| Step: 9
Training loss: 0.22009930677655737
Validation loss: 2.585834216214071

Epoch: 6| Step: 10
Training loss: 0.21880324601231715
Validation loss: 2.6029327488219103

Epoch: 6| Step: 11
Training loss: 0.10630396986911388
Validation loss: 2.5678046697507657

Epoch: 6| Step: 12
Training loss: 0.21518270457350985
Validation loss: 2.5748047829244474

Epoch: 6| Step: 13
Training loss: 0.17728029661966183
Validation loss: 2.546760362734871

Epoch: 603| Step: 0
Training loss: 0.12426454281800396
Validation loss: 2.5346543047920598

Epoch: 6| Step: 1
Training loss: 0.15099950865245607
Validation loss: 2.568619256479396

Epoch: 6| Step: 2
Training loss: 0.12635836297756503
Validation loss: 2.5357311684025867

Epoch: 6| Step: 3
Training loss: 0.19597897305145653
Validation loss: 2.5413888582427697

Epoch: 6| Step: 4
Training loss: 0.19009663728060522
Validation loss: 2.551535011103592

Epoch: 6| Step: 5
Training loss: 0.19147785949205506
Validation loss: 2.5722292929762673

Epoch: 6| Step: 6
Training loss: 0.17744712883345465
Validation loss: 2.5786318025118145

Epoch: 6| Step: 7
Training loss: 0.1679974243173815
Validation loss: 2.5811346739280685

Epoch: 6| Step: 8
Training loss: 0.09826964379571156
Validation loss: 2.6000913829536176

Epoch: 6| Step: 9
Training loss: 0.19432090816177222
Validation loss: 2.594678998801717

Epoch: 6| Step: 10
Training loss: 0.1917295158957417
Validation loss: 2.5903054117611393

Epoch: 6| Step: 11
Training loss: 0.11379219206052923
Validation loss: 2.5736998077405318

Epoch: 6| Step: 12
Training loss: 0.242225282552186
Validation loss: 2.579296055166619

Epoch: 6| Step: 13
Training loss: 0.08922545558161675
Validation loss: 2.5444009303243966

Epoch: 604| Step: 0
Training loss: 0.14921428064573458
Validation loss: 2.5588173103621643

Epoch: 6| Step: 1
Training loss: 0.13625720318949516
Validation loss: 2.5487059104409324

Epoch: 6| Step: 2
Training loss: 0.13805583668944446
Validation loss: 2.5096382439168132

Epoch: 6| Step: 3
Training loss: 0.08316998067845291
Validation loss: 2.537706999188484

Epoch: 6| Step: 4
Training loss: 0.13704997539351296
Validation loss: 2.5112665516624295

Epoch: 6| Step: 5
Training loss: 0.13762577817265506
Validation loss: 2.5432985057738247

Epoch: 6| Step: 6
Training loss: 0.14298393033425078
Validation loss: 2.5420310261757355

Epoch: 6| Step: 7
Training loss: 0.1700333635114361
Validation loss: 2.513383091970165

Epoch: 6| Step: 8
Training loss: 0.17442054736479515
Validation loss: 2.52726252469813

Epoch: 6| Step: 9
Training loss: 0.1633150353225781
Validation loss: 2.566347428780581

Epoch: 6| Step: 10
Training loss: 0.22316374581246232
Validation loss: 2.5453282086974474

Epoch: 6| Step: 11
Training loss: 0.14802664439892685
Validation loss: 2.5571154766030917

Epoch: 6| Step: 12
Training loss: 0.14294745020808935
Validation loss: 2.5352484972918785

Epoch: 6| Step: 13
Training loss: 0.09886546598041178
Validation loss: 2.5492858729647847

Epoch: 605| Step: 0
Training loss: 0.13546912082150578
Validation loss: 2.55260460163249

Epoch: 6| Step: 1
Training loss: 0.13165065319679414
Validation loss: 2.574555271355819

Epoch: 6| Step: 2
Training loss: 0.17855630240067896
Validation loss: 2.576951977120459

Epoch: 6| Step: 3
Training loss: 0.10267940181787345
Validation loss: 2.57398242921648

Epoch: 6| Step: 4
Training loss: 0.08545673337318567
Validation loss: 2.561610316777646

Epoch: 6| Step: 5
Training loss: 0.19762974361563257
Validation loss: 2.5192483101920446

Epoch: 6| Step: 6
Training loss: 0.13900965533066506
Validation loss: 2.539583109576918

Epoch: 6| Step: 7
Training loss: 0.14881972617132427
Validation loss: 2.5033378335354577

Epoch: 6| Step: 8
Training loss: 0.1622819441595571
Validation loss: 2.5286867143847243

Epoch: 6| Step: 9
Training loss: 0.11259000029263673
Validation loss: 2.5258498610703684

Epoch: 6| Step: 10
Training loss: 0.12683488768438878
Validation loss: 2.545594969325231

Epoch: 6| Step: 11
Training loss: 0.17337786835014632
Validation loss: 2.5362906795502567

Epoch: 6| Step: 12
Training loss: 0.16861263220671077
Validation loss: 2.5134507116936606

Epoch: 6| Step: 13
Training loss: 0.18860423255681041
Validation loss: 2.5547840473593646

Epoch: 606| Step: 0
Training loss: 0.1543371172227235
Validation loss: 2.545237071069245

Epoch: 6| Step: 1
Training loss: 0.12643297449301424
Validation loss: 2.536042181428031

Epoch: 6| Step: 2
Training loss: 0.20664349718026775
Validation loss: 2.5542716088272877

Epoch: 6| Step: 3
Training loss: 0.11553298117393329
Validation loss: 2.515724466016391

Epoch: 6| Step: 4
Training loss: 0.1837895141012256
Validation loss: 2.5602358828365905

Epoch: 6| Step: 5
Training loss: 0.14574751855183893
Validation loss: 2.542055005189078

Epoch: 6| Step: 6
Training loss: 0.11769479779961158
Validation loss: 2.545507569622095

Epoch: 6| Step: 7
Training loss: 0.1792493225235154
Validation loss: 2.5428677495948757

Epoch: 6| Step: 8
Training loss: 0.1975228549312122
Validation loss: 2.5707264024081544

Epoch: 6| Step: 9
Training loss: 0.22505502028087596
Validation loss: 2.54452766733228

Epoch: 6| Step: 10
Training loss: 0.09021710482380015
Validation loss: 2.559406243756023

Epoch: 6| Step: 11
Training loss: 0.1724546260694102
Validation loss: 2.544121652175386

Epoch: 6| Step: 12
Training loss: 0.12128064130951258
Validation loss: 2.532046317496165

Epoch: 6| Step: 13
Training loss: 0.10727565523999602
Validation loss: 2.5708012175314465

Epoch: 607| Step: 0
Training loss: 0.13863433410334025
Validation loss: 2.527295572433129

Epoch: 6| Step: 1
Training loss: 0.12418249773851761
Validation loss: 2.534158456428004

Epoch: 6| Step: 2
Training loss: 0.09314101831871144
Validation loss: 2.5459585407522733

Epoch: 6| Step: 3
Training loss: 0.09525737301695297
Validation loss: 2.559098580123396

Epoch: 6| Step: 4
Training loss: 0.16101723774264723
Validation loss: 2.542426375193688

Epoch: 6| Step: 5
Training loss: 0.12509392398504793
Validation loss: 2.528566549177705

Epoch: 6| Step: 6
Training loss: 0.1522929828369923
Validation loss: 2.5350139469336592

Epoch: 6| Step: 7
Training loss: 0.1241495137426369
Validation loss: 2.5352746649634352

Epoch: 6| Step: 8
Training loss: 0.12009095471504216
Validation loss: 2.4883751546501762

Epoch: 6| Step: 9
Training loss: 0.1616373716610514
Validation loss: 2.5207397543910375

Epoch: 6| Step: 10
Training loss: 0.11010524806818191
Validation loss: 2.5418434582541236

Epoch: 6| Step: 11
Training loss: 0.15965987252056743
Validation loss: 2.5639441457839935

Epoch: 6| Step: 12
Training loss: 0.08992683673695068
Validation loss: 2.5181969073666326

Epoch: 6| Step: 13
Training loss: 0.10830065036693538
Validation loss: 2.542893004104881

Epoch: 608| Step: 0
Training loss: 0.22412718554759273
Validation loss: 2.5390468933282118

Epoch: 6| Step: 1
Training loss: 0.11507120541540743
Validation loss: 2.511253656691242

Epoch: 6| Step: 2
Training loss: 0.08201715654831626
Validation loss: 2.526548541844098

Epoch: 6| Step: 3
Training loss: 0.09799943703433774
Validation loss: 2.5474397790671794

Epoch: 6| Step: 4
Training loss: 0.1848388816985655
Validation loss: 2.50226961089509

Epoch: 6| Step: 5
Training loss: 0.11117963759771196
Validation loss: 2.535979510993701

Epoch: 6| Step: 6
Training loss: 0.16135333605462823
Validation loss: 2.5237839872145

Epoch: 6| Step: 7
Training loss: 0.07295241891462483
Validation loss: 2.5442768531427746

Epoch: 6| Step: 8
Training loss: 0.07707545896961741
Validation loss: 2.5344206695004483

Epoch: 6| Step: 9
Training loss: 0.12725542463167316
Validation loss: 2.543626878333787

Epoch: 6| Step: 10
Training loss: 0.14024317084224772
Validation loss: 2.487932483114616

Epoch: 6| Step: 11
Training loss: 0.07814236090405674
Validation loss: 2.513010731176854

Epoch: 6| Step: 12
Training loss: 0.13091167429697578
Validation loss: 2.5232663269413056

Epoch: 6| Step: 13
Training loss: 0.15133934380180153
Validation loss: 2.495450181455655

Epoch: 609| Step: 0
Training loss: 0.172190279496843
Validation loss: 2.5164136741369663

Epoch: 6| Step: 1
Training loss: 0.12361290335992994
Validation loss: 2.5386182438344647

Epoch: 6| Step: 2
Training loss: 0.15699154603347276
Validation loss: 2.550890409225675

Epoch: 6| Step: 3
Training loss: 0.13645638769039137
Validation loss: 2.5530260110925456

Epoch: 6| Step: 4
Training loss: 0.18786113452063583
Validation loss: 2.518809746454225

Epoch: 6| Step: 5
Training loss: 0.17646842788239958
Validation loss: 2.5379314256498486

Epoch: 6| Step: 6
Training loss: 0.1383639597442784
Validation loss: 2.5424828720858925

Epoch: 6| Step: 7
Training loss: 0.17813774071687127
Validation loss: 2.553872418876805

Epoch: 6| Step: 8
Training loss: 0.1504690287935045
Validation loss: 2.5358525317708294

Epoch: 6| Step: 9
Training loss: 0.18423132066489475
Validation loss: 2.576022781443432

Epoch: 6| Step: 10
Training loss: 0.12252681061695622
Validation loss: 2.5422541875494122

Epoch: 6| Step: 11
Training loss: 0.1100868281963988
Validation loss: 2.549740086032447

Epoch: 6| Step: 12
Training loss: 0.13091074234272343
Validation loss: 2.5222737478430073

Epoch: 6| Step: 13
Training loss: 0.11855937313768689
Validation loss: 2.5042770121736444

Epoch: 610| Step: 0
Training loss: 0.11860957375606386
Validation loss: 2.5261720123676867

Epoch: 6| Step: 1
Training loss: 0.08828026446070865
Validation loss: 2.5359731382249926

Epoch: 6| Step: 2
Training loss: 0.09914327006948605
Validation loss: 2.5069078018503714

Epoch: 6| Step: 3
Training loss: 0.12374137733984704
Validation loss: 2.5215442061596653

Epoch: 6| Step: 4
Training loss: 0.11645096745623519
Validation loss: 2.522129668938107

Epoch: 6| Step: 5
Training loss: 0.09906136540686751
Validation loss: 2.533499365073739

Epoch: 6| Step: 6
Training loss: 0.08312442386309225
Validation loss: 2.5232537488199105

Epoch: 6| Step: 7
Training loss: 0.11292722481622353
Validation loss: 2.4947849295598377

Epoch: 6| Step: 8
Training loss: 0.1900894647077936
Validation loss: 2.4923181912621617

Epoch: 6| Step: 9
Training loss: 0.11158190211911762
Validation loss: 2.5143151934132364

Epoch: 6| Step: 10
Training loss: 0.14173748464519506
Validation loss: 2.529020131676471

Epoch: 6| Step: 11
Training loss: 0.2019172673516254
Validation loss: 2.500575661780236

Epoch: 6| Step: 12
Training loss: 0.18737536500051624
Validation loss: 2.5062266915420244

Epoch: 6| Step: 13
Training loss: 0.15818217221191366
Validation loss: 2.5354845355324542

Epoch: 611| Step: 0
Training loss: 0.11018703230127315
Validation loss: 2.497302080363645

Epoch: 6| Step: 1
Training loss: 0.15850843004317627
Validation loss: 2.504316711134805

Epoch: 6| Step: 2
Training loss: 0.1119139300174162
Validation loss: 2.5570388053073922

Epoch: 6| Step: 3
Training loss: 0.10911473319362767
Validation loss: 2.533310652898751

Epoch: 6| Step: 4
Training loss: 0.17381534100789137
Validation loss: 2.5061708380686505

Epoch: 6| Step: 5
Training loss: 0.11848661834724013
Validation loss: 2.5267201342907617

Epoch: 6| Step: 6
Training loss: 0.07916275942042521
Validation loss: 2.534964056348971

Epoch: 6| Step: 7
Training loss: 0.16972983678681794
Validation loss: 2.540714764145417

Epoch: 6| Step: 8
Training loss: 0.138661887924111
Validation loss: 2.5259654429515352

Epoch: 6| Step: 9
Training loss: 0.12665900860033416
Validation loss: 2.5444244769296964

Epoch: 6| Step: 10
Training loss: 0.11938261642549793
Validation loss: 2.533830559605205

Epoch: 6| Step: 11
Training loss: 0.15162882189482124
Validation loss: 2.5248594070893327

Epoch: 6| Step: 12
Training loss: 0.15956284915274743
Validation loss: 2.518986515810454

Epoch: 6| Step: 13
Training loss: 0.11225812195384739
Validation loss: 2.5246124605352143

Epoch: 612| Step: 0
Training loss: 0.10216753728210667
Validation loss: 2.528837940819009

Epoch: 6| Step: 1
Training loss: 0.14341299369169777
Validation loss: 2.5332666322198785

Epoch: 6| Step: 2
Training loss: 0.08022202959515719
Validation loss: 2.554578190923857

Epoch: 6| Step: 3
Training loss: 0.126699943440439
Validation loss: 2.5426160628513346

Epoch: 6| Step: 4
Training loss: 0.11573665067501382
Validation loss: 2.53085628533055

Epoch: 6| Step: 5
Training loss: 0.20294152740215854
Validation loss: 2.527908567658273

Epoch: 6| Step: 6
Training loss: 0.10073986589937589
Validation loss: 2.526641206895806

Epoch: 6| Step: 7
Training loss: 0.10028684926144622
Validation loss: 2.5575474547096775

Epoch: 6| Step: 8
Training loss: 0.1374242020974357
Validation loss: 2.51936602892171

Epoch: 6| Step: 9
Training loss: 0.16515894491546732
Validation loss: 2.5666484153182805

Epoch: 6| Step: 10
Training loss: 0.11758486215166754
Validation loss: 2.5817225553762704

Epoch: 6| Step: 11
Training loss: 0.13950545987857854
Validation loss: 2.5506738761573455

Epoch: 6| Step: 12
Training loss: 0.16383420864701215
Validation loss: 2.5747555209771753

Epoch: 6| Step: 13
Training loss: 0.052777707434010966
Validation loss: 2.5285731160125153

Epoch: 613| Step: 0
Training loss: 0.13094891857987542
Validation loss: 2.553628948623062

Epoch: 6| Step: 1
Training loss: 0.11643694690495172
Validation loss: 2.514215555402941

Epoch: 6| Step: 2
Training loss: 0.08888054317679911
Validation loss: 2.5353777575817302

Epoch: 6| Step: 3
Training loss: 0.09632325213467986
Validation loss: 2.536017023470713

Epoch: 6| Step: 4
Training loss: 0.15543993534301648
Validation loss: 2.5420031540829324

Epoch: 6| Step: 5
Training loss: 0.12846360646675475
Validation loss: 2.5337321858250546

Epoch: 6| Step: 6
Training loss: 0.1398823852553843
Validation loss: 2.5338841461508186

Epoch: 6| Step: 7
Training loss: 0.14294269407715543
Validation loss: 2.5407176428875307

Epoch: 6| Step: 8
Training loss: 0.09447500904584903
Validation loss: 2.5331313599456853

Epoch: 6| Step: 9
Training loss: 0.16698690037974143
Validation loss: 2.51756566407663

Epoch: 6| Step: 10
Training loss: 0.20547811465081245
Validation loss: 2.54993301889147

Epoch: 6| Step: 11
Training loss: 0.13775120270484412
Validation loss: 2.5252428128531776

Epoch: 6| Step: 12
Training loss: 0.11210854028264765
Validation loss: 2.507201071062642

Epoch: 6| Step: 13
Training loss: 0.07593215610594009
Validation loss: 2.513387656958002

Epoch: 614| Step: 0
Training loss: 0.1432891387806138
Validation loss: 2.5203439955737776

Epoch: 6| Step: 1
Training loss: 0.14365265546047848
Validation loss: 2.5037941910082617

Epoch: 6| Step: 2
Training loss: 0.08932728140410803
Validation loss: 2.507420555708566

Epoch: 6| Step: 3
Training loss: 0.15787463758899714
Validation loss: 2.5125075840385316

Epoch: 6| Step: 4
Training loss: 0.16699325271177473
Validation loss: 2.5188564527916877

Epoch: 6| Step: 5
Training loss: 0.09871898323966184
Validation loss: 2.5109030803319365

Epoch: 6| Step: 6
Training loss: 0.06670585183243968
Validation loss: 2.527337706933106

Epoch: 6| Step: 7
Training loss: 0.1324660185433081
Validation loss: 2.5195193662535673

Epoch: 6| Step: 8
Training loss: 0.188700330653707
Validation loss: 2.53167886264681

Epoch: 6| Step: 9
Training loss: 0.1458361333056001
Validation loss: 2.5629868683900887

Epoch: 6| Step: 10
Training loss: 0.1754895757373751
Validation loss: 2.576386616336783

Epoch: 6| Step: 11
Training loss: 0.09297494086321124
Validation loss: 2.5337670240246104

Epoch: 6| Step: 12
Training loss: 0.11197989393338155
Validation loss: 2.5332331310796192

Epoch: 6| Step: 13
Training loss: 0.18900074974988648
Validation loss: 2.5065705457596605

Epoch: 615| Step: 0
Training loss: 0.1173621624445553
Validation loss: 2.518396900696999

Epoch: 6| Step: 1
Training loss: 0.1562538265713381
Validation loss: 2.546490634522001

Epoch: 6| Step: 2
Training loss: 0.12102490821704683
Validation loss: 2.5098141584734814

Epoch: 6| Step: 3
Training loss: 0.16005749099844985
Validation loss: 2.526335292572827

Epoch: 6| Step: 4
Training loss: 0.1113062552671481
Validation loss: 2.5195405398216093

Epoch: 6| Step: 5
Training loss: 0.139797544571354
Validation loss: 2.5386409054225343

Epoch: 6| Step: 6
Training loss: 0.17810041860320275
Validation loss: 2.5342321174808182

Epoch: 6| Step: 7
Training loss: 0.12705734816519526
Validation loss: 2.5368661139362403

Epoch: 6| Step: 8
Training loss: 0.10507589926365489
Validation loss: 2.560222117017346

Epoch: 6| Step: 9
Training loss: 0.07097048317209341
Validation loss: 2.5145477860343854

Epoch: 6| Step: 10
Training loss: 0.16603362602926103
Validation loss: 2.4991829500919125

Epoch: 6| Step: 11
Training loss: 0.05970788532054283
Validation loss: 2.5275756062136128

Epoch: 6| Step: 12
Training loss: 0.11075063299844216
Validation loss: 2.5359537084601307

Epoch: 6| Step: 13
Training loss: 0.08568626222266001
Validation loss: 2.5209674252066026

Epoch: 616| Step: 0
Training loss: 0.12255781864969822
Validation loss: 2.5313920194283126

Epoch: 6| Step: 1
Training loss: 0.14090548464646965
Validation loss: 2.5458589106415954

Epoch: 6| Step: 2
Training loss: 0.15490830273025205
Validation loss: 2.5260697010050523

Epoch: 6| Step: 3
Training loss: 0.08045336856405107
Validation loss: 2.5186663467853556

Epoch: 6| Step: 4
Training loss: 0.17803046955622578
Validation loss: 2.5574323244865833

Epoch: 6| Step: 5
Training loss: 0.10969888891558932
Validation loss: 2.5438577603805723

Epoch: 6| Step: 6
Training loss: 0.10166181238677821
Validation loss: 2.5535509267399523

Epoch: 6| Step: 7
Training loss: 0.08543729971455481
Validation loss: 2.5489190668416635

Epoch: 6| Step: 8
Training loss: 0.15088102345385412
Validation loss: 2.5404492641099385

Epoch: 6| Step: 9
Training loss: 0.14144906349549696
Validation loss: 2.5345726370986603

Epoch: 6| Step: 10
Training loss: 0.1085342467185671
Validation loss: 2.5228779231178464

Epoch: 6| Step: 11
Training loss: 0.0940761654137657
Validation loss: 2.5428389299102876

Epoch: 6| Step: 12
Training loss: 0.19296432366487656
Validation loss: 2.5096379875157826

Epoch: 6| Step: 13
Training loss: 0.12158055285432032
Validation loss: 2.5080375525681022

Epoch: 617| Step: 0
Training loss: 0.15297145394964012
Validation loss: 2.5268514140669573

Epoch: 6| Step: 1
Training loss: 0.1091559123185005
Validation loss: 2.4835712682946713

Epoch: 6| Step: 2
Training loss: 0.15300800320552796
Validation loss: 2.4869455196194297

Epoch: 6| Step: 3
Training loss: 0.07358333610142789
Validation loss: 2.500248625913162

Epoch: 6| Step: 4
Training loss: 0.07235802079203942
Validation loss: 2.500873675528843

Epoch: 6| Step: 5
Training loss: 0.1305242917053507
Validation loss: 2.491969168421057

Epoch: 6| Step: 6
Training loss: 0.15828361935927437
Validation loss: 2.4944150047204197

Epoch: 6| Step: 7
Training loss: 0.22583017710090736
Validation loss: 2.513614516362311

Epoch: 6| Step: 8
Training loss: 0.09616300483101516
Validation loss: 2.536456509326054

Epoch: 6| Step: 9
Training loss: 0.11822883154979831
Validation loss: 2.535694969562798

Epoch: 6| Step: 10
Training loss: 0.10748583450108379
Validation loss: 2.5247104453572327

Epoch: 6| Step: 11
Training loss: 0.10588821250606908
Validation loss: 2.5442011522383154

Epoch: 6| Step: 12
Training loss: 0.09406663650307728
Validation loss: 2.540669011585695

Epoch: 6| Step: 13
Training loss: 0.1952318024818831
Validation loss: 2.551716942737317

Epoch: 618| Step: 0
Training loss: 0.15773692138906442
Validation loss: 2.5612911851726037

Epoch: 6| Step: 1
Training loss: 0.14825872899421638
Validation loss: 2.5852334110171196

Epoch: 6| Step: 2
Training loss: 0.14106416342425943
Validation loss: 2.577970191978816

Epoch: 6| Step: 3
Training loss: 0.16436264421345137
Validation loss: 2.5662420039246197

Epoch: 6| Step: 4
Training loss: 0.1109424653755399
Validation loss: 2.5348350045426313

Epoch: 6| Step: 5
Training loss: 0.17739149702831053
Validation loss: 2.520080528917701

Epoch: 6| Step: 6
Training loss: 0.10411052879954831
Validation loss: 2.5346565860849526

Epoch: 6| Step: 7
Training loss: 0.11199609818830591
Validation loss: 2.5198748376624778

Epoch: 6| Step: 8
Training loss: 0.09634802987772292
Validation loss: 2.539886699275055

Epoch: 6| Step: 9
Training loss: 0.18386220581230328
Validation loss: 2.5059043226703674

Epoch: 6| Step: 10
Training loss: 0.10240164131361633
Validation loss: 2.495320826470005

Epoch: 6| Step: 11
Training loss: 0.11024580588710524
Validation loss: 2.5045218376585137

Epoch: 6| Step: 12
Training loss: 0.11617582255456652
Validation loss: 2.4747494160845913

Epoch: 6| Step: 13
Training loss: 0.0928595845645194
Validation loss: 2.496857802934154

Epoch: 619| Step: 0
Training loss: 0.1386605916335457
Validation loss: 2.471710986544214

Epoch: 6| Step: 1
Training loss: 0.17564480042073746
Validation loss: 2.497186796608619

Epoch: 6| Step: 2
Training loss: 0.1757479954099219
Validation loss: 2.521905934930797

Epoch: 6| Step: 3
Training loss: 0.07803339952594966
Validation loss: 2.5209804001488276

Epoch: 6| Step: 4
Training loss: 0.17753789332710931
Validation loss: 2.5261717748969468

Epoch: 6| Step: 5
Training loss: 0.17251122369050176
Validation loss: 2.5684338827752886

Epoch: 6| Step: 6
Training loss: 0.16094195304191272
Validation loss: 2.569854522976127

Epoch: 6| Step: 7
Training loss: 0.15252874830398763
Validation loss: 2.574590606673072

Epoch: 6| Step: 8
Training loss: 0.1374627306670262
Validation loss: 2.566381326765637

Epoch: 6| Step: 9
Training loss: 0.16551362602534223
Validation loss: 2.5743162926630077

Epoch: 6| Step: 10
Training loss: 0.0944578202818357
Validation loss: 2.5656422133783403

Epoch: 6| Step: 11
Training loss: 0.14696905695668017
Validation loss: 2.5880083843858124

Epoch: 6| Step: 12
Training loss: 0.16366123902352167
Validation loss: 2.594807883140854

Epoch: 6| Step: 13
Training loss: 0.07535004796196368
Validation loss: 2.5926343937997194

Epoch: 620| Step: 0
Training loss: 0.09718755783373716
Validation loss: 2.6061862253427788

Epoch: 6| Step: 1
Training loss: 0.16062041800268287
Validation loss: 2.5689607096340623

Epoch: 6| Step: 2
Training loss: 0.13984941146088806
Validation loss: 2.5885189673811175

Epoch: 6| Step: 3
Training loss: 0.099683803912855
Validation loss: 2.538649803174873

Epoch: 6| Step: 4
Training loss: 0.1615461769380402
Validation loss: 2.5707200290159506

Epoch: 6| Step: 5
Training loss: 0.07983415061163437
Validation loss: 2.589030803773777

Epoch: 6| Step: 6
Training loss: 0.15059941524647608
Validation loss: 2.555299182236279

Epoch: 6| Step: 7
Training loss: 0.16890614116111163
Validation loss: 2.538658959415208

Epoch: 6| Step: 8
Training loss: 0.07211807691839532
Validation loss: 2.5083718989407613

Epoch: 6| Step: 9
Training loss: 0.16653248605969154
Validation loss: 2.56262678427483

Epoch: 6| Step: 10
Training loss: 0.18645274235602943
Validation loss: 2.533709772747213

Epoch: 6| Step: 11
Training loss: 0.13902262533904045
Validation loss: 2.535292782363408

Epoch: 6| Step: 12
Training loss: 0.2507176529528578
Validation loss: 2.5414458709653847

Epoch: 6| Step: 13
Training loss: 0.08284446688622099
Validation loss: 2.4986283077051703

Epoch: 621| Step: 0
Training loss: 0.10604983541724525
Validation loss: 2.518409759092754

Epoch: 6| Step: 1
Training loss: 0.1077867812426568
Validation loss: 2.5601333566221274

Epoch: 6| Step: 2
Training loss: 0.21743373291598903
Validation loss: 2.5721246693493707

Epoch: 6| Step: 3
Training loss: 0.16417221533367096
Validation loss: 2.561243989986122

Epoch: 6| Step: 4
Training loss: 0.30895171348509015
Validation loss: 2.552200074295576

Epoch: 6| Step: 5
Training loss: 0.13169865701581923
Validation loss: 2.5449731005180993

Epoch: 6| Step: 6
Training loss: 0.0963472179106696
Validation loss: 2.5331689793694543

Epoch: 6| Step: 7
Training loss: 0.14152022031432934
Validation loss: 2.530845451765863

Epoch: 6| Step: 8
Training loss: 0.2271287845627976
Validation loss: 2.5267261514402195

Epoch: 6| Step: 9
Training loss: 0.20909523029171131
Validation loss: 2.536739349885433

Epoch: 6| Step: 10
Training loss: 0.28283562328585754
Validation loss: 2.4891128030171497

Epoch: 6| Step: 11
Training loss: 0.2048564166583611
Validation loss: 2.5134395690227214

Epoch: 6| Step: 12
Training loss: 0.2147226859497989
Validation loss: 2.493035194576695

Epoch: 6| Step: 13
Training loss: 0.19044615845485113
Validation loss: 2.513168683751146

Epoch: 622| Step: 0
Training loss: 0.1890207252378802
Validation loss: 2.4916137992676473

Epoch: 6| Step: 1
Training loss: 0.22175643029453307
Validation loss: 2.5330147971092574

Epoch: 6| Step: 2
Training loss: 0.21703784026321554
Validation loss: 2.577483028707174

Epoch: 6| Step: 3
Training loss: 0.20802921310443032
Validation loss: 2.622551200159891

Epoch: 6| Step: 4
Training loss: 0.2370391820361194
Validation loss: 2.5939358588932167

Epoch: 6| Step: 5
Training loss: 0.23115102350964328
Validation loss: 2.6077884736053445

Epoch: 6| Step: 6
Training loss: 0.17923187457237655
Validation loss: 2.5694817554085954

Epoch: 6| Step: 7
Training loss: 0.1881462325347201
Validation loss: 2.5785037322178

Epoch: 6| Step: 8
Training loss: 0.20269035640589422
Validation loss: 2.570109654878673

Epoch: 6| Step: 9
Training loss: 0.1895937446907361
Validation loss: 2.518930773521618

Epoch: 6| Step: 10
Training loss: 0.14771486360276667
Validation loss: 2.5527061728671376

Epoch: 6| Step: 11
Training loss: 0.30665099982915495
Validation loss: 2.5406489194706072

Epoch: 6| Step: 12
Training loss: 0.1439998109463603
Validation loss: 2.5258852146634525

Epoch: 6| Step: 13
Training loss: 0.17715122637083314
Validation loss: 2.5197552864277406

Epoch: 623| Step: 0
Training loss: 0.16897615801638335
Validation loss: 2.554233781806387

Epoch: 6| Step: 1
Training loss: 0.15987549573763296
Validation loss: 2.569218423871189

Epoch: 6| Step: 2
Training loss: 0.18576314268427757
Validation loss: 2.554682901937825

Epoch: 6| Step: 3
Training loss: 0.23897317576409985
Validation loss: 2.532815878059409

Epoch: 6| Step: 4
Training loss: 0.21290744050136967
Validation loss: 2.531930940999477

Epoch: 6| Step: 5
Training loss: 0.14411765279925876
Validation loss: 2.579687900831005

Epoch: 6| Step: 6
Training loss: 0.1625378301033324
Validation loss: 2.549740301199112

Epoch: 6| Step: 7
Training loss: 0.1821237721882881
Validation loss: 2.5677321188161857

Epoch: 6| Step: 8
Training loss: 0.199889288747605
Validation loss: 2.5345203395866487

Epoch: 6| Step: 9
Training loss: 0.20511795747024364
Validation loss: 2.559287443780259

Epoch: 6| Step: 10
Training loss: 0.19128111232496472
Validation loss: 2.5159552379117596

Epoch: 6| Step: 11
Training loss: 0.17551127470478672
Validation loss: 2.5324838735989017

Epoch: 6| Step: 12
Training loss: 0.18261342376257564
Validation loss: 2.5134189292732247

Epoch: 6| Step: 13
Training loss: 0.11703621317750772
Validation loss: 2.511425994044066

Epoch: 624| Step: 0
Training loss: 0.1731184606831963
Validation loss: 2.5186062620059655

Epoch: 6| Step: 1
Training loss: 0.16822362015697268
Validation loss: 2.5210172104255837

Epoch: 6| Step: 2
Training loss: 0.11327732835755934
Validation loss: 2.5420973634923563

Epoch: 6| Step: 3
Training loss: 0.11123665180386602
Validation loss: 2.524429287413012

Epoch: 6| Step: 4
Training loss: 0.20941205693163167
Validation loss: 2.5407814526534054

Epoch: 6| Step: 5
Training loss: 0.21487875566534653
Validation loss: 2.523218790863575

Epoch: 6| Step: 6
Training loss: 0.12633450983269442
Validation loss: 2.5207352296687198

Epoch: 6| Step: 7
Training loss: 0.2572971597592212
Validation loss: 2.5044683987749465

Epoch: 6| Step: 8
Training loss: 0.2420747248278402
Validation loss: 2.5331551975201467

Epoch: 6| Step: 9
Training loss: 0.1552479921040635
Validation loss: 2.5331961522041295

Epoch: 6| Step: 10
Training loss: 0.12937716961391327
Validation loss: 2.522121727333809

Epoch: 6| Step: 11
Training loss: 0.11841373234059963
Validation loss: 2.543096329561767

Epoch: 6| Step: 12
Training loss: 0.18311400330045116
Validation loss: 2.5795890084465474

Epoch: 6| Step: 13
Training loss: 0.1415434882679666
Validation loss: 2.576606607141383

Epoch: 625| Step: 0
Training loss: 0.21066765832900233
Validation loss: 2.5809161706617587

Epoch: 6| Step: 1
Training loss: 0.3087216848447642
Validation loss: 2.5994887570972005

Epoch: 6| Step: 2
Training loss: 0.1337015185770632
Validation loss: 2.616703229243382

Epoch: 6| Step: 3
Training loss: 0.1751039755979226
Validation loss: 2.623456951656717

Epoch: 6| Step: 4
Training loss: 0.11016572647726322
Validation loss: 2.603111400952072

Epoch: 6| Step: 5
Training loss: 0.20910228540276687
Validation loss: 2.6131520465529

Epoch: 6| Step: 6
Training loss: 0.2919600095848226
Validation loss: 2.6021737543371426

Epoch: 6| Step: 7
Training loss: 0.11346838965998286
Validation loss: 2.5711083687182206

Epoch: 6| Step: 8
Training loss: 0.10959220504324413
Validation loss: 2.56480860069458

Epoch: 6| Step: 9
Training loss: 0.15141900929010624
Validation loss: 2.544250513054561

Epoch: 6| Step: 10
Training loss: 0.15920621849773778
Validation loss: 2.522772177040201

Epoch: 6| Step: 11
Training loss: 0.1484287723685924
Validation loss: 2.564416911221384

Epoch: 6| Step: 12
Training loss: 0.10968408168998155
Validation loss: 2.5206993890857716

Epoch: 6| Step: 13
Training loss: 0.10816249428849033
Validation loss: 2.506313318888806

Epoch: 626| Step: 0
Training loss: 0.10431326940891572
Validation loss: 2.506143314927509

Epoch: 6| Step: 1
Training loss: 0.12583362247210667
Validation loss: 2.510725344912844

Epoch: 6| Step: 2
Training loss: 0.16817143321083375
Validation loss: 2.504804617093765

Epoch: 6| Step: 3
Training loss: 0.11094364481684534
Validation loss: 2.532685937382819

Epoch: 6| Step: 4
Training loss: 0.2029899368211278
Validation loss: 2.501771450014921

Epoch: 6| Step: 5
Training loss: 0.09042319775027989
Validation loss: 2.5246561188052197

Epoch: 6| Step: 6
Training loss: 0.1849223820784546
Validation loss: 2.5328390171755863

Epoch: 6| Step: 7
Training loss: 0.15589620948485966
Validation loss: 2.525065978658476

Epoch: 6| Step: 8
Training loss: 0.1441253555811245
Validation loss: 2.5379208303743086

Epoch: 6| Step: 9
Training loss: 0.13063839858527826
Validation loss: 2.5694978207542154

Epoch: 6| Step: 10
Training loss: 0.14334103521550193
Validation loss: 2.5480151070293293

Epoch: 6| Step: 11
Training loss: 0.15293594337812338
Validation loss: 2.554500947706158

Epoch: 6| Step: 12
Training loss: 0.17469846172436146
Validation loss: 2.565246658694162

Epoch: 6| Step: 13
Training loss: 0.1146358325469177
Validation loss: 2.5769827312495237

Epoch: 627| Step: 0
Training loss: 0.186012647173172
Validation loss: 2.578060970462165

Epoch: 6| Step: 1
Training loss: 0.13968023191655626
Validation loss: 2.591092575514478

Epoch: 6| Step: 2
Training loss: 0.09045213499003527
Validation loss: 2.5629737210035937

Epoch: 6| Step: 3
Training loss: 0.15804766445933857
Validation loss: 2.5575303600225654

Epoch: 6| Step: 4
Training loss: 0.10617543489636797
Validation loss: 2.5352529450465884

Epoch: 6| Step: 5
Training loss: 0.1335969785110577
Validation loss: 2.51632915372268

Epoch: 6| Step: 6
Training loss: 0.10554251034265517
Validation loss: 2.5201486677940674

Epoch: 6| Step: 7
Training loss: 0.14655714135042694
Validation loss: 2.5297292797349122

Epoch: 6| Step: 8
Training loss: 0.12479591473116466
Validation loss: 2.5202920980653625

Epoch: 6| Step: 9
Training loss: 0.1783437030405157
Validation loss: 2.5407044741040035

Epoch: 6| Step: 10
Training loss: 0.1767583183154883
Validation loss: 2.527578874185011

Epoch: 6| Step: 11
Training loss: 0.16562113734905365
Validation loss: 2.504232031200302

Epoch: 6| Step: 12
Training loss: 0.11576568833559342
Validation loss: 2.491396098094883

Epoch: 6| Step: 13
Training loss: 0.11871461058617558
Validation loss: 2.5259796014858704

Epoch: 628| Step: 0
Training loss: 0.1615336432225255
Validation loss: 2.532714748096103

Epoch: 6| Step: 1
Training loss: 0.17750478944562706
Validation loss: 2.5123711093523635

Epoch: 6| Step: 2
Training loss: 0.2654165684347006
Validation loss: 2.511689206479411

Epoch: 6| Step: 3
Training loss: 0.13665539090837142
Validation loss: 2.552161256773738

Epoch: 6| Step: 4
Training loss: 0.16947846272030662
Validation loss: 2.5753449954886514

Epoch: 6| Step: 5
Training loss: 0.11413441213556998
Validation loss: 2.5568684915618936

Epoch: 6| Step: 6
Training loss: 0.18201747891312647
Validation loss: 2.591056869611268

Epoch: 6| Step: 7
Training loss: 0.1317765349321886
Validation loss: 2.6052283638471887

Epoch: 6| Step: 8
Training loss: 0.1200607446316824
Validation loss: 2.544300682017139

Epoch: 6| Step: 9
Training loss: 0.09271630987756378
Validation loss: 2.5699069344027916

Epoch: 6| Step: 10
Training loss: 0.11675356154298576
Validation loss: 2.5747759791971654

Epoch: 6| Step: 11
Training loss: 0.14758493881287515
Validation loss: 2.5301811141988733

Epoch: 6| Step: 12
Training loss: 0.09769775938945416
Validation loss: 2.5426443678258943

Epoch: 6| Step: 13
Training loss: 0.1014816668591798
Validation loss: 2.5258178050173257

Epoch: 629| Step: 0
Training loss: 0.10646876680448471
Validation loss: 2.5259310837798403

Epoch: 6| Step: 1
Training loss: 0.11232667790604517
Validation loss: 2.5290932774245616

Epoch: 6| Step: 2
Training loss: 0.08043610410583205
Validation loss: 2.5573313635036192

Epoch: 6| Step: 3
Training loss: 0.12717884245141306
Validation loss: 2.5192068672254195

Epoch: 6| Step: 4
Training loss: 0.1887699472548099
Validation loss: 2.5238032140601248

Epoch: 6| Step: 5
Training loss: 0.1654971441216275
Validation loss: 2.527651538293692

Epoch: 6| Step: 6
Training loss: 0.08243124940180781
Validation loss: 2.5307387414612803

Epoch: 6| Step: 7
Training loss: 0.07901981038072506
Validation loss: 2.5499571136111108

Epoch: 6| Step: 8
Training loss: 0.10233815811255936
Validation loss: 2.5442694794368306

Epoch: 6| Step: 9
Training loss: 0.19070183307752375
Validation loss: 2.5246988918858446

Epoch: 6| Step: 10
Training loss: 0.15447701429083863
Validation loss: 2.535208860005319

Epoch: 6| Step: 11
Training loss: 0.12326700335546883
Validation loss: 2.571712265973577

Epoch: 6| Step: 12
Training loss: 0.17425883435016207
Validation loss: 2.596014989656964

Epoch: 6| Step: 13
Training loss: 0.10841451989544927
Validation loss: 2.5885255603920987

Epoch: 630| Step: 0
Training loss: 0.09612234899563432
Validation loss: 2.546820164803648

Epoch: 6| Step: 1
Training loss: 0.1909806326738481
Validation loss: 2.62384167129314

Epoch: 6| Step: 2
Training loss: 0.11555750848874137
Validation loss: 2.558838922933728

Epoch: 6| Step: 3
Training loss: 0.1366305407297567
Validation loss: 2.583345887202928

Epoch: 6| Step: 4
Training loss: 0.159537293976296
Validation loss: 2.575933692188279

Epoch: 6| Step: 5
Training loss: 0.14323788674136975
Validation loss: 2.5325946505135457

Epoch: 6| Step: 6
Training loss: 0.10826018684538016
Validation loss: 2.5297555323653476

Epoch: 6| Step: 7
Training loss: 0.14755924686714006
Validation loss: 2.5146049969659714

Epoch: 6| Step: 8
Training loss: 0.19568336562190877
Validation loss: 2.5308060696708274

Epoch: 6| Step: 9
Training loss: 0.12334323192784344
Validation loss: 2.5407797898259528

Epoch: 6| Step: 10
Training loss: 0.08425651306119485
Validation loss: 2.5389353356965234

Epoch: 6| Step: 11
Training loss: 0.07927841561253765
Validation loss: 2.52071894405902

Epoch: 6| Step: 12
Training loss: 0.1122557574948267
Validation loss: 2.511226682849589

Epoch: 6| Step: 13
Training loss: 0.08470513761029641
Validation loss: 2.5225021511831223

Epoch: 631| Step: 0
Training loss: 0.10593428125808599
Validation loss: 2.5160931718630444

Epoch: 6| Step: 1
Training loss: 0.12419638627348747
Validation loss: 2.524864739753148

Epoch: 6| Step: 2
Training loss: 0.18303134689536907
Validation loss: 2.5769212723666772

Epoch: 6| Step: 3
Training loss: 0.10870118864033787
Validation loss: 2.5521680270806373

Epoch: 6| Step: 4
Training loss: 0.14468308154706833
Validation loss: 2.543552143809095

Epoch: 6| Step: 5
Training loss: 0.12569935187822892
Validation loss: 2.5701468417725937

Epoch: 6| Step: 6
Training loss: 0.1450339030841193
Validation loss: 2.5603834205349423

Epoch: 6| Step: 7
Training loss: 0.09425846931174928
Validation loss: 2.572860905155667

Epoch: 6| Step: 8
Training loss: 0.12366693426590154
Validation loss: 2.5533746719960506

Epoch: 6| Step: 9
Training loss: 0.09508327294661743
Validation loss: 2.5286195588743086

Epoch: 6| Step: 10
Training loss: 0.11174514532051791
Validation loss: 2.5375273505793396

Epoch: 6| Step: 11
Training loss: 0.09164863141687853
Validation loss: 2.5363539538047655

Epoch: 6| Step: 12
Training loss: 0.10277227493144753
Validation loss: 2.5305168217269842

Epoch: 6| Step: 13
Training loss: 0.17040881727506899
Validation loss: 2.510280464680486

Epoch: 632| Step: 0
Training loss: 0.12439846797445152
Validation loss: 2.5177515567894133

Epoch: 6| Step: 1
Training loss: 0.15229984408805503
Validation loss: 2.480275916162593

Epoch: 6| Step: 2
Training loss: 0.11197111928840822
Validation loss: 2.5049597747959647

Epoch: 6| Step: 3
Training loss: 0.15872285384580656
Validation loss: 2.4852095971987933

Epoch: 6| Step: 4
Training loss: 0.16231574859753978
Validation loss: 2.502367517564498

Epoch: 6| Step: 5
Training loss: 0.09301900987699675
Validation loss: 2.5150974479481603

Epoch: 6| Step: 6
Training loss: 0.1391241729794005
Validation loss: 2.5144279616374963

Epoch: 6| Step: 7
Training loss: 0.09741101945539812
Validation loss: 2.51960145700352

Epoch: 6| Step: 8
Training loss: 0.1500765629914954
Validation loss: 2.5507163998874574

Epoch: 6| Step: 9
Training loss: 0.11456852423452285
Validation loss: 2.528445919968222

Epoch: 6| Step: 10
Training loss: 0.17490229731760948
Validation loss: 2.529025502196656

Epoch: 6| Step: 11
Training loss: 0.1231451815013976
Validation loss: 2.542982762954997

Epoch: 6| Step: 12
Training loss: 0.15029624975042488
Validation loss: 2.5520452306103394

Epoch: 6| Step: 13
Training loss: 0.1221758310119272
Validation loss: 2.552040479114814

Epoch: 633| Step: 0
Training loss: 0.11600965009260633
Validation loss: 2.5737731877629786

Epoch: 6| Step: 1
Training loss: 0.1523943108017387
Validation loss: 2.520664841171846

Epoch: 6| Step: 2
Training loss: 0.19057067151626764
Validation loss: 2.52648012098224

Epoch: 6| Step: 3
Training loss: 0.18184103215964967
Validation loss: 2.5211608317698624

Epoch: 6| Step: 4
Training loss: 0.07077941901110299
Validation loss: 2.5315105183139477

Epoch: 6| Step: 5
Training loss: 0.13206447995746626
Validation loss: 2.5246203932890503

Epoch: 6| Step: 6
Training loss: 0.15311473987226268
Validation loss: 2.5221681212774714

Epoch: 6| Step: 7
Training loss: 0.10103088408220116
Validation loss: 2.5304902279815016

Epoch: 6| Step: 8
Training loss: 0.14543311230573983
Validation loss: 2.5310486622673345

Epoch: 6| Step: 9
Training loss: 0.17359357718829077
Validation loss: 2.516965506509241

Epoch: 6| Step: 10
Training loss: 0.09104502473224091
Validation loss: 2.497831800032234

Epoch: 6| Step: 11
Training loss: 0.1203914511786549
Validation loss: 2.5455928705509363

Epoch: 6| Step: 12
Training loss: 0.2509513426700129
Validation loss: 2.53743849394432

Epoch: 6| Step: 13
Training loss: 0.20910365720227406
Validation loss: 2.553229229453389

Epoch: 634| Step: 0
Training loss: 0.09569852195102095
Validation loss: 2.5144504543173274

Epoch: 6| Step: 1
Training loss: 0.1668504314070798
Validation loss: 2.553674576405438

Epoch: 6| Step: 2
Training loss: 0.08099508966983056
Validation loss: 2.512383890935783

Epoch: 6| Step: 3
Training loss: 0.16222534857115947
Validation loss: 2.5277814162667367

Epoch: 6| Step: 4
Training loss: 0.13156081562141927
Validation loss: 2.5121118310065516

Epoch: 6| Step: 5
Training loss: 0.16331696279466923
Validation loss: 2.498468120451725

Epoch: 6| Step: 6
Training loss: 0.09048930730141233
Validation loss: 2.4949459271690646

Epoch: 6| Step: 7
Training loss: 0.12396114016274892
Validation loss: 2.4839965362808702

Epoch: 6| Step: 8
Training loss: 0.1398538532550008
Validation loss: 2.527271236301146

Epoch: 6| Step: 9
Training loss: 0.10112067090406318
Validation loss: 2.5411796735359924

Epoch: 6| Step: 10
Training loss: 0.17702697577034535
Validation loss: 2.5475452491629875

Epoch: 6| Step: 11
Training loss: 0.16953475197018525
Validation loss: 2.564065570032967

Epoch: 6| Step: 12
Training loss: 0.10341925003367511
Validation loss: 2.5788006287232617

Epoch: 6| Step: 13
Training loss: 0.15438306187996173
Validation loss: 2.576119860721458

Epoch: 635| Step: 0
Training loss: 0.15475018223488327
Validation loss: 2.5947332365636457

Epoch: 6| Step: 1
Training loss: 0.11423327924343478
Validation loss: 2.604651755816709

Epoch: 6| Step: 2
Training loss: 0.10280669118391268
Validation loss: 2.5807035049257494

Epoch: 6| Step: 3
Training loss: 0.18006870013416346
Validation loss: 2.5880981139241834

Epoch: 6| Step: 4
Training loss: 0.10017374449779255
Validation loss: 2.56704280127092

Epoch: 6| Step: 5
Training loss: 0.20847935129165543
Validation loss: 2.576877749462487

Epoch: 6| Step: 6
Training loss: 0.09489788215294451
Validation loss: 2.559352259020476

Epoch: 6| Step: 7
Training loss: 0.1152871948352511
Validation loss: 2.520198320670485

Epoch: 6| Step: 8
Training loss: 0.0772162784999489
Validation loss: 2.5114939094023363

Epoch: 6| Step: 9
Training loss: 0.10749103747199805
Validation loss: 2.500940394168152

Epoch: 6| Step: 10
Training loss: 0.17468874831939316
Validation loss: 2.483015275870554

Epoch: 6| Step: 11
Training loss: 0.08106788562271644
Validation loss: 2.5104673660735233

Epoch: 6| Step: 12
Training loss: 0.1613390787206844
Validation loss: 2.5071117316636946

Epoch: 6| Step: 13
Training loss: 0.10150318522781686
Validation loss: 2.4806093387490056

Epoch: 636| Step: 0
Training loss: 0.11577931558225998
Validation loss: 2.4782953369282974

Epoch: 6| Step: 1
Training loss: 0.14074977663718638
Validation loss: 2.5006785471728548

Epoch: 6| Step: 2
Training loss: 0.13545354851346172
Validation loss: 2.485969932349077

Epoch: 6| Step: 3
Training loss: 0.09843789566051349
Validation loss: 2.515209265809233

Epoch: 6| Step: 4
Training loss: 0.15737694603199312
Validation loss: 2.5341062748018923

Epoch: 6| Step: 5
Training loss: 0.10789975595196956
Validation loss: 2.5709034579220043

Epoch: 6| Step: 6
Training loss: 0.0809592265117899
Validation loss: 2.565517372808712

Epoch: 6| Step: 7
Training loss: 0.15900665075597165
Validation loss: 2.596712214105339

Epoch: 6| Step: 8
Training loss: 0.2005497284089206
Validation loss: 2.5951741634522945

Epoch: 6| Step: 9
Training loss: 0.1537712415117732
Validation loss: 2.5464237773957294

Epoch: 6| Step: 10
Training loss: 0.1670214532560962
Validation loss: 2.5669958211869575

Epoch: 6| Step: 11
Training loss: 0.12506697767669084
Validation loss: 2.560787099644193

Epoch: 6| Step: 12
Training loss: 0.1536369213386025
Validation loss: 2.5861119666667824

Epoch: 6| Step: 13
Training loss: 0.10219169543196108
Validation loss: 2.5181659290501646

Epoch: 637| Step: 0
Training loss: 0.08748107965302471
Validation loss: 2.563237460047288

Epoch: 6| Step: 1
Training loss: 0.09153106432993907
Validation loss: 2.585629424924079

Epoch: 6| Step: 2
Training loss: 0.08270836278933298
Validation loss: 2.5345287308894022

Epoch: 6| Step: 3
Training loss: 0.17340283391079367
Validation loss: 2.558943882374718

Epoch: 6| Step: 4
Training loss: 0.12847146490091488
Validation loss: 2.5470025922496022

Epoch: 6| Step: 5
Training loss: 0.18310157263107524
Validation loss: 2.544692926075934

Epoch: 6| Step: 6
Training loss: 0.11699731812347981
Validation loss: 2.5556973433347645

Epoch: 6| Step: 7
Training loss: 0.08405324418755529
Validation loss: 2.6007815115704975

Epoch: 6| Step: 8
Training loss: 0.11024526523351348
Validation loss: 2.581615977378891

Epoch: 6| Step: 9
Training loss: 0.17149672822187798
Validation loss: 2.5970313276036356

Epoch: 6| Step: 10
Training loss: 0.1402455614988995
Validation loss: 2.619241472773479

Epoch: 6| Step: 11
Training loss: 0.1271092848258704
Validation loss: 2.6264682488039766

Epoch: 6| Step: 12
Training loss: 0.1075461535708788
Validation loss: 2.5949663210492866

Epoch: 6| Step: 13
Training loss: 0.28737244264145895
Validation loss: 2.5908509969997913

Epoch: 638| Step: 0
Training loss: 0.13632159449722034
Validation loss: 2.5732135356490944

Epoch: 6| Step: 1
Training loss: 0.15835804477164944
Validation loss: 2.574453896950482

Epoch: 6| Step: 2
Training loss: 0.19489741085854162
Validation loss: 2.556128401202975

Epoch: 6| Step: 3
Training loss: 0.07379670988513083
Validation loss: 2.537617244665889

Epoch: 6| Step: 4
Training loss: 0.11417066478414124
Validation loss: 2.5637242093880945

Epoch: 6| Step: 5
Training loss: 0.1340620777594757
Validation loss: 2.5540689973612563

Epoch: 6| Step: 6
Training loss: 0.16303994906620983
Validation loss: 2.5594947714496095

Epoch: 6| Step: 7
Training loss: 0.10680115567706736
Validation loss: 2.551744236788787

Epoch: 6| Step: 8
Training loss: 0.16428886419439667
Validation loss: 2.547872476219112

Epoch: 6| Step: 9
Training loss: 0.11892326257086895
Validation loss: 2.535442756337068

Epoch: 6| Step: 10
Training loss: 0.15621112101363563
Validation loss: 2.5545760764483347

Epoch: 6| Step: 11
Training loss: 0.15324725700587044
Validation loss: 2.5521656745517007

Epoch: 6| Step: 12
Training loss: 0.22737201403554613
Validation loss: 2.535620121063616

Epoch: 6| Step: 13
Training loss: 0.22887626132534195
Validation loss: 2.540601068881538

Epoch: 639| Step: 0
Training loss: 0.10885754865962545
Validation loss: 2.521217622672254

Epoch: 6| Step: 1
Training loss: 0.13689267131528646
Validation loss: 2.534834630337958

Epoch: 6| Step: 2
Training loss: 0.10177180840126984
Validation loss: 2.5182806555395354

Epoch: 6| Step: 3
Training loss: 0.12128971763102196
Validation loss: 2.520360351248208

Epoch: 6| Step: 4
Training loss: 0.17252503820643314
Validation loss: 2.5480614581227345

Epoch: 6| Step: 5
Training loss: 0.19467842172731445
Validation loss: 2.5667704891892424

Epoch: 6| Step: 6
Training loss: 0.14533232020495623
Validation loss: 2.535196632366874

Epoch: 6| Step: 7
Training loss: 0.167219704128916
Validation loss: 2.557872198482392

Epoch: 6| Step: 8
Training loss: 0.10578845717277566
Validation loss: 2.5359503845603664

Epoch: 6| Step: 9
Training loss: 0.10481185679559675
Validation loss: 2.5582329463179025

Epoch: 6| Step: 10
Training loss: 0.2301627082980388
Validation loss: 2.567063837767418

Epoch: 6| Step: 11
Training loss: 0.1397014730620561
Validation loss: 2.576112313448772

Epoch: 6| Step: 12
Training loss: 0.13706607977310137
Validation loss: 2.5672741298416413

Epoch: 6| Step: 13
Training loss: 0.14740405975228507
Validation loss: 2.5792042521377265

Epoch: 640| Step: 0
Training loss: 0.13699836067668567
Validation loss: 2.57889748314865

Epoch: 6| Step: 1
Training loss: 0.09552083852983556
Validation loss: 2.6167088959468945

Epoch: 6| Step: 2
Training loss: 0.09491981378522966
Validation loss: 2.591606535416932

Epoch: 6| Step: 3
Training loss: 0.14004774957843644
Validation loss: 2.568557340972383

Epoch: 6| Step: 4
Training loss: 0.15275135287389685
Validation loss: 2.6198439542204337

Epoch: 6| Step: 5
Training loss: 0.14210284065503526
Validation loss: 2.5895621745352826

Epoch: 6| Step: 6
Training loss: 0.11576365295977402
Validation loss: 2.5959662131559242

Epoch: 6| Step: 7
Training loss: 0.20917126507726094
Validation loss: 2.556141363152598

Epoch: 6| Step: 8
Training loss: 0.09593709255964511
Validation loss: 2.537733032406792

Epoch: 6| Step: 9
Training loss: 0.09256954374661373
Validation loss: 2.5523288145823937

Epoch: 6| Step: 10
Training loss: 0.12746907076429376
Validation loss: 2.5495934877067947

Epoch: 6| Step: 11
Training loss: 0.13387718918022878
Validation loss: 2.535977204101801

Epoch: 6| Step: 12
Training loss: 0.18728392787287443
Validation loss: 2.5439248764171136

Epoch: 6| Step: 13
Training loss: 0.045684755843844176
Validation loss: 2.528028353436043

Epoch: 641| Step: 0
Training loss: 0.12013103436309322
Validation loss: 2.5044785510836363

Epoch: 6| Step: 1
Training loss: 0.159434746080688
Validation loss: 2.524921059996441

Epoch: 6| Step: 2
Training loss: 0.1455916412869751
Validation loss: 2.518914960188507

Epoch: 6| Step: 3
Training loss: 0.14704011401903114
Validation loss: 2.534455445637425

Epoch: 6| Step: 4
Training loss: 0.10473035248468986
Validation loss: 2.5473741980408677

Epoch: 6| Step: 5
Training loss: 0.189372035497495
Validation loss: 2.580236568698257

Epoch: 6| Step: 6
Training loss: 0.13183014468429266
Validation loss: 2.5656594088951676

Epoch: 6| Step: 7
Training loss: 0.13360811094984965
Validation loss: 2.5908967999403614

Epoch: 6| Step: 8
Training loss: 0.2010072200958716
Validation loss: 2.603956477060703

Epoch: 6| Step: 9
Training loss: 0.09190903568423736
Validation loss: 2.610780664123519

Epoch: 6| Step: 10
Training loss: 0.14247592764527506
Validation loss: 2.6047727543217043

Epoch: 6| Step: 11
Training loss: 0.11245464596204102
Validation loss: 2.607916887504355

Epoch: 6| Step: 12
Training loss: 0.11538812515169818
Validation loss: 2.598899063505434

Epoch: 6| Step: 13
Training loss: 0.10277290473866596
Validation loss: 2.587469531622914

Epoch: 642| Step: 0
Training loss: 0.08866502487510056
Validation loss: 2.6049244883474207

Epoch: 6| Step: 1
Training loss: 0.08790814966752203
Validation loss: 2.5650339386298726

Epoch: 6| Step: 2
Training loss: 0.1300679658238964
Validation loss: 2.602139059586136

Epoch: 6| Step: 3
Training loss: 0.09895084587013196
Validation loss: 2.5873688851505876

Epoch: 6| Step: 4
Training loss: 0.2010597453528979
Validation loss: 2.5643582193215684

Epoch: 6| Step: 5
Training loss: 0.1562277658855601
Validation loss: 2.5947294317072593

Epoch: 6| Step: 6
Training loss: 0.11339626146568374
Validation loss: 2.57697123803851

Epoch: 6| Step: 7
Training loss: 0.18933646552828978
Validation loss: 2.5970730616893083

Epoch: 6| Step: 8
Training loss: 0.08174931521212749
Validation loss: 2.5897294863487637

Epoch: 6| Step: 9
Training loss: 0.12525317510846218
Validation loss: 2.5823189261763395

Epoch: 6| Step: 10
Training loss: 0.14137065739838495
Validation loss: 2.5644889913820466

Epoch: 6| Step: 11
Training loss: 0.13237211901804952
Validation loss: 2.6112447289331517

Epoch: 6| Step: 12
Training loss: 0.19532140711501328
Validation loss: 2.6007657360703327

Epoch: 6| Step: 13
Training loss: 0.15386978627567197
Validation loss: 2.5893419607080697

Epoch: 643| Step: 0
Training loss: 0.09139530124463045
Validation loss: 2.5136769086067385

Epoch: 6| Step: 1
Training loss: 0.08059496806789539
Validation loss: 2.5579792646558186

Epoch: 6| Step: 2
Training loss: 0.10985673249118062
Validation loss: 2.565100226246479

Epoch: 6| Step: 3
Training loss: 0.10023054280615253
Validation loss: 2.538381128001846

Epoch: 6| Step: 4
Training loss: 0.09254378957659329
Validation loss: 2.5560833889083185

Epoch: 6| Step: 5
Training loss: 0.15345861186752224
Validation loss: 2.5446518390752053

Epoch: 6| Step: 6
Training loss: 0.09713038959057042
Validation loss: 2.5501119654615323

Epoch: 6| Step: 7
Training loss: 0.11607785578830139
Validation loss: 2.5381627156850657

Epoch: 6| Step: 8
Training loss: 0.14493289761640454
Validation loss: 2.537333422893933

Epoch: 6| Step: 9
Training loss: 0.1656490654825747
Validation loss: 2.54556659544224

Epoch: 6| Step: 10
Training loss: 0.08275233953531097
Validation loss: 2.528373127611299

Epoch: 6| Step: 11
Training loss: 0.15255337744446437
Validation loss: 2.5410887886503755

Epoch: 6| Step: 12
Training loss: 0.09324883077357603
Validation loss: 2.5285355022252243

Epoch: 6| Step: 13
Training loss: 0.21072512991585882
Validation loss: 2.53333587871687

Epoch: 644| Step: 0
Training loss: 0.13582109312283533
Validation loss: 2.5556908466970767

Epoch: 6| Step: 1
Training loss: 0.1000129713645958
Validation loss: 2.533924006504926

Epoch: 6| Step: 2
Training loss: 0.08370666275822704
Validation loss: 2.5291216972496806

Epoch: 6| Step: 3
Training loss: 0.07098439840458713
Validation loss: 2.527033867855855

Epoch: 6| Step: 4
Training loss: 0.1051806603719428
Validation loss: 2.51534522570914

Epoch: 6| Step: 5
Training loss: 0.15037950251680782
Validation loss: 2.5143479535211264

Epoch: 6| Step: 6
Training loss: 0.08731471629220965
Validation loss: 2.4757349276114318

Epoch: 6| Step: 7
Training loss: 0.09212514336288871
Validation loss: 2.5147218187956852

Epoch: 6| Step: 8
Training loss: 0.1511216479407718
Validation loss: 2.4836457050741148

Epoch: 6| Step: 9
Training loss: 0.11447820844269485
Validation loss: 2.5092359532085786

Epoch: 6| Step: 10
Training loss: 0.06547453752305572
Validation loss: 2.5199635811316337

Epoch: 6| Step: 11
Training loss: 0.1368144313607097
Validation loss: 2.481701840452296

Epoch: 6| Step: 12
Training loss: 0.1676645462902262
Validation loss: 2.498061698226836

Epoch: 6| Step: 13
Training loss: 0.1592634308408531
Validation loss: 2.545375356547276

Epoch: 645| Step: 0
Training loss: 0.08034660816913901
Validation loss: 2.5334383692066766

Epoch: 6| Step: 1
Training loss: 0.10904455505944553
Validation loss: 2.5750841550917083

Epoch: 6| Step: 2
Training loss: 0.09035763764232477
Validation loss: 2.5561048310269525

Epoch: 6| Step: 3
Training loss: 0.2200858252047952
Validation loss: 2.6125609168473027

Epoch: 6| Step: 4
Training loss: 0.18755369609622063
Validation loss: 2.5867112442167217

Epoch: 6| Step: 5
Training loss: 0.12666011154421075
Validation loss: 2.5927388028486797

Epoch: 6| Step: 6
Training loss: 0.08564979989386975
Validation loss: 2.5784282268596974

Epoch: 6| Step: 7
Training loss: 0.10020517297005466
Validation loss: 2.5884189430952644

Epoch: 6| Step: 8
Training loss: 0.09619890948624726
Validation loss: 2.5190501613642384

Epoch: 6| Step: 9
Training loss: 0.1088081641009833
Validation loss: 2.5839669273958807

Epoch: 6| Step: 10
Training loss: 0.08689997858956312
Validation loss: 2.4983410514727047

Epoch: 6| Step: 11
Training loss: 0.18702040370764192
Validation loss: 2.5249784328774636

Epoch: 6| Step: 12
Training loss: 0.18411132215195247
Validation loss: 2.5184190535602426

Epoch: 6| Step: 13
Training loss: 0.21352739208861451
Validation loss: 2.5291819325996765

Epoch: 646| Step: 0
Training loss: 0.08610839270517899
Validation loss: 2.528986033979777

Epoch: 6| Step: 1
Training loss: 0.149516886815525
Validation loss: 2.5427475266229767

Epoch: 6| Step: 2
Training loss: 0.12453373733008433
Validation loss: 2.5556156072773324

Epoch: 6| Step: 3
Training loss: 0.1226373206857586
Validation loss: 2.5801947605060347

Epoch: 6| Step: 4
Training loss: 0.145370636354624
Validation loss: 2.5784921384084583

Epoch: 6| Step: 5
Training loss: 0.1193462496920494
Validation loss: 2.5904633739087513

Epoch: 6| Step: 6
Training loss: 0.10743474883184785
Validation loss: 2.5804716764288202

Epoch: 6| Step: 7
Training loss: 0.2406577976589669
Validation loss: 2.5957313913278357

Epoch: 6| Step: 8
Training loss: 0.12964515166961904
Validation loss: 2.582664278729323

Epoch: 6| Step: 9
Training loss: 0.07539442255407493
Validation loss: 2.5249807406803444

Epoch: 6| Step: 10
Training loss: 0.19142316237488405
Validation loss: 2.5194468229787392

Epoch: 6| Step: 11
Training loss: 0.1270231347348198
Validation loss: 2.525300001274864

Epoch: 6| Step: 12
Training loss: 0.130961975755304
Validation loss: 2.5454083770975306

Epoch: 6| Step: 13
Training loss: 0.12893285621263154
Validation loss: 2.559644841747637

Epoch: 647| Step: 0
Training loss: 0.0712128421185565
Validation loss: 2.522878895072047

Epoch: 6| Step: 1
Training loss: 0.15871565413455335
Validation loss: 2.4991004863782527

Epoch: 6| Step: 2
Training loss: 0.10988850198113603
Validation loss: 2.541861457225953

Epoch: 6| Step: 3
Training loss: 0.1034645143322848
Validation loss: 2.553611936128375

Epoch: 6| Step: 4
Training loss: 0.1493178163590346
Validation loss: 2.551042050928419

Epoch: 6| Step: 5
Training loss: 0.23077636330040394
Validation loss: 2.5161514780970977

Epoch: 6| Step: 6
Training loss: 0.10402488944558419
Validation loss: 2.555169830093039

Epoch: 6| Step: 7
Training loss: 0.11735948816455742
Validation loss: 2.5304257924566995

Epoch: 6| Step: 8
Training loss: 0.188140381551762
Validation loss: 2.5638801280637664

Epoch: 6| Step: 9
Training loss: 0.11991393330150973
Validation loss: 2.525908868916838

Epoch: 6| Step: 10
Training loss: 0.13716507674118886
Validation loss: 2.5536423589588546

Epoch: 6| Step: 11
Training loss: 0.11838316898572969
Validation loss: 2.5324580481031376

Epoch: 6| Step: 12
Training loss: 0.08849896132706923
Validation loss: 2.5384085081315853

Epoch: 6| Step: 13
Training loss: 0.13897385423927033
Validation loss: 2.5212122792438665

Epoch: 648| Step: 0
Training loss: 0.13503241737000604
Validation loss: 2.537105841428435

Epoch: 6| Step: 1
Training loss: 0.14784463012044696
Validation loss: 2.5855268843813515

Epoch: 6| Step: 2
Training loss: 0.16537639745927737
Validation loss: 2.6227614960897387

Epoch: 6| Step: 3
Training loss: 0.2535061838893062
Validation loss: 2.611654662623562

Epoch: 6| Step: 4
Training loss: 0.1300964820784777
Validation loss: 2.598466818841197

Epoch: 6| Step: 5
Training loss: 0.13858893425884775
Validation loss: 2.5819260080567883

Epoch: 6| Step: 6
Training loss: 0.18095359284314358
Validation loss: 2.560487510672752

Epoch: 6| Step: 7
Training loss: 0.19588944099739683
Validation loss: 2.5493553412519496

Epoch: 6| Step: 8
Training loss: 0.12435167536005735
Validation loss: 2.5566784259366186

Epoch: 6| Step: 9
Training loss: 0.18612034166474611
Validation loss: 2.521470502850168

Epoch: 6| Step: 10
Training loss: 0.22934960339035593
Validation loss: 2.4968007880628913

Epoch: 6| Step: 11
Training loss: 0.2752121421373287
Validation loss: 2.4897960733788294

Epoch: 6| Step: 12
Training loss: 0.18160298685593051
Validation loss: 2.511583379747325

Epoch: 6| Step: 13
Training loss: 0.14206017515459424
Validation loss: 2.520728748185626

Epoch: 649| Step: 0
Training loss: 0.15586531491541206
Validation loss: 2.5323399210550392

Epoch: 6| Step: 1
Training loss: 0.1060904528620985
Validation loss: 2.513655370247323

Epoch: 6| Step: 2
Training loss: 0.386773789467556
Validation loss: 2.5149128794527758

Epoch: 6| Step: 3
Training loss: 0.33362164793906796
Validation loss: 2.553296647865212

Epoch: 6| Step: 4
Training loss: 0.20957257926404727
Validation loss: 2.5487277631527845

Epoch: 6| Step: 5
Training loss: 0.08539380865540354
Validation loss: 2.5630650671393034

Epoch: 6| Step: 6
Training loss: 0.13395282023457608
Validation loss: 2.5491533052419815

Epoch: 6| Step: 7
Training loss: 0.5737942794052597
Validation loss: 2.537959542462261

Epoch: 6| Step: 8
Training loss: 0.20005207985564566
Validation loss: 2.5421127245311346

Epoch: 6| Step: 9
Training loss: 0.18054624272643913
Validation loss: 2.506856702523643

Epoch: 6| Step: 10
Training loss: 0.19270157909585167
Validation loss: 2.4942379783910464

Epoch: 6| Step: 11
Training loss: 0.25581298291058024
Validation loss: 2.474847147441413

Epoch: 6| Step: 12
Training loss: 0.23710082759879664
Validation loss: 2.5047481065435355

Epoch: 6| Step: 13
Training loss: 0.18883488249613253
Validation loss: 2.502593398605881

Epoch: 650| Step: 0
Training loss: 0.24355395209133346
Validation loss: 2.5092416010590592

Epoch: 6| Step: 1
Training loss: 0.2778681243890128
Validation loss: 2.539151361391871

Epoch: 6| Step: 2
Training loss: 0.24032537551089828
Validation loss: 2.5375197905617313

Epoch: 6| Step: 3
Training loss: 0.1274987015237324
Validation loss: 2.5651044238531644

Epoch: 6| Step: 4
Training loss: 0.20470963933473618
Validation loss: 2.5666959740790416

Epoch: 6| Step: 5
Training loss: 0.24998243091360686
Validation loss: 2.583434986796548

Epoch: 6| Step: 6
Training loss: 0.16091461435575163
Validation loss: 2.5652833834244726

Epoch: 6| Step: 7
Training loss: 0.22073039164945082
Validation loss: 2.52761967072994

Epoch: 6| Step: 8
Training loss: 0.303542713051334
Validation loss: 2.5411862985717124

Epoch: 6| Step: 9
Training loss: 0.1346064470607011
Validation loss: 2.5106550071280935

Epoch: 6| Step: 10
Training loss: 0.22377792381283224
Validation loss: 2.5235752606680313

Epoch: 6| Step: 11
Training loss: 0.16735360704236857
Validation loss: 2.5538135107428728

Epoch: 6| Step: 12
Training loss: 0.24534023061357974
Validation loss: 2.482993974875215

Epoch: 6| Step: 13
Training loss: 0.2352361277271398
Validation loss: 2.545386818182855

Testing loss: 2.4946120822010895
