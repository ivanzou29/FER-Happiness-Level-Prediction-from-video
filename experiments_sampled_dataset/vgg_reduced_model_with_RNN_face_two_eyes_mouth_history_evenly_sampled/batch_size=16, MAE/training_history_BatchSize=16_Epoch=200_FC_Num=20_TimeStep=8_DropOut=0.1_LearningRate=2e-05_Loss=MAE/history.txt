Epoch: 1| Step: 0
Training loss: 5.835212707519531
Validation loss: 5.178332779997138

Epoch: 6| Step: 1
Training loss: 4.400722026824951
Validation loss: 5.159463933719102

Epoch: 6| Step: 2
Training loss: 3.698185920715332
Validation loss: 5.1436267360564205

Epoch: 6| Step: 3
Training loss: 5.001382350921631
Validation loss: 5.126079374744046

Epoch: 6| Step: 4
Training loss: 4.603725910186768
Validation loss: 5.105913510886571

Epoch: 6| Step: 5
Training loss: 5.192929267883301
Validation loss: 5.083344249315159

Epoch: 6| Step: 6
Training loss: 6.470809459686279
Validation loss: 5.05688286853093

Epoch: 6| Step: 7
Training loss: 4.998227596282959
Validation loss: 5.0270356978139565

Epoch: 6| Step: 8
Training loss: 4.6040191650390625
Validation loss: 4.993608649059008

Epoch: 6| Step: 9
Training loss: 3.755679130554199
Validation loss: 4.955430307695942

Epoch: 6| Step: 10
Training loss: 5.478645324707031
Validation loss: 4.912838792288175

Epoch: 6| Step: 11
Training loss: 4.0511980056762695
Validation loss: 4.867135222240161

Epoch: 6| Step: 12
Training loss: 4.525417804718018
Validation loss: 4.815526731552616

Epoch: 6| Step: 13
Training loss: 4.810370445251465
Validation loss: 4.759833482003981

Epoch: 2| Step: 0
Training loss: 5.115895748138428
Validation loss: 4.701646502299975

Epoch: 6| Step: 1
Training loss: 4.695645332336426
Validation loss: 4.644021003477035

Epoch: 6| Step: 2
Training loss: 4.720112323760986
Validation loss: 4.584294580644177

Epoch: 6| Step: 3
Training loss: 4.537797927856445
Validation loss: 4.526249993231989

Epoch: 6| Step: 4
Training loss: 3.5140233039855957
Validation loss: 4.469668406312183

Epoch: 6| Step: 5
Training loss: 4.516458511352539
Validation loss: 4.415718581086846

Epoch: 6| Step: 6
Training loss: 3.459346294403076
Validation loss: 4.363890750433809

Epoch: 6| Step: 7
Training loss: 2.882657051086426
Validation loss: 4.31232697989351

Epoch: 6| Step: 8
Training loss: 4.35396671295166
Validation loss: 4.261414010037658

Epoch: 6| Step: 9
Training loss: 3.533045768737793
Validation loss: 4.209079209194388

Epoch: 6| Step: 10
Training loss: 4.246307849884033
Validation loss: 4.157801428148823

Epoch: 6| Step: 11
Training loss: 3.611933708190918
Validation loss: 4.10830714625697

Epoch: 6| Step: 12
Training loss: 5.172408103942871
Validation loss: 4.055800227708714

Epoch: 6| Step: 13
Training loss: 3.7905986309051514
Validation loss: 4.00498075895412

Epoch: 3| Step: 0
Training loss: 3.3142611980438232
Validation loss: 3.9587476586782806

Epoch: 6| Step: 1
Training loss: 3.282395839691162
Validation loss: 3.9138213024344495

Epoch: 6| Step: 2
Training loss: 3.731968641281128
Validation loss: 3.8745396649965675

Epoch: 6| Step: 3
Training loss: 4.863060474395752
Validation loss: 3.833212996041903

Epoch: 6| Step: 4
Training loss: 4.135160446166992
Validation loss: 3.796080479057886

Epoch: 6| Step: 5
Training loss: 3.1102828979492188
Validation loss: 3.7720467813553347

Epoch: 6| Step: 6
Training loss: 4.184813499450684
Validation loss: 3.7572518061566096

Epoch: 6| Step: 7
Training loss: 4.069169044494629
Validation loss: 3.7318708358272428

Epoch: 6| Step: 8
Training loss: 3.0735926628112793
Validation loss: 3.7009529939261814

Epoch: 6| Step: 9
Training loss: 2.044525623321533
Validation loss: 3.6775203545888266

Epoch: 6| Step: 10
Training loss: 3.339548110961914
Validation loss: 3.653449122623731

Epoch: 6| Step: 11
Training loss: 4.156553268432617
Validation loss: 3.6292831410643873

Epoch: 6| Step: 12
Training loss: 3.2626967430114746
Validation loss: 3.6071497266010573

Epoch: 6| Step: 13
Training loss: 5.050893783569336
Validation loss: 3.5908124677596556

Epoch: 4| Step: 0
Training loss: 1.8792619705200195
Validation loss: 3.5703064216080533

Epoch: 6| Step: 1
Training loss: 4.136753082275391
Validation loss: 3.5498892568772837

Epoch: 6| Step: 2
Training loss: 4.0668487548828125
Validation loss: 3.5293956520736858

Epoch: 6| Step: 3
Training loss: 4.85841703414917
Validation loss: 3.5100717518919256

Epoch: 6| Step: 4
Training loss: 3.2370128631591797
Validation loss: 3.4891684311692432

Epoch: 6| Step: 5
Training loss: 3.761258602142334
Validation loss: 3.4665513602636193

Epoch: 6| Step: 6
Training loss: 2.2981362342834473
Validation loss: 3.446435341271021

Epoch: 6| Step: 7
Training loss: 3.0743956565856934
Validation loss: 3.431403734350717

Epoch: 6| Step: 8
Training loss: 2.9297773838043213
Validation loss: 3.412942235187818

Epoch: 6| Step: 9
Training loss: 3.2816543579101562
Validation loss: 3.390856627495058

Epoch: 6| Step: 10
Training loss: 4.367500305175781
Validation loss: 3.370174538704657

Epoch: 6| Step: 11
Training loss: 3.3125369548797607
Validation loss: 3.3461873351886706

Epoch: 6| Step: 12
Training loss: 3.236701011657715
Validation loss: 3.3352221929898827

Epoch: 6| Step: 13
Training loss: 2.7457242012023926
Validation loss: 3.3196590382565736

Epoch: 5| Step: 0
Training loss: 2.9272964000701904
Validation loss: 3.31127167260775

Epoch: 6| Step: 1
Training loss: 3.0574088096618652
Validation loss: 3.298436354565364

Epoch: 6| Step: 2
Training loss: 4.197177886962891
Validation loss: 3.282043103248842

Epoch: 6| Step: 3
Training loss: 2.8840277194976807
Validation loss: 3.2659787157530427

Epoch: 6| Step: 4
Training loss: 3.061408519744873
Validation loss: 3.2443796896165416

Epoch: 6| Step: 5
Training loss: 3.4796183109283447
Validation loss: 3.2315283795838714

Epoch: 6| Step: 6
Training loss: 3.4295828342437744
Validation loss: 3.2131378496846845

Epoch: 6| Step: 7
Training loss: 3.024320125579834
Validation loss: 3.1963960637328444

Epoch: 6| Step: 8
Training loss: 2.8436286449432373
Validation loss: 3.1831925428041847

Epoch: 6| Step: 9
Training loss: 3.159505844116211
Validation loss: 3.166554771443849

Epoch: 6| Step: 10
Training loss: 2.443481922149658
Validation loss: 3.151244758277811

Epoch: 6| Step: 11
Training loss: 4.0186896324157715
Validation loss: 3.1767025993716334

Epoch: 6| Step: 12
Training loss: 3.384282350540161
Validation loss: 3.170598509491131

Epoch: 6| Step: 13
Training loss: 3.056375026702881
Validation loss: 3.162977764683385

Epoch: 6| Step: 0
Training loss: 3.3320562839508057
Validation loss: 3.145973974658597

Epoch: 6| Step: 1
Training loss: 2.804356098175049
Validation loss: 3.129541063821444

Epoch: 6| Step: 2
Training loss: 3.4790897369384766
Validation loss: 3.1159787690767677

Epoch: 6| Step: 3
Training loss: 2.697495698928833
Validation loss: 3.1064106418240454

Epoch: 6| Step: 4
Training loss: 3.2077975273132324
Validation loss: 3.1039138686272407

Epoch: 6| Step: 5
Training loss: 3.1011221408843994
Validation loss: 3.0992972543162685

Epoch: 6| Step: 6
Training loss: 3.1155409812927246
Validation loss: 3.0905635279993855

Epoch: 6| Step: 7
Training loss: 3.012516975402832
Validation loss: 3.0745205648483767

Epoch: 6| Step: 8
Training loss: 2.8375496864318848
Validation loss: 3.0659684724705194

Epoch: 6| Step: 9
Training loss: 3.5038228034973145
Validation loss: 3.057013755203575

Epoch: 6| Step: 10
Training loss: 3.115736484527588
Validation loss: 3.044412894915509

Epoch: 6| Step: 11
Training loss: 3.892524003982544
Validation loss: 3.0418286400456584

Epoch: 6| Step: 12
Training loss: 3.126814126968384
Validation loss: 3.03692594651253

Epoch: 6| Step: 13
Training loss: 1.8541336059570312
Validation loss: 3.0326658115592053

Epoch: 7| Step: 0
Training loss: 2.7114367485046387
Validation loss: 3.0219749968539

Epoch: 6| Step: 1
Training loss: 3.4258408546447754
Validation loss: 3.016656985846899

Epoch: 6| Step: 2
Training loss: 3.122462749481201
Validation loss: 3.015395679781514

Epoch: 6| Step: 3
Training loss: 1.987748146057129
Validation loss: 3.0057821376349336

Epoch: 6| Step: 4
Training loss: 3.7286252975463867
Validation loss: 2.9964254838164135

Epoch: 6| Step: 5
Training loss: 3.388174295425415
Validation loss: 2.986599078742407

Epoch: 6| Step: 6
Training loss: 2.4869179725646973
Validation loss: 2.9805080557382233

Epoch: 6| Step: 7
Training loss: 3.410982608795166
Validation loss: 2.9791695276896157

Epoch: 6| Step: 8
Training loss: 2.457862377166748
Validation loss: 3.001448885087044

Epoch: 6| Step: 9
Training loss: 3.4389684200286865
Validation loss: 3.012221100509808

Epoch: 6| Step: 10
Training loss: 3.2440295219421387
Validation loss: 3.0064445029022875

Epoch: 6| Step: 11
Training loss: 3.1430134773254395
Validation loss: 2.9660612972833778

Epoch: 6| Step: 12
Training loss: 3.053483009338379
Validation loss: 2.9607345211890435

Epoch: 6| Step: 13
Training loss: 3.4311037063598633
Validation loss: 2.9631223781134493

Epoch: 8| Step: 0
Training loss: 3.2947614192962646
Validation loss: 2.963637431462606

Epoch: 6| Step: 1
Training loss: 3.5791893005371094
Validation loss: 2.9583755872582875

Epoch: 6| Step: 2
Training loss: 2.4307923316955566
Validation loss: 2.961643385630782

Epoch: 6| Step: 3
Training loss: 2.760014057159424
Validation loss: 2.9724873394094486

Epoch: 6| Step: 4
Training loss: 3.448653221130371
Validation loss: 2.943641162687732

Epoch: 6| Step: 5
Training loss: 2.8934078216552734
Validation loss: 2.9640902075716244

Epoch: 6| Step: 6
Training loss: 3.7245562076568604
Validation loss: 2.9892734635260796

Epoch: 6| Step: 7
Training loss: 2.467017650604248
Validation loss: 2.988476412270659

Epoch: 6| Step: 8
Training loss: 2.688783645629883
Validation loss: 2.966283695672148

Epoch: 6| Step: 9
Training loss: 3.208289623260498
Validation loss: 2.946230278220228

Epoch: 6| Step: 10
Training loss: 3.2336385250091553
Validation loss: 2.9344668567821546

Epoch: 6| Step: 11
Training loss: 2.883415699005127
Validation loss: 2.929038065736012

Epoch: 6| Step: 12
Training loss: 2.8083395957946777
Validation loss: 2.9308193473405737

Epoch: 6| Step: 13
Training loss: 3.260836362838745
Validation loss: 2.9385599526025916

Epoch: 9| Step: 0
Training loss: 2.6957058906555176
Validation loss: 2.9363604181556293

Epoch: 6| Step: 1
Training loss: 2.406865119934082
Validation loss: 2.9270448171964256

Epoch: 6| Step: 2
Training loss: 3.335988998413086
Validation loss: 2.9202487032900573

Epoch: 6| Step: 3
Training loss: 3.4518110752105713
Validation loss: 2.914857115796817

Epoch: 6| Step: 4
Training loss: 3.4700746536254883
Validation loss: 2.910341185908164

Epoch: 6| Step: 5
Training loss: 1.825665831565857
Validation loss: 2.9065662789088424

Epoch: 6| Step: 6
Training loss: 3.2043333053588867
Validation loss: 2.9062993577731553

Epoch: 6| Step: 7
Training loss: 2.6237850189208984
Validation loss: 2.90578951374177

Epoch: 6| Step: 8
Training loss: 3.70913028717041
Validation loss: 2.906137704849243

Epoch: 6| Step: 9
Training loss: 3.496084213256836
Validation loss: 2.9011861201255553

Epoch: 6| Step: 10
Training loss: 2.295959711074829
Validation loss: 2.8974909141499507

Epoch: 6| Step: 11
Training loss: 3.684560537338257
Validation loss: 2.894028599544238

Epoch: 6| Step: 12
Training loss: 2.945864677429199
Validation loss: 2.892399293120189

Epoch: 6| Step: 13
Training loss: 2.9268295764923096
Validation loss: 2.889000008183141

Epoch: 10| Step: 0
Training loss: 2.6445236206054688
Validation loss: 2.8875032894072996

Epoch: 6| Step: 1
Training loss: 2.097848415374756
Validation loss: 2.8869636725353938

Epoch: 6| Step: 2
Training loss: 2.6852142810821533
Validation loss: 2.886467505526799

Epoch: 6| Step: 3
Training loss: 2.822699546813965
Validation loss: 2.883660688195177

Epoch: 6| Step: 4
Training loss: 3.7381067276000977
Validation loss: 2.882129423079952

Epoch: 6| Step: 5
Training loss: 3.753330945968628
Validation loss: 2.8809474693831576

Epoch: 6| Step: 6
Training loss: 2.7507338523864746
Validation loss: 2.877639268034248

Epoch: 6| Step: 7
Training loss: 2.8618597984313965
Validation loss: 2.8753533722251974

Epoch: 6| Step: 8
Training loss: 2.8739676475524902
Validation loss: 2.872858521758869

Epoch: 6| Step: 9
Training loss: 2.538848400115967
Validation loss: 2.8674691877057477

Epoch: 6| Step: 10
Training loss: 3.055288791656494
Validation loss: 2.8629382130920247

Epoch: 6| Step: 11
Training loss: 3.5794782638549805
Validation loss: 2.8569928112850396

Epoch: 6| Step: 12
Training loss: 3.683469772338867
Validation loss: 2.8521568621358564

Epoch: 6| Step: 13
Training loss: 2.436588764190674
Validation loss: 2.8487212965565343

Epoch: 11| Step: 0
Training loss: 3.1313722133636475
Validation loss: 2.8470124352362847

Epoch: 6| Step: 1
Training loss: 1.7917258739471436
Validation loss: 2.8443885362276466

Epoch: 6| Step: 2
Training loss: 3.156860113143921
Validation loss: 2.840908835011144

Epoch: 6| Step: 3
Training loss: 3.027456283569336
Validation loss: 2.8420997614501626

Epoch: 6| Step: 4
Training loss: 3.1004810333251953
Validation loss: 2.8392223363281577

Epoch: 6| Step: 5
Training loss: 1.9278661012649536
Validation loss: 2.8352627933666272

Epoch: 6| Step: 6
Training loss: 3.153033494949341
Validation loss: 2.833717317991359

Epoch: 6| Step: 7
Training loss: 3.952146053314209
Validation loss: 2.8314559921141593

Epoch: 6| Step: 8
Training loss: 2.7168493270874023
Validation loss: 2.827181790464668

Epoch: 6| Step: 9
Training loss: 3.2677741050720215
Validation loss: 2.8225683909590527

Epoch: 6| Step: 10
Training loss: 3.030032157897949
Validation loss: 2.821552099720124

Epoch: 6| Step: 11
Training loss: 3.221860408782959
Validation loss: 2.8186767357651905

Epoch: 6| Step: 12
Training loss: 3.0974860191345215
Validation loss: 2.8142895467819704

Epoch: 6| Step: 13
Training loss: 2.628014326095581
Validation loss: 2.813508284989224

Epoch: 12| Step: 0
Training loss: 2.7837915420532227
Validation loss: 2.810807510088849

Epoch: 6| Step: 1
Training loss: 2.928551197052002
Validation loss: 2.809812207375803

Epoch: 6| Step: 2
Training loss: 3.105010509490967
Validation loss: 2.8077830268490698

Epoch: 6| Step: 3
Training loss: 3.2079930305480957
Validation loss: 2.8045325458690686

Epoch: 6| Step: 4
Training loss: 2.5697178840637207
Validation loss: 2.8039099529225338

Epoch: 6| Step: 5
Training loss: 3.5253119468688965
Validation loss: 2.8033195567387406

Epoch: 6| Step: 6
Training loss: 3.9872376918792725
Validation loss: 2.800985925941057

Epoch: 6| Step: 7
Training loss: 2.366997480392456
Validation loss: 2.801447924747262

Epoch: 6| Step: 8
Training loss: 2.559473752975464
Validation loss: 2.7990428837396766

Epoch: 6| Step: 9
Training loss: 2.771669387817383
Validation loss: 2.7964738081860285

Epoch: 6| Step: 10
Training loss: 3.1374573707580566
Validation loss: 2.795498845397785

Epoch: 6| Step: 11
Training loss: 2.598716974258423
Validation loss: 2.7931407805412047

Epoch: 6| Step: 12
Training loss: 2.765158176422119
Validation loss: 2.792008666582005

Epoch: 6| Step: 13
Training loss: 2.664506673812866
Validation loss: 2.7891737363671743

Epoch: 13| Step: 0
Training loss: 2.652730703353882
Validation loss: 2.7888334592183432

Epoch: 6| Step: 1
Training loss: 3.843472480773926
Validation loss: 2.7897061558179956

Epoch: 6| Step: 2
Training loss: 3.1162397861480713
Validation loss: 2.786954228596021

Epoch: 6| Step: 3
Training loss: 2.535449981689453
Validation loss: 2.783384987103042

Epoch: 6| Step: 4
Training loss: 2.6375975608825684
Validation loss: 2.7832486424394833

Epoch: 6| Step: 5
Training loss: 3.5532350540161133
Validation loss: 2.7822510068134596

Epoch: 6| Step: 6
Training loss: 2.8468027114868164
Validation loss: 2.7820617255344184

Epoch: 6| Step: 7
Training loss: 2.4013891220092773
Validation loss: 2.7822305694703133

Epoch: 6| Step: 8
Training loss: 2.772059917449951
Validation loss: 2.781610099218225

Epoch: 6| Step: 9
Training loss: 3.3232152462005615
Validation loss: 2.7831945650039183

Epoch: 6| Step: 10
Training loss: 2.686777114868164
Validation loss: 2.777418076351125

Epoch: 6| Step: 11
Training loss: 2.92128324508667
Validation loss: 2.775162612238238

Epoch: 6| Step: 12
Training loss: 2.9648427963256836
Validation loss: 2.7725475962444017

Epoch: 6| Step: 13
Training loss: 2.4887967109680176
Validation loss: 2.770440017023394

Epoch: 14| Step: 0
Training loss: 3.5157806873321533
Validation loss: 2.7701140885711997

Epoch: 6| Step: 1
Training loss: 2.784295082092285
Validation loss: 2.7694573633132444

Epoch: 6| Step: 2
Training loss: 2.3927993774414062
Validation loss: 2.7691781597752727

Epoch: 6| Step: 3
Training loss: 2.9869437217712402
Validation loss: 2.769241717553908

Epoch: 6| Step: 4
Training loss: 3.1465606689453125
Validation loss: 2.767262525455926

Epoch: 6| Step: 5
Training loss: 2.738055467605591
Validation loss: 2.764402235707929

Epoch: 6| Step: 6
Training loss: 3.2868235111236572
Validation loss: 2.7666027571565364

Epoch: 6| Step: 7
Training loss: 3.3495779037475586
Validation loss: 2.761947016562185

Epoch: 6| Step: 8
Training loss: 3.692692279815674
Validation loss: 2.7635475102291314

Epoch: 6| Step: 9
Training loss: 2.780996799468994
Validation loss: 2.7633881184362594

Epoch: 6| Step: 10
Training loss: 2.452265739440918
Validation loss: 2.7626737112640054

Epoch: 6| Step: 11
Training loss: 2.1982948780059814
Validation loss: 2.7612278922911613

Epoch: 6| Step: 12
Training loss: 2.548962354660034
Validation loss: 2.7604777043865574

Epoch: 6| Step: 13
Training loss: 2.879227638244629
Validation loss: 2.758856652885355

Epoch: 15| Step: 0
Training loss: 3.016937732696533
Validation loss: 2.759469252760692

Epoch: 6| Step: 1
Training loss: 2.4598002433776855
Validation loss: 2.756279335227064

Epoch: 6| Step: 2
Training loss: 2.71960711479187
Validation loss: 2.75342571350836

Epoch: 6| Step: 3
Training loss: 3.0513205528259277
Validation loss: 2.751983686160016

Epoch: 6| Step: 4
Training loss: 3.2605767250061035
Validation loss: 2.751036828564059

Epoch: 6| Step: 5
Training loss: 2.4638140201568604
Validation loss: 2.7493849390296528

Epoch: 6| Step: 6
Training loss: 4.006239891052246
Validation loss: 2.748421097314486

Epoch: 6| Step: 7
Training loss: 2.7209272384643555
Validation loss: 2.7469256744589856

Epoch: 6| Step: 8
Training loss: 2.2571229934692383
Validation loss: 2.7456864310849096

Epoch: 6| Step: 9
Training loss: 3.0519537925720215
Validation loss: 2.745414710813953

Epoch: 6| Step: 10
Training loss: 3.87186336517334
Validation loss: 2.7425457251969205

Epoch: 6| Step: 11
Training loss: 2.583005905151367
Validation loss: 2.7416921764291744

Epoch: 6| Step: 12
Training loss: 2.4577670097351074
Validation loss: 2.7396825257168023

Epoch: 6| Step: 13
Training loss: 2.5383894443511963
Validation loss: 2.738446666348365

Epoch: 16| Step: 0
Training loss: 2.1335904598236084
Validation loss: 2.7383338815422467

Epoch: 6| Step: 1
Training loss: 2.943235158920288
Validation loss: 2.7409492359366467

Epoch: 6| Step: 2
Training loss: 3.5976457595825195
Validation loss: 2.7407840528795795

Epoch: 6| Step: 3
Training loss: 2.5308446884155273
Validation loss: 2.737602515887189

Epoch: 6| Step: 4
Training loss: 2.761530876159668
Validation loss: 2.7368887752614994

Epoch: 6| Step: 5
Training loss: 3.231616735458374
Validation loss: 2.7351705079437583

Epoch: 6| Step: 6
Training loss: 2.8792386054992676
Validation loss: 2.734799672198552

Epoch: 6| Step: 7
Training loss: 3.8682608604431152
Validation loss: 2.735322247269333

Epoch: 6| Step: 8
Training loss: 2.6314029693603516
Validation loss: 2.7325573326438986

Epoch: 6| Step: 9
Training loss: 2.807440757751465
Validation loss: 2.731040305988763

Epoch: 6| Step: 10
Training loss: 2.61371111869812
Validation loss: 2.730459079947523

Epoch: 6| Step: 11
Training loss: 2.954847574234009
Validation loss: 2.7289165219952984

Epoch: 6| Step: 12
Training loss: 3.342116355895996
Validation loss: 2.728804488335886

Epoch: 6| Step: 13
Training loss: 1.6158924102783203
Validation loss: 2.7287875734349734

Epoch: 17| Step: 0
Training loss: 2.8268051147460938
Validation loss: 2.7270458667509017

Epoch: 6| Step: 1
Training loss: 2.477036237716675
Validation loss: 2.7275950037023073

Epoch: 6| Step: 2
Training loss: 2.994443655014038
Validation loss: 2.727059215627691

Epoch: 6| Step: 3
Training loss: 3.353947162628174
Validation loss: 2.725745613856982

Epoch: 6| Step: 4
Training loss: 3.0751521587371826
Validation loss: 2.7242554977375972

Epoch: 6| Step: 5
Training loss: 2.589278221130371
Validation loss: 2.7242860935067617

Epoch: 6| Step: 6
Training loss: 2.9572839736938477
Validation loss: 2.7223176545994257

Epoch: 6| Step: 7
Training loss: 3.2516210079193115
Validation loss: 2.7216466780631774

Epoch: 6| Step: 8
Training loss: 3.035118579864502
Validation loss: 2.7216278788863972

Epoch: 6| Step: 9
Training loss: 3.0054283142089844
Validation loss: 2.721638007830548

Epoch: 6| Step: 10
Training loss: 3.197237968444824
Validation loss: 2.7206032301789973

Epoch: 6| Step: 11
Training loss: 1.473602533340454
Validation loss: 2.7205628810390348

Epoch: 6| Step: 12
Training loss: 3.808417320251465
Validation loss: 2.7203232447306314

Epoch: 6| Step: 13
Training loss: 1.9164042472839355
Validation loss: 2.7203727101766937

Epoch: 18| Step: 0
Training loss: 2.2760961055755615
Validation loss: 2.719754085745863

Epoch: 6| Step: 1
Training loss: 2.824908971786499
Validation loss: 2.7190564473470054

Epoch: 6| Step: 2
Training loss: 3.3682749271392822
Validation loss: 2.7190365047865015

Epoch: 6| Step: 3
Training loss: 2.4484338760375977
Validation loss: 2.717213935749505

Epoch: 6| Step: 4
Training loss: 2.4857301712036133
Validation loss: 2.7164307896808912

Epoch: 6| Step: 5
Training loss: 3.2158052921295166
Validation loss: 2.716710723856444

Epoch: 6| Step: 6
Training loss: 3.1780710220336914
Validation loss: 2.714816524136451

Epoch: 6| Step: 7
Training loss: 3.099316120147705
Validation loss: 2.7145116303556707

Epoch: 6| Step: 8
Training loss: 2.5863513946533203
Validation loss: 2.713003276496805

Epoch: 6| Step: 9
Training loss: 2.8401243686676025
Validation loss: 2.712329856811031

Epoch: 6| Step: 10
Training loss: 2.9060091972351074
Validation loss: 2.711405441325198

Epoch: 6| Step: 11
Training loss: 2.326775074005127
Validation loss: 2.711508120259931

Epoch: 6| Step: 12
Training loss: 3.6225922107696533
Validation loss: 2.7106219953106296

Epoch: 6| Step: 13
Training loss: 3.3166494369506836
Validation loss: 2.7097935548392673

Epoch: 19| Step: 0
Training loss: 2.703199625015259
Validation loss: 2.7097003511203233

Epoch: 6| Step: 1
Training loss: 3.6078429222106934
Validation loss: 2.708866403948876

Epoch: 6| Step: 2
Training loss: 3.0364608764648438
Validation loss: 2.7058344938421763

Epoch: 6| Step: 3
Training loss: 2.719511032104492
Validation loss: 2.7066459245579217

Epoch: 6| Step: 4
Training loss: 3.4530391693115234
Validation loss: 2.7053958933840514

Epoch: 6| Step: 5
Training loss: 2.608175754547119
Validation loss: 2.705532048338203

Epoch: 6| Step: 6
Training loss: 2.0890743732452393
Validation loss: 2.70600107536521

Epoch: 6| Step: 7
Training loss: 3.224970817565918
Validation loss: 2.7061996639415784

Epoch: 6| Step: 8
Training loss: 2.842125654220581
Validation loss: 2.705383285399406

Epoch: 6| Step: 9
Training loss: 3.0034170150756836
Validation loss: 2.701757328484648

Epoch: 6| Step: 10
Training loss: 3.3325538635253906
Validation loss: 2.7008306082858833

Epoch: 6| Step: 11
Training loss: 2.775137424468994
Validation loss: 2.7017569311203493

Epoch: 6| Step: 12
Training loss: 2.0420889854431152
Validation loss: 2.7011767587354107

Epoch: 6| Step: 13
Training loss: 2.7089362144470215
Validation loss: 2.699468543452601

Epoch: 20| Step: 0
Training loss: 2.3877105712890625
Validation loss: 2.697825736896966

Epoch: 6| Step: 1
Training loss: 3.7215709686279297
Validation loss: 2.702149437319848

Epoch: 6| Step: 2
Training loss: 3.6550774574279785
Validation loss: 2.7005381481621855

Epoch: 6| Step: 3
Training loss: 3.178816080093384
Validation loss: 2.69341008381177

Epoch: 6| Step: 4
Training loss: 2.684621810913086
Validation loss: 2.71771086928665

Epoch: 6| Step: 5
Training loss: 2.6073169708251953
Validation loss: 2.694608057698896

Epoch: 6| Step: 6
Training loss: 2.3782052993774414
Validation loss: 2.7030408228597333

Epoch: 6| Step: 7
Training loss: 2.379941701889038
Validation loss: 2.715384101354948

Epoch: 6| Step: 8
Training loss: 3.23551082611084
Validation loss: 2.7031739270815285

Epoch: 6| Step: 9
Training loss: 1.564989686012268
Validation loss: 2.697035179343275

Epoch: 6| Step: 10
Training loss: 2.762521982192993
Validation loss: 2.696577828417542

Epoch: 6| Step: 11
Training loss: 3.184560775756836
Validation loss: 2.6939104577546478

Epoch: 6| Step: 12
Training loss: 3.2230124473571777
Validation loss: 2.6923433375614945

Epoch: 6| Step: 13
Training loss: 3.473356008529663
Validation loss: 2.6979966189271662

Epoch: 21| Step: 0
Training loss: 2.428309917449951
Validation loss: 2.693907235258369

Epoch: 6| Step: 1
Training loss: 3.060732364654541
Validation loss: 2.6942976802907963

Epoch: 6| Step: 2
Training loss: 3.5264720916748047
Validation loss: 2.6936086300880677

Epoch: 6| Step: 3
Training loss: 3.127034902572632
Validation loss: 2.6876318326560398

Epoch: 6| Step: 4
Training loss: 3.039071559906006
Validation loss: 2.687083157159949

Epoch: 6| Step: 5
Training loss: 2.91847562789917
Validation loss: 2.687708085583102

Epoch: 6| Step: 6
Training loss: 3.336576223373413
Validation loss: 2.689502646846156

Epoch: 6| Step: 7
Training loss: 3.184689998626709
Validation loss: 2.689270391259142

Epoch: 6| Step: 8
Training loss: 3.1639609336853027
Validation loss: 2.688808930817471

Epoch: 6| Step: 9
Training loss: 1.830946683883667
Validation loss: 2.6857234303669264

Epoch: 6| Step: 10
Training loss: 2.054877519607544
Validation loss: 2.68277633061973

Epoch: 6| Step: 11
Training loss: 2.2000489234924316
Validation loss: 2.682999005881689

Epoch: 6| Step: 12
Training loss: 3.5128302574157715
Validation loss: 2.713822011024721

Epoch: 6| Step: 13
Training loss: 2.6365716457366943
Validation loss: 2.7114346335011144

Epoch: 22| Step: 0
Training loss: 3.033444881439209
Validation loss: 2.684965720740698

Epoch: 6| Step: 1
Training loss: 2.566197633743286
Validation loss: 2.676683779685728

Epoch: 6| Step: 2
Training loss: 2.7348642349243164
Validation loss: 2.6904856851024013

Epoch: 6| Step: 3
Training loss: 3.1193714141845703
Validation loss: 2.703539120253696

Epoch: 6| Step: 4
Training loss: 2.2529335021972656
Validation loss: 2.689427234793222

Epoch: 6| Step: 5
Training loss: 2.2989659309387207
Validation loss: 2.675142483044696

Epoch: 6| Step: 6
Training loss: 2.6447932720184326
Validation loss: 2.678191036306402

Epoch: 6| Step: 7
Training loss: 3.630470037460327
Validation loss: 2.72395113847589

Epoch: 6| Step: 8
Training loss: 3.4008522033691406
Validation loss: 2.751325335553897

Epoch: 6| Step: 9
Training loss: 2.4968247413635254
Validation loss: 2.7276327738197903

Epoch: 6| Step: 10
Training loss: 3.925729274749756
Validation loss: 2.710300583993235

Epoch: 6| Step: 11
Training loss: 2.6430418491363525
Validation loss: 2.6840148792471936

Epoch: 6| Step: 12
Training loss: 2.847731113433838
Validation loss: 2.6675956992692846

Epoch: 6| Step: 13
Training loss: 2.284926414489746
Validation loss: 2.6733324758468138

Epoch: 23| Step: 0
Training loss: 2.2919864654541016
Validation loss: 2.694023819379909

Epoch: 6| Step: 1
Training loss: 3.2330095767974854
Validation loss: 2.70306481084516

Epoch: 6| Step: 2
Training loss: 2.8513450622558594
Validation loss: 2.695694056890344

Epoch: 6| Step: 3
Training loss: 3.045076370239258
Validation loss: 2.6818456777962307

Epoch: 6| Step: 4
Training loss: 2.5546586513519287
Validation loss: 2.6689279053800847

Epoch: 6| Step: 5
Training loss: 2.916086196899414
Validation loss: 2.664871361947829

Epoch: 6| Step: 6
Training loss: 2.204047918319702
Validation loss: 2.664372741535146

Epoch: 6| Step: 7
Training loss: 2.754584789276123
Validation loss: 2.6673844322081535

Epoch: 6| Step: 8
Training loss: 3.2567460536956787
Validation loss: 2.6782822865311817

Epoch: 6| Step: 9
Training loss: 3.0453848838806152
Validation loss: 2.677693546459239

Epoch: 6| Step: 10
Training loss: 3.1346449851989746
Validation loss: 2.681732944262925

Epoch: 6| Step: 11
Training loss: 2.3238306045532227
Validation loss: 2.6758427055933143

Epoch: 6| Step: 12
Training loss: 3.0324208736419678
Validation loss: 2.671358452048353

Epoch: 6| Step: 13
Training loss: 3.6384828090667725
Validation loss: 2.668851185870427

Epoch: 24| Step: 0
Training loss: 3.120342254638672
Validation loss: 2.664912680143951

Epoch: 6| Step: 1
Training loss: 2.9953250885009766
Validation loss: 2.6588399897339525

Epoch: 6| Step: 2
Training loss: 2.351379871368408
Validation loss: 2.659603072750953

Epoch: 6| Step: 3
Training loss: 2.046872615814209
Validation loss: 2.6647425287513324

Epoch: 6| Step: 4
Training loss: 2.2661967277526855
Validation loss: 2.6931050541580364

Epoch: 6| Step: 5
Training loss: 3.344280481338501
Validation loss: 2.7562792813906105

Epoch: 6| Step: 6
Training loss: 2.7552499771118164
Validation loss: 2.6961926798666678

Epoch: 6| Step: 7
Training loss: 4.096581935882568
Validation loss: 2.6528152470947592

Epoch: 6| Step: 8
Training loss: 1.966027021408081
Validation loss: 2.6574564159557386

Epoch: 6| Step: 9
Training loss: 2.7731118202209473
Validation loss: 2.7129819752067648

Epoch: 6| Step: 10
Training loss: 3.2079672813415527
Validation loss: 2.725813591352073

Epoch: 6| Step: 11
Training loss: 3.3120720386505127
Validation loss: 2.740720287446053

Epoch: 6| Step: 12
Training loss: 2.902944803237915
Validation loss: 2.734458279866044

Epoch: 6| Step: 13
Training loss: 2.8882381916046143
Validation loss: 2.6703847198076147

Epoch: 25| Step: 0
Training loss: 3.2396297454833984
Validation loss: 2.6337363079030025

Epoch: 6| Step: 1
Training loss: 2.7683730125427246
Validation loss: 2.6425650376145557

Epoch: 6| Step: 2
Training loss: 2.953702926635742
Validation loss: 2.653547768951744

Epoch: 6| Step: 3
Training loss: 2.699063539505005
Validation loss: 2.6719309976024013

Epoch: 6| Step: 4
Training loss: 1.943150520324707
Validation loss: 2.7013386936597925

Epoch: 6| Step: 5
Training loss: 2.7922983169555664
Validation loss: 2.6859643331138034

Epoch: 6| Step: 6
Training loss: 3.4261837005615234
Validation loss: 2.6467923348949802

Epoch: 6| Step: 7
Training loss: 3.281308650970459
Validation loss: 2.6080288630659862

Epoch: 6| Step: 8
Training loss: 2.3060340881347656
Validation loss: 2.601392412698397

Epoch: 6| Step: 9
Training loss: 3.0749194622039795
Validation loss: 2.6117221027292232

Epoch: 6| Step: 10
Training loss: 2.576326370239258
Validation loss: 2.6344676838126233

Epoch: 6| Step: 11
Training loss: 3.2873849868774414
Validation loss: 2.6356384856726534

Epoch: 6| Step: 12
Training loss: 2.8556630611419678
Validation loss: 2.625503296493202

Epoch: 6| Step: 13
Training loss: 2.0474305152893066
Validation loss: 2.618989036929223

Epoch: 26| Step: 0
Training loss: 2.3551950454711914
Validation loss: 2.6119704425975843

Epoch: 6| Step: 1
Training loss: 2.651000499725342
Validation loss: 2.604574393200618

Epoch: 6| Step: 2
Training loss: 3.117527484893799
Validation loss: 2.5966624636803903

Epoch: 6| Step: 3
Training loss: 2.573975086212158
Validation loss: 2.591265445114464

Epoch: 6| Step: 4
Training loss: 2.083167552947998
Validation loss: 2.5985394549626175

Epoch: 6| Step: 5
Training loss: 1.8166241645812988
Validation loss: 2.617685492320727

Epoch: 6| Step: 6
Training loss: 3.109644651412964
Validation loss: 2.633888711211502

Epoch: 6| Step: 7
Training loss: 2.948396682739258
Validation loss: 2.6801179070626535

Epoch: 6| Step: 8
Training loss: 3.248718738555908
Validation loss: 2.6663540358184488

Epoch: 6| Step: 9
Training loss: 2.8203558921813965
Validation loss: 2.6140120644723215

Epoch: 6| Step: 10
Training loss: 3.465099334716797
Validation loss: 2.612593622617824

Epoch: 6| Step: 11
Training loss: 2.7355329990386963
Validation loss: 2.612224958276236

Epoch: 6| Step: 12
Training loss: 3.831353187561035
Validation loss: 2.61464153182122

Epoch: 6| Step: 13
Training loss: 2.656806230545044
Validation loss: 2.6195633949772006

Epoch: 27| Step: 0
Training loss: 3.2124080657958984
Validation loss: 2.61533050639655

Epoch: 6| Step: 1
Training loss: 2.853546142578125
Validation loss: 2.6156987041555424

Epoch: 6| Step: 2
Training loss: 2.9195289611816406
Validation loss: 2.6073272625605264

Epoch: 6| Step: 3
Training loss: 2.2250328063964844
Validation loss: 2.6063160639937206

Epoch: 6| Step: 4
Training loss: 2.562082052230835
Validation loss: 2.601876620323427

Epoch: 6| Step: 5
Training loss: 3.857720136642456
Validation loss: 2.600405869945403

Epoch: 6| Step: 6
Training loss: 3.150649070739746
Validation loss: 2.5957697668383197

Epoch: 6| Step: 7
Training loss: 2.8706135749816895
Validation loss: 2.598973802340928

Epoch: 6| Step: 8
Training loss: 2.9982776641845703
Validation loss: 2.5935033444435365

Epoch: 6| Step: 9
Training loss: 2.9356818199157715
Validation loss: 2.589615386019471

Epoch: 6| Step: 10
Training loss: 1.824634075164795
Validation loss: 2.5900667098260697

Epoch: 6| Step: 11
Training loss: 2.2474563121795654
Validation loss: 2.5916252443867345

Epoch: 6| Step: 12
Training loss: 3.0854973793029785
Validation loss: 2.5951494093864196

Epoch: 6| Step: 13
Training loss: 2.0339622497558594
Validation loss: 2.6105003792752504

Epoch: 28| Step: 0
Training loss: 2.4717493057250977
Validation loss: 2.6222611678543912

Epoch: 6| Step: 1
Training loss: 2.946103811264038
Validation loss: 2.638090064448695

Epoch: 6| Step: 2
Training loss: 3.1897196769714355
Validation loss: 2.6474696205508326

Epoch: 6| Step: 3
Training loss: 2.353408098220825
Validation loss: 2.6241491225457962

Epoch: 6| Step: 4
Training loss: 3.028801441192627
Validation loss: 2.6113676332658335

Epoch: 6| Step: 5
Training loss: 2.610812187194824
Validation loss: 2.5969453883427445

Epoch: 6| Step: 6
Training loss: 2.83201265335083
Validation loss: 2.5861112174167427

Epoch: 6| Step: 7
Training loss: 3.069159507751465
Validation loss: 2.590821163628691

Epoch: 6| Step: 8
Training loss: 2.5264530181884766
Validation loss: 2.593095725582492

Epoch: 6| Step: 9
Training loss: 2.633209228515625
Validation loss: 2.5931588859968286

Epoch: 6| Step: 10
Training loss: 3.3848187923431396
Validation loss: 2.5806210451228644

Epoch: 6| Step: 11
Training loss: 2.298948287963867
Validation loss: 2.5792948481857136

Epoch: 6| Step: 12
Training loss: 2.580502510070801
Validation loss: 2.5823433911928566

Epoch: 6| Step: 13
Training loss: 3.2098448276519775
Validation loss: 2.5667027632395425

Epoch: 29| Step: 0
Training loss: 3.5926895141601562
Validation loss: 2.580795911050612

Epoch: 6| Step: 1
Training loss: 2.5733070373535156
Validation loss: 2.585077608785322

Epoch: 6| Step: 2
Training loss: 3.011518955230713
Validation loss: 2.5848514264629734

Epoch: 6| Step: 3
Training loss: 2.7532100677490234
Validation loss: 2.579307576661469

Epoch: 6| Step: 4
Training loss: 2.012662410736084
Validation loss: 2.570574450236495

Epoch: 6| Step: 5
Training loss: 2.6079392433166504
Validation loss: 2.566064291102912

Epoch: 6| Step: 6
Training loss: 2.8280622959136963
Validation loss: 2.561833325252738

Epoch: 6| Step: 7
Training loss: 3.2324042320251465
Validation loss: 2.564073501094695

Epoch: 6| Step: 8
Training loss: 2.46178936958313
Validation loss: 2.574264854513189

Epoch: 6| Step: 9
Training loss: 2.8791544437408447
Validation loss: 2.604812399033577

Epoch: 6| Step: 10
Training loss: 2.0976662635803223
Validation loss: 2.6300124199159685

Epoch: 6| Step: 11
Training loss: 2.058840751647949
Validation loss: 2.572918168960079

Epoch: 6| Step: 12
Training loss: 3.602112293243408
Validation loss: 2.552160216915992

Epoch: 6| Step: 13
Training loss: 3.635723114013672
Validation loss: 2.5598967946985716

Epoch: 30| Step: 0
Training loss: 2.4922478199005127
Validation loss: 2.5588295946839037

Epoch: 6| Step: 1
Training loss: 1.8388429880142212
Validation loss: 2.5544481456920667

Epoch: 6| Step: 2
Training loss: 2.5721116065979004
Validation loss: 2.5568943715864614

Epoch: 6| Step: 3
Training loss: 2.895512819290161
Validation loss: 2.555859940026396

Epoch: 6| Step: 4
Training loss: 3.2323355674743652
Validation loss: 2.563290988245318

Epoch: 6| Step: 5
Training loss: 2.810023069381714
Validation loss: 2.5569373587126374

Epoch: 6| Step: 6
Training loss: 2.8194432258605957
Validation loss: 2.5516543285821074

Epoch: 6| Step: 7
Training loss: 3.1199655532836914
Validation loss: 2.5512277080166723

Epoch: 6| Step: 8
Training loss: 2.4875717163085938
Validation loss: 2.544075253189251

Epoch: 6| Step: 9
Training loss: 2.5859947204589844
Validation loss: 2.5453613137686126

Epoch: 6| Step: 10
Training loss: 2.4101250171661377
Validation loss: 2.5586652781373713

Epoch: 6| Step: 11
Training loss: 3.2883477210998535
Validation loss: 2.5617804860556

Epoch: 6| Step: 12
Training loss: 2.9173736572265625
Validation loss: 2.574551377245175

Epoch: 6| Step: 13
Training loss: 3.4428486824035645
Validation loss: 2.575048280018632

Epoch: 31| Step: 0
Training loss: 2.1753273010253906
Validation loss: 2.5848175043700845

Epoch: 6| Step: 1
Training loss: 2.5709054470062256
Validation loss: 2.5731051147625013

Epoch: 6| Step: 2
Training loss: 2.4826736450195312
Validation loss: 2.5643752697975404

Epoch: 6| Step: 3
Training loss: 2.8950061798095703
Validation loss: 2.547723367650022

Epoch: 6| Step: 4
Training loss: 2.7115566730499268
Validation loss: 2.544807708391579

Epoch: 6| Step: 5
Training loss: 3.6856420040130615
Validation loss: 2.5454879345432406

Epoch: 6| Step: 6
Training loss: 3.1784591674804688
Validation loss: 2.54407900123186

Epoch: 6| Step: 7
Training loss: 2.6021246910095215
Validation loss: 2.536164176079535

Epoch: 6| Step: 8
Training loss: 2.0229227542877197
Validation loss: 2.5330629989665043

Epoch: 6| Step: 9
Training loss: 2.9568777084350586
Validation loss: 2.53478999804425

Epoch: 6| Step: 10
Training loss: 3.3503575325012207
Validation loss: 2.5369761477234545

Epoch: 6| Step: 11
Training loss: 2.524735689163208
Validation loss: 2.536527095302459

Epoch: 6| Step: 12
Training loss: 3.1674516201019287
Validation loss: 2.5358413906507593

Epoch: 6| Step: 13
Training loss: 1.6783393621444702
Validation loss: 2.5315372764423327

Epoch: 32| Step: 0
Training loss: 2.7278568744659424
Validation loss: 2.531585006303685

Epoch: 6| Step: 1
Training loss: 2.986851692199707
Validation loss: 2.5355252835058395

Epoch: 6| Step: 2
Training loss: 2.5345282554626465
Validation loss: 2.5304176730494343

Epoch: 6| Step: 3
Training loss: 2.5707671642303467
Validation loss: 2.5317870673312934

Epoch: 6| Step: 4
Training loss: 2.8670196533203125
Validation loss: 2.5341371823382635

Epoch: 6| Step: 5
Training loss: 2.553070545196533
Validation loss: 2.5350403119159

Epoch: 6| Step: 6
Training loss: 2.9651098251342773
Validation loss: 2.5406591430787118

Epoch: 6| Step: 7
Training loss: 3.0501813888549805
Validation loss: 2.5413944336675827

Epoch: 6| Step: 8
Training loss: 2.7181034088134766
Validation loss: 2.5532957405172367

Epoch: 6| Step: 9
Training loss: 1.971534252166748
Validation loss: 2.553338025205879

Epoch: 6| Step: 10
Training loss: 3.3952839374542236
Validation loss: 2.542352312354631

Epoch: 6| Step: 11
Training loss: 2.5801923274993896
Validation loss: 2.5277160598385717

Epoch: 6| Step: 12
Training loss: 2.9064481258392334
Validation loss: 2.519716226926414

Epoch: 6| Step: 13
Training loss: 2.4338347911834717
Validation loss: 2.5212797862227245

Epoch: 33| Step: 0
Training loss: 3.1497631072998047
Validation loss: 2.5254578949302755

Epoch: 6| Step: 1
Training loss: 2.4979500770568848
Validation loss: 2.5245836063097884

Epoch: 6| Step: 2
Training loss: 2.8648300170898438
Validation loss: 2.5286501658860074

Epoch: 6| Step: 3
Training loss: 3.1129889488220215
Validation loss: 2.541161539734051

Epoch: 6| Step: 4
Training loss: 2.695622682571411
Validation loss: 2.521810016324443

Epoch: 6| Step: 5
Training loss: 2.841158151626587
Validation loss: 2.5222789036330355

Epoch: 6| Step: 6
Training loss: 1.4534616470336914
Validation loss: 2.546382891234531

Epoch: 6| Step: 7
Training loss: 2.698744773864746
Validation loss: 2.5753326364742812

Epoch: 6| Step: 8
Training loss: 2.5597665309906006
Validation loss: 2.67542250182039

Epoch: 6| Step: 9
Training loss: 3.5895228385925293
Validation loss: 2.7964408910402687

Epoch: 6| Step: 10
Training loss: 3.2092480659484863
Validation loss: 2.8617044187361196

Epoch: 6| Step: 11
Training loss: 2.856210708618164
Validation loss: 2.831401199422857

Epoch: 6| Step: 12
Training loss: 2.8618221282958984
Validation loss: 2.6685027922353437

Epoch: 6| Step: 13
Training loss: 2.819551944732666
Validation loss: 2.5707527540063344

Epoch: 34| Step: 0
Training loss: 2.645446300506592
Validation loss: 2.532554349591655

Epoch: 6| Step: 1
Training loss: 3.21279239654541
Validation loss: 2.549852227651945

Epoch: 6| Step: 2
Training loss: 2.8066349029541016
Validation loss: 2.556025174356276

Epoch: 6| Step: 3
Training loss: 2.8890113830566406
Validation loss: 2.574743406746977

Epoch: 6| Step: 4
Training loss: 3.128033399581909
Validation loss: 2.584349488699308

Epoch: 6| Step: 5
Training loss: 2.164677619934082
Validation loss: 2.589458050266389

Epoch: 6| Step: 6
Training loss: 1.9770408868789673
Validation loss: 2.581362250030682

Epoch: 6| Step: 7
Training loss: 2.3873844146728516
Validation loss: 2.5714343824694232

Epoch: 6| Step: 8
Training loss: 3.4510769844055176
Validation loss: 2.556561387995238

Epoch: 6| Step: 9
Training loss: 3.091482639312744
Validation loss: 2.5351750901950303

Epoch: 6| Step: 10
Training loss: 3.3109302520751953
Validation loss: 2.5134006674571703

Epoch: 6| Step: 11
Training loss: 1.5993950366973877
Validation loss: 2.5219274400382914

Epoch: 6| Step: 12
Training loss: 2.5821845531463623
Validation loss: 2.531090992753224

Epoch: 6| Step: 13
Training loss: 3.6998329162597656
Validation loss: 2.552341466308922

Epoch: 35| Step: 0
Training loss: 2.9089035987854004
Validation loss: 2.6009311804207425

Epoch: 6| Step: 1
Training loss: 2.38114333152771
Validation loss: 2.6282258290116505

Epoch: 6| Step: 2
Training loss: 3.6007561683654785
Validation loss: 2.6586315554957234

Epoch: 6| Step: 3
Training loss: 2.19484543800354
Validation loss: 2.6143844307109876

Epoch: 6| Step: 4
Training loss: 2.4356112480163574
Validation loss: 2.57273470458164

Epoch: 6| Step: 5
Training loss: 2.538705348968506
Validation loss: 2.5245083275661675

Epoch: 6| Step: 6
Training loss: 2.937047004699707
Validation loss: 2.503256551681026

Epoch: 6| Step: 7
Training loss: 3.2315220832824707
Validation loss: 2.5069397239274878

Epoch: 6| Step: 8
Training loss: 2.991878032684326
Validation loss: 2.527551668946461

Epoch: 6| Step: 9
Training loss: 3.356626510620117
Validation loss: 2.548309341553719

Epoch: 6| Step: 10
Training loss: 2.888561487197876
Validation loss: 2.5560743988201184

Epoch: 6| Step: 11
Training loss: 2.1081655025482178
Validation loss: 2.5199691275114655

Epoch: 6| Step: 12
Training loss: 2.0639851093292236
Validation loss: 2.5018949354848554

Epoch: 6| Step: 13
Training loss: 3.151278018951416
Validation loss: 2.4956910328198503

Epoch: 36| Step: 0
Training loss: 2.70145320892334
Validation loss: 2.4975865246147237

Epoch: 6| Step: 1
Training loss: 2.754054307937622
Validation loss: 2.5164163163913194

Epoch: 6| Step: 2
Training loss: 3.0336153507232666
Validation loss: 2.555554243826097

Epoch: 6| Step: 3
Training loss: 2.551722526550293
Validation loss: 2.5899218948938514

Epoch: 6| Step: 4
Training loss: 2.4686713218688965
Validation loss: 2.605845541082403

Epoch: 6| Step: 5
Training loss: 2.815600633621216
Validation loss: 2.6397902401544715

Epoch: 6| Step: 6
Training loss: 2.427217483520508
Validation loss: 2.6178270924475884

Epoch: 6| Step: 7
Training loss: 2.3737399578094482
Validation loss: 2.5747578451710362

Epoch: 6| Step: 8
Training loss: 2.562309980392456
Validation loss: 2.5331403337499148

Epoch: 6| Step: 9
Training loss: 2.4789328575134277
Validation loss: 2.515124623493482

Epoch: 6| Step: 10
Training loss: 2.5872559547424316
Validation loss: 2.5003708562543316

Epoch: 6| Step: 11
Training loss: 3.0494627952575684
Validation loss: 2.4923795833382556

Epoch: 6| Step: 12
Training loss: 3.598839282989502
Validation loss: 2.491993775931738

Epoch: 6| Step: 13
Training loss: 2.9746806621551514
Validation loss: 2.492650467862365

Epoch: 37| Step: 0
Training loss: 2.395387649536133
Validation loss: 2.491269096251457

Epoch: 6| Step: 1
Training loss: 2.6593141555786133
Validation loss: 2.4928699513917327

Epoch: 6| Step: 2
Training loss: 2.4296700954437256
Validation loss: 2.496934513891897

Epoch: 6| Step: 3
Training loss: 2.8046867847442627
Validation loss: 2.5138088695464598

Epoch: 6| Step: 4
Training loss: 2.725377321243286
Validation loss: 2.522018471071797

Epoch: 6| Step: 5
Training loss: 3.412672519683838
Validation loss: 2.515948364811559

Epoch: 6| Step: 6
Training loss: 3.0528531074523926
Validation loss: 2.5129220460050847

Epoch: 6| Step: 7
Training loss: 2.2298812866210938
Validation loss: 2.4998646756654144

Epoch: 6| Step: 8
Training loss: 3.280273914337158
Validation loss: 2.4965755375482703

Epoch: 6| Step: 9
Training loss: 2.3107080459594727
Validation loss: 2.4924293794939594

Epoch: 6| Step: 10
Training loss: 2.4603984355926514
Validation loss: 2.4909928896093882

Epoch: 6| Step: 11
Training loss: 2.018333911895752
Validation loss: 2.491979682317344

Epoch: 6| Step: 12
Training loss: 3.4467639923095703
Validation loss: 2.4851500680369716

Epoch: 6| Step: 13
Training loss: 2.6516683101654053
Validation loss: 2.4792575118362263

Epoch: 38| Step: 0
Training loss: 2.5229225158691406
Validation loss: 2.4732060329888457

Epoch: 6| Step: 1
Training loss: 2.732041835784912
Validation loss: 2.4718776031207015

Epoch: 6| Step: 2
Training loss: 2.8332247734069824
Validation loss: 2.4678253948047595

Epoch: 6| Step: 3
Training loss: 2.79864764213562
Validation loss: 2.4669732483484412

Epoch: 6| Step: 4
Training loss: 2.8758912086486816
Validation loss: 2.48135874348302

Epoch: 6| Step: 5
Training loss: 2.8339083194732666
Validation loss: 2.4832562720903786

Epoch: 6| Step: 6
Training loss: 3.0046725273132324
Validation loss: 2.5068836007066952

Epoch: 6| Step: 7
Training loss: 2.6811740398406982
Validation loss: 2.4730962220058648

Epoch: 6| Step: 8
Training loss: 2.41379714012146
Validation loss: 2.4642981841999996

Epoch: 6| Step: 9
Training loss: 2.8409030437469482
Validation loss: 2.486350772201374

Epoch: 6| Step: 10
Training loss: 3.03459095954895
Validation loss: 2.5223471554376746

Epoch: 6| Step: 11
Training loss: 2.9719176292419434
Validation loss: 2.5722043386069675

Epoch: 6| Step: 12
Training loss: 2.2900209426879883
Validation loss: 2.5477534929911294

Epoch: 6| Step: 13
Training loss: 1.8325456380844116
Validation loss: 2.5244954785993023

Epoch: 39| Step: 0
Training loss: 2.8872904777526855
Validation loss: 2.506580650165517

Epoch: 6| Step: 1
Training loss: 2.8024730682373047
Validation loss: 2.4822364314909904

Epoch: 6| Step: 2
Training loss: 1.847898244857788
Validation loss: 2.4736092398243565

Epoch: 6| Step: 3
Training loss: 3.6896018981933594
Validation loss: 2.469646748676095

Epoch: 6| Step: 4
Training loss: 3.529078960418701
Validation loss: 2.470152670337308

Epoch: 6| Step: 5
Training loss: 2.84751558303833
Validation loss: 2.4716135583898073

Epoch: 6| Step: 6
Training loss: 2.4807188510894775
Validation loss: 2.4695354097632953

Epoch: 6| Step: 7
Training loss: 2.9665286540985107
Validation loss: 2.470805114315402

Epoch: 6| Step: 8
Training loss: 2.598172187805176
Validation loss: 2.473356064929757

Epoch: 6| Step: 9
Training loss: 2.7081990242004395
Validation loss: 2.4683661383967244

Epoch: 6| Step: 10
Training loss: 1.7520055770874023
Validation loss: 2.469284619054487

Epoch: 6| Step: 11
Training loss: 2.3951470851898193
Validation loss: 2.4659802118937173

Epoch: 6| Step: 12
Training loss: 2.4172654151916504
Validation loss: 2.466346227994529

Epoch: 6| Step: 13
Training loss: 3.0064873695373535
Validation loss: 2.466909485478555

Epoch: 40| Step: 0
Training loss: 3.137369155883789
Validation loss: 2.473616418018136

Epoch: 6| Step: 1
Training loss: 2.8306617736816406
Validation loss: 2.4868039302928473

Epoch: 6| Step: 2
Training loss: 3.073599338531494
Validation loss: 2.504675716482183

Epoch: 6| Step: 3
Training loss: 2.903122663497925
Validation loss: 2.4953717506060036

Epoch: 6| Step: 4
Training loss: 3.070890426635742
Validation loss: 2.4831605367763068

Epoch: 6| Step: 5
Training loss: 2.893770933151245
Validation loss: 2.46924158834642

Epoch: 6| Step: 6
Training loss: 2.3032941818237305
Validation loss: 2.4624981623823925

Epoch: 6| Step: 7
Training loss: 1.9986767768859863
Validation loss: 2.4621949836771977

Epoch: 6| Step: 8
Training loss: 2.4140052795410156
Validation loss: 2.4613423142381894

Epoch: 6| Step: 9
Training loss: 2.253175973892212
Validation loss: 2.457168012536982

Epoch: 6| Step: 10
Training loss: 3.730883836746216
Validation loss: 2.450550438255392

Epoch: 6| Step: 11
Training loss: 2.5165669918060303
Validation loss: 2.444606698969359

Epoch: 6| Step: 12
Training loss: 2.1542091369628906
Validation loss: 2.472384771993083

Epoch: 6| Step: 13
Training loss: 2.327448844909668
Validation loss: 2.504510297570177

Epoch: 41| Step: 0
Training loss: 2.477598190307617
Validation loss: 2.5214238371900333

Epoch: 6| Step: 1
Training loss: 2.817451000213623
Validation loss: 2.5618339969265844

Epoch: 6| Step: 2
Training loss: 3.314631223678589
Validation loss: 2.583493789037069

Epoch: 6| Step: 3
Training loss: 2.7604587078094482
Validation loss: 2.579077169459353

Epoch: 6| Step: 4
Training loss: 2.011563539505005
Validation loss: 2.5245199254764024

Epoch: 6| Step: 5
Training loss: 2.5625205039978027
Validation loss: 2.543603822749148

Epoch: 6| Step: 6
Training loss: 2.460794687271118
Validation loss: 2.5451501107984975

Epoch: 6| Step: 7
Training loss: 3.1608211994171143
Validation loss: 2.5337375210177515

Epoch: 6| Step: 8
Training loss: 2.2796783447265625
Validation loss: 2.5258205757346204

Epoch: 6| Step: 9
Training loss: 3.3813886642456055
Validation loss: 2.5932529844263548

Epoch: 6| Step: 10
Training loss: 2.8992373943328857
Validation loss: 2.6240483663415395

Epoch: 6| Step: 11
Training loss: 2.986445903778076
Validation loss: 2.6337638798580376

Epoch: 6| Step: 12
Training loss: 2.4898152351379395
Validation loss: 2.6770965899190595

Epoch: 6| Step: 13
Training loss: 2.7035293579101562
Validation loss: 2.7361897191693707

Epoch: 42| Step: 0
Training loss: 2.7175540924072266
Validation loss: 2.8255498306725615

Epoch: 6| Step: 1
Training loss: 3.213759422302246
Validation loss: 2.92112297396506

Epoch: 6| Step: 2
Training loss: 2.701510429382324
Validation loss: 2.9285008984227336

Epoch: 6| Step: 3
Training loss: 2.767502784729004
Validation loss: 2.986698589017314

Epoch: 6| Step: 4
Training loss: 2.1158409118652344
Validation loss: 2.8605940162494616

Epoch: 6| Step: 5
Training loss: 3.6783041954040527
Validation loss: 2.857878738834012

Epoch: 6| Step: 6
Training loss: 3.645209312438965
Validation loss: 2.815283839420606

Epoch: 6| Step: 7
Training loss: 2.188382148742676
Validation loss: 2.762038007859261

Epoch: 6| Step: 8
Training loss: 3.5831995010375977
Validation loss: 2.6812764777932117

Epoch: 6| Step: 9
Training loss: 3.0549564361572266
Validation loss: 2.5858915211052023

Epoch: 6| Step: 10
Training loss: 2.6196649074554443
Validation loss: 2.5950121187394664

Epoch: 6| Step: 11
Training loss: 2.6874313354492188
Validation loss: 2.6638043260061615

Epoch: 6| Step: 12
Training loss: 3.22699236869812
Validation loss: 2.7050229862172115

Epoch: 6| Step: 13
Training loss: 2.2021634578704834
Validation loss: 2.7520607261247534

Epoch: 43| Step: 0
Training loss: 3.3605916500091553
Validation loss: 2.7455476714718725

Epoch: 6| Step: 1
Training loss: 3.4288887977600098
Validation loss: 2.7286066368062007

Epoch: 6| Step: 2
Training loss: 3.1228904724121094
Validation loss: 2.695107549749395

Epoch: 6| Step: 3
Training loss: 2.800405263900757
Validation loss: 2.65789960276696

Epoch: 6| Step: 4
Training loss: 2.4813928604125977
Validation loss: 2.652214116947625

Epoch: 6| Step: 5
Training loss: 1.9632271528244019
Validation loss: 2.6180903219407603

Epoch: 6| Step: 6
Training loss: 3.1414504051208496
Validation loss: 2.5840160641618954

Epoch: 6| Step: 7
Training loss: 2.538633108139038
Validation loss: 2.5839195815465783

Epoch: 6| Step: 8
Training loss: 2.332852363586426
Validation loss: 2.566908562055198

Epoch: 6| Step: 9
Training loss: 2.714712619781494
Validation loss: 2.5456328110028337

Epoch: 6| Step: 10
Training loss: 2.911893606185913
Validation loss: 2.5235331648139545

Epoch: 6| Step: 11
Training loss: 2.355132579803467
Validation loss: 2.5053234407978673

Epoch: 6| Step: 12
Training loss: 2.832735538482666
Validation loss: 2.4885417927977858

Epoch: 6| Step: 13
Training loss: 2.6200032234191895
Validation loss: 2.4685774003305743

Epoch: 44| Step: 0
Training loss: 2.652784824371338
Validation loss: 2.4564521081985964

Epoch: 6| Step: 1
Training loss: 2.4436888694763184
Validation loss: 2.4349914571290374

Epoch: 6| Step: 2
Training loss: 1.9548777341842651
Validation loss: 2.42664094637799

Epoch: 6| Step: 3
Training loss: 2.690687417984009
Validation loss: 2.4281279784376903

Epoch: 6| Step: 4
Training loss: 2.556633234024048
Validation loss: 2.4230974258915072

Epoch: 6| Step: 5
Training loss: 3.6850194931030273
Validation loss: 2.424308428200342

Epoch: 6| Step: 6
Training loss: 2.2893967628479004
Validation loss: 2.4266483809358332

Epoch: 6| Step: 7
Training loss: 2.35374116897583
Validation loss: 2.425138319692304

Epoch: 6| Step: 8
Training loss: 3.100874900817871
Validation loss: 2.4300390802403933

Epoch: 6| Step: 9
Training loss: 2.798853874206543
Validation loss: 2.4289208278861096

Epoch: 6| Step: 10
Training loss: 2.2595772743225098
Validation loss: 2.4333580745163785

Epoch: 6| Step: 11
Training loss: 3.174992084503174
Validation loss: 2.4327130240778767

Epoch: 6| Step: 12
Training loss: 2.8977832794189453
Validation loss: 2.4351620981770177

Epoch: 6| Step: 13
Training loss: 2.5710525512695312
Validation loss: 2.4252465232726066

Epoch: 45| Step: 0
Training loss: 2.7947659492492676
Validation loss: 2.4172131015408422

Epoch: 6| Step: 1
Training loss: 3.000406265258789
Validation loss: 2.4130144913991294

Epoch: 6| Step: 2
Training loss: 3.130446672439575
Validation loss: 2.414791384050923

Epoch: 6| Step: 3
Training loss: 2.3634324073791504
Validation loss: 2.4186175305356263

Epoch: 6| Step: 4
Training loss: 3.0093135833740234
Validation loss: 2.425872528424827

Epoch: 6| Step: 5
Training loss: 2.6532881259918213
Validation loss: 2.422427399184114

Epoch: 6| Step: 6
Training loss: 2.546799421310425
Validation loss: 2.4162006121809765

Epoch: 6| Step: 7
Training loss: 2.815669536590576
Validation loss: 2.416072540385749

Epoch: 6| Step: 8
Training loss: 2.7012481689453125
Validation loss: 2.410300475294872

Epoch: 6| Step: 9
Training loss: 2.470292091369629
Validation loss: 2.4104245913925992

Epoch: 6| Step: 10
Training loss: 2.8266351222991943
Validation loss: 2.4116725639630388

Epoch: 6| Step: 11
Training loss: 2.146723747253418
Validation loss: 2.423351723660705

Epoch: 6| Step: 12
Training loss: 2.3299293518066406
Validation loss: 2.4517979826978458

Epoch: 6| Step: 13
Training loss: 2.302057981491089
Validation loss: 2.5115133511122836

Epoch: 46| Step: 0
Training loss: 2.6924052238464355
Validation loss: 2.521875407106133

Epoch: 6| Step: 1
Training loss: 2.9979310035705566
Validation loss: 2.528292409835323

Epoch: 6| Step: 2
Training loss: 2.2287745475769043
Validation loss: 2.5074170225410053

Epoch: 6| Step: 3
Training loss: 3.0119519233703613
Validation loss: 2.4870757377275856

Epoch: 6| Step: 4
Training loss: 2.587317943572998
Validation loss: 2.454350474060223

Epoch: 6| Step: 5
Training loss: 2.3288662433624268
Validation loss: 2.428971064988003

Epoch: 6| Step: 6
Training loss: 2.632279872894287
Validation loss: 2.411529976834533

Epoch: 6| Step: 7
Training loss: 3.0104331970214844
Validation loss: 2.405489085822977

Epoch: 6| Step: 8
Training loss: 2.8706560134887695
Validation loss: 2.3961757229220484

Epoch: 6| Step: 9
Training loss: 2.1363043785095215
Validation loss: 2.4001309358945457

Epoch: 6| Step: 10
Training loss: 3.21026611328125
Validation loss: 2.397420298668646

Epoch: 6| Step: 11
Training loss: 2.7683067321777344
Validation loss: 2.3930215656116443

Epoch: 6| Step: 12
Training loss: 2.6637215614318848
Validation loss: 2.394894943442396

Epoch: 6| Step: 13
Training loss: 2.4361441135406494
Validation loss: 2.391478625676965

Epoch: 47| Step: 0
Training loss: 2.830618381500244
Validation loss: 2.3872323907831663

Epoch: 6| Step: 1
Training loss: 3.01570987701416
Validation loss: 2.38179954918482

Epoch: 6| Step: 2
Training loss: 2.553755044937134
Validation loss: 2.38145338848073

Epoch: 6| Step: 3
Training loss: 2.6956429481506348
Validation loss: 2.382987244154817

Epoch: 6| Step: 4
Training loss: 1.962028980255127
Validation loss: 2.382597836115027

Epoch: 6| Step: 5
Training loss: 3.44399356842041
Validation loss: 2.3803263607845513

Epoch: 6| Step: 6
Training loss: 2.628598213195801
Validation loss: 2.383932452048025

Epoch: 6| Step: 7
Training loss: 2.4129371643066406
Validation loss: 2.3863254977810766

Epoch: 6| Step: 8
Training loss: 2.01137113571167
Validation loss: 2.3918054693488666

Epoch: 6| Step: 9
Training loss: 3.0707578659057617
Validation loss: 2.4010642933589157

Epoch: 6| Step: 10
Training loss: 3.080111026763916
Validation loss: 2.3967723641344296

Epoch: 6| Step: 11
Training loss: 1.8016927242279053
Validation loss: 2.3953112966270855

Epoch: 6| Step: 12
Training loss: 2.5106201171875
Validation loss: 2.4007331376434653

Epoch: 6| Step: 13
Training loss: 3.2722227573394775
Validation loss: 2.3905194754241617

Epoch: 48| Step: 0
Training loss: 2.5323269367218018
Validation loss: 2.385807955136863

Epoch: 6| Step: 1
Training loss: 2.5754995346069336
Validation loss: 2.385748512001448

Epoch: 6| Step: 2
Training loss: 2.1490602493286133
Validation loss: 2.3756659466733216

Epoch: 6| Step: 3
Training loss: 3.0280842781066895
Validation loss: 2.3717911089620283

Epoch: 6| Step: 4
Training loss: 2.6285388469696045
Validation loss: 2.3669536600830736

Epoch: 6| Step: 5
Training loss: 3.1461195945739746
Validation loss: 2.3704133725935415

Epoch: 6| Step: 6
Training loss: 2.8849549293518066
Validation loss: 2.369210325261598

Epoch: 6| Step: 7
Training loss: 2.7305736541748047
Validation loss: 2.367726436225317

Epoch: 6| Step: 8
Training loss: 2.160191535949707
Validation loss: 2.3667033231386574

Epoch: 6| Step: 9
Training loss: 2.7673180103302
Validation loss: 2.3648381310124553

Epoch: 6| Step: 10
Training loss: 2.6271181106567383
Validation loss: 2.359167580963463

Epoch: 6| Step: 11
Training loss: 2.3199219703674316
Validation loss: 2.357194205766083

Epoch: 6| Step: 12
Training loss: 2.6172127723693848
Validation loss: 2.3531934574086177

Epoch: 6| Step: 13
Training loss: 2.7024974822998047
Validation loss: 2.353796407740603

Epoch: 49| Step: 0
Training loss: 2.551697015762329
Validation loss: 2.357111410428119

Epoch: 6| Step: 1
Training loss: 2.511467933654785
Validation loss: 2.380910022284395

Epoch: 6| Step: 2
Training loss: 3.5785140991210938
Validation loss: 2.386326418128065

Epoch: 6| Step: 3
Training loss: 2.6999282836914062
Validation loss: 2.374150836339561

Epoch: 6| Step: 4
Training loss: 2.7308197021484375
Validation loss: 2.354504972375849

Epoch: 6| Step: 5
Training loss: 2.652803421020508
Validation loss: 2.3458776038180114

Epoch: 6| Step: 6
Training loss: 1.9663267135620117
Validation loss: 2.3459403207225185

Epoch: 6| Step: 7
Training loss: 2.588662624359131
Validation loss: 2.3512993935615785

Epoch: 6| Step: 8
Training loss: 3.246537208557129
Validation loss: 2.3539829305423203

Epoch: 6| Step: 9
Training loss: 2.050631523132324
Validation loss: 2.361724458714967

Epoch: 6| Step: 10
Training loss: 2.053536891937256
Validation loss: 2.3676716742977018

Epoch: 6| Step: 11
Training loss: 2.770267963409424
Validation loss: 2.3610062137726815

Epoch: 6| Step: 12
Training loss: 2.491797924041748
Validation loss: 2.3649495724708802

Epoch: 6| Step: 13
Training loss: 3.1759514808654785
Validation loss: 2.364179277932772

Epoch: 50| Step: 0
Training loss: 2.2208797931671143
Validation loss: 2.3558052842335035

Epoch: 6| Step: 1
Training loss: 2.7634828090667725
Validation loss: 2.3539351750445623

Epoch: 6| Step: 2
Training loss: 2.7449464797973633
Validation loss: 2.3521432351040583

Epoch: 6| Step: 3
Training loss: 2.5623183250427246
Validation loss: 2.349133822225755

Epoch: 6| Step: 4
Training loss: 2.7921252250671387
Validation loss: 2.350663338938067

Epoch: 6| Step: 5
Training loss: 2.2522618770599365
Validation loss: 2.3467926517609627

Epoch: 6| Step: 6
Training loss: 2.308544635772705
Validation loss: 2.346528196847567

Epoch: 6| Step: 7
Training loss: 2.8199000358581543
Validation loss: 2.340224781344014

Epoch: 6| Step: 8
Training loss: 1.9747498035430908
Validation loss: 2.338647296351771

Epoch: 6| Step: 9
Training loss: 3.022545337677002
Validation loss: 2.343223020594607

Epoch: 6| Step: 10
Training loss: 2.3280115127563477
Validation loss: 2.339417544744348

Epoch: 6| Step: 11
Training loss: 2.6940882205963135
Validation loss: 2.3528435794256066

Epoch: 6| Step: 12
Training loss: 3.319408416748047
Validation loss: 2.362170898786155

Epoch: 6| Step: 13
Training loss: 2.9587209224700928
Validation loss: 2.3594900818281275

Epoch: 51| Step: 0
Training loss: 2.517087936401367
Validation loss: 2.35731590178705

Epoch: 6| Step: 1
Training loss: 3.192727565765381
Validation loss: 2.352068567788729

Epoch: 6| Step: 2
Training loss: 2.766510248184204
Validation loss: 2.3396605753129527

Epoch: 6| Step: 3
Training loss: 2.336548089981079
Validation loss: 2.3393131097157798

Epoch: 6| Step: 4
Training loss: 2.629821538925171
Validation loss: 2.3403030287834907

Epoch: 6| Step: 5
Training loss: 2.101095676422119
Validation loss: 2.337205958622758

Epoch: 6| Step: 6
Training loss: 2.9123287200927734
Validation loss: 2.3469148912737445

Epoch: 6| Step: 7
Training loss: 2.1477794647216797
Validation loss: 2.3614188958239812

Epoch: 6| Step: 8
Training loss: 2.652963161468506
Validation loss: 2.374306623653699

Epoch: 6| Step: 9
Training loss: 3.2191548347473145
Validation loss: 2.3735750618801323

Epoch: 6| Step: 10
Training loss: 2.107239246368408
Validation loss: 2.3867645878945627

Epoch: 6| Step: 11
Training loss: 2.602111577987671
Validation loss: 2.3795169630358295

Epoch: 6| Step: 12
Training loss: 3.155639171600342
Validation loss: 2.3671914351883756

Epoch: 6| Step: 13
Training loss: 2.3179128170013428
Validation loss: 2.359005848566691

Epoch: 52| Step: 0
Training loss: 2.9984822273254395
Validation loss: 2.354304036786479

Epoch: 6| Step: 1
Training loss: 2.2698326110839844
Validation loss: 2.344891817339005

Epoch: 6| Step: 2
Training loss: 2.152557849884033
Validation loss: 2.3356017553678123

Epoch: 6| Step: 3
Training loss: 3.010965347290039
Validation loss: 2.3338048458099365

Epoch: 6| Step: 4
Training loss: 2.437155246734619
Validation loss: 2.332985875427082

Epoch: 6| Step: 5
Training loss: 3.1040124893188477
Validation loss: 2.3371900371325913

Epoch: 6| Step: 6
Training loss: 2.844468593597412
Validation loss: 2.337140223031403

Epoch: 6| Step: 7
Training loss: 2.3792006969451904
Validation loss: 2.3418449919710875

Epoch: 6| Step: 8
Training loss: 2.7130050659179688
Validation loss: 2.342523661992883

Epoch: 6| Step: 9
Training loss: 2.1572186946868896
Validation loss: 2.3442167979414745

Epoch: 6| Step: 10
Training loss: 2.4663960933685303
Validation loss: 2.3446650017974195

Epoch: 6| Step: 11
Training loss: 2.894813299179077
Validation loss: 2.352160815269716

Epoch: 6| Step: 12
Training loss: 2.834774971008301
Validation loss: 2.352785307873962

Epoch: 6| Step: 13
Training loss: 2.0811829566955566
Validation loss: 2.3521233835527973

Epoch: 53| Step: 0
Training loss: 2.4505414962768555
Validation loss: 2.360006429815805

Epoch: 6| Step: 1
Training loss: 2.906558036804199
Validation loss: 2.361069547232761

Epoch: 6| Step: 2
Training loss: 2.347594976425171
Validation loss: 2.3621678224173923

Epoch: 6| Step: 3
Training loss: 2.479766368865967
Validation loss: 2.36085367971851

Epoch: 6| Step: 4
Training loss: 3.2320656776428223
Validation loss: 2.352181383358535

Epoch: 6| Step: 5
Training loss: 3.074911594390869
Validation loss: 2.3296227326957126

Epoch: 6| Step: 6
Training loss: 2.5550811290740967
Validation loss: 2.320065588079473

Epoch: 6| Step: 7
Training loss: 2.356071949005127
Validation loss: 2.3176658307352374

Epoch: 6| Step: 8
Training loss: 2.1687889099121094
Validation loss: 2.320546970572523

Epoch: 6| Step: 9
Training loss: 1.7982091903686523
Validation loss: 2.316309057256227

Epoch: 6| Step: 10
Training loss: 2.806576728820801
Validation loss: 2.3180584612713067

Epoch: 6| Step: 11
Training loss: 2.1760244369506836
Validation loss: 2.3220748439911874

Epoch: 6| Step: 12
Training loss: 3.236406087875366
Validation loss: 2.330201182314145

Epoch: 6| Step: 13
Training loss: 3.20345401763916
Validation loss: 2.3294590186047297

Epoch: 54| Step: 0
Training loss: 1.9950758218765259
Validation loss: 2.325402577718099

Epoch: 6| Step: 1
Training loss: 2.9021458625793457
Validation loss: 2.316593543175728

Epoch: 6| Step: 2
Training loss: 2.2560386657714844
Validation loss: 2.321982183764058

Epoch: 6| Step: 3
Training loss: 2.4149773120880127
Validation loss: 2.3215100303772958

Epoch: 6| Step: 4
Training loss: 2.4835205078125
Validation loss: 2.3253069154677855

Epoch: 6| Step: 5
Training loss: 3.019329309463501
Validation loss: 2.3253053952288885

Epoch: 6| Step: 6
Training loss: 2.5665230751037598
Validation loss: 2.329423173781364

Epoch: 6| Step: 7
Training loss: 3.007096290588379
Validation loss: 2.3543675458559425

Epoch: 6| Step: 8
Training loss: 3.044318437576294
Validation loss: 2.399208455957392

Epoch: 6| Step: 9
Training loss: 2.9262924194335938
Validation loss: 2.443904184526013

Epoch: 6| Step: 10
Training loss: 1.7991814613342285
Validation loss: 2.473057667414347

Epoch: 6| Step: 11
Training loss: 2.5321829319000244
Validation loss: 2.488201595121814

Epoch: 6| Step: 12
Training loss: 3.1576695442199707
Validation loss: 2.4415871404832408

Epoch: 6| Step: 13
Training loss: 2.849368095397949
Validation loss: 2.3899743018611783

Epoch: 55| Step: 0
Training loss: 2.3189544677734375
Validation loss: 2.363339980443319

Epoch: 6| Step: 1
Training loss: 3.0722696781158447
Validation loss: 2.3463030861270044

Epoch: 6| Step: 2
Training loss: 2.696394920349121
Validation loss: 2.3180893416045816

Epoch: 6| Step: 3
Training loss: 2.7400946617126465
Validation loss: 2.3213632709236554

Epoch: 6| Step: 4
Training loss: 1.9778825044631958
Validation loss: 2.323607531926965

Epoch: 6| Step: 5
Training loss: 2.8386902809143066
Validation loss: 2.3271732535413516

Epoch: 6| Step: 6
Training loss: 2.5382022857666016
Validation loss: 2.3283500594477498

Epoch: 6| Step: 7
Training loss: 2.9560322761535645
Validation loss: 2.3294474629945654

Epoch: 6| Step: 8
Training loss: 2.7054014205932617
Validation loss: 2.3255040850690616

Epoch: 6| Step: 9
Training loss: 2.6577749252319336
Validation loss: 2.3216321558080693

Epoch: 6| Step: 10
Training loss: 2.975700855255127
Validation loss: 2.317168107596777

Epoch: 6| Step: 11
Training loss: 1.6719086170196533
Validation loss: 2.315448917368407

Epoch: 6| Step: 12
Training loss: 3.2706212997436523
Validation loss: 2.3088173276634625

Epoch: 6| Step: 13
Training loss: 2.0398051738739014
Validation loss: 2.3163345154895576

Epoch: 56| Step: 0
Training loss: 2.4071576595306396
Validation loss: 2.312869241160731

Epoch: 6| Step: 1
Training loss: 2.5095646381378174
Validation loss: 2.319177045617052

Epoch: 6| Step: 2
Training loss: 3.001251220703125
Validation loss: 2.324255322897306

Epoch: 6| Step: 3
Training loss: 2.519054889678955
Validation loss: 2.327860173358712

Epoch: 6| Step: 4
Training loss: 1.7637526988983154
Validation loss: 2.335774069191307

Epoch: 6| Step: 5
Training loss: 2.943671703338623
Validation loss: 2.3318533897399902

Epoch: 6| Step: 6
Training loss: 3.027383804321289
Validation loss: 2.330858422863868

Epoch: 6| Step: 7
Training loss: 2.6482644081115723
Validation loss: 2.329863732860934

Epoch: 6| Step: 8
Training loss: 1.8759315013885498
Validation loss: 2.3236161252503753

Epoch: 6| Step: 9
Training loss: 2.653414726257324
Validation loss: 2.3191240269650697

Epoch: 6| Step: 10
Training loss: 2.9912304878234863
Validation loss: 2.3283683356418403

Epoch: 6| Step: 11
Training loss: 2.679104804992676
Validation loss: 2.3267038586319133

Epoch: 6| Step: 12
Training loss: 2.3415393829345703
Validation loss: 2.315076861330258

Epoch: 6| Step: 13
Training loss: 3.2587945461273193
Validation loss: 2.3026438784855667

Epoch: 57| Step: 0
Training loss: 2.3564181327819824
Validation loss: 2.299663230937014

Epoch: 6| Step: 1
Training loss: 2.6875133514404297
Validation loss: 2.302478198082216

Epoch: 6| Step: 2
Training loss: 2.8786492347717285
Validation loss: 2.3021539001054663

Epoch: 6| Step: 3
Training loss: 1.9364566802978516
Validation loss: 2.2982534029150523

Epoch: 6| Step: 4
Training loss: 3.070678234100342
Validation loss: 2.302341494508969

Epoch: 6| Step: 5
Training loss: 2.8924400806427
Validation loss: 2.30017916874219

Epoch: 6| Step: 6
Training loss: 2.4985928535461426
Validation loss: 2.296972333744008

Epoch: 6| Step: 7
Training loss: 1.942297339439392
Validation loss: 2.29577051695957

Epoch: 6| Step: 8
Training loss: 2.746283531188965
Validation loss: 2.297966218763782

Epoch: 6| Step: 9
Training loss: 2.973647117614746
Validation loss: 2.299827855120423

Epoch: 6| Step: 10
Training loss: 2.3089632987976074
Validation loss: 2.297710164900749

Epoch: 6| Step: 11
Training loss: 3.1356728076934814
Validation loss: 2.297810713450114

Epoch: 6| Step: 12
Training loss: 2.6862645149230957
Validation loss: 2.305960391157417

Epoch: 6| Step: 13
Training loss: 1.811932921409607
Validation loss: 2.3143437395813646

Epoch: 58| Step: 0
Training loss: 2.5764589309692383
Validation loss: 2.312803796542588

Epoch: 6| Step: 1
Training loss: 2.2051987648010254
Validation loss: 2.3142106199777253

Epoch: 6| Step: 2
Training loss: 2.226536273956299
Validation loss: 2.3224987394066265

Epoch: 6| Step: 3
Training loss: 2.9050981998443604
Validation loss: 2.314998360090358

Epoch: 6| Step: 4
Training loss: 3.470933675765991
Validation loss: 2.304838152341945

Epoch: 6| Step: 5
Training loss: 2.477372884750366
Validation loss: 2.298887377144188

Epoch: 6| Step: 6
Training loss: 2.7221384048461914
Validation loss: 2.2928422881710913

Epoch: 6| Step: 7
Training loss: 2.3144021034240723
Validation loss: 2.295527127481276

Epoch: 6| Step: 8
Training loss: 2.7158143520355225
Validation loss: 2.2944526646726873

Epoch: 6| Step: 9
Training loss: 2.824690580368042
Validation loss: 2.2937331404737247

Epoch: 6| Step: 10
Training loss: 2.4174327850341797
Validation loss: 2.2930549959982596

Epoch: 6| Step: 11
Training loss: 2.814810276031494
Validation loss: 2.290115699973158

Epoch: 6| Step: 12
Training loss: 2.4231762886047363
Validation loss: 2.291058435234972

Epoch: 6| Step: 13
Training loss: 1.8162765502929688
Validation loss: 2.290141797834827

Epoch: 59| Step: 0
Training loss: 2.625870943069458
Validation loss: 2.288201211601175

Epoch: 6| Step: 1
Training loss: 2.6788489818573
Validation loss: 2.2953466830715055

Epoch: 6| Step: 2
Training loss: 2.5287187099456787
Validation loss: 2.3038771537042435

Epoch: 6| Step: 3
Training loss: 2.1036858558654785
Validation loss: 2.309119503985169

Epoch: 6| Step: 4
Training loss: 2.578162431716919
Validation loss: 2.3151136470097367

Epoch: 6| Step: 5
Training loss: 3.147706985473633
Validation loss: 2.318734727880006

Epoch: 6| Step: 6
Training loss: 2.611508846282959
Validation loss: 2.324359886107906

Epoch: 6| Step: 7
Training loss: 2.257986307144165
Validation loss: 2.3324593292769564

Epoch: 6| Step: 8
Training loss: 2.7411129474639893
Validation loss: 2.3539160477217806

Epoch: 6| Step: 9
Training loss: 1.9718835353851318
Validation loss: 2.340709323524147

Epoch: 6| Step: 10
Training loss: 2.974091053009033
Validation loss: 2.33188957552756

Epoch: 6| Step: 11
Training loss: 2.5887451171875
Validation loss: 2.2991890804741972

Epoch: 6| Step: 12
Training loss: 2.966859817504883
Validation loss: 2.277766748141217

Epoch: 6| Step: 13
Training loss: 2.125985860824585
Validation loss: 2.270544534088463

Epoch: 60| Step: 0
Training loss: 2.7864935398101807
Validation loss: 2.2761829181384017

Epoch: 6| Step: 1
Training loss: 2.0177111625671387
Validation loss: 2.2812143577042447

Epoch: 6| Step: 2
Training loss: 2.555405616760254
Validation loss: 2.284221928606751

Epoch: 6| Step: 3
Training loss: 3.104860544204712
Validation loss: 2.292000311677174

Epoch: 6| Step: 4
Training loss: 2.7254014015197754
Validation loss: 2.2919922003182034

Epoch: 6| Step: 5
Training loss: 2.5433197021484375
Validation loss: 2.2932815564576017

Epoch: 6| Step: 6
Training loss: 3.23765230178833
Validation loss: 2.2909096415324877

Epoch: 6| Step: 7
Training loss: 2.1448159217834473
Validation loss: 2.283145866086406

Epoch: 6| Step: 8
Training loss: 2.438681125640869
Validation loss: 2.2777147113635974

Epoch: 6| Step: 9
Training loss: 1.9321179389953613
Validation loss: 2.2714820036324124

Epoch: 6| Step: 10
Training loss: 3.0022482872009277
Validation loss: 2.2661688507244153

Epoch: 6| Step: 11
Training loss: 2.3774518966674805
Validation loss: 2.270214501247611

Epoch: 6| Step: 12
Training loss: 3.1178178787231445
Validation loss: 2.274822537617017

Epoch: 6| Step: 13
Training loss: 2.256216526031494
Validation loss: 2.283618668074249

Epoch: 61| Step: 0
Training loss: 1.8648226261138916
Validation loss: 2.294644319882957

Epoch: 6| Step: 1
Training loss: 2.2150301933288574
Validation loss: 2.326405473934707

Epoch: 6| Step: 2
Training loss: 3.000278949737549
Validation loss: 2.3627205587202504

Epoch: 6| Step: 3
Training loss: 3.4829905033111572
Validation loss: 2.3529494565020324

Epoch: 6| Step: 4
Training loss: 2.466071128845215
Validation loss: 2.3487193122986825

Epoch: 6| Step: 5
Training loss: 1.9530267715454102
Validation loss: 2.311322066091722

Epoch: 6| Step: 6
Training loss: 1.9155075550079346
Validation loss: 2.2863455331453713

Epoch: 6| Step: 7
Training loss: 2.4292759895324707
Validation loss: 2.275882972184048

Epoch: 6| Step: 8
Training loss: 3.541018486022949
Validation loss: 2.268679654726418

Epoch: 6| Step: 9
Training loss: 3.433450222015381
Validation loss: 2.26871520216747

Epoch: 6| Step: 10
Training loss: 2.7073264122009277
Validation loss: 2.2663833556636686

Epoch: 6| Step: 11
Training loss: 2.1253628730773926
Validation loss: 2.2661684200327885

Epoch: 6| Step: 12
Training loss: 2.7861387729644775
Validation loss: 2.2659080310534407

Epoch: 6| Step: 13
Training loss: 2.481400489807129
Validation loss: 2.266488435447857

Epoch: 62| Step: 0
Training loss: 2.1445441246032715
Validation loss: 2.268550229328935

Epoch: 6| Step: 1
Training loss: 3.010730743408203
Validation loss: 2.267940080294045

Epoch: 6| Step: 2
Training loss: 3.46420955657959
Validation loss: 2.2679735563134633

Epoch: 6| Step: 3
Training loss: 2.5351431369781494
Validation loss: 2.27477603830317

Epoch: 6| Step: 4
Training loss: 2.795508861541748
Validation loss: 2.2894431673070437

Epoch: 6| Step: 5
Training loss: 2.348267078399658
Validation loss: 2.310657457638812

Epoch: 6| Step: 6
Training loss: 2.367738723754883
Validation loss: 2.344281640104068

Epoch: 6| Step: 7
Training loss: 2.873072862625122
Validation loss: 2.357832590738932

Epoch: 6| Step: 8
Training loss: 3.109978675842285
Validation loss: 2.3756025068221556

Epoch: 6| Step: 9
Training loss: 2.505429267883301
Validation loss: 2.3356462960602133

Epoch: 6| Step: 10
Training loss: 2.2993550300598145
Validation loss: 2.3137925183901222

Epoch: 6| Step: 11
Training loss: 1.5753800868988037
Validation loss: 2.29190997410846

Epoch: 6| Step: 12
Training loss: 2.496896743774414
Validation loss: 2.264674250797559

Epoch: 6| Step: 13
Training loss: 2.6435327529907227
Validation loss: 2.265185148485245

Epoch: 63| Step: 0
Training loss: 2.3130276203155518
Validation loss: 2.260432756075295

Epoch: 6| Step: 1
Training loss: 2.082866668701172
Validation loss: 2.259226119646462

Epoch: 6| Step: 2
Training loss: 2.825143575668335
Validation loss: 2.2584846301745345

Epoch: 6| Step: 3
Training loss: 1.9921987056732178
Validation loss: 2.2592777206051733

Epoch: 6| Step: 4
Training loss: 3.4897780418395996
Validation loss: 2.2582188203770626

Epoch: 6| Step: 5
Training loss: 2.381108045578003
Validation loss: 2.2587369026676303

Epoch: 6| Step: 6
Training loss: 2.901742935180664
Validation loss: 2.263994727083432

Epoch: 6| Step: 7
Training loss: 1.9767547845840454
Validation loss: 2.2625989221757457

Epoch: 6| Step: 8
Training loss: 2.7769196033477783
Validation loss: 2.260775694283106

Epoch: 6| Step: 9
Training loss: 2.568448066711426
Validation loss: 2.2525786994605936

Epoch: 6| Step: 10
Training loss: 2.872906446456909
Validation loss: 2.2523743901201474

Epoch: 6| Step: 11
Training loss: 2.8673524856567383
Validation loss: 2.2582857531885945

Epoch: 6| Step: 12
Training loss: 2.1926515102386475
Validation loss: 2.284003516679169

Epoch: 6| Step: 13
Training loss: 3.1293673515319824
Validation loss: 2.304701917914934

Epoch: 64| Step: 0
Training loss: 2.6450514793395996
Validation loss: 2.3263533576842277

Epoch: 6| Step: 1
Training loss: 2.635615348815918
Validation loss: 2.3413236166841243

Epoch: 6| Step: 2
Training loss: 2.7249536514282227
Validation loss: 2.360973427372594

Epoch: 6| Step: 3
Training loss: 2.405003070831299
Validation loss: 2.3682546000326834

Epoch: 6| Step: 4
Training loss: 1.8196684122085571
Validation loss: 2.3676634834658716

Epoch: 6| Step: 5
Training loss: 1.901869773864746
Validation loss: 2.359848468534408

Epoch: 6| Step: 6
Training loss: 3.4183759689331055
Validation loss: 2.3134829472470027

Epoch: 6| Step: 7
Training loss: 2.817333221435547
Validation loss: 2.2781781740086053

Epoch: 6| Step: 8
Training loss: 2.6412601470947266
Validation loss: 2.257125787837531

Epoch: 6| Step: 9
Training loss: 2.588047981262207
Validation loss: 2.2488222378556446

Epoch: 6| Step: 10
Training loss: 2.7283177375793457
Validation loss: 2.246884484444895

Epoch: 6| Step: 11
Training loss: 2.4226880073547363
Validation loss: 2.2438301706826813

Epoch: 6| Step: 12
Training loss: 2.8838984966278076
Validation loss: 2.245189816721024

Epoch: 6| Step: 13
Training loss: 2.066715717315674
Validation loss: 2.2444038724386566

Epoch: 65| Step: 0
Training loss: 2.4016828536987305
Validation loss: 2.2452686653342298

Epoch: 6| Step: 1
Training loss: 3.0776920318603516
Validation loss: 2.2401939233144126

Epoch: 6| Step: 2
Training loss: 2.5171494483947754
Validation loss: 2.2438337290158836

Epoch: 6| Step: 3
Training loss: 2.3395986557006836
Validation loss: 2.2412716855284986

Epoch: 6| Step: 4
Training loss: 2.740830659866333
Validation loss: 2.2439794591678086

Epoch: 6| Step: 5
Training loss: 2.2069954872131348
Validation loss: 2.2466916063780427

Epoch: 6| Step: 6
Training loss: 2.1522789001464844
Validation loss: 2.253675606942946

Epoch: 6| Step: 7
Training loss: 2.6395440101623535
Validation loss: 2.243524166845506

Epoch: 6| Step: 8
Training loss: 2.102907419204712
Validation loss: 2.2470739374878588

Epoch: 6| Step: 9
Training loss: 3.0769314765930176
Validation loss: 2.243688162936959

Epoch: 6| Step: 10
Training loss: 3.0468170642852783
Validation loss: 2.2458215246918383

Epoch: 6| Step: 11
Training loss: 2.379828453063965
Validation loss: 2.2424965058603594

Epoch: 6| Step: 12
Training loss: 2.7722339630126953
Validation loss: 2.242448322234615

Epoch: 6| Step: 13
Training loss: 2.3682916164398193
Validation loss: 2.2436879168274584

Epoch: 66| Step: 0
Training loss: 2.4856035709381104
Validation loss: 2.246551990509033

Epoch: 6| Step: 1
Training loss: 2.7703323364257812
Validation loss: 2.248829336576564

Epoch: 6| Step: 2
Training loss: 2.534776210784912
Validation loss: 2.249045269463652

Epoch: 6| Step: 3
Training loss: 2.43874192237854
Validation loss: 2.257083859494937

Epoch: 6| Step: 4
Training loss: 2.7574172019958496
Validation loss: 2.2633080469664706

Epoch: 6| Step: 5
Training loss: 2.3432793617248535
Validation loss: 2.261667766878682

Epoch: 6| Step: 6
Training loss: 2.5384581089019775
Validation loss: 2.2689799839450466

Epoch: 6| Step: 7
Training loss: 2.3669848442077637
Validation loss: 2.284090752242714

Epoch: 6| Step: 8
Training loss: 2.5340518951416016
Validation loss: 2.289460310371973

Epoch: 6| Step: 9
Training loss: 2.889775276184082
Validation loss: 2.295444708998485

Epoch: 6| Step: 10
Training loss: 2.956576347351074
Validation loss: 2.2937884548658967

Epoch: 6| Step: 11
Training loss: 2.05690598487854
Validation loss: 2.281598534635318

Epoch: 6| Step: 12
Training loss: 2.36458420753479
Validation loss: 2.270333832310092

Epoch: 6| Step: 13
Training loss: 2.87774920463562
Validation loss: 2.2563330152983307

Epoch: 67| Step: 0
Training loss: 2.543508529663086
Validation loss: 2.245533520175565

Epoch: 6| Step: 1
Training loss: 2.2466228008270264
Validation loss: 2.2373572446966685

Epoch: 6| Step: 2
Training loss: 3.040107488632202
Validation loss: 2.2349962572897635

Epoch: 6| Step: 3
Training loss: 2.4185667037963867
Validation loss: 2.2295839453256256

Epoch: 6| Step: 4
Training loss: 2.039442539215088
Validation loss: 2.231027087857646

Epoch: 6| Step: 5
Training loss: 2.682577133178711
Validation loss: 2.2321369673616145

Epoch: 6| Step: 6
Training loss: 2.4324779510498047
Validation loss: 2.2322249912446543

Epoch: 6| Step: 7
Training loss: 2.5401647090911865
Validation loss: 2.230258280231107

Epoch: 6| Step: 8
Training loss: 2.7294223308563232
Validation loss: 2.2280658265595794

Epoch: 6| Step: 9
Training loss: 2.7308945655822754
Validation loss: 2.224374617299726

Epoch: 6| Step: 10
Training loss: 2.1428771018981934
Validation loss: 2.228282384974982

Epoch: 6| Step: 11
Training loss: 2.787919521331787
Validation loss: 2.2230788584678405

Epoch: 6| Step: 12
Training loss: 2.634477138519287
Validation loss: 2.227471741296912

Epoch: 6| Step: 13
Training loss: 3.1948118209838867
Validation loss: 2.23211758623841

Epoch: 68| Step: 0
Training loss: 2.3487563133239746
Validation loss: 2.241406674026161

Epoch: 6| Step: 1
Training loss: 2.2086215019226074
Validation loss: 2.2476927080462055

Epoch: 6| Step: 2
Training loss: 2.4475250244140625
Validation loss: 2.2859953911073747

Epoch: 6| Step: 3
Training loss: 2.5084056854248047
Validation loss: 2.308333607130153

Epoch: 6| Step: 4
Training loss: 2.979560375213623
Validation loss: 2.327248698921614

Epoch: 6| Step: 5
Training loss: 2.271306037902832
Validation loss: 2.3283905188242593

Epoch: 6| Step: 6
Training loss: 2.925276279449463
Validation loss: 2.284665894764726

Epoch: 6| Step: 7
Training loss: 3.29610013961792
Validation loss: 2.253606624500726

Epoch: 6| Step: 8
Training loss: 2.579486608505249
Validation loss: 2.224478489609175

Epoch: 6| Step: 9
Training loss: 2.0901618003845215
Validation loss: 2.220342582271945

Epoch: 6| Step: 10
Training loss: 2.831855297088623
Validation loss: 2.2185041314812115

Epoch: 6| Step: 11
Training loss: 2.0283303260803223
Validation loss: 2.225566489722139

Epoch: 6| Step: 12
Training loss: 2.6964962482452393
Validation loss: 2.2321035785059773

Epoch: 6| Step: 13
Training loss: 2.534086227416992
Validation loss: 2.2330389574009883

Epoch: 69| Step: 0
Training loss: 2.2311155796051025
Validation loss: 2.2377387374959965

Epoch: 6| Step: 1
Training loss: 2.2276763916015625
Validation loss: 2.2503750631886144

Epoch: 6| Step: 2
Training loss: 2.7806341648101807
Validation loss: 2.238936262746011

Epoch: 6| Step: 3
Training loss: 2.7849621772766113
Validation loss: 2.227168216500231

Epoch: 6| Step: 4
Training loss: 3.2380077838897705
Validation loss: 2.269899704123056

Epoch: 6| Step: 5
Training loss: 2.750082015991211
Validation loss: 2.2993687929645663

Epoch: 6| Step: 6
Training loss: 2.148855686187744
Validation loss: 2.3104878574289303

Epoch: 6| Step: 7
Training loss: 2.1265745162963867
Validation loss: 2.323601166407267

Epoch: 6| Step: 8
Training loss: 2.689685821533203
Validation loss: 2.331817175752373

Epoch: 6| Step: 9
Training loss: 3.0360348224639893
Validation loss: 2.3287013833240797

Epoch: 6| Step: 10
Training loss: 2.1014533042907715
Validation loss: 2.326607624689738

Epoch: 6| Step: 11
Training loss: 2.3401122093200684
Validation loss: 2.3149204125968357

Epoch: 6| Step: 12
Training loss: 2.4465837478637695
Validation loss: 2.312581741681663

Epoch: 6| Step: 13
Training loss: 3.7672581672668457
Validation loss: 2.3007547881013606

Epoch: 70| Step: 0
Training loss: 3.0148415565490723
Validation loss: 2.294069263242906

Epoch: 6| Step: 1
Training loss: 2.596658706665039
Validation loss: 2.2951579478479203

Epoch: 6| Step: 2
Training loss: 2.5516068935394287
Validation loss: 2.2889191822339128

Epoch: 6| Step: 3
Training loss: 2.612273693084717
Validation loss: 2.295146567847139

Epoch: 6| Step: 4
Training loss: 2.176974058151245
Validation loss: 2.3011675124527304

Epoch: 6| Step: 5
Training loss: 2.5224075317382812
Validation loss: 2.3001464771968063

Epoch: 6| Step: 6
Training loss: 2.5653960704803467
Validation loss: 2.293533913550838

Epoch: 6| Step: 7
Training loss: 2.157238483428955
Validation loss: 2.2904140615975983

Epoch: 6| Step: 8
Training loss: 2.8167333602905273
Validation loss: 2.2782713649093465

Epoch: 6| Step: 9
Training loss: 2.839089870452881
Validation loss: 2.2732524718007734

Epoch: 6| Step: 10
Training loss: 1.9158287048339844
Validation loss: 2.2692658593577724

Epoch: 6| Step: 11
Training loss: 2.1982038021087646
Validation loss: 2.263919661121984

Epoch: 6| Step: 12
Training loss: 2.8704707622528076
Validation loss: 2.2640787837325886

Epoch: 6| Step: 13
Training loss: 3.381411552429199
Validation loss: 2.2509796696324504

Epoch: 71| Step: 0
Training loss: 3.1707844734191895
Validation loss: 2.218586557654924

Epoch: 6| Step: 1
Training loss: 2.406648635864258
Validation loss: 2.203141975146468

Epoch: 6| Step: 2
Training loss: 2.5133423805236816
Validation loss: 2.205959532850532

Epoch: 6| Step: 3
Training loss: 2.276036500930786
Validation loss: 2.21027026894272

Epoch: 6| Step: 4
Training loss: 2.838761806488037
Validation loss: 2.213351977768765

Epoch: 6| Step: 5
Training loss: 2.189925193786621
Validation loss: 2.204270362854004

Epoch: 6| Step: 6
Training loss: 2.9338223934173584
Validation loss: 2.2136098825803368

Epoch: 6| Step: 7
Training loss: 2.283320903778076
Validation loss: 2.204621681603052

Epoch: 6| Step: 8
Training loss: 2.283470630645752
Validation loss: 2.2018578155066377

Epoch: 6| Step: 9
Training loss: 2.2130706310272217
Validation loss: 2.205862286270306

Epoch: 6| Step: 10
Training loss: 2.5835089683532715
Validation loss: 2.2251599270810365

Epoch: 6| Step: 11
Training loss: 2.640282154083252
Validation loss: 2.2394691333975842

Epoch: 6| Step: 12
Training loss: 2.5283730030059814
Validation loss: 2.231560963456349

Epoch: 6| Step: 13
Training loss: 2.350768566131592
Validation loss: 2.2283678182991604

Epoch: 72| Step: 0
Training loss: 2.4994335174560547
Validation loss: 2.224256364248132

Epoch: 6| Step: 1
Training loss: 2.444331407546997
Validation loss: 2.2351975928070726

Epoch: 6| Step: 2
Training loss: 2.656034231185913
Validation loss: 2.2509099104071177

Epoch: 6| Step: 3
Training loss: 2.338839292526245
Validation loss: 2.2455856876988567

Epoch: 6| Step: 4
Training loss: 2.14306640625
Validation loss: 2.2576912910707536

Epoch: 6| Step: 5
Training loss: 2.8058056831359863
Validation loss: 2.2965149751273533

Epoch: 6| Step: 6
Training loss: 2.498504638671875
Validation loss: 2.315345112995435

Epoch: 6| Step: 7
Training loss: 3.051379680633545
Validation loss: 2.3361146014223815

Epoch: 6| Step: 8
Training loss: 2.2253339290618896
Validation loss: 2.3462795954878612

Epoch: 6| Step: 9
Training loss: 2.7654151916503906
Validation loss: 2.3601543595713954

Epoch: 6| Step: 10
Training loss: 2.734103202819824
Validation loss: 2.333352986202445

Epoch: 6| Step: 11
Training loss: 2.3083550930023193
Validation loss: 2.3027095512677263

Epoch: 6| Step: 12
Training loss: 2.697901725769043
Validation loss: 2.2694720375922417

Epoch: 6| Step: 13
Training loss: 2.501859664916992
Validation loss: 2.2274562543438328

Epoch: 73| Step: 0
Training loss: 3.0865848064422607
Validation loss: 2.225142332815355

Epoch: 6| Step: 1
Training loss: 2.38464093208313
Validation loss: 2.248910222002255

Epoch: 6| Step: 2
Training loss: 3.0234689712524414
Validation loss: 2.276303240047988

Epoch: 6| Step: 3
Training loss: 2.499028444290161
Validation loss: 2.310929326600926

Epoch: 6| Step: 4
Training loss: 2.2645721435546875
Validation loss: 2.315160566760648

Epoch: 6| Step: 5
Training loss: 2.350506067276001
Validation loss: 2.286843758757396

Epoch: 6| Step: 6
Training loss: 3.992424964904785
Validation loss: 2.2599402037999963

Epoch: 6| Step: 7
Training loss: 2.224050521850586
Validation loss: 2.2474044830568376

Epoch: 6| Step: 8
Training loss: 2.8366312980651855
Validation loss: 2.2787375193770214

Epoch: 6| Step: 9
Training loss: 2.352531671524048
Validation loss: 2.311985875970574

Epoch: 6| Step: 10
Training loss: 1.9199649095535278
Validation loss: 2.354713201522827

Epoch: 6| Step: 11
Training loss: 2.6825814247131348
Validation loss: 2.3912630234995196

Epoch: 6| Step: 12
Training loss: 2.48952054977417
Validation loss: 2.426970702345653

Epoch: 6| Step: 13
Training loss: 2.222546100616455
Validation loss: 2.40859398406039

Epoch: 74| Step: 0
Training loss: 2.7158796787261963
Validation loss: 2.3455382034342778

Epoch: 6| Step: 1
Training loss: 2.3446109294891357
Validation loss: 2.2922810713450112

Epoch: 6| Step: 2
Training loss: 3.183852195739746
Validation loss: 2.25993440997216

Epoch: 6| Step: 3
Training loss: 2.854672431945801
Validation loss: 2.2506265588985976

Epoch: 6| Step: 4
Training loss: 2.7250328063964844
Validation loss: 2.278820296769501

Epoch: 6| Step: 5
Training loss: 2.11737322807312
Validation loss: 2.338782374576856

Epoch: 6| Step: 6
Training loss: 2.048994541168213
Validation loss: 2.3813695471773864

Epoch: 6| Step: 7
Training loss: 3.0318384170532227
Validation loss: 2.4220334509367585

Epoch: 6| Step: 8
Training loss: 2.3081021308898926
Validation loss: 2.4885978237275155

Epoch: 6| Step: 9
Training loss: 2.468841552734375
Validation loss: 2.425903904822565

Epoch: 6| Step: 10
Training loss: 3.447556495666504
Validation loss: 2.3823533788804085

Epoch: 6| Step: 11
Training loss: 2.5200955867767334
Validation loss: 2.324690188131025

Epoch: 6| Step: 12
Training loss: 2.764292001724243
Validation loss: 2.28148675862179

Epoch: 6| Step: 13
Training loss: 1.8539971113204956
Validation loss: 2.242317940599175

Epoch: 75| Step: 0
Training loss: 2.351275682449341
Validation loss: 2.22408660252889

Epoch: 6| Step: 1
Training loss: 2.1024351119995117
Validation loss: 2.2330509744664675

Epoch: 6| Step: 2
Training loss: 3.0234217643737793
Validation loss: 2.2526675706268637

Epoch: 6| Step: 3
Training loss: 2.147984504699707
Validation loss: 2.2518991398554977

Epoch: 6| Step: 4
Training loss: 2.7744529247283936
Validation loss: 2.244806863928354

Epoch: 6| Step: 5
Training loss: 3.116060256958008
Validation loss: 2.239556304870113

Epoch: 6| Step: 6
Training loss: 2.35642147064209
Validation loss: 2.2364411225882908

Epoch: 6| Step: 7
Training loss: 2.7310550212860107
Validation loss: 2.2522885748135146

Epoch: 6| Step: 8
Training loss: 2.040370464324951
Validation loss: 2.2649080471325944

Epoch: 6| Step: 9
Training loss: 2.4896645545959473
Validation loss: 2.2571415516637985

Epoch: 6| Step: 10
Training loss: 1.8231770992279053
Validation loss: 2.2588170613012006

Epoch: 6| Step: 11
Training loss: 2.9819416999816895
Validation loss: 2.2313523113086657

Epoch: 6| Step: 12
Training loss: 2.6245298385620117
Validation loss: 2.224861793620612

Epoch: 6| Step: 13
Training loss: 2.8940930366516113
Validation loss: 2.205975926050576

Epoch: 76| Step: 0
Training loss: 2.7477030754089355
Validation loss: 2.1939484457815848

Epoch: 6| Step: 1
Training loss: 2.241082191467285
Validation loss: 2.177503180760209

Epoch: 6| Step: 2
Training loss: 2.539607048034668
Validation loss: 2.1697335755953224

Epoch: 6| Step: 3
Training loss: 2.641935110092163
Validation loss: 2.1634908286474084

Epoch: 6| Step: 4
Training loss: 2.471853256225586
Validation loss: 2.161460066354403

Epoch: 6| Step: 5
Training loss: 2.334439754486084
Validation loss: 2.165914238140147

Epoch: 6| Step: 6
Training loss: 2.5877320766448975
Validation loss: 2.165014728423088

Epoch: 6| Step: 7
Training loss: 2.63018798828125
Validation loss: 2.15629082341348

Epoch: 6| Step: 8
Training loss: 2.576955795288086
Validation loss: 2.156946741124635

Epoch: 6| Step: 9
Training loss: 2.25266695022583
Validation loss: 2.151494126166067

Epoch: 6| Step: 10
Training loss: 2.9607596397399902
Validation loss: 2.1555204724752777

Epoch: 6| Step: 11
Training loss: 2.3103907108306885
Validation loss: 2.157905641422477

Epoch: 6| Step: 12
Training loss: 2.5971837043762207
Validation loss: 2.1643645507033153

Epoch: 6| Step: 13
Training loss: 2.2255468368530273
Validation loss: 2.178242375773768

Epoch: 77| Step: 0
Training loss: 3.165980100631714
Validation loss: 2.173962846879036

Epoch: 6| Step: 1
Training loss: 2.2637128829956055
Validation loss: 2.174268489242882

Epoch: 6| Step: 2
Training loss: 2.3857758045196533
Validation loss: 2.1787426702437864

Epoch: 6| Step: 3
Training loss: 2.7245428562164307
Validation loss: 2.1870749304371495

Epoch: 6| Step: 4
Training loss: 1.8819016218185425
Validation loss: 2.1832812050337433

Epoch: 6| Step: 5
Training loss: 2.6572158336639404
Validation loss: 2.190524458885193

Epoch: 6| Step: 6
Training loss: 2.824098587036133
Validation loss: 2.187843730372767

Epoch: 6| Step: 7
Training loss: 2.4334216117858887
Validation loss: 2.1912494167204826

Epoch: 6| Step: 8
Training loss: 3.018794298171997
Validation loss: 2.194586625663183

Epoch: 6| Step: 9
Training loss: 2.1565141677856445
Validation loss: 2.1913904707918883

Epoch: 6| Step: 10
Training loss: 2.2709219455718994
Validation loss: 2.1704951768280356

Epoch: 6| Step: 11
Training loss: 3.176844596862793
Validation loss: 2.153014886763788

Epoch: 6| Step: 12
Training loss: 2.0486466884613037
Validation loss: 2.142866003897882

Epoch: 6| Step: 13
Training loss: 1.5757288932800293
Validation loss: 2.145350562628879

Epoch: 78| Step: 0
Training loss: 1.9226703643798828
Validation loss: 2.1421245067350325

Epoch: 6| Step: 1
Training loss: 1.9570207595825195
Validation loss: 2.1413924206969557

Epoch: 6| Step: 2
Training loss: 2.525247573852539
Validation loss: 2.146506594073388

Epoch: 6| Step: 3
Training loss: 2.4870314598083496
Validation loss: 2.146107214753346

Epoch: 6| Step: 4
Training loss: 2.33956241607666
Validation loss: 2.144286476155763

Epoch: 6| Step: 5
Training loss: 2.4782400131225586
Validation loss: 2.145944436391195

Epoch: 6| Step: 6
Training loss: 2.4628148078918457
Validation loss: 2.1431077116279194

Epoch: 6| Step: 7
Training loss: 3.5375113487243652
Validation loss: 2.15148062603448

Epoch: 6| Step: 8
Training loss: 2.3599517345428467
Validation loss: 2.1505833748848207

Epoch: 6| Step: 9
Training loss: 2.7907166481018066
Validation loss: 2.15353326900031

Epoch: 6| Step: 10
Training loss: 2.9465460777282715
Validation loss: 2.158065676689148

Epoch: 6| Step: 11
Training loss: 2.241954803466797
Validation loss: 2.15603304934758

Epoch: 6| Step: 12
Training loss: 2.3582613468170166
Validation loss: 2.1640253643835745

Epoch: 6| Step: 13
Training loss: 2.536836862564087
Validation loss: 2.1718956193616314

Epoch: 79| Step: 0
Training loss: 2.0437510013580322
Validation loss: 2.170217070528256

Epoch: 6| Step: 1
Training loss: 2.40144944190979
Validation loss: 2.156178187298518

Epoch: 6| Step: 2
Training loss: 2.346201181411743
Validation loss: 2.153928659295523

Epoch: 6| Step: 3
Training loss: 2.258098602294922
Validation loss: 2.1432193581775953

Epoch: 6| Step: 4
Training loss: 2.574411153793335
Validation loss: 2.1471990975000526

Epoch: 6| Step: 5
Training loss: 3.125169277191162
Validation loss: 2.15058643843538

Epoch: 6| Step: 6
Training loss: 2.745405912399292
Validation loss: 2.147837487600183

Epoch: 6| Step: 7
Training loss: 2.4641976356506348
Validation loss: 2.1398164943982194

Epoch: 6| Step: 8
Training loss: 1.5669132471084595
Validation loss: 2.1430844978619645

Epoch: 6| Step: 9
Training loss: 3.38865327835083
Validation loss: 2.148337603897177

Epoch: 6| Step: 10
Training loss: 2.005749225616455
Validation loss: 2.1447819279086207

Epoch: 6| Step: 11
Training loss: 2.541066884994507
Validation loss: 2.149225145257929

Epoch: 6| Step: 12
Training loss: 2.71260929107666
Validation loss: 2.1478691024164998

Epoch: 6| Step: 13
Training loss: 2.643570899963379
Validation loss: 2.1479654645407074

Epoch: 80| Step: 0
Training loss: 2.9244096279144287
Validation loss: 2.145570762695805

Epoch: 6| Step: 1
Training loss: 2.16141414642334
Validation loss: 2.1361219242054927

Epoch: 6| Step: 2
Training loss: 2.353030204772949
Validation loss: 2.1262484186439106

Epoch: 6| Step: 3
Training loss: 2.359659194946289
Validation loss: 2.1290251926709245

Epoch: 6| Step: 4
Training loss: 2.935006618499756
Validation loss: 2.131219338345271

Epoch: 6| Step: 5
Training loss: 2.4080018997192383
Validation loss: 2.1308445930480957

Epoch: 6| Step: 6
Training loss: 2.054790496826172
Validation loss: 2.1479861479933544

Epoch: 6| Step: 7
Training loss: 2.782289743423462
Validation loss: 2.1445608408220354

Epoch: 6| Step: 8
Training loss: 2.9509263038635254
Validation loss: 2.1511344499485467

Epoch: 6| Step: 9
Training loss: 2.3007352352142334
Validation loss: 2.1612453153056483

Epoch: 6| Step: 10
Training loss: 2.9236092567443848
Validation loss: 2.1648730398506246

Epoch: 6| Step: 11
Training loss: 2.5785884857177734
Validation loss: 2.1608819397546912

Epoch: 6| Step: 12
Training loss: 2.026977062225342
Validation loss: 2.174198437762517

Epoch: 6| Step: 13
Training loss: 1.2614531517028809
Validation loss: 2.2020721717547347

Epoch: 81| Step: 0
Training loss: 2.174898386001587
Validation loss: 2.239551897971861

Epoch: 6| Step: 1
Training loss: 3.3386073112487793
Validation loss: 2.259323030389765

Epoch: 6| Step: 2
Training loss: 2.7158684730529785
Validation loss: 2.2708429316038727

Epoch: 6| Step: 3
Training loss: 2.266465663909912
Validation loss: 2.269449249390633

Epoch: 6| Step: 4
Training loss: 1.984379768371582
Validation loss: 2.231123060308477

Epoch: 6| Step: 5
Training loss: 2.7000417709350586
Validation loss: 2.204792994324879

Epoch: 6| Step: 6
Training loss: 1.7198768854141235
Validation loss: 2.177499019971458

Epoch: 6| Step: 7
Training loss: 2.622729778289795
Validation loss: 2.1727174956311464

Epoch: 6| Step: 8
Training loss: 3.290921211242676
Validation loss: 2.1669079462687173

Epoch: 6| Step: 9
Training loss: 2.954458475112915
Validation loss: 2.155367612838745

Epoch: 6| Step: 10
Training loss: 2.1137423515319824
Validation loss: 2.1516283199351323

Epoch: 6| Step: 11
Training loss: 1.7142515182495117
Validation loss: 2.1480591168967624

Epoch: 6| Step: 12
Training loss: 2.947695732116699
Validation loss: 2.1458931635784846

Epoch: 6| Step: 13
Training loss: 2.1888108253479004
Validation loss: 2.1367315887123026

Epoch: 82| Step: 0
Training loss: 2.3522205352783203
Validation loss: 2.1397403465804232

Epoch: 6| Step: 1
Training loss: 2.6528759002685547
Validation loss: 2.155903667531988

Epoch: 6| Step: 2
Training loss: 2.4553470611572266
Validation loss: 2.1799135733676214

Epoch: 6| Step: 3
Training loss: 1.961040735244751
Validation loss: 2.1760411493239866

Epoch: 6| Step: 4
Training loss: 2.6056487560272217
Validation loss: 2.186025465688398

Epoch: 6| Step: 5
Training loss: 2.9609804153442383
Validation loss: 2.163220792688349

Epoch: 6| Step: 6
Training loss: 2.6273207664489746
Validation loss: 2.156698052601148

Epoch: 6| Step: 7
Training loss: 2.187288284301758
Validation loss: 2.1556470265952488

Epoch: 6| Step: 8
Training loss: 2.2264564037323
Validation loss: 2.157727224852449

Epoch: 6| Step: 9
Training loss: 2.0901622772216797
Validation loss: 2.1675850486242645

Epoch: 6| Step: 10
Training loss: 2.8710248470306396
Validation loss: 2.17137901500989

Epoch: 6| Step: 11
Training loss: 2.662590503692627
Validation loss: 2.1897890695961575

Epoch: 6| Step: 12
Training loss: 2.785186290740967
Validation loss: 2.1782859063917592

Epoch: 6| Step: 13
Training loss: 1.8655675649642944
Validation loss: 2.1623900731404624

Epoch: 83| Step: 0
Training loss: 2.5746278762817383
Validation loss: 2.1363464042704594

Epoch: 6| Step: 1
Training loss: 2.0769906044006348
Validation loss: 2.117109308960617

Epoch: 6| Step: 2
Training loss: 1.9494950771331787
Validation loss: 2.1117609880303823

Epoch: 6| Step: 3
Training loss: 2.817283868789673
Validation loss: 2.1056701073082547

Epoch: 6| Step: 4
Training loss: 1.9793050289154053
Validation loss: 2.107557547989712

Epoch: 6| Step: 5
Training loss: 2.527716636657715
Validation loss: 2.106435929575274

Epoch: 6| Step: 6
Training loss: 2.6601366996765137
Validation loss: 2.1070481987409693

Epoch: 6| Step: 7
Training loss: 2.866755247116089
Validation loss: 2.104482784066149

Epoch: 6| Step: 8
Training loss: 1.9299755096435547
Validation loss: 2.1093813821833622

Epoch: 6| Step: 9
Training loss: 2.4459517002105713
Validation loss: 2.105476058939452

Epoch: 6| Step: 10
Training loss: 2.9917478561401367
Validation loss: 2.1236155853476575

Epoch: 6| Step: 11
Training loss: 2.5093226432800293
Validation loss: 2.1311845702509724

Epoch: 6| Step: 12
Training loss: 2.6380715370178223
Validation loss: 2.1404923546698784

Epoch: 6| Step: 13
Training loss: 2.1454100608825684
Validation loss: 2.1546239942632694

Epoch: 84| Step: 0
Training loss: 2.490414619445801
Validation loss: 2.1456721162283294

Epoch: 6| Step: 1
Training loss: 3.0175139904022217
Validation loss: 2.1423159145539805

Epoch: 6| Step: 2
Training loss: 2.8957719802856445
Validation loss: 2.1391724771068943

Epoch: 6| Step: 3
Training loss: 2.7569093704223633
Validation loss: 2.127332797614477

Epoch: 6| Step: 4
Training loss: 2.1385421752929688
Validation loss: 2.1316544958340224

Epoch: 6| Step: 5
Training loss: 1.751117467880249
Validation loss: 2.1236108759398102

Epoch: 6| Step: 6
Training loss: 1.977205514907837
Validation loss: 2.135124203979328

Epoch: 6| Step: 7
Training loss: 2.5633950233459473
Validation loss: 2.145606651101061

Epoch: 6| Step: 8
Training loss: 2.1593198776245117
Validation loss: 2.1362549463907876

Epoch: 6| Step: 9
Training loss: 2.3720967769622803
Validation loss: 2.149409765838295

Epoch: 6| Step: 10
Training loss: 2.1934871673583984
Validation loss: 2.1488214462034163

Epoch: 6| Step: 11
Training loss: 3.5232558250427246
Validation loss: 2.1387602385654243

Epoch: 6| Step: 12
Training loss: 2.3334906101226807
Validation loss: 2.1269952507429224

Epoch: 6| Step: 13
Training loss: 1.6917470693588257
Validation loss: 2.119574918541857

Epoch: 85| Step: 0
Training loss: 2.2463760375976562
Validation loss: 2.1234978552787536

Epoch: 6| Step: 1
Training loss: 2.1356983184814453
Validation loss: 2.1299808409906205

Epoch: 6| Step: 2
Training loss: 3.1881027221679688
Validation loss: 2.139082531775198

Epoch: 6| Step: 3
Training loss: 2.793583869934082
Validation loss: 2.128914906132606

Epoch: 6| Step: 4
Training loss: 1.9949593544006348
Validation loss: 2.129137618567354

Epoch: 6| Step: 5
Training loss: 2.679830551147461
Validation loss: 2.12730412842125

Epoch: 6| Step: 6
Training loss: 2.0251309871673584
Validation loss: 2.1219219469255015

Epoch: 6| Step: 7
Training loss: 2.515272617340088
Validation loss: 2.131017978473376

Epoch: 6| Step: 8
Training loss: 2.385650634765625
Validation loss: 2.1333317525925173

Epoch: 6| Step: 9
Training loss: 2.4526596069335938
Validation loss: 2.131168765406455

Epoch: 6| Step: 10
Training loss: 3.2382659912109375
Validation loss: 2.137854186437463

Epoch: 6| Step: 11
Training loss: 2.3825292587280273
Validation loss: 2.1359787141123125

Epoch: 6| Step: 12
Training loss: 2.050116777420044
Validation loss: 2.140202251813745

Epoch: 6| Step: 13
Training loss: 2.0207431316375732
Validation loss: 2.1602143984968945

Epoch: 86| Step: 0
Training loss: 2.7689929008483887
Validation loss: 2.1858201283280567

Epoch: 6| Step: 1
Training loss: 3.3536648750305176
Validation loss: 2.21158351180374

Epoch: 6| Step: 2
Training loss: 1.9658204317092896
Validation loss: 2.1862811375689764

Epoch: 6| Step: 3
Training loss: 2.3408093452453613
Validation loss: 2.150846819723806

Epoch: 6| Step: 4
Training loss: 2.017493486404419
Validation loss: 2.120863206924931

Epoch: 6| Step: 5
Training loss: 2.2009878158569336
Validation loss: 2.1213869920340915

Epoch: 6| Step: 6
Training loss: 1.7345385551452637
Validation loss: 2.122303473052158

Epoch: 6| Step: 7
Training loss: 2.7759246826171875
Validation loss: 2.124606970817812

Epoch: 6| Step: 8
Training loss: 2.648221492767334
Validation loss: 2.1496361917065037

Epoch: 6| Step: 9
Training loss: 3.0667080879211426
Validation loss: 2.143856410057314

Epoch: 6| Step: 10
Training loss: 2.5165066719055176
Validation loss: 2.139094623186255

Epoch: 6| Step: 11
Training loss: 2.2931036949157715
Validation loss: 2.1472275282747004

Epoch: 6| Step: 12
Training loss: 1.8961317539215088
Validation loss: 2.133701975627612

Epoch: 6| Step: 13
Training loss: 2.6047756671905518
Validation loss: 2.134015690895819

Epoch: 87| Step: 0
Training loss: 2.536470413208008
Validation loss: 2.1160979899027015

Epoch: 6| Step: 1
Training loss: 2.5310134887695312
Validation loss: 2.1040793541939027

Epoch: 6| Step: 2
Training loss: 2.639324903488159
Validation loss: 2.1044612930667017

Epoch: 6| Step: 3
Training loss: 2.9664487838745117
Validation loss: 2.0866281191507974

Epoch: 6| Step: 4
Training loss: 2.4435901641845703
Validation loss: 2.082476382614464

Epoch: 6| Step: 5
Training loss: 2.6067912578582764
Validation loss: 2.092709590029973

Epoch: 6| Step: 6
Training loss: 2.3171732425689697
Validation loss: 2.089737069222235

Epoch: 6| Step: 7
Training loss: 2.851560592651367
Validation loss: 2.0874732155953684

Epoch: 6| Step: 8
Training loss: 2.058018684387207
Validation loss: 2.0860886548155095

Epoch: 6| Step: 9
Training loss: 1.3976348638534546
Validation loss: 2.0729055994300434

Epoch: 6| Step: 10
Training loss: 2.422152519226074
Validation loss: 2.0876590231413483

Epoch: 6| Step: 11
Training loss: 2.2728426456451416
Validation loss: 2.1135264647904264

Epoch: 6| Step: 12
Training loss: 2.5983939170837402
Validation loss: 2.1832792810214463

Epoch: 6| Step: 13
Training loss: 2.579977512359619
Validation loss: 2.2402765289429696

Epoch: 88| Step: 0
Training loss: 3.5549187660217285
Validation loss: 2.296372006016393

Epoch: 6| Step: 1
Training loss: 2.408003807067871
Validation loss: 2.303444636765347

Epoch: 6| Step: 2
Training loss: 2.6547775268554688
Validation loss: 2.280666620500626

Epoch: 6| Step: 3
Training loss: 1.9858911037445068
Validation loss: 2.1764691055461927

Epoch: 6| Step: 4
Training loss: 2.1971817016601562
Validation loss: 2.1249691542758735

Epoch: 6| Step: 5
Training loss: 2.0505309104919434
Validation loss: 2.0996507060143257

Epoch: 6| Step: 6
Training loss: 3.3100054264068604
Validation loss: 2.0902841373156478

Epoch: 6| Step: 7
Training loss: 2.2886714935302734
Validation loss: 2.078003506506643

Epoch: 6| Step: 8
Training loss: 2.521212577819824
Validation loss: 2.0741266794102167

Epoch: 6| Step: 9
Training loss: 1.798972249031067
Validation loss: 2.0755612516915924

Epoch: 6| Step: 10
Training loss: 2.670236587524414
Validation loss: 2.0743702957707066

Epoch: 6| Step: 11
Training loss: 2.337063789367676
Validation loss: 2.082535974441036

Epoch: 6| Step: 12
Training loss: 2.206144332885742
Validation loss: 2.076056780353669

Epoch: 6| Step: 13
Training loss: 2.498745918273926
Validation loss: 2.0751229511794222

Epoch: 89| Step: 0
Training loss: 1.732437014579773
Validation loss: 2.0923790342064312

Epoch: 6| Step: 1
Training loss: 2.1454193592071533
Validation loss: 2.116016721212736

Epoch: 6| Step: 2
Training loss: 2.7671866416931152
Validation loss: 2.129228566282539

Epoch: 6| Step: 3
Training loss: 2.877499580383301
Validation loss: 2.15551245597101

Epoch: 6| Step: 4
Training loss: 3.170370578765869
Validation loss: 2.1691722741691013

Epoch: 6| Step: 5
Training loss: 2.8869173526763916
Validation loss: 2.148564402775098

Epoch: 6| Step: 6
Training loss: 1.2969210147857666
Validation loss: 2.1248155614381194

Epoch: 6| Step: 7
Training loss: 2.6107921600341797
Validation loss: 2.1133130852894118

Epoch: 6| Step: 8
Training loss: 2.7290260791778564
Validation loss: 2.0974194695872646

Epoch: 6| Step: 9
Training loss: 1.8487350940704346
Validation loss: 2.10964802516404

Epoch: 6| Step: 10
Training loss: 2.3889763355255127
Validation loss: 2.1207567850748696

Epoch: 6| Step: 11
Training loss: 2.3934667110443115
Validation loss: 2.1231400030915455

Epoch: 6| Step: 12
Training loss: 2.333423614501953
Validation loss: 2.1199624717876477

Epoch: 6| Step: 13
Training loss: 2.89327335357666
Validation loss: 2.1115896906903995

Epoch: 90| Step: 0
Training loss: 2.139861583709717
Validation loss: 2.1227178958154496

Epoch: 6| Step: 1
Training loss: 2.648495674133301
Validation loss: 2.1136053275036555

Epoch: 6| Step: 2
Training loss: 2.416109561920166
Validation loss: 2.107475241025289

Epoch: 6| Step: 3
Training loss: 2.6062750816345215
Validation loss: 2.0957257824559368

Epoch: 6| Step: 4
Training loss: 2.157728672027588
Validation loss: 2.0867186387379966

Epoch: 6| Step: 5
Training loss: 1.9287391901016235
Validation loss: 2.0865622938320203

Epoch: 6| Step: 6
Training loss: 3.0659635066986084
Validation loss: 2.0842727589350876

Epoch: 6| Step: 7
Training loss: 2.7347381114959717
Validation loss: 2.0948240603170087

Epoch: 6| Step: 8
Training loss: 2.243907928466797
Validation loss: 2.0879271825154624

Epoch: 6| Step: 9
Training loss: 2.359247922897339
Validation loss: 2.096872281002742

Epoch: 6| Step: 10
Training loss: 1.7361822128295898
Validation loss: 2.104941455266809

Epoch: 6| Step: 11
Training loss: 2.770197868347168
Validation loss: 2.1060627762989332

Epoch: 6| Step: 12
Training loss: 2.371793746948242
Validation loss: 2.098209731040462

Epoch: 6| Step: 13
Training loss: 2.6696596145629883
Validation loss: 2.100163839196646

Epoch: 91| Step: 0
Training loss: 1.3450109958648682
Validation loss: 2.1002572531341226

Epoch: 6| Step: 1
Training loss: 2.230008840560913
Validation loss: 2.082304334127775

Epoch: 6| Step: 2
Training loss: 2.6760454177856445
Validation loss: 2.077736314906869

Epoch: 6| Step: 3
Training loss: 2.325972080230713
Validation loss: 2.078133629214379

Epoch: 6| Step: 4
Training loss: 2.106940984725952
Validation loss: 2.0793906219543947

Epoch: 6| Step: 5
Training loss: 2.563852310180664
Validation loss: 2.075551989257977

Epoch: 6| Step: 6
Training loss: 2.5725502967834473
Validation loss: 2.079121123078049

Epoch: 6| Step: 7
Training loss: 2.8224096298217773
Validation loss: 2.083259164646108

Epoch: 6| Step: 8
Training loss: 1.5503008365631104
Validation loss: 2.074805792941842

Epoch: 6| Step: 9
Training loss: 2.558745861053467
Validation loss: 2.083481396398237

Epoch: 6| Step: 10
Training loss: 3.345581293106079
Validation loss: 2.1039441234322003

Epoch: 6| Step: 11
Training loss: 3.0173583030700684
Validation loss: 2.1145335089775825

Epoch: 6| Step: 12
Training loss: 1.7813899517059326
Validation loss: 2.1395181917375132

Epoch: 6| Step: 13
Training loss: 2.6042847633361816
Validation loss: 2.1268125452021116

Epoch: 92| Step: 0
Training loss: 2.3015146255493164
Validation loss: 2.1368016837745585

Epoch: 6| Step: 1
Training loss: 2.3008995056152344
Validation loss: 2.13357299886724

Epoch: 6| Step: 2
Training loss: 2.098097562789917
Validation loss: 2.138275461812173

Epoch: 6| Step: 3
Training loss: 2.79996395111084
Validation loss: 2.160410319605181

Epoch: 6| Step: 4
Training loss: 2.10060453414917
Validation loss: 2.115609448443177

Epoch: 6| Step: 5
Training loss: 2.6551337242126465
Validation loss: 2.083763773723315

Epoch: 6| Step: 6
Training loss: 2.0373892784118652
Validation loss: 2.070817255204724

Epoch: 6| Step: 7
Training loss: 2.023151397705078
Validation loss: 2.0619933374466433

Epoch: 6| Step: 8
Training loss: 2.7021822929382324
Validation loss: 2.0716839682671333

Epoch: 6| Step: 9
Training loss: 3.095733165740967
Validation loss: 2.071145030759996

Epoch: 6| Step: 10
Training loss: 2.1593518257141113
Validation loss: 2.0830310749751266

Epoch: 6| Step: 11
Training loss: 2.266712188720703
Validation loss: 2.072712770072363

Epoch: 6| Step: 12
Training loss: 2.3244709968566895
Validation loss: 2.070028620381509

Epoch: 6| Step: 13
Training loss: 2.8900513648986816
Validation loss: 2.0700170891259306

Epoch: 93| Step: 0
Training loss: 2.6895761489868164
Validation loss: 2.0662190375789518

Epoch: 6| Step: 1
Training loss: 2.497959613800049
Validation loss: 2.061547181939566

Epoch: 6| Step: 2
Training loss: 2.8400611877441406
Validation loss: 2.0635844058887933

Epoch: 6| Step: 3
Training loss: 1.8349192142486572
Validation loss: 2.081131976137879

Epoch: 6| Step: 4
Training loss: 2.4925954341888428
Validation loss: 2.0890764677396385

Epoch: 6| Step: 5
Training loss: 2.1854166984558105
Validation loss: 2.08673071604903

Epoch: 6| Step: 6
Training loss: 2.806692600250244
Validation loss: 2.0952800730223298

Epoch: 6| Step: 7
Training loss: 2.86175537109375
Validation loss: 2.120562732860606

Epoch: 6| Step: 8
Training loss: 2.407641649246216
Validation loss: 2.1286665816460886

Epoch: 6| Step: 9
Training loss: 2.7974276542663574
Validation loss: 2.1092435929083053

Epoch: 6| Step: 10
Training loss: 2.290161371231079
Validation loss: 2.0818189203098254

Epoch: 6| Step: 11
Training loss: 2.07420015335083
Validation loss: 2.0684197461733254

Epoch: 6| Step: 12
Training loss: 1.9483261108398438
Validation loss: 2.058055636703327

Epoch: 6| Step: 13
Training loss: 1.6357108354568481
Validation loss: 2.0658502014734412

Epoch: 94| Step: 0
Training loss: 2.3619449138641357
Validation loss: 2.0642362204931115

Epoch: 6| Step: 1
Training loss: 2.199741840362549
Validation loss: 2.070160068491454

Epoch: 6| Step: 2
Training loss: 2.655881881713867
Validation loss: 2.0695655768917454

Epoch: 6| Step: 3
Training loss: 2.839395523071289
Validation loss: 2.0666636369561635

Epoch: 6| Step: 4
Training loss: 2.549393653869629
Validation loss: 2.0527411225021526

Epoch: 6| Step: 5
Training loss: 2.8152523040771484
Validation loss: 2.0525602884190057

Epoch: 6| Step: 6
Training loss: 2.3385074138641357
Validation loss: 2.050240224407565

Epoch: 6| Step: 7
Training loss: 2.2154042720794678
Validation loss: 2.0548935538978985

Epoch: 6| Step: 8
Training loss: 1.6110036373138428
Validation loss: 2.0556146021812194

Epoch: 6| Step: 9
Training loss: 2.7650275230407715
Validation loss: 2.104066123244583

Epoch: 6| Step: 10
Training loss: 1.85236656665802
Validation loss: 2.1657830233215005

Epoch: 6| Step: 11
Training loss: 2.439694881439209
Validation loss: 2.220453800693635

Epoch: 6| Step: 12
Training loss: 2.7724366188049316
Validation loss: 2.2631436624834613

Epoch: 6| Step: 13
Training loss: 2.288966655731201
Validation loss: 2.198475201924642

Epoch: 95| Step: 0
Training loss: 1.7510600090026855
Validation loss: 2.1448165575663247

Epoch: 6| Step: 1
Training loss: 2.184295892715454
Validation loss: 2.07109506412219

Epoch: 6| Step: 2
Training loss: 2.40183162689209
Validation loss: 2.0591382224072694

Epoch: 6| Step: 3
Training loss: 2.886500835418701
Validation loss: 2.04982223562015

Epoch: 6| Step: 4
Training loss: 2.956911563873291
Validation loss: 2.0496398902708486

Epoch: 6| Step: 5
Training loss: 2.7107365131378174
Validation loss: 2.0567277349451536

Epoch: 6| Step: 6
Training loss: 2.953629970550537
Validation loss: 2.065232846044725

Epoch: 6| Step: 7
Training loss: 2.4334142208099365
Validation loss: 2.080620317048924

Epoch: 6| Step: 8
Training loss: 1.7632901668548584
Validation loss: 2.081930391250118

Epoch: 6| Step: 9
Training loss: 2.8184590339660645
Validation loss: 2.0797634675938594

Epoch: 6| Step: 10
Training loss: 2.499368906021118
Validation loss: 2.0751364500291887

Epoch: 6| Step: 11
Training loss: 2.042496919631958
Validation loss: 2.073658699630409

Epoch: 6| Step: 12
Training loss: 2.137864589691162
Validation loss: 2.0778946261252127

Epoch: 6| Step: 13
Training loss: 2.0574898719787598
Validation loss: 2.085041064088063

Epoch: 96| Step: 0
Training loss: 2.014951229095459
Validation loss: 2.086314647428451

Epoch: 6| Step: 1
Training loss: 1.9905657768249512
Validation loss: 2.101902351584486

Epoch: 6| Step: 2
Training loss: 2.378714084625244
Validation loss: 2.129305681874675

Epoch: 6| Step: 3
Training loss: 3.2779479026794434
Validation loss: 2.130746405611756

Epoch: 6| Step: 4
Training loss: 2.4686341285705566
Validation loss: 2.145274341747325

Epoch: 6| Step: 5
Training loss: 2.124208450317383
Validation loss: 2.1183042436517696

Epoch: 6| Step: 6
Training loss: 2.1108603477478027
Validation loss: 2.1240795786662767

Epoch: 6| Step: 7
Training loss: 2.1167404651641846
Validation loss: 2.1236525658638246

Epoch: 6| Step: 8
Training loss: 2.7210941314697266
Validation loss: 2.083777602000903

Epoch: 6| Step: 9
Training loss: 2.917501926422119
Validation loss: 2.0780072109673613

Epoch: 6| Step: 10
Training loss: 1.9795511960983276
Validation loss: 2.0632065534591675

Epoch: 6| Step: 11
Training loss: 1.9925570487976074
Validation loss: 2.0536194719294065

Epoch: 6| Step: 12
Training loss: 2.414936065673828
Validation loss: 2.0567187058028353

Epoch: 6| Step: 13
Training loss: 3.141939401626587
Validation loss: 2.054943133425969

Epoch: 97| Step: 0
Training loss: 1.8509777784347534
Validation loss: 2.062517903184378

Epoch: 6| Step: 1
Training loss: 1.973496675491333
Validation loss: 2.059485455994965

Epoch: 6| Step: 2
Training loss: 2.4232826232910156
Validation loss: 2.0651369069212224

Epoch: 6| Step: 3
Training loss: 2.909487724304199
Validation loss: 2.0551175071347143

Epoch: 6| Step: 4
Training loss: 2.3610713481903076
Validation loss: 2.0614371120288806

Epoch: 6| Step: 5
Training loss: 1.933820128440857
Validation loss: 2.0684385735501527

Epoch: 6| Step: 6
Training loss: 2.392296314239502
Validation loss: 2.0876663090080343

Epoch: 6| Step: 7
Training loss: 2.092717409133911
Validation loss: 2.1060928683127127

Epoch: 6| Step: 8
Training loss: 2.8360650539398193
Validation loss: 2.130038317813668

Epoch: 6| Step: 9
Training loss: 2.455242395401001
Validation loss: 2.1362329157449866

Epoch: 6| Step: 10
Training loss: 2.678356647491455
Validation loss: 2.126595994477631

Epoch: 6| Step: 11
Training loss: 2.537497043609619
Validation loss: 2.114115834236145

Epoch: 6| Step: 12
Training loss: 2.2015867233276367
Validation loss: 2.1158842168828493

Epoch: 6| Step: 13
Training loss: 2.6971559524536133
Validation loss: 2.114406898457517

Epoch: 98| Step: 0
Training loss: 2.0406012535095215
Validation loss: 2.0834585261601273

Epoch: 6| Step: 1
Training loss: 2.8986597061157227
Validation loss: 2.0704469039875972

Epoch: 6| Step: 2
Training loss: 2.847337245941162
Validation loss: 2.054149172639334

Epoch: 6| Step: 3
Training loss: 2.005483627319336
Validation loss: 2.0350132885799614

Epoch: 6| Step: 4
Training loss: 2.298771381378174
Validation loss: 2.0405775500882055

Epoch: 6| Step: 5
Training loss: 2.0742950439453125
Validation loss: 2.0483262103091002

Epoch: 6| Step: 6
Training loss: 2.2399044036865234
Validation loss: 2.0495002500472532

Epoch: 6| Step: 7
Training loss: 2.92621111869812
Validation loss: 2.052370386738931

Epoch: 6| Step: 8
Training loss: 2.5102643966674805
Validation loss: 2.05795520095415

Epoch: 6| Step: 9
Training loss: 2.050718307495117
Validation loss: 2.0547879254946144

Epoch: 6| Step: 10
Training loss: 2.899376630783081
Validation loss: 2.0472346210992463

Epoch: 6| Step: 11
Training loss: 2.51737117767334
Validation loss: 2.0454056570606847

Epoch: 6| Step: 12
Training loss: 2.001495599746704
Validation loss: 2.056065341477753

Epoch: 6| Step: 13
Training loss: 1.8826050758361816
Validation loss: 2.1056311822706655

Epoch: 99| Step: 0
Training loss: 2.584196090698242
Validation loss: 2.1682627021625476

Epoch: 6| Step: 1
Training loss: 2.5583808422088623
Validation loss: 2.1540835390808764

Epoch: 6| Step: 2
Training loss: 2.6486148834228516
Validation loss: 2.1319339582996983

Epoch: 6| Step: 3
Training loss: 2.5389485359191895
Validation loss: 2.1059626725412186

Epoch: 6| Step: 4
Training loss: 2.246535301208496
Validation loss: 2.1110429238247614

Epoch: 6| Step: 5
Training loss: 2.645462989807129
Validation loss: 2.0959717586476314

Epoch: 6| Step: 6
Training loss: 2.806088447570801
Validation loss: 2.1161693526852514

Epoch: 6| Step: 7
Training loss: 2.748279571533203
Validation loss: 2.127360536206153

Epoch: 6| Step: 8
Training loss: 1.9034857749938965
Validation loss: 2.121451968787819

Epoch: 6| Step: 9
Training loss: 2.0496981143951416
Validation loss: 2.1144304275512695

Epoch: 6| Step: 10
Training loss: 2.1592211723327637
Validation loss: 2.091037622062109

Epoch: 6| Step: 11
Training loss: 1.6428269147872925
Validation loss: 2.08058431840712

Epoch: 6| Step: 12
Training loss: 2.0302488803863525
Validation loss: 2.0705434148029616

Epoch: 6| Step: 13
Training loss: 3.205596923828125
Validation loss: 2.0655799168412403

Epoch: 100| Step: 0
Training loss: 2.4840588569641113
Validation loss: 2.0714896289251183

Epoch: 6| Step: 1
Training loss: 2.405890464782715
Validation loss: 2.0802787760252595

Epoch: 6| Step: 2
Training loss: 1.7120912075042725
Validation loss: 2.0886284664113033

Epoch: 6| Step: 3
Training loss: 2.3146448135375977
Validation loss: 2.090968393510388

Epoch: 6| Step: 4
Training loss: 2.738645315170288
Validation loss: 2.074117910477423

Epoch: 6| Step: 5
Training loss: 2.880598306655884
Validation loss: 2.0711362349089755

Epoch: 6| Step: 6
Training loss: 2.5373263359069824
Validation loss: 2.066254431201566

Epoch: 6| Step: 7
Training loss: 1.9793164730072021
Validation loss: 2.0621397008178053

Epoch: 6| Step: 8
Training loss: 2.163121223449707
Validation loss: 2.038731566039465

Epoch: 6| Step: 9
Training loss: 2.315247058868408
Validation loss: 2.0334455608039774

Epoch: 6| Step: 10
Training loss: 2.3136677742004395
Validation loss: 2.029696956757576

Epoch: 6| Step: 11
Training loss: 3.1418190002441406
Validation loss: 2.0553522404804023

Epoch: 6| Step: 12
Training loss: 2.4361939430236816
Validation loss: 2.072392461120441

Epoch: 6| Step: 13
Training loss: 2.2380452156066895
Validation loss: 2.0995370264976256

Epoch: 101| Step: 0
Training loss: 2.001739740371704
Validation loss: 2.136608455770759

Epoch: 6| Step: 1
Training loss: 1.9385706186294556
Validation loss: 2.1912420347172725

Epoch: 6| Step: 2
Training loss: 2.3213820457458496
Validation loss: 2.2401044368743896

Epoch: 6| Step: 3
Training loss: 2.803744316101074
Validation loss: 2.346614924810266

Epoch: 6| Step: 4
Training loss: 2.710944175720215
Validation loss: 2.328001988831387

Epoch: 6| Step: 5
Training loss: 2.6900601387023926
Validation loss: 2.2694509029388428

Epoch: 6| Step: 6
Training loss: 2.769747734069824
Validation loss: 2.1595045520413305

Epoch: 6| Step: 7
Training loss: 2.45963978767395
Validation loss: 2.096618716434766

Epoch: 6| Step: 8
Training loss: 3.0121448040008545
Validation loss: 2.061278725183138

Epoch: 6| Step: 9
Training loss: 2.407863140106201
Validation loss: 2.05758422933599

Epoch: 6| Step: 10
Training loss: 1.7807402610778809
Validation loss: 2.0483132895602973

Epoch: 6| Step: 11
Training loss: 2.438997745513916
Validation loss: 2.077887886313982

Epoch: 6| Step: 12
Training loss: 2.4254236221313477
Validation loss: 2.08556947400493

Epoch: 6| Step: 13
Training loss: 2.292954444885254
Validation loss: 2.133407267191077

Epoch: 102| Step: 0
Training loss: 2.564751148223877
Validation loss: 2.1223381591099564

Epoch: 6| Step: 1
Training loss: 2.084376335144043
Validation loss: 2.0850526504619147

Epoch: 6| Step: 2
Training loss: 3.210738182067871
Validation loss: 2.0526220619037585

Epoch: 6| Step: 3
Training loss: 1.9953858852386475
Validation loss: 2.0386926486927974

Epoch: 6| Step: 4
Training loss: 2.7815797328948975
Validation loss: 2.0266148813309206

Epoch: 6| Step: 5
Training loss: 2.2996883392333984
Validation loss: 2.022663134400563

Epoch: 6| Step: 6
Training loss: 2.5792410373687744
Validation loss: 2.0145738881121398

Epoch: 6| Step: 7
Training loss: 1.9552934169769287
Validation loss: 2.0282450183745353

Epoch: 6| Step: 8
Training loss: 1.9471871852874756
Validation loss: 2.0502989574145247

Epoch: 6| Step: 9
Training loss: 2.3789520263671875
Validation loss: 2.063411294773061

Epoch: 6| Step: 10
Training loss: 1.9016999006271362
Validation loss: 2.0913452820111345

Epoch: 6| Step: 11
Training loss: 3.2661430835723877
Validation loss: 2.1164536591499084

Epoch: 6| Step: 12
Training loss: 1.9814281463623047
Validation loss: 2.10693016359883

Epoch: 6| Step: 13
Training loss: 2.0798838138580322
Validation loss: 2.067730998480192

Epoch: 103| Step: 0
Training loss: 2.239976167678833
Validation loss: 2.024471946941909

Epoch: 6| Step: 1
Training loss: 2.620788097381592
Validation loss: 2.0080389361227713

Epoch: 6| Step: 2
Training loss: 2.133323907852173
Validation loss: 2.0005317554678967

Epoch: 6| Step: 3
Training loss: 1.6014683246612549
Validation loss: 2.002936811857326

Epoch: 6| Step: 4
Training loss: 2.148336172103882
Validation loss: 2.0101789351432555

Epoch: 6| Step: 5
Training loss: 2.9900474548339844
Validation loss: 2.0095970092281217

Epoch: 6| Step: 6
Training loss: 2.687767505645752
Validation loss: 2.0268089527724893

Epoch: 6| Step: 7
Training loss: 2.5631484985351562
Validation loss: 2.0167328491005847

Epoch: 6| Step: 8
Training loss: 2.7000935077667236
Validation loss: 2.0015939179287163

Epoch: 6| Step: 9
Training loss: 2.6444830894470215
Validation loss: 2.0044892077804892

Epoch: 6| Step: 10
Training loss: 2.3216500282287598
Validation loss: 1.9962819930045836

Epoch: 6| Step: 11
Training loss: 2.6584653854370117
Validation loss: 2.004266576100421

Epoch: 6| Step: 12
Training loss: 1.8464404344558716
Validation loss: 2.0074063065231487

Epoch: 6| Step: 13
Training loss: 2.127992868423462
Validation loss: 2.0130149702872

Epoch: 104| Step: 0
Training loss: 3.0352606773376465
Validation loss: 2.012972459998182

Epoch: 6| Step: 1
Training loss: 2.405579090118408
Validation loss: 2.0136403922111756

Epoch: 6| Step: 2
Training loss: 2.458524703979492
Validation loss: 2.018159612532585

Epoch: 6| Step: 3
Training loss: 1.6260135173797607
Validation loss: 2.0216572259062078

Epoch: 6| Step: 4
Training loss: 2.1159963607788086
Validation loss: 2.0178117752075195

Epoch: 6| Step: 5
Training loss: 2.518733501434326
Validation loss: 2.021985325762021

Epoch: 6| Step: 6
Training loss: 2.4666972160339355
Validation loss: 2.024944393865524

Epoch: 6| Step: 7
Training loss: 1.4942123889923096
Validation loss: 2.036596013653663

Epoch: 6| Step: 8
Training loss: 2.5990285873413086
Validation loss: 2.041162790790681

Epoch: 6| Step: 9
Training loss: 2.9541234970092773
Validation loss: 2.0472352068911315

Epoch: 6| Step: 10
Training loss: 2.518795967102051
Validation loss: 2.082387360193396

Epoch: 6| Step: 11
Training loss: 2.6556308269500732
Validation loss: 2.0952828468814975

Epoch: 6| Step: 12
Training loss: 2.3922977447509766
Validation loss: 2.1009971262306295

Epoch: 6| Step: 13
Training loss: 1.6182247400283813
Validation loss: 2.089266384801557

Epoch: 105| Step: 0
Training loss: 2.828758955001831
Validation loss: 2.031703625955889

Epoch: 6| Step: 1
Training loss: 2.348161220550537
Validation loss: 2.0227620370926394

Epoch: 6| Step: 2
Training loss: 1.6785938739776611
Validation loss: 2.0184592893046718

Epoch: 6| Step: 3
Training loss: 2.0607495307922363
Validation loss: 2.006809107718929

Epoch: 6| Step: 4
Training loss: 2.344409942626953
Validation loss: 2.0075253658397223

Epoch: 6| Step: 5
Training loss: 1.5269805192947388
Validation loss: 2.00423615465882

Epoch: 6| Step: 6
Training loss: 3.021091938018799
Validation loss: 2.0019577010985343

Epoch: 6| Step: 7
Training loss: 2.9995083808898926
Validation loss: 2.0018394788106284

Epoch: 6| Step: 8
Training loss: 1.8080356121063232
Validation loss: 2.0103342353656726

Epoch: 6| Step: 9
Training loss: 2.5582613945007324
Validation loss: 2.005131088277345

Epoch: 6| Step: 10
Training loss: 2.0203304290771484
Validation loss: 2.000698043454078

Epoch: 6| Step: 11
Training loss: 3.1502819061279297
Validation loss: 1.9920679728190105

Epoch: 6| Step: 12
Training loss: 2.3928632736206055
Validation loss: 1.9939754880884641

Epoch: 6| Step: 13
Training loss: 1.876157283782959
Validation loss: 1.9947279319968274

Epoch: 106| Step: 0
Training loss: 2.689159393310547
Validation loss: 1.9938911417479157

Epoch: 6| Step: 1
Training loss: 2.067664861679077
Validation loss: 1.9963416079039216

Epoch: 6| Step: 2
Training loss: 2.2971887588500977
Validation loss: 1.9891671813944334

Epoch: 6| Step: 3
Training loss: 2.0028653144836426
Validation loss: 1.9909976823355562

Epoch: 6| Step: 4
Training loss: 2.544066905975342
Validation loss: 1.986177041966428

Epoch: 6| Step: 5
Training loss: 2.37148380279541
Validation loss: 1.9854734661758586

Epoch: 6| Step: 6
Training loss: 1.9203672409057617
Validation loss: 1.9934376209012923

Epoch: 6| Step: 7
Training loss: 1.9532692432403564
Validation loss: 1.9895950260982718

Epoch: 6| Step: 8
Training loss: 2.1145968437194824
Validation loss: 1.987190350409477

Epoch: 6| Step: 9
Training loss: 2.2382187843322754
Validation loss: 1.9887262877597605

Epoch: 6| Step: 10
Training loss: 2.522496461868286
Validation loss: 2.004478948090666

Epoch: 6| Step: 11
Training loss: 2.448410987854004
Validation loss: 2.024040614404986

Epoch: 6| Step: 12
Training loss: 3.2605435848236084
Validation loss: 2.0382685840770765

Epoch: 6| Step: 13
Training loss: 2.3155977725982666
Validation loss: 2.0081531898949736

Epoch: 107| Step: 0
Training loss: 2.8661460876464844
Validation loss: 1.9900780377849456

Epoch: 6| Step: 1
Training loss: 2.647343158721924
Validation loss: 1.9858369032541912

Epoch: 6| Step: 2
Training loss: 2.8684921264648438
Validation loss: 1.9920187368187854

Epoch: 6| Step: 3
Training loss: 1.8154120445251465
Validation loss: 1.987802069674256

Epoch: 6| Step: 4
Training loss: 1.9517265558242798
Validation loss: 1.992698851452079

Epoch: 6| Step: 5
Training loss: 1.7885243892669678
Validation loss: 1.9903977968359505

Epoch: 6| Step: 6
Training loss: 2.267083168029785
Validation loss: 1.9892233597334994

Epoch: 6| Step: 7
Training loss: 1.9954614639282227
Validation loss: 1.9872471683768815

Epoch: 6| Step: 8
Training loss: 2.7056474685668945
Validation loss: 1.9963513574292582

Epoch: 6| Step: 9
Training loss: 2.765603542327881
Validation loss: 2.0100788147218767

Epoch: 6| Step: 10
Training loss: 2.3155765533447266
Validation loss: 2.0126640950479815

Epoch: 6| Step: 11
Training loss: 2.356226921081543
Validation loss: 2.007174539309676

Epoch: 6| Step: 12
Training loss: 1.9253748655319214
Validation loss: 2.0020316082944154

Epoch: 6| Step: 13
Training loss: 2.383650541305542
Validation loss: 2.0031201916356243

Epoch: 108| Step: 0
Training loss: 1.3080494403839111
Validation loss: 1.9969770728900869

Epoch: 6| Step: 1
Training loss: 2.7040319442749023
Validation loss: 2.011725212938042

Epoch: 6| Step: 2
Training loss: 1.3445160388946533
Validation loss: 2.012998811660274

Epoch: 6| Step: 3
Training loss: 2.536489725112915
Validation loss: 1.9990796530118553

Epoch: 6| Step: 4
Training loss: 3.0860886573791504
Validation loss: 2.0095281729134182

Epoch: 6| Step: 5
Training loss: 2.6785340309143066
Validation loss: 2.0009097258249917

Epoch: 6| Step: 6
Training loss: 2.479600429534912
Validation loss: 1.9932053935143255

Epoch: 6| Step: 7
Training loss: 2.9059958457946777
Validation loss: 1.9885840082681308

Epoch: 6| Step: 8
Training loss: 1.3119676113128662
Validation loss: 2.0040903347794727

Epoch: 6| Step: 9
Training loss: 2.328685760498047
Validation loss: 2.000514846976085

Epoch: 6| Step: 10
Training loss: 2.7374792098999023
Validation loss: 2.0005411614653883

Epoch: 6| Step: 11
Training loss: 2.689948797225952
Validation loss: 1.9972372029417305

Epoch: 6| Step: 12
Training loss: 1.7225499153137207
Validation loss: 2.004289633484297

Epoch: 6| Step: 13
Training loss: 2.7355268001556396
Validation loss: 2.0098290456238614

Epoch: 109| Step: 0
Training loss: 2.1271297931671143
Validation loss: 2.0116015736774733

Epoch: 6| Step: 1
Training loss: 2.5092811584472656
Validation loss: 2.009063697630359

Epoch: 6| Step: 2
Training loss: 2.040698528289795
Validation loss: 2.009530985227195

Epoch: 6| Step: 3
Training loss: 2.156729221343994
Validation loss: 2.0040580585438716

Epoch: 6| Step: 4
Training loss: 1.9112298488616943
Validation loss: 2.0119560918500348

Epoch: 6| Step: 5
Training loss: 1.7303612232208252
Validation loss: 2.0204558641679826

Epoch: 6| Step: 6
Training loss: 2.5101490020751953
Validation loss: 2.013984498157296

Epoch: 6| Step: 7
Training loss: 2.4332215785980225
Validation loss: 2.013665759435264

Epoch: 6| Step: 8
Training loss: 2.470759630203247
Validation loss: 2.0236216975796606

Epoch: 6| Step: 9
Training loss: 2.501214027404785
Validation loss: 2.0252949422405613

Epoch: 6| Step: 10
Training loss: 1.6794055700302124
Validation loss: 2.034967299430601

Epoch: 6| Step: 11
Training loss: 2.813086986541748
Validation loss: 2.0620781196061

Epoch: 6| Step: 12
Training loss: 2.706202268600464
Validation loss: 2.1023172127303256

Epoch: 6| Step: 13
Training loss: 3.0271360874176025
Validation loss: 2.1337173395259406

Epoch: 110| Step: 0
Training loss: 2.42596173286438
Validation loss: 2.219393922436622

Epoch: 6| Step: 1
Training loss: 2.2090868949890137
Validation loss: 2.274952273215017

Epoch: 6| Step: 2
Training loss: 2.0426993370056152
Validation loss: 2.268120768249676

Epoch: 6| Step: 3
Training loss: 2.713137149810791
Validation loss: 2.195400543110345

Epoch: 6| Step: 4
Training loss: 2.644491195678711
Validation loss: 2.1130019874982935

Epoch: 6| Step: 5
Training loss: 1.7739737033843994
Validation loss: 2.0718139345927904

Epoch: 6| Step: 6
Training loss: 2.634564161300659
Validation loss: 2.0267391256106797

Epoch: 6| Step: 7
Training loss: 2.95839786529541
Validation loss: 2.0126325366317586

Epoch: 6| Step: 8
Training loss: 1.9028706550598145
Validation loss: 2.0183470774722356

Epoch: 6| Step: 9
Training loss: 2.398287296295166
Validation loss: 2.0311795473098755

Epoch: 6| Step: 10
Training loss: 3.0174853801727295
Validation loss: 2.032626723730436

Epoch: 6| Step: 11
Training loss: 1.958655834197998
Validation loss: 2.0381266506769324

Epoch: 6| Step: 12
Training loss: 2.255305290222168
Validation loss: 2.0727364401663504

Epoch: 6| Step: 13
Training loss: 2.3008170127868652
Validation loss: 2.054713511979708

Epoch: 111| Step: 0
Training loss: 1.6413705348968506
Validation loss: 2.0754869035495225

Epoch: 6| Step: 1
Training loss: 2.2593445777893066
Validation loss: 2.1052677426286923

Epoch: 6| Step: 2
Training loss: 1.923309326171875
Validation loss: 2.0828370573700115

Epoch: 6| Step: 3
Training loss: 2.340456962585449
Validation loss: 2.0272680482556744

Epoch: 6| Step: 4
Training loss: 2.53772234916687
Validation loss: 2.0223217036134455

Epoch: 6| Step: 5
Training loss: 2.169621467590332
Validation loss: 2.0343944385487545

Epoch: 6| Step: 6
Training loss: 2.60349178314209
Validation loss: 2.0345523152300107

Epoch: 6| Step: 7
Training loss: 2.1915531158447266
Validation loss: 2.032586436117849

Epoch: 6| Step: 8
Training loss: 2.7921817302703857
Validation loss: 2.03789020610112

Epoch: 6| Step: 9
Training loss: 2.2789950370788574
Validation loss: 2.0593794199728195

Epoch: 6| Step: 10
Training loss: 2.4370760917663574
Validation loss: 2.0587604673959876

Epoch: 6| Step: 11
Training loss: 2.3085718154907227
Validation loss: 2.070051429092243

Epoch: 6| Step: 12
Training loss: 2.9605765342712402
Validation loss: 2.0548137541740172

Epoch: 6| Step: 13
Training loss: 2.4434261322021484
Validation loss: 2.045787739497359

Epoch: 112| Step: 0
Training loss: 2.798513412475586
Validation loss: 2.0509309691767537

Epoch: 6| Step: 1
Training loss: 1.8969659805297852
Validation loss: 2.0343008400291525

Epoch: 6| Step: 2
Training loss: 2.3953123092651367
Validation loss: 2.0349519150231474

Epoch: 6| Step: 3
Training loss: 2.008359432220459
Validation loss: 2.0372817157417216

Epoch: 6| Step: 4
Training loss: 2.053581714630127
Validation loss: 2.034489159942955

Epoch: 6| Step: 5
Training loss: 2.357455253601074
Validation loss: 2.0446204652068434

Epoch: 6| Step: 6
Training loss: 2.5955214500427246
Validation loss: 2.0576163748259186

Epoch: 6| Step: 7
Training loss: 2.5063886642456055
Validation loss: 2.0576354560031684

Epoch: 6| Step: 8
Training loss: 2.340064525604248
Validation loss: 2.0483443634484404

Epoch: 6| Step: 9
Training loss: 1.9433658123016357
Validation loss: 2.038612454168258

Epoch: 6| Step: 10
Training loss: 2.2497267723083496
Validation loss: 2.0494803485049995

Epoch: 6| Step: 11
Training loss: 2.607571840286255
Validation loss: 2.04991848750781

Epoch: 6| Step: 12
Training loss: 1.9516584873199463
Validation loss: 2.052346060352941

Epoch: 6| Step: 13
Training loss: 2.4620561599731445
Validation loss: 2.051982516883522

Epoch: 113| Step: 0
Training loss: 2.566787004470825
Validation loss: 2.0423984373769453

Epoch: 6| Step: 1
Training loss: 2.457493305206299
Validation loss: 2.031857159829909

Epoch: 6| Step: 2
Training loss: 1.83780038356781
Validation loss: 2.0350122246690976

Epoch: 6| Step: 3
Training loss: 2.520329236984253
Validation loss: 2.0285393217558503

Epoch: 6| Step: 4
Training loss: 2.311530828475952
Validation loss: 2.0136194741854103

Epoch: 6| Step: 5
Training loss: 2.002628803253174
Validation loss: 2.0120537281036377

Epoch: 6| Step: 6
Training loss: 2.339590072631836
Validation loss: 2.017980670416227

Epoch: 6| Step: 7
Training loss: 1.8506842851638794
Validation loss: 2.012590362179664

Epoch: 6| Step: 8
Training loss: 2.352684497833252
Validation loss: 2.019481062889099

Epoch: 6| Step: 9
Training loss: 2.4212229251861572
Validation loss: 2.0397008131909113

Epoch: 6| Step: 10
Training loss: 2.4735264778137207
Validation loss: 2.0697127029459965

Epoch: 6| Step: 11
Training loss: 2.607077121734619
Validation loss: 2.0881396711513562

Epoch: 6| Step: 12
Training loss: 1.6124614477157593
Validation loss: 2.0875461883442377

Epoch: 6| Step: 13
Training loss: 2.7091150283813477
Validation loss: 2.060414950052897

Epoch: 114| Step: 0
Training loss: 1.5288316011428833
Validation loss: 2.126731644394577

Epoch: 6| Step: 1
Training loss: 1.983086347579956
Validation loss: 2.19743198861358

Epoch: 6| Step: 2
Training loss: 2.4801454544067383
Validation loss: 2.225180701542926

Epoch: 6| Step: 3
Training loss: 2.1261143684387207
Validation loss: 2.245589769014748

Epoch: 6| Step: 4
Training loss: 3.5398476123809814
Validation loss: 2.1676988909321446

Epoch: 6| Step: 5
Training loss: 2.1769280433654785
Validation loss: 2.1447131582485732

Epoch: 6| Step: 6
Training loss: 2.5459706783294678
Validation loss: 2.135624897095465

Epoch: 6| Step: 7
Training loss: 2.267712354660034
Validation loss: 2.10302076801177

Epoch: 6| Step: 8
Training loss: 2.8889822959899902
Validation loss: 2.0917856257448912

Epoch: 6| Step: 9
Training loss: 2.8952584266662598
Validation loss: 2.0461788459490706

Epoch: 6| Step: 10
Training loss: 2.288219928741455
Validation loss: 2.021499794016602

Epoch: 6| Step: 11
Training loss: 1.5039663314819336
Validation loss: 1.9957521974399526

Epoch: 6| Step: 12
Training loss: 1.986552357673645
Validation loss: 1.990483037887081

Epoch: 6| Step: 13
Training loss: 2.288367748260498
Validation loss: 1.978752798931573

Epoch: 115| Step: 0
Training loss: 2.017969846725464
Validation loss: 1.9762139448555567

Epoch: 6| Step: 1
Training loss: 2.082996368408203
Validation loss: 1.9903430913084297

Epoch: 6| Step: 2
Training loss: 2.6674747467041016
Validation loss: 1.9992193380991619

Epoch: 6| Step: 3
Training loss: 2.687595844268799
Validation loss: 1.9859931853509718

Epoch: 6| Step: 4
Training loss: 2.4875640869140625
Validation loss: 1.9796406325473581

Epoch: 6| Step: 5
Training loss: 2.1540770530700684
Validation loss: 1.968707779402374

Epoch: 6| Step: 6
Training loss: 2.5273213386535645
Validation loss: 1.969030411012711

Epoch: 6| Step: 7
Training loss: 2.1250123977661133
Validation loss: 1.9728953210256432

Epoch: 6| Step: 8
Training loss: 2.792032241821289
Validation loss: 1.979571319395496

Epoch: 6| Step: 9
Training loss: 1.8982537984848022
Validation loss: 1.9862225491513488

Epoch: 6| Step: 10
Training loss: 1.432389736175537
Validation loss: 1.999888518805145

Epoch: 6| Step: 11
Training loss: 2.5869193077087402
Validation loss: 2.0106583308148127

Epoch: 6| Step: 12
Training loss: 2.754157781600952
Validation loss: 2.009410253135107

Epoch: 6| Step: 13
Training loss: 1.5943222045898438
Validation loss: 2.006552711609871

Epoch: 116| Step: 0
Training loss: 1.927738070487976
Validation loss: 2.011124146881924

Epoch: 6| Step: 1
Training loss: 2.4736571311950684
Validation loss: 1.9953069404889179

Epoch: 6| Step: 2
Training loss: 2.511806011199951
Validation loss: 2.00283416240446

Epoch: 6| Step: 3
Training loss: 1.8482081890106201
Validation loss: 1.9938701237401655

Epoch: 6| Step: 4
Training loss: 2.687717914581299
Validation loss: 2.001478433609009

Epoch: 6| Step: 5
Training loss: 2.017698287963867
Validation loss: 1.9945616209378807

Epoch: 6| Step: 6
Training loss: 2.243821382522583
Validation loss: 1.9872560193461757

Epoch: 6| Step: 7
Training loss: 2.4912943840026855
Validation loss: 1.9779744340527443

Epoch: 6| Step: 8
Training loss: 2.144351005554199
Validation loss: 1.9716659104952248

Epoch: 6| Step: 9
Training loss: 2.4120888710021973
Validation loss: 1.9811441052344538

Epoch: 6| Step: 10
Training loss: 2.0966734886169434
Validation loss: 1.9834853167174964

Epoch: 6| Step: 11
Training loss: 2.8031058311462402
Validation loss: 1.9746346755694317

Epoch: 6| Step: 12
Training loss: 2.014834403991699
Validation loss: 1.9829554121981385

Epoch: 6| Step: 13
Training loss: 1.7792248725891113
Validation loss: 1.9911714112886818

Epoch: 117| Step: 0
Training loss: 1.9090697765350342
Validation loss: 1.9814919733232068

Epoch: 6| Step: 1
Training loss: 2.5861716270446777
Validation loss: 1.9823635714028471

Epoch: 6| Step: 2
Training loss: 2.3961238861083984
Validation loss: 1.9762015342712402

Epoch: 6| Step: 3
Training loss: 2.3839449882507324
Validation loss: 1.9744639242849042

Epoch: 6| Step: 4
Training loss: 1.9617505073547363
Validation loss: 1.9702757071423274

Epoch: 6| Step: 5
Training loss: 2.2413387298583984
Validation loss: 1.9802539835694015

Epoch: 6| Step: 6
Training loss: 2.2746081352233887
Validation loss: 1.9775680675301501

Epoch: 6| Step: 7
Training loss: 2.3480567932128906
Validation loss: 1.9776098830725557

Epoch: 6| Step: 8
Training loss: 1.672957181930542
Validation loss: 1.9805130625283847

Epoch: 6| Step: 9
Training loss: 2.1278016567230225
Validation loss: 1.988126257414459

Epoch: 6| Step: 10
Training loss: 2.5222816467285156
Validation loss: 1.9786939441516835

Epoch: 6| Step: 11
Training loss: 2.746298313140869
Validation loss: 1.985057496255444

Epoch: 6| Step: 12
Training loss: 1.309682846069336
Validation loss: 1.999076215169763

Epoch: 6| Step: 13
Training loss: 3.237009286880493
Validation loss: 1.9972127560646302

Epoch: 118| Step: 0
Training loss: 1.8278841972351074
Validation loss: 2.0146895377866683

Epoch: 6| Step: 1
Training loss: 2.637874126434326
Validation loss: 2.023075992061246

Epoch: 6| Step: 2
Training loss: 1.9452154636383057
Validation loss: 2.018705106550647

Epoch: 6| Step: 3
Training loss: 2.6884357929229736
Validation loss: 2.02436666334829

Epoch: 6| Step: 4
Training loss: 2.48995304107666
Validation loss: 2.024688870676102

Epoch: 6| Step: 5
Training loss: 2.6266956329345703
Validation loss: 2.008130513211732

Epoch: 6| Step: 6
Training loss: 2.3385303020477295
Validation loss: 2.013712957341184

Epoch: 6| Step: 7
Training loss: 2.7340893745422363
Validation loss: 2.021741444064725

Epoch: 6| Step: 8
Training loss: 1.9341524839401245
Validation loss: 2.017302364431402

Epoch: 6| Step: 9
Training loss: 1.3966820240020752
Validation loss: 2.013695106711439

Epoch: 6| Step: 10
Training loss: 2.31076979637146
Validation loss: 2.012010246194819

Epoch: 6| Step: 11
Training loss: 1.7987427711486816
Validation loss: 1.9939121584738455

Epoch: 6| Step: 12
Training loss: 2.5293123722076416
Validation loss: 1.992671525606545

Epoch: 6| Step: 13
Training loss: 2.0415894985198975
Validation loss: 1.977194207970814

Epoch: 119| Step: 0
Training loss: 2.6093640327453613
Validation loss: 1.977904365908715

Epoch: 6| Step: 1
Training loss: 1.1683188676834106
Validation loss: 1.9685452061314737

Epoch: 6| Step: 2
Training loss: 2.354877471923828
Validation loss: 1.9629190839746946

Epoch: 6| Step: 3
Training loss: 2.7035017013549805
Validation loss: 1.967309990236836

Epoch: 6| Step: 4
Training loss: 2.1149420738220215
Validation loss: 1.9744697475946078

Epoch: 6| Step: 5
Training loss: 2.1719932556152344
Validation loss: 1.9772179870195286

Epoch: 6| Step: 6
Training loss: 1.9309580326080322
Validation loss: 1.9686222550689534

Epoch: 6| Step: 7
Training loss: 2.0092339515686035
Validation loss: 1.9728137395715202

Epoch: 6| Step: 8
Training loss: 1.991660475730896
Validation loss: 1.9679830856220697

Epoch: 6| Step: 9
Training loss: 2.552216053009033
Validation loss: 1.9797557092482043

Epoch: 6| Step: 10
Training loss: 2.4389688968658447
Validation loss: 1.995663571101363

Epoch: 6| Step: 11
Training loss: 1.920480489730835
Validation loss: 2.0225720379942205

Epoch: 6| Step: 12
Training loss: 2.2889299392700195
Validation loss: 2.003450421876805

Epoch: 6| Step: 13
Training loss: 3.3661866188049316
Validation loss: 2.0082395333115772

Epoch: 120| Step: 0
Training loss: 1.9615628719329834
Validation loss: 1.9776896827964372

Epoch: 6| Step: 1
Training loss: 2.6321380138397217
Validation loss: 1.9996913812493766

Epoch: 6| Step: 2
Training loss: 2.2490434646606445
Validation loss: 1.99269901808872

Epoch: 6| Step: 3
Training loss: 1.867620587348938
Validation loss: 1.9899739347478396

Epoch: 6| Step: 4
Training loss: 2.4121274948120117
Validation loss: 1.9772972804243847

Epoch: 6| Step: 5
Training loss: 1.7289303541183472
Validation loss: 1.979646428938835

Epoch: 6| Step: 6
Training loss: 1.7849793434143066
Validation loss: 1.978170899934666

Epoch: 6| Step: 7
Training loss: 2.4374213218688965
Validation loss: 1.9897023093315862

Epoch: 6| Step: 8
Training loss: 3.0972349643707275
Validation loss: 1.9948799302501063

Epoch: 6| Step: 9
Training loss: 2.007091522216797
Validation loss: 1.9893010149719894

Epoch: 6| Step: 10
Training loss: 2.242770195007324
Validation loss: 1.9943324340287076

Epoch: 6| Step: 11
Training loss: 2.6409456729888916
Validation loss: 1.9937029500161447

Epoch: 6| Step: 12
Training loss: 2.2713935375213623
Validation loss: 1.993105351283986

Epoch: 6| Step: 13
Training loss: 1.7975599765777588
Validation loss: 1.9913001124576857

Epoch: 121| Step: 0
Training loss: 1.8566720485687256
Validation loss: 2.009044075524935

Epoch: 6| Step: 1
Training loss: 1.460257649421692
Validation loss: 2.021330548870948

Epoch: 6| Step: 2
Training loss: 2.6388564109802246
Validation loss: 2.046632394995741

Epoch: 6| Step: 3
Training loss: 2.460911512374878
Validation loss: 2.0556264795282835

Epoch: 6| Step: 4
Training loss: 2.1138031482696533
Validation loss: 2.0718314468219714

Epoch: 6| Step: 5
Training loss: 2.744716167449951
Validation loss: 2.0476959879680345

Epoch: 6| Step: 6
Training loss: 2.2863621711730957
Validation loss: 2.049847473380386

Epoch: 6| Step: 7
Training loss: 1.8097405433654785
Validation loss: 2.0186629833713656

Epoch: 6| Step: 8
Training loss: 2.699188470840454
Validation loss: 1.9871622670081355

Epoch: 6| Step: 9
Training loss: 2.1062755584716797
Validation loss: 1.9764510816143406

Epoch: 6| Step: 10
Training loss: 2.489790916442871
Validation loss: 1.9743936984769759

Epoch: 6| Step: 11
Training loss: 2.470743179321289
Validation loss: 1.9677886206616637

Epoch: 6| Step: 12
Training loss: 1.7787796258926392
Validation loss: 1.957947769472676

Epoch: 6| Step: 13
Training loss: 2.645907163619995
Validation loss: 1.9518327661739883

Epoch: 122| Step: 0
Training loss: 2.6211905479431152
Validation loss: 1.9668232728076238

Epoch: 6| Step: 1
Training loss: 1.4978735446929932
Validation loss: 1.9589444668062272

Epoch: 6| Step: 2
Training loss: 2.0163002014160156
Validation loss: 1.9685743829255462

Epoch: 6| Step: 3
Training loss: 2.464665174484253
Validation loss: 1.9686591727759248

Epoch: 6| Step: 4
Training loss: 1.807409405708313
Validation loss: 1.9772147888778357

Epoch: 6| Step: 5
Training loss: 2.009796619415283
Validation loss: 1.972893831550434

Epoch: 6| Step: 6
Training loss: 2.935729503631592
Validation loss: 1.997289829356696

Epoch: 6| Step: 7
Training loss: 3.0398483276367188
Validation loss: 1.9943452586409867

Epoch: 6| Step: 8
Training loss: 2.8881351947784424
Validation loss: 2.005780643032443

Epoch: 6| Step: 9
Training loss: 1.887131690979004
Validation loss: 2.0125976095917406

Epoch: 6| Step: 10
Training loss: 1.908558964729309
Validation loss: 2.005304444220758

Epoch: 6| Step: 11
Training loss: 1.4467129707336426
Validation loss: 1.9977368923925585

Epoch: 6| Step: 12
Training loss: 2.1640522480010986
Validation loss: 2.0083841841707946

Epoch: 6| Step: 13
Training loss: 2.197019577026367
Validation loss: 1.997700504077378

Epoch: 123| Step: 0
Training loss: 2.491091251373291
Validation loss: 1.9843222325847996

Epoch: 6| Step: 1
Training loss: 1.206272840499878
Validation loss: 1.9774078938268846

Epoch: 6| Step: 2
Training loss: 2.220633029937744
Validation loss: 1.9661162604567826

Epoch: 6| Step: 3
Training loss: 1.3967127799987793
Validation loss: 1.9767086916072394

Epoch: 6| Step: 4
Training loss: 2.2621335983276367
Validation loss: 1.9953237605351273

Epoch: 6| Step: 5
Training loss: 2.538496255874634
Validation loss: 1.9993421851947744

Epoch: 6| Step: 6
Training loss: 2.2755911350250244
Validation loss: 1.9986738927902714

Epoch: 6| Step: 7
Training loss: 2.8879892826080322
Validation loss: 2.0232990377692768

Epoch: 6| Step: 8
Training loss: 1.7459959983825684
Validation loss: 2.013090507958525

Epoch: 6| Step: 9
Training loss: 1.970569133758545
Validation loss: 1.9932066907164872

Epoch: 6| Step: 10
Training loss: 2.914531707763672
Validation loss: 1.9633610081929032

Epoch: 6| Step: 11
Training loss: 2.2384276390075684
Validation loss: 1.957568412185997

Epoch: 6| Step: 12
Training loss: 2.4612815380096436
Validation loss: 1.970950388139294

Epoch: 6| Step: 13
Training loss: 2.113016366958618
Validation loss: 2.0196206544035222

Epoch: 124| Step: 0
Training loss: 2.4572854042053223
Validation loss: 2.043242818565779

Epoch: 6| Step: 1
Training loss: 1.9024183750152588
Validation loss: 2.0636062147796794

Epoch: 6| Step: 2
Training loss: 1.9740595817565918
Validation loss: 2.088126746557092

Epoch: 6| Step: 3
Training loss: 2.389436721801758
Validation loss: 2.1011165982933453

Epoch: 6| Step: 4
Training loss: 2.4673209190368652
Validation loss: 2.083229813524472

Epoch: 6| Step: 5
Training loss: 2.8884379863739014
Validation loss: 2.0640533739520657

Epoch: 6| Step: 6
Training loss: 2.40423583984375
Validation loss: 2.03167978666162

Epoch: 6| Step: 7
Training loss: 2.3209638595581055
Validation loss: 2.013672582564815

Epoch: 6| Step: 8
Training loss: 2.0033555030822754
Validation loss: 2.012974577565347

Epoch: 6| Step: 9
Training loss: 1.5558425188064575
Validation loss: 2.0251811191599858

Epoch: 6| Step: 10
Training loss: 2.7496604919433594
Validation loss: 2.0435019231611684

Epoch: 6| Step: 11
Training loss: 1.972487449645996
Validation loss: 2.0069901930388583

Epoch: 6| Step: 12
Training loss: 2.4486427307128906
Validation loss: 1.9818638422155892

Epoch: 6| Step: 13
Training loss: 2.0419209003448486
Validation loss: 1.965348474441036

Epoch: 125| Step: 0
Training loss: 1.9959412813186646
Validation loss: 1.9537508846611105

Epoch: 6| Step: 1
Training loss: 2.4229602813720703
Validation loss: 1.9426385561625164

Epoch: 6| Step: 2
Training loss: 1.8802727460861206
Validation loss: 1.9435620974468928

Epoch: 6| Step: 3
Training loss: 1.6309607028961182
Validation loss: 1.9402607615276048

Epoch: 6| Step: 4
Training loss: 2.6898109912872314
Validation loss: 1.964684650462161

Epoch: 6| Step: 5
Training loss: 2.0532281398773193
Validation loss: 1.9712509698765253

Epoch: 6| Step: 6
Training loss: 2.3180153369903564
Validation loss: 2.0056829913969962

Epoch: 6| Step: 7
Training loss: 2.1446056365966797
Validation loss: 2.0383291167597615

Epoch: 6| Step: 8
Training loss: 2.2787349224090576
Validation loss: 2.054316475827207

Epoch: 6| Step: 9
Training loss: 2.766181468963623
Validation loss: 2.0683535555357575

Epoch: 6| Step: 10
Training loss: 2.728208541870117
Validation loss: 2.020731520909135

Epoch: 6| Step: 11
Training loss: 2.4882009029388428
Validation loss: 2.009678038217688

Epoch: 6| Step: 12
Training loss: 1.8751567602157593
Validation loss: 1.9831776285684237

Epoch: 6| Step: 13
Training loss: 2.1840944290161133
Validation loss: 1.9540396915969027

Epoch: 126| Step: 0
Training loss: 2.9891409873962402
Validation loss: 1.9838704601410897

Epoch: 6| Step: 1
Training loss: 3.0989837646484375
Validation loss: 2.0062760383852067

Epoch: 6| Step: 2
Training loss: 2.4326863288879395
Validation loss: 2.0374937980405745

Epoch: 6| Step: 3
Training loss: 1.9171767234802246
Validation loss: 2.0639237562815347

Epoch: 6| Step: 4
Training loss: 2.803997039794922
Validation loss: 2.038835402457945

Epoch: 6| Step: 5
Training loss: 1.6504443883895874
Validation loss: 2.011033155584848

Epoch: 6| Step: 6
Training loss: 2.167692184448242
Validation loss: 1.9706851115790747

Epoch: 6| Step: 7
Training loss: 1.9086718559265137
Validation loss: 1.9462761058602283

Epoch: 6| Step: 8
Training loss: 2.5658552646636963
Validation loss: 1.9241350607205463

Epoch: 6| Step: 9
Training loss: 1.74953293800354
Validation loss: 1.9124394219408754

Epoch: 6| Step: 10
Training loss: 2.1139869689941406
Validation loss: 1.9178124217576877

Epoch: 6| Step: 11
Training loss: 1.9393346309661865
Validation loss: 1.9207049390321136

Epoch: 6| Step: 12
Training loss: 2.2458901405334473
Validation loss: 1.919316791719006

Epoch: 6| Step: 13
Training loss: 1.500038743019104
Validation loss: 1.9254744796342746

Epoch: 127| Step: 0
Training loss: 2.6172451972961426
Validation loss: 1.9328677859357608

Epoch: 6| Step: 1
Training loss: 2.2972164154052734
Validation loss: 1.9394817724022815

Epoch: 6| Step: 2
Training loss: 2.3837413787841797
Validation loss: 1.953115504275086

Epoch: 6| Step: 3
Training loss: 1.7556867599487305
Validation loss: 1.9742739636410949

Epoch: 6| Step: 4
Training loss: 2.1630020141601562
Validation loss: 1.9941271120502102

Epoch: 6| Step: 5
Training loss: 2.1590230464935303
Validation loss: 1.991251927550121

Epoch: 6| Step: 6
Training loss: 1.9523779153823853
Validation loss: 2.002899185303719

Epoch: 6| Step: 7
Training loss: 1.8860483169555664
Validation loss: 1.9933462168580742

Epoch: 6| Step: 8
Training loss: 2.36017107963562
Validation loss: 2.001108633574619

Epoch: 6| Step: 9
Training loss: 2.281543731689453
Validation loss: 1.9937695380180114

Epoch: 6| Step: 10
Training loss: 2.4239702224731445
Validation loss: 1.9793337391268822

Epoch: 6| Step: 11
Training loss: 2.126051425933838
Validation loss: 1.954969104900155

Epoch: 6| Step: 12
Training loss: 1.6734404563903809
Validation loss: 1.9594411003974177

Epoch: 6| Step: 13
Training loss: 2.770352840423584
Validation loss: 1.9619181309976885

Epoch: 128| Step: 0
Training loss: 2.548884868621826
Validation loss: 1.980268936003408

Epoch: 6| Step: 1
Training loss: 2.4454164505004883
Validation loss: 1.9492282085521246

Epoch: 6| Step: 2
Training loss: 2.3629069328308105
Validation loss: 1.9694770266932826

Epoch: 6| Step: 3
Training loss: 2.9896140098571777
Validation loss: 1.9575374690435265

Epoch: 6| Step: 4
Training loss: 1.8907349109649658
Validation loss: 1.955009251512507

Epoch: 6| Step: 5
Training loss: 1.4784200191497803
Validation loss: 1.9622660042137228

Epoch: 6| Step: 6
Training loss: 2.2641992568969727
Validation loss: 1.9635866034415461

Epoch: 6| Step: 7
Training loss: 2.791431427001953
Validation loss: 1.9916033552538963

Epoch: 6| Step: 8
Training loss: 2.153510808944702
Validation loss: 1.996955708790851

Epoch: 6| Step: 9
Training loss: 2.06491756439209
Validation loss: 1.995584931424869

Epoch: 6| Step: 10
Training loss: 2.315905809402466
Validation loss: 1.9806639225252214

Epoch: 6| Step: 11
Training loss: 1.0591251850128174
Validation loss: 1.9902175934084

Epoch: 6| Step: 12
Training loss: 1.9968650341033936
Validation loss: 1.9718524999515985

Epoch: 6| Step: 13
Training loss: 1.7470202445983887
Validation loss: 1.9567207610735329

Epoch: 129| Step: 0
Training loss: 2.266908884048462
Validation loss: 1.9742563655299525

Epoch: 6| Step: 1
Training loss: 1.5588569641113281
Validation loss: 1.9931890913235244

Epoch: 6| Step: 2
Training loss: 1.8121027946472168
Validation loss: 1.9967672876132432

Epoch: 6| Step: 3
Training loss: 2.3063225746154785
Validation loss: 1.9959116110237696

Epoch: 6| Step: 4
Training loss: 2.2135114669799805
Validation loss: 1.9607578426279046

Epoch: 6| Step: 5
Training loss: 1.7456920146942139
Validation loss: 1.9569224439641482

Epoch: 6| Step: 6
Training loss: 2.7144198417663574
Validation loss: 1.9175134089685255

Epoch: 6| Step: 7
Training loss: 1.9363250732421875
Validation loss: 1.9149242703632643

Epoch: 6| Step: 8
Training loss: 1.878594160079956
Validation loss: 1.924069276420019

Epoch: 6| Step: 9
Training loss: 2.560511589050293
Validation loss: 1.9467385558671848

Epoch: 6| Step: 10
Training loss: 2.5475919246673584
Validation loss: 1.9560528698787893

Epoch: 6| Step: 11
Training loss: 2.3798720836639404
Validation loss: 1.9614648947151758

Epoch: 6| Step: 12
Training loss: 1.4465715885162354
Validation loss: 1.9707622143530077

Epoch: 6| Step: 13
Training loss: 3.4828507900238037
Validation loss: 1.965574182489867

Epoch: 130| Step: 0
Training loss: 1.7436339855194092
Validation loss: 1.982273087706617

Epoch: 6| Step: 1
Training loss: 1.9999885559082031
Validation loss: 1.9937341174771708

Epoch: 6| Step: 2
Training loss: 2.480438470840454
Validation loss: 2.0086320190019507

Epoch: 6| Step: 3
Training loss: 1.786234736442566
Validation loss: 2.007183773543245

Epoch: 6| Step: 4
Training loss: 2.7995386123657227
Validation loss: 2.0232841353262625

Epoch: 6| Step: 5
Training loss: 1.7165701389312744
Validation loss: 2.0312182416198072

Epoch: 6| Step: 6
Training loss: 2.069056987762451
Validation loss: 2.032962852908719

Epoch: 6| Step: 7
Training loss: 2.063856363296509
Validation loss: 2.017262566474176

Epoch: 6| Step: 8
Training loss: 2.1458306312561035
Validation loss: 2.0013398008961834

Epoch: 6| Step: 9
Training loss: 2.0186922550201416
Validation loss: 1.984876549372109

Epoch: 6| Step: 10
Training loss: 2.4927890300750732
Validation loss: 1.9853365767386653

Epoch: 6| Step: 11
Training loss: 2.8011763095855713
Validation loss: 1.990863839785258

Epoch: 6| Step: 12
Training loss: 1.6684629917144775
Validation loss: 2.0023800429477485

Epoch: 6| Step: 13
Training loss: 1.7878398895263672
Validation loss: 2.007783712879304

Epoch: 131| Step: 0
Training loss: 2.3851869106292725
Validation loss: 1.9994662628378919

Epoch: 6| Step: 1
Training loss: 1.515100359916687
Validation loss: 2.007049914329283

Epoch: 6| Step: 2
Training loss: 1.806618332862854
Validation loss: 2.0058744389523744

Epoch: 6| Step: 3
Training loss: 2.4560012817382812
Validation loss: 2.005944973678999

Epoch: 6| Step: 4
Training loss: 2.1494054794311523
Validation loss: 2.0008878348976054

Epoch: 6| Step: 5
Training loss: 1.4777828454971313
Validation loss: 1.9867049160824026

Epoch: 6| Step: 6
Training loss: 2.6202330589294434
Validation loss: 2.0059811338301627

Epoch: 6| Step: 7
Training loss: 2.063993453979492
Validation loss: 2.0078512443009244

Epoch: 6| Step: 8
Training loss: 1.9669996500015259
Validation loss: 1.976585094646741

Epoch: 6| Step: 9
Training loss: 2.1288139820098877
Validation loss: 1.9633748992796867

Epoch: 6| Step: 10
Training loss: 2.5915846824645996
Validation loss: 1.9587135596941876

Epoch: 6| Step: 11
Training loss: 2.945551872253418
Validation loss: 1.9669433255349436

Epoch: 6| Step: 12
Training loss: 2.201698064804077
Validation loss: 1.954639293814218

Epoch: 6| Step: 13
Training loss: 1.8144479990005493
Validation loss: 1.9618275960286458

Epoch: 132| Step: 0
Training loss: 2.3062729835510254
Validation loss: 1.9567802259998937

Epoch: 6| Step: 1
Training loss: 2.190786838531494
Validation loss: 1.9371773632623817

Epoch: 6| Step: 2
Training loss: 2.065737009048462
Validation loss: 1.9320432729618524

Epoch: 6| Step: 3
Training loss: 1.2676329612731934
Validation loss: 1.9384217698086974

Epoch: 6| Step: 4
Training loss: 2.4737324714660645
Validation loss: 1.9414515418391074

Epoch: 6| Step: 5
Training loss: 2.431337356567383
Validation loss: 1.968643174376539

Epoch: 6| Step: 6
Training loss: 2.2688825130462646
Validation loss: 1.976131562263735

Epoch: 6| Step: 7
Training loss: 1.7544689178466797
Validation loss: 1.9774454562894759

Epoch: 6| Step: 8
Training loss: 2.5421504974365234
Validation loss: 1.9597563051408338

Epoch: 6| Step: 9
Training loss: 1.8401432037353516
Validation loss: 1.966038279635932

Epoch: 6| Step: 10
Training loss: 2.4949452877044678
Validation loss: 1.9723688889575262

Epoch: 6| Step: 11
Training loss: 2.092772960662842
Validation loss: 2.0151647175512006

Epoch: 6| Step: 12
Training loss: 1.9518715143203735
Validation loss: 2.0847308738257295

Epoch: 6| Step: 13
Training loss: 2.8760976791381836
Validation loss: 2.0627389133617444

Epoch: 133| Step: 0
Training loss: 2.1592531204223633
Validation loss: 1.9700246882695023

Epoch: 6| Step: 1
Training loss: 2.1439709663391113
Validation loss: 1.9327152557270502

Epoch: 6| Step: 2
Training loss: 2.2424325942993164
Validation loss: 1.944854961928501

Epoch: 6| Step: 3
Training loss: 2.350135326385498
Validation loss: 1.9349177678426106

Epoch: 6| Step: 4
Training loss: 1.8945772647857666
Validation loss: 1.9385184613607263

Epoch: 6| Step: 5
Training loss: 2.1043038368225098
Validation loss: 1.9423273007074993

Epoch: 6| Step: 6
Training loss: 2.3523340225219727
Validation loss: 1.9527538886634253

Epoch: 6| Step: 7
Training loss: 2.2046964168548584
Validation loss: 1.9622731593347364

Epoch: 6| Step: 8
Training loss: 1.5382754802703857
Validation loss: 1.9754699609612907

Epoch: 6| Step: 9
Training loss: 2.2485053539276123
Validation loss: 1.985778239465529

Epoch: 6| Step: 10
Training loss: 2.739779472351074
Validation loss: 1.992142096642525

Epoch: 6| Step: 11
Training loss: 1.7781412601470947
Validation loss: 1.985452490468179

Epoch: 6| Step: 12
Training loss: 2.1170754432678223
Validation loss: 1.9924604098002117

Epoch: 6| Step: 13
Training loss: 1.9078500270843506
Validation loss: 1.9905075783370643

Epoch: 134| Step: 0
Training loss: 2.1469807624816895
Validation loss: 1.9957130147564797

Epoch: 6| Step: 1
Training loss: 2.689363479614258
Validation loss: 1.9950019364715905

Epoch: 6| Step: 2
Training loss: 1.939199686050415
Validation loss: 1.996125610925818

Epoch: 6| Step: 3
Training loss: 1.9522342681884766
Validation loss: 1.9769472563138573

Epoch: 6| Step: 4
Training loss: 1.5739530324935913
Validation loss: 1.9514751152325702

Epoch: 6| Step: 5
Training loss: 0.946699321269989
Validation loss: 1.9316617622170398

Epoch: 6| Step: 6
Training loss: 2.769728660583496
Validation loss: 1.9274990456078642

Epoch: 6| Step: 7
Training loss: 2.4429636001586914
Validation loss: 1.937720497449239

Epoch: 6| Step: 8
Training loss: 1.9874413013458252
Validation loss: 1.966299928644652

Epoch: 6| Step: 9
Training loss: 1.9141991138458252
Validation loss: 1.9636672517304778

Epoch: 6| Step: 10
Training loss: 2.617474317550659
Validation loss: 1.9637352189710062

Epoch: 6| Step: 11
Training loss: 2.4866814613342285
Validation loss: 1.9308398359565324

Epoch: 6| Step: 12
Training loss: 2.602485418319702
Validation loss: 1.9211102019074142

Epoch: 6| Step: 13
Training loss: 2.2599263191223145
Validation loss: 1.9013422548129995

Epoch: 135| Step: 0
Training loss: 2.362905502319336
Validation loss: 1.8980418097588323

Epoch: 6| Step: 1
Training loss: 2.337512493133545
Validation loss: 1.909697828754302

Epoch: 6| Step: 2
Training loss: 2.4070212841033936
Validation loss: 1.9134229254978958

Epoch: 6| Step: 3
Training loss: 1.7615110874176025
Validation loss: 1.9270366391827982

Epoch: 6| Step: 4
Training loss: 2.4661545753479004
Validation loss: 1.9262108905341035

Epoch: 6| Step: 5
Training loss: 1.6699249744415283
Validation loss: 1.909088014274515

Epoch: 6| Step: 6
Training loss: 2.4157960414886475
Validation loss: 1.9025903389018068

Epoch: 6| Step: 7
Training loss: 1.690192461013794
Validation loss: 1.901403780906431

Epoch: 6| Step: 8
Training loss: 1.913928508758545
Validation loss: 1.9217339446467738

Epoch: 6| Step: 9
Training loss: 1.8778774738311768
Validation loss: 1.9236627112152755

Epoch: 6| Step: 10
Training loss: 2.264035224914551
Validation loss: 1.9487202090601767

Epoch: 6| Step: 11
Training loss: 1.9384061098098755
Validation loss: 1.970763438491411

Epoch: 6| Step: 12
Training loss: 1.9779739379882812
Validation loss: 2.0047230528246973

Epoch: 6| Step: 13
Training loss: 2.304729461669922
Validation loss: 2.0525664155201246

Epoch: 136| Step: 0
Training loss: 1.8855706453323364
Validation loss: 2.118408187743156

Epoch: 6| Step: 1
Training loss: 1.984740138053894
Validation loss: 2.1009218833779775

Epoch: 6| Step: 2
Training loss: 2.6275076866149902
Validation loss: 2.0419432309366043

Epoch: 6| Step: 3
Training loss: 1.9544943571090698
Validation loss: 1.9852407850244993

Epoch: 6| Step: 4
Training loss: 1.7151650190353394
Validation loss: 1.9534483853206839

Epoch: 6| Step: 5
Training loss: 2.9850587844848633
Validation loss: 1.9323752798059934

Epoch: 6| Step: 6
Training loss: 2.016469955444336
Validation loss: 1.9467490065482356

Epoch: 6| Step: 7
Training loss: 2.4064512252807617
Validation loss: 1.934039879870671

Epoch: 6| Step: 8
Training loss: 1.5890072584152222
Validation loss: 1.9455056639127835

Epoch: 6| Step: 9
Training loss: 1.6125905513763428
Validation loss: 1.947793988771336

Epoch: 6| Step: 10
Training loss: 2.254096031188965
Validation loss: 1.9400001892479517

Epoch: 6| Step: 11
Training loss: 3.0443811416625977
Validation loss: 1.957759698232015

Epoch: 6| Step: 12
Training loss: 2.5016560554504395
Validation loss: 1.9483318739039923

Epoch: 6| Step: 13
Training loss: 1.6983330249786377
Validation loss: 1.968072839962539

Epoch: 137| Step: 0
Training loss: 2.050414562225342
Validation loss: 1.975330734765658

Epoch: 6| Step: 1
Training loss: 1.9306590557098389
Validation loss: 1.9921674638666131

Epoch: 6| Step: 2
Training loss: 2.0170509815216064
Validation loss: 1.97027192577239

Epoch: 6| Step: 3
Training loss: 2.368314504623413
Validation loss: 1.9840650930199573

Epoch: 6| Step: 4
Training loss: 0.9563628435134888
Validation loss: 1.980487100539669

Epoch: 6| Step: 5
Training loss: 2.0808184146881104
Validation loss: 1.9524118156843289

Epoch: 6| Step: 6
Training loss: 2.2119650840759277
Validation loss: 1.9470171646405292

Epoch: 6| Step: 7
Training loss: 2.278313636779785
Validation loss: 1.9306226712401195

Epoch: 6| Step: 8
Training loss: 2.4193508625030518
Validation loss: 1.9218479253912484

Epoch: 6| Step: 9
Training loss: 2.0158205032348633
Validation loss: 1.908565362294515

Epoch: 6| Step: 10
Training loss: 2.2990283966064453
Validation loss: 1.9043192145644978

Epoch: 6| Step: 11
Training loss: 2.1696929931640625
Validation loss: 1.9133045173460437

Epoch: 6| Step: 12
Training loss: 2.707831382751465
Validation loss: 1.9214738133133098

Epoch: 6| Step: 13
Training loss: 2.602388381958008
Validation loss: 1.9265496371894755

Epoch: 138| Step: 0
Training loss: 1.9288462400436401
Validation loss: 1.9276337726141817

Epoch: 6| Step: 1
Training loss: 2.612161159515381
Validation loss: 1.9565773522982033

Epoch: 6| Step: 2
Training loss: 1.7950407266616821
Validation loss: 1.9612395801851827

Epoch: 6| Step: 3
Training loss: 2.0017387866973877
Validation loss: 1.9870042852176133

Epoch: 6| Step: 4
Training loss: 2.244457483291626
Validation loss: 2.0182244777679443

Epoch: 6| Step: 5
Training loss: 1.93129563331604
Validation loss: 2.0258356384051743

Epoch: 6| Step: 6
Training loss: 2.0597331523895264
Validation loss: 2.070687105578761

Epoch: 6| Step: 7
Training loss: 2.0454201698303223
Validation loss: 2.052820651761947

Epoch: 6| Step: 8
Training loss: 1.8260952234268188
Validation loss: 1.9887879356261222

Epoch: 6| Step: 9
Training loss: 2.567298650741577
Validation loss: 1.9313459678362774

Epoch: 6| Step: 10
Training loss: 2.490826368331909
Validation loss: 1.9193124155844412

Epoch: 6| Step: 11
Training loss: 2.454261541366577
Validation loss: 1.9136524943895237

Epoch: 6| Step: 12
Training loss: 1.897608995437622
Validation loss: 1.9156349833293627

Epoch: 6| Step: 13
Training loss: 1.6408119201660156
Validation loss: 1.9356871984338249

Epoch: 139| Step: 0
Training loss: 2.4977915287017822
Validation loss: 1.9490727865567772

Epoch: 6| Step: 1
Training loss: 1.9638636112213135
Validation loss: 1.9364091965460009

Epoch: 6| Step: 2
Training loss: 1.6552703380584717
Validation loss: 1.9325836243168

Epoch: 6| Step: 3
Training loss: 3.1018786430358887
Validation loss: 1.9078878125836771

Epoch: 6| Step: 4
Training loss: 1.9231733083724976
Validation loss: 1.901782335773591

Epoch: 6| Step: 5
Training loss: 2.7278480529785156
Validation loss: 1.9021539303564257

Epoch: 6| Step: 6
Training loss: 2.4903249740600586
Validation loss: 1.9046348025721889

Epoch: 6| Step: 7
Training loss: 1.9308292865753174
Validation loss: 1.9150556492549118

Epoch: 6| Step: 8
Training loss: 1.6644717454910278
Validation loss: 1.9447736983658166

Epoch: 6| Step: 9
Training loss: 2.0594747066497803
Validation loss: 1.9663059532001455

Epoch: 6| Step: 10
Training loss: 2.5896658897399902
Validation loss: 1.9640929993762766

Epoch: 6| Step: 11
Training loss: 1.6814625263214111
Validation loss: 1.9472015416750343

Epoch: 6| Step: 12
Training loss: 2.382204532623291
Validation loss: 1.9501261634211386

Epoch: 6| Step: 13
Training loss: 1.9363248348236084
Validation loss: 1.9622949771983649

Epoch: 140| Step: 0
Training loss: 2.422146797180176
Validation loss: 1.9762375188130203

Epoch: 6| Step: 1
Training loss: 2.2258739471435547
Validation loss: 1.9767235299592376

Epoch: 6| Step: 2
Training loss: 2.2252073287963867
Validation loss: 1.9713483984752367

Epoch: 6| Step: 3
Training loss: 1.9958678483963013
Validation loss: 1.9651138141591062

Epoch: 6| Step: 4
Training loss: 2.691457748413086
Validation loss: 1.9551613792296378

Epoch: 6| Step: 5
Training loss: 2.526185989379883
Validation loss: 1.9559996461355558

Epoch: 6| Step: 6
Training loss: 1.9847108125686646
Validation loss: 1.9519144591464792

Epoch: 6| Step: 7
Training loss: 1.9124934673309326
Validation loss: 1.97680147745276

Epoch: 6| Step: 8
Training loss: 2.347029209136963
Validation loss: 1.9704873766950382

Epoch: 6| Step: 9
Training loss: 1.9828910827636719
Validation loss: 1.9672598274805213

Epoch: 6| Step: 10
Training loss: 1.8277052640914917
Validation loss: 1.9475516478220622

Epoch: 6| Step: 11
Training loss: 1.8460333347320557
Validation loss: 1.9224765377659951

Epoch: 6| Step: 12
Training loss: 1.7824993133544922
Validation loss: 1.9203270660933627

Epoch: 6| Step: 13
Training loss: 1.9066895246505737
Validation loss: 1.9199315501797585

Epoch: 141| Step: 0
Training loss: 1.8605307340621948
Validation loss: 1.9406000439838698

Epoch: 6| Step: 1
Training loss: 2.4236385822296143
Validation loss: 1.9508097658875168

Epoch: 6| Step: 2
Training loss: 2.2135274410247803
Validation loss: 1.9627312755071988

Epoch: 6| Step: 3
Training loss: 2.3647208213806152
Validation loss: 1.9765132216997043

Epoch: 6| Step: 4
Training loss: 2.4447743892669678
Validation loss: 1.9595847052912558

Epoch: 6| Step: 5
Training loss: 2.3273210525512695
Validation loss: 1.9545207715803576

Epoch: 6| Step: 6
Training loss: 2.1753697395324707
Validation loss: 1.9531213006665629

Epoch: 6| Step: 7
Training loss: 1.5062729120254517
Validation loss: 1.9776260878450127

Epoch: 6| Step: 8
Training loss: 2.666311740875244
Validation loss: 1.986074762959634

Epoch: 6| Step: 9
Training loss: 2.5420634746551514
Validation loss: 2.0002343757178194

Epoch: 6| Step: 10
Training loss: 1.3722113370895386
Validation loss: 2.006860412577147

Epoch: 6| Step: 11
Training loss: 1.6608293056488037
Validation loss: 1.9791140351244199

Epoch: 6| Step: 12
Training loss: 2.1303775310516357
Validation loss: 1.9788119998029483

Epoch: 6| Step: 13
Training loss: 1.5971531867980957
Validation loss: 1.9888660228380592

Epoch: 142| Step: 0
Training loss: 2.1121678352355957
Validation loss: 1.9524071062764814

Epoch: 6| Step: 1
Training loss: 2.3713369369506836
Validation loss: 1.9543959786815028

Epoch: 6| Step: 2
Training loss: 2.944244384765625
Validation loss: 1.9544459696738952

Epoch: 6| Step: 3
Training loss: 1.975602388381958
Validation loss: 1.9404587104756346

Epoch: 6| Step: 4
Training loss: 2.5380587577819824
Validation loss: 1.9410294768630818

Epoch: 6| Step: 5
Training loss: 2.0761070251464844
Validation loss: 1.9383027643285773

Epoch: 6| Step: 6
Training loss: 2.283332347869873
Validation loss: 1.9379762372662943

Epoch: 6| Step: 7
Training loss: 1.6933341026306152
Validation loss: 1.9270826526867446

Epoch: 6| Step: 8
Training loss: 1.3420665264129639
Validation loss: 1.9413463710456766

Epoch: 6| Step: 9
Training loss: 2.0541818141937256
Validation loss: 1.9255803656834427

Epoch: 6| Step: 10
Training loss: 1.626591444015503
Validation loss: 1.9345606398838822

Epoch: 6| Step: 11
Training loss: 2.0061540603637695
Validation loss: 1.9254994161667363

Epoch: 6| Step: 12
Training loss: 1.6502418518066406
Validation loss: 1.9150423285781697

Epoch: 6| Step: 13
Training loss: 2.261577606201172
Validation loss: 1.9289946351000058

Epoch: 143| Step: 0
Training loss: 1.7675163745880127
Validation loss: 1.9279747675823908

Epoch: 6| Step: 1
Training loss: 1.9987865686416626
Validation loss: 1.9285441675493795

Epoch: 6| Step: 2
Training loss: 1.7436332702636719
Validation loss: 1.9235972704425934

Epoch: 6| Step: 3
Training loss: 2.252518892288208
Validation loss: 1.9273956052718624

Epoch: 6| Step: 4
Training loss: 2.2983241081237793
Validation loss: 1.9350084361209665

Epoch: 6| Step: 5
Training loss: 2.456186056137085
Validation loss: 1.9537736523535945

Epoch: 6| Step: 6
Training loss: 1.8608245849609375
Validation loss: 1.950407338398759

Epoch: 6| Step: 7
Training loss: 1.8538413047790527
Validation loss: 1.9493138918312647

Epoch: 6| Step: 8
Training loss: 2.1724565029144287
Validation loss: 1.9523705859338083

Epoch: 6| Step: 9
Training loss: 1.984655737876892
Validation loss: 1.9736418724060059

Epoch: 6| Step: 10
Training loss: 1.7839446067810059
Validation loss: 1.995763788941086

Epoch: 6| Step: 11
Training loss: 2.3907573223114014
Validation loss: 2.0030858516693115

Epoch: 6| Step: 12
Training loss: 1.8118106126785278
Validation loss: 2.008432383178383

Epoch: 6| Step: 13
Training loss: 2.850900411605835
Validation loss: 1.9948990242455595

Epoch: 144| Step: 0
Training loss: 2.22761869430542
Validation loss: 1.990740587634425

Epoch: 6| Step: 1
Training loss: 1.366182565689087
Validation loss: 1.9675687756589664

Epoch: 6| Step: 2
Training loss: 2.8806211948394775
Validation loss: 1.9350736923115228

Epoch: 6| Step: 3
Training loss: 1.6392815113067627
Validation loss: 1.910602879780595

Epoch: 6| Step: 4
Training loss: 2.1011648178100586
Validation loss: 1.8913951509742326

Epoch: 6| Step: 5
Training loss: 2.402247905731201
Validation loss: 1.891424491841306

Epoch: 6| Step: 6
Training loss: 2.017303705215454
Validation loss: 1.8834197123845418

Epoch: 6| Step: 7
Training loss: 2.6623687744140625
Validation loss: 1.8798503978278047

Epoch: 6| Step: 8
Training loss: 1.9677155017852783
Validation loss: 1.8818638222191924

Epoch: 6| Step: 9
Training loss: 1.9017951488494873
Validation loss: 1.8922563111910256

Epoch: 6| Step: 10
Training loss: 1.9007174968719482
Validation loss: 1.8987915067262546

Epoch: 6| Step: 11
Training loss: 1.287886619567871
Validation loss: 1.9200067898278594

Epoch: 6| Step: 12
Training loss: 2.3134379386901855
Validation loss: 1.922506441352188

Epoch: 6| Step: 13
Training loss: 2.06388521194458
Validation loss: 1.9366750537708242

Epoch: 145| Step: 0
Training loss: 1.8894635438919067
Validation loss: 1.9580023609181887

Epoch: 6| Step: 1
Training loss: 2.5214905738830566
Validation loss: 1.9735592449865034

Epoch: 6| Step: 2
Training loss: 1.9462976455688477
Validation loss: 1.9599254977318548

Epoch: 6| Step: 3
Training loss: 2.4248461723327637
Validation loss: 1.9751051138806086

Epoch: 6| Step: 4
Training loss: 1.9310650825500488
Validation loss: 1.943469524383545

Epoch: 6| Step: 5
Training loss: 2.08535099029541
Validation loss: 1.9321488372741207

Epoch: 6| Step: 6
Training loss: 2.670117139816284
Validation loss: 1.9510450414431992

Epoch: 6| Step: 7
Training loss: 1.9658358097076416
Validation loss: 1.9475204649791922

Epoch: 6| Step: 8
Training loss: 1.73758864402771
Validation loss: 1.9252850855550458

Epoch: 6| Step: 9
Training loss: 2.460977554321289
Validation loss: 1.9245377663643128

Epoch: 6| Step: 10
Training loss: 1.6053229570388794
Validation loss: 1.9238799438681653

Epoch: 6| Step: 11
Training loss: 2.0838522911071777
Validation loss: 1.9101586123948455

Epoch: 6| Step: 12
Training loss: 1.4031798839569092
Validation loss: 1.9009323312390236

Epoch: 6| Step: 13
Training loss: 0.6609243750572205
Validation loss: 1.9016808438044723

Epoch: 146| Step: 0
Training loss: 2.08518648147583
Validation loss: 1.8881483949640745

Epoch: 6| Step: 1
Training loss: 2.456556558609009
Validation loss: 1.8912223083998567

Epoch: 6| Step: 2
Training loss: 2.224971294403076
Validation loss: 1.892008819887715

Epoch: 6| Step: 3
Training loss: 1.4410805702209473
Validation loss: 1.8833055137306132

Epoch: 6| Step: 4
Training loss: 1.4688401222229004
Validation loss: 1.8917185004039476

Epoch: 6| Step: 5
Training loss: 2.18316912651062
Validation loss: 1.9005145718974452

Epoch: 6| Step: 6
Training loss: 1.8440319299697876
Validation loss: 1.8990381712554603

Epoch: 6| Step: 7
Training loss: 2.2410900592803955
Validation loss: 1.9004783835462344

Epoch: 6| Step: 8
Training loss: 1.7338618040084839
Validation loss: 1.9108309258696854

Epoch: 6| Step: 9
Training loss: 1.7343499660491943
Validation loss: 1.8997235375065957

Epoch: 6| Step: 10
Training loss: 1.992809772491455
Validation loss: 1.938992661814536

Epoch: 6| Step: 11
Training loss: 1.8042750358581543
Validation loss: 1.9415749349901754

Epoch: 6| Step: 12
Training loss: 2.7531039714813232
Validation loss: 1.9467152369919645

Epoch: 6| Step: 13
Training loss: 2.274777889251709
Validation loss: 1.9400468641711819

Epoch: 147| Step: 0
Training loss: 1.5895075798034668
Validation loss: 1.9712027644598356

Epoch: 6| Step: 1
Training loss: 2.334517478942871
Validation loss: 1.9755047957102458

Epoch: 6| Step: 2
Training loss: 2.8671934604644775
Validation loss: 1.968477294009219

Epoch: 6| Step: 3
Training loss: 2.4477310180664062
Validation loss: 1.9842097913065264

Epoch: 6| Step: 4
Training loss: 1.864213466644287
Validation loss: 1.9610506655067526

Epoch: 6| Step: 5
Training loss: 1.5105397701263428
Validation loss: 1.9096176855025753

Epoch: 6| Step: 6
Training loss: 0.9900637865066528
Validation loss: 1.8885681808635753

Epoch: 6| Step: 7
Training loss: 1.9496560096740723
Validation loss: 1.8942406741521691

Epoch: 6| Step: 8
Training loss: 2.463728904724121
Validation loss: 1.8914704912452287

Epoch: 6| Step: 9
Training loss: 2.7793450355529785
Validation loss: 1.888040824603009

Epoch: 6| Step: 10
Training loss: 1.7355847358703613
Validation loss: 1.8891817523587136

Epoch: 6| Step: 11
Training loss: 1.9686301946640015
Validation loss: 1.875067102011814

Epoch: 6| Step: 12
Training loss: 1.8350846767425537
Validation loss: 1.888200649651148

Epoch: 6| Step: 13
Training loss: 2.292182445526123
Validation loss: 1.9044701155795847

Epoch: 148| Step: 0
Training loss: 1.6776124238967896
Validation loss: 1.9367952321165351

Epoch: 6| Step: 1
Training loss: 2.1416282653808594
Validation loss: 1.95116425073275

Epoch: 6| Step: 2
Training loss: 1.3225054740905762
Validation loss: 1.9444622339740876

Epoch: 6| Step: 3
Training loss: 1.9100513458251953
Validation loss: 1.9502105764163438

Epoch: 6| Step: 4
Training loss: 2.0536184310913086
Validation loss: 1.941053202075343

Epoch: 6| Step: 5
Training loss: 1.7962312698364258
Validation loss: 1.947139686153781

Epoch: 6| Step: 6
Training loss: 2.5055906772613525
Validation loss: 1.9353766979709748

Epoch: 6| Step: 7
Training loss: 1.8278517723083496
Validation loss: 1.9505380866348103

Epoch: 6| Step: 8
Training loss: 1.9323415756225586
Validation loss: 1.953653322753086

Epoch: 6| Step: 9
Training loss: 1.3939616680145264
Validation loss: 1.9010540958373778

Epoch: 6| Step: 10
Training loss: 1.8969340324401855
Validation loss: 1.9138142626772645

Epoch: 6| Step: 11
Training loss: 2.196091651916504
Validation loss: 1.8999279365744641

Epoch: 6| Step: 12
Training loss: 2.3779544830322266
Validation loss: 1.9009318685018888

Epoch: 6| Step: 13
Training loss: 3.1726415157318115
Validation loss: 1.890017791460919

Epoch: 149| Step: 0
Training loss: 1.5787012577056885
Validation loss: 1.9061969480206888

Epoch: 6| Step: 1
Training loss: 2.238809585571289
Validation loss: 1.9211650099805606

Epoch: 6| Step: 2
Training loss: 2.2407212257385254
Validation loss: 1.924249796457188

Epoch: 6| Step: 3
Training loss: 1.788421630859375
Validation loss: 1.947815683580214

Epoch: 6| Step: 4
Training loss: 1.8330546617507935
Validation loss: 1.971835611968912

Epoch: 6| Step: 5
Training loss: 1.7574169635772705
Validation loss: 1.975029049381133

Epoch: 6| Step: 6
Training loss: 1.7147265672683716
Validation loss: 1.9641170168435702

Epoch: 6| Step: 7
Training loss: 1.8907430171966553
Validation loss: 1.9386318473405735

Epoch: 6| Step: 8
Training loss: 1.4623125791549683
Validation loss: 1.9410176853979788

Epoch: 6| Step: 9
Training loss: 2.0284955501556396
Validation loss: 1.9252300236814766

Epoch: 6| Step: 10
Training loss: 2.191532850265503
Validation loss: 1.918575507338329

Epoch: 6| Step: 11
Training loss: 2.494131088256836
Validation loss: 1.9013717264257453

Epoch: 6| Step: 12
Training loss: 2.1852688789367676
Validation loss: 1.8991623565714846

Epoch: 6| Step: 13
Training loss: 2.209909439086914
Validation loss: 1.9003447281417025

Epoch: 150| Step: 0
Training loss: 1.6776741743087769
Validation loss: 1.8885008058240336

Epoch: 6| Step: 1
Training loss: 2.0017552375793457
Validation loss: 1.9166095590078702

Epoch: 6| Step: 2
Training loss: 1.593881368637085
Validation loss: 1.928263456590714

Epoch: 6| Step: 3
Training loss: 1.559131383895874
Validation loss: 1.9311514772394651

Epoch: 6| Step: 4
Training loss: 1.4501593112945557
Validation loss: 1.9585132111785233

Epoch: 6| Step: 5
Training loss: 2.2154195308685303
Validation loss: 1.935791156625235

Epoch: 6| Step: 6
Training loss: 1.4670770168304443
Validation loss: 1.9617072151553245

Epoch: 6| Step: 7
Training loss: 1.6636244058609009
Validation loss: 1.9901579374908118

Epoch: 6| Step: 8
Training loss: 2.6866865158081055
Validation loss: 2.0162705298393004

Epoch: 6| Step: 9
Training loss: 2.3768486976623535
Validation loss: 1.9835862318674724

Epoch: 6| Step: 10
Training loss: 2.728884696960449
Validation loss: 1.9539701041354929

Epoch: 6| Step: 11
Training loss: 2.81894588470459
Validation loss: 1.9458625854984406

Epoch: 6| Step: 12
Training loss: 1.402108907699585
Validation loss: 1.9396395362833494

Epoch: 6| Step: 13
Training loss: 3.5243539810180664
Validation loss: 1.8816097180048625

Epoch: 151| Step: 0
Training loss: 2.6616764068603516
Validation loss: 1.859518631812065

Epoch: 6| Step: 1
Training loss: 1.356945514678955
Validation loss: 1.8621486899673299

Epoch: 6| Step: 2
Training loss: 1.8373570442199707
Validation loss: 1.8549637845767442

Epoch: 6| Step: 3
Training loss: 2.314192771911621
Validation loss: 1.867891106554257

Epoch: 6| Step: 4
Training loss: 1.9108986854553223
Validation loss: 1.8649563392003377

Epoch: 6| Step: 5
Training loss: 2.278142213821411
Validation loss: 1.8627001034316195

Epoch: 6| Step: 6
Training loss: 1.0564451217651367
Validation loss: 1.8880690656682497

Epoch: 6| Step: 7
Training loss: 1.9044121503829956
Validation loss: 1.925813990254556

Epoch: 6| Step: 8
Training loss: 1.8472843170166016
Validation loss: 1.9534387998683478

Epoch: 6| Step: 9
Training loss: 2.6346275806427
Validation loss: 1.984044849231679

Epoch: 6| Step: 10
Training loss: 1.9456137418746948
Validation loss: 1.952562221916773

Epoch: 6| Step: 11
Training loss: 2.206843852996826
Validation loss: 1.9485398492505472

Epoch: 6| Step: 12
Training loss: 2.287623882293701
Validation loss: 1.9394018368054462

Epoch: 6| Step: 13
Training loss: 1.9812853336334229
Validation loss: 1.9102524788148942

Epoch: 152| Step: 0
Training loss: 1.7603143453598022
Validation loss: 1.8712998269706644

Epoch: 6| Step: 1
Training loss: 2.156585216522217
Validation loss: 1.8613216415528329

Epoch: 6| Step: 2
Training loss: 2.0382277965545654
Validation loss: 1.8800180035252725

Epoch: 6| Step: 3
Training loss: 2.405208110809326
Validation loss: 1.8668647530258342

Epoch: 6| Step: 4
Training loss: 2.539566993713379
Validation loss: 1.8357379949221047

Epoch: 6| Step: 5
Training loss: 2.144296646118164
Validation loss: 1.8472318123745661

Epoch: 6| Step: 6
Training loss: 1.3659313917160034
Validation loss: 1.8599452434047576

Epoch: 6| Step: 7
Training loss: 1.8922147750854492
Validation loss: 1.8858342080987909

Epoch: 6| Step: 8
Training loss: 1.679369568824768
Validation loss: 1.9267285895603958

Epoch: 6| Step: 9
Training loss: 1.5425407886505127
Validation loss: 1.9448552234198457

Epoch: 6| Step: 10
Training loss: 2.214082717895508
Validation loss: 1.9448615915031844

Epoch: 6| Step: 11
Training loss: 2.1508121490478516
Validation loss: 1.962187546555714

Epoch: 6| Step: 12
Training loss: 2.3869359493255615
Validation loss: 1.9547797556846374

Epoch: 6| Step: 13
Training loss: 1.9433858394622803
Validation loss: 1.955890376080749

Epoch: 153| Step: 0
Training loss: 1.6447992324829102
Validation loss: 1.9600820092744724

Epoch: 6| Step: 1
Training loss: 2.230358123779297
Validation loss: 1.9662614535259944

Epoch: 6| Step: 2
Training loss: 1.909909963607788
Validation loss: 1.9779849680521155

Epoch: 6| Step: 3
Training loss: 1.4902100563049316
Validation loss: 2.0052197799887708

Epoch: 6| Step: 4
Training loss: 1.9149161577224731
Validation loss: 2.036994393153857

Epoch: 6| Step: 5
Training loss: 2.672436475753784
Validation loss: 2.0065496019137803

Epoch: 6| Step: 6
Training loss: 1.8128514289855957
Validation loss: 2.003861076088362

Epoch: 6| Step: 7
Training loss: 1.971236228942871
Validation loss: 2.004411335914366

Epoch: 6| Step: 8
Training loss: 1.868969440460205
Validation loss: 1.9924619095299834

Epoch: 6| Step: 9
Training loss: 2.484170913696289
Validation loss: 1.9461529985550912

Epoch: 6| Step: 10
Training loss: 2.2604498863220215
Validation loss: 1.932232517068104

Epoch: 6| Step: 11
Training loss: 2.045494794845581
Validation loss: 1.9214243273581229

Epoch: 6| Step: 12
Training loss: 1.6851465702056885
Validation loss: 1.9031335615342664

Epoch: 6| Step: 13
Training loss: 1.3787623643875122
Validation loss: 1.90213732821967

Epoch: 154| Step: 0
Training loss: 1.767302393913269
Validation loss: 1.8737466796751945

Epoch: 6| Step: 1
Training loss: 1.4292120933532715
Validation loss: 1.8849099810405443

Epoch: 6| Step: 2
Training loss: 2.4000000953674316
Validation loss: 1.8971861793148903

Epoch: 6| Step: 3
Training loss: 2.0405054092407227
Validation loss: 1.914735092911669

Epoch: 6| Step: 4
Training loss: 2.1711196899414062
Validation loss: 1.934966646214967

Epoch: 6| Step: 5
Training loss: 2.438746929168701
Validation loss: 1.9486471606839089

Epoch: 6| Step: 6
Training loss: 1.5203771591186523
Validation loss: 1.945267549125097

Epoch: 6| Step: 7
Training loss: 1.9219744205474854
Validation loss: 1.9123043065430017

Epoch: 6| Step: 8
Training loss: 2.02524471282959
Validation loss: 1.8915362691366544

Epoch: 6| Step: 9
Training loss: 1.598651647567749
Validation loss: 1.8702256820535148

Epoch: 6| Step: 10
Training loss: 2.2610135078430176
Validation loss: 1.8811726365038144

Epoch: 6| Step: 11
Training loss: 1.7858357429504395
Validation loss: 1.8730718064051803

Epoch: 6| Step: 12
Training loss: 1.9513649940490723
Validation loss: 1.901095062173823

Epoch: 6| Step: 13
Training loss: 2.434440851211548
Validation loss: 1.9119875559242823

Epoch: 155| Step: 0
Training loss: 1.8035855293273926
Validation loss: 1.9182812039570143

Epoch: 6| Step: 1
Training loss: 1.9828301668167114
Validation loss: 1.943848717597223

Epoch: 6| Step: 2
Training loss: 1.7437217235565186
Validation loss: 1.9544742376573625

Epoch: 6| Step: 3
Training loss: 1.5542773008346558
Validation loss: 1.9778354373029483

Epoch: 6| Step: 4
Training loss: 2.65729022026062
Validation loss: 1.9816845232440579

Epoch: 6| Step: 5
Training loss: 2.288801431655884
Validation loss: 1.9867289937952513

Epoch: 6| Step: 6
Training loss: 1.4389570951461792
Validation loss: 1.9788232208580099

Epoch: 6| Step: 7
Training loss: 2.4810562133789062
Validation loss: 1.9861997327496927

Epoch: 6| Step: 8
Training loss: 1.9801180362701416
Validation loss: 1.9741330480062833

Epoch: 6| Step: 9
Training loss: 1.864274263381958
Validation loss: 1.9571413442652712

Epoch: 6| Step: 10
Training loss: 1.5989227294921875
Validation loss: 1.9446461533987394

Epoch: 6| Step: 11
Training loss: 1.2094340324401855
Validation loss: 1.9120711882909138

Epoch: 6| Step: 12
Training loss: 2.909546375274658
Validation loss: 1.8764126377720987

Epoch: 6| Step: 13
Training loss: 1.6820517778396606
Validation loss: 1.8660980475846158

Epoch: 156| Step: 0
Training loss: 1.7461578845977783
Validation loss: 1.8584395006138792

Epoch: 6| Step: 1
Training loss: 1.3228294849395752
Validation loss: 1.8367052347429338

Epoch: 6| Step: 2
Training loss: 2.2364423274993896
Validation loss: 1.8588767769516155

Epoch: 6| Step: 3
Training loss: 1.7171859741210938
Validation loss: 1.861575335584661

Epoch: 6| Step: 4
Training loss: 1.86639404296875
Validation loss: 1.8937675709365516

Epoch: 6| Step: 5
Training loss: 1.9844787120819092
Validation loss: 1.9217630381225257

Epoch: 6| Step: 6
Training loss: 1.9706891775131226
Validation loss: 1.9284099122529388

Epoch: 6| Step: 7
Training loss: 2.05678129196167
Validation loss: 1.936213444637996

Epoch: 6| Step: 8
Training loss: 2.070714235305786
Validation loss: 1.9394893107875701

Epoch: 6| Step: 9
Training loss: 2.0930895805358887
Validation loss: 1.8902840896319317

Epoch: 6| Step: 10
Training loss: 1.741833209991455
Validation loss: 1.8887466025608841

Epoch: 6| Step: 11
Training loss: 2.4524970054626465
Validation loss: 1.891865357275932

Epoch: 6| Step: 12
Training loss: 2.1604909896850586
Validation loss: 1.8992552423989901

Epoch: 6| Step: 13
Training loss: 1.446789264678955
Validation loss: 1.8880383711989208

Epoch: 157| Step: 0
Training loss: 2.3657281398773193
Validation loss: 1.9118618401147986

Epoch: 6| Step: 1
Training loss: 1.9078727960586548
Validation loss: 1.91740979174132

Epoch: 6| Step: 2
Training loss: 2.1521377563476562
Validation loss: 1.9203222438853274

Epoch: 6| Step: 3
Training loss: 2.326620101928711
Validation loss: 1.924545375249719

Epoch: 6| Step: 4
Training loss: 1.298665165901184
Validation loss: 1.9489344217443978

Epoch: 6| Step: 5
Training loss: 2.5851263999938965
Validation loss: 1.9736250062142648

Epoch: 6| Step: 6
Training loss: 1.8316562175750732
Validation loss: 1.9694240477777296

Epoch: 6| Step: 7
Training loss: 2.232787847518921
Validation loss: 1.9504238046625608

Epoch: 6| Step: 8
Training loss: 1.9109320640563965
Validation loss: 1.9200860338826333

Epoch: 6| Step: 9
Training loss: 1.4923831224441528
Validation loss: 1.927344904151014

Epoch: 6| Step: 10
Training loss: 1.5261328220367432
Validation loss: 1.8938845011495775

Epoch: 6| Step: 11
Training loss: 1.4294929504394531
Validation loss: 1.9020797847419657

Epoch: 6| Step: 12
Training loss: 2.3067991733551025
Validation loss: 1.8946489544324978

Epoch: 6| Step: 13
Training loss: 1.636492371559143
Validation loss: 1.9159984306622577

Epoch: 158| Step: 0
Training loss: 2.085486888885498
Validation loss: 1.9114180662298714

Epoch: 6| Step: 1
Training loss: 1.5531388521194458
Validation loss: 1.9205836173026793

Epoch: 6| Step: 2
Training loss: 1.6283538341522217
Validation loss: 1.9081945265493085

Epoch: 6| Step: 3
Training loss: 1.5145865678787231
Validation loss: 1.9106655787396174

Epoch: 6| Step: 4
Training loss: 1.8572473526000977
Validation loss: 1.897492854825912

Epoch: 6| Step: 5
Training loss: 2.5043230056762695
Validation loss: 1.9026078716401131

Epoch: 6| Step: 6
Training loss: 1.9589290618896484
Validation loss: 1.8839515139979701

Epoch: 6| Step: 7
Training loss: 1.9832066297531128
Validation loss: 1.8762814690989833

Epoch: 6| Step: 8
Training loss: 1.5936224460601807
Validation loss: 1.8746593139504875

Epoch: 6| Step: 9
Training loss: 1.36149001121521
Validation loss: 1.8732228215022753

Epoch: 6| Step: 10
Training loss: 2.0720953941345215
Validation loss: 1.8806519392997987

Epoch: 6| Step: 11
Training loss: 1.8816255331039429
Validation loss: 1.9179756487569501

Epoch: 6| Step: 12
Training loss: 2.3249120712280273
Validation loss: 1.8988147486922562

Epoch: 6| Step: 13
Training loss: 2.4744279384613037
Validation loss: 1.9022629825017785

Epoch: 159| Step: 0
Training loss: 1.8092124462127686
Validation loss: 1.8895713154987623

Epoch: 6| Step: 1
Training loss: 1.9245409965515137
Validation loss: 1.8946987710973269

Epoch: 6| Step: 2
Training loss: 2.347764015197754
Validation loss: 1.8749791934926023

Epoch: 6| Step: 3
Training loss: 1.7819304466247559
Validation loss: 1.8907119356175905

Epoch: 6| Step: 4
Training loss: 2.739826202392578
Validation loss: 1.8891212094214656

Epoch: 6| Step: 5
Training loss: 2.27812123298645
Validation loss: 1.8862167340452953

Epoch: 6| Step: 6
Training loss: 1.2167999744415283
Validation loss: 1.87249675104695

Epoch: 6| Step: 7
Training loss: 1.38401198387146
Validation loss: 1.869319506870803

Epoch: 6| Step: 8
Training loss: 1.855870246887207
Validation loss: 1.842656353468536

Epoch: 6| Step: 9
Training loss: 1.6791043281555176
Validation loss: 1.8627452209431639

Epoch: 6| Step: 10
Training loss: 2.1143181324005127
Validation loss: 1.8743729809279084

Epoch: 6| Step: 11
Training loss: 1.5304698944091797
Validation loss: 1.8752394299353323

Epoch: 6| Step: 12
Training loss: 2.2221884727478027
Validation loss: 1.8620174084940264

Epoch: 6| Step: 13
Training loss: 1.4230461120605469
Validation loss: 1.8326343195412749

Epoch: 160| Step: 0
Training loss: 1.389469027519226
Validation loss: 1.816736985278386

Epoch: 6| Step: 1
Training loss: 0.9930233955383301
Validation loss: 1.8115720825810586

Epoch: 6| Step: 2
Training loss: 2.086289882659912
Validation loss: 1.7969055419327111

Epoch: 6| Step: 3
Training loss: 1.5667527914047241
Validation loss: 1.807199025666842

Epoch: 6| Step: 4
Training loss: 1.6421594619750977
Validation loss: 1.8212616482088644

Epoch: 6| Step: 5
Training loss: 1.7432546615600586
Validation loss: 1.8412486468591998

Epoch: 6| Step: 6
Training loss: 1.511462688446045
Validation loss: 1.8673276414153397

Epoch: 6| Step: 7
Training loss: 1.8235934972763062
Validation loss: 1.8937716983979749

Epoch: 6| Step: 8
Training loss: 1.493149757385254
Validation loss: 1.9092183638644475

Epoch: 6| Step: 9
Training loss: 2.3768808841705322
Validation loss: 1.9211437573996923

Epoch: 6| Step: 10
Training loss: 2.478726625442505
Validation loss: 1.9088565713615828

Epoch: 6| Step: 11
Training loss: 1.857290506362915
Validation loss: 1.9074909917769893

Epoch: 6| Step: 12
Training loss: 2.8863394260406494
Validation loss: 1.8864524108107372

Epoch: 6| Step: 13
Training loss: 2.7025415897369385
Validation loss: 1.9098303010386806

Epoch: 161| Step: 0
Training loss: 1.7565734386444092
Validation loss: 1.922397631470875

Epoch: 6| Step: 1
Training loss: 1.6071455478668213
Validation loss: 1.9335817290890602

Epoch: 6| Step: 2
Training loss: 1.9638218879699707
Validation loss: 1.9217659696455924

Epoch: 6| Step: 3
Training loss: 2.1001880168914795
Validation loss: 1.8805415373976513

Epoch: 6| Step: 4
Training loss: 1.3839142322540283
Validation loss: 1.8709404071172078

Epoch: 6| Step: 5
Training loss: 1.5547442436218262
Validation loss: 1.8714669622400755

Epoch: 6| Step: 6
Training loss: 1.846492052078247
Validation loss: 1.8646129920918455

Epoch: 6| Step: 7
Training loss: 1.7797393798828125
Validation loss: 1.8607198807501024

Epoch: 6| Step: 8
Training loss: 1.7586185932159424
Validation loss: 1.8475209705291256

Epoch: 6| Step: 9
Training loss: 1.6390252113342285
Validation loss: 1.8814114678290583

Epoch: 6| Step: 10
Training loss: 2.7838149070739746
Validation loss: 1.8795686075764317

Epoch: 6| Step: 11
Training loss: 1.1959353685379028
Validation loss: 1.8640843591382426

Epoch: 6| Step: 12
Training loss: 2.202420711517334
Validation loss: 1.8480788136041293

Epoch: 6| Step: 13
Training loss: 2.1363444328308105
Validation loss: 1.8294579534120456

Epoch: 162| Step: 0
Training loss: 1.8662539720535278
Validation loss: 1.8137320703075779

Epoch: 6| Step: 1
Training loss: 1.6203961372375488
Validation loss: 1.811142167737407

Epoch: 6| Step: 2
Training loss: 1.6067174673080444
Validation loss: 1.7991675753747263

Epoch: 6| Step: 3
Training loss: 2.169720411300659
Validation loss: 1.825245995675364

Epoch: 6| Step: 4
Training loss: 1.839188575744629
Validation loss: 1.847917079925537

Epoch: 6| Step: 5
Training loss: 2.200753688812256
Validation loss: 1.86483585193593

Epoch: 6| Step: 6
Training loss: 1.7343263626098633
Validation loss: 1.8830975396658785

Epoch: 6| Step: 7
Training loss: 2.6747019290924072
Validation loss: 1.8962985161812074

Epoch: 6| Step: 8
Training loss: 1.2506694793701172
Validation loss: 1.9107372991500362

Epoch: 6| Step: 9
Training loss: 1.9246902465820312
Validation loss: 1.915023744747203

Epoch: 6| Step: 10
Training loss: 1.7401833534240723
Validation loss: 1.9413088060194446

Epoch: 6| Step: 11
Training loss: 1.5333788394927979
Validation loss: 1.9239004619659916

Epoch: 6| Step: 12
Training loss: 1.5292465686798096
Validation loss: 1.8839081820621286

Epoch: 6| Step: 13
Training loss: 1.2242932319641113
Validation loss: 1.8465432633635819

Epoch: 163| Step: 0
Training loss: 1.7721502780914307
Validation loss: 1.8379709566793134

Epoch: 6| Step: 1
Training loss: 1.3070448637008667
Validation loss: 1.8398858911247664

Epoch: 6| Step: 2
Training loss: 2.031637668609619
Validation loss: 1.8154032371377433

Epoch: 6| Step: 3
Training loss: 2.1550564765930176
Validation loss: 1.8232729845149542

Epoch: 6| Step: 4
Training loss: 2.0421087741851807
Validation loss: 1.8414893124693184

Epoch: 6| Step: 5
Training loss: 1.1168229579925537
Validation loss: 1.8818807332746443

Epoch: 6| Step: 6
Training loss: 1.8295661211013794
Validation loss: 1.8959686807406846

Epoch: 6| Step: 7
Training loss: 1.9579012393951416
Validation loss: 1.8664060946433776

Epoch: 6| Step: 8
Training loss: 1.146750569343567
Validation loss: 1.8527851143190939

Epoch: 6| Step: 9
Training loss: 1.173986792564392
Validation loss: 1.8386590275713193

Epoch: 6| Step: 10
Training loss: 1.988071084022522
Validation loss: 1.824775880382907

Epoch: 6| Step: 11
Training loss: 2.2860512733459473
Validation loss: 1.8571898450133622

Epoch: 6| Step: 12
Training loss: 2.512287139892578
Validation loss: 1.8303968393674461

Epoch: 6| Step: 13
Training loss: 1.6084100008010864
Validation loss: 1.8492812059258903

Epoch: 164| Step: 0
Training loss: 1.3346083164215088
Validation loss: 1.8800137555727394

Epoch: 6| Step: 1
Training loss: 2.1470978260040283
Validation loss: 1.962133663956837

Epoch: 6| Step: 2
Training loss: 1.4592771530151367
Validation loss: 1.9705836132008543

Epoch: 6| Step: 3
Training loss: 1.970461130142212
Validation loss: 1.932789251368533

Epoch: 6| Step: 4
Training loss: 1.4569237232208252
Validation loss: 1.8864078188455233

Epoch: 6| Step: 5
Training loss: 2.0648322105407715
Validation loss: 1.847782111937

Epoch: 6| Step: 6
Training loss: 2.114225387573242
Validation loss: 1.815565163089383

Epoch: 6| Step: 7
Training loss: 1.6534981727600098
Validation loss: 1.8210426248529905

Epoch: 6| Step: 8
Training loss: 2.3989734649658203
Validation loss: 1.8179617248555666

Epoch: 6| Step: 9
Training loss: 1.4637866020202637
Validation loss: 1.8150535155368108

Epoch: 6| Step: 10
Training loss: 2.1891355514526367
Validation loss: 1.8278313708561722

Epoch: 6| Step: 11
Training loss: 1.4763665199279785
Validation loss: 1.829106625690255

Epoch: 6| Step: 12
Training loss: 1.8455393314361572
Validation loss: 1.837515716911644

Epoch: 6| Step: 13
Training loss: 1.738198161125183
Validation loss: 1.8362609955572313

Epoch: 165| Step: 0
Training loss: 1.0782935619354248
Validation loss: 1.8478094890553465

Epoch: 6| Step: 1
Training loss: 2.076483964920044
Validation loss: 1.872513900520981

Epoch: 6| Step: 2
Training loss: 1.5632479190826416
Validation loss: 1.946649238627444

Epoch: 6| Step: 3
Training loss: 2.3732011318206787
Validation loss: 2.008962327434171

Epoch: 6| Step: 4
Training loss: 2.119095802307129
Validation loss: 2.0084339700719362

Epoch: 6| Step: 5
Training loss: 2.153810501098633
Validation loss: 1.9484700131159958

Epoch: 6| Step: 6
Training loss: 1.6255618333816528
Validation loss: 1.9100789088074879

Epoch: 6| Step: 7
Training loss: 1.3372278213500977
Validation loss: 1.8859006871459305

Epoch: 6| Step: 8
Training loss: 1.3765010833740234
Validation loss: 1.8878934383392334

Epoch: 6| Step: 9
Training loss: 1.7152202129364014
Validation loss: 1.895854252640919

Epoch: 6| Step: 10
Training loss: 1.5029884576797485
Validation loss: 1.8940532284398233

Epoch: 6| Step: 11
Training loss: 2.630354404449463
Validation loss: 1.8952907990383845

Epoch: 6| Step: 12
Training loss: 2.275609016418457
Validation loss: 1.8738683539052163

Epoch: 6| Step: 13
Training loss: 1.618957281112671
Validation loss: 1.877238586384763

Epoch: 166| Step: 0
Training loss: 1.748429775238037
Validation loss: 1.9128683510647024

Epoch: 6| Step: 1
Training loss: 1.8391506671905518
Validation loss: 1.9926023226912304

Epoch: 6| Step: 2
Training loss: 2.334434986114502
Validation loss: 1.9776708208104616

Epoch: 6| Step: 3
Training loss: 2.1651015281677246
Validation loss: 1.9316350542088991

Epoch: 6| Step: 4
Training loss: 1.6433125734329224
Validation loss: 1.861875000820365

Epoch: 6| Step: 5
Training loss: 2.292232036590576
Validation loss: 1.8577827868923065

Epoch: 6| Step: 6
Training loss: 0.7760525941848755
Validation loss: 1.8371422918893958

Epoch: 6| Step: 7
Training loss: 2.029867649078369
Validation loss: 1.8256730469324256

Epoch: 6| Step: 8
Training loss: 1.9204391241073608
Validation loss: 1.8289318148807814

Epoch: 6| Step: 9
Training loss: 1.9849567413330078
Validation loss: 1.8211658488037765

Epoch: 6| Step: 10
Training loss: 1.5572444200515747
Validation loss: 1.8196269965940906

Epoch: 6| Step: 11
Training loss: 1.515153408050537
Validation loss: 1.824491811055009

Epoch: 6| Step: 12
Training loss: 1.6681504249572754
Validation loss: 1.847338238070088

Epoch: 6| Step: 13
Training loss: 1.255574107170105
Validation loss: 1.886940715133503

Epoch: 167| Step: 0
Training loss: 1.4493331909179688
Validation loss: 1.8956700473703363

Epoch: 6| Step: 1
Training loss: 1.7999954223632812
Validation loss: 1.8849746552846764

Epoch: 6| Step: 2
Training loss: 1.6251866817474365
Validation loss: 1.8868703508889804

Epoch: 6| Step: 3
Training loss: 1.6200411319732666
Validation loss: 1.8621507972799323

Epoch: 6| Step: 4
Training loss: 1.0055309534072876
Validation loss: 1.8531537543060959

Epoch: 6| Step: 5
Training loss: 2.330183982849121
Validation loss: 1.8402907925267373

Epoch: 6| Step: 6
Training loss: 2.2083492279052734
Validation loss: 1.8496871609841623

Epoch: 6| Step: 7
Training loss: 1.519160270690918
Validation loss: 1.8791069587071736

Epoch: 6| Step: 8
Training loss: 1.4894319772720337
Validation loss: 1.8645552089137416

Epoch: 6| Step: 9
Training loss: 2.0705807209014893
Validation loss: 1.8753769115735126

Epoch: 6| Step: 10
Training loss: 1.647322416305542
Validation loss: 1.8762687521596109

Epoch: 6| Step: 11
Training loss: 1.8399996757507324
Validation loss: 1.9073417353373703

Epoch: 6| Step: 12
Training loss: 2.2203502655029297
Validation loss: 1.9510635355467438

Epoch: 6| Step: 13
Training loss: 1.634542465209961
Validation loss: 1.9383242860917123

Epoch: 168| Step: 0
Training loss: 1.7143206596374512
Validation loss: 1.8759247461954753

Epoch: 6| Step: 1
Training loss: 1.1269395351409912
Validation loss: 1.8610278098813948

Epoch: 6| Step: 2
Training loss: 1.6425727605819702
Validation loss: 1.8557120061689807

Epoch: 6| Step: 3
Training loss: 1.7351469993591309
Validation loss: 1.866032326093284

Epoch: 6| Step: 4
Training loss: 1.8816883563995361
Validation loss: 1.8586887672383299

Epoch: 6| Step: 5
Training loss: 1.3490049839019775
Validation loss: 1.8902215086003786

Epoch: 6| Step: 6
Training loss: 1.8835532665252686
Validation loss: 1.9112654616755824

Epoch: 6| Step: 7
Training loss: 2.0943784713745117
Validation loss: 1.9422890588801394

Epoch: 6| Step: 8
Training loss: 1.9121150970458984
Validation loss: 1.9831964995271416

Epoch: 6| Step: 9
Training loss: 1.5786442756652832
Validation loss: 1.9729457721915296

Epoch: 6| Step: 10
Training loss: 2.2058768272399902
Validation loss: 1.961223179294217

Epoch: 6| Step: 11
Training loss: 1.5153955221176147
Validation loss: 1.9402523527863205

Epoch: 6| Step: 12
Training loss: 1.8543667793273926
Validation loss: 1.9206645757921281

Epoch: 6| Step: 13
Training loss: 2.8078670501708984
Validation loss: 1.9000151413743214

Epoch: 169| Step: 0
Training loss: 1.9040230512619019
Validation loss: 1.8912039136373868

Epoch: 6| Step: 1
Training loss: 1.835191249847412
Validation loss: 1.8471578039148802

Epoch: 6| Step: 2
Training loss: 1.4246113300323486
Validation loss: 1.854900707480728

Epoch: 6| Step: 3
Training loss: 2.0562992095947266
Validation loss: 1.8246181549564484

Epoch: 6| Step: 4
Training loss: 2.0605592727661133
Validation loss: 1.7955906621871456

Epoch: 6| Step: 5
Training loss: 1.874969720840454
Validation loss: 1.7920773067782003

Epoch: 6| Step: 6
Training loss: 1.1783056259155273
Validation loss: 1.808326082844888

Epoch: 6| Step: 7
Training loss: 2.10595703125
Validation loss: 1.825238045825753

Epoch: 6| Step: 8
Training loss: 1.5914032459259033
Validation loss: 1.8359395842398367

Epoch: 6| Step: 9
Training loss: 1.2299587726593018
Validation loss: 1.8159379613014959

Epoch: 6| Step: 10
Training loss: 2.0603134632110596
Validation loss: 1.8135503184410833

Epoch: 6| Step: 11
Training loss: 1.36021888256073
Validation loss: 1.7977333825121644

Epoch: 6| Step: 12
Training loss: 1.4253854751586914
Validation loss: 1.8170191959668232

Epoch: 6| Step: 13
Training loss: 1.9026339054107666
Validation loss: 1.8223300441618888

Epoch: 170| Step: 0
Training loss: 1.8376303911209106
Validation loss: 1.7968648492649038

Epoch: 6| Step: 1
Training loss: 1.5943539142608643
Validation loss: 1.8150143956625333

Epoch: 6| Step: 2
Training loss: 1.7920711040496826
Validation loss: 1.8179040596049318

Epoch: 6| Step: 3
Training loss: 1.8287346363067627
Validation loss: 1.8352250693946757

Epoch: 6| Step: 4
Training loss: 1.6049551963806152
Validation loss: 1.8344849104522376

Epoch: 6| Step: 5
Training loss: 1.6996212005615234
Validation loss: 1.8517926572471537

Epoch: 6| Step: 6
Training loss: 2.142456531524658
Validation loss: 1.8488794911292292

Epoch: 6| Step: 7
Training loss: 2.02886962890625
Validation loss: 1.8929865616624073

Epoch: 6| Step: 8
Training loss: 2.7607309818267822
Validation loss: 1.889911954120923

Epoch: 6| Step: 9
Training loss: 1.2409799098968506
Validation loss: 1.9142543244105514

Epoch: 6| Step: 10
Training loss: 1.4722998142242432
Validation loss: 1.9059788565481863

Epoch: 6| Step: 11
Training loss: 1.2960753440856934
Validation loss: 1.899091394998694

Epoch: 6| Step: 12
Training loss: 1.3131462335586548
Validation loss: 1.8812758999486123

Epoch: 6| Step: 13
Training loss: 1.801270604133606
Validation loss: 1.8683773881645613

Epoch: 171| Step: 0
Training loss: 1.97701895236969
Validation loss: 1.879573538739194

Epoch: 6| Step: 1
Training loss: 1.6213667392730713
Validation loss: 1.8666051498023413

Epoch: 6| Step: 2
Training loss: 1.7989962100982666
Validation loss: 1.8819768787712179

Epoch: 6| Step: 3
Training loss: 2.052060604095459
Validation loss: 1.8679612234074583

Epoch: 6| Step: 4
Training loss: 1.7869319915771484
Validation loss: 1.880358556265472

Epoch: 6| Step: 5
Training loss: 1.2363917827606201
Validation loss: 1.9445771222473474

Epoch: 6| Step: 6
Training loss: 1.5950353145599365
Validation loss: 1.9837341359866563

Epoch: 6| Step: 7
Training loss: 1.7254760265350342
Validation loss: 1.9560884327016852

Epoch: 6| Step: 8
Training loss: 1.6873133182525635
Validation loss: 1.9221274622025029

Epoch: 6| Step: 9
Training loss: 1.721504807472229
Validation loss: 1.9035702110618673

Epoch: 6| Step: 10
Training loss: 1.3780289888381958
Validation loss: 1.8877774002731487

Epoch: 6| Step: 11
Training loss: 1.265857219696045
Validation loss: 1.869055148093931

Epoch: 6| Step: 12
Training loss: 2.4429984092712402
Validation loss: 1.8410373938980924

Epoch: 6| Step: 13
Training loss: 1.6058979034423828
Validation loss: 1.8367866854513846

Epoch: 172| Step: 0
Training loss: 1.779033899307251
Validation loss: 1.8208508209515644

Epoch: 6| Step: 1
Training loss: 1.6918647289276123
Validation loss: 1.8104450138666297

Epoch: 6| Step: 2
Training loss: 1.2968664169311523
Validation loss: 1.8466607985957977

Epoch: 6| Step: 3
Training loss: 2.005685329437256
Validation loss: 1.8494829080438102

Epoch: 6| Step: 4
Training loss: 1.7704540491104126
Validation loss: 1.883486073504212

Epoch: 6| Step: 5
Training loss: 1.9479930400848389
Validation loss: 1.892069766598363

Epoch: 6| Step: 6
Training loss: 1.7204585075378418
Validation loss: 1.9275045497443086

Epoch: 6| Step: 7
Training loss: 1.0015274286270142
Validation loss: 1.898868409536218

Epoch: 6| Step: 8
Training loss: 2.1090431213378906
Validation loss: 1.88148416883202

Epoch: 6| Step: 9
Training loss: 1.730997085571289
Validation loss: 1.878661714574342

Epoch: 6| Step: 10
Training loss: 1.911116600036621
Validation loss: 1.869170335031325

Epoch: 6| Step: 11
Training loss: 1.265702724456787
Validation loss: 1.8706717542422715

Epoch: 6| Step: 12
Training loss: 1.6538230180740356
Validation loss: 1.8508619569963025

Epoch: 6| Step: 13
Training loss: 1.9883923530578613
Validation loss: 1.8373906432941396

Epoch: 173| Step: 0
Training loss: 1.5409977436065674
Validation loss: 1.8427013940708612

Epoch: 6| Step: 1
Training loss: 1.5217843055725098
Validation loss: 1.8513735635306245

Epoch: 6| Step: 2
Training loss: 1.5332878828048706
Validation loss: 1.8376216721791092

Epoch: 6| Step: 3
Training loss: 1.0809483528137207
Validation loss: 1.8326812944104593

Epoch: 6| Step: 4
Training loss: 1.3213655948638916
Validation loss: 1.82905387942509

Epoch: 6| Step: 5
Training loss: 1.175729751586914
Validation loss: 1.818692761082803

Epoch: 6| Step: 6
Training loss: 1.389693021774292
Validation loss: 1.8086200760256859

Epoch: 6| Step: 7
Training loss: 2.301253318786621
Validation loss: 1.8298479651892057

Epoch: 6| Step: 8
Training loss: 2.171450138092041
Validation loss: 1.8263194394367996

Epoch: 6| Step: 9
Training loss: 2.1198782920837402
Validation loss: 1.8118315730043637

Epoch: 6| Step: 10
Training loss: 1.9553310871124268
Validation loss: 1.8286534252987112

Epoch: 6| Step: 11
Training loss: 2.065798759460449
Validation loss: 1.8309691875211653

Epoch: 6| Step: 12
Training loss: 1.2574567794799805
Validation loss: 1.8313557345380065

Epoch: 6| Step: 13
Training loss: 1.6958497762680054
Validation loss: 1.85011459935096

Epoch: 174| Step: 0
Training loss: 1.4791812896728516
Validation loss: 1.9007244494653517

Epoch: 6| Step: 1
Training loss: 1.7780895233154297
Validation loss: 1.9442812832452918

Epoch: 6| Step: 2
Training loss: 1.3022056818008423
Validation loss: 1.9642486520992812

Epoch: 6| Step: 3
Training loss: 1.719404935836792
Validation loss: 1.9083314621320335

Epoch: 6| Step: 4
Training loss: 1.74470853805542
Validation loss: 1.8571734812951857

Epoch: 6| Step: 5
Training loss: 1.574648141860962
Validation loss: 1.8356787645688621

Epoch: 6| Step: 6
Training loss: 1.2378888130187988
Validation loss: 1.8200095699679466

Epoch: 6| Step: 7
Training loss: 1.851370930671692
Validation loss: 1.7867405747854581

Epoch: 6| Step: 8
Training loss: 1.6682584285736084
Validation loss: 1.785650041795546

Epoch: 6| Step: 9
Training loss: 1.8731727600097656
Validation loss: 1.790998512698758

Epoch: 6| Step: 10
Training loss: 2.002809762954712
Validation loss: 1.787712109986172

Epoch: 6| Step: 11
Training loss: 1.6432931423187256
Validation loss: 1.7881891009628132

Epoch: 6| Step: 12
Training loss: 1.7417432069778442
Validation loss: 1.8204122128025177

Epoch: 6| Step: 13
Training loss: 1.480483889579773
Validation loss: 1.883408736157161

Epoch: 175| Step: 0
Training loss: 1.7603143453598022
Validation loss: 1.856065421976069

Epoch: 6| Step: 1
Training loss: 1.7962199449539185
Validation loss: 1.8633746075373825

Epoch: 6| Step: 2
Training loss: 1.4334654808044434
Validation loss: 1.876548336398217

Epoch: 6| Step: 3
Training loss: 1.5717847347259521
Validation loss: 1.9202129187122468

Epoch: 6| Step: 4
Training loss: 1.6956987380981445
Validation loss: 1.8962070429196922

Epoch: 6| Step: 5
Training loss: 2.2774760723114014
Validation loss: 1.8759296453127297

Epoch: 6| Step: 6
Training loss: 1.5937376022338867
Validation loss: 1.8457142883731472

Epoch: 6| Step: 7
Training loss: 1.7234272956848145
Validation loss: 1.8235320801376014

Epoch: 6| Step: 8
Training loss: 1.911663293838501
Validation loss: 1.814834003807396

Epoch: 6| Step: 9
Training loss: 1.4453420639038086
Validation loss: 1.802732877833869

Epoch: 6| Step: 10
Training loss: 0.9808169603347778
Validation loss: 1.7819034284160984

Epoch: 6| Step: 11
Training loss: 1.5318957567214966
Validation loss: 1.7809727704653175

Epoch: 6| Step: 12
Training loss: 1.1646687984466553
Validation loss: 1.8010201415707987

Epoch: 6| Step: 13
Training loss: 1.7191462516784668
Validation loss: 1.8122260006525184

Epoch: 176| Step: 0
Training loss: 1.8067654371261597
Validation loss: 1.7732396920522053

Epoch: 6| Step: 1
Training loss: 1.2315735816955566
Validation loss: 1.72308389986715

Epoch: 6| Step: 2
Training loss: 1.8954081535339355
Validation loss: 1.7088664077943372

Epoch: 6| Step: 3
Training loss: 1.1961652040481567
Validation loss: 1.7087068096283944

Epoch: 6| Step: 4
Training loss: 1.0019102096557617
Validation loss: 1.675906649199865

Epoch: 6| Step: 5
Training loss: 1.5474364757537842
Validation loss: 1.6996364260232577

Epoch: 6| Step: 6
Training loss: 1.8036768436431885
Validation loss: 1.7598715571946995

Epoch: 6| Step: 7
Training loss: 2.023221731185913
Validation loss: 1.791030360806373

Epoch: 6| Step: 8
Training loss: 1.468292474746704
Validation loss: 1.809866932130629

Epoch: 6| Step: 9
Training loss: 2.1063294410705566
Validation loss: 1.8468635543700187

Epoch: 6| Step: 10
Training loss: 1.6896941661834717
Validation loss: 1.8763078412702006

Epoch: 6| Step: 11
Training loss: 1.760534405708313
Validation loss: 1.9086205946501864

Epoch: 6| Step: 12
Training loss: 1.8148036003112793
Validation loss: 1.909725260990922

Epoch: 6| Step: 13
Training loss: 2.238229990005493
Validation loss: 1.8917684375598867

Epoch: 177| Step: 0
Training loss: 1.022848129272461
Validation loss: 1.8702184846324306

Epoch: 6| Step: 1
Training loss: 1.5149850845336914
Validation loss: 1.842514435450236

Epoch: 6| Step: 2
Training loss: 1.9817748069763184
Validation loss: 1.8773924766048309

Epoch: 6| Step: 3
Training loss: 1.9953746795654297
Validation loss: 1.8995611539451025

Epoch: 6| Step: 4
Training loss: 1.59735107421875
Validation loss: 1.900828146165417

Epoch: 6| Step: 5
Training loss: 1.2304402589797974
Validation loss: 1.8878007973394086

Epoch: 6| Step: 6
Training loss: 1.5678104162216187
Validation loss: 1.9490927009172336

Epoch: 6| Step: 7
Training loss: 1.6243512630462646
Validation loss: 2.032472986046986

Epoch: 6| Step: 8
Training loss: 2.0961029529571533
Validation loss: 2.1365152661518385

Epoch: 6| Step: 9
Training loss: 2.0134201049804688
Validation loss: 2.1138816777096

Epoch: 6| Step: 10
Training loss: 2.1420788764953613
Validation loss: 1.9456998725091257

Epoch: 6| Step: 11
Training loss: 1.865973949432373
Validation loss: 1.824450174967448

Epoch: 6| Step: 12
Training loss: 1.3382105827331543
Validation loss: 1.7357226776820358

Epoch: 6| Step: 13
Training loss: 1.6167362928390503
Validation loss: 1.7142412918870167

Epoch: 178| Step: 0
Training loss: 2.2752535343170166
Validation loss: 1.7126660962258615

Epoch: 6| Step: 1
Training loss: 1.6647634506225586
Validation loss: 1.7400122663026214

Epoch: 6| Step: 2
Training loss: 2.26023006439209
Validation loss: 1.7299804854136642

Epoch: 6| Step: 3
Training loss: 1.659272313117981
Validation loss: 1.7268201574202506

Epoch: 6| Step: 4
Training loss: 1.8370776176452637
Validation loss: 1.7253296964912004

Epoch: 6| Step: 5
Training loss: 1.4654383659362793
Validation loss: 1.7100470450616652

Epoch: 6| Step: 6
Training loss: 1.6612598896026611
Validation loss: 1.7429477130213091

Epoch: 6| Step: 7
Training loss: 1.9473954439163208
Validation loss: 1.7865102726926085

Epoch: 6| Step: 8
Training loss: 1.3803510665893555
Validation loss: 1.8383925807091497

Epoch: 6| Step: 9
Training loss: 2.29044246673584
Validation loss: 1.8773169491880684

Epoch: 6| Step: 10
Training loss: 1.847095012664795
Validation loss: 1.8835616573210685

Epoch: 6| Step: 11
Training loss: 2.15610933303833
Validation loss: 1.85068267391574

Epoch: 6| Step: 12
Training loss: 1.4147586822509766
Validation loss: 1.7846368602527085

Epoch: 6| Step: 13
Training loss: 0.8783214092254639
Validation loss: 1.7971688175714144

Epoch: 179| Step: 0
Training loss: 1.5793910026550293
Validation loss: 1.8335399371321484

Epoch: 6| Step: 1
Training loss: 1.6200190782546997
Validation loss: 1.8538491161920692

Epoch: 6| Step: 2
Training loss: 1.5473263263702393
Validation loss: 1.8526297051419494

Epoch: 6| Step: 3
Training loss: 1.7929306030273438
Validation loss: 1.8571682617228518

Epoch: 6| Step: 4
Training loss: 1.5939539670944214
Validation loss: 1.8888444131420505

Epoch: 6| Step: 5
Training loss: 2.2089507579803467
Validation loss: 1.9149090987379833

Epoch: 6| Step: 6
Training loss: 1.6747217178344727
Validation loss: 1.9056885434735207

Epoch: 6| Step: 7
Training loss: 1.7978237867355347
Validation loss: 1.905777867122363

Epoch: 6| Step: 8
Training loss: 1.0603053569793701
Validation loss: 1.8351432738765594

Epoch: 6| Step: 9
Training loss: 1.2752474546432495
Validation loss: 1.763113941556664

Epoch: 6| Step: 10
Training loss: 1.6536731719970703
Validation loss: 1.707191216048374

Epoch: 6| Step: 11
Training loss: 1.51162588596344
Validation loss: 1.712875896884549

Epoch: 6| Step: 12
Training loss: 1.974953293800354
Validation loss: 1.7393019430098995

Epoch: 6| Step: 13
Training loss: 2.027087450027466
Validation loss: 1.7412554833196825

Epoch: 180| Step: 0
Training loss: 1.6701401472091675
Validation loss: 1.7683158536111154

Epoch: 6| Step: 1
Training loss: 1.6289639472961426
Validation loss: 1.783846209126134

Epoch: 6| Step: 2
Training loss: 1.3184187412261963
Validation loss: 1.795243845191053

Epoch: 6| Step: 3
Training loss: 1.3315441608428955
Validation loss: 1.7646882521208895

Epoch: 6| Step: 4
Training loss: 1.612951636314392
Validation loss: 1.7621523949407762

Epoch: 6| Step: 5
Training loss: 1.5769248008728027
Validation loss: 1.7355315146907684

Epoch: 6| Step: 6
Training loss: 2.172956943511963
Validation loss: 1.6920984368170462

Epoch: 6| Step: 7
Training loss: 1.6151952743530273
Validation loss: 1.6906001798568233

Epoch: 6| Step: 8
Training loss: 1.9605947732925415
Validation loss: 1.7332578602657522

Epoch: 6| Step: 9
Training loss: 1.5391666889190674
Validation loss: 1.832100320887822

Epoch: 6| Step: 10
Training loss: 1.5711641311645508
Validation loss: 1.9170215668216828

Epoch: 6| Step: 11
Training loss: 2.1807010173797607
Validation loss: 2.0074492000764415

Epoch: 6| Step: 12
Training loss: 1.8147454261779785
Validation loss: 1.9799456045191774

Epoch: 6| Step: 13
Training loss: 1.3739123344421387
Validation loss: 1.8433368103478545

Epoch: 181| Step: 0
Training loss: 1.4259271621704102
Validation loss: 1.7732615368340605

Epoch: 6| Step: 1
Training loss: 1.538543462753296
Validation loss: 1.750516612042663

Epoch: 6| Step: 2
Training loss: 1.607576847076416
Validation loss: 1.7540477501448763

Epoch: 6| Step: 3
Training loss: 1.0456230640411377
Validation loss: 1.7786975112012637

Epoch: 6| Step: 4
Training loss: 2.1281213760375977
Validation loss: 1.7762900193532307

Epoch: 6| Step: 5
Training loss: 2.003538131713867
Validation loss: 1.7621406688485095

Epoch: 6| Step: 6
Training loss: 2.035548686981201
Validation loss: 1.6973021927700247

Epoch: 6| Step: 7
Training loss: 1.9771814346313477
Validation loss: 1.6759707620066981

Epoch: 6| Step: 8
Training loss: 1.1129869222640991
Validation loss: 1.735709878706163

Epoch: 6| Step: 9
Training loss: 1.4621392488479614
Validation loss: 1.8453803100893575

Epoch: 6| Step: 10
Training loss: 1.5803368091583252
Validation loss: 1.9708687400305143

Epoch: 6| Step: 11
Training loss: 2.2327754497528076
Validation loss: 2.0533256953762424

Epoch: 6| Step: 12
Training loss: 1.858372688293457
Validation loss: 2.0173510761671167

Epoch: 6| Step: 13
Training loss: 1.7699949741363525
Validation loss: 1.9841337973071682

Epoch: 182| Step: 0
Training loss: 1.444739580154419
Validation loss: 1.9099535980532247

Epoch: 6| Step: 1
Training loss: 1.279733419418335
Validation loss: 1.854311361107775

Epoch: 6| Step: 2
Training loss: 1.4071224927902222
Validation loss: 1.7702133117183563

Epoch: 6| Step: 3
Training loss: 1.143981695175171
Validation loss: 1.7656812014118317

Epoch: 6| Step: 4
Training loss: 1.5251338481903076
Validation loss: 1.7803263779609435

Epoch: 6| Step: 5
Training loss: 1.6264572143554688
Validation loss: 1.773194779631912

Epoch: 6| Step: 6
Training loss: 1.998282790184021
Validation loss: 1.7681784732367403

Epoch: 6| Step: 7
Training loss: 1.7487668991088867
Validation loss: 1.7531565773871638

Epoch: 6| Step: 8
Training loss: 1.3289164304733276
Validation loss: 1.7441980582411571

Epoch: 6| Step: 9
Training loss: 2.0320401191711426
Validation loss: 1.7685072921937512

Epoch: 6| Step: 10
Training loss: 1.4009101390838623
Validation loss: 1.7897646093881259

Epoch: 6| Step: 11
Training loss: 1.5693076848983765
Validation loss: 1.8261386245809577

Epoch: 6| Step: 12
Training loss: 1.8529871702194214
Validation loss: 1.8498647738528509

Epoch: 6| Step: 13
Training loss: 1.383690595626831
Validation loss: 1.8156695878633888

Epoch: 183| Step: 0
Training loss: 1.9676227569580078
Validation loss: 1.749331848595732

Epoch: 6| Step: 1
Training loss: 1.7657241821289062
Validation loss: 1.707015165718653

Epoch: 6| Step: 2
Training loss: 2.1240780353546143
Validation loss: 1.6711249620683732

Epoch: 6| Step: 3
Training loss: 1.2317276000976562
Validation loss: 1.6523852450873262

Epoch: 6| Step: 4
Training loss: 2.382375717163086
Validation loss: 1.656935759769973

Epoch: 6| Step: 5
Training loss: 1.6649795770645142
Validation loss: 1.657337442521126

Epoch: 6| Step: 6
Training loss: 1.225541353225708
Validation loss: 1.6622689167658489

Epoch: 6| Step: 7
Training loss: 1.8602213859558105
Validation loss: 1.6664331190047725

Epoch: 6| Step: 8
Training loss: 1.5429542064666748
Validation loss: 1.6910945497533327

Epoch: 6| Step: 9
Training loss: 1.1780864000320435
Validation loss: 1.697754898378926

Epoch: 6| Step: 10
Training loss: 1.6660308837890625
Validation loss: 1.7489181821064284

Epoch: 6| Step: 11
Training loss: 0.8532619476318359
Validation loss: 1.779789609293784

Epoch: 6| Step: 12
Training loss: 1.2401551008224487
Validation loss: 1.8402526865723312

Epoch: 6| Step: 13
Training loss: 0.9014813303947449
Validation loss: 1.86642195845163

Epoch: 184| Step: 0
Training loss: 1.2172850370407104
Validation loss: 1.9020439463277017

Epoch: 6| Step: 1
Training loss: 1.6864893436431885
Validation loss: 1.9091588784289617

Epoch: 6| Step: 2
Training loss: 1.6633391380310059
Validation loss: 1.8644312863708825

Epoch: 6| Step: 3
Training loss: 1.8511853218078613
Validation loss: 1.828454412439818

Epoch: 6| Step: 4
Training loss: 0.94420325756073
Validation loss: 1.7989325984831779

Epoch: 6| Step: 5
Training loss: 1.5525836944580078
Validation loss: 1.785131060948936

Epoch: 6| Step: 6
Training loss: 1.775911808013916
Validation loss: 1.7729047959850681

Epoch: 6| Step: 7
Training loss: 1.7162741422653198
Validation loss: 1.7805841738177883

Epoch: 6| Step: 8
Training loss: 1.5109095573425293
Validation loss: 1.7641681830088298

Epoch: 6| Step: 9
Training loss: 1.3528028726577759
Validation loss: 1.802022155895028

Epoch: 6| Step: 10
Training loss: 1.8893449306488037
Validation loss: 1.8026725233242076

Epoch: 6| Step: 11
Training loss: 1.3482067584991455
Validation loss: 1.7931549138920282

Epoch: 6| Step: 12
Training loss: 1.3586235046386719
Validation loss: 1.7814460928722093

Epoch: 6| Step: 13
Training loss: 1.4618041515350342
Validation loss: 1.7603712633091917

Epoch: 185| Step: 0
Training loss: 1.1534719467163086
Validation loss: 1.7188474965351883

Epoch: 6| Step: 1
Training loss: 1.1825973987579346
Validation loss: 1.7095331133052867

Epoch: 6| Step: 2
Training loss: 1.764963984489441
Validation loss: 1.6990045039884505

Epoch: 6| Step: 3
Training loss: 1.885523796081543
Validation loss: 1.6888924837112427

Epoch: 6| Step: 4
Training loss: 1.696192741394043
Validation loss: 1.700657993234614

Epoch: 6| Step: 5
Training loss: 1.6380586624145508
Validation loss: 1.758221254553846

Epoch: 6| Step: 6
Training loss: 0.9461584091186523
Validation loss: 1.809580006907063

Epoch: 6| Step: 7
Training loss: 0.9731619358062744
Validation loss: 1.849139041798089

Epoch: 6| Step: 8
Training loss: 1.3798989057540894
Validation loss: 1.903864593916042

Epoch: 6| Step: 9
Training loss: 1.3537790775299072
Validation loss: 1.9482378523836854

Epoch: 6| Step: 10
Training loss: 1.540364384651184
Validation loss: 1.9455020094430575

Epoch: 6| Step: 11
Training loss: 1.9214715957641602
Validation loss: 1.9023191159771335

Epoch: 6| Step: 12
Training loss: 2.163846731185913
Validation loss: 1.8194381934340282

Epoch: 6| Step: 13
Training loss: 2.0723860263824463
Validation loss: 1.7973677894120574

Epoch: 186| Step: 0
Training loss: 2.106757640838623
Validation loss: 1.773605187733968

Epoch: 6| Step: 1
Training loss: 1.8592499494552612
Validation loss: 1.7613965516449304

Epoch: 6| Step: 2
Training loss: 1.4597666263580322
Validation loss: 1.7778071024084603

Epoch: 6| Step: 3
Training loss: 1.5614993572235107
Validation loss: 1.7882723372469667

Epoch: 6| Step: 4
Training loss: 1.355324387550354
Validation loss: 1.7921816354156823

Epoch: 6| Step: 5
Training loss: 1.0443637371063232
Validation loss: 1.8453047685725714

Epoch: 6| Step: 6
Training loss: 1.416858196258545
Validation loss: 1.9041859398606003

Epoch: 6| Step: 7
Training loss: 1.5005786418914795
Validation loss: 1.9421772033937517

Epoch: 6| Step: 8
Training loss: 1.9827337265014648
Validation loss: 1.9432004062078332

Epoch: 6| Step: 9
Training loss: 1.9203641414642334
Validation loss: 1.891174049787624

Epoch: 6| Step: 10
Training loss: 1.284210205078125
Validation loss: 1.8409588849672707

Epoch: 6| Step: 11
Training loss: 0.9145675897598267
Validation loss: 1.805099477050125

Epoch: 6| Step: 12
Training loss: 1.8297300338745117
Validation loss: 1.7809494080082062

Epoch: 6| Step: 13
Training loss: 1.6183180809020996
Validation loss: 1.764227778680863

Epoch: 187| Step: 0
Training loss: 0.9925165176391602
Validation loss: 1.7616555998402257

Epoch: 6| Step: 1
Training loss: 1.4674406051635742
Validation loss: 1.7587226718984625

Epoch: 6| Step: 2
Training loss: 1.662672519683838
Validation loss: 1.7149319725651895

Epoch: 6| Step: 3
Training loss: 1.4204659461975098
Validation loss: 1.7298578344365603

Epoch: 6| Step: 4
Training loss: 1.281254529953003
Validation loss: 1.7520502510891165

Epoch: 6| Step: 5
Training loss: 1.4291908740997314
Validation loss: 1.7564673680131153

Epoch: 6| Step: 6
Training loss: 1.8897199630737305
Validation loss: 1.7904268387825257

Epoch: 6| Step: 7
Training loss: 1.1647582054138184
Validation loss: 1.7957855783483034

Epoch: 6| Step: 8
Training loss: 1.2484698295593262
Validation loss: 1.7907555680121146

Epoch: 6| Step: 9
Training loss: 1.3836123943328857
Validation loss: 1.790132822528962

Epoch: 6| Step: 10
Training loss: 1.9271024465560913
Validation loss: 1.748274459633776

Epoch: 6| Step: 11
Training loss: 1.722546100616455
Validation loss: 1.7719401531322028

Epoch: 6| Step: 12
Training loss: 1.5912010669708252
Validation loss: 1.7730607012266755

Epoch: 6| Step: 13
Training loss: 1.7001891136169434
Validation loss: 1.786877162994877

Epoch: 188| Step: 0
Training loss: 1.0155620574951172
Validation loss: 1.8331641202331872

Epoch: 6| Step: 1
Training loss: 1.5647716522216797
Validation loss: 1.876732054577079

Epoch: 6| Step: 2
Training loss: 1.4065935611724854
Validation loss: 1.8847261654433383

Epoch: 6| Step: 3
Training loss: 1.2871931791305542
Validation loss: 1.838590322002288

Epoch: 6| Step: 4
Training loss: 1.4240033626556396
Validation loss: 1.7779077714489353

Epoch: 6| Step: 5
Training loss: 1.426872968673706
Validation loss: 1.7515133619308472

Epoch: 6| Step: 6
Training loss: 1.4378966093063354
Validation loss: 1.7309205596164992

Epoch: 6| Step: 7
Training loss: 1.0939652919769287
Validation loss: 1.721563563551954

Epoch: 6| Step: 8
Training loss: 1.5607208013534546
Validation loss: 1.68374902074055

Epoch: 6| Step: 9
Training loss: 1.58793306350708
Validation loss: 1.6922264278575938

Epoch: 6| Step: 10
Training loss: 1.2390748262405396
Validation loss: 1.6944394291088145

Epoch: 6| Step: 11
Training loss: 1.2103867530822754
Validation loss: 1.7103365851986794

Epoch: 6| Step: 12
Training loss: 2.3513877391815186
Validation loss: 1.6991383785842566

Epoch: 6| Step: 13
Training loss: 1.9973078966140747
Validation loss: 1.7077387071424914

Epoch: 189| Step: 0
Training loss: 2.017054557800293
Validation loss: 1.6924119636576662

Epoch: 6| Step: 1
Training loss: 1.2461509704589844
Validation loss: 1.709663160385624

Epoch: 6| Step: 2
Training loss: 1.6148854494094849
Validation loss: 1.7186384726596136

Epoch: 6| Step: 3
Training loss: 1.3495323657989502
Validation loss: 1.7267247502521803

Epoch: 6| Step: 4
Training loss: 1.3328547477722168
Validation loss: 1.7314142898846698

Epoch: 6| Step: 5
Training loss: 1.7215484380722046
Validation loss: 1.7315812777447444

Epoch: 6| Step: 6
Training loss: 1.6964592933654785
Validation loss: 1.7358181591956847

Epoch: 6| Step: 7
Training loss: 1.1970477104187012
Validation loss: 1.7061300226437148

Epoch: 6| Step: 8
Training loss: 0.652956485748291
Validation loss: 1.714978071951097

Epoch: 6| Step: 9
Training loss: 1.6024020910263062
Validation loss: 1.7361952130512526

Epoch: 6| Step: 10
Training loss: 1.404824137687683
Validation loss: 1.7355797008801532

Epoch: 6| Step: 11
Training loss: 1.6510851383209229
Validation loss: 1.7394762449367072

Epoch: 6| Step: 12
Training loss: 1.4750072956085205
Validation loss: 1.6967615671055292

Epoch: 6| Step: 13
Training loss: 1.0250288248062134
Validation loss: 1.68044723233869

Epoch: 190| Step: 0
Training loss: 1.4363789558410645
Validation loss: 1.6705307229872672

Epoch: 6| Step: 1
Training loss: 1.3270611763000488
Validation loss: 1.679299924963264

Epoch: 6| Step: 2
Training loss: 1.5901058912277222
Validation loss: 1.6602622488493561

Epoch: 6| Step: 3
Training loss: 1.3523759841918945
Validation loss: 1.6654403363504717

Epoch: 6| Step: 4
Training loss: 2.1131696701049805
Validation loss: 1.6502887741211922

Epoch: 6| Step: 5
Training loss: 1.0736992359161377
Validation loss: 1.6535794696500223

Epoch: 6| Step: 6
Training loss: 1.4274811744689941
Validation loss: 1.6647230848189323

Epoch: 6| Step: 7
Training loss: 1.5365687608718872
Validation loss: 1.6972511327394875

Epoch: 6| Step: 8
Training loss: 1.2300190925598145
Validation loss: 1.7316922654387772

Epoch: 6| Step: 9
Training loss: 0.9276328086853027
Validation loss: 1.7628709859745477

Epoch: 6| Step: 10
Training loss: 1.6155791282653809
Validation loss: 1.7899105318130986

Epoch: 6| Step: 11
Training loss: 1.6036852598190308
Validation loss: 1.7607489760204027

Epoch: 6| Step: 12
Training loss: 1.3866660594940186
Validation loss: 1.7639724413553874

Epoch: 6| Step: 13
Training loss: 1.4200876951217651
Validation loss: 1.699919363503815

Epoch: 191| Step: 0
Training loss: 1.3560696840286255
Validation loss: 1.688150898102791

Epoch: 6| Step: 1
Training loss: 1.6593881845474243
Validation loss: 1.6801564693450928

Epoch: 6| Step: 2
Training loss: 0.7518870830535889
Validation loss: 1.660783604909015

Epoch: 6| Step: 3
Training loss: 1.498248815536499
Validation loss: 1.6988257297905542

Epoch: 6| Step: 4
Training loss: 0.9907114505767822
Validation loss: 1.7202412454030847

Epoch: 6| Step: 5
Training loss: 1.4322404861450195
Validation loss: 1.721668863809237

Epoch: 6| Step: 6
Training loss: 1.2542165517807007
Validation loss: 1.752423055710331

Epoch: 6| Step: 7
Training loss: 1.9479173421859741
Validation loss: 1.7393950390559372

Epoch: 6| Step: 8
Training loss: 1.1867166757583618
Validation loss: 1.7442233613742295

Epoch: 6| Step: 9
Training loss: 2.042558431625366
Validation loss: 1.7547672833165815

Epoch: 6| Step: 10
Training loss: 1.4225112199783325
Validation loss: 1.7486519390536892

Epoch: 6| Step: 11
Training loss: 1.157984972000122
Validation loss: 1.7485626333503312

Epoch: 6| Step: 12
Training loss: 1.3366997241973877
Validation loss: 1.7303061562199746

Epoch: 6| Step: 13
Training loss: 1.2097920179367065
Validation loss: 1.712876163503175

Epoch: 192| Step: 0
Training loss: 1.7856369018554688
Validation loss: 1.7078764976993683

Epoch: 6| Step: 1
Training loss: 1.739668607711792
Validation loss: 1.7144427504590762

Epoch: 6| Step: 2
Training loss: 1.197121262550354
Validation loss: 1.7129045442868305

Epoch: 6| Step: 3
Training loss: 0.8669739961624146
Validation loss: 1.7196866235425394

Epoch: 6| Step: 4
Training loss: 1.2023382186889648
Validation loss: 1.718139026754646

Epoch: 6| Step: 5
Training loss: 1.548384666442871
Validation loss: 1.693088423821234

Epoch: 6| Step: 6
Training loss: 1.5164366960525513
Validation loss: 1.6765855179038098

Epoch: 6| Step: 7
Training loss: 1.8594021797180176
Validation loss: 1.6656161072433635

Epoch: 6| Step: 8
Training loss: 1.2988059520721436
Validation loss: 1.656181909704721

Epoch: 6| Step: 9
Training loss: 1.3893158435821533
Validation loss: 1.66915423639359

Epoch: 6| Step: 10
Training loss: 1.6215845346450806
Validation loss: 1.6650685725673553

Epoch: 6| Step: 11
Training loss: 1.2010993957519531
Validation loss: 1.6655769604508595

Epoch: 6| Step: 12
Training loss: 1.318437099456787
Validation loss: 1.6680081941748177

Epoch: 6| Step: 13
Training loss: 0.5266435742378235
Validation loss: 1.693960843547698

Epoch: 193| Step: 0
Training loss: 1.1593862771987915
Validation loss: 1.7116055078403924

Epoch: 6| Step: 1
Training loss: 0.8398157358169556
Validation loss: 1.7440263878914617

Epoch: 6| Step: 2
Training loss: 1.8536860942840576
Validation loss: 1.7241984195606683

Epoch: 6| Step: 3
Training loss: 1.3673007488250732
Validation loss: 1.7201860656020462

Epoch: 6| Step: 4
Training loss: 1.2890065908432007
Validation loss: 1.704273607141228

Epoch: 6| Step: 5
Training loss: 1.3950488567352295
Validation loss: 1.6927981684284825

Epoch: 6| Step: 6
Training loss: 1.6016610860824585
Validation loss: 1.6699427058619838

Epoch: 6| Step: 7
Training loss: 1.5888532400131226
Validation loss: 1.6763196529880646

Epoch: 6| Step: 8
Training loss: 0.9112763404846191
Validation loss: 1.6690784385127406

Epoch: 6| Step: 9
Training loss: 1.8951818943023682
Validation loss: 1.6799029727135935

Epoch: 6| Step: 10
Training loss: 1.4715667963027954
Validation loss: 1.6783441523069977

Epoch: 6| Step: 11
Training loss: 0.9075207710266113
Validation loss: 1.692648668443003

Epoch: 6| Step: 12
Training loss: 1.2439624071121216
Validation loss: 1.668747527624971

Epoch: 6| Step: 13
Training loss: 1.5282633304595947
Validation loss: 1.666038550356383

Epoch: 194| Step: 0
Training loss: 1.4503748416900635
Validation loss: 1.6821877020661549

Epoch: 6| Step: 1
Training loss: 1.1995019912719727
Validation loss: 1.6985431742924515

Epoch: 6| Step: 2
Training loss: 1.0541751384735107
Validation loss: 1.6800101277648762

Epoch: 6| Step: 3
Training loss: 1.3532347679138184
Validation loss: 1.6971050667506393

Epoch: 6| Step: 4
Training loss: 1.76383638381958
Validation loss: 1.6770958009586538

Epoch: 6| Step: 5
Training loss: 1.0308315753936768
Validation loss: 1.6975676391714363

Epoch: 6| Step: 6
Training loss: 0.6275511980056763
Validation loss: 1.694266047528995

Epoch: 6| Step: 7
Training loss: 1.3509736061096191
Validation loss: 1.7125858465830486

Epoch: 6| Step: 8
Training loss: 1.3281798362731934
Validation loss: 1.7727675104653964

Epoch: 6| Step: 9
Training loss: 0.8104221820831299
Validation loss: 1.771148100976021

Epoch: 6| Step: 10
Training loss: 2.0491743087768555
Validation loss: 1.7791546660084878

Epoch: 6| Step: 11
Training loss: 1.4915279150009155
Validation loss: 1.7726763268952728

Epoch: 6| Step: 12
Training loss: 1.7754648923873901
Validation loss: 1.7370529777260237

Epoch: 6| Step: 13
Training loss: 1.5414992570877075
Validation loss: 1.7076331466756842

Epoch: 195| Step: 0
Training loss: 1.291707158088684
Validation loss: 1.6837232817885697

Epoch: 6| Step: 1
Training loss: 1.6087777614593506
Validation loss: 1.649992996646512

Epoch: 6| Step: 2
Training loss: 0.933394193649292
Validation loss: 1.6635358288723936

Epoch: 6| Step: 3
Training loss: 0.8062922358512878
Validation loss: 1.646964438499943

Epoch: 6| Step: 4
Training loss: 1.6953768730163574
Validation loss: 1.641735690896229

Epoch: 6| Step: 5
Training loss: 1.531963586807251
Validation loss: 1.69279940923055

Epoch: 6| Step: 6
Training loss: 1.0363794565200806
Validation loss: 1.7302951658925703

Epoch: 6| Step: 7
Training loss: 2.194248676300049
Validation loss: 1.7544500212515555

Epoch: 6| Step: 8
Training loss: 1.2366209030151367
Validation loss: 1.787712998287652

Epoch: 6| Step: 9
Training loss: 1.615344762802124
Validation loss: 1.8014440946681525

Epoch: 6| Step: 10
Training loss: 1.1539933681488037
Validation loss: 1.7957571245008899

Epoch: 6| Step: 11
Training loss: 1.2196135520935059
Validation loss: 1.8005534974477624

Epoch: 6| Step: 12
Training loss: 1.388273000717163
Validation loss: 1.757716150693996

Epoch: 6| Step: 13
Training loss: 1.6491445302963257
Validation loss: 1.7205521131074557

Epoch: 196| Step: 0
Training loss: 1.353046178817749
Validation loss: 1.6813212197314027

Epoch: 6| Step: 1
Training loss: 1.5427579879760742
Validation loss: 1.6803905387078562

Epoch: 6| Step: 2
Training loss: 1.181612253189087
Validation loss: 1.7299951609744821

Epoch: 6| Step: 3
Training loss: 1.6971428394317627
Validation loss: 1.7557642998233918

Epoch: 6| Step: 4
Training loss: 1.766592264175415
Validation loss: 1.76216628730938

Epoch: 6| Step: 5
Training loss: 1.7659223079681396
Validation loss: 1.745732730434787

Epoch: 6| Step: 6
Training loss: 1.755726933479309
Validation loss: 1.7337021225242204

Epoch: 6| Step: 7
Training loss: 1.3287689685821533
Validation loss: 1.7739740225576586

Epoch: 6| Step: 8
Training loss: 1.6214239597320557
Validation loss: 1.8243742322409024

Epoch: 6| Step: 9
Training loss: 1.024910569190979
Validation loss: 1.890939821479141

Epoch: 6| Step: 10
Training loss: 1.6217341423034668
Validation loss: 1.968493079626432

Epoch: 6| Step: 11
Training loss: 1.2367565631866455
Validation loss: 1.91556542534982

Epoch: 6| Step: 12
Training loss: 1.2211415767669678
Validation loss: 1.8267569016384821

Epoch: 6| Step: 13
Training loss: 1.3259800672531128
Validation loss: 1.8107388763017551

Epoch: 197| Step: 0
Training loss: 1.0197498798370361
Validation loss: 1.7716080052878267

Epoch: 6| Step: 1
Training loss: 1.1339268684387207
Validation loss: 1.7743661249837568

Epoch: 6| Step: 2
Training loss: 1.3883923292160034
Validation loss: 1.7414510737183273

Epoch: 6| Step: 3
Training loss: 1.435510277748108
Validation loss: 1.7285313567807596

Epoch: 6| Step: 4
Training loss: 1.0855530500411987
Validation loss: 1.7384655065433954

Epoch: 6| Step: 5
Training loss: 1.2170177698135376
Validation loss: 1.7420581707390406

Epoch: 6| Step: 6
Training loss: 2.1523609161376953
Validation loss: 1.7427041056335613

Epoch: 6| Step: 7
Training loss: 1.4772648811340332
Validation loss: 1.7029876375711093

Epoch: 6| Step: 8
Training loss: 1.0827263593673706
Validation loss: 1.7061348345971876

Epoch: 6| Step: 9
Training loss: 1.131109356880188
Validation loss: 1.6867737282988846

Epoch: 6| Step: 10
Training loss: 1.3550457954406738
Validation loss: 1.6861239120524416

Epoch: 6| Step: 11
Training loss: 1.3207030296325684
Validation loss: 1.7450901334003737

Epoch: 6| Step: 12
Training loss: 1.9340099096298218
Validation loss: 1.8719382311708184

Epoch: 6| Step: 13
Training loss: 1.0877655744552612
Validation loss: 1.9418192909609886

Epoch: 198| Step: 0
Training loss: 1.154902696609497
Validation loss: 2.042329988171977

Epoch: 6| Step: 1
Training loss: 1.5774608850479126
Validation loss: 2.045151860483231

Epoch: 6| Step: 2
Training loss: 1.4200170040130615
Validation loss: 1.9641853904211393

Epoch: 6| Step: 3
Training loss: 1.141538381576538
Validation loss: 1.834546132754254

Epoch: 6| Step: 4
Training loss: 1.6667581796646118
Validation loss: 1.7762216521847634

Epoch: 6| Step: 5
Training loss: 1.6183959245681763
Validation loss: 1.7621898728032266

Epoch: 6| Step: 6
Training loss: 1.2120368480682373
Validation loss: 1.7914964204193444

Epoch: 6| Step: 7
Training loss: 1.6389665603637695
Validation loss: 1.7829244393174366

Epoch: 6| Step: 8
Training loss: 0.9386593103408813
Validation loss: 1.7427734944128221

Epoch: 6| Step: 9
Training loss: 2.274089813232422
Validation loss: 1.6475456222411125

Epoch: 6| Step: 10
Training loss: 1.189347743988037
Validation loss: 1.6523855014513897

Epoch: 6| Step: 11
Training loss: 1.5513077974319458
Validation loss: 1.7048322564812117

Epoch: 6| Step: 12
Training loss: 1.5148738622665405
Validation loss: 1.7531771659851074

Epoch: 6| Step: 13
Training loss: 1.5986464023590088
Validation loss: 1.7318772269833473

Epoch: 199| Step: 0
Training loss: 1.114797830581665
Validation loss: 1.7153445072071527

Epoch: 6| Step: 1
Training loss: 0.9205206632614136
Validation loss: 1.7283912525382092

Epoch: 6| Step: 2
Training loss: 1.7288413047790527
Validation loss: 1.7005346462290774

Epoch: 6| Step: 3
Training loss: 0.7610935568809509
Validation loss: 1.6722557877981534

Epoch: 6| Step: 4
Training loss: 1.78486967086792
Validation loss: 1.5892572787500197

Epoch: 6| Step: 5
Training loss: 0.8170427083969116
Validation loss: 1.582046922817025

Epoch: 6| Step: 6
Training loss: 1.3743455410003662
Validation loss: 1.6047630079330937

Epoch: 6| Step: 7
Training loss: 1.0830061435699463
Validation loss: 1.6286166021900792

Epoch: 6| Step: 8
Training loss: 1.7953252792358398
Validation loss: 1.6614454279663742

Epoch: 6| Step: 9
Training loss: 1.748549461364746
Validation loss: 1.6623900180221887

Epoch: 6| Step: 10
Training loss: 1.7678656578063965
Validation loss: 1.6860907795608684

Epoch: 6| Step: 11
Training loss: 1.1369314193725586
Validation loss: 1.6962190225560179

Epoch: 6| Step: 12
Training loss: 1.9178003072738647
Validation loss: 1.7148912734882806

Epoch: 6| Step: 13
Training loss: 1.6609461307525635
Validation loss: 1.720484282380791

Epoch: 200| Step: 0
Training loss: 2.009476900100708
Validation loss: 1.7070002158482869

Epoch: 6| Step: 1
Training loss: 1.2944529056549072
Validation loss: 1.6697870787753855

Epoch: 6| Step: 2
Training loss: 1.1235113143920898
Validation loss: 1.6661103348578177

Epoch: 6| Step: 3
Training loss: 1.3210135698318481
Validation loss: 1.6039046254209293

Epoch: 6| Step: 4
Training loss: 1.3804872035980225
Validation loss: 1.5856057315744378

Epoch: 6| Step: 5
Training loss: 0.9386881589889526
Validation loss: 1.5842187660996632

Epoch: 6| Step: 6
Training loss: 1.4151721000671387
Validation loss: 1.5954713026682537

Epoch: 6| Step: 7
Training loss: 0.9847730994224548
Validation loss: 1.6128299300388624

Epoch: 6| Step: 8
Training loss: 1.5003515481948853
Validation loss: 1.6121217268769459

Epoch: 6| Step: 9
Training loss: 1.008033275604248
Validation loss: 1.6086454429934103

Epoch: 6| Step: 10
Training loss: 1.699616551399231
Validation loss: 1.6103016304713424

Epoch: 6| Step: 11
Training loss: 0.8957088589668274
Validation loss: 1.6385465283547678

Epoch: 6| Step: 12
Training loss: 1.592956781387329
Validation loss: 1.6586979768609489

Epoch: 6| Step: 13
Training loss: 0.8528826236724854
Validation loss: 1.6759278146169518

Testing loss: 2.52881621254815
